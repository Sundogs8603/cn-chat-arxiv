# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [FastMAC: Stochastic Spectral Sampling of Correspondence Graph](https://arxiv.org/abs/2403.08770) | 这项研究将图信号处理引入到对应图领域，提出了一种随机谱采样策略。 |
| [^2] | [Simple and Scalable Strategies to Continually Pre-train Large Language Models](https://arxiv.org/abs/2403.08763) | 通过简单和可扩展的学习率调整、重放数据的方法，可以在不重新训练的情况下，持续预训练大型语言模型以匹配完全重新训练时的性能。 |
| [^3] | [DAM: Dynamic Adapter Merging for Continual Video QA Learning](https://arxiv.org/abs/2403.08755) | 提出了一种用于持续视频问答学习的动态适配器合并方法DAM，能够减轻灾难性遗忘、有效适应不断到来的数据集、处理未知数据集输入，并允许在类似数据集领域之间共享知识。 |
| [^4] | [Steering LLMs Towards Unbiased Responses: A Causality-Guided Debiasing Framework](https://arxiv.org/abs/2403.08743) | 本文提出了一种基于因果关系的去偏倾框架，通过选择机制指导设计提示来减少大型语言模型(LLMs)产生的社会偏见。 |
| [^5] | [The Garden of Forking Paths: Observing Dynamic Parameters Distribution in Large Language Models](https://arxiv.org/abs/2403.08739) | 观察大型语言模型中动态参数分布的时间演变，特别是叉分效应，能帮助理解模型质量，减少训练成本和评估工作，同时实证显示稀疏权重有效性背后的原因。 |
| [^6] | [Ambient Diffusion Posterior Sampling: Solving Inverse Problems with Diffusion Models trained on Corrupted Data](https://arxiv.org/abs/2403.08728) | 提出了一种使用环境扩散后验采样解决逆问题的框架，能在受损数据上训练的扩散模型上表现出色，并在图像恢复和MRI模型训练中取得优越性能。 |
| [^7] | [Implicit Regularization of Gradient Flow on One-Layer Softmax Attention](https://arxiv.org/abs/2403.08699) | 研究了在一层Softmax注意力模型上指数损失函数的梯度流，发现在渐进最小化损失值时隐式最小化了关键和查询权重矩阵乘积的核范数，这种隐式正则化可通过与注意力权重相关的SVM问题描述。 |
| [^8] | [Token Alignment via Character Matching for Subword Completion](https://arxiv.org/abs/2403.08688) | 通过字符匹配实现标记对齐的方法，显著改进了生成模型在处理部分标记对齐的情景中的性能，包括空格前缀和部分缩进等微妙情况。 |
| [^9] | [Human Alignment of Large Language Models through Online Preference Optimisation](https://arxiv.org/abs/2403.08635) | 本文展示了两种最近对齐方法之间的等价性，并介绍了一种泛化版本，有助于实现大型语言模型与人类的对齐。 |
| [^10] | [Verifix: Post-Training Correction to Improve Label Noise Robustness with Verified Samples](https://arxiv.org/abs/2403.08618) | 提出了后训练校正的新范式，通过奇异值分解算法Verifix在初始训练后校正模型权重以减轻标签噪声，避免了重新训练的需求 |
| [^11] | [Link Prediction for Social Networks using Representation Learning and Heuristic-based Features](https://arxiv.org/abs/2403.08613) | 提出了一种结合启发式特征和学习表示的方法，用于社交网络中缺失链接的预测任务，取得了较好的性能提升 |
| [^12] | [MedInsight: A Multi-Source Context Augmentation Framework for Generating Patient-Centric Medical Responses using Large Language Models](https://arxiv.org/abs/2403.08607) | MedInsight是一种检索增强框架，通过从多个来源提取与患者医疗记录相关的背景信息，将其与大型语言模型输入结合，生成丰富的、针对患者的响应 |
| [^13] | [Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over Structured Environments](https://arxiv.org/abs/2403.08593) | LLMs借助Reasoning-Path-Editing (Readi)框架，可以在结构化环境中高效且忠实地推理，显著提升了多个KGQA和TableQA数据集上的表现。 |
| [^14] | [Non-discrimination Criteria for Generative Language Models](https://arxiv.org/abs/2403.08564) | 本文研究如何在生成式语言模型中识别和量化性别偏见，提出了三个生成式人工智能的非歧视标准并设计了相应的提示。 |
| [^15] | [Structural perspective on constraint-based learning of Markov networks](https://arxiv.org/abs/2403.08562) | 本论文从结构角度研究了基于约束的学习马尔可夫网络，发现了图的结构特性和学习所需测试数量之间的重要关系 |
| [^16] | [SM4Depth: Seamless Monocular Metric Depth Estimation across Multiple Cameras and Scenes by One Model](https://arxiv.org/abs/2403.08556) | SM4Depth通过一种新的预处理单元和深度间隔离散化的方法，解决了单目度量深度估计中的相机敏感性、场景精度不一致和数据依赖性等问题。 |
| [^17] | [Federated Knowledge Graph Unlearning via Diffusion Model](https://arxiv.org/abs/2403.08554) | 提出了FedDM，一个基于扩散模型的新框架，用于联邦知识图中的机器去学习。 |
| [^18] | [GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting](https://arxiv.org/abs/2403.08551) | 通过2D高斯喷涂实现图像表示和压缩，在GPU内存占用降低的情况下，提供了更快的渲染速度，并在表示性能上与INR相匹敌。 |
| [^19] | [HOLMES: HOLonym-MEronym based Semantic inspection for Convolutional Image Classifiers](https://arxiv.org/abs/2403.08536) | HOLMES提出了一种新技术，通过将标签分解为一组相关概念并提供部件级解释，来帮助理解和解释卷积图像分类模型。 |
| [^20] | [Pig aggression classification using CNN, Transformers and Recurrent Networks](https://arxiv.org/abs/2403.08528) | 研究开发了使用CNN、Transformer和循环网络对猪的攻击性进行分类的技术，从而解决了人工分析动物行为可能存在的错误和耗时问题。 |
| [^21] | [DiPrompT: Disentangled Prompt Tuning for Multiple Latent Domain Generalization in Federated Learning](https://arxiv.org/abs/2403.08506) | 提出了一种名为DiPrompT的解耦提示调整方法，通过学习适应提示来解决在联邦学习中对领域泛化的限制。 |
| [^22] | [Content-aware Masked Image Modeling Transformer for Stereo Image Compression](https://arxiv.org/abs/2403.08505) | 提出了一种名为CAMSIC的立体图像压缩框架，通过引入面向内容感知的掩码图像建模（MIM）技术，使得无需额外Transformer解码器就能捕捉空间和视差依赖关系，实验结果表明实现了最先进的率失真结果。 |
| [^23] | [Masked Generative Story Transformer with Character Guidance and Caption Augmentation](https://arxiv.org/abs/2403.08502) | 该论文提出了一种遮蔽生成故事变换器，利用字符引导和标题增强来实现一致性生成。 |
| [^24] | [Reproducibility and Geometric Intrinsic Dimensionality: An Investigation on Graph Neural Network Research](https://arxiv.org/abs/2403.08438) | 本文研究了图神经网络研究中的再现性和几何内在维度性问题，并引入机器学习中的再现性本体论，以及探讨了维度诅咒对数据收集、表示和分析的挑战。 |
| [^25] | [Search-based Optimisation of LLM Learning Shots for Story Point Estimation](https://arxiv.org/abs/2403.08430) | 使用搜索方法优化LLM在故事点估计中的表现，使其平均估计性能提高了59.34%。 |
| [^26] | [Software Vulnerability and Functionality Assessment using LLMs](https://arxiv.org/abs/2403.08429) | 本文调查了如何使用大型语言模型（LLMs）协助进行代码审查，重点关注标记安全漏洞代码和执行软件功能验证两个任务，结果显示专有模型表现优于开源模型 |
| [^27] | [Language-Driven Visual Consensus for Zero-Shot Semantic Segmentation](https://arxiv.org/abs/2403.08426) | 基于语言驱动的 LDVC 方法通过引入路由注意力机制，实现了零样本语义分割中的语义和视觉信息更好的对齐 |
| [^28] | [Specification Overfitting in Artificial Intelligence](https://arxiv.org/abs/2403.08425) | 本文定义了规格过度拟合问题，即系统过度关注指定指标而损害了高级要求和任务性能。 |
| [^29] | [Tastle: Distract Large Language Models for Automatic Jailbreak Attack](https://arxiv.org/abs/2403.08424) | Tastle是一种新颖的黑盒越狱框架，采用恶意内容隐藏和内存重构以及迭代优化算法，用于自动对大型语言模型进行红队攻击。 |
| [^30] | [Causal Graph Neural Networks for Wildfire Danger Prediction](https://arxiv.org/abs/2403.08414) | 通过将因果性与图神经网络相结合，模型能够显式地建模复杂变量之间的因果机理，提高了火灾模式预测的性能。 |
| [^31] | [Optimizing Risk-averse Human-AI Hybrid Teams](https://arxiv.org/abs/2403.08386) | 提出了一种经理通过强化学习方案学习如何在混合人工智能团队中最佳分配决策责任，并最小化不良团队行为导致的委派变更次数。 |
| [^32] | [Translating between SQL Dialects for Cloud Migration](https://arxiv.org/abs/2403.08375) | 本文讨论了云迁移中SQL数据库方言的转换困难，尽管有一些工具可以帮助转换方言，但并不能完全解决问题，需要人工干预。 |
| [^33] | [SMART: Submodular Data Mixture Strategy for Instruction Tuning](https://arxiv.org/abs/2403.08370) | SMART引入了一种新颖的数据混合策略，利用子模块函数为任务分配重要性分数，并在微调中重新分配预算，从而在指令调整任务中取得明显优势。 |
| [^34] | [Decoupled Federated Learning on Long-Tailed and Non-IID data with Feature Statistics](https://arxiv.org/abs/2403.08364) | 本文提出了针对长尾和非独立同分布数据的特征统计分开式联邦学习框架，通过两阶段方式解决尾部类别稀疏分布导致的模型性能下降问题 |
| [^35] | [Data augmentation with automated machine learning: approaches and performance comparison with classical data augmentation methods](https://arxiv.org/abs/2403.08352) | 自动化机器学习的数据增强方法旨在自动化数据增强过程，为改善机器学习模型泛化性能提供了更高效的方式。 |
| [^36] | [LLM-Assisted Light: Leveraging Large Language Model Capabilities for Human-Mimetic Traffic Signal Control in Complex Urban Environments](https://arxiv.org/abs/2403.08337) | 本研究提出了将大型语言模型(LLMs)整合到交通信号控制(TSC)系统中的创新方法，以解决传统TSC系统在适应不熟悉场景方面的限制，并提出了一个混合框架，使得LLMs与一系列感知和决策工具相结合，从而提升TSC系统对城市交通复杂性和变异性的管理能力。 |
| [^37] | [A Sparsity Principle for Partially Observable Causal Representation Learning](https://arxiv.org/abs/2403.08335) | 提出了部分可观测因果表示学习的稀疏原则，建立了两个可识别性结果，为线性混合函数和分段线性混合函数设置了基础模型。 |
| [^38] | [Fast Inference of Removal-Based Node Influence](https://arxiv.org/abs/2403.08333) | 提出了一种评估节点影响的新方法，通过测量训练好的图神经网络模型在移除节点后的预测变化，以实现快速推断。 |
| [^39] | [Autoregressive Score Generation for Multi-trait Essay Scoring](https://arxiv.org/abs/2403.08332) | 提出一种自回归预测多特征分数的方法（ArTS），通过利用预先训练的T5来结合解码过程，实现了自动作文评分中多分数预测的效果。 |
| [^40] | [Knowledge Conflicts for LLMs: A Survey](https://arxiv.org/abs/2403.08319) | 这项调查深入分析了LLMs在融合上下文和参数化知识时所面临的知识冲突，探讨了三类知识冲突对其可信度和性能的重要影响，并提出改进LLMs稳健性策略的策略。 |
| [^41] | [StreamingDialogue: Prolonged Dialogue Learning via Long Context Compression with Minimal Losses](https://arxiv.org/abs/2403.08312) | 提出了StreamingDialogue，通过将长对话历史压缩为"会话注意力汇集点"，最小化损失，使计算复杂度减少，并有潜力处理超过200k条话语，实现长时间对话学习 |
| [^42] | [HRLAIF: Improvements in Helpfulness and Harmlessness in Open-domain Reinforcement Learning From AI Feedback](https://arxiv.org/abs/2403.08309) | 提出了HRLAIF方法来改善开放域强化学习中的模型响应帮助性，通过增强AI注释响应的准确性来提高模型在训练过程中的鲁棒性 |
| [^43] | [AutoDev: Automated AI-Driven Development](https://arxiv.org/abs/2403.08299) | AutoDev是一个完全自动化的AI驱动软件开发框架，旨在实现复杂软件工程任务的自主规划和执行。 |
| [^44] | [Gemma: Open Models Based on Gemini Research and Technology](https://arxiv.org/abs/2403.08295) | Gemma是基于Gemini研究和技术所构建的开放模型系列，在语言理解、推理和安全性等方面表现出色，负责任地发布这些大型语言模型对于提高前沿模型的安全性至关重要。 |
| [^45] | [Generative Pretrained Structured Transformers: Unsupervised Syntactic Language Models at Scale](https://arxiv.org/abs/2403.08293) | GPST是一种无监督的句法语言模型，通过联合训练两个模型实现对原始文本的高并行预训练，克服了之前SLM依赖于黄金树和顺序训练的限制，展示了在多个任务中优于同等规模的GPT-2。 |
| [^46] | [Weak Collocation Regression for Inferring Stochastic Dynamics with L\'{e}vy Noise](https://arxiv.org/abs/2403.08292) | 本文提出了一种弱配对回归（WCR）方法，可以从离散的聚合数据中明确揭示具有Lévy噪声的随机微分方程（SDE），填补了在提取具有Lévy噪声的随机动力学方面的空白。 |
| [^47] | [CleanAgent: Automating Data Standardization with LLM-based Agents](https://arxiv.org/abs/2403.08291) | 提出了一个具有声明性、统一API的Python库，通过简洁的API调用简化LLM的代码生成流程 |
| [^48] | [Mastering Text, Code and Math Simultaneously via Fusing Highly Specialized Language Models](https://arxiv.org/abs/2403.08281) | 通过融合高度专业化的语言、代码和数学模型，提出了一种名为UltraFuser的融合框架，引入了标记级别的门控机制，并设计了两阶段训练策略，以同时在三个领域取得高性能。 |
| [^49] | [LiqD: A Dynamic Liquid Level Detection Model under Tricky Small Containers](https://arxiv.org/abs/2403.08273) | 提出了一种基于U^2-Net的容器动态液位检测模型，通过SAM模型生成初始数据集并结合SemiReward框架过滤伪标签图像，使用U^2-Net提取掩模图像并进行形态学处理，最终通过轻量级神经网络实现液位分类 |
| [^50] | [Efficient Prompt Tuning of Large Vision-Language Model for Fine-Grained Ship Classification](https://arxiv.org/abs/2403.08271) | 本研究使用大规模预训练的视觉-语言模型，提出了一种高效的提示调整方法，以增强未见船舶类别的分类准确性。 |
| [^51] | [Random Search as a Baseline for Sparse Neural Network Architecture Search](https://arxiv.org/abs/2403.08265) | 论文提出了一种评估方法和基于随机搜索的基线方法，用于发现高质量的稀疏神经网络配置，以解决当前缺乏可靠比较和可重现性的问题。 |
| [^52] | [GPT, Ontology, and CAABAC: A Tripartite Personalized Access Control Model Anchored by Compliance, Context and Attribute](https://arxiv.org/abs/2403.08264) | GPT-Onto-CAABAC框架整合了GPT、本体论和CAABAC，动态解释策略并提供定制的访问控制解决方案，有效提高了EHR安全性，适应复杂的法规和情境要求。 |
| [^53] | [CoroNetGAN: Controlled Pruning of GANs via Hypernetworks](https://arxiv.org/abs/2403.08261) | CoroNetGAN通过超网络结合可微剪枝方法，提出了一种压缩GAN的方法，具有可控的压缩优势并显著减少训练时间 |
| [^54] | [Emergence of Social Norms in Large Language Model-based Agent Societies](https://arxiv.org/abs/2403.08251) | 提出了第一个赋予大型语言模型Agent群体内社会规范出现的生成式Agent架构CRSEC，实验证明其能力。 |
| [^55] | [A Novel Feature Learning-based Bio-inspired Neural Network for Real-time Collision-free Rescue of Multi-Robot Systems](https://arxiv.org/abs/2403.08238) | 该论文提出了一种基于特征学习的仿生神经网络方法，用于在多机器人系统中实时生成无碰救援路径，在复杂环境中快速响应环境变化，提高了救援效率。 |
| [^56] | [Robust Decision Aggregation with Adversarial Experts](https://arxiv.org/abs/2403.08222) | 论文考虑了在既有真实专家又有对抗性专家的情况下的二元决策聚合问题，提出了设计鲁棒聚合器以最小化遗憾的方法，并证明了当真实专家是对称的且对抗性专家不太多时，截尾均值是最优的。 |
| [^57] | [LIX: Implicitly Infusing Spatial Geometric Prior Knowledge into Visual Semantic Segmentation for Autonomous Driving](https://arxiv.org/abs/2403.08215) | 将双编码器教师模型获得的空间几何先验知识隐式注入单编码器学生模型，通过新的logit蒸馏和特征蒸馏方法，解决自动驾驶中的视觉语义分割问题。 |
| [^58] | [P2LHAP:Wearable sensor-based human activity recognition, segmentation and forecast through Patch-to-Label Seq2Seq Transformer](https://arxiv.org/abs/2403.08214) | P2LHAP提出了一种新颖的Patch-to-Label Seq2Seq框架，可以在一个高效的单一任务模型中同时实现人类活动的分割、识别和预测 |
| [^59] | [Large Language Models are Contrastive Reasoners](https://arxiv.org/abs/2403.08211) | 对比提示方法显著提高大型语言模型进行复杂推理的能力，不仅在算术、常识和符号推理任务上表现优良，还可以与现有提示方法整合，实现更好的性能。 |
| [^60] | [Deep Submodular Peripteral Network](https://arxiv.org/abs/2403.08199) | 引入了深度子模逆点网络（DSPNs），并提出了一种使用对比学习启发的GPC-ready策略进行训练的方法，以应对子模函数学习中的两大挑战。 |
| [^61] | [PAGE: Domain-Incremental Adaptation with Past-Agnostic Generative Replay for Smart Healthcare](https://arxiv.org/abs/2403.08197) | PAGE提出了一种面向智能医疗的领域增量适应策略，能够在不依赖于保留数据或信息的情况下实现生成回放，有效平衡领域适应和知识保留，并结合扩展的归纳确认预测方法提供可解释的疾病检测预测。 |
| [^62] | [Rethinking Loss Functions for Fact Verification](https://arxiv.org/abs/2403.08174) | 提出了专为FEVER任务定制的两种任务特定目标函数，相比标准交叉熵在事实验证中表现更好，并通过简单类别加权进一步提高性能。 |
| [^63] | [LAFS: Landmark-based Facial Self-supervised Learning for Face Recognition](https://arxiv.org/abs/2403.08161) | 本研究提出了一种基于地标的人脸自监督学习方法，通过利用面部地标定位的补丁来学习更适合于人脸识别的关键表示。 |
| [^64] | [The Runtime of Random Local Search on the Generalized Needle Problem](https://arxiv.org/abs/2403.08153) | 本研究在广义Needle问题上研究了随机局部搜索的运行时间，提出了一种新的确定参数$k$影响的下限方法，并改进了现有的预期运行时间上限。 |
| [^65] | [Measuring the Energy Consumption and Efficiency of Deep Neural Networks: An Empirical Analysis and Design Recommendations](https://arxiv.org/abs/2403.08151) | 这项研究针对大规模神经网络不断增长的能耗问题进行了实证分析，提出了一个考虑网络尺寸、计算和内存层次结构的能耗模型。 |
| [^66] | [From Paper to Card: Transforming Design Implications with Generative AI](https://arxiv.org/abs/2403.08137) | 使用生成人工智能构建系统，从学术论文中创建设计卡片，帮助设计师更好理解设计启示并提高沟通效率。 |
| [^67] | [RoboCertProb: Property Specification for Probabilistic RoboChart Models](https://arxiv.org/abs/2403.08136) | 本研究提出了RoboCertProb，用于指定在RoboChart中建模的概率机器人系统的定量属性，并通过基于PCTL*的语义和马尔可夫语义（DTMCs和MDPs），支持对这些属性进行解释和验证。 |
| [^68] | [Physics-Inspired Deep Learning Anti-Aliasing Framework in Efficient Channel State Feedback](https://arxiv.org/abs/2403.08133) | 本文引入了一种新的CSI上采样框架，利用物理原理和学习方法，有效解决了在大规模MIMO FDD系统中由欠采样导致的混叠效应问题。 |
| [^69] | [Towards Independence Criterion in Machine Unlearning of Features and Labels](https://arxiv.org/abs/2403.08124) | 提出了一种利用影响函数和分布独立原则的新方法，以应对机器遗忘中非均匀特征和标签删除的挑战，保护隐私同时保持模型性能和适应性 |
| [^70] | [Characterising harmful data sources when constructing multi-fidelity surrogate models](https://arxiv.org/abs/2403.08118) | 研究指出在构建多保真度代理模型时，有害数据源的特征化有助于指导从业者在选择时何时忽略某个数据源。 |
| [^71] | [Legally Binding but Unfair? Towards Assessing Fairness of Privacy Policies](https://arxiv.org/abs/2403.08115) | 本研究旨在评估隐私政策的公平性，通过从法律来源和公平性研究中确定信息公正性、表现公正性和道德/伦理与隐私政策的关系，并提出自动评估政策的选项。 |
| [^72] | [AI-Assisted Causal Pathway Diagram for Human-Centered Design](https://arxiv.org/abs/2403.08111) | 本文研究了将因果路径图整合到人类中心设计中的方法，开发了专用插件用于在线协作白板平台，通过用户研究发现其支持设计过程中的分散和集中阶段，减少设计师的认知负荷并增加创造力。 |
| [^73] | [Contextual Clarity: Generating Sentences with Transformer Models using Context-Reverso Data](https://arxiv.org/abs/2403.08103) | 使用Transformer模型和Context-Reverso数据生成具有上下文清晰度的句子 |
| [^74] | [Mechanics of Next Token Prediction with Self-Attention](https://arxiv.org/abs/2403.08081) | 通过梯度下降训练自注意力学习到一个自动机，在下一个标记预测中生成标记的两个不同步骤是：硬检索和软组合。 |
| [^75] | [A Multimodal Intermediate Fusion Network with Manifold Learning for Stress Detection](https://arxiv.org/abs/2403.08077) | 该论文提出了一种具有流形学习的中间多模态融合网络，从多个模态中捕获协同特征，并通过维度降低优化多模态学习，提高压力检测准确性，同时减少计算复杂性。 |
| [^76] | [FluoroSAM: A Language-aligned Foundation Model for X-ray Image Segmentation](https://arxiv.org/abs/2403.08059) | FluoroSAM是用于X光图像的分割的语言对齐基础模型，提供了一种在X光成像领域具有广泛适用性的自动图像分析工具。 |
| [^77] | [TutoAI: A Cross-domain Framework for AI-assisted Mixed-media Tutorial Creation on Physical Tasks](https://arxiv.org/abs/2403.08049) | TutoAI 是一个跨领域的框架，用于在物理任务上利用AI辅助混合媒体教程创建，通过调查常见教程组件、评估AI模型提取组件的方法以及设计UI支持教程创建的指南，证明了其较基准模型具有更高或相似的质量。 |
| [^78] | [A Review of Cybersecurity Incidents in the Food and Agriculture Sector](https://arxiv.org/abs/2403.08036) | 该综述分析了食品与农业领域的网络安全事件并报告了不断增加的网络安全威胁频率。 |
| [^79] | [Harnessing Artificial Intelligence to Combat Online Hate: Exploring the Challenges and Opportunities of Large Language Models in Hate Speech Detection](https://arxiv.org/abs/2403.08035) | 该论文围绕大型语言模型（LLMs）在检测和分类令人憎恶或有毒内容方面的作用展开文献综述和实证分析，旨在揭示LLM在识别令人憎恶内容方面的能力及其影响因素。 |
| [^80] | [LG-Traj: LLM Guided Pedestrian Trajectory Prediction](https://arxiv.org/abs/2403.08032) | 本文探讨了利用大型语言模型（LLMs）改进行人轨迹预测任务的可能性，通过引入运动线索来提高模型性能，并通过LG-Traj方法结合LLMs生成过去和未来轨迹中的运动线索，以增进对行人轨迹的理解。 |
| [^81] | [Red Teaming Models for Hyperspectral Image Analysis Using Explainable AI](https://arxiv.org/abs/2403.08017) | 本文介绍了一种使用可解释人工智能的红队建模方法，用于检验高光谱图像上的机器学习模型，并成功构建出一个只使用1%的输入特征即可达到可比较性能的模型。 |
| [^82] | [Gujarati-English Code-Switching Speech Recognition using ensemble prediction of spoken language](https://arxiv.org/abs/2403.08011) | 通过在输出中以每层有监督的方式对单词和字符的语言ID条件化变压器层，该方法虽然未能显著降低词错误率，但展现了在仅仅通过口语数据预测正确语言的潜力。 |
| [^83] | [Pix2Pix-OnTheFly: Leveraging LLMs for Instruction-Guided Image Editing](https://arxiv.org/abs/2403.08004) | 本文提出了一种新方法，实现了基于自然语言指令的图像编辑，在不需要任何预备工作的情况下，通过图像字幕和DDIM反演，获取编辑方向嵌入，进行指导图像编辑，表现出有效性和竞争力。 |
| [^84] | [Do Agents Dream of Electric Sheep?: Improving Generalization in Reinforcement Learning through Generative Learning](https://arxiv.org/abs/2403.07979) | 通过生成式增强技术，本研究研究了在稀疏奖励环境中通过基于想象力的强化学习训练来提高强化学习智能体泛化能力的方法。 |
| [^85] | [KnowCoder: Coding Structured Knowledge into LLMs for Universal Information Extraction](https://arxiv.org/abs/2403.07969) | 本文提出了KnowCoder，一个通过代码生成执行普适信息提取的大型语言模型，引入了代码风格的模式表示方法和两阶段学习框架，以提高LLMs对结构化知识的准确提取能力 |
| [^86] | [Do Deep Neural Network Solutions Form a Star Domain?](https://arxiv.org/abs/2403.07968) | SGD解决方案集是一个星形域，包含一个星形模型，通过低损失数值的路径与其他解决方案线性相连，模除排列。 |
| [^87] | [Conditional computation in neural networks: principles and research trends](https://arxiv.org/abs/2403.07965) | 该论文总结了将条件计算方法应用于设计神经网络的新兴领域中的原理和思想，并介绍了专家混合网络、标记选择机制和提前退出神经网络等三种实现方式。 |
| [^88] | [Optimal Design and Implementation of an Open-source Emulation Platform for User-Centric Shared E-mobility Services](https://arxiv.org/abs/2403.07964) | 提供了一种开源框架，用于共享电动出行，以代理-环路方法和模块化架构为特色，旨在弥补现有共享电动出行服务的设计缺陷，向电动出行研究社区提供福利。 |
| [^89] | [An Interpretable Generalization Mechanism for Accurately Detecting Anomaly and Identifying Networking Intrusion Techniques](https://arxiv.org/abs/2403.07959) | IG是一个可解释泛化机制，能够准确区分正常和异常的网络流量，并揭示复杂的入侵路径，为网络安全取证提供重要见解。 |
| [^90] | [Temporal Decisions: Leveraging Temporal Correlation for Efficient Decisions in Early Exit Neural Networks](https://arxiv.org/abs/2403.07958) | 该论文引入了差异检测和时间耐心作为早期退出神经网络的决策机制，利用传感器数据流中的时间相关性来有效终止推断。 |
| [^91] | [Efficient Post-Training Augmentation for Adaptive Inference in Heterogeneous and Distributed IoT Environments](https://arxiv.org/abs/2403.07957) | 提出了一种自动增强流程，能够将现有模型转换为早期退出神经网络（EENN），提高神经网络部署效率，实现了在物联网和图像分类用例上显著减少推断操作的效果。 |
| [^92] | [DeepCDCL: An CDCL-based Neural Network Verification Framework](https://arxiv.org/abs/2403.07956) | 提出了一种基于CDCL算法的神经网络验证框架DeepCDCL，通过引入异步子句学习和管理结构，显著减少了时间消耗，并在ACAS Xu和MNIST数据集上展示了显著的加速。 |
| [^93] | [Towards Faithful Explanations: Boosting Rationalization with Shortcuts Discovery](https://arxiv.org/abs/2403.07955) | 本文提出了一种Shortcuts-fused Selective Rationalization (SSR)方法，通过发现和利用潜在的快捷方式来提升理性化，并通过两种策略缓解利用快捷方式来组成理性化的问题，以及通过数据增强方法来补充已注释理性化数量的差距。 |
| [^94] | [Abstracting Sparse DNN Acceleration via Structured Sparse Tensor Decomposition](https://arxiv.org/abs/2403.07953) | 本文提出了通过结构化分解张量进一步抽象稀疏DNN加速的方法，实现了将稀疏张量转换成一系列结构化稀疏张量，从而弥合了稀疏DNN模型和硬件之间的差距。 |
| [^95] | [AesopAgent: Agent-driven Evolutionary System on Story-to-Video Production](https://arxiv.org/abs/2403.07952) | AesopAgent是一种基于Agent的故事到视频制作系统，能将用户故事提案转化为剧本、图像和音频，并将这些内容集成为视频，同时确保生成的视频内容丰富且连贯。 |
| [^96] | [Algorithmic Bayesian Epistemology](https://arxiv.org/abs/2403.07949) | 这里是中文总结出的一句话要点: 本论文将算法视角应用于贝叶斯认识论，挑战传统方法在信息不完备情况下的应用，为个体如何演化其信念提供了新的理论视角。 |
| [^97] | [WorldGPT: A Sora-Inspired Video AI Agent as Rich World Models from Text and Image Inputs](https://arxiv.org/abs/2403.07944) | 本文提出了一种视频生成AI代理，通过结合文本提示和图像输入，利用Sora启发的多模态学习技术构建丰富的世界模型，有效解决了视频生成中的时间一致性和动作平滑性挑战。 |
| [^98] | [Text-to-Audio Generation Synchronized with Videos](https://arxiv.org/abs/2403.07938) | 介绍了一个新的与视频对齐的文本到音频生成基准T2AV-Bench，以及一种简单而有效的视频对齐TTA生成模型T2AV，改进了传统方法，并融合了视觉对齐文本嵌入。 |
| [^99] | [Feint in Multi-Player Games](https://arxiv.org/abs/2403.07932) | 该论文介绍了多人游戏中假动作的首次形式化、实现和定量评估，并证明其能够显著提高奖励收益、增加游戏多样性，且时间消耗方面开销很小。 |
| [^100] | [Implications of Identity of AI: Creators, Creations, and Consequences](https://arxiv.org/abs/2403.07924) | 该论文探讨了人工智能领域的身份问题，强调了通过身份视角促进AI多样性在创造者、创作物和后果方面的重要性。 |
| [^101] | [The Fusion of Deep Reinforcement Learning and Edge Computing for Real-time Monitoring and Control Optimization in IoT Environments](https://arxiv.org/abs/2403.07923) | 本文提出了一种基于深度强化学习和边缘计算的优化控制系统，通过云边协同和动态资源分配实现工业目标的监控和优化，显著提升了系统性能，并节省了成本。 |
| [^102] | [Merino: Entropy-driven Design for Generative Language Models on IoT Devices](https://arxiv.org/abs/2403.07921) | 在本文中，我们提出了一个新颖的信息熵框架，用于设计手机友好的生成式语言模型，通过最大化transformer解码器的熵来在计算预算内，成功设计了MeRino模型，在移动设置下展现出与当前最先进的自回归transformer模型竞争性能的特点 |
| [^103] | [ProtLLM: An Interleaved Protein-Language LLM with Protein-as-Word Pre-Training](https://arxiv.org/abs/2403.07920) | 提出了ProtLLM，一种具有独特动态蛋白质装配机制及蛋白质作为单词语言建模方法的交织式蛋白质-语言LLM，并构建了大规模的交织式蛋白质-文本数据集用于预训练。 |
| [^104] | [On the Societal Impact of Open Foundation Models](https://arxiv.org/abs/2403.07918) | 开放基金会模型具有广泛可用的模型权重，带来了重大利益，但也存在边际风险，需要进一步研究来评估其相对于现有技术的安全性。 |
| [^105] | [Advancing Investment Frontiers: Industry-grade Deep Reinforcement Learning for Portfolio Optimization](https://arxiv.org/abs/2403.07916) | 本研究将深度强化学习应用于投资组合优化中，融合了产业级方法和量化金融，提出了结合多领域方法的独特视角。 |
| [^106] | [Standing on FURM ground -- A framework for evaluating Fair, Useful, and Reliable AI Models in healthcare systems](https://arxiv.org/abs/2403.07911) | 开发了一种机制来评估医疗系统中的公平、有用和可靠AI模型，弥合AI模型开发与实际受益之间的鸿沟。 |
| [^107] | [Enhancing Kubernetes Automated Scheduling with Deep Learning and Reinforcement Techniques for Large-Scale Cloud Computing Optimization](https://arxiv.org/abs/2403.07905) | 本文提出了一种基于深度学习和强化学习的自动任务调度方案，旨在实现大规模云计算系统中任务调度的最优利用和最大执行效率。 |
| [^108] | [Addressing the Regulatory Gap: Moving Towards an EU AI Audit Ecosystem Beyond the AIA by Including Civil Society](https://arxiv.org/abs/2403.07904) | 提出了一个融合合规和监督的AI审计生态系统，强调了DSA和AIA监管框架中存在的监管空白，并要求AIA为研究人员和社会公民提供数据和模型访问权限 |
| [^109] | [$\widetilde{O}(T^{-1})$ Convergence to (Coarse) Correlated Equilibria in Full-Information General-Sum Markov Games](https://arxiv.org/abs/2403.07890) | 本研究通过使用乐观的前瞻性领导者算法（OFTRL）和适当的数值更新程序，在全信息一般和马尔可夫博弈中找到了$\widetilde{O}(T^{-1})$-approximate（粗糙）相关均衡，这在$T$次迭代内得以实现。 |
| [^110] | [Cross-modality debiasing: using language to mitigate sub-population shifts in imaging](https://arxiv.org/abs/2403.07888) | 使用自然语言输入去偏置图像特征表示，以改善在子群体上的最坏情况表现。 |
| [^111] | [Neural Slot Interpreters: Grounding Object Semantics in Emergent Slot Representations](https://arxiv.org/abs/2403.07887) | 提出了神经槽解释器（NSI），通过槽表示学习接地和生成物体语义，实现了将现实世界的物体语义结合到抽象中。 |
| [^112] | [A Memetic Algorithm To Find a Hamiltonian Cycle in a Hamiltonian Graph](https://arxiv.org/abs/2403.07886) | 提出了一种用于在哈密顿图中寻找哈密顿循环的模因算法，并引入了增强局部搜索和动态增强输入图的新颖技术，该方法在实践中成功证明了哈密顿性。 |
| [^113] | [MOD-CL: Multi-label Object Detection with Constrained Loss](https://arxiv.org/abs/2403.07885) | 引入了MOD-CL多标签目标检测框架，利用约束损失改善输出，通过修正器模型和混合器模型生成更受限制的结果，并利用Product T-Norm将约束损失集成到MOD_YOLO架构中，显著提高了任务1和任务2的得分。 |
| [^114] | [Seg-metrics: a Python package to compute segmentation metrics](https://arxiv.org/abs/2403.07884) | seg-metrics是一个用于计算分割度量的Python包，为医学图像分割研究提供了全面的标准化模型评估解决方案，具有用户友好的界面和支持多种文件格式的特点。 |
| [^115] | [Efficient Vision-and-Language Pre-training with Text-Relevant Image Patch Selection](https://arxiv.org/abs/2403.07883) | TRIPS是一种高效的视觉与语言预训练方法，通过使用文本引导的图像块选择层，动态计算文本相关的视觉注意力，加速训练和推理过程，而且不增加额外参数。 |
| [^116] | [AI incidents and 'networked trouble': The case for a research agenda](https://arxiv.org/abs/2403.07879) | 论文主张一个AI事件的研究议程，重点关注AI出错并引发争议的示例以及它们在在线环境中如何构建，认为这些事件是参与AI系统的重要手段，需要进一步研究。 |
| [^117] | [Beyond Memorization: The Challenge of Random Memory Access in Language Models](https://arxiv.org/abs/2403.07805) | 本文研究了语言模型在访问内存时的挑战，发现通过背诵和置换等技术可以改善语言模型的随机内存访问能力，从而在开放域问题回答任务中取得显著改进。 |
| [^118] | [Equipping Computational Pathology Systems with Artifact Processing Pipelines: A Showcase for Computation and Performance Trade-offs](https://arxiv.org/abs/2403.07743) | 提出了一种专家混合方案，用于在计算病理学系统中检测和排除五种显著的工件，并应用概率阈值处理。 |
| [^119] | [Online Continual Learning For Interactive Instruction Following Agents](https://arxiv.org/abs/2403.07548) | 我们提出了针对具身代理的两种持续学习设置：学习新行为和新环境。同时，我们通过自信度得分来更新存储的信息，从而避免需要任务边界信息的问题。 |
| [^120] | [Vector Quantization for Deep-Learning-Based CSI Feedback in Massive MIMO Systems](https://arxiv.org/abs/2403.07355) | 提出了一种基于矢量量化的深度学习方法，用于大规模MIMO系统中的CSI反馈，通过引入特定的转换函数和可训练的码本设计策略，降低了计算复杂度并提高了CSI重建性能。 |
| [^121] | [The negation of permutation mass function](https://arxiv.org/abs/2403.06483) | 本文提出了排列质量函数的否定方法，并验证了其收敛性，研究了否定操作后的不确定性和不相似性变化趋势。 |
| [^122] | [Towards a Generic Representation of Cominatorial Problems for Learning-Based Approaches](https://arxiv.org/abs/2403.06026) | 本文倡导为基于学习方法的组合问题构建通用表示，以解决特定表示无法跨越不同组合问题的问题。 |
| [^123] | [MuseGraph: Graph-oriented Instruction Tuning of Large Language Models for Generic Graph Mining](https://arxiv.org/abs/2403.04780) | MuseGraph将GNNs和LLMs的优势结合起来，提出了一种更有效和通用的图挖掘方法，可以跨不同任务和数据集使用 |
| [^124] | [Are Language Models Puzzle Prodigies? Algorithmic Puzzles Unveil Serious Challenges in Multimodal Reasoning](https://arxiv.org/abs/2403.03864) | 这项研究提出了多模态解谜任务AlgoPuzzleVQA，通过算法谜题挑战评估了多模态语言模型在需要视觉理解、语言理解和复杂算法推理的能力，旨在评估视觉数据解释与算法问题解决能力之间的差距。 |
| [^125] | [Leveraging Federated Learning and Edge Computing for Recommendation Systems within Cloud Computing Networks](https://arxiv.org/abs/2403.03165) | 边缘智能结合了AI和边缘计算，利用联邦学习实现隐私保护的机器学习，在FL网络中提出分层联邦学习（HFL）框架以提高通信效率。 |
| [^126] | [Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation](https://arxiv.org/abs/2402.18920) | 该研究提出了一个统一的框架，结合光谱和空间域的映射，以预测3D形状之间的点对应和形状插值，相比先前方法，取得更准确、平滑的点对应结果，并且在计算上更高效。 |
| [^127] | [Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data](https://arxiv.org/abs/2402.14989) | 神经常微分方程（Neural ODEs）的扩展——神经随机微分方程（Neural SDEs）在处理不规则时间序列数据中的稳定性和性能方面提出了重要指导，需要谨慎设计漂移和扩散函数以保持稳定性。 |
| [^128] | [LongAgent: Scaling Language Models to 128k Context through Multi-Agent Collaboration](https://arxiv.org/abs/2402.11550) | LongAgent通过多智能体协作将语言模型扩展到128K上下文，并在长文本处理方面表现出潜在的优越性。 |
| [^129] | [Network Formation and Dynamics Among Multi-LLMs](https://arxiv.org/abs/2402.10659) | 分析了多个LLM在社交网络中的行为，发现它们在给定网络结构并被询问形成网络偏好时表现出与人类社交动态一致的原则。 |
| [^130] | [SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM](https://arxiv.org/abs/2402.03246) | SGS-SLAM是一种基于三维高斯点云的语义稠密SLAM系统，通过多通道优化和关键帧优化，实现了高质量的重建和精确的语义分割。 |
| [^131] | [CERM: Context-aware Literature-based Discovery via Sentiment Analysis](https://arxiv.org/abs/2402.01724) | CERM是一个通过情感分析进行基于文献的上下文感知发现的系统，旨在理解食品与健康之间的关系。通常情况下，基于食材营养成分或基于标记数据的计算模型已被用于食谱推荐和分析系统。然而，本研究提出了一种增强模型，通过捕捉食材与生物医学概念之间的固有关系，利用标记和未标记的数据来更好地支持食品相关研究。 |
| [^132] | [Agricultural Recommendation System based on Deep Learning: A Multivariate Weather Forecasting Approach](https://arxiv.org/abs/2401.11410) | 提出了一种基于深度学习和天气预测的农业推荐系统，旨在解决孟加拉国农业面临的天气不利因素对粮食生产的影响，以实现盈利、可持续和农民友好的农业实践。 |
| [^133] | [Learning Human-like Representations to Enable Learning Human Values](https://arxiv.org/abs/2312.14106) | 通过学习类人的表示，可以实现机器学习系统符合人类价值观，支持伦理等多方面的价值对齐。 |
| [^134] | [Imitate the Good and Avoid the Bad: An Incremental Approach to Safe Reinforcement Learning](https://arxiv.org/abs/2312.10385) | 提出了一种不修改基于轨迹成本约束的方法，在安全强化学习中通过模仿好的轨迹和避免坏的轨迹来改进策略。 |
| [^135] | [A Hitchhiker's Guide to Geometric GNNs for 3D Atomic Systems](https://arxiv.org/abs/2312.07511) | 几何图神经网络在3D原子系统中以利用物理对称性和化学性质等归纳偏差来学习几何图信息表示而著称。 |
| [^136] | [KnowGPT: Black-Box Knowledge Injection for Large Language Models](https://arxiv.org/abs/2312.06185) | KnowGPT是一种为大型语言模型提供黑盒知识注入的框架，通过深度强化学习和多臂老虎机构建最适合每个问题的提示，在三个基准数据集上实验证明其显著提升了知识注入的效果。 |
| [^137] | [TimeDRL: Disentangled Representation Learning for Multivariate Time-Series](https://arxiv.org/abs/2312.04142) | TimeDRL是一个具有解缠双层嵌入的通用多变量时间序列表示学习框架，通过时间戳级别和实例级别的嵌入之间的解缠派生以及时间戳-预测和实例-对比任务的利用，实现了学习丰富表示并解决归纳偏差的目标。 |
| [^138] | [Jellyfish: A Large Language Model for Data Preprocessing](https://arxiv.org/abs/2312.01678) | 这项研究探讨了在数据挖掘中利用大型语言模型进行数据预处理的方法，通过指导调整本地LLMs来解决通用数据预处理问题，确保数据安全并进行进一步调整 |
| [^139] | [MLLMs-Augmented Visual-Language Representation Learning](https://arxiv.org/abs/2311.18765) | MLLMs通过为图像-文本数据集建立更丰富的图像-文本关联，以增强视觉-语言表示学习，并通过“文本剪切”方法来避免偏见引入，显著提高了图像-文本检索的性能。 |
| [^140] | [WsiCaption: Multiple Instance Generation of Pathology Reports for Gigapixel Whole-Slide Images](https://arxiv.org/abs/2311.16480) | 研究提出了一种基于多实例生成模型的方法，能够生成千亿像素全切片图像的病理报告，实验结果表明该模型能够产生包含多个临床线索的病理报告。 |
| [^141] | [Safety-aware Causal Representation for Trustworthy Offline Reinforcement Learning in Autonomous Driving](https://arxiv.org/abs/2311.10747) | 本文提出了一种面向安全的因果表示方法FUSION，在自动驾驶中的离线强化学习中利用结构化情景信息促进泛化的端到端驾驶策略学习。 |
| [^142] | [Deceptive Semantic Shortcuts on Reasoning Chains: How Far Can Models Go without Hallucination?](https://arxiv.org/abs/2311.09702) | 本研究探讨了大型语言模型存在的幻觉和不忠实推理问题，提出一种新的探测方法和基准测试以研究LLMs在推理过程中是否会采取欺骗性语义快捷方式。 |
| [^143] | [Agent Lumos: Unified and Modular Training for Open-Source Language Agents](https://arxiv.org/abs/2311.05657) | Agent Lumos提出了一种统一和模块化的框架，通过规划模块学习高级子目标生成，训练接地模块将其转化为动作，促进广泛互动任务应用。 |
| [^144] | [Making RL with Preference-based Feedback Efficient via Randomization](https://arxiv.org/abs/2310.14554) | 在基于偏好反馈的强化学习中，通过引入随机化设计的算法在线性MDP模型下表现出样本高效性和多项式运行时间，并通过随机化主动学习过程最小化了查询复杂性。 |
| [^145] | [Language Model Beats Diffusion -- Tokenizer is Key to Visual Generation](https://arxiv.org/abs/2310.05737) | 分词器是视觉生成的关键，新的视频分词器MAGVIT-v2使得大型语言模型LLMs在图像和视频生成任务上胜过扩散模型，并在视频压缩和有效表示学习方面表现优异。 |
| [^146] | [Scaling Laws of RoPE-based Extrapolation](https://arxiv.org/abs/2310.05209) | 本研究提出了RoPE基外推的尺度律，通过调整 RoPE 中的基数和微调文本长度来显著提高大型语言模型的外推性能。 |
| [^147] | [Demystifying Embedding Spaces using Large Language Models](https://arxiv.org/abs/2310.04475) | 通过使用大型语言模型（LLMs）直接与嵌入交互，将抽象向量转换为可理解的叙述，使得复杂嵌入数据更具解释性和广泛实用性。 |
| [^148] | [Quantifying the Plausibility of Context Reliance in Neural Machine Translation](https://arxiv.org/abs/2310.01188) | 引入了PECoRe框架，用于量化语言模型生成中的上下文使用情况，从而评估上下文感知机器翻译模型的可信度。 |
| [^149] | [Linear attention is (maybe) all you need (to understand transformer optimization)](https://arxiv.org/abs/2310.01082) | 研究者通过训练线性Transformer模型解决回归任务，发现这种简单的线性化模型能够重现Transformer训练动态的多个关键方面，表明线性注意力可能是理解Transformer优化的关键。 |
| [^150] | [Pink: Unveiling the Power of Referential Comprehension for Multi-modal LLMs](https://arxiv.org/abs/2310.00582) | 提出了一个新框架来增强MLLMs细粒度图像理解能力，包括通过低成本构建指令调优数据集和引入自一致的自举方法扩展密集目标注释等关键方法。 |
| [^151] | [CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets](https://arxiv.org/abs/2309.17428) | CRAFT提出了一个通用工具创建和检索框架，能够定制LLMs，为其创建特定任务的工具集，并使用这些工具集增强其解决复杂任务的能力。 |
| [^152] | [Empowering Private Tutoring by Chaining Large Language Models](https://arxiv.org/abs/2309.08112) | 通过链式连接大型语言模型，开发了一种全面智能辅导系统，实现了自动课程规划、个性化指导和灵活测验评估。 |
| [^153] | [ChatEDA: A Large Language Model Powered Autonomous Agent for EDA](https://arxiv.org/abs/2308.10204) | 该研究介绍了ChatEDA，一个由大型语言模型AutoMage赋能的EDA自主代理，通过有效管理任务计划、脚本生成和任务执行，简化了从RTL到GDSII的设计流程，并证明了其性能优越性。 |
| [^154] | [SSMG: Spatial-Semantic Map Guided Diffusion Model for Free-form Layout-to-Image Generation](https://arxiv.org/abs/2308.10156) | SSMG模型采用特征图作为引导，相比其他方法具有更好的生成质量和空间语义可控性 |
| [^155] | [Multi-Level Compositional Reasoning for Interactive Instruction Following](https://arxiv.org/abs/2308.09387) | 提出了一种名为MCR-Agent的方法，能够通过将任务分解为多个子目标并分别处理它们来解决复杂任务导航和交互的挑战 |
| [^156] | [A generative artificial intelligence framework based on a molecular diffusion model for the design of metal-organic frameworks for carbon capture](https://arxiv.org/abs/2306.08695) | GHP-MOFassemble是一个生成人工智能框架，用于合理和加速设计具有高CO2吸附能力和可合成连接剂的MOFs，通过生成新颖连接剂并与预选金属节点组装成MOFs，在研究其稳定性、化学一致性和CO2吸附量方面展现出独特性和前景。 |
| [^157] | [Explainable Anomaly Detection in Images and Videos: A Survey](https://arxiv.org/abs/2302.06670) | 这项研究提供了针对图像和视频的可解释异常检测方法的首次调研，为机器学习学术界和实际应用提供了重要参考。 |
| [^158] | [Lowering Detection in Sport Climbing Based on Orientation of the Sensor Enhanced Quickdraw](https://arxiv.org/abs/2301.10164) | 通过在攀岩快挂上安装的加速度传感器采集数据，实现了在攀岩活动中检测攀岩者下降情况的技术，保护攀岩者隐私和健身房成本的同时提高了效率和便利性。 |
| [^159] | [Towards Benchmarking and Evaluating Deepfake Detection](https://arxiv.org/abs/2203.02115) | 该论文旨在建立一个全面一致的基准，以开发可重复的评估流程，并评估来自多种检测方法的性能，以实现结果的有力比较。 |
| [^160] | [mForms : Multimodal Form-Filling with Question Answering](https://arxiv.org/abs/2011.12340) | 本文提出了一种将表单填充任务重新构造为多模态自然语言问答的新方法，通过预训练的QA系统实现表单元素的填充，并通过多任务训练进一步细化表单填充过程。 |
| [^161] | [Temporal Positive-unlabeled Learning for Biomedical Hypothesis Generation via Risk Estimation](https://arxiv.org/abs/2010.01916) | 通过正无标记学习捕捉科学术语关系的时间动态 |
| [^162] | [Recurrent Attention Walk for Semi-supervised Classification](https://arxiv.org/abs/1910.10266) | 本文提出了一种基于循环注意力步行的方法，使用强化学习设置来探索图中的邻域，找到适合分类未标记目标节点的路径。 |
| [^163] | [Collaborative Graph Walk for Semi-supervised Multi-Label Node Classification](https://arxiv.org/abs/1910.09706) | 提出了一种名为多标签图遍历的新方法，通过合作式的图遍历策略学习节点标签与图结构属性之间的关系，以及多标签特定任务之间的相关性。 |
| [^164] | [Bridging State and History Representations: Understanding Self-Predictive RL.](http://arxiv.org/abs/2401.08898) | 本论文研究了深度强化学习中状态和历史表示间的关系，发现了这些方法和框架实际上都基于自预测抽象的共同思想，并提供了理论洞见和简化算法来学习自预测表示。 |
| [^165] | [GPT-4V(ision) is a Generalist Web Agent, if Grounded.](http://arxiv.org/abs/2401.01614) | GPT-4V(ision)是一个通用的网络代理，具有综合视觉理解和网页操作的能力。实验证明，如果将文本计划转化为实际行动，GPT-4V可以在50%的任务上取得成功。这一结果显著优于传统方法。 |
| [^166] | [Beyond Gradient and Priors in Privacy Attacks: Leveraging Pooler Layer Inputs of Language Models in Federated Learning.](http://arxiv.org/abs/2312.05720) | 本文引入了一种创新的方法，在联邦学习中利用语言模型的池化层输入来实现对隐私攻击的改进。通过恢复池化层输入，这种方法能够在不同的批处理大小下提供更高的文本恢复率，从而提供更细致和有效的见解。 |
| [^167] | [Interactive Navigation in Environments with Traversable Obstacles Using Large Language and Vision-Language Models.](http://arxiv.org/abs/2310.08873) | 本文提出了一个使用大型语言和视觉-语言模型的交互式导航框架，使机器人能够在带有可通行障碍的环境中进行导航。通过使用这些模型，我们可以实现从文本指令到动作感知边界框的端到端系统，无需微调和额外的训练数据。同时，我们还使用大型模型划分激光雷达点云，生成动作感知成本地图以生成可行路径。 |
| [^168] | [GenTKG: Generative Forecasting on Temporal Knowledge Graph.](http://arxiv.org/abs/2310.07793) | 研究提出了一种名为GenTKG的生成模型，用于在时间知识图谱上进行预测。该模型通过结合基于时间逻辑规则的检索策略和轻量级的参数效率指导，克服了复杂的时间图数据结构和庞大的数据量所带来的挑战。 |
| [^169] | [Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion.](http://arxiv.org/abs/2310.02279) | 提出了一种一致性轨迹模型（CTM），它可以加速扩散模型的采样，同时通过对抗训练和去噪得分匹配损失的组合来提高性能，并实现了最先进的采样质量。 |
| [^170] | [SmartPlay : A Benchmark for LLMs as Intelligent Agents.](http://arxiv.org/abs/2310.01557) | SmartPlay是一个用于评估LLMs作为智能Agent能力的基准，包括6个具有不同挑战的游戏，并测试了智能LLM Agent的多种关键能力。这不仅是一个评估LLM Agent整体性能的严格测试场地，还可以分析每个能力的表现。 |
| [^171] | [Certified Robustness via Dynamic Margin Maximization and Improved Lipschitz Regularization.](http://arxiv.org/abs/2310.00116) | 本文提出了一种基于动态边界最大化和改进的Lipschitz正则化的认证鲁棒性训练算法，通过增加输出空间中的边界和正则化模型的Lipschitz常数来提高深度分类器对抗性扰动的鲁棒性。 |
| [^172] | [Class Incremental Learning via Likelihood Ratio Based Task Prediction.](http://arxiv.org/abs/2309.15048) | 该论文提出了一种基于似然比的任务预测的类增量学习方法，利用离群检测器进行任务标识预测，解决了无任务标识符的测试样本的任务预测问题。 |
| [^173] | [Generating and Explaining Corner Cases Using Learnt Probabilistic Lane Graphs.](http://arxiv.org/abs/2308.13658) | 本论文提出了使用概率车道图生成和解释角落情况的方法，该方法基于历史交通数据生成新颖而逼真的角落情况，以提高自动驾驶车辆的安全性。 |
| [^174] | [Context-Aware Planning and Environment-Aware Memory for Instruction Following Embodied Agents.](http://arxiv.org/abs/2308.07241) | 这项研究提出了一种称为CPEM的系统，它利用上下文信息和环境感知记忆来改进行为智能体的感知能力，从而提高视觉导航和物体交互的效果。 |
| [^175] | [Contrastive Explanations of Multi-agent Optimization Solutions.](http://arxiv.org/abs/2308.05984) | 本研究提出了MAoE，一种用于多智能体优化问题的对比解释方法。该方法通过生成新的解决方案并突出显示与初始解决方案的差异，帮助智能体理解为什么初始解决方案优于他们的期望。 |
| [^176] | [Nature and the Machines.](http://arxiv.org/abs/2308.04440) | 《自然》杂志在一篇社论中呼吁我们“停止谈论明天的AI末日，而AI今天就存在风险。”这被认为是一个严重的判断失误，特别是对于有影响力的行动者来说，因为我们期望他们能够考虑到错误的后果。 |
| [^177] | [In-Context Learning in Large Language Models Learns Label Relationships but Is Not Conventional Learning.](http://arxiv.org/abs/2307.12375) | 大型语言模型（LLMs）在包含标签关系示例的上下文中的学习能力使其在下游任务中表现显著提高，但与传统学习方法不同。我们研究了上下文示例中的标签如何影响预测、预训练中学习到的标签关系如何与上下文示例相互作用以及上下文学习如何聚合标签信息。研究结果揭示了LLMs的工作机制及其对上下文信息的处理方式。 |
| [^178] | [UniTabE: Pretraining a Unified Tabular Encoder for Heterogeneous Tabular Data.](http://arxiv.org/abs/2307.09249) | UniTabE是一种面向异构表格数据的统一预训练表格编码器，能够处理不同表格结构的挑战，并具有对多样化下游应用的适应性。 |
| [^179] | [VertiBench: Advancing Feature Distribution Diversity in Vertical Federated Learning Benchmarks.](http://arxiv.org/abs/2307.02040) | 本文引入了两个影响VFL性能的关键因素：特征重要性和特征相关性，并提出了相关的评估指标和数据集划分方法。同时，通过引入真实的VFL数据集，填补了图像-图像VFL情景中的不足。研究对于未来的VFL研究提供了有价值的见解。 |
| [^180] | [Probabilistic Constraint for Safety-Critical Reinforcement Learning.](http://arxiv.org/abs/2306.17279) | 本文研究了概率约束下的安全关键强化学习问题，提出了具有明确梯度表达式的Safe Policy Gradient-REINFORCE（SPG-REINFORCE）算法，并通过理论界限证明了概率约束设置在最优性和安全性之间具有更好的权衡。 |
| [^181] | [Identifiability of Discretized Latent Coordinate Systems via Density Landmarks Detection.](http://arxiv.org/abs/2306.16334) | 本文提出了一种新颖的可识别性形式，称为量化坐标可识别性。在无监督的情况下，我们展示了在高度通用的非线性映射下，可以恢复离散化的潜在坐标，而无需额外的归纳偏差。这一发现对解缠研究具有重要意义。 |
| [^182] | [Explainability in Simplicial Map Neural Networks.](http://arxiv.org/abs/2306.00010) | 本文提出了简单形式映射神经网络（SMNN）的训练过程和替代凸多面体的方法，并且首次引入了 SMNN 的可解释性能力。 |
| [^183] | [GRACE++: Loss-Resilient Real-Time Video through Neural Codecs.](http://arxiv.org/abs/2305.12333) | GRACE++是一个抗丢包的实时视频系统，通过神经视频编解码器实现了在各种丢包情况下保持用户体验质量的目标。 |
| [^184] | [Retentive or Forgetful? Diving into the Knowledge Memorizing Mechanism of Language Models.](http://arxiv.org/abs/2305.09144) | 本论文研究了语言模型的记忆机制，发现预训练可以有效提高模型的记忆能力，而知识相关性和多样性对于记忆形成也有显著影响。 |
| [^185] | [Artificial General Intelligence (AGI) for Education.](http://arxiv.org/abs/2304.12479) | AGI技术具有革命教育领域潜力，可以建立e-learning平台、教育协作工具等，弥补传统AI模型因受限于数据和人际交互限制而无法满足教育需求的不足。 |
| [^186] | [CT Multi-Task Learning with a Large Image-Text (LIT) Model.](http://arxiv.org/abs/2304.02649) | 本研究通过将大型图像模型和大语言模型结合起来，建立了一个用于肺癌诊断的多任务CT大型图像文本（LIT）模型，能很好地执行肺部CT分割等多个医学任务。 |
| [^187] | [A Survey on Causal Discovery Methods for Temporal and Non-Temporal Data.](http://arxiv.org/abs/2303.15027) | 本文综述了时序和非时序数据因果发现的方法，探讨了不同算法在不同情况下识别因果边缘的能力。同时还介绍了可用于评估因果发现方法性能的基准数据集和常见指标。 |
| [^188] | [Data-Efficient Contrastive Self-supervised Learning: Easy Examples Contribute the Most.](http://arxiv.org/abs/2302.09195) | 该研究证明了在自监督学习中容易学习的样本对学习高质量表示起到最大的作用，这有助于减少所需的训练数据量，并提高性能。 |
| [^189] | [Referential communication in heterogeneous communities of pre-trained visual deep networks.](http://arxiv.org/abs/2302.08913) | 异构视觉深度网络社区中的预训练网络可以自我监督地开发出共享协议，以指代一组目标中的目标对象，并可用于沟通不同粒度的未知对象类别。 |

# 详细

[^1]: FastMAC: 对应图的随机谱采样

    FastMAC: Stochastic Spectral Sampling of Correspondence Graph

    [https://arxiv.org/abs/2403.08770](https://arxiv.org/abs/2403.08770)

    这项研究将图信号处理引入到对应图领域，提出了一种随机谱采样策略。

    

    3D对应，即一对3D点，在计算机视觉中是一个基本概念。一组3D对应，当具有兼容性边缘时，形成一个对应图。在几种最先进的3D点云配准方法中，该图是一个关键组件。我们将图信号处理引入到对应图领域，利用对应图上的广义度信号，并追求保留此信号高频组件的采样策略。为了解决确定性采样中耗时的奇异值分解，我们采用了一种随机近似采样策略。因此，我们方法的核心是对应图的随机谱采样。

    arXiv:2403.08770v1 Announce Type: cross  Abstract: 3D correspondence, i.e., a pair of 3D points, is a fundamental concept in computer vision. A set of 3D correspondences, when equipped with compatibility edges, forms a correspondence graph. This graph is a critical component in several state-of-the-art 3D point cloud registration approaches, e.g., the one based on maximal cliques (MAC). However, its properties have not been well understood. So we present the first study that introduces graph signal processing into the domain of correspondence graph. We exploit the generalized degree signal on correspondence graph and pursue sampling strategies that preserve high-frequency components of this signal. To address time-consuming singular value decomposition in deterministic sampling, we resort to a stochastic approximate sampling strategy. As such, the core of our method is the stochastic spectral sampling of correspondence graph. As an application, we build a complete 3D registration algor
    
[^2]: 持续预训练大型语言模型的简单可扩展策略

    Simple and Scalable Strategies to Continually Pre-train Large Language Models

    [https://arxiv.org/abs/2403.08763](https://arxiv.org/abs/2403.08763)

    通过简单和可扩展的学习率调整、重放数据的方法，可以在不重新训练的情况下，持续预训练大型语言模型以匹配完全重新训练时的性能。

    

    大型语言模型（LLMs）通常在数十亿的标记上进行常规预训练，一旦有新数据可用就重新开始该过程。一个更有效率的解决方案是持续预训练这些模型，与重新训练相比能节省大量计算资源。然而，新数据引起的分布转移通常会导致在以前数据上降低性能或无法适应新数据。在本工作中，我们展示了一种简单且可扩展的学习率（LR）重新升温、LR重新衰减和重放上一数据的组合足以与完全从头开始重新训练在所有可用数据上的性能相匹配，从最终损失和语言模型（LM）评估基准的角度衡量。具体而言，我们展示了在两个常用的LLM预训练数据集（英语→英语）之间的弱但现实的分布转移以及更强烈的分布转移（英语→德语）下的情况。

    arXiv:2403.08763v1 Announce Type: cross  Abstract: Large language models (LLMs) are routinely pre-trained on billions of tokens, only to start the process over again once new data becomes available. A much more efficient solution is to continually pre-train these models, saving significant compute compared to re-training. However, the distribution shift induced by new data typically results in degraded performance on previous data or poor adaptation to the new data. In this work, we show that a simple and scalable combination of learning rate (LR) re-warming, LR re-decaying, and replay of previous data is sufficient to match the performance of fully re-training from scratch on all available data, as measured by final loss and language model (LM) evaluation benchmarks. Specifically, we show this for a weak but realistic distribution shift between two commonly used LLM pre-training datasets (English$\rightarrow$English) and a stronger distribution shift (English$\rightarrow$German) at th
    
[^3]: DAM:用于持续视频问答学习的动态适配器合并

    DAM: Dynamic Adapter Merging for Continual Video QA Learning

    [https://arxiv.org/abs/2403.08755](https://arxiv.org/abs/2403.08755)

    提出了一种用于持续视频问答学习的动态适配器合并方法DAM，能够减轻灾难性遗忘、有效适应不断到来的数据集、处理未知数据集输入，并允许在类似数据集领域之间共享知识。

    

    我们提出了一种参数高效的方法，用于持续视频问答（VidQA）学习。我们的方法名为DAM，使用所提出的动态适配器合并来（i）减轻灾难性遗忘，（ii）实现对持续到达的数据集的高效适应，（iii）在推理过程中处理来自未知数据集的输入，（iv）实现跨相似数据集领域的知识共享。在给定一组持续流式传输的VidQA数据集的情况下，我们为每个数据集顺序训练特定于数据集的适配器，同时冻结大型预训练视频语言骨干的参数。在推理过程中，给定来自未知领域的视频问题示例，我们的方法首先使用所提出的非参数路由器函数计算每个适配器的概率，反映出该适配器与当前视频问题输入实例的相关性。随后，所提出的动态适配器合并方案聚合所有适配器权重。

    arXiv:2403.08755v1 Announce Type: cross  Abstract: We present a parameter-efficient method for continual video question-answering (VidQA) learning. Our method, named DAM, uses the proposed Dynamic Adapter Merging to (i) mitigate catastrophic forgetting, (ii) enable efficient adaptation to continually arriving datasets, (iii) handle inputs from unknown datasets during inference, and (iv) enable knowledge sharing across similar dataset domains. Given a set of continually streaming VidQA datasets, we sequentially train dataset-specific adapters for each dataset while freezing the parameters of a large pretrained video-language backbone. During inference, given a video-question sample from an unknown domain, our method first uses the proposed non-parametric router function to compute a probability for each adapter, reflecting how relevant that adapter is to the current video-question input instance. Subsequently, the proposed dynamic adapter merging scheme aggregates all the adapter weight
    
[^4]: 将LLMs引导到无偏响应：基于因果关系的去偏倾框架

    Steering LLMs Towards Unbiased Responses: A Causality-Guided Debiasing Framework

    [https://arxiv.org/abs/2403.08743](https://arxiv.org/abs/2403.08743)

    本文提出了一种基于因果关系的去偏倾框架，通过选择机制指导设计提示来减少大型语言模型(LLMs)产生的社会偏见。

    

    大型语言模型（LLMs）很容易产生偏见和歧视性的响应。由于LLMs涉及到重要的决策制定（例如招聘和医疗保健），开发减轻这些偏见的策略至关重要。本文侧重于社会偏见，解决了人口统计信息与LLM输出之间的关联。我们提出了一种基于因果关系的去偏倾框架，利用对LLMs输入的训练语料库的数据生成过程以及LLM推理的内部推理过程的因果理解，通过选择机制指导去偏倾LLM输出的提示设计。我们的框架统一了现有的去偏指示方法，如抑制指令和上下文对比例子，并通过鼓励无偏推理的方法，启示了新的去偏倾方式。我们在真实数据集上的强大实证表现表明，我们的框架可以

    arXiv:2403.08743v1 Announce Type: cross  Abstract: Large language models (LLMs) can easily generate biased and discriminative responses. As LLMs tap into consequential decision-making (e.g., hiring and healthcare), it is of crucial importance to develop strategies to mitigate these biases. This paper focuses on social bias, tackling the association between demographic information and LLM outputs. We propose a causality-guided debiasing framework that utilizes causal understandings of (1) the data-generating process of the training corpus fed to LLMs, and (2) the internal reasoning process of LLM inference, to guide the design of prompts for debiasing LLM outputs through selection mechanisms. Our framework unifies existing de-biasing prompting approaches such as inhibitive instructions and in-context contrastive examples, and sheds light on new ways of debiasing by encouraging bias-free reasoning. Our strong empirical performance on real-world datasets demonstrates that our framework pr
    
[^5]: 分叉路径的花园：观察大型语言模型中动态参数分布

    The Garden of Forking Paths: Observing Dynamic Parameters Distribution in Large Language Models

    [https://arxiv.org/abs/2403.08739](https://arxiv.org/abs/2403.08739)

    观察大型语言模型中动态参数分布的时间演变，特别是叉分效应，能帮助理解模型质量，减少训练成本和评估工作，同时实证显示稀疏权重有效性背后的原因。

    

    在理解Transformer架构在自然语言处理中卓越性能背后原因方面仍存在巨大差距。尤其是一个尚未被探索的领域涉及在训练过程中参数分布如何随时间演变的机械描述。在这项工作中，我们建议观察模型参数的统计分布随时间演变的方式，尤其是对叉分影响，可以帮助理解模型质量，潜在地减少训练成本和评估工作，并从实证上展示了稀疏权重有效性背后的原因。

    arXiv:2403.08739v1 Announce Type: cross  Abstract: A substantial gap persists in understanding the reasons behind the exceptional performance of the Transformer architecture in NLP. A particularly unexplored area involves the mechanistic description of how the distribution of parameters evolves over time during training. In this work we suggest that looking at the time evolution of the statistic distribution of model parameters, and specifically at bifurcation effects, can help understanding the model quality, potentially reducing training costs and evaluation efforts and empirically showing the reasons behind the effectiveness of weights sparsification.
    
[^6]: 使用环境扩散后验采样：在受损数据上训练的扩散模型解决逆问题

    Ambient Diffusion Posterior Sampling: Solving Inverse Problems with Diffusion Models trained on Corrupted Data

    [https://arxiv.org/abs/2403.08728](https://arxiv.org/abs/2403.08728)

    提出了一种使用环境扩散后验采样解决逆问题的框架，能在受损数据上训练的扩散模型上表现出色，并在图像恢复和MRI模型训练中取得优越性能。

    

    我们提供了一个框架，用于使用从线性受损数据中学习的扩散模型解决逆问题。我们的方法，Ambient Diffusion Posterior Sampling (A-DPS)，利用一个预先在一种类型的损坏数据上进行过训练的生成模型，以在可能来自不同前向过程（例如图像模糊）的测量条件下执行后验采样。我们在标准自然图像数据集（CelebA、FFHQ 和 AFHQ）上测试了我们的方法的有效性，并展示了 A-DPS 有时在速度和性能上都能胜过在清洁数据上训练的模型，用于几个图像恢复任务。我们进一步扩展了环境扩散框架，以仅访问傅里叶子采样的多线圈 MRI 测量数据来训练 MRI 模型，其加速因子为不同的加速因子（R=2、4、6、8）。我们再次观察到，在高度子采样数据上训练的模型更适用于解决高加速 MRI 逆问题。

    arXiv:2403.08728v1 Announce Type: cross  Abstract: We provide a framework for solving inverse problems with diffusion models learned from linearly corrupted data. Our method, Ambient Diffusion Posterior Sampling (A-DPS), leverages a generative model pre-trained on one type of corruption (e.g. image inpainting) to perform posterior sampling conditioned on measurements from a potentially different forward process (e.g. image blurring). We test the efficacy of our approach on standard natural image datasets (CelebA, FFHQ, and AFHQ) and we show that A-DPS can sometimes outperform models trained on clean data for several image restoration tasks in both speed and performance. We further extend the Ambient Diffusion framework to train MRI models with access only to Fourier subsampled multi-coil MRI measurements at various acceleration factors (R=2, 4, 6, 8). We again observe that models trained on highly subsampled data are better priors for solving inverse problems in the high acceleration r
    
[^7]: 一层Softmax注意力模型上梯度流的隐式正则化

    Implicit Regularization of Gradient Flow on One-Layer Softmax Attention

    [https://arxiv.org/abs/2403.08699](https://arxiv.org/abs/2403.08699)

    研究了在一层Softmax注意力模型上指数损失函数的梯度流，发现在渐进最小化损失值时隐式最小化了关键和查询权重矩阵乘积的核范数，这种隐式正则化可通过与注意力权重相关的SVM问题描述。

    

    我们研究了在一层Softmax注意力模型上指数损失函数的梯度流，其中关键和查询权重矩阵是分别训练的。在数据可分性假设下，我们证明了当梯度流达到最小损失值时，它进一步隐式地最小化了关键和查询权重矩阵乘积的核范数。这种隐式正则化可以通过与注意力权重相关的支持向量机（SVM）问题来描述。这一发现与先前的结果形成对比，先前的结果显示当将关键和查询矩阵合并为单个权重矩阵进行训练时，梯度下降会在乘积权重矩阵上实施隐式正则化，最小化弗罗贝尼乌斯范数。对于对角关键和查询矩阵，我们的分析建立在重新参数化技术和利用与分类任务相关的SVM的近似KKT条件的基础上。

    arXiv:2403.08699v1 Announce Type: cross  Abstract: We study gradient flow on the exponential loss for a classification problem with a one-layer softmax attention model, where the key and query weight matrices are trained separately. Under a separability assumption on the data, we show that when gradient flow achieves the minimal loss value, it further implicitly minimizes the nuclear norm of the product of the key and query weight matrices. Such implicit regularization can be described by a Support Vector Machine (SVM) problem with respect to the attention weights. This finding contrasts with prior results showing that the gradient descent induces an implicit regularization on the Frobenius norm on the product weight matrix when the key and query matrices are combined into a single weight matrix for training. For diagonal key and query matrices, our analysis builds upon the reparameterization technique and exploits approximate KKT conditions of the SVM associated with the classificatio
    
[^8]: 通过字符匹配实现标记对齐用于子词补全

    Token Alignment via Character Matching for Subword Completion

    [https://arxiv.org/abs/2403.08688](https://arxiv.org/abs/2403.08688)

    通过字符匹配实现标记对齐的方法，显著改进了生成模型在处理部分标记对齐的情景中的性能，包括空格前缀和部分缩进等微妙情况。

    

    生成模型在各种应用中被广泛使用，但通常难以处理与部分标记对齐的提示。这种困难源自标记化，在推理过程中部分标记会脱离分布，导致不正确或荒谬的输出。本文研究了一种技术，用于减轻生成模型中文本补全时的标记化问题，即使在常规非子词情况下也能保持性能。该方法称为标记对齐，涉及回溯到最后完整标记，并确保模型生成与提示对齐。这种方法在许多部分标记场景中展示了显著的改进，包括空格前缀和部分缩进等微妙情况，仅增加了少量时间。本文详细介绍的技术和分析有助于在处理部分输入方面不断推进生成模型，对诸如的应用具有相关意义

    arXiv:2403.08688v1 Announce Type: cross  Abstract: Generative models, widely utilized in various applications, can often struggle with prompts corresponding to partial tokens. This struggle stems from tokenization, where partial tokens fall out of distribution during inference, leading to incorrect or nonsensical outputs. This paper examines a technique to alleviate the tokenization artifact on text completion in generative models, maintaining performance even in regular non-subword cases. The method, termed token alignment, involves backtracking to the last complete tokens and ensuring the model's generation aligns with the prompt. This approach showcases marked improvement across many partial token scenarios, including nuanced cases like space-prefix and partial indentation, with only a minor time increase. The technique and analysis detailed in this paper contribute to the continuous advancement of generative models in handling partial inputs, bearing relevance for applications like
    
[^9]: 通过在线偏好优化实现大型语言模型与人类的对齐

    Human Alignment of Large Language Models through Online Preference Optimisation

    [https://arxiv.org/abs/2403.08635](https://arxiv.org/abs/2403.08635)

    本文展示了两种最近对齐方法之间的等价性，并介绍了一种泛化版本，有助于实现大型语言模型与人类的对齐。

    

    确保语言模型的输出与人类偏好对齐对于确保用户体验的有用性、安全性和愉悦性至关重要。最近，人类对齐已经得到广泛研究，出现了几种方法，例如强化学习来自人类反馈（RLHF）、直接策略优化（DPO）和序列似然校准（SLiC）。本文的贡献有两个方面：首先，我们展示了两种最近对齐方法之间的等价性，即身份策略优化（IPO）和纳什镜像下降（Nash-MD）。其次，我们介绍了IPO的一种泛化版本，名为IPO-MD，它利用了Nash-MD提出的正则化抽样方法。

    arXiv:2403.08635v1 Announce Type: cross  Abstract: Ensuring alignment of language models' outputs with human preferences is critical to guarantee a useful, safe, and pleasant user experience. Thus, human alignment has been extensively studied recently and several methods such as Reinforcement Learning from Human Feedback (RLHF), Direct Policy Optimisation (DPO) and Sequence Likelihood Calibration (SLiC) have emerged. In this paper, our contribution is two-fold. First, we show the equivalence between two recent alignment methods, namely Identity Policy Optimisation (IPO) and Nash Mirror Descent (Nash-MD). Second, we introduce a generalisation of IPO, named IPO-MD, that leverages the regularised sampling approach proposed by Nash-MD.   This equivalence may seem surprising at first sight, since IPO is an offline method whereas Nash-MD is an online method using a preference model. However, this equivalence can be proven when we consider the online version of IPO, that is when both generati
    
[^10]: Verifix: 后训练校正以改善具有经过验证样本的标签噪声鲁棒性

    Verifix: Post-Training Correction to Improve Label Noise Robustness with Verified Samples

    [https://arxiv.org/abs/2403.08618](https://arxiv.org/abs/2403.08618)

    提出了后训练校正的新范式，通过奇异值分解算法Verifix在初始训练后校正模型权重以减轻标签噪声，避免了重新训练的需求

    

    标签错误，即训练样本具有不正确的标签，可能严重损害机器学习模型的性能。这种错误往往来自非专家标注或敌对攻击。获取大型、完全标记的数据集成本高，当有干净的数据集可用时，重新训练大型模型就变得计算昂贵。为了解决这一挑战，我们提出了后训练校正，这是一种在初始训练后调整模型参数以减轻标签噪声的新范式，消除了重新训练的需要。我们引入了Verifix，这是一种基于奇异值分解（SVD）的新算法，利用一个小的、经过验证的数据集，通过单个更新校正模型权重。Verifix使用SVD估计干净激活空间，然后将模型的权重投影到这个空间上，以抑制对应于损坏数据的激活。我们展示了Verifix的有效性。

    arXiv:2403.08618v1 Announce Type: cross  Abstract: Label corruption, where training samples have incorrect labels, can significantly degrade the performance of machine learning models. This corruption often arises from non-expert labeling or adversarial attacks. Acquiring large, perfectly labeled datasets is costly, and retraining large models from scratch when a clean dataset becomes available is computationally expensive. To address this challenge, we propose Post-Training Correction, a new paradigm that adjusts model parameters after initial training to mitigate label noise, eliminating the need for retraining. We introduce Verifix, a novel Singular Value Decomposition (SVD) based algorithm that leverages a small, verified dataset to correct the model weights using a single update. Verifix uses SVD to estimate a Clean Activation Space and then projects the model's weights onto this space to suppress activations corresponding to corrupted data. We demonstrate Verifix's effectiveness 
    
[^11]: 利用表示学习和基于启发式特征的方法进行社交网络的链接预测

    Link Prediction for Social Networks using Representation Learning and Heuristic-based Features

    [https://arxiv.org/abs/2403.08613](https://arxiv.org/abs/2403.08613)

    提出了一种结合启发式特征和学习表示的方法，用于社交网络中缺失链接的预测任务，取得了较好的性能提升

    

    在社交网络的规模和相关性呈指数增长的情况下，预测社交网络中缺失的链接变得越来越重要。本文探讨了各种特征提取技术，以生成社交网络中节点和边的表示，从而帮助预测缺失的链接。我们比较了十种特征提取技术的结果，这些技术分为结构嵌入、基于邻居的嵌入、图神经网络和图启发式。接着，我们使用集成分类器和定制神经网络进行建模。此外，我们提出了将基于启发式特征和学习表示相结合的方法，这一方法在社交网络数据集上展现出了更好的性能。

    arXiv:2403.08613v1 Announce Type: cross  Abstract: The exponential growth in scale and relevance of social networks enable them to provide expansive insights. Predicting missing links in social networks efficiently can help in various modern-day business applications ranging from generating recommendations to influence analysis. Several categories of solutions exist for the same. Here, we explore various feature extraction techniques to generate representations of nodes and edges in a social network that allow us to predict missing links. We compare the results of using ten feature extraction techniques categorized across Structural embeddings, Neighborhood-based embeddings, Graph Neural Networks, and Graph Heuristics, followed by modeling with ensemble classifiers and custom Neural Networks. Further, we propose combining heuristic-based features and learned representations that demonstrate improved performance for the link prediction task on social network datasets. Using this method 
    
[^12]: MedInsight：用于使用大型语言模型生成以患者为中心的医疗响应的多源上下文增强框架

    MedInsight: A Multi-Source Context Augmentation Framework for Generating Patient-Centric Medical Responses using Large Language Models

    [https://arxiv.org/abs/2403.08607](https://arxiv.org/abs/2403.08607)

    MedInsight是一种检索增强框架，通过从多个来源提取与患者医疗记录相关的背景信息，将其与大型语言模型输入结合，生成丰富的、针对患者的响应

    

    大型语言模型（LLMs）在生成类人响应方面展现出令人印象深刻的能力。然而，它们缺乏领域特定知识，限制了它们在医疗环境中的适用性，而在医疗保健领域，具有上下文和全面性响应至关重要。为了解决这一挑战，实现生成具有上下文相关性和全面性的以患者为中心的响应，我们提出了MedInsight：一种新颖的检索增强框架，它使用多个来源的相关背景信息增强LLM输入（提示）。MedInsight从患者的病历或会诊记录中提取相关详细信息。然后，根据患者的健康历史和状况，集成来自权威医学教科书和策划的网络资源的信息。通过构建一个将患者记录与相关医学知识相结合的增强上下文，MedInsight生成丰富的、特定于患者的响应

    arXiv:2403.08607v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have shown impressive capabilities in generating human-like responses. However, their lack of domain-specific knowledge limits their applicability in healthcare settings, where contextual and comprehensive responses are vital. To address this challenge and enable the generation of patient-centric responses that are contextually relevant and comprehensive, we propose MedInsight:a novel retrieval augmented framework that augments LLM inputs (prompts) with relevant background information from multiple sources. MedInsight extracts pertinent details from the patient's medical record or consultation transcript. It then integrates information from authoritative medical textbooks and curated web resources based on the patient's health history and condition. By constructing an augmented context combining the patient's record with relevant medical knowledge, MedInsight generates enriched, patient-specific responses t
    
[^13]: 当需要时给我打电话：LLM可以高效而忠实地推理结构化环境

    Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over Structured Environments

    [https://arxiv.org/abs/2403.08593](https://arxiv.org/abs/2403.08593)

    LLMs借助Reasoning-Path-Editing (Readi)框架，可以在结构化环境中高效且忠实地推理，显著提升了多个KGQA和TableQA数据集上的表现。

    

    大型语言模型（LLMs）已经展示出在推理结构化环境中的潜力，例如知识图谱和表格。这些任务通常需要多跳推理，即将自然语言话语与环境中的实例匹配。以往的方法利用LLMs逐步构建推理路径，其中LLMs通过与环境逐步交互来调用工具或选择模式。我们提出了一种新颖的框架Reasoning-Path-Editing（Readi），在其中LLMs可以高效且忠实地在结构化环境中进行推理。在Readi中，LLMs在给定查询时最初生成一个推理路径，只有在必要时才编辑路径。我们将路径实例化到结构化环境上，并在出现问题时提供反馈以编辑路径。对三个KGQA数据集和两个TableQA数据集的实验结果显示，Readi的有效性，显著超越了所有基于LLM的方法（在WebQ上提高了9.1％）。

    arXiv:2403.08593v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have shown potential in reasoning over structured environments, e.g., knowledge graph and table. Such tasks typically require multi-hop reasoning, i.e., match natural language utterance with instances in the environment. Previous methods leverage LLMs to incrementally build a reasoning path, where the LLMs either invoke tools or pick up schemas by step-by-step interacting with the environment. We propose Reasoning-Path-Editing (Readi), a novel framework where LLMs can efficiently and faithfully reason over structured environments. In Readi, LLMs initially generate a reasoning path given a query, and edit the path only when necessary. We instantiate the path on structured environments and provide feedback to edit the path if anything goes wrong. Experimental results on three KGQA datasets and two TableQA datasets show the effectiveness of Readi, significantly surpassing all LLM-based methods (by 9.1% on WebQ
    
[^14]: 生成语言模型的非歧视标准

    Non-discrimination Criteria for Generative Language Models

    [https://arxiv.org/abs/2403.08564](https://arxiv.org/abs/2403.08564)

    本文研究如何在生成式语言模型中识别和量化性别偏见，提出了三个生成式人工智能的非歧视标准并设计了相应的提示。

    

    近年来，生成式人工智能，如大型语言模型，经历了快速发展。随着这些模型越来越普遍地提供给公众使用，人们开始担心在应用中延续和放大有害偏见的问题。性别刻板印象可能对其针对的个人造成伤害和限制，无论是由误传还是歧视所构成。识别性别偏见作为一种普遍的社会构造，本文研究如何发现和量化生成式语言模型中性别偏见的存在。具体而言，我们推导出三个来自分类的著名非歧视标准的生成式人工智能类比，即独立性、分离性和充分性。为了展示这些标准的作用，我们设计了针对每个标准的提示，重点关注职业性别刻板印象，具体利用医学测试来在生成式人工智能背景中引入基本事实。

    arXiv:2403.08564v1 Announce Type: cross  Abstract: Within recent years, generative AI, such as large language models, has undergone rapid development. As these models become increasingly available to the public, concerns arise about perpetuating and amplifying harmful biases in applications. Gender stereotypes can be harmful and limiting for the individuals they target, whether they consist of misrepresentation or discrimination. Recognizing gender bias as a pervasive societal construct, this paper studies how to uncover and quantify the presence of gender biases in generative language models. In particular, we derive generative AI analogues of three well-known non-discrimination criteria from classification, namely independence, separation and sufficiency. To demonstrate these criteria in action, we design prompts for each of the criteria with a focus on occupational gender stereotype, specifically utilizing the medical test to introduce the ground truth in the generative AI context. 
    
[^15]: 结构视角下基于约束的马尔可夫网络学习

    Structural perspective on constraint-based learning of Markov networks

    [https://arxiv.org/abs/2403.08562](https://arxiv.org/abs/2403.08562)

    本论文从结构角度研究了基于约束的学习马尔可夫网络，发现了图的结构特性和学习所需测试数量之间的重要关系

    

    马尔可夫网络是概率图模型，使用无向图来表示变量之间的条件独立关系。我们关注约束-based结构学习，通过执行条件独立性检验从数据中学习无向图。我们确定了关于马尔可夫网络约束-based学习的两个关键方面的理论限制：测试数量和条件设置的大小。这些界限揭示了图的结构特性与学习马尔可夫网络所需测试量之间的有趣互动。我们工作的出发点是图参数最大成对连通性 $\kappa$，即，图中连接一对顶点的最大数量的顶点不相交路径，负责独立性测试所需的大小，以学习图。一方面, 我们表明至少 såorest

    arXiv:2403.08562v1 Announce Type: cross  Abstract: Markov networks are probabilistic graphical models that employ undirected graphs to depict conditional independence relationships among variables. Our focus lies in constraint-based structure learning, which entails learning the undirected graph from data through the execution of conditional independence tests. We establish theoretical limits concerning two critical aspects of constraint-based learning of Markov networks: the number of tests and the sizes of the conditioning sets. These bounds uncover an exciting interplay between the structural properties of the graph and the amount of tests required to learn a Markov network. The starting point of our work is that the graph parameter maximum pairwise connectivity, $\kappa$, that is, the maximum number of vertex-disjoint paths connecting a pair of vertices in the graph, is responsible for the sizes of independence tests required to learn the graph. On one hand, we show that at least o
    
[^16]: SM4Depth: 一种通过单一模型实现跨多摄像头和场景的无缝单目度量深度估计

    SM4Depth: Seamless Monocular Metric Depth Estimation across Multiple Cameras and Scenes by One Model

    [https://arxiv.org/abs/2403.08556](https://arxiv.org/abs/2403.08556)

    SM4Depth通过一种新的预处理单元和深度间隔离散化的方法，解决了单目度量深度估计中的相机敏感性、场景精度不一致和数据依赖性等问题。

    

    单目度量深度估计（MMDE）的泛化一直是一个长期存在的挑战。最近的方法通过结合相对深度和度量深度或对齐输入图像焦距取得了进展。然而，它们仍然面临着在相机、场景和数据级别上的挑战：（1）对不同摄像头的敏感性；（2）在不同场景中精度不一致；（3）依赖大规模训练数据。本文提出了一种无缝的MMDE方法SM4Depth，以在单个网络内解决上述所有问题。

    arXiv:2403.08556v1 Announce Type: cross  Abstract: The generalization of monocular metric depth estimation (MMDE) has been a longstanding challenge. Recent methods made progress by combining relative and metric depth or aligning input image focal length. However, they are still beset by challenges in camera, scene, and data levels: (1) Sensitivity to different cameras; (2) Inconsistent accuracy across scenes; (3) Reliance on massive training data. This paper proposes SM4Depth, a seamless MMDE method, to address all the issues above within a single network. First, we reveal that a consistent field of view (FOV) is the key to resolve ``metric ambiguity'' across cameras, which guides us to propose a more straightforward preprocessing unit. Second, to achieve consistently high accuracy across scenes, we explicitly model the metric scale determination as discretizing the depth interval into bins and propose variation-based unnormalized depth bins. This method bridges the depth gap of divers
    
[^17]: 基于扩散模型的联邦知识图去学习

    Federated Knowledge Graph Unlearning via Diffusion Model

    [https://arxiv.org/abs/2403.08554](https://arxiv.org/abs/2403.08554)

    提出了FedDM，一个基于扩散模型的新框架，用于联邦知识图中的机器去学习。

    

    arXiv:2403.08554v1 公告类型: 跨领域 摘要: 联邦学习（FL）通过促进模型共享和协作，同时维护数据隐私，推动了人工智能技术的发展和应用。知识图（KG）嵌入表示通过将实体和关系映射到向量空间，为知识推理和应用提供基础。联邦知识图嵌入能够利用来自不同客户端的知识，同时保护本地数据的隐私。然而，由于隐私保护等需求以及需要适应动态数据变化，机器去学习（MU）的研究得以展开。然而，在忘记特定遗忘数据对模型的影响的同时，保持KG嵌入模型的性能是具有挑战性的。本文提出了FedDM，一个针对联邦知识图中机器去学习而量身定制的新型框架。通过利用扩散模型，我们生成带有噪声的...

    arXiv:2403.08554v1 Announce Type: cross  Abstract: Federated learning (FL) promotes the development and application of artificial intelligence technologies by enabling model sharing and collaboration while safeguarding data privacy. Knowledge graph (KG) embedding representation provides a foundation for knowledge reasoning and applications by mapping entities and relations into vector space. Federated KG embedding enables the utilization of knowledge from diverse client sources while safeguarding the privacy of local data. However, due to demands such as privacy protection and the need to adapt to dynamic data changes, investigations into machine unlearning (MU) have been sparked. However, it is challenging to maintain the performance of KG embedding models while forgetting the influence of specific forgotten data on the model. In this paper, we propose FedDM, a novel framework tailored for machine unlearning in federated knowledge graphs. Leveraging diffusion models, we generate noisy
    
[^18]: 高斯图像：通过2D高斯喷涂进行1000帧每秒的图像表示和压缩

    GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting

    [https://arxiv.org/abs/2403.08551](https://arxiv.org/abs/2403.08551)

    通过2D高斯喷涂实现图像表示和压缩，在GPU内存占用降低的情况下，提供了更快的渲染速度，并在表示性能上与INR相匹敌。

    

    最近，隐式神经表示（INR）在图像表示和压缩方面取得了巨大成功，提供了高视觉质量和快速渲染速度，每秒10-1000帧，假设有足够的GPU资源可用。然而，这种要求常常阻碍了它们在内存有限的低端设备上的使用。为此，我们提出了一种通过2D高斯喷涂进行图像表示和压缩的开创性范式，名为GaussianImage。我们首先引入2D高斯来表示图像，其中每个高斯具有8个参数，包括位置、协方差和颜色。随后，我们揭示了一种基于累积求和的新颖渲染算法。值得注意的是，我们的方法使用GPU内存至少降低3倍，拟合时间快5倍，不仅在表示性能上与INR（例如WIRE，I-NGP）不相上下，而且无论参数大小如何都能提供1500-2000帧每秒的更快渲染速度。

    arXiv:2403.08551v1 Announce Type: cross  Abstract: Implicit neural representations (INRs) recently achieved great success in image representation and compression, offering high visual quality and fast rendering speeds with 10-1000 FPS, assuming sufficient GPU resources are available. However, this requirement often hinders their use on low-end devices with limited memory. In response, we propose a groundbreaking paradigm of image representation and compression by 2D Gaussian Splatting, named GaussianImage. We first introduce 2D Gaussian to represent the image, where each Gaussian has 8 parameters including position, covariance and color. Subsequently, we unveil a novel rendering algorithm based on accumulated summation. Remarkably, our method with a minimum of 3$\times$ lower GPU memory usage and 5$\times$ faster fitting time not only rivals INRs (e.g., WIRE, I-NGP) in representation performance, but also delivers a faster rendering speed of 1500-2000 FPS regardless of parameter size. 
    
[^19]: HOLMES: 基于HOLonym-MEronym的语义检查技术用于卷积图像分类器

    HOLMES: HOLonym-MEronym based Semantic inspection for Convolutional Image Classifiers

    [https://arxiv.org/abs/2403.08536](https://arxiv.org/abs/2403.08536)

    HOLMES提出了一种新技术，通过将标签分解为一组相关概念并提供部件级解释，来帮助理解和解释卷积图像分类模型。

    

    卷积神经网络(CNNs)如今是计算机视觉中的首选模型，因为它们能够自动化视觉任务中的特征提取过程。然而，在训练期间获得的知识完全是亚符号的，因此难以理解和解释给最终用户。本文提出了一种名为HOLMES (HOLonym-MEronym based Semantic inspection)的新技术，它将标签分解为一组相关概念，并为图像分类模型提供部件级解释。具体来说，HOLMES利用本体论、网络抓取和迁移学习来自动构建给定holonym (类别)的meronym (部件)检测器。然后，它在meronym级别生成热图，最后通过使用遮挡图像对CNN的holonym进行探测，突出每个部件对分类输出的重要性。与最先进的显著性方法相比，HOLMES

    arXiv:2403.08536v1 Announce Type: cross  Abstract: Convolutional Neural Networks (CNNs) are nowadays the model of choice in Computer Vision, thanks to their ability to automatize the feature extraction process in visual tasks. However, the knowledge acquired during training is fully subsymbolic, and hence difficult to understand and explain to end users. In this paper, we propose a new technique called HOLMES (HOLonym-MEronym based Semantic inspection) that decomposes a label into a set of related concepts, and provides component-level explanations for an image classification model. Specifically, HOLMES leverages ontologies, web scraping and transfer learning to automatically construct meronym (parts)-based detectors for a given holonym (class). Then, it produces heatmaps at the meronym level and finally, by probing the holonym CNN with occluded images, it highlights the importance of each part on the classification output. Compared to state-of-the-art saliency methods, HOLMES takes a 
    
[^20]: 使用CNN、Transformer和循环网络对猪的攻击性进行分类

    Pig aggression classification using CNN, Transformers and Recurrent Networks

    [https://arxiv.org/abs/2403.08528](https://arxiv.org/abs/2403.08528)

    研究开发了使用CNN、Transformer和循环网络对猪的攻击性进行分类的技术，从而解决了人工分析动物行为可能存在的错误和耗时问题。

    

    研发能用于分析和检测动物行为的技术是畜牧业的关键活动，可以监测压力和动物福利，并有助于农场决策。因此，开发应用程序可以帮助饲养员做出改善生产表现和降低成本的决策，因为动物行为由人类分析可能存在错误和耗时。猪的攻击性是一个被研究的行为样本，通过动物分类和识别来降低其影响。然而，这一过程繁琐、容易出错，可以通过自动化减少，通过在受控环境下捕捉视频进行视觉分类以实现。捕获的视频可用于训练，结果通过计算机视觉和人工智能进行分类，采用神经网络技术。

    arXiv:2403.08528v1 Announce Type: cross  Abstract: The development of techniques that can be used to analyze and detect animal behavior is a crucial activity for the livestock sector, as it is possible to monitor the stress and animal welfare and contributes to decision making in the farm. Thus, the development of applications can assist breeders in making decisions to improve production performance and reduce costs, once the animal behavior is analyzed by humans and this can lead to susceptible errors and time consumption. Aggressiveness in pigs is an example of behavior that is studied to reduce its impact through animal classification and identification. However, this process is laborious and susceptible to errors, which can be reduced through automation by visually classifying videos captured in controlled environment. The captured videos can be used for training and, as a result, for classification through computer vision and artificial intelligence, employing neural network techn
    
[^21]: DiPrompT: 多潜在领域泛化的解耦提示调整在联邦学习中

    DiPrompT: Disentangled Prompt Tuning for Multiple Latent Domain Generalization in Federated Learning

    [https://arxiv.org/abs/2403.08506](https://arxiv.org/abs/2403.08506)

    提出了一种名为DiPrompT的解耦提示调整方法，通过学习适应提示来解决在联邦学习中对领域泛化的限制。

    

    arXiv:2403.08506v1 公告类型: 跨领域  摘要: 联邦学习（FL）已经成为一种强大的学习范式，可以从分散的数据中学习，而联邦领域泛化进一步考虑测试数据集（目标领域）不存在于分散的训练数据（源领域）中。然而，大多数现有的FL方法假设在训练过程中提供了领域标签，并且它们的评估对领域数量施加明确的约束，这些约束必须严格匹配客户端的数量。由于现实世界中众多边缘设备的被低效利用以及额外的跨客户端领域注释，这些限制可能是不切实际的，并涉及潜在的隐私泄漏。在本文中，我们提出了一种高效而新颖的方法，称为解耦提示调整（DiPrompT），该方法通过分布式学习适应提示来处理上述限制，来实现领域泛化。具体而言，我们首先设计了两种提示类型，即

    arXiv:2403.08506v1 Announce Type: cross  Abstract: Federated learning (FL) has emerged as a powerful paradigm for learning from decentralized data, and federated domain generalization further considers the test dataset (target domain) is absent from the decentralized training data (source domains). However, most existing FL methods assume that domain labels are provided during training, and their evaluation imposes explicit constraints on the number of domains, which must strictly match the number of clients. Because of the underutilization of numerous edge devices and additional cross-client domain annotations in the real world, such restrictions may be impractical and involve potential privacy leaks. In this paper, we propose an efficient and novel approach, called Disentangled Prompt Tuning (DiPrompT), a method that tackles the above restrictions by learning adaptive prompts for domain generalization in a distributed manner. Specifically, we first design two types of prompts, i.e., 
    
[^22]: 面向内容感知的掩码图像建模变压器用于立体图像压缩

    Content-aware Masked Image Modeling Transformer for Stereo Image Compression

    [https://arxiv.org/abs/2403.08505](https://arxiv.org/abs/2403.08505)

    提出了一种名为CAMSIC的立体图像压缩框架，通过引入面向内容感知的掩码图像建模（MIM）技术，使得无需额外Transformer解码器就能捕捉空间和视差依赖关系，实验结果表明实现了最先进的率失真结果。

    

    现有基于学习的立体图像编解码器采用了复杂的转换方法，但在编码潜在表示时却采用了从单个图像编解码器导出的简单熵模型。然而，这些熵模型难以有效捕捉立体图像固有的空间-视差特征，导致亚最优的率失真结果。本文提出了一种名为CAMSIC的立体图像压缩框架。 CAMSIC 独立地将每个图像转换为潜在表示，并采用强大的无解码器变压器熵模型来捕捉空间和视差依赖关系，引入了一种新颖的面向内容感知的掩码图像建模（MIM）技术。我们的面向内容感知的MIM促进了先验信息与估计令牌之间的高效双向交互，自然地消除了额外的Transformer解码器的需求。实验证明，我们的立体图像编解码器实现了最先进的率失真结果。

    arXiv:2403.08505v1 Announce Type: cross  Abstract: Existing learning-based stereo image codec adopt sophisticated transformation with simple entropy models derived from single image codecs to encode latent representations. However, those entropy models struggle to effectively capture the spatial-disparity characteristics inherent in stereo images, which leads to suboptimal rate-distortion results. In this paper, we propose a stereo image compression framework, named CAMSIC. CAMSIC independently transforms each image to latent representation and employs a powerful decoder-free Transformer entropy model to capture both spatial and disparity dependencies, by introducing a novel content-aware masked image modeling (MIM) technique. Our content-aware MIM facilitates efficient bidirectional interaction between prior information and estimated tokens, which naturally obviates the need for an extra Transformer decoder. Experiments show that our stereo image codec achieves state-of-the-art rate-d
    
[^23]: 具有字符引导和标题增强的遮蔽生成故事变换器

    Masked Generative Story Transformer with Character Guidance and Caption Augmentation

    [https://arxiv.org/abs/2403.08502](https://arxiv.org/abs/2403.08502)

    该论文提出了一种遮蔽生成故事变换器，利用字符引导和标题增强来实现一致性生成。

    

    Story Visualization (SV)是一项具有挑战性的生成视觉任务，既要求生成图像序列的视觉质量，又要求不同帧之间的一致性。我们提出了一种全新的并行变换器方法，通过过去和未来的标题之间的交叉注意力来实现一致性。此外，我们提出了一种字符引导技术，通过在logit空间中形成文本条件和字符条件logits的组合，以隐式地聚焦于角色的生成。我们还采用了一种由大型语言模型（LLM）执行的标题增强技术，以增强我们方法的鲁棒性。

    arXiv:2403.08502v1 Announce Type: cross  Abstract: Story Visualization (SV) is a challenging generative vision task, that requires both visual quality and consistency between different frames in generated image sequences. Previous approaches either employ some kind of memory mechanism to maintain context throughout an auto-regressive generation of the image sequence, or model the generation of the characters and their background separately, to improve the rendering of characters. On the contrary, we embrace a completely parallel transformer-based approach, exclusively relying on Cross-Attention with past and future captions to achieve consistency. Additionally, we propose a Character Guidance technique to focus on the generation of characters in an implicit manner, by forming a combination of text-conditional and character-conditional logits in the logit space. We also employ a caption-augmentation technique, carried out by a Large Language Model (LLM), to enhance the robustness of our
    
[^24]: 再现性和几何内在维度性：对图神经网络研究的调查

    Reproducibility and Geometric Intrinsic Dimensionality: An Investigation on Graph Neural Network Research

    [https://arxiv.org/abs/2403.08438](https://arxiv.org/abs/2403.08438)

    本文研究了图神经网络研究中的再现性和几何内在维度性问题，并引入机器学习中的再现性本体论，以及探讨了维度诅咒对数据收集、表示和分析的挑战。

    

    机器学习研究中复制和可再现性的困难近年来成为一个突出的话题。确保机器学习研究结果的可靠性需要可再现性，通过使用相同的代码和数据验证研究结果的可靠性。这促进了开放和可访问的研究、稳健的实验工作流程以及新发现的快速整合。评估研究出版物支持再现性的程度是本文的一个目标。为此，我们引入了一个机器学习中的再现性本体论，并将其应用于图神经网络的方法。在这些努力的基础上，我们转向机器学习中的另一个关键挑战，即维度诅咒，它在数据收集、表示和分析方面带来挑战，使得更难找到代表性数据。

    arXiv:2403.08438v1 Announce Type: cross  Abstract: Difficulties in replication and reproducibility of empirical evidences in machine learning research have become a prominent topic in recent years. Ensuring that machine learning research results are sound and reliable requires reproducibility, which verifies the reliability of research findings using the same code and data. This promotes open and accessible research, robust experimental workflows, and the rapid integration of new findings. Evaluating the degree to which research publications support these different aspects of reproducibility is one goal of the present work. For this we introduce an ontology of reproducibility in machine learning and apply it to methods for graph neural networks. Building on these efforts we turn towards another critical challenge in machine learning, namely the curse of dimensionality, which poses challenges in data collection, representation, and analysis, making it harder to find representative data 
    
[^25]: 基于搜索的对LLM学习样本进行优化以进行故事点估计

    Search-based Optimisation of LLM Learning Shots for Story Point Estimation

    [https://arxiv.org/abs/2403.08430](https://arxiv.org/abs/2403.08430)

    使用搜索方法优化LLM在故事点估计中的表现，使其平均估计性能提高了59.34%。

    

    大型语言模型（LLMs）用于执行机器学习任务的一种方式是在要求它们进行预测之前提供一些示例。这是一种称为少样本学习的元学习过程。本文使用可用的基于搜索的方法来优化数量和组合示例，可以提高LLM在用于估计新的敏捷任务的故事点时的估计性能。我们的初步结果显示，我们的SBSE技术在三个数据集上平均提高了59.34%的LLM估计性能（以估计的平均绝对误差为指标），相对于零样本设置。

    arXiv:2403.08430v1 Announce Type: cross  Abstract: One of the ways Large Language Models (LLMs) are used to perform machine learning tasks is to provide them with a few examples before asking them to produce a prediction. This is a meta-learning process known as few-shot learning. In this paper, we use available Search-Based methods to optimise the number and combination of examples that can improve an LLM's estimation performance, when it is used to estimate story points for new agile tasks. Our preliminary results show that our SBSE technique improves the estimation performance of the LLM by 59.34% on average (in terms of mean absolute error of the estimation) over three datasets against a zero-shot setting.
    
[^26]: 使用LLMs进行软件漏洞和功能评估

    Software Vulnerability and Functionality Assessment using LLMs

    [https://arxiv.org/abs/2403.08429](https://arxiv.org/abs/2403.08429)

    本文调查了如何使用大型语言模型（LLMs）协助进行代码审查，重点关注标记安全漏洞代码和执行软件功能验证两个任务，结果显示专有模型表现优于开源模型

    

    虽然代码审查在软件开发过程中至关重要，但进行代码审查可能会很繁琐且昂贵。在本文中，我们调查了大型语言模型（LLMs）是否可以帮助进行代码审查，重点关注两项我们认为对良好审查至关重要的任务：（i）标记具有安全漏洞的代码和（ii）执行软件功能验证，即确保代码符合其预期功能。为了测试在这两个任务上的表现，我们使用零镜像和链式提示来获得最终的“批准或拒绝”建议。作为数据，我们使用了里程碑式的代码生成数据集（HumanEval和MBPP），以及来自通用弱点枚举（CWE）的带有安全漏洞的专家编写代码片段。我们的实验考虑了来自OpenAI的三个专有模型和较小的开源LLMs的组合。我们发现前者表现优于后者

    arXiv:2403.08429v1 Announce Type: cross  Abstract: While code review is central to the software development process, it can be tedious and expensive to carry out. In this paper, we investigate whether and how Large Language Models (LLMs) can aid with code reviews. Our investigation focuses on two tasks that we argue are fundamental to good reviews: (i) flagging code with security vulnerabilities and (ii) performing software functionality validation, i.e., ensuring that code meets its intended functionality. To test performance on both tasks, we use zero-shot and chain-of-thought prompting to obtain final ``approve or reject'' recommendations. As data, we employ seminal code generation datasets (HumanEval and MBPP) along with expert-written code snippets with security vulnerabilities from the Common Weakness Enumeration (CWE). Our experiments consider a mixture of three proprietary models from OpenAI and smaller open-source LLMs. We find that the former outperforms the latter by a large
    
[^27]: 基于语言驱动的视觉一致性方法用于零样本语义分割

    Language-Driven Visual Consensus for Zero-Shot Semantic Segmentation

    [https://arxiv.org/abs/2403.08426](https://arxiv.org/abs/2403.08426)

    基于语言驱动的 LDVC 方法通过引入路由注意力机制，实现了零样本语义分割中的语义和视觉信息更好的对齐

    

    通过将视觉特征与类别嵌入对齐，借助变换器解码器生成语义掩模，预训练的视觉-语言模型（如CLIP）推动了零样本语义分割的发展。然而，目前这一范式内的方法遇到了一些挑战，包括在已见类别上过度拟合和掩模中的小碎片化。为了缓解这些问题，我们提出了一种基于语言驱动的视觉一致性（LDVC）方法，促进了语义和视觉信息的改进对齐。具体来说，我们利用类别嵌入作为锚点，引导视觉特征朝向类别嵌入。此外，为了避免由于视觉部分的冗余性而导致的嘈杂对齐，我们将路由注意引入到自注意力中，用于找到视觉一致性，从而增强同一物体内的语义一致性。

    arXiv:2403.08426v1 Announce Type: cross  Abstract: The pre-trained vision-language model, exemplified by CLIP, advances zero-shot semantic segmentation by aligning visual features with class embeddings through a transformer decoder to generate semantic masks. Despite its effectiveness, prevailing methods within this paradigm encounter challenges, including overfitting on seen classes and small fragmentation in masks. To mitigate these issues, we propose a Language-Driven Visual Consensus (LDVC) approach, fostering improved alignment of semantic and visual information.Specifically, we leverage class embeddings as anchors due to their discrete and abstract nature, steering vision features toward class embeddings. Moreover, to circumvent noisy alignments from the vision part due to its redundant nature, we introduce route attention into self-attention for finding visual consensus, thereby enhancing semantic consistency within the same object. Equipped with a vision-language prompting stra
    
[^28]: 人工智能规格过度拟合问题

    Specification Overfitting in Artificial Intelligence

    [https://arxiv.org/abs/2403.08425](https://arxiv.org/abs/2403.08425)

    本文定义了规格过度拟合问题，即系统过度关注指定指标而损害了高级要求和任务性能。

    

    机器学习（ML）和人工智能（AI）方法经常被批评存在固有的偏见，以及缺乏控制、问责和透明度，监管机构因此难以控制这种技术的潜在负面影响。高级要求，如公平性和鲁棒性，需要被形式化为具体的规格度量，而这些度量是捕捉基本要求的独立方面的不完美代理。鉴于不同指标之间可能存在的权衡及其对过度优化的脆弱性，将规格度量整合到系统开发过程中并不是一件简单的事情。本文定义了规格过度拟合，即系统过度侧重于指定的度量，从而损害了高级要求和任务性能。我们进行了大量文献调研，对研究人员如何提出、测量和优化规格进行了分类。

    arXiv:2403.08425v1 Announce Type: new  Abstract: Machine learning (ML) and artificial intelligence (AI) approaches are often criticized for their inherent bias and for their lack of control, accountability, and transparency. Consequently, regulatory bodies struggle with containing this technology's potential negative side effects. High-level requirements such as fairness and robustness need to be formalized into concrete specification metrics, imperfect proxies that capture isolated aspects of the underlying requirements. Given possible trade-offs between different metrics and their vulnerability to over-optimization, integrating specification metrics in system development processes is not trivial. This paper defines specification overfitting, a scenario where systems focus excessively on specified metrics to the detriment of high-level requirements and task performance. We present an extensive literature survey to categorize how researchers propose, measure, and optimize specification
    
[^29]: Tastle: 为自动越狱攻击干扰大型语言模型

    Tastle: Distract Large Language Models for Automatic Jailbreak Attack

    [https://arxiv.org/abs/2403.08424](https://arxiv.org/abs/2403.08424)

    Tastle是一种新颖的黑盒越狱框架，采用恶意内容隐藏和内存重构以及迭代优化算法，用于自动对大型语言模型进行红队攻击。

    

    大型语言模型（LLMs）近年来取得了重要进展。在LLMs公开发布之前，人们已经做出了大量努力来将它们的行为与人类价值观保持一致。对齐的主要目标是确保它们的有益性、诚实性和无害性。然而，即使经过细致对齐的LLMs仍然容易受到恶意操纵，如越狱，导致意外的行为。越狱是有意开发恶意提示，从LLM安全限制中逃脱以生成未经审查的有害内容。以前的工作探索了不同的越狱方法来对LLMs进行红队攻击，但它们在效果和可伸缩性方面遇到了挑战。在这项工作中，我们提出了Tastle，一种新颖的黑盒越狱框架，用于自动对LLMs进行红队攻击。我们设计了恶意内容隐藏和内存重构，并结合迭代优化算法来越狱LLMs。

    arXiv:2403.08424v1 Announce Type: cross  Abstract: Large language models (LLMs) have achieved significant advances in recent days. Extensive efforts have been made before the public release of LLMs to align their behaviors with human values. The primary goal of alignment is to ensure their helpfulness, honesty and harmlessness. However, even meticulously aligned LLMs remain vulnerable to malicious manipulations such as jailbreaking, leading to unintended behaviors. The jailbreak is to intentionally develop a malicious prompt that escapes from the LLM security restrictions to produce uncensored detrimental contents. Previous works explore different jailbreak methods for red teaming LLMs, yet they encounter challenges regarding to effectiveness and scalability. In this work, we propose Tastle, a novel black-box jailbreak framework for automated red teaming of LLMs. We designed malicious content concealing and memory reframing with an iterative optimization algorithm to jailbreak LLMs, mo
    
[^30]: 用于火灾危险预测的因果图神经网络

    Causal Graph Neural Networks for Wildfire Danger Prediction

    [https://arxiv.org/abs/2403.08414](https://arxiv.org/abs/2403.08414)

    通过将因果性与图神经网络相结合，模型能够显式地建模复杂变量之间的因果机理，提高了火灾模式预测的性能。

    

    火灾预测因天气条件、植被类型和人类活动等不同因素的复杂相互作用而变得难以预测。深度学习模型展现了直接从数据中学习处理这种复杂性的潜力。然而，为了支持关键决策，我们认为我们需要适合正确原因的模型；也就是说，学到的隐式规则应该以推动火灾的基本过程为基础。在这个方向上，我们建议将因果性与图神经网络（GNNs）相结合，通过图学习显式地对复杂变量之间的因果机理建模。因果邻接矩阵考虑了不同变量之间的协同作用，并消除了高度相关影响之间的虚假联系。我们的方法的有效性通过在欧洲北部和地中海生物群系中优越性能预测火灾模式而得到证明。收益是

    arXiv:2403.08414v1 Announce Type: cross  Abstract: Wildfire forecasting is notoriously hard due to the complex interplay of different factors such as weather conditions, vegetation types and human activities. Deep learning models show promise in dealing with this complexity by learning directly from data. However, to inform critical decision making, we argue that we need models that are right for the right reasons; that is, the implicit rules learned should be grounded by the underlying processes driving wildfires. In that direction, we propose integrating causality with Graph Neural Networks (GNNs) that explicitly model the causal mechanism among complex variables via graph learning. The causal adjacency matrix considers the synergistic effect among variables and removes the spurious links from highly correlated impacts. Our methodology's effectiveness is demonstrated through superior performance forecasting wildfire patterns in the European boreal and mediterranean biome. The gain is
    
[^31]: 优化风险敏感的人工智能混合团队

    Optimizing Risk-averse Human-AI Hybrid Teams

    [https://arxiv.org/abs/2403.08386](https://arxiv.org/abs/2403.08386)

    提出了一种经理通过强化学习方案学习如何在混合人工智能团队中最佳分配决策责任，并最小化不良团队行为导致的委派变更次数。

    

    我们预计随着人类和人工智能系统在所谓的混合团队中合作的增加，这种合作的频率将增加。随着人工智能系统的熟练度提高和其采用变得更加广泛，预计协作将增加。但是，它们的行为并非无误，从而使混合团队成为一种非常合适的解决方案。因此，我们考虑了改进这些由人类和人工智能系统组成的团队的绩效的方法。对于混合团队，我们将人类和人工智能系统都称为代理。为了提高团队的表现，我们提出了一种经理，该经理通过标准的强化学习方案学习如何在一段时间内最好地委派决策责任给任何一个代理。我们进一步引导经理的学习，让他们最小化因不良团队行为而导致的委派变更次数。我们展示了管理者绩效的最优性。

    arXiv:2403.08386v1 Announce Type: new  Abstract: We anticipate increased instances of humans and AI systems working together in what we refer to as a hybrid team. The increase in collaboration is expected as AI systems gain proficiency and their adoption becomes more widespread. However, their behavior is not error-free, making hybrid teams a very suitable solution. As such, we consider methods for improving performance for these teams of humans and AI systems. For hybrid teams, we will refer to both the humans and AI systems as agents. To improve team performance over that seen for agents operating individually, we propose a manager which learns, through a standard Reinforcement Learning scheme, how to best delegate, over time, the responsibility of taking a decision to any of the agents. We further guide the manager's learning so they also minimize how many changes in delegation are made resulting from undesirable team behavior. We demonstrate the optimality of our manager's performa
    
[^32]: 云迁移中SQL方言的转换

    Translating between SQL Dialects for Cloud Migration

    [https://arxiv.org/abs/2403.08375](https://arxiv.org/abs/2403.08375)

    本文讨论了云迁移中SQL数据库方言的转换困难，尽管有一些工具可以帮助转换方言，但并不能完全解决问题，需要人工干预。

    

    从现场到云的系统迁移是许多工业机构的重要工作。这种云迁移的关键组成部分是将数据库转移到在线主机。在这项工作中，我们考虑了SQL数据库的迁移困难。尽管SQL是存储数据库程序的显著方法之一，但存在着大量不同的SQL方言（例如MySQL，Postgres等），当现场的SQL方言与云上托管的方言不同时，这可能会使迁移复杂化。一些常见云提供商如AWS和Azure提供了工具来帮助在方言之间进行转换，以减轻大部分困难。然而，这些工具并不成功地转换 100% 的代码。因此，软件工程师必须手动转换未翻译数据库的其余部分。对于大型组织，这项任务很快变得棘手。

    arXiv:2403.08375v1 Announce Type: cross  Abstract: Migrations of systems from on-site premises to the cloud has been a fundamental endeavor by many industrial institutions. A crucial component of such cloud migrations is the transition of databases to be hosted online. In this work, we consider the difficulties of this migration for SQL databases. While SQL is one of the prominent methods for storing database procedures, there are a plethora of different SQL dialects (e.g., MySQL, Postgres, etc.) which can complicate migrations when the on-premise SQL dialect differs to the dialect hosted on the cloud. Tools exist by common cloud provides such as AWS and Azure to aid in translating between dialects in order to mitigate the majority of the difficulties. However, these tools do not successfully translate $100\%$ of the code. Consequently, software engineers must manually convert the remainder of the untranslated database. For large organizations, this task quickly becomes intractable and
    
[^33]: SMART: 用于指令调整的子模块数据混合策略

    SMART: Submodular Data Mixture Strategy for Instruction Tuning

    [https://arxiv.org/abs/2403.08370](https://arxiv.org/abs/2403.08370)

    SMART引入了一种新颖的数据混合策略，利用子模块函数为任务分配重要性分数，并在微调中重新分配预算，从而在指令调整任务中取得明显优势。

    

    指令调整涉及在一组以指令格式化的数据集上对语言模型进行微调，以增强模型对未见任务的泛化能力。研究表明，在微调过程中平衡不同任务比例的重要性，但找到合适的平衡仍然具有挑战性。目前除了手动调整或依赖从业者的直觉外，尚无系统方法。在本文中，我们介绍了SMART（Submodular data Mixture strAtegy for instRuction Tuning）- 一种利用子模块函数为任务分配重要性分数的新颖数据混合策略，然后用这些分数来确定混合权重。给定微调预算，SMART重新分配任务间的预算，并从每个任务中选择非冗余样本。实验结果表明，SMART显著优于传统方法，如例子比例混合和均等分配。

    arXiv:2403.08370v1 Announce Type: cross  Abstract: Instruction Tuning involves finetuning a language model on a collection of instruction-formatted datasets in order to enhance the generalizability of the model to unseen tasks. Studies have shown the importance of balancing different task proportions during finetuning, but finding the right balance remains challenging. Unfortunately, there's currently no systematic method beyond manual tuning or relying on practitioners' intuition. In this paper, we introduce SMART (Submodular data Mixture strAtegy for instRuction Tuning) - a novel data mixture strategy which makes use of a submodular function to assign importance scores to tasks which are then used to determine the mixture weights. Given a fine-tuning budget, SMART redistributes the budget among tasks and selects non-redundant samples from each task. Experimental results demonstrate that SMART significantly outperforms traditional methods such as examples proportional mixing and equal
    
[^34]: 针对长尾和非独立同分布数据的特征统计分开式联邦学习

    Decoupled Federated Learning on Long-Tailed and Non-IID data with Feature Statistics

    [https://arxiv.org/abs/2403.08364](https://arxiv.org/abs/2403.08364)

    本文提出了针对长尾和非独立同分布数据的特征统计分开式联邦学习框架，通过两阶段方式解决尾部类别稀疏分布导致的模型性能下降问题

    

    联邦学习旨在增强数据安全性和隐私性，但在处理长尾和非独立同分布的异构数据时面临挑战。本文探讨了一个被忽视的情景，即尾部类别在少数客户端上稀疏分布，导致使用这些类别训练的模型在客户端聚合过程中被选择的概率较低，从而导致收敛速度较慢和模型性能较差。为了解决这个问题，我们提出了一个使用特征统计的两阶段分开式联邦学习框架（DFL-FS）。在第一阶段，服务器通过蒙版局部特征统计聚类估计客户端的类别覆盖分布，以加快收敛速度和增强特征学习而不泄露隐私。在第二阶段，DFL-FS基于全局特征统计采用联邦特征再生，并利用重采样

    arXiv:2403.08364v1 Announce Type: cross  Abstract: Federated learning is designed to enhance data security and privacy, but faces challenges when dealing with heterogeneous data in long-tailed and non-IID distributions. This paper explores an overlooked scenario where tail classes are sparsely distributed over a few clients, causing the models trained with these classes to have a lower probability of being selected during client aggregation, leading to slower convergence rates and poorer model performance. To address this issue, we propose a two-stage Decoupled Federated learning framework using Feature Statistics (DFL-FS). In the first stage, the server estimates the client's class coverage distributions through masked local feature statistics clustering to select models for aggregation to accelerate convergence and enhance feature learning without privacy leakage. In the second stage, DFL-FS employs federated feature regeneration based on global feature statistics and utilizes resamp
    
[^35]: 利用自动化机器学习的数据增强方法及与传统数据增强方法性能比较

    Data augmentation with automated machine learning: approaches and performance comparison with classical data augmentation methods

    [https://arxiv.org/abs/2403.08352](https://arxiv.org/abs/2403.08352)

    自动化机器学习的数据增强方法旨在自动化数据增强过程，为改善机器学习模型泛化性能提供了更高效的方式。

    

    数据增强被认为是常用于提高机器学习模型泛化性能的最重要的正则化技术。它主要涉及应用适当的数据转换操作，以创建具有所需属性的新数据样本。尽管其有效性，这一过程通常具有挑战性，因为手动创建和测试不同候选增强及其超参数需耗费大量时间。自动化数据增强方法旨在自动化这一过程。最先进的方法通常依赖于自动化机器学习（AutoML）原则。本研究提供了基于AutoML的数据增强技术的全面调查。我们讨论了使用AutoML实现数据增强的各种方法，包括数据操作、数据集成和数据合成技术。我们详细讨论了技术

    arXiv:2403.08352v1 Announce Type: cross  Abstract: Data augmentation is arguably the most important regularization technique commonly used to improve generalization performance of machine learning models. It primarily involves the application of appropriate data transformation operations to create new data samples with desired properties. Despite its effectiveness, the process is often challenging because of the time-consuming trial and error procedures for creating and testing different candidate augmentations and their hyperparameters manually. Automated data augmentation methods aim to automate the process. State-of-the-art approaches typically rely on automated machine learning (AutoML) principles. This work presents a comprehensive survey of AutoML-based data augmentation techniques. We discuss various approaches for accomplishing data augmentation with AutoML, including data manipulation, data integration and data synthesis techniques. We present extensive discussion of technique
    
[^36]: LLM辅助下的交通信号控制：利用大型语言模型在复杂城市环境中实现人类仿生交通信号控制

    LLM-Assisted Light: Leveraging Large Language Model Capabilities for Human-Mimetic Traffic Signal Control in Complex Urban Environments

    [https://arxiv.org/abs/2403.08337](https://arxiv.org/abs/2403.08337)

    本研究提出了将大型语言模型(LLMs)整合到交通信号控制(TSC)系统中的创新方法，以解决传统TSC系统在适应不熟悉场景方面的限制，并提出了一个混合框架，使得LLMs与一系列感知和决策工具相结合，从而提升TSC系统对城市交通复杂性和变异性的管理能力。

    

    大都市地区的交通拥堵是一个具有深远经济、环境和社会影响的巨大挑战。因此，有效的拥堵管理至关重要，交通信号控制(TSC)系统在这方面起着至关重要的作用。为了回应传统TSC系统在管理城市交通流动的复杂性和变异性方面经常表现出的不足，本研究引入了一种创新方法，将大型语言模型(LLMs)整合到TSC中，利用其先进的推理和决策能力。具体来说，提出了一个混合框架，将LLMs与一套感知和决策工具相结合，有助于探讨静态和动态交通信息。

    arXiv:2403.08337v1 Announce Type: cross  Abstract: Traffic congestion in metropolitan areas presents a formidable challenge with far-reaching economic, environmental, and societal ramifications. Therefore, effective congestion management is imperative, with traffic signal control (TSC) systems being pivotal in this endeavor. Conventional TSC systems, designed upon rule-based algorithms or reinforcement learning (RL), frequently exhibit deficiencies in managing the complexities and variabilities of urban traffic flows, constrained by their limited capacity for adaptation to unfamiliar scenarios. In response to these limitations, this work introduces an innovative approach that integrates Large Language Models (LLMs) into TSC, harnessing their advanced reasoning and decision-making faculties. Specifically, a hybrid framework that augments LLMs with a suite of perception and decision-making tools is proposed, facilitating the interrogation of both the static and dynamic traffic informatio
    
[^37]: 部分可观测因果表示学习的稀疏原则

    A Sparsity Principle for Partially Observable Causal Representation Learning

    [https://arxiv.org/abs/2403.08335](https://arxiv.org/abs/2403.08335)

    提出了部分可观测因果表示学习的稀疏原则，建立了两个可识别性结果，为线性混合函数和分段线性混合函数设置了基础模型。

    

    因果表示学习旨在从感知数据中识别高层次的因果变量。本文考虑部分观测设置，其中每次测量仅提供关于潜在因果状态子集的信息。我们专注于从数据集中不配对观察学习，其中存在实例相关的部分可观测模式。我们的主要贡献是为该设置建立两个可识别性结果：一个是关于线性混合函数的结果，无需对潜在因果模型做参数假设，另一个是对具有高斯潜在因果变量的分段线性混合函数的结果。基于这些见解，我们提出了两种用于估计潜在因果变量的方法。

    arXiv:2403.08335v1 Announce Type: cross  Abstract: Causal representation learning aims at identifying high-level causal variables from perceptual data. Most methods assume that all latent causal variables are captured in the high-dimensional observations. We instead consider a partially observed setting, in which each measurement only provides information about a subset of the underlying causal state. Prior work has studied this setting with multiple domains or views, each depending on a fixed subset of latents. Here, we focus on learning from unpaired observations from a dataset with an instance-dependent partial observability pattern. Our main contribution is to establish two identifiability results for this setting: one for linear mixing functions without parametric assumptions on the underlying causal model, and one for piecewise linear mixing functions with Gaussian latent causal variables. Based on these insights, we propose two methods for estimating the underlying causal variab
    
[^38]: 快速推断基于移除的节点影响

    Fast Inference of Removal-Based Node Influence

    [https://arxiv.org/abs/2403.08333](https://arxiv.org/abs/2403.08333)

    提出了一种评估节点影响的新方法，通过测量训练好的图神经网络模型在移除节点后的预测变化，以实现快速推断。

    

    图神经网络（GNNs）被广泛用于捕获图中信息传播模式。虽然取得了显著的性能，但评估节点影响的新趋势日益受到关注。我们提出了一种评估节点影响的新方法，通过衡量训练好的GNN模型在移除节点后的预测变化。一个真实应用是，“在预测Twitter账户极性的任务中，如果移除特定账户，其他账户的极性会如何改变？”我们将GNN作为一个代理模型，其预测可以模拟移除节点引起的节点或边的变化。为了获得每个节点的影响，一种直接的方法是交替移除每个节点，并在修改后的图上应用训练好的GNN。这是可靠的但耗时，因此我们需要一种高效的方法。

    arXiv:2403.08333v1 Announce Type: cross  Abstract: Graph neural networks (GNNs) are widely utilized to capture the information spreading patterns in graphs. While remarkable performance has been achieved, there is a new trending topic of evaluating node influence. We propose a new method of evaluating node influence, which measures the prediction change of a trained GNN model caused by removing a node. A real-world application is, "In the task of predicting Twitter accounts' polarity, had a particular account been removed, how would others' polarity change?". We use the GNN as a surrogate model whose prediction could simulate the change of nodes or edges caused by node removal. To obtain the influence for every node, a straightforward way is to alternately remove every node and apply the trained GNN on the modified graph. It is reliable but time-consuming, so we need an efficient method. The related lines of work, such as graph adversarial attack and counterfactual explanation, cannot 
    
[^39]: 自回归得分生成用于多特征作文评分

    Autoregressive Score Generation for Multi-trait Essay Scoring

    [https://arxiv.org/abs/2403.08332](https://arxiv.org/abs/2403.08332)

    提出一种自回归预测多特征分数的方法（ArTS），通过利用预先训练的T5来结合解码过程，实现了自动作文评分中多分数预测的效果。

    

    最近，仅编码器预训练模型如BERT已成功应用于自动作文评分（AES）中，用于预测单一整体分数。然而，研究尚未探索这些模型在多特征AES中的应用，可能是由于为每个特征复制基于BERT的模型的效率低下。我们突破了现有仅使用编码器的模型，提出了一种自回归预测多特征分数（ArTS）的方法，通过利用预先训练的T5来结合一个解码过程。与先前的回归或分类方法不同，我们重新定义AES为一个得分生成任务，允许单个模型预测多个分数。在解码过程中，随后的特征预测可以通过在先前的特征分数上进行条件化而受益。实验结果证明了ArTS的有效性，显示了在提示和特征方面平均提高5%以上。

    arXiv:2403.08332v1 Announce Type: cross  Abstract: Recently, encoder-only pre-trained models such as BERT have been successfully applied in automated essay scoring (AES) to predict a single overall score. However, studies have yet to explore these models in multi-trait AES, possibly due to the inefficiency of replicating BERT-based models for each trait. Breaking away from the existing sole use of encoder, we propose an autoregressive prediction of multi-trait scores (ArTS), incorporating a decoding process by leveraging the pre-trained T5. Unlike prior regression or classification methods, we redefine AES as a score-generation task, allowing a single model to predict multiple scores. During decoding, the subsequent trait prediction can benefit by conditioning on the preceding trait scores. Experimental results proved the efficacy of ArTS, showing over 5% average improvements in both prompts and traits.
    
[^40]: LLMs的知识冲突：一项调查

    Knowledge Conflicts for LLMs: A Survey

    [https://arxiv.org/abs/2403.08319](https://arxiv.org/abs/2403.08319)

    这项调查深入分析了LLMs在融合上下文和参数化知识时所面临的知识冲突，探讨了三类知识冲突对其可信度和性能的重要影响，并提出改进LLMs稳健性策略的策略。

    

    这项调查对大型语言模型（LLMs）的知识冲突进行了深入分析，突出了当它们融合上下文和参数化知识时所遇到的复杂挑战。我们关注三类知识冲突：上下文-记忆冲突、跨上下文冲突和内部记忆冲突。这些冲突可能会显著影响LLMs的可信度和性能，特别是在现实世界应用中，噪音和错误信息很常见。通过对这些冲突进行分类，探讨其原因，研究LLMs在这些冲突下的行为，并回顾可用的解决方案，本调查旨在为改进LLMs的稳健性策略提供启示，从而成为推动这一不断发展领域研究的宝贵资源。

    arXiv:2403.08319v1 Announce Type: cross  Abstract: This survey provides an in-depth analysis of knowledge conflicts for large language models (LLMs), highlighting the complex challenges they encounter when blending contextual and parametric knowledge. Our focus is on three categories of knowledge conflicts: context-memory, inter-context, and intra-memory conflict. These conflicts can significantly impact the trustworthiness and performance of LLMs, especially in real-world applications where noise and misinformation are common. By categorizing these conflicts, exploring the causes, examining the behaviors of LLMs under such conflicts, and reviewing available solutions, this survey aims to shed light on strategies for improving the robustness of LLMs, thereby serving as a valuable resource for advancing research in this evolving area.
    
[^41]: 通过最小损失进行长上下文压缩的StreamingDialogue：长对话学习

    StreamingDialogue: Prolonged Dialogue Learning via Long Context Compression with Minimal Losses

    [https://arxiv.org/abs/2403.08312](https://arxiv.org/abs/2403.08312)

    提出了StreamingDialogue，通过将长对话历史压缩为"会话注意力汇集点"，最小化损失，使计算复杂度减少，并有潜力处理超过200k条话语，实现长时间对话学习

    

    标准的大型语言模型(LLMs)在处理具有长上下文的对话时遇到了效率和一致性问题。根据我们的观察，对话上下文具有高度结构化，并且对话中的特殊标记\textit{End-of-Utterance} (EoU) 有聚合信息的潜力。我们将EoU标记称为"会话注意力汇集点"（conv-attn sinks）。因此，我们介绍了StreamingDialogue，将长对话历史压缩为conv-attn沉点，并最小化损失，从而使计算复杂度与沉点数量（即话语数量）的平方成正比。当前的LLMs已经展示了处理长上下文窗口的能力，例如，窗口大小达到200k甚至更大。通过将话语压缩为EoUs，我们的方法有潜力处理超过200k条话语，实现长时间对话学习。

    arXiv:2403.08312v1 Announce Type: cross  Abstract: Standard Large Language Models (LLMs) struggle with handling dialogues with long contexts due to efficiency and consistency issues. According to our observation, dialogue contexts are highly structured, and the special token of \textit{End-of-Utterance} (EoU) in dialogues has the potential to aggregate information. We refer to the EoU tokens as ``conversational attention sinks'' (conv-attn sinks). Accordingly, we introduce StreamingDialogue, which compresses long dialogue history into conv-attn sinks with minimal losses, and thus reduces computational complexity quadratically with the number of sinks (i.e., the number of utterances). Current LLMs already demonstrate the ability to handle long context window, e.g., a window size of 200k or more. To this end, by compressing utterances into EoUs, our method has the potential to handle more than 200k of utterances, resulting in a prolonged dialogue learning. In order to minimize informatio
    
[^42]: HRLAIF: 通过AI反馈改进开放域强化学习中的帮助性和无害性

    HRLAIF: Improvements in Helpfulness and Harmlessness in Open-domain Reinforcement Learning From AI Feedback

    [https://arxiv.org/abs/2403.08309](https://arxiv.org/abs/2403.08309)

    提出了HRLAIF方法来改善开放域强化学习中的模型响应帮助性，通过增强AI注释响应的准确性来提高模型在训练过程中的鲁棒性

    

    强化学习从AI反馈（RLAIF）相比从人类反馈中学习（RLHF）具有更短的注释周期和更低的成本优势，使其在大型语言模型（LLM）训练的快速策略迭代阶段非常高效。使用ChatGPT作为标注员，在RLAIF训练中为开放域提示提供反馈，我们观察到人类评估者对模型响应的偏好胜率增加，但评估者的满意度下降。分析表明，满意度下降主要是因为一些响应变得不够有帮助，特别是在正确性和真实性方面，突显了基本RLAIF的实际局限性。在本文中，我们提出了混合强化学习从AI反馈（HRLAIF）。该方法增强了AI注释响应的准确性，在训练过程中使模型的帮助性更加稳健。

    arXiv:2403.08309v1 Announce Type: cross  Abstract: Reinforcement Learning from AI Feedback (RLAIF) has the advantages of shorter annotation cycles and lower costs over Reinforcement Learning from Human Feedback (RLHF), making it highly efficient during the rapid strategy iteration periods of large language model (LLM) training. Using ChatGPT as a labeler to provide feedback on open-domain prompts in RLAIF training, we observe an increase in human evaluators' preference win ratio for model responses, but a decrease in evaluators' satisfaction rate. Analysis suggests that the decrease in satisfaction rate is mainly due to some responses becoming less helpful, particularly in terms of correctness and truthfulness, highlighting practical limitations of basic RLAIF. In this paper, we propose Hybrid Reinforcement Learning from AI Feedback (HRLAIF). This method enhances the accuracy of AI annotations for responses, making the model's helpfulness more robust in training process. Additionally, 
    
[^43]: AutoDev：自动化AI驱动开发

    AutoDev: Automated AI-Driven Development

    [https://arxiv.org/abs/2403.08299](https://arxiv.org/abs/2403.08299)

    AutoDev是一个完全自动化的AI驱动软件开发框架，旨在实现复杂软件工程任务的自主规划和执行。

    

    软件开发领域随着AI助手的出现（如GitHub Copilot）而发生了范式转变。然而，现有解决方案并未充分利用IDE中可用的所有潜在功能，如构建、测试、执行代码、git操作等。因此，它们受到其有限能力的限制，主要集中在在基于聊天的界面中建议代码片段和文件操作。为了填补这一缺口，我们提出了AutoDev，这是一个完全自动化的AI驱动软件开发框架，旨在实现复杂软件工程任务的自主规划和执行。AutoDev使用户能够定义复杂的软件工程目标，并将这些目标分配给AutoDev的自主AI代理以实现。这些AI代理可以在代码库上执行各种操作，包括文件编辑、检索、构建过程、执行、测试和git操作。

    arXiv:2403.08299v1 Announce Type: cross  Abstract: The landscape of software development has witnessed a paradigm shift with the advent of AI-powered assistants, exemplified by GitHub Copilot. However, existing solutions are not leveraging all the potential capabilities available in an IDE such as building, testing, executing code, git operations, etc. Therefore, they are constrained by their limited capabilities, primarily focusing on suggesting code snippets and file manipulation within a chat-based interface. To fill this gap, we present AutoDev, a fully automated AI-driven software development framework, designed for autonomous planning and execution of intricate software engineering tasks. AutoDev enables users to define complex software engineering objectives, which are assigned to AutoDev's autonomous AI Agents to achieve. These AI agents can perform diverse operations on a codebase, including file editing, retrieval, build processes, execution, testing, and git operations. They
    
[^44]: Gemma：基于Gemini研究和技术的开放模型

    Gemma: Open Models Based on Gemini Research and Technology

    [https://arxiv.org/abs/2403.08295](https://arxiv.org/abs/2403.08295)

    Gemma是基于Gemini研究和技术所构建的开放模型系列，在语言理解、推理和安全性等方面表现出色，负责任地发布这些大型语言模型对于提高前沿模型的安全性至关重要。

    

    本文介绍了Gemma，这是一个基于Gemini模型研究和技术构建的轻量级、最先进的开放模型系列。Gemma模型在语言理解、推理和安全性等学术基准上表现出色。我们发布了两个规模的模型（20亿和70亿参数），并提供了预训练和微调的检查点。Gemma在18个基于文本的任务中，有11个任务优于类似规模的开放模型，并对模型的安全性和责任方面进行了全面评估，同时详细描述了模型开发过程。我们相信负责任地发布大型语言模型对于提高前沿模型的安全性，并实现下一波大型语言模型创新至关重要。

    arXiv:2403.08295v1 Announce Type: cross  Abstract: This work introduces Gemma, a family of lightweight, state-of-the art open models built from the research and technology used to create Gemini models. Gemma models demonstrate strong performance across academic benchmarks for language understanding, reasoning, and safety. We release two sizes of models (2 billion and 7 billion parameters), and provide both pretrained and fine-tuned checkpoints. Gemma outperforms similarly sized open models on 11 out of 18 text-based tasks, and we present comprehensive evaluations of safety and responsibility aspects of the models, alongside a detailed description of model development. We believe the responsible release of LLMs is critical for improving the safety of frontier models, and for enabling the next wave of LLM innovations.
    
[^45]: 生成预训练结构化Transformer：规模化的无监督句法语言模型

    Generative Pretrained Structured Transformers: Unsupervised Syntactic Language Models at Scale

    [https://arxiv.org/abs/2403.08293](https://arxiv.org/abs/2403.08293)

    GPST是一种无监督的句法语言模型，通过联合训练两个模型实现对原始文本的高并行预训练，克服了之前SLM依赖于黄金树和顺序训练的限制，展示了在多个任务中优于同等规模的GPT-2。

    

    句法语言模型（SLM）以从左到右的方式逐步生成带有其句法树的句子。我们提出了生成预训练结构化Transformer（GPST），这是一种规模化的无监督SLM，能够在原始文本上从头开始进行高并行预训练。GPST规避了之前SLM的一些限制，比如依赖于黄金树和顺序训练。它由两个组件组成，一个通常的SLM受单向语言建模损失的监督，以及一个额外的组合模型，用于引导句法解析树并计算成分表示，受双向语言建模损失的监督。我们提出了一个表示替代方案，以实现两个模型的联合并行训练，采用硬EM的方式。我们在OpenWebText上对GPST进行了预训练，该语料库包括90亿个token，并展示了GPST在许多任务上的优越性，涵盖了与GPT-2相当规模的内容。

    arXiv:2403.08293v1 Announce Type: cross  Abstract: A syntactic language model (SLM) incrementally generates a sentence with its syntactic tree in a left-to-right manner. We present Generative Pretrained Structured Transformers (GPST), an unsupervised SLM at scale capable of being pre-trained from scratch on raw texts with high parallelism. GPST circumvents the limitations of previous SLMs such as relying on gold trees and sequential training. It consists of two components, a usual SLM supervised by a uni-directional language modeling loss, and an additional composition model, which induces syntactic parse trees and computes constituent representations, supervised by a bi-directional language modeling loss. We propose a representation surrogate to enable joint parallel training of the two models in a hard-EM fashion. We pre-train GPST on OpenWebText, a corpus with $9$ billion tokens, and demonstrate the superiority of GPST over GPT-2 with a comparable size in numerous tasks covering bot
    
[^46]: 使用弱配对回归推断具有Lévy噪声的随机动力学

    Weak Collocation Regression for Inferring Stochastic Dynamics with L\'{e}vy Noise

    [https://arxiv.org/abs/2403.08292](https://arxiv.org/abs/2403.08292)

    本文提出了一种弱配对回归（WCR）方法，可以从离散的聚合数据中明确揭示具有Lévy噪声的随机微分方程（SDE），填补了在提取具有Lévy噪声的随机动力学方面的空白。

    

    随着随机系统的观测、实验和模拟数据快速增加，人们为了找到这些系统演化背后的控制规律进行了大量努力。尽管非高斯波动在许多物理现象中有着广泛的应用，但用于提取具有Lévy噪声的随机动力学的数据驱动方法相对较少。在这项工作中，我们提出了一种弱配对回归（WCR）方法，来明确揭示未知的随机动力系统，即具有$\alpha$-稳定Lévy噪声和高斯噪声的随机微分方程（SDE），从离散的聚合数据中。此方法利用概率分布函数的演化方程，即福克-普朗克（FP）方程。通过FP方程的弱形式，WCR构建了一个未知参数的线性系统，其中所有积分都通过蒙特卡罗方法进行评估。

    arXiv:2403.08292v1 Announce Type: cross  Abstract: With the rapid increase of observational, experimental and simulated data for stochastic systems, tremendous efforts have been devoted to identifying governing laws underlying the evolution of these systems. Despite the broad applications of non-Gaussian fluctuations in numerous physical phenomena, the data-driven approaches to extracting stochastic dynamics with L\'{e}vy noise are relatively few. In this work, we propose a Weak Collocation Regression (WCR) to explicitly reveal unknown stochastic dynamical systems, i.e., the Stochastic Differential Equation (SDE) with both $\alpha$-stable L\'{e}vy noise and Gaussian noise, from discrete aggregate data. This method utilizes the evolution equation of the probability distribution function, i.e., the Fokker-Planck (FP) equation. With the weak form of the FP equation, the WCR constructs a linear system of unknown parameters where all integrals are evaluated by Monte Carlo method with the ob
    
[^47]: CleanAgent：基于LLM代理自动化数据标准化

    CleanAgent: Automating Data Standardization with LLM-based Agents

    [https://arxiv.org/abs/2403.08291](https://arxiv.org/abs/2403.08291)

    提出了一个具有声明性、统一API的Python库，通过简洁的API调用简化LLM的代码生成流程

    

    数据标准化是数据科学生命周期中至关重要的一部分。虽然诸如Pandas之类的工具提供了强大的功能，但它们的复杂性以及需要定制代码以适应不同列类型的手动操作带来了重大挑战。尽管大型语言模型（LLMs）如ChatGPT已经展现出通过自然语言理解和代码生成自动化此过程的潜力，但仍需要专业程度的编程知识和持续互动以进行及时的完善。为了解决这些挑战，我们的关键想法是提出一个具有声明性、统一API的Python库，用于标准化列类型，通过简洁的API调用简化LLM的代码生成流程。我们首先提出了Dataprep.Clean，作为Dataprep库的一个组件，通过一行代码实现特定列类型的标准化，极大降低了复杂性。然后我们介绍了CleanAgen

    arXiv:2403.08291v1 Announce Type: cross  Abstract: Data standardization is a crucial part in data science life cycle. While tools like Pandas offer robust functionalities, their complexity and the manual effort required for customizing code to diverse column types pose significant challenges. Although large language models (LLMs) like ChatGPT have shown promise in automating this process through natural language understanding and code generation, it still demands expert-level programming knowledge and continuous interaction for prompt refinement. To solve these challenges, our key idea is to propose a Python library with declarative, unified APIs for standardizing column types, simplifying the code generation of LLM with concise API calls. We first propose Dataprep.Clean which is written as a component of the Dataprep Library, offers a significant reduction in complexity by enabling the standardization of specific column types with a single line of code. Then we introduce the CleanAgen
    
[^48]: 通过融合高度专业化语言模型同时掌握文本、代码和数学

    Mastering Text, Code and Math Simultaneously via Fusing Highly Specialized Language Models

    [https://arxiv.org/abs/2403.08281](https://arxiv.org/abs/2403.08281)

    通过融合高度专业化的语言、代码和数学模型，提出了一种名为UltraFuser的融合框架，引入了标记级别的门控机制，并设计了两阶段训练策略，以同时在三个领域取得高性能。

    

    自然语言、编程代码和数学符号的底层数据分布变化巨大，对于那些努力同时在三个领域实现高性能的大型语言模型（LLMs）提出了复杂挑战。本文提出了一种直接融合已经高度专业化模型的方法。所提出的融合框架UltraFuser包括三个已经在语言、编码和数学上得到充分训练的专家。引入了一个标记级别的门控机制来混合专家的输出。设计了一个伴随平衡采样的两阶段训练策略以确保稳定性。为了有效训练融合模型，我们进一步构建了一个

    arXiv:2403.08281v1 Announce Type: cross  Abstract: Underlying data distributions of natural language, programming code, and mathematical symbols vary vastly, presenting a complex challenge for large language models (LLMs) that strive to achieve high performance across all three domains simultaneously. Achieving a very high level of proficiency for an LLM within a specific domain often requires extensive training with relevant corpora, which is typically accompanied by a sacrifice in performance in other domains. In this paper, we propose to fuse models that are already highly-specialized directly. The proposed fusing framework, UltraFuser, consists of three distinct specialists that are already sufficiently trained on language, coding, and mathematics. A token-level gating mechanism is introduced to blend the specialists' outputs. A two-stage training strategy accompanied by balanced sampling is designed to ensure stability. To effectively train the fused model, we further construct a 
    
[^49]: LiqD：一种用于Tricky小容器的动态液位检测模型

    LiqD: A Dynamic Liquid Level Detection Model under Tricky Small Containers

    [https://arxiv.org/abs/2403.08273](https://arxiv.org/abs/2403.08273)

    提出了一种基于U^2-Net的容器动态液位检测模型，通过SAM模型生成初始数据集并结合SemiReward框架过滤伪标签图像，使用U^2-Net提取掩模图像并进行形态学处理，最终通过轻量级神经网络实现液位分类

    

    在日常生活和工业生产中，准确检测容器中液位的变化至关重要。传统的接触式测量方法存在一些限制，而新兴的非接触式图像处理技术显示出良好的应用前景。本文提出了一种基于U^2-Net的容器动态液位检测模型。该模型利用SAM模型生成初始数据集，然后通过SemiReward框架评估和过滤高质量伪标签图像，构建专属数据集。模型使用U^2-Net从数据集中提取容器的掩模图像，并利用形态学处理来补偿掩模缺陷。随后，模型计算同一位置相邻视频帧图像之间的灰度差异，通过设置差异阈值分割液位变化区域，最终使用轻量级神经网络对液位进行分类。

    arXiv:2403.08273v1 Announce Type: cross  Abstract: In daily life and industrial production, it is crucial to accurately detect changes in liquid level in containers. Traditional contact measurement methods have some limitations, while emerging non-contact image processing technology shows good application prospects. This paper proposes a container dynamic liquid level detection model based on U^2-Net. This model uses the SAM model to generate an initial data set, and then evaluates and filters out high-quality pseudo-label images through the SemiReward framework to build an exclusive data set. The model uses U^2-Net to extract mask images of containers from the data set, and uses morphological processing to compensate for mask defects. Subsequently, the model calculates the grayscale difference between adjacent video frame images at the same position, segments the liquid level change area by setting a difference threshold, and finally uses a lightweight neural network to classify the l
    
[^50]: 用于细粒度船舶分类的大规模视觉-语言模型的高效提示调整

    Efficient Prompt Tuning of Large Vision-Language Model for Fine-Grained Ship Classification

    [https://arxiv.org/abs/2403.08271](https://arxiv.org/abs/2403.08271)

    本研究使用大规模预训练的视觉-语言模型，提出了一种高效的提示调整方法，以增强未见船舶类别的分类准确性。

    

    遥感中的细粒度船舶分类 (RS-FGSC) 由于类别之间的高相似性以及有限的标记数据可用性而面临重大挑战，限制了传统监督分类方法的有效性。最近大规模预训练的视觉-语言模型 (VLMs) 在少样本或零样本学习中展现出令人印象深刻的能力，特别是在理解图像内容方面。本研究深入挖掘了VLMs的潜力，以提高未见船舶类别的分类准确性，在由于成本或隐私限制而数据受限的情况下具有重要意义。直接为RS-FGSC微调VLMs通常会遇到过拟合可见类的挑战，导致对未见类的泛化不佳，突出了区分复杂背景和捕捉独特船舶特征的困难。

    arXiv:2403.08271v1 Announce Type: cross  Abstract: Fine-grained ship classification in remote sensing (RS-FGSC) poses a significant challenge due to the high similarity between classes and the limited availability of labeled data, limiting the effectiveness of traditional supervised classification methods. Recent advancements in large pre-trained Vision-Language Models (VLMs) have demonstrated impressive capabilities in few-shot or zero-shot learning, particularly in understanding image content. This study delves into harnessing the potential of VLMs to enhance classification accuracy for unseen ship categories, which holds considerable significance in scenarios with restricted data due to cost or privacy constraints. Directly fine-tuning VLMs for RS-FGSC often encounters the challenge of overfitting the seen classes, resulting in suboptimal generalization to unseen classes, which highlights the difficulty in differentiating complex backgrounds and capturing distinct ship features. To 
    
[^51]: 随机搜索作为稀疏神经网络架构搜索的基准线

    Random Search as a Baseline for Sparse Neural Network Architecture Search

    [https://arxiv.org/abs/2403.08265](https://arxiv.org/abs/2403.08265)

    论文提出了一种评估方法和基于随机搜索的基线方法，用于发现高质量的稀疏神经网络配置，以解决当前缺乏可靠比较和可重现性的问题。

    

    稀疏神经网络在参数效率更高的情况下展现出与密集网络类似甚至更好的泛化性能，这促使许多工作学习、诱导或搜索性能高的稀疏网络。然而，尽管质量或效率的提升值得注意，但标准基线缺乏，因此妨碍了方法之间的可靠比较和可重现性。在这项工作中，我们提供了一种评估方法和一个简单的随机搜索基线方法，用于发现良好的稀疏配置。我们在过度参数化网络的节点空间上应用随机搜索，目标是找到在损失景观中位置更有优势的更好初始化的稀疏子网络。我们记录了不同稀疏程度下稀疏网络的训练后性能，并与它们的完全连接父网络以及随机稀疏配置进行比较。

    arXiv:2403.08265v1 Announce Type: cross  Abstract: Sparse neural networks have shown similar or better generalization performance than their dense counterparts while having higher parameter efficiency. This has motivated a number of works to learn, induce, or search for high performing sparse networks. While reports of quality or efficiency gains are impressive, standard baselines are lacking, therefore hindering having reliable comparability and reproducibility across methods. In this work, we provide an evaluation approach and a naive Random Search baseline method for finding good sparse configurations. We apply Random Search on the node space of an overparameterized network with the goal of finding better initialized sparse sub-networks that are positioned more advantageously in the loss landscape. We record sparse network post-training performances at various levels of sparsity and compare against both their fully connected parent networks and random sparse configurations at the sa
    
[^52]: GPT、本体论和CAABAC：以合规性、环境和属性为支柱的三方个性化访问控制模型

    GPT, Ontology, and CAABAC: A Tripartite Personalized Access Control Model Anchored by Compliance, Context and Attribute

    [https://arxiv.org/abs/2403.08264](https://arxiv.org/abs/2403.08264)

    GPT-Onto-CAABAC框架整合了GPT、本体论和CAABAC，动态解释策略并提供定制的访问控制解决方案，有效提高了EHR安全性，适应复杂的法规和情境要求。

    

    随着数字医疗的发展，电子健康记录（EHR）的安全性变得日益重要。本研究提出了GPT-Onto-CAABAC框架，将生成式预训练转换器（GPT）、医疗法律本体和上下文感知属性访问控制（CAABAC）集成，以增强EHR访问安全性。与传统模型不同，GPT-Onto-CAABAC动态解释策略，并适应不断变化的医疗和法律环境，提供定制的访问控制解决方案。通过经验评估，该框架被证明在通过将访问决策与复杂的监管和情境要求准确对齐而提高EHR安全性方面是有效的。研究结果表明，该框架在需要满足严格合规性和适应性标准的行业中具有更广泛的适用性。

    arXiv:2403.08264v1 Announce Type: cross  Abstract: As digital healthcare evolves, the security of electronic health records (EHR) becomes increasingly crucial. This study presents the GPT-Onto-CAABAC framework, integrating Generative Pretrained Transformer (GPT), medical-legal ontologies and Context-Aware Attribute-Based Access Control (CAABAC) to enhance EHR access security. Unlike traditional models, GPT-Onto-CAABAC dynamically interprets policies and adapts to changing healthcare and legal environments, offering customized access control solutions. Through empirical evaluation, this framework is shown to be effective in improving EHR security by accurately aligning access decisions with complex regulatory and situational requirements. The findings suggest its broader applicability in sectors where access control must meet stringent compliance and adaptability standards.
    
[^53]: CoroNetGAN：通过超网络控制GAN的剪枝

    CoroNetGAN: Controlled Pruning of GANs via Hypernetworks

    [https://arxiv.org/abs/2403.08261](https://arxiv.org/abs/2403.08261)

    CoroNetGAN通过超网络结合可微剪枝方法，提出了一种压缩GAN的方法，具有可控的压缩优势并显著减少训练时间

    

    生成对抗网络（GANs）已被证明在许多生成计算机视觉应用中表现出卓越性能，并被广泛使用。然而，在资源受限的边缘设备上部署GAN的需求前所未有，这仍然是一个挑战，因为在生成过程中涉及了大量参数。这导致关注点集中在压缩GAN领域。大多数现有作品使用知识蒸馏，但存在着需要教师依赖的开销。此外，在这些方法中没有能力控制压缩程度。因此，我们提出了使用超网络通过可微剪枝方法压缩GAN的CoroNet-GAN。所提出的方法在训练过程中提供了可控制的压缩优势，并通过实验表现出显著减少训练时间的特点。在各种条件GAN架构上进行了实验。

    arXiv:2403.08261v1 Announce Type: cross  Abstract: Generative Adversarial Networks (GANs) have proven to exhibit remarkable performance and are widely used across many generative computer vision applications. However, the unprecedented demand for the deployment of GANs on resource-constrained edge devices still poses a challenge due to huge number of parameters involved in the generation process. This has led to focused attention on the area of compressing GANs. Most of the existing works use knowledge distillation with the overhead of teacher dependency. Moreover, there is no ability to control the degree of compression in these methods. Hence, we propose CoroNet-GAN for compressing GAN using the combined strength of differentiable pruning method via hypernetworks. The proposed method provides the advantage of performing controllable compression while training along with reducing training time by a substantial factor. Experiments have been done on various conditional GAN architectures
    
[^54]: 基于大型语言模型的Agent社会中社会规范的出现

    Emergence of Social Norms in Large Language Model-based Agent Societies

    [https://arxiv.org/abs/2403.08251](https://arxiv.org/abs/2403.08251)

    提出了第一个赋予大型语言模型Agent群体内社会规范出现的生成式Agent架构CRSEC，实验证明其能力。

    

    社会规范的出现吸引了社会科学、认知科学以及人工智能等各个领域的广泛关注。本文提出了第一个赋予大型语言模型Agent群体内社会规范出现的生成式Agent架构CRSEC。我们的架构包括四个模块：Creation & Representation、Spreading、Evaluation和Compliance。我们的架构处理了几个关键方面的紧急过程：(i)社会规范的来源，(ii)它们如何被正式表示，(iii)它们如何通过Agent的交流和观察传播，(iv)如何通过合理检查进行检查并在长期内进行综合，(v)如何被纳入Agent的计划和行动中。我们在Smallville沙盒游戏环境中进行的实验展示了我们的架构的能力。

    arXiv:2403.08251v1 Announce Type: cross  Abstract: The emergence of social norms has attracted much interest in a wide array of disciplines, ranging from social science and cognitive science to artificial intelligence. In this paper, we propose the first generative agent architecture that empowers the emergence of social norms within a population of large language model-based agents. Our architecture, named CRSEC, consists of four modules: Creation & Representation, Spreading, Evaluation, and Compliance. Our architecture addresses several important aspects of the emergent processes all in one: (i) where social norms come from, (ii) how they are formally represented, (iii) how they spread through agents' communications and observations, (iv) how they are examined with a sanity check and synthesized in the long term, and (v) how they are incorporated into agents' planning and actions. Our experiments deployed in the Smallville sandbox game environment demonstrate the capability of our ar
    
[^55]: 一种基于特征学习的仿生神经网络用于多机器人系统实时无碰救援的创新方法

    A Novel Feature Learning-based Bio-inspired Neural Network for Real-time Collision-free Rescue of Multi-Robot Systems

    [https://arxiv.org/abs/2403.08238](https://arxiv.org/abs/2403.08238)

    该论文提出了一种基于特征学习的仿生神经网络方法，用于在多机器人系统中实时生成无碰救援路径，在复杂环境中快速响应环境变化，提高了救援效率。

    

    自然灾害和城市事故推动了对救援机器人的需求，以提供更安全、更快速、更高效的救援路径。本文提出了一种基于特征学习的仿生神经网络（FLBBINN），用于在复杂和动态环境中快速生成启发式救援路径，因为传统方法通常无法提供对突发环境变化实时响应满意的解决方案。神经动力学模型结合了特征学习方法，可以利用环境信息改进路径规划策略。通过机器人姿势和神经活动的动态景观产生任务分配和无碰救援轨迹。使用双通道尺度过滤器、神经活动通道和二次距离融合来提取和过滤特征神经元。特征学习过程完成后，基于神经动力学的特征矩阵被生成。

    arXiv:2403.08238v1 Announce Type: cross  Abstract: Natural disasters and urban accidents drive the demand for rescue robots to provide safer, faster, and more efficient rescue trajectories. In this paper, a feature learning-based bio-inspired neural network (FLBBINN) is proposed to quickly generate a heuristic rescue path in complex and dynamic environments, as traditional approaches usually cannot provide a satisfactory solution to real-time responses to sudden environmental changes. The neurodynamic model is incorporated into the feature learning method that can use environmental information to improve path planning strategies. Task assignment and collision-free rescue trajectory are generated through robot poses and the dynamic landscape of neural activity. A dual-channel scale filter, a neural activity channel, and a secondary distance fusion are employed to extract and filter feature neurons. After completion of the feature learning process, a neurodynamics-based feature matrix is
    
[^56]: 具有对抗性专家的鲁棒决策聚合

    Robust Decision Aggregation with Adversarial Experts

    [https://arxiv.org/abs/2403.08222](https://arxiv.org/abs/2403.08222)

    论文考虑了在既有真实专家又有对抗性专家的情况下的二元决策聚合问题，提出了设计鲁棒聚合器以最小化遗憾的方法，并证明了当真实专家是对称的且对抗性专家不太多时，截尾均值是最优的。

    

    我们考虑了在既有真实专家又有对抗性专家的情况下的二元决策聚合问题。真实专家将会如实报告他们的私人信号，并获得适当的激励，而对抗性专家可以任意报告。决策者需要设计一个鲁棒的聚合器，根据专家的报告来预测世界的真实状态。决策者不了解具体的信息结构，即信号、状态以及对抗性专家的策略的联合分布。我们希望找到在最坏信息结构下最小化遗憾的最优聚合器。遗憾被定义为聚合器和一个基准之间的期望损失差，该基准根据联合分布和真实专家的报告做出最优决策。我们证明了当真实专家是对称的且对抗性专家不太多时，截尾均值是最优的。

    arXiv:2403.08222v1 Announce Type: cross  Abstract: We consider a binary decision aggregation problem in the presence of both truthful and adversarial experts. The truthful experts will report their private signals truthfully with proper incentive, while the adversarial experts can report arbitrarily. The decision maker needs to design a robust aggregator to forecast the true state of the world based on the reports of experts. The decision maker does not know the specific information structure, which is a joint distribution of signals, states, and strategies of adversarial experts. We want to find the optimal aggregator minimizing regret under the worst information structure. The regret is defined by the difference in expected loss between the aggregator and a benchmark who makes the optimal decision given the joint distribution and reports of truthful experts.   We prove that when the truthful experts are symmetric and adversarial experts are not too numerous, the truncated mean is opt
    
[^57]: LIX：将空间几何先验知识隐式注入视觉语义分割，用于自动驾驶

    LIX: Implicitly Infusing Spatial Geometric Prior Knowledge into Visual Semantic Segmentation for Autonomous Driving

    [https://arxiv.org/abs/2403.08215](https://arxiv.org/abs/2403.08215)

    将双编码器教师模型获得的空间几何先验知识隐式注入单编码器学生模型，通过新的logit蒸馏和特征蒸馏方法，解决自动驾驶中的视觉语义分割问题。

    

    尽管数据融合网络在视觉语义分割中表现出色，但当缺乏空间几何数据时，双编码器变得无效。将双编码器教师模型获得的空间几何先验知识隐式注入单编码器学生模型是一个实用但不太探索的研究领域。本文深入探讨了这个主题，并采用知识蒸馏方法来解决这个问题。我们引入了Learning to Infuse "X" (LIX) 框架，在logit蒸馏和特征蒸馏方面进行了新颖贡献。我们提出了一个数学证明，强调在解耦知识蒸馏中使用单一固定权重的局限性，并引入了logit智能动态权重控制器作为解决这个问题的方法。此外，我们开发了一种自适应重新校准的特征蒸馏算法，包括两种技术。

    arXiv:2403.08215v1 Announce Type: cross  Abstract: Despite the impressive performance achieved by data-fusion networks with duplex encoders for visual semantic segmentation, they become ineffective when spatial geometric data are not available. Implicitly infusing the spatial geometric prior knowledge acquired by a duplex-encoder teacher model into a single-encoder student model is a practical, albeit less explored research avenue. This paper delves into this topic and resorts to knowledge distillation approaches to address this problem. We introduce the Learning to Infuse "X" (LIX) framework, with novel contributions in both logit distillation and feature distillation aspects. We present a mathematical proof that underscores the limitation of using a single fixed weight in decoupled knowledge distillation and introduce a logit-wise dynamic weight controller as a solution to this issue. Furthermore, we develop an adaptively-recalibrated feature distillation algorithm, including two tec
    
[^58]: P2LHAP：基于可穿戴传感器的人类活动识别、分割和预测的Patch-to-Label Seq2Seq Transformer

    P2LHAP:Wearable sensor-based human activity recognition, segmentation and forecast through Patch-to-Label Seq2Seq Transformer

    [https://arxiv.org/abs/2403.08214](https://arxiv.org/abs/2403.08214)

    P2LHAP提出了一种新颖的Patch-to-Label Seq2Seq框架，可以在一个高效的单一任务模型中同时实现人类活动的分割、识别和预测

    

    传统深度学习方法很难同时从传感器数据中分割、识别和预测人类活动，限制了它们在医疗保健和辅助生活等领域的实用性，而这些领域对于实时理解正在进行和即将发生的活动至关重要。本文提出了P2LHAP，一种新颖的Patch-to-Label Seq2Seq框架，可以在一个高效的单一任务模型中解决这三个任务。P2LHAP将传感器数据流划分为一系列“补丁”，作为输入标记，并输出一系列包括预测的未来活动在内的补丁级活动标签。提出了一种基于周围补丁标签的独特平滑技术，可准确识别活动边界。此外，P2LHAP通过传感器信号通道独立的Transformer编码器和解码器学习补丁级表示。所有通道在所有序列上共享嵌入和Transformer权重。

    arXiv:2403.08214v1 Announce Type: cross  Abstract: Traditional deep learning methods struggle to simultaneously segment, recognize, and forecast human activities from sensor data. This limits their usefulness in many fields such as healthcare and assisted living, where real-time understanding of ongoing and upcoming activities is crucial. This paper introduces P2LHAP, a novel Patch-to-Label Seq2Seq framework that tackles all three tasks in a efficient single-task model. P2LHAP divides sensor data streams into a sequence of "patches", served as input tokens, and outputs a sequence of patch-level activity labels including the predicted future activities. A unique smoothing technique based on surrounding patch labels, is proposed to identify activity boundaries accurately. Additionally, P2LHAP learns patch-level representation by sensor signal channel-independent Transformer encoders and decoders. All channels share embedding and Transformer weights across all sequences. Evaluated on thre
    
[^59]: 大型语言模型是对比推理者

    Large Language Models are Contrastive Reasoners

    [https://arxiv.org/abs/2403.08211](https://arxiv.org/abs/2403.08211)

    对比提示方法显著提高大型语言模型进行复杂推理的能力，不仅在算术、常识和符号推理任务上表现优良，还可以与现有提示方法整合，实现更好的性能。

    

    提示方法在增强预训练大型语言模型（LLMs）的能力方面发挥着至关重要的作用。我们探讨了对比提示（CP）如何显著提高大型语言模型执行复杂推理的能力。我们通过简单地在LLMs提供答案之前添加"让我们给出一个正确答案和一个错误答案"来演示LLMs是体面的对比推理者。对两个大型语言模型的实验表明，零迁移对比提示提升了在一系列算术、常识和符号推理任务上的表现，而不需要手工制作的少量迁移示例，比如使用最先进的GPT-4模型，提高了在GSM8K上的准确率从35.9%到88.8%以及AQUA-RAT从41.3%到62.2%。我们的方法不仅在大多数算术和常识推理任务中胜过零迁移CoT和少量迁移CoT，还可以与现有的提示方法无缝整合，从而实现改进或者竞争

    arXiv:2403.08211v1 Announce Type: cross  Abstract: Prompting methods play a crucial role in enhancing the capabilities of pre-trained large language models (LLMs). We explore how contrastive prompting (CP) significantly improves the ability of large language models to perform complex reasoning. We demonstrate that LLMs are decent contrastive reasoners by simply adding "Let's give a correct and a wrong answer." before LLMs provide answers. Experiments on two large language models show that zero-shot contrastive prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks without any hand-crafted few-shot examples, such as increasing the accuracy on GSM8K from 35.9% to 88.8% and AQUA-RAT from 41.3% to 62.2% with the state-of-the-art GPT-4 model. Our method not only surpasses zero-shot CoT and few-shot CoT in most arithmetic and commonsense reasoning tasks but also can seamlessly integrate with existing prompting methods, resulting in improved or comp
    
[^60]: 深度子模逆点网络

    Deep Submodular Peripteral Network

    [https://arxiv.org/abs/2403.08199](https://arxiv.org/abs/2403.08199)

    引入了深度子模逆点网络（DSPNs），并提出了一种使用对比学习启发的GPC-ready策略进行训练的方法，以应对子模函数学习中的两大挑战。

    

    子模函数对各种应用至关重要，但通常缺乏实用的学习方法来获取它们。本文引入了深度子模逆点网络（DSPNs），一种新颖的子模函数参数化族，并提出了使用对比学习启发的GPC-ready策略对其进行训练的方法，以连接并解决上述两个挑战。

    arXiv:2403.08199v1 Announce Type: cross  Abstract: Submodular functions, crucial for various applications, often lack practical learning methods for their acquisition. Seemingly unrelated, learning a scaling from oracles offering graded pairwise preferences (GPC) is underexplored, despite a rich history in psychometrics. In this paper, we introduce deep submodular peripteral networks (DSPNs), a novel parametric family of submodular functions, and methods for their training using a contrastive-learning inspired GPC-ready strategy to connect and then tackle both of the above challenges. We introduce newly devised GPC-style "peripteral" loss which leverages numerically graded relationships between pairs of objects (sets in our case). Unlike traditional contrastive learning, our method utilizes graded comparisons, extracting more nuanced information than just binary-outcome comparisons, and contrasts sets of any size (not just two). We also define a novel suite of automatic sampling strate
    
[^61]: PAGE: 具有面向过去无关生成回放的领域增量适应策略

    PAGE: Domain-Incremental Adaptation with Past-Agnostic Generative Replay for Smart Healthcare

    [https://arxiv.org/abs/2403.08197](https://arxiv.org/abs/2403.08197)

    PAGE提出了一种面向智能医疗的领域增量适应策略，能够在不依赖于保留数据或信息的情况下实现生成回放，有效平衡领域适应和知识保留，并结合扩展的归纳确认预测方法提供可解释的疾病检测预测。

    

    我们提出了PAGE，一种具有面向过去无关生成回放的领域增量适应策略，用于智能医疗。PAGE能够实现生成回放，而无需保留来自先前领域的任何数据或信息。在适应新领域时，它利用来自新分布和当前模型的真实数据来生成合成数据，以保留先前领域的学习知识。通过在训练过程中重新播放合成数据和新实际数据，PAGE在领域适应和知识保留之间取得良好平衡。此外，我们将扩展的归纳确认预测（EICP）方法整合到PAGE中，为每个检测结果生成置信度分数和可信度值。这使得预测结果具有可解释性，并为智能医疗应用中的疾病检测提供统计保证。我们展示了PAGE在领域增量疾病检测中的有效性。

    arXiv:2403.08197v1 Announce Type: cross  Abstract: We propose PAGE, a domain-incremental adaptation strategy with past-agnostic generative replay for smart healthcare. PAGE enables generative replay without the aid of any preserved data or information from prior domains. When adapting to a new domain, it exploits real data from the new distribution and the current model to generate synthetic data that retain the learned knowledge of previous domains. By replaying the synthetic data with the new real data during training, PAGE achieves a good balance between domain adaptation and knowledge retention. In addition, we incorporate an extended inductive conformal prediction (EICP) method into PAGE to produce a confidence score and a credibility value for each detection result. This makes the predictions interpretable and provides statistical guarantees for disease detection in smart healthcare applications. We demonstrate PAGE's effectiveness in domain-incremental disease detection with thr
    
[^62]: 重新思考事实验证的损失函数

    Rethinking Loss Functions for Fact Verification

    [https://arxiv.org/abs/2403.08174](https://arxiv.org/abs/2403.08174)

    提出了专为FEVER任务定制的两种任务特定目标函数，相比标准交叉熵在事实验证中表现更好，并通过简单类别加权进一步提高性能。

    

    我们研究了FEVER共享任务中事实验证的损失函数。虽然交叉熵损失是训练判决预测器的标准目标，但它未能捕捉到FEVER判决类别之间的异质性。本文提出了两个针对FEVER的特定任务目标。实验结果证实，所提出的目标函数优于标准的交叉熵。当这些目标与简单的类别加权相结合时，性能进一步提高，有效地克服了训练数据中的不平衡。源代码可在https://github.com/yuta-mukobara/RLF-KGAT 上找到。

    arXiv:2403.08174v1 Announce Type: cross  Abstract: We explore loss functions for fact verification in the FEVER shared task. While the cross-entropy loss is a standard objective for training verdict predictors, it fails to capture the heterogeneity among the FEVER verdict classes. In this paper, we develop two task-specific objectives tailored to FEVER. Experimental results confirm that the proposed objective functions outperform the standard cross-entropy. Performance is further improved when these objectives are combined with simple class weighting, which effectively overcomes the imbalance in the training data. The souce code is available at https://github.com/yuta-mukobara/RLF-KGAT
    
[^63]: 基于地标的人脸自监督学习用于人脸识别

    LAFS: Landmark-based Facial Self-supervised Learning for Face Recognition

    [https://arxiv.org/abs/2403.08161](https://arxiv.org/abs/2403.08161)

    本研究提出了一种基于地标的人脸自监督学习方法，通过利用面部地标定位的补丁来学习更适合于人脸识别的关键表示。

    

    在这项工作中，我们专注于学习可以适应训练有效人脸识别模型的人脸表示，特别是在缺乏标签的情况下。与现有的带标签人脸数据集相比，现实世界中存在着一个数量上大得多的未标记人脸。我们通过自监督预训练探索这些未标记面部图像的学习策略，以转移广义人脸识别性能。此外，受到最近的一个发现的启发，即面部显著区域对于人脸识别至关重要，与利用随机裁剪的图像块进行预训练增广相反，我们利用通过提取的面部地标定位的补丁。这使得我们的方法 - 即基于地标的人脸自监督学习(LAndmark-based Facial Self-supervised learning LAFS)能够学习更适合人脸识别的关键表示。我们还融入了两种特定于地标的增广，引入了更多

    arXiv:2403.08161v1 Announce Type: cross  Abstract: In this work we focus on learning facial representations that can be adapted to train effective face recognition models, particularly in the absence of labels. Firstly, compared with existing labelled face datasets, a vastly larger magnitude of unlabeled faces exists in the real world. We explore the learning strategy of these unlabeled facial images through self-supervised pretraining to transfer generalized face recognition performance. Moreover, motivated by one recent finding, that is, the face saliency area is critical for face recognition, in contrast to utilizing random cropped blocks of images for constructing augmentations in pretraining, we utilize patches localized by extracted facial landmarks. This enables our method - namely LAndmark-based Facial Self-supervised learning LAFS), to learn key representation that is more critical for face recognition. We also incorporate two landmark-specific augmentations which introduce mo
    
[^64]: 在广义Needle问题上的随机局部搜索运行时间

    The Runtime of Random Local Search on the Generalized Needle Problem

    [https://arxiv.org/abs/2403.08153](https://arxiv.org/abs/2403.08153)

    本研究在广义Needle问题上研究了随机局部搜索的运行时间，提出了一种新的确定参数$k$影响的下限方法，并改进了现有的预期运行时间上限。

    

    在最近的工作中，C. Doerr和Krejca（2023年《进化计算交易》）证明了随机局部搜索启发式算法在广义Needle函数上的预期运行时间的上限。基于这些上限，他们以一种不完全严谨的方式推断了针半径$k$对运行时间的巨大影响。在这篇简短的文章中，我们添加了确定参数$k$对运行时间影响所需的缺失下限。为此，我们导出了一个对预期运行时间的精确描述，这也显著改进了C. Doerr和Krejca给出的上限。我们还描述了预期运行时间的渐近估计。

    arXiv:2403.08153v1 Announce Type: cross  Abstract: In their recent work, C. Doerr and Krejca (Transactions on Evolutionary Computation, 2023) proved upper bounds on the expected runtime of the randomized local search heuristic on generalized Needle functions. Based on these upper bounds, they deduce in a not fully rigorous manner a drastic influence of the needle radius $k$ on the runtime.   In this short article, we add the missing lower bound necessary to determine the influence of parameter $k$ on the runtime. To this aim, we derive an exact description of the expected runtime, which also significantly improves the upper bound given by C. Doerr and Krejca. We also describe asymptotic estimates of the expected runtime.
    
[^65]: 衡量深度神经网络的能耗和效率：实证分析与设计建议

    Measuring the Energy Consumption and Efficiency of Deep Neural Networks: An Empirical Analysis and Design Recommendations

    [https://arxiv.org/abs/2403.08151](https://arxiv.org/abs/2403.08151)

    这项研究针对大规模神经网络不断增长的能耗问题进行了实证分析，提出了一个考虑网络尺寸、计算和内存层次结构的能耗模型。

    

    针对大规模神经网络日益增长的能耗问题（所谓的“红色AI”趋势），本研究通过节点级瓦特表测量了训练各种全连接神经网络架构的实际能耗。我们介绍了BUTTER-E数据集，这是BUTTER实证深度学习数据集的一个扩充，包含了来自63,527个单独实验运行的能耗和性能数据，涵盖了30,582个不同的配置：13个数据集、20个大小（可训练参数数量）、8个网络“形状”和14个深度，以及在CPU和GPU硬件上使用节点级瓦特表收集的数据。这个数据集揭示了数据集大小、网络结构和能耗之间复杂的关系，并突出了缓存效应的影响。我们提出了一个简单而有效的能耗模型，考虑了网络大小、计算和内存层次结构。我们的分析还揭示了

    arXiv:2403.08151v1 Announce Type: cross  Abstract: Addressing the so-called ``Red-AI'' trend of rising energy consumption by large-scale neural networks, this study investigates the actual energy consumption, as measured by node-level watt-meters, of training various fully connected neural network architectures. We introduce the BUTTER-E dataset, an augmentation to the BUTTER Empirical Deep Learning dataset, containing energy consumption and performance data from 63,527 individual experimental runs spanning 30,582 distinct configurations: 13 datasets, 20 sizes (number of trainable parameters), 8 network ``shapes'', and 14 depths on both CPU and GPU hardware collected using node-level watt-meters. This dataset reveals the complex relationship between dataset size, network structure, and energy use, and highlights the impact of cache effects. We propose a straightforward and effective energy model that accounts for network size, computing, and memory hierarchy. Our analysis also uncovers
    
[^66]: 从论文到卡片：利用生成人工智能改变设计启示

    From Paper to Card: Transforming Design Implications with Generative AI

    [https://arxiv.org/abs/2403.08137](https://arxiv.org/abs/2403.08137)

    使用生成人工智能构建系统，从学术论文中创建设计卡片，帮助设计师更好理解设计启示并提高沟通效率。

    

    交流设计启示在人机交互领域中发表学术论文时很常见，然而这些论文很少被设计师们阅读和使用。一种解决方案是使用设计卡片作为一种翻译资源，以更易消化和获取的方式传达论文中的有价值见解，以协助设计过程。然而，创建设计卡片可能耗时，而作者可能缺乏制作卡片的资源和知识。通过迭代设计过程，我们构建了一个系统，使用LLM和文本转图像模型从学术论文中帮助创建设计卡片。我们对设计师（N=21）和所选论文的作者（N=12）进行的评估显示，设计师认为我们设计卡片中的设计启示比阅读原始论文文本更具启发性和生成性，而作者则认为我们的系统是传达他们设计启示的有效方式。

    arXiv:2403.08137v1 Announce Type: cross  Abstract: Communicating design implications is common within the HCI community when publishing academic papers, yet these papers are rarely read and used by designers. One solution is to use design cards as a form of translational resource that communicates valuable insights from papers in a more digestible and accessible format to assist in design processes. However, creating design cards can be time-consuming, and authors may lack the resources/know-how to produce cards. Through an iterative design process, we built a system that helps create design cards from academic papers using an LLM and text-to-image model. Our evaluation with designers (N=21) and authors of selected papers (N=12) revealed that designers perceived the design implications from our design cards as more inspiring and generative, compared to reading original paper texts, and the authors viewed our system as an effective way of communicating their design implications. We also
    
[^67]: RoboCertProb：概率RoboChart模型的属性规范

    RoboCertProb: Property Specification for Probabilistic RoboChart Models

    [https://arxiv.org/abs/2403.08136](https://arxiv.org/abs/2403.08136)

    本研究提出了RoboCertProb，用于指定在RoboChart中建模的概率机器人系统的定量属性，并通过基于PCTL*的语义和马尔可夫语义（DTMCs和MDPs），支持对这些属性进行解释和验证。

    

    RoboChart是RoboStar框架中的核心符号，将现代建模和形式化验证技术引入软件工程领域的机器人技术中。它是一种面向机器人的定时和概率特定领域语言，提供类似UML的架构和状态机建模。本文介绍了RoboCertProb，用于指定在RoboChart中建模的概率机器人系统的定量属性。RoboCertProb的语义基于PCTL*。为了在RoboChart模型上解释RoboCertProb，我们为RoboChart提供了一个马尔可夫语义（DTMC和MDPs），该语义来自于RoboChart到PRISM语言的现有转换语义。除了属性规范，RoboCertProb还允许我们在RoboChart模型中配置松散常量和未指定的函数和操作。它使我们能够设置环境输入以验证在概率模型检查器中不直接支持的反应式概率系统。

    arXiv:2403.08136v1 Announce Type: cross  Abstract: RoboChart is a core notation in the RoboStar framework which brings modern modelling and formal verification technologies into software engineering for robotics. It is a timed and probabilistic domain-specific language for robotics and provides a UML-like architectural and state machine modelling. This work presents RoboCertProb for specifying quantitative properties of probabilistic robotic systems modelled in RoboChart. RoboCertProb's semantics is based on PCTL*. To interpret RoboCertProb over RoboChart models, we give a Markov semantics (DTMCs and MDPs) to RoboChart, derived from its existing transformation semantics to the PRISM language. In addition to property specification, RoboCertProb also entitles us to configure loose constants and unspecified functions and operations in RoboChart models. It allows us to set up environmental inputs to verify reactive probabilistic systems not directly supported in probabilistic model checker
    
[^68]: 物理启发的深度学习抗混叠框架在高效信道状态反馈中的应用

    Physics-Inspired Deep Learning Anti-Aliasing Framework in Efficient Channel State Feedback

    [https://arxiv.org/abs/2403.08133](https://arxiv.org/abs/2403.08133)

    本文引入了一种新的CSI上采样框架，利用物理原理和学习方法，有效解决了在大规模MIMO FDD系统中由欠采样导致的混叠效应问题。

    

    获取基站处的下行信道状态信息（CSI）对于优化大规模MIMO FDD系统性能至关重要。尽管深度学习架构成功地促进了UE端的CSI反馈和gNB端的恢复，但在CSI反馈之前出现的欠采样问题经常被忽视。本文引入了一种新的CSI上采样框架，作为处理由欠采样引起的间隙的后处理解决方案。利用离散傅立叶变换移位定理和多径互易性的物理原理，我们的框架有效地利用上行CSI来减轻混叠效应。我们进一步发展了一种基于学习的方法。

    arXiv:2403.08133v1 Announce Type: cross  Abstract: Acquiring downlink channel state information (CSI) at the base station is vital for optimizing performance in massive Multiple input multiple output (MIMO) Frequency-Division Duplexing (FDD) systems. While deep learning architectures have been successful in facilitating UE-side CSI feedback and gNB-side recovery, the undersampling issue prior to CSI feedback is often overlooked. This issue, which arises from low density pilot placement in current standards, results in significant aliasing effects in outdoor channels and consequently limits CSI recovery performance. To this end, this work introduces a new CSI upsampling framework at the gNB as a post-processing solution to address the gaps caused by undersampling. Leveraging the physical principles of discrete Fourier transform shifting theorem and multipath reciprocity, our framework effectively uses uplink CSI to mitigate aliasing effects. We further develop a learning-based method th
    
[^69]: 在机器特征和标签的遗忘中朝向独立准则

    Towards Independence Criterion in Machine Unlearning of Features and Labels

    [https://arxiv.org/abs/2403.08124](https://arxiv.org/abs/2403.08124)

    提出了一种利用影响函数和分布独立原则的新方法，以应对机器遗忘中非均匀特征和标签删除的挑战，保护隐私同时保持模型性能和适应性

    

    这项工作深入探讨了面临分布转移时的机器遗忘复杂性，特别关注非均匀特征和标签删除所带来的挑战。随着GDPR等法规强调数据隐私和被遗忘的权利，机器学习模型面临着遗忘敏感信息而不损害其完整性或性能的艰巨任务。我们的研究引入了一种利用影响函数和分布独立原则来应对这些挑战的新方法。通过提出一个全面的机器遗忘框架，我们旨在确保隐私保护，同时在不同分布下保持模型性能和适应性。我们的方法不仅有助于高效地删除数据，还动态调整模型以保持其泛化能力。通过大量实验，我们证明了

    arXiv:2403.08124v1 Announce Type: cross  Abstract: This work delves into the complexities of machine unlearning in the face of distributional shifts, particularly focusing on the challenges posed by non-uniform feature and label removal. With the advent of regulations like the GDPR emphasizing data privacy and the right to be forgotten, machine learning models face the daunting task of unlearning sensitive information without compromising their integrity or performance. Our research introduces a novel approach that leverages influence functions and principles of distributional independence to address these challenges. By proposing a comprehensive framework for machine unlearning, we aim to ensure privacy protection while maintaining model performance and adaptability across varying distributions. Our method not only facilitates efficient data removal but also dynamically adjusts the model to preserve its generalization capabilities. Through extensive experimentation, we demonstrate the
    
[^70]: 研究构建多保真度代理模型时有害数据来源的特征

    Characterising harmful data sources when constructing multi-fidelity surrogate models

    [https://arxiv.org/abs/2403.08118](https://arxiv.org/abs/2403.08118)

    研究指出在构建多保真度代理模型时，有害数据源的特征化有助于指导从业者在选择时何时忽略某个数据源。

    

    近年来，当应用于工业设计问题的建模和优化中，代理建模技术受到越来越多的关注。当评估特定设计的性能成本很高时，通过构建一个模型以代替可用的高成本来源来查询可以降低总成本。构建这些模型有时可以利用其他便宜且不太准确的信息源。然而，这些信息源的存在引发了一个问题，即在构建模型时应该使用哪些信息源。最近的研究尝试对有害数据源进行特征化，以指导从业者何时忽略某个信息源。

    arXiv:2403.08118v1 Announce Type: cross  Abstract: Surrogate modelling techniques have seen growing attention in recent years when applied to both modelling and optimisation of industrial design problems. These techniques are highly relevant when assessing the performance of a particular design carries a high cost, as the overall cost can be mitigated via the construction of a model to be queried in lieu of the available high-cost source. The construction of these models can sometimes employ other sources of information which are both cheaper and less accurate. The existence of these sources however poses the question of which sources should be used when constructing a model. Recent studies have attempted to characterise harmful data sources to guide practitioners in choosing when to ignore a certain source. These studies have done so in a synthetic setting, characterising sources using a large amount of data that is not available in practice. Some of these studies have also been shown
    
[^71]: 法律约束但不公平？朝向评估隐私政策公平性的方向

    Legally Binding but Unfair? Towards Assessing Fairness of Privacy Policies

    [https://arxiv.org/abs/2403.08115](https://arxiv.org/abs/2403.08115)

    本研究旨在评估隐私政策的公平性，通过从法律来源和公平性研究中确定信息公正性、表现公正性和道德/伦理与隐私政策的关系，并提出自动评估政策的选项。

    

    隐私政策应当告知数据主体其数据保护权利，解释数据控制者的数据管理实践，并使保留期限或数据转移给第三方等事实透明化。隐私政策只有在数据主体正确感知、解释、理解和信任时才能实现其目的。其中，这要求隐私政策以公平的方式编写，例如不使用极端的术语，不需要特定的教育程度，或不假设特定的社会背景。在这份进行中的工作论文中，我们概述了我们评估隐私政策公平性的方法。为此，我们从基本法律来源和公平性研究中确定信息公正性、表现公正性和道德/伦理与隐私政策的关系。我们提出了自动评估政策的选项。

    arXiv:2403.08115v1 Announce Type: cross  Abstract: Privacy policies are expected to inform data subjects about their data protection rights. They should explain the data controller's data management practices, and make facts such as retention periods or data transfers to third parties transparent. Privacy policies only fulfill their purpose, if they are correctly perceived, interpreted, understood, and trusted by the data subject. Amongst others, this requires that a privacy policy is written in a fair way, e.g., it does not use polarizing terms, does not require a certain education, or does not assume a particular social background. In this work-in-progress paper, we outline our approach to assessing fairness in privacy policies. To this end, we identify from fundamental legal sources and fairness research, how the dimensions informational fairness, representational fairness and ethics/morality are related to privacy policies. We propose options to automatically assess policies in the
    
[^72]: 人类中心设计的AI辅助因果路径图

    AI-Assisted Causal Pathway Diagram for Human-Centered Design

    [https://arxiv.org/abs/2403.08111](https://arxiv.org/abs/2403.08111)

    本文研究了将因果路径图整合到人类中心设计中的方法，开发了专用插件用于在线协作白板平台，通过用户研究发现其支持设计过程中的分散和集中阶段，减少设计师的认知负荷并增加创造力。

    

    本文探讨了将因果路径图（CPD）整合到人类中心设计（HCD）中，研究这些图如何增强设计过程的早期阶段。开发了专用的CPD插件，用于在线协作白板平台Miro，以简化图的创建并提供实时的AI驱动指导。通过与设计师（N=20）的用户研究，我们发现CPD的分支和其对因果关系的强调在设计过程的分散和集中阶段都得到了支持。CPD也可以促进利益相关者之间的沟通。此外，我们发现我们的插件显著减少了设计师的认知负荷，并在头脑风暴过程中增加了他们的创造力，突显了AI辅助工具在支持创造性工作和基于证据的设计中的影响。

    arXiv:2403.08111v1 Announce Type: cross  Abstract: This paper explores the integration of causal pathway diagrams (CPD) into human-centered design (HCD), investigating how these diagrams can enhance the early stages of the design process. A dedicated CPD plugin for the online collaborative whiteboard platform Miro was developed to streamline diagram creation and offer real-time AI-driven guidance. Through a user study with designers (N=20), we found that CPD's branching and its emphasis on causal connections supported both divergent and convergent processes during design. CPD can also facilitate communication among stakeholders. Additionally, we found our plugin significantly reduces designers' cognitive workload and increases their creativity during brainstorming, highlighting the implications of AI-assisted tools in supporting creative work and evidence-based designs.
    
[^73]: 利用Context-Reverso数据使用Transformer模型生成具有上下文清晰度的句子

    Contextual Clarity: Generating Sentences with Transformer Models using Context-Reverso Data

    [https://arxiv.org/abs/2403.08103](https://arxiv.org/abs/2403.08103)

    使用Transformer模型和Context-Reverso数据生成具有上下文清晰度的句子

    

    在信息丰富的时代，提供与上下文相关且简洁的信息对用户至关重要。关键词上下文(KIC)生成是在一些应用中扮演至关重要角色的任务，比如搜索引擎、个人助手和内容摘要。本文提出了一种利用T5 transformer模型生成给定关键词的明确且简洁句子上下文的新方法，利用了从Context-Reverso API获取的数据。

    arXiv:2403.08103v1 Announce Type: cross  Abstract: In the age of information abundance, the ability to provide users with contextually relevant and concise information is crucial. Keyword in Context (KIC) generation is a task that plays a vital role in and generation applications, such as search engines, personal assistants, and content summarization. In this paper, we present a novel approach to generating unambiguous and brief sentence-contexts for given keywords using the T5 transformer model, leveraging data obtained from the Context-Reverso API. The code is available at https://github.com/Rusamus/word2context/tree/main .
    
[^74]: 具有自注意力机制的下一个标记预测的力学

    Mechanics of Next Token Prediction with Self-Attention

    [https://arxiv.org/abs/2403.08081](https://arxiv.org/abs/2403.08081)

    通过梯度下降训练自注意力学习到一个自动机，在下一个标记预测中生成标记的两个不同步骤是：硬检索和软组合。

    

    基于Transformer的语言模型在大型数据集上训练，以预测给定输入序列的下一个标记。尽管训练目标简单，但它们已经在自然语言处理领域取得了革命性进展。这一成功的基础是自注意力机制。在这项研究中，我们提出了一个问题：一个单独的自注意力层从下一个标记预测中学到了什么？我们展示：通过梯度下降训练自注意力学习到一个自动机，该自动机通过两个不同的步骤生成下一个标记：(1) 硬检索：在给定输入序列的情况下，自注意力精确选择与上一个输入标记相关的高优先级输入标记。(2) 软组合：然后，它创建高优先级标记的凸组合。

    arXiv:2403.08081v1 Announce Type: cross  Abstract: Transformer-based language models are trained on large datasets to predict the next token given an input sequence. Despite this simple training objective, they have led to revolutionary advances in natural language processing. Underlying this success is the self-attention mechanism. In this work, we ask: $\textit{What}$ $\textit{does}$ $\textit{a}$ $\textit{single}$ $\textit{self-attention}$ $\textit{layer}$ $\textit{learn}$ $\textit{from}$ $\textit{next-token}$ $\textit{prediction?}$ We show that training self-attention with gradient descent learns an automaton which generates the next token in two distinct steps: $\textbf{(1)}$ $\textbf{Hard}$ $\textbf{retrieval:}$ Given input sequence, self-attention precisely selects the $\textit{high-priority}$ $\textit{input}$ $\textit{tokens}$ associated with the last input token. $\textbf{(2)}$ $\textbf{Soft}$ $\textbf{composition:}$ It then creates a convex combination of the high-priority tok
    
[^75]: 一种具有流形学习的多模态中间融合网络用于压力检测

    A Multimodal Intermediate Fusion Network with Manifold Learning for Stress Detection

    [https://arxiv.org/abs/2403.08077](https://arxiv.org/abs/2403.08077)

    该论文提出了一种具有流形学习的中间多模态融合网络，从多个模态中捕获协同特征，并通过维度降低优化多模态学习，提高压力检测准确性，同时减少计算复杂性。

    

    多模态深度学习方法从多个模态中捕获协同特征，并且与单模态方法相比，具有提高压力检测准确性的潜力。然而，这种准确性提升通常来自于高计算成本，原因是高维特征空间，尤其对于中间融合。降维是优化多模态学习的一种方式，通过简化数据并使特征更易于处理和分析，从而降低计算复杂性。本文介绍了一种具有基于流形学习的维度降低的中间多模态融合网络。多模态网络通过1D-CNN和2D-CNN从生物特征信号和面部标记生成独立表示。最后，这些特征被融合并馈送给另一个1D-CNN层，然后是一个全连接的稠密层。我们比较了各种维度减少技术。

    arXiv:2403.08077v1 Announce Type: cross  Abstract: Multimodal deep learning methods capture synergistic features from multiple modalities and have the potential to improve accuracy for stress detection compared to unimodal methods. However, this accuracy gain typically comes from high computational cost due to the high-dimensional feature spaces, especially for intermediate fusion. Dimensionality reduction is one way to optimize multimodal learning by simplifying data and making the features more amenable to processing and analysis, thereby reducing computational complexity. This paper introduces an intermediate multimodal fusion network with manifold learning-based dimensionality reduction. The multimodal network generates independent representations from biometric signals and facial landmarks through 1D-CNN and 2D-CNN. Finally, these features are fused and fed to another 1D-CNN layer, followed by a fully connected dense layer. We compared various dimensionality reduction techniques f
    
[^76]: FluoroSAM: 用于X光图像分割的语言对齐基础模型

    FluoroSAM: A Language-aligned Foundation Model for X-ray Image Segmentation

    [https://arxiv.org/abs/2403.08059](https://arxiv.org/abs/2403.08059)

    FluoroSAM是用于X光图像的分割的语言对齐基础模型，提供了一种在X光成像领域具有广泛适用性的自动图像分析工具。

    

    自动X光图像分割将加速诊断和介入精准医学领域的研究和发展。先前的研究已经提出了适用于解决特定图像分析问题的特定任务模型，但这些模型的效用受限于特定任务领域，要拓展到更广泛的应用则需要额外的数据、标签和重新训练工作。最近，基础模型（FMs） - 训练在大量高度变化数据上的机器学习模型因此使得广泛适用性成为可能 - 已经成为自动图像分析的有希望的工具。现有的用于医学图像分析的FMs聚焦于对象被明显可见边界清晰定义的场景和模式，如内窥镜手术工具分割。相比之下，X光成像通常没有提供这种清晰的边界或结构先验。在X光图像形成期间，复杂的三维

    arXiv:2403.08059v1 Announce Type: cross  Abstract: Automated X-ray image segmentation would accelerate research and development in diagnostic and interventional precision medicine. Prior efforts have contributed task-specific models capable of solving specific image analysis problems, but the utility of these models is restricted to their particular task domain, and expanding to broader use requires additional data, labels, and retraining efforts. Recently, foundation models (FMs) -- machine learning models trained on large amounts of highly variable data thus enabling broad applicability -- have emerged as promising tools for automated image analysis. Existing FMs for medical image analysis focus on scenarios and modalities where objects are clearly defined by visually apparent boundaries, such as surgical tool segmentation in endoscopy. X-ray imaging, by contrast, does not generally offer such clearly delineated boundaries or structure priors. During X-ray image formation, complex 3D
    
[^77]: TutoAI：用于物理任务的跨领域 AI 辅助混合媒体教程创作框架

    TutoAI: A Cross-domain Framework for AI-assisted Mixed-media Tutorial Creation on Physical Tasks

    [https://arxiv.org/abs/2403.08049](https://arxiv.org/abs/2403.08049)

    TutoAI 是一个跨领域的框架，用于在物理任务上利用AI辅助混合媒体教程创建，通过调查常见教程组件、评估AI模型提取组件的方法以及设计UI支持教程创建的指南，证明了其较基准模型具有更高或相似的质量。

    

    混合媒体教程将视频、图片、文本和图表整合起来，以教授过程技能，提供比基于时间轴的视频更具可浏览性的选择。然而，手动创建此类教程是乏味的，现有的自动化解决方案通常局限于特定领域。虽然 AI 模型具有潜力，但如何有效利用它们的能力尚不清楚，考虑到所涉及的多模态数据和模型的广阔领域。我们提出了 TutoAI，这是一个用于物理任务的跨领域 AI 辅助混合媒体教程创作的框架。首先，通过调查现有工作，我们提炼了常见的教程组件；然后，我们提出了一种识别、组装和评估用于组件提取的 AI 模型的方法；最后，我们提出了为基于 AI 生成的组件支持教程创建的用户界面（UI）设计指南。我们展示了 TutoAI 在质量上达到或高于基准模型的结果。

    arXiv:2403.08049v1 Announce Type: cross  Abstract: Mixed-media tutorials, which integrate videos, images, text, and diagrams to teach procedural skills, offer more browsable alternatives than timeline-based videos. However, manually creating such tutorials is tedious, and existing automated solutions are often restricted to a particular domain. While AI models hold promise, it is unclear how to effectively harness their powers, given the multi-modal data involved and the vast landscape of models. We present TutoAI, a cross-domain framework for AI-assisted mixed-media tutorial creation on physical tasks. First, we distill common tutorial components by surveying existing work; then, we present an approach to identify, assemble, and evaluate AI models for component extraction; finally, we propose guidelines for designing user interfaces (UI) that support tutorial creation based on AI-generated components. We show that TutoAI has achieved higher or similar quality compared to a baseline mo
    
[^78]: 食品与农业领域网络安全事件综述

    A Review of Cybersecurity Incidents in the Food and Agriculture Sector

    [https://arxiv.org/abs/2403.08036](https://arxiv.org/abs/2403.08036)

    该综述分析了食品与农业领域的网络安全事件并报告了不断增加的网络安全威胁频率。

    

    食品与农业（FA）领域对新兴技术的日益利用增加了减少网络风险的安全需求。鉴于这一情况，本文审查了FA领域披露和记录的网络安全事件。为此，确定了发生在2011年7月至2023年4月之间的30起网络安全事件。这些事件的详细信息来源于多个来源，包括：私营行业和联邦调查局（FBI）发布的闪电通知、受影响组织的内部报告和可获得的媒体来源。根据提供的信息，对每一起事件的安全威胁概况、勒索金额和对组织的影响进行了讨论。该综述报告显示网络安全威胁对FA领域的频率增加。为了减少这些网络风险，流行的网络安全框架...

    arXiv:2403.08036v1 Announce Type: cross  Abstract: The increasing utilization of emerging technologies in the Food & Agriculture (FA) sector has heightened the need for security to minimize cyber risks. Considering this aspect, this manuscript reviews disclosed and documented cybersecurity incidents in the FA sector. For this purpose, thirty cybersecurity incidents were identified, which took place between July 2011 and April 2023. The details of these incidents are reported from multiple sources such as: the private industry and flash notifications generated by the Federal Bureau of Investigation (FBI), internal reports from the affected organizations, and available media sources. Considering the available information, a brief description of the security threat, ransom amount, and impact on the organization are discussed for each incident. This review reports an increased frequency of cybersecurity threats to the FA sector. To minimize these cyber risks, popular cybersecurity framewor
    
[^79]: 利用人工智能打击网络仇恨：探讨大型语言模型在仇恨言论检测中的挑战和机遇

    Harnessing Artificial Intelligence to Combat Online Hate: Exploring the Challenges and Opportunities of Large Language Models in Hate Speech Detection

    [https://arxiv.org/abs/2403.08035](https://arxiv.org/abs/2403.08035)

    该论文围绕大型语言模型（LLMs）在检测和分类令人憎恶或有毒内容方面的作用展开文献综述和实证分析，旨在揭示LLM在识别令人憎恶内容方面的能力及其影响因素。

    

    大型语言模型（LLMs）在许多不同的应用中表现出色，除了语言生成，还包括翻译、摘要和情感分析等。一个引人注目的应用是文本分类。在识别令人憎恶或有毒言论的领域中，这变得至关重要，这是一个充满挑战和伦理困境的领域。在我们的研究中，我们有两个目标：首先，提供一个围绕LLMs作为分类器的文献综述，强调它们在检测和分类令人憎恶或有毒内容方面的作用。随后，我们探究了几种LLMs在分类仇恨言论方面的效力：识别哪些LLMs在这一任务中表现出色以及它们的基本属性和训练。借此洞察促成LLM在识别令人憎恶内容方面的优劣性所依赖的因素。通过结合全面的文献回顾和实证分析，我们的论文旨在解开这些大型语言模型在辨别令人憎恶内容方面的能力。

    arXiv:2403.08035v1 Announce Type: cross  Abstract: Large language models (LLMs) excel in many diverse applications beyond language generation, e.g., translation, summarization, and sentiment analysis. One intriguing application is in text classification. This becomes pertinent in the realm of identifying hateful or toxic speech -- a domain fraught with challenges and ethical dilemmas. In our study, we have two objectives: firstly, to offer a literature review revolving around LLMs as classifiers, emphasizing their role in detecting and classifying hateful or toxic content. Subsequently, we explore the efficacy of several LLMs in classifying hate speech: identifying which LLMs excel in this task as well as their underlying attributes and training. Providing insight into the factors that contribute to an LLM proficiency (or lack thereof) in discerning hateful content. By combining a comprehensive literature review with an empirical analysis, our paper strives to shed light on the capabil
    
[^80]: LG-Traj: LLM引导的行人轨迹预测

    LG-Traj: LLM Guided Pedestrian Trajectory Prediction

    [https://arxiv.org/abs/2403.08032](https://arxiv.org/abs/2403.08032)

    本文探讨了利用大型语言模型（LLMs）改进行人轨迹预测任务的可能性，通过引入运动线索来提高模型性能，并通过LG-Traj方法结合LLMs生成过去和未来轨迹中的运动线索，以增进对行人轨迹的理解。

    

    准确的行人轨迹预测对于各种应用至关重要，它需要深入了解动态环境中行人运动模式。然而，现有的行人轨迹预测方法仍需要更多探索来充分利用这些运动模式。本文研究了使用大型语言模型（LLMs）改进行人轨迹预测任务的可能性，通过引入运动线索。我们介绍了LG-Traj，一种将LLMs结合起来产生出行人过去/观察轨迹中的运动线索的新方法。我们的方法还通过使用高斯混合对训练数据的未来轨迹进行聚类，从而结合了在行人未来轨迹中存在的运动线索。这些运动线索，再加上行人坐标，有助于更好地理解潜在的表示。此外，我们运用奇异值分解来增强观测结果。

    arXiv:2403.08032v1 Announce Type: cross  Abstract: Accurate pedestrian trajectory prediction is crucial for various applications, and it requires a deep understanding of pedestrian motion patterns in dynamic environments. However, existing pedestrian trajectory prediction methods still need more exploration to fully leverage these motion patterns. This paper investigates the possibilities of using Large Language Models (LLMs) to improve pedestrian trajectory prediction tasks by inducing motion cues. We introduce LG-Traj, a novel approach incorporating LLMs to generate motion cues present in pedestrian past/observed trajectories. Our approach also incorporates motion cues present in pedestrian future trajectories by clustering future trajectories of training data using a mixture of Gaussians. These motion cues, along with pedestrian coordinates, facilitate a better understanding of the underlying representation. Furthermore, we utilize singular value decomposition to augment the observe
    
[^81]: 使用可解释人工智能的高光谱图像分析红队建模

    Red Teaming Models for Hyperspectral Image Analysis Using Explainable AI

    [https://arxiv.org/abs/2403.08017](https://arxiv.org/abs/2403.08017)

    本文介绍了一种使用可解释人工智能的红队建模方法，用于检验高光谱图像上的机器学习模型，并成功构建出一个只使用1%的输入特征即可达到可比较性能的模型。

    

    遥感领域要求可靠、稳健且经过质量保证的机器学习模型，使得红队成为识别和暴露潜在缺陷和偏见的重要方法。本文介绍了一种方法论，用于检查在HYPERVIEW挑战赛中运行在高光谱图像上的机器学习模型，重点关注土壤参数的估计。我们使用可解释人工智能（XAI）领域的事后解释方法，对赢得HYPERVIEW挑战赛并作为INTUITION-1高光谱任务上部署模型灵感的表现最佳模型进行批判性评估。我们的方法通过指出和验证关键缺陷，构建出一个只使用1%的输入特征即可达到可比较性能的模型。

    arXiv:2403.08017v1 Announce Type: cross  Abstract: Remote sensing (RS) applications in the space domain demand machine learning (ML) models that are reliable, robust, and quality-assured, making red teaming a vital approach for identifying and exposing potential flaws and biases. Since both fields advance independently, there is a notable gap in integrating red teaming strategies into RS. This paper introduces a methodology for examining ML models operating on hyperspectral images within the HYPERVIEW challenge, focusing on soil parameters' estimation. We use post-hoc explanation methods from the Explainable AI (XAI) domain to critically assess the best performing model that won the HYPERVIEW challenge and served as an inspiration for the model deployed on board the INTUITION-1 hyperspectral mission. Our approach effectively red teams the model by pinpointing and validating key shortcomings, constructing a model that achieves comparable performance using just 1% of the input features a
    
[^82]: 使用集成预测口语言识别的古吉拉特语-英语混合语音识别

    Gujarati-English Code-Switching Speech Recognition using ensemble prediction of spoken language

    [https://arxiv.org/abs/2403.08011](https://arxiv.org/abs/2403.08011)

    通过在输出中以每层有监督的方式对单词和字符的语言ID条件化变压器层，该方法虽然未能显著降低词错误率，但展现了在仅仅通过口语数据预测正确语言的潜力。

    

    混合语音识别中一个重要且困难的任务是识别语言，因为两种语言中的许多词在某些口音下听起来相似。我们专注于通过在输出中以每层有监督的方式对单词和字符的语言ID条件化变压器层，以改善端到端自动语音识别模型的性能。为此，我们提出了两种引入语言特定参数和可解释性到多头注意力机制的方法，并实施了一个有助于保持输入对齐连续性的时间损失。尽管无法显著降低词错误率（WER），我们的方法展现了在仅仅通过口语数据预测正确语言的潜力。我们通过在序列中删除LID引入了语言预测的正则化，有助于对齐长重复的输出序列。

    arXiv:2403.08011v1 Announce Type: cross  Abstract: An important and difficult task in code-switched speech recognition is to recognize the language, as lots of words in two languages can sound similar, especially in some accents. We focus on improving performance of end-to-end Automatic Speech Recognition models by conditioning transformer layers on language ID of words and character in the output in an per layer supervised manner. To this end, we propose two methods of introducing language specific parameters and explainability in the multi-head attention mechanism, and implement a Temporal Loss that helps maintain continuity in input alignment. Despite being unable to reduce WER significantly, our method shows promise in predicting the correct language from just spoken data. We introduce regularization in the language prediction by dropping LID in the sequence, which helps align long repeated output sequences.
    
[^83]: Pix2Pix-OnTheFly: 利用LLMs进行指导图像编辑

    Pix2Pix-OnTheFly: Leveraging LLMs for Instruction-Guided Image Editing

    [https://arxiv.org/abs/2403.08004](https://arxiv.org/abs/2403.08004)

    本文提出了一种新方法，实现了基于自然语言指令的图像编辑，在不需要任何预备工作的情况下，通过图像字幕和DDIM反演，获取编辑方向嵌入，进行指导图像编辑，表现出有效性和竞争力。

    

    众所周知，最近结合语言处理和图像处理的研究引起了广泛关注，本文提出了一种全新的方法，通过图像字幕和DDIM反演，获取编辑方向嵌入，进行指导图像编辑，而无需预备工作，证明了该方法的有效性和竞争力。

    arXiv:2403.08004v1 Announce Type: cross  Abstract: The combination of language processing and image processing keeps attracting increased interest given recent impressive advances that leverage the combined strengths of both domains of research. Among these advances, the task of editing an image on the basis solely of a natural language instruction stands out as a most challenging endeavour. While recent approaches for this task resort, in one way or other, to some form of preliminary preparation, training or fine-tuning, this paper explores a novel approach: We propose a preparation-free method that permits instruction-guided image editing on the fly. This approach is organized along three steps properly orchestrated that resort to image captioning and DDIM inversion, followed by obtaining the edit direction embedding, followed by image editing proper. While dispensing with preliminary preparation, our approach demonstrates to be effective and competitive, outperforming recent, state 
    
[^84]: 多智体是否梦见电子羊？：通过生成式学习提高强化学习的泛化能力

    Do Agents Dream of Electric Sheep?: Improving Generalization in Reinforcement Learning through Generative Learning

    [https://arxiv.org/abs/2403.07979](https://arxiv.org/abs/2403.07979)

    通过生成式增强技术，本研究研究了在稀疏奖励环境中通过基于想象力的强化学习训练来提高强化学习智能体泛化能力的方法。

    

    过度拟合的大脑假设表明梦的发生是为了让人类大脑进行泛化。在这里，我们询问是否对强化学习智能体也是如此。在真实环境中经验有限的情况下，我们使用基于想象力的强化学习来在类似梦境的情节中训练策略，在那里，对非想象力、预测的轨迹进行生成性增强。在四个ProcGen环境的实验中表明，与经典的想象力和离线训练相比，我们的方法在处理稀疏奖励环境时可以达到更高的泛化水平。

    arXiv:2403.07979v1 Announce Type: cross  Abstract: The Overfitted Brain hypothesis suggests dreams happen to allow generalization in the human brain. Here, we ask if the same is true for reinforcement learning agents as well. Given limited experience in a real environment, we use imagination-based reinforcement learning to train a policy on dream-like episodes, where non-imaginative, predicted trajectories are modified through generative augmentations. Experiments on four ProcGen environments show that, compared to classic imagination and offline training on collected experience, our method can reach a higher level of generalization when dealing with sparsely rewarded environments.
    
[^85]: KnowCoder：将结构化知识编码到LLMs中用于普适信息提取

    KnowCoder: Coding Structured Knowledge into LLMs for Universal Information Extraction

    [https://arxiv.org/abs/2403.07969](https://arxiv.org/abs/2403.07969)

    本文提出了KnowCoder，一个通过代码生成执行普适信息提取的大型语言模型，引入了代码风格的模式表示方法和两阶段学习框架，以提高LLMs对结构化知识的准确提取能力

    

    在本文中，我们提出了KnowCoder，这是一个大型语言模型（LLM），用于通过代码生成进行普适信息提取（UIE）。KnowCoder旨在开发一种统一的模式表示，使LLMs能够轻松理解，并且提出了一种有效的学习框架，鼓励LLMs遵循模式并准确提取结构化知识。为了实现这一目标，KnowCoder引入了一种代码风格的模式表示方法，将不同的模式统一转换为Python类，从而可以以LLM友好的方式捕捉UIE中任务之间的约束等复杂模式信息。我们进一步构建了一个包含超过30,000种知识类型的代码风格模式库，据我们所知，这是UIE中最大的库。为了简化LLMs的学习过程，KnowCoder包含一个通过代码预训练增强其模式理解能力的两阶段学习框架。

    arXiv:2403.07969v1 Announce Type: cross  Abstract: In this paper, we propose KnowCoder, a Large Language Model (LLM) to conduct Universal Information Extraction (UIE) via code generation. KnowCoder aims to develop a kind of unified schema representation that LLMs can easily understand and an effective learning framework that encourages LLMs to follow schemas and extract structured knowledge accurately. To achieve these, KnowCoder introduces a code-style schema representation method to uniformly transform different schemas into Python classes, with which complex schema information, such as constraints among tasks in UIE, can be captured in an LLM-friendly manner. We further construct a code-style schema library covering over $\textbf{30,000}$ types of knowledge, which is the largest one for UIE, to the best of our knowledge. To ease the learning process of LLMs, KnowCoder contains a two-phase learning framework that enhances its schema understanding ability via code pretraining and its 
    
[^86]: 深度神经网络解决方案是否形成星形区域？

    Do Deep Neural Network Solutions Form a Star Domain?

    [https://arxiv.org/abs/2403.07968](https://arxiv.org/abs/2403.07968)

    SGD解决方案集是一个星形域，包含一个星形模型，通过低损失数值的路径与其他解决方案线性相连，模除排列。

    

    Entezari等人（2022）推测通过随机梯度下降（SGD）可达到的神经网络解决方案集是凸的，考虑到排列不变性。本文提出了一个更加宽松的观点：SGD解决方案集是一个星形域，包含一个星形模型，通过低损失数值的路径与其他解决方案线性相连，模除排列。我们提出了Starlight算法，用于找到给定学习任务的星形模型。我们通过展示这个星形模型与其他独立找到的解决方案是线性相连的来验证我们的观点。

    arXiv:2403.07968v1 Announce Type: cross  Abstract: Entezari et al. (2022) conjectured that neural network solution sets reachable via stochastic gradient descent (SGD) are convex, considering permutation invariances. This means that two independent solutions can be connected by a linear path with low loss, given one of them is appropriately permuted. However, current methods to test this theory often fail to eliminate loss barriers between two independent solutions (Ainsworth et al., 2022; Benzing et al., 2022). In this work, we conjecture that a more relaxed claim holds: the SGD solution set is a star domain that contains a star model that is linearly connected to all the other solutions via paths with low loss values, modulo permutations. We propose the Starlight algorithm that finds a star model of a given learning task. We validate our claim by showing that this star model is linearly connected with other independently found solutions. As an additional benefit of our study, we demo
    
[^87]: 神经网络中的条件计算: 原理与研究趋势

    Conditional computation in neural networks: principles and research trends

    [https://arxiv.org/abs/2403.07965](https://arxiv.org/abs/2403.07965)

    该论文总结了将条件计算方法应用于设计神经网络的新兴领域中的原理和思想，并介绍了专家混合网络、标记选择机制和提前退出神经网络等三种实现方式。

    

    这篇文章总结了将条件计算方法应用于设计神经网络的新兴领域中的原理和思想。我们特别关注可以根据输入动态激活或去激活其计算图部分的神经网络。例如，动态选择输入标记、层（或一组层）以及每个层内的子模块（例如，卷积滤波器中的通道）。我们首先提供一个通用形式来统一描述这些技术。然后，我们介绍了这些原则的三个值得注意的实现：专家混合（MoEs）网络、标记选择机制和提前退出神经网络。本文旨在向这一不断发展的领域提供类似教程的介绍。为此，我们分析了这些模块化设计在效率、可解释性和迁移学习方面的好处，重点放在...

    arXiv:2403.07965v1 Announce Type: cross  Abstract: This article summarizes principles and ideas from the emerging area of applying \textit{conditional computation} methods to the design of neural networks. In particular, we focus on neural networks that can dynamically activate or de-activate parts of their computational graph conditionally on their input. Examples include the dynamic selection of, e.g., input tokens, layers (or sets of layers), and sub-modules inside each layer (e.g., channels in a convolutional filter). We first provide a general formalism to describe these techniques in an uniform way. Then, we introduce three notable implementations of these principles: mixture-of-experts (MoEs) networks, token selection mechanisms, and early-exit neural networks. The paper aims to provide a tutorial-like introduction to this growing field. To this end, we analyze the benefits of these modular designs in terms of efficiency, explainability, and transfer learning, with a focus on em
    
[^88]: 一种开源仿真平台的最佳设计与实施，用于以用户为中心的共享电动出行服务

    Optimal Design and Implementation of an Open-source Emulation Platform for User-Centric Shared E-mobility Services

    [https://arxiv.org/abs/2403.07964](https://arxiv.org/abs/2403.07964)

    提供了一种开源框架，用于共享电动出行，以代理-环路方法和模块化架构为特色，旨在弥补现有共享电动出行服务的设计缺陷，向电动出行研究社区提供福利。

    

    针对交通排放和污染不断加剧的全球挑战，共享电动出行服务成为一种流行的策略，包括电动汽车、电动自行车和电动滑板车。然而，现有的共享电动出行服务存在关键设计缺陷，包括服务整合不足、能源消耗预测不精确、可扩展性和地理覆盖范围有限，以及在多模式交通背景下尤其缺乏以用户为中心的视角。更重要的是，目前没有一个整合的开源框架，可以为电动出行研究社区带来益处。本文旨在填补这一空白，提供一个开创性的共享电动出行开源框架。所提出的框架采用代理-环路方法和模块化架构，旨在满足不同用户偏好，并提供增强的自定义功能。

    arXiv:2403.07964v1 Announce Type: new  Abstract: In response to the escalating global challenge of increasing emissions and pollution in transportation, shared electric mobility services, encompassing e-cars, e-bikes, and e-scooters, have emerged as a popular strategy. However, existingshared electric mobility services exhibit critical design deficiencies, including insufficient service integration, imprecise energy consumption forecasting, limited scalability and geographical coverage, and a notable absence of a user-centric perspective, particularly in the context of multi-modal transportation. More importantly, there is no consolidated open-source framework which could benefit the e-mobility research community. This paper aims to bridge this gap by providing a pioneering open-source framework for shared e-mobility. The proposed framework, with an agent-in-the-loop approach and modular architecture, is tailored to diverse user preferences and offers enhanced customization. We demonst
    
[^89]: 一个用于准确检测异常并识别网络入侵技术的可解释泛化机制

    An Interpretable Generalization Mechanism for Accurately Detecting Anomaly and Identifying Networking Intrusion Techniques

    [https://arxiv.org/abs/2403.07959](https://arxiv.org/abs/2403.07959)

    IG是一个可解释泛化机制，能够准确区分正常和异常的网络流量，并揭示复杂的入侵路径，为网络安全取证提供重要见解。

    

    最近入侵检测系统（IDS）中整合可解释人工智能（XAI）方法的发展，通过精确的特征选择，显著提升了系统性能。然而，对网络攻击的彻底理解要求IDS内在可解释的决策过程。本文介绍了“可解释泛化机制”（IG），旨在彻底改变IDS的能力。IG能够识别连贯模式，使其能够解释区分正常和异常的网络流量。此外，连贯模式的综合揭示复杂的入侵路径，为网络安全取证提供了必要的见解。通过对真实数据集NSL-KDD、UNSW-NB15和UKM-IDS20的实验，IG即使在较低的训练-测试比率下也能准确。在NSL-KDD数据集中，当训练-测试比率为10%-90%时，IG实现的Precision（PRE）=0.93、Recall（REC）=0.94和Area Under Curve（AUC）=0.94；PRE=0.98...

    arXiv:2403.07959v1 Announce Type: cross  Abstract: Recent advancements in Intrusion Detection Systems (IDS), integrating Explainable AI (XAI) methodologies, have led to notable improvements in system performance via precise feature selection. However, a thorough understanding of cyber-attacks requires inherently explainable decision-making processes within IDS. In this paper, we present the Interpretable Generalization Mechanism (IG), poised to revolutionize IDS capabilities. IG discerns coherent patterns, making it interpretable in distinguishing between normal and anomalous network traffic. Further, the synthesis of coherent patterns sheds light on intricate intrusion pathways, providing essential insights for cybersecurity forensics. By experiments with real-world datasets NSL-KDD, UNSW-NB15, and UKM-IDS20, IG is accurate even at a low ratio of training-to-test. With 10%-to-90%, IG achieves Precision (PRE)=0.93, Recall (REC)=0.94, and Area Under Curve (AUC)=0.94 in NSL-KDD; PRE=0.98
    
[^90]: 时间决策：利用早期退出神经网络中的时间相关性进行有效决策

    Temporal Decisions: Leveraging Temporal Correlation for Efficient Decisions in Early Exit Neural Networks

    [https://arxiv.org/abs/2403.07958](https://arxiv.org/abs/2403.07958)

    该论文引入了差异检测和时间耐心作为早期退出神经网络的决策机制，利用传感器数据流中的时间相关性来有效终止推断。

    

    深度学习在嵌入式和物联网应用中变得越来越重要。但是，在嵌入式设备上部署模型面临资源限制的挑战，这可能影响模型的推断准确性和延迟。早期退出神经网络是一种潜在解决方案，它通过在隐藏层之间附加的额外分类器动态调整模型深度。然而，实时终止决策机制对系统的效率、延迟和持续准确性至关重要。本文引入了差异检测和时间耐心作为早期退出神经网络的决策机制。它们利用传感器数据流中存在的时间相关性来有效地终止推断。我们评估了它们在健康监测、图像分类和唤醒词检测任务中的有效性。我们的创新贡献能够减少计算负担。

    arXiv:2403.07958v1 Announce Type: cross  Abstract: Deep Learning is becoming increasingly relevant in Embedded and Internet-of-things applications. However, deploying models on embedded devices poses a challenge due to their resource limitations. This can impact the model's inference accuracy and latency. One potential solution are Early Exit Neural Networks, which adjust model depth dynamically through additional classifiers attached between their hidden layers. However, the real-time termination decision mechanism is critical for the system's efficiency, latency, and sustained accuracy.   This paper introduces Difference Detection and Temporal Patience as decision mechanisms for Early Exit Neural Networks. They leverage the temporal correlation present in sensor data streams to efficiently terminate the inference. We evaluate their effectiveness in health monitoring, image classification, and wake-word detection tasks. Our novel contributions were able to reduce the computational foo
    
[^91]: 高效的后训练增强方法用于异构和分布式物联网环境中的自适应推断

    Efficient Post-Training Augmentation for Adaptive Inference in Heterogeneous and Distributed IoT Environments

    [https://arxiv.org/abs/2403.07957](https://arxiv.org/abs/2403.07957)

    提出了一种自动增强流程，能够将现有模型转换为早期退出神经网络（EENN），提高神经网络部署效率，实现了在物联网和图像分类用例上显著减少推断操作的效果。

    

    早期退出神经网络（EENN）提出了一种增强神经网络部署效率的解决方案。然而，创建EENN具有挑战性，并且需要专业领域知识，由于大量额外的设计选择。为了解决这个问题，我们提出了一种自动增强流程，专注于将现有模型转换为EENN。它执行了部署到异构或分布式硬件目标所需的所有设计决策：我们的框架构建了EENN架构，将其子图映射到硬件目标，并配置了其决策机制。据我们所知，这是第一个能够执行所有这些步骤的框架。我们在一系列物联网和标准图像分类用例上评估了我们的方法。对于语音命令检测任务，我们的解决方案能够将每次推断的平均操作减少了59.67%。

    arXiv:2403.07957v1 Announce Type: cross  Abstract: Early Exit Neural Networks (EENNs) present a solution to enhance the efficiency of neural network deployments. However, creating EENNs is challenging and requires specialized domain knowledge, due to the large amount of additional design choices. To address this issue, we propose an automated augmentation flow that focuses on converting an existing model into an EENN. It performs all required design decisions for the deployment to heterogeneous or distributed hardware targets: Our framework constructs the EENN architecture, maps its subgraphs to the hardware targets, and configures its decision mechanism. To the best of our knowledge, it is the first framework that is able to perform all of these steps.   We evaluated our approach on a collection of Internet-of-Things and standard image classification use cases. For a speech command detection task, our solution was able to reduce the mean operations per inference by 59.67%. For an ECG 
    
[^92]: DeepCDCL: 基于CDCL算法的神经网络验证框架

    DeepCDCL: An CDCL-based Neural Network Verification Framework

    [https://arxiv.org/abs/2403.07956](https://arxiv.org/abs/2403.07956)

    提出了一种基于CDCL算法的神经网络验证框架DeepCDCL，通过引入异步子句学习和管理结构，显著减少了时间消耗，并在ACAS Xu和MNIST数据集上展示了显著的加速。

    

    在安全关键应用中，神经网络面临越来越多的安全和安全性问题，这是由于它们对微小扰动的敏感性。在本文中，我们提出了DeepCDCL，这是一种基于冲突驱动子句学习（CDCL）算法的新型神经网络验证框架。我们引入了一种异步子句学习和管理结构，相比直接应用CDCL框架，减少了冗余的时间消耗。此外，我们还对我们的方法在ACAS Xu和MNIST数据集上的性能进行了详细评估，结果显示在大多数情况下实现了显著的加速。

    arXiv:2403.07956v1 Announce Type: cross  Abstract: Neural networks in safety-critical applications face increasing safety and security concerns due to their susceptibility to little disturbance. In this paper, we propose DeepCDCL, a novel neural network verification framework based on the Conflict-Driven Clause Learning (CDCL) algorithm. We introduce an asynchronous clause learning and management structure, reducing redundant time consumption compared to the direct application of the CDCL framework. Furthermore, we also provide a detailed evaluation of the performance of our approach on the ACAS Xu and MNIST datasets, showing that a significant speed-up is achieved in most cases.
    
[^93]: 朝着忠实解释：利用快捷方式发现来增强理性化

    Towards Faithful Explanations: Boosting Rationalization with Shortcuts Discovery

    [https://arxiv.org/abs/2403.07955](https://arxiv.org/abs/2403.07955)

    本文提出了一种Shortcuts-fused Selective Rationalization (SSR)方法，通过发现和利用潜在的快捷方式来提升理性化，并通过两种策略缓解利用快捷方式来组成理性化的问题，以及通过数据增强方法来补充已注释理性化数量的差距。

    

    人工智能领域神经网络的显著成功引发了有选择性的理性化。本文提出了一种Shortcuts-fused Selective Rationalization (SSR)方法，通过发现和利用潜在的快捷方式来提升理性化。具体而言，SSR首先设计了一种快捷方式发现方法来检测几个潜在的快捷方式。然后，通过引入识别出的快捷方式，我们提出了两种策略来缓解利用快捷方式来组成理性化的问题。最后，我们开发了两种数据增强方法来弥补已注释理性化数量的差距。对真实世界数据集的广泛实验结果清楚地验证了这一方法的有效性。

    arXiv:2403.07955v1 Announce Type: cross  Abstract: The remarkable success in neural networks provokes the selective rationalization. It explains the prediction results by identifying a small subset of the inputs sufficient to support them. Since existing methods still suffer from adopting the shortcuts in data to compose rationales and limited large-scale annotated rationales by human, in this paper, we propose a Shortcuts-fused Selective Rationalization (SSR) method, which boosts the rationalization by discovering and exploiting potential shortcuts. Specifically, SSR first designs a shortcuts discovery approach to detect several potential shortcuts. Then, by introducing the identified shortcuts, we propose two strategies to mitigate the problem of utilizing shortcuts to compose rationales. Finally, we develop two data augmentations methods to close the gap in the number of annotated rationales. Extensive experimental results on real-world datasets clearly validate the effectiveness of
    
[^94]: 通过结构化稀疏张量分解对稀疏DNN加速进行抽象化

    Abstracting Sparse DNN Acceleration via Structured Sparse Tensor Decomposition

    [https://arxiv.org/abs/2403.07953](https://arxiv.org/abs/2403.07953)

    本文提出了通过结构化分解张量进一步抽象稀疏DNN加速的方法，实现了将稀疏张量转换成一系列结构化稀疏张量，从而弥合了稀疏DNN模型和硬件之间的差距。

    

    在深度神经网络（DNNs）中利用稀疏性已成为满足现代DNN日益增长的计算需求的一种具有前景的领域。然而，在实践中，稀疏DNN加速仍然面临一个关键挑战。为了最小化稀疏加速的开销，硬件设计师最近提出了结构化稀疏硬件支持，这提供了有限的灵活性并需要额外的模型微调。此外，为某些结构化稀疏硬件微调的任何稀疏模型无法被其他结构化硬件加速。为了弥合稀疏DNN模型和硬件之间的差距，本文提出了通过结构分解的张量近似（TASD），利用了线性代数中的分配性质将任何稀疏张量转化为一系列结构化稀疏张量。接下来，我们开发了一个软件框架TASDER，通过搜索逐层高质量的结构化分解来加速DNNs的权重和...

    arXiv:2403.07953v1 Announce Type: cross  Abstract: Exploiting sparsity in deep neural networks (DNNs) has been a promising area to meet the growing computation need of modern DNNs. However, in practice, sparse DNN acceleration still faces a key challenge. To minimize the overhead of sparse acceleration, hardware designers have proposed structured sparse hardware support recently, which provides limited flexibility and requires extra model fine-tuning. Moreover, any sparse model fine-tuned for certain structured sparse hardware cannot be accelerated by other structured hardware. To bridge the gap between sparse DNN models and hardware, this paper proposes tensor approximation via structured decomposition (TASD), which leverages the distributive property in linear algebra to turn any sparse tensor into a series of structured sparse tensors. Next, we develop a software framework, TASDER, to accelerate DNNs by searching layer-wise, high-quality structured decomposition for both weight and 
    
[^95]: AesopAgent: 基于Agent的故事到视频制作系统

    AesopAgent: Agent-driven Evolutionary System on Story-to-Video Production

    [https://arxiv.org/abs/2403.07952](https://arxiv.org/abs/2403.07952)

    AesopAgent是一种基于Agent的故事到视频制作系统，能将用户故事提案转化为剧本、图像和音频，并将这些内容集成为视频，同时确保生成的视频内容丰富且连贯。

    

    近年来，Agent和AIGC（Artificial Intelligence Generated Content）技术取得了显著进展。我们提出了AesopAgent，一种基于Agent的故事到视频制作演进系统。AesopAgent是Agent技术在多模态内容生成方面的实际应用。该系统在统一框架内集成了多种生成能力，使个人用户可以轻松利用这些模块。这一创新系统将用户的故事提案转化为剧本、图像和音频，然后将这些多模态内容集成到视频中。此外，动画单元（例如Gen-2和Sora）可以使视频更具感染力。AesopAgent系统可以协调视频生成的任务工作流程，确保生成的视频内容丰富且连贯。该系统主要包含两个层，即水平层和实用层。在水平层中，

    arXiv:2403.07952v1 Announce Type: cross  Abstract: The Agent and AIGC (Artificial Intelligence Generated Content) technologies have recently made significant progress. We propose AesopAgent, an Agent-driven Evolutionary System on Story-to-Video Production. AesopAgent is a practical application of agent technology for multimodal content generation. The system integrates multiple generative capabilities within a unified framework, so that individual users can leverage these modules easily. This innovative system would convert user story proposals into scripts, images, and audio, and then integrate these multimodal contents into videos. Additionally, the animating units (e.g., Gen-2 and Sora) could make the videos more infectious. The AesopAgent system could orchestrate task workflow for video generation, ensuring that the generated video is both rich in content and coherent. This system mainly contains two layers, i.e., the Horizontal Layer and the Utility Layer. In the Horizontal Layer,
    
[^96]: 算法贝叶斯认识论

    Algorithmic Bayesian Epistemology

    [https://arxiv.org/abs/2403.07949](https://arxiv.org/abs/2403.07949)

    这里是中文总结出的一句话要点: 本论文将算法视角应用于贝叶斯认识论，挑战传统方法在信息不完备情况下的应用，为个体如何演化其信念提供了新的理论视角。

    

    理论计算机科学中算法视角的一个方面是关注其他科学学科的视角，重点放在满足实际约束条件的令人满意的解决方案上，而不是忽略这些约束条件的最优解决方案。算法视角为许多学术领域，包括分子生物学、生态学、神经科学、量子物理学、经济学和社会科学，提供了独特而重要的视角。本论文将算法视角应用于贝叶斯认识论。传统的贝叶斯认识论为个体在接收新信息后如何演化其信念提供了全面的框架。然而，这些方法通常假定了这种信息的详尽模型，包括不同证据之间的相关结构。事实上，个体可能缺乏这样的详尽模型，但仍需要形成信念。除此之外

    arXiv:2403.07949v1 Announce Type: cross  Abstract: One aspect of the algorithmic lens in theoretical computer science is a view on other scientific disciplines that focuses on satisfactory solutions that adhere to real-world constraints, as opposed to solutions that would be optimal ignoring such constraints. The algorithmic lens has provided a unique and important perspective on many academic fields, including molecular biology, ecology, neuroscience, quantum physics, economics, and social science.   This thesis applies the algorithmic lens to Bayesian epistemology. Traditional Bayesian epistemology provides a comprehensive framework for how an individual's beliefs should evolve upon receiving new information. However, these methods typically assume an exhaustive model of such information, including the correlation structure between different pieces of evidence. In reality, individuals might lack such an exhaustive model, while still needing to form beliefs. Beyond such informational 
    
[^97]: WorldGPT：受Sora启发的视频AI代理作为文本和图像输入的丰富世界模型

    WorldGPT: A Sora-Inspired Video AI Agent as Rich World Models from Text and Image Inputs

    [https://arxiv.org/abs/2403.07944](https://arxiv.org/abs/2403.07944)

    本文提出了一种视频生成AI代理，通过结合文本提示和图像输入，利用Sora启发的多模态学习技术构建丰富的世界模型，有效解决了视频生成中的时间一致性和动作平滑性挑战。

    

    几种文本到视频扩散模型展示了在合成高质量视频内容方面出色的能力。然而，保持生成序列中的时间一致性并确保动作平滑仍然是一个严峻的挑战。本文提出了一种创新的视频生成AI代理，利用受Sora启发的多模态学习的力量来基于文本提示和附带图像构建熟练的世界模型框架。该框架包括两部分：提示增强器和完整视频翻译。

    arXiv:2403.07944v1 Announce Type: cross  Abstract: Several text-to-video diffusion models have demonstrated commendable capabilities in synthesizing high-quality video content. However, it remains a formidable challenge pertaining to maintaining temporal consistency and ensuring action smoothness throughout the generated sequences. In this paper, we present an innovative video generation AI agent that harnesses the power of Sora-inspired multimodal learning to build skilled world models framework based on textual prompts and accompanying images. The framework includes two parts: prompt enhancer and full video translation. The first part employs the capabilities of ChatGPT to meticulously distill and proactively construct precise prompts for each subsequent step, thereby guaranteeing the utmost accuracy in prompt communication and accurate execution in following model operations. The second part employ compatible with existing advanced diffusion techniques to expansively generate and re
    
[^98]: 文本到音频生成与视频同步

    Text-to-Audio Generation Synchronized with Videos

    [https://arxiv.org/abs/2403.07938](https://arxiv.org/abs/2403.07938)

    介绍了一个新的与视频对齐的文本到音频生成基准T2AV-Bench，以及一种简单而有效的视频对齐TTA生成模型T2AV，改进了传统方法，并融合了视觉对齐文本嵌入。

    

    最近，人们对文本到音频（TTA）生成的关注日益加强，研究人员努力从文本描述中合成音频。然而，大多数现有方法虽然利用潜在扩散模型来学习音频和文本嵌入之间的关系，但在保持生成的音频与其视频之间无缝同步方面表现不佳。这经常导致可察觉的音频-视觉不匹配。为填补这一空白，我们引入了一个与视频对齐的文本到音频生成的开创性基准，名为T2AV-Bench。该基准通过三个专门用于评估视觉对齐和时间一致性的新颖指标而脱颖而出。为了补充这一点，我们还提出了一个简单而有效的视频对齐TTA生成模型，即T2AV。超越传统方法，T2AV通过将视觉对齐文本嵌入集成为其c

    arXiv:2403.07938v1 Announce Type: cross  Abstract: In recent times, the focus on text-to-audio (TTA) generation has intensified, as researchers strive to synthesize audio from textual descriptions. However, most existing methods, though leveraging latent diffusion models to learn the correlation between audio and text embeddings, fall short when it comes to maintaining a seamless synchronization between the produced audio and its video. This often results in discernible audio-visual mismatches. To bridge this gap, we introduce a groundbreaking benchmark for Text-to-Audio generation that aligns with Videos, named T2AV-Bench. This benchmark distinguishes itself with three novel metrics dedicated to evaluating visual alignment and temporal consistency. To complement this, we also present a simple yet effective video-aligned TTA generation model, namely T2AV. Moving beyond traditional methods, T2AV refines the latent diffusion approach by integrating visual-aligned text embeddings as its c
    
[^99]: 多人游戏中的假动作

    Feint in Multi-Player Games

    [https://arxiv.org/abs/2403.07932](https://arxiv.org/abs/2403.07932)

    该论文介绍了多人游戏中假动作的首次形式化、实现和定量评估，并证明其能够显著提高奖励收益、增加游戏多样性，且时间消耗方面开销很小。

    

    这篇论文介绍了对多人游戏中的假动作进行了首次形式化、实现和定量评估。我们首先从多人游戏的角度对假动作进行了形式化，涉及到时间、空间和它们的集体影响。该形式化建立在非传递性主动马尔可夫游戏模型之上，其中假动作能够产生可观的影响。接下来，我们考虑了在多代理建模的最新进展下（即多智能体强化学习）在多人游戏中实施假动作的实际细节。最后，我们定量检验了我们设计的有效性，结果显示我们的假动作设计可以（1）显著提高游戏中的奖励收益；（2）显著提高多人游戏的多样性；以及（3）仅在时间消耗方面产生可忽略的开销。我们得出结论，我们的假动作设计是有效的。

    arXiv:2403.07932v1 Announce Type: cross  Abstract: This paper introduces the first formalization, implementation and quantitative evaluation of Feint in Multi-Player Games. Our work first formalizes Feint from the perspective of Multi-Player Games, in terms of the temporal, spatial, and their collective impacts. The formalization is built upon Non-transitive Active Markov Game Model, where Feint can have a considerable amount of impacts. Then, our work considers practical implementation details of Feint in Multi-Player Games, under the state-of-the-art progress of multi-agent modeling to date (namely Multi-Agent Reinforcement Learning). Finally, our work quantitatively examines the effectiveness of our design, and the results show that our design of Feint can (1) greatly improve the reward gains from the game; (2) significantly improve the diversity of Multi-Player Games; and (3) only incur negligible overheads in terms of time consumption. We conclude that our design of Feint is effec
    
[^100]: AI身份的意义：创造者、创作物和后果的含义

    Implications of Identity of AI: Creators, Creations, and Consequences

    [https://arxiv.org/abs/2403.07924](https://arxiv.org/abs/2403.07924)

    该论文探讨了人工智能领域的身份问题，强调了通过身份视角促进AI多样性在创造者、创作物和后果方面的重要性。

    

    人工智能（AI）领域正在快速发展，具有显著潜力改变社会。然而，它面临着一个明显的挑战：缺乏多样性，这是STEM领域长期存在的问题。本立场论文探讨了人工智能和身份的交叉点，作为理解AI发展和应用中的偏见、不平等和道德考虑的途径。我们提出了一个多维度的AI身份定义，涵盖其创造者、应用以及它们的更广泛影响。理解AI的身份涉及分析参与AI发展的各种个体、所产生的技术以及社会、道德和心理影响。在探讨AI身份生态系统及其社会动态后，我们提出了一个框架，强调了通过身份视角跨三个维度——创造者、创作物和后果，在AI中需要多样性的必要性。

    arXiv:2403.07924v1 Announce Type: cross  Abstract: The field of Artificial Intelligence (AI) is rapidly advancing, with significant potential to transform society. However, it faces a notable challenge: lack of diversity, a longstanding issue in STEM fields. In this context, This position paper examines the intersection of AI and identity as a pathway to understand biases, inequalities, and ethical considerations in AI development and deployment. We present a multifaceted definition of AI identity, which encompasses its creators, applications, and their broader impacts. Understanding AI's identity involves analyzing the diverse individuals involved in AI's development, the technologies produced, and the social, ethical, and psychological implications. After exploring the AI identity ecosystem and its societal dynamics, We propose a framework that highlights the need for diversity in AI across three dimensions: Creators, Creations, and Consequences through the lens of identity. This pap
    
[^101]: 深度强化学习与边缘计算在物联网环境中的实时监控与控制优化融合

    The Fusion of Deep Reinforcement Learning and Edge Computing for Real-time Monitoring and Control Optimization in IoT Environments

    [https://arxiv.org/abs/2403.07923](https://arxiv.org/abs/2403.07923)

    本文提出了一种基于深度强化学习和边缘计算的优化控制系统，通过云边协同和动态资源分配实现工业目标的监控和优化，显著提升了系统性能，并节省了成本。

    

    针对工业物联网环境中对实时性能和控制质量的需求，本文提出了基于深度强化学习和边缘计算的优化控制系统。该系统利用云边协同，部署轻量级策略网络在边缘，预测系统状态，并以高频率输出控制，实现工业目标的监控和优化。此外，设计了动态资源分配机制，以确保边缘计算资源的合理调度，实现全局优化。结果表明，该方法减少了云边通信延迟，加快了对异常情况的响应，降低了系统故障率，延长了设备平均运行时间，并节省了手动维护和更换成本。这确保了实时和稳定的控制。

    arXiv:2403.07923v1 Announce Type: cross  Abstract: In response to the demand for real-time performance and control quality in industrial Internet of Things (IoT) environments, this paper proposes an optimization control system based on deep reinforcement learning and edge computing. The system leverages cloud-edge collaboration, deploys lightweight policy networks at the edge, predicts system states, and outputs controls at a high frequency, enabling monitoring and optimization of industrial objectives. Additionally, a dynamic resource allocation mechanism is designed to ensure rational scheduling of edge computing resources, achieving global optimization. Results demonstrate that this approach reduces cloud-edge communication latency, accelerates response to abnormal situations, reduces system failure rates, extends average equipment operating time, and saves costs for manual maintenance and replacement. This ensures real-time and stable control.
    
[^102]: Merino：基于熵驱动的IoT设备上生成式语言模型设计

    Merino: Entropy-driven Design for Generative Language Models on IoT Devices

    [https://arxiv.org/abs/2403.07921](https://arxiv.org/abs/2403.07921)

    在本文中，我们提出了一个新颖的信息熵框架，用于设计手机友好的生成式语言模型，通过最大化transformer解码器的熵来在计算预算内，成功设计了MeRino模型，在移动设置下展现出与当前最先进的自回归transformer模型竞争性能的特点

    

    大规模生成式语言模型（LLMs）作为人工智能现代时代的革命性进步，然而，直接部署LLMs在资源受限的硬件上，比如物联网（IoT）设备，由于其高计算成本而变得困难。在本文中，我们提出了一个新颖的信息熵框架，用于设计手机友好的生成式语言模型。我们的主要设计范式是在给定的计算预算内最大化transformer解码器的熵。整个设计过程涉及解决一个数学规划（MP）问题，可以在几分钟内在CPU上完成，使其几乎是零成本的。我们评估了我们设计的模型MeRino，在九个NLP下游任务上展示了它们在移动设置下对抗当前最先进的自回归transformer模型的竞争性表现。值得注意的是，MeRino在移动设置下获得了类似或更好的零性能表现

    arXiv:2403.07921v1 Announce Type: cross  Abstract: Generative Large Language Models (LLMs) stand as a revolutionary advancement in the modern era of artificial intelligence (AI). However, directly deploying LLMs in resource-constrained hardware, such as Internet-of-Things (IoT) devices, is difficult due to their high computational cost. In this paper, we propose a novel information-entropy framework for designing mobile-friendly generative language models. Our key design paradigm is to maximize the entropy of transformer decoders within the given computational budgets. The whole design procedure involves solving a mathematical programming (MP) problem, which can be done on the CPU within minutes, making it nearly zero-cost. We evaluate our designed models, termed MeRino, across nine NLP downstream tasks, showing their competitive performance against the state-of-the-art autoregressive transformer models under the mobile setting. Notably, MeRino achieves similar or better zero performan
    
[^103]: ProtLLM：一种具有蛋白质作为单词预训练的交织式蛋白质-语言LLM

    ProtLLM: An Interleaved Protein-Language LLM with Protein-as-Word Pre-Training

    [https://arxiv.org/abs/2403.07920](https://arxiv.org/abs/2403.07920)

    提出了ProtLLM，一种具有独特动态蛋白质装配机制及蛋白质作为单词语言建模方法的交织式蛋白质-语言LLM，并构建了大规模的交织式蛋白质-文本数据集用于预训练。

    

    我们提出了ProtLLM，一种多功能的跨模式大型语言模型（LLM），用于处理既有蛋白质为中心又有蛋白质-语言任务。ProtLLM具有独特的动态蛋白质装配机制，使其能够处理自然语言文本与任意数量的蛋白质交织在一起的复杂输入。此外，我们提出了蛋白质作为单词语言建模方法来训练ProtLLM。通过开发专门的蛋白质词汇表，我们赋予该模型不仅预测自然语言而且预测来自大量候选蛋白质的能力。此外，我们构建了一个大规模的交织式蛋白质-文本数据集，命名为InterPT，用于预训练。该数据集全面涵盖了结构化数据源（如蛋白质注释）和非结构化数据源（如生物研究论文），从而赋予ProtLLM理解蛋白质的关键知识。我们在经典数据集上对ProtLLM进行了评估。

    arXiv:2403.07920v1 Announce Type: cross  Abstract: We propose ProtLLM, a versatile cross-modal large language model (LLM) for both protein-centric and protein-language tasks. ProtLLM features a unique dynamic protein mounting mechanism, enabling it to handle complex inputs where the natural language text is interspersed with an arbitrary number of proteins. Besides, we propose the protein-as-word language modeling approach to train ProtLLM. By developing a specialized protein vocabulary, we equip the model with the capability to predict not just natural language but also proteins from a vast pool of candidates. Additionally, we construct a large-scale interleaved protein-text dataset, named InterPT, for pre-training. This dataset comprehensively encompasses both (1) structured data sources like protein annotations and (2) unstructured data sources like biological research papers, thereby endowing ProtLLM with crucial knowledge for understanding proteins. We evaluate ProtLLM on classic 
    
[^104]: 论开放基金会模型的社会影响

    On the Societal Impact of Open Foundation Models

    [https://arxiv.org/abs/2403.07918](https://arxiv.org/abs/2403.07918)

    开放基金会模型具有广泛可用的模型权重，带来了重大利益，但也存在边际风险，需要进一步研究来评估其相对于现有技术的安全性。

    

    arXiv:2403.07918v1 公告类型：交叉摘要：基金会模型是强大的技术：它们如何公开发布直接影响了它们的社会影响。 在这篇立场论文中，我们关注开放基金会模型，在这里定义为具有广泛可用模型权重的模型（例如Llama 2、Stable Diffusion XL）。 我们确定了开放基金会模型的五个独特属性（例如更大的可定制性、较差的监控），这些属性导致了它们的利益和风险。 开放基金会模型提供了重大的利益，但也有一些限制，涵盖了创新、竞争、决策权的分配以及透明度。为了理解其被滥用的风险，我们设计了一个用于分析其边际风险的风险评估框架。 在几个滥用向量（例如网络攻击、生物武器）中，我们发现目前的研究不足以有效地表征开放基金会模型相对于现有技术的边际风险。 该框架有助于扩展论文中建议的分析以估计新技术的安全性边际风险。

    arXiv:2403.07918v1 Announce Type: cross  Abstract: Foundation models are powerful technologies: how they are released publicly directly shapes their societal impact. In this position paper, we focus on open foundation models, defined here as those with broadly available model weights (e.g. Llama 2, Stable Diffusion XL). We identify five distinctive properties (e.g. greater customizability, poor monitoring) of open foundation models that lead to both their benefits and risks. Open foundation models present significant benefits, with some caveats, that span innovation, competition, the distribution of decision-making power, and transparency. To understand their risks of misuse, we design a risk assessment framework for analyzing their marginal risk. Across several misuse vectors (e.g. cyberattacks, bioweapons), we find that current research is insufficient to effectively characterize the marginal risk of open foundation models relative to pre-existing technologies. The framework helps ex
    
[^105]: 推进投资前沿：面向产业的深度强化学习在投资组合优化中的应用

    Advancing Investment Frontiers: Industry-grade Deep Reinforcement Learning for Portfolio Optimization

    [https://arxiv.org/abs/2403.07916](https://arxiv.org/abs/2403.07916)

    本研究将深度强化学习应用于投资组合优化中，融合了产业级方法和量化金融，提出了结合多领域方法的独特视角。

    

    本研究探讨了深度强化学习（DRL）在资产类别无关投资组合优化中的应用，将产业级方法与量化金融相结合。在这一融合的核心是我们的强大框架，不仅将先进的DRL算法与现代计算技术相结合，还强调严格的统计分析、软件工程和监管合规性。据我们所知，这是第一项将金融强化学习与机器人学和数学物理中的从模拟到真实方法相结合的研究，为我们的框架和论据带来了独特的视角。我们的研究最终介绍了AlphaOptimizerNet，一种具有专有权的强化学习代理（以及相应的库）。AlphaOptimizerNet是从最新的文献和我们独特的跨学科方法的综合中发展而来的。

    arXiv:2403.07916v1 Announce Type: new  Abstract: This research paper delves into the application of Deep Reinforcement Learning (DRL) in asset-class agnostic portfolio optimization, integrating industry-grade methodologies with quantitative finance. At the heart of this integration is our robust framework that not only merges advanced DRL algorithms with modern computational techniques but also emphasizes stringent statistical analysis, software engineering and regulatory compliance. To the best of our knowledge, this is the first study integrating financial Reinforcement Learning with sim-to-real methodologies from robotics and mathematical physics, thus enriching our frameworks and arguments with this unique perspective. Our research culminates with the introduction of AlphaOptimizerNet, a proprietary Reinforcement Learning agent (and corresponding library). Developed from a synthesis of state-of-the-art (SOTA) literature and our unique interdisciplinary methodology, AlphaOptimizerNe
    
[^106]: 站在FURM基础上-评估医疗系统中公平、有用和可靠AI模型的框架

    Standing on FURM ground -- A framework for evaluating Fair, Useful, and Reliable AI Models in healthcare systems

    [https://arxiv.org/abs/2403.07911](https://arxiv.org/abs/2403.07911)

    开发了一种机制来评估医疗系统中的公平、有用和可靠AI模型，弥合AI模型开发与实际受益之间的鸿沟。

    

    使用人工智能（AI）指导患者护理或操作流程的影响取决于AI模型的输出、基于该输出的决策协议以及相关利益相关者采取必要后续行动的能力。在部署前估计这种相互作用的影响，并在部署后实时研究它，对于弥合AI模型开发与可实现利益之间的鸿沟至关重要。为了实现这一点，斯坦福医疗保健的数据科学团队开发了一种机制，通过进行伦理审查以识别潜在的价值不匹配、仿真估算有用性、财务预测评估可持续性，以及分析确定IT可行性、设计部署策略，并建议前瞻性监测和评估计划来识别公平、有用和可靠的AI模型（FURM）。我们报告了对FURM评估进行的评估。

    arXiv:2403.07911v1 Announce Type: cross  Abstract: The impact of using artificial intelligence (AI) to guide patient care or operational processes is an interplay of the AI model's output, the decision-making protocol based on that output, and the capacity of the stakeholders involved to take the necessary subsequent action. Estimating the effects of this interplay before deployment, and studying it in real time afterwards, are essential to bridge the chasm between AI model development and achievable benefit. To accomplish this, the Data Science team at Stanford Health Care has developed a mechanism to identify fair, useful and reliable AI models (FURM) by conducting an ethical review to identify potential value mismatches, simulations to estimate usefulness, financial projections to assess sustainability, as well as analyses to determine IT feasibility, design a deployment strategy, and recommend a prospective monitoring and evaluation plan. We report on FURM assessments done to evalu
    
[^107]: 用深度学习和强化学习技术增强Kubernetes自动调度，用于大规模云计算优化

    Enhancing Kubernetes Automated Scheduling with Deep Learning and Reinforcement Techniques for Large-Scale Cloud Computing Optimization

    [https://arxiv.org/abs/2403.07905](https://arxiv.org/abs/2403.07905)

    本文提出了一种基于深度学习和强化学习的自动任务调度方案，旨在实现大规模云计算系统中任务调度的最优利用和最大执行效率。

    

    随着云计算应用规模的持续扩大，深度学习和强化学习等人工智能技术逐渐成为解决大规模云计算系统自动任务调度的关键工具。针对大规模云计算系统中任务调度的复杂性和实时性需求，本文提出了一种基于深度学习和强化学习的自动任务调度方案。首先，使用深度学习技术实时监测和预测云计算系统中的参数，以获取系统状态信息。然后，结合强化学习算法，根据实时系统状态和任务特征动态调整任务调度策略，实现系统资源的最佳利用和任务执行效率的最大化。

    arXiv:2403.07905v1 Announce Type: cross  Abstract: With the continuous expansion of the scale of cloud computing applications, artificial intelligence technologies such as Deep Learning and Reinforcement Learning have gradually become the key tools to solve the automated task scheduling of large-scale cloud computing systems. Aiming at the complexity and real-time requirement of task scheduling in large-scale cloud computing system, this paper proposes an automatic task scheduling scheme based on deep learning and reinforcement learning. Firstly, the deep learning technology is used to monitor and predict the parameters in the cloud computing system in real time to obtain the system status information. Then, combined with reinforcement learning algorithm, the task scheduling strategy is dynamically adjusted according to the real-time system state and task characteristics to achieve the optimal utilization of system resources and the maximum of task execution efficiency. This paper veri
    
[^108]: 正视监管空白：通过纳入社会公民打造超越AIA的欧盟AI审计生态系统

    Addressing the Regulatory Gap: Moving Towards an EU AI Audit Ecosystem Beyond the AIA by Including Civil Society

    [https://arxiv.org/abs/2403.07904](https://arxiv.org/abs/2403.07904)

    提出了一个融合合规和监督的AI审计生态系统，强调了DSA和AIA监管框架中存在的监管空白，并要求AIA为研究人员和社会公民提供数据和模型访问权限

    

    欧洲立法机构提出了数字服务法案（DSA）和人工智能法案（AIA）来规范平台和人工智能（AI）产品。本文审查了第三方审计在这两项法律中的地位以及在多大程度上提供模型和数据的访问权限。通过考虑审计生态系统中第三方审计和第三方数据访问的价值，我们发现了一个监管空白，即《人工智能法案》没有为研究人员和社会公民提供数据访问权限。我们对文献的贡献包括：（1）定义了一个融合合规和监督的AI审计生态系统。（2）强调了DSA和AIA监管框架中存在的监管空白，阻碍了AI审计生态系统的建立。（3）强调研究和社会公民的第三方审计必须成为该生态系统的一部分，并要求AIA包括数据和模型访问权限。

    arXiv:2403.07904v1 Announce Type: cross  Abstract: The European legislature has proposed the Digital Services Act (DSA) and Artificial Intelligence Act (AIA) to regulate platforms and Artificial Intelligence (AI) products. We review to what extent third-party audits are part of both laws and to what extent access to models and data is provided. By considering the value of third-party audits and third-party data access in an audit ecosystem, we identify a regulatory gap in that the Artificial Intelligence Act does not provide access to data for researchers and civil society. Our contributions to the literature include: (1) Defining an AI audit ecosystem that incorporates compliance and oversight. (2) Highlighting a regulatory gap within the DSA and AIA regulatory framework, preventing the establishment of an AI audit ecosystem. (3) Emphasizing that third-party audits by research and civil society must be part of that ecosystem and demand that the AIA include data and model access for ce
    
[^109]: $\widetilde{O}(T^{-1})$ 收敛到（粗糙）相关均衡在全信息一般和马尔可夫博弈中的问题

    $\widetilde{O}(T^{-1})$ Convergence to (Coarse) Correlated Equilibria in Full-Information General-Sum Markov Games

    [https://arxiv.org/abs/2403.07890](https://arxiv.org/abs/2403.07890)

    本研究通过使用乐观的前瞻性领导者算法（OFTRL）和适当的数值更新程序，在全信息一般和马尔可夫博弈中找到了$\widetilde{O}(T^{-1})$-approximate（粗糙）相关均衡，这在$T$次迭代内得以实现。

    

    No-regret学习与博弈论密切相关，最近的研究提出了非耦合的无悔学习动态，当所有玩家在正则形式游戏中采用时，以$\widetilde{O}(T^{-1})$的接近最优速率收敛到各种均衡解，这显着改进了经典无悔学习者的$O(1/\sqrt{T})$速率。然而，在马尔可夫博弈中类似的收敛结果很少见，这是一个更通用的设置，为多智能体强化学习奠定了基础。在这项工作中，我们通过展示乐观的前瞻性领导者算法（OFTRL），连同适当的数值更新程序，可以在$T$次迭代内找到全信息一般和马尔可夫博弈中的$\widetilde{O}(T^{-1})$近似（粗糙）相关均衡。数值结果也包括以证实我们的理论发现。

    arXiv:2403.07890v1 Announce Type: cross  Abstract: No-regret learning has a long history of being closely connected to game theory. Recent works have devised uncoupled no-regret learning dynamics that, when adopted by all the players in normal-form games, converge to various equilibrium solutions at a near-optimal rate of $\widetilde{O}(T^{-1})$, a significant improvement over the $O(1/\sqrt{T})$ rate of classic no-regret learners. However, analogous convergence results are scarce in Markov games, a more generic setting that lays the foundation for multi-agent reinforcement learning. In this work, we close this gap by showing that the optimistic-follow-the-regularized-leader (OFTRL) algorithm, together with appropriate value update procedures, can find $\widetilde{O}(T^{-1})$-approximate (coarse) correlated equilibria in full-information general-sum Markov games within $T$ iterations. Numerical results are also included to corroborate our theoretical findings.
    
[^110]: 跨模态去偏见: 使用语言减轻影像中的子群体转变

    Cross-modality debiasing: using language to mitigate sub-population shifts in imaging

    [https://arxiv.org/abs/2403.07888](https://arxiv.org/abs/2403.07888)

    使用自然语言输入去偏置图像特征表示，以改善在子群体上的最坏情况表现。

    

    子群体转变是一种特定类型的领域转变，突显了在训练和测试之间特定子群体或人口的数据分布的变化。子群体转变占据了算法偏见的一个重要来源，并需要分布鲁棒性。最近的研究发现，多模态基础模型，如视觉-语言模型CLIP，具有固有的分布鲁棒性，但这种鲁棒性对参数微调是脆弱的。在本文中，我们提出利用不同模态之间的鲁棒性连接，重新塑造一个模态的分布鲁棒性。具体地，在CLIP的分布鲁棒性上下文中，我们提出利用自然语言输入来去偏置图像特征表示，以改善在子群体上的最坏情况表现。我们的广泛实证研究表明，通过自然语言输入进行去偏见处理的图像表示能够在子群体上改善最坏情况的性能。

    arXiv:2403.07888v1 Announce Type: cross  Abstract: Sub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by na
    
[^111]: 神经槽解释器：在新兴的槽表示中接地对象语义

    Neural Slot Interpreters: Grounding Object Semantics in Emergent Slot Representations

    [https://arxiv.org/abs/2403.07887](https://arxiv.org/abs/2403.07887)

    提出了神经槽解释器（NSI），通过槽表示学习接地和生成物体语义，实现了将现实世界的物体语义结合到抽象中。

    

    物体中心方法在将原始感知无监督分解为丰富的类似物体的抽象方面取得了重大进展。然而，将现实世界的物体语义接地到学到的抽象中的能力有限，这阻碍了它们在下游理解应用中的采用。我们提出神经槽解释器（NSI），它通过槽表示学习接地和生成物体语义。NSI的核心是一种类似XML的编程语言，它使用简单的语法规则将场景的物体语义组织成以物体为中心的程序原语。然后，一个对齐模型学习通过共享嵌入空间上的双层对比学习目标将程序原语接地到槽。最后，我们构建NSI程序生成模型，利用对齐模型推断的密集关联从槽生成以物体为中心的程序。在双模式检索实验中，

    arXiv:2403.07887v1 Announce Type: cross  Abstract: Object-centric methods have seen significant progress in unsupervised decomposition of raw perception into rich object-like abstractions. However, limited ability to ground object semantics of the real world into the learned abstractions has hindered their adoption in downstream understanding applications. We present the Neural Slot Interpreter (NSI) that learns to ground and generate object semantics via slot representations. At the core of NSI is an XML-like programming language that uses simple syntax rules to organize the object semantics of a scene into object-centric program primitives. Then, an alignment model learns to ground program primitives into slots through a bi-level contrastive learning objective over a shared embedding space. Finally, we formulate the NSI program generator model to use the dense associations inferred from the alignment model to generate object-centric programs from slots. Experiments on bi-modal retrie
    
[^112]: 一个在哈密顿图中寻找哈密顿循环的模因算法

    A Memetic Algorithm To Find a Hamiltonian Cycle in a Hamiltonian Graph

    [https://arxiv.org/abs/2403.07886](https://arxiv.org/abs/2403.07886)

    提出了一种用于在哈密顿图中寻找哈密顿循环的模因算法，并引入了增强局部搜索和动态增强输入图的新颖技术，该方法在实践中成功证明了哈密顿性。

    

    我们提出了一种用于在哈密顿图中寻找哈密顿循环的模因算法。这种算法基于一种已被证明有效的解决非对称旅行商问题 (\atspp) 的方法，本文中还通过引入更强大的局部搜索来增强这种算法。我们的方法还引入了一种在考虑哈密顿性的输入图中稀疏化并在搜索过程中动态增强它的新颖技术。这种综合启发式方法有助于通过更短的时间找到哈密顿循环来证明哈密顿性。此外，我们还采用了最近介绍的从 \hamcyc 到对称 \tsp 的多项式时间归约方法，该方法基于计算图的传递闭包。尽管我们的方法是一种元启发式方法，即在理论上不能保证找到哈密顿循环，但我们观察到该方法在实践中成功验证了哈密顿性。

    arXiv:2403.07886v1 Announce Type: cross  Abstract: We present a memetic algorithm (\maa) approach for finding a Hamiltonian cycle in a Hamiltonian graph. The \ma is based on a proven approach to the Asymmetric Travelling Salesman Problem (\atspp) that, in this contribution, is boosted by the introduction of more powerful local searches. Our approach also introduces a novel technique that sparsifies the input graph under consideration for Hamiltonicity and dynamically augments it during the search. Such a combined heuristic approach helps to prove Hamiltonicity by finding a Hamiltonian cycle in less time. In addition, we also employ a recently introduced polynomial-time reduction from the \hamcyc to the Symmetric \tsp, which is based on computing the transitive closure of the graph. Although our approach is a metaheuristic, i.e., it does not give a theoretical guarantee for finding a Hamiltonian cycle, we have observed that the method is successful in practice in verifying the Hamiltoni
    
[^113]: MOD-CL: 带约束损失的多标签目标检测

    MOD-CL: Multi-label Object Detection with Constrained Loss

    [https://arxiv.org/abs/2403.07885](https://arxiv.org/abs/2403.07885)

    引入了MOD-CL多标签目标检测框架，利用约束损失改善输出，通过修正器模型和混合器模型生成更受限制的结果，并利用Product T-Norm将约束损失集成到MOD_YOLO架构中，显著提高了任务1和任务2的得分。

    

    我们引入了MOD-CL，这是一个利用训练过程中的约束损失来产生更好满足给定需求的输出的多标签目标检测框架。在本文中，我们使用了基于最先进目标检测模型YOLOv8构建的多标签目标检测模型MOD_YOLO，该模型近年来已被发表。在任务1中，我们引入了修正器模型和混合器模型，这两个新模型跟在目标检测过程之后，旨在生成更受限制的输出。对于任务2，我们使用Product T-Norm将约束损失合并到MOD_YOLO架构中。结果表明，这些实现对于改善任务1和任务2的得分至关重要。

    arXiv:2403.07885v1 Announce Type: cross  Abstract: We introduce MOD-CL, a multi-label object detection framework that utilizes constrained loss in the training process to produce outputs that better satisfy the given requirements. In this paper, we use $\mathrm{MOD_{YOLO}}$, a multi-label object detection model built upon the state-of-the-art object detection model YOLOv8, which has been published in recent years. In Task 1, we introduce the Corrector Model and Blender Model, two new models that follow after the object detection process, aiming to generate a more constrained output. For Task 2, constrained losses have been incorporated into the $\mathrm{MOD_{YOLO}}$ architecture using Product T-Norm. The results show that these implementations are instrumental to improving the scores for both Task 1 and Task 2.
    
[^114]: Seg-metrics: 一个用于计算分割度量的Python包

    Seg-metrics: a Python package to compute segmentation metrics

    [https://arxiv.org/abs/2403.07884](https://arxiv.org/abs/2403.07884)

    seg-metrics是一个用于计算分割度量的Python包，为医学图像分割研究提供了全面的标准化模型评估解决方案，具有用户友好的界面和支持多种文件格式的特点。

    

    针对医学图像分割(MIS)研究中选择性强调指标的令人担忧的趋势，我们介绍了\texttt{seg-metrics}，这是一个用于标准化MIS模型评估的开源Python包。与现有的包不同，\texttt{seg-metrics}为各种基于重叠和距离的度量提供了用户友好的界面，提供了全面的解决方案。\texttt{seg-metrics}支持多种文件格式，并且可以通过Python软件包索引(PyPI)轻松安装。聚焦于速度和便利性，\texttt{seg-metrics}成为高效MIS模型评估的宝贵工具。

    arXiv:2403.07884v1 Announce Type: cross  Abstract: In response to a concerning trend of selectively emphasizing metrics in medical image segmentation (MIS) studies, we introduce \texttt{seg-metrics}, an open-source Python package for standardized MIS model evaluation. Unlike existing packages, \texttt{seg-metrics} offers user-friendly interfaces for various overlap-based and distance-based metrics, providing a comprehensive solution. \texttt{seg-metrics} supports multiple file formats and is easily installable through the Python Package Index (PyPI). With a focus on speed and convenience, \texttt{seg-metrics} stands as a valuable tool for efficient MIS model assessment.
    
[^115]: 使用与文本相关的图像块选择进行高效的视觉与语言预训练

    Efficient Vision-and-Language Pre-training with Text-Relevant Image Patch Selection

    [https://arxiv.org/abs/2403.07883](https://arxiv.org/abs/2403.07883)

    TRIPS是一种高效的视觉与语言预训练方法，通过使用文本引导的图像块选择层，动态计算文本相关的视觉注意力，加速训练和推理过程，而且不增加额外参数。

    

    Vision Transformers (ViTs)在大规模的视觉与语言预训练(VLP)模型中变得越来越受欢迎。尽管先前的VLP研究已经证明了ViTs的有效性，但这些努力仍然受到由于冗长的视觉序列引起的计算效率低下的困扰。为了解决这一挑战，我们引入了一种高效的VLP方法，称为TRIPS，全称为Text-Relevant Image Patch Selection。TRIPS通过在视觉主干网络中逐步减少视觉序列，使用一个文本引导的图像块选择层，从而加速训练和推理过程。这个块选择层动态计算文本相关的视觉注意力，使其能够在端到端的方式中通过文本引导识别出关注的图像记号并融合不关注的记号。重要的是，TRIPS不添加任何额外的参数，并且适用于大多数基于ViT的VLP模型。

    arXiv:2403.07883v1 Announce Type: cross  Abstract: Vision Transformers (ViTs) have become increasingly popular in large-scale Vision and Language Pre-training (VLP) models. Although previous VLP research has demonstrated the efficacy of ViTs, these efforts still struggle with computational inefficiencies caused by lengthy visual sequences. To address this challenge, we introduce an efficient VLP approach called TRIPS, which stands for Text-Relevant Image Patch Selection. TRIPS progressively reduces the visual sequence using a text-guided patch-selection layer in the visual backbone, thereby accelerating both training and inference processes. This patch-selection layer dynamically computes text-dependent visual attention, enabling it to identify attentive image tokens with text guidance and fuse inattentive ones in an end-to-end fashion. Importantly, TRIPS does not add any extra parameters and generalizes to most ViT-based VLP models. We incorporate TRIPS into three representative VLP m
    
[^116]: AI事件和“网络故障”: 研究议程的案例

    AI incidents and 'networked trouble': The case for a research agenda

    [https://arxiv.org/abs/2403.07879](https://arxiv.org/abs/2403.07879)

    论文主张一个AI事件的研究议程，重点关注AI出错并引发争议的示例以及它们在在线环境中如何构建，认为这些事件是参与AI系统的重要手段，需要进一步研究。

    

    在人们普遍关注公众如何参与AI设计的背景下，我主张一个专注于AI事件的研究议程 - 即AI出错并引发争议的示例 - 以及它们在在线环境中如何构建的研究议程。我以2020年9月的一个AI事件为例，当时一个Twitter用户创建了一个“可怕的实验”来展示Twitter算法在裁剪图像时存在的种族偏见。这导致Twitter不仅放弃了该算法的使用，还否认了使用任何算法进行该任务的决定。我认为像这样的AI事件是参与需要进一步研究的AI系统的重要手段。我认为，这项研究议程应集中于如何通过我称之为“网络故障”的网络化在线行为来构建事件，其中参与的格式使个人和算法以各种方式进行交互。

    arXiv:2403.07879v1 Announce Type: cross  Abstract: Against a backdrop of widespread interest in how publics can participate in the design of AI, I argue for a research agenda focused on AI incidents - examples of AI going wrong and sparking controversy - and how they are constructed in online environments. I take up the example of an AI incident from September 2020, when a Twitter user created a 'horrible experiment' to demonstrate the racist bias of Twitter's algorithm for cropping images. This resulted in Twitter not only abandoning its use of that algorithm, but also disavowing its decision to use any algorithm for the task. I argue that AI incidents like this are a significant means for participating in AI systems that require further research. That research agenda, I argue, should focus on how incidents are constructed through networked online behaviours that I refer to as 'networked trouble', where formats for participation enable individuals and algorithms to interact in ways th
    
[^117]: 超越死记硬背：语言模型中的随机内存访问挑战

    Beyond Memorization: The Challenge of Random Memory Access in Language Models

    [https://arxiv.org/abs/2403.07805](https://arxiv.org/abs/2403.07805)

    本文研究了语言模型在访问内存时的挑战，发现通过背诵和置换等技术可以改善语言模型的随机内存访问能力，从而在开放域问题回答任务中取得显著改进。

    

    最近语言模型(LMs)的发展展示了它们在NLP任务中的有效性，尤其是在知识密集型任务中。然而，在其参数内部的知识存储和内存访问机制仍然令人费解。本文探讨了生成式语言模型（如GPT-2）是否能够顺序或随机地访问其内存。通过精心设计的合成任务，涵盖全面背诵、选择性背诵和基于问题回答的情景，我们揭示了LMs能够顺序访问其内存，同时在随机访问已记忆内容时遇到挑战。我们发现，通过背诵和置换等技术可以提高LMs的随机内存访问能力。此外，通过将这种干预应用于开放域问题回答的现实场景，我们验证了通过背诵来增强随机访问技术对问题回答能力的显著改进。

    arXiv:2403.07805v1 Announce Type: cross  Abstract: Recent developments in Language Models (LMs) have shown their effectiveness in NLP tasks, particularly in knowledge-intensive tasks. However, the mechanisms underlying knowledge storage and memory access within their parameters remain elusive. In this paper, we investigate whether a generative LM (e.g., GPT-2) is able to access its memory sequentially or randomly. Through carefully-designed synthetic tasks, covering the scenarios of full recitation, selective recitation and grounded question answering, we reveal that LMs manage to sequentially access their memory while encountering challenges in randomly accessing memorized content. We find that techniques including recitation and permutation improve the random memory access capability of LMs. Furthermore, by applying this intervention to realistic scenarios of open-domain question answering, we validate that enhancing random access by recitation leads to notable improvements in questi
    
[^118]: 为计算病理学系统配备工件处理流水线：计算与性能权衡的展示

    Equipping Computational Pathology Systems with Artifact Processing Pipelines: A Showcase for Computation and Performance Trade-offs

    [https://arxiv.org/abs/2403.07743](https://arxiv.org/abs/2403.07743)

    提出了一种专家混合方案，用于在计算病理学系统中检测和排除五种显著的工件，并应用概率阈值处理。

    

    组织病理学是癌症诊断的黄金标准，在显微镜下进行检查。然而，组织病理学处理过程会产生一些工件，最终会转移到玻璃载玻片的数字化版本，即全玻幻灯片。工件是诊断无关的区域，可能导致错误的深度学习算法预测。因此，在计算病理学（CPATH）系统中检测和排除工件对于可靠的自动诊断至关重要。在本文中，我们提出了一种专家混合（MoE）方案，用于检测包括损坏组织、模糊、褶皱组织、气泡和在WSIs中的组织学无关血液等五种显著工件。首先，我们训练独立的二元DL模型作为专家来捕捉特定的工件形态。然后，我们使用融合机制来集成它们的预测。我们对最终的概率进行概率阈值处理

    arXiv:2403.07743v1 Announce Type: cross  Abstract: Histopathology is a gold standard for cancer diagnosis under a microscopic examination. However, histological tissue processing procedures result in artifacts, which are ultimately transferred to the digitized version of glass slides, known as whole slide images (WSIs). Artifacts are diagnostically irrelevant areas and may result in wrong deep learning (DL) algorithms predictions. Therefore, detecting and excluding artifacts in the computational pathology (CPATH) system is essential for reliable automated diagnosis. In this paper, we propose a mixture of experts (MoE) scheme for detecting five notable artifacts, including damaged tissue, blur, folded tissue, air bubbles, and histologically irrelevant blood from WSIs. First, we train independent binary DL models as experts to capture particular artifact morphology. Then, we ensemble their predictions using a fusion mechanism. We apply probabilistic thresholding over the final probabilit
    
[^119]: 互动指令跟随代理的在线持续学习

    Online Continual Learning For Interactive Instruction Following Agents

    [https://arxiv.org/abs/2403.07548](https://arxiv.org/abs/2403.07548)

    我们提出了针对具身代理的两种持续学习设置：学习新行为和新环境。同时，我们通过自信度得分来更新存储的信息，从而避免需要任务边界信息的问题。

    

    在通过语言指令执行日常任务的具身代理学习过程中，文献大都假定代理在开始时就学习所有训练数据。我们认为这样的学习场景较不现实，因为机器人代理应该在探索和感知世界的过程中不断地学习。为了朝着更真实的具身代理学习场景迈进一步，我们提出了两种持续学习设置供具身代理使用；学习新行为（行为增量学习，Behavior-IL）和新环境（环境增量学习，Environment-IL）。在任务中，先前基于“数据先验”的持续学习方法维护过去任务的logits。然而，存储的信息往往是不充分学习的信息，需要任务边界信息，而这种信息并不总是可用。在这里，我们提议基于自信度得分而无需任务边界信息来更新它们。

    arXiv:2403.07548v1 Announce Type: new  Abstract: In learning an embodied agent executing daily tasks via language directives, the literature largely assumes that the agent learns all training data at the beginning. We argue that such a learning scenario is less realistic since a robotic agent is supposed to learn the world continuously as it explores and perceives it. To take a step towards a more realistic embodied agent learning scenario, we propose two continual learning setups for embodied agents; learning new behaviors (Behavior Incremental Learning, Behavior-IL) and new environments (Environment Incremental Learning, Environment-IL) For the tasks, previous 'data prior' based continual learning methods maintain logits for the past tasks. However, the stored information is often insufficiently learned information and requires task boundary information, which might not always be available. Here, we propose to update them based on confidence scores without task boundary information d
    
[^120]: 基于矢量量化的深度学习在大规模MIMO系统中用于CSI反馈

    Vector Quantization for Deep-Learning-Based CSI Feedback in Massive MIMO Systems

    [https://arxiv.org/abs/2403.07355](https://arxiv.org/abs/2403.07355)

    提出了一种基于矢量量化的深度学习方法，用于大规模MIMO系统中的CSI反馈，通过引入特定的转换函数和可训练的码本设计策略，降低了计算复杂度并提高了CSI重建性能。

    

    本文介绍了一种基于有限速率深度学习（DL）的信道状态信息（CSI）反馈方法，用于大规模多输入多输出（MIMO）系统。该方法在矢量量化变分自动编码器（VQ-VAE）框架下提供了潜在矢量的有限位表示，同时基于形状增益矢量量化减少了计算复杂度。在这种方法中，潜在矢量的幅度使用合适的转换函数和非均匀标量码本进行量化，而潜在矢量的方向则使用可训练的Grassmann码本进行量化。通过引入一个用于嵌套码本的码字选择规则和损失函数设计，还开发了一种多速率码本设计策略。仿真结果表明，所提出的方法降低了与VQ-VAE相关的计算复杂度，同时改善了CSI重建性能。

    arXiv:2403.07355v1 Announce Type: cross  Abstract: This paper presents a finite-rate deep-learning (DL)-based channel state information (CSI) feedback method for massive multiple-input multiple-output (MIMO) systems. The presented method provides a finite-bit representation of the latent vector based on a vector-quantized variational autoencoder (VQ-VAE) framework while reducing its computational complexity based on shape-gain vector quantization. In this method, the magnitude of the latent vector is quantized using a non-uniform scalar codebook with a proper transformation function, while the direction of the latent vector is quantized using a trainable Grassmannian codebook. A multi-rate codebook design strategy is also developed by introducing a codeword selection rule for a nested codebook along with the design of a loss function. Simulation results demonstrate that the proposed method reduces the computational complexity associated with VQ-VAE while improving CSI reconstruction pe
    
[^121]: 排列质量函数的否定

    The negation of permutation mass function

    [https://arxiv.org/abs/2403.06483](https://arxiv.org/abs/2403.06483)

    本文提出了排列质量函数的否定方法，并验证了其收敛性，研究了否定操作后的不确定性和不相似性变化趋势。

    

    否定是知识表示中的一个重要视角。现有的否定方法主要应用于概率论、证据理论和复杂证据理论。作为证据理论的一种泛化，随机排列集合理论可以更精确地表示信息。然而，如何将否定的概念应用于随机排列集合理论尚未被研究。本文提出了排列质量函数的否定。此外，在否定过程中，验证了所提出的否定方法的收敛性。研究了每个否定操作后不确定性和不相似性的趋势。数值例子被用来证明所提出方法的合理性。

    arXiv:2403.06483v1 Announce Type: new  Abstract: Negation is a important perspective of knowledge representation. Existing negation methods are mainly applied in probability theory, evidence theory and complex evidence theory. As a generalization of evidence theory, random permutation sets theory may represent information more precisely. However, how to apply the concept of negation to random permutation sets theory has not been studied. In this paper, the negation of permutation mass function is proposed. Moreover, in the negation process, the convergence of proposed negation method is verified. The trends of uncertainty and dissimilarity after each negation operation are investigated. Numerical examples are used to demonstrate the rationality of the proposed method.
    
[^122]: 为基于学习方法的组合问题构建通用表示

    Towards a Generic Representation of Cominatorial Problems for Learning-Based Approaches

    [https://arxiv.org/abs/2403.06026](https://arxiv.org/abs/2403.06026)

    本文倡导为基于学习方法的组合问题构建通用表示，以解决特定表示无法跨越不同组合问题的问题。

    

    近年来，越来越多的研究人员对使用基于学习方法解决组合问题产生了兴趣，无论是以端到端的方式还是与传统优化算法结合使用。在这两种情景下，挑战在于将目标组合问题编码成适用于学习算法的结构。许多现有作品提出了特定于问题的表示，通常以图的形式，以利用图神经网络的优势。然而，这些方法缺乏泛化性，因为表示不能轻易从一个组合问题转移到另一个组合问题。虽然已经有一些尝试去填补这一差距，但它们仍然只提供了部分泛化性。鉴于这一挑战，本文倡导为基于学习方法的组合问题朝着完全通用的表示方式迈进。我们提出的方法包括

    arXiv:2403.06026v1 Announce Type: cross  Abstract: In recent years, there has been a growing interest in using learning-based approaches for solving combinatorial problems, either in an end-to-end manner or in conjunction with traditional optimization algorithms. In both scenarios, the challenge lies in encoding the targeted combinatorial problems into a structure compatible with the learning algorithm. Many existing works have proposed problem-specific representations, often in the form of a graph, to leverage the advantages of \textit{graph neural networks}. However, these approaches lack generality, as the representation cannot be easily transferred from one combinatorial problem to another one. While some attempts have been made to bridge this gap, they still offer a partial generality only. In response to this challenge, this paper advocates for progress toward a fully generic representation of combinatorial problems for learning-based approaches. The approach we propose involves 
    
[^123]: MuseGraph：面向大型语言模型的图导向指令调整用于通用图挖掘

    MuseGraph: Graph-oriented Instruction Tuning of Large Language Models for Generic Graph Mining

    [https://arxiv.org/abs/2403.04780](https://arxiv.org/abs/2403.04780)

    MuseGraph将GNNs和LLMs的优势结合起来，提出了一种更有效和通用的图挖掘方法，可以跨不同任务和数据集使用

    

    具有丰富属性的图在建模互联实体和改进各种实际应用中的预测方面至关重要。传统图神经网络（GNNs）通常用于建模带属性的图，但需要在应用于不同图任务和数据集时进行重新训练。尽管大型语言模型（LLMs）的出现在自然语言处理中引入了新的范例，但LLMs在图挖掘中的生成潜力仍未得到充分探索。为此，我们提出了一个新颖的框架 MuseGraph，它无缝整合了GNNs和LLMs的优势，并促进了一种更有效和通用的图挖掘方法，可跨不同任务和数据集使用。具体而言，我们首先通过提出的自适应输入生成引入一个紧凑的图描述，以在语言令牌限制的约束下封装来自图的关键信息。

    arXiv:2403.04780v1 Announce Type: cross  Abstract: Graphs with abundant attributes are essential in modeling interconnected entities and improving predictions in various real-world applications. Traditional Graph Neural Networks (GNNs), which are commonly used for modeling attributed graphs, need to be re-trained every time when applied to different graph tasks and datasets. Although the emergence of Large Language Models (LLMs) has introduced a new paradigm in natural language processing, the generative potential of LLMs in graph mining remains largely under-explored. To this end, we propose a novel framework MuseGraph, which seamlessly integrates the strengths of GNNs and LLMs and facilitates a more effective and generic approach for graph mining across different tasks and datasets. Specifically, we first introduce a compact graph description via the proposed adaptive input generation to encapsulate key information from the graph under the constraints of language token limitations. T
    
[^124]: 语言模型是否是解谜天才？算法谜题揭示了多模态推理中的严峻挑战

    Are Language Models Puzzle Prodigies? Algorithmic Puzzles Unveil Serious Challenges in Multimodal Reasoning

    [https://arxiv.org/abs/2403.03864](https://arxiv.org/abs/2403.03864)

    这项研究提出了多模态解谜任务AlgoPuzzleVQA，通过算法谜题挑战评估了多模态语言模型在需要视觉理解、语言理解和复杂算法推理的能力，旨在评估视觉数据解释与算法问题解决能力之间的差距。

    

    这篇论文介绍了多模态解谜任务，将其放在视觉问答的背景中。我们提出了一个新的数据集AlgoPuzzleVQA，旨在挑战和评估多模态语言模型在解决需要视觉理解、语言理解和复杂算法推理的算法谜题方面的能力。我们创建了涵盖布尔逻辑、组合数学、图论、优化、搜索等多种数学和算法主题的谜题，旨在评估视觉数据解释与算法问题解决能力之间的差距。数据集是通过人类编写的代码自动生成的。我们所有的谜题都有精确的解决方案，可以从算法中找到，无需繁琐的人工计算。这确保了我们的数据集在推理复杂性和数据集大小方面可以任意扩展。

    arXiv:2403.03864v1 Announce Type: cross  Abstract: This paper introduces the novel task of multimodal puzzle solving, framed within the context of visual question-answering. We present a new dataset, AlgoPuzzleVQA designed to challenge and evaluate the capabilities of multimodal language models in solving algorithmic puzzles that necessitate both visual understanding, language understanding, and complex algorithmic reasoning. We create the puzzles to encompass a diverse array of mathematical and algorithmic topics such as boolean logic, combinatorics, graph theory, optimization, search, etc., aiming to evaluate the gap between visual data interpretation and algorithmic problem-solving skills. The dataset is generated automatically from code authored by humans. All our puzzles have exact solutions that can be found from the algorithm without tedious human calculations. It ensures that our dataset can be scaled up arbitrarily in terms of reasoning complexity and dataset size. Our investi
    
[^125]: 利用联邦学习和边缘计算实现云计算网络中的推荐系统

    Leveraging Federated Learning and Edge Computing for Recommendation Systems within Cloud Computing Networks

    [https://arxiv.org/abs/2403.03165](https://arxiv.org/abs/2403.03165)

    边缘智能结合了AI和边缘计算，利用联邦学习实现隐私保护的机器学习，在FL网络中提出分层联邦学习（HFL）框架以提高通信效率。

    

    为了实现人工智能（AI）的大规模高效部署，AI和边缘计算的结合产生了边缘智能，利用末端设备和边缘服务器的计算和通信能力来更接近数据生成地处理数据。边缘智能的关键技术之一是隐私保护的机器学习范式联邦学习（FL），使数据所有者能够在无需将原始数据传输至第三方服务器的情况下训练模型。然而，FL网络预计会涉及数千个异构分布式设备。因此，通信效率仍然是一个关键瓶颈。为了减少节点故障和设备退出，提出了一种分层联邦学习（HFL）框架，其中指定的集群领导者通过中间模型聚合来支持数据所有者。

    arXiv:2403.03165v1 Announce Type: new  Abstract: To enable large-scale and efficient deployment of artificial intelligence (AI), the combination of AI and edge computing has spawned Edge Intelligence, which leverages the computing and communication capabilities of end devices and edge servers to process data closer to where it is generated. A key technology for edge intelligence is the privacy-protecting machine learning paradigm known as Federated Learning (FL), which enables data owners to train models without having to transfer raw data to third-party servers. However, FL networks are expected to involve thousands of heterogeneous distributed devices. As a result, communication efficiency remains a key bottleneck. To reduce node failures and device exits, a Hierarchical Federated Learning (HFL) framework is proposed, where a designated cluster leader supports the data owner through intermediate model aggregation. Therefore, based on the improvement of edge server resource utilizatio
    
[^126]: 光谱遇见空间: 和谐3D形状匹配和插值

    Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation

    [https://arxiv.org/abs/2402.18920](https://arxiv.org/abs/2402.18920)

    该研究提出了一个统一的框架，结合光谱和空间域的映射，以预测3D形状之间的点对应和形状插值，相比先前方法，取得更准确、平滑的点对应结果，并且在计算上更高效。

    

    虽然3D形状匹配和插值密切相关，但它们经常被分开研究并依次应用于关联不同的3D形状，从而导致性能不佳。在这项工作中，我们提出了一个统一的框架，用于预测3D形状之间的点对应和形状插值。为此，我们将深度功能映射框架与经典表面变形模型结合起来，以在光谱和空间域中映射形状。一方面，通过整合空间映射，我们的方法相对于先前用于形状匹配的功能映射方法获得更精确和平滑的点对应。另一方面，通过引入光谱映射，我们的方法摆脱了通常使用但计算昂贵的仅对近等距形状变形有效的测地距离约束。

    arXiv:2402.18920v1 Announce Type: cross  Abstract: Although 3D shape matching and interpolation are highly interrelated, they are often studied separately and applied sequentially to relate different 3D shapes, thus resulting in sub-optimal performance. In this work we present a unified framework to predict both point-wise correspondences and shape interpolation between 3D shapes. To this end, we combine the deep functional map framework with classical surface deformation models to map shapes in both spectral and spatial domains. On the one hand, by incorporating spatial maps, our method obtains more accurate and smooth point-wise correspondences compared to previous functional map methods for shape matching. On the other hand, by introducing spectral maps, our method gets rid of commonly used but computationally expensive geodesic distance constraints that are only valid for near-isometric shape deformations. Furthermore, we propose a novel test-time adaptation scheme to capture both 
    
[^127]: 分析不规则时间序列数据中的稳定神经随机微分方程

    Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data

    [https://arxiv.org/abs/2402.14989](https://arxiv.org/abs/2402.14989)

    神经常微分方程（Neural ODEs）的扩展——神经随机微分方程（Neural SDEs）在处理不规则时间序列数据中的稳定性和性能方面提出了重要指导，需要谨慎设计漂移和扩散函数以保持稳定性。

    

    实际时间序列数据中的不规则采样间隔和缺失值对于假设一致间隔和完整数据的传统方法构成挑战。神经常微分方程（Neural ODEs）提供了一种替代方法，利用神经网络与常微分方程求解器结合，通过参数化向量场学习连续潜在表示。神经随机微分方程（Neural SDEs）通过引入扩散项扩展了神经常微分方程，然而在处理不规则间隔和缺失值时，这种添加并不是微不足道的。因此，仔细设计漂移和扩散函数对于保持稳定性和增强性能至关重要，而粗心的选择可能导致出现没有强解、随机破坏或不稳定的Euler离散化等不利的性质，显著影响神经随机微分方程的性能。

    arXiv:2402.14989v1 Announce Type: cross  Abstract: Irregular sampling intervals and missing values in real-world time series data present challenges for conventional methods that assume consistent intervals and complete data. Neural Ordinary Differential Equations (Neural ODEs) offer an alternative approach, utilizing neural networks combined with ODE solvers to learn continuous latent representations through parameterized vector fields. Neural Stochastic Differential Equations (Neural SDEs) extend Neural ODEs by incorporating a diffusion term, although this addition is not trivial, particularly when addressing irregular intervals and missing values. Consequently, careful design of drift and diffusion functions is crucial for maintaining stability and enhancing performance, while incautious choices can result in adverse properties such as the absence of strong solutions, stochastic destabilization, or unstable Euler discretizations, significantly affecting Neural SDEs' performance. In 
    
[^128]: LongAgent: 通过多智能体协作将语言模型扩展到128K上下文

    LongAgent: Scaling Language Models to 128k Context through Multi-Agent Collaboration

    [https://arxiv.org/abs/2402.11550](https://arxiv.org/abs/2402.11550)

    LongAgent通过多智能体协作将语言模型扩展到128K上下文，并在长文本处理方面表现出潜在的优越性。

    

    大型语言模型（LLMs）在理解语言和执行复杂推理任务方面表现出色。然而，具有长上下文窗口的LLMs以其昂贵的训练成本和高推理延迟而臭名昭著。即使是最先进的模型如GPT-4和Claude2在处理超过$100k$标记的输入时也经常出错，这种现象也被称为\textit{中间迷失}。在本文中，我们提出了基于多智能体协作的方法\textsc{LongAgent}，将LLMs（例如LLaMA）扩展到128K上下文，并展示出在长文本处理方面可能优于GPT-4的潜力。在\textsc{LongAgent}中，一位领导者负责理解用户意图并指导团队成员从文档中获取信息。由于成员存在幻觉，领导者从几十到数百名成员的回应中获取准确信息并非易事。

    arXiv:2402.11550v1 Announce Type: cross  Abstract: Large language models (LLMs) have demonstrated impressive performance in understanding language and executing complex reasoning tasks. However, LLMs with long context windows have been notorious for their expensive training costs and high inference latency. Even the most advanced models such as GPT-4 and Claude2 often make mistakes when processing inputs of over $100k$ tokens, a phenomenon also known as \textit{lost in the middle}. In this paper, we propose \textsc{LongAgent}, a method based on multi-agent collaboration, which scales LLMs (e.g., LLaMA) to a context of 128K and demonstrates potential superiority in long-text processing compared to GPT-4. In \textsc{LongAgent}, a leader is responsible for understanding user intent and directing team members to acquire information from documents. Due to members' hallucinations, it is non-trivial for a leader to obtain accurate information from the responses of dozens to hundreds of member
    
[^129]: 多个LLM之间的网络形成与动态

    Network Formation and Dynamics Among Multi-LLMs

    [https://arxiv.org/abs/2402.10659](https://arxiv.org/abs/2402.10659)

    分析了多个LLM在社交网络中的行为，发现它们在给定网络结构并被询问形成网络偏好时表现出与人类社交动态一致的原则。

    

    社交网络影响行为、偏好和关系，在人类社会中对信息和规范的传播起着至关重要的作用。随着大型语言模型（LLMs）越来越多地融入社交和专业环境中，理解它们在社交网络和互动背景下的行为变得至关重要。我们的研究分析了标准网络结构和现实世界网络的行为，以确定多个LLMs的动态是否与人类社交动态一致。我们探讨了各种社交网络原则，包括微观层面的概念，如偏爱附着、三角闭合和同似性，以及宏观层面的概念，如社区结构和小世界现象。我们的研究发现表明，当向LLMs提供网络结构并询问它们对网络形成的偏好时，它们表现出所有这些原则。

    arXiv:2402.10659v1 Announce Type: cross  Abstract: Social networks influence behaviors, preferences, and relationships and play a crucial role in the dissemination of information and norms within human societies. As large language models (LLMs) increasingly integrate into social and professional environments, understanding their behavior within the context of social networks and interactions becomes essential. Our study analyzes the behaviors of standard network structures and real-world networks to determine whether the dynamics of multiple LLMs align with human social dynamics. We explore various social network principles, including micro-level concepts such as preferential attachment, triadic closure, and homophily, as well as macro-level concepts like community structure and the small-world phenomenon. Our findings suggest that LLMs demonstrate all these principles when they are provided with network structures and asked about their preferences regarding network formation. Furtherm
    
[^130]: SGS-SLAM：基于高斯点云的语义稠密SLAM

    SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM

    [https://arxiv.org/abs/2402.03246](https://arxiv.org/abs/2402.03246)

    SGS-SLAM是一种基于三维高斯点云的语义稠密SLAM系统，通过多通道优化和关键帧优化，实现了高质量的重建和精确的语义分割。

    

    语义理解在稠密同时定位和建图（SLAM）中起着关键作用，有助于全面的场景解析。最近将高斯点云集成到SLAM系统中的进展表明，通过使用显式的三维高斯表示，可以生成高质量的渲染效果。基于这一进展，我们提出了SGS-SLAM，这是第一个基于三维高斯点云的语义稠密视觉SLAM系统，它不仅提供精确的三维语义分割，还实现了高保真度的重建。具体而言，我们提出在建图过程中采用多通道优化，将外观、几何和语义约束与关键帧优化相结合，以提高重建质量。大量实验证明SGS-SLAM在相机位姿估计、地图重建和语义分割方面表现出了最先进的性能，优于现有方法同时保持实时渲染。

    Semantic understanding plays a crucial role in Dense Simultaneous Localization and Mapping (SLAM), facilitating comprehensive scene interpretation. Recent advancements that integrate Gaus- sian Splatting into SLAM systems have demonstrated its effectiveness in generating high-quality renderings through the use of explicit 3D Gaussian representations. Building on this progress, we propose SGS-SLAM, the first semantic dense visual SLAM system grounded in 3D Gaussians, which provides precise 3D semantic segmentation alongside high-fidelity reconstructions. Specifically, we propose to employ multi-channel optimization during the mapping process, integrating appearance, geometric, and semantic constraints with key-frame optimization to enhance reconstruction quality. Extensive experiments demonstrate that SGS-SLAM delivers state-of-the-art performance in camera pose estimation, map reconstruction, and semantic segmentation, outperforming existing methods meanwhile preserving real-time rende
    
[^131]: CERM: 通过情感分析进行基于文献的上下文感知发现

    CERM: Context-aware Literature-based Discovery via Sentiment Analysis

    [https://arxiv.org/abs/2402.01724](https://arxiv.org/abs/2402.01724)

    CERM是一个通过情感分析进行基于文献的上下文感知发现的系统，旨在理解食品与健康之间的关系。通常情况下，基于食材营养成分或基于标记数据的计算模型已被用于食谱推荐和分析系统。然而，本研究提出了一种增强模型，通过捕捉食材与生物医学概念之间的固有关系，利用标记和未标记的数据来更好地支持食品相关研究。

    

    鉴于生物医学出版物的丰富，我们引入了一项情感分析任务来理解食品与健康之间的关系。之前将健康纳入食谱推荐和分析系统的尝试主要集中在食材营养成分上，或者利用基于标记数据的基本计算模型进行训练。捕捉食材和生物医学概念之间固有关系的增强模型对于食品相关研究更有益处，鉴于生物医学文本中的丰富信息。考虑到昂贵的数据标记过程，这些模型应该有效利用标记和未标记的数据。本文介绍了一项名为实体关系情感分析（ERSA）的新任务，该任务基于实体对捕捉文本的情感。ERSA扩展了广泛研究的基于方面的情感分析（ABSA）任务。具体而言，我们的研究集中在应用于生物医学文本的ERSA任务上，重点关注(entity-ent

    Driven by the abundance of biomedical publications, we introduce a sentiment analysis task to understand food-health relationship. Prior attempts to incorporate health into recipe recommendation and analysis systems have primarily focused on ingredient nutritional components or utilized basic computational models trained on curated labeled data. Enhanced models that capture the inherent relationship between food ingredients and biomedical concepts can be more beneficial for food-related research, given the wealth of information in biomedical texts. Considering the costly data labeling process, these models should effectively utilize both labeled and unlabeled data. This paper introduces Entity Relationship Sentiment Analysis (ERSA), a new task that captures the sentiment of a text based on an entity pair. ERSA extends the widely studied Aspect Based Sentiment Analysis (ABSA) task. Specifically, our study concentrates on the ERSA task applied to biomedical texts, focusing on (entity-ent
    
[^132]: 基于深度学习的农业推荐系统：一种多变量天气预测方法

    Agricultural Recommendation System based on Deep Learning: A Multivariate Weather Forecasting Approach

    [https://arxiv.org/abs/2401.11410](https://arxiv.org/abs/2401.11410)

    提出了一种基于深度学习和天气预测的农业推荐系统，旨在解决孟加拉国农业面临的天气不利因素对粮食生产的影响，以实现盈利、可持续和农民友好的农业实践。

    

    孟加拉国主要是一个农业国家，农业部门对于加快经济增长和保障人民粮食安全起着至关重要的作用。虽然孟加拉国劳动密集型农业取得了粮食产量稳步增长，但常常受到不利天气条件的影响，如暴雨、低温和干旱。因此，这些因素严重影响了粮食生产，使得国家的粮食安全受到威胁。为了实现盈利、可持续且农民友好的农业实践，本文提出了一种基于天气预测模型的基于上下文的作物推荐系统。

    arXiv:2401.11410v2 Announce Type: replace-cross  Abstract: Bangladesh is predominantly an agricultural country, where the agrarian sector plays an essential role in accelerating economic growth and enabling the food security of the people. The performance of this sector has an overwhelming impact on the primary macroeconomic objectives like food security, employment generation, poverty alleviation, human resources development, and other economic and social forces. Although Bangladesh's labor-intensive agriculture has achieved steady increases in food grain production, it often suffered from unfavorable weather conditions such as heavy rainfall, low temperature, and drought. Consequently, these factors hinder the production of food substantially, putting the country's overall food security in danger. In order to have a profitable, sustainable, and farmer-friendly agricultural practice, this paper proposes a context-based crop recommendation system powered by a weather forecast model. Wi
    
[^133]: 学习类人表示以实现学习类人价值观

    Learning Human-like Representations to Enable Learning Human Values

    [https://arxiv.org/abs/2312.14106](https://arxiv.org/abs/2312.14106)

    通过学习类人的表示，可以实现机器学习系统符合人类价值观，支持伦理等多方面的价值对齐。

    

    如何构建与人类价值观相一致的人工智能系统，以避免造成伤害或违反社会对可接受行为的标准？我们认为，人类与人工智能代理之间的表征对齐有助于价值观的对齐。使人工智能系统学习类人类对世界的表示具有许多已知好处，包括提高泛化能力、增强对领域转移的稳健性和提高少样本学习性能。我们提出，这种机器学习（ML）模型与人类之间的表示对齐也可以支持价值对齐，使ML系统遵循人类价值观和社会规范。我们关注伦理学作为价值对齐的一个方面，并在多臂老虎机设置中使用各种方法训练ML代理，其中奖励反映所选行动的道德可接受性。我们使用一个合成实验来证明代理与环境之间的表示对齐

    arXiv:2312.14106v2 Announce Type: replace  Abstract: How can we build AI systems that are aligned with human values to avoid causing harm or violating societal standards for acceptable behavior? We argue that representational alignment between humans and AI agents facilitates value alignment. Making AI systems learn human-like representations of the world has many known benefits, including improving generalization, robustness to domain shifts, and few-shot learning performance. We propose that this kind of representational alignment between machine learning (ML) models and humans can also support value alignment, allowing ML systems to conform to human values and societal norms. We focus on ethics as one aspect of value alignment and train ML agents using a variety of methods in a multi-armed bandit setting, where rewards reflect the moral acceptability of the chosen action. We use a synthetic experiment to demonstrate that agents' representational alignment with the environment bounds
    
[^134]: 模仿好的并避免坏的：安全强化学习的增量方法

    Imitate the Good and Avoid the Bad: An Incremental Approach to Safe Reinforcement Learning

    [https://arxiv.org/abs/2312.10385](https://arxiv.org/abs/2312.10385)

    提出了一种不修改基于轨迹成本约束的方法，在安全强化学习中通过模仿好的轨迹和避免坏的轨迹来改进策略。

    

    在强化学习（RL）中执行安全动作的流行框架是约束RL，其中利用基于轨迹的成本约束（或其他成本度量）来执行安全操作，更重要的是在最大化期望奖励的同时执行这些约束。最近解决约束RL的方法将基于轨迹的成本约束转换为一个替代问题，可以通过对RL方法进行轻微修改来解决。这类方法的一个主要缺点是在每个状态上对成本约束进行过度或不足估计。因此，我们提供了一种方法，不修改基于轨迹的成本约束，而是模仿“好”轨迹并避免从逐步改进的策略生成的“坏”轨迹。我们使用一个oracle，利用奖励阈值（随学习变化）和整体成本约束来将轨迹标记为“好”或“坏”。

    arXiv:2312.10385v3 Announce Type: replace-cross  Abstract: A popular framework for enforcing safe actions in Reinforcement Learning (RL) is Constrained RL, where trajectory based constraints on expected cost (or other cost measures) are employed to enforce safety and more importantly these constraints are enforced while maximizing expected reward. Most recent approaches for solving Constrained RL convert the trajectory based cost constraint into a surrogate problem that can be solved using minor modifications to RL methods. A key drawback with such approaches is an over or underestimation of the cost constraint at each state. Therefore, we provide an approach that does not modify the trajectory based cost constraint and instead imitates ``good'' trajectories and avoids ``bad'' trajectories generated from incrementally improving policies. We employ an oracle that utilizes a reward threshold (which is varied with learning) and the overall cost constraint to label trajectories as ``good''
    
[^135]: 几何图神经网络在3D原子系统中的实践指南

    A Hitchhiker's Guide to Geometric GNNs for 3D Atomic Systems

    [https://arxiv.org/abs/2312.07511](https://arxiv.org/abs/2312.07511)

    几何图神经网络在3D原子系统中以利用物理对称性和化学性质等归纳偏差来学习几何图信息表示而著称。

    

    近年来，几何图神经网络作为首选的机器学习架构崭露头角，支持从蛋白结构预测到分子模拟和材料生成等应用，其独特之处在于利用诸如物理对称性和化学性质之类的归纳偏差，学习这些几何图的信息表示。在这篇主观论文中，我们全面而自足地概述了用于3D原子系统的几何图神经网络领域。

    arXiv:2312.07511v2 Announce Type: replace-cross  Abstract: Recent advances in computational modelling of atomic systems, spanning molecules, proteins, and materials, represent them as geometric graphs with atoms embedded as nodes in 3D Euclidean space. In these graphs, the geometric attributes transform according to the inherent physical symmetries of 3D atomic systems, including rotations and translations in Euclidean space, as well as node permutations. In recent years, Geometric Graph Neural Networks have emerged as the preferred machine learning architecture powering applications ranging from protein structure prediction to molecular simulations and material generation. Their specificity lies in the inductive biases they leverage - such as physical symmetries and chemical properties - to learn informative representations of these geometric graphs.   In this opinionated paper, we provide a comprehensive and self-contained overview of the field of Geometric GNNs for 3D atomic systems
    
[^136]: KnowGPT：大型语言模型的黑盒知识注入

    KnowGPT: Black-Box Knowledge Injection for Large Language Models

    [https://arxiv.org/abs/2312.06185](https://arxiv.org/abs/2312.06185)

    KnowGPT是一种为大型语言模型提供黑盒知识注入的框架，通过深度强化学习和多臂老虎机构建最适合每个问题的提示，在三个基准数据集上实验证明其显著提升了知识注入的效果。

    

    生成式大型语言模型（LLMs），如ChatGPT，提供互动式API，可以以人类专家水平回答常见问题。然而，当面临需要特定领域或专业领域知识的问题时，这些模型通常会给出不准确或不正确的响应，这些知识并未包含在它们的训练语料库中。此外，许多最先进的LLMs并非开源，这使得仅使用模型API注入知识具有挑战性。在本研究中，我们介绍了KnowGPT，一种用于LLMs在问答中的黑盒知识注入框架。KnowGPT利用深度强化学习（RL）从知识图中提取相关知识，并使用多臂老虎机（MAB）为每个问题构建最合适的提示。我们在三个基准数据集上进行了大量实验，展示了KnowGPT显著增强了现有方法。值得注意的是，KnowGPT平均改进了23%。

    arXiv:2312.06185v2 Announce Type: replace-cross  Abstract: Generative Large Language Models (LLMs), such as ChatGPT, offer interactive APIs that can answer common questions at a human-expert level. However, these models often give inaccurate or incorrect responses when faced with questions requiring domain-specific or professional-specific knowledge not covered in their training corpus. Furthermore, many state-of-the-art LLMs are not open-source, making it challenging to inject knowledge with model APIs only. In this work, we introduce KnowGPT, a black-box knowledge injection framework for LLMs in question answering. KnowGPT leverages deep reinforcement learning (RL) to extract relevant knowledge from Knowledge Graphs (KGs) and use Multi-Armed Bandit (MAB) to construct the most suitable prompt for each question. Our extensive experiments on three benchmark datasets showcase that KnowGPT significantly enhances the existing methods. Notably, KnowGPT achieves an average improvement of 23.
    
[^137]: TimeDRL：多变量时间序列的解缠表示学习

    TimeDRL: Disentangled Representation Learning for Multivariate Time-Series

    [https://arxiv.org/abs/2312.04142](https://arxiv.org/abs/2312.04142)

    TimeDRL是一个具有解缠双层嵌入的通用多变量时间序列表示学习框架，通过时间戳级别和实例级别的嵌入之间的解缠派生以及时间戳-预测和实例-对比任务的利用，实现了学习丰富表示并解决归纳偏差的目标。

    

    多变量时间序列数据在许多现实世界应用中（例如医疗保健和工业）非常具有信息量，但由于缺乏标签和高维度而具有挑战性。最近的自监督学习研究显示了在学习丰富表示而不依赖于标签的潜力，但它们在学习解缠嵌入和解决归纳偏差（例如变换不变性）方面还有不足。为了解决这些挑战，我们提出了TimeDRL，一个具有解缠双层嵌入的通用多变量时间序列表示学习框架。TimeDRL的三个新颖特征为：（i）使用[CLS]令牌策略从打补丁的时间序列数据中解缠时间戳级和实例级嵌入；（ii）利用时间戳预测和实例对比任务进行解缠表示学习，前者优化时间戳级别

    arXiv:2312.04142v2 Announce Type: replace-cross  Abstract: Multivariate time-series data in numerous real-world applications (e.g., healthcare and industry) are informative but challenging due to the lack of labels and high dimensionality. Recent studies in self-supervised learning have shown their potential in learning rich representations without relying on labels, yet they fall short in learning disentangled embeddings and addressing issues of inductive bias (e.g., transformation-invariance). To tackle these challenges, we propose TimeDRL, a generic multivariate time-series representation learning framework with disentangled dual-level embeddings. TimeDRL is characterized by three novel features: (i) disentangled derivation of timestamp-level and instance-level embeddings from patched time-series data using a [CLS] token strategy; (ii) utilization of timestamp-predictive and instance-contrastive tasks for disentangled representation learning, with the former optimizing timestamp-lev
    
[^138]: Jellyfish：一个用于数据预处理的大型语言模型

    Jellyfish: A Large Language Model for Data Preprocessing

    [https://arxiv.org/abs/2312.01678](https://arxiv.org/abs/2312.01678)

    这项研究探讨了在数据挖掘中利用大型语言模型进行数据预处理的方法，通过指导调整本地LLMs来解决通用数据预处理问题，确保数据安全并进行进一步调整

    

    这篇论文探讨了在数据挖掘管道中将原始数据转换为有利于简单处理的干净格式的数据预处理（DP）中LLMs的利用。与使用LLMs为DP设计通用解决方案引起了兴趣相比，最近在这一领域的倡议通常依赖于GPT API，引发了不可避免的数据泄霏担忧。与这些方法不同，我们考虑将指导调整本地LLMs（7-13B模型）作为通用DP问解器。我们选择了代表性DP任务的四组数据集，并利用针对DP定制的序列化和知识注入技术构建了指导调整数据。因此，指导调整的LLMs使用户能够为DP手动制定指导。同时，它们可以在本地、单一和价格低廉的GPU上运行，确保数据安全并实现进一步调整。我们的实验表明，我们为DP指导构建的数据集

    arXiv:2312.01678v4 Announce Type: replace  Abstract: This paper explores the utilization of LLMs for data preprocessing (DP), a crucial step in the data mining pipeline that transforms raw data into a clean format conducive to easy processing. Whereas the use of LLMs has sparked interest in devising universal solutions to DP, recent initiatives in this domain typically rely on GPT APIs, raising inevitable data breach concerns. Unlike these approaches, we consider instruction-tuning local LLMs (7 - 13B models) as universal DP ask solver. We select a collection of datasets across four representative DP tasks and construct instruction-tuning data using serialization and knowledge injection techniques tailored to DP. As such, the instruction-tuned LLMs empower users to manually craft instructions for DP. Meanwhile, they can operate on a local, single, and low-priced GPU, ensuring data security and enabling further tuning. Our experiments show that our dataset constructed for DP instruction
    
[^139]: MLLMs增强视觉-语言表示学习

    MLLMs-Augmented Visual-Language Representation Learning

    [https://arxiv.org/abs/2311.18765](https://arxiv.org/abs/2311.18765)

    MLLMs通过为图像-文本数据集建立更丰富的图像-文本关联，以增强视觉-语言表示学习，并通过“文本剪切”方法来避免偏见引入，显著提高了图像-文本检索的性能。

    

    arXiv:2311.18765v3 公告类型: replace-cross 视觉-语言预训练在许多多模态任务中取得了显著成功，这在很大程度上归功于大规模图像-文本数据集的可用性。在这项工作中，我们证明了多模态大型语言模型（MLLMs）可以通过为图像-文本数据集建立更丰富的图像-文本关联来加强视觉-语言表示学习。我们的方法很简单，利用MLLMs为每个图像扩展多个不同的标题。为了防止MLLMs的幻觉和单调语言风格引入的偏见，我们提出了“文本剪切”来保持扩展标题的质量和可用性。在图像-文本检索中，在不引入额外的训练成本的情况下，我们的方法在精调和零-shot设置下一致地在Recall@1上获得了5.6 ~ 35.0和16.8 ~ 46.1的改进。值得注意的是，我们获得了与在目标数据集上进行微调相当的零-shot结果。

    arXiv:2311.18765v3 Announce Type: replace-cross  Abstract: Visual-language pre-training has achieved remarkable success in many multi-modal tasks, largely attributed to the availability of large-scale image-text datasets. In this work, we demonstrate that Multi-modal Large Language Models (MLLMs) can enhance visual-language representation learning by establishing richer image-text associations for image-text datasets. Our approach is simple, utilizing MLLMs to extend multiple diverse captions for each image. To prevent the bias introduced by MLLMs' hallucinations and monotonous language styles, we propose "text shearing" to maintain the quality and availability of extended captions. In image-text retrieval, without introducing additional training cost, our method consistently obtains 5.6 ~ 35.0 and 16.8 ~ 46.1 improvement on Recall@1 under the fine-tuning and zero-shot settings, respectively. Notably, we obtain zero-shot results that are comparable to fine-tuning on target datasets, wh
    
[^140]: 病理报告的多实例生成用于千亿像素全切片图像

    WsiCaption: Multiple Instance Generation of Pathology Reports for Gigapixel Whole-Slide Images

    [https://arxiv.org/abs/2311.16480](https://arxiv.org/abs/2311.16480)

    研究提出了一种基于多实例生成模型的方法，能够生成千亿像素全切片图像的病理报告，实验结果表明该模型能够产生包含多个临床线索的病理报告。

    

    全切片图像是用于癌症诊断和治疗的数字病理学的基础。撰写病理报告对经验不足的病理学家来说是费时且容易出错的。为了减少工作量并改善临床自动化，我们研究了如何生成给定全切片图像的病理报告。在数据端，我们整理了最大的WSI-文本数据集（TCGA-PathoText）。具体来说，我们通过识别和清理TCGA中叙述诊断幻灯片的病理报告，收集了近1万对高质量的WSI-文本配对，供视觉-语言模型使用。在模型端，我们提出了可以为千亿像素WSI生成病理报告的多实例生成模型（MI-Gen）。我们在TCGA-PathoText的最大子集上对我们的模型进行了基准测试。实验结果表明，我们的模型可以生成包含多个临床线索的病理报告。此外，WSI-文本预测可被视为一种方法。

    arXiv:2311.16480v2 Announce Type: replace-cross  Abstract: Whole slide images are the foundation of digital pathology for the diagnosis and treatment of carcinomas. Writing pathology reports is laborious and error-prone for inexperienced pathologists. To reduce the workload and improve clinical automation, we investigate how to generate pathology reports given whole slide images. On the data end, we curated the largest WSI-text dataset (TCGA-PathoText). In specific, we collected nearly 10000 high-quality WSI-text pairs for visual-language models by recognizing and cleaning pathology reports which narrate diagnostic slides in TCGA. On the model end, we propose the multiple instance generative model (MI-Gen) which can produce pathology reports for gigapixel WSIs. We benchmark our model on the largest subset of TCGA-PathoText. Experimental results show our model can generate pathology reports which contain multiple clinical clues. Furthermore, WSI-text prediction can be seen as an approac
    
[^141]: 面向安全的因果表示方法用于自动驾驶中值得信赖的离线强化学习

    Safety-aware Causal Representation for Trustworthy Offline Reinforcement Learning in Autonomous Driving

    [https://arxiv.org/abs/2311.10747](https://arxiv.org/abs/2311.10747)

    本文提出了一种面向安全的因果表示方法FUSION，在自动驾驶中的离线强化学习中利用结构化情景信息促进泛化的端到端驾驶策略学习。

    

    在自动驾驶领域，离线强化学习方法在解决来自离线数据集的顺序决策问题方面表现出显著的效果。然而，在各种安全关键场景中保持安全性仍然是一个重要挑战，因为离线数据集中缺乏长尾和无法预见的场景。在本文中，我们引入了saFety-aware strUctured Scenario representatION (FUSION)，这是一种离线强化学习中的开创性表示学习方法，通过利用结构化场景信息促进学习可泛化的端到端驾驶策略。FUSION利用分解奖励、成本、状态和动作空间之间的因果关系，构建了一个在动态交通环境中进行结构化顺序推理的框架。我们在自动驾驶领域的两个典型真实世界设定下进行了广泛的评估。

    arXiv:2311.10747v3 Announce Type: replace-cross  Abstract: In the domain of autonomous driving, the offline Reinforcement Learning~(RL) approaches exhibit notable efficacy in addressing sequential decision-making problems from offline datasets. However, maintaining safety in diverse safety-critical scenarios remains a significant challenge due to long-tailed and unforeseen scenarios absent from offline datasets. In this paper, we introduce the saFety-aware strUctured Scenario representatION (FUSION), a pioneering representation learning method in offline RL to facilitate the learning of a generalizable end-to-end driving policy by leveraging structured scenario information. FUSION capitalizes on the causal relationships between the decomposed reward, cost, state, and action space, constructing a framework for structured sequential reasoning in dynamic traffic environments. We conduct extensive evaluations in two typical real-world settings of the distribution shift in autonomous vehicl
    
[^142]: 推理链上的欺骗性语义快捷方式：模型在没有幻觉的情况下能走多远？

    Deceptive Semantic Shortcuts on Reasoning Chains: How Far Can Models Go without Hallucination?

    [https://arxiv.org/abs/2311.09702](https://arxiv.org/abs/2311.09702)

    本研究探讨了大型语言模型存在的幻觉和不忠实推理问题，提出一种新的探测方法和基准测试以研究LLMs在推理过程中是否会采取欺骗性语义快捷方式。

    

    尽管大型语言模型（LLMs）近期取得了显著进展，并在众多基准测试中表现出色，但最近的研究揭示了LLMs存在幻觉和不忠实推理的问题。本研究探讨了一种特定类型由语义关联引起的幻觉。具体来说，我们调查了LLMs在提示中是否会因为某些关键字/实体偏见而采取捷径，而不是遵循正确的推理路径。为了量化这一现象，我们提出了一种名为EureQA的新型探测方法和基准测试。我们从LLMs会以绝对确定性正确回答的问题开始，然后递归地用证据句子遮蔽重要实体，要求模型在回答问题之前找到根据证据链条遮蔽的实体。

    arXiv:2311.09702v2 Announce Type: replace-cross  Abstract: Despite the recent advancement in large language models (LLMs) and their high performances across numerous benchmarks, recent research has unveiled that LLMs suffer from hallucinations and unfaithful reasoning. This work studies a specific type of hallucination induced by semantic associations. Specifically, we investigate to what extent LLMs take shortcuts from certain keyword/entity biases in the prompt instead of following the correct reasoning path. To quantify this phenomenon, we propose a novel probing method and benchmark called EureQA. We start from questions that LLMs will answer correctly with utmost certainty, and mask the important entity with evidence sentence recursively, asking models to find masked entities according to a chain of evidence before answering the question.   During the construction of the evidence, we purposefully replace semantic clues (entities) that may lead to the correct answer with distractor
    
[^143]: Agent Lumos: 统一和模块化训练开源语言代理

    Agent Lumos: Unified and Modular Training for Open-Source Language Agents

    [https://arxiv.org/abs/2311.05657](https://arxiv.org/abs/2311.05657)

    Agent Lumos提出了一种统一和模块化的框架，通过规划模块学习高级子目标生成，训练接地模块将其转化为动作，促进广泛互动任务应用。

    

    闭源代理存在诸多问题，如缺乏负担得起性、透明度和可重复性，特别是在复杂的互动任务中。这促使了开源替代方案的发展。我们介绍了 LUMOS，这是第一个为训练开源 LLM-based 代理而设计的框架之一。LUMOS具有可学习、统一和模块化的架构，其中包括一个学习高级子目标生成的规划模块，以及一个训练有素的接地模块，用于使用执行模块中的各种工具将这些转化为动作。这种设计允许模块化升级，并更广泛地适用于不同的互动任务。为了促进通用代理学习，我们收集了源自各种复杂互动任务中不同地面真实推理原理的大规模、统一和高质量的训练注释。在9个数据集上，LUMOS表现出了几个关键优势：（1）LUMOS在多个较大的开源a

    arXiv:2311.05657v2 Announce Type: replace  Abstract: Closed-source agents suffer from several issues such as a lack of affordability, transparency, and reproducibility, particularly on complex interactive tasks. This motivates the development of open-source alternatives. We introduce LUMOS, one of the first frameworks for training open-source LLM-based agents. LUMOS features a learnable, unified, and modular architecture with a planning module that learns high-level subgoal generation, and a grounding module trained to translate these into actions using various tools in the execution module. The design allows for modular upgrades and wider applicability to diverse interactive tasks. To foster generalizable agent learning, we collect large-scale, unified, and high-quality training annotations derived from diverse ground-truth reasoning rationales across various complex interactive tasks. On 9 datasets, LUMOS exhibits several key advantages: (1) LUMOS excels multiple larger open-source a
    
[^144]: 通过随机化使基于偏好反馈的强化学习变得高效

    Making RL with Preference-based Feedback Efficient via Randomization

    [https://arxiv.org/abs/2310.14554](https://arxiv.org/abs/2310.14554)

    在基于偏好反馈的强化学习中，通过引入随机化设计的算法在线性MDP模型下表现出样本高效性和多项式运行时间，并通过随机化主动学习过程最小化了查询复杂性。

    

    强化学习算法需要从人类反馈中学习，而且在统计复杂性、计算复杂性和查询复杂性方面需要高效。本研究考虑了使用偏好来表达对轨迹对的反馈的强化学习设置。在线性MDP模型中，通过在算法设计中引入随机化，我们提出了一种算法，具有样本高效性（即具有近乎最优的最坏情况遗憾界限）和多项式运行时间（即计算复杂度与相关参数是多项式关系）。我们的算法进一步通过一种新颖的随机化主动学习过程最小化了查询复杂性。特别地，我们的算法展示了遗憾界限和查询复杂性之间的近乎最优折衷。为了将结果推广到更一般的非线性函数逼近，我们设计了一个受线性MDP模型的随机化算法启发而来的基于模型的随机化算法。

    arXiv:2310.14554v2 Announce Type: replace-cross  Abstract: Reinforcement Learning algorithms that learn from human feedback (RLHF) need to be efficient in terms of statistical complexity, computational complexity, and query complexity. In this work, we consider the RLHF setting where the feedback is given in the format of preferences over pairs of trajectories. In the linear MDP model, using randomization in algorithm design, we present an algorithm that is sample efficient (i.e., has near-optimal worst-case regret bounds) and has polynomial running time (i.e., computational complexity is polynomial with respect to relevant parameters). Our algorithm further minimizes the query complexity through a novel randomized active learning procedure. In particular, our algorithm demonstrates a near-optimal tradeoff between the regret bound and the query complexity. To extend the results to more general nonlinear function approximation, we design a model-based randomized algorithm inspired by th
    
[^145]: 语言模型击败扩散模型--分词器是视觉生成的关键

    Language Model Beats Diffusion -- Tokenizer is Key to Visual Generation

    [https://arxiv.org/abs/2310.05737](https://arxiv.org/abs/2310.05737)

    分词器是视觉生成的关键，新的视频分词器MAGVIT-v2使得大型语言模型LLMs在图像和视频生成任务上胜过扩散模型，并在视频压缩和有效表示学习方面表现优异。

    

    大型语言模型(LLMs)是语言生成任务中的主导模型，但在图像和视频生成方面表现不如扩散模型。为了有效地利用LLMs进行视觉生成，一个至关重要的组件是视觉分词器，它将像素空间输入映射到适合LLM学习的离散标记中。本文介绍了MAGVIT-v2，一个视频分词器，旨在使用共同的标记词汇为视频和图像生成简洁和富有表现力的标记。配备了这个新的分词器，我们展示了LLMs在标准图像和视频生成基准上优于扩散模型，包括ImageNet和Kinetics。此外，我们证明了我们的分词器在两项任务上超过了先前表现最佳的视频分词器：(1)根据人类评估，视频压缩与下一代视频编解码器(VCC)相媲美，(2)学习有效的表示。

    arXiv:2310.05737v2 Announce Type: replace-cross  Abstract: While Large Language Models (LLMs) are the dominant models for generative tasks in language, they do not perform as well as diffusion models on image and video generation. To effectively use LLMs for visual generation, one crucial component is the visual tokenizer that maps pixel-space inputs to discrete tokens appropriate for LLM learning. In this paper, we introduce MAGVIT-v2, a video tokenizer designed to generate concise and expressive tokens for both videos and images using a common token vocabulary. Equipped with this new tokenizer, we show that LLMs outperform diffusion models on standard image and video generation benchmarks including ImageNet and Kinetics. In addition, we demonstrate that our tokenizer surpasses the previously top-performing video tokenizer on two more tasks: (1) video compression comparable to the next-generation video codec (VCC) according to human evaluations, and (2) learning effective representati
    
[^146]: RoPE基外推的尺度律

    Scaling Laws of RoPE-based Extrapolation

    [https://arxiv.org/abs/2310.05209](https://arxiv.org/abs/2310.05209)

    本研究提出了RoPE基外推的尺度律，通过调整 RoPE 中的基数和微调文本长度来显著提高大型语言模型的外推性能。

    

    基于Rotary Position Embedding的大型语言模型（LLMs）的外推能力是目前备受关注的话题。用于解决LLMs外推问题的主流方法是通过将RoPE中的10000, $\theta_n={10000}^{-2n/d}$，这个旋转基数，替换为更大的值，并提供更长的微调文本。本研究首先观察到，在预训练上用较小或较大的基数微调RoPE-based LLM，可以显著提高其外推性能。之后，我们提出了RoPE基外推的尺度律，这是一个从周期性的角度描述外推性能与基值以及调整上下文长度之间关系的统一框架。在这个过程中，我们还通过RoPE基外推问题的关键维度介绍了其起源。

    arXiv:2310.05209v2 Announce Type: replace-cross  Abstract: The extrapolation capability of Large Language Models (LLMs) based on Rotary Position Embedding is currently a topic of considerable interest. The mainstream approach to addressing extrapolation with LLMs involves modifying RoPE by replacing 10000, the rotary base of $\theta_n={10000}^{-2n/d}$ in the original RoPE, with a larger value and providing longer fine-tuning text. In this work, we first observe that fine-tuning a RoPE-based LLM with either a smaller or larger base in pre-training context length could significantly enhance its extrapolation performance. After that, we propose \textbf{\textit{Scaling Laws of RoPE-based Extrapolation}}, a unified framework from the periodic perspective, to describe the relationship between the extrapolation performance and base value as well as tuning context length. In this process, we also explain the origin of the RoPE-based extrapolation issue by \textbf{\textit{critical dimension for
    
[^147]: 用大型语言模型解密嵌入空间

    Demystifying Embedding Spaces using Large Language Models

    [https://arxiv.org/abs/2310.04475](https://arxiv.org/abs/2310.04475)

    通过使用大型语言模型（LLMs）直接与嵌入交互，将抽象向量转换为可理解的叙述，使得复杂嵌入数据更具解释性和广泛实用性。

    

    嵌入已经成为表示有关实体、概念和关系的复杂多方面信息的关键手段，以一种紧凑且有用的方式。然而，它们通常难以直接解释。尽管下游任务利用了这些压缩表示，但有意义的解释通常需要使用降维或专门的机器学习可解释性方法进行可视化。本文通过使用大型语言模型（LLMs）直接与嵌入交互，将抽象向量转换为可理解的叙述，从而解决了使这些嵌入更具解释性和广泛实用性的挑战。通过将嵌入注入LLMs，我们实现了对复杂嵌入数据的查询和探索。我们在各种不同的任务上演示了我们的方法，其中包括：增强概念激活向量（CAVs）、传达新颖的嵌入实体等。

    arXiv:2310.04475v2 Announce Type: replace-cross  Abstract: Embeddings have become a pivotal means to represent complex, multi-faceted information about entities, concepts, and relationships in a condensed and useful format. Nevertheless, they often preclude direct interpretation. While downstream tasks make use of these compressed representations, meaningful interpretation usually requires visualization using dimensionality reduction or specialized machine learning interpretability methods. This paper addresses the challenge of making such embeddings more interpretable and broadly useful, by employing Large Language Models (LLMs) to directly interact with embeddings -- transforming abstract vectors into understandable narratives. By injecting embeddings into LLMs, we enable querying and exploration of complex embedding data. We demonstrate our approach on a variety of diverse tasks, including: enhancing concept activation vectors (CAVs), communicating novel embedded entities, and decod
    
[^148]: 量化神经机器翻译中背景依赖性的可信度

    Quantifying the Plausibility of Context Reliance in Neural Machine Translation

    [https://arxiv.org/abs/2310.01188](https://arxiv.org/abs/2310.01188)

    引入了PECoRe框架，用于量化语言模型生成中的上下文使用情况，从而评估上下文感知机器翻译模型的可信度。

    

    本文介绍了一种名为PECoRe的端到端可解释性框架，旨在量化语言模型生成中上下文使用的情况。我们的方法利用模型内部来对比识别生成文本中上下文敏感的目标令牌，并将它们与证明其预测的上下文线索联系起来。我们使用PECORE来量化具有上下文感知的机器翻译模型的可信度，将模型的理由与人类注释在几个层次的话语水平上进行比较。

    arXiv:2310.01188v2 Announce Type: replace-cross  Abstract: Establishing whether language models can use contextual information in a human-plausible way is important to ensure their trustworthiness in real-world settings. However, the questions of when and which parts of the context affect model generations are typically tackled separately, with current plausibility evaluations being practically limited to a handful of artificial benchmarks. To address this, we introduce Plausibility Evaluation of Context Reliance (PECoRe), an end-to-end interpretability framework designed to quantify context usage in language models' generations. Our approach leverages model internals to (i) contrastively identify context-sensitive target tokens in generated texts and (ii) link them to contextual cues justifying their prediction. We use \pecore to quantify the plausibility of context-aware machine translation models, comparing model rationales with human annotations across several discourse-level pheno
    
[^149]: 线性注意力可能就是理解Transformer优化的关键

    Linear attention is (maybe) all you need (to understand transformer optimization)

    [https://arxiv.org/abs/2310.01082](https://arxiv.org/abs/2310.01082)

    研究者通过训练线性Transformer模型解决回归任务，发现这种简单的线性化模型能够重现Transformer训练动态的多个关键方面，表明线性注意力可能是理解Transformer优化的关键。

    

    Transformer的训练因需要仔细设计优化器并使用各种启发式而变得困难。本文通过仔细研究一个简单但经典的线性化浅层Transformer模型，取得了解析Transformer训练细微之处的进展。具体来说，我们训练线性Transformer来解决回归任务，灵感来源于J. von Oswald等人（ICML 2023）和K. Ahn等人（NeurIPS 2023）。最重要的是，我们观察到我们提出的线性化模型能够重现Transformer训练动态的几个重要方面。因此，本文得到的结果表明，一个简单的线性化Transformer模型实际上可能是理解Transformer优化的有价值、现实的抽象。

    arXiv:2310.01082v2 Announce Type: replace-cross  Abstract: Transformer training is notoriously difficult, requiring a careful design of optimizers and use of various heuristics. We make progress towards understanding the subtleties of training Transformers by carefully studying a simple yet canonical linearized shallow Transformer model. Specifically, we train linear Transformers to solve regression tasks, inspired by J.~von Oswald et al.~(ICML 2023), and K.~Ahn et al.~(NeurIPS 2023). Most importantly, we observe that our proposed linearized models can reproduce several prominent aspects of Transformer training dynamics. Consequently, the results obtained in this paper suggest that a simple linearized Transformer model could actually be a valuable, realistic abstraction for understanding Transformer optimization.
    
[^150]: Pink: 揭示引用理解在多模态LLMs中的能力

    Pink: Unveiling the Power of Referential Comprehension for Multi-modal LLMs

    [https://arxiv.org/abs/2310.00582](https://arxiv.org/abs/2310.00582)

    提出了一个新框架来增强MLLMs细粒度图像理解能力，包括通过低成本构建指令调优数据集和引入自一致的自举方法扩展密集目标注释等关键方法。

    

    多模态大型语言模型（MLLMs）在各种多模态任务中表现出了显著的能力。然而，它们在细粒度图像理解任务中的性能仍然有限。为了解决这个问题，本文提出了一个增强MLLMs细粒度图像理解能力的新框架。具体地，我们提出了一种通过利用现有数据集中的注释来以低成本构建指令调优数据集的新方法。还引入了一种自一致的自举方法，将现有的密集目标注释扩展为高质量的引用表达-边界框对。这些方法使得生成包含对细粒度图像感知至关重要的广泛基本能力的高质量指令数据成为可能。另外，我们认为在指令调优过程中应该调整视觉编码器，以减轻完成图像感知和指令理解之间的差距。

    arXiv:2310.00582v3 Announce Type: replace-cross  Abstract: Multi-modal Large Language Models (MLLMs) have shown remarkable capabilities in various multi-modal tasks. Nevertheless, their performance in fine-grained image understanding tasks is still limited. To address this issue, this paper proposes a new framework to enhance the fine-grained image understanding abilities of MLLMs. Specifically, we present a new method for constructing the instruction tuning dataset at a low cost by leveraging annotations in existing datasets. A self-consistent bootstrapping method is also introduced to extend existing dense object annotations into high-quality referring-expression-bounding-box pairs. These methods enable the generation of high-quality instruction data which includes a wide range of fundamental abilities essential for fine-grained image perception. Moreover, we argue that the visual encoder should be tuned during instruction tuning to mitigate the gap between full image perception and 
    
[^151]: CRAFT: 通过创建和检索专业工具集定制LLMs

    CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets

    [https://arxiv.org/abs/2309.17428](https://arxiv.org/abs/2309.17428)

    CRAFT提出了一个通用工具创建和检索框架，能够定制LLMs，为其创建特定任务的工具集，并使用这些工具集增强其解决复杂任务的能力。

    

    大语言模型（LLMs）通常通过生成代码片段并通过特定任务的应用程序编程接口（API）执行它们来解决复杂任务。本文介绍了CRAFT，这是一个专门为LLMs创建工具集的通用工具创建和检索框架。它为任务创建了特定的工具集，并为LLMs配备了一个组件，用于从这些集合中检索工具，以增强它们解决复杂任务的能力。

    arXiv:2309.17428v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) are often augmented with tools to solve complex tasks. By generating code snippets and executing them through task-specific Application Programming Interfaces (APIs), they can offload certain functions to dedicated external modules, such as image encoding and performing calculations. However, most existing approaches to augment LLMs with tools are constrained by general-purpose APIs and lack the flexibility for tailoring them to specific tasks. In this work, we present CRAFT, a general tool creation and retrieval framework for LLMs. It creates toolsets specifically curated for the tasks and equips LLMs with a component that retrieves tools from these sets to enhance their capability to solve complex tasks. For each task, we collect specific code solutions by prompting GPT-4 to solve the training examples. Following a validation step ensuring the correctness, these solutions are abstracted into code 
    
[^152]: 通过链接大型语言模型增强私人辅导

    Empowering Private Tutoring by Chaining Large Language Models

    [https://arxiv.org/abs/2309.08112](https://arxiv.org/abs/2309.08112)

    通过链式连接大型语言模型，开发了一种全面智能辅导系统，实现了自动课程规划、个性化指导和灵活测验评估。

    

    人工智能已被应用于在线教育的各个方面，以促进教学和学习。然而，很少有方法致力于完整的AI辅导系统。在这项工作中，我们探讨了一个由最先进的大型语言模型（LLMs）驱动的全面智能辅导系统的开发，涵盖自动课程规划和调整、定制指导以及灵活的测验评估。为了使系统能够经受住长时间交互并满足个性化教育的需求，系统被分解为三个相互连接的核心流程-交互、反思和反应。每个流程都通过链接LLM驱动的工具以及动态更新的记忆模块来实现。工具是LLMs，被提示执行一项特定任务，而记忆是在教育过程中更新的数据存储。学习日志中的统计结果证明了这种方法的有效性。

    arXiv:2309.08112v1 Announce Type: cross  Abstract: Artificial intelligence has been applied in various aspects of online education to facilitate teaching and learning. However, few approaches has been made toward a complete AI-powered tutoring system. In this work, we explore the development of a full-fledged intelligent tutoring system powered by state-of-the-art large language models (LLMs), covering automatic course planning and adjusting, tailored instruction, and flexible quiz evaluation. To make the system robust to prolonged interaction and cater to individualized education, the system is decomposed into three inter-connected core processes-interaction, reflection, and reaction. Each process is implemented by chaining LLM-powered tools along with dynamically updated memory modules. Tools are LLMs prompted to execute one specific task at a time, while memories are data storage that gets updated during education process. Statistical results from learning logs demonstrate the effec
    
[^153]: ChatEDA：基于大型语言模型的自主代理用于EDA

    ChatEDA: A Large Language Model Powered Autonomous Agent for EDA

    [https://arxiv.org/abs/2308.10204](https://arxiv.org/abs/2308.10204)

    该研究介绍了ChatEDA，一个由大型语言模型AutoMage赋能的EDA自主代理，通过有效管理任务计划、脚本生成和任务执行，简化了从RTL到GDSII的设计流程，并证明了其性能优越性。

    

    arXiv:2308.10204v2 公告类型：替换-交叉摘要：集成一系列复杂的电子设计自动化（EDA）工具以增强互操作性是电路设计者关注的重要问题。大型语言模型（LLMs）的最新进展展示了它们在自然语言处理和理解方面的卓越能力，提供了一种新颖的与EDA工具接口的方法。本研究论文介绍了ChatEDA，一个由大型语言模型AutoMage赋能的EDA自主代理，结合作为执行器的EDA工具。ChatEDA通过有效管理任务计划、脚本生成和任务执行，简化了从寄存器传输级（RTL）到图形数据系统第二版（GDSII）的设计流程。通过全面的实验评估，ChatEDA已经证明了其处理各种需求的能力，我们经过精心调优的AutoMage模型在性能上表现出优越性，相较于GPT-4和其他类似的模型。

    arXiv:2308.10204v2 Announce Type: replace-cross  Abstract: The integration of a complex set of Electronic Design Automation (EDA) tools to enhance interoperability is a critical concern for circuit designers. Recent advancements in large language models (LLMs) have showcased their exceptional capabilities in natural language processing and comprehension, offering a novel approach to interfacing with EDA tools. This research paper introduces ChatEDA, an autonomous agent for EDA empowered by a large language model, AutoMage, complemented by EDA tools serving as executors. ChatEDA streamlines the design flow from the Register-Transfer Level (RTL) to the Graphic Data System Version II (GDSII) by effectively managing task planning, script generation, and task execution. Through comprehensive experimental evaluations, ChatEDA has demonstrated its proficiency in handling diverse requirements, and our fine-tuned AutoMage model has exhibited superior performance compared to GPT-4 and other simi
    
[^154]: SSMG：空间语义地图引导扩散模型用于自由形式布局到图像生成

    SSMG: Spatial-Semantic Map Guided Diffusion Model for Free-form Layout-to-Image Generation

    [https://arxiv.org/abs/2308.10156](https://arxiv.org/abs/2308.10156)

    SSMG模型采用特征图作为引导，相比其他方法具有更好的生成质量和空间语义可控性

    

    尽管文本到图像(T2I)生成模型取得了显著进展，但即使是冗长复杂的文本描述仍然难以传达详细的控制。相比之下，布局到图像(L2I)生成旨在从用户指定的布局生成逼真且复杂的场景图像，现已引起人们的关注。然而，现有方法将布局信息转换为标记或RGB图像，用于生成过程中的条件控制，导致个体实例的空间和语义可控性不足。为解决这些限制，我们提出了一种新颖的空间语义地图引导(SSMG)扩散模型，采用从布局中获取的特征图作为引导。由于富含设计良好的特征图内的丰富空间和语义信息，SSMG相比之前的工作实现了更优秀的生成质量，具有足够的空间和语义可控性。此外，我们还提出了

    arXiv:2308.10156v2 Announce Type: replace-cross  Abstract: Despite significant progress in Text-to-Image (T2I) generative models, even lengthy and complex text descriptions still struggle to convey detailed controls. In contrast, Layout-to-Image (L2I) generation, aiming to generate realistic and complex scene images from user-specified layouts, has risen to prominence. However, existing methods transform layout information into tokens or RGB images for conditional control in the generative process, leading to insufficient spatial and semantic controllability of individual instances. To address these limitations, we propose a novel Spatial-Semantic Map Guided (SSMG) diffusion model that adopts the feature map, derived from the layout, as guidance. Owing to rich spatial and semantic information encapsulated in well-designed feature maps, SSMG achieves superior generation quality with sufficient spatial and semantic controllability compared to previous works. Additionally, we propose the 
    
[^155]: 互动指令跟随的多层次组合推理

    Multi-Level Compositional Reasoning for Interactive Instruction Following

    [https://arxiv.org/abs/2308.09387](https://arxiv.org/abs/2308.09387)

    提出了一种名为MCR-Agent的方法，能够通过将任务分解为多个子目标并分别处理它们来解决复杂任务导航和交互的挑战

    

    在本文中，我们提出了一种名为Multi-level Compositional Reasoning Agent（MCR-Agent）的方法，用于解决通过自然语言指令执行家务任务的机器人代理面临的复杂环境导航和与环境中物体交互的挑战。我们通过将任务分解为多个子目标，并单独处理它们以进行更好的导航和交互来应对这一挑战。具体来说，我们学习了一个三级动作策略，分别是高级策略组合控制器推断基于语言指令要执行的一系列可理解的子目标；中级策略通过导航主策略对代理的导航进行判别控制，从而交替地执行导航操作。

    arXiv:2308.09387v2 Announce Type: replace-cross  Abstract: Robotic agents performing domestic chores by natural language directives are required to master the complex job of navigating environment and interacting with objects in the environments. The tasks given to the agents are often composite thus are challenging as completing them require to reason about multiple subtasks, e.g., bring a cup of coffee. To address the challenge, we propose to divide and conquer it by breaking the task into multiple subgoals and attend to them individually for better navigation and interaction. We call it Multi-level Compositional Reasoning Agent (MCR-Agent). Specifically, we learn a three-level action policy. At the highest level, we infer a sequence of human-interpretable subgoals to be executed based on language instructions by a high-level policy composition controller. At the middle level, we discriminatively control the agent's navigation by a master policy by alternating between a navigation po
    
[^156]: 基于分子扩散模型的用于碳捕获的金属有机框架设计的生成人工智能框架

    A generative artificial intelligence framework based on a molecular diffusion model for the design of metal-organic frameworks for carbon capture

    [https://arxiv.org/abs/2306.08695](https://arxiv.org/abs/2306.08695)

    GHP-MOFassemble是一个生成人工智能框架，用于合理和加速设计具有高CO2吸附能力和可合成连接剂的MOFs，通过生成新颖连接剂并与预选金属节点组装成MOFs，在研究其稳定性、化学一致性和CO2吸附量方面展现出独特性和前景。

    

    金属有机框架（MOFs）对CO2捕获具有巨大潜力。然而，在广阔的潜在构建块的化学空间中找到性能最佳的材料在计算和实验上存在巨大挑战。在这里，我们引入了GHP-MOFassemble，这是一个用于合理和加速设计具有高CO2吸附能力和可合成连接剂的MOFs的生成人工智能（AI），高性能框架。GHP-MOFassemble生成新颖的连接剂，并与三种预选金属节点（铜桨轮，锌桨轮，锌四聚体）中的一个组装成具有原始立方拓扑结构的MOFs。GHP-MOFassemble通过分子动力学模拟研究其稳定性和化学一致性，晶体图神经网络和大规模巧合蒙特卡洛模拟来量化其CO2吸附，并对AI生成的MOFs进行筛选和验证，以确保其独特性、可合成性和结构有效性。

    arXiv:2306.08695v2 Announce Type: replace-cross  Abstract: Metal-organic frameworks (MOFs) exhibit great promise for CO2 capture. However, finding the best performing materials poses computational and experimental grand challenges in view of the vast chemical space of potential building blocks. Here, we introduce GHP-MOFassemble, a generative artificial intelligence (AI), high performance framework for the rational and accelerated design of MOFs with high CO2 adsorption capacity and synthesizable linkers. GHP-MOFassemble generates novel linkers, assembled with one of three pre-selected metal nodes (Cu paddlewheel, Zn paddlewheel, Zn tetramer) into MOFs in a primitive cubic topology. GHP-MOFassemble screens and validates AI-generated MOFs for uniqueness, synthesizability, structural validity, uses molecular dynamics simulations to study their stability and chemical consistency, and crystal graph neural networks and Grand Canonical Monte Carlo simulations to quantify their CO2 adsorption
    
[^157]: 图像和视频中可解释的异常检测：一项调研

    Explainable Anomaly Detection in Images and Videos: A Survey

    [https://arxiv.org/abs/2302.06670](https://arxiv.org/abs/2302.06670)

    这项研究提供了针对图像和视频的可解释异常检测方法的首次调研，为机器学习学术界和实际应用提供了重要参考。

    

    异常检测和定位视觉数据（包括图像和视频）在机器学习学术界和应用实际场景中具有重要意义。尽管近年来可视异常检测技术迅速发展，但对于这些黑盒模型的解释以及为何可以区分异常的合理解释却十分稀缺。本文首次提供了一项集中于可解释视觉异常检测方法的调研。我们首先介绍了图像级和视频级异常检测的基本背景。然后，作为本调研的主要内容，我们展示了针对图像和视频的可解释异常检测方法的全面和详尽的文献综述。接下来，我们分析了为什么一些可解释异常检测方法可以应用于图像和视频，而另一些则只能应用于一种模态。此外，我们提供了总结

    arXiv:2302.06670v2 Announce Type: replace-cross  Abstract: Anomaly detection and localization of visual data, including images and videos, are of great significance in both machine learning academia and applied real-world scenarios. Despite the rapid development of visual anomaly detection techniques in recent years, the interpretations of these black-box models and reasonable explanations of why anomalies can be distinguished out are scarce. This paper provides the first survey concentrated on explainable visual anomaly detection methods. We first introduce the basic background of image-level and video-level anomaly detection. Then, as the main content of this survey, a comprehensive and exhaustive literature review of explainable anomaly detection methods for both images and videos is presented. Next, we analyze why some explainable anomaly detection methods can be applied to both images and videos and why others can be only applied to one modality. Additionally, we provide summaries
    
[^158]: 基于传感器增强快挂的朝向的攀岩中下降行为的检测

    Lowering Detection in Sport Climbing Based on Orientation of the Sensor Enhanced Quickdraw

    [https://arxiv.org/abs/2301.10164](https://arxiv.org/abs/2301.10164)

    通过在攀岩快挂上安装的加速度传感器采集数据，实现了在攀岩活动中检测攀岩者下降情况的技术，保护攀岩者隐私和健身房成本的同时提高了效率和便利性。

    

    跟踪攀岩者的活动以改善服务并最大限度地利用他们的基础设施是攀岩健身房关注的焦点。必须从开始分析每个攀岩活动直到攀登者降下来。因此，发现攀岩者下降是至关重要的，因为这标志着攀登结束。必须在保护攀岩者和健身房成本隐私和便利性的同时解决这个问题。为此，开发了一个硬件原型，使用附在墙上的攀岩设备上的加速度传感器收集数据，称为快挂，它连接攀岩绳和螺栓锚点。相应的传感器被配置为节能，因此在攀岩健身房大量使用时在费用和更换所需时间方面变得实用。本文描述了硬件规格，并研究了传感器测得的数据。

    arXiv:2301.10164v2 Announce Type: replace-cross  Abstract: Tracking climbers' activity to improve services and make the best use of their infrastructure is a concern for climbing gyms. Each climbing session must be analyzed from beginning till lowering of the climber. Therefore, spotting the climbers descending is crucial since it indicates when the ascent has come to an end. This problem must be addressed while preserving privacy and convenience of the climbers and the costs of the gyms. To this aim, a hardware prototype is developed to collect data using accelerometer sensors attached to a piece of climbing equipment mounted on the wall, called quickdraw, that connects the climbing rope to the bolt anchors. The corresponding sensors are configured to be energy-efficient, hence become practical in terms of expenses and time consumption for replacement when using in large quantity in a climbing gym. This paper describes hardware specifications, studies data measured by the sensors in u
    
[^159]: 朝向测评和评估Deepfake检测

    Towards Benchmarking and Evaluating Deepfake Detection

    [https://arxiv.org/abs/2203.02115](https://arxiv.org/abs/2203.02115)

    该论文旨在建立一个全面一致的基准，以开发可重复的评估流程，并评估来自多种检测方法的性能，以实现结果的有力比较。

    

    Deepfake检测是通过分析操纵和未操纵视频之间的差异来自动识别操纵媒体的过程。现在自然而然地询问哪些现有的Deepfake检测方法是表现最好的，以确定应该关注哪些研究方向并提供实际指导。然而，由于评估条件在研究中存在不一致性，使用文献中的结果难以进行现有检测方法的合理基准比较。我们的目标是建立一个全面且一致的基准，开发可重复的评估程序，并测量各种检测方法的性能，以便结果可以得到合理比较。我们收集了一个具有挑战性的数据集，其中包含由13种以上不同方法生成的操纵样本，以及来自11种流行的检测方法（9种算法）。

    arXiv:2203.02115v2 Announce Type: replace-cross  Abstract: Deepfake detection automatically recognizes the manipulated medias through the analysis of the difference between manipulated and non-altered videos. It is natural to ask which are the top performers among the existing deepfake detection approaches to identify promising research directions and provide practical guidance. Unfortunately, it's difficult to conduct a sound benchmarking comparison of existing detection approaches using the results in the literature because evaluation conditions are inconsistent across studies. Our objective is to establish a comprehensive and consistent benchmark, to develop a repeatable evaluation procedure, and to measure the performance of a range of detection approaches so that the results can be compared soundly. A challenging dataset consisting of the manipulated samples generated by more than 13 different methods has been collected, and 11 popular detection approaches (9 algorithms) from the 
    
[^160]: mForms: 多模态问答形式填充

    mForms : Multimodal Form-Filling with Question Answering

    [https://arxiv.org/abs/2011.12340](https://arxiv.org/abs/2011.12340)

    本文提出了一种将表单填充任务重新构造为多模态自然语言问答的新方法，通过预训练的QA系统实现表单元素的填充，并通过多任务训练进一步细化表单填充过程。

    

    本文提出了一种新的表单填充方法，将任务重新构造为多模态自然语言问答（QA）。通过首先将GUI表单上的元素（文本字段、按钮、图标等）转化为自然语言问题来实现这种重新构造，这些问题捕捉了元素的多模态语义。在确定表单元素（问题）和用户话语（答案）之间的匹配后，通过一个经过预训练的抽取式QA系统填充表单元素。通过利用预训练的QA模型，而不需要特定于表单的训练，这种表单填充方法是零-shot 的。本文还提出了进一步通过使用多任务训练来细化表单填充的方法，以整合可能大量的连续任务。最后，本文介绍了一个多模态自然语言表单填充数据集Multimodal Forms（mForms），以及一个多模态扩展

    arXiv:2011.12340v3 Announce Type: replace  Abstract: This paper presents a new approach to form-filling by reformulating the task as multimodal natural language Question Answering (QA). The reformulation is achieved by first translating the elements on the GUI form (text fields, buttons, icons, etc.) to natural language questions, where these questions capture the element's multimodal semantics. After a match is determined between the form element (Question) and the user utterance (Answer), the form element is filled through a pre-trained extractive QA system. By leveraging pre-trained QA models and not requiring form-specific training, this approach to form-filling is zero-shot. The paper also presents an approach to further refine the form-filling by using multi-task training to incorporate a potentially large number of successive tasks. Finally, the paper introduces a multimodal natural language form-filling dataset Multimodal Forms (mForms), as well as a multimodal extension of the
    
[^161]: 通过风险估计实现生物医学假设生成的时间正无标记学习

    Temporal Positive-unlabeled Learning for Biomedical Hypothesis Generation via Risk Estimation

    [https://arxiv.org/abs/2010.01916](https://arxiv.org/abs/2010.01916)

    通过正无标记学习捕捉科学术语关系的时间动态

    

    理解病毒、药物和症状等生物医学术语之间的关系对于抗击疾病至关重要。本研究将假设生成（HG）问题表述为动态属性图上未来连接性预测任务，并通过正无标记（PU）学习来捕捉科学术语关系的时间动态。

    arXiv:2010.01916v1 Announce Type: cross  Abstract: Understanding the relationships between biomedical terms like viruses, drugs, and symptoms is essential in the fight against diseases. Many attempts have been made to introduce the use of machine learning to the scientific process of hypothesis generation(HG), which refers to the discovery of meaningful implicit connections between biomedical terms. However, most existing methods fail to truly capture the temporal dynamics of scientific term relations and also assume unobserved connections to be irrelevant (i.e., in a positive-negative (PN) learning setting). To break these limits, we formulate this HG problem as future connectivity prediction task on a dynamic attributed graph via positive-unlabeled (PU) learning. Then, the key is to capture the temporal evolution of node pair (term pair) relations from just the positive and unlabeled data. We propose a variational inference model to estimate the positive prior, and incorporate it in 
    
[^162]: 基于循环注意力步行的半监督分类

    Recurrent Attention Walk for Semi-supervised Classification

    [https://arxiv.org/abs/1910.10266](https://arxiv.org/abs/1910.10266)

    本文提出了一种基于循环注意力步行的方法，使用强化学习设置来探索图中的邻域，找到适合分类未标记目标节点的路径。

    

    在本文中，我们研究了基于图的半监督学习，用于对带属性网络中的节点进行分类，其中节点和边都包含内容信息。最近的方法，如图卷积网络和注意力机制，已被提出来组合一阶邻居并整合相关邻居。然而，考虑所有邻居而不进行先前区分显得昂贵（尤其是在内存方面）。我们提出在强化学习设置中探索邻域，并找到一个经过调整以便对未标记目标节点进行分类的路径。我们让一个代理人（节点分类任务）在图上行走，并决定在哪里前进以最大化分类准确性。我们将图漫步定义为部分可观察的马尔可夫决策过程（POMDP）。所提出的方法灵活地适用于工作在转导和归纳设置中。对四个数据集的广泛实验证明了承认

    arXiv:1910.10266v1 Announce Type: cross  Abstract: In this paper, we study the graph-based semi-supervised learning for classifying nodes in attributed networks, where the nodes and edges possess content information. Recent approaches like graph convolution networks and attention mechanisms have been proposed to ensemble the first-order neighbors and incorporate the relevant neighbors. However, it is costly (especially in memory) to consider all neighbors without a prior differentiation. We propose to explore the neighborhood in a reinforcement learning setting and find a walk path well-tuned for classifying the unlabelled target nodes. We let an agent (of node classification task) walk over the graph and decide where to direct to maximize classification accuracy. We define the graph walk as a partially observable Markov decision process (POMDP). The proposed method is flexible for working in both transductive and inductive setting. Extensive experiments on four datasets demonstrate th
    
[^163]: 合作图遍历用于半监督多标签节点分类

    Collaborative Graph Walk for Semi-supervised Multi-Label Node Classification

    [https://arxiv.org/abs/1910.09706](https://arxiv.org/abs/1910.09706)

    提出了一种名为多标签图遍历的新方法，通过合作式的图遍历策略学习节点标签与图结构属性之间的关系，以及多标签特定任务之间的相关性。

    

    在这项工作中，我们研究了属性图中的半监督多标签节点分类问题。经典的多标签节点分类解决方案通常包括两个步骤，首先学习节点嵌入，然后在学习的嵌入上构建节点分类器。为了提高节点嵌入的区分能力，我们提出了一种新颖的合作图遍历方法，称为多标签图遍历，通过强化学习在属性图中使用可用的标签分配来精细调整节点表示。所提出的方法将多标签节点分类任务作为由多个特定于标签的代理进行的同时图遍历来表述。此外，标签化图遍历的政策以协同方式学习，以首先捕捉节点标签与图结构属性之间的预测关系，其次是捕捉多个特定于标签的分类任务之间的相关性。一项全面的实验……

    arXiv:1910.09706v2 Announce Type: cross  Abstract: In this work, we study semi-supervised multi-label node classification problem in attributed graphs. Classic solutions to multi-label node classification follow two steps, first learn node embedding and then build a node classifier on the learned embedding. To improve the discriminating power of the node embedding, we propose a novel collaborative graph walk, named Multi-Label-Graph-Walk, to finely tune node representations with the available label assignments in attributed graphs via reinforcement learning. The proposed method formulates the multi-label node classification task as simultaneous graph walks conducted by multiple label-specific agents. Furthermore, policies of the label-wise graph walks are learned in a cooperative way to capture first the predictive relation between node labels and structural attributes of graphs; and second, the correlation among the multiple label-specific classification tasks. A comprehensive experim
    
[^164]: 桥接状态和历史表示：理解自预测强化学习

    Bridging State and History Representations: Understanding Self-Predictive RL. (arXiv:2401.08898v1 [cs.LG])

    [http://arxiv.org/abs/2401.08898](http://arxiv.org/abs/2401.08898)

    本论文研究了深度强化学习中状态和历史表示间的关系，发现了这些方法和框架实际上都基于自预测抽象的共同思想，并提供了理论洞见和简化算法来学习自预测表示。

    

    表示是所有深度强化学习方法的核心，适用于马尔可夫决策过程（MDP）和部分可观察的马尔可夫决策过程（POMDP）。许多表示学习方法和理论框架被开发用于理解什么构成了有效的表示。然而，这些方法之间的关系和它们之间的共同属性仍然不清楚。在本文中，我们展示了许多看似不同的状态和历史抽象方法和框架实际上基于自预测抽象的共同思想。此外，我们提供了关于广泛采用的目标和优化（如停梯度技术）在学习自预测表示中的理论洞见。这些发现共同产生了一种简化的算法，用于学习状态和历史的自预测表示。我们通过将我们的算法应用于标准MDP、带有dist的MDP进行验证。

    Representations are at the core of all deep reinforcement learning (RL) methods for both Markov decision processes (MDPs) and partially observable Markov decision processes (POMDPs). Many representation learning methods and theoretical frameworks have been developed to understand what constitutes an effective representation. However, the relationships between these methods and the shared properties among them remain unclear. In this paper, we show that many of these seemingly distinct methods and frameworks for state and history abstractions are, in fact, based on a common idea of self-predictive abstraction. Furthermore, we provide theoretical insights into the widely adopted objectives and optimization, such as the stop-gradient technique, in learning self-predictive representations. These findings together yield a minimalist algorithm to learn self-predictive representations for states and histories. We validate our theories by applying our algorithm to standard MDPs, MDPs with dist
    
[^165]: GPT-4V(ision)是一个通用的网络代理，如果有基础的话。

    GPT-4V(ision) is a Generalist Web Agent, if Grounded. (arXiv:2401.01614v1 [cs.IR])

    [http://arxiv.org/abs/2401.01614](http://arxiv.org/abs/2401.01614)

    GPT-4V(ision)是一个通用的网络代理，具有综合视觉理解和网页操作的能力。实验证明，如果将文本计划转化为实际行动，GPT-4V可以在50%的任务上取得成功。这一结果显著优于传统方法。

    

    最近对大型多模型（LMM）的研究，特别是GPT-4V(ision)和Gemini，快速推动了多模型的能力边界超越传统任务，如图像字幕和视觉问答。在这项工作中，我们探索了像GPT-4V这样的LMM作为通用网络代理的潜力，可以根据自然语言指令在任何给定的网站上完成任务。我们提出了SEEACT，一种利用LMM的力量进行综合视觉理解和网页操作的通用网络代理。我们在最新的MIND2WEB基准上进行评估。除了对缓存网站的标准离线评估外，我们还通过开发一个允许在实时网站上运行网络代理的工具，实现了一种新的在线评估设置。我们展示了GPT-4V在网页代理方面表现出巨大的潜力-如果我们将其文本计划手动地实施为网站上的行动，它可以成功地完成50%的任务。此结果明显超过了传统方法。

    The recent development on large multimodal models (LMMs), especially GPT-4V(ision) and Gemini, has been quickly expanding the capability boundaries of multimodal models beyond traditional tasks like image captioning and visual question answering. In this work, we explore the potential of LMMs like GPT-4V as a generalist web agent that can follow natural language instructions to complete tasks on any given website. We propose SEEACT, a generalist web agent that harnesses the power of LMMs for integrated visual understanding and acting on the web. We evaluate on the recent MIND2WEB benchmark. In addition to standard offline evaluation on cached websites, we enable a new online evaluation setting by developing a tool that allows running web agents on live websites. We show that GPT-4V presents a great potential for web agents - it can successfully complete 50% of the tasks on live websites if we manually ground its textual plans into actions on the websites. This substantially outperforms
    
[^166]: 超越梯度和先验知识在隐私攻击中：利用联邦学习中语言模型的池化层输入

    Beyond Gradient and Priors in Privacy Attacks: Leveraging Pooler Layer Inputs of Language Models in Federated Learning. (arXiv:2312.05720v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.05720](http://arxiv.org/abs/2312.05720)

    本文引入了一种创新的方法，在联邦学习中利用语言模型的池化层输入来实现对隐私攻击的改进。通过恢复池化层输入，这种方法能够在不同的批处理大小下提供更高的文本恢复率，从而提供更细致和有效的见解。

    

    联邦学习强调分散式训练，通过本地存储数据并仅发送模型更新，强调用户隐私。最近，一系列有关隐私攻击的工作通过从联邦学习上下文的语言模型中提取敏感的训练文本来损害用户隐私。然而，这些攻击技术面临着不同的障碍：一些工作主要使用有限的批处理大小（例如，批处理大小为1），而其他技术则容易被检测出来。本文介绍了一种创新的方法，具有难以检测的特点，在不同的批处理大小设置下显著提高了文本恢复率。基于基本的梯度匹配和领域先验知识，我们通过恢复语言模型的池化层输入来增强攻击能力，这使我们能够在特征级别提供额外的监督信号。与梯度数据不同，这些信号不会在句子和标记之间进行平均，从而提供更细致和有效的见解。

    Federated learning (FL) emphasizes decentralized training by storing data locally and sending only model updates, underlining user privacy. Recently, a line of works on privacy attacks impairs user privacy by extracting sensitive training text from language models in the context of FL. Yet, these attack techniques face distinct hurdles: some work chiefly with limited batch sizes (e.g., batch size of 1), and others are easily detectable. This paper introduces an innovative approach that is challenging to detect, significantly enhancing the recovery rate of text in various batch-size settings. Building on fundamental gradient matching and domain prior knowledge, we enhance the attack by recovering the input of the Pooler layer of language models, which enables us to provide additional supervised signals at the feature level. Unlike gradient data, these signals do not average across sentences and tokens, thereby offering more nuanced and effective insights. We benchmark our method using t
    
[^167]: 在带有可通行障碍的环境中使用大型语言和视觉-语言模型进行交互式导航

    Interactive Navigation in Environments with Traversable Obstacles Using Large Language and Vision-Language Models. (arXiv:2310.08873v1 [cs.RO] CROSS LISTED)

    [http://arxiv.org/abs/2310.08873](http://arxiv.org/abs/2310.08873)

    本文提出了一个使用大型语言和视觉-语言模型的交互式导航框架，使机器人能够在带有可通行障碍的环境中进行导航。通过使用这些模型，我们可以实现从文本指令到动作感知边界框的端到端系统，无需微调和额外的训练数据。同时，我们还使用大型模型划分激光雷达点云，生成动作感知成本地图以生成可行路径。

    

    本文提出了一种使用大型语言和视觉-语言模型的交互式导航框架，使机器人能够在带有可通行障碍的环境中进行导航。我们利用大型语言模型(GPT-3.5)和开放式视觉-语言模型(基于Grounding DINO)创建了一个动作感知成本地图，用于进行有效的路径规划而无需微调。通过大型模型，我们可以实现从文本指令（例如“你能通过窗帘给我送药吗？”）到具有动作感知属性的边界框（例如窗帘）的端到端系统。它们可以用于将激光雷达点云分成两部分：可通行和不可通行部分，然后构建一个动作感知成本地图用于生成可行路径。预训练的大型模型具有很强的泛化能力，不需要额外的注释数据进行训练，可以快速部署于交互式导航任务中。我们选择使用多个可通行对象。

    This paper proposes an interactive navigation framework by using large language and vision-language models, allowing robots to navigate in environments with traversable obstacles. We utilize the large language model (GPT-3.5) and the open-set Vision-language Model (Grounding DINO) to create an action-aware costmap to perform effective path planning without fine-tuning. With the large models, we can achieve an end-to-end system from textual instructions like "Can you pass through the curtains to deliver medicines to me?", to bounding boxes (e.g., curtains) with action-aware attributes. They can be used to segment LiDAR point clouds into two parts: traversable and untraversable parts, and then an action-aware costmap is constructed for generating a feasible path. The pre-trained large models have great generalization ability and do not require additional annotated data for training, allowing fast deployment in the interactive navigation tasks. We choose to use multiple traversable object
    
[^168]: GenTKG: 基于生成模型的时间知识图谱预测

    GenTKG: Generative Forecasting on Temporal Knowledge Graph. (arXiv:2310.07793v1 [cs.CL])

    [http://arxiv.org/abs/2310.07793](http://arxiv.org/abs/2310.07793)

    研究提出了一种名为GenTKG的生成模型，用于在时间知识图谱上进行预测。该模型通过结合基于时间逻辑规则的检索策略和轻量级的参数效率指导，克服了复杂的时间图数据结构和庞大的数据量所带来的挑战。

    

    大规模语言模型(LLM)的快速发展引发了对时间知识图谱(tKG)领域的兴趣，其中传统的基于嵌入和规则的模型占主导地位。目前仍然存在一个问题，即预训练的LLM是否能够理解结构化的时间关系数据，并取代它们成为时间关系预测的基础模型。因此，我们将时间知识预测引入生成模式。然而，在复杂的时间图数据结构和LLM可以处理的序列自然表达之间存在巨大的鸿沟，在tKG的庞大数据量和微调LLM的巨大计算成本之间也存在挑战。为了解决这些挑战，我们提出了一种新颖的检索增强生成框架，称为GenTKG，它在tKG上执行生成式预测，结合了基于时间逻辑规则的检索策略和轻量级的参数效率指导。通过大量实验证明了GenTKG的有效性。

    The rapid advancements in large language models (LLMs) have ignited interest in the temporal knowledge graph (tKG) domain, where conventional carefully designed embedding-based and rule-based models dominate. The question remains open of whether pre-trained LLMs can understand structured temporal relational data and replace them as the foundation model for temporal relational forecasting. Therefore, we bring temporal knowledge forecasting into the generative setting. However, challenges occur in the huge chasms between complex temporal graph data structure and sequential natural expressions LLMs can handle, and between the enormous data sizes of tKGs and heavy computation costs of finetuning LLMs. To address these challenges, we propose a novel retrieval augmented generation framework that performs generative forecasting on tKGs named GenTKG, which combines a temporal logical rule-based retrieval strategy and lightweight parameter-efficient instruction tuning. Extensive experiments hav
    
[^169]: 一致性轨迹模型：学习扩散的概率流ODE轨迹

    Consistency Trajectory Models: Learning Probability Flow ODE Trajectory of Diffusion. (arXiv:2310.02279v1 [cs.LG])

    [http://arxiv.org/abs/2310.02279](http://arxiv.org/abs/2310.02279)

    提出了一种一致性轨迹模型（CTM），它可以加速扩散模型的采样，同时通过对抗训练和去噪得分匹配损失的组合来提高性能，并实现了最先进的采样质量。

    

    一致性模型（CM）加速基于得分的扩散模型采样，但以牺牲样本质量为代价，缺乏一种自然的方法来权衡速度和质量。为了解决这个限制，我们提出了一致性轨迹模型（CTM），它是包括CM和基于得分模型在内的泛化模型。CTM训练一个单一的神经网络，可以在单次前向传递中输出得分（即对数密度的梯度），并允许在扩散过程中任意初始和最终时间之间进行不受限制的遍历概率流普通微分方程（ODE）。CTM利用对抗训练和去噪得分匹配损失的有效组合来提高性能，并在CIFAR-10（FID 1.73）和64X64分辨率的ImageNet上实现新的最先进FID。CTM还实现了一系列新的采样方案，包括确定性和随机的ODE解中的长跳跃。

    Consistency Models (CM) (Song et al., 2023) accelerate score-based diffusion model sampling at the cost of sample quality but lack a natural way to trade-off quality for speed. To address this limitation, we propose Consistency Trajectory Model (CTM), a generalization encompassing CM and score-based models as special cases. CTM trains a single neural network that can -- in a single forward pass -- output scores (i.e., gradients of log-density) and enables unrestricted traversal between any initial and final time along the Probability Flow Ordinary Differential Equation (ODE) in a diffusion process. CTM enables the efficient combination of adversarial training and denoising score matching loss to enhance performance and achieves new state-of-the-art FIDs for single-step diffusion model sampling on CIFAR-10 (FID 1.73) and ImageNet at 64X64 resolution (FID 2.06). CTM also enables a new family of sampling schemes, both deterministic and stochastic, involving long jumps along the ODE soluti
    
[^170]: SmartPlay: 一种用于评估LLMs作为智能Agent能力的基准

    SmartPlay : A Benchmark for LLMs as Intelligent Agents. (arXiv:2310.01557v1 [cs.LG])

    [http://arxiv.org/abs/2310.01557](http://arxiv.org/abs/2310.01557)

    SmartPlay是一个用于评估LLMs作为智能Agent能力的基准，包括6个具有不同挑战的游戏，并测试了智能LLM Agent的多种关键能力。这不仅是一个评估LLM Agent整体性能的严格测试场地，还可以分析每个能力的表现。

    

    最近的大型语言模型(LLMs)在智能Agent和下一代自动化方面展示了巨大的潜力，但目前缺乏一个系统化的基准来评估LLMs作为Agent的能力。我们介绍了SmartPlay：一个具有挑战性的基准和评估LLMs作为Agent的方法论。SmartPlay包括6个不同的游戏，包括剪刀石头布、汉诺塔、Minecraft等。每个游戏都具有独特的设置，提供最多20个评估设置和无限的环境变化。SmartPlay中的每个游戏都独特地挑战了智能LLM Agent的9个重要能力的子集，包括对对象依赖的推理、提前规划、空间推理、从历史中学习和理解随机性。每个游戏测试的能力集的区别使我们能够单独分析每个能力。SmartPlay不仅是评估LLM Agent整体性能的严格测试场地，而且也是评估Agent在不同能力方面的性能的一个重要工具。

    Recent large language models (LLMs) have demonstrated great potential toward intelligent agents and next-gen automation, but there currently lacks a systematic benchmark for evaluating LLMs' abilities as agents. We introduce SmartPlay: both a challenging benchmark and a methodology for evaluating LLMs as agents. SmartPlay consists of 6 different games, including Rock-Paper-Scissors, Tower of Hanoi, Minecraft. Each game features a unique setting, providing up to 20 evaluation settings and infinite environment variations. Each game in SmartPlay uniquely challenges a subset of 9 important capabilities of an intelligent LLM agent, including reasoning with object dependencies, planning ahead, spatial reasoning, learning from history, and understanding randomness. The distinction between the set of capabilities each game test allows us to analyze each capability separately. SmartPlay serves not only as a rigorous testing ground for evaluating the overall performance of LLM agents but also as
    
[^171]: 动态边界最大化和改进的Lipschitz正则化的认证鲁棒性

    Certified Robustness via Dynamic Margin Maximization and Improved Lipschitz Regularization. (arXiv:2310.00116v1 [cs.LG])

    [http://arxiv.org/abs/2310.00116](http://arxiv.org/abs/2310.00116)

    本文提出了一种基于动态边界最大化和改进的Lipschitz正则化的认证鲁棒性训练算法，通过增加输出空间中的边界和正则化模型的Lipschitz常数来提高深度分类器对抗性扰动的鲁棒性。

    

    为了提高深度分类器对抗性扰动的鲁棒性，已经提出了许多方法，例如设计具有更好鲁棒性性质的新架构（例如，Lipschitz-capped网络）或修改训练过程本身（例如，最小-最大优化，约束学习或正则化）。然而，这些方法对于增加输入（特征）空间中的边界可能并不有效。因此，越来越多的人开始对开发能够直接操纵输入空间中的决策边界的训练过程感兴趣。在本文中，我们在该类别的最新发展基础上，开发了一种鲁棒训练算法，其目标是在输出（logit）空间中增加边界，并沿着脆弱方向正则化模型的Lipschitz常数。我们证明这两个目标可以直接促进输入空间中更大的边界。为此，我们开发了一种可扩展的方法来计算...

    To improve the robustness of deep classifiers against adversarial perturbations, many approaches have been proposed, such as designing new architectures with better robustness properties (e.g., Lipschitz-capped networks), or modifying the training process itself (e.g., min-max optimization, constrained learning, or regularization). These approaches, however, might not be effective at increasing the margin in the input (feature) space. As a result, there has been an increasing interest in developing training procedures that can directly manipulate the decision boundary in the input space. In this paper, we build upon recent developments in this category by developing a robust training algorithm whose objective is to increase the margin in the output (logit) space while regularizing the Lipschitz constant of the model along vulnerable directions. We show that these two objectives can directly promote larger margins in the input space. To this end, we develop a scalable method for calcula
    
[^172]: 基于似然比的任务预测的类增量学习

    Class Incremental Learning via Likelihood Ratio Based Task Prediction. (arXiv:2309.15048v1 [cs.LG])

    [http://arxiv.org/abs/2309.15048](http://arxiv.org/abs/2309.15048)

    该论文提出了一种基于似然比的任务预测的类增量学习方法，利用离群检测器进行任务标识预测，解决了无任务标识符的测试样本的任务预测问题。

    

    类增量学习是一种具有挑战性的不断学习的设置，通过顺序学习一系列任务。每个任务由一组唯一的类组成。类增量学习的关键特点是，在测试时不提供每个测试样本的任务标识符（或任务ID）。为每个测试样本预测任务ID是一个具有挑战性的问题。一种新兴的理论上合理且有效的方法是根据任务增量学习的方法，在共享网络中为所有任务训练每个任务的任务特定模型，以处理遗忘。该方法中每个任务的模型是一个非常规分类器而不是传统分类器的离群检测器。离群检测器可以对任务内（分布内（IND））的类进行预测和识别离群数据。在推断期间，离群检测能力是每个测试样本的任务ID预测的关键。然而，本文认为使用传统的离群检测器进行任务ID预测是次优的。

    Class incremental learning (CIL) is a challenging setting of continual learning, which learns a series of tasks sequentially. Each task consists of a set of unique classes. The key feature of CIL is that no task identifier (or task-id) is provided at test time for each test sample. Predicting the task-id for each test sample is a challenging problem. An emerging theoretically justified and effective approach is to train a task-specific model for each task in a shared network for all tasks based on a task-incremental learning (TIL) method to deal with forgetting. The model for each task in this approach is an out-of-distribution (OOD) detector rather than a conventional classifier. The OOD detector can perform both within-task (in-distribution (IND)) class prediction and OOD detection. The OOD detection capability is the key for task-id prediction during inference for each test sample. However, this paper argues that using a traditional OOD detector for task-id prediction is sub-optimal
    
[^173]: 使用学习到的概率车道图来生成和解释角落情况

    Generating and Explaining Corner Cases Using Learnt Probabilistic Lane Graphs. (arXiv:2308.13658v1 [cs.AI])

    [http://arxiv.org/abs/2308.13658](http://arxiv.org/abs/2308.13658)

    本论文提出了使用概率车道图生成和解释角落情况的方法，该方法基于历史交通数据生成新颖而逼真的角落情况，以提高自动驾驶车辆的安全性。

    

    在开放动态环境中验证自动驾驶汽车（AV）的安全性具有挑战性，因为车辆最终会遇到没有代表性训练数据的安全关键情况。通过在基于模拟的场景测试中增加不同的道路和交通条件的覆盖范围，并包括角落情况，可以提高AV的安全性。然而，包含多个代理的角落情况场景的创建是非常困难的。我们的方法可以让工程师基于历史交通数据生成新颖而逼真的角落情况，并解释为什么这些情况是安全关键的。在本文中，我们引入了概率车道图（PLGs）来描述车辆可能行驶的有限一组车道位置和方向。PLGs的结构是直接从时空交通数据中学习得到的。图模型以概率策略的形式表示驾驶员对给定状态的响应行为。

    Validating the safety of Autonomous Vehicles (AVs) operating in open-ended, dynamic environments is challenging as vehicles will eventually encounter safety-critical situations for which there is not representative training data. By increasing the coverage of different road and traffic conditions and by including corner cases in simulation-based scenario testing, the safety of AVs can be improved. However, the creation of corner case scenarios including multiple agents is non-trivial. Our approach allows engineers to generate novel, realistic corner cases based on historic traffic data and to explain why situations were safety-critical. In this paper, we introduce Probabilistic Lane Graphs (PLGs) to describe a finite set of lane positions and directions in which vehicles might travel. The structure of PLGs is learnt directly from spatio-temporal traffic data. The graph model represents the actions of the drivers in response to a given state in the form of a probabilistic policy. We use
    
[^174]: 具有环境感知记忆的上下文感知规划用于指导行为智能体

    Context-Aware Planning and Environment-Aware Memory for Instruction Following Embodied Agents. (arXiv:2308.07241v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2308.07241](http://arxiv.org/abs/2308.07241)

    这项研究提出了一种称为CPEM的系统，它利用上下文信息和环境感知记忆来改进行为智能体的感知能力，从而提高视觉导航和物体交互的效果。

    

    完成家务任务（例如“拿一杯水”）需要通过保持对空间对象的空间布局和先前行动的结果的知识来进行逐步的规划。然而，当前的行为智能体在感知模型方面经常出错，因为缺乏这种知识，而依赖于不完美的学习的模仿智能体或者没有关于先前行动对环境变化的知识的算法规划器。为了解决这个问题，我们提出了CPEM（上下文感知规划器和环境感知记忆），将先前行动的上下文信息与环境中物体的空间布局和状态（例如物体是否被移动）结合到感知模型中，以改进视觉导航和物体交互。我们观察到，CPEM在各种度量指标上实现了最先进的任务成功性能。

    Accomplishing household tasks such as 'bringing a cup of water' requires planning step-by-step actions by maintaining knowledge about the spatial arrangement of objects and the consequences of previous actions. Perception models of the current embodied AI agents, however, often make mistakes due to a lack of such knowledge but rely on imperfect learning of imitating agents or an algorithmic planner without knowledge about the changed environment by the previous actions. To address the issue, we propose CPEM (Context-aware Planner and Environment-aware Memory) to incorporate the contextual information of previous actions for planning and maintaining spatial arrangement of objects with their states (e.g., if an object has been moved or not) in an environment to the perception model for improving both visual navigation and object interaction. We observe that CPEM achieves state-of-the-art task success performance in various metrics using a challenging interactive instruction following ben
    
[^175]: 多智能体优化解决方案的对比解释

    Contrastive Explanations of Multi-agent Optimization Solutions. (arXiv:2308.05984v1 [cs.AI])

    [http://arxiv.org/abs/2308.05984](http://arxiv.org/abs/2308.05984)

    本研究提出了MAoE，一种用于多智能体优化问题的对比解释方法。该方法通过生成新的解决方案并突出显示与初始解决方案的差异，帮助智能体理解为什么初始解决方案优于他们的期望。

    

    在许多现实世界的场景中，智能体参与优化问题。由于大多数情况都是超约束的，最优解并不总能满足所有智能体的要求。有些智能体可能不满意，并提出类似“为什么解决方案S不满足属性P？”的问题。在本文中，我们提出了MAoE，这是一种领域无关的方法，通过（i）生成一个新的解决方案S'，该解决方案强制满足属性P，同时最小化S和S'之间的差异；以及（ii）突出显示这两个解决方案之间的差异。这样的解释旨在帮助智能体理解为什么初始解决方案优于他们的期望。我们进行了计算评估，表明MAoE可以为大型多智能体优化问题生成对比解释。我们还在四个不同的领域进行了广泛的用户研究，结果显示，在提供这些解释后，用户对解决方案的理解有所改善。

    In many real-world scenarios, agents are involved in optimization problems. Since most of these scenarios are over-constrained, optimal solutions do not always satisfy all agents. Some agents might be unhappy and ask questions of the form ``Why does solution $S$ not satisfy property $P$?''. In this paper, we propose MAoE, a domain-independent approach to obtain contrastive explanations by (i) generating a new solution $S^\prime$ where the property $P$ is enforced, while also minimizing the differences between $S$ and $S^\prime$; and (ii) highlighting the differences between the two solutions. Such explanations aim to help agents understanding why the initial solution is better than what they expected. We have carried out a computational evaluation that shows that MAoE can generate contrastive explanations for large multi-agent optimization problems. We have also performed an extensive user study in four different domains that shows that, after being presented with these explanations, h
    
[^176]: 自然和机器

    Nature and the Machines. (arXiv:2308.04440v1 [cs.CY])

    [http://arxiv.org/abs/2308.04440](http://arxiv.org/abs/2308.04440)

    《自然》杂志在一篇社论中呼吁我们“停止谈论明天的AI末日，而AI今天就存在风险。”这被认为是一个严重的判断失误，特别是对于有影响力的行动者来说，因为我们期望他们能够考虑到错误的后果。

    

    人工智能(AI)是否对人类构成存在危险？一些批评家认为这个问题正在受到过多的关注，他们希望将其推到一边，转而讨论AI的即时风险。这些批评家现在包括《自然》杂志，在最近的一篇社论中敦促我们“停止谈论明天的AI末日，而AI今天就存在风险。”我们认为这是一种严重的判断失误，对于《自然》杂志来说。在科学领域，就像在日常生活中一样，我们希望有影响力的行为者能够考虑错误的后果。作为世界领先的科学期刊，《自然》杂志无疑是一个有影响力的行为者，特别是在缺乏健全全球AI监管的情况下。然而，它在这个案例中明显未能考虑到错误的代价。

    Does artificial intelligence (AI) pose existential risks to humanity? Some critics feel this question is getting too much attention, and want to push it aside in favour of conversations about the immediate risks of AI. These critics now include the journal Nature, where a recent editorial urges us to 'stop talking about tomorrow's AI doomsday when AI poses risks today.' We argue that this is a serious failure of judgement, on Nature's part. In science, as in everyday life, we expect influential actors to consider the consequences of error. As the world's leading scientific journal, Nature is certainly an influential actor, especially so in the absence of robust global regulation of AI. Yet it has manifestly failed to consider the cost of error in this case.
    
[^177]: 大型语言模型中的上下文学习在学习标签关系上具有创新，但并非传统学习方法

    In-Context Learning in Large Language Models Learns Label Relationships but Is Not Conventional Learning. (arXiv:2307.12375v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.12375](http://arxiv.org/abs/2307.12375)

    大型语言模型（LLMs）在包含标签关系示例的上下文中的学习能力使其在下游任务中表现显著提高，但与传统学习方法不同。我们研究了上下文示例中的标签如何影响预测、预训练中学习到的标签关系如何与上下文示例相互作用以及上下文学习如何聚合标签信息。研究结果揭示了LLMs的工作机制及其对上下文信息的处理方式。

    

    在下游任务中，大型语言模型（LLMs）的性能在包含输入-标签关系示例的上下文中通常显著提高。然而，目前对LLMs的这种上下文学习（ICL）能力的工作机制尚无共识：例如，虽然Xie等人（2021年）将ICL比作一种通用学习算法，但Min等人（2022b年）认为ICL甚至不能从上下文示例中学习标签关系。在本文中，我们研究了以下三个问题：（1）上下文示例的标签如何影响预测结果，（2）预训练期间学习到的标签关系如何与上下文中提供的输入-标签示例相互作用，以及（3）ICL如何聚合来自上下文示例的标签信息。我们的研究发现，LLMs通常会整合上下文标签的信息，但预训练和上下文标签关系被区别对待，模型不会将所有上下文信息等同对待。我们的结果揭示了对LLMs的理解。

    The performance of Large Language Models (LLMs) on downstream tasks often improves significantly when including examples of the input-label relationship in the context. However, there is currently no consensus about how this in-context learning (ICL) ability of LLMs works: for example, while Xie et al. (2021) liken ICL to a general-purpose learning algorithm, Min et al. (2022b) argue ICL does not even learn label relationships from in-context examples. In this paper, we study (1) how labels of in-context examples affect predictions, (2) how label relationships learned during pre-training interact with input-label examples provided in-context, and (3) how ICL aggregates label information across in-context examples. Our findings suggests LLMs usually incorporate information from in-context labels, but that pre-training and in-context label relationships are treated differently, and that the model does not consider all in-context information equally. Our results give insights into underst
    
[^178]: UniTabE: 面向异构表格数据的统一预训练表格编码器

    UniTabE: Pretraining a Unified Tabular Encoder for Heterogeneous Tabular Data. (arXiv:2307.09249v1 [cs.LG])

    [http://arxiv.org/abs/2307.09249](http://arxiv.org/abs/2307.09249)

    UniTabE是一种面向异构表格数据的统一预训练表格编码器，能够处理不同表格结构的挑战，并具有对多样化下游应用的适应性。

    

    自然语言处理（NLP）的最新进展明证了预训练模型的突破性影响，在各种任务上取得了令人印象深刻的结果。本研究旨在将预训练方法的威力扩展到传统被忽视的表格数据领域，该领域由于不同任务固有的众多表格模式而具有挑战性。本工作的主要研究问题围绕异构表格结构的适应性、表格数据的统一预训练协议的建立、学到的知识在任务之间的泛化和可传递性、对多样化下游应用的适应性以及随时间的增量列的纳入进行了探讨。针对这些挑战，我们引入了UniTabE，这是一种创新的方法，旨在以一致的方式处理表格，摆脱了特定表格结构强加的约束。UniTabE的核心概念是对每个基本表格进行表示

    Recent advancements in Natural Language Processing (NLP) have witnessed the groundbreaking impact of pretrained models, yielding impressive outcomes across various tasks. This study seeks to extend the power of pretraining methodologies to tabular data, a domain traditionally overlooked, yet inherently challenging due to the plethora of table schemas intrinsic to different tasks. The primary research questions underpinning this work revolve around the adaptation to heterogeneous table structures, the establishment of a universal pretraining protocol for tabular data, the generalizability and transferability of learned knowledge across tasks, the adaptation to diverse downstream applications, and the incorporation of incremental columns over time. In response to these challenges, we introduce UniTabE, a pioneering method designed to process tables in a uniform manner, devoid of constraints imposed by specific table structures. UniTabE's core concept relies on representing each basic tab
    
[^179]: VertiBench: 在垂直联邦学习基准中推进特征分布多样性

    VertiBench: Advancing Feature Distribution Diversity in Vertical Federated Learning Benchmarks. (arXiv:2307.02040v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.02040](http://arxiv.org/abs/2307.02040)

    本文引入了两个影响VFL性能的关键因素：特征重要性和特征相关性，并提出了相关的评估指标和数据集划分方法。同时，通过引入真实的VFL数据集，填补了图像-图像VFL情景中的不足。研究对于未来的VFL研究提供了有价值的见解。

    

    垂直联邦学习（VFL）是在特征划分的分布式数据上训练机器学习模型的重要范例。然而，由于隐私限制，很少有公开的真实世界VFL数据集用于算法评估，而这些数据集只代表了有限的特征分布。现有的基准通常采用从全局集合中的任意特征划分导出的合成数据集，这只捕捉到了一部分特征分布，导致算法性能评估不足。本文通过引入影响VFL性能的两个关键因素——特征重要性和特征相关性，并提出相关的评估指标和数据集划分方法，解决了这些问题。此外，我们还引入了一个真实的VFL数据集来弥补图像-图像VFL情景中的不足。我们对尖端VFL算法进行全面评估，为未来研究提供了有价值的见解。

    Vertical Federated Learning (VFL) is a crucial paradigm for training machine learning models on feature-partitioned, distributed data. However, due to privacy restrictions, few public real-world VFL datasets exist for algorithm evaluation, and these represent a limited array of feature distributions. Existing benchmarks often resort to synthetic datasets, derived from arbitrary feature splits from a global set, which only capture a subset of feature distributions, leading to inadequate algorithm performance assessment. This paper addresses these shortcomings by introducing two key factors affecting VFL performance - feature importance and feature correlation - and proposing associated evaluation metrics and dataset splitting methods. Additionally, we introduce a real VFL dataset to address the deficit in image-image VFL scenarios. Our comprehensive evaluation of cutting-edge VFL algorithms provides valuable insights for future research in the field.
    
[^180]: 安全关键强化学习的概率约束

    Probabilistic Constraint for Safety-Critical Reinforcement Learning. (arXiv:2306.17279v1 [cs.LG])

    [http://arxiv.org/abs/2306.17279](http://arxiv.org/abs/2306.17279)

    本文研究了概率约束下的安全关键强化学习问题，提出了具有明确梯度表达式的Safe Policy Gradient-REINFORCE（SPG-REINFORCE）算法，并通过理论界限证明了概率约束设置在最优性和安全性之间具有更好的权衡。

    

    本文考虑了概率约束强化学习中学习安全策略的问题。具体来说，安全策略或控制器是指以高概率保持代理在给定安全集合中的轨迹。我们在现有文献中频繁探索的累积约束问题和这种概率约束问题之间建立了联系。我们提供了理论界限，阐明概率约束设置在最优性和安全性（约束满足）方面具有更好的权衡。在处理概率约束时遇到的挑战，正如我们在这项工作中所探索的那样，源于没有明确的梯度表达式。我们之前的工作提供了这种明确的梯度表达式，称之为Safe Policy Gradient-REINFORCE（SPG-REINFORCE）。在这项工作中，我们提供了一个改进的梯度SPG-Actor-Critic

    In this paper, we consider the problem of learning safe policies for probabilistic-constrained reinforcement learning (RL). Specifically, a safe policy or controller is one that, with high probability, maintains the trajectory of the agent in a given safe set. We establish a connection between this probabilistic-constrained setting and the cumulative-constrained formulation that is frequently explored in the existing literature. We provide theoretical bounds elucidating that the probabilistic-constrained setting offers a better trade-off in terms of optimality and safety (constraint satisfaction). The challenge encountered when dealing with the probabilistic constraints, as explored in this work, arises from the absence of explicit expressions for their gradients. Our prior work provides such an explicit gradient expression for probabilistic constraints which we term Safe Policy Gradient-REINFORCE (SPG-REINFORCE). In this work, we provide an improved gradient SPG-Actor-Critic that lead
    
[^181]: 通过密度标志检测来识别离散化潜在坐标系统的可识别性

    Identifiability of Discretized Latent Coordinate Systems via Density Landmarks Detection. (arXiv:2306.16334v1 [cs.LG])

    [http://arxiv.org/abs/2306.16334](http://arxiv.org/abs/2306.16334)

    本文提出了一种新颖的可识别性形式，称为量化坐标可识别性。在无监督的情况下，我们展示了在高度通用的非线性映射下，可以恢复离散化的潜在坐标，而无需额外的归纳偏差。这一发现对解缠研究具有重要意义。

    

    解缠旨在仅从观察到的分布中恢复有意义的潜在真实因素。 可识别性为解缠提供了理论基础。 不幸的是，在自适应独立潜变量因子的情况下，在一般的非线性光滑因子到观测的映射下，无监督的可识别性在i.i.d.设置下是理论上不可能的。 在这项工作中，我们展示了非常惊人的是，在高度通用的非线性光滑映射（一个微分同胚）下，可以恢复离散化的潜在坐标，而不需要对映射进行任何额外的归纳偏差。 这是在假设潜在密度具有轴对齐的不连续标志的情况下，但不做因素的统计独立的不现实的假设。 我们引入了这种新颖的可识别性形式，称为量化坐标可识别性，并对恢复离散坐标进行了全面的证明。

    Disentanglement aims to recover meaningful latent ground-truth factors from only the observed distribution. Identifiability provides the theoretical grounding for disentanglement to be well-founded. Unfortunately, unsupervised identifiability of independent latent factors is a theoretically proven impossibility in the i.i.d. setting under a general nonlinear smooth map from factors to observations. In this work, we show that, remarkably, it is possible to recover discretized latent coordinates under a highly generic nonlinear smooth mapping (a diffeomorphism) without any additional inductive bias on the mapping. This is, assuming that latent density has axis-aligned discontinuity landmarks, but without making the unrealistic assumption of statistical independence of the factors. We introduce this novel form of identifiability, termed quantized coordinate identifiability, and provide a comprehensive proof of the recovery of discretized coordinates.
    
[^182]: 简单形式映射神经网络中的可解释性

    Explainability in Simplicial Map Neural Networks. (arXiv:2306.00010v1 [cs.LG])

    [http://arxiv.org/abs/2306.00010](http://arxiv.org/abs/2306.00010)

    本文提出了简单形式映射神经网络（SMNN）的训练过程和替代凸多面体的方法，并且首次引入了 SMNN 的可解释性能力。

    

    简单形式映射神经网络（SMNN）是基于拓扑学的神经网络，具有普适逼近能力和在适当条件下对抗性示例的鲁棒性。然而，在高维中应用 SMNN 存在一些瓶颈，首先没有定义 SMNN 的训练过程，其次对于输入数据集需要构建一个包围凸多面体。本文提出了基于给定数据集的支持子集和投影到超球面的方法作为替代凸多面体的 SMNN 训练过程，并首次引入了 SMNN 的可解释性能力。

    Simplicial map neural networks (SMNNs) are topology-based neural networks with interesting properties such as universal approximation capability and robustness to adversarial examples under appropriate conditions. However, SMNNs present some bottlenecks for their possible application in high dimensions. First, no SMNN training process has been defined so far. Second, SMNNs require the construction of a convex polytope surrounding the input dataset. In this paper, we propose a SMNN training procedure based on a support subset of the given dataset and a method based on projection to a hypersphere as a replacement for the convex polytope construction. In addition, the explainability capacity of SMNNs is also introduced for the first time in this paper.
    
[^183]: GRACE++：通过神经编解码器实现抗丢包的实时视频

    GRACE++: Loss-Resilient Real-Time Video through Neural Codecs. (arXiv:2305.12333v2 [cs.MM] UPDATED)

    [http://arxiv.org/abs/2305.12333](http://arxiv.org/abs/2305.12333)

    GRACE++是一个抗丢包的实时视频系统，通过神经视频编解码器实现了在各种丢包情况下保持用户体验质量的目标。

    

    在实时视频通信中，由于严格的延迟要求，重新传输丢失的数据包在高延迟网络下是不可行的。为了应对没有重传的丢包情况，使用了两种主要策略--基于编码器的前向差错纠正（FEC）和基于解码器的错误隐藏。前者在传输之前用冗余编码数据，但提前确定最佳冗余级别是具有挑战性的。后者从部分收到的帧中重建视频，但将帧划分为独立编码的分区会降低压缩效率，并且丢失的信息在没有适应编码器的情况下无法有效地被解码器恢复。我们提出了一种名为GRACE++的抗丢包实时视频系统，通过一种新的神经视频编解码器，它能够在各种丢包情况下保持用户的体验质量（QoE）。

    In real-time video communication, retransmitting lost packets over high-latency networks is not viable due to strict latency requirements. To counter packet losses without retransmission, two primary strategies are employed -- encoder-based forward error correction (FEC) and decoder-based error concealment. The former encodes data with redundancy before transmission, yet determining the optimal redundancy level in advance proves challenging. The latter reconstructs video from partially received frames, but dividing a frame into independently coded partitions inherently compromises compression efficiency, and the lost information cannot be effectively recovered by the decoder without adapting the encoder.  We present a loss-resilient real-time video system called GRACE++, which preserves the user's quality of experience (QoE) across a wide range of packet losses through a new neural video codec. Central to GRACE++'s enhanced loss resilience is its joint training of the neural encoder an
    
[^184]: 记忆还是忘却？深入探讨语言模型的知识记忆机制

    Retentive or Forgetful? Diving into the Knowledge Memorizing Mechanism of Language Models. (arXiv:2305.09144v1 [cs.CL])

    [http://arxiv.org/abs/2305.09144](http://arxiv.org/abs/2305.09144)

    本论文研究了语言模型的记忆机制，发现预训练可以有效提高模型的记忆能力，而知识相关性和多样性对于记忆形成也有显著影响。

    

    记忆是最基本的认知功能之一，是存储世界知识和活动经历的储藏库。近年来，大规模预训练语言模型展现出卓越的记忆能力。相反，没有预训练的神经网络长期以来一直存在灾难性遗忘问题。为了研究这种保持-遗忘的矛盾并了解语言模型的记忆机制，我们通过控制目标知识类型、学习策略和学习时间表等，开展了深入的实验研究。结果发现：1）传统语言模型是容易遗忘的；2）预训练可以使语言模型具有记忆能力；3）知识相关性和多样性显著影响记忆形成。这些结论有助于理解预训练语言模型的能力，并为设计和评估新的语言模型学习方法和推理算法提供了启示。

    Memory is one of the most essential cognitive functions serving as a repository of world knowledge and episodes of activities. In recent years, large-scale pre-trained language models have shown remarkable memorizing ability. On the contrary, vanilla neural networks without pre-training have been long observed suffering from the catastrophic forgetting problem. To investigate such a retentive-forgetful contradiction and understand the memory mechanism of language models, we conduct thorough experiments by controlling the target knowledge types, the learning strategies and the learning schedules. We find that: 1) Vanilla language models are forgetful; 2) Pre-training leads to retentive language models; 3) Knowledge relevance and diversification significantly influence the memory formation. These conclusions are useful for understanding the abilities of pre-trained language models and shed light on designing and evaluating new learning and inference algorithms of language models.
    
[^185]: 用于教育的通用人工智能（AGI）

    Artificial General Intelligence (AGI) for Education. (arXiv:2304.12479v1 [cs.AI])

    [http://arxiv.org/abs/2304.12479](http://arxiv.org/abs/2304.12479)

    AGI技术具有革命教育领域潜力，可以建立e-learning平台、教育协作工具等，弥补传统AI模型因受限于数据和人际交互限制而无法满足教育需求的不足。

    

    由于最新的大型语言模型和聊天机器人（如GPT-4和ChatGPT）的出现，通用人工智能（AGI）作为未来技术已经得到全球认可。AGI旨在通过计算机系统复制人类智能，是具有革命教育领域潜力的关键技术之一。与传统的人工智能模型相比，这些模型通常只针对有限范围的任务进行设计，需要大量特定领域的数据进行训练，可能无法考虑教育中复杂的人际动态。受最近的大规模预训练模型驱动，AGI代表了机器在执行需要人类水平智能的任务方面的重大飞跃，例如推理、解决问题、做出决策，甚至理解人类情感和社交互动。本研究回顾了AGI的关键概念、能力、范围和在未来教育中的潜力，包括建立e-learning平台和教育协作工具等。

    Artificial general intelligence (AGI) has gained global recognition as a future technology due to the emergence of breakthrough large language models and chatbots such as GPT-4 and ChatGPT, respectively. AGI aims to replicate human intelligence through computer systems, which is one of the critical technologies having the potential to revolutionize the field of education. Compared to conventional AI models, typically designed for a limited range of tasks, demand significant amounts of domain-specific data for training and may not always consider intricate interpersonal dynamics in education. AGI, driven by the recent large pre-trained models, represents a significant leap in the capability of machines to perform tasks that require human-level intelligence, such as reasoning, problem-solving, decision-making, and even understanding human emotions and social interactions. This work reviews AGI's key concepts, capabilities, scope, and potential within future education, including setting e
    
[^186]: 带有大型图像文本（LIT）模型的CT多任务学习

    CT Multi-Task Learning with a Large Image-Text (LIT) Model. (arXiv:2304.02649v1 [eess.IV])

    [http://arxiv.org/abs/2304.02649](http://arxiv.org/abs/2304.02649)

    本研究通过将大型图像模型和大语言模型结合起来，建立了一个用于肺癌诊断的多任务CT大型图像文本（LIT）模型，能很好地执行肺部CT分割等多个医学任务。

    

    大语言模型（LLM）不仅能够支持多种语言任务，而且还可以作为不同领域的通用接口。迄今为止，还没有证明如何将LLM在计算机视觉领域的成功有效地转化为涉及高维和多模态医学图像的医学成像领域。在本文中，我们报告了一项可行性研究，通过组合LLM和大型图像模型（LIM），建立多任务CT大型图像文本（LIT）模型，用于肺癌诊断。具体而言，LLM和LIM用作编码器，根据特定任务的文本提示来感知多模态信息，从而协同作用于多源信息和任务特定和患者特定的先验，以优化诊断性能。我们的LIT模型和相关技术的关键组成部分将重点评估3D肺部CT分析。我们的初步结果表明，LIT模型能够很好地执行多项医学任务，包括肺分割。

    Large language models (LLM) not only empower multiple language tasks but also serve as a general interface across different spaces. Up to now, it has not been demonstrated yet how to effectively translate the successes of LLMs in the computer vision field to the medical imaging field which involves high-dimensional and multi-modal medical images. In this paper, we report a feasibility study of building a multi-task CT large image-text (LIT) model for lung cancer diagnosis by combining an LLM and a large image model (LIM). Specifically, the LLM and LIM are used as encoders to perceive multi-modal information under task-specific text prompts, which synergizes multi-source information and task-specific and patient-specific priors for optimized diagnostic performance. The key components of our LIT model and associated techniques are evaluated with an emphasis on 3D lung CT analysis. Our initial results show that the LIT model performs multiple medical tasks well, including lung segmentatio
    
[^187]: 时序和非时序数据因果发现方法综述

    A Survey on Causal Discovery Methods for Temporal and Non-Temporal Data. (arXiv:2303.15027v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.15027](http://arxiv.org/abs/2303.15027)

    本文综述了时序和非时序数据因果发现的方法，探讨了不同算法在不同情况下识别因果边缘的能力。同时还介绍了可用于评估因果发现方法性能的基准数据集和常见指标。

    

    因果发现（CD）是从数据中识别系统变量间因果关系的过程。多年来，已经开发了几种方法，主要基于数据的统计特性来揭示潜在的因果机制。本文对设计用于处理独立同分布（i.i.d.）数据和时间序列数据的因果发现方法进行了广泛探讨。为此，我们首先介绍了因果发现中的常用术语，然后全面讨论了在不同情况下识别因果边缘的算法。我们进一步讨论了可用于评估因果发现方法性能的基准数据集，可用于执行因果发现的工具或软件包以及评估这些方法的常见指标。我们还在不同基准数据集上测试了一些常见因果发现算法。

    Causal Discovery (CD) is the process of identifying the cause-effect relationships among the variables of a system from data. Over the years, several methods have been developed primarily based on the statistical properties of data to uncover the underlying causal mechanism. In this study, we present an extensive discussion on the methods designed to perform causal discovery from both independent and identically distributed (i.i.d.) data and time series data. For this purpose, we first introduce the common terminologies in causal discovery, and then provide a comprehensive discussion of the algorithms designed to identify the causal edges in different settings. We further discuss some of the benchmark datasets available for evaluating the performance of the causal discovery methods, available tools or software packages to perform causal discovery readily, and the common metrics used to evaluate these methods. We also test some common causal discovery algorithms on different benchmark d
    
[^188]: 数据高效的对比自监督学习：易于学习的样本起到最大的作用。

    Data-Efficient Contrastive Self-supervised Learning: Easy Examples Contribute the Most. (arXiv:2302.09195v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.09195](http://arxiv.org/abs/2302.09195)

    该研究证明了在自监督学习中容易学习的样本对学习高质量表示起到最大的作用，这有助于减少所需的训练数据量，并提高性能。

    

    自监督学习（SSL）从大量的无标签训练数据中学习高质量的表示。随着数据集变得越来越大，识别对学习此类表示最有用的示例变得至关重要。这可以通过减少学习高质量表示所需的数据量来实现有效的SSL。然而，对于SSL的价值如何量化一直是一个悬而未决的问题。在本文中，我们首次解决了这个问题，证明在期望意义下，对比SSL中对学习做出最大贡献的示例是具有最相似数据增强的示例。我们对这些子集的SSL的广义性能提供了严格的保证。实验证明，令人惊讶的是，对SSL做出最大贡献的子集是对监督学习做出最小贡献的子集。通过广泛的实验，我们证明了我们的子集在CIFAR100、CIFAR中的表现优于随机子集3%以上。

    Self-supervised learning (SSL) learns high-quality representations from large pools of unlabeled training data. As datasets grow larger, it becomes crucial to identify the examples that contribute the most to learning such representations. This enables efficient SSL by reducing the volume of data required for learning high-quality representations. Nevertheless, quantifying the value of examples for SSL has remained an open question. In this work, we address this for the first time, by proving that examples that contribute the most to contrastive SSL are those that have the most similar augmentations to other examples, in expectation. We provide rigorous guarantees for the generalization performance of SSL on such subsets. Empirically, we discover, perhaps surprisingly, the subsets that contribute the most to SSL are those that contribute the least to supervised learning. Through extensive experiments, we show that our subsets outperform random subsets by more than 3% on CIFAR100, CIFAR
    
[^189]: 异构视觉深度网络社区中的指代性沟通

    Referential communication in heterogeneous communities of pre-trained visual deep networks. (arXiv:2302.08913v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.08913](http://arxiv.org/abs/2302.08913)

    异构视觉深度网络社区中的预训练网络可以自我监督地开发出共享协议，以指代一组目标中的目标对象，并可用于沟通不同粒度的未知对象类别。

    

    随着大型预训练图像处理神经网络被嵌入自动驾驶汽车或机器人等自主代理中，一个问题出现了：在它们具有不同架构和训练方式的情况下，这些系统如何相互之间进行沟通以了解周围的世界。作为朝着这个方向的第一步，我们系统地探索了在一组异构最先进的预训练视觉网络社区中进行"指代性沟通"的任务，结果表明它们可以自我监督地发展一种共享协议来指代一组候选目标中的目标对象。在某种程度上，这种共享协议也可以用来沟通不同粒度的先前未见过的对象类别。此外，一个最初不属于现有社区的视觉网络可以轻松地学习到社区的协议。最后，我们定性和定量地研究了这种新产生的协议的属性，提供了一些证据。

    As large pre-trained image-processing neural networks are being embedded in autonomous agents such as self-driving cars or robots, the question arises of how such systems can communicate with each other about the surrounding world, despite their different architectures and training regimes. As a first step in this direction, we systematically explore the task of \textit{referential communication} in a community of heterogeneous state-of-the-art pre-trained visual networks, showing that they can develop, in a self-supervised way, a shared protocol to refer to a target object among a set of candidates. This shared protocol can also be used, to some extent, to communicate about previously unseen object categories of different granularity. Moreover, a visual network that was not initially part of an existing community can learn the community's protocol with remarkable ease. Finally, we study, both qualitatively and quantitatively, the properties of the emergent protocol, providing some evi
    

