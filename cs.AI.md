# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Generalized Independent Noise Condition for Estimating Causal Structure with Latent Variables.](http://arxiv.org/abs/2308.06718) | 这篇论文提出了具有潜变量的因果结构估计的广义独立噪声（GIN）条件，并给出了线性非高斯无环因果模型中满足GIN条件的图形判据。 |
| [^2] | [Estimating and Incentivizing Imperfect-Knowledge Agents with Hidden Rewards.](http://arxiv.org/abs/2308.06717) | 本文研究了一个自私学习代理和学习委托人之间的重复对自选游戏，探索如何估计和激励具有隐藏奖励的不完全知识代理。 |
| [^3] | [Learning on Graphs with Out-of-Distribution Nodes.](http://arxiv.org/abs/2308.06714) | 这篇论文提出了一种在图中学习的方法，能够处理存在分布外节点（OOD nodes）的场景。作者定义了分布外节点，并设定了两个任务：检测不属于已知分布的节点，并对剩余节点进行分类。他们通过提出的Out-of-Distribution Graph Attention Network (OODGAT)方法来解决这个问题。 |
| [^4] | [Camouflaged Image Synthesis Is All You Need to Boost Camouflaged Detection.](http://arxiv.org/abs/2308.06701) | 该研究提出了一个用于合成伪装数据以改善对自然场景中伪装物体检测的框架，该方法利用生成模型生成逼真的伪装图像，并在三个数据集上取得了优于目前最先进方法的结果。 |
| [^5] | [MACO: A Modality Adversarial and Contrastive Framework for Modality-missing Multi-modal Knowledge Graph Completion.](http://arxiv.org/abs/2308.06696) | 提出了一种名为MACO的模态对抗和对比框架，用于解决多模态知识图完成中的模态缺失问题，通过对抗训练生成器和判别器生成缺失模态特征，并使用跨模态对比损失改善生成器性能。 |
| [^6] | [Video Captioning with Aggregated Features Based on Dual Graphs and Gated Fusion.](http://arxiv.org/abs/2308.06685) | 本文提出了一种基于双图和门控融合的视频字幕生成模型，通过适应两种类型的图来生成多样的特征表示，并利用门控融合来更好地理解视频内容。 |
| [^7] | [Law of Balance and Stationary Distribution of Stochastic Gradient Descent.](http://arxiv.org/abs/2308.06671) | 本文证明了随机梯度下降算法中的小批量噪音会使解决方案向平衡解靠近，只要损失函数包含重新缩放对称性。利用这个结果，我们导出了对角线性网络的随机梯度流稳态分布，该分布展示了复杂的非线性现象。这些发现揭示了动态梯度下降法在训练神经网络中的工作原理。 |
| [^8] | [Unsupervised Adaptation of Polyp Segmentation Models via Coarse-to-Fine Self-Supervision.](http://arxiv.org/abs/2308.06665) | 本研究提出了一种新的方法来解决无监督自适应问题，称为区域到像素自适应网络（RPANet）。通过由粗到细的自监督学习方法，RPANet能够学习目标域的区域级别和像素级别的判别表示。这种方法解决了目标域内在结构被忽视的问题，并解决了伪标签自训练中的误差累积问题。 |
| [^9] | [ALGAN: Time Series Anomaly Detection with Adjusted-LSTM GAN.](http://arxiv.org/abs/2308.06663) | 该论文提出了一种名为ALGAN的新型GAN模型，通过调整LSTM网络的输出，实现了在无监督设置下对单变量和多变量时间序列数据进行异常检测，并在实验中优于传统方法和其他GAN方法。 |
| [^10] | [Smart Knowledge Transfer using Google-like Search.](http://arxiv.org/abs/2308.06653) | 研究提出了SMARTKT，通过一个类似谷歌搜索的框架，将程序理解过程转化为语义图查询，从而解决了软件维护成本上升的挑战。 |
| [^11] | [Accelerating Diffusion-based Combinatorial Optimization Solvers by Progressive Distillation.](http://arxiv.org/abs/2308.06644) | 本文提出使用逐步蒸馏来加速基于扩散的组合优化求解器，并在TSP-50数据集上展示了16倍的推理速度提升，仅有0.019%的性能降级。 |
| [^12] | [Can Unstructured Pruning Reduce the Depth in Deep Neural Networks?.](http://arxiv.org/abs/2308.06619) | 本研究介绍了一种名为EGP的创新的熵引导剪枝算法，该算法能够通过优先剪除熵较低的层中的连接来有效压缩深度神经网络，同时保持其竞争性能水平。 |
| [^13] | [On the Interplay of Convolutional Padding and Adversarial Robustness.](http://arxiv.org/abs/2308.06612) | 本研究分析了卷积填充和对抗攻击之间的相互作用，探讨了不同填充模式对对抗鲁棒性的影响。 |
| [^14] | [Bio-SIEVE: Exploring Instruction Tuning Large Language Models for Systematic Review Automation.](http://arxiv.org/abs/2308.06610) | 本研究通过探索大型语言模型在医学系统性评述中的应用，尤其是通过指令调优来提高摘要筛选的性能，提出了一种名称为Bio-SIEVE的模型，该模型在医学领域中表现出优异的泛化能力和性能，但在安全性优先场景下仍存在挑战。同时，我们也尝试了多任务训练，但发现其不能与单任务的Bio-SIEVE性能相匹配。这一研究是为了将语言模型专门用于生物医学系统性评述过程迈出的重要一步。我们提供了模型、代码和DOI列表以供复现。 |
| [^15] | [VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use.](http://arxiv.org/abs/2308.06595) | VisIT-Bench是一个用于评价真实世界中视觉语言模型指示遵循的基准，包含了各种任务并提供了详细描述，可以自动评估多模态生成的质量差距。 |
| [^16] | [Value-Distributional Model-Based Reinforcement Learning.](http://arxiv.org/abs/2308.06590) | 该论文介绍了一种基于价值分布模型的强化学习方法，该方法通过学习后验分布来解决决策任务中的政策不确定性问题。所提出的算法能够有效地优化策略，在连续控制任务中表现出性能优势。 |
| [^17] | [Approximate Answering of Graph Queries.](http://arxiv.org/abs/2308.06585) | 本章概述了几种方法，用于在知识图谱不完整的情况下回答查询。这些方法涵盖了不同的查询类型和图类型，并具有不同的推理能力。 |
| [^18] | [4DRVO-Net: Deep 4D Radar-Visual Odometry Using Multi-Modal and Multi-Scale Adaptive Fusion.](http://arxiv.org/abs/2308.06573) | 4DRVO-Net是一种深度4D雷达-视觉里程计的方法，它通过整合4D雷达和相机的信息，并利用多尺度特征提取网络和成本体积网络逐步估计和改进姿态。 |
| [^19] | [ModelScope Text-to-Video Technical Report.](http://arxiv.org/abs/2308.06571) | 本论文介绍了ModelScopeT2V，一种从文本到视频合成的模型。该模型采用时空块确保帧生成和运动过渡的一致性，并能适应不同的帧数量。ModelScopeT2V在三个评估指标上表现出优越性能，代码和在线演示可在指定链接获取。 |
| [^20] | [MC-DRE: Multi-Aspect Cross Integration for Drug Event/Entity Extraction.](http://arxiv.org/abs/2308.06546) | 本文提出了一个新的多方面交叉整合框架，用于从药物相关文档中提取药物事件/实体。该框架能够捕捉并对齐不同的上下文/语言/知识属性，并实现药物事件信息的全面检测和理解。 |
| [^21] | [Digital elevation model correction in urban areas using extreme gradient boosting, land cover and terrain parameters.](http://arxiv.org/abs/2308.06545) | 本研究采用了极限梯度提升算法来提高城市区域中数字高程模型的精度，并结合土地覆盖和地形参数校正，以解决DEM在城市环境建模中的质量和适用性问题。 |
| [^22] | [Dealing with Small Annotated Datasets for Deep Learning in Medical Imaging: An Evaluation of Self-Supervised Pre-Training on CT Scans Comparing Contrastive and Masked Autoencoder Methods for Convolutional Models.](http://arxiv.org/abs/2308.06534) | 本研究评估了在医学影像领域使用自监督预训练方法的可行性，比较了共同对比学习和掩码自编码器方法在CT扫描卷积模型中的性能。 |
| [^23] | [Learning Abstract Visual Reasoning via Task Decomposition: A Case Study in Raven Progressive Matrices.](http://arxiv.org/abs/2308.06528) | 通过任务分解学习抽象视觉推理，提出了一种基于变形器蓝图的深度学习架构，该架构预测单个对象及其排列的视觉特性，通过多维预测来选择答案。 |
| [^24] | [SLoRA: Federated Parameter Efficient Fine-Tuning of Language Models.](http://arxiv.org/abs/2308.06522) | SLoRA是一种联邦参数高效微调语言模型的方法，用于在联邦学习中利用分布式和私有数据进行微调，以克服高异构数据下的性能差距。 |
| [^25] | [HyperFormer: Enhancing Entity and Relation Interaction for Hyper-Relational Knowledge Graph Completion.](http://arxiv.org/abs/2308.06512) | HyperFormer是一个考虑局部级顺序信息的模型，用于解决超关系知识图谱补全中多跳信息引入噪音的问题。 |
| [^26] | [Three Ways of Using Large Language Models to Evaluate Chat.](http://arxiv.org/abs/2308.06502) | 本文提出了三种使用大型语言模型（LLMs）评估聊天的方法，并报告了相对于基准线的改进。还分析了另外两种方法的性能，并提出了未来工作的改进方向。 |
| [^27] | [Latent Emission-Augmented Perspective-Taking (LEAPT) for Human-Robot Interaction.](http://arxiv.org/abs/2308.06498) | 该论文介绍了一个名为LEAPT的方法，通过使用隐变量发射增强的透视视角模型，使机器人能够理解和推断人类观察和信念，该模型通过优化ELBO来学习隐空间中的不确定性。 |
| [^28] | [EgoPoser: Robust Real-Time Ego-Body Pose Estimation in Large Scenes.](http://arxiv.org/abs/2308.06493) | 本文提出了EgoPoser，一种能够在大场景中鲁棒地实时估计自我身体姿势的方法。通过重新思考输入表示、引入新的运动分解方法以及建模身体姿势，EgoPoser在定性和定量上均表现优于现有方法，并具有较高的推理速度。 |
| [^29] | [Generating Faithful Text From a Knowledge Graph with Noisy Reference Text.](http://arxiv.org/abs/2308.06488) | 本文提出了一种KG到文本生成模型，能够在存在噪声参考文本的情况下，从给定的图生成忠实的自然语言文本 |
| [^30] | [Not So Robust After All: Evaluating the Robustness of Deep Neural Networks to Unseen Adversarial Attacks.](http://arxiv.org/abs/2308.06467) | 这项研究旨在评估深度神经网络对未知对抗攻击的鲁棒性，并挑战针对这些攻击的现有防御机制的有效性。实验结果表明，在仅使用鲁棒特征的数据集上训练的DNN模型并不一定能抵抗对抗性攻击。 |
| [^31] | [Multi-Label Knowledge Distillation.](http://arxiv.org/abs/2308.06453) | 这篇论文提出了一种专门针对多标签学习的新颖知识蒸馏方法，通过将多标签问题分解为一组二分类问题以利用逻辑回归的信息性语义知识，并通过利用标签嵌入的结构信息增强学习到的特征表示的独特性。 |
| [^32] | [Semantic Equivariant Mixup.](http://arxiv.org/abs/2308.06451) | 这篇论文提出了一种基于语义等变的Mixup方法，通过在表示级别上进行混合来充分利用混合样本中的语义信息，进一步规范神经网络。 |
| [^33] | [A Sequential Meta-Transfer (SMT) Learning to Combat Complexities of Physics-Informed Neural Networks: Application to Composites Autoclave Processing.](http://arxiv.org/abs/2308.06447) | 本论文提出了一种顺序元转移（SMT）学习框架，用于解决物理信息神经网络（PINNs）在高度非线性系统中的训练和适应问题，提供了一种统一的、快速的解决方案。 |
| [^34] | [Sensitivity-Aware Mixed-Precision Quantization and Width Optimization of Deep Neural Networks Through Cluster-Based Tree-Structured Parzen Estimation.](http://arxiv.org/abs/2308.06422) | 本研究引入了一种创新的深度神经网络优化方法，通过自动选择最佳的位宽和层宽来提高网络效率。同时，通过剪枝和聚类技术，优化了搜索过程，并在多个数据集上进行了严格测试，结果显示该方法明显优于现有方法。 |
| [^35] | [Pedestrian Trajectory Prediction in Pedestrian-Vehicle Mixed Environments: A Systematic Review.](http://arxiv.org/abs/2308.06419) | 本文系统综述了行人-车辆混合环境下的行人轨迹预测方法，探讨了车辆和行人的相互作用对行人未来行为的影响，并回顾了先前提出的预测模型中如何考虑不确定性和行为差异。 |
| [^36] | [Dialogue Possibilities between a Human Supervisor and UAM Air Traffic Management: Route Alteration.](http://arxiv.org/abs/2308.06411) | 本文介绍了一种基于知识表示和推理的方法，在城市空中交通管理中实现了人类监管者和系统之间的对话，并通过验证了该方法的稳健性和效力，为人类知识和先进AI技术的共生做出了贡献。 |
| [^37] | [A Brain-Computer Interface Augmented Reality Framework with Auto-Adaptive SSVEP Recognition.](http://arxiv.org/abs/2308.06401) | 提出了一种自适应的SSVEP识别的脑机接口增强现实框架，可以帮助身体残障人士和健康用户使用增强现实技术进行交互，通过稳态视觉诱发电位（SSVEP）信号识别用户需求和愿望。 |
| [^38] | [ZYN: Zero-Shot Reward Models with Yes-No Questions.](http://arxiv.org/abs/2308.06385) | 本文提出了ZYN框架，通过使用是非问题作为奖励模型的提示，以及增强学习来微调语言模型，使其生成的文本与人类操作者的偏好对齐。实验证据表明该方法在不同领域的文本生成任务中具有很好的效果，包括解毒、情感优化和个性化提示生成器等。 |
| [^39] | [DCNFIS: Deep Convolutional Neuro-Fuzzy Inference System.](http://arxiv.org/abs/2308.06378) | 本文介绍了一种新的深度卷积神经模糊推理系统（DCNFIS），它通过将模糊逻辑和深度学习模型相结合，实现了提高透明度而不损失准确性的目标。DCNFIS在准确性上与现有卷积神经网络相当，并且胜过了最先进的深度模糊系统。通过模糊规则提取的解释可以提高模型的可解释性。 |
| [^40] | [Large Language Models and Knowledge Graphs: Opportunities and Challenges.](http://arxiv.org/abs/2308.06374) | 大型语言模型和知识图谱的结合为知识表示带来了新的机遇和挑战。 |
| [^41] | [Wireless Federated $k$-Means Clustering with Non-coherent Over-the-Air Computation.](http://arxiv.org/abs/2308.06371) | 本研究提出了一种利用无线信道的非相干空中计算方案来降低联合k均值聚类算法在无线网络上的通信延迟。此方法通过利用平衡进制和信号叠加性质实现联合k均值的更新，同时通过重新初始化未有效使用的质心来改善对异构数据分布的聚类性能。 |
| [^42] | [Topic-Level Bayesian Surprise and Serendipity for Recommender Systems.](http://arxiv.org/abs/2308.06368) | 本文通过引入基于主题的贝叶斯惊喜概念，提出了一种用于推荐系统的意外性模型，以解决过滤泡问题，通过识别相似用户和测量用户对物品的意外性来推荐具有高潜力的意外性物品。 |
| [^43] | [Large Language Models to Identify Social Determinants of Health in Electronic Health Records.](http://arxiv.org/abs/2308.06354) | 本研究利用大型语言模型从电子健康记录中提取社会健康决定因素（SDoH），并通过合成临床文本改进了这些极有价值但很少被记录的临床数据的提取。最佳模型为经过微调的Flan-T5 XL和Flan-T5 XXL，其中小型模型改进了性能。 |
| [^44] | [Combining feature aggregation and geometric similarity for re-identification of patterned animals.](http://arxiv.org/abs/2308.06335) | 本文提出了一种组合特征聚合和几何相似性的方法，用于图案动物的重新识别。该方法利用图案的外观相似度和几何一致性来实现综合性的重新识别，可以适用于各种不同类型的图案。 |
| [^45] | [Defensive Perception: Estimation and Monitoring of Neural Network Performance under Deployment.](http://arxiv.org/abs/2308.06299) | 本文提出了一种方法，用于解决自动驾驶中神经网络的部署中不被察觉的灾难性问题和领域转移问题。我们通过不确定性估计封装了部署中的神经网络，以提高感知系统的性能和安全性。 |
| [^46] | [Enhancing Phenotype Recognition in Clinical Notes Using Large Language Models: PhenoBCBERT and PhenoGPT.](http://arxiv.org/abs/2308.06294) | 本研究利用大型语言模型（LLMs）开发了两种表型识别模型PhenoBCBERT和PhenoGPT，相比于基于规则和深度学习的方法，这些模型能够更准确地识别临床表型术语，包括HPO未记录的新术语。 |
| [^47] | [Are We Closing the Loop Yet? Gaps in the Generalizability of VIS4ML Research.](http://arxiv.org/abs/2308.06290) | VIS4ML研究在推广实践应用方面存在差异，需要填补未被代表性情况过度拟合、缺乏关键依赖因素的空白。 |
| [^48] | [Towards a Comprehensive Human-Centred Evaluation Framework for Explainable AI.](http://arxiv.org/abs/2308.06274) | 本论文提出了一个综合的以人为中心的评估框架，用于评估可解释的人工智能（XAI）。当前的评估过程不全面评估XAI方法的效果，也未将解释对人类的影响视为一种复杂的用户体验。我们的框架整合了解释的因素，总结了解释的特性，并分类了测量这些特性的指标，旨在为XAI评估的以人为中心的标准化做出贡献。 |
| [^49] | [Beyond Reality: The Pivotal Role of Generative AI in the Metaverse.](http://arxiv.org/abs/2308.06272) | 本文全面探讨了生成式人工智能技术如何塑造元宇宙，将其转变为一个充满活力、沉浸式和互动式的虚拟世界。我们深入研究了文本生成模型（如ChatGPT和GPT-3）和图像生成模型（如DALL-E和MidJourney）的应用，以及三维模型生成技术（如Point-E和Lumirithmic）的潜力。同时，我们还讨论了实施这些技术所面临的挑战和伦理考虑。 |
| [^50] | [Rotation-Invariant Random Features Provide a Strong Baseline for Machine Learning on 3D Point Clouds.](http://arxiv.org/abs/2308.06271) | 本研究提出了一种简单且通用的方法，使用随机特征学习三维点云数据的旋转不变函数，为机器学习在3D点云上提供了一个强大的基准。 |
| [^51] | [Improving Zero-Shot Text Matching for Financial Auditing with Large Language Models.](http://arxiv.org/abs/2308.06111) | 这项研究提出了ZeroShotALI，它使用了一种新颖的推荐系统来改进金融审计中的零样本文本匹配。通过采用大型语言模型（LLM）和经过领域优化的基于transformer的文本匹配解决方案，该系统实现了从报告中推荐与法律要求相符的相关文本段落，并在现有方法上取得了显著的性能提升。 |
| [^52] | [Audio-Visual Spatial Integration and Recursive Attention for Robust Sound Source Localization.](http://arxiv.org/abs/2308.06087) | 本文提出了一种音频-视觉空间融合网络，通过整合音频和视觉模态的空间线索来模仿人类检测声音产生物体的行为，并引入递归注意力网络来得到更准确的注意力区域。通过音频和视觉模态的空间线索和递归聚焦策略，方法在声源定位任务上取得了良好的性能。 |
| [^53] | [Cost-effective On-device Continual Learning over Memory Hierarchy with Miro.](http://arxiv.org/abs/2308.06053) | 这项工作是首次探索基于层次内存回放的持续学习的设计空间，旨在在边缘设备上实现成本效益。提出了Miro，一个通过动态配置持续学习系统的新颖系统运行时，以实现最佳的成本效益。广泛的评估显示Miro明显优于其他方案。 |
| [^54] | [Audio is all in one: speech-driven gesture synthetics using WavLM pre-trained model.](http://arxiv.org/abs/2308.05995) | 本文介绍了一种利用WavLM预训练模型的基于语音驱动的手势合成方法，实现只使用原始语音音频生成个性化全身手势，消除了复杂的多模态处理和手动注释的需求。 |
| [^55] | [Multi-domain Recommendation with Embedding Disentangling and Domain Alignment.](http://arxiv.org/abs/2308.05508) | 该研究提出了一种新的多领域推荐方法EDDA，它通过嵌入解耦推荐器和领域对齐两个关键组件分别解决了知识解耦和跨领域知识转移的挑战。 |
| [^56] | [Beyond Semantics: Learning a Behavior Augmented Relevance Model with Self-supervised Learning.](http://arxiv.org/abs/2308.05379) | 这篇论文提出了一种行为增强的相关模型，利用自我监督学习，通过从用户历史行为数据中提取辅助查询-项目交互，来改进搜索引擎中的查询-项目匹配，提高准确性和鲁棒性。 |
| [^57] | [LayoutLLM-T2I: Eliciting Layout Guidance from LLM for Text-to-Image Generation.](http://arxiv.org/abs/2308.05095) | 本论文提出了LayoutLLM-T2I的方法，用于从LLM中获取布局指导以用于文本到图像生成。该方法采用由粗到细的范例，通过基于大型语言模型的上下文学习，在给定文本提示的条件下合成与文本语义对齐的高保真度图像。 |
| [^58] | [Adversarial Deep Reinforcement Learning for Cyber Security in Software Defined Networks.](http://arxiv.org/abs/2308.04909) | 本文研究了在软件定义网络中利用对抗性学习来训练更加鲁棒的深度强化学习智能体，探讨了两种算法的差异。攻击者利用因果攻击试图破坏学习过程。游戏中进行了有序的因果攻击。 |
| [^59] | [NLLG Quarterly arXiv Report 06/23: What are the most influential current AI Papers?.](http://arxiv.org/abs/2308.04889) | 该报告关注当前最具影响力的AI论文，并以标准化引用计数为依据编制了40篇最受欢迎的论文列表。观察到在2023年上半年，大型语言模型（LLMs）和具体而言的ChatGPT相关的论文占主导地位，ChatGPT表现出下降的趋势。 |
| [^60] | [Bird's-Eye-View Scene Graph for Vision-Language Navigation.](http://arxiv.org/abs/2308.04758) | 这项研究提出了一种鸟瞰场景图（BSG）用于视觉语言导航，通过使用多步鸟瞰表示来编码场景布局和几何线索，从而改进了当前全景观察的导航代理的能力，并提供了更准确的动作预测。 |
| [^61] | [Fine-Tuning Games: Bargaining and Adaptation for General-Purpose Models.](http://arxiv.org/abs/2308.04399) | 本文提出了一个模型，探讨了通用模型的微调过程中的利润分享问题，为一般类的成本和收入函数描述了解决方案的条件。 |
| [^62] | [Diffusion Model in Causal Inference with Unmeasured Confounders.](http://arxiv.org/abs/2308.03669) | 本研究扩展了扩散模型的使用，提出了一种新的模型BDCM，可以在存在无法测量的混淆因素的情况下更准确地回答因果问题。 |
| [^63] | [Discrete Message via Online Clustering Labels in Decentralized POMDP.](http://arxiv.org/abs/2308.03358) | 本文通过建立回报差距上界，将多智能体通信问题转化为离散消息的在线聚类问题。该方法能够提供量化保证，并且具有通信开销低、可解释性好的特点。 |
| [^64] | [Expediting Neural Network Verification via Network Reduction.](http://arxiv.org/abs/2308.03330) | 本研究提出了一种网络简化技术，在验证之前对神经网络进行预处理，通过消除稳定的ReLU神经元，并将其转化为由ReLU和仿射层组成的顺序神经网络，从而显著减小了神经网络的规模并加速了现有的验证工具。 |
| [^65] | [Source-free Domain Adaptive Human Pose Estimation.](http://arxiv.org/abs/2308.03202) | 提出了无源域自适应的人体姿势估计任务，旨在解决在适应过程中无法访问源数据的跨域学习挑战。通过提出的新框架，源保护模块更有效地保留源信息并抵抗噪声。 |
| [^66] | [A stochastic optimization approach to train non-linear neural networks with regularization of higher-order total variation.](http://arxiv.org/abs/2308.02293) | 通过引入高阶总变差正则化的随机优化算法，可以高效地训练非线性神经网络，避免过拟合问题。 |
| [^67] | [ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on Class-level Code Generation.](http://arxiv.org/abs/2308.01861) | ClassEval是一种手工构建的类级代码生成基准，该研究首次尝试在这一更具挑战性的场景中评估LLMs，并发现现有LLMs在类级代码生成上的性能相对较差。GPT-4和GPT-3.5在类级代码生成方面表现出相对其他LLMs更卓越的优势。 |
| [^68] | [LiDAR-Camera Panoptic Segmentation via Geometry-Consistent and Semantic-Aware Alignment.](http://arxiv.org/abs/2308.01686) | 本文提出了LCPS，第一个LiDAR-相机全景分割网络，通过异步补偿像素对齐、语义感知区域对齐和点到体素特征传播的融合策略，显著提高了全景分割的性能。 |
| [^69] | [Can We Transfer Noise Patterns? An Multi-environment Spectrum Analysis Model Using Generated Cases.](http://arxiv.org/abs/2308.01138) | 这项研究提出了一个噪声模式转移模型，可以将噪声模式从不同环境的标准样本应用到未知样本，通过生成案例库来解决样本级噪声对数据集级噪声学习的干扰，提高了系统的学习性能。 |
| [^70] | [A Counterfactual Safety Margin Perspective on the Scoring of Autonomous Vehicles' Riskiness.](http://arxiv.org/abs/2308.01050) | 本文基于反事实模拟提出了一个数据驱动的框架，用于比较不同自动驾驶车辆在不同操作设计领域中行为风险。通过引入反事实安全边界的概念，该框架可以找到最关键的情景，并评估自动驾驶车辆的风险频率和严重程度。该方法即使在自动驾驶车辆的行为策略未知的情况下也适用，对外部第三方风险评估机构有用。 |
| [^71] | [FusionAD: Multi-modality Fusion for Prediction and Planning Tasks of Autonomous Driving.](http://arxiv.org/abs/2308.01006) | FusionAD是第一个将来自相机和激光雷达的信息融合起来用于自动驾驶预测和规划任务的统一框架，在常用数据集上的实验中达到了最先进的性能。 |
| [^72] | [Contrastive Learning for API Aspect Analysis.](http://arxiv.org/abs/2307.16878) | 这项研究提出了一种对API方面分析进行对比学习的方法，通过训练变换器模型并使用监督对比损失函数，可以显著改进性能，对Performance、Security、Usability和Documentation等方面的检测效果进行了评估，并进行了实证和开发者研究验证。 |
| [^73] | [On the use of associative memory in Hopfield networks designed to solve propositional satisfiability problems.](http://arxiv.org/abs/2307.16807) | 该论文研究了在解决命题可满足性问题的Hopfield网络中使用关联记忆的方法。通过自我优化模型，网络可以解决具体的组合问题。然而，研究还发现在某些情况下，关键信息可能会永久丢失，导致网络产生看似最优但实际上不适用的解决方案。这一发现对理解网络解决难以处理问题的过程很有启发。 |
| [^74] | [On the Trustworthiness Landscape of State-of-the-art Generative Models: A Comprehensive Survey.](http://arxiv.org/abs/2307.16680) | 本文综合调查了大规模生成模型的可信度问题，涵盖了隐私、安全、公平性和责任等多个维度，并提出了实际建议和未来发展方向。 |
| [^75] | [Relation-Oriented: Toward Knowledge-Aligned Causal AI.](http://arxiv.org/abs/2307.16387) | 本研究从创新的关系导向视角出发，探讨了当前的建模范式中的观察模型与实际理解的不对齐问题，并提出了关系定义的表示学习方法作为实现关系导向建模的实践方法。 |
| [^76] | [AlignDet: Aligning Pre-training and Fine-tuning in Object Detection.](http://arxiv.org/abs/2307.11077) | 本文提出了一个统一的预训练框架AlignDet，通过将预训练过程分解为图像域和框域预训练，可以减轻目标检测中现有实践中的数据、模型和任务差异，提高检测器性能和泛化能力。 |
| [^77] | [The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence.](http://arxiv.org/abs/2307.07522) | 生成型人工智能和大型语言模型可能为基础科学的发现提供机会，通过其自主生成假设和探索假设空间的闭环方法，加速科学发现的进程。 |
| [^78] | [VesselMorph: Domain-Generalized Retinal Vessel Segmentation via Shape-Aware Representation.](http://arxiv.org/abs/2307.00240) | VesselMorph使用一个基于形状感知的表征方法，通过合成血管的形态学特征来推广视网膜血管分割任务，以提高深度模型的通用性。 |
| [^79] | [Transforming Graphs for Enhanced Attribute-Based Clustering: An Innovative Graph Transformer Method.](http://arxiv.org/abs/2306.11307) | 本文提出了一种称为GTAGC的图形自编码器图形变换自编码器方法，通过融合图自编码器和图形变换器，GTAGC能够捕获全局依赖关系，从而有助于提高图聚类的性能。 |
| [^80] | [STUDY: Socially Aware Temporally Casual Decoder Recommender Systems.](http://arxiv.org/abs/2306.07946) | 该论文提出了一种基于社交感知和时间因素的解码器推荐系统(STUDY)，使用transformer解码器网络实现对社交网络图中相邻的用户组的联合推断。该方法在教育内容领域中经过测试，能够取得优于社交和顺序方法的结果。 |
| [^81] | [MADiff: Offline Multi-agent Learning with Diffusion Models.](http://arxiv.org/abs/2305.17330) | 本论文提出了基于注意力的扩散模型MADiff，解决了多智能体问题，是第一个扩散模型应用于多智能体离线RL的框架。 |
| [^82] | [How many samples are needed to leverage smoothness?.](http://arxiv.org/abs/2305.16014) | 本文通过研究泛化误差的新下界，探讨了学习平滑函数时需要的样本数量及其机器学习问题中的挑战。 |
| [^83] | [Testing System Intelligence.](http://arxiv.org/abs/2305.11472) | 该论文讨论了以往智能系统测试的不足和所提出的替换测试作为一种完善测试的能力，该测试反映了人类和机器之间的技能互补性，能够构建更多反映智能可能的概念和属性。 |
| [^84] | [Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization.](http://arxiv.org/abs/2305.11095) | 本文通过提示工程技术调整Whisper模型，成功适应未见过的三个任务，并提出的提示比默认提示性能提升了10%到45％，展现了Whisper模型的鲁棒性和多语言理解能力。 |
| [^85] | [G-MATT: Single-step Retrosynthesis Prediction using Molecular Grammar Tree Transformer.](http://arxiv.org/abs/2305.03153) | G-MATT是一个结合数据驱动模型与化学知识的化学感知回溯合成预测框架，在分层SMILES语法树输入的基础上采用树到序列变换器架构，能够显著提高单步回溯合成的准确率。 |
| [^86] | [Optimizing the AI Development Process by Providing the Best Support Environment.](http://arxiv.org/abs/2305.00136) | 本研究旨在提供人工智能（AI）和机器学习（ML）应用的最佳支持环境，具体重点研究了ML开发中数据管理阶段的障碍以及如何构建和开发一个框架，利用多种数据增强技术来解决数据管理阶段缺乏足够数据的问题。 |
| [^87] | [UDTIRI: An Open-Source Road Pothole Detection Benchmark Suite.](http://arxiv.org/abs/2304.08842) | 该论文介绍了一个开源的道路坑洞检测基准套件UDTIRI，包含了标记齐全的1000张道路坑洞图像，可以用于深度学习方法在城市道路检查中的目标检测、语义分割和实例分割任务。 |
| [^88] | [Procedural Generation of Complex Roundabouts for Autonomous Vehicle Testing.](http://arxiv.org/abs/2303.17900) | 本文提出了一种基于附近道路结构的几何限制的过程生成方法，用于生成非完全圆形且类似于真实世界中的环形交叉口的车道，适用于自动驾驶场景测试。 |
| [^89] | [Multi-View Zero-Shot Open Intent Induction from Dialogues: Multi Domain Batch and Proxy Gradient Transfer.](http://arxiv.org/abs/2303.13099) | 本研究提出了一种多领域批处理和代理梯度转移的语义多视角模型，可以解决任务导向对话系统中的意图检测和诱导新意图的问题，在Open Intent Induction中有显著的性能提升。 |
| [^90] | [Breaking Common Sense: WHOOPS! A Vision-and-Language Benchmark of Synthetic and Compositional Images.](http://arxiv.org/abs/2303.07274) | WHOOPS!是一个新的视觉常识数据集和基准测试，包括了图像字幕、跨模态匹配和视觉问答等若干个任务，引入了解释生成任务，挑战了AI模型识别和解释不合常规的图像的能力。 |
| [^91] | [TARGET: Federated Class-Continual Learning via Exemplar-Free Distillation.](http://arxiv.org/abs/2303.06937) | 本文研究了一个重要但鲜为人知的问题：联邦类式持续学习，在联邦学习中动态添加新的类别。我们提出了一种称为TARGET的新颖方法，通过无样本蒸馏来减轻FCCL中的灾难性遗忘问题，并保护客户数据的隐私。该方法利用先前训练的全局模型在模型层面上传递旧任务的知识，并通过生成器生成合成数据来模拟数据的全局分布。与先前的FCCL方法相比，TARGET无需额外的数据集或存储先前任务的私有数据。 |
| [^92] | [Real-Time Tube-Based Non-Gaussian Risk Bounded Motion Planning for Stochastic Nonlinear Systems in Uncertain Environments via Motion Primitives.](http://arxiv.org/abs/2303.01631) | 本文提出了一种实时在线运动规划算法，用于在不确定环境中的随机非线性系统中进行长期任务的规划。这种方法通过构建离散时间运动基元和连续时间管状体来保证系统状态的安全性。 |
| [^93] | [Non-Gaussian Uncertainty Minimization Based Control of Stochastic Nonlinear Robotic Systems.](http://arxiv.org/abs/2303.01628) | 本文提出了一种针对非线性机器人系统的闭环控制问题的解决方案，通过最小化不确定性和干扰引起的系统状态偏差，设计了一个状态反馈控制器。相比于现有方法，该方法可以处理非线性动力学模型和任意已知概率不确定性。 |
| [^94] | [RemoteNet: Remote Sensing Image Segmentation Network based on Global-Local Information.](http://arxiv.org/abs/2302.13084) | 本文提出了一种名为RemoteNet的遥感图像分割网络，通过使用全局-局部信息和多尺度特征，以及注意力机制和Transformer进行特征融合和学习，改进了遥感图像的语义分割性能。 |
| [^95] | [Why Target Networks Stabilise Temporal Difference Methods.](http://arxiv.org/abs/2302.12537) | 本文解释了深度强化学习中一种流行的时序差分方法中关键的稳定性问题：为什么目标网络能够有效降低不满足条件时的影响。 |
| [^96] | [SAT Requires Exhaustive Search.](http://arxiv.org/abs/2302.09512) | 本文证明了对于一些具有大域和长子句的极难例子，要求进行彻底搜索才能解决，这意味着P $\neq$ NP。 |
| [^97] | [LabelPrompt: Effective Prompt-based Learning for Relation Classification.](http://arxiv.org/abs/2302.08068) | LabelPrompt是一种面向关系分类任务的提示式学习方法，通过定义额外的令牌来表示关系标签，并使用提示模板方法明确构建它们，从而解决了将填充掩码标记的自然语言词汇与语义关系标签相关联的挑战。同时，该方法还实现了一个实体感知模块来减轻预测关系和给定实体之间的不一致性。 |
| [^98] | [HumanMAC: Masked Motion Completion for Human Motion Prediction.](http://arxiv.org/abs/2302.03665) | HumanMAC是一个掩码动作修复框架，通过训练阶段的运动扩散模型和推断阶段的去噪过程，在观察到的运动数据的控制下进行运动预测，并在多个基准数据集上展示了显著的改进。 |
| [^99] | [Zero-shot causal learning.](http://arxiv.org/abs/2301.12292) | 无先验因果学习是一个解决预测新型干预措施个性化影响的框架，并通过元学习对任务的处理达成了目的，能够将干预措施的知识传输到未见过的干预措施中，并在合成和真实数据集上表现出了优越性能。 |
| [^100] | [Slice Transformer and Self-supervised Learning for 6DoF Localization in 3D Point Cloud Maps.](http://arxiv.org/abs/2301.08957) | 这篇论文介绍了一种新的自监督学习方法，首次使用Transformer进行室外定位的任务。作者提出了切片Transformer模型，并利用轴向特性重新组织了激光雷达扫描的切片。此外，作者还引入了Perth-WA数据集，并在多个数据集上进行了实验评估，证明了方法的有效性。 |
| [^101] | [Data-centric Artificial Intelligence.](http://arxiv.org/abs/2212.11854) | 数据中心人工智能是一种新兴的范式，它强调系统性地设计和构建数据对于建立有效和高效的基于人工智能的系统至关重要。 |
| [^102] | [Foiling Explanations in Deep Neural Networks.](http://arxiv.org/abs/2211.14860) | 本文发现了解释图像 DNN 的一个令人担忧的属性：通过微小视觉更改，我们演示了解释可以通过进化策略任意操纵。我们提出了 AttaXAI，一个针对 XAI 算法的敌对攻击，可访问分类器输出信息和解释图，这使得我们的方法在实际应用中非常有用。 |
| [^103] | [StyleNAT: Giving Each Head a New Perspective.](http://arxiv.org/abs/2211.05770) | StyleNAT是一个新的基于transformer的图像生成框架，通过使用邻域注意力（NA）来捕捉局部和全局信息，能够高效灵活地适应不同的数据集，并在FFHQ-256上取得了新的最佳结果。 |
| [^104] | [Agent-Controller Representations: Principled Offline RL with Rich Exogenous Information.](http://arxiv.org/abs/2211.00164) | 本文针对具有丰富外部信息的原则性离线强化学习进行研究，并提出了新的离线强化学习基准。研究发现，当噪声是复杂且与时间相关的过程时，现有的表示学习技术可能无法成功应用于这类数据集。 |
| [^105] | [JAX-DIPS: Neural bootstrapping of finite discretization methods and application to elliptic problems with discontinuities.](http://arxiv.org/abs/2210.14312) | JAX-DIPS是一种基于有限离散方法和神经网络的可伸缩策略，用于开发无网格混合神经符号偏微分方程求解器，并在具有间断的椭圆问题中得到应用。 |
| [^106] | [NECE: Narrative Event Chain Extraction Toolkit.](http://arxiv.org/abs/2208.08063) | NECE是一个开源的故事事件链提取工具包，能够自动提取和对齐故事事件，并可用于分析故事偏见。 |
| [^107] | [Machine Learning and Computer Vision Techniques in Bee Monitoring Applications.](http://arxiv.org/abs/2208.00085) | 本文介绍了机器学习和计算机视觉在蜜蜂监测中的最新应用，展示了自动化蜜蜂计数算法的潜力，并希望能够激发其他科学家的灵感和兴趣。 |
| [^108] | [GUARD: Graph Universal Adversarial Defense.](http://arxiv.org/abs/2204.09803) | GUARD是一种新颖的图形通用对抗防御方法，旨在提高GCNs对针对性攻击的局部节点的鲁棒性，并在不降低整体性能的情况下进行防御。 |
| [^109] | [POSTER: A Pyramid Cross-Fusion Transformer Network for Facial Expression Recognition.](http://arxiv.org/abs/2204.04083) | POSTER是一种金字塔交叉融合变压器网络，旨在全面解决面部表情识别中的类间相似性、类内差异性和尺度敏感性问题。通过设计变压器的交叉融合方法和采用金字塔结构，POSTER达到了最先进的效果。 |
| [^110] | [Scalable Decision-Focused Learning in Restless Multi-Armed Bandits with Application to Maternal and Child Health.](http://arxiv.org/abs/2202.00916) | 本文提出了一种在不安定多臂赌博（RMAB）问题中进行决策集中学习的新方法，通过直接训练预测模型来最大化Whittle指数解决方案质量。 |
| [^111] | [On the Power of Gradual Network Alignment Using Dual-Perception Similarities.](http://arxiv.org/abs/2201.10945) | 本研究提出了Grad-Align，一种渐进网络对齐方法，通过利用强一致性节点对逐步发现节点对。该方法首先生成节点嵌入，然后计算双感知相似性度量逐步对齐节点。 |
| [^112] | [Model-Based Safe Reinforcement Learning with Time-Varying State and Control Constraints: An Application to Intelligent Vehicles.](http://arxiv.org/abs/2112.11217) | 本文提出了一种安全RL算法，结合了基于屏障力的控制策略结构与多步策略评估机制，在保证控制安全的同时，能够应对时间变化的安全约束，并证明了其稳定性、鲁棒性和收敛性，优于几种最先进的RL算法。 |
| [^113] | [Representations of epistemic uncertainty and its perception in data-driven initiatives.](http://arxiv.org/abs/2110.11482) | 本研究为了支持不断发展的数据驱动方法论，提出了一个新颖的概念模型，用于描述知识表示中的不确定性，并推理代理人进行的信息传输。通过对知识状态和其动态的代数描述，我们能够比较和组合知识状态，以表示更新。 |
| [^114] | [Large-scale Autonomous Flight with Real-time Semantic SLAM under Dense Forest Canopy.](http://arxiv.org/abs/2109.06479) | 本文提出了一个集成系统，可以在密集森林林冠下进行大规模自主飞行和实时语义地图构建。系统使用LiDAR数据检测和建模树干和地面平面，并利用多级规划和地图构建框架计算动态可行的轨迹，以构建用户定义感兴趣区域的语义地图，并通过语义SLAM来最小化里程计漂移。 |
| [^115] | [MathBERT: A Pre-trained Language Model for General NLP Tasks in Mathematics Education.](http://arxiv.org/abs/2106.07340) | MathBERT是一个基于BASE BERT模型在大规模数学语料库上进行预训练的模型，为数学教育中的通用NLP任务提供了新的解决方案。 |
| [^116] | [Adaptive Filters in Graph Convolutional Neural Networks.](http://arxiv.org/abs/2105.10377) | 该论文研究了自适应滤波器在图卷积神经网络中的应用，通过探索和利用图结构的灵活性，提高了网络处理图数据的性能。 |
| [^117] | [Causal Collaborative Filtering.](http://arxiv.org/abs/2102.01868) | 本论文提出了一种名为因果协同过滤（CCF）的通用框架，用于对协同过滤和推荐中的因果关系进行建模。这种方法可以解决纯粹相关学习导致的预测中的辛普森悖论问题，提高推荐性能。 |
| [^118] | [Learning NP-Hard Multi-Agent Assignment Planning using GNN: Inference on a Random Graph and Provable Auction-Fitted Q-learning.](http://arxiv.org/abs/1905.12204) | 本文探索了使用学习算法近乎最优地解决具有时间相关奖励的多智能体、多任务的NP-hard规划问题的可能性。研究结果展示了提出方法在解决机器人/机器调度问题上的近乎最优性。 |

# 详细

[^1]: 具有潜变量的因果结构估计的广义独立噪声条件

    Generalized Independent Noise Condition for Estimating Causal Structure with Latent Variables. (arXiv:2308.06718v1 [cs.LG])

    [http://arxiv.org/abs/2308.06718](http://arxiv.org/abs/2308.06718)

    这篇论文提出了具有潜变量的因果结构估计的广义独立噪声（GIN）条件，并给出了线性非高斯无环因果模型中满足GIN条件的图形判据。

    

    我们研究了在存在潜变量的情况下学习因果结构的挑战性任务，包括定位潜变量并确定它们的数量，以及识别潜变量和观测变量之间的因果关系。为了解决这个问题，我们提出了一种适用于包含潜变量的线性非高斯无环因果模型的广义独立噪声（GIN）条件，该条件建立了某些测量变量的线性组合与其他测量变量之间的独立性。具体而言，对于两个观测随机向量 $\bf{Y}$ 和 $\bf{Z}$，当且仅当 $\omega^{\intercal}\mathbf{Y}$ 和 $\mathbf{Z}$ 是独立的时，GIN 成立，其中 $\omega$ 是由 $\mathbf{Y}$ 和 $\mathbf{Z}$ 之间的交叉协方差确定的非零参数向量。然后，我们给出了线性非高斯无环因果模型中 GIN 条件的必要和充分图形判据。简言之，GIN 意味着存在一个外源的...

    We investigate the challenging task of learning causal structure in the presence of latent variables, including locating latent variables and determining their quantity, and identifying causal relationships among both latent and observed variables. To address this, we propose a Generalized Independent Noise (GIN) condition for linear non-Gaussian acyclic causal models that incorporate latent variables, which establishes the independence between a linear combination of certain measured variables and some other measured variables. Specifically, for two observed random vectors $\bf{Y}$ and $\bf{Z}$, GIN holds if and only if $\omega^{\intercal}\mathbf{Y}$ and $\mathbf{Z}$ are independent, where $\omega$ is a non-zero parameter vector determined by the cross-covariance between $\mathbf{Y}$ and $\mathbf{Z}$. We then give necessary and sufficient graphical criteria of the GIN condition in linear non-Gaussian acyclic causal models. Roughly speaking, GIN implies the existence of an exogenous se
    
[^2]: 估计和激励具有隐藏奖励的不完全知识代理

    Estimating and Incentivizing Imperfect-Knowledge Agents with Hidden Rewards. (arXiv:2308.06717v1 [cs.LG])

    [http://arxiv.org/abs/2308.06717](http://arxiv.org/abs/2308.06717)

    本文研究了一个自私学习代理和学习委托人之间的重复对自选游戏，探索如何估计和激励具有隐藏奖励的不完全知识代理。

    

    在实践中，激励提供者（即委托人）通常无法观察受到激励的代理的奖励实现情况，这与许多先前研究过的委托人-代理模型形成了对比。这种信息不对称性使委托人仅通过观察代理的决策就要始终估计代理的未知奖励变得更加困难，当代理需要学习自己的奖励时，这个挑战变得更加困难。这种复杂情况在各种现实场景中被观察到，从可再生能源储存合同到个性化医疗保健激励。因此，它不仅提供了有趣的理论问题，而且具有广泛的实际相关性。本文探讨了一个自私学习代理和学习委托人之间的重复对自选游戏。代理解决多臂老虎机（MAB）问题，以最大化他们预期的奖励和激励。除代理的学习外，委托人还训练了一个并行算法，并面临一个折中情况

    In practice, incentive providers (i.e., principals) often cannot observe the reward realizations of incentivized agents, which is in contrast to many principal-agent models that have been previously studied. This information asymmetry challenges the principal to consistently estimate the agent's unknown rewards by solely watching the agent's decisions, which becomes even more challenging when the agent has to learn its own rewards. This complex setting is observed in various real-life scenarios ranging from renewable energy storage contracts to personalized healthcare incentives. Hence, it offers not only interesting theoretical questions but also wide practical relevance. This paper explores a repeated adverse selection game between a self-interested learning agent and a learning principal. The agent tackles a multi-armed bandit (MAB) problem to maximize their expected reward plus incentive. On top of the agent's learning, the principal trains a parallel algorithm and faces a trade-of
    
[^3]: 存在分布外节点的图上学习

    Learning on Graphs with Out-of-Distribution Nodes. (arXiv:2308.06714v1 [cs.LG])

    [http://arxiv.org/abs/2308.06714](http://arxiv.org/abs/2308.06714)

    这篇论文提出了一种在图中学习的方法，能够处理存在分布外节点（OOD nodes）的场景。作者定义了分布外节点，并设定了两个任务：检测不属于已知分布的节点，并对剩余节点进行分类。他们通过提出的Out-of-Distribution Graph Attention Network (OODGAT)方法来解决这个问题。

    

    图神经网络（GNNs）是在图上执行预测任务的最先进模型。现有的GNNs在与图相关的各种任务上表现出色，但在训练和推理过程中存在分布外（OOD）节点的情况下，却很少引起注意。借鉴CV和NLP的概念，我们将OOD节点定义为训练集中未见的节点标签。由于许多网络是由程序自动生成的，现实世界的图往往存在噪音，并且可能包含来自未知分布的节点。本文定义了存在分布外节点的图上学习问题。具体而言，我们的目标是完成两个任务：1）检测不属于已知分布的节点；2）将剩余的节点分类为已知类别之一。我们证明图中的连接模式对于异常值检测具有信息性，并提出了Out-of-Distribution Graph Attention Network (OODGAT)。

    Graph Neural Networks (GNNs) are state-of-the-art models for performing prediction tasks on graphs. While existing GNNs have shown great performance on various tasks related to graphs, little attention has been paid to the scenario where out-of-distribution (OOD) nodes exist in the graph during training and inference. Borrowing the concept from CV and NLP, we define OOD nodes as nodes with labels unseen from the training set. Since a lot of networks are automatically constructed by programs, real-world graphs are often noisy and may contain nodes from unknown distributions. In this work, we define the problem of graph learning with out-of-distribution nodes. Specifically, we aim to accomplish two tasks: 1) detect nodes which do not belong to the known distribution and 2) classify the remaining nodes to be one of the known classes. We demonstrate that the connection patterns in graphs are informative for outlier detection, and propose Out-of-Distribution Graph Attention Network (OODGAT)
    
[^4]: 伪装图像合成是提高伪装物体检测的关键

    Camouflaged Image Synthesis Is All You Need to Boost Camouflaged Detection. (arXiv:2308.06701v1 [cs.CV])

    [http://arxiv.org/abs/2308.06701](http://arxiv.org/abs/2308.06701)

    该研究提出了一个用于合成伪装数据以改善对自然场景中伪装物体检测的框架，该方法利用生成模型生成逼真的伪装图像，并在三个数据集上取得了优于目前最先进方法的结果。

    

    融入自然场景的伪装物体给深度学习模型检测和合成带来了重大挑战。伪装物体检测是计算机视觉中一个关键任务，具有广泛的实际应用，然而由于数据有限，该研究课题一直受到限制。我们提出了一个用于合成伪装数据以增强对自然场景中伪装物体检测的框架。我们的方法利用生成模型生成逼真的伪装图像，这些图像可以用来训练现有的物体检测模型。具体而言，我们使用伪装环境生成器，由伪装分布分类器进行监督，合成伪装图像，然后将其输入我们的生成器以扩展数据集。我们的框架在三个数据集（COD10k、CAMO和CHAMELEON）上的效果超过了目前最先进的方法，证明了它在改善伪装物体检测方面的有效性。

    Camouflaged objects that blend into natural scenes pose significant challenges for deep-learning models to detect and synthesize. While camouflaged object detection is a crucial task in computer vision with diverse real-world applications, this research topic has been constrained by limited data availability. We propose a framework for synthesizing camouflage data to enhance the detection of camouflaged objects in natural scenes. Our approach employs a generative model to produce realistic camouflage images, which can be used to train existing object detection models. Specifically, we use a camouflage environment generator supervised by a camouflage distribution classifier to synthesize the camouflage images, which are then fed into our generator to expand the dataset. Our framework outperforms the current state-of-the-art method on three datasets (COD10k, CAMO, and CHAMELEON), demonstrating its effectiveness in improving camouflaged object detection. This approach can serve as a plug-
    
[^5]: MACO: 一种用于模态缺失多模态知识图完成的模态对抗和对比框架

    MACO: A Modality Adversarial and Contrastive Framework for Modality-missing Multi-modal Knowledge Graph Completion. (arXiv:2308.06696v1 [cs.CL])

    [http://arxiv.org/abs/2308.06696](http://arxiv.org/abs/2308.06696)

    提出了一种名为MACO的模态对抗和对比框架，用于解决多模态知识图完成中的模态缺失问题，通过对抗训练生成器和判别器生成缺失模态特征，并使用跨模态对比损失改善生成器性能。

    

    近年来，多模态知识图完成（MMKGC）取得了显著进展。MMKGC通过整合多模态实体信息来增强知识图完成（KGC），从而促进了在大规模知识图中发现未观察到的三元组。然而，现有方法强调设计优雅的KGC模型以促进模态交互，忽略了知识图中缺失模态的真实问题。缺失的模态信息阻碍了模态交互，从而削弱了模型的性能。在本文中，我们提出了一种模态对抗和对比框架（MACO）来解决MMKGC中的模态缺失问题。MACO通过对抗性地训练生成器和判别器来生成可以整合到MMKGC模型中的缺失模态特征。同时，我们设计了一个跨模态对比损失来提高生成器的性能。在公共基准上进行了实验和进一步的探索。

    Recent years have seen significant advancements in multi-modal knowledge graph completion (MMKGC). MMKGC enhances knowledge graph completion (KGC) by integrating multi-modal entity information, thereby facilitating the discovery of unobserved triples in the large-scale knowledge graphs (KGs). Nevertheless, existing methods emphasize the design of elegant KGC models to facilitate modality interaction, neglecting the real-life problem of missing modalities in KGs. The missing modality information impedes modal interaction, consequently undermining the model's performance. In this paper, we propose a modality adversarial and contrastive framework (MACO) to solve the modality-missing problem in MMKGC. MACO trains a generator and discriminator adversarially to generate missing modality features that can be incorporated into the MMKGC model. Meanwhile, we design a cross-modal contrastive loss to improve the performance of the generator. Experiments on public benchmarks with further explorati
    
[^6]: 基于双图和门控融合的聚合特征视频字幕生成

    Video Captioning with Aggregated Features Based on Dual Graphs and Gated Fusion. (arXiv:2308.06685v1 [cs.CV])

    [http://arxiv.org/abs/2308.06685](http://arxiv.org/abs/2308.06685)

    本文提出了一种基于双图和门控融合的视频字幕生成模型，通过适应两种类型的图来生成多样的特征表示，并利用门控融合来更好地理解视频内容。

    

    视频字幕生成模型旨在通过准确的自然语言翻译视频内容。由于视频中对象之间的复杂相互作用，对象的时空关系的全面理解仍然是一个具有挑战性的任务。现有方法往往在生成足够的视频内容特征表示方面存在缺陷。在本文中，我们提出了一种基于双图和门控融合的视频字幕生成模型：我们适应了两种类型的图来生成视频内容的特征表示，并利用门控融合来进一步理解这些不同层次的信息。使用双图模型分别生成外观特征和动作特征可以利用帧间的内容相关性从多个角度生成多样的特征。其中，双图推理可以增强帧序列中的内容相关性，生成高级语义特征；另一方面，门控融合可以组合不同层次的特征，以更好地表示视频内容。

    The application of video captioning models aims at translating the content of videos by using accurate natural language. Due to the complex nature inbetween object interaction in the video, the comprehensive understanding of spatio-temporal relations of objects remains a challenging task. Existing methods often fail in generating sufficient feature representations of video content. In this paper, we propose a video captioning model based on dual graphs and gated fusion: we adapt two types of graphs to generate feature representations of video content and utilize gated fusion to further understand these different levels of information. Using a dual-graphs model to generate appearance features and motion features respectively can utilize the content correlation in frames to generate various features from multiple perspectives. Among them, dual-graphs reasoning can enhance the content correlation in frame sequences to generate advanced semantic features; The gated fusion, on the other han
    
[^7]: 动态梯度下降法的平衡法则与稳态分布

    Law of Balance and Stationary Distribution of Stochastic Gradient Descent. (arXiv:2308.06671v1 [cs.LG])

    [http://arxiv.org/abs/2308.06671](http://arxiv.org/abs/2308.06671)

    本文证明了随机梯度下降算法中的小批量噪音会使解决方案向平衡解靠近，只要损失函数包含重新缩放对称性。利用这个结果，我们导出了对角线性网络的随机梯度流稳态分布，该分布展示了复杂的非线性现象。这些发现揭示了动态梯度下降法在训练神经网络中的工作原理。

    

    随机梯度下降（SGD）算法是我们用于训练神经网络的算法。然而，我们很难理解SGD如何在神经网络的非线性和退化的损失曲面中进行导航。在这项工作中，我们证明了SGD的小批量噪音可以使解决方案向平衡解靠近，只要损失函数包含一个重新缩放对称性。由于简单扩散过程和SGD动力学的差异在对称性存在时最重要，我们的理论表明，损失函数的对称性是了解SGD工作方式的重要线索。然后，我们将这个结果应用于导出具有任意深度和宽度的对角线性网络的随机梯度流的稳态分布。稳态分布展现了复杂的非线性现象，如相变、破坏的遍历性和波动反转。这些现象仅在深层网络中存在，表明了一种基本的新的加深训练理论。

    The stochastic gradient descent (SGD) algorithm is the algorithm we use to train neural networks. However, it remains poorly understood how the SGD navigates the highly nonlinear and degenerate loss landscape of a neural network. In this work, we prove that the minibatch noise of SGD regularizes the solution towards a balanced solution whenever the loss function contains a rescaling symmetry. Because the difference between a simple diffusion process and SGD dynamics is the most significant when symmetries are present, our theory implies that the loss function symmetries constitute an essential probe of how SGD works. We then apply this result to derive the stationary distribution of stochastic gradient flow for a diagonal linear network with arbitrary depth and width. The stationary distribution exhibits complicated nonlinear phenomena such as phase transitions, broken ergodicity, and fluctuation inversion. These phenomena are shown to exist uniquely in deep networks, implying a fundam
    
[^8]: 无监督自适应息肉分割模型通过由粗到细的自监督学习方法

    Unsupervised Adaptation of Polyp Segmentation Models via Coarse-to-Fine Self-Supervision. (arXiv:2308.06665v1 [cs.CV])

    [http://arxiv.org/abs/2308.06665](http://arxiv.org/abs/2308.06665)

    本研究提出了一种新的方法来解决无监督自适应问题，称为区域到像素自适应网络（RPANet）。通过由粗到细的自监督学习方法，RPANet能够学习目标域的区域级别和像素级别的判别表示。这种方法解决了目标域内在结构被忽视的问题，并解决了伪标签自训练中的误差累积问题。

    

    无监督域自适应（UDA）近十年来备受关注，但在实际应用中很难使用。考虑到隐私保护问题和安全问题，本文研究了无源域自适应（SFDA）的实际问题，即消除了对标注源数据的依赖。当前的SFDA方法侧重于从源培训模型中提取领域知识，但忽视了目标域的内在结构。此外，它们通常利用伪标签进行目标域的自训练，但受到臭名昭著的误差累积问题的困扰。为了解决这些问题，我们提出了一种新的SFDA框架，称为区域到像素自适应网络（RPANet），通过由粗到细的自监督学习方法学习区域级别和像素级别的判别表示。所提出的RPANet包括两个模块，即前景感知的对比学习（FCL）和置信度校准的伪标签训练（CCPLT）。

    Unsupervised Domain Adaptation~(UDA) has attracted a surge of interest over the past decade but is difficult to be used in real-world applications. Considering the privacy-preservation issues and security concerns, in this work, we study a practical problem of Source-Free Domain Adaptation (SFDA), which eliminates the reliance on annotated source data. Current SFDA methods focus on extracting domain knowledge from the source-trained model but neglects the intrinsic structure of the target domain. Moreover, they typically utilize pseudo labels for self-training in the target domain, but suffer from the notorious error accumulation problem. To address these issues, we propose a new SFDA framework, called Region-to-Pixel Adaptation Network~(RPANet), which learns the region-level and pixel-level discriminative representations through coarse-to-fine self-supervision. The proposed RPANet consists of two modules, Foreground-aware Contrastive Learning (FCL) and Confidence-Calibrated Pseudo-Lab
    
[^9]: ALGAN：具有调整的LSTM GAN的时间序列异常检测

    ALGAN: Time Series Anomaly Detection with Adjusted-LSTM GAN. (arXiv:2308.06663v1 [cs.LG])

    [http://arxiv.org/abs/2308.06663](http://arxiv.org/abs/2308.06663)

    该论文提出了一种名为ALGAN的新型GAN模型，通过调整LSTM网络的输出，实现了在无监督设置下对单变量和多变量时间序列数据进行异常检测，并在实验中优于传统方法和其他GAN方法。

    

    时间序列数据中的异常检测是各个领域（如制造业，医学成像和网络安全）中常见的问题，旨在识别偏离正常行为的点。最近，生成对抗网络（GANs）在检测时间序列数据中的异常方面显示出了有效性。GANs的神经网络结构（即生成器和鉴别器）可以显着提高异常检测准确性。本文提出了一种新的GAN模型，名为Adjusted-LSTM GAN（ALGAN），它调整LSTM网络的输出，以提高单变量和多变量时间序列数据的异常检测能力，而且是在无监督设置下进行的。我们在46个真实世界的单变量时间序列数据集和涵盖多个领域的大型多变量数据集上评估了ALGAN的性能。我们的实验表明，ALGAN在时间序列数据的异常检测中优于传统的、基于神经网络的和其他基于GAN的方法。

    Anomaly detection in time series data, to identify points that deviate from normal behaviour, is a common problem in various domains such as manufacturing, medical imaging, and cybersecurity. Recently, Generative Adversarial Networks (GANs) are shown to be effective in detecting anomalies in time series data. The neural network architecture of GANs (i.e. Generator and Discriminator) can significantly improve anomaly detection accuracy. In this paper, we propose a new GAN model, named Adjusted-LSTM GAN (ALGAN), which adjusts the output of an LSTM network for improved anomaly detection in both univariate and multivariate time series data in an unsupervised setting. We evaluate the performance of ALGAN on 46 real-world univariate time series datasets and a large multivariate dataset that spans multiple domains. Our experiments demonstrate that ALGAN outperforms traditional, neural network-based, and other GAN-based methods for anomaly detection in time series data.
    
[^10]: 使用类似谷歌搜索的智能知识传输的研究

    Smart Knowledge Transfer using Google-like Search. (arXiv:2308.06653v1 [cs.SE])

    [http://arxiv.org/abs/2308.06653](http://arxiv.org/abs/2308.06653)

    研究提出了SMARTKT，通过一个类似谷歌搜索的框架，将程序理解过程转化为语义图查询，从而解决了软件维护成本上升的挑战。

    

    为了解决程序理解挑战导致的软件维护成本上升的问题，我们提出了智能知识传输（SMARTKT），一个搜索框架，该框架以语义图的形式提取并整合与应用程序各个方面相关的知识。这个图支持语法和语义查询，并将程序理解的过程转化为类似于谷歌搜索的问题。

    To address the issue of rising software maintenance cost due to program comprehension challenges, we propose SMARTKT (Smart Knowledge Transfer), a search framework, which extracts and integrates knowledge related to various aspects of an application in form of a semantic graph. This graph supports syntax and semantic queries and converts the process of program comprehension into a {\em google-like} search problem.
    
[^11]: 通过逐步蒸馏加速基于扩散的组合优化求解器

    Accelerating Diffusion-based Combinatorial Optimization Solvers by Progressive Distillation. (arXiv:2308.06644v1 [cs.LG])

    [http://arxiv.org/abs/2308.06644](http://arxiv.org/abs/2308.06644)

    本文提出使用逐步蒸馏来加速基于扩散的组合优化求解器，并在TSP-50数据集上展示了16倍的推理速度提升，仅有0.019%的性能降级。

    

    基于图扩散模型在生成高质量解决方案的NP完全组合优化问题方面表现出了良好的结果。然而，由于去噪扩散过程的迭代评估特性，这些模型在推理上常常效率低下。本文提出使用逐步蒸馏来加速推理过程，仅在单步内预测两个步骤之前的情况。我们的实验结果表明，经过逐步蒸馏的模型可以在TSP-50数据集上进行推理，速度快了16倍，性能仅有0.019%的降级。

    Graph-based diffusion models have shown promising results in terms of generating high-quality solutions to NP-complete (NPC) combinatorial optimization (CO) problems. However, those models are often inefficient in inference, due to the iterative evaluation nature of the denoising diffusion process. This paper proposes to use progressive distillation to speed up the inference by taking fewer steps (e.g., forecasting two steps ahead within a single step) during the denoising process. Our experimental results show that the progressively distilled model can perform inference 16 times faster with only 0.019% degradation in performance on the TSP-50 dataset.
    
[^12]: 能否通过非结构化剪枝来减少深度神经网络的层数？

    Can Unstructured Pruning Reduce the Depth in Deep Neural Networks?. (arXiv:2308.06619v1 [cs.LG])

    [http://arxiv.org/abs/2308.06619](http://arxiv.org/abs/2308.06619)

    本研究介绍了一种名为EGP的创新的熵引导剪枝算法，该算法能够通过优先剪除熵较低的层中的连接来有效压缩深度神经网络，同时保持其竞争性能水平。

    

    剪枝是一种广泛使用的技术，可以减小深度神经网络的大小，同时保持其性能。然而，即使是在有结构的情况下，这种技术也很难从模型中完全去除整个层：这是一个可以解决的任务吗？在这项研究中，我们引入了一种名为EGP的创新的熵引导剪枝算法，旨在减小深度神经网络的大小，同时保持其性能。EGP的关键重点是优先剪除熵较低的层中的连接，最终完全去除这些层。通过在ResNet-18和Swin-T等流行模型上进行大量实验，我们的研究结果表明，EGP能够有效压缩深度神经网络，同时保持竞争性能水平。我们的结果不仅揭示了非结构化剪枝优势背后的机制，还为进一步研究复杂的关系铺平了道路。

    Pruning is a widely used technique for reducing the size of deep neural networks while maintaining their performance. However, such a technique, despite being able to massively compress deep models, is hardly able to remove entire layers from a model (even when structured): is this an addressable task? In this study, we introduce EGP, an innovative Entropy Guided Pruning algorithm aimed at reducing the size of deep neural networks while preserving their performance. The key focus of EGP is to prioritize pruning connections in layers with low entropy, ultimately leading to their complete removal. Through extensive experiments conducted on popular models like ResNet-18 and Swin-T, our findings demonstrate that EGP effectively compresses deep neural networks while maintaining competitive performance levels. Our results not only shed light on the underlying mechanism behind the advantages of unstructured pruning, but also pave the way for further investigations into the intricate relations
    
[^13]: 关于卷积填充与对抗鲁棒性之间的相互作用

    On the Interplay of Convolutional Padding and Adversarial Robustness. (arXiv:2308.06612v1 [cs.CV])

    [http://arxiv.org/abs/2308.06612](http://arxiv.org/abs/2308.06612)

    本研究分析了卷积填充和对抗攻击之间的相互作用，探讨了不同填充模式对对抗鲁棒性的影响。

    

    在卷积神经网络（CNN）中，常常在卷积操作之前进行填充操作，以保留特征图的分辨率。虽然有很多替代方法，但通常是通过在输入周围添加一圈零进行填充。在这项工作中，我们展示了对抗攻击通常会在图像边界出现扰动异常，而这些边界正是填充所用的区域。因此，我们旨在对填充和对抗攻击之间的相互作用进行分析，并寻找不同填充模式（或缺乏填充）对不同场景下的对抗鲁棒性产生的影响。

    It is common practice to apply padding prior to convolution operations to preserve the resolution of feature-maps in Convolutional Neural Networks (CNN). While many alternatives exist, this is often achieved by adding a border of zeros around the inputs. In this work, we show that adversarial attacks often result in perturbation anomalies at the image boundaries, which are the areas where padding is used. Consequently, we aim to provide an analysis of the interplay between padding and adversarial attacks and seek an answer to the question of how different padding modes (or their absence) affect adversarial robustness in various scenarios.
    
[^14]: Bio-SIEVE：探索针对系统性评述自动化的大型语言模型的指令调优

    Bio-SIEVE: Exploring Instruction Tuning Large Language Models for Systematic Review Automation. (arXiv:2308.06610v1 [cs.CL])

    [http://arxiv.org/abs/2308.06610](http://arxiv.org/abs/2308.06610)

    本研究通过探索大型语言模型在医学系统性评述中的应用，尤其是通过指令调优来提高摘要筛选的性能，提出了一种名称为Bio-SIEVE的模型，该模型在医学领域中表现出优异的泛化能力和性能，但在安全性优先场景下仍存在挑战。同时，我们也尝试了多任务训练，但发现其不能与单任务的Bio-SIEVE性能相匹配。这一研究是为了将语言模型专门用于生物医学系统性评述过程迈出的重要一步。我们提供了模型、代码和DOI列表以供复现。

    

    医学系统性评述成本高、资源密集。我们探索了如何使用大型语言模型（LLMs）在提供详细的选择标准的情况下支持和训练其执行文献筛选。具体而言，我们对LLaMA和Guanaco模型进行了指令调优，以执行医学系统性评述的摘要筛选。我们的最佳模型Bio-SIEVE在性能上超过了ChatGPT和经过训练的传统方法，并在医学领域中具有更好的泛化能力。然而，将模型调整为以安全为先的场景仍然具有挑战。我们还探索了与Bio-SIEVE-Multi的多任务训练的影响，包括PICO提取和排除推理等任务，但发现它无法达到单任务Bio-SIEVE的性能。我们认为Bio-SIEVE是为生物医学系统性评述过程专门化的语言模型的重要一步，同时还探索了其未来的发展机会。我们发布了我们的模型、代码和一份DOI列表以供重现。

    Medical systematic reviews can be very costly and resource intensive. We explore how Large Language Models (LLMs) can support and be trained to perform literature screening when provided with a detailed set of selection criteria. Specifically, we instruction tune LLaMA and Guanaco models to perform abstract screening for medical systematic reviews. Our best model, Bio-SIEVE, outperforms both ChatGPT and trained traditional approaches, and generalises better across medical domains. However, there remains the challenge of adapting the model to safety-first scenarios. We also explore the impact of multi-task training with Bio-SIEVE-Multi, including tasks such as PICO extraction and exclusion reasoning, but find that it is unable to match single-task Bio-SIEVE's performance. We see Bio-SIEVE as an important step towards specialising LLMs for the biomedical systematic review process and explore its future developmental opportunities. We release our models, code and a list of DOIs to reconst
    
[^15]: VisIT-Bench: 一个受真实世界使用启发的视觉语言指示评估基准

    VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use. (arXiv:2308.06595v1 [cs.CL])

    [http://arxiv.org/abs/2308.06595](http://arxiv.org/abs/2308.06595)

    VisIT-Bench是一个用于评价真实世界中视觉语言模型指示遵循的基准，包含了各种任务并提供了详细描述，可以自动评估多模态生成的质量差距。

    

    我们引入了VisIT-Bench（Visual InsTruction Benchmark），这是一个评价用于真实世界使用的视觉语言模型的指示遵循基准。我们的起点是策划了70个“指示家族”，我们认为指示调优的视觉语言模型应该能够解决这些家族。任务不仅限于VQAv2和COCO等评估，涵盖了从基本识别到游戏玩法和创造性生成的各种任务。在策划之后，我们的数据集包括592个测试查询，每个查询都带有一个人工编写的指示条件化的字幕。这些描述展现了特定指示因素，例如对于询问店面对于轮椅用户的易访问性的指示，条件化的字幕描述了斜坡/潜在障碍物。这些描述使得我们可以：1）收集每个实例的人工验证的参考输出；2）使用仅文本的语言模型对候选多模态生成进行自动评估，与人类判断相一致。我们量化了质量差距。

    We introduce VisIT-Bench (Visual InsTruction Benchmark), a benchmark for evaluation of instruction-following vision-language models for real-world use. Our starting point is curating 70 'instruction families' that we envision instruction tuned vision-language models should be able to address. Extending beyond evaluations like VQAv2 and COCO, tasks range from basic recognition to game playing and creative generation. Following curation, our dataset comprises 592 test queries, each with a human-authored instruction-conditioned caption. These descriptions surface instruction-specific factors, e.g., for an instruction asking about the accessibility of a storefront for wheelchair users, the instruction-conditioned caption describes ramps/potential obstacles. These descriptions enable 1) collecting human-verified reference outputs for each instance; and 2) automatic evaluation of candidate multimodal generations using a text-only LLM, aligning with human judgment. We quantify quality gaps be
    
[^16]: 基于价值分布模型的强化学习

    Value-Distributional Model-Based Reinforcement Learning. (arXiv:2308.06590v1 [cs.LG])

    [http://arxiv.org/abs/2308.06590](http://arxiv.org/abs/2308.06590)

    该论文介绍了一种基于价值分布模型的强化学习方法，该方法通过学习后验分布来解决决策任务中的政策不确定性问题。所提出的算法能够有效地优化策略，在连续控制任务中表现出性能优势。

    

    在解决顺序决策任务中，量化政策长期绩效的不确定性是很重要的。我们从基于模型的贝叶斯强化学习的角度研究这个问题，目标是学习由马尔科夫决策过程的参数（认知）不确定性引发的值函数的后验分布。以往的研究将分析限制在少数分布值上，或者约束分布形状，例如，高斯分布。受到分布式强化学习的启发，我们引入一个Bellman算子，其固定点是值分布函数。基于我们的理论，我们提出了Epistemic Quantile-Regression（EQR），这是一种基于模型的算法，可以学习一个值分布函数用于策略优化。在几个连续控制任务上的评估结果显示相对于已有的基于模型和基于模型的算法，EQR具有性能优势。

    Quantifying uncertainty about a policy's long-term performance is important to solve sequential decision-making tasks. We study the problem from a model-based Bayesian reinforcement learning perspective, where the goal is to learn the posterior distribution over value functions induced by parameter (epistemic) uncertainty of the Markov decision process. Previous work restricts the analysis to a few moments of the distribution over values or imposes a particular distribution shape, e.g., Gaussians. Inspired by distributional reinforcement learning, we introduce a Bellman operator whose fixed-point is the value distribution function. Based on our theory, we propose Epistemic Quantile-Regression (EQR), a model-based algorithm that learns a value distribution function that can be used for policy optimization. Evaluation across several continuous-control tasks shows performance benefits with respect to established model-based and model-free algorithms.
    
[^17]: 图查询的近似答案

    Approximate Answering of Graph Queries. (arXiv:2308.06585v1 [cs.LG])

    [http://arxiv.org/abs/2308.06585](http://arxiv.org/abs/2308.06585)

    本章概述了几种方法，用于在知识图谱不完整的情况下回答查询。这些方法涵盖了不同的查询类型和图类型，并具有不同的推理能力。

    

    知识图谱（KG）由于世界知识的不完整和输入KG的偏见而本质上是不完整的。此外，世界知识不断扩展和发展，使现有事实过时或引入新的事实。然而，我们仍然希望能够像图谱完整一样回答查询。在本章中，我们将概述几种已经提出的方法，以在这种情况下回答查询。首先，我们将概述这些方法支持的不同查询类型和通常用于评估的数据集，以及对它们的限制的了解。然后，我们将概述不同的方法，并以表达能力、支持的图类型和推理能力来描述它们。

    Knowledge graphs (KGs) are inherently incomplete because of incomplete world knowledge and bias in what is the input to the KG. Additionally, world knowledge constantly expands and evolves, making existing facts deprecated or introducing new ones. However, we would still want to be able to answer queries as if the graph were complete. In this chapter, we will give an overview of several methods which have been proposed to answer queries in such a setting. We will first provide an overview of the different query types which can be supported by these methods and datasets typically used for evaluation, as well as an insight into their limitations. Then, we give an overview of the different approaches and describe them in terms of expressiveness, supported graph types, and inference capabilities.
    
[^18]: 4DRVO-Net: 使用多模态和多尺度自适应融合的深度4D雷达-视觉里程计

    4DRVO-Net: Deep 4D Radar-Visual Odometry Using Multi-Modal and Multi-Scale Adaptive Fusion. (arXiv:2308.06573v1 [cs.CV])

    [http://arxiv.org/abs/2308.06573](http://arxiv.org/abs/2308.06573)

    4DRVO-Net是一种深度4D雷达-视觉里程计的方法，它通过整合4D雷达和相机的信息，并利用多尺度特征提取网络和成本体积网络逐步估计和改进姿态。

    

    4DRVO-Net是一种用于4D雷达-视觉里程计的方法，它通过整合4D雷达和相机的互补信息，实现了准确和稳健的姿态估计。本文提出了一种名为Radar-PointNet++的多尺度特征提取网络，它充分考虑了丰富的4D雷达点信息，从而实现了对稀疏4D雷达点云的精细学习。同时，该方法还利用特征金字塔、姿态变形和成本体积网络体系结构逐步估计和改进姿态。

    Four-dimensional (4D) radar--visual odometry (4DRVO) integrates complementary information from 4D radar and cameras, making it an attractive solution for achieving accurate and robust pose estimation. However, 4DRVO may exhibit significant tracking errors owing to three main factors: 1) sparsity of 4D radar point clouds; 2) inaccurate data association and insufficient feature interaction between the 4D radar and camera; and 3) disturbances caused by dynamic objects in the environment, affecting odometry estimation. In this paper, we present 4DRVO-Net, which is a method for 4D radar--visual odometry. This method leverages the feature pyramid, pose warping, and cost volume (PWC) network architecture to progressively estimate and refine poses. Specifically, we propose a multi-scale feature extraction network called Radar-PointNet++ that fully considers rich 4D radar point information, enabling fine-grained learning for sparse 4D radar point clouds. To effectively integrate the two modalit
    
[^19]: ModelScope文本到视频技术报告

    ModelScope Text-to-Video Technical Report. (arXiv:2308.06571v1 [cs.CV])

    [http://arxiv.org/abs/2308.06571](http://arxiv.org/abs/2308.06571)

    本论文介绍了ModelScopeT2V，一种从文本到视频合成的模型。该模型采用时空块确保帧生成和运动过渡的一致性，并能适应不同的帧数量。ModelScopeT2V在三个评估指标上表现出优越性能，代码和在线演示可在指定链接获取。

    

    本论文介绍了ModelScopeT2V，一种从文本到图像合成模型（即Stable Diffusion）演变而来的文本到视频合成模型。ModelScopeT2V采用时空块来确保一致的帧生成和平滑的运动过渡。该模型在训练和推断过程中能够适应不同的帧数量，适用于图像-文本和视频-文本数据集。ModelScopeT2V结合了三个组件（即VQGAN，文本编码器和去噪UNet），总共包含17亿个参数，其中5亿个参数用于时间能力。该模型在三个评估指标上表现出优越的性能，超过了现有方法。代码和在线演示可在\url{https://modelscope.cn/models/damo/text-to-video-synthesis/summary}获取。

    This paper introduces ModelScopeT2V, a text-to-video synthesis model that evolves from a text-to-image synthesis model (i.e., Stable Diffusion). ModelScopeT2V incorporates spatio-temporal blocks to ensure consistent frame generation and smooth movement transitions. The model could adapt to varying frame numbers during training and inference, rendering it suitable for both image-text and video-text datasets. ModelScopeT2V brings together three components (i.e., VQGAN, a text encoder, and a denoising UNet), totally comprising 1.7 billion parameters, in which 0.5 billion parameters are dedicated to temporal capabilities. The model demonstrates superior performance over state-of-the-art methods across three evaluation metrics. The code and an online demo are available at \url{https://modelscope.cn/models/damo/text-to-video-synthesis/summary}.
    
[^20]: MC-DRE: 多方面交叉整合用于药物事件/实体提取

    MC-DRE: Multi-Aspect Cross Integration for Drug Event/Entity Extraction. (arXiv:2308.06546v1 [cs.CL])

    [http://arxiv.org/abs/2308.06546](http://arxiv.org/abs/2308.06546)

    本文提出了一个新的多方面交叉整合框架，用于从药物相关文档中提取药物事件/实体。该框架能够捕捉并对齐不同的上下文/语言/知识属性，并实现药物事件信息的全面检测和理解。

    

    提取有意义的药物相关信息块，如不良药物事件（ADE），对于预防疾病和拯救许多生命至关重要。大多数ADE是通过医疗背景下的非结构化对话报告的。因此，应用通用实体识别方法是不足够的。关键在于如何整合和对齐多个关键方面来检测药物事件信息，包括药物事件语义、句法结构和医学领域术语。在本文中，我们提出了一个新的多方面交叉整合框架，通过从药物相关文档中捕捉和对齐不同的上下文/语言/知识属性，用于药物实体/事件检测。我们首先构建多方面编码器来描述语义、句法和医学文档上下文信息，方法包括槽标注任务、主要药物实体/事件检测、词性标注和通用医学命名实体识别。然后，每个编码器进行交叉整合。

    Extracting meaningful drug-related information chunks, such as adverse drug events (ADE), is crucial for preventing morbidity and saving many lives. Most ADE are reported via an unstructured conversation with the medical context. Hence, applying a general entity recognition approach is not sufficient enough. The key is how to integrate and align multiple crucial aspects to detect drug event information, including drug event semantics, syntactic structures, and medical domain terminology. In this paper, we propose a new multi-aspect cross-integration framework for drug entity/event detection by capturing and aligning different context/language/knowledge properties from drug-related documents. We first construct multi-aspect encoders to describe semantic, syntactic, and medical document contextual information by conducting those slot tagging tasks, main drug entity/event detection, part-of-speech tagging, and general medical named entity recognition. Then, each encoder conducts cross int
    
[^21]: 在城市区域中使用极限梯度提升、土地覆盖和地形参数进行数字高程模型校正

    Digital elevation model correction in urban areas using extreme gradient boosting, land cover and terrain parameters. (arXiv:2308.06545v1 [cs.LG])

    [http://arxiv.org/abs/2308.06545](http://arxiv.org/abs/2308.06545)

    本研究采用了极限梯度提升算法来提高城市区域中数字高程模型的精度，并结合土地覆盖和地形参数校正，以解决DEM在城市环境建模中的质量和适用性问题。

    

    在城市区域中，数字高程模型（DEMs）的精度受到土地覆盖和地形不规则性等多种因素的影响。此外，全局DEM中的建筑物人工阻塞了地表水流路径，降低了DEM的质量和适用性，而在精确和准确的地形信息在城市景观中需要进行水文和环境建模。本研究采用了极限梯度提升（XGBoost）集成算法来提高两个中分辨率30米DEM（Copernicus GLO-30和ALOS World 3D）在南非开普敦的精度。XGBoost是一个可扩展、可移植和多功能的梯度提升库，可以解决许多环境建模问题。训练数据集包括十一个预测变量，包括高程、城市轮廓、坡度、坡向、表面粗糙度、地形位置指数、地形崎岖指数、地表纹理、矢量粗糙度测量等。

    The accuracy of digital elevation models (DEMs) in urban areas is influenced by numerous factors including land cover and terrain irregularities. Moreover, building artifacts in global DEMs cause artificial blocking of surface flow pathways. This compromises their quality and adequacy for hydrological and environmental modelling in urban landscapes where precise and accurate terrain information is needed. In this study, the extreme gradient boosting (XGBoost) ensemble algorithm is adopted for enhancing the accuracy of two medium-resolution 30m DEMs over Cape Town, South Africa: Copernicus GLO-30 and ALOS World 3D (AW3D). XGBoost is a scalable, portable and versatile gradient boosting library that can solve many environmental modelling problems. The training datasets are comprised of eleven predictor variables including elevation, urban footprints, slope, aspect, surface roughness, topographic position index, terrain ruggedness index, terrain surface texture, vector roughness measure, f
    
[^22]: 解决医学影像深度学习中的小型注释数据集问题：对比共同对比学习和掩码自编码器方法在CT扫描卷积模型中的自监督预训练的评估

    Dealing with Small Annotated Datasets for Deep Learning in Medical Imaging: An Evaluation of Self-Supervised Pre-Training on CT Scans Comparing Contrastive and Masked Autoencoder Methods for Convolutional Models. (arXiv:2308.06534v1 [cs.CV])

    [http://arxiv.org/abs/2308.06534](http://arxiv.org/abs/2308.06534)

    本研究评估了在医学影像领域使用自监督预训练方法的可行性，比较了共同对比学习和掩码自编码器方法在CT扫描卷积模型中的性能。

    

    医学影像中的深度学习有潜力减少诊断错误的风险、减轻放射科医生的工作负担并加速确诊。训练这样的深度学习模型需要大型且准确的数据集，并且需要为所有训练样本提供注释。然而，在医学影像领域，由于注释的高复杂性、受限的获取方式或疾病的罕见性，特定任务的注释数据集通常很小。为了应对这一挑战，深度学习模型可以使用自监督学习领域的方法，在没有注释的大型图像数据集上进行预训练。在预训练之后，小型的已注释数据集就足以对模型进行特定任务的微调，即所谓的“下游任务”。医学影像中最流行的自监督预训练方法基于共同对比学习。然而，最近的自然图像处理研究表明掩码自编码器方法具有很大的潜力。本研究比较了二者在CT扫描卷积模型中的性能。

    Deep learning in medical imaging has the potential to minimize the risk of diagnostic errors, reduce radiologist workload, and accelerate diagnosis. Training such deep learning models requires large and accurate datasets, with annotations for all training samples. However, in the medical imaging domain, annotated datasets for specific tasks are often small due to the high complexity of annotations, limited access, or the rarity of diseases. To address this challenge, deep learning models can be pre-trained on large image datasets without annotations using methods from the field of self-supervised learning. After pre-training, small annotated datasets are sufficient to fine-tune the models for a specific task, the so-called ``downstream task". The most popular self-supervised pre-training approaches in medical imaging are based on contrastive learning. However, recent studies in natural image processing indicate a strong potential for masked autoencoder approaches. Our work compares sta
    
[^23]: 通过任务分解学习抽象视觉推理：基于Raven渐进矩阵的案例研究

    Learning Abstract Visual Reasoning via Task Decomposition: A Case Study in Raven Progressive Matrices. (arXiv:2308.06528v1 [cs.AI])

    [http://arxiv.org/abs/2308.06528](http://arxiv.org/abs/2308.06528)

    通过任务分解学习抽象视觉推理，提出了一种基于变形器蓝图的深度学习架构，该架构预测单个对象及其排列的视觉特性，通过多维预测来选择答案。

    

    学习进行抽象推理的挑战之一是问题通常被提出为整体任务，没有中间目标。在Raven渐进矩阵（RPM）中，任务是在给定上下文的情况下选择一个可用答案，其中上下文和答案都是复合图像，具有多个对象以及各种空间安排。由于只有这个高级目标作为指导，学习变得具有挑战性，大多数现代解决方案往往不透明。在本研究中，我们提出了一种基于变形器蓝图的深度学习架构，该架构不直接进行上述选择，而是预测单个对象及其排列的视觉特性。通过这种方式获得的多维预测直接并置以选择答案。我们考虑了模型将视觉输入解析为令牌的几种方式，并采用了几种自监督训练中输入的屏蔽方法。

    One of the challenges in learning to perform abstract reasoning is that problems are often posed as monolithic tasks, with no intermediate subgoals. In Raven Progressive Matrices (RPM), the task is to choose one of the available answers given a context, where both contexts and answers are composite images featuring multiple objects in various spatial arrangements. As this high-level goal is the only guidance available, learning is challenging and most contemporary solvers tend to be opaque. In this study, we propose a deep learning architecture based on the transformer blueprint which, rather than directly making the above choice, predicts the visual properties of individual objects and their arrangements. The multidimensional predictions obtained in this way are then directly juxtaposed to choose the answer. We consider a few ways in which the model parses the visual input into tokens and several regimes of masking parts of the input in self-supervised training. In experimental assess
    
[^24]: SLoRA: 联邦参数高效微调语言模型

    SLoRA: Federated Parameter Efficient Fine-Tuning of Language Models. (arXiv:2308.06522v1 [cs.LG])

    [http://arxiv.org/abs/2308.06522](http://arxiv.org/abs/2308.06522)

    SLoRA是一种联邦参数高效微调语言模型的方法，用于在联邦学习中利用分布式和私有数据进行微调，以克服高异构数据下的性能差距。

    

    通过微调预训练的转换器模型进行迁移学习，在各种自然语言处理任务中取得了显著的成功。在没有集中式数据的情况下，联邦学习可以从联邦学习边缘客户端的分布式和私有数据中受益。然而，由于边缘设备的有限通信、计算和存储能力以及流行的转换器模型的巨大大小，高效的微调对于使联邦训练成为可行的是至关重要的。本文探讨了在不同的联邦学习设置下应用参数高效微调方法（PEFT）在语言任务中的机遇和挑战。具体而言，我们的研究发现，随着用户之间的数据越来越多样化，全面微调模型和使用PEFT方法之间的差距变大。为了弥补这个性能差距，我们提出了一种称为SLoRA的方法，它克服了高异构数据下LoRA的关键限制。

    Transfer learning via fine-tuning pre-trained transformer models has gained significant success in delivering state-of-the-art results across various NLP tasks. In the absence of centralized data, Federated Learning (FL) can benefit from distributed and private data of the FL edge clients for fine-tuning. However, due to the limited communication, computation, and storage capabilities of edge devices and the huge sizes of popular transformer models, efficient fine-tuning is crucial to make federated training feasible. This work explores the opportunities and challenges associated with applying parameter efficient fine-tuning (PEFT) methods in different FL settings for language tasks. Specifically, our investigation reveals that as the data across users becomes more diverse, the gap between fully fine-tuning the model and employing PEFT methods widens. To bridge this performance gap, we propose a method called SLoRA, which overcomes the key limitations of LoRA in high heterogeneous data
    
[^25]: HyperFormer: 增强超关系知识图谱补全中的实体和关系交互

    HyperFormer: Enhancing Entity and Relation Interaction for Hyper-Relational Knowledge Graph Completion. (arXiv:2308.06512v1 [cs.AI])

    [http://arxiv.org/abs/2308.06512](http://arxiv.org/abs/2308.06512)

    HyperFormer是一个考虑局部级顺序信息的模型，用于解决超关系知识图谱补全中多跳信息引入噪音的问题。

    

    超关系知识图谱（HKGs）通过将属性-值修饰符与三元组相关联来扩展标准知识图谱，这有效地表示了与其关联三元组的额外细粒度信息。超关系知识图谱补全（HKGC）旨在在考虑其修饰符的情况下推断未知三元组。大多数现有的HKGC方法利用全局级图结构将超关系知识编码为图卷积消息传递过程。然而，多跳信息的添加可能会在三元组预测过程中引入噪音。为了解决这个问题，我们提出了HyperFormer，这是一个考虑局部级顺序信息的模型，它编码了三元组的实体、关系和修饰符的内容。更具体地说，HyperFormer由三个不同的模块组成：一个实体邻居聚合器模块，用于整合实体邻居的信息，以捕捉不同的视角。

    Hyper-relational knowledge graphs (HKGs) extend standard knowledge graphs by associating attribute-value qualifiers to triples, which effectively represent additional fine-grained information about its associated triple. Hyper-relational knowledge graph completion (HKGC) aims at inferring unknown triples while considering its qualifiers. Most existing approaches to HKGC exploit a global-level graph structure to encode hyper-relational knowledge into the graph convolution message passing process. However, the addition of multi-hop information might bring noise into the triple prediction process. To address this problem, we propose HyperFormer, a model that considers local-level sequential information, which encodes the content of the entities, relations and qualifiers of a triple. More precisely, HyperFormer is composed of three different modules: an entity neighbor aggregator module allowing to integrate the information of the neighbors of an entity to capture different perspectives of
    
[^26]: 使用大型语言模型评估聊天的三种方法

    Three Ways of Using Large Language Models to Evaluate Chat. (arXiv:2308.06502v1 [cs.CL])

    [http://arxiv.org/abs/2308.06502](http://arxiv.org/abs/2308.06502)

    本文提出了三种使用大型语言模型（LLMs）评估聊天的方法，并报告了相对于基准线的改进。还分析了另外两种方法的性能，并提出了未来工作的改进方向。

    

    本文描述了团队6提交的ChatEval系统，这是DSTC 11 Track 4竞赛的一部分。我们提出了三种不同的方法来预测基于大型语言模型（LLMs）的聊天机器人回复的转向级别质量。我们通过从向量存储中使用动态的少样本示例作为ChatGPT的提示，报告了相对于基准线的改进。我们还分析了另外两种方法的性能，并报告了未来工作的改进方向。我们仅用两周时间开发了这三个系统，展示了LLMs在此任务中的潜力。在挑战截止日期后进行的消融研究表明，新的Llama 2模型正在缩小ChatGPT和开源LLMs之间的性能差距。然而，我们发现Llama 2模型无法像ChatGPT那样从少样本示例中受益。

    This paper describes the systems submitted by team6 for ChatEval, the DSTC 11 Track 4 competition. We present three different approaches to predicting turn-level qualities of chatbot responses based on large language models (LLMs). We report improvement over the baseline using dynamic few-shot examples from a vector store for the prompts for ChatGPT. We also analyze the performance of the other two approaches and report needed improvements for future work. We developed the three systems over just two weeks, showing the potential of LLMs for this task. An ablation study conducted after the challenge deadline shows that the new Llama 2 models are closing the performance gap between ChatGPT and open-source LLMs. However, we find that the Llama 2 models do not benefit from few-shot examples in the same way as ChatGPT.
    
[^27]: 隐变量发射增强的透视视角（LEAPT）用于人机交互

    Latent Emission-Augmented Perspective-Taking (LEAPT) for Human-Robot Interaction. (arXiv:2308.06498v1 [cs.AI])

    [http://arxiv.org/abs/2308.06498](http://arxiv.org/abs/2308.06498)

    该论文介绍了一个名为LEAPT的方法，通过使用隐变量发射增强的透视视角模型，使机器人能够理解和推断人类观察和信念，该模型通过优化ELBO来学习隐空间中的不确定性。

    

    透视视角是指从他人的角度感知或理解情境或概念的能力，在日常人际互动中至关重要。使机器人能够进行透视视角仍然是一个未解决的问题；现有的使用确定性或手工制定方法的方法无法准确考虑到部分可观察环境中的不确定性。本研究提出通过深度世界模型来解决这个限制，该模型使机器人能够执行感知和概念透视视角，即机器人能够推断人类所见和所信的内容。关键创新是一个分解的多模态隐状态空间模型，能够生成和增强虚拟的观测/发射。通过优化这个概率图模型产生的ELBO，可以学习隐空间中的不确定性，从而便于从高维观测中进行不确定性估计。我们的模型任务是预测人类的观察和信念。

    Perspective-taking is the ability to perceive or understand a situation or concept from another individual's point of view, and is crucial in daily human interactions. Enabling robots to perform perspective-taking remains an unsolved problem; existing approaches that use deterministic or handcrafted methods are unable to accurately account for uncertainty in partially-observable settings. This work proposes to address this limitation via a deep world model that enables a robot to perform both perception and conceptual perspective taking, i.e., the robot is able to infer what a human sees and believes. The key innovation is a decomposed multi-modal latent state space model able to generate and augment fictitious observations/emissions. Optimizing the ELBO that arises from this probabilistic graphical model enables the learning of uncertainty in latent space, which facilitates uncertainty estimation from high-dimensional observations. We tasked our model to predict human observations and
    
[^28]: EgoPoser：大场景下鲁棒的实时自我身体姿势估计

    EgoPoser: Robust Real-Time Ego-Body Pose Estimation in Large Scenes. (arXiv:2308.06493v1 [cs.CV])

    [http://arxiv.org/abs/2308.06493](http://arxiv.org/abs/2308.06493)

    本文提出了EgoPoser，一种能够在大场景中鲁棒地实时估计自我身体姿势的方法。通过重新思考输入表示、引入新的运动分解方法以及建模身体姿势，EgoPoser在定性和定量上均表现优于现有方法，并具有较高的推理速度。

    

    头部和手部姿势仅通过完整身体自我姿势估计已成为研究的一个热点领域，以为头戴式平台上的虚拟角色表达提供动力。然而，现有方法过于依赖数据集记录时的运动捕捉空间的限制，同时假设连续捕捉关节运动和均匀身体尺寸。在本文中，我们提出了EgoPoser，通过以下方式克服了这些限制：1）重新思考基于头戴式平台的自我姿势估计的输入表示，并引入一种新的运动分解方法来预测与全局位置无关的完整身体姿势，2）从头戴式设备视野内的间歇性手部姿势跟踪中鲁棒地建模身体姿势，3）针对不同用户的各种身体尺寸进行通用化推广。我们的实验表明，EgoPoser在定性和定量上优于现有的方法，并保持较高的推理速度。

    Full-body ego-pose estimation from head and hand poses alone has become an active area of research to power articulate avatar representation on headset-based platforms. However, existing methods over-rely on the confines of the motion-capture spaces in which datasets were recorded, while simultaneously assuming continuous capture of joint motions and uniform body dimensions. In this paper, we propose EgoPoser, which overcomes these limitations by 1) rethinking the input representation for headset-based ego-pose estimation and introducing a novel motion decomposition method that predicts full-body pose independent of global positions, 2) robustly modeling body pose from intermittent hand position and orientation tracking only when inside a headset's field of view, and 3) generalizing across various body sizes for different users. Our experiments show that EgoPoser outperforms state-of-the-art methods both qualitatively and quantitatively, while maintaining a high inference speed of over
    
[^29]: 无噪声参考文本的知识图生成忠实文本

    Generating Faithful Text From a Knowledge Graph with Noisy Reference Text. (arXiv:2308.06488v1 [cs.CL])

    [http://arxiv.org/abs/2308.06488](http://arxiv.org/abs/2308.06488)

    本文提出了一种KG到文本生成模型，能够在存在噪声参考文本的情况下，从给定的图生成忠实的自然语言文本

    

    知识图（KG）到文本的生成旨在生成流畅的自然语言文本，准确地表示给定知识图的信息。虽然通过利用预训练语言模型（PLMs）与适当的图结构感知模块在这个任务上取得了显著的进展，但现有模型在生成忠实文本方面仍存在不足，特别是当地面真实语言文本中包含图中不存在的额外信息时。本文提出了一种KG到文本生成模型，能够在存在噪声参考文本的情况下，从给定的图生成忠实的自然语言文本。我们的框架融合了两个核心思想：首先，我们利用对比学习增强模型区分文本中的忠实和虚构信息的能力，从而鼓励解码器生成与输入图对齐的文本。其次，我们赋予解码器控制文本生成过程的能力，

    Knowledge Graph (KG)-to-Text generation aims at generating fluent natural-language text that accurately represents the information of a given knowledge graph. While significant progress has been made in this task by exploiting the power of pre-trained language models (PLMs) with appropriate graph structure-aware modules, existing models still fall short of generating faithful text, especially when the ground-truth natural-language text contains additional information that is not present in the graph. In this paper, we develop a KG-to-text generation model that can generate faithful natural-language text from a given graph, in the presence of noisy reference text. Our framework incorporates two core ideas: Firstly, we utilize contrastive learning to enhance the model's ability to differentiate between faithful and hallucinated information in the text, thereby encouraging the decoder to generate text that aligns with the input graph. Secondly, we empower the decoder to control the level 
    
[^30]: 并不那么强大：评估深度神经网络对未知对抗攻击的鲁棒性

    Not So Robust After All: Evaluating the Robustness of Deep Neural Networks to Unseen Adversarial Attacks. (arXiv:2308.06467v1 [cs.LG])

    [http://arxiv.org/abs/2308.06467](http://arxiv.org/abs/2308.06467)

    这项研究旨在评估深度神经网络对未知对抗攻击的鲁棒性，并挑战针对这些攻击的现有防御机制的有效性。实验结果表明，在仅使用鲁棒特征的数据集上训练的DNN模型并不一定能抵抗对抗性攻击。

    

    深度神经网络(DNNs)在各种应用中取得了显著的成就，如分类、识别和预测，这引起了对其属性的增加关注。传统DNN的一个基本属性是它们对输入数据的修改的脆弱性，这导致了对对抗攻击的调查。这些攻击通过操纵数据来误导DNN。本研究旨在挑战针对对抗攻击的当代防御机制的有效性和泛化性。具体而言，我们探讨了Ilyas等人提出的假设，即DNN的图像特征可以是鲁棒的或非鲁棒的，而对抗性攻击针对的是后者。该假设认为，仅在由鲁棒特征组成的数据集上训练DNN应该产生对抗攻击具有抵抗力的模型。然而，我们的实验表明这并不普遍成立。为了进一步了解我们的发现，我们对我们的实验结果进行了分析。

    Deep neural networks (DNNs) have gained prominence in various applications, such as classification, recognition, and prediction, prompting increased scrutiny of their properties. A fundamental attribute of traditional DNNs is their vulnerability to modifications in input data, which has resulted in the investigation of adversarial attacks. These attacks manipulate the data in order to mislead a DNN. This study aims to challenge the efficacy and generalization of contemporary defense mechanisms against adversarial attacks. Specifically, we explore the hypothesis proposed by Ilyas et. al, which posits that DNN image features can be either robust or non-robust, with adversarial attacks targeting the latter. This hypothesis suggests that training a DNN on a dataset consisting solely of robust features should produce a model resistant to adversarial attacks. However, our experiments demonstrate that this is not universally true. To gain further insights into our findings, we analyze the imp
    
[^31]: 多标签知识蒸馏

    Multi-Label Knowledge Distillation. (arXiv:2308.06453v1 [cs.LG])

    [http://arxiv.org/abs/2308.06453](http://arxiv.org/abs/2308.06453)

    这篇论文提出了一种专门针对多标签学习的新颖知识蒸馏方法，通过将多标签问题分解为一组二分类问题以利用逻辑回归的信息性语义知识，并通过利用标签嵌入的结构信息增强学习到的特征表示的独特性。

    

    现有的知识蒸馏方法通常通过将教师网络的输出逻辑回归或中间特征映射传授给学生网络来工作，在多类单标签学习中非常成功。然而，在多标签学习场景下，这些方法很难推广，每个实例都与多个语义标签相关，因为预测概率不等于一，并且在这种情况下，整个示例的特征映射可能会忽略小类别。在本文中，我们提出了一种新颖的多标签知识蒸馏方法。一方面，它通过将多标签学习问题分解为一组二分类问题来利用逻辑回归中的信息性语义知识；另一方面，它通过利用标签嵌入的结构信息来增强学习到的特征表示的独特性。多个基准数据集上的实验结果验证了该方法的有效性。

    Existing knowledge distillation methods typically work by imparting the knowledge of output logits or intermediate feature maps from the teacher network to the student network, which is very successful in multi-class single-label learning. However, these methods can hardly be extended to the multi-label learning scenario, where each instance is associated with multiple semantic labels, because the prediction probabilities do not sum to one and feature maps of the whole example may ignore minor classes in such a scenario. In this paper, we propose a novel multi-label knowledge distillation method. On one hand, it exploits the informative semantic knowledge from the logits by dividing the multi-label learning problem into a set of binary classification problems; on the other hand, it enhances the distinctiveness of the learned feature representations by leveraging the structural information of label-wise embeddings. Experimental results on multiple benchmark datasets validate that the pr
    
[^32]: 语义等变 Mixup

    Semantic Equivariant Mixup. (arXiv:2308.06451v1 [cs.CV])

    [http://arxiv.org/abs/2308.06451](http://arxiv.org/abs/2308.06451)

    这篇论文提出了一种基于语义等变的Mixup方法，通过在表示级别上进行混合来充分利用混合样本中的语义信息，进一步规范神经网络。

    

    Mixup是一种广为使用的数据增强技术，通过在标签等变的基础上创建混合样本，扩展训练分布并规范神经网络。然而，先前的Mixup变体可能未能充分利用训练过程中混合样本中的独立于标签的信息，其中通常包含更丰富的语义信息。为了进一步发挥Mixup的作用，我们首先改进了先前的标签等变假设为语义等变假设，即输入数据的比例混合应导致相应表示的比例混合。然后，我们提出了一种在表示级别上的通用Mixup正则化方法，可以通过混合样本中的语义信息进一步规范模型。

    Mixup is a well-established data augmentation technique, which can extend the training distribution and regularize the neural networks by creating ''mixed'' samples based on the label-equivariance assumption, i.e., a proportional mixup of the input data results in the corresponding labels being mixed in the same proportion. However, previous mixup variants may fail to exploit the label-independent information in mixed samples during training, which usually contains richer semantic information. To further release the power of mixup, we first improve the previous label-equivariance assumption by the semantic-equivariance assumption, which states that the proportional mixup of the input data should lead to the corresponding representation being mixed in the same proportion. Then a generic mixup regularization at the representation level is proposed, which can further regularize the model with the semantic information in mixed samples. At a high level, the proposed semantic equivariant mix
    
[^33]: 顺序元转移（SMT）学习用于应对物理信息神经网络的复杂性：在复合材料热压过程中的应用

    A Sequential Meta-Transfer (SMT) Learning to Combat Complexities of Physics-Informed Neural Networks: Application to Composites Autoclave Processing. (arXiv:2308.06447v1 [cs.LG])

    [http://arxiv.org/abs/2308.06447](http://arxiv.org/abs/2308.06447)

    本论文提出了一种顺序元转移（SMT）学习框架，用于解决物理信息神经网络（PINNs）在高度非线性系统中的训练和适应问题，提供了一种统一的、快速的解决方案。

    

    物理信息神经网络（PINNs）通过将物理定律融入神经网络的训练中，已经在解决非线性偏微分方程（PDEs）方面变得越来越流行，并在许多科学和工程应用中表现出优越性。然而，传统的PINNs在准确逼近具有强非线性的复杂系统的解方面仍然存在一定的局限性，尤其是在长时间域下。此外，由于PINNs被设计为逼近给定PDE系统的特定实现，它们缺乏必要的通用性来有效适应新系统配置。这就需要在系统发生任何变化时进行从头重新训练，计算成本较高。为了解决这些问题，在这项工作中提出了一种新颖的顺序元转移（SMT）学习框架，为高度非线性系统的PINNs提供了快速训练和高效适应的统一解决方案。

    Physics-Informed Neural Networks (PINNs) have gained popularity in solving nonlinear partial differential equations (PDEs) via integrating physical laws into the training of neural networks, making them superior in many scientific and engineering applications. However, conventional PINNs still fall short in accurately approximating the solution of complex systems with strong nonlinearity, especially in long temporal domains. Besides, since PINNs are designed to approximate a specific realization of a given PDE system, they lack the necessary generalizability to efficiently adapt to new system configurations. This entails computationally expensive re-training from scratch for any new change in the system. To address these shortfalls, in this work a novel sequential meta-transfer (SMT) learning framework is proposed, offering a unified solution for both fast training and efficient adaptation of PINNs in highly nonlinear systems with long temporal domains. Specifically, the framework deco
    
[^34]: 使用基于聚类的树状Parzen估计的敏感性感知混合精度量化和宽度优化的深度神经网络

    Sensitivity-Aware Mixed-Precision Quantization and Width Optimization of Deep Neural Networks Through Cluster-Based Tree-Structured Parzen Estimation. (arXiv:2308.06422v1 [cs.LG])

    [http://arxiv.org/abs/2308.06422](http://arxiv.org/abs/2308.06422)

    本研究引入了一种创新的深度神经网络优化方法，通过自动选择最佳的位宽和层宽来提高网络效率。同时，通过剪枝和聚类技术，优化了搜索过程，并在多个数据集上进行了严格测试，结果显示该方法明显优于现有方法。

    

    随着深度学习模型的复杂性和计算需求的提高，对神经网络设计的有效优化方法的需求变得至关重要。本文引入了一种创新的搜索机制，用于自动选择单个神经网络层的最佳位宽和层宽。这导致深度神经网络效率的明显提高。通过利用基于Hessian的剪枝策略，有选择地减少搜索域，确保移除非关键参数。随后，我们通过使用基于聚类的树状Parzen估计器开发有利和不利结果的替代模型。这种策略允许对架构可能性进行简化的探索，并迅速确定表现最好的设计。通过对知名数据集进行严格测试，我们的方法证明了与现有方法相比的明显优势。与领先的压缩策略相比，我们的方法取得了令人瞩目的成果。

    As the complexity and computational demands of deep learning models rise, the need for effective optimization methods for neural network designs becomes paramount. This work introduces an innovative search mechanism for automatically selecting the best bit-width and layer-width for individual neural network layers. This leads to a marked enhancement in deep neural network efficiency. The search domain is strategically reduced by leveraging Hessian-based pruning, ensuring the removal of non-crucial parameters. Subsequently, we detail the development of surrogate models for favorable and unfavorable outcomes by employing a cluster-based tree-structured Parzen estimator. This strategy allows for a streamlined exploration of architectural possibilities and swift pinpointing of top-performing designs. Through rigorous testing on well-known datasets, our method proves its distinct advantage over existing methods. Compared to leading compression strategies, our approach records an impressive 
    
[^35]: 行人-车辆混合环境下的行人轨迹预测:一项系统综述

    Pedestrian Trajectory Prediction in Pedestrian-Vehicle Mixed Environments: A Systematic Review. (arXiv:2308.06419v1 [cs.RO])

    [http://arxiv.org/abs/2308.06419](http://arxiv.org/abs/2308.06419)

    本文系统综述了行人-车辆混合环境下的行人轨迹预测方法，探讨了车辆和行人的相互作用对行人未来行为的影响，并回顾了先前提出的预测模型中如何考虑不确定性和行为差异。

    

    在与行人共享空间的自动驾驶车辆（AV）路径规划中，需要推理出行人的未来轨迹。为了应用于AV的实际行人轨迹预测算法，需要考虑车辆与行人的相互作用对行人未来运动行为的影响。在这方面，本文系统综述了文献中针对在存在车辆的非结构化环境中对行人轨迹预测进行建模的不同方法。本文还探讨了与行人-行人交互相比，行人-车辆交互的特定考虑，并回顾了先前提出的预测模型中如何考虑预测不确定性和行为差异等不同变量。遵循PRISMA指南。本文还考察了如何在先前提出的预测模型中考虑预测不确定性和行为差异等不同变量。

    Planning an autonomous vehicle's (AV) path in a space shared with pedestrians requires reasoning about pedestrians' future trajectories. A practical pedestrian trajectory prediction algorithm for the use of AVs needs to consider the effect of the vehicle's interactions with the pedestrians on pedestrians' future motion behaviours. In this regard, this paper systematically reviews different methods proposed in the literature for modelling pedestrian trajectory prediction in presence of vehicles that can be applied for unstructured environments. This paper also investigates specific considerations for pedestrian-vehicle interaction (compared with pedestrian-pedestrian interaction) and reviews how different variables such as prediction uncertainties and behavioural differences are accounted for in the previously proposed prediction models. PRISMA guidelines were followed. Articles that did not consider vehicle and pedestrian interactions or actual trajectories, and articles that only focu
    
[^36]: 人类监管者与城市空中交通管理之间的对话可能性：路径更改

    Dialogue Possibilities between a Human Supervisor and UAM Air Traffic Management: Route Alteration. (arXiv:2308.06411v1 [cs.AI])

    [http://arxiv.org/abs/2308.06411](http://arxiv.org/abs/2308.06411)

    本文介绍了一种基于知识表示和推理的方法，在城市空中交通管理中实现了人类监管者和系统之间的对话，并通过验证了该方法的稳健性和效力，为人类知识和先进AI技术的共生做出了贡献。

    

    本文介绍了一种利用知识表示和推理在城市空中交通管理（UATM）中进行绕行管理的新方法。它旨在了解UAM绕行的复杂性和要求，实现一种能够在经过仔细采样的环境中快速确定安全和高效路线的方法。该方法采用了非单调推理和人类经理与UATM系统之间的两阶段对话，考虑了安全性和潜在影响等因素。通过两个模拟场景中的几个查询验证了所提出方法的稳健性和效力，为人类知识和先进AI技术的共生做出了贡献。本文提供了引言、引用相关研究、问题阐述、解决方案、讨论和结论性评论。

    This paper introduces a novel approach to detour management in Urban Air Traffic Management (UATM) using knowledge representation and reasoning. It aims to understand the complexities and requirements of UAM detours, enabling a method that quickly identifies safe and efficient routes in a carefully sampled environment. This method implemented in Answer Set Programming uses non-monotonic reasoning and a two-phase conversation between a human manager and the UATM system, considering factors like safety and potential impacts. The robustness and efficacy of the proposed method were validated through several queries from two simulation scenarios, contributing to the symbiosis of human knowledge and advanced AI techniques. The paper provides an introduction, citing relevant studies, problem formulation, solution, discussions, and concluding comments.
    
[^37]: 一种自适应SSVEP识别的脑机接口增强现实框架

    A Brain-Computer Interface Augmented Reality Framework with Auto-Adaptive SSVEP Recognition. (arXiv:2308.06401v1 [cs.HC])

    [http://arxiv.org/abs/2308.06401](http://arxiv.org/abs/2308.06401)

    提出了一种自适应的SSVEP识别的脑机接口增强现实框架，可以帮助身体残障人士和健康用户使用增强现实技术进行交互，通过稳态视觉诱发电位（SSVEP）信号识别用户需求和愿望。

    

    脑机接口（BCI）最初引起关注是为了开发帮助被身体残障人士的应用。最近，将BCI与增强现实（AR）结合的想法出现了，这不仅可以增强残障人士的生活质量，还可以为健康用户开发主流应用。其中一种常用的BCI信号模式是稳态视觉诱发电位（SSVEP），它捕捉了大脑对闪烁视觉刺激的响应。基于SSVEP的BCI-AR应用使用户可以通过简单地看着相应的命令选项来表达他们的需求/愿望。然而，不同个体的脑信号是不同的，因此需要针对每个个体进行SSVEP识别。此外，肌肉运动和眼睑闪烁会干扰脑信号，因此受试者需要在BCI实验期间保持静止，这限制了增强现实的参与。本文提出了一个简单的自适应集成分类系统来处理这些问题。

    Brain-Computer Interface (BCI) initially gained attention for developing applications that aid physically impaired individuals. Recently, the idea of integrating BCI with Augmented Reality (AR) emerged, which uses BCI not only to enhance the quality of life for individuals with disabilities but also to develop mainstream applications for healthy users. One commonly used BCI signal pattern is the Steady-state Visually-evoked Potential (SSVEP), which captures the brain's response to flickering visual stimuli. SSVEP-based BCI-AR applications enable users to express their needs/wants by simply looking at corresponding command options. However, individuals are different in brain signals and thus require per-subject SSVEP recognition. Moreover, muscle movements and eye blinks interfere with brain signals, and thus subjects are required to remain still during BCI experiments, which limits AR engagement. In this paper, we (1) propose a simple adaptive ensemble classification system that handle
    
[^38]: ZYN：零式奖励模型与是非问题

    ZYN: Zero-Shot Reward Models with Yes-No Questions. (arXiv:2308.06385v1 [cs.CL])

    [http://arxiv.org/abs/2308.06385](http://arxiv.org/abs/2308.06385)

    本文提出了ZYN框架，通过使用是非问题作为奖励模型的提示，以及增强学习来微调语言模型，使其生成的文本与人类操作者的偏好对齐。实验证据表明该方法在不同领域的文本生成任务中具有很好的效果，包括解毒、情感优化和个性化提示生成器等。

    

    在这项工作中，我们解决了将语言模型的文本生成定向于期望行为的问题，将生成的文本与人类操作者的偏好对齐。我们建议使用另一个语言模型作为批评者，通过一个表示用户偏好的是非问题的提示，以零式方式作为奖励模型，而不需要进一步标记数据。这种零式奖励模型为进一步微调基本语言模型提供了学习信号，使用增强学习，就像在RLAIF中一样；然而我们的方法在其他上下文中也是兼容的，例如质量多样性搜索。通过在与文本生成相关的不同领域进行实验，包括解毒、优化电影评论的情感或任何其他属性、引导模型可能具有的关于特定主题的观点，以及个性化的文本到图像任务的提示生成器，提供了对所提出的ZYN框架能力的大量证据。代码将在\url处发布。

    In this work, we address the problem of directing the text generations of a LLM towards a desired behavior, aligning the generated text with the preferences of the human operator. We propose using another language model as a critic, reward model in a zero-shot way thanks to the prompt of a Yes-No question that represents the user preferences, without requiring further labeled data. This zero-shot reward model provides the learning signal to further fine-tune the base LLM using reinforcement learning, as in RLAIF; yet our approach is also compatible in other contexts such as quality-diversity search. Extensive evidence of the capabilities of the proposed ZYN framework is provided through experiments in different domains related to text generation, including detoxification; optimizing sentiment of movie reviews, or any other attribute; steering the opinion about a particular topic the model may have; and personalizing prompt generators for text-to-image tasks. Code to be released at \url
    
[^39]: DCNFIS：深度卷积神经模糊推理系统

    DCNFIS: Deep Convolutional Neuro-Fuzzy Inference System. (arXiv:2308.06378v1 [cs.AI])

    [http://arxiv.org/abs/2308.06378](http://arxiv.org/abs/2308.06378)

    本文介绍了一种新的深度卷积神经模糊推理系统（DCNFIS），它通过将模糊逻辑和深度学习模型相结合，实现了提高透明度而不损失准确性的目标。DCNFIS在准确性上与现有卷积神经网络相当，并且胜过了最先进的深度模糊系统。通过模糊规则提取的解释可以提高模型的可解释性。

    

    在可解释的人工智能中，透明度与准确性之间存在一个著名的权衡。本文介绍了一种新的深度网络设计，通过将模糊逻辑和深度学习模型相结合，实现了提高透明度但不损失准确性的目标。我们设计了一个深度卷积神经模糊推理系统（DCNFIS），并在四个著名数据集上展示了它与三个现有卷积神经网络的相同准确性。我们进一步发现，DCNFIS在性能上胜过了最先进的深度模糊系统。然后，我们利用模糊逻辑的透明度，从DCNFIS中编码的模糊规则中提取解释，以渐变映射的形式展示。我们还利用Fashion-MNIST数据集对这些解释的特性进行了深入研究。

    A key challenge in eXplainable Artificial Intelligence is the well-known tradeoff between the transparency of an algorithm (i.e., how easily a human can directly understand the algorithm, as opposed to receiving a post-hoc explanation), and its accuracy. We report on the design of a new deep network that achieves improved transparency without sacrificing accuracy. We design a deep convolutional neuro-fuzzy inference system (DCNFIS) by hybridizing fuzzy logic and deep learning models and show that DCNFIS performs as accurately as three existing convolutional neural networks on four well-known datasets. We furthermore that DCNFIS outperforms state-of-the-art deep fuzzy systems. We then exploit the transparency of fuzzy logic by deriving explanations, in the form of saliency maps, from the fuzzy rules encoded in DCNFIS. We investigate the properties of these explanations in greater depth using the Fashion-MNIST dataset.
    
[^40]: 大型语言模型和知识图谱：机遇与挑战

    Large Language Models and Knowledge Graphs: Opportunities and Challenges. (arXiv:2308.06374v1 [cs.AI])

    [http://arxiv.org/abs/2308.06374](http://arxiv.org/abs/2308.06374)

    大型语言模型和知识图谱的结合为知识表示带来了新的机遇和挑战。

    

    大型语言模型（LLMs）已经给知识表示领域和整个世界带来了风暴。这一转折点标志着知识表示从显式知识表示转向显式知识和参数化知识混合表示的焦点的重塑。在这篇立场论文中，我们将讨论LLMs（参数化知识）和知识图谱（显式知识）领域内的一些常见争论，展望焦点重塑所带来的机遇和愿景，以及相关的研究主题和挑战。

    Large Language Models (LLMs) have taken Knowledge Representation -- and the world -- by storm. This inflection point marks a shift from explicit knowledge representation to a renewed focus on the hybrid representation of both explicit knowledge and parametric knowledge. In this position paper, we will discuss some of the common debate points within the community on LLMs (parametric knowledge) and Knowledge Graphs (explicit knowledge) and speculate on opportunities and visions that the renewed focus brings, as well as related research topics and challenges.
    
[^41]: 无线联合k均值聚类与非相干空中计算

    Wireless Federated $k$-Means Clustering with Non-coherent Over-the-Air Computation. (arXiv:2308.06371v1 [eess.SP])

    [http://arxiv.org/abs/2308.06371](http://arxiv.org/abs/2308.06371)

    本研究提出了一种利用无线信道的非相干空中计算方案来降低联合k均值聚类算法在无线网络上的通信延迟。此方法通过利用平衡进制和信号叠加性质实现联合k均值的更新，同时通过重新初始化未有效使用的质心来改善对异构数据分布的聚类性能。

    

    本研究提出了一种无线联合k均值聚类算法的空中计算方案，以降低在无线网络上实施时的每轮通信延迟。该空中计算方案依赖于编码器利用平衡进制中数字的表示方式，并通过无线多址信道的信号叠加性质非相干地计算联合k均值的更新之和，消除了对精确相位和时间同步的需求。此外，还提出了一种重新初始化方法来改善对异构数据分布的未有效使用的质心的性能。针对客户位置聚类场景，我们展示了所提算法的性能，并与标准k均值聚类进行了比较。结果表明，所提方法在降低通信延迟的同时，与标准k均值聚类具有相似的性能。

    In this study, we propose using an over-the-air computation (OAC) scheme for the federated k-means clustering algorithm to reduce the per-round communication latency when it is implemented over a wireless network. The OAC scheme relies on an encoder exploiting the representation of a number in a balanced number system and computes the sum of the updates for the federated k-means via signal superposition property of wireless multiple-access channels non-coherently to eliminate the need for precise phase and time synchronization. Also, a reinitialization method for ineffectively used centroids is proposed to improve the performance of the proposed method for heterogeneous data distribution. For a customer-location clustering scenario, we demonstrate the performance of the proposed algorithm and compare it with the standard k-means clustering. Our results show that the proposed approach performs similarly to the standard k-means while reducing communication latency.
    
[^42]: 基于主题的贝叶斯惊喜和意外性用于推荐系统

    Topic-Level Bayesian Surprise and Serendipity for Recommender Systems. (arXiv:2308.06368v1 [cs.IR])

    [http://arxiv.org/abs/2308.06368](http://arxiv.org/abs/2308.06368)

    本文通过引入基于主题的贝叶斯惊喜概念，提出了一种用于推荐系统的意外性模型，以解决过滤泡问题，通过识别相似用户和测量用户对物品的意外性来推荐具有高潜力的意外性物品。

    

    推荐系统优化其推荐仅适合用户对已消费物品的评级历史，这可能导致过滤泡，用户无法从新颖、未见过的类别中体验物品。我们提出了一种基于内容的意外性形式，以贝叶斯惊喜为基础，用于测量用户消费并评级后物品的意外性。结合识别相似用户的协同过滤组件，可以推荐具有高潜力意外性的物品。为了便于评估主题级别的惊喜和意外性模型，我们介绍了一个从Goodreads中提取的图书阅读历史数据集，包含超过26千个用户和近130万本书，并对其中的449篇书进行了手动注释。

    A recommender system that optimizes its recommendations solely to fit a user's history of ratings for consumed items can create a filter bubble, wherein the user does not get to experience items from novel, unseen categories. One approach to mitigate this undesired behavior is to recommend items with high potential for serendipity, namely surprising items that are likely to be highly rated. In this paper, we propose a content-based formulation of serendipity that is rooted in Bayesian surprise and use it to measure the serendipity of items after they are consumed and rated by the user. When coupled with a collaborative-filtering component that identifies similar users, this enables recommending items with high potential for serendipity. To facilitate the evaluation of topic-level models for surprise and serendipity, we introduce a dataset of book reading histories extracted from Goodreads, containing over 26 thousand users and close to 1.3 million books, where we manually annotate 449 
    
[^43]: 大型语言模型在电子健康记录中识别社会健康决定因素

    Large Language Models to Identify Social Determinants of Health in Electronic Health Records. (arXiv:2308.06354v1 [cs.CL])

    [http://arxiv.org/abs/2308.06354](http://arxiv.org/abs/2308.06354)

    本研究利用大型语言模型从电子健康记录中提取社会健康决定因素（SDoH），并通过合成临床文本改进了这些极有价值但很少被记录的临床数据的提取。最佳模型为经过微调的Flan-T5 XL和Flan-T5 XXL，其中小型模型改进了性能。

    

    社会健康决定因素（SDoH）对患者的结果有重要影响，但在电子健康记录（EHR）中的收集不完整。本研究研究了大型语言模型从EHR中提取SDoH的能力，并探讨了合成临床文本在改进这些少见但极有价值的临床数据提取中的作用。对800份患者记录进行了SDoH类别的注释，并评估了几个基于transformer的模型。本研究还尝试了合成数据生成，并评估了算法偏差。我们表现最佳的模型是经过微调的Flan-T5 XL（macro-F1 0.71）用于任何SDoH，以及Flan-T5 XXL（macro-F1 0.70）。通过合成数据辅助微调的效益因模型架构和大小而异，在较小的Flan-T5模型（基础和大型）中表现出最大的性能提升（delta F1 +0.12到+0.23）。模型性能。

    Social determinants of health (SDoH) have an important impact on patient outcomes but are incompletely collected from the electronic health records (EHR). This study researched the ability of large language models to extract SDoH from free text in EHRs, where they are most commonly documented, and explored the role of synthetic clinical text for improving the extraction of these scarcely documented, yet extremely valuable, clinical data. 800 patient notes were annotated for SDoH categories, and several transformer-based models were evaluated. The study also experimented with synthetic data generation and assessed for algorithmic bias. Our best-performing models were fine-tuned Flan-T5 XL (macro-F1 0.71) for any SDoH, and Flan-T5 XXL (macro-F1 0.70). The benefit of augmenting fine-tuning with synthetic data varied across model architecture and size, with smaller Flan-T5 models (base and large) showing the greatest improvements in performance (delta F1 +0.12 to +0.23). Model performance 
    
[^44]: 组合特征聚合和几何相似性用于图案动物的重新识别

    Combining feature aggregation and geometric similarity for re-identification of patterned animals. (arXiv:2308.06335v1 [cs.CV])

    [http://arxiv.org/abs/2308.06335](http://arxiv.org/abs/2308.06335)

    本文提出了一种组合特征聚合和几何相似性的方法，用于图案动物的重新识别。该方法利用图案的外观相似度和几何一致性来实现综合性的重新识别，可以适用于各种不同类型的图案。

    

    基于图像的动物个体重新识别可以获取动物随时间的迁徙模式等信息。这与使用相机陷阱和众包收集的大量图像卷打开了研究动物种群的新可能性。对于许多物种，可以通过分析每个个体独有的永久毛、羽毛或皮肤图案来进行重新识别。在本文中，我们通过组合两种类型的图案相似度度量来解决重新识别问题：1）通过图案特征聚合获得的图案外观相似度和2）通过分析图案相似度的几何一致性获得的几何图案相似度。所提出的组合方法可以有效地利用局部和全局图案特征，提供了一种通用的重新识别方法，可应用于各种不同的图案类型。在实验部分中，我们证明了该方法可以实现。

    Image-based re-identification of animal individuals allows gathering of information such as migration patterns of the animals over time. This, together with large image volumes collected using camera traps and crowdsourcing, opens novel possibilities to study animal populations. For many species, the re-identification can be done by analyzing the permanent fur, feather, or skin patterns that are unique to each individual. In this paper, we address the re-identification by combining two types of pattern similarity metrics: 1) pattern appearance similarity obtained by pattern feature aggregation and 2) geometric pattern similarity obtained by analyzing the geometric consistency of pattern similarities. The proposed combination allows to efficiently utilize both the local and global pattern features, providing a general re-identification approach that can be applied to a wide variety of different pattern types. In the experimental part of the work, we demonstrate that the method achieves 
    
[^45]: 防御感知：神经网络在部署中的性能估计和监测

    Defensive Perception: Estimation and Monitoring of Neural Network Performance under Deployment. (arXiv:2308.06299v1 [cs.CV])

    [http://arxiv.org/abs/2308.06299](http://arxiv.org/abs/2308.06299)

    本文提出了一种方法，用于解决自动驾驶中神经网络的部署中不被察觉的灾难性问题和领域转移问题。我们通过不确定性估计封装了部署中的神经网络，以提高感知系统的性能和安全性。

    

    本文提出了一种方法，用于解决自动驾驶中语义分割神经网络在部署过程中不被察觉的灾难性问题和领域转移问题。我们的方法基于深度学习感知对自动驾驶的不确定性并将其最佳表示为概率分布。由于自动车辆的安全至关重要，感知系统必须能够识别车辆是否离开了操作设计领域，预测危险的不确定性并降低感知系统性能。为了解决这个问题，我们提出了在部署中对神经网络进行不确定性估计封装，该封装基于蒙特卡罗 Dropout 方法通过对认知不确定性进行估计。该方法不需要修改部署的神经网络，并保证预期的模型性能。我们的防御性感知封装能够估计神经网络的

    In this paper, we propose a method for addressing the issue of unnoticed catastrophic deployment and domain shift in neural networks for semantic segmentation in autonomous driving. Our approach is based on the idea that deep learning-based perception for autonomous driving is uncertain and best represented as a probability distribution. As autonomous vehicles' safety is paramount, it is crucial for perception systems to recognize when the vehicle is leaving its operational design domain, anticipate hazardous uncertainty, and reduce the performance of the perception system. To address this, we propose to encapsulate the neural network under deployment within an uncertainty estimation envelope that is based on the epistemic uncertainty estimation through the Monte Carlo Dropout approach. This approach does not require modification of the deployed neural network and guarantees expected model performance. Our defensive perception envelope has the capability to estimate a neural network's 
    
[^46]: 使用大型语言模型提升临床笔记中表型识别能力：PhenoBCBERT和PhenoGPT

    Enhancing Phenotype Recognition in Clinical Notes Using Large Language Models: PhenoBCBERT and PhenoGPT. (arXiv:2308.06294v1 [q-bio.QM])

    [http://arxiv.org/abs/2308.06294](http://arxiv.org/abs/2308.06294)

    本研究利用大型语言模型（LLMs）开发了两种表型识别模型PhenoBCBERT和PhenoGPT，相比于基于规则和深度学习的方法，这些模型能够更准确地识别临床表型术语，包括HPO未记录的新术语。

    

    我们假设基于Transformer架构的大型语言模型（LLMs）可以实现对临床表型术语的自动检测，包括未在HPO中记录的术语。在本研究中，我们开发了两种模型：PhenoBCBERT，一种基于BERT的模型，利用Bio+Clinical BERT作为其预训练模型；以及PhenoGPT，一种基于GPT的模型，可以从不同的GPT模型（包括开源版本如GPT-J、Falcon和LLaMA，以及关闭源版本如GPT-3和GPT-3.5）进行初始化。我们将我们的方法与最近开发的结合了基于规则和深度学习方法的HPO识别工具PhenoTagger进行了比较。我们发现我们的方法可以提取更多的表型概念，包括HPO未描述的新概念。我们还对生物医学文献进行了案例研究，以说明如何识别和提取新的表型信息。我们比较了当前基于BERT和基于GPT的模型在多个表型标记任务上的表现。

    We hypothesize that large language models (LLMs) based on the transformer architecture can enable automated detection of clinical phenotype terms, including terms not documented in the HPO. In this study, we developed two types of models: PhenoBCBERT, a BERT-based model, utilizing Bio+Clinical BERT as its pre-trained model, and PhenoGPT, a GPT-based model that can be initialized from diverse GPT models, including open-source versions such as GPT-J, Falcon, and LLaMA, as well as closed-source versions such as GPT-3 and GPT-3.5. We compared our methods with PhenoTagger, a recently developed HPO recognition tool that combines rule-based and deep learning methods. We found that our methods can extract more phenotype concepts, including novel ones not characterized by HPO. We also performed case studies on biomedical literature to illustrate how new phenotype information can be recognized and extracted. We compared current BERT-based versus GPT-based models for phenotype tagging, in multipl
    
[^47]: 我们已经闭环了吗？VIS4ML研究中的推广性差异

    Are We Closing the Loop Yet? Gaps in the Generalizability of VIS4ML Research. (arXiv:2308.06290v1 [cs.HC])

    [http://arxiv.org/abs/2308.06290](http://arxiv.org/abs/2308.06290)

    VIS4ML研究在推广实践应用方面存在差异，需要填补未被代表性情况过度拟合、缺乏关键依赖因素的空白。

    

    机器学习可视化(VIS4ML)研究旨在帮助专家应用其先前知识来开发、理解和改进机器学习模型的性能。在构思VIS4ML系统时，研究人员对支持人机交互任务的人类知识进行了表征，设计了交互式可视化以使机器学习组件可解释并引出知识，并评估了人机互换的有效性。我们调查了最近的VIS4ML论文，以评估研究贡献和推动人机交互机器学习的普适性。我们的结果显示，当前VIS4ML研究的范围与实际应用的期望之间存在潜在差距。我们发现，虽然论文认为VIS4ML系统适用于研究之外的条件，但结论往往过度拟合非代表性场景，基于与少量机器学习专家和众所周知数据集的互动，未能承认关键依赖因素。

    Visualization for machine learning (VIS4ML) research aims to help experts apply their prior knowledge to develop, understand, and improve the performance of machine learning models. In conceiving VIS4ML systems, researchers characterize the nature of human knowledge to support human-in-the-loop tasks, design interactive visualizations to make ML components interpretable and elicit knowledge, and evaluate the effectiveness of human-model interchange. We survey recent VIS4ML papers to assess the generalizability of research contributions and claims in enabling human-in-the-loop ML. Our results show potential gaps between the current scope of VIS4ML research and aspirations for its use in practice. We find that while papers motivate that VIS4ML systems are applicable beyond the specific conditions studied, conclusions are often overfitted to non-representative scenarios, are based on interactions with a small set of ML experts and well-understood datasets, fail to acknowledge crucial depe
    
[^48]: 为可解释的人工智能构建一个综合的以人为中心的评估框架

    Towards a Comprehensive Human-Centred Evaluation Framework for Explainable AI. (arXiv:2308.06274v1 [cs.HC])

    [http://arxiv.org/abs/2308.06274](http://arxiv.org/abs/2308.06274)

    本论文提出了一个综合的以人为中心的评估框架，用于评估可解释的人工智能（XAI）。当前的评估过程不全面评估XAI方法的效果，也未将解释对人类的影响视为一种复杂的用户体验。我们的框架整合了解释的因素，总结了解释的特性，并分类了测量这些特性的指标，旨在为XAI评估的以人为中心的标准化做出贡献。

    

    尽管可解释的人工智能（XAI）的研究正在蓬勃发展，并且解释技术在许多应用领域已被证明是有前景的，但标准化的以人为中心的评估过程仍然缺失。此外，当前的评估过程并未全面评估XAI方法，即它们未将解释对人类的影响视为一种复杂的用户体验。为了解决这个挑战，我们建议借鉴在推荐系统中使用的用户中心评估框架：我们整合解释方面的因素，总结解释的特性，指示它们之间的关系，并对测量这些特性的指标进行分类。通过这个综合评估框架，我们希望为XAI评估的以人为中心的标准化做出贡献。

    While research on explainable AI (XAI) is booming and explanation techniques have proven promising in many application domains, standardised human-centred evaluation procedures are still missing. In addition, current evaluation procedures do not assess XAI methods holistically in the sense that they do not treat explanations' effects on humans as a complex user experience. To tackle this challenge, we propose to adapt the User-Centric Evaluation Framework used in recommender systems: we integrate explanation aspects, summarise explanation properties, indicate relations between them, and categorise metrics that measure these properties. With this comprehensive evaluation framework, we hope to contribute to the human-centred standardisation of XAI evaluation.
    
[^49]: 超越现实：生成式人工智能在元宇宙中的关键作用

    Beyond Reality: The Pivotal Role of Generative AI in the Metaverse. (arXiv:2308.06272v1 [cs.HC])

    [http://arxiv.org/abs/2308.06272](http://arxiv.org/abs/2308.06272)

    本文全面探讨了生成式人工智能技术如何塑造元宇宙，将其转变为一个充满活力、沉浸式和互动式的虚拟世界。我们深入研究了文本生成模型（如ChatGPT和GPT-3）和图像生成模型（如DALL-E和MidJourney）的应用，以及三维模型生成技术（如Point-E和Lumirithmic）的潜力。同时，我们还讨论了实施这些技术所面临的挑战和伦理考虑。

    

    想象一下，进入一个与我们物理世界一样丰富、动态和互动的虚拟世界。这就是元宇宙的承诺，而生成式人工智能的变革力量正在给它注入生命。本文全面探讨了生成式人工智能技术如何塑造元宇宙，将其转变为一个充满活力、沉浸式和互动式的虚拟世界。我们深入研究了文本生成模型（如ChatGPT和GPT-3）在增强带有人工智能生成角色的对话界面方面的应用。我们探索了图像生成模型（如DALL-E和MidJourney）在创建视觉上令人惊艳和多样化的内容方面的作用。我们还考察了三维模型生成技术（如Point-E和Lumirithmic）在创建丰富元宇宙体验的逼真虚拟物体方面的潜力。但旅程并不止于此。我们还讨论了实施这些技术所面临的挑战和伦理考虑。

    Imagine stepping into a virtual world that's as rich, dynamic, and interactive as our physical one. This is the promise of the Metaverse, and it's being brought to life by the transformative power of Generative Artificial Intelligence (AI). This paper offers a comprehensive exploration of how generative AI technologies are shaping the Metaverse, transforming it into a dynamic, immersive, and interactive virtual world. We delve into the applications of text generation models like ChatGPT and GPT-3, which are enhancing conversational interfaces with AI-generated characters. We explore the role of image generation models such as DALL-E and MidJourney in creating visually stunning and diverse content. We also examine the potential of 3D model generation technologies like Point-E and Lumirithmic in creating realistic virtual objects that enrich the Metaverse experience. But the journey doesn't stop there. We also address the challenges and ethical considerations of implementing these techno
    
[^50]: 旋转不变的随机特征为3D点云上的机器学习提供了一个强大的基准

    Rotation-Invariant Random Features Provide a Strong Baseline for Machine Learning on 3D Point Clouds. (arXiv:2308.06271v1 [cs.CV])

    [http://arxiv.org/abs/2308.06271](http://arxiv.org/abs/2308.06271)

    本研究提出了一种简单且通用的方法，使用随机特征学习三维点云数据的旋转不变函数，为机器学习在3D点云上提供了一个强大的基准。

    

    旋转不变性是机器学习中许多领域使用的一种普遍的归纳偏好，例如计算机视觉和量子化学的机器学习。旋转不变的机器学习方法在许多任务中达到了最先进的水平，包括分子性质预测和3D形状分类。这些方法通常要么依赖于任务特定的旋转不变特征，要么使用复杂设计和训练的通用深度神经网络。然而，目前尚不清楚这些方法的成功主要是由于旋转不变性还是深度神经网络。为了解决这个问题，我们提出了一种简单且通用的方法来学习三维点云数据的旋转不变函数，采用了随机特征方法。具体来说，我们通过推导出一种对三维旋转不变的版本，并证明它在点云数据上的快速评估。

    Rotational invariance is a popular inductive bias used by many fields in machine learning, such as computer vision and machine learning for quantum chemistry. Rotation-invariant machine learning methods set the state of the art for many tasks, including molecular property prediction and 3D shape classification. These methods generally either rely on task-specific rotation-invariant features, or they use general-purpose deep neural networks which are complicated to design and train. However, it is unclear whether the success of these methods is primarily due to the rotation invariance or the deep neural networks. To address this question, we suggest a simple and general-purpose method for learning rotation-invariant functions of three-dimensional point cloud data using a random features approach. Specifically, we extend the random features method of Rahimi & Recht 2007 by deriving a version that is invariant to three-dimensional rotations and showing that it is fast to evaluate on point
    
[^51]: 使用大型语言模型提升金融审计的零样本文本匹配

    Improving Zero-Shot Text Matching for Financial Auditing with Large Language Models. (arXiv:2308.06111v1 [cs.CL])

    [http://arxiv.org/abs/2308.06111](http://arxiv.org/abs/2308.06111)

    这项研究提出了ZeroShotALI，它使用了一种新颖的推荐系统来改进金融审计中的零样本文本匹配。通过采用大型语言模型（LLM）和经过领域优化的基于transformer的文本匹配解决方案，该系统实现了从报告中推荐与法律要求相符的相关文本段落，并在现有方法上取得了显著的性能提升。

    

    审计金融文件是一个非常繁琐和耗时的过程。目前，通过使用基于人工智能的解决方案可以简化这一过程，以推荐与严格会计标准的法律要求相符的报告中的相关文本段落。然而，这些方法需要定期进行微调，并且通常在工业环境中缺乏大量的注释数据。因此，我们提出了ZeroShotALI，这是一个新颖的推荐系统，利用了最先进的大型语言模型（LLM）与领域特定的优化的基于transformer的文本匹配解决方案。我们发现，首先使用自定义BERT模型检索与法律要求相符的若干最佳匹配的文档部分，然后使用LLM对这些选择进行过滤，可以显著改善现有方法的性能。

    Auditing financial documents is a very tedious and time-consuming process. As of today, it can already be simplified by employing AI-based solutions to recommend relevant text passages from a report for each legal requirement of rigorous accounting standards. However, these methods need to be fine-tuned regularly, and they require abundant annotated data, which is often lacking in industrial environments. Hence, we present ZeroShotALI, a novel recommender system that leverages a state-of-the-art large language model (LLM) in conjunction with a domain-specifically optimized transformer-based text-matching solution. We find that a two-step approach of first retrieving a number of best matching document sections per legal requirement with a custom BERT-based model and second filtering these selections using an LLM yields significant performance improvements over existing approaches.
    
[^52]: 鲁棒的声源定位的音频-视觉空间融合和递归注意力

    Audio-Visual Spatial Integration and Recursive Attention for Robust Sound Source Localization. (arXiv:2308.06087v1 [cs.MM] CROSS LISTED)

    [http://arxiv.org/abs/2308.06087](http://arxiv.org/abs/2308.06087)

    本文提出了一种音频-视觉空间融合网络，通过整合音频和视觉模态的空间线索来模仿人类检测声音产生物体的行为，并引入递归注意力网络来得到更准确的注意力区域。通过音频和视觉模态的空间线索和递归聚焦策略，方法在声源定位任务上取得了良好的性能。

    

    声源定位任务的目标是让机器能够在视觉场景中检测出声音产生物体的位置。虽然音频模态提供了定位声源的空间线索，但现有方法仅将音频作为视觉模态空间区域比较的辅助角色。而人类则利用音频和视觉模态作为定位声源的空间线索。本文提出了一种音频-视觉空间融合网络，通过整合两种模态的空间线索来模仿人类检测声音产生物体时的行为。此外，我们引入了一种递归注意力网络来模仿人类迭代地聚焦对象，从而得到更准确的注意力区域。为了有效地编码两种模态的空间信息，我们提出了音频-视觉配对匹配损失和空间区域对齐损失。通过利用音频-视觉模态的空间线索和递归聚焦的策略，我们的方法在声源定位任务上取得了良好的性能。

    The objective of the sound source localization task is to enable machines to detect the location of sound-making objects within a visual scene. While the audio modality provides spatial cues to locate the sound source, existing approaches only use audio as an auxiliary role to compare spatial regions of the visual modality. Humans, on the other hand, utilize both audio and visual modalities as spatial cues to locate sound sources. In this paper, we propose an audio-visual spatial integration network that integrates spatial cues from both modalities to mimic human behavior when detecting sound-making objects. Additionally, we introduce a recursive attention network to mimic human behavior of iterative focusing on objects, resulting in more accurate attention regions. To effectively encode spatial information from both modalities, we propose audio-visual pair matching loss and spatial region alignment loss. By utilizing the spatial cues of audio-visual modalities and recursively focusing
    
[^53]: 在内存层次结构上具有MiRo的成本效益的设备上的持续学习

    Cost-effective On-device Continual Learning over Memory Hierarchy with Miro. (arXiv:2308.06053v1 [cs.LG])

    [http://arxiv.org/abs/2308.06053](http://arxiv.org/abs/2308.06053)

    这项工作是首次探索基于层次内存回放的持续学习的设计空间，旨在在边缘设备上实现成本效益。提出了Miro，一个通过动态配置持续学习系统的新颖系统运行时，以实现最佳的成本效益。广泛的评估显示Miro明显优于其他方案。

    

    持续学习是从持续的任务流中逐步训练神经网络模型。为了记住先前学到的知识，之前的研究将旧样本存储在一个内存层次结构中，并在新任务到来时进行回放。采用持续学习以保护数据隐私的边缘设备通常对能源敏感，因此需要在不损害能源效率的情况下保持高模型准确度，即成本效益。我们的工作是首次探索基于层次内存回放的持续学习的设计空间，以获得在边缘设备上的成本效益。我们提出了Miro，一个新颖的系统运行时，通过使其能够根据资源状态动态配置持续学习系统，从而将我们的见解精确地整合到持续学习框架中，以实现最佳成本效益。为了实现这个目标，Miro还对带有明确准确度-能量平衡的参数进行在线分析，并以低开销地适应最佳值。广泛的评估显示Miro明显优于其他方案。

    Continual learning (CL) trains NN models incrementally from a continuous stream of tasks. To remember previously learned knowledge, prior studies store old samples over a memory hierarchy and replay them when new tasks arrive. Edge devices that adopt CL to preserve data privacy are typically energy-sensitive and thus require high model accuracy while not compromising energy efficiency, i.e., cost-effectiveness. Our work is the first to explore the design space of hierarchical memory replay-based CL to gain insights into achieving cost-effectiveness on edge devices. We present Miro, a novel system runtime that carefully integrates our insights into the CL framework by enabling it to dynamically configure the CL system based on resource states for the best cost-effectiveness. To reach this goal, Miro also performs online profiling on parameters with clear accuracy-energy trade-offs and adapts to optimal values with low overhead. Extensive evaluations show that Miro significantly outperfo
    
[^54]: 一体化音频：利用WavLM预训练模型进行基于语音驱动的手势合成

    Audio is all in one: speech-driven gesture synthetics using WavLM pre-trained model. (arXiv:2308.05995v1 [cs.SD])

    [http://arxiv.org/abs/2308.05995](http://arxiv.org/abs/2308.05995)

    本文介绍了一种利用WavLM预训练模型的基于语音驱动的手势合成方法，实现只使用原始语音音频生成个性化全身手势，消除了复杂的多模态处理和手动注释的需求。

    

    在虚拟人创作领域，生成与语音配套的手势是一个正在兴起的研究方向。先前的研究通过以声学和语义信息作为输入，采用分类方法来识别人物的ID和情感，以驱动与语音配套的手势生成。然而，这项工作仍然面临着重大挑战。这些挑战不仅涉及手势、语音声学和语义之间错综复杂的相互作用，还包括与个性、情感和其他不明确但重要的因素相关的复杂性。本文介绍了“diffmotion-v2”，这是一种基于语音条件扩散和基于非自回归Transformer的生成模型，采用WavLM预训练模型。它可以仅使用原始语音音频生成个性化的全身手势，消除了复杂的多模态处理和手动注释的需求。

    The generation of co-speech gestures for digital humans is an emerging area in the field of virtual human creation. Prior research has made progress by using acoustic and semantic information as input and adopting classify method to identify the person's ID and emotion for driving co-speech gesture generation. However, this endeavour still faces significant challenges. These challenges go beyond the intricate interplay between co-speech gestures, speech acoustic, and semantics; they also encompass the complexities associated with personality, emotion, and other obscure but important factors. This paper introduces "diffmotion-v2," a speech-conditional diffusion-based and non-autoregressive transformer-based generative model with WavLM pre-trained model. It can produce individual and stylized full-body co-speech gestures only using raw speech audio, eliminating the need for complex multimodal processing and manually annotated. Firstly, considering that speech audio not only contains acou
    
[^55]: 多领域推荐中的嵌入解耦与领域对齐

    Multi-domain Recommendation with Embedding Disentangling and Domain Alignment. (arXiv:2308.05508v1 [cs.IR])

    [http://arxiv.org/abs/2308.05508](http://arxiv.org/abs/2308.05508)

    该研究提出了一种新的多领域推荐方法EDDA，它通过嵌入解耦推荐器和领域对齐两个关键组件分别解决了知识解耦和跨领域知识转移的挑战。

    

    多领域推荐(MDR)旨在为具有重叠用户/物品的不同领域(例如产品类型)提供推荐，对于拥有多个服务的平台如亚马逊、Facebook和LinkedIn是常见的。现有的MDR模型面临两个挑战：首先，很难解耦可以泛化到所有领域的知识(例如，用户喜欢廉价的物品)与特定于单个领域的知识(例如，用户喜欢蓝色的服装但不喜欢蓝色的汽车)。其次，它们在具有小重叠的领域之间转移知识的能力有限。我们提出了一种名为EDDA的新的MDR方法，其中包含两个关键组成部分，即嵌入解耦推荐器和领域对齐，分别解决了这两个挑战。特别地，嵌入解耦推荐器分离了跨领域部分和单领域部分的模型和嵌入，而大多数现有的MDR方法只关注模型层面的解耦。领域对齐使用领域特定的对抗训练来提升不同领域之间的知识转移能力。

    Multi-domain recommendation (MDR) aims to provide recommendations for different domains (e.g., types of products) with overlapping users/items and is common for platforms such as Amazon, Facebook, and LinkedIn that host multiple services. Existing MDR models face two challenges: First, it is difficult to disentangle knowledge that generalizes across domains (e.g., a user likes cheap items) and knowledge specific to a single domain (e.g., a user likes blue clothing but not blue cars). Second, they have limited ability to transfer knowledge across domains with small overlaps. We propose a new MDR method named EDDA with two key components, i.e., embedding disentangling recommender and domain alignment, to tackle the two challenges respectively. In particular, the embedding disentangling recommender separates both the model and embedding for the inter-domain part and the intra-domain part, while most existing MDR methods only focus on model-level disentangling. The domain alignment leverag
    
[^56]: 超越语义：利用自我监督学习的行为增强相关模型的学习

    Beyond Semantics: Learning a Behavior Augmented Relevance Model with Self-supervised Learning. (arXiv:2308.05379v1 [cs.IR])

    [http://arxiv.org/abs/2308.05379](http://arxiv.org/abs/2308.05379)

    这篇论文提出了一种行为增强的相关模型，利用自我监督学习，通过从用户历史行为数据中提取辅助查询-项目交互，来改进搜索引擎中的查询-项目匹配，提高准确性和鲁棒性。

    

    相关建模旨在定位与对应查询相关的理想项目，这对于搜索引擎确保用户体验非常重要。虽然大多数传统方法通过评估查询与项目之间的语义相似性来解决这个问题，但纯语义匹配并不是唯一的方法。实际上，从用户搜索记录的历史行为数据中提取的辅助查询-项目交互可以提供进一步揭示用户搜索意图的线索。得益于此，我们设计了一种新颖的基于行为增强相关学习模型的支付宝搜索模型（BARL-ASe），该模型利用目标项目的相邻查询和目标查询的相邻项目来补充目标查询-项目的语义匹配。具体而言，我们的模型建立了多层共同注意力，从相邻和目标视图中提取了粗粒度和细粒度的语义表示。模型随后采用邻居-目标的自我监督学习来提高精度和鲁棒性。

    Relevance modeling aims to locate desirable items for corresponding queries, which is crucial for search engines to ensure user experience. Although most conventional approaches address this problem by assessing the semantic similarity between the query and item, pure semantic matching is not everything. In reality, auxiliary query-item interactions extracted from user historical behavior data of the search log could provide hints to reveal users' search intents further. Drawing inspiration from this, we devise a novel Behavior Augmented Relevance Learning model for Alipay Search (BARL-ASe) that leverages neighbor queries of target item and neighbor items of target query to complement target query-item semantic matching. Specifically, our model builds multi-level co-attention for distilling coarse-grained and fine-grained semantic representations from both neighbor and target views. The model subsequently employs neighbor-target self-supervised learning to improve the accuracy and robu
    
[^57]: LayoutLLM-T2I：从LLM中获取布局指导以用于文本到图像生成

    LayoutLLM-T2I: Eliciting Layout Guidance from LLM for Text-to-Image Generation. (arXiv:2308.05095v1 [cs.CV])

    [http://arxiv.org/abs/2308.05095](http://arxiv.org/abs/2308.05095)

    本论文提出了LayoutLLM-T2I的方法，用于从LLM中获取布局指导以用于文本到图像生成。该方法采用由粗到细的范例，通过基于大型语言模型的上下文学习，在给定文本提示的条件下合成与文本语义对齐的高保真度图像。

    

    在文本到图像生成领域，近期稳定扩散技术的显著进展使得生成各种新颖的逼真图像成为可能。然而，当前的模型在复杂自然场景中仍然面临着错位问题（例如，空间关系理解和数字化失败），这阻碍了高保真度的文本到图像生成。尽管最近已经进行了一些改进，通过提供细粒度的指导（例如，草图和涂鸦）来改善可控性，但是由于用户必须手动提供这些指导信息，因此这个问题尚未根本解决。在这项工作中，我们努力合成与给定文本提示语义对齐且不需要任何指导的高保真度图像。为了达到这个目标，我们提出了一个由粗到细的范例，用于布局规划和图像生成。具体而言，我们首先通过基于大型语言模型的上下文学习，在给定的文本提示条件下生成粗粒度的布局。

    In the text-to-image generation field, recent remarkable progress in Stable Diffusion makes it possible to generate rich kinds of novel photorealistic images. However, current models still face misalignment issues (e.g., problematic spatial relation understanding and numeration failure) in complex natural scenes, which impedes the high-faithfulness text-to-image generation. Although recent efforts have been made to improve controllability by giving fine-grained guidance (e.g., sketch and scribbles), this issue has not been fundamentally tackled since users have to provide such guidance information manually. In this work, we strive to synthesize high-fidelity images that are semantically aligned with a given textual prompt without any guidance. Toward this end, we propose a coarse-to-fine paradigm to achieve layout planning and image generation. Concretely, we first generate the coarse-grained layout conditioned on a given textual prompt via in-context learning based on Large Language M
    
[^58]: 软件定义网络中对抗性深度强化学习在网络安全中的应用

    Adversarial Deep Reinforcement Learning for Cyber Security in Software Defined Networks. (arXiv:2308.04909v1 [cs.CR])

    [http://arxiv.org/abs/2308.04909](http://arxiv.org/abs/2308.04909)

    本文研究了在软件定义网络中利用对抗性学习来训练更加鲁棒的深度强化学习智能体，探讨了两种算法的差异。攻击者利用因果攻击试图破坏学习过程。游戏中进行了有序的因果攻击。

    

    本文研究了在软件定义网络（Software Defined Networks，SDN）中，利用自主攻击方法在深度强化学习（Deep Reinforcement Learning，DRL）中训练更加鲁棒的智能体的影响，探讨了将对抗性学习应用于DRL的自主安全性。比较了两种算法：Double Deep Q-Networks（DDQN）和Neural Episodic Control to Deep Q-Network（NEC2DQN或N2D）。攻击者对环境具有完全的可见性，并且可以利用状态操作进行因果攻击，试图破坏学习过程。攻击实施在白盒环境中进行，攻击者可以访问防御者的模型和经验。进行了两轮游戏：第一轮游戏中，DDQN是防御者，N2D是攻击者；第二轮游戏中，角色互换。两轮游戏分别进行了两次，第一次没有主动的因果攻击，第二次进行了有序的因果攻击。

    This paper focuses on the impact of leveraging autonomous offensive approaches in Deep Reinforcement Learning (DRL) to train more robust agents by exploring the impact of applying adversarial learning to DRL for autonomous security in Software Defined Networks (SDN). Two algorithms, Double Deep Q-Networks (DDQN) and Neural Episodic Control to Deep Q-Network (NEC2DQN or N2D), are compared. NEC2DQN was proposed in 2018 and is a new member of the deep q-network (DQN) family of algorithms. The attacker has full observability of the environment and access to a causative attack that uses state manipulation in an attempt to poison the learning process. The implementation of the attack is done under a white-box setting, in which the attacker has access to the defender's model and experiences. Two games are played; in the first game, DDQN is a defender and N2D is an attacker, and in second game, the roles are reversed. The games are played twice; first, without an active causative attack and se
    
[^59]: NLLG季度arXiv报告 06/23：当前最具影响力的AI论文是什么？（arXiv:2308.04889v1 [cs.CY]）

    NLLG Quarterly arXiv Report 06/23: What are the most influential current AI Papers?. (arXiv:2308.04889v1 [cs.CY])

    [http://arxiv.org/abs/2308.04889](http://arxiv.org/abs/2308.04889)

    该报告关注当前最具影响力的AI论文，并以标准化引用计数为依据编制了40篇最受欢迎的论文列表。观察到在2023年上半年，大型语言模型（LLMs）和具体而言的ChatGPT相关的论文占主导地位，ChatGPT表现出下降的趋势。

    

    人工智能（AI）领域中的生成式人工智能（Generative Artificial Intelligence，特别是自然语言处理（Natural Language Processing，NLP）和机器学习（Machine Learning，ML））信息的快速增长给研究人员和从业者带来了巨大的挑战，使得他们难以跟上最新的发展。为了解决信息过载的问题，Bielefeld大学的自然语言学习组在本报告中专注于识别arXiv上最受欢迎的论文，特别关注NLP和ML。其目标是为最相关且被广泛讨论的研究提供快速指南，以帮助新来者和已有研究人员跟上当前趋势。具体而言，我们根据2023年上半年的标准化引用计数编制了一个由40篇最受欢迎的论文组成的列表。我们观察到在2023年上半年，与大型语言模型（Large Language Models，LLMs）和具体而言的ChatGPT相关的论文占主导地位，而ChatGPT显示出下降的趋势。

    The rapid growth of information in the field of Generative Artificial Intelligence (AI), particularly in the subfields of Natural Language Processing (NLP) and Machine Learning (ML), presents a significant challenge for researchers and practitioners to keep pace with the latest developments. To address the problem of information overload, this report by the Natural Language Learning Group at Bielefeld University focuses on identifying the most popular papers on arXiv, with a specific emphasis on NLP and ML. The objective is to offer a quick guide to the most relevant and widely discussed research, aiding both newcomers and established researchers in staying abreast of current trends. In particular, we compile a list of the 40 most popular papers based on normalized citation counts from the first half of 2023. We observe the dominance of papers related to Large Language Models (LLMs) and specifically ChatGPT during the first half of 2023, with the latter showing signs of declining popul
    
[^60]: 鸟瞰场景图用于视觉语言导航

    Bird's-Eye-View Scene Graph for Vision-Language Navigation. (arXiv:2308.04758v1 [cs.CV])

    [http://arxiv.org/abs/2308.04758](http://arxiv.org/abs/2308.04758)

    这项研究提出了一种鸟瞰场景图（BSG）用于视觉语言导航，通过使用多步鸟瞰表示来编码场景布局和几何线索，从而改进了当前全景观察的导航代理的能力，并提供了更准确的动作预测。

    

    视觉语言导航（VLN）需要一个代理根据人类指示在3D环境中导航，已经取得了显著的进展。然而，当前的代理基于全景观察构建，这限制了它们感知3D场景几何和容易导致全景视图的模糊选择能力。为了解决这些限制，我们提出了一种鸟瞰场景图（BSG），它利用多步鸟瞰表示来编码室内环境的场景布局和几何线索，在3D检测的监督下。在导航过程中，BSG在每个步骤构建一个本地鸟瞰表示，并维护一个基于鸟瞰的全局场景地图，根据它们的拓扑关系存储和组织所有在线收集的本地鸟瞰表示。基于BSG，代理预测本地鸟瞰网格级决策得分和全局图形级决策得分，结合全景视图的子视图选择得分，以实现更准确的动作预测。我们的方法

    Vision-language navigation (VLN), which entails an agent to navigate 3D environments following human instructions, has shown great advances. However, current agents are built upon panoramic observations, which hinders their ability to perceive 3D scene geometry and easily leads to ambiguous selection of panoramic view. To address these limitations, we present a BEV Scene Graph (BSG), which leverages multi-step BEV representations to encode scene layouts and geometric cues of indoor environment under the supervision of 3D detection. During navigation, BSG builds a local BEV representation at each step and maintains a BEV-based global scene map, which stores and organizes all the online collected local BEV representations according to their topological relations. Based on BSG, the agent predicts a local BEV grid-level decision score and a global graph-level decision score, combined with a sub-view selection score on panoramic views, for more accurate action prediction. Our approach signi
    
[^61]: Fine-Tuning Games: Bargaining and Adaptation for General-Purpose Models

    Fine-Tuning Games: Bargaining and Adaptation for General-Purpose Models. (arXiv:2308.04399v1 [cs.GT])

    [http://arxiv.org/abs/2308.04399](http://arxiv.org/abs/2308.04399)

    本文提出了一个模型，探讨了通用模型的微调过程中的利润分享问题，为一般类的成本和收入函数描述了解决方案的条件。

    

    机器学习（ML）和人工智能（AI）方面的重大进展越来越多地采用开发和发布通用模型的形式。这些模型旨在由其他企业和机构进行适应，以执行特定的领域专用功能。这个过程被称为适应或微调。本文提供了一个微调过程的模型，其中一位通用专家将技术产品（即ML模型）提升到一定的性能水平，并且一位或多位领域专家将其调整适用于特定领域。这两个实体都是追求利润的，当他们投资于技术时会产生成本，在技术进入市场前，他们必须就如何分享收入达成谈判协议。对于相对一般的成本和收入函数类，我们刻画了微调博弈产生利润分享解决方案的条件。我们观察到，任何潜在的领域专业化都会产生...

    Major advances in Machine Learning (ML) and Artificial Intelligence (AI) increasingly take the form of developing and releasing general-purpose models. These models are designed to be adapted by other businesses and agencies to perform a particular, domain-specific function. This process has become known as adaptation or fine-tuning. This paper offers a model of the fine-tuning process where a Generalist brings the technological product (here an ML model) to a certain level of performance, and one or more Domain-specialist(s) adapts it for use in a particular domain. Both entities are profit-seeking and incur costs when they invest in the technology, and they must reach a bargaining agreement on how to share the revenue for the technology to reach the market. For a relatively general class of cost and revenue functions, we characterize the conditions under which the fine-tuning game yields a profit-sharing solution. We observe that any potential domain-specialization will either contri
    
[^62]: 无法测量混淆因素下因果推断中的扩散模型

    Diffusion Model in Causal Inference with Unmeasured Confounders. (arXiv:2308.03669v1 [cs.LG])

    [http://arxiv.org/abs/2308.03669](http://arxiv.org/abs/2308.03669)

    本研究扩展了扩散模型的使用，提出了一种新的模型BDCM，可以在存在无法测量的混淆因素的情况下更准确地回答因果问题。

    

    我们研究了如何在无法测量的混淆因素存在的情况下，扩展扩散模型的使用，以从观测数据中回答因果问题。在Pearl的使用有向无环图（DAG）捕捉因果干预的框架中，提出了一种基于扩散模型的因果模型（DCM），可以更准确地回答因果问题，假设所有混淆因素都是可以观察到的。然而，实际中存在无法测量的混淆因素，这使得DCM无法应用。为了缓解DCM的这一局限性，我们提出了一个扩展模型，称为基于反门准则的DCM（BDCM），其思想根植于在DAG中找到要包括在扩散模型解码过程中的变量的反门准则，这样我们可以将DCM扩展到存在无法测量的混淆因素的情况。合成数据实验表明，我们提出的模型在无法测量混淆因素的情况下更精确地捕捉到了反事实分布。

    We study how to extend the use of the diffusion model to answer the causal question from the observational data under the existence of unmeasured confounders. In Pearl's framework of using a Directed Acyclic Graph (DAG) to capture the causal intervention, a Diffusion-based Causal Model (DCM) was proposed incorporating the diffusion model to answer the causal questions more accurately, assuming that all of the confounders are observed. However, unmeasured confounders in practice exist, which hinders DCM from being applicable. To alleviate this limitation of DCM, we propose an extended model called Backdoor Criterion based DCM (BDCM), whose idea is rooted in the Backdoor criterion to find the variables in DAG to be included in the decoding process of the diffusion model so that we can extend DCM to the case with unmeasured confounders. Synthetic data experiment demonstrates that our proposed model captures the counterfactual distribution more precisely than DCM under the unmeasured confo
    
[^63]: 分散式POMDP中基于在线聚类标签的离散消息传递

    Discrete Message via Online Clustering Labels in Decentralized POMDP. (arXiv:2308.03358v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.03358](http://arxiv.org/abs/2308.03358)

    本文通过建立回报差距上界，将多智能体通信问题转化为离散消息的在线聚类问题。该方法能够提供量化保证，并且具有通信开销低、可解释性好的特点。

    

    在部分可观察的马尔可夫决策过程中，通信对于解决合作多智能体强化学习任务至关重要。现有工作通常依赖于黑盒方法，将本地信息/特征编码成与其他智能体共享的消息。然而，这种黑盒方法无法对期望回报提供任何量化保证，常常导致生成通信开销高、可解释性差的连续消息。本文在理想策略与最优部分可观察策略之间建立了回报差距的上界。该结果使我们能够将多智能体通信重新定义为每个智能体的本地观察中的一种新颖的在线聚类问题，其中消息作为聚类标签，并且回报差距的上界作为聚类损失。通过最小化上界，我们提出了一个令人惊讶地简单的消息生成函数设计。

    Communication is crucial for solving cooperative Multi-Agent Reinforcement Learning tasks in Partially-Observable Markov Decision Processes. Existing works often rely on black-box methods to encode local information/features into messages shared with other agents. However, such black-box approaches are unable to provide any quantitative guarantees on the expected return and often lead to the generation of continuous messages with high communication overhead and poor interpretability. In this paper, we establish an upper bound on the return gap between an ideal policy with full observability and an optimal partially-observable policy with discrete communication. This result enables us to recast multi-agent communication into a novel online clustering problem over the local observations at each agent, with messages as cluster labels and the upper bound on the return gap as clustering loss. By minimizing the upper bound, we propose a surprisingly simple design of message generation functi
    
[^64]: 通过网络简化加速神经网络验证

    Expediting Neural Network Verification via Network Reduction. (arXiv:2308.03330v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2308.03330](http://arxiv.org/abs/2308.03330)

    本研究提出了一种网络简化技术，在验证之前对神经网络进行预处理，通过消除稳定的ReLU神经元，并将其转化为由ReLU和仿射层组成的顺序神经网络，从而显著减小了神经网络的规模并加速了现有的验证工具。

    

    已经提出了各种验证方法来验证深度神经网络的安全性，以确保网络在关键应用中正确运行。然而，许多众所周知的验证工具在复杂的网络架构和大型网络大小上仍然存在困难。在这项工作中，我们提出了一种网络简化技术作为验证之前的预处理方法。所提出的方法通过消除稳定的ReLU神经元，并将其转化为由ReLU和仿射层组成的顺序神经网络，从而可以通过大多数验证工具处理。我们在最先进的完整和不完整验证工具上实现了简化技术，包括alpha-beta-crown，VeriNet和PRIMA。我们在大量基准测试中的实验表明，所提出的技术可以显著减小神经网络并加速现有的验证工具。此外，实验结果还表明...

    A wide range of verification methods have been proposed to verify the safety properties of deep neural networks ensuring that the networks function correctly in critical applications. However, many well-known verification tools still struggle with complicated network architectures and large network sizes. In this work, we propose a network reduction technique as a pre-processing method prior to verification. The proposed method reduces neural networks via eliminating stable ReLU neurons, and transforming them into a sequential neural network consisting of ReLU and Affine layers which can be handled by the most verification tools. We instantiate the reduction technique on the state-of-the-art complete and incomplete verification tools, including alpha-beta-crown, VeriNet and PRIMA. Our experiments on a large set of benchmarks indicate that the proposed technique can significantly reduce neural networks and speed up existing verification tools. Furthermore, the experiment results also sh
    
[^65]: 无源域自适应的人体姿势估计

    Source-free Domain Adaptive Human Pose Estimation. (arXiv:2308.03202v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2308.03202](http://arxiv.org/abs/2308.03202)

    提出了无源域自适应的人体姿势估计任务，旨在解决在适应过程中无法访问源数据的跨域学习挑战。通过提出的新框架，源保护模块更有效地保留源信息并抵抗噪声。

    

    人体姿势估计广泛应用于运动分析、医疗保健和虚拟现实等领域。然而，标注实际场景的数据集的巨大开销对姿势估计构成了重要挑战。为了解决这个问题，一种方法是在合成数据集上训练姿势估计模型，然后在真实世界数据上进行域自适应(DA)。然而，现有的HPE的DA方法在适应过程中忽略了数据隐私和安全问题，因为使用了源数据和目标数据。为此，我们提出了一种新的任务，名为无源域自适应的HPE，旨在解决在适应过程中无法访问源数据的HPE的跨域学习挑战。我们进一步提出了一个由三个模型组成的新框架：源模型、中间模型和目标模型，从源数据和目标数据的角度探索该任务。源保护模块更有效地保留源信息并抵抗噪声。

    Human Pose Estimation (HPE) is widely used in various fields, including motion analysis, healthcare, and virtual reality. However, the great expenses of labeled real-world datasets present a significant challenge for HPE. To overcome this, one approach is to train HPE models on synthetic datasets and then perform domain adaptation (DA) on real-world data. Unfortunately, existing DA methods for HPE neglect data privacy and security by using both source and target data in the adaptation process. To this end, we propose a new task, named source-free domain adaptive HPE, which aims to address the challenges of cross-domain learning of HPE without access to source data during the adaptation process. We further propose a novel framework that consists of three models: source model, intermediate model, and target model, which explores the task from both source-protect and target-relevant perspectives. The source-protect module preserves source information more effectively while resisting noise
    
[^66]: 用正则化高阶总变差的随机优化方法训练非线性神经网络

    A stochastic optimization approach to train non-linear neural networks with regularization of higher-order total variation. (arXiv:2308.02293v1 [stat.ME])

    [http://arxiv.org/abs/2308.02293](http://arxiv.org/abs/2308.02293)

    通过引入高阶总变差正则化的随机优化算法，可以高效地训练非线性神经网络，避免过拟合问题。

    

    尽管包括深度神经网络在内的高度表达的参数模型可以更好地建模复杂概念，但训练这种高度非线性模型已知会导致严重的过拟合风险。针对这个问题，本研究考虑了一种k阶总变差（k-TV）正则化，它被定义为要训练的参数模型的k阶导数的平方积分，通过惩罚k-TV来产生一个更平滑的函数，从而避免过拟合。尽管将k-TV项应用于一般的参数模型由于积分而导致计算复杂，本研究提供了一种随机优化算法，可以高效地训练带有k-TV正则化的一般模型，而无需进行显式的数值积分。这种方法可以应用于结构任意的深度神经网络的训练，因为它只需要进行简单的随机梯度优化即可实现。

    While highly expressive parametric models including deep neural networks have an advantage to model complicated concepts, training such highly non-linear models is known to yield a high risk of notorious overfitting. To address this issue, this study considers a $k$th order total variation ($k$-TV) regularization, which is defined as the squared integral of the $k$th order derivative of the parametric models to be trained; penalizing the $k$-TV is expected to yield a smoother function, which is expected to avoid overfitting. While the $k$-TV terms applied to general parametric models are computationally intractable due to the integration, this study provides a stochastic optimization algorithm, that can efficiently train general models with the $k$-TV regularization without conducting explicit numerical integration. The proposed approach can be applied to the training of even deep neural networks whose structure is arbitrary, as it can be implemented by only a simple stochastic gradien
    
[^67]: ClassEval: 一种手工构建的用于评估LLMs在类级代码生成上的基准

    ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on Class-level Code Generation. (arXiv:2308.01861v1 [cs.CL])

    [http://arxiv.org/abs/2308.01861](http://arxiv.org/abs/2308.01861)

    ClassEval是一种手工构建的类级代码生成基准，该研究首次尝试在这一更具挑战性的场景中评估LLMs，并发现现有LLMs在类级代码生成上的性能相对较差。GPT-4和GPT-3.5在类级代码生成方面表现出相对其他LLMs更卓越的优势。

    

    在这项工作中，我们首次尝试在更具挑战性的代码生成场景中评估LLMs，即类级代码生成。我们首先手动构建了第一个类级代码生成基准ClassEval，其中包含100个类级Python代码生成任务，总共耗时约500人小时。在此基础上，我们对11个最先进的LLMs在类级代码生成上进行了第一次研究。根据我们的结果，我们得出以下主要发现。首先，我们发现所有现有的LLMs在类级代码生成上的性能要远低于独立的方法级代码生成基准（如HumanEval）；而方法级的编码能力不能等同地反映LLMs在类级编码能力上的表现。其次，我们发现GPT-4和GPT-3.5在类级代码生成上仍然表现出相对其他LLMs更卓越的优势，而二线模型包括Instruct-Starcoder，Instruct-Codegen和Wizardcoder在性能上非常相似。

    In this work, we make the first attempt to evaluate LLMs in a more challenging code generation scenario, i.e. class-level code generation. We first manually construct the first class-level code generation benchmark ClassEval of 100 class-level Python code generation tasks with approximately 500 person-hours. Based on it, we then perform the first study of 11 state-of-the-art LLMs on class-level code generation. Based on our results, we have the following main findings. First, we find that all existing LLMs show much worse performance on class-level code generation compared to on standalone method-level code generation benchmarks like HumanEval; and the method-level coding ability cannot equivalently reflect the class-level coding ability among LLMs. Second, we find that GPT-4 and GPT-3.5 still exhibit dominate superior than other LLMs on class-level code generation, and the second-tier models includes Instruct-Starcoder, Instruct-Codegen, and Wizardcoder with very similar performance. 
    
[^68]: 基于几何一致性和语义感知对齐的LiDAR-相机全景分割

    LiDAR-Camera Panoptic Segmentation via Geometry-Consistent and Semantic-Aware Alignment. (arXiv:2308.01686v1 [cs.CV])

    [http://arxiv.org/abs/2308.01686](http://arxiv.org/abs/2308.01686)

    本文提出了LCPS，第一个LiDAR-相机全景分割网络，通过异步补偿像素对齐、语义感知区域对齐和点到体素特征传播的融合策略，显著提高了全景分割的性能。

    

    3D全景分割是一个具有挑战性的感知任务，需要同时进行语义分割和实例分割。在这个任务中，我们注意到图像可以提供丰富的纹理、颜色和辨别信息，可以为LiDAR数据提供明显的性能改进，但它们的融合仍然是一个具有挑战性的问题。为此，我们提出了LCPS，第一个LiDAR-相机全景分割网络。在我们的方法中，我们将LiDAR-相机融合分为三个阶段：1）一个异步补偿像素对齐（ACPA）模块，校正传感器之间异步问题导致的坐标错位；2）一个语义感知区域对齐（SARA）模块，将一对一的点-像素映射扩展到一对多的语义关系；3）一个点到体素特征传播（PVP）模块，整合几何和语义融合信息对整个点云进行处理。我们的融合策略相对于仅使用LiDAR的方法，性能提升了约6.9%的PQ。

    3D panoptic segmentation is a challenging perception task that requires both semantic segmentation and instance segmentation. In this task, we notice that images could provide rich texture, color, and discriminative information, which can complement LiDAR data for evident performance improvement, but their fusion remains a challenging problem. To this end, we propose LCPS, the first LiDAR-Camera Panoptic Segmentation network. In our approach, we conduct LiDAR-Camera fusion in three stages: 1) an Asynchronous Compensation Pixel Alignment (ACPA) module that calibrates the coordinate misalignment caused by asynchronous problems between sensors; 2) a Semantic-Aware Region Alignment (SARA) module that extends the one-to-one point-pixel mapping to one-to-many semantic relations; 3) a Point-to-Voxel feature Propagation (PVP) module that integrates both geometric and semantic fusion information for the entire point cloud. Our fusion strategy improves about 6.9% PQ performance over the LiDAR-on
    
[^69]: 能否转移噪声模式？使用生成案例的多环境频谱分析模型

    Can We Transfer Noise Patterns? An Multi-environment Spectrum Analysis Model Using Generated Cases. (arXiv:2308.01138v1 [cs.LG])

    [http://arxiv.org/abs/2308.01138](http://arxiv.org/abs/2308.01138)

    这项研究提出了一个噪声模式转移模型，可以将噪声模式从不同环境的标准样本应用到未知样本，通过生成案例库来解决样本级噪声对数据集级噪声学习的干扰，提高了系统的学习性能。

    

    在在线水质检测中，频谱分析系统旨在检测污染物的类型和浓度，并使监管机构能够及时回应污染事件。然而，基于频谱数据的测试设备在非实验室环境中部署时会受到复杂的噪声模式的影响。为了使分析模型适用于更多的环境，我们提出了一个噪声模式转移模型，该模型将不同环境中标准水样品的频谱作为案例，并学习它们噪声模式的差异，从而使噪声模式能够应用于未知样品。不幸的是，必然存在的样本级基线噪声使得模型无法获取只在数据集级环境噪声上有差异的配对数据。为了解决这个问题，我们生成了一个样本对样本的案例库，排除了样本级噪声对数据集级噪声学习的干扰，提高了系统的学习性能。

    Spectrum analysis systems in online water quality testing are designed to detect types and concentrations of pollutants and enable regulatory agencies to respond promptly to pollution incidents. However, spectral data-based testing devices suffer from complex noise patterns when deployed in non-laboratory environments. To make the analysis model applicable to more environments, we propose a noise patterns transferring model, which takes the spectrum of standard water samples in different environments as cases and learns the differences in their noise patterns, thus enabling noise patterns to transfer to unknown samples. Unfortunately, the inevitable sample-level baseline noise makes the model unable to obtain the paired data that only differ in dataset-level environmental noise. To address the problem, we generate a sample-to-sample case-base to exclude the interference of sample-level noise on dataset-level noise learning, enhancing the system's learning performance. Experiments on sp
    
[^70]: 对自动驾驶车辆风险评估的反事实安全边界视角

    A Counterfactual Safety Margin Perspective on the Scoring of Autonomous Vehicles' Riskiness. (arXiv:2308.01050v1 [cs.RO])

    [http://arxiv.org/abs/2308.01050](http://arxiv.org/abs/2308.01050)

    本文基于反事实模拟提出了一个数据驱动的框架，用于比较不同自动驾驶车辆在不同操作设计领域中行为风险。通过引入反事实安全边界的概念，该框架可以找到最关键的情景，并评估自动驾驶车辆的风险频率和严重程度。该方法即使在自动驾驶车辆的行为策略未知的情况下也适用，对外部第三方风险评估机构有用。

    

    自动驾驶车辆（AVs）有潜力提供诸多社会效益，如减少道路事故和提高交通效率。然而，由于缺乏历史数据和技术的快速发展，量化AVs的风险是具有挑战性的。本文提出了一个基于数据驱动的框架，用于比较不同AVs在各种操作设计领域（ODDs）中行为的风险，该框架基于对“不良”道路用户进行反事实模拟。我们引入了反事实安全边界的概念，表示可能导致碰撞的最小偏离正常行为的量。该概念有助于找到最关键的情景，同时也有助于评估AVs的风险频率和严重程度。我们证明，即使AV的行为策略是未知的，提出的方法仍然适用于最坏和最佳情况分析，使该方法对外部第三方风险评估机构也有用。

    Autonomous Vehicles (AVs) have the potential to provide numerous societal benefits, such as decreased road accidents and increased overall transportation efficiency. However, quantifying the risk associated with AVs is challenging due to the lack of historical data and the rapidly evolving technology. This paper presents a data-driven framework for comparing the risk of different AVs' behaviors in various operational design domains (ODDs), based on counterfactual simulations of "misbehaving" road users. We introduce the concept of counterfactual safety margin, which represents the minimum deviation from normal behavior that could lead to a collision. This concept helps to find the most critical scenarios but also to assess the frequency and severity of risk of AVs. We show that the proposed methodology is applicable even when the AV's behavioral policy is unknown -- through worst- and best-case analyses -- making the method useful also to external third-party risk assessors. Our experi
    
[^71]: FusionAD: 自动驾驶预测和规划任务的多模态融合

    FusionAD: Multi-modality Fusion for Prediction and Planning Tasks of Autonomous Driving. (arXiv:2308.01006v1 [cs.CV])

    [http://arxiv.org/abs/2308.01006](http://arxiv.org/abs/2308.01006)

    FusionAD是第一个将来自相机和激光雷达的信息融合起来用于自动驾驶预测和规划任务的统一框架，在常用数据集上的实验中达到了最先进的性能。

    

    在自动驾驶感知任务中，构建一个多模态多任务神经网络以实现准确和稳健的性能已成为铁板一块的标准。然而，利用来自多个传感器的数据来联合优化预测和规划任务仍然几乎未被探索。本文提出了FusionAD，据我们所知，这是第一个将来自两个最关键传感器相机和激光雷达的信息融合起来超越感知任务的统一框架。具体来说，我们首先构建了一个基于转换器的多模态融合网络，以有效地产生基于融合的特征。然后，与基于相机的端到端方法UniAD相比，我们建立了一个融合辅助的模态感知预测和状态感知规划模块，称为FMSPnP，充分利用多模态特征的优势。我们在常用的nuScenes数据集上进行了大量实验，结果表明我们的FusionAD达到了最先进的性能，并优于基准线平均15%的性能。

    Building a multi-modality multi-task neural network toward accurate and robust performance is a de-facto standard in perception task of autonomous driving. However, leveraging such data from multiple sensors to jointly optimize the prediction and planning tasks remains largely unexplored. In this paper, we present FusionAD, to the best of our knowledge, the first unified framework that fuse the information from two most critical sensors, camera and LiDAR, goes beyond perception task. Concretely, we first build a transformer based multi-modality fusion network to effectively produce fusion based features. In constrast to camera-based end-to-end method UniAD, we then establish a fusion aided modality-aware prediction and status-aware planning modules, dubbed FMSPnP that take advantages of multi-modality features. We conduct extensive experiments on commonly used benchmark nuScenes dataset, our FusionAD achieves state-of-the-art performance and surpassing baselines on average 15% on perce
    
[^72]: 对API方面分析的对比学习

    Contrastive Learning for API Aspect Analysis. (arXiv:2307.16878v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2307.16878](http://arxiv.org/abs/2307.16878)

    这项研究提出了一种对API方面分析进行对比学习的方法，通过训练变换器模型并使用监督对比损失函数，可以显著改进性能，对Performance、Security、Usability和Documentation等方面的检测效果进行了评估，并进行了实证和开发者研究验证。

    

    我们提出了一种新颖的方法- CLAA-用于API评论中的API方面检测，该方法利用了训练有监督对比损失目标函数的变换器模型。我们通过性能和影响分析评估了CLAA。对于性能分析，我们使用了从Stack Overflow收集的开发者讨论的基准数据集，并将结果与使用最先进的变换器模型获得的结果进行了比较。实验证明，对比学习可以显著提高变换器模型在检测性能、安全性、可用性和文档方面等方面的性能。对于影响分析，我们进行了实证和开发者研究。在随机选择的并人工标记的200个在线评论上，CLAA达到了92%的准确率，而最先进的基线方法只有81.5%。根据我们对10名参与者进行的开发者研究，使用“Stack Overflow + CLAA”在API选择过程中可以提高准确性和信心。复制程序包：

    We present a novel approach - CLAA - for API aspect detection in API reviews that utilizes transformer models trained with a supervised contrastive loss objective function. We evaluate CLAA using performance and impact analysis. For performance analysis, we utilized a benchmark dataset on developer discussions collected from Stack Overflow and compare the results to those obtained using state-of-the-art transformer models. Our experiments show that contrastive learning can significantly improve the performance of transformer models in detecting aspects such as Performance, Security, Usability, and Documentation. For impact analysis, we performed empirical and developer study. On a randomly selected and manually labeled 200 online reviews, CLAA achieved 92% accuracy while the SOTA baseline achieved 81.5%. According to our developer study involving 10 participants, the use of 'Stack Overflow + CLAA' resulted in increased accuracy and confidence during API selection. Replication package: 
    
[^73]: 关于在解决命题可满足性问题的Hopfield网络中使用关联记忆的研究

    On the use of associative memory in Hopfield networks designed to solve propositional satisfiability problems. (arXiv:2307.16807v2 [nlin.AO] UPDATED)

    [http://arxiv.org/abs/2307.16807](http://arxiv.org/abs/2307.16807)

    该论文研究了在解决命题可满足性问题的Hopfield网络中使用关联记忆的方法。通过自我优化模型，网络可以解决具体的组合问题。然而，研究还发现在某些情况下，关键信息可能会永久丢失，导致网络产生看似最优但实际上不适用的解决方案。这一发现对理解网络解决难以处理问题的过程很有启发。

    

    Hopfield网络由于提供了一种生物学上可行的机制，因此在解决许多类型的计算问题时是一个有吸引力的选择。自我优化（SO）模型通过使用基于生物学原理的赫布学习规则和重复的网络重置到任意初始状态，来优化网络行为以达到网络中编码的某个希望的目标状态。为了更好地理解该过程，我们首先证明了SO模型可以通过使用Liars问题和地图着色问题的两个例子来解决具体的组合问题。此外，我们展示了在某些条件下关键信息可能永远丢失，从而使得学习网络产生看似最优解但实际上对所要解决的问题不合适。这种SO模型的副作用看似不好，却可以对其解决难以处理的问题的过程提供洞察力。

    Hopfield networks are an attractive choice for solving many types of computational problems because they provide a biologically plausible mechanism. The Self-Optimization (SO) model adds to the Hopfield network by using a biologically founded Hebbian learning rule, in combination with repeated network resets to arbitrary initial states, for optimizing its own behavior towards some desirable goal state encoded in the network. In order to better understand that process, we demonstrate first that the SO model can solve concrete combinatorial problems in SAT form, using two examples of the Liars problem and the map coloring problem. In addition, we show how under some conditions critical information might get lost forever with the learned network producing seemingly optimal solutions that are in fact inappropriate for the problem it was tasked to solve. What appears to be an undesirable side-effect of the SO model, can provide insight into its process for solving intractable problems.
    
[^74]: 关于最先进生成模型的可信度景观：一项综合调查

    On the Trustworthiness Landscape of State-of-the-art Generative Models: A Comprehensive Survey. (arXiv:2307.16680v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.16680](http://arxiv.org/abs/2307.16680)

    本文综合调查了大规模生成模型的可信度问题，涵盖了隐私、安全、公平性和责任等多个维度，并提出了实际建议和未来发展方向。

    

    扩散模型和大规模语言模型已经成为领先的生成模型，并对人类生活的各个方面产生了革命性的影响。然而，这些模型的实际应用也暴露出固有的风险，突显了它们的双重性质，并引发了对它们可信度的担忧。尽管有大量关于这个主题的文献，但针对大规模生成模型及其可信度的综合调查仍然很少见。为了弥补这一空白，本文调查了涉及这些模型的长期和新兴威胁，涵盖了隐私、安全、公平和责任这四个基本维度。通过这种方式，我们构建了一张详尽的地图，概述了这些模型的可信度，并提供了实际建议和未来的发展方向。这些努力对于促进这些模型的可信度部署至关重要。

    Diffusion models and large language models have emerged as leading-edge generative models and have sparked a revolutionary impact on various aspects of human life. However, the practical implementation of these models has also exposed inherent risks, highlighting their dual nature and raising concerns regarding their trustworthiness. Despite the abundance of literature on this subject, a comprehensive survey specifically delving into the intersection of large-scale generative models and their trustworthiness remains largely absent. To bridge this gap, This paper investigates both the long-standing and emerging threats associated with these models across four fundamental dimensions: privacy, security, fairness, and responsibility. In this way, we construct an extensive map outlining the trustworthiness of these models, while also providing practical recommendations and identifying future directions. These efforts are crucial for promoting the trustworthy deployment of these models, ulti
    
[^75]: Relation-Oriented: 迈向与知识对准的因果人工智能

    Relation-Oriented: Toward Knowledge-Aligned Causal AI. (arXiv:2307.16387v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2307.16387](http://arxiv.org/abs/2307.16387)

    本研究从创新的关系导向视角出发，探讨了当前的建模范式中的观察模型与实际理解的不对齐问题，并提出了关系定义的表示学习方法作为实现关系导向建模的实践方法。

    

    在机器学习中，我们自然地应用一个观察导向的原则，其中观察变量先存在并为构建关系奠定基础。虽然对于传统模型来说足够了，但是人工智能与大数据的整合暴露了观察模型与我们的实际理解之间的不对齐。相反，人类塑造了由关系定义的认知实体，使我们能够跨越时间和超维度空间制定知识，而不是被限制在观察构建中。从一种创新的关系导向的视角出发，本研究通过来自计算机视觉和健康信息学的直观例子，分析了在我们当前的建模范式中这种不对齐的根源。我们还介绍了关系定义的表示学习方法作为关系导向建模的一种实际实施，支持广泛的实验验证。

    In machine learning, we naturally apply an Observation-Oriented principle, in which observational variables preexist and set the stage for constructing relationships. While sufficient for traditional models, the integration of AI with big data exposes the misalignment between the observational models and our actual comprehension. Contrarily, humans shape cognitive entities defined by relationships, enabling us to formulate knowledge across temporal and hyper-dimensional spaces, rather than being confined to observational constructs. From an innovative Relation-Oriented perspective, this study examines the roots of this misalignment within our current modeling paradigm, illuminated by intuitive examples from computer vision and health informatics. We also introduce the relation-defined representation learning methodology as a practical implementation of Relation-Oriented modeling, supported by extensive experimental validation.
    
[^76]: AlignDet: 对齐目标检测的预训练与微调

    AlignDet: Aligning Pre-training and Fine-tuning in Object Detection. (arXiv:2307.11077v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2307.11077](http://arxiv.org/abs/2307.11077)

    本文提出了一个统一的预训练框架AlignDet，通过将预训练过程分解为图像域和框域预训练，可以减轻目标检测中现有实践中的数据、模型和任务差异，提高检测器性能和泛化能力。

    

    大规模预训练后进行微调的范式在各种目标检测算法中被广泛应用。本文揭示了现有实践中预训练和微调过程之间的数据、模型和任务差异，这些差异隐含地限制了检测器的性能、泛化能力和收敛速度。为此，我们提出了AlignDet，一个统一的预训练框架，可适用于各种现有检测器，以减轻这些差异。AlignDet将预训练过程分解为两个阶段，即图像域和框域预训练。图像域预训练优化检测主干以捕捉整体视觉抽象，而框域预训练学习实例级语义和任务感知概念以初始化主干之外的部分。通过融入自监督预训练的主干，我们可以对各种检测器的所有模块进行无监督预训练。

    The paradigm of large-scale pre-training followed by downstream fine-tuning has been widely employed in various object detection algorithms. In this paper, we reveal discrepancies in data, model, and task between the pre-training and fine-tuning procedure in existing practices, which implicitly limit the detector's performance, generalization ability, and convergence speed. To this end, we propose AlignDet, a unified pre-training framework that can be adapted to various existing detectors to alleviate the discrepancies. AlignDet decouples the pre-training process into two stages, i.e., image-domain and box-domain pre-training. The image-domain pre-training optimizes the detection backbone to capture holistic visual abstraction, and box-domain pre-training learns instance-level semantics and task-aware concepts to initialize the parts out of the backbone. By incorporating the self-supervised pre-trained backbones, we can pre-train all modules for various detectors in an unsupervised par
    
[^77]: 由生成闭环人工智能引领的基础科学的未来

    The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence. (arXiv:2307.07522v1 [cs.AI])

    [http://arxiv.org/abs/2307.07522](http://arxiv.org/abs/2307.07522)

    生成型人工智能和大型语言模型可能为基础科学的发现提供机会，通过其自主生成假设和探索假设空间的闭环方法，加速科学发现的进程。

    

    机器学习和人工智能的最新进展，包括生成型人工智能和大型语言模型，正在颠覆技术创新、产品开发和整个社会。人工智能对技术的贡献可以通过多种途径实现，需要大量训练数据集和明确的性能评估标准，范围从模式识别和分类到生成模型。然而，由于科学实践和模型发现需要访问高质量的大型数据集，人工智能对基础科学的贡献较少。生成型人工智能，特别是大型语言模型，可能代表了通过定量模型增强和加速基础深度科学的科学发现的机会。在这里，我们探索和研究了一种由人工智能驱动、自动化的闭环科学发现方法的各个方面，包括自主生成假设和开放式自主探索假设空间。

    Recent advances in machine learning and AI, including Generative AI and LLMs, are disrupting technological innovation, product development, and society as a whole. AI's contribution to technology can come from multiple approaches that require access to large training data sets and clear performance evaluation criteria, ranging from pattern recognition and classification to generative models. Yet, AI has contributed less to fundamental science in part because large data sets of high-quality data for scientific practice and model discovery are more difficult to access. Generative AI, in general, and Large Language Models in particular, may represent an opportunity to augment and accelerate the scientific discovery of fundamental deep science with quantitative models. Here we explore and investigate aspects of an AI-driven, automated, closed-loop approach to scientific discovery, including self-driven hypothesis generation and open-ended autonomous exploration of the hypothesis space. Int
    
[^78]: VesselMorph: 基于形状感知表征的领域通用的视网膜血管分割方法

    VesselMorph: Domain-Generalized Retinal Vessel Segmentation via Shape-Aware Representation. (arXiv:2307.00240v1 [cs.CV])

    [http://arxiv.org/abs/2307.00240](http://arxiv.org/abs/2307.00240)

    VesselMorph使用一个基于形状感知的表征方法，通过合成血管的形态学特征来推广视网膜血管分割任务，以提高深度模型的通用性。

    

    由于缺乏统一的成像协议，来自不同站点的数据之间的领域转移是医学图像的固有属性，已经成为学习算法大规模应用的主要障碍。对于视网膜血管图像，领域转移通常表现为强度、对比度和分辨率的变化，而血管的基本管状形状保持不变。因此，利用这种领域不变的形态学特征可以大大提高深度模型的通用性。在本研究中，我们提出了一种名为VesselMorph的方法，通过合成形状感知表征来推广2D视网膜血管分割任务。受传统Frangi滤波器和扩散张量成像文献的启发，我们引入了一种基于Hessian的双极张量场来描述血管的形态学特征，从而考虑到形状信息。我们将强度图像和张量场映射到潜在空间中。

    Due to the absence of a single standardized imaging protocol, domain shift between data acquired from different sites is an inherent property of medical images and has become a major obstacle for large-scale deployment of learning-based algorithms. For retinal vessel images, domain shift usually presents as the variation of intensity, contrast and resolution, while the basic tubular shape of vessels remains unaffected. Thus, taking advantage of such domain-invariant morphological features can greatly improve the generalizability of deep models. In this study, we propose a method named VesselMorph which generalizes the 2D retinal vessel segmentation task by synthesizing a shape-aware representation. Inspired by the traditional Frangi filter and the diffusion tensor imaging literature, we introduce a Hessian-based bipolar tensor field to depict the morphology of the vessels so that the shape information is taken into account. We map the intensity image and the tensor field to a latent sp
    
[^79]: 增强属性聚类的图形变换方法：一种创新的图形转换器方法

    Transforming Graphs for Enhanced Attribute-Based Clustering: An Innovative Graph Transformer Method. (arXiv:2306.11307v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.11307](http://arxiv.org/abs/2306.11307)

    本文提出了一种称为GTAGC的图形自编码器图形变换自编码器方法，通过融合图自编码器和图形变换器，GTAGC能够捕获全局依赖关系，从而有助于提高图聚类的性能。

    

    图表示学习是一种有影响力的方法，它使得我们更深入地理解图结构化数据，并有助于图聚类，这是各个领域的一个关键任务。注意力机制最近已经进入了图学习的领域，这从根本上改变了研究趋势。因此，图注意力网络和图注意力自编码器已成为图聚类任务优选的工具。然而，这些方法主要采用局部注意机制，从而限制了它们理解图中节点之间复杂全局依赖性的能力。为了解决这些障碍，本研究介绍了一种称为图自编码器的图形变换自编码器的图形聚类（GTAGC）的创新方法。通过将图自编码器与图形变换器融合，GTAGC能够捕获节点之间的全局依赖关系。这种融合提高了性能，使得图形聚类任务有了显着的提升。

    Graph Representation Learning (GRL) is an influential methodology, enabling a more profound understanding of graph-structured data and aiding graph clustering, a critical task across various domains. The recent incursion of attention mechanisms, originally an artifact of Natural Language Processing (NLP), into the realm of graph learning has spearheaded a notable shift in research trends. Consequently, Graph Attention Networks (GATs) and Graph Attention Auto-Encoders have emerged as preferred tools for graph clustering tasks. Yet, these methods primarily employ a local attention mechanism, thereby curbing their capacity to apprehend the intricate global dependencies between nodes within graphs. Addressing these impediments, this study introduces an innovative method known as the Graph Transformer Auto-Encoder for Graph Clustering (GTAGC). By melding the Graph Auto-Encoder with the Graph Transformer, GTAGC is adept at capturing global dependencies between nodes. This integration amplifi
    
[^80]: 研究：社交感知时间松散解码器推荐系统

    STUDY: Socially Aware Temporally Casual Decoder Recommender Systems. (arXiv:2306.07946v1 [cs.SI])

    [http://arxiv.org/abs/2306.07946](http://arxiv.org/abs/2306.07946)

    该论文提出了一种基于社交感知和时间因素的解码器推荐系统(STUDY)，使用transformer解码器网络实现对社交网络图中相邻的用户组的联合推断。该方法在教育内容领域中经过测试，能够取得优于社交和顺序方法的结果。

    

    随着现在在线和离线可获取的数据数量过于庞大，推荐系统变得越来越必要，以帮助用户找到符合他们兴趣的物品。当社交网络信息存在时，有一些方法利用这些信息来做出更好的推荐，但这些方法通常有复杂的结构和训练过程。此外，许多现有的方法使用图神经网络，而这些网络训练起来非常困难。为了解决这个问题，我们提出了基于社交感知和时间因素的解码器推荐系统(STUDY)。STUDY采用一个经过修改的transformer解码器网络的单向前传，对社交网络图中相邻的用户组进行联合推断。我们在基于学校课堂结构定义社交网络的教育内容领域测试了我们的方法。我们的方法在保持单一均匀网络设计简单性的同时，优于社交和顺序方法。

    With the overwhelming amount of data available both on and offline today, recommender systems have become much needed to help users find items tailored to their interests. When social network information exists there are methods that utilize this information to make better recommendations, however the methods are often clunky with complex architectures and training procedures. Furthermore many of the existing methods utilize graph neural networks which are notoriously difficult to train. To address this, we propose Socially-aware Temporally caUsal Decoder recommender sYstems (STUDY). STUDY does joint inference over groups of users who are adjacent in the social network graph using a single forward pass of a modified transformer decoder network. We test our method in a school-based educational content setting, using classroom structure to define social networks. Our method outperforms both social and sequential methods while maintaining the design simplicity of a single homogeneous netw
    
[^81]: MADiff：离线多智能体学习与扩散模型

    MADiff: Offline Multi-agent Learning with Diffusion Models. (arXiv:2305.17330v1 [cs.AI])

    [http://arxiv.org/abs/2305.17330](http://arxiv.org/abs/2305.17330)

    本论文提出了基于注意力的扩散模型MADiff，解决了多智能体问题，是第一个扩散模型应用于多智能体离线RL的框架。

    

    扩散模型（DM）是一种强大的生成模型，最近在包括离线强化学习在内的各种场景中取得了巨大成功，其中策略通过在在线评估中产生轨迹来进行规划学习。然而，尽管单智能体学习显示了其有效性，但仍不清楚DM如何在多智能体问题中操作，其中代理商很难在独立建模每个代理商轨迹的情况下完成团队合作。在本文中，我们提出MADiff，一种新的生成式多智能体学习框架，以解决这个问题。MADiff是通过基于注意力的扩散模型来实现对多个扩散智能体行为的复杂协调建模。据我们所知，MADiff是第一个基于扩散的多智能体离线RL框架，它既可以行为为分散的政策，又可以为集中控制器，其中包括对手建模，并可用于多智能体轨迹预测。

    Diffusion model (DM), as a powerful generative model, recently achieved huge success in various scenarios including offline reinforcement learning, where the policy learns to conduct planning by generating trajectory in the online evaluation. However, despite the effectiveness shown for single-agent learning, it remains unclear how DMs can operate in multi-agent problems, where agents can hardly complete teamwork without good coordination by independently modeling each agent's trajectories. In this paper, we propose MADiff, a novel generative multi-agent learning framework to tackle this problem. MADiff is realized with an attention-based diffusion model to model the complex coordination among behaviors of multiple diffusion agents. To the best of our knowledge, MADiff is the first diffusion-based multi-agent offline RL framework, which behaves as both a decentralized policy and a centralized controller, which includes opponent modeling and can be used for multi-agent trajectory predic
    
[^82]: 当前机器学习需要多少样本才能利用平滑性？

    How many samples are needed to leverage smoothness?. (arXiv:2305.16014v1 [stat.ML])

    [http://arxiv.org/abs/2305.16014](http://arxiv.org/abs/2305.16014)

    本文通过研究泛化误差的新下界，探讨了学习平滑函数时需要的样本数量及其机器学习问题中的挑战。

    

    统计学习的核心原则之一是，目标函数的平滑性可以打破维度灾难。然而，通过泰勒展开学习平滑函数需要足够接近一起的样本来获得高阶导数的有意义估计，这在数据量相对较小的机器学习问题中似乎很困难。本文通过推导广义泛化误差的新的下界，研究了常数和瞬态区域在实践中通常被忽略却发挥了主导作用的问题。

    A core principle in statistical learning is that smoothness of target functions allows to break the curse of dimensionality. However, learning a smooth function through Taylor expansions requires enough samples close to one another to get meaningful estimate of high-order derivatives, which seems hard in machine learning problems where the ratio between number of data and input dimension is relatively small. Should we really hope to break the curse of dimensionality based on Taylor expansion estimation? What happens if Taylor expansions are replaced by Fourier or wavelet expansions? By deriving a new lower bound on the generalization error, this paper investigates the role of constants and transitory regimes which are usually not depicted beyond classical learning theory statements while that play a dominant role in practice.
    
[^83]: 智能系统测试探讨

    Testing System Intelligence. (arXiv:2305.11472v1 [cs.AI])

    [http://arxiv.org/abs/2305.11472](http://arxiv.org/abs/2305.11472)

    该论文讨论了以往智能系统测试的不足和所提出的替换测试作为一种完善测试的能力，该测试反映了人类和机器之间的技能互补性，能够构建更多反映智能可能的概念和属性。

    

    我们讨论了针对智能系统的测试的充分性以及其实施带来的实际问题。我们提出了替换测试作为系统在给定环境下成功替换另一个执行任务的系统的能力。我们展示了它如何表征人类智能的显著方面，这些方面不能被图灵测试考虑到。我们认为，构建通过替换测试的智能系统涉及到一系列当前人工智能所无法解决的技术问题。我们提出了一个框架来实施所提出的测试并验证智能系统的属性。我们讨论了智能系统验证的固有局限性，并倡导新的理论基础以扩展现有的严格测试方法。我们建议基于人类和机器之间技能互补性的替换测试可以导致多种反映结合基于数据和知识的能力的智能概念。

    We discuss the adequacy of tests for intelligent systems and practical problems raised by their implementation. We propose the replacement test as the ability of a system to replace successfully another system performing a task in a given context. We show how it can characterize salient aspects of human intelligence that cannot be taken into account by the Turing test. We argue that building intelligent systems passing the replacement test involves a series of technical problems that are outside the scope of current AI. We present a framework for implementing the proposed test and validating the properties of the intelligent systems. We discuss the inherent limitations of intelligent system validation and advocate new theoretical foundations for extending existing rigorous test methods. We suggest that the replacement test, based on the complementarity of skills between human and machine, can lead to a multitude of intelligence concepts reflecting the ability to combine data-based and 
    
[^84]: 激发Web规模语音模型的潜在能力以实现零-shot任务泛化

    Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization. (arXiv:2305.11095v1 [eess.AS])

    [http://arxiv.org/abs/2305.11095](http://arxiv.org/abs/2305.11095)

    本文通过提示工程技术调整Whisper模型，成功适应未见过的三个任务，并提出的提示比默认提示性能提升了10%到45％，展现了Whisper模型的鲁棒性和多语言理解能力。

    

    本文研究了最近提出的Web规模语音模型Whisper的新兴功能，在使用提示工程技术调整模型后，适应了未见过的AVSR，CS-ASR和ST三个任务。我们设计了特定于任务的提示，要么利用另一个大规模模型，要么简单地操作默认提示中的特殊标记。实验证明，与默认提示相比，我们提出的提示使这三个零-shot任务的性能提高了10%到45％，甚至在一些数据集上超过了SotA监督模型。此外，我们的实验揭示了Whisper的许多有趣属性，包括其提示的鲁棒性，对口音的偏好以及潜在空间中的多语言理解。代码可在https://github.com/jasonppy/PromptingWhisper上找到。

    We investigate the emergent abilities of the recently proposed web-scale speech model Whisper, by adapting it to unseen tasks with prompt engineering. We selected three tasks: audio-visual speech recognition (AVSR), code-switched speech recognition (CS-ASR), and speech translation (ST) on unseen language pairs. We design task-specific prompts, by either leveraging another large-scale model, or simply manipulating the special tokens in the default prompts. Experiments show that compared to the default prompts, our proposed prompts improve performance by 10% to 45% on the three zero-shot tasks, and even outperform SotA supervised models on some datasets. In addition, our experiments reveal many interesting properties of Whisper, including its robustness to prompts, bias on accents, and the multilingual understanding in its latent space. Code is available at https://github.com/jasonppy/PromptingWhisper
    
[^85]: G-MATT: 分子语法树变换器的单步回溯合成预测

    G-MATT: Single-step Retrosynthesis Prediction using Molecular Grammar Tree Transformer. (arXiv:2305.03153v1 [cs.LG])

    [http://arxiv.org/abs/2305.03153](http://arxiv.org/abs/2305.03153)

    G-MATT是一个结合数据驱动模型与化学知识的化学感知回溯合成预测框架，在分层SMILES语法树输入的基础上采用树到序列变换器架构，能够显著提高单步回溯合成的准确率。

    

    近年来，已经报道了几种基于反应模板和基于自由模板的单步回溯合成预测方法。尽管这些方法中的许多在传统数据驱动指标方面表现良好，但使用的模型架构与支配反向合成的底层化学原则之间存在脱节。在这里，我们提出了一种新颖的化学感知回溯合成预测框架，将强大的数据驱动模型与化学知识相结合。我们报告了一种基于分层SMILES语法树的树到序列变换器架构，其中包含被纯SMILES表示法的模型忽略的底层化学信息。所提出的框架，基于语法的分子注意力树变换器（G-MATT），与基线回溯合成模型相比，实现了显着的性能提高。 G-MATT的准确率排名前1为51％（前10为79.1％），无效率为1.5％，

    In recent years, several reaction templates-based and template-free approaches have been reported for single-step retrosynthesis prediction. Even though many of these approaches perform well from traditional data-driven metrics standpoint, there is a disconnect between model architectures used and underlying chemistry principles governing retrosynthesis. Here, we propose a novel chemistry-aware retrosynthesis prediction framework that combines powerful data-driven models with chemistry knowledge. We report a tree-to-sequence transformer architecture based on hierarchical SMILES grammar trees as input containing underlying chemistry information that is otherwise ignored by models based on purely SMILES-based representations. The proposed framework, grammar-based molecular attention tree transformer (G-MATT), achieves significant performance improvements compared to baseline retrosynthesis models. G-MATT achieves a top-1 accuracy of 51% (top-10 accuracy of 79.1%), invalid rate of 1.5%, a
    
[^86]: 提供最佳支持环境优化人工智能开发过程

    Optimizing the AI Development Process by Providing the Best Support Environment. (arXiv:2305.00136v1 [cs.SE])

    [http://arxiv.org/abs/2305.00136](http://arxiv.org/abs/2305.00136)

    本研究旨在提供人工智能（AI）和机器学习（ML）应用的最佳支持环境，具体重点研究了ML开发中数据管理阶段的障碍以及如何构建和开发一个框架，利用多种数据增强技术来解决数据管理阶段缺乏足够数据的问题。

    

    本研究旨在调查人工智能（AI）和机器学习（ML）应用的开发过程，以提供最佳支持环境。ML的主要阶段包括问题理解，数据管理，模型构建，模型部署和维护。本项目重点研究了ML开发的数据管理阶段及其障碍，因为最终模型的准确性取决于输入到模型中的数据类型。发现这一阶段最大的障碍是缺乏足够的模型学习数据，尤其是在数据保密领域。本项目旨在构建和开发一个框架，帮助解决数据管理阶段缺乏足够数据的问题。该框架利用多种数据增强技术，可以从原始数据集中生成新数据。

    The purpose of this study is to investigate the development process for Artificial inelegance (AI) and machine learning (ML) applications in order to provide the best support environment. The main stages of ML are problem understanding, data management, model building, model deployment and maintenance. This project focuses on investigating the data management stage of ML development and its obstacles as it is the most important stage of machine learning development because the accuracy of the end model is relying on the kind of data fed into the model. The biggest obstacle found on this stage was the lack of sufficient data for model learning, especially in the fields where data is confidential. This project aimed to build and develop a framework for researchers and developers that can help solve the lack of sufficient data during data management stage. The framework utilizes several data augmentation techniques that can be used to generate new data from the original dataset which can 
    
[^87]: UDTIRI:一个开源的道路坑洞检测基准套件

    UDTIRI: An Open-Source Road Pothole Detection Benchmark Suite. (arXiv:2304.08842v1 [cs.CV])

    [http://arxiv.org/abs/2304.08842](http://arxiv.org/abs/2304.08842)

    该论文介绍了一个开源的道路坑洞检测基准套件UDTIRI，包含了标记齐全的1000张道路坑洞图像，可以用于深度学习方法在城市道路检查中的目标检测、语义分割和实例分割任务。

    

    看到在城市数字孪生领域中利用强大的深度学习方法的巨大潜力。特别是在智能道路检查领域，目前研究和数据有限。为了促进这一领域的进展，我们开发了一个名为Urban Digital Twins Intelligent Road Inspection (UDTIRI)数据集的标记齐全的道路坑洞数据集。我们希望这个数据集能够让强大的深度学习方法在城市道路检查中发挥作用，让算法更全面地理解场景并最大化其潜力。我们的数据集包括1000张道路坑洞图像，拍摄于不同的情境中，具有不同的光照和湿度条件。我们的意图是将这个数据集应用于目标检测、语义分割和实例分割任务。我们的团队花费了大量精力进行了详细的统计分析，并对UDTIRI数据集的一些代表性深度学习模型进行了基准测试。

    It is seen that there is enormous potential to leverage powerful deep learning methods in the emerging field of urban digital twins. It is particularly in the area of intelligent road inspection where there is currently limited research and data available. To facilitate progress in this field, we have developed a well-labeled road pothole dataset named Urban Digital Twins Intelligent Road Inspection (UDTIRI) dataset. We hope this dataset will enable the use of powerful deep learning methods in urban road inspection, providing algorithms with a more comprehensive understanding of the scene and maximizing their potential. Our dataset comprises 1000 images of potholes, captured in various scenarios with different lighting and humidity conditions. Our intention is to employ this dataset for object detection, semantic segmentation, and instance segmentation tasks. Our team has devoted significant effort to conducting a detailed statistical analysis, and benchmarking a selection of represent
    
[^88]: 用于自动驾驶测试的复杂环形交叉口的过程生成

    Procedural Generation of Complex Roundabouts for Autonomous Vehicle Testing. (arXiv:2303.17900v1 [cs.RO])

    [http://arxiv.org/abs/2303.17900](http://arxiv.org/abs/2303.17900)

    本文提出了一种基于附近道路结构的几何限制的过程生成方法，用于生成非完全圆形且类似于真实世界中的环形交叉口的车道，适用于自动驾驶场景测试。

    

    高清道路是自动驾驶场景模拟测试的重要组成部分，而环形交叉口是其中一个关键的路段，目前对其研究还不够深入。本研究基于附近道路结构的几何限制，提出一种新颖的建造环形交叉口的过程生成方法。该方法可以产生不完全圆形且类似于真实世界中的环形交叉口的车道，因为它允许连接到环形交叉口的途径道路的任意角度。可以轻松地将环形交叉口融入高清道路生成过程中，或使用独立的环形交叉口进行自动驾驶场景测试。

    High-definition roads are an essential component of realistic driving scenario simulation for autonomous vehicle testing. Roundabouts are one of the key road segments that have not been thoroughly investigated. Based on the geometric constraints of the nearby road structure, this work presents a novel method for procedurally building roundabouts. The suggested method can result in roundabout lanes that are not perfectly circular and resemble real-world roundabouts by allowing approaching roadways to be connected to a roundabout at any angle. One can easily incorporate the roundabout in their HD road generation process or use the standalone roundabouts in scenario-based testing of autonomous driving.
    
[^89]: 多视角的零样本开放意图归纳：多领域批处理和代理梯度转移

    Multi-View Zero-Shot Open Intent Induction from Dialogues: Multi Domain Batch and Proxy Gradient Transfer. (arXiv:2303.13099v1 [cs.CL])

    [http://arxiv.org/abs/2303.13099](http://arxiv.org/abs/2303.13099)

    本研究提出了一种多领域批处理和代理梯度转移的语义多视角模型，可以解决任务导向对话系统中的意图检测和诱导新意图的问题，在Open Intent Induction中有显著的性能提升。

    

    在任务导向的对话系统中，检测和诱导新的意图是将该系统应用于实际应用的两个主要挑战。本文提出了语义多视角模型来解决这两个难题：（1）用于一般嵌入的SBERT（2）多领域批处理（MDB）用于对话领域知识，以及（3）用于集群专业语义的代理梯度转移（PGT）。 MDB一次向模型提供多种对话数据集，通过学习多领域知识来解决多领域问题。我们引入了一种新的方法PGT，它采用Siamese网络直接使用聚类方法微调模型。我们的模型可以学习如何使用PGT聚类对话语句。实验结果表明，与基线系统相比，我们的多视角模型与MDB和PGT显着提高了Open Intent Induction的性能。

    In Task Oriented Dialogue (TOD) system, detecting and inducing new intents are two main challenges to apply the system in the real world. In this paper, we suggest the semantic multi-view model to resolve these two challenges: (1) SBERT for General Embedding (GE), (2) Multi Domain Batch (MDB) for dialogue domain knowledge, and (3) Proxy Gradient Transfer (PGT) for cluster-specialized semantic. MDB feeds diverse dialogue datasets to the model at once to tackle the multi-domain problem by learning the multiple domain knowledge. We introduce a novel method PGT, which employs the Siamese network to fine-tune the model with a clustering method directly.Our model can learn how to cluster dialogue utterances by using PGT. Experimental results demonstrate that our multi-view model with MDB and PGT significantly improves the Open Intent Induction performance compared to baseline systems.
    
[^90]: 打破常识：WHOOPS！一个基于合成和组合图像的视觉与语言基准测试

    Breaking Common Sense: WHOOPS! A Vision-and-Language Benchmark of Synthetic and Compositional Images. (arXiv:2303.07274v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.07274](http://arxiv.org/abs/2303.07274)

    WHOOPS!是一个新的视觉常识数据集和基准测试，包括了图像字幕、跨模态匹配和视觉问答等若干个任务，引入了解释生成任务，挑战了AI模型识别和解释不合常规的图像的能力。

    

    奇怪、异常和神秘的图像会引起观察者的好奇心，因为它们挑战了常识。我们提出WHOOPS！一个新的视觉常识数据集和基准测试。该数据集由设计师使用Midjourney等公共可用图像生成工具制作，并包含若干个任务。除了图像字幕、跨模态匹配和视觉问答之外，我们还引入了一个困难的解释生成任务，其中模型必须识别并解释给定图像的异常之处。

    Weird, unusual, and uncanny images pique the curiosity of observers because they challenge commonsense. For example, an image released during the 2022 world cup depicts the famous soccer stars Lionel Messi and Cristiano Ronaldo playing chess, which playfully violates our expectation that their competition should occur on the football field. Humans can easily recognize and interpret these unconventional images, but can AI models do the same? We introduce WHOOPS!, a new dataset and benchmark for visual commonsense. The dataset is comprised of purposefully commonsense-defying images created by designers using publicly-available image generation tools like Midjourney. We consider several tasks posed over the dataset. In addition to image captioning, cross-modal matching, and visual question answering, we introduce a difficult explanation generation task, where models must identify and explain why a given image is unusual. Our results show that state-of-the-art models such as GPT3 and BLIP2
    
[^91]: TARGET: 通过无样本蒸馏实现联邦类式持续学习

    TARGET: Federated Class-Continual Learning via Exemplar-Free Distillation. (arXiv:2303.06937v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.06937](http://arxiv.org/abs/2303.06937)

    本文研究了一个重要但鲜为人知的问题：联邦类式持续学习，在联邦学习中动态添加新的类别。我们提出了一种称为TARGET的新颖方法，通过无样本蒸馏来减轻FCCL中的灾难性遗忘问题，并保护客户数据的隐私。该方法利用先前训练的全局模型在模型层面上传递旧任务的知识，并通过生成器生成合成数据来模拟数据的全局分布。与先前的FCCL方法相比，TARGET无需额外的数据集或存储先前任务的私有数据。

    

    本文针对一个鲜为人知但重要的问题进行研究：联邦类式持续学习（FCCL），在联邦学习中动态添加新的类别。已有的FCCL方法存在各种限制，如需要额外的数据集或存储先前任务的私有数据。为此，我们首先证明非独立同分布的数据加剧了联邦学习中的灾难性遗忘问题。然后，我们提出了一种新颖的方法——TARGET（通过无样本蒸馏实现联邦类式持续学习），该方法在减轻FCCL的灾难性遗忘问题的同时保护客户数据的隐私。我们的方法利用先前训练的全局模型，在模型层面上将旧任务的知识传递给当前任务。此外，我们训练一个生成器来生成合成数据，以模拟每个客户端上数据的全局分布。与先前的FCCL方法相比，TARGET不需要额外的数据集或存储先前任务的私有数据。

    This paper focuses on an under-explored yet important problem: Federated Class-Continual Learning (FCCL), where new classes are dynamically added in federated learning. Existing FCCL works suffer from various limitations, such as requiring additional datasets or storing the private data from previous tasks. In response, we first demonstrate that non-IID data exacerbates catastrophic forgetting issue in FL. Then we propose a novel method called TARGET (federat\textbf{T}ed cl\textbf{A}ss-continual lea\textbf{R}nin\textbf{G} via \textbf{E}xemplar-free dis\textbf{T}illation), which alleviates catastrophic forgetting in FCCL while preserving client data privacy. Our proposed method leverages the previously trained global model to transfer knowledge of old tasks to the current task at the model level. Moreover, a generator is trained to produce synthetic data to simulate the global distribution of data on each client at the data level. Compared to previous FCCL methods, TARGET does not requi
    
[^92]: 实时基于管状非高斯风险有界运动规划方法用于不确定环境中的随机非线性系统

    Real-Time Tube-Based Non-Gaussian Risk Bounded Motion Planning for Stochastic Nonlinear Systems in Uncertain Environments via Motion Primitives. (arXiv:2303.01631v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.01631](http://arxiv.org/abs/2303.01631)

    本文提出了一种实时在线运动规划算法，用于在不确定环境中的随机非线性系统中进行长期任务的规划。这种方法通过构建离散时间运动基元和连续时间管状体来保证系统状态的安全性。

    

    我们考虑在不确定环境中的随机非线性系统的运动规划问题。具体来说，该问题中机器人具有随机非线性动力学和不确定的初始位置，环境中包含多个动态不确定障碍物。障碍物可以具有任意形状，可以变形和移动。所有不确定性不一定服从高斯分布。这个通用设置已在文献[1]中被考虑并解决。除了上述假设之外，本文还考虑了长期任务，在这种情况下，文献[1]中的规划方法将会失败，因为系统状态的不确定性在长时间范围内变得过大。与[1]不同，我们提出了一个实时在线运动规划算法。我们离线构建离散时间运动基元及其对应的连续时间管状体，以确保每个运动基元的几乎所有系统状态都保持在对应的管状体内。我们将概率安全约束转换为一种方法来积累管状体的概率界的在线优化问题。

    We consider the motion planning problem for stochastic nonlinear systems in uncertain environments. More precisely, in this problem the robot has stochastic nonlinear dynamics and uncertain initial locations, and the environment contains multiple dynamic uncertain obstacles. Obstacles can be of arbitrary shape, can deform, and can move. All uncertainties do not necessarily have Gaussian distribution. This general setting has been considered and solved in [1]. In addition to the assumptions above, in this paper, we consider long-term tasks, where the planning method in [1] would fail, as the uncertainty of the system states grows too large over a long time horizon. Unlike [1], we present a real-time online motion planning algorithm. We build discrete-time motion primitives and their corresponding continuous-time tubes offline, so that almost all system states of each motion primitive are guaranteed to stay inside the corresponding tube. We convert probabilistic safety constraints into a
    
[^93]: 基于非高斯不确定性最小化的随机非线性机器人系统控制

    Non-Gaussian Uncertainty Minimization Based Control of Stochastic Nonlinear Robotic Systems. (arXiv:2303.01628v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.01628](http://arxiv.org/abs/2303.01628)

    本文提出了一种针对非线性机器人系统的闭环控制问题的解决方案，通过最小化不确定性和干扰引起的系统状态偏差，设计了一个状态反馈控制器。相比于现有方法，该方法可以处理非线性动力学模型和任意已知概率不确定性。

    

    本文考虑了存在概率性不确定性和干扰的非线性机器人系统的闭环控制问题。我们设计了一种状态反馈控制器，通过最小化系统状态与名义状态轨迹之间的偏差，来处理因不确定性和干扰而引起的偏差。现有的方法只限于处理特定类别的不确定性和系统，如高斯不确定性、过程和线性化系统。我们提出了一种处理非线性动力学模型和任意已知概率不确定性的方法。我们将控制器设计问题转化为一个基于概率分布的统计量优化问题，包括矩和特征函数。具体而言，在所提供的优化问题中，我们使用矩和特征函数来传播不确定性到机器人非线性运动模型中。

    In this paper, we consider the closed-loop control problem of nonlinear robotic systems in the presence of probabilistic uncertainties and disturbances. More precisely, we design a state feedback controller that minimizes deviations of the states of the system from the nominal state trajectories due to uncertainties and disturbances. Existing approaches to address the control problem of probabilistic systems are limited to particular classes of uncertainties and systems such as Gaussian uncertainties and processes and linearized systems. We present an approach that deals with nonlinear dynamics models and arbitrary known probabilistic uncertainties. We formulate the controller design problem as an optimization problem in terms of statistics of the probability distributions including moments and characteristic functions. In particular, in the provided optimization problem, we use moments and characteristic functions to propagate uncertainties throughout the nonlinear motion model of rob
    
[^94]: RemoteNet: 基于全局-局部信息的遥感图像分割网络

    RemoteNet: Remote Sensing Image Segmentation Network based on Global-Local Information. (arXiv:2302.13084v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.13084](http://arxiv.org/abs/2302.13084)

    本文提出了一种名为RemoteNet的遥感图像分割网络，通过使用全局-局部信息和多尺度特征，以及注意力机制和Transformer进行特征融合和学习，改进了遥感图像的语义分割性能。

    

    由于复杂的场景，远程捕获的图像具有巨大的尺度和物体外观的变化。对于其分割，捕捉全局和局部上下文中的潜在属性变得具有挑战性。现有的网络难以捕捉因杂乱的背景而产生的内在特征。为了解决这些问题，我们提出了一种用于遥感图像语义分割的遥感图像分割网络RemoteNet。我们通过利用Transformer和卷积机制的优势来捕捉全局和局部特征。RemoteNet采用编码解码器的设计，使用多尺度特征。我们构建了一个注意力映射模块来生成通道注意力分数，用于融合这些特征。我们在解码器网络中构建了一个全局-局部Transformer块（GLTB）来支持在解码阶段学习鲁棒表示。此外，我们设计了一个特征细化模块来优化浅层阶段编码器的融合输出。

    Remotely captured images possess an immense scale and object appearance variability due to the complex scene. It becomes challenging to capture the underlying attributes in the global and local context for their segmentation. Existing networks struggle to capture the inherent features due to the cluttered background. To address these issues, we propose a remote sensing image segmentation network, RemoteNet, for semantic segmentation of remote sensing images. We capture the global and local features by leveraging the benefits of the transformer and convolution mechanisms. RemoteNet is an encoder-decoder design that uses multi-scale features. We construct an attention map module to generate channel-wise attention scores for fusing these features. We construct a global-local transformer block (GLTB) in the decoder network to support learning robust representations during a decoding phase. Further, we designed a feature refinement module to refine the fused output of the shallow stage enco
    
[^95]: 目标网络如何稳定时间差分方法

    Why Target Networks Stabilise Temporal Difference Methods. (arXiv:2302.12537v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.12537](http://arxiv.org/abs/2302.12537)

    本文解释了深度强化学习中一种流行的时序差分方法中关键的稳定性问题：为什么目标网络能够有效降低不满足条件时的影响。

    

    深度强化学习中近期成功的关键在于一类使用不频繁更新目标值进行策略评估的时序差分方法。然而，有关目标网络有效性的完整理论解释仍然难以捉摸。本文针对这种流行算法进行了分析，最终回答了“为什么目标网络可以稳定时间差分学习”的问题。我们规范化了部分拟合的策略评估方法的概念，其中包括目标网络的使用，并且填补了拟合方法和半梯度时序差分算法之间的差距。利用这个框架，我们能够独特地描述所谓的致命三元组，即使用时序差分更新，结合（非线性）函数逼近和处于离线状态的数据，这经常会导致不收敛的算法。这一认识使我们得出结论：目标网络的使用可以减轻条件差时的影响。

    Integral to recent successes in deep reinforcement learning has been a class of temporal difference methods that use infrequently updated target values for policy evaluation in a Markov Decision Process. Yet a complete theoretical explanation for the effectiveness of target networks remains elusive. In this work, we provide an analysis of this popular class of algorithms, to finally answer the question: `why do target networks stabilise TD learning'? To do so, we formalise the notion of a partially fitted policy evaluation method, which describes the use of target networks and bridges the gap between fitted methods and semigradient temporal difference algorithms. Using this framework we are able to uniquely characterise the so-called deadly triad - the use of TD updates with (nonlinear) function approximation and off-policy data - which often leads to nonconvergent algorithms. This insight leads us to conclude that the use of target networks can mitigate the effects of poor conditionin
    
[^96]: SAT需要彻底搜索

    SAT Requires Exhaustive Search. (arXiv:2302.09512v4 [cs.CC] CROSS LISTED)

    [http://arxiv.org/abs/2302.09512](http://arxiv.org/abs/2302.09512)

    本文证明了对于一些具有大域和长子句的极难例子，要求进行彻底搜索才能解决，这意味着P $\neq$ NP。

    

    本文通过构造具有大域和长子句的CSP和SAT的极难例子，证明这些例子无法在不进行彻底搜索的情况下解决，这意味着一个较弱的结论P $\neq$ NP。本文采用的是一种证明不可能性结果的建设性方法，与目前计算复杂性理论中使用的方法非常不同，但与Kurt G\"{o}del在证明他著名的逻辑不可能性结果时使用的方法相似。正如G\"{o}del的结果表明，在数学中证明形式上的不可证明性是可行的一样，本文的结果表明，在数学中证明计算上的难度不是很难的。具体来说，对许多问题，如3-SAT，证明下界可能具有挑战性，因为这些问题有各种有效的策略可用于避免进行彻底搜索。然而，在极难的例子中，彻底搜索可能是唯一可行的选择，证明其必要性变得更加重要。

    In this paper, by constructing extremely hard examples of CSP (with large domains) and SAT (with long clauses), we prove that such examples cannot be solved without exhaustive search, which implies a weaker conclusion P $\neq$ NP. This constructive approach for proving impossibility results is very different (and missing) from those currently used in computational complexity theory, but is similar to that used by Kurt G\"{o}del in proving his famous logical impossibility results. Just as shown by G\"{o}del's results that proving formal unprovability is feasible in mathematics, the results of this paper show that proving computational hardness is not hard in mathematics. Specifically, proving lower bounds for many problems, such as 3-SAT, can be challenging because these problems have various effective strategies available for avoiding exhaustive search. However, in cases of extremely hard examples, exhaustive search may be the only viable option, and proving its necessity becomes more 
    
[^97]: LabelPrompt: 关于关系分类的有效的提示式学习

    LabelPrompt: Effective Prompt-based Learning for Relation Classification. (arXiv:2302.08068v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.08068](http://arxiv.org/abs/2302.08068)

    LabelPrompt是一种面向关系分类任务的提示式学习方法，通过定义额外的令牌来表示关系标签，并使用提示模板方法明确构建它们，从而解决了将填充掩码标记的自然语言词汇与语义关系标签相关联的挑战。同时，该方法还实现了一个实体感知模块来减轻预测关系和给定实体之间的不一致性。

    

    最近，通过将自然语言处理（NLP）任务转换为填空式格式，以更好地与预训练语言模型（PLMs）对齐的方式，提示式学习在许多NLP任务中变得流行起来。然而，将这种方法应用于关系分类任务面临着独特的挑战。具体而言，将填充掩码标记的自然语言词汇与语义关系标签（如"org:founded_by"）相关联是困难的。为了解决这个挑战，本文提出了一种新颖的提示式学习方法，称为LabelPrompt，用于关系分类任务。受到“给予模型选择”的直觉的启发，我们首先定义额外的令牌来表示关系标签，将这些令牌视为具有语义初始化的口述者，并使用提示模板方法明确构建它们。然后，为了减轻预测关系和给定实体之间的不一致性，我们实现了一个实体感知模块，并采用对抗性的方式进行引导。

    Recently, prompt-based learning has gained popularity across many natural language processing (NLP) tasks by reformulating them into a cloze-style format to better align pre-trained language models (PLMs) with downstream tasks. However, applying this approach to relation classification poses unique challenges. Specifically, associating natural language words that fill the masked token with semantic relation labels (\textit{e.g.} \textit{``org:founded\_by}'') is difficult. To address this challenge, this paper presents a novel prompt-based learning method, namely LabelPrompt, for the relation classification task. Motivated by the intuition to ``GIVE MODEL CHOICES!'', we first define additional tokens to represent relation labels, which regard these tokens as the verbaliser with semantic initialisation and explicitly construct them with a prompt template method. Then, to mitigate inconsistency between predicted relations and given entities, we implement an entity-aware module with contra
    
[^98]: HumanMAC：用于人体运动预测的掩码动作修复

    HumanMAC: Masked Motion Completion for Human Motion Prediction. (arXiv:2302.03665v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.03665](http://arxiv.org/abs/2302.03665)

    HumanMAC是一个掩码动作修复框架，通过训练阶段的运动扩散模型和推断阶段的去噪过程，在观察到的运动数据的控制下进行运动预测，并在多个基准数据集上展示了显著的改进。

    

    人体运动预测是计算机视觉和计算机图形学中的一个经典问题，具有广泛的实际应用。以编码-解码风格为基础的先前方法在经验性能方面取得了巨大的成功，但实际上仍存在一些问题，包括复杂的损失约束、繁琐的培训过程以及预测中不同类别运动的稀缺切换。本文从新的角度提出了一个新颖的框架，采用掩蔽完成方式解决了以上问题。具体来说，在训练阶段，我们学习了一个运动扩散模型来从随机噪声中生成运动。在推断阶段，通过去噪过程，我们进行了运动预测并在观察到的运动数据的控制下进行了预测。我们提出的框架名为HumanMAC，在几个基准数据集上显示出明显的改进。

    Human motion prediction is a classical problem in computer vision and computer graphics, which has a wide range of practical applications. Previous effects achieve great empirical performance based on an encoding-decoding style. The methods of this style work by first encoding previous motions to latent representations and then decoding the latent representations into predicted motions. However, in practice, they are still unsatisfactory due to several issues, including complicated loss constraints, cumbersome training processes, and scarce switch of different categories of motions in prediction. In this paper, to address the above issues, we jump out of the foregoing style and propose a novel framework from a new perspective. Specifically, our framework works in a masked completion fashion. In the training stage, we learn a motion diffusion model that generates motions from random noise. In the inference stage, with a denoising procedure, we make motion prediction conditioning on obse
    
[^99]: 无先验因果学习

    Zero-shot causal learning. (arXiv:2301.12292v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12292](http://arxiv.org/abs/2301.12292)

    无先验因果学习是一个解决预测新型干预措施个性化影响的框架，并通过元学习对任务的处理达成了目的，能够将干预措施的知识传输到未见过的干预措施中，并在合成和真实数据集上表现出了优越性能。

    

    在个性化医疗、公共政策和在线营销等领域，预测不同干预措施对特定个体的因果影响非常重要。预测现有干预措施的影响有许多方法，这些方法基于接受过干预措施的个体的历史数据。然而，在许多场景中，预测新型干预措施的影响也很重要，这些方法无法解决。在这里，我们考虑了无先验因果学习：预测新型干预措施的个性化影响。我们提出了CaML，这是一个因果元学习框架，它将每个干预措施的个性化预测效果作为一个任务来进行处理。CaML在数千个任务中训练单一的元模型，每个任务都是通过抽样生成一个干预措施及其接收者和非接收者来构建的。通过利用干预信息（例如，药物的属性）和个体特征（例如，特定个体的医疗记录），CaML学习如何将已观察到的干预措施的知识有效地传输给未见过的干预措施。我们在合成和真实数据集上展示了我们方法的有效性，展示了该方法具有推广到未见过干预措施并胜过现有方法的能力。

    Predicting how different interventions will causally affect a specific individual is important in a variety of domains such as personalized medicine, public policy, and online marketing. There are a large number of methods to predict the effect of an existing intervention based on historical data from individuals who received it. However, in many settings it is important to predict the effects of novel interventions (\emph{e.g.}, a newly invented drug), which these methods do not address. Here, we consider zero-shot causal learning: predicting the personalized effects of a novel intervention. We propose CaML, a causal meta-learning framework which formulates the personalized prediction of each intervention's effect as a task. CaML trains a single meta-model across thousands of tasks, each constructed by sampling an intervention, along with its recipients and nonrecipients. By leveraging both intervention information (\emph{e.g.}, a drug's attributes) and individual features~(\emph{e.g.
    
[^100]: 切片Transformer和自监督学习用于3D点云地图中的六自由度定位

    Slice Transformer and Self-supervised Learning for 6DoF Localization in 3D Point Cloud Maps. (arXiv:2301.08957v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.08957](http://arxiv.org/abs/2301.08957)

    这篇论文介绍了一种新的自监督学习方法，首次使用Transformer进行室外定位的任务。作者提出了切片Transformer模型，并利用轴向特性重新组织了激光雷达扫描的切片。此外，作者还引入了Perth-WA数据集，并在多个数据集上进行了实验评估，证明了方法的有效性。

    

    精确定位对于自动驾驶汽车至关重要。我们提出了一种自监督学习方法，首次采用了Transformer进行使用激光雷达数据进行室外定位的任务。我们提出了一个预训练任务，重新组织了$360^\circ$激光雷达扫描的切片，利用其轴向特性。我们的模型称为切片Transformer，在处理切片时使用多头注意力。据我们所知，这是首次利用多头注意力进行室外点云处理。我们还引入了Perth-WA数据集，该数据集提供了西澳大利亚珀斯市的大规模激光雷达地图，涵盖了约4平方公里的区域。Perth-WA提供了定位标注。我们在Perth-WA和Appollo-SouthBay数据集上对所提出的定位方法进行了全面评估。我们还证明了我们的自监督学习方法在常见的下游任务，如ModelNet40和...方面的有效性。

    Precise localization is critical for autonomous vehicles. We present a self-supervised learning method that employs Transformers for the first time for the task of outdoor localization using LiDAR data. We propose a pre-text task that reorganizes the slices of a $360^\circ$ LiDAR scan to leverage its axial properties. Our model, called Slice Transformer, employs multi-head attention while systematically processing the slices. To the best of our knowledge, this is the first instance of leveraging multi-head attention for outdoor point clouds. We additionally introduce the Perth-WA dataset, which provides a large-scale LiDAR map of Perth city in Western Australia, covering $\sim$4km$^2$ area. Localization annotations are provided for Perth-WA. The proposed localization method is thoroughly evaluated on Perth-WA and Appollo-SouthBay datasets. We also establish the efficacy of our self-supervised learning approach for the common downstream task of object classification using ModelNet40 and
    
[^101]: 数据中心人工智能

    Data-centric Artificial Intelligence. (arXiv:2212.11854v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.11854](http://arxiv.org/abs/2212.11854)

    数据中心人工智能是一种新兴的范式，它强调系统性地设计和构建数据对于建立有效和高效的基于人工智能的系统至关重要。

    

    数据中心人工智能（data-centric AI）是一种新兴的范式，强调系统性地设计和构建数据对于建立有效和高效的基于人工智能的系统至关重要。本文的目的是向信息系统领域的从业者和研究人员介绍数据中心人工智能。我们定义相关术语，提供关键特征来对比数据中心范式和模型中心范式，并介绍了一个数据中心人工智能的框架。我们区分数据中心人工智能和相关概念，并讨论其对信息系统社区的长期影响。

    Data-centric artificial intelligence (data-centric AI) represents an emerging paradigm emphasizing that the systematic design and engineering of data is essential for building effective and efficient AI-based systems. The objective of this article is to introduce practitioners and researchers from the field of Information Systems (IS) to data-centric AI. We define relevant terms, provide key characteristics to contrast the data-centric paradigm to the model-centric one, and introduce a framework for data-centric AI. We distinguish data-centric AI from related concepts and discuss its longer-term implications for the IS community.
    
[^102]: 深度神经网络中的解释方法破解

    Foiling Explanations in Deep Neural Networks. (arXiv:2211.14860v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.14860](http://arxiv.org/abs/2211.14860)

    本文发现了解释图像 DNN 的一个令人担忧的属性：通过微小视觉更改，我们演示了解释可以通过进化策略任意操纵。我们提出了 AttaXAI，一个针对 XAI 算法的敌对攻击，可访问分类器输出信息和解释图，这使得我们的方法在实际应用中非常有用。

    

    深度神经网络的黑盒特性对于可解释性仍然存在重大挑战，因为仅仅获得其输出是不够有用的。本文发现了图像 DNN 的解释方法的一个令人担忧的属性：通过对输入图像进行微小的视觉更改，我们演示了如何通过进化策略任意操纵解释。我们提出了一个新的算法 AttaXAI，一个针对 XAI 算法的模型无关的敌对攻击，只需要访问分类器的输出信息和解释图，这些弱假设使我们的方法在实际应用中非常有用。

    Deep neural networks (DNNs) have greatly impacted numerous fields over the past decade. Yet despite exhibiting superb performance over many problems, their black-box nature still poses a significant challenge with respect to explainability. Indeed, explainable artificial intelligence (XAI) is crucial in several fields, wherein the answer alone -- sans a reasoning of how said answer was derived -- is of little value. This paper uncovers a troubling property of explanation methods for image-based DNNs: by making small visual changes to the input image -- hardly influencing the network's output -- we demonstrate how explanations may be arbitrarily manipulated through the use of evolution strategies. Our novel algorithm, AttaXAI, a model-agnostic, adversarial attack on XAI algorithms, only requires access to the output logits of a classifier and to the explanation map; these weak assumptions render our approach highly useful where real-world models and data are concerned. We compare our me
    
[^103]: StyleNAT：给每个头部一个新的视角

    StyleNAT: Giving Each Head a New Perspective. (arXiv:2211.05770v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.05770](http://arxiv.org/abs/2211.05770)

    StyleNAT是一个新的基于transformer的图像生成框架，通过使用邻域注意力（NA）来捕捉局部和全局信息，能够高效灵活地适应不同的数据集，并在FFHQ-256上取得了新的最佳结果。

    

    图像生成一直是一个既期望又具有挑战性的任务，以高效的方式执行生成任务同样困难。通常，研究人员试图创建一个“一刀切”的生成器，在参数空间中，即使是截然不同的数据集，也有很少的差异。在这里，我们提出了一种新的基于transformer的框架，称为StyleNAT，旨在实现高质量的图像生成，并具有卓越的效率和灵活性。在我们的模型核心是一个精心设计的框架，它将注意力头部划分为捕捉局部和全局信息的方式，这是通过使用邻域注意力（NA）实现的。由于不同的头部能够关注不同的感受野，模型能够更好地结合这些信息，并以高度灵活的方式适应手头的数据。StyleNAT在FFHQ-256上获得了新的SOTA FID得分2.046 ，击败了以卷积模型（如StyleGAN-XL）和transformer模型（如HIT）为基础的先前方法。

    Image generation has been a long sought-after but challenging task, and performing the generation task in an efficient manner is similarly difficult. Often researchers attempt to create a "one size fits all" generator, where there are few differences in the parameter space for drastically different datasets. Herein, we present a new transformer-based framework, dubbed StyleNAT, targeting high-quality image generation with superior efficiency and flexibility. At the core of our model, is a carefully designed framework that partitions attention heads to capture local and global information, which is achieved through using Neighborhood Attention (NA). With different heads able to pay attention to varying receptive fields, the model is able to better combine this information, and adapt, in a highly flexible manner, to the data at hand. StyleNAT attains a new SOTA FID score on FFHQ-256 with 2.046, beating prior arts with convolutional models such as StyleGAN-XL and transformers such as HIT 
    
[^104]: 代理-控制器表示：具有丰富外部信息的原则性离线强化学习

    Agent-Controller Representations: Principled Offline RL with Rich Exogenous Information. (arXiv:2211.00164v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.00164](http://arxiv.org/abs/2211.00164)

    本文针对具有丰富外部信息的原则性离线强化学习进行研究，并提出了新的离线强化学习基准。研究发现，当噪声是复杂且与时间相关的过程时，现有的表示学习技术可能无法成功应用于这类数据集。

    

    在丰富的像素视觉观测空间中，从离线数据中学习控制代理对于强化学习在实际应用中至关重要。这种设置中的一个主要挑战是输入信息中存在难以建模和控制代理相关的信息。理论强化学习领域已经通过外部信息的观点来解决这个问题，即观测中包含的与控制无关的信息。例如，一个在繁忙街道上导航的机器人需要忽略与控制无关的信息，如背景中的其他人行走、物体的纹理或天空中的鸟类。本文针对具有视觉细节的外部信息的设置，并引入了新的离线强化学习基准，以研究这个问题。我们发现当噪声是复杂且与时间相关的过程时，当代的表示学习技术可能在数据集上失败，而这种噪声在实际中普遍存在。

    Learning to control an agent from data collected offline in a rich pixel-based visual observation space is vital for real-world applications of reinforcement learning (RL). A major challenge in this setting is the presence of input information that is hard to model and irrelevant to controlling the agent. This problem has been approached by the theoretical RL community through the lens of exogenous information, i.e, any control-irrelevant information contained in observations. For example, a robot navigating in busy streets needs to ignore irrelevant information, such as other people walking in the background, textures of objects, or birds in the sky. In this paper, we focus on the setting with visually detailed exogenous information, and introduce new offline RL benchmarks offering the ability to study this problem. We find that contemporary representation learning techniques can fail on datasets where the noise is a complex and time dependent process, which is prevalent in practical 
    
[^105]: JAX-DIPS：有限离散方法的神经引导法及其在具有间断的椭圆问题中的应用

    JAX-DIPS: Neural bootstrapping of finite discretization methods and application to elliptic problems with discontinuities. (arXiv:2210.14312v2 [math.NA] UPDATED)

    [http://arxiv.org/abs/2210.14312](http://arxiv.org/abs/2210.14312)

    JAX-DIPS是一种基于有限离散方法和神经网络的可伸缩策略，用于开发无网格混合神经符号偏微分方程求解器，并在具有间断的椭圆问题中得到应用。

    

    我们提出了一种可伸缩的策略，用于基于现有基于网格的数值离散方法开发无网格混合神经符号偏微分方程求解器。特别是，这种策略可以通过（i）利用先进数值方法、求解器和预处理器的准确性和收敛性以及（ii）将优化限制在一阶自动微分上，以更高效地训练偏微分方程的神经网络代理模型。所提出的神经引导方法（以下简称NBM）基于相对于神经网络的可训练参数的随机取样点上隐式笛卡尔单元格上获得的PDE系统的有限离散残差的评估。值得注意的是，引导有限离散方程中存在的守恒定律和对称性能够向神经网络提供有关解的信息。

    We present a scalable strategy for development of mesh-free hybrid neuro-symbolic partial differential equation solvers based on existing mesh-based numerical discretization methods. Particularly, this strategy can be used to efficiently train neural network surrogate models of partial differential equations by (i) leveraging the accuracy and convergence properties of advanced numerical methods, solvers, and preconditioners, as well as (ii) better scalability to higher order PDEs by strictly limiting optimization to first order automatic differentiation. The presented neural bootstrapping method (hereby dubbed NBM) is based on evaluation of the finite discretization residuals of the PDE system obtained on implicit Cartesian cells centered on a set of random collocation points with respect to trainable parameters of the neural network. Importantly, the conservation laws and symmetries present in the bootstrapped finite discretization equations inform the neural network about solution re
    
[^106]: NECE: 故事事件链提取工具包

    NECE: Narrative Event Chain Extraction Toolkit. (arXiv:2208.08063v5 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2208.08063](http://arxiv.org/abs/2208.08063)

    NECE是一个开源的故事事件链提取工具包，能够自动提取和对齐故事事件，并可用于分析故事偏见。

    

    为了理解一个故事，理解事件的时间流动尤为重要，尤其是与主要角色相关的事件；然而，对于冗长和非结构化的故事文本，这可能是具有挑战性的。为了解决这个问题，我们介绍了NECE，一个开放获取的、基于文档级别的工具包，它可以自动提取和对齐故事事件，按照它们发生的时间顺序排列。通过广泛的评估，我们展示了NECE工具包的高质量，并展示了它在分析与性别相关的故事偏见方面的应用。我们还公开讨论了当前方法的缺点，以及未来工作中利用生成模型的潜力。最后，NECE工具包包括一个Python库和一个用户友好的Web界面，为专业人员和普通大众提供平等的访问权，可以可视化事件链，获取故事流程，或者研究故事偏见。

    To understand a narrative, it is essential to comprehend the temporal event flows, especially those associated with main characters; however, this can be challenging with lengthy and unstructured narrative texts. To address this, we introduce NECE, an open-access, document-level toolkit that automatically extracts and aligns narrative events in the temporal order of their occurrence. Through extensive evaluations, we show the high quality of the NECE toolkit and demonstrates its downstream application in analyzing narrative bias regarding gender. We also openly discuss the shortcomings of the current approach, and potential of leveraging generative models in future works. Lastly the NECE toolkit includes both a Python library and a user-friendly web interface, which offer equal access to professionals and layman audience alike, to visualize event chain, obtain narrative flows, or study narrative bias.
    
[^107]: 机器学习和计算机视觉技术在蜜蜂监测应用中的应用

    Machine Learning and Computer Vision Techniques in Bee Monitoring Applications. (arXiv:2208.00085v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2208.00085](http://arxiv.org/abs/2208.00085)

    本文介绍了机器学习和计算机视觉在蜜蜂监测中的最新应用，展示了自动化蜜蜂计数算法的潜力，并希望能够激发其他科学家的灵感和兴趣。

    

    机器学习和计算机视觉是快速发展的领域，已经证明能够解决非常复杂的任务。它们可以用于监测蜜蜂群体并检查其健康状况，从而在情况变得严重之前，识别出潜在危险状态，或者更好地计划定期蜜蜂群体检查，从而节省重要的成本。本文概述了用于蜜蜂监测的最先进的计算机视觉和机器学习应用，并以自动化蜜蜂计数算法为例展示了这些方法的潜力。本文面向兽医学和蜜蜂学专业人员和专家，旨在向他们介绍机器学习的可能性，因此每个应用类别都以简要的理论介绍和与其基本方法相关的动机开篇。我们希望这篇论文能激发其他科学家的灵感...

    Machine learning and computer vision are dynamically growing fields, which have proven to be able to solve very complex tasks. They could also be used for the monitoring of the honeybee colonies and for the inspection of their health state, which could identify potentially dangerous states before the situation is critical, or to better plan periodic bee colony inspections and therefore save significant costs. In this paper, we present an overview of the state-of-the-art computer vision and machine learning applications used for bee monitoring. We also demonstrate the potential of those methods as an example of an automated bee counter algorithm. The paper is aimed at veterinary and apidology professionals and experts, who might not be familiar with machine learning to introduce to them its possibilities, therefore each family of applications is opened by a brief theoretical introduction and motivation related to its base method. We hope that this paper will inspire other scientists to 
    
[^108]: GUARD: 图形通用对抗防御

    GUARD: Graph Universal Adversarial Defense. (arXiv:2204.09803v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2204.09803](http://arxiv.org/abs/2204.09803)

    GUARD是一种新颖的图形通用对抗防御方法，旨在提高GCNs对针对性攻击的局部节点的鲁棒性，并在不降低整体性能的情况下进行防御。

    

    图形卷积网络（GCNs）已被证明对小的对抗性扰动具有脆弱性，这成为安全关键场景下应用的严重威胁并且极大限制了其应用。为了减轻这种威胁，已经投入大量研究工作来增加GCNs对抗性攻击的鲁棒性。然而，当前的防御方法通常被设计用于防止GCNs遭受非针对性的对抗性攻击并且着重于整体性能，这使得保护重要局部节点免受更强有力的针对性攻击变得具有挑战性。此外，现有研究往往在鲁棒性和性能之间进行权衡。这些限制凸显了开发一种能够防御针对性攻击的局部节点而不损害GCNs整体性能的有效且高效方法的必要性。在这项工作中，我们提出了一种简单而有效的方法，名为Graph Universal Adversarial Defense（GUARD）。

    Graph convolutional networks (GCNs) have been shown to be vulnerable to small adversarial perturbations, which becomes a severe threat and largely limits their applications in security-critical scenarios. To mitigate such a threat, considerable research efforts have been devoted to increasing the robustness of GCNs against adversarial attacks. However, current defense approaches are typically designed to prevent GCNs from untargeted adversarial attacks and focus on overall performance, making it challenging to protect important local nodes from more powerful targeted adversarial attacks. Additionally, a trade-off between robustness and performance is often made in existing research. Such limitations highlight the need for developing an effective and efficient approach that can defend local nodes against targeted attacks, without compromising the overall performance of GCNs. In this work, we present a simple yet effective method, named Graph Universal Adversarial Defense (GUARD). Unlike
    
[^109]: POSTER:一种金字塔交叉融合变压器网络用于面部表情识别

    POSTER: A Pyramid Cross-Fusion Transformer Network for Facial Expression Recognition. (arXiv:2204.04083v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.04083](http://arxiv.org/abs/2204.04083)

    POSTER是一种金字塔交叉融合变压器网络，旨在全面解决面部表情识别中的类间相似性、类内差异性和尺度敏感性问题。通过设计变压器的交叉融合方法和采用金字塔结构，POSTER达到了最先进的效果。

    

    面部表情识别（FER）是计算机视觉中的一项重要任务，在人机交互、教育、医疗和在线监控等领域具有实际应用。在这个具有挑战性的FER任务中，存在三个主要问题: 类间相似性、类内差异性和尺度敏感性。虽然现有的作品通常解决其中的一些问题，但没有一个统一框架完全解决了这三个挑战。在本文中，我们提出了一种称为POSTER的双流金字塔交叉融合变压器网络，旨在全面解决这三个问题。具体而言，我们设计了一种基于变压器的交叉融合方法，以实现面部标志特征和图像特征的有效协作，最大限度地关注显著的面部区域。此外，POSTER采用了金字塔结构来提高尺度不变性。广泛的实验结果表明，我们的POSTER取得了新的最先进的结果。

    Facial expression recognition (FER) is an important task in computer vision, having practical applications in areas such as human-computer interaction, education, healthcare, and online monitoring. In this challenging FER task, there are three key issues especially prevalent: inter-class similarity, intra-class discrepancy, and scale sensitivity. While existing works typically address some of these issues, none have fully addressed all three challenges in a unified framework. In this paper, we propose a two-stream Pyramid crOss-fuSion TransformER network (POSTER), that aims to holistically solve all three issues. Specifically, we design a transformer-based cross-fusion method that enables effective collaboration of facial landmark features and image features to maximize proper attention to salient facial regions. Furthermore, POSTER employs a pyramid structure to promote scale invariance. Extensive experimental results demonstrate that our POSTER achieves new state-of-the-art results o
    
[^110]: 可扩展的决策集中学习在具有应用于母婴健康的不安定多臂赌博环境下

    Scalable Decision-Focused Learning in Restless Multi-Armed Bandits with Application to Maternal and Child Health. (arXiv:2202.00916v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.00916](http://arxiv.org/abs/2202.00916)

    本文提出了一种在不安定多臂赌博（RMAB）问题中进行决策集中学习的新方法，通过直接训练预测模型来最大化Whittle指数解决方案质量。

    

    本文研究了具有未知臂之间转移动力学但具有已知相关臂特征的不安定多臂赌博（RMAB）问题。目标是学习一个模型，根据特征预测转移动力学，其中Whittle指数策略使用预测的转移来解决RMAB问题。然而，先前的研究通常通过最大化预测准确性而不是最终RMAB解决方案质量来学习模型，导致训练目标与评估目标不匹配。为了解决这个问题，我们提出了一种在RMAB中直接训练预测模型以最大化Whittle指数解决方案质量的新方法。

    This paper studies restless multi-armed bandit (RMAB) problems with unknown arm transition dynamics but with known correlated arm features. The goal is to learn a model to predict transition dynamics given features, where the Whittle index policy solves the RMAB problems using predicted transitions. However, prior works often learn the model by maximizing the predictive accuracy instead of final RMAB solution quality, causing a mismatch between training and evaluation objectives. To address this shortcoming, we propose a novel approach for decision-focused learning in RMAB that directly trains the predictive model to maximize the Whittle index solution quality. We present three key contributions: (i) we establish differentiability of the Whittle index policy to support decision-focused learning; (ii) we significantly improve the scalability of decision-focused learning approaches in sequential problems, specifically RMAB problems; (iii) we apply our algorithm to a previously collected 
    
[^111]: 关于使用双感知相似性进行渐进网络对齐的能力研究

    On the Power of Gradual Network Alignment Using Dual-Perception Similarities. (arXiv:2201.10945v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2201.10945](http://arxiv.org/abs/2201.10945)

    本研究提出了Grad-Align，一种渐进网络对齐方法，通过利用强一致性节点对逐步发现节点对。该方法首先生成节点嵌入，然后计算双感知相似性度量逐步对齐节点。

    

    网络对齐（NA）是基于网络结构和节点属性查找两个网络之间节点对应关系的任务。我们的研究动机在于，由于大多数现有的NA方法都试图一次性发现所有节点对，因此它们没有利用通过节点对应关系的中间发现来更准确地找到节点匹配过程中的下一个对应关系的信息。为了解决这个挑战，我们提出了Grad-Align，一种新的渐进网络对齐方法，通过充分利用在渐进匹配的早期阶段容易发现的节点对来逐步发现节点对。具体而言，Grad-Align首先基于图神经网络和我们的逐层重构损失生成两个网络的节点嵌入。然后，通过计算双感知相似性度量逐步对齐节点。

    Network alignment (NA) is the task of finding the correspondence of nodes between two networks based on the network structure and node attributes. Our study is motivated by the fact that, since most of existing NA methods have attempted to discover all node pairs at once, they do not harness information enriched through interim discovery of node correspondences to more accurately find the next correspondences during the node matching. To tackle this challenge, we propose Grad-Align, a new NA method that gradually discovers node pairs by making full use of node pairs exhibiting strong consistency, which are easy to be discovered in the early stage of gradual matching. Specifically, Grad-Align first generates node embeddings of the two networks based on graph neural networks along with our layer-wise reconstruction loss, a loss built upon capturing the first-order and higher-order neighborhood structures. Then, nodes are gradually aligned by computing dual-perception similarity measures 
    
[^112]: 模型为基础的安全强化学习在时间变化状态和控制约束下的应用：智能车辆中的应用

    Model-Based Safe Reinforcement Learning with Time-Varying State and Control Constraints: An Application to Intelligent Vehicles. (arXiv:2112.11217v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.11217](http://arxiv.org/abs/2112.11217)

    本文提出了一种安全RL算法，结合了基于屏障力的控制策略结构与多步策略评估机制，在保证控制安全的同时，能够应对时间变化的安全约束，并证明了其稳定性、鲁棒性和收敛性，优于几种最先进的RL算法。

    

    近年来，基于演员-评论家结构的安全强化学习（RL）在连续控制任务中受到越来越多的关注。学习一个具有安全性和收敛性保证的近似最优控制策略仍然具有挑战性。同时，很少有作品讨论了在时间变化的安全性约束下设计安全RL算法。本文提出了一种安全RL算法，用于具有时间变化状态和控制约束的非线性系统的最优控制。在所提出的方法中，我们构建了一种新颖的基于屏障力的控制策略结构，以保证控制安全。提出了一种多步策略评估机制，用于预测策略在时间变化的安全约束下的安全风险，并指导策略安全更新。已证明稳定性和鲁棒性的理论结果。同时，分析了演员评论家实现的收敛性。所提出的算法的性能在模拟的Sa中优于几种最先进的RL算法

    Recently, safe reinforcement learning (RL) with the actor-critic structure for continuous control tasks has received increasing attention. It is still challenging to learn a near-optimal control policy with safety and convergence guarantees. Also, few works have addressed the safe RL algorithm design under time-varying safety constraints. This paper proposes a safe RL algorithm for optimal control of nonlinear systems with time-varying state and control constraints. In the proposed approach, we construct a novel barrier force-based control policy structure to guarantee control safety. A multi-step policy evaluation mechanism is proposed to predict the policy's safety risk under time-varying safety constraints and guide the policy to update safely. Theoretical results on stability and robustness are proven. Also, the convergence of the actor-critic implementation is analyzed. The performance of the proposed algorithm outperforms several state-of-the-art RL algorithms in the simulated Sa
    
[^113]: 数据驱动举措中认识不确定性的表达及其感知

    Representations of epistemic uncertainty and its perception in data-driven initiatives. (arXiv:2110.11482v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2110.11482](http://arxiv.org/abs/2110.11482)

    本研究为了支持不断发展的数据驱动方法论，提出了一个新颖的概念模型，用于描述知识表示中的不确定性，并推理代理人进行的信息传输。通过对知识状态和其动态的代数描述，我们能够比较和组合知识状态，以表示更新。

    

    借助人工智能的出现推动的新兴数据驱动策略正在重塑决策过程，远离对直接数据交互的传统依赖。这种范式转变引入了评估数据驱动举措影响的新挑战。为了支持这些不断发展的方法论，迫切需要新的模型，能够描述源于有限数据可观测性以及由此产生的决策中的歧义的不确定性。本文提出了一个新颖的概念模型，旨在处理知识表示中的不确定性，并推理代理人进行信息传输的不确定性。借鉴目前用于评估数据驱动举措产生的价值的多维框架，我们提供了对知识状态及其动态的代数描述。具体而言，我们赋予我们的模型一种形式化结构，用于比较和组合知识状态；通过这些组合来表示更新。

    Emerging data-driven strategies, powered by the advent of AI, are reshaping decision-making processes, moving away from traditional reliance on direct data interaction. This paradigm shift introduces new challenges in assessing the impact of data-driven initiatives. To support these evolving methodologies, there is a crucial need for new models capable of describing the uncertainties stemming from limited data observability and the resulting ambiguities in decision-making. This contribution presents a novel conceptual model designed to deal with uncertainty in knowledge representations and reasoning about information transfer mediated by agents. Drawing from the multidimensional frameworks currently adopted to assess the value generated in data-driven initiatives, we provide an algebraic description of knowledge states and their dynamics. Specifically, we endow our model with a formal structure to compare and combine knowledge states; an update is represented through these combinations
    
[^114]: 密集森林林冠下的大规模自主飞行与实时语义SLAM

    Large-scale Autonomous Flight with Real-time Semantic SLAM under Dense Forest Canopy. (arXiv:2109.06479v5 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2109.06479](http://arxiv.org/abs/2109.06479)

    本文提出了一个集成系统，可以在密集森林林冠下进行大规模自主飞行和实时语义地图构建。系统使用LiDAR数据检测和建模树干和地面平面，并利用多级规划和地图构建框架计算动态可行的轨迹，以构建用户定义感兴趣区域的语义地图，并通过语义SLAM来最小化里程计漂移。

    

    语义地图使用一组具有语义意义的对象表示环境。这种表示方式在存储效率、歧义性减少和信息丰富度方面更好，为在高度无结构、无GPS的环境中进行大规模自治飞行和获取可操作信息提供方便。在本文中，我们提出了一个集成系统，能够在具有挑战性的林冠下环境中进行大规模自主飞行和实时语义地图构建。我们使用LiDAR数据检测和建模树干和地面平面，这些信息与扫描数据相关联，并用于约束机器人姿态和树干模型。自主导航模块利用多级规划和地图构建框架，以计算动态可行的轨迹，使无人机以计算和存储有效的方式构建用户定义感兴趣区域的语义地图。设计了漂移补偿机制，通过语义SLAM来最小化里程计漂移。

    Semantic maps represent the environment using a set of semantically meaningful objects. This representation is storage-efficient, less ambiguous, and more informative, thus facilitating large-scale autonomy and the acquisition of actionable information in highly unstructured, GPS-denied environments. In this letter, we propose an integrated system that can perform large-scale autonomous flights and real-time semantic mapping in challenging under-canopy environments. We detect and model tree trunks and ground planes from LiDAR data, which are associated across scans and used to constrain robot poses as well as tree trunk models. The autonomous navigation module utilizes a multi-level planning and mapping framework and computes dynamically feasible trajectories that lead the UAV to build a semantic map of the user-defined region of interest in a computationally and storage efficient manner. A drift-compensation mechanism is designed to minimize the odometry drift using semantic SLAM outp
    
[^115]: MathBERT: 一种用于数学教育中的通用自然语言处理任务的预训练语言模型

    MathBERT: A Pre-trained Language Model for General NLP Tasks in Mathematics Education. (arXiv:2106.07340v5 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2106.07340](http://arxiv.org/abs/2106.07340)

    MathBERT是一个基于BASE BERT模型在大规模数学语料库上进行预训练的模型，为数学教育中的通用NLP任务提供了新的解决方案。

    

    自从原始的BERT（即BASE BERT）的引入以来，研究人员通过利用迁移学习的优势，开发了各种定制的BERT模型来改进特定领域和任务的性能。由于数学文本的性质，经常使用领域特定的词汇以及方程和数学符号，我们认为开发一个针对数学的新BERT模型将对许多数学下游任务有用。在这篇资源论文中，我们介绍了我们的多机构努力（即两个学习平台和三个美国学术机构）以满足这个需求：MathBERT，一个通过在大规模数学语料库上对BASE BERT模型进行预训练而创建的模型，该语料库涵盖了从学前教育（pre-k）到高中以及研究生水平的数学内容。此外，我们选择了三个常用于数学教育的通用NLP任务：知识组件预测，自动评分开放性问题和知识追溯。

    Since the introduction of the original BERT (i.e., BASE BERT), researchers have developed various customized BERT models with improved performance for specific domains and tasks by exploiting the benefits of transfer learning. Due to the nature of mathematical texts, which often use domain specific vocabulary along with equations and math symbols, we posit that the development of a new BERT model for mathematics would be useful for many mathematical downstream tasks. In this resource paper, we introduce our multi-institutional effort (i.e., two learning platforms and three academic institutions in the US) toward this need: MathBERT, a model created by pre-training the BASE BERT model on a large mathematical corpus ranging from pre-kindergarten (pre-k), to high-school, to college graduate level mathematical content. In addition, we select three general NLP tasks that are often used in mathematics education: prediction of knowledge component, auto-grading open-ended Q&A, and knowledge tr
    
[^116]: 图卷积神经网络中的自适应滤波器

    Adaptive Filters in Graph Convolutional Neural Networks. (arXiv:2105.10377v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2105.10377](http://arxiv.org/abs/2105.10377)

    该论文研究了自适应滤波器在图卷积神经网络中的应用，通过探索和利用图结构的灵活性，提高了网络处理图数据的性能。

    

    在过去的几年中，我们目睹了非欧几里得领域产生的越来越多的数据可用性，这些领域通常以复杂关系表示为图形，图神经网络 (GNN) 由于在处理图结构数据时的潜力而引起了高度关注。特别地，人们对使用 GNN 架构的扩展来在图上进行卷积的可能性非常感兴趣，这个架构通常被称为图卷积神经网络 (ConvGNN)。在图上的卷积主要分为频谱卷积和空间卷积两种形式。由于在探索和利用数据的图结构方面更加灵活，最近对于研究空间方法所能提供的可能性越来越感兴趣。找到一种适应处理输入的网络行为的方法，以最大化总体性能的想法，在神经网络中引起了广泛的兴趣。

    Over the last few years, we have witnessed the availability of an increasing data generated from non-Euclidean domains, which are usually represented as graphs with complex relationships, and Graph Neural Networks (GNN) have gained a high interest because of their potential in processing graph-structured data. In particular, there is a strong interest in exploring the possibilities in performing convolution on graphs using an extension of the GNN architecture, generally referred to as Graph Convolutional Neural Networks (ConvGNN). Convolution on graphs has been achieved mainly in two forms: spectral and spatial convolutions. Due to the higher flexibility in exploring and exploiting the graph structure of data, there is recently an increasing interest in investigating the possibilities that the spatial approach can offer. The idea of finding a way to adapt the network behaviour to the inputs they process to maximize the total performances has aroused much interest in the neural networks
    
[^117]: 因果协同过滤

    Causal Collaborative Filtering. (arXiv:2102.01868v5 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2102.01868](http://arxiv.org/abs/2102.01868)

    本论文提出了一种名为因果协同过滤（CCF）的通用框架，用于对协同过滤和推荐中的因果关系进行建模。这种方法可以解决纯粹相关学习导致的预测中的辛普森悖论问题，提高推荐性能。

    

    许多传统的推荐算法基于从数据中挖掘或学习相关模式来估计用户-项目的相关偏好的基本思想设计。然而，纯粹的相关学习可能导致预测中的辛普森悖论，从而导致推荐性能的损失。辛普森悖论是一个众所周知的统计现象，它会导致统计结论的混淆，忽视这个悖论可能导致不准确的决策。幸运的是，因果和反事实建模可以帮助我们超越观察数据进行用户建模和个性化，以解决这些问题。在本文中，我们提出了一种名为因果协同过滤（CCF）的通用框架，用于对协同过滤和推荐中的因果关系进行建模。我们提供了一个统一的因果视图，并从数学上证明了许多传统的协同过滤算法实际上是简化因果图下CCF的特殊情况。

    Many of the traditional recommendation algorithms are designed based on the fundamental idea of mining or learning correlative patterns from data to estimate the user-item correlative preference. However, pure correlative learning may lead to Simpson's paradox in predictions, and thus results in sacrificed recommendation performance. Simpson's paradox is a well-known statistical phenomenon, which causes confusions in statistical conclusions and ignoring the paradox may result in inaccurate decisions. Fortunately, causal and counterfactual modeling can help us to think outside of the observational data for user modeling and personalization so as to tackle such issues. In this paper, we propose Causal Collaborative Filtering (CCF) -- a general framework for modeling causality in collaborative filtering and recommendation. We provide a unified causal view of CF and mathematically show that many of the traditional CF algorithms are actually special cases of CCF under simplified causal grap
    
[^118]: 使用GNN学习NP-Hard多智能体分配规划：在随机图上的推理和可证明的拍卖适配Q学习

    Learning NP-Hard Multi-Agent Assignment Planning using GNN: Inference on a Random Graph and Provable Auction-Fitted Q-learning. (arXiv:1905.12204v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1905.12204](http://arxiv.org/abs/1905.12204)

    本文探索了使用学习算法近乎最优地解决具有时间相关奖励的多智能体、多任务的NP-hard规划问题的可能性。研究结果展示了提出方法在解决机器人/机器调度问题上的近乎最优性。

    

    本文探讨了使用基于学习的算法来近乎最优地解决具有时间相关奖励的多智能体、多任务的NP-hard规划问题的可能性。特别地，我们考虑了一类称为多机器人奖励收集问题（MRRC）的机器人/机器调度问题。这些MRRC问题很好地模拟了共乘、取送和其他相关问题。在将MRRC问题表示为顺序决策问题时，我们观察到每个状态可以被表示为概率图模型（PGM）的扩展，我们将其称为随机PGMs。然后，我们为随机PGMs开发了一种均场推理方法。接下来，我们提出了（1）一个可进行顺序转移的Q函数估计器和（2）一个支持顺序转移的拍卖方法，以在多项式时间内选择联合分配。这些方法导致了一个具有至少$1-1/e$最优性的强化学习框架。在解决MRRC问题的实验结果中突出了近乎最优性。

    This paper explores the possibility of near-optimally solving multi-agent, multi-task NP-hard planning problems with time-dependent rewards using a learning-based algorithm. In particular, we consider a class of robot/machine scheduling problems called the multi-robot reward collection problem (MRRC). Such MRRC problems well model ride-sharing, pickup-and-delivery, and a variety of related problems. In representing the MRRC problem as a sequential decision-making problem, we observe that each state can be represented as an extension of probabilistic graphical models (PGMs), which we refer to as random PGMs. We then develop a mean-field inference method for random PGMs. We then propose (1) an order-transferable Q-function estimator and (2) an order-transferability-enabled auction to select a joint assignment in polynomial time. These result in a reinforcement learning framework with at least $1-1/e$ optimality. Experimental results on solving MRRC problems highlight the near-optimality 
    

