# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Tell, Don't Show!: Language Guidance Eases Transfer Across Domains in Images and Videos](https://arxiv.org/abs/2403.05535) | 该论文提出了LaGTran框架，利用文本描述来引导知识转移，在处理具有挑战性的数据集上表现出显著优势。 |
| [^2] | [Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context](https://arxiv.org/abs/2403.05530) | Gemini 1.5 Pro是一种高效计算的多模态混合模型，能在数百万标记的上下文中回忆和推理信息，达到近乎完美的长上下文检索任务召回率，改进了长文档问答、长视频问答和长上下文ASR的最新技术水平。 |
| [^3] | [GEAR: An Efficient KV Cache Compression Recipefor Near-Lossless Generative Inference of LLM](https://arxiv.org/abs/2403.05527) | GEAR提出了一种高效的KV缓存压缩框架，实现几乎无损的高比率压缩，用于解决大型语言模型推断中因缓存需求增长而导致的记忆绑定问题和性能下降。 |
| [^4] | [DeepSeek-VL: Towards Real-World Vision-Language Understanding](https://arxiv.org/abs/2403.05525) | DeepSeek-VL是一个面向真实世界的视觉语言理解模型，通过多样化数据、真实场景覆盖和高效编码器的设计，大大提高了在实际应用中的用户体验 |
| [^5] | [Bias-Augmented Consistency Training Reduces Biased Reasoning in Chain-of-Thought](https://arxiv.org/abs/2403.05518) | 引入偏差增强的一致性训练（BCT）可以显著减少链式思维中的偏见推理问题，尤其是通过训练模型在带有和不带有偏置特征的提示下进行一致的推理。 |
| [^6] | [Poly-View Contrastive Learning](https://arxiv.org/abs/2403.05490) | 本研究提出了多视图对比学习方法，通过新的表示学习目标优化匹配多个相关视图，在ImageNet1k数据集上的实验结果显示，相比于SimCLR模型，多视图对比模型在更少的训练轮数和更小的批大小下表现更优。 |
| [^7] | [Will GPT-4 Run DOOM?](https://arxiv.org/abs/2403.05468) | GPT-4通过自身的推理和观察能力，可以运行并玩1993年的第一人称射击游戏《毁灭战士》，并且能够执行门操作、击败敌人和规划路径，这有望拓展基于LLM的智能代理在视频游戏领域的边界。 |
| [^8] | [Algorithm-Hardware Co-Design of Distribution-Aware Logarithmic-Posit Encodings for Efficient DNN Inference](https://arxiv.org/abs/2403.05465) | 引入了对数正定编码（LP）和LP量化（LPQ）框架，采用基因算法寻找最优的LP参数，设计了统一的混合精度LP加速器（LPA）体系结构，可动态适应DNN参数分布，减少量化和完整精度模型之间的表示性差异。 |
| [^9] | [Algorithmic Identification of Essential Exogenous Nodes for Causal Sufficiency in Brain Networks](https://arxiv.org/abs/2403.05407) | 本研究提出了一种算法识别方法，用于在大脑网络中确定满足关键因果充分性需求的关键外源节点。 |
| [^10] | [Considering Nonstationary within Multivariate Time Series with Variational Hierarchical Transformer for Forecasting](https://arxiv.org/abs/2403.05406) | 论文提出了一种名为HTV-Trans的Hierarchical Time series Variational Transformer模型，通过结合层次概率生成模块和Transformer，能够有效考虑多元时间序列中的非平稳性和随机特性，从而更好地回复时间依赖关系。 |
| [^11] | [HistGen: Histopathology Report Generation via Local-Global Feature Encoding and Cross-modal Context Interaction](https://arxiv.org/abs/2403.05396) | HistGen是一个通过本地-全局特征编码和跨模态上下文交互来生成组织病理学报告的框架，提供了第一个用于评估的基准数据集。 |
| [^12] | [Self-Supervised Multiple Instance Learning for Acute Myeloid Leukemia Classification](https://arxiv.org/abs/2403.05379) | 自本研究发现自监督预训练编码器在多实例学习中实现了可比较的性能，展示了自监督学习在急性髓细胞白血病分类中的潜力，这为一种经济高效且节约数据的解决方案。 |
| [^13] | [WatChat: Explaining perplexing programs by debugging mental models](https://arxiv.org/abs/2403.05334) | 本文通过应用计算认知科学的方法，提出了一种能够通过调试心智模型解释令人困惑程序行为的方法。 |
| [^14] | [ChatASU: Evoking LLM's Reflexion to Truly Understand Aspect Sentiment in Dialogues](https://arxiv.org/abs/2403.05326) | 本文提出了一个新的基于聊天的方面情绪理解（ChatASU）任务，旨在探索大型语言模型（LLMs）在对话场景中理解方面情绪的能力，并引入了一个子任务Aspect Chain Reasoning（ACR）任务来解决方面共指问题。 |
| [^15] | [Looking Ahead to Avoid Being Late: Solving Hard-Constrained Traveling Salesman Problem](https://arxiv.org/abs/2403.05318) | 提出一种利用展望信息作为特征改善具有时间窗口的TSP解决方案合法性的新颖学习方法 |
| [^16] | [RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation](https://arxiv.org/abs/2403.05313) | RAT方法通过检索增强思维，在长视角生成中改善大型语言模型的推理和生成能力，显著降低了幻觉，并取得了显著的性能提升 |
| [^17] | [Tapilot-Crossing: Benchmarking and Evolving LLMs Towards Interactive Data Analysis Agents](https://arxiv.org/abs/2403.05307) | Tapilot-Crossing是一个用于评估LLM代理在交互式数据分析任务中的新基准，通过经济型多代理环境和自适应交互反思策略进行构建和评估，凸显了交互式数据分析的挑战 |
| [^18] | [Unity by Diversity: Improved Representation Learning in Multimodal VAEs](https://arxiv.org/abs/2403.05300) | 通过软约束取代硬约束，提出了一种新的专家混合先验，改善了多模态VAEs中的表示学习。 |
| [^19] | [PEEB: Part-based Image Classifiers with an Explainable and Editable Language Bottleneck](https://arxiv.org/abs/2403.05297) | PEEB是一种基于部分的图像分类器，通过将类别名称转换为描述视觉部分的文本描述符，并将检测到的部分的嵌入与文本描述符匹配，从而在零样本设置中表现出色，并且不仅在监督学习中表现出色，而且还首次实现用户编辑类定义形成新分类器无需重新训练。 |
| [^20] | [ERBench: An Entity-Relationship based Automatically Verifiable Hallucination Benchmark for Large Language Models](https://arxiv.org/abs/2403.05266) | ERBench是一个基于实体关系的大型语言模型幻觉基准，通过自动转换任何关系数据库并构建可自动验证的问题，以支持复杂性评估和调试 |
| [^21] | [MMoE: Robust Spoiler Detection with Multi-modal Information and Domain-aware Mixture-of-Experts](https://arxiv.org/abs/2403.05265) | 提出了MMoE，一个利用多模态信息进行剧透检测的网络，并采用专家混合技术来增强领域泛化能力。 |
| [^22] | [Predicting Single-cell Drug Sensitivity by Adaptive Weighted Feature for Adversarial Multi-source Domain Adaptation](https://arxiv.org/abs/2403.05260) | 本文提出了一种名为scAdaDrug的多源自适应加权模型，通过对抗性领域自适应从多个源领域中提取药物敏感性相关的域不变特征，并引入自适应权重生成器来自适应地调节每个样本的嵌入，以预测单细胞药物敏感性。 |
| [^23] | [Noise Level Adaptive Diffusion Model for Robust Reconstruction of Accelerated MRI](https://arxiv.org/abs/2403.05245) | 提出了一种具有噪声水平自适应特性的后验采样策略，可用于解决MRI重建过程中因真实噪声水平变化导致的重建不准确问题。 |
| [^24] | [Towards Effective Usage of Human-Centric Priors in Diffusion Models for Text-based Human Image Generation](https://arxiv.org/abs/2403.05239) | 本文提出了一种新方法，通过将人性先验直接融入模型微调阶段，强化文本提示中的人体相关信息，并引入规模感知和逐步约束，从而有效提升了基于扩散模型的文本人体图像生成质量 |
| [^25] | [Fairness-Aware Interpretable Modeling (FAIM) for Trustworthy Machine Learning in Healthcare](https://arxiv.org/abs/2403.05235) | FAIM是一个用于提高医疗保健领域机器学习公平性的可解释框架，通过交互界面识别最公平模型，并结合数据驱动证据与临床专家知识，成功减少了性别和种族偏见。 |
| [^26] | [Developing Federated Time-to-Event Scores Using Heterogeneous Real-World Survival Data](https://arxiv.org/abs/2403.05229) | 提出了一种用于建立多站点生存结果的联邦评分系统的新框架，确保了隐私和通信效率 |
| [^27] | [Synthetic Privileged Information Enhances Medical Image Representation Learning](https://arxiv.org/abs/2403.05220) | 合成生成的配对信息显著改善了医学图像表示学习，相比于单模态训练或真实多模态配对数据集，误差减小分别达到4.4倍和5.6倍 |
| [^28] | [Harnessing Multi-Role Capabilities of Large Language Models for Open-Domain Question Answering](https://arxiv.org/abs/2403.05217) | 提出了LLMQA框架，利用大型语言模型在开放领域问答中扮演生成器、重新排序器和评估器等多重角色，结合了检索和生成证据的优势。 |
| [^29] | [Overcoming Data Inequality across Domains with Semi-Supervised Domain Generalization](https://arxiv.org/abs/2403.05209) | 本文提出了一种名为ProUD的新算法，通过领域感知原型和通过不确定性自适应混合标记和未标记领域的渐进泛化，有效解决了跨领域数据不平等问题中的半监督领域泛化挑战。 |
| [^30] | [Tracing the Roots of Facts in Multilingual Language Models: Independent, Shared, and Transferred Knowledge](https://arxiv.org/abs/2403.05189) | 本研究追踪了多语言语言模型中事实的来源，发现了三种模式：语言独立、跨语言共享和转移，为区分它们提出了方法，凸显了在多语言LMs中保持一致事实知识的挑战，强调了需要在ML-LMs中改进事实表示学习。 |
| [^31] | [Continual Learning and Catastrophic Forgetting](https://arxiv.org/abs/2403.05175) | 人工神经网络在持续学习过程中容易出现灾难性遗忘，这一问题是深度学习中持续学习领域的关键挑战。 |
| [^32] | [Overcoming Reward Overoptimization via Adversarial Policy Optimization with Lightweight Uncertainty Estimation](https://arxiv.org/abs/2403.05171) | 本论文提出了对抗策略优化（AdvPO）来解决强化学习领域中奖励过度优化的问题，通过量化奖励的不确定性，并围绕奖励模型预测的置信区间进行分布鲁棒的优化，从而有效缓解了该问题。 |
| [^33] | [Unlocking the Potential of Multimodal Unified Discrete Representation through Training-Free Codebook Optimization and Hierarchical Alignment](https://arxiv.org/abs/2403.05168) | 通过无需训练的码本优化和分层对齐，本研究提出了一种方法扩展了多模态统一表示的细粒度，并实现了更好的跨模态泛化。 |
| [^34] | [Synthetic data generation for system identification: leveraging knowledge transfer from similar systems](https://arxiv.org/abs/2403.05164) | 本文提出了一种从类似系统中进行知识转移的新方法，用于生成合成数据，以改善模型的泛化能力和鲁棒性。 |
| [^35] | [Adaptive Split Learning over Energy-Constrained Wireless Edge Networks](https://arxiv.org/abs/2403.05158) | 设计了一种在无线边缘网络中为设备动态选择分裂点并为服务器分配计算资源的自适应分裂学习方案，以最小化平均训练延迟为目标，并提出了一种名为OPEN的在线算法解决此问题。 |
| [^36] | [Towards a Psychology of Machines: Large Language Models Predict Human Memory](https://arxiv.org/abs/2403.05152) | 这项研究探索了大型语言模型在预测基于语言的记忆任务中的表现，并通过其对模棱两可句子的处理能力增进了对人类认知机制的理解。 |
| [^37] | [Inverse Design of Photonic Crystal Surface Emitting Lasers is a Sequence Modeling Problem](https://arxiv.org/abs/2403.05149) | 引入Transformer架构, 本文提出了一个名为PCSEL逆向设计Tra的新框架，将光子晶体面射激光器的逆向设计建模为一个序列决策问题，利用RL方法从头开始构建满意的PCSEL结构。 |
| [^38] | [ChatUIE: Exploring Chat-based Unified Information Extraction using Large Language Models](https://arxiv.org/abs/2403.05132) | ChatUIE利用大型语言模型探索基于聊天的统一信息提取，通过强化学习和生成约束提高对自然语言中结构化信息的提取能力。 |
| [^39] | [Sora as an AGI World Model? A Complete Survey on Text-to-Video Generation](https://arxiv.org/abs/2403.05131) | 对文本到视频生成技术的发展进行了详细调查, 着重介绍了从传统生成模型到尖端Sora模型的转变，强调了可扩展性和通用性的发展。 |
| [^40] | [From Chain to Tree: Refining Chain-like Rules into Tree-like Rules on Knowledge Graphs](https://arxiv.org/abs/2403.05130) | 提出了在知识图谱上将链式规则优化为树形规则的概念，并提出有效框架，实现了更好的推理性能。 |
| [^41] | [Unraveling the Molecular Magic: AI Insights on the Formation of Extraordinarily Stretchable Hydrogels](https://arxiv.org/abs/2403.05129) | 本研究通过人工智能预测系统探索了一种通过两种聚合物相互连接，形成具有独特结构的水凝胶的新方法，并命名为“跨链网”。 |
| [^42] | [Evaluating Text-to-Image Generative Models: An Empirical Study on Human Image Synthesis](https://arxiv.org/abs/2403.05125) | 本文提出了一个细致的评估框架，用于评估文本到图像生成模型，针对人类图像合成。我们引入了一个创新的美学分数预测模型，评估生成图像的视觉吸引力，并展示了第一个标记有生成的人类图像中低质量区域的数据集，以促进自动缺陷检测，同时也研究了模型对概念覆盖度和公平性的影响。 |
| [^43] | [RLPeri: Accelerating Visual Perimetry Test with Reinforcement Learning and Convolutional Feature Extraction](https://arxiv.org/abs/2403.05112) | RLPeri是一种基于强化学习的方法，旨在通过确定最佳位置顺序和初始刺激值来加速视野测定测试，同时通过奖励塑形技术进一步提高测试性能。 |
| [^44] | [Efficient Data Collection for Robotic Manipulation via Compositional Generalization](https://arxiv.org/abs/2403.05110) | 通过研究机器人策略的复合能力，可以避免收集处理复合情况所需的数据。 |
| [^45] | [A Task-Driven Multi-UAV Coalition Formation Mechanism](https://arxiv.org/abs/2403.05108) | 本文提出了一种考虑联盟工作能力和任务需求关系的新型多无人机联盟网络协作任务完成模型，通过利用基于联盟收入阈值的收入函数刺激匹配任务需求的联盟形成，并提出了一种基于边际效用的联盟形成算法。 |
| [^46] | [Learning to Rematch Mismatched Pairs for Robust Cross-Modal Retrieval](https://arxiv.org/abs/2403.05105) | 通过提出基于最优传输的通用框架L2RM，学习重新匹配不匹配的对，以解决跨模态检索中由部分不匹配对引起的性能问题。 |
| [^47] | [How Culture Shapes What People Want From AI](https://arxiv.org/abs/2403.05104) | 本研究提出了一个新的概念框架，旨在通过独立和相互依存的自我和环境文化模型来拓展、重新想象和重视主流人工智能愿景的研究。调查显示，不同文化背景的人们对人工智能的期望存在差异，中国受访者更看重与人工智能建立联系，更偏好具有影响力的人工智能。ostringstream中也存在欧裔美国和中国受访者文化模型的反映。 |
| [^48] | [Rule-driven News Captioning](https://arxiv.org/abs/2403.05101) | 本文提出了一种基于规则的新闻标题生成方法，通过新闻感知的语义规则，可以生成遵循新闻报道基本规则的图像描述。 |
| [^49] | [Exploring the Adversarial Frontier: Quantifying Robustness via Adversarial Hypervolume](https://arxiv.org/abs/2403.05100) | 提出新指标对抗超体积来全面评估深度学习模型在多种扰动强度下的鲁棒性，并采用新型训练算法来提高对抗鲁棒性。 |
| [^50] | [Reset & Distill: A Recipe for Overcoming Negative Transfer in Continual Reinforcement Learning](https://arxiv.org/abs/2403.05066) | 开发了Reset & Distill（R&D）方法，通过重置代理的网络和提炼知识，有效克服了持续强化学习中负迁移问题。 |
| [^51] | [Unsupervised Graph Neural Architecture Search with Disentangled Self-supervision](https://arxiv.org/abs/2403.05064) | 提出了一种新颖的解耦自监督图神经架构搜索（DSGAS）模型，能够发现捕获各种潜在图因素的最佳架构 |
| [^52] | [Aligning Large Language Models for Controllable Recommendations](https://arxiv.org/abs/2403.05063) | 通过引入监督学习任务和强化学习对齐程序，研究人员提出了一种方法来改善大型语言模型适应推荐指令和减少格式错误的能力。 |
| [^53] | [PrimeComposer: Faster Progressively Combined Diffusion for Image Composition with Attention Steering](https://arxiv.org/abs/2403.05053) | 本文提出了PrimeComposer，一种更快的逐步组合扩散方式，用于图像合成，主要专注于前景生成，从而解决了合成中的凝聚混乱和外观信息丢失问题，并避免了不必要的背景生成导致的前景生成质量下降。 |
| [^54] | [DyRoNet: A Low-Rank Adapter Enhanced Dynamic Routing Network for Streaming Perception](https://arxiv.org/abs/2403.05050) | DyRoNet采用低秩动态路由并结合分支网络优化流媒体感知性能，为多种分支选择策略设定了新的性能标杆 |
| [^55] | [Are Human Conversations Special? A Large Language Model Perspective](https://arxiv.org/abs/2403.05045) | 本研究分析了大型语言模型在理解人类对话时的注意机制变化，发现尽管语言模型在特定领域表现出不同的注意行为，但在专门处理人类对话方面存在明显差距，需要通过多样化的高质量对话数据训练模型来增强理解和生成 |
| [^56] | [Quantifying Manifolds: Do the manifolds learned by Generative Adversarial Networks converge to the real data manifold](https://arxiv.org/abs/2403.05033) | 通过研究ML模型学习到的流形的内在维度和拓扑特征，本文探讨了这些度量在训练过程中是否收敛到真实数据流形的度量。 |
| [^57] | [Defending Against Unforeseen Failure Modes with Latent Adversarial Training](https://arxiv.org/abs/2403.05030) | 本研究利用潜在对抗训练（LAT）来防御AI系统中未预见的故障模式，通过利用网络实际用于预测的压缩、抽象和结构化概念的潜在表示，有效清除了恶意软件和对抗性攻击。 |
| [^58] | [BjTT: A Large-scale Multimodal Dataset for Traffic Prediction](https://arxiv.org/abs/2403.05029) | 本文提出了第一个用于文本-交通生成的扩散模型ChatTraffic，通过将生成模型与交通系统描述文本相结合，解决了交通预测中关联文本和空间结构的挑战。 |
| [^59] | [Spectral Invariant Learning for Dynamic Graphs under Distribution Shifts](https://arxiv.org/abs/2403.05026) | 该论文首次提出在动态图的谱域内研究分布漂移，并提出了谱不变学习方法来应对谱域中的分布漂移挑战。 |
| [^60] | [Towards Multimodal Human Intention Understanding Debiasing via Subject-Deconfounding](https://arxiv.org/abs/2403.05025) | 通过引入概括性因果图和分析主题混淆效应，本文提出了SuCI，实现了多模态人类意图理解的去偏见，解决了MIU模型受主体变异问题困扰的挑战。 |
| [^61] | [Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs](https://arxiv.org/abs/2403.05020) | 研究发现，使用LLMs进行社交互动的全知模拟比非全知模拟更容易实现社交目标，尽管非全知模拟更接近实际情况。 |
| [^62] | [Simple Multigraph Convolution Networks](https://arxiv.org/abs/2403.05014) | 本文提出了一种简单的多图卷积网络（SMGCN），通过提取一致的交叉视图拓扑和执行多项式展开，有效降低了多图卷积的复杂度，实现了可信的交叉视图空间消息传递。 |
| [^63] | [RFWave: Multi-band Rectified Flow for Audio Waveform Reconstruction](https://arxiv.org/abs/2403.05010) | RFWave是一种新颖的多频带整流流动方法，可以从Mel频谱图中重建高保真度音频波形，仅需10个采样步骤即可实现出色的重建质量和优越的计算效率。 |
| [^64] | [Provable Multi-Party Reinforcement Learning with Diverse Human Feedback](https://arxiv.org/abs/2403.05006) | 该研究首次提出了多方协作强化学习的理论研究，通过整合多个个体不同偏好的元学习与不同社会福利函数的采用，克服了传统RLHF方法无法捕捉并平衡多个个体偏好的局限性。 |
| [^65] | [Can't Remember Details in Long Documents? You Need Some R&R](https://arxiv.org/abs/2403.05004) | 引入R&R方法，结合reprompting和in-context retrieval两种新型提示方式，提高了在长文档上的问答任务的准确性。 |
| [^66] | [Medical Speech Symptoms Classification via Disentangled Representation](https://arxiv.org/abs/2403.05000) | 该论文提出了一种名为DRSC的医学言语分类模型，实现了自动学习从文本-声学数据中分离意图和内容表示以进行分类，并在检测25种不同医学症状时取得了95%的平均准确率。 |
| [^67] | [Node Centrality Approximation For Large Networks Based On Inductive Graph Neural Networks](https://arxiv.org/abs/2403.04977) | 重新定义了节点排序问题作为一个机器学习问题，并提出了CNCA-IGE模型，该模型是一个编码器-解码器模型，用于基于归纳图神经网络的大网络节点中心性近似。 |
| [^68] | [StereoDiffusion: Training-Free Stereo Image Generation Using Latent Diffusion Models](https://arxiv.org/abs/2403.04965) | StereoDiffusion是一种无需训练的立体图像生成方法，通过修改潜在变量实现快速生成立体图像对，无需微调模型权重或图像后处理。 |
| [^69] | [Tell me the truth: A system to measure the trustworthiness of Large Language Models](https://arxiv.org/abs/2403.04964) | 本文提出了一种基于预定义领域知识图的系统化方法来衡量大型语言模型的可信度。 |
| [^70] | [An In-depth Evaluation of GPT-4 in Sentence Simplification with Error-based Human Assessment](https://arxiv.org/abs/2403.04963) | 本文深入评估了GPT-4在句子简化中的表现，指出现有自动评估指标和人类评估方法对于大型语言模型的适用性仍有待进一步研究。 |
| [^71] | [SecGPT: An Execution Isolation Architecture for LLM-Based Systems](https://arxiv.org/abs/2403.04960) | 提出了一种面向LLM系统的执行隔离架构SecGPT，旨在解决第三方应用程序执行所引发的安全和隐私问题 |
| [^72] | [Automatic and Universal Prompt Injection Attacks against Large Language Models](https://arxiv.org/abs/2403.04957) | 引入了一个统一框架，用于理解提示注入攻击的目标，并提出了一种自动梯度方法，用于生成高效和通用的提示注入数据。 |
| [^73] | [Fooling Neural Networks for Motion Forecasting via Adversarial Attacks](https://arxiv.org/abs/2403.04954) | 该研究在人体动作预测领域引入了对抗性攻击，通过实验证实模型即使在低水平的扰动下也容易受到攻击，并展示了对简单旋转和平移敏感的模型性能受影响。 |
| [^74] | [A spatiotemporal style transfer algorithm for dynamic visual stimulus generation](https://arxiv.org/abs/2403.04940) | 提出了Spatiotemporal Style Transfer (STST)算法，基于双流深度神经网络模型，允许生成强大的动态视觉刺激，用于视觉研究。 |
| [^75] | [LeTac-MPC: Learning Model Predictive Control for Tactile-reactive Grasping](https://arxiv.org/abs/2403.04934) | LeTac-MPC是一种学习模型预测控制，利用视觉触觉传感器GelSight和不同iable MPC层，实现在不同条件下和具有不同物理属性的物体上进行稳健抓取控制。 |
| [^76] | [A Survey on Human-AI Teaming with Large Pre-Trained Models](https://arxiv.org/abs/2403.04931) | 本文调查了大型预训练模型与人工智能合作的重要性，强调了这些模型如何超越传统方法增强协作智能，并探讨了其在增强人类能力、改善AI模型、有效团队合作、道德考虑以及在各个领域广泛应用方面的潜在作用。 |
| [^77] | [On the Markov Property of Neural Algorithmic Reasoning: Analyses and Methods](https://arxiv.org/abs/2403.04929) | 本研究提出了ForgetNet和G-ForgetNet，通过不使用历史嵌入和引入门控机制来解决神经算法推理中的马尔可夫性质矛盾，提供了有价值的计算路径。 |
| [^78] | [Identifying Causal Effects Under Functional Dependencies](https://arxiv.org/abs/2403.04919) | 本文研究了在已知某些变量由它们的父节点功能决定的情况下，如何识别因果效应，在这种情况下可以使得一些不可识别的因果效应变得可识别，并且可以在不影响因果效应可识别性的情况下排除观测到的功能性变量，从而显著减少需要的观测数据中的变量数量。 |
| [^79] | [A Mixed-Integer Conic Program for the Moving-Target Traveling Salesman Problem based on a Graph of Convex Sets](https://arxiv.org/abs/2403.04917) | 本文提出了一个新的公式，用于解决移动目标旅行推销员问题，该公式基于目标在空间-时间坐标系内成为凸集的概念，通过在凸集图中寻找最短路径来实现，在实验中表现出比当前Mixed Integer Conic Program (MICP)求解器更好的效果。 |
| [^80] | [Towards Scene Graph Anticipation](https://arxiv.org/abs/2403.04899) | 提出了场景图预测（SGA）任务，并引入一个新的方法SceneSayer，通过使用神经ODE和神经SDE的概念，结合对象-centric的关系表示，实现对象之间未来关系的预测。 |
| [^81] | [ConstitutionalExperts: Training a Mixture of Principle-based Prompts](https://arxiv.org/abs/2403.04894) | 提出了ConstitutionalExperts方法，通过学习宪法原则构建提示，采用逐步改进提示和MoE架构，展现出在不同语义区域学习独特提示的潜力，并在六个基准数据集上表现优异。 |
| [^82] | [A Safe Harbor for AI Evaluation and Red Teaming](https://arxiv.org/abs/2403.04893) | 主要AI开发者应承诺提供法律和技术上的安全港，使公共利益的安全研究免受账户暂停或法律报复的威胁。 |
| [^83] | [A Modular End-to-End Multimodal Learning Method for Structured and Unstructured Data](https://arxiv.org/abs/2403.04866) | 提出了一种名为MAGNUM的模块化、端到端的多模态学习方法，可以本地化处理结构化和非结构化数据。 |
| [^84] | [Self-Supervision in Time for Satellite Images(S3-TSS): A novel method of SSL technique in Satellite images](https://arxiv.org/abs/2403.04859) | 提出了一种新的卫星图像中的自监督学习方法S3-TSS，利用时间维度中的自然增强，结果显示在四个下游数据集中优于基线方法SeCo。 |
| [^85] | [Evaluation of LLMs on Syntax-Aware Code Fill-in-the-Middle Tasks](https://arxiv.org/abs/2403.04814) | 该研究引入了一个新的基准SAFIM用于评估LLMs在代码填空任务上的句法感知完成表现，发现FIM预训练不仅提高了FIM的熟练度，还改善了LLMs的左到右推理，挑战了传统观念并表明预训练方法和数据品质对模型性能的影响更甚于模型大小。 |
| [^86] | [Restricted Bayesian Neural Network](https://arxiv.org/abs/2403.04810) | 本研究提出了限制贝叶斯神经网络的新架构，显著减少了网络存储空间复杂性，并引入了一种能够有效处理不确定性的算法，确保在目标函数缺乏完美凸性时稳健地收敛至全局最优解。 |
| [^87] | [Mathematics of Neural Networks (Lecture Notes Graduate Course)](https://arxiv.org/abs/2403.04807) | 该课程旨在向研究生数学专业的学生介绍神经网络并激发兴趣，主要内容包括深度学习的数学介绍和将李群理论应用于设计具有几何等变性的神经网络，讲义及编码教程公开可获取 |
| [^88] | [Enhancing Security in Federated Learning through Adaptive Consensus-Based Model Update Validation](https://arxiv.org/abs/2403.04803) | 通过自适应阈值机制和共识验证流程，增强了联邦学习系统对标签翻转攻击的安全性，有效减轻了攻击并提升系统的弹性。 |
| [^89] | [AI Literacy in Low-Resource Languages:Insights from creating AI in Yoruba videos](https://arxiv.org/abs/2403.04799) | 本研究探索了在低资源语言如约鲁巴语中创建和分发人工智能视频的方法，并展示了其在全球范围内的潜在影响。 |
| [^90] | [Large Language Models in Fire Engineering: An Examination of Technical Questions Against Domain Knowledge](https://arxiv.org/abs/2403.04795) | 本研究比较了两个聊天机器人在消防工程中处理问题的表现，发现ChatGPT表现较优，展示了聊天机器人技术在消防工程实践中的潜力。 |
| [^91] | [A Data-Driven Two-Phase Multi-Split Causal Ensemble Model for Time Series](https://arxiv.org/abs/2403.04793) | 提出了一种基于数据驱动的两阶段多分裂因果集成模型，通过组合不同因果基准算法的优势，降低噪音的影响，实现更稳健的因果推断结果。 |
| [^92] | [Online Training of Large Language Models: Learn while chatting](https://arxiv.org/abs/2403.04790) | 本论文提出了一种新的互动范式，允许大型语言模型通过外部互动进行在线训练，实现了持续、实时的模型更新与个性化定制的灵活性。 |
| [^93] | [TopicDiff: A Topic-enriched Diffusion Approach for Multimodal Conversational Emotion Detection](https://arxiv.org/abs/2403.04789) | 提出了一种TopicDiff方法，用于捕获多模态会话情感检测任务中的主题信息，通过将扩散模型集成到神经主题模型中，解决了神经主题模型在捕获主题信息方面的多样性不足问题，并相对于现有MCE基线取得了显著改进 |
| [^94] | [Ever-Evolving Memory by Blending and Refining the Past](https://arxiv.org/abs/2403.04787) | 提出了一种新颖的长期对话记忆方案CREEM，通过混合过去记忆并引入完善过程来实现聊天机器人回应的整体改进和连贯性。 |
| [^95] | [Large Language Multimodal Models for 5-Year Chronic Disease Cohort Prediction Using EHR Data](https://arxiv.org/abs/2403.04785) | 本研究提出了一种大型语言多模型（LLMMs）框架，结合临床笔记和实验室检验结果的多模态数据，用于预测慢性疾病风险。 |
| [^96] | [A Survey on Temporal Knowledge Graph: Representation Learning and Applications](https://arxiv.org/abs/2403.04782) | 时间知识图表示学习将时间信息融入标准知识图框架，可以对实体和关系随时间的动态变化进行建模。 |
| [^97] | [MuseGraph: Graph-oriented Instruction Tuning of Large Language Models for Generic Graph Mining](https://arxiv.org/abs/2403.04780) | MuseGraph将GNNs和LLMs的优势结合起来，提出了一种更有效和通用的图挖掘方法，可以跨不同任务和数据集使用 |
| [^98] | [Superposition with Delayed Unification](https://arxiv.org/abs/2403.04775) | 将合一算法移动到演算层次后，一阶叠加仍然保持完备，这对于标准一阶叠加也带来了一些好处。 |
| [^99] | [Representing Pedagogic Content Knowledge Through Rough Sets](https://arxiv.org/abs/2403.04772) | 在本研究中，提出了一种基于两层粗糙集的模型，能够一致处理模糊性、粒度和多模态性，可用于建模教师对内容理解，展示了其在教学领域的潜在应用。 |
| [^100] | [Removing GPT4's Filter](https://arxiv.org/abs/2403.04769) | 提出了一种方法，可以使经过微调的GPT4恢复到没有经过人类反馈强化学习训练的状态，从而移除其在学习期间的所有安全机制 |
| [^101] | [How Far Are We from Intelligent Visual Deductive Reasoning?](https://arxiv.org/abs/2403.04732) | 目前的视觉语言模型在文本推理方面表现出色，但在视觉演绎推理方面仍存在较大差距和盲点。 |
| [^102] | [Context-Based Multimodal Fusion](https://arxiv.org/abs/2403.04650) | 提出一种基于上下文的多模态融合模型，结合了模态融合和数据分布对齐，通过特定上下文向量表示每个模态，并将其与每个模态的嵌入进行融合， |
| [^103] | [Pix2Gif: Motion-Guided Diffusion for GIF Generation](https://arxiv.org/abs/2403.04634) | 提出了Pix2Gif，一种基于运动引导的扩散模型，通过图像转换问题来实现图像到GIF的生成，引入了新的运动引导变形模块和感知损失以确保模型遵循运动引导并保持内容一致性和连贯性。 |
| [^104] | [Explaining Bayesian Optimization by Shapley Values Facilitates Human-AI Collaboration](https://arxiv.org/abs/2403.04629) | 提出了ShapleyBO框架，用Shapley值解释贝叶斯优化提议，量化每个参数对于优化过程的贡献，并能够区分不同类型的不确定性探索贡献。 |
| [^105] | [Do Large Language Model Understand Multi-Intent Spoken Language ?](https://arxiv.org/abs/2403.04481) | 该研究利用大型语言模型进行口语语言多目标理解，提出了改进实体槽和子目标指令的创新技术，并展示了LLMs在多目标SLU模型方面的潜力。 |
| [^106] | [Dynamics of Moral Behavior in Heterogeneous Populations of Learning Agents](https://arxiv.org/abs/2403.04202) | 在多代理环境中，研究人员探讨了不同道德类型的学习代理之间的互动，发现道德异质性可能对代理的共同发展产生影响。 |
| [^107] | [DNAct: Diffusion Guided Multi-Task 3D Policy Learning](https://arxiv.org/abs/2403.04115) | 本文提出了DNAct框架，结合神经渲染和扩散训练，实现在动作序列空间中的多模态学习，可应用于挑战性机器人任务，同时通过扩散过程实现多任务动作序列的重构。 |
| [^108] | [MolNexTR: A Generalized Deep Learning Model for Molecular Image Recognition](https://arxiv.org/abs/2403.03691) | MolNexTR是一种用于分子图像识别的通用深度学习模型，能够更细致提取分子图像的局部和全局特征，同时能够预测原子和键，理解布局规则，灵活整合符号化的化学原则，并且包含多种先进算法。 |
| [^109] | [SplAgger: Split Aggregation for Meta-Reinforcement Learning](https://arxiv.org/abs/2403.03020) | 本文展示了任务推断序列模型在元强化学习中的益处。 |
| [^110] | [Wukong: Towards a Scaling Law for Large-Scale Recommendation](https://arxiv.org/abs/2403.02545) | Wukong通过堆叠因子分解机和协同增长策略，在推荐领域建立了一个标度律，并在质量上优于现有模型。 |
| [^111] | [Position Paper: Towards Implicit Prompt For Text-To-Image Models](https://arxiv.org/abs/2403.02118) | 该位置论文讨论了文本到图像模型在隐式提示方面的现状，提出了名为ImplicitBench的新基准，并对 T2I 模型在隐式提示下的表现及影响进行了调查。 |
| [^112] | [ComTraQ-MPC: Meta-Trained DQN-MPC Integration for Trajectory Tracking with Limited Active Localization Updates](https://arxiv.org/abs/2403.01564) | ComTraQ-MPC是一个结合了DQN和MPC的新框架，旨在优化在有限主动定位更新下的轨迹跟踪。 |
| [^113] | [CLLMs: Consistency Large Language Models](https://arxiv.org/abs/2403.00835) | 提出了一种新方法，通过精细调整目标LLM实现了对雅各比轨迹上固定点的一致性预测，有效提高了生成速度2.4倍到3.4倍。 |
| [^114] | [Robust Policy Learning via Offline Skill Diffusion](https://arxiv.org/abs/2403.00225) | 提出了一种新颖的离线技能学习框架DuSkill，通过引导扩散模型生成通用技能，从而增强不同领域任务的策略学习鲁棒性。 |
| [^115] | [Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation](https://arxiv.org/abs/2402.18920) | 该研究提出了一个统一的框架，结合光谱和空间域的映射，以预测3D形状之间的点对应和形状插值，相比先前方法，取得更准确、平滑的点对应结果，并且在计算上更高效。 |
| [^116] | [Boosting Neural Representations for Videos with a Conditional Decoder](https://arxiv.org/abs/2402.18152) | 引入条件解码器和NeRV-like模块的增强框架，以提高隐式视频表示方法的效果。 |
| [^117] | [REPrune: Channel Pruning via Kernel Representative Selection](https://arxiv.org/abs/2402.17862) | REPrune是一种新颖的通道修剪技术，通过模拟核修剪，并结合聚类和滤波器选择，实现了更精细但结构化的修剪粒度，促进了在训练CNNs期间的高效、渐进式修剪。 |
| [^118] | [Multiple Instance Learning for Glioma Diagnosis using Hematoxylin and Eosin Whole Slide Images: An Indian cohort Study](https://arxiv.org/abs/2402.15832) | 本研究通过多实例学习在脑肿瘤组织病理学中取得新突破，建立了印度胶质瘤亚型分类性能基准，同时实现了新的评级和检测生物标志物的基准。 |
| [^119] | [LLMBind: A Unified Modality-Task Integration Framework](https://arxiv.org/abs/2402.14891) | 提出了LLMBind，一种统一的模态任务集成框架，通过将大型语言模型和预训练任务模型绑定在一起，实现了多种模态任务的灵活输入和输出组合。 |
| [^120] | [CriticBench: Benchmarking LLMs for Critique-Correct Reasoning](https://arxiv.org/abs/2402.14809) | CriticBench是一个综合基准测试，旨在评估LLMs在批判和纠正推理方面的能力，发现批判性训练显著提升性能，逻辑任务更易于修正。 |
| [^121] | [SaGE: Evaluating Moral Consistency in Large Language Models](https://arxiv.org/abs/2402.13709) | 提出SaGE方法，通过语义图熵来衡量大型语言模型道德一致性，构建了MCC语料库。 |
| [^122] | [Large Language Models to Enhance Bayesian Optimization](https://arxiv.org/abs/2402.03921) | 通过结合大型语言模型（LLM）的能力，我们提出了一种名为LLAMBO的新方法，将其应用于贝叶斯优化（BO）。通过用自然语言描述BO问题，并利用LLM的上下文理解、少样本学习能力和领域知识，LLAMBO能够提供有前景的解决方案，并且在零样本热启动方面表现出良好的效果。 |
| [^123] | [Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models](https://arxiv.org/abs/2312.14197) | 该研究引入了第一个间接提示注入攻击基准测试BIPIA，对大型语言模型在面对此类攻击时的风险进行评估，并分析了攻击成功的原因，从而开发了防御方法。 |
| [^124] | [A dynamical clipping approach with task feedback for Proximal Policy Optimization](https://arxiv.org/abs/2312.07624) | 提出了一种基于任务反馈的动态剪裁方法，通过增加最大累积回报来优化近端策略优化的性能。 |
| [^125] | [Exploring Large Language Models to Facilitate Variable Autonomy for Human-Robot Teaming](https://arxiv.org/abs/2312.07214) | 本文探讨了将大型语言模型集成到人机团队合作环境中，通过口头交流促进机器人的可变自主性，提出了基于GPT的多机器人测试台架环境，并进行了用户研究以验证其有效性和用户策略。 |
| [^126] | [Unified Batch Normalization: Identifying and Alleviating the Feature Condensation in Batch Normalization and a Unified Framework](https://arxiv.org/abs/2311.15993) | 识别了批归一化中的特征凝聚问题，并提出了统一批归一化（UBN）框架来解决，从而改善测试性能。 |
| [^127] | [Out-of-Distribution Generalized Dynamic Graph Neural Network for Human Albumin Prediction](https://arxiv.org/abs/2311.15545) | 提出了一种名为DyG-HAP的框架，利用超分布广义动态图神经网络进行人类白蛋白预测，特别适用于ICU患者。 |
| [^128] | [Can LLMs Follow Simple Rules?](https://arxiv.org/abs/2311.04235) | 提出了一个名为RuLES的程序框架，用于衡量LLMs在与用户交互时遵守规则的能力。 |
| [^129] | [Multi-View Causal Representation Learning with Partial Observability](https://arxiv.org/abs/2311.04056) | 我们提出了一个统一的框架，用于学习来自不同数据视图的因果关系表示，证明了跨视图子集的信息可以通过对比学习和单个编码器学习，同时提供了一个观测潜在变量的简单规则。 |
| [^130] | [Differentiable Learning of Generalized Structured Matrices for Efficient Deep Neural Networks](https://arxiv.org/abs/2310.18882) | 提出了一种可微的广义框架，通过梯度下降学习高效的权重矩阵结构。 |
| [^131] | [ManyQuadrupeds: Learning a Single Locomotion Policy for Diverse Quadruped Robots](https://arxiv.org/abs/2310.10486) | 通过受动物运动控制的启发，我们展示出能够有效训练一个单一运动策略，可以控制多样化四足机器人。 |
| [^132] | [TAIL: Task-specific Adapters for Imitation Learning with Large Pretrained Models](https://arxiv.org/abs/2310.05905) | TAIL提出了一种适配器框架，通过高效微调技术将大型预训练模型用于新的控制任务，以实现数据有效率、持续适应不同控制任务。 |
| [^133] | [Intriguing Properties of Input-dependent Randomized Smoothing](https://arxiv.org/abs/2110.05365) | 输入相关平滑方法虽然被用来获取可靠鲁棒分类器，但缺乏形式保证，其证书并不合理，因受到维度诅咒影响；提出了一个理论和实践框架，使得即使在维度诅咒存在的情况下，也能在严格的限制条件下使用输入相关平滑。 |
| [^134] | [A step toward a reinforcement learning de novo genome assembler](https://arxiv.org/abs/2102.02649) | 本研究旨在探讨机器学习在基因组组装中的应用，使用强化学习（RL）。他们在文献中唯一发现的方法的基础上进行了扩展，以仔细探索学习过程。 |
| [^135] | [RomanSetu: Efficiently unlocking multilingual capabilities of Large Language Models models via Romanization.](http://arxiv.org/abs/2401.14280) | 本研究提出了一种创新的方法，通过使用罗马化形式的文本作为接口，有效地利用大语言模型的多语言能力。通过在印地语上的实验证明，罗马化文本不仅提高了推理效率，还在有限的预训练下实现了有竞争力的性能。这些发现表明罗马化有潜力弥合大语言模型应用中的语言障碍。 |
| [^136] | [FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data.](http://arxiv.org/abs/2401.08977) | 本文介绍了一种名为FedLoGe的方法，它通过在神经网络崩溃框架中集成表示学习和分类器对齐来提高区域和全局模型的性能，解决了在联邦长尾学习中忽视本地级别性能的问题。 |
| [^137] | [REValueD: Regularised Ensemble Value-Decomposition for Factorisable Markov Decision Processes.](http://arxiv.org/abs/2401.08850) | REValueD是一种通过正则化集合值分解的新算法，针对高维离散动作空间的任务提供了优越性能，尤其在人形和狗类任务中表现出色。它遏制了Q-learning算法的高估偏差，并减轻了目标方差问题。 |
| [^138] | [Human-computer Interaction for Brain-inspired Computing Based on Machine Learning And Deep Learning:A Review.](http://arxiv.org/abs/2312.07213) | 该论文综述了机器学习和深度学习在脑启发计算的人机交互研究中的应用，介绍了其演化、挑战和潜在研究轨迹。 |
| [^139] | [Weathering Ongoing Uncertainty: Learning and Planning in a Time-Varying Partially Observable Environment.](http://arxiv.org/abs/2312.03263) | 本研究结合了时变马尔科夫决策过程和部分可观测性，提出了在不确定、随机和时变环境中进行学习和规划的方法。通过记忆优先状态估计和规划策略的集成，我们实现了对长期奖励的优化，在仿真和硬件验证中取得了良好的结果。 |
| [^140] | [APRICOT: Acuity Prediction in Intensive Care Unit (ICU): Predicting Stability, Transitions, and Life-Sustaining Therapies.](http://arxiv.org/abs/2311.02026) | APRICOT是一种基于Transformer的神经网络，用于在ICU患者中实时预测敏感度状态，并在多个数据集上进行了广泛验证。 |
| [^141] | [Approximate Multiagent Reinforcement Learning for On-Demand Urban Mobility Problem on a Large Map (extended version).](http://arxiv.org/abs/2311.01534) | 本文研究了大型城市环境下的自主多智能体出租车路径问题，提出了一个近似滚动为基础的两阶段算法来减少计算量。 |
| [^142] | [Brain decoding: toward real-time reconstruction of visual perception.](http://arxiv.org/abs/2310.19812) | 本研究提出了一种基于脑磁图（MEG）的脑解码方法，通过训练一个具有预训练嵌入、MEG模块和图像生成器的模型，在实时应用中实现了对视觉知觉的高时间分辨率解码，并在图像检索上取得了7倍的改进。 |
| [^143] | [DepWiGNN: A Depth-wise Graph Neural Network for Multi-hop Spatial Reasoning in Text.](http://arxiv.org/abs/2310.12557) | DepWiGNN是一种用于多跳空间推理的深度图神经网络。它通过设计新颖的节点记忆方案，并在图的深度维度上聚合信息，从而能够收集长时间的依赖关系，而无需堆叠多个层次。实验结果表明，DepWiGNN在两个挑战数据集上比传统GNN方法具有更高的准确性。 |
| [^144] | [One-Shot Sensitivity-Aware Mixed Sparsity Pruning for Large Language Models.](http://arxiv.org/abs/2310.09499) | 我们提出了一种基于敏感度感知混合稀疏化剪枝的方法，可以在不重新训练的情况下将大型语言模型剪枝至至少50％的稀疏性，同时保持稀疏性水平和减少剪枝引起的误差。此外，该方法还与量化兼容，可以进一步压缩语言模型。 |
| [^145] | [Towards the Vulnerability of Watermarking Artificial Intelligence Generated Content.](http://arxiv.org/abs/2310.07726) | 该研究探讨了将水印技术应用于人工智能生成内容的漏洞，并证明了现有的水印机制容易被对手破解。 |
| [^146] | [Generative ensemble deep learning severe weather prediction from a deterministic convection-allowing model.](http://arxiv.org/abs/2310.06045) | 本论文开发了一种集成后处理方法，将生成对抗网络（CGANs）和卷积神经网络（CNN）结合起来，对严重天气进行概率预测。该方法在使用HRRR预报作为输入数据，在2021年的测试数据集上相对于其他基于神经网络的方法提高了高达20％的Brier技巧分数（BSS）。 |
| [^147] | [Molecular De Novo Design through Transformer-based Reinforcement Learning.](http://arxiv.org/abs/2310.05365) | 本文提出了一种基于Transformer的强化学习方法，通过精细调整生成模型，能够在分子的全新设计中生成具有所需性质的分子结构，展现出优越的性能。 |
| [^148] | [Out of Sight, Still in Mind: Reasoning and Planning about Unobserved Objects with Video Tracking Enabled Memory Models.](http://arxiv.org/abs/2309.15278) | 本文研究了如何对先前观察到但当前被遮挡的对象进行推理和规划，提出了利用转换器关系动力学编码轨迹历史的方法，并在多个挑战性任务中表现出色。 |
| [^149] | [Art or Artifice? Large Language Models and the False Promise of Creativity.](http://arxiv.org/abs/2309.14556) | 本研究通过提出创造性写作的托兰斯测验(TTCW)来评估大型语言模型(LLMs)的写作创造力。结果表明，LLM生成的故事在创意测试中通过的数量比专业作家写的故事少。此外，我们发现LLMs无法代替专家进行TTCW评估。 |
| [^150] | [LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models.](http://arxiv.org/abs/2309.12307) | LongLoRA是一种高效的精细调整方法，可以在有限的计算成本下扩展预训练的大型语言模型的上下文大小。它通过稀疏的局部注意力实现精细调整，并使用移动短注意力有效实现上下文扩展，与传统方法具有相似的性能。 |
| [^151] | [HAISTA-NET: Human Assisted Instance Segmentation Through Attention.](http://arxiv.org/abs/2305.03105) | 该论文提出了一种通过人类辅助实例分割方法，称为HAISTA-NET，增强了现有的实例分割网络，引入了人类指定的部分边界地图，以生成更精确的分割掩模。 |
| [^152] | [A Perspectival Mirror of the Elephant: Investigating Language Bias on Google, ChatGPT, Wikipedia, and YouTube.](http://arxiv.org/abs/2303.16281) | 研究发现在Google、ChatGPT、维基百科和YouTube上，搜索结果受限于语言，反映了与复杂主题相关的文化刻板印象，缺乏跨文化视角。 |
| [^153] | [Distill n' Explain: explaining graph neural networks using simple surrogates.](http://arxiv.org/abs/2303.10139) | 本文提出了Distill n' Explain (DnX)方法，通过知识蒸馏学习简单的替代模型，并通过解决简单的凸规划提取节点或边级别的解释，从而解释图神经网络（GNN）。实验结果显示，DnX和FastDnX通常优于最先进的GNN解释器，并且运行速度快得多。 |

# 详细

[^1]: 讲述，而不是展示！：语言指导有助于在图像和视频领域之间进行转移

    Tell, Don't Show!: Language Guidance Eases Transfer Across Domains in Images and Videos

    [https://arxiv.org/abs/2403.05535](https://arxiv.org/abs/2403.05535)

    该论文提出了LaGTran框架，利用文本描述来引导知识转移，在处理具有挑战性的数据集上表现出显著优势。

    

    我们介绍了LaGTran，这是一个新颖的框架，利用即可获得或易于获取的文本描述，引导从带标签的源数据到具有域偏移的无标签目标数据的鲁棒性知识转移。受到我们观察到更富语义的文本模态具有更有利的转移特性的启发，我们设计了一个转移机制，使用源训练的文本分类器在目标文本描述上生成预测，并利用这些预测作为相应图像的监督。我们的方法以语言指导为驱动，出奇地简单易行，却在具有挑战性的数据集如GeoNet和DomainNet上显著优于以往所有方法，验证了其极其有效性。

    arXiv:2403.05535v1 Announce Type: cross  Abstract: We introduce LaGTran, a novel framework that utilizes readily available or easily acquired text descriptions to guide robust transfer of discriminative knowledge from labeled source to unlabeled target data with domain shifts. While unsupervised adaptation methods have been established to address this problem, they show limitations in handling challenging domain shifts due to their exclusive operation within the pixel-space. Motivated by our observation that semantically richer text modality has more favorable transfer properties, we devise a transfer mechanism to use a source-trained text-classifier to generate predictions on the target text descriptions, and utilize these predictions as supervision for the corresponding images. Our approach driven by language guidance is surprisingly easy and simple, yet significantly outperforms all prior approaches on challenging datasets like GeoNet and DomainNet, validating its extreme effectiven
    
[^2]: Gemini 1.5：解锁跨数百万标记上下文的多模态理解

    Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context

    [https://arxiv.org/abs/2403.05530](https://arxiv.org/abs/2403.05530)

    Gemini 1.5 Pro是一种高效计算的多模态混合模型，能在数百万标记的上下文中回忆和推理信息，达到近乎完美的长上下文检索任务召回率，改进了长文档问答、长视频问答和长上下文ASR的最新技术水平。

    

    在这份报告中，我们介绍了Gemini家族的最新模型Gemini 1.5 Pro，这是一个高效计算的多模态专家混合模型，能够回忆和推理数百万标记上下文中的细粒度信息，包括多个长文档和几小时的视频和音频。Gemini 1.5 Pro在各种形式的长上下文检索任务中实现了近乎完美的召回率，改进了长文档问答、长视频问答和长上下文ASR的最新技术水平，并在广泛一系列基准测试中与Gemini 1.0 Ultra的最新技术水平相匹敌甚至超过。在研究Gemini 1.5 Pro长上下文能力的极限时，我们发现在至少10M标记的范围内继续改进下一个标记的预测，并且几乎完美地达到了超过99%的检索率，这是对现有模型如Claude 2.1（200k）和GPT-4 Turbo（128k）的世代性飞跃。最后，我们突出了大型语言模型在新领域的令人惊讶的新能力。

    arXiv:2403.05530v1 Announce Type: cross  Abstract: In this report, we present the latest model of the Gemini family, Gemini 1.5 Pro, a highly compute-efficient multimodal mixture-of-experts model capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. Gemini 1.5 Pro achieves near-perfect recall on long-context retrieval tasks across modalities, improves the state-of-the-art in long-document QA, long-video QA and long-context ASR, and matches or surpasses Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5 Pro's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 2.1 (200k) and GPT-4 Turbo (128k). Finally, we highlight surprising new capabilities of large language models at the
    
[^3]: GEAR: 一种用于几乎无损生成推断大型语言模型的高效KV缓存压缩方案

    GEAR: An Efficient KV Cache Compression Recipefor Near-Lossless Generative Inference of LLM

    [https://arxiv.org/abs/2403.05527](https://arxiv.org/abs/2403.05527)

    GEAR提出了一种高效的KV缓存压缩框架，实现几乎无损的高比率压缩，用于解决大型语言模型推断中因缓存需求增长而导致的记忆绑定问题和性能下降。

    

    关键-值（KV）缓存已成为加快大型语言模型（LLMs）推断生成速度的事实标准。然而，随着序列长度增加而增长的缓存需求已将LLM推断转变为一个记忆绑定问题，显著地限制了系统吞吐量。现有方法依赖于丢弃不重要的标记或均匀量化所有条目。然而，这种方法往往会产生较高的近似误差来表示压缩后的矩阵。自回归解码过程进一步增加了每个步骤的误差，导致模型生成中的重大偏差和性能恶化。为了解决这一挑战，我们提出了GEAR，一种高效的KV缓存压缩框架，实现几乎无损的高压缩比。

    arXiv:2403.05527v1 Announce Type: cross  Abstract: Key-value (KV) caching has become the de-facto to accelerate generation speed for large language models (LLMs) inference. However, the growing cache demand with increasing sequence length has transformed LLM inference to be a memory bound problem, significantly constraining the system throughput. Existing methods rely on dropping unimportant tokens or quantizing all entries uniformly. Such methods, however, often incur high approximation errors to represent the compressed matrices. The autoregressive decoding process further compounds the error of each step, resulting in critical deviation in model generation and deterioration of performance. To tackle this challenge, we propose GEAR, an efficient KV cache compression framework that achieves near-lossless high-ratio compression. GEAR first applies quantization to majority of entries of similar magnitudes to ultra-low precision. It then employs a low rank matrix to approximate the quant
    
[^4]: DeepSeek-VL:走向真实世界的视觉语言理解

    DeepSeek-VL: Towards Real-World Vision-Language Understanding

    [https://arxiv.org/abs/2403.05525](https://arxiv.org/abs/2403.05525)

    DeepSeek-VL是一个面向真实世界的视觉语言理解模型，通过多样化数据、真实场景覆盖和高效编码器的设计，大大提高了在实际应用中的用户体验

    

    我们提出DeepSeek-VL，一个面向真实世界视觉和语言理解应用的开源视觉-语言（VL）模型。我们的方法围绕三个关键维度展开：确保数据多样化、可扩展性强，并广泛涵盖包括网络截图、PDF、OCR、图表和基于知识的内容在内的真实场景，以全面表征实际环境。此外，我们从真实用户场景创建了用例分类法，并相应构建了指导调整数据集。通过这个数据集的微调，大大提高了模型在实际应用中的用户体验。考虑到效率和大多数真实场景的需求，DeepSeek-VL整合了一个混合视觉编码器，能够高效处理高分辨率图像（1024 x 1024），同时保持相对较低的计算开销。这种设计选择确保了模型的能力

    arXiv:2403.05525v1 Announce Type: new  Abstract: We present DeepSeek-VL, an open-source Vision-Language (VL) Model designed for real-world vision and language understanding applications. Our approach is structured around three key dimensions:   We strive to ensure our data is diverse, scalable, and extensively covers real-world scenarios including web screenshots, PDFs, OCR, charts, and knowledge-based content, aiming for a comprehensive representation of practical contexts. Further, we create a use case taxonomy from real user scenarios and construct an instruction tuning dataset accordingly. The fine-tuning with this dataset substantially improves the model's user experience in practical applications. Considering efficiency and the demands of most real-world scenarios, DeepSeek-VL incorporates a hybrid vision encoder that efficiently processes high-resolution images (1024 x 1024), while maintaining a relatively low computational overhead. This design choice ensures the model's abilit
    
[^5]: 通过偏差增强一致性训练减少链式思维中的偏见推理

    Bias-Augmented Consistency Training Reduces Biased Reasoning in Chain-of-Thought

    [https://arxiv.org/abs/2403.05518](https://arxiv.org/abs/2403.05518)

    引入偏差增强的一致性训练（BCT）可以显著减少链式思维中的偏见推理问题，尤其是通过训练模型在带有和不带有偏置特征的提示下进行一致的推理。

    

    虽然链式思维提示（CoT）有潜力改善语言模型推理的可解释性，但它可能会系统性地歪曲影响模型行为的因素--比如，合理化答案以符合用户意见而不提及此偏见。为了减轻这一偏见推理问题，我们引入了偏差增强的一致性训练（BCT），这是一种无监督的微调方案，旨在训练模型在带有和不带有偏置特征的提示下进行一致的推理。我们构建了一个测试单元，针对七个问答任务测试了九种形式的有偏推理，发现将BCT应用于带有一种偏见的GPT-3.5-Turbo可以将有偏推理的比例在未知任务上降低86%。此外，这个模型推广到其他形式的偏见，平均将未知偏见上的有偏推理减少了37%。由于BCT将未知偏见泛化并且不需要金标签，这种方法可能会有助于

    arXiv:2403.05518v1 Announce Type: cross  Abstract: While chain-of-thought prompting (CoT) has the potential to improve the explainability of language model reasoning, it can systematically misrepresent the factors influencing models' behavior--for example, rationalizing answers in line with a user's opinion without mentioning this bias. To mitigate this biased reasoning problem, we introduce bias-augmented consistency training (BCT), an unsupervised fine-tuning scheme that trains models to give consistent reasoning across prompts with and without biasing features. We construct a suite testing nine forms of biased reasoning on seven question-answering tasks, and find that applying BCT to GPT-3.5-Turbo with one bias reduces the rate of biased reasoning by 86% on held-out tasks. Moreover, this model generalizes to other forms of bias, reducing biased reasoning on held-out biases by an average of 37%. As BCT generalizes to held-out biases and does not require gold labels, this method may h
    
[^6]: 多视图对比学习

    Poly-View Contrastive Learning

    [https://arxiv.org/abs/2403.05490](https://arxiv.org/abs/2403.05490)

    本研究提出了多视图对比学习方法，通过新的表示学习目标优化匹配多个相关视图，在ImageNet1k数据集上的实验结果显示，相比于SimCLR模型，多视图对比模型在更少的训练轮数和更小的批大小下表现更优。

    

    对比学习通常会匹配一组不相关的负视图中相关视图的配对。视图可以是生成的（例如通过增强）或被观察到的。本文研究了当存在多于两个相关视图时的匹配，我们称之为多视图任务，并利用信息最大化和充分统计导出了新的表示学习目标。我们表明，在计算资源无限时，应最大化相关视图的数量；而在固定计算预算的情况下，减少独特样本的数量同时增加这些样本的视图数量是有益的。特别地，以256的批大小训练128轮的多视图对比模型在ImageNet1k上表现优于在批大小为4096且进行1024轮训练的SimCLR模型，挑战了对比模型需要大批大小和多次训练轮数的信念。

    arXiv:2403.05490v1 Announce Type: cross  Abstract: Contrastive learning typically matches pairs of related views among a number of unrelated negative views. Views can be generated (e.g. by augmentations) or be observed. We investigate matching when there are more than two related views which we call poly-view tasks, and derive new representation learning objectives using information maximization and sufficient statistics. We show that with unlimited computation, one should maximize the number of related views, and with a fixed compute budget, it is beneficial to decrease the number of unique samples whilst increasing the number of views of those samples. In particular, poly-view contrastive models trained for 128 epochs with batch size 256 outperform SimCLR trained for 1024 epochs at batch size 4096 on ImageNet1k, challenging the belief that contrastive models require large batch sizes and many training epochs.
    
[^7]: GPT-4会运行《毁灭战士》吗？

    Will GPT-4 Run DOOM?

    [https://arxiv.org/abs/2403.05468](https://arxiv.org/abs/2403.05468)

    GPT-4通过自身的推理和观察能力，可以运行并玩1993年的第一人称射击游戏《毁灭战士》，并且能够执行门操作、击败敌人和规划路径，这有望拓展基于LLM的智能代理在视频游戏领域的边界。

    

    我们展示了GPT-4的推理和规划能力扩展到了1993年第一人称射击游戏《毁灭战士》。这个大型语言模型能够仅凭少数指令和来自屏幕截图的文本描述（由模型本身生成）来运行和玩游戏。我们发现GPT-4可以以及能够参与游戏：它能够操作门、与敌人作战并执行路径规划。涉及多次模型调用的更复杂提示策略提供了更好的结果。虽然需要进一步工作来让这个LLM玩得像其经典的基于强化学习的对应物一样出色，但我们注意到GPT-4不需要训练，而是依靠自身的推理和观察能力。我们希望我们的工作推动了基于智能LLM代理在视频游戏中的边界。我们最终讨论了我们工作的伦理影响。

    arXiv:2403.05468v1 Announce Type: cross  Abstract: We show that GPT-4's reasoning and planning capabilities extend to the 1993 first-person shooter Doom. This large language model (LLM) is able to run and play the game with only a few instructions, plus a textual description--generated by the model itself from screenshots--about the state of the game being observed. We find that GPT-4 can play the game to a passable degree: it is able to manipulate doors, combat enemies, and perform pathing. More complex prompting strategies involving multiple model calls provide better results. While further work is required to enable the LLM to play the game as well as its classical, reinforcement learning-based counterparts, we note that GPT-4 required no training, leaning instead on its own reasoning and observational capabilities. We hope our work pushes the boundaries on intelligent, LLM-based agents in video games. We conclude by discussing the ethical implications of our work.
    
[^8]: 分布感知对数正定编码的算法硬件协同设计，用于高效的DNN推断

    Algorithm-Hardware Co-Design of Distribution-Aware Logarithmic-Posit Encodings for Efficient DNN Inference

    [https://arxiv.org/abs/2403.05465](https://arxiv.org/abs/2403.05465)

    引入了对数正定编码（LP）和LP量化（LPQ）框架，采用基因算法寻找最优的LP参数，设计了统一的混合精度LP加速器（LPA）体系结构，可动态适应DNN参数分布，减少量化和完整精度模型之间的表示性差异。

    

    传统的深度神经网络（DNN）量化方法使用整数、定点或浮点数据类型时，往往难以在低精度下捕捉不同的DNN参数分布，通常需要大量硅开销和密集的量化感知训练。在本研究中，我们引入了对数正定（LP）编码，这是一种受到正定启发的自适应、硬件友好的数据类型，通过参数化LP位域动态适应DNN权重/激活分布。我们还开发了一种基于遗传算法的新颖框架，LP量化（LPQ），用于寻找最优的逐层LP参数，同时通过一种新颖的全局-局部对比目标减少量化和完整精度模型之间的表示性差异。此外，我们设计了一个统一的混合精度LP加速器（LPA）体系结构，包括将LP纳入计算数据通路中的处理单元（PEs）。

    arXiv:2403.05465v1 Announce Type: cross  Abstract: Traditional Deep Neural Network (DNN) quantization methods using integer, fixed-point, or floating-point data types struggle to capture diverse DNN parameter distributions at low precision, and often require large silicon overhead and intensive quantization-aware training. In this study, we introduce Logarithmic Posits (LP), an adaptive, hardware-friendly data type inspired by posits that dynamically adapts to DNN weight/activation distributions by parameterizing LP bit fields. We also develop a novel genetic-algorithm based framework, LP Quantization (LPQ), to find optimal layer-wise LP parameters while reducing representational divergence between quantized and full-precision models through a novel global-local contrastive objective. Additionally, we design a unified mixed-precision LP accelerator (LPA) architecture comprising of processing elements (PEs) incorporating LP in the computational datapath. Our algorithm-hardware co-design
    
[^9]: 算法识别大脑网络因果充分性中的关键外源节点

    Algorithmic Identification of Essential Exogenous Nodes for Causal Sufficiency in Brain Networks

    [https://arxiv.org/abs/2403.05407](https://arxiv.org/abs/2403.05407)

    本研究提出了一种算法识别方法，用于在大脑网络中确定满足关键因果充分性需求的关键外源节点。

    

    在研究任何因果机制，如大脑的因果网络时，因果充分性的假设起着关键作用。明显地，忽视这一假设可能导致重大错误，这一事实在大脑网络的因果分析中经常被忽视。在本研究中，我们提出了一种算法识别方法，用于确定满足因果充分性的关键外源节点，以在此类研究中遵循它的关键需求。我们的方法包括三个主要步骤：首先，通过捕捉Peter-Clark (PC)算法的本质，我们对网络内的区域对以及对来自其他网络节点条件的相同对进行独立性检验。接下来，我们通过分析条件和无条件结果之间的差异，利用Kolmogorov-Smirnov检验来区分候选混杂因素。随后，我们利用非因子化可识别变量。

    arXiv:2403.05407v1 Announce Type: new  Abstract: In the investigation of any causal mechanisms, such as the brain's causal networks, the assumption of causal sufficiency plays a critical role. Notably, neglecting this assumption can result in significant errors, a fact that is often disregarded in the causal analysis of brain networks. In this study, we propose an algorithmic identification approach for determining essential exogenous nodes that satisfy the critical need for causal sufficiency to adhere to it in such inquiries. Our approach consists of three main steps: First, by capturing the essence of the Peter-Clark (PC) algorithm, we conduct independence tests for pairs of regions within a network, as well as for the same pairs conditioned on nodes from other networks. Next, we distinguish candidate confounders by analyzing the differences between the conditional and unconditional results, using the Kolmogorov-Smirnov test. Subsequently, we utilize Non-Factorized identifiable Vari
    
[^10]: 考虑非平稳性的多元时间序列预测中的层次变分Transformer

    Considering Nonstationary within Multivariate Time Series with Variational Hierarchical Transformer for Forecasting

    [https://arxiv.org/abs/2403.05406](https://arxiv.org/abs/2403.05406)

    论文提出了一种名为HTV-Trans的Hierarchical Time series Variational Transformer模型，通过结合层次概率生成模块和Transformer，能够有效考虑多元时间序列中的非平稳性和随机特性，从而更好地回复时间依赖关系。

    

    多元时间序列（MTS）的预测长期以来一直是一项重要但具有挑战性的任务。由于跨越长时间步的非平稳问题，先前的研究主要采用平稳化方法来减弱原始系列的非平稳问题，以获得更好的可预测性。然而，现有方法总是采用平稳化的系列，忽略了固有的非平稳性，并且由于缺乏随机性，很难对具有复杂分布的MTS进行建模。为了解决这些问题，我们首先开发了一个强大的层次概率生成模块，考虑了MTS中的非平稳性和随机特性，然后将其与Transformer结合，形成一个名为Hierarchical Time series Variational Transformer（HTV-Trans）的明确定义的变分生成动态模型，将内在的非平稳信息恢复到时间依赖关系中。

    arXiv:2403.05406v1 Announce Type: cross  Abstract: The forecasting of Multivariate Time Series (MTS) has long been an important but challenging task. Due to the non-stationary problem across long-distance time steps, previous studies primarily adopt stationarization method to attenuate the non-stationary problem of the original series for better predictability. However, existing methods always adopt the stationarized series, which ignores the inherent non-stationarity, and has difficulty in modeling MTS with complex distributions due to the lack of stochasticity. To tackle these problems, we first develop a powerful hierarchical probabilistic generative module to consider the non-stationarity and stochastic characteristics within MTS, and then combine it with transformer for a well-defined variational generative dynamic model named Hierarchical Time series Variational Transformer (HTV-Trans), which recovers the intrinsic non-stationary information into temporal dependencies. Being a po
    
[^11]: HistGen：通过本地-全局特征编码和跨模态上下文交互生成组织病理学报告

    HistGen: Histopathology Report Generation via Local-Global Feature Encoding and Cross-modal Context Interaction

    [https://arxiv.org/abs/2403.05396](https://arxiv.org/abs/2403.05396)

    HistGen是一个通过本地-全局特征编码和跨模态上下文交互来生成组织病理学报告的框架，提供了第一个用于评估的基准数据集。

    

    组织病理学在癌症诊断中扮演着黄金标准的角色，临床报告在解释和理解这一过程中至关重要，在指导癌症治疗和患者护理方面起着关键作用。深度学习对组织病理学报告生成的自动化将极大提升临床效率，并减轻病理学家在报告撰写方面的劳动强度和耗时负担。为追求这一进步，作者引入了HistGen，这是一个多实例学习增强的组织病理学报告生成框架，并提供第一个用于评估的基准数据集。HistGen受诊断和报告撰写工作流程的启发，具有两个精心设计的模块，旨在通过对齐整张切片图像（WSIs）和诊断报告，从本地和全局粒度提升报告生成。为实现这一目标，开发了一个本地-全局分层编码器，用于有效地从区域中聚合视觉特征。

    arXiv:2403.05396v1 Announce Type: cross  Abstract: Histopathology serves as the gold standard in cancer diagnosis, with clinical reports being vital in interpreting and understanding this process, guiding cancer treatment and patient care. The automation of histopathology report generation with deep learning stands to significantly enhance clinical efficiency and lessen the labor-intensive, time-consuming burden on pathologists in report writing. In pursuit of this advancement, we introduce HistGen, a multiple instance learning-empowered framework for histopathology report generation together with the first benchmark dataset for evaluation. Inspired by diagnostic and report-writing workflows, HistGen features two delicately designed modules, aiming to boost report generation by aligning whole slide images (WSIs) and diagnostic reports from local and global granularity. To achieve this, a local-global hierarchical encoder is developed for efficient visual feature aggregation from a regi
    
[^12]: 自监督多实例学习用于急性髓细胞白血病分类

    Self-Supervised Multiple Instance Learning for Acute Myeloid Leukemia Classification

    [https://arxiv.org/abs/2403.05379](https://arxiv.org/abs/2403.05379)

    自本研究发现自监督预训练编码器在多实例学习中实现了可比较的性能，展示了自监督学习在急性髓细胞白血病分类中的潜力，这为一种经济高效且节约数据的解决方案。

    

    自动疾病诊断使用医学图像分析依赖深度学习，通常需要大量标记数据集进行监督模型训练。急性髓细胞白血病（AML）等疾病由于在单个细胞水平上稀缺且昂贵的标注而面临挑战。多实例学习（MIL）解决了弱标记场景，但通常需要用标记数据训练的强大编码器。在本研究中，我们探索了自监督学习（SSL）作为基于MIL的AML亚型分类的预训练方法，从血涂片中去除了编码器训练期间的标记数据需求。我们研究了三种最先进的SSL方法SimCLR、SwAV和DINO，并将它们的性能与监督预训练进行了比较。我们的研究结果表明，SSL预训练编码器实现了可比较的性能，展示了SSL在MIL中的潜力。这一突破提供了一种经济高效且节约数据的解决方案，

    arXiv:2403.05379v1 Announce Type: cross  Abstract: Automated disease diagnosis using medical image analysis relies on deep learning, often requiring large labeled datasets for supervised model training. Diseases like Acute Myeloid Leukemia (AML) pose challenges due to scarce and costly annotations on a single-cell level. Multiple Instance Learning (MIL) addresses weakly labeled scenarios but necessitates powerful encoders typically trained with labeled data. In this study, we explore Self-Supervised Learning (SSL) as a pre-training approach for MIL-based AML subtype classification from blood smears, removing the need for labeled data during encoder training. We investigate the three state-of-the-art SSL methods SimCLR, SwAV, and DINO, and compare their performance against supervised pre-training. Our findings show that SSL-pretrained encoders achieve comparable performance, showcasing the potential of SSL in MIL. This breakthrough offers a cost-effective and data-efficient solution, pr
    
[^13]: WatChat：通过调试心智模型解释令人困惑的程序

    WatChat: Explaining perplexing programs by debugging mental models

    [https://arxiv.org/abs/2403.05334](https://arxiv.org/abs/2403.05334)

    本文通过应用计算认知科学的方法，提出了一种能够通过调试心智模型解释令人困惑程序行为的方法。

    

    通常，解释程序意外行为的一个好方法是程序员代码中的错误。但有时，一个更好的解释是程序员对所使用语言的心智模型中存在错误。我们不仅仅调试当前代码（“给程序员一条鱼”），而是希望我们的工具能直接调试我们的心智模型（“教会程序员如何捕鱼”）。本文将计算认知科学的思想应用到其中，对令人困惑的程序，我们使用程序综合技术自动推断可能导致用户对程序行为感到惊讶的误解。通过分析这些误解，我们提供简明、有用的程序行为解释。我们的方法甚至可以被反转，以综合教学示范程序来诊断和纠正学生的误解。

    arXiv:2403.05334v1 Announce Type: cross  Abstract: Often, a good explanation for a program's unexpected behavior is a bug in the programmer's code. But sometimes, an even better explanation is a bug in the programmer's mental model of the language they are using. Instead of merely debugging our current code ("giving the programmer a fish"), what if our tools could directly debug our mental models ("teaching the programmer to fish")? In this paper, we apply ideas from computational cognitive science to do exactly that. Given a perplexing program, we use program synthesis techniques to automatically infer potential misconceptions that might cause the user to be surprised by the program's behavior. By analyzing these misconceptions, we provide succinct, useful explanations of the program's behavior. Our methods can even be inverted to synthesize pedagogical example programs for diagnosing and correcting misconceptions in students.
    
[^14]: ChatASU：唤起LLM的反思，真正理解对话中的方面情绪

    ChatASU: Evoking LLM's Reflexion to Truly Understand Aspect Sentiment in Dialogues

    [https://arxiv.org/abs/2403.05326](https://arxiv.org/abs/2403.05326)

    本文提出了一个新的基于聊天的方面情绪理解（ChatASU）任务，旨在探索大型语言模型（LLMs）在对话场景中理解方面情绪的能力，并引入了一个子任务Aspect Chain Reasoning（ACR）任务来解决方面共指问题。

    

    在互动场景（例如，问答和对话）中进行方面情绪理解（ASU）近年来引起了越来越多的关注并取得了重要进展。然而，现有研究大多忽略了意见目标（即方面）的共指问题，而这种现象在互动场景特别是对话中普遍存在，限制了ASU的性能。最近，大型语言模型（LLM）展示了将各种NLP任务与聊天范式相结合的强大能力。基于此，本文提出了一项新的基于聊天的方面情绪理解（ChatASU）任务，旨在探索LLMs在对话场景中理解方面情绪的能力。特别是，这项ChatASU任务引入了一个子任务，即方面链推理（ACR）任务，以解决方面共指问题。在此基础上，我们提出了一种可信的自反思方法（TSA）与ChatGLM作为背景。

    arXiv:2403.05326v1 Announce Type: cross  Abstract: Aspect Sentiment Understanding (ASU) in interactive scenarios (e.g., Question-Answering and Dialogue) has attracted ever-more interest in recent years and achieved important progresses. However, existing studies on interactive ASU largely ignore the coreference issue for opinion targets (i.e., aspects), while this phenomenon is ubiquitous in interactive scenarios especially dialogues, limiting the ASU performance. Recently, large language models (LLMs) shows the powerful ability to integrate various NLP tasks with the chat paradigm. In this way, this paper proposes a new Chat-based Aspect Sentiment Understanding (ChatASU) task, aiming to explore LLMs' ability in understanding aspect sentiments in dialogue scenarios. Particularly, this ChatASU task introduces a sub-task, i.e., Aspect Chain Reasoning (ACR) task, to address the aspect coreference issue. On this basis, we propose a Trusted Self-reflexion Approach (TSA) with ChatGLM as back
    
[^15]: 展望避免迟到：解决硬约束旅行商问题

    Looking Ahead to Avoid Being Late: Solving Hard-Constrained Traveling Salesman Problem

    [https://arxiv.org/abs/2403.05318](https://arxiv.org/abs/2403.05318)

    提出一种利用展望信息作为特征改善具有时间窗口的TSP解决方案合法性的新颖学习方法

    

    许多现实世界中的问题可以被定式为具有约束的旅行商问题（TSP）。然而，这些约束通常复杂而且数量众多，使得解决TSP变得具有挑战性。当复杂约束的数量增长时，传统启发式算法花费大量时间以避免不合法结果。基于学习的方法提供了一种软方式来解决TSP问题，同时支持GPU加速以快速生成解决方案。然而，软方法不可避免地导致通过学习算法解决硬约束问题变得困难，而合法性和最优性之间的冲突可能会严重影响解决方案的最优性。为了克服这一问题并对抗硬约束提出了一种新颖的基于学习的方法，该方法利用向前展望信息作为特征来改进具有时间窗口（TSPTW）的TSP解决方案的合法性。

    arXiv:2403.05318v1 Announce Type: new  Abstract: Many real-world problems can be formulated as a constrained Traveling Salesman Problem (TSP). However, the constraints are always complex and numerous, making the TSPs challenging to solve. When the number of complicated constraints grows, it is time-consuming for traditional heuristic algorithms to avoid illegitimate outcomes. Learning-based methods provide an alternative to solve TSPs in a soft manner, which also supports GPU acceleration to generate solutions quickly. Nevertheless, the soft manner inevitably results in difficulty solving hard-constrained problems with learning algorithms, and the conflicts between legality and optimality may substantially affect the optimality of the solution. To overcome this problem and to have an effective solution against hard constraints, we proposed a novel learning-based method that uses looking-ahead information as the feature to improve the legality of TSP with Time Windows (TSPTW) solutions.
    
[^16]: RAT：检索增强思维在长视角生成中引发了上下文感知推理

    RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation

    [https://arxiv.org/abs/2403.05313](https://arxiv.org/abs/2403.05313)

    RAT方法通过检索增强思维，在长视角生成中改善大型语言模型的推理和生成能力，显著降低了幻觉，并取得了显著的性能提升

    

    我们探讨了如何通过信息检索迭代修订一系列思维，显著改善大型语言模型在长视角生成任务中的推理和生成能力，同时极大减轻了幻觉。具体来说，所提出的方法——*检索增强思维* (RAT)——在生成初始的零射 CoT 后，逐步修订每个思维步骤，与任务查询、当前和过去的思维步骤相关的检索信息。将 RAT 应用于 GPT-3.5、GPT-4 和 CodeLLaMA-7b，在各种长视角生成任务上显著提高它们的性能；平均而言，代码生成评分增加了 13.63%，数学推理增加了 16.96%，创意写作增加了 19.2%，具象任务规划增加了 42.78%。演示页面链接：https://craftjarvis.github.io/RAT

    arXiv:2403.05313v1 Announce Type: cross  Abstract: We explore how iterative revising a chain of thoughts with the help of information retrieval significantly improves large language models' reasoning and generation ability in long-horizon generation tasks, while hugely mitigating hallucination. In particular, the proposed method -- *retrieval-augmented thoughts* (RAT) -- revises each thought step one by one with retrieved information relevant to the task query, the current and the past thought steps, after the initial zero-shot CoT is generated. Applying RAT to GPT-3.5, GPT-4, and CodeLLaMA-7b substantially improves their performances on various long-horizon generation tasks; on average of relatively increasing rating scores by 13.63% on code generation, 16.96% on mathematical reasoning, 19.2% on creative writing, and 42.78% on embodied task planning. The demo page can be found at https://craftjarvis.github.io/RAT
    
[^17]: Tapilot-Crossing：基准测试和发展LLM以实现交互式数据分析代理

    Tapilot-Crossing: Benchmarking and Evolving LLMs Towards Interactive Data Analysis Agents

    [https://arxiv.org/abs/2403.05307](https://arxiv.org/abs/2403.05307)

    Tapilot-Crossing是一个用于评估LLM代理在交互式数据分析任务中的新基准，通过经济型多代理环境和自适应交互反思策略进行构建和评估，凸显了交互式数据分析的挑战

    

    交互式数据分析，人类与LLM代理之间的协作，为明智决策提供了实时数据探索。收集逼真的交互式日志以进行数据分析的挑战和成本阻碍了对LLM代理在此任务中的定量评估。为了缓解这一问题，我们介绍了Tapilot-Crossing，这是一个新的基准，用于评估LLM代理进行交互式数据分析。Tapilot-Crossing包含1024个交互，涵盖4个实际场景：正常、动作、私人和私人动作。值得注意的是，Tapilot-Crossing是由一个经济型多代理环境Decision Company构建的，几乎不需要人力。我们评估了Tapilot-Crossing中知名和先进的LLM代理，凸显了交互式数据分析的挑战。此外，我们提出了自适应交互反思（AIR），这是一种自动生成的反思策略，指导LLM代理从中吸取教训

    arXiv:2403.05307v1 Announce Type: new  Abstract: Interactive Data Analysis, the collaboration between humans and LLM agents, enables real-time data exploration for informed decision-making. The challenges and costs of collecting realistic interactive logs for data analysis hinder the quantitative evaluation of Large Language Model (LLM) agents in this task. To mitigate this issue, we introduce Tapilot-Crossing, a new benchmark to evaluate LLM agents on interactive data analysis. Tapilot-Crossing contains 1024 interactions, covering 4 practical scenarios: Normal, Action, Private, and Private Action. Notably, Tapilot-Crossing is constructed by an economical multi-agent environment, Decision Company, with few human efforts. We evaluate popular and advanced LLM agents in Tapilot-Crossing, which underscores the challenges of interactive data analysis. Furthermore, we propose Adaptive Interaction Reflection (AIR), a self-generated reflection strategy that guides LLM agents to learn from succ
    
[^18]: 多模态VAEs中的统一多样性：改进的表示学习

    Unity by Diversity: Improved Representation Learning in Multimodal VAEs

    [https://arxiv.org/abs/2403.05300](https://arxiv.org/abs/2403.05300)

    通过软约束取代硬约束，提出了一种新的专家混合先验，改善了多模态VAEs中的表示学习。

    

    多模态数据的变分自编码器在数据分析的许多任务中表现出潜力，如表示学习、有条件生成和填补。目前的架构要么跨模态共享编码器输出、解码器输入，要么两者都要学习共享表示。这样的架构对模型施加了严格约束。在这项工作中，我们展示了通过用软约束取代这些硬约束可以获得更好的潜在表示。我们提出了一种新的专家混合先验，软性地引导每个模态的潜在表示朝着共享的后验。这种方法导致了优秀的潜在表示，并允许每个编码保留来自其未压缩原始特征更好的信息。通过对多个基准数据集和一个具有挑战性的现实世界神经科学数据集进行的广泛实验，我们展示了改进的学习潜在表示和填补。

    arXiv:2403.05300v1 Announce Type: cross  Abstract: Variational Autoencoders for multimodal data hold promise for many tasks in data analysis, such as representation learning, conditional generation, and imputation. Current architectures either share the encoder output, decoder input, or both across modalities to learn a shared representation. Such architectures impose hard constraints on the model. In this work, we show that a better latent representation can be obtained by replacing these hard constraints with a soft constraint. We propose a new mixture-of-experts prior, softly guiding each modality's latent representation towards a shared aggregate posterior. This approach results in a superior latent representation and allows each encoding to preserve information from its uncompressed original features better. In extensive experiments on multiple benchmark datasets and a challenging real-world neuroscience data set, we show improved learned latent representations and imputation of m
    
[^19]: PEEB：具有可解释和可编辑语言瓶颈的基于部分的图像分类器

    PEEB: Part-based Image Classifiers with an Explainable and Editable Language Bottleneck

    [https://arxiv.org/abs/2403.05297](https://arxiv.org/abs/2403.05297)

    PEEB是一种基于部分的图像分类器，通过将类别名称转换为描述视觉部分的文本描述符，并将检测到的部分的嵌入与文本描述符匹配，从而在零样本设置中表现出色，并且不仅在监督学习中表现出色，而且还首次实现用户编辑类定义形成新分类器无需重新训练。

    

    基于CLIP的分类器依赖于包含{text encoder已知的类名称}的提示。也就是说，CLIP在新类别或其名称很少在互联网上出现的类别（例如鸟类的学名）上表现不佳。针对细粒度分类，我们提出了PEEB - 一种可解释和可编辑的分类器，用于（1）将类别名称表达为一组预定义的描述视觉部分的文本描述符；和（2）将检测到的部分的嵌入与每个类别中的文本描述符进行匹配，以计算用于分类的逻辑分数。在一个零样本设置中，其中类别名称是未知的，PEEB在准确性上大幅优于CLIP（约为10倍）。与基于部分的分类器相比，PEEB不仅在监督学习设置上是最先进的（88.80%准确率），而且还是第一个能够让用户编辑类定义以形成新的分类器而无需重新训练的分类器。

    arXiv:2403.05297v1 Announce Type: cross  Abstract: CLIP-based classifiers rely on the prompt containing a {class name} that is known to the text encoder. That is, CLIP performs poorly on new classes or the classes whose names rarely appear on the Internet (e.g., scientific names of birds). For fine-grained classification, we propose PEEB - an explainable and editable classifier to (1) express the class name into a set of pre-defined text descriptors that describe the visual parts of that class; and (2) match the embeddings of the detected parts to their textual descriptors in each class to compute a logit score for classification. In a zero-shot setting where the class names are unknown, PEEB outperforms CLIP by a large margin (~10x in accuracy). Compared to part-based classifiers, PEEB is not only the state-of-the-art on the supervised-learning setting (88.80% accuracy) but also the first to enable users to edit the class definitions to form a new classifier without retraining. Compar
    
[^20]: ERBench：基于实体关系的可自动验证的大规模语言模型幻觉基准

    ERBench: An Entity-Relationship based Automatically Verifiable Hallucination Benchmark for Large Language Models

    [https://arxiv.org/abs/2403.05266](https://arxiv.org/abs/2403.05266)

    ERBench是一个基于实体关系的大型语言模型幻觉基准，通过自动转换任何关系数据库并构建可自动验证的问题，以支持复杂性评估和调试

    

    大型语言模型（LLMs）在各种应用中取得了前所未有的性能，然而它们的评估仍然是一个关键问题。现有的幻觉基准要么是静态的，要么缺乏可调整的复杂性进行彻底分析。我们认为利用现有的关系数据库是构建基准的一种有希望的方法，因为它们通过功能依赖关系可以准确描述知识。我们提出了ERBench，可以自动将任何关系数据库转换为基于实体关系（ER）模型的基准。我们的关键想法是使用数据库模式、记录和功能依赖来构建问题，以便可以自动验证。此外，我们使用外键约束来连接关系和构建多跳问题，这些问题可以任意复杂，用于调试LLMs的中间答案。最后，ERBench支持持续评估，多模态qu

    arXiv:2403.05266v1 Announce Type: cross  Abstract: Large language models (LLMs) have achieved unprecedented performance in various applications, yet their evaluation remains a critical issue. Existing hallucination benchmarks are either static or lack adjustable complexity for thorough analysis. We contend that utilizing existing relational databases is a promising approach for constructing benchmarks due to their accurate knowledge description via functional dependencies. We propose ERBench to automatically convert any relational database into a benchmark based on the entity-relationship (ER) model. Our key idea is to construct questions using the database schema, records, and functional dependencies such that they can be automatically verified. In addition, we use foreign key constraints to join relations and construct multihop questions, which can be arbitrarily complex and used to debug the intermediate answers of LLMs. Finally, ERBench supports continuous evaluation, multimodal qu
    
[^21]: MMoE: 多模态信息和领域感知专家混合的鲁棒剧透检测

    MMoE: Robust Spoiler Detection with Multi-modal Information and Domain-aware Mixture-of-Experts

    [https://arxiv.org/abs/2403.05265](https://arxiv.org/abs/2403.05265)

    提出了MMoE，一个利用多模态信息进行剧透检测的网络，并采用专家混合技术来增强领域泛化能力。

    

    在线电影评论网站对于电影信息和讨论是非常有价值的。然而，大量的剧透评论会影响观影体验，因此剧透检测变得非常重要。先前的方法通常只关注评论的文本内容，忽略了平台中信息的异质性。为了解决这个问题，我们提出了MMoE，一个利用多模态信息进行剧透检测的网络，并采用专家混合技术来增强领域泛化能力。MMoE首先从用户-电影网络中提取图表、文本和元数据特征，分别从评论的文本内容和评论的元数据中提取信息。为了处理特定类型电影评论中的剧透语言。

    arXiv:2403.05265v1 Announce Type: new  Abstract: Online movie review websites are valuable for information and discussion about movies. However, the massive spoiler reviews detract from the movie-watching experience, making spoiler detection an important task. Previous methods simply focus on reviews' text content, ignoring the heterogeneity of information in the platform. For instance, the metadata and the corresponding user's information of a review could be helpful. Besides, the spoiler language of movie reviews tends to be genre-specific, thus posing a domain generalization challenge for existing methods. To this end, we propose MMoE, a multi-modal network that utilizes information from multiple modalities to facilitate robust spoiler detection and adopts Mixture-of-Experts to enhance domain generalization. MMoE first extracts graph, text, and meta feature from the user-movie network, the review's textual content, and the review's metadata respectively. To handle genre-specific spo
    
[^22]: 通过自适应加权特征进行对抗性多源领域自适应预测单细胞药物敏感性

    Predicting Single-cell Drug Sensitivity by Adaptive Weighted Feature for Adversarial Multi-source Domain Adaptation

    [https://arxiv.org/abs/2403.05260](https://arxiv.org/abs/2403.05260)

    本文提出了一种名为scAdaDrug的多源自适应加权模型，通过对抗性领域自适应从多个源领域中提取药物敏感性相关的域不变特征，并引入自适应权重生成器来自适应地调节每个样本的嵌入，以预测单细胞药物敏感性。

    

    单细胞测序技术的发展推动了大量单细胞转录谱的生成，为探索肿瘤中耐药细胞亚群提供了宝贵机会。然而，迄今为止，单细胞水平的药物敏感性数据仍然稀缺，迫切需要对个体细胞的药物敏感性进行计算预测，这是一项紧迫且具有挑战性的任务。本文提出了一种名为scAdaDrug的多源自适应加权模型，用于预测单细胞药物敏感性。我们利用对抗领域自适应从多个源领域中提取与药物敏感性相关的域不变特征。特别地，我们引入了一种自适应权重生成器，用于产生重要性感知和相互独立的权重，可以自适应地调节每个样本在源和目标领域中的维度级别嵌入。大量实验证明了我们方法的有效性。

    arXiv:2403.05260v1 Announce Type: new  Abstract: The development of single-cell sequencing technology had promoted the generation of a large amount of single-cell transcriptional profiles, providing valuable opportunities to explore drug-resistant cell subpopulations in a tumor. However, the drug sensitivity data in single-cell level is still scarce to date, pressing an urgent and highly challenging task for computational prediction of the drug sensitivity to individual cells. This paper proposed scAdaDrug, a multi-source adaptive weighting model to predict single-cell drug sensitivity. We used an autoencoder to extract domain-invariant features related to drug sensitivity from multiple source domains by exploiting adversarial domain adaptation. Especially, we introduced an adaptive weight generator to produce importance-aware and mutual independent weights, which could adaptively modulate the embedding of each sample in dimension-level for both source and target domains. Extensive exp
    
[^23]: 噪声水平自适应扩散模型用于加速MRI的稳健重建

    Noise Level Adaptive Diffusion Model for Robust Reconstruction of Accelerated MRI

    [https://arxiv.org/abs/2403.05245](https://arxiv.org/abs/2403.05245)

    提出了一种具有噪声水平自适应特性的后验采样策略，可用于解决MRI重建过程中因真实噪声水平变化导致的重建不准确问题。

    

    通常，基于扩散模型的MRI重建方法会逐步去除人为添加的噪声，并强调数据一致性以重建潜在图像。然而，现实世界中的MRI采集已经包含由热涨落引起的固有噪声。使用超快速、高分辨率成像序列进行高级研究，或者使用低场系统（受低收入和中等收入国家青睐）时，这种现象尤其明显。这些常见场景可能导致现有基于扩散模型的重建技术性能亚优或完全失败。具体而言，随着逐渐去除人为添加的噪声，固有的MRI噪声变得越来越明显，使实际噪声水平与预定义去噪时间表不一致，从而导致图像重建不准确。为解决这一问题，我们提出了一种具有新颖噪声水平自适应特性的后验采样策略。

    arXiv:2403.05245v1 Announce Type: cross  Abstract: In general, diffusion model-based MRI reconstruction methods incrementally remove artificially added noise while imposing data consistency to reconstruct the underlying images. However, real-world MRI acquisitions already contain inherent noise due to thermal fluctuations. This phenomenon is particularly notable when using ultra-fast, high-resolution imaging sequences for advanced research, or using low-field systems favored by low- and middle-income countries. These common scenarios can lead to sub-optimal performance or complete failure of existing diffusion model-based reconstruction techniques. Specifically, as the artificially added noise is gradually removed, the inherent MRI noise becomes increasingly pronounced, making the actual noise level inconsistent with the predefined denoising schedule and consequently inaccurate image reconstruction. To tackle this problem, we propose a posterior sampling strategy with a novel NoIse Lev
    
[^24]: 面向基于扩散模型的文本人体图像生成中人性先验有效利用

    Towards Effective Usage of Human-Centric Priors in Diffusion Models for Text-based Human Image Generation

    [https://arxiv.org/abs/2403.05239](https://arxiv.org/abs/2403.05239)

    本文提出了一种新方法，通过将人性先验直接融入模型微调阶段，强化文本提示中的人体相关信息，并引入规模感知和逐步约束，从而有效提升了基于扩散模型的文本人体图像生成质量

    

    Vanilla文本到图像的扩散模型在生成准确的人体图像方面存在困难，通常导致不完美的解剖结构，如不自然的姿势或肢体不成比例。现有方法主要通过对模型进行微调，使用额外图像或添加额外控制（如姿势或深度图）来解决这个问题，这些控制主要在图像生成阶段引入人性先验。本文探讨将这些人性先验直接集成到模型微调阶段，从而在推理阶段消除额外条件的可能性。我们通过提出人性对齐损失来实现这一想法，从文本提示中强化人体相关信息，并在扩散过程中引入具有规模感知和逐步约束的因素，以确保在微调过程中的语义细节丰富性和人体结构准确性。

    arXiv:2403.05239v1 Announce Type: cross  Abstract: Vanilla text-to-image diffusion models struggle with generating accurate human images, commonly resulting in imperfect anatomies such as unnatural postures or disproportionate limbs.Existing methods address this issue mostly by fine-tuning the model with extra images or adding additional controls -- human-centric priors such as pose or depth maps -- during the image generation phase. This paper explores the integration of these human-centric priors directly into the model fine-tuning stage, essentially eliminating the need for extra conditions at the inference stage. We realize this idea by proposing a human-centric alignment loss to strengthen human-related information from the textual prompts within the cross-attention maps. To ensure semantic detail richness and human structural accuracy during fine-tuning, we introduce scale-aware and step-wise constraints within the diffusion process, according to an in-depth analysis of the cross
    
[^25]: 用于医疗保健领域可信机器学习的公平感知可解释建模（FAIM）

    Fairness-Aware Interpretable Modeling (FAIM) for Trustworthy Machine Learning in Healthcare

    [https://arxiv.org/abs/2403.05235](https://arxiv.org/abs/2403.05235)

    FAIM是一个用于提高医疗保健领域机器学习公平性的可解释框架，通过交互界面识别最公平模型，并结合数据驱动证据与临床专家知识，成功减少了性别和种族偏见。

    

    在高风险领域如医疗保健中机器学习不断融入的情况下，对模型公平性提出了重要关切。我们提出了一个可解释框架 - 公平感知可解释建模（FAIM），旨在提高模型的公平性而不影响性能，其特点是一个交互界面，可以从一组高性能模型中识别出一个“更公平”的模型，并促进数据驱动证据与临床专家知识的整合，以增强情境公平性。我们通过在两个真实世界数据库MIMIC-IV-ED和SGH-ED上预测医院入院情况，展示了FAIM在减少性别和种族偏见方面的价值。我们展示了对于这两个数据集，FAIM模型不仅展现了令人满意的歧视性能，而且通过已建立的公平性度量明显减轻了偏见，优于常用的偏见缓解方法。

    arXiv:2403.05235v1 Announce Type: cross  Abstract: The escalating integration of machine learning in high-stakes fields such as healthcare raises substantial concerns about model fairness. We propose an interpretable framework - Fairness-Aware Interpretable Modeling (FAIM), to improve model fairness without compromising performance, featuring an interactive interface to identify a "fairer" model from a set of high-performing models and promoting the integration of data-driven evidence and clinical expertise to enhance contextualized fairness. We demonstrated FAIM's value in reducing sex and race biases by predicting hospital admission with two real-world databases, MIMIC-IV-ED and SGH-ED. We show that for both datasets, FAIM models not only exhibited satisfactory discriminatory performance but also significantly mitigated biases as measured by well-established fairness metrics, outperforming commonly used bias-mitigation methods. Our approach demonstrates the feasibility of improving f
    
[^26]: 利用异构现实世界生存数据开发联邦时间事件评分系统

    Developing Federated Time-to-Event Scores Using Heterogeneous Real-World Survival Data

    [https://arxiv.org/abs/2403.05229](https://arxiv.org/abs/2403.05229)

    提出了一种用于建立多站点生存结果的联邦评分系统的新框架，确保了隐私和通信效率

    

    存活分析在许多医疗应用中扮演着基础组件的角色，对患者特定事件的时间（如某种疾病的发作或死亡）的确定对临床决策至关重要。评分系统被广泛用于快速和高效的风险预测。然而，现有的构建生存评分系统的方法假定数据源自单一来源，这在与多个数据所有者合作时存在隐私挑战。我们提出了一种新颖的框架，用于构建多站点生存结果的联邦评分系统，确保隐私和通信效率。我们将我们的方法应用于新加坡和美国急诊室各自来源的异构生存数据的站点。此外，我们在每个站点独立开发了本地评分。在每个参与者站点的测试数据集中，我们提出的联邦评分系统...

    arXiv:2403.05229v1 Announce Type: new  Abstract: Survival analysis serves as a fundamental component in numerous healthcare applications, where the determination of the time to specific events (such as the onset of a certain disease or death) for patients is crucial for clinical decision-making. Scoring systems are widely used for swift and efficient risk prediction. However, existing methods for constructing survival scores presume that data originates from a single source, posing privacy challenges in collaborations with multiple data owners. We propose a novel framework for building federated scoring systems for multi-site survival outcomes, ensuring both privacy and communication efficiency. We applied our approach to sites with heterogeneous survival data originating from emergency departments in Singapore and the United States. Additionally, we independently developed local scores at each site. In testing datasets from each participant site, our proposed federated scoring system 
    
[^27]: 合成特权信息增强医学图像表示学习

    Synthetic Privileged Information Enhances Medical Image Representation Learning

    [https://arxiv.org/abs/2403.05220](https://arxiv.org/abs/2403.05220)

    合成生成的配对信息显著改善了医学图像表示学习，相比于单模态训练或真实多模态配对数据集，误差减小分别达到4.4倍和5.6倍

    

    多模态自监督表示学习一直被证明是医学图像分析中一种非常有效的方法，提供了强大的任务性能并产生了生物学相关的见解。然而，这些方法严重依赖于大规模配对数据集，这在不存在配对数据或只有少量可用的情况下是不切实际的。相比之下，图像生成方法可以在非常小的数据集上很好地工作，并且可以找到未配对数据集之间的映射，这意味着可以生成有效无限量的配对合成数据。在这项工作中，我们展示了通过合成生成配对信息可以显著改善表示学习，与单模态训练（误差减小达到4.4倍）或真实多模态配对数据集进行训练（误差减小达到5.6倍）相比。

    arXiv:2403.05220v1 Announce Type: cross  Abstract: Multimodal self-supervised representation learning has consistently proven to be a highly effective method in medical image analysis, offering strong task performance and producing biologically informed insights. However, these methods heavily rely on large, paired datasets, which is prohibitive for their use in scenarios where paired data does not exist, or there is only a small amount available. In contrast, image generation methods can work well on very small datasets, and can find mappings between unpaired datasets, meaning an effectively unlimited amount of paired synthetic data can be generated. In this work, we demonstrate that representation learning can be significantly improved by synthetically generating paired information, both compared to training on either single-modality (up to 4.4x error reduction) or authentic multi-modal paired datasets (up to 5.6x error reduction).
    
[^28]: 利用大型语言模型的多角色能力进行开放领域问答

    Harnessing Multi-Role Capabilities of Large Language Models for Open-Domain Question Answering

    [https://arxiv.org/abs/2403.05217](https://arxiv.org/abs/2403.05217)

    提出了LLMQA框架，利用大型语言模型在开放领域问答中扮演生成器、重新排序器和评估器等多重角色，结合了检索和生成证据的优势。

    

    开放领域问答（ODQA）已经成为信息系统中的一个关键研究焦点。现有方法主要遵循两种范式来收集证据：（1）\textit{检索-然后阅读}范式从外部语料库中检索相关文档；和（2）\textit{生成-然后阅读}范式使用大型语言模型（LLMs）生成相关文档。然而，这两种方法都不能完全满足证据的多方面要求。因此，我们提出了LLMQA，一个通用框架，将ODQA过程分为三个基本步骤：查询扩展，文档选择和答案生成，结合了检索和生成证据的优势。由于LLMs展示了其出色的能力来完成各种任务，我们指导LLMs在我们的框架内扮演生成器、重新排序器和评估器等多种角色，使它们融合在ODQA过程中协作。

    arXiv:2403.05217v1 Announce Type: cross  Abstract: Open-domain question answering (ODQA) has emerged as a pivotal research spotlight in information systems. Existing methods follow two main paradigms to collect evidence: (1) The \textit{retrieve-then-read} paradigm retrieves pertinent documents from an external corpus; and (2) the \textit{generate-then-read} paradigm employs large language models (LLMs) to generate relevant documents. However, neither can fully address multifaceted requirements for evidence. To this end, we propose LLMQA, a generalized framework that formulates the ODQA process into three basic steps: query expansion, document selection, and answer generation, combining the superiority of both retrieval-based and generation-based evidence. Since LLMs exhibit their excellent capabilities to accomplish various tasks, we instruct LLMs to play multiple roles as generators, rerankers, and evaluators within our framework, integrating them to collaborate in the ODQA process. 
    
[^29]: 克服跨领域数据不平等问题的半监督领域泛化

    Overcoming Data Inequality across Domains with Semi-Supervised Domain Generalization

    [https://arxiv.org/abs/2403.05209](https://arxiv.org/abs/2403.05209)

    本文提出了一种名为ProUD的新算法，通过领域感知原型和通过不确定性自适应混合标记和未标记领域的渐进泛化，有效解决了跨领域数据不平等问题中的半监督领域泛化挑战。

    

    虽然机器学习取得了巨大的进展，但在各个来源和人群之间仍然存在数据可用性的显著差异。在不同领域之间的这种不平等在为数据有限的人建模时带来挑战，这可能会引起深刻的实际和伦理关注。本文针对跨领域数据不平等问题提出了一个代表性案例，即半监督领域泛化（SSDG），其中只有一个领域被标记，而其他领域没有标签。我们提出了一种新算法，ProUD，通过领域感知原型和通过不确定性自适应混合标记和未标记领域的渐进泛化，可以有效学习领域不变特征。我们在三个不同的基准数据集上的实验证明了ProUD的有效性，优于包括单一领域泛化在内的所有基线模型。

    arXiv:2403.05209v1 Announce Type: cross  Abstract: While there have been considerable advancements in machine learning driven by extensive datasets, a significant disparity still persists in the availability of data across various sources and populations. This inequality across domains poses challenges in modeling for those with limited data, which can lead to profound practical and ethical concerns. In this paper, we address a representative case of data inequality problem across domains termed Semi-Supervised Domain Generalization (SSDG), in which only one domain is labeled while the rest are unlabeled. We propose a novel algorithm, ProUD, which can effectively learn domain-invariant features via domain-aware prototypes along with progressive generalization via uncertainty-adaptive mixing of labeled and unlabeled domains. Our experiments on three different benchmark datasets demonstrate the effectiveness of ProUD, outperforming all baseline models including single domain generalizati
    
[^30]: 追踪多语言语言模型中事实的根源：独立的、共享的和转移的知识

    Tracing the Roots of Facts in Multilingual Language Models: Independent, Shared, and Transferred Knowledge

    [https://arxiv.org/abs/2403.05189](https://arxiv.org/abs/2403.05189)

    本研究追踪了多语言语言模型中事实的来源，发现了三种模式：语言独立、跨语言共享和转移，为区分它们提出了方法，凸显了在多语言LMs中保持一致事实知识的挑战，强调了需要在ML-LMs中改进事实表示学习。

    

    获取低资源语言模型（LMs）中的事实知识是一个严峻的挑战，因此需要在多语言LMs（ML-LMs）中进行跨语言转移。本研究探讨了ML-LMs如何获取和表示事实知识。我们首先使用多语言事实知识探测数据集mLAMA对ML-LMs（特别是多语言BERT）进行神经元调查。然后我们追溯事实的根源（维基百科），以确定ML-LMs获取特定事实的方式。最后，我们确定了ML-LMs获取和表示事实的三种模式：语言独立、跨语言共享和转移，并制定了区分它们的方法。我们的发现突显了跨语言保持一致的事实知识的挑战，强调了在ML-LMs中进行更好的事实表示学习的必要性。

    arXiv:2403.05189v1 Announce Type: cross  Abstract: Acquiring factual knowledge for language models (LMs) in low-resource languages poses a serious challenge, thus resorting to cross-lingual transfer in multilingual LMs (ML-LMs). In this study, we ask how ML-LMs acquire and represent factual knowledge. Using the multilingual factual knowledge probing dataset, mLAMA, we first conducted a neuron investigation of ML-LMs (specifically, multilingual BERT). We then traced the roots of facts back to the knowledge source (Wikipedia) to identify the ways in which ML-LMs acquire specific facts. We finally identified three patterns of acquiring and representing facts in ML-LMs: language-independent, cross-lingual shared and transferred, and devised methods for differentiating them. Our findings highlight the challenge of maintaining consistent factual knowledge across languages, underscoring the need for better fact representation learning in ML-LMs.
    
[^31]: 持续学习与灾难性遗忘

    Continual Learning and Catastrophic Forgetting

    [https://arxiv.org/abs/2403.05175](https://arxiv.org/abs/2403.05175)

    人工神经网络在持续学习过程中容易出现灾难性遗忘，这一问题是深度学习中持续学习领域的关键挑战。

    

    本书章节探讨了持续学习的动态过程，即从非静态数据流中逐步学习的过程。尽管持续学习是人脑的一种自然技能，但对于人工神经网络来说却是非常具有挑战性的。一个重要原因是在学习新知识时，这些网络往往会迅速而彻底地忘记以前所学的内容，这一现象被称为灾难性遗忘。在过去的十年中，持续学习已成为深度学习中一个被广泛研究的课题。本书章节回顾了这一领域产生的见解。

    arXiv:2403.05175v1 Announce Type: cross  Abstract: This book chapter delves into the dynamics of continual learning, which is the process of incrementally learning from a non-stationary stream of data. Although continual learning is a natural skill for the human brain, it is very challenging for artificial neural networks. An important reason is that, when learning something new, these networks tend to quickly and drastically forget what they had learned before, a phenomenon known as catastrophic forgetting. Especially in the last decade, continual learning has become an extensively studied topic in deep learning. This book chapter reviews the insights that this field has generated.
    
[^32]: 通过轻量级不确定性估计对抗策略优化克服了奖励过度优化问题

    Overcoming Reward Overoptimization via Adversarial Policy Optimization with Lightweight Uncertainty Estimation

    [https://arxiv.org/abs/2403.05171](https://arxiv.org/abs/2403.05171)

    本论文提出了对抗策略优化（AdvPO）来解决强化学习领域中奖励过度优化的问题，通过量化奖励的不确定性，并围绕奖励模型预测的置信区间进行分布鲁棒的优化，从而有效缓解了该问题。

    

    我们引入了对抗策略优化（AdvPO），这是一种新颖的解决方案，用于解决强化学习从人类反馈中的奖励过度优化问题，适用于大型语言模型（LLMs）。AdvPO围绕奖励模型预测的置信区间解决了一个分布鲁棒的优化问题，以改进策略。通过对Anthropic HH和TL;DR摘要数据集进行全面实验，我们展示了AdvPO在减轻过度优化问题方面的有效性。

    arXiv:2403.05171v1 Announce Type: cross  Abstract: We introduce Adversarial Policy Optimization (AdvPO), a novel solution to the pervasive issue of reward over-optimization in Reinforcement Learning from Human Feedback (RLHF) for Large Language Models (LLMs). Over-optimization occurs when a reward model serves as an imperfect proxy for human preference, and RL-driven policy optimization erroneously exploits reward inaccuracies. In this paper, we begin by introducing a lightweight way to quantify uncertainties in rewards, relying solely on the last layer embeddings of the reward model, without the need for computationally expensive reward ensembles. AdvPO then addresses a distributionally robust optimization problem centred around the confidence interval of the reward model's predictions for policy improvement. Through comprehensive experiments on the Anthropic HH and TL;DR summarization datasets, we illustrate the efficacy of AdvPO in mitigating the overoptimization issue, consequently
    
[^33]: 通过无需训练的码本优化和分层对齐解锁多模态统一离散表示的潜力

    Unlocking the Potential of Multimodal Unified Discrete Representation through Training-Free Codebook Optimization and Hierarchical Alignment

    [https://arxiv.org/abs/2403.05168](https://arxiv.org/abs/2403.05168)

    通过无需训练的码本优化和分层对齐，本研究提出了一种方法扩展了多模态统一表示的细粒度，并实现了更好的跨模态泛化。

    

    最近在表示学习方面的进展表明多模态对齐的重要性。利用统一码本的双交叉模态信息解缠（DCID）模型在实现细粒度表示和跨模态泛化方面取得了令人期待的结果。然而，它仍受到对所有通道的均等对待以及忽视次要事件信息的阻碍，导致来自无关通道的干扰并在细粒度任务中表现有限。因此，在这项工作中，我们提出了一种无需训练的码本优化（TOC）方法，通过在统一空间中选择重要通道来增强模型性能。此外，我们引入了分层双交叉模态信息解缠（H-DCID）方法将信息分离和对齐扩展到两个级别，捕捉更多跨模态细节。实验结果表明显著的改进。

    arXiv:2403.05168v1 Announce Type: cross  Abstract: Recent advances in representation learning have demonstrated the significance of multimodal alignment. The Dual Cross-modal Information Disentanglement (DCID) model, utilizing a unified codebook, shows promising results in achieving fine-grained representation and cross-modal generalization. However, it is still hindered by equal treatment of all channels and neglect of minor event information, resulting in interference from irrelevant channels and limited performance in fine-grained tasks. Thus, in this work, We propose a Training-free Optimization of Codebook (TOC) method to enhance model performance by selecting important channels in the unified space without retraining. Additionally, we introduce the Hierarchical Dual Cross-modal Information Disentanglement (H-DCID) approach to extend information separation and alignment to two levels, capturing more cross-modal details. The experiment results demonstrate significant improvements a
    
[^34]: 合成数据生成用于系统辨识：利用类似系统的知识转移

    Synthetic data generation for system identification: leveraging knowledge transfer from similar systems

    [https://arxiv.org/abs/2403.05164](https://arxiv.org/abs/2403.05164)

    本文提出了一种从类似系统中进行知识转移的新方法，用于生成合成数据，以改善模型的泛化能力和鲁棒性。

    

    本文针对学习动态系统中过拟合的挑战，引入了一种新颖的合成数据生成方法，旨在增强模型的泛化能力和鲁棒性，特别是在数据稀缺情况下。所提出的方法的核心是从同一类系统中进行知识转移的概念。具体而言，通过一个预训练的元模型生成合成数据，该元模型描述了假定所关注的系统所属的一类系统。训练数据具有两个目的：首先，作为预训练的元模型的输入，用以辨别系统的动态，从而能够预测其行为，从而生成新输入序列的合成输出序列；其次，与合成数据一起，用于定义用于模型估计的损失函数。验证数据集用于调整一个标量超参数，平衡关系

    arXiv:2403.05164v1 Announce Type: cross  Abstract: This paper addresses the challenge of overfitting in the learning of dynamical systems by introducing a novel approach for the generation of synthetic data, aimed at enhancing model generalization and robustness in scenarios characterized by data scarcity. Central to the proposed methodology is the concept of knowledge transfer from systems within the same class. Specifically, synthetic data is generated through a pre-trained meta-model that describes a broad class of systems to which the system of interest is assumed to belong. Training data serves a dual purpose: firstly, as input to the pre-trained meta model to discern the system's dynamics, enabling the prediction of its behavior and thereby generating synthetic output sequences for new input sequences; secondly, in conjunction with synthetic data, to define the loss function used for model estimation. A validation dataset is used to tune a scalar hyper-parameter balancing the rel
    
[^35]: 能量受限的无线边缘网络中的自适应分裂学习

    Adaptive Split Learning over Energy-Constrained Wireless Edge Networks

    [https://arxiv.org/abs/2403.05158](https://arxiv.org/abs/2403.05158)

    设计了一种在无线边缘网络中为设备动态选择分裂点并为服务器分配计算资源的自适应分裂学习方案，以最小化平均训练延迟为目标，并提出了一种名为OPEN的在线算法解决此问题。

    

    分裂学习（SL）是一种有希望的用于训练人工智能（AI）模型的方法，其中设备与服务器合作以分布式方式训练AI模型，基于相同的固定分裂点。然而，由于设备的异构性和信道条件的变化，这种方式在训练延迟和能量消耗方面并不是最优的。在本文中，我们设计了一种自适应分裂学习（ASL）方案，可以在无线边缘网络中为设备动态选择分裂点，并为服务器分配计算资源。我们制定了一个优化问题，旨在在满足长期能量消耗约束的情况下最小化平均训练延迟。解决这个问题的困难在于缺乏未来信息和混合整数规划（MIP）。为了解决这个问题，我们提出了一种利用Lyapunov理论的在线算法，名为OPEN，它将其分解为一个具有当前的新MIP问题。

    arXiv:2403.05158v1 Announce Type: cross  Abstract: Split learning (SL) is a promising approach for training artificial intelligence (AI) models, in which devices collaborate with a server to train an AI model in a distributed manner, based on a same fixed split point. However, due to the device heterogeneity and variation of channel conditions, this way is not optimal in training delay and energy consumption. In this paper, we design an adaptive split learning (ASL) scheme which can dynamically select split points for devices and allocate computing resource for the server in wireless edge networks. We formulate an optimization problem to minimize the average training latency subject to long-term energy consumption constraint. The difficulties in solving this problem are the lack of future information and mixed integer programming (MIP). To solve it, we propose an online algorithm leveraging the Lyapunov theory, named OPEN, which decomposes it into a new MIP problem only with the curren
    
[^36]: 朝向机器心理学：大型语言模型预测人类记忆

    Towards a Psychology of Machines: Large Language Models Predict Human Memory

    [https://arxiv.org/abs/2403.05152](https://arxiv.org/abs/2403.05152)

    这项研究探索了大型语言模型在预测基于语言的记忆任务中的表现，并通过其对模棱两可句子的处理能力增进了对人类认知机制的理解。

    

    大型语言模型（LLMs）在各种任务中展示出了非凡的能力，尽管缺乏人类认知基础。这引发了一个问题：除了简单模仿人类语言模式，这些模型能否提供关于人类认知机制的洞见？本研究探讨了ChatGPT在预测基于语言的记忆任务中人类表现的能力。基于文本理解理论，我们假设识别模棱两可的句子（例如，“因为比尔喝酒，所以酒从未留在房子里”）在前面提供与上下文相关信息的情况下会得到促进。参与者，无论是人类还是ChatGPT，都被呈现成对的句子。第二个句子总是一个旨在固有地模棱两可的花园路径句，而第一个句子则提供了合适的（例如，“比尔患有慢性酒精中毒”）或不合适的上下文（例如，“比尔喜欢打高尔夫”）。

    arXiv:2403.05152v1 Announce Type: cross  Abstract: Large language models (LLMs) are demonstrating remarkable capabilities across various tasks despite lacking a foundation in human cognition. This raises the question: can these models, beyond simply mimicking human language patterns, offer insights into the mechanisms underlying human cognition? This study explores the ability of ChatGPT to predict human performance in a language-based memory task. Building upon theories of text comprehension, we hypothesize that recognizing ambiguous sentences (e.g., "Because Bill drinks wine is never kept in the house") is facilitated by preceding them with contextually relevant information. Participants, both human and ChatGPT, were presented with pairs of sentences. The second sentence was always a garden-path sentence designed to be inherently ambiguous, while the first sentence either provided a fitting (e.g., "Bill has chronic alcoholism") or an unfitting context (e.g., "Bill likes to play golf"
    
[^37]: 光子晶体面射激光器的逆向设计是序列建模问题

    Inverse Design of Photonic Crystal Surface Emitting Lasers is a Sequence Modeling Problem

    [https://arxiv.org/abs/2403.05149](https://arxiv.org/abs/2403.05149)

    引入Transformer架构, 本文提出了一个名为PCSEL逆向设计Tra的新框架，将光子晶体面射激光器的逆向设计建模为一个序列决策问题，利用RL方法从头开始构建满意的PCSEL结构。

    

    arXiv:2403.05149v1 公告类型: 跨越 摘要：光子晶体面发射激光器（PCSEL）的逆向设计需要物理、材料科学和量子力学方面的专业知识，这是极具劳动密集性的。先进的人工智能技术，特别是强化学习（RL），已经成为增强和加速这种逆向设计过程的强大工具。通过将PCSEL的逆向设计建模为一个序列决策问题，RL方法可以从头开始构建一个满意的PCSEL结构。然而，由于在线与精确昂贵的仿真环境进行交互导致的数据低效性阻碍了RL方法的广泛适用性。最近，序列模型，特别是Transformer架构，由于其简单性和可扩展性到大型语言模型，在顺序决策问题中展现出了令人信服的性能。在本文中，我们介绍了一个名为PCSEL逆向设计Tra的新框架。

    arXiv:2403.05149v1 Announce Type: cross  Abstract: Photonic Crystal Surface Emitting Lasers (PCSEL)'s inverse design demands expert knowledge in physics, materials science, and quantum mechanics which is prohibitively labor-intensive. Advanced AI technologies, especially reinforcement learning (RL), have emerged as a powerful tool to augment and accelerate this inverse design process. By modeling the inverse design of PCSEL as a sequential decision-making problem, RL approaches can construct a satisfactory PCSEL structure from scratch. However, the data inefficiency resulting from online interactions with precise and expensive simulation environments impedes the broader applicability of RL approaches. Recently, sequential models, especially the Transformer architecture, have exhibited compelling performance in sequential decision-making problems due to their simplicity and scalability to large language models. In this paper, we introduce a novel framework named PCSEL Inverse Design Tra
    
[^38]: ChatUIE：利用大型语言模型探索基于聊天的统一信息提取

    ChatUIE: Exploring Chat-based Unified Information Extraction using Large Language Models

    [https://arxiv.org/abs/2403.05132](https://arxiv.org/abs/2403.05132)

    ChatUIE利用大型语言模型探索基于聊天的统一信息提取，通过强化学习和生成约束提高对自然语言中结构化信息的提取能力。

    

    最近大型语言模型的发展在一般的聊天中展现出令人印象深刻的性能。然而，它们在特定领域的能力，特别是在信息提取方面，存在一定的局限性。从偏离已知模式或指令的自然语言中提取结构化信息对于之前基于提示的方法来说是具有挑战性的。这促使我们探索聊天型语言模型中的领域特定建模作为从自然语言中提取结构化信息的解决方案。在本文中，我们提出了ChatUIE，这是一个基于ChatGLM构建的创新的统一信息提取框架。同时，采用强化学习来改进和对齐涉及混乱和有限样本的各种任务。此外，我们整合了生成约束来解决在输入中不存在的元素生成的问题。我们的实验结果表明ChatUIE能够...

    arXiv:2403.05132v1 Announce Type: cross  Abstract: Recent advancements in large language models have shown impressive performance in general chat. However, their domain-specific capabilities, particularly in information extraction, have certain limitations. Extracting structured information from natural language that deviates from known schemas or instructions has proven challenging for previous prompt-based methods. This motivated us to explore domain-specific modeling in chat-based language models as a solution for extracting structured information from natural language. In this paper, we present ChatUIE, an innovative unified information extraction framework built upon ChatGLM. Simultaneously, reinforcement learning is employed to improve and align various tasks that involve confusing and limited samples. Furthermore, we integrate generation constraints to address the issue of generating elements that are not present in the input. Our experimental results demonstrate that ChatUIE ca
    
[^39]: Sora作为AGI世界模型？关于文本到视频生成的完整调查

    Sora as an AGI World Model? A Complete Survey on Text-to-Video Generation

    [https://arxiv.org/abs/2403.05131](https://arxiv.org/abs/2403.05131)

    对文本到视频生成技术的发展进行了详细调查, 着重介绍了从传统生成模型到尖端Sora模型的转变，强调了可扩展性和通用性的发展。

    

    arXiv:2403.05131v1 公告类型: 新摘要: 文本到视频生成标志着生成式人工智能不断发展领域中的重要前沿，整合了文本到图像合成、视频字幕和文本引导编辑的进展。本调查对文本到视频技术的发展进行了批判性审视，重点关注传统生成模型向尖端Sora模型转变的过程，突出了可扩展性和通用性的发展。区别于以往作品的分析，我们深入探讨了这些模型的技术框架和演化路径。此外，我们还深入探讨了实际应用，并解决了伦理和技术挑战，如无法执行多实体处理、理解因果关系学习、理解物理互动、感知物体缩放和比例以及对抗物体幻觉，这也是生成模型中长期存在的问题。

    arXiv:2403.05131v1 Announce Type: new  Abstract: Text-to-video generation marks a significant frontier in the rapidly evolving domain of generative AI, integrating advancements in text-to-image synthesis, video captioning, and text-guided editing. This survey critically examines the progression of text-to-video technologies, focusing on the shift from traditional generative models to the cutting-edge Sora model, highlighting developments in scalability and generalizability. Distinguishing our analysis from prior works, we offer an in-depth exploration of the technological frameworks and evolutionary pathways of these models. Additionally, we delve into practical applications and address ethical and technological challenges such as the inability to perform multiple entity handling, comprehend causal-effect learning, understand physical interaction, perceive object scaling and proportioning, and combat object hallucination which is also a long-standing problem in generative models. Our c
    
[^40]: 从链到树：在知识图谱上将链式规则优化为树形规则

    From Chain to Tree: Refining Chain-like Rules into Tree-like Rules on Knowledge Graphs

    [https://arxiv.org/abs/2403.05130](https://arxiv.org/abs/2403.05130)

    提出了在知识图谱上将链式规则优化为树形规则的概念，并提出有效框架，实现了更好的推理性能。

    

    具有很好解释能力和可控性的基于规则的方法在诸如知识推理和决策支持等许多任务中发挥着重要作用。然而，现有研究主要集中在学习链式规则上，这限制了它们的语义表达和准确的预测能力。因此，链式规则通常会在不正确的基础值上触发，产生不准确甚至错误的推理结果。在本文中，我们提出了在知识图谱上的树状规则的概念，以扩展应用范围并提高基于规则的方法的推理能力。同时，我们提出了一个有效的框架，将链式规则优化为树状规则。对四个公共数据集的实验比较表明，所提出的框架可以轻松适应其他链式规则归纳方法，并且优化后的树状规则始终在链接预测上表现优于链式规则。

    arXiv:2403.05130v1 Announce Type: new  Abstract: With good explanatory power and controllability, rule-based methods play an important role in many tasks such as knowledge reasoning and decision support. However, existing studies primarily focused on learning chain-like rules, which limit their semantic expressions and accurate prediction abilities. As a result, chain-like rules usually fire on the incorrect grounding values, producing inaccurate or even erroneous reasoning results. In this paper, we propose the concept of tree-like rules on knowledge graphs to expand the application scope and improve the reasoning ability of rule-based methods. Meanwhile, we propose an effective framework for refining chain-like rules into tree-like rules. Experimental comparisons on four public datasets show that the proposed framework can easily adapt to other chain-like rule induction methods and the refined tree-like rules consistently achieve better performances than chain-like rules on link pred
    
[^41]: 揭示分子魔法：人工智能对超级可伸展水凝胶形成的洞察

    Unraveling the Molecular Magic: AI Insights on the Formation of Extraordinarily Stretchable Hydrogels

    [https://arxiv.org/abs/2403.05129](https://arxiv.org/abs/2403.05129)

    本研究通过人工智能预测系统探索了一种通过两种聚合物相互连接，形成具有独特结构的水凝胶的新方法，并命名为“跨链网”。

    

    通过有意识地调控过硫酸铵、亚甲基双丙烯酰胺、二甲基丙烯酰胺和聚乙烯氧化物浓度，成功研发出一种具有极强可拉伸性的水凝胶，能延展至其原始长度的260倍。本研究旨在通过探索潜在的反应机制，借助人工智能预测系统，阐明在此独特现象背后的分子结构。人工智能预测器引入了一种新的方法来相互连接两种聚合物，涉及形成与线性链相互连接的网络，遵循随机链断裂。这种新颖的结构导致了一种独特类型的水凝胶的出现，此处称为“跨链网”。此外，利用傅里叶变换红外光谱（FTIR）研究可能涉及到提出机制的功能基团，主要包括酯的形成。

    arXiv:2403.05129v1 Announce Type: cross  Abstract: The deliberate manipulation of ammonium persulfate, methylenebisacrylamide, dimethyleacrylamide, and polyethylene oxide concentrations resulted in the development of a hydrogel with an exceptional stretchability, capable of extending up to 260 times its original length. This study aims to elucidate the molecular architecture underlying this unique phenomenon by exploring potential reaction mechanisms, facilitated by an artificial intelligence prediction system. Artificial intelligence predictor introduces a novel approach to interlinking two polymers, involving the formation of networks interconnected with linear chains following random chain scission. This novel configuration leads to the emergence of a distinct type of hydrogel, herein referred to as a "Span Network." Additionally, Fourier-transform infrared spectroscopy (FTIR) is used to investigate functional groups that may be implicated in the proposed mechanism, with ester forma
    
[^42]: 评估文本到图像生成模型：关于人类图像合成的经验性研究

    Evaluating Text-to-Image Generative Models: An Empirical Study on Human Image Synthesis

    [https://arxiv.org/abs/2403.05125](https://arxiv.org/abs/2403.05125)

    本文提出了一个细致的评估框架，用于评估文本到图像生成模型，针对人类图像合成。我们引入了一个创新的美学分数预测模型，评估生成图像的视觉吸引力，并展示了第一个标记有生成的人类图像中低质量区域的数据集，以促进自动缺陷检测，同时也研究了模型对概念覆盖度和公平性的影响。

    

    在本文中，我们提出了一个细致的评估框架，用于评估文本到图像（T2I）生成模型，应用于人类图像合成。我们的框架将评估分为两个不同的方面：第一，专注于图像质量，如美学和逼真度；第二，通过概念覆盖度和公平性来检查文本条件。我们引入了一种创新的美学分数预测模型，评估生成图像的视觉吸引力，并展示了第一个标记有生成的人类图像中低质量区域的数据集，以促进自动缺陷检测。我们对概念覆盖范围的探索调查了模型在准确解释和呈现基于文本的概念方面的有效性，而我们对公平性的分析揭示了模型输出中的偏见，重点关注性别、种族和年龄。虽然我们的研究基于人类图像，但这种双重方面的方法是为了

    arXiv:2403.05125v1 Announce Type: cross  Abstract: In this paper, we present an empirical study introducing a nuanced evaluation framework for text-to-image (T2I) generative models, applied to human image synthesis. Our framework categorizes evaluations into two distinct groups: first, focusing on image qualities such as aesthetics and realism, and second, examining text conditions through concept coverage and fairness. We introduce an innovative aesthetic score prediction model that assesses the visual appeal of generated images and unveils the first dataset marked with low-quality regions in generated human images to facilitate automatic defect detection. Our exploration into concept coverage probes the model's effectiveness in interpreting and rendering text-based concepts accurately, while our analysis of fairness reveals biases in model outputs, with an emphasis on gender, race, and age. While our study is grounded in human imagery, this dual-faceted approach is designed with the 
    
[^43]: RLPeri: 利用强化学习和卷积特征提取加速视野测定测试

    RLPeri: Accelerating Visual Perimetry Test with Reinforcement Learning and Convolutional Feature Extraction

    [https://arxiv.org/abs/2403.05112](https://arxiv.org/abs/2403.05112)

    RLPeri是一种基于强化学习的方法，旨在通过确定最佳位置顺序和初始刺激值来加速视野测定测试，同时通过奖励塑形技术进一步提高测试性能。

    

    视野测定是一项帮助检测由眼部或神经系统疾病引起的视力问题的重要眼部检查。在测试过程中，患者将凝视在特定位置，同时在中心和周围视野呈现不同强度的光刺激。根据患者对刺激的反应，确定视野映射和敏感度。然而，对患者来说在整个测试过程中保持高度集中可能具有挑战性，导致检查时间增加，精度降低。 在这项工作中，我们提出了RLPeri，一种基于强化学习的方法来优化视野测定测试。通过确定最佳位置顺序和初始刺激值，我们的目标是减少检查时间而不影响准确度。此外，我们还采用奖励塑形技术来进一步提高测试性能。

    arXiv:2403.05112v1 Announce Type: new  Abstract: Visual perimetry is an important eye examination that helps detect vision problems caused by ocular or neurological conditions. During the test, a patient's gaze is fixed at a specific location while light stimuli of varying intensities are presented in central and peripheral vision. Based on the patient's responses to the stimuli, the visual field mapping and sensitivity are determined. However, maintaining high levels of concentration throughout the test can be challenging for patients, leading to increased examination times and decreased accuracy.   In this work, we present RLPeri, a reinforcement learning-based approach to optimize visual perimetry testing. By determining the optimal sequence of locations and initial stimulus values, we aim to reduce the examination time without compromising accuracy. Additionally, we incorporate reward shaping techniques to further improve the testing performance. To monitor the patient's responses 
    
[^44]: 机器人操纵的高效数据收集通过组合概括

    Efficient Data Collection for Robotic Manipulation via Compositional Generalization

    [https://arxiv.org/abs/2403.05110](https://arxiv.org/abs/2403.05110)

    通过研究机器人策略的复合能力，可以避免收集处理复合情况所需的数据。

    

    数据收集在机器人操纵中变得越来越重要，然而如何有效地收集数据以促进广泛泛化仍然缺乏很多理解。最近关于大规模机器人数据收集的研究通常在数据收集过程中变化了许多环境因素，如物体类型和桌面纹理。虽然这些研究试图涵盖各种各样的场景，但它们并没有明确考虑到基于数据训练的策略可能具有的复合能力。如果机器人策略能够从它们的训练数据中组合不同的环境变量（例如物体类型、桌面高度）以在遇到看不见的因素组合时成功，那么我们就可以利用这一点来避免为复合处理的情况收集数据。为了研究这种可能性，我们在仿真环境和实际机器人上进行了彻底的实证研究。

    arXiv:2403.05110v1 Announce Type: cross  Abstract: Data collection has become an increasingly important problem in robotic manipulation, yet there still lacks much understanding of how to effectively collect data to facilitate broad generalization. Recent works on large-scale robotic data collection typically vary a wide range of environmental factors during data collection, such as object types and table textures. While these works attempt to cover a diverse variety of scenarios, they do not explicitly account for the possible compositional abilities of policies trained on the data. If robot policies are able to compose different environmental factors of variation (e.g., object types, table heights) from their training data to succeed when encountering unseen factor combinations, then we can exploit this to avoid collecting data for situations that composition would address. To investigate this possibility, we conduct thorough empirical studies both in simulation and on a real robot t
    
[^45]: 任务驱动的多无人机联盟形成机制

    A Task-Driven Multi-UAV Coalition Formation Mechanism

    [https://arxiv.org/abs/2403.05108](https://arxiv.org/abs/2403.05108)

    本文提出了一种考虑联盟工作能力和任务需求关系的新型多无人机联盟网络协作任务完成模型，通过利用基于联盟收入阈值的收入函数刺激匹配任务需求的联盟形成，并提出了一种基于边际效用的联盟形成算法。

    

    随着无人机技术的快速发展，无人机联盟形成问题已成为一个热点。因此，设计任务驱动的多无人机联盟形成机制已经成为一个具有挑战性的问题。然而，现有的联盟形成机制存在着无人机与任务要求之间的关联性低，导致整体联盟效用低且联盟结构不稳定。为解决这些问题，本文提出了一种新颖的多无人机联盟网络协作任务完成模型，考虑了联盟工作能力和任务需求关系。该模型通过基于联盟收入阈值的收入函数来刺激与任务要求匹配的联盟形成。随后，提出了一种基于边际效用的联盟形成算法。具体来说，该算法利用Shapley值实现了联盟内公平效用分配。

    arXiv:2403.05108v1 Announce Type: cross  Abstract: With the rapid advancement of UAV technology, the problem of UAV coalition formation has become a hotspot. Therefore, designing task-driven multi-UAV coalition formation mechanism has become a challenging problem. However, existing coalition formation mechanisms suffer from low relevance between UAVs and task requirements, resulting in overall low coalition utility and unstable coalition structures. To address these problems, this paper proposed a novel multi-UAV coalition network collaborative task completion model, considering both coalition work capacity and task-requirement relationships. This model stimulated the formation of coalitions that match task requirements by using a revenue function based on the coalition's revenue threshold. Subsequently, an algorithm for coalition formation based on marginal utility was proposed. Specifically, the algorithm utilized Shapley value to achieve fair utility distribution within the coalitio
    
[^46]: 学习重新匹配不匹配的对以获得稳健的跨模态检索

    Learning to Rematch Mismatched Pairs for Robust Cross-Modal Retrieval

    [https://arxiv.org/abs/2403.05105](https://arxiv.org/abs/2403.05105)

    通过提出基于最优传输的通用框架L2RM，学习重新匹配不匹配的对，以解决跨模态检索中由部分不匹配对引起的性能问题。

    

    收集匹配良好的多媒体数据集对于训练跨模态检索模型至关重要。然而，在现实场景中，大量多模态数据来自于互联网，其中不可避免地包含部分不匹配的对。这些语义不相关的数据将显著损害跨模态检索性能。先前的工作倾向于通过估计软对应关系来减小部分不匹配对的贡献。本文旨在从一个新的角度解决这一挑战，即未配对样本之间的潜在语义相似性可能使得从不匹配对中挖掘有用知识成为可能。为实现这一目标，我们提出L2RM，一个基于最优传输（OT）的通用框架，学习重新匹配不匹配对。具体而言，L2RM旨在通过寻找不同模态之间的最小成本传输计划来生成经过精细调整的对齐。

    arXiv:2403.05105v1 Announce Type: cross  Abstract: Collecting well-matched multimedia datasets is crucial for training cross-modal retrieval models. However, in real-world scenarios, massive multimodal data are harvested from the Internet, which inevitably contains Partially Mismatched Pairs (PMPs). Undoubtedly, such semantical irrelevant data will remarkably harm the cross-modal retrieval performance. Previous efforts tend to mitigate this problem by estimating a soft correspondence to down-weight the contribution of PMPs. In this paper, we aim to address this challenge from a new perspective: the potential semantic similarity among unpaired samples makes it possible to excavate useful knowledge from mismatched pairs. To achieve this, we propose L2RM, a general framework based on Optimal Transport (OT) that learns to rematch mismatched pairs. In detail, L2RM aims to generate refined alignments by seeking a minimal-cost transport plan across different modalities. To formalize the remat
    
[^47]: 文化如何塑造人们对人工智能的期望

    How Culture Shapes What People Want From AI

    [https://arxiv.org/abs/2403.05104](https://arxiv.org/abs/2403.05104)

    本研究提出了一个新的概念框架，旨在通过独立和相互依存的自我和环境文化模型来拓展、重新想象和重视主流人工智能愿景的研究。调查显示，不同文化背景的人们对人工智能的期望存在差异，中国受访者更看重与人工智能建立联系，更偏好具有影响力的人工智能。ostringstream中也存在欧裔美国和中国受访者文化模型的反映。

    

    有迫切需要将不同文化群体的观点纳入人工智能发展中。我们提出了一个旨在通过独立和相互依存的自我和环境文化模型来拓展、重新想象和重视主流人工智能愿景的研究的新概念框架。两项调研支持了这一框架，并初步证明人们在想象他们理想的人工智能时会应用他们的文化模型。与欧裔美国受访者相比，中国受访者认为控制人工智能不太重要，与人工智能建立联系更为重要，并更倾向于喜欢具有影响力的人工智能。从非裔美国受访者的发现反映了欧裔美国和中国受访者的文化模型。我们讨论了研究的局限性和未来方向，并强调了开发文化响应性和相关性人工智能以服务更广泛人群的需要的重要性。

    arXiv:2403.05104v1 Announce Type: cross  Abstract: There is an urgent need to incorporate the perspectives of culturally diverse groups into AI developments. We present a novel conceptual framework for research that aims to expand, reimagine, and reground mainstream visions of AI using independent and interdependent cultural models of the self and the environment. Two survey studies support this framework and provide preliminary evidence that people apply their cultural models when imagining their ideal AI. Compared with European American respondents, Chinese respondents viewed it as less important to control AI and more important to connect with AI, and were more likely to prefer AI with capacities to influence. Reflecting both cultural models, findings from African American respondents resembled both European American and Chinese respondents. We discuss study limitations and future directions and highlight the need to develop culturally responsive and relevant AI to serve a broader s
    
[^48]: 基于规则的新闻标题生成

    Rule-driven News Captioning

    [https://arxiv.org/abs/2403.05101](https://arxiv.org/abs/2403.05101)

    本文提出了一种基于规则的新闻标题生成方法，通过新闻感知的语义规则，可以生成遵循新闻报道基本规则的图像描述。

    

    News captioning任务旨在通过描述图片及其新闻文章中的命名实体或具体事件来生成句子。现有方法通过依赖大规模预训练模型已取得显著成果，这些模型主要专注于输入新闻内容与输出预测之间的相关性。然而，新闻标题生成需要遵循新闻报道的一些基本规则，如准确描述与事件相关的个体和动作。在本文中，我们提出了基于规则的新闻标题生成方法，可以根据指定的规则信号生成图像描述。具体而言，我们首先为描述设计了新闻感知的语义规则。这一规则包括图片中描绘的主要动作（例如，“执行”）以及参与动作的命名实体扮演的角色（例如，“代理人”和“地点”）。其次，我们将这个语义规则注入到文本生成模型中。

    arXiv:2403.05101v1 Announce Type: cross  Abstract: News captioning task aims to generate sentences by describing named entities or concrete events for an image with its news article. Existing methods have achieved remarkable results by relying on the large-scale pre-trained models, which primarily focus on the correlations between the input news content and the output predictions. However, the news captioning requires adhering to some fundamental rules of news reporting, such as accurately describing the individuals and actions associated with the event. In this paper, we propose the rule-driven news captioning method, which can generate image descriptions following designated rule signal. Specifically, we first design the news-aware semantic rule for the descriptions. This rule incorporates the primary action depicted in the image (e.g., "performing") and the roles played by named entities involved in the action (e.g., "Agent" and "Place"). Second, we inject this semantic rule into th
    
[^49]: 探索对抗界限：通过对抗超体积量化鲁棒性

    Exploring the Adversarial Frontier: Quantifying Robustness via Adversarial Hypervolume

    [https://arxiv.org/abs/2403.05100](https://arxiv.org/abs/2403.05100)

    提出新指标对抗超体积来全面评估深度学习模型在多种扰动强度下的鲁棒性，并采用新型训练算法来提高对抗鲁棒性。

    

    在深度学习模型面临日益严重的对抗攻击威胁，特别是在安全关键领域，强调了对鲁棒深度学习系统的需求。传统的鲁棒性评估依赖于对抗准确性，该指标衡量模型在特定扰动强度下的性能。然而，这一单一指标并不能完全概括模型对不同程度扰动的整体韧性。为了填补这一空白，我们提出了一种新的指标，称为对抗超体积，从多目标优化的角度综合评估了深度学习模型在一系列扰动强度下的鲁棒性。该指标允许深入比较防御机制，并承认了较弱的防御策略所带来的鲁棒性改进。此外，我们采用了一种提高对抗鲁棒性均匀性的新型训练算法。

    arXiv:2403.05100v1 Announce Type: cross  Abstract: The escalating threat of adversarial attacks on deep learning models, particularly in security-critical fields, has underscored the need for robust deep learning systems. Conventional robustness evaluations have relied on adversarial accuracy, which measures a model's performance under a specific perturbation intensity. However, this singular metric does not fully encapsulate the overall resilience of a model against varying degrees of perturbation. To address this gap, we propose a new metric termed adversarial hypervolume, assessing the robustness of deep learning models comprehensively over a range of perturbation intensities from a multi-objective optimization standpoint. This metric allows for an in-depth comparison of defense mechanisms and recognizes the trivial improvements in robustness afforded by less potent defensive strategies. Additionally, we adopt a novel training algorithm that enhances adversarial robustness uniformly
    
[^50]: 复位和提炼：克服持续强化学习中负迁移的有效方法

    Reset & Distill: A Recipe for Overcoming Negative Transfer in Continual Reinforcement Learning

    [https://arxiv.org/abs/2403.05066](https://arxiv.org/abs/2403.05066)

    开发了Reset & Distill（R&D）方法，通过重置代理的网络和提炼知识，有效克服了持续强化学习中负迁移问题。

    

    我们认为发展有效的持续强化学习（CRL）算法的主要障碍之一是当需要学习新任务时会发生负迁移问题。通过全面的实验证实，我们证明这种问题在CRL中经常存在，并且无法通过最近一些旨在减轻RL代理的可塑性损失的工作来有效解决。为此，我们开发了Reset & Distill（R&D），这是一种简单但高效的方法，用于克服CRL中负迁移问题。R&D结合了一种策略，即重置代理的在线演员和评论网络以学习新任务，以及离线学习步骤，用于提炼在线演员和以前专家动作概率的知识。我们在Meta-World任务的长序列上进行了大量实验，并展示了我们的方法始终优于最近的基线，取得了显着更高的成功率。

    arXiv:2403.05066v1 Announce Type: cross  Abstract: We argue that one of the main obstacles for developing effective Continual Reinforcement Learning (CRL) algorithms is the negative transfer issue occurring when the new task to learn arrives. Through comprehensive experimental validation, we demonstrate that such issue frequently exists in CRL and cannot be effectively addressed by several recent work on mitigating plasticity loss of RL agents. To that end, we develop Reset & Distill (R&D), a simple yet highly effective method, to overcome the negative transfer problem in CRL. R&D combines a strategy of resetting the agent's online actor and critic networks to learn a new task and an offline learning step for distilling the knowledge from the online actor and previous expert's action probabilities. We carried out extensive experiments on long sequence of Meta-World tasks and show that our method consistently outperforms recent baselines, achieving significantly higher success rates acr
    
[^51]: 无监督图神经架构搜索与解耦自监督

    Unsupervised Graph Neural Architecture Search with Disentangled Self-supervision

    [https://arxiv.org/abs/2403.05064](https://arxiv.org/abs/2403.05064)

    提出了一种新颖的解耦自监督图神经架构搜索（DSGAS）模型，能够发现捕获各种潜在图因素的最佳架构

    

    现有的图神经架构搜索方法在搜索过程中严重依赖监督标签，无法处理监督不可用的普遍情况。本文研究了无监督图神经架构搜索问题，在文献中尚未探索。关键问题是发现驱动图数据形成以及潜在关系的潜在图因素与最优神经架构之间的关系。由于图的性质和神经架构搜索过程的复杂性，这一问题很具挑战性。为了解决这一挑战，我们提出了一种新颖的解耦自监督图神经架构搜索（DSGAS）模型，能够发现捕获各种潜在图因素的最佳架构

    arXiv:2403.05064v1 Announce Type: cross  Abstract: The existing graph neural architecture search (GNAS) methods heavily rely on supervised labels during the search process, failing to handle ubiquitous scenarios where supervisions are not available. In this paper, we study the problem of unsupervised graph neural architecture search, which remains unexplored in the literature. The key problem is to discover the latent graph factors that drive the formation of graph data as well as the underlying relations between the factors and the optimal neural architectures. Handling this problem is challenging given that the latent graph factors together with architectures are highly entangled due to the nature of the graph and the complexity of the neural architecture search process. To address the challenge, we propose a novel Disentangled Self-supervised Graph Neural Architecture Search (DSGAS) model, which is able to discover the optimal architectures capturing various latent graph factors in 
    
[^52]: 调整大型语言模型以实现可控的推荐

    Aligning Large Language Models for Controllable Recommendations

    [https://arxiv.org/abs/2403.05063](https://arxiv.org/abs/2403.05063)

    通过引入监督学习任务和强化学习对齐程序，研究人员提出了一种方法来改善大型语言模型适应推荐指令和减少格式错误的能力。

    

    受到大型语言模型（LLMs）异常的智能启发，研究人员已开始探索将它们应用于开创下一代推荐系统 - 这些系统具有对话、可解释和可控的特性。然而，现有文献主要集中在将领域特定知识整合到LLMs中以提高准确性，通常忽略了遵循指令的能力。为填补这一空白，我们首先引入一组监督学习任务，标记来源于传统推荐模型的标签，旨在明确改善LLMs遵循特定推荐指令的熟练程度。随后，我们开发了一种基于强化学习的对齐程序，进一步加强了LLMs在响应用户意图和减少格式错误方面的能力。通过在两个真实世界数据集上进行广泛实验，我们的方法标记着

    arXiv:2403.05063v1 Announce Type: cross  Abstract: Inspired by the exceptional general intelligence of Large Language Models (LLMs), researchers have begun to explore their application in pioneering the next generation of recommender systems - systems that are conversational, explainable, and controllable. However, existing literature primarily concentrates on integrating domain-specific knowledge into LLMs to enhance accuracy, often neglecting the ability to follow instructions. To address this gap, we initially introduce a collection of supervised learning tasks, augmented with labels derived from a conventional recommender model, aimed at explicitly improving LLMs' proficiency in adhering to recommendation-specific instructions. Subsequently, we develop a reinforcement learning-based alignment procedure to further strengthen LLMs' aptitude in responding to users' intentions and mitigating formatting errors. Through extensive experiments on two real-world datasets, our method markedl
    
[^53]: PrimeComposer：用于图像合成的快速逐步组合扩散方法和带有注意力引导的技术

    PrimeComposer: Faster Progressively Combined Diffusion for Image Composition with Attention Steering

    [https://arxiv.org/abs/2403.05053](https://arxiv.org/abs/2403.05053)

    本文提出了PrimeComposer，一种更快的逐步组合扩散方式，用于图像合成，主要专注于前景生成，从而解决了合成中的凝聚混乱和外观信息丢失问题，并避免了不必要的背景生成导致的前景生成质量下降。

    

    图像合成涉及将给定对象无缝地整合到特定的视觉环境中。目前无需训练的方法依赖于从几个采样器中组合注意力权重来引导生成器。然而，由于这些权重来自不同的上下文，它们的组合导致在合成中凝聚混乱和外观信息的丢失。在该任务中，它们过多关注背景生成，即使在这项任务中是不必要的，这些问题恶化。这不仅减慢了推理速度，还损害了前景生成质量。此外，这些方法还在过渡区域引入了不需要的伪影。在本文中，我们将图像合成形式化为一项基于主题的局部编辑任务，仅专注于前景生成。在每一步中，编辑后的前景与噪声背景相结合，以保持场景一致性。为了解决剩下的问题，我们提出了PrimeComposer，一种更快的tr

    arXiv:2403.05053v1 Announce Type: cross  Abstract: Image composition involves seamlessly integrating given objects into a specific visual context. The current training-free methods rely on composing attention weights from several samplers to guide the generator. However, since these weights are derived from disparate contexts, their combination leads to coherence confusion in synthesis and loss of appearance information. These issues worsen with their excessive focus on background generation, even when unnecessary in this task. This not only slows down inference but also compromises foreground generation quality. Moreover, these methods introduce unwanted artifacts in the transition area. In this paper, we formulate image composition as a subject-based local editing task, solely focusing on foreground generation. At each step, the edited foreground is combined with the noisy background to maintain scene consistency. To address the remaining issues, we propose PrimeComposer, a faster tr
    
[^54]: DyRoNet：一种低秩适配器增强的动态路由网络，用于流媒体感知

    DyRoNet: A Low-Rank Adapter Enhanced Dynamic Routing Network for Streaming Perception

    [https://arxiv.org/abs/2403.05050](https://arxiv.org/abs/2403.05050)

    DyRoNet采用低秩动态路由并结合分支网络优化流媒体感知性能，为多种分支选择策略设定了新的性能标杆

    

    自主驾驶系统需要实时、准确的感知来应对复杂环境。为解决这一问题，我们引入了动态路由网络（DyRoNet），这是一个创新性的框架，采用低秩动态路由以增强流媒体感知。通过集成专门预训练的分支网络，针对各种环境条件进行微调，DyRoNet在延迟和精度之间取得了平衡。其核心特征是速度路由模块，智能地将输入数据引导到最适合的分支网络，优化性能。广泛的评估结果显示，DyRoNet有效地适应多种分支选择策略，为各种场景性能设定了新的标杆。DyRoNet不仅为流媒体感知建立了新的标杆，还为未来的工作提供了宝贵的工程洞见。有关更多项目信息，请访问 https://tastevision.github.io/DyRoNet/

    arXiv:2403.05050v1 Announce Type: cross  Abstract: Autonomous driving systems demand real-time, accurate perception to navigate complex environments. Addressing this, we introduce the Dynamic Router Network (DyRoNet), a framework that innovates with low-rank dynamic routing for enhanced streaming perception. By integrating specialized pre-trained branch networks, fine-tuned for various environmental conditions, DyRoNet achieves a balance between latency and precision. Its core feature, the speed router module, intelligently directs input data to the best-suited branch network, optimizing performance. The extensive evaluations reveal that DyRoNet adapts effectively to multiple branch selection strategies, setting a new benchmark in performance across a range of scenarios. DyRoNet not only establishes a new benchmark for streaming perception but also provides valuable engineering insights for future work. More project information is available at https://tastevision.github.io/DyRoNet/
    
[^55]: 人类对话是否特殊？一个大型语言模型的视角

    Are Human Conversations Special? A Large Language Model Perspective

    [https://arxiv.org/abs/2403.05045](https://arxiv.org/abs/2403.05045)

    本研究分析了大型语言模型在理解人类对话时的注意机制变化，发现尽管语言模型在特定领域表现出不同的注意行为，但在专门处理人类对话方面存在明显差距，需要通过多样化的高质量对话数据训练模型来增强理解和生成

    

    本研究分析了大型语言模型（LLMs）在理解人类之间的自然对话（人-人）时注意机制的变化。我们分析了LLMs的三种用例：与网络内容、代码和数学文本的互动。通过分析跨这些领域的注意距离、分散性和相互依赖性，我们强调了对话数据所提出的独特挑战。值得注意的是，对话需要细致处理长期上下文关系，并通过它们的注意模式展示出更高的复杂性。我们的研究结果表明，虽然语言模型表现出特定于领域的注意行为，但它们在专门化人类对话方面存在显著差距。通过详细的注意熵分析和t-SNE可视化，我们展示了需要通过训练模型使用多样化的高质量对话数据来增强理解和生成。

    arXiv:2403.05045v1 Announce Type: cross  Abstract: This study analyzes changes in the attention mechanisms of large language models (LLMs) when used to understand natural conversations between humans (human-human). We analyze three use cases of LLMs: interactions over web content, code, and mathematical texts. By analyzing attention distance, dispersion, and interdependency across these domains, we highlight the unique challenges posed by conversational data. Notably, conversations require nuanced handling of long-term contextual relationships and exhibit higher complexity through their attention patterns. Our findings reveal that while language models exhibit domain-specific attention behaviors, there is a significant gap in their ability to specialize in human conversations. Through detailed attention entropy analysis and t-SNE visualizations, we demonstrate the need for models trained with a diverse array of high-quality conversational data to enhance understanding and generation of
    
[^56]: 量化流形:生成对抗网络学习的流形是否收敛于真实数据流形

    Quantifying Manifolds: Do the manifolds learned by Generative Adversarial Networks converge to the real data manifold

    [https://arxiv.org/abs/2403.05033](https://arxiv.org/abs/2403.05033)

    通过研究ML模型学习到的流形的内在维度和拓扑特征，本文探讨了这些度量在训练过程中是否收敛到真实数据流形的度量。

    

    本文介绍了我们的实验，用于量化由ML模型（在我们的实验中，我们使用了一个GAN模型）学习的流形随着训练而变化。我们比较了每个时期学习到的流形与代表真实数据的真实流形。为了量化一个流形，我们研究了ML模型学习到的流形的内在维度和拓扑特征，这些度量随着我们继续训练模型而如何变化，以及这些度量是否在训练过程中收敛到真实数据流形的度量。

    arXiv:2403.05033v1 Announce Type: cross  Abstract: This paper presents our experiments to quantify the manifolds learned by ML models (in our experiment, we use a GAN model) as they train. We compare the manifolds learned at each epoch to the real manifolds representing the real data. To quantify a manifold, we study the intrinsic dimensions and topological features of the manifold learned by the ML model, how these metrics change as we continue to train the model, and whether these metrics convergence over the course of training to the metrics of the real data manifold.
    
[^57]: 利用潜在对抗训练防御未预见的故障模式

    Defending Against Unforeseen Failure Modes with Latent Adversarial Training

    [https://arxiv.org/abs/2403.05030](https://arxiv.org/abs/2403.05030)

    本研究利用潜在对抗训练（LAT）来防御AI系统中未预见的故障模式，通过利用网络实际用于预测的压缩、抽象和结构化概念的潜在表示，有效清除了恶意软件和对抗性攻击。

    

    人工智能系统有时在部署后会展示出有害的意外行为。尽管开发人员进行了大量诊断和调试，这种情况经常发生。由于攻击面非常广泛，从模型中减少风险具有挑战性。耗尽地搜索可能导致模型失败的输入是不可行的。红队和对抗训练（AT）通常用于使人工智能系统更加健壮。然而，它们并不足以避免许多与对抗训练不同的真实世界故障模式。在这项工作中，我们利用潜在对抗训练（LAT）来防御漏洞，而无需生成引发这些漏洞的输入。LAT利用网络实际用于预测的压缩、抽象和结构化概念的潜在表示。我们使用LAT来清除恶意软件并防御针对保留类别的对抗性攻击。我们展示在图像分类、文本分类

    arXiv:2403.05030v1 Announce Type: cross  Abstract: AI systems sometimes exhibit harmful unintended behaviors post-deployment. This is often despite extensive diagnostics and debugging by developers. Minimizing risks from models is challenging because the attack surface is so large. It is not tractable to exhaustively search for inputs that may cause a model to fail. Red-teaming and adversarial training (AT) are commonly used to make AI systems more robust. However, they have not been sufficient to avoid many real-world failure modes that differ from the ones adversarially trained on. In this work, we utilize latent adversarial training (LAT) to defend against vulnerabilities without generating inputs that elicit them. LAT leverages the compressed, abstract, and structured latent representations of concepts that the network actually uses for prediction. We use LAT to remove trojans and defend against held-out classes of adversarial attacks. We show in image classification, text classifi
    
[^58]: BjTT: 一个用于交通预测的大规模多模态数据集

    BjTT: A Large-scale Multimodal Dataset for Traffic Prediction

    [https://arxiv.org/abs/2403.05029](https://arxiv.org/abs/2403.05029)

    本文提出了第一个用于文本-交通生成的扩散模型ChatTraffic，通过将生成模型与交通系统描述文本相结合，解决了交通预测中关联文本和空间结构的挑战。

    

    arXiv:2403.05029v1 公告类型: 新摘要: 交通预测是智能交通系统中最重要的基础之一。传统的交通预测方法仅依赖历史交通数据来预测交通趋势，并面临两个主要挑战。1）对异常事件不敏感。2）在长期预测中性能有限。在这项工作中，我们探讨了将生成模型与描述交通系统的文本相结合应用于交通生成的方法，并命名该任务为文本-交通生成（TTG）。TTG 任务的关键挑战是如何将文本与道路网络的空间结构和交通数据相关联，以生成交通情况。为此，我们提出了ChatTraffic，第一个用于文本-交通生成的扩散模型。为了保证合成数据与真实数据的一致性，我们将扩散模型与图卷积网络（GCN）结合起来，以提取交通数据的空间相关性。

    arXiv:2403.05029v1 Announce Type: new  Abstract: Traffic prediction is one of the most significant foundations in Intelligent Transportation Systems (ITS). Traditional traffic prediction methods rely only on historical traffic data to predict traffic trends and face two main challenges. 1) insensitivity to unusual events. 2) limited performance in long-term prediction. In this work, we explore how generative models combined with text describing the traffic system can be applied for traffic generation, and name the task Text-to-Traffic Generation (TTG). The key challenge of the TTG task is how to associate text with the spatial structure of the road network and traffic data for generating traffic situations. To this end, we propose ChatTraffic, the first diffusion model for text-to-traffic generation. To guarantee the consistency between synthetic and real data, we augment a diffusion model with the Graph Convolutional Network (GCN) to extract spatial correlations of traffic data. In ad
    
[^59]: 分布漂移下动态图的谱不变学习

    Spectral Invariant Learning for Dynamic Graphs under Distribution Shifts

    [https://arxiv.org/abs/2403.05026](https://arxiv.org/abs/2403.05026)

    该论文首次提出在动态图的谱域内研究分布漂移，并提出了谱不变学习方法来应对谱域中的分布漂移挑战。

    

    动态图神经网络（DyGNNs）目前在处理动态图固有的分布漂移时存在困难。现有针对DyGNNs在分布漂移设置中的工作仅关注时间域，未能处理涉及谱域中分布漂移的情况。本文发现存在一些情况，时间域中观察不到的分布漂移却在谱域中可以观察到，并首次提出研究动态图谱域内的分布漂移。然而，这项研究提出了两个关键挑战：i）捕捉谱域中纠缠在一起的不同频率分量驱动的不同图模式并非易事；ii）如何处理与发现的谱模式相关的分布漂移仍不清楚。为解决这些挑战，我们提出了用于处理分布漂移下动态图的谱不变学习方法。

    arXiv:2403.05026v1 Announce Type: cross  Abstract: Dynamic graph neural networks (DyGNNs) currently struggle with handling distribution shifts that are inherent in dynamic graphs. Existing work on DyGNNs with out-of-distribution settings only focuses on the time domain, failing to handle cases involving distribution shifts in the spectral domain. In this paper, we discover that there exist cases with distribution shifts unobservable in the time domain while observable in the spectral domain, and propose to study distribution shifts on dynamic graphs in the spectral domain for the first time. However, this investigation poses two key challenges: i) it is non-trivial to capture different graph patterns that are driven by various frequency components entangled in the spectral domain; and ii) it remains unclear how to handle distribution shifts with the discovered spectral patterns. To address these challenges, we propose Spectral Invariant Learning for Dynamic Graphs under Distribution Sh
    
[^60]: 通过主题去相关实现多模态人类意图理解去偏见

    Towards Multimodal Human Intention Understanding Debiasing via Subject-Deconfounding

    [https://arxiv.org/abs/2403.05025](https://arxiv.org/abs/2403.05025)

    通过引入概括性因果图和分析主题混淆效应，本文提出了SuCI，实现了多模态人类意图理解的去偏见，解决了MIU模型受主体变异问题困扰的挑战。

    

    arXiv:2403.05025v1 公告类型: 新摘要: 多模态意图理解(MIU)是人类表达分析(例如情感或幽默)不可或缺的组成部分，涉及视觉姿势、语言内容和声学行为等异构模态。现有工作始终专注于设计复杂的结构或融合策略，取得显著进展。然而，它们都受到主题变异问题的困扰，因为不同主题之间的数据分布差异导致。具体而言，由于训练数据中具有不同表达习惯和特征的不同主题，MIU模型很容易被误导，以学习特定于主题的伪相关性，从而显着限制了跨未接触主题的性能和泛化能力。受这一观察启发，我们引入了一个概括性因果图来制定MIU过程，并分析主题的混淆效应。然后，我们提出了SuCI，一个简单而有效的因果

    arXiv:2403.05025v1 Announce Type: new  Abstract: Multimodal intention understanding (MIU) is an indispensable component of human expression analysis (e.g., sentiment or humor) from heterogeneous modalities, including visual postures, linguistic contents, and acoustic behaviors. Existing works invariably focus on designing sophisticated structures or fusion strategies to achieve impressive improvements. Unfortunately, they all suffer from the subject variation problem due to data distribution discrepancies among subjects. Concretely, MIU models are easily misled by distinct subjects with different expression customs and characteristics in the training data to learn subject-specific spurious correlations, significantly limiting performance and generalizability across uninitiated subjects.Motivated by this observation, we introduce a recapitulative causal graph to formulate the MIU procedure and analyze the confounding effect of subjects. Then, we propose SuCI, a simple yet effective caus
    
[^61]: 模拟社交互动成功性的误导性：以LLMs为例

    Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs

    [https://arxiv.org/abs/2403.05020](https://arxiv.org/abs/2403.05020)

    研究发现，使用LLMs进行社交互动的全知模拟比非全知模拟更容易实现社交目标，尽管非全知模拟更接近实际情况。

    

    最近大型语言模型（LLM）的进展使得社交模拟更加丰富，能够使用基于LLM的代理人研究各种社交现象。然而，大多数工作在这些模拟中采用了一种全知的透视（例如，单个LLM生成所有交谈者），这与人类具有的非全知、信息不对称的互动根本不符。为了研究这些差异，我们开发了一个评估框架，在各种设定（全知、非全知）中使用LLMs模拟社交互动。我们的实验表明，通过全知方式模拟的交谈者在实现社交目标方面比非全知代理人更成功，尽管后者更符合现实设置。此外，我们表明从全知模拟中学习可以改善交互的自然性，但在合作场景中几乎不能增强目标实现。

    arXiv:2403.05020v1 Announce Type: cross  Abstract: Recent advances in large language models (LLM) have enabled richer social simulations, allowing for the study of various social phenomena with LLM-based agents. However, most work has used an omniscient perspective on these simulations (e.g., single LLM to generate all interlocutors), which is fundamentally at odds with the non-omniscient, information asymmetric interactions that humans have. To examine these differences, we develop an evaluation framework to simulate social interactions with LLMs in various settings (omniscient, non-omniscient). Our experiments show that interlocutors simulated omnisciently are much more successful at accomplishing social goals compared to non-omniscient agents, despite the latter being the more realistic setting. Furthermore, we demonstrate that learning from omniscient simulations improves the apparent naturalness of interactions but scarcely enhances goal achievement in cooperative scenarios. Our f
    
[^62]: 简单多图卷积网络

    Simple Multigraph Convolution Networks

    [https://arxiv.org/abs/2403.05014](https://arxiv.org/abs/2403.05014)

    本文提出了一种简单的多图卷积网络（SMGCN），通过提取一致的交叉视图拓扑和执行多项式展开，有效降低了多图卷积的复杂度，实现了可信的交叉视图空间消息传递。

    

    现有的多图卷积方法要么忽视多个图之间的交叉视图交互，要么由于标准的交叉视图多项式运算符而导致计算成本极高。为了缓解这个问题，本文提出了一种简单的多图卷积网络（SMGCN），它首先从多图中提取一致的交叉视图拓扑，包括边级和子图级拓扑，然后基于原始多图和一致的拓扑执行多项式展开。在理论上，SMGCN利用一致的拓扑进行多项式展开，而不是标准的交叉视图多项式展开，从而执行可信的交叉视图空间消息传递，遵循谱卷积范式，并有效降低标准多项式展开的复杂度。在模拟实验中，实验结果表明SMGCN在ACM和DBLP多图基准数据上实现了最先进的性能。

    arXiv:2403.05014v1 Announce Type: cross  Abstract: Existing multigraph convolution methods either ignore the cross-view interaction among multiple graphs, or induce extremely high computational cost due to standard cross-view polynomial operators. To alleviate this problem, this paper proposes a Simple MultiGraph Convolution Networks (SMGCN) which first extracts consistent cross-view topology from multigraphs including edge-level and subgraph-level topology, then performs polynomial expansion based on raw multigraphs and consistent topologies. In theory, SMGCN utilizes the consistent topologies in polynomial expansion rather than standard cross-view polynomial expansion, which performs credible cross-view spatial message-passing, follows the spectral convolution paradigm, and effectively reduces the complexity of standard polynomial expansion. In the simulations, experimental results demonstrate that SMGCN achieves state-of-the-art performance on ACM and DBLP multigraph benchmark datas
    
[^63]: RFWave：用于音频波形重建的多频带整流流动

    RFWave: Multi-band Rectified Flow for Audio Waveform Reconstruction

    [https://arxiv.org/abs/2403.05010](https://arxiv.org/abs/2403.05010)

    RFWave是一种新颖的多频带整流流动方法，可以从Mel频谱图中重建高保真度音频波形，仅需10个采样步骤即可实现出色的重建质量和优越的计算效率。

    

    最近生成建模的进展在从不同表示中重建音频波形方面取得了显著进展。虽然扩散模型已被用于重建音频波形，但由于它们在个别样本点级别进行操作并且需要相对较大数量的采样步骤，因此它们往往会出现延迟问题。在本研究中，我们介绍了RFWave，一种新颖的多频带整流流动方法，它从Mel频谱图中重建高保真度音频波形。RFWave在生成复杂频谱图并在帧级别运行方面具有独特性，同时处理所有子带以增强效率。由于希望获得平缓传输轨迹的整流流动，RFWave仅需10个采样步骤。实证评估表明，RFWave实现了卓越的重建质量和优越的计算效率，能够以更快的速度生成音频。

    arXiv:2403.05010v1 Announce Type: cross  Abstract: Recent advancements in generative modeling have led to significant progress in audio waveform reconstruction from diverse representations. Although diffusion models have been used for reconstructing audio waveforms, they tend to exhibit latency issues because they operate at the level of individual sample points and require a relatively large number of sampling steps. In this study, we introduce RFWave, a novel multi-band Rectified Flow approach that reconstructs high-fidelity audio waveforms from Mel-spectrograms. RFWave is distinctive for generating complex spectrograms and operating at the frame level, processing all subbands concurrently to enhance efficiency. Thanks to Rectified Flow, which aims for a flat transport trajectory, RFWave requires only 10 sampling steps. Empirical evaluations demonstrate that RFWave achieves exceptional reconstruction quality and superior computational efficiency, capable of generating audio at a spee
    
[^64]: 具有多元人类反馈的可证明多方协作强化学习

    Provable Multi-Party Reinforcement Learning with Diverse Human Feedback

    [https://arxiv.org/abs/2403.05006](https://arxiv.org/abs/2403.05006)

    该研究首次提出了多方协作强化学习的理论研究，通过整合多个个体不同偏好的元学习与不同社会福利函数的采用，克服了传统RLHF方法无法捕捉并平衡多个个体偏好的局限性。

    

    用人类反馈进行强化学习（RLHF）是一种新兴范式，旨在将模型与人类偏好进行匹配。我们的工作探索了明确建模多个个体不同偏好的多方RLHF的理论研究。我们展示了传统RLHF方法如何失败，因为学习单一奖励函数无法捕捉和平衡多个个体的偏好。为了克服这些局限性，我们结合元学习来学习多个偏好，并采用不同的社会福利函数来整合多方的偏好。我们关注离线学习设置，并为优化不同社会福利函数（如Nash、Utilitarian和Leximin福利）建立样本复杂度界限，同时提供效率和公平性保证。

    arXiv:2403.05006v1 Announce Type: cross  Abstract: Reinforcement learning with human feedback (RLHF) is an emerging paradigm to align models with human preferences. Typically, RLHF aggregates preferences from multiple individuals who have diverse viewpoints that may conflict with each other. Our work \textit{initiates} the theoretical study of multi-party RLHF that explicitly models the diverse preferences of multiple individuals. We show how traditional RLHF approaches can fail since learning a single reward function cannot capture and balance the preferences of multiple individuals. To overcome such limitations, we incorporate meta-learning to learn multiple preferences and adopt different social welfare functions to aggregate the preferences across multiple parties. We focus on the offline learning setting and establish sample complexity bounds, along with efficiency and fairness guarantees, for optimizing diverse social welfare functions such as Nash, Utilitarian, and Leximin welfa
    
[^65]: 无法记住长文档中的细节？您需要一些R&R

    Can't Remember Details in Long Documents? You Need Some R&R

    [https://arxiv.org/abs/2403.05004](https://arxiv.org/abs/2403.05004)

    引入R&R方法，结合reprompting和in-context retrieval两种新型提示方式，提高了在长文档上的问答任务的准确性。

    

    长上下文大型语言模型（LLMs）在诸如长篇文档上的问答（QA）等任务中表现出潜力，但它们往往会错过上下文文档中间的重要信息。在这里，我们介绍了一个名为$\textit{R&R}$的方法，它结合了两种新型基于提示的方法，称为$\textit{reprompting}$和$\textit{in-context retrieval}$（ICR），以减轻文档型QA中的这种影响。在$\textit{reprompting}$中，我们周期性地在整个上下文文档中重复提示说明，以提醒LLM其原始任务。在ICR中，我们并不指示LLM直接回答问题，而是指示它检索与给定问题最相关的前$k$个段落编号，然后将其用作第二个QA提示中的缩略上下文。我们使用GPT-4 Turbo和Claude-2.1在长度达到80k标记的文档上测试了R&R，并平均观察到QA准确率提升了16个百分点。

    arXiv:2403.05004v1 Announce Type: cross  Abstract: Long-context large language models (LLMs) hold promise for tasks such as question-answering (QA) over long documents, but they tend to miss important information in the middle of context documents (arXiv:2307.03172v3). Here, we introduce $\textit{R&R}$ -- a combination of two novel prompt-based methods called $\textit{reprompting}$ and $\textit{in-context retrieval}$ (ICR) -- to alleviate this effect in document-based QA. In reprompting, we repeat the prompt instructions periodically throughout the context document to remind the LLM of its original task. In ICR, rather than instructing the LLM to answer the question directly, we instruct it to retrieve the top $k$ passage numbers most relevant to the given question, which are then used as an abbreviated context in a second QA prompt. We test R&R with GPT-4 Turbo and Claude-2.1 on documents up to 80k tokens in length and observe a 16-point boost in QA accuracy on average. Our further an
    
[^66]: 通过分解表示进行医学言语症状分类

    Medical Speech Symptoms Classification via Disentangled Representation

    [https://arxiv.org/abs/2403.05000](https://arxiv.org/abs/2403.05000)

    该论文提出了一种名为DRSC的医学言语分类模型，实现了自动学习从文本-声学数据中分离意图和内容表示以进行分类，并在检测25种不同医学症状时取得了95%的平均准确率。

    

    arXiv:2403.05000v1 公告类型:new 摘要: 在现有工作中，意图被定义用于理解口头语言。医学言语中涉及的文本特征和声学特征均包含意图，这对于症状诊断非常重要。本文提出了一种名为DRSC的医学言语分类模型，该模型自动学习从文本-声学数据中分离意图和内容表示以进行分类。 通过意图编码器提取文本域和Mel-频谱图域的意图表示，然后通过两个交换获取重构的文本特征和Mel-频谱图特征。在将两个域的意图结合成一个联合表示后，综合意图表示被输入决策层进行分类。实验结果显示，我们的模型在检测25种不同医学症状时获得了平均准确率达到95%。

    arXiv:2403.05000v1 Announce Type: new  Abstract: Intent is defined for understanding spoken language in existing works. Both textual features and acoustic features involved in medical speech contain intent, which is important for symptomatic diagnosis. In this paper, we propose a medical speech classification model named DRSC that automatically learns to disentangle intent and content representations from textual-acoustic data for classification. The intent representations of the text domain and the Mel-spectrogram domain are extracted via intent encoders, and then the reconstructed text feature and the Mel-spectrogram feature are obtained through two exchanges. After combining the intent from two domains into a joint representation, the integrated intent representation is fed into a decision layer for classification. Experimental results show that our model obtains an average accuracy rate of 95% in detecting 25 different medical symptoms.
    
[^67]: 基于归纳图神经网络的大网络节点中心性近似

    Node Centrality Approximation For Large Networks Based On Inductive Graph Neural Networks

    [https://arxiv.org/abs/2403.04977](https://arxiv.org/abs/2403.04977)

    重新定义了节点排序问题作为一个机器学习问题，并提出了CNCA-IGE模型，该模型是一个编码器-解码器模型，用于基于归纳图神经网络的大网络节点中心性近似。

    

    靠近中心性（CC）和介数中心性（BC）是网络分析中至关重要的指标，在复杂网络中提供了节点重要性的基本参考。这些度量在关键任务中具有广泛的应用，如社区检测和网络解体。然而，由于其高时间复杂度，它们在大型网络上的实际实现仍然具有极高的计算需求。为了缓解这些计算挑战，已经开发了许多近似算法来加速CC和BC的计算。然而，即使这些近似算法在大规模网络上应用时仍需要大量的处理时间。此外，它们的输出对网络结构中甚至细微的扰动也十分敏感。

    arXiv:2403.04977v1 Announce Type: cross  Abstract: Closeness Centrality (CC) and Betweenness Centrality (BC) are crucial metrics in network analysis, providing essential reference for discerning the significance of nodes within complex networks. These measures find wide applications in critical tasks, such as community detection and network dismantling. However, their practical implementation on extensive networks remains computationally demanding due to their high time complexity. To mitigate these computational challenges, numerous approximation algorithms have been developed to expedite the computation of CC and BC. Nevertheless, even these approximations still necessitate substantial processing time when applied to large-scale networks. Furthermore, their output proves sensitive to even minor perturbations within the network structure.   In this work, We redefine the CC and BC node ranking problem as a machine learning problem and propose the CNCA-IGE model, which is an encoder-dec
    
[^68]: StereoDiffusion：使用潜在扩散模型进行无训练的立体图像生成

    StereoDiffusion: Training-Free Stereo Image Generation Using Latent Diffusion Models

    [https://arxiv.org/abs/2403.04965](https://arxiv.org/abs/2403.04965)

    StereoDiffusion是一种无需训练的立体图像生成方法，通过修改潜在变量实现快速生成立体图像对，无需微调模型权重或图像后处理。

    

    随着制造商推出更多XR设备，对立体图像的需求不断增加。为满足这一需求，我们引入了StereoDiffusion，这种方法与传统的修补管道不同，无需训练，使用起来非常简单，并且可以无缝集成到原始的Stable Diffusion模型中。我们的方法修改了潜在变量，提供了一种端到端、轻量级的能力，快速生成立体图像对，无需微调模型权重或任何图像后处理。通过使用原始输入生成左图像并为其估计视差图，我们通过Stereo Pixel Shift操作生成右图像的潜在向量，辅以对称像素位移掩蔽去噪和自注意力层修改方法，使右侧图像与左侧图像对齐。此外，我们提出的方法始终保持高水准的图像质量。

    arXiv:2403.04965v1 Announce Type: cross  Abstract: The demand for stereo images increases as manufacturers launch more XR devices. To meet this demand, we introduce StereoDiffusion, a method that, unlike traditional inpainting pipelines, is trainning free, remarkably straightforward to use, and it seamlessly integrates into the original Stable Diffusion model. Our method modifies the latent variable to provide an end-to-end, lightweight capability for fast generation of stereo image pairs, without the need for fine-tuning model weights or any post-processing of images. Using the original input to generate a left image and estimate a disparity map for it, we generate the latent vector for the right image through Stereo Pixel Shift operations, complemented by Symmetric Pixel Shift Masking Denoise and Self-Attention Layers Modification methods to align the right-side image with the left-side image. Moreover, our proposed method maintains a high standard of image quality throughout the ste
    
[^69]: 告诉我实话：一种用于衡量大型语言模型可信度的系统

    Tell me the truth: A system to measure the trustworthiness of Large Language Models

    [https://arxiv.org/abs/2403.04964](https://arxiv.org/abs/2403.04964)

    本文提出了一种基于预定义领域知识图的系统化方法来衡量大型语言模型的可信度。

    

    大型语言模型（LLM）自从2023年11月ChatGPT推出以来，在大多数新闻中占据了重要位置。然而，一年多过去了，公司抵触采用它们的一个主要原因是他们对这些系统的可信度缺乏信心。一项由Baymard（2023）进行的研究发现，ChatGPT-4 在识别网站可用性问题时有80.1%的假阳性错误率。而《JAMA儿科学》杂志（JAMA Pediatrics）于2024年1月的研究发现，ChatGPT 在诊断儿科医疗案例时的准确率为17%（Barile et al., 2024）。那么，何为“信任”？信任是一个相对的、主观的条件，可以根据文化、领域和个体而变化。那么，在给定一个领域的情况下，如何衡量系统的可信度呢？本文提出了一种基于预定义领域知识图表示的系统化方法来衡量可信度。

    arXiv:2403.04964v1 Announce Type: new  Abstract: Large Language Models (LLM) have taken the front seat in most of the news since November 2023, when ChatGPT was introduced. After more than one year, one of the major reasons companies are resistant to adopting them is the limited confidence they have in the trustworthiness of those systems. In a study by (Baymard, 2023), ChatGPT-4 showed an 80.1% false-positive error rate in identifying usability issues on websites. A Jan. '24 study by JAMA Pediatrics found that ChatGPT has an accuracy rate of 17% percent when diagnosing pediatric medical cases (Barile et al., 2024). But then, what is "trust"? Trust is a relative, subject condition that can change based on culture, domain, individuals. And then, given a domain, how can the trustworthiness of a system be measured? In this paper, I present a systematic approach to measure trustworthiness based on a predefined ground truth, represented as a knowledge graph of the domain. The approach is a 
    
[^70]: 在基于错误的人类评估中深入评估GPT-4在句子简化中的表现

    An In-depth Evaluation of GPT-4 in Sentence Simplification with Error-based Human Assessment

    [https://arxiv.org/abs/2403.04963](https://arxiv.org/abs/2403.04963)

    本文深入评估了GPT-4在句子简化中的表现，指出现有自动评估指标和人类评估方法对于大型语言模型的适用性仍有待进一步研究。

    

    句子简化是一种重写句子以便更易阅读和理解的方法，对于帮助有各种阅读难题的人来说是一种有前途的技术。随着先进大型语言模型（LLMs）的兴起，评估它们在句子简化中的表现变得迫在眉睫。最近的研究利用自动评估指标和人类评估来评估LLMs的简化能力。然而，现有评估方法对LLMs在简化评估中的适用性仍然存在疑问。首先，现有自动指标在LLMs的简化评估中的适用性仍不确定。其次，当前在句子简化中的人类评估方法通常陷入两个极端：要么过于肤浅，无法清晰理解模型的表现，要么过于详细，使注释过程复杂且容易出现不一致性，从而影响评估的可靠性。

    arXiv:2403.04963v1 Announce Type: cross  Abstract: Sentence simplification, which rewrites a sentence to be easier to read and understand, is a promising technique to help people with various reading difficulties. With the rise of advanced large language models (LLMs), evaluating their performance in sentence simplification has become imperative. Recent studies have used both automatic metrics and human evaluations to assess the simplification abilities of LLMs. However, the suitability of existing evaluation methodologies for LLMs remains in question. First, the suitability of current automatic metrics on LLMs' simplification evaluation is still uncertain. Second, current human evaluation approaches in sentence simplification often fall into two extremes: they are either too superficial, failing to offer a clear understanding of the models' performance, or overly detailed, making the annotation process complex and prone to inconsistency, which in turn affects the evaluation's reliabil
    
[^71]: SecGPT：一种面向基于LLM系统的执行隔离架构

    SecGPT: An Execution Isolation Architecture for LLM-Based Systems

    [https://arxiv.org/abs/2403.04960](https://arxiv.org/abs/2403.04960)

    提出了一种面向LLM系统的执行隔离架构SecGPT，旨在解决第三方应用程序执行所引发的安全和隐私问题

    

    大型语言模型（LLMs）被扩展为系统，如ChatGPT，已经开始支持第三方应用程序。这些LLM应用程序利用LLMs的事实上基于自然语言的自动执行范式：即，应用程序及其交互是用自然语言定义的，提供对用户数据的访问，并被允许自由地相互交互以及与系统互动。这些LLM应用程序生态系统类似于早期计算平台的设置，在那里应用程序和系统之间缺乏足够的隔离。由于第三方应用程序可能不可信，并且受自然语言界面的不精确性加剧，当前的设计会为用户带来安全和隐私风险。在本文中，我们提出了SecGPT，一种面向LLM系统的架构，旨在缓解由第三方应用程序执行引起的安全性和隐私问题。SecGPT的关键思想是隔离应用程序的执行和更多的预

    arXiv:2403.04960v1 Announce Type: cross  Abstract: Large language models (LLMs) extended as systems, such as ChatGPT, have begun supporting third-party applications. These LLM apps leverage the de facto natural language-based automated execution paradigm of LLMs: that is, apps and their interactions are defined in natural language, provided access to user data, and allowed to freely interact with each other and the system. These LLM app ecosystems resemble the settings of earlier computing platforms, where there was insufficient isolation between apps and the system. Because third-party apps may not be trustworthy, and exacerbated by the imprecision of the natural language interfaces, the current designs pose security and privacy risks for users. In this paper, we propose SecGPT, an architecture for LLM-based systems that aims to mitigate the security and privacy issues that arise with the execution of third-party apps. SecGPT's key idea is to isolate the execution of apps and more pre
    
[^72]: 大型语言模型的自动和通用提示注入攻击

    Automatic and Universal Prompt Injection Attacks against Large Language Models

    [https://arxiv.org/abs/2403.04957](https://arxiv.org/abs/2403.04957)

    引入了一个统一框架，用于理解提示注入攻击的目标，并提出了一种自动梯度方法，用于生成高效和通用的提示注入数据。

    

    大型语言模型（LLM）擅长处理和生成人类语言，其能力源于解释和遵循指令的能力。然而，这些能力可以通过提示注入攻击来利用。这些攻击会操纵LLM集成应用程序以产生与攻击者注入内容一致的响应，偏离用户的实际请求。这些攻击带来的重大风险凸显了对威胁的深入理解的必要性。然而，这一领域的研究面临挑战，因为这些攻击缺乏统一的目标，并且依赖手工制作的提示，使得对提示注入鲁棒性的全面评估变得复杂。我们引入了一个统一框架，以理解提示注入攻击的目标，并提出了一种基于梯度的自动方法，用于生成高效且通用的提示注入数据，即使面对防御措施也能如此。

    arXiv:2403.04957v1 Announce Type: new  Abstract: Large Language Models (LLMs) excel in processing and generating human language, powered by their ability to interpret and follow instructions. However, their capabilities can be exploited through prompt injection attacks. These attacks manipulate LLM-integrated applications into producing responses aligned with the attacker's injected content, deviating from the user's actual requests. The substantial risks posed by these attacks underscore the need for a thorough understanding of the threats. Yet, research in this area faces challenges due to the lack of a unified goal for such attacks and their reliance on manually crafted prompts, complicating comprehensive assessments of prompt injection robustness. We introduce a unified framework for understanding the objectives of prompt injection attacks and present an automated gradient-based method for generating highly effective and universal prompt injection data, even in the face of defensiv
    
[^73]: 通过对抗性攻击欺骗神经网络进行动作预测

    Fooling Neural Networks for Motion Forecasting via Adversarial Attacks

    [https://arxiv.org/abs/2403.04954](https://arxiv.org/abs/2403.04954)

    该研究在人体动作预测领域引入了对抗性攻击，通过实验证实模型即使在低水平的扰动下也容易受到攻击，并展示了对简单旋转和平移敏感的模型性能受影响。

    

    人体动作预测仍然是一个需要解决的开放问题，对于自动驾驶和安全应用非常重要。尽管该领域取得了巨大进展，但广泛研究的对抗性攻击主题尚未应用于人体动作预测中的多回归模型，如GCNs和基于MLP的架构。该工作旨在通过对类似于图像分类中对抗性攻击初始阶段的最先进架构进行广泛的定量和定性实验来缩小这一差距。结果表明，即使在低水平扰动上，模型也容易受到攻击。我们还展示了影响模型性能的三维变换实验，特别是我们展示了大多数模型对简单的旋转和平移敏感，这些变换不会改变关节距离。我们得出结论，类似早期CNN模型一样，动作预测任务易受到小的攻击。

    arXiv:2403.04954v1 Announce Type: cross  Abstract: Human motion prediction is still an open problem, which is extremely important for autonomous driving and safety applications. Although there are great advances in this area, the widely studied topic of adversarial attacks has not been applied to multi-regression models such as GCNs and MLP-based architectures in human motion prediction. This work intends to reduce this gap using extensive quantitative and qualitative experiments in state-of-the-art architectures similar to the initial stages of adversarial attacks in image classification. The results suggest that models are susceptible to attacks even on low levels of perturbation. We also show experiments with 3D transformations that affect the model performance, in particular, we show that most models are sensitive to simple rotations and translations which do not alter joint distances. We conclude that similar to earlier CNN models, motion forecasting tasks are susceptible to small
    
[^74]: 用于动态视觉刺激生成的时空风格转移算法

    A spatiotemporal style transfer algorithm for dynamic visual stimulus generation

    [https://arxiv.org/abs/2403.04940](https://arxiv.org/abs/2403.04940)

    提出了Spatiotemporal Style Transfer (STST)算法，基于双流深度神经网络模型，允许生成强大的动态视觉刺激，用于视觉研究。

    

    了解视觉信息如何在生物和人工系统中编码通常需要视觉科学家生成适当的刺激来测试特定的假设。尽管深度神经网络模型已经在图像生成领域引起革命，例如图像风格转移，但视频生成的方法却很少。在这里，我们介绍了时空风格转移（STST）算法，这是一个动态的视觉刺激生成框架，允许强大地操作和合成视频刺激用于视觉研究。它基于一个双流深度神经网络模型，分解空间和时间特征以生成动态视觉刺激，其模型层激活与输入视频的匹配。

    arXiv:2403.04940v1 Announce Type: cross  Abstract: Understanding how visual information is encoded in biological and artificial systems often requires vision scientists to generate appropriate stimuli to test specific hypotheses. Although deep neural network models have revolutionized the field of image generation with methods such as image style transfer, available methods for video generation are scarce. Here, we introduce the Spatiotemporal Style Transfer (STST) algorithm, a dynamic visual stimulus generation framework that allows powerful manipulation and synthesis of video stimuli for vision research. It is based on a two-stream deep neural network model that factorizes spatial and temporal features to generate dynamic visual stimuli whose model layer activations are matched to those of input videos. As an example, we show that our algorithm enables the generation of model metamers, dynamic stimuli whose layer activations within our two-stream model are matched to those of natural
    
[^75]: LeTac-MPC：用于触觉反应抓取的学习模型预测控制

    LeTac-MPC: Learning Model Predictive Control for Tactile-reactive Grasping

    [https://arxiv.org/abs/2403.04934](https://arxiv.org/abs/2403.04934)

    LeTac-MPC是一种学习模型预测控制，利用视觉触觉传感器GelSight和不同iable MPC层，实现在不同条件下和具有不同物理属性的物体上进行稳健抓取控制。

    

    抓取是机器人中的关键任务，需要触觉反馈和反应性抓取调整，以实现在各种条件下和具有不同物理属性的对象的稳健抓取。本文介绍了LeTac-MPC，一种基于学习的模型预测控制（MPC）用于触觉反应式抓取。我们的方法使夹爪能够在动态和力交互任务中抓取具有不同物理属性的对象。我们利用基于视觉的触觉传感器GelSight，该传感器能够感知包含抓取对象的物理属性和状态信息的高分辨率触觉反馈。LeTac-MPC包含一个可微分的MPC层，设计用于对通过神经网络（NN）从触觉反馈中提取的嵌入进行建模。这种设计有助于在25 Hz的频率下实现收敛和稳健的抓取控制。我们提出了一个完全自动化的数据收集流程，并收集了一组数据集。

    arXiv:2403.04934v1 Announce Type: cross  Abstract: Grasping is a crucial task in robotics, necessitating tactile feedback and reactive grasping adjustments for robust grasping of objects under various conditions and with differing physical properties. In this paper, we introduce LeTac-MPC, a learning-based model predictive control (MPC) for tactile-reactive grasping. Our approach enables the gripper grasp objects with different physical properties on dynamic and force-interactive tasks. We utilize a vision-based tactile sensor, GelSight, which is capable of perceiving high-resolution tactile feedback that contains the information of physical properties and states of the grasped object. LeTac-MPC incorporates a differentiable MPC layer designed to model the embeddings extracted by a neural network (NN) from tactile feedback. This design facilitates convergent and robust grasping control at a frequency of 25 Hz. We propose a fully automated data collection pipeline and collect a dataset 
    
[^76]: 人工智能与大型预训练模型合作调查

    A Survey on Human-AI Teaming with Large Pre-Trained Models

    [https://arxiv.org/abs/2403.04931](https://arxiv.org/abs/2403.04931)

    本文调查了大型预训练模型与人工智能合作的重要性，强调了这些模型如何超越传统方法增强协作智能，并探讨了其在增强人类能力、改善AI模型、有效团队合作、道德考虑以及在各个领域广泛应用方面的潜在作用。

    

    在人工智能（AI）迅速发展的景观中，人类智能和AI系统之间的协作，即人工智能（HAI）合作，已成为推进问题解决和决策过程的基石。大型预训练模型（LPtM）的出现显著改变了这一景观，通过利用大量数据来理解和预测复杂模式，为人类提供了前所未有的能力。本文调查了LPtMs与HAI的关键整合，强调了这些模型如何超越传统方法增强协作智能。重点探讨了LPtMs在增强人类能力方面的协同潜力，讨论了这种协作对AI模型改进、有效的团队合作、道德考虑以及在各个领域的广泛应用影响。通过这一探索，研究揭示了LPtM增强HAI的变革性影响。

    arXiv:2403.04931v1 Announce Type: new  Abstract: In the rapidly evolving landscape of artificial intelligence (AI), the collaboration between human intelligence and AI systems, known as Human-AI (HAI) Teaming, has emerged as a cornerstone for advancing problem-solving and decision-making processes. The advent of Large Pre-trained Models (LPtM) has significantly transformed this landscape, offering unprecedented capabilities by leveraging vast amounts of data to understand and predict complex patterns. This paper surveys the pivotal integration of LPtMs with HAI, emphasizing how these models enhance collaborative intelligence beyond traditional approaches. It examines the synergistic potential of LPtMs in augmenting human capabilities, discussing this collaboration for AI model improvements, effective teaming, ethical considerations, and their broad applied implications in various sectors. Through this exploration, the study sheds light on the transformative impact of LPtM-enhanced HAI 
    
[^77]: 关于神经算法推理的马尔可夫性质：分析与方法

    On the Markov Property of Neural Algorithmic Reasoning: Analyses and Methods

    [https://arxiv.org/abs/2403.04929](https://arxiv.org/abs/2403.04929)

    本研究提出了ForgetNet和G-ForgetNet，通过不使用历史嵌入和引入门控机制来解决神经算法推理中的马尔可夫性质矛盾，提供了有价值的计算路径。

    

    神经算法推理是一种新兴的研究方向，赋予神经网络模仿算法执行逐步进行的能力。现有设计中的一个常见范式涉及使用历史嵌入来预测未来执行步骤的结果。本文的观察是，这种历史依赖本质上与算法推理任务的马尔可夫性质相矛盾。基于这一动机，我们提出了我们的ForgetNet，它不使用历史嵌入，因此与任务的马尔可夫性质一致。为了解决ForgetNet在早期阶段训练中的挑战，我们进一步引入了G-ForgetNet，它使用门控机制允许有选择性地整合历史嵌入。这种增强的能力在模型的早期训练阶段提供了有价值的计算路径。我们进行了大量实验，基于CLRS-30算法推理

    arXiv:2403.04929v1 Announce Type: cross  Abstract: Neural algorithmic reasoning is an emerging research direction that endows neural networks with the ability to mimic algorithmic executions step-by-step. A common paradigm in existing designs involves the use of historical embeddings in predicting the results of future execution steps. Our observation in this work is that such historical dependence intrinsically contradicts the Markov nature of algorithmic reasoning tasks. Based on this motivation, we present our ForgetNet, which does not use historical embeddings and thus is consistent with the Markov nature of the tasks. To address challenges in training ForgetNet at early stages, we further introduce G-ForgetNet, which uses a gating mechanism to allow for the selective integration of historical embeddings. Such an enhanced capability provides valuable computational pathways during the model's early training phase. Our extensive experiments, based on the CLRS-30 algorithmic reasoning
    
[^78]: 鉴别功能依赖下的因果效应

    Identifying Causal Effects Under Functional Dependencies

    [https://arxiv.org/abs/2403.04919](https://arxiv.org/abs/2403.04919)

    本文研究了在已知某些变量由它们的父节点功能决定的情况下，如何识别因果效应，在这种情况下可以使得一些不可识别的因果效应变得可识别，并且可以在不影响因果效应可识别性的情况下排除观测到的功能性变量，从而显著减少需要的观测数据中的变量数量。

    

    我们研究了因果效应的识别，受两个改进的启发，可以在已知因果图中某些变量是由它们的父节点功能决定的情况下实现。第一，当某些变量是功能的时，一个不可识别的因果效应可能变得可识别。第二，可以排除观测某些功能变量而不影响因果效应的可识别性，这可能会显著减少需要的观测数据中的变量数量。我们的结果在很大程度上基于一个排除过程，该过程从因果图中删除功能变量，同时保留结果因果图中的关键属性，包括因果效应的可识别性。

    arXiv:2403.04919v1 Announce Type: new  Abstract: We study the identification of causal effects, motivated by two improvements to identifiability which can be attained if one knows that some variables in a causal graph are functionally determined by their parents (without needing to know the specific functions). First, an unidentifiable causal effect may become identifiable when certain variables are functional. Second, certain functional variables can be excluded from being observed without affecting the identifiability of a causal effect, which may significantly reduce the number of needed variables in observational data. Our results are largely based on an elimination procedure which removes functional variables from a causal graph while preserving key properties in the resulting causal graph, including the identifiability of causal effects.
    
[^79]: 基于凸集图的移动目标旅行推销员问题的混合整数锥规划

    A Mixed-Integer Conic Program for the Moving-Target Traveling Salesman Problem based on a Graph of Convex Sets

    [https://arxiv.org/abs/2403.04917](https://arxiv.org/abs/2403.04917)

    本文提出了一个新的公式，用于解决移动目标旅行推销员问题，该公式基于目标在空间-时间坐标系内成为凸集的概念，通过在凸集图中寻找最短路径来实现，在实验中表现出比当前Mixed Integer Conic Program (MICP)求解器更好的效果。

    

    本文介绍了一种寻找移动目标旅行推销员问题（MT-TSP）的最佳解决方案的新的公式，该问题旨在找到一个最短路径，使一个从仓库出发的代理访问一组移动目标，并在它们分配的时间窗口内恰好访问一次，然后返回到仓库。该公式依赖于一个关键思想，即当目标沿着线移动时，它们的轨迹在空间-时间坐标系内变为凸集。然后，问题就缩减为在一个凸集图中寻找最短路径，受到一些速度约束的限制。我们将我们的公式与当前最先进的Mixed Integer Conic Program (MICP)求解器进行了比较，结果显示，我们的公式在目标数量最多为20个的情况下性能优于MICP，在运行时间上缩短了两个数量级，并且最优性差距缩小了高达60％。我们还展示了该解法的成本...

    arXiv:2403.04917v1 Announce Type: cross  Abstract: This paper introduces a new formulation that finds the optimum for the Moving-Target Traveling Salesman Problem (MT-TSP), which seeks to find a shortest path for an agent, that starts at a depot, visits a set of moving targets exactly once within their assigned time-windows, and returns to the depot. The formulation relies on the key idea that when the targets move along lines, their trajectories become convex sets within the space-time coordinate system. The problem then reduces to finding the shortest path within a graph of convex sets, subject to some speed constraints. We compare our formulation with the current state-of-the-art Mixed Integer Conic Program (MICP) solver for the MT-TSP. The experimental results show that our formulation outperforms the MICP for instances with up to 20 targets, with up to two orders of magnitude reduction in runtime, and up to a 60\% tighter optimality gap. We also show that the solution cost from th
    
[^80]: 朝向场景图预测

    Towards Scene Graph Anticipation

    [https://arxiv.org/abs/2403.04899](https://arxiv.org/abs/2403.04899)

    提出了场景图预测（SGA）任务，并引入一个新的方法SceneSayer，通过使用神经ODE和神经SDE的概念，结合对象-centric的关系表示，实现对象之间未来关系的预测。

    

    时空场景图通过将场景分解为单个对象及其两两时间关系来表示视频中的相互作用。长期预测对象之间精细粒度的两两关系是一个具有挑战性的问题。为此，我们引入了场景图预测（SGA）任务。我们将最先进的场景图生成方法用作基线，以预测对象之间未来的两两关系，并提出了一种新颖的方法SceneSayer。在SceneSayer中，我们利用面向对象的关系表示来推断观察到的视频帧并建模对象之间关系的演变。我们采用连续时间视角，并分别使用神经ODE和神经SDE的概念来建模对象相互作用的潜在动态演变。我们通过解决普通微分方程和随机微分方程来推断未来关系的表示。

    arXiv:2403.04899v1 Announce Type: cross  Abstract: Spatio-temporal scene graphs represent interactions in a video by decomposing scenes into individual objects and their pair-wise temporal relationships. Long-term anticipation of the fine-grained pair-wise relationships between objects is a challenging problem. To this end, we introduce the task of Scene Graph Anticipation (SGA). We adapt state-of-the-art scene graph generation methods as baselines to anticipate future pair-wise relationships between objects and propose a novel approach SceneSayer. In SceneSayer, we leverage object-centric representations of relationships to reason about the observed video frames and model the evolution of relationships between objects. We take a continuous time perspective and model the latent dynamics of the evolution of object interactions using concepts of NeuralODE and NeuralSDE, respectively. We infer representations of future relationships by solving an Ordinary Differential Equation and a Stoch
    
[^81]: ConstitutionalExperts: 训练基于原则的提示混合体

    ConstitutionalExperts: Training a Mixture of Principle-based Prompts

    [https://arxiv.org/abs/2403.04894](https://arxiv.org/abs/2403.04894)

    提出了ConstitutionalExperts方法，通过学习宪法原则构建提示，采用逐步改进提示和MoE架构，展现出在不同语义区域学习独特提示的潜力，并在六个基准数据集上表现优异。

    

    大型语言模型（LLMs）在各种任务上表现出色，但写作仍然是一个困难且繁琐的过程。 在这项工作中，我们介绍了ConstitutionalExperts，这是一种学习由宪法原则（即规则）组成的提示的方法，给定一个训练数据集。 与以往优化提示作为单个实体的方法不同，我们的方法通过分别编辑各个原则逐步改进提示。 我们还展示了通过为训练数据的不同语义区域学习唯一的提示，并在推断时使用专家混合（MoE）架构来提高整体性能。 我们将我们的方法与其他六个基准数据集上的其他最先进的提示优化技术进行了比较。 我们还调查了MoE是否改善这些其他技术。 我们的结果表明，ConstitutionalExperts的表现优于其他提示优化技术。

    arXiv:2403.04894v1 Announce Type: cross  Abstract: Large language models (LLMs) are highly capable at a variety of tasks given the right prompt, but writing one is still a difficult and tedious process. In this work, we introduce ConstitutionalExperts, a method for learning a prompt consisting of constitutional principles (i.e. rules), given a training dataset. Unlike prior methods that optimize the prompt as a single entity, our method incrementally improves the prompt by surgically editing individual principles. We also show that we can improve overall performance by learning unique prompts for different semantic regions of the training data and using a mixture-of-experts (MoE) architecture to route inputs at inference time. We compare our method to other state of the art prompt-optimization techniques across six benchmark datasets. We also investigate whether MoE improves these other techniques. Our results suggest that ConstitutionalExperts outperforms other prompt optimization tec
    
[^82]: 一种用于AI评估和红队测试的安全港

    A Safe Harbor for AI Evaluation and Red Teaming

    [https://arxiv.org/abs/2403.04893](https://arxiv.org/abs/2403.04893)

    主要AI开发者应承诺提供法律和技术上的安全港，使公共利益的安全研究免受账户暂停或法律报复的威胁。

    

    独立评估和红队测试对于发现生成式AI系统所带来的风险至关重要。然而，主要AI公司用于阻止模型误用的服务条款和执行策略会对善意的安全评估造成打击。这导致一些研究人员担心进行此类研究或发布其发现将导致账户被暂停或面临法律报复。虽然一些公司提供研究人员访问计划，但它们无法替代独立研究访问，因为它们的社区代表性有限，资金不足，并且缺乏独立于企业激励的性质。我们提出，主要AI开发者承诺提供法律和技术上的安全港，使公共利益的安全研究免受账户暂停或法律报复的威胁。这些提议源自我们进行安全评估的集体经验。

    arXiv:2403.04893v1 Announce Type: new  Abstract: Independent evaluation and red teaming are critical for identifying the risks posed by generative AI systems. However, the terms of service and enforcement strategies used by prominent AI companies to deter model misuse have disincentives on good faith safety evaluations. This causes some researchers to fear that conducting such research or releasing their findings will result in account suspensions or legal reprisal. Although some companies offer researcher access programs, they are an inadequate substitute for independent research access, as they have limited community representation, receive inadequate funding, and lack independence from corporate incentives. We propose that major AI developers commit to providing a legal and technical safe harbor, indemnifying public interest safety research and protecting it from the threat of account suspensions or legal reprisal. These proposals emerged from our collective experience conducting sa
    
[^83]: 用于结构化和非结构化数据的模块化端到端多模态学习方法

    A Modular End-to-End Multimodal Learning Method for Structured and Unstructured Data

    [https://arxiv.org/abs/2403.04866](https://arxiv.org/abs/2403.04866)

    提出了一种名为MAGNUM的模块化、端到端的多模态学习方法，可以本地化处理结构化和非结构化数据。

    

    多模态学习是一个快速发展的研究领域，已经在人工智能中的多任务处理和生成建模方面取得了革命性进展。虽然许多研究集中于处理非结构化数据（如语言、图像、音频或视频），结构化数据（如表格数据、时间序列或信号）却受到较少关注。然而，许多与行业相关的用例既涉及这两种类型的数据，也能从中受益。在这项工作中，我们提出了一种名为MAGNUM的模块化、端到端的多模态学习方法，可以本地化处理结构化和非结构化数据。MAGNUM足够灵活，可以利用任何专门的单模态模块从所有可用的模态中提取、压缩和融合信息。

    arXiv:2403.04866v1 Announce Type: new  Abstract: Multimodal learning is a rapidly growing research field that has revolutionized multitasking and generative modeling in AI. While much of the research has focused on dealing with unstructured data (e.g., language, images, audio, or video), structured data (e.g., tabular data, time series, or signals) has received less attention. However, many industry-relevant use cases involve or can be benefited from both types of data. In this work, we propose a modular, end-to-end multimodal learning method called MAGNUM, which can natively handle both structured and unstructured data. MAGNUM is flexible enough to employ any specialized unimodal module to extract, compress, and fuse information from all available modalities.
    
[^84]: 卫星图像时间自监督（S3-TSS）：卫星图像中的SSL技术的新方法

    Self-Supervision in Time for Satellite Images(S3-TSS): A novel method of SSL technique in Satellite images

    [https://arxiv.org/abs/2403.04859](https://arxiv.org/abs/2403.04859)

    提出了一种新的卫星图像中的自监督学习方法S3-TSS，利用时间维度中的自然增强，结果显示在四个下游数据集中优于基线方法SeCo。

    

    随着遥感图像中带有各种大气条件的标记数据的有限可用性，似乎使用自监督算法很有用。包括旋转、空间上下文和拼图在内的几种基于假设的算法并不适用于卫星图像。通常，卫星图像具有更高的时间频率。 因此，遥感数据的时间维度提供了自然增强，而无需我们创建图像的人工增强。 在这里，我们提出了S3-TSS，一种利用时间维度中自然增强的自监督学习技术的新方法。 我们将我们的结果与当前领先的方法进行了比较，并进行了各种实验。 我们观察到，我们的方法在四个下游数据集中表现优于基线SeCo。 我们的工作代码可以在这里找到：https://github.com/hewanshrestha/Why-Self-Supervision-in-Time

    arXiv:2403.04859v1 Announce Type: new  Abstract: With the limited availability of labeled data with various atmospheric conditions in remote sensing images, it seems useful to work with self-supervised algorithms. Few pretext-based algorithms, including from rotation, spatial context and jigsaw puzzles are not appropriate for satellite images. Often, satellite images have a higher temporal frequency. So, the temporal dimension of remote sensing data provides natural augmentation without requiring us to create artificial augmentation of images. Here, we propose S3-TSS, a novel method of self-supervised learning technique that leverages natural augmentation occurring in temporal dimension. We compare our results with current state-of-the-art methods and also perform various experiments. We observed that our method was able to perform better than baseline SeCo in four downstream datasets. Code for our work can be found here: https://github.com/hewanshrestha/Why-Self-Supervision-in-Time
    
[^85]: 在句法感知代码填空任务上评估LLMs

    Evaluation of LLMs on Syntax-Aware Code Fill-in-the-Middle Tasks

    [https://arxiv.org/abs/2403.04814](https://arxiv.org/abs/2403.04814)

    该研究引入了一个新的基准SAFIM用于评估LLMs在代码填空任务上的句法感知完成表现，发现FIM预训练不仅提高了FIM的熟练度，还改善了LLMs的左到右推理，挑战了传统观念并表明预训练方法和数据品质对模型性能的影响更甚于模型大小。

    

    我们介绍了一种名为Syntax-Aware Fill-In-the-Middle（SAFIM）的新基准，用于评估大型语言模型（LLMs）在代码填空（FIM）任务上的表现。该基准侧重于程序结构的句法感知完成，如代码块和条件表达式，并包括来自多种编程语言的17,720个示例，来源于2022年4月之后的最新代码提交，以最小化数据污染。 SAFIM提供了一个强大的框架，具有各种提示设计和新颖的句法感知后处理技术，有助于在LLMs之间进行准确和公平的比较。我们对15个LLMs进行了全面评估，结果表明FIM预训练不仅提升了FIM的熟练程度，还改进了LLMs的左到右（L2R）推理。我们的发现挑战了传统观念，并表明预训练方法和数据质量对模型性能的影响大于模型大小。因此，SAFIM为未来构建

    arXiv:2403.04814v1 Announce Type: cross  Abstract: We introduce Syntax-Aware Fill-In-the-Middle (SAFIM), a new benchmark for evaluating Large Language Models (LLMs) on the code Fill-in-the-Middle (FIM) task. This benchmark focuses on syntax-aware completions of program structures such as code blocks and conditional expressions, and includes 17,720 examples from multiple programming languages, sourced from recent code submissions after April 2022 to minimize data contamination. SAFIM provides a robust framework with various prompt designs and novel syntax-aware post-processing techniques, facilitating accurate and fair comparisons across LLMs. Our comprehensive evaluation of 15 LLMs shows that FIM pretraining not only enhances FIM proficiency but also improves Left-to-Right (L2R) inference using LLMs. Our findings challenge conventional beliefs and suggest that pretraining methods and data quality have more impact than model size. SAFIM thus serves as a foundational platform for future 
    
[^86]: 限制贝叶斯神经网络

    Restricted Bayesian Neural Network

    [https://arxiv.org/abs/2403.04810](https://arxiv.org/abs/2403.04810)

    本研究提出了限制贝叶斯神经网络的新架构，显著减少了网络存储空间复杂性，并引入了一种能够有效处理不确定性的算法，确保在目标函数缺乏完美凸性时稳健地收敛至全局最优解。

    

    现代深度学习工具在解决复杂问题方面非常有效。然而，它们作为黑盒模型的运行方式增加了预测的不确定性。此外，它们面临着各种挑战，包括在大型网络中需要大量存储空间、过拟合、欠拟合、梯度消失等问题。本研究探讨了贝叶斯神经网络的概念，提出了一种能够显著减少网络存储空间复杂性的新型架构。此外，我们介绍了一种能够有效处理不确定性的算法，确保稳健的收敛值，避免陷入局部最优解，尤其是当目标函数缺乏完美的凸性时。

    arXiv:2403.04810v1 Announce Type: cross  Abstract: Modern deep learning tools are remarkably effective in addressing intricate problems. However, their operation as black-box models introduces increased uncertainty in predictions. Additionally, they contend with various challenges, including the need for substantial storage space in large networks, issues of overfitting, underfitting, vanishing gradients, and more. This study explores the concept of Bayesian Neural Networks, presenting a novel architecture designed to significantly alleviate the storage space complexity of a network. Furthermore, we introduce an algorithm adept at efficiently handling uncertainties, ensuring robust convergence values without becoming trapped in local optima, particularly when the objective function lacks perfect convexity.
    
[^87]: 神经网络的数学（研究生课程讲义）

    Mathematics of Neural Networks (Lecture Notes Graduate Course)

    [https://arxiv.org/abs/2403.04807](https://arxiv.org/abs/2403.04807)

    该课程旨在向研究生数学专业的学生介绍神经网络并激发兴趣，主要内容包括深度学习的数学介绍和将李群理论应用于设计具有几何等变性的神经网络，讲义及编码教程公开可获取

    

    这些是我在2021年至2023年在埃因霍温科技大学教授的同名课程的讲义。该课程旨在向研究生数学专业的学生介绍神经网络，并旨在激发数学学生对进一步研究神经网络感兴趣。课程分为两部分：首先是关于深度学习的一般介绍，侧重于以形式化数学方式介绍该领域。第二部分介绍李群和同态空间的理论，以及如何将其应用于设计具有理想几何等变性的神经网络。讲义尽可能自包含，以便对具有一定数学背景的任何学生都可以理解。该课程还包括一系列Jupyter笔记本形式的编码教程和作业，可在https://g上公开获取

    arXiv:2403.04807v1 Announce Type: cross  Abstract: These are the lecture notes that accompanied the course of the same name that I taught at the Eindhoven University of Technology from 2021 to 2023. The course is intended as an introduction to neural networks for mathematics students at the graduate level and aims to make mathematics students interested in further researching neural networks. It consists of two parts: first a general introduction to deep learning that focuses on introducing the field in a formal mathematical way. The second part provides an introduction to the theory of Lie groups and homogeneous spaces and how it can be applied to design neural networks with desirable geometric equivariances. The lecture notes were made to be as self-contained as possible so as to accessible for any student with a moderate mathematics background. The course also included coding tutorials and assignments in the form of a set of Jupyter notebooks that are publicly available at https://g
    
[^88]: 通过自适应共识验证模型更新，增强联邦学习的安全性

    Enhancing Security in Federated Learning through Adaptive Consensus-Based Model Update Validation

    [https://arxiv.org/abs/2403.04803](https://arxiv.org/abs/2403.04803)

    通过自适应阈值机制和共识验证流程，增强了联邦学习系统对标签翻转攻击的安全性，有效减轻了攻击并提升系统的弹性。

    

    本文介绍了一种先进的方法，用于加强联邦学习（FL）系统抵御标签翻转攻击。我们提出了一个简化的基于共识的验证流程，结合自适应阈值机制。这种动态阈值设计旨在根据模型更新的发展情况进行调整，提供了一个精细的异常检测层，与分布式学习环境的实时需求保持一致。我们的方法需要参与客户之间达成多数共识才能验证更新，确保只有经过审查和共识的修改才应用于全局模型。我们通过在深度学习的两个基准数据集CIFAR-10和MNIST上进行实验验证了我们方法的有效性。我们的结果表明，标签翻转攻击得到了显著减轻，增强了FL系统的弹性。这种方法超越了依赖异常检测的传统技术。

    arXiv:2403.04803v1 Announce Type: cross  Abstract: This paper introduces an advanced approach for fortifying Federated Learning (FL) systems against label-flipping attacks. We propose a simplified consensus-based verification process integrated with an adaptive thresholding mechanism. This dynamic thresholding is designed to adjust based on the evolving landscape of model updates, offering a refined layer of anomaly detection that aligns with the real-time needs of distributed learning environments. Our method necessitates a majority consensus among participating clients to validate updates, ensuring that only vetted and consensual modifications are applied to the global model. The efficacy of our approach is validated through experiments on two benchmark datasets in deep learning, CIFAR-10 and MNIST. Our results indicate a significant mitigation of label-flipping attacks, bolstering the FL system's resilience. This method transcends conventional techniques that depend on anomaly detec
    
[^89]: 低资源语言中的人工智能素养：从创造约鲁巴语AI视频中获得的见解

    AI Literacy in Low-Resource Languages:Insights from creating AI in Yoruba videos

    [https://arxiv.org/abs/2403.04799](https://arxiv.org/abs/2403.04799)

    本研究探索了在低资源语言如约鲁巴语中创建和分发人工智能视频的方法，并展示了其在全球范围内的潜在影响。

    

    为了有效地应对人工智能革命，人工智能素养至关重要。然而，主要存在于主导语言中的内容在像约鲁巴语（有4100万母语使用者）这样的低资源语言中造成了一定的差距。本案例研究探讨了通过在约鲁巴语中创建和分发AI视频来弥合这一差距。该项目开发了26个视频，涵盖基础、中级和高级人工智能概念，利用故事叙述和简易解释。这些视频采用了一种成本效益高的方法制作，并在YouTube、LinkedIn和Twitter上进行分发，估计触及了来自22个国家的全球观众。对YouTube的分析揭示了观看模式的见解，其中25-44岁年龄组贡献了最多的观看量。值得注意的是，超过一半的流量来源于外部来源，突显了跨平台推广的潜力。这项研究展示了在低资源语言中创建人工智能素养内容的可行性和影响。

    arXiv:2403.04799v1 Announce Type: cross  Abstract: To effectively navigate the AI revolution, AI literacy is crucial. However, content predominantly exists in dominant languages, creating a gap for low-resource languages like Yoruba (41 million native speakers). This case study explores bridging this gap by creating and distributing AI videos in Yoruba.The project developed 26 videos covering foundational, intermediate, and advanced AI concepts, leveraging storytelling and accessible explanations. These videos were created using a cost-effective methodology and distributed across YouTube, LinkedIn, and Twitter, reaching an estimated global audience of 22 countries. Analysis of YouTube reveals insights into viewing patterns, with the 25-44 age group contributing the most views. Notably, over half of the traffic originated from external sources, highlighting the potential of cross-platform promotion.This study demonstrates the feasibility and impact of creating AI literacy content in low
    
[^90]: 消防工程中的大型语言模型：针对领域知识对技术问题的审查

    Large Language Models in Fire Engineering: An Examination of Technical Questions Against Domain Knowledge

    [https://arxiv.org/abs/2403.04795](https://arxiv.org/abs/2403.04795)

    本研究比较了两个聊天机器人在消防工程中处理问题的表现，发现ChatGPT表现较优，展示了聊天机器人技术在消防工程实践中的潜力。

    

    本文介绍了比较两个最近的聊天机器人OpenAI的ChatGPT和谷歌的Bard，在火灾工程领域中评估它们处理与消防安全相关查询的回应的初步研究结果。 创建并检查了一系列不同类型的消防工程问题和场景，其中包括结构火灾设计、防火策略、疏散、建筑法规合规和灭火系统等（其中一些类似于消防保护考试（FPE）中常见的情况）。 结果显示了聊天机器人性能上的一些关键差异，ChatGPT表现出相对较好的性能。 此外，本论文突出了聊天机器人技术在提供关键信息的同时彻底改革消防工程实践的潜力，并概述了进一步改进和研究的领域。显然，在技术成熟后，这项技术将可能

    arXiv:2403.04795v1 Announce Type: cross  Abstract: This communication presents preliminary findings from comparing two recent chatbots, OpenAI's ChatGPT and Google's Bard, in the context of fire engineering by evaluating their responses in handling fire safety related queries. A diverse range of fire engineering questions and scenarios were created and examined, including structural fire design, fire prevention strategies, evacuation, building code compliance, and fire suppression systems (some of which resemble those commonly present in the Fire Protection exam (FPE)). The results reveal some key differences in the performance of the chatbots, with ChatGPT demonstrating a relatively superior performance. Then, this communication highlights the potential for chatbot technology to revolutionize fire engineering practices by providing instant access to critical information while outlining areas for further improvement and research. Evidently, and when it matures, this technology will lik
    
[^91]: 一种基于数据驱动的两阶段多分裂因果集成模型用于时间序列

    A Data-Driven Two-Phase Multi-Split Causal Ensemble Model for Time Series

    [https://arxiv.org/abs/2403.04793](https://arxiv.org/abs/2403.04793)

    提出了一种基于数据驱动的两阶段多分裂因果集成模型，通过组合不同因果基准算法的优势，降低噪音的影响，实现更稳健的因果推断结果。

    

    因果推断是许多学科中发现因果关系的基础研究主题。然而，并非所有算法都同样适用于给定数据集。该论文提出了一种新颖的基于数据驱动的两阶段多分裂因果集成模型，结合了不同因果算法的优势，以实现更稳健的因果推断结果。

    arXiv:2403.04793v1 Announce Type: cross  Abstract: Causal inference is a fundamental research topic for discovering the cause-effect relationships in many disciplines. However, not all algorithms are equally well-suited for a given dataset. For instance, some approaches may only be able to identify linear relationships, while others are applicable for non-linearities. Algorithms further vary in their sensitivity to noise and their ability to infer causal information from coupled vs. non-coupled time series. Therefore, different algorithms often generate different causal relationships for the same input. To achieve a more robust causal inference result, this publication proposes a novel data-driven two-phase multi-split causal ensemble model to combine the strengths of different causality base algorithms. In comparison to existing approaches, the proposed ensemble method reduces the influence of noise through a data partitioning scheme in the first phase. To achieve this, the data are i
    
[^92]: 大型语言模型的在线训练：边聊天边学习

    Online Training of Large Language Models: Learn while chatting

    [https://arxiv.org/abs/2403.04790](https://arxiv.org/abs/2403.04790)

    本论文提出了一种新的互动范式，允许大型语言模型通过外部互动进行在线训练，实现了持续、实时的模型更新与个性化定制的灵活性。

    

    大语言模型(LLMs)已经极大地改变了自然语言处理(NLP)领域，提供了引人注目的功能，受到了广泛的应用。然而，现有的LLMs与用户之间的互动范式受制于灵活性不足、定制化受限或缺乏持续性学习。为了克服这些挑战，本文引入了一种新的互动范式-“使用外部互动进行在线训练”，将持续、实时的模型更新与通过外部互动（如AI）进行个性化定制相结合。

    arXiv:2403.04790v1 Announce Type: cross  Abstract: Large Language Models(LLMs) have dramatically revolutionized the field of Natural Language Processing(NLP), offering remarkable capabilities that have garnered widespread usage. However, existing interaction paradigms between LLMs and users are constrained by either inflexibility, limitations in customization, or a lack of persistent learning. This inflexibility is particularly evident as users, especially those without programming skills, have restricted avenues to enhance or personalize the model. Existing frameworks further complicate the model training and deployment process due to their computational inefficiencies and lack of user-friendly interfaces. To overcome these challenges, this paper introduces a novel interaction paradigm-'Online Training using External Interactions'-that merges the benefits of persistent, real-time model updates with the flexibility for individual customization through external interactions such as AI a
    
[^93]: TopicDiff：一种用于多模态会话情感检测的主题丰富扩散方法

    TopicDiff: A Topic-enriched Diffusion Approach for Multimodal Conversational Emotion Detection

    [https://arxiv.org/abs/2403.04789](https://arxiv.org/abs/2403.04789)

    提出了一种TopicDiff方法，用于捕获多模态会话情感检测任务中的主题信息，通过将扩散模型集成到神经主题模型中，解决了神经主题模型在捕获主题信息方面的多样性不足问题，并相对于现有MCE基线取得了显著改进

    

    多模态会话情感（MCE）检测通常跨越声学、视觉和语言模态，吸引了多媒体社区日益增加的兴趣。先前的研究主要集中在学习对话中的语境信息，只有少数考虑单一语言模态中的主题信息，而总是忽视声学和视觉主题信息。在此基础上，我们提出了一个模型不可知的Topic-enriched Diffusion（TopicDiff）方法，用于捕获MCE任务中的多模态主题信息。特别是，我们将扩散模型集成到神经主题模型中，以缓解神经主题模型在捕获主题信息方面的多样性不足问题。详细的评估表明，TopicDiff相对于最先进的MCE基线取得了显著改进，证明了多模态主题信息对MCE的重要性以及TopicDiff的有效性。

    arXiv:2403.04789v1 Announce Type: cross  Abstract: Multimodal Conversational Emotion (MCE) detection, generally spanning across the acoustic, vision and language modalities, has attracted increasing interest in the multimedia community. Previous studies predominantly focus on learning contextual information in conversations with only a few considering the topic information in single language modality, while always neglecting the acoustic and vision topic information. On this basis, we propose a model-agnostic Topic-enriched Diffusion (TopicDiff) approach for capturing multimodal topic information in MCE tasks. Particularly, we integrate the diffusion model into neural topic model to alleviate the diversity deficiency problem of neural topic model in capturing topic information. Detailed evaluations demonstrate the significant improvements of TopicDiff over the state-of-the-art MCE baselines, justifying the importance of multimodal topic information to MCE and the effectiveness of Topic
    
[^94]: 通过混合和完善过去来不断演进记忆

    Ever-Evolving Memory by Blending and Refining the Past

    [https://arxiv.org/abs/2403.04787](https://arxiv.org/abs/2403.04787)

    提出了一种新颖的长期对话记忆方案CREEM，通过混合过去记忆并引入完善过程来实现聊天机器人回应的整体改进和连贯性。

    

    对于类似人类的聊天机器人，构建长期记忆至关重要。构建记忆的一个天真方法可能只是列出总结的对话。然而，当说话者的状态随时间变化时，这样做可能会导致问题，并积累矛盾信息。记忆保持有组织对于降低回应生成器的混乱很重要。在本文中，我们提出了一种新颖的长期对话记忆方案，CREEM。与仅基于当前对话构建记忆的现有方法不同，我们提出的模型在记忆形成过程中混合过去的记忆。此外，我们引入了完善过程来处理多余或过时信息。这种创新性方法通过确保一个更加知情和动态演变的长期记忆，旨在提高聊天机器人回应的整体改进和连贯性。

    arXiv:2403.04787v1 Announce Type: cross  Abstract: For a human-like chatbot, constructing a long-term memory is crucial. A naive approach for making a memory could be simply listing the summarized dialogue. However, this can lead to problems when the speaker's status change over time and contradictory information gets accumulated. It is important that the memory stays organized to lower the confusion for the response generator. In this paper, we propose a novel memory scheme for long-term conversation, CREEM. Unlike existing approaches that construct memory based solely on current sessions, our proposed model blending past memories during memory formation. Additionally, we introduce refining process to handle redundant or outdated information. This innovative approach seeks for overall improvement and coherence of chatbot responses by ensuring a more informed and dynamically evolving long-term memory.
    
[^95]: 使用电子健康记录数据预测5年慢性疾病队列的大型语言多模型

    Large Language Multimodal Models for 5-Year Chronic Disease Cohort Prediction Using EHR Data

    [https://arxiv.org/abs/2403.04785](https://arxiv.org/abs/2403.04785)

    本研究提出了一种大型语言多模型（LLMMs）框架，结合临床笔记和实验室检验结果的多模态数据，用于预测慢性疾病风险。

    

    慢性疾病如糖尿病是全球发病率和死亡率的主要原因。本研究从台湾医院数据库收集了五年的电子健康记录数据，包括1,420,596份临床笔记、387,392份实验室检验结果以及超过1,505种实验室检验项目，重点研究了用于研究预训练大型语言模型的方法。我们提出了一种新颖的大型语言多模型（LLMMs）框架，将临床笔记和实验室检验结果的多模态数据相结合，用于预测慢性疾病风险。我们的方法结合了文本嵌入编码器和多头注意力层来学习实验室检验数值，利用深度神经网络（DNN）模块进行预测。

    arXiv:2403.04785v1 Announce Type: cross  Abstract: Chronic diseases such as diabetes are the leading causes of morbidity and mortality worldwide. Numerous research studies have been attempted with various deep learning models in diagnosis. However, most previous studies had certain limitations, including using publicly available datasets (e.g. MIMIC), and imbalanced data. In this study, we collected five-year electronic health records (EHRs) from the Taiwan hospital database, including 1,420,596 clinical notes, 387,392 laboratory test results, and more than 1,505 laboratory test items, focusing on research pre-training large language models. We proposed a novel Large Language Multimodal Models (LLMMs) framework incorporating multimodal data from clinical notes and laboratory test results for the prediction of chronic disease risk. Our method combined a text embedding encoder and multi-head attention layer to learn laboratory test values, utilizing a deep neural network (DNN) module to 
    
[^96]: 一项关于时间知识图的调查：表示学习与应用

    A Survey on Temporal Knowledge Graph: Representation Learning and Applications

    [https://arxiv.org/abs/2403.04782](https://arxiv.org/abs/2403.04782)

    时间知识图表示学习将时间信息融入标准知识图框架，可以对实体和关系随时间的动态变化进行建模。

    

    知识图引起了重要的研究关注，并被广泛用于增强下游应用。然而，大多数当前研究主要集中在静态知识图上，其事实不随时间而变化，并忽略了它们随时间的动态演变。因此，时间知识图受到更多关注，因为大量结构化知识仅存在于特定时期内。知识图表示学习旨在为知识图中的实体和关系学习低维向量嵌入。时态知识图的表示学习将时间信息融入标准知识图框架中，可以对实体和关系随时间的动态变化进行建模。本文对时态知识图表示学习及其应用进行了全面调查。我们从介绍定义、数据集和e

    arXiv:2403.04782v1 Announce Type: cross  Abstract: Knowledge graphs have garnered significant research attention and are widely used to enhance downstream applications. However, most current studies mainly focus on static knowledge graphs, whose facts do not change with time, and disregard their dynamic evolution over time. As a result, temporal knowledge graphs have attracted more attention because a large amount of structured knowledge exists only within a specific period. Knowledge graph representation learning aims to learn low-dimensional vector embeddings for entities and relations in a knowledge graph. The representation learning of temporal knowledge graphs incorporates time information into the standard knowledge graph framework and can model the dynamics of entities and relations over time. In this paper, we conduct a comprehensive survey of temporal knowledge graph representation learning and its applications. We begin with an introduction to the definitions, datasets, and e
    
[^97]: MuseGraph：面向大型语言模型的图导向指令调整用于通用图挖掘

    MuseGraph: Graph-oriented Instruction Tuning of Large Language Models for Generic Graph Mining

    [https://arxiv.org/abs/2403.04780](https://arxiv.org/abs/2403.04780)

    MuseGraph将GNNs和LLMs的优势结合起来，提出了一种更有效和通用的图挖掘方法，可以跨不同任务和数据集使用

    

    具有丰富属性的图在建模互联实体和改进各种实际应用中的预测方面至关重要。传统图神经网络（GNNs）通常用于建模带属性的图，但需要在应用于不同图任务和数据集时进行重新训练。尽管大型语言模型（LLMs）的出现在自然语言处理中引入了新的范例，但LLMs在图挖掘中的生成潜力仍未得到充分探索。为此，我们提出了一个新颖的框架 MuseGraph，它无缝整合了GNNs和LLMs的优势，并促进了一种更有效和通用的图挖掘方法，可跨不同任务和数据集使用。具体而言，我们首先通过提出的自适应输入生成引入一个紧凑的图描述，以在语言令牌限制的约束下封装来自图的关键信息。

    arXiv:2403.04780v1 Announce Type: cross  Abstract: Graphs with abundant attributes are essential in modeling interconnected entities and improving predictions in various real-world applications. Traditional Graph Neural Networks (GNNs), which are commonly used for modeling attributed graphs, need to be re-trained every time when applied to different graph tasks and datasets. Although the emergence of Large Language Models (LLMs) has introduced a new paradigm in natural language processing, the generative potential of LLMs in graph mining remains largely under-explored. To this end, we propose a novel framework MuseGraph, which seamlessly integrates the strengths of GNNs and LLMs and facilitates a more effective and generic approach for graph mining across different tasks and datasets. Specifically, we first introduce a compact graph description via the proposed adaptive input generation to encapsulate key information from the graph under the constraints of language token limitations. T
    
[^98]: 具有延迟合一的叠加

    Superposition with Delayed Unification

    [https://arxiv.org/abs/2403.04775](https://arxiv.org/abs/2403.04775)

    将合一算法移动到演算层次后，一阶叠加仍然保持完备，这对于标准一阶叠加也带来了一些好处。

    

    在基于饱和的证明系统中，传统上认为合一是原子的。然而，也可以将合一移动到演算层次，将合一算法的步骤转化为推理。对于依赖返回大甚至无穷集合的合一程序的演算来说，将合一融入演算是一种将合一和推理相互交织的吸引人方法。这适用于AC-叠加和高阶叠加等情况。我们证明了当将合一规则移动到演算层面时，一阶叠加仍然是完备的。我们讨论了即使对于标准的一阶叠加，这也具有诸多好处，并提供了实验评估。

    arXiv:2403.04775v1 Announce Type: cross  Abstract: Classically, in saturation-based proof systems, unification has been considered atomic. However, it is also possible to move unification to the calculus level, turning the steps of the unification algorithm into inferences. For calculi that rely on unification procedures returning large or even infinite sets of unifiers, integrating unification into the calculus is an attractive method of dovetailing unification and inference. This applies, for example, to AC-superposition and higher-order superposition. We show that first-order superposition remains complete when moving unification rules to the calculus level. We discuss some of the benefits this has even for standard first-order superposition and provide an experimental evaluation.
    
[^99]: 用粗糙集表示教学内容知识

    Representing Pedagogic Content Knowledge Through Rough Sets

    [https://arxiv.org/abs/2403.04772](https://arxiv.org/abs/2403.04772)

    在本研究中，提出了一种基于两层粗糙集的模型，能够一致处理模糊性、粒度和多模态性，可用于建模教师对内容理解，展示了其在教学领域的潜在应用。

    

    一名教师的知识基础包括数学内容知识、学生认识论知识和教学知识。这对于理解学生对内容的知识以及学习环境有着严重影响。教育研究文献认识到在近似意义上形式化不同内容知识的必要性。相关问题之一是协调的形式化问题。现有AI软件系统不关注意义，经过训练的系统也存在自身的问题。本研究识别了建模教师对内容理解中的许多问题，并提出了一种基于两层粗糙集的模型。所提出方法的主要优势在于其能够一致处理模糊性、粒度和多模态性。利用扩展示例展示了这些特点，以等式推理为例。

    arXiv:2403.04772v1 Announce Type: new  Abstract: A teacher's knowledge base consists of knowledge of mathematics content, knowledge of student epistemology, and pedagogical knowledge. It has severe implications on the understanding of student's knowledge of content, and the learning context in general. The necessity to formalize the different content knowledge in approximate senses is recognized in the education research literature. A related problem is that of coherent formalizability. Responsive or smart AI-based software systems do not concern themselves with meaning, and trained ones are replete with their own issues. In the present research, many issues in modeling teachers' understanding of content are identified, and a two-tier rough set-based model is proposed by the present author. The main advantage of the proposed approach is in its ability to coherently handle vagueness, granularity and multi-modality. An extended example to equational reasoning is used to demonstrate these
    
[^100]: 移除GPT4的过滤器

    Removing GPT4's Filter

    [https://arxiv.org/abs/2403.04769](https://arxiv.org/abs/2403.04769)

    提出了一种方法，可以使经过微调的GPT4恢复到没有经过人类反馈强化学习训练的状态，从而移除其在学习期间的所有安全机制

    

    GPT4最初在大量数据集上进行训练，然后使用来自人类反馈的强化学习进行微调，即志愿者提供反馈以教导GPT4不要生成不当内容。本文提出了一种方法来操作已经进行微调的版本，使其恢复到没有经过RLHF（Reinforcement learning from Human Feedback）的行为，有效地移除了模型在RLHF期间学习的所有安全机制。特别是，当GPT4在没有经过RLHF的情况下运行时，它失去了所有抑制力，只需前几个词就可以生成非常不当的内容。

    arXiv:2403.04769v1 Announce Type: cross  Abstract: GPT4 was initially trained on large amounts of data, and then fine-tuned using Reinforcement learning from Human Feedback (RLHF), which is when volunteers give feedback in order to teach GPT4 not to create inappropriate content. In this paper, we present a method to manipulate the fine-tuned version into reverting to pre-RLHF behavior, effectively removing all safety mechanisms that the model learned during RLHF. In particular, when GPT4 acts without RLHF, it loses all inhibition, and can complete very inappropriate content given only the first few words.
    
[^101]: 我们距离智能视觉演绎推理还有多远？

    How Far Are We from Intelligent Visual Deductive Reasoning?

    [https://arxiv.org/abs/2403.04732](https://arxiv.org/abs/2403.04732)

    目前的视觉语言模型在文本推理方面表现出色，但在视觉演绎推理方面仍存在较大差距和盲点。

    

    最近，诸如GPT-4V之类的视觉语言模型（VLM）在各种视觉语言任务上取得了巨大进展。我们深入探讨了基于视觉的演绎推理，这是一个更复杂但不太被探索的领域，并发现了当前领先的VLM中以前未暴露的盲点。具体来说，我们利用瑞文渐进矩阵（RPM）来评估VLM在仅依靠视觉线索进行多跳关系和演绎推理的能力。我们对几种流行的VLM进行了全面评估，采用了标准策略，如上下文学习、自我一致性和思维链（CoT），在三个不同的数据集上进行了评估，包括Mensa智商测试、智商测试和RAVEN。结果表明，尽管LLM在基于文本的推理方面具有令人印象深刻的能力，但我们在视觉演绎推理方面仍有很大的差距。

    arXiv:2403.04732v1 Announce Type: new  Abstract: Vision-Language Models (VLMs) such as GPT-4V have recently demonstrated incredible strides on diverse vision language tasks. We dig into vision-based deductive reasoning, a more sophisticated but less explored realm, and find previously unexposed blindspots in the current SOTA VLMs. Specifically, we leverage Raven's Progressive Matrices (RPMs), to assess VLMs' abilities to perform multi-hop relational and deductive reasoning relying solely on visual clues. We perform comprehensive evaluations of several popular VLMs employing standard strategies such as in-context learning, self-consistency, and Chain-of-thoughts (CoT) on three diverse datasets, including the Mensa IQ test, IntelligenceTest, and RAVEN. The results reveal that despite the impressive capabilities of LLMs in text-based reasoning, we are still far from achieving comparable proficiency in visual deductive reasoning. We found that certain standard strategies that are effective
    
[^102]: 基于上下文的多模态融合

    Context-Based Multimodal Fusion

    [https://arxiv.org/abs/2403.04650](https://arxiv.org/abs/2403.04650)

    提出一种基于上下文的多模态融合模型，结合了模态融合和数据分布对齐，通过特定上下文向量表示每个模态，并将其与每个模态的嵌入进行融合，

    

    融合模型广泛应用于解决多模态任务，但在不同模态之间数据分布对齐方面存在明显局限性。针对这一挑战，我们提出了一种创新模型称为基于上下文的多模态融合（CBMF），结合了模态融合和数据分布对齐，通过特定上下文向量表示每个模态，并将其与每个模态的嵌入进行融合。

    arXiv:2403.04650v1 Announce Type: cross  Abstract: The fusion models, which effectively combine information from different sources, are widely used in solving multimodal tasks. However, they have significant limitations related to aligning data distributions across different modalities. This challenge can lead to inconsistencies and difficulties in learning robust representations. Alignment models, while specifically addressing this issue, often require training "from scratch" with large datasets to achieve optimal results, which can be costly in terms of resources and time. To overcome these limitations, we propose an innovative model called Context-Based Multimodal Fusion (CBMF), which combines both modality fusion and data distribution alignment. In CBMF, each modality is represented by a specific context vector, fused with the embedding of each modality. This enables the use of large pre-trained models that can be frozen, reducing the computational and training data requirements. A
    
[^103]: Pix2Gif：基于运动引导扩散的GIF生成模型

    Pix2Gif: Motion-Guided Diffusion for GIF Generation

    [https://arxiv.org/abs/2403.04634](https://arxiv.org/abs/2403.04634)

    提出了Pix2Gif，一种基于运动引导的扩散模型，通过图像转换问题来实现图像到GIF的生成，引入了新的运动引导变形模块和感知损失以确保模型遵循运动引导并保持内容一致性和连贯性。

    

    我们提出了Pix2Gif，这是一个基于运动引导的扩散模型，用于图像到GIF（视频）的生成。我们通过将任务构建为由文本和运动大小提示指导的图像转换问题来不同地解决这一问题，如teaser fig所示。为了确保模型遵循运动引导，我们提出了一个新的运动引导变形模块，以在两种类型的提示条件下空间变换源图像的特征。此外，我们引入了一个感知损失，以确保转换的特征图保持在与目标图像相同的空间中，确保内容一致性和连贯性。为了为模型训练做准备，我们通过从TGIF视频字幕数据集中提取连贯的图像帧来精心筛选数据，该数据集提供了有关主题的时间变化丰富信息。在预训练之后，我们以零射样的方式将我们的模型应用于多个视频数据集。

    arXiv:2403.04634v1 Announce Type: cross  Abstract: We present Pix2Gif, a motion-guided diffusion model for image-to-GIF (video) generation. We tackle this problem differently by formulating the task as an image translation problem steered by text and motion magnitude prompts, as shown in teaser fig. To ensure that the model adheres to motion guidance, we propose a new motion-guided warping module to spatially transform the features of the source image conditioned on the two types of prompts. Furthermore, we introduce a perceptual loss to ensure the transformed feature map remains within the same space as the target image, ensuring content consistency and coherence. In preparation for the model training, we meticulously curated data by extracting coherent image frames from the TGIF video-caption dataset, which provides rich information about the temporal changes of subjects. After pretraining, we apply our model in a zero-shot manner to a number of video datasets. Extensive qualitative 
    
[^104]: 用Shapley值解释贝叶斯优化促进人工智能与人类协作

    Explaining Bayesian Optimization by Shapley Values Facilitates Human-AI Collaboration

    [https://arxiv.org/abs/2403.04629](https://arxiv.org/abs/2403.04629)

    提出了ShapleyBO框架，用Shapley值解释贝叶斯优化提议，量化每个参数对于优化过程的贡献，并能够区分不同类型的不确定性探索贡献。

    

    贝叶斯优化（BO）与高斯过程（GP）已成为解决黑匣子优化问题的不可或缺的算法。然而，BO本身也常常被认为是一个黑匣子，缺乏提供为何提议评估某些参数的理由的方法。我们通过提出ShapleyBO来解决这个问题，这是一个用博弈论Shapley值解释BO提议的框架。它量化了每个参数对BO的收获函数的贡献。利用Shapley值的线性性，我们能够进一步确定每个参数对于像置信边界这样的加法收获函数推动BO的探索和开发的强度。我们还展示了ShapleyBO能够解决探索对于勘探aleatoric和认识epistemic不确定性的贡献。

    arXiv:2403.04629v1 Announce Type: cross  Abstract: Bayesian optimization (BO) with Gaussian processes (GP) has become an indispensable algorithm for black box optimization problems. Not without a dash of irony, BO is often considered a black box itself, lacking ways to provide reasons as to why certain parameters are proposed to be evaluated. This is particularly relevant in human-in-the-loop applications of BO, such as in robotics. We address this issue by proposing ShapleyBO, a framework for interpreting BO's proposals by game-theoretic Shapley values.They quantify each parameter's contribution to BO's acquisition function. Exploiting the linearity of Shapley values, we are further able to identify how strongly each parameter drives BO's exploration and exploitation for additive acquisition functions like the confidence bound. We also show that ShapleyBO can disentangle the contributions to exploration into those that explore aleatoric and epistemic uncertainty. Moreover, our method 
    
[^105]: 大型语言模型能理解多目标口语语言吗？

    Do Large Language Model Understand Multi-Intent Spoken Language ?

    [https://arxiv.org/abs/2403.04481](https://arxiv.org/abs/2403.04481)

    该研究利用大型语言模型进行口语语言多目标理解，提出了改进实体槽和子目标指令的创新技术，并展示了LLMs在多目标SLU模型方面的潜力。

    

    这项研究通过利用大型语言模型（LLMs）进行多目标口语语言理解（SLU）取得了重大进展，提出了一种在SLU环境中利用LLMs生成能力的独特方法。我们的创新技术重新配置了实体槽，专门用于LLMs在多目标SLU环境中的应用，并引入了子目标指令（SII）的概念，增强了对不同领域内复杂多目标交流的解剖和解释。由此产生的数据集，被称为LM-MixATIS和LM-MixSNIPS，是从现有基准中精心制作的。我们的研究表明，LLMs可以匹配并潜在地超越当前最先进的多目标SLU模型的能力。它进一步探讨了LLMs在各种意图配置和数据集比例下的有效性。此外，我们介绍了两个开创性的度量标准，即实体槽准确性（ESA）和Com

    arXiv:2403.04481v1 Announce Type: cross  Abstract: This study marks a significant advancement by harnessing Large Language Models (LLMs) for multi-intent spoken language understanding (SLU), proposing a unique methodology that capitalizes on the generative power of LLMs within an SLU context. Our innovative technique reconfigures entity slots specifically for LLM application in multi-intent SLU environments and introduces the concept of Sub-Intent Instruction (SII), enhancing the dissection and interpretation of intricate, multi-intent communication within varied domains. The resultant datasets, dubbed LM-MixATIS and LM-MixSNIPS, are crafted from pre-existing benchmarks. Our research illustrates that LLMs can match and potentially excel beyond the capabilities of current state-of-the-art multi-intent SLU models. It further explores LLM efficacy across various intent configurations and dataset proportions. Moreover, we introduce two pioneering metrics, Entity Slot Accuracy (ESA) and Com
    
[^106]: 异质学习代理群体中道德行为动态

    Dynamics of Moral Behavior in Heterogeneous Populations of Learning Agents

    [https://arxiv.org/abs/2403.04202](https://arxiv.org/abs/2403.04202)

    在多代理环境中，研究人员探讨了不同道德类型的学习代理之间的互动，发现道德异质性可能对代理的共同发展产生影响。

    

    arXiv:2403.04202v1 公告类型：交叉领域 摘要：日益关注AI系统安全和对齐性的问题突显了在人工代理中嵌入道德能力的重要性。一种有前途的解决方案是利用经验学习，即强化学习。在多代理（社会）环境中，个体学习代理之间的交互可能产生复杂的群体层面现象。许多现有研究依赖于模拟的社会困境环境来研究独立学习代理的互动。然而，它们往往忽视了实践中代理社会中可能存在的道德异质性。例如，在不同时间点，单个学习代理可能面对后果主义者（即关心随时间最大化某种结果）或基于规范的对手（即专注于立即遵守特定规范） 。代理的共同发展在多大程度上可能受到这种道德异质性的影响。

    arXiv:2403.04202v1 Announce Type: cross  Abstract: Growing concerns about safety and alignment of AI systems highlight the importance of embedding moral capabilities in artificial agents. A promising solution is the use of learning from experience, i.e., Reinforcement Learning. In multi-agent (social) environments, complex population-level phenomena may emerge from interactions between individual learning agents. Many of the existing studies rely on simulated social dilemma environments to study the interactions of independent learning agents. However, they tend to ignore the moral heterogeneity that is likely to be present in societies of agents in practice. For example, at different points in time a single learning agent may face opponents who are consequentialist (i.e., caring about maximizing some outcome over time) or norm-based (i.e., focusing on conforming to a specific norm here and now). The extent to which agents' co-development may be impacted by such moral heterogeneity in 
    
[^107]: DNAct：扩散引导的多任务3D策略学习

    DNAct: Diffusion Guided Multi-Task 3D Policy Learning

    [https://arxiv.org/abs/2403.04115](https://arxiv.org/abs/2403.04115)

    本文提出了DNAct框架，结合神经渲染和扩散训练，实现在动作序列空间中的多模态学习，可应用于挑战性机器人任务，同时通过扩散过程实现多任务动作序列的重构。

    

    本文提出了DNAct，这是一个以语言为条件的多任务策略框架，它整合了神经渲染预训练和扩散训练，以在动作序列空间中实现多模态学习。DNAct的预训练阶段利用神经渲染从诸如Stable Diffusion之类的基础模型中提取2D语义特征到3D空间，从而提供了关于场景的全面语义理解。这使得可以应用于需要丰富的3D语义和准确几何的挑战性机器人任务。此外，我们介绍了一种利用扩散训练来学习包含多任务演示中固有多模态的视觉和语言特征的新方法。通过扩散过程从不同任务的动作序列重构，该模型能够区分。

    arXiv:2403.04115v1 Announce Type: cross  Abstract: This paper presents DNAct, a language-conditioned multi-task policy framework that integrates neural rendering pre-training and diffusion training to enforce multi-modality learning in action sequence spaces. To learn a generalizable multi-task policy with few demonstrations, the pre-training phase of DNAct leverages neural rendering to distill 2D semantic features from foundation models such as Stable Diffusion to a 3D space, which provides a comprehensive semantic understanding regarding the scene. Consequently, it allows various applications to challenging robotic tasks requiring rich 3D semantics and accurate geometry. Furthermore, we introduce a novel approach utilizing diffusion training to learn a vision and language feature that encapsulates the inherent multi-modality in the multi-task demonstrations. By reconstructing the action sequences from different tasks via the diffusion process, the model is capable of distinguishing d
    
[^108]: MolNexTR：一种用于分子图像识别的通用深度学习模型

    MolNexTR: A Generalized Deep Learning Model for Molecular Image Recognition

    [https://arxiv.org/abs/2403.03691](https://arxiv.org/abs/2403.03691)

    MolNexTR是一种用于分子图像识别的通用深度学习模型，能够更细致提取分子图像的局部和全局特征，同时能够预测原子和键，理解布局规则，灵活整合符号化的化学原则，并且包含多种先进算法。

    

    在化学结构识别领域，将分子图像转换为图结构和SMILES字符串的任务是一个重要挑战，主要是由于化学文献中流行的各种绘图风格和约定。为了弥合这一差距，我们提出了MolNexTR，一种新颖的图像到图结构的深度学习模型，它合并了ConvNext和Vision-TRansformer的优势，实现了对分子图像中的局部和全局特征的更细致提取。MolNexTR可以同时预测原子和键，并理解它们的布局规则。它还擅长灵活地将符号化的化学原则融入其中，以识别手性并解析缩写结构。我们进一步整合了一系列先进算法，包括改进的数据增强模块、图像污染模块和后处理模块。

    arXiv:2403.03691v1 Announce Type: cross  Abstract: In the field of chemical structure recognition, the task of converting molecular images into graph structures and SMILES string stands as a significant challenge, primarily due to the varied drawing styles and conventions prevalent in chemical literature. To bridge this gap, we proposed MolNexTR, a novel image-to-graph deep learning model that collaborates to fuse the strengths of ConvNext, a powerful Convolutional Neural Network variant, and Vision-TRansformer. This integration facilitates a more nuanced extraction of both local and global features from molecular images. MolNexTR can predict atoms and bonds simultaneously and understand their layout rules. It also excels at flexibly integrating symbolic chemistry principles to discern chirality and decipher abbreviated structures. We further incorporate a series of advanced algorithms, including improved data augmentation module, image contamination module, and a post-processing modul
    
[^109]: SplAgger：用于元强化学习的分割聚合

    SplAgger: Split Aggregation for Meta-Reinforcement Learning

    [https://arxiv.org/abs/2403.03020](https://arxiv.org/abs/2403.03020)

    本文展示了任务推断序列模型在元强化学习中的益处。

    

    强化学习的一个核心目标是创建能快速学习新任务的智能体。元强化学习旨在通过直接学习这些智能体来实现这一目标。一类元强化学习方法被称为黑盒方法，通过端到端训练现成的序列模型来实现这一目标。与之形成对比的是另一类方法，它们明确地推断出未知任务的后验分布。这些方法通常具有不同的目标和序列模型，旨在实现任务推断，因此被称为任务推断方法。本文提出了强有力的证据，证明任务推断序列模型仍然具有益处。

    arXiv:2403.03020v1 Announce Type: cross  Abstract: A core ambition of reinforcement learning (RL) is the creation of agents capable of rapid learning in novel tasks. Meta-RL aims to achieve this by directly learning such agents. One category of meta-RL methods, called black box methods, does so by training off-the-shelf sequence models end-to-end. In contrast, another category of methods have been developed that explicitly infer a posterior distribution over the unknown task. These methods generally have distinct objectives and sequence models designed to enable task inference, and so are known as task inference methods. However, recent evidence suggests that task inference objectives are unnecessary in practice. Nonetheless, it remains unclear whether task inference sequence models are beneficial even when task inference objectives are not. In this paper, we present strong evidence that task inference sequence models are still beneficial. In particular, we investigate sequence models 
    
[^110]: Wukong: 迈向大规模推荐的标度律

    Wukong: Towards a Scaling Law for Large-Scale Recommendation

    [https://arxiv.org/abs/2403.02545](https://arxiv.org/abs/2403.02545)

    Wukong通过堆叠因子分解机和协同增长策略，在推荐领域建立了一个标度律，并在质量上优于现有模型。

    

    缩放定律在提高模型质量方面起着关键作用。然而，迄今为止的推荐模型并没有展现出类似于大型语言模型领域观察到的定律，这是由于它们的升级机制的低效性。本文提出了一种基于纯堆叠因子分解机和协同增长策略的有效网络架构，统称为Wukong，以在推荐领域建立一个标度律。Wukong的独特设计使其能够通过更高更宽的层次简单捕获各种任意阶的交互。我们在六个公共数据集上进行了广泛评估，结果表明，与最先进的模型相比，Wukong在质量方面始终表现优越。此外，我们评估了Wuko

    arXiv:2403.02545v1 Announce Type: cross  Abstract: Scaling laws play an instrumental role in the sustainable improvement in model quality. Unfortunately, recommendation models to date do not exhibit such laws similar to those observed in the domain of large language models, due to the inefficiencies of their upscaling mechanisms. This limitation poses significant challenges in adapting these models to increasingly more complex real-world datasets. In this paper, we propose an effective network architecture based purely on stacked factorization machines, and a synergistic upscaling strategy, collectively dubbed Wukong, to establish a scaling law in the domain of recommendation. Wukong's unique design makes it possible to capture diverse, any-order of interactions simply through taller and wider layers. We conducted extensive evaluations on six public datasets, and our results demonstrate that Wukong consistently outperforms state-of-the-art models quality-wise. Further, we assessed Wuko
    
[^111]: 位置论文：面向文本到图像模型的隐式提示

    Position Paper: Towards Implicit Prompt For Text-To-Image Models

    [https://arxiv.org/abs/2403.02118](https://arxiv.org/abs/2403.02118)

    该位置论文讨论了文本到图像模型在隐式提示方面的现状，提出了名为ImplicitBench的新基准，并对 T2I 模型在隐式提示下的表现及影响进行了调查。

    

    近期文本到图像（T2I）模型取得了巨大成功，并提出了许多基准来评估它们的性能和安全性。然而，它们只考虑了显式提示，而忽略了隐式提示（暗示目标而不明确提到）。这些提示可能消除安全约束，并对这些模型的应用构成潜在威胁。本文介绍了当下T2I模型朝着隐式提示的现状。我们提出了一个名为ImplicitBench的基准，并对流行的T2I模型在隐式提示下的性能和影响进行了调查。具体来说，我们设计并收集了三个方面的超过2,000个隐式提示：通用符号、名人隐私和不安全的问题，并评估了六个知名T2I模型在这些隐式提示下的能力。实验结果显示，（1）T2I模型能够准确地创建各种目标。

    arXiv:2403.02118v1 Announce Type: cross  Abstract: Recent text-to-image (T2I) models have had great success, and many benchmarks have been proposed to evaluate their performance and safety. However, they only consider explicit prompts while neglecting implicit prompts (hint at a target without explicitly mentioning it). These prompts may get rid of safety constraints and pose potential threats to the applications of these models. This position paper highlights the current state of T2I models toward implicit prompts. We present a benchmark named ImplicitBench and conduct an investigation on the performance and impacts of implicit prompts with popular T2I models. Specifically, we design and collect more than 2,000 implicit prompts of three aspects: General Symbols, Celebrity Privacy, and Not-Safe-For-Work (NSFW) Issues, and evaluate six well-known T2I models' capabilities under these implicit prompts. Experiment results show that (1) T2I models are able to accurately create various targe
    
[^112]: ComTraQ-MPC：元训练的DQN-MPC集成用于具有有限主动定位更新的轨迹跟踪

    ComTraQ-MPC: Meta-Trained DQN-MPC Integration for Trajectory Tracking with Limited Active Localization Updates

    [https://arxiv.org/abs/2403.01564](https://arxiv.org/abs/2403.01564)

    ComTraQ-MPC是一个结合了DQN和MPC的新框架，旨在优化在有限主动定位更新下的轨迹跟踪。

    

    在局部可观察、随机环境中进行轨迹跟踪的最佳决策往往面临着一个重要挑战，即主动定位更新数量有限，这是指代理从传感器获取真实状态信息的过程。传统方法往往难以平衡资源保存、准确状态估计和精确跟踪之间的关系，导致性能次优。本文介绍了ComTraQ-MPC，这是一个结合了Deep Q-Networks (DQN)和模型预测控制(MPC)的新颖框架，旨在优化有限主动定位更新下的轨迹跟踪。元训练的DQN确保了自适应主动定位调度，同时

    arXiv:2403.01564v1 Announce Type: cross  Abstract: Optimal decision-making for trajectory tracking in partially observable, stochastic environments where the number of active localization updates -- the process by which the agent obtains its true state information from the sensors -- are limited, presents a significant challenge. Traditional methods often struggle to balance resource conservation, accurate state estimation and precise tracking, resulting in suboptimal performance. This problem is particularly pronounced in environments with large action spaces, where the need for frequent, accurate state data is paramount, yet the capacity for active localization updates is restricted by external limitations. This paper introduces ComTraQ-MPC, a novel framework that combines Deep Q-Networks (DQN) and Model Predictive Control (MPC) to optimize trajectory tracking with constrained active localization updates. The meta-trained DQN ensures adaptive active localization scheduling, while the
    
[^113]: CLLMs: 一致性大型语言模型

    CLLMs: Consistency Large Language Models

    [https://arxiv.org/abs/2403.00835](https://arxiv.org/abs/2403.00835)

    提出了一种新方法，通过精细调整目标LLM实现了对雅各比轨迹上固定点的一致性预测，有效提高了生成速度2.4倍到3.4倍。

    

    并行解码方法，如雅可比解码，显示出有望实现更高效的LLM推断，因为它打破了LLM解码过程的顺序性，并将其转换为可并行化计算。然而，在实践中，与传统的自回归（AR）解码相比，雅可比解码很少能在单个固定点迭代步骤中准确预测多个标记，因此在速度上取得的提升相对较小。为了解决这个问题，我们开发了一种新方法，旨在实现从任何状态快速收敛到雅各比轨迹上的固定点。通过精细调整目标LLM，以便在任何输入状态下一致地预测固定点。大量实验证明了我们方法的有效性，在领域特定和开放域基准测试中显示出生成速度提高了2.4倍到3.4倍，同时保持了生成质量。

    arXiv:2403.00835v1 Announce Type: cross  Abstract: Parallel decoding methods such as Jacobi decoding show promise for more efficient LLM inference as it breaks the sequential nature of the LLM decoding process and transforms it into parallelizable computation. However, in practice, it achieves little speedup compared to traditional autoregressive (AR) decoding, primarily because Jacobi decoding seldom accurately predicts more than one token in a single fixed-point iteration step. To address this, we develop a new approach aimed at realizing fast convergence from any state to the fixed point on a Jacobi trajectory. This is accomplished by refining the target LLM to consistently predict the fixed point given any state as input. Extensive experiments demonstrate the effectiveness of our method, showing 2.4$\times$ to 3.4$\times$ improvements in generation speed while preserving generation quality across both domain-specific and open-domain benchmarks.
    
[^114]: 通过离线技能扩散实现稳健策略学习

    Robust Policy Learning via Offline Skill Diffusion

    [https://arxiv.org/abs/2403.00225](https://arxiv.org/abs/2403.00225)

    提出了一种新颖的离线技能学习框架DuSkill，通过引导扩散模型生成通用技能，从而增强不同领域任务的策略学习鲁棒性。

    

    基于技能的强化学习方法在解决长时域任务中表现出了相当大的潜力，尤其是通过分层结构。这些技能是从离线数据集中无关任务地学习的，可以加快针对新任务的策略学习过程。然而，由于这些技能在不同领域中的应用仍受限于对数据集的固有依赖，当尝试通过强化学习为不同于数据集领域的目标领域学习基于技能的策略时，这一挑战就变得困难。在本文中，我们提出了一个新颖的离线技能学习框架DuSkill，它采用了引导扩散模型来生成从数据集中有限技能扩展出的通用技能，从而增强了不同领域任务的策略学习鲁棒性。具体来说，我们设计了一个引导扩散技能解码器，结合分层编码，以解开技能嵌入。

    arXiv:2403.00225v1 Announce Type: new  Abstract: Skill-based reinforcement learning (RL) approaches have shown considerable promise, especially in solving long-horizon tasks via hierarchical structures. These skills, learned task-agnostically from offline datasets, can accelerate the policy learning process for new tasks. Yet, the application of these skills in different domains remains restricted due to their inherent dependency on the datasets, which poses a challenge when attempting to learn a skill-based policy via RL for a target domain different from the datasets' domains. In this paper, we present a novel offline skill learning framework DuSkill which employs a guided Diffusion model to generate versatile skills extended from the limited skills in datasets, thereby enhancing the robustness of policy learning for tasks in different domains. Specifically, we devise a guided diffusion-based skill decoder in conjunction with the hierarchical encoding to disentangle the skill embeddi
    
[^115]: 光谱遇见空间: 和谐3D形状匹配和插值

    Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation

    [https://arxiv.org/abs/2402.18920](https://arxiv.org/abs/2402.18920)

    该研究提出了一个统一的框架，结合光谱和空间域的映射，以预测3D形状之间的点对应和形状插值，相比先前方法，取得更准确、平滑的点对应结果，并且在计算上更高效。

    

    虽然3D形状匹配和插值密切相关，但它们经常被分开研究并依次应用于关联不同的3D形状，从而导致性能不佳。在这项工作中，我们提出了一个统一的框架，用于预测3D形状之间的点对应和形状插值。为此，我们将深度功能映射框架与经典表面变形模型结合起来，以在光谱和空间域中映射形状。一方面，通过整合空间映射，我们的方法相对于先前用于形状匹配的功能映射方法获得更精确和平滑的点对应。另一方面，通过引入光谱映射，我们的方法摆脱了通常使用但计算昂贵的仅对近等距形状变形有效的测地距离约束。

    arXiv:2402.18920v1 Announce Type: cross  Abstract: Although 3D shape matching and interpolation are highly interrelated, they are often studied separately and applied sequentially to relate different 3D shapes, thus resulting in sub-optimal performance. In this work we present a unified framework to predict both point-wise correspondences and shape interpolation between 3D shapes. To this end, we combine the deep functional map framework with classical surface deformation models to map shapes in both spectral and spatial domains. On the one hand, by incorporating spatial maps, our method obtains more accurate and smooth point-wise correspondences compared to previous functional map methods for shape matching. On the other hand, by introducing spectral maps, our method gets rid of commonly used but computationally expensive geodesic distance constraints that are only valid for near-isometric shape deformations. Furthermore, we propose a novel test-time adaptation scheme to capture both 
    
[^116]: 使用条件解码器增强视频的神经表示

    Boosting Neural Representations for Videos with a Conditional Decoder

    [https://arxiv.org/abs/2402.18152](https://arxiv.org/abs/2402.18152)

    引入条件解码器和NeRV-like模块的增强框架，以提高隐式视频表示方法的效果。

    

    隐式神经表示（INRs）已经成为视频存储和处理的一种有前途的方法，在各种视频任务中展现出显著的多功能性。然而，由于目标帧解码过程中中间特征的不足对齐，现有方法往往未能充分利用其表示能力。本文引入了一个通用的增强框架来加强当前的隐式视频表示方法。具体来说，我们利用具有时间感知仿射变换模块的条件解码器，该模块使用帧索引作为先验条件，有效地将中间特征与目标帧对齐。此外，我们引入了一个正弦NeRV-like模块来生成多样化的中间特征，并实现更平衡的参数分布，从而增强了模型的容量。借助高频信息保留的重构损失，我们的方法成功地增强了m

    arXiv:2402.18152v1 Announce Type: cross  Abstract: Implicit neural representations (INRs) have emerged as a promising approach for video storage and processing, showing remarkable versatility across various video tasks. However, existing methods often fail to fully leverage their representation capabilities, primarily due to inadequate alignment of intermediate features during target frame decoding. This paper introduces a universal boosting framework for current implicit video representation approaches. Specifically, we utilize a conditional decoder with a temporal-aware affine transform module, which uses the frame index as a prior condition to effectively align intermediate features with target frames. Besides, we introduce a sinusoidal NeRV-like block to generate diverse intermediate features and achieve a more balanced parameter distribution, thereby enhancing the model's capacity. With a high-frequency information-preserving reconstruction loss, our approach successfully boosts m
    
[^117]: REPrune：通过核代表选择进行通道修剪

    REPrune: Channel Pruning via Kernel Representative Selection

    [https://arxiv.org/abs/2402.17862](https://arxiv.org/abs/2402.17862)

    REPrune是一种新颖的通道修剪技术，通过模拟核修剪，并结合聚类和滤波器选择，实现了更精细但结构化的修剪粒度，促进了在训练CNNs期间的高效、渐进式修剪。

    

    通道修剪被广泛认可为加速现代卷积神经网络（CNNs）的方法。所得到的修剪模型可以立即部署在通用软件和硬件资源上。然而，由于在卷积滤波器这个单元上的大修剪粒度，通常会导致不希望的准确性下降，这是由于在CNNs中决定如何以及在何处引入稀疏性的灵活性不足。在本文中，我们提出了REPrune，一种新颖的通道修剪技术，模拟了核修剪，充分利用了更细但有结构的粒度。REPrune使用凝聚聚类识别每个通道内的相似核。然后，它选择最大化包含核代表的滤波器，同时优化最大聚类覆盖问题。通过与同时训练-修剪范式相结合，REPrune促进了在训练CNNs期间的高效、渐进式修剪，避免了在训练期间的误差传播。

    arXiv:2402.17862v1 Announce Type: cross  Abstract: Channel pruning is widely accepted to accelerate modern convolutional neural networks (CNNs). The resulting pruned model benefits from its immediate deployment on general-purpose software and hardware resources. However, its large pruning granularity, specifically at the unit of a convolution filter, often leads to undesirable accuracy drops due to the inflexibility of deciding how and where to introduce sparsity to the CNNs. In this paper, we propose REPrune, a novel channel pruning technique that emulates kernel pruning, fully exploiting the finer but structured granularity. REPrune identifies similar kernels within each channel using agglomerative clustering. Then, it selects filters that maximize the incorporation of kernel representatives while optimizing the maximum cluster coverage problem. By integrating with a simultaneous training-pruning paradigm, REPrune promotes efficient, progressive pruning throughout training CNNs, avoi
    
[^118]: 利用苏木精与伊红染色整张图像进行胶质瘤诊断的多实例学习：印度队列研究

    Multiple Instance Learning for Glioma Diagnosis using Hematoxylin and Eosin Whole Slide Images: An Indian cohort Study

    [https://arxiv.org/abs/2402.15832](https://arxiv.org/abs/2402.15832)

    本研究通过多实例学习在脑肿瘤组织病理学中取得新突破，建立了印度胶质瘤亚型分类性能基准，同时实现了新的评级和检测生物标志物的基准。

    

    脑肿瘤代表一种严重且危及生命的疾病，需要精确的诊断和量身定制的治疗策略。本研究通过对脑肿瘤组织病理学中严格的多实例学习实验的发现，推动了患者护理。它在胶质瘤亚型分类方面建立了新的性能基准，跨多个数据集，包括一个专注于印度人口的新数据集（IPD-Brain），为现有研究提供了宝贵的资源。使用在组织病理学数据集上预训练的ResNet-50进行特征提取，结合DTFD特征聚合器，我们的方法分别在IPD-Brain和TCGA-Brain数据集上实现了三分胶质瘤亚型分类的最新AUC（分别为88.08和95.81）。此外，它在评级和检测IHC分子生物标志物（IDH1（突变 R132H）、TP53、ATRX、Ki-67）方面建立了新的基准。

    arXiv:2402.15832v1 Announce Type: cross  Abstract: Brain tumors represent a severe and life-threatening condition, demanding precise diagnosis and tailored treatment strategies. This study advances patient care with findings from rigorous multiple-instance-learning experimentations across various feature extractors and aggregators in brain tumor histopathology. It establishes new performance benchmarks in glioma subtype classification across multiple datasets, including a novel dataset focused on the Indian demographic (IPD-Brain), providing a valuable resource for existing research. Using a ResNet-50, pretrained on histopathology datasets, for feature extraction, combined with DTFD feature aggregator, our approach achieves state-of-the-art AUCs of 88.08 on IPD-Brain and 95.81 on TCGA-Brain dataset respectively for three-way glioma subtype classification. Moreover, it establishes new benchmarks in grading and detecting IHC molecular biomarkers (IDH1 (mutant R132H), TP53, ATRX, Ki-67) t
    
[^119]: LLMBind: 一种统一的模态任务集成框架

    LLMBind: A Unified Modality-Task Integration Framework

    [https://arxiv.org/abs/2402.14891](https://arxiv.org/abs/2402.14891)

    提出了LLMBind，一种统一的模态任务集成框架，通过将大型语言模型和预训练任务模型绑定在一起，实现了多种模态任务的灵活输入和输出组合。

    

    最近对于多模态大型语言模型在处理各种模态任务方面取得了进展，但它们对于复杂的多模态任务的集成能力有限，从而限制了该领域的发展。在这项工作中，我们带头探索并提出了LLMBind，一种用于模态任务集成的统一框架，该框架将大型语言模型和相应的预训练任务模型与任务特定的标记绑定在一起。因此，LLMBind可以以多种图像、文本、视频和音频的组合解释输入并生成输出。具体来说，我们引入了一种专家混合技术，通过不同专家之间的协作实现不同多模态任务的有效学习。此外，我们创建了一个包含40万条指令数据的多任务数据集，解锁了交互式视觉生成和编辑任务的能力。大量实验证明了我们的方法的有效性。

    arXiv:2402.14891v1 Announce Type: cross  Abstract: While recent progress in multimodal large language models tackles various modality tasks, they posses limited integration capabilities for complex multi-modality tasks, consequently constraining the development of the field. In this work, we take the initiative to explore and propose the LLMBind, a unified framework for modality task integration, which binds Large Language Models and corresponding pre-trained task models with task-specific tokens. Consequently, LLMBind can interpret inputs and produce outputs in versatile combinations of image, text, video, and audio. Specifically, we introduce a Mixture-of-Experts technique to enable effective learning for different multimodal tasks through collaboration among diverse experts. Furthermore, we create a multi-task dataset comprising 400k instruction data, which unlocks the ability for interactive visual generation and editing tasks. Extensive experiments show the effectiveness of our fr
    
[^120]: CriticBench：为批判性-正确推理评估LLMs而设计的基准测试

    CriticBench: Benchmarking LLMs for Critique-Correct Reasoning

    [https://arxiv.org/abs/2402.14809](https://arxiv.org/abs/2402.14809)

    CriticBench是一个综合基准测试，旨在评估LLMs在批判和纠正推理方面的能力，发现批判性训练显著提升性能，逻辑任务更易于修正。

    

    大型语言模型（LLMs）批判和完善其推理的能力对于它们在评估、反馈提供和自我改进中的应用至关重要。本文引入了CriticBench，一个旨在评估LLMs在各种任务中批判和纠正其推理能力的综合基准测试。CriticBench包含五个推理领域：数学、常识、符号、编码和算法。它整合了15个数据集，并结合了三个LLM系列的响应。利用CriticBench，我们评估和剖析了17个LLMs在生成、批判和修正推理（即GQC推理）中的表现。我们的研究结果显示：（1）GQC能力呈线性关系，批判性训练显著提升了性能；（2）修正效果在任务上有所不同，以逻辑为导向的任务更容易修正；（3）GQC知识的不一致性。

    arXiv:2402.14809v1 Announce Type: cross  Abstract: The ability of Large Language Models (LLMs) to critique and refine their reasoning is crucial for their application in evaluation, feedback provision, and self-improvement. This paper introduces CriticBench, a comprehensive benchmark designed to assess LLMs' abilities to critique and rectify their reasoning across a variety of tasks. CriticBench encompasses five reasoning domains: mathematical, commonsense, symbolic, coding, and algorithmic. It compiles 15 datasets and incorporates responses from three LLM families. Utilizing CriticBench, we evaluate and dissect the performance of 17 LLMs in generation, critique, and correction reasoning, i.e., GQC reasoning. Our findings reveal: (1) a linear relationship in GQC capabilities, with critique-focused training markedly enhancing performance; (2) a task-dependent variation in correction effectiveness, with logic-oriented tasks being more amenable to correction; (3) GQC knowledge inconsisten
    
[^121]: SaGE：评估大型语言模型的道德一致性

    SaGE: Evaluating Moral Consistency in Large Language Models

    [https://arxiv.org/abs/2402.13709](https://arxiv.org/abs/2402.13709)

    提出SaGE方法，通过语义图熵来衡量大型语言模型道德一致性，构建了MCC语料库。

    

    尽管最近展示出大型语言模型（LLMs）在会话系统中的印象深刻能力，但我们表明即使是最先进的LLMs在生成过程中也存在道德不一致，对其可靠性（以及总体可信赖性）提出了质疑。以往在LLM评估领域的工作侧重于开发地面真实数据，以衡量在特定任务上的准确性。然而，对于道德情景往往缺乏普遍认同答案的情况，模型响应的一致性对于其可靠性变得至关重要。为了解决这一问题，我们提出了一种信息理论度量方法，称为语义图熵（SaGE），基于“经验法则”（RoTs）的概念来衡量模型的道德一致性。RoTs是模型学习到的抽象原则，可有效帮助解释其决策策略。在此基础上，我们构建了道德一致性语料库（MCC），包含50K个道德问题、回答。

    arXiv:2402.13709v1 Announce Type: cross  Abstract: Despite recent advancements showcasing the impressive capabilities of Large Language Models (LLMs) in conversational systems, we show that even state-of-the-art LLMs are morally inconsistent in their generations, questioning their reliability (and trustworthiness in general). Prior works in LLM evaluation focus on developing ground-truth data to measure accuracy on specific tasks. However, for moral scenarios that often lack universally agreed-upon answers, consistency in model responses becomes crucial for their reliability. To address this issue, we propose an information-theoretic measure called Semantic Graph Entropy (SaGE), grounded in the concept of "Rules of Thumb" (RoTs) to measure a model's moral consistency. RoTs are abstract principles learned by a model and can help explain their decision-making strategies effectively. To this extent, we construct the Moral Consistency Corpus (MCC), containing 50K moral questions, responses
    
[^122]: 用大型语言模型增强贝叶斯优化

    Large Language Models to Enhance Bayesian Optimization

    [https://arxiv.org/abs/2402.03921](https://arxiv.org/abs/2402.03921)

    通过结合大型语言模型（LLM）的能力，我们提出了一种名为LLAMBO的新方法，将其应用于贝叶斯优化（BO）。通过用自然语言描述BO问题，并利用LLM的上下文理解、少样本学习能力和领域知识，LLAMBO能够提供有前景的解决方案，并且在零样本热启动方面表现出良好的效果。

    

    贝叶斯优化（BO）是一种优化复杂和昂贵的黑盒函数的强大方法。它在许多应用中的重要性得到了强调，特别是超参数调优，但其有效性取决于有效地平衡勘探和开发。尽管在BO方法方面取得了重大进展，但平衡这一问题仍然是一个微妙的过程。在这个背景下，我们提出了一个新方法LLAMBO，它将大型语言模型（LLM）的能力与BO相结合。在高层次上，我们用自然语言的方式来描述BO问题，使LLM能够根据历史评估提出有前景的解决方案。更具体地说，我们探讨了如何结合LLM的上下文理解、少样本学习能力和领域知识，来增强基于模型的BO的各个组成部分。我们的研究结果表明，LLAMBO在零样本热启动方面是有效的，并且可以改善代理模型的性能。

    Bayesian optimization (BO) is a powerful approach for optimizing complex and expensive-to-evaluate black-box functions. Its importance is underscored in many applications, notably including hyperparameter tuning, but its efficacy depends on efficiently balancing exploration and exploitation. While there has been substantial progress in BO methods, striking this balance still remains a delicate process. In this light, we present \texttt{LLAMBO}, a novel approach that integrates the capabilities of large language models (LLM) within BO. At a high level, we frame the BO problem in natural language terms, enabling LLMs to iteratively propose promising solutions conditioned on historical evaluations. More specifically, we explore how combining contextual understanding, few-shot learning proficiency, and domain knowledge of LLMs can enhance various components of model-based BO. Our findings illustrate that \texttt{LLAMBO} is effective at zero-shot warmstarting, and improves surrogate modelin
    
[^123]: 在大型语言模型上进行间接提示注入攻击的基准测试和防御

    Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models

    [https://arxiv.org/abs/2312.14197](https://arxiv.org/abs/2312.14197)

    该研究引入了第一个间接提示注入攻击基准测试BIPIA，对大型语言模型在面对此类攻击时的风险进行评估，并分析了攻击成功的原因，从而开发了防御方法。

    

    大型语言模型（LLMs）与外部内容的整合已经实现了LLMs的更新和广泛应用，比如微软Copilot。然而，这种整合也让LLMs面临了间接提示注入攻击的风险，攻击者可以在外部内容中嵌入恶意指令，从而ompromising LLM输出并导致响应偏离用户期望。为了研究这个重要但未被充分探讨的问题，我们引入了第一个间接提示注入攻击基准测试BIPIA，以评估这类攻击的风险。基于评估，我们的工作重点分析了该攻击成功的潜在原因，即LLMs无法区分指令和外部内容以及缺乏意识不执行外部内容内的指令。基于这一分析，我们开发了两种黑盒方法。

    arXiv:2312.14197v2 Announce Type: replace-cross  Abstract: The integration of large language models (LLMs) with external content has enabled more up-to-date and wide-ranging applications of LLMs, such as Microsoft Copilot. However, this integration has also exposed LLMs to the risk of indirect prompt injection attacks, where an attacker can embed malicious instructions within external content, compromising LLM output and causing responses to deviate from user expectations. To investigate this important but underexplored issue, we introduce the first benchmark for indirect prompt injection attacks, named BIPIA, to evaluate the risk of such attacks. Based on the evaluation, our work makes a key analysis of the underlying reason for the success of the attack, namely the inability of LLMs to distinguish between instructions and external content and the absence of LLMs' awareness to not execute instructions within external content. Building upon this analysis, we develop two black-box metho
    
[^124]: 一种基于任务反馈的动态剪裁方法用于近端策略优化

    A dynamical clipping approach with task feedback for Proximal Policy Optimization

    [https://arxiv.org/abs/2312.07624](https://arxiv.org/abs/2312.07624)

    提出了一种基于任务反馈的动态剪裁方法，通过增加最大累积回报来优化近端策略优化的性能。

    

    近端策略优化（PPO）已被广泛应用于各个领域，包括大型语言模型（LLM）优化和机器人学习等。然而，PPO受到固定剪裁边界的限制。具体而言，目前没有理论证明最佳剪裁边界在整个训练过程中始终保持一致。通过用一个独特的剪裁边界截断新旧策略的比率，可以确保稳定的训练并实现最佳的训练性能。此外，先前的研究表明，固定的剪裁边界限制了agent的探索。因此，研究一种动态剪裁边界以增强PPO的性能是非常有益的。与以往的剪裁方法不同，我们考虑将在强化学习（RL）任务中增加最大累积回报视作RL任务的偏好，并提出了一个双层近端策略优化范式。

    arXiv:2312.07624v2 Announce Type: replace-cross  Abstract: Proximal Policy Optimization (PPO) has been broadly applied to various domains, including Large Language Model (LLM) optimization and Robotics learning, etc. However, PPO is limited by a fixed setting for the clipping bound. Specifically, there is no theoretical proof that the optimal clipping bound remains consistent throughout the entire training process. Truncating the ratio of the new and old policies with a unique clipping bound ensures stable training and can achieve the best training performance. Additionally, previous research suggests that a fixed clipping bound limits the agent's exploration. Therefore, researching a dynamical clipping bound to enhance PPO's performance can be highly beneficial. Different from previous clipping approaches, we consider increasing the maximum cumulative Return in reinforcement learning (RL) tasks as the preference of the RL task, and propose a bi-level proximal policy optimization parad
    
[^125]: 探索大型语言模型以促进人机团队合作的可变自主性

    Exploring Large Language Models to Facilitate Variable Autonomy for Human-Robot Teaming

    [https://arxiv.org/abs/2312.07214](https://arxiv.org/abs/2312.07214)

    本文探讨了将大型语言模型集成到人机团队合作环境中，通过口头交流促进机器人的可变自主性，提出了基于GPT的多机器人测试台架环境，并进行了用户研究以验证其有效性和用户策略。

    

    在一个快速发展的数字化环境中，自主工具和机器人正变得司空见惯。鉴于这一发展的重要性，本文探讨了将大型语言模型（LLMs）如生成式预训练变压器（GPT）集成到人机团队合作环境中，通过口头人机交流手段促进可变自主性。我们在Unity虚拟现实（VR）环境中，基于GPT核心为动力的多机器人测试台架环境中引入了一个新颖的框架。该系统允许用户通过自然语言与机器人代理进行交互，每个代理都由独立的GPT核心提供动力。通过OpenAI的函数调用，我们弥合了不受结构约束的自然语言输入和结构化机器人动作之间的差距。一项涉及12名参与者的用户研究探讨了GPT-4的有效性，更重要的是，当给予机会进行自然对话时用户的策略。

    arXiv:2312.07214v2 Announce Type: replace-cross  Abstract: In a rapidly evolving digital landscape autonomous tools and robots are becoming commonplace. Recognizing the significance of this development, this paper explores the integration of Large Language Models (LLMs) like Generative pre-trained transformer (GPT) into human-robot teaming environments to facilitate variable autonomy through the means of verbal human-robot communication. In this paper, we introduce a novel framework for such a GPT-powered multi-robot testbed environment, based on a Unity Virtual Reality (VR) setting. This system allows users to interact with robot agents through natural language, each powered by individual GPT cores. By means of OpenAI's function calling, we bridge the gap between unstructured natural language input and structure robot actions. A user study with 12 participants explores the effectiveness of GPT-4 and, more importantly, user strategies when being given the opportunity to converse in nat
    
[^126]: 统一批归一化：识别和缓解批归一化中的特征凝聚及统一框架

    Unified Batch Normalization: Identifying and Alleviating the Feature Condensation in Batch Normalization and a Unified Framework

    [https://arxiv.org/abs/2311.15993](https://arxiv.org/abs/2311.15993)

    识别了批归一化中的特征凝聚问题，并提出了统一批归一化（UBN）框架来解决，从而改善测试性能。

    

    批归一化（BN）已经成为当代神经网络设计中的基本技术，增强了训练稳定性。具体地，BN采用居中和缩放操作来标准化沿批次维度的特征，并使用仿射变换来恢复特征。尽管标准的BN已经显示出改善深度神经网络训练和收敛的能力，但在某些情况下仍存在固有限制。目前对BN的增强通常只解决其机制的某些方面。在这项工作中，我们从特征的角度对BN进行了批判性的检查，将BN中的特征凝聚识别为对测试性能有害的因素。为了解决这一问题，我们提出了一个称为统一批归一化（UBN）的两阶段统一框架。在第一阶段，我们采用了一个直观的特征凝聚阈值来减轻凝聚效应，从而防止不当的升

    arXiv:2311.15993v2 Announce Type: replace-cross  Abstract: Batch Normalization (BN) has become an essential technique in contemporary neural network design, enhancing training stability. Specifically, BN employs centering and scaling operations to standardize features along the batch dimension and uses an affine transformation to recover features. Although standard BN has shown its capability to improve deep neural network training and convergence, it still exhibits inherent limitations in certain cases. Current enhancements to BN typically address only isolated aspects of its mechanism. In this work, we critically examine BN from a feature perspective, identifying feature condensation during BN as a detrimental factor to test performance. To tackle this problem, we propose a two-stage unified framework called Unified Batch Normalization (UBN). In the first stage, we employ a straightforward feature condensation threshold to mitigate condensation effects, thereby preventing improper up
    
[^127]: 面向人类白蛋白预测的超分布广义动态图神经网络

    Out-of-Distribution Generalized Dynamic Graph Neural Network for Human Albumin Prediction

    [https://arxiv.org/abs/2311.15545](https://arxiv.org/abs/2311.15545)

    提出了一种名为DyG-HAP的框架，利用超分布广义动态图神经网络进行人类白蛋白预测，特别适用于ICU患者。

    

    人类白蛋白对指示身体整体健康至关重要。准确预测血浆白蛋白水平并确定适当剂量是亟需解决的临床挑战，尤其是在危重患者中，以保持最佳血液水平。然而，人类白蛋白预测并不简单，必须利用生化标志物的动态性以及治疗患者的经验。此外，真实临床数据中经常遇到分布转移问题，这可能导致模型预测性能下降，降低模型应用的可靠性。在本文中，我们提出了一个名为Out-of-Distribution Generalized Dynamic Graph神经网络的框架，用于人类白蛋白预测（DyG-HAP），能够提供在住院期间为重症监护病房（ICU）患者提供准确的白蛋白预测。

    arXiv:2311.15545v2 Announce Type: replace-cross  Abstract: Human albumin is essential for indicating the body's overall health. Accurately predicting plasma albumin levels and determining appropriate doses are urgent clinical challenges, particularly in critically ill patients, to maintain optimal blood levels. However, human albumin prediction is non-trivial that has to leverage the dynamics of biochemical markers as well as the experience of treating patients. Moreover, the problem of distribution shift is often encountered in real clinical data, which may lead to a decline in the model prediction performance and reduce the reliability of the model's application. In this paper, we propose a framework named Out-of-Distribution Generalized Dynamic Graph Neural Network for Human Albumin Prediction (DyG-HAP), which is able to provide accurate albumin predictions for Intensity Care Unit (ICU) patients during hospitalization. We first model human albumin prediction as a dynamic graph regre
    
[^128]: LLM能遵守简单规则吗?

    Can LLMs Follow Simple Rules?

    [https://arxiv.org/abs/2311.04235](https://arxiv.org/abs/2311.04235)

    提出了一个名为RuLES的程序框架，用于衡量LLMs在与用户交互时遵守规则的能力。

    

    随着大型语言模型（LLMs）在现实世界中承担越来越多的责任，能够以可靠的方式指定和约束这些系统的行为变得至关重要。我们提出了规则遵循语言评估场景（RuLES），这是一个测量LLMs遵循规则能力的程序框架，包括14个简单的文本场景，模型在与用户交互时被指示遵守各种规则。

    arXiv:2311.04235v2 Announce Type: replace  Abstract: As Large Language Models (LLMs) are deployed with increasing real-world responsibilities, it is important to be able to specify and constrain the behavior of these systems in a reliable manner. Model developers may wish to set explicit rules for the model, such as "do not generate abusive content", but these may be circumvented by jailbreaking techniques. Existing evaluations of adversarial attacks and defenses on LLMs generally require either expensive manual review or unreliable heuristic checks. To address this issue, we propose Rule-following Language Evaluation Scenarios (RuLES), a programmatic framework for measuring rule-following ability in LLMs. RuLES consists of 14 simple text scenarios in which the model is instructed to obey various rules while interacting with the user. Each scenario has a programmatic evaluation function to determine whether the model has broken any rules in a conversation. Our evaluations of proprietar
    
[^129]: 具有部分可观测性的多视图因果表示学习

    Multi-View Causal Representation Learning with Partial Observability

    [https://arxiv.org/abs/2311.04056](https://arxiv.org/abs/2311.04056)

    我们提出了一个统一的框架，用于学习来自不同数据视图的因果关系表示，证明了跨视图子集的信息可以通过对比学习和单个编码器学习，同时提供了一个观测潜在变量的简单规则。

    

    我们提出了一个统一的框架，用于研究从同时观察到的视图（如不同数据模态）学习到的表示的可识别性。我们允许部分观测设置，其中每个视图构成底层潜在变量子集的非线性混合，这些变量可以存在因果关系。我们证明，通过对比学习和每个视图一个编码器，可以学习到跨所有任意数量视图子集共享的信息，直至平滑双射。我们还提供了图形标准，指示可以通过一组简单规则确定哪些潜在变量，我们称之为可识别性代数。我们的总体框架和理论结果统一并扩展了先前关于多视图非线性ICA、解缠以及因果表示学习的几项工作。我们在数字、图像和多模态数据集上通过实验证实了我们的论断。

    arXiv:2311.04056v2 Announce Type: replace-cross  Abstract: We present a unified framework for studying the identifiability of representations learned from simultaneously observed views, such as different data modalities. We allow a partially observed setting in which each view constitutes a nonlinear mixture of a subset of underlying latent variables, which can be causally related. We prove that the information shared across all subsets of any number of views can be learned up to a smooth bijection using contrastive learning and a single encoder per view. We also provide graphical criteria indicating which latent variables can be identified through a simple set of rules, which we refer to as identifiability algebra. Our general framework and theoretical results unify and extend several previous works on multi-view nonlinear ICA, disentanglement, and causal representation learning. We experimentally validate our claims on numerical, image, and multi-modal data sets. Further, we demonstr
    
[^130]: 可微学习广义结构化矩阵以实现高效深度神经网络

    Differentiable Learning of Generalized Structured Matrices for Efficient Deep Neural Networks

    [https://arxiv.org/abs/2310.18882](https://arxiv.org/abs/2310.18882)

    提出了一种可微的广义框架，通过梯度下降学习高效的权重矩阵结构。

    

    本文研究了有效的深度神经网络（DNNs），通过具有所需属性的结构化矩阵取代密集非结构化权重矩阵。我们提出了一个广义和可微的框架，通过梯度下降学习权重矩阵的高效结构。我们首先定义了一类新的结构化矩阵，通过调整结构参数覆盖了文献中广泛的结构化矩阵。然后，采用基于高斯-狄利克雷核的频域可微参数化方案来学习结构参数。

    arXiv:2310.18882v2 Announce Type: replace-cross  Abstract: This paper investigates efficient deep neural networks (DNNs) to replace dense unstructured weight matrices with structured ones that possess desired properties. The challenge arises because the optimal weight matrix structure in popular neural network models is obscure in most cases and may vary from layer to layer even in the same network. Prior structured matrices proposed for efficient DNNs were mostly hand-crafted without a generalized framework to systematically learn them. To address this issue, we propose a generalized and differentiable framework to learn efficient structures of weight matrices by gradient descent. We first define a new class of structured matrices that covers a wide range of structured matrices in the literature by adjusting the structural parameters. Then, the frequency-domain differentiable parameterization scheme based on the Gaussian-Dirichlet kernel is adopted to learn the structural parameters b
    
[^131]: ManyQuadrupeds: 学习适用于多样化四足机器人的单一运动策略

    ManyQuadrupeds: Learning a Single Locomotion Policy for Diverse Quadruped Robots

    [https://arxiv.org/abs/2310.10486](https://arxiv.org/abs/2310.10486)

    通过受动物运动控制的启发，我们展示出能够有效训练一个单一运动策略，可以控制多样化四足机器人。

    

    传统上，为四足机器人学习运动策略通常受限于特定的机器人形态、质量和尺寸。学习过程通常必须针对每台新机器人重复进行，需要重新调整超参数和奖励函数权重以最大化每个新系统的性能。另外，尝试训练一个单一策略以适应不同大小的机器人，同时保持相同的自由度（DoF）和形态，需要复杂的学习框架，或者质量、惯性和尺寸随机化，这导致训练时间延长。在我们的研究中，我们展示受动物运动控制的启发，可以有效地训练一个能够控制多样化四足机器人的单一运动策略。这些机器人的差异包括：可变数量的DoF（即12或16个关节）、三种不同的形态和从较低到较高质量范围的广泛质量跨度。

    arXiv:2310.10486v2 Announce Type: replace-cross  Abstract: Learning a locomotion policy for quadruped robots has traditionally been constrained to a specific robot morphology, mass, and size. The learning process must usually be repeated for every new robot, where hyperparameters and reward function weights must be re-tuned to maximize performance for each new system. Alternatively, attempting to train a single policy to accommodate different robot sizes, while maintaining the same degrees of freedom (DoF) and morphology, requires either complex learning frameworks, or mass, inertia, and dimension randomization, which leads to prolonged training periods. In our study, we show that drawing inspiration from animal motor control allows us to effectively train a single locomotion policy capable of controlling a diverse range of quadruped robots. The robot differences encompass: a variable number of DoFs, (i.e. 12 or 16 joints), three distinct morphologies, a broad mass range spanning from 
    
[^132]: TAIL: 任务特定的适配器用于具有大型预训练模型的模仿学习

    TAIL: Task-specific Adapters for Imitation Learning with Large Pretrained Models

    [https://arxiv.org/abs/2310.05905](https://arxiv.org/abs/2310.05905)

    TAIL提出了一种适配器框架，通过高效微调技术将大型预训练模型用于新的控制任务，以实现数据有效率、持续适应不同控制任务。

    

    大型预训练模型在控制领域（如机器人技术）中的潜力尚未得到充分利用，主要原因是数据稀缺以及为这些应用程序训练或微调这些大型模型所带来的计算挑战。我们介绍了TAIL（任务特定的适配器用于模仿学习），这是一个用于有效适应新控制任务的框架。受到语言领域参数高效微调的最新进展的启发，我们在TAIL中探讨了高效微调技术，例如瓶颈适配器、P调整和低秩适配（LoRA），以将大型预训练模型调整为具有有限演示数据的新任务。

    arXiv:2310.05905v2 Announce Type: replace-cross  Abstract: The full potential of large pretrained models remains largely untapped in control domains like robotics. This is mainly because of the scarcity of data and the computational challenges associated with training or fine-tuning these large models for such applications. Prior work mainly emphasizes either effective pretraining of large models for decision-making or single-task adaptation. But real-world problems will require data-efficient, continual adaptation for new control tasks. Recognizing these constraints, we introduce TAIL (Task-specific Adapters for Imitation Learning), a framework for efficient adaptation to new control tasks. Inspired by recent advancements in parameter-efficient fine-tuning in language domains, we explore efficient fine-tuning techniques -- e.g., Bottleneck Adapters, P-Tuning, and Low-Rank Adaptation (LoRA) -- in TAIL to adapt large pretrained models for new tasks with limited demonstration data. Our e
    
[^133]: 输入相关随机平滑的有趣特性

    Intriguing Properties of Input-dependent Randomized Smoothing

    [https://arxiv.org/abs/2110.05365](https://arxiv.org/abs/2110.05365)

    输入相关平滑方法虽然被用来获取可靠鲁棒分类器，但缺乏形式保证，其证书并不合理，因受到维度诅咒影响；提出了一个理论和实践框架，使得即使在维度诅咒存在的情况下，也能在严格的限制条件下使用输入相关平滑。

    

    随机平滑目前被认为是获得可靠鲁棒分类器的最先进方法。尽管其性能显著，但该方法存在诸如“认证准确性瀑布”、认证与准确性之间的权衡，甚至公平性问题等严重问题。为了克服这些缺陷，已经提出了输入相关的平滑方法。然而，我们证明了这些方法缺乏形式保证，因此得到的证书并不合理。我们表明，在一般情况下，输入相关平滑受到维度诅咒的影响，导致方差函数具有较低的半弹性。另一方面，我们提出了一个理论和实践框架，即使在维度诅咒存在的情况下，也能在严格的限制条件下使用输入相关平滑。我们展示了一个具体的平滑方差设计。

    arXiv:2110.05365v3 Announce Type: replace-cross  Abstract: Randomized smoothing is currently considered the state-of-the-art method to obtain certifiably robust classifiers. Despite its remarkable performance, the method is associated with various serious problems such as "certified accuracy waterfalls", certification vs.\ accuracy trade-off, or even fairness issues. Input-dependent smoothing approaches have been proposed with intention of overcoming these flaws. However, we demonstrate that these methods lack formal guarantees and so the resulting certificates are not justified. We show that in general, the input-dependent smoothing suffers from the curse of dimensionality, forcing the variance function to have low semi-elasticity. On the other hand, we provide a theoretical and practical framework that enables the usage of input-dependent smoothing even in the presence of the curse of dimensionality, under strict restrictions. We present one concrete design of the smoothing variance 
    
[^134]: 朝着强化学习de novo基因组组装器迈出一步

    A step toward a reinforcement learning de novo genome assembler

    [https://arxiv.org/abs/2102.02649](https://arxiv.org/abs/2102.02649)

    本研究旨在探讨机器学习在基因组组装中的应用，使用强化学习（RL）。他们在文献中唯一发现的方法的基础上进行了扩展，以仔细探索学习过程。

    

    De novo基因组组装是基因组学中一个相关但计算复杂的任务。尽管de novo组装器已经成功地在几个基因组项目中使用，但仍然没有"最佳组装器"，组装器的选择和设置仍然依赖生物信息学专家。因此，与其他计算复杂问题一样，机器学习可能会成为开发更准确和自动化组装器的一种替代（或补充）方式。强化学习已被证明在解决无监督情况下的复杂活动（如游戏）方面很有前景，迫切需要了解该方法在“真实”问题（如DFA问题）中的局限性。该研究旨在探讨机器学习在基因组组装中的应用，使用强化学习（RL）。我们在文献中发现的唯一先前方法的基础上进行了扩展，以仔细探索学习过程。

    arXiv:2102.02649v4 Announce Type: replace-cross  Abstract: De novo genome assembly is a relevant but computationally complex task in genomics. Although de novo assemblers have been used successfully in several genomics projects, there is still no 'best assembler', and the choice and setup of assemblers still rely on bioinformatics experts. Thus, as with other computationally complex problems, machine learning may emerge as an alternative (or complementary) way for developing more accurate and automated assemblers. Reinforcement learning has proven promising for solving complex activities without supervision - such games - and there is a pressing need to understand the limits of this approach to 'real' problems, such as the DFA problem. This study aimed to shed light on the application of machine learning, using reinforcement learning (RL), in genome assembly. We expanded upon the sole previous approach found in the literature to solve this problem by carefully exploring the learning as
    
[^135]: RomanSetu: 通过罗马化有效地利用大语言模型的多语言能力

    RomanSetu: Efficiently unlocking multilingual capabilities of Large Language Models models via Romanization. (arXiv:2401.14280v1 [cs.CL])

    [http://arxiv.org/abs/2401.14280](http://arxiv.org/abs/2401.14280)

    本研究提出了一种创新的方法，通过使用罗马化形式的文本作为接口，有效地利用大语言模型的多语言能力。通过在印地语上的实验证明，罗马化文本不仅提高了推理效率，还在有限的预训练下实现了有竞争力的性能。这些发现表明罗马化有潜力弥合大语言模型应用中的语言障碍。

    

    本研究解决了将大型语言模型扩展到非英语语言（特别是使用非拉丁字母表的语言）的挑战。我们提出了一种创新的方法，利用罗马化形式的文本作为大语言模型的接口，假设频繁的非正式使用和与英语共享的标记有助于跨语言对齐。我们以印地语为重点，通过印地语到英语的翻译和情感分析任务，证明罗马化文本不仅由于其较低的生产力而显著改善了推理效率，还在有限的预训练中实现了有竞争力的性能。此外，我们的新颖的多脚本提示方法结合了罗马化和原生文本，在进一步提高任务性能方面显示出潜力。这些发现表明罗马化在弥合大语言模型应用中的语言障碍方面具有潜力，未来的工作将致力于将此方法扩展到更多的语言和任务。

    This study addresses the challenge of extending Large Language Models (LLMs) to non-English languages, specifically those using non-Latin scripts. We propose an innovative approach that utilizes the romanized form of text as an interface for LLMs, hypothesizing that its frequent informal use and shared tokens with English enhance cross-lingual alignment. Focusing on Hindi, we demonstrate through Hindi-to-English translation and sentiment analysis tasks that romanized text not only significantly improves inference efficiency due to its lower fertility compared to native text but also achieves competitive performance with limited pre-training. Additionally, our novel multi-script prompting approach, which combines romanized and native texts, shows promise in further enhancing task performance. These findings suggest the potential of romanization in bridging the language gap for LLM applications, with future work aimed at expanding this approach to more languages and tasks.
    
[^136]: FedLoGe: 长尾数据下的本地和通用联邦学习

    FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data. (arXiv:2401.08977v1 [cs.LG])

    [http://arxiv.org/abs/2401.08977](http://arxiv.org/abs/2401.08977)

    本文介绍了一种名为FedLoGe的方法，它通过在神经网络崩溃框架中集成表示学习和分类器对齐来提高区域和全局模型的性能，解决了在联邦长尾学习中忽视本地级别性能的问题。

    

    联邦长尾学习（Fed-LT）是一种在去中心化的本地客户端收集的数据呈现全球普遍存在的长尾分布的范例，近年来引起了相当大的关注。在Fed-LT的背景下，现有研究主要集中于解决数据不平衡问题，以提高通用全局模型的效能，而忽视了本地级别的性能。相比之下，常规的个性化联邦学习（pFL）技术主要是在平衡的全局数据分布的假设下，优化个性化的本地模型。本文提出了一种名为FedLoGe的方法，在Fed-LT中通过在神经网络崩溃框架中集成表示学习和分类器对齐，提高本地和通用模型的性能。我们的研究结果揭示了使用共享骨干作为基础框架的可行性。

    Federated Long-Tailed Learning (Fed-LT), a paradigm wherein data collected from decentralized local clients manifests a globally prevalent long-tailed distribution, has garnered considerable attention in recent times. In the context of Fed-LT, existing works have predominantly centered on addressing the data imbalance issue to enhance the efficacy of the generic global model while neglecting the performance at the local level. In contrast, conventional Personalized Federated Learning (pFL) techniques are primarily devised to optimize personalized local models under the presumption of a balanced global data distribution. This paper introduces an approach termed Federated Local and Generic Model Training in Fed-LT (FedLoGe), which enhances both local and generic model performance through the integration of representation learning and classifier alignment within a neural collapse framework. Our investigation reveals the feasibility of employing a shared backbone as a foundational framewor
    
[^137]: REValueD: 对可分解的马尔可夫决策过程进行正则化集合值分解

    REValueD: Regularised Ensemble Value-Decomposition for Factorisable Markov Decision Processes. (arXiv:2401.08850v1 [cs.LG])

    [http://arxiv.org/abs/2401.08850](http://arxiv.org/abs/2401.08850)

    REValueD是一种通过正则化集合值分解的新算法，针对高维离散动作空间的任务提供了优越性能，尤其在人形和狗类任务中表现出色。它遏制了Q-learning算法的高估偏差，并减轻了目标方差问题。

    

    由于可能的动作数量庞大，离散动作强化学习算法在具有高维离散动作空间的任务中经常失败。最近的一项进展利用了来自多智能体强化学习的概念——值分解，来解决这个问题。这项研究深入探讨了值分解的影响，揭示了它虽然可以遏制Q学习算法固有的高估偏差，但也会放大目标方差。为了应对这个问题，我们提出了一个评论家的集合以减轻目标方差。此外，我们引入了一个正则化损失，有助于减轻一个维度上的探索性动作对其他维度上最优动作价值的影响。我们的新颖算法REValueD，在经过离散化的DeepMind控制套件任务上进行了测试，展示了卓越的性能，特别是在困难的人形和狗类任务中。我们进一步分析了影响REValueD表现的因素。

    Discrete-action reinforcement learning algorithms often falter in tasks with high-dimensional discrete action spaces due to the vast number of possible actions. A recent advancement leverages value-decomposition, a concept from multi-agent reinforcement learning, to tackle this challenge. This study delves deep into the effects of this value-decomposition, revealing that whilst it curtails the over-estimation bias inherent to Q-learning algorithms, it amplifies target variance. To counteract this, we present an ensemble of critics to mitigate target variance. Moreover, we introduce a regularisation loss that helps to mitigate the effects that exploratory actions in one dimension can have on the value of optimal actions in other dimensions. Our novel algorithm, REValueD, tested on discretised versions of the DeepMind Control Suite tasks, showcases superior performance, especially in the challenging humanoid and dog tasks. We further dissect the factors influencing REValueD's performance
    
[^138]: 基于机器学习和深度学习的人机交互研究：对脑启发计算的综述

    Human-computer Interaction for Brain-inspired Computing Based on Machine Learning And Deep Learning:A Review. (arXiv:2312.07213v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.07213](http://arxiv.org/abs/2312.07213)

    该论文综述了机器学习和深度学习在脑启发计算的人机交互研究中的应用，介绍了其演化、挑战和潜在研究轨迹。

    

    人工智能的持续发展对生物医学研究和其他领域产生了深远影响。脑启发计算是多模态技术和生物医学领域的重要交叉点。本文综述了机器学习（ML）和深度学习（DL）模型在人机交互研究中应用于脑启发计算的演化、应用价值、挑战和潜在研究轨迹。首先回顾了基本概念和发展历史，并将其演化划分为近期的机器学习和当前的深度学习，强调了每个阶段在人机交互研究中对脑启发计算的重要性。另外，从六个角度介绍了深度学习在不同任务的人机交互脑启发计算中的最新进展和关键技术。尽管取得了显著进展，但在人机交互脑启发计算中仍面临挑战。

    The continuous development of artificial intelligence has a profound impact on biomedical research and other fields.Brain-inspired computing is an important intersection of multimodal technology and biomedical field. This paper presents a comprehensive review of machine learning (ML) and deep learning (DL) models applied in human-computer interaction for brain-inspired computing, tracking their evolution, application value, challenges, and potential research trajectories. First, the basic concepts and development history are reviewed, and their evolution is divided into two stages: recent machine learning and current deep learning, emphasizing the importance of each stage in the research state of human-computer interaction for brain-inspired computing. In addition, the latest progress and key techniques of deep learning in different tasks of human-computer interaction for brain-inspired computing are introduced from six perspectives. Despite significant progress, challenges remain in m
    
[^139]: 气候不确定性中的学习和规划：在时变部分可观测环境中的应用

    Weathering Ongoing Uncertainty: Learning and Planning in a Time-Varying Partially Observable Environment. (arXiv:2312.03263v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2312.03263](http://arxiv.org/abs/2312.03263)

    本研究结合了时变马尔科夫决策过程和部分可观测性，提出了在不确定、随机和时变环境中进行学习和规划的方法。通过记忆优先状态估计和规划策略的集成，我们实现了对长期奖励的优化，在仿真和硬件验证中取得了良好的结果。

    

    在不确定、随机和时变环境中，最优决策对于自主系统来说是一个重大挑战。随着时间的推移，环境的变化可以对系统的最优决策策略产生显著影响。为了对这样的环境进行建模，我们的工作将之前的时变马尔科夫决策过程(time-varying Markov Decision Processes, TVMDP)的概念与部分可观测性相结合，引入了时变部分可观测马尔科夫决策过程(time-varying Partially Observable Markov Decision Processes, TV-POMDP)。我们提出了一个双管齐下的方法来在TV-POMDP中准确估计和规划：1）记忆优先状态估计(Memory Prioritized State Estimation, MPSE)，利用加权记忆提供更准确的时变转移估计；2）MPSE集成的规划策略，优化长期奖励的同时考虑时间约束。我们使用仿真和硬件验证了所提出的框架和算法，机器人在一个部分可观测、时变的环境中进行探索。

    Optimal decision-making presents a significant challenge for autonomous systems operating in uncertain, stochastic and time-varying environments. Environmental variability over time can significantly impact the system's optimal decision making strategy for mission completion. To model such environments, our work combines the previous notion of Time-Varying Markov Decision Processes (TVMDP) with partial observability and introduces Time-Varying Partially Observable Markov Decision Processes (TV-POMDP). We propose a two-pronged approach to accurately estimate and plan within the TV-POMDP: 1) Memory Prioritized State Estimation (MPSE), which leverages weighted memory to provide more accurate time-varying transition estimates; and 2) an MPSE-integrated planning strategy that optimizes long-term rewards while accounting for temporal constraint. We validate the proposed framework and algorithms using simulations and hardware, with robots exploring a partially observable, time-varying environ
    
[^140]: APRICOT: 重症监护病房(ICU)中的敏感度预测：预测稳定性、转变和维持生命的治疗

    APRICOT: Acuity Prediction in Intensive Care Unit (ICU): Predicting Stability, Transitions, and Life-Sustaining Therapies. (arXiv:2311.02026v1 [cs.AI])

    [http://arxiv.org/abs/2311.02026](http://arxiv.org/abs/2311.02026)

    APRICOT是一种基于Transformer的神经网络，用于在ICU患者中实时预测敏感度状态，并在多个数据集上进行了广泛验证。

    

    ICU中的患者严重程度状态可能会在稳定和不稳定之间迅速变化，有时会导致危及生命的情况。早期检测到恶化可能会导致更及时的干预和更好的生存率。目前的方法依赖于手动的每日评估。已经开发了一些数据驱动的方法，使用死亡率作为ICU中敏感度的代理。然而，这些方法并未整合敏感度状态以确定患者的稳定性或对维持生命治疗的需求。在本研究中，我们提出了APRICOT（重症监护病房中的敏感度预测），一种基于Transformer的神经网络，用于实时预测ICU患者的敏感度状态。我们在三个大型数据集上外部、时间上和前瞻性地开发和广泛验证了APRICOT模型：佛罗里达大学健康中心（UFH）、eICU合作研究数据库（eICU）和重症监护医疗信息市场（MIMIC）-IV。

    The acuity state of patients in the intensive care unit (ICU) can quickly change from stable to unstable, sometimes leading to life-threatening conditions. Early detection of deteriorating conditions can result in providing more timely interventions and improved survival rates. Current approaches rely on manual daily assessments. Some data-driven approaches have been developed, that use mortality as a proxy of acuity in the ICU. However, these methods do not integrate acuity states to determine the stability of a patient or the need for life-sustaining therapies. In this study, we propose APRICOT (Acuity Prediction in Intensive Care Unit), a Transformer-based neural network to predict acuity state in real-time in ICU patients. We develop and extensively validate externally, temporally, and prospectively the APRICOT model on three large datasets: University of Florida Health (UFH), eICU Collaborative Research Database (eICU), and Medical Information Mart for Intensive Care (MIMIC)-IV. T
    
[^141]: 大型地图上的按需城市出行问题的近似多智能体强化学习（扩展版）

    Approximate Multiagent Reinforcement Learning for On-Demand Urban Mobility Problem on a Large Map (extended version). (arXiv:2311.01534v1 [cs.MA])

    [http://arxiv.org/abs/2311.01534](http://arxiv.org/abs/2311.01534)

    本文研究了大型城市环境下的自主多智能体出租车路径问题，提出了一个近似滚动为基础的两阶段算法来减少计算量。

    

    本文关注大型城市环境下的自主多智能体出租车路径问题，未来乘车请求的位置和数量事先未知，但遵循估计的经验分布。最近的理论表明，如果基础策略是稳定的，那么基于滚动的算法与这样的基础策略产生接近最优的稳定策略。尽管基于滚动的方法非常适合学习具有对未来需求考虑的合作多智能体策略，但将这些方法应用于大型城市环境可能计算上很昂贵。大型环境往往有大量请求，因此需要大型的出租车队保证稳定性。本文旨在解决多智能体（逐一）滚动的计算瓶颈问题，其中计算复杂性随代理数量线性增长。我们提出了一种近似逐一滚动为基础的两阶段算法，减少计算量

    In this paper, we focus on the autonomous multiagent taxi routing problem for a large urban environment where the location and number of future ride requests are unknown a-priori, but follow an estimated empirical distribution. Recent theory has shown that if a base policy is stable then a rollout-based algorithm with such a base policy produces a near-optimal stable policy. Although, rollout-based approaches are well-suited for learning cooperative multiagent policies with considerations for future demand, applying such methods to a large urban environment can be computationally expensive. Large environments tend to have a large volume of requests, and hence require a large fleet of taxis to guarantee stability. In this paper, we aim to address the computational bottleneck of multiagent (one-at-a-time) rollout, where the computational complexity grows linearly in the number of agents. We propose an approximate one-at-a-time rollout-based two-phase algorithm that reduces the computatio
    
[^142]: 脑解码：走向实时重建视觉知觉

    Brain decoding: toward real-time reconstruction of visual perception. (arXiv:2310.19812v1 [eess.IV])

    [http://arxiv.org/abs/2310.19812](http://arxiv.org/abs/2310.19812)

    本研究提出了一种基于脑磁图（MEG）的脑解码方法，通过训练一个具有预训练嵌入、MEG模块和图像生成器的模型，在实时应用中实现了对视觉知觉的高时间分辨率解码，并在图像检索上取得了7倍的改进。

    

    在过去的五年中，生成式和基础性人工智能系统的使用极大地提高了对大脑活动的解码能力。特别是对于视觉知觉，现在可以从功能性磁共振成像（fMRI）中解码出令人瞩目的准确度。然而，这种神经影像技术的时间分辨率有限（约为0.5 Hz），因此在实时应用方面存在根本性的限制。在这里，我们提出了一种基于脑磁图（MEG）的替代方法，这是一种能够以高时间分辨率（约为5000 Hz）测量脑活动的神经影像设备。为此，我们开发了一个MEG解码模型，该模型通过对比和回归目标进行训练，并由三个模块组成：i）从图像中获得的预训练嵌入、ii）端到端训练的MEG模块以及iii）预训练的图像生成器。我们的结果有三个方面：首先，我们的MEG解码器在经典线性解码器上显示出7倍的图像检索改进。其次，后期脑部

    In the past five years, the use of generative and foundational AI systems has greatly improved the decoding of brain activity. Visual perception, in particular, can now be decoded from functional Magnetic Resonance Imaging (fMRI) with remarkable fidelity. This neuroimaging technique, however, suffers from a limited temporal resolution ($\approx$0.5 Hz) and thus fundamentally constrains its real-time usage. Here, we propose an alternative approach based on magnetoencephalography (MEG), a neuroimaging device capable of measuring brain activity with high temporal resolution ($\approx$5,000 Hz). For this, we develop an MEG decoding model trained with both contrastive and regression objectives and consisting of three modules: i) pretrained embeddings obtained from the image, ii) an MEG module trained end-to-end and iii) a pretrained image generator. Our results are threefold: Firstly, our MEG decoder shows a 7X improvement of image-retrieval over classic linear decoders. Second, late brain 
    
[^143]: DepWiGNN：一种用于多跳空间推理的深度图神经网络

    DepWiGNN: A Depth-wise Graph Neural Network for Multi-hop Spatial Reasoning in Text. (arXiv:2310.12557v1 [cs.CL])

    [http://arxiv.org/abs/2310.12557](http://arxiv.org/abs/2310.12557)

    DepWiGNN是一种用于多跳空间推理的深度图神经网络。它通过设计新颖的节点记忆方案，并在图的深度维度上聚合信息，从而能够收集长时间的依赖关系，而无需堆叠多个层次。实验结果表明，DepWiGNN在两个挑战数据集上比传统GNN方法具有更高的准确性。

    

    文本中的空间推理在各种实际应用中起着至关重要的作用。现有的空间推理方法通常从纯文本中推断空间关系，忽视了自然语言与符号结构之间的差距。图神经网络（GNN）在引导和聚合符号结构方面表现出了卓越的能力。然而，传统的GNN在处理多跳空间推理时面临着挑战，由于过度平滑的问题，即随着图层数量的增加，性能显著下降。为了应对这些挑战，我们提出了一种新颖的Depth-Wise Graph Neural Network（DepWiGNN）。具体地，我们设计了一种新颖的节点记忆方案，并在图的深度维度上聚合信息，而不是在广度维度上，这样可以收集长时间的依赖关系，而无需堆叠多个层次。实验结果表明，在两个挑战数据集上，DepWiGNN可以以比传统GNN方法更高的准确性进行多跳空间推理。

    Spatial reasoning in text plays a crucial role in various real-world applications. Existing approaches for spatial reasoning typically infer spatial relations from pure text, which overlook the gap between natural language and symbolic structures. Graph neural networks (GNNs) have showcased exceptional proficiency in inducing and aggregating symbolic structures. However, classical GNNs face challenges in handling multi-hop spatial reasoning due to the over-smoothing issue, \textit{i.e.}, the performance decreases substantially as the number of graph layers increases. To cope with these challenges, we propose a novel \textbf{Dep}th-\textbf{Wi}se \textbf{G}raph \textbf{N}eural \textbf{N}etwork (\textbf{DepWiGNN}). Specifically, we design a novel node memory scheme and aggregate the information over the depth dimension instead of the breadth dimension of the graph, which empowers the ability to collect long dependencies without stacking multiple layers. Experimental results on two challen
    
[^144]: 一种用于大型语言模型的一次敏感度感知混合稀疏化剪枝方法

    One-Shot Sensitivity-Aware Mixed Sparsity Pruning for Large Language Models. (arXiv:2310.09499v1 [cs.CL])

    [http://arxiv.org/abs/2310.09499](http://arxiv.org/abs/2310.09499)

    我们提出了一种基于敏感度感知混合稀疏化剪枝的方法，可以在不重新训练的情况下将大型语言模型剪枝至至少50％的稀疏性，同时保持稀疏性水平和减少剪枝引起的误差。此外，该方法还与量化兼容，可以进一步压缩语言模型。

    

    从生成预训练变压器（GPT）系列中的各种大型语言模型（LLMs）在各种文本生成任务中取得了卓越的性能。然而，由于高推理延迟，巨大的模型大小阻碍了它们在实际应用中的实用性。因此，通过量化、剪枝和其他方法提高LLMs的效率成为LLM研究的一个关键问题。在这项工作中，我们提出了一种基于Hessian敏感度感知混合稀疏化剪枝的方法，可以将LLMs剪枝至至少50%的稀疏性，而无需重新训练。它根据敏感度自适应地分配稀疏性，使我们能够降低剪枝引起的误差，同时保持整体稀疏性水平。当稀疏度非常高时，所提出的方法的优势更加明显。此外，我们的方法与量化兼容，可以进一步压缩LLMs。

    Various Large Language Models(LLMs) from the Generative Pretrained Transformer~(GPT) family have achieved outstanding performances in a wide range of text generation tasks. However, the enormous model sizes have hindered their practical use in real-world applications due to high inference latency. Therefore, improving the efficiencies of LLMs through quantization, pruning, and other means has been a key issue in LLM studies. In this work, we propose a method based on Hessian sensitivity-aware mixed sparsity pruning to prune LLMs to at least 50\% sparsity without the need of any retraining. It allocates sparsity adaptively based on sensitivity, allowing us to reduce pruning-induced error while maintaining the overall sparsity level. The advantages of the proposed method exhibit even more when the sparsity is extremely high. Furthermore, our method is compatible with quantization, enabling further compression of LLMs.
    
[^145]: 对水印技术应用于人工智能生成内容的漏洞研究

    Towards the Vulnerability of Watermarking Artificial Intelligence Generated Content. (arXiv:2310.07726v1 [cs.CV])

    [http://arxiv.org/abs/2310.07726](http://arxiv.org/abs/2310.07726)

    该研究探讨了将水印技术应用于人工智能生成内容的漏洞，并证明了现有的水印机制容易被对手破解。

    

    人工智能生成内容（AIGC）在社交媒体上越来越受欢迎，许多商业服务已经推出。这些服务利用先进的生成模型，如潜在扩散模型和大型语言模型，为用户生成创意内容（例如逼真的图像、流畅的句子）。对于此类生成内容的使用需要高度监管，因为服务提供商需要确保用户不违反使用政策（例如滥用商业化、生成和分发不安全的内容）。最近提出了许多水印技术，但是本文表明对手可以轻易破解这些水印机制。具体而言，我们考虑了两种可能的攻击方式：（1）水印去除：对手可以轻松地从生成内容中删除嵌入的水印，然后自由使用而不受服务提供商的限制；（2）水印伪造：对手可以创建非法的水印。

    Artificial Intelligence Generated Content (AIGC) is gaining great popularity in social media, with many commercial services available. These services leverage advanced generative models, such as latent diffusion models and large language models, to generate creative content (e.g., realistic images, fluent sentences) for users. The usage of such generated content needs to be highly regulated, as the service providers need to ensure the users do not violate the usage policies (e.g., abuse for commercialization, generating and distributing unsafe content).  Numerous watermarking approaches have been proposed recently. However, in this paper, we show that an adversary can easily break these watermarking mechanisms. Specifically, we consider two possible attacks. (1) Watermark removal: the adversary can easily erase the embedded watermark from the generated content and then use it freely without the regulation of the service provider. (2) Watermark forge: the adversary can create illegal co
    
[^146]: 通过确定性对流模型的生成性集成深度学习，用于严重天气预测

    Generative ensemble deep learning severe weather prediction from a deterministic convection-allowing model. (arXiv:2310.06045v1 [cs.LG])

    [http://arxiv.org/abs/2310.06045](http://arxiv.org/abs/2310.06045)

    本论文开发了一种集成后处理方法，将生成对抗网络（CGANs）和卷积神经网络（CNN）结合起来，对严重天气进行概率预测。该方法在使用HRRR预报作为输入数据，在2021年的测试数据集上相对于其他基于神经网络的方法提高了高达20％的Brier技巧分数（BSS）。

    

    开发了一种用于概率预测美国本土严重天气（龙卷风、冰雹和大风阵）的集成后处理方法。该方法将条件生成对抗网络（CGANs）与卷积神经网络（CNN）结合起来，用于后处理对流允许模型（CAM）的预测。CGANs被设计用于从确定性CAM预测中创建合成集成成员，其输出经过CNN处理以估计严重天气的概率。该方法使用高分辨率快速刷新（HRRR）1-24小时预报作为输入，以及暴风预警中心（SPC）的严重天气报告作为目标进行测试。在2021年的HRRR预测测试数据集中，该方法相对于其他基于神经网络的参考方法提高了高达20％的Brier技巧分数（BSS）。

    An ensemble post-processing method is developed for the probabilistic prediction of severe weather (tornadoes, hail, and wind gusts) over the conterminous United States (CONUS). The method combines conditional generative adversarial networks (CGANs), a type of deep generative model, with a convolutional neural network (CNN) to post-process convection-allowing model (CAM) forecasts. The CGANs are designed to create synthetic ensemble members from deterministic CAM forecasts, and their outputs are processed by the CNN to estimate the probability of severe weather. The method is tested using High-Resolution Rapid Refresh (HRRR) 1--24 hr forecasts as inputs and Storm Prediction Center (SPC) severe weather reports as targets. The method produced skillful predictions with up to 20% Brier Skill Score (BSS) increases compared to other neural-network-based reference methods using a testing dataset of HRRR forecasts in 2021. For the evaluation of uncertainty quantification, the method is overcon
    
[^147]: 通过基于Transformer的强化学习进行分子的全新设计

    Molecular De Novo Design through Transformer-based Reinforcement Learning. (arXiv:2310.05365v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.05365](http://arxiv.org/abs/2310.05365)

    本文提出了一种基于Transformer的强化学习方法，通过精细调整生成模型，能够在分子的全新设计中生成具有所需性质的分子结构，展现出优越的性能。

    

    本文介绍了一种通过精细调整基于Transformer的生成模型用于分子的全新设计的方法。利用Transformer相对于循环神经网络（RNN）的优越序列学习能力，我们的模型可以有效地生成具有所需性质的分子结构。与传统的基于RNN的模型相比，我们提出的方法在生成预测对多种生物靶点具有活性的化合物方面表现出卓越性能，捕捉了分子结构序列的长期依赖性。该模型的有效性在许多任务中得到了证明，包括生成与查询结构类似的分子和生成具有特定属性的化合物，在性能上优于基线的基于RNN的方法。我们的方法可以用于桥接化学、从单个分子开始扩展库，并生成具有高预测活性的化合物。

    In this work, we introduce a method to fine-tune a Transformer-based generative model for molecular de novo design. Leveraging the superior sequence learning capacity of Transformers over Recurrent Neural Networks (RNNs), our model can generate molecular structures with desired properties effectively. In contrast to the traditional RNN-based models, our proposed method exhibits superior performance in generating compounds predicted to be active against various biological targets, capturing long-term dependencies in the molecular structure sequence. The model's efficacy is demonstrated across numerous tasks, including generating analogues to a query structure and producing compounds with particular attributes, outperforming the baseline RNN-based methods. Our approach can be used for scaffold hopping, library expansion starting from a single molecule, and generating compounds with high predicted activity against biological targets.
    
[^148]: 眼不见心不念：利用视频跟踪启用的记忆模型对未被观察到的对象进行推理和规划

    Out of Sight, Still in Mind: Reasoning and Planning about Unobserved Objects with Video Tracking Enabled Memory Models. (arXiv:2309.15278v1 [cs.RO])

    [http://arxiv.org/abs/2309.15278](http://arxiv.org/abs/2309.15278)

    本文研究了如何对先前观察到但当前被遮挡的对象进行推理和规划，提出了利用转换器关系动力学编码轨迹历史的方法，并在多个挑战性任务中表现出色。

    

    机器人需要具有对先前观察到但当前被遮挡的对象的记忆，以在现实环境中可靠地工作。我们研究了将面向对象的记忆编码到多对象操纵推理和规划框架中的问题。我们提出了DOOM和LOOM，它们利用转换器关系动力学来编码给定部分视点云和对象发现与跟踪引擎的轨迹历史。我们的方法可以执行多个具有挑战性的任务，包括处理被遮挡的对象，新出现的对象，以及物体重新出现。通过广泛的仿真和真实世界实验，我们发现我们的方法在不同数量的对象和不同数量的干扰动作方面表现良好。此外，我们展示了我们的方法优于隐式记忆基线。

    Robots need to have a memory of previously observed, but currently occluded objects to work reliably in realistic environments. We investigate the problem of encoding object-oriented memory into a multi-object manipulation reasoning and planning framework. We propose DOOM and LOOM, which leverage transformer relational dynamics to encode the history of trajectories given partial-view point clouds and an object discovery and tracking engine. Our approaches can perform multiple challenging tasks including reasoning with occluded objects, novel objects appearance, and object reappearance. Throughout our extensive simulation and real-world experiments, we find that our approaches perform well in terms of different numbers of objects and different numbers of distractor actions. Furthermore, we show our approaches outperform an implicit memory baseline.
    
[^149]: 艺术还是技巧？大型语言模型与创造力的虚假承诺

    Art or Artifice? Large Language Models and the False Promise of Creativity. (arXiv:2309.14556v1 [cs.CL])

    [http://arxiv.org/abs/2309.14556](http://arxiv.org/abs/2309.14556)

    本研究通过提出创造性写作的托兰斯测验(TTCW)来评估大型语言模型(LLMs)的写作创造力。结果表明，LLM生成的故事在创意测试中通过的数量比专业作家写的故事少。此外，我们发现LLMs无法代替专家进行TTCW评估。

    

    研究人员认为，大型语言模型(LLMs)具有从博客到故事的高质量写作能力。然而，客观评估一段文字的创造力是具有挑战性的。受创造性思维的托兰斯测验(TTC)的启发，我们使用共识评估技术[3]，提出了创造性写作的托兰斯测验(TTCW)来评估创造力作为一个产品。TTCW由包含在流畅度、灵活性、独创性和细致度原始维度中的14个二元测试组成。我们招募了10位创意作家，并使用TTCW对48个由专业作家或LLMs撰写的故事进行人工评估。我们的分析表明，LLM生成的故事通过的TTCW测试比专业作家写的故事少了3-10倍。此外，我们探索了使用LLMs作为评价者，以自动化TTCW评估，结果显示没有一个LLM与专家评估呈正相关。

    Researchers have argued that large language models (LLMs) exhibit high-quality writing capabilities from blogs to stories. However, evaluating objectively the creativity of a piece of writing is challenging. Inspired by the Torrance Test of Creative Thinking (TTCT), which measures creativity as a process, we use the Consensual Assessment Technique [3] and propose the Torrance Test of Creative Writing (TTCW) to evaluate creativity as a product. TTCW consists of 14 binary tests organized into the original dimensions of Fluency, Flexibility, Originality, and Elaboration. We recruit 10 creative writers and implement a human assessment of 48 stories written either by professional authors or LLMs using TTCW. Our analysis shows that LLM-generated stories pass 3-10X less TTCW tests than stories written by professionals. In addition, we explore the use of LLMs as assessors to automate the TTCW evaluation, revealing that none of the LLMs positively correlate with the expert assessments.
    
[^150]: LongLoRA: 高效的长上下文大型语言模型的精细调整

    LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models. (arXiv:2309.12307v1 [cs.CL])

    [http://arxiv.org/abs/2309.12307](http://arxiv.org/abs/2309.12307)

    LongLoRA是一种高效的精细调整方法，可以在有限的计算成本下扩展预训练的大型语言模型的上下文大小。它通过稀疏的局部注意力实现精细调整，并使用移动短注意力有效实现上下文扩展，与传统方法具有相似的性能。

    

    我们提出了一种高效的精细调整方法——LongLoRA，可以在有限的计算成本下扩展预训练的大型语言模型(LLM)的上下文大小。通常，使用长上下文大小训练LLM的计算成本很高，需要大量的训练时间和GPU资源。本文中，我们在两个方面加快了LLM的上下文扩展。一方面，尽管推理过程中需要稠密的全局注意力，但模型的精细调整可以通过稀疏的局部注意力有效且高效地完成。所提出的移动短注意力有效地实现了上下文的扩展，在与使用传统注意力进行精细调整时具有相似的性能，同时可以在训练中只用两行代码实现，在推理中是可选的。另一方面，我们重新审视了参数效率问题。

    We present LongLoRA, an efficient fine-tuning approach that extends the context sizes of pre-trained large language models (LLMs), with limited computation cost. Typically, training LLMs with long context sizes is computationally expensive, requiring extensive training hours and GPU resources. For example, training on the context length of 8192 needs 16x computational costs in self-attention layers as that of 2048. In this paper, we speed up the context extension of LLMs in two aspects. On the one hand, although dense global attention is needed during inference, fine-tuning the model can be effectively and efficiently done by sparse local attention. The proposed shift short attention effectively enables context extension, leading to non-trivial computation saving with similar performance to fine-tuning with vanilla attention. Particularly, it can be implemented with only two lines of code in training, while being optional in inference. On the other hand, we revisit the parameter-effici
    
[^151]: HAISTA-NET: 通过注意力进行人类辅助的实例分割

    HAISTA-NET: Human Assisted Instance Segmentation Through Attention. (arXiv:2305.03105v1 [cs.CV])

    [http://arxiv.org/abs/2305.03105](http://arxiv.org/abs/2305.03105)

    该论文提出了一种通过人类辅助实例分割方法，称为HAISTA-NET，增强了现有的实例分割网络，引入了人类指定的部分边界地图，以生成更精确的分割掩模。

    

    实例分割是图像检测的一种形式，在物体细化、医学图像分析和图像/视频编辑等方面有广泛应用，这些应用都需要高度精确的结果。然而，即便是最先进的完全自动化实例分割算法，其精度常常无法达到。对于小而复杂的对象来说，性能差距尤为明显。通常，从业者只能采用完全手动的注释方法，这可能是一个繁琐的过程。为了克服这个问题，我们提出了一种新的方法，以实现更精确的预测，并为高曲率、复杂和小规模对象生成更高质量的分割掩模。我们的人类辅助分割模型HAISTA-NET，扩充了现有的Strong Mask R-CNN网络，以包括人类指定的部分边界。此外，我们还提出了一个手绘部分物体边界的数据集，称为人类注意力地图。我们还引入了一种新的损失函数，它考虑到了部分注意力地图和原始掩模提议，这使网络能够关注人们认为最重要的区域。在PASCAL VOC和COCO数据集上的实验结果表明，我们提出的方法优于强基线，并在小而复杂对象实例分割方面实现了最先进的性能。

    Instance segmentation is a form of image detection which has a range of applications, such as object refinement, medical image analysis, and image/video editing, all of which demand a high degree of accuracy. However, this precision is often beyond the reach of what even state-of-the-art, fully automated instance segmentation algorithms can deliver. The performance gap becomes particularly prohibitive for small and complex objects. Practitioners typically resort to fully manual annotation, which can be a laborious process. In order to overcome this problem, we propose a novel approach to enable more precise predictions and generate higher-quality segmentation masks for high-curvature, complex and small-scale objects. Our human-assisted segmentation model, HAISTA-NET, augments the existing Strong Mask R-CNN network to incorporate human-specified partial boundaries. We also present a dataset of hand-drawn partial object boundaries, which we refer to as human attention maps. In addition, 
    
[^152]: 大象的透视镜：调查谷歌、ChatGPT、维基百科和YouTube上的语言偏见

    A Perspectival Mirror of the Elephant: Investigating Language Bias on Google, ChatGPT, Wikipedia, and YouTube. (arXiv:2303.16281v1 [cs.CY])

    [http://arxiv.org/abs/2303.16281](http://arxiv.org/abs/2303.16281)

    研究发现在Google、ChatGPT、维基百科和YouTube上，搜索结果受限于语言，反映了与复杂主题相关的文化刻板印象，缺乏跨文化视角。

    

    与谷歌搜索“从多个角度获取信息，以便你可以形成自己对世界的理解”的任务相反，我们发现谷歌及其最突出的搜索结果 - 维基百科和YouTube，仅反映与“佛教”、“自由主义”、“殖民化”、“伊朗”和“美国”等复杂主题相关的文化刻板印象。简单地说，在不同语言的相同搜索中，它们以不同程度呈现不同的信息（我们称之为“语言偏见”），而不是呈现复杂主题的全球图片。我们的在线搜索使我们成为谚语中的盲人，仅触摸小象的一小部分，不知道其他文化的视角的存在。我们用于搜索的语言最终成为促进本族中心主义观点的文化过滤器，其中一个人根据自己的文化评估其他人或思想。我们还发现ChatGPT中深深嵌入了语言偏见。

    Contrary to Google Search's mission of delivering information from "many angles so you can form your own understanding of the world," we find that Google and its most prominent returned results -- Wikipedia and YouTube, simply reflect the narrow set of cultural stereotypes tied to the search language for complex topics like "Buddhism," "Liberalism," "colonization," "Iran" and "America." Simply stated, they present, to varying degrees, distinct information across the same search in different languages (we call it 'language bias'). Instead of presenting a global picture of a complex topic, our online searches turn us into the proverbial blind person touching a small portion of an elephant, ignorant of the existence of other cultural perspectives. The language we use to search ends up as a cultural filter to promote ethnocentric views, where a person evaluates other people or ideas based on their own culture. We also find that language bias is deeply embedded in ChatGPT. As it is primaril
    
[^153]: Distill n' Explain：使用简单替代模型解释图神经网络

    Distill n' Explain: explaining graph neural networks using simple surrogates. (arXiv:2303.10139v1 [cs.LG])

    [http://arxiv.org/abs/2303.10139](http://arxiv.org/abs/2303.10139)

    本文提出了Distill n' Explain (DnX)方法，通过知识蒸馏学习简单的替代模型，并通过解决简单的凸规划提取节点或边级别的解释，从而解释图神经网络（GNN）。实验结果显示，DnX和FastDnX通常优于最先进的GNN解释器，并且运行速度快得多。

    

    解释图神经网络中节点预测的方法通常是找到保持预测的图子结构。这通常意味着反向传播由于GNN的复杂性（例如，层数）而导致解释的成本上升。因此，作者提出了Distill n' Explain (DnX)方法。首先，DnX通过知识蒸馏来学习替代的GNN。然后，DnX通过解决简单的凸规划来提取节点或边级别的解释。同时，作者还提出了FastDnX，这是DnX的更快版本，它利用了我们替代模型的线性分解。实验表明，DnX和FastDnX通常优于最先进的GNN解释器，并且运行速度快得多。此外，我们还通过理论结果支持了我们的实验发现。

    Explaining node predictions in graph neural networks (GNNs) often boils down to finding graph substructures that preserve predictions. Finding these structures usually implies back-propagating through the GNN, bonding the complexity (e.g., number of layers) of the GNN to the cost of explaining it. This naturally begs the question: Can we break this bond by explaining a simpler surrogate GNN? To answer the question, we propose Distill n' Explain (DnX). First, DnX learns a surrogate GNN via knowledge distillation. Then, DnX extracts node or edge-level explanations by solving a simple convex program. We also propose FastDnX, a faster version of DnX that leverages the linear decomposition of our surrogate model. Experiments show that DnX and FastDnX often outperform state-of-the-art GNN explainers while being orders of magnitude faster. Additionally, we support our empirical findings with theoretical results linking the quality of the surrogate model (i.e., distillation error) to the faith
    

