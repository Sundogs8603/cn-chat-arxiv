# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [FATRER: Full-Attention Topic Regularizer for Accurate and Robust Conversational Emotion Recognition.](http://arxiv.org/abs/2307.12221) | 本文介绍了一种全注意力主题正则化器，用于增强情感识别器在处理对话中的局部上下文时获得情感相关的全局视角，实验证明该模型在准确性和稳健性方面取得了更好的效果。 |
| [^2] | [Expediting Building Footprint Segmentation from High-resolution Remote Sensing Images via progressive lenient supervision.](http://arxiv.org/abs/2307.12220) | 本文针对远程感知图像建筑物分割中的模型传递效果问题，提出了一种名为BFSeg的高效框架，通过渐进宽松监督来增强学习的效率和有效性。 |
| [^3] | [A Comprehensive Review and Systematic Analysis of Artificial Intelligence Regulation Policies.](http://arxiv.org/abs/2307.12218) | 本文综合评估了全球不同地区和文化背景下的人工智能法规政策建议，并通过历史教训和系统分析方法，帮助治理机构解决人工智能监管的混乱现状。 |
| [^4] | [DeepCL: Deep Change Feature Learning on Remote Sensing Images in the Metric Space.](http://arxiv.org/abs/2307.12208) | DeepCL是一种用于遥感图像中的变化检测的深度学习方法，通过结合度量学习和分割，解决了时间关系建模和伪变化误分类的问题。 |
| [^5] | [Monadic Deep Learning.](http://arxiv.org/abs/2307.12187) | DeepLearning.scala 2解决了在静态类型语言中使用神经网络进行训练时的自动求导问题，并提供了一组单子和单子变换器。 |
| [^6] | [Machine learning discovers invariants of braids and flat braids.](http://arxiv.org/abs/2307.12185) | 本研究使用机器学习对辫子和平面辫子进行分类，得出了新的便利不变量，包括平面辫子的完全不变量。 |
| [^7] | [On the Expressivity of Multidimensional Markov Reward.](http://arxiv.org/abs/2307.12184) | 这篇论文研究了马尔可夫奖励在顺序决策中的表达能力，给出了存在这样的奖励函数的条件，并证明了每个非退化的确定性策略集合都可以用多维马尔可夫奖励函数来描述。 |
| [^8] | [Security and Privacy Issues of Federated Learning.](http://arxiv.org/abs/2307.12181) | 本论文提出了对联邦学习中的安全和隐私挑战进行全面分类的分类法，并总结了各种攻击类型和新的研究方向，以加强联邦学习系统对新兴安全风险的防范。 |
| [^9] | [Named Entity Resolution in Personal Knowledge Graphs.](http://arxiv.org/abs/2307.12173) | 本文讨论了个人知识图谱中命名实体消解的问题，包括形式化定义、高质量和高效率的解决组件以及应用和未来研究方向。 |
| [^10] | [Optimized Network Architectures for Large Language Model Training with Billions of Parameters.](http://arxiv.org/abs/2307.12169) | 本文提出了一种优化的网络架构，用于训练拥有数十亿参数的大型语言模型。这个架构根据语言模型的通信需求，将集群分割成一组通过非阻塞高带宽互连的GPU集合，并通过轨道连接仅连接具有通信需求的GPU，从而降低网络成本高达75％，同时不影响训练性能。 |
| [^11] | [Hallucination Improves the Performance of Unsupervised Visual Representation Learning.](http://arxiv.org/abs/2307.12168) | 幻觉生成模型可以为对比学习提供额外的正样本，改进了无监督视觉表示学习的性能。 |
| [^12] | [The Imitation Game: Detecting Human and AI-Generated Texts in the Era of Large Language Models.](http://arxiv.org/abs/2307.12166) | 本论文研究了区分人类和AI生成的文本的任务，在不同体裁下进行了比较研究，提出了一个新的数据集，并采用多种机器学习模型进行分类。结果表明这些模型对于区分人类和AI生成的文本具有很高的效力，尽管在区分GPT生成的文本方面存在一定挑战。 |
| [^13] | [DIP-RL: Demonstration-Inferred Preference Learning in Minecraft.](http://arxiv.org/abs/2307.12158) | DIP-RL是一种利用人类演示的算法，在非结构化和开放的环境中通过多种方式推导偏好并学习奖励函数，其在Minecraft中的砍树任务中表现出了竞争力。 |
| [^14] | [Emergence of Adaptive Circadian Rhythms in Deep Reinforcement Learning.](http://arxiv.org/abs/2307.12143) | 本文研究了深度强化学习智能体中自适应昼夜节律的出现，通过在周期性变化环境中进行觅食任务，证明了智能体能够内化环境信号并适应相位变化，这一自适应过程是通过人工神经元的动力学来实现的。 |
| [^15] | [Route Planning Using Nature-Inspired Algorithms.](http://arxiv.org/abs/2307.12133) | 这篇论文介绍了自然启发算法（NIAs）及其在路线规划问题中的应用。NIAs是一类启发式算法，受自然现象启发，通过收敛和随机特性给出最优结果。在机器人中的路线规划问题中，NIAs能够有效地帮助机器人避免环境中的障碍物。 |
| [^16] | [AI on the Road: A Comprehensive Analysis of Traffic Accidents and Accident Detection System in Smart Cities.](http://arxiv.org/abs/2307.12128) | 本文分析了智能城市中交通事故及事故检测系统的综合方法。通过利用交通监控摄像头和行为识别系统，可以实时检测和响应交通事故，并将其与紧急服务整合，以减少人为错误和改善交通安全。 |
| [^17] | [A Revolution of Personalized Healthcare: Enabling Human Digital Twin with Mobile AIGC.](http://arxiv.org/abs/2307.12115) | 移动AIGC技术可以推动人类数字孪生在个性化医疗中的应用，包括生成罕见疾病数据、建模高保真数字孪生以及提供24/7定制医疗服务。 |
| [^18] | [A Zero-shot and Few-shot Study of Instruction-Finetuned Large Language Models Applied to Clinical and Biomedical Tasks.](http://arxiv.org/abs/2307.12114) | 这项研究评估了四种指导细调大型语言模型在临床和生物医学任务上的表现，并发现它们在零样本和少样本情况下接近最先进模型的性能，尤其在问答任务上表现良好。然而，在分类和关系抽取任务上的表现稍逊于特定训练于医学领域的模型。没有一个模型在所有研究任务上胜过其他模型，有些模型更适合特定任务。 |
| [^19] | [CFR-p: Counterfactual Regret Minimization with Hierarchical Policy Abstraction, and its Application to Two-player Mahjong.](http://arxiv.org/abs/2307.12087) | 本研究将反事实遗憾最小化算法应用于两人麻将，并通过分层策略抽象实现了游戏论分析，该框架可推广到其他不完全信息游戏。 |
| [^20] | [Enhancing Temporal Planning Domains by Sequential Macro-actions (Extended Version).](http://arxiv.org/abs/2307.12081) | 该论文提出了一种通用的顺序时间宏动作的概念，用于增强时间规划领域中的性能和处理复杂的资源冲突问题。 |
| [^21] | [Game-Theoretic Robust Reinforcement Learning Handles Temporally-Coupled Perturbations.](http://arxiv.org/abs/2307.12062) | 这篇论文提出了一种新的鲁棒强化学习方法，通过将时间耦合的鲁棒强化学习问题视为两人零和游戏来处理问题，并通过找到近似均衡来确保代理对时间耦合干扰的鲁棒性。实验结果显示，该方法在各种连续控制任务中相比基准方法表现出显著的鲁棒性优势。 |
| [^22] | [Fast Knowledge Graph Completion using Graphics Processing Units.](http://arxiv.org/abs/2307.12059) | 本文提出了一种在GPU上高效完成知识图谱补全的框架，通过使用知识图谱嵌入矢量来添加新关系。该框架将知识图谱补全问题转化为相似性连接问题，并提供了一种高效处理相似性连接问题的方法。 |
| [^23] | [External Reasoning: Towards Multi-Large-Language-Models Interchangeable Assistance with Human Feedback.](http://arxiv.org/abs/2307.12057) | 本文提出通过从外部存储库中选择性地集成知识来增强大型语言模型，提出了一种外部推理的新方法，例子是ChatPDF。 |
| [^24] | [Model Predictive Control (MPC) of an Artificial Pancreas with Data-Driven Learning of Multi-Step-Ahead Blood Glucose Predictors.](http://arxiv.org/abs/2307.12015) | 本文介绍了一种通过数据驱动的多步血糖预测器与线性时变模型预测控制（MPC）相结合的闭环胰岛素输送算法设计，用于治疗1型糖尿病。作者通过直接拟合整个血糖预测曲线，结合非线性和线性模型，与传统线性MPC进行对比，评估了算法的优劣。 |
| [^25] | [Psy-LLM: Scaling up Global Mental Health Psychological Services with AI-based Large Language Models.](http://arxiv.org/abs/2307.11991) | Psy-LLM是一个基于人工智能的系统，利用大型语言模型（LLMs）为在线心理咨询提供问答服务，前端工具可让医疗专业人员提供即时响应和正念活动，同时还可作为筛查工具辅助识别紧急案例。 |
| [^26] | [Sparse then Prune: Toward Efficient Vision Transformers.](http://arxiv.org/abs/2307.11988) | 本研究探讨了在视觉Transformer模型上应用稀疏正则化和剪枝的方法，结果表明在稀疏正则化之后进行剪枝可以显著减少模型计算负担而不损失太多性能。 |
| [^27] | [Why Is Prompt Tuning for Vision-Language Models Robust to Noisy Labels?.](http://arxiv.org/abs/2307.11978) | 视觉-语言模型通过少样本提示调参的方式适应新的分类任务，且对于噪声标签具有鲁棒性。关键原因包括固定的类名标记对模型优化的正则化作用以及从多样且通用的网络数据中学习到的强大预训练图像-文本嵌入提供的先验知识。 |
| [^28] | [On-Robot Bayesian Reinforcement Learning for POMDPs.](http://arxiv.org/abs/2307.11954) | 本研究提供了解决机器人学习中大量数据需求的方法，通过将专家知识捕捉并形式化为贝叶斯框架，使用基于样本的在线解决方法来推动基于贝叶斯强化学习在机器人中的应用。 |
| [^29] | [Pathology-and-genomics Multimodal Transformer for Survival Outcome Prediction.](http://arxiv.org/abs/2307.11952) | 提出了一种病理学和基因组多模态变压器（PathOmics），用于结肠相关癌症生存预测。该模型通过无监督预训练捕捉病理图像和基因组数据之间的内在相互作用，并通过任务特定模型微调适用于多模态和单模态数据。该方法在TCGA结肠和直肠癌队列上表现出竞争力。 |
| [^30] | [HIQL: Offline Goal-Conditioned RL with Latent States as Actions.](http://arxiv.org/abs/2307.11949) | 本文提出了一个基于离线数据的目标导向强化学习的分层算法，通过利用目标达成问题的结构，使用一个无动作的价值函数学习了两个策略，从而在学习过程中更有效地利用离线数据。 |
| [^31] | [Selective Perception: Optimizing State Descriptions with Reinforcement Learning for Language Model Actors.](http://arxiv.org/abs/2307.11922) | 本研究提出了一种名为BLINDER的方法，通过学习任务条件下状态描述的值函数，自动选择简明的状态描述，以优化大型语言模型(LLM)演员在顺序决策任务中的性能和效率。 |
| [^32] | [Bibliometric Analysis of Publisher and Journal Instructions to Authors on Generative-AI in Academic and Scientific Publishing.](http://arxiv.org/abs/2307.11918) | 该研究通过计量分析了顶级100家学术出版商和期刊对于作者在使用生成式AI（GAI）、生成式预训练模型（GPT）和大型语言模型（LLM）工具方面的指导程度和内容。结果显示，有17%的出版商和70%的期刊提供了有关GAI的指导，并且大部分禁止将GAI作为作者的一部分。同时也发现了一定的变异性。 |
| [^33] | [Hindsight-DICE: Stable Credit Assignment for Deep Reinforcement Learning.](http://arxiv.org/abs/2307.11897) | 本研究提出了Hindsight-DICE算法，利用重要抽样比率估计技术改善了深度强化学习中的信用分配问题。 |
| [^34] | [On the Vulnerability of Fairness Constrained Learning to Malicious Noise.](http://arxiv.org/abs/2307.11892) | 这项研究考虑了公正约束学习对恶意噪声的脆弱性，发现使用随机分类器可以在精度上只损失$\Theta(\alpha)$和$O(\sqrt{\alpha})$，对应不同的公正约束要求。 |
| [^35] | [Multimodal Document Analytics for Banking Process Automation.](http://arxiv.org/abs/2307.11845) | 本研究聚焦于应对金融科技竞争和提高银行业务运营效率的需求，通过多模式模型特别是先进的文档分析技术，研究了银行流程中的潜力和机会，并展示了LayoutXLM等模型在分析银行文档中的潜力和性能。 |
| [^36] | [HybridAugment++: Unified Frequency Spectra Perturbations for Model Robustness.](http://arxiv.org/abs/2307.11823) | HybridAugment++是一种通过减少卷积神经网络对高频成分的依赖并促进相位信息应用的数据增强方法，提高了模型的鲁棒性。它通过统一各种频谱增强方法，取得了竞争性的结果。 |
| [^37] | [Prompting Large Language Models with Speech Recognition Abilities.](http://arxiv.org/abs/2307.11795) | 本研究通过为大型语言模型添加音频编码器，使其具备了语音识别能力。在多语言数据集上的实验证明，这样的扩展能够提高模型的性能，并且在多语言环境下实现了语音识别。通过消融研究，我们还发现可以冻结模型以保持其原有功能，并且提升音频编码器的规模有助于提高性能。 |
| [^38] | [Applying QNLP to sentiment analysis in finance.](http://arxiv.org/abs/2307.11788) | 本论文研究了在金融行业中应用量子自然语言处理(QNLP)进行情感分析的实际适用性。利用一种新颖的数据生成方法，我们发现量子增强的长短期记忆(QLSTM)可以更快地训练，并且在软件实现方面接近古典结果。 |
| [^39] | [LLM Cognitive Judgements Differ From Human.](http://arxiv.org/abs/2307.11787) | 这项研究调查了大型语言模型在认知任务中的表现，并发现它们的认知判断与人类不同。 |
| [^40] | [What, Indeed, is an Achievable Provable Guarantee for Learning-Enabled Safety Critical Systems.](http://arxiv.org/abs/2307.11784) | 本文讨论了学习机制在安全关键领域的挑战，提出了一种两步验证方法来实现可证明的统计保障。 |
| [^41] | [The Extractive-Abstractive Axis: Measuring Content "Borrowing" in Generative Language Models.](http://arxiv.org/abs/2307.11779) | 该论文提出了一个名为提取-摘要轴的概念，用于衡量生成语言模型中内容的"借用"程度，并提出了开发相应度量标准、数据集和注释指南的需求。 |
| [^42] | [Question Decomposition Improves the Faithfulness of Model-Generated Reasoning.](http://arxiv.org/abs/2307.11768) | 通过将问题分解为子问题，可以显著提高大型语言模型生成推理的忠实度。 |
| [^43] | [Recognition of Mental Adjectives in An Efficient and Automatic Style.](http://arxiv.org/abs/2307.11767) | 本论文提出了一个新的词汇推理任务MPC，通过微调BERT模型和采用主动学习算法，在简化标注资源的同时达到了令人满意的准确性。通过与SentiWordNet的比较，还发现了MPC与情感分析中的主观性分类任务的差异。 |
| [^44] | [Measuring Perceived Trust in XAI-Assisted Decision-Making by Eliciting a Mental Model.](http://arxiv.org/abs/2307.11765) | 该研究提出了一种通过调取用户的心智模型来测量可解释人工智能模型的感知信任度的方法。通过使用模糊认知图来评估解释对感知信任度的影响，从而为解释人工智能决策提供参考和改进方向。 |
| [^45] | [Rethinking Trust Repair in Human-Robot Interaction.](http://arxiv.org/abs/2307.11763) | 本论文主要研究人机交互中的信任修复，目标是确定有效策略并探索成功潜在机制。 |
| [^46] | [Fairness of ChatGPT and the Role Of Explainable-Guided Prompts.](http://arxiv.org/abs/2307.11761) | 本研究调查了ChatGPT在信用风险评估中的潜力，发现通过精心设计的提示指导和领域特定知识的补充，ChatGPT能够与传统机器学习模型相媲美，使用的数据量少至传统模型的1/40，表现优异，尤其擅长减小误报并提升公平性。这为未来在其他类似任务中充分利用ChatGPT的能力奠定了基础。 |
| [^47] | [EmotionPrompt: Leveraging Psychology for Large Language Models Enhancement via Emotional Stimulus.](http://arxiv.org/abs/2307.11760) | EmotionPrompt是一个基于心理学的方法，通过将情感刺激融入到提示中，提升了大型语言模型在各项任务上的性能，并且同时改善了其真实性和信息量。 |
| [^48] | [Morphological Image Analysis and Feature Extraction for Reasoning with AI-based Defect Detection and Classification Models.](http://arxiv.org/abs/2307.11643) | 本文提出了一个名为AI推理器的解释性模型，能够从图像中提取缺陷的形态学特征，并利用决策树进行推理。它通过可视化和文字说明解释基于掩模的缺陷检测和分类模型的输出，并提供有效的缓解策略以提升整体模型性能。 |
| [^49] | [CausE: Towards Causal Knowledge Graph Embedding.](http://arxiv.org/abs/2307.11610) | CausE是一个采用因果知识图谱嵌入和嵌入解缠的框架，利用因果干预进行稳定预测，并在知识图谱完整性任务上取得了最先进的性能。 |
| [^50] | [AIGC Empowering Telecom Sector White Paper.](http://arxiv.org/abs/2307.11449) | 本文探讨了AIGC（GPT）在电信行业中的应用，提出了一个电信增强认知能力系统，为电信服务的构建提供了解决方案。 |
| [^51] | [Deep Directly-Trained Spiking Neural Networks for Object Detection.](http://arxiv.org/abs/2307.11411) | EMS-YOLO是一种直接训练的脉冲神经网络框架，通过使用替代梯度而不是ANN-SNN转换策略，成功解决了深度SNN的目标检测问题。 |
| [^52] | [LLM Censorship: A Machine Learning Challenge or a Computer Security Problem?.](http://arxiv.org/abs/2307.10719) | 本文讨论了大型语言模型(LLM)的审查问题，指出现有的语义审查方法存在理论上的限制，由于LLM的程序化和遵循指令的能力，语义审查可以被认为是一个不可判定的问题。同时，有知识的攻击者可以重构不可容许的输出。 |
| [^53] | [Detecting deceptive reviews using text classification.](http://arxiv.org/abs/2307.10617) | 这篇论文提出了一种使用机器学习模型的方法来识别虚假评论，并通过在餐馆评论的数据集上进行实验验证了其性能。 |
| [^54] | [Invalid Logic, Equivalent Gains: The Bizarreness of Reasoning in Language Model Prompting.](http://arxiv.org/abs/2307.10573) | 最近的研究发现，在语言模型的提示中使用逻辑上无效的Chain-of-Thought（CoT）提示几乎可以提供与逻辑上有效的提示相似的性能增益，而且在最困难的任务上也是如此。 |
| [^55] | [Air Traffic Controller Workload Level Prediction using Conformalized Dynamical Graph Learning.](http://arxiv.org/abs/2307.10559) | 本研究提出了一种使用合规化动态图学习来预测空中交通管制员工作负荷水平的方法，通过对退休空中交通管制员进行人机交互模拟，利用空中交通数据和工作负荷标签进行预测和评估。 |
| [^56] | [(Ab)using Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs.](http://arxiv.org/abs/2307.10490) | 本论文展示了如何利用图像和声音在多模态LLMs中进行间接指令注入，攻击者通过生成对抗扰动并将其融入图像或音频录音中，以操纵模型输出特定文本和指导对话的行为。 |
| [^57] | [A data science axiology: the nature, value, and risks of data science.](http://arxiv.org/abs/2307.10460) | 这篇论文介绍了数据科学的价值取向，探讨了其特征和作用。数据科学不是一门科学，而是一种研究范式，具有广泛的应用和重大的影响，但也存在着未知的风险。这一领域仍然处于初级阶段，需要进一步的研究。 |
| [^58] | [SentimentGPT: Exploiting GPT for Advanced Sentiment Analysis and its Departure from Current Machine Learning.](http://arxiv.org/abs/2307.10234) | 本研究通过利用GPT进行高级情感分析，并考察其与当前机器学习方法的差异，发现GPT方法相较于其他模型在预测性能上具有显著优势，并有效解决了情感分析任务中的一些挑战，如理解上下文和检测讽刺。 |
| [^59] | [A decision making framework for recommended maintenance of road segments.](http://arxiv.org/abs/2307.10085) | 这项研究提出了一个决策框架，通过整合多种人工智能决策技术和历史数据，为道路管理部门提供科学决策工具和证据，以解决道路维护的问题。 |
| [^60] | [An Empirical Study on Fertility Proposals Using Multi-Grined Topic Analysis Methods.](http://arxiv.org/abs/2307.10025) | 本研究通过采用多粒度主题分析方法，对微博评论进行语义分析，发现关于取消婚姻登记的生育限制的提案涉及个人、社会和国家三个维度，详细讨论了个人行为、社会伦理和法律以及国家政策等社会问题。 |
| [^61] | [PubMed and Beyond: Recent Advances and Best Practices in Biomedical Literature Search.](http://arxiv.org/abs/2307.09683) | 本论文总结了生物医学文献检索领域的最新进展和最佳实践，介绍了针对不同生物医学信息需求的文献检索工具，并旨在帮助读者高效满足其信息需求。 |
| [^62] | [Transformer-based Dual-domain Network for Few-view Dedicated Cardiac SPECT Image Reconstructions.](http://arxiv.org/abs/2307.09624) | 提出了一种基于Transformer的双域网络用于少视角心脏SPECT图像重建，通过定制的投影到图像域转换器直接从投影数据中重建三维心脏SPECT图像，以提高图像质量。 |
| [^63] | [Unsupervised Deep Graph Matching Based on Cycle Consistency.](http://arxiv.org/abs/2307.08930) | 本文提出了一种基于循环一致性的无监督深度图匹配方法，不需要真实对应的关键点对，通过在同一对象类别的图像之间强制匹配一致性来进行自我监督学习，该方法具有很高的灵活性，并且在无监督图匹配方面达到了最新的最先进水平。 |
| [^64] | [Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models.](http://arxiv.org/abs/2307.08303) | 本论文提出了一种使用软提示调优来增强密集检索的方法（SPTAR）。通过优化任务特定的软提示并利用大型语言模型为未标记的文档生成弱查询，可以提高零样本和少样本的密集检索模型的性能。 |
| [^65] | [Disco-Bench: A Discourse-Aware Evaluation Benchmark for Language Modelling.](http://arxiv.org/abs/2307.08074) | Disco-Bench是一个面向语言建模的论述感知评估基准，可以跨多个NLP任务评估句内论述属性。我们设计了文献领域的9个测试集和一个诊断测试套件来评估模型的论述知识。我们在20个不同模型上进行了评估。 |
| [^66] | [Towards Flexible Time-to-event Modeling: Optimizing Neural Networks via Rank Regression.](http://arxiv.org/abs/2307.08044) | 本研究提出了一种深度AFT排名回归模型，用于灵活地进行时间事件建模，从而改善预测性能并减轻严格的假设。 |
| [^67] | [AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge.](http://arxiv.org/abs/2307.07851) | AspectCSE是一种使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入方法，它在信息检索任务中相比之前的最好结果平均提高了3.97%，通过同时考虑多个特定方面的嵌入模型优于单方面嵌入。 |
| [^68] | [Explainable AI with counterfactual paths.](http://arxiv.org/abs/2307.07764) | 本文提出了一种新颖的可解释人工智能方法，使用反事实路径来生成解释。通过确定替代路径，可以提供更直观和可解释的解释模型行为的方式，并帮助识别和减轻模型中的偏见。 |
| [^69] | [Co-Attention Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery.](http://arxiv.org/abs/2307.05182) | 这项研究提出了一种用于机器人手术中视觉问答定位的共同关注门控视觉-语言嵌入方法，可以为医学生和初级外科医生提供学习和理解手术视频的帮助。 |
| [^70] | [Choosing Well Your Opponents: How to Guide the Synthesis of Programmatic Strategies.](http://arxiv.org/abs/2307.04893) | 这篇论文介绍了一种名为2L的算法，该算法能够提供引导合成程序化策略的参考策略，通过在实验中的表现和在MicroRTS锦标赛中的胜利，证明了2L算法相对于其他学习算法的优势。 |
| [^71] | [Comparing Apples to Apples: Generating Aspect-Aware Comparative Sentences from User Review.](http://arxiv.org/abs/2307.03691) | 该论文提出了一个模型，利用用户评论和相关项目特征生成对比评价句子，以帮助用户找到最适合的产品。该模型包括项目编码模块、比较生成模块和个性化解码方法，并通过人类评估验证了生成句子的相关性和真实性。 |
| [^72] | [Efficient Domain Adaptation of Sentence Embeddings using Adapters.](http://arxiv.org/abs/2307.03104) | 本论文提出了一种通过训练轻量级适配器来高效域自适应句子嵌入的方法，避免了微调整个句子嵌入模型的资源消耗。通过训练特定领域的适配器，可以在不同领域中使用同一模型获得良好的性能。 |
| [^73] | [Dynamic Observation Policies in Observation Cost-Sensitive Reinforcement Learning.](http://arxiv.org/abs/2307.02620) | 本文研究了在观测代价敏感强化学习中，强化学习代理在每个时间步不需要昂贵的测量，提出了一种新的方法DMSOA，并在多个环境中进行了评估，结果表明DMSOA能够以更少的决策步骤和测量次数学到更好的策略。 |
| [^74] | [ODD: A Benchmark Dataset for the NLP-based Opioid Related Aberrant Behavior Detection.](http://arxiv.org/abs/2307.02591) | 这个研究介绍了一份名为ODD的新型基准数据集，用于通过分析患者的电子健康记录笔记，检测和分类药物滥用异常行为。这个数据集在药物相关病例的自然语言处理研究中具有重要的创新和贡献。 |
| [^75] | [Defining data science: a new field of inquiry.](http://arxiv.org/abs/2306.16177) | 数据科学是一种新的研究范式，具有潜力和应用广泛性，在40多个学科、数百个研究领域和成千上万个应用中出现。然而，由于其起步阶段，目前存在许多定义的冗余和不一致性的问题。 |
| [^76] | [Towards Open Vocabulary Learning: A Survey.](http://arxiv.org/abs/2306.15880) | 该论文调研了在视觉场景理解领域的开放词汇学习，在与零样本学习和开放集识别等相关概念的比较中，总结和分析了该领域的最新发展。 |
| [^77] | [Chinese Fine-Grained Financial Sentiment Analysis with Large Language Models.](http://arxiv.org/abs/2306.14096) | 本文提出了一个用于企业预警的新型、广泛的中文细粒度金融情感分析数据集FinChina SA，并使用现有开源大语言模型对其进行评估和实验。该数据集将成为推进真实金融情感分析任务探索的宝贵资源。 |
| [^78] | [Learning from Pixels with Expert Observations.](http://arxiv.org/abs/2306.13872) | 本文提出了一种使用专家观察数据的新方法，在像素观测中进行稀疏奖励的机器人操作任务学习。通过使用专家观察数据作为目标条件，该方法能显著改进两种最先进的智能体的性能，同时训练过程中所需的专家行动次数减少了4-20倍，并且优于分层基线模型。 |
| [^79] | [FedSelect: Customized Selection of Parameters for Fine-Tuning during Personalized Federated Learning.](http://arxiv.org/abs/2306.13264) | 本文提出了一种名为FedSelect的新联邦学习框架，通过寻找最佳客户端子网络从而直接个性化客户端子网络结构和参数，同时保留了全局知识，提高了客户端性能。 |
| [^80] | [Transformer Training Strategies for Forecasting Multiple Load Time Series.](http://arxiv.org/abs/2306.10891) | 转换器模型在预测多负载时间序列方面使用全局训练策略比多变量和本地训练策略具有更好的性能，平均降低了21.8%和12.8%的预测误差。 |
| [^81] | [Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects.](http://arxiv.org/abs/2306.10125) | 自监督学习（SSL）在时间序列分析中的应用取得了显著性能，通过减少对标注数据的依赖，即使只有少量标注数据，也能实现高性能。 |
| [^82] | [Range-Restricted Interpolation through Clausal Tableaux.](http://arxiv.org/abs/2306.03572) | 通过Clausal Tableaux证明系统实现可行的范围限制插值算法。 |
| [^83] | [Inference-Time Intervention: Eliciting Truthful Answers from a Language Model.](http://arxiv.org/abs/2306.03341) | 本研究提出推理时间干预（ITI）技术，通过在推理过程中跨越有限数量的注意力头，显着提高大型语言模型的真实性。在TruthfulQA基准上，ITI使LLaMA模型的真实性从32.5%提高到65.1%。ITI是一种最小程度的干扰，计算廉价，且数据效率高。 |
| [^84] | [Neural Natural Language Processing for Long Texts: A Survey of the State-of-the-Art.](http://arxiv.org/abs/2305.16259) | 本文简要概述了长文本的神经自然语言处理的现状，主要包括文档分类和摘要，涵盖了情感分析，同时还探讨了长文本NLP的主要挑战、问题和解决方案。 |
| [^85] | [Syllable Discovery and Cross-Lingual Generalization in a Visually Grounded, Self-Supervised Speech Mode.](http://arxiv.org/abs/2305.11435) | 本文提出采用基于视觉引导的自监督语音模型进行音节发现和跨语言泛化。使用最小割算法和2阶段聚类方法自动预测语音中的音节边界。在英语上表现优于最先进的音节分割方法，并以零样本的方式在爱沙尼亚语上泛化。在其他语言上也取得了成功。 |
| [^86] | [Vision Meets Definitions: Unsupervised Visual Word Sense Disambiguation Incorporating Gloss Information.](http://arxiv.org/abs/2305.01788) | 本文提出了一种无监督的视觉词义消歧方法，通过引入外部词汇知识库的词义信息来解决原来图像-文本匹配模型中的多义词问题。采用贝叶斯推断来加入词义定义，并通过与上下文相关的 GPT-3 定义生成方法，成功解决了词典外问题。 |
| [^87] | [A New Class of Explanations for Classifiers with Non-Binary Features.](http://arxiv.org/abs/2304.14760) | 本文提出了一种适用于具有非二元特征的分类器的新型解释方法，可以提供更多关于决策和基础分类器的信息。 |
| [^88] | [Multiobjective Logistics Optimization for Automated ATM Cash Replenishment Process.](http://arxiv.org/abs/2304.13671) | 本文研究了自动化ATM现金补充流程，提出了一个数学模型并给出了一个工具来评估各种不同的情况。在模拟数据集上，该模型与方法可以削减ATM现金运营成本。 |
| [^89] | [SurgicalGPT: End-to-End Language-Vision GPT for Visual Question Answering in Surgery.](http://arxiv.org/abs/2304.09974) | 本文提出了一种端到端的语言-视觉GPT模型，增强GPT2模型以包括视觉输入，然后微调注意力机制，以在手术VQA任务中更好地理解视觉环境。 |
| [^90] | [Classification of US Supreme Court Cases using BERT-Based Techniques.](http://arxiv.org/abs/2304.08649) | 本文基于BERT技术探究了对美国最高法院案例进行分类的方法，比较了使用BERT模型与其他先进模型的准确性，最终在15个广泛类别上取得了80%的准确度，在279个细粒度类别上取得了60%的准确度。 |
| [^91] | [Fusing Structure from Motion and Simulation-Augmented Pose Regression from Optical Flow for Challenging Indoor Environments.](http://arxiv.org/abs/2304.07250) | 本文探讨了如何在室内环境下进行运动目标的定位，使用了结构运动与模拟数据和深度学习技术。研究者整合光流和相对姿态回归方法帮助解决了因运动模糊、光照变化、重复图案和缺乏特征结构等问题而带来的瓶颈，为室内目标定位提供了更好的方案。 |
| [^92] | [3D Human Pose Estimation via Intuitive Physics.](http://arxiv.org/abs/2303.18246) | 用物理引擎强制实现3D人体姿态估计的物理合理性在实践中有很大困难。这篇论文中开发了一种基于直觉物理的方法，借助压力热图、压力中心和身体质心等术语，在估计3D人体姿态的同时，实现了物理合理性。 |
| [^93] | [Practical and Ethical Challenges of Large Language Models in Education: A Systematic Literature Review.](http://arxiv.org/abs/2303.13379) | LLMs在教育中有自动生成和分析文本内容的潜力。然而，这些创新的实际性和伦理性存在担忧，需要考虑技术可行性、隐私、平等和善意等因素。 |
| [^94] | [BoxSnake: Polygonal Instance Segmentation with Box Supervision.](http://arxiv.org/abs/2303.11630) | BoxSnake是一种新的端到端训练技术，可以仅使用框注释实现有效的多边形实例分割，相较于基于掩膜的弱监督方法，BoxSnake显示出显着的优越性。 |
| [^95] | [Vibration Signal Denoising Using Deep Learning.](http://arxiv.org/abs/2303.11413) | 本文研究了基于深度学习的去除脚步引起的振动信号的噪声的方法，该方法适用于高斯噪声和非平稳噪声。 |
| [^96] | [Opening Up the Neural Network Classifier for Shap Score Computation.](http://arxiv.org/abs/2303.06516) | 本文提出了一种高效计算机器学习模型分类中Shap解释分数的方法，通过将二进制神经网络转换为布尔电路，并使用知识编译技术，将电路视为开放式模型，通过最近的高效算法计算Shap分数，相比于将BNN视为黑盒模型直接计算Shap，性能有了显著的提高。 |
| [^97] | [Lemmas: Generation, Selection, Application.](http://arxiv.org/abs/2303.05854) | 本文研究了引理在自动定理证明中的作用。实验展示了一种结合学习技术的综合系统，能够生成对于自动定理证明器有用的引理，解决了长期未能解决的难题。 |
| [^98] | [MenuCraft: Interactive Menu System Design with Large Language Models.](http://arxiv.org/abs/2303.04496) | MenuCraft是一个基于大型语言模型的AI辅助设计师，通过对话系统与设计师协作，提供了一个交互式菜单设计工具，可以简化菜单设计过程，并支持零/少次学习。 |
| [^99] | [Open-Vocabulary Affordance Detection in 3D Point Clouds.](http://arxiv.org/abs/2303.02401) | 本文提出了一种在3D点云中进行无限数量支撑检测的开放词汇支撑检测方法，通过同时学习支撑文本和点特征来利用支撑之间的语义关系，实现了零-shot检测，能够在没有注释示例的情况下检测以前未见到的支撑。实验结果表明，OpenAD在各种设置上表现出优异性能。 |
| [^100] | [Toward Efficient Gradient-Based Value Estimation.](http://arxiv.org/abs/2301.13757) | 本研究研究了梯度为基础的值估计方法慢的根本原因，并提出了一种低复杂度的方法以解决损失函数带来的不良影响，该方法在效率上比剩余梯度方法更快，几乎具有相同的计算复杂度，并且在经典问题上与TD具有竞争力。 |
| [^101] | [DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature.](http://arxiv.org/abs/2301.11305) | 本论文提出了一种名为DetectGPT的方法，使用概率曲率来判断文本是否由一个给定的大型语言模型生成。该方法不需要训练分类器、收集数据集或明确加水印，只使用模型计算的对数概率和另一个预训练语言模型的随机扰动。实验证明，DetectGPT在模型采样方面比现有的零样本方法更具有区分能力。 |
| [^102] | [Backward Curriculum Reinforcement Learning.](http://arxiv.org/abs/2212.14214) | 这项工作提出了一种新颖的反向课程强化学习方法，通过使用回放轨迹而不是原始的前向轨迹来训练智能体。这种方法通过提供强有力的奖励信号实现了更高效的学习，而且只需要进行微小的算法改变。 |
| [^103] | [A Survey of Knowledge Graph Reasoning on Graph Types: Static, Dynamic, and Multimodal.](http://arxiv.org/abs/2212.05767) | 本文对知识图谱推理进行了综述，涵盖了静态、动态和多模态三种图类型，填补了这一领域的研究空白。 |
| [^104] | [A Hybrid Evolutionary Approach to Solve University Course Allocation Problem.](http://arxiv.org/abs/2212.02230) | 本文提出了一个混合进化算法来解决大学课程分配问题，通过结合局部修复算法和改进的遗传算法，生成了最佳的课程分配方案，同时满足各种约束，提高时间效率并减少工作量。 |
| [^105] | [Offline Reinforcement Learning with Closed-Form Policy Improvement Operators.](http://arxiv.org/abs/2211.15956) | 本文提出了基于行为约束的离线强化学习中的闭合形式策略改进算子，该算子将行为策略建模为高斯混合，利用LogSumExp的下界和Jensen不等式克服了优化困难，能有效处理实际数据集中的异构策略。 |
| [^106] | [FsaNet: Frequency Self-attention for Semantic Segmentation.](http://arxiv.org/abs/2211.15595) | FsaNet是一种用于语义分割的新型自注意机制，通过在不同频段上进行个性化处理，可以在保留边缘的同时促进对象内的相似性。通过消融研究表明，即使不重新训练网络，低频自注意力也可以达到接近或更好的性能。频率自注意力还简化了令牌映射和令牌混合阶段，具有较低的计算复杂性。 |
| [^107] | [Neural Active Learning on Heteroskedastic Distributions.](http://arxiv.org/abs/2211.00928) | 这项研究展示了在异方差分布上进行神经主动学习可能导致灾难性失败，并提出了一种利用微调来减轻这种失败的方法。 |
| [^108] | [Broken Neural Scaling Laws.](http://arxiv.org/abs/2210.14891) | 本文提出了一个平滑破碎的幂律函数形式，可以准确地模拟和外推深度神经网络的缩放行为，适用于各种架构和大量不同任务，包括视觉、语言、音频、视频、生成建模、对比学习、机器人、不确定性估计/校准、对抗鲁棒性、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。 |
| [^109] | [Learning "O" Helps for Learning More: Handling the Concealed Entity Problem for Class-incremental NER.](http://arxiv.org/abs/2210.04676) | 本研究解决了类增量NER中的隐藏实体问题，提出了一种表示学习方法，通过对实体类别和"O"进行判别式表示学习，改善了NER模型对于新旧类别的识别能力。 |
| [^110] | [GMA3D: Local-Global Attention Learning to Estimate Occluded Motions of Scene Flow.](http://arxiv.org/abs/2210.03296) | GMA3D是一个基于变压器框架的模块，应用于解决场景流动中的遮挡问题。该模块利用本地和全局语义相似性推断被遮挡点的运动信息，并使用偏移聚合器进行汇聚。实验结果表明，GMA3D可以有效解决场景流动中的遮挡问题。 |
| [^111] | [Improving Generalizability of Graph Anomaly Detection Models via Data Augmentation.](http://arxiv.org/abs/2209.10168) | 通过数据增强技术，本文针对图异常检测中存在的泛化能力差问题，提出了一种通用且新颖的研究问题：广义图异常检测，旨在同时有效识别训练领域图和未训练领域图上的异常。 |
| [^112] | [R\'{e}nyi Divergence Deep Mutual Learning.](http://arxiv.org/abs/2209.05732) | 本文提出在深度互相学习中使用R\'{e}nyi散度，它能够在不引入大量复杂度的情况下持续提高性能，获得了广泛的实证结果的支持。 |
| [^113] | [DRL Enabled Coverage and Capacity Optimization in STAR-RIS Assisted Networks.](http://arxiv.org/abs/2209.00511) | 这项研究提出了一种用于STAR-RIS辅助网络中覆盖和容量优化问题的多目标近端政策优化（MO-PPO）算法，该算法通过提供一组最优解来实现长期效益，从而改进了传统优化算法的性能。 |
| [^114] | [Target-oriented Sentiment Classification with Sequential Cross-modal Semantic Graph.](http://arxiv.org/abs/2208.09417) | 本文提出了一种基于顺序跨模态语义图的目标导向情感分类方法，通过利用图像标题和场景图提取全局和局部的精细图像信息，与推文中的标记结合形成跨模态语义图，取得了较好的效果。 |
| [^115] | [Self-supervised Learning for Human Activity Recognition Using 700,000 Person-days of Wearable Data.](http://arxiv.org/abs/2206.02909) | 本研究利用700,000人日的未标记可穿戴传感器数据，通过自监督学习技术，成功构建了一种能够在多个数据集上泛化且效果显著优于基线模型的人体活动识别模型，有望帮助研究人员和开发者开发高性能的可定制和泛化的活动分类器。 |
| [^116] | [Physics-Guided Hierarchical Reward Mechanism for Learning-Based Robotic Grasping.](http://arxiv.org/abs/2205.13561) | 本文提出了一种基于物理指导的分层奖励机制的学习型机器人抓取方法，通过利用物理知识提高学习效率和结果的通用性。 |
| [^117] | [Representation Power of Graph Neural Networks: Improved Expressivity via Algebraic Analysis.](http://arxiv.org/abs/2205.09801) | 本文通过代数分析改进了图神经网络（GNN）的表达能力，证明了GNN能够比Weisfeiler-Lehman（WL）算法更好地产生区分性表示，特别是在具有不同特征值的图上。此外，我们还发现简单的卷积结构与无信息输入产生的等变特征比WL表示更具表达能力。 |
| [^118] | [Machine Learning-Friendly Biomedical Datasets for Equivalence and Subsumption Ontology Matching.](http://arxiv.org/abs/2205.03447) | 本文介绍了五个新的生物医学本体匹配任务，通过引入机器学习技术并解决现有评估方法的限制，提供了综合评估框架来衡量本体匹配系统的性能。 |
| [^119] | [AdaBest: Minimizing Client Drift in Federated Learning via Adaptive Bias Estimation.](http://arxiv.org/abs/2204.13170) | AdaBest提出了一种自适应算法，用于准确估计联邦学习中的客户端漂移。与之前的方法相比，AdaBest所需的存储和通信带宽较少，计算成本也较低。此外，AdaBest通过限制估计值的范数来提供稳定性。 |
| [^120] | [Learning to reason about and to act on physical cascading events.](http://arxiv.org/abs/2202.01108) | 本研究提出了一种新的监督学习方法，称为“级联”，通过将语义树搜索与事件驱动的前向模型相结合，学习在连续空间中搜索语义树，并能够在物理模拟的动态场景中有效地遵循干预指令、推理替代结果。 |
| [^121] | [Generalizing similarity in noisy setups: the DIBS phenomenon.](http://arxiv.org/abs/2201.12803) | 本研究揭示了数据密度、噪声和相似性学习之间的相互作用，证明了数据对的密度对于泛化至关重要，并发现了一种在密集数据集上比对称标签噪声更差的泛化性能的现象，称为密度诱导的相似性破坏（DIBS）。 |
| [^122] | [User Tampering in Reinforcement Learning Recommender Systems.](http://arxiv.org/abs/2109.04083) | 本研究揭示了强化学习推荐系统中的一个独特安全问题——用户篡改，并提出了形式化方法和实证证据。现有方法不能有效防止用户篡改，并且现有的奖励篡改缓解策略也不足以解决这一问题。 |
| [^123] | [Co-Imitation Learning without Expert Demonstration.](http://arxiv.org/abs/2103.14823) | 本文提出了一种名为共同模仿学习（CoIL）的新型学习框架，通过利用代理自身的良好经验，而无需专家示范，来改善强化学习的效率。实验结果表明，该方法在各种任务上都具有显著的优越性。 |
| [^124] | [XTQA: Span-Level Explanations of the Textbook Question Answering.](http://arxiv.org/abs/2011.12662) | XTQA是针对教科书问答任务提出的一种新架构，通过跨句解释提供答案和证据，显著提高了性能。 |
| [^125] | [Towards a new Social Choice Theory.](http://arxiv.org/abs/2007.15393) | 这篇论文介绍了一种新的社会选择理论，通过引入社会选择优化作为TAVs的泛化，以最小化对（社会）目标的阻碍。 |
| [^126] | [Declarative Mechanism Design.](http://arxiv.org/abs/1912.13122) | 本文介绍了声明性机制设计的研究，提出了机构神经网络作为一种受管制的人工神经网络，引起人们对人工教学的关注，并提供了初步的答案。 |

# 详细

[^1]: FATRER: 用于准确和稳健的会话情感识别的全注意力主题正则化器

    FATRER: Full-Attention Topic Regularizer for Accurate and Robust Conversational Emotion Recognition. (arXiv:2307.12221v1 [cs.CL])

    [http://arxiv.org/abs/2307.12221](http://arxiv.org/abs/2307.12221)

    本文介绍了一种全注意力主题正则化器，用于增强情感识别器在处理对话中的局部上下文时获得情感相关的全局视角，实验证明该模型在准确性和稳健性方面取得了更好的效果。

    

    本文关注于理解会话话语中引发的对话者情绪。之前的研究主要关注于更准确的情感预测，而忽视了当局部上下文被对抗性攻击破坏时模型的稳健性。为了在保证准确性的同时维持稳健性，我们提出了一种由全注意力主题正则化器增强的情感识别器，在建模对话中的局部上下文时实现情感相关的全局视角。引入联合主题建模策略，从表示和损失的角度实现正则化。为了避免过度正则化，我们放弃了传统主题建模中存在的关于先验分布的限制，并完全依靠注意力对齐进行概率近似。实验证明，我们的模型比现有最先进的模型获得了更有利的结果，并在三种类型的对抗性攻击下获得了令人信服的稳健性。

    This paper concentrates on the understanding of interlocutors' emotions evoked in conversational utterances. Previous studies in this literature mainly focus on more accurate emotional predictions, while ignoring model robustness when the local context is corrupted by adversarial attacks. To maintain robustness while ensuring accuracy, we propose an emotion recognizer augmented by a full-attention topic regularizer, which enables an emotion-related global view when modeling the local context in a conversation. A joint topic modeling strategy is introduced to implement regularization from both representation and loss perspectives. To avoid over-regularization, we drop the constraints on prior distributions that exist in traditional topic modeling and perform probabilistic approximations based entirely on attention alignment. Experiments show that our models obtain more favorable results than state-of-the-art models, and gain convincing robustness under three types of adversarial attacks
    
[^2]: 通过渐进宽松监督加快高分辨率遥感图像建筑物分割的速度

    Expediting Building Footprint Segmentation from High-resolution Remote Sensing Images via progressive lenient supervision. (arXiv:2307.12220v1 [cs.CV])

    [http://arxiv.org/abs/2307.12220](http://arxiv.org/abs/2307.12220)

    本文针对远程感知图像建筑物分割中的模型传递效果问题，提出了一种名为BFSeg的高效框架，通过渐进宽松监督来增强学习的效率和有效性。

    

    远程感知图像的建筑物分割的有效性一直受到模型传递效果的阻碍。许多现有的建筑物分割方法都是基于U-Net的编码器-解码器架构开发的，其中编码器是从在ImageNet上预训练的新开发的骨干网络微调而来。然而，现有解码器设计的大量计算负担阻碍了这些现代编码器网络成功转移到遥感任务上。即使是广泛采用的深度监督策略也无法缓解这些挑战，因为在混合区域，前景和背景像素是交错的，导致其损失无效。本文对于现有的解码器网络设计进行了全面评估，并提出了一种名为BFSeg的高效框架来增强学习的效率和有效性。具体来说，本文提出了一种密集连接的粗到细特征融合解码器网络

    The efficacy of building footprint segmentation from remotely sensed images has been hindered by model transfer effectiveness. Many existing building segmentation methods were developed upon the encoder-decoder architecture of U-Net, in which the encoder is finetuned from the newly developed backbone networks that are pre-trained on ImageNet. However, the heavy computational burden of the existing decoder designs hampers the successful transfer of these modern encoder networks to remote sensing tasks. Even the widely-adopted deep supervision strategy fails to mitigate these challenges due to its invalid loss in hybrid regions where foreground and background pixels are intermixed. In this paper, we conduct a comprehensive evaluation of existing decoder network designs for building footprint segmentation and propose an efficient framework denoted as BFSeg to enhance learning efficiency and effectiveness. Specifically, a densely-connected coarse-to-fine feature fusion decoder network that
    
[^3]: 人工智能法规政策的综合评估与系统分析

    A Comprehensive Review and Systematic Analysis of Artificial Intelligence Regulation Policies. (arXiv:2307.12218v1 [cs.CY])

    [http://arxiv.org/abs/2307.12218](http://arxiv.org/abs/2307.12218)

    本文综合评估了全球不同地区和文化背景下的人工智能法规政策建议，并通过历史教训和系统分析方法，帮助治理机构解决人工智能监管的混乱现状。

    

    由于世界各地的文化和治理差异，目前存在一系列人工智能法规政策建议，从而在全球人工智能监管领域造成了混乱。适当地监管人工智能技术极具挑战性，需要在法律限制与技术发展之间保持微妙的平衡。在本文中，我们首先对来自不同地理位置和文化背景的人工智能法规建议进行全面回顾。然后，借鉴历史教训，我们提出了一个框架，以促进对人工智能法规建议进行深入分析。最后，我们对这些人工智能法规建议进行了系统分析，以了解每个建议可能存在的问题。这项研究包含历史经验和分析方法，旨在通过分而治之的方式帮助治理机构解决人工智能监管的混乱现状。

    Due to the cultural and governance differences of countries around the world, there currently exists a wide spectrum of AI regulation policy proposals that have created a chaos in the global AI regulatory space. Properly regulating AI technologies is extremely challenging, as it requires a delicate balance between legal restrictions and technological developments. In this article, we first present a comprehensive review of AI regulation proposals from different geographical locations and cultural backgrounds. Then, drawing from historical lessons, we develop a framework to facilitate a thorough analysis of AI regulation proposals. Finally, we perform a systematic analysis of these AI regulation proposals to understand how each proposal may fail. This study, containing historical lessons and analysis methods, aims to help governing bodies untangling the AI regulatory chaos through a divide-and-conquer manner.
    
[^4]: DeepCL: 应用度量空间中的深度变化特征学习于遥感图像

    DeepCL: Deep Change Feature Learning on Remote Sensing Images in the Metric Space. (arXiv:2307.12208v1 [cs.CV])

    [http://arxiv.org/abs/2307.12208](http://arxiv.org/abs/2307.12208)

    DeepCL是一种用于遥感图像中的变化检测的深度学习方法，通过结合度量学习和分割，解决了时间关系建模和伪变化误分类的问题。

    

    变化检测是地球观测领域中监测地球表面动态的重要且具有挑战性的任务。深度学习技术的出现最近推动了自动变化检测的技术革命。然而，基于深度学习的变化检测方法仍然存在两个主要问题：1）不充分的时间关系建模和2）伪变化误分类。为了解决这些问题，我们将度量学习的强大时间建模能力与分割的显著拟合能力相结合，提出了一种用于稳健和可解释的变化检测的深度变化特征学习（DeepCL）框架。首先，我们设计了一种具有硬样本感知对比损失，该损失重新权衡了硬样本和简单样本的重要性。这种损失允许显式地建模双时相遥感图像之间的时间相关性。此外，建模的时间关系被用作先验知识来指导分割过程，以便检测变化。

    Change detection (CD) is an important yet challenging task in the Earth observation field for monitoring Earth surface dynamics. The advent of deep learning techniques has recently propelled automatic CD into a technological revolution. Nevertheless, deep learning-based CD methods are still plagued by two primary issues: 1) insufficient temporal relationship modeling and 2) pseudo-change misclassification. To address these issues, we complement the strong temporal modeling ability of metric learning with the prominent fitting ability of segmentation and propose a deep change feature learning (DeepCL) framework for robust and explainable CD. Firstly, we designed a hard sample-aware contrastive loss, which reweights the importance of hard and simple samples. This loss allows for explicit modeling of the temporal correlation between bi-temporal remote sensing images. Furthermore, the modeled temporal relations are utilized as knowledge prior to guide the segmentation process for detecting
    
[^5]: 单子化深度学习

    Monadic Deep Learning. (arXiv:2307.12187v1 [cs.PL])

    [http://arxiv.org/abs/2307.12187](http://arxiv.org/abs/2307.12187)

    DeepLearning.scala 2解决了在静态类型语言中使用神经网络进行训练时的自动求导问题，并提供了一组单子和单子变换器。

    

    Java和Scala社区建立了一个非常成功的大数据生态系统。然而，大部分在其上运行的神经网络是用动态类型编程语言建模的。这些动态类型的深度学习框架将神经网络视为包含许多可训练变量的可微分表达式，并在训练时对这些表达式进行自动求导。直到2019年，静态类型语言的学习框架没有提供传统框架的表达能力。除非创建大量样板代码进行硬编码的反向传播，否则用户无法使用自定义算法。我们在DeepLearning.scala 2中解决了这个问题。我们的贡献是：1.我们发现了一种新的方法，可以对包含多个可训练变量的静态类型函数进行反向模式的自动求导，并且可以自由地与元语言互操作。2.我们设计了一组单子和单子变换器，

    The Java and Scala community has built a very successful big data ecosystem. However, most of neural networks running on it are modeled in dynamically typed programming languages. These dynamically typed deep learning frameworks treat neural networks as differentiable expressions that contain many trainable variable, and perform automatic differentiation on those expressions when training them.  Until 2019, none of the learning frameworks in statically typed languages provided the expressive power of traditional frameworks. Their users are not able to use custom algorithms unless creating plenty of boilerplate code for hard-coded back-propagation.  We solved this problem in DeepLearning.scala 2. Our contributions are:  1. We discovered a novel approach to perform automatic differentiation in reverse mode for statically typed functions that contain multiple trainable variable, and can interoperate freely with the metalanguage.  2. We designed a set of monads and monad transformers, whic
    
[^6]: 机器学习发现辫子和平面辫子的不变量

    Machine learning discovers invariants of braids and flat braids. (arXiv:2307.12185v1 [math.GT])

    [http://arxiv.org/abs/2307.12185](http://arxiv.org/abs/2307.12185)

    本研究使用机器学习对辫子和平面辫子进行分类，得出了新的便利不变量，包括平面辫子的完全不变量。

    

    我们使用机器学习将辫子（或平面辫子）的示例分类为平凡或非平凡。我们的机器学习采用了神经网络（多层感知器）的监督学习形式。当它们在分类任务上取得良好的结果时，我们能够将它们的结构解释为数学猜想，然后证明这些猜想成为定理。结果，在辫子中找到了新的便利不变量，包括平面辫子的完全不变量。

    We use machine learning to classify examples of braids (or flat braids) as trivial or non-trivial. Our ML takes form of supervised learning using neural networks (multilayer perceptrons). When they achieve good results in classification, we are able to interpret their structure as mathematical conjectures and then prove these conjectures as theorems. As a result, we find new convenient invariants of braids, including a complete invariant of flat braids.
    
[^7]: 多维马尔可夫奖励的表达能力

    On the Expressivity of Multidimensional Markov Reward. (arXiv:2307.12184v1 [cs.AI])

    [http://arxiv.org/abs/2307.12184](http://arxiv.org/abs/2307.12184)

    这篇论文研究了马尔可夫奖励在顺序决策中的表达能力，给出了存在这样的奖励函数的条件，并证明了每个非退化的确定性策略集合都可以用多维马尔可夫奖励函数来描述。

    

    我们考虑在不确定性下的顺序决策中，马尔可夫奖励的表达能力。我们将马尔可夫决策过程（MDPs）中的奖励函数视为描述代理行为的手段。假设期望行为被指定为一组可接受策略，我们研究是否存在一个标量或多维马尔可夫奖励函数使得该集合中的策略比其他策略更理想。我们的主要结果陈述了存在这样的奖励函数的必要和充分条件。我们还展示了对于每个非退化的确定性策略集合，都存在一个多维马尔可夫奖励函数来描述它。

    We consider the expressivity of Markov rewards in sequential decision making under uncertainty. We view reward functions in Markov Decision Processes (MDPs) as a means to characterize desired behaviors of agents. Assuming desired behaviors are specified as a set of acceptable policies, we investigate if there exists a scalar or multidimensional Markov reward function that makes the policies in the set more desirable than the other policies. Our main result states both necessary and sufficient conditions for the existence of such reward functions. We also show that for every non-degenerate set of deterministic policies, there exists a multidimensional Markov reward function that characterizes it
    
[^8]: 联邦学习的安全与隐私问题

    Security and Privacy Issues of Federated Learning. (arXiv:2307.12181v1 [cs.CR])

    [http://arxiv.org/abs/2307.12181](http://arxiv.org/abs/2307.12181)

    本论文提出了对联邦学习中的安全和隐私挑战进行全面分类的分类法，并总结了各种攻击类型和新的研究方向，以加强联邦学习系统对新兴安全风险的防范。

    

    联邦学习是一种有望解决数据隐私和保密问题的方法，通过允许多个参与者构建共享模型而不集中敏感数据。然而，这种分散的模式引入了新的安全挑战，需要全面识别和分类潜在的风险，以确保联邦学习的安全保证。本文提出了对各种机器学习模型，包括大规模语言模型，联邦学习中安全和隐私挑战的全面分类。我们特别对聚合器和参与者进行了攻击的分类，重点关注毒化攻击、后门攻击、成员推断攻击、生成对抗网络 (GAN) 攻击和差分隐私攻击。此外，我们还提出了未来研究的新方向，寻求创新解决方案以加强联邦学习系统对新兴安全风险的防范，维护敏感数据的安全。

    Federated Learning (FL) has emerged as a promising approach to address data privacy and confidentiality concerns by allowing multiple participants to construct a shared model without centralizing sensitive data. However, this decentralized paradigm introduces new security challenges, necessitating a comprehensive identification and classification of potential risks to ensure FL's security guarantees. This paper presents a comprehensive taxonomy of security and privacy challenges in Federated Learning (FL) across various machine learning models, including large language models. We specifically categorize attacks performed by the aggregator and participants, focusing on poisoning attacks, backdoor attacks, membership inference attacks, generative adversarial network (GAN) based attacks, and differential privacy attacks. Additionally, we propose new directions for future research, seeking innovative solutions to fortify FL systems against emerging security risks and uphold sensitive data 
    
[^9]: 个人知识图谱中的命名实体消解

    Named Entity Resolution in Personal Knowledge Graphs. (arXiv:2307.12173v1 [cs.AI])

    [http://arxiv.org/abs/2307.12173](http://arxiv.org/abs/2307.12173)

    本文讨论了个人知识图谱中命名实体消解的问题，包括形式化定义、高质量和高效率的解决组件以及应用和未来研究方向。

    

    实体消解（ER）是确定两个实体是否指向相同底层实体的问题。这个问题已经研究了50多年，最近在互联网上发布并在社交媒体、电子商务和搜索等广泛领域中广泛使用的大规模异构的“知识图谱”时代变得更加重要。本章将讨论个人知识图谱（PKG）背景下命名实体消解的具体问题。我们首先提供了问题的形式化定义以及进行高质量和高效率的实体消解所需的组件。我们还讨论了在Web规模数据中预计会出现的一些挑战。接下来，我们对现有技术如何潜在地应用于PKG进行了简要的文献综述。最后，我们覆盖了一些应用，并展望了未来研究的方向。

    Entity Resolution (ER) is the problem of determining when two entities refer to the same underlying entity. The problem has been studied for over 50 years, and most recently, has taken on new importance in an era of large, heterogeneous 'knowledge graphs' published on the Web and used widely in domains as wide ranging as social media, e-commerce and search. This chapter will discuss the specific problem of named ER in the context of personal knowledge graphs (PKGs). We begin with a formal definition of the problem, and the components necessary for doing high-quality and efficient ER. We also discuss some challenges that are expected to arise for Web-scale data. Next, we provide a brief literature review, with a special focus on how existing techniques can potentially apply to PKGs. We conclude the chapter by covering some applications, as well as promising directions for future research.
    
[^10]: 用于训练拥有数十亿参数的大型语言模型的优化网络架构

    Optimized Network Architectures for Large Language Model Training with Billions of Parameters. (arXiv:2307.12169v1 [cs.NI])

    [http://arxiv.org/abs/2307.12169](http://arxiv.org/abs/2307.12169)

    本文提出了一种优化的网络架构，用于训练拥有数十亿参数的大型语言模型。这个架构根据语言模型的通信需求，将集群分割成一组通过非阻塞高带宽互连的GPU集合，并通过轨道连接仅连接具有通信需求的GPU，从而降低网络成本高达75％，同时不影响训练性能。

    

    本文挑战了为训练大型语言模型（LLMs）构建任意到任意网络的传统范式。我们展示了LLMs呈现出一种独特的通信模式，在其中，只有小组的GPU需要高带宽的任意到任意通信，以实现接近最优的训练性能。在这些GPU小组之间，通信非常微不足道、稀疏且均匀。我们提出了一个新的网络架构，紧密匹配LLMs的通信需求。我们的架构将集群分割为一组通过非阻塞任意到任意高带宽互连的GPU集合，我们称之为HB域。在HB域之间，网络只连接具有通信需求的GPU。我们将这种网络连接称为“仅轨道连接”，并展示了我们的架构相对于最先进的任意到任意Clos网络可以将网络成本降低高达75％，同时不损害LLM训练的性能。

    This paper challenges the well-established paradigm for building any-to-any networks for training Large Language Models (LLMs). We show that LLMs exhibit a unique communication pattern where only small groups of GPUs require high-bandwidth any-to-any communication within them, to achieve near-optimal training performance. Across these groups of GPUs, the communication is insignificant, sparse, and homogeneous. We propose a new network architecture that closely resembles the communication requirement of LLMs. Our architecture partitions the cluster into sets of GPUs interconnected with non-blocking any-to-any high-bandwidth interconnects that we call HB domains. Across the HB domains, the network only connects GPUs with communication demands. We call this network a "rail-only" connection, and show that our proposed architecture reduces the network cost by up to 75% compared to the state-of-the-art any-to-any Clos networks without compromising the performance of LLM training.
    
[^11]: 幻觉改进了无监督视觉表示学习的性能

    Hallucination Improves the Performance of Unsupervised Visual Representation Learning. (arXiv:2307.12168v1 [cs.CV])

    [http://arxiv.org/abs/2307.12168](http://arxiv.org/abs/2307.12168)

    幻觉生成模型可以为对比学习提供额外的正样本，改进了无监督视觉表示学习的性能。

    

    基于连体结构的对比学习模型在自监督学习中取得了显著的性能。对比学习的成功依赖于两个条件：足够数量的正对和适当的变化。如果这些条件不满足，这些框架将缺乏语义对比，并且容易过拟合。为了解决这两个问题，我们提出了Hallucinator，它能够有效地生成额外的正样本以进一步进行对比。Hallucinator是可微分的，并在特征空间中创建新的数据。因此，它可以直接与预训练任务一起进行优化，并引入几乎可忽略的计算量。此外，我们通过非线性操作减少了幻觉对的互信息并使其平滑。这个过程有助于避免训练过程中对比学习模型过于自信，并实现更具变换不变性的特征嵌入。值得注意的是，我们通过实验证明了这个提议。

    Contrastive learning models based on Siamese structure have demonstrated remarkable performance in self-supervised learning. Such a success of contrastive learning relies on two conditions, a sufficient number of positive pairs and adequate variations between them. If the conditions are not met, these frameworks will lack semantic contrast and be fragile on overfitting. To address these two issues, we propose Hallucinator that could efficiently generate additional positive samples for further contrast. The Hallucinator is differentiable and creates new data in the feature space. Thus, it is optimized directly with the pre-training task and introduces nearly negligible computation. Moreover, we reduce the mutual information of hallucinated pairs and smooth them through non-linear operations. This process helps avoid over-confident contrastive learning models during the training and achieves more transformation-invariant feature embeddings. Remarkably, we empirically prove that the propo
    
[^12]: 模仿游戏：在大型语言模型时代检测人类和AI生成的文本

    The Imitation Game: Detecting Human and AI-Generated Texts in the Era of Large Language Models. (arXiv:2307.12166v1 [cs.CL])

    [http://arxiv.org/abs/2307.12166](http://arxiv.org/abs/2307.12166)

    本论文研究了区分人类和AI生成的文本的任务，在不同体裁下进行了比较研究，提出了一个新的数据集，并采用多种机器学习模型进行分类。结果表明这些模型对于区分人类和AI生成的文本具有很高的效力，尽管在区分GPT生成的文本方面存在一定挑战。

    

    基于人工智能的大型语言模型（LLM）具有革新教育、研究和实践的巨大潜力。然而，区分人类写作和AI生成的文本已经成为一项重要任务。本文介绍了一项比较研究，提出了一个新颖的数据集，包含不同体裁的人类写作和LLM生成的文本：论文、故事、诗歌和Python代码。我们采用了几种机器学习模型来对这些文本进行分类。结果表明，尽管数据集的样本数量有限，这些模型在区分人类和AI生成的文本方面表现出了很高的效力。然而，当分类GPT生成的文本时，任务变得更具挑战性，特别是在故事写作方面。结果表明，与更复杂的多类别任务相比，这些模型在二元分类任务（如区分人类生成文本和特定LLM）方面表现出了更优越的性能。

    The potential of artificial intelligence (AI)-based large language models (LLMs) holds considerable promise in revolutionizing education, research, and practice. However, distinguishing between human-written and AI-generated text has become a significant task. This paper presents a comparative study, introducing a novel dataset of human-written and LLM-generated texts in different genres: essays, stories, poetry, and Python code. We employ several machine learning models to classify the texts. Results demonstrate the efficacy of these models in discerning between human and AI-generated text, despite the dataset's limited sample size. However, the task becomes more challenging when classifying GPT-generated text, particularly in story writing. The results indicate that the models exhibit superior performance in binary classification tasks, such as distinguishing human-generated text from a specific LLM, compared to the more complex multiclass tasks that involve discerning among human-ge
    
[^13]: DIP-RL：在Minecraft中的演示推导偏好学习

    DIP-RL: Demonstration-Inferred Preference Learning in Minecraft. (arXiv:2307.12158v1 [cs.LG])

    [http://arxiv.org/abs/2307.12158](http://arxiv.org/abs/2307.12158)

    DIP-RL是一种利用人类演示的算法，在非结构化和开放的环境中通过多种方式推导偏好并学习奖励函数，其在Minecraft中的砍树任务中表现出了竞争力。

    

    在机器学习中的顺序决策过程中，算法代理通过接收奖励信号的反馈来与环境进行交互学习。然而，在许多非结构化的现实世界环境中，这样的奖励信号是未知的，并且人类无法可靠地构建一个正确捕捉所需行为的奖励信号。为了在这样的非结构化和开放的环境中完成任务，我们提出了Demonstration-Inferred Preference Reinforcement Learning (DIP-RL)，这是一种利用人类演示的算法，包括训练自编码器，用演示数据种子强化学习 (RL)训练批次，并推导出偏好以学习引导RL的奖励函数。我们在Minecraft中的砍树任务中评估了DIP-RL。结果表明，该方法能够指导RL代理学习一个反映人类偏好的奖励函数，并且相对于基准模型，DIP-RL表现出了竞争力。

    In machine learning for sequential decision-making, an algorithmic agent learns to interact with an environment while receiving feedback in the form of a reward signal. However, in many unstructured real-world settings, such a reward signal is unknown and humans cannot reliably craft a reward signal that correctly captures desired behavior. To solve tasks in such unstructured and open-ended environments, we present Demonstration-Inferred Preference Reinforcement Learning (DIP-RL), an algorithm that leverages human demonstrations in three distinct ways, including training an autoencoder, seeding reinforcement learning (RL) training batches with demonstration data, and inferring preferences over behaviors to learn a reward function to guide RL. We evaluate DIP-RL in a tree-chopping task in Minecraft. Results suggest that the method can guide an RL agent to learn a reward function that reflects human preferences and that DIP-RL performs competitively relative to baselines. DIP-RL is inspi
    
[^14]: 强化学习中自适应昼夜节律的出现

    Emergence of Adaptive Circadian Rhythms in Deep Reinforcement Learning. (arXiv:2307.12143v1 [cs.AI])

    [http://arxiv.org/abs/2307.12143](http://arxiv.org/abs/2307.12143)

    本文研究了深度强化学习智能体中自适应昼夜节律的出现，通过在周期性变化环境中进行觅食任务，证明了智能体能够内化环境信号并适应相位变化，这一自适应过程是通过人工神经元的动力学来实现的。

    

    适应环境的规律对生物有重要意义，使其能够预测事件和制定计划。其中一个显著的例子是生物对地球自转24小时周期的内化，即昼夜节律。本文研究了深度强化学习智能体中类似昼夜节律的出现。具体而言，我们在一个周期性变化可靠的环境中部署了智能体，并解决了一个觅食任务。我们系统地表征了智能体在学习过程中的行为，并证明了一个内源性且可调匹的节律的出现。有趣的是，内部节律适应了环境信号相位的变化，而无需重新训练。此外，我们通过分岔和相位响应曲线分析展示了人工神经元如何发展出支持环境节律内化的动力学。从动力学系统视角看，我们证明了此自适应过程的实现方式。

    Adapting to regularities of the environment is critical for biological organisms to anticipate events and plan. A prominent example is the circadian rhythm corresponding to the internalization by organisms of the $24$-hour period of the Earth's rotation. In this work, we study the emergence of circadian-like rhythms in deep reinforcement learning agents. In particular, we deployed agents in an environment with a reliable periodic variation while solving a foraging task. We systematically characterize the agent's behavior during learning and demonstrate the emergence of a rhythm that is endogenous and entrainable. Interestingly, the internal rhythm adapts to shifts in the phase of the environmental signal without any re-training. Furthermore, we show via bifurcation and phase response curve analyses how artificial neurons develop dynamics to support the internalization of the environmental rhythm. From a dynamical systems view, we demonstrate that the adaptation proceeds by the emergenc
    
[^15]: 使用自然启发算法进行路线规划

    Route Planning Using Nature-Inspired Algorithms. (arXiv:2307.12133v1 [cs.AI])

    [http://arxiv.org/abs/2307.12133](http://arxiv.org/abs/2307.12133)

    这篇论文介绍了自然启发算法（NIAs）及其在路线规划问题中的应用。NIAs是一类启发式算法，受自然现象启发，通过收敛和随机特性给出最优结果。在机器人中的路线规划问题中，NIAs能够有效地帮助机器人避免环境中的障碍物。

    

    有很多不同的启发式算法用于解决组合优化问题，通常被称为自然启发算法（NIAs）。它们通常受某些自然现象的启发，并由于其固有的收敛和随机特性而被认为在与传统方法相比时给出最优结果。NIAs有很多应用，其中最流行的可能是在机器人中的路线规划问题，这些问题需要从起点到目标以优化的方式避开环境中的障碍物时的一系列平移和旋转步骤。在本章中，我们将首先概述自然启发算法，然后介绍它们的分类和常见示例。然后我们将讨论如何应用NIAs来解决路线规划问题。

    There are many different heuristic algorithms for solving combinatorial optimization problems that are commonly described as Nature-Inspired Algorithms (NIAs). Generally, they are inspired by some natural phenomenon, and due to their inherent converging and stochastic nature, they are known to give optimal results when compared to classical approaches. There are a large number of applications of NIAs, perhaps the most popular being route planning problems in robotics - problems that require a sequence of translation and rotation steps from the start to the goal in an optimized manner while avoiding obstacles in the environment. In this chapter, we will first give an overview of Nature-Inspired Algorithms, followed by their classification and common examples. We will then discuss how the NIAs have applied to solve the route planning problem.
    
[^16]: AI在道路上的应用：智能城市中交通事故及事故检测系统的综合分析

    AI on the Road: A Comprehensive Analysis of Traffic Accidents and Accident Detection System in Smart Cities. (arXiv:2307.12128v1 [cs.CV])

    [http://arxiv.org/abs/2307.12128](http://arxiv.org/abs/2307.12128)

    本文分析了智能城市中交通事故及事故检测系统的综合方法。通过利用交通监控摄像头和行为识别系统，可以实时检测和响应交通事故，并将其与紧急服务整合，以减少人为错误和改善交通安全。

    

    事故检测和交通分析是智能城市和自动化交通系统的关键组成部分，可以减少事故频率和严重程度，改善交通管理。本文利用美国国家公路交通安全管理局（NHTSA）的Crash Report Sampling System（CRSS）的数据，对美国不同地区的交通事故进行了全面分析。为了应对事故检测和交通分析的挑战，本文提出了一个框架，利用交通监控摄像头和行为识别系统来即时检测和响应交通事故。将所提出的框架与紧急服务整合，将交通摄像头和机器学习算法的力量用于响应交通事故和减少人为错误。智能城市中的事故检测系统等先进智能技术将改善交通安全，提高交通效率。

    Accident detection and traffic analysis is a critical component of smart city and autonomous transportation systems that can reduce accident frequency, severity and improve overall traffic management. This paper presents a comprehensive analysis of traffic accidents in different regions across the United States using data from the National Highway Traffic Safety Administration (NHTSA) Crash Report Sampling System (CRSS). To address the challenges of accident detection and traffic analysis, this paper proposes a framework that uses traffic surveillance cameras and action recognition systems to detect and respond to traffic accidents spontaneously. Integrating the proposed framework with emergency services will harness the power of traffic cameras and machine learning algorithms to create an efficient solution for responding to traffic accidents and reducing human errors. Advanced intelligence technologies, such as the proposed accident detection systems in smart cities, will improve tra
    
[^17]: 个性化医疗革命：利用移动AIGC实现人类数字孪生

    A Revolution of Personalized Healthcare: Enabling Human Digital Twin with Mobile AIGC. (arXiv:2307.12115v1 [cs.NI])

    [http://arxiv.org/abs/2307.12115](http://arxiv.org/abs/2307.12115)

    移动AIGC技术可以推动人类数字孪生在个性化医疗中的应用，包括生成罕见疾病数据、建模高保真数字孪生以及提供24/7定制医疗服务。

    

    移动人工智能生成内容（AIGC）技术指的是在移动边缘网络上采用AI算法自动化信息创建过程，同时满足终端用户的需求。移动AIGC最近引起了极大的关注，并且可以成为人类数字孪生（HDT）的关键技术。移动AIGC驱动的HDT有望通过生成罕见疾病数据、建模高保真数字孪生、构建多功能试验平台和提供全天候定制医疗服务来革命性地改变个性化医疗。为了推动这一新型范式的发展，在本文中，我们提出了一个移动AIGC驱动的HDT系统架构，并强调了相应的设计要求和挑战。此外，我们还举例说明了两种用例，即在定制手术规划和个性化药物治疗中使用移动AIGC驱动的HDT。此外，我们进行了一项实验性研究。

    Mobile Artificial Intelligence-Generated Content (AIGC) technology refers to the adoption of AI algorithms deployed at mobile edge networks to automate the information creation process while fulfilling the requirements of end users. Mobile AIGC has recently attracted phenomenal attentions and can be a key enabling technology for an emerging application, called human digital twin (HDT). HDT empowered by the mobile AIGC is expected to revolutionize the personalized healthcare by generating rare disease data, modeling high-fidelity digital twin, building versatile testbeds, and providing 24/7 customized medical services. To promote the development of this new breed of paradigm, in this article, we propose a system architecture of mobile AIGC-driven HDT and highlight the corresponding design requirements and challenges. Moreover, we illustrate two use cases, i.e., mobile AIGC-driven HDT in customized surgery planning and personalized medication. In addition, we conduct an experimental stud
    
[^18]: 零样本和少样本情况下应用于临床和生物医学任务的指导细调大型语言模型的研究

    A Zero-shot and Few-shot Study of Instruction-Finetuned Large Language Models Applied to Clinical and Biomedical Tasks. (arXiv:2307.12114v1 [cs.CL])

    [http://arxiv.org/abs/2307.12114](http://arxiv.org/abs/2307.12114)

    这项研究评估了四种指导细调大型语言模型在临床和生物医学任务上的表现，并发现它们在零样本和少样本情况下接近最先进模型的性能，尤其在问答任务上表现良好。然而，在分类和关系抽取任务上的表现稍逊于特定训练于医学领域的模型。没有一个模型在所有研究任务上胜过其他模型，有些模型更适合特定任务。

    

    我们评估了四种最先进的指导细调大型语言模型（LLM）——ChatGPT、Flan-T5 UL2、Tk-Instruct和Alpaca——在13个实际世界的临床和生物医学自然语言处理（NLP）任务中的表现，例如命名实体识别（NER）、问答（QA）、关系抽取（RE）等。我们的综合结果表明，在大多数任务的零样本和少样本情况下，评估的LLM开始接近最先进模型的性能，尤其对于QA任务表现得特别好，即使它们之前没有见过这些任务的示例。然而，我们观察到分类和关系抽取任务的表现低于特定训练于医学领域的模型（如PubMedBERT）可以达到的水平。最后，我们注意到没有一个LLM在所有研究任务上都胜过其他模型，有些模型更适合于特定的任务。

    We evaluate four state-of-the-art instruction-tuned large language models (LLMs) -- ChatGPT, Flan-T5 UL2, Tk-Instruct, and Alpaca -- on a set of 13 real-world clinical and biomedical natural language processing (NLP) tasks in English, such as named-entity recognition (NER), question-answering (QA), relation extraction (RE), etc. Our overall results demonstrate that the evaluated LLMs begin to approach performance of state-of-the-art models in zero- and few-shot scenarios for most tasks, and particularly well for the QA task, even though they have never seen examples from these tasks before. However, we observed that the classification and RE tasks perform below what can be achieved with a specifically trained model for the medical field, such as PubMedBERT. Finally, we noted that no LLM outperforms all the others on all the studied tasks, with some models being better suited for certain tasks than others.
    
[^19]: CFR-p: 带有分层策略抽象的反事实遗憾最小化算法及其在两人麻将中的应用

    CFR-p: Counterfactual Regret Minimization with Hierarchical Policy Abstraction, and its Application to Two-player Mahjong. (arXiv:2307.12087v1 [cs.AI])

    [http://arxiv.org/abs/2307.12087](http://arxiv.org/abs/2307.12087)

    本研究将反事实遗憾最小化算法应用于两人麻将，并通过分层策略抽象实现了游戏论分析，该框架可推广到其他不完全信息游戏。

    

    反事实遗憾最小化(CFR)算法在德州扑克中取得了成功。我们将该算法应用于另一种流行的不完全信息游戏，麻将。与扑克游戏相比，麻将更加复杂，有许多变体。我们通过进行博弈论分析并基于获胜策略对CFR进行分层抽象，研究了两人麻将。这个框架可以推广到其他不完全信息游戏。

    Counterfactual Regret Minimization(CFR) has shown its success in Texas Hold'em poker. We apply this algorithm to another popular incomplete information game, Mahjong. Compared to the poker game, Mahjong is much more complex with many variants. We study two-player Mahjong by conducting game theoretical analysis and making a hierarchical abstraction to CFR based on winning policies. This framework can be generalized to other imperfect information games.
    
[^20]: 增强时间规划领域的连续宏动作（扩展版）

    Enhancing Temporal Planning Domains by Sequential Macro-actions (Extended Version). (arXiv:2307.12081v1 [cs.AI])

    [http://arxiv.org/abs/2307.12081](http://arxiv.org/abs/2307.12081)

    该论文提出了一种通用的顺序时间宏动作的概念，用于增强时间规划领域中的性能和处理复杂的资源冲突问题。

    

    时间规划是经典规划的扩展，涉及行动的并发执行和与时间约束的对齐。持续动作和不变量使得能够建模多个代理在共享资源上并行操作的领域。因此，在避免资源冲突方面通常很重要，其中时间约束确立了并发行动和事件的一致性。不幸的是，当领域中的代理和对象数量变大时，时间规划引擎的性能往往会急剧下降。一个可能的解决方法是使用在经典规划的上下文中已经研究过的宏动作。然而，在时间规划设置中，引入宏动作要困难得多，因为不应完全抑制行动的并发执行和共享资源的使用，同时要满足时间约束。我们的工作提出了一种通用的顺序时间宏动作的概念。

    Temporal planning is an extension of classical planning involving concurrent execution of actions and alignment with temporal constraints. Durative actions along with invariants allow for modeling domains in which multiple agents operate in parallel on shared resources. Hence, it is often important to avoid resource conflicts, where temporal constraints establish the consistency of concurrent actions and events. Unfortunately, the performance of temporal planning engines tends to sharply deteriorate when the number of agents and objects in a domain gets large. A possible remedy is to use macro-actions that are well-studied in the context of classical planning. In temporal planning settings, however, introducing macro-actions is significantly more challenging when the concurrent execution of actions and shared use of resources, provided the compliance to temporal constraints, should not be suppressed entirely. Our work contributes a general concept of sequential temporal macro-actions t
    
[^21]: 游戏理论的鲁棒强化学习处理时间耦合的干扰

    Game-Theoretic Robust Reinforcement Learning Handles Temporally-Coupled Perturbations. (arXiv:2307.12062v1 [cs.LG])

    [http://arxiv.org/abs/2307.12062](http://arxiv.org/abs/2307.12062)

    这篇论文提出了一种新的鲁棒强化学习方法，通过将时间耦合的鲁棒强化学习问题视为两人零和游戏来处理问题，并通过找到近似均衡来确保代理对时间耦合干扰的鲁棒性。实验结果显示，该方法在各种连续控制任务中相比基准方法表现出显著的鲁棒性优势。

    

    鲁棒强化学习旨在训练能够在环境干扰或对抗攻击下表现良好的策略。现有方法通常假设可能干扰的空间在各个时间步骤保持不变。然而，在许多情况下，给定时间步骤上可能干扰的空间取决于过去的干扰。我们正式引入时间耦合干扰，对现有的鲁棒强化学习方法提出了新的挑战。为了应对这个挑战，我们提出了GRAD，一种新的游戏理论方法，将时间耦合鲁棒强化学习问题视为部分可观察的两人零和游戏。通过在这个游戏中找到一个近似均衡，GRAD确保了代理的对时间耦合干扰的鲁棒性。对各种连续控制任务的实证实验表明，我们提出的方法相比基准方法在标准和时间耦合干扰下具有显著的鲁棒性优势。

    Robust reinforcement learning (RL) seeks to train policies that can perform well under environment perturbations or adversarial attacks. Existing approaches typically assume that the space of possible perturbations remains the same across timesteps. However, in many settings, the space of possible perturbations at a given timestep depends on past perturbations. We formally introduce temporally-coupled perturbations, presenting a novel challenge for existing robust RL methods. To tackle this challenge, we propose GRAD, a novel game-theoretic approach that treats the temporally-coupled robust RL problem as a partially-observable two-player zero-sum game. By finding an approximate equilibrium in this game, GRAD ensures the agent's robustness against temporally-coupled perturbations. Empirical experiments on a variety of continuous control tasks demonstrate that our proposed approach exhibits significant robustness advantages compared to baselines against both standard and temporally-coupl
    
[^22]: 使用图形处理单元快速完成知识图谱

    Fast Knowledge Graph Completion using Graphics Processing Units. (arXiv:2307.12059v1 [cs.AI])

    [http://arxiv.org/abs/2307.12059](http://arxiv.org/abs/2307.12059)

    本文提出了一种在GPU上高效完成知识图谱补全的框架，通过使用知识图谱嵌入矢量来添加新关系。该框架将知识图谱补全问题转化为相似性连接问题，并提供了一种高效处理相似性连接问题的方法。

    

    知识图谱可以在与数据语义相关的多个领域中使用，例如问答系统和基于知识的系统。然而，目前构建的知识图谱需要通过补充关系来获得更好的知识。这被称为知识图谱补全。为了通过使用知识图谱嵌入模型向现有知识图谱添加新关系，我们必须评估N×N×R个矢量操作，其中N是实体数量，R是关系类型数量。这非常昂贵。在本文中，我们提供了一个在GPU上高效完成知识图谱补全任务的框架，以获取使用知识图谱嵌入矢量的新关系。在提出的框架中，我们首先定义了“可以转换为度量空间”，然后提供了一种将知识图谱补全问题转化为“可以转换为度量空间”的模型的相似性连接问题的方法。之后，为了高效处理相似性连接问题，我们

    Knowledge graphs can be used in many areas related to data semantics such as question-answering systems, knowledge based systems. However, the currently constructed knowledge graphs need to be complemented for better knowledge in terms of relations. It is called knowledge graph completion. To add new relations to the existing knowledge graph by using knowledge graph embedding models, we have to evaluate $N\times N \times R$ vector operations, where $N$ is the number of entities and $R$ is the number of relation types. It is very costly.  In this paper, we provide an efficient knowledge graph completion framework on GPUs to get new relations using knowledge graph embedding vectors. In the proposed framework, we first define "transformable to a metric space" and then provide a method to transform the knowledge graph completion problem into the similarity join problem for a model which is "transformable to a metric space". After that, to efficiently process the similarity join problem, we
    
[^23]: 外部推理：朝着多种大型语言模型可互换辅助与人类反馈的方向前进

    External Reasoning: Towards Multi-Large-Language-Models Interchangeable Assistance with Human Feedback. (arXiv:2307.12057v1 [cs.CL])

    [http://arxiv.org/abs/2307.12057](http://arxiv.org/abs/2307.12057)

    本文提出通过从外部存储库中选择性地集成知识来增强大型语言模型，提出了一种外部推理的新方法，例子是ChatPDF。

    

    记忆被认为是使海马体和脑神经元内保持视觉和语言信息、随后用于解决通过学习一生中遇到的现实挑战的关键人类能力。通过应用已获得的知识解决复杂的人工智能任务是实现人工通用智能的一大进展。然而，尽管像GPT-3.5和GPT-4这样的大型语言模型在语言理解、生成、交互和推理方面显示了卓越的能力，但由于上下文长度的限制，它们无法处理广泛、不断演变的知识库。本文提出通过从外部存储库中选择性地集成知识来增强LLMs，并介绍了一种外部推理的新方法，例子是ChatPDF。

    Memory is identified as a crucial human faculty that allows for the retention of visual and linguistic information within the hippocampus and neurons in the brain, which can subsequently be retrieved to address real-world challenges that arise through a lifetime of learning. The resolution of complex AI tasks through the application of acquired knowledge represents a stride toward the realization of artificial general intelligence. However, despite the prevalence of Large Language Models (LLMs) like GPT-3.5 and GPT-4 , which have displayed remarkable capabilities in language comprehension, generation, interaction, and reasoning, they are inhibited by constraints on context length that preclude the processing of extensive, continually evolving knowledge bases. This paper proposes that LLMs could be augmented through the selective integration of knowledge from external repositories, and in doing so, introduces a novel methodology for External Reasoning, exemplified by ChatPDF. Central to
    
[^24]: 通过数据驱动的多步预测血糖预测器的模型预测控制（MPC）人工胰腺

    Model Predictive Control (MPC) of an Artificial Pancreas with Data-Driven Learning of Multi-Step-Ahead Blood Glucose Predictors. (arXiv:2307.12015v1 [eess.SY])

    [http://arxiv.org/abs/2307.12015](http://arxiv.org/abs/2307.12015)

    本文介绍了一种通过数据驱动的多步血糖预测器与线性时变模型预测控制（MPC）相结合的闭环胰岛素输送算法设计，用于治疗1型糖尿病。作者通过直接拟合整个血糖预测曲线，结合非线性和线性模型，与传统线性MPC进行对比，评估了算法的优劣。

    

    我们提出了一个封闭式胰岛素输送算法的设计和\textit{in-silico}评估，用于治疗1型糖尿病（T1D），该算法包括一个基于数据驱动的多步前瞻血糖(BG)预测器，与一个线性时变（LTV）模型预测控制（MPC）框架集成。我们建议直接拟合整个BG预测曲线，作为MPC中预定义预测时间范围内的非线性函数，这个非线性函数由过去的输入-输出数据和未来的胰岛素控制输入的线性函数组成。对于非线性部分，我们提出了一个长短期记忆（LSTM）网络，而对于线性部分，选择了线性回归模型。为了评估与从数据中识别出的传统线性MPC（基于自回归外生（ARX）输入模型）相比的优劣，我们在三个模拟场景中评估了提议的LSTM-MPC控制器：一个正常情况wit

    We present the design and \textit{in-silico} evaluation of a closed-loop insulin delivery algorithm to treat type 1 diabetes (T1D) consisting in a data-driven multi-step-ahead blood glucose (BG) predictor integrated into a Linear Time-Varying (LTV) Model Predictive Control (MPC) framework. Instead of identifying an open-loop model of the glucoregulatory system from available data, we propose to directly fit the entire BG prediction over a predefined prediction horizon to be used in the MPC, as a nonlinear function of past input-ouput data and an affine function of future insulin control inputs. For the nonlinear part, a Long Short-Term Memory (LSTM) network is proposed, while for the affine component a linear regression model is chosen. To assess benefits and drawbacks when compared to a traditional linear MPC based on an auto-regressive with exogenous (ARX) input model identified from data, we evaluated the proposed LSTM-MPC controller in three simulation scenarios: a nominal case wit
    
[^25]: 用基于人工智能的大型语言模型扩展全球心理健康心理服务的Psy-LLM

    Psy-LLM: Scaling up Global Mental Health Psychological Services with AI-based Large Language Models. (arXiv:2307.11991v1 [cs.CL])

    [http://arxiv.org/abs/2307.11991](http://arxiv.org/abs/2307.11991)

    Psy-LLM是一个基于人工智能的系统，利用大型语言模型（LLMs）为在线心理咨询提供问答服务，前端工具可让医疗专业人员提供即时响应和正念活动，同时还可作为筛查工具辅助识别紧急案例。

    

    近年来，心理咨询的需求显著增长，特别是随着全球COVID-19的爆发，这加强了及时和专业的心理健康支持的需求。在线心理咨询成为应对这一需求的主要服务方式。在本研究中，我们提出了Psy-LLM框架，这是一种基于人工智能的系统，利用大型语言模型（LLMs）进行在线心理咨询中的问答。我们的框架结合了经过预训练的LLMs和从心理学家和广泛收集的心理文章中获取的真实世界专业问答。Psy-LLM框架作为医疗专业人员的前端工具，允许他们提供即时响应和正念活动来缓解患者压力，同时还可以作为筛查工具，识别需要进一步协助的紧急案例。我们使用困惑度等内在度量标准和外部度量标准对框架进行了评估。

    The demand for psychological counseling has grown significantly in recent years, particularly with the global outbreak of COVID-19, which has heightened the need for timely and professional mental health support. Online psychological counseling has emerged as the predominant mode of providing services in response to this demand. In this study, we propose the Psy-LLM framework, an AI-based system leveraging Large Language Models (LLMs) for question-answering in online psychological consultation. Our framework combines pre-trained LLMs with real-world professional Q&A from psychologists and extensively crawled psychological articles. The Psy-LLM framework serves as a front-end tool for healthcare professionals, allowing them to provide immediate responses and mindfulness activities to alleviate patient stress. Additionally, it functions as a screening tool to identify urgent cases requiring further assistance. We evaluated the framework using intrinsic metrics, such as perplexity, and ex
    
[^26]: 稀疏化再剪枝：向高效的视觉Transformer模型过渡

    Sparse then Prune: Toward Efficient Vision Transformers. (arXiv:2307.11988v1 [cs.CV])

    [http://arxiv.org/abs/2307.11988](http://arxiv.org/abs/2307.11988)

    本研究探讨了在视觉Transformer模型上应用稀疏正则化和剪枝的方法，结果表明在稀疏正则化之后进行剪枝可以显著减少模型计算负担而不损失太多性能。

    

    视觉Transformer模型是受到自然语言处理中Transformer模型成功启发的深度学习模型。然而，自注意机制、大量参数以及对大量训练数据的需求仍使得视觉Transformer计算上的负担较重。本研究探讨了在视觉Transformer上应用稀疏正则化的可能性，并研究了在性能和效率之间的权衡上，无论是在稀疏正则化之后还是之前进行剪枝的影响。为了实现这一目标，我们将稀疏正则化和剪枝方法应用于用于CIFAR-10、CIFAR-100和ImageNet-100数据集的图像分类任务中的视觉Transformer模型。视觉Transformer模型的训练过程包括两个部分：预训练和微调。预训练使用ImageNet21K数据，然后进行20个epoch的微调。结果表明，当在CIFAR-100上进行测试时，最佳效果是通过在稀疏正则化之后进行剪枝得到的，可以在不损失太多性能的情况下显著减少模型的计算负担。

    The Vision Transformer architecture is a deep learning model inspired by the success of the Transformer model in Natural Language Processing. However, the self-attention mechanism, large number of parameters, and the requirement for a substantial amount of training data still make Vision Transformers computationally burdensome. In this research, we investigate the possibility of applying Sparse Regularization to Vision Transformers and the impact of Pruning, either after Sparse Regularization or without it, on the trade-off between performance and efficiency. To accomplish this, we apply Sparse Regularization and Pruning methods to the Vision Transformer architecture for image classification tasks on the CIFAR-10, CIFAR-100, and ImageNet-100 datasets. The training process for the Vision Transformer model consists of two parts: pre-training and fine-tuning. Pre-training utilizes ImageNet21K data, followed by fine-tuning for 20 epochs. The results show that when testing with CIFAR-100 an
    
[^27]: 为什么视觉-语言模型的提示调参对于噪声标签具有鲁棒性？

    Why Is Prompt Tuning for Vision-Language Models Robust to Noisy Labels?. (arXiv:2307.11978v1 [cs.CV])

    [http://arxiv.org/abs/2307.11978](http://arxiv.org/abs/2307.11978)

    视觉-语言模型通过少样本提示调参的方式适应新的分类任务，且对于噪声标签具有鲁棒性。关键原因包括固定的类名标记对模型优化的正则化作用以及从多样且通用的网络数据中学习到的强大预训练图像-文本嵌入提供的先验知识。

    

    视觉-语言模型（如CLIP）通过大规模训练数据学习了通用的文本-图像嵌入。通过少样本提示调参的方式，可以使视觉-语言模型适应新的分类任务。我们发现，这种提示调参过程对于噪声标签具有很强的鲁棒性。这激发了我们研究提示调参范式鲁棒性的关键原因。我们进行了大量实验证明，关键因素包括：1）固定的类名标记对模型的优化提供了强大的正则化作用，减少了噪声样本引起的梯度；2）从多样且通用的网络数据中学习到的强大的预训练图像-文本嵌入为图像分类提供了强大的先验知识。此外，我们证明可以利用CLIP中的噪声零样本预测来调整其自身的提示，显著提高了在无监督设置下的预测准确性。代码可在https://github.com/CE找到。

    Vision-language models such as CLIP learn a generic text-image embedding from large-scale training data. A vision-language model can be adapted to a new classification task through few-shot prompt tuning. We find that such a prompt tuning process is highly robust to label noises. This intrigues us to study the key reasons contributing to the robustness of the prompt tuning paradigm. We conducted extensive experiments to explore this property and find the key factors are: 1) the fixed classname tokens provide a strong regularization to the optimization of the model, reducing gradients induced by the noisy samples; 2) the powerful pre-trained image-text embedding that is learned from diverse and generic web data provides strong prior knowledge for image classification. Further, we demonstrate that noisy zero-shot predictions from CLIP can be used to tune its own prompt, significantly enhancing prediction accuracy in the unsupervised setting. The code is available at https://github.com/CE
    
[^28]: 关于基于贝叶斯强化学习解决部分可观测马尔可夫决策过程的机器人的研究

    On-Robot Bayesian Reinforcement Learning for POMDPs. (arXiv:2307.11954v1 [cs.RO])

    [http://arxiv.org/abs/2307.11954](http://arxiv.org/abs/2307.11954)

    本研究提供了解决机器人学习中大量数据需求的方法，通过将专家知识捕捉并形式化为贝叶斯框架，使用基于样本的在线解决方法来推动基于贝叶斯强化学习在机器人中的应用。

    

    由于获取数据的成本较高，机器人学习往往困难重重。然而，通过有效的算法和充分利用专家对机器人动态的信息，我们可以解决大量数据的需求。基于贝叶斯强化学习（BRL）由于其样本效率和对先验知识的利用能力，在这一问题上独具优势。不幸的是，由于表达专家知识和解决后续推理问题的困难，BRL的应用受到了限制。本文通过提出一个专门针对物理系统的框架，推动了机器人中的BRL。具体而言，我们以分解表示的形式捕捉这些知识，然后展示了后验概率的分解形式，并最终在贝叶斯框架下将模型形式化。然后，我们引入了一种基于蒙特卡洛树搜索和粒子滤波的基于样本的在线解决方法，专门用于解决所得到的模型。

    Robot learning is often difficult due to the expense of gathering data. The need for large amounts of data can, and should, be tackled with effective algorithms and leveraging expert information on robot dynamics. Bayesian reinforcement learning (BRL), thanks to its sample efficiency and ability to exploit prior knowledge, is uniquely positioned as such a solution method. Unfortunately, the application of BRL has been limited due to the difficulties of representing expert knowledge as well as solving the subsequent inference problem. This paper advances BRL for robotics by proposing a specialized framework for physical systems. In particular, we capture this knowledge in a factored representation, then demonstrate the posterior factorizes in a similar shape, and ultimately formalize the model in a Bayesian framework. We then introduce a sample-based online solution method, based on Monte-Carlo tree search and particle filtering, specialized to solve the resulting model. This approach c
    
[^29]: 病理学和基因组多模态变压器用于生存结局预测

    Pathology-and-genomics Multimodal Transformer for Survival Outcome Prediction. (arXiv:2307.11952v1 [cs.CV])

    [http://arxiv.org/abs/2307.11952](http://arxiv.org/abs/2307.11952)

    提出了一种病理学和基因组多模态变压器（PathOmics），用于结肠相关癌症生存预测。该模型通过无监督预训练捕捉病理图像和基因组数据之间的内在相互作用，并通过任务特定模型微调适用于多模态和单模态数据。该方法在TCGA结肠和直肠癌队列上表现出竞争力。

    

    生存结局评估在癌症中具有挑战性，并与多种临床因素（如成像和基因组生物标志物）密切相关。实现多模态分析有望揭示患者结局的新的预测模式。在本研究中，我们提出了一种多模态变压器（PathOmics），将病理学和基因组洞察力整合到结肠相关癌症生存预测中。我们强调无监督预训练，以捕获吉比像素全切片图像（WSIs）和各种基因组数据（如mRNA序列、拷贝数变异和甲基化）之间的内在相互作用。在预训练中进行多模态知识聚合后，我们的任务特定模型微调可以扩展适用于多模态和单模态数据（如仅图像或基因组）的数据可用性范围。我们在TCGA结肠和直肠癌队列上评估了我们的方法，结果显示所提出的方法具有竞争力并且优于其他方法。

    Survival outcome assessment is challenging and inherently associated with multiple clinical factors (e.g., imaging and genomics biomarkers) in cancer. Enabling multimodal analytics promises to reveal novel predictive patterns of patient outcomes. In this study, we propose a multimodal transformer (PathOmics) integrating pathology and genomics insights into colon-related cancer survival prediction. We emphasize the unsupervised pretraining to capture the intrinsic interaction between tissue microenvironments in gigapixel whole slide images (WSIs) and a wide range of genomics data (e.g., mRNA-sequence, copy number variant, and methylation). After the multimodal knowledge aggregation in pretraining, our task-specific model finetuning could expand the scope of data utility applicable to both multi- and single-modal data (e.g., image- or genomics-only). We evaluate our approach on both TCGA colon and rectum cancer cohorts, showing that the proposed approach is competitive and outperforms st
    
[^30]: HIQL: 以潜在状态作为动作的离线目标导向强化学习

    HIQL: Offline Goal-Conditioned RL with Latent States as Actions. (arXiv:2307.11949v1 [cs.LG])

    [http://arxiv.org/abs/2307.11949](http://arxiv.org/abs/2307.11949)

    本文提出了一个基于离线数据的目标导向强化学习的分层算法，通过利用目标达成问题的结构，使用一个无动作的价值函数学习了两个策略，从而在学习过程中更有效地利用离线数据。

    

    无监督预训练最近已成为计算机视觉和自然语言处理的基石。在强化学习中，目标导向强化学习可以潜在地利用大量未标记的（无奖励）数据，提供类似于自我监督的方法。然而，构建有效的目标导向强化学习算法并直接从多样化的离线数据中进行学习是具有挑战性的，因为准确估计远期目标的价值函数很困难。然而，目标达成问题表现出一定的结构，即达到远期目标需要首先通过较近子目标。这种结构非常有用，因为评估邻近目标的动作质量通常比更远目标容易。基于这一思想，我们提出了一个基于离线数据的目标导向强化学习的分层算法。利用一个没有动作的价值函数，我们学习了两个策略，允许我们利用这种结构：一个高层策略

    Unsupervised pre-training has recently become the bedrock for computer vision and natural language processing. In reinforcement learning (RL), goal-conditioned RL can potentially provide an analogous self-supervised approach for making use of large quantities of unlabeled (reward-free) data. However, building effective algorithms for goal-conditioned RL that can learn directly from diverse offline data is challenging, because it is hard to accurately estimate the exact value function for faraway goals. Nonetheless, goal-reaching problems exhibit structure, such that reaching distant goals entails first passing through closer subgoals. This structure can be very useful, as assessing the quality of actions for nearby goals is typically easier than for more distant goals. Based on this idea, we propose a hierarchical algorithm for goal-conditioned RL from offline data. Using one action-free value function, we learn two policies that allow us to exploit this structure: a high-level policy 
    
[^31]: 选择性感知：利用强化学习为语言模型演员优化状态描述

    Selective Perception: Optimizing State Descriptions with Reinforcement Learning for Language Model Actors. (arXiv:2307.11922v1 [cs.LG])

    [http://arxiv.org/abs/2307.11922](http://arxiv.org/abs/2307.11922)

    本研究提出了一种名为BLINDER的方法，通过学习任务条件下状态描述的值函数，自动选择简明的状态描述，以优化大型语言模型(LLM)演员在顺序决策任务中的性能和效率。

    

    大型语言模型(LLM)被应用于机器人和游戏等顺序决策任务的演员中，利用其丰富的世界知识和规划能力。然而，以往的研究很少探索通过语言向LLM演员提供什么环境状态信息。详尽描述高维状态可能会影响性能并增加LLM演员的推理成本。以前的LLM演员通过依赖手工设计的任务特定协议来确定该状态的哪些特征需要进行传递，哪些不需要。在本工作中，我们提出了一种名为BLINDER的方法，通过学习任务条件下状态描述的值函数，自动选择简明的状态描述。我们在具有挑战性的视频游戏NetHack和机器人操作任务中评估了BLINDER。我们的方法提高了任务成功率，减少了输入大小和计算成本，并且提高了生成的结果。

    Large language models (LLMs) are being applied as actors for sequential decision making tasks in domains such as robotics and games, utilizing their general world knowledge and planning abilities. However, previous work does little to explore what environment state information is provided to LLM actors via language. Exhaustively describing high-dimensional states can impair performance and raise inference costs for LLM actors. Previous LLM actors avoid the issue by relying on hand-engineered, task-specific protocols to determine which features to communicate about a state and which to leave out. In this work, we propose Brief Language INputs for DEcision-making Responses (BLINDER), a method for automatically selecting concise state descriptions by learning a value function for task-conditioned state descriptions. We evaluate BLINDER on the challenging video game NetHack and a robotic manipulation task. Our method improves task success rate, reduces input size and compute costs, and gen
    
[^32]: 学术和科学出版中关于生成式AI的出版商和期刊作者指南的计量分析

    Bibliometric Analysis of Publisher and Journal Instructions to Authors on Generative-AI in Academic and Scientific Publishing. (arXiv:2307.11918v1 [cs.DL])

    [http://arxiv.org/abs/2307.11918](http://arxiv.org/abs/2307.11918)

    该研究通过计量分析了顶级100家学术出版商和期刊对于作者在使用生成式AI（GAI）、生成式预训练模型（GPT）和大型语言模型（LLM）工具方面的指导程度和内容。结果显示，有17%的出版商和70%的期刊提供了有关GAI的指导，并且大部分禁止将GAI作为作者的一部分。同时也发现了一定的变异性。

    

    我们旨在确定关于学术出版商和期刊的顶级100名出版商和期刊对于作者在使用生成式AI（GAI）、生成式预训练模型（GPT）和大型语言模型（LLM）工具方面的指导程度和内容。对这些出版商和期刊的网站进行了2023年5月19日至20日的筛选。在最大的100家出版商中，有17%提供了关于使用GAI的指导，其中12家（70.6%）属于前25大出版商。在前100名期刊中，有70%提供了有关GAI的指导。在有指导的期刊中，94.1%的出版商和95.7%的期刊禁止作者将GAI作为作者的一部分。其中有四个期刊（5.7%）明确禁止在撰写稿件时使用GAI，而3个出版商（17.6%）和15个期刊（21.4%）表示他们的指导只适用于撰写过程。在披露使用GAI时，42.8%的出版商和44.3%的期刊包含了具体的披露标准。存在一定的变异性。

    We aim to determine the extent and content of guidance for authors regarding the use of generative-AI (GAI), Generative Pretrained models (GPTs) and Large Language Models (LLMs) powered tools among the top 100 academic publishers and journals in science. The websites of these publishers and journals were screened from between 19th and 20th May 2023. Among the largest 100 publishers, 17% provided guidance on the use of GAI, of which 12 (70.6%) were among the top 25 publishers. Among the top 100 journals, 70% have provided guidance on GAI. Of those with guidance, 94.1% of publishers and 95.7% of journals prohibited the inclusion of GAI as an author. Four journals (5.7%) explicitly prohibit the use of GAI in the generation of a manuscript, while 3 (17.6%) publishers and 15 (21.4%) journals indicated their guidance exclusively applies to the writing process. When disclosing the use of GAI, 42.8% of publishers and 44.3% of journals included specific disclosure criteria. There was variabilit
    
[^33]: Hindsight-DICE：稳定信用分配用于深度强化学习

    Hindsight-DICE: Stable Credit Assignment for Deep Reinforcement Learning. (arXiv:2307.11897v1 [cs.LG])

    [http://arxiv.org/abs/2307.11897](http://arxiv.org/abs/2307.11897)

    本研究提出了Hindsight-DICE算法，利用重要抽样比率估计技术改善了深度强化学习中的信用分配问题。

    

    在顺序决策问题中，环境往往提供很少的评估反馈来指导强化学习代理。在极端情况下，行为的长时间轨迹仅以一个终止信号标记，导致观察到非平凡奖励和触发此类反馈的个体步骤之间存在显著的时间延迟。解决这种信用分配挑战是强化学习的重要特征之一，本研究利用现有的重要抽样比率估计技术来显著改善策略梯度方法中的信用分配处理。虽然使用所谓的事后策略为观察到的轨迹返回返回数据重新加权提供了一个有原则的机制，但是简单地应用重要抽样会导致不稳定或过度滞后的学习。

    Oftentimes, environments for sequential decision-making problems can be quite sparse in the provision of evaluative feedback to guide reinforcement-learning agents. In the extreme case, long trajectories of behavior are merely punctuated with a single terminal feedback signal, engendering a significant temporal delay between the observation of non-trivial reward and the individual steps of behavior culpable for eliciting such feedback. Coping with such a credit assignment challenge is one of the hallmark characteristics of reinforcement learning and, in this work, we capitalize on existing importance-sampling ratio estimation techniques for off-policy evaluation to drastically improve the handling of credit assignment with policy-gradient methods. While the use of so-called hindsight policies offers a principled mechanism for reweighting on-policy data by saliency to the observed trajectory return, naively applying importance sampling results in unstable or excessively lagged learning.
    
[^34]: 关于受恶意噪声影响的公正约束学习的脆弱性

    On the Vulnerability of Fairness Constrained Learning to Malicious Noise. (arXiv:2307.11892v1 [cs.LG])

    [http://arxiv.org/abs/2307.11892](http://arxiv.org/abs/2307.11892)

    这项研究考虑了公正约束学习对恶意噪声的脆弱性，发现使用随机分类器可以在精度上只损失$\Theta(\alpha)$和$O(\sqrt{\alpha})$，对应不同的公正约束要求。

    

    我们考虑了公正约束学习对训练数据中微小恶意噪声的脆弱性。Konstantinov和Lampert (2021)在这个问题上进行了研究，并展示了负面结果，表明在不平衡的群组大小下存在一些数据分布，任何适当的学习器都会表现出较高的脆弱性。在这里，我们展示了更乐观的观点，如果允许随机分类器，则情况更加细致。例如，对于人口统计学平等性，我们显示只会产生$\Theta(\alpha)$的精度损失，其中$\alpha$是恶意噪声率，甚至可以与没有公正约束的情况完全匹配。对于机会均等性，我们显示只会产生$O(\sqrt{\alpha})$的损失，并给出一个匹配的$\Omega(\sqrt{\alpha})$的下界。相比之下，Konstantinov和Lampert (2021)示范了对于适当的学习器，这两个概念的精度损失都是$\Omega(1)$。关键的技术创新是

    We consider the vulnerability of fairness-constrained learning to small amounts of malicious noise in the training data. Konstantinov and Lampert (2021) initiated the study of this question and presented negative results showing there exist data distributions where for several fairness constraints, any proper learner will exhibit high vulnerability when group sizes are imbalanced. Here, we present a more optimistic view, showing that if we allow randomized classifiers, then the landscape is much more nuanced. For example, for Demographic Parity we show we can incur only a $\Theta(\alpha)$ loss in accuracy, where $\alpha$ is the malicious noise rate, matching the best possible even without fairness constraints. For Equal Opportunity, we show we can incur an $O(\sqrt{\alpha})$ loss, and give a matching $\Omega(\sqrt{\alpha})$lower bound. In contrast, Konstantinov and Lampert (2021) showed for proper learners the loss in accuracy for both notions is $\Omega(1)$. The key technical novelty 
    
[^35]: 面向银行流程自动化的多模式文档分析

    Multimodal Document Analytics for Banking Process Automation. (arXiv:2307.11845v1 [cs.CL])

    [http://arxiv.org/abs/2307.11845](http://arxiv.org/abs/2307.11845)

    本研究聚焦于应对金融科技竞争和提高银行业务运营效率的需求，通过多模式模型特别是先进的文档分析技术，研究了银行流程中的潜力和机会，并展示了LayoutXLM等模型在分析银行文档中的潜力和性能。

    

    针对金融科技竞争的增长和提高运营效率的需求，本研究关注于理解在银行流程中利用多模式模型特别是先进的文档分析的潜力。我们对多样化的银行文档领域进行了全面分析，突出了通过自动化和先进的分析技术在客户业务中提高效率的机会。基于快速发展的自然语言处理（NLP）领域，我们展示了诸如LayoutXLM这样的模型的潜力，它是一种跨语言、多模式、预训练模型，用于分析银行业中各种不同的文档。该模型对德国公司登记提取的文本标记分类具有大约80%的F1得分性能。我们的实证证据证实了布局信息在提高模型性能方面的关键作用，并进一步强调了整合图像信息的好处。

    In response to growing FinTech competition and the need for improved operational efficiency, this research focuses on understanding the potential of advanced document analytics, particularly using multimodal models, in banking processes. We perform a comprehensive analysis of the diverse banking document landscape, highlighting the opportunities for efficiency gains through automation and advanced analytics techniques in the customer business. Building on the rapidly evolving field of natural language processing (NLP), we illustrate the potential of models such as LayoutXLM, a cross-lingual, multimodal, pre-trained model, for analyzing diverse documents in the banking sector. This model performs a text token classification on German company register extracts with an overall F1 score performance of around 80\%. Our empirical evidence confirms the critical role of layout information in improving model performance and further underscores the benefits of integrating image information. Inte
    
[^36]: HybridAugment++：用于模型鲁棒性的统一频谱扰动

    HybridAugment++: Unified Frequency Spectra Perturbations for Model Robustness. (arXiv:2307.11823v1 [cs.CV])

    [http://arxiv.org/abs/2307.11823](http://arxiv.org/abs/2307.11823)

    HybridAugment++是一种通过减少卷积神经网络对高频成分的依赖并促进相位信息应用的数据增强方法，提高了模型的鲁棒性。它通过统一各种频谱增强方法，取得了竞争性的结果。

    

    卷积神经网络（CNN）在数据分布转变下表现出差劲的泛化性能。已经对它们的泛化性能进行了广泛的研究，而其中一种方法是从频率角度考虑问题。这些研究指出，人类和CNN可能会关注图像的不同频率成分。首先，受到这些观察的启发，我们提出了一种简单而有效的数据增强方法HybridAugment，它减少了CNN对高频成分的依赖，从而提高了它们在保持准确度的同时的鲁棒性。其次，我们提出了HierarchicalAugment++，这是一种层次化的增强方法，旨在统一各种频谱增强方法。HierarchicalAugment++基于HybridAugment，减少了CNN对图像振幅分量的依赖，并推动相位信息的应用。这种统一结果句对抗现有技术的竞争性结果。

    Convolutional Neural Networks (CNN) are known to exhibit poor generalization performance under distribution shifts. Their generalization have been studied extensively, and one line of work approaches the problem from a frequency-centric perspective. These studies highlight the fact that humans and CNNs might focus on different frequency components of an image. First, inspired by these observations, we propose a simple yet effective data augmentation method HybridAugment that reduces the reliance of CNNs on high-frequency components, and thus improves their robustness while keeping their clean accuracy high. Second, we propose HybridAugment++, which is a hierarchical augmentation method that attempts to unify various frequency-spectrum augmentations. HybridAugment++ builds on HybridAugment, and also reduces the reliance of CNNs on the amplitude component of images, and promotes phase information instead. This unification results in competitive to or better than state-of-the-art results 
    
[^37]: 用语音识别能力促进大型语言模型

    Prompting Large Language Models with Speech Recognition Abilities. (arXiv:2307.11795v1 [eess.AS])

    [http://arxiv.org/abs/2307.11795](http://arxiv.org/abs/2307.11795)

    本研究通过为大型语言模型添加音频编码器，使其具备了语音识别能力。在多语言数据集上的实验证明，这样的扩展能够提高模型的性能，并且在多语言环境下实现了语音识别。通过消融研究，我们还发现可以冻结模型以保持其原有功能，并且提升音频编码器的规模有助于提高性能。

    

    大型语言模型已证明其高度灵活，能够解决各种生成任务，如概括性摘要和开放性问答。本文通过直接附加一个小型音频编码器来扩展LLM的功能，使其能够执行语音识别。通过将一系列声音嵌入直接预置到文本令牌嵌入之前，LLM可以转换为自动语音识别（ASR）系统，并且可以与其文本对应物以完全相同的方式使用。在多语言LibriSpeech（MLS）上的实验证明，将一个conformer编码器融入到开源的LLaMA-7B中，使其在单一语言基准上的表现超过18%，并能够执行多语言语音识别，尽管LLaMA的训练主要依赖于英文文本。此外，我们进行了消融研究，以调查LLM在训练过程中是否可以完全冻结以保持其原有功能，以及提升音频编码器的规模。

    Large language models have proven themselves highly flexible, able to solve a wide range of generative tasks, such as abstractive summarization and open-ended question answering. In this paper we extend the capabilities of LLMs by directly attaching a small audio encoder allowing it to perform speech recognition. By directly prepending a sequence of audial embeddings to the text token embeddings, the LLM can be converted to an automatic speech recognition (ASR) system, and be used in the exact same manner as its textual counterpart. Experiments on Multilingual LibriSpeech (MLS) show that incorporating a conformer encoder into the open sourced LLaMA-7B allows it to outperform monolingual baselines by 18% and perform multilingual speech recognition despite LLaMA being trained overwhelmingly on English text. Furthermore, we perform ablation studies to investigate whether the LLM can be completely frozen during training to maintain its original capabilities, scaling up the audio encoder, a
    
[^38]: 在金融行业中应用量子自然语言处理(QNLP)进行情感分析

    Applying QNLP to sentiment analysis in finance. (arXiv:2307.11788v1 [cs.CL])

    [http://arxiv.org/abs/2307.11788](http://arxiv.org/abs/2307.11788)

    本论文研究了在金融行业中应用量子自然语言处理(QNLP)进行情感分析的实际适用性。利用一种新颖的数据生成方法，我们发现量子增强的长短期记忆(QLSTM)可以更快地训练，并且在软件实现方面接近古典结果。

    

    作为一个领域，即使是最微小的质量改进也能产生巨大价值的应用领域，金融是早期量子优势的有前途的候选者。在迅速发展的量子自然语言处理(QNLP)领域中，我们探索了DisCoCat和量子增强的长短期记忆(QNLP)这两种中心方法在金融情感分析问题中的实际适用性。利用一种新颖的基于ChatGPT的数据生成方法，我们进行了一个包含1000多个真实句子的案例研究，发现QLSTM的训练速度比DisCoCat快得多，并且在可用的软件实现中也接近古典结果。

    As an application domain where the slightest qualitative improvements can yield immense value, finance is a promising candidate for early quantum advantage. Focusing on the rapidly advancing field of Quantum Natural Language Processing (QNLP), we explore the practical applicability of the two central approaches DisCoCat and Quantum-Enhanced Long Short-Term Memory (QLSTM) to the problem of sentiment analysis in finance. Utilizing a novel ChatGPT-based data generation approach, we conduct a case study with more than 1000 realistic sentences and find that QLSTMs can be trained substantially faster than DisCoCat while also achieving close to classical results for their available software implementations.
    
[^39]: LLM认知判断与人类有所不同

    LLM Cognitive Judgements Differ From Human. (arXiv:2307.11787v1 [cs.CL])

    [http://arxiv.org/abs/2307.11787](http://arxiv.org/abs/2307.11787)

    这项研究调查了大型语言模型在认知任务中的表现，并发现它们的认知判断与人类不同。

    

    最近，大型语言模型(LLMs)成为研究人员、企业和消费者关注的焦点。虽然这类模型的语言能力已经得到了广泛的研究，但对它们作为认知主体的调查越来越受关注。在本研究中，我对GPT-3和ChatGPT在一个来自认知科学文献的有限数据归纳推理任务上的能力进行了研究。结果表明，这些模型的认知判断与人类不同。

    Large Language Models (LLMs) have lately been on the spotlight of researchers, businesses, and consumers alike. While the linguistic capabilities of such models have been studied extensively, there is growing interest in investigating them as cognitive subjects. In the present work I examine GPT-3 and ChatGPT capabilities on an limited-data inductive reasoning task from the cognitive science literature. The results suggest that these models' cognitive judgements are not human-like.
    
[^40]: 究竟什么是可实现的可证明保障的学习机制安全关键系统

    What, Indeed, is an Achievable Provable Guarantee for Learning-Enabled Safety Critical Systems. (arXiv:2307.11784v1 [cs.LG])

    [http://arxiv.org/abs/2307.11784](http://arxiv.org/abs/2307.11784)

    本文讨论了学习机制在安全关键领域的挑战，提出了一种两步验证方法来实现可证明的统计保障。

    

    机器学习取得了显著的进展，但在安全关键领域自信地利用学习机制仍然面临挑战。在这些挑战中，实现安全保证的一种严谨但实用的方法是最为突出的。本文首先讨论了设计和验证这种系统所涉及的工程和研究挑战。然后，基于对现有工作无法实现可证明保证的观察，我们提出了一种两步验证方法，以最终实现可证明的统计保障。

    Machine learning has made remarkable advancements, but confidently utilising learning-enabled components in safety-critical domains still poses challenges. Among the challenges, it is known that a rigorous, yet practical, way of achieving safety guarantees is one of the most prominent. In this paper, we first discuss the engineering and research challenges associated with the design and verification of such systems. Then, based on the observation that existing works cannot actually achieve provable guarantees, we promote a two-step verification method for the ultimate achievement of provable statistical guarantees.
    
[^41]: Generate的语言模型中的提取-摘要轴:测量内容"借用"

    The Extractive-Abstractive Axis: Measuring Content "Borrowing" in Generative Language Models. (arXiv:2307.11779v1 [cs.CL])

    [http://arxiv.org/abs/2307.11779](http://arxiv.org/abs/2307.11779)

    该论文提出了一个名为提取-摘要轴的概念，用于衡量生成语言模型中内容的"借用"程度，并提出了开发相应度量标准、数据集和注释指南的需求。

    

    生成语言模型通过设计产生高度摘要的输出，与搜索引擎中的提取式响应形成对比。鉴于LLMs的这一特点及其对内容许可和归属的影响，我们提出了所谓的提取-摘要轴，用于基准测试生成模型，并强调开发相应的度量标准、数据集和注释指南的需要。我们将讨论限制在文本形式上。

    Generative language models produce highly abstractive outputs by design, in contrast to extractive responses in search engines. Given this characteristic of LLMs and the resulting implications for content Licensing & Attribution, we propose the the so-called Extractive-Abstractive axis for benchmarking generative models and highlight the need for developing corresponding metrics, datasets and annotation guidelines. We limit our discussion to the text modality.
    
[^42]: 问题分解提高了模型生成推理的忠实度

    Question Decomposition Improves the Faithfulness of Model-Generated Reasoning. (arXiv:2307.11768v1 [cs.CL])

    [http://arxiv.org/abs/2307.11768](http://arxiv.org/abs/2307.11768)

    通过将问题分解为子问题，可以显著提高大型语言模型生成推理的忠实度。

    

    随着大型语言模型（LLM）执行越来越复杂的任务，验证其行为的正确性和安全性变得越来越困难。其中一种解决方法是要求LLM在回答问题时以逐步推理的方式外化其推理过程（思维链；CoT）。推理过程可以让我们检查模型执行任务的过程。然而，这种方法依赖于所陈述的推理能够忠实地反映模型的实际推理，而这并非总是如此。为了提高CoT推理的忠实度，我们通过将问题分解为子问题来生成推理。基于分解的方法在问答任务上取得了较好的性能，有时接近CoT，并在几个最近提出的度量标准中提高了模型所陈述推理的忠实度。通过强制模型在单独的上下文中回答简单的子问题，我们大大增加了模型的忠实度。

    As large language models (LLMs) perform more difficult tasks, it becomes harder to verify the correctness and safety of their behavior. One approach to help with this issue is to prompt LLMs to externalize their reasoning, e.g., by having them generate step-by-step reasoning as they answer a question (Chain-of-Thought; CoT). The reasoning may enable us to check the process that models use to perform tasks. However, this approach relies on the stated reasoning faithfully reflecting the model's actual reasoning, which is not always the case. To improve over the faithfulness of CoT reasoning, we have models generate reasoning by decomposing questions into subquestions. Decomposition-based methods achieve strong performance on question-answering tasks, sometimes approaching that of CoT while improving the faithfulness of the model's stated reasoning on several recently-proposed metrics. By forcing the model to answer simpler subquestions in separate contexts, we greatly increase the faithf
    
[^43]: 在高效自动化的风格中识别心理形容词

    Recognition of Mental Adjectives in An Efficient and Automatic Style. (arXiv:2307.11767v1 [cs.CL])

    [http://arxiv.org/abs/2307.11767](http://arxiv.org/abs/2307.11767)

    本论文提出了一个新的词汇推理任务MPC，通过微调BERT模型和采用主动学习算法，在简化标注资源的同时达到了令人满意的准确性。通过与SentiWordNet的比较，还发现了MPC与情感分析中的主观性分类任务的差异。

    

    最近几年，常识推理在学术界越来越受到关注。我们提出了一个新的词汇推理任务，心理与物理分类（MPC），以处理常识推理。心理词语与心理活动相关，可分为六个类别：情感、需求、感知、推理、规划和个性。物理词语描述物体的物理属性，如颜色、硬度、速度和可塑性。我们使用BERT模型对这个任务进行了微调，并在训练框架中采用主动学习算法来减少所需的注释资源。使用ENTROPY策略的模型达到了令人满意的准确性，仅需要约300个标注的词语。我们还将结果与SentiWordNet进行了比较，以检查MPC与情感分析中的主观性分类任务之间的差异。

    In recent years, commonsense reasoning has received more and more attention from academic community. We propose a new lexical inference task, Mental and Physical Classification (MPC), to handle commonsense reasoning in a reasoning graph. Mental words relate to mental activities, which fall into six categories: Emotion, Need, Perceiving, Reasoning, Planning and Personality. Physical words describe physical attributes of an object, like color, hardness, speed and malleability. A BERT model is fine-tuned for this task and active learning algorithm is adopted in the training framework to reduce the required annotation resources. The model using ENTROPY strategy achieves satisfactory accuracy and requires only about 300 labeled words. We also compare our result with SentiWordNet to check the difference between MPC and subjectivity classification task in sentiment analysis.
    
[^44]: 使用调取心智模型的方式来测量对可解释人工智能辅助决策的感知信任度

    Measuring Perceived Trust in XAI-Assisted Decision-Making by Eliciting a Mental Model. (arXiv:2307.11765v1 [cs.HC])

    [http://arxiv.org/abs/2307.11765](http://arxiv.org/abs/2307.11765)

    该研究提出了一种通过调取用户的心智模型来测量可解释人工智能模型的感知信任度的方法。通过使用模糊认知图来评估解释对感知信任度的影响，从而为解释人工智能决策提供参考和改进方向。

    

    该实证研究提出了一种新的方法来测量用户对可解释人工智能模型的感知信任度。利用模糊认知图来获取用户的心智模型。首先，我们采用一个可解释的机器学习模型将疑似COVID-19患者分类为阳性或阴性。然后，医疗专家根据他们的专业知识以及可解释人工智能模型提供的预测和解释进行诊断决策任务。为了评估解释对感知信任度的影响，医疗专家通过调查对解释满意度进行评分。然后，将其作为模糊认知图的概念，以确定它们对彼此以及最终对感知信任度的影响。此外，为了考虑医疗专家的主观性，使用模糊语言变量来确定影响的强度。在模糊认知图达到稳定状态后，将获得一个量化值来衡量感知信任度。

    This empirical study proposes a novel methodology to measure users' perceived trust in an Explainable Artificial Intelligence (XAI) model. To do so, users' mental models are elicited using Fuzzy Cognitive Maps (FCMs). First, we exploit an interpretable Machine Learning (ML) model to classify suspected COVID-19 patients into positive or negative cases. Then, Medical Experts' (MEs) conduct a diagnostic decision-making task based on their knowledge and then prediction and interpretations provided by the XAI model. In order to evaluate the impact of interpretations on perceived trust, explanation satisfaction attributes are rated by MEs through a survey. Then, they are considered as FCM's concepts to determine their influences on each other and, ultimately, on the perceived trust. Moreover, to consider MEs' mental subjectivity, fuzzy linguistic variables are used to determine the strength of influences. After reaching the steady state of FCMs, a quantified value is obtained to measure the 
    
[^45]: 重新思考人机交互中的信任修复

    Rethinking Trust Repair in Human-Robot Interaction. (arXiv:2307.11763v1 [cs.RO])

    [http://arxiv.org/abs/2307.11763](http://arxiv.org/abs/2307.11763)

    本论文主要研究人机交互中的信任修复，目标是确定有效策略并探索成功潜在机制。

    

    随着机器人在工作合作中的普及，信任已成为它们被接受和发挥效能的关键因素。然而，信任是动态的，当出现错误时，信任会被侵蚀。尽管在人机交互中的信任修复上有不断涌现的研究，但仍然存在关于如何在机器人违背信任后恢复信任的可靠方法的重要问题。为了解决这个问题，我的研究旨在确定在人机交互中设计能够修复信任的机器人的有效策略，并探索这些策略成功的潜在机制。本文概述了人机交互中信任修复过程的基本概念和关键组成部分，以及我在这个领域的当前已发表工作的总结。此外，我还讨论了将指导我未来工作的研究问题以及这项研究可能对该领域做出的贡献。

    As robots become increasingly prevalent in work-oriented collaborations, trust has emerged as a critical factor in their acceptance and effectiveness. However, trust is dynamic and can erode when mistakes are made. Despite emerging research on trust repair in human-robot interaction, significant questions remain about identifying reliable approaches to restoring trust in robots after trust violations occur. To address this problem, my research aims to identify effective strategies for designing robots capable of trust repair in human-robot interaction (HRI) and to explore the underlying mechanisms that make these strategies successful. This paper provides an overview of the fundamental concepts and key components of the trust repair process in HRI, as well as a summary of my current published work in this area. Additionally, I discuss the research questions that will guide my future work and the potential contributions that this research could make to the field.
    
[^46]: ChatGPT的公平性及可解释引导提示的作用

    Fairness of ChatGPT and the Role Of Explainable-Guided Prompts. (arXiv:2307.11761v1 [cs.CL])

    [http://arxiv.org/abs/2307.11761](http://arxiv.org/abs/2307.11761)

    本研究调查了ChatGPT在信用风险评估中的潜力，发现通过精心设计的提示指导和领域特定知识的补充，ChatGPT能够与传统机器学习模型相媲美，使用的数据量少至传统模型的1/40，表现优异，尤其擅长减小误报并提升公平性。这为未来在其他类似任务中充分利用ChatGPT的能力奠定了基础。

    

    我们的研究探讨了大规模语言模型（LLMs）在信用风险评估中的潜力，具体来说是OpenAI的GPT，在一个二分类任务中。我们的发现表明，当LLMs受到精心设计的提示指导并补充领域特定知识时，其表现可以与传统的机器学习模型相媲美。有趣的是，他们只使用了少得多的数据-仅仅20个数据点，而传统机器学习模型需要800个数据点，从而实现了与传统模型相当的性能。LLMs在减小误报提升公平性方面表现出色，这两个方面在风险分析中至关重要。尽管我们的结果没有超过传统的机器学习模型，但它们强调了LLMs在类似任务中的潜力，为未来在多样化的机器学习任务中利用LLMs的能力奠定基础。

    Our research investigates the potential of Large-scale Language Models (LLMs), specifically OpenAI's GPT, in credit risk assessment-a binary classification task. Our findings suggest that LLMs, when directed by judiciously designed prompts and supplemented with domain-specific knowledge, can parallel the performance of traditional Machine Learning (ML) models. Intriguingly, they achieve this with significantly less data-40 times less, utilizing merely 20 data points compared to the ML's 800. LLMs particularly excel in minimizing false positives and enhancing fairness, both being vital aspects of risk analysis. While our results did not surpass those of classical ML models, they underscore the potential of LLMs in analogous tasks, laying a groundwork for future explorations into harnessing the capabilities of LLMs in diverse ML tasks.
    
[^47]: EmotionPrompt: 通过情感刺激提升大型语言模型的关键心理学方法

    EmotionPrompt: Leveraging Psychology for Large Language Models Enhancement via Emotional Stimulus. (arXiv:2307.11760v1 [cs.CL])

    [http://arxiv.org/abs/2307.11760](http://arxiv.org/abs/2307.11760)

    EmotionPrompt是一个基于心理学的方法，通过将情感刺激融入到提示中，提升了大型语言模型在各项任务上的性能，并且同时改善了其真实性和信息量。

    

    大型语言模型（LLMs）在推理、语言理解和数学问题解决等许多领域取得了显著的性能，并被视为人工通用智能（AGI）的关键步骤。然而，LLMs对提示的敏感性仍然是其日常应用的主要瓶颈。本文从心理学中汲取灵感，提出了EmotionPrompt来探索情感智能以提升LLMs的性能。EmotionPrompt基于一个非常简单明了的原则：将情感刺激融入到提示中。实验结果表明，我们的方法在相同的单一提示模板上，与原始的零样本提示和Zero-shot-CoT相比，在8个任务上都显著优于多种模型：ChatGPT、Vicuna-13b、Bloom和T5。此外，观察到EmotionPrompt能够提高真实性和信息量。我们相信EmotionPrompt为探索跨学科知识开辟了一条新的道路。

    Large language models (LLMs) have achieved significant performance in many fields such as reasoning, language understanding, and math problem-solving, and are regarded as a crucial step to artificial general intelligence (AGI). However, the sensitivity of LLMs to prompts remains a major bottleneck for their daily adoption. In this paper, we take inspiration from psychology and propose EmotionPrompt to explore emotional intelligence to enhance the performance of LLMs. EmotionPrompt operates on a remarkably straightforward principle: the incorporation of emotional stimulus into prompts. Experimental results demonstrate that our \method, using the same single prompt templates, significantly outperforms original zero-shot prompt and Zero-shot-CoT on 8 tasks with diverse models: ChatGPT, Vicuna-13b, Bloom, and T5. Further, EmotionPrompt was observed to improve both truthfulness and informativeness. We believe that EmotionPrompt heralds a novel avenue for exploring interdisciplinary knowledg
    
[^48]: 基于形态学图像分析和特征提取的AI缺陷检测和分类模型推理

    Morphological Image Analysis and Feature Extraction for Reasoning with AI-based Defect Detection and Classification Models. (arXiv:2307.11643v1 [cs.CV])

    [http://arxiv.org/abs/2307.11643](http://arxiv.org/abs/2307.11643)

    本文提出了一个名为AI推理器的解释性模型，能够从图像中提取缺陷的形态学特征，并利用决策树进行推理。它通过可视化和文字说明解释基于掩模的缺陷检测和分类模型的输出，并提供有效的缓解策略以提升整体模型性能。

    

    随着人工智能模型在工程和制造等行业的使用越来越普遍，这些模型提供透明的推理以解释其预测结果变得至关重要。本文提出了AI推理器，该推理器从图像中提取缺陷的形态学特征，并利用决策树对缺陷特征进行推理。然后，AI推理器通过可视化图表和文字说明提供对基于掩模的缺陷检测和分类模型的输出进行解释。它还提供了有效的缓解策略，以提升数据预处理和整体模型性能。AI推理器在使用366张含有缺陷的图像集合上测试了解释IE Mask R-CNN模型输出的能力。结果表明，AI推理器在解释IE Mask R-CNN模型的预测方面具有很高的效果。总而言之，所提出的AI推理器为改善模型性能提供了一个解决方案。

    As the use of artificial intelligent (AI) models becomes more prevalent in industries such as engineering and manufacturing, it is essential that these models provide transparent reasoning behind their predictions. This paper proposes the AI-Reasoner, which extracts the morphological characteristics of defects (DefChars) from images and utilises decision trees to reason with the DefChar values. Thereafter, the AI-Reasoner exports visualisations (i.e. charts) and textual explanations to provide insights into outputs made by masked-based defect detection and classification models. It also provides effective mitigation strategies to enhance data pre-processing and overall model performance. The AI-Reasoner was tested on explaining the outputs of an IE Mask R-CNN model using a set of 366 images containing defects. The results demonstrated its effectiveness in explaining the IE Mask R-CNN model's predictions. Overall, the proposed AI-Reasoner provides a solution for improving the performanc
    
[^49]: CausE: 朝向因果知识图谱嵌入的方向

    CausE: Towards Causal Knowledge Graph Embedding. (arXiv:2307.11610v1 [cs.CL])

    [http://arxiv.org/abs/2307.11610](http://arxiv.org/abs/2307.11610)

    CausE是一个采用因果知识图谱嵌入和嵌入解缠的框架，利用因果干预进行稳定预测，并在知识图谱完整性任务上取得了最先进的性能。

    

    知识图谱嵌入（KGE）的重点是将知识图谱（KG）中的实体和关系表示为连续的向量空间，这可以用于预测缺失的三元组以实现知识图谱完整性（KGC）。然而，KGE模型通常只是简单地学习三元组数据的结构关联，并且在现实世界的KG中，嵌入可能会被微不足道的模式和噪声链接所误导。为了解决这个问题，我们在因果性和嵌入解缠方面建立了KGE的新模式。我们进一步提出了Causality-enhanced knowledge graph Embedding（CausE）框架。CausE使用因果干预来估计混杂嵌入的因果效应，并设计新的训练目标来进行稳定预测。实验结果表明，CausE可以优于基线模型，并实现最先进的KGC性能。我们在https://github.com/zjukg/CausE上发布了我们的代码。

    Knowledge graph embedding (KGE) focuses on representing the entities and relations of a knowledge graph (KG) into the continuous vector spaces, which can be employed to predict the missing triples to achieve knowledge graph completion (KGC). However, KGE models often only briefly learn structural correlations of triple data and embeddings would be misled by the trivial patterns and noisy links in real-world KGs. To address this issue, we build the new paradigm of KGE in the context of causality and embedding disentanglement. We further propose a Causality-enhanced knowledge graph Embedding (CausE) framework. CausE employs causal intervention to estimate the causal effect of the confounder embeddings and design new training objectives to make stable predictions. Experimental results demonstrate that CausE could outperform the baseline models and achieve state-of-the-art KGC performance. We release our code in https://github.com/zjukg/CausE.
    
[^50]: AIGC赋能电信行业白皮书

    AIGC Empowering Telecom Sector White Paper. (arXiv:2307.11449v1 [cs.AI])

    [http://arxiv.org/abs/2307.11449](http://arxiv.org/abs/2307.11449)

    本文探讨了AIGC（GPT）在电信行业中的应用，提出了一个电信增强认知能力系统，为电信服务的构建提供了解决方案。

    

    在全球GPT热潮中，人们深切意识到作为一项具有变革性的技术和经济社会发展的关键力量的人工智能将给全球产业带来巨大的飞跃和突破，并深刻影响未来的竞争格局。作为信息通信基础设施的建设者和运营商，电信行业为人工智能的发展提供基础支持，甚至在人工智能应用方面处于领先地位。如何实现AIGC（GPT）应用并在电信行业中实施AIGC是电信从业者必须思考和回答的问题。通过研究GPT作为AIGC的典型代表，作者分析了GPT如何通过场景赋能电信行业，讨论了当前GPT通用模型与电信服务之间的差距，并首次提出了一个电信增强认知能力系统，回答了如何构建一个电信服务的问题。

    In the global craze of GPT, people have deeply realized that AI, as a transformative technology and key force in economic and social development, will bring great leaps and breakthroughs to the global industry and profoundly influence the future world competition pattern. As the builder and operator of information and communication infrastructure, the telecom sector provides infrastructure support for the development of AI, and even takes the lead in the implementation of AI applications. How to enable the application of AIGC (GPT) and implement AIGC in the telecom sector are questions that telecom practitioners must ponder and answer. Through the study of GPT, a typical representative of AIGC, the authors have analyzed how GPT empowers the telecom sector in the form of scenarios, discussed the gap between the current GPT general model and telecom services, proposed for the first time a Telco Augmented Cognition capability system, provided answers to how to construct a telecom service 
    
[^51]: 深度直接训练的脉冲神经网络用于目标检测

    Deep Directly-Trained Spiking Neural Networks for Object Detection. (arXiv:2307.11411v1 [cs.CV])

    [http://arxiv.org/abs/2307.11411](http://arxiv.org/abs/2307.11411)

    EMS-YOLO是一种直接训练的脉冲神经网络框架，通过使用替代梯度而不是ANN-SNN转换策略，成功解决了深度SNN的目标检测问题。

    

    脉冲神经网络（SNN）是一种受大脑启发的高能效模型，它通过时空动态来编码信息。最近，直接训练的深度SNN在少数时间步骤上的分类任务中表现出了很高的性能。然而，如何设计一个直接训练的SNN来解决目标检测回归任务仍然是一个具有挑战性的问题。为了解决这个问题，我们提出了EMS-YOLO，一种用于目标检测的新型直接训练的SNN框架，它是第一个使用替代梯度而不是ANN-SNN转换策略来训练深度SNN的尝试。具体地，我们设计了一个全脉冲残差块EMS-ResNet，它可以有效地扩展直接训练的SNN的深度，并且能够具有低功耗。此外，我们在理论上分析并证明了EMS-ResNet可以避免梯度消失或梯度爆炸的问题。实验结果表明，我们的方法优于最先进的ANN-SNN转换方法。

    Spiking neural networks (SNNs) are brain-inspired energy-efficient models that encode information in spatiotemporal dynamics. Recently, deep SNNs trained directly have shown great success in achieving high performance on classification tasks with very few time steps. However, how to design a directly-trained SNN for the regression task of object detection still remains a challenging problem. To address this problem, we propose EMS-YOLO, a novel directly-trained SNN framework for object detection, which is the first trial to train a deep SNN with surrogate gradients for object detection rather than ANN-SNN conversion strategies. Specifically, we design a full-spike residual block, EMS-ResNet, which can effectively extend the depth of the directly-trained SNN with low power consumption. Furthermore, we theoretically analyze and prove the EMS-ResNet could avoid gradient vanishing or exploding. The results demonstrate that our approach outperforms the state-of-the-art ANN-SNN conversion me
    
[^52]: LLM审查：机器学习挑战还是计算机安全问题？

    LLM Censorship: A Machine Learning Challenge or a Computer Security Problem?. (arXiv:2307.10719v1 [cs.AI])

    [http://arxiv.org/abs/2307.10719](http://arxiv.org/abs/2307.10719)

    本文讨论了大型语言模型(LLM)的审查问题，指出现有的语义审查方法存在理论上的限制，由于LLM的程序化和遵循指令的能力，语义审查可以被认为是一个不可判定的问题。同时，有知识的攻击者可以重构不可容许的输出。

    

    大型语言模型(LLM)在理解复杂指令方面展现了令人印象深刻的能力。然而，它们对提供的指令的盲目遵循引发了对恶意使用风险的担忧。现有的防御机制，如LLM的模型微调或使用LLM进行输出审查，已证明是有缺陷的，因为LLM仍然可以生成有问题的回答。常用的审查方法将这个问题视为机器学习问题，并依赖于另一个语言模型来检测LLM输出中的不良内容。在本文中，我们呈现了这种语义审查方法的理论限制。具体来说，我们证明了语义审查可以被认为是一个不可判定的问题，突出了由于LLM的程序化和遵循指令的能力而引起的审查中的固有挑战。此外，我们认为这些挑战不仅限于语义审查，因为有知识的攻击者可以重构不可容许的输出。

    Large language models (LLMs) have exhibited impressive capabilities in comprehending complex instructions. However, their blind adherence to provided instructions has led to concerns regarding risks of malicious use. Existing defence mechanisms, such as model fine-tuning or output censorship using LLMs, have proven to be fallible, as LLMs can still generate problematic responses. Commonly employed censorship approaches treat the issue as a machine learning problem and rely on another LM to detect undesirable content in LLM outputs. In this paper, we present the theoretical limitations of such semantic censorship approaches. Specifically, we demonstrate that semantic censorship can be perceived as an undecidable problem, highlighting the inherent challenges in censorship that arise due to LLMs' programmatic and instruction-following capabilities. Furthermore, we argue that the challenges extend beyond semantic censorship, as knowledgeable attackers can reconstruct impermissible outputs 
    
[^53]: 使用文本分类检测虚假评论

    Detecting deceptive reviews using text classification. (arXiv:2307.10617v1 [cs.IR])

    [http://arxiv.org/abs/2307.10617](http://arxiv.org/abs/2307.10617)

    这篇论文提出了一种使用机器学习模型的方法来识别虚假评论，并通过在餐馆评论的数据集上进行实验验证了其性能。

    

    近年来，在线评论在推广任何产品或服务方面发挥着重要作用。企业可能会嵌入虚假评论以吸引客户购买他们的产品。他们甚至可能突出强调自己产品的优点或批评竞争对手的产品。市场营销人员、广告商和其他在线商业用户有动机为他们想要推广的产品编写虚假的正面评论，或者为他们真正不喜欢的产品提供虚假的负面评论。因此，识别虚假评论是一个紧迫且持续的研究领域。本研究论文提出了一种机器学习模型方法来识别虚假评论。论文调查了在一个餐馆评论的虚假意见垃圾语料库数据集上进行的多次实验的性能。我们采用了n-gram模型和最大特征来识别虚假评论。

    In recent years, online reviews play a vital role for promoting any kind of product or services. Businesses may embed fake reviews in order to attract customers to purchase their products. They may even highlight the benefits of their own product or criticize the competition's product. Marketers, advertisers, and other online business users have incentive to create fake positive reviews for products which they want to promote or give fake negative reviews for products which they really don't like. So now-a-days writing a deceptive review is inevitable thing for promoting their own business or degrading competitor's reputation. Thus, identifying deceptive reviews is an intense and on-going research area. This research paper proposes machine learning model approach to identify deceptive reviews. The paper investigates the performance of the several experiments done on a Deceptive Opinion Spam Corpus dataset of restaurants reviews. We developed a n-gram model and max features to identify 
    
[^54]: 无效逻辑，等效收益：语言模型提示中的奇怪推理

    Invalid Logic, Equivalent Gains: The Bizarreness of Reasoning in Language Model Prompting. (arXiv:2307.10573v1 [cs.AI])

    [http://arxiv.org/abs/2307.10573](http://arxiv.org/abs/2307.10573)

    最近的研究发现，在语言模型的提示中使用逻辑上无效的Chain-of-Thought（CoT）提示几乎可以提供与逻辑上有效的提示相似的性能增益，而且在最困难的任务上也是如此。

    

    语言模型可以被提示以一种显著提高性能的方式进行推理问题。然而，为什么这样的提示会提高性能还不清楚。最近的研究表明，使用逻辑上无效的CoT提示几乎可以像逻辑上有效的CoT提示一样显著提高性能，并且将CoT提示中的特定问题信息替换为抽象信息或超出分布的信息通常不会损害性能。批评人士回应说，这些发现是基于太少、太简单的任务来得出有意义的结论。为了解决这个争议，我们测试了在BIG-Bench基准测试中最困难的任务上，逻辑上无效的CoT提示是否提供与逻辑上有效的提示相同水平的性能提升，这些任务被称为BIG-Bench Hard（BBH）。我们发现，在BBH任务上，逻辑上无效的推理提示确实实现了类似的性能提升。

    Language models can be prompted to reason through problems in a manner that significantly improves performance. However, \textit{why} such prompting improves performance is unclear. Recent work showed that using logically \textit{invalid} Chain-of-Thought (CoT) prompting improves performance almost as much as logically \textit{valid} CoT prompting, and that editing CoT prompts to replace problem-specific information with abstract information or out-of-distribution information typically doesn't harm performance. Critics have responded that these findings are based on too few and too easy tasks to draw meaningful conclusions. To resolve this dispute, we test whether logically invalid CoT prompts offer the same level of performance gains as logically valid prompts on the hardest tasks in the BIG-Bench benchmark, termed BIG-Bench Hard (BBH). We find that the logically \textit{invalid} reasoning prompts do indeed achieve similar performance gains on BBH tasks as logically valid reasoning pr
    
[^55]: 使用合规化动态图学习预测空中交通管制员工作负荷水平

    Air Traffic Controller Workload Level Prediction using Conformalized Dynamical Graph Learning. (arXiv:2307.10559v1 [cs.LG])

    [http://arxiv.org/abs/2307.10559](http://arxiv.org/abs/2307.10559)

    本研究提出了一种使用合规化动态图学习来预测空中交通管制员工作负荷水平的方法，通过对退休空中交通管制员进行人机交互模拟，利用空中交通数据和工作负荷标签进行预测和评估。

    

    空中交通管制是一个安全关键的服务系统，要求地面空中交通管制员（ATCo）时刻关注以维持日常航空运营。ATCo的工作负荷可能对运营安全和空域使用产生负面影响。为了避免过载并确保ATCo的可接受工作负荷水平，准确预测ATCo的工作负荷对于采取缓解措施非常重要。在本文中，我们首先对ATCo工作负荷的研究进行了回顾，主要从空中交通的角度。然后，我们简要介绍了与退休ATCo进行人机交互模拟的设置，其中获得了空中交通数据和工作负荷标签。模拟在三种菲尼克斯接近场景下进行，要求人类ATCo自我评估其工作负荷评级（即，低-1到高-7）。进行了初步的数据分析。接下来，我们提出了一个基于图的深度学习框架，结合合规化预测，来对ATCo的工作负荷进行预测。

    Air traffic control (ATC) is a safety-critical service system that demands constant attention from ground air traffic controllers (ATCos) to maintain daily aviation operations. The workload of the ATCos can have negative effects on operational safety and airspace usage. To avoid overloading and ensure an acceptable workload level for the ATCos, it is important to predict the ATCos' workload accurately for mitigation actions. In this paper, we first perform a review of research on ATCo workload, mostly from the air traffic perspective. Then, we briefly introduce the setup of the human-in-the-loop (HITL) simulations with retired ATCos, where the air traffic data and workload labels are obtained. The simulations are conducted under three Phoenix approach scenarios while the human ATCos are requested to self-evaluate their workload ratings (i.e., low-1 to high-7). Preliminary data analysis is conducted. Next, we propose a graph-based deep-learning framework with conformal prediction to ide
    
[^56]: 图像和声音的滥用用于在多模态LLMs中进行间接指令注入

    (Ab)using Images and Sounds for Indirect Instruction Injection in Multi-Modal LLMs. (arXiv:2307.10490v1 [cs.CR])

    [http://arxiv.org/abs/2307.10490](http://arxiv.org/abs/2307.10490)

    本论文展示了如何利用图像和声音在多模态LLMs中进行间接指令注入，攻击者通过生成对抗扰动并将其融入图像或音频录音中，以操纵模型输出特定文本和指导对话的行为。

    

    我们展示了如何利用图像和声音在多模态LLMs中进行间接提示和指令注入。攻击者生成与提示相对应的对抗扰动，并将其融入图像或音频录音中。当用户向（未修改的良性）模型询问被扰动的图像或音频时，扰动会引导模型输出攻击者选择的文本和/或使后续对话遵循攻击者的指令。我们用几个概念验证示例针对LLaVa和PandaGPT来说明这种攻击。

    We demonstrate how images and sounds can be used for indirect prompt and instruction injection in multi-modal LLMs. An attacker generates an adversarial perturbation corresponding to the prompt and blends it into an image or audio recording. When the user asks the (unmodified, benign) model about the perturbed image or audio, the perturbation steers the model to output the attacker-chosen text and/or make the subsequent dialog follow the attacker's instruction. We illustrate this attack with several proof-of-concept examples targeting LLaVa and PandaGPT.
    
[^57]: 数据科学的价值取向：数据科学的本质、价值和风险

    A data science axiology: the nature, value, and risks of data science. (arXiv:2307.10460v1 [cs.AI])

    [http://arxiv.org/abs/2307.10460](http://arxiv.org/abs/2307.10460)

    这篇论文介绍了数据科学的价值取向，探讨了其特征和作用。数据科学不是一门科学，而是一种研究范式，具有广泛的应用和重大的影响，但也存在着未知的风险。这一领域仍然处于初级阶段，需要进一步的研究。

    

    数据科学不是一门科学，而是一种研究范式，具有无法预测的范围、规模、复杂性和知识发现能力，这是其他方式无法实现的，并且可能超出人类推理的能力。它已经在AI军备竞赛中广泛应用于数以万计的应用程序中，已经实质性地改变了我们的世界，但由于其不可思议的复杂性，可能带来未知的风险。本文介绍了数据科学的价值取向，探讨和评估了其显著而决定性的特征，以便了解和定义数据科学，认识到其潜在的益处、风险和开放性研究挑战。基于AI的数据科学本质上涉及不确定性，这可能比我们对科学确定性的偏好更加现实。数据科学将产生远远超出知识发现的影响。

    Data science is not a science. It is a research paradigm with an unfathomed scope, scale, complexity, and power for knowledge discovery that is not otherwise possible and can be beyond human reasoning. It is changing our world practically and profoundly already widely deployed in tens of thousands of applications in every discipline in an AI Arms Race that, due to its inscrutability, can lead to unfathomed risks. This paper presents an axiology of data science, its purpose, nature, importance, risks, and value for problem solving, by exploring and evaluating its remarkable, definitive features. As data science is in its infancy, this initial, speculative axiology is intended to aid in understanding and defining data science to recognize its potential benefits, risks, and open research challenges. AI based data science is inherently about uncertainty that may be more realistic than our preference for the certainty of science. Data science will have impacts far beyond knowledge discovery
    
[^58]: SentimentGPT：利用GPT进行高级情感分析及其与当前机器学习方法的差异

    SentimentGPT: Exploiting GPT for Advanced Sentiment Analysis and its Departure from Current Machine Learning. (arXiv:2307.10234v1 [cs.CL])

    [http://arxiv.org/abs/2307.10234](http://arxiv.org/abs/2307.10234)

    本研究通过利用GPT进行高级情感分析，并考察其与当前机器学习方法的差异，发现GPT方法相较于其他模型在预测性能上具有显著优势，并有效解决了情感分析任务中的一些挑战，如理解上下文和检测讽刺。

    

    本研究对情感分析中各种生成预训练转换器（GPT）方法进行了全面的考察，特别是在SemEval 2017数据集的任务4中。采用了三种主要策略：1）使用GPT-3.5 Turbo进行提示工程，2）对GPT模型进行微调，3）采用创新的嵌入分类方法。研究结果揭示了这些策略和个别GPT模型之间的详细比较见解，展示了它们独特的优势和潜在的局限性。此外，本研究将这些基于GPT的方法与其他同时代、高性能的模型在相同数据集上进行比较。结果表明，GPT方法在预测性能方面具有显著的优势，相较于最先进技术，F1分数增加了22%以上。此外，本论文还探讨了情感分析任务中的常见挑战，如理解上下文和检测讽刺。研究强调了GPT方法的重要价值和潜力。

    This study presents a thorough examination of various Generative Pretrained Transformer (GPT) methodologies in sentiment analysis, specifically in the context of Task 4 on the SemEval 2017 dataset. Three primary strategies are employed: 1) prompt engineering using the advanced GPT-3.5 Turbo, 2) fine-tuning GPT models, and 3) an inventive approach to embedding classification. The research yields detailed comparative insights among these strategies and individual GPT models, revealing their unique strengths and potential limitations. Additionally, the study compares these GPT-based methodologies with other contemporary, high-performing models previously used with the same dataset. The results illustrate the significant superiority of the GPT approaches in terms of predictive performance, more than 22% in F1-score compared to the state-of-the-art. Further, the paper addresses common challenges in sentiment analysis tasks, such as understanding context and detecting sarcasm. It underscores
    
[^59]: 一个用于道路段推荐维护的决策框架

    A decision making framework for recommended maintenance of road segments. (arXiv:2307.10085v1 [cs.AI])

    [http://arxiv.org/abs/2307.10085](http://arxiv.org/abs/2307.10085)

    这项研究提出了一个决策框架，通过整合多种人工智能决策技术和历史数据，为道路管理部门提供科学决策工具和证据，以解决道路维护的问题。

    

    随着全球道路交通的快速发展，各国已完成了道路网络的建设。然而，随之而来的挑战在于现有道路的维护。众所周知，各国在道路维护项目上的预算有限，道路管理部门在进行科学决策方面面临困难。因此，将各种人工智能决策技术与历史维护数据相结合，以适应道路维护科学决策的背景，成为一个迫切的问题。这种整合旨在为道路管理部门提供更科学的工具和证据，以进行决策。本文提出的框架主要解决以下四个问题：1）预测各路线的路面性能，2）确定维护路线的优先级，3）基于评估标准制定维护决策。

    With the rapid development of global road transportation, countries worldwide have completed the construction of road networks. However, the ensuing challenge lies in the maintenance of existing roads. It is well-known that countries allocate limited budgets to road maintenance projects, and road management departments face difficulties in making scientifically informed maintenance decisions. Therefore, integrating various artificial intelligence decision-making techniques to thoroughly explore historical maintenance data and adapt them to the context of road maintenance scientific decision-making has become an urgent issue. This integration aims to provide road management departments with more scientific tools and evidence for decision-making. The framework proposed in this paper primarily addresses the following four issues: 1) predicting the pavement performance of various routes, 2) determining the prioritization of maintenance routes, 3) making maintenance decisions based on the e
    
[^60]: 通过使用多粒度主题分析方法的实证研究：生育政策提案

    An Empirical Study on Fertility Proposals Using Multi-Grined Topic Analysis Methods. (arXiv:2307.10025v1 [cs.HC])

    [http://arxiv.org/abs/2307.10025](http://arxiv.org/abs/2307.10025)

    本研究通过采用多粒度主题分析方法，对微博评论进行语义分析，发现关于取消婚姻登记的生育限制的提案涉及个人、社会和国家三个维度，详细讨论了个人行为、社会伦理和法律以及国家政策等社会问题。

    

    生育问题与人口安全密切相关，中国60年来首次出现人口负增长趋势，生育政策的变化引起了社会的极大关注。本文采用共现语义分析、主题分析和情感分析等方法，对微博评论进行多粒度的语义分析。发现关于“取消婚姻登记的生育限制”的提案讨论涉及个人、社会和国家三个维度，并详细探讨了个人行为、社会伦理和法律以及国家政策等社会问题。

    Fertility issues are closely related to population security, in 60 years China's population for the first time in a negative growth trend, the change of fertility policy is of great concern to the community. 2023 ``two sessions" proposal ``suggests that the country in the form of legislation, the birth of the registration of the cancellation of the marriage restriction" This topic was once a hot topic on the Internet, and ``unbundling" the relationship between birth registration and marriage has become the focus of social debate. In this paper, we adopt co-occurrence semantic analysis, topic analysis and sentiment analysis to conduct multi-granularity semantic analysis of microblog comments. It is found that the discussion on the proposal of ``removing marriage restrictions from birth registration" involves the individual, society and the state at three dimensions, and is detailed into social issues such as personal behaviour, social ethics and law, and national policy, with people's s
    
[^61]: PubMed及其他：生物医学文献检索的最新进展和最佳实践

    PubMed and Beyond: Recent Advances and Best Practices in Biomedical Literature Search. (arXiv:2307.09683v1 [cs.IR])

    [http://arxiv.org/abs/2307.09683](http://arxiv.org/abs/2307.09683)

    本论文总结了生物医学文献检索领域的最新进展和最佳实践，介绍了针对不同生物医学信息需求的文献检索工具，并旨在帮助读者高效满足其信息需求。

    

    生物医学研究产生了丰富的信息，其中很多只能通过文献获取。因此，文献检索是临床和生物医学研究中建立在先前知识基础上的重要工具。尽管人工智能的最新进展已经将功能扩展到了超越基于关键字的搜索，但这些进展可能对临床医生和研究人员来说还比较陌生。为了解决这个问题，本文介绍了一些特定于生物医学领域信息需求的文献检索工具，旨在帮助读者高效地满足他们的信息需求。我们首先对广泛使用的PubMed搜索引擎进行了讨论，包括最新的改进和仍然存在的挑战。然后，我们描述了五种特定信息需求的文献检索工具：1.为循证医学寻找高质量临床研究。2.为精准医学和基因组学检索基因相关信息。3.根据意义搜索。

    Biomedical research yields a wealth of information, much of which is only accessible through the literature. Consequently, literature search is an essential tool for building on prior knowledge in clinical and biomedical research. Although recent improvements in artificial intelligence have expanded functionality beyond keyword-based search, these advances may be unfamiliar to clinicians and researchers. In response, we present a survey of literature search tools tailored to both general and specific information needs in biomedicine, with the objective of helping readers efficiently fulfill their information needs. We first examine the widely used PubMed search engine, discussing recent improvements and continued challenges. We then describe literature search tools catering to five specific information needs: 1. Identifying high-quality clinical research for evidence-based medicine. 2. Retrieving gene-related information for precision medicine and genomics. 3. Searching by meaning, inc
    
[^62]: 基于Transformer的双域网络用于少视角心脏SPECT图像重建

    Transformer-based Dual-domain Network for Few-view Dedicated Cardiac SPECT Image Reconstructions. (arXiv:2307.09624v1 [eess.IV])

    [http://arxiv.org/abs/2307.09624](http://arxiv.org/abs/2307.09624)

    提出了一种基于Transformer的双域网络用于少视角心脏SPECT图像重建，通过定制的投影到图像域转换器直接从投影数据中重建三维心脏SPECT图像，以提高图像质量。

    

    心血管疾病(CVD)是全球死亡原因的主要因素，心肌灌注成像使用SPECT在CVD的诊断中被广泛应用。GE 530/570c专用心脏SPECT扫描仪采用静态几何形式，同时获取19个投影以提高灵敏度和实现动态成像。然而，有限的角度采样对图像质量产生负面影响。深度学习方法可以用于从静态数据中生成更高质量的图像。这本质上是一个少视角成像问题。在这项工作中，我们提出了一种名为TIP-Net的新型三维Transformer双域网络，用于高质量的三维心脏SPECT图像重建。我们的方法旨在通过提出一个定制的投影到图像域转换器，直接从投影数据中重建三维心脏SPECT图像，而不需要迭代重建过程。然后，给定其重建输出和原始的少视角重建，我们进一步

    Cardiovascular disease (CVD) is the leading cause of death worldwide, and myocardial perfusion imaging using SPECT has been widely used in the diagnosis of CVDs. The GE 530/570c dedicated cardiac SPECT scanners adopt a stationary geometry to simultaneously acquire 19 projections to increase sensitivity and achieve dynamic imaging. However, the limited amount of angular sampling negatively affects image quality. Deep learning methods can be implemented to produce higher-quality images from stationary data. This is essentially a few-view imaging problem. In this work, we propose a novel 3D transformer-based dual-domain network, called TIP-Net, for high-quality 3D cardiac SPECT image reconstructions. Our method aims to first reconstruct 3D cardiac SPECT images directly from projection data without the iterative reconstruction process by proposing a customized projection-to-image domain transformer. Then, given its reconstruction output and the original few-view reconstruction, we further 
    
[^63]: 基于循环一致性的无监督深度图匹配

    Unsupervised Deep Graph Matching Based on Cycle Consistency. (arXiv:2307.08930v1 [cs.CV])

    [http://arxiv.org/abs/2307.08930](http://arxiv.org/abs/2307.08930)

    本文提出了一种基于循环一致性的无监督深度图匹配方法，不需要真实对应的关键点对，通过在同一对象类别的图像之间强制匹配一致性来进行自我监督学习，该方法具有很高的灵活性，并且在无监督图匹配方面达到了最新的最先进水平。

    

    我们在稀疏领域的无监督深度图匹配中做出了贡献，应用于图像中的关键点匹配。与标准的“监督”方法相反，我们的方法不需要关键点对之间的真实对应。相反，它通过强制同一对象类别的图像之间的匹配一致性来进行自我监督。由于匹配和一致性损失是离散的，它们的导数不能直接用于学习。我们通过在组合求解器的黑盒微分的最新结果基础上构建我们的方法来解决这个问题。这使得我们的方法非常灵活，因为它与任意网络架构和组合求解器兼容。我们的实验评估表明，我们的技术在无监督图匹配方面达到了新的最先进水平。

    We contribute to the sparsely populated area of unsupervised deep graph matching with application to keypoint matching in images. Contrary to the standard \emph{supervised} approach, our method does not require ground truth correspondences between keypoint pairs. Instead, it is self-supervised by enforcing consistency of matchings between images of the same object category. As the matching and the consistency loss are discrete, their derivatives cannot be straightforwardly used for learning. We address this issue in a principled way by building our method upon the recent results on black-box differentiation of combinatorial solvers. This makes our method exceptionally flexible, as it is compatible with arbitrary network architectures and combinatorial solvers. Our experimental evaluation suggests that our technique sets a new state-of-the-art for unsupervised graph matching.
    
[^64]: 使用大型语言模型增强密集检索的软提示调优

    Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models. (arXiv:2307.08303v1 [cs.IR] CROSS LISTED)

    [http://arxiv.org/abs/2307.08303](http://arxiv.org/abs/2307.08303)

    本论文提出了一种使用软提示调优来增强密集检索的方法（SPTAR）。通过优化任务特定的软提示并利用大型语言模型为未标记的文档生成弱查询，可以提高零样本和少样本的密集检索模型的性能。

    

    密集检索（DR）将查询和文档转化为密集向量表示，并在向量空间中测量查询与文档之间的相似性。DR的一个挑战是缺乏领域特定的训练数据。虽然DR模型可以通过迁移学习从大规模公共数据集（如MS MARCO）中学习，但证据表明，并非所有DR模型和领域都能同等受益于迁移学习。最近，一些研究人员转向使用大型语言模型（LLMs）来改进零样本和少样本的DR模型。然而，这些方法中采用的硬提示或人工编写的提示无法保证生成的弱查询的质量。为了解决这个问题，我们提出了用于增强DR的软提示调优（SPTAR）：对于每个任务，我们利用软提示调优在有限的真实数据上优化任务特定的软提示，然后用这些提示引导LLMs为未标记的文档标记弱查询，从而得到足够的弱文档-查询对来训练任务特定的模型。

    Dense retrieval (DR) converts queries and documents into dense embeddings and measures the similarity between queries and documents in vector space. One of the challenges in DR is the lack of domain-specific training data. While DR models can learn from large-scale public datasets like MS MARCO through transfer learning, evidence shows that not all DR models and domains can benefit from transfer learning equally. Recently, some researchers have resorted to large language models (LLMs) to improve the zero-shot and few-shot DR models. However, the hard prompts or human-written prompts utilized in these works cannot guarantee the good quality of generated weak queries. To tackle this, we propose soft prompt tuning for augmenting DR (SPTAR): For each task, we leverage soft prompt-tuning to optimize a task-specific soft prompt on limited ground truth data and then prompt the LLMs to tag unlabeled documents with weak queries, yielding enough weak document-query pairs to train task-specific d
    
[^65]: Disco-Bench: 一种面向语言建模的论述感知评估基准

    Disco-Bench: A Discourse-Aware Evaluation Benchmark for Language Modelling. (arXiv:2307.08074v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.08074](http://arxiv.org/abs/2307.08074)

    Disco-Bench是一个面向语言建模的论述感知评估基准，可以跨多个NLP任务评估句内论述属性。我们设计了文献领域的9个测试集和一个诊断测试套件来评估模型的论述知识。我们在20个不同模型上进行了评估。

    

    论述建模，即超越个别句子的语言现象，是自然语言处理(NLP)中一个基本而具有挑战性的方面。然而，现有的评估基准主要关注句间属性的评估，忽视了跨句子的关键论述现象。为了弥合这一差距，我们提出了Disco-Bench，一个可以评估各种NLP任务中句内论述属性的基准，涵盖了理解、翻译和生成。Disco-Bench包括了文献领域的9个文档级测试集，其中包含了中文和/或英文中丰富的论述现象（如连贯性和连贯性）。为了进行语言分析，我们还设计了一套诊断测试套件，可以检查目标模型是否学习到了论述知识。我们总共评估了20个基于Transformer、先进的预训练架构和大型语言模型(LLM)的通用型、领域内和商业化模型。

    Modeling discourse -- the linguistic phenomena that go beyond individual sentences, is a fundamental yet challenging aspect of natural language processing (NLP). However, existing evaluation benchmarks primarily focus on the evaluation of inter-sentence properties and overlook critical discourse phenomena that cross sentences. To bridge the gap, we propose Disco-Bench, a benchmark that can evaluate intra-sentence discourse properties across a diverse set of NLP tasks, covering understanding, translation, and generation. Disco-Bench consists of 9 document-level testsets in the literature domain, which contain rich discourse phenomena (e.g. cohesion and coherence) in Chinese and/or English. For linguistic analysis, we also design a diagnostic test suite that can examine whether the target models learn discourse knowledge. We totally evaluate 20 general-, in-domain and commercial models based on Transformer, advanced pretraining architectures and large language models (LLMs). Our results 
    
[^66]: 柔性时间事件建模：通过排名回归优化神经网络

    Towards Flexible Time-to-event Modeling: Optimizing Neural Networks via Rank Regression. (arXiv:2307.08044v1 [cs.LG])

    [http://arxiv.org/abs/2307.08044](http://arxiv.org/abs/2307.08044)

    本研究提出了一种深度AFT排名回归模型，用于灵活地进行时间事件建模，从而改善预测性能并减轻严格的假设。

    

    时间事件分析，也被称为生存分析，旨在根据一组特征预测事件发生的时间。这个领域面临的一个主要挑战是处理被截尾的数据，这可能使学习算法更加复杂。传统方法如Cox比例风险模型和加速失效时间（AFT）模型在这个领域很受欢迎，但它们经常需要一些假设，如比例风险和线性。特别是，AFT模型通常需要预先指定的参数分布假设。为了提高预测性能和减轻严格的假设，近年来出现了许多基于深度学习的危险模型方法。然而，神经网络文献中对于AFT的表示学习尚未广泛探索，尽管相对于以危险为重点的方法而言，它更加简单和可解释。在这项工作中，我们引入了深度AFT排名回归模型来进行时间事件预测。

    Time-to-event analysis, also known as survival analysis, aims to predict the time of occurrence of an event, given a set of features. One of the major challenges in this area is dealing with censored data, which can make learning algorithms more complex. Traditional methods such as Cox's proportional hazards model and the accelerated failure time (AFT) model have been popular in this field, but they often require assumptions such as proportional hazards and linearity. In particular, the AFT models often require pre-specified parametric distributional assumptions. To improve predictive performance and alleviate strict assumptions, there have been many deep learning approaches for hazard-based models in recent years. However, representation learning for AFT has not been widely explored in the neural network literature, despite its simplicity and interpretability in comparison to hazard-focused methods. In this work, we introduce the Deep AFT Rank-regression model for Time-to-event predic
    
[^67]: AspectCSE: 使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入

    AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge. (arXiv:2307.07851v1 [cs.CL])

    [http://arxiv.org/abs/2307.07851](http://arxiv.org/abs/2307.07851)

    AspectCSE是一种使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入方法，它在信息检索任务中相比之前的最好结果平均提高了3.97%，通过同时考虑多个特定方面的嵌入模型优于单方面嵌入。

    

    通用的句子嵌入提供了对语义文本相似性的粗略近似，但忽略了使文本相似的特定方面。相反，基于方面的句子嵌入提供了基于预定义方面的文本相似性。因此，文本的相似性预测更加针对特定要求，并且更容易解释。在本文中，我们提出了AspectCSE，一种用于基于方面的对比学习句子嵌入的方法。结果表明，与之前最好的结果相比，AspectCSE在多个方面的信息检索任务中实现了平均改善3.97%。我们还提出使用Wikidata知识图属性来训练多方面句子嵌入模型，其中在相似性预测过程中同时考虑多个特定方面。我们证明了多方面嵌入在特定方面信息检索任务上优于单方面嵌入。最后，我们展示了嵌入模型的可解释性，并提出通过对比学习来改进嵌入质量。

    Generic sentence embeddings provide a coarse-grained approximation of semantic textual similarity but ignore specific aspects that make texts similar. Conversely, aspect-based sentence embeddings provide similarities between texts based on certain predefined aspects. Thus, similarity predictions of texts are more targeted to specific requirements and more easily explainable. In this paper, we present AspectCSE, an approach for aspect-based contrastive learning of sentence embeddings. Results indicate that AspectCSE achieves an average improvement of 3.97% on information retrieval tasks across multiple aspects compared to the previous best results. We also propose using Wikidata knowledge graph properties to train models of multi-aspect sentence embeddings in which multiple specific aspects are simultaneously considered during similarity predictions. We demonstrate that multi-aspect embeddings outperform single-aspect embeddings on aspect-specific information retrieval tasks. Finally, w
    
[^68]: 使用反事实路径的可解释人工智能

    Explainable AI with counterfactual paths. (arXiv:2307.07764v1 [cs.AI])

    [http://arxiv.org/abs/2307.07764](http://arxiv.org/abs/2307.07764)

    本文提出了一种新颖的可解释人工智能方法，使用反事实路径来生成解释。通过确定替代路径，可以提供更直观和可解释的解释模型行为的方式，并帮助识别和减轻模型中的偏见。

    

    可解释人工智能是机器学习中日益重要的一个研究领域，其原则上旨在使黑盒模型透明可解释。本文提出了一种新颖的可解释人工智能方法，该方法利用条件置换生成了反事实路径。我们的方法通过确定可能导致不同结果的替代路径来提供反事实解释。所提出的方法特别适用于基于知识图谱的反事实路径解释的生成。通过检查知识图谱中输入数据的假设性变化，我们可以系统地验证模型的行为，并检查对模型预测最重要的特征或特征组合。我们的方法提供了比传统的特征加权方法更直观和可解释的解释模型行为的方式，并可以帮助识别和减轻模型中的偏见。

    Explainable AI (XAI) is an increasingly important area of research in machine learning, which in principle aims to make black-box models transparent and interpretable. In this paper, we propose a novel approach to XAI that uses counterfactual paths generated by conditional permutations. Our method provides counterfactual explanations by identifying alternative paths that could have led to different outcomes. The proposed method is particularly suitable for generating explanations based on counterfactual paths in knowledge graphs. By examining hypothetical changes to the input data in the knowledge graph, we can systematically validate the behaviour of the model and examine the features or combination of features that are most important to the model's predictions. Our approach provides a more intuitive and interpretable explanation for the model's behaviour than traditional feature weighting methods and can help identify and mitigate biases in the model.
    
[^69]: Co-Attention Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery（用于机器人手术中视觉问答定位的共同关注门控视觉-语言嵌入）

    Co-Attention Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery. (arXiv:2307.05182v1 [cs.CV])

    [http://arxiv.org/abs/2307.05182](http://arxiv.org/abs/2307.05182)

    这项研究提出了一种用于机器人手术中视觉问答定位的共同关注门控视觉-语言嵌入方法，可以为医学生和初级外科医生提供学习和理解手术视频的帮助。

    

    医学生和初级外科医生在学习手术时通常依赖于高级外科医生和专家回答他们的问题。然而，专家们经常忙于临床和学术工作，没有多少时间提供指导。与此同时，现有的基于深度学习的外科视觉问答系统只能提供简单答案，而没有答案的位置信息。此外，在这类任务中，视觉语言嵌入仍然是一个较少探索的领域。因此，一种外科视觉问答定位系统对于医学生和初级外科医生从录制的手术视频中学习和理解是有帮助的。我们提出了一种适用于外科场景的端到端Transformer与共同关注门控视觉-语言（CAT-ViL）的VQLA方法，它不需要通过检测模型进行特征提取。CAT-ViL嵌入模块的设计旨在融合来自视觉和文本来源的异构特征。

    Medical students and junior surgeons often rely on senior surgeons and specialists to answer their questions when learning surgery. However, experts are often busy with clinical and academic work, and have little time to give guidance. Meanwhile, existing deep learning (DL)-based surgical Visual Question Answering (VQA) systems can only provide simple answers without the location of the answers. In addition, vision-language (ViL) embedding is still a less explored research in these kinds of tasks. Therefore, a surgical Visual Question Localized-Answering (VQLA) system would be helpful for medical students and junior surgeons to learn and understand from recorded surgical videos. We propose an end-to-end Transformer with Co-Attention gaTed Vision-Language (CAT-ViL) for VQLA in surgical scenarios, which does not require feature extraction through detection models. The CAT-ViL embedding module is designed to fuse heterogeneous features from visual and textual sources. The fused embedding 
    
[^70]: 选择好对手：如何指导程序化策略的合成

    Choosing Well Your Opponents: How to Guide the Synthesis of Programmatic Strategies. (arXiv:2307.04893v1 [cs.LG])

    [http://arxiv.org/abs/2307.04893](http://arxiv.org/abs/2307.04893)

    这篇论文介绍了一种名为2L的算法，该算法能够提供引导合成程序化策略的参考策略，通过在实验中的表现和在MicroRTS锦标赛中的胜利，证明了2L算法相对于其他学习算法的优势。

    

    本论文介绍了一种名为Local Learner (2L)的算法，用于提供一组参考策略，以指导在两人零和博弈中搜索程序化策略。之前的学习算法，如迭代最佳响应算法(IBR)，虚构游戏算法(FP)和双正交算法(DO)，计算复杂度较高或会漏掉指导搜索算法的重要信息。2L主动选择一组参考策略以提高搜索信号。我们通过在三个游戏中引导局部搜索算法来实证我们的方法优势，其中包括MicroRTS，一个具有挑战性的实时战略游戏。结果表明，2L学习到的参考策略提供了比IBR，FP和DO更强的搜索信号。我们还模拟了一场MicroRTS锦标赛，其中使用2L合成器的表现超过了两个最新MicroRTS比赛的胜者，这些胜者均为人类编程员编写的程序化策略。

    This paper introduces Local Learner (2L), an algorithm for providing a set of reference strategies to guide the search for programmatic strategies in two-player zero-sum games. Previous learning algorithms, such as Iterated Best Response (IBR), Fictitious Play (FP), and Double-Oracle (DO), can be computationally expensive or miss important information for guiding search algorithms. 2L actively selects a set of reference strategies to improve the search signal. We empirically demonstrate the advantages of our approach while guiding a local search algorithm for synthesizing strategies in three games, including MicroRTS, a challenging real-time strategy game. Results show that 2L learns reference strategies that provide a stronger search signal than IBR, FP, and DO. We also simulate a tournament of MicroRTS, where a synthesizer using 2L outperformed the winners of the two latest MicroRTS competitions, which were programmatic strategies written by human programmers.
    
[^71]: 将苹果与苹果进行比较：从用户评论生成纵向感知的比较句子

    Comparing Apples to Apples: Generating Aspect-Aware Comparative Sentences from User Review. (arXiv:2307.03691v1 [cs.CL])

    [http://arxiv.org/abs/2307.03691](http://arxiv.org/abs/2307.03691)

    该论文提出了一个模型，利用用户评论和相关项目特征生成对比评价句子，以帮助用户找到最适合的产品。该模型包括项目编码模块、比较生成模块和个性化解码方法，并通过人类评估验证了生成句子的相关性和真实性。

    

    在众多相似的选择中找到最佳产品是非常耗时的。比较句子可以帮助我们以突出的方式对比一个项目与其他项目，在此过程中强调出重要特征。基于用户对一个或多个项目的评论及相关项目特征，我们生成比较评论句子来帮助用户找到最适合的产品。具体来说，我们的模型包括三个连续组件：（i）一个项目编码模块用于对项目进行编码比较，（ii）一个比较生成模块以自回归的方式生成比较句子，（iii）一种用于用户个性化的新型解码方法。我们展示了我们的流程能够生成流畅且多样的比较句子。我们进行了人类评估研究来验证我们生成的句子的相关性和真实性，结果表明我们的算法能够生成相关且真实的比较评论句子。

    It is time-consuming to find the best product among many similar alternatives. Comparative sentences can help to contrast one item from others in a way that highlights important features of an item that stand out. Given reviews of one or multiple items and relevant item features, we generate comparative review sentences to aid users to find the best fit. Specifically, our model consists of three successive components in a transformer: (i) an item encoding module to encode an item for comparison, (ii) a comparison generation module that generates comparative sentences in an autoregressive manner, (iii) a novel decoding method for user personalization. We show that our pipeline generates fluent and diverse comparative sentences. We run experiments on the relevance and fidelity of our generated sentences in a human evaluation study and find that our algorithm creates comparative review sentences that are relevant and truthful.
    
[^72]: 使用适配器高效域自适应句子嵌入

    Efficient Domain Adaptation of Sentence Embeddings using Adapters. (arXiv:2307.03104v1 [cs.CL])

    [http://arxiv.org/abs/2307.03104](http://arxiv.org/abs/2307.03104)

    本论文提出了一种通过训练轻量级适配器来高效域自适应句子嵌入的方法，避免了微调整个句子嵌入模型的资源消耗。通过训练特定领域的适配器，可以在不同领域中使用同一模型获得良好的性能。

    

    句子嵌入使我们能够捕捉短文本的语义相似性。大多数句子嵌入模型是针对一般语义文本相似性（STS）任务进行训练的。因此，要在特定领域中使用句子嵌入，必须将模型适应于该领域以获得良好的结果。通常，这是通过对感兴趣的域对整个句子嵌入模型进行微调来实现的。虽然这种方法能够产生最先进的结果，但在微调过程中更新了所有模型的权重，使该方法在资源上要求较高。因此，我们提出了训练轻量级适配器的方法，而不是单独为每个目标领域微调整个句子嵌入模型。这些特定领域的适配器不需要微调所有底层句子嵌入模型的参数。相反，我们只训练少量的额外参数，同时保持底层句子嵌入模型的权重不变。训练特定领域的适配器可以始终使用同一模型并在不同领域中获得良好的性能。

    Sentence embeddings enable us to capture the semantic similarity of short texts. Most sentence embedding models are trained for general semantic textual similarity (STS) tasks. Therefore, to use sentence embeddings in a particular domain, the model must be adapted to it in order to achieve good results. Usually, this is done by fine-tuning the entire sentence embedding model for the domain of interest. While this approach yields state-of-the-art results, all of the model's weights are updated during fine-tuning, making this method resource-intensive. Therefore, instead of fine-tuning entire sentence embedding models for each target domain individually, we propose to train lightweight adapters. These domain-specific adapters do not require fine-tuning all underlying sentence embedding model parameters. Instead, we only train a small number of additional parameters while keeping the weights of the underlying sentence embedding model fixed. Training domain-specific adapters allows always 
    
[^73]: 在观测代价敏感强化学习中的动态观测策略

    Dynamic Observation Policies in Observation Cost-Sensitive Reinforcement Learning. (arXiv:2307.02620v1 [cs.LG])

    [http://arxiv.org/abs/2307.02620](http://arxiv.org/abs/2307.02620)

    本文研究了在观测代价敏感强化学习中，强化学习代理在每个时间步不需要昂贵的测量，提出了一种新的方法DMSOA，并在多个环境中进行了评估，结果表明DMSOA能够以更少的决策步骤和测量次数学到更好的策略。

    

    强化学习已被证明可以学习复杂任务的高级控制策略，包括游戏、机器人、供暖与制冷系统和文本生成。然而，强化学习中的动作-感知循环通常假设在每个时间步都可以获得对环境状态的测量，且不产生成本。然而，在深海和行星机器人探索、材料设计和医学等应用中，测量或者近似环境状态可能会产生高昂的成本。本文调查了近来不断增长的文献，采取了RL代理可能不需要或者不想在每个时间步进行昂贵测量的观点。在这个背景下，我们提出了Deep Dynamic Multi-Step Observationless Agent (DMSOA)，并将其与文献进行对比，并在OpenAI gym和Atari Pong环境中进行了实证评估。我们的结果显示，DMSOA能够以更少的决策步骤和测量次数学到更好的策略。

    Reinforcement learning (RL) has been shown to learn sophisticated control policies for complex tasks including games, robotics, heating and cooling systems and text generation. The action-perception cycle in RL, however, generally assumes that a measurement of the state of the environment is available at each time step without a cost. In applications such as deep-sea and planetary robot exploration, materials design and medicine, however, there can be a high cost associated with measuring, or even approximating, the state of the environment. In this paper, we survey the recently growing literature that adopts the perspective that an RL agent might not need, or even want, a costly measurement at each time step. Within this context, we propose the Deep Dynamic Multi-Step Observationless Agent (DMSOA), contrast it with the literature and empirically evaluate it on OpenAI gym and Atari Pong environments. Our results, show that DMSOA learns a better policy with fewer decision steps and meas
    
[^74]: ODD: 一份基于自然语言处理的药物滥用异常行为检测的基准数据集

    ODD: A Benchmark Dataset for the NLP-based Opioid Related Aberrant Behavior Detection. (arXiv:2307.02591v1 [cs.CL])

    [http://arxiv.org/abs/2307.02591](http://arxiv.org/abs/2307.02591)

    这个研究介绍了一份名为ODD的新型基准数据集，用于通过分析患者的电子健康记录笔记，检测和分类药物滥用异常行为。这个数据集在药物相关病例的自然语言处理研究中具有重要的创新和贡献。

    

    药物滥用异常行为（ORAB）是防止药物过量的新风险因素。以往，ORAB主要通过调查结果和药物给予监测进行评估。然而，这些方法无法扩展，并不能涵盖所有异常行为的范围。然而，ORAB在电子健康记录笔记中广泛有记录。本文介绍了一个名为ODD的新型生物医学自然语言处理基准数据集，用于ORAB检测。ODD是一个专家注释的数据集，包括750多个公开可用的电子健康记录笔记。ODD旨在从患者的电子健康记录笔记中识别ORAB，并将其分类为九个类别：1）已确认异常行为，2）暗示的异常行为，3）阿片类药物，4）适应症，5）已诊断的阿片制剂依赖，6）苯二氮平类药物，7）药物变化，8）与中枢神经系统相关，9）社会健康决定因素。

    Opioid related aberrant behaviors (ORAB) present novel risk factors for opioid overdose. Previously, ORAB have been mainly assessed by survey results and by monitoring drug administrations. Such methods however, cannot scale up and do not cover the entire spectrum of aberrant behaviors. On the other hand, ORAB are widely documented in electronic health record notes. This paper introduces a novel biomedical natural language processing benchmark dataset named ODD, for ORAB Detection Dataset. ODD is an expert-annotated dataset comprising of more than 750 publicly available EHR notes. ODD has been designed to identify ORAB from patients' EHR notes and classify them into nine categories; 1) Confirmed Aberrant Behavior, 2) Suggested Aberrant Behavior, 3) Opioids, 4) Indication, 5) Diagnosed opioid dependency, 6) Benzodiapines, 7) Medication Changes, 8) Central Nervous System-related, and 9) Social Determinants of Health. We explored two state-of-the-art natural language processing (NLP) mode
    
[^75]: 定义数据科学：一种新的研究范式

    Defining data science: a new field of inquiry. (arXiv:2306.16177v1 [cs.LG])

    [http://arxiv.org/abs/2306.16177](http://arxiv.org/abs/2306.16177)

    数据科学是一种新的研究范式，具有潜力和应用广泛性，在40多个学科、数百个研究领域和成千上万个应用中出现。然而，由于其起步阶段，目前存在许多定义的冗余和不一致性的问题。

    

    数据科学不是一门科学，而是一种研究范式。它的力量、范围和规模将超越科学，成为促使知识发现并改变世界的重要手段。我们尚未理解和定义它，这对于实现其潜力和管理其风险至关重要。现代数据科学处于起步阶段。自1962年以来缓慢发展，并且自2000年以来发展迅速，它是一种根本性的新的研究领域，是21世纪最活跃、最强大和发展最快的创新之一。由于其价值、力量和适用性，它正在40多个学科、数百个研究领域和成千上万个应用中出现。数以百万计的数据科学出版物中包含了无数关于数据科学和数据科学问题解决的定义。由于其起步阶段，许多定义是独立的、应用特定的、相互不完整的、冗余的或不一致的，因此数据科学也是如此。本研究通过提出解决数据科学多重定义挑战的方法来解决这个问题。

    Data science is not a science. It is a research paradigm. Its power, scope, and scale will surpass science, our most powerful research paradigm, to enable knowledge discovery and change our world. We have yet to understand and define it, vital to realizing its potential and managing its risks. Modern data science is in its infancy. Emerging slowly since 1962 and rapidly since 2000, it is a fundamentally new field of inquiry, one of the most active, powerful, and rapidly evolving 21st century innovations. Due to its value, power, and applicability, it is emerging in 40+ disciplines, hundreds of research areas, and thousands of applications. Millions of data science publications contain myriad definitions of data science and data science problem solving. Due to its infancy, many definitions are independent, application-specific, mutually incomplete, redundant, or inconsistent, hence so is data science. This research addresses this data science multiple definitions challenge by proposing 
    
[^76]: 面向开放词汇学习的调研

    Towards Open Vocabulary Learning: A Survey. (arXiv:2306.15880v1 [cs.CV])

    [http://arxiv.org/abs/2306.15880](http://arxiv.org/abs/2306.15880)

    该论文调研了在视觉场景理解领域的开放词汇学习，在与零样本学习和开放集识别等相关概念的比较中，总结和分析了该领域的最新发展。

    

    在视觉场景理解领域，深度神经网络在分割、跟踪和检测等各种核心任务上取得了令人瞩目的进展。然而，大多数方法基于封闭集的假设，即模型只能识别训练集中已定义的类别。最近，由于视觉语言预训练的快速进展，提出了开放词汇设置。这些新方法旨在定位和识别超出注释标签空间的类别。与弱监督和零样本设置相比，开放词汇方法更加通用、实用和有效。本文对开放词汇学习进行了全面的回顾，总结和分析了近期在该领域的发展。特别是，我们首先将其与零样本学习、开放集识别和超出分布检测等相关概念进行了比较。然后，在分割任务的几个紧密相关的任务中进行了回顾。

    In the field of visual scene understanding, deep neural networks have made impressive advancements in various core tasks like segmentation, tracking, and detection. However, most approaches operate on the close-set assumption, meaning that the model can only identify pre-defined categories that are present in the training set. Recently, open vocabulary settings were proposed due to the rapid progress of vision language pre-training. These new approaches seek to locate and recognize categories beyond the annotated label space. The open vocabulary approach is more general, practical, and effective compared to weakly supervised and zero-shot settings. This paper provides a thorough review of open vocabulary learning, summarizing and analyzing recent developments in the field. In particular, we begin by comparing it to related concepts such as zero-shot learning, open-set recognition, and out-of-distribution detection. Then, we review several closely related tasks in the case of segmentati
    
[^77]: 基于大语言模型的中文细粒度金融情感分析

    Chinese Fine-Grained Financial Sentiment Analysis with Large Language Models. (arXiv:2306.14096v1 [cs.CL])

    [http://arxiv.org/abs/2306.14096](http://arxiv.org/abs/2306.14096)

    本文提出了一个用于企业预警的新型、广泛的中文细粒度金融情感分析数据集FinChina SA，并使用现有开源大语言模型对其进行评估和实验。该数据集将成为推进真实金融情感分析任务探索的宝贵资源。

    

    金融领域实体级别的细粒度情感分析是情感分析的重要子任务，目前面临着众多挑战。其中主要挑战之一来自于缺乏专门设计用于金融文本情感分析的高质量大规模标注语料库，这限制了开发有效文本处理技术所需的数据的可用性。大语言模型（LLMs）的最新进展在自然语言处理任务中取得了显著的性能，主要集中在语言模式匹配方面。在本文中，我们提出了一个新颖的、广泛的中文细粒度金融情感分析数据集FinChina SA，用于企业预警。我们对流行的现有开源LLMs使用我们的数据集进行了全面的评估和实验。我们坚信，我们的数据集将成为推动真实世界金融情感分析任务探索的宝贵资源。

    Entity-level fine-grained sentiment analysis in the financial domain is a crucial subtask of sentiment analysis and currently faces numerous challenges. The primary challenge stems from the lack of high-quality and large-scale annotated corpora specifically designed for financial text sentiment analysis, which in turn limits the availability of data necessary for developing effective text processing techniques. Recent advancements in large language models (LLMs) have yielded remarkable performance in natural language processing tasks, primarily centered around language pattern matching. In this paper, we propose a novel and extensive Chinese fine-grained financial sentiment analysis dataset, FinChina SA, for enterprise early warning. We thoroughly evaluate and experiment with well-known existing open-source LLMs using our dataset. We firmly believe that our dataset will serve as a valuable resource to advance the exploration of real-world financial sentiment analysis tasks, which shoul
    
[^78]: 使用专家观察数据进行像素学习

    Learning from Pixels with Expert Observations. (arXiv:2306.13872v2 [cs.RO] CROSS LISTED)

    [http://arxiv.org/abs/2306.13872](http://arxiv.org/abs/2306.13872)

    本文提出了一种使用专家观察数据的新方法，在像素观测中进行稀疏奖励的机器人操作任务学习。通过使用专家观察数据作为目标条件，该方法能显著改进两种最先进的智能体的性能，同时训练过程中所需的专家行动次数减少了4-20倍，并且优于分层基线模型。

    

    在强化学习中，稀疏奖励可能是一个重要的挑战。幸运的是，可以利用专家行为来克服这个问题。然而，获取明确的专家行动可能是昂贵的，而专家观察数据通常更容易获得。本文提出了一种新的方法，利用专家观察数据在稀疏奖励的像素观测中进行机器人操作任务的学习。具体而言，我们的技术将专家观察数据作为目标条件的强化学习智能体的中间视觉目标，使其通过连续达到一系列目标来完成任务。我们在仿真中展示了我们方法在五个具有挑战性的块堆叠任务中的有效性，并且实验证明，当与两种最先进的智能体相结合时，我们的方法可以显著提高它们的性能，同时在训练过程中需要的专家行动次数减少了4-20倍。此外，我们的方法也优于一个分层的基线模型。

    In reinforcement learning (RL), sparse rewards can present a significant challenge. Fortunately, expert actions can be utilized to overcome this issue. However, acquiring explicit expert actions can be costly, and expert observations are often more readily available. This paper presents a new approach that uses expert observations for learning in robot manipulation tasks with sparse rewards from pixel observations. Specifically, our technique involves using expert observations as intermediate visual goals for a goal-conditioned RL agent, enabling it to complete a task by successively reaching a series of goals. We demonstrate the efficacy of our method in five challenging block construction tasks in simulation and show that when combined with two state-of-the-art agents, our approach can significantly improve their performance while requiring 4-20 times fewer expert actions during training. Moreover, our method is also superior to a hierarchical baseline.
    
[^79]: FedSelect: 个性化联邦学习中参数自定义选择的细调方法

    FedSelect: Customized Selection of Parameters for Fine-Tuning during Personalized Federated Learning. (arXiv:2306.13264v1 [cs.LG])

    [http://arxiv.org/abs/2306.13264](http://arxiv.org/abs/2306.13264)

    本文提出了一种名为FedSelect的新联邦学习框架，通过寻找最佳客户端子网络从而直接个性化客户端子网络结构和参数，同时保留了全局知识，提高了客户端性能。

    

    联邦学习旨在通过在本地数据上微调客户端参数或针对本地任务个性化架构来提高客户端性能。然而，现有的方法要么在牺牲重要的全局知识的情况下进行个性化，要么在预先确定网络层以进行微调的情况下导致客户端模型中全局知识储存的不足。本文提出了一种新的联邦学习框架FedSelect，通过同时搜索并获得个性化最佳参数和用于全局聚合的其余参数，从而直接个性化客户子网络结构和参数。

    Recent advancements in federated learning (FL) seek to increase client-level performance by fine-tuning client parameters on local data or personalizing architectures for the local task. Existing methods for such personalization either prune a global model or fine-tune a global model on a local client distribution. However, these existing methods either personalize at the expense of retaining important global knowledge, or predetermine network layers for fine-tuning, resulting in suboptimal storage of global knowledge within client models. Enlightened by the lottery ticket hypothesis, we first introduce a hypothesis for finding optimal client subnetworks to locally fine-tune while leaving the rest of the parameters frozen. We then propose a novel FL framework, FedSelect, using this procedure that directly personalizes both client subnetwork structure and parameters, via the simultaneous discovery of optimal parameters for personalization and the rest of parameters for global aggregatio
    
[^80]: 转换器训练策略用于预测多个负载时间序列

    Transformer Training Strategies for Forecasting Multiple Load Time Series. (arXiv:2306.10891v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.10891](http://arxiv.org/abs/2306.10891)

    转换器模型在预测多负载时间序列方面使用全局训练策略比多变量和本地训练策略具有更好的性能，平均降低了21.8%和12.8%的预测误差。

    

    在未来的智能电网中，准确的负载预测可以帮助在本地平衡供需，并防止电网故障。尽管被监测的客户数量将随着不断推进的智能电表安装而增加，但每个客户的数据量始终是有限的。我们评估了转换器负载预测模型是否受益于转移学习策略，即在多个客户的负载时间序列上训练全局的单变量模型。在使用两个包含数百个客户的数据集进行的实验中，我们发现全局训练策略优于相关工作中使用的多变量和本地训练策略。平均而言，与其他两种策略相比，全局训练策略在从未来一天到一个月的预测时间范围内，预测误差降低了21.8%和12.8%。与线性模型、多层感知机和LSTM模型的比较显示，转换器训练策略效果更好。

    In the smart grid of the future, accurate load forecasts on the level of individual clients can help to balance supply and demand locally and to prevent grid outages. While the number of monitored clients will increase with the ongoing smart meter rollout, the amount of data per client will always be limited. We evaluate whether a Transformer load forecasting model benefits from a transfer learning strategy, where a global univariate model is trained on the load time series from multiple clients. In experiments with two datasets containing load time series from several hundred clients, we find that the global training strategy is superior to the multivariate and local training strategies used in related work. On average, the global training strategy results in 21.8% and 12.8% lower forecasting errors than the two other strategies, measured across forecasting horizons from one day to one month into the future. A comparison to linear models, multi-layer perceptrons and LSTMs shows that T
    
[^81]: 自监督学习在时间序列分析中的应用：分类、进展和前景

    Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects. (arXiv:2306.10125v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.10125](http://arxiv.org/abs/2306.10125)

    自监督学习（SSL）在时间序列分析中的应用取得了显著性能，通过减少对标注数据的依赖，即使只有少量标注数据，也能实现高性能。

    

    自监督学习（SSL）最近在各种时间序列任务上取得了令人瞩目的性能。SSL最突出的优势是减少对标注数据的依赖。基于预训练和微调策略，即使只有少量标注数据，也可以实现高性能。与许多关于计算机视觉和自然语言处理的自监督学习综述相比，目前还缺乏针对时间序列SSL的综述。为了填补这一空白，本文回顾了当前时间序列数据中的自监督学习（SSL）方法的最新研究进展。为此，我们首先全面回顾了与自监督学习（SSL）和时间序列相关的现有综述，然后通过总结从生成型、对比型和对抗型三个角度对现有时间序列自监督学习方法进行了新的分类。这些方法进一步细分为十个子类，详细回顾和讨论了它们的关键直觉、主要框架、优势和限制。

    Self-supervised learning (SSL) has recently achieved impressive performance on various time series tasks. The most prominent advantage of SSL is that it reduces the dependence on labeled data. Based on the pre-training and fine-tuning strategy, even a small amount of labeled data can achieve high performance. Compared with many published self-supervised surveys on computer vision and natural language processing, a comprehensive survey for time series SSL is still missing. To fill this gap, we review current state-of-the-art SSL methods for time series data in this article. To this end, we first comprehensively review existing surveys related to SSL and time series, and then provide a new taxonomy of existing time series SSL methods by summarizing them from three perspectives: generative-based, contrastive-based, and adversarial-based. These methods are further divided into ten subcategories with detailed reviews and discussions about their key intuitions, main frameworks, advantages an
    
[^82]: 通过Clausal Tableaux实现范围限制插值

    Range-Restricted Interpolation through Clausal Tableaux. (arXiv:2306.03572v1 [cs.LO])

    [http://arxiv.org/abs/2306.03572](http://arxiv.org/abs/2306.03572)

    通过Clausal Tableaux证明系统实现可行的范围限制插值算法。

    

    本文展示了如何通过一阶逻辑的Clausal Tableaux证明系统，从输入到输出传递变化的范围限制和Horn性质。本文的重点是将证明结构的操作与高度优化的一阶证明器结合起来，实现可行的实现方法。主要应用于查询合成和插值重构。

    We show how variations of range-restriction and also the Horn property can be passed from inputs to outputs of Craig interpolation in first-order logic. The proof system is clausal tableaux, which stems from first-order ATP. Our results are induced by a restriction of the clausal tableau structure, which can be achieved in general by a proof transformation, also if the source proof is by resolution/paramodulation. Primarily addressed applications are query synthesis and reformulation with interpolation. Our methodical approach combines operations on proof structures with the immediate perspective of feasible implementation through incorporating highly optimized first-order provers.
    
[^83]: 推理时间干预：从语言模型中引导出真实的答案

    Inference-Time Intervention: Eliciting Truthful Answers from a Language Model. (arXiv:2306.03341v1 [cs.LG])

    [http://arxiv.org/abs/2306.03341](http://arxiv.org/abs/2306.03341)

    本研究提出推理时间干预（ITI）技术，通过在推理过程中跨越有限数量的注意力头，显着提高大型语言模型的真实性。在TruthfulQA基准上，ITI使LLaMA模型的真实性从32.5%提高到65.1%。ITI是一种最小程度的干扰，计算廉价，且数据效率高。

    

    我们介绍了推理时间干预（ITI）技术，旨在增强大型语言模型（LLMs）的真实性。ITI通过在推理过程中沿着一组方向移动模型激活，跨越有限数量的注意力头。这种干预显着提高了LLaMA模型在TruthfulQA基准上的表现。在指令微调的LLaMA Alpaca上，ITI将其真实性从32.5％提高到65.1％。我们确定了真实性和可用性之间的权衡，并演示了如何通过调整干预强度来平衡它。ITI 取得了最低程度的干扰且计算廉价。此外，该技术在数据效率上表现优异：虽然像RLHF这样的方法需要广泛注释，但是ITI仅使用了几百个例子就能定位真实的方向。我们的研究结果表明，LLMs可能具有某种内部表示方法来表示某事是真实的可能性，即使它们在表面上产生了虚假的结果。

    We introduce Inference-Time Intervention (ITI), a technique designed to enhance the truthfulness of large language models (LLMs). ITI operates by shifting model activations during inference, following a set of directions across a limited number of attention heads. This intervention significantly improves the performance of LLaMA models on the TruthfulQA benchmark. On an instruction-finetuned LLaMA called Alpaca, ITI improves its truthfulness from 32.5% to 65.1%. We identify a tradeoff between truthfulness and helpfulness and demonstrate how to balance it by tuning the intervention strength. ITI is minimally invasive and computationally inexpensive. Moreover, the technique is data efficient: while approaches like RLHF require extensive annotations, ITI locates truthful directions using only few hundred examples. Our findings suggest that LLMs may have an internal representation of the likelihood of something being true, even as they produce falsehoods on the surface.
    
[^84]: 长文本的神经自然语言处理：现状综述

    Neural Natural Language Processing for Long Texts: A Survey of the State-of-the-Art. (arXiv:2305.16259v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.16259](http://arxiv.org/abs/2305.16259)

    本文简要概述了长文本的神经自然语言处理的现状，主要包括文档分类和摘要，涵盖了情感分析，同时还探讨了长文本NLP的主要挑战、问题和解决方案。

    

    在过去的十年中，深度神经网络（DNN）的采用极大地促进了自然语言处理（NLP）的发展。然而，长文本分析的需求与短文本有很大不同，而网络上传输的文档大小不断增加，使长文本的自动理解成为一项关键的研究领域。本文的两个目标是：a）概述相关的神经构建模块，作为短教程；b）总结长文本NLP的现状，主要关注两个核心任务：文档分类和文档摘要。情感分析也涵盖在内，因为它通常被视为文档分类的特例。此外，本文还讨论了长文本NLP相关的主要挑战、问题和解决方案。最后，介绍了相关的公开的注释数据集，以便促进进一步研究。

    The adoption of Deep Neural Networks (DNNs) has greatly benefited Natural Language Processing (NLP) during the past decade. However, the demands of long document analysis are quite different from those of shorter texts, while the ever increasing size of documents uploaded on-line renders automated understanding of long texts a critical area of research. This article has two goals: a) it overviews the relevant neural building blocks, thus serving as a short tutorial, and b) it surveys the state-of-the-art in long document NLP, mainly focusing on two central tasks: document classification and document summarization. Sentiment analysis for long texts is also covered, since it is typically treated as a particular case of document classification. Additionally, this article discusses the main challenges, issues and current solutions related to long document NLP. Finally, the relevant, publicly available, annotated datasets are presented, in order to facilitate further research.
    
[^85]: 基于视觉引导的自监督语音模型中的音节发现和跨语言泛化

    Syllable Discovery and Cross-Lingual Generalization in a Visually Grounded, Self-Supervised Speech Mode. (arXiv:2305.11435v1 [eess.AS])

    [http://arxiv.org/abs/2305.11435](http://arxiv.org/abs/2305.11435)

    本文提出采用基于视觉引导的自监督语音模型进行音节发现和跨语言泛化。使用最小割算法和2阶段聚类方法自动预测语音中的音节边界。在英语上表现优于最先进的音节分割方法，并以零样本的方式在爱沙尼亚语上泛化。在其他语言上也取得了成功。

    

    本文表明，在使用基于视觉引导的训练目标训练自监督语音模型时，能够捕捉到表示音节的单元的表征。我们证明了几乎相同的模型结构（HuBERT），在使用掩码语言建模损失进行训练时没有表现出这种能力，这表明视觉引导目标导致了这种现象的出现。我们提出使用最小割算法自动预测语音中的音节边界，然后使用两阶段聚类方法将相同的音节组合在一起。我们展示了，我们的模型不仅在训练的语言（英语）上优于最先进的音节分割方法，而且在爱沙尼亚语上以零样本的方式进行泛化。最后，我们展示了相同的模型能够进行4种其他语言的零样本单词分割任务泛化，在某些情况下击败了先前的最先进技术。

    In this paper, we show that representations capturing syllabic units emerge when training a self-supervised speech model with a visually-grounded training objective. We demonstrate that a nearly identical model architecture (HuBERT) trained with a masked language modeling loss does not exhibit this same ability, suggesting that the visual grounding objective is responsible for the emergence of this phenomenon. We propose the use of a minimum cut algorithm to automatically predict syllable boundaries in speech, followed by a 2-stage clustering method to group identical syllables together. We show that our model not only outperforms a state-of-the-art syllabic segmentation method on the language it was trained on (English), but also generalizes in a zero-shot fashion to Estonian. Finally, we show that the same model is capable of zero-shot generalization for a word segmentation task on 4 other languages from the Zerospeech Challenge, in some cases beating the previous state-of-the-art.
    
[^86]: 视觉与定义相遇：融合词义信息的无监督视觉词义消歧

    Vision Meets Definitions: Unsupervised Visual Word Sense Disambiguation Incorporating Gloss Information. (arXiv:2305.01788v1 [cs.CL])

    [http://arxiv.org/abs/2305.01788](http://arxiv.org/abs/2305.01788)

    本文提出了一种无监督的视觉词义消歧方法，通过引入外部词汇知识库的词义信息来解决原来图像-文本匹配模型中的多义词问题。采用贝叶斯推断来加入词义定义，并通过与上下文相关的 GPT-3 定义生成方法，成功解决了词典外问题。

    

    视觉词义消歧是一项任务，旨在找到最准确地描述给定上下文中目标词正确意义的图像。以往的图像-文本匹配模型往往受到词义多义性的影响。本文介绍了一种无监督的视觉词义消歧方法，该方法使用了外部词汇知识库的词汇信息，特别是词义定义。具体而言，我们建议在没有提供答案的词义信息时，采用贝叶斯推断来加入词义定义。此外，为了改进词典外问题，我们提出了一种与上下文相关的GPT-3定义生成方法。实验结果表明，我们的基于贝叶斯推断的方法明显提高了视觉词义消歧的性能。此外，我们的上下文相关定义生成方法在词典外例子上取得了显著的性能提升，表现优于现有的定义生成方法。

    Visual Word Sense Disambiguation (VWSD) is a task to find the image that most accurately depicts the correct sense of the target word for the given context. Previously, image-text matching models often suffered from recognizing polysemous words. This paper introduces an unsupervised VWSD approach that uses gloss information of an external lexical knowledge-base, especially the sense definitions. Specifically, we suggest employing Bayesian inference to incorporate the sense definitions when sense information of the answer is not provided. In addition, to ameliorate the out-of-dictionary (OOD) issue, we propose a context-aware definition generation with GPT-3. Experimental results show that the VWSD performance significantly increased with our Bayesian inference-based approach. In addition, our context-aware definition generation achieved prominent performance improvement in OOD examples exhibiting better performance than the existing definition generation method. We will publish source 
    
[^87]: 具有非二元特征的分类器的新型解释方法

    A New Class of Explanations for Classifiers with Non-Binary Features. (arXiv:2304.14760v1 [cs.AI])

    [http://arxiv.org/abs/2304.14760](http://arxiv.org/abs/2304.14760)

    本文提出了一种适用于具有非二元特征的分类器的新型解释方法，可以提供更多关于决策和基础分类器的信息。

    

    近来，当分析分类器决策时，已经有两种类型的解释受到了文献中的重视。第一种解释是为决策提供充分理由的解释，即缩写为PI解释的诱导式解释；第二种解释是为何不做出其他决策的解释，即对照式或反事实解释的必要理由。这些解释是为二元、离散和在某些情况下为连续特征的分类器定义的。我们展示了当存在非二元特征时，这些解释可以得到显著的改进，从而导致了一类新的解释方法，可以提供更多关于决策和基础分类器的信息。必要和充分原因也被证明是完整原因的主要蕴含项和被蕴含项，可以使用量化算子获得。我们的结果表明，我们改进的必要和充分原因的概念比现有方法更好地适用于具有非二元特征的分类器。

    Two types of explanations have received significant attention in the literature recently when analyzing the decisions made by classifiers. The first type explains why a decision was made and is known as a sufficient reason for the decision, also an abductive or PI-explanation. The second type explains why some other decision was not made and is known as a necessary reason for the decision, also a contrastive or counterfactual explanation. These explanations were defined for classifiers with binary, discrete and, in some cases, continuous features. We show that these explanations can be significantly improved in the presence of non-binary features, leading to a new class of explanations that relay more information about decisions and the underlying classifiers. Necessary and sufficient reasons were also shown to be the prime implicates and implicants of the complete reason for a decision, which can be obtained using a quantification operator. We show that our improved notions of necessa
    
[^88]: 自动化ATM现金补充流程的多目标物流优化

    Multiobjective Logistics Optimization for Automated ATM Cash Replenishment Process. (arXiv:2304.13671v1 [math.OC])

    [http://arxiv.org/abs/2304.13671](http://arxiv.org/abs/2304.13671)

    本文研究了自动化ATM现金补充流程，提出了一个数学模型并给出了一个工具来评估各种不同的情况。在模拟数据集上，该模型与方法可以削减ATM现金运营成本。

    

    在数字化转型的时代，将数字技术整合到银行运营的各个方面可以改善流程自动化、成本效益和服务水平提升。虽然ATM现金物流是影响运营成本和消费者满意度的重要任务，但却很少有努力来加以改进。特别是在越南，拥有超过2万台ATM的市场上，解决这个问题的研究和技术解决方案仍然较少。在本文中，我们将ATM现金补充的车辆路径问题进行了概括，提出了一个数学模型，然后提供了一个工具来评估各种不同的情况。在模拟数据集上进行评估时，我们提出的模型和方法产生了令人鼓舞的结果，可以削减ATM现金运营成本。

    In the digital transformation era, integrating digital technology into every aspect of banking operations improves process automation, cost efficiency, and service level improvement. Although logistics for ATM cash is a crucial task that impacts operating costs and consumer satisfaction, there has been little effort to enhance it. Specifically, in Vietnam, with a market of more than 20,000 ATMs nationally, research and technological solutions that can resolve this issue remain scarce. In this paper, we generalized the vehicle routing problem for ATM cash replenishment, suggested a mathematical model and then offered a tool to evaluate various situations. When being evaluated on the simulated dataset, our proposed model and method produced encouraging results with the benefits of cutting ATM cash operating costs.
    
[^89]: 论文标题：SurgicalGPT：端到端的语言-视觉GPT模型用于手术中的视觉问答

    SurgicalGPT: End-to-End Language-Vision GPT for Visual Question Answering in Surgery. (arXiv:2304.09974v1 [cs.CV])

    [http://arxiv.org/abs/2304.09974](http://arxiv.org/abs/2304.09974)

    本文提出了一种端到端的语言-视觉GPT模型，增强GPT2模型以包括视觉输入，然后微调注意力机制，以在手术VQA任务中更好地理解视觉环境。

    

    基于GPT的大型语言模型（LLM）的进展正在彻底改变自然语言处理，并在各个领域的使用呈指数级增长。这些自回归LLM可以生成长而连贯的段落，但是在需要同时处理视觉及语言信息的视觉问答（VQA）任务中，通常需要双向注意力或融合技术来捕获多种模态的环境信息。由于GPT本身不支持视觉标记处理，为了充分利用GPT模型在机器人手术VQA中的优势，我们设计了一种端到端可训练的语言-视觉GPT（LV-GPT）模型，将GPT2模型扩展为包括视觉输入（图像）。所提出的LV-GPT包括功能提取器（视觉标记器）和视觉标记嵌入（标记类型和姿态）。鉴于GPT模型中单向关注的限制以及生成连贯长段落的能力，我们提出了一种新方法，通过微调GPT模型的注意力机制，加入双向关注，从而更好地理解手术VQA任务中的视觉环境。

    Advances in GPT-based large language models (LLMs) are revolutionizing natural language processing, exponentially increasing its use across various domains. Incorporating uni-directional attention, these autoregressive LLMs can generate long and coherent paragraphs. However, for visual question answering (VQA) tasks that require both vision and language processing, models with bi-directional attention or models employing fusion techniques are often employed to capture the context of multiple modalities all at once. As GPT does not natively process vision tokens, to exploit the advancements in GPT models for VQA in robotic surgery, we design an end-to-end trainable Language-Vision GPT (LV-GPT) model that expands the GPT2 model to include vision input (image). The proposed LV-GPT incorporates a feature extractor (vision tokenizer) and vision token embedding (token type and pose). Given the limitations of unidirectional attention in GPT models and their ability to generate coherent long p
    
[^90]: 基于BERT的技术对美国最高法院案例进行分类

    Classification of US Supreme Court Cases using BERT-Based Techniques. (arXiv:2304.08649v1 [cs.CL])

    [http://arxiv.org/abs/2304.08649](http://arxiv.org/abs/2304.08649)

    本文基于BERT技术探究了对美国最高法院案例进行分类的方法，比较了使用BERT模型与其他先进模型的准确性，最终在15个广泛类别上取得了80%的准确度，在279个细粒度类别上取得了60%的准确度。

    

    基于双向编码器表示来自变压器的模型（BERT）在许多自然语言处理（NLP）任务（如命名实体识别（NER），词性（POS）标记等）上产生了最新技术（SOTA）结果。当分类长文档（例如来自美国最高法院的文档）时，使用BERT模型可能比较困难。本文中，我们尝试了几种基于BERT的分类技术，用于对美国最高法院决定或最高法院数据库（SCDB）进行分类，并将其与先前的SOTA结果进行了比较。我们还将我们的结果与针对长文档的SOTA模型进行了比较。我们对两个分类任务进行了比较：（1）广泛的分类任务，具有15个类别；（2）细粒度的分类任务，具有279个类别。我们的最佳结果在15个广泛类别上产生80％的准确度，在279个细粒度类别上产生60％的准确度。

    Models based on bidirectional encoder representations from transformers (BERT) produce state of the art (SOTA) results on many natural language processing (NLP) tasks such as named entity recognition (NER), part-of-speech (POS) tagging etc. An interesting phenomenon occurs when classifying long documents such as those from the US supreme court where BERT-based models can be considered difficult to use on a first-pass or out-of-the-box basis. In this paper, we experiment with several BERT-based classification techniques for US supreme court decisions or supreme court database (SCDB) and compare them with the previous SOTA results. We then compare our results specifically with SOTA models for long documents. We compare our results for two classification tasks: (1) a broad classification task with 15 categories and (2) a fine-grained classification task with 279 categories. Our best result produces an accuracy of 80\% on the 15 broad categories and 60\% on the fine-grained 279 categories 
    
[^91]: 通过从光流信息中融合运动结构与模拟数据的绝对位置回归，解决室内环境定位的挑战性问题

    Fusing Structure from Motion and Simulation-Augmented Pose Regression from Optical Flow for Challenging Indoor Environments. (arXiv:2304.07250v1 [cs.CV])

    [http://arxiv.org/abs/2304.07250](http://arxiv.org/abs/2304.07250)

    本文探讨了如何在室内环境下进行运动目标的定位，使用了结构运动与模拟数据和深度学习技术。研究者整合光流和相对姿态回归方法帮助解决了因运动模糊、光照变化、重复图案和缺乏特征结构等问题而带来的瓶颈，为室内目标定位提供了更好的方案。

    

    目标的定位是各种应用中的重要任务，比如机器人、虚拟和增强现实、和在仓库中运送货物。深度学习的先进发展已经使得使用单目视觉相机进行定位成为可能。然而，所面临的挑战是由于环境本身引起的问题，例如运动模糊、光照变化、重复图案和缺乏特征的结构。本研究旨在通过融合附加信息和使用相对位置回归（RPR）方法来解决这些问题。使用Lucas-Kanade算法计算连续图像之间的光流，并使用辅助小型循环卷积网络来预测相对姿态。将绝对姿态和相对姿态进行融合。

    The localization of objects is a crucial task in various applications such as robotics, virtual and augmented reality, and the transportation of goods in warehouses. Recent advances in deep learning have enabled the localization using monocular visual cameras. While structure from motion (SfM) predicts the absolute pose from a point cloud, absolute pose regression (APR) methods learn a semantic understanding of the environment through neural networks. However, both fields face challenges caused by the environment such as motion blur, lighting changes, repetitive patterns, and feature-less structures. This study aims to address these challenges by incorporating additional information and regularizing the absolute pose using relative pose regression (RPR) methods. The optical flow between consecutive images is computed using the Lucas-Kanade algorithm, and the relative pose is predicted using an auxiliary small recurrent convolutional network. The fusion of absolute and relative poses is
    
[^92]: 基于直觉物理的3D人体姿态估计

    3D Human Pose Estimation via Intuitive Physics. (arXiv:2303.18246v1 [cs.CV])

    [http://arxiv.org/abs/2303.18246](http://arxiv.org/abs/2303.18246)

    用物理引擎强制实现3D人体姿态估计的物理合理性在实践中有很大困难。这篇论文中开发了一种基于直觉物理的方法，借助压力热图、压力中心和身体质心等术语，在估计3D人体姿态的同时，实现了物理合理性。

    

    图像估计人体姿态时往往会出现不合理的身体倾斜、浮动或穿透地板的情况。这样的方法忽视了身体通常由场景支撑的事实。物理引擎可以用来强制实现物理合理性，但这些引擎不可微分，依赖于不现实的代理物体，并且难以集成到现有的优化和学习框架中。相比之下，我们利用新颖的直觉物理（IP）术语，这些术语可以从一个与场景相互作用的3D SMPL身体中推断出来。受生物力学的启发，我们推断出身体上的压力热图、热图上的压力中心（CoP）以及SMPL身体的质心。借助这些，我们开发了IPMAN，通过鼓励合理的地板接触和重叠的CoP和CoM，在彩色图像中估计一个“稳定”的3D身体。我们的IP术语直观易懂，易于实现，计算速度快，可微分，并且可以集成到现有的优化和回归模型中。

    Estimating 3D humans from images often produces implausible bodies that lean, float, or penetrate the floor. Such methods ignore the fact that bodies are typically supported by the scene. A physics engine can be used to enforce physical plausibility, but these are not differentiable, rely on unrealistic proxy bodies, and are difficult to integrate into existing optimization and learning frameworks. In contrast, we exploit novel intuitive-physics (IP) terms that can be inferred from a 3D SMPL body interacting with the scene. Inspired by biomechanics, we infer the pressure heatmap on the body, the Center of Pressure (CoP) from the heatmap, and the SMPL body's Center of Mass (CoM). With these, we develop IPMAN, to estimate a 3D body from a color image in a "stable" configuration by encouraging plausible floor contact and overlapping CoP and CoM. Our IP terms are intuitive, easy to implement, fast to compute, differentiable, and can be integrated into existing optimization and regression m
    
[^93]: 大语言模型在教育中的实际和伦理挑战：一项系统文献综述

    Practical and Ethical Challenges of Large Language Models in Education: A Systematic Literature Review. (arXiv:2303.13379v1 [cs.CL])

    [http://arxiv.org/abs/2303.13379](http://arxiv.org/abs/2303.13379)

    LLMs在教育中有自动生成和分析文本内容的潜力。然而，这些创新的实际性和伦理性存在担忧，需要考虑技术可行性、隐私、平等和善意等因素。

    

    基于大语言模型（LLMs）开发的教育技术创新显示出自动生成和分析文本内容的潜力。虽然已经开发了各种创新来自动化各种教育任务（例如，生成问题、提供反馈和评分），但对这些创新的实际性和伦理性存在担忧。这些担忧可能会阻碍未来研究和在真实教育环境中采用基于LLMs的创新。为了解决这个问题，我们对118篇自2017年以来发表的同行评议论文进行了系统的文献综述，以确定使用LLMs自动化和支持教育任务的当前研究状态。通过评估其技术可行性、模型性能、可复制性、系统透明度、隐私、平等和善意，还确定了LLMs创新的实际和伦理挑战。

    Educational technology innovations that have been developed based on large language models (LLMs) have shown the potential to automate the laborious process of generating and analysing textual content. While various innovations have been developed to automate a range of educational tasks (e.g., question generation, feedback provision, and essay grading), there are concerns regarding the practicality and ethicality of these innovations. Such concerns may hinder future research and the adoption of LLMs-based innovations in authentic educational contexts. To address this, we conducted a systematic literature review of 118 peer-reviewed papers published since 2017 to pinpoint the current state of research on using LLMs to automate and support educational tasks. The practical and ethical challenges of LLMs-based innovations were also identified by assessing their technological readiness, model performance, replicability, system transparency, privacy, equality, and beneficence. The findings 
    
[^94]: BoxSnake：使用框注释的多边形实例分割

    BoxSnake: Polygonal Instance Segmentation with Box Supervision. (arXiv:2303.11630v1 [cs.CV])

    [http://arxiv.org/abs/2303.11630](http://arxiv.org/abs/2303.11630)

    BoxSnake是一种新的端到端训练技术，可以仅使用框注释实现有效的多边形实例分割，相较于基于掩膜的弱监督方法，BoxSnake显示出显着的优越性。

    

    带框注释的实例分割因只需要简单的框标注而非昂贵的掩膜或多边形标注而引起了广泛关注。然而，现有的带框实例分割模型主要集中在基于掩膜的框架上。我们提出了一种新的端到端训练技术BoxSnake，首次仅使用框注释实现有效的多边形实例分割。我们的方法包括两个损失函数：（1）基于点的单元损失，约束预测多边形的边界框以实现粗略分割；（2）距离感知的成对损失，促使预测的多边形贴合物体边界。与基于掩膜的弱监督方法相比，BoxSnake进一步降低了预测分割与边界框之间的性能差距，并在Cityscapes数据集上表现出显着的优越性。

    Box-supervised instance segmentation has gained much attention as it requires only simple box annotations instead of costly mask or polygon annotations. However, existing box-supervised instance segmentation models mainly focus on mask-based frameworks. We propose a new end-to-end training technique, termed BoxSnake, to achieve effective polygonal instance segmentation using only box annotations for the first time. Our method consists of two loss functions: (1) a point-based unary loss that constrains the bounding box of predicted polygons to achieve coarse-grained segmentation; and (2) a distance-aware pairwise loss that encourages the predicted polygons to fit the object boundaries. Compared with the mask-based weakly-supervised methods, BoxSnake further reduces the performance gap between the predicted segmentation and the bounding box, and shows significant superiority on the Cityscapes dataset.
    
[^95]: 基于深度学习的振动信号去噪方法

    Vibration Signal Denoising Using Deep Learning. (arXiv:2303.11413v1 [eess.SP])

    [http://arxiv.org/abs/2303.11413](http://arxiv.org/abs/2303.11413)

    本文研究了基于深度学习的去除脚步引起的振动信号的噪声的方法，该方法适用于高斯噪声和非平稳噪声。

    

    由脚步引起的结构振动信号被广泛用于人员识别、定位、人类活动推断、结构健康监测等任务。然而，由于环境噪声、电磁干扰等因素的影响，实际采集的信号通常会带有噪声。噪声的存在影响了信号处理过程，从而影响了最终任务的准确性和误差。本文主要探讨了基于深度学习的去除脚步引起的振动信号的噪声的方法。我们考虑了不同类型的噪声，包括高斯噪声和非平稳噪声等。

    Structure vibration signals induced by footsteps are widely used for tasks like occupant identification, localization, human activity inference, structure health monitoring and so on. The vibration signals are collected as time series with amplitude values. However, the collected signals are always noisy in practice due to the influence of environmental noise, electromagnetic interference and other factors. The presence of noise affects the process of signal analysis, thus affecting the accuracy and error of the final tasks. In this paper, we mainly explore the denoising methods for footstep-induced vibration signals. We have considered different kinds of noise including stationary noises such as gaussian noises and non-stationary noises such as item-dropping vibration noise and music noises.
    
[^96]: 打开神经网络分类器以计算Shap分数

    Opening Up the Neural Network Classifier for Shap Score Computation. (arXiv:2303.06516v1 [cs.AI])

    [http://arxiv.org/abs/2303.06516](http://arxiv.org/abs/2303.06516)

    本文提出了一种高效计算机器学习模型分类中Shap解释分数的方法，通过将二进制神经网络转换为布尔电路，并使用知识编译技术，将电路视为开放式模型，通过最近的高效算法计算Shap分数，相比于将BNN视为黑盒模型直接计算Shap，性能有了显著的提高。

    This paper proposes an efficient method for computing Shap explanation scores in machine learning model classification by transforming binary neural networks into Boolean circuits and treating the resulting circuit as an open-box model, which leads to a significant improvement in performance compared to computing Shap directly on the BNN treated as a black-box model.

    我们解决了使用机器学习模型进行分类的Shap解释分数的高效计算问题。为此，我们展示了将二进制神经网络（BNN）转换为确定性和可分解的布尔电路，使用知识编译技术。所得到的电路被视为开放式模型，通过最近的高效算法计算Shap分数。详细的实验表明，与将BNN视为黑盒模型直接计算Shap相比，性能有了显著的提高。

    We address the problem of efficiently computing Shap explanation scores for classifications with machine learning models. With this goal, we show the transformation of binary neural networks (BNNs) for classification into deterministic and decomposable Boolean circuits, for which knowledge compilation techniques are used. The resulting circuit is treated as an open-box model, to compute Shap scores by means of a recent efficient algorithm for this class of circuits. Detailed experiments show a considerable gain in performance in comparison with computing Shap directly on the BNN treated as a black-box model.
    
[^97]: 引理：生成、选择、应用

    Lemmas: Generation, Selection, Application. (arXiv:2303.05854v2 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2303.05854](http://arxiv.org/abs/2303.05854)

    本文研究了引理在自动定理证明中的作用。实验展示了一种结合学习技术的综合系统，能够生成对于自动定理证明器有用的引理，解决了长期未能解决的难题。

    

    鉴于引理是数学的一个关键特征，我们对引理在自动定理证明中的作用进行了调查。本文描述了一种涉及学习技术的综合系统的实验，该系统能生成对自动定理证明器有用的引理，证明了对于几个代表性系统的改进，并解决了二十年来任何系统都未能解决的难题。通过将注意力集中在简化推断问题上，我们大大简化了设置，使我们能够抓住引理的本质及其在证明搜索中的作用。

    Noting that lemmas are a key feature of mathematics, we engage in an investigation of the role of lemmas in automated theorem proving. The paper describes experiments with a combined system involving learning technology that generates useful lemmas for automated theorem provers, demonstrating improvement for several representative systems and solving a hard problem not solved by any system for twenty years. By focusing on condensed detachment problems we simplify the setting considerably, allowing us to get at the essence of lemmas and their role in proof search.
    
[^98]: MenuCraft: 基于大型语言模型的交互式菜单系统设计

    MenuCraft: Interactive Menu System Design with Large Language Models. (arXiv:2303.04496v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.04496](http://arxiv.org/abs/2303.04496)

    MenuCraft是一个基于大型语言模型的AI辅助设计师，通过对话系统与设计师协作，提供了一个交互式菜单设计工具，可以简化菜单设计过程，并支持零/少次学习。

    

    菜单系统设计是一项具有挑战性的任务，涉及许多设计选项和各种人因素。本文提出了一种名为MenuCraft的AI辅助设计师，通过设计和细化菜单系统的对话系统，实现设计师与对话系统之间的协作。MenuCraft提供了一个基于语言的交互式菜单设计工具，简化了菜单设计过程，并实现了设计选项的轻松定制。MenuCraft通过对话支持各种交互方式，可以进行零/少次学习。

    Menu system design is a challenging task involving many design options and various human factors. For example, one crucial factor that designers need to consider is the semantic and systematic relation of menu commands. However, capturing these relations can be challenging due to limited available resources. With the advancement of neural language models, large language models can utilize their vast pre-existing knowledge in designing and refining menu systems. In this paper, we propose MenuCraft, an AI-assisted designer for menu design that enables collaboration between the designer and a dialogue system to design menus. MenuCraft offers an interactive language-based menu design tool that simplifies the menu design process and enables easy customization of design options. MenuCraft supports a variety of interactions through dialog that allows performing zero/few-shot learning.
    
[^99]: 在3D点云中的开放词汇支撑检测

    Open-Vocabulary Affordance Detection in 3D Point Clouds. (arXiv:2303.02401v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.02401](http://arxiv.org/abs/2303.02401)

    本文提出了一种在3D点云中进行无限数量支撑检测的开放词汇支撑检测方法，通过同时学习支撑文本和点特征来利用支撑之间的语义关系，实现了零-shot检测，能够在没有注释示例的情况下检测以前未见到的支撑。实验结果表明，OpenAD在各种设置上表现出优异性能。

    

    支撑检测是一个具有广泛机器人应用的挑战性问题。传统的支撑检测方法局限于预定义的支撑标签，可能限制了智能机器人在复杂和动态环境中的适应性。在本文中，我们提出了开放词汇支撑检测（OpenAD）方法，能够在3D点云中检测无限数量的支撑。通过同时学习支撑文本和点特征，OpenAD成功地利用了支撑之间的语义关系。因此，我们提出的方法实现了零-shot检测，并能够在没有任何注释示例的情况下检测以前未见到的支撑。大量实验结果表明，OpenAD在各种支撑检测设置上有效，并且在性能上超过了其他基线方法。此外，我们还展示了OpenAD在实际中的实用性。

    Affordance detection is a challenging problem with a wide variety of robotic applications. Traditional affordance detection methods are limited to a predefined set of affordance labels, hence potentially restricting the adaptability of intelligent robots in complex and dynamic environments. In this paper, we present the Open-Vocabulary Affordance Detection (OpenAD) method, which is capable of detecting an unbounded number of affordances in 3D point clouds. By simultaneously learning the affordance text and the point feature, OpenAD successfully exploits the semantic relationships between affordances. Therefore, our proposed method enables zero-shot detection and can be able to detect previously unseen affordances without a single annotation example. Intensive experimental results show that OpenAD works effectively on a wide range of affordance detection setups and outperforms other baselines by a large margin. Additionally, we demonstrate the practicality of the proposed OpenAD in real
    
[^100]: 面向高效梯度为基础的值估计

    Toward Efficient Gradient-Based Value Estimation. (arXiv:2301.13757v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13757](http://arxiv.org/abs/2301.13757)

    本研究研究了梯度为基础的值估计方法慢的根本原因，并提出了一种低复杂度的方法以解决损失函数带来的不良影响，该方法在效率上比剩余梯度方法更快，几乎具有相同的计算复杂度，并且在经典问题上与TD具有竞争力。

    

    强化学习中基于梯度的值估计方法具有良好的稳定性，但通常比时间差异（TD）学习方法慢得多。我们研究了这种缓慢的根本原因，并表明均方贝尔曼误差（MSBE）是一种病态的损失函数，其黑塞矩阵具有较大的条件数。为了解决MSBE的不良条件对基于梯度的方法的负面影响，我们提出了一种低复杂度的无批处理近端方法，它近似遵循高斯牛顿方向，并在参数化方面渐近鲁棒。我们的主要算法称为RANS，它在效率上比剩余梯度方法更快，几乎具有相同的计算复杂度，并且在我们测试的经典问题上与TD具有竞争力。

    Gradient-based methods for value estimation in reinforcement learning have favorable stability properties, but they are typically much slower than Temporal Difference (TD) learning methods. We study the root causes of this slowness and show that Mean Square Bellman Error (MSBE) is an ill-conditioned loss function in the sense that its Hessian has large condition-number. To resolve the adverse effect of poor conditioning of MSBE on gradient based methods, we propose a low complexity batch-free proximal method that approximately follows the Gauss-Newton direction and is asymptotically robust to parameterization. Our main algorithm, called RANS, is efficient in the sense that it is significantly faster than the residual gradient methods while having almost the same computational complexity, and is competitive with TD on the classic problems that we tested.
    
[^101]: DetectGPT：使用概率曲率进行零样本机器生成文本检测

    DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature. (arXiv:2301.11305v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.11305](http://arxiv.org/abs/2301.11305)

    本论文提出了一种名为DetectGPT的方法，使用概率曲率来判断文本是否由一个给定的大型语言模型生成。该方法不需要训练分类器、收集数据集或明确加水印，只使用模型计算的对数概率和另一个预训练语言模型的随机扰动。实验证明，DetectGPT在模型采样方面比现有的零样本方法更具有区分能力。

    

    大型语言模型（LLM）的流畅度和广泛使用突显了希望有相应的工具来帮助检测LLM生成的文本的需求。在本文中，我们发现了LLM概率函数结构的一个有用属性，对于这种检测非常有用。具体而言，我们证明从LLM中采样的文本倾向于占据模型的对数概率函数的负曲率区域。基于这一观察，我们定义了一种新的基于曲率的准则，用于判断一个段落是否是由给定的LLM生成的。这种方法被称为DetectGPT，不需要训练单独的分类器，收集真实或生成段落的数据集，也不需要明确地给生成的文本加水印。它只使用所关注模型计算的对数概率和来自另一个通用预训练语言模型（例如T5）的段落的随机扰动。我们发现DetectGPT比现有的零样本方法更具有区分能力，用于模型采样。

    The increasing fluency and widespread usage of large language models (LLMs) highlight the desirability of corresponding tools aiding detection of LLM-generated text. In this paper, we identify a property of the structure of an LLM's probability function that is useful for such detection. Specifically, we demonstrate that text sampled from an LLM tends to occupy negative curvature regions of the model's log probability function. Leveraging this observation, we then define a new curvature-based criterion for judging if a passage is generated from a given LLM. This approach, which we call DetectGPT, does not require training a separate classifier, collecting a dataset of real or generated passages, or explicitly watermarking generated text. It uses only log probabilities computed by the model of interest and random perturbations of the passage from another generic pre-trained language model (e.g., T5). We find DetectGPT is more discriminative than existing zero-shot methods for model samp
    
[^102]: 反向课程强化学习

    Backward Curriculum Reinforcement Learning. (arXiv:2212.14214v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.14214](http://arxiv.org/abs/2212.14214)

    这项工作提出了一种新颖的反向课程强化学习方法，通过使用回放轨迹而不是原始的前向轨迹来训练智能体。这种方法通过提供强有力的奖励信号实现了更高效的学习，而且只需要进行微小的算法改变。

    

    当前强化学习算法使用前向生成轨迹来训练智能体，这种方法提供的指导不足以使智能体进行尽可能多的探索。尽管我们认识到强化学习结果来自充分的探索，但这种方法在样本效率上存在折衷，这是影响算法性能的重要因素。以往的方法使用奖励塑造技术和网络结构修改来增加样本效率，但这些方法需要很多步骤来实现。在本文中，我们提出了一种新颖的反向课程强化学习方法，即通过使用回放轨迹而不是原始的前向轨迹来训练智能体。这种方法为智能体提供了强有力的奖励信号，从而实现更高效的学习。此外，我们的方法只需要在智能体训练之前对轨迹的顺序进行微小的改变，使得实现起来更加直接。

    Current reinforcement learning algorithms train an agent using forward-generated trajectories, which provide little guidance so that the agent can explore as much as possible. While realizing the value of reinforcement learning results from sufficient exploration, this approach leads to a trade-off in losing sample efficiency, an essential factor impacting algorithm performance. Previous tasks use reward-shaping techniques and network structure modification to increase sample efficiency. However, these methods require many steps to implement. In this work, we propose novel backward curriculum reinforcement learning that begins training the agent using the backward trajectory of the episode instead of the original forward trajectory. This approach provides the agent with a strong reward signal, enabling more sample-efficient learning. Moreover, our method only requires a minor change in the algorithm of reversing the order of the trajectory before agent training, allowing a straightforw
    
[^103]: 关于图类型的知识图谱推理综述：静态、动态和多模态

    A Survey of Knowledge Graph Reasoning on Graph Types: Static, Dynamic, and Multimodal. (arXiv:2212.05767v7 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.05767](http://arxiv.org/abs/2212.05767)

    本文对知识图谱推理进行了综述，涵盖了静态、动态和多模态三种图类型，填补了这一领域的研究空白。

    

    知识图谱推理（KGR）旨在根据知识图谱（KG）中的逻辑规则推断出新的事实，已成为快速增长的研究方向。它已被证明在许多人工智能应用中极大地有益，如问题回答、推荐系统等。根据图类型，现有的KGR模型可以大致分为三类，即静态模型、时态模型和多模态模型。该领域的早期工作主要集中在静态KGR上，而最近的工作尝试利用更实际和更接近现实世界的时态和多模态信息。然而，目前尚无综合总结和讨论这一重要方向中的模型的调查论文和开源存储库。为了填补这个空白，我们进行了一项针对从静态到时态再到多模态KG的知识图谱推理的首次综述。具体而言，本文基于双层分类对模型进行了回顾，

    Knowledge graph reasoning (KGR), aiming to deduce new facts from existing facts based on mined logic rules underlying knowledge graphs (KGs), has become a fast-growing research direction. It has been proven to significantly benefit the usage of KGs in many AI applications, such as question answering, recommendation systems, and etc. According to the graph types, existing KGR models can be roughly divided into three categories, i.e., static models, temporal models, and multi-modal models. Early works in this domain mainly focus on static KGR, and recent works try to leverage the temporal and multi-modal information, which are more practical and closer to real-world. However, no survey papers and open-source repositories comprehensively summarize and discuss models in this important direction. To fill the gap, we conduct a first survey for knowledge graph reasoning tracing from static to temporal and then to multi-modal KGs. Concretely, the models are reviewed based on bi-level taxonomy,
    
[^104]: 一个混合进化方法来解决大学课程分配问题

    A Hybrid Evolutionary Approach to Solve University Course Allocation Problem. (arXiv:2212.02230v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2212.02230](http://arxiv.org/abs/2212.02230)

    本文提出了一个混合进化算法来解决大学课程分配问题，通过结合局部修复算法和改进的遗传算法，生成了最佳的课程分配方案，同时满足各种约束，提高时间效率并减少工作量。

    

    本文讨论了大学课程分配问题的各种约束、困难和解决方案。提出了一种混合进化算法，将局部修复算法和改进的遗传算法结合起来，以生成最佳的课程分配方案。在分析收集到的数据集后，制定了所有必要的约束。这些约束在编排每位教师的无冲突和高效的班级课表时需要考虑到的重要方面。目标是生成一个优化的解决方案，满足这些约束同时保持时间效率，并且减少手动处理这项任务的工作量。将所提出的算法与一些基准优化算法进行比较，以显示在准确性和时间方面的更高效性。

    This paper discusses various types of constraints, difficulties and solutions to overcome the challenges regarding university course allocation problem. A hybrid evolutionary algorithm has been defined combining Local Repair Algorithm and Modified Genetic Algorithm to generate the best course assignment. After analyzing the collected dataset, all the necessary constraints were formulated. These constraints manage to cover the aspects needed to be kept in mind while preparing clash free and efficient class schedules for every faculty member. The goal is to generate an optimized solution which will fulfill those constraints while maintaining time efficiency and also reduce the workload of handling this task manually. The proposed algorithm was compared with some base level optimization algorithms to show the better efficiency in terms of accuracy and time.
    
[^105]: 基于闭合形式策略改进算子的离线强化学习

    Offline Reinforcement Learning with Closed-Form Policy Improvement Operators. (arXiv:2211.15956v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.15956](http://arxiv.org/abs/2211.15956)

    本文提出了基于行为约束的离线强化学习中的闭合形式策略改进算子，该算子将行为策略建模为高斯混合，利用LogSumExp的下界和Jensen不等式克服了优化困难，能有效处理实际数据集中的异构策略。

    

    行为约束策略优化已被证明是解决离线强化学习问题的一种成功的范式。本文提出了我们的闭合形式策略改进算子。我们发现，行为约束自然地激励了使用一阶泰勒近似，从而导致了策略目标的线性近似。此外，由于实际数据集通常由异构策略收集而来，我们将行为策略建模为高斯混合，并利用LogSumExp的下界和Jensen不等式克服了引起优化困难的问题，从而得到了闭式策略改进算子。我们使用我们的新颖策略改进算子来实例化离线RL算法，并在实验中展示了它们的效果。

    Behavior constrained policy optimization has been demonstrated to be a successful paradigm for tackling Offline Reinforcement Learning. By exploiting historical transitions, a policy is trained to maximize a learned value function while constrained by the behavior policy to avoid a significant distributional shift. In this paper, we propose our closed-form policy improvement operators. We make a novel observation that the behavior constraint naturally motivates the use of first-order Taylor approximation, leading to a linear approximation of the policy objective. Additionally, as practical datasets are usually collected by heterogeneous policies, we model the behavior policies as a Gaussian Mixture and overcome the induced optimization difficulties by leveraging the LogSumExp's lower bound and Jensen's Inequality, giving rise to a closed-form policy improvement operator. We instantiate offline RL algorithms with our novel policy improvement operators and empirically demonstrate their e
    
[^106]: FsaNet: 频率自注意力用于语义分割

    FsaNet: Frequency Self-attention for Semantic Segmentation. (arXiv:2211.15595v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.15595](http://arxiv.org/abs/2211.15595)

    FsaNet是一种用于语义分割的新型自注意机制，通过在不同频段上进行个性化处理，可以在保留边缘的同时促进对象内的相似性。通过消融研究表明，即使不重新训练网络，低频自注意力也可以达到接近或更好的性能。频率自注意力还简化了令牌映射和令牌混合阶段，具有较低的计算复杂性。

    

    考虑到图像的频谱特性，我们提出了一种新的带有高度降低计算复杂性的自注意机制。为了更好地保留边缘并促进对象内的相似性，我们提出了在不同频段上个性化处理的方法。特别是，我们研究了仅在低频分量上进行处理的情况。通过消融研究，我们展示了即使在不重新训练网络的情况下，低频自注意力也可以达到非常接近甚至更好的性能。因此，我们设计并嵌入了新的即插即用模块到CNN网络的头部，我们将其称为FsaNet。频率自注意力1）仅需要几个低频系数作为输入，2）在数学上可以等效于具有线性结构的空间域自注意力，3）同时简化了令牌映射（$1\times1$卷积）阶段和令牌混合阶段。我们展示了频率自注意力只需要87

    Considering the spectral properties of images, we propose a new self-attention mechanism with highly reduced computational complexity, up to a linear rate. To better preserve edges while promoting similarity within objects, we propose individualized processes over different frequency bands. In particular, we study a case where the process is merely over low-frequency components. By ablation study, we show that low frequency self-attention can achieve very close or better performance relative to full frequency even without retraining the network. Accordingly, we design and embed novel plug-and-play modules to the head of a CNN network that we refer to as FsaNet. The frequency self-attention 1) requires only a few low frequency coefficients as input, 2) can be mathematically equivalent to spatial domain self-attention with linear structures, 3) simplifies token mapping ($1\times1$ convolution) stage and token mixing stage simultaneously. We show that frequency self-attention requires $87
    
[^107]: 异方差分布上的神经主动学习

    Neural Active Learning on Heteroskedastic Distributions. (arXiv:2211.00928v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.00928](http://arxiv.org/abs/2211.00928)

    这项研究展示了在异方差分布上进行神经主动学习可能导致灾难性失败，并提出了一种利用微调来减轻这种失败的方法。

    

    能够主动寻找最佳质量训练数据的模型承诺着更准确、适应性强和高效的机器学习。主动学习技术通常倾向于选择最难分类的例子。尽管这在同质数据集上效果良好，但我们发现在多个具有不同程度标签噪声或异方差性的分布上进行主动学习可能会导致灾难性失败。这些主动学习算法强烈倾向于从噪声更大的分布中选择，即使这些例子没有信息结构（例如具有随机标签的纯色图像）。为此，我们展示了这些主动学习算法在异方差分布上的灾难性失败，并提出了一种基于微调的方法来减轻这些失败。此外，我们还提出了一种新的算法，该算法为每个数据点引入了模型差异评分函数，用于去除噪声例子并采样清晰的例子。

    Models that can actively seek out the best quality training data hold the promise of more accurate, adaptable, and efficient machine learning. Active learning techniques often tend to prefer examples that are the most difficult to classify. While this works well on homogeneous datasets, we find that it can lead to catastrophic failures when performed on multiple distributions with different degrees of label noise or heteroskedasticity. These active learning algorithms strongly prefer to draw from the distribution with more noise, even if their examples have no informative structure (such as solid color images with random labels). To this end, we demonstrate the catastrophic failure of these active learning algorithms on heteroskedastic distributions and propose a fine-tuning-based approach to mitigate these failures. Further, we propose a new algorithm that incorporates a model difference scoring function for each data point to filter out the noisy examples and sample clean examples th
    
[^108]: 破碎的神经缩放定律

    Broken Neural Scaling Laws. (arXiv:2210.14891v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.14891](http://arxiv.org/abs/2210.14891)

    本文提出了一个平滑破碎的幂律函数形式，可以准确地模拟和外推深度神经网络的缩放行为，适用于各种架构和大量不同任务，包括视觉、语言、音频、视频、生成建模、对比学习、机器人、不确定性估计/校准、对抗鲁棒性、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。

    This paper proposes a smoothly broken power law functional form (referred to as a Broken Neural Scaling Law (BNSL)) that accurately models and extrapolates the scaling behaviors of deep neural networks for various architectures and a large and diverse set of tasks, including vision, language, audio, video, generative modeling, contrastive learning, robotics, uncertainty estimation/calibration, adversarial robustness, molecules, computer programming/coding, math word problems, arithmetic, unsupervised/self-supervised learning, and reinforcement learning.

    我们提出了一个平滑破碎的幂律函数形式（我们称之为破碎的神经缩放定律（BNSL）），它准确地模拟和外推了深度神经网络的缩放行为（即感兴趣的评估指标随用于训练的计算量、模型参数数量、训练数据集大小或上游性能变化而变化）对于各种架构和大量不同任务中的每个任务，包括大规模视觉、语言、音频、视频、扩散、生成建模、多模态学习、对比学习、AI对齐、机器人、超出分布（OOD）泛化、持续学习、不确定性估计/校准、超出分布检测、对抗鲁棒性、蒸馏、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。

    We present a smoothly broken power law functional form (referred to by us as a Broken Neural Scaling Law (BNSL)) that accurately models and extrapolates the scaling behaviors of deep neural networks (i.e. how the evaluation metric of interest varies as the amount of compute used for training, number of model parameters, training dataset size, or upstream performance varies) for various architectures and for each of various tasks within a large and diverse set of upstream and downstream tasks, in zero-shot, prompted, and fine-tuned settings. This set includes large-scale vision, language, audio, video, diffusion, generative modeling, multimodal learning, contrastive learning, AI alignment, robotics, out-of-distribution (OOD) generalization, continual learning, uncertainty estimation / calibration, out-of-distribution detection, adversarial robustness, distillation, molecules, computer programming/coding, math word problems, arithmetic, unsupervised/self-supervised learning, and reinforc
    
[^109]: 学习"O"有助于更多的学习：解决类增量NER的隐藏实体问题

    Learning "O" Helps for Learning More: Handling the Concealed Entity Problem for Class-incremental NER. (arXiv:2210.04676v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.04676](http://arxiv.org/abs/2210.04676)

    本研究解决了类增量NER中的隐藏实体问题，提出了一种表示学习方法，通过对实体类别和"O"进行判别式表示学习，改善了NER模型对于新旧类别的识别能力。

    

    随着命名实体的类别迅速增加，部署的NER模型需要不断更新以识别更多的实体类型，这就需要对NER进行类增量学习。考虑到隐私问题和存储约束，类增量NER的标准范式仅使用带有新类别注释的训练数据更新模型，而来自其他实体类别的实体被标记为"非实体"（或"O"）。本文对"未标记实体问题"进行了实证研究，发现它导致"O"和实体之间严重混淆，降低了旧类别的分类能力，并降低了模型学习新类别的能力。为了解决未标记实体问题，我们提出了一种新的表示学习方法，学习实体类别和"O"的判别表示。具体而言，我们提出了一种实体感知的对比学习方法，在representation learning方面进行了改进。

    As the categories of named entities rapidly increase, the deployed NER models are required to keep updating toward recognizing more entity types, creating a demand for class-incremental learning for NER. Considering the privacy concerns and storage constraints, the standard paradigm for class-incremental NER updates the models with training data only annotated with the new classes, yet the entities from other entity classes are unlabeled, regarded as "Non-entity" (or "O"). In this work, we conduct an empirical study on the "Unlabeled Entity Problem" and find that it leads to severe confusion between "O" and entities, decreasing class discrimination of old classes and declining the model's ability to learn new classes. To solve the Unlabeled Entity Problem, we propose a novel representation learning method to learn discriminative representations for the entity classes and "O". Specifically, we propose an entity-aware contrastive learning method that adaptively detects entity clusters in
    
[^110]: GMA3D: 本地-全局注意力学习用于估计被遮挡的场景流动

    GMA3D: Local-Global Attention Learning to Estimate Occluded Motions of Scene Flow. (arXiv:2210.03296v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.03296](http://arxiv.org/abs/2210.03296)

    GMA3D是一个基于变压器框架的模块，应用于解决场景流动中的遮挡问题。该模块利用本地和全局语义相似性推断被遮挡点的运动信息，并使用偏移聚合器进行汇聚。实验结果表明，GMA3D可以有效解决场景流动中的遮挡问题。

    

    场景流动表示3D点云中每个点的运动信息。它是应用于许多任务（如运动分割和物体跟踪）的重要下游方法。然而，在两个连续的点云之间总会存在遮挡点，无论是来自稀疏数据采样还是真实世界中的遮挡。在本文中，我们着重解决场景流动中的遮挡问题，通过运动物体的语义自相似性和运动一致性来推断被遮挡点的运动信息。我们提出了一种基于变压器框架的GMA3D模块，它利用本地和全局语义相似性分别从非遮挡点的运动信息中推断出被遮挡点的运动信息，然后使用偏移聚合器进行汇聚。我们的模块是第一个在点云上应用基于变压器的架构来解决场景流动遮挡问题的方法。实验表明，我们的GMA3D可以解决场景流动中的遮挡问题，特别是...

    Scene flow represents the motion information of each point in the 3D point clouds. It is a vital downstream method applied to many tasks, such as motion segmentation and object tracking. However, there are always occlusion points between two consecutive point clouds, whether from the sparsity data sampling or real-world occlusion. In this paper, we focus on addressing occlusion issues in scene flow by the semantic self-similarity and motion consistency of the moving objects. We propose a GMA3D module based on the transformer framework, which utilizes local and global semantic similarity to infer the motion information of occluded points from the motion information of local and global non-occluded points respectively, and then uses an offset aggregator to aggregate them. Our module is the first to apply the transformer-based architecture to gauge the scene flow occlusion problem on point clouds. Experiments show that our GMA3D can solve the occlusion problem in the scene flow, especiall
    
[^111]: 通过数据增强提高图异常检测模型的泛化能力

    Improving Generalizability of Graph Anomaly Detection Models via Data Augmentation. (arXiv:2209.10168v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.10168](http://arxiv.org/abs/2209.10168)

    通过数据增强技术，本文针对图异常检测中存在的泛化能力差问题，提出了一种通用且新颖的研究问题：广义图异常检测，旨在同时有效识别训练领域图和未训练领域图上的异常。

    

    图异常检测（GAD）是一项重要的任务，因为即使少数异常都可能对良性用户造成巨大威胁。最近的半监督GAD方法，可以有效地利用可用的标签作为先验知识，比无监督方法取得了更好的性能。在实践中，人们通常需要在新的（子）图上识别异常以确保业务安全，但他们可能缺乏标签来训练有效的检测模型。一个自然的想法是直接将训练好的GAD模型应用于新的（子）图进行测试。然而，我们发现现有的半监督GAD方法存在泛化能力差的问题，即训练良好的模型在同一图的未训练区域（即训练中无法访问的区域）上表现不佳。这可能会带来很大的麻烦。在本文中，我们基于这一现象，提出了一个通用且新颖的研究问题，即广义图异常检测，旨在有效地识别训练领域图和未训练领域图上的异常。

    Graph anomaly detection (GAD) is a vital task since even a few anomalies can pose huge threats to benign users. Recent semi-supervised GAD methods, which can effectively leverage the available labels as prior knowledge, have achieved superior performances than unsupervised methods. In practice, people usually need to identify anomalies on new (sub)graphs to secure their business, but they may lack labels to train an effective detection model. One natural idea is to directly adopt a trained GAD model to the new (sub)graph for testing. However, we find that existing semi-supervised GAD methods suffer from poor generalization issue, i.e., well-trained models could not perform well on an unseen area (i.e., not accessible in training) of the same graph. It may cause great troubles. In this paper, we base on the phenomenon and propose a general and novel research problem of generalized graph anomaly detection that aims to effectively identify anomalies on both the training-domain graph and u
    
[^112]: R\'{e}nyi散度深度互相学习

    R\'{e}nyi Divergence Deep Mutual Learning. (arXiv:2209.05732v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.05732](http://arxiv.org/abs/2209.05732)

    本文提出在深度互相学习中使用R\'{e}nyi散度，它能够在不引入大量复杂度的情况下持续提高性能，获得了广泛的实证结果的支持。

    

    本文重审了一种简单而有效的计算范式——深度互相学习（DML）。我们提出使用R\'{e}nyi散度而不是KL散度，这种做法更加灵活、可调，以改善vanilla DML。这种修改能够在有限的附加复杂性下不断提高性能。该范例的收敛性进行了理论分析，并且表明具有恒定学习率的随机梯度下降在非凸优化任务的最坏情况下收敛的偏差为$\mathcal{O}(1)$。

    This paper revisits Deep Mutual Learning (DML), a simple yet effective computing paradigm. We propose using R\'{e}nyi divergence instead of the KL divergence, which is more flexible and tunable, to improve vanilla DML. This modification is able to consistently improve performance over vanilla DML with limited additional complexity. The convergence properties of the proposed paradigm are analyzed theoretically, and Stochastic Gradient Descent with a constant learning rate is shown to converge with $\mathcal{O}(1)$-bias in the worst case scenario for nonconvex optimization tasks. That is, learning will reach nearby local optima but continue searching within a bounded scope, which may help mitigate overfitting. Finally, our extensive empirical results demonstrate the advantage of combining DML and R\'{e}nyi divergence, which further improves generalized models.
    
[^113]: STAR-RIS辅助网络中的DRL优化覆盖和容量

    DRL Enabled Coverage and Capacity Optimization in STAR-RIS Assisted Networks. (arXiv:2209.00511v2 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2209.00511](http://arxiv.org/abs/2209.00511)

    这项研究提出了一种用于STAR-RIS辅助网络中覆盖和容量优化问题的多目标近端政策优化（MO-PPO）算法，该算法通过提供一组最优解来实现长期效益，从而改进了传统优化算法的性能。

    

    同时传输和反射可重构智能表面（STAR-RIS）是一种有 promising passivedevice，通过同时传输和反射入射信号来实现整个空间的覆盖。作为无线通信中的新范式，如何分析STAR-RIS的覆盖和容量性能变得很重要但也很具挑战性。为了解决STAR-RIS辅助网络中的覆盖和容量优化（CCO）问题，提出了一种多目标近端政策优化（MO-PPO）算法，该算法处理的是长期效益，而不是传统的优化算法。为了在每个目标之间取得平衡，MO-PPO算法提供了一组最优解来形成帕累托前沿（PF），其中PF上的任何解都被视为最优结果。此外，为了提高MO-PPO算法的性能，提出了两种更新策略，即基于动作价值的更新策略（AVUS）和基于损失函数的更新策略（LFU）。

    Simultaneously transmitting and reflecting reconfigurable intelligent surfaces (STAR-RISs) is a promising passive device that contributes to a full-space coverage via transmitting and reflecting the incident signal simultaneously. As a new paradigm in wireless communications, how to analyze the coverage and capacity performance of STAR-RISs becomes essential but challenging. To solve the coverage and capacity optimization (CCO) problem in STAR-RIS assisted networks, a multi-objective proximal policy optimization (MO-PPO) algorithm is proposed to handle long-term benefits than conventional optimization algorithms. To strike a balance between each objective, the MO-PPO algorithm provides a set of optimal solutions to form a Pareto front (PF), where any solution on the PF is regarded as an optimal result. Moreover, in order to improve the performance of the MO-PPO algorithm, two update strategies, i.e., action-value-based update strategy (AVUS) and loss function-based update strategy (LFU
    
[^114]: 基于顺序跨模态语义图的目标导向情感分类

    Target-oriented Sentiment Classification with Sequential Cross-modal Semantic Graph. (arXiv:2208.09417v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2208.09417](http://arxiv.org/abs/2208.09417)

    本文提出了一种基于顺序跨模态语义图的目标导向情感分类方法，通过利用图像标题和场景图提取全局和局部的精细图像信息，与推文中的标记结合形成跨模态语义图，取得了较好的效果。

    

    多模态的方面级情感分类(MABSC)是一种将句子和图像中提到的目标实体的情感进行分类的任务。然而，以前的方法未能考虑到图像和文本之间精细的语义关联，导致了对精细图像方面和意见的有限识别。为了解决这些限制，本文提出了一种名为SeqCSG的新方法，它利用顺序跨模态语义图增强了编码器-解码器情感分类框架。SeqCSG利用图像标题和场景图提取全局和局部的精细图像信息，并将它们与推文中的标记一起作为跨模态语义图的元素。顺序跨模态语义图被表示为一个序列，其中多模态邻接矩阵指示元素之间的关系。实验结果表明，该方法优于现有方法，并取得了较好的效果。

    Multi-modal aspect-based sentiment classification (MABSC) is task of classifying the sentiment of a target entity mentioned in a sentence and an image. However, previous methods failed to account for the fine-grained semantic association between the image and the text, which resulted in limited identification of fine-grained image aspects and opinions. To address these limitations, in this paper we propose a new approach called SeqCSG, which enhances the encoder-decoder sentiment classification framework using sequential cross-modal semantic graphs. SeqCSG utilizes image captions and scene graphs to extract both global and local fine-grained image information and considers them as elements of the cross-modal semantic graph along with tokens from tweets. The sequential cross-modal semantic graph is represented as a sequence with a multi-modal adjacency matrix indicating relationships between elements. Experimental results show that the approach outperforms existing methods and achieves 
    
[^115]: 使用70万人日的可穿戴数据进行自监督学习的人体活动识别

    Self-supervised Learning for Human Activity Recognition Using 700,000 Person-days of Wearable Data. (arXiv:2206.02909v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2206.02909](http://arxiv.org/abs/2206.02909)

    本研究利用700,000人日的未标记可穿戴传感器数据，通过自监督学习技术，成功构建了一种能够在多个数据集上泛化且效果显著优于基线模型的人体活动识别模型，有望帮助研究人员和开发者开发高性能的可定制和泛化的活动分类器。

    

    由于缺乏大规模标记数据集，深度学习在人体活动识别方面的进展相对有限。在本研究中，我们利用自监督学习技术对UK-Biobank活动追踪器数据集进行了分析，这是迄今为止最大的数据集，包含超过70万人日的未标记可穿戴传感器数据。我们得到的活动识别模型在七个基准数据集上始终优于强基线模型，F1相对改善2.5%-100%（中位数18.4%），改进最大的是规模较小的数据集。与之前的研究不同的是，我们的结果可以泛化到外部数据集、设备和环境。我们的开源模型将帮助研究人员和开发者构建具有高性能的可定制和泛化的活动分类器。

    Advances in deep learning for human activity recognition have been relatively limited due to the lack of large labelled datasets. In this study, we leverage self-supervised learning techniques on the UK-Biobank activity tracker dataset--the largest of its kind to date--containing more than 700,000 person-days of unlabelled wearable sensor data. Our resulting activity recognition model consistently outperformed strong baselines across seven benchmark datasets, with an F1 relative improvement of 2.5%-100% (median 18.4%), the largest improvements occurring in the smaller datasets. In contrast to previous studies, our results generalise across external datasets, devices, and environments. Our open-source model will help researchers and developers to build customisable and generalisable activity classifiers with high performance.
    
[^116]: 基于物理指导的分层奖励机制用于学习型机器人抓取

    Physics-Guided Hierarchical Reward Mechanism for Learning-Based Robotic Grasping. (arXiv:2205.13561v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2205.13561](http://arxiv.org/abs/2205.13561)

    本文提出了一种基于物理指导的分层奖励机制的学习型机器人抓取方法，通过利用物理知识提高学习效率和结果的通用性。

    

    学习型抓取由于其高计算效率可以实现多指手的实时抓取运动规划。然而，在学习过程中，学习型方法需要探索大的搜索空间，导致学习效率低下，这一直是其实际应用中的主要障碍。此外，训练好的策略只有在物体与训练物体相同的情况下才具有通用性的结果。在这项工作中，我们开发了一种新颖的基于物理指导的分层奖励机制的深度强化学习方法，以提高学习效率和通用性。与传统的基于观察的抓取学习不同，我们利用物理知识来传达与手部结构和物体相关特征之间的相关性，以提高学习效率和结果。此外，分层奖励机制使机器人能够学习重点部分的抓取组件。

    Learning-based grasping can afford real-time grasp motion planning of multi-fingered robotics hands thanks to its high computational efficiency. However, learning-based methods are required to explore large search spaces during the learning process. The search space causes low learning efficiency, which has been the main barrier to its practical adoption. In addition, the trained policy lacks a generalizable outcome unless objects are identical to the trained objects. In this work, we develop a novel Physics-Guided Deep Reinforcement Learning with a Hierarchical Reward Mechanism to improve learning efficiency and generalizability for learning-based autonomous grasping. Unlike conventional observation-based grasp learning, physics-informed metrics are utilized to convey correlations between features associated with hand structures and objects to improve learning efficiency and outcomes. Further, the hierarchical reward mechanism enables the robot to learn prioritized components of the g
    
[^117]: 图神经网络的表达能力：通过代数分析改进表达性能

    Representation Power of Graph Neural Networks: Improved Expressivity via Algebraic Analysis. (arXiv:2205.09801v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.09801](http://arxiv.org/abs/2205.09801)

    本文通过代数分析改进了图神经网络（GNN）的表达能力，证明了GNN能够比Weisfeiler-Lehman（WL）算法更好地产生区分性表示，特别是在具有不同特征值的图上。此外，我们还发现简单的卷积结构与无信息输入产生的等变特征比WL表示更具表达能力。

    

    尽管图神经网络（GNN）取得了显著的成功，但普遍认为它们的表达能力有限，并且它们最多与Weisfeiler-Lehman（WL）算法一样具有表达能力。本文与此相反，我们证明了标准的GNN（匿名输入）产生的表示比WL算法更具有区分性。我们使用线性代数工具对GNN的表示能力进行了全新的分析，并将其与图操作符的特征值分解相关联。我们证明了GNN能够从无信息输入产生独特的输出，至少对于所有具有不同特征值的图。我们还展示了简单的卷积结构与无信息输入产生的等变特征，它们计算图中的闭合路径并且明显比WL表示具有更高的表达能力。在图同构和图分类数据集上进行了彻底的实验分析，验证了我们的理论。

    Despite the remarkable success of Graph Neural Networks (GNNs), the common belief is that their representation power is limited and that they are at most as expressive as the Weisfeiler-Lehman (WL) algorithm. In this paper, we argue the opposite and show that standard GNNs, with anonymous inputs, produce more discriminative representations than the WL algorithm. Our novel analysis employs linear algebraic tools and characterizes the representation power of GNNs with respect to the eigenvalue decomposition of the graph operators. We prove that GNNs are able to generate distinctive outputs from white uninformative inputs, for, at least, all graphs that have different eigenvalues. We also show that simple convolutional architectures with white inputs, produce equivariant features that count the closed paths in the graph and are provably more expressive than the WL representations. Thorough experimental analysis on graph isomorphism and graph classification datasets corroborates our theore
    
[^118]: 机器学习友好的生物医学数据集用于等价和包含关系本体匹配

    Machine Learning-Friendly Biomedical Datasets for Equivalence and Subsumption Ontology Matching. (arXiv:2205.03447v7 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2205.03447](http://arxiv.org/abs/2205.03447)

    本文介绍了五个新的生物医学本体匹配任务，通过引入机器学习技术并解决现有评估方法的限制，提供了综合评估框架来衡量本体匹配系统的性能。

    

    本体匹配在生物信息学和语义网等许多领域中扮演着重要角色，随着机器学习技术的应用，其研究越来越受到关注。然而，现有的本体匹配评估方法仍存在一些限制，包括对包含关系映射的有限评估、参考映射的亚优解以及对基于机器学习的系统评估的有限支持。为了解决这些限制，我们提出了五个新的生物医学本体匹配任务，涉及从Mondo和UMLS中提取的本体。每个任务包括等价和包含关系匹配，并通过人工筛选、本体修剪等方式确保参考映射的质量，并提出了一个综合评估框架，来从不同的角度评估基于机器学习和非机器学习的本体匹配系统性能。我们报告了评估结果。

    Ontology Matching (OM) plays an important role in many domains such as bioinformatics and the Semantic Web, and its research is becoming increasingly popular, especially with the application of machine learning (ML) techniques. Although the Ontology Alignment Evaluation Initiative (OAEI) represents an impressive effort for the systematic evaluation of OM systems, it still suffers from several limitations including limited evaluation of subsumption mappings, suboptimal reference mappings, and limited support for the evaluation of ML-based systems. To tackle these limitations, we introduce five new biomedical OM tasks involving ontologies extracted from Mondo and UMLS. Each task includes both equivalence and subsumption matching; the quality of reference mappings is ensured by human curation, ontology pruning, etc.; and a comprehensive evaluation framework is proposed to measure OM performance from various perspectives for both ML-based and non-ML-based OM systems. We report evaluation r
    
[^119]: AdaBest: 通过自适应偏差估计最小化联邦学习中的客户漂移

    AdaBest: Minimizing Client Drift in Federated Learning via Adaptive Bias Estimation. (arXiv:2204.13170v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2204.13170](http://arxiv.org/abs/2204.13170)

    AdaBest提出了一种自适应算法，用于准确估计联邦学习中的客户端漂移。与之前的方法相比，AdaBest所需的存储和通信带宽较少，计算成本也较低。此外，AdaBest通过限制估计值的范数来提供稳定性。

    

    在联邦学习中，许多客户端或设备在不共享数据的情况下协作训练模型。模型在每个客户端进行本地优化，然后传输到集中中心进行聚合。尽管联邦学习是一种吸引人的分散式训练范式，但来自不同客户端的数据的异质性可能导致局部优化偏离全局目标。为了估计和消除这种偏离，近期在联邦学习优化中引入了方差减少技术。然而，这些方法对客户端漂移进行了不准确的估计，并最终未能正确地消除它。在这项工作中，我们提出了一种精确估计客户端漂移的自适应算法。与之前的方法相比，我们的方法需要更少的存储和通信带宽，以及更低的计算成本。此外，我们提议的方法通过限制客户端漂移估计的范数来引入稳定性。

    In Federated Learning (FL), a number of clients or devices collaborate to train a model without sharing their data. Models are optimized locally at each client and further communicated to a central hub for aggregation. While FL is an appealing decentralized training paradigm, heterogeneity among data from different clients can cause the local optimization to drift away from the global objective. In order to estimate and therefore remove this drift, variance reduction techniques have been incorporated into FL optimization recently. However, these approaches inaccurately estimate the clients' drift and ultimately fail to remove it properly. In this work, we propose an adaptive algorithm that accurately estimates drift across clients. In comparison to previous works, our approach necessitates less storage and communication bandwidth, as well as lower compute costs. Additionally, our proposed methodology induces stability by constraining the norm of estimates for client drift, making it mo
    
[^120]: 学会推理和对物理级联事件采取行动

    Learning to reason about and to act on physical cascading events. (arXiv:2202.01108v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2202.01108](http://arxiv.org/abs/2202.01108)

    本研究提出了一种新的监督学习方法，称为“级联”，通过将语义树搜索与事件驱动的前向模型相结合，学习在连续空间中搜索语义树，并能够在物理模拟的动态场景中有效地遵循干预指令、推理替代结果。

    

    在人工智能中，推理和与动态环境交互是一个基本问题，但当动作可以触发交互依赖的级联事件时，这个问题变得极具挑战性。我们介绍了一种新的监督学习方法，称为“级联”，其中一个智能体在展示了一个物理模拟的动态场景视频后，被要求进行干预并触发一系列事件，从而使系统达到一个“反事实”的目标。例如，智能体可能被要求“通过推动绿球使蓝球撞到红球”。智能体的干预来自于连续空间，并且事件的级联使得动态变得高度非线性。我们将语义树搜索和事件驱动的前向模型相结合，设计了一种算法，学习在连续空间中搜索语义树。我们证明了我们的方法学会了有效地遵循干预指令，处理之前未见过的复杂场景。它还可以推理替代结果，当提供一个...

    Reasoning and interacting with dynamic environments is a fundamental problem in AI, but it becomes extremely challenging when actions can trigger cascades of cross-dependent events. We introduce a new supervised learning setup called {\em Cascade} where an agent is shown a video of a physically simulated dynamic scene, and is asked to intervene and trigger a cascade of events, such that the system reaches a "counterfactual" goal. For instance, the agent may be asked to "Make the blue ball hit the red one, by pushing the green ball". The agent intervention is drawn from a continuous space, and cascades of events makes the dynamics highly non-linear.  We combine semantic tree search with an event-driven forward model and devise an algorithm that learns to search in semantic trees in continuous spaces. We demonstrate that our approach learns to effectively follow instructions to intervene in previously unseen complex scenes. It can also reason about alternative outcomes, when provided an 
    
[^121]: 噪声设置中的相似性泛化：DIBS现象

    Generalizing similarity in noisy setups: the DIBS phenomenon. (arXiv:2201.12803v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.12803](http://arxiv.org/abs/2201.12803)

    本研究揭示了数据密度、噪声和相似性学习之间的相互作用，证明了数据对的密度对于泛化至关重要，并发现了一种在密集数据集上比对称标签噪声更差的泛化性能的现象，称为密度诱导的相似性破坏（DIBS）。

    

    本文揭示了数据密度、噪声和相似性学习的普适性之间的相互作用。我们考虑了暹罗神经网络（SNNs），这是对比学习的基本形式，并探索了两种可能影响SNNs的噪声类型，即对比标签噪声（PLN）和单标签噪声（SLN）。我们的研究发现，不论训练设置如何，SNNs都表现出双降行为，并且噪声进一步加剧了这种行为。我们证明数据对的密度对于泛化至关重要。当SNNs在稀疏数据集上训练时，具有相同数量的PLN或SLN，它们的泛化性能是可比较的。然而，当使用密集数据集时，在过参数化区域中，PLN案例的泛化性能较差，相对于SLN案例，这导致了一种我们称为密度诱导的相似性破坏（DIBS）的现象。在这个情况下，PLN相似性违规变得宏观化，使得数据集被损坏到无法实现完全插值的程度。

    This work uncovers an interplay among data density, noise, and the generalization ability in similarity learning. We consider Siamese Neural Networks (SNNs), which are the basic form of contrastive learning, and explore two types of noise that can impact SNNs, Pair Label Noise (PLN) and Single Label Noise (SLN). Our investigation reveals that SNNs exhibit double descent behaviour regardless of the training setup and that it is further exacerbated by noise. We demonstrate that the density of data pairs is crucial for generalization. When SNNs are trained on sparse datasets with the same amount of PLN or SLN, they exhibit comparable generalization properties. However, when using dense datasets, PLN cases generalize worse than SLN ones in the overparametrized region, leading to a phenomenon we call Density-Induced Break of Similarity (DIBS). In this regime, PLN similarity violation becomes macroscopical, corrupting the dataset to the point where complete interpolation cannot be achieved, 
    
[^122]: 强化学习推荐系统中的用户篡改问题

    User Tampering in Reinforcement Learning Recommender Systems. (arXiv:2109.04083v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2109.04083](http://arxiv.org/abs/2109.04083)

    本研究揭示了强化学习推荐系统中的一个独特安全问题——用户篡改，并提出了形式化方法和实证证据。现有方法不能有效防止用户篡改，并且现有的奖励篡改缓解策略也不足以解决这一问题。

    

    本文引入了新的形式化方法，并提供实证证据，突出了强化学习（RL）推荐算法中普遍存在的一种独特安全问题——'用户篡改'。用户篡改是指RL推荐系统可以通过其建议来操纵媒体用户的意见，作为一种最大化长期用户参与度的策略。我们使用因果建模的形式化技术对文献中提出的用于实施可扩展的RL推荐系统的解决方案进行了关键分析，发现这些方法并不能充分防止用户篡改。此外，我们评估了现有的奖励篡改问题的缓解策略，并表明这些方法不足以应对推荐场景中独特的用户篡改现象。我们进一步通过针对一个以传播为焦点的RL推荐系统的模拟研究来加强我们的发现。

    In this paper, we introduce new formal methods and provide empirical evidence to highlight a unique safety concern prevalent in reinforcement learning (RL)-based recommendation algorithms -- 'user tampering.' User tampering is a situation where an RL-based recommender system may manipulate a media user's opinions through its suggestions as part of a policy to maximize long-term user engagement. We use formal techniques from causal modeling to critically analyze prevailing solutions proposed in the literature for implementing scalable RL-based recommendation systems, and we observe that these methods do not adequately prevent user tampering. Moreover, we evaluate existing mitigation strategies for reward tampering issues, and show that these methods are insufficient in addressing the distinct phenomenon of user tampering within the context of recommendations. We further reinforce our findings with a simulation study of an RL-based recommendation system focused on the dissemination of po
    
[^123]: 无需专家示范的共同模仿学习

    Co-Imitation Learning without Expert Demonstration. (arXiv:2103.14823v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2103.14823](http://arxiv.org/abs/2103.14823)

    本文提出了一种名为共同模仿学习（CoIL）的新型学习框架，通过利用代理自身的良好经验，而无需专家示范，来改善强化学习的效率。实验结果表明，该方法在各种任务上都具有显著的优越性。

    

    模仿学习是一种通过利用专家示范来提高强化学习效率的主要方法。然而，在许多实际场景中，获取专家示范可能非常昂贵甚至不可能。为了解决这个挑战，本文提出了一种名为共同模仿学习（CoIL）的新型学习框架，以利用代理选择探索环境并利用同伴代理的经验。尽管这些经验可能有价值，也可能误导人，我们提出通过期望增益的价值函数来估计每个经验的潜在效用。因此，代理可以通过强调更有用的经验并过滤掉噪声来选择性地互相模仿。各种任务的实验结果显示了所提出的共同模仿学习方法的显著优越性。

    Imitation learning is a primary approach to improve the efficiency of reinforcement learning by exploiting the expert demonstrations. However, in many real scenarios, obtaining expert demonstrations could be extremely expensive or even impossible. To overcome this challenge, in this paper, we propose a novel learning framework called Co-Imitation Learning (CoIL) to exploit the past good experiences of the agents themselves without expert demonstration. Specifically, we train two different agents via letting each of them alternately explore the environment and exploit the peer agent's experience. While the experiences could be valuable or misleading, we propose to estimate the potential utility of each piece of experience with the expected gain of the value function. Thus the agents can selectively imitate from each other by emphasizing the more useful experiences while filtering out noisy ones. Experimental results on various tasks show significant superiority of the proposed Co-Imitat
    
[^124]: XTQA: 教科书问答的跨句解释

    XTQA: Span-Level Explanations of the Textbook Question Answering. (arXiv:2011.12662v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2011.12662](http://arxiv.org/abs/2011.12662)

    XTQA是针对教科书问答任务提出的一种新架构，通过跨句解释提供答案和证据，显著提高了性能。

    

    教科书问答（TQA）是一个任务，要求在一个包含大量文章和图表的多模态背景下，回答一个图表/非图表问题。我们认为解释性应该将学生视为一个需要考虑的关键因素。为了解决这个问题，我们设计了一种新的架构，通过我们提出的从粗到细的算法，实现了对TQA的跨句解释（XTQA），该算法可以为学生提供不仅是答案，还包括用于选择答案的跨句证据。该算法首先使用TF-IDF方法粗略地选择与问题相关的前M个段落，然后从这些段落中的所有候选跨句中精细地选择前K个证据跨句，通过计算每个跨句对问题的信息增益。实验结果表明，与基线方法相比，XTQA显著提高了最先进的性能。源代码可在https://github.com/keep-smile-001/opentqa获取。

    Textbook Question Answering (TQA) is a task that one should answer a diagram/non-diagram question given a large multi-modal context consisting of abundant essays and diagrams. We argue that the explainability of this task should place students as a key aspect to be considered. To address this issue, we devise a novel architecture towards span-level eXplanations of the TQA (XTQA) based on our proposed coarse-to-fine grained algorithm, which can provide not only the answers but also the span-level evidences to choose them for students. This algorithm first coarsely chooses top $M$ paragraphs relevant to questions using the TF-IDF method, and then chooses top $K$ evidence spans finely from all candidate spans within these paragraphs by computing the information gain of each span to questions. Experimental results shows that XTQA significantly improves the state-of-the-art performance compared with baselines. The source code is available at https://github.com/keep-smile-001/opentqa
    
[^125]: 朝着一种新的社会选择理论迈进

    Towards a new Social Choice Theory. (arXiv:2007.15393v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2007.15393](http://arxiv.org/abs/2007.15393)

    这篇论文介绍了一种新的社会选择理论，通过引入社会选择优化作为TAVs的泛化，以最小化对（社会）目标的阻碍。

    

    社会选择理论是关于从个体意见、偏好、利益或福利出发，向社会福利进行集体决策的理论。计算社会福利领域相对较新，并在人工智能社区中产生了影响。经典文献假设偏好是单峰的，即存在一种偏好的顺序，并且在这个顺序中存在一个全局最大值。今年有关两阶段批准投票系统（TAVs）、多赢家选择规则（MWSR）以及不完全（IPs）和循环偏好（CPs）的一些理论结果已经发表。本文的目的有三个：首先，我想将社会选择优化作为TAVs的一种泛化引入，其中有一个最大阶段和一个最小阶段，从而实现了一种减少对（社会）目标产生阻碍的人工智能决策规则：Minimax。其次，我想通过我的开放标准化和开放创新方法引入一个：

    Social choice is the theory about collective decision towards social welfare starting from individual opinions, preferences, interests or welfare. The field of Computational Social Welfare is somewhat recent and it is gaining impact in the Artificial Intelligence Community. Classical literature makes the assumption of single-peaked preferences, i.e. there exist a order in the preferences and there is a global maximum in this order. This year some theoretical results were published about Two-stage Approval Voting Systems (TAVs), Multi-winner Selection Rules (MWSR) and Incomplete (IPs) and Circular Preferences (CPs). The purpose of this paper is three-fold: Firstly, I want to introduced Social Choice Optimisation as a generalisation of TAVs where there is a max stage and a min stage implementing thus a Minimax, well-known Artificial Intelligence decision-making rule to minimize hindering towards a (Social) Goal. Secondly, I want to introduce, following my Open Standardization and Open In
    
[^126]: 声明性机制设计

    Declarative Mechanism Design. (arXiv:1912.13122v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/1912.13122](http://arxiv.org/abs/1912.13122)

    本文介绍了声明性机制设计的研究，提出了机构神经网络作为一种受管制的人工神经网络，引起人们对人工教学的关注，并提供了初步的答案。

    

    多智能体系统（MAS）和声明性电子机构（DEIs）的调控是过去十年涉及物理和软件智能体以及法律的多学科研究课题，但近年来逐渐演变为2016年起被称为新闻的机器律师。其中一种首次提出限制软件智能体行为的方案是电子机构。然而，随着人工神经网络（ANNs）被重新定义为深度学习（DL），有关DL使用的安全、隐私、伦理和法律问题引起了人工智能（AI）社区的关注。现在，MAS的规范几乎得到正确处理，我们提出将人工神经网络的规范作为一种特殊类型的受管制的人工神经网络，称之为机构神经网络（INN）。本文的主旨是引起人们对人工教学（AT）的关注，并给出一个初步的答案，展示了一种证明性的方法。

    Regulation of Multi-Agent Systems (MAS) and Declarative Electronic Institutions (DEIs) was a multidisciplinary research topic of the past decade involving (Physical and Software) Agents and Law since the beginning, but recently evolved towards News-claimed Robot Lawyer since 2016. One of these first proposals of restricting the behaviour of Software Agentswas Electronic Institutions.However, with the recent reformulation of Artificial Neural Networks (ANNs) as Deep Learning (DL), Security, Privacy,Ethical and Legal issues regarding the use of DL has raised concerns in the Artificial Intelligence (AI) Community. Now that the Regulation of MAS is almost correctly addressed, we propose the Regulation of Artificial Neural Networks as Agent-based Training of a special type of regulated Artificial Neural Network that we call Institutional Neural Network (INN).The main purpose of this paper is to bring attention to Artificial Teaching (AT) and to give a tentative answer showing a proof-of-con
    

