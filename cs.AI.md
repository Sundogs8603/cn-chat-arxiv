# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Survey of Large Language Models for Autonomous Driving.](http://arxiv.org/abs/2311.01043) | 这篇论文概述了自动驾驶技术的发展趋势，从传统的基于规则的系统过渡到基于数据驱动的端到端系统，并介绍了利用大型语言模型与视觉模型相结合来增强自动驾驶系统能力的思路。 |
| [^2] | [GraphTransformers for Geospatial Forecasting.](http://arxiv.org/abs/2310.20174) | 本研究提出了一种新的基于图转换器的框架，用于改进地理空间序列轨迹预测。通过显式利用自动生成的图结构，可以显著提高地理空间轨迹预测的准确性。实验证明，该方法在飓风轨迹预测任务中表现优于基准模型。 |
| [^3] | [Automated Verification of Equivalence Properties in Advanced Logic Programs -- Bachelor Thesis.](http://arxiv.org/abs/2310.19806) | 这篇论文介绍了一种自动验证工具，用于验证优化的逻辑子程序是否可以替代原始子程序，在工业应用中具有重要意义。 |
| [^4] | [Evaluating Large Language Models: A Comprehensive Survey.](http://arxiv.org/abs/2310.19736) | 本调查综述了对大型语言模型（LLMs）的评估，包括知识和能力评估、对齐评估和安全评估。对于充分利用LLMs的能力以及确保其安全和有益的发展至关重要。 |
| [^5] | [Enhancing Energy-efficiency by Solving the Throughput Bottleneck of LSTM Cells for Embedded FPGAs.](http://arxiv.org/abs/2310.16842) | 本研究通过优化LSTM单元，提出了一种在终端设备上进行能效推断的新方法。以交通速度预测为例，优化后的LSTM单元在FPGA上实现了较快的推断速度和较低的能耗，相比现有方法提高了吞吐量和能效。 |
| [^6] | [ManiCast: Collaborative Manipulation with Cost-Aware Human Forecasting.](http://arxiv.org/abs/2310.13258) | ManiCast是一个基于成本感知的人体预测的协同操作框架，通过提供能够捕捉未来人体运动如何影响机器人计划成本的预测，实现了人机协同操纵任务的流畅执行和实时交互。 |
| [^7] | [Understanding Addition in Transformers.](http://arxiv.org/abs/2310.13121) | 本文通过对经过训练进行整数加法的单层Transformer模型的深入分析，揭示了该模型将任务分为并行的、特定于数字的流，并针对不同的数字位置采用不同的算法，同时还发现了一种罕见的高损失的使用情况。这些发现对于机制可解释性、人工智能安全性和对齐性等方面的研究具有重要贡献。 |
| [^8] | [Efficient Dataset Distillation through Alignment with Smooth and High-Quality Expert Trajectories.](http://arxiv.org/abs/2310.10541) | 本论文提出了一种高效的数据集精炼方法，通过与平滑高质量的专家轨迹对齐，实现对大规模数据集的替代，并提出了剪辑损失和梯度惩罚的集成来调节学生和专家之间的互动。 |
| [^9] | [Semantic Parsing by Large Language Models for Intricate Updating Strategies of Zero-Shot Dialogue State Tracking.](http://arxiv.org/abs/2310.10520) | 本论文提出了ParsingDST方法，利用大型语言模型和语义解析技术，实现了复杂的零样本对话状态跟踪的更新策略，并在实验中展示了明显的改进。 |
| [^10] | [Point-NeuS: Point-Guided Neural Implicit Surface Reconstruction by Volume Rendering.](http://arxiv.org/abs/2310.07997) | 该论文提出了一种名为Point-NeuS的新方法，通过利用点导向机制实现准确和高效的神经隐式曲面重建，解决了当前方法精度有限和时间复杂度过高的问题。 |
| [^11] | [Deep Backtracking Counterfactuals for Causally Compliant Explanations.](http://arxiv.org/abs/2310.07665) | 本研究提供了一种实用方法，用于在深度生成组件的结构因果模型中计算回溯反事实。通过在因果模型的结构化潜在空间中解决优化问题，我们的方法能够生成反事实，并且与其他方法相比具备了多功能、模块化和符合因果关系的特点。 |
| [^12] | [Fed-GraB: Federated Long-tailed Learning with Self-Adjusting Gradient Balancer.](http://arxiv.org/abs/2310.07587) | 本文提出了一种名为Fed-GraB的方法，该方法通过自适应梯度平衡器来解决联邦式长尾学习的问题。该方法能够在隐私约束下刻画全局长尾分布，并通过调整本地学习策略来解决头部-尾部不平衡的问题。 |
| [^13] | [Large Language Models for Propaganda Detection.](http://arxiv.org/abs/2310.06422) | 这项研究探讨了使用现代大型语言模型（LLMs）如GPT-3和GPT-4在宣传信息检测方面的有效性。实验结果显示，GPT-4达到了与当前最先进方法相符的结果。 |
| [^14] | [LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment.](http://arxiv.org/abs/2310.01852) | LanguageBind提出了将语言作为不同模态之间纽带的方法，通过冻结视频-语言预训练获取的语言编码器，并使用对比学习训练其他模态的编码器，实现了多模态的语义对齐。此外，作者还提出了VIDAL-10M数据集来支持该方法。 |
| [^15] | [Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation.](http://arxiv.org/abs/2310.01828) | 本论文介绍了一种可训练的噪声模型作为XAI评估方法，在遥感图像分割中的应用。在图像处理中提供深度神经网络的可解释性对于广泛采用和部署至关重要。虽然图像分割在计算机视觉应用中很重要，但在可解释性方面受到了相对较少的关注。 |
| [^16] | [Empirical Study of PEFT techniques for Winter Wheat Segmentation.](http://arxiv.org/abs/2310.01825) | 本研究通过使用PEFT技术，探索跨区域和跨年份的分布外推广性，以适应农作物监测的需求。 |
| [^17] | [Improving Trajectory Prediction in Dynamic Multi-Agent Environment by Dropping Waypoints.](http://arxiv.org/abs/2309.17338) | 本文引入了一种新的框架，通过航点去除技术促进了显式的时间学习，并显著提高了轨迹预测的效果。 |
| [^18] | [Knowledge Graphs for the Life Sciences: Recent Developments, Challenges and Opportunities.](http://arxiv.org/abs/2309.17255) | 这篇论文综述了在生命科学领域中使用知识图谱的最新发展和进展，并展望了这些技术在未来对这些领域的影响。 |
| [^19] | [Are Human-generated Demonstrations Necessary for In-context Learning?.](http://arxiv.org/abs/2309.14681) | 本文研究了上下文学习中人工生成的演示是否有必要，并提出了一种新的自反思提示策略（SEC），通过这种策略，大型语言模型（LLMs）可以自行生成演示和最终输出，避免了手动生成过程的复杂性。 |
| [^20] | [StratMed: Relevance Stratification for Low-resource Medication Recommendation.](http://arxiv.org/abs/2308.16781) | StratMed是一种面向低资源药物推荐的模型，通过相关性分层机制来解决医疗数据长尾分布不平衡的问题，平衡了药物组合的安全性和准确性。 |
| [^21] | [Evaluating the Robustness to Instructions of Large Language Models.](http://arxiv.org/abs/2308.14306) | 本论文评估了大型语言模型对指令的鲁棒性。结果表明，指令微调可以提升中等规模模型的性能，并且模型对陌生指令的处理能力有待改进。 |
| [^22] | [Decoding Natural Images from EEG for Object Recognition.](http://arxiv.org/abs/2308.13234) | 本文提出了一种自我监督的框架，从EEG信号中学习图像表示，并采用对比学习来对齐这两种模态。通过在最广泛的EEG图像数据集上的实验证明了该方法的优越性能和生物合理性。 |
| [^23] | [FedSoL: Bridging Global Alignment and Local Generality in Federated Learning.](http://arxiv.org/abs/2308.12532) | FedSoL提出了一种联邦学习的方法，该方法旨在解决数据分布不均匀导致性能下降的问题。它通过平衡全局对齐和本地一般性来改善FL的学习效果。 |
| [^24] | [Will More Expressive Graph Neural Networks do Better on Generative Tasks?.](http://arxiv.org/abs/2308.11978) | 本论文调查了更具表现力的图神经网络在分子图生成任务中的表现能力，并通过替换图生成模型的基础GNN来进行实验。研究发现，使用更具表现力的GNN可以改善生成任务的性能。 |
| [^25] | [Is There Any Social Principle for LLM-Based Agents?.](http://arxiv.org/abs/2308.11136) | LLM基于智能体不仅应关注“以人为中心”的对齐或应用，还应关注智能体自身，并探讨社会科学在智能体中的潜力。 |
| [^26] | [Evaluating the Instruction-Following Robustness of Large Language Models to Prompt Injection.](http://arxiv.org/abs/2308.10819) | 该论文提出了一个用于评估大型语言模型对注入的对抗性指令的鲁棒性的基准，旨在量化模型受到注入指令影响的程度，并评估其区分原始用户指令和注入指令的能力。 |
| [^27] | [Bayesian Flow Networks.](http://arxiv.org/abs/2308.07037) | 本文介绍了贝叶斯流网络（BFNs），一种新的生成模型，它通过贝叶斯推断修改了一组独立分布的参数，并将其作为输入传递给神经网络来生成另一个相互依赖的分布。该方法不需要前向过程，适用于连续和离散数据，并具有优化数据压缩的功能。 |
| [^28] | [Relation-Oriented: Toward Knowledge-Aligned Causal AI.](http://arxiv.org/abs/2307.16387) | 本研究从创新的关系导向视角出发，探讨了当前的建模范式中的观察模型与实际理解的不对齐问题，并提出了关系定义的表示学习方法作为实现关系导向建模的实践方法。 |
| [^29] | [RCT Rejection Sampling for Causal Estimation Evaluation.](http://arxiv.org/abs/2307.15176) | 该论文提出了一种名为RCT拒绝抽样的新抽样算法，用于因果估计评估。该方法通过子抽样随机控制试验(RCT)创建混淆的观测数据集，并使用RCT的平均因果效应作为基准真实值，以进行有效比较。 |
| [^30] | [WavJourney: Compositional Audio Creation with Large Language Models.](http://arxiv.org/abs/2307.14335) | 本研究提出了WavJourney系统，利用大型语言模型实现音频内容的创作。该系统可以根据文本指令生成包含语音、音乐和音效的音频内容。 |
| [^31] | [Multimodal Document Analytics for Banking Process Automation.](http://arxiv.org/abs/2307.11845) | 本研究聚焦于应对金融科技竞争和提高银行业务运营效率的需求，通过多模式模型特别是先进的文档分析技术，研究了银行流程中的潜力和机会，并展示了LayoutXLM等模型在分析银行文档中的潜力和性能。 |
| [^32] | [Expressivity Enhancement with Efficient Quadratic Neurons for Convolutional Neural Networks.](http://arxiv.org/abs/2306.07294) | 本文提出了基于二次神经元的高效CNN结构，能够有效地提高网络性能，而且参数和计算成本都有大幅度减少。 |
| [^33] | [Boosting Text-to-Image Diffusion Models with Fine-Grained Semantic Rewards.](http://arxiv.org/abs/2305.19599) | 本文提出了FineRewards，通过引入细粒度的语义奖励，即标题奖励和SAM奖励，来改进文本到图像扩散模型中文本和图像之间的对齐。 |
| [^34] | [SelfzCoT: a Self-Prompt Zero-shot CoT from Semantic-level to Code-level for a Better Utilization of LLMs.](http://arxiv.org/abs/2305.11461) | 本文提出了 SelfzCoT 自动自我生成的零样本编码，通过使用LLMs和代码级别的自我提示，在六个零样本算术推理任务中实现了巨大的准确度提升。同时，修改的零样本编码 MzCoT 在推理任务中也取得了显著的表现。 |
| [^35] | [AI-Augmented Surveys: Leveraging Large Language Models for Opinion Prediction in Nationally Representative Surveys.](http://arxiv.org/abs/2305.09620) | 本论文研究了利用经过全国代表性调查微调的大语言模型（LLMs）来增强调查的观点预测，取得了在遗漏数据插值和回溯推理方面优秀的成果，在零次预测方面仍需进一步研究。 |
| [^36] | [Search for the UGLE Truth: An Investigation into Unsupervised GNN Learning Environments.](http://arxiv.org/abs/2305.06026) | 本文提出了一种GNN学习环境下的社区检测算法比较框架，包括数据集和评估指标，以解决目前文献中对于基于GNN的社区检测缺乏公平且严谨评估的问题。 |
| [^37] | [Rank-Based Learning and Local Model Based Evolutionary Algorithm for High-Dimensional Expensive Multi-Objective Problems.](http://arxiv.org/abs/2304.09444) | 本文提出了一种基于排名学习和局部模型的多目标进化算法，该算法使用分类器进行排名，以解决高维昂贵多目标优化问题。 |
| [^38] | [A Review on Longitudinal Car-Following Model.](http://arxiv.org/abs/2304.07143) | 这篇论文综述了逐车跟驰模型的不同原则和分类，以及面临的挑战和局限性。 |
| [^39] | [A review of ensemble learning and data augmentation models for class imbalanced problems: combination, implementation and evaluation.](http://arxiv.org/abs/2304.02858) | 本文研究了集成学习和数据增强方法的应用，针对类别不平衡问题，通过计算评估，找到了最有效的组合。 |
| [^40] | [An Embedding-based Approach to Inconsistency-tolerant Reasoning with Inconsistent Ontologies.](http://arxiv.org/abs/2304.01664) | 本文提出了一种基于嵌入的方法来处理具有不一致性本体的容错推理问题，这种方法通过语义向量计算公理之间的关联，定义了选择最大一致子集的方法，并证明了推理关系的合理性。 |
| [^41] | [From Isolated Islands to Pangea: Unifying Semantic Space for Human Action Understanding.](http://arxiv.org/abs/2304.00553) | 本文提出了一个统一的语义空间Poincare行为语义空间，通过将以前数据集的类别与这个语义空间对齐，收集（图像/视频/骨架/MoCap）数据集到一个统一的数据库中，即将“孤立的岛屿”桥接成一个“泛大陆”，这将有助于推进可推广的行为学习。 |
| [^42] | [PowerPruning: Selecting Weights and Activations for Power-Efficient Neural Network Acceleration.](http://arxiv.org/abs/2303.13997) | PowerPruning是一种新颖的方法，通过选择能减少神经网络硬件中MAC操作功耗的权重来优化效率。该方法可以将DNN在硬件上的功耗降低高达78.3％，同时没有显著的准确度损失。 |
| [^43] | [Adding Conditional Control to Text-to-Image Diffusion Models.](http://arxiv.org/abs/2302.05543) | ControlNet是一种神经网络架构，用于为大规模预训练的文本到图像扩散模型添加条件控制。它可以通过重复使用预先训练的编码层学习多样的条件控制，并通过逐渐增加参数进行微调，从而在控制图像扩散模型方面具有鲁棒性。 |
| [^44] | [Self-Guided Diffusion Models.](http://arxiv.org/abs/2210.06462) | 本文提出了一种框架，利用自我监督信号的灵活性设计了自我指导扩散模型。实验表明，自标记指导始终优于没有指导的扩散模型，并且在不平衡数据上甚至可以超过基于真实标签的指导。 |
| [^45] | [Early Detection of Bark Beetle Attack Using Remote Sensing and Machine Learning: A Review.](http://arxiv.org/abs/2210.03829) | 本文综述了早期检测树皮甲虫攻击的过去和现有进展，重点关注了使用遥感和机器学习方法的优势和劣势，以及提供了有关树皮甲虫物种、攻击阶段、寄主树木、研究区域、遥感平台与传感器、光谱分辨率、光谱特征、机器学习方法和深度学习网络的知识。 |
| [^46] | [Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change).](http://arxiv.org/abs/2206.10498) | 本研究提出了一个用于测评LLMs规划和变化推理能力的框架，并测试了流行的LLMs (GPT-3 和 GShard) 在此基准上的表现。研究发现这些模型在最简单的规划任务上都表现不佳，强调了目前LLMs推理能力的严重限制，建议需要大量工作来开发更先进的LLM基础系统来满足实际应用需求。 |

# 详细

[^1]: 自动驾驶的大型语言模型概述

    A Survey of Large Language Models for Autonomous Driving. (arXiv:2311.01043v1 [cs.AI])

    [http://arxiv.org/abs/2311.01043](http://arxiv.org/abs/2311.01043)

    这篇论文概述了自动驾驶技术的发展趋势，从传统的基于规则的系统过渡到基于数据驱动的端到端系统，并介绍了利用大型语言模型与视觉模型相结合来增强自动驾驶系统能力的思路。

    

    自动驾驶技术作为改变交通和城市流动性的催化剂，正趋向于从基于规则的系统转向基于数据驱动的策略。传统的模块化系统受到级联模块中的累积误差和不灵活的预设规则的限制。相比之下，端到端自动驾驶系统通过完全数据驱动的训练过程，有潜力避免错误累积，尽管由于其黑盒性质，它们往往缺乏透明度，使得决策的验证和可追溯性变得复杂。近期，大型语言模型（LLMs）展示了理解背景、逻辑推理和生成答案等能力。自然而然的想法是利用这些能力赋予自动驾驶以更强大的能力。通过将LLM与基础视觉模型结合，可能打开对开放世界理解、推理和少样本学习的大门，这是当前自动驾驶系统所缺乏的。

    Autonomous driving technology, a catalyst for revolutionizing transportation and urban mobility, has the tend to transition from rule-based systems to data-driven strategies. Traditional module-based systems are constrained by cumulative errors among cascaded modules and inflexible pre-set rules. In contrast, end-to-end autonomous driving systems have the potential to avoid error accumulation due to their fully data-driven training process, although they often lack transparency due to their ``black box" nature, complicating the validation and traceability of decisions. Recently, large language models (LLMs) have demonstrated abilities including understanding context, logical reasoning, and generating answers. A natural thought is to utilize these abilities to empower autonomous driving. By combining LLM with foundation vision models, it could open the door to open-world understanding, reasoning, and few-shot learning, which current autonomous driving systems are lacking. In this paper,
    
[^2]: 基于图转换器的地理空间预测

    GraphTransformers for Geospatial Forecasting. (arXiv:2310.20174v1 [cs.AI])

    [http://arxiv.org/abs/2310.20174](http://arxiv.org/abs/2310.20174)

    本研究提出了一种新的基于图转换器的框架，用于改进地理空间序列轨迹预测。通过显式利用自动生成的图结构，可以显著提高地理空间轨迹预测的准确性。实验证明，该方法在飓风轨迹预测任务中表现优于基准模型。

    

    本文介绍了一种使用图转换器进行地理空间序列轨迹预测的新框架。通过观察多个序列，我们发现在这些序列之间会自动形成一个图结构，而这种结构在序列建模任务中通常被忽视。我们展示了通过显式利用这个图结构，地理空间轨迹预测可以显著改善。我们的图转换器方法在HURDAT数据集上，即对飓风轨迹进行6小时基础上的预测上，相比基于Transformer的基准模型有了显著的提升。

    In this paper we introduce a novel framework for trajectory prediction of geospatial sequences using GraphTransformers. When viewed across several sequences, we observed that a graph structure automatically emerges between different geospatial points that is often not taken into account for such sequence modeling tasks. We show that by leveraging this graph structure explicitly, geospatial trajectory prediction can be significantly improved. Our GraphTransformer approach improves upon state-of-the-art Transformer based baseline significantly on HURDAT, a dataset where we are interested in predicting the trajectory of a hurricane on a 6 hourly basis.
    
[^3]: 高级逻辑程序等价性属性的自动验证-学士论文

    Automated Verification of Equivalence Properties in Advanced Logic Programs -- Bachelor Thesis. (arXiv:2310.19806v1 [cs.LO])

    [http://arxiv.org/abs/2310.19806](http://arxiv.org/abs/2310.19806)

    这篇论文介绍了一种自动验证工具，用于验证优化的逻辑子程序是否可以替代原始子程序，在工业应用中具有重要意义。

    

    随着使用答案集编程的工业应用增加，对形式验证工具，特别是对关键应用的需求也增加了。在程序优化过程中，希望有一种工具可以自动验证优化的子程序是否可以替代原始子程序。从形式上讲，这对应于验证两个程序的强等价性的问题。为了做到这一点，开发了翻译工具anthem。它可以与用于经典逻辑的自动定理证明器一起使用，以验证两个程序是否强等价。在当前版本的anthem中，只能验证具有受限输入语言的正程序的强等价性。这是anthem中实现的翻译τ*的结果，它生成了here-and-there逻辑中的公式，该逻辑只对正程序与经典逻辑相一致。这篇论文扩展了anthem，以便可以验证更广泛的高级逻辑程序的强等价性。

    With the increase in industrial applications using Answer Set Programming, the need for formal verification tools, particularly for critical applications, has also increased. During the program optimisation process, it would be desirable to have a tool which can automatically verify whether an optimised subprogram can replace the original subprogram. Formally this corresponds to the problem of verifying the strong equivalence of two programs. In order to do so, the translation tool anthem was developed. It can be used in conjunction with an automated theorem prover for classical logic to verify that two programs are strongly equivalent. With the current version of anthem, only the strong equivalence of positive programs with a restricted input language can be verified. This is a result of the translation $\tau^*$ implemented in anthem that produces formulas in the logic of here-and-there, which coincides with classical logic only for positive programs. This thesis extends anthem in ord
    
[^4]: 评估大型语言模型：一项全面调查

    Evaluating Large Language Models: A Comprehensive Survey. (arXiv:2310.19736v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.19736](http://arxiv.org/abs/2310.19736)

    本调查综述了对大型语言模型（LLMs）的评估，包括知识和能力评估、对齐评估和安全评估。对于充分利用LLMs的能力以及确保其安全和有益的发展至关重要。

    

    大型语言模型（LLMs）在各种任务中展示了卓越的能力。它们吸引了广泛的关注，并在许多下游应用中得到了应用。然而，与双刃剑一样，LLMs也存在潜在风险。它们可能受到私人数据泄露，产生不适当、有害或误导性的内容。此外，LLMs的快速进展引发了对可能出现没有足够保障的超智能系统的担忧。为了有效利用LLMs的能力，并确保其安全和有益的发展，对LLMs进行严格和全面的评估至关重要。本调查旨在提供对LLMs评估的全面概述。我们将LLMs的评估分为三大类别：知识和能力评估，对齐评估和安全评估。除了全面回顾评估方法和技术之外，

    Large language models (LLMs) have demonstrated remarkable capabilities across a broad spectrum of tasks. They have attracted significant attention and been deployed in numerous downstream applications. Nevertheless, akin to a double-edged sword, LLMs also present potential risks. They could suffer from private data leaks or yield inappropriate, harmful, or misleading content. Additionally, the rapid progress of LLMs raises concerns about the potential emergence of superintelligent systems without adequate safeguards. To effectively capitalize on LLM capacities as well as ensure their safe and beneficial development, it is critical to conduct a rigorous and comprehensive evaluation of LLMs.  This survey endeavors to offer a panoramic perspective on the evaluation of LLMs. We categorize the evaluation of LLMs into three major groups: knowledge and capability evaluation, alignment evaluation and safety evaluation. In addition to the comprehensive review on the evaluation methodologies and
    
[^5]: 通过解决嵌入式FPGA中LSTM单元的吞吐量瓶颈，增强能效

    Enhancing Energy-efficiency by Solving the Throughput Bottleneck of LSTM Cells for Embedded FPGAs. (arXiv:2310.16842v1 [cs.AR])

    [http://arxiv.org/abs/2310.16842](http://arxiv.org/abs/2310.16842)

    本研究通过优化LSTM单元，提出了一种在终端设备上进行能效推断的新方法。以交通速度预测为例，优化后的LSTM单元在FPGA上实现了较快的推断速度和较低的能耗，相比现有方法提高了吞吐量和能效。

    

    在物联网中处理传感器数据，嵌入式深度学习对于一维数据非常重要。过去，经常使用CNN因为它们对于特殊的嵌入式硬件比如FPGA来说很容易优化。本研究提出了一种针对在终端设备上进行能效推断的新型LSTM单元优化方法。以交通速度预测为案例研究，优化后的LSTM单元的简单LSTM模型在FPGA XC7S15（来自Spartan-7系列）上每秒可实现17534个推断，仅消耗每个推断3.8微焦耳的能量。相比现有方法，它的吞吐量至少提高了5.4倍，能效提高了1.37倍。

    To process sensor data in the Internet of Things(IoTs), embedded deep learning for 1-dimensional data is an important technique. In the past, CNNs were frequently used because they are simple to optimise for special embedded hardware such as FPGAs. This work proposes a novel LSTM cell optimisation aimed at energy-efficient inference on end devices. Using the traffic speed prediction as a case study, a vanilla LSTM model with the optimised LSTM cell achieves 17534 inferences per second while consuming only 3.8 $\mu$J per inference on the FPGA \textit{XC7S15} from \textit{Spartan-7} family. It achieves at least 5.4$\times$ faster throughput and 1.37$\times$ more energy efficient than existing approaches.
    
[^6]: ManiCast: 基于成本感知人体预测的协同操作

    ManiCast: Collaborative Manipulation with Cost-Aware Human Forecasting. (arXiv:2310.13258v1 [cs.RO])

    [http://arxiv.org/abs/2310.13258](http://arxiv.org/abs/2310.13258)

    ManiCast是一个基于成本感知的人体预测的协同操作框架，通过提供能够捕捉未来人体运动如何影响机器人计划成本的预测，实现了人机协同操纵任务的流畅执行和实时交互。

    

    紧密合作的人机操纵依赖准确的人体运动预测。尽管在大规模学习预测模型方面取得了显著进展，但当应用于操作任务时，这些模型在关键转折点处积累了较高的误差，导致下游规划性能的降低。我们的关键见解是，与其预测最有可能的人体运动，产生能够捕捉未来人体运动如何影响机器人计划成本的预测就足够了。我们提出了ManiCast，一种新颖的框架，学习成本感知的人体预测并将其提供给模型预测控制规划器以执行协同操作任务。我们的框架实现了人类和7个自由度的机械臂在如反应搅拌、物体交接和协同摆桌等多个真实任务中的流畅、实时交互。我们对运动预测和端到端的预测-规划系统进行了评估

    Seamless human-robot manipulation in close proximity relies on accurate forecasts of human motion. While there has been significant progress in learning forecast models at scale, when applied to manipulation tasks, these models accrue high errors at critical transition points leading to degradation in downstream planning performance. Our key insight is that instead of predicting the most likely human motion, it is sufficient to produce forecasts that capture how future human motion would affect the cost of a robot's plan. We present ManiCast, a novel framework that learns cost-aware human forecasts and feeds them to a model predictive control planner to execute collaborative manipulation tasks. Our framework enables fluid, real-time interactions between a human and a 7-DoF robot arm across a number of real-world tasks such as reactive stirring, object handovers, and collaborative table setting. We evaluate both the motion forecasts and the end-to-end forecaster-planner system against a
    
[^7]: 理解Transformer中的加法

    Understanding Addition in Transformers. (arXiv:2310.13121v1 [cs.LG])

    [http://arxiv.org/abs/2310.13121](http://arxiv.org/abs/2310.13121)

    本文通过对经过训练进行整数加法的单层Transformer模型的深入分析，揭示了该模型将任务分为并行的、特定于数字的流，并针对不同的数字位置采用不同的算法，同时还发现了一种罕见的高损失的使用情况。这些发现对于机制可解释性、人工智能安全性和对齐性等方面的研究具有重要贡献。

    

    了解像Transformer这样的机器学习模型的内部工作方式对于其安全和道德使用至关重要。本文对经过训练进行整数加法的单层Transformer模型进行了深入分析。我们揭示了该模型将任务分为并行的、特定于数字的流，并针对不同的数字位置采用不同的算法。我们的研究还发现该模型开始计算较晚，但执行速度非常快。我们还发现了一种罕见的高损失的使用情况，并予以解释。总体而言，我们详细解释了该模型的算法。这些发现通过严格测试和数学建模得到了验证，对于机制可解释性、人工智能安全性和对齐性等广泛研究做出了贡献。我们的方法为分析更复杂的任务和多层Transformer模型打开了大门。

    Understanding the inner workings of machine learning models like Transformers is vital for their safe and ethical use. This paper presents an in-depth analysis of a one-layer Transformer model trained for integer addition. We reveal that the model divides the task into parallel, digit-specific streams and employs distinct algorithms for different digit positions. Our study also finds that the model starts calculations late but executes them rapidly. A rare use case with high loss is identified and explained. Overall, the model's algorithm is explained in detail. These findings are validated through rigorous testing and mathematical modeling, contributing to the broader works in Mechanistic Interpretability, AI safety, and alignment. Our approach opens the door for analyzing more complex tasks and multi-layer Transformer models.
    
[^8]: 通过与平滑高质量专家轨迹对齐实现高效数据集精炼

    Efficient Dataset Distillation through Alignment with Smooth and High-Quality Expert Trajectories. (arXiv:2310.10541v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2310.10541](http://arxiv.org/abs/2310.10541)

    本论文提出了一种高效的数据集精炼方法，通过与平滑高质量的专家轨迹对齐，实现对大规模数据集的替代，并提出了剪辑损失和梯度惩罚的集成来调节学生和专家之间的互动。

    

    训练一大型的先进机器学习模型通常需要使用大规模数据集，这使得训练和参数调整过程变得昂贵且耗时。一些研究人员选择将真实世界数据集中的信息精炼为小型合成数据集，同时保持其训练性能，从而提出了一种称为数据集精炼（DD）的数据高效方法。尽管该领域近年来取得了进展，但现有方法仍然表现不佳，不能有效替代大规模数据集。在本文中，与仅关注改进学生成绩的先前方法不同，我们首次认识到专家和学生之间的重要相互作用。我们认为在后续数据集精炼中，采用更强大的专家轨迹时，专家的平滑性具有重要影响。基于此，我们引入了剪辑损失和梯度惩罚的集成，以调节学生和专家之间的互动。

    Training a large and state-of-the-art machine learning model typically necessitates the use of large-scale datasets, which, in turn, makes the training and parameter-tuning process expensive and time-consuming. Some researchers opt to distil information from real-world datasets into tiny and compact synthetic datasets while maintaining their ability to train a well-performing model, hence proposing a data-efficient method known as Dataset Distillation (DD). Despite recent progress in this field, existing methods still underperform and cannot effectively replace large datasets. In this paper, unlike previous methods that focus solely on improving the efficacy of student distillation, we are the first to recognize the important interplay between expert and student. We argue the significant impact of expert smoothness when employing more potent expert trajectories in subsequent dataset distillation. Based on this, we introduce the integration of clipping loss and gradient penalty to regul
    
[^9]: 用大型语言模型进行语义解析，用于复杂的零样本对话状态跟踪的更新策略

    Semantic Parsing by Large Language Models for Intricate Updating Strategies of Zero-Shot Dialogue State Tracking. (arXiv:2310.10520v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.10520](http://arxiv.org/abs/2310.10520)

    本论文提出了ParsingDST方法，利用大型语言模型和语义解析技术，实现了复杂的零样本对话状态跟踪的更新策略，并在实验中展示了明显的改进。

    

    零样本对话状态跟踪（DST）解决了获取和注释面向任务的对话的挑战，这可能耗时费力。然而，DST超出了简单的填槽，需要有效的更新策略来跟踪对话状态随着对话的进行。本文提出了ParsingDST，一种新的In-Context Learning（ICL）方法，以引入额外的复杂更新策略用于零样本DST。我们的方法通过利用强大的大型语言模型（LLMs）并通过语义解析将原始对话文本转换为JSON作为一个中间状态来重新定义DST任务。我们还设计了一个新颖的框架，其中包括更多的模块来确保文本到JSON过程中更新策略的有效性。实验结果表明，我们的方法在MultiWOZ数据集上优于现有的零样本DST方法，在联合目标准确率（JGA）和槽准确度方面与现有的ICL方法相比呈现出显著改进。

    Zero-shot Dialogue State Tracking (DST) addresses the challenge of acquiring and annotating task-oriented dialogues, which can be time consuming and costly. However, DST extends beyond simple slot-filling and requires effective updating strategies for tracking dialogue state as conversations progress. In this paper, we propose ParsingDST, a new In-Context Learning (ICL) method, to introduce additional intricate updating strategies in zero-shot DST. Our approach reformulates the DST task by leveraging powerful Large Language Models (LLMs) and translating the original dialogue text to JSON through semantic parsing as an intermediate state. We also design a novel framework that includes more modules to ensure the effectiveness of updating strategies in the text-to-JSON process. Experimental results demonstrate that our approach outperforms existing zero-shot DST methods on MultiWOZ, exhibiting significant improvements in Joint Goal Accuracy (JGA) and slot accuracy compared to existing ICL
    
[^10]: Point-NeuS：通过体渲染进行点导向的神经隐式曲面重建

    Point-NeuS: Point-Guided Neural Implicit Surface Reconstruction by Volume Rendering. (arXiv:2310.07997v1 [cs.CV])

    [http://arxiv.org/abs/2310.07997](http://arxiv.org/abs/2310.07997)

    该论文提出了一种名为Point-NeuS的新方法，通过利用点导向机制实现准确和高效的神经隐式曲面重建，解决了当前方法精度有限和时间复杂度过高的问题。

    

    最近，通过体渲染学习神经隐式曲面已成为多视角重建的一种有前景的方法。然而，目前的方法存在精度有限和时间复杂度过高的瓶颈问题，亟需解决。为了应对这些挑战，我们提出了一种称为Point-NeuS的新方法，利用点导向机制实现准确和高效的重建。点建模有机地嵌入到体渲染中，以增强和规范隐式曲面的表示。具体而言，为了实现精确的点导向和抗噪能力，建模了点云的随机不确定性，以捕捉噪声分布并估计点的可靠性。此外，引入了一个连接点和图像的神经投影模块，以向符号距离函数（SDF）添加几何约束。为了更好地补偿体渲染和点建模之间的几何偏差，对高保真度点进行了滤波处理。

    Recently, learning neural implicit surface by volume rendering has been a promising way for multi-view reconstruction. However, limited accuracy and excessive time complexity remain bottlenecks that current methods urgently need to overcome. To address these challenges, we propose a new method called Point-NeuS, utilizing point-guided mechanisms to achieve accurate and efficient reconstruction. Point modeling is organically embedded into the volume rendering to enhance and regularize the representation of implicit surface. Specifically, to achieve precise point guidance and noise robustness, aleatoric uncertainty of the point cloud is modeled to capture the distribution of noise and estimate the reliability of points. Additionally, a Neural Projection module connecting points and images is introduced to add geometric constraints to the Signed Distance Function (SDF). To better compensate for geometric bias between volume rendering and point modeling, high-fidelity points are filtered i
    
[^11]: 深度回溯对因果一致解释的反事实推理

    Deep Backtracking Counterfactuals for Causally Compliant Explanations. (arXiv:2310.07665v1 [cs.AI])

    [http://arxiv.org/abs/2310.07665](http://arxiv.org/abs/2310.07665)

    本研究提供了一种实用方法，用于在深度生成组件的结构因果模型中计算回溯反事实。通过在因果模型的结构化潜在空间中解决优化问题，我们的方法能够生成反事实，并且与其他方法相比具备了多功能、模块化和符合因果关系的特点。

    

    反事实推理可以通过回答在改变情况下会观察到什么来提供有价值的见解，条件是根据实际观察。虽然经典的介入式解释已经得到了广泛研究，回溯原则被提出作为一种保持所有因果定律完整性的替代哲学，但其研究较少。在本研究中，我们介绍了在由深度生成组件组成的结构因果模型中计算回溯反事实的实用方法。为此，我们对结构分配施加了条件，通过在因果模型的结构化潜在空间中解决一个可行的约束优化问题来生成反事实。我们的方法还可以与反事实解释领域的方法进行比较。与这些方法相比，我们的方法代表了一种多功能、模块化和遵守因果的替代方案。

    Counterfactuals can offer valuable insights by answering what would have been observed under altered circumstances, conditional on a factual observation. Whereas the classical interventional interpretation of counterfactuals has been studied extensively, backtracking constitutes a less studied alternative the backtracking principle has emerged as an alternative philosophy where all causal laws are kept intact. In the present work, we introduce a practical method for computing backtracking counterfactuals in structural causal models that consist of deep generative components. To this end, we impose conditions on the structural assignments that enable the generation of counterfactuals by solving a tractable constrained optimization problem in the structured latent space of a causal model. Our formulation also facilitates a comparison with methods in the field of counterfactual explanations. Compared to these, our method represents a versatile, modular and causally compliant alternative. 
    
[^12]: Fed-GraB：具有自适应梯度平衡器的联邦式长尾学习

    Fed-GraB: Federated Long-tailed Learning with Self-Adjusting Gradient Balancer. (arXiv:2310.07587v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.07587](http://arxiv.org/abs/2310.07587)

    本文提出了一种名为Fed-GraB的方法，该方法通过自适应梯度平衡器来解决联邦式长尾学习的问题。该方法能够在隐私约束下刻画全局长尾分布，并通过调整本地学习策略来解决头部-尾部不平衡的问题。

    

    数据隐私和长尾分布在许多现实任务中是常态而非例外。本文研究了一种联邦式长尾学习（Fed-LT）任务，在该任务中，每个客户端持有一个本地异构数据集；如果可以全局聚合数据集，则它们共同展现出长尾分布。在这样的设置下，现有的联邦优化和/或集中式长尾学习方法很难应用，因为存在以下挑战：（a）在隐私约束下刻画全局长尾分布，以及（b）调整本地学习策略以应对头部-尾部不平衡。为此，我们提出了一种方法称为$\texttt{Fed-GraB}$，它包括一个自适应梯度平衡器（SGB）模块，该模块以闭环方式根据全局长尾分布的反馈对客户端的梯度进行重新加权，评估方法为直接先验分析器（DPA）模块。使用$\texttt{Fed-GraB}$，客户端可以有效缓解数据分布的不均衡问题。

    Data privacy and long-tailed distribution are the norms rather than the exception in many real-world tasks. This paper investigates a federated long-tailed learning (Fed-LT) task in which each client holds a locally heterogeneous dataset; if the datasets can be globally aggregated, they jointly exhibit a long-tailed distribution. Under such a setting, existing federated optimization and/or centralized long-tailed learning methods hardly apply due to challenges in (a) characterizing the global long-tailed distribution under privacy constraints and (b) adjusting the local learning strategy to cope with the head-tail imbalance. In response, we propose a method termed $\texttt{Fed-GraB}$, comprised of a Self-adjusting Gradient Balancer (SGB) module that re-weights clients' gradients in a closed-loop manner, based on the feedback of global long-tailed distribution evaluated by a Direct Prior Analyzer (DPA) module. Using $\texttt{Fed-GraB}$, clients can effectively alleviate the distribution
    
[^13]: 用于传播信息检测的大型语言模型

    Large Language Models for Propaganda Detection. (arXiv:2310.06422v1 [cs.CL])

    [http://arxiv.org/abs/2310.06422](http://arxiv.org/abs/2310.06422)

    这项研究探讨了使用现代大型语言模型（LLMs）如GPT-3和GPT-4在宣传信息检测方面的有效性。实验结果显示，GPT-4达到了与当前最先进方法相符的结果。

    

    在我们数字化社会中，宣传信息的普遍存在对社会和真相的传播构成了挑战。通过自然语言处理在文本中检测宣传信息是具有挑战性的，因为存在微妙的操纵技术和语境依赖。为了解决这个问题，我们研究了现代大型语言模型（LLMs）如GPT-3和GPT-4在宣传信息检测方面的有效性。我们使用SemEval-2020任务11数据集进行实验，该数据集包含具有14种宣传技术标签的新闻文章，作为一个多标签分类问题。我们采用了GPT-3和GPT-4的五种变体，结合了不同模型之间的各种提示工程和微调策略。通过评估$F1$分数，$Precision$和$Recall$等指标来评估模型的性能，并将结果与使用RoBERTa的当前最先进方法进行比较。我们的研究结果表明，GPT-4实现了与当前最先进方法相当的结果。

    The prevalence of propaganda in our digital society poses a challenge to societal harmony and the dissemination of truth. Detecting propaganda through NLP in text is challenging due to subtle manipulation techniques and contextual dependencies. To address this issue, we investigate the effectiveness of modern Large Language Models (LLMs) such as GPT-3 and GPT-4 for propaganda detection. We conduct experiments using the SemEval-2020 task 11 dataset, which features news articles labeled with 14 propaganda techniques as a multi-label classification problem. Five variations of GPT-3 and GPT-4 are employed, incorporating various prompt engineering and fine-tuning strategies across the different models. We evaluate the models' performance by assessing metrics such as $F1$ score, $Precision$, and $Recall$, comparing the results with the current state-of-the-art approach using RoBERTa. Our findings demonstrate that GPT-4 achieves comparable results to the current state-of-the-art. Further, thi
    
[^14]: LanguageBind:通过基于语义对齐的语言将视频-语言预训练扩展到N模态（arXiv:2310.01852v1[cs.CV]）

    LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment. (arXiv:2310.01852v1 [cs.CV])

    [http://arxiv.org/abs/2310.01852](http://arxiv.org/abs/2310.01852)

    LanguageBind提出了将语言作为不同模态之间纽带的方法，通过冻结视频-语言预训练获取的语言编码器，并使用对比学习训练其他模态的编码器，实现了多模态的语义对齐。此外，作者还提出了VIDAL-10M数据集来支持该方法。

    

    视频-语言（VL）预训练在多个下游任务中取得了显著的进展。然而，当前的VL预训练框架难以将其扩展到除视觉和语言之外的多模态（N模态，N>=3）。因此，我们提出了LanguageBind，通过将语言作为不同模态之间的纽带，因为语言模态已经得到了很好的探索，包含丰富的语义信息。具体而言，我们使用VL预训练获取的语言编码器，并通过对比学习训练其他模态的编码器。结果是，所有模态被映射到一个共享的特征空间中，实现了多模态的语义对齐。虽然LanguageBind可以扩展VL模态到N模态，但我们还需要一个带有以语言为中心的对齐数据对的高质量数据集。因此，我们提出了VIDAL-10M，其中包含了视频、红外、深度、音频及其相应的语言数据，命名为VIDAL-10M。

    The video-language (VL) pretraining has achieved remarkable improvement in multiple downstream tasks. However, the current VL pretraining framework is hard to extend to multiple modalities (N modalities, N>=3) beyond vision and language. We thus propose LanguageBind, taking the language as the bind across different modalities because the language modality is well-explored and contains rich semantics. Specifically, we freeze the language encoder acquired by VL pretraining, then train encoders for other modalities with contrastive learning. As a result, all modalities are mapped to a shared feature space, implementing multi-modal semantic alignment. While LanguageBind ensures that we can extend VL modalities to N modalities, we also need a high-quality dataset with alignment data pairs centered on language. We thus propose VIDAL-10M with Video, Infrared, Depth, Audio and their corresponding Language, naming as VIDAL-10M. In our VIDAL-10M, all videos are from short video platforms with co
    
[^15]: 可训练的噪声模型作为XAI评估方法：在遥感图像分割中的应用

    Trainable Noise Model as an XAI evaluation method: application on Sobol for remote sensing image segmentation. (arXiv:2310.01828v1 [cs.CV])

    [http://arxiv.org/abs/2310.01828](http://arxiv.org/abs/2310.01828)

    本论文介绍了一种可训练的噪声模型作为XAI评估方法，在遥感图像分割中的应用。在图像处理中提供深度神经网络的可解释性对于广泛采用和部署至关重要。虽然图像分割在计算机视觉应用中很重要，但在可解释性方面受到了相对较少的关注。

    

    可解释的人工智能（XAI）已成为处理关键任务应用时的必备要求，确保所使用的黑盒子人工智能模型的透明度和可解释性。XAI的重要性涵盖了各个领域，从医疗保健到金融，在这些领域中，了解深度学习算法的决策过程是至关重要的。大多数基于人工智能的计算机视觉模型往往是黑盒子，因此在图像处理中提供深度神经网络的可解释性对于它们在医疗图像分析、自动驾驶和遥感应用中的广泛采用和部署至关重要。最近，已经提出了几种针对图像分类任务的XAI方法。相比之下，在可解释性方面，图像分割在计算机视觉应用中，特别是在遥感领域中，受到了相对较少的关注。只有少数研究提出了基于梯度的XAI算法来进行图像分割。

    eXplainable Artificial Intelligence (XAI) has emerged as an essential requirement when dealing with mission-critical applications, ensuring transparency and interpretability of the employed black box AI models. The significance of XAI spans various domains, from healthcare to finance, where understanding the decision-making process of deep learning algorithms is essential. Most AI-based computer vision models are often black boxes; hence, providing explainability of deep neural networks in image processing is crucial for their wide adoption and deployment in medical image analysis, autonomous driving, and remote sensing applications. Recently, several XAI methods for image classification tasks have been introduced. On the contrary, image segmentation has received comparatively less attention in the context of explainability, although it is a fundamental task in computer vision applications, especially in remote sensing. Only some research proposes gradient-based XAI algorithms for imag
    
[^16]: 冬小麦分割的PEFT技术的实证研究

    Empirical Study of PEFT techniques for Winter Wheat Segmentation. (arXiv:2310.01825v1 [cs.CV])

    [http://arxiv.org/abs/2310.01825](http://arxiv.org/abs/2310.01825)

    本研究通过使用PEFT技术，探索跨区域和跨年份的分布外推广性，以适应农作物监测的需求。

    

    参数高效微调（PEFT）技术最近经历了显著的增长，并被广泛用于将大规模视觉和语言模型适应于各种领域，以最小的计算需求实现令人满意的模型性能。尽管取得了这些进展，但在实际场景中，特别是在遥感和农作物监测的关键领域中，仍需要进一步研究潜在的PEFT应用。不同地区的气候多样性和对全面的大规模数据集的需求，给精确识别不同地理位置和不断变化的种植季节的作物类型造成了重大障碍。本研究旨在通过全面探索跨区域和跨年份的分布外推广性，使用国内领先的冬小麦作物监测模型，来填补这一差距。这项工作的目标是探索PEFT方法在作物监测中的应用。具体而言，我们专注于适应性地调整PEFT方法以适应农作物监测的需求。

    Parameter Efficient Fine Tuning (PEFT) techniques have recently experienced significant growth and have been extensively employed to adapt large vision and language models to various domains, enabling satisfactory model performance with minimal computational needs. Despite these advances, more research has yet to delve into potential PEFT applications in real-life scenarios, particularly in the critical domains of remote sensing and crop monitoring. The diversity of climates across different regions and the need for comprehensive large-scale datasets have posed significant obstacles to accurately identify crop types across varying geographic locations and changing growing seasons. This study seeks to bridge this gap by comprehensively exploring the feasibility of cross-area and cross-year out-of-distribution generalization using the State-of-the-Art (SOTA) wheat crop monitoring model. The aim of this work is to explore PEFT approaches for crop monitoring. Specifically, we focus on adap
    
[^17]: 在动态多智能体环境中通过去掉航点来改进轨迹预测

    Improving Trajectory Prediction in Dynamic Multi-Agent Environment by Dropping Waypoints. (arXiv:2309.17338v1 [cs.RO])

    [http://arxiv.org/abs/2309.17338](http://arxiv.org/abs/2309.17338)

    本文引入了一种新的框架，通过航点去除技术促进了显式的时间学习，并显著提高了轨迹预测的效果。

    

    轨迹的多样和不确定性本质给准确建模带来了巨大的挑战。运动预测系统必须有效地从过去学习空间和时间信息，以预测智能体的未来轨迹。许多现有方法通过堆叠模型中的单独组件学习时间运动，以捕捉时间特征。本文介绍了一种新颖的框架，称为Temporal Waypoint Dropping（TWD），通过航点去除技术促进显式的时间学习。通过航点去除学习可以迫使模型改善其对智能体之间的时间关联的理解，从而显著提高轨迹预测的效果。轨迹预测方法常常假设观测到的轨迹航点序列是完整的，忽略了现实世界中可能存在缺失值的情况，这可能会影响其性能。

    The inherently diverse and uncertain nature of trajectories presents a formidable challenge in accurately modeling them. Motion prediction systems must effectively learn spatial and temporal information from the past to forecast the future trajectories of the agent. Many existing methods learn temporal motion via separate components within stacked models to capture temporal features. This paper introduces a novel framework, called Temporal Waypoint Dropping (TWD), that promotes explicit temporal learning through the waypoint dropping technique. Learning through waypoint dropping can compel the model to improve its understanding of temporal correlations among agents, thus leading to a significant enhancement in trajectory prediction. Trajectory prediction methods often operate under the assumption that observed trajectory waypoint sequences are complete, disregarding real-world scenarios where missing values may occur, which can influence their performance. Moreover, these models freque
    
[^18]: 生命科学领域的知识图谱：最新发展、挑战和机遇

    Knowledge Graphs for the Life Sciences: Recent Developments, Challenges and Opportunities. (arXiv:2309.17255v1 [cs.AI])

    [http://arxiv.org/abs/2309.17255](http://arxiv.org/abs/2309.17255)

    这篇论文综述了在生命科学领域中使用知识图谱的最新发展和进展，并展望了这些技术在未来对这些领域的影响。

    

    生命科学是研究生物和生命过程的学科，包括化学、生物学、医学和一系列其他相关学科。生命科学的研究工作非常依赖数据，因为它们产生和消费大量科学数据，其中很多数据具有关系和图结构。数据的数量和其中涉及的科学概念和关系的复杂性推动了应用先进的知识驱动技术来管理和解释数据，最终目标是推动科学发现。在这篇综述和观点论文中，我们讨论了知识图谱在生命科学中的最新发展和进展，并展望了这些技术在未来对这些领域的影响。我们重点关注三个主题：知识图谱的构建和管理，以及在新发现的过程中使用知识图谱和相关技术。

    The term life sciences refers to the disciplines that study living organisms and life processes, and include chemistry, biology, medicine, and a range of other related disciplines. Research efforts in life sciences are heavily data-driven, as they produce and consume vast amounts of scientific data, much of which is intrinsically relational and graph-structured.  The volume of data and the complexity of scientific concepts and relations referred to therein promote the application of advanced knowledge-driven technologies for managing and interpreting data, with the ultimate aim to advance scientific discovery.  In this survey and position paper, we discuss recent developments and advances in the use of graph-based technologies in life sciences and set out a vision for how these technologies will impact these fields into the future. We focus on three broad topics: the construction and management of Knowledge Graphs (KGs), the use of KGs and associated technologies in the discovery of ne
    
[^19]: 人工生成的演示是否对于上下文学习有必要？

    Are Human-generated Demonstrations Necessary for In-context Learning?. (arXiv:2309.14681v1 [cs.LG])

    [http://arxiv.org/abs/2309.14681](http://arxiv.org/abs/2309.14681)

    本文研究了上下文学习中人工生成的演示是否有必要，并提出了一种新的自反思提示策略（SEC），通过这种策略，大型语言模型（LLMs）可以自行生成演示和最终输出，避免了手动生成过程的复杂性。

    

    尽管大型语言模型（LLMs）具备良好的少样本能力，但在上下文学习（ICL）的标准范式中存在以下弊端：易受选定演示的影响，生成这些演示的复杂性。本文提出了对于ICL，人工生成的演示是否有必要的基本问题，并提出了自反思提示策略（SEC），这是一种不依赖人工演示的范例。SEC的关键点在于，不使用手工制作的示例作为ICL中的演示，而是要求LLMs首先自行创建演示，然后生成最终输出。SEC是一种灵活的框架，可适应原始ICL和“思维链”（CoT），并且更加便捷：因为可以节省示例和理由的手动生成过程。在算术推理、常识推理和多任务语言理解方面进行了大量实验。

    Despite the promising few-shot ability of large language models (LLMs), the standard paradigm of In-context Learning (ICL) suffers the disadvantages of susceptibility to selected demonstrations and the intricacy to generate these demonstrations. In this paper, we raise the fundamental question that whether human-generated demonstrations are necessary for ICL. To answer this question, we propose self-contemplation prompting strategy (SEC), a paradigm free from human-crafted demonstrations. The key point of SEC is that, instead of using hand-crafted examples as demonstrations in ICL, SEC asks LLMs to first create demonstrations on their own, based on which the final output is generated. SEC is a flexible framework and can be adapted to both the vanilla ICL and the chain-of-thought (CoT), but with greater ease: as the manual-generation process of both examples and rationale can be saved. Extensive experiments in arithmetic reasoning, commonsense reasoning, multi-task language understandin
    
[^20]: StratMed：面向低资源药物推荐的相关性分层方法

    StratMed: Relevance Stratification for Low-resource Medication Recommendation. (arXiv:2308.16781v1 [cs.AI])

    [http://arxiv.org/abs/2308.16781](http://arxiv.org/abs/2308.16781)

    StratMed是一种面向低资源药物推荐的模型，通过相关性分层机制来解决医疗数据长尾分布不平衡的问题，平衡了药物组合的安全性和准确性。

    

    随着有限医疗资源与日益增长的需求之间的失衡，基于人工智能的临床任务变得至关重要。作为一个子领域，药物推荐旨在将患者的纵向历史与医学知识相结合，帮助医生更安全、更准确地开具药物组合处方。现有方法忽视了医疗数据中固有的长尾分布，缺乏头尾数据之间的平衡表示，导致模型性能次优。为了解决这个挑战，我们引入了StratMed，这是一个结合了创新的相关性分层机制的模型。它通过协调数据长尾分布中的差异，并在药物组合的安全性和准确性之间取得平衡。具体而言，我们首先使用深度学习网络构建预训练方法来获取实体表示。然后，我们设计了一个类似金字塔的数据分层方法，以获得更通用的实体表示。

    With the growing imbalance between limited medical resources and escalating demands, AI-based clinical tasks have become paramount. Medication recommendation, as a sub-domain, aims to amalgamate longitudinal patient history with medical knowledge, assisting physicians in prescribing safer and more accurate medication combinations. Existing methods overlook the inherent long-tail distribution in medical data, lacking balanced representation between head and tail data, which leads to sub-optimal model performance. To address this challenge, we introduce StratMed, a model that incorporates an innovative relevance stratification mechanism. It harmonizes discrepancies in data long-tail distribution and strikes a balance between the safety and accuracy of medication combinations. Specifically, we first construct a pre-training method using deep learning networks to obtain entity representation. After that, we design a pyramid-like data stratification method to obtain more generalized entity 
    
[^21]: 评估大型语言模型对指令的鲁棒性

    Evaluating the Robustness to Instructions of Large Language Models. (arXiv:2308.14306v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.14306](http://arxiv.org/abs/2308.14306)

    本论文评估了大型语言模型对指令的鲁棒性。结果表明，指令微调可以提升中等规模模型的性能，并且模型对陌生指令的处理能力有待改进。

    

    最近，指令微调已成为提升大型语言模型在新任务中零-shot能力的潜在方法。该技术显示出出色的能力，可以提升中等规模的语言模型的性能，有时甚至达到相当于更大模型变体的性能水平。本研究重点研究了经过指令微调的语言模型对已知任务和未知任务的鲁棒性。我们对六个模型进行了探索，包括Alpaca、Vicuna、WizardLM和传统的任务导向模型（Flan-T5-XL/XXL、T0++），以真实世界的关系提取数据集作为案例研究。我们对这些遵循指令的语言模型进行了全面评估，这些模型是基于开放域指令和任务导向指令进行微调的。主要讨论的是它们在处理指令时的性能和鲁棒性。我们观察到，在大多数情况下，模型在处理陌生指令方面的性能往往会受到影响。

    Recently, Instruction fine-tuning has risen to prominence as a potential method for enhancing the zero-shot capabilities of Large Language Models (LLMs) on novel tasks. This technique has shown an exceptional ability to boost the performance of moderately sized LLMs, sometimes even reaching performance levels comparable to those of much larger model variants. The focus is on the robustness of instruction-tuned LLMs to seen and unseen tasks. We conducted an exploration of six models including Alpaca, Vicuna, WizardLM, and Traditional Task-oriented Models(Flan-T5-XL/XXL, T0++) using real-world relation extraction datasets as case studies. We carried out a comprehensive evaluation of these instruction-following LLMs which have been tuned based on open-domain instructions and task-oriented instructions. The main discussion is their performance and robustness towards instructions. We have observed that in most cases, the model's performance in dealing with unfamiliar instructions tends to w
    
[^22]: 从脑电图解码自然图像进行物体识别

    Decoding Natural Images from EEG for Object Recognition. (arXiv:2308.13234v1 [cs.HC])

    [http://arxiv.org/abs/2308.13234](http://arxiv.org/abs/2308.13234)

    本文提出了一种自我监督的框架，从EEG信号中学习图像表示，并采用对比学习来对齐这两种模态。通过在最广泛的EEG图像数据集上的实验证明了该方法的优越性能和生物合理性。

    

    电脑脑图（EEG）以其高时间分辨率和适度的信噪比而闻名。最近，能否从EEG中解码自然图像成为热门问题。在本文中，我们提出了一个自我监督的框架，从EEG信号中学习图像表示。具体而言，我们首先使用图像和EEG编码器从配对的图像刺激和EEG响应中提取特征。然后，我们采用对比学习来通过约束它们的相似性来对齐这两种模态。此外，在EEG编码器之前，我们引入了两个即插即用的模块，用于捕捉空间相关性。我们的方法在最广泛的EEG图像数据集上取得了最先进的结果，在200种零样本任务中，top-1准确度达到15.6%，top-5准确度达到42.8%。更重要的是，对EEG信号的时间、空间、频谱和语义方面进行的大量实验证明了其良好的生物合理性。这些结果提供了有价值的见解。

    Electroencephalogram (EEG) is a brain signal known for its high time resolution and moderate signal-to-noise ratio. Whether natural images can be decoded from EEG has been a hot issue recently. In this paper, we propose a self-supervised framework to learn image representations from EEG signals. Specifically, image and EEG encoders are first used to extract features from paired image stimuli and EEG responses. Then we employ contrastive learning to align these two modalities by constraining their similarity. Additionally, we introduce two plug-in-play modules that capture spatial correlations before the EEG encoder. Our approach achieves state-of-the-art results on the most extensive EEG-image dataset, with a top-1 accuracy of 15.6% and a top-5 accuracy of 42.8% in 200-way zero-shot tasks. More importantly, extensive experiments analyzing the temporal, spatial, spectral, and semantic aspects of EEG signals demonstrate good biological plausibility. These results offer valuable insights 
    
[^23]: FedSoL: 在联邦学习中解决全局对齐和本地一般性的问题

    FedSoL: Bridging Global Alignment and Local Generality in Federated Learning. (arXiv:2308.12532v1 [cs.LG])

    [http://arxiv.org/abs/2308.12532](http://arxiv.org/abs/2308.12532)

    FedSoL提出了一种联邦学习的方法，该方法旨在解决数据分布不均匀导致性能下降的问题。它通过平衡全局对齐和本地一般性来改善FL的学习效果。

    

    联邦学习(Federated Learning, FL)通过聚合来自个体客户端的本地训练模型来构建全局模型。虽然FL可以在保护数据隐私的情况下学习模型，但当客户端数据分布不均匀时，常常导致性能下降。许多先前的FL算法通过引入各种近似约束来解决这个问题。这些约束旨在通过限制局部学习与全局目标的偏离来促进全局对齐。然而，它们本质上通过干扰原始的局部目标而限制了局部学习。最近，出现了一种替代方法来改善本地学习的一般性。通过在平滑的损失空间中获得本地模型，这种方法减轻了客户端不同本地目标之间的冲突。然而，它不能确保稳定的全局对齐，因为本地学习不考虑全局目标。在本研究中，我们提出了联邦学习的稳定性(FedSoL)方法来在FL中解决全局对齐和本地一般性的问题。

    Federated Learning (FL) aggregates locally trained models from individual clients to construct a global model. While FL enables learning a model with data privacy, it often suffers from significant performance degradation when client data distributions are heterogeneous. Many previous FL algorithms have addressed this issue by introducing various proximal restrictions. These restrictions aim to encourage global alignment by constraining the deviation of local learning from the global objective. However, they inherently limit local learning by interfering with the original local objectives. Recently, an alternative approach has emerged to improve local learning generality. By obtaining local models within a smooth loss landscape, this approach mitigates conflicts among different local objectives of the clients. Yet, it does not ensure stable global alignment, as local learning does not take the global objective into account. In this study, we propose Federated Stability on Learning (Fed
    
[^24]: 更具表现力的图神经网络在生成任务中是否更好？

    Will More Expressive Graph Neural Networks do Better on Generative Tasks?. (arXiv:2308.11978v1 [cs.LG])

    [http://arxiv.org/abs/2308.11978](http://arxiv.org/abs/2308.11978)

    本论文调查了更具表现力的图神经网络在分子图生成任务中的表现能力，并通过替换图生成模型的基础GNN来进行实验。研究发现，使用更具表现力的GNN可以改善生成任务的性能。

    

    图生成是一个重要的挑战，它涉及根据给定的标签预测一个完整的具有多个节点和边的图。这个任务对许多实际应用非常重要，包括药物和分子设计。近年来，在图生成领域出现了几种成功的方法。然而，这些方法存在两个重大问题：(1) 这些方法中使用的基础图神经网络（GNN）架构往往未经深入探索；(2) 这些方法往往只在有限的指标上进行评估。为填补这个空白，我们通过将图生成模型的基础GNN替换为更具表现力的GNN，研究了GNN在分子图生成任务中的表现能力。具体而言，我们分析了两种不同生成框架（GCPN和GraphAF）中六种GNN在六个不同的分子生成目标上的性能。

    Graph generation poses a significant challenge as it involves predicting a complete graph with multiple nodes and edges based on simply a given label. This task also carries fundamental importance to numerous real-world applications, including de-novo drug and molecular design. In recent years, several successful methods have emerged in the field of graph generation. However, these approaches suffer from two significant shortcomings: (1) the underlying Graph Neural Network (GNN) architectures used in these methods are often underexplored; and (2) these methods are often evaluated on only a limited number of metrics. To fill this gap, we investigate the expressiveness of GNNs under the context of the molecular graph generation task, by replacing the underlying GNNs of graph generative models with more expressive GNNs. Specifically, we analyse the performance of six GNNs in two different generative frameworks (GCPN and GraphAF), on six different molecular generative objectives on the ZIN
    
[^25]: LLM基于智能体是否存在社会原则？

    Is There Any Social Principle for LLM-Based Agents?. (arXiv:2308.11136v1 [cs.CY])

    [http://arxiv.org/abs/2308.11136](http://arxiv.org/abs/2308.11136)

    LLM基于智能体不仅应关注“以人为中心”的对齐或应用，还应关注智能体自身，并探讨社会科学在智能体中的潜力。

    

    关注基于大型语言模型的智能体应该超越“以人为中心”的对齐或应用。我们认为应该更多关注智能体本身，并探讨社会科学在智能体中的潜力。

    Focus on Large Language Model based agents should involve more than "human-centered" alignment or application. We argue that more attention should be paid to the agent itself and discuss the potential of social sciences for agents.
    
[^26]: 评估大型语言模型对提示注入的指令跟随鲁棒性的研究

    Evaluating the Instruction-Following Robustness of Large Language Models to Prompt Injection. (arXiv:2308.10819v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.10819](http://arxiv.org/abs/2308.10819)

    该论文提出了一个用于评估大型语言模型对注入的对抗性指令的鲁棒性的基准，旨在量化模型受到注入指令影响的程度，并评估其区分原始用户指令和注入指令的能力。

    

    大型语言模型（LLM）在遵循指令方面表现出卓越的能力，使其在面向客户的应用中具有重要价值。然而，它们的出色能力也引发了对由第三方攻击者注入模型输入的对抗性指令的风险放大的担忧，这些指令可能操纵LLM的原始指令并导致意外的行为和内容。因此，了解LLM准确辨别要遵循的指令的能力对于确保它们在现实场景中的安全部署至关重要。在本文中，我们提出了一个开创性的基准，用于自动评估注入的对抗性指令对LLM指令跟随鲁棒性的影响。该基准的目标是量化LLM受注入的对抗性指令影响的程度，并评估其区分这些注入的对抗性指令和原始用户指令的能力。

    Large Language Models (LLMs) have shown remarkable proficiency in following instructions, making them valuable in customer-facing applications. However, their impressive capabilities also raise concerns about the amplification of risks posed by adversarial instructions, which can be injected into the model input by third-party attackers to manipulate LLMs' original instructions and prompt unintended actions and content. Therefore, it is crucial to understand LLMs' ability to accurately discern which instructions to follow to ensure their safe deployment in real-world scenarios. In this paper, we propose a pioneering benchmark for automatically evaluating the robustness of instruction-following LLMs against adversarial instructions injected in the prompt. The objective of this benchmark is to quantify the extent to which LLMs are influenced by injected adversarial instructions and assess their ability to differentiate between these injected adversarial instructions and original user ins
    
[^27]: 贝叶斯流网络

    Bayesian Flow Networks. (arXiv:2308.07037v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2308.07037](http://arxiv.org/abs/2308.07037)

    本文介绍了贝叶斯流网络（BFNs），一种新的生成模型，它通过贝叶斯推断修改了一组独立分布的参数，并将其作为输入传递给神经网络来生成另一个相互依赖的分布。该方法不需要前向过程，适用于连续和离散数据，并具有优化数据压缩的功能。

    

    本文介绍了贝叶斯流网络（BFNs），一种新的生成模型。在BFNs中，独立分布的参数会在嘈杂的数据样本的影响下通过贝叶斯推断进行修改，然后作为输入传递给神经网络，该神经网络输出一个相互依赖的分布。从简单的先验开始，通过迭代更新这两个分布可以得到一个类似于扩散模型反向过程的生成过程；不过，这个过程在概念上更简单，无需前向过程。对于连续、离散化和离散数据，推导出了离散和连续时间的损失函数，以及样本生成过程。值得注意的是，对于离散数据，网络的输入位于概率单纯形上，因此本质上是可微分的，为基于梯度的样本引导和在语言建模等离散领域进行少量步骤生成铺平了道路。损失函数直接优化了数据压缩，并且不放置限制。

    This paper introduces Bayesian Flow Networks (BFNs), a new class of generative model in which the parameters of a set of independent distributions are modified with Bayesian inference in the light of noisy data samples, then passed as input to a neural network that outputs a second, interdependent distribution. Starting from a simple prior and iteratively updating the two distributions yields a generative procedure similar to the reverse process of diffusion models; however it is conceptually simpler in that no forward process is required. Discrete and continuous-time loss functions are derived for continuous, discretised and discrete data, along with sample generation procedures. Notably, the network inputs for discrete data lie on the probability simplex, and are therefore natively differentiable, paving the way for gradient-based sample guidance and few-step generation in discrete domains such as language modelling. The loss function directly optimises data compression and places no
    
[^28]: Relation-Oriented: 迈向与知识对准的因果人工智能

    Relation-Oriented: Toward Knowledge-Aligned Causal AI. (arXiv:2307.16387v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2307.16387](http://arxiv.org/abs/2307.16387)

    本研究从创新的关系导向视角出发，探讨了当前的建模范式中的观察模型与实际理解的不对齐问题，并提出了关系定义的表示学习方法作为实现关系导向建模的实践方法。

    

    在机器学习中，我们自然地应用一个观察导向的原则，其中观察变量先存在并为构建关系奠定基础。虽然对于传统模型来说足够了，但是人工智能与大数据的整合暴露了观察模型与我们的实际理解之间的不对齐。相反，人类塑造了由关系定义的认知实体，使我们能够跨越时间和超维度空间制定知识，而不是被限制在观察构建中。从一种创新的关系导向的视角出发，本研究通过来自计算机视觉和健康信息学的直观例子，分析了在我们当前的建模范式中这种不对齐的根源。我们还介绍了关系定义的表示学习方法作为关系导向建模的一种实际实施，支持广泛的实验验证。

    In machine learning, we naturally apply an Observation-Oriented principle, in which observational variables preexist and set the stage for constructing relationships. While sufficient for traditional models, the integration of AI with big data exposes the misalignment between the observational models and our actual comprehension. Contrarily, humans shape cognitive entities defined by relationships, enabling us to formulate knowledge across temporal and hyper-dimensional spaces, rather than being confined to observational constructs. From an innovative Relation-Oriented perspective, this study examines the roots of this misalignment within our current modeling paradigm, illuminated by intuitive examples from computer vision and health informatics. We also introduce the relation-defined representation learning methodology as a practical implementation of Relation-Oriented modeling, supported by extensive experimental validation.
    
[^29]: RCT拒绝抽样用于因果估计评估

    RCT Rejection Sampling for Causal Estimation Evaluation. (arXiv:2307.15176v1 [cs.AI])

    [http://arxiv.org/abs/2307.15176](http://arxiv.org/abs/2307.15176)

    该论文提出了一种名为RCT拒绝抽样的新抽样算法，用于因果估计评估。该方法通过子抽样随机控制试验(RCT)创建混淆的观测数据集，并使用RCT的平均因果效应作为基准真实值，以进行有效比较。

    

    混淆是从观测数据中无偏估计因果效应的一个重要障碍。对于高维协变量的情况，如文本数据、基因组学或行为社会科学，研究人员提出了适应机器学习方法进行因果估计的调整方法。然而，这些调整方法的经验评估一直存在困难和限制。在这项工作中，我们基于一种有前景的经验评估策略，简化了评估设计，并使用真实数据：对随机控制试验(RCT)进行子抽样，以创建混淆的观测数据集，同时使用RCT的平均因果效应作为基准真实值。我们提出了一种新的抽样算法，称为RCT拒绝抽样，并提供了理论保证，以确保观测数据的因果识别成立，从而可以与基准RCT进行有效比较。通过使用合成数据，我们展示了我们的算法在...

    Confounding is a significant obstacle to unbiased estimation of causal effects from observational data. For settings with high-dimensional covariates -- such as text data, genomics, or the behavioral social sciences -researchers have proposed methods to adjust for confounding by adapting machine learning methods to the goal of causal estimation. However, empirical evaluation of these adjustment methods has been challenging and limited. In this work, we build on a promising empirical evaluation strategy that simplifies evaluation design and uses real data: subsampling randomized controlled trials (RCTs) to create confounded observational datasets while using the average causal effects from the RCTs as ground-truth. We contribute a new sampling algorithm, which we call RCT rejection sampling, and provide theoretical guarantees that causal identification holds in the observational data to allow for valid comparisons to the ground-truth RCT. Using synthetic data, we show our algorithm in
    
[^30]: WavJourney：使用大型语言模型进行音频创作

    WavJourney: Compositional Audio Creation with Large Language Models. (arXiv:2307.14335v1 [cs.SD])

    [http://arxiv.org/abs/2307.14335](http://arxiv.org/abs/2307.14335)

    本研究提出了WavJourney系统，利用大型语言模型实现音频内容的创作。该系统可以根据文本指令生成包含语音、音乐和音效的音频内容。

    

    大型语言模型在整合不同的专家模型以解决复杂的语言和视觉任务方面显示出巨大的潜力。尽管它们在推动人工智能生成内容领域的发展方面具有重要意义，但它们在智能音频内容创作方面的潜力仍未被发掘。在这项工作中，我们解决了使用文本指令创建涵盖语音、音乐和音效的音频内容的问题。我们提出了一种名为WavJourney的系统，利用大型语言模型连接各种音频模型进行音频内容生成。给定一个听觉场景的文本描述，WavJourney首先提示大型语言模型生成一个专用于音频叙事的结构脚本。音频脚本包含了不同的音频元素，根据它们的时空关系进行组织。作为音频的概念表示，音频脚本为人类参与提供了互动和可解释的理由。随后，音频脚本被传递给音频生成模型，生成相应的音频内容。

    Large Language Models (LLMs) have shown great promise in integrating diverse expert models to tackle intricate language and vision tasks. Despite their significance in advancing the field of Artificial Intelligence Generated Content (AIGC), their potential in intelligent audio content creation remains unexplored. In this work, we tackle the problem of creating audio content with storylines encompassing speech, music, and sound effects, guided by text instructions. We present WavJourney, a system that leverages LLMs to connect various audio models for audio content generation. Given a text description of an auditory scene, WavJourney first prompts LLMs to generate a structured script dedicated to audio storytelling. The audio script incorporates diverse audio elements, organized based on their spatio-temporal relationships. As a conceptual representation of audio, the audio script provides an interactive and interpretable rationale for human engagement. Afterward, the audio script is fe
    
[^31]: 面向银行流程自动化的多模式文档分析

    Multimodal Document Analytics for Banking Process Automation. (arXiv:2307.11845v1 [cs.CL])

    [http://arxiv.org/abs/2307.11845](http://arxiv.org/abs/2307.11845)

    本研究聚焦于应对金融科技竞争和提高银行业务运营效率的需求，通过多模式模型特别是先进的文档分析技术，研究了银行流程中的潜力和机会，并展示了LayoutXLM等模型在分析银行文档中的潜力和性能。

    

    针对金融科技竞争的增长和提高运营效率的需求，本研究关注于理解在银行流程中利用多模式模型特别是先进的文档分析的潜力。我们对多样化的银行文档领域进行了全面分析，突出了通过自动化和先进的分析技术在客户业务中提高效率的机会。基于快速发展的自然语言处理（NLP）领域，我们展示了诸如LayoutXLM这样的模型的潜力，它是一种跨语言、多模式、预训练模型，用于分析银行业中各种不同的文档。该模型对德国公司登记提取的文本标记分类具有大约80%的F1得分性能。我们的实证证据证实了布局信息在提高模型性能方面的关键作用，并进一步强调了整合图像信息的好处。

    In response to growing FinTech competition and the need for improved operational efficiency, this research focuses on understanding the potential of advanced document analytics, particularly using multimodal models, in banking processes. We perform a comprehensive analysis of the diverse banking document landscape, highlighting the opportunities for efficiency gains through automation and advanced analytics techniques in the customer business. Building on the rapidly evolving field of natural language processing (NLP), we illustrate the potential of models such as LayoutXLM, a cross-lingual, multimodal, pre-trained model, for analyzing diverse documents in the banking sector. This model performs a text token classification on German company register extracts with an overall F1 score performance of around 80\%. Our empirical evidence confirms the critical role of layout information in improving model performance and further underscores the benefits of integrating image information. Inte
    
[^32]: 基于二次神经元的卷积神经网络的表现力增强

    Expressivity Enhancement with Efficient Quadratic Neurons for Convolutional Neural Networks. (arXiv:2306.07294v1 [cs.LG])

    [http://arxiv.org/abs/2306.07294](http://arxiv.org/abs/2306.07294)

    本文提出了基于二次神经元的高效CNN结构，能够有效地提高网络性能，而且参数和计算成本都有大幅度减少。

    

    卷积神经网络已经成功应用于图像分类和目标分割等领域。为了提高网络的表现力，人们研究了各种技术，如新的CNN架构。但是，来自这些技术的性能提升往往会减弱。为解决这一挑战，许多研究人员把重点转向增加神经元的非线性，以增强网络表现力。然而，大多数这些方法会带来大量的参数，因此不可避免地会导致可部署性方面的低效率。在本研究中，提出了一种高效的二次神经元结构，以仅有微小参数和计算成本开销来保留非线性。所提出的二次神经元可以最大化利用二阶计算信息来改善网络性能。实验结果表明，所提出的二次神经元结构可以实现与现有非线性激活函数相比具有更少的参数和计算成本的竞争性能。

    Convolutional neural networks (CNNs) have been successfully applied in a range of fields such as image classification and object segmentation. To improve their expressivity, various techniques, such as novel CNN architectures, have been explored. However, the performance gain from such techniques tends to diminish. To address this challenge, many researchers have shifted their focus to increasing the non-linearity of neurons, the fundamental building blocks of neural networks, to enhance the network expressivity. Nevertheless, most of these approaches incur a large number of parameters and thus formidable computation cost inevitably, impairing their efficiency to be deployed in practice. In this work, an efficient quadratic neuron structure is proposed to preserve the non-linearity with only negligible parameter and computation cost overhead. The proposed quadratic neuron can maximize the utilization of second-order computation information to improve the network performance. The experi
    
[^33]: 细粒度语义奖励增强文本到图像扩散模型

    Boosting Text-to-Image Diffusion Models with Fine-Grained Semantic Rewards. (arXiv:2305.19599v1 [cs.CV])

    [http://arxiv.org/abs/2305.19599](http://arxiv.org/abs/2305.19599)

    本文提出了FineRewards，通过引入细粒度的语义奖励，即标题奖励和SAM奖励，来改进文本到图像扩散模型中文本和图像之间的对齐。

    

    最近，文本到图像扩散模型的研究取得了显著的成功，在给定的文本提示下生成了高质量、逼真的图像。然而，由于缺乏细粒度语义指导，以成功诊断形态差异为止，以前的方法无法执行文本概念和生成的图像之间的准确形态对齐。在本文中，我们提出了FineRewards，通过引入两种新的细粒度语义奖励--标题奖励和语义分割任何事物（SAM）奖励，来改进文本到图像扩散模型中文本和图像之间的对齐。

    Recent advances in text-to-image diffusion models have achieved remarkable success in generating high-quality, realistic images from given text prompts. However, previous methods fail to perform accurate modality alignment between text concepts and generated images due to the lack of fine-level semantic guidance that successfully diagnoses the modality discrepancy. In this paper, we propose FineRewards to improve the alignment between text and images in text-to-image diffusion models by introducing two new fine-grained semantic rewards: the caption reward and the Semantic Segment Anything (SAM) reward. From the global semantic view, the caption reward generates a corresponding detailed caption that depicts all important contents in the synthetic image via a BLIP-2 model and then calculates the reward score by measuring the similarity between the generated caption and the given prompt. From the local semantic view, the SAM reward segments the generated images into local parts with categ
    
[^34]: 自动自我生成的零样本编码从语义级别到代码级别的 SelfzCoT，更好地利用LLMs

    SelfzCoT: a Self-Prompt Zero-shot CoT from Semantic-level to Code-level for a Better Utilization of LLMs. (arXiv:2305.11461v1 [cs.AI])

    [http://arxiv.org/abs/2305.11461](http://arxiv.org/abs/2305.11461)

    本文提出了 SelfzCoT 自动自我生成的零样本编码，通过使用LLMs和代码级别的自我提示，在六个零样本算术推理任务中实现了巨大的准确度提升。同时，修改的零样本编码 MzCoT 在推理任务中也取得了显著的表现。

    

    本文通过 SelfzCoT 自动自我生成的零样本编码，研究了如何更好地利用LLMs。具体地，我们将 SelfzCoT 应用于零样本算术推理任务，其准确性从GSM8K的40.50%提高至82.34%，MultiArith从79.3%提高至94.7%，ADDSUB从74.70%提高至94.10%，SingleEq从78.70%提高至91.30%，AQUA从31.90%提高至82.33%，SVAMP从63.70%提高至79.70%。总的来说，使用前两个持久路径激活到LLM，特别是代码级别的自我提示，使 SelfzCoT 在所有六个零样本算术推理任务上实现了巨大的改进。此外，我们修改的零样本编码 MzCoT 在推理任务中也取得了显著的表现。在GSM8K中，MzCoT的准确性从40.50%提高至76.32%，MultiArith从79.3%提高至96.97%，ADDSUB从74.70%提高至92.39%，SingleEq从78.70%提高至94.60%，AQUA从31.90%提高至79.90%，SVAMP从63.70%提高至81.50%。

    This paper show a work on better use of LLMs with SelfzCoT a self-prompt zero-shot CoT. Specifically, on the zero-shot arithmetic reasoning tasks, the accuracy of the proposed SelfzCoT is improved with GSM8K from 40.50% to 82.34%, with MultiArith from 79.3% to 94.7%, with ADDSUB from 74.70% to 94.10%, with SingleEq from 78.70% to 91.30%, with AQUA from 31.90% to 82.33%, and with SVAMP from 63.70% to 79.70%. Totally, using the first two lasting path activations to LLM and particularly, the code-level self-prompt, the SelfzCoT has a huge improvement on all six zero-shot arithmetic reasoning tasks. Additionally, our modified zero-shot CoT (MzCoT) also achieves remarkable performance in the reasoning tasks. The accuracy of the proposed MzCoT is enhanced with GSM8K from 40.50% to 76.32%, with MultiArith from 79.3% to 96.97%, with ADDSUB from 74.70% to 92.39%, with SingleEq from 78.70% to 94.60%, with AQUA from 31.90% to 79.90%, and with SVAMP from 63.70% to 81.50%. Notably, SelfzCoT has the
    
[^35]: AI增强的调查：利用大语言模型进行全国代表性调查的观点预测

    AI-Augmented Surveys: Leveraging Large Language Models for Opinion Prediction in Nationally Representative Surveys. (arXiv:2305.09620v1 [cs.CL])

    [http://arxiv.org/abs/2305.09620](http://arxiv.org/abs/2305.09620)

    本论文研究了利用经过全国代表性调查微调的大语言模型（LLMs）来增强调查的观点预测，取得了在遗漏数据插值和回溯推理方面优秀的成果，在零次预测方面仍需进一步研究。

    

    本论文研究了如何使用经过全国代表性调查微调的大语言模型（LLMs）来增强调查。本文探讨了LLMs在观点预测中，遗漏数据插值，回溯推理和零次预测三个不同应用。我们提出了一种新的方法论框架，将调查问题、个人信念和时间背景的神经嵌入引入到观点预测的个性化LLMs中。在1972年到2021年的“常规社会调查”中，我们从68,846名美国人中获得了3,110个二进制观点，在Alpaca-7b模型的基础上取得了最好的成果，在缺失数据插值（AUC=0.87，公开观点预测为$\rho$=0.99）和回溯推理（AUC=0.86，$\rho$=0.98）方面表现出色。这些显著的预测能力能够以高置信度填补缺失的趋势，并标明公众态度何时发生变化，如同性婚姻的获取支持。然而，在零次预测的情况下，模型的表现受到限制，需要进一步研究。

    How can we use large language models (LLMs) to augment surveys? This paper investigates three distinct applications of LLMs fine-tuned by nationally representative surveys for opinion prediction -- missing data imputation, retrodiction, and zero-shot prediction. We present a new methodological framework that incorporates neural embeddings of survey questions, individual beliefs, and temporal contexts to personalize LLMs in opinion prediction. Among 3,110 binarized opinions from 68,846 Americans in the General Social Survey from 1972 to 2021, our best models based on Alpaca-7b excels in missing data imputation (AUC = 0.87 for personal opinion prediction and $\rho$ = 0.99 for public opinion prediction) and retrodiction (AUC = 0.86, $\rho$ = 0.98). These remarkable prediction capabilities allow us to fill in missing trends with high confidence and pinpoint when public attitudes changed, such as the rising support for same-sex marriage. However, the models show limited performance in a zer
    
[^36]: 搜索UGLE真相：无监督GNN学习环境的调查

    Search for the UGLE Truth: An Investigation into Unsupervised GNN Learning Environments. (arXiv:2305.06026v1 [cs.LG])

    [http://arxiv.org/abs/2305.06026](http://arxiv.org/abs/2305.06026)

    本文提出了一种GNN学习环境下的社区检测算法比较框架，包括数据集和评估指标，以解决目前文献中对于基于GNN的社区检测缺乏公平且严谨评估的问题。

    

    图神经网络 (GNN) 是任何机器学习任务中的一个重要工具，因为它们能够学习图结构上的函数，这是一种强大和表达性强的数据表示。社区检测是一种无监督任务，越来越多地使用GNN进行。利用节点特征的多维度与图的连接性对图中的节点进行聚类，对从社交网络到基因组学的真实世界任务有许多应用。不幸的是，目前文献中缺乏公平且严谨评估基于GNN的社区检测的充分基准环境，从而可能阻碍这一新兴领域的进展。我们观察到这种情况下的特定困难是模糊的超参数调整环境与性能和评估数据集的冲突指标。在这项工作中，我们提出和评估了框架，用于在GNN学习环境中进行一致的社区检测算法比较。我们提供了一个基准数据集，并提出了评估指标，反映了检测到的社区的内在质量以及聚类的准确性。

    Graph Neural Networks (GNNs) are a pertinent tool for any machine learning task due to their ability to learn functions over graph structures, a powerful and expressive data representation. The detection of communities, an unsupervised task has increasingly been performed with GNNs. Clustering nodes in a graph using the multi-dimensionality of node features with the connectivity of the graph has many applications to real world tasks from social networks to genomics. Unfortunately, there is currently a gap in the literature with no established sufficient benchmarking environment for fairly and rigorously evaluating GNN based community detection, thereby potentially impeding progress in this nascent field. We observe the particular difficulties in this setting is the ambiguous hyperparameter tuning environments combined with conflicting metrics of performance and evaluation datasets. In this work, we propose and evaluate frameworks for the consistent comparisons of community detection al
    
[^37]: 基于排名学习和局部模型的多目标高维昂贵问题的进化算法

    Rank-Based Learning and Local Model Based Evolutionary Algorithm for High-Dimensional Expensive Multi-Objective Problems. (arXiv:2304.09444v1 [cs.NE])

    [http://arxiv.org/abs/2304.09444](http://arxiv.org/abs/2304.09444)

    本文提出了一种基于排名学习和局部模型的多目标进化算法，该算法使用分类器进行排名，以解决高维昂贵多目标优化问题。

    

    近年来，辅以代理模型的进化算法广泛应用于解决复杂而计算代价昂贵的多目标优化问题。但是在处理高维优化问题时，这些辅以代理模型的多目标进化算法的性能会急剧恶化。本文提出了一种新颖的基于分类器辅助的排名学习和局部模型的多目标进化算法 (CLMEA)，用于解决高维昂贵的多目标优化问题。该算法由三部分组成：分类器辅助的排名学习、超体积非支配搜索和相对稀疏目标空间的局部搜索。具体来说，该算法建立了一个概率神经网络作为分类器，将后代划分为几个等级。不同等级的后代使用排名学习策略生成更具有前景性和信息性的候选解用于实际优化函数。

    Surrogate-assisted evolutionary algorithms have been widely developed to solve complex and computationally expensive multi-objective optimization problems in recent years. However, when dealing with high-dimensional optimization problems, the performance of these surrogate-assisted multi-objective evolutionary algorithms deteriorate drastically. In this work, a novel Classifier-assisted rank-based learning and Local Model based multi-objective Evolutionary Algorithm (CLMEA) is proposed for high-dimensional expensive multi-objective optimization problems. The proposed algorithm consists of three parts: classifier-assisted rank-based learning, hypervolume-based non-dominated search, and local search in the relatively sparse objective space. Specifically, a probabilistic neural network is built as classifier to divide the offspring into a number of ranks. The offspring in different ranks uses rank-based learning strategy to generate more promising and informative candidates for real funct
    
[^38]: 逐车跟驰模型综述

    A Review on Longitudinal Car-Following Model. (arXiv:2304.07143v1 [eess.SY])

    [http://arxiv.org/abs/2304.07143](http://arxiv.org/abs/2304.07143)

    这篇论文综述了逐车跟驰模型的不同原则和分类，以及面临的挑战和局限性。

    

    车跟车模型是交通仿真的核心组成部分，已经内置于许多配备ADAS的汽车中。对车跟车行为的研究使我们能够确定由基本的车辆交互过程引起的不同宏观现象的根源。本文提供了一份详尽的调查，重点介绍了各种车跟车模型之间的区别、互补性和重叠之处。该审查将在不同原则中概念化的车跟车模型进行分类。

    The car-following (CF) model is the core component for traffic simulations and has been built-in in many production vehicles with Advanced Driving Assistance Systems (ADAS). Research of CF behavior allows us to identify the sources of different macro phenomena induced by the basic process of pairwise vehicle interaction. The CF behavior and control model encompasses various fields, such as traffic engineering, physics, cognitive science, machine learning, and reinforcement learning. This paper provides a comprehensive survey highlighting differences, complementarities, and overlaps among various CF models according to their underlying logic and principles. We reviewed representative algorithms, ranging from the theory-based kinematic models, stimulus-response models, and cruise control models to data-driven Behavior Cloning (BC) and Imitation Learning (IL) and outlined their strengths and limitations. This review categorizes CF models that are conceptualized in varying principles and s
    
[^39]: 面向类别不均问题的集成学习和数据增强模型综述：组合、实现和评估

    A review of ensemble learning and data augmentation models for class imbalanced problems: combination, implementation and evaluation. (arXiv:2304.02858v1 [cs.LG])

    [http://arxiv.org/abs/2304.02858](http://arxiv.org/abs/2304.02858)

    本文研究了集成学习和数据增强方法的应用，针对类别不平衡问题，通过计算评估，找到了最有效的组合。

    

    分类问题中的类别不平衡（CI）是指属于一个类的观测值数量低于其他类的数量。集成学习结合数据增强方法已被广泛应用于解决类别不平衡问题。在过去的十年里，一些策略已经被应用于增强集成学习和数据增强方法，同时还开发了一些新方法，如生成对抗网络（GAN）。本文对用于解决基准CI问题的数据增强和集成学习方法进行计算评估。我们提出了一个评估CI问题的10个数据增强方法和10个集成学习方法的通用框架。我们的目标是识别提高分类效果最有效的组合。

    Class imbalance (CI) in classification problems arises when the number of observations belonging to one class is lower than the other classes. Ensemble learning that combines multiple models to obtain a robust model has been prominently used with data augmentation methods to address class imbalance problems. In the last decade, a number of strategies have been added to enhance ensemble learning and data augmentation methods, along with new methods such as generative adversarial networks (GANs). A combination of these has been applied in many studies, but the true rank of different combinations would require a computational review. In this paper, we present a computational review to evaluate data augmentation and ensemble learning methods used to address prominent benchmark CI problems. We propose a general framework that evaluates 10 data augmentation and 10 ensemble learning methods for CI problems. Our objective was to identify the most effective combination for improving classificat
    
[^40]: 一种基于嵌入的处理具有不一致性本体的容错推理方法

    An Embedding-based Approach to Inconsistency-tolerant Reasoning with Inconsistent Ontologies. (arXiv:2304.01664v1 [cs.AI])

    [http://arxiv.org/abs/2304.01664](http://arxiv.org/abs/2304.01664)

    本文提出了一种基于嵌入的方法来处理具有不一致性本体的容错推理问题，这种方法通过语义向量计算公理之间的关联，定义了选择最大一致子集的方法，并证明了推理关系的合理性。

    

    处理不一致性是知识管理中的重要问题，特别是在本体工程中，本体构建过程中可能出现逻辑不一致性。本文提出了一种基于描述逻辑的嵌入方法，通过将公理转化为分布式语义向量计算公理之间的语义关联，进而定义了一种基于嵌入的选择最大一致子集的方法，并将其用于定义容错推理关系。通过考虑某些逻辑属性，证明了推理关系的合理性。最后，在几个数据集上验证了实验效果。

    Inconsistency handling is an important issue in knowledge management. Especially in ontology engineering, logical inconsistencies may occur during ontology construction. A natural way to reason with an inconsistent ontology is to utilize the maximal consistent subsets of the ontology. However, previous studies on selecting maximum consistent subsets have rarely considered the semantics of the axioms, which may result in irrational inference. In this paper, we propose a novel approach to reasoning with inconsistent ontologies in description logics based on the embeddings of axioms. We first give a method for turning axioms into distributed semantic vectors to compute the semantic connections between the axioms. We then define an embedding-based method for selecting the maximum consistent subsets and use it to define an inconsistency-tolerant inference relation. We show the rationality of our inference relation by considering some logical properties. Finally, we conduct experiments on se
    
[^41]: 从孤立的岛屿到泛大陆：统一语义空间用于人类行为理解

    From Isolated Islands to Pangea: Unifying Semantic Space for Human Action Understanding. (arXiv:2304.00553v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2304.00553](http://arxiv.org/abs/2304.00553)

    本文提出了一个统一的语义空间Poincare行为语义空间，通过将以前数据集的类别与这个语义空间对齐，收集（图像/视频/骨架/MoCap）数据集到一个统一的数据库中，即将“孤立的岛屿”桥接成一个“泛大陆”，这将有助于推进可推广的行为学习。

    

    行为理解是一项重要的研究领域并且备受关注。它可以被理解为从行为的物理空间到语义空间的映射。通常，研究人员会根据独特的选择构建行为数据集，以定义各种类别并将基准线推向极限。因此，数据集之间存在语义差距和不同的类别粒度，就像“孤立的岛屿”一样互不兼容，例如数据集A中的家务和数据集B中的洗盘子。我们认为需要一个更具原则性的语义空间来集中社区的力量，并使我们能够一起使用所有数据集以追求可推广的行为学习。为此，我们设计了一个Poincare行为语义空间，给定动词分类层次结构并涵盖大量行为。通过将以前数据集的类别与我们的语义空间对齐，我们将（图像/视频/骨架/MoCap）数据集收集到一个统一的数据库中，使用统一的标签系统，即将“孤立的岛屿”桥接成一个“泛大陆”。因此，我们对这个统一的数据库进行了广泛的实验，结果证明了我们提出的语义空间和统一数据库的有效性。

    Action understanding matters and attracts attention. It can be formed as the mapping from the action physical space to the semantic space. Typically, researchers built action datasets according to idiosyncratic choices to define classes and push the envelope of benchmarks respectively. Thus, datasets are incompatible with each other like "Isolated Islands" due to semantic gaps and various class granularities, e.g., do housework in dataset A and wash plate in dataset B. We argue that a more principled semantic space is an urgent need to concentrate the community efforts and enable us to use all datasets together to pursue generalizable action learning. To this end, we design a Poincare action semantic space given verb taxonomy hierarchy and covering massive actions. By aligning the classes of previous datasets to our semantic space, we gather (image/video/skeleton/MoCap) datasets into a unified database in a unified label system, i.e., bridging "isolated islands" into a "Pangea". Accord
    
[^42]: PowerPruning: 针对功耗优化的神经网络权重和激活选择方法

    PowerPruning: Selecting Weights and Activations for Power-Efficient Neural Network Acceleration. (arXiv:2303.13997v1 [cs.NE])

    [http://arxiv.org/abs/2303.13997](http://arxiv.org/abs/2303.13997)

    PowerPruning是一种新颖的方法，通过选择能减少神经网络硬件中MAC操作功耗的权重来优化效率。该方法可以将DNN在硬件上的功耗降低高达78.3％，同时没有显著的准确度损失。

    

    深度神经网络在多个领域都获得了成功应用。然而，在将这些网络部署到边缘设备上，尤其是功耗问题上仍然是一个关键挑战，其中最主要的因素是大量的乘加（MAC）操作。为解决这个问题，本文提出了PowerPruning方法，通过选择导致MAC操作消耗更少功耗的权重来减少数字神经网络加速器的功耗。在此基础上，对所选权重及其与所有激活转换的时序特征进行评估，挑选出在引起较小延迟的权重和激活。因此，即使不修改MAC单元，MAC单元中敏感电路路径的最大延迟也将被减小，从而允许灵活缩小供电电压以进一步减少功耗。结合重新训练，本方法可以在不显著降低准确度的情况下，将DNN在硬件上的功耗降低高达78.3％。

    Deep neural networks (DNNs) have been successfully applied in various fields. A major challenge of deploying DNNs, especially on edge devices, is power consumption, due to the large number of multiply-and-accumulate (MAC) operations. To address this challenge, we propose PowerPruning, a novel method to reduce power consumption in digital neural network accelerators by selecting weights that lead to less power consumption in MAC operations. In addition, the timing characteristics of the selected weights together with all activation transitions are evaluated. The weights and activations that lead to small delays are further selected. Consequently, the maximum delay of the sensitized circuit paths in the MAC units is reduced even without modifying MAC units, which thus allows a flexible scaling of supply voltage to reduce power consumption further. Together with retraining, the proposed method can reduce power consumption of DNNs on hardware by up to 78.3% with only a slight accuracy loss
    
[^43]: 在文本到图像扩散模型中添加条件控制

    Adding Conditional Control to Text-to-Image Diffusion Models. (arXiv:2302.05543v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.05543](http://arxiv.org/abs/2302.05543)

    ControlNet是一种神经网络架构，用于为大规模预训练的文本到图像扩散模型添加条件控制。它可以通过重复使用预先训练的编码层学习多样的条件控制，并通过逐渐增加参数进行微调，从而在控制图像扩散模型方面具有鲁棒性。

    

    我们提出了ControlNet，一种神经网络架构，可以为大规模预训练的文本到图像扩散模型添加空间条件控制。ControlNet锁定了生产就绪的大型扩散模型，并重复使用它们以数十亿张图像进行预训练的深度和稳健的编码层作为强大的骨干，从而学习多样化的条件控制。该神经架构与“零卷积”（零初始化的卷积层）连接，从零开始逐渐增加参数，并确保没有有害的噪声影响微调。我们使用单个或多个条件进行稳定扩散测试了各种条件控制，例如边缘、深度、分割、人体姿势等，并且可以有或没有提示。我们展示了ControlNets的训练对于小（<50k）和大（>1m）数据集是鲁棒的。广泛的结果表明，ControlNet可以促进更广泛的应用以控制图像扩散模型。

    We present ControlNet, a neural network architecture to add spatial conditioning controls to large, pretrained text-to-image diffusion models. ControlNet locks the production-ready large diffusion models, and reuses their deep and robust encoding layers pretrained with billions of images as a strong backbone to learn a diverse set of conditional controls. The neural architecture is connected with "zero convolutions" (zero-initialized convolution layers) that progressively grow the parameters from zero and ensure that no harmful noise could affect the finetuning. We test various conditioning controls, eg, edges, depth, segmentation, human pose, etc, with Stable Diffusion, using single or multiple conditions, with or without prompts. We show that the training of ControlNets is robust with small (<50k) and large (>1m) datasets. Extensive results show that ControlNet may facilitate wider applications to control image diffusion models.
    
[^44]: 自我指导扩散模型

    Self-Guided Diffusion Models. (arXiv:2210.06462v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.06462](http://arxiv.org/abs/2210.06462)

    本文提出了一种框架，利用自我监督信号的灵活性设计了自我指导扩散模型。实验表明，自标记指导始终优于没有指导的扩散模型，并且在不平衡数据上甚至可以超过基于真实标签的指导。

    

    扩散模型在图像生成方面取得了显著进展，特别是在使用指导来控制生成过程时。然而，指导需要大量的图像-注释对进行训练，因此依赖于其可用性、正确性和无偏性。本文提出一种可以消除这种注释需求的框架，利用自我监督信号的灵活性设计了自我指导扩散模型。通过利用特征提取函数和自我注释函数，我们的方法在各种图像粒度上提供指导信号：从整体图像到物体框，甚至到分割蒙版。我们在单标签和多标签图像数据集上的实验表明，自标记指导始终优于没有指导的扩散模型，并且在不平衡数据上甚至可以超过基于真实标签的指导。

    Diffusion models have demonstrated remarkable progress in image generation quality, especially when guidance is used to control the generative process. However, guidance requires a large amount of image-annotation pairs for training and is thus dependent on their availability, correctness and unbiasedness. In this paper, we eliminate the need for such annotation by instead leveraging the flexibility of self-supervision signals to design a framework for self-guided diffusion models. By leveraging a feature extraction function and a self-annotation function, our method provides guidance signals at various image granularities: from the level of holistic images to object boxes and even segmentation masks. Our experiments on single-label and multi-label image datasets demonstrate that self-labeled guidance always outperforms diffusion models without guidance and may even surpass guidance based on ground-truth labels, especially on unbalanced data. When equipped with self-supervised box or m
    
[^45]: 利用遥感和机器学习实现早期检测树皮甲虫攻击：一项综述

    Early Detection of Bark Beetle Attack Using Remote Sensing and Machine Learning: A Review. (arXiv:2210.03829v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.03829](http://arxiv.org/abs/2210.03829)

    本文综述了早期检测树皮甲虫攻击的过去和现有进展，重点关注了使用遥感和机器学习方法的优势和劣势，以及提供了有关树皮甲虫物种、攻击阶段、寄主树木、研究区域、遥感平台与传感器、光谱分辨率、光谱特征、机器学习方法和深度学习网络的知识。

    

    本文全面回顾了早期检测树皮甲虫引起的树木死亡方面的过去和现有进展，从树皮甲虫与寄主之间的相互作用、遥感和机器学习/深度学习三个主要角度进行了总结。与以往的努力相反，本综述包括了所有遥感系统，并强调了机器学习/深度学习方法来研究它们的优势和劣势。我们根据多光谱或高光谱分析解析了现有文献，并从树皮甲虫物种和攻击阶段，重点关注攻击的早期阶段、寄主树木、研究区域、遥感平台和传感器、光谱/空间/时间分辨率、光谱特征、光谱植被指数（SVIs）、机器学习方法、学习方案、任务类别、模型、算法、类别/簇、特征和深度学习网络与架构方面提取知识。尽管基于深度学习的方法和随机森林（RF）算法显示出有希望的结果，突出了它们在可见光和热红外等波段上检测微小变化的潜力。

    This paper provides a comprehensive review of past and current advances in the early detection of bark beetle-induced tree mortality from three primary perspectives: bark beetle & host interactions, RS, and ML/DL. In contrast to prior efforts, this review encompasses all RS systems and emphasizes ML/DL methods to investigate their strengths and weaknesses. We parse existing literature based on multi- or hyper-spectral analyses and distill their knowledge based on: bark beetle species & attack phases with a primary emphasis on early stages of attacks, host trees, study regions, RS platforms & sensors, spectral/spatial/temporal resolutions, spectral signatures, spectral vegetation indices (SVIs), ML approaches, learning schemes, task categories, models, algorithms, classes/clusters, features, and DL networks & architectures. Although DL-based methods and the random forest (RF) algorithm showed promising results, highlighting their potential to detect subtle changes across visible, therma
    
[^46]: 大型语言模型仍无法规划（LLM在规划和变化推理中的基准）。（arXiv:2206.10498v3 [cs.CL] UPDATED）

    Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change). (arXiv:2206.10498v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.10498](http://arxiv.org/abs/2206.10498)

    本研究提出了一个用于测评LLMs规划和变化推理能力的框架，并测试了流行的LLMs (GPT-3 和 GShard) 在此基准上的表现。研究发现这些模型在最简单的规划任务上都表现不佳，强调了目前LLMs推理能力的严重限制，建议需要大量工作来开发更先进的LLM基础系统来满足实际应用需求。

    

    大型语言模型（LLMs）的最新进展已经改变了自然语言处理（NLP）领域。从GPT-3到PaLM，自然语言任务的最新性能正在随着每个新的大型语言模型的推出不断提高。除了自然语言能力外，人们对于理解此类模型是否具有推理能力产生了极大的兴趣，并采用了推理基准来进行测评。然而，尽管结果看似积极，这些基准在本质上是简单的，LLMs在这些基准上的表现并不能作为支持LLMs推理能力（有时是荒谬的）声称的证据。此外，这些只代表了一个非常有限的简单推理任务集，如果我们要衡量此类基于LLM的系统的真正限制，我们需要研究更复杂的推理问题。受此启发，我们提出了一个可扩展的评估框架，用于测试LLMs规划和变化推理的能力。我们的框架包括一系列的规划和推理任务，例如命题逻辑、因果推断和常识推理，这些任务的难度随着任务的进展而逐渐增加。我们测量了两个流行的LLMs（GPT-3和GShard）在这个基准上的表现，并发现这些模型甚至无法处理最简单的规划任务。我们的发现强调了当前LLMs推理能力的严重局限性，并建议需要大量工作来开发可以规划和推理变化的LLM基础系统，以满足实际应用的需求。

    Recent advances in large language models (LLMs) have transformed the field of natural language processing (NLP). From GPT-3 to PaLM, the state-of-the-art performance on natural language tasks is being pushed forward with every new large language model. Along with natural language abilities, there has been a significant interest in understanding whether such models exhibit reasoning capabilities with the use of reasoning benchmarks. However, even though results are seemingly positive, these benchmarks prove to be simplistic in nature and the performance of LLMs on these benchmarks cannot be used as evidence to support, many a times outlandish, claims being made about LLMs' reasoning capabilities. Further, these only represent a very limited set of simple reasoning tasks and we need to look at more sophisticated reasoning problems if we are to measure the true limits of such LLM-based systems. Motivated by this, we propose an extensible assessment framework to test the capabilities of LL
    

