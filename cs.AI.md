# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Tracking through Containers and Occluders in the Wild.](http://arxiv.org/abs/2305.03052) | 本文介绍了一个新的基准模型 $\textbf{TCOW}$，用于在重度遮挡和容器中进行视觉跟踪。我们创建了一组混合的合成和真实数据集，评估了两种最新的基于变压器的视频模型，并发现它们在某些情况下能够出人意料地跟踪目标，但仍存在相当大的性能差距，必须进一步研究。 |
| [^2] | [Personalize Segment Anything Model with One Shot.](http://arxiv.org/abs/2305.03048) | 本文提出了一种无需训练的SAM个性化方法PerSAM，只需要一张带有参考掩模的单张图像即可定位和分割目标概念，还提出了高效的一次性微调变体PerSAM-F，旨在解决掩模不确定性问题。 |
| [^3] | [Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision.](http://arxiv.org/abs/2305.03047) | 这篇论文提出了SELF-ALIGN方法，使用基于原则的推理和LLMs的生成能力以最少的人类监督实现AI代理的自我对齐。 |
| [^4] | [Learning Hand-Held Object Reconstruction from In-The-Wild Videos.](http://arxiv.org/abs/2305.03036) | 本研究提出了一种从野外视频中自动提取三维监督来扩展手持物体重建模型的学习方法。通过使用手部姿势作为物体姿势的代理和学习数据驱动的三维形状先验知识等方法，有效地解决了未知相机姿势和遮挡等问题，从而通过从单个RGB图像预测物体三维形状的占据网络得到了优秀的结果。 |
| [^5] | [What changes when you randomly choose BPE merge operations? Not much.](http://arxiv.org/abs/2305.03029) | 本文提出了三个随机BPE变体，在翻译到形态丰富的语言时，随机选择合并操作对下游机器翻译任务影响很小。标准BPE虽然被广泛使用，但存在着有趣的潜在变化宇宙值得探究。 |
| [^6] | [Panda LLM: Training Data and Evaluation for Open-Sourced Chinese Instruction-Following Large Language Models.](http://arxiv.org/abs/2305.03025) | 该项目研究了如何通过指令调整来提升开源大型语言模型的性能，探讨了训练数据的因素对指令调整模型性能的影响，并通过量化分析来为聊天模型的持续发展提供有价值的洞察力。 |
| [^7] | [FastAMI -- a Monte Carlo Approach to the Adjustment for Chance in Clustering Comparison Metrics.](http://arxiv.org/abs/2305.03022) | FastAMI是一种用于大型数据集的聚类比较的快速方法，通过蒙特卡罗模拟来实现偶然性调整，相比于传统的基于排列的方法更准确。 |
| [^8] | [Improving Code Example Recommendations on Informal Documentation Using BERT and Query-Aware LSH: A Comparative Study.](http://arxiv.org/abs/2305.03017) | 本研究使用BERT和Query-Aware LSH提高非正式文档中代码示例推荐的质量，重点关注于Stack Overflow上的Java编程语言。研究使用BERT将代码示例转换为数值向量。 |
| [^9] | [Evaluating Post-hoc Interpretability with Intrinsic Interpretability.](http://arxiv.org/abs/2305.03002) | 本文通过改进内部可解释性 ProtoPNet 方法，并将其生成的指向性图与后续方法生成的显著性图进行比较，以解决现有解释性方法间存在的差异，为卷积神经网络在组织病理学图像领域的临床应用提供了可行方案。 |
| [^10] | [When Do Neural Nets Outperform Boosted Trees on Tabular Data?.](http://arxiv.org/abs/2305.02997) | 这项研究通过对176个数据集的比较分析发现，在许多数据集中，GBDT和NN之间的性能差异可以忽略不计，或者GBDT的轻微超参数调整比选择最佳算法更重要。此外，研究人员对965个元特征进行了分析，发现GBDT在高维稀疏数据上表现更好。 |
| [^11] | [On the nonlinear correlation of ML performance between data subpopulations.](http://arxiv.org/abs/2305.02995) | 在不同数据子群体间，机器学习模型的内部准确性和外部准确性之间的相关性是非线性的，呈现出“月亮形”的相关性。 |
| [^12] | [SemEval-2023 Task 7: Multi-Evidence Natural Language Inference for Clinical Trial Data.](http://arxiv.org/abs/2305.02993) | 本论文介绍SemEval 2023的任务七，旨在进行临床试验数据的多证据自然语言推理，该任务难度较大，证据选择任务相对于蕴含任务表现更佳。 |
| [^13] | [ExeKGLib: Knowledge Graphs-Empowered Machine Learning Analytics.](http://arxiv.org/abs/2305.02966) | ExeKGLib是一个基于知识图谱的Python机器学习库，可帮助不具备深入ML知识的用户构建可执行的ML工作流，并提高透明度和可重用性。 |
| [^14] | [Weighted Tallying Bandits: Overcoming Intractability via Repeated Exposure Optimality.](http://arxiv.org/abs/2305.02955) | 该论文提出了一种受权重影响的计数赌博机(WTB)设置，通过Repeated Exposure Optimality(REO)来研究它。他们提出了一个算法来满足REO，并提供了最优的遗憾边界。 |
| [^15] | [Leveraging gradient-derived metrics for data selection and valuation in differentially private training.](http://arxiv.org/abs/2305.02942) | 研究如何在隐私增强技术下，利用梯度信息识别训练中感兴趣的数据样本进行数据选择和估价。 |
| [^16] | [An automatically discovered chain-of-thought prompt generalizes to novel models and datasets.](http://arxiv.org/abs/2305.02897) | 本文研究了一系列零照顾提示在六个最新发布的语言模型和问题回答数据集的实验中的表现，发现自动提示发现的CoT提示可在新模型和数据集上表现良好，并在应用于GPT-4模型时取得最佳结果。 |
| [^17] | [Simple Noisy Environment Augmentation for Reinforcement Learning.](http://arxiv.org/abs/2305.02882) | 本论文探讨了一系列通用封装，用于噪声增强RL环境，提供了两种新的增强技术，有助于代理人探索和改善训练数据多样性。同时，介绍了控制噪声注入频率的超参数噪声率。在实验中使用了三种流行的RL算法，Soft Actor-Critic（SAC），Twin Delayed DDPG（TD3）和Proximal Policy，以研究这些封装对回报的影响。 |
| [^18] | [The AI generation gap: Are Gen Z students more interested in adopting generative AI such as ChatGPT in teaching and learning than their Gen X and Millennial Generation teachers?.](http://arxiv.org/abs/2305.02878) | 研究探讨了GenZ学生和X世代、千禧一代教师在高等教育中使用生成式人工智能（GenAI）的体验和态度。结果显示，GenZ学生普遍看好GenAI的潜在好处，而教师则更关注其在伦理和教学上的影响。 |
| [^19] | [Hierarchical Transformer for Scalable Graph Learning.](http://arxiv.org/abs/2305.02866) | 本文提出了分层可扩展图Transformer (HSGT)用于解决图表示学习中的规模问题和上下文信息捕获不足问题，通过构建多尺度图分层结构，HSGT实现了对大型图的快速和内存高效处理，并在基准数据集上展现了卓越的性能表现。 |
| [^20] | [CausalAPM: Generalizable Literal Disentanglement for NLU Debiasing.](http://arxiv.org/abs/2305.02865) | CausalAPM是一个通用的NLU文本解缠框架，它将文字和语义信息投射到独立的特征子空间中，并限制了文字信息在后续预测中的参与程度。该框架可以有效地应对数据集偏置问题，提高了推广性能而不损失性能水平。 |
| [^21] | [ReMask: A Robust Information-Masking Approach for Domain Counterfactual Generation.](http://arxiv.org/abs/2305.02858) | 本文提出一种三步领域混淆方法，包括基于频率和注意力规范的遮盖、遮盖领域特定提示信息，以及揭示领域通用上下文。实验证明这种方法在领域转移方面有较好效果。 |
| [^22] | [Maximum Causal Entropy Inverse Constrained Reinforcement Learning.](http://arxiv.org/abs/2305.02857) | 该论文提出了一种新颖的最大因果熵逆约束强化学习方法，通过利用最大因果熵原理来学习代理遵守限制的约束条件和最优策略，使用遵守这些限制的代理的实例进行学习。此方法已被证明在各种任务和环境中优于最先进的方法。 |
| [^23] | [Noise-Resistant Multimodal Transformer for Emotion Recognition.](http://arxiv.org/abs/2305.02814) | 本论文提出了一种名为噪声抑制的多模态变压器 (NORM.TR)的方法，通过NRGF提取器和变压器来提高多模态情感识别任务的鲁棒性, 试图在其流程中提取噪声抑制特征并引入噪声感知学习方案。实验结果表明，NORM-TR具有优越的性能。 |
| [^24] | [MTLSegFormer: Multi-task Learning with Transformers for Semantic Segmentation in Precision Agriculture.](http://arxiv.org/abs/2305.02813) | 提出了一种基于Transformer和注意机制的语义分割方法MTLSegFormer，在精细化农业领域中的作物排查和作物分类任务中表现优于现有最新方法。 |
| [^25] | [Maximizing Submodular Functions for Recommendation in the Presence of Biases.](http://arxiv.org/abs/2305.02806) | 该论文研究了如何在存在偏见的情况下，通过最大化子模函数来优化推荐系统。先前研究指出，基于公平性约束的干预可以确保比例代表性，并在存在偏见时获得接近最优的效用。而本文则探讨了一组能够捕捉这种目的的子模函数。 |
| [^26] | [Local Optima Correlation Assisted Adaptive Operator Selection.](http://arxiv.org/abs/2305.02805) | 本研究提出了一种根据局部最优解相关性的算子关系分析和度量方法，并根据这个方法提出了一种自适应算子选择的新方法。 |
| [^27] | [Automated Code generation for Information Technology Tasks in YAML through Large Language Models.](http://arxiv.org/abs/2305.02783) | 这项研究提出了一种名为Ansible Wisdom的自然语言转Ansible-YAML代码的工具，可自动化生成Ansible脚本，提高IT自动化生产力，并相比现有技术达到或更好的性能水平。 |
| [^28] | [Unified Model Learning for Various Neural Machine Translation.](http://arxiv.org/abs/2305.02777) | 本文提出了一种统一学习方法，即统一模型学习，可以同时适用于翻译各种任务数据，并实现智能按需翻译，相对现有的特定数据集模型能够得到明显的改进。 |
| [^29] | [A Survey on Proactive Dialogue Systems: Problems, Methods, and Prospects.](http://arxiv.org/abs/2305.02750) | 本综述全面概述了不同类型对话中对话代理主动性的突出问题和先进设计，讨论了符合实际应用需求但需要未来更大研究重点的挑战，激发更多的会话 AI 进展到下一级别。 |
| [^30] | [A computational framework of human values for ethical AI.](http://arxiv.org/abs/2305.02748) | 该论文提出了一个根据社会科学理论建立的计算框架，为研究人类价值观如何支持设计道德人工智能提供了基础。 |
| [^31] | [Unsupervised Dialogue Topic Segmentation with Topic-aware Utterance Representation.](http://arxiv.org/abs/2305.02747) | 本文提出一种利用未标记的对话数据进行无监督对话主题分割的方法，通过邻近话语匹配和伪分割学习主题感知的话语表示，实验显示其明显优于强基准方法。 |
| [^32] | [Human Values in Multiagent Systems.](http://arxiv.org/abs/2305.02739) | 本文提出了一种基于社会科学的形式化价值观表征，并阐明了多智能体系统中实现与价值观一致的行为的关键挑战和相应的研究路线图。 |
| [^33] | [Can Fair Federated Learning reduce the need for Personalisation?.](http://arxiv.org/abs/2305.02728) | 本文探索了联邦学习的公正性与个性化需求的关系，提出个性化公正联邦学习（PFL）算法，能够解决准确性差异以及在FL模型表现不佳时提供参与激励的问题。 |
| [^34] | [An Asynchronous Updating Reinforcement Learning Framework for Task-oriented Dialog System.](http://arxiv.org/abs/2305.02718) | 本文提出了一种异步更新强化学习框架 (AURL) 来训练面向任务型对话系统，解决了不同模块互相影响的问题。同时，采用课程学习来解决数据分布不平衡问题，并引入多个用户模型来增加对话的多样性。该方法在公共数据集上取得了31.37%的对话成功率改进。 |
| [^35] | [DECICE: Device-Edge-Cloud Intelligent Collaboration Framework.](http://arxiv.org/abs/2305.02697) | DECICE是一个跨设备-边缘和云的智能协作框架，具有自适应优化和部署应用的能力，能够应用于智能交通、医学成像和紧急响应等方面。 |
| [^36] | [Learning Language-Specific Layers for Multilingual Machine Translation.](http://arxiv.org/abs/2305.02665) | 本文介绍了语言特异Transformer层（LSLs），这使我们能够增加模型容量，同时保持正向传递中使用的计算量和参数数量不变，从而提高多语机器翻译的质量。 |
| [^37] | [Learning to Recover Causal Relationship from Indefinite Data in the Presence of Latent Confounders.](http://arxiv.org/abs/2305.02640) | 本文提出了因果强度变分模型，解决了从不确定数据中恢复因果关系存在的低样本利用率和分布假设无能力的问题，同时考虑了潜在混淆因素。 |
| [^38] | [Towards Weakly-Supervised Hate Speech Classification Across Datasets.](http://arxiv.org/abs/2305.02637) | 该论文提出使用极度弱的监督方法，只依赖于类别名称而不是注释数据中的类别示例，解决当前仇恨言论识别的研究存在的数据创建策略不系统和不同注释方案问题，并展示了有效性。 |
| [^39] | [A framework for the emergence and analysis of language in social learning agents.](http://arxiv.org/abs/2305.02632) | 本研究提出了一个模拟语言特征的通信协议，用于分析个体和共享抽象的形成及其对任务表现的影响。通过优化信息内容以最大化学生奖励改善了信息编码，提高了学习表现。 |
| [^40] | ["Oops, Did I Just Say That?" Testing and Repairing Unethical Suggestions of Large Language Models with Suggest-Critique-Reflect Process.](http://arxiv.org/abs/2305.02626) | 随着大型语言模型(LLM)在各种应用中的流行，本文提出了第一个测试和修复LLM在道德准则上失当建议的框架，并引入ETHICSSUITE测试套件和建议-批判-反思(SCR)过程以自动检测和修复LLM的不道德建议。 |
| [^41] | [Affective Reasoning at Utterance Level in Conversations: A Causal Discovery Approach.](http://arxiv.org/abs/2305.02615) | 本文提出了一种新的会话情感因果发现方法（CACD），并通过设计公共骨架和生成替代隐含原因解决了因果模型的不确定性和隐含原因的不可观察性的问题。这种方法可以在变长会话中发现因果关系。 |
| [^42] | [High-dimensional Bayesian Optimization via Semi-supervised Learning with Optimized Unlabeled Data Sampling.](http://arxiv.org/abs/2305.02614) | 本文提出基于半监督学习的高维贝叶斯优化方法，利用特定的未标记数据采样、参数化采样分布的优化及动态选择无标记数据等策略，解决了高维贝叶斯优化难以处理的问题。 |
| [^43] | [From Statistical Methods to Deep Learning, Automatic Keyphrase Prediction: A Survey.](http://arxiv.org/abs/2305.02579) | 本文综述了关键词预测的代表性研究，分析了主要模型、数据集和评估指标，特别关注了基于深度学习的关键词预测，并进行了实验比较代表性模型，为深入分析它们的优缺点提供了可比性的数据支持。 |
| [^44] | [Should ChatGPT and Bard Share Revenue with Their Data Providers? A New Business Model for the AI Era.](http://arxiv.org/abs/2305.02555) | ChatGPT和Bard等AI工具需要持续大量且高质量的数据来提高其性能，但现行的版权法则限制了它们对各种数据的获取。与数据提供者分享收益将有助于将AI工具与大多数版权数据拥有者之间的敌对关系转变为合作关系，使AI生态系统更健康。 |
| [^45] | [PersonaLLM: Investigating the Ability of GPT-3.5 to Express Personality Traits and Gender Differences.](http://arxiv.org/abs/2305.02547) | 本文探究了基于LLMs模拟代理的行为，称之为LLM Personas，在分配大五人格类型和性别角色时是否可以生成具有一致性的个性化特质的内容。 |
| [^46] | [Language, Time Preferences, and Consumer Behavior: Evidence from Large Language Models.](http://arxiv.org/abs/2305.02531) | 本研究分析了大型语言模型在不同语言提示下的奖励时间偏好，并发现GPT在具有较弱未来时态的语言下表现出更大的耐心，这与使用该语言的人类的偏好相似。 |
| [^47] | [Reinforcement Learning with Delayed, Composite, and Partially Anonymous Reward.](http://arxiv.org/abs/2305.02527) | 本文提出了一种算法用于解决具有延迟、复合和部分匿名奖励反馈的无限时平均奖励马尔可夫决策过程(MDP)，并取得了较好的效果。 |
| [^48] | [Stimulative Training++: Go Beyond The Performance Limits of Residual Networks.](http://arxiv.org/abs/2305.02507) | 本文从一种新的社会心理学角度重新审视残差网络的训练过程，发现了网络贡献不足问题并提出解决方案和改进策略，以提高残差网络的性能。 |
| [^49] | [AutoML-GPT: Automatic Machine Learning with GPT.](http://arxiv.org/abs/2305.02499) | AutoML-GPT 是一种基于 GPT 的自动机器学习方法，利用大型语言模型动态地利用各种人工智能模型，自动化训练管道，节约了选择模型架构、优化算法和调整超参数的人力和时间成本。 |
| [^50] | [Revisiting Graph Contrastive Learning for Anomaly Detection.](http://arxiv.org/abs/2305.02496) | 本文重新审视了用于异常检测的图对比学习方法。通过深入探讨现有方法的基本机制，提出了统一的多GNN和增强图对比框架MAG，并从中提取轻量级实例L-MAG和M-MAG。 |
| [^51] | [How to Use Reinforcement Learning to Facilitate Future Electricity Market Design? Part 1: A Paradigmatic Theory.](http://arxiv.org/abs/2305.02485) | 本文提出基于强化学习的方法，设计联合市场以应对电力行业脱碳，实现电力系统的安全和经济效益，并为环境做出贡献。该范型理论的框架将在两部分中详细介绍。 |
| [^52] | [Breast Cancer Diagnosis Using Machine Learning Techniques.](http://arxiv.org/abs/2305.02482) | 本文回顾和讨论了来自不同源的最新机器学习技术在乳腺癌诊断中的应用，其中包括热成像、红外热成像、电阻抗层析成像以及血液检测中发现的生物标志物，这些技术比传统方法更快、更可靠和更便宜，并且机器学习技术能够提高诊断的准确性。 |
| [^53] | [Toward the Automated Construction of Probabilistic Knowledge Graphs for the Maritime Domain.](http://arxiv.org/abs/2305.02471) | 该论文研究了海事领域的概率知识图谱的自动构建，以利用含有丰富信息的未结构化软数据，并解决了软数据提取方面的问题。 |
| [^54] | [Multiplicity Boost Of Transit Signal Classifiers: Validation of 69 New Exoplanets Using The Multiplicity Boost of ExoMiner.](http://arxiv.org/abs/2305.02470) | 该论文介绍了一种可提高探测行星信号分类器性能的框架，称为多重性增强分类器，基于现有的分类器并使用多重性信息来验证69个新的系外行星。 |
| [^55] | [The System Model and the User Model: Exploring AI Dashboard Design.](http://arxiv.org/abs/2305.02469) | 论文探讨了基于神经网络的AI系统应该有面板以提高其可用性和安全性，并且界面应该具有基于系统模型和用户模型状态的并行显示。 |
| [^56] | [Tackling Universal Properties of Minimal Trap Spaces of Boolean Networks.](http://arxiv.org/abs/2305.02442) | 本论文介绍了一种新方法——记数器示例引导的精炼抽象(CEGAR)，用于解决布尔网络的最小陷阱空间(MTSs)的通用属性的逻辑推理问题，同时可用于识别在所有MTSs上执行给定属性的布尔变量的永久冻结的重编程问题。 |
| [^57] | [Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory.](http://arxiv.org/abs/2305.02437) | 本文提出了一种新的检索增强文本生成模型Selfmem，通过迭代生成自我记忆池并采用记忆选择器，使检索更加自适应，提高了文本生成的质量和多样性。 |
| [^58] | [PTP: Boosting Stability and Performance of Prompt Tuning with Perturbation-Based Regularizer.](http://arxiv.org/abs/2305.02423) | PTP算法引入基于扰动的正则化器来平滑loss图像，提升prompt tuning性能和稳定性，在四个测试数据集中获得了显著优于现有方法的表现。 |
| [^59] | [Plan, Eliminate, and Track -- Language Models are Good Teachers for Embodied Agents.](http://arxiv.org/abs/2305.02412) | 本文介绍了Plan，Eliminate，和Track（PET）框架，该框架利用预先训练的大型语言模型（LLM）帮助智能体简化控制任务，从而解决了LLM直接作为智能体所面临的一些限制和问题。 |
| [^60] | [Can Feature Engineering Help Quantum Machine Learning for Malware Detection?.](http://arxiv.org/abs/2305.02396) | 本文通过量子机器学习与特征选择策略相结合的混合框架，以降低恶意软件分类器培训时间，初步结果表明在模拟器上可以达到78.91％的测试准确性。 |
| [^61] | [Defending against Insertion-based Textual Backdoor Attacks via Attribution.](http://arxiv.org/abs/2305.02394) | 本文提出了一种基于归因的管道AttDef，用于防御两种插入式污染攻击BadNL和InSent，该管道可以成功缓解插入式文本后门攻击并在四个基准数据集上平均提高了56.59%至79.97%和15.25%至48.34%的准确率。 |
| [^62] | [On the Security Risks of Knowledge Graph Reasoning.](http://arxiv.org/abs/2305.02383) | 本文介绍了一个重要的人工智能任务 - 知识图谱推理(KGR)，并基于攻击者的目的、知识和攻击向量概括了KGR的安全威胁。本文提出了一种新型攻击ROAR，高度有效地误导KGR向目标查询提供预定义答案，但对于非目标查询几乎没有影响。 |
| [^63] | [Metric Tools for Sensitivity Analysis with Applications to Neural Networks.](http://arxiv.org/abs/2305.02368) | 本文提出了一种度量框架和新的聚合指标，用于敏感性分析，可以适用于任何可微分模型。其中新的聚合指标基于三种方法获取有价值的信息，并在神经网络模型上进行了验证。 |
| [^64] | [Fashionpedia-Ads: Do Your Favorite Advertisements Reveal Your Fashion Taste?.](http://arxiv.org/abs/2305.02360) | 本文探讨广告与时尚品味之间的相关性，并引入了一个新的数据集Fashionpedia-Ads，收集并注释了广告图像的情感、视觉和文本信息，以便未来的研究。 |
| [^65] | [Cultivated Wildness: Technodiversity and Wildness in Machines.](http://arxiv.org/abs/2305.02328) | 本研究探讨了通过机器构建野生地点的框架，将机器理解为能够参与生产智能的活动代理。 |
| [^66] | [The Future of Artificial Intelligence (AI) and Machine Learning (ML) in Landscape Design: A Case Study in Coastal Virginia, USA.](http://arxiv.org/abs/2305.02327) | 本论文以介绍使用机器学习技术在海岸环境中预测变量的案例为例，提供了未来景观设计中即将到来的网络环境的实证证据。设计师将不再是作家，而是智能代理中的编舞者、催化剂和指挥者。本文从后人类主义中获得灵感，认为要真正理解网络环境，我们必须采取后人类主义的伦理并克服人类的优越主义。 |
| [^67] | [Cybernetic Environment: A Historical Reflection on System, Design, and Machine Intelligence.](http://arxiv.org/abs/2305.02326) | 本文以历史的视角回顾了控制论和系统思维的发展历程，并在介绍景观设计学科研究的谱系基础上指出景观设计师通过基于生态学的景观设计实现基于控制论原则的系统是控制论发展中的重要组成部分。本文呼吁建立一种新的环境参与范式，以理解设计和机器智能等问题。 |
| [^68] | [Can ChatGPT Pass An Introductory Level Functional Language Programming Course?.](http://arxiv.org/abs/2305.02230) | 本研究测试了ChatGPT在入门级函数式语言编程课程中的表现，结果显示它可以获得B-的成绩并且能够给学生和讲师带来潜在好处。 |
| [^69] | [Doc2SoarGraph: Discrete Reasoning over Visually-Rich Table-Text Documents with Semantic-Oriented Hierarchical Graphs.](http://arxiv.org/abs/2305.01938) | 本文提出了 Doc2SoarGraph 框架，利用语义导向分层图结构中元素之间的差异和相关性，在富含视觉表格文本的TAT-DQA问题下实现了离散推理，表现出了最佳的实验结果。 |
| [^70] | [Improving Contrastive Learning of Sentence Embeddings from AI Feedback.](http://arxiv.org/abs/2305.01918) | 本文提出了一种利用人工智能反馈改进句子嵌入对比学习方法的方式，可以提高对比学习样本对的质量，并结合人类反馈来提供更好的监督信号。 |
| [^71] | [Causality-aware Concept Extraction based on Knowledge-guided Prompting.](http://arxiv.org/abs/2305.01876) | 该论文提出了一种基于因果感知的知识引导提示方法，将其作为干预器装备到基于预训练语言模型的句子提取器中，以缓解概念偏差。在代表性的多语言KG数据集上进行广泛实验，获得了最先进的结果。 |
| [^72] | [Few-shot In-context Learning for Knowledge Base Question Answering.](http://arxiv.org/abs/2305.01750) | 该论文提出了KB-BINDER框架，通过少量的上下文演示实现了在多个知识库问答数据集上的背景学习，大大提高了KBQA问题的可解性。 |
| [^73] | [Generalizing Dataset Distillation via Deep Generative Prior.](http://arxiv.org/abs/2305.01649) | 该方法提出一种基于预训练深度生成模型的学习先验的数据集蒸馏方法，通过在生成模型的潜在空间中将大量图像蒸馏为少量中间特征向量，显著提高了在所有设置中的跨体系结构的泛化能力。 |
| [^74] | [An Autonomous Non-monolithic Agent with Multi-mode Exploration based on Options Framework.](http://arxiv.org/abs/2305.01322) | 该论文关注强化学习中的探索研究，提出了一个能够自主管理探索策略的多模式智能体非单体探索方法，并通过实验结果展示了该方法的优越性能。 |
| [^75] | [Expertise Trees Resolve Knowledge Limitations in Collective Decision-Making.](http://arxiv.org/abs/2305.01063) | 本研究通过引入专业知识树算法，解决了集体决策中专业知识水平不同的问题，并在多个问题上进行了验证。 |
| [^76] | [Interpreting Vision and Language Generative Models with Semantic Visual Priors.](http://arxiv.org/abs/2304.14986) | 本研究提出了一种利用SHAP框架和视觉先验知识生成全面、有意义解释的方法，相较于传统方法具有更低的计算成本、更高的解释表现力，并可以推广到其他模型上。 |
| [^77] | [FineEHR: Refine Clinical Note Representations to Improve Mortality Prediction.](http://arxiv.org/abs/2304.11794) | FineEHR利用度量学习和微调技术来优化临床记录嵌入，以解决原始临床数据的复杂结构和噪声对预测算法准确性的限制。 |
| [^78] | [Detecting Adversarial Faces Using Only Real Face Self-Perturbations.](http://arxiv.org/abs/2304.11359) | 本文提出了一种使用真实人脸自扰动生成伪对抗性人脸的方法，利用这种方法训练的对抗性人脸检测器不需攻击数据即可检测新型未知攻击。 |
| [^79] | [Perceptual Quality Assessment of Face Video Compression: A Benchmark and An Effective Method.](http://arxiv.org/abs/2304.07056) | 本文介绍了大规模压缩面部视频质量评估（CFVQA）数据库，用于系统地了解面部视频感知质量和多样化压缩失真。生成式编码方法被确定为具有合理的感知码率失真折衷的有前途的替代方法，利用面部视频的统计先验知识。 |
| [^80] | [Wild Face Anti-Spoofing Challenge 2023: Benchmark and Results.](http://arxiv.org/abs/2304.05753) | 前人的人脸防伪（FAS）技术应用于实际场景仍然存在限制，因为当前公开的FAS数据集数量和多样性不足，引起过拟合和场景误判。通过引入野外人脸防伪（WFAS）数据集，该研究提高了数据规模和多样化程度，促进了FAS技术的发展。 |
| [^81] | [Generative AI for learning: Investigating the potential of synthetic learning videos.](http://arxiv.org/abs/2304.03784) | 本研究探讨了使用生成AI合成视频来创建在线教育内容的效用，使用混合方法和成年学习者进行实验。结果显示，合成学习视频对学习内容获取和学习体验有着积极的影响。 |
| [^82] | [Revisiting Dense Retrieval with Unanswerable Counterfactuals.](http://arxiv.org/abs/2304.03031) | 本文观察到基于DPR的最近的密集检索模型经常将无法回答的反事实情景排名高于可回答的原始情景，提出了一种新颖的用于段落检索的表示学习方法PiCL。 |
| [^83] | [A Survey of Large Language Models.](http://arxiv.org/abs/2303.18223) | 本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。 |
| [^84] | [Sigmoid Loss for Language Image Pre-Training.](http://arxiv.org/abs/2303.15343) | 本论文提出了适用于语言图像预训练的成对Sigmoid损失函数，可以有效地提高训练批量大小，同时不需要全局查看配对相似性进行归一化，其训练出来的模型在ImageNet上表现良好。 |
| [^85] | [DR.CPO: Diversified and Realistic 3D Augmentation via Iterative Construction, Random Placement, and HPR Occlusion.](http://arxiv.org/abs/2303.12743) | 该论文提出了一种多样化和逼真的增强方法，可以创建整体对象并灵活地定位和旋转对象，并相应地应用自遮挡和外遮挡。通过迭代构建多个对象来提高整体对象构造的多样性，构造的对象可以在训练帧中随机放置和旋转。 |
| [^86] | [Domain-Specific Pre-training Improves Confidence in Whole Slide Image Classification.](http://arxiv.org/abs/2302.09833) | 本文研究了面向领域的预训练对整张切片图像分类的作用，发现使用面向领域的预训练可以提高多实例学习模型在切片图像分类任务中的性能。 |
| [^87] | [Development of an Immersive Virtual Colonoscopy Viewer for Colon Growths Diagnosis.](http://arxiv.org/abs/2302.02946) | 本文开发了一种用于结肠生长诊断的沉浸式虚拟结肠镜查看器，并通过实验确定了其覆盖范围、持续时间和诊断准确性等方面的影响。 |
| [^88] | [A Survey on Efficient Training of Transformers.](http://arxiv.org/abs/2302.01107) | 本文是对高效训练Transformer领域的系统综述，分析和比较了在训练中为中间张量节省计算和内存成本的方法与硬件/算法共同设计的技术，并探讨了未来研究的挑战和前景。 |
| [^89] | [Learning Topology-Preserving Data Representations.](http://arxiv.org/abs/2302.00136) | 本文提出了一种名为RTD-AE的方法用于学习保持数据拓扑结构的降维表示,在保留全局结构和拓扑性方面，其表现优于现有最先进竞争对手。 |
| [^90] | [Large Language Models Are Implicitly Topic Models: Explaining and Finding Good Demonstrations for In-Context Learning.](http://arxiv.org/abs/2301.11916) | 本研究发现，大型语言模型可以被视为隐式的主题模型，并提出了一种算法，从注释数据中选择最佳示范，大大提高了上下文学习的能力。 |
| [^91] | [Generalized Object Search.](http://arxiv.org/abs/2301.10121) | 该论文介绍了一种基于POMDP模型和人类世界结构以及人机交互的结构，可以实现实际有效的广义目标搜索系统。 |
| [^92] | [Understanding the Spectral Bias of Coordinate Based MLPs Via Training Dynamics.](http://arxiv.org/abs/2301.05816) | 该论文研究了基于坐标的MLPs的谱偏置对高频组件收敛的阻碍，并提出使用高频正弦波编码输入来克服这一限制。 |
| [^93] | [Reasoning with Language Model Prompting: A Survey.](http://arxiv.org/abs/2212.09597) | 本文提供了使用语言模型提示进行推理的前沿研究综合调查。讨论了新兴推理能力出现的潜在原因，并提供系统资源帮助初学者。 |
| [^94] | [xTrimoABFold: De novo Antibody Structure Prediction without MSA.](http://arxiv.org/abs/2212.00735) | xTrimoABFold是一种基于深度抗体语言模型的新型抗体结构预测方法，无需多序列比对，有望促进高通量药物设计的应用。 |
| [^95] | [Hierarchical Dynamic Image Harmonization.](http://arxiv.org/abs/2211.08639) | 本文提出了一种分层动态网络（HDNet），以实现有效的图像协调。我们提出了本地动态（LD）模块和基于掩码的全局动态（MGD）模块，LD保留了详细的本地视觉一致性。在我们的实验中，HDNet在定量和定性评估上优于最先进的图像协调方法。 |
| [^96] | [Tutorial and Practice in Linear Programming: Optimization Problems in Supply Chain and Transport Logistics.](http://arxiv.org/abs/2211.07345) | 本文介绍线性规划的基本原理和实践，并通过供应链管理和运输物流中的空间分析优化问题演示如何解决经典的优化问题。 |
| [^97] | [Exploration Policies for On-the-Fly Controller Synthesis: A Reinforcement Learning Approach.](http://arxiv.org/abs/2210.05393) | 本文提出了一种基于强化学习的方法，用于产生启发式来指导有向控制器合成算法的增量探索过程。 |
| [^98] | [Rhythmic Gesticulator: Rhythm-Aware Co-Speech Gesture Synthesis with Hierarchical Neural Embeddings.](http://arxiv.org/abs/2210.01448) | 本论文提出了一种新颖的协同手势合成方法，设计了一个强大的基于节奏的分割流程，并有效地区分了基于语言学理论的语音和动作的低级和高级神经嵌入，从而实现了在语音和手势之间的真正情感互动。 |
| [^99] | [Towards Complex Document Understanding By Discrete Reasoning.](http://arxiv.org/abs/2207.11871) | 本文介绍了一个新的文档视觉问答数据集TAT-DQA，并通过该数据集开发了一种新型模型MHST。MHST模型考虑了多种模态的信息来智能地回答不同类型的问题，实验表明其在TAT-DQA数据集上显著优于其他模型。 |
| [^100] | [AutoOpt: A General Framework for Automatically Designing Metaheuristic Optimization Algorithms with Diverse Structures.](http://arxiv.org/abs/2204.00998) | 本文提出了一个通用的框架AutoOpt，用于自动设计具有多样化结构的元启发式算法，通过发布一个通用的算法原型，它可以更好地发掘元启发式算法家族的潜力和新颖性，从而提高设计的质量。 |
| [^101] | [Spatial State-Action Features for General Games.](http://arxiv.org/abs/2201.06401) | 本文提出了通用博弈的空间状态动作特征的设计和高效实现方法，可以支持不同棋盘和图形的多种不同游戏。同时提出了实时评估活跃特征的高效方法，并在多个游戏中取得了最先进的性能表现。 |
| [^102] | [Representing and Implementing Matrices Using Algebraic ZX-calculus.](http://arxiv.org/abs/2110.06898) | 本文提出了一种方法，在代数ZX演算中对所有 $2^m\times 2^n$ 大小的基本矩阵进行图示表示，为量子计算等领域中的ZX演算应用奠定了基础。 |
| [^103] | [Supervisory Control of Quantum Discrete Event Systems.](http://arxiv.org/abs/2104.09753) | 本文建立了量子离散事件系统的监督控制框架，使用量子有限状态自动机作为建模形式，并提出并证明了其监督控制定理。同时，还提出了一个用于决定QDES状态可达性问题的多项式时间算法，并且该方法可以直接扩展到DES中。 |
| [^104] | [QNLP in Practice: Running Compositional Models of Meaning on a Quantum Computer.](http://arxiv.org/abs/2102.12846) | 本文介绍了在嘈杂的中间规模量子计算机上进行的首个大于100个句子数据集的NLP实验结果，成功地训练了解决简单句子分类任务的NLP模型，证明了组合模型的含义与量子理论具有形式相似性。 |
| [^105] | [ISP Distillation.](http://arxiv.org/abs/2101.10203) | 该论文介绍了一种称为ISP精馏的方法，通过使用知识蒸馏将RAW图像的预测与经过处理的RGB图像的预测相匹配，成功地提高了直接将机器视觉模型应用于RAW图像的性能。 |

# 详细

[^1]: 在复杂环境中跟踪含容器和遮挡物的目标

    Tracking through Containers and Occluders in the Wild. (arXiv:2305.03052v1 [cs.CV])

    [http://arxiv.org/abs/2305.03052](http://arxiv.org/abs/2305.03052)

    本文介绍了一个新的基准模型 $\textbf{TCOW}$，用于在重度遮挡和容器中进行视觉跟踪。我们创建了一组混合的合成和真实数据集，评估了两种最新的基于变压器的视频模型，并发现它们在某些情况下能够出人意料地跟踪目标，但仍存在相当大的性能差距，必须进一步研究。

    

    在杂乱且动态的环境中跟踪具有持久性的目标仍是计算机视觉系统面临的难题。本文介绍了一个新的基准模型 $\textbf{TCOW}$，用于在重度遮挡和容器中进行视觉跟踪。我们设定了一个任务，即在给定视频序列的情况下，分割出目标物体的投影范围以及周围的容器或遮挡物。为了研究这个任务，我们创建了一组混合的合成和真实数据集，以支持模型在各种任务变化形式下的监督学习和结构化评估。我们评估了两种最新的基于变压器的视频模型，并发现尽管它们在某些任务变化的设置下能够出人意料地跟踪目标，但在我们宣称一个跟踪模型已经获得了真正的对象恒常性概念之前，仍存在相当大的性能差距。

    Tracking objects with persistence in cluttered and dynamic environments remains a difficult challenge for computer vision systems. In this paper, we introduce $\textbf{TCOW}$, a new benchmark and model for visual tracking through heavy occlusion and containment. We set up a task where the goal is to, given a video sequence, segment both the projected extent of the target object, as well as the surrounding container or occluder whenever one exists. To study this task, we create a mixture of synthetic and annotated real datasets to support both supervised learning and structured evaluation of model performance under various forms of task variation, such as moving or nested containment. We evaluate two recent transformer-based video models and find that while they can be surprisingly capable of tracking targets under certain settings of task variation, there remains a considerable performance gap before we can claim a tracking model to have acquired a true notion of object permanence.
    
[^2]: 个性化一次性分割模型

    Personalize Segment Anything Model with One Shot. (arXiv:2305.03048v1 [cs.CV])

    [http://arxiv.org/abs/2305.03048](http://arxiv.org/abs/2305.03048)

    本文提出了一种无需训练的SAM个性化方法PerSAM，只需要一张带有参考掩模的单张图像即可定位和分割目标概念，还提出了高效的一次性微调变体PerSAM-F，旨在解决掩模不确定性问题。

    

    在大数据预训练的推动下，分割任何物体模型（SAM）已被证明是一个强大且高效的框架，革新了分割模型领域。尽管SAM非常通用，但自动为特定视觉概念定制SAM而不需要手动提示，如在不同图像中自动分割你的宠物狗等， 还未深入研究。本文提出了一种无需训练的SAM个性化方法，称为PerSAM。只需要一张带有参考掩模的单张图像，PerSAM首先通过位置先验定位目标概念，并通过三种技术来在其他图像或视频中分割它：目标引导注意力，目标语义提示和级联后处理。这样，我们有效地适应了SAM的私人使用而无需任何训练。为了进一步缓解掩模的不确定性，我们提出了一个高效的一次性微调变体，即PerSAM-F。冻结整个SAM，我们引入了两个可学习权重用于多尺度掩模，仅训练2个参数即可。

    Driven by large-data pre-training, Segment Anything Model (SAM) has been demonstrated as a powerful and promptable framework, revolutionizing the segmentation models. Despite the generality, customizing SAM for specific visual concepts without man-powered prompting is under explored, e.g., automatically segmenting your pet dog in different images. In this paper, we propose a training-free Personalization approach for SAM, termed as PerSAM. Given only a single image with a reference mask, PerSAM first localizes the target concept by a location prior, and segments it within other images or videos via three techniques: target-guided attention, target-semantic prompting, and cascaded post-refinement. In this way, we effectively adapt SAM for private use without any training. To further alleviate the mask ambiguity, we present an efficient one-shot fine-tuning variant, PerSAM-F. Freezing the entire SAM, we introduce two learnable weights for multi-scale masks, only training 2 parameters wit
    
[^3]: 原则驱动自我对齐的最小人力监督的语言模型从零开始构建

    Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision. (arXiv:2305.03047v1 [cs.LG])

    [http://arxiv.org/abs/2305.03047](http://arxiv.org/abs/2305.03047)

    这篇论文提出了SELF-ALIGN方法，使用基于原则的推理和LLMs的生成能力以最少的人类监督实现AI代理的自我对齐。

    

    最近的AI助手代理，如ChatGPT，主要依赖于监督微调和人类反馈的强化学习来对齐大型语言模型的输出与人类意图，确保它们是有用的、道德的、可靠的。然而，这种依赖性可能会极大地限制AI助手代理的真正潜力，因为获得人类监督的成本很高，相关问题有质量、可靠性、多样性、自一致性和不良偏见。为了解决这些挑战，我们提出了一种新的方法 SELF-ALIGN，它结合了基于原则的推理和LLMs的生成能力，以最少的人类监督实现AI代理的自我对齐。方法包括四个阶段：第一，我们使用LLM生成合成提示，使用主题引导方法增加提示多样性；第二，我们使用一小组人工编写的AI模型原则，并指导AI模型遵循；

    Recent AI-assistant agents, such as ChatGPT, predominantly rely on supervised fine-tuning (SFT) with human annotations and reinforcement learning from human feedback (RLHF) to align the output of large language models (LLMs) with human intentions, ensuring they are helpful, ethical, and reliable. However, this dependence can significantly constrain the true potential of AI-assistant agents due to the high cost of obtaining human supervision and the related issues on quality, reliability, diversity, self-consistency, and undesirable biases. To address these challenges, we propose a novel approach called SELF-ALIGN, which combines principle-driven reasoning and the generative power of LLMs for the self-alignment of AI agents with minimal human supervision. Our approach encompasses four stages: first, we use an LLM to generate synthetic prompts, and a topic-guided method to augment the prompt diversity; second, we use a small set of human-written principles for AI models to follow, and gu
    
[^4]: 从野外视频中学习手持物体重建

    Learning Hand-Held Object Reconstruction from In-The-Wild Videos. (arXiv:2305.03036v1 [cs.CV])

    [http://arxiv.org/abs/2305.03036](http://arxiv.org/abs/2305.03036)

    本研究提出了一种从野外视频中自动提取三维监督来扩展手持物体重建模型的学习方法。通过使用手部姿势作为物体姿势的代理和学习数据驱动的三维形状先验知识等方法，有效地解决了未知相机姿势和遮挡等问题，从而通过从单个RGB图像预测物体三维形状的占据网络得到了优秀的结果。

    

    先前的单影像手持物体重建方法依赖于难以在真实世界中规模化收集的直接3D形状监督，因此这些方法在野外环境下面对新颖物体时难以推广。本文从生动的野外原始视频数据中自动提取三维监督，并通过多视角二维监督来扩展手持物体重建模型的学习。这需要应对两个关键挑战：未知的相机姿势和遮挡。对于前者，我们使用手部姿势作为物体姿势的代理。对于后者，我们使用ObMan数据集中合成的物体来学习数据驱动的三维形状先验知识。我们使用这些间接的三维线索来训练占据网络，从单个RGB图像预测物体的三维形状。

    Prior works for reconstructing hand-held objects from a single image rely on direct 3D shape supervision which is challenging to gather in real world at scale. Consequently, these approaches do not generalize well when presented with novel objects in in-the-wild settings. While 3D supervision is a major bottleneck, there is an abundance of in-the-wild raw video data showing hand-object interactions. In this paper, we automatically extract 3D supervision (via multiview 2D supervision) from such raw video data to scale up the learning of models for hand-held object reconstruction. This requires tackling two key challenges: unknown camera pose and occlusion. For the former, we use hand pose (predicted from existing techniques, e.g. FrankMocap) as a proxy for object pose. For the latter, we learn data-driven 3D shape priors using synthetic objects from the ObMan dataset. We use these indirect 3D cues to train occupancy networks that predict the 3D shape of objects from a single RGB image. 
    
[^5]: 随机选择BPE合并操作会带来什么变化？不多。

    What changes when you randomly choose BPE merge operations? Not much. (arXiv:2305.03029v1 [cs.CL])

    [http://arxiv.org/abs/2305.03029](http://arxiv.org/abs/2305.03029)

    本文提出了三个随机BPE变体，在翻译到形态丰富的语言时，随机选择合并操作对下游机器翻译任务影响很小。标准BPE虽然被广泛使用，但存在着有趣的潜在变化宇宙值得探究。

    

    我们介绍了三个简单的随机BPE变体，并探讨了随机选择合并操作是否会对下游机器翻译任务产生实质性影响。我们着重翻译到形态丰富的语言，假设这个任务可能对选择子词的方法表现出敏感性。使用贝叶斯线性模型进行分析表明，其中两个变体与标准BPE相比表现几乎无法区分，而另一个变体的性能下降程度比我们预期的要小。我们得出结论，尽管标准BPE被广泛使用，但存在一个有趣的潜在变化宇宙值得探究。我们的代码可在以下网址找到：https://github.com/bltlab/random-bpe。

    We introduce three simple randomized variants of byte pair encoding (BPE) and explore whether randomizing the selection of merge operations substantially affects a downstream machine translation task. We focus on translation into morphologically rich languages, hypothesizing that this task may show sensitivity to the method of choosing subwords. Analysis using a Bayesian linear model indicates that two of the variants perform nearly indistinguishably compared to standard BPE while the other degrades performance less than we anticipated. We conclude that although standard BPE is widely used, there exists an interesting universe of potential variations on it worth investigating. Our code is available at: https://github.com/bltlab/random-bpe.
    
[^6]: Panda LLM：训练数据和评估针对开源汉语指令跟随大语言模型的性能

    Panda LLM: Training Data and Evaluation for Open-Sourced Chinese Instruction-Following Large Language Models. (arXiv:2305.03025v1 [cs.CL])

    [http://arxiv.org/abs/2305.03025](http://arxiv.org/abs/2305.03025)

    该项目研究了如何通过指令调整来提升开源大型语言模型的性能，探讨了训练数据的因素对指令调整模型性能的影响，并通过量化分析来为聊天模型的持续发展提供有价值的洞察力。

    

    该项目着重于通过指令调整来增强开源大型语言模型，并对其性能进行全面评估。我们探讨了各种训练数据因素，如数量、质量和语言分布，对在公开高质量指令数据集上训练的中英双语指令调整模型性能的影响。我们的目标是通过定量分析来补充评估，为开源聊天模型的持续发展提供有价值的洞察力。我们的模型、数据和代码都是公开的，供其他人使用和建立。

    This project focuses on enhancing open-source large language models through instruction-tuning and providing comprehensive evaluations of their performance. We explore how various training data factors, such as quantity, quality, and linguistic distribution, influence the performance of instruction-tuned models trained on publicly accessible high-quality instruction datasets for both English and Chinese languages. Our goal is to supplement evaluation with quantitative analyses, providing valuable insights for the continued advancement of open-source chat models. Our model, data, and code are publicly available for others to use and build upon.
    
[^7]: FastAMI -- 一种蒙特卡罗方法用于聚类比较度量中的偶然性调整

    FastAMI -- a Monte Carlo Approach to the Adjustment for Chance in Clustering Comparison Metrics. (arXiv:2305.03022v1 [cs.LG])

    [http://arxiv.org/abs/2305.03022](http://arxiv.org/abs/2305.03022)

    FastAMI是一种用于大型数据集的聚类比较的快速方法，通过蒙特卡罗模拟来实现偶然性调整，相比于传统的基于排列的方法更准确。

    

    聚类是机器学习的核心，随着数据可用性的增加，其应用日益增多。然而，随着数据集的增长，带有偶然性调整的聚类比较变得计算困难，导致没有偏见的真实比较和解决方案选择。我们提出了FastAMI，一种基于蒙特卡罗的方法，用于高效地估计经过调整的互信息（AMI）并将其扩展到标准化互信息（SMI）。与准确计算相比，我们的方法足够快，可以为大型数据集启用这些带有调整的信息论比较，同时保持比配对方法更准确的结果。

    Clustering is at the very core of machine learning, and its applications proliferate with the increasing availability of data. However, as datasets grow, comparing clusterings with an adjustment for chance becomes computationally difficult, preventing unbiased ground-truth comparisons and solution selection. We propose FastAMI, a Monte Carlo-based method to efficiently approximate the Adjusted Mutual Information (AMI) and extend it to the Standardized Mutual Information (SMI). The approach is compared with the exact calculation and a recently developed variant of the AMI based on pairwise permutations, using both synthetic and real data. In contrast to the exact calculation our method is fast enough to enable these adjusted information-theoretic comparisons for large datasets while maintaining considerably more accurate results than the pairwise approach.
    
[^8]: 使用BERT和Query-Aware LSH提高非正式文档中代码示例推荐：一项比较研究

    Improving Code Example Recommendations on Informal Documentation Using BERT and Query-Aware LSH: A Comparative Study. (arXiv:2305.03017v1 [cs.SE])

    [http://arxiv.org/abs/2305.03017](http://arxiv.org/abs/2305.03017)

    本研究使用BERT和Query-Aware LSH提高非正式文档中代码示例推荐的质量，重点关注于Stack Overflow上的Java编程语言。研究使用BERT将代码示例转换为数值向量。

    

    过去和最近一直在进行代码示例推荐的研究，以帮助开发人员完成软件开发任务。由于开发人员经常花费大量时间在互联网上寻找相关的代码示例，利用开源项目和非正式文档。为了找到有用的代码示例，非正式文档（如Stack Overflow讨论和论坛）可以非常宝贵。我们的研究重点是Stack Overflow，它是软件开发人员讨论不同主题的流行资源。为了提高推荐代码示例的质量，我们收集并推荐了Java编程语言中最佳的代码示例。我们采用了BERT来进行处理，它是一个大型语言模型（LLM），可以有效地从文本数据中提取语义信息。我们的第一步是使用BERT将代码示例转换为数值向量。

    The study of code example recommendation has been conducted extensively in the past and recently in order to assist developers in their software development tasks. This is because developers often spend significant time searching for relevant code examples on the internet, utilizing open-source projects and informal documentation. For finding useful code examples, informal documentation, such as Stack Overflow discussions and forums, can be invaluable. We have focused our research on Stack Overflow, which is a popular resource for discussing different topics among software developers. For increasing the quality of the recommended code examples, we have collected and recommended the best code examples in the Java programming language. We have utilized BERT in our approach, which is a Large Language Model (LLM) for text representation that can effectively extract semantic information from textual data. Our first step involved using BERT to convert code examples into numerical vectors. Su
    
[^9]: 通过内在的可解释性评估后续解释性

    Evaluating Post-hoc Interpretability with Intrinsic Interpretability. (arXiv:2305.03002v1 [cs.CV])

    [http://arxiv.org/abs/2305.03002](http://arxiv.org/abs/2305.03002)

    本文通过改进内部可解释性 ProtoPNet 方法，并将其生成的指向性图与后续方法生成的显著性图进行比较，以解决现有解释性方法间存在的差异，为卷积神经网络在组织病理学图像领域的临床应用提供了可行方案。

    

    虽然卷积神经网络在某些医学任务中达到了人类水平的性能，但它们的临床应用受到了可解释性的限制。为解决这个问题，提出了两种主要的解释性策略：后续方法和内在方法。本文将内部可解释性 ProtoPNet 进行改进，适用于组织病理学图像的背景，并将其生成的指向性图与后续方法生成的显著性图进行比较。同时，为了评估显著性图方法和指向性图之间的相似性，本文从显著性模型文献中选取了10个显著性度量指标，并使用包含327,680个组织病理学图像补丁的乳腺癌转移检测数据集 PatchCamelyon 进行评估。

    Despite Convolutional Neural Networks having reached human-level performance in some medical tasks, their clinical use has been hindered by their lack of interpretability. Two major interpretability strategies have been proposed to tackle this problem: post-hoc methods and intrinsic methods. Although there are several post-hoc methods to interpret DL models, there is significant variation between the explanations provided by each method, and it a difficult to validate them due to the lack of ground-truth. To address this challenge, we adapted the intrinsical interpretable ProtoPNet for the context of histopathology imaging and compared the attribution maps produced by it and the saliency maps made by post-hoc methods. To evaluate the similarity between saliency map methods and attribution maps we adapted 10 saliency metrics from the saliency model literature, and used the breast cancer metastases detection dataset PatchCamelyon with 327,680 patches of histopathological images of sentin
    
[^10]: 神经网络何时在表格数据上胜过增强树？

    When Do Neural Nets Outperform Boosted Trees on Tabular Data?. (arXiv:2305.02997v1 [cs.LG])

    [http://arxiv.org/abs/2305.02997](http://arxiv.org/abs/2305.02997)

    这项研究通过对176个数据集的比较分析发现，在许多数据集中，GBDT和NN之间的性能差异可以忽略不计，或者GBDT的轻微超参数调整比选择最佳算法更重要。此外，研究人员对965个元特征进行了分析，发现GBDT在高维稀疏数据上表现更好。

    

    表格数据是机器学习中最常用的数据类型之一。尽管神经网络（NN）在表格数据上取得了最近的进展，但人们仍在积极讨论NN是否通常优于梯度提升决策树（GBDT）在表格数据上的表现，一些最近的工作要么认为GBDT在表格数据上一贯优于NN，要么认为NN优于GBDT。在这项工作中，我们退一步问：'这重要吗？'我们通过对176个数据集比较19种算法，进行了迄今为止最大的表格数据分析，并发现'NN vs. GBDT'争论被过分强调：令人惊讶的是，在相当多的数据集中，GBDT和NN之间的性能差异要么可以忽略不计，要么GBDT的轻微超参数调整比选择最佳算法更重要。接下来，我们分析了965个元特征，以确定数据集的哪些特性使NN或GBDT更适合表现良好。例如，我们发现GBDT要比NN在高维稀疏数据上表现更好。

    Tabular data is one of the most commonly used types of data in machine learning. Despite recent advances in neural nets (NNs) for tabular data, there is still an active discussion on whether or not NNs generally outperform gradient-boosted decision trees (GBDTs) on tabular data, with several recent works arguing either that GBDTs consistently outperform NNs on tabular data, or vice versa. In this work, we take a step back and ask, 'does it matter?' We conduct the largest tabular data analysis to date, by comparing 19 algorithms across 176 datasets, and we find that the 'NN vs. GBDT' debate is overemphasized: for a surprisingly high number of datasets, either the performance difference between GBDTs and NNs is negligible, or light hyperparameter tuning on a GBDT is more important than selecting the best algorithm. Next, we analyze 965 metafeatures to determine what properties of a dataset make NNs or GBDTs better-suited to perform well. For example, we find that GBDTs are much better th
    
[^11]: 关于数据子群体间机器学习模型性能的非线性相关性

    On the nonlinear correlation of ML performance between data subpopulations. (arXiv:2305.02995v1 [cs.LG])

    [http://arxiv.org/abs/2305.02995](http://arxiv.org/abs/2305.02995)

    在不同数据子群体间，机器学习模型的内部准确性和外部准确性之间的相关性是非线性的，呈现出“月亮形”的相关性。

    

    理解机器学习模型在不同数据分布下的性能对于可靠的应用至关重要。尽管最新的经验研究认为训练数据内部的准确性和新数据外部的准确性之间存在近乎完美的线性相关性，但我们在各种数据集、模型和训练时期进行了严格的实验和分析，发现在子群体转移下，内部准确性和外部准确性之间的相关性更为微妙，并且在上升阶段存在“月亮形”的相关性（抛物线上升曲线）。

    Understanding the performance of machine learning (ML) models across diverse data distributions is critically important for reliable applications. Despite recent empirical studies positing a near-perfect linear correlation between in-distribution (ID) and out-of-distribution (OOD) accuracies, we empirically demonstrate that this correlation is more nuanced under subpopulation shifts. Through rigorous experimentation and analysis across a variety of datasets, models, and training epochs, we demonstrate that OOD performance often has a nonlinear correlation with ID performance in subpopulation shifts. Our findings, which contrast previous studies that have posited a linear correlation in model performance during distribution shifts, reveal a "moon shape" correlation (parabolic uptrend curve) between the test performance on the majority subpopulation and the minority subpopulation. This non-trivial nonlinear correlation holds across model architectures, hyperparameters, training durations
    
[^12]: SemEval-2023任务7: 临床试验数据的多证据自然语言推理

    SemEval-2023 Task 7: Multi-Evidence Natural Language Inference for Clinical Trial Data. (arXiv:2305.02993v1 [cs.CL])

    [http://arxiv.org/abs/2305.02993](http://arxiv.org/abs/2305.02993)

    本论文介绍SemEval 2023的任务七，旨在进行临床试验数据的多证据自然语言推理，该任务难度较大，证据选择任务相对于蕴含任务表现更佳。

    

    本篇论文介绍SemEval 2023任务7的结果，该任务主要涉及临床试验数据中的多证据自然语言推理（NLI4CT），由两个子任务组成：一个是自然语言推理（NLI）任务，另一个是证据选择任务。这两个任务需要进行医学和数字推理，这对于开发能够进行大规模医疗证据解释和检索、提供个性化基于证据的保健具有重要意义。第1个子任务“蕴含任务”收到了来自40位参赛者的643份提交，第2个子任务“证据选择任务”收到了来自23位参赛者的364份提交。这两个任务具有挑战性，大部分提交的系统在蕴含任务上未能明显优于大多数类基线，而我们观察到证据选择任务的表现明显优于蕴含任务。增加模型参数会导致模型在测试集上表现更差。

    This paper describes the results of SemEval 2023 task 7 -- Multi-Evidence Natural Language Inference for Clinical Trial Data (NLI4CT) -- consisting of 2 tasks, a Natural Language Inference (NLI) task, and an evidence selection task on clinical trial data. The proposed challenges require multi-hop biomedical and numerical reasoning, which are of significant importance to the development of systems capable of large-scale interpretation and retrieval of medical evidence, to provide personalized evidence-based care.  Task 1, the entailment task, received 643 submissions from 40 participants, and Task 2, the evidence selection task, received 364 submissions from 23 participants. The tasks are challenging, with the majority of submitted systems failing to significantly outperform the majority class baseline on the entailment task, and we observe significantly better performance on the evidence selection task than on the entailment task. Increasing the number of model parameters leads to a di
    
[^13]: ExeKGLib：基于知识图谱的机器学习分析库

    ExeKGLib: Knowledge Graphs-Empowered Machine Learning Analytics. (arXiv:2305.02966v1 [cs.LG])

    [http://arxiv.org/abs/2305.02966](http://arxiv.org/abs/2305.02966)

    ExeKGLib是一个基于知识图谱的Python机器学习库，可帮助不具备深入ML知识的用户构建可执行的ML工作流，并提高透明度和可重用性。

    

    许多机器学习（ML）库对ML从业者开放。典型的ML流程是复杂的，由一系列步骤组成，每个步骤都调用了几个ML库。在这篇论文中，我们介绍了ExeKGLib，这是一个Python库，允许具有编码技能和最小ML知识的用户构建ML流水线。ExeKGLib依赖于知识图谱，以改善构建的ML工作流的透明度和可重用性，并确保其可执行性。我们演示了ExeKGLib的用法，并将其与传统的ML代码进行比较，以展示其优势。

    Many machine learning (ML) libraries are accessible online for ML practitioners. Typical ML pipelines are complex and consist of a series of steps, each of them invoking several ML libraries. In this demo paper, we present ExeKGLib, a Python library that allows users with coding skills and minimal ML knowledge to build ML pipelines. ExeKGLib relies on knowledge graphs to improve the transparency and reusability of the built ML workflows, and to ensure that they are executable. We demonstrate the usage of ExeKGLib and compare it with conventional ML code to show its benefits.
    
[^14]: 受权重影响的计数赌博机: 通过重复暴露来克服不可解性

    Weighted Tallying Bandits: Overcoming Intractability via Repeated Exposure Optimality. (arXiv:2305.02955v1 [stat.ML])

    [http://arxiv.org/abs/2305.02955](http://arxiv.org/abs/2305.02955)

    该论文提出了一种受权重影响的计数赌博机(WTB)设置，通过Repeated Exposure Optimality(REO)来研究它。他们提出了一个算法来满足REO，并提供了最优的遗憾边界。

    

    在在线学习的推荐系统或众包应用中，人类的偏好或能力通常是算法最近行动的一个函数。 相关工作已经形式化了设置，在这些设置中，行动的损失是最近$m$个时间步中该行动的播放次数的函数，其中$m$对应于人类记忆能力的上限。 为了更忠实地反映人类记忆随时间的衰减，我们引入了受权重影响的计数赌博机(WTB)，它通过要求行动损失是最近$m$个时间步中该臂被玩的次数的加权总和的函数来概括这个设置。除非进一步假设，否则WTB设置是不可解的。因此，我们在Repeated Exposure Optimality(REO)下研究了它，该条件是受人体生理学文献的启发，它要求存在一种行动，当反复播放时，最终将产生比任何其他行动更小的损失。 我们提出了一种算法，满足WTB设置下的REO，并提供了最优地缩放$m$和行动集大小的遗憾边界。 我们的证明技术要求在一种解耦形式下进行新颖的浓度结果，这可能是独立感兴趣的。

    In recommender system or crowdsourcing applications of online learning, a human's preferences or abilities are often a function of the algorithm's recent actions. Motivated by this, a significant line of work has formalized settings where an action's loss is a function of the number of times that action was recently played in the prior $m$ timesteps, where $m$ corresponds to a bound on human memory capacity. To more faithfully capture decay of human memory with time, we introduce the Weighted Tallying Bandit (WTB), which generalizes this setting by requiring that an action's loss is a function of a \emph{weighted} summation of the number of times that arm was played in the last $m$ timesteps. This WTB setting is intractable without further assumption. So we study it under Repeated Exposure Optimality (REO), a condition motivated by the literature on human physiology, which requires the existence of an action that when repetitively played will eventually yield smaller loss than any othe
    
[^15]: 利用梯度衡量数据选择和估价在差分隐私训练中的应用

    Leveraging gradient-derived metrics for data selection and valuation in differentially private training. (arXiv:2305.02942v1 [cs.LG])

    [http://arxiv.org/abs/2305.02942](http://arxiv.org/abs/2305.02942)

    研究如何在隐私增强技术下，利用梯度信息识别训练中感兴趣的数据样本进行数据选择和估价。

    

    由于监管担忧和参与度的不足，为机器学习模型进行协作训练获取高质量数据可能是一项具有挑战性的任务。隐私增强技术（PET）是解决监管问题的一种常用方法，差分隐私（DP）训练是其中最常用的一种方法。本文研究了如何使用梯度信息来识别隐私训练中感兴趣的训练样本。我们展示了在最严格的隐私设置中，存在着能够为客户提供有原则的数据选择工具的技术。

    Obtaining high-quality data for collaborative training of machine learning models can be a challenging task due to A) the regulatory concerns and B) lack of incentive to participate. The first issue can be addressed through the use of privacy enhancing technologies (PET), one of the most frequently used one being differentially private (DP) training. The second challenge can be addressed by identifying which data points can be beneficial for model training and rewarding data owners for sharing this data. However, DP in deep learning typically adversely affects atypical (often informative) data samples, making it difficult to assess the usefulness of individual contributions. In this work we investigate how to leverage gradient information to identify training samples of interest in private training settings. We show that there exist techniques which are able to provide the clients with the tools for principled data selection even in strictest privacy settings.
    
[^16]: 自动发现的思维链提示可以推广到新模型和数据集

    An automatically discovered chain-of-thought prompt generalizes to novel models and datasets. (arXiv:2305.02897v1 [cs.CL])

    [http://arxiv.org/abs/2305.02897](http://arxiv.org/abs/2305.02897)

    本文研究了一系列零照顾提示在六个最新发布的语言模型和问题回答数据集的实验中的表现，发现自动提示发现的CoT提示可在新模型和数据集上表现良好，并在应用于GPT-4模型时取得最佳结果。

    

    新兴的思维链（CoT）推理能力有望提高大型语言模型（LLM）的性能和可解释性。然而，对于先前模型所制定的提示策略如何适用于新模型和不同数据集仍存在不确定性。在这项小型研究中，我们比较了一系列零照顾提示（zero-shot prompts）的性能，以诱导CoT推理，在6个最新发布的LLM（davinci-002，davinci-003，GPT-3.5-turbo，GPT-4，Flan-T5-xxl和Cohere command-xlarge）上与包括科学和医学领域的六个问答数据集混合在一起。我们发现，通过自动提示发现的CoT提示在实验条件下表现出鲁棒性，并在应用于最先进的GPT-4模型时产生最佳结果。

    Emergent chain-of-thought (CoT) reasoning capabilities promise to improve performance and explainability of large language models (LLMs). However, uncertainties remain about how prompting strategies formulated for previous model generations generalize to new model generations and different datasets. In this small-scale study we compare the performance of a range of zero-shot prompts for inducing CoT reasoning across six recently released LLMs (davinci-002, davinci-003, GPT-3.5-turbo, GPT-4, Flan-T5-xxl and Cohere command-xlarge) on a mixture of six question-answering datasets, including datasets from scientific and medical domains. We find that a CoT prompt that was previously discovered through automated prompt discovery shows robust performance across experimental conditions and produces best results when applied to the state-of-the-art model GPT-4.
    
[^17]: 简单的嘈杂环境增强用于强化学习

    Simple Noisy Environment Augmentation for Reinforcement Learning. (arXiv:2305.02882v1 [cs.LG])

    [http://arxiv.org/abs/2305.02882](http://arxiv.org/abs/2305.02882)

    本论文探讨了一系列通用封装，用于噪声增强RL环境，提供了两种新的增强技术，有助于代理人探索和改善训练数据多样性。同时，介绍了控制噪声注入频率的超参数噪声率。在实验中使用了三种流行的RL算法，Soft Actor-Critic（SAC），Twin Delayed DDPG（TD3）和Proximal Policy，以研究这些封装对回报的影响。

    

    数据增强是提升机器学习模型性能的一种广泛应用的技术，尤其是在计算机视觉和自然语言处理方面。最近，越来越多的人开始应用增强技术来解决强化学习（RL）问题，主要专注于基于图像的增强。本文旨在探讨一系列通用封装，设计用于噪声增强RL环境，并鼓励代理人探索和改善训练数据多样性，适用于广泛的RL算法和环境。具体而言，我们集中于涉及状态、奖励和转换动态的增强，并介绍了两种新的增强技术。此外，我们引入噪声率超参数，以控制噪声注入的频率。我们使用三种流行的RL算法，Soft Actor-Critic（SAC），Twin Delayed DDPG（TD3）和Proximal Policy进行实验，研究这些封装对回报的影响。

    Data augmentation is a widely used technique for improving model performance in machine learning, particularly in computer vision and natural language processing. Recently, there has been increasing interest in applying augmentation techniques to reinforcement learning (RL) problems, with a focus on image-based augmentation. In this paper, we explore a set of generic wrappers designed to augment RL environments with noise and encourage agent exploration and improve training data diversity which are applicable to a broad spectrum of RL algorithms and environments. Specifically, we concentrate on augmentations concerning states, rewards, and transition dynamics and introduce two novel augmentation techniques. In addition, we introduce a noise rate hyperparameter for control over the frequency of noise injection. We present experimental results on the impact of these wrappers on return using three popular RL algorithms, Soft Actor-Critic (SAC), Twin Delayed DDPG (TD3), and Proximal Policy
    
[^18]: 人工智能代际差距：与X世代和千禧一代相比，GenZ学生更愿意采用生成式人工智能(如ChatGPT)在教学中吗？

    The AI generation gap: Are Gen Z students more interested in adopting generative AI such as ChatGPT in teaching and learning than their Gen X and Millennial Generation teachers?. (arXiv:2305.02878v1 [cs.CY])

    [http://arxiv.org/abs/2305.02878](http://arxiv.org/abs/2305.02878)

    研究探讨了GenZ学生和X世代、千禧一代教师在高等教育中使用生成式人工智能（GenAI）的体验和态度。结果显示，GenZ学生普遍看好GenAI的潜在好处，而教师则更关注其在伦理和教学上的影响。

    

    本研究旨在探索GenZ学生与X世代和千禧一代教师在使用生成式人工智能（GenAI）在高等教育中的经验、看法、知识、担忧和意图。通过招募一定数量的学生和教师来进行调查，使用包括开放式和封闭式问题的调查问卷。研究结果表明，GenZ参与者普遍乐观地看待GenAI的潜在益处，包括提高生产力、效率和个性化学习，并表达了在各种教育目的中使用GenAI的意向。X世代和千禧一代教师承认GenAI的潜在好处，但对其过度依赖、伦理和教学影响表示长期关注，强调需要适当的指南和政策来确保技术的负责使用。该研究突出了结合传统教学方法和技术，以提供更加有效的学习体验的重要性。

    This study aimed to explore the experiences, perceptions, knowledge, concerns, and intentions of Gen Z students with Gen X and Gen Y teachers regarding the use of generative AI (GenAI) in higher education. A sample of students and teachers were recruited to investigate the above using a survey consisting of both open and closed questions. The findings showed that Gen Z participants were generally optimistic about the potential benefits of GenAI, including enhanced productivity, efficiency, and personalized learning, and expressed intentions to use GenAI for various educational purposes. Gen X and Gen Y teachers acknowledged the potential benefits of GenAI but expressed heightened concerns about overreliance, ethical and pedagogical implications, emphasizing the need for proper guidelines and policies to ensure responsible use of the technology. The study highlighted the importance of combining technology with traditional teaching methods to provide a more effective learning experience.
    
[^19]: 分层Transformer用于可扩展图学习

    Hierarchical Transformer for Scalable Graph Learning. (arXiv:2305.02866v1 [cs.LG])

    [http://arxiv.org/abs/2305.02866](http://arxiv.org/abs/2305.02866)

    本文提出了分层可扩展图Transformer (HSGT)用于解决图表示学习中的规模问题和上下文信息捕获不足问题，通过构建多尺度图分层结构，HSGT实现了对大型图的快速和内存高效处理，并在基准数据集上展现了卓越的性能表现。

    

    图Transformer在机器学习领域中越来越受到关注，并在图表示学习的基准测试中展现出了最先进的性能。然而，由于当前实现的图Transformer主要集中在学习小规模图的表示上，全局自注意机制的二次复杂度对于应用于较大规模图的全批量训练构成了挑战。此外，传统的基于采样的方法无法捕捉必要的高层次上下文信息，导致性能严重下降。在本文中，我们引入了分层可扩展图Transformer (HSGT)作为这些挑战的解决方案。HSGT成功地将Transformer架构扩展到大规模图上的节点表示学习任务中，同时保持高性能。通过利用通过粗化技术构建的图分层结构，HSGT有效地更新和存储多尺度信息，从而实现对大型图的快速和内存高效处理。我们在几个基准数据集上评估了HSGT，并展示了它相对于现有方法的卓越性能。

    Graph Transformer is gaining increasing attention in the field of machine learning and has demonstrated state-of-the-art performance on benchmarks for graph representation learning. However, as current implementations of Graph Transformer primarily focus on learning representations of small-scale graphs, the quadratic complexity of the global self-attention mechanism presents a challenge for full-batch training when applied to larger graphs. Additionally, conventional sampling-based methods fail to capture necessary high-level contextual information, resulting in a significant loss of performance. In this paper, we introduce the Hierarchical Scalable Graph Transformer (HSGT) as a solution to these challenges. HSGT successfully scales the Transformer architecture to node representation learning tasks on large-scale graphs, while maintaining high performance. By utilizing graph hierarchies constructed through coarsening techniques, HSGT efficiently updates and stores multi-scale informat
    
[^20]: CausalAPM: 用于NLU去偏置的通用文本解缠框架

    CausalAPM: Generalizable Literal Disentanglement for NLU Debiasing. (arXiv:2305.02865v1 [cs.CL])

    [http://arxiv.org/abs/2305.02865](http://arxiv.org/abs/2305.02865)

    CausalAPM是一个通用的NLU文本解缠框架，它将文字和语义信息投射到独立的特征子空间中，并限制了文字信息在后续预测中的参与程度。该框架可以有效地应对数据集偏置问题，提高了推广性能而不损失性能水平。

    

    数据集偏置问题越来越引起人们对NLU模型推广能力的关注。本文从因果推断的角度分析了数据集偏置问题的原因，提出了CausalAPM，一种通用的文本解缠框架来解决偏置问题。该方法将文字和语义信息投射到独立的特征子空间中，并限制了文字信息在后续预测中的参与程度。在三个NLP基准测试中广泛的实验表明，我们的框架显著提高了OOD的推广性能，同时保持了ID的性能水平。

    Dataset bias, i.e., the over-reliance on dataset-specific literal heuristics, is getting increasing attention for its detrimental effect on the generalization ability of NLU models. Existing works focus on eliminating dataset bias by down-weighting problematic data in the training process, which induce the omission of valid feature information while mitigating bias. In this work, We analyze the causes of dataset bias from the perspective of causal inference and propose CausalAPM, a generalizable literal disentangling framework to ameliorate the bias problem from feature granularity. The proposed approach projects literal and semantic information into independent feature subspaces, and constrains the involvement of literal information in subsequent predictions. Extensive experiments on three NLP benchmarks (MNLI, FEVER, and QQP) demonstrate that our proposed framework significantly improves the OOD generalization performance while maintaining ID performance.
    
[^21]: ReMask：一种针对领域反事实生成的稳健信息遮盖方法

    ReMask: A Robust Information-Masking Approach for Domain Counterfactual Generation. (arXiv:2305.02858v1 [cs.CL])

    [http://arxiv.org/abs/2305.02858](http://arxiv.org/abs/2305.02858)

    本文提出一种三步领域混淆方法，包括基于频率和注意力规范的遮盖、遮盖领域特定提示信息，以及揭示领域通用上下文。实验证明这种方法在领域转移方面有较好效果。

    

    领域偏移是NLP中的一个重大挑战，因此许多方法采用学习领域不变特征来减轻推理阶段的领域偏移。然而，这种方法无法利用与任务相关的领域特定细微差别。为避免这种缺点，领域反事实生成旨在将源域中的文本转换为给定的目标域。然而，由于数据的有限性，这种基于频率的方法经常会错过一些有效和虚假的领域标记关联。因此，我们采用了一种三步领域混淆方法，其中包括基于频率和注意力规范的遮盖、遮盖领域特定提示信息，以及揭示领域通用上下文。我们的实验实证表明，来自我们遮盖文本的反事实样本在12个领域情感分类设置中有10个实现了改进的领域转移，相对于最先进技术平均提高了2%的准确率。

    Domain shift is a big challenge in NLP, thus, many approaches resort to learning domain-invariant features to mitigate the inference phase domain shift. Such methods, however, fail to leverage the domain-specific nuances relevant to the task at hand. To avoid such drawbacks, domain counterfactual generation aims to transform a text from the source domain to a given target domain. However, due to the limited availability of data, such frequency-based methods often miss and lead to some valid and spurious domain-token associations. Hence, we employ a three-step domain obfuscation approach that involves frequency and attention norm-based masking, to mask domain-specific cues, and unmasking to regain the domain generic context. Our experiments empirically show that the counterfactual samples sourced from our masked text lead to improved domain transfer on 10 out of 12 domain sentiment classification settings, with an average of 2% accuracy improvement over the state-of-the-art for unsuperv
    
[^22]: 最大因果熵逆约束强化学习

    Maximum Causal Entropy Inverse Constrained Reinforcement Learning. (arXiv:2305.02857v1 [cs.LG])

    [http://arxiv.org/abs/2305.02857](http://arxiv.org/abs/2305.02857)

    该论文提出了一种新颖的最大因果熵逆约束强化学习方法，通过利用最大因果熵原理来学习代理遵守限制的约束条件和最优策略，使用遵守这些限制的代理的实例进行学习。此方法已被证明在各种任务和环境中优于最先进的方法。

    

    在实际环境中，当人们与人工智能代理进行交互时，代理的行为与该环境的价值观、社会规范或其他要求相一致至关重要。然而，许多环境都有难以规定和转移给学习代理的隐含限制。为了应对这一挑战，我们提出了一种新的方法，利用最大因果熵原理来学习代理遵守限制的约束条件和最优策略，并使用遵守这些限制的代理的实例进行学习。我们在表格设置中证明了收敛性，并提供了一种适用于复杂环境的近似方法。我们通过评估所获得的奖励和违反约束的次数来评估学习到的策略的有效性，并根据其对其他代理的可转移性来评估学习到的成本函数。我们的方法已被证明在各种任务和环境中优于最先进的方法。

    When deploying artificial agents in real-world environments where they interact with humans, it is crucial that their behavior is aligned with the values, social norms or other requirements of that environment. However, many environments have implicit constraints that are difficult to specify and transfer to a learning agent. To address this challenge, we propose a novel method that utilizes the principle of maximum causal entropy to learn constraints and an optimal policy that adheres to these constraints, using demonstrations of agents that abide by the constraints. We prove convergence in a tabular setting and provide an approximation which scales to complex environments. We evaluate the effectiveness of the learned policy by assessing the reward received and the number of constraint violations, and we evaluate the learned cost function based on its transferability to other agents. Our method has been shown to outperform state-of-the-art approaches across a variety of tasks and envi
    
[^23]: 噪声抑制的多模态变压器用于情感识别

    Noise-Resistant Multimodal Transformer for Emotion Recognition. (arXiv:2305.02814v1 [cs.MM])

    [http://arxiv.org/abs/2305.02814](http://arxiv.org/abs/2305.02814)

    本论文提出了一种名为噪声抑制的多模态变压器 (NORM.TR)的方法，通过NRGF提取器和变压器来提高多模态情感识别任务的鲁棒性, 试图在其流程中提取噪声抑制特征并引入噪声感知学习方案。实验结果表明，NORM-TR具有优越的性能。

    

    多模态情感识别可以从各种数据模态(如视频、文本和音频)中识别人类的情感。然而，我们发现这项任务很容易受到不包含有用语义的噪声信息的影响。为此，我们提出了一种新的范例，试图在其流程中提取噪声抑制特征并引入噪声感知学习方案，以有效提高多模态情感理解的鲁棒性。我们的新流程，即噪声抑制的多模态变压器(NORM-TR)，主要介绍了一个噪声抑制通用特征(NRGF)提取器和用于多模态情感识别任务的变压器。尤其是，我们使NRGF提取器学习通用和不受扰动的表示形式，以便获得一致且有意义的语义。此外，我们应用变压器来结合多模态输入的多模态特征(MFs)，基于它们与NRGF之间的关系。因此，可能的不敏感部分可以自然地被抑制，进而提高模型在嘈杂数据上的性能。我们的实验表明，所提出的NORM-TR在各种实际的多模态情感识别基准上都具有优越的性能，表明我们的噪声抑制方法的有效性。

    Multimodal emotion recognition identifies human emotions from various data modalities like video, text, and audio. However, we found that this task can be easily affected by noisy information that does not contain useful semantics. To this end, we present a novel paradigm that attempts to extract noise-resistant features in its pipeline and introduces a noise-aware learning scheme to effectively improve the robustness of multimodal emotion understanding. Our new pipeline, namely Noise-Resistant Multimodal Transformer (NORM-TR), mainly introduces a Noise-Resistant Generic Feature (NRGF) extractor and a Transformer for the multimodal emotion recognition task. In particular, we make the NRGF extractor learn a generic and disturbance-insensitive representation so that consistent and meaningful semantics can be obtained. Furthermore, we apply a Transformer to incorporate Multimodal Features (MFs) of multimodal inputs based on their relations to the NRGF. Therefore, the possible insensitive 
    
[^24]: 基于Transformer的多任务学习在农业精细化中的应用

    MTLSegFormer: Multi-task Learning with Transformers for Semantic Segmentation in Precision Agriculture. (arXiv:2305.02813v1 [cs.CV])

    [http://arxiv.org/abs/2305.02813](http://arxiv.org/abs/2305.02813)

    提出了一种基于Transformer和注意机制的语义分割方法MTLSegFormer，在精细化农业领域中的作物排查和作物分类任务中表现优于现有最新方法。

    

    多任务学习已被证明在提高相关任务的性能方面非常有效。大多数现有的方法使用主干网提取独立任务的初始特征，并通过将分支的特征图连接或求和来实现分支之间的信息交换。然而，这种信息交换并没有直接考虑图像的局部特征以及任务间的重要程度或相关性。本文提出了一种语义分割方法MTLSegFormer，它结合了多任务学习和注意机制。在主干网特征提取后，为每个任务学习两个特征图。第一个特征图旨在学习与其任务相关的特征，而第二个特征图是通过应用学习到的视觉注意力来对其他任务的特征图进行局部加权得到的。通过这种方式，为其他任务的图像局部区域分配了权重，显着提高了每个任务的分割性能。我们在精细化农业领域中评估了我们的方法，包括两个任务：作物排查和作物分类。实验结果表明，我们提出的方法在两个任务中均优于现有的最新方法。

    Multi-task learning has proven to be effective in improving the performance of correlated tasks. Most of the existing methods use a backbone to extract initial features with independent branches for each task, and the exchange of information between the branches usually occurs through the concatenation or sum of the feature maps of the branches. However, this type of information exchange does not directly consider the local characteristics of the image nor the level of importance or correlation between the tasks. In this paper, we propose a semantic segmentation method, MTLSegFormer, which combines multi-task learning and attention mechanisms. After the backbone feature extraction, two feature maps are learned for each task. The first map is proposed to learn features related to its task, while the second map is obtained by applying learned visual attention to locally re-weigh the feature maps of the other tasks. In this way, weights are assigned to local regions of the image of other 
    
[^25]: 在存在偏见的情况下，最大化子模函数用于推荐系统

    Maximizing Submodular Functions for Recommendation in the Presence of Biases. (arXiv:2305.02806v1 [cs.LG])

    [http://arxiv.org/abs/2305.02806](http://arxiv.org/abs/2305.02806)

    该论文研究了如何在存在偏见的情况下，通过最大化子模函数来优化推荐系统。先前研究指出，基于公平性约束的干预可以确保比例代表性，并在存在偏见时获得接近最优的效用。而本文则探讨了一组能够捕捉这种目的的子模函数。

    

    子集选择任务在推荐系统和搜索引擎中经常出现，要求选择一些最大化用户价值的物品子集。子集的价值往往呈现出递减的回报，因此，使用子模函数来建模。然而，在许多应用中，发现输入具有社会偏见，会降低输出子集的效用，因此需要干预以提高其效用。本文研究了一组子模函数的最大化，这些函数涵盖了上述应用中出现的函数。

    Subset selection tasks, arise in recommendation systems and search engines and ask to select a subset of items that maximize the value for the user. The values of subsets often display diminishing returns, and hence, submodular functions have been used to model them. If the inputs defining the submodular function are known, then existing algorithms can be used. In many applications, however, inputs have been observed to have social biases that reduce the utility of the output subset. Hence, interventions to improve the utility are desired. Prior works focus on maximizing linear functions -- a special case of submodular functions -- and show that fairness constraint-based interventions can not only ensure proportional representation but also achieve near-optimal utility in the presence of biases. We study the maximization of a family of submodular functions that capture functions arising in the aforementioned applications. Our first result is that, unlike linear functions, constraint-ba
    
[^26]: 本地最优解相关性辅助自适应算子选择

    Local Optima Correlation Assisted Adaptive Operator Selection. (arXiv:2305.02805v1 [cs.AI])

    [http://arxiv.org/abs/2305.02805](http://arxiv.org/abs/2305.02805)

    本研究提出了一种根据局部最优解相关性的算子关系分析和度量方法，并根据这个方法提出了一种自适应算子选择的新方法。

    

    在使用元启发式算法解决组合优化问题时，不同的搜索算子被应用于在给定解的邻域中采样新解。了解算子之间的关系对于各种目的都很重要，例如适应性地决定何时使用哪个算子以有效地找到最优解。然而，在组合优化问题的复杂解空间中，理论分析这种关系是困难的。在本文中，我们提出了根据局部最优解之间的相关性来经验分析算子之间关系并度量其关系的方法。在广泛的带有容量限制的车辆路径问题基准实例上进行的全面分析表明，常用算子之间的相关性具有一致的模式。基于新提出的局部最优解相关度量，我们提出了一种自适应算子选择的新方法。

    For solving combinatorial optimisation problems with metaheuristics, different search operators are applied for sampling new solutions in the neighbourhood of a given solution. It is important to understand the relationship between operators for various purposes, e.g., adaptively deciding when to use which operator to find optimal solutions efficiently. However, it is difficult to theoretically analyse this relationship, especially in the complex solution space of combinatorial optimisation problems. In this paper, we propose to empirically analyse the relationship between operators in terms of the correlation between their local optima and develop a measure for quantifying their relationship. The comprehensive analyses on a wide range of capacitated vehicle routing problem benchmark instances show that there is a consistent pattern in the correlation between commonly used operators. Based on this newly proposed local optima correlation metric, we propose a novel approach for adaptivel
    
[^27]: 大语言模型在信息技术任务中自动生成YAML代码

    Automated Code generation for Information Technology Tasks in YAML through Large Language Models. (arXiv:2305.02783v1 [cs.SE])

    [http://arxiv.org/abs/2305.02783](http://arxiv.org/abs/2305.02783)

    这项研究提出了一种名为Ansible Wisdom的自然语言转Ansible-YAML代码的工具，可自动化生成Ansible脚本，提高IT自动化生产力，并相比现有技术达到或更好的性能水平。

    

    由于大语言模型在代码生成方面的不断提升，在通用编程语言方面的受益最大，而针对IT自动化等领域特定语言的研究较少。本研究聚焦于Ansible-YAML的生成，提出了一种名为Ansible Wisdom的自然语言转Ansible-YAML代码的工具，旨在提高IT自动化生产力。研究采用基于Transformer的模型，并通过新的包含Ansible-YAML的数据集进行扩展训练。同时，还开发了两个用于捕捉此领域特征的YAML和Ansible性能指标。结果表明，Ansible Wisdom可以精确地从自然语言提示中生成Ansible脚本，并且其性能可与现有技术的状态相媲美或更好。

    The recent improvement in code generation capabilities due to the use of large language models has mainly benefited general purpose programming languages. Domain specific languages, such as the ones used for IT Automation, have received far less attention, despite involving many active developers and being an essential component of modern cloud platforms. This work focuses on the generation of Ansible-YAML, a widely used markup language for IT Automation. We present Ansible Wisdom, a natural-language to Ansible-YAML code generation tool, aimed at improving IT automation productivity. Ansible Wisdom is a transformer-based model, extended by training with a new dataset containing Ansible-YAML. We also develop two novel performance metrics for YAML and Ansible to capture the specific characteristics of this domain. Results show that Ansible Wisdom can accurately generate Ansible script from natural language prompts with performance comparable or better than existing state of the art code 
    
[^28]: 各种神经机器翻译的统一模型学习

    Unified Model Learning for Various Neural Machine Translation. (arXiv:2305.02777v1 [cs.CL])

    [http://arxiv.org/abs/2305.02777](http://arxiv.org/abs/2305.02777)

    本文提出了一种统一学习方法，即统一模型学习，可以同时适用于翻译各种任务数据，并实现智能按需翻译，相对现有的特定数据集模型能够得到明显的改进。

    

    现有的神经机器翻译(NMT)研究主要集中在根据来自不同任务(例如，文档翻译和聊天翻译)的数据开发特定于数据集的模型。虽然特定于数据集的模型已经取得了令人瞩目的性能，但每个数据集需要设计、训练和存储一个模型，这很麻烦。在这项工作中，我们的目标是将这些翻译任务统一到更普遍的设置中。具体而言，我们提出了一个“多才多艺”的模型，即适用于不同任务数据的统一模型学习(NMT)，可以同时在多种环境下进行良好的翻译，并在理论上可以尽可能多地扩展。通过统一学习，UMLNMT能够跨多个任务进行联合训练，实现智能按需翻译。在七个广泛使用的翻译任务，包括句子翻译、文档翻译和聊天翻译中，我们的UMLNMT相对于特定数据集模型表现出了明显的改进。

    Existing neural machine translation (NMT) studies mainly focus on developing dataset-specific models based on data from different tasks (e.g., document translation and chat translation). Although the dataset-specific models have achieved impressive performance, it is cumbersome as each dataset demands a model to be designed, trained, and stored. In this work, we aim to unify these translation tasks into a more general setting. Specifically, we propose a ``versatile'' model, i.e., the Unified Model Learning for NMT (UMLNMT) that works with data from different tasks, and can translate well in multiple settings simultaneously, and theoretically it can be as many as possible. Through unified learning, UMLNMT is able to jointly train across multiple tasks, implementing intelligent on-demand translation. On seven widely-used translation tasks, including sentence translation, document translation, and chat translation, our UMLNMT results in substantial improvements over dataset-specific model
    
[^29]: 主动对话系统综述：问题、方法和展望

    A Survey on Proactive Dialogue Systems: Problems, Methods, and Prospects. (arXiv:2305.02750v1 [cs.CL])

    [http://arxiv.org/abs/2305.02750](http://arxiv.org/abs/2305.02750)

    本综述全面概述了不同类型对话中对话代理主动性的突出问题和先进设计，讨论了符合实际应用需求但需要未来更大研究重点的挑战，激发更多的会话 AI 进展到下一级别。

    

    主动对话系统与广泛的现实世界对话应用相关，使对话代理能够引导对话方向，以实现预定义的目标或满足系统方面的特定目标。它通过先进技术赋能以进展到需要战略性和激励性交互的更复杂任务。在本综述中，我们全面概述了不同类型对话中对话代理主动性的突出问题和先进设计。此外，我们还讨论了符合实际应用需求但需要未来更大研究重点的挑战。我们希望这篇主动对话系统的第一篇综述可以为社区提供快速访问和整体图片，激发更多的会话 AI 进展到下一级别。

    Proactive dialogue systems, related to a wide range of real-world conversational applications, equip the conversational agent with the capability of leading the conversation direction towards achieving pre-defined targets or fulfilling certain goals from the system side. It is empowered by advanced techniques to progress to more complicated tasks that require strategical and motivational interactions. In this survey, we provide a comprehensive overview of the prominent problems and advanced designs for conversational agent's proactivity in different types of dialogues. Furthermore, we discuss challenges that meet the real-world application needs but require a greater research focus in the future. We hope that this first survey of proactive dialogue systems can provide the community with a quick access and an overall picture to this practical problem, and stimulate more progresses on conversational AI to the next level.
    
[^30]: 人类价值观的计算框架对于道德人工智能的应用

    A computational framework of human values for ethical AI. (arXiv:2305.02748v1 [cs.AI])

    [http://arxiv.org/abs/2305.02748](http://arxiv.org/abs/2305.02748)

    该论文提出了一个根据社会科学理论建立的计算框架，为研究人类价值观如何支持设计道德人工智能提供了基础。

    

    从心理学、哲学和社会科学的多元化探索中，可以得出一个明确的共识，那就是价值观指导着行为。最近，人们认识到，价值观为工程化道德人工智能提供了一种方式。我们基于社会科学的正式概念框架，提出了对于人类价值观的计算形式定义，为系统、综合和跨学科地研究人类价值观如何支持设计道德人工智能提供了基础。

    In the diverse array of work investigating the nature of human values from psychology, philosophy and social sciences, there is a clear consensus that values guide behaviour. More recently, a recognition that values provide a means to engineer ethical AI has emerged. Indeed, Stuart Russell proposed shifting AI's focus away from simply ``intelligence'' towards intelligence ``provably aligned with human values''. This challenge -- the value alignment problem -- with others including an AI's learning of human values, aggregating individual values to groups, and designing computational mechanisms to reason over values, has energised a sustained research effort. Despite this, no formal, computational definition of values has yet been proposed. We address this through a formal conceptual framework rooted in the social sciences, that provides a foundation for the systematic, integrated and interdisciplinary investigation into how human values can support designing ethical AI.
    
[^31]: 无监督对话主题分割及话语表示中主题感知方法

    Unsupervised Dialogue Topic Segmentation with Topic-aware Utterance Representation. (arXiv:2305.02747v1 [cs.CL])

    [http://arxiv.org/abs/2305.02747](http://arxiv.org/abs/2305.02747)

    本文提出一种利用未标记的对话数据进行无监督对话主题分割的方法，通过邻近话语匹配和伪分割学习主题感知的话语表示，实验显示其明显优于强基准方法。

    

    对话主题分割在各种对话建模任务中起着重要作用。现有的DTS方法要么关注语义相似性，要么关注对话连贯性来评估主题相似性以进行无监督对话分割。但主题相似性不能通过语义相似性或对话连贯性的方式来完全识别。此外，未标记的对话数据中包含有用的话语关系提示，但这些提示未被充分利用。在本文中，我们提出了一种新颖的无监督DTS框架，通过邻近话语匹配和伪分割从未标记的对话数据中学习主题感知的话语表示。在两个基准数据集（DialSeg711和Doc2Dial）上的广泛实验表明，我们的方法显著优于强基准方法。为了可复现性，我们在https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/dial-start上提供了我们的代码和数据。

    Dialogue Topic Segmentation (DTS) plays an essential role in a variety of dialogue modeling tasks. Previous DTS methods either focus on semantic similarity or dialogue coherence to assess topic similarity for unsupervised dialogue segmentation. However, the topic similarity cannot be fully identified via semantic similarity or dialogue coherence. In addition, the unlabeled dialogue data, which contains useful clues of utterance relationships, remains underexploited. In this paper, we propose a novel unsupervised DTS framework, which learns topic-aware utterance representations from unlabeled dialogue data through neighboring utterance matching and pseudo-segmentation. Extensive experiments on two benchmark datasets (i.e., DialSeg711 and Doc2Dial) demonstrate that our method significantly outperforms the strong baseline methods. For reproducibility, we provide our code and data at:https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/dial-start.
    
[^32]: 多智能体系统中的人类价值观

    Human Values in Multiagent Systems. (arXiv:2305.02739v1 [cs.AI])

    [http://arxiv.org/abs/2305.02739](http://arxiv.org/abs/2305.02739)

    本文提出了一种基于社会科学的形式化价值观表征，并阐明了多智能体系统中实现与价值观一致的行为的关键挑战和相应的研究路线图。

    

    当今伦理人工智能面临的主要挑战之一是开发计算系统，其推理和行为可证明与人类价值观一致。然而，“人类价值观”以其歧义、矛盾和多变而著称。为了弥合这种差距，拉近我们可以正式推断将价值观实施于人工智能的情况，本文提出了一种基于社会科学的价值观的正式表征。我们使用这种正式呈现方式来阐明在多智能体系统中实现与价值观一致的行为的关键挑战，以及解决这些挑战的研究路线图。

    One of the major challenges we face with ethical AI today is developing computational systems whose reasoning and behaviour are provably aligned with human values. Human values, however, are notorious for being ambiguous, contradictory and ever-changing. In order to bridge this gap, and get us closer to the situation where we can formally reason about implementing values into AI, this paper presents a formal representation of values, grounded in the social sciences. We use this formal representation to articulate the key challenges for achieving value-aligned behaviour in multiagent systems (MAS) and a research roadmap for addressing them.
    
[^33]: 公正联邦学习可以减少个性化需求吗？

    Can Fair Federated Learning reduce the need for Personalisation?. (arXiv:2305.02728v1 [cs.LG])

    [http://arxiv.org/abs/2305.02728](http://arxiv.org/abs/2305.02728)

    本文探索了联邦学习的公正性与个性化需求的关系，提出个性化公正联邦学习（PFL）算法，能够解决准确性差异以及在FL模型表现不佳时提供参与激励的问题。

    

    联邦学习（FL）使得在不共享数据的情况下在边缘客户端上训练ML模型成为可能。然而，联邦模型在本地数据上的性能会有所差异，这会造成对于没有从FL中受益的客户端参与的不利影响。公正FL通过关注损失更高的客户端来减少准确性差异，而个性化调整则在本地微调模型。在FL模型相对于本地训练模型表现较差时，个性化提供了参与激励。本文评估了两种公正FL算法作为个性化的起点。结果表明，基于公正FL的方法对于语言任务并没有产生相对性能优势，并且在图像任务中可能会使表现不佳的客户端数量增加一倍。相反，我们提出了个性化公正联邦学习（PFL），并展示了在语言和图像任务中减少准确性差异的同时，在FL模型相对于本地模型表现较差时提供了参与激励。

    Federated Learning (FL) enables training ML models on edge clients without sharing data. However, the federated model's performance on local data varies, disincentivising the participation of clients who benefit little from FL. Fair FL reduces accuracy disparity by focusing on clients with higher losses while personalisation locally fine-tunes the model. Personalisation provides a participation incentive when an FL model underperforms relative to one trained locally. For situations where the federated model provides a lower accuracy than a model trained entirely locally by a client, personalisation improves the accuracy of the pre-trained federated weights to be similar to or exceed those of the local client model. This paper evaluates two Fair FL (FFL) algorithms as starting points for personalisation. Our results show that FFL provides no benefit to relative performance in a language task and may double the number of underperforming clients for an image task. Instead, we propose Pers
    
[^34]: 面向任务型对话系统的异步更新强化学习框架

    An Asynchronous Updating Reinforcement Learning Framework for Task-oriented Dialog System. (arXiv:2305.02718v1 [cs.CL])

    [http://arxiv.org/abs/2305.02718](http://arxiv.org/abs/2305.02718)

    本文提出了一种异步更新强化学习框架 (AURL) 来训练面向任务型对话系统，解决了不同模块互相影响的问题。同时，采用课程学习来解决数据分布不平衡问题，并引入多个用户模型来增加对话的多样性。该方法在公共数据集上取得了31.37%的对话成功率改进。

    

    许多对话系统中已经应用了强化学习来进行训练。先前的方法将对话系统分成多个模块，包括对话状态跟踪 (DST) 和对话策略 (DP)，并同时训练这些模块。然而，不同模块在训练过程中会相互影响。来自 DST 的误差可能会误导对话策略，系统操作也会给 DST 模块带来额外的困难。为了缓解这个问题，我们提出了一种异步更新强化学习框架 (AURL)，在合作设置下异步地更新 DST 模块和 DP 模块。此外，采用课程学习来解决强化学习采样过程中的数据分布不平衡问题，并引入多个用户模型来增加对话的多样性。公共 SSD-PHONE 数据集上的结果表明，我们的方法在对话成功率方面取得了显著的31.37%改进。代码可在 https://github.com/thu-coai/AURL-Dialog-System 上获得。

    Reinforcement learning has been applied to train the dialog systems in many works. Previous approaches divide the dialog system into multiple modules including DST (dialog state tracking) and DP (dialog policy), and train these modules simultaneously. However, different modules influence each other during training. The errors from DST might misguide the dialog policy, and the system action brings extra difficulties for the DST module. To alleviate this problem, we propose Asynchronous Updating Reinforcement Learning framework (AURL) that updates the DST module and the DP module asynchronously under a cooperative setting. Furthermore, curriculum learning is implemented to address the problem of unbalanced data distribution during reinforcement learning sampling, and multiple user models are introduced to increase the dialog diversity. Results on the public SSD-PHONE dataset show that our method achieves a compelling result with a 31.37% improvement on the dialog success rate. The code i
    
[^35]: DECICE: 设备-边缘-云智能协作框架(arXiv:2305.02697v1 [cs.DC])

    DECICE: Device-Edge-Cloud Intelligent Collaboration Framework. (arXiv:2305.02697v1 [cs.DC])

    [http://arxiv.org/abs/2305.02697](http://arxiv.org/abs/2305.02697)

    DECICE是一个跨设备-边缘和云的智能协作框架，具有自适应优化和部署应用的能力，能够应用于智能交通、医学成像和紧急响应等方面。

    

    DECICE是一个Horizon Europe项目，正在开发一种AI-enabled的开放式和可移植式管理框架，用于计算连续体中应用程序的自动和自适应优化和部署，该连续体涵盖了从边缘IoT传感器到大规模云/HPC计算基础设施的范围。在本文中，我们描述了DECICE框架和架构。此外，我们还突出了用于框架评估的用例：智能交通路口，磁共振成像和紧急响应。

    DECICE is a Horizon Europe project that is developing an AI-enabled open and portable management framework for automatic and adaptive optimization and deployment of applications in computing continuum encompassing from IoT sensors on the Edge to large-scale Cloud / HPC computing infrastructures. In this paper, we describe the DECICE framework and architecture. Furthermore, we highlight use-cases for framework evaluation: intelligent traffic intersection, magnetic resonance imaging, and emergency response.
    
[^36]: 学习多语机器翻译的语言特异层

    Learning Language-Specific Layers for Multilingual Machine Translation. (arXiv:2305.02665v1 [cs.CL])

    [http://arxiv.org/abs/2305.02665](http://arxiv.org/abs/2305.02665)

    本文介绍了语言特异Transformer层（LSLs），这使我们能够增加模型容量，同时保持正向传递中使用的计算量和参数数量不变，从而提高多语机器翻译的质量。

    

    多语机器翻译可以提高非英语语言之间的翻译质量，在许多方面都有优势，例如更低的延迟（无需翻译两次）和减少错误级联（例如，在通过英语进行翻译时避免丢失性别和礼貌等信息）。但是，添加更多语言会减少每种语言的模型容量，通常通过增加总体模型大小来抵消，从而使训练更加困难，推理速度变慢。在这项工作中，我们引入了语言特异Transformer层（LSLs），它们使我们能够增加模型容量，同时保持正向传递中使用的计算量和参数数量不变。关键思想是让编码器的某些层为源语言或目标语言特异，同时保持其余层共享。我们使用神经架构搜索启发式方法研究了放置这些层的最佳方法，并实现了1.3 chrF（1.5 spBLE）的改进。

    Multilingual Machine Translation promises to improve translation quality between non-English languages. This is advantageous for several reasons, namely lower latency (no need to translate twice), and reduced error cascades (e.g., avoiding losing gender and formality information when translating through English). On the downside, adding more languages reduces model capacity per language, which is usually countered by increasing the overall model size, making training harder and inference slower. In this work, we introduce Language-Specific Transformer Layers (LSLs), which allow us to increase model capacity, while keeping the amount of computation and the number of parameters used in the forward pass constant. The key idea is to have some layers of the encoder be source or target language-specific, while keeping the remaining layers shared. We study the best way to place these layers using a neural architecture search inspired approach, and achieve an improvement of 1.3 chrF (1.5 spBLE
    
[^37]: 学习在存在隐性混淆因素的情况下从不确定数据中恢复因果关系

    Learning to Recover Causal Relationship from Indefinite Data in the Presence of Latent Confounders. (arXiv:2305.02640v1 [cs.LG])

    [http://arxiv.org/abs/2305.02640](http://arxiv.org/abs/2305.02640)

    本文提出了因果强度变分模型，解决了从不确定数据中恢复因果关系存在的低样本利用率和分布假设无能力的问题，同时考虑了潜在混淆因素。

    

    在具有潜在变量的因果发现中，我们定义了两个数据范式：确定数据：具有观察节点单值的单个骨架结构，和不确定数据：具有观察节点多值的一组多骨架结构。多个骨架引入低样本利用率，多个值引入了分布假设的无能力，这两者导致从不确定数据中恢复因果关系至今仍然未被充分探索。我们设计了因果强度变分模型来解决这两个问题。具体地，我们利用因果强度而不是独立噪声作为潜变量来调节证据下界。通过这种设计思想，不同骨架的因果强度被看作是一个分布，并可以表示为单值因果图矩阵。此外，考虑到潜在混淆因素，我们将因果图G分解为两个相关子图O和C。O包含观察节点之间的纯关系，而C表示混淆因素。

    In Causal Discovery with latent variables, We define two data paradigms: definite data: a single-skeleton structure with observed nodes single-value, and indefinite data: a set of multi-skeleton structures with observed nodes multi-value. Multi,skeletons induce low sample utilization and multi values induce incapability of the distribution assumption, both leading that recovering causal relations from indefinite data is, as of yet, largely unexplored. We design the causal strength variational model to settle down these two problems. Specifically, we leverage the causal strength instead of independent noise as latent variable to mediate evidence lower bound. By this design ethos, The causal strength of different skeletons is regarded as a distribution and can be expressed as a single-valued causal graph matrix. Moreover, considering the latent confounders, we disentangle the causal graph G into two relatisubgraphs O and C. O contains pure relations between observed nodes, while C repres
    
[^38]: 面向跨数据集的弱监督仇恨言论分类

    Towards Weakly-Supervised Hate Speech Classification Across Datasets. (arXiv:2305.02637v1 [cs.CL])

    [http://arxiv.org/abs/2305.02637](http://arxiv.org/abs/2305.02637)

    该论文提出使用极度弱的监督方法，只依赖于类别名称而不是注释数据中的类别示例，解决当前仇恨言论识别的研究存在的数据创建策略不系统和不同注释方案问题，并展示了有效性。

    

    如多位学者指出的那样，当前针对仇恨言论（HS）识别的研究特点是不系统的数据创建策略和不同的注释方案。因此，监督学习模型往往对它们未被训练的数据集进行泛化性能差，并且不同HS分类法标记的数据集所训练的模型的性能无法比较。为了解决这个问题，我们提出了一种极度弱的监督方法，只依赖于类别名称而不是注释数据中的类别示例。我们展示了一种最先进的弱监督文本分类模型在各种数据集内和跨数据集的情况下的有效性。此外，我们对HS分类模型通用性较差的原因进行了深入的定量和定性分析。

    As pointed out by several scholars, current research on hate speech (HS) recognition is characterized by unsystematic data creation strategies and diverging annotation schemata. Subsequently, supervised-learning models tend to generalize poorly to datasets they were not trained on, and the performance of the models trained on datasets labeled using different HS taxonomies cannot be compared. To ease this problem, we propose applying extremely weak supervision that only relies on the class name rather than on class samples from the annotated data. We demonstrate the effectiveness of a state-of-the-art weakly-supervised text classification model in various in-dataset and cross-dataset settings. Furthermore, we conduct an in-depth quantitative and qualitative analysis of the source of poor generalizability of HS classification models.
    
[^39]: 一种社交学习代理中语言出现与分析的框架

    A framework for the emergence and analysis of language in social learning agents. (arXiv:2305.02632v1 [cs.CL])

    [http://arxiv.org/abs/2305.02632](http://arxiv.org/abs/2305.02632)

    本研究提出了一个模拟语言特征的通信协议，用于分析个体和共享抽象的形成及其对任务表现的影响。通过优化信息内容以最大化学生奖励改善了信息编码，提高了学习表现。

    

    人工神经网络（ANNs）越来越被用作研究模型，但它们的普适性和表征不变性仍存在问题。生物神经网络在社交约束下演化形成可传达的表征，展示了泛化能力。本研究提出了一种合作代理之间的通信协议，用于分析个体和共享抽象的形成及其对任务表现的影响。该通信协议旨在通过低维表示编码高维信息，模拟语言特征。使用网格世界迷宫和强化学习，教师ANNs向学生ANN传递压缩消息，以便更好地完成任务。通过这种方式，学生实现了更高的目标发现率，并在不同的任务世界中推广了目标位置。进一步优化信息内容以最大化学生奖励改善了信息编码，表明精确的表征可以在通信协议中得到实现。

    Artificial neural networks (ANNs) are increasingly used as research models, but questions remain about their generalizability and representational invariance. Biological neural networks under social constraints evolved to enable communicable representations, demonstrating generalization capabilities. This study proposes a communication protocol between cooperative agents to analyze the formation of individual and shared abstractions and their impact on task performance. This communication protocol aims to mimic language features by encoding high-dimensional information through low-dimensional representation. Using grid-world mazes and reinforcement learning, teacher ANNs pass a compressed message to a student ANN for better task completion. Through this, the student achieves a higher goal-finding rate and generalizes the goal location across task worlds. Further optimizing message content to maximize student reward improves information encoding, suggesting that an accurate representati
    
[^40]: “哎呀，我刚刚说了什么？”用建议-批判-反思过程测试和修复大型语言模型的不道德建议

    "Oops, Did I Just Say That?" Testing and Repairing Unethical Suggestions of Large Language Models with Suggest-Critique-Reflect Process. (arXiv:2305.02626v1 [cs.SE])

    [http://arxiv.org/abs/2305.02626](http://arxiv.org/abs/2305.02626)

    随着大型语言模型(LLM)在各种应用中的流行，本文提出了第一个测试和修复LLM在道德准则上失当建议的框架，并引入ETHICSSUITE测试套件和建议-批判-反思(SCR)过程以自动检测和修复LLM的不道德建议。

    

    随着大型语言模型（LLM）在各种应用中的流行，确保它们与人类价值观相一致已成为一个重要关注点。特别是，考虑到LLM有望成为日常生活中通用的人工智能助手，它们微妙的不道德建议成为了一个严重而现实的问题。因此，自动化测试和修复不道德建议的挑战是很大的。本文介绍了第一个测试和修复LLM不道德建议的框架。我首先提出了ETHICSSUITE，一个测试套件，用于测试LLM的复杂、情境化和现实的道德场景。然后我提出了一种新颖的建议-批判-反思（SCR）过程，作为自动化测试预言，用于检测不道德建议。我们将判断LLM是否产生不道德建议（通常需要人类专业知识和成本较高）转化为一个可以自动检查违规的PCR任务。此外，SCR过程还提供了修复不道德建议的反馈。

    As the popularity of large language models (LLMs) soars across various applications, ensuring their alignment with human values has become a paramount concern. In particular, given that LLMs have great potential to serve as general-purpose AI assistants in daily life, their subtly unethical suggestions become a serious and real concern. Tackling the challenge of automatically testing and repairing unethical suggestions is thus demanding.  This paper introduces the first framework for testing and repairing unethical suggestions made by LLMs. We first propose ETHICSSUITE, a test suite that presents complex, contextualized, and realistic moral scenarios to test LLMs. We then propose a novel suggest-critic-reflect (SCR) process, serving as an automated test oracle to detect unethical suggestions. We recast deciding if LLMs yield unethical suggestions (a hard problem; often requiring human expertise and costly to decide) into a PCR task that can be automatically checked for violation. Moreo
    
[^41]: 会话中的情感推理：因果发现方法的应用

    Affective Reasoning at Utterance Level in Conversations: A Causal Discovery Approach. (arXiv:2305.02615v1 [cs.CL])

    [http://arxiv.org/abs/2305.02615](http://arxiv.org/abs/2305.02615)

    本文提出了一种新的会话情感因果发现方法（CACD），并通过设计公共骨架和生成替代隐含原因解决了因果模型的不确定性和隐含原因的不可观察性的问题。这种方法可以在变长会话中发现因果关系。

    

    情感推理任务是包括会话中的情感识别、情感-原因对抽取和情感-原因跨度识别在内的一组新兴的基于情感的任务。现有的方法在假设表面关系时忽略了基本的因果模型，因为骨架的不确定性和隐含原因的不可观察性。本文解决了上述两个问题，并进一步提出了会话情感因果发现（CACD）方法。这是一种新颖的因果发现方法，展示了如何通过设计公共骨架和生成替代隐含原因来发现会话中的因果关系。CACD包含两个步骤：（i）为变长会话中的所有话语建立一个中心化的单一图节点因果骨架；（ii）因果自编码器（CAE）通过生成隐含原因和已知显式原因来修正骨架，从而产生因果表示。

    The affective reasoning task is a set of emerging affect-based tasks in conversation, including Emotion Recognition in Conversation (ERC),Emotion-Cause Pair Extraction (ECPE), and Emotion-Cause Span Recognition (ECSR). Existing methods make various assumptions on the apparent relationship while neglecting the essential causal model due to the nonuniqueness of skeletons and unobservability of implicit causes. This paper settled down the above two problems and further proposed Conversational Affective Causal Discovery (CACD). It is a novel causal discovery method showing how to discover causal relationships in a conversation via designing a common skeleton and generating a substitute for implicit causes. CACD contains two steps: (i) building a common centering one graph node causal skeleton for all utterances in variable-length conversations; (ii) Causal Auto-Encoder (CAE) correcting the skeleton to yield causal representation through generated implicit causes and known explicit causes. 
    
[^42]: 基于半监督学习的高维贝叶斯优化及优化无标签数据采样

    High-dimensional Bayesian Optimization via Semi-supervised Learning with Optimized Unlabeled Data Sampling. (arXiv:2305.02614v1 [cs.LG])

    [http://arxiv.org/abs/2305.02614](http://arxiv.org/abs/2305.02614)

    本文提出基于半监督学习的高维贝叶斯优化方法，利用特定的未标记数据采样、参数化采样分布的优化及动态选择无标记数据等策略，解决了高维贝叶斯优化难以处理的问题。

    

    贝叶斯优化（BO）是一种寻找黑箱函数全局最优解的强大工具。虽然黑箱函数的评估成本往往很高，但减少昂贵标记数据的使用是理想的。本文首次提出了一种教师-学生模型，利用半监督学习在BO环境下利用大量未标记的数据。其中，关键在于选择验证和未标记数据以提高BO的表现。为了优化无标签数据的采样，我们采用黑箱参数化采样分布，将其优化为所采用双层优化框架的一部分。更进一步，通过从动态适应的极值分布中选择未标签数据，我们证明了BO的性能可以进一步提高。我们的BO方法在学习后的低维潜在空间中运行，使其可扩展到高维问题。

    Bayesian optimization (BO) is a powerful tool for seeking the global optimum of black-box functions. While evaluations of the black-box functions can be highly costly, it is desirable to reduce the use of expensive labeled data. For the first time, we introduce a teacher-student model to exploit semi-supervised learning that can make use of large amounts of unlabelled data under the context of BO. Importantly, we show that the selection of the validation and unlabeled data is key to the performance of BO. To optimize the sampling of unlabeled data, we employ a black-box parameterized sampling distribution optimized as part of the employed bi-level optimization framework. Taking one step further, we demonstrate that the performance of BO can be further improved by selecting unlabeled data from a dynamically fitted extreme value distribution. Our BO method operates in a learned latent space with reduced dimensionality, making it scalable to high-dimensional problems. The proposed approac
    
[^43]: 从统计方法到深度学习，自动关键词预测：一次综述

    From Statistical Methods to Deep Learning, Automatic Keyphrase Prediction: A Survey. (arXiv:2305.02579v1 [cs.CL])

    [http://arxiv.org/abs/2305.02579](http://arxiv.org/abs/2305.02579)

    本文综述了关键词预测的代表性研究，分析了主要模型、数据集和评估指标，特别关注了基于深度学习的关键词预测，并进行了实验比较代表性模型，为深入分析它们的优缺点提供了可比性的数据支持。

    

    关键词预测旨在生成高度总结给定文档的短语（关键词）。近年来，研究人员从不同的视角对这个任务进行了深入的研究。本文从主要模型、数据集和评估指标的角度全面总结了代表性的研究。我们分析了多达167篇先前的作品，比以前的调查实现了更大范围的覆盖。特别是，我们高度关注基于深度学习的关键词预测，在近年来引起了越来越多的关注。此外，我们进行了几组实验，仔细比较了代表性模型。据我们所知，我们的工作是第一个使用相同常用数据集和评估指标来比较这些模型的尝试，有助于深入分析它们的优缺点。最后，我们讨论了未来该任务的可能研究方向。

    Keyphrase prediction aims to generate phrases (keyphrases) that highly summarizes a given document. Recently, researchers have conducted in-depth studies on this task from various perspectives. In this paper, we comprehensively summarize representative studies from the perspectives of dominant models, datasets and evaluation metrics. Our work analyzes up to 167 previous works, achieving greater coverage of this task than previous surveys. Particularly, we focus highly on deep learning-based keyphrase prediction, which attracts increasing attention of this task in recent years. Afterwards, we conduct several groups of experiments to carefully compare representative models. To the best of our knowledge, our work is the first attempt to compare these models using the identical commonly-used datasets and evaluation metric, facilitating in-depth analyses of their disadvantages and advantages. Finally, we discuss the possible research directions of this task in the future.
    
[^44]: ChatGPT和Bard是否应该与其数据提供者分享收益？AI时代的新商业模式

    Should ChatGPT and Bard Share Revenue with Their Data Providers? A New Business Model for the AI Era. (arXiv:2305.02555v1 [cs.LG])

    [http://arxiv.org/abs/2305.02555](http://arxiv.org/abs/2305.02555)

    ChatGPT和Bard等AI工具需要持续大量且高质量的数据来提高其性能，但现行的版权法则限制了它们对各种数据的获取。与数据提供者分享收益将有助于将AI工具与大多数版权数据拥有者之间的敌对关系转变为合作关系，使AI生态系统更健康。

    

    随着ChatGPT等各种人工智能工具越来越受欢迎，我们正进入真正的AI时代。我们可以预见，卓越的AI工具很快将获得可观的利润。一个关键问题出现了：除了传统的利益相关者和股东，AI工具是否应该与它们的训练数据提供者分享收益？答案是肯定的。大型AI工具，例如大型语言模型，始终需要更多、更高质量的数据来不断改进，但当前的版权法限制了它们对各种类型数据的获取。在AI工具和数据提供者之间分享收益可以将当前敌对的零和游戏关系转变为一种合作和互利的关系，而这种关系对于促进AI工具、用户和数据提供者之间的良性循环发展、推动AI技术并建立健康的AI生态系统是必要的。然而，当前的收益分享商业模式……

    With various AI tools such as ChatGPT becoming increasingly popular, we are entering a true AI era. We can foresee that exceptional AI tools will soon reap considerable profits. A crucial question arise: should AI tools share revenue with their training data providers in additional to traditional stakeholders and shareholders? The answer is Yes. Large AI tools, such as large language models, always require more and better quality data to continuously improve, but current copyright laws limit their access to various types of data. Sharing revenue between AI tools and their data providers could transform the current hostile zero-sum game relationship between AI tools and a majority of copyrighted data owners into a collaborative and mutually beneficial one, which is necessary to facilitate the development of a virtuous cycle among AI tools, their users and data providers that drives forward AI technology and builds a healthy AI ecosystem. However, current revenue-sharing business models 
    
[^45]: PersonaLLM: 探究GPT-3.5表达个性特征和性别差异的能力

    PersonaLLM: Investigating the Ability of GPT-3.5 to Express Personality Traits and Gender Differences. (arXiv:2305.02547v1 [cs.CL])

    [http://arxiv.org/abs/2305.02547](http://arxiv.org/abs/2305.02547)

    本文探究了基于LLMs模拟代理的行为，称之为LLM Personas，在分配大五人格类型和性别角色时是否可以生成具有一致性的个性化特质的内容。

    

    尽管大型语言模型在各个行业的聊天机器人设计中有许多用途，并且研究表明个性化聊天机器人在满足不同人格特征方面的重要性，但很少有研究评估个性化LLM的行为是否能够准确、一致地反映某些人格特征。我们考虑研究基于LLM的模拟代理的行为，称之为LLM personas，并使用GPT-3.5（text-davinci-003）进行案例研究，以研究LLM在分配大五人格类型和性别角色时是否可以生成具有一致性的个性化特质的内容。我们创建了320个LLM personas（每种大五人格类型有5个女性和5个男性），并提示他们完成经典的44项大五人格问卷（BFI），然后撰写一个关于他们童年的800字故事。结果表明，LLM personas的自我报告的BFI分数与他们分配的人格类型一致。

    Despite the many use cases for large language models (LLMs) in the design of chatbots in various industries and the research showing the importance of personalizing chatbots to cater to different personality traits, little work has been done to evaluate whether the behaviors of personalized LLMs can reflect certain personality traits accurately and consistently. We consider studying the behavior of LLM-based simulated agents which refer to as LLM personas and present a case study with GPT-3.5 (text-davinci-003) to investigate whether LLMs can generate content with consistent, personalized traits when assigned Big Five personality types and gender roles. We created 320 LLM personas (5 females and 5 males for each of the 32 Big Five personality types) and prompted them to complete the classic 44-item Big Five Inventory (BFI) and then write an 800-word story about their childhood. Results showed that LLM personas' self-reported BFI scores are consistent with their assigned personality typ
    
[^46]: 语言、时间偏好和消费行为：大型语言模型的证据

    Language, Time Preferences, and Consumer Behavior: Evidence from Large Language Models. (arXiv:2305.02531v1 [econ.GN])

    [http://arxiv.org/abs/2305.02531](http://arxiv.org/abs/2305.02531)

    本研究分析了大型语言模型在不同语言提示下的奖励时间偏好，并发现GPT在具有较弱未来时态的语言下表现出更大的耐心，这与使用该语言的人类的偏好相似。

    

    语言对我们对时间和奖励的感知有很大的影响。这引发了一个问题，即当以不同的语言询问大型语言模型时，它们是否显示出不同的奖励时间偏好，并且它们的选择是否类似于人类的选择。本研究分析了GPT-3.5（以下简称GPT）在多种语言提示下的响应，探索了较小、较早的奖励和较大、较晚的奖励之间的偏好。我们的结果显示，当以语义含义较弱的未来时态参考（FTR），如德语和汉语，为提示语时，GPT表现出更大的耐心，相比英语和法语等具有强大FTR的语言。这些发现与现有文献一致，并表明了GPT的选择与这些语言的使用者的偏好之间的关联。然而，进一步的分析揭示了较早或较晚奖励的偏好并没有随着奖励差异系统地改变，这表明了一种词典序优先的选择。

    Language has a strong influence on our perceptions of time and rewards. This raises the question of whether large language models, when asked in different languages, show different preferences for rewards over time and if their choices are similar to those of humans. In this study, we analyze the responses of GPT-3.5 (hereafter referred to as GPT) to prompts in multiple languages, exploring preferences between smaller, sooner rewards and larger, later rewards. Our results show that GPT displays greater patience when prompted in languages with weak future tense references (FTR), such as German and Mandarin, compared to languages with strong FTR, like English and French. These findings are consistent with existing literature and suggest a correlation between GPT's choices and the preferences of speakers of these languages. However, further analysis reveals that the preference for earlier or later rewards does not systematically change with reward gaps, indicating a lexicographic preferen
    
[^47]: 《延迟、复合和部分匿名奖励的强化学习》

    Reinforcement Learning with Delayed, Composite, and Partially Anonymous Reward. (arXiv:2305.02527v1 [cs.LG])

    [http://arxiv.org/abs/2305.02527](http://arxiv.org/abs/2305.02527)

    本文提出了一种算法用于解决具有延迟、复合和部分匿名奖励反馈的无限时平均奖励马尔可夫决策过程(MDP)，并取得了较好的效果。

    

    我们研究了具有延迟、复合和部分匿名奖励反馈的无限时平均奖励马尔可夫决策过程(MDP)。奖励的延迟和复杂性意味着在给定状态下采取行动生成的奖励被分解为不同的组成部分，并在延迟的时间实例中被顺序实现。部分匿名属性意味着对于每个状态，学习者只观察到在该状态下采取不同行动产生的过去奖励组成部分的总和，但是在观察实例中实现。我们提出了一种名为$\mathrm{DUCRL2}$的算法，用于获得此设置的近似最优策略，并表明它实现了$\tilde{\mathcal{O}}\left(DS\sqrt{AT} + d (SA)^3\right)$ 的遗憾界，其中$S$和$A$分别是状态和动作空间的大小，$D$是MDP的直径，$d$是一个由最大奖励延迟限制的参数，$T$表示时间的长度。

    We investigate an infinite-horizon average reward Markov Decision Process (MDP) with delayed, composite, and partially anonymous reward feedback. The delay and compositeness of rewards mean that rewards generated as a result of taking an action at a given state are fragmented into different components, and they are sequentially realized at delayed time instances. The partial anonymity attribute implies that a learner, for each state, only observes the aggregate of past reward components generated as a result of different actions taken at that state, but realized at the observation instance. We propose an algorithm named $\mathrm{DUCRL2}$ to obtain a near-optimal policy for this setting and show that it achieves a regret bound of $\tilde{\mathcal{O}}\left(DS\sqrt{AT} + d (SA)^3\right)$ where $S$ and $A$ are the sizes of the state and action spaces, respectively, $D$ is the diameter of the MDP, $d$ is a parameter upper bounded by the maximum reward delay, and $T$ denotes the time horizon
    
[^48]: Stimulative Training++：超越残差网络性能极限

    Stimulative Training++: Go Beyond The Performance Limits of Residual Networks. (arXiv:2305.02507v1 [cs.LG])

    [http://arxiv.org/abs/2305.02507](http://arxiv.org/abs/2305.02507)

    本文从一种新的社会心理学角度重新审视残差网络的训练过程，发现了网络贡献不足问题并提出解决方案和改进策略，以提高残差网络的性能。

    

    残差网络在近期深度神经网络模型中表现出极大的成功，并变得不可或缺。本文从一种新的社会心理学角度重新考察了残差网络的训练过程，并进一步提出了一种新的训练方案以及三种改进策略，以提高残差网络的性能。我们发现一种类似社会贡献的被忽视的问题，即在残差网络内部，子网络在群体中工作时倾向于比独自工作时付出更少的努力，这被我们定义为“网络贡献不足”。与社会中表现出的个体生产力和整体绩效下降类似，网络贡献不足必然导致残差网络的性能下降。

    Residual networks have shown great success and become indispensable in recent deep neural network models. In this work, we aim to re-investigate the training process of residual networks from a novel social psychology perspective of loafing, and further propose a new training scheme as well as three improved strategies for boosting residual networks beyond their performance limits. Previous research has suggested that residual networks can be considered as ensembles of shallow networks, which implies that the final performance of a residual network is influenced by a group of subnetworks. We identify a previously overlooked problem that is analogous to social loafing, where subnetworks within a residual network are prone to exert less effort when working as part of a group compared to working alone. We define this problem as \textit{network loafing}. Similar to the decreased individual productivity and overall performance as demonstrated in society, network loafing inevitably causes su
    
[^49]: AutoML-GPT: 基于 GPT 的自动机器学习

    AutoML-GPT: Automatic Machine Learning with GPT. (arXiv:2305.02499v1 [cs.CL])

    [http://arxiv.org/abs/2305.02499](http://arxiv.org/abs/2305.02499)

    AutoML-GPT 是一种基于 GPT 的自动机器学习方法，利用大型语言模型动态地利用各种人工智能模型，自动化训练管道，节约了选择模型架构、优化算法和调整超参数的人力和时间成本。

    

    AI 任务涵盖了广泛的领域和领域。虽然为特定任务和应用程序设计了众多 AI 模型，但它们通常需要大量的人力投入来查找正确的模型架构、优化算法和超参数。最近，像 ChatGPT 这样的大型语言模型 (LLM) 在推理、理解和交互的各个方面展现出了卓越的能力。因此，我们提出了开发面向任务的提示并自动利用 LLM 自动化训练管道的想法。为了实现这个概念，我们推出了 AutoML-GPT，它采用 GPT 作为连接多种 AI 模型的桥梁，并动态地使用优化超参数训练模型。AutoML-GPT 从模型和数据卡中动态获取用户请求，并组成相应的提示段落。最终，通过这个提示段落，AutoML-GPT 将自动从数据处理到模型架构、超参数调整进行实验。

    AI tasks encompass a wide range of domains and fields. While numerous AI models have been designed for specific tasks and applications, they often require considerable human efforts in finding the right model architecture, optimization algorithm, and hyperparameters. Recent advances in large language models (LLMs) like ChatGPT show remarkable capabilities in various aspects of reasoning, comprehension, and interaction. Consequently, we propose developing task-oriented prompts and automatically utilizing LLMs to automate the training pipeline. To implement this concept, we present the AutoML-GPT, which employs GPT as the bridge to diverse AI models and dynamically trains models with optimized hyperparameters. AutoML-GPT dynamically takes user requests from the model and data cards and composes the corresponding prompt paragraph. Ultimately, with this prompt paragraph, AutoML-GPT will automatically conduct the experiments from data processing to model architecture, hyperparameter tuning,
    
[^50]: 重新审视用于异常检测的图对比学习

    Revisiting Graph Contrastive Learning for Anomaly Detection. (arXiv:2305.02496v1 [cs.LG])

    [http://arxiv.org/abs/2305.02496](http://arxiv.org/abs/2305.02496)

    本文重新审视了用于异常检测的图对比学习方法。通过深入探讨现有方法的基本机制，提出了统一的多GNN和增强图对比框架MAG，并从中提取轻量级实例L-MAG和M-MAG。

    

    最近，将图神经网络（GNN）与对比学习相结合进行异常检测引起了越来越多的关注。现有的图对比异常检测（GCAD）方法主要集中于通过图扩充和多尺度对比模块改善检测能力。然而，这些模块的基本机制尚未得到充分的探索。我们深入研究了多尺度和图扩充机制，并观察到多尺度对比模块并没有增强表达，而多GNN模块是隐藏的贡献者。先前的研究往往将多GNN带来的收益归因于多尺度模块。在本文中，我们深入探讨了这种误解，并提出了多GNN和增强图对比框架MAG，将现有的GCAD方法统一在对比自监督的视角下。我们从MAG框架中提取了两个变体，L-MAG和M-MAG。L-MAG是轻量级的实例。

    Combining Graph neural networks (GNNs) with contrastive learning for anomaly detection has drawn rising attention recently. Existing graph contrastive anomaly detection (GCAD) methods have primarily focused on improving detection capability through graph augmentation and multi-scale contrast modules. However, the underlying mechanisms of how these modules work have not been fully explored. We dive into the multi-scale and graph augmentation mechanism and observed that multi-scale contrast modules do not enhance the expression, while the multi-GNN modules are the hidden contributors. Previous studies have tended to attribute the benefits brought by multi-GNN to the multi-scale modules. In the paper, we delve into the misconception and propose Multi-GNN and Augmented Graph contrastive framework MAG, which unified the existing GCAD methods in the contrastive self-supervised perspective. We extracted two variants from the MAG framework, L-MAG and M-MAG. The L-MAG is the lightweight instanc
    
[^51]: 如何利用强化学习促进未来电力市场设计？第一部分：范型理论。（arXiv:2305.02485v1 [cs.AI]）

    How to Use Reinforcement Learning to Facilitate Future Electricity Market Design? Part 1: A Paradigmatic Theory. (arXiv:2305.02485v1 [cs.AI])

    [http://arxiv.org/abs/2305.02485](http://arxiv.org/abs/2305.02485)

    本文提出基于强化学习的方法，设计联合市场以应对电力行业脱碳，实现电力系统的安全和经济效益，并为环境做出贡献。该范型理论的框架将在两部分中详细介绍。

    

    面对电力行业脱碳的迫切需求，重新设计电力市场是一种宏观层面的方法，以适应可再生能源的高渗透率，并实现电力系统的操作安全、经济效率和环境友好性。然而，现有的市场设计方法学存在于能源现货市场（ESM）、辅助服务市场（ASM）和金融市场（FM）之间协调不足，即“联合市场”，以及缺乏可靠的基于模拟的验证。为了解决这些缺陷，本文将基于强化学习（RL）的模拟，开发联合市场设计的范型理论和详细方法。第一部分提出了这种新型市场设计哲学的理论和框架。首先，总结了在设计联合市场时存在的有争议的市场设计选项作为目标研究问题。其次，提出了马尔可夫博弈模型。

    In face of the pressing need of decarbonization in the power sector, the re-design of electricity market is necessary as a Marco-level approach to accommodate the high penetration of renewable generations, and to achieve power system operation security, economic efficiency, and environmental friendliness. However, existing market design methodologies suffer from the lack of coordination among energy spot market (ESM), ancillary service market (ASM) and financial market (FM), i.e., the "joint market", and the lack of reliable simulation-based verification. To tackle these deficiencies, this two-part paper develops a paradigmatic theory and detailed methods of the joint market design using reinforcement-learning (RL)-based simulation. In Part 1, the theory and framework of this novel market design philosophy are proposed. First, the controversial market design options while designing the joint market are summarized as the targeted research questions. Second, the Markov game model is deve
    
[^52]: 使用机器学习技术的乳腺癌诊断

    Breast Cancer Diagnosis Using Machine Learning Techniques. (arXiv:2305.02482v1 [cs.LG])

    [http://arxiv.org/abs/2305.02482](http://arxiv.org/abs/2305.02482)

    本文回顾和讨论了来自不同源的最新机器学习技术在乳腺癌诊断中的应用，其中包括热成像、红外热成像、电阻抗层析成像以及血液检测中发现的生物标志物，这些技术比传统方法更快、更可靠和更便宜，并且机器学习技术能够提高诊断的准确性。

    

    乳腺癌是女性生命中最具威胁的疾病之一，因此早期和准确的诊断在减少患者死亡风险方面起着关键作用。最近计算工具、红外相机以及生物阻抗定量设备的最新进展，为其他参考技术的出现提供了机会，如热成像、红外热成像、电阻抗层析成像以及血液检测中发现的生物标志物，因此比其他方法更快、更可靠和更便宜。在过去的20年中，上述技术一直被认为是乳腺癌诊断的并行和扩展方法，许多作者得出结论，假阳性和假阴性率显著降低。此外，当筛查方法与临床诊断一起使用时，可以提高诊断的准确性。本文回顾和讨论了来自不同源的最新机器学习技术在乳腺癌诊断中的应用，考虑它们的性能、可用性和重要性。

    Breast cancer is one of the most threatening diseases in women's life; thus, the early and accurate diagnosis plays a key role in reducing the risk of death in a patient's life. Mammography stands as the reference technique for breast cancer screening; nevertheless, many countries still lack access to mammograms due to economic, social, and cultural issues. Latest advances in computational tools, infrared cameras and devices for bio-impedance quantification, have given a chance to emerge other reference techniques like thermography, infrared thermography, electrical impedance tomography and biomarkers found in blood tests, therefore being faster, reliable and cheaper than other methods. In the last two decades, the techniques mentioned above have been considered as parallel and extended approaches for breast cancer diagnosis, as well many authors concluded that false positives and false negatives rates are significantly reduced. Moreover, when a screening method works together with a c
    
[^53]: 面向海事领域概率知识图谱的自动构建

    Toward the Automated Construction of Probabilistic Knowledge Graphs for the Maritime Domain. (arXiv:2305.02471v1 [cs.AI])

    [http://arxiv.org/abs/2305.02471](http://arxiv.org/abs/2305.02471)

    该论文研究了海事领域的概率知识图谱的自动构建，以利用含有丰富信息的未结构化软数据，并解决了软数据提取方面的问题。

    

    国际海上犯罪变得越来越复杂，并常与更广泛的犯罪网络有关。仅融合与物理移动相关的数据（即由物理传感器或硬数据生成的数据）来检测海上威胁是不够的。这导致了研究和开发工作，旨在将硬数据与其他类型的数据（特别是人工生成的软数据）相结合。现有研究通常假设输入的软数据以结构化格式提供，或者集中于提取某些相关实体或概念以配合或注释硬数据。对于从未结构化格式（如情报报告和新闻文章）中提取与感兴趣情况隐含相关的丰富信息，关注度要少得多。为了利用这些来源中潜在有用和丰富的信息，需要提取不仅相关的实体和概念，还需要提取隐含于大量软数据中的相关情境的丰富知识。

    International maritime crime is becoming increasingly sophisticated, often associated with wider criminal networks. Detecting maritime threats by means of fusing data purely related to physical movement (i.e., those generated by physical sensors, or hard data) is not sufficient. This has led to research and development efforts aimed at combining hard data with other types of data (especially human-generated or soft data). Existing work often assumes that input soft data is available in a structured format, or is focused on extracting certain relevant entities or concepts to accompany or annotate hard data. Much less attention has been given to extracting the rich knowledge about the situations of interest implicitly embedded in the large amount of soft data existing in unstructured formats (such as intelligence reports and news articles). In order to exploit the potentially useful and rich information from such sources, it is necessary to extract not only the relevant entities and conc
    
[^54]: 探测行星信号的多重性增强分类器：使用ExoMiner的多重性增强验证69个新行星

    Multiplicity Boost Of Transit Signal Classifiers: Validation of 69 New Exoplanets Using The Multiplicity Boost of ExoMiner. (arXiv:2305.02470v1 [astro-ph.EP])

    [http://arxiv.org/abs/2305.02470](http://arxiv.org/abs/2305.02470)

    该论文介绍了一种可提高探测行星信号分类器性能的框架，称为多重性增强分类器，基于现有的分类器并使用多重性信息来验证69个新的系外行星。

    

    大多数已知的系外行星是通过验证技术而不是通过补充观测进行确认的。这些技术生成的分数通常代表了有关信号的某些信息（用x表示）给出的探测行星信号的概率（y（x）=行星）。这项工作引入了一种框架，即在给定的探测行星信号确认器的基础上，利用多重性信息改善其性能。我们将此框架应用于几个现有的分类器，包括vespa（Morton等人2016）、Robovetter（Coughlin等人2017）、AstroNet（Shallue和Vanderburg 2018）、ExoNet（Ansdel等人2018）、GPC和RFC（Armstrong等人2020）以及ExoMiner（Valizadegan等人2022），以支持我们的分类结果的有效性。

    Most existing exoplanets are discovered using validation techniques rather than being confirmed by complementary observations. These techniques generate a score that is typically the probability of the transit signal being an exoplanet (y(x)=exoplanet) given some information related to that signal (represented by x). Except for the validation technique in Rowe et al. (2014) that uses multiplicity information to generate these probability scores, the existing validation techniques ignore the multiplicity boost information. In this work, we introduce a framework with the following premise: given an existing transit signal vetter (classifier), improve its performance using multiplicity information. We apply this framework to several existing classifiers, which include vespa (Morton et al. 2016), Robovetter (Coughlin et al. 2017), AstroNet (Shallue & Vanderburg 2018), ExoNet (Ansdel et al. 2018), GPC and RFC (Armstrong et al. 2020), and ExoMiner (Valizadegan et al. 2022), to support our cl
    
[^55]: 系统模型和用户模型：探索人工智能面板设计

    The System Model and the User Model: Exploring AI Dashboard Design. (arXiv:2305.02469v1 [cs.HC])

    [http://arxiv.org/abs/2305.02469](http://arxiv.org/abs/2305.02469)

    论文探讨了基于神经网络的AI系统应该有面板以提高其可用性和安全性，并且界面应该具有基于系统模型和用户模型状态的并行显示。

    

    这是一篇关于界面设计和人工智能的推测性论文。最近，基于大语言模型的聊天机器人受到了广泛关注，包括被报道的不良交互。我们认为问题的部分原因是文本并不是所有你需要的东西：复杂的AI系统应该有面板，就像所有其他复杂的设备一样。假设基于神经网络的AI系统将包含可解释的周围世界方面的模型，我们讨论这些面板可能显示的数据。我们推测，对于许多系统来说，最重要的模型将是用户模型和系统模型。我们称之为“系统模型”和“用户模型”。我们认为，为了可用性和安全性，面向基于对话的AI系统的界面应该具有基于系统模型和用户模型状态的并行显示。找到识别、解释和显示这两个模型的方法应该是界面研究的核心部分。

    This is a speculative essay on interface design and artificial intelligence. Recently there has been a surge of attention to chatbots based on large language models, including widely reported unsavory interactions. We contend that part of the problem is that text is not all you need: sophisticated AI systems should have dashboards, just like all other complicated devices. Assuming the hypothesis that AI systems based on neural networks will contain interpretable models of aspects of the world around them, we discuss what data such dashboards might display. We conjecture that, for many systems, the two most important models will be of the user and of the system itself. We call these the System Model and User Model. We argue that, for usability and safety, interfaces to dialogue-based AI systems should have a parallel display based on the state of the System Model and the User Model. Finding ways to identify, interpret, and display these two models should be a core part of interface rese
    
[^56]: 处理布尔网络的最小陷阱空间的通用属性

    Tackling Universal Properties of Minimal Trap Spaces of Boolean Networks. (arXiv:2305.02442v1 [cs.LO])

    [http://arxiv.org/abs/2305.02442](http://arxiv.org/abs/2305.02442)

    本论文介绍了一种新方法——记数器示例引导的精炼抽象(CEGAR)，用于解决布尔网络的最小陷阱空间(MTSs)的通用属性的逻辑推理问题，同时可用于识别在所有MTSs上执行给定属性的布尔变量的永久冻结的重编程问题。

    

    最小陷阱空间(MTSs)捕捉布尔动态被困的子空间，无论更新模式如何，它们都对应于最让人满意的模式的吸引子。由于其多功能性，近年来计算MTSs已经引起了人们的关注，主要是通过重点关注其枚举来实现的。在本文中，我们讨论了MTS的通用属性的逻辑推理，并解决了两个问题：用于识别在所有MTSs上执行给定属性的布尔变量的永久冻结的重编程问题，并从其MTSs的通用属性合成布尔网络。这两个问题都归结为解决具有3个量化器($\exists\forall\exists$)的命题逻辑公式的可满足性。在本文中，我们引入了一个记数器示例引导的精炼抽象(CEGAR)来通过耦合解决两个更简单的公式来有效地解决这些问题。我们提供了一个原型，依赖于答案集编程来说明我们的方法的有效性。

    Minimal trap spaces (MTSs) capture subspaces in which the Boolean dynamics is trapped, whatever the update mode. They correspond to the attractors of the most permissive mode. Due to their versatility, the computation of MTSs has recently gained traction, essentially by focusing on their enumeration. In this paper, we address the logical reasoning on universal properties of MTSs in the scope of two problems: the reprogramming of Boolean networks for identifying the permanent freeze of Boolean variables that enforce a given property on all the MTSs, and the synthesis of Boolean networks from universal properties on their MTSs. Both problems reduce to solving the satisfiability of quantified propositional logic formula with 3 levels of quantifiers ($\exists\forall\exists$). In this paper, we introduce a Counter-Example Guided Refinement Abstraction (CEGAR) to efficiently solve these problems by coupling the resolution of two simpler formulas. We provide a prototype relying on Answer-Set 
    
[^57]: 运用自我记忆的检索增强文本生成模型

    Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory. (arXiv:2305.02437v1 [cs.CL])

    [http://arxiv.org/abs/2305.02437](http://arxiv.org/abs/2305.02437)

    本文提出了一种新的检索增强文本生成模型Selfmem，通过迭代生成自我记忆池并采用记忆选择器，使检索更加自适应，提高了文本生成的质量和多样性。

    

    相较于传统文本生成模型，检索增强文本生成模型能够直接迭代人类编写的参考库，并从中检索出相应的信息，以生成更优质的文本。但当前文献存在一个关键问题：检索到的记忆来自于固定的语料库，其质量存在一定局限性，可能会限制记忆增强模型的潜力。本文提出一种名为Selfmem的框架，该框架通过迭代地采用检索增强生成器自身以生成无限制的自我记忆池，并使用记忆选择器为下一轮生成选择一个生成的记忆。相结合，这两个主要问题提出了运用自我记忆的检索增强文本生成模型。

    With direct access to human-written reference as memory, retrieval-augmented generation has achieved much progress in a wide range of text generation tasks. Since better memory would typically prompt better generation~(we define this as primal problem), previous works mainly focus on how to retrieve better memory. However, one fundamental limitation exists for current literature: the memory is retrieved from a fixed corpus and is bounded by the quality of the corpus. Due to the finite retrieval space, bounded memory would greatly limit the potential of the memory-augmented generation model. In this paper, by exploring the duality of the primal problem: better generation also prompts better memory, we propose a framework called Selfmem, which iteratively adopts a retrieval-augmented generator itself to generate an unbounded memory pool and uses a memory selector to pick one generated memory for the next generation round. By combining the primal and dual problem, a retrieval-augmented ge
    
[^58]: PTP：利用基于扰动的正则化器提升Prompt Tuning的稳定性和性能

    PTP: Boosting Stability and Performance of Prompt Tuning with Perturbation-Based Regularizer. (arXiv:2305.02423v1 [cs.CL])

    [http://arxiv.org/abs/2305.02423](http://arxiv.org/abs/2305.02423)

    PTP算法引入基于扰动的正则化器来平滑loss图像，提升prompt tuning性能和稳定性，在四个测试数据集中获得了显著优于现有方法的表现。

    

    最近的研究表明，在下游自然语言理解任务上，使用prompt tuning比微调方法更能发挥大型语言模型的力量。然而，现有的prompt tuning方法存在训练不稳定性问题，因为不同随机种子下的分数方差相当大。为了解决这个关键问题，我们首先调查并发现，普通的prompt tuning的损失函数图像在可视化时呈峭壁状，输入数据的微小变化可以导致损失函数图像的剧烈波动。这是导致prompt tuning不稳定性的一个重要因素。基于这个观察结果，我们将平滑损失函数图像的基于扰动的正则化器引入到prompt tuning中。我们提出了一种名为PTP的新算法，它不仅可以显著减轻训练不稳定性，还可以提高prompt tuning的性能。我们设计了两种基于扰动的正则化器，并在四个受欢迎的NLU数据集上进行了广泛实验。实验结果表明，PTP在超级GLUE和GLUE上分别获得了高达3.9％和2.0％的性能提升，可明显优于现有的prompt tuning方法。此外，PTP还可以提高prompt tuning的鲁棒性，使多次运行获得的性能标准偏差更小。

    Recent studies show that prompt tuning can better leverage the power of large language models than fine-tuning on downstream natural language understanding tasks. However, the existing prompt tuning methods have training instability issues, as the variance of scores under different random seeds is quite large. To address this critical problem, we first investigate and find that the loss landscape of vanilla prompt tuning is precipitous when it is visualized, where a slight change of input data can cause a big fluctuation in the loss landscape. This is an essential factor that leads to the instability of prompt tuning. Based on this observation, we introduce perturbation-based regularizers, which can smooth the loss landscape, into prompt tuning. We propose a new algorithm, called Prompt Tuning with Perturbation-based regularizer~(PTP), which can not only alleviate training instability dramatically but also boost the performance of prompt tuning. We design two kinds of perturbation-base
    
[^59]: 计划、消除和跟踪——语言模型是具备体验的智能体的良师益友。

    Plan, Eliminate, and Track -- Language Models are Good Teachers for Embodied Agents. (arXiv:2305.02412v1 [cs.CL])

    [http://arxiv.org/abs/2305.02412](http://arxiv.org/abs/2305.02412)

    本文介绍了Plan，Eliminate，和Track（PET）框架，该框架利用预先训练的大型语言模型（LLM）帮助智能体简化控制任务，从而解决了LLM直接作为智能体所面临的一些限制和问题。

    

    预训练的大型语言模型(LLMs)可以捕捉到关于世界的程序化知识。最近的研究利用LLM产生的抽象计划来简化具有挑战性的控制任务，通过动作打分或动作建模（微调）来实现。然而，变压器架构继承了几个限制，使得LLM难以直接作为智能体：例如有限的输入长度，微调的效率，预训练的偏见以及与非文本环境的不兼容性。为了与低级别可训练的执行器保持兼容性，我们建议使用LLMs中的知识来简化控制问题，而不是解决问题。 我们提出了Plan，Eliminate和Track（PET）框架。计划模块将任务描述转化为高层次子任务的列表。消除模块从当前子任务的观察中屏蔽不相关的对象和容器。最后，跟踪模块确定智能体是否已经实现了当前子任务。

    Pre-trained large language models (LLMs) capture procedural knowledge about the world. Recent work has leveraged LLM's ability to generate abstract plans to simplify challenging control tasks, either by action scoring, or action modeling (fine-tuning). However, the transformer architecture inherits several constraints that make it difficult for the LLM to directly serve as the agent: e.g. limited input lengths, fine-tuning inefficiency, bias from pre-training, and incompatibility with non-text environments. To maintain compatibility with a low-level trainable actor, we propose to instead use the knowledge in LLMs to simplify the control problem, rather than solving it. We propose the Plan, Eliminate, and Track (PET) framework. The Plan module translates a task description into a list of high-level sub-tasks. The Eliminate module masks out irrelevant objects and receptacles from the observation for the current sub-task. Finally, the Track module determines whether the agent has accompli
    
[^60]: 特征工程能帮助量子机器学习进行恶意软件检测吗？

    Can Feature Engineering Help Quantum Machine Learning for Malware Detection?. (arXiv:2305.02396v1 [cs.LG])

    [http://arxiv.org/abs/2305.02396](http://arxiv.org/abs/2305.02396)

    本文通过量子机器学习与特征选择策略相结合的混合框架，以降低恶意软件分类器培训时间，初步结果表明在模拟器上可以达到78.91％的测试准确性。

    

    随着恶意软件攻击数量和复杂度的增加，基于机器学习（ML）的恶意软件检测系统变得越来越重要。同时，许多用于恶意软件分类的流行ML模型都是有监督学习。这些有监督分类器通常对新型恶意软件的推广效果不好。因此，需要经常重新训练它们以检测新的恶意软件样本，这可能非常耗时。本文通过理论量子ML与特征选择策略相结合的混合框架来解决这个问题，以降低数据大小和恶意软件分类器培训时间。初步结果表明，使用XGBoost选择的特征的VQC在模拟器上可以获得78.91％的测试准确性。使用XGBoost选择的特征训练的模型在IBM 5 qubits机器上的平均准确性为74％（+-11.35％）。

    With the increasing number and sophistication of malware attacks, malware detection systems based on machine learning (ML) grow in importance. At the same time, many popular ML models used in malware classification are supervised solutions. These supervised classifiers often do not generalize well to novel malware. Therefore, they need to be re-trained frequently to detect new malware specimens, which can be time-consuming. Our work addresses this problem in a hybrid framework of theoretical Quantum ML, combined with feature selection strategies to reduce the data size and malware classifier training time. The preliminary results show that VQC with XGBoost selected features can get a 78.91% test accuracy on the simulator. The average accuracy for the model trained using the features selected with XGBoost was 74% (+- 11.35%) on the IBM 5 qubits machines.
    
[^61]: 基于归因的防御插入式文本后门攻击

    Defending against Insertion-based Textual Backdoor Attacks via Attribution. (arXiv:2305.02394v1 [cs.CL])

    [http://arxiv.org/abs/2305.02394](http://arxiv.org/abs/2305.02394)

    本文提出了一种基于归因的管道AttDef，用于防御两种插入式污染攻击BadNL和InSent，该管道可以成功缓解插入式文本后门攻击并在四个基准数据集上平均提高了56.59%至79.97%和15.25%至48.34%的准确率。

    

    文本后门攻击是一种新型攻击模式，已被证明在训练期间向模型添加后门是有效的。防御此类后门攻击已变得紧迫和重要。本文提出了一种名为AttDef的高效归因管道，用于防御两种插入式污染攻击BadNL和InSent。具体而言，我们将具有较大归因分数的令牌视为潜在触发器，因为较大的归因词对于错误预测结果做出较大贡献，因此更有可能是污染触发器。此外，我们进一步利用外部预训练语言模型来区分输入是否被污染。我们展示了我们的方法可以在两种常见的攻击场景（污染训练数据和测试数据）中具有足够的泛化性，这一点持续改善了之前的方法。例如，AttDef在四个基准数据集上可以成功缓解两种攻击，平均准确率为79.97%（提高了56.59%）和48.34%（提高了15.25%），证明了它在防御插入式文本后门攻击方面的有效性。

    Textual backdoor attack, as a novel attack model, has been shown to be effective in adding a backdoor to the model during training. Defending against such backdoor attacks has become urgent and important. In this paper, we propose AttDef, an efficient attribution-based pipeline to defend against two insertion-based poisoning attacks, BadNL and InSent. Specifically, we regard the tokens with larger attribution scores as potential triggers since larger attribution words contribute more to the false prediction results and therefore are more likely to be poison triggers. Additionally, we further utilize an external pre-trained language model to distinguish whether input is poisoned or not. We show that our proposed method can generalize sufficiently well in two common attack scenarios (poisoning training data and testing data), which consistently improves previous methods. For instance, AttDef can successfully mitigate both attacks with an average accuracy of 79.97% (56.59% up) and 48.34% 
    
[^62]: 论知识图谱推理的安全风险

    On the Security Risks of Knowledge Graph Reasoning. (arXiv:2305.02383v1 [cs.CR])

    [http://arxiv.org/abs/2305.02383](http://arxiv.org/abs/2305.02383)

    本文介绍了一个重要的人工智能任务 - 知识图谱推理(KGR)，并基于攻击者的目的、知识和攻击向量概括了KGR的安全威胁。本文提出了一种新型攻击ROAR，高度有效地误导KGR向目标查询提供预定义答案，但对于非目标查询几乎没有影响。

    

    知识图谱推理 (KGR) - 回答大型知识图谱上复杂逻辑查询的任务，代表了一项重要的人工智能任务，涉及多种应用（例如网络威胁狩猎）。然而，尽管它越来越流行，但是 KGR 的潜在安全风险还未被广泛探讨，这一点令人担忧，因为它在安全关键领域的应用越来越广泛。本文是架起狭隘鸿沟的一个可靠的初始步骤。我们根据攻击者的目的、知识和攻击向量系统化地概括了 KGR 的安全威胁。此外，我们提出了 ROAR，一种新型攻击，它是实现各种此类威胁的攻击。通过在代表性用例（如医疗决策支持、网络威胁狩猎和常识推理）中的实证评估，我们证明 ROAR 对于误导 KGR 提供预定义答案的目标查询非常有效，但对非目标查询影响微乎其微。

    Knowledge graph reasoning (KGR) -- answering complex logical queries over large knowledge graphs -- represents an important artificial intelligence task, entailing a range of applications (e.g., cyber threat hunting). However, despite its surging popularity, the potential security risks of KGR are largely unexplored, which is concerning, given the increasing use of such capability in security-critical domains.  This work represents a solid initial step towards bridging the striking gap. We systematize the security threats to KGR according to the adversary's objectives, knowledge, and attack vectors. Further, we present ROAR, a new class of attacks that instantiate a variety of such threats. Through empirical evaluation in representative use cases (e.g., medical decision support, cyber threat hunting, and commonsense reasoning), we demonstrate that ROAR is highly effective to mislead KGR to suggest pre-defined answers for target queries, yet with negligible impact on non-target ones. Fi
    
[^63]: 应用于神经网络的敏感性分析度量工具

    Metric Tools for Sensitivity Analysis with Applications to Neural Networks. (arXiv:2305.02368v1 [cs.LG])

    [http://arxiv.org/abs/2305.02368](http://arxiv.org/abs/2305.02368)

    本文提出了一种度量框架和新的聚合指标，用于敏感性分析，可以适用于任何可微分模型。其中新的聚合指标基于三种方法获取有价值的信息，并在神经网络模型上进行了验证。

    

    随着机器学习模型被考虑用于拥有重大社会影响的自主决策，了解这些模型如何工作的需求迅速增长。可解释人工智能(XAI)旨在为机器学习模型所做的预测提供解释，以使该模型对用户更具可信度和透明度。本文提出了一个理论框架，使用度量技巧来研究敏感度分析。从这个度量框架开始，介绍了新的聚合指标，以根据三种方法从偏导数中获取有价值的信息：局部扰动分析、全局扰动分析和混合方法。这些指标适用于任何可微分模型，并且它们的性能在神经网络模型上进行了说明。

    As Machine Learning models are considered for autonomous decisions with significant social impact, the need for understanding how these models work rises rapidly. Explainable Artificial Intelligence (XAI) aims to provide interpretations for predictions made by Machine Learning models, in order to make the model trustworthy and more transparent for the user. For example, selecting relevant input variables for the problem directly impacts the model's ability to learn and make accurate predictions, so obtaining information about input importance play a crucial role when training the model. One of the main XAI techniques to obtain input variable importance is the sensitivity analysis based on partial derivatives. However, existing literature of this method provide no justification of the aggregation metrics used to retrieved information from the partial derivatives.  In this paper, a theoretical framework is proposed to study sensitivities of ML models using metric techniques. From this me
    
[^64]: Fashionpedia-Ads: 你喜欢的广告能透露你的时尚品味吗？

    Fashionpedia-Ads: Do Your Favorite Advertisements Reveal Your Fashion Taste?. (arXiv:2305.02360v1 [cs.CV])

    [http://arxiv.org/abs/2305.02360](http://arxiv.org/abs/2305.02360)

    本文探讨广告与时尚品味之间的相关性，并引入了一个新的数据集Fashionpedia-Ads，收集并注释了广告图像的情感、视觉和文本信息，以便未来的研究。

    

    在互联网上，消费者暴露于多个领域的广告中，如时尚、美容、汽车、食品等等。与此同时，时尚是第二大电子商务购物类别。消费者在各种时尚广告图片上的数字记录行为是否能透露出他们的时尚品味？来自其他领域的广告是否也能推断出他们的时尚品味？本文研究广告和时尚品味之间的相关性。为此，我们引入了一个新的数据集Fashionpedia-Ads，该数据集要求受试者提供对广告（时尚、美容、汽车和甜点）以及时尚产品（社交网络和电子商务款式）图像的偏好。此外，我们从多个角度（抽象级别、物理级别、标题和品牌）全面收集并注释广告图像上的情感、视觉和文本信息。我们开源了Fashionpedia-Ads，以便未来的研究，并鼓励更多的可解释性研究方法。

    Consumers are exposed to advertisements across many different domains on the internet, such as fashion, beauty, car, food, and others. On the other hand, fashion represents second highest e-commerce shopping category. Does consumer digital record behavior on various fashion ad images reveal their fashion taste? Does ads from other domains infer their fashion taste as well? In this paper, we study the correlation between advertisements and fashion taste. Towards this goal, we introduce a new dataset, Fashionpedia-Ads, which asks subjects to provide their preferences on both ad (fashion, beauty, car, and dessert) and fashion product (social network and e-commerce style) images. Furthermore, we exhaustively collect and annotate the emotional, visual and textual information on the ad images from multi-perspectives (abstractive level, physical level, captions, and brands). We open-source Fashionpedia-Ads to enable future studies and encourage more approaches to interpretability research bet
    
[^65]: 培育野性：机器中的技术多样性与野性

    Cultivated Wildness: Technodiversity and Wildness in Machines. (arXiv:2305.02328v1 [cs.AI])

    [http://arxiv.org/abs/2305.02328](http://arxiv.org/abs/2305.02328)

    本研究探讨了通过机器构建野生地点的框架，将机器理解为能够参与生产智能的活动代理。

    

    本文探讨了景观设计和人工智能交叉点上的培育野性的概念。本文认为，当代景观实践应该克服对野生状态单一理解的可能性，而是应该通过当代环境人文学、科学技术研究、生态学和景观建筑的思想和关注点，探索培育新形式的野生地点的景观策略。本文通过环境工程、计算机科学和景观建筑研究案例，探讨了构建具有智能机器的野生地点的框架。在这个框架中，机器不是被理解为一层“数字基础设施”，用于扩展本地化的人类智能和代理。相反，机器被概念化为能够参与共同生产智能的活动代理。近期的控制论技术发展，例如传感网络，人工智能等，开创了这种机器参与生产智能的可能性。

    This paper investigates the idea of cultivated wildness at the intersection of landscape design and artificial intelligence. The paper posits that contemporary landscape practices should overcome the potentially single understanding on wilderness, and instead explore landscape strategies to cultivate new forms of wild places via ideas and concerns in contemporary Environmental Humanities, Science and Technology Studies, Ecological Sciences, and Landscape Architecture. Drawing cases in environmental engineering, computer science, and landscape architecture research, this paper explores a framework to construct wild places with intelligent machines. In this framework, machines are not understood as a layer of "digital infrastructure" that is used to extend localized human intelligence and agency. Rather machines are conceptualized as active agents who can participate in the intelligence of co-production. Recent developments in cybernetic technologies such as sensing networks, artificial 
    
[^66]: 人工智能（AI）和机器学习（ML）在景观设计中的未来：以美国弗吉尼亚州海岸为例研究

    The Future of Artificial Intelligence (AI) and Machine Learning (ML) in Landscape Design: A Case Study in Coastal Virginia, USA. (arXiv:2305.02327v1 [cs.AI])

    [http://arxiv.org/abs/2305.02327](http://arxiv.org/abs/2305.02327)

    本论文以介绍使用机器学习技术在海岸环境中预测变量的案例为例，提供了未来景观设计中即将到来的网络环境的实证证据。设计师将不再是作家，而是智能代理中的编舞者、催化剂和指挥者。本文从后人类主义中获得灵感，认为要真正理解网络环境，我们必须采取后人类主义的伦理并克服人类的优越主义。

    

    在景观设计领域中，已经有一些理论性的尝试直接涉及到AI和ML。本文通过展示一个使用机器学习技术来预测海岸环境变量的案例，提供了即将到来的网络环境的实证证据。在这个环境中，设计师不再是作家，而是许多智能代理中的编舞者、催化剂和指挥者。本文从后人类主义的思想中获取灵感，认为要真正理解网络环境，我们必须采取后人类主义的伦理并克服人类的优越主义。

    There have been theory-based endeavours that directly engage with AI and ML in the landscape discipline. By presenting a case that uses machine learning techniques to predict variables in a coastal environment, this paper provides empirical evidence of the forthcoming cybernetic environment, in which designers are conceptualized not as authors but as choreographers, catalyst agents, and conductors among many other intelligent agents. Drawing ideas from posthumanism, this paper argues that, to truly understand the cybernetic environment, we have to take on posthumanist ethics and overcome human exceptionalism.
    
[^67]: 控制论环境：关于系统、设计和机器智能的历史反思

    Cybernetic Environment: A Historical Reflection on System, Design, and Machine Intelligence. (arXiv:2305.02326v1 [cs.AI])

    [http://arxiv.org/abs/2305.02326](http://arxiv.org/abs/2305.02326)

    本文以历史的视角回顾了控制论和系统思维的发展历程，并在介绍景观设计学科研究的谱系基础上指出景观设计师通过基于生态学的景观设计实现基于控制论原则的系统是控制论发展中的重要组成部分。本文呼吁建立一种新的环境参与范式，以理解设计和机器智能等问题。

    

    本文以历史的视角回顾了控制论和系统思维的发展历程，追溯到20世纪50年代，一群跨学科学者基于机器和系统创建了一个新的理论模型来理解意义、信息、意识和生命等问题。通过介绍景观设计学科研究的谱系，本文认为景观设计师通过基于生态学的景观设计在环境中实现基于控制论原则的系统，是控制论发展中的重要组成部分。景观学科已经发展出了一个设计框架，提供了深入理解机器智能的转化性洞见。本文呼吁建立一种新的环境参与范式，以理解设计和机器智能等问题。

    Taking on a historical lens, this paper traces the development of cybernetics and systems thinking back to the 1950s, when a group of interdisciplinary scholars converged to create a new theoretical model based on machines and systems for understanding matters of meaning, information, consciousness, and life. By presenting a genealogy of research in the landscape architecture discipline, the paper argues that landscape architects have been an important part of the development of cybernetics by materializing systems based on cybernetic principles in the environment through ecologically based landscape design. The landscape discipline has developed a design framework that provides transformative insights into understanding machine intelligence. The paper calls for a new paradigm of environmental engagement to understand matters of design and machine intelligence.
    
[^68]: ChatGPT能通过入门级函数式语言编程课程吗？

    Can ChatGPT Pass An Introductory Level Functional Language Programming Course?. (arXiv:2305.02230v1 [cs.CY])

    [http://arxiv.org/abs/2305.02230](http://arxiv.org/abs/2305.02230)

    本研究测试了ChatGPT在入门级函数式语言编程课程中的表现，结果显示它可以获得B-的成绩并且能够给学生和讲师带来潜在好处。

    

    ChatGPT的引入引起了工业界和学术界的广泛关注，因为它在解决各种任务，包括语言翻译、文本摘要和计算机编程方面具有卓越的能力。它编写、修改甚至纠正代码的能力加上其易于使用和访问已经对计算机科学教育产生了巨大影响。本文旨在探讨ChatGPT在入门级函数式语言编程课程中的表现。在我们的系统评估中，我们把ChatGPT视为我们的一名学生，并证明它可以获得B-的成绩，排名在314名学生中的第155位。我们的综合评估从学生和讲师的角度提供了有价值的见解。此外，我们还确定了ChatGPT可以为这两个群体提供的几个潜在好处。总体而言，我们认为本研究明确了ChatGPT在计算机科学教育中的应用价值。

    The recent introduction of ChatGPT has drawn significant attention from both industry and academia due to its impressive capabilities in solving a diverse range of tasks, including language translation, text summarization, and computer programming. Its capability for writing, modifying, and even correcting code together with its ease of use and access is already dramatically impacting computer science education. This paper aims to explore how well ChatGPT can perform in an introductory-level functional language programming course. In our systematic evaluation, we treated ChatGPT as one of our students and demonstrated that it can achieve a grade B- and its rank in the class is 155 out of 314 students overall. Our comprehensive evaluation provides valuable insights into ChatGPT's impact from both student and instructor perspectives. Additionally, we identify several potential benefits that ChatGPT can offer to both groups. Overall, we believe that this study significantly clarifies and 
    
[^69]: Doc2SoarGraph：基于语义导向分层图的富含视觉表格文档的离散推理

    Doc2SoarGraph: Discrete Reasoning over Visually-Rich Table-Text Documents with Semantic-Oriented Hierarchical Graphs. (arXiv:2305.01938v1 [cs.CL])

    [http://arxiv.org/abs/2305.01938](http://arxiv.org/abs/2305.01938)

    本文提出了 Doc2SoarGraph 框架，利用语义导向分层图结构中元素之间的差异和相关性，在富含视觉表格文本的TAT-DQA问题下实现了离散推理，表现出了最佳的实验结果。

    

    近两年来，对于表格文本文档（例如财务报告）的离散推理越来越受到关注。现有的工作大多通过手动选择和转换文档页面到结构化的表格和段落来简化这一挑战，从而阻碍其实际应用。在这项工作中，我们探究了一种更为现实的问题设置，即以 TAT-DQA 的形式回答富含视觉表格文本的问题。具体而言，我们提出了一种新颖的 Doc2SoarGraph 框架，通过利用语义导向分层图结构中不同元素之间的差异和相关性，提高了其离散推理能力。我们对 TAT-DQA 数据集进行了广泛的实验，结果显示，我们的提出的框架在测试集上的精确匹配（EM）和 F1 得分方面分别比最佳基线模型分别提高了 17.73% 和 16.91%，实现了新的最先进技术水平。

    Discrete reasoning over table-text documents (e.g., financial reports) gains increasing attention in recent two years. Existing works mostly simplify this challenge by manually selecting and transforming document pages to structured tables and paragraphs, hindering their practical application. In this work, we explore a more realistic problem setting in the form of TAT-DQA, i.e. to answer the question over a visually-rich table-text document. Specifically, we propose a novel Doc2SoarGraph framework with enhanced discrete reasoning capability by harnessing the differences and correlations among different elements (e.g., quantities, dates) of the given question and document with Semantic-oriented hierarchical Graph structures. We conduct extensive experiments on TAT-DQA dataset, and the results show that our proposed framework outperforms the best baseline model by 17.73% and 16.91% in terms of Exact Match (EM) and F1 score respectively on the test set, achieving the new state-of-the-art
    
[^70]: 改进句子嵌入的对比学习方法，利用人工智能反馈

    Improving Contrastive Learning of Sentence Embeddings from AI Feedback. (arXiv:2305.01918v1 [cs.CL])

    [http://arxiv.org/abs/2305.01918](http://arxiv.org/abs/2305.01918)

    本文提出了一种利用人工智能反馈改进句子嵌入对比学习方法的方式，可以提高对比学习样本对的质量，并结合人类反馈来提供更好的监督信号。

    

    对比学习已成为自然语言处理中句子嵌入学习中的流行方法。然而，自然语言的离散性使得通过数据增强方法生成的正负样本对的质量难以保证。虽然有监督的对比学习可以通过人类反馈标签生成更准确的样本对，但仍缺乏细粒度的训练信号。本文提出了一种基于AI反馈来改进句子嵌入对比学习的方法（CLAIF），利用大型预训练语言模型 (LLMs) 的AI反馈构建带有细粒度样本相似度分数的样本对，以改进对比学习。此外，我们结合人工反馈和AI反馈为对比学习中的句子嵌入提供更好的监督信号。实验结果表明，我们的方法达到了最先进的水平。

    Contrastive learning has become a popular approach in natural language processing, particularly for the learning of sentence embeddings. However, the discrete nature of natural language makes it difficult to ensure the quality of positive and negative sample pairs generated through data augmentation methods. Although supervised contrastive learning can produce more accurate sample pairs with human feedback labels, it still lacks fine-grained training signals. In this paper, we propose to improve \textbf{C}ontrastive \textbf{L}earning of sentence embeddings from \textbf{AI} \textbf{F}eedback \textbf{(CLAIF)}. Our method utilizes AI feedback from large pre-trained language models (LLMs) to construct sample pairs with fine-grained sample similarity scores to improve contrastive learning. Besides, we combine human feedback and AI feedback to provide better supervision signals for supervised contrastive learning of sentence embeddings. Experimental results show that our method achieves stat
    
[^71]: 基于因果感知的知识引导句子提取

    Causality-aware Concept Extraction based on Knowledge-guided Prompting. (arXiv:2305.01876v1 [cs.CL])

    [http://arxiv.org/abs/2305.01876](http://arxiv.org/abs/2305.01876)

    该论文提出了一种基于因果感知的知识引导提示方法，将其作为干预器装备到基于预训练语言模型的句子提取器中，以缓解概念偏差。在代表性的多语言KG数据集上进行广泛实验，获得了最先进的结果。

    

    概念有助于自然语言理解，但现有的知识图谱（KG）中远未完善。最近，预训练语言模型（PLM）已被广泛用于基于文本的概念提取（CE）。然而，PLM往往从大量语料库的共现关联中进行预训练知识挖掘，而非Token之间的真实因果关系。因此，预训练知识混淆了PLM，导致提取基于虚假共现相关性的有偏概念，不可避免地导致低精度。本文通过结构因果模型（SCM）提出了一种知识引导提示方法，将其作为干预器装备到基于PLM的提取器中，以减轻概念偏差。提示采用现有KG中的给定实体主题来缓解实体和有偏概念之间的虚假共现相关性。我们在代表性的多语言KG数据集上进行了广泛的实验，证明了我们提出的提示显著改进了提取性能，并达到了最先进的结果。

    Concepts benefit natural language understanding but are far from complete in existing knowledge graphs (KGs). Recently, pre-trained language models (PLMs) have been widely used in text-based concept extraction (CE). However, PLMs tend to mine the co-occurrence associations from massive corpus as pre-trained knowledge rather than the real causal effect between tokens.As a result, the pre-trained knowledge confounds PLMs to extract biased concepts based on spurious co-occurrence correlations, inevitably resulting in low precision. In this paper, through the lens of a Structural Causal Model (SCM), we propose equipping the PLM-based extractor with a knowledge-guided prompt as an intervention to alleviate concept bias. The prompt adopts the topic of the given entity from the existing knowledge in KGs to mitigate the spurious co-occurrence correlations between entities and biased concepts. Our extensive experiments on representative multilingual KG datasets justify that our proposed prompt 
    
[^72]: 基于少样本背景学习的知识库问答

    Few-shot In-context Learning for Knowledge Base Question Answering. (arXiv:2305.01750v1 [cs.CL])

    [http://arxiv.org/abs/2305.01750](http://arxiv.org/abs/2305.01750)

    该论文提出了KB-BINDER框架，通过少量的上下文演示实现了在多个知识库问答数据集上的背景学习，大大提高了KBQA问题的可解性。

    

    知识库问答被认为是一个难以解决的问题，因为需要应对各种可能的自然语言问题。此外，不同知识库架构项之间的异构性通常需要针对不同的知识库问答（KBQA）数据集进行专门的训练。为了处理多种KBQA数据集上的问题，我们提出了KB-BINDER，该框架可以进行少量样本的背景学习，并将不同的KBQA数据集统一。首先，KB-BINDER利用像Codex这样的大型语言模型通过模仿少量演示来生成特定问题的逻辑形式作为草稿。其次，KB-BINDER基于知识库来绑定生成的草稿至可执行形式，通过BM25分数匹配。在四个公开的异构KBQA数据集上的实验结果表明，KB-BINDER可以在少量上下文演示的情况下取得强大的性能，在某些情况下超过了最先进的方法。

    Question answering over knowledge bases is considered a difficult problem due to the challenge of generalizing to a wide variety of possible natural language questions. Additionally, the heterogeneity of knowledge base schema items between different knowledge bases often necessitates specialized training for different knowledge base question-answering (KBQA) datasets. To handle questions over diverse KBQA datasets with a unified training-free framework, we propose KB-BINDER, which for the first time enables few-shot in-context learning over KBQA tasks. Firstly, KB-BINDER leverages large language models like Codex to generate logical forms as the draft for a specific question by imitating a few demonstrations. Secondly, KB-BINDER grounds on the knowledge base to bind the generated draft to an executable one with BM25 score matching. The experimental results on four public heterogeneous KBQA datasets show that KB-BINDER can achieve a strong performance with only a few in-context demonstr
    
[^73]: 基于深度生成先验的数据集蒸馏方法的泛化

    Generalizing Dataset Distillation via Deep Generative Prior. (arXiv:2305.01649v1 [cs.CV])

    [http://arxiv.org/abs/2305.01649](http://arxiv.org/abs/2305.01649)

    该方法提出一种基于预训练深度生成模型的学习先验的数据集蒸馏方法，通过在生成模型的潜在空间中将大量图像蒸馏为少量中间特征向量，显著提高了在所有设置中的跨体系结构的泛化能力。

    

    数据集蒸馏旨在将整个数据集的知识蒸馏到几个合成图像中。其思想是合成少量的合成数据点，并将其作为训练数据提供给学习算法，以得到一个逼近原始数据训练的模型。尽管该领域最近取得了进展，但现有的数据集蒸馏方法无法推广到新的体系结构并扩展到高分辨率数据集。为了克服上述问题，我们建议使用预训练深度生成模型的学习先验来合成蒸馏的数据。为实现这一目的，我们提出了一种新的优化算法，在生成模型的潜在空间中将大量图像蒸馏为少量中间特征向量。我们的方法增强了现有技术，显著提高了在所有设置中的跨体系结构的泛化能力。

    Dataset Distillation aims to distill an entire dataset's knowledge into a few synthetic images. The idea is to synthesize a small number of synthetic data points that, when given to a learning algorithm as training data, result in a model approximating one trained on the original data. Despite recent progress in the field, existing dataset distillation methods fail to generalize to new architectures and scale to high-resolution datasets. To overcome the above issues, we propose to use the learned prior from pre-trained deep generative models to synthesize the distilled data. To achieve this, we present a new optimization algorithm that distills a large number of images into a few intermediate feature vectors in the generative model's latent space. Our method augments existing techniques, significantly improving cross-architecture generalization in all settings.
    
[^74]: 基于Option框架的多模式探索自主非单体智能体

    An Autonomous Non-monolithic Agent with Multi-mode Exploration based on Options Framework. (arXiv:2305.01322v1 [cs.AI])

    [http://arxiv.org/abs/2305.01322](http://arxiv.org/abs/2305.01322)

    该论文关注强化学习中的探索研究，提出了一个能够自主管理探索策略的多模式智能体非单体探索方法，并通过实验结果展示了该方法的优越性能。

    

    强化学习领域的探索研究主要关注“如何探索”的探索方式，而“何时探索”的探索研究一直没有成为重点。典型的探索行为通常将探索行为与智能体的开发利用行为绑定在一起。最近出现了非单体探索行为的研究，以研究人类和动物的模式切换行为。本研究的最终目的是使智能体能够自主决定何时探索或利用。我们在Option框架中描述了自主多模式探索的初始研究。通过比较实验结果，我们展示了我们的方法相对于现有的非单体探索方法的更高性能。

    Most exploration research on reinforcement learning (RL) has paid attention to `the way of exploration', which is `how to explore'. The other exploration research, `when to explore', has not been the main focus of RL exploration research. \textcolor{black}{The issue of `when' of a monolithic exploration in the usual RL exploration behaviour binds an exploratory action to an exploitational action of an agent. Recently, a non-monolithic exploration research has emerged to examine the mode-switching exploration behaviour of humans and animals.} The ultimate purpose of our research is to enable an agent to decide when to explore or exploit autonomously. We describe the initial research of an autonomous multi-mode exploration of non-monolithic behaviour in an options framework. The higher performance of our method is shown against the existing non-monolithic exploration method through comparative experimental results.
    
[^75]: 专业知识树在集体决策中解决知识局限性问题

    Expertise Trees Resolve Knowledge Limitations in Collective Decision-Making. (arXiv:2305.01063v1 [cs.AI])

    [http://arxiv.org/abs/2305.01063](http://arxiv.org/abs/2305.01063)

    本研究通过引入专业知识树算法，解决了集体决策中专业知识水平不同的问题，并在多个问题上进行了验证。

    

    向决策者提供建议的专家往往会显示出随问题实例变化而变化的专业知识水平。在实践中，这可能导致针对少数情况的次优或歧视性决策。在本文中，我们将这种知识深度和广度的变化建模为将问题空间划分为不同专业知识区域。我们提供了一些新算法，它们明确考虑并适应问题实例与专家知识之间的关系。我们首先提出并强调了一种基于最近邻查询的天真方法的缺点。为了解决这些问题，我们引入了一种新的算法——专业知识树，它构建决策树，使学习者能够选择适当的模型。我们提供了理论见解，并在一系列现有方法被证明不足以解决问题的问题上进行了经验证实了我们的新方法的改进性能。

    Experts advising decision-makers are likely to display expertise which varies as a function of the problem instance. In practice, this may lead to sub-optimal or discriminatory decisions against minority cases. In this work we model such changes in depth and breadth of knowledge as a partitioning of the problem space into regions of differing expertise. We provide here new algorithms that explicitly consider and adapt to the relationship between problem instances and experts' knowledge. We first propose and highlight the drawbacks of a naive approach based on nearest neighbor queries. To address these drawbacks we then introduce a novel algorithm - expertise trees - that constructs decision trees enabling the learner to select appropriate models. We provide theoretical insights and empirically validate the improved performance of our novel approach on a range of problems for which existing methods proved to be inadequate.
    
[^76]: 利用语义视觉先验解释视觉和语言生成模型

    Interpreting Vision and Language Generative Models with Semantic Visual Priors. (arXiv:2304.14986v1 [cs.CV])

    [http://arxiv.org/abs/2304.14986](http://arxiv.org/abs/2304.14986)

    本研究提出了一种利用SHAP框架和视觉先验知识生成全面、有意义解释的方法，相较于传统方法具有更低的计算成本、更高的解释表现力，并可以推广到其他模型上。

    

    在应用于图像到文本模型时，可解释性方法通常提供逐个标记的解释，即为所生成的序列中的每个标记计算视觉解释。这些解释计算成本高，无法全面解释模型的输出。因此，这些模型通常需要某种近似方法，最终会导致误导性的解释。本文提出了一种基于SHAP的框架，该框架允许利用输出序列的含义表示生成全面、有意义的解释。此外，通过利用视觉主干网络中的语义先验知识，我们提取了任意数量的特征，并能够在大规模模型上高效计算Shapley值，同时生成高度明确的视觉解释。我们证明了我们的方法在更低的计算成本下生成语义上更具表现力的解释，并且可以推广到其他模型上。

    When applied to Image-to-text models, interpretability methods often provide token-by-token explanations namely, they compute a visual explanation for each token of the generated sequence. Those explanations are expensive to compute and unable to comprehensively explain the model's output. Therefore, these models often require some sort of approximation that eventually leads to misleading explanations. We develop a framework based on SHAP, that allows for generating comprehensive, meaningful explanations leveraging the meaning representation of the output sequence as a whole. Moreover, by exploiting semantic priors in the visual backbone, we extract an arbitrary number of features that allows the efficient computation of Shapley values on large-scale models, generating at the same time highly meaningful visual explanations. We demonstrate that our method generates semantically more expressive explanations than traditional methods at a lower compute cost and that it can be generalized o
    
[^77]: FineEHR：优化临床记录表示以提高死亡预测能力

    FineEHR: Refine Clinical Note Representations to Improve Mortality Prediction. (arXiv:2304.11794v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2304.11794](http://arxiv.org/abs/2304.11794)

    FineEHR利用度量学习和微调技术来优化临床记录嵌入，以解决原始临床数据的复杂结构和噪声对预测算法准确性的限制。

    

    监测重症监护室(ICU)患者健康状况是提供优质医疗护理和治疗的关键。大规模电子病历(EHR)的出现为机器学习模型提供了丰富的临床文本和生命体征数据，使它们能够进行高度准确的预测。尽管现在有先进的自然语言处理(NLP)算法用于临床记录分析，但原始临床数据中的复杂文本结构和噪声仍带来了重大挑战。没有进行特定领域改进的粗略嵌入方法限制了这些算法的精确性。为了解决这个问题，我们提出了FINEEHR，这是一个系统，利用两种表示学习技术，即度量学习和微调，来优化临床记录嵌入，同时利用不同健康状态和记录类别之间的内在相关性。我们使用两个指标n...

    Monitoring the health status of patients in the Intensive Care Unit (ICU) is a critical aspect of providing superior care and treatment. The availability of large-scale electronic health records (EHR) provides machine learning models with an abundance of clinical text and vital sign data, enabling them to make highly accurate predictions. Despite the emergence of advanced Natural Language Processing (NLP) algorithms for clinical note analysis, the complex textual structure and noise present in raw clinical data have posed significant challenges. Coarse embedding approaches without domain-specific refinement have limited the accuracy of these algorithms. To address this issue, we propose FINEEHR, a system that utilizes two representation learning techniques, namely metric learning and fine-tuning, to refine clinical note embeddings, while leveraging the intrinsic correlations among different health statuses and note categories. We evaluate the performance of FINEEHR using two metrics, n
    
[^78]: 仅使用真实人脸自扰动检测对抗性人脸

    Detecting Adversarial Faces Using Only Real Face Self-Perturbations. (arXiv:2304.11359v1 [cs.CV])

    [http://arxiv.org/abs/2304.11359](http://arxiv.org/abs/2304.11359)

    本文提出了一种使用真实人脸自扰动生成伪对抗性人脸的方法，利用这种方法训练的对抗性人脸检测器不需攻击数据即可检测新型未知攻击。

    

    对抗性攻击旨在通过向输入样本添加特定噪声来扰乱目标系统的功能，当应用于人脸识别系统时，对安全性和稳健性带来潜在威胁。虽然现有的防御技术在检测某些特定的对抗性人脸（adv-faces）方面取得了高准确性，但具有完全不同噪声模式的新攻击方法尤其是基于 GAN 的攻击则绕过它们并达到更高的攻击成功率。更糟糕的是，现有技术需要攻击数据才能实现防御，使得防御者无法防御未被发现的新兴攻击。在本文中，我们研究了adv-faces的内在普遍性，通过使用三种启发式设计的噪声模式扰动真实人脸来生成伪对抗性人脸。我们是第一个仅使用真实人脸及其自扰动训练对抗性人脸检测器的研究，不受受害者人脸识别系统影响，也不受未知攻击影响。

    Adversarial attacks aim to disturb the functionality of a target system by adding specific noise to the input samples, bringing potential threats to security and robustness when applied to facial recognition systems. Although existing defense techniques achieve high accuracy in detecting some specific adversarial faces (adv-faces), new attack methods especially GAN-based attacks with completely different noise patterns circumvent them and reach a higher attack success rate. Even worse, existing techniques require attack data before implementing the defense, making it impractical to defend newly emerging attacks that are unseen to defenders. In this paper, we investigate the intrinsic generality of adv-faces and propose to generate pseudo adv-faces by perturbing real faces with three heuristically designed noise patterns. We are the first to train an adv-face detector using only real faces and their self-perturbations, agnostic to victim facial recognition systems, and agnostic to unsee
    
[^79]: 面部视频压缩的感知质量评估：基准和有效方法

    Perceptual Quality Assessment of Face Video Compression: A Benchmark and An Effective Method. (arXiv:2304.07056v1 [eess.IV])

    [http://arxiv.org/abs/2304.07056](http://arxiv.org/abs/2304.07056)

    本文介绍了大规模压缩面部视频质量评估（CFVQA）数据库，用于系统地了解面部视频感知质量和多样化压缩失真。生成式编码方法被确定为具有合理的感知码率失真折衷的有前途的替代方法，利用面部视频的统计先验知识。

    

    近年来，对面部视频压缩的需求呈指数级增长，人工智能的成功使得超出了传统的混合视频编码范围。生成式编码方法被确定为具有合理的感知码率失真折衷的有前途的替代方法，利用面部视频的统计先验知识。然而，空间和时间域中扭曲类型的极大多样性，从传统的混合编码框架到生成模型，给压缩面部视频质量评估（VQA）带来了巨大挑战。在本文中，我们介绍了大规模压缩面部视频质量评估（CFVQA）数据库，这是系统地了解面部视频感知质量和多样化压缩失真的第一次尝试。该数据库包含 3,240 个压缩的面部视频片段，涵盖多个压缩级别，这些片段来自 135 个源视频，具有多样性。

    Recent years have witnessed an exponential increase in the demand for face video compression, and the success of artificial intelligence has expanded the boundaries beyond traditional hybrid video coding. Generative coding approaches have been identified as promising alternatives with reasonable perceptual rate-distortion trade-offs, leveraging the statistical priors of face videos. However, the great diversity of distortion types in spatial and temporal domains, ranging from the traditional hybrid coding frameworks to generative models, present grand challenges in compressed face video quality assessment (VQA). In this paper, we introduce the large-scale Compressed Face Video Quality Assessment (CFVQA) database, which is the first attempt to systematically understand the perceptual quality and diversified compression distortions in face videos. The database contains 3,240 compressed face video clips in multiple compression levels, which are derived from 135 source videos with diversif
    
[^80]: 野外人脸防伪挑战赛2023：基准和结果

    Wild Face Anti-Spoofing Challenge 2023: Benchmark and Results. (arXiv:2304.05753v1 [cs.CV])

    [http://arxiv.org/abs/2304.05753](http://arxiv.org/abs/2304.05753)

    前人的人脸防伪（FAS）技术应用于实际场景仍然存在限制，因为当前公开的FAS数据集数量和多样性不足，引起过拟合和场景误判。通过引入野外人脸防伪（WFAS）数据集，该研究提高了数据规模和多样化程度，促进了FAS技术的发展。

    

    人脸防伪（FAS）是保护自动人脸识别系统完整性的重要机制。尽管有了重大进展，但将现有方法推广到实际应用仍然具有挑战性。这种限制可以归因于公开可用的FAS数据集的稀缺性和缺乏多样性，这经常导致训练期间过拟合或测试期间饱和。就数量而言，欺诈主体的数量是一个重要的决定因素。大多数数据集仅包括少于2,000个受试者。就多样性而言，大多数数据集由在受控环境中使用重复机械化过程收集的欺诈样本组成。这种数据收集方法导致同质化样本和场景多样性的匮乏。为了解决这些缺点，我们介绍了野外人脸防伪（WFAS）数据集，这是一个大规模的、多样化的FAS数据集，可在不受限制的情况下收集。

    Face anti-spoofing (FAS) is an essential mechanism for safeguarding the integrity of automated face recognition systems. Despite substantial advancements, the generalization of existing approaches to real-world applications remains challenging. This limitation can be attributed to the scarcity and lack of diversity in publicly available FAS datasets, which often leads to overfitting during training or saturation during testing. In terms of quantity, the number of spoof subjects is a critical determinant. Most datasets comprise fewer than 2,000 subjects. With regard to diversity, the majority of datasets consist of spoof samples collected in controlled environments using repetitive, mechanical processes. This data collection methodology results in homogenized samples and a dearth of scenario diversity. To address these shortcomings, we introduce the Wild Face Anti-Spoofing (WFAS) dataset, a large-scale, diverse FAS dataset collected in unconstrained settings. Our dataset encompasses 853
    
[^81]: 生成AI用于学习：研究合成学习视频的潜力。

    Generative AI for learning: Investigating the potential of synthetic learning videos. (arXiv:2304.03784v1 [cs.CV])

    [http://arxiv.org/abs/2304.03784](http://arxiv.org/abs/2304.03784)

    本研究探讨了使用生成AI合成视频来创建在线教育内容的效用，使用混合方法和成年学习者进行实验。结果显示，合成学习视频对学习内容获取和学习体验有着积极的影响。

    

    最近，生成人工智能（AI）的最新进展已经引起了全球的关注。像Dalle-2和ChatGPT这样的工具表明，以前被认为超出了AI能力的任务现在可以以各种新方式增加创意媒体的生产力，包括生成合成视频。本研究探讨了使用生成AI合成视频来创建在在线教育环境下可行的教育内容的效用。到目前为止，还没有研究调查AI生成的合成媒体在现实世界中的教育价值。为了填补这一空白，我们采用混合方法随机将成年学习者（n = 83）分配到两种微型学习条件之一，收集前后学习评估，并调查参与者的学习体验。控制组

    Recent advances in generative artificial intelligence (AI) have captured worldwide attention. Tools such as Dalle-2 and ChatGPT suggest that tasks previously thought to be beyond the capabilities of AI may now augment the productivity of creative media in various new ways, including through the generation of synthetic video. This research paper explores the utility of using AI-generated synthetic video to create viable educational content for online educational settings. To date, there is limited research investigating the real-world educational value of AI-generated synthetic media. To address this gap, we examined the impact of using AI-generated synthetic video in an online learning platform on both learners content acquisition and learning experience. We took a mixed-method approach, randomly assigning adult learners (n=83) into one of two micro-learning conditions, collecting pre- and post-learning assessments, and surveying participants on their learning experience. The control c
    
[^82]: 重新审视带有无法回答的反事实情景的密集检索

    Revisiting Dense Retrieval with Unanswerable Counterfactuals. (arXiv:2304.03031v1 [cs.AI])

    [http://arxiv.org/abs/2304.03031](http://arxiv.org/abs/2304.03031)

    本文观察到基于DPR的最近的密集检索模型经常将无法回答的反事实情景排名高于可回答的原始情景，提出了一种新颖的用于段落检索的表示学习方法PiCL。

    

    在开放领域问答（ODQA）中，检索器-阅读器框架很受欢迎，其中检索器从大型语料库中为阅读器抽取一组相关的候选段落。这种方法背后的一个关键假设是，从检索器得到的高相关性分数可能表明从阅读器获取答案的可能性很高，这意味着检索到的段落很可能包含给定问题的答案。我们在本研究中实证驳斥了这种观点，并观察到基于DPR的最近的密集检索模型经常将无法回答的反事实情景排名高于可回答的原始情景。为了解决密集检索中这种对答案无感知的问题，我们寻求使用反事实样本作为额外的训练资源，以更好地同步DPR的相关性测量和问题-段落对的可答性。具体地，我们提出了反事实Pivoting对比学习（PiCL），这是一种新颖的用于段落检索的表示学习方法。

    The retriever-reader framework is popular for open-domain question answering (ODQA), where a retriever samples for the reader a set of relevant candidate passages from a large corpus. A key assumption behind this method is that high relevance scores from the retriever likely indicate high answerability from the reader, which implies a high probability that the retrieved passages contain answers to a given question. In this work, we empirically dispel this belief and observe that recent dense retrieval models based on DPR often rank unanswerable counterfactual passages higher than their answerable original passages. To address such answer-unawareness in dense retrievers, we seek to use counterfactual samples as additional training resources to better synchronize the relevance measurement of DPR with the answerability of question-passage pairs. Specifically, we present counterfactually-Pivoting Contrastive Learning (PiCL), a novel representation learning approach for passage retrieval th
    
[^83]: 大型语言模型综述

    A Survey of Large Language Models. (arXiv:2303.18223v1 [cs.CL])

    [http://arxiv.org/abs/2303.18223](http://arxiv.org/abs/2303.18223)

    本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。

    

    语言本质上是一个由语法规则控制的复杂精细的人类表达系统，对于开发理解和掌握语言的能力的AI算法来说是一项重大挑战。作为主要方法之一，语言建模在过去二十年里广泛研究用于语言理解和生成，从统计语言模型演化为神经语言模型。最近，通过在大规模语料库上预训练Transformer模型，提出了预训练语言模型（PLMs），在解决各种NLP任务方面显示出强大的能力。由于研究人员发现模型缩放可以导致性能改进，他们进一步通过增加模型规模来研究缩放效应，有趣的是，当参数规模超过一定水平时，这些扩大的语言模型不仅可以实现显着的性能提升，而且还显示出一些小规模语言模型所没有的特殊能力。

    Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale langu
    
[^84]: Sigmoid Loss用于语言图像预训练

    Sigmoid Loss for Language Image Pre-Training. (arXiv:2303.15343v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.15343](http://arxiv.org/abs/2303.15343)

    本论文提出了适用于语言图像预训练的成对Sigmoid损失函数，可以有效地提高训练批量大小，同时不需要全局查看配对相似性进行归一化，其训练出来的模型在ImageNet上表现良好。

    

    我们提出了一种简单的成对Sigmoid损失函数，用于图像-文本预训练。与标准的具有softmax归一化的对比学习不同，Sigmoid损失只操作图像-文本对，不需要全局查看配对相似性以进行归一化。Sigmoid损失同时使批量大小进一步增加，并可在较小的批量大小下表现更好。仅使用四个TPUv4芯片，我们就能在4k批量大小下训练出一个Base CLIP模型和在20k批量大小下训练出一个大规模LiT模型，后者在两天内实现了84.5%的ImageNet零样本准确率。这种损失函数将批量大小与损失函数分离，使我们能够研究示例与对之间、负-正例比率的影响。最后，我们将批量大小推到极限，高达一百万，发现扩大批量大小的好处很快就会减弱，32k批量大小已经足够。我们希望我们的研究能够激发进一步探索如何提高质量的研究。

    We propose a simple pairwise sigmoid loss for image-text pre-training. Unlike standard contrastive learning with softmax normalization, the sigmoid loss operates solely on image-text pairs and does not require a global view of the pairwise similarities for normalization. The sigmoid loss simultaneously allows further scaling up the batch size, while also performing better at smaller batch sizes. With only four TPUv4 chips, we can train a Base CLIP model at 4k batch size and a Large LiT model at 20k batch size, the latter achieves 84.5% ImageNet zero-shot accuracy in two days. This disentanglement of the batch size from the loss further allows us to study the impact of examples vs pairs and negative to positive ratio. Finally, we push the batch size to the extreme, up to one million, and find that the benefits of growing batch size quickly diminish, with a more reasonable batch size of 32k being sufficient. We hope our research motivates further explorations in improving the quality and
    
[^85]: DR.CPO：通过迭代构建、随机放置和 HPR 遮蔽实现的多样化和逼真的三维增强

    DR.CPO: Diversified and Realistic 3D Augmentation via Iterative Construction, Random Placement, and HPR Occlusion. (arXiv:2303.12743v1 [cs.CV])

    [http://arxiv.org/abs/2303.12743](http://arxiv.org/abs/2303.12743)

    该论文提出了一种多样化和逼真的增强方法，可以创建整体对象并灵活地定位和旋转对象，并相应地应用自遮挡和外遮挡。通过迭代构建多个对象来提高整体对象构造的多样性，构造的对象可以在训练帧中随机放置和旋转。

    

    在自动驾驶中，数据增强常用于改进三维物体检测。最基本的方法包括插入复制对象和旋转和缩放整个训练帧。也已经开发了许多变体。然而，现有方法与现实世界的可能性相比相当有限。在这项工作中，我们开发了一种多样化和逼真增强方法，可以灵活地构造整体对象，自由地定位和旋转对象，并相应地应用自遮挡和外遮挡。为了提高整体对象构造的多样性，我们开发了一种迭代方法，将从现实世界观察到的多个对象随机组合成单个对象。与现有增强方法不同的是，构造的对象可以随机放置和旋转在训练帧中，因为适当的遮挡可以反映在最终整体对象中。最后，为了防止过度增强导致过拟合，我们介绍了一种分层遮挡概率设置，通过对象的位置和大小调整遮挡强度。

    In autonomous driving, data augmentation is commonly used for improving 3D object detection. The most basic methods include insertion of copied objects and rotation and scaling of the entire training frame. Numerous variants have been developed as well. The existing methods, however, are considerably limited when compared to the variety of the real world possibilities. In this work, we develop a diversified and realistic augmentation method that can flexibly construct a whole-body object, freely locate and rotate the object, and apply self-occlusion and external-occlusion accordingly. To improve the diversity of the whole-body object construction, we develop an iterative method that stochastically combines multiple objects observed from the real world into a single object. Unlike the existing augmentation methods, the constructed objects can be randomly located and rotated in the training frame because proper occlusions can be reflected to the whole-body objects in the final step. Fina
    
[^86]: 面向领域的预训练提高了整张切片图像分类的信心

    Domain-Specific Pre-training Improves Confidence in Whole Slide Image Classification. (arXiv:2302.09833v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.09833](http://arxiv.org/abs/2302.09833)

    本文研究了面向领域的预训练对整张切片图像分类的作用，发现使用面向领域的预训练可以提高多实例学习模型在切片图像分类任务中的性能。

    

    整张切片图像或组织病理学图像在数字病理学中被广泛使用。由于其大小和缺乏像素级注释，整张切片图像对于临床诊断的深度学习模型构成了巨大挑战。最近在计算病理学领域，提出了基于多实例学习的新模型。多实例学习需要创建补丁，并使用这些补丁的编码进行诊断。这些模型使用通用的预训练模型（在ImageNet上预训练的ResNet-50）进行补丁编码。最近提出的KimiaNet是一种基于DenseNet121的面向领域的预训练模型，该模型是在TCGA切片上进行预训练的。本文展示了面向领域的预训练对整张切片图像分类的影响。为了调查面向领域的预训练的效果，我们考虑了当前最先进的多实例学习模型：1）基于注意力的CLAM模型和2）自注意的TransMIL模型，并评估了模型的性能。

    Whole Slide Images (WSIs) or histopathology images are used in digital pathology. WSIs pose great challenges to deep learning models for clinical diagnosis, owing to their size and lack of pixel-level annotations. With the recent advancements in computational pathology, newer multiple-instance learning-based models have been proposed. Multiple-instance learning for WSIs necessitates creating patches and uses the encoding of these patches for diagnosis. These models use generic pre-trained models (ResNet-50 pre-trained on ImageNet) for patch encoding. The recently proposed KimiaNet, a DenseNet121 model pre-trained on TCGA slides, is a domain-specific pre-trained model. This paper shows the effect of domain-specific pre-training on WSI classification. To investigate the effect of domain-specific pre-training, we considered the current state-of-the-art multiple-instance learning models, 1) CLAM, an attention-based model, and 2) TransMIL, a self-attention-based model, and evaluated the mod
    
[^87]: 开发用于结肠生长诊断的沉浸式虚拟结肠镜查看器

    Development of an Immersive Virtual Colonoscopy Viewer for Colon Growths Diagnosis. (arXiv:2302.02946v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2302.02946](http://arxiv.org/abs/2302.02946)

    本文开发了一种用于结肠生长诊断的沉浸式虚拟结肠镜查看器，并通过实验确定了其覆盖范围、持续时间和诊断准确性等方面的影响。

    

    桌面虚拟结肠镜已被证明在发现结肠异常方面是一种有用的工具。虽然这一过程准确，但耗时较长。沉浸式界面在虚拟结肠镜中的应用尚处于初步阶段，尚未被充分理解。本文提出了一个新的设计，探索虚拟现实范式元素，以使沉浸式分析更加高效而仍然有效。我们还计划进行专家实验，评估覆盖范围、持续时间和诊断准确性等多个因素的影响。

    Desktop-based virtual colonoscopy has been proven to be an asset in the identification of colon anomalies. The process is accurate, although time-consuming. The use of immersive interfaces for virtual colonoscopy is incipient and not yet understood. In this work, we present a new design exploring elements of the VR paradigm to make the immersive analysis more efficient while still effective. We also plan the conduction of experiments with experts to assess the multi-factor influences of coverage, duration, and diagnostic accuracy.
    
[^88]: Transformers训练的高效方法综述

    A Survey on Efficient Training of Transformers. (arXiv:2302.01107v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01107](http://arxiv.org/abs/2302.01107)

    本文是对高效训练Transformer领域的系统综述，分析和比较了在训练中为中间张量节省计算和内存成本的方法与硬件/算法共同设计的技术，并探讨了未来研究的挑战和前景。

    

    近年来，Transformers的发展为计算资源提出了巨大要求，强调了开发高效训练技术以通过有效利用计算和内存资源使Transformer的训练更快、更低成本且更高精度的重要性。本研究提供了高效训练Transformer的首个系统综述，覆盖了加速算术和硬件领域的最新进展，重点关注前者。我们分析和比较了在训练期间为中间张量节省计算和内存成本的方法，以及硬件/算法共同设计的技术。最后，我们讨论了未来研究的挑战和有前途的领域。

    Recent advances in Transformers have come with a huge requirement on computing resources, highlighting the importance of developing efficient training techniques to make Transformer training faster, at lower cost, and to higher accuracy by the efficient use of computation and memory resources. This survey provides the first systematic overview of the efficient training of Transformers, covering the recent progress in acceleration arithmetic and hardware, with a focus on the former. We analyze and compare methods that save computation and memory costs for intermediate tensors during training, together with techniques on hardware/algorithm co-design. We finally discuss challenges and promising areas for future research.
    
[^89]: 学习保持拓扑结构的数据表示

    Learning Topology-Preserving Data Representations. (arXiv:2302.00136v2 [cs.LG] CROSS LISTED)

    [http://arxiv.org/abs/2302.00136](http://arxiv.org/abs/2302.00136)

    本文提出了一种名为RTD-AE的方法用于学习保持数据拓扑结构的降维表示,在保留全局结构和拓扑性方面，其表现优于现有最先进竞争对手。

    

    本文提出了一种用于学习拓扑保持数据表示（降维）的方法。该方法旨在通过强制拓扑特征（聚类、环、2D空洞等）及其本地化的相似性提供数据流形和其潜在表示之间的拓扑相似性。该方法的核心是在潜在空间中在原始高维数据和低维表示之间最小化表示拓扑散度（RTD）。RTD最小化提供了强有力的理论保证，拓扑特征的相似性。我们开发了一种RTD分化方案，并将其应用为自编码器损失项。 RTD-AE方法与现有最先进竞争对手相比，通过线性相关、三重距离排名准确性以及持久条形码之间的Wasserstein距离等测量，更好地保留了数据流形的全局结构和拓扑性。

    We propose a method for learning topology-preserving data representations (dimensionality reduction). The method aims to provide topological similarity between the data manifold and its latent representation via enforcing the similarity in topological features (clusters, loops, 2D voids, etc.) and their localization. The core of the method is the minimization of the Representation Topology Divergence (RTD) between original high-dimensional data and low-dimensional representation in latent space. RTD minimization provides closeness in topological features with strong theoretical guarantees. We develop a scheme for RTD differentiation and apply it as a loss term for the autoencoder. The proposed method "RTD-AE" better preserves the global structure and topology of the data manifold than state-of-the-art competitors as measured by linear correlation, triplet distance ranking accuracy, and Wasserstein distance between persistence barcodes.
    
[^90]: 大型语言模型可被视为隐含的主题模型：解释和寻找好的示范以实现上下文学习

    Large Language Models Are Implicitly Topic Models: Explaining and Finding Good Demonstrations for In-Context Learning. (arXiv:2301.11916v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.11916](http://arxiv.org/abs/2301.11916)

    本研究发现，大型语言模型可以被视为隐式的主题模型，并提出了一种算法，从注释数据中选择最佳示范，大大提高了上下文学习的能力。

    

    近年来，预训练的大型语言模型表现出了在推理时实现少量样本学习能力的显著效率，被称为上下文学习。 然而，现有文献强调这种能力对少量样本示范的选择很敏感。本研究旨在通过贝叶斯视角研究上下文学习现象，将大型语言模型视为从示范中隐含地推断出相关信息的主题模型。在此前提下，我们提出了一种算法，用于从一组注释数据中选择最佳示范，并证明相对于随机选择基线的平均值，在八个不同的真实文本分类数据集上平均每个 GPT2 和 GPT3 模型有显着的 12.5% 的提升。我们的实证发现支持我们的假设，即大型语言模型可被视为隐含的主题模型。

    In recent years, pre-trained large language models have demonstrated remarkable efficiency in achieving an inference-time few-shot learning capability known as in-context learning. However, existing literature has highlighted the sensitivity of this capability to the selection of few-shot demonstrations. The underlying mechanisms by which this capability arises from regular language model pretraining objectives remain poorly understood. In this study, we aim to examine the in-context learning phenomenon through a Bayesian lens, viewing large language models as topic models that implicitly infer task-related information from demonstrations. On this premise, we propose an algorithm for selecting optimal demonstrations from a set of annotated data and demonstrate a significant 12.5% improvement relative to the random selection baseline, averaged over eight GPT2 and GPT3 models on eight different real-world text classification datasets. Our empirical findings support our hypothesis that la
    
[^91]: 广义目标搜索

    Generalized Object Search. (arXiv:2301.10121v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2301.10121](http://arxiv.org/abs/2301.10121)

    该论文介绍了一种基于POMDP模型和人类世界结构以及人机交互的结构，可以实现实际有效的广义目标搜索系统。

    

    未来的协作机器人必须具备寻找物体的能力。作为一项基本技能，我们预计目标搜索最终会成为任何机器人的现成能力，类似于物体检测、SLAM和运动规划等。然而，现有的方法要么做出不切实际的妥协（例如将问题从3D缩减到2D），要么采用专门的贪婪搜索策略，或者试图在模拟中学习端到端策略，这些策略尚未在真实机器人和环境中得到推广。该论文认为，通过利用部分可观测马尔可夫决策过程（POMDP）来建模目标搜索，同时利用人类世界（例如八叉树、相关性）和人机交互中的结构（例如空间语言），可以实现一种实用有效的广义目标搜索系统。为了支持这一论点，我开发了在有限视野、遮挡和噪声存在的不确定性下，在3D环境中进行（多个）目标搜索的方法和系统，并在模拟和真实场景中进行了评估。

    Future collaborative robots must be capable of finding objects. As such a fundamental skill, we expect object search to eventually become an off-the-shelf capability for any robot, similar to e.g., object detection, SLAM, and motion planning. However, existing approaches either make unrealistic compromises (e.g., reduce the problem from 3D to 2D), resort to ad-hoc, greedy search strategies, or attempt to learn end-to-end policies in simulation that are yet to generalize across real robots and environments. This thesis argues that through using Partially Observable Markov Decision Processes (POMDPs) to model object search while exploiting structures in the human world (e.g., octrees, correlations) and in human-robot interaction (e.g., spatial language), a practical and effective system for generalized object search can be achieved. In support of this argument, I develop methods and systems for (multi-)object search in 3D environments under uncertainty due to limited field of view, occlu
    
[^92]: 通过训练动态理解基于坐标的MLPs的谱偏置

    Understanding the Spectral Bias of Coordinate Based MLPs Via Training Dynamics. (arXiv:2301.05816v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.05816](http://arxiv.org/abs/2301.05816)

    该论文研究了基于坐标的MLPs的谱偏置对高频组件收敛的阻碍，并提出使用高频正弦波编码输入来克服这一限制。

    

    谱偏置是神经网络训练的重要观察结果，它表示网络在收敛到更高频率组件前，会学习目标函数的低频表示。这一属性与超参数网络的良好泛化能力有关，但在应用于场景渲染时，采用具有ReLU激活的多层感知器(MLPs)利用密集的低维坐标输入会导致严重的谱偏差，完全阻碍了收敛到高频组件。为了克服这个限制，可以使用高频正弦波编码输入。以前的研究试图使用神经切向核(NTK)和傅里叶分析来解释坐标系中的谱偏差及其严重性。然而，这种方法存在各种限制，因为NTK不能捕捉到真正的网络动态，而傅里叶分析只能提供对频率组件的全局视角。

    Spectral bias is an important observation of neural network training, stating that the network will learn a low frequency representation of the target function before converging to higher frequency components. This property is interesting due to its link to good generalization in over-parameterized networks. However, in applications to scene rendering, where multi-layer perceptrons (MLPs) with ReLU activations utilize dense, low dimensional coordinate based inputs, a severe spectral bias occurs that obstructs convergence to high freqeuncy components entirely. In order to overcome this limitation, one can encode the inputs using high frequency sinusoids. Previous works attempted to explain both spectral bias and its severity in the coordinate based regime using Neural Tangent Kernel (NTK) and Fourier analysis. However, such methods come with various limitations, since NTK does not capture real network dynamics, and Fourier analysis only offers a global perspective on the frequency compo
    
[^93]: 使用语言模型提示进行推理：一项调查

    Reasoning with Language Model Prompting: A Survey. (arXiv:2212.09597v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09597](http://arxiv.org/abs/2212.09597)

    本文提供了使用语言模型提示进行推理的前沿研究综合调查。讨论了新兴推理能力出现的潜在原因，并提供系统资源帮助初学者。

    

    推理作为复杂问题解决的重要能力，可以为医疗诊断、谈判等各种实际应用提供后端支持。本文对使用语言模型提示进行推理的前沿研究进行了综合调查。我们介绍了研究成果的比较和总结，并提供了系统资源以帮助初学者。我们还讨论了新兴推理能力出现的潜在原因，并突出了未来的研究方向。资源可在 https://github.com/zjunlp/Prompt4ReasoningPapers 上获取（定期更新）。

    Reasoning, as an essential ability for complex problem-solving, can provide back-end support for various real-world applications, such as medical diagnosis, negotiation, etc. This paper provides a comprehensive survey of cutting-edge research on reasoning with language model prompting. We introduce research works with comparisons and summaries and provide systematic resources to help beginners. We also discuss the potential reasons for emerging such reasoning abilities and highlight future research directions. Resources are available at https://github.com/zjunlp/Prompt4ReasoningPapers (updated periodically).
    
[^94]: xTrimoABFold：无多序列比对的新型抗体结构预测方法

    xTrimoABFold: De novo Antibody Structure Prediction without MSA. (arXiv:2212.00735v2 [q-bio.QM] CROSS LISTED)

    [http://arxiv.org/abs/2212.00735](http://arxiv.org/abs/2212.00735)

    xTrimoABFold是一种基于深度抗体语言模型的新型抗体结构预测方法，无需多序列比对，有望促进高通量药物设计的应用。

    

    在抗体工程领域，设计一个新型抗体以正确地结合特定抗原的表位是一项重要的任务。了解抗体结构和其表位可以促进对其功能的机制理解。因此，从其序列预测抗体结构一直是一项高度有价值的任务，而AlphaFold2提供了一种基于蛋白质序列预测蛋白质结构的解决方案，但对于抗体，特别是对于抗体的互补决定区（CDRs），其预测效率和准确性有限制。

    In the field of antibody engineering, an essential task is to design a novel antibody whose paratopes bind to a specific antigen with correct epitopes. Understanding antibody structure and its paratope can facilitate a mechanistic understanding of its function. Therefore, antibody structure prediction from its sequence alone has always been a highly valuable problem for de novo antibody design. AlphaFold2, a breakthrough in the field of structural biology, provides a solution to predict protein structure based on protein sequences and computationally expensive coevolutionary multiple sequence alignments (MSAs). However, the computational efficiency and undesirable prediction accuracy of antibodies, especially on the complementarity-determining regions (CDRs) of antibodies limit their applications in the industrially high-throughput drug design. To learn an informative representation of antibodies, we employed a deep antibody language model (ALM) on curated sequences from the observed a
    
[^95]: 分层动态图像协调

    Hierarchical Dynamic Image Harmonization. (arXiv:2211.08639v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.08639](http://arxiv.org/abs/2211.08639)

    本文提出了一种分层动态网络（HDNet），以实现有效的图像协调。我们提出了本地动态（LD）模块和基于掩码的全局动态（MGD）模块，LD保留了详细的本地视觉一致性。在我们的实验中，HDNet在定量和定性评估上优于最先进的图像协调方法。

    

    图像协调是计算机视觉中的一个关键任务，旨在调整前景以使其与背景兼容。最近的工作主要关注使用全局变换（即归一化和色彩曲线渲染）来实现视觉一致性。然而，这些模型忽略了本地视觉一致性，并且它们巨大的模型大小限制了它们在边缘设备上的调和能力。在本文中，我们提出了一种分层动态网络（HDNet），以适应特征从局部到整体的视角，以实现有效的图像协调。在各种动态模型取得成功的基础上，本文提出了本地动态（LD）模块和基于掩码的全局动态（MGD）模块。具体而言，LD基于语义相似性匹配前景和背景区域之间的本地表示，然后根据其$K$个最近邻背景区域的外观自适应地调整每个前景本地表示。这样，LD保留了详细的本地视觉一致性。此外，基于LD的MGD通过将前景掩码引入模型，增强了全局变换的性能。在我们的实验中，HDNet在定量和定性评估上优于最先进的图像协调方法。

    Image harmonization is a critical task in computer vision, which aims to adjust the foreground to make it compatible with the background. Recent works mainly focus on using global transformations (i.e., normalization and color curve rendering) to achieve visual consistency. However, these models ignore local visual consistency and their huge model sizes limit their harmonization ability on edge devices. In this paper, we propose a hierarchical dynamic network (HDNet) to adapt features from local to global view for better feature transformation in efficient image harmonization. Inspired by the success of various dynamic models, local dynamic (LD) module and mask-aware global dynamic (MGD) module are proposed in this paper. Specifically, LD matches local representations between the foreground and background regions based on semantic similarities, then adaptively adjust every foreground local representation according to the appearance of its $K$-nearest neighbor background regions. In thi
    
[^96]: 线性规划中的教程与实践：供应链与运输物流中的优化问题

    Tutorial and Practice in Linear Programming: Optimization Problems in Supply Chain and Transport Logistics. (arXiv:2211.07345v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2211.07345](http://arxiv.org/abs/2211.07345)

    本文介绍线性规划的基本原理和实践，并通过供应链管理和运输物流中的空间分析优化问题演示如何解决经典的优化问题。

    

    这篇论文是一篇面向学生和实践者的成人教育指南，旨在帮助他们理解线性规划的基本原理和实践。本文通过重点介绍供应链管理和运输物流中的空间分析优化问题来演示如何解决经典的优化问题。所有的习题都展示了用于解决它们的Python程序和优化库。第一章介绍了线性规划的关键概念，并提出了一种新的认知框架，以帮助学生和实践者设置每个优化问题。该认知框架将决策变量、约束、目标函数和变量范围组织成一个格式，以直接应用于优化软件。第二章介绍了两种类型的移动优化问题（网络上的最短路径和最小成本巡回），并将其应用于交付和服务计划物流。第三章介绍了四种类型的空间优化问题。

    This tutorial is an andragogical guide for students and practitioners seeking to understand the fundamentals and practice of linear programming. The exercises demonstrate how to solve classical optimization problems with an emphasis on spatial analysis in supply chain management and transport logistics. All exercises display the Python programs and optimization libraries used to solve them. The first chapter introduces key concepts in linear programming and contributes a new cognitive framework to help students and practitioners set up each optimization problem. The cognitive framework organizes the decision variables, constraints, the objective function, and variable bounds in a format for direct application to optimization software. The second chapter introduces two types of mobility optimization problems (shortest path in a network and minimum cost tour) in the context of delivery and service planning logistics. The third chapter introduces four types of spatial optimization problem
    
[^97]: 基于强化学习的即兴控制器合成策略探索算法研究

    Exploration Policies for On-the-Fly Controller Synthesis: A Reinforcement Learning Approach. (arXiv:2210.05393v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.05393](http://arxiv.org/abs/2210.05393)

    本文提出了一种基于强化学习的方法，用于产生启发式来指导有向控制器合成算法的增量探索过程。

    

    控制器合成是基于模型的规划的一种，本文提出一种基于强化学习方法获得启发式来进行有向控制器合成的算法研究。此算法的增量探索由与领域无关的人工设计引导。

    Controller synthesis is in essence a case of model-based planning for non-deterministic environments in which plans (actually ''strategies'') are meant to preserve system goals indefinitely. In the case of supervisory control environments are specified as the parallel composition of state machines and valid strategies are required to be ''non-blocking'' (i.e., always enabling the environment to reach certain marked states) in addition to safe (i.e., keep the system within a safe zone). Recently, On-the-fly Directed Controller Synthesis techniques were proposed to avoid the exploration of the entire -and exponentially large-environment space, at the cost of non-maximal permissiveness, to either find a strategy or conclude that there is none. The incremental exploration of the plant is currently guided by a domain-independent human-designed heuristic. In this work, we propose a new method for obtaining heuristics based on Reinforcement Learning (RL). The synthesis algorithm is thus frame
    
[^98]: 节奏性手势生成器：带有分层神经嵌入的节奏感知语音协同手势合成

    Rhythmic Gesticulator: Rhythm-Aware Co-Speech Gesture Synthesis with Hierarchical Neural Embeddings. (arXiv:2210.01448v3 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2210.01448](http://arxiv.org/abs/2210.01448)

    本论文提出了一种新颖的协同手势合成方法，设计了一个强大的基于节奏的分割流程，并有效地区分了基于语言学理论的语音和动作的低级和高级神经嵌入，从而实现了在语音和手势之间的真正情感互动。

    

    在人造智能体的创作中，自动生成逼真的协同手势成为了越来越重要的、具有挑战性的任务。过去的系统主要集中在以端到端的方式生成手势，这导致了在语音和手势之间的复杂但微妙的和谐关系中挖掘清晰的节奏和语义的困难。我们提出了一种新颖的协同手势合成方法，能够在节奏和语义方面都实现令人信服的结果。对于节奏，我们的系统包含了一个强大的基于节奏的分割流程，以确保语音和手势之间的时间协调明确可见。对于手势的语义，我们设计了一种机制来有效地区分基于语言学理论的语音和动作的低级和高级神经嵌入。高级嵌入对应语义，而低级嵌入则涉及微小的变化。最后，我们建立了语音和动作的分层嵌入之间的对应关系，使得我们的系统可以在语音和手势之间实现真正的情感互动。

    Automatic synthesis of realistic co-speech gestures is an increasingly important yet challenging task in artificial embodied agent creation. Previous systems mainly focus on generating gestures in an end-to-end manner, which leads to difficulties in mining the clear rhythm and semantics due to the complex yet subtle harmony between speech and gestures. We present a novel co-speech gesture synthesis method that achieves convincing results both on the rhythm and semantics. For the rhythm, our system contains a robust rhythm-based segmentation pipeline to ensure the temporal coherence between the vocalization and gestures explicitly. For the gesture semantics, we devise a mechanism to effectively disentangle both low- and high-level neural embeddings of speech and motion based on linguistic theory. The high-level embedding corresponds to semantics, while the low-level embedding relates to subtle variations. Lastly, we build correspondence between the hierarchical embeddings of the speech 
    
[^99]: 通过离散推理实现复杂文档理解

    Towards Complex Document Understanding By Discrete Reasoning. (arXiv:2207.11871v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2207.11871](http://arxiv.org/abs/2207.11871)

    本文介绍了一个新的文档视觉问答数据集TAT-DQA，并通过该数据集开发了一种新型模型MHST。MHST模型考虑了多种模态的信息来智能地回答不同类型的问题，实验表明其在TAT-DQA数据集上显著优于其他模型。

    

    文档视觉问答旨在理解视觉丰富的文档，以回答自然语言中的问题，这是自然语言处理和计算机视觉的一个新兴研究课题。本文介绍了一个名为TAT-DQA的新的文档视觉问答数据集，它由3067个半结构化表格和非结构化文本页面以及16558个问题-答案对组成，是通过扩展TAT-QA数据集得到的。这些文档来自于现实世界的财务报告，包含大量数字，因此需要具有离散推理能力来回答这个数据集上的问题。基于TAT-DQA，我们进一步开发了一种名为MHST的新型模型，它考虑了多种模态的信息，包括文本、布局和视觉图像，以智能地针对不同类型的问题采用相应的策略，即抽取或推理。广泛的实验表明，MHST模型在TAT-DQA数据集上显著优于基线方法和几种最先进的文档视觉问答模型。

    Document Visual Question Answering (VQA) aims to understand visually-rich documents to answer questions in natural language, which is an emerging research topic for both Natural Language Processing and Computer Vision. In this work, we introduce a new Document VQA dataset, named TAT-DQA, which consists of 3,067 document pages comprising semi-structured table(s) and unstructured text as well as 16,558 question-answer pairs by extending the TAT-QA dataset. These documents are sampled from real-world financial reports and contain lots of numbers, which means discrete reasoning capability is demanded to answer questions on this dataset. Based on TAT-DQA, we further develop a novel model named MHST that takes into account the information in multi-modalities, including text, layout and visual image, to intelligently address different types of questions with corresponding strategies, i.e., extraction or reasoning. Extensive experiments show that the MHST model significantly outperforms the ba
    
[^100]: AutoOpt：一个自动设计多样化结构元启发式优化算法的通用框架

    AutoOpt: A General Framework for Automatically Designing Metaheuristic Optimization Algorithms with Diverse Structures. (arXiv:2204.00998v6 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2204.00998](http://arxiv.org/abs/2204.00998)

    本文提出了一个通用的框架AutoOpt，用于自动设计具有多样化结构的元启发式算法，通过发布一个通用的算法原型，它可以更好地发掘元启发式算法家族的潜力和新颖性，从而提高设计的质量。

    

    元启发式算法被广泛认可为解决不满足常规求解器严格数学假设的难题的无梯度求解器。自动设计元启发式算法提供了一条吸引人的路径，可以减轻手工设计的工作量，并获得超越人造算法的增强性能。然而，当前自动设计流水线中具体的算法原型和线性算法表示将设计限制在固定的算法结构内，这阻碍了发现元启发式家族中的新颖性和多样性。为了解决这一挑战，本文提出了一个自动设计多样化结构元启发式算法的通用框架——AutoOpt。AutoOpt包含三个创新点：（1）一个通用的算法原型，专门涵盖了尽可能广泛的元启发式算法家族。它通过完全发掘潜力和新颖性，在不同的问题上促进高质量的自动设计。

    Metaheuristics are widely recognized gradient-free solvers to hard problems that do not meet the rigorous mathematical assumptions of conventional solvers. The automated design of metaheuristic algorithms provides an attractive path to relieve manual design effort and gain enhanced performance beyond human-made algorithms. However, the specific algorithm prototype and linear algorithm representation in the current automated design pipeline restrict the design within a fixed algorithm structure, which hinders discovering novelties and diversity across the metaheuristic family. To address this challenge, this paper proposes a general framework, AutoOpt, for automatically designing metaheuristic algorithms with diverse structures. AutoOpt contains three innovations: (i) A general algorithm prototype dedicated to covering the metaheuristic family as widely as possible. It promotes high-quality automated design on different problems by fully discovering potentials and novelties across the f
    
[^101]: 通用博弈的空间状态动作特征

    Spatial State-Action Features for General Games. (arXiv:2201.06401v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2201.06401](http://arxiv.org/abs/2201.06401)

    本文提出了通用博弈的空间状态动作特征的设计和高效实现方法，可以支持不同棋盘和图形的多种不同游戏。同时提出了实时评估活跃特征的高效方法，并在多个游戏中取得了最先进的性能表现。

    

    在许多棋盘游戏和其他抽象游戏中，使用图案作为特征可以指导自动化游戏代理的操作，而这些特征通常代表着对于游戏的策略而言非常重要的棋子、空位等特定配置。在本文中，我们提出了一种设计和高效实现通用博弈的空间状态动作特征的方法。这些特征是可以根据所处区域的状态变量匹配情况来鼓励或者排斥动作的图案。我们提供了若干设计和实现选择的详细细节，并着重实现了高度通用性以支持不同棋盘几何图形或其他图形的各种不同游戏。其次，我们提出了一种高效的方法，在游戏过程中实时评估活跃特征，基于一种将活跃特征集合表示为稀疏二值向量的新颖方法，它支持与权重向量的有效点积计算。我们在几个游戏中进行了实验，包括围棋、六角、五子棋等游戏，并展示了我们的方法可以在少量活跃要素的情况下实现最先进的性能表现。

    In many board games and other abstract games, patterns have been used as features that can guide automated game-playing agents. Such patterns or features often represent particular configurations of pieces, empty positions, etc., which may be relevant for a game's strategies. Their use has been particularly prevalent in the game of Go, but also many other games used as benchmarks for AI research. In this paper, we formulate a design and efficient implementation of spatial state-action features for general games. These are patterns that can be trained to incentivise or disincentivise actions based on whether or not they match variables of the state in a local area around action variables. We provide extensive details on several design and implementation choices, with a primary focus on achieving a high degree of generality to support a wide variety of different games using different board geometries or other graphs. Secondly, we propose an efficient approach for evaluating active featur
    
[^102]: 用代数ZX演算表示和实现矩阵

    Representing and Implementing Matrices Using Algebraic ZX-calculus. (arXiv:2110.06898v4 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2110.06898](http://arxiv.org/abs/2110.06898)

    本文提出了一种方法，在代数ZX演算中对所有 $2^m\times 2^n$ 大小的基本矩阵进行图示表示，为量子计算等领域中的ZX演算应用奠定了基础。

    

    在线性代数应用中，基本矩阵扮演着重要的角色。本文提出了一个在代数ZX演算中对所有 $2^m\times 2^n$ 大小的基本矩阵进行图示表示的方法，展示了它们的逆和转置等特性。此外，本文利用这种表示方法在代数ZX演算中展示了Jozsa-style matchgate。为了进一步提高实际应用，我们在\texttt{discopy}中实现了这种表示方法。总的来说，这项工作为如在量子计算中合成受控矩阵[arXiv:2212.04462]等更多应用领域中的ZX演算奠定了基础。

    In linear algebra applications, elementary matrices hold a significant role. This paper presents a diagrammatic representation of all $2^m\times 2^n$-sized elementary matrices in algebraic ZX-calculus, showcasing their properties on inverses and transpose through diagrammatic rewriting. Additionally, the paper uses this representation to depict the Jozsa-style matchgate in algebraic ZX-calculus. To further enhance practical use, we have implemented this representation in \texttt{discopy}. Overall, this work sets the groundwork for more applications of ZX-calculus such as synthesising controlled matrices [arXiv:2212.04462] in quantum computing.
    
[^103]: 量子离散事件系统的监督控制

    Supervisory Control of Quantum Discrete Event Systems. (arXiv:2104.09753v3 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2104.09753](http://arxiv.org/abs/2104.09753)

    本文建立了量子离散事件系统的监督控制框架，使用量子有限状态自动机作为建模形式，并提出并证明了其监督控制定理。同时，还提出了一个用于决定QDES状态可达性问题的多项式时间算法，并且该方法可以直接扩展到DES中。

    

    离散事件系统（DES）已在实践中得到深入发展和应用，但DES中的状态复杂度仍然是需要创新方法更好地解决的重要问题。随着量子计算和量子控制的发展，一个自然的问题是通过量子计算模型模拟DES，并建立“量子离散事件系统”（QDES）。其动机是双重的：一方面，在利用量子计算机模拟和处理DES时，QDES具有潜在的应用价值，其中量子系统被用于模拟由离散事件驱动的状态演化；另一方面，对于模拟某些实际问题，QDES可能比DES具有更重要的优势，尤其是在状态复杂度方面。因此，本文旨在利用“量子有限状态自动机”（QFA）作为建模形式，建立QDES的基本框架，并建立并证明了QDES的监督控制定理。然后，我们提出了一个用于决定QDES状态可达性问题的多项式时间算法，并证明了在DES中使用的方法可以直接扩展到QDES。最后，我们提供了一些案例研究以说明所提出的QDES框架的有效性和潜在优势。

    Discrete event systems (DES) have been deeply developed and applied in practice, but state complexity in DES still is an important problem to be better solved with innovative methods. With the development of quantum computing and quantum control, a natural problem is to simulate DES by means of quantum computing models and to establish {\it quantum DES} (QDES). The motivation is twofold: on the one hand, QDES have potential applications when DES are simulated and processed by quantum computers, where quantum systems are employed to simulate the evolution of states driven by discrete events, and on the other hand, QDES may have essential advantages over DES concerning state complexity for imitating some practical problems. So, the goal of this paper is to establish a basic framework of QDES by using {\it quantum finite automata} (QFA) as the modelling formalisms, and the supervisory control theorems of QDES are established and proved. Then we present a polynomial-time algorithm to decid
    
[^104]: 实践中的QNLP：在量子计算机上运行组合模型的含义。

    QNLP in Practice: Running Compositional Models of Meaning on a Quantum Computer. (arXiv:2102.12846v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2102.12846](http://arxiv.org/abs/2102.12846)

    本文介绍了在嘈杂的中间规模量子计算机上进行的首个大于100个句子数据集的NLP实验结果，成功地训练了解决简单句子分类任务的NLP模型，证明了组合模型的含义与量子理论具有形式相似性。

    

    量子自然语言处理（QNLP）涉及设计和实现旨在在量子硬件上运行的NLP模型。在本文中，我们介绍了在嘈杂的中间规模量子（NISQ）计算机上进行的首个大于100个句子数据集的NLP实验结果。利用由Coecke、Sadrzadeh和Clark（2010）提出的含义组合模型与量子理论的形式相似性，我们创建了具有自然映射到量子电路的句子表示。我们使用这些表示来实现并成功训练在量子硬件上解决简单句子分类任务的NLP模型。我们进行了量子模拟，比较了Coecke等人的语法敏感模型与使用较少或无语法的两个基线，具体而言，我们实现了“词袋”模型的量子模拟，其中根本不考虑语法，以及单词序列模型的量子模拟，仅尊重单词顺序。

    Quantum Natural Language Processing (QNLP) deals with the design and implementation of NLP models intended to be run on quantum hardware. In this paper, we present results on the first NLP experiments conducted on Noisy Intermediate-Scale Quantum (NISQ) computers for datasets of size greater than 100 sentences. Exploiting the formal similarity of the compositional model of meaning by Coecke, Sadrzadeh and Clark (2010) with quantum theory, we create representations for sentences that have a natural mapping to quantum circuits. We use these representations to implement and successfully train NLP models that solve simple sentence classification tasks on quantum hardware. We conduct quantum simulations that compare the syntax-sensitive model of Coecke et al. with two baselines that use less or no syntax; specifically, we implement the quantum analogues of a "bag-of-words" model, where syntax is not taken into account at all, and of a word-sequence model, where only word order is respected.
    
[^105]: ISP精馏

    ISP Distillation. (arXiv:2101.10203v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2101.10203](http://arxiv.org/abs/2101.10203)

    该论文介绍了一种称为ISP精馏的方法，通过使用知识蒸馏将RAW图像的预测与经过处理的RGB图像的预测相匹配，成功地提高了直接将机器视觉模型应用于RAW图像的性能。

    

    如今，许多图像只能由机器而不是人类“观察”，例如在自动系统中。高级机器视觉模型（如对象识别或语义分割）假定相机将图像转换为某个规范化的图像空间，即图像信号处理器（ISP）。然而，相机ISP优化的是为人类观察者生成视觉上令人愉悦的图像，而不是机器。因此，我们可能会省略ISP的计算时间，直接将视觉模型应用于RAW图像。然而，直接在RAW图像上训练这些模型会导致性能下降。为了缓解这种下降，我们使用了一个RAW和RGB图像对数据集，该数据集可以轻松获取且无需人工标记。然后，我们使用知识蒸馏来训练一个直接应用于RAW数据的模型，使得该模型对于RAW图像的预测与已处理的RGB图像的预测相匹配。我们在语义分割和目标检测任务上的实验表明，我们提出的ISP精馏方法可以持续而显著地提高直接应用机器视觉模型于RAW图像的性能。

    Nowadays, many of the images captured are `observed' by machines only and not by humans, e.g., in autonomous systems. High-level machine vision models, such as object recognition or semantic segmentation, assume images are transformed into some canonical image space by the camera \ans{Image Signal Processor (ISP)}. However, the camera ISP is optimized for producing visually pleasing images for human observers and not for machines. Therefore, one may spare the ISP compute time and apply vision models directly to RAW images. Yet, it has been shown that training such models directly on RAW images results in a performance drop. To mitigate this drop, we use a RAW and RGB image pairs dataset, which can be easily acquired with no human labeling. We then train a model that is applied directly to the RAW data by using knowledge distillation such that the model predictions for RAW images will be aligned with the predictions of an off-the-shelf pre-trained model for processed RGB images. Our exp
    

