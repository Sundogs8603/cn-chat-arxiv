# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Data-Centric Solution to NonHomogeneous Dehazing via Vision Transformer.](http://arxiv.org/abs/2304.07874) | 本文提出了一种基于Vision Transformer的数据中心的解决方案，用于解决非均质去雾问题。传统方法在处理NH-HAZE23数据集等非均质雾图像时存在问题，因为它们无法满足建模均质雾所需的假设之一。同时，本文指出光靠数据增广并不能解决问题，因为需要处理分布差异。 |
| [^2] | [Neural Machine Translation For Low Resource Languages.](http://arxiv.org/abs/2304.07869) | 该论文研究了低资源语言的神经机器翻译，并构建了一个基于 \texttt{mBART.CC25} 语言模型的模型，利用后向翻译和迁移学习等 NLP 和深度学习技术进行增强，以达到最先进的结果。 |
| [^3] | [A Virtual Simulation-Pilot Agent for Training of Air Traffic Controllers.](http://arxiv.org/abs/2304.07842) | 本文提出了一个用于加速空中交通管制员培训的基于人工智能的虚拟模拟飞行员引擎，它能够理解口头通讯的意义并进行响应。 |
| [^4] | [A Random-patch based Defense Strategy Against Physical Attacks for Face Recognition Systems.](http://arxiv.org/abs/2304.07822) | 本文提出了一种基于随机补丁的防御策略，用于强化人脸识别系统（FRS）来检测物理攻击，该方法在检测白盒攻击和自适应攻击方面表现出优越性，且简单易用。 |
| [^5] | [VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping.](http://arxiv.org/abs/2304.07810) | VISAR是一个AI写作助手，旨在帮助作者提升写作体验和输出。它可以在写作上下文中随时帮助作者构思和修改目标，通过可视化编程来组织论证结构，并提供推荐来增加说服力。自动草案原型可以用来验证计划。 |
| [^6] | [Assisting clinical practice with fuzzy probabilistic decision trees.](http://arxiv.org/abs/2304.07788) | 我们提出了一种基于概率树和模糊逻辑的新方法MedFP，用于辅助医学实践。该方法可以完全解释，允许临床医生产生、控制和验证整个诊断过程，并减少误诊率，通过提供不确定性和反事实分析的估计值。 |
| [^7] | [It's All in the Embedding! Fake News Detection Using Document Embeddings.](http://arxiv.org/abs/2304.07781) | 本文提出一种基于文本嵌入的假新闻检测方法，利用新闻文章的时间和主题背景，可有效检测假新闻。 |
| [^8] | [MisRoB{\AE}RTa: Transformers versus Misinformation.](http://arxiv.org/abs/2304.07759) | 本文提出了一种新型基于Transformer的深度神经网络集成体系结构MisRoB{\AE}RTa，用于不实信息检测，并在大型现实世界新闻文章数据集上进行了测试和评估。 |
| [^9] | [TransFusionOdom: Interpretable Transformer-based LiDAR-Inertial Fusion Odometry Estimation.](http://arxiv.org/abs/2304.07728) | 本文提出了一种可解释的基于Transformer的LiDAR-惯性融合里程计估计方法，通过多头注意力融合模块展示了不同融合方法，实验表明该方法在KITTI和EuRoC数据集上表现优于现有方法。 |
| [^10] | [Learning Empirical Bregman Divergence for Uncertain Distance Representation.](http://arxiv.org/abs/2304.07689) | 本文介绍了一种新的基于Deep Metric Learning的方法，通过学习经验Bregman散度直接从数据中进行不确定距离表示，能够有效的在模式识别和聚类任务上提高准确性。 |
| [^11] | [FedBlockHealth: A Synergistic Approach to Privacy and Security in IoT-Enabled Healthcare through Federated Learning and Blockchain.](http://arxiv.org/abs/2304.07668) | 本文提出了一种基于联邦学习和区块链技术的创新方法，为IoT医疗保健应用提供安全和隐私保护的解决方案，实现了安全的模型聚合，同时不共享敏感患者数据。 |
| [^12] | [EEGSN: Towards Efficient Low-latency Decoding of EEG with Graph Spiking Neural Networks.](http://arxiv.org/abs/2304.07655) | 该论文提出了一种名为 EEGSN 的图形脉冲神经网络（SNN）架构，面向多通道 EEG 分类任务，在学习分布式 EEG 传感器中的动态关系信息的同时，将推断计算复杂度降低了20倍，为低延迟和功耗效率的脑计算机接口的开发提供了一个可行的框架。 |
| [^13] | [Non-Proportional Parametrizations for Stable Hypernetwork Learning.](http://arxiv.org/abs/2304.07645) | 本文提出一种针对当前超网络训练策略不稳定、收敛速度慢的问题的解决方案，通过使用非比例加性参数化的方式来修订超网络形式，实现更加稳定和快速的训练。 |
| [^14] | [Estimation of minimum miscibility pressure (MMP) in impure/pure N2 based enhanced oil recovery process: A comparative study of statistical and machine learning algorithms.](http://arxiv.org/abs/2304.07617) | 本研究比较了统计学和机器学习方法用于估计N2增油过程中的最小相溶压力，表明本研究开发的预测模型具有更好的性能。 |
| [^15] | [High-Speed and Energy-Efficient Non-Binary Computing with Polymorphic Electro-Optic Circuits and Architectures.](http://arxiv.org/abs/2304.07608) | 本文提出了一种基于微环谐振器的多态电光电路与架构，可用于高速、节能的非二进制可重构计算，并能处理多种数据格式和卷积神经网络。 |
| [^16] | [Teacher Network Calibration Improves Cross-Quality Knowledge Distillation.](http://arxiv.org/abs/2304.07593) | 本论文研究了跨质量知识蒸馏方法，将使用高分辨率图像训练的教师网络中的知识转移到低分辨率图像的学生网络中，并通过提高温度平滑教师输出分布来优化方法，实现在大规模图像分类问题中的性能优越。 |
| [^17] | [From Online Behaviours to Images: A Novel Approach to Social Bot Detection.](http://arxiv.org/abs/2304.07535) | 该论文提出了一种基于算法和卷积神经网络的新方法来检测 Twitter 机器人账号，通过将其行为转换为图片进行分类，通过测试发现该方法比传统的机器人检测方法更加有效。 |
| [^18] | [STAS: Spatial-Temporal Return Decomposition for Multi-agent Reinforcement Learning.](http://arxiv.org/abs/2304.07520) | 提出了一种名为STAS的新方法，用于多智能体强化学习中时空回报分解，可以对代理进行信用分配。该方法引入了Shapley值和空间-时间注意机制来解决先前方法中延迟全局回报的复杂关系问题。在各种基准环境下，该方法表现良好。 |
| [^19] | [PI-FL: Personalized and Incentivized Federated Learning.](http://arxiv.org/abs/2304.07514) | PI-FL是一种个性化的联邦学习解决方案，使用基于令牌的激励机制奖励个性化训练，可以在尊重客户端隐私的同时生成高质量的个性化模型。 |
| [^20] | [Hierarchical and Contrastive Representation Learning for Knowledge-aware Recommendation.](http://arxiv.org/abs/2304.07506) | 本文提出了HiCON框架，运用层次化对比表示学习提高了学习到的节点表示的区分能力，同时采用分层消息聚合机制避免了邻居的指数级扩展，从而有效地解决了知识驱动推荐中的过度平滑问题。 |
| [^21] | [Robust Educational Dialogue Act Classifiers with Low-Resource and Imbalanced Datasets.](http://arxiv.org/abs/2304.07499) | 本文提出了一种新型的教育对话行为分类器MIREX，它采用互信息最小化损失来提高对不平衡和低资源数据情景下数据的鲁棒性，并在实验中展现出较好的效果。 |
| [^22] | [Communication and Energy Efficient Wireless Federated Learning with Intrinsic Privacy.](http://arxiv.org/abs/2304.07460) | 本文提出了一种名为PFELS的无线FL方案，通过先压缩模型更新再自适应地设计发送功率来提供客户端级别DP保证，并降低通信和能量开销并提高模型精度。 |
| [^23] | [Context-aware Domain Adaptation for Time Series Anomaly Detection.](http://arxiv.org/abs/2304.07453) | 本论文提出了一个框架，通过自适应地采样两个领域的上下文信息来在两个领域之间传递知识。这个框架结合了上下文采样和异常检测，既可以进行无监督域适应，也可以进行有监督的异常检测。 |
| [^24] | [Efficient Quality-Diversity Optimization through Diverse Quality Species.](http://arxiv.org/abs/2304.07425) | 本文提出了一种新的质量多样性优化算法，通过将解决方案分解为独立进化的物种，并使用无监督的技能发现来学习多样化的高性能解决方案，相对于传统方法，该方法无需存档或预先定义行为范围的限制。 |
| [^25] | [Text-Conditional Contextualized Avatars For Zero-Shot Personalization.](http://arxiv.org/abs/2304.07410) | 本研究提出了一个零样本管道，使得可以捕捉用户身份的人物形象以令人愉悦的方式进行图像生成的个性化处理，并在大规模图像数据集上提高了性能，扩展适用于数百万用户。 |
| [^26] | [Repeated Principal-Agent Games with Unobserved Agent Rewards and Perfect-Knowledge Agents.](http://arxiv.org/abs/2304.07407) | 本文提出了一个利用多臂老虎机框架结构来处理未知代理奖励的策略，并证明了其性能是渐进最优的。 |
| [^27] | [Improving Patient Pre-screening for Clinical Trials: Assisting Physicians with Large Language Models.](http://arxiv.org/abs/2304.07396) | 本文研究了使用大型语言模型InstructGPT辅助医生预筛选患者是否符合临床试验资格。通过10个合成患者简况的性能评估，展示了LLMs在识别筛选资格标准、单独分类、整体分类、以及需要筛选资格标准的百分比上的表现。 |
| [^28] | [Shape of You: Precise 3D shape estimations for diverse body types.](http://arxiv.org/abs/2304.07389) | 本文提出了一种名为SoY的方法，通过两种损失函数和测试时优化例程，可以在不同的人体类型上提高精确的3D形体估计准确度，为时尚行业的实际应用提供了希望。 |
| [^29] | [Combining Generators of Adversarial Malware Examples to Increase Evasion Rate.](http://arxiv.org/abs/2304.07360) | 本文介绍了一种结合不同生成器的技术，以创建更复杂的对抗性示例，从而大幅提高逃避反恶意软件工具的检测的成功率。 |
| [^30] | [Learning to Learn Group Alignment: A Self-Tuning Credo Framework with Multiagent Teams.](http://arxiv.org/abs/2304.07337) | 本研究提出了一个自适应Credo框架，通过元学习和层次强化学习来支持智能体对群体对齐参数进行自我调节，从而实现更好的多智能体团队结果。 |
| [^31] | [OpenAssistant Conversations -- Democratizing Large Language Model Alignment.](http://arxiv.org/abs/2304.07327) | 释放了OpenAssistant Conversations，这是一个由全球超过1,000名参与者进行人工生成和人工注释的助手风格对话语料库，可以通过SFT和RLHF有效地用于LLM对齐，提高模型性能和可用性。 |
| [^32] | [Uncovering the Inner Workings of STEGO for Safe Unsupervised Semantic Segmentation.](http://arxiv.org/abs/2304.07314) | 这篇论文详细研究了STEGO方法的内部机制和培训策略，揭示了其进行无监督语义分割的工作原理，可用于新领域的应用。 |
| [^33] | [Federated and distributed learning applications for electronic health records and structured medical data: A scoping review.](http://arxiv.org/abs/2304.07310) | 本研究是一份面向电子病历和结构化医疗数据的联邦与分布式学习应用的范围审查，研究发现FL应用于结构化医学数据的研究大多集中在隐私保护方面，未来应该探索FL在降低通信成本和提高模型通用性方面的应用。 |
| [^34] | [Learning to Defer with Limited Expert Predictions.](http://arxiv.org/abs/2304.07306) | 本论文提出了一个三步方法，用于降低学习推迟算法所需的专家预测数量。该方法通过训练嵌入模型、使用少量的专家预测和利用样本相似性来提高性能。 |
| [^35] | [Smart Metro: Deep Learning Approaches to Forecasting the MRT Line 3 Ridership.](http://arxiv.org/abs/2304.07303) | 本研究使用时间序列模型预测菲律宾马尼拉地铁三号线每天乘客量的变化，帮助人们更好地规划出行。 |
| [^36] | [Supervised Machine Learning for Breast Cancer Risk Factors Analysis and Survival Prediction.](http://arxiv.org/abs/2304.07299) | 本研究利用机器学习方法预测了乳腺癌患者的5年生存率，并比较了七种分类模型的表现，结果表明这些模型能够准确地预测测试样本的生存率，机器学习模型可以成为乳腺癌生存预测和风险因素分析的有价值工具。 |
| [^37] | [Road Network Representation Learning: A Dual Graph based Approach.](http://arxiv.org/abs/2304.07298) | 提出了一种基于双重图的方法来解决传统道路网络表示学习模型无法捕捉道路之间高阶和远程关系的问题。 |
| [^38] | [Language Instructed Reinforcement Learning for Human-AI Coordination.](http://arxiv.org/abs/2304.07297) | 本文提出了一种称之为instructRL的新的框架，它通过自然语言指令来指定对人工智能搭档的预期策略，解决在缺乏高质量人类行为数据的领域中多智能体强化学习收敛于人类不偏爱的策略的问题，从而提高了人工智能协作的性能。 |
| [^39] | [Experts' cognition-driven safe noisy labels learning for precise segmentation of residual tumor in breast cancer.](http://arxiv.org/abs/2304.07295) | 本文提出了一种基于专家认知驱动的安全噪声标签学习方法，用于乳腺癌残余肿瘤的精确分割，该方法将病理专家的认知和人工智能专家的数据建模认知相结合，以缓解乳腺癌组织和肿瘤细胞形态学改变的挑战。 |
| [^40] | [Machine Perception-Driven Image Compression: A Layered Generative Approach.](http://arxiv.org/abs/2304.06896) | 本文提出了一种分层生成图像压缩模型，能够在极端压缩比下实现高质量的视觉重建，同时支持各种基于压缩域的分析任务。 |
| [^41] | [SpectFormer: Frequency and Attention is what you need in a Vision Transformer.](http://arxiv.org/abs/2304.06446) | 本文提出了结合多头注意力和谱层的Spectformer架构，可以得到更好的性能表现，提高了top-1准确率2%。 |
| [^42] | [Exploiting Logic Locking for a Neural Trojan Attack on Machine Learning Accelerators.](http://arxiv.org/abs/2304.06017) | 本文研究了如何利用逻辑锁定来破坏神经加速器的安全性，并展示了如何利用特洛伊秘钥来产生神经特洛伊式的后门。在基准数据集上进行的实验表明，我们的方法可以生成诱导大量错误分类率的特洛伊秘钥，同时保持高的特洛伊激活概率。 |
| [^43] | [NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair and Representative Benchmarking.](http://arxiv.org/abs/2304.04640) | NeuroBench是由学术界和工业界成员共同开发的一套协作、公平和代表性的基准测试，可以解决神经形态计算中缺乏清晰标准的问题，推动该领域的发展。 |
| [^44] | [Personalizing Digital Health Behavior Change Interventions using Machine Learning and Domain Knowledge.](http://arxiv.org/abs/2304.03392) | 该论文提出了一种采用机器学习和领域知识进行个性化数字健康行为变革干预的系统，其利用反事实例子进行特征控制以预测干预效果并优化干预效果。 |
| [^45] | [smProbLog: Stable Model Semantics in ProbLog for Probabilistic Argumentation.](http://arxiv.org/abs/2304.00879) | 本文提出了将概率论证框架解释为概率逻辑程序的方法，并提出了一种新的PLP语义，用于处理不同概率事实之间的不确定性。该论文在推理论证领域内有一定的应用意义。 |
| [^46] | [Managing power grids through topology actions: A comparative study between advanced rule-based and reinforcement learning agents.](http://arxiv.org/abs/2304.00765) | 本研究分析了使用强化学习和基于规则方法的电力网络运行智能体并提供了新策略。其中最主要的改进是采用N-1策略，考虑到在某条线路断开时的拓扑操作以保持网络稳定。另外，拓扑反转也有利于提高性能。在挑战测试集上，该方法的性能提高了27%。 |
| [^47] | [A Survey of Large Language Models.](http://arxiv.org/abs/2303.18223) | 本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。 |
| [^48] | [Advances in apparent conceptual physics reasoning in ChatGPT-4.](http://arxiv.org/abs/2303.17012) | ChatGPT-4是一个基于大规模语言模型训练的对话机器人，能达到接近于物理专家水平的力概念测试成绩，对未来的物理教育和教学有重要意义。 |
| [^49] | [TabRet: Pre-training Transformer-based Tabular Models for Unseen Columns.](http://arxiv.org/abs/2303.15747) | 提出了一种可预训练的Transformer-based表格模型：TabRet，能够支持未知列，并在医疗保健分类任务上表现优秀。重新标记化和随机洗牌增强对性能提升有贡献。 |
| [^50] | [MeMaHand: Exploiting Mesh-Mano Interaction for Single Image Two-Hand Reconstruction.](http://arxiv.org/abs/2303.15718) | 本文提出了一种利用网格-手部互动进行单张图像双手重建的新方法，使用网格顶点位置和MANO参数作为查询令牌，实现了精确的网格重建，并通过实验表明这一方法优于现有最先进方法。 |
| [^51] | [MeshDiffusion: Score-based Generative 3D Mesh Modeling.](http://arxiv.org/abs/2303.08133) | 本文提出了一种基于分数的生成式3D网格建模方法，依赖网格的图形结构和扩散模型，在不需要后处理的前提下，生成高质量、细节丰富的3D网格。 |
| [^52] | [Disambiguation of Company names via Deep Recurrent Networks.](http://arxiv.org/abs/2303.05391) | 本研究提出了一种利用深度递归网络进行公司名称消歧的方法，相较于标准字符串匹配算法具有更优的表现，还采用主动学习来优化样本标记效率。 |
| [^53] | [Helpful, Misleading or Confusing: How Humans Perceive Fundamental Building Blocks of Artificial Intelligence Explanations.](http://arxiv.org/abs/2303.00934) | 该论文旨在以人为中心的角度评估人工智能中的解释可理解性，以及评估可解释性的适当方法落后于技术的发展速度。 |
| [^54] | [AR3n: A Reinforcement Learning-based Assist-As-Needed Controller for Robotic Rehabilitation.](http://arxiv.org/abs/2303.00085) | 本文提出了一种基于强化学习的机器人康复辅助控制器AR3n，通过使用虚拟患者模型实现控制器的泛化，实时调节机器人辅助力度并最小化机器人辅助的量，该控制器在实验验证中表现出良好的效果。 |
| [^55] | [Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation.](http://arxiv.org/abs/2302.09664) | 本文提出了一种测量大型语言模型中不确定性的方法，引入了语义熵以克服自然语言中的“语义等价性”，该方法是无监督的，并且对于问题回答数据集上的模型准确性具有更好的预测性能。 |
| [^56] | [Is Multimodal Vision Supervision Beneficial to Language?.](http://arxiv.org/abs/2302.05016) | 本文探讨了使用视觉监督训练的语言表示是否比普通语言表示在自然语言理解和常识推理基准测试方面表现更好。结果表明，大多数任务中，普通的语言表示表现出更好的性能。 |
| [^57] | [Diversity is Definitely Needed: Improving Model-Agnostic Zero-shot Classification via Stable Diffusion.](http://arxiv.org/abs/2302.03298) | 本文提出了一种通过增强生成数据集中图像的多样性来提高模型无关的零样本分类性能的方法，比最先进的方法提高了1.4mAP（CUB数据集）和8.4mAP（ImageNet数据集），并且适用于任何下游的分类架构。 |
| [^58] | [KNOD: Domain Knowledge Distilled Tree Decoder for Automated Program Repair.](http://arxiv.org/abs/2302.01857) | KNOD是一种用于自动程序修复的DL-based APR方法。它利用领域知识在补丁生成中指导修复过程，具有一种新颖的三阶段树解码器和领域规则提取方法。 |
| [^59] | [Policy Expansion for Bridging Offline-to-Online Reinforcement Learning.](http://arxiv.org/abs/2302.00935) | 本文提出了一种政策扩展方案，用于离线到在线强化学习，以保留离线学习的策略并在在线学习中进行自适应扩展。 |
| [^60] | [GLIGEN: Open-Set Grounded Text-to-Image Generation.](http://arxiv.org/abs/2301.07093) | GLIGEN是一种开放式基于语言关联性和预训练的文本到图像生成方法，通过门控机制注入连结信息，能够实现零样本的基于关键字和边界框的文本到图像生成，性能优于现有的监督布局到图像的基线。 |
| [^61] | [Reasoning about Causality in Games.](http://arxiv.org/abs/2301.02324) | 本文提出了一种新的解决方案——结构因果游戏，它将因果理论和博弈理论相结合，能够在统一、原则性的框架下建模游戏中的依赖关系和计算因果效应，是游戏中因果推理领域的一次有益尝试。 |
| [^62] | [Single-round Self-supervised Distributed Learning using Vision Transformer.](http://arxiv.org/abs/2301.02064) | 本文提出了一种自监督蒸馏方法，可以在分布式学习中实现不需要连续通信，并通过利用Vision Transformer特定的加密技术来增强隐私保护。实验结果表明，该方法在两个不同任务上均优于现有的分布式学习策略和微调基线。 |
| [^63] | [Behavioral Cloning via Search in Video PreTraining Latent Space.](http://arxiv.org/abs/2212.13326) | 本文通过基于模仿学习方法中的搜索问题，将控制问题表述为专家演示数据集中的模仿。该方法通过在视频预训练模型的潜表示中进行近邻搜索，可以有效地在Minecraft环境中复制出有意义的演示轨迹并呈现类人行为。 |
| [^64] | [Efficient aggregation of face embeddings for decentralized face recognition deployments (extended version).](http://arxiv.org/abs/2212.10108) | 本文提出了一种在去中心化人脸识别部署中有效聚合面部嵌入的方式，旨在减少网络和硬件需求以鼓励设备多样性。 |
| [^65] | [Semantics-Empowered Communication: A Tutorial-cum-Survey.](http://arxiv.org/abs/2212.08487) | 本文提供了基于语义的沟通方面的教程兼综述，回顾了文献，介绍了SemCom生态系统，并将研究方向进行了分类。此外，还提供了启用技术的分类和未来应用场景的展望。 |
| [^66] | [Accelerating Dataset Distillation via Model Augmentation.](http://arxiv.org/abs/2212.06152) | 本文提出了两种模型增强技术，即使用早期模型和参数扰动，以显着降低训练成本的方式优化数据集蒸馏，实现了高达20倍的加速。 |
| [^67] | [Leveraging Sequentiality in Reinforcement Learning from a Single Demonstration.](http://arxiv.org/abs/2211.04786) | 本文提出用单个演示来增强强化学习，利用连续性偏见来学习控制复杂机器人任务，学习一个目标条件策略，通过DCIL-II解决连续目标间的兼容性问题。 |
| [^68] | [Efficiently Trained Low-Resource Mongolian Text-to-Speech System Based On FullConv-TTS.](http://arxiv.org/abs/2211.01948) | 该论文提出了一个基于全卷积神经网络训练的低资源蒙古语文本到语音系统，相较于传统的包含循环神经网络的TTS模型，训练时间更短且音频合成质量不降低。 |
| [^69] | [Universal Adversarial Directions.](http://arxiv.org/abs/2210.15997) | 研究证明传统的通用对抗干扰 (UAPs) 在深度神经网络分类器之间转移性是次优的，为此本文提出了通用对抗方向 (UADs)，只固定通用方向，以便克服在跨DNN架构上转移的挑战。 |
| [^70] | [MEET: A Monte Carlo Exploration-Exploitation Trade-off for Buffer Sampling.](http://arxiv.org/abs/2210.13545) | 提出了一种新的基于探索-开发权衡的缓冲区采样策略，可以根据任务的复杂性自适应地调整采样策略，并在经典控制环境中表现出优越性能。 |
| [^71] | [BARS: A Benchmark for Airport Runway Segmentation.](http://arxiv.org/abs/2210.12922) | BARS是一个机场跑道分割基准数据集，通过11种代表性的实例分割方法的评估和性能分析，让基于深度学习的方法能更好地适应复杂场景。 |
| [^72] | [Schema-aware Reference as Prompt Improves Data-Efficient Knowledge Graph Construction.](http://arxiv.org/abs/2210.10709) | 提出了一种以检索增强的架构感知参考作为提示的方法，可动态利用人类注释和弱监督数据所继承的架构和知识，指导生成具有更好语义连贯性和一致性的结构化知识，从而在数据效率和知识质量方面具有优越性。 |
| [^73] | [Turbocharging Solution Concepts: Solving NEs, CEs and CCEs with Neural Equilibrium Solvers.](http://arxiv.org/abs/2210.09257) | 该论文介绍了一种神经平衡求解器，可以快速、准确地解决所有固定形状游戏空间的NEs、CEs和CCEs问题，并提供一个灵活的平衡选择框架，有助于加强多智能体算法的实现和应用。 |
| [^74] | [Learning image representations for anomaly detection: application to discovery of histological alterations in drug development.](http://arxiv.org/abs/2210.07675) | 该论文提出了一种基于CNN的异常检测系统，通过对健康组织进行辅助任务训练，使表示适应组织中的相关细节，实现对组织学图像中的异常情况检测。 |
| [^75] | [Over-the-Air Computation Based on Balanced Number Systems for Federated Edge Learning.](http://arxiv.org/abs/2210.07012) | 本研究提出了一种基于平衡数系统的数字计算方案，用于联邦边缘学习中的梯度聚合。通过数字的平均值计算实数参数的平均值，避免了对精确样本级时间同步、信道估计开销和信道反转的需求，同时提高了聚合性能。 |
| [^76] | [Intrinsic Dimension for Large-Scale Geometric Learning.](http://arxiv.org/abs/2210.05301) | 本研究提出了一种计算上可行的方法来确定大规模复杂数据的内在维度，该方法考虑了数据集的几何特性，并在准确性和计算效率方面优于现有方法。 |
| [^77] | [Predicting Cellular Responses with Variational Causal Inference and Refined Relational Information.](http://arxiv.org/abs/2210.00116) | 本研究利用基因调控网络信息设计了一种新的因果推断框架，并通过邻接矩阵更新技术预训练图卷积网络以更好地预测细胞在反事实干扰下的基因表达。同时，我们提出了一个鲁棒的估计器来高效估计边缘干扰效应。研究结果展示了该框架的优越性能。 |
| [^78] | [DecAF: Joint Decoding of Answers and Logical Forms for Question Answering over Knowledge Bases.](http://arxiv.org/abs/2210.00063) | DecAF 提出了一种联合生成逻辑形式和直接答案的新型框架，结合了它们的优点以获取最终答案；同时，它还采用了简单的自由文本检索，相比以往的方法更易于适应不同的数据集。 |
| [^79] | [Employing Deep Ensemble Learning for Improving the Security of Computer Networks against Adversarial Attacks.](http://arxiv.org/abs/2209.12195) | 本文提出了一种基于集成分类器的架构，称作SPRITZ-1.5C，它同时结合了1类分类的安全性和传统2类分类的高性能，在计算机网络等安全型应用中抵御对抗攻击具有挑战性。 |
| [^80] | [Proof-of-Learning is Currently More Broken Than You Think.](http://arxiv.org/abs/2208.03567) | 学习证明机制PoL存在不少问题，由于现有的欺骗策略很容易被打败或无法重现，因此对对手的安全保障不稳健。新的欺骗策略引入可以打破PoL的最新防御方法，但成本较低。 |
| [^81] | [Infant movement classification through pressure distribution analysis -- added value for research and clinical implementation.](http://arxiv.org/abs/2208.00884) | 本文提出了一种创新型的非侵入式方法，使用压力传感器对婴儿的一般运动进行分类，旨在实现早期神经肌肉障碍（如脑瘫）的客观检测。研究结果表明，使用压力数据可以区分婴儿的典型运动模式，即“坐立不安期”和“坐立不安前期”。 |
| [^82] | [Deep Contrastive One-Class Time Series Anomaly Detection.](http://arxiv.org/abs/2207.01472) | 本论文提出了一种基于对比学习和一类分类法的深度对比单类时序异常检测方法(COCA)，能够提高检测性能。 |
| [^83] | [Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes.](http://arxiv.org/abs/2205.13589) | 本文提出了代理变量悲观策略优化 (P3O) 算法，它通过近端因果推断构建悲观置信区间耦合序列解决了部分可观察马尔可夫决策过程中的混淆偏差和最优策略与行为策略之间的分布偏移问题。 |
| [^84] | [Least-to-Most Prompting Enables Complex Reasoning in Large Language Models.](http://arxiv.org/abs/2205.10625) | 本文提出最少到最多提示的策略，能够帮助大规模语言模型实现复杂推理并推广到难度更高的问题。通过这种策略结合GPT-3 code-davinci-002模型能够完美解决组合泛化基准SCAN中的所有分割。 |
| [^85] | [Rethinking Portrait Matting with Privacy Preserving.](http://arxiv.org/abs/2203.16828) | 本论文提出了P3M-10k，这是首个用于隐私保护肖像抠图的大规模匿名基准测试。同时，本研究提出了统一的抠图模型P3M-Net和有效的跨域性能提升策略P3M-CP。 |
| [^86] | [Unified Instance and Knowledge Alignment Pretraining for Aspect-based Sentiment Analysis.](http://arxiv.org/abs/2110.13398) | 本论文提出了一种统一实例和知识对齐预训练框架，能够有效解决预训练和下游ABSA数据集之间的领域偏移问题，提高了基于方面的情感分析的性能，达到了最先进水平。 |
| [^87] | [Super Neurons.](http://arxiv.org/abs/2109.01594) | 本文提出了一种新型产生神经元模型——超级神经元，可以克服传统神经网络的核定位限制，从而实现随机或可学习的核移位，增加每个连接的接受野大小，提高深度学习模型的性能同时降低模型的复杂性。 |
| [^88] | [Situated Conditional Reasoning.](http://arxiv.org/abs/2109.01552) | 本文提出了一种基于情境的条件语句形式，其比经典条件语句表现力更强，能区分期望和虚拟语气，并被证明可以用一组合理性假设进行描述，在此基础上为情境条件知识库定义了一种最小闭包的包含形式。 |
| [^89] | [DeliData: A dataset for deliberation in multi-party problem solving.](http://arxiv.org/abs/2108.05271) | 该文介绍了第一个公开可用的群体协商数据集，500个小组对话和14k个话语，64%的小组成员能够找到比他们单独找到的更好的解决方案。同时提出了一种新的注释模式用于捕捉协商线索，并使用该数据集评估了两种生成协商话语的方法。 |
| [^90] | [AdvSim: Generating Safety-Critical Scenarios for Self-Driving Vehicles.](http://arxiv.org/abs/2101.06549) | 提出了AdvSim框架，利用对抗性方法生成自动驾驶车辆的安全关键场景，具有可扩展性，适用于任何基于激光雷达的自主系统，可以识别各种具有语义意义的安全关键场景。 |
| [^91] | [Theoretical Analyses of Multiobjective Evolutionary Algorithms on Multimodal Objectives.](http://arxiv.org/abs/2012.07231) | 本文证明了当运行时间为无穷大时，SEMO无法找到所有Pareto前沿。但全局SEMO证明了在期望迭代次数上限内找到了所有Pareto前沿，这对于理解多目标进化算法在多峰问题中的应用具有参考价值。 |
| [^92] | [Zero-Shot Compositional Policy Learning via Language Grounding.](http://arxiv.org/abs/2004.07200) | 本论文提出了一种通过语言基础实现零样本组合策略学习的算法，该算法将自然语言描述与策略网络结合，使策略网络能够推广到未见过的属性组合上，实验证明该算法在零样本组合策略学习任务中表现优于现有的RL/IL算法。 |

# 详细

[^1]: 一种数据中心的、基于Vision Transformer的非均质去雾解决方案。

    A Data-Centric Solution to NonHomogeneous Dehazing via Vision Transformer. (arXiv:2304.07874v1 [cs.CV])

    [http://arxiv.org/abs/2304.07874](http://arxiv.org/abs/2304.07874)

    本文提出了一种基于Vision Transformer的数据中心的解决方案，用于解决非均质去雾问题。传统方法在处理NH-HAZE23数据集等非均质雾图像时存在问题，因为它们无法满足建模均质雾所需的假设之一。同时，本文指出光靠数据增广并不能解决问题，因为需要处理分布差异。

    

    近年来，图像去雾引起了越来越多的关注。许多深度学习方法已经被提出来应对这一挑战，并在处理均质雾时取得了显著的成就。然而，这些解决方案无法在应用于存在非均质雾的图像时保持类似的性能，例如NTIRE挑战介绍的NH-HAZE23数据集。其中一个失败的原因是非均质雾不符合建模均质雾所需的假设之一。此外，传统的端到端训练方法需要对大量的非均质雾图像与其清晰对应项进行配对，而NH-HAZE23数据集的数量是有限的。尽管可以通过利用其他非均质去雾数据集扩充NH-HAZE23数据集，但我们观察到有必要设计一种适当的数据预处理方法以减少目标数据集之间的分布差距。

    Recent years have witnessed an increased interest in image dehazing. Many deep learning methods have been proposed to tackle this challenge, and have made significant accomplishments dealing with homogeneous haze. However, these solutions cannot maintain comparable performance when they are applied to images with non-homogeneous haze, e.g., NH-HAZE23 dataset introduced by NTIRE challenges. One of the reasons for such failures is that non-homogeneous haze does not obey one of the assumptions that is required for modeling homogeneous haze. In addition, a large number of pairs of non-homogeneous hazy image and the clean counterpart is required using traditional end-to-end training approaches, while NH-HAZE23 dataset is of limited quantities. Although it is possible to augment the NH-HAZE23 dataset by leveraging other non-homogeneous dehazing datasets, we observe that it is necessary to design a proper data-preprocessing approach that reduces the distribution gaps between the target datase
    
[^2]: 低资源语言的神经机器翻译

    Neural Machine Translation For Low Resource Languages. (arXiv:2304.07869v1 [cs.CL])

    [http://arxiv.org/abs/2304.07869](http://arxiv.org/abs/2304.07869)

    该论文研究了低资源语言的神经机器翻译，并构建了一个基于 \texttt{mBART.CC25} 语言模型的模型，利用后向翻译和迁移学习等 NLP 和深度学习技术进行增强，以达到最先进的结果。

    

    由于自然语言的内在复杂性和流动性，神经机器翻译是一个具有挑战性的任务。尽管近年来在几种语言对中取得了最先进的表现，但在多语言神经机器翻译 (MNMT) 领域看到了很多关注，却没有进行全面调查以确定哪些方法表现良好。该项目的目标是研究低资源语言的领域，并构建一个神经机器翻译模型，以实现最先进的结果。该项目旨在建立在 \texttt{mBART.CC25} 语言模型基础上，并探索利用各种 NLP 和深度学习技术（如后向翻译和迁移学习）来增强它的策略。该实现试图解开 NMT 应用程序的架构，并确定不同的组件，这些组件为我们提供了修改所述应用程序的机会。

    Neural Machine translation is a challenging task due to the inherent complex nature and the fluidity that natural languages bring. Nonetheless, in recent years, it has achieved state-of-the-art performance in several language pairs. Although, a lot of traction can be seen in the areas of multilingual neural machine translation (MNMT) in the recent years, there are no comprehensive survey done to identify what approaches work well. The goal of this project is to investigate the realm of low resource languages and build a Neural Machine Translation model to achieve state-of-the-art results. The project looks to build upon the \texttt{mBART.CC25} \cite{liu2020multilingual} language model and explore strategies to augment it with various NLP and Deep Learning techniques like back translation and transfer learning. This implementation tries to unpack the architecture of the NMT application and determine the different components which offers us opportunities to amend the said application wit
    
[^3]: 一个用于空中交通管制员培训的虚拟模拟飞行员代理

    A Virtual Simulation-Pilot Agent for Training of Air Traffic Controllers. (arXiv:2304.07842v1 [eess.AS])

    [http://arxiv.org/abs/2304.07842](http://arxiv.org/abs/2304.07842)

    本文提出了一个用于加速空中交通管制员培训的基于人工智能的虚拟模拟飞行员引擎，它能够理解口头通讯的意义并进行响应。

    

    本文提出了一个创新的、基于人工智能的虚拟模拟飞行员引擎，用于加速空中交通管制员（ATCo）的培训。虚拟模拟飞行员引擎接收来自ATCo学员的口头通讯，进行自动语音识别和理解，不仅仅是简单的文本转录，还能理解其意义并进行响应。整个流程由以下子模块组成：(i)自动语音识别（ASR），将音频转换为单词序列；(ii)高级空中交通管制（ATC）相关实体解析器，理解转录的语音通讯；(iii)文本转语音子模块，根据对话的情境生成类似于飞行员的口头语回复。

    In this paper we propose a novel virtual simulation-pilot engine for speeding up air traffic controller (ATCo) training by integrating different state-of-the-art artificial intelligence (AI) based tools. The virtual simulation-pilot engine receives spoken communications from ATCo trainees, and it performs automatic speech recognition and understanding. Thus, it goes beyond only transcribing the communication and can also understand its meaning. The output is subsequently sent to a response generator system, which resembles the spoken read back that pilots give to the ATCo trainees. The overall pipeline is composed of the following submodules: (i) automatic speech recognition (ASR) system that transforms audio into a sequence of words; (ii) high-level air traffic control (ATC) related entity parser that understands the transcribed voice communication; and (iii) a text-to-speech submodule that generates a spoken utterance that resembles a pilot based on the situation of the dialogue. Our
    
[^4]: 基于随机补丁的人脸识别系统防物理攻击策略

    A Random-patch based Defense Strategy Against Physical Attacks for Face Recognition Systems. (arXiv:2304.07822v1 [cs.CV])

    [http://arxiv.org/abs/2304.07822](http://arxiv.org/abs/2304.07822)

    本文提出了一种基于随机补丁的防御策略，用于强化人脸识别系统（FRS）来检测物理攻击，该方法在检测白盒攻击和自适应攻击方面表现出优越性，且简单易用。

    

    物理攻击被视为真实世界计算机视觉系统的一种威胁。然而，许多现有的防御方法只适用于小扰动攻击，并且不能有效检测物理攻击。本文提出了一种基于随机补丁的防御策略，用于强化人脸识别系统（FRS）来检测物理攻击。不同于主流防御方法着眼于构建复杂的深度神经网络（DNN）以在攻击中获得高识别率，我们将基于补丁的防御策略引入到标准DNN中，旨在获得强大的检测模型。利用所采用数据集的广泛实验结果表明了所提出的防御方法在检测白盒攻击和攻击FRS和防御方法的自适应攻击方面的优越性。此外，由于我们方法的简单而强大，它可以轻松应用于真实世界的人脸识别系统，并扩展到其他防御方法。

    The physical attack has been regarded as a kind of threat against real-world computer vision systems. Still, many existing defense methods are only useful for small perturbations attacks and can't detect physical attacks effectively. In this paper, we propose a random-patch based defense strategy to robustly detect physical attacks for Face Recognition System (FRS). Different from mainstream defense methods which focus on building complex deep neural networks (DNN) to achieve high recognition rate on attacks, we introduce a patch based defense strategy to a standard DNN aiming to obtain robust detection models. Extensive experimental results on the employed datasets show the superiority of the proposed defense method on detecting white-box attacks and adaptive attacks which attack both FRS and the defense method. Additionally, due to the simpleness yet robustness of our method, it can be easily applied to the real world face recognition system and extended to other defense methods to b
    
[^5]: VISAR：一种带有可视化编程和快速草案原型的人工智能论证写作助手

    VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping. (arXiv:2304.07810v1 [cs.HC])

    [http://arxiv.org/abs/2304.07810](http://arxiv.org/abs/2304.07810)

    VISAR是一个AI写作助手，旨在帮助作者提升写作体验和输出。它可以在写作上下文中随时帮助作者构思和修改目标，通过可视化编程来组织论证结构，并提供推荐来增加说服力。自动草案原型可以用来验证计划。

    

    在辩论写作中，作者必须构思分层写作目标，确保其论点的说服力，并通过起草来修订和组织他们的计划。最近大型语言模型（LLM）的进展使得通过聊天界面进行交互式文本生成（例如ChatGPT）成为可能。然而，这种方法常常忽略了隐含的写作上下文和用户意图，缺乏用户控制和自主权，并且提供有限的帮助来进行意义构建和修订写作计划。为了应对这些挑战，我们引入了VISAR，一种AI支持的写作助手系统，旨在帮助作者在其写作上下文中构思和修订分层目标，通过同步文本编辑和可视化编程组织论证结构，并通过论证火花推荐增强说服力。VISAR允许用户使用自动草案原型探索、实验和验证他们的写作计划。一个受控实验室研究证实，VISAR可以通过客观和主观评估，有效地改善用户的写作体验和结果。

    In argumentative writing, writers must brainstorm hierarchical writing goals, ensure the persuasiveness of their arguments, and revise and organize their plans through drafting. Recent advances in large language models (LLMs) have made interactive text generation through a chat interface (e.g., ChatGPT) possible. However, this approach often neglects implicit writing context and user intent, lacks support for user control and autonomy, and provides limited assistance for sensemaking and revising writing plans. To address these challenges, we introduce VISAR, an AI-enabled writing assistant system designed to help writers brainstorm and revise hierarchical goals within their writing context, organize argument structures through synchronized text editing and visual programming, and enhance persuasiveness with argumentation spark recommendations. VISAR allows users to explore, experiment with, and validate their writing plans using automatic draft prototyping. A controlled lab study confi
    
[^6]: 基于模糊概率决策树的临床实践辅助研究

    Assisting clinical practice with fuzzy probabilistic decision trees. (arXiv:2304.07788v1 [cs.LG])

    [http://arxiv.org/abs/2304.07788](http://arxiv.org/abs/2304.07788)

    我们提出了一种基于概率树和模糊逻辑的新方法MedFP，用于辅助医学实践。该方法可以完全解释，允许临床医生产生、控制和验证整个诊断过程，并减少误诊率，通过提供不确定性和反事实分析的估计值。

    

    越来越多的人意识到需要完全人类可理解的模型，这是人工智能研究的一个核心主题。当这些模型是可解释的时，接受人工智能模型辅助敏感领域决策的趋势将会增长，并且即将出台的法规将会加强对可解释模型的倾斜。可解释人工智能的切入点之一是医学实践，它可以受益于精确的决策支持方法，这些方法本质上会产生信任。在这项工作中，我们提出了一种新的方法——MedFP，它结合了概率树和模糊逻辑来辅助临床实践。该方法完全可解释，因为它允许临床医生产生、控制和验证整个诊断过程；该方法的一个优点是减少误诊率，通过提供不确定性和反事实分析的估计值。我们的方法作为概念证明应用于两个真实的医学场景中：肿瘤分类和糖尿病类型2的诊断。

    The need for fully human-understandable models is increasingly being recognised as a central theme in AI research. The acceptance of AI models to assist in decision making in sensitive domains will grow when these models are interpretable, and this trend towards interpretable models will be amplified by upcoming regulations. One of the killer applications of interpretable AI is medical practice, which can benefit from accurate decision support methodologies that inherently generate trust. In this work, we propose FPT, (MedFP), a novel method that combines probabilistic trees and fuzzy logic to assist clinical practice. This approach is fully interpretable as it allows clinicians to generate, control and verify the entire diagnosis procedure; one of the methodology's strength is the capability to decrease the frequency of misdiagnoses by providing an estimate of uncertainties and counterfactuals. Our approach is applied as a proof-of-concept to two real medical scenarios: classifying ma
    
[^7]: 文本嵌入精准检测假新闻

    It's All in the Embedding! Fake News Detection Using Document Embeddings. (arXiv:2304.07781v1 [cs.CL])

    [http://arxiv.org/abs/2304.07781](http://arxiv.org/abs/2304.07781)

    本文提出一种基于文本嵌入的假新闻检测方法，利用新闻文章的时间和主题背景，可有效检测假新闻。

    

    随着媒体的数字化进程和社交媒体的兴起，个性化社交媒体已成为新的常态。然而，数字化进程增加了流传假信息、错误信息和变形信息的风险，从而导致了假新闻这一有害现象的出现。这些信息可以扭曲公众对特定话题的看法，并且缺乏传统新闻的严谨性。为了开发有效的工具来检测假新闻，自然语言处理和机器学习技术至关重要。本文提出了一种基于文本嵌入的假新闻检测方法，利用新闻文章的时间和主题背景。实验结果表明，我们的方法在各种数据集上均取得了较高的准确度，并且超越了基线模型和其他最先进的方法。

    With the current shift in the mass media landscape from journalistic rigor to social media, personalized social media is becoming the new norm. Although the digitalization progress of the media brings many advantages, it also increases the risk of spreading disinformation, misinformation, and malformation through the use of fake news. The emergence of this harmful phenomenon has managed to polarize society and manipulate public opinion on particular topics, e.g., elections, vaccinations, etc. Such information propagated on social media can distort public perceptions and generate social unrest while lacking the rigor of traditional journalism. Natural Language Processing and Machine Learning techniques are essential for developing efficient tools that can detect fake news. Models that use the context of textual data are essential for resolving the fake news detection problem, as they manage to encode linguistic features within the vector representation of words. In this paper, we propos
    
[^8]: MisRoB{\AE}RTa：变形金刚对抗不实信息

    MisRoB{\AE}RTa: Transformers versus Misinformation. (arXiv:2304.07759v1 [cs.CL])

    [http://arxiv.org/abs/2304.07759](http://arxiv.org/abs/2304.07759)

    本文提出了一种新型基于Transformer的深度神经网络集成体系结构MisRoB{\AE}RTa，用于不实信息检测，并在大型现实世界新闻文章数据集上进行了测试和评估。

    

    不实信息被认为是我们民主的价值观和原则的威胁。这种内容在社交媒体上的传播会使社会极端化，并通过扭曲公众的看法并引发社会动荡而破坏公共话语，同时缺乏传统新闻的严谨性。在多个具有知名度的自然语言处理任务中，Transformer和迁移学习被证明是最先进的方法。在本文中，我们提出了MisRoB{\AE}RTa，这是一种新颖的基于Transformer的深度神经网络集成体系结构，用于不实信息检测。MisRoB{\AE}RTa利用了两个Transformer（BART和RoBERTa）来提高分类性能。我们还对多个Transformer在不实信息检测任务上的性能进行了基准测试和评估。对于训练和测试，我们使用了一个带有10个类别标签的大型现实世界新闻文章数据集，解决了当前研究中的两个缺点：将数据集的规模从小到大，并将焦点从社交媒体移动到新闻领域。

    Misinformation is considered a threat to our democratic values and principles. The spread of such content on social media polarizes society and undermines public discourse by distorting public perceptions and generating social unrest while lacking the rigor of traditional journalism. Transformers and transfer learning proved to be state-of-the-art methods for multiple well-known natural language processing tasks. In this paper, we propose MisRoB{\AE}RTa, a novel transformer-based deep neural ensemble architecture for misinformation detection. MisRoB{\AE}RTa takes advantage of two transformers (BART \& RoBERTa) to improve the classification performance. We also benchmarked and evaluated the performances of multiple transformers on the task of misinformation detection. For training and testing, we used a large real-world news articles dataset labeled with 10 classes, addressing two shortcomings in the current research: increasing the size of the dataset from small to large, and moving th
    
[^9]: 可解释的基于Transformer的LiDAR-惯性融合里程计估计

    TransFusionOdom: Interpretable Transformer-based LiDAR-Inertial Fusion Odometry Estimation. (arXiv:2304.07728v1 [cs.RO])

    [http://arxiv.org/abs/2304.07728](http://arxiv.org/abs/2304.07728)

    本文提出了一种可解释的基于Transformer的LiDAR-惯性融合里程计估计方法，通过多头注意力融合模块展示了不同融合方法，实验表明该方法在KITTI和EuRoC数据集上表现优于现有方法。

    

    增强里程计估计性能的常用方法是多模态传感器融合，这也是移动机器人的基本模块。然而，在监督式传感器融合里程计估计任务中，如何在不同模态之间执行融合仍然是具有挑战性的问题。一些简单的操作，如逐元素求和和连接，并不具备分配自适应关注权重以有效合并不同模态的能力，这使得获得具有竞争力的里程计结果变得困难。最近，Transformer架构显示出在视觉与语言领域的多模态融合任务中具有潜力。在本文中，我们提出了一种基于Transformer的端到端的激光雷达-惯性融合框架(即TransFusionOdom)来进行里程计估计。多头注意力融合模块展示了同构和异构模态的不同融合方法。所提出的TransFusionOdom模型在KITTI和EuRoC数据集上显示出比现有方法更好的性能。

    Multi-modal fusion of sensors is a commonly used approach to enhance the performance of odometry estimation, which is also a fundamental module for mobile robots. However, the question of \textit{how to perform fusion among different modalities in a supervised sensor fusion odometry estimation task?} is still one of challenging issues remains. Some simple operations, such as element-wise summation and concatenation, are not capable of assigning adaptive attentional weights to incorporate different modalities efficiently, which make it difficult to achieve competitive odometry results. Recently, the Transformer architecture has shown potential for multi-modal fusion tasks, particularly in the domains of vision with language. In this work, we propose an end-to-end supervised Transformer-based LiDAR-Inertial fusion framework (namely TransFusionOdom) for odometry estimation. The multi-attention fusion module demonstrates different fusion approaches for homogeneous and heterogeneous modalit
    
[^10]: 学习经验Bregman散度用于不确定距离表示

    Learning Empirical Bregman Divergence for Uncertain Distance Representation. (arXiv:2304.07689v1 [cs.CV])

    [http://arxiv.org/abs/2304.07689](http://arxiv.org/abs/2304.07689)

    本文介绍了一种新的基于Deep Metric Learning的方法，通过学习经验Bregman散度直接从数据中进行不确定距离表示，能够有效的在模式识别和聚类任务上提高准确性。

    

    深度度量学习技术已应用于各种监督和无监督学习任务，通过深度网络学习样本嵌入来进行视觉表示。然而，经典方法采用固定距离度量作为两个嵌入之间的相似性函数，可能导致捕捉复杂数据分布的亚最优性能。Bregman散度概括了各种距离度量的度量，并在许多深度度量学习领域中产生。本文首先展示了如何从Bregman散度获得深度度量学习损失。然后，我们介绍了一种直接从数据中学习经验Bregman散度的新方法，通过使用深度学习设置对Bregman散度下的凸函数进行参数化。我们进一步实验证明，与其他SOTA深度度量学习方法相比，我们的方法在五个流行公共数据集上表现出色，特别是在模式识别和聚类任务上。

    Deep metric learning techniques have been used for visual representation in various supervised and unsupervised learning tasks through learning embeddings of samples with deep networks. However, classic approaches, which employ a fixed distance metric as a similarity function between two embeddings, may lead to suboptimal performance for capturing the complex data distribution. The Bregman divergence generalizes measures of various distance metrics and arises throughout many fields of deep metric learning. In this paper, we first show how deep metric learning loss can arise from the Bregman divergence. We then introduce a novel method for learning empirical Bregman divergence directly from data based on parameterizing the convex function underlying the Bregman divergence with a deep learning setting. We further experimentally show that our approach performs effectively on five popular public datasets compared to other SOTA deep metric learning methods, particularly for pattern recognit
    
[^11]: FedBlockHealth：基于联邦学习和区块链的IoT医疗保健隐私和安全协同方法

    FedBlockHealth: A Synergistic Approach to Privacy and Security in IoT-Enabled Healthcare through Federated Learning and Blockchain. (arXiv:2304.07668v1 [cs.CR])

    [http://arxiv.org/abs/2304.07668](http://arxiv.org/abs/2304.07668)

    本文提出了一种基于联邦学习和区块链技术的创新方法，为IoT医疗保健应用提供安全和隐私保护的解决方案，实现了安全的模型聚合，同时不共享敏感患者数据。

    

    在医疗保健领域，物联网设备的广泛应用给数据隐私、安全和患者安全带来新的挑战。传统的方法需要保证安全和隐私，同时保持计算效率，特别是对于资源受限的物联网设备。本文提出了一种创新的混合方法，结合了联邦学习和区块链技术，为IoT医疗保健应用提供安全和隐私保护的解决方案。我们的方法利用公钥加密系统为本地模型更新提供语义安全，而区块链技术确保这些更新的完整性并强制访问控制和问责制。联邦学习过程实现了安全的模型聚合，同时不共享敏感患者数据。我们使用EMNIST数据集实现和评估了我们提出的框架，证明了在保持计算效率的同时，有效地保护了数据隐私和安全。

    The rapid adoption of Internet of Things (IoT) devices in healthcare has introduced new challenges in preserving data privacy, security and patient safety. Traditional approaches need to ensure security and privacy while maintaining computational efficiency, particularly for resource-constrained IoT devices. This paper proposes a novel hybrid approach combining federated learning and blockchain technology to provide a secure and privacy-preserved solution for IoT-enabled healthcare applications. Our approach leverages a public-key cryptosystem that provides semantic security for local model updates, while blockchain technology ensures the integrity of these updates and enforces access control and accountability. The federated learning process enables a secure model aggregation without sharing sensitive patient data. We implement and evaluate our proposed framework using EMNIST datasets, demonstrating its effectiveness in preserving data privacy and security while maintaining computatio
    
[^12]: EEG SN：面向 EEG 的图形脉冲神经网络的高效低延迟解码

    EEGSN: Towards Efficient Low-latency Decoding of EEG with Graph Spiking Neural Networks. (arXiv:2304.07655v1 [cs.NE])

    [http://arxiv.org/abs/2304.07655](http://arxiv.org/abs/2304.07655)

    该论文提出了一种名为 EEGSN 的图形脉冲神经网络（SNN）架构，面向多通道 EEG 分类任务，在学习分布式 EEG 传感器中的动态关系信息的同时，将推断计算复杂度降低了20倍，为低延迟和功耗效率的脑计算机接口的开发提供了一个可行的框架。

    

    目前大多数脉冲神经网络（SNN）的训练依赖于归纳偏差，这并不一定适用于多个需要低延迟和功耗效率的关键任务。 基于相关的脑电图（EEG）信号推断大脑行为就是一个这样的例子，学习时空依赖关系会严重影响网络的训练和推断效率。目前，SNN仅仅依靠一般归纳偏差来模拟不同数据流之间的动态关系。在这里，我们提出了一种用于多通道 EEG 分类的图形脉冲神经网络架构（EEGSN），它能够学习分布在 EEG 传感器中的动态关系信息。与现有技术相比，我们的方法将推断计算复杂度降低了20倍，同时在运动执行分类任务上达到了可比较的准确性。总体而言，我们的工作为可解释和高效训练 EEG 数据的图形SNN提供了一个框架，从而实现了低延迟和功耗效率的脑-计算机界面的开发。

    A vast majority of spiking neural networks (SNNs) are trained based on inductive biases that are not necessarily a good fit for several critical tasks that require low-latency and power efficiency. Inferring brain behavior based on the associated electroenchephalography (EEG) signals is an example of how networks training and inference efficiency can be heavily impacted by learning spatio-temporal dependencies. Up to now, SNNs rely solely on general inductive biases to model the dynamic relations between different data streams. Here, we propose a graph spiking neural network architecture for multi-channel EEG classification (EEGSN) that learns the dynamic relational information present in the distributed EEG sensors. Our method reduced the inference computational complexity by $\times 20$ compared to the state-of-the-art SNNs, while achieved comparable accuracy on motor execution classification tasks. Overall, our work provides a framework for interpretable and efficient training of gr
    
[^13]: 针对稳定的超网络学习的非比例参数化

    Non-Proportional Parametrizations for Stable Hypernetwork Learning. (arXiv:2304.07645v1 [cs.LG])

    [http://arxiv.org/abs/2304.07645](http://arxiv.org/abs/2304.07645)

    本文提出一种针对当前超网络训练策略不稳定、收敛速度慢的问题的解决方案，通过使用非比例加性参数化的方式来修订超网络形式，实现更加稳定和快速的训练。

    

    超网络是生成另一个神经网络参数的神经网络。在许多情况下，当前的超网络训练策略是不稳定的，收敛速度通常比非超网络模型慢得多。我们展示了这个问题与使用常见的超网络架构和初始化时出现的问题有关。我们在理论上和实验上证明了这种数值问题在训练过程中会导致不稳定性，从而降低甚至阻止收敛。我们还证明了流行的深度学习归一化策略无法解决这些问题。然后，我们提出了一种基于修订的超网络形式的解决方案，该超网络使用非比例加性参数化。我们在几个任务上测试了所提出的重新参数化，并证明它始终可以导致更稳定的训练，实现更快的收敛。

    Hypernetworks are neural networks that generate the parameters of another neural network. In many scenarios, current hypernetwork training strategies are unstable, and convergence is often far slower than for non-hypernetwork models. We show that this problem is linked to an issue that arises when using common choices of hypernetwork architecture and initialization. We demonstrate analytically and experimentally how this numerical issue can lead to an instability during training that slows, and sometimes even prevents, convergence. We also demonstrate that popular deep learning normalization strategies fail to address these issues. We then propose a solution to the problem based on a revised hypernetwork formulation that uses non-proportional additive parametrizations. We test the proposed reparametrization on several tasks, and demonstrate that it consistently leads to more stable training, achieving faster convergence.
    
[^14]: 基于纯净/不纯的N2增油过程中最小相溶压力（MMP）的估计：统计学和机器学习算法的比较研究。

    Estimation of minimum miscibility pressure (MMP) in impure/pure N2 based enhanced oil recovery process: A comparative study of statistical and machine learning algorithms. (arXiv:2304.07617v1 [cs.LG])

    [http://arxiv.org/abs/2304.07617](http://arxiv.org/abs/2304.07617)

    本研究比较了统计学和机器学习方法用于估计N2增油过程中的最小相溶压力，表明本研究开发的预测模型具有更好的性能。

    

    最小相溶压力（MMP）的预测在设计和操作基于氮的增油过程中起着重要作用。本文进行了统计学和机器学习方法用于MMP估计的比较研究。本研究开发的大多数预测模型显示出比文献中报告的相关和预测模型更优越的性能。

    Minimum miscibility pressure (MMP) prediction plays an important role in design and operation of nitrogen based enhanced oil recovery processes. In this work, a comparative study of statistical and machine learning methods used for MMP estimation is carried out. Most of the predictive models developed in this study exhibited superior performance over correlation and predictive models reported in literature.
    
[^15]: 基于多态电光电路与架构的高速、节能的非二进制计算

    High-Speed and Energy-Efficient Non-Binary Computing with Polymorphic Electro-Optic Circuits and Architectures. (arXiv:2304.07608v1 [cs.AR])

    [http://arxiv.org/abs/2304.07608](http://arxiv.org/abs/2304.07608)

    本文提出了一种基于微环谐振器的多态电光电路与架构，可用于高速、节能的非二进制可重构计算，并能处理多种数据格式和卷积神经网络。

    

    本文提出了基于微环谐振器的多态电光电路与架构，可用于高速、节能的非二进制可重构计算。我们的多态电光电路可以动态编程，在不同时间实现不同的逻辑和算术功能。它们可以提供紧凑性和多态性，从而提高操作数处理能力，减少空闲时间，并增加面积和静态功率开销的摊销。当与柔性光电探测器结合使用时，我们的电路可以支持非二进制格式（如随机/一元和高维储备格式）的数据的节能处理。此外，我们的多态电光电路还可以实现可配置的电光计算加速器架构，用于处理二进制和整数量化的卷积神经网络（CNN）。我们比较了我们设计的多态电光电路

    In this paper, we present microring resonator (MRR) based polymorphic E-O circuits and architectures that can be employed for high-speed and energy-efficient non-binary reconfigurable computing. Our polymorphic E-O circuits can be dynamically programmed to implement different logic and arithmetic functions at different times. They can provide compactness and polymorphism to consequently improve operand handling, reduce idle time, and increase amortization of area and static power overheads. When combined with flexible photodetectors with the innate ability to accumulate a high number of optical pulses in situ, our circuits can support energy-efficient processing of data in non-binary formats such as stochastic/unary and high-dimensional reservoir formats. Furthermore, our polymorphic E-O circuits enable configurable E-O computing accelerator architectures for processing binarized and integer quantized convolutional neural networks (CNNs). We compare our designed polymorphic E-O circuit
    
[^16]: 教师网络校准在跨质量知识蒸馏中的应用

    Teacher Network Calibration Improves Cross-Quality Knowledge Distillation. (arXiv:2304.07593v1 [cs.CV])

    [http://arxiv.org/abs/2304.07593](http://arxiv.org/abs/2304.07593)

    本论文研究了跨质量知识蒸馏方法，将使用高分辨率图像训练的教师网络中的知识转移到低分辨率图像的学生网络中，并通过提高温度平滑教师输出分布来优化方法，实现在大规模图像分类问题中的性能优越。

    

    本研究探讨了跨质量知识蒸馏（CQKD），一种知识蒸馏方法，其中从使用高分辨率图像训练的教师网络中获取知识，然后将其转移到仅使用低分辨率图像的学生网络。由于图像大小是影响计算机视觉应用程序计算负荷的重要因素，CQKD通过仅在推断时使用学生网络，显着降低了要求。我们的实验结果表明，CQKD在大规模图像分类问题中优于监督学习。我们还强调了校准神经网络的重要性：我们表明，通过更高的温度平滑教师输出分布，学生分布展现出更高的熵，这既降低了校准误差，也提高了网络精度。

    We investigate cross-quality knowledge distillation (CQKD), a knowledge distillation method where knowledge from a teacher network trained with full-resolution images is transferred to a student network that takes as input low-resolution images. As image size is a deciding factor for the computational load of computer vision applications, CQKD notably reduces the requirements by only using the student network at inference time. Our experimental results show that CQKD outperforms supervised learning in large-scale image classification problems. We also highlight the importance of calibrating neural networks: we show that with higher temperature smoothing of the teacher's output distribution, the student distribution exhibits a higher entropy, which leads to both, a lower calibration error and a higher network accuracy.
    
[^17]: 从在线行为到图片：社交机器人检测的新方法

    From Online Behaviours to Images: A Novel Approach to Social Bot Detection. (arXiv:2304.07535v1 [cs.SI])

    [http://arxiv.org/abs/2304.07535](http://arxiv.org/abs/2304.07535)

    该论文提出了一种基于算法和卷积神经网络的新方法来检测 Twitter 机器人账号，通过将其行为转换为图片进行分类，通过测试发现该方法比传统的机器人检测方法更加有效。

    

    在线社交网络彻底改变了我们消费和共享信息的方式，但也带来了一大堆不可靠和不准确的内容。其中一种特殊类型的社交账号，被称为“机器人”，它们通过自动化操作来宣传不可信的内容、过度支持政治派系和宣传机构化信息。我们专注于 Twitter 账号，提出了一种新颖的机器人检测方法，利用一种新的算法将账号执行的操作序列转换成图片，然后利用卷积神经网络的强大功能进行图像分类。

    Online Social Networks have revolutionized how we consume and share information, but they have also led to a proliferation of content not always reliable and accurate. One particular type of social accounts is known to promote unreputable content, hyperpartisan, and propagandistic information. They are automated accounts, commonly called bots. Focusing on Twitter accounts, we propose a novel approach to bot detection: we first propose a new algorithm that transforms the sequence of actions that an account performs into an image; then, we leverage the strength of Convolutional Neural Networks to proceed with image classification. We compare our performances with state-of-the-art results for bot detection on genuine accounts / bot accounts datasets well known in the literature. The results confirm the effectiveness of the proposal, because the detection capability is on par with the state of the art, if not better in some cases.
    
[^18]: STAS: 多智能体强化学习的时空回报分解

    STAS: Spatial-Temporal Return Decomposition for Multi-agent Reinforcement Learning. (arXiv:2304.07520v1 [cs.AI])

    [http://arxiv.org/abs/2304.07520](http://arxiv.org/abs/2304.07520)

    提出了一种名为STAS的新方法，用于多智能体强化学习中时空回报分解，可以对代理进行信用分配。该方法引入了Shapley值和空间-时间注意机制来解决先前方法中延迟全局回报的复杂关系问题。在各种基准环境下，该方法表现良好。

    

    集中式训练和分散式执行（CTDE）已被证明是合作多智能体强化学习（MARL）中有效的范例。其中一个主要的挑战是赋信用值，即通过代理的贡献来给代理赋信用值。先前的研究集中于隐式地分解联合价值函数或显式地计算所有代理的支付分配。然而，在只有在周期性强化学习设置中，全局奖励只能在周期结束时显示。现有的方法通常不起作用。它们缺乏对延迟全局奖励在时间维度中复杂关系的建模功能，并且受偏差和方差的影响较大。我们提出了一种名为空间时间关注与 Shapley（STAS）的新方法，用于回报分解；STAS 在时间和空间维度上学习信用分配。它首先将全局回报分解回到每个时间步，然后使用Shapley值来评估协作MARL中每个代理的贡献。 STAS 还引入了一种空间 - 时间关注机制，以捕获延迟全局奖励的复杂关系。我们的实验表明，在各种基准环境中，STAS 能够胜过最先进的方法。

    Centralized Training with Decentralized Execution (CTDE) has been proven to be an effective paradigm in cooperative multi-agent reinforcement learning (MARL). One of the major challenges is yet credit assignment, which aims to credit agents by their contributions. Prior studies focus on either implicitly decomposing the joint value function or explicitly computing the payoff distribution of all agents. However, in episodic reinforcement learning settings where global rewards can only be revealed at the end of the episode, existing methods usually fail to work. They lack the functionality of modeling complicated relations of the delayed global reward in the temporal dimension and suffer from large variance and bias. We propose a novel method named Spatial-Temporal Attention with Shapley (STAS) for return decomposition; STAS learns credit assignment in both the temporal and the spatial dimension. It first decomposes the global return back to each time step, then utilizes Shapley Value to
    
[^19]: PI-FL：个性化和激励联邦学习

    PI-FL: Personalized and Incentivized Federated Learning. (arXiv:2304.07514v1 [cs.LG])

    [http://arxiv.org/abs/2304.07514](http://arxiv.org/abs/2304.07514)

    PI-FL是一种个性化的联邦学习解决方案，使用基于令牌的激励机制奖励个性化训练，可以在尊重客户端隐私的同时生成高质量的个性化模型。

    

    个性化联邦学习已被广泛应用于应对非独立同分布数据异质性的挑战。主要问题是考虑来自客户端的个性化过程以保护其自治权。允许客户端参与个性化联邦学习决策变得重要，因为存在隐私和安全问题，客户端可能无法自由共享生成良好质量个性化模型所必需的私人信息。此外，具有高质量数据和资源的客户端不愿意在没有合理激励的情况下参与联邦学习过程。在本文中，我们提出了PI-FL，这是一个一次性个性化解决方案，配合一个基于令牌的激励机制，奖励个性化训练。PI-FL优于其他最先进的方法，并且可以在尊重客户端隐私的同时生成高质量的个性化模型。

    Personalized FL has been widely used to cater to heterogeneity challenges with non-IID data. A primary obstacle is considering the personalization process from the client's perspective to preserve their autonomy. Allowing the clients to participate in personalized FL decisions becomes significant due to privacy and security concerns, where the clients may not be at liberty to share private information necessary for producing good quality personalized models. Moreover, clients with high-quality data and resources are reluctant to participate in the FL process without reasonable incentive. In this paper, we propose PI-FL, a one-shot personalization solution complemented by a token-based incentive mechanism that rewards personalized training. PI-FL outperforms other state-of-the-art approaches and can generate good-quality personalized models while respecting clients' privacy.
    
[^20]: 层次化对比表示学习用于知识驱动推荐

    Hierarchical and Contrastive Representation Learning for Knowledge-aware Recommendation. (arXiv:2304.07506v1 [cs.IR])

    [http://arxiv.org/abs/2304.07506](http://arxiv.org/abs/2304.07506)

    本文提出了HiCON框架，运用层次化对比表示学习提高了学习到的节点表示的区分能力，同时采用分层消息聚合机制避免了邻居的指数级扩展，从而有效地解决了知识驱动推荐中的过度平滑问题。

    

    将知识图谱融入推荐是缓解数据稀疏性的有效方法。然而，现有的知识驱动方法通常通过枚举图的邻居进行递归嵌入传播。随着跳数的增加，节点的邻居数呈指数级增长，迫使节点在此递归传播中了解大量邻居以提炼高阶语义相关性。这可能会引入更多有害噪声，导致学习到的节点表示彼此难以区分，即众所周知的过度平滑问题。为了缓解这个问题，我们提出了一种名为HiCON的知识驱动推荐的Hierarchical and Contrastive表示学习框架。具体而言，为了避免邻居的指数级扩展，我们提出了一种分层消息聚合机制，以单独与低阶邻居和元路径受限的高阶邻居交互。此外，为了提高学习表示的区分能力，我们提出了一种对比学习策略，其中鼓励相似的节点相互靠近，而把不相似的节点推开。在三个基准数据集上的实验结果验证了我们所提出方法的有效性。

    Incorporating knowledge graph into recommendation is an effective way to alleviate data sparsity. Most existing knowledge-aware methods usually perform recursive embedding propagation by enumerating graph neighbors. However, the number of nodes' neighbors grows exponentially as the hop number increases, forcing the nodes to be aware of vast neighbors under this recursive propagation for distilling the high-order semantic relatedness. This may induce more harmful noise than useful information into recommendation, leading the learned node representations to be indistinguishable from each other, that is, the well-known over-smoothing issue. To relieve this issue, we propose a Hierarchical and CONtrastive representation learning framework for knowledge-aware recommendation named HiCON. Specifically, for avoiding the exponential expansion of neighbors, we propose a hierarchical message aggregation mechanism to interact separately with low-order neighbors and meta-path-constrained high-order
    
[^21]: 低资源和不平衡数据集下的鲁棒教育对话行为分类器

    Robust Educational Dialogue Act Classifiers with Low-Resource and Imbalanced Datasets. (arXiv:2304.07499v1 [cs.CL])

    [http://arxiv.org/abs/2304.07499](http://arxiv.org/abs/2304.07499)

    本文提出了一种新型的教育对话行为分类器MIREX，它采用互信息最小化损失来提高对不平衡和低资源数据情景下数据的鲁棒性，并在实验中展现出较好的效果。

    

    对话行为可以代表在辅导对话期间发生的教练员或学生的对话动作。在教育对话中自动识别对话行为对于基于对话的智能辅导系统的设计是重要的。许多先前的研究采用机器学习模型对辅导对话中的对话行为进行分类，并投入大量精力使用有限的训练数据（即低资源数据场景）来优化分类准确性。然而，除了分类准确性之外，分类器的鲁棒性也很重要，这可以反映分类器学习不同类别分布的模式的能力。我们注意到，许多先前的教育对话行为分类研究采用交叉熵（CE）损失来优化低资源数据中的DA分类器。这些研究中的DA分类器往往以牺牲少数类的代价来优先考虑大多数类的准确性，从而可能导致在少数类上性能差。在这篇论文中，我们提出了一种新型的DA分类器MIREX，它采用互信息最小化损失来提高DA分类器在不平衡和低资源数据情景下的鲁棒性。实验结果表明，MIREX在不平衡和低资源的DA数据集上优于现有方法。

    Dialogue acts (DAs) can represent conversational actions of tutors or students that take place during tutoring dialogues. Automating the identification of DAs in tutoring dialogues is significant to the design of dialogue-based intelligent tutoring systems. Many prior studies employ machine learning models to classify DAs in tutoring dialogues and invest much effort to optimize the classification accuracy by using limited amounts of training data (i.e., low-resource data scenario). However, beyond the classification accuracy, the robustness of the classifier is also important, which can reflect the capability of the classifier on learning the patterns from different class distributions. We note that many prior studies on classifying educational DAs employ cross entropy (CE) loss to optimize DA classifiers on low-resource data with imbalanced DA distribution. The DA classifiers in these studies tend to prioritize accuracy on the majority class at the expense of the minority class which 
    
[^22]: 具有内在隐私保护的高效通信和节能无线联邦学习

    Communication and Energy Efficient Wireless Federated Learning with Intrinsic Privacy. (arXiv:2304.07460v1 [cs.LG])

    [http://arxiv.org/abs/2304.07460](http://arxiv.org/abs/2304.07460)

    本文提出了一种名为PFELS的无线FL方案，通过先压缩模型更新再自适应地设计发送功率来提供客户端级别DP保证，并降低通信和能量开销并提高模型精度。

    

    联邦学习（FL）是一种协同学习框架，使边缘设备在保留原始数据的同时协同学习全局模型。虽然FL避免了从本地数据集泄漏直接信息，但仍可能从共享模型推断出敏感信息。为解决FL中的隐私问题，利用差分隐私（DP）机制提供正式的隐私保证。然而，使用无线边缘部署FL时，确保客户端级别的DP面临着重大挑战。在本文中，我们提出了一种名为带稀疏化的私有联邦边缘学习（PFELS）的新型无线FL方案，以提供具有内在信道噪声的客户端级别DP保证，同时降低通信和能量开销并提高模型精度。PFELS的关键思想是使每个设备先压缩其模型更新，然后根据无线信道自适应设计压缩模型更新的发送功率。

    Federated Learning (FL) is a collaborative learning framework that enables edge devices to collaboratively learn a global model while keeping raw data locally. Although FL avoids leaking direct information from local datasets, sensitive information can still be inferred from the shared models. To address the privacy issue in FL, differential privacy (DP) mechanisms are leveraged to provide formal privacy guarantee. However, when deploying FL at the wireless edge with over-the-air computation, ensuring client-level DP faces significant challenges. In this paper, we propose a novel wireless FL scheme called private federated edge learning with sparsification (PFELS) to provide client-level DP guarantee with intrinsic channel noise while reducing communication and energy overhead and improving model accuracy. The key idea of PFELS is for each device to first compress its model update and then adaptively design the transmit power of the compressed model update according to the wireless cha
    
[^23]: 基于上下文感知的时间序列异常检测领域自适应

    Context-aware Domain Adaptation for Time Series Anomaly Detection. (arXiv:2304.07453v1 [cs.LG])

    [http://arxiv.org/abs/2304.07453](http://arxiv.org/abs/2304.07453)

    本论文提出了一个框架，通过自适应地采样两个领域的上下文信息来在两个领域之间传递知识。这个框架结合了上下文采样和异常检测，既可以进行无监督域适应，也可以进行有监督的异常检测。

    

    时间序列异常检测是一项具有广泛实际应用的挑战性任务。由于标签稀疏性，训练深度异常检测器通常依赖于无监督方法。最近已经致力于时间序列领域自适应，以利用类似领域中的知识。然而，现有解决方案可能会因其稀疏性和多样性而在异常方面受到负面知识转移的影响。受到两个领域之间上下文对齐的实证研究的启发，我们旨在通过自适应地采样两个领域的上下文信息来在两个领域之间传递知识。这是具有挑战性的，因为它需要同时建模复杂的域内时间相关性和跨域相关性，并利用源域的标签信息。为此，我们提出了一个框架将上下文采样和异常检测结合到一个联合学习过程中。我们将上下文采样表述为马尔可夫决策过程，并利用源域的标签信息进行无监督域适应和有监督的异常检测。

    Time series anomaly detection is a challenging task with a wide range of real-world applications. Due to label sparsity, training a deep anomaly detector often relies on unsupervised approaches. Recent efforts have been devoted to time series domain adaptation to leverage knowledge from similar domains. However, existing solutions may suffer from negative knowledge transfer on anomalies due to their diversity and sparsity. Motivated by the empirical study of context alignment between two domains, we aim to transfer knowledge between two domains via adaptively sampling context information for two domains. This is challenging because it requires simultaneously modeling the complex in-domain temporal dependencies and cross-domain correlations while exploiting label information from the source domain. To this end, we propose a framework that combines context sampling and anomaly detection into a joint learning procedure. We formulate context sampling into the Markov decision process and ex
    
[^24]: 通过多样性优质个体实现高效的质量多样性优化

    Efficient Quality-Diversity Optimization through Diverse Quality Species. (arXiv:2304.07425v1 [cs.LG])

    [http://arxiv.org/abs/2304.07425](http://arxiv.org/abs/2304.07425)

    本文提出了一种新的质量多样性优化算法，通过将解决方案分解为独立进化的物种，并使用无监督的技能发现来学习多样化的高性能解决方案，相对于传统方法，该方法无需存档或预先定义行为范围的限制。

    

    单一目标优化的普遍局限性是它可能会被误导，陷入局部最优解。这可以通过质量多样性(QD)算法来纠正，其中首选问题的高质量和多样性解决方案的人群。大多数传统的QD方法，例如MAP-Elites，明确管理解决方案被分解成预定义的壁龛的行为档案。在这项工作中，我们展示了可以在不需要存档或预先定义行为范围的限制下找到多样化的解决方案种群。相反，我们将解决方案分解为独立进化的物种，并使用无监督的技能发现来学习多样化的高性能解决方案。我们表明，这可以通过基于梯度的突变来完成，这些突变采取互信息和性能的信息理论视角共同最大化。我们提出了多样性优质物种(DQS)作为存档型QD算法的替代方法。

    A prevalent limitation of optimizing over a single objective is that it can be misguided, becoming trapped in local optimum. This can be rectified by Quality-Diversity (QD) algorithms, where a population of high-quality and diverse solutions to a problem is preferred. Most conventional QD approaches, for example, MAP-Elites, explicitly manage a behavioral archive where solutions are broken down into predefined niches. In this work, we show that a diverse population of solutions can be found without the limitation of needing an archive or defining the range of behaviors in advance. Instead, we break down solutions into independently evolving species and use unsupervised skill discovery to learn diverse, high-performing solutions. We show that this can be done through gradient-based mutations that take on an information theoretic perspective of jointly maximizing mutual information and performance. We propose Diverse Quality Species (DQS) as an alternative to archive-based QD algorithms.
    
[^25]: 为零样本个性化提供条件化文本人物形象

    Text-Conditional Contextualized Avatars For Zero-Shot Personalization. (arXiv:2304.07410v1 [cs.CV])

    [http://arxiv.org/abs/2304.07410](http://arxiv.org/abs/2304.07410)

    本研究提出了一个零样本管道，使得可以捕捉用户身份的人物形象以令人愉悦的方式进行图像生成的个性化处理，并在大规模图像数据集上提高了性能，扩展适用于数百万用户。

    

    近期的大型文本到图像生成模型在合成图像的质量、真实性和多样性方面取得了显著进展，并且使用户通过语言来控制生成的内容。然而，这些生成模型的个性化方面仍然具有挑战性并且未经深入探索。在本研究中，我们提出了一种能够以令人愉悦的方式捕捉用户身份的人物形象，从而实现图像生成的个性化管道。我们的管道是零样本、人物形象纹理和风格不可知，并且不需要对人物形象进行训练 - 它可以扩展到数百万用户，这些用户可以用他们的人物形象生成场景。为了以忠实于给定的文本提示的姿势呈现人物形象，我们提出了一种新颖的文本到3D姿势扩散模型，该模型在一个策划的大规模野外人类姿势数据集上进行训练，显著提高了SOTA文本到动作模型的性能。我们首次展示了利用大规模图像数据集来提高人物形象生成的个性化效果。

    Recent large-scale text-to-image generation models have made significant improvements in the quality, realism, and diversity of the synthesized images and enable users to control the created content through language. However, the personalization aspect of these generative models is still challenging and under-explored. In this work, we propose a pipeline that enables personalization of image generation with avatars capturing a user's identity in a delightful way. Our pipeline is zero-shot, avatar texture and style agnostic, and does not require training on the avatar at all - it is scalable to millions of users who can generate a scene with their avatar. To render the avatar in a pose faithful to the given text prompt, we propose a novel text-to-3D pose diffusion model trained on a curated large-scale dataset of in-the-wild human poses improving the performance of the SOTA text-to-motion models significantly. We show, for the first time, how to leverage large-scale image datasets to le
    
[^26]: 未观测到代理奖励的重复负责人代理博弈问题研究

    Repeated Principal-Agent Games with Unobserved Agent Rewards and Perfect-Knowledge Agents. (arXiv:2304.07407v1 [cs.LG])

    [http://arxiv.org/abs/2304.07407](http://arxiv.org/abs/2304.07407)

    本文提出了一个利用多臂老虎机框架结构来处理未知代理奖励的策略，并证明了其性能是渐进最优的。

    

    本文研究了一个多臂老虎机框架中的重复负责人代理博弈场景，其中代理选择一种老虎机后会获得奖励和激励，但负责人只能观察到代理选择了哪个老虎机以及代理相应的激励，而想要设计一种合适的策略却充满了挑战性。本文提出了一种利用多臂老虎机框架结构来处理未知代理奖励的策略，并证明了其性能是渐进最优的。

    Motivated by a number of real-world applications from domains like healthcare and sustainable transportation, in this paper we study a scenario of repeated principal-agent games within a multi-armed bandit (MAB) framework, where: the principal gives a different incentive for each bandit arm, the agent picks a bandit arm to maximize its own expected reward plus incentive, and the principal observes which arm is chosen and receives a reward (different than that of the agent) for the chosen arm. Designing policies for the principal is challenging because the principal cannot directly observe the reward that the agent receives for their chosen actions, and so the principal cannot directly learn the expected reward using existing estimation techniques. As a result, the problem of designing policies for this scenario, as well as similar ones, remains mostly unexplored. In this paper, we construct a policy that achieves a low regret (i.e., square-root regret up to a log factor) in this scenar
    
[^27]: 改善临床试验的患者预筛选：利用大型语言模型辅助医生

    Improving Patient Pre-screening for Clinical Trials: Assisting Physicians with Large Language Models. (arXiv:2304.07396v1 [cs.LG])

    [http://arxiv.org/abs/2304.07396](http://arxiv.org/abs/2304.07396)

    本文研究了使用大型语言模型InstructGPT辅助医生预筛选患者是否符合临床试验资格。通过10个合成患者简况的性能评估，展示了LLMs在识别筛选资格标准、单独分类、整体分类、以及需要筛选资格标准的百分比上的表现。

    

    考虑到患者的临床试验，医生需要进行繁琐的检查，以确定患者是否符合文本基准。大型语言模型（LLMs）已被证明在临床信息提取和临床推理方面表现良好，但尚未在现实场景中得到应用。本文研究了使用InstructGPT辅助医生根据患者的医疗简况确定其是否符合临床试验的资格。使用一次性、选择-推理和思维链策略相结合的提示策略，我们研究了LLMs在10个合成患者简况上的表现。在四个级别上评估了性能：能否从临床试验中给出的医疗简况中识别筛选资格标准；能否为每个单独的标准分类是否符合患者；整体分类是否符合临床试验资格以及需要筛选资格标准的百分比。

    Physicians considering clinical trials for their patients are met with the laborious process of checking many text based eligibility criteria. Large Language Models (LLMs) have shown to perform well for clinical information extraction and clinical reasoning, including medical tests, but not yet in real-world scenarios. This paper investigates the use of InstructGPT to assist physicians in determining eligibility for clinical trials based on a patient's summarised medical profile. Using a prompting strategy combining one-shot, selection-inference and chain-of-thought techniques, we investigate the performance of LLMs on 10 synthetically created patient profiles. Performance is evaluated at four levels: ability to identify screenable eligibility criteria from a trial given a medical profile; ability to classify for each individual criterion whether the patient qualifies; the overall classification whether a patient is eligible for a clinical trial and the percentage of criteria to be scr
    
[^28]: Shape of You：针对多样化身材的精准3D形体估计

    Shape of You: Precise 3D shape estimations for diverse body types. (arXiv:2304.07389v1 [cs.CV])

    [http://arxiv.org/abs/2304.07389](http://arxiv.org/abs/2304.07389)

    本文提出了一种名为SoY的方法，通过两种损失函数和测试时优化例程，可以在不同的人体类型上提高精确的3D形体估计准确度，为时尚行业的实际应用提供了希望。

    

    本文提出了一种名为SoY的方法，旨在改善基于视觉的服装推荐系统中3D身体形状估计的准确性。尽管现有的方法已经成功地估计了3D姿势，但在精确形状估计方面，尤其是对于不同的人体类型，仍存在缺乏的问题。为了解决这个问题，我们提出了两种损失函数，可以轻松地集成到参数化的3D人体重建管道中。此外，我们还提出了一种测试时优化例程，进一步提高了质量。我们的方法在具有挑战性的SSP-3D数据集上比最近的SHAPY方法提高了17.7％。我们认为我们的工作是朝着更准确的3D形态估计系统迈出的一步，该系统可在不同的体型上可靠地工作，并有望在时尚行业中得到实际应用。

    This paper presents Shape of You (SoY), an approach to improve the accuracy of 3D body shape estimation for vision-based clothing recommendation systems. While existing methods have successfully estimated 3D poses, there remains a lack of work in precise shape estimation, particularly for diverse human bodies. To address this gap, we propose two loss functions that can be readily integrated into parametric 3D human reconstruction pipelines. Additionally, we propose a test-time optimization routine that further improves quality. Our method improves over the recent SHAPY method by 17.7% on the challenging SSP-3D dataset. We consider our work to be a step towards a more accurate 3D shape estimation system that works reliably on diverse body types and holds promise for practical applications in the fashion industry.
    
[^29]: 结合对抗性恶意软件示例的生成器以增加规避率。

    Combining Generators of Adversarial Malware Examples to Increase Evasion Rate. (arXiv:2304.07360v1 [cs.CR])

    [http://arxiv.org/abs/2304.07360](http://arxiv.org/abs/2304.07360)

    本文介绍了一种结合不同生成器的技术，以创建更复杂的对抗性示例，从而大幅提高逃避反恶意软件工具的检测的成功率。

    

    杀毒软件开发人员越来越多地拥抱机器学习作为恶意软件防御的关键组成部分。虽然机器学习在许多领域取得了尖端的成果，但它也有弱点，被几种对抗性攻击技术所利用。许多作者提出了能够绕过恶意软件检测器的白盒和黑盒生成器的对抗性恶意软件示例，其成功率有所不同。我们建议将现代生成器结合起来，以增加它们的潜力。结合不同的生成器可以创建更复杂的对抗性示例，这些示例更有可能逃避反恶意软件工具的检测。我们在五个知名的生成器上演示了这种技术，并记录了有希望的结果。AMG-random和MAB-Malware生成器的最佳组合对顶尖杀毒产品的平均规避率为15.9%。这代表了使用仅AMG-random和MAB-Malware生成器的结果平均提高了超过36%和627%。

    Antivirus developers are increasingly embracing machine learning as a key component of malware defense. While machine learning achieves cutting-edge outcomes in many fields, it also has weaknesses that are exploited by several adversarial attack techniques. Many authors have presented both white-box and black-box generators of adversarial malware examples capable of bypassing malware detectors with varying success. We propose to combine contemporary generators in order to increase their potential. Combining different generators can create more sophisticated adversarial examples that are more likely to evade anti-malware tools. We demonstrated this technique on five well-known generators and recorded promising results. The best-performing combination of AMG-random and MAB-Malware generators achieved an average evasion rate of 15.9% against top-tier antivirus products. This represents an average improvement of more than 36% and 627% over using only the AMG-random and MAB-Malware generato
    
[^30]: 学习群体调整：具有多智能体团队的自适应Credo框架。

    Learning to Learn Group Alignment: A Self-Tuning Credo Framework with Multiagent Teams. (arXiv:2304.07337v1 [cs.AI])

    [http://arxiv.org/abs/2304.07337](http://arxiv.org/abs/2304.07337)

    本研究提出了一个自适应Credo框架，通过元学习和层次强化学习来支持智能体对群体对齐参数进行自我调节，从而实现更好的多智能体团队结果。

    

    多个智能体团队中混合激励比完全合作系统具有优势，然而，发现最佳的激励组合或团队结构是一个困难而动态的问题。我们提出了一个框架，其中个体学习智能体通过其奖励函数的不同部分自我调节其激励配置。该模型扩展了以前的工作，让智能体能够在学习过程中动态更新其团队对齐，并允许队友具有不同的团队对齐。我们的模型借鉴了层次强化学习和元学习的思想，以学习支持行为策略发展的奖励函数的配置。我们在一个常见的多智能体环境中提供了初步结果，并发现智能体通过自我调整其各自的组对准参数可以实现更好的全局结果。

    Mixed incentives among a population with multiagent teams has been shown to have advantages over a fully cooperative system; however, discovering the best mixture of incentives or team structure is a difficult and dynamic problem. We propose a framework where individual learning agents self-regulate their configuration of incentives through various parts of their reward function. This work extends previous work by giving agents the ability to dynamically update their group alignment during learning and by allowing teammates to have different group alignment. Our model builds on ideas from hierarchical reinforcement learning and meta-learning to learn the configuration of a reward function that supports the development of a behavioral policy. We provide preliminary results in a commonly studied multiagent environment and find that agents can achieve better global outcomes by self-tuning their respective group alignment parameters.
    
[^31]: OpenAssistant Conversations -- 民主化大型语言模型的对齐方法

    OpenAssistant Conversations -- Democratizing Large Language Model Alignment. (arXiv:2304.07327v1 [cs.CL])

    [http://arxiv.org/abs/2304.07327](http://arxiv.org/abs/2304.07327)

    释放了OpenAssistant Conversations，这是一个由全球超过1,000名参与者进行人工生成和人工注释的助手风格对话语料库，可以通过SFT和RLHF有效地用于LLM对齐，提高模型性能和可用性。

    

    对齐大型语言模型（LLM）与人类偏好的技术已被证明可以显著提高可用性并推动其快速应用，如ChatGPT所示。 监督微调（SFT）和根据人类反馈进行的强化学习（RLHF）等对齐技术大大降低了有效发挥LLM能力所需的技能和领域知识，提高了它们在各个领域的可访问性和实用性。 然而，像RLHF这样的最先进的对齐技术依赖于高质量的人类反馈数据，这些数据往往昂贵且保密。 为了民主化大规模对齐的研究，我们发布了OpenAssistant Conversations，这是一个由全球超过1,000名参与者进行人工生成和人工注释的助手风格对话语料库，包含161,443条消息，分布在66,497个对话树中，并在35种不同的语言中用461,292个质量评分进行注释。我们的实验表明，OpenAssistant Conversations可以通过SFT和RLHF有效地用于LLM对齐，从而提高模型性能和可用性。我们发布语料库，使更广泛的研究社区能够进一步研究民主化LLM的能力，从而改善人类交互。

    Aligning large language models (LLMs) with human preferences has proven to drastically improve usability and has driven rapid adoption as demonstrated by ChatGPT. Alignment techniques such as supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) greatly reduce the required skill and domain knowledge to effectively harness the capabilities of LLMs, increasing their accessibility and utility across various domains. However, state-of-the-art alignment techniques like RLHF rely on high-quality human feedback data, which is expensive to create and often remains proprietary. In an effort to democratize research on large-scale alignment, we release OpenAssistant Conversations, a human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages distributed across 66,497 conversation trees, in 35 different languages, annotated with 461,292 quality ratings. The corpus is a product of a worldwide crowd-sourcing effort involving over 1
    
[^32]: 揭示STEGO进行安全无监督语义分割的内部机制

    Uncovering the Inner Workings of STEGO for Safe Unsupervised Semantic Segmentation. (arXiv:2304.07314v1 [cs.CV])

    [http://arxiv.org/abs/2304.07314](http://arxiv.org/abs/2304.07314)

    这篇论文详细研究了STEGO方法的内部机制和培训策略，揭示了其进行无监督语义分割的工作原理，可用于新领域的应用。

    

    最近，自监督预训练策略在计算机视觉中训练通用特征提取骨干网络方面取得了显著的成果。结合Vision Transformer架构，DINO自蒸馏技术具有有趣的新兴特性，如潜在空间中的无监督聚类和生成特征的语义对应，而不需要使用显式的人工标注标签。无监督语义分割的STEGO方法通过对DINO预训练的Vision Transformer的特征对应进行对比蒸馏，最近创造了一个新的最优性。然而，STEGO的详细工作机制尚未得到分解，阻碍了它在安全关键应用中的使用。本文通过进行研究，揭示了STEGO架构和培训策略的工作机制，重现和扩展其实验证，以及研究STEGO在新领域中的应用能力。

    Self-supervised pre-training strategies have recently shown impressive results for training general-purpose feature extraction backbones in computer vision. In combination with the Vision Transformer architecture, the DINO self-distillation technique has interesting emerging properties, such as unsupervised clustering in the latent space and semantic correspondences of the produced features without using explicit human-annotated labels. The STEGO method for unsupervised semantic segmentation contrastively distills feature correspondences of a DINO-pre-trained Vision Transformer and recently set a new state of the art. However, the detailed workings of STEGO have yet to be disentangled, preventing its usage in safety-critical applications. This paper provides a deeper understanding of the STEGO architecture and training strategy by conducting studies that uncover the working mechanisms behind STEGO, reproduce and extend its experimental validation, and investigate the ability of STEGO t
    
[^33]: 面向电子病历和结构化医疗数据的联邦与分布式学习应用：范围审查

    Federated and distributed learning applications for electronic health records and structured medical data: A scoping review. (arXiv:2304.07310v1 [cs.LG])

    [http://arxiv.org/abs/2304.07310](http://arxiv.org/abs/2304.07310)

    本研究是一份面向电子病历和结构化医疗数据的联邦与分布式学习应用的范围审查，研究发现FL应用于结构化医学数据的研究大多集中在隐私保护方面，未来应该探索FL在降低通信成本和提高模型通用性方面的应用。

    

    在近年来的临床研究中，联邦学习（FL）已经在隐私保护协作方面获得了广泛的关注。随着电子健康记录在临床实践中的广泛应用，结构化数据作为最常见的临床数据形式之一，同时也经历了显着的增长。本研究检查了FL应用于结构化医学数据的应用，确定了当代的限制，并讨论了潜在的创新。我们在SCOPUS、MEDLINE、Web of Science、Embase和CINAHL等五个数据库中进行搜索，以识别将FL应用于结构化医学数据并根据PRISMA准则报告结果的文章。每篇选定的出版物从数据质量、建模策略和FL框架三个主要角度进行评估。经过筛选，34篇文章符合纳入标准，每篇文章包括一个或多个使用FL处理结构化临床/医学数据的研究。其中18个研究应用了FL来训练预测模型，而仅有2个研究调查了使用FL进行联邦迁移学习的应用。大多数研究集中在保护隐私方面，只有少数研究探索了FL的其他优点，如降低通信成本和提高模型通用性。本范围审查最后讨论了FL在结构化医疗数据背景下的挑战、限制和未来方向。

    Federated learning (FL) has gained popularity in clinical research in recent years to facilitate privacy-preserving collaboration. Structured data, one of the most prevalent forms of clinical data, has experienced significant growth in volume concurrently, notably with the widespread adoption of electronic health records in clinical practice. This review examines FL applications on structured medical data, identifies contemporary limitations and discusses potential innovations. We searched five databases, SCOPUS, MEDLINE, Web of Science, Embase, and CINAHL, to identify articles that applied FL to structured medical data and reported results following the PRISMA guidelines. Each selected publication was evaluated from three primary perspectives, including data quality, modeling strategies, and FL frameworks. Out of the 1160 papers screened, 34 met the inclusion criteria, with each article consisting of one or more studies that used FL to handle structured clinical/medical data. Of these
    
[^34]: 有限专家预测下的学习推迟决策

    Learning to Defer with Limited Expert Predictions. (arXiv:2304.07306v1 [cs.LG])

    [http://arxiv.org/abs/2304.07306](http://arxiv.org/abs/2304.07306)

    本论文提出了一个三步方法，用于降低学习推迟算法所需的专家预测数量。该方法通过训练嵌入模型、使用少量的专家预测和利用样本相似性来提高性能。

    

    最近的研究表明，将人工智能模型与人类专家结合使用可以超出单独应用的性能。他们的能力结合通常通过学习推迟算法实现，这使得人工智能学会决定是否为特定样本做出预测或将其推迟给人类专家。然而，为了准确地学习哪些样本应该推迟给人类专家，需要大量准确反映专家能力的专家预测，除了训练人工智能所需的地面真实标签。这是许多学习推迟算法共享的要求，阻碍了它们在责任专家经常更改或获得足够的专家预测的成本较高的场景中的采用。在本文中，我们提出了一个三步方法来减少学习推迟算法所需的专家预测数量。它包括（1）使用地面真实标签训练嵌入模型，

    Recent research suggests that combining AI models with a human expert can exceed the performance of either alone. The combination of their capabilities is often realized by learning to defer algorithms that enable the AI to learn to decide whether to make a prediction for a particular instance or defer it to the human expert. However, to accurately learn which instances should be deferred to the human expert, a large number of expert predictions that accurately reflect the expert's capabilities are required -- in addition to the ground truth labels needed to train the AI. This requirement shared by many learning to defer algorithms hinders their adoption in scenarios where the responsible expert regularly changes or where acquiring a sufficient number of expert predictions is costly. In this paper, we propose a three-step approach to reduce the number of expert predictions required to train learning to defer algorithms. It encompasses (1) the training of an embedding model with ground 
    
[^35]: 智慧地铁：深度学习在预测菲律宾马尼拉地铁三号线乘客量上的应用

    Smart Metro: Deep Learning Approaches to Forecasting the MRT Line 3 Ridership. (arXiv:2304.07303v1 [cs.LG])

    [http://arxiv.org/abs/2304.07303](http://arxiv.org/abs/2304.07303)

    本研究使用时间序列模型预测菲律宾马尼拉地铁三号线每天乘客量的变化，帮助人们更好地规划出行。

    

    自1999年建立以来，菲律宾马尼拉地铁三号线（MRT3）为众多乘客提供了交通选择。菲律宾政府交通部记录每天有超过一千人使用MRT3，预测每天的乘客数量可能相当具有挑战性，受假期、工作日和其他意外问题等变量影响，MRT3的日常乘客量波动较大。乘客无法知道某一天他们所乘路线上有多少其他乘客，这可能会妨碍他们规划高效行程的能力。目前，菲律宾交通运输部依赖包含历史数据的电子表格，这可能难以检查。本研究提出了一种时间序列预测模型，可以预测特定日期某个车站的未来出勤人数。

    Since its establishment in 1999, the Metro Rail Transit Line 3 (MRT3) has served as a transportation option for numerous passengers in Metro Manila, Philippines. The Philippine government's transportation department records more than a thousand people using the MRT3 daily and forecasting the daily passenger count may be rather challenging. The MRT3's daily ridership fluctuates owing to variables such as holidays, working days, and other unexpected issues. Commuters do not know how many other commuters are on their route on a given day, which may hinder their ability to plan an efficient itinerary. Currently, the DOTr depends on spreadsheets containing historical data, which might be challenging to examine. This study presents a time series prediction of daily traffic to anticipate future attendance at a particular station on specific days.
    
[^36]: 用于乳腺癌风险分析和生存预测的监督学习机器学习

    Supervised Machine Learning for Breast Cancer Risk Factors Analysis and Survival Prediction. (arXiv:2304.07299v1 [cs.LG])

    [http://arxiv.org/abs/2304.07299](http://arxiv.org/abs/2304.07299)

    本研究利用机器学习方法预测了乳腺癌患者的5年生存率，并比较了七种分类模型的表现，结果表明这些模型能够准确地预测测试样本的生存率，机器学习模型可以成为乳腺癌生存预测和风险因素分析的有价值工具。

    

    选择最有效的治疗方案可能会受到乳腺癌生存预测的影响。为了预测患者存活的机会，采用了多种技术，如统计学、机器学习和深度学习模型等。本研究利用METABRIC数据集中的1904条患者记录，采用机器学习方法预测5年乳腺癌生存。在本研究中，我们比较了七种分类模型的结果，评估它们的表现如下：召回率、AUC、混淆矩阵、准确度、精确度、假正率和真正率。结果表明，Logistic回归(LR)、支持向量机(SVM)、决策树(DT)、随机森林(RD)、极端随机化树(ET)、K-近邻(KNN)和自适应增强(AdaBoost)的分类器可以准确地预测测试样本的生存率，分别是75.4％、74.7％、71.5％、75.5％、70.3％、72.5％和72.2％。这些结果表明，机器学习模型可以成为乳腺癌生存预测和风险因素分析的有价值工具。

    The choice of the most effective treatment may eventually be influenced by breast cancer survival prediction. To predict the chances of a patient surviving, a variety of techniques were employed, such as statistical, machine learning, and deep learning models. In the current study, 1904 patient records from the METABRIC dataset were utilized to predict a 5-year breast cancer survival using a machine learning approach. In this study, we compare the outcomes of seven classification models to evaluate how well they perform using the following metrics: recall, AUC, confusion matrix, accuracy, precision, false positive rate, and true positive rate. The findings demonstrate that the classifiers for Logistic Regression (LR), Support Vector Machines (SVM), Decision Tree (DT), Random Forest (RD), Extremely Randomized Trees (ET), K-Nearest Neighbor (KNN), and Adaptive Boosting (AdaBoost) can accurately predict the survival rate of the tested samples, which is 75,4\%, 74,7\%, 71,5\%, 75,5\%, 70,3
    
[^37]: 道路网络表示学习：一种基于双重图的方法

    Road Network Representation Learning: A Dual Graph based Approach. (arXiv:2304.07298v1 [cs.LG])

    [http://arxiv.org/abs/2304.07298](http://arxiv.org/abs/2304.07298)

    提出了一种基于双重图的方法来解决传统道路网络表示学习模型无法捕捉道路之间高阶和远程关系的问题。

    

    道路网络是支撑许多实际应用，包括交通、移动性和物流的关键基础设施。为了利用道路网络在这些不同的应用中的输入，有必要学习道路的向量表示形式，称为道路网络表示学习（RNRL）。虽然已经提出了几种 RNRL 模型，但它们只捕捉道路之间的成对关系 / 连接（即作为简单图），无法捕捉道路之间的高阶关系（例如，那些共同形成本地区域的道路通常具有类似的特征，例如速度限制）和远程关系（例如，一些相距较远的道路可能具有类似的语义，例如是住宅区道路）。出于这个原因，我们提出构建一个“超图”，其中每个超边对应于构成区域的多条道路的集合。构建的超图会自然地捕捉到道路之间的高阶关系和远程关系。

    Road network is a critical infrastructure powering many applications including transportation, mobility and logistics in real life. To leverage the input of a road network across these different applications, it is necessary to learn the representations of the roads in the form of vectors, which is named \emph{road network representation learning} (RNRL). While several models have been proposed for RNRL, they capture the pairwise relationships/connections among roads only (i.e., as a simple graph), and fail to capture among roads the high-order relationships (e.g., those roads that jointly form a local region usually have similar features such as speed limit) and long-range relationships (e.g., some roads that are far apart may have similar semantics such as being roads in residential areas). Motivated by this, we propose to construct a \emph{hypergraph}, where each hyperedge corresponds to a set of multiple roads forming a region. The constructed hypergraph would naturally capture the
    
[^38]: 语言指导下的强化学习以实现人工智能协作

    Language Instructed Reinforcement Learning for Human-AI Coordination. (arXiv:2304.07297v1 [cs.AI])

    [http://arxiv.org/abs/2304.07297](http://arxiv.org/abs/2304.07297)

    本文提出了一种称之为instructRL的新的框架，它通过自然语言指令来指定对人工智能搭档的预期策略，解决在缺乏高质量人类行为数据的领域中多智能体强化学习收敛于人类不偏爱的策略的问题，从而提高了人工智能协作的性能。

    

    人工智能的一个基本问题是如何让智能体能够和人类有效地协作。本文提出了一种称之为instructRL的新的框架，让人们可以通过自然语言指令来指定对人工智能搭档的预期策略，以此解决在缺乏较高质量的人类行为数据的领域中，由于多智能体强化学习常常会收敛到人类并不偏爱的策略的不足。我们使用预先训练的大型语言模型来生成一个在人类指令下的先验策略，并将其用于约束强化学习目标。这导致强化学习智能体收敛到与人类喜好一致的均衡点。通过概念证明环境和具有挑战性的Hanabi基准，证明了instructRL收敛于满足给定指令的类似人类智能体的策略。最后，我们证明了知道语言指令显著提高了人工智能协作的性能。

    One of the fundamental quests of AI is to produce agents that coordinate well with humans. This problem is challenging, especially in domains that lack high quality human behavioral data, because multi-agent reinforcement learning (RL) often converges to different equilibria from the ones that humans prefer. We propose a novel framework, instructRL, that enables humans to specify what kind of strategies they expect from their AI partners through natural language instructions. We use pretrained large language models to generate a prior policy conditioned on the human instruction and use the prior to regularize the RL objective. This leads to the RL agent converging to equilibria that are aligned with human preferences. We show that instructRL converges to human-like policies that satisfy the given instructions in a proof-of-concept environment as well as the challenging Hanabi benchmark. Finally, we show that knowing the language instruction significantly boosts human-AI coordination pe
    
[^39]: 基于专家认知驱动的安全噪声标签学习用于乳腺癌残余肿瘤的精确分割

    Experts' cognition-driven safe noisy labels learning for precise segmentation of residual tumor in breast cancer. (arXiv:2304.07295v1 [q-bio.QM])

    [http://arxiv.org/abs/2304.07295](http://arxiv.org/abs/2304.07295)

    本文提出了一种基于专家认知驱动的安全噪声标签学习方法，用于乳腺癌残余肿瘤的精确分割，该方法将病理专家的认知和人工智能专家的数据建模认知相结合，以缓解乳腺癌组织和肿瘤细胞形态学改变的挑战。

    

    新辅助化疗后准确分割乳腺癌残余肿瘤 (PSRTBC) 是乳腺癌治疗过程中的一个基本关键技术。然而，由于乳腺癌组织和肿瘤细胞在新辅助化疗后常常具有复杂和多种多样的形态学改变，因此产生一个具有良好泛化性能的预测模型仍然是一个挑战。为了缓解这种情况，本文提出了一种基于专家认知驱动的安全噪声标签学习 (ECDSNLL) 方法。ECDSNLL是在安全噪声标签学习的概念下构建的，后者是一种典型的安全弱监督学习方法，它将病理专家对乳腺癌残余肿瘤识别的认知与提供的数据基础上的人工智能专家的数据建模认知相结合。我们展示了所提出的ECDSNLL方法的优势和潜力。

    Precise segmentation of residual tumor in breast cancer (PSRTBC) after neoadjuvant chemotherapy is a fundamental key technique in the treatment process of breast cancer. However, achieving PSRTBC is still a challenge, since the breast cancer tissue and tumor cells commonly have complex and varied morphological changes after neoadjuvant chemotherapy, which inevitably increases the difficulty to produce a predictive model that has good generalization with machine learning. To alleviate this situation, in this paper, we propose an experts' cognition-driven safe noisy labels learning (ECDSNLL) approach. In the concept of safe noisy labels learning, which is a typical type of safe weakly supervised learning, ECDSNLL is constructed by integrating the pathology experts' cognition about identifying residual tumor in breast cancer and the artificial intelligence experts' cognition about data modeling with provided data basis. We show the advantages of the proposed ECDSNLL approach and its promi
    
[^40]: 基于机器感知的图像压缩：一种分层生成方法

    Machine Perception-Driven Image Compression: A Layered Generative Approach. (arXiv:2304.06896v1 [eess.IV] CROSS LISTED)

    [http://arxiv.org/abs/2304.06896](http://arxiv.org/abs/2304.06896)

    本文提出了一种分层生成图像压缩模型，能够在极端压缩比下实现高质量的视觉重建，同时支持各种基于压缩域的分析任务。

    

    在这个信息时代，图像是存储和传输信息的重要媒介。随着图像数据量的快速增长，视觉压缩和视觉数据感知成为了两个重要的研究课题。然而，这两个课题很少被一起讨论，遵循着不同的研究路径。本文提出了一种分层生成图像压缩模型，即使在极端压缩比下，也能实现高质量的视觉重建。为了获得分析效率和灵活性，提出了一种任务不可知的学习型压缩模型，有效地支持各种基于压缩域的分析任务，同时保留了出色的视觉重建感知质量。

    In this age of information, images are a critical medium for storing and transmitting information. With the rapid growth of image data amount, visual compression and visual data perception are two important research topics attracting a lot attention. However, those two topics are rarely discussed together and follow separate research path. Due to the compact compressed domain representation offered by learning-based image compression methods, there exists possibility to have one stream targeting both efficient data storage and compression, and machine perception tasks. In this paper, we propose a layered generative image compression model achieving high human vision-oriented image reconstructed quality, even at extreme compression ratios. To obtain analysis efficiency and flexibility, a task-agnostic learning-based compression model is proposed, which effectively supports various compressed domain-based analytical tasks while reserves outstanding reconstructed perceptual quality, compa
    
[^41]: SpectFormer: 频率和注意力是视觉Transformer所需要的。

    SpectFormer: Frequency and Attention is what you need in a Vision Transformer. (arXiv:2304.06446v1 [cs.CV])

    [http://arxiv.org/abs/2304.06446](http://arxiv.org/abs/2304.06446)

    本文提出了结合多头注意力和谱层的Spectformer架构，可以得到更好的性能表现，提高了top-1准确率2%。

    

    视觉Transformer已成功地应用于图像识别任务中。其种类包括基于多头自我注意力机制（如ViT、DeIT）和基于谱层（如Fnet、GFNet、AFNO）的模型。本文发现，多头注意力和谱层都对Transformer起到重要作用，将两者结合可以得到更好的性能表现。因此提出了新的Spectformer架构，将多头注意力和谱层融合起来。实验表明，Spectformer可恰当地捕捉特征表示，与其他Transformer表征相比，可以提高top-1准确率2%。

    Vision transformers have been applied successfully for image recognition tasks. There have been either multi-headed self-attention based (ViT \cite{dosovitskiy2020image}, DeIT, \cite{touvron2021training}) similar to the original work in textual models or more recently based on spectral layers (Fnet\cite{lee2021fnet}, GFNet\cite{rao2021global}, AFNO\cite{guibas2021efficient}). We hypothesize that both spectral and multi-headed attention plays a major role. We investigate this hypothesis through this work and observe that indeed combining spectral and multi-headed attention layers provides a better transformer architecture. We thus propose the novel Spectformer architecture for transformers that combines spectral and multi-headed attention layers. We believe that the resulting representation allows the transformer to capture the feature representation appropriately and it yields improved performance over other transformer representations. For instance, it improves the top-1 accuracy by 2
    
[^42]: 基于逻辑锁定的神经特洛伊攻击机器学习加速器

    Exploiting Logic Locking for a Neural Trojan Attack on Machine Learning Accelerators. (arXiv:2304.06017v1 [cs.CR])

    [http://arxiv.org/abs/2304.06017](http://arxiv.org/abs/2304.06017)

    本文研究了如何利用逻辑锁定来破坏神经加速器的安全性，并展示了如何利用特洛伊秘钥来产生神经特洛伊式的后门。在基准数据集上进行的实验表明，我们的方法可以生成诱导大量错误分类率的特洛伊秘钥，同时保持高的特洛伊激活概率。

    

    逻辑锁定被提出来保护芯片制造过程中的知识产权。逻辑锁定技术通过使设计中的一部分组合模块依赖于保密的秘钥来保护硬件IP。如果使用了不正确的秘钥，锁定模块会产生一组确定性错误，限制未经授权的使用。神经加速器是逻辑锁定的常见目标，特别是随着机器学习服务的普及。在这篇论文中，我们探讨了如何利用逻辑锁定来破坏它所保护的神经加速器的安全性。具体而言，我们展示了如何利用使用不正确秘钥所引起的确定性错误来产生神经特洛伊式的后门。为此，我们首先概述了一个动机攻击场景，其中精心选择的不正确秘钥，我们称之为特洛伊秘钥，在锁定的加速器中为攻击者指定的输入类别产生了错误分类。然后，我们开发了一种系统方法来为受逻辑锁定保护的神经加速器设计特洛伊秘钥。通过对基准数据集进行大量实验，我们证明了我们的方法可以生成诱导大量错误分类率的特洛伊秘钥，同时保持高的特洛伊激活概率。

    Logic locking has been proposed to safeguard intellectual property (IP) during chip fabrication. Logic locking techniques protect hardware IP by making a subset of combinational modules in a design dependent on a secret key that is withheld from untrusted parties. If an incorrect secret key is used, a set of deterministic errors is produced in locked modules, restricting unauthorized use. A common target for logic locking is neural accelerators, especially as machine-learning-as-a-service becomes more prevalent. In this work, we explore how logic locking can be used to compromise the security of a neural accelerator it protects. Specifically, we show how the deterministic errors caused by incorrect keys can be harnessed to produce neural-trojan-style backdoors. To do so, we first outline a motivational attack scenario where a carefully chosen incorrect key, which we call a trojan key, produces misclassifications for an attacker-specified input class in a locked accelerator. We then dev
    
[^43]: NeuroBench：通过合作、公平和代表性基准测试推进神经形态计算

    NeuroBench: Advancing Neuromorphic Computing through Collaborative, Fair and Representative Benchmarking. (arXiv:2304.04640v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2304.04640](http://arxiv.org/abs/2304.04640)

    NeuroBench是由学术界和工业界成员共同开发的一套协作、公平和代表性的基准测试，可以解决神经形态计算中缺乏清晰标准的问题，推动该领域的发展。

    

    神经形态计算领域在遵循仿生学原理的基础上，具有推进计算效率和能力的巨大潜力。然而，神经形态研究中采用的技术多样性导致缺乏清晰的基准测试标准，阻碍了对神经形态方法与传统基于深度学习的方法的优劣势进行有效评估。本文提出了一个协作项目——NeuroBench，将学术界和工业界成员聚集起来为神经形态计算定义基准测试。NeuroBench的目标是成为社区开发的协作、公平和代表性的基准测试套件。本文讨论了基准测试神经形态解决方案面临的挑战，并概述了NeuroBench的关键特性。我们相信，NeuroBench将是定义能够统一神经形态计算目标的标准的重要一步。

    The field of neuromorphic computing holds great promise in terms of advancing computing efficiency and capabilities by following brain-inspired principles. However, the rich diversity of techniques employed in neuromorphic research has resulted in a lack of clear standards for benchmarking, hindering effective evaluation of the advantages and strengths of neuromorphic methods compared to traditional deep-learning-based methods. This paper presents a collaborative effort, bringing together members from academia and the industry, to define benchmarks for neuromorphic computing: NeuroBench. The goals of NeuroBench are to be a collaborative, fair, and representative benchmark suite developed by the community, for the community. In this paper, we discuss the challenges associated with benchmarking neuromorphic solutions, and outline the key features of NeuroBench. We believe that NeuroBench will be a significant step towards defining standards that can unify the goals of neuromorphic comput
    
[^44]: 应用机器学习和领域知识个性化数字健康行为变革干预

    Personalizing Digital Health Behavior Change Interventions using Machine Learning and Domain Knowledge. (arXiv:2304.03392v1 [cs.LG])

    [http://arxiv.org/abs/2304.03392](http://arxiv.org/abs/2304.03392)

    该论文提出了一种采用机器学习和领域知识进行个性化数字健康行为变革干预的系统，其利用反事实例子进行特征控制以预测干预效果并优化干预效果。

    

    我们正在开发一种虚拟教练系统，帮助患者坚持行为变革干预（BCI）。我们的系统预测患者是否会执行目标行为，并使用反事实例子进行特征控制，以指导个性化BCI。我们使用具有不同响应水平的模拟患者数据评估了我们的预测模型。

    We are developing a virtual coaching system that helps patients adhere to behavior change interventions (BCI). Our proposed system predicts whether a patient will perform the targeted behavior and uses counterfactual examples with feature control to guide personalizsation of BCI. We evaluated our prediction model using simulated patient data with varying levels of receptivity to intervention.
    
[^45]: smProbLog:利用ProbLog实现稳定模型语义的概率推理论证

    smProbLog: Stable Model Semantics in ProbLog for Probabilistic Argumentation. (arXiv:2304.00879v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2304.00879](http://arxiv.org/abs/2304.00879)

    本文提出了将概率论证框架解释为概率逻辑程序的方法，并提出了一种新的PLP语义，用于处理不同概率事实之间的不确定性。该论文在推理论证领域内有一定的应用意义。

    

    论证问题关注于从它们的关系结构中确定一组参数的可接受性问题。当可用信息不确定时，概率论证框架提供了建模工具来解决这个问题。本文的首次贡献是将概率论证框架解释为概率逻辑程序。概率逻辑程序是逻辑程序，其中一些事实带有概率注释。我们展示了表示概率论证框架的程序不能满足概率逻辑编程(PLP)语义中的一项普遍假设，即概率事实完全捕捉到研究领域的不确定性。本文的第二个贡献是提出PLP语义的新方法，用于可以使用不同的概率事实来确定逻辑原子的真值分配的程序。本文的第三个贡献是对文献进行翻译。

    Argumentation problems are concerned with determining the acceptability of a set of arguments from their relational structure. When the available information is uncertain, probabilistic argumentation frameworks provide modelling tools to account for it. The first contribution of this paper is a novel interpretation of probabilistic argumentation frameworks as probabilistic logic programs. Probabilistic logic programs are logic programs in which some of the facts are annotated with probabilities. We show that the programs representing probabilistic argumentation frameworks do not satisfy a common assumption in probabilistic logic programming (PLP) semantics, which is, that probabilistic facts fully capture the uncertainty in the domain under investigation. The second contribution of this paper is then a novel PLP semantics for programs where a choice of probabilistic facts does not uniquely determine the truth assignment of the logical atoms. The third contribution of this paper is the 
    
[^46]: 通过拓扑操作管理电力网络：先进基于规则和强化学习的智能体比较研究

    Managing power grids through topology actions: A comparative study between advanced rule-based and reinforcement learning agents. (arXiv:2304.00765v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2304.00765](http://arxiv.org/abs/2304.00765)

    本研究分析了使用强化学习和基于规则方法的电力网络运行智能体并提供了新策略。其中最主要的改进是采用N-1策略，考虑到在某条线路断开时的拓扑操作以保持网络稳定。另外，拓扑反转也有利于提高性能。在挑战测试集上，该方法的性能提高了27%。

    

    由于当前形势的动荡和可再生能源生产的增加，电力网络运行变得越来越复杂。因此，传统方法的主动网格管理已经达到了极限。通过“学习运行电力网络”挑战，我们发现增强学习是一种有效可靠的自动化网格运行方法。本文分析了Binbinchen提交的代理，并提供了改进强化学习和基于规则方法的新策略。主要的改进是N-1策略，即考虑到在某条线路断开时，仍可保持网络稳定的拓扑操作。此外，我们还提出了将拓扑结构恢复到原始状态的拓扑反转，证明其有益。基于我们的改进方法，在挑战测试集上，我们的方法能够使基于规则的智能体性能提高27％。

    The operation of electricity grids has become increasingly complex due to the current upheaval and the increase in renewable energy production. As a consequence, active grid management is reaching its limits with conventional approaches. In the context of the Learning to Run a Power Network challenge, it has been shown that Reinforcement Learning (RL) is an efficient and reliable approach with considerable potential for automatic grid operation. In this article, we analyse the submitted agent from Binbinchen and provide novel strategies to improve the agent, both for the RL and the rule-based approach. The main improvement is a N-1 strategy, where we consider topology actions that keep the grid stable, even if one line is disconnected. More, we also propose a topology reversion to the original grid, which proved to be beneficial. The improvements are tested against reference approaches on the challenge test sets and are able to increase the performance of the rule-based agent by 27%. I
    
[^47]: 大型语言模型综述

    A Survey of Large Language Models. (arXiv:2303.18223v1 [cs.CL])

    [http://arxiv.org/abs/2303.18223](http://arxiv.org/abs/2303.18223)

    本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。

    

    语言本质上是一个由语法规则控制的复杂精细的人类表达系统，对于开发理解和掌握语言的能力的AI算法来说是一项重大挑战。作为主要方法之一，语言建模在过去二十年里广泛研究用于语言理解和生成，从统计语言模型演化为神经语言模型。最近，通过在大规模语料库上预训练Transformer模型，提出了预训练语言模型（PLMs），在解决各种NLP任务方面显示出强大的能力。由于研究人员发现模型缩放可以导致性能改进，他们进一步通过增加模型规模来研究缩放效应，有趣的是，当参数规模超过一定水平时，这些扩大的语言模型不仅可以实现显着的性能提升，而且还显示出一些小规模语言模型所没有的特殊能力。

    Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale langu
    
[^48]: ChatGPT-4中显著概念物理推理的进展

    Advances in apparent conceptual physics reasoning in ChatGPT-4. (arXiv:2303.17012v1 [physics.ed-ph])

    [http://arxiv.org/abs/2303.17012](http://arxiv.org/abs/2303.17012)

    ChatGPT-4是一个基于大规模语言模型训练的对话机器人，能达到接近于物理专家水平的力概念测试成绩，对未来的物理教育和教学有重要意义。

    

    ChatGPT是建立在一个巨大的人类文本信息库上的大型语言模型，以模拟人类对话。最近Kortemeyer（2023）的研究表明，尽管没有任何关于物理定律的明确编程指导，ChatGPT-3.5可以通过一些名义水平的入门物理课程，并在力学的力概念测试中得到接近最小理解的成绩。本研究复制了这些结果，并证明了最新版本ChatGPT-4在该环境下的成绩远高于前版本，在一些非常值得注意的例外和限制条件下，其回答非常接近于完美地展示专家水平的能力。我们简要评述了这对于未来物理教育和教学的含义。

    ChatGPT is built on a large language model trained on an enormous corpus of human text to emulate human conversation. Despite lacking any explicit programming regarding the laws of physics, recent work by Kortemeyer (2023) has demonstrated that ChatGPT-3.5 could pass an introductory physics course at some nominal level and register something close to a minimal understanding of Newtonian Mechanics on the Force Concept Inventory. This work replicates those results and also demonstrates that the latest version, ChatGPT-4, has reached a much higher mark in the latter context. Indeed, its responses come quite close to perfectly demonstrating expert-level competence, with a few very notable exceptions and limitations. We briefly comment on the implications of this for the future of physics education and pedagogy.
    
[^49]: TabRet: 预训练Transformer-based表格模型，支持未知列

    TabRet: Pre-training Transformer-based Tabular Models for Unseen Columns. (arXiv:2303.15747v1 [cs.LG])

    [http://arxiv.org/abs/2303.15747](http://arxiv.org/abs/2303.15747)

    提出了一种可预训练的Transformer-based表格模型：TabRet，能够支持未知列，并在医疗保健分类任务上表现优秀。重新标记化和随机洗牌增强对性能提升有贡献。

    

    我们提出了一种名为TabRet的可预训练Transformer-based表格模型。TabRet旨在为包含未在预训练中见过的列的下游任务提供支持。与其他方法不同，TabRet在微调之前有一个额外的学习步骤，称为重新标记化，它基于遮蔽自动编码损失来校准特征嵌入。在实验中，我们使用大量的公共健康调查数据对TabRet进行预训练，并在医疗保健分类任务上进行微调，在四个数据集上实现了最佳AUC性能。此外，消融研究表明，在预训练期间进行重新标记化和随机洗牌增强对性能提升有贡献。

    We present \emph{TabRet}, a pre-trainable Transformer-based model for tabular data. TabRet is designed to work on a downstream task that contains columns not seen in pre-training. Unlike other methods, TabRet has an extra learning step before fine-tuning called \emph{retokenizing}, which calibrates feature embeddings based on the masked autoencoding loss. In experiments, we pre-trained TabRet with a large collection of public health surveys and fine-tuned it on classification tasks in healthcare, and TabRet achieved the best AUC performance on four datasets. In addition, an ablation study shows retokenizing and random shuffle augmentation of columns during pre-training contributed to performance gains.
    
[^50]: MeMaHand：利用网格-手部互动进行单张图像双手重建

    MeMaHand: Exploiting Mesh-Mano Interaction for Single Image Two-Hand Reconstruction. (arXiv:2303.15718v1 [cs.CV])

    [http://arxiv.org/abs/2303.15718](http://arxiv.org/abs/2303.15718)

    本文提出了一种利用网格-手部互动进行单张图像双手重建的新方法，使用网格顶点位置和MANO参数作为查询令牌，实现了精确的网格重建，并通过实验表明这一方法优于现有最先进方法。

    

    现有的手重建方法通常对一个通用的3D手模型进行参数化或者直接预测手掌网格位置，参数表示的手部形状和旋转姿态更为稳定，而非参数化的方法可以更精确地预测网格位置。本文提出了一种新方法，从单张RGB图像中同时重建两只手的网格并估计MANO参数，以利用两种手表示方法的优点。为了实现这个目标，我们提出了新的网格-手部互动块（MMIBs），它将网格顶点位置和MANO参数作为两种查询令牌。MMIB由一个图形残差块来聚合局部信息和两个变换编码器来建模远程依赖关系。变换编码器配备不同的不对称关注掩码来分别建模手内和手间关注。此外，我们还引入了网格对齐细化模块来进一步提高网格重建的准确性。实验结果表明，我们提出的方法在单手和双手重建任务上优于现有最先进方法。

    Existing methods proposed for hand reconstruction tasks usually parameterize a generic 3D hand model or predict hand mesh positions directly. The parametric representations consisting of hand shapes and rotational poses are more stable, while the non-parametric methods can predict more accurate mesh positions. In this paper, we propose to reconstruct meshes and estimate MANO parameters of two hands from a single RGB image simultaneously to utilize the merits of two kinds of hand representations. To fulfill this target, we propose novel Mesh-Mano interaction blocks (MMIBs), which take mesh vertices positions and MANO parameters as two kinds of query tokens. MMIB consists of one graph residual block to aggregate local information and two transformer encoders to model long-range dependencies. The transformer encoders are equipped with different asymmetric attention masks to model the intra-hand and inter-hand attention, respectively. Moreover, we introduce the mesh alignment refinement mo
    
[^51]: MeshDiffusion：基于分数的生成式3D网格建模

    MeshDiffusion: Score-based Generative 3D Mesh Modeling. (arXiv:2303.08133v1 [cs.GR])

    [http://arxiv.org/abs/2303.08133](http://arxiv.org/abs/2303.08133)

    本文提出了一种基于分数的生成式3D网格建模方法，依赖网格的图形结构和扩散模型，在不需要后处理的前提下，生成高质量、细节丰富的3D网格。

    

    本文研究了生成逼真的3D物体的任务，这对于自动场景生成和物理仿真等多种应用非常有用。相比于体素和点云等其他3D表示，网格在实践中更加优越，因为(1)它们可以轻松任意地操纵形状以供重新照明和仿真，(2)可以充分发挥现代图形流水线的能力，而这些流水线大多数针对网格进行了优化。以往可扩展的3D网格生成方法通常依赖于次优的后处理，并且它们往往会产生过于平滑或嘈杂的表面，缺乏精细的几何细节。为了克服这些缺点，我们利用网格的图形结构，使用简单但非常有效的生成式建模方法生成3D网格。具体来说，我们使用可变形四面体网格来表示网格，然后在这个直接参数化的网格上训练扩散模型。

    We consider the task of generating realistic 3D shapes, which is useful for a variety of applications such as automatic scene generation and physical simulation. Compared to other 3D representations like voxels and point clouds, meshes are more desirable in practice, because (1) they enable easy and arbitrary manipulation of shapes for relighting and simulation, and (2) they can fully leverage the power of modern graphics pipelines which are mostly optimized for meshes. Previous scalable methods for generating meshes typically rely on sub-optimal post-processing, and they tend to produce overly-smooth or noisy surfaces without fine-grained geometric details. To overcome these shortcomings, we take advantage of the graph structure of meshes and use a simple yet very effective generative modeling method to generate 3D meshes. Specifically, we represent meshes with deformable tetrahedral grids, and then train a diffusion model on this direct parametrization. We demonstrate the effectivene
    
[^52]: 基于深度递归网络的公司名称消歧

    Disambiguation of Company names via Deep Recurrent Networks. (arXiv:2303.05391v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.05391](http://arxiv.org/abs/2303.05391)

    本研究提出了一种利用深度递归网络进行公司名称消歧的方法，相较于标准字符串匹配算法具有更优的表现，还采用主动学习来优化样本标记效率。

    

    命名实体消歧是自然语言处理的一个任务，其目标是识别对应于同一命名实体的文本记录。本研究的任务是根据公司的书面名称消除歧义。我们提出了一种连续LSTM网络方法来提取公司名称字符串的嵌入，进而使用这种表示来识别真正表示同一公司（即相同实体）的公司名称对。考虑到手动标记字符串对是一项费力的任务，我们分析了主动学习方法如何优先选择样本进行标记从而使整个学习流程更加高效。经实证，我们的Siamese网络优于多种基于标准字符串匹配算法的基准方法。

    Name Entity Disambiguation is the Natural Language Processing task of identifying textual records corresponding to the same Named Entity, i.e. real-world entities represented as a list of attributes (names, places, organisations, etc.). In this work, we face the task of disambiguating companies on the basis of their written names. We propose a Siamese LSTM Network approach to extract -- via supervised learning -- an embedding of company name strings in a (relatively) low dimensional vector space and use this representation to identify pairs of company names that actually represent the same company (i.e. the same Entity).  Given that the manual labelling of string pairs is a rather onerous task, we analyse how an Active Learning approach to prioritise the samples to be labelled leads to a more efficient overall learning pipeline.  With empirical investigations, we show that our proposed Siamese Network outperforms several benchmark approaches based on standard string matching algorithms
    
[^53]: 有帮助、引导还是让人困惑: 人们如何看待人工智能解释的基本构建块。

    Helpful, Misleading or Confusing: How Humans Perceive Fundamental Building Blocks of Artificial Intelligence Explanations. (arXiv:2303.00934v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2303.00934](http://arxiv.org/abs/2303.00934)

    该论文旨在以人为中心的角度评估人工智能中的解释可理解性，以及评估可解释性的适当方法落后于技术的发展速度。

    

    可解释的人工智能技术正在以惊人的速度发展，但适当的评估方法落后。随着解释器变得越来越复杂，以及缺乏关于如何评估它们效用的共识，评判不同解释的好处和有效性变得具有挑战性。为了填补这一空白，我们退一步研究简单决策模型的可解释性，而不是复杂的预测算法。在这种环境下，我们旨在评估人们如何理解它们的不同表示形式，例如数学公式、图形表示和文本摘要（不同复杂度和范围）。这使我们能够捕捉到各种利益相关者（工程师、研究者、消费者、监管机构等）如何评判更复杂的人工智能解释所构建的基本概念的可理解性。本文介绍我们从以人为中心的角度建立适当的可解释性评估方法的方法。

    Explainable artificial intelligence techniques are developed at breakneck speed, but suitable evaluation approaches lag behind. With explainers becoming increasingly complex and a lack of consensus on how to assess their utility, it is challenging to judge the benefit and effectiveness of different explanations. To address this gap, we take a step back from sophisticated predictive algorithms and instead look into explainability of simple decision-making models. In this setting, we aim to assess how people perceive comprehensibility of their different representations such as mathematical formulation, graphical representation and textual summarisation (of varying complexity and scope). This allows us to capture how diverse stakeholders -engineers, researchers, consumers, regulators and the like -- judge intelligibility of fundamental concepts that more elaborate artificial intelligence explanations are built from. This position paper charts our approach to establishing appropriate eva
    
[^54]: AR3n: 一种基于强化学习的机器人康复辅助控制器

    AR3n: A Reinforcement Learning-based Assist-As-Needed Controller for Robotic Rehabilitation. (arXiv:2303.00085v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.00085](http://arxiv.org/abs/2303.00085)

    本文提出了一种基于强化学习的机器人康复辅助控制器AR3n，通过使用虚拟患者模型实现控制器的泛化，实时调节机器人辅助力度并最小化机器人辅助的量，该控制器在实验验证中表现出良好的效果。

    

    本文提出了AR3n（发音为Aaron），一种采用强化学习的辅助控制器，可在机器人辅助的书写康复任务中提供适应性辅助。与以往的辅助控制器不同，我们的方法不依赖于患者特定的控制器参数或物理模型。我们建议使用虚拟患者模型来使AR3n推广到多个受试者。该系统实时调节机器人辅助力度，同时最小化机器人辅助的量，基于被试的跟踪误差。通过一组仿真实验和人体受试实验对控制器进行实验验证。最后，进行了与传统基于规则的控制器的比较研究，以分析两种控制器的辅助机制的差异。

    In this paper, we present AR3n (pronounced as Aaron), an assist-as-needed (AAN) controller that utilizes reinforcement learning to supply adaptive assistance during a robot assisted handwriting rehabilitation task. Unlike previous AAN controllers, our method does not rely on patient specific controller parameters or physical models. We propose the use of a virtual patient model to generalize AR3n across multiple subjects. The system modulates robotic assistance in realtime based on a subject's tracking error, while minimizing the amount of robotic assistance. The controller is experimentally validated through a set of simulations and human subject experiments. Finally, a comparative study with a traditional rule-based controller is conducted to analyze differences in assistance mechanisms of the two controllers.
    
[^55]: 语义不确定性：自然语言生成不确定性估计中的语言不变量

    Semantic Uncertainty: Linguistic Invariances for Uncertainty Estimation in Natural Language Generation. (arXiv:2302.09664v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.09664](http://arxiv.org/abs/2302.09664)

    本文提出了一种测量大型语言模型中不确定性的方法，引入了语义熵以克服自然语言中的“语义等价性”，该方法是无监督的，并且对于问题回答数据集上的模型准确性具有更好的预测性能。

    

    我们介绍了一种测量大型语言模型中不确定性的方法。对于像问答任务这样的任务，了解何时可以信任基础模型的自然语言输出至关重要。我们发现，由于“语义等价性”，测量自然语言的不确定性是有挑战性的——不同的句子可以表示相同的意思。为了克服这些挑战，我们引入了语义熵——一种包含共享含义所创建的语言不变量的熵。我们的方法是无监督的，仅使用单个模型，并且不需要修改现成的语言模型。在全面的消融研究中，我们展示了语义熵对于问题回答数据集上的模型准确性比可比基线更具有预测性。

    We introduce a method to measure uncertainty in large language models. For tasks like question answering, it is essential to know when we can trust the natural language outputs of foundation models. We show that measuring uncertainty in natural language is challenging because of "semantic equivalence" -- different sentences can mean the same thing. To overcome these challenges we introduce semantic entropy -- an entropy which incorporates linguistic invariances created by shared meanings. Our method is unsupervised, uses only a single model, and requires no modifications to off-the-shelf language models. In comprehensive ablation studies we show that the semantic entropy is more predictive of model accuracy on question answering data sets than comparable baselines.
    
[^56]: 多模态视觉监督对语言有益吗？

    Is Multimodal Vision Supervision Beneficial to Language?. (arXiv:2302.05016v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.05016](http://arxiv.org/abs/2302.05016)

    本文探讨了使用视觉监督训练的语言表示是否比普通语言表示在自然语言理解和常识推理基准测试方面表现更好。结果表明，大多数任务中，普通的语言表示表现出更好的性能。

    

    视觉（图像和视频）-语言（VL）预训练是最近流行的模式，它在多模态任务如图像检索、视频检索、视觉问题回答等方面取得了最先进的结果。这些模型以无监督的方式进行训练，并且非常受益于补充模态监督。在本文中，我们探讨了使用视觉监督训练的语言表示是否比普通语言表示在自然语言理解和常识推理基准测试方面表现更好。我们将试验不同的图像-文本模型，如ALBEF、BLIP、METER等，以及视频-文本模型，如ALPRO、Frozen-in-Time（FiT）、VIOLET等。我们将这些模型的独立文本编码器的语言表示与通过视觉监督学习的文本编码器的语言表示进行比较。我们的实验表明，大多数任务中，普通的语言表示表现出更好的性能。

    Vision (image and video) - Language (VL) pre-training is the recent popular paradigm that achieved state-of-the-art results on multi-modal tasks like image-retrieval, video-retrieval, visual question answering etc. These models are trained in an unsupervised way and greatly benefit from the complementary modality supervision. In this paper, we explore if the language representations trained using vision supervision perform better than vanilla language representations on Natural Language Understanding and commonsense reasoning benchmarks. We experiment with a diverse set of image-text models such as ALBEF, BLIP, METER and video-text models like ALPRO, Frozen-in-Time (FiT), VIOLET. We compare the performance of language representations of stand-alone text encoders of these models to the language representations of text encoders learnt through vision supervision. Our experiments suggest that vanilla language representations show superior performance on most of the tasks. These results she
    
[^57]: 需要多样性：通过稳定的扩散改善模型无关的零样本分类

    Diversity is Definitely Needed: Improving Model-Agnostic Zero-shot Classification via Stable Diffusion. (arXiv:2302.03298v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.03298](http://arxiv.org/abs/2302.03298)

    本文提出了一种通过增强生成数据集中图像的多样性来提高模型无关的零样本分类性能的方法，比最先进的方法提高了1.4mAP（CUB数据集）和8.4mAP（ImageNet数据集），并且适用于任何下游的分类架构。

    

    本文研究了模型无关的零样本分类（MA-ZSC）问题，这意味着训练分类架构来对真实图像进行分类，而在训练过程中不使用任何真实图像。最近的研究表明，使用扩散模型生成合成训练图像可以提供潜在的解决MA-ZSC问题的方法。然而，该方法的性能目前仍然不如大规模视觉-语言模型所取得的性能。我们提出了一种通过改善生成数据集中图像的多样性来提高MA-ZSC性能的新思路。我们提出了一组修改文本到图像生成过程的方法，使用预训练的扩散模型来增强多样性，我们称之为“绝招”。我们的方法适用于任何下游的分类架构，尽管我们重点关注视觉-语言模型。实验证明，在CUB数据集上，我们的方法比最先进的方法提高了1.4mAP，在ImageNet数据集上提高了8.4mAP，同时需要更少的生成图像进行训练。

    In this work, we investigate the problem of Model-Agnostic Zero-Shot Classification (MA-ZSC), which refers to training non-specific classification architectures (downstream models) to classify real images without using any real images during training. Recent research has demonstrated that generating synthetic training images using diffusion models provides a potential solution to address MA-ZSC. However, the performance of this approach currently falls short of that achieved by large-scale vision-language models. One possible explanation is a potential significant domain gap between synthetic and real images. Our work offers a fresh perspective on the problem by providing initial insights that MA-ZSC performance can be improved by improving the diversity of images in the generated dataset. We propose a set of modifications to the text-to-image generation process using a pre-trained diffusion model to enhance diversity, which we refer to as our $\textbf{bag of tricks}$. Our approach sho
    
[^58]: KNOD：领域知识提取树解码器用于自动程序修复

    KNOD: Domain Knowledge Distilled Tree Decoder for Automated Program Repair. (arXiv:2302.01857v3 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2302.01857](http://arxiv.org/abs/2302.01857)

    KNOD是一种用于自动程序修复的DL-based APR方法。它利用领域知识在补丁生成中指导修复过程，具有一种新颖的三阶段树解码器和领域规则提取方法。

    

    自动程序修复（APR）通过自动生成一个有问题程序的补丁来提高软件可靠性。近期的APR技术利用深度学习（DL）构建模型，从现有的代码库中学习生成补丁。然而，基于DL的APR技术在补丁空间中存在大量语法或语义不正确的补丁，这些补丁违反了源代码的语法和语义领域知识，因此不能成为修复错误的正确补丁。我们提出了一种DL-based APR方法KNOD，它采用直接和全面的方法将领域知识纳入到补丁生成中。KNOD有两个主要创新点，包括（1）一种新颖的三阶段树解码器，根据内在的树结构直接生成修补程序的抽象语法树，以及（2）一种新颖的领域规则提取方法，利用语法和语义规则以及教师-学生分布显式注入领域知识。

    Automated Program Repair (APR) improves software reliability by generating patches for a buggy program automatically. Recent APR techniques leverage deep learning (DL) to build models to learn to generate patches from existing patches and code corpora. While promising, DL-based APR techniques suffer from the abundant syntactically or semantically incorrect patches in the patch space. These patches often disobey the syntactic and semantic domain knowledge of source code and thus cannot be the correct patches to fix a bug.  We propose a DL-based APR approach KNOD, which incorporates domain knowledge to guide patch generation in a direct and comprehensive way. KNOD has two major novelties, including (1) a novel three-stage tree decoder, which directly generates Abstract Syntax Trees of patched code according to the inherent tree structure, and (2) a novel domain-rule distillation, which leverages syntactic and semantic rules and teacher-student distributions to explicitly inject the domai
    
[^59]: 离线到在线强化学习的政策扩展

    Policy Expansion for Bridging Offline-to-Online Reinforcement Learning. (arXiv:2302.00935v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.00935](http://arxiv.org/abs/2302.00935)

    本文提出了一种政策扩展方案，用于离线到在线强化学习，以保留离线学习的策略并在在线学习中进行自适应扩展。

    

    利用离线数据进行预训练，并使用在线强化学习进行微调，是一种学习控制策略的有希望的策略，能够在样本效率和性能方面充分利用两者的优点。一种自然的方法是使用离线训练的策略初始化在线学习的策略。本文提出了一种用于此任务的政策扩展方案。在学习离线策略后，我们将其用作策略集中的一个候选策略。然后，我们通过另一个策略来扩展策略集，该策略将负责进一步的学习。两个策略将以自适应的方式组合起来与环境进行交互。通过这种方法，先前离线学习的策略完全在在线学习过程中得以保留，因此减轻了潜在问题，例如在在线学习的初始阶段破坏离线策略的有用行为，同时允许离线策略在自适应方式下自然参与

    Pre-training with offline data and online fine-tuning using reinforcement learning is a promising strategy for learning control policies by leveraging the best of both worlds in terms of sample efficiency and performance. One natural approach is to initialize the policy for online learning with the one trained offline. In this work, we introduce a policy expansion scheme for this task. After learning the offline policy, we use it as one candidate policy in a policy set. We then expand the policy set with another policy which will be responsible for further learning. The two policies will be composed in an adaptive manner for interacting with the environment. With this approach, the policy previously learned offline is fully retained during online learning, thus mitigating the potential issues such as destroying the useful behaviors of the offline policy in the initial stage of online learning while allowing the offline policy participate in the exploration naturally in an adaptive mann
    
[^60]: GLIGEN：开放式基于文本的图像生成方法

    GLIGEN: Open-Set Grounded Text-to-Image Generation. (arXiv:2301.07093v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.07093](http://arxiv.org/abs/2301.07093)

    GLIGEN是一种开放式基于语言关联性和预训练的文本到图像生成方法，通过门控机制注入连结信息，能够实现零样本的基于关键字和边界框的文本到图像生成，性能优于现有的监督布局到图像的基线。

    

    大规模的文本到图像扩散模型取得了令人惊叹的进展。然而，现状是仅使用文本输入，这可能会限制可控性。在这项工作中，我们提出了GLIGEN，基于语言关联的图像生成方法，这是一种新颖的方法，它建立在现有预训练的文本到图像扩散模型的基础上，并使其能够依赖于语言关联性输入。为了保留预训练模型的广泛概念知识，我们冻结所有权重，并通过门控机制将连结信息注入到新的可训练层中。我们的模型实现了开放式基于关键字和边界框的文本到图像生成，而且连结能力在新的空间配置和概念上具有良好的普适性。GLIGEN在COCO和LVIS的零样本表现优于现有的监督布局到图像的基线。

    Large-scale text-to-image diffusion models have made amazing advances. However, the status quo is to use text input alone, which can impede controllability. In this work, we propose GLIGEN, Grounded-Language-to-Image Generation, a novel approach that builds upon and extends the functionality of existing pre-trained text-to-image diffusion models by enabling them to also be conditioned on grounding inputs. To preserve the vast concept knowledge of the pre-trained model, we freeze all of its weights and inject the grounding information into new trainable layers via a gated mechanism. Our model achieves open-world grounded text2img generation with caption and bounding box condition inputs, and the grounding ability generalizes well to novel spatial configurations and concepts. GLIGEN's zero-shot performance on COCO and LVIS outperforms that of existing supervised layout-to-image baselines by a large margin.
    
[^61]: 游戏中的因果推理

    Reasoning about Causality in Games. (arXiv:2301.02324v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.02324](http://arxiv.org/abs/2301.02324)

    本文提出了一种新的解决方案——结构因果游戏，它将因果理论和博弈理论相结合，能够在统一、原则性的框架下建模游戏中的依赖关系和计算因果效应，是游戏中因果推理领域的一次有益尝试。

    

    因果推理和博弈论推理是人工智能等多学科的基本问题，这篇论文关注它们的交叉点。 在此之前，缺乏一个支持这两种推理的形式框架。我们提供了一种解决方案：结构因果游戏，可以看作将Pearl的因果层次结构扩展到博弈理论领域，或将Koller和Milch的多代理影响图扩展到因果领域。 我们研究了三个关键问题：1）如何以统一、有原则的方式建模游戏中的(因果)依赖性-无论是变量之间，还是策略之间？2）如何在因果游戏中计算因果查询，并需要什么假设？3）因果游戏与现有形式主义的比较？

    Causal reasoning and game-theoretic reasoning are fundamental topics in artificial intelligence, among many other disciplines: this paper is concerned with their intersection. Despite their importance, a formal framework that supports both these forms of reasoning has, until now, been lacking. We offer a solution in the form of (structural) causal games, which can be seen as extending Pearl's causal hierarchy to the game-theoretic domain, or as extending Koller and Milch's multi-agent influence diagrams to the causal domain. We then consider three key questions: i) How can the (causal) dependencies in games - either between variables, or between strategies - be modelled in a uniform, principled manner? ii) How may causal queries be computed in causal games, and what assumptions does this require? iii) How do causal games compare to existing formalisms? To address question i), we introduce mechanised games, which encode dependencies between agents' decision rules and the distributions g
    
[^62]: 使用Vision Transformer的单轮自监督分布式学习

    Single-round Self-supervised Distributed Learning using Vision Transformer. (arXiv:2301.02064v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.02064](http://arxiv.org/abs/2301.02064)

    本文提出了一种自监督蒸馏方法，可以在分布式学习中实现不需要连续通信，并通过利用Vision Transformer特定的加密技术来增强隐私保护。实验结果表明，该方法在两个不同任务上均优于现有的分布式学习策略和微调基线。

    

    尽管深度学习在医学领域取得了一系列的成功，但由于对隐私和数据所有权的担忧，数据稀缺问题更加严重。已经研究过分布式学习方法，包括联合学习，以解决这些问题。然而，由于需要繁琐的通信开销和隐私保护存在的弱点，这些方法受到了阻碍。为了解决这些挑战，我们提出了一种利用Vision Transformer特定加密技术，采用自监督遮蔽采样蒸馏方法的方法。这种方法可以在不连续通信的情况下实现，并可以通过利用Vision Transformer特定的加密技术来增强隐私保护。我们在两个不同的任务上进行了大量实验，证明了我们方法的有效性。与现有的分布式学习策略以及仅基于微调的基线相比，我们达到了更为优秀的性能。此外，由于我们提出的方法创建的自监督模型可以实现一般化。

    Despite the recent success of deep learning in the field of medicine, the issue of data scarcity is exacerbated by concerns about privacy and data ownership. Distributed learning approaches, including federated learning, have been investigated to address these issues. However, they are hindered by the need for cumbersome communication overheads and weaknesses in privacy protection. To tackle these challenges, we propose a self-supervised masked sampling distillation method for the vision transformer. This method can be implemented without continuous communication and can enhance privacy by utilizing a vision transformer-specific encryption technique. We conducted extensive experiments on two different tasks, which demonstrated the effectiveness of our method. We achieved superior performance compared to the existing distributed learning strategy as well as the fine-tuning only baseline. Furthermore, since the self-supervised model created using our proposed method can achieve a general
    
[^63]: 通过视频预训练潜空间搜索的行为克隆

    Behavioral Cloning via Search in Video PreTraining Latent Space. (arXiv:2212.13326v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.13326](http://arxiv.org/abs/2212.13326)

    本文通过基于模仿学习方法中的搜索问题，将控制问题表述为专家演示数据集中的模仿。该方法通过在视频预训练模型的潜表示中进行近邻搜索，可以有效地在Minecraft环境中复制出有意义的演示轨迹并呈现类人行为。

    

    本文旨在建立能够解决像Minecraft这样环境中任务的自主智能体。为此，我们使用了基于模仿学习的方法。我们将控制问题表述为基于专家演示数据集的搜索问题，其中代理从类似于图像-动作对的演示轨迹中复制动作。我们在视频预训练模型的潜表示中对BASALT MineRL数据集进行了近邻搜索。只要代理和数据集中选定的专家轨迹的状态表示之间的距离不会分散，代理就会复制专家轨迹中的动作。然后重新进行近邻搜索。我们的方法可以有效地恢复有意义的演示轨迹，并在Minecraft环境中展示出类似于人类的行为。

    Our aim is to build autonomous agents that can solve tasks in environments like Minecraft. To do so, we used an imitation learning-based approach. We formulate our control problem as a search problem over a dataset of experts' demonstrations, where the agent copies actions from a similar demonstration trajectory of image-action pairs. We perform a proximity search over the BASALT MineRL-dataset in the latent representation of a Video PreTraining model. The agent copies the actions from the expert trajectory as long as the distance between the state representations of the agent and the selected expert trajectory from the dataset do not diverge. Then the proximity search is repeated. Our approach can effectively recover meaningful demonstration trajectories and show human-like behavior of an agent in the Minecraft environment.
    
[^64]: 面向去中心化人脸识别部署的有效聚合面部嵌入（扩展版）

    Efficient aggregation of face embeddings for decentralized face recognition deployments (extended version). (arXiv:2212.10108v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2212.10108](http://arxiv.org/abs/2212.10108)

    本文提出了一种在去中心化人脸识别部署中有效聚合面部嵌入的方式，旨在减少网络和硬件需求以鼓励设备多样性。

    

    生物识别是最敏感的数据之一。以隐私为重点的 ubiquitous 认证系统倾向于使用去中心化方法，因为它们减少了潜在的攻击向量，在技术和组织层面上都是如此。最理想的情况是让用户控制其数据存储的位置，这将导致使用多种设备。此外，与集中式系统相比，设计更注重用户自由的系统通常会增加额外的网络开销。因此，在使用人脸识别进行生物识别验证时，一种有效比较面部的方法在实际部署中是至关重要的，因为它可以减少网络和硬件需求，从而鼓励设备的多样性。本文提出了一种有效的方式来聚合用于人脸识别的嵌入，该方式基于对不同数据集和使用不同聚合策略的广泛分析。作为分析的一部分，还收集了一个新的数据集。

    Biometrics are one of the most privacy-sensitive data. Ubiquitous authentication systems with a focus on privacy favor decentralized approaches as they reduce potential attack vectors, both on a technical and organizational level. The gold standard is to let the user be in control of where their own data is stored, which consequently leads to a high variety of devices used. Moreover, in comparison with a centralized system, designs with higher end-user freedom often incur additional network overhead. Therefore, when using face recognition for biometric authentication, an efficient way to compare faces is important in practical deployments, because it reduces both network and hardware requirements that are essential to encourage device diversity. This paper proposes an efficient way to aggregate embeddings used for face recognition based on an extensive analysis on different datasets and the use of different aggregation strategies. As part of this analysis, a new dataset has been collec
    
[^65]: 基于语义的沟通：一篇教程兼综述

    Semantics-Empowered Communication: A Tutorial-cum-Survey. (arXiv:2212.08487v3 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2212.08487](http://arxiv.org/abs/2212.08487)

    本文提供了基于语义的沟通方面的教程兼综述，回顾了文献，介绍了SemCom生态系统，并将研究方向进行了分类。此外，还提供了启用技术的分类和未来应用场景的展望。

    

    随着基于语义的沟通（SemCom）研究的兴起，学术界和工业界对其各个方面（如理论、应用、度量和实现）的兴趣不断增长。本文的目的是提供一个综合性的调查，涵盖了背景和研究分类，以及详细的技术教程。具体而言，我们首先回顾文献并回答关于语义传输的“什么”和“为什么”问题。然后，我们展示了SemCom生态系统，包括历史、理论、度量、数据集和工具包，并介绍了研究方向的分类方式。此外，我们提议通过显式和隐式基于推理的方法对关键的启用技术进行分类，并详细阐述它们如何演变并为现代内容和通道语义驱动的通信做出贡献。除了回顾和总结最新的e技术，我们还提供了未来的展望和应用场景。

    Along with the springing up of the semantics-empowered communication (SemCom) research, it is now witnessing an unprecedentedly growing interest towards a wide range of aspects (e.g., theories, applications, metrics and implementations) in both academia and industry. In this work, we primarily aim to provide a comprehensive survey on both the background and research taxonomy, as well as a detailed technical tutorial. Specifically, we start by reviewing the literature and answering the "what" and "why" questions in semantic transmissions. Afterwards, we present the ecosystems of SemCom, including history, theories, metrics, datasets and toolkits, on top of which the taxonomy for research directions is presented. Furthermore, we propose to categorize the critical enabling techniques by explicit and implicit reasoning-based methods, and elaborate on how they evolve and contribute to modern content & channel semantics-empowered communications. Besides reviewing and summarizing the latest e
    
[^66]: 模型增强下的数据集蒸馏加速

    Accelerating Dataset Distillation via Model Augmentation. (arXiv:2212.06152v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.06152](http://arxiv.org/abs/2212.06152)

    本文提出了两种模型增强技术，即使用早期模型和参数扰动，以显着降低训练成本的方式优化数据集蒸馏，实现了高达20倍的加速。

    

    数据集蒸馏（DD）是一个新兴的领域，旨在从大型原始数据集中产生更小但高效的合成训练数据集。现有的基于梯度匹配的DD方法达到了领先的性能；但是，它们非常计算密集，因为他们需要在成千上万个随机初始化模型中不断优化数据集。在本文中，我们假设使用多种模型对合成数据进行训练可以获得更好的泛化性能。因此，我们提出了两种模型增强技术，即使用早期模型和参数扰动来学习具有显着降低训练成本的信息合成集。广泛的实验表明，我们的方法实现了高达20倍的加速，并且与最先进的方法具有相当的性能。

    Dataset Distillation (DD), a newly emerging field, aims at generating much smaller but efficient synthetic training datasets from large ones. Existing DD methods based on gradient matching achieve leading performance; however, they are extremely computationally intensive as they require continuously optimizing a dataset among thousands of randomly initialized models. In this paper, we assume that training the synthetic data with diverse models leads to better generalization performance. Thus we propose two model augmentation techniques, i.e. using early-stage models and parameter perturbation to learn an informative synthetic set with significantly reduced training cost. Extensive experiments demonstrate that our method achieves up to 20x speedup and comparable performance on par with state-of-the-art methods.
    
[^67]: 利用单个演示中的连续性来增强强化学习

    Leveraging Sequentiality in Reinforcement Learning from a Single Demonstration. (arXiv:2211.04786v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2211.04786](http://arxiv.org/abs/2211.04786)

    本文提出用单个演示来增强强化学习，利用连续性偏见来学习控制复杂机器人任务，学习一个目标条件策略，通过DCIL-II解决连续目标间的兼容性问题。

    

    深度强化学习已成功应用于学习机器人控制。然而，当代理只在完成复杂任务后得到奖励时，相应的算法会遇到困难。在这种情况下，使用演示可以显著加速学习过程，但演示可能很难获得。本文提出利用连续性偏见来学习控制复杂机器人任务的策略，只需要一个演示。为此，我们的方法学习了一个目标条件策略，以控制系统在连续的低维度目标之间移动。这种连续目标达成方法引起了一个连续目标间的兼容性问题：我们需要确保达成目标后的状态与后续目标的实现相兼容。为了解决这个问题，我们提出了一种名为DCIL-II的新算法。我们展示了DCIL-II能够以前所未有的样本效率解决一些挑战性的模拟任务。

    Deep Reinforcement Learning has been successfully applied to learn robotic control. However, the corresponding algorithms struggle when applied to problems where the agent is only rewarded after achieving a complex task. In this context, using demonstrations can significantly speed up the learning process, but demonstrations can be costly to acquire. In this paper, we propose to leverage a sequential bias to learn control policies for complex robotic tasks using a single demonstration. To do so, our method learns a goal-conditioned policy to control a system between successive low-dimensional goals. This sequential goal-reaching approach raises a problem of compatibility between successive goals: we need to ensure that the state resulting from reaching a goal is compatible with the achievement of the following goals. To tackle this problem, we present a new algorithm called DCIL-II. We show that DCIL-II can solve with unprecedented sample efficiency some challenging simulated tasks suc
    
[^68]: 基于全卷积神经网络训练的低资源蒙古语文本到语音系统的高效实现

    Efficiently Trained Low-Resource Mongolian Text-to-Speech System Based On FullConv-TTS. (arXiv:2211.01948v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.01948](http://arxiv.org/abs/2211.01948)

    该论文提出了一个基于全卷积神经网络训练的低资源蒙古语文本到语音系统，相较于传统的包含循环神经网络的TTS模型，训练时间更短且音频合成质量不降低。

    

    循环神经网络(RNN)已经成为了序列数据建模的标准技术，也被用于构建一些新奇的文本到语音模型。但是，包含RNN组件的TTS模型要求GPU性能高且训练时间长。相反，研究发现基于CNN的序列合成技术可以大大减少TTS模型的训练时间，同时由于其高度并行化，可以保证一定的性能。我们提出了一个基于深度卷积神经网络的新型文本到语音系统，不使用任何RNN组件(循环单元)。同时，通过一系列的数据增强方法，如时间扭曲，频率屏蔽和时间屏蔽等，提高了我们模型的普适性和鲁棒性。最终的实验结果表明，仅使用CNN组件的TTS模型可以减少与Tacotron等传统TTS模型相比的训练时间，同时确保合成音频的质量。

    Recurrent Neural Networks (RNNs) have become the standard modeling technique for sequence data, and are used in a number of novel text-to-speech models. However, training a TTS model including RNN components has certain requirements for GPU performance and takes a long time. In contrast, studies have shown that CNN-based sequence synthesis technology can greatly reduce training time in text-to-speech models while ensuring a certain performance due to its high parallelism. We propose a new text-to-speech system based on deep convolutional neural networks that does not employ any RNN components (recurrent units). At the same time, we improve the generality and robustness of our model through a series of data augmentation methods such as Time Warping, Frequency Mask, and Time Mask. The final experimental results show that the TTS model using only the CNN component can reduce the training time compared to the classic TTS models such as Tacotron while ensuring the quality of the synthesized
    
[^69]: 通用对抗方向

    Universal Adversarial Directions. (arXiv:2210.15997v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.15997](http://arxiv.org/abs/2210.15997)

    研究证明传统的通用对抗干扰 (UAPs) 在深度神经网络分类器之间转移性是次优的，为此本文提出了通用对抗方向 (UADs)，只固定通用方向，以便克服在跨DNN架构上转移的挑战。

    

    尽管深度神经网络在图像识别任务中表现出色，但观察到它们容易受到通用对抗干扰 (UAPs) 的影响，这些干扰使用单个扰动向量干扰所有输入样本。然而，UAPs在跨DNN架构转移时通常很困难并导致挑战性优化问题。本文研究了UAP的可Transfer性，通过分析分类器和UAP对手玩家之间在通用对抗示例博弈中的均衡情况。我们表明，在温和的假设下，通用对抗示例博弈缺乏一个纯纳什均衡，这表明UAPs在DNN分类器之间的转移性是次优的。针对这个问题，我们提出了通用对抗方向 (UADs)，只固定对抗干扰的通用方向，允许跨样本自由选择干扰的幅度。我们证明，UAD对抗示例博弈可以具有纳什均衡且该均衡状态纯。

    Despite their great success in image recognition tasks, deep neural networks (DNNs) have been observed to be susceptible to universal adversarial perturbations (UAPs) which perturb all input samples with a single perturbation vector. However, UAPs often struggle in transferring across DNN architectures and lead to challenging optimization problems. In this work, we study the transferability of UAPs by analyzing equilibrium in the universal adversarial example game between the classifier and UAP adversary players. We show that under mild assumptions the universal adversarial example game lacks a pure Nash equilibrium, indicating UAPs' suboptimal transferability across DNN classifiers. To address this issue, we propose Universal Adversarial Directions (UADs) which only fix a universal direction for adversarial perturbations and allow the perturbations' magnitude to be chosen freely across samples. We prove that the UAD adversarial example game can possess a Nash equilibrium with a pure U
    
[^70]: MEET: 缓冲区采样的蒙特卡罗探索-开发权衡

    MEET: A Monte Carlo Exploration-Exploitation Trade-off for Buffer Sampling. (arXiv:2210.13545v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.13545](http://arxiv.org/abs/2210.13545)

    提出了一种新的基于探索-开发权衡的缓冲区采样策略，可以根据任务的复杂性自适应地调整采样策略，并在经典控制环境中表现出优越性能。

    

    数据选择是任何基于数据的优化技术的关键，例如强化学习。针对回放缓冲区的最新采样策略可以提高强化学习智能体的性能。然而，它们没有考虑Q值估计的不确定性。因此，它们不能根据任务的复杂性自适应地调整采样策略，包括转换的探索和开发。为了解决这个问题，本文提出了一种新的采样策略，这种策略利用了探索-开发权衡。这是通过Q值函数的不确定性估计实现的，它指导采样探索更重要的转换，从而学习更有效的策略。对于经典控制环境的实验表明，在不同环境中平稳的结果。它们表明，在密集奖励的情况下，与收敛和峰值性能相比，所提出的方法的表现比最新的采样策略提高了26％。

    Data selection is essential for any data-based optimization technique, such as Reinforcement Learning. State-of-the-art sampling strategies for the experience replay buffer improve the performance of the Reinforcement Learning agent. However, they do not incorporate uncertainty in the Q-Value estimation. Consequently, they cannot adapt the sampling strategies, including exploration and exploitation of transitions, to the complexity of the task. To address this, this paper proposes a new sampling strategy that leverages the exploration-exploitation trade-off. This is enabled by the uncertainty estimation of the Q-Value function, which guides the sampling to explore more significant transitions and, thus, learn a more efficient policy. Experiments on classical control environments demonstrate stable results across various environments. They show that the proposed method outperforms state-of-the-art sampling strategies for dense rewards w.r.t. convergence and peak performance by 26% on av
    
[^71]: BARS：机场跑道分割基准数据集

    BARS: A Benchmark for Airport Runway Segmentation. (arXiv:2210.12922v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.12922](http://arxiv.org/abs/2210.12922)

    BARS是一个机场跑道分割基准数据集，通过11种代表性的实例分割方法的评估和性能分析，让基于深度学习的方法能更好地适应复杂场景。

    

    机场跑道分割可有效降低降落阶段的事故率，而深度学习相关方法在分割任务上表现良好，可以很好地适应复杂场景。然而，该领域缺乏大规模、公开可用的数据集，使基于深度学习的方法难以开发。因此，我们提出了一个名为BARS的机场跑道分割基准数据集。该数据集是利用X-Plane模拟平台收集的，包含10,256张图像和30,201个实例，有三个类别。我们在BARS上评估了11种代表性的实例分割方法，并分析了它们的性能。

    Airport runway segmentation can effectively reduce the accident rate during the landing phase, which has the largest risk of flight accidents. With the rapid development of deep learning (DL), related methods achieve good performance on segmentation tasks and can be well adapted to complex scenes. However, the lack of large-scale, publicly available datasets in this field makes the development of methods based on DL difficult. Therefore, we propose a benchmark for airport runway segmentation, named BARS. Additionally, a semiautomatic annotation pipeline is designed to reduce the annotation workload. BARS has the largest dataset with the richest categories and the only instance annotation in the field. The dataset, which was collected using the X-Plane simulation platform, contains 10,256 images and 30,201 instances with three categories. We evaluate eleven representative instance segmentation methods on BARS and analyze their performance. Based on the characteristic of an airport runwa
    
[^72]: 以架构感知参考作为提示提高了数据有效的知识图谱构建

    Schema-aware Reference as Prompt Improves Data-Efficient Knowledge Graph Construction. (arXiv:2210.10709v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.10709](http://arxiv.org/abs/2210.10709)

    提出了一种以检索增强的架构感知参考作为提示的方法，可动态利用人类注释和弱监督数据所继承的架构和知识，指导生成具有更好语义连贯性和一致性的结构化知识，从而在数据效率和知识质量方面具有优越性。

    

    随着预训练语言模型的发展，许多基于提示的方法被提出并在数据有效的知识图谱构建中取得了令人瞩目的表现。然而，现有的基于提示的学习方法仍存在几个潜在的限制：（i）自然语言和预定义模式的输出结构化知识之间的语义差距，这意味着模型无法充分利用受限模板的语义知识；（ii）基于局部个体实例的表示学习限制了性能，给定了不充足的特征，这些特征不能释放预先训练语言模型的潜在类比能力。受这些观察的启发，我们提出了一种检索增强的方法，使用检索得到的架构感知参考作为提示，提高了数据有效的知识图谱构建的语义连贯性和一致性。在两个标准数据集上的实验结果表明，相比现有的基于提示和非提示的方法，我们提出的方法在数据效率和知识质量方面具有优越性。

    With the development of pre-trained language models, many prompt-based approaches to data-efficient knowledge graph construction have been proposed and achieved impressive performance. However, existing prompt-based learning methods for knowledge graph construction are still susceptible to several potential limitations: (i) semantic gap between natural language and output structured knowledge with pre-defined schema, which means model cannot fully exploit semantic knowledge with the constrained templates; (ii) representation learning with locally individual instances limits the performance given the insufficient features, which are unable to unleash the potential analogical capability of pre-trained language models. Motivated by these observations, we propose a retrieval-augmented approach, which retrieves schema-aware Reference As Prompt (RAP), for data-efficient knowledge graph construction. It can dynamically leverage schema and knowledge inherited from human-annotated and weak-supe
    
[^73]: 用神经平衡求解器解决NEs、CEs和CCEs的方法

    Turbocharging Solution Concepts: Solving NEs, CEs and CCEs with Neural Equilibrium Solvers. (arXiv:2210.09257v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.09257](http://arxiv.org/abs/2210.09257)

    该论文介绍了一种神经平衡求解器，可以快速、准确地解决所有固定形状游戏空间的NEs、CEs和CCEs问题，并提供一个灵活的平衡选择框架，有助于加强多智能体算法的实现和应用。

    

    解决博弈论中的Nash Equilibria、Correlated Equilibria和Coarse Correlated Equilibria等解决方案对于许多多智能体机器学习算法非常有用。然而，解决正则形式的博弈可能需要禁止或非确定性时间收敛，并且可能会失败。我们介绍了神经平衡求解器，它利用一种特殊的等变神经网络结构来近似解决所有固定形状的游戏空间，从而提高速度和确定性。我们定义了一个灵活的平衡选择框架，能够唯一选择最小化相对熵或最大化福利的平衡。网络可以在不需要生成任何监督训练数据的情况下进行训练。我们展示了惊人的零-shot泛化能力，使网络适用于更大的游戏。我们认为这样的网络是许多可能多智能体算法的强大组件。

    Solution concepts such as Nash Equilibria, Correlated Equilibria, and Coarse Correlated Equilibria are useful components for many multiagent machine learning algorithms. Unfortunately, solving a normal-form game could take prohibitive or non-deterministic time to converge, and could fail. We introduce the Neural Equilibrium Solver which utilizes a special equivariant neural network architecture to approximately solve the space of all games of fixed shape, buying speed and determinism. We define a flexible equilibrium selection framework, that is capable of uniquely selecting an equilibrium that minimizes relative entropy, or maximizes welfare. The network is trained without needing to generate any supervised training data. We show remarkable zero-shot generalization to larger games. We argue that such a network is a powerful component for many possible multiagent algorithms.
    
[^74]: 学习图像表示以进行异常检测：在药物开发中发现组织学改变的应用

    Learning image representations for anomaly detection: application to discovery of histological alterations in drug development. (arXiv:2210.07675v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.07675](http://arxiv.org/abs/2210.07675)

    该论文提出了一种基于CNN的异常检测系统，通过对健康组织进行辅助任务训练，使表示适应组织中的相关细节，实现对组织学图像中的异常情况检测。

    

    我们提出了一种用于组织病理学图像异常检测的系统。在组织学中，正常样本通常是大量存在的，而异常（病理）情况通常很少或不可用。在这种情况下，使用在健康数据上训练的单类分类器可以检测到分布外的异常样本。这样的方法与预训练的卷积神经网络（CNN）图像表示相结合，以前已经用于异常检测（AD）。但是，预训练的现成CNN表示可能对组织中的异常情况不敏感，而健康组织的自然变异可能导致远离的表示。为了使表示适应健康组织中的相关细节，我们建议在辅助任务上训练CNN，该任务区分不同物种、器官和染色试剂的健康组织。几乎不需要额外的标注工作量，因为健康样本可以自动获得上述标签。在训练中，我们强制执行

    We present a system for anomaly detection in histopathological images. In histology, normal samples are usually abundant, whereas anomalous (pathological) cases are scarce or not available. Under such settings, one-class classifiers trained on healthy data can detect out-of-distribution anomalous samples. Such approaches combined with pre-trained Convolutional Neural Network (CNN) representations of images were previously employed for anomaly detection (AD). However, pre-trained off-the-shelf CNN representations may not be sensitive to abnormal conditions in tissues, while natural variations of healthy tissue may result in distant representations. To adapt representations to relevant details in healthy tissue we propose training a CNN on an auxiliary task that discriminates healthy tissue of different species, organs, and staining reagents. Almost no additional labeling workload is required, since healthy samples come automatically with aforementioned labels. During training we enforce
    
[^75]: 基于平衡数系统的联邦边缘学习无线计算设计方案

    Over-the-Air Computation Based on Balanced Number Systems for Federated Edge Learning. (arXiv:2210.07012v2 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2210.07012](http://arxiv.org/abs/2210.07012)

    本研究提出了一种基于平衡数系统的数字计算方案，用于联邦边缘学习中的梯度聚合。通过数字的平均值计算实数参数的平均值，避免了对精确样本级时间同步、信道估计开销和信道反转的需求，同时提高了聚合性能。

    

    本研究提出了一种数字无线计算（OAC）方案，用于联邦边缘学习（FEEL）的连续值（模拟）聚合。我们展示了利用基于平衡数系统的数字可以近似计算一组实数参数的平均值。通过利用该关键属性，该方案将本地随机梯度编码为一组数字。接下来，它利用数字的值确定激活的正交频分复用（OFDM）子载波的位置。该方案在边缘服务器（ES）使用非相干接收器，不需要精确的样本级时间同步、信道估计开销和信道反转，并且不利用边缘设备（EDs）上的预均衡。我们理论分析了该方案的MSE性能和收敛速度。

    In this study, we propose a digital over-the-air computation (OAC) scheme for achieving continuous-valued (analog) aggregation for federated edge learning (FEEL). We show that the average of a set of real-valued parameters can be calculated approximately by using the average of the corresponding numerals, where the numerals are obtained based on a balanced number system. By exploiting this key property, the proposed scheme encodes the local stochastic gradients into a set of numerals. Next, it determines the positions of the activated orthogonal frequency division multiplexing (OFDM) subcarriers by using the values of the numerals. To eliminate the need for precise sample-level time synchronization, channel estimation overhead, and channel inversion, the proposed scheme also uses a non-coherent receiver at the edge server (ES) and does not utilize a pre-equalization at the edge devices (EDs). We theoretically analyze the MSE performance of the proposed scheme and the convergence rate f
    
[^76]: 大规模几何学习的内在维度

    Intrinsic Dimension for Large-Scale Geometric Learning. (arXiv:2210.05301v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.05301](http://arxiv.org/abs/2210.05301)

    本研究提出了一种计算上可行的方法来确定大规模复杂数据的内在维度，该方法考虑了数据集的几何特性，并在准确性和计算效率方面优于现有方法。

    

    维度的概念对于理解数据的复杂性至关重要。确定数据集的维度的一种天真的方法是基于属性的数量。更复杂的方法推导出内在维度（ID）的概念，使用更复杂的特征函数，例如数据点之间的距离。然而，许多这些方法基于经验观察，无法应对当代数据集的几何特性，并且缺乏公理基础。V. Pestov提出了一种不同的方法，将内在维度公理地与数学集中度现象联系起来。首先，对于大规模实际数据集，计算这些内在维度的方法计算上是不可行的。在本研究中，我们推导出了一种计算上可行的方法来确定这些公理的内在维度函数。

    The concept of dimension is essential to grasp the complexity of data. A naive approach to determine the dimension of a dataset is based on the number of attributes. More sophisticated methods derive a notion of intrinsic dimension (ID) that employs more complex feature functions, e.g., distances between data points. Yet, many of these approaches are based on empirical observations, cannot cope with the geometric character of contemporary datasets, and do lack an axiomatic foundation. A different approach was proposed by V. Pestov, who links the intrinsic dimension axiomatically to the mathematical concentration of measure phenomenon. First methods to compute this and related notions for ID were computationally intractable for large-scale real-world datasets. In the present work, we derive a computationally feasible method for determining said axiomatic ID functions. Moreover, we demonstrate how the geometric properties of complex data are accounted for in our modeling. In particular, 
    
[^77]: 利用变分因果推断和精细关系信息预测细胞响应

    Predicting Cellular Responses with Variational Causal Inference and Refined Relational Information. (arXiv:2210.00116v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.00116](http://arxiv.org/abs/2210.00116)

    本研究利用基因调控网络信息设计了一种新的因果推断框架，并通过邻接矩阵更新技术预训练图卷积网络以更好地预测细胞在反事实干扰下的基因表达。同时，我们提出了一个鲁棒的估计器来高效估计边缘干扰效应。研究结果展示了该框架的优越性能。

    

    预测细胞在干扰下的响应可能为药物研发和个性化治疗带来重要好处。在本研究中，我们提出了一种新的图形变分贝叶斯因果推断框架，预测细胞在反事实干扰下（即细胞未真实接收的干扰）的基因表达，利用代表生物学知识的基因调控网络（GRN）信息来辅助个性化细胞响应预测。我们还针对数据自适应GRN开发了邻接矩阵更新技术用于图卷积网络的预训练，在模型性能上提供了更多的基因关系洞见。

    Predicting the responses of a cell under perturbations may bring important benefits to drug discovery and personalized therapeutics. In this work, we propose a novel graph variational Bayesian causal inference framework to predict a cell's gene expressions under counterfactual perturbations (perturbations that this cell did not factually receive), leveraging information representing biological knowledge in the form of gene regulatory networks (GRNs) to aid individualized cellular response predictions. Aiming at a data-adaptive GRN, we also developed an adjacency matrix updating technique for graph convolutional networks and used it to refine GRNs during pre-training, which generated more insights on gene relations and enhanced model performance. Additionally, we propose a robust estimator within our framework for the asymptotically efficient estimation of marginal perturbation effect, which is yet to be carried out in previous works. With extensive experiments, we exhibited the advanta
    
[^78]: DecAF：针对知识库问答的答案和逻辑形式联合解码

    DecAF: Joint Decoding of Answers and Logical Forms for Question Answering over Knowledge Bases. (arXiv:2210.00063v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.00063](http://arxiv.org/abs/2210.00063)

    DecAF 提出了一种联合生成逻辑形式和直接答案的新型框架，结合了它们的优点以获取最终答案；同时，它还采用了简单的自由文本检索，相比以往的方法更易于适应不同的数据集。

    

    知识库问答旨在使用知识库中的实体和关系等事实信息回答自然语言问题。先前的方法要么生成可在知识库上执行以获取最终答案的逻辑形式，要么直接预测答案。实验证据表明，前者通常能产生更准确的答案，但由于生成的逻辑形式可能存在语法和语义错误的潜在问题，因此存在无法执行的问题。在本文中，我们提出了一种新颖的框架 DecAF，它联合生成逻辑形式和直接答案，然后将它们的优点结合起来得到最终答案。此外，与大多数先前的方法不同，DecAF 基于简单的自由文本检索，而不依赖任何实体链接工具--这种简化使其适应不同的数据集更加容易。DecAF 在 WebQSP、FreebaseQA 和 GrailQA 基准测试中取得了新的最高准确性，同时在 CommonsenseQA 基准测试上取得了具有竞争力的结果。

    Question answering over knowledge bases (KBs) aims to answer natural language questions with factual information such as entities and relations in KBs. Previous methods either generate logical forms that can be executed over KBs to obtain final answers or predict answers directly. Empirical results show that the former often produces more accurate answers, but it suffers from non-execution issues due to potential syntactic and semantic errors in the generated logical forms. In this work, we propose a novel framework DecAF that jointly generates both logical forms and direct answers, and then combines the merits of them to get the final answers. Moreover, different from most of the previous methods, DecAF is based on simple free-text retrieval without relying on any entity linking tools -- this simplification eases its adaptation to different datasets. DecAF achieves new state-of-the-art accuracy on WebQSP, FreebaseQA, and GrailQA benchmarks, while getting competitive results on the Com
    
[^79]: 使用深度集成学习提升计算机网络对抗攻击的安全性

    Employing Deep Ensemble Learning for Improving the Security of Computer Networks against Adversarial Attacks. (arXiv:2209.12195v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2209.12195](http://arxiv.org/abs/2209.12195)

    本文提出了一种基于集成分类器的架构，称作SPRITZ-1.5C，它同时结合了1类分类的安全性和传统2类分类的高性能，在计算机网络等安全型应用中抵御对抗攻击具有挑战性。

    

    近年来，卷积神经网络在网络和多媒体安全等各种实际应用中表现出了极大的潜力。然而，这种网络结构的脆弱性使其容易受到攻击，这使得它们在安全性方面不太适用于诸如计算机网络等的安全型应用中。为了保护这些架构免受对抗攻击，需要使用具有挑战攻击能力的安全型架构。本研究提出了一种基于集成分类器的创新架构，该架构在面临攻击时同时结合了增强的一类分类和传统的二类分类的高性能。我们的架构被称为1.5类分类器（SPRITZ-1.5C），由终密集分类器、一个二类分类器（即CNN）和两个并行的一类分类器（即自动编码器）构成。

    In the past few years, Convolutional Neural Networks (CNN) have demonstrated promising performance in various real-world cybersecurity applications, such as network and multimedia security. However, the underlying fragility of CNN structures poses major security problems, making them inappropriate for use in security-oriented applications including such computer networks. Protecting these architectures from adversarial attacks necessitates using security-wise architectures that are challenging to attack.  In this study, we present a novel architecture based on an ensemble classifier that combines the enhanced security of 1-Class classification (known as 1C) with the high performance of conventional 2-Class classification (known as 2C) in the absence of attacks.Our architecture is referred to as the 1.5-Class (SPRITZ-1.5C) classifier and constructed using a final dense classifier, one 2C classifier (i.e., CNNs), and two parallel 1C classifiers (i.e., auto-encoders). In our experiments, 
    
[^80]: 学习证明机制目前存在许多问题

    Proof-of-Learning is Currently More Broken Than You Think. (arXiv:2208.03567v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.03567](http://arxiv.org/abs/2208.03567)

    学习证明机制PoL存在不少问题，由于现有的欺骗策略很容易被打败或无法重现，因此对对手的安全保障不稳健。新的欺骗策略引入可以打破PoL的最新防御方法，但成本较低。

    

    学习证明（PoL）提出，模型所有者记录训练检查点，以建立为训练耗费的计算提供证明。 PoL的作者放弃了加密方法，以换取深度学习的可扩展性，从而换取了严格的安全保证。他们通过展示盗用模型的计算证明--计算偷来的模型的证明，和真正地训练模型所需要的证明一样昂贵来实证证明了这种方法的优点。但是，最近的研究提供了一个反例，从而使这个观察失效。在这项工作中，我们首先证明，尽管当前PoL验证对于对手来说不稳健是真实的，但是最近的工作大大低估了这种缺乏稳健性。这是因为现有的欺骗策略要么不可重现，要么针对PoL的削弱形式--这意味着它们很容易被更改验证的超参数来挫败。相反，我们引入了第一批欺骗策略，它们可以打破适用于PoL的最新防御方法，但代价很低。

    Proof-of-Learning (PoL) proposes that a model owner logs training checkpoints to establish a proof of having expended the computation necessary for training. The authors of PoL forego cryptographic approaches and trade rigorous security guarantees for scalability to deep learning. They empirically argued the benefit of this approach by showing how spoofing--computing a proof for a stolen model--is as expensive as obtaining the proof honestly by training the model. However, recent work has provided a counter-example and thus has invalidated this observation.  In this work we demonstrate, first, that while it is true that current PoL verification is not robust to adversaries, recent work has largely underestimated this lack of robustness. This is because existing spoofing strategies are either unreproducible or target weakened instantiations of PoL--meaning they are easily thwarted by changing hyperparameters of the verification. Instead, we introduce the first spoofing strategies that c
    
[^81]: 基于压力分布分析的婴儿运动分类——研究和临床应用的附加价值

    Infant movement classification through pressure distribution analysis -- added value for research and clinical implementation. (arXiv:2208.00884v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2208.00884](http://arxiv.org/abs/2208.00884)

    本文提出了一种创新型的非侵入式方法，使用压力传感器对婴儿的一般运动进行分类，旨在实现早期神经肌肉障碍（如脑瘫）的客观检测。研究结果表明，使用压力数据可以区分婴儿的典型运动模式，即“坐立不安期”和“坐立不安前期”。

    

    本研究旨在通过使用压力传感设备来对婴儿的一般运动进行分类，从而实现早期的神经肌肉障碍（如脑瘫）的客观检测。本文测试了使用压力数据来区分“坐立不安期”（即坐立不安运动）与“坐立不安前期”（即扭动运动）的典型运动模式的可行性。在此过程中，我们记录了每个婴儿在出生后 4-16 周的间隔期内连续七个实验室会话的多模态传感器数据，包括来自一个 32x32 网格压力传感垫及其 1024 个传感器的压力数据。为了验证概念，从两个目标年龄段中，每个持续 5 秒的 1776 个压力数据片段被用于运动分类。每个片段都是根据相应的同步视频数据由人工评估员进行预注释的，标记为坐立不安存在或不存在。

    Aiming at objective early detection of neuromotor disorders such as cerebral palsy, we proposed an innovative non-intrusive approach using a pressure sensing device to classify infant general movements (GMs). Here, we tested the feasibility of using pressure data to differentiate typical GM patterns of the ''fidgety period'' (i.e., fidgety movements) vs. the ''pre-fidgety period'' (i.e., writhing movements). Participants (N = 45) were sampled from a typically-developing infant cohort. Multi-modal sensor data, including pressure data from a 32x32-grid pressure sensing mat with 1024 sensors, were prospectively recorded for each infant in seven succeeding laboratory sessions in biweekly intervals from 4-16 weeks of post-term age. For proof-of-concept, 1776 pressure data snippets, each 5s long, from the two targeted age periods were taken for movement classification. Each snippet was pre-annotated based on corresponding synchronised video data by human assessors as either fidgety present (
    
[^82]: 深度对比单类时序异常检测方法

    Deep Contrastive One-Class Time Series Anomaly Detection. (arXiv:2207.01472v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.01472](http://arxiv.org/abs/2207.01472)

    本论文提出了一种基于对比学习和一类分类法的深度对比单类时序异常检测方法(COCA)，能够提高检测性能。

    

    由于时间序列数据的累积和标签的缺失，时序异常检测是一个自我监督的深度学习任务。为了克服现有方法的不足，本文提出了一种基于对比学习和一类分类法的深度对比单类时序异常检测方法(COCA)，它通过所谓的"序列对比"来提高检测性能。

    The accumulation of time-series data and the absence of labels make time-series Anomaly Detection (AD) a self-supervised deep learning task. Single-normality-assumption-based methods, which reveal only a certain aspect of the whole normality, are incapable of tasks involved with a large number of anomalies. Specifically, Contrastive Learning (CL) methods distance negative pairs, many of which consist of both normal samples, thus reducing the AD performance. Existing multi-normality-assumption-based methods are usually two-staged, firstly pre-training through certain tasks whose target may differ from AD, limiting their performance. To overcome the shortcomings, a deep Contrastive One-Class Anomaly detection method of time series (COCA) is proposed by authors, following the normality assumptions of CL and one-class classification. It treats the original and reconstructed representations as the positive pair of negative-sample-free CL, namely "sequence contrast". Next, invariance terms a
    
[^83]: 面对混淆因素的悲观情绪：部分可观察马尔可夫决策过程的证明有效离线强化学习

    Pessimism in the Face of Confounders: Provably Efficient Offline Reinforcement Learning in Partially Observable Markov Decision Processes. (arXiv:2205.13589v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.13589](http://arxiv.org/abs/2205.13589)

    本文提出了代理变量悲观策略优化 (P3O) 算法，它通过近端因果推断构建悲观置信区间耦合序列解决了部分可观察马尔可夫决策过程中的混淆偏差和最优策略与行为策略之间的分布偏移问题。

    

    本文研究了部分可观测马尔可夫决策过程中的离线强化学习。特别地，我们旨在从由行为策略收集的数据集中学习最优策略，该策略可能取决于潜在状态。这样的数据集在混淆意义上同时影响行动和观测值，这对于现有的离线强化学习算法来说是禁止的。为此，我们提出了通过近端因果推断构建的悲观置信区间耦合序列的代理变量悲观策略优化（P3O）算法，该算法在广义函数逼近的上下文中解决了混淆偏差和最优策略与行为策略之间的分布偏移问题。我们证明，在混淆数据集的部分覆盖假设下，P3O可以实现n^{-1/2}的收敛率。

    We study offline reinforcement learning (RL) in partially observable Markov decision processes. In particular, we aim to learn an optimal policy from a dataset collected by a behavior policy which possibly depends on the latent state. Such a dataset is confounded in the sense that the latent state simultaneously affects the action and the observation, which is prohibitive for existing offline RL algorithms. To this end, we propose the \underline{P}roxy variable \underline{P}essimistic \underline{P}olicy \underline{O}ptimization (\texttt{P3O}) algorithm, which addresses the confounding bias and the distributional shift between the optimal and behavior policies in the context of general function approximation. At the core of \texttt{P3O} is a coupled sequence of pessimistic confidence regions constructed via proximal causal inference, which is formulated as minimax estimation. Under a partial coverage assumption on the confounded dataset, we prove that \texttt{P3O} achieves a $n^{-1/2}$-
    
[^84]: 最少到最多提示可以使大规模语言模型实现复杂推理

    Least-to-Most Prompting Enables Complex Reasoning in Large Language Models. (arXiv:2205.10625v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2205.10625](http://arxiv.org/abs/2205.10625)

    本文提出最少到最多提示的策略，能够帮助大规模语言模型实现复杂推理并推广到难度更高的问题。通过这种策略结合GPT-3 code-davinci-002模型能够完美解决组合泛化基准SCAN中的所有分割。

    

    思维链提示在各种自然语言推理任务中表现出卓越的性能。然而，它在需要解决比提示中的示例更难的问题时表现不佳。为了克服这种易于困难泛化的挑战，我们提出了一种新的提示策略，即最少到最多提示。该策略的关键思想是将复杂问题分解成一系列更简单的子问题，然后按顺序解决它们。解决每个子问题都得益于先前解决的子问题的答案。我们在符号操作、组合推理和数学推理相关的任务上的实验结果表明，最少到最多提示能够推广到比提示中更难的问题。一个值得注意的发现是，在使用最少到最多提示与GPT-3 code-davinci-002模型的情况下，它可以以完美的准确性解决组合泛化基准SCAN中的任何分割(包括具有挑战性的零样本分割)，尽管之前无法在没有微调的情况下解决任何分割点。

    Chain-of-thought prompting has demonstrated remarkable performance on various natural language reasoning tasks. However, it tends to perform poorly on tasks which requires solving problems harder than the exemplars shown in the prompts. To overcome this challenge of easy-to-hard generalization, we propose a novel prompting strategy, least-to-most prompting. The key idea in this strategy is to break down a complex problem into a series of simpler subproblems and then solve them in sequence. Solving each subproblem is facilitated by the answers to previously solved subproblems. Our experimental results on tasks related to symbolic manipulation, compositional generalization, and math reasoning reveal that least-to-most prompting is capable of generalizing to more difficult problems than those seen in the prompts. A notable finding is that when the GPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve the compositional generalization benchmark SCAN in any split (i
    
[^85]: 保护隐私的肖像抠图研究

    Rethinking Portrait Matting with Privacy Preserving. (arXiv:2203.16828v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2203.16828](http://arxiv.org/abs/2203.16828)

    本论文提出了P3M-10k，这是首个用于隐私保护肖像抠图的大规模匿名基准测试。同时，本研究提出了统一的抠图模型P3M-Net和有效的跨域性能提升策略P3M-CP。

    

    机器学习中个人信息的识别问题引起了越来越多人的关注。然而，以前的肖像抠图方法都是基于可识别的图像。为了填补这一空白，我们提出了P3M-10k，这是首个用于隐私保护肖像抠图(P3M)的大规模匿名基准测试。P3M-10k包括10,421张高分辨率模糊的人像图像以及高质量的alpha抠图，这使我们能够系统地评估基于Trimap和非Trimap的抠图方法，并在隐私保护训练（PPT）环境下获得有用的结果。我们还提出了一种统一的抠图模型P3M-Net，它兼容CNN和transformer骨干网络。为了进一步减轻在PPT设置下跨域性能差距问题，我们设计了一种简单但有效的Copy and Paste策略(P3M-CP)，它借鉴了公共名人图像的面部信息。

    Recently, there has been an increasing concern about the privacy issue raised by identifiable information in machine learning. However, previous portrait matting methods were all based on identifiable images. To fill the gap, we present P3M-10k, which is the first large-scale anonymized benchmark for Privacy-Preserving Portrait Matting (P3M). P3M-10k consists of 10,421 high resolution face-blurred portrait images along with high-quality alpha mattes, which enables us to systematically evaluate both trimap-free and trimap-based matting methods and obtain some useful findings about model generalization ability under the privacy preserving training (PPT) setting. We also present a unified matting model dubbed P3M-Net that is compatible with both CNN and transformer backbones. To further mitigate the cross-domain performance gap issue under the PPT setting, we devise a simple yet effective Copy and Paste strategy (P3M-CP), which borrows facial information from public celebrity images and d
    
[^86]: 统一实例和知识对齐预训练用于基于方面的情感分析

    Unified Instance and Knowledge Alignment Pretraining for Aspect-based Sentiment Analysis. (arXiv:2110.13398v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2110.13398](http://arxiv.org/abs/2110.13398)

    本论文提出了一种统一实例和知识对齐预训练框架，能够有效解决预训练和下游ABSA数据集之间的领域偏移问题，提高了基于方面的情感分析的性能，达到了最先进水平。

    

    基于方面的情感分析（ABSA）旨在确定对某个方面的情感倾向。由于昂贵且有限的标记数据，预训练策略已成为ABSA的事实标准。然而，预训练和下游ABSA数据集之间总是存在严重的领域偏移，直接微调时的知识转移效果不佳，导致下游任务表现亚优化。为了缓解这种领域偏移，我们引入了一个统一的对齐预训练框架，包括实例和知识层面的对齐，将其融入到预训练和微调流程中。具体而言，我们首先设计了一种新颖的分阶段检索采样方法，从大规模的预训练数据集中选择与目标领域相关的实例，从而实现预训练和目标领域实例的对齐（第一阶段）。然后，我们引入了基于知识指导的策略，进一步桥接知识层面的领域差异。我们在基准ABSA数据集上评估了我们的方法，并展示了其超越强基线的卓越性能。我们的方法在多个ABSA数据集上实现了最先进的结果，包括SemEval 2014任务4、SemEval 2015任务12和SemEval 2016任务5。

    Aspect-based Sentiment Analysis (ABSA) aims to determine the sentiment polarity towards an aspect. Because of the expensive and limited labelled data, the pretraining strategy has become the de-facto standard for ABSA. However, there always exists severe domain shift between the pretraining and downstream ABSA datasets, hindering the effective knowledge transfer when directly finetuning and making the downstream task performs sub-optimal. To mitigate such domain shift, we introduce a unified alignment pretraining framework into the vanilla pretrain-finetune pipeline with both instance- and knowledge-level alignments. Specifically, we first devise a novel coarse-to-fine retrieval sampling approach to select target domain-related instances from the large-scale pretraining dataset, thus aligning the instances between pretraining and target domains (First Stage). Then, we introduce a knowledge guidance-based strategy to further bridge the domain gap at the knowledge level. In practice, we 
    
[^87]: 超级神经元

    Super Neurons. (arXiv:2109.01594v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2109.01594](http://arxiv.org/abs/2109.01594)

    本文提出了一种新型产生神经元模型——超级神经元，可以克服传统神经网络的核定位限制，从而实现随机或可学习的核移位，增加每个连接的接受野大小，提高深度学习模型的性能同时降低模型的复杂性。

    

    最近提出了一种称为自组织操作神经网络(Self-Organized Operational Neural Networks,Self-ONNs)的新一代神经网络模型,该模型具有非线性学习单元——产生神经元,可以提供一种优雅的多样性层次。但是,像传统卷积神经网络(CNN)一样,Self-ONNs仍然具有一个普遍的缺陷:本地化（固定）核操作。这严重限制了不同层之间的接受野和信息流,因此需要深度和复杂的模型。本文提出了一种优越的(产生)神经元模型,或者简称为超级神经元,它允许随机或可学习的核移位,从而可以增加每个连接的接受野大小。使用这些超级神经元可以克服传统神经网络的核定位限制，从而提高了深度学习模型的性能并减少了复杂性。

    Self-Organized Operational Neural Networks (Self-ONNs) have recently been proposed as new-generation neural network models with nonlinear learning units, i.e., the generative neurons that yield an elegant level of diversity; however, like its predecessor, conventional Convolutional Neural Networks (CNNs), they still have a common drawback: localized (fixed) kernel operations. This severely limits the receptive field and information flow between layers and thus brings the necessity for deep and complex models. It is highly desired to improve the receptive field size without increasing the kernel dimensions. This requires a significant upgrade over the generative neurons to achieve the non-localized kernel operations for each connection between consecutive layers. In this article, we present superior (generative) neuron models (or super neurons in short) that allow random or learnable kernel shifts and thus can increase the receptive field size of each connection. The kernel localization
    
[^88]: 情境条件推理

    Situated Conditional Reasoning. (arXiv:2109.01552v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2109.01552](http://arxiv.org/abs/2109.01552)

    本文提出了一种基于情境的条件语句形式，其比经典条件语句表现力更强，能区分期望和虚拟语气，并被证明可以用一组合理性假设进行描述，在此基础上为情境条件知识库定义了一种最小闭包的包含形式。

    

    条件语句在建模中很有用，但不能总是准确地捕捉信息。本文提出了一种基于情境的条件语句形式。这些条件语句比经典条件语句更具表现力，足以在多个应用领域中使用，并能够区分期望和虚拟语气。形式上，它们被证明是Kraus、Lehmann和Magidor风格的条件设定的推广。本文表明，情境条件可以用一组合理性假设进行描述。然后，我们提出了这些条件语句的直观语义，并提出了一个表示结果，证明了我们的语义构造与假设描述完全一致。有了语义之后，我们为情境条件知识库定义了一种包含形式，称为最小闭包。

    Conditionals are useful for modelling, but are not always sufficiently expressive for capturing information accurately. In this paper we make the case for a form of conditional that is situation-based. These conditionals are more expressive than classical conditionals, are general enough to be used in several application domains, and are able to distinguish, for example, between expectations and counterfactuals. Formally, they are shown to generalise the conditional setting in the style of Kraus, Lehmann, and Magidor. We show that situation-based conditionals can be described in terms of a set of rationality postulates. We then propose an intuitive semantics for these conditionals, and present a representation result which shows that our semantic construction corresponds exactly to the description in terms of postulates. With the semantics in place, we proceed to define a form of entailment for situated conditional knowledge bases, which we refer to as minimal closure. It is reminiscen
    
[^89]: DeliData: 用于多方问题解决中的协商数据集

    DeliData: A dataset for deliberation in multi-party problem solving. (arXiv:2108.05271v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2108.05271](http://arxiv.org/abs/2108.05271)

    该文介绍了第一个公开可用的群体协商数据集，500个小组对话和14k个话语，64%的小组成员能够找到比他们单独找到的更好的解决方案。同时提出了一种新的注释模式用于捕捉协商线索，并使用该数据集评估了两种生成协商话语的方法。

    

    群体协商使人们能够协作解决问题，但由于缺乏资源，这方面的研究尚不完善。为此，我们引入了第一个公开可用的数据集，其中包含解决一个已经确立的认知任务的协作对话，包括500个小组对话和14k个话语。在这些对话中，64％的小组成员能够找到比他们单独找到的更好的解决方案，在最终解决方案为正确答案的小组中，有43.8％的小组中没有任何参与者自己就能正确解决任务。此外，我们提出了一种新的注释模式，捕捉协商线索，并公开了所有14k个注释过的话语。最后，我们使用提出的数据集开发和评估了两种生成协商话语的方法。数据收集平台、数据集和注释语料库可在https://delibot.xyz上公开获得。

    Group deliberation enables people to collaborate and solve problems, however, it is understudied due to a lack of resources. To this end, we introduce the first publicly available dataset containing collaborative conversations on solving a well-established cognitive task, consisting of 500 group dialogues and 14k utterances. In 64% of these conversations, the group members are able to find a better solution than they had identified individually, and in 43.8% of the groups who had a correct answer as their final solution, none of the participants had solved the task correctly by themselves. Furthermore, we propose a novel annotation schema that captures deliberation cues and release all 14k utterances annotated with it. Finally, we use the proposed dataset to develop and evaluate two methods for generating deliberation utterances. The data collection platform, dataset and annotated corpus are publicly available at https://delibot.xyz.
    
[^90]: AdvSim: 生成自动驾驶车辆的安全关键场景

    AdvSim: Generating Safety-Critical Scenarios for Self-Driving Vehicles. (arXiv:2101.06549v4 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2101.06549](http://arxiv.org/abs/2101.06549)

    提出了AdvSim框架，利用对抗性方法生成自动驾驶车辆的安全关键场景，具有可扩展性，适用于任何基于激光雷达的自主系统，可以识别各种具有语义意义的安全关键场景。

    

    随着自动驾驶系统的不断提升，模拟可能出现自主堆栈失败的情况变得越来越重要。传统上，这些场景只为规划模块生成了一些相对较少的场景，其输入为地面真实车辆状态。这不具有可扩展性，并且无法识别所有可能的自主失败，例如由于遮挡导致的感知故障。本文提出了AdvSim，一个对于任何基于激光雷达的自主系统生成安全关键场景的对抗性框架。给定一个初始交通场景，AdvSim以物理可行的方式修改参与者的轨迹并更新激光雷达传感器数据以匹配受扰动的世界。重要的是，通过直接从传感器数据进行模拟，我们获得安全关键场景，适用于完整的自主堆栈。我们的实验表明，我们的方法具有普适性，可以识别出大量具有语义意义的安全关键场景，适用于现代自动驾驶系统的各种情况。

    As self-driving systems become better, simulating scenarios where the autonomy stack may fail becomes more important. Traditionally, those scenarios are generated for a few scenes with respect to the planning module that takes ground-truth actor states as input. This does not scale and cannot identify all possible autonomy failures, such as perception failures due to occlusion. In this paper, we propose AdvSim, an adversarial framework to generate safety-critical scenarios for any LiDAR-based autonomy system. Given an initial traffic scenario, AdvSim modifies the actors' trajectories in a physically plausible manner and updates the LiDAR sensor data to match the perturbed world. Importantly, by simulating directly from sensor data, we obtain adversarial scenarios that are safety-critical for the full autonomy stack. Our experiments show that our approach is general and can identify thousands of semantically meaningful safety-critical scenarios for a wide range of modern self-driving sy
    
[^91]: 多目标进化算法在多峰目标上的理论分析

    Theoretical Analyses of Multiobjective Evolutionary Algorithms on Multimodal Objectives. (arXiv:2012.07231v4 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2012.07231](http://arxiv.org/abs/2012.07231)

    本文证明了当运行时间为无穷大时，SEMO无法找到所有Pareto前沿。但全局SEMO证明了在期望迭代次数上限内找到了所有Pareto前沿，这对于理解多目标进化算法在多峰问题中的应用具有参考价值。

    

    多目标进化算法（MOEA）在实践中的成功远远超过了理论研究的进展。特别是，以前的理论工作主要考虑由单峰目标组成的简单问题。为了更深入地了解进化算法如何解决多峰多目标问题，本文提出了OJZJ问题，这是一个由两个与经典跳跃函数基准同构的目标组成的双目标问题。我们证明了对于SEMO，无论运行时间如何，概率都不可能计算出完整的 Pareto 前沿。相反，对于所有问题大小n和所有跳跃大小k∈[ 4 . . n 2 −1 ]，全局SEMO（GSEMO）在 Θ ((n−2k)n^k）次迭代中覆盖 Pareto 前沿预期。

    The theoretical understanding of MOEAs is lagging far behind their success in practice. In particular, previous theory work considers mostly easy problems that are composed of unimodal objectives.  As a first step towards a deeper understanding of how evolutionary algorithms solve multimodal multiobjective problems, we propose the OJZJ problem, a bi-objective problem composed of two objectives isomorphic to the classic jump function benchmark. We prove that SEMO with probability one does not compute the full Pareto front, regardless of the runtime. In contrast, for all problem sizes $n$ and all jump sizes ${k \in [4..\frac n2 - 1]}$, the global SEMO (GSEMO) covers the Pareto front in an expected number of $\Theta((n-2k)n^{k})$ iterations. For $k = o(n)$, we also show the tighter bound $\frac 32 e n^{k+1} \pm o(n^{k+1})$, which might be the first runtime bound for an MOEA that is tight apart from lower-order terms. We also combine the GSEMO with two approaches that showed advantages in 
    
[^92]: 通过语言基础实现零样本组合策略学习

    Zero-Shot Compositional Policy Learning via Language Grounding. (arXiv:2004.07200v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2004.07200](http://arxiv.org/abs/2004.07200)

    本论文提出了一种通过语言基础实现零样本组合策略学习的算法，该算法将自然语言描述与策略网络结合，使策略网络能够推广到未见过的属性组合上，实验证明该算法在零样本组合策略学习任务中表现优于现有的RL/IL算法。

    

    尽管强化学习（RL）和模仿学习（IL）在最近都有了突破，但现有算法无法在训练环境之外进行推广。实际上，人类能够通过利用先前关于世界（如语言描述）的知识来快速适应新任务。为了促进带有领域自适应的语言引导代理的研究，我们提出了一项新的零样本组合策略学习任务，其中环境被描述为不同属性的组合。由于没有公共环境支持这项研究，我们介绍了一个新的研究平台BabyAI++，其中环境的动力学与视觉外观解耦。在每个回合中，BabyAI++提供了各种视觉动力学组合以及相应的描述性文本。为了评估所学代理的自适应能力，一组视觉动力学配对被保留在BabyAI++上进行测试。不出所料，我们发现当前的语言引导RL/IL方法无法解决这个零样本组合策略学习任务。因此，我们提出了一种新的语言引导策略学习算法，通过将自然语言描述与策略网络结合，使策略网络能够推广到未见过的属性组合上。为了实现这一目标，我们引入了一种新的语言基础模块，将符号属性表示和自然语言输入集成到策略网络中。我们的实验表明，我们提出的算法在零样本组合策略学习任务上显著优于现有的RL/IL算法。

    Despite recent breakthroughs in reinforcement learning (RL) and imitation learning (IL), existing algorithms fail to generalize beyond the training environments. In reality, humans can adapt to new tasks quickly by leveraging prior knowledge about the world such as language descriptions. To facilitate the research on language-guided agents with domain adaption, we propose a novel zero-shot compositional policy learning task, where the environments are characterized as a composition of different attributes. Since there are no public environments supporting this study, we introduce a new research platform BabyAI++ in which the dynamics of environments are disentangled from visual appearance. At each episode, BabyAI++ provides varied vision-dynamics combinations along with corresponding descriptive texts. To evaluate the adaption capability of learned agents, a set of vision-dynamics pairings are held-out for testing on BabyAI++. Unsurprisingly, we find that current language-guided RL/IL 
    

