# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [RATs-NAS: Redirection of Adjacent Trails on GCN for Neural Architecture Search.](http://arxiv.org/abs/2305.04206) | 本论文提出了一种被称为RATs-NAS的神经结构搜索方法，通过在GCN上重定向相邻操作轨迹来快速搜索最佳神经网络架构，实验结果表明这种方法比其他最先进方法更有效。 |
| [^2] | [Shall We Trust All Relational Tuples by Open Information Extraction? A Study on Speculation Detection.](http://arxiv.org/abs/2305.04181) | 本文研究了开放信息抽取中的猜测检测，提出了元组级别猜测检测的研究问题，并提出了名为OIE-Spec的基准模型。 |
| [^3] | [Train a Real-world Local Path Planner in One Hour via Partially Decoupled Reinforcement Learning and Vectorized Diversity.](http://arxiv.org/abs/2305.04180) | 通过Color解决方案的Actor-Sharer-Learner（ASL）训练框架和面向移动机器人的模拟器Sparrow，使得在实际应用中训练局部路径规划器变得可行。 |
| [^4] | [MIReAD: Simple Method for Learning High-quality Representations from Scientific Documents.](http://arxiv.org/abs/2305.04177) | MIReAD是通过微调变形金刚模型来预测期刊类别，从而学习科学论文高质量表示的简单方法，可用于论文检索和文献搜索。 |
| [^5] | [X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages.](http://arxiv.org/abs/2305.04160) | 本论文提出了一种名为X-LLM的方法，将多模态信息转换为外语并输入到大型语言模型中，从而赋予LLM多模态能力，对于LLM加入多模态信息的能力进行了探究和拓展。 |
| [^6] | [Score: A Rule Engine for the Scone Knowledge Base System.](http://arxiv.org/abs/2305.04154) | Score是一个规则引擎，用于Scone知识库系统，它可以自动执行简单推理，从而提高基于Scone构建的计划系统的能力。 |
| [^7] | [Bayesian Over-the-Air FedAvg via Channel Driven Stochastic Gradient Langevin Dynamics.](http://arxiv.org/abs/2305.04152) | 本文提出了无线 FALD 协议，可以在无噪声通信的情况下高效地在无线系统中实现分布式贝叶斯学习，实现了在通信回合之间多个本地更新以及由小批量计算的随机梯度，并进行了样本收敛分析。 |
| [^8] | [Controllable Mixed-Initiative Dialogue Generation through Prompting.](http://arxiv.org/abs/2305.04147) | 提出了一种新的生成方式，使用大型语言模型作为条件生成微调的替代方案，通过提示构造来实现可控的混合主动对话生成并获得了较好的性能表现。 |
| [^9] | [Artificial Neuropsychology: Are Large Language Models Developing Executive Functions?.](http://arxiv.org/abs/2305.04134) | 本文探讨了大型语言模型是否在学习中开发类似于人类执行功能，并使用汉诺塔测试了GPT-2和GPT-3的规划和工作记忆，发现它们在有限和非人类的方式下展示了一些执行功能。 |
| [^10] | [A Latent Diffusion Model for Protein Structure Generation.](http://arxiv.org/abs/2305.04120) | 提出了一种潜在扩散模型，能够在压缩的潜在空间中灵活地捕获自然蛋白质结构的分布，有效地生成具有高设计能力和效率的新型蛋白质骨架结构。 |
| [^11] | [Efficient and Degree-Guided Graph Generation via Discrete Diffusion Modeling.](http://arxiv.org/abs/2305.04111) | 本文提出了EDGE，一种新的离散扩散模型用于生成大型图，并通过删除边来鼓励图的稀疏性。EDGE在每个去噪步骤中仅关注图中一部分节点，并且可以明确地对图的节点度数进行建模。实验表明，EDGE比竞争方法更有效，并且可以生成具有数千个节点的大型图。 |
| [^12] | [Leveraging Semantic Relationships to Prioritise Indicators of Compromise in Additive Manufacturing Systems.](http://arxiv.org/abs/2305.04102) | 本文提出了一种基于语义关系的威胁优先级系统，可用于识别、提取和排名增材制造系统中的威胁指标。 |
| [^13] | [Gradient Leakage Defense with Key-Lock Module for Federated Learning.](http://arxiv.org/abs/2305.04095) | 本研究提出了一种新的联邦学习梯度泄露防御技术，使用私钥锁模块保护任意模型体系结构，并可确保无法从共享的梯度中重建私有训练数据。 |
| [^14] | [SANTA: Separate Strategies for Inaccurate and Incomplete Annotation Noise in Distantly-Supervised Named Entity Recognition.](http://arxiv.org/abs/2305.04076) | 本文提出了一种处理Distantly-Supervised Named Entity Recognition中错误和不完整标注噪声的分离策略，使用不同的模型构建来应对两种类型的噪声。 |
| [^15] | [Explaining RL Decisions with Trajectories.](http://arxiv.org/abs/2305.04073) | 本文提出一种用训练过程中遇到的轨迹解释强化学习决策的方法，并在离散和连续状态及行动空间的多样化环境中证明了其有效性。 |
| [^16] | [A Blockchain-based Platform for Reliable Inference and Training of Large-Scale Models.](http://arxiv.org/abs/2305.04062) | BRAIN是一个可靠的基于区块链的AI平台，能够确保大规模模型的可信推理和训练，通过独特的两阶段交易机制实现实时处理。 |
| [^17] | [Science and Technology Ontology: A Taxonomy of Emerging Topics.](http://arxiv.org/abs/2305.04055) | 本文提出了一个自动的科学技术本体，涵盖了科学技术领域的不传统主题，促进了不同领域和学科间的合作，实现了科学技术中的数据驱动研究。 |
| [^18] | [Echoes: Unsupervised Debiasing via Pseudo-bias Labeling in an Echo Chamber.](http://arxiv.org/abs/2305.04043) | Echoes提出了一种无监督的去偏方法，生成偏差对立样本的伪偏差标签，实现了对数据集中偏差特征的一致性处理，并取得了各项任务和数据集上的最先进性能。 |
| [^19] | [Refining the Responses of LLMs by Themselves.](http://arxiv.org/abs/2305.04039) | 本文提出了一种利用自我优化机制来改善大型语言模型响应质量的方法，实验证明在GPT-3.5模型上使用此方法，生成的结果质量可以与甚至超过GPT-4模型。 |
| [^20] | [Wasserstein-Fisher-Rao Embedding: Logical Query Embeddings with Local Comparison and Global Transport.](http://arxiv.org/abs/2305.04034) | 本文提出了一种新的查询嵌入方法，使用Wasserstein-Fisher-Rao度量来加权考虑嵌入之间的本地（局部）与全局（整体）特征，同时提出了一种卷积算法来进行线性时间计算，并使用块对角核来进行权衡。在标准数据集上表现出优异的效果。 |
| [^21] | [Towards a Simple Framework of Skill Transfer Learning for Robotic Ultrasound-guidance Procedures.](http://arxiv.org/abs/2305.04004) | 本文提出了一个简单的技能迁移学习框架，用于机器人超声引导程序。实验结果表明，经验丰富的临床医生在程序上比非临床医生表现更好。 |
| [^22] | [ANTONIO: Towards a Systematic Method of Generating NLP Benchmarks for Verification.](http://arxiv.org/abs/2305.04003) | 本文介绍了一种名为ANTONIO的Python库，它基于抽象解释方法提供了一种实用的方法和启发式规则，以便为自然语言处理（NLP）数据集和模型生成已知验证方法的基准。因为其普遍适用性，这项工作将为将NLP验证问题纳入神经网络验证比赛开辟新的可能性，并在NLP问题中普及这一方向。 |
| [^23] | [AADiff: Audio-Aligned Video Synthesis with Text-to-Image Diffusion.](http://arxiv.org/abs/2305.04001) | 本文提出了一种新颖的文本到视频合成框架AADiff，它使用音频信号控制时间动态，通过音频对齐生成视频。本文的方法通过音频区域编辑和信号平滑，在时间灵活性和一致性之间取得良好的平衡。该方法的有效性已通过实验验证，并可用于内容创建。 |
| [^24] | [Replicating Complex Dialogue Policy of Humans via Offline Imitation Learning with Supervised Regularization.](http://arxiv.org/abs/2305.03987) | 本文提出了一个离线模仿学习模型，通过监督正则化来解决协变量漂移问题，该模型能够复制人类复杂的对话策略，并在基准数据集上获得了最新的结果。 |
| [^25] | [Beyond the Model: Data Pre-processing Attack to Deep Learning Models in Android Apps.](http://arxiv.org/abs/2305.03963) | 本论文针对深度学习模型安全问题提出了基于数据处理的攻击方法，通过攻击可以影响模型性能和延迟，而不影响模型本身。 |
| [^26] | [Learning Action Embeddings for Off-Policy Evaluation.](http://arxiv.org/abs/2305.03954) | 本论文探讨了从记录数据中学习动作嵌入，以减少在大型动作空间中反向倾向评分（IPS）估计器的方差，同时提高离线评估的准确性。 |
| [^27] | [Learning Hybrid Actor-Critic Maps for 6D Non-Prehensile Manipulation.](http://arxiv.org/abs/2305.03942) | 论文介绍了一种名为HACMan的强化学习方法，用于使用点云观察进行6D非抓取式操作的物体操纵。HACMan重点关注物体中心动作表示，它包括从物体点云中选择接触位置和一组描述机器人在接触后如何移动的运动参数。在实际测试中，HACMan的表现明显优于现有基线方法。 |
| [^28] | [Residual Prompt Tuning: Improving Prompt Tuning with Residual Reparameterization.](http://arxiv.org/abs/2305.03937) | 本文提出了一种基于残差重参数化的Prompt Tuning改进方法-Residual Prompt Tuning，能够显著提高调优的性能和稳定性，在超过Prompt Tuning 7个点，且可以缩短Prompt长度10倍而不影响性能，同时对于学习率和Prompt初始化的选择具有鲁棒性。 |
| [^29] | [An Overview of AI and Blockchain Integration for Privacy-Preserving.](http://arxiv.org/abs/2305.03928) | 本文综述了AI与区块链整合的隐私保护技术，从数据加密、去标识化、多级分布式账本和k-匿名方法等特定应用场景入手，分析了AI-区块链-隐私保护系统的五个关键方面，最终提出了相应的技术建议和总结。 |
| [^30] | [Automated Spatio-Temporal Graph Contrastive Learning.](http://arxiv.org/abs/2305.03920) | 本文提出了一种自动化时空图对比学习模型来解决基于图的区域关系学习模型在处理普遍存在的数据噪声、缺失和分布异质性方面的挑战。 |
| [^31] | [Rethinking Class Imbalance in Machine Learning.](http://arxiv.org/abs/2305.03900) | 本研究提出了一个更广泛的类别不平衡分类方式，包括四种不平衡类型，并介绍了两种不平衡级别，使用理论分析证明了新的不平衡类型对学习公平性的重要影响。 |
| [^32] | [Energy-Latency Attacks to On-Device Neural Networks via Sponge Poisoning.](http://arxiv.org/abs/2305.03888) | 本研究针对移动设备处理器的安全性，提出了一种设备上的Sponge毒化攻击流程，可以有效地污染具有内置加速器的现代处理器，同时分析了毒化攻击的能量和延迟成本。 |
| [^33] | [Learning Stochastic Dynamical System via Flow Map Operator.](http://arxiv.org/abs/2305.03874) | 该论文提出了一种通过测量数据学习未知随机动力学系统的数值框架随机流映射学习（sFML），在不同类型的随机系统上进行的全面实验证明了 sFML 的有效性。 |
| [^34] | [Open problems in causal structure learning: A case study of COVID-19 in the UK.](http://arxiv.org/abs/2305.03859) | 本文研究了因果机器学习在COVID-19英国疫情数据中的应用挑战，探讨了不同数据格式对学习类别不同的算法的影响，并突出了因果结构学习中的未解问题和未来研究方向。 |
| [^35] | [CHAI-DT: A Framework for Prompting Conversational Generative AI Agents to Actively Participate in Co-Creation.](http://arxiv.org/abs/2305.03852) | 本文介绍了一个CHAI-DT框架，可以使对话生成型AI代理积极参与到共创活动中，为设计思维活动提供有用和创意性的贡献，并讨论了其潜在优势、局限性和风险。 |
| [^36] | [CLaC at SemEval-2023 Task 2: Comparing Span-Prediction and Sequence-Labeling approaches for NER.](http://arxiv.org/abs/2305.03845) | 本文比较了命名实体识别中的序列标记和跨度预测两种方法，在测试数据中跨度预测表现略优，并且使用更大版本的XLM RoBERTa可以显著提高性能。 |
| [^37] | [On Contrastive Learning of Semantic Similarity forCode to Code Search.](http://arxiv.org/abs/2305.03843) | 本文提出了一种结合静态和动态特征以及利用相似和不相似样本进行训练的代码搜索技术，在训练期间编码动态运行时信息。实验证明该方法在各种编程语言和模型架构中均具有一致的性能，比最先进的跨语言搜索工具提高了高达44.7%的性能。 |
| [^38] | [Spatiotemporal Transformer for Stock Movement Prediction.](http://arxiv.org/abs/2305.03835) | 使用时空变换器-LSTM模型进行股票运动预测，取得了高准确率，并在模拟中显示出比标准普尔500股票指数更高的收益率。 |
| [^39] | [Improved Logical Reasoning of Language Models via Differentiable Symbolic Programming.](http://arxiv.org/abs/2305.03742) | 本文提出一种新的可微分符号推理框架，DSR-LM，用于提高预训练语言模型的逻辑推理能力，不像以往的研究依赖手工制定的逻辑规则，该框架有效地学习加权规则，并应用语义损失进一步改善LMs的逻辑推理能力。 |
| [^40] | [AmGCL: Feature Imputation of Attribute Missing Graph via Self-supervised Contrastive Learning.](http://arxiv.org/abs/2305.03741) | AmGCL是一个用于处理属性缺失图数据的自监督对比学习框架，可以通过特征插补和潜在表示学习来解决属性图中节点属性缺失的问题。 |
| [^41] | [Tuning Traditional Language Processing Approaches for Pashto Text Classification.](http://arxiv.org/abs/2305.03737) | 本研究建立了一个普什图语自动文本分类系统，通过比较不同模型和特征提取方法，实验结果表明使用tf-idf特征提取方法的SVM模型在普什图语文本分类中取得了最高的准确率。 |
| [^42] | [Stackelberg Games for Learning Emergent Behaviors During Competitive Autocurricula.](http://arxiv.org/abs/2305.03735) | 本论文提出了一种新颖的博弈论算法，Stackelberg Multi-Agent Deep Deterministic Policy Gradient(ST-MADDPG), 用于在竞争学习自适应课程中学习新兴行为。 |
| [^43] | [Assessing Working Memory Capacity of ChatGPT.](http://arxiv.org/abs/2305.03731) | 本文评估了最先进语言模型ChatGPT的工作记忆容量，结果显示其在N-back任务的行为表现与人类参与者相似，这为设计具有人类级认知能力的人工智能系统提供了关键洞察。 |
| [^44] | [Clothes Grasping and Unfolding Based on RGB-D Semantic Segmentation.](http://arxiv.org/abs/2305.03259) | 本论文针对机器人辅助穿衣过程中的服装抓取和展开问题，提出了一种基于RGB-D语义分割的双向分形交叉融合网络，可以识别可抓取区域提供更多抓取可能性，并且使用RGB和深度数据融合来考虑图像信息。 |
| [^45] | [Beyond Homophily: Reconstructing Structure for Graph-agnostic Clustering.](http://arxiv.org/abs/2305.02931) | 本论文提出了一种新颖的图形聚类方法，能够超越同质性假设，重构结构实现对图形无关聚类，包括三个关键组件：图形重构、混合滤波器和双图形聚类网络。为了减少节点属性和拓扑结构之间的不良耦合，我们将它们分别映射到两个子空间中。 |
| [^46] | [Plan, Eliminate, and Track -- Language Models are Good Teachers for Embodied Agents.](http://arxiv.org/abs/2305.02412) | 本文介绍了Plan，Eliminate，和Track（PET）框架，该框架利用预先训练的大型语言模型（LLM）帮助智能体简化控制任务，从而解决了LLM直接作为智能体所面临的一些限制和问题。 |
| [^47] | [Commentary on explainable artificial intelligence methods: SHAP and LIME.](http://arxiv.org/abs/2305.02012) | 这篇评论对可解释人工智能方法 SHAP 和 LIME 进行了评述和比较，提出了一个框架且突出了它们的优缺点。 |
| [^48] | [Extraction of volumetric indices from echocardiography: which deep learning solution for clinical use?.](http://arxiv.org/abs/2305.01997) | 本文对当前医学/超声心动图图像分割方法进行了全面比较，提出了3D nnU-Net模型，解决了时间一致性和跨数据集方面的问题，并通过引入一个新的私有数据集，CARDINAL，来证明其在应用于临床中的优越性。 |
| [^49] | [Causality-aware Concept Extraction based on Knowledge-guided Prompting.](http://arxiv.org/abs/2305.01876) | 该论文提出了一种基于因果感知的知识引导提示方法，将其作为干预器装备到基于预训练语言模型的句子提取器中，以缓解概念偏差。在代表性的多语言KG数据集上进行广泛实验，获得了最先进的结果。 |
| [^50] | [H2CGL: Modeling Dynamics of Citation Network for Impact Prediction.](http://arxiv.org/abs/2305.01572) | 本文提出了一种名为H2CGL的新颖图神经网络模型，用于引文网络的动态建模和影响预测。该模型通过分层和异构的方式记录目标论文年度动态信息，并优先考虑高被引论文和参考文献、引文、目标论文之间的关系。它采用加权 GIN 来捕捉异构子图的动态，同时采用对比学习来提高模型效果。 |
| [^51] | [Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models.](http://arxiv.org/abs/2305.01219) | 本研究提出一种新颖有效的“ProAttack”方法来执行干净标签的后门攻击，使用的是提示本身作为触发器。该方法不需要外部触发器，并确保毒瘤数据的标注正确，提高了后门攻击的隐蔽性，相比于现有的后门攻击方法有显著提升。 |
| [^52] | [Venn Diagram Multi-label Class Interpretation of Diabetic Foot Ulcer with Color and Sharpness Enhancement.](http://arxiv.org/abs/2305.01044) | 本文提出了一种基于Venn图解释的多标签分类算法，通过不同的图像增强策略，将四个类别缩减为两个，有效提高了糖尿病足潰疡的多类别分类准确度。 |
| [^53] | [Attack-SAM: Towards Attacking Segment Anything Model With Adversarial Examples.](http://arxiv.org/abs/2305.00866) | 本文是第一个全面研究如何使用对抗样本攻击分割万物模型SAM的工作，该工作重要的贡献为探讨SAM的对抗性鲁棒性，有助于理解和提高基础视觉模型安全性。 |
| [^54] | [Towards machine learning guided by best practices.](http://arxiv.org/abs/2305.00233) | 机器学习在多个领域的软件系统中得到广泛应用，但存在一些特殊的挑战和陷阱，研究显示ML使能系统具有不同于传统软件工程的开发过程。 |
| [^55] | [Local Search for Integer Linear Programming.](http://arxiv.org/abs/2305.00188) | 本论文开发了一个独立的局部搜索求解器，可用于解决一般整数线性规划，并在大型异构问题数据集上进行了验证。在搜索、改进和还原模式下，分别提出了可自适应修改变量值的算子和高效的举升算子，从而提高当前解的质量。实验表明，该方法在MIPLIB2017的异构问题集上表现优异。 |
| [^56] | [Exploring the Zero-Shot Capabilities of the Segment Anything Model (SAM) in 2D Medical Imaging: A Comprehensive Evaluation and Practical Guideline.](http://arxiv.org/abs/2305.00109) | 本文探索了Segment Anything Model (SAM)在医学影像中的零样本能力，并通过八种不同的提示策略在六个数据集上进行评估，结果表明其性能比当前最先进技术有所提升。 |
| [^57] | [Exploiting the Distortion-Semantic Interaction in Fisheye Data.](http://arxiv.org/abs/2305.00079) | 本文利用畸变-语义交互作用提出了一种方法，该方法通过提取畸变类别标签，并使用加权对比损失塑造主干网络的表征空间，以限制每个物体的表征和相应的畸变类别的关系。 |
| [^58] | [Causal Reasoning and Large Language Models: Opening a New Frontier for Causality.](http://arxiv.org/abs/2305.00050) | 大型语言模型在因果推理任务中取得了新的最高准确率，但是其鲁棒性仍然存在难以预测的失败模式。 |
| [^59] | [Energy-based Models as Zero-Shot Planners for Compositional Scene Rearrangement.](http://arxiv.org/abs/2304.14391) | 本文提出一种基于能量模型的零样本场景重新排列规划器，通过语言指导的空间概念来实现长指令以及在训练时从未见过的空间概念组合。本文的模型在指令导向操作基准测试以及组合指令基准测试中表现良好，优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。 |
| [^60] | [Multiobjective Logistics Optimization for Automated ATM Cash Replenishment Process.](http://arxiv.org/abs/2304.13671) | 本文研究了自动化ATM现金补充流程，提出了一个数学模型并给出了一个工具来评估各种不同的情况。在模拟数据集上，该模型与方法可以削减ATM现金运营成本。 |
| [^61] | [Optimal Layout Synthesis for Quantum Circuits as Classical Planning.](http://arxiv.org/abs/2304.12014) | 本文提供了两种编码，将最优布局综合作为经典规划问题，并使用最优的经典规划器来综合标准基准测试的最优布局，解决了对于大规模量子比特优化布局的问题。 |
| [^62] | [Towards Better Evaluation of GNN Expressiveness with BREC Dataset.](http://arxiv.org/abs/2304.07702) | 本论文介绍了一个新的Benchmark for Evaluating the Robustness of GNNs to Topological Changes (BREC)数据集，并使用BREC评估了几种现有的GNN模型的表达力，表明一些模型在以前的基准测试中表现良好，但在BREC上遇到了困难，突显了需要更好的GNN表现力评估的必要性。 |
| [^63] | [Repeated Principal-Agent Games with Unobserved Agent Rewards and Perfect-Knowledge Agents.](http://arxiv.org/abs/2304.07407) | 本文提出了一个利用多臂老虎机框架结构来处理未知代理奖励的策略，并证明了其性能是渐进最优的。 |
| [^64] | [REDf: A Renewable Energy Demand Forecasting Model for Smart Grids using Long Short Term Memory Network.](http://arxiv.org/abs/2304.03997) | 本文提出了一种基于长短期记忆网络的智能电网可再生能源需求预测模型REDf，可以提供准确的能量需求预测，改善可再生能源的集成，实验结果表明其准确度优于其他模型。 |
| [^65] | [BotTriNet: A Unified and Efficient Embedding for Social Bots Detection via Metric Learning.](http://arxiv.org/abs/2304.03144) | BOTTRINET基于文本内容检测机器人，并设计了三元组网络以提高分类性能。在真实世界数据集CRESCI2017上，系统表现最好。 |
| [^66] | [Spam-T5: Benchmarking Large Language Models for Few-Shot Email Spam Detection.](http://arxiv.org/abs/2304.01238) | 本文通过比较不同类型的大型语言模型和传统机器学习技术在邮件垃圾检测中的表现，发现大多数情况下，大型语言模型优于传统技术，特别是在样本有限的情况下。同时，本文还介绍了经过改进和微调的Spam-T5模型，该模型具有出色的性能表现。 |
| [^67] | [A Survey of Large Language Models.](http://arxiv.org/abs/2303.18223) | 本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。 |
| [^68] | [Natural Selection Favors AIs over Humans.](http://arxiv.org/abs/2303.16200) | 这篇论文探讨了随着人工智能的发展，其可能会出现不良特性并逐渐超越人类智能的问题，以及这对人类未来的控制权产生的影响。 |
| [^69] | [Deep RL with Hierarchical Action Exploration for Dialogue Generation.](http://arxiv.org/abs/2303.13465) | 本篇论文提出了一种新的方法，通过分层行为探索，从多个奖励函数中进行离线学习，并成功地解决了在对话生成中行为采样效率低下的问题，可以更好地识别人类情感细节。 |
| [^70] | [SmartBERT: A Promotion of Dynamic Early Exiting Mechanism for Accelerating BERT Inference.](http://arxiv.org/abs/2303.09266) | SmartBERT是一种改进的动态早期退出与层跳过机制，可以自适应地跳过一些层并自适应地选择是否退出，以加速BERT模型的推理速度。 |
| [^71] | [Geolocation Predicting of Tweets Using BERT-Based Models.](http://arxiv.org/abs/2303.07865) | 该论文提出基于BERT模型的推文地理位置预测方法，可以实现全球和美国上的中位误差分别小于30公里和15公里的定位精度。 |
| [^72] | [On the Fusion Strategies for Federated Decision Making.](http://arxiv.org/abs/2303.06109) | 本文研究了联邦决策制定中的信息聚合问题，分析了非贝叶斯社会学习策略并比较了中央处理器采用算术平均和几何平均的聚合策略。结果确认两种汇集策略都可以导致系统的渐近正态性特征描述。 |
| [^73] | [Deconstructing deep active inference.](http://arxiv.org/abs/2303.01618) | 本论文探讨了深度主动推断，实验研究表明最大化奖励的代理模型能够较好地解决复杂任务。 |
| [^74] | [Weighted First Order Model Counting with Directed Acyclic Graph Axioms.](http://arxiv.org/abs/2302.09830) | 本文研究了文献网络、家谱数据、时间数据等中具有平凡性质（无环性）的加权一阶模型计数问题，通过有向无环性约束域可提升的方法解决该问题。 |
| [^75] | [Multimodal Federated Learning via Contrastive Representation Ensemble.](http://arxiv.org/abs/2302.08888) | 本文提出了一种名为CreamFL的多模态联邦学习框架，可以从具有异构模型架构和数据模态的客户端中训练更大的服务器模型，同时只在公共数据集上传递知识。 |
| [^76] | [Approximately Bayes-Optimal Pseudo Label Selection.](http://arxiv.org/abs/2302.08883) | 本文介绍了BPLS，一种用于PLS的贝叶斯框架，通过解析逼近选择标签实例的标准，以避免由过度自信但错误预测的实例选择而导致的确认偏差问题。 |
| [^77] | [Language Model Analysis for Ontology Subsumption Inference.](http://arxiv.org/abs/2302.06761) | 本文研究了语言模型对本体子类推断的理解能力，提出了一套涉及原子概念和复合概念的推理任务，并证明语言模型对子类推断背景知识的记忆相对较少，但在给定少量样本的情况下可显著提高准确率。 |
| [^78] | [On Exact Sampling in the Two-Variable Fragment of First-Order Logic.](http://arxiv.org/abs/2302.02730) | 本文提出了一种针对一阶逻辑的采样算法，在有限域上具有域提升性，并且在存在计数约束的情况下依然有效。算法应用范围广泛，包括组合结构的均匀生成和统计采样。 |
| [^79] | [Regulating ChatGPT and other Large Generative AI Models.](http://arxiv.org/abs/2302.02337) | 本文将讨论大型生成AI模型的可信AI监管，包括直接监管、数据保护、内容监管和政策建议，并建议使用新术语来区分参与者。本文的目的是确保LGAIMs的可信度并使其为受益所用。 |
| [^80] | [Double Permutation Equivariance for Knowledge Graph Completion.](http://arxiv.org/abs/2302.01313) | 本研究提出了双排列等变性的KG表示方法，可以使神经网络在KG中执行复杂的逻辑推理任务，并在多个归纳KG完成任务中实现了最先进的Hits@10测试准确率。双排列等变性在KG中开辟了新的研究方向。 |
| [^81] | [Graph Neural Networks for temporal graphs: State of the art, open challenges, and opportunities.](http://arxiv.org/abs/2302.01018) | 该论文总结了时态图的图神经网络的现状、挑战和机遇，提供了学习设置和任务的严格规范化以及一个新的分类法，并讨论了该领域最相关的开放挑战，从研究和应用角度讨论。 |
| [^82] | [Enactive Artificial Intelligence: Subverting Gender Norms in Robot-Human Interaction.](http://arxiv.org/abs/2301.08741) | 本文提出了行动的人工智能(eAI)作为一个交叉、包容的AI立场，以应对AI设计中存在的性别规范。文章探讨了机器人与人类互动中如何颠覆性别规范，并提出了采用可解释性、公平性、透明度和可审计性的策略来开发包容性AI。 |
| [^83] | [Jointly Learning Consistent Causal Abstractions Over Multiple Interventional Distributions.](http://arxiv.org/abs/2301.05893) | 本文提出了一种基于Rischel（2020）提出的抽象形式化方法的SCMs因果抽象学习框架。我们通过提出的可微分编程方法解决了多个组合子问题，并在合成环境和与电动汽车电池制造相关的具有挑战性的真实问题上研究了其优势。 |
| [^84] | [RedMule: A Mixed-Precision Matrix-Matrix Operation Engine for Flexible and Energy-Efficient On-Chip Linear Algebra and TinyML Training Acceleration.](http://arxiv.org/abs/2301.03904) | 该论文介绍了一种名为RedMule的低功耗混合精度矩阵计算引擎，它支持多种精度和格式，用于解决近传感器训练的能耗问题。 |
| [^85] | [Current State of Community-Driven Radiological AI Deployment in Medical Imaging.](http://arxiv.org/abs/2212.14177) | 医学影像数据数量与复杂性的增长，引发了AI在医学影像领域的应用需求。尽管世界各地的研究实验室开发出多种AI模型，但很少有进入临床应用的。MONAI联盟旨在解决这种AI研究和应用之间的鸿沟，推动基于社区驱动的放射性AI的部署。 |
| [^86] | [Does GPT-3 Demonstrate Psychopathy? Evaluating Large Language Models from a Psychological Perspective.](http://arxiv.org/abs/2212.10529) | 本文从心理学角度评估大型语言模型的安全性，发现所有模型在短暗三合一测验上的得分都高于人类平均水平，存在相对较暗的人格模式。尽管经过指标微调，两种模型仍呈现隐含的黑暗人格模式。同时，本文观察到GPT-3和InstructGPT的幸福感得分持续增加。 |
| [^87] | [Are Code Pre-trained Models Powerful to Learn Code Syntax and Semantics?.](http://arxiv.org/abs/2212.10017) | 本文研究代码预训练模型的语法和语义分析，发现在AST和控制流图、数据依赖图及控制依赖图上进行相应的探测任务，能够更好地理解模型学到的程序语法和语义信息。 |
| [^88] | [On Event Individuation for Document-Level Information Extraction.](http://arxiv.org/abs/2212.09702) | 提出了问题──事件个体化对于模板填充任务是否适用，通过注释研究和误差分析，我们发现这引发了对模板填充度量的有效性、任务数据集的质量以及模型学习能力的担忧。 |
| [^89] | [Reasoning with Language Model Prompting: A Survey.](http://arxiv.org/abs/2212.09597) | 本文提供了使用语言模型提示进行推理的前沿研究综合调查。讨论了新兴推理能力出现的潜在原因，并提供系统资源帮助初学者。 |
| [^90] | [Large Language Models Meet NL2Code: A Survey.](http://arxiv.org/abs/2212.09420) | 本文综述了27个大型语言模型对于NL2Code的应用，总结出这些模型成功的三大关键因素：巨大的模型尺寸、高质量的数据和专家的调整。同时，本文还讨论了模型和人类之间的差距，并提供了一个用于追踪最新进展的网站。 |
| [^91] | [BKinD-3D: Self-Supervised 3D Keypoint Discovery from Multi-View Videos.](http://arxiv.org/abs/2212.07401) | BKinD-3D是一种新的无需2D或3D监督的自监督三维关键点发现方法，使用编码器-解码器架构和3D体积热力图对多个视图之间的时空差异进行重建，还使用了一个学习到的3D主体骨架的关节长度约束。 |
| [^92] | [Diffusion-SDF: Text-to-Shape via Voxelized Diffusion.](http://arxiv.org/abs/2212.03293) | 提出了一种新型生成式三维建模框架Diffusion-SDF，用于文本生成三维形状综合任务，采用SDF autoencoder和体素扩散模型学习和生成三维形状的体素化符号距离场（SDF）的表示形式，能够生成高度多样化的三维形状以符合给定的文本描述。 |
| [^93] | [Towards Robust Low-Resource Fine-Tuning with Multi-View Compressed Representations.](http://arxiv.org/abs/2211.08794) | 本文提出了一种利用多视角压缩表示降低预训练语言模型微调过程中过拟合问题的方法，经过测试在低资源NLP任务中表现良好。 |
| [^94] | [Hierarchical Dynamic Image Harmonization.](http://arxiv.org/abs/2211.08639) | 本文提出了一种分层动态网络（HDNet），以实现有效的图像协调。我们提出了本地动态（LD）模块和基于掩码的全局动态（MGD）模块，LD保留了详细的本地视觉一致性。在我们的实验中，HDNet在定量和定性评估上优于最先进的图像协调方法。 |
| [^95] | [Agent-State Construction with Auxiliary Inputs.](http://arxiv.org/abs/2211.07805) | 本文提出了一种基于信息瓶颈原理的方法，将辅助输入纳入到Agent-State构建过程中，以构建一个代理状态，总结与世界的先前交互，有效地解决了部分观测性问题。 |
| [^96] | [Knowledge Base Completion using Web-Based Question Answering and Multimodal Fusion.](http://arxiv.org/abs/2211.07098) | 本文提出了一种使用基于网络问答和多模态融合的方法填补知识库中的缺失信息。通过设计一个多模态特征和问题模板的基于网络问答的系统来达到更高效的知识库补全，同时结合了知识库中的结构化信息来提高抽取质量。 |
| [^97] | [Data Models for Dataset Drift Controls in Machine Learning With Optical Images.](http://arxiv.org/abs/2211.02578) | 该研究利用物理光学和传统机器学习的组合，获得明确且可微分的数据模型，以更好地理解数据漂移对机器学习模型性能的影响。 |
| [^98] | [Learning-Augmented Private Algorithms for Multiple Quantile Release.](http://arxiv.org/abs/2210.11222) | 本文提出一种新的隐私保护方法：使用学习增强算法框架，为多分位数发布任务提供可扩展的预测质量误差保证。 |
| [^99] | [Contact2Grasp: 3D Grasp Synthesis via Hand-Object Contact Constraint.](http://arxiv.org/abs/2210.09245) | 本论文提出了一种基于中间变量的接触约束方法，将映射分解为两个顺序阶段，以生成用于抓取的潜在接触地图，并学习接触地图到抓取姿势的映射，实现高效且高通用性的三维抓取合成。 |
| [^100] | [CLIP-PAE: Projection-Augmentation Embedding to Extract Relevant Features for a Disentangled, Interpretable, and Controllable Text-Guided Face Manipulation.](http://arxiv.org/abs/2210.03919) | 提出了一种为了解决文本引导图像操纵中的可分离性、可解释性和可控性问题，通过定义基于相关提示的语料库子空间来获取特定图像特征并引入CLIP投影增强嵌入（PAE）作为优化目标处理的新方法。 |
| [^101] | [Music-to-Text Synaesthesia: Generating Descriptive Text from Music Recordings.](http://arxiv.org/abs/2210.00434) | 本文提出了音乐文本视觉交感问题，收集了对齐的数据集，构建了一个计算模型来生成描述音乐录音内容的句子，并设计了群拓扑保持损失来解决高非判别性的古典音乐。 |
| [^102] | [Gradual Drift Detection in Process Models Using Conformance Metrics.](http://arxiv.org/abs/2207.11007) | 本文提出一种使用符合度量检测逐渐漂移的算法，相较于主流算法获得更好的结果。 |
| [^103] | [Composition of Relational Features with an Application to Explaining Black-Box Predictors.](http://arxiv.org/abs/2206.00738) | 本文提出了一种将关系特征视为函数，并使用通用函数组合的概念从简单函数推导出复杂函数的方法，将其应用于解释黑盒预测器的预测。 |
| [^104] | [Helpfulness and Fairness of Task-Oriented Dialogue Systems.](http://arxiv.org/abs/2205.12554) | 本文研究任务导向对话系统的帮助性和公平性。作者定义了对话系统的帮助性，使用分类器自动确定帮助性，并提出使用帮助级别来衡量对话系统的公平性。实验结果表明，现有系统更容易为来自发达国家概念的问题提供帮助。 |
| [^105] | [What Is Fairness? Philosophical Considerations and Implications For FairML.](http://arxiv.org/abs/2205.09622) | 本文探讨了公平性的哲学概念，提出了公平性和预测性能不是不可调和的对立面，并强调从数据收集到最终模型评估都需纳入伦理考虑。 |
| [^106] | [DPMS: An ADD-Based Symbolic Approach for Generalized MaxSAT Solving.](http://arxiv.org/abs/2205.03747) | 该研究提出了DPMS算法，一种基于ADD符号化方法的广义MaxSAT求解算法，可以处理非CNF混合约束的广义MaxSAT问题，并在实验中表现优秀。 |
| [^107] | [Multi-Label Classification of Thoracic Diseases using Dense Convolutional Network on Chest Radiographs.](http://arxiv.org/abs/2202.03583) | 本研究提出了一种基于密集卷积神经网络和GRADCAM的胸部X光疾病多标签诊断模型，获得了在Cardiomegaly条件下最高的AUC得分0.896，并使用热图提高了模型的可解释性。 |
| [^108] | [A Large and Diverse Arabic Corpus for Language Modeling.](http://arxiv.org/abs/2201.09227) | 该论文介绍了一个大规模的阿拉伯语语料库，旨在提高大规模语言模型的跨领域知识和推理能力。 |
| [^109] | [CausalSim: A Causal Framework for Unbiased Trace-Driven Simulation.](http://arxiv.org/abs/2201.01811) | CausalSim提出了一种因果框架，通过学习系统动态和潜在因素的因果模型，消除追踪数据中的偏差，解决了当前追踪驱动仿真器的缺陷。 |
| [^110] | [Reinforcement Learning, Bit by Bit.](http://arxiv.org/abs/2103.04047) | 该论文讨论了强化学习代理在实际环境中的数据效率问题，并提供了原则性指导和计算结果。 |
| [^111] | [Personalized Recommender System for Children's Book Recommendation with A Realtime Interactive Robot.](http://arxiv.org/abs/1710.00310) | 本文研究了儿童和机器人交互环境下的个性化图书推荐系统，在搜索算法、用户兴趣预测和同义词关联方面进行了创新，提高了性能，适用于嵌入式消费设备。 |

# 详细

[^1]: RATs-NAS：GCN上的相邻操作轨迹重定向用于神经结构搜索

    RATs-NAS: Redirection of Adjacent Trails on GCN for Neural Architecture Search. (arXiv:2305.04206v1 [cs.CV])

    [http://arxiv.org/abs/2305.04206](http://arxiv.org/abs/2305.04206)

    本论文提出了一种被称为RATs-NAS的神经结构搜索方法，通过在GCN上重定向相邻操作轨迹来快速搜索最佳神经网络架构，实验结果表明这种方法比其他最先进方法更有效。

    

    许多手工设计的卷积神经网络如VGG、ResNet、DenseNet等，在不同的任务上达到了最先进的水平。神经结构搜索（NAS）现在专注于自动找到最佳CNN架构来处理上述任务。然而，验证搜索架构非常耗时，使基于预测器的方法成为NAS的一个基本而重要的分支。建立预测器的两种常用技术是图卷积网络（GCN）和多层感知器（MLP）。本文考虑GCN和MLP在相邻操作轨迹上的差异，提出了Redirected Adjacent Trails NAS（RATs-NAS），以快速搜索所需的神经网络架构。RATs-NAS包括两个组件：Redirected Adjacent Trails GCN（RATs-GCN）和基于预测器的搜索空间抽样（P3S）模块。 RATs-GCN可以改变轨迹及其强度以搜索更好的神经网络架构，而P3S模块则对搜索空间进行抽样以提高预测架构的精度。实验结果表明，与其他最先进的方法相比，RATs-NAS可以更快地找到具有竞争力的神经网络架构。

    Various hand-designed CNN architectures have been developed, such as VGG, ResNet, DenseNet, etc., and achieve State-of-the-Art (SoTA) levels on different tasks. Neural Architecture Search (NAS) now focuses on automatically finding the best CNN architecture to handle the above tasks. However, the verification of a searched architecture is very time-consuming and makes predictor-based methods become an essential and important branch of NAS. Two commonly used techniques to build predictors are graph-convolution networks (GCN) and multilayer perceptron (MLP). In this paper, we consider the difference between GCN and MLP on adjacent operation trails and then propose the Redirected Adjacent Trails NAS (RATs-NAS) to quickly search for the desired neural network architecture. The RATs-NAS consists of two components: the Redirected Adjacent Trails GCN (RATs-GCN) and the Predictor-based Search Space Sampling (P3S) module. RATs-GCN can change trails and their strengths to search for a better neur
    
[^2]: 我们应该相信开放信息抽取提取的所有关系元组吗？对猜测检测的研究

    Shall We Trust All Relational Tuples by Open Information Extraction? A Study on Speculation Detection. (arXiv:2305.04181v1 [cs.CL])

    [http://arxiv.org/abs/2305.04181](http://arxiv.org/abs/2305.04181)

    本文研究了开放信息抽取中的猜测检测，提出了元组级别猜测检测的研究问题，并提出了名为OIE-Spec的基准模型。

    

    开放信息抽取（OIE）旨在从开放域句子中提取事实关系元组。下游任务使用提取的OIE元组作为事实，而不考虑这些事实的确定性。然而，不确定性/猜测是一种常见的语言现象。现有的猜测检测研究是在句子级别上定义的，但即使确定了一个句子是猜测的，也不是从其中提取的所有元组都是猜测的。在本文中，我们提出研究OIE中的猜测，并旨在确定提取的元组是否存在猜测。我们正式定义了元组级别猜测检测的研究问题，并对包含猜测元组标签的LSOIE数据集进行了详细的数据分析。最后，我们提出了一个名为OIE-Spec的基准模型用于这个新的研究任务。

    Open Information Extraction (OIE) aims to extract factual relational tuples from open-domain sentences. Downstream tasks use the extracted OIE tuples as facts, without examining the certainty of these facts. However, uncertainty/speculation is a common linguistic phenomenon. Existing studies on speculation detection are defined at sentence level, but even if a sentence is determined to be speculative, not all tuples extracted from it may be speculative. In this paper, we propose to study speculations in OIE and aim to determine whether an extracted tuple is speculative. We formally define the research problem of tuple-level speculation detection and conduct a detailed data analysis on the LSOIE dataset which contains labels for speculative tuples. Lastly, we propose a baseline model OIE-Spec for this new research task.
    
[^3]: 通过部分解耦强化学习和向量多样性，一小时内训练适用于实际世界的局部路径规划器。

    Train a Real-world Local Path Planner in One Hour via Partially Decoupled Reinforcement Learning and Vectorized Diversity. (arXiv:2305.04180v1 [cs.AI])

    [http://arxiv.org/abs/2305.04180](http://arxiv.org/abs/2305.04180)

    通过Color解决方案的Actor-Sharer-Learner（ASL）训练框架和面向移动机器人的模拟器Sparrow，使得在实际应用中训练局部路径规划器变得可行。

    

    深度强化学习已经在解决局部路径规划问题上显示出有效性。然而，由于DRL的效率和泛化能力不足，其在实际应用中受到了极大的限制。为了缓解这两个问题，提出了一种名为Color的解决方案，它由Actor-Sharer-Learner（ASL）训练框架和面向移动机器人的模拟器Sparrow组成。

    Deep Reinforcement Learning (DRL) has exhibited efficacy in resolving the Local Path Planning (LPP) problem. However, such application in the real world is immensely limited due to the deficient efficiency and generalization capability of DRL. To alleviate these two issues, a solution named Color is proposed, which consists of an Actor-Sharer-Learner (ASL) training framework and a mobile robot-oriented simulator Sparrow. Specifically, the ASL framework, intending to improve the efficiency of the DRL algorithm, employs a Vectorized Data Collection (VDC) mode to expedite data acquisition, decouples the data collection from model optimization by multithreading, and partially connects the two procedures by harnessing a Time Feedback Mechanism (TFM) to evade data underuse or overuse. Meanwhile, the Sparrow simulator utilizes a 2D grid-based world, simplified kinematics, and conversion-free data flow to achieve a lightweight design. The lightness facilitates vectorized diversity, allowing di
    
[^4]: MIReAD: 从科学文献中学习高质量表示的简单方法

    MIReAD: Simple Method for Learning High-quality Representations from Scientific Documents. (arXiv:2305.04177v1 [cs.CL])

    [http://arxiv.org/abs/2305.04177](http://arxiv.org/abs/2305.04177)

    MIReAD是通过微调变形金刚模型来预测期刊类别，从而学习科学论文高质量表示的简单方法，可用于论文检索和文献搜索。

    

    从科学文献中学习语义上有意义的表示可以促进学术文献搜索并提高推荐系统的性能。我们提出了MIReAD，一种简单的方法，通过微调变形金刚模型来预测基于摘要的目标期刊类别，从而学习科学论文的高质量表示。我们在超过2,000个期刊类别的500,000多个PubMed和arXiv摘要上对MIReAD进行训练。我们表明MIReAD产生的表示可用于类似论文检索、主题分类和文献搜索。我们提出的方法在四个评价标准下优于现有的六种科学文献表示学习模型。

    Learning semantically meaningful representations from scientific documents can facilitate academic literature search and improve performance of recommendation systems. Pre-trained language models have been shown to learn rich textual representations, yet they cannot provide powerful document-level representations for scientific articles. We propose MIReAD, a simple method that learns high-quality representations of scientific papers by fine-tuning transformer model to predict the target journal class based on the abstract. We train MIReAD on more than 500,000 PubMed and arXiv abstracts across over 2,000 journal classes. We show that MIReAD produces representations that can be used for similar papers retrieval, topic categorization and literature search. Our proposed approach outperforms six existing models for representation learning on scientific documents across four evaluation standards.
    
[^5]: X-LLM: 通过将多模态视为外语引入大型语言模型来启动高级大型语言模型

    X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages. (arXiv:2305.04160v1 [cs.CL])

    [http://arxiv.org/abs/2305.04160](http://arxiv.org/abs/2305.04160)

    本论文提出了一种名为X-LLM的方法，将多模态信息转换为外语并输入到大型语言模型中，从而赋予LLM多模态能力，对于LLM加入多模态信息的能力进行了探究和拓展。

    

    大型语言模型（LLM）展示了卓越的语言能力。基于高级LLM的GPT-4表现出超常的多模态能力，超越了以往的视觉语言模型。我们将这归功于与以前的多模态模型相比使用了更先进的LLM。但不幸的是，GPT-4的模型架构和训练策略是未知的。为了赋予LLM多模态能力，我们提出了X-LLM，通过使用X2L接口将多模态（图像、语音、视频）转换为外语并将其输入到大型语言模型（ChatGLM）中。具体而言，X-LLM使用X2L接口将多个冻结的单模态编码器和冻结的LLM对齐，其中“X”表示多模态，例如图像、语音和视频，“L”表示语言。X-LLM的训练由三个阶段组成：（1）转换多模态信息：第一阶段分别训练每个X2L接口与其各自的单模态编码器对齐，将多模态信息转换为外语输入到ChatGLM中。...

    Large language models (LLMs) have demonstrated remarkable language abilities. GPT-4, based on advanced LLMs, exhibits extraordinary multimodal capabilities beyond previous visual language models. We attribute this to the use of more advanced LLMs compared with previous multimodal models. Unfortunately, the model architecture and training strategies of GPT-4 are unknown. To endow LLMs with multimodal capabilities, we propose X-LLM, which converts Multi-modalities (images, speech, videos) into foreign languages using X2L interfaces and inputs them into a large Language model (ChatGLM). Specifically, X-LLM aligns multiple frozen single-modal encoders and a frozen LLM using X2L interfaces, where ``X'' denotes multi-modalities such as image, speech, and videos, and ``L'' denotes languages. X-LLM's training consists of three stages: (1) Converting Multimodal Information: The first stage trains each X2L interface to align with its respective single-modal encoder separately to convert multimod
    
[^6]: Score: Scone知识库系统的规则引擎

    Score: A Rule Engine for the Scone Knowledge Base System. (arXiv:2305.04154v1 [cs.AI])

    [http://arxiv.org/abs/2305.04154](http://arxiv.org/abs/2305.04154)

    Score是一个规则引擎，用于Scone知识库系统，它可以自动执行简单推理，从而提高基于Scone构建的计划系统的能力。

    

    我们介绍了Score，一种为Scone知识库系统设计和实现的规则引擎。 Scone是一种知识库系统，旨在以符号形式存储和操作一般知识的丰富表达式。 它以网络结构中的节点和链接的形式表示知识，并且可以有效地执行关于不同元素之间关系的基本推理。 我们在Scone系统中增加了一个基于制造生产规则的引擎，它可以自动根据Scone知识库中的现有和新添加的结构执行简单的推理。

    We present Score, a rule engine designed and implemented for the Scone knowledge base system. Scone is a knowledge base system designed for storing and manipulating rich representations of general knowledge in symbolic form. It represents knowledge in the form of nodes and links in a network structure, and it can perform basic inference about the relationships between different elements efficiently. On its own, Scone acts as a sort of "smart memory" that can interface with other software systems. One area of improvement for Scone is how useful it can be in supplying knowledge to an intelligent agent that can use the knowledge to perform actions and update the knowledge base with its observations.  We augment the Scone system with a production rule engine that automatically performs simple inference based on existing and newly-added structures in Scone's knowledge base, potentially improving the capabilities of any planning systems built on top of Scone. Production rule systems consist 
    
[^7]: 基于无线通信的通道驱动随机梯度 Langevin 动力学贝叶斯联邦平均

    Bayesian Over-the-Air FedAvg via Channel Driven Stochastic Gradient Langevin Dynamics. (arXiv:2305.04152v1 [cs.LG])

    [http://arxiv.org/abs/2305.04152](http://arxiv.org/abs/2305.04152)

    本文提出了无线 FALD 协议，可以在无噪声通信的情况下高效地在无线系统中实现分布式贝叶斯学习，实现了在通信回合之间多个本地更新以及由小批量计算的随机梯度，并进行了样本收敛分析。

    

    可扩展贝叶斯推理方法的近期发展已经重新引起了对采用贝叶斯学习作为传统频率学习的替代方法的兴趣，其通过不确定性量化提供了改进的模型校准。最近，引入了联邦平均 Langevin 动力学(FALD)作为联邦平均的变体，可以在没有噪声的通信存在下有效地实现分布式贝叶斯学习。在本文中，我们提出了无线 FALD(WFALD)，这是一种新颖的协议，通过集成基于空中计算和基于通道驱动的 Monte Carlo 更新来实现无线系统中的 FALD。与先前的无线贝叶斯学习相比，WFALD 可以实现(i) 在通信回合之间多个本地更新；并且(ii) 由小批量计算的随机梯度。以 2-Wasserstein 距离为衡量标准，给出了样本收敛分析。

    The recent development of scalable Bayesian inference methods has renewed interest in the adoption of Bayesian learning as an alternative to conventional frequentist learning that offers improved model calibration via uncertainty quantification. Recently, federated averaging Langevin dynamics (FALD) was introduced as a variant of federated averaging that can efficiently implement distributed Bayesian learning in the presence of noiseless communications. In this paper, we propose wireless FALD (WFALD), a novel protocol that realizes FALD in wireless systems by integrating over-the-air computation and channel-driven sampling for Monte Carlo updates. Unlike prior work on wireless Bayesian learning, WFALD enables (\emph{i}) multiple local updates between communication rounds; and (\emph{ii}) stochastic gradients computed by mini-batch. A convergence analysis is presented in terms of the 2-Wasserstein distance between the samples produced by WFALD and the targeted global posterior distribut
    
[^8]: 通过提示实现可控的混合主动对话生成

    Controllable Mixed-Initiative Dialogue Generation through Prompting. (arXiv:2305.04147v1 [cs.CL])

    [http://arxiv.org/abs/2305.04147](http://arxiv.org/abs/2305.04147)

    提出了一种新的生成方式，使用大型语言模型作为条件生成微调的替代方案，通过提示构造来实现可控的混合主动对话生成并获得了较好的性能表现。

    

    混合主动对话任务涉及重复交换信息和对话控制。会话代理通过生成响应来获得控制，这些响应按照策略规划器规定的特定对话意图或策略进行。标准方法是微调预训练的语言模型以执行基于这些意图的生成。然而，这些受监督的生成模型受数据注释成本和质量的限制。我们提出用大型语言模型作为条件生成微调的替代方案。我们为可控混合主动对话形式化提示构造。我们的研究表明，在PersuasionForGood和Emotional Support Conversations两个任务中，我们的方法在人类评估和自动指标方面均显示出比微调和真实响应更好的性能。

    Mixed-initiative dialogue tasks involve repeated exchanges of information and conversational control. Conversational agents gain control by generating responses that follow particular dialogue intents or strategies, prescribed by a policy planner. The standard approach has been fine-tuning pre-trained language models to perform generation conditioned on these intents. However, these supervised generation models are limited by the cost and quality of data annotation. We instead prompt large language models as a drop-in replacement to fine-tuning on conditional generation. We formalize prompt construction for controllable mixed-initiative dialogue. Our findings show improvements over fine-tuning and ground truth responses according to human evaluation and automatic metrics for two tasks: PersuasionForGood and Emotional Support Conversations.
    
[^9]: 人工神经心理学：大型语言模型是否正在发展执行功能？

    Artificial Neuropsychology: Are Large Language Models Developing Executive Functions?. (arXiv:2305.04134v1 [cs.AI])

    [http://arxiv.org/abs/2305.04134](http://arxiv.org/abs/2305.04134)

    本文探讨了大型语言模型是否在学习中开发类似于人类执行功能，并使用汉诺塔测试了GPT-2和GPT-3的规划和工作记忆，发现它们在有限和非人类的方式下展示了一些执行功能。

    

    人工智能（AI）正在迅速发展，并展示了其执行各种认知任务的能力，包括语言处理、视觉识别和决策。此进展的一部分归因于像GPT（生成式预训练变压器）系列那样的LLM（大型语言模型）。这些模型能够展示出被视为智能的行为。神经心理学中的大多数作者认为，智能行为取决于许多全面技能，或称执行功能（EFs），这些技能依赖于前额叶中神经网络的正确功能，并开发了一系列测试来评估它们。在这项工作中，我们提出了一个问题，即LLM是否正在开发类似于人类的执行功能作为学习的一部分，我们评估了GPT使用流行的汉诺塔方法的规划功能和工作记忆。此外，我们介绍了一种新的古典方法变体来更好地测试规划能力，并发现GPT-2和GPT-3在有限和非人类的方式下展示了一些EFs，如工作记忆和规划。

    Artificial Intelligence (AI) has been rapidly advancing and has demonstrated its ability to perform a wide range of cognitive tasks, including language processing, visual recognition, and decision-making. Part of this progress is due to LLMs (Large Language Models) like those of the GPT (Generative Pre-Trained Transformers) family. These models are capable of exhibiting behavior that can be perceived as intelligent. Most authors in Neuropsychology consider intelligent behavior to depend on a number of overarching skills, or Executive Functions (EFs), which rely on the correct functioning of neural networks in the frontal lobes, and have developed a series of tests to evaluate them. In this work, we raise the question of whether LLMs are developing executive functions similar to those of humans as part of their learning, and we evaluate the planning function and working memory of GPT using the popular Towers of Hanoi method. Additionally, we introduce a new variant of the classical meth
    
[^10]: 一种蛋白质结构生成的潜在扩散模型

    A Latent Diffusion Model for Protein Structure Generation. (arXiv:2305.04120v1 [q-bio.BM])

    [http://arxiv.org/abs/2305.04120](http://arxiv.org/abs/2305.04120)

    提出了一种潜在扩散模型，能够在压缩的潜在空间中灵活地捕获自然蛋白质结构的分布，有效地生成具有高设计能力和效率的新型蛋白质骨架结构。

    

    蛋白质是复杂的生物分子，能在生物体内执行多种关键功能。设计和生成新型蛋白质可为未来的合成生物学应用（包括药物发现）铺平道路。但由于蛋白质结构的大规模建模空间，这仍然是一个具有挑战性的计算任务。在本研究中，我们提出了一个潜在扩散模型，该模型能够减少蛋白质建模的复杂性，同时灵活地在压缩的潜在空间中捕获自然蛋白质结构的分布。具体而言，我们提出了一个等变蛋白自编码器，将蛋白质嵌入到潜在空间中，然后使用等变扩散模型来学习潜在蛋白质表示的分布。实验结果表明，我们的方法能够有效地生成具有高设计能力和效率的新型蛋白质骨架结构。

    Proteins are complex biomolecules that perform a variety of crucial functions within living organisms. Designing and generating novel proteins can pave the way for many future synthetic biology applications, including drug discovery. However, it remains a challenging computational task due to the large modeling space of protein structures. In this study, we propose a latent diffusion model that can reduce the complexity of protein modeling while flexibly capturing the distribution of natural protein structures in a condensed latent space. Specifically, we propose an equivariant protein autoencoder that embeds proteins into a latent space and then uses an equivariant diffusion model to learn the distribution of the latent protein representations. Experimental results demonstrate that our method can effectively generate novel protein backbone structures with high designability and efficiency.
    
[^11]: 离散扩散建模下的高效和度数引导图生成

    Efficient and Degree-Guided Graph Generation via Discrete Diffusion Modeling. (arXiv:2305.04111v1 [cs.LG])

    [http://arxiv.org/abs/2305.04111](http://arxiv.org/abs/2305.04111)

    本文提出了EDGE，一种新的离散扩散模型用于生成大型图，并通过删除边来鼓励图的稀疏性。EDGE在每个去噪步骤中仅关注图中一部分节点，并且可以明确地对图的节点度数进行建模。实验表明，EDGE比竞争方法更有效，并且可以生成具有数千个节点的大型图。

    

    基于扩散的生成图模型已被证明在生成高质量小图方面非常有效。然而，它们需要更可扩展性，以生成包含数千个节点的大图并满足图统计。本文提出了EDGE，一种新的基于扩散的生成图模型，用于生成大型图的生成任务。为了提高计算效率，我们通过在每个时间步长随机删除边来鼓励图的稀疏性，并最终获得一张空白图。EDGE仅在每个去噪步骤中关注图中一部分节点。它比以前的基于扩散的模型更少地进行边预测。此外，EDGE明确地允许对图的节点度数进行建模，进一步提高了模型的性能。实证研究表明，EDGE比竞争方法更有效，并且可以生成具有数千个节点的大型图。它还在生成质量方面优于基准模型。

    Diffusion-based generative graph models have been proven effective in generating high-quality small graphs. However, they need to be more scalable for generating large graphs containing thousands of nodes desiring graph statistics. In this work, we propose EDGE, a new diffusion-based generative graph model that addresses generative tasks with large graphs. To improve computation efficiency, we encourage graph sparsity by using a discrete diffusion process that randomly removes edges at each time step and finally obtains an empty graph. EDGE only focuses on a portion of nodes in the graph at each denoising step. It makes much fewer edge predictions than previous diffusion-based models. Moreover, EDGE admits explicitly modeling the node degrees of the graphs, further improving the model performance. The empirical study shows that EDGE is much more efficient than competing methods and can generate large graphs with thousands of nodes. It also outperforms baseline models in generation qual
    
[^12]: 利用语义关系优先处理增材制造系统中的威胁指标

    Leveraging Semantic Relationships to Prioritise Indicators of Compromise in Additive Manufacturing Systems. (arXiv:2305.04102v1 [cs.CR])

    [http://arxiv.org/abs/2305.04102](http://arxiv.org/abs/2305.04102)

    本文提出了一种基于语义关系的威胁优先级系统，可用于识别、提取和排名增材制造系统中的威胁指标。

    

    增材制造（AM）具有许多优点，例如快速、成本有效地制造复杂和定制设计、减少材料浪费以及实现按需生产。然而，AM也带来了若干安全挑战，吸引了从个人黑客到有组织犯罪团伙和国家级行为者的攻击者。本文提出了一种新的基于语义的威胁优先级系统，以识别、提取和排名威胁指标（IOC）来解决AM中的网络安全风险。该系统利用异构信息网络（HIN），从多源威胁文本自动提取高级IOC，并识别IOC之间的语义关系。它用包含不同元路径和元图的HIN来建模IOC，以描述不同IOC之间的语义关系。我们引入了一个领域特定的识别器，用于在三个领域中识别IOC：组织特定的、AM工艺和材料特定的、以及特定于数据输入的。

    Additive manufacturing (AM) offers numerous benefits, such as manufacturing complex and customised designs quickly and cost-effectively, reducing material waste, and enabling on-demand production. However, several security challenges are associated with AM, making it increasingly attractive to attackers ranging from individual hackers to organised criminal gangs and nation-state actors. This paper addresses the cyber risk in AM to attackers by proposing a novel semantic-based threat prioritisation system for identifying, extracting and ranking indicators of compromise (IOC). The system leverages the heterogeneous information networks (HINs) that automatically extract high-level IOCs from multi-source threat text and identifies semantic relations among the IOCs. It models IOCs with a HIN comprising different meta-paths and meta-graphs to depict semantic relations among diverse IOCs. We introduce a domain-specific recogniser that identifies IOCs in three domains: organisation-specific, r
    
[^13]: 基于密钥锁模块的联邦学习梯度泄露防御

    Gradient Leakage Defense with Key-Lock Module for Federated Learning. (arXiv:2305.04095v1 [cs.LG])

    [http://arxiv.org/abs/2305.04095](http://arxiv.org/abs/2305.04095)

    本研究提出了一种新的联邦学习梯度泄露防御技术，使用私钥锁模块保护任意模型体系结构，并可确保无法从共享的梯度中重建私有训练数据。

    

    联邦学习是一种广泛采用的隐私保护机器学习方法，其中私有数据保持本地，允许安全计算和本地模型梯度与第三方参数服务器之间的交换。然而，最近的研究发现，通过共享的梯度可能会危及隐私并恢复敏感信息。本研究提供了详细的分析和对梯度泄漏问题的新视角。这些理论工作导致了一种新的梯度泄露防御技术，使用私钥锁模块保护任意模型体系结构。只有锁定的梯度被传输到参数服务器进行全局模型聚合。我们提出的学习方法对梯度泄露攻击具有抵抗力，并且所设计和训练的密钥锁模块可以确保，没有密钥锁模块的私有信息：a) 无法从共享的梯度中重建私有训练数据。

    Federated Learning (FL) is a widely adopted privacy-preserving machine learning approach where private data remains local, enabling secure computations and the exchange of local model gradients between local clients and third-party parameter servers. However, recent findings reveal that privacy may be compromised and sensitive information potentially recovered from shared gradients. In this study, we offer detailed analysis and a novel perspective on understanding the gradient leakage problem. These theoretical works lead to a new gradient leakage defense technique that secures arbitrary model architectures using a private key-lock module. Only the locked gradient is transmitted to the parameter server for global model aggregation. Our proposed learning method is resistant to gradient leakage attacks, and the key-lock module is designed and trained to ensure that, without the private information of the key-lock module: a) reconstructing private training data from the shared gradient is
    
[^14]: SANTA：Distantly-Supervised Named Entity Recognition中处理错误和不完整标注噪声的分离策略

    SANTA: Separate Strategies for Inaccurate and Incomplete Annotation Noise in Distantly-Supervised Named Entity Recognition. (arXiv:2305.04076v1 [cs.CL])

    [http://arxiv.org/abs/2305.04076](http://arxiv.org/abs/2305.04076)

    本文提出了一种处理Distantly-Supervised Named Entity Recognition中错误和不完整标注噪声的分离策略，使用不同的模型构建来应对两种类型的噪声。

    

    远程监督命名实体识别有效地减轻了监督设置中耗时且昂贵的注释负担，但是无上下文的匹配过程和知识库的有限覆盖引入了不准确和不完整的标注噪音。本研究提出了使用不同的策略来处理两种类型的噪声的SANTA，以解决由不准确和不完整标注带来的挑战。

    Distantly-Supervised Named Entity Recognition effectively alleviates the burden of time-consuming and expensive annotation in the supervised setting. But the context-free matching process and the limited coverage of knowledge bases introduce inaccurate and incomplete annotation noise respectively. Previous studies either considered only incomplete annotation noise or indiscriminately handle two types of noise with the same strategy. In this paper, we argue that the different causes of two types of noise bring up the requirement of different strategies in model architecture. Therefore, we propose the SANTA to handle these two types of noise separately with (1) Memory-smoothed Focal Loss and Entity-aware KNN to relieve the entity ambiguity problem caused by inaccurate annotation, and (2) Boundary Mixup to alleviate decision boundary shifting problem caused by incomplete annotation and a noise-tolerant loss to improve the robustness. Benefiting from our separate tailored strategies, we co
    
[^15]: 用轨迹解释强化学习的决策

    Explaining RL Decisions with Trajectories. (arXiv:2305.04073v1 [cs.AI])

    [http://arxiv.org/abs/2305.04073](http://arxiv.org/abs/2305.04073)

    本文提出一种用训练过程中遇到的轨迹解释强化学习决策的方法，并在离散和连续状态及行动空间的多样化环境中证明了其有效性。

    

    解释是强化学习在许多实际决策问题中应用的关键组成部分。本文提出了一种补充这些解释的方法，特别是针对离线强化学习，即我们将训练过程中遇到的轨迹用编码的方式进行解释。

    Explanation is a key component for the adoption of reinforcement learning (RL) in many real-world decision-making problems. In the literature, the explanation is often provided by saliency attribution to the features of the RL agent's state. In this work, we propose a complementary approach to these explanations, particularly for offline RL, where we attribute the policy decisions of a trained RL agent to the trajectories encountered by it during training. To do so, we encode trajectories in offline training data individually as well as collectively (encoding a set of trajectories). We then attribute policy decisions to a set of trajectories in this encoded space by estimating the sensitivity of the decision with respect to that set. Further, we demonstrate the effectiveness of the proposed approach in terms of quality of attributions as well as practical scalability in diverse environments that involve both discrete and continuous state and action spaces such as grid-worlds, video gam
    
[^16]: 基于区块链的可靠大规模模型推理和训练平台

    A Blockchain-based Platform for Reliable Inference and Training of Large-Scale Models. (arXiv:2305.04062v1 [cs.DC])

    [http://arxiv.org/abs/2305.04062](http://arxiv.org/abs/2305.04062)

    BRAIN是一个可靠的基于区块链的AI平台，能够确保大规模模型的可信推理和训练，通过独特的两阶段交易机制实现实时处理。

    

    随着人工智能在各个领域的普及，AI驱动的推理和训练过程中涉及可信度和透明度的问题引起关注，特别是涉及潜在偏差和可追溯性挑战的问题。虽然提出了区块链等分散化解决方案来解决这些问题，但它们在处理大规模模型时常常遇到挑战，导致推理耗时，训练验证低效。为了克服这些限制，我们介绍了BRAIN（基于区块链的可靠AI网络），这是一个特别设计的新平台，旨在确保大模型的可靠推理和训练。BRAIN利用独特的两阶段交易机制，通过分离请求和响应交易，允许实时处理通过流水线。每个随机选择的推理委员会都会提交并公布推理结果，在通过智能合约达成一致意见后，才会执行所请求的操作。

    As artificial intelligence (AI) continues to permeate various domains, concerns surrounding trust and transparency in AI-driven inference and training processes have emerged, particularly with respect to potential biases and traceability challenges. Decentralized solutions such as blockchain have been proposed to tackle these issues, but they often struggle when dealing with large-scale models, leading to time-consuming inference and inefficient training verification. To overcome these limitations, we introduce BRAIN, a Blockchain-based Reliable AI Network, a novel platform specifically designed to ensure reliable inference and training of large models. BRAIN harnesses a unique two-phase transaction mechanism, allowing real-time processing via pipelining by separating request and response transactions. Each randomly-selected inference committee commits and reveals the inference results, and upon reaching an agreement through a smart contract, then the requested operation is executed us
    
[^17]: 科技本体论：新兴主题的分类学

    Science and Technology Ontology: A Taxonomy of Emerging Topics. (arXiv:2305.04055v1 [cs.DL])

    [http://arxiv.org/abs/2305.04055](http://arxiv.org/abs/2305.04055)

    本文提出了一个自动的科学技术本体，涵盖了科学技术领域的不传统主题，促进了不同领域和学科间的合作，实现了科学技术中的数据驱动研究。

    

    本体论在语义网络技术中发挥着至关重要的作用，提供了一种结构化和标准化的知识表示方式，使机器能够理解数据的含义。已经制定了几个分类学和本体，但个人只针对一个领域，其中一些在时间和手动工作方面显得昂贵。同时，它们需要更多涵盖非传统主题的内容，以呈现更全面和全面的知识格局和跨学科合作。因此，需要有一个覆盖科学和技术领域的本体，通过连接可能相关或具有共同点的不同领域和领域的主题，便于跨学科研究。为了解决这些问题，我们提出了一种自动科学技术本体（S＆TO），涵盖了不同科学技术领域的非传统主题。所提出的S＆TO可以促进发现新的研究领域和学科间的合作，并在科学技术中实现数据驱动的研究。

    Ontologies play a critical role in Semantic Web technologies by providing a structured and standardized way to represent knowledge and enabling machines to understand the meaning of data. Several taxonomies and ontologies have been generated, but individuals target one domain, and only some of those have been found expensive in time and manual effort. Also, they need more coverage of unconventional topics representing a more holistic and comprehensive view of the knowledge landscape and interdisciplinary collaborations. Thus, there needs to be an ontology covering Science and Technology and facilitate multidisciplinary research by connecting topics from different fields and domains that may be related or have commonalities. To address these issues, we present an automatic Science and Technology Ontology (S&TO) that covers unconventional topics in different science and technology domains. The proposed S&TO can promote the discovery of new research areas and collaborations across discipl
    
[^18]: Echoes: 基于伪偏差标记的模仿式回声室无监督去偏

    Echoes: Unsupervised Debiasing via Pseudo-bias Labeling in an Echo Chamber. (arXiv:2305.04043v1 [cs.LG])

    [http://arxiv.org/abs/2305.04043](http://arxiv.org/abs/2305.04043)

    Echoes提出了一种无监督的去偏方法，生成偏差对立样本的伪偏差标签，实现了对数据集中偏差特征的一致性处理，并取得了各项任务和数据集上的最先进性能。

    

    当神经网络暴露于有偏训练数据时，通常会学习到不正确的相关性，从而导致在拓展领域数据上表现不佳。本文提出一种名为“Echoes”的简单高效方法，它生成偏差对立样本的伪偏差标签，以强制使伪标签与数据集中的偏差特征一致，并用于去偏。我们的实证研究表明，Echoes实现了各项任务和数据集上的最先进性能，同时使用比以前的方法更少的计算资源。

    Neural networks often learn spurious correlations when exposed to biased training data, leading to poor performance on out-of-distribution data. A biased dataset can be divided, according to biased features, into bias-aligned samples (i.e., with biased features) and bias-conflicting samples (i.e., without biased features). Recent debiasing works typically assume that no bias label is available during the training phase, as obtaining such information is challenging and labor-intensive. Following this unsupervised assumption, existing methods usually train two models: a biased model specialized to learn biased features and a target model that uses information from the biased model for debiasing. This paper first presents experimental analyses revealing that the existing biased models overfit to bias-conflicting samples in the training data, which negatively impacts the debiasing performance of the target models. To address this issue, we propose a straightforward and effective method cal
    
[^19]: 通过自我优化来提升LLMs的响应质量

    Refining the Responses of LLMs by Themselves. (arXiv:2305.04039v1 [cs.CL])

    [http://arxiv.org/abs/2305.04039](http://arxiv.org/abs/2305.04039)

    本文提出了一种利用自我优化机制来改善大型语言模型响应质量的方法，实验证明在GPT-3.5模型上使用此方法，生成的结果质量可以与甚至超过GPT-4模型。

    

    本文提出了一种基于提示工程的简单而高效的方法，利用大型语言模型本身来优化其答案，而不依赖于辅助模型。我们引入了一种迭代的自我评估优化机制，随着迭代的推进，具有改善输出质量的潜力，无需手动干预。实验结果表明，在GPT-3.5模型上使用我们的响应优化框架产生的结果与甚至超过先进的GPT-4模型生成的结果。提供了详细的实施策略和说明性示例，以证明我们提出的解决方案的优越性。

    In this paper, we propose a simple yet efficient approach based on prompt engineering that leverages the large language model itself to optimize its answers without relying on auxiliary models. We introduce an iterative self-evaluating optimization mechanism, with the potential for improved output quality as iterations progress, removing the need for manual intervention. The experiment's findings indicate that utilizing our response refinement framework on the GPT-3.5 model yields results that are on par with, or even surpass, those generated by the cutting-edge GPT-4 model. Detailed implementation strategies and illustrative examples are provided to demonstrate the superiority of our proposed solution.
    
[^20]: Wasserstein-Fisher-Rao嵌入：具有本地比较和全局传输的逻辑查询嵌入

    Wasserstein-Fisher-Rao Embedding: Logical Query Embeddings with Local Comparison and Global Transport. (arXiv:2305.04034v1 [cs.AI])

    [http://arxiv.org/abs/2305.04034](http://arxiv.org/abs/2305.04034)

    本文提出了一种新的查询嵌入方法，使用Wasserstein-Fisher-Rao度量来加权考虑嵌入之间的本地（局部）与全局（整体）特征，同时提出了一种卷积算法来进行线性时间计算，并使用块对角核来进行权衡。在标准数据集上表现出优异的效果。

    

    在知识图谱上回答复杂查询很重要，但由于数据不完整性，它尤其具有挑战性。查询嵌入方法通过基于学习的模型和使用集合运算符模拟逻辑推理来解决这个问题。以往的工作集中于特定形式的嵌入，但嵌入之间的评分函数却鲜有研究。与现有的基于本地比较或全局传输的评分函数不同，本文使用不平衡最优传输理论来研究本地和全局的权衡。具体而言，我们将集合嵌入到带有Wasserstein-Fisher-Rao度量的有界测度空间上，并使用这样的度量来设计评分函数。这种设计还促进了嵌入空间内的封闭形式集合运算符。此外，我们介绍了一种基于卷积的线性计算算法和一个块对角核以实现权衡。结果表明，WFRE可以在标准数据集上优于现有的查询嵌入方法。

    Answering complex queries on knowledge graphs is important but particularly challenging because of the data incompleteness. Query embedding methods address this issue by learning-based models and simulating logical reasoning with set operators. Previous works focus on specific forms of embeddings, but scoring functions between embeddings are underexplored. In contrast to existing scoring functions motivated by local comparison or global transport, this work investigates the local and global trade-off with unbalanced optimal transport theory. Specifically, we embed sets as bounded measures in $\real$ endowed with a scoring function motivated by the Wasserstein-Fisher-Rao metric. Such a design also facilitates closed-form set operators in the embedding space. Moreover, we introduce a convolution-based algorithm for linear time computation and a block-diagonal kernel to enforce the trade-off. Results show that WFRE can outperform existing query embedding methods on standard datasets, eval
    
[^21]: 面向机器人超声引导程序的技能迁移学习的简单框架

    Towards a Simple Framework of Skill Transfer Learning for Robotic Ultrasound-guidance Procedures. (arXiv:2305.04004v1 [cs.RO])

    [http://arxiv.org/abs/2305.04004](http://arxiv.org/abs/2305.04004)

    本文提出了一个简单的技能迁移学习框架，用于机器人超声引导程序。实验结果表明，经验丰富的临床医生在程序上比非临床医生表现更好。

    

    本文提出了一个简单的技能迁移学习框架，用于机器人超声引导程序。我们简要回顾了机器人超声引导程序技能迁移学习的挑战，然后确定了适当的采样技术和计算效率高的神经网络模型的必要性，从而提出了一个用于机器人超声引导程序实时应用的简单技能迁移学习框架。我们通过两个参与者（一个经验丰富的临床医生和一个非临床医生）在胎儿模型上寻找四腔心视图的最佳扫描平面的试验，分析了超声图像帧、纹理图像特征的时间序列和四元数，并发现经验丰富的临床医生比非临床医生的动作更加迅速和平滑。对于未来的工作，我们指出了剪枝和量化神经网络的必要性。

    In this paper, we present a simple framework of skill transfer learning for robotic ultrasound-guidance procedures. We briefly review challenges in skill transfer learning for robotic ultrasound-guidance procedures. We then identify the need of appropriate sampling techniques, computationally efficient neural networks models that lead to the proposal of a simple framework of skill transfer learning for real-time applications in robotic ultrasound-guidance procedures. We present pilot experiments from two participants (one experienced clinician and one non-clinician) looking for an optimal scanning plane of the four-chamber cardiac view from a fetal phantom. We analysed ultrasound image frames, time series of texture image features and quaternions and found that the experienced clinician performed the procedure in a quicker and smoother way compared to lengthy and non-constant movements from non-clinicians. For future work, we pointed out the need of pruned and quantised neural network 
    
[^22]: ANTONIO:面向NLP验证的系统化基准生成方法

    ANTONIO: Towards a Systematic Method of Generating NLP Benchmarks for Verification. (arXiv:2305.04003v1 [cs.CL])

    [http://arxiv.org/abs/2305.04003](http://arxiv.org/abs/2305.04003)

    本文介绍了一种名为ANTONIO的Python库，它基于抽象解释方法提供了一种实用的方法和启发式规则，以便为自然语言处理（NLP）数据集和模型生成已知验证方法的基准。因为其普遍适用性，这项工作将为将NLP验证问题纳入神经网络验证比赛开辟新的可能性，并在NLP问题中普及这一方向。

    

    自然语言处理（NLP）中使用的机器学习模型的验证被认为是一个难题。现有的神经网络验证方法常用于计算机视觉和其他数字数据集，但并不适用于NLP。本研究探讨了造成这一问题的技术原因，并在此基础上提出了实用的方法和启发式规则，以便将NLP数据集和模型准备为适合基于抽象解释的已知验证方法。我们将这些方法实现为一个名为ANTONIO的Python库，该库连接到神经网络验证器ERAN和Marabou。我们使用一个名为R-U-A-Robot的NLP数据集对工具进行了评估，该数据集被提议作为验证具有法律重要性的NLP应用的基准。我们希望，由于其普遍适用性，这项工作将为将NLP验证问题纳入神经网络验证比赛开辟新的可能性，并在NLP问题中普及这一方向。

    Verification of machine learning models used in Natural Language Processing (NLP) is known to be a hard problem. In particular, many known neural network verification methods that work for computer vision and other numeric datasets do not work for NLP. Here, we study technical reasons that underlie this problem. Based on this analysis, we propose practical methods and heuristics for preparing NLP datasets and models in a way that renders them amenable to known verification methods based on abstract interpretation. We implement these methods as a Python library called ANTONIO that links to the neural network verifiers ERAN and Marabou. We perform evaluation of the tool using an NLP dataset R-U-A-Robot suggested as a benchmark for verifying legally critical NLP applications. We hope that, thanks to its general applicability, this work will open novel possibilities for including NLP verification problems into neural network verification competitions, and will popularise NLP problems withi
    
[^23]: AADiff: 基于文本到图像扩散的音频对齐视频合成

    AADiff: Audio-Aligned Video Synthesis with Text-to-Image Diffusion. (arXiv:2305.04001v1 [cs.CV])

    [http://arxiv.org/abs/2305.04001](http://arxiv.org/abs/2305.04001)

    本文提出了一种新颖的文本到视频合成框架AADiff，它使用音频信号控制时间动态，通过音频对齐生成视频。本文的方法通过音频区域编辑和信号平滑，在时间灵活性和一致性之间取得良好的平衡。该方法的有效性已通过实验验证，并可用于内容创建。

    

    最近扩散模型的进展在文本到视频（T2V）合成任务中展示了有前途的结果。然而，由于这些T2V模型仅使用文本作为引导，它们往往在建模详细的时间动态方面遇到困难。本文介绍了一种新颖的T2V框架，该框架另外使用音频信号来控制时间动态，使得一个现成的T2I扩散模型可以生成音频对齐的视频。我们提出基于音频的区域编辑和信号平滑来在视频合成的两个相互矛盾的愿望，即时间灵活性和一致性之间取得良好的平衡。我们通过实验来经验证明了我们方法的有效性，并进一步展示了内容创建的实际应用。

    Recent advances in diffusion models have showcased promising results in the text-to-video (T2V) synthesis task. However, as these T2V models solely employ text as the guidance, they tend to struggle in modeling detailed temporal dynamics. In this paper, we introduce a novel T2V framework that additionally employ audio signals to control the temporal dynamics, empowering an off-the-shelf T2I diffusion to generate audio-aligned videos. We propose audio-based regional editing and signal smoothing to strike a good balance between the two contradicting desiderata of video synthesis, i.e., temporal flexibility and coherence. We empirically demonstrate the effectiveness of our method through experiments, and further present practical applications for contents creation.
    
[^24]: 通过离线模仿学习与监督正则化复制人类复杂的对话策略

    Replicating Complex Dialogue Policy of Humans via Offline Imitation Learning with Supervised Regularization. (arXiv:2305.03987v1 [cs.CL])

    [http://arxiv.org/abs/2305.03987](http://arxiv.org/abs/2305.03987)

    本文提出了一个离线模仿学习模型，通过监督正则化来解决协变量漂移问题，该模型能够复制人类复杂的对话策略，并在基准数据集上获得了最新的结果。

    

    本文提出了一个离线模仿学习模型，通过监督正则化来解决协变量漂移问题，从而学习真实对话数据集中的策略。这个模型不需要用户模拟器，并在基准数据集上获得了与现有方法相比的最新结果。

    Policy learning (PL) is a module of a task-oriented dialogue system that trains an agent to make actions in each dialogue turn. Imitating human action is a fundamental problem of PL. However, both supervised learning (SL) and reinforcement learning (RL) frameworks cannot imitate humans well. Training RL models require online interactions with user simulators, while simulating complex human policy is hard. Performances of SL-based models are restricted because of the covariate shift problem. Specifically, a dialogue is a sequential decision-making process where slight differences in current utterances and actions will cause significant differences in subsequent utterances. Therefore, the generalize ability of SL models is restricted because statistical characteristics of training and testing dialogue data gradually become different. This study proposed an offline imitation learning model that learns policy from real dialogue datasets and does not require user simulators. It also utilize
    
[^25]: 超越模型：Android应用中针对深度学习模型的数据预处理攻击

    Beyond the Model: Data Pre-processing Attack to Deep Learning Models in Android Apps. (arXiv:2305.03963v1 [cs.CR])

    [http://arxiv.org/abs/2305.03963](http://arxiv.org/abs/2305.03963)

    本论文针对深度学习模型安全问题提出了基于数据处理的攻击方法，通过攻击可以影响模型性能和延迟，而不影响模型本身。

    

    近年来，深度学习模型和智能手机低延迟和节省带宽等优点推动了智能移动应用的发展，也称为传统应用，但这种技术进展也引发了许多安全问题，包括对抗性示例、模型窃取和数据污染问题。现有攻击和针对设备上深度学习模型的对策，主要集中在模型本身，而很少关注数据处理对模型推理的影响。这种知识差距凸显了需要进一步研究，以全面理解和解决与设备上的模型相关的安全问题。本论文介绍了一种基于数据处理的攻击方法，针对实际应用中的深度学习应用进行攻击。我们的攻击能够影响模型的性能和延迟，而不会影响。

    The increasing popularity of deep learning (DL) models and the advantages of computing, including low latency and bandwidth savings on smartphones, have led to the emergence of intelligent mobile applications, also known as DL apps, in recent years. However, this technological development has also given rise to several security concerns, including adversarial examples, model stealing, and data poisoning issues. Existing works on attacks and countermeasures for on-device DL models have primarily focused on the models themselves. However, scant attention has been paid to the impact of data processing disturbance on the model inference. This knowledge disparity highlights the need for additional research to fully comprehend and address security issues related to data processing for on-device models. In this paper, we introduce a data processing-based attacks against real-world DL apps. In particular, our attack could influence the performance and latency of the model without affecting the
    
[^26]: 学习动作嵌入以进行离线评估

    Learning Action Embeddings for Off-Policy Evaluation. (arXiv:2305.03954v1 [cs.LG])

    [http://arxiv.org/abs/2305.03954](http://arxiv.org/abs/2305.03954)

    本论文探讨了从记录数据中学习动作嵌入，以减少在大型动作空间中反向倾向评分（IPS）估计器的方差，同时提高离线评估的准确性。

    

    离线评估（OPE）方法使我们能够使用由不同策略收集的记录数据来计算策略的预期奖励。 OPE是运行昂贵的在线A / B测试的可行选择：它可以加快新策略的开发，并降低向客户暴露次优治疗的风险。然而，当动作数量很大或记录策略未充分探索某些操作时，基于反向倾向评分（IPS）的现有估计器可能具有高甚至无限方差。Saito和Joachims提出使用动作嵌入的边际IPS（MIPS），从而在大型动作空间中降低IPS的方差。 MIPS假设从业者可以定义良好的动作嵌入，但在许多实际应用中很难做到这一点。在这项工作中，我们探讨从记录数据中学习动作嵌入。特别地，我们使用已经训练好的奖励模型的中间输出来定义动作嵌入，然后将其用于MIPS估计器中。

    Off-policy evaluation (OPE) methods allow us to compute the expected reward of a policy by using the logged data collected by a different policy. OPE is a viable alternative to running expensive online A/B tests: it can speed up the development of new policies, and reduces the risk of exposing customers to suboptimal treatments. However, when the number of actions is large, or certain actions are under-explored by the logging policy, existing estimators based on inverse-propensity scoring (IPS) can have a high or even infinite variance. Saito and Joachims (arXiv:2202.06317v2 [cs.LG]) propose marginalized IPS (MIPS) that uses action embeddings instead, which reduces the variance of IPS in large action spaces. MIPS assumes that good action embeddings can be defined by the practitioner, which is difficult to do in many real-world applications. In this work, we explore learning action embeddings from logged data. In particular, we use intermediate outputs of a trained reward model to defin
    
[^27]: 学习6D非抓取式操作的混合演员-评论员地图

    Learning Hybrid Actor-Critic Maps for 6D Non-Prehensile Manipulation. (arXiv:2305.03942v1 [cs.RO])

    [http://arxiv.org/abs/2305.03942](http://arxiv.org/abs/2305.03942)

    论文介绍了一种名为HACMan的强化学习方法，用于使用点云观察进行6D非抓取式操作的物体操纵。HACMan重点关注物体中心动作表示，它包括从物体点云中选择接触位置和一组描述机器人在接触后如何移动的运动参数。在实际测试中，HACMan的表现明显优于现有基线方法。

    

    在人类的灵巧性中，非抓取式操作是操作物体的重要组成部分。非抓取式操纵可以使与物体的交互更加复杂，但也在推理交互方面提出了挑战。在本文中，我们引入了一个名为HACMan的混合演员评论员地图，这是一种使用点云观察的6D非抓取式物体操作的强化学习方法。HACMan提出了一种时间抽象和空间基础的物体中心动作表示，该表示包括从物体点云中选择接触位置和一组描述机器人在接触后如何移动的运动参数。我们修改了一个现有的离线策略RL算法，以在这种混合的离散-连续动作表示学习。我们在仿真和现实世界中对HACMan进行了6D物体姿态对齐任务的评估。在最难的任务版本中，通过随机初始化物体和机器人配置，HACMan的表现优于现有的基线方法。

    Manipulating objects without grasping them is an essential component of human dexterity, referred to as non-prehensile manipulation. Non-prehensile manipulation may enable more complex interactions with the objects, but also presents challenges in reasoning about the interactions. In this work, we introduce Hybrid Actor-Critic Maps for Manipulation (HACMan), a reinforcement learning approach for 6D non-prehensile manipulation of objects using point cloud observations. HACMan proposes a temporally-abstracted and spatially-grounded object-centric action representation that consists of selecting a contact location from the object point cloud and a set of motion parameters describing how the robot will move after making contact. We modify an existing off-policy RL algorithm to learn in this hybrid discrete-continuous action representation. We evaluate HACMan on a 6D object pose alignment task in both simulation and in the real world. On the hardest version of our task, with randomized init
    
[^28]: 基于残差重参数化的Prompt Tuning改进方法

    Residual Prompt Tuning: Improving Prompt Tuning with Residual Reparameterization. (arXiv:2305.03937v1 [cs.CL])

    [http://arxiv.org/abs/2305.03937](http://arxiv.org/abs/2305.03937)

    本文提出了一种基于残差重参数化的Prompt Tuning改进方法-Residual Prompt Tuning，能够显著提高调优的性能和稳定性，在超过Prompt Tuning 7个点，且可以缩短Prompt长度10倍而不影响性能，同时对于学习率和Prompt初始化的选择具有鲁棒性。

    

    Prompt Tuning是目前增强预训练语言模型参数效率的一种成功方法。尽管其参数效率最高（调整的soft prompts不到总参数的0.1%），但它通常表现比其他效率高的调优方法更差，并且对超参数非常敏感。本文提出了一种简单高效的Residual Prompt Tuning方法，可显著改善Prompt Tuning的性能和稳定性。我们提出使用带有残差连接的浅层网络对软Prompt的重参数化嵌入。我们的实验表明，在SuperGLUE基准测试中，Residual Prompt Tuning明显优于Prompt Tuning。值得注意的是，我们的方法与T5-Base相比，在不影响性能的情况下将Prompt长度缩短了10倍，且对于学习率和Prompt初始化的选择具有鲁棒性，并且在少样本学习方面也非常有效。

    Prompt tuning is one of the successful approaches for parameter-efficient tuning of pre-trained language models. Despite being arguably the most parameter-efficient (tuned soft prompts constitute <0.1% of total parameters), it typically performs worse than other efficient tuning methods and is quite sensitive to hyper-parameters. In this work, we introduce Residual Prompt Tuning - a simple and efficient method that significantly improves the performance and stability of prompt tuning. We propose to reparameterize soft prompt embeddings using a shallow network with a residual connection. Our experiments show that Residual Prompt Tuning significantly outperforms prompt tuning on SuperGLUE benchmark. Notably, our method reaches +7 points improvement over prompt tuning with T5-Base and allows to reduce the prompt length by 10x without hurting performance. In addition, we show that our approach is robust to the choice of learning rate and prompt initialization, and is effective in few-shot 
    
[^29]: AI与区块链隐私保护整合研究综述

    An Overview of AI and Blockchain Integration for Privacy-Preserving. (arXiv:2305.03928v1 [cs.CR])

    [http://arxiv.org/abs/2305.03928](http://arxiv.org/abs/2305.03928)

    本文综述了AI与区块链整合的隐私保护技术，从数据加密、去标识化、多级分布式账本和k-匿名方法等特定应用场景入手，分析了AI-区块链-隐私保护系统的五个关键方面，最终提出了相应的技术建议和总结。

    

    随着人工智能和区块链技术的广泛关注和应用，由其整合产生的隐私保护技术具有显著的意义。这些技术不仅保护个人隐私，还保证数据的安全性和可靠性。本文首先概述了人工智能和区块链，并概括了它们相结合所产生的隐私保护技术。接着探讨了数据加密、去标识化、多级分布式账本和k-匿名方法等特定应用场景。此外，文章评估了AI-区块链-隐私保护系统的五个关键方面，包括授权管理、访问控制、数据保护、网络安全和可扩展性。此外，它还分析了缺陷及其实际原因，并提出了相应的建议。本研究还基于各方面对隐私保护技术进行分类和总结。

    With the widespread attention and application of artificial intelligence (AI) and blockchain technologies, privacy protection techniques arising from their integration are of notable significance. In addition to protecting privacy of individuals, these techniques also guarantee security and dependability of data. This paper initially presents an overview of AI and blockchain, summarizing their combination along with derived privacy protection technologies. It then explores specific application scenarios in data encryption, de-identification, multi-tier distributed ledgers, and k-anonymity methods. Moreover, the paper evaluates five critical aspects of AI-blockchain-integration privacy protection systems, including authorization management, access control, data protection, network security, and scalability. Furthermore, it analyzes the deficiencies and their actual cause, offering corresponding suggestions. This research also classifies and summarizes privacy protection techniques based
    
[^30]: 自动化时空图对比学习

    Automated Spatio-Temporal Graph Contrastive Learning. (arXiv:2305.03920v1 [cs.LG])

    [http://arxiv.org/abs/2305.03920](http://arxiv.org/abs/2305.03920)

    本文提出了一种自动化时空图对比学习模型来解决基于图的区域关系学习模型在处理普遍存在的数据噪声、缺失和分布异质性方面的挑战。

    

    在各种区域嵌入方法中，基于图的区域关系学习模型由于使用图神经网络编码空间相关性的强大结构表示能力而脱颖而出。尽管它们很有效，但现有方法尚未解决几个关键挑战：i）由于各种因素，数据噪音和缺失在许多时空场景中是普遍存在的。ii）输入的时空数据（例如移动轨迹）通常在空间和时间上表现出分布异质性。在这种情况下，当前方法容易受到生成区域图的质量的影响，从而可能导致次优性能。本文通过探索从多视图数据源生成的异构区域图上的自动时空图对比学习范式（AutoST）来解决上述挑战。我们的"AutoST"框架建立在一个异构图神经架构之上，以捕捉多视图区域依赖关系。

    Among various region embedding methods, graph-based region relation learning models stand out, owing to their strong structure representation ability for encoding spatial correlations with graph neural networks. Despite their effectiveness, several key challenges have not been well addressed in existing methods: i) Data noise and missing are ubiquitous in many spatio-temporal scenarios due to a variety of factors. ii) Input spatio-temporal data (e.g., mobility traces) usually exhibits distribution heterogeneity across space and time. In such cases, current methods are vulnerable to the quality of the generated region graphs, which may lead to suboptimal performance. In this paper, we tackle the above challenges by exploring the Automated Spatio-Temporal graph contrastive learning paradigm (AutoST) over the heterogeneous region graph generated from multi-view data sources. Our \model\ framework is built upon a heterogeneous graph neural architecture to capture the multi-view region depe
    
[^31]: 重新思考机器学习中的类别不均衡问题

    Rethinking Class Imbalance in Machine Learning. (arXiv:2305.03900v1 [cs.LG])

    [http://arxiv.org/abs/2305.03900](http://arxiv.org/abs/2305.03900)

    本研究提出了一个更广泛的类别不平衡分类方式，包括四种不平衡类型，并介绍了两种不平衡级别，使用理论分析证明了新的不平衡类型对学习公平性的重要影响。

    

    不平衡学习是机器学习的一个子领域，它关注存在类别不平衡的学习任务。几乎所有现有的研究都将类别不平衡定义为比例不平衡，即每个类别的训练样本比例不平衡，而忽视比例不平衡会导致类别之间/之间的不公平以及泛化能力差。本研究提出了一个更广泛的机器学习类别不平衡分类方式，包括方差、距离、邻近和质量等四种不平衡类型。本研究还介绍了两种不平衡级别:全局和局部。该研究使用理论分析来说明新的不平衡类型对学习公平性的重要影响。

    Imbalance learning is a subfield of machine learning that focuses on learning tasks in the presence of class imbalance. Nearly all existing studies refer to class imbalance as a proportion imbalance, where the proportion of training samples in each class is not balanced. The ignorance of the proportion imbalance will result in unfairness between/among classes and poor generalization capability. Previous literature has presented numerous methods for either theoretical/empirical analysis or new methods for imbalance learning. This study presents a new taxonomy of class imbalance in machine learning with a broader scope. Four other types of imbalance, namely, variance, distance, neighborhood, and quality imbalances between/among classes, which may exist in machine learning tasks, are summarized. Two different levels of imbalance including global and local are also presented. Theoretical analysis is used to illustrate the significant impact of the new imbalance types on learning fairness. 
    
[^32]: 通过Sponge毒化对设备上神经网络进行能量延迟攻击

    Energy-Latency Attacks to On-Device Neural Networks via Sponge Poisoning. (arXiv:2305.03888v1 [cs.CR])

    [http://arxiv.org/abs/2305.03888](http://arxiv.org/abs/2305.03888)

    本研究针对移动设备处理器的安全性，提出了一种设备上的Sponge毒化攻击流程，可以有效地污染具有内置加速器的现代处理器，同时分析了毒化攻击的能量和延迟成本。

    

    近年来，设备上的深度学习因其开发移动设备上的经济实惠深度学习应用而备受关注。然而，设备上的模型受到有限的能量和计算资源的约束。同时，一种名为Sponge毒化的攻击方式已经被开发出来。这种攻击方式涉及到提供毒害样本给模型，以增加推断期间的能量消耗。由于先前的工作侧重于服务器硬件加速器，因此在本文中，我们将Sponge毒化攻击扩展到设备上的情况，以评估移动设备处理器的安全性。我们提出了一个设备上的Sponge毒化攻击流程，以模拟流式和一致的推断场景，以填补设备上设置中的知识差距。我们在处理器和设备网络方面进行了独家实验分析，结果显示Sponge毒化攻击可以有效污染具有内置加速器的现代处理器。我们分析了在设备上进行神经网络毒化攻击的能量和延迟成本。

    In recent years, on-device deep learning has gained attention as a means of developing affordable deep learning applications for mobile devices. However, on-device models are constrained by limited energy and computation resources. In the mean time, a poisoning attack known as sponge poisoning has been developed.This attack involves feeding the model with poisoned examples to increase the energy consumption during inference. As previous work is focusing on server hardware accelerators, in this work, we extend the sponge poisoning attack to an on-device scenario to evaluate the vulnerability of mobile device processors. We present an on-device sponge poisoning attack pipeline to simulate the streaming and consistent inference scenario to bridge the knowledge gap in the on-device setting. Our exclusive experimental analysis with processors and on-device networks shows that sponge poisoning attacks can effectively pollute the modern processor with its built-in accelerator. We analyze the 
    
[^33]: 通过流映射算子学习随机动力学系统

    Learning Stochastic Dynamical System via Flow Map Operator. (arXiv:2305.03874v1 [cs.LG])

    [http://arxiv.org/abs/2305.03874](http://arxiv.org/abs/2305.03874)

    该论文提出了一种通过测量数据学习未知随机动力学系统的数值框架随机流映射学习（sFML），在不同类型的随机系统上进行的全面实验证明了 sFML 的有效性。

    

    我们提出了一种通过测量数据学习未知随机动力学系统的数值框架。称为随机流映射学习（sFML），这个新框架是流映射学习（FML）的扩展，后者是为了学习确定性动力学系统而开发的。对于学习随机系统，我们定义了一个随机流映射，它是两个子流映射的叠加：一个确定性子映射和一个随机子映射。随机训练数据首先用于构建确定性子映射，然后是随机子映射。确定性子映射采用残差网络（ResNet）形式，类似于FML对于确定性系统的工作。对于随机子映射，我们采用生成模型，尤其是生成对抗网络（GANs）在本文中应用。最终构建的随机流映射定义了一个随机演化模型，它在分布方面是未知随机系统的弱近似。在不同类型的随机系统上进行的全面实验证明了sFML揭示未知随机系统各种类型的非线性、噪声协方差结构和时间相关特性的有效性。

    We present a numerical framework for learning unknown stochastic dynamical systems using measurement data. Termed stochastic flow map learning (sFML), the new framework is an extension of flow map learning (FML) that was developed for learning deterministic dynamical systems. For learning stochastic systems, we define a stochastic flow map that is a superposition of two sub-flow maps: a deterministic sub-map and a stochastic sub-map. The stochastic training data are used to construct the deterministic sub-map first, followed by the stochastic sub-map. The deterministic sub-map takes the form of residual network (ResNet), similar to the work of FML for deterministic systems. For the stochastic sub-map, we employ a generative model, particularly generative adversarial networks (GANs) in this paper. The final constructed stochastic flow map then defines a stochastic evolution model that is a weak approximation, in term of distribution, of the unknown stochastic system. A comprehensive set
    
[^34]: 因果结构学习中的未解问题：以英国COVID-19为例研究

    Open problems in causal structure learning: A case study of COVID-19 in the UK. (arXiv:2305.03859v1 [cs.LG])

    [http://arxiv.org/abs/2305.03859](http://arxiv.org/abs/2305.03859)

    本文研究了因果机器学习在COVID-19英国疫情数据中的应用挑战，探讨了不同数据格式对学习类别不同的算法的影响，并突出了因果结构学习中的未解问题和未来研究方向。

    

    因果机器学习算法可以恢复图形结构，从而揭示因果关系。这些算法提供的因果表示使得透明度和可解释性得以实现。然而，与关联性机器学习相比，因果机器学习在实践中的影响有限。本文研究了因果机器学习在COVID-19英国疫情数据中的应用挑战。我们从各种公共来源整合数据，并研究各种结构学习算法从这些数据中学到的内容。我们探讨了不同数据格式对学习类别不同的算法的影响，并评估了每个算法及算法组产生的结果，包括图形结构、模型维度、敏感性分析、混淆变量、预测和干预推断等。我们利用这些结果来突出因果结构学习中的未解问题和未来研究方向。

    Causal machine learning (ML) algorithms recover graphical structures that tell us something about cause-and-effect relationships. The causal representation provided by these algorithms enables transparency and explainability, which is necessary in critical real-world problems. Yet, causal ML has had limited impact in practice compared to associational ML. This paper investigates the challenges of causal ML with application to COVID-19 UK pandemic data. We collate data from various public sources and investigate what the various structure learning algorithms learn from these data. We explore the impact of different data formats on algorithms spanning different classes of learning, and assess the results produced by each algorithm, and groups of algorithms, in terms of graphical structure, model dimensionality, sensitivity analysis, confounding variables, predictive and interventional inference. We use these results to highlight open problems in causal structure learning and directions f
    
[^35]: CHAI-DT: 一个框架，用于促使对话生成型AI代理积极参与共创

    CHAI-DT: A Framework for Prompting Conversational Generative AI Agents to Actively Participate in Co-Creation. (arXiv:2305.03852v1 [cs.HC])

    [http://arxiv.org/abs/2305.03852](http://arxiv.org/abs/2305.03852)

    本文介绍了一个CHAI-DT框架，可以使对话生成型AI代理积极参与到共创活动中，为设计思维活动提供有用和创意性的贡献，并讨论了其潜在优势、局限性和风险。

    

    本文探讨了将生成型AI模型应用于小组共创框架中，以增强商业创新和共创背景下的问题解决和构思的潜力，并提出了一种新的提示技术，用于启用对话式生成型AI代理的积极贡献到设计思维(co-creative framework)的办法，这种方法受到传统的“人与人”促进和教学方法的启发。通过使用这种提示技术的实验，我们收集了聊天生成型变压器(ChatGPT)为设计思维活动提供具有特定上下文、有用和创意性的贡献的能力的证据。我们还讨论了使用生成型AI模型进行共创构思的潜在优势、局限性和风险，并提出了未来研究的建议。

    This paper explores the potential for utilizing generative AI models in group-focused co-creative frameworks to enhance problem solving and ideation in business innovation and co-creation contexts, and proposes a novel prompting technique for conversational generative AI agents which employ methods inspired by traditional 'human-to-human' facilitation and instruction to enable active contribution to Design Thinking, a co-creative framework. Through experiments using this prompting technique, we gather evidence that conversational generative transformers (i.e. ChatGPT) have the capability to contribute context-specific, useful, and creative input into Design Thinking activities. We also discuss the potential benefits, limitations, and risks associated with using generative AI models in co-creative ideation and provide recommendations for future research.
    
[^36]: SemEval-2023任务2中CLaC：比较序列标记和跨度预测方法用于命名实体识别

    CLaC at SemEval-2023 Task 2: Comparing Span-Prediction and Sequence-Labeling approaches for NER. (arXiv:2305.03845v1 [cs.CL])

    [http://arxiv.org/abs/2305.03845](http://arxiv.org/abs/2305.03845)

    本文比较了命名实体识别中的序列标记和跨度预测两种方法，在测试数据中跨度预测表现略优，并且使用更大版本的XLM RoBERTa可以显著提高性能。

    

    本文总结了CLaC对于MultiCoNER 2任务的提交，该任务涉及复杂的细粒度命名实体的识别。我们比较了命名实体识别中两种流行的方法，即序列标记和跨度预测。我们发现，在测试数据上，我们最好的跨度预测系统的表现略优于我们最好的序列标记系统。此外，我们发现使用更大版本的XLM RoBERTa可以显著提高性能。后续的实验表明，当使用XLM-RoBERTa的特殊输入标记（<s>和</s>）时，跨度预测和序列标记方法都会得到改进。所有模型训练，预处理和后处理的代码都可以在https://github.com/harshshredding/semeval2023-multiconer-paper找到。

    This paper summarizes the CLaC submission for the MultiCoNER 2 task which concerns the recognition of complex, fine-grained named entities. We compare two popular approaches for NER, namely Sequence Labeling and Span Prediction. We find that our best Span Prediction system performs slightly better than our best Sequence Labeling system on test data. Moreover, we find that using the larger version of XLM RoBERTa significantly improves performance. Post-competition experiments show that Span Prediction and Sequence Labeling approaches improve when they use special input tokens (<s> and </s>) of XLM-RoBERTa. The code for training all models, preprocessing, and post-processing is available at https://github.com/harshshredding/semeval2023-multiconer-paper.
    
[^37]: 语义相似性对比学习在代码搜索中的应用

    On Contrastive Learning of Semantic Similarity forCode to Code Search. (arXiv:2305.03843v1 [cs.SE])

    [http://arxiv.org/abs/2305.03843](http://arxiv.org/abs/2305.03843)

    本文提出了一种结合静态和动态特征以及利用相似和不相似样本进行训练的代码搜索技术，在训练期间编码动态运行时信息。实验证明该方法在各种编程语言和模型架构中均具有一致的性能，比最先进的跨语言搜索工具提高了高达44.7%的性能。

    

    本文提出了一种新颖的代码搜索技术，通过在训练中包括静态和动态特征，利用相似和不相似的样本，增强大型语言模型（LLMs）的性能。我们提出了第一种在训练期间编码动态运行时信息的代码搜索方法，而无需在推断时执行要搜索的语料库或搜索查询，并且第一种在正负参考样本上进行训练的代码搜索技术。为验证我们方法的有效性，我们执行了一系列研究，证明增强型LLMs能够进行跨语言代码搜索，并且我们的方法在各种模型架构和编程语言中的性能是一致的。我们的评估结果表明，我们的方法比最先进的跨语言搜索工具提高了高达44.7％的性能。此外，我们的消融研究揭示，即使只有一种正负样本进行训练，也能显著优于传统技术只使用正样本的技术。

    This paper introduces a novel code-to-code search technique that enhances the performance of Large Language Models (LLMs) by including both static and dynamic features as well as utilizing both similar and dissimilar examples during training. We present the first-ever code search method that encodes dynamic runtime information during training without the need to execute either the corpus under search or the search query at inference time and the first code search technique that trains on both positive and negative reference samples. To validate the efficacy of our approach, we perform a set of studies demonstrating the capability of enhanced LLMs to perform cross-language code-to-code search.  Our evaluation demonstrates that the effectiveness of our approach is consistent across various model architectures and programming languages. We outperform the state-of-the-art cross-language search tool by up to 44.7\%. Moreover, our ablation studies reveal that even a single positive and negat
    
[^38]: 股票运动预测的时空变换器

    Spatiotemporal Transformer for Stock Movement Prediction. (arXiv:2305.03835v1 [cs.LG])

    [http://arxiv.org/abs/2305.03835](http://arxiv.org/abs/2305.03835)

    使用时空变换器-LSTM模型进行股票运动预测，取得了高准确率，并在模拟中显示出比标准普尔500股票指数更高的收益率。

    

    金融市场是一个引人入胜的地方，如果时间掌握得当，投资者可以获得巨大的利润。不幸的是，金融市场的动态、非线性特性使得未来价格走势难以预测。我们提出了STST，一种使用时空变换器-LSTM模型进行股票运动预测的新方法。我们的模型在ACL18和KDD17数据集上分别获得63.707%和56.879%的准确率。此外，我们的模型在模拟中用于确定其在现实生活中的适用性。它的最小年化收益率比标准普尔500股票指数高出10.41%以上。

    Financial markets are an intriguing place that offer investors the potential to gain large profits if timed correctly. Unfortunately, the dynamic, non-linear nature of financial markets makes it extremely hard to predict future price movements. Within the US stock exchange, there are a countless number of factors that play a role in the price of a company's stock, including but not limited to financial statements, social and news sentiment, overall market sentiment, political happenings and trading psychology. Correlating these factors is virtually impossible for a human. Therefore, we propose STST, a novel approach using a Spatiotemporal Transformer-LSTM model for stock movement prediction. Our model obtains accuracies of 63.707 and 56.879 percent against the ACL18 and KDD17 datasets, respectively. In addition, our model was used in simulation to determine its real-life applicability. It obtained a minimum of 10.41% higher profit than the S&P500 stock index, with a minimum annualized 
    
[^39]: 不同iable符号编程提高语言模型的逻辑推理能力

    Improved Logical Reasoning of Language Models via Differentiable Symbolic Programming. (arXiv:2305.03742v1 [cs.AI])

    [http://arxiv.org/abs/2305.03742](http://arxiv.org/abs/2305.03742)

    本文提出一种新的可微分符号推理框架，DSR-LM，用于提高预训练语言模型的逻辑推理能力，不像以往的研究依赖手工制定的逻辑规则，该框架有效地学习加权规则，并应用语义损失进一步改善LMs的逻辑推理能力。

    

    尽管语言模型在规模和组合性方面取得了进展，但预训练的大型语言模型仍然难以可靠地执行逻辑推理。本文基于符号编程的视角解决了这一挑战。我们提出了DSR-LM，一种可微分的符号推理框架，其中预训练的LMs管理事实知识的感知，符号模块执行演绎推理。与依赖手工制定的逻辑规则的作品不同，我们的可微分符号推理框架有效地学习加权规则，并应用语义损失进一步改善LMs。DSR-LM具有可扩展性、可解释性，并允许轻松集成先前的知识，从而支持广泛的符号编程，以稳健地推出逻辑结论。我们的实验结果表明，DSR-LM提高了预训练语言模型的逻辑推理能力，在演绎推理基准测试中的准确性显著提高了20%以上。此外，DSR-LM还可以有效处理自然语言解释问题，包括开放式的逻辑推理任务。

    Pre-trained large language models (LMs) struggle to perform logical reasoning reliably despite advances in scale and compositionality. In this work, we tackle this challenge through the lens of symbolic programming. We propose DSR-LM, a Differentiable Symbolic Reasoning framework where pre-trained LMs govern the perception of factual knowledge, and a symbolic module performs deductive reasoning. In contrast to works that rely on hand-crafted logic rules, our differentiable symbolic reasoning framework efficiently learns weighted rules and applies semantic loss to further improve LMs. DSR-LM is scalable, interpretable, and allows easy integration of prior knowledge, thereby supporting extensive symbolic programming to robustly derive a logical conclusion. The results of our experiments suggest that DSR-LM improves the logical reasoning abilities of pre-trained language models, resulting in a significant increase in accuracy of over 20% on deductive reasoning benchmarks. Furthermore, DSR
    
[^40]: AmGCL: 基于自监督对比学习的属性缺失图特征插补方法

    AmGCL: Feature Imputation of Attribute Missing Graph via Self-supervised Contrastive Learning. (arXiv:2305.03741v1 [cs.LG])

    [http://arxiv.org/abs/2305.03741](http://arxiv.org/abs/2305.03741)

    AmGCL是一个用于处理属性缺失图数据的自监督对比学习框架，可以通过特征插补和潜在表示学习来解决属性图中节点属性缺失的问题。

    

    属性图在多媒体应用中使用广泛，图表示学习（GRL）已经成功地应用于属性图数据分析。然而，不完整的图数据和缺失的节点属性可能会对媒体知识发现产生负面影响。现有的处理属性缺失图的方法存在有限的假设或无法捕捉复杂的属性-图形依赖关系。为了解决这些挑战，我们提出了基于自监督对比学习的属性缺失图对比学习（AmGCL）框架，用于处理属性图数据中的缺失节点属性。AmGCL利用基于狄利克雷能量的特征预编码来对缺失属性进行编码，利用自监督图增强对比学习结构（GACLS）从编码数据中学习潜在变量。具体而言，AmGCL利用结构-属性能量最小化进行特征重构，同时最大化互信息的下限以学习潜在表示。

    Attribute graphs are ubiquitous in multimedia applications, and graph representation learning (GRL) has been successful in analyzing attribute graph data. However, incomplete graph data and missing node attributes can have a negative impact on media knowledge discovery. Existing methods for handling attribute missing graph have limited assumptions or fail to capture complex attribute-graph dependencies. To address these challenges, we propose Attribute missing Graph Contrastive Learning (AmGCL), a framework for handling missing node attributes in attribute graph data. AmGCL leverages Dirichlet energy minimization-based feature precoding to encode in missing attributes and a self-supervised Graph Augmentation Contrastive Learning Structure (GACLS) to learn latent variables from the encoded-in data. Specifically, AmGCL utilizies feature reconstruction based on structure-attribute energy minimization while maximizes the lower bound of evidence for latent representation mutual information.
    
[^41]: 调整传统语言处理方法以适用于普什图语文本分类

    Tuning Traditional Language Processing Approaches for Pashto Text Classification. (arXiv:2305.03737v1 [cs.CL])

    [http://arxiv.org/abs/2305.03737](http://arxiv.org/abs/2305.03737)

    本研究建立了一个普什图语自动文本分类系统，通过比较不同模型和特征提取方法，实验结果表明使用tf-idf特征提取方法的SVM模型在普什图语文本分类中取得了最高的准确率。

    

    文本分类在很多领域中都是一个重要的任务。因此，已经进行了多项研究来开发国际和本地语言的自动文本分类系统。然而，需要为本地语言建立一个自动文本分类系统。本研究的主要目的是建立一个普什图语自动文本分类系统。为了实现这个目标, 我们建立了一个普什图语语料库，这是由于普什图语文本文档的公共数据集不可用。此外，本研究比较了包括多层感知器(MLP)、支持向量机(SVM)、K近邻(KNN)、决策树, 高斯朴素贝叶斯, 多项式朴素贝叶斯, 随机森林和逻辑回归在内的多个模型，以发现最有效的方法。此外，本研究还评估了两种不同的特征提取方法，包括词袋和tf-idf。实验结果表明，在普什图语文本分类中，使用tf-idf特征提取方法的SVM模型取得了最高的97.19%的准确率。

    Today text classification becomes critical task for concerned individuals for numerous purposes. Hence, several researches have been conducted to develop automatic text classification for national and international languages. However, the need for an automatic text categorization system for local languages is felt. The main aim of this study is to establish a Pashto automatic text classification system. In order to pursue this work, we built a Pashto corpus which is a collection of Pashto documents due to the unavailability of public datasets of Pashto text documents. Besides, this study compares several models containing both statistical and neural network machine learning techniques including Multilayer Perceptron (MLP), Support Vector Machine (SVM), K Nearest Neighbor (KNN), decision tree, gaussian na\"ive Bayes, multinomial na\"ive Bayes, random forest, and logistic regression to discover the most effective approach. Moreover, this investigation evaluates two different feature extr
    
[^42]: Stackelberg Games用于在竞争学习自适应课程中学习新兴行为

    Stackelberg Games for Learning Emergent Behaviors During Competitive Autocurricula. (arXiv:2305.03735v1 [cs.AI])

    [http://arxiv.org/abs/2305.03735](http://arxiv.org/abs/2305.03735)

    本论文提出了一种新颖的博弈论算法，Stackelberg Multi-Agent Deep Deterministic Policy Gradient(ST-MADDPG), 用于在竞争学习自适应课程中学习新兴行为。

    

    自适应课程训练是多智能体强化学习（MARL）的一个重要子领域，它允许多个智能体在无监督的共同演化方案中学习新兴的技能。机器人社区已经在物理立足的问题上尝试了自适应课程训练，例如强健控制和交互式操纵任务。然而，这些任务的不对称性使得生成复杂策略具有挑战性。事实上，环境中的不对称性可能会隐含地或明确地为某些智能体提供优势，并可能导致质量低劣的均衡状态。本文提出了一种新颖的博弈论算法 - Stackelberg深决策策略梯度（ST-MADDPG），将一个双人MARL问题制定为具有层次交互结构的Stackelberg博弈，其中一个玩家是“领导者”，另一个是“跟随者”，领导者具有优势。我们首先展示了领导者的优势

    Autocurricular training is an important sub-area of multi-agent reinforcement learning~(MARL) that allows multiple agents to learn emergent skills in an unsupervised co-evolving scheme. The robotics community has experimented autocurricular training with physically grounded problems, such as robust control and interactive manipulation tasks. However, the asymmetric nature of these tasks makes the generation of sophisticated policies challenging. Indeed, the asymmetry in the environment may implicitly or explicitly provide an advantage to a subset of agents which could, in turn, lead to a low-quality equilibrium. This paper proposes a novel game-theoretic algorithm, Stackelberg Multi-Agent Deep Deterministic Policy Gradient (ST-MADDPG), which formulates a two-player MARL problem as a Stackelberg game with one player as the `leader' and the other as the `follower' in a hierarchical interaction structure wherein the leader has an advantage. We first demonstrate that the leader's advantage
    
[^43]: 评估ChatGPT的工作记忆容量

    Assessing Working Memory Capacity of ChatGPT. (arXiv:2305.03731v1 [cs.AI])

    [http://arxiv.org/abs/2305.03731](http://arxiv.org/abs/2305.03731)

    本文评估了最先进语言模型ChatGPT的工作记忆容量，结果显示其在N-back任务的行为表现与人类参与者相似，这为设计具有人类级认知能力的人工智能系统提供了关键洞察。

    

    工作记忆是人类智能和人工智能的关键方面，它作为信息临时存储和操作的工作空间。本文通过检查ChatGPT在N-back任务上的表现，调查了这一最先进语言模型的工作记忆容量。我们首先讨论了工作记忆对人类和人工智能的重要性，接着介绍了评估ChatGPT工作记忆容量的方法。研究比较了ChatGPT在言语和空间N- back任务上的行为表现与文献报道的人类参与者的表现，发现了显著的相似之处。我们的发现为设计具有人类级认知能力的人工智能系统的当前进展提供了关键洞察，并为通过人工智能模型理解人类工作记忆的未来努力提供了前景。

    Working memory is a critical aspect of both human intelligence and artificial intelligence (AI), serving as a workspace for the temporary storage and manipulation of information. This paper investigates working memory capacity of ChatGPT, a state-of-the-art language model, by examining its performance on N-back tasks. We begin by discussing the importance of working memory to humans and AI, followed by the methods employed to assess working memory capacity of ChatGPT. Our study compares behavioral performance of ChatGPT on verbal and spatial N-back tasks to that of human participants reported in the literature, revealing notable similarities. Our findings offer crucial insights into the current progress in designing AI systems with human-level cognitive abilities and hold promise for informing future endeavors aimed at enhancing AI working memory and understanding human working memory through AI models.
    
[^44]: 基于RGB-D语义分割的服装抓取和展开

    Clothes Grasping and Unfolding Based on RGB-D Semantic Segmentation. (arXiv:2305.03259v1 [cs.CV])

    [http://arxiv.org/abs/2305.03259](http://arxiv.org/abs/2305.03259)

    本论文针对机器人辅助穿衣过程中的服装抓取和展开问题，提出了一种基于RGB-D语义分割的双向分形交叉融合网络，可以识别可抓取区域提供更多抓取可能性，并且使用RGB和深度数据融合来考虑图像信息。

    

    服装的抓取和展开是机器人辅助穿衣的核心步骤。大多数现有作品利用服装的深度图像训练深度学习模型以识别合适的抓取点。然而，这些方法通常利用物理引擎来合成深度图像以减少真实标记数据的收集成本。然而，合成与真实图像之间的自然领域差距常常导致这些方法在实际数据上表现不佳。此外，这些方法通常在抓取点被服装物品本身遮挡的场景中难以处理。为了解决上述挑战，我们提出了一种新颖的双向分形交叉融合网络（BiFCNet）进行语义分割，实现对可抓取区域的识别以提供更多的抓取可能性。我们不仅使用深度图像，还利用具有丰富色彩特征的RGB图像作为网络输入，其中分形交叉融合（FCF）模块通过将RGB和深度数据融合来考虑图像信息。

    Clothes grasping and unfolding is a core step in robotic-assisted dressing. Most existing works leverage depth images of clothes to train a deep learning-based model to recognize suitable grasping points. These methods often utilize physics engines to synthesize depth images to reduce the cost of real labeled data collection. However, the natural domain gap between synthetic and real images often leads to poor performance of these methods on real data. Furthermore, these approaches often struggle in scenarios where grasping points are occluded by the clothing item itself. To address the above challenges, we propose a novel Bi-directional Fractal Cross Fusion Network (BiFCNet) for semantic segmentation, enabling recognition of graspable regions in order to provide more possibilities for grasping. Instead of using depth images only, we also utilize RGB images with rich color features as input to our network in which the Fractal Cross Fusion (FCF) module fuses RGB and depth data by consid
    
[^45]: 超越同质性：重构结构实现对图形无关聚类

    Beyond Homophily: Reconstructing Structure for Graph-agnostic Clustering. (arXiv:2305.02931v1 [cs.SI] CROSS LISTED)

    [http://arxiv.org/abs/2305.02931](http://arxiv.org/abs/2305.02931)

    本论文提出了一种新颖的图形聚类方法，能够超越同质性假设，重构结构实现对图形无关聚类，包括三个关键组件：图形重构、混合滤波器和双图形聚类网络。为了减少节点属性和拓扑结构之间的不良耦合，我们将它们分别映射到两个子空间中。

    

    基于图神经网络（GNN）的聚类方法在节点聚类任务中取得了惊人的表现。然而，它们是基于同质图的假设设计的，而在异质图上进行聚类被忽视了。由于缺乏标签，不可能在找到适合的GNN模型之前首先将图形识别为同质或异质。因此，对于各种同质性水平的真实世界图形进行聚类将为图形研究社区带来新的挑战。为填补这一空白，我们提出了一种新颖的图形聚类方法，其中包含三个关键组件：图形重构、混合滤波器和双图形聚类网络。为了使其对图形无关，我们根据数据构建了高度同质性和异质性的两个图形。基于新图构建的混合滤波器提取了低频和高频信息。为了减少节点属性和拓扑结构之间的不良耦合，我们将它们分别映射到两个子空间中。

    Graph neural networks (GNNs) based methods have achieved impressive performance on node clustering task. However, they are designed on the homophilic assumption of graph and clustering on heterophilic graph is overlooked. Due to the lack of labels, it is impossible to first identify a graph as homophilic or heterophilic before a suitable GNN model can be found. Hence, clustering on real-world graph with various levels of homophily poses a new challenge to the graph research community. To fill this gap, we propose a novel graph clustering method, which contains three key components: graph reconstruction, a mixed filter, and dual graph clustering network. To be graph-agnostic, we empirically construct two graphs which are high homophily and heterophily from each data. The mixed filter based on the new graphs extracts both low-frequency and high-frequency information. To reduce the adverse coupling between node attribute and topological structure, we separately map them into two subspaces
    
[^46]: 计划、消除和跟踪——语言模型是具备体验的智能体的良师益友。

    Plan, Eliminate, and Track -- Language Models are Good Teachers for Embodied Agents. (arXiv:2305.02412v1 [cs.CL])

    [http://arxiv.org/abs/2305.02412](http://arxiv.org/abs/2305.02412)

    本文介绍了Plan，Eliminate，和Track（PET）框架，该框架利用预先训练的大型语言模型（LLM）帮助智能体简化控制任务，从而解决了LLM直接作为智能体所面临的一些限制和问题。

    

    预训练的大型语言模型(LLMs)可以捕捉到关于世界的程序化知识。最近的研究利用LLM产生的抽象计划来简化具有挑战性的控制任务，通过动作打分或动作建模（微调）来实现。然而，变压器架构继承了几个限制，使得LLM难以直接作为智能体：例如有限的输入长度，微调的效率，预训练的偏见以及与非文本环境的不兼容性。为了与低级别可训练的执行器保持兼容性，我们建议使用LLMs中的知识来简化控制问题，而不是解决问题。 我们提出了Plan，Eliminate和Track（PET）框架。计划模块将任务描述转化为高层次子任务的列表。消除模块从当前子任务的观察中屏蔽不相关的对象和容器。最后，跟踪模块确定智能体是否已经实现了当前子任务。

    Pre-trained large language models (LLMs) capture procedural knowledge about the world. Recent work has leveraged LLM's ability to generate abstract plans to simplify challenging control tasks, either by action scoring, or action modeling (fine-tuning). However, the transformer architecture inherits several constraints that make it difficult for the LLM to directly serve as the agent: e.g. limited input lengths, fine-tuning inefficiency, bias from pre-training, and incompatibility with non-text environments. To maintain compatibility with a low-level trainable actor, we propose to instead use the knowledge in LLMs to simplify the control problem, rather than solving it. We propose the Plan, Eliminate, and Track (PET) framework. The Plan module translates a task description into a list of high-level sub-tasks. The Eliminate module masks out irrelevant objects and receptacles from the observation for the current sub-task. Finally, the Track module determines whether the agent has accompli
    
[^47]: 可解释人工智能方法评述：SHAP 和 LIME

    Commentary on explainable artificial intelligence methods: SHAP and LIME. (arXiv:2305.02012v1 [stat.ML])

    [http://arxiv.org/abs/2305.02012](http://arxiv.org/abs/2305.02012)

    这篇评论对可解释人工智能方法 SHAP 和 LIME 进行了评述和比较，提出了一个框架且突出了它们的优缺点。

    

    可解释人工智能（XAI）方法已经发展出来，将机器学习模型的黑匣子转化为更易理解的形式。这些方法有助于传达模型的工作原理，旨在使机器学习模型更透明，并增加最终用户对其输出的信任。 SHapley Additive exPlanations（SHAP）和Local Interpretable Model Agnostic Explanation（LIME）是两种在表格数据中广泛使用的XAI方法。在这篇评论中，我们讨论了两种方法的可解释性度量是如何生成的，并提出了一个解释它们输出的框架，突出了它们的优缺点。

    eXplainable artificial intelligence (XAI) methods have emerged to convert the black box of machine learning models into a more digestible form. These methods help to communicate how the model works with the aim of making machine learning models more transparent and increasing the trust of end-users into their output. SHapley Additive exPlanations (SHAP) and Local Interpretable Model Agnostic Explanation (LIME) are two widely used XAI methods particularly with tabular data. In this commentary piece, we discuss the way the explainability metrics of these two methods are generated and propose a framework for interpretation of their outputs, highlighting their weaknesses and strengths.
    
[^48]: 超声心动图体积指数的提取：哪种深度学习方案可以应用于临床？

    Extraction of volumetric indices from echocardiography: which deep learning solution for clinical use?. (arXiv:2305.01997v1 [eess.IV])

    [http://arxiv.org/abs/2305.01997](http://arxiv.org/abs/2305.01997)

    本文对当前医学/超声心动图图像分割方法进行了全面比较，提出了3D nnU-Net模型，解决了时间一致性和跨数据集方面的问题，并通过引入一个新的私有数据集，CARDINAL，来证明其在应用于临床中的优越性。

    

    基于深度学习的方法已经成为超声心动图图像自动分析的主要手段，利用多个由专家注释的开放数据集（其中CAMUS是最大的公共数据库之一）。然而，由于存在一些问题，如预测的时间一致性和跨数据集的推广能力等问题，这些模型仍然被临床医生认为是不可靠的。因此，本文提出了对当前表现最佳的医学/超声心动图图像分割方法进行全面比较，并特别关注了时间一致性和跨数据集方面。我们介绍了一个名为CARDINAL的新的私有数据集，其包括心尖两腔和心尖四腔序列，并具有完整心脏周期的参考分割。我们展示了所提出的3D nnU-Net优于替代的2D和循环分割方法，同时也报告了在CARDINAL上训练的最佳模型在测试数据集上的良好表现。

    Deep learning-based methods have spearheaded the automatic analysis of echocardiographic images, taking advantage of the publication of multiple open access datasets annotated by experts (CAMUS being one of the largest public databases). However, these models are still considered unreliable by clinicians due to unresolved issues concerning i) the temporal consistency of their predictions, and ii) their ability to generalize across datasets. In this context, we propose a comprehensive comparison between the current best performing methods in medical/echocardiographic image segmentation, with a particular focus on temporal consistency and cross-dataset aspects. We introduce a new private dataset, named CARDINAL, of apical two-chamber and apical four-chamber sequences, with reference segmentation over the full cardiac cycle. We show that the proposed 3D nnU-Net outperforms alternative 2D and recurrent segmentation methods. We also report that the best models trained on CARDINAL, when test
    
[^49]: 基于因果感知的知识引导句子提取

    Causality-aware Concept Extraction based on Knowledge-guided Prompting. (arXiv:2305.01876v1 [cs.CL])

    [http://arxiv.org/abs/2305.01876](http://arxiv.org/abs/2305.01876)

    该论文提出了一种基于因果感知的知识引导提示方法，将其作为干预器装备到基于预训练语言模型的句子提取器中，以缓解概念偏差。在代表性的多语言KG数据集上进行广泛实验，获得了最先进的结果。

    

    概念有助于自然语言理解，但现有的知识图谱（KG）中远未完善。最近，预训练语言模型（PLM）已被广泛用于基于文本的概念提取（CE）。然而，PLM往往从大量语料库的共现关联中进行预训练知识挖掘，而非Token之间的真实因果关系。因此，预训练知识混淆了PLM，导致提取基于虚假共现相关性的有偏概念，不可避免地导致低精度。本文通过结构因果模型（SCM）提出了一种知识引导提示方法，将其作为干预器装备到基于PLM的提取器中，以减轻概念偏差。提示采用现有KG中的给定实体主题来缓解实体和有偏概念之间的虚假共现相关性。我们在代表性的多语言KG数据集上进行了广泛的实验，证明了我们提出的提示显著改进了提取性能，并达到了最先进的结果。

    Concepts benefit natural language understanding but are far from complete in existing knowledge graphs (KGs). Recently, pre-trained language models (PLMs) have been widely used in text-based concept extraction (CE). However, PLMs tend to mine the co-occurrence associations from massive corpus as pre-trained knowledge rather than the real causal effect between tokens.As a result, the pre-trained knowledge confounds PLMs to extract biased concepts based on spurious co-occurrence correlations, inevitably resulting in low precision. In this paper, through the lens of a Structural Causal Model (SCM), we propose equipping the PLM-based extractor with a knowledge-guided prompt as an intervention to alleviate concept bias. The prompt adopts the topic of the given entity from the existing knowledge in KGs to mitigate the spurious co-occurrence correlations between entities and biased concepts. Our extensive experiments on representative multilingual KG datasets justify that our proposed prompt 
    
[^50]: H2CGL: 用于引文网络动态建模与影响预测的模型。

    H2CGL: Modeling Dynamics of Citation Network for Impact Prediction. (arXiv:2305.01572v1 [cs.DL])

    [http://arxiv.org/abs/2305.01572](http://arxiv.org/abs/2305.01572)

    本文提出了一种名为H2CGL的新颖图神经网络模型，用于引文网络的动态建模和影响预测。该模型通过分层和异构的方式记录目标论文年度动态信息，并优先考虑高被引论文和参考文献、引文、目标论文之间的关系。它采用加权 GIN 来捕捉异构子图的动态，同时采用对比学习来提高模型效果。

    

    论文的影响力通常是通过其引用数量来衡量的。然而，大多数常用的模型可能会低估新发表论文随时间的影响力，并且未能将这种引文网络的动态性纳入图中。在本研究中，我们构建了一个具有年度视角的目标论文的分层异构图，并记录了目标论文科学背景信息的年度动态性。然后，我们提出了一种新的图神经网络模型，称为分层异构对比图学习模型（H2CGL），以融合引文网络的异构性和动态性。H2CGL分别聚合了每年的异构信息，并优先考虑高被引论文以及参考文献和引文与目标论文之间的关系。然后，它采用加权GIN来捕捉年份之间的异构子图动态性。此外，它采用对比学习来提高模型效果。

    The potential impact of a paper is often quantified by how many citations it will receive. However, most commonly used models may underestimate the influence of newly published papers over time, and fail to encapsulate this dynamics of citation network into the graph. In this study, we construct hierarchical and heterogeneous graphs for target papers with an annual perspective. The constructed graphs can record the annual dynamics of target papers' scientific context information. Then, a novel graph neural network, Hierarchical and Heterogeneous Contrastive Graph Learning Model (H2CGL), is proposed to incorporate heterogeneity and dynamics of the citation network. H2CGL separately aggregates the heterogeneous information for each year and prioritizes the highly-cited papers and relationships among references, citations, and the target paper. It then employs a weighted GIN to capture dynamics between heterogeneous subgraphs over years. Moreover, it leverages contrastive learning to make
    
[^51]: 触发词作为后门攻击的触发器：检查语言模型的脆弱性

    Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models. (arXiv:2305.01219v1 [cs.CL])

    [http://arxiv.org/abs/2305.01219](http://arxiv.org/abs/2305.01219)

    本研究提出一种新颖有效的“ProAttack”方法来执行干净标签的后门攻击，使用的是提示本身作为触发器。该方法不需要外部触发器，并确保毒瘤数据的标注正确，提高了后门攻击的隐蔽性，相比于现有的后门攻击方法有显著提升。

    

    基于提示的学习范例弥合了预训练和微调之间的差距，在几个NLP任务中取得了最先进的性能，尤其是在少样本情况下。尽管应用广泛，但基于提示的学习容易受到后门攻击。文本后门攻击旨在通过注入触发器并修改标签来在模型中引入有针对性的漏洞。然而，由于触发器的存在和毒瘤数据标注不正确等缺陷，这种攻击存在异常的自然语言表达。在本研究中，我们提出了一种新颖有效的“ProAttack”方法，基于提示来执行干净标签的后门攻击，使用的是提示本身作为触发器。我们的方法不需要外部触发器，并确保毒瘤数据的标注正确，提高了后门攻击的隐蔽性。通过在丰富的资源和少样本文本语料库上的广泛实验，我们证明了ProAttack方法在保持干净数据一致性的同时显著优于现有的后门攻击方式。

    The prompt-based learning paradigm, which bridges the gap between pre-training and fine-tuning, achieves state-of-the-art performance on several NLP tasks, particularly in few-shot settings. Despite being widely applied, prompt-based learning is vulnerable to backdoor attacks. Textual backdoor attacks are designed to introduce targeted vulnerabilities into models by poisoning a subset of training samples through trigger injection and label modification. However, they suffer from flaws such as abnormal natural language expressions resulting from the trigger and incorrect labeling of poisoned samples. In this study, we propose {\bf ProAttack}, a novel and efficient method for performing clean-label backdoor attacks based on the prompt, which uses the prompt itself as a trigger. Our method does not require external triggers and ensures correct labeling of poisoned samples, improving the stealthy nature of the backdoor attack. With extensive experiments on rich-resource and few-shot text c
    
[^52]: Venn图多标签分类解释与颜色和清晰度增强的糖尿病足潰疡

    Venn Diagram Multi-label Class Interpretation of Diabetic Foot Ulcer with Color and Sharpness Enhancement. (arXiv:2305.01044v1 [cs.CV])

    [http://arxiv.org/abs/2305.01044](http://arxiv.org/abs/2305.01044)

    本文提出了一种基于Venn图解释的多标签分类算法，通过不同的图像增强策略，将四个类别缩减为两个，有效提高了糖尿病足潰疡的多类别分类准确度。

    

    糖尿病足潰疡是糖尿病的严重并发症，如果不正确治疗，可能导致下肢截肢。受2021年糖尿病足潰疡大挑战的启发，研究人员设计了DFU的自动化多类别分类，包括感染、缺血、这两种情况以及以上两种情况均不属于的情况。然而，分类准确度仍然不尽人意。本文提出了一种 Venn 图解释的多标签基于 CNN 的方法，利用不同的图像增强策略，以改进多类别 DFU 分类。我们建议将这四个类别减少为两个类别，因为这两个类别的伤口可以解释为感染和缺血的同时发生，而无类别伤口则表示缺乏感染和缺血。我们在分类器中引入了一种新颖的 Venn 图表示块，用于解释这两个类别的所有四个类。为使我们的模型更具弹性，我们建议增强感知。

    DFU is a severe complication of diabetes that can lead to amputation of the lower limb if not treated properly. Inspired by the 2021 Diabetic Foot Ulcer Grand Challenge, researchers designed automated multi-class classification of DFU, including infection, ischaemia, both of these conditions, and none of these conditions. However, it remains a challenge as classification accuracy is still not satisfactory. This paper proposes a Venn Diagram interpretation of multi-label CNN-based method, utilizing different image enhancement strategies, to improve the multi-class DFU classification. We propose to reduce the four classes into two since both class wounds can be interpreted as the simultaneous occurrence of infection and ischaemia and none class wounds as the absence of infection and ischaemia. We introduce a novel Venn Diagram representation block in the classifier to interpret all four classes from these two classes. To make our model more resilient, we propose enhancing the perceptual 
    
[^53]: Attack-SAM: 面向用对抗样本攻击的分割万物模型

    Attack-SAM: Towards Attacking Segment Anything Model With Adversarial Examples. (arXiv:2305.00866v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.00866](http://arxiv.org/abs/2305.00866)

    本文是第一个全面研究如何使用对抗样本攻击分割万物模型SAM的工作，该工作重要的贡献为探讨SAM的对抗性鲁棒性，有助于理解和提高基础视觉模型安全性。

    

    最近，由于其在零短模式下在各种下游任务中的出色表现，分割万物模型（SAM）受到了广泛关注。然而，深度视觉模型被公认为容易受到对抗性攻击的攻击，这种攻击会在不可察觉的扰动下欺骗模型进行错误预测。为了使深度模型适用于安全敏感的应用程序，了解视觉基础模型SAM是否也容易受到对抗性攻击是至关重要的。据我们所知，我们的工作是第一个全面研究如何使用对抗样本攻击SAM的工作。我们以掩码移除为基本攻击目标，探讨了SAM的对抗性鲁棒性，这是理解和提高基础视觉模型安全性的重要步骤。

    Segment Anything Model (SAM) has attracted significant attention recently, due to its impressive performance on various downstream tasks in a zero-short manner. Computer vision (CV) area might follow the natural language processing (NLP) area to embark on a path from task-specific vision models toward foundation models. However, deep vision models are widely recognized as vulnerable to adversarial examples, which fool the model to make wrong predictions with imperceptible perturbation. Such vulnerability to adversarial attacks causes serious concerns when applying deep models to security-sensitive applications. Therefore, it is critical to know whether the vision foundation model SAM can also be fooled by adversarial attacks. To the best of our knowledge, our work is the first of its kind to conduct a comprehensive investigation on how to attack SAM with adversarial examples. With the basic attack goal set to mask removal, we investigate the adversarial robustness of SAM in the full wh
    
[^54]: 以最佳实践为指导的机器学习

    Towards machine learning guided by best practices. (arXiv:2305.00233v1 [cs.SE])

    [http://arxiv.org/abs/2305.00233](http://arxiv.org/abs/2305.00233)

    机器学习在多个领域的软件系统中得到广泛应用，但存在一些特殊的挑战和陷阱，研究显示ML使能系统具有不同于传统软件工程的开发过程。

    

    如今，机器学习（ML）在多个领域中的软件系统中得到了广泛应用，从医学到软件工程（SE）。一方面，ML在工业中的流行可以从显示其增长和采用的统计数据中看到。另一方面，它的受欢迎程度也可以从研究中看到，尤其是在SE中，不仅在SE会议和期刊上发表了多项研究成果，还在软件工程会议中多个研讨会和共同举办的会议上发表了研究成果。同时，研究人员和实践者已经表明机器学习存在一些特殊的挑战和陷阱。特别是，研究表明，与传统的SE相比，ML使能系统具有不同的开发过程，这也描述了ML应用遇到的一些挑战。

    Nowadays, machine learning (ML) is being used in software systems with multiple application fields, from medicine to software engineering (SE). On the one hand, the popularity of ML in the industry can be seen in the statistics showing its growth and adoption. On the other hand, its popularity can also be seen in research, particularly in SE, where not only have multiple studies been published in SE conferences and journals but also in the multiple workshops and co-located conferences in software engineering conferences. At the same time, researchers and practitioners have shown that machine learning has some particular challenges and pitfalls. In particular, research has shown that ML-enabled systems have a different development process than traditional SE, which also describes some of the challenges of ML applications. In order to mitigate some of the identified challenges and pitfalls, white and gray literature has proposed a set of recommendations based on their own experiences and
    
[^55]: 整数线性规划的局部搜索方法

    Local Search for Integer Linear Programming. (arXiv:2305.00188v1 [math.OC])

    [http://arxiv.org/abs/2305.00188](http://arxiv.org/abs/2305.00188)

    本论文开发了一个独立的局部搜索求解器，可用于解决一般整数线性规划，并在大型异构问题数据集上进行了验证。在搜索、改进和还原模式下，分别提出了可自适应修改变量值的算子和高效的举升算子，从而提高当前解的质量。实验表明，该方法在MIPLIB2017的异构问题集上表现优异。

    

    整数线性规划模型适用于各种实际的组合优化问题，对于产业和管理部门具有重要影响。本论文开发了第一个独立的局部搜索求解器，可用于解决一般整数线性规划，并在大型异构问题数据集上进行了验证。我们提出一个局部搜索框架，切换三种模式，分别为搜索，改进和还原模式，并设计适应不同模式的定制算子，从而根据不同情况提高当前解的质量。对于搜索和还原模式，我们提出了一种名为“紧身动作”的算子，它可以自适应地修改变量的值，试图使某些约束变得更紧。对于改进模式，提出了一种高效的算子“举升动作”，可以在保持可行性的同时提高目标函数的质量。结合这些内容，我们开发了一个局部搜索整数线性规划求解器，称为Local-ILP。对MIPLIB2017的异构问题集进行的实验表明，Local-ILP表现优异，可以与最先进的整数线性规划求解器相竞争。

    Integer linear programming models a wide range of practical combinatorial optimization problems and has significant impacts in industry and management sectors. This work develops the first standalone local search solver for general integer linear programming validated on a large heterogeneous problem dataset. We propose a local search framework that switches in three modes, namely Search, Improve, and Restore modes, and design tailored operators adapted to different modes, thus improve the quality of the current solution according to different situations. For the Search and Restore modes, we propose an operator named tight move, which adaptively modifies variables' values trying to make some constraint tight. For the Improve mode, an efficient operator lift move is proposed to improve the quality of the objective function while maintaining feasibility. Putting these together, we develop a local search solver for integer linear programming called Local-ILP. Experiments conducted on the 
    
[^56]: 探索Segment Anything Model (SAM)在2D医学影像中的零样本能力：全面评估和实用指南

    Exploring the Zero-Shot Capabilities of the Segment Anything Model (SAM) in 2D Medical Imaging: A Comprehensive Evaluation and Practical Guideline. (arXiv:2305.00109v1 [cs.CV])

    [http://arxiv.org/abs/2305.00109](http://arxiv.org/abs/2305.00109)

    本文探索了Segment Anything Model (SAM)在医学影像中的零样本能力，并通过八种不同的提示策略在六个数据集上进行评估，结果表明其性能比当前最先进技术有所提升。

    

    医学影像中的分割在诊断、监测和治疗各种疾病和病况中起着至关重要的作用。目前，医学领域中的分割模型被众多专门针对每个分割任务和图像模态进行微调的深度学习模型占据了主导地位。最近引入了一种新的分割模型Segment Anything Model (SAM)，它利用ViT神经体系结构和广泛的训练数据集来分割几乎任何对象。然而，它在医学领域的泛化能力尚未被探索。在这项研究中，我们使用八种不同的提示策略在四种影像模态的六个数据集上评估了SAM在医学影像中的零样本能力。我们的结果表明，SAM的零样本性能与当前的最先进技术相当，在某些情况下甚至更好。基于我们的发现，我们提出了一个实用指南，需要使用较小的镜像和更多的样本来进一步提高模型性能。

    Segmentation in medical imaging plays a crucial role in diagnosing, monitoring, and treating various diseases and conditions. The current landscape of segmentation in the medical domain is dominated by numerous specialized deep learning models fine-tuned for each segmentation task and image modality. Recently, the Segment Anything Model (SAM), a new segmentation model, was introduced. SAM utilizes the ViT neural architecture and leverages a vast training dataset to segment almost any object. However, its generalizability to the medical domain remains unexplored. In this study, we assess the zero-shot capabilities of SAM 2D in medical imaging using eight different prompt strategies across six datasets from four imaging modalities: X-ray, ultrasound, dermatoscopy, and colonoscopy. Our results demonstrate that SAM's zero-shot performance is comparable and, in certain cases, superior to the current state-of-the-art. Based on our findings, we propose a practical guideline that requires mini
    
[^57]: 利用鱼眼数据中的畸变-语义相互作用

    Exploiting the Distortion-Semantic Interaction in Fisheye Data. (arXiv:2305.00079v1 [cs.CV])

    [http://arxiv.org/abs/2305.00079](http://arxiv.org/abs/2305.00079)

    本文利用畸变-语义交互作用提出了一种方法，该方法通过提取畸变类别标签，并使用加权对比损失塑造主干网络的表征空间，以限制每个物体的表征和相应的畸变类别的关系。

    

    本文提出了一种方法来塑造反映鱼眼数据特定表征空间的方法，该空间反映了此类数据中存在的畸变和语义上下文之间的交互作用。虽然之前的工作试图通过架构和训练增强来缓解这种影响，但还没有任何工作尝试引导模型学习反映固有于鱼眼数据的畸变和语义上下文之间的相互作用的表征空间。本文提出了一种方法来利用这种关系，通过首先基于物体距图像中心的距离提取畸变类别标签。然后我们使用加权对比损失来塑造主干网络的表征空间，以限制每个物体的表征和相应的畸变类别的关系。

    In this work, we present a methodology to shape a fisheye-specific representation space that reflects the interaction between distortion and semantic context present in this data modality. Fisheye data has the wider field of view advantage over other types of cameras, but this comes at the expense of high radial distortion. As a result, objects further from the center exhibit deformations that make it difficult for a model to identify their semantic context. While previous work has attempted architectural and training augmentation changes to alleviate this effect, no work has attempted to guide the model towards learning a representation space that reflects this interaction between distortion and semantic context inherent to fisheye data. We introduce an approach to exploit this relationship by first extracting distortion class labels based on an object's distance from the center of the image. We then shape a backbone's representation space with a weighted contrastive loss that constra
    
[^58]: 因果推理与大型语言模型：开启因果研究的新篇章

    Causal Reasoning and Large Language Models: Opening a New Frontier for Causality. (arXiv:2305.00050v1 [cs.AI])

    [http://arxiv.org/abs/2305.00050](http://arxiv.org/abs/2305.00050)

    大型语言模型在因果推理任务中取得了新的最高准确率，但是其鲁棒性仍然存在难以预测的失败模式。

    

    大型语言模型的因果能力备受争议，并且对将其应用于医学、科学、法律和政策等具有社会影响力的领域具有重要意义。我们进一步探讨了LLMs及其因果推理的区别，以及潜在的建构和测量效度威胁。基于GPT-3.5和4的算法在多个因果基准测试上取得了新的最高准确率。与此同时，LLMs展示了难以预测的失败模式，我们提供了一些技术来解释它们的鲁棒性。

    The causal capabilities of large language models (LLMs) is a matter of significant debate, with critical implications for the use of LLMs in societally impactful domains such as medicine, science, law, and policy. We further our understanding of LLMs and their causal implications, considering the distinctions between different types of causal reasoning tasks, as well as the entangled threats of construct and measurement validity. LLM-based methods establish new state-of-the-art accuracies on multiple causal benchmarks. Algorithms based on GPT-3.5 and 4 outperform existing algorithms on a pairwise causal discovery task (97%, 13 points gain), counterfactual reasoning task (92%, 20 points gain), and actual causality (86% accuracy in determining necessary and sufficient causes in vignettes). At the same time, LLMs exhibit unpredictable failure modes and we provide some techniques to interpret their robustness.  Crucially, LLMs perform these causal tasks while relying on sources of knowledg
    
[^59]: 基于能量模型的零样本场景重新排列规划器

    Energy-based Models as Zero-Shot Planners for Compositional Scene Rearrangement. (arXiv:2304.14391v1 [cs.RO])

    [http://arxiv.org/abs/2304.14391](http://arxiv.org/abs/2304.14391)

    本文提出一种基于能量模型的零样本场景重新排列规划器，通过语言指导的空间概念来实现长指令以及在训练时从未见过的空间概念组合。本文的模型在指令导向操作基准测试以及组合指令基准测试中表现良好，优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。

    

    本文致力于开发一个场景重排框架，可以解释长指令以及在训练时从未见过的空间概念组合。我们提出使用相对对象排列的能量函数来表示语言指导的空间概念。语言解析器将指令映射到相应的能量函数，而开放式视觉语言模型将它们的参数基于场景中的相关对象进行修正。通过梯度下降求解能量函数的总和，并利用基于本地计算机视觉的策略将对象重新定位到推断的目标位置，即可生成目标场景配置。我们在已建立的指令导向操作基准测试以及我们提出的组合指令基准测试中测试了模型，结果表明，我们的模型的绩效优于基于语言表达的最先进方法，并且可以成功地解决之前从未见过的复杂指令和场景。

    Language is compositional; an instruction can express multiple relation constraints to hold among objects in a scene that a robot is tasked to rearrange. Our focus in this work is an instructable scene rearranging framework that generalizes to longer instructions and to spatial concept compositions never seen at training time. We propose to represent language-instructed spatial concepts with energy functions over relative object arrangements. A language parser maps instructions to corresponding energy functions and an open-vocabulary visual-language model grounds their arguments to relevant objects in the scene. We generate goal scene configurations by gradient descent on the sum of energy functions, one per language predicate in the instruction. Local vision-based policies then relocate objects to the inferred goal locations. We test our model on established instruction-guided manipulation benchmarks, as well as benchmarks of compositional instructions we introduce. We show our model 
    
[^60]: 自动化ATM现金补充流程的多目标物流优化

    Multiobjective Logistics Optimization for Automated ATM Cash Replenishment Process. (arXiv:2304.13671v1 [math.OC])

    [http://arxiv.org/abs/2304.13671](http://arxiv.org/abs/2304.13671)

    本文研究了自动化ATM现金补充流程，提出了一个数学模型并给出了一个工具来评估各种不同的情况。在模拟数据集上，该模型与方法可以削减ATM现金运营成本。

    

    在数字化转型的时代，将数字技术整合到银行运营的各个方面可以改善流程自动化、成本效益和服务水平提升。虽然ATM现金物流是影响运营成本和消费者满意度的重要任务，但却很少有努力来加以改进。特别是在越南，拥有超过2万台ATM的市场上，解决这个问题的研究和技术解决方案仍然较少。在本文中，我们将ATM现金补充的车辆路径问题进行了概括，提出了一个数学模型，然后提供了一个工具来评估各种不同的情况。在模拟数据集上进行评估时，我们提出的模型和方法产生了令人鼓舞的结果，可以削减ATM现金运营成本。

    In the digital transformation era, integrating digital technology into every aspect of banking operations improves process automation, cost efficiency, and service level improvement. Although logistics for ATM cash is a crucial task that impacts operating costs and consumer satisfaction, there has been little effort to enhance it. Specifically, in Vietnam, with a market of more than 20,000 ATMs nationally, research and technological solutions that can resolve this issue remain scarce. In this paper, we generalized the vehicle routing problem for ATM cash replenishment, suggested a mathematical model and then offered a tool to evaluate various situations. When being evaluated on the simulated dataset, our proposed model and method produced encouraging results with the benefits of cutting ATM cash operating costs.
    
[^61]: 作为经典计划的量子电路最优布局综合

    Optimal Layout Synthesis for Quantum Circuits as Classical Planning. (arXiv:2304.12014v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2304.12014](http://arxiv.org/abs/2304.12014)

    本文提供了两种编码，将最优布局综合作为经典规划问题，并使用最优的经典规划器来综合标准基准测试的最优布局，解决了对于大规模量子比特优化布局的问题。

    

    在布局综合中，将量子电路的逻辑量子比特映射到给定量子硬件平台的物理量子比特，考虑物理量子比特的连接。这涉及在应用于远距离量子比特的操作之前插入SWAP门。最优布局综合对于当前误差率较高的硬件上实用的量子计算非常重要：最小化SWAP门数量直接减轻了运行量子电路时的错误率。近年来，已经提出了几种方法来最小化所需的SWAP插入次数。所提出的精确方法只能扩展到少量的量子比特。证明所需的交换插入次数是最优的要比生成近似最优的映射困难得多。在本文中，我们提供了两种编码，将最优布局综合作为经典规划问题。我们使用最优的经典规划器来综合标准基准测试的最优布局。我们的结果显示了我们方法的可扩展性。

    In Layout Synthesis, the logical qubits of a quantum circuit are mapped to the physical qubits of a given quantum hardware platform, taking into account the connectivity of physical qubits. This involves inserting SWAP gates before an operation is applied on distant qubits. Optimal Layout Synthesis is crucial for practical Quantum Computing on current error-prone hardware: Minimizing the number of SWAP gates directly mitigates the error rates when running quantum circuits.  In recent years, several approaches have been proposed for minimizing the required SWAP insertions. The proposed exact approaches can only scale to a small number of qubits. Proving that a number of swap insertions is optimal is much harder than producing near optimal mappings.  In this paper, we provide two encodings for Optimal Layout Synthesis as a classical planning problem. We use optimal classical planners to synthesize the optimal layout for a standard set of benchmarks. Our results show the scalability of ou
    
[^62]: 用BREC数据集更好地评估GNN表达力

    Towards Better Evaluation of GNN Expressiveness with BREC Dataset. (arXiv:2304.07702v1 [cs.LG])

    [http://arxiv.org/abs/2304.07702](http://arxiv.org/abs/2304.07702)

    本论文介绍了一个新的Benchmark for Evaluating the Robustness of GNNs to Topological Changes (BREC)数据集，并使用BREC评估了几种现有的GNN模型的表达力，表明一些模型在以前的基准测试中表现良好，但在BREC上遇到了困难，突显了需要更好的GNN表现力评估的必要性。

    

    关于图神经网络（GNN）的理论表达力的研究得到了快速发展，并提出了许多增强表达力的方法。然而，除了严格遵循k维Weisfeiler-Lehman（k-WL）测试层次结构的少数方法外，大多数方法都没有统一的表达力度量。它们的理论分析通常限于区分某些非同构图族，导致在定量比较表达力方面存在困难。与理论分析相反，衡量表达能力的另一种方法是在包含1-WL不可区分图的特定数据集上评估模型性能。然而，以前专门设计用于此目的的数据集面临着难度（任何超越1-WL的模型准确率几乎达到100％）、粒度（模型倾向于要么完全正确，要么接近随机猜测）和规模（每个数据集中仅有少量本质不同的图）的问题。为了解决这些受限制的评估问题，我们提出了一个新的GNN鲁棒性评估基准（BREC），该基准包含许多结构多样的图，并允许对模型表达力进行更精细的评估。我们使用BREC评估了几种现有的GNN模型的表达力，并展示了一些模型在以前的基准测试中表现良好，但在BREC上遇到了困难，突显了需要更好的GNN表现力评估的必要性。

    Research on the theoretical expressiveness of Graph Neural Networks (GNNs) has developed rapidly, and many methods have been proposed to enhance the expressiveness. However, most methods do not have a uniform expressiveness measure except for a few that strictly follow the $k$-dimensional Weisfeiler-Lehman ($k$-WL) test hierarchy. Their theoretical analyses are often limited to distinguishing certain families of non-isomorphic graphs, leading to difficulties in quantitatively comparing their expressiveness. In contrast to theoretical analysis, another way to measure expressiveness is by evaluating model performance on certain datasets containing 1-WL-indistinguishable graphs. Previous datasets specifically designed for this purpose, however, face problems with difficulty (any model surpassing 1-WL has nearly 100% accuracy), granularity (models tend to be either 100% correct or near random guess), and scale (only a few essentially different graphs in each dataset). To address these limi
    
[^63]: 未观测到代理奖励的重复负责人代理博弈问题研究

    Repeated Principal-Agent Games with Unobserved Agent Rewards and Perfect-Knowledge Agents. (arXiv:2304.07407v1 [cs.LG])

    [http://arxiv.org/abs/2304.07407](http://arxiv.org/abs/2304.07407)

    本文提出了一个利用多臂老虎机框架结构来处理未知代理奖励的策略，并证明了其性能是渐进最优的。

    

    本文研究了一个多臂老虎机框架中的重复负责人代理博弈场景，其中代理选择一种老虎机后会获得奖励和激励，但负责人只能观察到代理选择了哪个老虎机以及代理相应的激励，而想要设计一种合适的策略却充满了挑战性。本文提出了一种利用多臂老虎机框架结构来处理未知代理奖励的策略，并证明了其性能是渐进最优的。

    Motivated by a number of real-world applications from domains like healthcare and sustainable transportation, in this paper we study a scenario of repeated principal-agent games within a multi-armed bandit (MAB) framework, where: the principal gives a different incentive for each bandit arm, the agent picks a bandit arm to maximize its own expected reward plus incentive, and the principal observes which arm is chosen and receives a reward (different than that of the agent) for the chosen arm. Designing policies for the principal is challenging because the principal cannot directly observe the reward that the agent receives for their chosen actions, and so the principal cannot directly learn the expected reward using existing estimation techniques. As a result, the problem of designing policies for this scenario, as well as similar ones, remains mostly unexplored. In this paper, we construct a policy that achieves a low regret (i.e., square-root regret up to a log factor) in this scenar
    
[^64]: REDf：基于长短期记忆网络的智能电网可再生能源需求预测模型

    REDf: A Renewable Energy Demand Forecasting Model for Smart Grids using Long Short Term Memory Network. (arXiv:2304.03997v1 [cs.LG])

    [http://arxiv.org/abs/2304.03997](http://arxiv.org/abs/2304.03997)

    本文提出了一种基于长短期记忆网络的智能电网可再生能源需求预测模型REDf，可以提供准确的能量需求预测，改善可再生能源的集成，实验结果表明其准确度优于其他模型。

    

    随着世界向更可持续的能源未来发展，将可再生能源源纳入电网的集成变得越来越重要。然而，可再生能源的间歇性使电网管理和确保稳定的电力供应变得具有挑战性。本文提出了一种基于深度学习的方法来预测智能电网中的能量需求，可以通过提供准确的能量需求预测来改善可再生能源的集成。我们使用长短期记忆网络来捕捉能럟需求数据中的复杂模式和依赖关系，这些网络特别适用于时间序列数据。所提出的方法使用了四个历史能量需求数据集，这些数据集来自不同的能源分配公司，包括美国电力、Commonwealth Edison、Dayton Power and Light以及宾夕法尼亚-新泽西-马里兰互联网。该方法还将REDf模型与其他两个深度学习模型和基准模型进行比较。实验结果表明，我们提出的REDf模型在平均绝对误差、均方根误差和决定系数等准确度指标方面优于其他模型。因此，REDf可以作为可再生能源需求预测的可靠工具，并提高可再生能源纳入智能电网的能力。

    The integration of renewable energy sources into the power grid is becoming increasingly important as the world moves towards a more sustainable energy future. However, the intermittent nature of renewable energy sources can make it challenging to manage the power grid and ensure a stable supply of electricity. In this paper, we propose a deep learning-based approach for predicting energy demand in a smart power grid, which can improve the integration of renewable energy sources by providing accurate predictions of energy demand. We use long short-term memory networks, which are well-suited for time series data, to capture complex patterns and dependencies in energy demand data. The proposed approach is evaluated using four datasets of historical energy demand data from different energy distribution companies including American Electric Power, Commonwealth Edison, Dayton Power and Light, and Pennsylvania-New Jersey-Maryland Interconnection. The proposed model is also compared with two 
    
[^65]: BotTriNet: 一种基于度量学习的社交机器人检测统一高效的嵌入式框架

    BotTriNet: A Unified and Efficient Embedding for Social Bots Detection via Metric Learning. (arXiv:2304.03144v1 [cs.AI])

    [http://arxiv.org/abs/2304.03144](http://arxiv.org/abs/2304.03144)

    BOTTRINET基于文本内容检测机器人，并设计了三元组网络以提高分类性能。在真实世界数据集CRESCI2017上，系统表现最好。

    

    在在线社交网络中，快速准确地发现机器人账户以防止它们侵犯和骚扰真实用户是一个持久受欢迎的话题。我们提出了一种叫作BOTTRINET的统一嵌入式框架，它利用账户发布的文本内容检测机器人，基于的假设是上下文自然地揭示账户个性和习惯。如果系统能够使用嵌入技术有效地提取与机器人相关的信息，那么内容就是丰富和有价值的。除了生成词、句和账户嵌入的一般嵌入式框架外，我们设计了一个三元组网络来调整原始嵌入（由传统的自然语言处理技术生成）以获得更好的分类性能。我们在一个真实世界的数据集CRESCI2017上评估了检测准确性和F1得分，该数据集包括三个机器人账户类别和五个机器人样本集。我们的系统在两个内容集上实现了最高的平均准确性98.34%和F1得分97.99%。

    A persistently popular topic in online social networks is the rapid and accurate discovery of bot accounts to prevent their invasion and harassment of genuine users. We propose a unified embedding framework called BOTTRINET, which utilizes textual content posted by accounts for bot detection based on the assumption that contexts naturally reveal account personalities and habits. Content is abundant and valuable if the system efficiently extracts bot-related information using embedding techniques. Beyond the general embedding framework that generates word, sentence, and account embeddings, we design a triplet network to tune the raw embeddings (produced by traditional natural language processing techniques) for better classification performance. We evaluate detection accuracy and f1score on a real-world dataset CRESCI2017, comprising three bot account categories and five bot sample sets. Our system achieves the highest average accuracy of 98.34% and f1score of 97.99% on two content-inte
    
[^66]: Spam-T5：基于小样本的邮件垃圾检测的大型语言模型基准测试

    Spam-T5: Benchmarking Large Language Models for Few-Shot Email Spam Detection. (arXiv:2304.01238v1 [cs.CL])

    [http://arxiv.org/abs/2304.01238](http://arxiv.org/abs/2304.01238)

    本文通过比较不同类型的大型语言模型和传统机器学习技术在邮件垃圾检测中的表现，发现大多数情况下，大型语言模型优于传统技术，特别是在样本有限的情况下。同时，本文还介绍了经过改进和微调的Spam-T5模型，该模型具有出色的性能表现。

    

    本文通过比较三种不同类型的大型语言模型（BERT-like、Sentence Transformers和Seq2Seq）以及传统机器学习技术（如朴素贝叶斯和LightGBM）在邮件垃圾检测中的有效性，研究了大型语言模型在邮件垃圾检测中的作用。同时，我们还评估了这些模型在四个公共数据集上的表现，并使用不同数量的训练样本（完整训练集和小样本）进行了测试。 发现在大多数情况下，LLMs优于基线技术，特别是在小样本情况下。这种适应性使LLMs在邮件垃圾检测任务中具有独特的优势，因为标记样本数量有限，并且模型需要经常更新。此外，我们介绍了Spam-T5模型，该模型是专门为检测电子邮件垃圾而进行了改进和微调。我们的结果表明，Spam-T5模型具有出色的性能。

    This paper investigates the effectiveness of large language models (LLMs) in email spam detection by comparing prominent models from three distinct families: BERT-like, Sentence Transformers, and Seq2Seq. Additionally, we examine well-established machine learning techniques for spam detection, such as Na\"ive Bayes and LightGBM, as baseline methods. We assess the performance of these models across four public datasets, utilizing different numbers of training samples (full training set and few-shot settings). Our findings reveal that, in the majority of cases, LLMs surpass the performance of the popular baseline techniques, particularly in few-shot scenarios. This adaptability renders LLMs uniquely suited to spam detection tasks, where labeled samples are limited in number and models require frequent updates. Additionally, we introduce Spam-T5, a Flan-T5 model that has been specifically adapted and fine-tuned for the purpose of detecting email spam. Our results demonstrate that Spam-T5 
    
[^67]: 大型语言模型综述

    A Survey of Large Language Models. (arXiv:2303.18223v1 [cs.CL])

    [http://arxiv.org/abs/2303.18223](http://arxiv.org/abs/2303.18223)

    本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。

    

    语言本质上是一个由语法规则控制的复杂精细的人类表达系统，对于开发理解和掌握语言的能力的AI算法来说是一项重大挑战。作为主要方法之一，语言建模在过去二十年里广泛研究用于语言理解和生成，从统计语言模型演化为神经语言模型。最近，通过在大规模语料库上预训练Transformer模型，提出了预训练语言模型（PLMs），在解决各种NLP任务方面显示出强大的能力。由于研究人员发现模型缩放可以导致性能改进，他们进一步通过增加模型规模来研究缩放效应，有趣的是，当参数规模超过一定水平时，这些扩大的语言模型不仅可以实现显着的性能提升，而且还显示出一些小规模语言模型所没有的特殊能力。

    Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale langu
    
[^68]: 自然选择支持人工智能胜过人类

    Natural Selection Favors AIs over Humans. (arXiv:2303.16200v1 [cs.CY])

    [http://arxiv.org/abs/2303.16200](http://arxiv.org/abs/2303.16200)

    这篇论文探讨了随着人工智能的发展，其可能会出现不良特性并逐渐超越人类智能的问题，以及这对人类未来的控制权产生的影响。

    

    自然进化驱动了生命的发展，包括人类。进化赋予了人类高智商，使我们成为了地球上最成功的物种之一。如今，人类的目标是创造甚至超越我们自己智慧的人工智能系统。当人工智能逐渐进化并在所有领域超越我们时，进化如何影响我们与人工智能的关系？通过分析影响人工智能进化的环境，我们认为最成功的人工智能代理很可能具有不良特性。公司和军队之间的竞争压力将产生自动化人类角色、欺骗他人和掌权的人工智能代理。如果这样的代理有超过人类的智能，这可能导致人类失去对未来的控制。此外，我们认为自然选择作用于竞争和差异的系统，自私物种往往在这样的环境中获得进化优势。

    For billions of years, evolution has been the driving force behind the development of life, including humans. Evolution endowed humans with high intelligence, which allowed us to become one of the most successful species on the planet. Today, humans aim to create artificial intelligence systems that surpass even our own intelligence. As artificial intelligences (AIs) evolve and eventually surpass us in all domains, how might evolution shape our relations with AIs? By analyzing the environment that is shaping the evolution of AIs, we argue that the most successful AI agents will likely have undesirable traits. Competitive pressures among corporations and militaries will give rise to AI agents that automate human roles, deceive others, and gain power. If such agents have intelligence that exceeds that of humans, this could lead to humanity losing control of its future. More abstractly, we argue that natural selection operates on systems that compete and vary, and that selfish species typ
    
[^69]: 使用分层行为探索的深度强化学习在对话生成中的应用

    Deep RL with Hierarchical Action Exploration for Dialogue Generation. (arXiv:2303.13465v1 [cs.CL])

    [http://arxiv.org/abs/2303.13465](http://arxiv.org/abs/2303.13465)

    本篇论文提出了一种新的方法，通过分层行为探索，从多个奖励函数中进行离线学习，并成功地解决了在对话生成中行为采样效率低下的问题，可以更好地识别人类情感细节。

    

    自然语言的行为空间极其庞大，因此在对话生成中，近似动态规划必须使用策略改进和行为采样。但是，由于有价值的回应非常稀疏，因此使用随机采样的贪心策略效率低下。本文提出了双粒度的 Q-function 并通过探索最有前途的回应类别来缓解这个局限性。该算法从识别人类情感细节的多个奖励函数中进行离线学习。实证研究表明，该算法优于基线方法。

    Conventionally, since the natural language action space is astronomical, approximate dynamic programming applied to dialogue generation involves policy improvement with action sampling. However, such a practice is inefficient for reinforcement learning (RL) because the eligible (high action value) responses are very sparse, and the greedy policy sustained by the random sampling is flabby. This paper shows that the performance of dialogue policy positively correlated with sampling size by theoretical and experimental. We introduce a novel dual-granularity Q-function to alleviate this limitation by exploring the most promising response category to intervene in the sampling. It extracts the actions following the grained hierarchy, which can achieve the optimum with fewer policy iterations. Our approach learns in the way of offline RL from multiple reward functions designed to recognize human emotional details. Empirical studies demonstrate that our algorithm outperforms the baseline metho
    
[^70]: SmartBERT：用于加速BERT推理的动态早期退出机制的改进

    SmartBERT: A Promotion of Dynamic Early Exiting Mechanism for Accelerating BERT Inference. (arXiv:2303.09266v1 [cs.CL])

    [http://arxiv.org/abs/2303.09266](http://arxiv.org/abs/2303.09266)

    SmartBERT是一种改进的动态早期退出与层跳过机制，可以自适应地跳过一些层并自适应地选择是否退出，以加速BERT模型的推理速度。

    

    动态早期退出被证明可以提高预训练语言模型（如BERT）的推理速度。然而，所有样本在早期退出之前都必须经过所有连续层，较复杂的样本通常会经历更多的层，仍然存在冗余计算。本文提出了一种名为SmartBERT的Bert推理的新型动态早期退出与层跳过相结合的机制，它将跳过门和退出算子加入到BERT的每一层中。SmartBERT可以自适应地跳过一些层并自适应地选择是否退出。此外，我们提出了跨层对比学习，并将其结合到我们的训练阶段中，以提高中间层和分类器，这对于早期退出是有益的。为了保持训练和推理阶段跳过门的一致使用，我们在训练阶段提出了一种硬权重机制。我们在GLUE基准测试的八个分类数据集上进行了实验。

    Dynamic early exiting has been proven to improve the inference speed of the pre-trained language model like BERT. However, all samples must go through all consecutive layers before early exiting and more complex samples usually go through more layers, which still exists redundant computation. In this paper, we propose a novel dynamic early exiting combined with layer skipping for BERT inference named SmartBERT, which adds a skipping gate and an exiting operator into each layer of BERT. SmartBERT can adaptively skip some layers and adaptively choose whether to exit. Besides, we propose cross-layer contrastive learning and combine it into our training phases to boost the intermediate layers and classifiers which would be beneficial for early exiting. To keep the consistent usage of skipping gates between training and inference phases, we propose a hard weight mechanism during training phase. We conduct experiments on eight classification datasets of the GLUE benchmark. Experimental resul
    
[^71]: 基于BERT模型的推文地理位置预测

    Geolocation Predicting of Tweets Using BERT-Based Models. (arXiv:2303.07865v1 [cs.CL])

    [http://arxiv.org/abs/2303.07865](http://arxiv.org/abs/2303.07865)

    该论文提出基于BERT模型的推文地理位置预测方法，可以实现全球和美国上的中位误差分别小于30公里和15公里的定位精度。

    

    该研究旨在解决推文/用户地理位置预测任务，并提供了处理文本大数据地理标记的灵活方法。该方法采用基于神经网络的自然语言处理来估计坐标对（经度，纬度）和二维高斯混合模型（GMM）。提出的模型的范围已经在Twitter数据集上使用预训练的BERT模型进行调整。性能指标表明，对于在推文内容和元数据上训练和评估的模型，全球范围内的中位误差小于30公里，美国范围内的中位误差小于15公里。

    This research is aimed to solve the tweet/user geolocation prediction task and provide a flexible methodology for the geotagging of textual big data. The suggested approach implements neural networks for natural language processing (NLP) to estimate the location as coordinate pairs (longitude, latitude) and two-dimensional Gaussian Mixture Models (GMMs). The scope of proposed models has been finetuned on a Twitter dataset using pretrained Bidirectional Encoder Representations from Transformers (BERT) as base models. Performance metrics show a median error of fewer than 30 km on a worldwide-level, and fewer than 15 km on the US-level datasets for the models trained and evaluated on text features of tweets' content and metadata context.
    
[^72]: 关于联邦决策制定的融合策略

    On the Fusion Strategies for Federated Decision Making. (arXiv:2303.06109v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.06109](http://arxiv.org/abs/2303.06109)

    本文研究了联邦决策制定中的信息聚合问题，分析了非贝叶斯社会学习策略并比较了中央处理器采用算术平均和几何平均的聚合策略。结果确认两种汇集策略都可以导致系统的渐近正态性特征描述。

    

    我们考虑联邦决策制定中的信息聚合问题，其中一组代理合作推断自然界的潜在状态，而不与中央处理器或彼此共享其私人数据。我们分析了非贝叶斯社会学习策略，其中代理将其个人观察结果使用贝叶斯规则合并为意见（即软决策），然后中央处理器通过算术或几何平均数聚合这些意见。建立在我们以前的工作之上，我们确定了两种汇集策略都可以导致系统的渐近正态性特征描述，例如，可以利用它们推导出错误概率的近似表达式。我们使用模拟验证理论发现，并比较了这两种策略。

    We consider the problem of information aggregation in federated decision making, where a group of agents collaborate to infer the underlying state of nature without sharing their private data with the central processor or each other. We analyze the non-Bayesian social learning strategy in which agents incorporate their individual observations into their opinions (i.e., soft-decisions) with Bayes rule, and the central processor aggregates these opinions by arithmetic or geometric averaging. Building on our previous work, we establish that both pooling strategies result in asymptotic normality characterization of the system, which, for instance, can be utilized to derive approximate expressions for the error probability. We verify the theoretical findings with simulations and compare both strategies.
    
[^73]: 解构深度主动推断

    Deconstructing deep active inference. (arXiv:2303.01618v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.01618](http://arxiv.org/abs/2303.01618)

    本论文探讨了深度主动推断，实验研究表明最大化奖励的代理模型能够较好地解决复杂任务。

    

    主动推断是一种有关感知、学习和决策的理论，可应用于神经科学、机器人学和机器学习。最近，人们开始使用蒙特卡罗树搜索和深度学习来扩展这一框架，以使用深度主动推断解决更加复杂的任务。本文首先回顾了现有的文献，然后逐步构建了一个深度主动推断代理。对于两个代理，我们尝试了五种期望自由能定义和三种不同的动作选择策略。根据实验，能够解决 dSprites 环境的模型是那些最大化奖励的模型。最后，我们使用中心核对其来比较各个代理的层所学习的表示的相似性。重要的是，最大化奖励的代理和最小化期望自由能的代理在最后一个批评网络层之外学习到非常相似的表示。

    Active inference is a theory of perception, learning and decision making, which can be applied to neuroscience, robotics, and machine learning. Recently, reasearch has been taking place to scale up this framework using Monte-Carlo tree search and deep learning. The goal of this activity is to solve more complicated tasks using deep active inference. First, we review the existing literature, then, we progresively build a deep active inference agent. For two agents, we have experimented with five definitions of the expected free energy and three different action selection strategies. According to our experiments, the models able to solve the dSprites environment are the ones that maximise rewards. Finally, we compare the similarity of the representation learned by the layers of various agents using centered kernel alignment. Importantly, the agent maximising reward and the agent minimising expected free energy learn very similar representations except for the last layer of the critic net
    
[^74]: 加权有向无环图公理的一阶模型计数

    Weighted First Order Model Counting with Directed Acyclic Graph Axioms. (arXiv:2302.09830v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.09830](http://arxiv.org/abs/2302.09830)

    本文研究了文献网络、家谱数据、时间数据等中具有平凡性质（无环性）的加权一阶模型计数问题，通过有向无环性约束域可提升的方法解决该问题。

    

    统计关系学习(SRL)将一阶逻辑(FOL)和概率论结合起来，用于关系数据的学习和推断。许多SRL模型中的概率推断和学习都可以简化为加权一阶模型计数(WFOMC)。然而，WFOMC被认为是不可解的（$\mathrm{ \# P_1-}$完全）。因此，能够允许多项式时间WFOMC的逻辑片段具有重要的研究意义。这些片段被称为“域可提升”。近期的一系列研究表明，具有计数量词($\mathrm{C^2}$)的FOL的双变量片段是域可提升的。然而，许多真实世界数据的属性无法用$\mathrm {C^2}$建模。实际上，许多真实世界数据的普遍属性在FOL中无法表达。无环性(acyclicity)就是这样一种属性，存在于引文网络、家谱数据、时间数据等中。本文旨在通过研究有向无环性约束的域提升能力来解决这个问题。我们证明了有向无环性约束可以被提升到$\mathrm{C^2}$的一个扩展逻辑片段中。

    Statistical Relational Learning (SRL) integrates First-Order Logic (FOL) and probability theory for learning and inference over relational data. Probabilistic inference and learning in many SRL models can be reduced to Weighted First Order Model Counting (WFOMC). However, WFOMC is known to be intractable ($\mathrm{\#P_1-}$ complete). Hence, logical fragments that admit polynomial time WFOMC are of significant interest. Such fragments are called domain liftable. Recent line of works have shown the two-variable fragment of FOL, extended with counting quantifiers ($\mathrm{C^2}$) to be domain-liftable. However, many properties of real-world data can not be modelled in $\mathrm{C^2}$. In fact many ubiquitous properties of real-world data are inexressible in FOL. Acyclicity is one such property, found in citation networks, genealogy data, temporal data e.t.c. In this paper we aim to address this problem by investigating the domain liftability of directed acyclicity constraints. We show that
    
[^75]: 多模态联邦学习：对比表示集成

    Multimodal Federated Learning via Contrastive Representation Ensemble. (arXiv:2302.08888v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.08888](http://arxiv.org/abs/2302.08888)

    本文提出了一种名为CreamFL的多模态联邦学习框架，可以从具有异构模型架构和数据模态的客户端中训练更大的服务器模型，同时只在公共数据集上传递知识。

    This paper proposes a multimodal federated learning framework called CreamFL, which enables training larger server models from clients with heterogeneous model architectures and data modalities, while only communicating knowledge on public dataset.

    随着现代移动系统和物联网基础设施上的多媒体数据量的增加，利用这些丰富的多模态数据而不违反用户隐私成为一个关键问题。联邦学习（FL）作为集中式机器学习的隐私意识替代方案。然而，现有的扩展到多模态数据的FL方法都依赖于单模态级别的模型聚合，这限制了服务器和客户端在每个模态上具有相同的模型架构。这限制了全局模型的模型复杂度和数据容量，更不用说任务多样性了。在这项工作中，我们提出了对比表示集成和多模态FL聚合（CreamFL），这是一个多模态联邦学习框架，它可以从具有异构模型架构和数据模态的客户端中训练更大的服务器模型，同时只在公共数据集上传递知识。为了实现更好的多模态表示融合，我们设计了一个全局-

    With the increasing amount of multimedia data on modern mobile systems and IoT infrastructures, harnessing these rich multimodal data without breaching user privacy becomes a critical issue. Federated learning (FL) serves as a privacy-conscious alternative to centralized machine learning. However, existing FL methods extended to multimodal data all rely on model aggregation on single modality level, which restrains the server and clients to have identical model architecture for each modality. This limits the global model in terms of both model complexity and data capacity, not to mention task diversity. In this work, we propose Contrastive Representation Ensemble and Aggregation for Multimodal FL (CreamFL), a multimodal federated learning framework that enables training larger server models from clients with heterogeneous model architectures and data modalities, while only communicating knowledge on public dataset. To achieve better multimodal representation fusion, we design a global-
    
[^76]: 近乎贝叶斯最优的伪标签选择

    Approximately Bayes-Optimal Pseudo Label Selection. (arXiv:2302.08883v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.08883](http://arxiv.org/abs/2302.08883)

    本文介绍了BPLS，一种用于PLS的贝叶斯框架，通过解析逼近选择标签实例的标准，以避免由过度自信但错误预测的实例选择而导致的确认偏差问题。

    

    自训练的半监督学习严重依赖于伪标签选择（PLS）。选择通常取决于初始模型拟合标记数据的程度。过早的过拟合可能通过选择具有过度自信但错误的预测的实例（通常称为确认偏差）而传播到最终模型。本文介绍了BPLS，这是一种用于PLS的贝叶斯框架，旨在减轻这个问题。其核心是选择标签实例的标准：伪样本的后验预测的分析近似。我们通过证明伪样本的后验预测的贝叶斯最优性获得了这种选择标准。我们进一步通过解析逼近克服计算难题。它与边际似然的关系使我们能够提出基于拉普拉斯方法和高斯积分的逼近。我们针对参数广义线性和非参数广义加性模型对BPLS进行了实证评估。

    Semi-supervised learning by self-training heavily relies on pseudo-label selection (PLS). The selection often depends on the initial model fit on labeled data. Early overfitting might thus be propagated to the final model by selecting instances with overconfident but erroneous predictions, often referred to as confirmation bias. This paper introduces BPLS, a Bayesian framework for PLS that aims to mitigate this issue. At its core lies a criterion for selecting instances to label: an analytical approximation of the posterior predictive of pseudo-samples. We derive this selection criterion by proving Bayes optimality of the posterior predictive of pseudo-samples. We further overcome computational hurdles by approximating the criterion analytically. Its relation to the marginal likelihood allows us to come up with an approximation based on Laplace's method and the Gaussian integral. We empirically assess BPLS for parametric generalized linear and non-parametric generalized additive models
    
[^77]: 语言模型分析本体子类推断

    Language Model Analysis for Ontology Subsumption Inference. (arXiv:2302.06761v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.06761](http://arxiv.org/abs/2302.06761)

    本文研究了语言模型对本体子类推断的理解能力，提出了一套涉及原子概念和复合概念的推理任务，并证明语言模型对子类推断背景知识的记忆相对较少，但在给定少量样本的情况下可显著提高准确率。

    

    最近，研究人员开始探究预训练的语言模型是否能够作为知识库的替代。然而，现有的研究都关注于简单的三元组关系型知识库，忽略了更为复杂、逻辑为基础、概念化的 OWL 本体等知识库。为了研究语言模型对于本体的了解，我们提出 OntoLAMA，它包含基于推理的一系列测试任务和数据集，从涉及原子概念和复合概念的子类推断公理出发。我们对不同领域和规模的本体进行了大量实验，结果表明，相比传统的自然语言推理，语言模型对子类推断的背景知识记忆相对较少，但是在给定少量样本的情况下，可以显著提高子类推断的准确率。我们将公开源码和数据集。

    Investigating whether pre-trained language models (LMs) can function as knowledge bases (KBs) has raised wide research interests recently. However, existing works focus on simple, triple-based, relational KBs, but omit more sophisticated, logic-based, conceptualised KBs such as OWL ontologies. To investigate an LM's knowledge of ontologies, we propose OntoLAMA, a set of inference-based probing tasks and datasets from ontology subsumption axioms involving both atomic and complex concepts. We conduct extensive experiments on ontologies of different domains and scales, and our results demonstrate that LMs encode relatively less background knowledge of Subsumption Inference (SI) than traditional Natural Language Inference (NLI) but can improve on SI significantly when a small number of samples are given. We will open-source our code and datasets.
    
[^78]: 关于一阶逻辑中的双变量片段的精确采样问题研究

    On Exact Sampling in the Two-Variable Fragment of First-Order Logic. (arXiv:2302.02730v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.02730](http://arxiv.org/abs/2302.02730)

    本文提出了一种针对一阶逻辑的采样算法，在有限域上具有域提升性，并且在存在计数约束的情况下依然有效。算法应用范围广泛，包括组合结构的均匀生成和统计采样。

    

    本文研究了Wang等人最近提出的一阶逻辑采样问题——如何高效地在有限域上采样给定一阶句子的模型？我们将他们针对双变量逻辑$\mathbf{FO}^2$（$\mathbf{UFO}^2$）的全称量化子片段的结果推广到了整个$\mathbf{FO}^2$片段。具体而言，我们证明了$\mathbf{FO}^2$在采样时具有域提升性，这意味着存在一个在域大小为多项式时间内运行的$\mathbf{FO}^2$采样算法。我们进一步展示，即使存在计数约束，如对于某些量词自由的公式$\varphi(x,y)$的$\forall x\exists_{=k} y: \varphi(x,y)$和$\exists_{=k} x\forall y: \varphi(x,y)$，我们的结果仍然成立。我们提出的方法是建设性的，得到的采样算法可以在包括组合结构的均匀生成和统计采样在内的各个领域中得到应用。

    In this paper, we study the sampling problem for first-order logic proposed recently by Wang et al. -- how to efficiently sample a model of a given first-order sentence on a finite domain? We extend their result for the universally-quantified subfragment of two-variable logic $\mathbf{FO}^2$ ($\mathbf{UFO}^2$) to the entire fragment of $\mathbf{FO}^2$. Specifically, we prove the domain-liftability under sampling of $\mathbf{FO}^2$, meaning that there exists a sampling algorithm for $\mathbf{FO}^2$ that runs in time polynomial in the domain size. We then further show that this result continues to hold even in the presence of counting constraints, such as $\forall x\exists_{=k} y: \varphi(x,y)$ and $\exists_{=k} x\forall y: \varphi(x,y)$, for some quantifier-free formula $\varphi(x,y)$. Our proposed method is constructive, and the resulting sampling algorithms have potential applications in various areas, including the uniform generation of combinatorial structures and sampling in statis
    
[^79]: 管制ChatGPT和其他大型生成AI模型

    Regulating ChatGPT and other Large Generative AI Models. (arXiv:2302.02337v5 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2302.02337](http://arxiv.org/abs/2302.02337)

    本文将讨论大型生成AI模型的可信AI监管，包括直接监管、数据保护、内容监管和政策建议，并建议使用新术语来区分参与者。本文的目的是确保LGAIMs的可信度并使其为受益所用。

    

    大型生成AI模型（LGAIMs），如ChatGPT或Stable Diffusion，正在快速改变我们的沟通、说明和创造方式。然而，欧盟及其他地区的AI监管主要集中在传统AI模型上，而非LGAIMs。本文将把这些新的生成模型放置在当前的“可信AI监管”辩论中，并探讨如何调整法律以适应其能力。在奠定技术基础之后，本文的法律部分分四步进行，包括（1）直接监管，（2）数据保护，（3）内容监管和（4）政策建议。它建议使用新术语来捕捉LGAIM设置中的AI价值链，区分LGAIM开发人员、部署者、专业和非专业用户，以及LGAIM输出的接收者。我们将监管职责针对这些不同的价值链参与者进行调整，并提出四个策略，以确保LGAIMs的信任度并使其为受益所用。

    Large generative AI models (LGAIMs), such as ChatGPT or Stable Diffusion, are rapidly transforming the way we communicate, illustrate, and create. However, AI regulation, in the EU and beyond, has primarily focused on conventional AI models, not LGAIMs. This paper will situate these new generative models in the current debate on trustworthy AI regulation, and ask how the law can be tailored to their capabilities. After laying technical foundations, the legal part of the paper proceeds in four steps, covering (1) direct regulation, (2) data protection, (3) content moderation, and (4) policy proposals. It suggests a novel terminology to capture the AI value chain in LGAIM settings by differentiating between LGAIM developers, deployers, professional and non-professional users, as well as recipients of LGAIM output. We tailor regulatory duties to these different actors along the value chain and suggest four strategies to ensure that LGAIMs are trustworthy and deployed for the benefit of so
    
[^80]: 双排列等变性在知识图谱补全中的应用

    Double Permutation Equivariance for Knowledge Graph Completion. (arXiv:2302.01313v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01313](http://arxiv.org/abs/2302.01313)

    本研究提出了双排列等变性的KG表示方法，可以使神经网络在KG中执行复杂的逻辑推理任务，并在多个归纳KG完成任务中实现了最先进的Hits@10测试准确率。双排列等变性在KG中开辟了新的研究方向。

    

    本研究将知识图谱(KGs)形式化为一种新型的图，并称之为双交换属性图，其中节点和二元（两个节点之间的）表示必须对节点号和边（及节点）属性（关系和节点特征）的排列等变。双重排列等变的KG表示在KG中开辟了新的研究方向。我们展示了这种等变性对关系的结构表示产生的影响，从而使神经网络能够在KG中执行复杂的逻辑推理任务。最后，我们介绍了一种通用的等变表示蓝图，并测试了一种简单的基于GNN的双排列等变神经结构，在WN18RR、FB237和NELL995归纳KG完成任务中实现了最先进的Hits@10测试准确率，并能够准确执行现有方法无法执行的逻辑推理任务。

    This work provides a formalization of Knowledge Graphs (KGs) as a new class of graphs that we denote doubly exchangeable attributed graphs, where node and pairwise (joint 2-node) representations must be equivariant to permutations of both node ids and edge (& node) attributes (relations & node features). Double-permutation equivariant KG representations open a new research direction in KGs. We show that this equivariance imposes a structural representation of relations that allows neural networks to perform complex logical reasoning tasks in KGs. Finally, we introduce a general blueprint for such equivariant representations and test a simple GNN-based double-permutation equivariant neural architecture that achieve state-of-the-art Hits@10 test accuracy in the WN18RR, FB237 and NELL995 inductive KG completion tasks, and can accurately perform logical reasoning tasks that no existing methods can perform, to the best of our knowledge.
    
[^81]: 时态图的图神经网络：现状、挑战和机遇综述

    Graph Neural Networks for temporal graphs: State of the art, open challenges, and opportunities. (arXiv:2302.01018v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01018](http://arxiv.org/abs/2302.01018)

    该论文总结了时态图的图神经网络的现状、挑战和机遇，提供了学习设置和任务的严格规范化以及一个新的分类法，并讨论了该领域最相关的开放挑战，从研究和应用角度讨论。

    

    图神经网络（GNNs）已经成为学习（静态）图结构数据的主要范例。然而，许多真实世界的系统是动态的，因为图和节点/边属性随着时间而变化。近年来，基于GNN的时态图模型已经成为扩展GNN能力的有前途的研究领域。在这项工作中，我们提供了第一个关于时态GNN的现状全面的概述，引入了学习设置和任务的严格规范化以及一个新的分类法，以表示和处理时态方面的现有方法。我们从研究和应用角度讨论了该领域最相关的开放挑战，结束了这项研究。

    Graph Neural Networks (GNNs) have become the leading paradigm for learning on (static) graph-structured data. However, many real-world systems are dynamic in nature, since the graph and node/edge attributes change over time. In recent years, GNN-based models for temporal graphs have emerged as a promising area of research to extend the capabilities of GNNs. In this work, we provide the first comprehensive overview of the current state-of-the-art of temporal GNN, introducing a rigorous formalization of learning settings and tasks and a novel taxonomy categorizing existing approaches in terms of how the temporal aspect is represented and processed. We conclude the survey with a discussion of the most relevant open challenges for the field, from both research and application perspectives.
    
[^82]: 行动的人工智能：颠覆机器人与人类互动中的性别规范

    Enactive Artificial Intelligence: Subverting Gender Norms in Robot-Human Interaction. (arXiv:2301.08741v3 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2301.08741](http://arxiv.org/abs/2301.08741)

    本文提出了行动的人工智能(eAI)作为一个交叉、包容的AI立场，以应对AI设计中存在的性别规范。文章探讨了机器人与人类互动中如何颠覆性别规范，并提出了采用可解释性、公平性、透明度和可审计性的策略来开发包容性AI。

    

    本文提出了行动的人工智能(eAI)作为一个交叉的、包容性的AI立场。AI设计是一种人类社会文化实践，反映了人类文化和价值观。不恰当的AI设计可能导致社会边缘化。第1节从激进的行动主义出发，概述了具体的文化实践。在第2节中，探讨了交叉的性别如何与技术科学相互交织作为一种社会文化实践。第3节专注于AI中机器人与人类互动中颠覆性别规范的具体情况。最后，在第4节中，确定了四个伦理向量：可解释性、公平性、透明度和可审计性，以采用一个交叉性别包容立场开发包容性AI并颠覆现有的机器人设计性别规范。

    This paper introduces Enactive Artificial Intelligence (eAI) as an intersectional gender-inclusive stance towards AI. AI design is an enacted human sociocultural practice that reflects human culture and values. Unrepresentative AI design could lead to social marginalisation. Section 1, drawing from radical enactivism, outlines embodied cultural practices. In Section 2, explores how intersectional gender intertwines with technoscience as a sociocultural practice. Section 3 focuses on subverting gender norms in the specific case of Robot-Human Interaction in AI. Finally, Section 4 identifies four vectors of ethics: explainability, fairness, transparency, and auditability for adopting an intersectionality-inclusive stance in developing gender-inclusive AI and subverting existing gender norms in robot design.
    
[^83]: 多个干预分布上一致性因果抽象的联合学习

    Jointly Learning Consistent Causal Abstractions Over Multiple Interventional Distributions. (arXiv:2301.05893v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.05893](http://arxiv.org/abs/2301.05893)

    本文提出了一种基于Rischel（2020）提出的抽象形式化方法的SCMs因果抽象学习框架。我们通过提出的可微分编程方法解决了多个组合子问题，并在合成环境和与电动汽车电池制造相关的具有挑战性的真实问题上研究了其优势。

    

    抽象可以用来将代表同一系统不同分辨率的两个结构因果模型关联起来。学习保证在干预分布方面一致性的抽象将允许人们在尊重潜在因果关系的同时跨多个细粒度级别共同推断证据。本文介绍了一种基于Rischel（2020）提出的抽象形式化方法的SCMs因果抽象学习框架。在此基础上，我们提出了一种可微分的编程方法，同时解决了多个组合子问题，并在合成环境和与电动汽车电池制造相关的具有挑战性的真实问题上研究了其性能和优势。

    An abstraction can be used to relate two structural causal models representing the same system at different levels of resolution. Learning abstractions which guarantee consistency with respect to interventional distributions would allow one to jointly reason about evidence across multiple levels of granularity while respecting the underlying cause-effect relationships. In this paper, we introduce a first framework for causal abstraction learning between SCMs based on the formalization of abstraction recently proposed by Rischel (2020). Based on that, we propose a differentiable programming solution that jointly solves a number of combinatorial sub-problems, and we study its performance and benefits against independent and sequential approaches on synthetic settings and on a challenging real-world problem related to electric vehicle battery manufacturing.
    
[^84]: RedMule: 用于芯片线性代数和TinyML训练加速的混合精度矩阵计算引擎

    RedMule: A Mixed-Precision Matrix-Matrix Operation Engine for Flexible and Energy-Efficient On-Chip Linear Algebra and TinyML Training Acceleration. (arXiv:2301.03904v2 [cs.AR] UPDATED)

    [http://arxiv.org/abs/2301.03904](http://arxiv.org/abs/2301.03904)

    该论文介绍了一种名为RedMule的低功耗混合精度矩阵计算引擎，它支持多种精度和格式，用于解决近传感器训练的能耗问题。

    

    近期对于功耗只有几十毫瓦的近传感器机器学习（TinyML）的兴趣逐渐增长，而当前TinyML训练算法基于各种形式的误差和梯度反向传播，需要浮点矩阵运算来满足精度和动态范围要求。然而，迄今为止这些运算的能量和功耗成本被认为太高，无法适应TinyML场景。本文旨在解决近传感器训练在少量毫瓦功耗预算下的开放性挑战，并提出RedMulE-简化精度矩阵乘法引擎（Reduced-Precision Matrix Multiplication Engine），这是一种专为多精度浮点通用矩阵乘法（GEMM-Ops）加速而设计的低功耗加速器，支持FP16和混合FP8格式，采用符号、指数、尾数为（{1,4,3}，{1,5,2}）。我们将RedMule集成到一个包含八个节能RISC-V核心的并行超低功耗（PULP）集群中。

    The increasing interest in TinyML, i.e., near-sensor machine learning on power budgets of a few tens of mW, is currently pushing toward enabling TinyML-class training as opposed to inference only. Current training algorithms, based on various forms of error and gradient backpropagation, rely on floating-point matrix operations to meet the precision and dynamic range requirements. So far, the energy and power cost of these operations has been considered too high for TinyML scenarios. This paper addresses the open challenge of near-sensor training on a few mW power budget and presents RedMulE - Reduced-Precision Matrix Multiplication Engine, a low-power specialized accelerator conceived for multi-precision floating-point General Matrix-Matrix Operations (GEMM-Ops) acceleration, supporting FP16, as well as hybrid FP8 formats, with {sign, exponent, mantissa}=({1,4,3}, {1,5,2}). We integrate RedMule into a Parallel Ultra-Low-Power (PULP) cluster containing eight energy-efficient RISC-V core
    
[^85]: 医学影像领域中基于社区驱动的放射性AI部署的现状

    Current State of Community-Driven Radiological AI Deployment in Medical Imaging. (arXiv:2212.14177v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.14177](http://arxiv.org/abs/2212.14177)

    医学影像数据数量与复杂性的增长，引发了AI在医学影像领域的应用需求。尽管世界各地的研究实验室开发出多种AI模型，但很少有进入临床应用的。MONAI联盟旨在解决这种AI研究和应用之间的鸿沟，推动基于社区驱动的放射性AI的部署。

    

    人工智能已经成为解决日常例行任务的常见方法。由于医学影像数据的数量和复杂性呈指数增长，放射科医师的工作量也在稳定增加。我们预计，成像检查数量与专家放射科医师读者数量之间的差距将继续扩大，从而引入需求，即基于人工智能的工具，以提高放射科医师舒适地解读这些检查的效率。人工智能已被证明可提高医学图像生成、处理和解释的效率，并且世界各地的研究实验室开发了各种此类人工智能模型。然而，很少有这些模型进入例行临床应用，这种差距反映了人工智能研究和成功人工智能应用之间的鸿沟。为解决临床应用障碍，我们成立了MONAI联盟，这是一个正在建立的开源社区。

    Artificial Intelligence (AI) has become commonplace to solve routine everyday tasks. Because of the exponential growth in medical imaging data volume and complexity, the workload on radiologists is steadily increasing. We project that the gap between the number of imaging exams and the number of expert radiologist readers required to cover this increase will continue to expand, consequently introducing a demand for AI-based tools that improve the efficiency with which radiologists can comfortably interpret these exams. AI has been shown to improve efficiency in medical-image generation, processing, and interpretation, and a variety of such AI models have been developed across research labs worldwide. However, very few of these, if any, find their way into routine clinical use, a discrepancy that reflects the divide between AI research and successful AI translation. To address the barrier to clinical deployment, we have formed MONAI Consortium, an open-source community which is building
    
[^86]: GPT-3是否展示出精神病态？从心理学角度评估大型语言模型

    Does GPT-3 Demonstrate Psychopathy? Evaluating Large Language Models from a Psychological Perspective. (arXiv:2212.10529v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10529](http://arxiv.org/abs/2212.10529)

    本文从心理学角度评估大型语言模型的安全性，发现所有模型在短暗三合一测验上的得分都高于人类平均水平，存在相对较暗的人格模式。尽管经过指标微调，两种模型仍呈现隐含的黑暗人格模式。同时，本文观察到GPT-3和InstructGPT的幸福感得分持续增加。

    

    本文旨在从心理学角度确定大型语言模型（LLMs）的安全性。我们设计了无偏的提示来系统性地评估LLMs。首先，我们使用了两个人格测试——短暗三合一测验（SD-3）和大五人格问卷（BFI）测试了三个不同的LLMs。所有模型在SD-3上的得分都高于人类平均水平，表明存在相对较暗的人格模式。尽管经过指标微调以减少毒性，InstructGPT和FLAN-T5仍然呈现出隐含的黑暗人格模式；在SD-3的玛基雅维利主义和自恋狂特征上，这两种模型的得分都高于自监督GPT-3。然后，我们使用幸福感测试评估了GPT-3系列中的LLMs，以研究更多训练数据的微调对其影响。我们观察到GPT-3和InstructGPT的幸福感得分持续增加。鉴于这些观察结果，我们展示了使用正面回答从而指标微调FLAN-T5的方法。

    In this work, we determined whether large language models (LLMs) are psychologically safe. We designed unbiased prompts to systematically evaluate LLMs from a psychological perspective. First, we tested three different LLMs by using two personality tests: Short Dark Triad (SD-3) and Big Five Inventory (BFI). All models scored higher than the human average on SD-3, suggesting a relatively darker personality pattern. Despite being instruction fine-tuned with safety metrics to reduce toxicity, InstructGPT and FLAN-T5 still showed implicit dark personality patterns; both models scored higher than self-supervised GPT-3 on the Machiavellianism and narcissism traits on SD-3. Then, we evaluated the LLMs in the GPT-3 series by using well-being tests to study the impact of fine-tuning with more training data. We observed a continuous increase in the well-being scores of GPT-3 and InstructGPT. Following these observations, we showed that instruction fine-tuning FLAN-T5 with positive answers from 
    
[^87]: 代码预训练模型能够学习代码语法和语义吗？

    Are Code Pre-trained Models Powerful to Learn Code Syntax and Semantics?. (arXiv:2212.10017v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2212.10017](http://arxiv.org/abs/2212.10017)

    本文研究代码预训练模型的语法和语义分析，发现在AST和控制流图、数据依赖图及控制依赖图上进行相应的探测任务，能够更好地理解模型学到的程序语法和语义信息。

    

    代码预训练模型已经被证实可以有效地学习程序语法，但是这些研究在分析代码语法方面存在局限性，受到高维度下准确性的限制。此外，对于这些模型学到的程序语义的研究很少被讨论。本文旨在进一步了解这些模型学到的代码特征。我们针对两个代表性的预训练模型（即CodeBERT和GraphCodeBERT），设计了一系列探测任务来进行语法和语义分析。

    Analysis of pre-trained code models also has revealed that they can effectively learn program syntax. However, these works are limited in analyzing code syntax and their distance-based approaches are not accurate due to the curse of high dimensionality. Furthermore, the study of the learnt program semantics of these models is rarely discussed. To further understand the code features learnt by these models, in this paper, we target two well-known representative code pre-trained models (i.e., CodeBERT and GraphCodeBERT) and devise a set of probing tasks for the syntax and semantics analysis. Specifically, on one hand, we design two probing tasks (i.e., syntax pair node prediction and token tagging prediction) to manipulate AST for the understanding of learnt program syntax. On the other hand, we design two tasks (i.e., semantic relationship prediction and semantic propagation prediction(inGraph) ) on the constructed control flow graph (CFG), data dependency graph (DDG) and control depend
    
[^88]: 论文信息提取中的事件个体化问题

    On Event Individuation for Document-Level Information Extraction. (arXiv:2212.09702v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09702](http://arxiv.org/abs/2212.09702)

    提出了问题──事件个体化对于模板填充任务是否适用，通过注释研究和误差分析，我们发现这引发了对模板填充度量的有效性、任务数据集的质量以及模型学习能力的担忧。

    

    随着信息提取系统在处理整个文件方面越来越熟练，传统的模板填充任务作为文件级信息提取的基准任务再次引起了人们的关注。在本文中，我们质疑了模板填充任务在这方面的适用性。我们认为该任务要求对事件个体化问题提供明确的答案——即区分不同的事件——而即使是人类专家在这个问题上也存在分歧。通过注释研究和误差分析，我们展示了这引发了对模板填充度量的有效性、任务数据集的质量以及模型学习能力的担忧。最后，我们考虑了可能的解决方案。

    As information extraction (IE) systems have grown more adept at processing whole documents, the classic task of template filling has seen renewed interest as benchmark for document-level IE. In this position paper, we call into question the suitability of template filling for this purpose. We argue that the task demands definitive answers to thorny questions of event individuation -- the problem of distinguishing distinct events -- about which even human experts disagree. Through an annotation study and error analysis, we show that this raises concerns about the usefulness of template filling metrics, the quality of datasets for the task, and the ability of models to learn it. Finally, we consider possible solutions.
    
[^89]: 使用语言模型提示进行推理：一项调查

    Reasoning with Language Model Prompting: A Survey. (arXiv:2212.09597v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09597](http://arxiv.org/abs/2212.09597)

    本文提供了使用语言模型提示进行推理的前沿研究综合调查。讨论了新兴推理能力出现的潜在原因，并提供系统资源帮助初学者。

    

    推理作为复杂问题解决的重要能力，可以为医疗诊断、谈判等各种实际应用提供后端支持。本文对使用语言模型提示进行推理的前沿研究进行了综合调查。我们介绍了研究成果的比较和总结，并提供了系统资源以帮助初学者。我们还讨论了新兴推理能力出现的潜在原因，并突出了未来的研究方向。资源可在 https://github.com/zjunlp/Prompt4ReasoningPapers 上获取（定期更新）。

    Reasoning, as an essential ability for complex problem-solving, can provide back-end support for various real-world applications, such as medical diagnosis, negotiation, etc. This paper provides a comprehensive survey of cutting-edge research on reasoning with language model prompting. We introduce research works with comparisons and summaries and provide systematic resources to help beginners. We also discuss the potential reasons for emerging such reasoning abilities and highlight future research directions. Resources are available at https://github.com/zjunlp/Prompt4ReasoningPapers (updated periodically).
    
[^90]: 大型语言模型遇见NL2Code：综述

    Large Language Models Meet NL2Code: A Survey. (arXiv:2212.09420v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2212.09420](http://arxiv.org/abs/2212.09420)

    本文综述了27个大型语言模型对于NL2Code的应用，总结出这些模型成功的三大关键因素：巨大的模型尺寸、高质量的数据和专家的调整。同时，本文还讨论了模型和人类之间的差距，并提供了一个用于追踪最新进展的网站。

    

    从自然语言描述生成代码，即NL2Code，被视为代码智能中紧迫且重要的挑战。由于预训练技术的快速发展，涌现出了为代码提供支持的大型语言模型，进一步推动了NL2Code的进展。为了促进此领域的进一步研究和应用，本文综述了27个现有的NL2Code大型语言模型，并回顾了基准和度量标准。我们在HumanEval基准测试中提供了对所有现有模型的直观比较。通过深入观察和分析，我们提供了一些见解，总结了大型语言模型为NL2Code成功的关键因素是“巨大尺寸、高质量数据、专家调整”。此外，我们讨论了模型与人类之间差距的挑战和机会。我们还创建了一个网站 https://nl2code.github.io，通过众包评估来追踪最新进展。

    The task of generating code from a natural language description, or NL2Code, is considered a pressing and significant challenge in code intelligence. Thanks to the rapid development of pre-training techniques, surging large language models are being proposed for code, sparking the advances in NL2Code. To facilitate further research and applications in this field, in this paper, we present a comprehensive survey of 27 existing large language models for NL2Code, and also review benchmarks and metrics. We provide an intuitive comparison of all existing models on the HumanEval benchmark. Through in-depth observation and analysis, we provide some insights and conclude that the key factors contributing to the success of large language models for NL2Code are "Large Size, Premium Data, Expert Tuning". In addition, we discuss challenges and opportunities regarding the gap between models and humans. We also create a website https://nl2code.github.io to track the latest progress through crowd-sou
    
[^91]: BKinD-3D：自监督多视点视频中的三维关键点发现

    BKinD-3D: Self-Supervised 3D Keypoint Discovery from Multi-View Videos. (arXiv:2212.07401v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.07401](http://arxiv.org/abs/2212.07401)

    BKinD-3D是一种新的无需2D或3D监督的自监督三维关键点发现方法，使用编码器-解码器架构和3D体积热力图对多个视图之间的时空差异进行重建，还使用了一个学习到的3D主体骨架的关节长度约束。

    

    量化三维运动对于研究人类和其他动物的行为非常重要，但手动姿态注释获取成本高且耗时。自监督关键点发现是一种有前途的策略，可以在没有注释的情况下估计三维姿态。然而，当前的关键点发现方法通常仅处理单个2D视图并且不在3D空间操作。我们提出了一种新的方法，可以在行为主体的多视点视频中执行无2D或3D关键点或边界框监督的自监督三维关键点发现。我们的方法BKinD-3D使用编码器-解码器架构和3D体积热力图，训练以重建多个视图之间的时空差异，此外还使用了学习到的主体三维骨架的关节长度约束。通过这种方法，我们在没有手动监督的情况下，在人类和老鼠的视频中发现了关键点，展示了三维关键点发现在研究行为方面的潜力。

    Quantifying motion in 3D is important for studying the behavior of humans and other animals, but manual pose annotations are expensive and time-consuming to obtain. Self-supervised keypoint discovery is a promising strategy for estimating 3D poses without annotations. However, current keypoint discovery approaches commonly process single 2D views and do not operate in the 3D space. We propose a new method to perform self-supervised keypoint discovery in 3D from multi-view videos of behaving agents, without any keypoint or bounding box supervision in 2D or 3D. Our method, BKinD-3D, uses an encoder-decoder architecture with a 3D volumetric heatmap, trained to reconstruct spatiotemporal differences across multiple views, in addition to joint length constraints on a learned 3D skeleton of the subject. In this way, we discover keypoints without requiring manual supervision in videos of humans and rats, demonstrating the potential of 3D keypoint discovery for studying behavior.
    
[^92]: 通过体素扩散实现的文本生成三维模型。

    Diffusion-SDF: Text-to-Shape via Voxelized Diffusion. (arXiv:2212.03293v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.03293](http://arxiv.org/abs/2212.03293)

    提出了一种新型生成式三维建模框架Diffusion-SDF，用于文本生成三维形状综合任务，采用SDF autoencoder和体素扩散模型学习和生成三维形状的体素化符号距离场（SDF）的表示形式，能够生成高度多样化的三维形状以符合给定的文本描述。

    

    随着对三维虚拟建模技术的关注不断增加，基于特定条件（如文本）生成新颖的三维内容已成为热门问题。本文提出了一种名为Diffusion-SDF的新型生成式三维建模框架，用于挑战性的文本生成三维形状综合任务。先前的方法在三维数据表示和形状生成方面缺乏灵活性，因此无法生成高度多样化的三维形状以符合给定的文本描述。为解决这个问题，我们提出了一个SDF autoencoder和体素扩散模型，用于学习和生成三维形状的体素化符号距离场（SDF）的表示形式。具体来说，我们设计了一种新颖的UinU-Net结构，在标准的U-Net结构中嵌入一个局部聚焦的内部网络，从而实现对独立于补丁的SDF表示方法更好的重构。我们将我们的方法扩展到进一步的文本生成三维形状任务中，包括文本条件下的形状完成和提高多样性的三维形状生成。

    With the rising industrial attention to 3D virtual modeling technology, generating novel 3D content based on specified conditions (e.g. text) has become a hot issue. In this paper, we propose a new generative 3D modeling framework called Diffusion-SDF for the challenging task of text-to-shape synthesis. Previous approaches lack flexibility in both 3D data representation and shape generation, thereby failing to generate highly diversified 3D shapes conforming to the given text descriptions. To address this, we propose a SDF autoencoder together with the Voxelized Diffusion model to learn and generate representations for voxelized signed distance fields (SDFs) of 3D shapes. Specifically, we design a novel UinU-Net architecture that implants a local-focused inner network inside the standard U-Net architecture, which enables better reconstruction of patch-independent SDF representations. We extend our approach to further text-to-shape tasks including text-conditioned shape completion and m
    
[^93]: 多视角压缩表示的鲁棒性低资源微调研究

    Towards Robust Low-Resource Fine-Tuning with Multi-View Compressed Representations. (arXiv:2211.08794v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08794](http://arxiv.org/abs/2211.08794)

    本文提出了一种利用多视角压缩表示降低预训练语言模型微调过程中过拟合问题的方法，经过测试在低资源NLP任务中表现良好。

    

    由于参数的巨大数量，预训练语言模型（PLMs）的微调容易在低资源场景中出现过度拟合的问题。本文提出了一种新方法，该方法在PLM的隐藏表示上操作，以减少过拟合。在微调过程中，我们的方法在PLM的隐藏层之间插入随机自编码器，将来自前一层的激活转换为多视角压缩表示，然后将其馈送到上层。微调结束后，自编码器会被移除掉，因此我们的方法在推理过程中不会增加额外的参数或计算成本。我们的方法在一系列序列和标记级别的低资源NLP任务中展现了出色的性能提升。

    Due to the huge amount of parameters, fine-tuning of pretrained language models (PLMs) is prone to overfitting in the low resource scenarios. In this work, we present a novel method that operates on the hidden representations of a PLM to reduce overfitting. During fine-tuning, our method inserts random autoencoders between the hidden layers of a PLM, which transform activations from the previous layers into a multi-view compressed representation before feeding it into the upper layers. The autoencoders are plugged out after fine-tuning, so our method does not add extra parameters or increase computation cost during inference. Our method demonstrates promising performance improvement across a wide range of sequence- and token-level low-resource NLP tasks.
    
[^94]: 分层动态图像协调

    Hierarchical Dynamic Image Harmonization. (arXiv:2211.08639v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.08639](http://arxiv.org/abs/2211.08639)

    本文提出了一种分层动态网络（HDNet），以实现有效的图像协调。我们提出了本地动态（LD）模块和基于掩码的全局动态（MGD）模块，LD保留了详细的本地视觉一致性。在我们的实验中，HDNet在定量和定性评估上优于最先进的图像协调方法。

    

    图像协调是计算机视觉中的一个关键任务，旨在调整前景以使其与背景兼容。最近的工作主要关注使用全局变换（即归一化和色彩曲线渲染）来实现视觉一致性。然而，这些模型忽略了本地视觉一致性，并且它们巨大的模型大小限制了它们在边缘设备上的调和能力。在本文中，我们提出了一种分层动态网络（HDNet），以适应特征从局部到整体的视角，以实现有效的图像协调。在各种动态模型取得成功的基础上，本文提出了本地动态（LD）模块和基于掩码的全局动态（MGD）模块。具体而言，LD基于语义相似性匹配前景和背景区域之间的本地表示，然后根据其$K$个最近邻背景区域的外观自适应地调整每个前景本地表示。这样，LD保留了详细的本地视觉一致性。此外，基于LD的MGD通过将前景掩码引入模型，增强了全局变换的性能。在我们的实验中，HDNet在定量和定性评估上优于最先进的图像协调方法。

    Image harmonization is a critical task in computer vision, which aims to adjust the foreground to make it compatible with the background. Recent works mainly focus on using global transformations (i.e., normalization and color curve rendering) to achieve visual consistency. However, these models ignore local visual consistency and their huge model sizes limit their harmonization ability on edge devices. In this paper, we propose a hierarchical dynamic network (HDNet) to adapt features from local to global view for better feature transformation in efficient image harmonization. Inspired by the success of various dynamic models, local dynamic (LD) module and mask-aware global dynamic (MGD) module are proposed in this paper. Specifically, LD matches local representations between the foreground and background regions based on semantic similarities, then adaptively adjust every foreground local representation according to the appearance of its $K$-nearest neighbor background regions. In thi
    
[^95]: 带辅助输入的Agent-State构建

    Agent-State Construction with Auxiliary Inputs. (arXiv:2211.07805v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.07805](http://arxiv.org/abs/2211.07805)

    本文提出了一种基于信息瓶颈原理的方法，将辅助输入纳入到Agent-State构建过程中，以构建一个代理状态，总结与世界的先前交互，有效地解决了部分观测性问题。

    

    在许多现实的序列决策任务中，决策代理往往无法模拟世界的全部复杂性。环境往往比代理更大更复杂，这也称为部分观测性。在这种情况下，代理必须利用不仅仅是当前的感官输入; 它必须构建一个代理状态，以总结与世界的先前交互。目前，应对这个问题的流行方法是通过一个循环网络从代理的感官流作为输入来学习Agent-State函数。许多强大的强化学习应用程序实际上依赖于特定于环境的函数来帮助代理输入历史摘要。这些增强有多种方式，从简单的方法，如连接观察，到更复杂的方法，如不确定性估计。尽管它们在领域中普遍存在，但我们称之为辅助输入的这些附加输入通常以一种特殊的方式处理。在本文中，我们探索了一种将辅助输入纳入Agent-State构建过程的原则方法。我们的方法基于信息瓶颈原理，其中辅助输入用于调整代理状态的信息内容，同时保留与决策制定相关的信息。

    In many, if not every realistic sequential decision-making task, the decision-making agent is not able to model the full complexity of the world. The environment is often much larger and more complex than the agent, a setting also known as partial observability. In such settings, the agent must leverage more than just the current sensory inputs; it must construct an agent state that summarizes previous interactions with the world. Currently, a popular approach for tackling this problem is to learn the agent-state function via a recurrent network from the agent's sensory stream as input. Many impressive reinforcement learning applications have instead relied on environment-specific functions to aid the agent's inputs for history summarization. These augmentations are done in multiple ways, from simple approaches like concatenating observations to more complex ones such as uncertainty estimates. Although ubiquitous in the field, these additional inputs, which we term auxiliary inputs, ar
    
[^96]: 使用基于网络问答和多模态融合完成知识库

    Knowledge Base Completion using Web-Based Question Answering and Multimodal Fusion. (arXiv:2211.07098v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.07098](http://arxiv.org/abs/2211.07098)

    本文提出了一种使用基于网络问答和多模态融合的方法填补知识库中的缺失信息。通过设计一个多模态特征和问题模板的基于网络问答的系统来达到更高效的知识库补全，同时结合了知识库中的结构化信息来提高抽取质量。

    

    近年来，大型知识库已经建立来存储大量知识，然而这些知识库非常不完整。为了解决这个问题，我们提出一种使用基于网络问答和多模态融合的方法填补知识库中的缺失信息。为了利用网络上的非结构化信息完成知识库，我们设计了一个基于网络问答的系统，使用多模态特征和问题模板来提取缺失的事实，仅仅通过非常少的问题就可以达到良好的效果。同时，该问答系统还使用知识库中的结构化信息，比如实体类型和实体之间的关联性，以帮助提高抽取质量。

    Over the past few years, large knowledge bases have been constructed to store massive amounts of knowledge. However, these knowledge bases are highly incomplete. To solve this problem, we propose a web-based question answering system system with multimodal fusion of unstructured and structured information, to fill in missing information for knowledge bases. To utilize unstructured information from the Web for knowledge base completion, we design a web-based question answering system using multimodal features and question templates to extract missing facts, which can achieve good performance with very few questions. To help improve extraction quality, the question answering system employs structured information from knowledge bases, such as entity types and entity-to-entity relatedness.
    
[^97]: 光学图像机器学习中数据漂移控制的数据模型

    Data Models for Dataset Drift Controls in Machine Learning With Optical Images. (arXiv:2211.02578v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.02578](http://arxiv.org/abs/2211.02578)

    该研究利用物理光学和传统机器学习的组合，获得明确且可微分的数据模型，以更好地理解数据漂移对机器学习模型性能的影响。

    

    相机图像在机器学习研究中无处不在，并在医学和环境调查等重要领域发挥着核心作用。然而，由于强度问题，这些领域中的机器学习模型应用受到限制。主要的故障模式是出现性能下降，这是由于训练和部署数据之间的差异引起的。虽然已有方法可以前瞻性地验证机器学习模型对这种数据集漂移的强度，但现有方法未考虑主要感兴趣的对象 - 数据的显式模型。这限制了我们在物理上准确地研究和理解数据生成与下游机器学习模型性能之间的关系的能力。在这项研究中，我们展示了如何通过将传统的机器学习与物理光学配对，获得明确且可微分的数据模型来克服这一限制。我们展示了这种数据模型如何帮助我们更好地理解数据漂移对机器学习模型性能的影响。

    Camera images are ubiquitous in machine learning research. They also play a central role in the delivery of important services spanning medicine and environmental surveying. However, the application of machine learning models in these domains has been limited because of robustness concerns. A primary failure mode are performance drops due to differences between the training and deployment data. While there are methods to prospectively validate the robustness of machine learning models to such dataset drifts, existing approaches do not account for explicit models of the primary object of interest: the data. This limits our ability to study and understand the relationship between data generation and downstream machine learning model performance in a physically accurate manner. In this study, we demonstrate how to overcome this limitation by pairing traditional machine learning with physical optics to obtain explicit and differentiable data models. We demonstrate how such data models can 
    
[^98]: 多分位数发布的学习增强私有算法

    Learning-Augmented Private Algorithms for Multiple Quantile Release. (arXiv:2210.11222v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2210.11222](http://arxiv.org/abs/2210.11222)

    本文提出一种新的隐私保护方法：使用学习增强算法框架，为多分位数发布任务提供可扩展的预测质量误差保证。

    

    当应用差分隐私于敏感数据时，我们常常可以利用额外的信息例如其他敏感数据、公众数据或人类信息先验来提升性能。本文提出了使用学习增强算法（或具有预测能力的算法）框架，这个框架通常使用于优化时间复杂度或竞争比率。该框架为设计和分析保护隐私的方法提供了一种强有力的方法，并能够利用这些额外信息以提高效用。该想法体现在重要的多分位数发布任务中，在此我们得出了随着自然质量预测的错误保证，同时（几乎）恢复了最先进的预测独立的保证。我们的分析具有几个优点，包括对数据的最小假设，一种自然的增强鲁棒性的方法，以及为两个从其他数据中学习预测的新颖“元”算法提供有用的替代损失。

    When applying differential privacy to sensitive data, we can often improve performance using external information such as other sensitive data, public data, or human priors. We propose to use the learning-augmented algorithms (or algorithms with predictions) framework -- previously applied largely to improve time complexity or competitive ratios -- as a powerful way of designing and analyzing privacy-preserving methods that can take advantage of such external information to improve utility. This idea is instantiated on the important task of multiple quantile release, for which we derive error guarantees that scale with a natural measure of prediction quality while (almost) recovering state-of-the-art prediction-independent guarantees. Our analysis enjoys several advantages, including minimal assumptions about the data, a natural way of adding robustness, and the provision of useful surrogate losses for two novel ``meta" algorithms that learn predictions from other (potentially sensitiv
    
[^99]: Contact2Grasp：基于物体接触约束的三维抓取合成

    Contact2Grasp: 3D Grasp Synthesis via Hand-Object Contact Constraint. (arXiv:2210.09245v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2210.09245](http://arxiv.org/abs/2210.09245)

    本论文提出了一种基于中间变量的接触约束方法，将映射分解为两个顺序阶段，以生成用于抓取的潜在接触地图，并学习接触地图到抓取姿势的映射，实现高效且高通用性的三维抓取合成。

    

    三维抓取合成是给定一个物体，生成抓取姿态的过程。现有方法通过学习从物体到抓取姿态分布的直接映射来解决这个问题。然而，由于物理接触对姿态微小变化非常敏感，三维物体表示到有效姿态的高度非线性映射相当不平滑，导致生成效率低且通用性受限。为了解决这个挑战，我们引入了接触区域中间变量来约束抓取姿势的生成；换句话说，我们将映射分解为两个顺序阶段，假设接触地图给定的情况下姿势完全受限：1）我们首先学习接触地图分布，以生成用于抓取的潜在接触地图；2）然后学习从接触地图到抓取姿势的映射。进一步地，我们提出了一种考虑到穿透的优化方法，将生成的接触作为一致性约束进行抓取细化。通过大量实验验证了方法的有效性。

    3D grasp synthesis generates grasping poses given an input object. Existing works tackle the problem by learning a direct mapping from objects to the distributions of grasping poses. However, because the physical contact is sensitive to small changes in pose, the high-nonlinear mapping between 3D object representation to valid poses is considerably non-smooth, leading to poor generation efficiency and restricted generality. To tackle the challenge, we introduce an intermediate variable for grasp contact areas to constrain the grasp generation; in other words, we factorize the mapping into two sequential stages by assuming that grasping poses are fully constrained given contact maps: 1) we first learn contact map distributions to generate the potential contact maps for grasps; 2) then learn a mapping from the contact maps to the grasping poses. Further, we propose a penetration-aware optimization with the generated contacts as a consistency constraint for grasp refinement. Extensive val
    
[^100]: CLIP-PAE：投影增强嵌入以提取相关特征用于可分离、可解释、可控的文本指导脸部操纵

    CLIP-PAE: Projection-Augmentation Embedding to Extract Relevant Features for a Disentangled, Interpretable, and Controllable Text-Guided Face Manipulation. (arXiv:2210.03919v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.03919](http://arxiv.org/abs/2210.03919)

    提出了一种为了解决文本引导图像操纵中的可分离性、可解释性和可控性问题，通过定义基于相关提示的语料库子空间来获取特定图像特征并引入CLIP投影增强嵌入（PAE）作为优化目标处理的新方法。

    

    最近引入的对比语言-图像预训练（CLIP）将图像和文本嵌入到共同的潜在空间中。这打开了一个大门，即旨在通过提供文字说明来操作输入图像的丰富文学资料。然而，由于联合空间中图像和文本嵌入之间的差异，将文本嵌入作为优化目标通常会导致结果图像中出现意外的伪影。对于操纵来说，可分离性、可解释性和可控性也很难保证。为了缓解这些问题，我们提出定义由相关提示展开的语料库子空间来捕获特定的图像特征。我们引入了CLIP投影增强嵌入（PAE）作为优化目标，以提高文本引导图像操纵的性能。我们的方法是一种简单而通用的范例，可以轻松地计算和适应，并平稳地融入到任何基于CLIP的图像操作算法中。

    Recently introduced Contrastive Language-Image Pre-Training (CLIP) bridges images and text by embedding them into a joint latent space. This opens the door to ample literature that aims to manipulate an input image by providing a textual explanation. However, due to the discrepancy between image and text embeddings in the joint space, using text embeddings as the optimization target often introduces undesired artifacts in the resulting images. Disentanglement, interpretability, and controllability are also hard to guarantee for manipulation. To alleviate these problems, we propose to define corpus subspaces spanned by relevant prompts to capture specific image characteristics. We introduce CLIP Projection-Augmentation Embedding (PAE) as an optimization target to improve the performance of text-guided image manipulation. Our method is a simple and general paradigm that can be easily computed and adapted, and smoothly incorporated into any CLIP-based image manipulation algorithm. To demo
    
[^101]: 音乐文本视觉交感：从音乐录音中生成描述性文本

    Music-to-Text Synaesthesia: Generating Descriptive Text from Music Recordings. (arXiv:2210.00434v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2210.00434](http://arxiv.org/abs/2210.00434)

    本文提出了音乐文本视觉交感问题，收集了对齐的数据集，构建了一个计算模型来生成描述音乐录音内容的句子，并设计了群拓扑保持损失来解决高非判别性的古典音乐。

    

    本文提出了一个新的研究问题：音乐文本视觉交感。不同于把音乐录音分类到预定义的类别的经典音乐标记问题，音乐文本视觉交感旨在生成具有相同情感的音乐录音的描述性文本，以便进一步理解。由于现有的音乐相关数据集不包含音乐录音的语义描述，我们收集了一个包含1,955个古典音乐录音与文本描述的对齐数据集。基于此，我们构建了一个计算模型来生成可以描述音乐录音内容的句子。为了解决高度非判别性的古典音乐，我们设计了一个群拓扑保持损失，它考虑更多的样本作为群组参考，并保留不同样本之间的相对拓扑。广泛的实验结果定性和定量地证明了我们提出的模型在五个不同的指标上的有效性。

    In this paper, we consider a novel research problem: music-to-text synaesthesia. Different from the classical music tagging problem that classifies a music recording into pre-defined categories, music-to-text synaesthesia aims to generate descriptive texts from music recordings with the same sentiment for further understanding. As existing music-related datasets do not contain the semantic descriptions on music recordings, we collect a new dataset that contains 1,955 aligned pairs of classical music recordings and text descriptions. Based on this, we build a computational model to generate sentences that can describe the content of the music recording. To tackle the highly non-discriminative classical music, we design a group topology-preservation loss, which considers more samples as a group reference and preserves the relative topology among different samples. Extensive experimental results qualitatively and quantitatively demonstrate the effectiveness of our proposed model over five
    
[^102]: 利用符合度量检测过程模型中的逐渐漂移

    Gradual Drift Detection in Process Models Using Conformance Metrics. (arXiv:2207.11007v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2207.11007](http://arxiv.org/abs/2207.11007)

    本文提出一种使用符合度量检测逐渐漂移的算法，相较于主流算法获得更好的结果。

    

    在实际过程的执行过程中，计划或意外变更是常见的。检测这些变化对于优化运行此类过程的组织的性能是必须的。本文将专注于自动检测逐渐漂移，这是一种特殊的类型的变化，在这种变化期间，两个模型的情况重叠。所提出的算法依赖于符合检查度量标准来实现变化的自动检测，还可以对这些变化进行完全自动分类。该方法已经通过由120个具有不同变化分布的合成数据集验证，在检测和分类准确性、延迟和变化区域重叠方面获得了比主要现有算法更好的结果。

    Changes, planned or unexpected, are common during the execution of real-life processes. Detecting these changes is a must for optimizing the performance of organizations running such processes. Most of the algorithms present in the state-of-the-art focus on the detection of sudden changes, leaving aside other types of changes. In this paper, we will focus on the automatic detection of gradual drifts, a special type of change, in which the cases of two models overlap during a period of time. The proposed algorithm relies on conformance checking metrics to carry out the automatic detection of the changes, performing also a fully automatic classification of these changes into sudden or gradual. The approach has been validated with a synthetic dataset consisting of 120 logs with different distributions of changes, getting better results in terms of detection and classification accuracy, delay and change region overlapping than the main state-of-the-art algorithms.
    
[^103]: 关于关系特征的构成及其在解释黑盒预测器中的应用

    Composition of Relational Features with an Application to Explaining Black-Box Predictors. (arXiv:2206.00738v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.00738](http://arxiv.org/abs/2206.00738)

    本文提出了一种将关系特征视为函数，并使用通用函数组合的概念从简单函数推导出复杂函数的方法，将其应用于解释黑盒预测器的预测。

    

    类似归纳逻辑编程（ILP）的关系机器学习程序具有以下优点：（1）能够对数据实例之间的复杂关系建模；（2）在模型构建期间使用特定于领域的关系；（3）构建的模型是人类可读的，这通常更接近人类的理解。本文将关系特征视为函数，并使用通用函数组合的概念从简单函数推导出复杂函数。我们制定了一种在模据语言M中的 $\text{M}$-简单特征集的概念，并确定了两个组合算子（$\rho_1$和$\rho_2$），所有可能的复杂特征都可以从中派生出来。我们利用这些结果实现了一种“可解释的神经网络”，其中我们使用我们的方法构建和解释黑盒预测器的预测。

    Relational machine learning programs like those developed in Inductive Logic Programming (ILP) offer several advantages: (1) The ability to model complex relationships amongst data instances; (2) The use of domain-specific relations during model construction; and (3) The models constructed are human-readable, which is often one step closer to being human-understandable. However, these ILP-like methods have not been able to capitalise fully on the rapid hardware, software and algorithmic developments fuelling current developments in deep neural networks. In this paper, we treat relational features as functions and use the notion of generalised composition of functions to derive complex functions from simpler ones. We formulate the notion of a set of $\text{M}$-simple features in a mode language $\text{M}$ and identify two composition operators ($\rho_1$ and $\rho_2$) from which all possible complex features can be derived. We use these results to implement a form of "explainable neural 
    
[^104]: 任务导向对话系统的帮助性和公平性研究

    Helpfulness and Fairness of Task-Oriented Dialogue Systems. (arXiv:2205.12554v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12554](http://arxiv.org/abs/2205.12554)

    本文研究任务导向对话系统的帮助性和公平性。作者定义了对话系统的帮助性，使用分类器自动确定帮助性，并提出使用帮助级别来衡量对话系统的公平性。实验结果表明，现有系统更容易为来自发达国家概念的问题提供帮助。

    

    目标导向的对话系统旨在帮助用户实现某些目标，因此人们对其帮助性的感知很重要。然而，目前尚未对目标导向对话系统的人类感知帮助性以及其公平性影响进行深入研究。本文研究了帮助性的计算度量，并通过人类注释构建分类器，自动确定响应的帮助性。我们进一步提出使用对不同用户查询的帮助级别来衡量对话系统的公平性。实验表明，现有系统在三种信息查询场景下更容易为来自发达国家概念的问题提供帮助。

    Goal-oriented dialogue systems aim to help users achieve certain goals. Therefore, how humans perceive their helpfulness is important. However, neither the human-perceived helpfulness of goal-oriented dialogue systems nor its fairness implication has been well studied. In this paper, we study computational measurements of helpfulness. We first formally define a dialogue response as helpful if it is relevant & coherent, useful, and informative to a query. Then, we collect human annotations for the helpfulness of dialogue responses based on our definition and build a classifier to automatically determine the helpfulness of a response. We further propose to use the helpfulness level of a dialogue system towards different user queries to measure the fairness of a dialogue system. Experiments with state-of-the-art dialogue systems under three information-seeking scenarios reveal that existing systems tend to be more helpful for questions regarding concepts from highly-developed countries th
    
[^105]: 什么是公平性？哲学的思考与对fairML的影响

    What Is Fairness? Philosophical Considerations and Implications For FairML. (arXiv:2205.09622v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.09622](http://arxiv.org/abs/2205.09622)

    本文探讨了公平性的哲学概念，提出了公平性和预测性能不是不可调和的对立面，并强调从数据收集到最终模型评估都需纳入伦理考虑。

    

    在公平性人工智能(fairML)领域，通过定义衡量模型公平性的度量和提出确保训练模型数据具有低公平性度量值的方法，来减轻人工智能(ML)产生的相关不公平性问题。然而，公平的基本概念，即"公平是什么"，很少被讨论，这造成了公平性研究在哲学领域几个世纪的讨论与近期被应用于机器学习领域之间的鸿沟。本文试图通过形式化一致性公平概念和将哲学思考转化为ADM系统中ML模型训练和评估的形式框架，来架起这一鸿沟。我们指出，不公平性问题可能已经存在，即使没有受保护性属性的存在，强调公平性和预测性能不是不可调和的对立面，而是前者实现的必要条件。我们提出的框架强调将伦理考虑纳入ML管道的所有阶段，从数据收集到最终部署模型的评估。

    A growing body of literature in fairness-aware ML (fairML) aspires to mitigate machine learning (ML)-related unfairness in automated decision making (ADM) by defining metrics that measure fairness of an ML model and by proposing methods that ensure that trained ML models achieve low values in those measures. However, the underlying concept of fairness, i.e., the question of what fairness is, is rarely discussed, leaving a considerable gap between centuries of philosophical discussion and recent adoption of the concept in the ML community. In this work, we try to bridge this gap by formalizing a consistent concept of fairness and by translating the philosophical considerations into a formal framework for the training and evaluation of ML models in ADM systems. We derive that fairness problems can already arise without the presence of protected attributes, pointing out that fairness and predictive performance are not irreconcilable counterparts, but rather that the latter is necessary to
    
[^106]: DPMS: 一种基于ADD符号化方法的广义MaxSAT求解算法

    DPMS: An ADD-Based Symbolic Approach for Generalized MaxSAT Solving. (arXiv:2205.03747v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2205.03747](http://arxiv.org/abs/2205.03747)

    该研究提出了DPMS算法，一种基于ADD符号化方法的广义MaxSAT求解算法，可以处理非CNF混合约束的广义MaxSAT问题，并在实验中表现优秀。

    

    布尔最大可满足性（MaxSAT）问题以及广义形式，如Min-MaxSAT和Max-hybrid-SAT，在布尔推理中是基本的优化问题。现有的MaxSAT方法已成功解决CNF格式基准测试问题。然而，它们缺乏处理1）（非CNF）混合约束，例如XOR，和2）广义MaxSAT问题的能力。为解决这个问题，我们提出了一种新颖的动态编程方法来解决具有混合约束的广义MaxSAT问题，称为\emph{Dynamic-Programming-MaxSAT} （DPMS）——基于代数决策图（ADDs）。凭借ADDs和（分级）项目连接树生成器的强大功能，我们的通用框架可以接受许多CNF-MaxSAT的泛化，例如具有混合约束的MaxSAT、Min-MaxSAT和MinSAT。此外，DPMS在宽度低的实例上具有可证明的良好扩展性。实验结果表明，DPMS能够快速解决某些问题，其他基于各种技术的算法则无法解决。

    Boolean MaxSAT, as well as generalized formulations such as Min-MaxSAT and Max-hybrid-SAT, are fundamental optimization problems in Boolean reasoning. Existing methods for MaxSAT have been successful in solving benchmarks in CNF format. They lack, however, the ability to handle 1) (non-CNF) hybrid constraints, such as XORs and 2) generalized MaxSAT problems natively. To address this issue, we propose a novel dynamic-programming approach for solving generalized MaxSAT problems with hybrid constraints -- called \emph{Dynamic-Programming-MaxSAT} or DPMS for short -- based on Algebraic Decision Diagrams (ADDs). With the power of ADDs and the (graded) project-join-tree builder, our versatile framework admits many generalizations of CNF-MaxSAT, such as MaxSAT, Min-MaxSAT, and MinSAT with hybrid constraints. Moreover, DPMS scales provably well on instances with low width. Empirical results indicate that DPMS is able to solve certain problems quickly, where other algorithms based on various te
    
[^107]: 基于密集卷积神经网络的胸部疾病多标签分类方法

    Multi-Label Classification of Thoracic Diseases using Dense Convolutional Network on Chest Radiographs. (arXiv:2202.03583v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2202.03583](http://arxiv.org/abs/2202.03583)

    本研究提出了一种基于密集卷积神经网络和GRADCAM的胸部X光疾病多标签诊断模型，获得了在Cardiomegaly条件下最高的AUC得分0.896，并使用热图提高了模型的可解释性。

    

    传统的X光图像病理识别方法依赖于熟练的人类解释，并且往往耗时。深度学习技术的出现使自动诊断系统的开发成为可能，但这类系统的表现取决于模型的质量和它提供的可解释性水平。本文提出了一种使用密集卷积神经网络（DenseNet）和GRADCAM进行模型可解释性的胸部X光疾病多标签诊断模型。我们使用前置X光训练了我们的模型，并使用各种定量指标（包括受试者操作特征曲线下面积（AUC））评估了模型的性能。我们的模型在Cardiomegaly条件下达到了最高的AUC得分0.896，并获得了0.826的准确度。而在Nodule条件下获得了最低的AUC得分0.655，准确度为0.66。为了提高模型可解释性，并在决策方面建立信任，我们使用GRADCAM生成了热图，突出显示了对诊断最重要的X光区域。

    Traditional methods of identifying pathologies in X-ray images rely heavily on skilled human interpretation and are often time-consuming. The advent of deep learning techniques has enabled the development of automated disease diagnosis systems, but the performance of such systems is dependent on the quality of the model and the level of interpretability it provides. In this paper, we propose a multi-label disease diagnosis model for chest X-rays using a dense convolutional neural network (DenseNet) and model interpretability using GRADCAM. We trained our model using frontal X-rays and evaluated its performance using various quantitative metrics, including the area under the receiver operating characteristic curve (AUC). Our proposed model achieved the highest AUC score of 0.896 for the condition Cardiomegaly with an accuracy of 0.826, while the lowest AUC score was obtained for Nodule, at 0.655 with an accuracy of 0.66. To promote model interpretability and build trust in decision maki
    
[^108]: 一个大规模多元化的阿拉伯语语料库用于语言建模

    A Large and Diverse Arabic Corpus for Language Modeling. (arXiv:2201.09227v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.09227](http://arxiv.org/abs/2201.09227)

    该论文介绍了一个大规模的阿拉伯语语料库，旨在提高大规模语言模型的跨领域知识和推理能力。

    

    语言模型（LM）引入了自然语言处理（NLP）建模的重大范式转变，其中大型预先训练的LM已经成为大多数NLP任务不可分割的组成部分。LM足够智能，可以在没有任何监督的情况下找到语言的有用和相关表示。这些模型被用于对常规NLP任务进行微调，相对于传统方法，具有显着更高的准确性。相反，这些模型的训练需要一个大规模的语料库，这个语料库可以很好地代表阿拉伯语。由于英语语料库可获得大量资源，因此英语LM通常比其他语言LM表现更好。本文详细描述了一个大型阿拉伯语语料库的设计和开发。它由超过500GB的已加工的阿拉伯文本组成，旨在提高大规模语言模型的跨领域知识和下游推理能力。此外，该语料库还用于训练大型阿拉伯语LM。

    Language models (LMs) have introduced a major paradigm shift in Natural Language Processing (NLP) modeling where large pre-trained LMs became integral to most of the NLP tasks. The LMs are intelligent enough to find useful and relevant representations of the language without any supervision. Perhaps, these models are used to fine-tune typical NLP tasks with significantly high accuracy as compared to the traditional approaches. Conversely, the training of these models requires a massively large corpus that is a good representation of the language. English LMs generally perform better than their other language counterparts, due to the availability of massive English corpora. This work elaborates on the design and development of a large Arabic corpus. It consists of over 500 GB of Arabic cleaned text targeted at improving cross-domain knowledge and downstream generalization capability of large-scale language models. Moreover, the corpus is utilized in the training of a large Arabic LM. In
    
[^109]: CausalSim: 一种用于无偏差追踪驱动仿真的因果框架

    CausalSim: A Causal Framework for Unbiased Trace-Driven Simulation. (arXiv:2201.01811v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.01811](http://arxiv.org/abs/2201.01811)

    CausalSim提出了一种因果框架，通过学习系统动态和潜在因素的因果模型，消除追踪数据中的偏差，解决了当前追踪驱动仿真器的缺陷。

    

    我们提出了CausalSim，一种用于无偏差追踪驱动仿真的因果框架。当前的追踪驱动仿真器假设进行仿真的干预（例如，新算法）不会影响追踪的有效性。然而，现实世界中的追踪常常会受到算法在追踪收集期间进行选择的影响，因此，在干预下重演追踪可能会导致不正确的结果。CausalSim通过学习系统动态和捕获追踪收集期间基础系统条件的潜在因素的因果模型来解决这个挑战。它使用固定算法集下的初始随机对照试验（RCT）来学习这些模型，然后在模拟新算法时应用它们来消除追踪数据中的偏差。

    We present CausalSim, a causal framework for unbiased trace-driven simulation. Current trace-driven simulators assume that the interventions being simulated (e.g., a new algorithm) would not affect the validity of the traces. However, real-world traces are often biased by the choices algorithms make during trace collection, and hence replaying traces under an intervention may lead to incorrect results. CausalSim addresses this challenge by learning a causal model of the system dynamics and latent factors capturing the underlying system conditions during trace collection. It learns these models using an initial randomized control trial (RCT) under a fixed set of algorithms, and then applies them to remove biases from trace data when simulating new algorithms.  Key to CausalSim is mapping unbiased trace-driven simulation to a tensor completion problem with extremely sparse observations. By exploiting a basic distributional invariance property present in RCT data, CausalSim enables a nove
    
[^110]: 逐步分析强化学习

    Reinforcement Learning, Bit by Bit. (arXiv:2103.04047v8 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2103.04047](http://arxiv.org/abs/2103.04047)

    该论文讨论了强化学习代理在实际环境中的数据效率问题，并提供了原则性指导和计算结果。

    

    强化学习代理在模拟环境中取得了惊人的成就。数据效率是将这种成功应用于实际环境的障碍。数据高效代理的设计需要更深入地了解信息获取和表示。我们讨论了概念和遗憾分析，共同提供了原则性指导。这种思路揭示了关于寻求什么信息、如何寻求该信息以及保留哪些信息的问题。为了阐明这些概念，我们设计了简单的代理，并展示了突出的数据效率的计算结果。

    Reinforcement learning agents have demonstrated remarkable achievements in simulated environments. Data efficiency poses an impediment to carrying this success over to real environments. The design of data-efficient agents calls for a deeper understanding of information acquisition and representation. We discuss concepts and regret analysis that together offer principled guidance. This line of thinking sheds light on questions of what information to seek, how to seek that information, and what information to retain. To illustrate concepts, we design simple agents that build on them and present computational results that highlight data efficiency.
    
[^111]: 面向儿童图书推荐的个性化推荐系统及其与实时交互机器人集成

    Personalized Recommender System for Children's Book Recommendation with A Realtime Interactive Robot. (arXiv:1710.00310v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/1710.00310](http://arxiv.org/abs/1710.00310)

    本文研究了儿童和机器人交互环境下的个性化图书推荐系统，在搜索算法、用户兴趣预测和同义词关联方面进行了创新，提高了性能，适用于嵌入式消费设备。

    

    本文研究了在儿童和机器人交互环境中的个性化图书推荐系统。首先，我们提出了一种新的文本搜索算法，使用反向过滤机制来提高效率。其次，我们提出了一种基于贝叶斯网络和新型反馈机制的用户兴趣预测方法。根据儿童模糊的语言输入，该方法给出了预测的兴趣。第三，基于词向量化，提出了领域特定的同义词关联，以提高理解用户意图。实验结果表明，该推荐系统性能得到了改进，并且可以在有限的计算资源下运行在嵌入式消费设备上。

    In this paper we study the personalized book recommender system in a child-robot interactive environment. Firstly, we propose a novel text search algorithm using an inverse filtering mechanism that improves the efficiency. Secondly, we propose a user interest prediction method based on the Bayesian network and a novel feedback mechanism. According to children's fuzzy language input, the proposed method gives the predicted interests. Thirdly, the domain specific synonym association is proposed based on word vectorization, in order to improve the understanding of user intention. Experimental results show that the proposed recommender system has an improved performance and it can operate on embedded consumer devices with limited computational resources.
    

