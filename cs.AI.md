# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [AgentOhana: Design Unified Data and Training Pipeline for Effective Agent Learning](https://arxiv.org/abs/2402.15506) | AgentOhana提供了一种统一数据和训练流水线的综合解决方案，有助于克服使用大型语言模型（LLMs）进行智能体任务时的挑战。 |
| [^2] | [Co-Supervised Learning: Improving Weak-to-Strong Generalization with Hierarchical Mixture of Experts](https://arxiv.org/abs/2402.15505) | 提出了一种通过使用分层专家混合模型来改善弱到强泛化的协同监督学习方法，利用一组多样化的专家教师共同监督强大的学生模型。 |
| [^3] | [Gen4Gen: Generative Data Pipeline for Generative Multi-Concept Composition](https://arxiv.org/abs/2402.15504) | 该论文介绍了Gen4Gen，为解决文本到图像扩散模型中个性化多概念组合的问题而提出的生成数据管道。 |
| [^4] | [API-BLEND: A Comprehensive Corpora for Training and Benchmarking API LLMs](https://arxiv.org/abs/2402.15491) | 本文介绍了API-BLEND，一个用于训练和系统测试工具增强型LLMs的大型语料库，旨在解决获取涉及调用工具/API的训练和测试数据的挑战，并模拟真实场景的API任务。 |
| [^5] | [RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for Robotic Manipulation](https://arxiv.org/abs/2402.15487) | 本文提出了交互式场景探索任务，通过自主探索环境生成了动作条件化场景图，捕捉了环境的结构 |
| [^6] | [Computer Vision for Multimedia Geolocation in Human Trafficking Investigation: A Systematic Literature Review](https://arxiv.org/abs/2402.15448) | 计算机视觉和深度学习在多媒体地理定位中展示出加速人口贩卖调查的重大潜力。 |
| [^7] | [Can we forget how we learned? Doxastic redundancy in iterated belief revision](https://arxiv.org/abs/2402.15445) | 在迭代信念修订中，有时候在其他修订存在时会出现信念修订的多余情况，以及给出了导致序列中第一个修订多余的必要和充分条件。 |
| [^8] | [Unleashing the Power of Imbalanced Modality Information for Multi-modal Knowledge Graph Completion](https://arxiv.org/abs/2402.15444) | 提出了自适应多模态融合和模态对抗训练（AdaMF-MAT）方法，以解决多模态知识图完成中存在的模态信息不平衡问题，发挥不平衡模态信息的力量。 |
| [^9] | [Active Few-Shot Fine-Tuning](https://arxiv.org/abs/2402.15441) | 该论文提出了ITL方法来实现主动少样本微调，通过最大化对下游任务的信息获取，从而在大型神经网络的微调中取得了显著的改进。 |
| [^10] | [ProTIP: Probabilistic Robustness Verification on Text-to-Image Diffusion Models against Stochastic Perturbation](https://arxiv.org/abs/2402.15429) | 本研究引入了概率概念的文本到图像扩散模型鲁棒性，并建立了一个名为ProTIP的高效框架用于评估其统计保证，解决了生成过程的高计算成本和对抗性样本判断困难的问题 |
| [^11] | [Understanding Entrainment in Human Groups: Optimising Human-Robot Collaboration from Lessons Learned during Human-Human Collaboration](https://arxiv.org/abs/2402.15427) | 本文通过混合方法研究了成功衔接的特征，从而实现成对和基于群体的同步，为人机/机器人交互领域提供了有益的贡献。 |
| [^12] | [A Data-Centric Approach To Generate Faithful and High Quality Patient Summaries with Large Language Models](https://arxiv.org/abs/2402.15422) | 本研究探讨了使用大型语言模型基于医生笔记生成患者总结的潜力，通过严格的标记协议和医学专家标记实验发现，在无幻觉数据上进行微调能有效减少幻觉的生成，并保留相关信息。 |
| [^13] | [Reputational Algorithm Aversion](https://arxiv.org/abs/2402.15418) | 选择跟随算法是否传达有关人类能力的信息是导致算法厌恶现象的关键因素，这种现象被称为“算法厌恶”。 |
| [^14] | [TransFlower: An Explainable Transformer-Based Model with Flow-to-Flow Attention for Commuting Flow Prediction](https://arxiv.org/abs/2402.15398) | TransFlower模型是一种基于Transformer的可解释模型，采用Flow-to-Flow注意力来预测城市通勤模式，以解决深度学习模型准确性和可解释性之间的权衡问题。 |
| [^15] | [NeuralThink: Algorithm Synthesis that Extrapolates in General Tasks](https://arxiv.org/abs/2402.15393) | NeuralThink 是一种新的递归架构，可以一贯地对对称和不对称任务进行外推，相较于之前的最先进的深度思维架构在稳定地从较小的训练规模对大观测进行外推方面表现出更好的性能。 |
| [^16] | [Genie: Generative Interactive Environments](https://arxiv.org/abs/2402.15391) | Genie是第一个经过无监督训练的生成交互环境，可生成各种动作可控的虚拟世界，并提供了学习潜在行动空间以训练代理程序模仿未见视频行为的可能性。 |
| [^17] | [Explorations of Self-Repair in Language Models](https://arxiv.org/abs/2402.15390) | 自修复现象存在于各种模型家族和尺寸上，但在完整的训练分布上是不完美和嘈杂的，有两种机制可促成自修复，包括最终LayerNorm缩放因子的变化和实现反擦除的稀疏神经元集。 |
| [^18] | [Homeostatic motion planning with innate physics knowledge](https://arxiv.org/abs/2402.15384) | 通过定义"任务"的方式和引入具有物理和因果关系理解的监督模块，我们提出了一种具有固有物理知识的稳态运动规划框架，可以在机器人上实现复杂计划。 |
| [^19] | [Dual Encoder: Exploiting the Potential of Syntactic and Semantic for Aspect Sentiment Triplet Extraction](https://arxiv.org/abs/2402.15370) | 提出了一种双编码器模型（D2E2S），结合了BERT通道和增强型LSTM通道来最大化单词间的句法和语义关系，引入了异构特征交互模块用于捕获复杂互动和动态选择重要节点。 |
| [^20] | [Safe Task Planning for Language-Instructed Multi-Robot Systems using Conformal Prediction](https://arxiv.org/abs/2402.15368) | 本文引入了一种新的基于分布式LLM和符合预测技术的多机器人规划器，实现了高任务成功率。 |
| [^21] | [Farsight: Fostering Responsible AI Awareness During AI Application Prototyping](https://arxiv.org/abs/2402.15350) | Farsight是一个新颖的实地交互工具，帮助人们在设计AI应用原型时识别潜在危害，用户研究表明使用Farsight后，AI原型设计者能够更好地独立识别与提示相关的潜在危害。 |
| [^22] | [Information-Theoretic Safe Bayesian Optimization](https://arxiv.org/abs/2402.15347) | 提出了一种信息论安全探索准则，结合贝叶斯优化收益函数，形成了一种新颖的安全贝叶斯优化选择准则。 |
| [^23] | [NuNER: Entity Recognition Encoder Pre-training via LLM-Annotated Data](https://arxiv.org/abs/2402.15343) | 利用LLM注释数据进行实体识别编码器预训练，创建了NuNER，一种专门用于命名实体识别任务的紧凑语言表示模型，可以在少样本学习领域胜过相似大小的基础模型，并与更大的LLMs竞争。 |
| [^24] | [A Quantum-Classical Collaborative Training Architecture Based on Quantum State Fidelity](https://arxiv.org/abs/2402.15333) | 量子深度学习引入了一种新的协同经典-量子架构co-TenQu，通过经典组件的压缩和特征提取，实现了高维数据编码到逻辑量子电路上。 |
| [^25] | [Categorical Deep Learning: An Algebraic Theory of Architectures](https://arxiv.org/abs/2402.15332) | 提出了一种关于深度学习架构的代数理论，应用范畴论构建了一个桥梁，有效地涵盖了神经网络设计的不同风格，同时自然地编码了计算机科学和自动机理论中的许多标准结构。 |
| [^26] | [OpenSUN3D: 1st Workshop Challenge on Open-Vocabulary 3D Scene Understanding](https://arxiv.org/abs/2402.15321) | 提供了OpenSUN3D研讨会上针对开放词汇3D场景理解的挑战概述，包括挑战数据集、评估方法和获胜方法的简要描述 |
| [^27] | [ArabianGPT: Native Arabic GPT-based Large Language](https://arxiv.org/abs/2402.15313) | 提出了ArabianGPT，这是一系列专门为阿拉伯语设计的基于Transformer的模型，包括大小和复杂性不同的ArabianGPT-0.1B和ArabianGPT-0.3B，帮助弥补了本土阿拉伯语大型语言模型的不足。 |
| [^28] | [Representing Online Handwriting for Recognition in Large Vision-Language Models](https://arxiv.org/abs/2402.15307) | 本文研究了在大型视觉语言模型中进行在线手写识别，提出了一种新颖的数字墨水(tokenized representation)表示方法，将手写呈现为文本序列和图像，取得了可与现有方法媲美的结果。 |
| [^29] | [Seeing is Believing: Mitigating Hallucination in Large Vision-Language Models via CLIP-Guided Decoding](https://arxiv.org/abs/2402.15300) | CLIP相似性作为更强大和更稳健的幻觉指标，研究提出了CLIP引导解码（CGD）方法，在大型视觉-语言模型中有效减少对象幻觉。 |
| [^30] | [A Survey of Music Generation in the Context of Interaction](https://arxiv.org/abs/2402.15294) | 该论文调查了音乐生成领域的现状，针对机器学习在音乐创作中的应用进行了综合评估，探讨了当前研究的主要焦点以及存在的挑战。 |
| [^31] | [Linear Dynamics-embedded Neural Network for Long-Sequence Modeling](https://arxiv.org/abs/2402.15290) | 提出了一种名为嵌入线性动力学的神经网络（LDNN），通过引入连续状态空间模型的属性和优化策略，实现了在长序列任务中具有少量参数、灵活推断和高效训练，最终在长距离竞技场上取得了有效且领先的性能。 |
| [^32] | [Spatiotemporal Observer Design for Predictive Learning of High-Dimensional Data](https://arxiv.org/abs/2402.15284) | 本文设计了一个名为“时空观察者”的观察者理论引导的深度学习架构，为高维数据的预测学习提供了泛化误差界限和收敛保证，并引入了动态正则化以更好地学习系统动态。 |
| [^33] | [When in Doubt, Think Slow: Iterative Reasoning with Latent Imagination](https://arxiv.org/abs/2402.15283) | 通过在决策时应用迭代推理来微调推断的代理状态，能够在视觉3D导航任务中取得一致的性能改进，并在部分可观察环境中得到更好的表现。 |
| [^34] | [Text2Pic Swift: Enhancing Long-Text to Image Retrieval for Large-Scale Libraries](https://arxiv.org/abs/2402.15276) | Text2Pic Swift框架针对大规模库中文本描述到图像的检索提出了一种高效且强大的方法，通过两阶段策略解决了长文本查询中的歧义问题 |
| [^35] | [EMIFF: Enhanced Multi-scale Image Feature Fusion for Vehicle-Infrastructure Cooperative 3D Object Detection](https://arxiv.org/abs/2402.15272) | 提出了一种新的基于相机的三维检测框架EMIFF，通过多尺度交叉注意力和相机感知通道屏蔽模块来增强基础设施和车辆特征，以解决车路协同三维目标检测中的姿态误差和信息丢失问题 |
| [^36] | [Smoothed Graph Contrastive Learning via Seamless Proximity Integration](https://arxiv.org/abs/2402.15270) | SGCL模型通过三种不同的平滑技术调整对比损失中节点对的惩罚，从而形成具有接近度感知的正样本和负样本 |
| [^37] | [MemoryPrompt: A Light Wrapper to Improve Context Tracking in Pre-trained Language Models](https://arxiv.org/abs/2402.15268) | MemoryPrompt方法通过引入辅助循环网络，将信息传递给语言模型，从而改进了预训练语言模型在上下文跟踪方面的性能，避免了灾难性遗忘现象。 |
| [^38] | [Adversarial Robustness of Deep Learning-based Malware Detectors via (De)Randomized Smoothing](https://arxiv.org/abs/2402.15267) | 通过选择相关的字节子集替代高斯噪声，在训练中进行基于消融的平滑方案，加强了基于深度学习的恶意软件检测器对抗性恶意软件示例的鲁棒性。 |
| [^39] | [Dynamic Memory Based Adaptive Optimization](https://arxiv.org/abs/2402.15262) | 提出了一种称为“回顾式学习法律修正”的通用方法，用于计算内存单元的动态变化线性组合，能够在具有线性更新规则和小内存的优化器中取得优于经典优化器的性能。 |
| [^40] | [Optimal Transport for Structure Learning Under Missing Data](https://arxiv.org/abs/2402.15255) | 提出了一种基于最优输运的得分算法，用于从缺失数据中学习因果结构，通过将结构学习视为密度拟合问题，并通过最小化与观测数据分布之间的沃尔仑斯坦距离来找到导致观测数据分布的因果模型 |
| [^41] | [A Bargaining-based Approach for Feature Trading in Vertical Federated Learning](https://arxiv.org/abs/2402.15247) | 该研究提出了一种基于谈判的垂直联邦学习特征交易方法，以促进经济高效的交易 |
| [^42] | [Artificial Bee Colony optimization of Deep Convolutional Neural Networks in the context of Biomedical Imaging](https://arxiv.org/abs/2402.15246) | 我们提出了Chimera算法，该算法是一种新颖的混合神经进化算法，用于优化深度学习架构。 |
| [^43] | [Fixed Random Classifier Rearrangement for Continual Learning](https://arxiv.org/abs/2402.15227) | 提出了一种名为固定随机分类器重排（FRCR）的两阶段持续学习算法，通过替换可学习的分类器为固定的随机分类器，在不影响网络性能的情况下，约束了等价的单分类器的范数。 |
| [^44] | [Enhancing ICU Patient Recovery: Using LLMs to Assist Nurses in Diary Writing](https://arxiv.org/abs/2402.15205) | 使用大型语言模型（LLMs）辅助护士书写日记，有助于改善ICU患者的长期康复结果 |
| [^45] | [Safety Optimized Reinforcement Learning via Multi-Objective Policy Optimization](https://arxiv.org/abs/2402.15197) | 本文提出了一种基于多目标策略优化框架的安全强化学习算法，通过安全评论家塑造环境奖励函数，使得策略可以同时朝着最优性和安全性优化，相较于传统方法，该算法无需约束策略搜索空间，实现了安全性和最优性之间的自然权衡。 |
| [^46] | [The AffectToolbox: Affect Analysis for Everyone](https://arxiv.org/abs/2402.15195) | AffectToolbox是一个新型软件系统，旨在为开发情感敏感研究和原型的研究人员提供支持，无需编程知识即可可靠分析用户情感状态，实现多模情感识别和融合评估。 |
| [^47] | [Fine-Tuning of Continuous-Time Diffusion Models as Entropy-Regularized Control](https://arxiv.org/abs/2402.15194) | 扩散模型的微调方法可以通过最大化奖励函数的价值来以目标导向方式进行微调，但可能会面临奖励崩溃的挑战。 |
| [^48] | [Biomedical Entity Linking as Multiple Choice Question Answering](https://arxiv.org/abs/2402.15189) | 提出了一种新颖的模型BioELQA，将生物医学实体链接看作是多项选择问答，通过使用快速检索器获得候选实体，实现了更好的实体链接效果。 |
| [^49] | [GraphEdit: Large Language Models for Graph Structure Learning](https://arxiv.org/abs/2402.15183) | 本研究提出了一种名为GraphEdit的方法，利用大型语言模型（LLMs）学习复杂的图结构化数据中的节点关系，通过在图结构上进行指导调整，增强LLMs的推理能力，从而提高图结构学习的可靠性。 |
| [^50] | [The Surprising Effectiveness of Skip-Tuning in Diffusion Sampling](https://arxiv.org/abs/2402.15170) | 跳跃调谐是一种简单而惊人有效的训练方法，可以提高扩散采样中UNet模型的性能，并突破了ODE采样器的限制 |
| [^51] | [Studying the Impact of Stochasticity on the Evaluation of Deep Neural Networks for Forest-Fire Prediction](https://arxiv.org/abs/2402.15163) | 该论文首次系统研究了在随机假设下评估深度神经网络用于森林火灾预测的影响，发现评估对统计的忠实度是在高度随机场景下的可靠替代方法。 |
| [^52] | [Entity-level Factual Adaptiveness of Fine-tuning based Abstractive Summarization Models](https://arxiv.org/abs/2402.15162) | 分析了基于微调的摘要模型在处理知识冲突时的实体级事实适应性，并提出了一种反事实数据增强方法，实验结果表明该方法增强了事实适应性，同时保持了事实一致性。 |
| [^53] | [Spatially-Aware Transformer Memory for Embodied Agents](https://arxiv.org/abs/2402.15160) | 本文探讨了利用包含空间信息的面向空间感知变压器模型，以改善记忆利用效率。 |
| [^54] | [Machine Unlearning of Pre-trained Large Language Models](https://arxiv.org/abs/2402.15159) | 本研究在大型语言模型（LLMs）中探讨了“被遗忘权”的概念，提出机器遗忘作为解决方案，并在预训练模型中建立了全面的遗忘框架及高效的遗忘方法，同时提供了改进超参数鲁棒性以及高效调整超参数的指南。 |
| [^55] | [On the Duality Between Sharpness-Aware Minimization and Adversarial Training](https://arxiv.org/abs/2402.15152) | 通过研究Sharpness-Aware最小化(SAM)和对抗训练(AT)之间的对偶性，发现单独使用SAM可以提高对抗性能。 |
| [^56] | [A Relation-Interactive Approach for Message Passing in Hyper-relational Knowledge Graphs](https://arxiv.org/abs/2402.15140) | 提出了一种消息传递的图编码器ReSaE，具有全局关系结构意识能力，强调了关系在消息传递过程中的交互，并优化了用于链接预测任务的读取结构，在超关系知识图上表现出色。 |
| [^57] | [Modified CycleGAN for the synthesization of samples for wheat head segmentation](https://arxiv.org/abs/2402.15135) | 通过修改的CycleGAN模型，成功解决了合成数据与真实数据之间的域差异，为小麦头部分割样本合成提供了可用于训练深度学习模型的合成数据集。 |
| [^58] | [Deep Coupling Network For Multivariate Time Series Forecasting](https://arxiv.org/abs/2402.15134) | 重新审视多元时间序列的序内和序间关系，提出了一种用于预测的深度耦合网络，可以同时捕捉多阶序内和序间的复杂耦合。 |
| [^59] | [Interactive-KBQA: Multi-Turn Interactions for Knowledge Base Question Answering with Large Language Models](https://arxiv.org/abs/2402.15131) | 提出了一种互动式KBQA框架，通过直接与知识库互动生成逻辑形式，开发了用于KB交互的通用API，并设计了示例来指导大型语言模型进行推理。 |
| [^60] | [Fine-tuning CLIP Text Encoders with Two-step Paraphrasing](https://arxiv.org/abs/2402.15120) | 通过两步重述生成过程对CLIP模型进行微调，以增强对释义的表示能力。 |
| [^61] | [Large Multimodal Agents: A Survey](https://arxiv.org/abs/2402.15116) | 大型语言模型驱动的多模态代理（LMAs）的系统审查，涵盖了开发组件、研究类型分类以及集体效能增强的合作框架等内容。 |
| [^62] | [Trajectory-wise Iterative Reinforcement Learning Framework for Auto-bidding](https://arxiv.org/abs/2402.15102) | 自动广告竞标中使用了一种新的迭代离线强化学习框架，有效缓解了传统RL算法在在线环境下性能下降的问题。 |
| [^63] | [AttributionBench: How Hard is Automatic Attribution Evaluation?](https://arxiv.org/abs/2402.15089) | AttributionBench是一个综合基准，揭示了自动归因评估的挑战，即使对于最先进的语言模型也只能达到80%的准确率。 |
| [^64] | [Hands-Free VR](https://arxiv.org/abs/2402.15083) | Hands-Free VR 是一种无需手部操作的虚拟现实系统，通过语音命令实现，具有英语口音鲁棒性，通过深度学习模型和大型语言模型实现对文本的转换和执行。 |
| [^65] | [Stacking Factorizing Partitioned Expressions in Hybrid Bayesian Network Models](https://arxiv.org/abs/2402.15075) | 提出了一种新算法叫做堆叠分解（SF），用于在混合贝叶斯网络模型中处理分区表达式，可以有效地减小复杂条件概率分布的大小。 |
| [^66] | [On the Multi-turn Instruction Following for Conversational Web Agents](https://arxiv.org/abs/2402.15057) | 提出了一个新任务——对话式网络导航，引入了一个名为MT-Mind2Web的特殊数据集，并提出了一个名为Self-MAP的框架，旨在解决大型语言模型在多轮指令跟踪中的长度和上下文依赖性问题。 |
| [^67] | [Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions](https://arxiv.org/abs/2402.15055) | 该研究探究了Transformer中注意力头和MLP之间的相互作用，并揭示了特定上下文下激活特定token预测的机制，从而阐明在LLMs中注意力如何促成依赖上下文的专门化处理。 |
| [^68] | [ToMBench: Benchmarking Theory of Mind in Large Language Models](https://arxiv.org/abs/2402.15052) | 提出了ToMBench框架，在大型语言模型中进行心灵理论性能评估，发现最先进的模型仍然落后于人类表现超过10%。 |
| [^69] | [Unlocking the Power of Large Language Models for Entity Alignment](https://arxiv.org/abs/2402.15048) | ChatEA是一个创新性框架，利用大型语言模型提高实体对齐准确性，通过引入KG-code翻译模块和两阶段EA策略来克服传统方法的局限性。 |
| [^70] | [KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large Language Models](https://arxiv.org/abs/2402.15043) | 该论文引入了KIEval，一种知识引导式交互评估框架，通过LLM-powered "interactor"角色实现动态的抗污染评估 |
| [^71] | [Dynamics-Guided Diffusion Model for Robot Manipulator Design](https://arxiv.org/abs/2402.15038) | 该论文提出了动态引导扩散模型，利用共享的动力学网络为不同操作任务生成 manipulator 几何设计，通过设计目标构建的梯度引导手指几何设计的完善过程。 |
| [^72] | [Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education](https://arxiv.org/abs/2402.15027) | 本研究从多利益相关者视角探讨了教育中不同人工智能应用的可接受性，关注数据隐私、AI代理、透明度、可解释性和道德部署等问题。 |
| [^73] | [Consistency-Guided Temperature Scaling Using Style and Content Information for Out-of-Domain Calibration](https://arxiv.org/abs/2402.15019) | 提出了一种新的一致性引导温度缩放（CTS）策略，通过提供源域数据样本之间的相互监督，显著增强了域外（OOD）校准性能。 |
| [^74] | [Towards Few-Shot Adaptation of Foundation Models via Multitask Finetuning](https://arxiv.org/abs/2402.15017) | 多任务微调的方法通过在基础模型上对相关任务进行微调，然后适应限制标签数的目标任务，能够降低目标任务中的误差，并提出了一种实用的任务选择算法。 |
| [^75] | [Ar-Spider: Text-to-SQL in Arabic](https://arxiv.org/abs/2402.15012) | 本文介绍了Ar-Spider，这是第一个阿拉伯跨领域文本到SQL数据集，为解决阿拉伯语言的独特性质所带来的模式语言和SQL结构挑战，引入了两个基线模型并测试了两个跨语言模型，取得了不错的性能。 |
| [^76] | [A Conversational Brain-Artificial Intelligence Interface](https://arxiv.org/abs/2402.15011) | BAIs利用人工智能代替神经-认知处理管线的部分，让认知功能受损的个体能够通过高层意图完成复杂任务，例如通过主观提供意图完成模拟电话对话。 |
| [^77] | [How Important Is Tokenization in French Medical Masked Language Models?](https://arxiv.org/abs/2402.15010) | 子词标记化成为自然语言处理领域的主流标准，但其成功因素，如不同任务和语言的最佳分割粒度、数据源对标记工具的影响以及形态信息在印欧语言中的作用，仍不明确。 |
| [^78] | [tinyBenchmarks: evaluating LLMs with fewer examples](https://arxiv.org/abs/2402.14992) | 本文研究了减少评估LLMs性能所需的评估次数的策略，并展示了在小规模示例上可以准确估计LLMs在多种基准测试上的性能。 |
| [^79] | [Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data](https://arxiv.org/abs/2402.14989) | 神经常微分方程（Neural ODEs）的扩展——神经随机微分方程（Neural SDEs）在处理不规则时间序列数据中的稳定性和性能方面提出了重要指导，需要谨慎设计漂移和扩散函数以保持稳定性。 |
| [^80] | [AI-Augmented Brainwriting: Investigating the use of LLMs in group ideation](https://arxiv.org/abs/2402.14978) | 本文探讨了在团体构思中将LLMs整合到创意过程中的两个方面，并发现将LLMs整合到Brainwriting中可以增强构思过程及其结果，并提供了支持想法评估的证据。 |
| [^81] | [Unsupervised Domain Adaptation within Deep Foundation Latent Spaces](https://arxiv.org/abs/2402.14976) | 提出了一种在深度基础潜空间内进行无监督领域自适应的方法，通过分析和定性解释，展示了该方法可以优于现有基线，并显示了尚未解决的局限性。 |
| [^82] | [Towards Spatially-Lucid AI Classification in Non-Euclidean Space: An Application for MxIF Oncology Data](https://arxiv.org/abs/2402.14974) | 发展了一个使用空间集合框架的分类器，可以根据点的排列在非欧几里得空间中区分两个类别，对于肿瘤学等应用具有重要意义 |
| [^83] | [GenCeption: Evaluate Multimodal LLMs with Unlabeled Unimodal Data](https://arxiv.org/abs/2402.14973) | 提出了一种名为GenCeption的新型MLLM评估框架，可以仅利用单模态数据评估跨模态语义一致性，并有效反映模型产生幻觉的倾向，具有较强的相关性和潜力于流行的MLLM基准结果。 |
| [^84] | [MultiLS: A Multi-task Lexical Simplification Framework](https://arxiv.org/abs/2402.14972) | MultiLS是第一个允许创建多任务LS数据集的框架，提出了MultiLS-PT作为第一个使用该框架创建的数据集，展示了其在词汇简化相关任务中的潜力。 |
| [^85] | [Mirror: A Multiple-perspective Self-Reflection Method for Knowledge-rich Reasoning](https://arxiv.org/abs/2402.14963) | Mirror 提出了一种多视角自我反思方法，通过导航者和推理者之间的启发式交互，促进多样性而具有可靠性的推理轨迹发展，解决了大型语言模型在处理知识丰富问题上的困难。 |
| [^86] | [Path Planning based on 2D Object Bounding-box](https://arxiv.org/abs/2402.14933) | 提出了一种利用2D物体边界框进行路径规划的方法，通过融合高清地图数据和周围摄像头拍摄的图像，在城市驾驶场景中实现了路径规划。 |
| [^87] | [Federated Fairness without Access to Sensitive Groups](https://arxiv.org/abs/2402.14929) | 提出了一种不依赖于预定义敏感群体定义或额外标签的方法，通过一个超参数实现公平性和效用之间的权衡，保证任何足够大的人群子集能获得至少最低效用性能。 |
| [^88] | [Learning Inverse Kinodynamics for Autonomous Vehicle Drifting](https://arxiv.org/abs/2402.14928) | 通过数据驱动的方法学习小型自动车的运动学模型，特别是为了实现高速圆形导航和自主漂移，帮助车辆学习世界状态并避开障碍物。 |
| [^89] | [Practical Insights into Knowledge Distillation for Pre-Trained Models](https://arxiv.org/abs/2402.14922) | 研究对知识蒸馏在预训练模型中的应用进行了深入比较，包括优化的温度和权重参数的调整，以及数据分区KD，揭示了最有效的知识蒸馏策略。 |
| [^90] | [MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases](https://arxiv.org/abs/2402.14905) | MobileLLM通过优化模型架构，采用深度和瘦身结构、嵌入共享和分组查询注意机制，实现了2.7%/4.3%的准确率提升，并提出了一种无需增加模型大小且仅有极小延迟开销的块状权重共享方法 |
| [^91] | [Watermarking Makes Language Models Radioactive](https://arxiv.org/abs/2402.14904) | 本文研究了LLM生成文本的放射性，表明使用数字水印训练数据能更容易检测到，同时也展示了即使只有很少比例的水印训练文本，仍可以高置信度地检测出使用数字水印进行微调的情况。 |
| [^92] | [A Usage-centric Take on Intent Understanding in E-Commerce](https://arxiv.org/abs/2402.14901) | 该论文提出了电子商务中意图理解的一个新视角，不依赖于产品本体，通过引入产品恢复基准验证了当前意图知识图的弱点。 |
| [^93] | [Stop Reasoning! When Multimodal LLMs with Chain-of-Thought Reasoning Meets Adversarial Images](https://arxiv.org/abs/2402.14899) | 该研究评估了多模态LLMs在采用串联推理时的对抗鲁棒性，发现串联推理在一定程度上提高了对抗性鲁棒性，但引入了一种新的停止推理攻击技术成功规避了这种增强。 |
| [^94] | [Chain-of-Thought Unfaithfulness as Disguised Accuracy](https://arxiv.org/abs/2402.14897) | 了解Chain-of-Thought生成与大语言模型内部计算的一致程度对于决定是否信任模型输出至关重要，研究发现模型大小与忠实度之间存在着特定关系，并且发现130亿参数模型表现出更高的忠实度。 |
| [^95] | [Data Augmentation is Dead, Long Live Data Augmentation](https://arxiv.org/abs/2402.14895) | 数据增强不过是更好地微调模型，零唁态和少样本数据生成可提高性能 |
| [^96] | [Data-Driven Ground-Fault Location Method in Distribution Power System With Distributed Generation](https://arxiv.org/abs/2402.14894) | 提出了一种基于数据驱动的接地故障定位方法，通过离散小波变换和人工神经网络分析处理数据，实现了对配电系统中故障的准确预测 |
| [^97] | [LLMBind: A Unified Modality-Task Integration Framework](https://arxiv.org/abs/2402.14891) | 提出了LLMBind，一种统一的模态任务集成框架，通过将大型语言模型和预训练任务模型绑定在一起，实现了多种模态任务的灵活输入和输出组合。 |
| [^98] | [Vygotsky Distance: Measure for Benchmark Task Similarity](https://arxiv.org/abs/2402.14890) | 论文提出了一种基于相对性能而非任务属性的相似性度量方法，即“维果茨基距离”，可帮助减少评估任务数量并保持高验证质量。 |
| [^99] | [COBIAS: Contextual Reliability in Bias Assessment](https://arxiv.org/abs/2402.14889) | 我们提出了COBIAS，旨在通过考虑多样情境的用户输入内容，衡量语句的情境可靠性，从而培养偏见意识。 |
| [^100] | [Efficient data selection employing Semantic Similarity-based Graph Structures for model training](https://arxiv.org/abs/2402.14888) | 提出了一种基于语义相似性的图结构的高效数据选择机制，可在不经过计算密集型模型或其他密集的预处理转换的情况下，用于模型训练。 |
| [^101] | [Applying Reinforcement Learning to Optimize Traffic Light Cycles](https://arxiv.org/abs/2402.14886) | 提出了将强化学习应用于交通信号灯循环优化，实验证明能显著减少紧急停车次数，降低交通拥堵，改善交通流。 |
| [^102] | [Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning](https://arxiv.org/abs/2402.14883) | 提出了一种名为“双I水印”的水印方法，通过引入两种backdoor数据范例并利用LLM的学习能力，有效地保护了LLM微调定制模型的版权。 |
| [^103] | [Deep Generative Model-based Synthesis of Four-bar Linkage Mechanisms with Target Conditions](https://arxiv.org/abs/2402.14882) | 提出了基于深度生成模型的方法，利用条件生成对抗网络生成满足运动学和准静态要求的多连杆四连杆机构。 |
| [^104] | [A Study on the Vulnerability of Test Questions against ChatGPT-based Cheating](https://arxiv.org/abs/2402.14881) | 研究揭示了基于ChatGPT的作弊对测试题的漏洞，并开发了一个工具来辨别测试题中对ChatGPT最容易回答错误的类型。 |
| [^105] | [Automatic Histograms: Leveraging Language Models for Text Dataset Exploration](https://arxiv.org/abs/2402.14880) | 该论文提出了一种利用语言模型的自动直方图可视化工具AutoHistograms，能够自动识别相关特征、以直方图形式展示并允许用户交互式地查询数据集，帮助数据工作者快速探索文本数据集。 |
| [^106] | [Driving Generative Agents With Their Personality](https://arxiv.org/abs/2402.14879) | 大型语言模型（LLMs）利用心理测量值，在视频游戏角色开发中代表给定的人格特征，增强游戏角色的类人特性。 |
| [^107] | [Energy-efficiency Limits on Training AI Systems using Learning-in-Memory](https://arxiv.org/abs/2402.14878) | 该论文提出了使用内存中学习的方法训练AI系统时的能效限制，并推导了新的理论下限。 |
| [^108] | [What's in a Name? Auditing Large Language Models for Race and Gender Bias](https://arxiv.org/abs/2402.14875) | 调查发现，大型语言模型存在种族和性别偏见，尤其对与黑人女性相关的名字表现最不利。审计在模型部署和实施时的重要性得到强调。 |
| [^109] | [Distillation Contrastive Decoding: Improving LLMs Reasoning with Contrastive Decoding and Distillation](https://arxiv.org/abs/2402.14874) | 该研究提出了一种叫做蒸馏对比解码（DCD）的方法，通过结合对比提示与蒸馏技术，有效提升了大型语言模型（LLM）在推理任务上的性能表现，超过了传统的对比解码方法，并在多个基准数据集上取得了显著成果。 |
| [^110] | [Technical Report on the Checkfor.ai AI-Generated Text Classifier](https://arxiv.org/abs/2402.14873) | Checkfor.ai AI生成文本分类器在区分大型语言模型生成文本和人类编写文本方面表现优异，提出了硬负挖掘与合成镜像训练算法，具有高准确性和泛化能力。 |
| [^111] | [Semantic Mirror Jailbreak: Genetic Algorithm Based Jailbreak Prompts Against Open-source LLMs](https://arxiv.org/abs/2402.14872) | 本文提出了一种语义镜像越狱（SMJ）方法，通过生成在语义上类似于原始问题的越狱提示来绕过LLMs。 |
| [^112] | [LLM Based Multi-Agent Generation of Semi-structured Documents from Semantic Templates in the Public Administration Domain](https://arxiv.org/abs/2402.14871) | 该论文创新之处在于将LLMs与提示工程和多Agent系统相结合，以生成符合特定结构的新文档。 |
| [^113] | [Effects of term weighting approach with and without stop words removing on Arabic text classification](https://arxiv.org/abs/2402.14867) | 本研究比较不同的加权特征方法（二元和词频加权）在文本分类中使用和不使用停用词时的影响，通过评估准确性、召回率、精确度和F-度量值，结果表明停用词的处理方式对文本分类结果具有重要影响。 |
| [^114] | [APTQ: Attention-aware Post-Training Mixed-Precision Quantization for Large Language Models](https://arxiv.org/abs/2402.14866) | APTQ提出了针对大型语言模型的注意力感知后训练混合精度量化方法，在保持模型性能的同时，超越了先前的量化方法，并在零-shot任务上达到了最先进的准确率 |
| [^115] | [DyVal 2: Dynamic Evaluation of Large Language Models by Meta Probing Agents](https://arxiv.org/abs/2402.14865) | 本文提出了一种基于心理测量学思想的元探测代理（MPA）动态评估协议，用于评估大型语言模型（LLMs）的能力。 |
| [^116] | [CloudNine: Analyzing Meteorological Observation Impact on Weather Prediction Using Explainable Graph Neural Networks](https://arxiv.org/abs/2402.14861) | 提出了一个名为“CloudNine”的系统，利用可解释图神经网络分析气象观测对特定天气预测的影响 |
| [^117] | [Ranking Large Language Models without Ground Truth](https://arxiv.org/abs/2402.14860) | 不需要基准实况或参考响应的条件下，通过考虑模型的三元组来排名大型语言模型，并提出了两种排名方法。 |
| [^118] | [The Wolf Within: Covert Injection of Malice into MLLM Societies via an MLLM Operative](https://arxiv.org/abs/2402.14859) | 这里是中文总结出的一句话要点: 论文探讨了在MLLM社会中通过单个操作员间接影响其他代理生成恶意内容的新型漏洞。 |
| [^119] | [ChatEL: Entity Linking with Chatbots](https://arxiv.org/abs/2402.14858) | ChatEL框架通过三步框架改进了实体链接任务的性能，使得平均F1性能提高超过2％ |
| [^120] | [Is the System Message Really Important to Jailbreaks in Large Language Models?](https://arxiv.org/abs/2402.14857) | 系统消息在大型语言模型中的越狱过程中起着重要作用，不同系统消息对抵抗越狱具有不同影响，且越狱可能在不同语言模型之间具有可转移性。 |
| [^121] | [Comparing Inferential Strategies of Humans and Large Language Models in Deductive Reasoning](https://arxiv.org/abs/2402.14856) | 该研究通过对大型语言模型对命题逻辑问题的响应进行评估，揭示出它们展现出与人类类似的推理模式和策略。 |
| [^122] | [An LLM Maturity Model for Reliable and Transparent Text-to-Query](https://arxiv.org/abs/2402.14855) | 这项工作提出了一种适用于文本到查询应用的LLM成熟度模型，不仅关注准确性，还扩展到更多维度。同时，展示了一个用于执法领域的实际案例，介绍了域特定文本到查询助手QueryIQ。 |
| [^123] | [A Dual-Prompting for Interpretable Mental Health Language Models](https://arxiv.org/abs/2402.14854) | 提出了一种双提示方法，结合专家身份和自杀词典与心理健康特定LLM相结合，有效提升了在心理健康分析中的解释性和帮助临床医生评估心理状态进展。 |
| [^124] | [NL2Formula: Generating Spreadsheet Formulas from Natural Language Queries](https://arxiv.org/abs/2402.14853) | 提出了NL2Formula任务，旨在通过自然语言查询生成基于电子表格表格的可执行公式，并提供了一个名为fCoder的基准实现。 |
| [^125] | [HumanEval on Latest GPT Models -- 2024](https://arxiv.org/abs/2402.14852) | 使用最新的GPT-4模型在程序合成方面取得显著进展，通过在HumanEval任务中展示了在零样本Python代码生成中的竞争性性能和更多多步骤范式综合。 |
| [^126] | [SQL-CRAFT: Text-to-SQL through Interactive Refinement and Enhanced Reasoning](https://arxiv.org/abs/2402.14851) | 提出了SQL-CRAFT框架，通过交互式改进和增强推理，提升了大语言模型在文本到SQL转换任务中的性能，实验结果显示性能提升高达5.7%，并在Spider榜单上超越了当前最先进技术。 |
| [^127] | [CHATATC: Large Language Model-Driven Conversational Agents for Supporting Strategic Air Traffic Flow Management](https://arxiv.org/abs/2402.14850) | 本研究探讨了如何将大型语言模型应用于非安全关键的战略交通流量管理环境，提出了一个名为CHATATC的模型，通过训练大量历史数据集实现对话系统，并测试了其查询和响应能力。 |
| [^128] | [Asynchronous and Segmented Bidirectional Encoding for NMT](https://arxiv.org/abs/2402.14849) | 本文介绍了一种基于Transformer的改进模型，引入了异步和分段的双向编码策略，以提高神经机器翻译的效率和准确性。 |
| [^129] | [Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models](https://arxiv.org/abs/2402.14848) | 输入长度对大型语言模型的推理性能有显著影响，降级趋势出现在比技术最大值短得多的输入长度下。 |
| [^130] | [Deep learning-driven scheduling algorithm for a single machine problem minimizing the total tardiness](https://arxiv.org/abs/2402.14847) | 本文提出了一种基于深度学习的单机问题调度算法，通过神经网络估计最佳问题划分方式以最小化总滞后。 |
| [^131] | [Stick to your Role! Stability of Personal Values Expressed in Large Language Models](https://arxiv.org/abs/2402.14846) | 本文提出研究在大型语言模型中个人价值在不同背景下的表达稳定性，通过模拟对话的方式进行评估，对19个LLMs进行比较研究。 |
| [^132] | [Purifying Large Language Models by Ensembling a Small Language Model](https://arxiv.org/abs/2402.14845) | 通过将大型语言模型与小型语言模型集成，可以有效净化大型语言模型，保持其性能并减轻版权侵权、数据污染和隐私侵犯等问题 |
| [^133] | [Text Diffusion with Reinforced Conditioning](https://arxiv.org/abs/2402.14843) | 提出了一种名为TREC的文本扩散模型，通过强化调节和时间感知方差缩放解决了现有文本扩散模型在训练过程中自我调节的退化和训练与采样不一致的问题，展示了其在不同序列生成任务中的竞争力。 |
| [^134] | [RJUA-MedDQA: A Multimodal Benchmark for Medical Document Question Answering and Clinical Reasoning](https://arxiv.org/abs/2402.14840) | 介绍了RJUA-MedDQA，一个医学专业领域的全面基准，具有挑战性的要求，涉及解释图像内容、数值推理和临床推理能力。 |
| [^135] | [RFBES at SemEval-2024 Task 8: Investigating Syntactic and Semantic Features for Distinguishing AI-Generated and Human-Written Texts](https://arxiv.org/abs/2402.14838) | 该研究探究了语义和句法两个方面用于区分AI生成文本和人类撰写文本的问题，并提出了一个高准确度的AI模型，在M4数据集上表现出较好的性能。 |
| [^136] | [An Empirical Categorization of Prompting Techniques for Large Language Models: A Practitioner's Guide](https://arxiv.org/abs/2402.14837) | 编制了一个全面的大型语言模型提示技术清单，并建立了一个跨学科的分类框架，以帮助从业者更有效地利用这些技术。 |
| [^137] | [Stealthy Attack on Large Language Model based Recommendation](https://arxiv.org/abs/2402.14836) | 大型语言模型推荐系统容易受到隐秘攻击，攻击者可以通过微调文本内容在不干预模型训练的情况下显著提高物品的曝光度，而这种攻击对整体推荐性能无影响且难以被检测到。 |
| [^138] | [MIKE: A New Benchmark for Fine-grained Multimodal Entity Knowledge Editing](https://arxiv.org/abs/2402.14835) | MIKE是一个针对细粒度多模态实体知识编辑的全面基准和数据集，突破了现有基准主要侧重于粗粒度知识的局限性，引入了新的知识编辑形式以评估编辑效率。 |
| [^139] | [MSynFD: Multi-hop Syntax aware Fake News Detection](https://arxiv.org/abs/2402.14834) | 提出一种新的多跳语法感知假新闻检测方法，通过引入补充的语法信息来处理假新闻中的微妙转折 |
| [^140] | [CliqueParcel: An Approach For Batching LLM Prompts That Jointly Optimizes Efficiency And Faithfulness](https://arxiv.org/abs/2402.14833) | CliqueParcel提出了一种通过提示批处理来提高LLM效率的方法，旨在在推理过程中同时确保准确性和最小化与原始输出的偏差，解决了折价输出问题。 |
| [^141] | [Orca-Math: Unlocking the potential of SLMs in Grade School Math](https://arxiv.org/abs/2402.14830) | 提出了一个基于Mistral-7B的70亿参数的Orca-Math小语言模型，旨在在小学数学中实现更高的准确度。 |
| [^142] | [Optimizing Uterine Synchronization Analysis in Pregnancy and Labor through Window Selection and Node Optimization](https://arxiv.org/abs/2402.14827) | 通过窗口方法和节点优化分析EHG信号，提出一种新方法来优化妊娠和分娩中的子宫同步分析。 |
| [^143] | [ConceptMath: A Bilingual Concept-wise Benchmark for Measuring Mathematical Reasoning of Large Language Models](https://arxiv.org/abs/2402.14660) | 介绍了ConceptMath，一种双语的细粒度基准测试，用于评估大型语言模型的概念性数学推理能力，并发现现有模型在不同数学概念上存在显著性能差异，甚至可能在最基本的概念上出现失败。 |
| [^144] | [Bringing Generative AI to Adaptive Learning in Education](https://arxiv.org/abs/2402.14601) | 生成式人工智能技术与自适应学习概念的交叉研究将对教育中下一阶段学习格式的发展做出重要贡献。 |
| [^145] | [OmniPred: Language Models as Universal Regressors](https://arxiv.org/abs/2402.14547) | 本文提出了OmniPred框架，用于训练语言模型作为通用的端到端回归器，实验证明，在多个任务上训练时，语言模型能够显著优于传统回归模型。 |
| [^146] | [REPOFUSE: Repository-Level Code Completion with Fused Dual Context](https://arxiv.org/abs/2402.14323) | RepoGenix独特融合类比上下文和理性上下文，并提出了截断排名生成（RTG）技术，以提高仓库级代码自动补全的准确性而不牺牲推理效率。 |
| [^147] | [Content Conditional Debiasing for Fair Text Embedding](https://arxiv.org/abs/2402.14208) | 通过在内容条件下确保敏感属性与文本嵌入之间的条件独立性，我们提出了一种可以改善公平性的新方法，在保持效用的同时，解决了缺乏适当训练数据的问题。 |
| [^148] | [EyeTrans: Merging Human and Machine Attention for Neural Code Summarization](https://arxiv.org/abs/2402.14096) | 引入EyeTrans方法，将人类注意力融入机器注意力，以增强神经代码摘要能力。 |
| [^149] | [Deep Generative Models for Offline Policy Learning: Tutorial, Survey, and Perspectives on Future Directions](https://arxiv.org/abs/2402.13777) | 深度生成模型在离线策略学习中展现了巨大潜力，本文提供了首个系统性综述，涵盖了五种主流深度生成模型及其应用。 |
| [^150] | [CriticBench: Evaluating Large Language Models as Critic](https://arxiv.org/abs/2402.13764) | CriticBench是一个旨在全面和可靠地评估大型语言模型的评论能力的新型基准，展示了评论能力与任务、响应质量和模型规模之间的关系。 |
| [^151] | [DSLR: Diversity Enhancement and Structure Learning for Rehearsal-based Graph Continual Learning](https://arxiv.org/abs/2402.13711) | DSLR提出了一种基于覆盖范围的多样性方法，以解决基于重播的图持续学习中回放节点过于集中导致过拟合和灾难性遗忘的问题。 |
| [^152] | [KetGPT -- Dataset Augmentation of Quantum Circuits using Transformers](https://arxiv.org/abs/2402.13352) | 该研究利用Transformer机器学习架构生成“看起来真实”的量子电路，以增强现有的量子电路数据集。 |
| [^153] | [Deep Hedging with Market Impact](https://arxiv.org/abs/2402.13326) | 本文提出了一种基于深度强化学习的市场影响动态套期保值模型，考虑了凸市场影响和随时间持续的影响，通过与常用程序比较，展示了其在期权套期保值方面的优越性。 |
| [^154] | [Benchmarking Retrieval-Augmented Generation for Medicine](https://arxiv.org/abs/2402.13178) | 通过提出首个医学信息检索增强生成评估(MIRAGE)基准测试，并使用MedRAG工具包进行大规模实验，实现了对多个大型语言模型的准确性改进。 |
| [^155] | [Learning to Check: Unleashing Potentials for Self-Correction in Large Language Models](https://arxiv.org/abs/2402.13035) | 通过精心设计训练数据和构建检查-校正数据集，本研究增强了大型语言模型的自我校正能力，提高了自我校正的准确性。 |
| [^156] | [A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence](https://arxiv.org/abs/2402.12928) | 本文旨在提供对模式分析与机器智能领域文献综述的全面评估，引入大语言模型驱动的文献计量指标，并构建了RiPAMI元数据数据库和主题数据集以获取PAMI综述的统计特征。 |
| [^157] | [Tables as Images? Exploring the Strengths and Limitations of LLMs on Multimodal Representations of Tabular Data](https://arxiv.org/abs/2402.12424) | 本研究探讨了LLM在解释表格数据方面的有效性，比较了文本和图像表格表示对LLM性能的影响，为在表格相关任务上有效使用LLM提供了见解。 |
| [^158] | [Robust agents learn causal world models](https://arxiv.org/abs/2402.10877) | 智能体必须学习因果模型才能在广泛的分布转变下达到后悔界限，这对迁移学习和因果推断等研究领域有重要影响。 |
| [^159] | [A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts](https://arxiv.org/abs/2402.09727) | ReadAgent是一个具有长期上下文概要记忆的阅读代理系统，通过实现一个简单的提示系统，它能够处理长输入并提高有效上下文长度。在评估中表现良好。 |
| [^160] | [Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications](https://arxiv.org/abs/2402.09015) | 本研究引入了AgentEval框架，用于评估LLM驱动应用的任务效用。该框架通过自动提出一套针对特定应用的评估标准，简化了效用验证过程，并对应用的效用进行了全面量化分析。 |
| [^161] | [UFO: A UI-Focused Agent for Windows OS Interaction](https://arxiv.org/abs/2402.07939) | UFO是一个专注于Windows操作系统上应用程序的用户界面智能体，利用GPT-Vision的能力来满足用户需求。它通过观察和分析Windows应用程序的图形用户界面和控制信息，实现无缝导航和操作以满足用户的请求。UFO的控制交互模块使得无需人工干预即可实现动作连接和完全自动化执行，使繁琐和耗时的过程变为简单任务。经过测试，UFO在各种场景中取得了良好效果。 |
| [^162] | [QACP: An Annotated Question Answering Dataset for Assisting Chinese Python Programming Learners](https://arxiv.org/abs/2402.07913) | 为解决编程智能教育系统中数据稀缺问题，本文提出了一个新的针对Python学习者的中文问答数据集，通过收集与分类真实学生问题，提高在线编程教育的效果和质量。 |
| [^163] | [Online Sequential Decision-Making with Unknown Delays](https://arxiv.org/abs/2402.07703) | 本文提出了在在线顺序决策中处理未知延迟问题的三个延迟算法族，并提供了相应的遗憾界限。 |
| [^164] | [Do Large Code Models Understand Programming Concepts? A Black-box Approach](https://arxiv.org/abs/2402.05980) | 本文使用反事实分析框架评估了十个大型代码模型对四种编程概念的理解情况，发现当前模型缺乏对数据流和控制流等概念的理解。 |
| [^165] | [KICGPT: Large Language Model with Knowledge in Context for Knowledge Graph Completion](https://arxiv.org/abs/2402.02389) | 本文提出了KICGPT，它是一个集成了大型语言模型和基于三元组的知识图谱补全检索器的框架。它通过知识提示的上下文学习策略，缓解了长尾问题，并且无需额外的训练开销。实验证明了其有效性。 |
| [^166] | [Evaluating Large Language Models in Analysing Classroom Dialogue](https://arxiv.org/abs/2402.02380) | 本研究评估了大型语言模型（LLMs），特点是GPT-4，对课堂对话进行分析的应用。结果显示，GPT-4能够显著节省时间，且在编码一致性方面表现出很高的一致性。 |
| [^167] | [Accelerating a Triton Fused Kernel for W4A16 Quantized Inference with SplitK work decomposition](https://arxiv.org/abs/2402.00025) | 本研究提出了一种加速W4A16量化推断的Triton融合内核的实现方法，通过使用SplitK工作分解实现解量化和GEMM操作，显著提高了瘦矩阵乘法的执行速度。 |
| [^168] | [Explainable Benchmarking for Iterative Optimization Heuristics](https://arxiv.org/abs/2401.17842) | 本文介绍了一种称为可解释基准测试的新方法，并提出了IOH-Xplainer软件框架，用于分析和理解优化算法的性能和影响。通过该框架，研究人员可以评估和解释迭代优化启发式方法在不同场景下的行为和效率。 |
| [^169] | [Graph Transformers without Positional Encodings](https://arxiv.org/abs/2401.17791) | 本文介绍了一种不需要位置编码的图变压器模型，该模型通过注意机制本身包含图结构信息，并通过实验证明了其有效性。 |
| [^170] | [Rethinking Channel Dependence for Multivariate Time Series Forecasting: Learning from Leading Indicators](https://arxiv.org/abs/2401.17548) | 本文提出了一种新方法，LIFT，通过利用通道相关性和领先指标，为多元时间序列预测提供准确的预测。LIFT方法可以无缝与任意时间序列预测方法协作，大量实验证明了其有效性。 |
| [^171] | [PythonSaga: Redefining the Benchmark to Evaluate Code Generating LLM](https://arxiv.org/abs/2401.03855) | PythonSaga提出了一种新的基准，针对Python代码生成进行评估,弥补了现有基准存在的编程概念偏见和简单任务普遍性的问题 |
| [^172] | [Exploring the Capabilities of ChatGPT in Ancient Chinese Translation and Person Name Recognition](https://arxiv.org/abs/2312.15304) | 本论文探索了ChatGPT在古代汉语翻译和人名识别方面的能力，并发现其在翻译方面的表现仍有待提高，最佳表现是在输入三个上下文句子时实现的。 |
| [^173] | [Factored Online Planning in Many-Agent POMDPs](https://arxiv.org/abs/2312.11434) | 该论文提出了一种针对多智能体POMDP的分解在线规划方法，通过引入加权粒子滤波和可扩展的信念逼近方法解决了值估计和信念估计难题。 |
| [^174] | [Revisiting the Role of Label Smoothing in Enhanced Text Sentiment Classification](https://arxiv.org/abs/2312.06522) | 通过在文本情感分类中进行深入分析，发现标签平滑可以加速深度模型的收敛，并使不同标签的样本更容易区分 |
| [^175] | [Remembering to Be Fair: Non-Markovian Fairness in Sequential Decision Making](https://arxiv.org/abs/2312.04772) | 本文研究了在序贯决策过程中的非马尔可夫公平性，发现公平往往取决于历史，需要在过程中的不同时间点进行评估。 |
| [^176] | [Contact Energy Based Hindsight Experience Prioritization](https://arxiv.org/abs/2312.02677) | 本文提出了一种基于接触能量的优先级排序方法（CEBP），用于解决强化学习算法中选择具有丰富接触信息的样本以提高学习效率的问题。 |
| [^177] | [InteRACT: Transformer Models for Human Intent Prediction Conditioned on Robot Actions](https://arxiv.org/abs/2311.12943) | InteRACT通过在大型人类-人类数据集上预训练条件意图预测模型，并在小型人机数据集上微调，解决了人机交互中的先有鸡还是先有蛋问题。 |
| [^178] | [Efficient Temporally-Aware DeepFake Detection using H.264 Motion Vectors](https://arxiv.org/abs/2311.10788) | 使用H.264视频编解码器中的运动矢量和信息掩模来检测DeepFake的时域不一致，有效且计算成本低，可能为视频通话和流媒体提供新的实时DeepFake检测方法 |
| [^179] | [Adversarial Preference Optimization](https://arxiv.org/abs/2311.08045) | 提出了一种对抗偏好优化（APO）框架，实现了在没有额外注释的情况下，通过对抗学习自适应于生成分布差距。 |
| [^180] | [Everything of Thoughts: Defying the Law of Penrose Triangle for Thought Generation](https://arxiv.org/abs/2311.04254) | 引入一种名为“一切的思考”（XoT）的新型思考促进方法，借助预训练的强化学习和蒙特卡洛树搜索（MCTS）将外部领域知识融入思想，从而提高大型语言模型（LLMs）的能力，使其可以高效地推广到未知问题。 |
| [^181] | [Joint Problems in Learning Multiple Dynamical Systems](https://arxiv.org/abs/2311.02181) | 聚类时间序列的新问题，提出联合划分轨迹集并学习每个部分的线性动态系统模型，以最小化所有模型的最大误差 |
| [^182] | [Generative Artificial Intelligence in Healthcare: Ethical Considerations and Assessment Checklist](https://arxiv.org/abs/2311.02107) | 对医疗保健中的生成人工智能（GenAI）进行了伦理讨论的范围审查，提出了一份检查表，以推动伦理讨论的全面评估和透明记录。 |
| [^183] | [Exploring Memorization in Fine-tuned Language Models](https://arxiv.org/abs/2310.06714) | 在微调语言模型过程中，该研究首次全面分析了不同任务中模型的记忆现象，发现了记忆在各种微调任务中表现出显著的差异，并通过稀疏编码理论解释了这种任务差异性。 |
| [^184] | [FedDefender: Backdoor Attack Defense in Federated Learning](https://arxiv.org/abs/2307.08672) | FedDefender是一种针对联邦学习中有针对性的中毒攻击的防御机制，通过差分测试来识别潜在包含后门的恶意客户，有效降低攻击成功率到10%。 |
| [^185] | [Oversmoothing: A Nightmare for Graph Contrastive Learning?](https://arxiv.org/abs/2306.02117) | 对于图对比学习（GCL），研究表明增加网络深度会导致过度平滑，包括深度表示和浅层，提出了BlockGCL解决这一问题 |
| [^186] | [Can large language models build causal graphs?](https://arxiv.org/abs/2303.05279) | 大型语言模型被证明对于探测词、上下文和提示敏感，但可以作为一种工具辅助因果图的发展。 |
| [^187] | [DMODE: Differential Monocular Object Distance Estimation Module without Class Specific Information](https://arxiv.org/abs/2210.12596) | DMODE是一种无需物体类别信息的单目目标距离估计方法，通过融合物体大小变化和摄像头运动来实现对各种目标检测和未知物体的适应，解决了单目距离估计中缺乏参考点和对象特定线索的挑战。 |
| [^188] | [Experimental Design for Multi-Channel Imaging via Task-Driven Feature Selection](https://arxiv.org/abs/2210.06891) | 提出了一种基于任务驱动特征选择的多通道成像实验设计方法，通过优化设计和训练机器学习模型执行用户指定的图像分析任务。 |
| [^189] | [GNNInterpreter: A Probabilistic Generative Model-Level Explanation for Graph Neural Networks](https://arxiv.org/abs/2209.07924) | 提出了GNNInterpreter，一种用于解释图神经网络高级决策过程的模型级解释方法，通过学习概率生成图分布来揭示GNN模型内部工作机制。 |
| [^190] | [Hyperbolic Hierarchical Knowledge Graph Embeddings for Link Prediction in Low Dimensions](https://arxiv.org/abs/2204.13704) | 提出了一种新颖的KGE模型，名为HypH，利用超几何空间嵌入分层数据，以提高知识图中链接预测的性能 |
| [^191] | [From Abstractions to Grounded Languages for Robust Coordination of Task Planning Robots](https://arxiv.org/abs/1905.00517) | 本文旨在自动构建能最大程度灵活且足够解释性的语言，用于协调任务规划机器人，通过将计划表达为“计划草图”，实现稳健协调。 |
| [^192] | [Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach.](http://arxiv.org/abs/2401.12686) | 这篇论文提出了一种在稀疏图上学习平均场对局博弈的新方法，通过引入图形扩展的概念，解决了现有方法对于稀疏网络拓扑结构的限制。 |
| [^193] | [SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents.](http://arxiv.org/abs/2401.10935) | SeeClick是一种基于屏幕截图的视觉GUI代理，通过GUI grounding预训练和自动化数据生成，实现了在复杂任务自动化中准确定位屏幕元素，并创建了全面覆盖移动、桌面和Web环境的GUI grounding数据集ScreenSpot。 |
| [^194] | [Semi-supervised Semantic Segmentation using Redesigned Self-Training for White Blood Cell.](http://arxiv.org/abs/2401.07278) | 本文通过引入半监督学习框架和结合FixMatch，提出了一种重新设计的自训练流程，用于解决白细胞分割中缺乏标记数据集和过时方法的问题。在深度学习架构和自训练方案的支持下，取得了在不同数据集上的优异性能。 |
| [^195] | [Kun: Answer Polishment for Chinese Self-Alignment with Instruction Back-Translation.](http://arxiv.org/abs/2401.06477) | Kun是一种使用指令反向翻译和答案优化的方法，用于创建高质量的指导调整数据集，该方法不依赖于手动注释，通过自我筛选过程来改善和选择最有效的指令-输出对。它的主要创新在于通过算法改进提高数据的保留和清晰度，并通过创新的数据生成方法减少了手动注释的依赖。 |
| [^196] | [Machine unlearning through fine-grained model parameters perturbation.](http://arxiv.org/abs/2401.04385) | 本文提出了一种精细的机器去学习策略，通过细粒度模型参数的扰动来实现用户隐私保护，同时保持可控的计算成本。采用遗忘率和记忆保留率等新的指标来评估去学习效果和模型泛化能力。 |
| [^197] | [Neural Causal Abstractions.](http://arxiv.org/abs/2401.02602) | 本文提出了一种新的神经因果抽象方法，通过聚类变量和其域，用于解决真实因果推断任务中的挑战，并通过神经因果模型实现了学习和应用。 |
| [^198] | [Perceptual Musical Features for Interpretable Audio Tagging.](http://arxiv.org/abs/2312.11234) | 本研究在自动音乐标记中探索了解释性的重要性，并构建了一个工作流来提取音频文件中的感知特征，从而训练出可解释的机器学习模型。 |
| [^199] | [Diffusion Models for Reinforcement Learning: A Survey.](http://arxiv.org/abs/2311.01223) | 强化学习中的扩散模型已经成为一种突出的生成模型，通过在样本质量和训练稳定性方面的优势改进了强化学习解决方案。该综述提供了这一新兴领域发展的概述，并探讨了扩散模型在强化学习中的分类法和应用。 |
| [^200] | [Alquist 5.0: Dialogue Trees Meet Generative Models. A Novel Approach for Enhancing SocialBot Conversations.](http://arxiv.org/abs/2310.16119) | Alquist 5.0是一种新的SocialBot系统，通过将对话树和生成模型相结合，以及引入NRG Barista和支持多模式设备，提高了用户对话体验，并保持了共情和知识型对话能力。 |
| [^201] | [EpiK-Eval: Evaluation for Language Models as Epistemic Models.](http://arxiv.org/abs/2310.15372) | 这项研究介绍了一种新的评估方法EpiK-Eval，旨在评估大型语言模型（LLMs）在从分割的叙述中构建连贯和一致的知识表示方面的能力。研究发现当前的训练目标存在固有的缺陷，因此提出了改进知识整合方法的建议，以大幅提高LLMs的整体效果和性能。 |
| [^202] | [Masked Pretraining for Multi-Agent Decision Making.](http://arxiv.org/abs/2310.11846) | 我们提出了一个掩码预训练框架(MaskMA)用于解决多智能体决策中的挑战。这个框架采用变压器架构，并使用基于掩码的协作学习策略，同时整合了可泛化的动作表示。 |
| [^203] | [A Fixed-Parameter Tractable Algorithm for Counting Markov Equivalence Classes with the same Skeleton.](http://arxiv.org/abs/2310.04218) | 本文提出了一个固定参数可处理算法，用于计数具有相同骨架的马尔可夫等价类。 |
| [^204] | [Rayleigh Quotient Graph Neural Networks for Graph-level Anomaly Detection.](http://arxiv.org/abs/2310.02861) | 《Rayleigh Quotient Graph Neural Networks用于图级异常检测的研究》提出使用Rayleigh Quotient作为驱动因素，通过探索图的固有光谱特征来实现图级异常检测。 |
| [^205] | [Conformal Temporal Logic Planning using Large Language Models: Knowing When to Do What and When to Ask for Help.](http://arxiv.org/abs/2309.10092) | 本文提出了一个使用大型语言模型的一致时间逻辑规划方法，用于解决多个高级子任务的移动机器人运动规划问题。其中的一个关键挑战是如何以正确性的角度推理机器人计划与基于自然语言的逻辑任务的关系。 |
| [^206] | [GenDOM: Generalizable One-shot Deformable Object Manipulation with Parameter-Aware Policy.](http://arxiv.org/abs/2309.09051) | GenDOM是一个框架，通过条件化操作策略和多样化模拟训练，使操作策略能够仅通过一个真实世界演示来处理不同的可变形物体，并通过最小化真实世界演示和模拟之间的点云格密度差异来估计新物体的可变形物体参数。 |
| [^207] | [ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style Transfer.](http://arxiv.org/abs/2308.15459) | ParaGuide是一种用于通用风格转移的引导性扩散改写器，可以灵活适应任意目标风格，通过梯度引导和改写条件的扩散模型实现文本的风格转变，同时保留语义信息。 |
| [^208] | [CodeCoT and Beyond: Learning to Program and Test like a Developer.](http://arxiv.org/abs/2308.08784) | 本文介绍了CodeCoT和Beyond的学习方法，该方法可以帮助模型在处理任务时从少量特定数据中进行适应。通过链式思维引导，模型可以揭示多步推理过程中的认知过程，并通过自我检查不断优化输出。 |
| [^209] | [Variance-Covariance Regularization Improves Representation Learning.](http://arxiv.org/abs/2306.13292) | 提出了方差-协方差正则化方法，旨在促进学习网络特征的多样性，改善表示学习和迁移学习的性能。 |
| [^210] | [Efficient Recruitment Strategy for Collaborative Mobile Crowd Sensing Based on GCN Trustworthiness Prediction.](http://arxiv.org/abs/2306.04366) | 本文提出了一种基于GCN可信度预测的协同移动群感知的高效招募策略，通过捕获工人之间的非对称信任关系和工人能力来实现有效的任务分配，优于现有方法。 |
| [^211] | [Can we forget how we learned? Representing states in iterated belief revision}.](http://arxiv.org/abs/2305.09200) | 本文比较了迭代信念修正中的三种状态表示方法，证明了用字典序修订的重写历史是最有效率的，并提供了一个多项式时间算法，用于确定Horn公式是否等价于neg。 |
| [^212] | [Learning Action Embeddings for Off-Policy Evaluation.](http://arxiv.org/abs/2305.03954) | 本论文探讨了从记录数据中学习动作嵌入，以减少在大型动作空间中反向倾向评分（IPS）估计器的方差，同时提高离线评估的准确性。 |
| [^213] | [Out-of-Domain Intent Detection Considering Multi-turn Dialogue Contexts.](http://arxiv.org/abs/2305.03237) | 本文提出了一个上下文感知的OOD意图检测框架（Caro），用于模拟OOD意图检测任务中的多轮对话上下文，并在提取稳健的表示时删除与意图检测无关的多余信息。Caro在多个标准数据集上表现出最先进的性能，并超越了先前方法。 |
| [^214] | [CMOS + stochastic nanomagnets: heterogeneous computers for probabilistic inference and learning.](http://arxiv.org/abs/2304.05949) | 本文展示了如何将基于随机磁隧道结（sMTJ）的概率比特（p位）与多功能可编程门阵列（FPGA）相结合，设计出一种能源高效的异构CMOS + X（X = sMTJ）原型，其成功地执行了概率推理和异步Boltzmann学习。 |
| [^215] | [Training Language Models with Language Feedback at Scale.](http://arxiv.org/abs/2303.16755) | 本文提出一种新方法，即利用更丰富的语言反馈进行模仿学习，通过三个迭代步骤对语言模型进行训练以生成更符合人类偏好的输出。 |
| [^216] | [Improving Code Generation by Training with Natural Language Feedback.](http://arxiv.org/abs/2303.16749) | 该论文提出了一种新算法ILF，通过从自然语言反馈中进行学习来显著提高代码生成模型的性能，即使只有少量反馈，也可以获得很好的效果。 |
| [^217] | [Contrastive Learning Is Spectral Clustering On Similarity Graph.](http://arxiv.org/abs/2303.15103) | 本文通过证明标准InfoNCE损失下的对比学习等同于相似性图上的谱聚类，揭示了这种方法的内在等价性，并进一步将这种分析扩展到CLIP模型，提出新的核混合损失函数。 |
| [^218] | [Zero-shot causal learning.](http://arxiv.org/abs/2301.12292) | 无先验因果学习是一个解决预测新型干预措施个性化影响的框架，并通过元学习对任务的处理达成了目的，能够将干预措施的知识传输到未见过的干预措施中，并在合成和真实数据集上表现出了优越性能。 |
| [^219] | [On the Inconsistencies of Conditionals Learned by Masked Language Models.](http://arxiv.org/abs/2301.00068) | 本论文研究发现，遮蔽语言模型学习的条件句往往存在着不一致性，无法从一个连贯的联合分布中推导出来。我们通过实证发现这种不一致性普遍存在于不同尺寸和配置的遮蔽语言模型中。为了解决这个问题，我们提出了条件句集合方法来在推断阶段处理不一致性。 |

# 详细

[^1]: AgentOhana：为有效智能体学习设计统一数据和训练流水线

    AgentOhana: Design Unified Data and Training Pipeline for Effective Agent Learning

    [https://arxiv.org/abs/2402.15506](https://arxiv.org/abs/2402.15506)

    AgentOhana提供了一种统一数据和训练流水线的综合解决方案，有助于克服使用大型语言模型（LLMs）进行智能体任务时的挑战。

    

    由大型语言模型（LLMs）提供支持的自主智能体引起了重大研究关注。然而，充分利用LLMs的潜力进行基于智能体的任务面临困难，这是由于具有多轮轨迹的多样化数据源的异构性。在本文中，我们介绍AgentOhana作为解决这些挑战的综合解决方案。AgentOhana从不同环境中聚合智能体轨迹，涵盖了各种情景。它精心地将这些轨迹标准化和统一到一致的格式中，简化了为智能体训练优化的通用数据加载器的创建。通过数据统一，我们的训练流水线在不同数据源之间保持平衡，并在数据集划分和模型训练过程中保持设备之间的独立随机性。此外，我们还介绍了xLAM-v0.1，一个大动作模式

    arXiv:2402.15506v1 Announce Type: new  Abstract: Autonomous agents powered by large language models (LLMs) have garnered significant research attention. However, fully harnessing the potential of LLMs for agent-based tasks presents inherent challenges due to the heterogeneous nature of diverse data sources featuring multi-turn trajectories. In this paper, we introduce \textbf{AgentOhana} as a comprehensive solution to address these challenges. \textit{AgentOhana} aggregates agent trajectories from distinct environments, spanning a wide array of scenarios. It meticulously standardizes and unifies these trajectories into a consistent format, streamlining the creation of a generic data loader optimized for agent training. Leveraging the data unification, our training pipeline maintains equilibrium across different data sources and preserves independent randomness across devices during dataset partitioning and model training. Additionally, we present \textbf{xLAM-v0.1}, a large action mode
    
[^2]: Co-Supervised Learning: Improving Weak-to-Strong Generalization with Hierarchical Mixture of Experts

    Co-Supervised Learning: Improving Weak-to-Strong Generalization with Hierarchical Mixture of Experts

    [https://arxiv.org/abs/2402.15505](https://arxiv.org/abs/2402.15505)

    提出了一种通过使用分层专家混合模型来改善弱到强泛化的协同监督学习方法，利用一组多样化的专家教师共同监督强大的学生模型。

    

    强有力的模型经过在互联网规模数据上的预训练后，由于缺乏胜任的监督者，在引导其行为时可能会变得困难。最近的研究表明，尽管存在监督噪声，一个强大的学生模型在针对特定目标进行微调后可能会超越其弱教师。然而，这种从弱到强的泛化效果仍然有限，特别是在存在巨大能力差距的情况下。在本文中，我们提出通过利用一组多样化的专家教师，而不是单一的通才教师，共同监督强大的学生模型来应对这一挑战。我们的方法类似于传统的分层专家混合模型，其中包含两个针对协同监督的组件：(i)我们逐步交替进行学生训练和教师分配，利用强大学生模型的增长来识别可能的监督方式；(ii)我们谨慎地强化教师-学生和局部-全局的一致性。

    arXiv:2402.15505v1 Announce Type: cross  Abstract: Steering the behavior of a strong model pre-trained on internet-scale data can be difficult due to the scarcity of competent supervisors. Recent studies reveal that, despite supervisory noises, a strong student model may surpass its weak teacher when fine-tuned on specific objectives. Yet, the effectiveness of such weak-to-strong generalization remains limited, especially in the presence of large capability gaps. In this paper, we propose to address this challenge by harnessing a diverse set of specialized teachers, instead of a single generalist one, that collectively supervises the strong student. Our approach resembles the classical hierarchical mixture of experts, with two components tailored for co-supervision: (i) we progressively alternate student training and teacher assignment, leveraging the growth of the strong student to identify plausible supervisions; (ii) we conservatively enforce teacher-student and local-global consist
    
[^3]: Gen4Gen: 生成式多概念组合的生成数据管道

    Gen4Gen: Generative Data Pipeline for Generative Multi-Concept Composition

    [https://arxiv.org/abs/2402.15504](https://arxiv.org/abs/2402.15504)

    该论文介绍了Gen4Gen，为解决文本到图像扩散模型中个性化多概念组合的问题而提出的生成数据管道。

    

    最近的文本到图像扩散模型能够学习和合成包含新颖、个性化概念的图像（例如，他们自己的宠物或特定物品），只需少量示例进行训练。本文解决了文本到图像扩散模型个性化中的两个相互关联问题。首先，当前的个性化技术未能可靠地扩展到多个概念--我们假设这是由于预训练数据集（例如，LAION）中复杂场景与简单文本描述之间的不匹配所导致的。其次，对于包含多个个性化概念的图像，缺乏一个 holistic度量标准，旨在评估不仅个性化概念的相似度程度，还有图像是否包含所有概念以及图像是否准确地反映了整体文本描述。为了解决这些问题，我们引入Gen4Gen，一个半自动化的数据集创建管道。

    arXiv:2402.15504v1 Announce Type: cross  Abstract: Recent text-to-image diffusion models are able to learn and synthesize images containing novel, personalized concepts (e.g., their own pets or specific items) with just a few examples for training. This paper tackles two interconnected issues within this realm of personalizing text-to-image diffusion models. First, current personalization techniques fail to reliably extend to multiple concepts -- we hypothesize this to be due to the mismatch between complex scenes and simple text descriptions in the pre-training dataset (e.g., LAION). Second, given an image containing multiple personalized concepts, there lacks a holistic metric that evaluates performance on not just the degree of resemblance of personalized concepts, but also whether all concepts are present in the image and whether the image accurately reflects the overall text description. To address these issues, we introduce Gen4Gen, a semi-automated dataset creation pipeline util
    
[^4]: API-BLEND：用于训练和基准测试API LLM的综合语料库

    API-BLEND: A Comprehensive Corpora for Training and Benchmarking API LLMs

    [https://arxiv.org/abs/2402.15491](https://arxiv.org/abs/2402.15491)

    本文介绍了API-BLEND，一个用于训练和系统测试工具增强型LLMs的大型语料库，旨在解决获取涉及调用工具/API的训练和测试数据的挑战，并模拟真实场景的API任务。

    

    随着对大型语言模型（LLMs）有效使用工具和外部应用程序编程接口（APIs）来规划和完成任务的需求日益增长，对可以获取涉及调用工具/API的足够数量的训练和测试数据的方法引起了极大关注。本文关注识别、整理和转化现有数据集，并介绍API-BLEND，一个用于训练和系统测试工具增强型LLMs的大型语料库。这些数据集模拟涉及API任务的真实场景，如API/工具检测、槽填充以及检测到的API的排序。

    arXiv:2402.15491v1 Announce Type: cross  Abstract: There is a growing need for Large Language Models (LLMs) to effectively use tools and external Application Programming Interfaces (APIs) to plan and complete tasks. As such, there is tremendous interest in methods that can acquire sufficient quantities of train and test data that involve calls to tools / APIs. Two lines of research have emerged as the predominant strategies for addressing this challenge. The first has focused on synthetic data generation techniques, while the second has involved curating task-adjacent datasets which can be transformed into API / Tool-based tasks. In this paper, we focus on the task of identifying, curating, and transforming existing datasets and, in turn, introduce API-BLEND, a large corpora for training and systematic testing of tool-augmented LLMs. The datasets mimic real-world scenarios involving API-tasks such as API / tool detection, slot filling, and sequencing of the detected APIs. We demonstrat
    
[^5]: RoboEXP: 通过交互式探索实现动作条件化场景图用于机器人操作

    RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for Robotic Manipulation

    [https://arxiv.org/abs/2402.15487](https://arxiv.org/abs/2402.15487)

    本文提出了交互式场景探索任务，通过自主探索环境生成了动作条件化场景图，捕捉了环境的结构

    

    机器人需要探索周围环境以适应并应对未知环境中的任务。本文介绍了交互式场景探索的新任务，其中机器人自主探索环境并生成一个捕捉基础环境结构的动作条件化场景图（ACSG）

    arXiv:2402.15487v1 Announce Type: cross  Abstract: Robots need to explore their surroundings to adapt to and tackle tasks in unknown environments. Prior work has proposed building scene graphs of the environment but typically assumes that the environment is static, omitting regions that require active interactions. This severely limits their ability to handle more complex tasks in household and office environments: before setting up a table, robots must explore drawers and cabinets to locate all utensils and condiments. In this work, we introduce the novel task of interactive scene exploration, wherein robots autonomously explore environments and produce an action-conditioned scene graph (ACSG) that captures the structure of the underlying environment. The ACSG accounts for both low-level information, such as geometry and semantics, and high-level information, such as the action-conditioned relationships between different entities in the scene. To this end, we present the Robotic Explo
    
[^6]: 多媒体地理定位在人口贩卖调查中的计算机视觉：系统性文献综述

    Computer Vision for Multimedia Geolocation in Human Trafficking Investigation: A Systematic Literature Review

    [https://arxiv.org/abs/2402.15448](https://arxiv.org/abs/2402.15448)

    计算机视觉和深度学习在多媒体地理定位中展示出加速人口贩卖调查的重大潜力。

    

    多媒体地理定位的任务正在成为数字取证工具包的一个越来越重要的组成部分，以有效打击人口贩卖、儿童性剥削和其他非法行为。当多媒体内容通过即时通讯和社交媒体分享时，通常会剥离基于元数据的地理定位信息。在这些内容中进行地理定位、地理标记或找到地理线索的复杂性往往对调查人员造成不必要的负担。最近的研究表明，人工智能的当代发展，特别是计算机视觉和深度学习，显示出加速多媒体地理定位任务的重大潜力。这项系统性文献综述彻底审查了利用计算机视觉技术进行多媒体地理定位的最新技术，并评估它们加速人口贩卖调查的潜力。

    arXiv:2402.15448v1 Announce Type: cross  Abstract: The task of multimedia geolocation is becoming an increasingly essential component of the digital forensics toolkit to effectively combat human trafficking, child sexual exploitation, and other illegal acts. Typically, metadata-based geolocation information is stripped when multimedia content is shared via instant messaging and social media. The intricacy of geolocating, geotagging, or finding geographical clues in this content is often overly burdensome for investigators. Recent research has shown that contemporary advancements in artificial intelligence, specifically computer vision and deep learning, show significant promise towards expediting the multimedia geolocation task. This systematic literature review thoroughly examines the state-of-the-art leveraging computer vision techniques for multimedia geolocation and assesses their potential to expedite human trafficking investigation. This includes a comprehensive overview of the a
    
[^7]: 我们能否忘记我们是如何学习的？在迭代信念修订中的信念多余

    Can we forget how we learned? Doxastic redundancy in iterated belief revision

    [https://arxiv.org/abs/2402.15445](https://arxiv.org/abs/2402.15445)

    在迭代信念修订中，有时候在其他修订存在时会出现信念修订的多余情况，以及给出了导致序列中第一个修订多余的必要和充分条件。

    

    信息的获取方式可能变得无关紧要。明显的情况是当某事被多次确认时。在迭代信念修订方面，特定的修订在其他修订存在时可能变得无关紧要。简单的重复是一个例子，但并非唯一的情况。有时，即使没有相等的修订存在，甚至没有暗示它的其他修订，一个修订也会变得多余。给出了词典修订序列中第一个修订多余的一个必要且充分条件。即使只有两个命题修订，该问题的复杂性也是coNP-完全的。在Horn情况下复杂性相同，但只有不受限制的修订数量：在两个修订情况下它变为多项式。词典修订不仅仅因为它们本身是相关的，也因为它们的序列是用于表示迭代修订过程状态的常见机制中最紧凑的。缩短词典修订序列。

    arXiv:2402.15445v1 Announce Type: new  Abstract: How information was acquired may become irrelevant. An obvious case is when something is confirmed many times. In terms of iterated belief revision, a specific revision may become irrelevant in presence of others. Simple repetitions are an example, but not the only case when this happens. Sometimes, a revision becomes redundant even in presence of none equal, or even no else implying it. A necessary and sufficient condition for the redundancy of the first of a sequence of lexicographic revisions is given. The problem is coNP-complete even with two propositional revisions only. Complexity is the same in the Horn case but only with an unbounded number of revisions: it becomes polynomial with two revisions. Lexicographic revisions are not only relevant by themselves, but also because sequences of them are the most compact of the common mechanisms used to represent the state of an iterated revision process. Shortening sequences of lexicograp
    
[^8]: 发挥不平衡模态信息在多模态知识图完成中的力量

    Unleashing the Power of Imbalanced Modality Information for Multi-modal Knowledge Graph Completion

    [https://arxiv.org/abs/2402.15444](https://arxiv.org/abs/2402.15444)

    提出了自适应多模态融合和模态对抗训练（AdaMF-MAT）方法，以解决多模态知识图完成中存在的模态信息不平衡问题，发挥不平衡模态信息的力量。

    

    多模态知识图完成（MMKGC）旨在通过将实体的结构、视觉和文本信息纳入判别模型来预测多模态知识图中缺失的三元组。来自不同模态的信息将共同工作以衡量三元组的可能性。现有的MMKGC方法忽视了实体之间模态信息不平衡的问题，导致模态融合不足以及对原始模态信息的低效利用。为解决上述问题，我们提出了自适应多模态融合和模态对抗训练（AdaMF-MAT），以发挥不平衡模态信息在MMKGC中的力量。AdaMF-MAT通过自适应模态权重实现多模态融合，并通过模态对抗训练生成对抗样本，以增强不平衡模态信息。我们的方法是MMKGC模型和训练的协同设计。

    arXiv:2402.15444v1 Announce Type: new  Abstract: Multi-modal knowledge graph completion (MMKGC) aims to predict the missing triples in the multi-modal knowledge graphs by incorporating structural, visual, and textual information of entities into the discriminant models. The information from different modalities will work together to measure the triple plausibility. Existing MMKGC methods overlook the imbalance problem of modality information among entities, resulting in inadequate modal fusion and inefficient utilization of the raw modality information. To address the mentioned problems, we propose Adaptive Multi-modal Fusion and Modality Adversarial Training (AdaMF-MAT) to unleash the power of imbalanced modality information for MMKGC. AdaMF-MAT achieves multi-modal fusion with adaptive modality weights and further generates adversarial samples by modality-adversarial training to enhance the imbalanced modality information. Our approach is a co-design of the MMKGC model and training s
    
[^9]: 主动少样本微调

    Active Few-Shot Fine-Tuning

    [https://arxiv.org/abs/2402.15441](https://arxiv.org/abs/2402.15441)

    该论文提出了ITL方法来实现主动少样本微调，通过最大化对下游任务的信息获取，从而在大型神经网络的微调中取得了显著的改进。

    

    我们研究了大型神经网络对下游任务进行主动少样本微调。我们表明少样本微调是传统主动学习和转导主动学习的泛化实例，我们提出了信息基于转导学习（ITL）的方法，该方法自适应地进行采样以最大化获得对指定下游任务的信息。在一般正则性假设下，我们证明ITL均匀收敛到可从可访问数据获取的最小可能的不确定性。据我们所知，我们是首批推导出这种泛化界限的人，这对于主动学习可能是具有独立意义的。我们将ITL应用于大型神经网络的少样本微调中，结果显示ITL明显改进了现有技术。

    arXiv:2402.15441v1 Announce Type: cross  Abstract: We study the active few-shot fine-tuning of large neural networks to downstream tasks. We show that few-shot fine-tuning is an instance of a generalization of classical active learning, transductive active learning, and we propose ITL, short for information-based transductive learning, an approach which samples adaptively to maximize the information gained about specified downstream tasks. Under general regularity assumptions, we prove that ITL converges uniformly to the smallest possible uncertainty obtainable from the accessible data. To the best of our knowledge, we are the first to derive generalization bounds of this kind, and they may be of independent interest for active learning. We apply ITL to the few-shot fine-tuning of large neural networks and show that ITL substantially improves upon the state-of-the-art.
    
[^10]: ProTIP：针对文本到图像扩散模型抗随机扰动的概率鲁棒性验证

    ProTIP: Probabilistic Robustness Verification on Text-to-Image Diffusion Models against Stochastic Perturbation

    [https://arxiv.org/abs/2402.15429](https://arxiv.org/abs/2402.15429)

    本研究引入了概率概念的文本到图像扩散模型鲁棒性，并建立了一个名为ProTIP的高效框架用于评估其统计保证，解决了生成过程的高计算成本和对抗性样本判断困难的问题

    

    文本到图像（T2I）扩散模型（DMs）展现了在简单文本描述基础上生成高质量图像的印象能力。然而，与许多深度学习（DL）模型一样，DMs存在缺乏鲁棒性的问题。在评估T2I DMs的鲁棒性时，存在以二元或最坏情况问题解方面的尝试，但无法回答模型在存在对抗性样本（AE）时的总体鲁棒性如何。本研究首先引入了T2I DMs鲁棒性的概率概念；然后建立了一个名为ProTIP的高效框架，用于具有统计保证的评估。主要挑战源自：i）生成过程的高计算成本；和ii）确定扰动输入是否为AE涉及比较两个输出分布，这与其他DL任务（如分类）不同，其中AE是在标签错误预测时被识别的。为解决这些挑战，

    arXiv:2402.15429v1 Announce Type: cross  Abstract: Text-to-Image (T2I) Diffusion Models (DMs) have shown impressive abilities in generating high-quality images based on simple text descriptions. However, as is common with many Deep Learning (DL) models, DMs are subject to a lack of robustness. While there are attempts to evaluate the robustness of T2I DMs as a binary or worst-case problem, they cannot answer how robust in general the model is whenever an adversarial example (AE) can be found. In this study, we first introduce a probabilistic notion of T2I DMs' robustness; and then establish an efficient framework, ProTIP, to evaluate it with statistical guarantees. The main challenges stem from: i) the high computational cost of the generation process; and ii) determining if a perturbed input is an AE involves comparing two output distributions, which is fundamentally harder compared to other DL tasks like classification where an AE is identified upon misprediction of labels. To tackle
    
[^11]: 理解人类群体中的衔接：从人际协作中学到的经验优化人机协作

    Understanding Entrainment in Human Groups: Optimising Human-Robot Collaboration from Lessons Learned during Human-Human Collaboration

    [https://arxiv.org/abs/2402.15427](https://arxiv.org/abs/2402.15427)

    本文通过混合方法研究了成功衔接的特征，从而实现成对和基于群体的同步，为人机/机器人交互领域提供了有益的贡献。

    

    成功的衔接在协作过程中积极影响信任、愿意合作以及对合作者的好感。本文通过一项混合方法研究探讨了成功衔接的特征，从而实现成对和基于群体的同步。我们从工业场景中汲取灵感，设计了一个快节奏、短周期重复任务。利用运动跟踪技术，我们研究了二人和三人任务完成中的衔接。此外，我们利用音视频录制和半结构化访谈来对参与者的经验进行情境化。本文通过以人为中心的方法，为人机/机器人交互（HCI/HRI）文献作出贡献，以确定在成对和基于群体的协作中的衔接特征。我们提出了与成功衔接相关的五个特征。

    arXiv:2402.15427v1 Announce Type: cross  Abstract: Successful entrainment during collaboration positively affects trust, willingness to collaborate, and likeability towards collaborators. In this paper, we present a mixed-method study to investigate characteristics of successful entrainment leading to pair and group-based synchronisation. Drawing inspiration from industrial settings, we designed a fast-paced, short-cycle repetitive task. Using motion tracking, we investigated entrainment in both dyadic and triadic task completion. Furthermore, we utilise audio-video recordings and semi-structured interviews to contextualise participants' experiences. This paper contributes to the Human-Computer/Robot Interaction (HCI/HRI) literature using a human-centred approach to identify characteristics of entrainment during pair- and group-based collaboration. We present five characteristics related to successful entrainment. These are related to the occurrence of entrainment, leader-follower patt
    
[^12]: 用大型语言模型生成忠实且高质量的病人总结的数据中心方法

    A Data-Centric Approach To Generate Faithful and High Quality Patient Summaries with Large Language Models

    [https://arxiv.org/abs/2402.15422](https://arxiv.org/abs/2402.15422)

    本研究探讨了使用大型语言模型基于医生笔记生成患者总结的潜力，通过严格的标记协议和医学专家标记实验发现，在无幻觉数据上进行微调能有效减少幻觉的生成，并保留相关信息。

    

    患者经常面临难以理解其住院情况的困难，而医护人员资源有限以提供解释。在这项工作中，我们研究了大型语言模型基于医生笔记生成患者总结的潜力，并研究了训练数据对生成总结的忠实性和质量的影响。为此，我们开发了严格的标记协议用于幻觉，让两位医学专家标记了100个真实总结和100个生成的总结。我们展示了在无幻觉数据进行微调可以有效地减少Llama 2每个总结的幻觉从2.60降低到1.55，同时保留相关信息。虽然效果仍然存在，但当使用五个例子提示GPT-4时，该效果要小得多（0.70降至0.40）。我们还对无幻觉和改进的训练数据进行了定性评估。即使在幻觉自由数据下，GPT-4也展现出非常好的结果。

    arXiv:2402.15422v1 Announce Type: cross  Abstract: Patients often face difficulties in understanding their hospitalizations, while healthcare workers have limited resources to provide explanations. In this work, we investigate the potential of large language models to generate patient summaries based on doctors' notes and study the effect of training data on the faithfulness and quality of the generated summaries. To this end, we develop a rigorous labeling protocol for hallucinations, and have two medical experts annotate 100 real-world summaries and 100 generated summaries. We show that fine-tuning on hallucination-free data effectively reduces hallucinations from 2.60 to 1.55 per summary for Llama 2, while preserving relevant information. Although the effect is still present, it is much smaller for GPT-4 when prompted with five examples (0.70 to 0.40). We also conduct a qualitative evaluation using hallucination-free and improved training data. GPT-4 shows very good results even in 
    
[^13]: 声誉算法厌恶

    Reputational Algorithm Aversion

    [https://arxiv.org/abs/2402.15418](https://arxiv.org/abs/2402.15418)

    选择跟随算法是否传达有关人类能力的信息是导致算法厌恶现象的关键因素，这种现象被称为“算法厌恶”。

    

    人们常常不愿将算法产生的信息纳入自己的决策中，这种现象被称为“算法厌恶”。本文展示了算法厌恶是如何产生的，当选择跟随算法传达有关人类能力的信息时。我建立了一个模型，其中工作者根据自己的私人信息和算法的信号对随机结果进行预测。低技能工作者接收到比算法更差的信息，因此应始终遵循算法的信号，而高技能工作者接收到比算法更好的信息，因此有时应该覆盖算法的决策。然而，由于声誉上的考虑，低技能工作者会不合理地覆盖算法，以增加被视为高技能的可能性。该模型为与AI系统可能会取代许多类型的工作者的广泛关注提供了完全理性的微观基础。

    arXiv:2402.15418v1 Announce Type: cross  Abstract: People are often reluctant to incorporate information produced by algorithms into their decisions, a phenomenon called "algorithm aversion". This paper shows how algorithm aversion arises when the choice to follow an algorithm conveys information about a human's ability. I develop a model in which workers make forecasts of a random outcome based on their own private information and an algorithm's signal. Low-skill workers receive worse information than the algorithm and hence should always follow the algorithm's signal, while high-skill workers receive better information than the algorithm and should sometimes override it. However, due to reputational concerns, low-skill workers inefficiently override the algorithm to increase the likelihood they are perceived as high-skill. The model provides a fully rational microfoundation for algorithm aversion that aligns with the broad concern that AI systems will displace many types of workers.
    
[^14]: TransFlower: 一种基于Transformer的模型，使用Flow-to-Flow注意力进行通勤流预测

    TransFlower: An Explainable Transformer-Based Model with Flow-to-Flow Attention for Commuting Flow Prediction

    [https://arxiv.org/abs/2402.15398](https://arxiv.org/abs/2402.15398)

    TransFlower模型是一种基于Transformer的可解释模型，采用Flow-to-Flow注意力来预测城市通勤模式，以解决深度学习模型准确性和可解释性之间的权衡问题。

    

    理解城市规划和通勤流之间的联系对指导城市发展和政策制定至关重要。这项研究跨越计算机科学和城市研究，解决了整合这些领域及其不同关注点的挑战。传统的城市研究方法，如引力和辐射模型，通常在复杂情况下表现不佳，因为它们对多个变量的处理有限，并且依赖于过于简化且不现实的假设，如空间各向同性。虽然深度学习模型提供了更高的准确性，但它们的黑盒特性在性能和可解释性之间存在权衡，这两者对于分析通勤流等复杂社会现象至关重要。为了解决这个问题，我们引入了TransFlower，一种可解释的、基于Transformer的模型，采用Flow-to-Flow注意力来预测城市通勤模式。它具有一个带有各向异性感知的地理空间编码器

    arXiv:2402.15398v1 Announce Type: cross  Abstract: Understanding the link between urban planning and commuting flows is crucial for guiding urban development and policymaking. This research, bridging computer science and urban studies, addresses the challenge of integrating these fields with their distinct focuses. Traditional urban studies methods, like the gravity and radiation models, often underperform in complex scenarios due to their limited handling of multiple variables and reliance on overly simplistic and unrealistic assumptions, such as spatial isotropy. While deep learning models offer improved accuracy, their black-box nature poses a trade-off between performance and explainability -- both vital for analyzing complex societal phenomena like commuting flows. To address this, we introduce TransFlower, an explainable, transformer-based model employing flow-to-flow attention to predict urban commuting patterns. It features a geospatial encoder with an anisotropy-aware relative
    
[^15]: NeuralThink: 在一般任务中进行外推的算法综合

    NeuralThink: Algorithm Synthesis that Extrapolates in General Tasks

    [https://arxiv.org/abs/2402.15393](https://arxiv.org/abs/2402.15393)

    NeuralThink 是一种新的递归架构，可以一贯地对对称和不对称任务进行外推，相较于之前的最先进的深度思维架构在稳定地从较小的训练规模对大观测进行外推方面表现出更好的性能。

    

    虽然机器学习方法擅长模式识别，但在可扩展的算法方式上处理复杂的推理任务时仍然面临困难。最近的深度思维方法展现了学习可以外推的算法的潜力：在较小的环境中学习并在较大的环境中执行学到的算法。然而，这些工作局限于对称任务，即输入和输出的维度相同。为了填补这一空白，我们提出了 NeuralThink，一种新的递归架构，可以一贯地对对称和不对称任务进行外推，其中输入和输出的维度不同。我们提供了一个新颖的不对称任务外推基准。我们展示了 NeuralThink 在稳定地从较小的训练规模对大观测进行外推方面一直优于之前的最先进的深度思维架构。

    arXiv:2402.15393v1 Announce Type: cross  Abstract: While machine learning methods excel at pattern recognition, they struggle with complex reasoning tasks in a scalable, algorithmic manner. Recent Deep Thinking methods show promise in learning algorithms that extrapolate: learning in smaller environments and executing the learned algorithm in larger environments. However, these works are limited to symmetrical tasks, where the input and output dimensionalities are the same. To address this gap, we propose NeuralThink, a new recurrent architecture that can consistently extrapolate to both symmetrical and asymmetrical tasks, where the dimensionality of the input and output are different. We contribute with a novel benchmark of asymmetrical tasks for extrapolation. We show that NeuralThink consistently outperforms the prior state-of-the-art Deep Thinking architectures, in regards to stable extrapolation to large observations from smaller training sizes.
    
[^16]: Genie：生成交互环境

    Genie: Generative Interactive Environments

    [https://arxiv.org/abs/2402.15391](https://arxiv.org/abs/2402.15391)

    Genie是第一个经过无监督训练的生成交互环境，可生成各种动作可控的虚拟世界，并提供了学习潜在行动空间以训练代理程序模仿未见视频行为的可能性。

    

    我们介绍了Genie，这是第一个通过无监督方式从未标记的互联网视频中训练而成的生成式交互环境。该模型可以被提示生成通过文本、合成图像、照片甚至素描描述的无限种类的动作可控虚拟世界。拥有110亿个参数的Genie可以被视为基础世界模型。其由时空视频标记器、自回归动力学模型以及简单且可扩展的潜在行动模型组成。尽管训练过程中没有使用任何地面真值行动标签或其他通常在世界模型文献中找到的领域特定要求，但Genie使用户可以基于逐帧基础在生成的环境中行动。进一步，所得到的学习潜在行动空间有助于训练代理程序模仿来自未见视频的行为，为未来培训通用代理铺平了道路。

    arXiv:2402.15391v1 Announce Type: cross  Abstract: We introduce Genie, the first generative interactive environment trained in an unsupervised manner from unlabelled Internet videos. The model can be prompted to generate an endless variety of action-controllable virtual worlds described through text, synthetic images, photographs, and even sketches. At 11B parameters, Genie can be considered a foundation world model. It is comprised of a spatiotemporal video tokenizer, an autoregressive dynamics model, and a simple and scalable latent action model. Genie enables users to act in the generated environments on a frame-by-frame basis despite training without any ground-truth action labels or other domain-specific requirements typically found in the world model literature. Further the resulting learned latent action space facilitates training agents to imitate behaviors from unseen videos, opening the path for training generalist agents of the future.
    
[^17]: 在语言模型中自修复的探索

    Explorations of Self-Repair in Language Models

    [https://arxiv.org/abs/2402.15390](https://arxiv.org/abs/2402.15390)

    自修复现象存在于各种模型家族和尺寸上，但在完整的训练分布上是不完美和嘈杂的，有两种机制可促成自修复，包括最终LayerNorm缩放因子的变化和实现反擦除的稀疏神经元集。

    

    先前研究狭窄分布的可解释性发现了自修复现象，即如果剥离大型语言模型中的组件，后续组件会改变其行为以进行补偿。我们的工作基于这些过去的文献，展示了当在完整的训练分布上剥离单个注意力头时，自修复存在于各种模型家族和尺寸上。我们进一步表明，在完整的训练分布上，自修复是不完美的，因为头部的原始直接效果并未完全恢复，并且是嘈杂的，因为自修复程度在不同提示之间显著变化（有时超过原始效果）。我们强调了促成自修复的两种不同机制，包括最终LayerNorm缩放因子的变化（可修复直接效果的30%）以及实现反擦除的稀疏神经元集。

    arXiv:2402.15390v1 Announce Type: cross  Abstract: Prior interpretability research studying narrow distributions has preliminarily identified self-repair, a phenomena where if components in large language models are ablated, later components will change their behavior to compensate. Our work builds off this past literature, demonstrating that self-repair exists on a variety of models families and sizes when ablating individual attention heads on the full training distribution. We further show that on the full training distribution self-repair is imperfect, as the original direct effect of the head is not fully restored, and noisy, since the degree of self-repair varies significantly across different prompts (sometimes overcorrecting beyond the original effect). We highlight two different mechanisms that contribute to self-repair, including changes in the final LayerNorm scaling factor (which can repair up to 30% of the direct effect) and sparse sets of neurons implementing Anti-Erasure
    
[^18]: 具有固有物理知识的稳态运动规划

    Homeostatic motion planning with innate physics knowledge

    [https://arxiv.org/abs/2402.15384](https://arxiv.org/abs/2402.15384)

    通过定义"任务"的方式和引入具有物理和因果关系理解的监督模块，我们提出了一种具有固有物理知识的稳态运动规划框架，可以在机器人上实现复杂计划。

    

    生物体以闭环方式与周围环境进行互动，其中感官输入决定行为的启动和终止。即使是简单的动物也能制定并执行复杂计划，但纯闭环输入控制的机器人尚未复制这一点。我们提出通过定义一组离散临时闭环控制器，称为“任务”，每个任务代表一个闭环行为，来解决这个问题。我们进一步引入了一个具有固有物理和因果关系理解的监督模块，通过该模块可以模拟随时间执行任务序列并将结果存储在环境模型中。基于这个模型，可以通过链接临时闭环控制器进行制定计划。所提出的框架已在实际机器人中实施，并在两种场景下作为概念验证进行了测试。

    arXiv:2402.15384v1 Announce Type: cross  Abstract: Living organisms interact with their surroundings in a closed-loop fashion, where sensory inputs dictate the initiation and termination of behaviours. Even simple animals are able to develop and execute complex plans, which has not yet been replicated in robotics using pure closed-loop input control. We propose a solution to this problem by defining a set of discrete and temporary closed-loop controllers, called "tasks", each representing a closed-loop behaviour. We further introduce a supervisory module which has an innate understanding of physics and causality, through which it can simulate the execution of task sequences over time and store the results in a model of the environment. On the basis of this model, plans can be made by chaining temporary closed-loop controllers. The proposed framework was implemented for a real robot and tested in two scenarios as proof of concept.
    
[^19]: 双编码器：利用句法和语义潜力进行方面情感三元组提取

    Dual Encoder: Exploiting the Potential of Syntactic and Semantic for Aspect Sentiment Triplet Extraction

    [https://arxiv.org/abs/2402.15370](https://arxiv.org/abs/2402.15370)

    提出了一种双编码器模型（D2E2S），结合了BERT通道和增强型LSTM通道来最大化单词间的句法和语义关系，引入了异构特征交互模块用于捕获复杂互动和动态选择重要节点。

    

    方面情感三元组提取（ASTE）是精细情感分析中的一个新兴任务。最近的研究使用图神经网络（GNN）来建模三元组元素固有的句法-语义关系。然而，他们尚未充分发挥ASTE任务中句法和语义信息的巨大潜力。在这项工作中，我们提出了一种\emph{双编码器：利用句法和语义潜力}模型（D2E2S），最大化单词间的句法和语义关系。具体而言，我们的模型利用双通道编码器，其中包括一个BERT通道来捕捉语义信息，以及一个增强型LSTM通道用于全面捕捉句法信息。随后，我们介绍了异构特征交互模块，以捕获依赖句法与注意力语义之间的复杂互动，并动态选择重要节点。我们利用这些模块的协同作用

    arXiv:2402.15370v1 Announce Type: cross  Abstract: Aspect Sentiment Triple Extraction (ASTE) is an emerging task in fine-grained sentiment analysis. Recent studies have employed Graph Neural Networks (GNN) to model the syntax-semantic relationships inherent in triplet elements. However, they have yet to fully tap into the vast potential of syntactic and semantic information within the ASTE task. In this work, we propose a \emph{Dual Encoder: Exploiting the potential of Syntactic and Semantic} model (D2E2S), which maximizes the syntactic and semantic relationships among words. Specifically, our model utilizes a dual-channel encoder with a BERT channel to capture semantic information, and an enhanced LSTM channel for comprehensive syntactic information capture. Subsequently, we introduce the heterogeneous feature interaction module to capture intricate interactions between dependency syntax and attention semantics, and to dynamically select vital nodes. We leverage the synergy of these m
    
[^20]: 使用符合预测的技术实现语言指导多机器人系统的安全任务规划

    Safe Task Planning for Language-Instructed Multi-Robot Systems using Conformal Prediction

    [https://arxiv.org/abs/2402.15368](https://arxiv.org/abs/2402.15368)

    本文引入了一种新的基于分布式LLM和符合预测技术的多机器人规划器，实现了高任务成功率。

    

    本文解决了语言指导机器人团队的任务规划问题。任务用自然语言（NL）表示，要求机器人在各种位置和语义对象上应用它们的能力（例如移动、操作和感知）。最近几篇论文通过利用预训练的大型语言模型（LLMs）设计有效的多机器人计划来解决类似的规划问题。然而，这些方法缺乏任务性能和安全性保证。为了解决这一挑战，我们引入了一种新的基于分布式LLM的规划器，能够实现高任务成功率。这是通过利用符合预测（CP）来实现的，CP是一种基于分布的不确定性量化工具，可以在黑盒模型中对其固有不确定性进行推理。CP允许所提出的多机器人规划器以分布方式推理其固有不确定性，使得机器人在充分信任时能够做出个别决策。

    arXiv:2402.15368v1 Announce Type: cross  Abstract: This paper addresses task planning problems for language-instructed robot teams. Tasks are expressed in natural language (NL), requiring the robots to apply their capabilities (e.g., mobility, manipulation, and sensing) at various locations and semantic objects. Several recent works have addressed similar planning problems by leveraging pre-trained Large Language Models (LLMs) to design effective multi-robot plans. However, these approaches lack mission performance and safety guarantees. To address this challenge, we introduce a new decentralized LLM-based planner that is capable of achieving high mission success rates. This is accomplished by leveraging conformal prediction (CP), a distribution-free uncertainty quantification tool in black-box models. CP allows the proposed multi-robot planner to reason about its inherent uncertainty in a decentralized fashion, enabling robots to make individual decisions when they are sufficiently ce
    
[^21]: Farsight：在AI应用原型设计过程中培养负责任的AI意识

    Farsight: Fostering Responsible AI Awareness During AI Application Prototyping

    [https://arxiv.org/abs/2402.15350](https://arxiv.org/abs/2402.15350)

    Farsight是一个新颖的实地交互工具，帮助人们在设计AI应用原型时识别潜在危害，用户研究表明使用Farsight后，AI原型设计者能够更好地独立识别与提示相关的潜在危害。

    

    大型语言模型（LLM）的提示驱动界面使得原型设计和构建AI应用比以往任何时候都更容易。然而，识别可能在AI应用中出现的潜在危害仍然是一个挑战，特别是在基于提示的原型设计过程中。为了解决这一问题，我们提出了一种新颖的实地交互工具Farsight，帮助人们识别他们正在设计原型的AI应用中可能出现的潜在危害。根据用户的提示，Farsight突出显示了与相关AI事件有关的新闻文章，并允许用户探索和编辑LLM生成的用例、利益相关者和危害。我们报告了与10位AI原型设计者进行的共同设计研究的设计见解，以及与42位AI原型设计者进行的用户研究结果。在使用Farsight后，我们用户研究中的AI原型设计者能够更好地独立识别与提示相关的潜在危害，并发现我们的工具比现有资源更有用且更易于使用。

    arXiv:2402.15350v1 Announce Type: cross  Abstract: Prompt-based interfaces for Large Language Models (LLMs) have made prototyping and building AI-powered applications easier than ever before. However, identifying potential harms that may arise from AI applications remains a challenge, particularly during prompt-based prototyping. To address this, we present Farsight, a novel in situ interactive tool that helps people identify potential harms from the AI applications they are prototyping. Based on a user's prompt, Farsight highlights news articles about relevant AI incidents and allows users to explore and edit LLM-generated use cases, stakeholders, and harms. We report design insights from a co-design study with 10 AI prototypers and findings from a user study with 42 AI prototypers. After using Farsight, AI prototypers in our user study are better able to independently identify potential harms associated with a prompt and find our tool more useful and usable than existing resources. T
    
[^22]: 信息论安全贝叶斯优化

    Information-Theoretic Safe Bayesian Optimization

    [https://arxiv.org/abs/2402.15347](https://arxiv.org/abs/2402.15347)

    提出了一种信息论安全探索准则，结合贝叶斯优化收益函数，形成了一种新颖的安全贝叶斯优化选择准则。

    

    我们考虑了一个顺序决策任务，其目标是在不评估违反先验未知（安全）约束的参数的情况下优化未知函数。一个常见的方法是在未知函数上放置高斯过程先验，并且仅允许在高概率安全区域内进行评估。大多数当前方法依赖于对域的离散化，并且不能直接扩展到连续情况。此外，它们利用约束的规则假设的方式引入了一个额外的关键超参数。在本文中，我们提出了一个信息论安全探索准则，该准则直接利用GP后验来识别最具信息的安全参数进行评估。将这一探索准则与众所周知的贝叶斯优化收益函数结合起来，产生了一种新颖的安全贝叶斯优化选择准则。

    arXiv:2402.15347v1 Announce Type: cross  Abstract: We consider a sequential decision making task, where the goal is to optimize an unknown function without evaluating parameters that violate an a~priori unknown (safety) constraint. A common approach is to place a Gaussian process prior on the unknown functions and allow evaluations only in regions that are safe with high probability. Most current methods rely on a discretization of the domain and cannot be directly extended to the continuous case. Moreover, the way in which they exploit regularity assumptions about the constraint introduces an additional critical hyperparameter. In this paper, we propose an information-theoretic safe exploration criterion that directly exploits the GP posterior to identify the most informative safe parameters to evaluate. The combination of this exploration criterion with a well known Bayesian optimization acquisition function yields a novel safe Bayesian optimization selection criterion. Our approach 
    
[^23]: NuNER: 利用LLM注释数据进行实体识别编码器预训练

    NuNER: Entity Recognition Encoder Pre-training via LLM-Annotated Data

    [https://arxiv.org/abs/2402.15343](https://arxiv.org/abs/2402.15343)

    利用LLM注释数据进行实体识别编码器预训练，创建了NuNER，一种专门用于命名实体识别任务的紧凑语言表示模型，可以在少样本学习领域胜过相似大小的基础模型，并与更大的LLMs竞争。

    

    大型语言模型（LLMs）展现出在数据标注方面令人印象深刻的能力，为解决经典的自然语言处理问题提供了新的途径。本文展示了如何利用LLMs创建NuNER，这是一个专门针对命名实体识别（NER）任务的紧凑语言表示模型。NuNER可以被微调以以高效的方式解决下游的NER问题，在少样本学习领域胜过相似大小的基础模型，并与更大的LLMs竞争。我们发现预训练数据集的大小和实体类型的多样性是取得良好性能的关键。我们将NuNER视为最近被LLMs解锁的更广泛的特定任务基础模型家族的一员。

    arXiv:2402.15343v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have shown impressive abilities in data annotation, opening the way for new approaches to solve classic NLP problems. In this paper, we show how to use LLMs to create NuNER, a compact language representation model specialized in the Named Entity Recognition (NER) task. NuNER can be fine-tuned to solve downstream NER problems in a data-efficient way, outperforming similar-sized foundation models in the few-shot regime and competing with much larger LLMs. We find that the size and entity-type diversity of the pre-training dataset are key to achieving good performance. We view NuNER as a member of the broader family of task-specific foundation models, recently unlocked by LLMs.
    
[^24]: 基于量子态保真度的量子-经典协同训练架构

    A Quantum-Classical Collaborative Training Architecture Based on Quantum State Fidelity

    [https://arxiv.org/abs/2402.15333](https://arxiv.org/abs/2402.15333)

    量子深度学习引入了一种新的协同经典-量子架构co-TenQu，通过经典组件的压缩和特征提取，实现了高维数据编码到逻辑量子电路上。

    

    近期的进展突显了当前量子系统的局限，特别是在近期量子设备上可用的量子比特数量受到限制。这一约束大大限制了能够利用量子计算机的应用范围。此外，随着可用量子比特的增加，计算复杂性呈指数级增长，带来额外的挑战。因此，迫切需要高效利用量子比特，以缓解当前的限制和未来的复杂性。为解决这一问题，现有的量子应用尝试在混合框架中集成经典和量子系统。在本研究中，我们关注量子深度学习，并引入了一种称为co-TenQu的协同经典-量子架构。经典组件采用张量网络进行压缩和特征提取，使高维数据能够被编码到具有限量量子比特的逻辑量子电路上。

    arXiv:2402.15333v1 Announce Type: cross  Abstract: Recent advancements have highlighted the limitations of current quantum systems, particularly the restricted number of qubits available on near-term quantum devices. This constraint greatly inhibits the range of applications that can leverage quantum computers. Moreover, as the available qubits increase, the computational complexity grows exponentially, posing additional challenges. Consequently, there is an urgent need to use qubits efficiently and mitigate both present limitations and future complexities. To address this, existing quantum applications attempt to integrate classical and quantum systems in a hybrid framework. In this study, we concentrate on quantum deep learning and introduce a collaborative classical-quantum architecture called co-TenQu. The classical component employs a tensor network for compression and feature extraction, enabling higher-dimensional data to be encoded onto logical quantum circuits with limited qub
    
[^25]: 分类深度学习：一种关于架构的代数理论

    Categorical Deep Learning: An Algebraic Theory of Architectures

    [https://arxiv.org/abs/2402.15332](https://arxiv.org/abs/2402.15332)

    提出了一种关于深度学习架构的代数理论，应用范畴论构建了一个桥梁，有效地涵盖了神经网络设计的不同风格，同时自然地编码了计算机科学和自动机理论中的许多标准结构。

    

    我们提出了一个关于指定和研究深度学习架构的通用框架的立场。我们认为到目前为止关于这一领域的关键尝试缺乏一种一致的桥梁，能够指定模型必须满足的约束并规定它们的实现方式。专注于构建这样一个桥梁，我们建议应用范畴论——准确地说，单子值于参数映射的二范畴的通用代数——作为一种单一理论，优雅地包含了神经网络设计的这两种风格。为了支持我们的观点，我们展示了这一理论如何恢复由几何深度学习导致的约束，以及从神经网络不同领域的多种架构（如RNNs）的实现。我们还展示了这一理论如何自然地编码了计算机科学和自动机理论中的许多标准结构。

    arXiv:2402.15332v1 Announce Type: cross  Abstract: We present our position on the elusive quest for a general-purpose framework for specifying and studying deep learning architectures. Our opinion is that the key attempts made so far lack a coherent bridge between specifying constraints which models must satisfy and specifying their implementations. Focusing on building a such a bridge, we propose to apply category theory -- precisely, the universal algebra of monads valued in a 2-category of parametric maps -- as a single theory elegantly subsuming both of these flavours of neural network design. To defend our position, we show how this theory recovers constraints induced by geometric deep learning, as well as implementations of many architectures drawn from the diverse landscape of neural networks, such as RNNs. We also illustrate how the theory naturally encodes many standard constructs in computer science and automata theory.
    
[^26]: OpenSUN3D: 开放词汇的3D场景理解第一次研讨会挑战

    OpenSUN3D: 1st Workshop Challenge on Open-Vocabulary 3D Scene Understanding

    [https://arxiv.org/abs/2402.15321](https://arxiv.org/abs/2402.15321)

    提供了OpenSUN3D研讨会上针对开放词汇3D场景理解的挑战概述，包括挑战数据集、评估方法和获胜方法的简要描述

    

    这份报告概述了在2023年ICCV会议上举办的OpenSUN3D Workshop关于开放词汇3D场景理解的挑战。该研讨会系列的目标是为开放词汇3D场景理解任务提供探索和讨论平台，包括但不限于分割、检测和映射。我们提供了研讨会上举办的挑战概述，展示了挑战数据集、评估方法以及获胜方法的简要描述。更多详情请参阅https://opensun3d.github.io/index_iccv23.html。

    arXiv:2402.15321v1 Announce Type: cross  Abstract: This report provides an overview of the challenge hosted at the OpenSUN3D Workshop on Open-Vocabulary 3D Scene Understanding held in conjunction with ICCV 2023. The goal of this workshop series is to provide a platform for exploration and discussion of open-vocabulary 3D scene understanding tasks, including but not limited to segmentation, detection and mapping. We provide an overview of the challenge hosted at the workshop, present the challenge dataset, the evaluation methodology, and brief descriptions of the winning methods. For additional details, please see https://opensun3d.github.io/index_iccv23.html.
    
[^27]: ArabianGPT：基于原生阿拉伯语的大型语言模型

    ArabianGPT: Native Arabic GPT-based Large Language

    [https://arxiv.org/abs/2402.15313](https://arxiv.org/abs/2402.15313)

    提出了ArabianGPT，这是一系列专门为阿拉伯语设计的基于Transformer的模型，包括大小和复杂性不同的ArabianGPT-0.1B和ArabianGPT-0.3B，帮助弥补了本土阿拉伯语大型语言模型的不足。

    

    英语和拉丁语为主导的大型语言模型（LLMs）的主导地位导致了本土阿拉伯语LLMs的显著不足。本文提出ArabianGPT，这是一系列基于Transformer的模型，专门为阿拉伯语设计而成。这些模型包括ArabianGPT-0.1B和ArabianGPT-0.3B，大小和复杂性不同，与阿拉伯语的微妙语言特征相契合。

    arXiv:2402.15313v1 Announce Type: cross  Abstract: The predominance of English and Latin-based large language models (LLMs) has led to a notable deficit in native Arabic LLMs. This discrepancy is accentuated by the prevalent inclusion of English tokens in existing Arabic models, detracting from their efficacy in processing native Arabic's intricate morphology and syntax. Consequently, there is a theoretical and practical imperative for developing LLMs predominantly focused on Arabic linguistic elements. To address this gap, this paper proposes ArabianGPT, a series of transformer-based models within the ArabianLLM suite designed explicitly for Arabic. These models, including ArabianGPT-0.1B and ArabianGPT-0.3B, vary in size and complexity, aligning with the nuanced linguistic characteristics of Arabic. The AraNizer tokenizer, integral to these models, addresses the unique morphological aspects of Arabic script, ensuring more accurate text processing. Empirical results from fine-tuning t
    
[^28]: 在大型视觉语言模型中表示在线手写识别

    Representing Online Handwriting for Recognition in Large Vision-Language Models

    [https://arxiv.org/abs/2402.15307](https://arxiv.org/abs/2402.15307)

    本文研究了在大型视觉语言模型中进行在线手写识别，提出了一种新颖的数字墨水(tokenized representation)表示方法，将手写呈现为文本序列和图像，取得了可与现有方法媲美的结果。

    

    随着带有触摸屏和触控笔的平板电脑的普及，将手写转换为文本的关键功能得以实现，实现了搜索、索引和人工智能辅助。与此同时，视觉语言模型(VLMs)现在已成为图像理解的首选解决方案，这要归功于它们在各种任务上的最先进性能，以及训练、微调和推理的统一方法的简洁性。虽然VLMs在基于图像的任务上表现出色，但在朴素应用时(即将手写呈现为图像并执行光学字符识别(OCR))在手写识别方面效果不佳。在本文中，我们研究了VLMs中的在线手写识别，超越了朴素的OCR。我们提出了一种将数字墨水(在线手写)的新型标记化表示，其中包括作为文本的一系列按时间顺序排列的笔画，以及作为图像。我们展示了这种表示得到的结果与

    arXiv:2402.15307v1 Announce Type: cross  Abstract: The adoption of tablets with touchscreens and styluses is increasing, and a key feature is converting handwriting to text, enabling search, indexing, and AI assistance. Meanwhile, vision-language models (VLMs) are now the go-to solution for image understanding, thanks to both their state-of-the-art performance across a variety of tasks and the simplicity of a unified approach to training, fine-tuning, and inference. While VLMs obtain high performance on image-based tasks, they perform poorly on handwriting recognition when applied naively, i.e., by rendering handwriting as an image and performing optical character recognition (OCR). In this paper, we study online handwriting recognition with VLMs, going beyond naive OCR. We propose a novel tokenized representation of digital ink (online handwriting) that includes both a time-ordered sequence of strokes as text, and as image. We show that this representation yields results comparable to
    
[^29]: 见证为信：通过CLIP引导解码缓解大型视觉-语言模型中的幻觉

    Seeing is Believing: Mitigating Hallucination in Large Vision-Language Models via CLIP-Guided Decoding

    [https://arxiv.org/abs/2402.15300](https://arxiv.org/abs/2402.15300)

    CLIP相似性作为更强大和更稳健的幻觉指标，研究提出了CLIP引导解码（CGD）方法，在大型视觉-语言模型中有效减少对象幻觉。

    

    大型视觉-语言模型(LVLMs)容易出现对象幻觉，即生成的文本包含不存在的对象，严重限制了它们的可靠性和实用性。我们首先对句子级LVLM幻觉进行实证分析，发现与图像的CLIP相似性作为一个比单词可能性更强大、更稳健的幻觉指示器。基于这一发现，我们提出了CLIP引导解码（CGD）方法，这是一种简单但有效的无需训练的方法，用于减少解码时的对象幻觉。CGD利用CLIP来引导模型的解码过程，通过增强生成文本与图像的视觉联系。实验表明，CGD有效地减轻了对象幻觉。

    arXiv:2402.15300v1 Announce Type: cross  Abstract: Large Vision-Language Models (LVLMs) are susceptible to object hallucinations, an issue in which their generated text contains non-existent objects, greatly limiting their reliability and practicality. Current approaches often rely on the model's token likelihoods or other internal information, instruction tuning on additional datasets, or incorporating complex external tools. We first perform empirical analysis on sentence-level LVLM hallucination, finding that CLIP similarity to the image acts as a stronger and more robust indicator of hallucination compared to token likelihoods. Motivated by this, we introduce our CLIP-Guided Decoding (CGD) approach, a straightforward but effective training-free approach to reduce object hallucination at decoding time. CGD uses CLIP to guide the model's decoding process by enhancing visual grounding of generated text with the image. Experiments demonstrate that CGD effectively mitigates object hallu
    
[^30]: 在互动背景下音乐生成的调查

    A Survey of Music Generation in the Context of Interaction

    [https://arxiv.org/abs/2402.15294](https://arxiv.org/abs/2402.15294)

    该论文调查了音乐生成领域的现状，针对机器学习在音乐创作中的应用进行了综合评估，探讨了当前研究的主要焦点以及存在的挑战。

    

    近年来，机器学习，特别是生成对抗神经网络（GANs）和基于注意力机制的神经网络（transformers），已成功用于创作和生成音乐，包括旋律和复调作品。当前研究主要集中在风格复制（例如生成巴赫风格赋格曲）或风格转移（例如古典到爵士）上，基于大量录制或转录的音乐，这也允许相当直接的“表现”评估。然而，大多数这些模型不适合通过实时互动进行人机共创，也不清楚这些模型和生成的作品将如何评估。本文全面审查了音乐表示、特征分析、启发式算法、统计和参数建模，以及人为和自动评估措施，同时讨论了哪些方法和模型似乎最为重要。

    arXiv:2402.15294v1 Announce Type: cross  Abstract: In recent years, machine learning, and in particular generative adversarial neural networks (GANs) and attention-based neural networks (transformers), have been successfully used to compose and generate music, both melodies and polyphonic pieces. Current research focuses foremost on style replication (eg. generating a Bach-style chorale) or style transfer (eg. classical to jazz) based on large amounts of recorded or transcribed music, which in turn also allows for fairly straight-forward "performance" evaluation. However, most of these models are not suitable for human-machine co-creation through live interaction, neither is clear, how such models and resulting creations would be evaluated. This article presents a thorough review of music representation, feature analysis, heuristic algorithms, statistical and parametric modelling, and human and automatic evaluation measures, along with a discussion of which approaches and models seem m
    
[^31]: 嵌入线性动力学的神经网络用于长序列建模

    Linear Dynamics-embedded Neural Network for Long-Sequence Modeling

    [https://arxiv.org/abs/2402.15290](https://arxiv.org/abs/2402.15290)

    提出了一种名为嵌入线性动力学的神经网络（LDNN），通过引入连续状态空间模型的属性和优化策略，实现了在长序列任务中具有少量参数、灵活推断和高效训练，最终在长距离竞技场上取得了有效且领先的性能。

    

    由于现有模型在长序列建模中性能和计算效率之间的权衡成为瓶颈，受到控制理论中具有多输入多输出的连续状态空间模型（SSMs）启发，我们提出了一种名为嵌入线性动力学的神经网络（LDNN）的新型神经网络。 SSM的连续、离散和卷积属性使LDNN具有少量参数、灵活的推断和在长序列任务中高效训练的特点。 我们开发了两种有效策略，对角化和“解耦然后快速傅立叶变换（FFT）”，以将卷积的时间复杂度从$O(LNH\max\{L, N\})$降低到$O(LN\max\{H, \log L\})$。 我们通过双向非因果和多头设置进一步改进了LDNN，以适应更广泛的应用范围。 对长距离竞技场（LRA）的大量实验表明了LDNN的有效性和最先进的性能。

    arXiv:2402.15290v1 Announce Type: cross  Abstract: The trade-off between performance and computational efficiency in long-sequence modeling becomes a bottleneck for existing models. Inspired by the continuous state space models (SSMs) with multi-input and multi-output in control theory, we propose a new neural network called Linear Dynamics-embedded Neural Network (LDNN). SSMs' continuous, discrete, and convolutional properties enable LDNN to have few parameters, flexible inference, and efficient training in long-sequence tasks. Two efficient strategies, diagonalization and $'\text{Disentanglement then Fast Fourier Transform (FFT)}'$, are developed to reduce the time complexity of convolution from $O(LNH\max\{L, N\})$ to $O(LN\max \{H, \log L\})$. We further improve LDNN through bidirectional noncausal and multi-head settings to accommodate a broader range of applications. Extensive experiments on the Long Range Arena (LRA) demonstrate the effectiveness and state-of-the-art performance
    
[^32]: 高维数据预测学习的时空观察者设计

    Spatiotemporal Observer Design for Predictive Learning of High-Dimensional Data

    [https://arxiv.org/abs/2402.15284](https://arxiv.org/abs/2402.15284)

    本文设计了一个名为“时空观察者”的观察者理论引导的深度学习架构，为高维数据的预测学习提供了泛化误差界限和收敛保证，并引入了动态正则化以更好地学习系统动态。

    

    虽然基于深度学习的方法在时空预测学习中取得了巨大成功，但这些模型的框架主要是基于直觉设计的。如何进行具有理论保证的时空预测仍然是一个具有挑战性的问题。在这项工作中，我们通过将动态系统的领域知识应用于深度学习模型的框架设计，来解决这个问题。我们设计了一个名为“时空观察者”的观察者理论引导的深度学习架构，用于高维数据的预测学习。提出的框架的特点是双重的：首先，它为时空预测提供了泛化误差界限和收敛保证；其次，在训练过程中引入了动态正则化，使模型能够更好地学习系统动态。进一步的实验结果表明，该框架能够捕捉时空动态并进行准确预测。

    arXiv:2402.15284v1 Announce Type: cross  Abstract: Although deep learning-based methods have shown great success in spatiotemporal predictive learning, the framework of those models is designed mainly by intuition. How to make spatiotemporal forecasting with theoretical guarantees is still a challenging issue. In this work, we tackle this problem by applying domain knowledge from the dynamical system to the framework design of deep learning models. An observer theory-guided deep learning architecture, called Spatiotemporal Observer, is designed for predictive learning of high dimensional data. The characteristics of the proposed framework are twofold: firstly, it provides the generalization error bound and convergence guarantee for spatiotemporal prediction; secondly, dynamical regularization is introduced to enable the model to learn system dynamics better during training. Further experimental results show that this framework could capture the spatiotemporal dynamics and make accurate
    
[^33]: 犹豫时，要慢慢思考：具有潜在想象力的迭代推理

    When in Doubt, Think Slow: Iterative Reasoning with Latent Imagination

    [https://arxiv.org/abs/2402.15283](https://arxiv.org/abs/2402.15283)

    通过在决策时应用迭代推理来微调推断的代理状态，能够在视觉3D导航任务中取得一致的性能改进，并在部分可观察环境中得到更好的表现。

    

    在一个陌生的环境中，基于模型的强化学习代理可能会受到其世界模型准确性的限制。在这项工作中，我们提出了一种改进这类代理性能的新颖、无需训练的方法，与规划和学习分开。我们通过在决策时应用迭代推理来进行微调，以基于未来状态表示的连贯性来改进推断的代理状态。我们的方法在应用于视觉3D导航任务时，在重构精度和任务性能方面实现了一致的改进。我们进一步展示，在部分可观察环境中考虑更多的未来状态会进一步提高代理的性能，但在完全可观察的环境中不会。最后，我们证明训练预评估较少的代理从我们的方法中获益最多。

    arXiv:2402.15283v1 Announce Type: cross  Abstract: In an unfamiliar setting, a model-based reinforcement learning agent can be limited by the accuracy of its world model. In this work, we present a novel, training-free approach to improving the performance of such agents separately from planning and learning. We do so by applying iterative inference at decision-time, to fine-tune the inferred agent states based on the coherence of future state representations. Our approach achieves a consistent improvement in both reconstruction accuracy and task performance when applied to visual 3D navigation tasks. We go on to show that considering more future states further improves the performance of the agent in partially-observable environments, but not in a fully-observable one. Finally, we demonstrate that agents with less training pre-evaluation benefit most from our approach.
    
[^34]: Text2Pic Swift：增强大规模库中长文本到图像的检索

    Text2Pic Swift: Enhancing Long-Text to Image Retrieval for Large-Scale Libraries

    [https://arxiv.org/abs/2402.15276](https://arxiv.org/abs/2402.15276)

    Text2Pic Swift框架针对大规模库中文本描述到图像的检索提出了一种高效且强大的方法，通过两阶段策略解决了长文本查询中的歧义问题

    

    arXiv:2402.15276v1 公告类型：跨领域 摘要：文本到图像检索在各种应用中起着至关重要的作用，包括数字图书馆、电子商务平台和多媒体数据库，通过使用文本查询来搜索图像。尽管多模态大语言模型（MLLMs）取得了先进的性能，但它们在大规模、多样化和模糊的检索场景中的适用性受到显着的计算需求和生成可注入的嵌入所限制。本文介绍了Text2Pic Swift框架，专为在庞大的数据集中有效和稳健地检索与广泛文本描述对应的图像而设计。该框架采用了两阶段方法：初始基于实体的排序（ER）阶段通过多查询对多目标的策略来解决长文本查询中固有的歧义，从而有效地缩小了可能的候选项，以便进行后续分析。接下来

    arXiv:2402.15276v1 Announce Type: cross  Abstract: Text-to-image retrieval plays a crucial role across various applications, including digital libraries, e-commerce platforms, and multimedia databases, by enabling the search for images using text queries. Despite the advancements in Multimodal Large Language Models (MLLMs), which offer leading-edge performance, their applicability in large-scale, varied, and ambiguous retrieval scenarios is constrained by significant computational demands and the generation of injective embeddings. This paper introduces the Text2Pic Swift framework, tailored for efficient and robust retrieval of images corresponding to extensive textual descriptions in sizable datasets. The framework employs a two-tier approach: the initial Entity-based Ranking (ER) stage addresses the ambiguity inherent in lengthy text queries through a multiple-queries-to-multiple-targets strategy, effectively narrowing down potential candidates for subsequent analysis. Following thi
    
[^35]: EMIFF：增强型多尺度图像特征融合用于车路协同三维目标检测

    EMIFF: Enhanced Multi-scale Image Feature Fusion for Vehicle-Infrastructure Cooperative 3D Object Detection

    [https://arxiv.org/abs/2402.15272](https://arxiv.org/abs/2402.15272)

    提出了一种新的基于相机的三维检测框架EMIFF，通过多尺度交叉注意力和相机感知通道屏蔽模块来增强基础设施和车辆特征，以解决车路协同三维目标检测中的姿态误差和信息丢失问题

    

    在自动驾驶中，合作感知利用来自车辆和基础设施的多视图摄像头，提供丰富的语义上下文，超越单个车辆视角的道路条件的全局视角。本文针对车路协同三维（VIC3D）目标检测中存在的两个主要挑战提出了一种新的基于相机的三维检测框架，增强型多尺度图像特征融合（EMIFF）。为了充分利用来自车辆和基础设施的整体视角，我们提出了多尺度交叉注意力（MCA）和相机感知通道屏蔽（CCM）模块，以增强基础设施和车辆特征在尺度、空间和通道级别上进行校正，以解决多视图图像融合时固有的姿态误差和传输过程中的信息丢失问题。

    arXiv:2402.15272v1 Announce Type: cross  Abstract: In autonomous driving, cooperative perception makes use of multi-view cameras from both vehicles and infrastructure, providing a global vantage point with rich semantic context of road conditions beyond a single vehicle viewpoint. Currently, two major challenges persist in vehicle-infrastructure cooperative 3D (VIC3D) object detection: $1)$ inherent pose errors when fusing multi-view images, caused by time asynchrony across cameras; $2)$ information loss in transmission process resulted from limited communication bandwidth. To address these issues, we propose a novel camera-based 3D detection framework for VIC3D task, Enhanced Multi-scale Image Feature Fusion (EMIFF). To fully exploit holistic perspectives from both vehicles and infrastructure, we propose Multi-scale Cross Attention (MCA) and Camera-aware Channel Masking (CCM) modules to enhance infrastructure and vehicle features at scale, spatial, and channel levels to correct the po
    
[^36]: 通过无缝接近度整合的平滑图对比学习

    Smoothed Graph Contrastive Learning via Seamless Proximity Integration

    [https://arxiv.org/abs/2402.15270](https://arxiv.org/abs/2402.15270)

    SGCL模型通过三种不同的平滑技术调整对比损失中节点对的惩罚，从而形成具有接近度感知的正样本和负样本

    

    图对比学习（GCL）通过将节点对归类为正样本和负样本来对齐节点表示，其选择过程通常依赖于在两个增强图中建立对应关系。传统的GCL方法在对比损失中统一地融入负样本，导致负节点被平等对待，而不考虑它们与真正正样本的接近程度。本文提出了一种平滑图对比学习模型（SGCL），利用增强图的几何结构来在对比损失中注入与正负样本相关的接近度信息，从而显著规范化学习过程。所提出的SGCL通过整合三种不同的平滑技术调整对比损失中节点对的惩罚，形成了具有接近度感知的正样本和负样本。

    arXiv:2402.15270v1 Announce Type: cross  Abstract: Graph contrastive learning (GCL) aligns node representations by classifying node pairs into positives and negatives using a selection process that typically relies on establishing correspondences within two augmented graphs. The conventional GCL approaches incorporate negative samples uniformly in the contrastive loss, resulting in the equal treatment negative nodes, regardless of their proximity to the true positive. In this paper, we present a Smoothed Graph Contrastive Learning model (SGCL), which leverages the geometric structure of augmented graphs to inject proximity information associated with positive/negative pairs in the contrastive loss, thus significantly regularizing the learning process. The proposed SGCL adjusts the penalties associated with node pairs in the contrastive loss by incorporating three distinct smoothing techniques that result in proximity aware positives and negatives. To enhance scalability for large-scale
    
[^37]: MemoryPrompt: 一种改进预训练语言模型上下文跟踪的轻量封装方法

    MemoryPrompt: A Light Wrapper to Improve Context Tracking in Pre-trained Language Models

    [https://arxiv.org/abs/2402.15268](https://arxiv.org/abs/2402.15268)

    MemoryPrompt方法通过引入辅助循环网络，将信息传递给语言模型，从而改进了预训练语言模型在上下文跟踪方面的性能，避免了灾难性遗忘现象。

    

    基于Transformer的语言模型通过大型硬编码输入窗口跟踪上下文信息。我们引入MemoryPrompt，一种更精简的方法，其中语言模型由一个小的辅助循环网络补充，通过在其常规输入之前添加一系列向量（类似于软提示）将信息传递给语言模型，而无需需要对语言模型进行微调。在对一个旨在检测语言模型跟踪多个事实更新能力的任务上进行测试时，MemoryPrompt增强的语言模型优于那些可以访问完整输入历史记录的更大型语言模型。我们还在一个长距离对话数据集上测试了MemoryPrompt，在该数据集上，其性能与在整个对话历史记录上进行条件处理的模型相当。在这两个实验中，我们还观察到，与完全微调方法不同，MemoryPrompt在适应新任务时不会出现灾难性遗忘，因此不会破坏非专家能力。

    arXiv:2402.15268v1 Announce Type: cross  Abstract: Transformer-based language models (LMs) track contextual information through large, hard-coded input windows. We introduce MemoryPrompt, a leaner approach in which the LM is complemented by a small auxiliary recurrent network that passes information to the LM by prefixing its regular input with a sequence of vectors, akin to soft prompts, without requiring LM finetuning. Tested on a task designed to probe a LM's ability to keep track of multiple fact updates, a MemoryPrompt-augmented LM outperforms much larger LMs that have access to the full input history. We also test MemoryPrompt on a long-distance dialogue dataset, where its performance is comparable to that of a model conditioned on the entire conversation history. In both experiments we also observe that, unlike full-finetuning approaches, MemoryPrompt does not suffer from catastrophic forgetting when adapted to new tasks, thus not disrupting the generalist capabilities of the un
    
[^38]: 通过（去）随机平滑提高基于深度学习的恶意软件检测器的对抗鲁棒性

    Adversarial Robustness of Deep Learning-based Malware Detectors via (De)Randomized Smoothing

    [https://arxiv.org/abs/2402.15267](https://arxiv.org/abs/2402.15267)

    通过选择相关的字节子集替代高斯噪声，在训练中进行基于消融的平滑方案，加强了基于深度学习的恶意软件检测器对抗性恶意软件示例的鲁棒性。

    

    基于深度学习的恶意软件检测器已被证明容易受到对抗性恶意软件示例的攻击，即恶意软件示例经过故意操纵以避免检测。鉴于深度学习检测器对微妙输入文件修改的脆弱性，我们提出了一种受（去）随机平滑启发的针对对抗性恶意软件示例的实用防御方法。本文中，我们通过选择相关的字节子集而不是像计算机视觉（CV）领域那样使用高斯噪声来随机化输入，来降低被恶意软件作者注入的对抗内容被采样的几率。在训练期间，我们的去除基于消融的平滑方案训练一个基本分类器对一部分连续字节或字节块进行分类。在测试时，基本分类器对大量字节块进行分类，最后预测结果是这些分类中的一致性。

    arXiv:2402.15267v1 Announce Type: cross  Abstract: Deep learning-based malware detectors have been shown to be susceptible to adversarial malware examples, i.e. malware examples that have been deliberately manipulated in order to avoid detection. In light of the vulnerability of deep learning detectors to subtle input file modifications, we propose a practical defense against adversarial malware examples inspired by (de)randomized smoothing. In this work, we reduce the chances of sampling adversarial content injected by malware authors by selecting correlated subsets of bytes, rather than using Gaussian noise to randomize inputs like in the Computer Vision (CV) domain. During training, our ablation-based smoothing scheme trains a base classifier to make classifications on a subset of contiguous bytes or chunk of bytes. At test time, a large number of chunks are then classified by a base classifier and the consensus among these classifications is then reported as the final prediction. W
    
[^39]: 基于动态内存的自适应优化

    Dynamic Memory Based Adaptive Optimization

    [https://arxiv.org/abs/2402.15262](https://arxiv.org/abs/2402.15262)

    提出了一种称为“回顾式学习法律修正”的通用方法，用于计算内存单元的动态变化线性组合，能够在具有线性更新规则和小内存的优化器中取得优于经典优化器的性能。

    

    将优化器定义为在参数空间中存储$k$个动态变化向量的具有内存$k$的优化器。经典的SGD优化器具有内存$0$，动量SGD优化器具有$1$，Adam优化器具有$2$。本文探讨了以下问题：优化器如何利用更多内存单元？应该在其中存储哪些信息？如何将它们用于学习步骤？作为最后一个问题的方法，我们介绍了一种称为“回顾式学习法律修正”或简称RLLC的通用方法。该方法旨在计算内存单元的动态变化线性组合（称为学习法则），这些内存单元本身可能会任意演变。我们在内存单元具有线性更新规则和小内存（$\leq 4$内存单元）的优化器上展示了RLLC。我们的实验表明，在各种标准问题中，这些优化器表现优于上述三种经典优化器。我们得出结论，RLLC是一种有前途的方法。

    arXiv:2402.15262v1 Announce Type: cross  Abstract: Define an optimizer as having memory $k$ if it stores $k$ dynamically changing vectors in the parameter space. Classical SGD has memory $0$, momentum SGD optimizer has $1$ and Adam optimizer has $2$. We address the following questions: How can optimizers make use of more memory units? What information should be stored in them? How to use them for the learning steps? As an approach to the last question, we introduce a general method called "Retrospective Learning Law Correction" or shortly RLLC. This method is designed to calculate a dynamically varying linear combination (called learning law) of memory units, which themselves may evolve arbitrarily. We demonstrate RLLC on optimizers whose memory units have linear update rules and small memory ($\leq 4$ memory units). Our experiments show that in a variety of standard problems, these optimizers outperform the above mentioned three classical optimizers. We conclude that RLLC is a promisi
    
[^40]: 缺失数据下的结构学习的最优输运

    Optimal Transport for Structure Learning Under Missing Data

    [https://arxiv.org/abs/2402.15255](https://arxiv.org/abs/2402.15255)

    提出了一种基于最优输运的得分算法，用于从缺失数据中学习因果结构，通过将结构学习视为密度拟合问题，并通过最小化与观测数据分布之间的沃尔仑斯坦距离来找到导致观测数据分布的因果模型

    

    在缺失数据的情况下进行因果发现会引入鸡生蛋问题。虽然目标是恢复真实的因果结构，但鲁棒的插补需要考虑变量之间的依赖性或更好地因果关系。仅仅用现有的插补方法填充缺失值，然后在完整数据上应用结构学习被证明是次优的。为此，本文提出了一种基于最优输运的基于得分的算法，用于从缺失数据中学习因果结构。这种最优输运的观点不同于现有基于EM的基于得分方法。我们将结构学习投影为密度拟合问题，其目标是找到引起观测数据分布和观测数据之间的沃尔仑斯坦距离的因果模型。通过大量的模拟和实际数据实验，我们的框架...

    arXiv:2402.15255v1 Announce Type: cross  Abstract: Causal discovery in the presence of missing data introduces a chicken-and-egg dilemma. While the goal is to recover the true causal structure, robust imputation requires considering the dependencies or preferably causal relations among variables. Merely filling in missing values with existing imputation methods and subsequently applying structure learning on the complete data is empirical shown to be sub-optimal. To this end, we propose in this paper a score-based algorithm, based on optimal transport, for learning causal structure from missing data. This optimal transport viewpoint diverges from existing score-based approaches that are dominantly based on EM. We project structure learning as a density fitting problem, where the goal is to find the causal model that induces a distribution of minimum Wasserstein distance with the distribution over the observed data. Through extensive simulations and real-data experiments, our framework 
    
[^41]: 一种基于谈判的垂直联邦学习特征交易方法

    A Bargaining-based Approach for Feature Trading in Vertical Federated Learning

    [https://arxiv.org/abs/2402.15247](https://arxiv.org/abs/2402.15247)

    该研究提出了一种基于谈判的垂直联邦学习特征交易方法，以促进经济高效的交易

    

    垂直联邦学习（VFL）已经成为一种流行的机器学习范式，可以在保护数据隐私的同时，实现跨数据和任务方对相同用户集的模型训练。在生产环境中，VFL通常涉及一个任务方和一个数据方。公平和经济高效的特征交易对VFL的商业化至关重要，其中任务方被视为购买数据方特征的数据消费者。然而，当前的VFL特征交易做法通常将数据方的数据整体定价，并假定交易发生在执行VFL之前。忽略交易特征产生的性能增益可能导致不公平支付和过度支付问题。在本研究中，我们提出了一种基于谈判的VFL特征交易方法，以促进经济高效的交易。我们的模型结合了基于性能增益的定价，

    arXiv:2402.15247v1 Announce Type: cross  Abstract: Vertical Federated Learning (VFL) has emerged as a popular machine learning paradigm, enabling model training across the data and the task parties with different features about the same user set while preserving data privacy. In production environment, VFL usually involves one task party and one data party. Fair and economically efficient feature trading is crucial to the commercialization of VFL, where the task party is considered as the data consumer who buys the data party's features. However, current VFL feature trading practices often price the data party's data as a whole and assume transactions occur prior to the performing VFL. Neglecting the performance gains resulting from traded features may lead to underpayment and overpayment issues. In this study, we propose a bargaining-based feature trading approach in VFL to encourage economically efficient transactions. Our model incorporates performance gain-based pricing, taking int
    
[^42]: 在生物医学成像背景下，使用人工蜂群优化深度卷积神经网络

    Artificial Bee Colony optimization of Deep Convolutional Neural Networks in the context of Biomedical Imaging

    [https://arxiv.org/abs/2402.15246](https://arxiv.org/abs/2402.15246)

    我们提出了Chimera算法，该算法是一种新颖的混合神经进化算法，用于优化深度学习架构。

    

    计算机视觉领域的大多数工作集中在自然图像或艺术品上，这些图像与生物医学图像处理所涉及的数据在大小和内容上有着显著不同。因此，即使经过手动微调，迁移学习模型在这些任务中通常也被证明是亚优化的。由于超参数空间的广阔性、时间不足、计算资源不足以及大多数生物医学研究实验室缺乏深度学习专家，因此从头开始开发架构通常是不可行的。手动定义模型的替代方法是使用神经进化，它采用元启发技术来优化深度学习架构。然而，神经进化文献中提出的许多算法要么不够可靠，要么受限于超参数空间的小范围。为了克服这些缺点，我们提出了Chimera算法，这是一种新颖的、混合的神经进化算

    arXiv:2402.15246v1 Announce Type: cross  Abstract: Most efforts in Computer Vision focus on natural images or artwork, which differ significantly both in size and contents from the kind of data biomedical image processing deals with. Thus, Transfer Learning models often prove themselves suboptimal for these tasks, even after manual finetuning. The development of architectures from scratch is oftentimes unfeasible due to the vastness of the hyperparameter space and a shortage of time, computational resources and Deep Learning experts in most biomedical research laboratories. An alternative to manually defining the models is the use of Neuroevolution, which employs metaheuristic techniques to optimize Deep Learning architectures. However, many algorithms proposed in the neuroevolutive literature are either too unreliable or limited to a small, predefined region of the hyperparameter space. To overcome these shortcomings, we propose the Chimera Algorithm, a novel, hybrid neuroevolutive al
    
[^43]: 固定随机分类器重排在持续学习中的应用

    Fixed Random Classifier Rearrangement for Continual Learning

    [https://arxiv.org/abs/2402.15227](https://arxiv.org/abs/2402.15227)

    提出了一种名为固定随机分类器重排（FRCR）的两阶段持续学习算法，通过替换可学习的分类器为固定的随机分类器，在不影响网络性能的情况下，约束了等价的单分类器的范数。

    

    随着数据的爆炸性增长，神经网络的持续学习能力变得越来越重要。由于灾难性遗忘，神经网络在学习新任务后不可避免地会忘记旧任务的知识。在视觉分类场景中，缓解遗忘的常见做法是限制主干网络，然而分类器的影响被低估了。本文分析了模型在顺序二元分类任务中的预测变化，并发现等价单分类器的范数显著影响遗忘水平。基于这一结论，我们提出了一个名为固定随机分类器重排（Fixed Random Classifier Rearrangement，FRCR）的两阶段持续学习算法。在第一阶段，FRCR用固定的随机分类器替换可学习的分类器，约束了等价的单分类器的范数，而不影响网络的性能。

    arXiv:2402.15227v1 Announce Type: cross  Abstract: With the explosive growth of data, continual learning capability is increasingly important for neural networks. Due to catastrophic forgetting, neural networks inevitably forget the knowledge of old tasks after learning new ones. In visual classification scenario, a common practice of alleviating the forgetting is to constrain the backbone. However, the impact of classifiers is underestimated. In this paper, we analyze the variation of model predictions in sequential binary classification tasks and find that the norm of the equivalent one-class classifiers significantly affects the forgetting level. Based on this conclusion, we propose a two-stage continual learning algorithm named Fixed Random Classifier Rearrangement (FRCR). In first stage, FRCR replaces the learnable classifiers with fixed random classifiers, constraining the norm of the equivalent one-class classifiers without affecting the performance of the network. In second sta
    
[^44]: 使用LLMs辅助护士书写日记，增强ICU患者康复

    Enhancing ICU Patient Recovery: Using LLMs to Assist Nurses in Diary Writing

    [https://arxiv.org/abs/2402.15205](https://arxiv.org/abs/2402.15205)

    使用大型语言模型（LLMs）辅助护士书写日记，有助于改善ICU患者的长期康复结果

    

    重症监护病房（ICU）患者在长期康复过程中往往会出现新的健康问题。医护人员记录患者留院情况的日记是一种有效的策略，但面临着诸多采纳障碍，如缺乏时间和不知道该写些什么。大型语言模型（LLMs）凭借其生成人类化文本和可适应性的能力，可能解决这些挑战。然而，实现这一愿景需要解决几个社会技术和实际研究挑战。本文讨论了这些挑战，并提出了未来研究方向，以利用LLMs在ICU日记撰写中的潜力，最终改善ICU患者的长期康复结果。

    arXiv:2402.15205v1 Announce Type: cross  Abstract: Intensive care unit (ICU) patients often develop new health-related problems in their long-term recovery. Health care professionals keeping a diary of a patient's stay is a proven strategy to tackle this but faces several adoption barriers, such as lack of time and difficulty in knowing what to write. Large language models (LLMs), with their ability to generate human-like text and adaptability, could solve these challenges. However, realizing this vision involves addressing several socio-technical and practical research challenges. This paper discusses these challenges and proposes future research directions to utilize the potential of LLMs in ICU diary writing, ultimately improving the long-term recovery outcomes for ICU patients.
    
[^45]: 安全优化的多目标策略优化强化学习

    Safety Optimized Reinforcement Learning via Multi-Objective Policy Optimization

    [https://arxiv.org/abs/2402.15197](https://arxiv.org/abs/2402.15197)

    本文提出了一种基于多目标策略优化框架的安全强化学习算法，通过安全评论家塑造环境奖励函数，使得策略可以同时朝着最优性和安全性优化，相较于传统方法，该算法无需约束策略搜索空间，实现了安全性和最优性之间的自然权衡。

    

    安全强化学习（安全RL）指的是一类技术，旨在防止RL算法在试错决策和探索过程中违反约束。本文介绍了一种基于多目标策略优化框架制定的新型无模型安全RL算法，其中策略同时朝着最优性和安全性进行优化。通过使用安全评论家来塑造环境奖励函数，从而实现最优性。相较于传统安全RL算法，安全优化RL（SORL）算法的优势在于省略了对策略搜索空间的约束需要。这使得SORL能够在不受严格搜索空间约束的情况下找到安全性和最优性之间的自然权衡，而无需因严格搜索空间约束而在安全性或最优性方面性能受损。通过对SORL的理论分析，我们提出了一种co

    arXiv:2402.15197v1 Announce Type: cross  Abstract: Safe reinforcement learning (Safe RL) refers to a class of techniques that aim to prevent RL algorithms from violating constraints in the process of decision-making and exploration during trial and error. In this paper, a novel model-free Safe RL algorithm, formulated based on the multi-objective policy optimization framework is introduced where the policy is optimized towards optimality and safety, simultaneously. The optimality is achieved by the environment reward function that is subsequently shaped using a safety critic. The advantage of the Safety Optimized RL (SORL) algorithm compared to the traditional Safe RL algorithms is that it omits the need to constrain the policy search space. This allows SORL to find a natural tradeoff between safety and optimality without compromising the performance in terms of either safety or optimality due to strict search space constraints. Through our theoretical analysis of SORL, we propose a co
    
[^46]: AffectToolbox：每个人的情感分析

    The AffectToolbox: Affect Analysis for Everyone

    [https://arxiv.org/abs/2402.15195](https://arxiv.org/abs/2402.15195)

    AffectToolbox是一个新型软件系统，旨在为开发情感敏感研究和原型的研究人员提供支持，无需编程知识即可可靠分析用户情感状态，实现多模情感识别和融合评估。

    

    在情感计算领域，研究不断以快速的速度前进，用户对用户友好工具的需求变得越来越显而易见。在本文中，我们介绍了AffectToolbox，这是一个旨在支持研究人员开发情感敏感研究和原型的新型软件系统。该系统旨在解决现有框架所提出的挑战，这些框架通常需要深入的编程知识，并主要面向高级用户或熟练开发人员。为了促进易用性，AffectToolbox不需要编程知识，并通过易于访问的图形用户界面提供其功能，可可靠地分析用户的情感状态。其架构涵盖了多种模型，用于在多种情感渠道和情感方式上进行情绪识别，以及一个复杂的融合系统，将多模态评估合并为统一结果。整个系统是公开的

    arXiv:2402.15195v1 Announce Type: cross  Abstract: In the field of affective computing, where research continually advances at a rapid pace, the demand for user-friendly tools has become increasingly apparent. In this paper, we present the AffectToolbox, a novel software system that aims to support researchers in developing affect-sensitive studies and prototypes. The proposed system addresses the challenges posed by existing frameworks, which often require profound programming knowledge and cater primarily to power-users or skilled developers. Aiming to facilitate ease of use, the AffectToolbox requires no programming knowledge and offers its functionality to reliably analyze the affective state of users through an accessible graphical user interface. The architecture encompasses a variety of models for emotion recognition on multiple affective channels and modalities, as well as an elaborate fusion system to merge multi-modal assessments into a unified result. The entire system is op
    
[^47]: 连续时间扩散模型的微调作为熵正则化控制

    Fine-Tuning of Continuous-Time Diffusion Models as Entropy-Regularized Control

    [https://arxiv.org/abs/2402.15194](https://arxiv.org/abs/2402.15194)

    扩散模型的微调方法可以通过最大化奖励函数的价值来以目标导向方式进行微调，但可能会面临奖励崩溃的挑战。

    

    扩散模型在捕捉复杂数据分布方面表现出色，例如自然图像和蛋白质的分布。虽然扩散模型经过训练可代表训练数据集中的分布，但我们通常更关注其他属性，例如生成图像的美学质量或生成蛋白质的功能属性。扩散模型可以通过最大化某些奖励函数的价值（例如图像的美学质量）以目标导向的方式进行微调。然而，这些方法可能会导致样本多样性减少，与训练数据分布出现显著偏差，甚至由于利用不完美的奖励函数而导致样本质量较差。在许多实际应用中奖励函数是用于近似真实“真实”奖励的学习模型时，最后一个问题经常会产生。这些挑战总称为“奖励崩溃”。

    arXiv:2402.15194v1 Announce Type: cross  Abstract: Diffusion models excel at capturing complex data distributions, such as those of natural images and proteins. While diffusion models are trained to represent the distribution in the training dataset, we often are more concerned with other properties, such as the aesthetic quality of the generated images or the functional properties of generated proteins. Diffusion models can be finetuned in a goal-directed way by maximizing the value of some reward function (e.g., the aesthetic quality of an image). However, these approaches may lead to reduced sample diversity, significant deviations from the training data distribution, and even poor sample quality due to the exploitation of an imperfect reward function. The last issue often occurs when the reward function is a learned model meant to approximate a ground-truth "genuine" reward, as is the case in many practical applications. These challenges, collectively termed "reward collapse," pose
    
[^48]: 将生物医学实体链接视为多项选择问答

    Biomedical Entity Linking as Multiple Choice Question Answering

    [https://arxiv.org/abs/2402.15189](https://arxiv.org/abs/2402.15189)

    提出了一种新颖的模型BioELQA，将生物医学实体链接看作是多项选择问答，通过使用快速检索器获得候选实体，实现了更好的实体链接效果。

    

    尽管预训练语言模型在生物医学实体链接（BioEL）方面取得了显著进展，但对于细粒度和长尾实体仍然存在挑战。为了解决这些挑战，我们提出了BioELQA，这是一种将生物医学实体链接视为多项选择问答的新颖模型。BioELQA首先利用快速检索器获得候选实体，将提及和候选实体共同呈现给生成器，然后输出与其选定实体相关的预测符号。这种公式使得不同候选实体之间的明确比较成为可能，从而捕捉了提及和实体之间以及实体之间的精细交互。为了改善长尾实体的泛化能力，我们检索相似的已标记训练实例作为线索，并将输入与检索实例连接到生成器。广泛的实验结果表明，BioELQA的表现优于统计结果。

    arXiv:2402.15189v1 Announce Type: cross  Abstract: Although biomedical entity linking (BioEL) has made significant progress with pre-trained language models, challenges still exist for fine-grained and long-tailed entities. To address these challenges, we present BioELQA, a novel model that treats Biomedical Entity Linking as Multiple Choice Question Answering. BioELQA first obtains candidate entities with a fast retriever, jointly presents the mention and candidate entities to a generator, and then outputs the predicted symbol associated with its chosen entity. This formulation enables explicit comparison of different candidate entities, thus capturing fine-grained interactions between mentions and entities, as well as among entities themselves. To improve generalization for long-tailed entities, we retrieve similar labeled training instances as clues and concatenate the input with retrieved instances for the generator. Extensive experimental results show that BioELQA outperforms stat
    
[^49]: GraphEdit：用于图结构学习的大型语言模型

    GraphEdit: Large Language Models for Graph Structure Learning

    [https://arxiv.org/abs/2402.15183](https://arxiv.org/abs/2402.15183)

    本研究提出了一种名为GraphEdit的方法，利用大型语言模型（LLMs）学习复杂的图结构化数据中的节点关系，通过在图结构上进行指导调整，增强LLMs的推理能力，从而提高图结构学习的可靠性。

    

    图结构学习（GSL）致力于通过生成新颖的图结构来捕捉图结构数据中节点之间的固有依赖性和相互作用。本文提出了一种名为GraphEdit的方法，利用大型语言模型（LLMs）学习图结构化数据中复杂的节点关系。通过在图结构上进行指导调整，增强LLMs的推理能力，我们旨在克服显式图结构信息带来的挑战，并提高图结构学习的可靠性。

    arXiv:2402.15183v1 Announce Type: cross  Abstract: Graph Structure Learning (GSL) focuses on capturing intrinsic dependencies and interactions among nodes in graph-structured data by generating novel graph structures. Graph Neural Networks (GNNs) have emerged as promising GSL solutions, utilizing recursive message passing to encode node-wise inter-dependencies. However, many existing GSL methods heavily depend on explicit graph structural information as supervision signals, leaving them susceptible to challenges such as data noise and sparsity. In this work, we propose GraphEdit, an approach that leverages large language models (LLMs) to learn complex node relationships in graph-structured data. By enhancing the reasoning capabilities of LLMs through instruction-tuning over graph structures, we aim to overcome the limitations associated with explicit graph structural information and enhance the reliability of graph structure learning. Our approach not only effectively denoises noisy co
    
[^50]: 跳跃调谐在扩散采样中的惊人有效性

    The Surprising Effectiveness of Skip-Tuning in Diffusion Sampling

    [https://arxiv.org/abs/2402.15170](https://arxiv.org/abs/2402.15170)

    跳跃调谐是一种简单而惊人有效的训练方法，可以提高扩散采样中UNet模型的性能，并突破了ODE采样器的限制

    

    随着UNet架构的整合，扩散概率模型已经成为图像生成任务中的一个主导力量。UNet中的一个关键设计是编码器和解码器块之间的跳跃连接。尽管已经证明跳跃连接可以提高训练稳定性和模型性能，我们发现这样的捷径可能限制了变换的复杂性。随着采样步骤减少，生成过程和UNet的作用更接近于从高斯分布向目标的推进转换，为网络的复杂性提出了挑战。为了解决这一挑战，我们提出了Skip-Tuning，一种简单而令人惊讶地有效的基于跳过连接的无需训练的调整方法。我们的方法可以在ImageNet 64上使用19个NFE（1.75）为预训练的EDM实现100%的FID改进，突破了ODE采样器的限制，不论采样步骤如何。

    arXiv:2402.15170v1 Announce Type: cross  Abstract: With the incorporation of the UNet architecture, diffusion probabilistic models have become a dominant force in image generation tasks. One key design in UNet is the skip connections between the encoder and decoder blocks. Although skip connections have been shown to improve training stability and model performance, we reveal that such shortcuts can be a limiting factor for the complexity of the transformation. As the sampling steps decrease, the generation process and the role of the UNet get closer to the push-forward transformations from Gaussian distribution to the target, posing a challenge for the network's complexity. To address this challenge, we propose Skip-Tuning, a simple yet surprisingly effective training-free tuning method on the skip connections. Our method can achieve 100% FID improvement for pretrained EDM on ImageNet 64 with only 19 NFEs (1.75), breaking the limit of ODE samplers regardless of sampling steps. Surpris
    
[^51]: 研究随机性对深度神经网络在森林火灾预测中评估的影响

    Studying the Impact of Stochasticity on the Evaluation of Deep Neural Networks for Forest-Fire Prediction

    [https://arxiv.org/abs/2402.15163](https://arxiv.org/abs/2402.15163)

    该论文首次系统研究了在随机假设下评估深度神经网络用于森林火灾预测的影响，发现评估对统计的忠实度是在高度随机场景下的可靠替代方法。

    

    本文首次系统研究了在随机假设下评估深度神经网络（DNNs）用于离散动力系统，重点关注野火预测。我们开发了一个框架来研究随机性对两类评估指标的影响：基于分类的指标，评估对观察地面真相（GT）的忠实度，以及适当的得分规则，测试对统计的忠实度。我们的研究结果表明，在高度随机的情况下，评估对统计的忠实度是一个可靠的替代方案。我们将我们的分析扩展到现实世界的森林火灾数据，突显了传统森林火灾预测评估方法中的局限性，并建议可解释的适用于随机性的替代方法。

    arXiv:2402.15163v1 Announce Type: cross  Abstract: This paper presents the first systematic study of the evaluation of Deep Neural Networks (DNNs) for discrete dynamical systems under stochastic assumptions, with a focus on wildfire prediction. We develop a framework to study the impact of stochasticity on two classes of evaluation metrics: classification-based metrics, which assess fidelity to observed ground truth (GT), and proper scoring rules, which test fidelity-to-statistic. Our findings reveal that evaluating for fidelity-to-statistic is a reliable alternative in highly stochastic scenarios. We extend our analysis to real-world wildfire data, highlighting limitations in traditional wildfire prediction evaluation methods, and suggest interpretable stochasticity-compatible alternatives.
    
[^52]: 基于微调的抽象式摘要模型的实体级事实适应性

    Entity-level Factual Adaptiveness of Fine-tuning based Abstractive Summarization Models

    [https://arxiv.org/abs/2402.15162](https://arxiv.org/abs/2402.15162)

    分析了基于微调的摘要模型在处理知识冲突时的实体级事实适应性，并提出了一种反事实数据增强方法，实验结果表明该方法增强了事实适应性，同时保持了事实一致性。

    

    抽象式摘要模型在处理参数化知识与输入文档中的知识冲突时，往往生成事实不一致的内容。本文分析了基于微调的摘要模型对知识冲突的鲁棒性，即我们称之为事实适应性。我们利用预训练语言模型构建评估集，并发现事实适应性与原始数据集上的事实一致性并非强相关。此外，我们引入了一种可控的反事实数据增强方法，其中增强数据中的知识冲突程度是可调节的。我们在两个预训练语言模型（PEGASUS 和 BART）和两个微调数据集（XSum 和 CNN/DailyMail）上的实验结果表明，我们的方法增强了事实适应性，同时在原始数据集上实现了与对比方法相当的事实一致性。

    arXiv:2402.15162v1 Announce Type: cross  Abstract: Abstractive summarization models often generate factually inconsistent content particularly when the parametric knowledge of the model conflicts with the knowledge in the input document. In this paper, we analyze the robustness of fine-tuning based summarization models to the knowledge conflict, which we call factual adaptiveness. We utilize pre-trained language models to construct evaluation sets and find that factual adaptiveness is not strongly correlated with factual consistency on original datasets. Furthermore, we introduce a controllable counterfactual data augmentation method where the degree of knowledge conflict within the augmented data can be adjustable. Our experimental results on two pre-trained language models (PEGASUS and BART) and two fine-tuning datasets (XSum and CNN/DailyMail) demonstrate that our method enhances factual adaptiveness while achieving factual consistency on original datasets on par with the contrastiv
    
[^53]: 面向空间感知的变压器记忆体用于体验代理

    Spatially-Aware Transformer Memory for Embodied Agents

    [https://arxiv.org/abs/2402.15160](https://arxiv.org/abs/2402.15160)

    本文探讨了利用包含空间信息的面向空间感知变压器模型，以改善记忆利用效率。

    

    情节记忆在各种认知过程中起着至关重要的作用，比如能够在头脑中回忆过去事件的能力。虽然认知科学强调空间上下文在情节记忆的形成和检索中的重要性，但当前实现人工智能系统中情节记忆的主要方法是通过存储时间顺序体验的变压器，这忽略了空间维度。因此，目前尚不清楚如何将基础结构扩展到除了仅有时间顺序之外的空间轴，并由此能够获得哪些好处。为了解决这个问题，本文探讨了利用包含空间信息的面向空间感知变压器模型。这些模型使得可以创建考虑时间和空间维度的场所中心情节记忆。采用这种方法，我们证明记忆利用效率可以得到提高，导致增强

    arXiv:2402.15160v1 Announce Type: cross  Abstract: Episodic memory plays a crucial role in various cognitive processes, such as the ability to mentally recall past events. While cognitive science emphasizes the significance of spatial context in the formation and retrieval of episodic memory, the current primary approach to implementing episodic memory in AI systems is through transformers that store temporally ordered experiences, which overlooks the spatial dimension. As a result, it is unclear how the underlying structure could be extended to incorporate the spatial axis beyond temporal order alone and thereby what benefits can be obtained. To address this, this paper explores the use of Spatially-Aware Transformer models that incorporate spatial information. These models enable the creation of place-centric episodic memory that considers both temporal and spatial dimensions. Adopting this approach, we demonstrate that memory utilization efficiency can be improved, leading to enhanc
    
[^54]: 面向预训练大型语言模型的机器遗忘

    Machine Unlearning of Pre-trained Large Language Models

    [https://arxiv.org/abs/2402.15159](https://arxiv.org/abs/2402.15159)

    本研究在大型语言模型（LLMs）中探讨了“被遗忘权”的概念，提出机器遗忘作为解决方案，并在预训练模型中建立了全面的遗忘框架及高效的遗忘方法，同时提供了改进超参数鲁棒性以及高效调整超参数的指南。

    

    本研究探讨了大型语言模型（LLMs）背景下“被遗忘权”的概念。我们以机器遗忘作为一个关键解决方案，重点关注预训练模型——一个明显缺乏研究的领域。我们在预训练LLMs中勾勒了一个全面的机器遗忘框架，包括对七种不同遗忘方法的批判性分析。通过使用来自arXiv、书籍和GitHub的策划数据集进行严格评估，我们建立了一个有力的机器遗忘性能基准，表明这些方法的计算效率比重新训练高出 $10^5$ 倍以上。我们的结果表明，在分布数据上将梯度上升与梯度下降结合可以改善超参数的鲁棒性。我们还提供了关于在遗忘过程中进行高效超参数调整的详细指南。我们的研究推动了有关伦理人工智能实践的讨论，提供了

    arXiv:2402.15159v1 Announce Type: cross  Abstract: This study investigates the concept of the `right to be forgotten' within the context of large language models (LLMs). We explore machine unlearning as a pivotal solution, with a focus on pre-trained models--a notably under-researched area. Our research delineates a comprehensive framework for machine unlearning in pre-trained LLMs, encompassing a critical analysis of seven diverse unlearning methods. Through rigorous evaluation using curated datasets from arXiv, books, and GitHub, we establish a robust benchmark for unlearning performance, demonstrating that these methods are over $10^5$ times more computationally efficient than retraining. Our results show that integrating gradient ascent with gradient descent on in-distribution data improves hyperparameter robustness. We also provide detailed guidelines for efficient hyperparameter tuning in the unlearning process. Our findings advance the discourse on ethical AI practices, offering
    
[^55]: 关于Sharpness-Aware最小化和对抗训练之间的对偶性

    On the Duality Between Sharpness-Aware Minimization and Adversarial Training

    [https://arxiv.org/abs/2402.15152](https://arxiv.org/abs/2402.15152)

    通过研究Sharpness-Aware最小化(SAM)和对抗训练(AT)之间的对偶性，发现单独使用SAM可以提高对抗性能。

    

    对抗训练(Adversarial Training, AT)在训练过程中对输入样本进行对抗性扰动，被认为是对抗攻击中最有效的防御之一，但不可避免地存在一种基本的权衡，即必然会降低干净准确性。与对样本进行扰动不同，Sharpness-Aware最小化(SAM)在训练过程中对模型权重进行扰动，以寻找更平坦的损失曲面并提高泛化性能。然而，由于SAM旨在提高干净准确性，其在增强对抗稳健性方面的有效性尚未被探索。在本研究中，考虑到SAM和AT之间的对偶性，我们调查了从SAM中派生的对抗稳健性。有趣的是，我们发现单独使用SAM可以提高对抗稳健性。为了理解SAM的这种意外特性，我们首先提供了关于SAM如何隐式学习更鲁棒特征的经验和理论的见解，并进行了全面的实验。

    arXiv:2402.15152v1 Announce Type: cross  Abstract: Adversarial Training (AT), which adversarially perturb the input samples during training, has been acknowledged as one of the most effective defenses against adversarial attacks, yet suffers from a fundamental tradeoff that inevitably decreases clean accuracy. Instead of perturbing the samples, Sharpness-Aware Minimization (SAM) perturbs the model weights during training to find a more flat loss landscape and improve generalization. However, as SAM is designed for better clean accuracy, its effectiveness in enhancing adversarial robustness remains unexplored. In this work, considering the duality between SAM and AT, we investigate the adversarial robustness derived from SAM. Intriguingly, we find that using SAM alone can improve adversarial robustness. To understand this unexpected property of SAM, we first provide empirical and theoretical insights into how SAM can implicitly learn more robust features, and conduct comprehensive exper
    
[^56]: 超关系知识图中消息传递的关系交互式方法

    A Relation-Interactive Approach for Message Passing in Hyper-relational Knowledge Graphs

    [https://arxiv.org/abs/2402.15140](https://arxiv.org/abs/2402.15140)

    提出了一种消息传递的图编码器ReSaE，具有全局关系结构意识能力，强调了关系在消息传递过程中的交互，并优化了用于链接预测任务的读取结构，在超关系知识图上表现出色。

    

    超关系知识图包含额外的键值对，提供关于关系的更多信息。在许多情况下，相同的关系可以具有不同的键值对，使原始三元组事实更具识别性和特定性。先前关于超关系知识图的研究已经建立了一种稳固的超关系图编码方法。在这项工作中，我们提出了一种具有全局关系结构意识能力的基于消息传递的图编码器，我们称之为ReSaE。与先前的最先进方法相比，ReSaE强调了在消息传递过程中关系的交互，并优化了用于链接预测任务的读取结构。总体而言，ReSaE为超关系知识图提供了一种编码解决方案，并确保在下游链接预测任务上具有更强的性能。我们的实验表明，ReSaE在多个链接预测基准上实现了最先进的性能。

    arXiv:2402.15140v1 Announce Type: new  Abstract: Hyper-relational knowledge graphs (KGs) contain additional key-value pairs, providing more information about the relations. In many scenarios, the same relation can have distinct key-value pairs, making the original triple fact more recognizable and specific. Prior studies on hyper-relational KGs have established a solid standard method for hyper-relational graph encoding. In this work, we propose a message-passing-based graph encoder with global relation structure awareness ability, which we call ReSaE. Compared to the prior state-of-the-art approach, ReSaE emphasizes the interaction of relations during message passing process and optimizes the readout structure for link prediction tasks. Overall, ReSaE gives a encoding solution for hyper-relational KGs and ensures stronger performance on downstream link prediction tasks. Our experiments demonstrate that ReSaE achieves state-of-the-art performance on multiple link prediction benchmarks.
    
[^57]: 修改的CycleGAN用于小麦头部分割样本的合成

    Modified CycleGAN for the synthesization of samples for wheat head segmentation

    [https://arxiv.org/abs/2402.15135](https://arxiv.org/abs/2402.15135)

    通过修改的CycleGAN模型，成功解决了合成数据与真实数据之间的域差异，为小麦头部分割样本合成提供了可用于训练深度学习模型的合成数据集。

    

    深度学习模型已被用于各种图像处理任务。然而，大多数模型是通过监督学习方法开发的，这种方法严重依赖大规模带有注释的数据集的可用性。在没有带有注释的数据集的情况下，可以使用合成数据来进行模型开发；然而，由于模拟数据和真实数据之间存在重大差异，被称为域差异，导致的模型在应用于真实数据时往往表现不佳。在这项研究中，我们首先通过计算模拟大规模带注释的数据集，然后使用生成对抗网络（GAN）来填补模拟和真实图像之间的差距。这种方法产生了一个可以有效用于训练深度学习模型的合成数据集。利用这种方法，我们开发了一个现实注释的

    arXiv:2402.15135v1 Announce Type: cross  Abstract: Deep learning models have been used for a variety of image processing tasks. However, most of these models are developed through supervised learning approaches, which rely heavily on the availability of large-scale annotated datasets. Developing such datasets is tedious and expensive. In the absence of an annotated dataset, synthetic data can be used for model development; however, due to the substantial differences between simulated and real data, a phenomenon referred to as domain gap, the resulting models often underperform when applied to real data. In this research, we aim to address this challenge by first computationally simulating a large-scale annotated dataset and then using a generative adversarial network (GAN) to fill the gap between simulated and real images. This approach results in a synthetic dataset that can be effectively utilized to train a deep-learning model. Using this approach, we developed a realistic annotated
    
[^58]: 多元时间序列预测的深度耦合网络

    Deep Coupling Network For Multivariate Time Series Forecasting

    [https://arxiv.org/abs/2402.15134](https://arxiv.org/abs/2402.15134)

    重新审视多元时间序列的序内和序间关系，提出了一种用于预测的深度耦合网络，可以同时捕捉多阶序内和序间的复杂耦合。

    

    多元时间序列（MTS）预测在许多实际应用中至关重要。为了实现准确的MTS预测，同时考虑时间序列数据中的序内和序间关系是至关重要的。然而，先前的工作通常分别建模序内和序间关系，并忽略了存在于时间序列数据内部和之间的多阶交互，这严重影响了预测的准确性。在本文中，我们从互信息的角度重新审视序内和序间关系，并相应地构建了一个专门捕捉复杂多阶序内和序间耦合的全面关系学习机制。基于这一机制，我们提出了一种新颖的用于MTS预测的深度耦合网络，称为DeepCN，它包括一个专用于明确探索多阶序内和间的耦合机制的耦合机制。

    arXiv:2402.15134v1 Announce Type: cross  Abstract: Multivariate time series (MTS) forecasting is crucial in many real-world applications. To achieve accurate MTS forecasting, it is essential to simultaneously consider both intra- and inter-series relationships among time series data. However, previous work has typically modeled intra- and inter-series relationships separately and has disregarded multi-order interactions present within and between time series data, which can seriously degrade forecasting accuracy. In this paper, we reexamine intra- and inter-series relationships from the perspective of mutual information and accordingly construct a comprehensive relationship learning mechanism tailored to simultaneously capture the intricate multi-order intra- and inter-series couplings. Based on the mechanism, we propose a novel deep coupling network for MTS forecasting, named DeepCN, which consists of a coupling mechanism dedicated to explicitly exploring the multi-order intra- and in
    
[^59]: 互动式知识库问答：基于大型语言模型的多轮交互式知识库问答

    Interactive-KBQA: Multi-Turn Interactions for Knowledge Base Question Answering with Large Language Models

    [https://arxiv.org/abs/2402.15131](https://arxiv.org/abs/2402.15131)

    提出了一种互动式KBQA框架，通过直接与知识库互动生成逻辑形式，开发了用于KB交互的通用API，并设计了示例来指导大型语言模型进行推理。

    

    本研究探讨了知识库问答（KBQA）的领域。KBQA被认为是一项具有挑战性的任务，特别是在将复杂问题解析为可执行逻辑形式方面。传统的基于语义解析（SP）的方法需要大量的数据注释，这导致了显著的成本。最近，由大型语言模型（LLM）推动的少样本上下文学习的出现展示了很好的能力。然而，在低资源情景下充分利用LLMs将问题解析为逻辑形式是一个重大挑战。为了应对这些障碍，我们引入了互动式知识库问答（Interactive-KBQA），这是一个旨在通过与知识库（KBs）直接互动来生成逻辑形式的框架。在这个框架内，我们开发了三个用于KB交互的通用API。对于每种复杂问题类别，我们设计了示例来指导LLMs完成推理过程。我们的方法取得了具有竞争力的结果。

    arXiv:2402.15131v1 Announce Type: cross  Abstract: This study explores the realm of knowledge-base question answering (KBQA). KBQA is considered a challenging task, particularly in parsing intricate questions into executable logical forms. Traditional semantic parsing (SP)-based methods require extensive data annotations, which result in significant costs. Recently, the advent of few-shot in-context learning, powered by large language models (LLMs), has showcased promising capabilities. Yet, fully leveraging LLMs to parse questions into logical forms in low-resource scenarios poses a substantial challenge. To tackle these hurdles, we introduce Interactive-KBQA, a framework designed to generate logical forms through direct interaction with knowledge bases (KBs). Within this framework, we have developed three generic APIs for KB interaction. For each category of complex question, we devised exemplars to guide LLMs through the reasoning processes. Our method achieves competitive results o
    
[^60]: 使用两步重述对CLIP文本编码器进行微调

    Fine-tuning CLIP Text Encoders with Two-step Paraphrasing

    [https://arxiv.org/abs/2402.15120](https://arxiv.org/abs/2402.15120)

    通过两步重述生成过程对CLIP模型进行微调，以增强对释义的表示能力。

    

    Contrastive language-image pre-training (CLIP)模型在各种视觉-语言任务中表现出色，如文本到图像检索，其中模型需要有效处理自然语言输入以产生准确的视觉输出。然而，当前模型在处理输入查询中的语言变化（如释义）方面仍然面临限制，这使得难以处理现实应用中用户查询的广泛范围。在这项研究中，我们引入了一种简单的微调方法，以增强CLIP模型对释义的表示。我们的方法涉及一个两步释义生成过程，我们通过利用大型语言模型从网页规模的图像标题中自动创建两类释义。随后，我们通过使用这些生成的释义来微调CLIP文本编码器，同时冻结图像编码器。我们的结果模型，...

    arXiv:2402.15120v1 Announce Type: cross  Abstract: Contrastive language-image pre-training (CLIP) models have demonstrated considerable success across various vision-language tasks, such as text-to-image retrieval, where the model is required to effectively process natural language input to produce an accurate visual output. However, current models still face limitations in dealing with linguistic variations in input queries, such as paraphrases, making it challenging to handle a broad range of user queries in real-world applications. In this study, we introduce a straightforward fine-tuning approach to enhance the representations of CLIP models for paraphrases. Our approach involves a two-step paraphrase generation process, where we automatically create two categories of paraphrases from web-scale image captions by leveraging large language models. Subsequently, we fine-tune the CLIP text encoder using these generated paraphrases while freezing the image encoder. Our resulting model, 
    
[^61]: 大型多模态代理：一项调查

    Large Multimodal Agents: A Survey

    [https://arxiv.org/abs/2402.15116](https://arxiv.org/abs/2402.15116)

    大型语言模型驱动的多模态代理（LMAs）的系统审查，涵盖了开发组件、研究类型分类以及集体效能增强的合作框架等内容。

    

    大型语言模型（LLMs）在推动基于文本的人工智能代理时取得了卓越表现，赋予它们类似于人类的决策和推理能力。同时，有一个新兴的研究趋势专注于将这些LLM驱动的人工智能代理扩展到多模态领域。本文系统地审查了LLM驱动的多模态代理，我们将其称为大型多模态代理（LMAs简称）。首先，我们介绍了发展LMAs所涉及的基本组成部分，并将当前的研究范畴分为四种不同类型。随后，我们审查了集成多个LMAs以增强集体效能的合作框架。这一领域面临的一个关键挑战是现有研究中使用的多样化评估方法。

    arXiv:2402.15116v1 Announce Type: cross  Abstract: Large language models (LLMs) have achieved superior performance in powering text-based AI agents, endowing them with decision-making and reasoning abilities akin to humans. Concurrently, there is an emerging research trend focused on extending these LLM-powered AI agents into the multimodal domain. This extension enables AI agents to interpret and respond to diverse multimodal user queries, thereby handling more intricate and nuanced tasks. In this paper, we conduct a systematic review of LLM-driven multimodal agents, which we refer to as large multimodal agents ( LMAs for short). First, we introduce the essential components involved in developing LMAs and categorize the current body of research into four distinct types. Subsequently, we review the collaborative frameworks integrating multiple LMAs , enhancing collective efficacy. One of the critical challenges in this field is the diverse evaluation methods used across existing studie
    
[^62]: 轨迹式迭代强化学习框架用于自动竞标

    Trajectory-wise Iterative Reinforcement Learning Framework for Auto-bidding

    [https://arxiv.org/abs/2402.15102](https://arxiv.org/abs/2402.15102)

    自动广告竞标中使用了一种新的迭代离线强化学习框架，有效缓解了传统RL算法在在线环境下性能下降的问题。

    

    在在线广告中，广告主参与广告竞拍以获取广告机会，通常是通过需求方平台(DSPs)提供的自动竞标工具。目前的自动竞标算法通常采用强化学习（RL）。然而，由于安全性问题，大多数基于RL的自动竞标策略是在模拟环境中进行训练的，在在线环境中部署会导致性能下降。为了缩小这一差距，我们可以并行部署多个自动竞标代理以收集大量交互数据集。然后，可以利用离线RL算法训练新策略。训练后的策略随后可以部署以进行进一步的数据收集，从而形成一个迭代训练框架，我们将其称为迭代离线RL。在这项工作中，我们确定了这种迭代离线RL框架的性能瓶颈，其根源在于由于内在原因而导致的探索和利用的低效问题。

    arXiv:2402.15102v1 Announce Type: cross  Abstract: In online advertising, advertisers participate in ad auctions to acquire ad opportunities, often by utilizing auto-bidding tools provided by demand-side platforms (DSPs). The current auto-bidding algorithms typically employ reinforcement learning (RL). However, due to safety concerns, most RL-based auto-bidding policies are trained in simulation, leading to a performance degradation when deployed in online environments. To narrow this gap, we can deploy multiple auto-bidding agents in parallel to collect a large interaction dataset. Offline RL algorithms can then be utilized to train a new policy. The trained policy can subsequently be deployed for further data collection, resulting in an iterative training framework, which we refer to as iterative offline RL. In this work, we identify the performance bottleneck of this iterative offline RL framework, which originates from the ineffective exploration and exploitation caused by the inhe
    
[^63]: AttributionBench：自动归因评估有多难？

    AttributionBench: How Hard is Automatic Attribution Evaluation?

    [https://arxiv.org/abs/2402.15089](https://arxiv.org/abs/2402.15089)

    AttributionBench是一个综合基准，揭示了自动归因评估的挑战，即使对于最先进的语言模型也只能达到80%的准确率。

    

    现代生成式搜索引擎通过提供引用证据增强了大型语言模型（LLM）响应的可靠性。然而，评估答案的归因，即生成响应中的每个声明是否都得到其引用证据的充分支持，仍然是一个未解决的问题。传统上依赖于昂贵的人工评估的这种验证强调了对自动归因评估方法的迫切需求。为了填补这种方法缺乏标准化基准的差距，我们提出了AttributionBench，这是一个综合性基准，由各种现有的归因数据集编制而成。我们在AttributionBench上的大量实验揭示了自动归因评估面临的挑战，即使对于最先进的LLM也是如此。具体而言，我们的发现表明，即使是经过优化的GPT-3.5在二元分类公式下也只能达到约80%的宏F1分数。更 than 300 error c

    arXiv:2402.15089v1 Announce Type: cross  Abstract: Modern generative search engines enhance the reliability of large language model (LLM) responses by providing cited evidence. However, evaluating the answer's attribution, i.e., whether every claim within the generated responses is fully supported by its cited evidence, remains an open problem. This verification, traditionally dependent on costly human evaluation, underscores the urgent need for automatic attribution evaluation methods. To bridge the gap in the absence of standardized benchmarks for these methods, we present AttributionBench, a comprehensive benchmark compiled from various existing attribution datasets. Our extensive experiments on AttributionBench reveal the challenges of automatic attribution evaluation, even for state-of-the-art LLMs. Specifically, our findings show that even a fine-tuned GPT-3.5 only achieves around 80% macro-F1 under a binary classification formulation. A detailed analysis of more than 300 error c
    
[^64]: 无需手部操作的虚拟现实系统

    Hands-Free VR

    [https://arxiv.org/abs/2402.15083](https://arxiv.org/abs/2402.15083)

    Hands-Free VR 是一种无需手部操作的虚拟现实系统，通过语音命令实现，具有英语口音鲁棒性，通过深度学习模型和大型语言模型实现对文本的转换和执行。

    

    本文介绍了一种名为Hands-Free VR的基于语音的自然语言虚拟现实界面。用户可以通过语音发出命令，其语音音频数据经过一个针对单词音素相似性和英语口音的鲁棒性进行微调的语音识别深度学习模型转换为文本，然后利用一个对自然语言多样性具有鲁棒性的大型语言模型将文本映射为可执行的虚拟现实命令。Hands-Free VR在一个受控的被试研究中（N = 22）进行了评估，要求参与者找到特定物体并以各种配置放置它们。在对照条件下，参与者使用传统的虚拟现实用户界面通过手持控制器抓取、搬运和定位物体。在实验条件下，参与者使用Hands-Free VR。结果表明：（1）Hands-Free VR对英语口音具有鲁棒性，因为在我们的20名参与者中，英语不是他们的首选语言。

    arXiv:2402.15083v1 Announce Type: cross  Abstract: The paper introduces Hands-Free VR, a voice-based natural-language interface for VR. The user gives a command using their voice, the speech audio data is converted to text using a speech-to-text deep learning model that is fine-tuned for robustness to word phonetic similarity and to spoken English accents, and the text is mapped to an executable VR command using a large language model that is robust to natural language diversity. Hands-Free VR was evaluated in a controlled within-subjects study (N = 22) that asked participants to find specific objects and to place them in various configurations. In the control condition participants used a conventional VR user interface to grab, carry, and position the objects using the handheld controllers. In the experimental condition participants used Hands-Free VR. The results confirm that: (1) Hands-Free VR is robust to spoken English accents, as for 20 of our participants English was not their f
    
[^65]: 在混合贝叶斯网络模型中堆叠分解分区表达式

    Stacking Factorizing Partitioned Expressions in Hybrid Bayesian Network Models

    [https://arxiv.org/abs/2402.15075](https://arxiv.org/abs/2402.15075)

    提出了一种新算法叫做堆叠分解（SF），用于在混合贝叶斯网络模型中处理分区表达式，可以有效地减小复杂条件概率分布的大小。

    

    混合贝叶斯网络（HBN）包含以分区表达式指定的复杂条件概率分布（CPD），涉及离散和连续变量。在使用离散推断时，随着父节点数量的增加，这些CPD的大小呈指数级增长，导致效率显著降低。通常，减小CPD大小的有效方法是使用二元分解（BF）算法，通过将连接的父节点数因子化为大小为二的集合来分解CPD中的统计或算术函数。然而，BF算法并非为处理分区表达式而设计。因此，我们提出了一种名为堆叠分解（SF）的新算法，用于分解分区表达式。SF算法创建中间节点，逐步重建原始分区表达式中的密度，允许每个子节点连接的不超过两个连续父节点。

    arXiv:2402.15075v1 Announce Type: new  Abstract: Hybrid Bayesian networks (HBN) contain complex conditional probabilistic distributions (CPD) specified as partitioned expressions over discrete and continuous variables. The size of these CPDs grows exponentially with the number of parent nodes when using discrete inference, resulting in significant inefficiency. Normally, an effective way to reduce the CPD size is to use a binary factorization (BF) algorithm to decompose the statistical or arithmetic functions in the CPD by factorizing the number of connected parent nodes to sets of size two. However, the BF algorithm was not designed to handle partitioned expressions. Hence, we propose a new algorithm called stacking factorization (SF) to decompose the partitioned expressions. The SF algorithm creates intermediate nodes to incrementally reconstruct the densities in the original partitioned expression, allowing no more than two continuous parent nodes to be connected to each child node 
    
[^66]: 关于面向对话式网络代理的多轮指令跟踪

    On the Multi-turn Instruction Following for Conversational Web Agents

    [https://arxiv.org/abs/2402.15057](https://arxiv.org/abs/2402.15057)

    提出了一个新任务——对话式网络导航，引入了一个名为MT-Mind2Web的特殊数据集，并提出了一个名为Self-MAP的框架，旨在解决大型语言模型在多轮指令跟踪中的长度和上下文依赖性问题。

    

    由大型语言模型（LLMs）驱动的网络代理在规划和执行复杂基于网络的多步交互方面展示了出色的能力，完成了各种网络导航任务。然而，尽管取得了这些进展，以LLM为动力的代理在真实场景中有效与顺序用户指令进行交互的潜力尚未得到充分探索。本研究介绍了一个名为对话式网络导航的新任务，该任务需要与用户和环境进行跨多轮的复杂交互，支持使用一个名为多轮Mind2Web（MT-Mind2Web）的特别开发的数据集。为了解决LLMs的有限上下文长度和对话任务的上下文依赖性问题，我们进一步提出了一种名为自反映记忆增强规划（Self-MAP）的新框架，采用了记忆利用和自我反思技术。

    arXiv:2402.15057v1 Announce Type: cross  Abstract: Web agents powered by Large Language Models (LLMs) have demonstrated remarkable abilities in planning and executing multi-step interactions within complex web-based environments, fulfilling a wide range of web navigation tasks. Despite these advancements, the potential for LLM-powered agents to effectively engage with sequential user instructions in real-world scenarios has not been fully explored. In this work, we introduce a new task of Conversational Web Navigation, which necessitates sophisticated interactions that span multiple turns with both the users and the environment, supported by a specially developed dataset named Multi-Turn Mind2Web (MT-Mind2Web). To tackle the limited context length of LLMs and the context-dependency issue of the conversational tasks, we further propose a novel framework, named self-reflective memory-augmented planning (Self-MAP), which employs memory utilization and self-reflection techniques. Extensive
    
[^67]: 在Transformer中解释上下文查找：探究注意力-MLP交互

    Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions

    [https://arxiv.org/abs/2402.15055](https://arxiv.org/abs/2402.15055)

    该研究探究了Transformer中注意力头和MLP之间的相互作用，并揭示了特定上下文下激活特定token预测的机制，从而阐明在LLMs中注意力如何促成依赖上下文的专门化处理。

    

    在本文中，我们研究了注意力头和Multilayer Perceptron中专门预测特定token的"next-token"神经元之间的相互作用。通过促使像GPT-4这样的LLM解释这些模型内部，我们可以阐明激活某些next-token神经元的注意力机制。我们的分析确定了识别与预测特定token相关的上下文的attention heads，通过残差连接激活相关联的神经元。我们专注于在较早的层中始终激活相同next-token神经元的attention heads。探索这些不同的激活模式揭示了为不同语言上下文专门化的头与生成某些tokens相关联。总体而言，我们的方法结合了神经解释和探测孤立的组件，以阐明注意力如何使LLMs中的依赖上下文的专门处理成为可能。

    arXiv:2402.15055v1 Announce Type: cross  Abstract: In this paper, we investigate the interplay between attention heads and specialized "next-token" neurons in the Multilayer Perceptron that predict specific tokens. By prompting an LLM like GPT-4 to explain these model internals, we can elucidate attention mechanisms that activate certain next-token neurons. Our analysis identifies attention heads that recognize contexts relevant to predicting a particular token, activating the associated neuron through the residual connection. We focus specifically on heads in earlier layers consistently activating the same next-token neuron across similar prompts. Exploring these differential activation patterns reveals that heads that specialize for distinct linguistic contexts are tied to generating certain tokens. Overall, our method combines neural explanations and probing isolated components to illuminate how attention enables context-dependent, specialized processing in LLMs.
    
[^68]: 在大型语言模型中基准测试心灵理论

    ToMBench: Benchmarking Theory of Mind in Large Language Models

    [https://arxiv.org/abs/2402.15052](https://arxiv.org/abs/2402.15052)

    提出了ToMBench框架，在大型语言模型中进行心灵理论性能评估，发现最先进的模型仍然落后于人类表现超过10%。

    

    心灵理论（ToM）是指感知和归因自己以及他人的心理状态的认知能力。最近的研究引发了关于大型语言模型（LLMs）是否表现出一种形式的心灵理论的争论。然而，现有的心灵理论评估受到诸如受限范围、主观判断和意外污染等挑战的制约，导致评估不足。为了填补这一空白，我们引入了ToMBench，具有三个关键特征：系统评估框架涵盖社会认知中的8项任务和31项能力，多项选择题格式以支持自动化和无偏见的评估，以及基于双语清单的从头构建，严格避免数据泄漏。基于ToMBench，我们进行了大量实验，评估了10个流行LLMs在任务和能力方面的心灵理论表现。我们发现，即使像GPT-4这样的最先进的LLMs也比人类表现落后超过10个百分点。

    arXiv:2402.15052v1 Announce Type: cross  Abstract: Theory of Mind (ToM) is the cognitive capability to perceive and ascribe mental states to oneself and others. Recent research has sparked a debate over whether large language models (LLMs) exhibit a form of ToM. However, existing ToM evaluations are hindered by challenges such as constrained scope, subjective judgment, and unintended contamination, yielding inadequate assessments. To address this gap, we introduce ToMBench with three key characteristics: a systematic evaluation framework encompassing 8 tasks and 31 abilities in social cognition, a multiple-choice question format to support automated and unbiased evaluation, and a build-from-scratch bilingual inventory to strictly avoid data leakage. Based on ToMBench, we conduct extensive experiments to evaluate the ToM performance of 10 popular LLMs across tasks and abilities. We find that even the most advanced LLMs like GPT-4 lag behind human performance by over 10% points, indicati
    
[^69]: 发挥大型语言模型在实体对齐中的力量

    Unlocking the Power of Large Language Models for Entity Alignment

    [https://arxiv.org/abs/2402.15048](https://arxiv.org/abs/2402.15048)

    ChatEA是一个创新性框架，利用大型语言模型提高实体对齐准确性，通过引入KG-code翻译模块和两阶段EA策略来克服传统方法的局限性。

    

    实体对齐（EA）对于整合不同知识图（KG）数据至关重要，在数据驱动的人工智能应用中发挥着关键作用。传统的EA方法主要依赖于比较实体嵌入，但受限于有限的输入KG数据和表示学习技术的能力，它们的有效性受到约束。在这一背景下，我们介绍了ChatEA，这是一个创新性框架，它将大型语言模型（LLMs）融入以改善EA。为了解决有限的输入KG数据的限制，ChatEA引入了一个KG-code翻译模块，将KG结构翻译成LLMs可理解的格式，从而使LLMs能够利用其广泛的背景知识提高EA的准确性。为了克服对实体嵌入比较的过度依赖，ChatEA实现了一个两阶段EA策略，利用LLMs在对话格式中的多步推理能力，从而提高准确性。

    arXiv:2402.15048v1 Announce Type: cross  Abstract: Entity Alignment (EA) is vital for integrating diverse knowledge graph (KG) data, playing a crucial role in data-driven AI applications. Traditional EA methods primarily rely on comparing entity embeddings, but their effectiveness is constrained by the limited input KG data and the capabilities of the representation learning techniques. Against this backdrop, we introduce ChatEA, an innovative framework that incorporates large language models (LLMs) to improve EA. To address the constraints of limited input KG data, ChatEA introduces a KG-code translation module that translates KG structures into a format understandable by LLMs, thereby allowing LLMs to utilize their extensive background knowledge to improve EA accuracy. To overcome the over-reliance on entity embedding comparisons, ChatEA implements a two-stage EA strategy that capitalizes on LLMs' capability for multi-step reasoning in a dialogue format, thereby enhancing accuracy wh
    
[^70]: KIEval：面向大型语言模型的知识引导式交互评估框架

    KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large Language Models

    [https://arxiv.org/abs/2402.15043](https://arxiv.org/abs/2402.15043)

    该论文引入了KIEval，一种知识引导式交互评估框架，通过LLM-powered "interactor"角色实现动态的抗污染评估

    

    大型语言模型（LLMs）的自动评估方法受到数据污染的影响，导致对其有效性的评估被夸大。现有的策略旨在检测受污染的文本，但侧重于量化污染程度而非准确衡量模型性能。本文介绍了KIEval，这是一种知识引导式交互评估框架，首次引入了LLM驱动的“交互者”角色，实现了动态抗污染评估。从涉及特定领域知识的常规LLM基准问题开始，KIEval利用动态生成的、多轮、以知识为重点的对话，以确定模型的响应是否仅是基准答案的回忆，还是表明了深入理解并能在更复杂的对话中应用知识。在五个数据集上对七个领先的LLM进行了大量实验证实了KI

    arXiv:2402.15043v1 Announce Type: cross  Abstract: Automatic evaluation methods for large language models (LLMs) are hindered by data contamination, leading to inflated assessments of their effectiveness. Existing strategies, which aim to detect contaminated texts, focus on quantifying contamination status instead of accurately gauging model performance. In this paper, we introduce KIEval, a Knowledge-grounded Interactive Evaluation framework, which incorporates an LLM-powered "interactor" role for the first time to accomplish a dynamic contamination-resilient evaluation. Starting with a question in a conventional LLM benchmark involving domain-specific knowledge, KIEval utilizes dynamically generated, multi-round, and knowledge-focused dialogues to determine whether a model's response is merely a recall of benchmark answers or demonstrates a deep comprehension to apply knowledge in more complex conversations. Extensive experiments on seven leading LLMs across five datasets validate KI
    
[^71]: 动态引导扩散模型用于机器人 manipulator 设计

    Dynamics-Guided Diffusion Model for Robot Manipulator Design

    [https://arxiv.org/abs/2402.15038](https://arxiv.org/abs/2402.15038)

    该论文提出了动态引导扩散模型，利用共享的动力学网络为不同操作任务生成 manipulator 几何设计，通过设计目标构建的梯度引导手指几何设计的完善过程。

    

    我们提出了一个名为动态引导扩散模型的数据驱动框架，用于为给定操作任务生成 manipulator 几何设计。与为每个任务训练不同的设计模型不同，我们的方法采用一个跨任务共享的学习动力学网络。对于新的操作任务，我们首先将其分解为一组称为目标相互作用配置文件的个别运动目标，其中每个个别运动可以由共享的动力学网络建模。从目标和预测的相互作用配置文件构建的设计目标为任务的手指几何设计提供了梯度引导。这个设计过程被执行为一种分类器引导的扩散过程，其中设计目标作为分类器引导。我们在只使用开环平行夹爪运动的无传感器设置下，在各种操作任务上评估了我们的框架。

    arXiv:2402.15038v1 Announce Type: cross  Abstract: We present Dynamics-Guided Diffusion Model, a data-driven framework for generating manipulator geometry designs for a given manipulation task. Instead of training different design models for each task, our approach employs a learned dynamics network shared across tasks. For a new manipulation task, we first decompose it into a collection of individual motion targets which we call target interaction profile, where each individual motion can be modeled by the shared dynamics network. The design objective constructed from the target and predicted interaction profiles provides a gradient to guide the refinement of finger geometry for the task. This refinement process is executed as a classifier-guided diffusion process, where the design objective acts as the classifier guidance. We evaluate our framework on various manipulation tasks, under the sensor-less setting using only an open-loop parallel jaw motion. Our generated designs outperfor
    
[^72]: 多利益相关者视角下的负责任人工智能与教育可接受性研究

    Multi-stakeholder Perspective on Responsible Artificial Intelligence and Acceptability in Education

    [https://arxiv.org/abs/2402.15027](https://arxiv.org/abs/2402.15027)

    本研究从多利益相关者视角探讨了教育中不同人工智能应用的可接受性，关注数据隐私、AI代理、透明度、可解释性和道德部署等问题。

    

    本研究从多利益相关者的视角，包括学生、教师和家长，调查了教育中不同人工智能（AI）应用的可接受性。认识到人工智能在教育中的变革潜力，它关注了与数据隐私、AI代理、透明度、可解释性以及道德部署有关的问题。通过创景方法，参与者被呈现了四个场景，其中AI的代理、透明度、可解释性和隐私遭到操纵。在每个场景后，参与者完成了一个调查问卷，其中捕捉了他们对AI的全球效用、个人实用性、公正性、信心、风险以及若每个场景的AI可用话，他们打算使用的意图。数据收集涵盖了最终样本量为1198名多利益相关者参与者，通过一个合作机构和社交媒体活动分发，并重点关注了对四个场景的个体回应。

    arXiv:2402.15027v1 Announce Type: cross  Abstract: This study investigates the acceptability of different artificial intelligence (AI) applications in education from a multi-stakeholder perspective, including students, teachers, and parents. Acknowledging the transformative potential of AI in education, it addresses concerns related to data privacy, AI agency, transparency, explainability and the ethical deployment of AI. Through a vignette methodology, participants were presented with four scenarios where AI's agency, transparency, explainability, and privacy were manipulated. After each scenario, participants completed a survey that captured their perceptions of AI's global utility, individual usefulness, justice, confidence, risk, and intention to use each scenario's AI if available. The data collection comprising a final sample of 1198 multi-stakeholder participants was distributed through a partner institution and social media campaigns and focused on individual responses to four 
    
[^73]: 使用样式和内容信息的一致性引导温度缩放用于域外校准

    Consistency-Guided Temperature Scaling Using Style and Content Information for Out-of-Domain Calibration

    [https://arxiv.org/abs/2402.15019](https://arxiv.org/abs/2402.15019)

    提出了一种新的一致性引导温度缩放（CTS）策略，通过提供源域数据样本之间的相互监督，显著增强了域外（OOD）校准性能。

    

    近年来，关于深度神经网络对领域转移的鲁棒性越来越受到关注。然而，大多数现有研究都集中在提高模型的准确性上，而不是校准性能，而后者是值得信赖的AI系统的另一个重要要求。温度缩放（TS）作为一种可以保持准确性的事后校准方法，在领域内环境中已被证明是有效的，但在领域外（OOD）却不是，因为事先很难获取未见领域的验证集。在本文中，我们提出了一种新的温度缩放策略，一致性引导温度缩放（CTS），通过提供源域数据样本之间的相互监督，可以显著提高OOD校准性能。受到我们的观察到的发现，由于不一致的样本预测导致的过度自信是OOD校准的主要障碍，我们提出了一种新的校准策略。

    arXiv:2402.15019v1 Announce Type: cross  Abstract: Research interests in the robustness of deep neural networks against domain shifts have been rapidly increasing in recent years. Most existing works, however, focus on improving the accuracy of the model, not the calibration performance which is another important requirement for trustworthy AI systems. Temperature scaling (TS), an accuracy-preserving post-hoc calibration method, has been proven to be effective in in-domain settings, but not in out-of-domain (OOD) due to the difficulty in obtaining a validation set for the unseen domain beforehand. In this paper, we propose consistency-guided temperature scaling (CTS), a new temperature scaling strategy that can significantly enhance the OOD calibration performance by providing mutual supervision among data samples in the source domains. Motivated by our observation that over-confidence stemming from inconsistent sample predictions is the main obstacle to OOD calibration, we propose to 
    
[^74]: 通过多任务微调实现基础模型的少样本适应

    Towards Few-Shot Adaptation of Foundation Models via Multitask Finetuning

    [https://arxiv.org/abs/2402.15017](https://arxiv.org/abs/2402.15017)

    多任务微调的方法通过在基础模型上对相关任务进行微调，然后适应限制标签数的目标任务，能够降低目标任务中的误差，并提出了一种实用的任务选择算法。

    

    基础模型已经成为许多人工智能问题的有力工具。尽管基础模型取得了巨大成功，但有效地适应新任务，特别是那些数据标签有限的任务，仍然是一个开放问题，并且缺乏理论理解。最近在视觉和自然语言处理领域取得成功的一种新兴解决方案是，在基础模型上对一系列相关任务进行微调，然后再适应具有有限标记样本的目标任务。本文研究了这种多任务微调方法的理论验证。我们的理论分析表明，通过一个多样化的相关任务集，这种多任务微调可以降低目标任务中的误差，与直接适应相同预训练模型相比。我们通过多样性和一致性指标量化了微调任务和目标任务之间的关系，并进一步提出了一个实用的任务选择算法。

    arXiv:2402.15017v1 Announce Type: cross  Abstract: Foundation models have emerged as a powerful tool for many AI problems. Despite the tremendous success of foundation models, effective adaptation to new tasks, particularly those with limited labels, remains an open question and lacks theoretical understanding. An emerging solution with recent success in vision and NLP involves finetuning a foundation model on a selection of relevant tasks, before its adaptation to a target task with limited labeled samples. In this paper, we study the theoretical justification of this multitask finetuning approach. Our theoretical analysis reveals that with a diverse set of related tasks, this multitask finetuning leads to reduced error in the target task, in comparison to directly adapting the same pretrained model. We quantify the relationship between finetuning tasks and target tasks by diversity and consistency metrics, and further propose a practical task selection algorithm. We substantiate our 
    
[^75]: Ar-Spider：阿拉伯语中的文本转SQL

    Ar-Spider: Text-to-SQL in Arabic

    [https://arxiv.org/abs/2402.15012](https://arxiv.org/abs/2402.15012)

    本文介绍了Ar-Spider，这是第一个阿拉伯跨领域文本到SQL数据集，为解决阿拉伯语言的独特性质所带来的模式语言和SQL结构挑战，引入了两个基线模型并测试了两个跨语言模型，取得了不错的性能。

    

    在自然语言处理（NLP）中，文本到SQL语义解析是最重要的任务之一，它旨在使用户以更自然的方式与数据库进行交互。近年来，文本到SQL已取得重大进展，但大多数是以英语为中心的。本文介绍了第一个阿拉伯跨领域文本到SQL数据集Ar-Spider。由于该语言的独特性质，我们遇到了两个主要挑战，即模式语言和SQL 结构挑战。为了处理这些问题并进行实验，我们采用了两个基线模型LGESQL和S2SQL，两者均与两个跨语言模型进行了测试，以减轻模式语言和SQL结构链接挑战的影响。基线模型在我们的阿拉伯文本到SQL数据集Ar-Spider上表现出不错的单语言性能，其中S2SQL实现了62.48%，LGESQL实现了65.57%，仅低于8.79%。

    arXiv:2402.15012v1 Announce Type: cross  Abstract: In Natural Language Processing (NLP), one of the most important tasks is text-to-SQL semantic parsing, which focuses on enabling users to interact with the database in a more natural manner. In recent years, text-to-SQL has made significant progress, but most were English-centric. In this paper, we introduce Ar-Spider 1, the first Arabic cross-domain text-to-SQL dataset. Due to the unique nature of the language, two major challenges have been encountered, namely schema linguistic and SQL structural challenges. In order to handle these issues and conduct the experiments, we adopt two baseline models LGESQL [4] and S2SQL [12], both of which are tested with two cross-lingual models to alleviate the effects of schema linguistic and SQL structure linking challenges. The baselines demonstrate decent single-language performance on our Arabic text-to-SQL dataset, Ar-Spider, achieving 62.48% for S2SQL and 65.57% for LGESQL, only 8.79% below the
    
[^76]: 一种对话式脑-人工智能界面

    A Conversational Brain-Artificial Intelligence Interface

    [https://arxiv.org/abs/2402.15011](https://arxiv.org/abs/2402.15011)

    BAIs利用人工智能代替神经-认知处理管线的部分，让认知功能受损的个体能够通过高层意图完成复杂任务，例如通过主观提供意图完成模拟电话对话。

    

    我们将脑-人工智能界面（BAIs）作为一种新的脑-计算机界面（BCIs）类别引入。不同于依赖完好认知功能的传统BCIs，BAIs利用人工智能的力量来替代神经-认知处理管线的部分。BAIs允许用户通过提供高层意图来完成复杂任务，而经过预训练的AI代理确定低层次细节。该方法将BCIs的目标受众扩大到认知功能受损的个体，这是常常被排除在传统BCIs好处之外的人群。我们提出了BAIs的一般概念，并通过基于脑电图的对话式BAI展示了这种新方法的潜力。特别是，我们在模拟电话对话的实验中展示了对话式BAI能够实现复杂通信，而无需生成语言。因此，我们的工作首次证明了，对于第一次，

    arXiv:2402.15011v1 Announce Type: cross  Abstract: We introduce Brain-Artificial Intelligence Interfaces (BAIs) as a new class of Brain-Computer Interfaces (BCIs). Unlike conventional BCIs, which rely on intact cognitive capabilities, BAIs leverage the power of artificial intelligence to replace parts of the neuro-cognitive processing pipeline. BAIs allow users to accomplish complex tasks by providing high-level intentions, while a pre-trained AI agent determines low-level details. This approach enlarges the target audience of BCIs to individuals with cognitive impairments, a population often excluded from the benefits of conventional BCIs. We present the general concept of BAIs and illustrate the potential of this new approach with a Conversational BAI based on EEG. In particular, we show in an experiment with simulated phone conversations that the Conversational BAI enables complex communication without the need to generate language. Our work thus demonstrates, for the first time, th
    
[^77]: 法语医用口罩语言模型中的标记化有多重要？

    How Important Is Tokenization in French Medical Masked Language Models?

    [https://arxiv.org/abs/2402.15010](https://arxiv.org/abs/2402.15010)

    子词标记化成为自然语言处理领域的主流标准，但其成功因素，如不同任务和语言的最佳分割粒度、数据源对标记工具的影响以及形态信息在印欧语言中的作用，仍不明确。

    

    近年来，基于子词的标记化已成为自然语言处理（NLP）领域中的主流标准，主要是由于预训练语言模型的广泛应用。然而，导致其成功的确切因素，如不同任务和语言的最佳分割粒度，数据源对标记工具的影响以及形态信息在印欧语言中的作用，仍然不够清楚。这在生物医学术语方面尤为重要，其特点是具有管理形态素组合的特定规则。

    arXiv:2402.15010v1 Announce Type: cross  Abstract: Subword tokenization has become the prevailing standard in the field of natural language processing (NLP) over recent years, primarily due to the widespread utilization of pre-trained language models. This shift began with Byte-Pair Encoding (BPE) and was later followed by the adoption of SentencePiece and WordPiece. While subword tokenization consistently outperforms character and word-level tokenization, the precise factors contributing to its success remain unclear. Key aspects such as the optimal segmentation granularity for diverse tasks and languages, the influence of data sources on tokenizers, and the role of morphological information in Indo-European languages remain insufficiently explored. This is particularly pertinent for biomedical terminology, characterized by specific rules governing morpheme combinations. Despite the agglutinative nature of biomedical terminology, existing language models do not explicitly incorporate 
    
[^78]: 小型基准测试：用更少的示例评估LLM

    tinyBenchmarks: evaluating LLMs with fewer examples

    [https://arxiv.org/abs/2402.14992](https://arxiv.org/abs/2402.14992)

    本文研究了减少评估LLMs性能所需的评估次数的策略，并展示了在小规模示例上可以准确估计LLMs在多种基准测试上的性能。

    

    大型语言模型（LLMs）的多功能性导致创建了多种基准测试，彻底测试各种语言模型的能力。这些基准测试包含成千上万个示例，使得评估LLMs非常昂贵。本文研究了减少评估LLMs性能所需的评估次数的策略。例如，我们展示了要准确估计LLMs在MMLU上的性能（一个包含14K个示例的流行多选问答基准测试），只需要在100个精心挑选的示例上评估这个LLMs。我们发布了评估工具和流行基准测试的微型版本：Open LLM Leaderboard、MMLU、HELM和AlpacaEval 2.0。我们的实证分析表明，这些工具和微型基准测试足以可靠且高效地重现原始评估结果。

    arXiv:2402.14992v1 Announce Type: cross  Abstract: The versatility of large language models (LLMs) led to the creation of diverse benchmarks that thoroughly test a variety of language models' abilities. These benchmarks consist of tens of thousands of examples making evaluation of LLMs very expensive. In this paper, we investigate strategies to reduce the number of evaluations needed to assess the performance of an LLM on several key benchmarks. For example, we show that to accurately estimate the performance of an LLM on MMLU, a popular multiple-choice QA benchmark consisting of 14K examples, it is sufficient to evaluate this LLM on 100 curated examples. We release evaluation tools and tiny versions of popular benchmarks: Open LLM Leaderboard, MMLU, HELM, and AlpacaEval 2.0. Our empirical analysis demonstrates that these tools and tiny benchmarks are sufficient to reliably and efficiently reproduce the original evaluation results.
    
[^79]: 分析不规则时间序列数据中的稳定神经随机微分方程

    Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data

    [https://arxiv.org/abs/2402.14989](https://arxiv.org/abs/2402.14989)

    神经常微分方程（Neural ODEs）的扩展——神经随机微分方程（Neural SDEs）在处理不规则时间序列数据中的稳定性和性能方面提出了重要指导，需要谨慎设计漂移和扩散函数以保持稳定性。

    

    实际时间序列数据中的不规则采样间隔和缺失值对于假设一致间隔和完整数据的传统方法构成挑战。神经常微分方程（Neural ODEs）提供了一种替代方法，利用神经网络与常微分方程求解器结合，通过参数化向量场学习连续潜在表示。神经随机微分方程（Neural SDEs）通过引入扩散项扩展了神经常微分方程，然而在处理不规则间隔和缺失值时，这种添加并不是微不足道的。因此，仔细设计漂移和扩散函数对于保持稳定性和增强性能至关重要，而粗心的选择可能导致出现没有强解、随机破坏或不稳定的Euler离散化等不利的性质，显著影响神经随机微分方程的性能。

    arXiv:2402.14989v1 Announce Type: cross  Abstract: Irregular sampling intervals and missing values in real-world time series data present challenges for conventional methods that assume consistent intervals and complete data. Neural Ordinary Differential Equations (Neural ODEs) offer an alternative approach, utilizing neural networks combined with ODE solvers to learn continuous latent representations through parameterized vector fields. Neural Stochastic Differential Equations (Neural SDEs) extend Neural ODEs by incorporating a diffusion term, although this addition is not trivial, particularly when addressing irregular intervals and missing values. Consequently, careful design of drift and diffusion functions is crucial for maintaining stability and enhancing performance, while incautious choices can result in adverse properties such as the absence of strong solutions, stochastic destabilization, or unstable Euler discretizations, significantly affecting Neural SDEs' performance. In 
    
[^80]: AI增强的头脑写作：探讨LLMs在团体构思中的应用

    AI-Augmented Brainwriting: Investigating the use of LLMs in group ideation

    [https://arxiv.org/abs/2402.14978](https://arxiv.org/abs/2402.14978)

    本文探讨了在团体构思中将LLMs整合到创意过程中的两个方面，并发现将LLMs整合到Brainwriting中可以增强构思过程及其结果，并提供了支持想法评估的证据。

    

    随着生成式人工智能技术（如大型语言模型LLMs）日益普及，对创意工作有着重要的影响。本文探讨了将LLMs整合到创意过程中的两个方面 - 创意生成的分歧阶段以及评估和选择想法的收敛阶段。我们设计了一个协作的团体-AI头脑写作构思框架，将LLM作为一个增强因素融入到团体构思过程中，并评估了创意生成过程和结果解空间。为评估在想法评估过程中使用LLMs的潜力，我们设计了一个评估引擎，并将其与三名专家和六名新手评估者分配的想法评级进行了比较。我们的发现表明，将LLMs整合到头脑写作中可以增强构思过程及其结果。我们还提供了LLMs可以支持想法评估的证据。最后，我们讨论了相关的启示。

    arXiv:2402.14978v1 Announce Type: cross  Abstract: The growing availability of generative AI technologies such as large language models (LLMs) has significant implications for creative work. This paper explores twofold aspects of integrating LLMs into the creative process - the divergence stage of idea generation, and the convergence stage of evaluation and selection of ideas. We devised a collaborative group-AI Brainwriting ideation framework, which incorporated an LLM as an enhancement into the group ideation process, and evaluated the idea generation process and the resulted solution space. To assess the potential of using LLMs in the idea evaluation process, we design an evaluation engine and compared it to idea ratings assigned by three expert and six novice evaluators. Our findings suggest that integrating LLM in Brainwriting could enhance both the ideation process and its outcome. We also provide evidence that LLMs can support idea evaluation. We conclude by discussing implicati
    
[^81]: 在深度基础潜空间内的无监督领域自适应

    Unsupervised Domain Adaptation within Deep Foundation Latent Spaces

    [https://arxiv.org/abs/2402.14976](https://arxiv.org/abs/2402.14976)

    提出了一种在深度基础潜空间内进行无监督领域自适应的方法，通过分析和定性解释，展示了该方法可以优于现有基线，并显示了尚未解决的局限性。

    

    基于Vision Transformer的基础模型，如ViT或Dino-V2，旨在解决无需或很少微调特征的问题。通过一组原型网络的设置，我们分析了这种基础模型在无需在源域或目标域进行微调情况下，能够解决无监督领域自适应的程度。通过定量分析以及对决策过程的定性解释，我们证明了建议方法可以改进现有基线，并展示了这种方法的局限性有待解决。

    arXiv:2402.14976v1 Announce Type: cross  Abstract: The vision transformer-based foundation models, such as ViT or Dino-V2, are aimed at solving problems with little or no finetuning of features. Using a setting of prototypical networks, we analyse to what extent such foundation models can solve unsupervised domain adaptation without finetuning over the source or target domain. Through quantitative analysis, as well as qualitative interpretations of decision making, we demonstrate that the suggested method can improve upon existing baselines, as well as showcase the limitations of such approach yet to be solved.
    
[^82]: 在非欧几里得空间中实现空间透明的AI分类：MxIF肿瘤数据应用

    Towards Spatially-Lucid AI Classification in Non-Euclidean Space: An Application for MxIF Oncology Data

    [https://arxiv.org/abs/2402.14974](https://arxiv.org/abs/2402.14974)

    发展了一个使用空间集合框架的分类器，可以根据点的排列在非欧几里得空间中区分两个类别，对于肿瘤学等应用具有重要意义

    

    针对来自不同地点类型的多类别点集，我们的目标是开发一个空间透明的分类器，可以根据点的排列区分两个类别。这个问题对于许多应用非常重要，比如肿瘤学，用于分析免疫-肿瘤关系和设计新的免疫治疗方法。这个问题具有挑战性，因为需要考虑空间变化和可解释性需求。以前提出的技术要求密集的训练数据，或者在处理单个地点类型内的显著空间变异性方面能力有限。最重要的是，这些深度神经网络（DNN）方法没有设计用于在非欧几里得空间中工作，特别是点集。现有的非欧几里得DNN方法局限于一刀切的方法。我们探索了一种空间集合框架，明确使用不同的训练策略，包括加权距离学习率和空间域自适应。

    arXiv:2402.14974v1 Announce Type: cross  Abstract: Given multi-category point sets from different place-types, our goal is to develop a spatially-lucid classifier that can distinguish between two classes based on the arrangements of their points. This problem is important for many applications, such as oncology, for analyzing immune-tumor relationships and designing new immunotherapies. It is challenging due to spatial variability and interpretability needs. Previously proposed techniques require dense training data or have limited ability to handle significant spatial variability within a single place-type. Most importantly, these deep neural network (DNN) approaches are not designed to work in non-Euclidean space, particularly point sets. Existing non-Euclidean DNN methods are limited to one-size-fits-all approaches. We explore a spatial ensemble framework that explicitly uses different training strategies, including weighted-distance learning rate and spatial domain adaptation, on v
    
[^83]: GenCeption：使用未标记的单模态数据评估多模态LLM

    GenCeption: Evaluate Multimodal LLMs with Unlabeled Unimodal Data

    [https://arxiv.org/abs/2402.14973](https://arxiv.org/abs/2402.14973)

    提出了一种名为GenCeption的新型MLLM评估框架，可以仅利用单模态数据评估跨模态语义一致性，并有效反映模型产生幻觉的倾向，具有较强的相关性和潜力于流行的MLLM基准结果。

    

    多模态大型语言模型（MLLMs）通常使用昂贵的带标注的多模态基准进行评估。然而，这些基准通常难以跟上MLLM评估的快速发展要求。我们提出了GenCeption，这是一个新颖的无需注释的MLLM评估框架，仅需要单模态数据来评估跨模态语义一致性，并反映出模型产生幻觉的倾向。类似于流行的DrawCeption游戏，GenCeption从一个非文本样本开始，并经历一系列迭代的描述和生成步骤。迭代之间的语义漂移使用GC@T指标进行量化。我们的实证发现验证了GenCeption的有效性，并显示出与流行的MLLM基准结果的强相关性。GenCeption可以通过利用普遍存在且以前未见的单模态数据来扩展，以减轻训练数据的污染。

    arXiv:2402.14973v1 Announce Type: cross  Abstract: Multimodal Large Language Models (MLLMs) are commonly evaluated using costly annotated multimodal benchmarks. However, these benchmarks often struggle to keep pace with the rapidly advancing requirements of MLLM evaluation. We propose GenCeption, a novel and annotation-free MLLM evaluation framework that merely requires unimodal data to assess inter-modality semantic coherence and inversely reflects the models' inclination to hallucinate. Analogous to the popular DrawCeption game, GenCeption initiates with a non-textual sample and undergoes a series of iterative description and generation steps. Semantic drift across iterations is quantified using the GC@T metric. Our empirical findings validate GenCeption's efficacy, showing strong correlations with popular MLLM benchmarking results. GenCeption may be extended to mitigate training data contamination by utilizing ubiquitous, previously unseen unimodal data.
    
[^84]: MultiLS: 一个多任务词汇简化框架

    MultiLS: A Multi-task Lexical Simplification Framework

    [https://arxiv.org/abs/2402.14972](https://arxiv.org/abs/2402.14972)

    MultiLS是第一个允许创建多任务LS数据集的框架，提出了MultiLS-PT作为第一个使用该框架创建的数据集，展示了其在词汇简化相关任务中的潜力。

    

    词汇简化（LS）自动替换难以理解的单词为更易读的替代词，同时保留句子的原始含义。LS是文本简化的前身，旨在改善文本对各种目标人群的可访问性，包括儿童、第二语言学习者、阅读障碍或低识字率的人群。存在一些专门用于LS的数据集，这些数据集专注于LS流程中的一个或两个子任务。然而，目前尚未开发出一个覆盖所有LS子任务的单个LS数据集。我们提出了MultiLS，这是第一个允许创建多任务LS数据集的LS框架。我们还提出了MultiLS-PT，这是第一个使用MultiLS框架创建的数据集。我们通过执行所有LS子任务，包括（1）词汇复杂性预测（LCP）、（2）替代词生成和（3）替代词排名，展示了MultiLS-PT的潜力。

    arXiv:2402.14972v1 Announce Type: cross  Abstract: Lexical Simplification (LS) automatically replaces difficult to read words for easier alternatives while preserving a sentence's original meaning. LS is a precursor to Text Simplification with the aim of improving text accessibility to various target demographics, including children, second language learners, individuals with reading disabilities or low literacy. Several datasets exist for LS. These LS datasets specialize on one or two sub-tasks within the LS pipeline. However, as of this moment, no single LS dataset has been developed that covers all LS sub-tasks. We present MultiLS, the first LS framework that allows for the creation of a multi-task LS dataset. We also present MultiLS-PT, the first dataset to be created using the MultiLS framework. We demonstrate the potential of MultiLS-PT by carrying out all LS sub-tasks of (1). lexical complexity prediction (LCP), (2). substitute generation, and (3). substitute ranking for Portugu
    
[^85]: 镜像：一种适用于知识丰富推理的多视角自我反思方法

    Mirror: A Multiple-perspective Self-Reflection Method for Knowledge-rich Reasoning

    [https://arxiv.org/abs/2402.14963](https://arxiv.org/abs/2402.14963)

    Mirror 提出了一种多视角自我反思方法，通过导航者和推理者之间的启发式交互，促进多样性而具有可靠性的推理轨迹发展，解决了大型语言模型在处理知识丰富问题上的困难。

    

    虽然大型语言模型（LLMs）有能力反复反思自己的输出，但最近的研究观察到它们在没有外部资源的情况下处理知识丰富问题时存在困难。除了LLMs在自我评估方面的低效率外，我们还观察到尽管受到明确负面反馈，LLMs仍然难以重新审视其预测。因此，我们提出了Mirror，一种适用于知识丰富推理的多角度自我反思方法，以避免在特定反思迭代中卡住。Mirror使LLMs能够通过导航者和推理者之间的启发式交互获得多视角线索的反思，引导代理向多样性而具有可靠性的推理轨迹发展，而无需访问地面真相，通过鼓励（1）导航者生成的方向的多样性与（2）策略性引发的扰动在产生的回应中的一致性。

    arXiv:2402.14963v1 Announce Type: cross  Abstract: While Large language models (LLMs) have the capability to iteratively reflect on their own outputs, recent studies have observed their struggles with knowledge-rich problems without access to external resources. In addition to the inefficiency of LLMs in self-assessment, we also observe that LLMs struggle to revisit their predictions despite receiving explicit negative feedback. Therefore, We propose Mirror, a Multiple-perspective self-reflection method for knowledge-rich reasoning, to avoid getting stuck at a particular reflection iteration. Mirror enables LLMs to reflect from multiple-perspective clues, achieved through a heuristic interaction between a Navigator and a Reasoner. It guides agents toward diverse yet plausibly reliable reasoning trajectory without access to ground truth by encouraging (1) diversity of directions generated by Navigator and (2) agreement among strategically induced perturbations in responses generated by 
    
[^86]: 基于2D物体边界框的路径规划

    Path Planning based on 2D Object Bounding-box

    [https://arxiv.org/abs/2402.14933](https://arxiv.org/abs/2402.14933)

    提出了一种利用2D物体边界框进行路径规划的方法，通过融合高清地图数据和周围摄像头拍摄的图像，在城市驾驶场景中实现了路径规划。

    

    自主驾驶技术在城市环境中的实施面临着重大挑战，需要发展先进的感知系统和运动规划算法来管理复杂情况。本研究提出了一种利用城市驾驶场景中通过模拟学习开发的2D物体边界框的路径规划方法，通过将高清地图数据与周围摄像头拍摄的图像相结合。接下来的感知任务涉及边界框检测和跟踪，规划部分...

    arXiv:2402.14933v1 Announce Type: cross  Abstract: The implementation of Autonomous Driving (AD) technologies within urban environments presents significant challenges. These challenges necessitate the development of advanced perception systems and motion planning algorithms capable of managing situations of considerable complexity. Although the end-to-end AD method utilizing LiDAR sensors has achieved significant success in this scenario, we argue that its drawbacks may hinder its practical application. Instead, we propose the vision-centric AD as a promising alternative offering a streamlined model without compromising performance. In this study, we present a path planning method that utilizes 2D bounding boxes of objects, developed through imitation learning in urban driving scenarios. This is achieved by integrating high-definition (HD) map data with images captured by surrounding cameras. Subsequent perception tasks involve bounding-box detection and tracking, while the planning p
    
[^87]: 在没有访问敏感群体的情况下实现联邦公平性

    Federated Fairness without Access to Sensitive Groups

    [https://arxiv.org/abs/2402.14929](https://arxiv.org/abs/2402.14929)

    提出了一种不依赖于预定义敏感群体定义或额外标签的方法，通过一个超参数实现公平性和效用之间的权衡，保证任何足够大的人群子集能获得至少最低效用性能。

    

    当前联邦学习中关于群体公平性的方法都假设在训练期间存在预定义和标记的敏感群体。然而，由于从新兴法规到受保护群体的动态和位置依赖性等多种因素，这一假设在许多实际情况下可能不合适。在这项工作中，我们提出了一种新的方法来保证群体公平性，不依赖于任何预定义的敏感群体的定义或额外的标签。我们的目标允许联邦学习学习一个帕累托有效的全局模型，确保最坏情况下的群体公平性，并且通过一个超参数，实现公平性和效用之间的权衡，仅受到群体大小约束。这意味着任何足够大的人群子集都保证能从模型中获得至少的最低效用性能。所提出的目标涵盖了现有方法作为特殊案例，

    arXiv:2402.14929v1 Announce Type: cross  Abstract: Current approaches to group fairness in federated learning assume the existence of predefined and labeled sensitive groups during training. However, due to factors ranging from emerging regulations to dynamics and location-dependency of protected groups, this assumption may be unsuitable in many real-world scenarios. In this work, we propose a new approach to guarantee group fairness that does not rely on any predefined definition of sensitive groups or additional labels. Our objective allows the federation to learn a Pareto efficient global model ensuring worst-case group fairness and it enables, via a single hyper-parameter, trade-offs between fairness and utility, subject only to a group size constraint. This implies that any sufficiently large subset of the population is guaranteed to receive at least a minimum level of utility performance from the model. The proposed objective encompasses existing approaches as special cases, such
    
[^88]: 学习逆运动学以实现自动车漂移

    Learning Inverse Kinodynamics for Autonomous Vehicle Drifting

    [https://arxiv.org/abs/2402.14928](https://arxiv.org/abs/2402.14928)

    通过数据驱动的方法学习小型自动车的运动学模型，特别是为了实现高速圆形导航和自主漂移，帮助车辆学习世界状态并避开障碍物。

    

    在这项工作中，我们探索了一种基于数据驱动的学习方法，用于学习小型自动车的运动学模型，并观察其对运动规划特别是自主漂移的影响。在现实世界中执行运动规划时，存在许多导致错误的原因，计划的内容通常与实际汽车上执行的内容不同。基于惯性测量和执行命令学习动力学规划器可以帮助我们学习世界状态。在我们的情况下，我们将目光转向漂移领域；漂移是一种复杂的演练，需要足够平滑的表面、足够高的速度和速度的急剧变化。我们尝试学习这些漂移演练的动力学模型，并尝试减小车辆的侧滑。我们的方法能够学习高速圆形航行的运动学模型，并能够通过校正自主高速漂移上的障碍物来避免障碍物。

    arXiv:2402.14928v1 Announce Type: cross  Abstract: In this work, we explore a data-driven learning-based approach to learning the kinodynamic model of a small autonomous vehicle, and observe the effect it has on motion planning, specifically autonomous drifting. When executing a motion plan in the real world, there are numerous causes for error, and what is planned is often not what is executed on the actual car. Learning a kinodynamic planner based off of inertial measurements and executed commands can help us learn the world state. In our case, we look towards the realm of drifting; it is a complex maneuver that requires a smooth enough surface, high enough speed, and a drastic change in velocity. We attempt to learn the kinodynamic model for these drifting maneuvers, and attempt to tighten the slip of the car. Our approach is able to learn a kinodynamic model for high-speed circular navigation, and is able to avoid obstacles on an autonomous drift at high speed by correcting an exec
    
[^89]: 针对预训练模型的知识蒸馏的实践见解

    Practical Insights into Knowledge Distillation for Pre-Trained Models

    [https://arxiv.org/abs/2402.14922](https://arxiv.org/abs/2402.14922)

    研究对知识蒸馏在预训练模型中的应用进行了深入比较，包括优化的温度和权重参数的调整，以及数据分区KD，揭示了最有效的知识蒸馏策略。

    

    这项研究探讨了在预训练模型中对知识蒸馏（KD）过程的增强，这是知识传输中一个新兴领域，并对分布式训练和联邦学习环境产生重要影响。尽管采用了许多知识蒸馏方法来在预训练模型之间传递知识，但在这些场景中了解知识蒸馏的应用仍然缺乏全面的理解。我们的研究对多种知识蒸馏技术进行了广泛比较，包括标准KD、经过优化温度和权重参数调整的KD、深度相互学习以及数据分区KD。我们评估这些方法在不同数据分布策略下的表现，以确定每种方法最有效的情境。通过详细研究超参数调整，结合广泛的网格搜索评估来获取信息

    arXiv:2402.14922v1 Announce Type: cross  Abstract: This research investigates the enhancement of knowledge distillation (KD) processes in pre-trained models, an emerging field in knowledge transfer with significant implications for distributed training and federated learning environments. These environments benefit from reduced communication demands and accommodate various model architectures. Despite the adoption of numerous KD approaches for transferring knowledge among pre-trained models, a comprehensive understanding of KD's application in these scenarios is lacking. Our study conducts an extensive comparison of multiple KD techniques, including standard KD, tuned KD (via optimized temperature and weight parameters), deep mutual learning, and data partitioning KD. We assess these methods across various data distribution strategies to identify the most effective contexts for each. Through detailed examination of hyperparameter tuning, informed by extensive grid search evaluations, w
    
[^90]: MobileLLM：优化亚十亿参数语言模型以用于设备端应用

    MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases

    [https://arxiv.org/abs/2402.14905](https://arxiv.org/abs/2402.14905)

    MobileLLM通过优化模型架构，采用深度和瘦身结构、嵌入共享和分组查询注意机制，实现了2.7%/4.3%的准确率提升，并提出了一种无需增加模型大小且仅有极小延迟开销的块状权重共享方法

    

    本文解决了移动设备上高效的大型语言模型(LLMs)的迫切需求问题，这是由于云成本和延迟问题不断增加所导致的。我们专注于设计具有不到十亿参数的顶级LLMs，这是移动部署的实际选择。与普遍的观点相反，强调数据和参数数量在确定模型质量方面的关键作用，我们的研究强调了亚十亿规模LLMs的模型架构的重要性。利用深度和瘦身结构，再加上嵌入共享和分组查询注意机制，我们建立了一个强大的基准网络，称为MobileLLM，其在将近125M/350M先进模型上分别获得了惊人的2.7%/4.3%的准确率提升。此外，我们提出了一种立即的块状权重共享方法，不增加模型大小，且仅具有极小的延迟开销。由此产生的模型被命名为MobileLLM-L

    arXiv:2402.14905v1 Announce Type: cross  Abstract: This paper addresses the growing need for efficient large language models (LLMs) on mobile devices, driven by increasing cloud costs and latency concerns. We focus on designing top-quality LLMs with fewer than a billion parameters, a practical choice for mobile deployment. Contrary to prevailing belief emphasizing the pivotal role of data and parameter quantity in determining model quality, our investigation underscores the significance of model architecture for sub-billion scale LLMs. Leveraging deep and thin architectures, coupled with embedding sharing and grouped-query attention mechanisms, we establish a strong baseline network denoted as MobileLLM, which attains a remarkable 2.7%/4.3% accuracy boost over preceding 125M/350M state-of-the-art models. Additionally, we propose an immediate block-wise weight sharing approach with no increase in model size and only marginal latency overhead. The resultant models, denoted as MobileLLM-L
    
[^91]: 数字水印使语言模型具有放射性

    Watermarking Makes Language Models Radioactive

    [https://arxiv.org/abs/2402.14904](https://arxiv.org/abs/2402.14904)

    本文研究了LLM生成文本的放射性，表明使用数字水印训练数据能更容易检测到，同时也展示了即使只有很少比例的水印训练文本，仍可以高置信度地检测出使用数字水印进行微调的情况。

    

    本文研究了LLM生成的文本的放射性，即是否可以检测到这种输入被用作训练数据。传统方法如成员推断可以以一定水平的准确性进行这种检测。我们表明，带有数字水印的训练数据留下的痕迹比成员推断更容易检测且更可靠。我们将污染水平与水印的鲁棒性、在训练集中的比例和微调过程联系起来。特别是我们展示，即使只有5％的训练文本被数字水印标记，训练在带有数字水印的合成指令上仍然可以具有高置信度（p值<1e-5）被检测到。因此，原本设计用于检测机器生成文本的LLM水印技术，使我们能够轻松确定带有数字水印的LLM的输出是否被用来对另一个LLM进行微调。

    arXiv:2402.14904v1 Announce Type: cross  Abstract: This paper investigates the radioactivity of LLM-generated texts, i.e. whether it is possible to detect that such input was used as training data. Conventional methods like membership inference can carry out this detection with some level of accuracy. We show that watermarked training data leaves traces easier to detect and much more reliable than membership inference. We link the contamination level to the watermark robustness, its proportion in the training set, and the fine-tuning process. We notably demonstrate that training on watermarked synthetic instructions can be detected with high confidence (p-value < 1e-5) even when as little as 5% of training text is watermarked. Thus, LLM watermarking, originally designed for detecting machine-generated text, gives the ability to easily identify if the outputs of a watermarked LLM were used to fine-tune another LLM.
    
[^92]: 电子商务中意图理解的使用中心视角

    A Usage-centric Take on Intent Understanding in E-Commerce

    [https://arxiv.org/abs/2402.14901](https://arxiv.org/abs/2402.14901)

    该论文提出了电子商务中意图理解的一个新视角，不依赖于产品本体，通过引入产品恢复基准验证了当前意图知识图的弱点。

    

    识别和理解用户意图是电子商务中至关重要的任务。尽管意图理解很受欢迎，但其定义并不一致，且缺乏准确的基准。本文关注将用户意图定义为"顾客如何使用产品"的预测性用户意图，并将意图理解视为一项自然语言推理任务，独立于产品本体。我们发现了FolkScope的两个弱点，这是目前最先进的电子商务意图知识图，限制了其推理用户意图和推荐多样有用产品的能力。基于这些观察，我们引入了一个产品恢复基准，包括一个新颖的评估框架和一个示例数据集。我们在这个基准上进一步验证了上述FolkScope的弱点。

    arXiv:2402.14901v1 Announce Type: cross  Abstract: Identifying and understanding user intents is a pivotal task for E-Commerce. Despite its popularity, intent understanding has not been consistently defined or accurately benchmarked. In this paper, we focus on predicative user intents as "how a customer uses a product", and pose intent understanding as a natural language reasoning task, independent of product ontologies. We identify two weaknesses of FolkScope, the SOTA E-Commerce Intent Knowledge Graph, that limit its capacity to reason about user intents and to recommend diverse useful products. Following these observations, we introduce a Product Recovery Benchmark including a novel evaluation framework and an example dataset. We further validate the above FolkScope weaknesses on this benchmark.
    
[^93]: 停止推理！当多模态LLMs与串联推理遇到对抗性图像

    Stop Reasoning! When Multimodal LLMs with Chain-of-Thought Reasoning Meets Adversarial Images

    [https://arxiv.org/abs/2402.14899](https://arxiv.org/abs/2402.14899)

    该研究评估了多模态LLMs在采用串联推理时的对抗鲁棒性，发现串联推理在一定程度上提高了对抗性鲁棒性，但引入了一种新的停止推理攻击技术成功规避了这种增强。

    

    最近，多模态LLMs（MLLMs）展示了很强的理解图像的能力。然而，像传统视觉模型一样，它们仍然容易受到对抗性图像的攻击。与此同时，串联推理（CoT）已经被广泛应用在MLLMs上，不仅提高了模型的性能，而且通过提供中间推理步骤来增强模型的可解释性。然而，目前还缺乏关于MLLMs在CoT下的对抗鲁棒性的研究，以及在MLLMs用对抗性图像推断错误答案时推理的合理性。我们的研究评估了采用CoT推理时MLLMs的对抗鲁棒性，发现CoT在一定程度上提高了对抗性鲁棒性，抵抗了已有的攻击方法。此外，我们引入了一种新的停止推理攻击技术，可以有效地规避CoT引起的鲁棒性增强。最后，我们展示了CoT推理的变化。

    arXiv:2402.14899v1 Announce Type: cross  Abstract: Recently, Multimodal LLMs (MLLMs) have shown a great ability to understand images. However, like traditional vision models, they are still vulnerable to adversarial images. Meanwhile, Chain-of-Thought (CoT) reasoning has been widely explored on MLLMs, which not only improves model's performance, but also enhances model's explainability by giving intermediate reasoning steps. Nevertheless, there is still a lack of study regarding MLLMs' adversarial robustness with CoT and an understanding of what the rationale looks like when MLLMs infer wrong answers with adversarial images. Our research evaluates the adversarial robustness of MLLMs when employing CoT reasoning, finding that CoT marginally improves adversarial robustness against existing attack methods. Moreover, we introduce a novel stop-reasoning attack technique that effectively bypasses the CoT-induced robustness enhancements. Finally, we demonstrate the alterations in CoT reasonin
    
[^94]: Chain-of-Thought不忠诚作为伪装的准确性

    Chain-of-Thought Unfaithfulness as Disguised Accuracy

    [https://arxiv.org/abs/2402.14897](https://arxiv.org/abs/2402.14897)

    了解Chain-of-Thought生成与大语言模型内部计算的一致程度对于决定是否信任模型输出至关重要，研究发现模型大小与忠实度之间存在着特定关系，并且发现130亿参数模型表现出更高的忠实度。

    

    了解Chain-of-Thought (CoT)生成与大语言模型(LLM)内部计算的一致程度对于决定是否信任LLM的输出至关重要。作为CoT忠实度的代理，arXiv:2307.13702提出了一个度量模型依赖其CoT生成答案的指标。在一个专有模型系列中，他们发现LLM表现出模型大小与其忠实度测量之间的缩放-反向缩放关系，并且130亿参数模型相比于尺寸介于8.1亿到1750亿参数之间的模型表现出增加的忠实度。我们评估这些结果是否作为所有LLM的特性泛化。我们使用三种不同系列的模型复制他们的实验设置，并在特定条件下，成功复制了他们报告的CoT忠实度的缩放趋势。然而，我们发现简单的改变设定会导致这些模式在多大程度上重复。

    arXiv:2402.14897v1 Announce Type: cross  Abstract: Understanding the extent to which Chain-of-Thought (CoT) generations align with a large language model's (LLM) internal computations is critical for deciding whether to trust an LLM's output. As a proxy for CoT faithfulness, arXiv:2307.13702 propose a metric that measures a model's dependence on its CoT for producing an answer. Within a single family of proprietary models, they find that LLMs exhibit a scaling-then-inverse-scaling relationship between model size and their measure of faithfulness, and that a 13 billion parameter model exhibits increased faithfulness compared to models ranging from 810 million to 175 billion parameters in size. We evaluate whether these results generalize as a property of all LLMs. We replicate their experimental setup with three different families of models and, under specific conditions, successfully reproduce the scaling trends for CoT faithfulness they report. However, we discover that simply changin
    
[^95]: 数据增强已死，数据增强万岁

    Data Augmentation is Dead, Long Live Data Augmentation

    [https://arxiv.org/abs/2402.14895](https://arxiv.org/abs/2402.14895)

    数据增强不过是更好地微调模型，零唁态和少样本数据生成可提高性能

    

    文本数据增强（DA）是一个繁荣的研究领域，不断提出新颖的技术来创建人工数据，已经在小数据环境中表现出很高的效率，至少对于文本分类任务而言。在本文中，我们质疑这些结果，表明经典的数据增强只是一种更好地进行微调的方式，并且在应用数据增强之前花更多时间进行微调会抵消其效果。这是一个重要的贡献，因为它回答了最近几年留下的几个问题，即：哪种DA技术表现最佳（只要它们生成的数据与训练集足够接近，不会损害训练），为什么DA表现出积极的结果（简化网络训练）。此外，我们还展示了通过对话代理（如ChatGPT或LLama2）零唁态和少样本数据生成可以提高性能，从而得出了结论，此法可以提高模型性能。

    arXiv:2402.14895v1 Announce Type: cross  Abstract: Textual data augmentation (DA) is a prolific field of study where novel techniques to create artificial data are regularly proposed, and that has demonstrated great efficiency on small data settings, at least for text classification tasks. In this paper, we challenge those results, showing that classical data augmentation is simply a way of performing better fine-tuning, and that spending more time fine-tuning before applying data augmentation negates its effect. This is a significant contribution as it answers several questions that were left open in recent years, namely~: which DA technique performs best (all of them as long as they generate data close enough to the training set as to not impair training) and why did DA show positive results (facilitates training of network). We furthermore show that zero and few-shot data generation via conversational agents such as ChatGPT or LLama2 can increase performances, concluding that this f
    
[^96]: 基于数据驱动的配电网分布式发电接地故障定位方法

    Data-Driven Ground-Fault Location Method in Distribution Power System With Distributed Generation

    [https://arxiv.org/abs/2402.14894](https://arxiv.org/abs/2402.14894)

    提出了一种基于数据驱动的接地故障定位方法，通过离散小波变换和人工神经网络分析处理数据，实现了对配电系统中故障的准确预测

    

    最近可再生能源在配电级别的增加引入了多方向功率流，使得过时的传统故障定位技术难以适用。为此，需要开发新的方法以确保快速准确的故障定位，从而增强电力系统可靠性。本文提出了一种针对配电系统的基于数据驱动的接地故障定位方法。在Matlab/Simulink中建模了一个11节点 20 kV的电力系统，用于模拟接地故障。在不同位置和不同系统运行状态下产生了故障。然后，使用离散小波变换分析系统变电站的时域故障三相电压。最终利用处理后的数据的统计量训练人工神经网络(ANN)来找到计算电压特征和故障之间的映射。具体而言，三个ANNs可以预测故障

    arXiv:2402.14894v1 Announce Type: cross  Abstract: The recent increase in renewable energy penetration at the distribution level introduces a multi-directional power flow that outdated traditional fault location techniques. To this extent, the development of new methods is needed to ensure fast and accurate fault localization and, hence, strengthen power system reliability. This paper proposes a data-driven ground fault location method for the power distribution system. An 11-bus 20 kV power system is modeled in Matlab/Simulink to simulate ground faults. The faults are generated at different locations and under various system operational states. Time-domain faulted three-phase voltages at the system substation are then analyzed with discrete wavelet transform. Statistical quantities of the processed data are eventually used to train an Artificial Neural Network (ANN) to find a mapping between computed voltage features and faults. Specifically, three ANNs allow the prediction of faulted
    
[^97]: LLMBind: 一种统一的模态任务集成框架

    LLMBind: A Unified Modality-Task Integration Framework

    [https://arxiv.org/abs/2402.14891](https://arxiv.org/abs/2402.14891)

    提出了LLMBind，一种统一的模态任务集成框架，通过将大型语言模型和预训练任务模型绑定在一起，实现了多种模态任务的灵活输入和输出组合。

    

    最近对于多模态大型语言模型在处理各种模态任务方面取得了进展，但它们对于复杂的多模态任务的集成能力有限，从而限制了该领域的发展。在这项工作中，我们带头探索并提出了LLMBind，一种用于模态任务集成的统一框架，该框架将大型语言模型和相应的预训练任务模型与任务特定的标记绑定在一起。因此，LLMBind可以以多种图像、文本、视频和音频的组合解释输入并生成输出。具体来说，我们引入了一种专家混合技术，通过不同专家之间的协作实现不同多模态任务的有效学习。此外，我们创建了一个包含40万条指令数据的多任务数据集，解锁了交互式视觉生成和编辑任务的能力。大量实验证明了我们的方法的有效性。

    arXiv:2402.14891v1 Announce Type: cross  Abstract: While recent progress in multimodal large language models tackles various modality tasks, they posses limited integration capabilities for complex multi-modality tasks, consequently constraining the development of the field. In this work, we take the initiative to explore and propose the LLMBind, a unified framework for modality task integration, which binds Large Language Models and corresponding pre-trained task models with task-specific tokens. Consequently, LLMBind can interpret inputs and produce outputs in versatile combinations of image, text, video, and audio. Specifically, we introduce a Mixture-of-Experts technique to enable effective learning for different multimodal tasks through collaboration among diverse experts. Furthermore, we create a multi-task dataset comprising 400k instruction data, which unlocks the ability for interactive visual generation and editing tasks. Extensive experiments show the effectiveness of our fr
    
[^98]: Vygotsky Distance: 用于基准任务相似性的度量方法

    Vygotsky Distance: Measure for Benchmark Task Similarity

    [https://arxiv.org/abs/2402.14890](https://arxiv.org/abs/2402.14890)

    论文提出了一种基于相对性能而非任务属性的相似性度量方法，即“维果茨基距离”，可帮助减少评估任务数量并保持高验证质量。

    

    论文介绍了一种理论工具和实践算法来计算基准任务之间的相似性，称之为"维果茨基距离"。这种相似性度量的核心思想是基于“学生”在给定任务上的相对表现，而不是基于任务本身的属性。如果两个任务在维果茨基距离上彼此接近，模型在这些任务上 tend to have similar relative performance。因此，通过了解任务之间的维果茨基距离，可以显著减少评估任务数量，同时保持高验证质量。

    arXiv:2402.14890v1 Announce Type: cross  Abstract: Evaluation plays a significant role in modern natural language processing. Most modern NLP benchmarks consist of arbitrary sets of tasks that neither guarantee any generalization potential for the model once applied outside the test set nor try to minimize the resource consumption needed for model evaluation. This paper presents a theoretical instrument and a practical algorithm to calculate similarity between benchmark tasks, we call this similarity measure "Vygotsky distance". The core idea of this similarity measure is that it is based on relative performance of the "students" on a given task, rather that on the properties of the task itself. If two tasks are close to each other in terms of Vygotsky distance the models tend to have similar relative performance on them. Thus knowing Vygotsky distance between tasks one can significantly reduce the number of evaluation tasks while maintaining a high validation quality. Experiments on v
    
[^99]: COBIAS：偏见评估中的情境可靠性

    COBIAS: Contextual Reliability in Bias Assessment

    [https://arxiv.org/abs/2402.14889](https://arxiv.org/abs/2402.14889)

    我们提出了COBIAS，旨在通过考虑多样情境的用户输入内容，衡量语句的情境可靠性，从而培养偏见意识。

    

    大型语言模型（LLMs）是基于固有偏见数据训练的。以往的去偏见模型研究依赖基准数据集来衡量模型性能。然而，这些数据集由于对偏见的极其主观理解而存在多个缺陷，凸显出对情境探索的迫切需求。我们提出考虑输入用户内容的情境，考虑到输入语句可能存在的多种情况。这种方法将允许培养偏见意识的框架，而不是伤害用户参与的防护设施。我们的贡献有两个方面：(i) 我们创建了一个包含2287个陈词滥调语句以及添加情境要点的数据集；(ii) 我们开发了面向情境的偏见指标和评估分数（COBIAS）来评估语句在衡量偏见方面的情境可靠性。我们的度量是衡量偏见基准数据集情境可靠性的重要预测因子。

    arXiv:2402.14889v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are trained on inherently biased data. Previous works on debiasing models rely on benchmark datasets to measure model performance. However, these datasets suffer from several pitfalls due to the extremely subjective understanding of bias, highlighting a critical need for contextual exploration. We propose understanding the context of user inputs with consideration of the diverse situations in which input statements are possible. This approach would allow for frameworks that foster bias awareness rather than guardrails that hurt user engagement. Our contribution is twofold: (i) we create a dataset of 2287 stereotyped statements augmented with points for adding context; (ii) we develop the Context-Oriented Bias Indicator and Assessment Score (COBIAS) to assess statements' contextual reliability in measuring bias. Our metric is a significant predictor of the contextual reliability of bias-benchmark datasets ($
    
[^100]: 利用基于语义相似性的图结构进行高效数据选择用于模型训练

    Efficient data selection employing Semantic Similarity-based Graph Structures for model training

    [https://arxiv.org/abs/2402.14888](https://arxiv.org/abs/2402.14888)

    提出了一种基于语义相似性的图结构的高效数据选择机制，可在不经过计算密集型模型或其他密集的预处理转换的情况下，用于模型训练。

    

    自然语言处理（NLP）领域的最新发展凸显了模型准确捕捉文本信息所需大量数据的必要性。这引发了关于训练此类模型所需的计算资源和时间的担忧。本文介绍了一种称为“SeSaME”的数据选择机制，它仅基于文本信息进行高效的数据采样，无需通过计算密集型模型或其他密集的预处理转换。

    arXiv:2402.14888v1 Announce Type: cross  Abstract: Recent developments in natural language processing (NLP) have highlighted the need for substantial amounts of data for models to capture textual information accurately. This raises concerns regarding the computational resources and time required for training such models. This paper introduces Semantics for data SAliency in Model performance Estimation (SeSaME). It is an efficient data sampling mechanism solely based on textual information without passing the data through a compute-heavy model or other intensive pre-processing transformations. The application of this approach is demonstrated in the use case of low-resource automated speech recognition (ASR) models, which excessively rely on text-to-speech (TTS) calls when using augmented data. SeSaME learns to categorize new incoming data points into speech recognition difficulty buckets by employing semantic similarity-based graph structures and discrete ASR information from homophilou
    
[^101]: 将强化学习应用于优化交通信号灯循环

    Applying Reinforcement Learning to Optimize Traffic Light Cycles

    [https://arxiv.org/abs/2402.14886](https://arxiv.org/abs/2402.14886)

    提出了将强化学习应用于交通信号灯循环优化，实验证明能显著减少紧急停车次数，降低交通拥堵，改善交通流。

    

    交通信号灯循环的手动优化是一项复杂且耗时的任务，需要开发自动化解决方案。本文提出了将强化学习应用于实时优化交通信号灯循环。我们通过使用模拟城市移动模拟器进行案例研究，训练了一个深度Q网络算法。实验结果显示平均紧急停车次数减少了44.16%，显示了我们方法减少交通拥堵、改善交通流的潜力。此外，我们还讨论了未来研究的途径和对强化学习模型的改进。

    arXiv:2402.14886v1 Announce Type: cross  Abstract: Manual optimization of traffic light cycles is a complex and time-consuming task, necessitating the development of automated solutions. In this paper, we propose the application of reinforcement learning to optimize traffic light cycles in real-time. We present a case study using the Simulation Urban Mobility simulator to train a Deep Q-Network algorithm. The experimental results showed 44.16% decrease in the average number of Emergency stops, showing the potential of our approach to reduce traffic congestion and improve traffic flow. Furthermore, we discuss avenues for future research and enhancements to the reinforcement learning model.
    
[^102]: 双I水印：保护LLM微调模型版权

    Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning

    [https://arxiv.org/abs/2402.14883](https://arxiv.org/abs/2402.14883)

    提出了一种名为“双I水印”的水印方法，通过引入两种backdoor数据范例并利用LLM的学习能力，有效地保护了LLM微调定制模型的版权。

    

    为了支持各种应用，业主经常通过LLM所有者或云服务器提供的API对预训练的LLM进行微调，以获取定制模型。然而，这一过程存在着模型被滥用的风险，可能会给业主带来严重的经济后果。因此，在LLM微调过程中保护这些定制模型的版权已成为紧迫的实际需求，但现有的解决方案有限。为了解决这一紧迫问题，我们提出了一种名为“双I水印”的新型水印方法。具体地，基于指导微调数据，引入了两种backdoor数据范例，分别在指令和输入中触发。通过利用LLM的学习能力将定制的后门样本纳入数据集，所提出的方法有效地注入了特定的水印。

    arXiv:2402.14883v1 Announce Type: cross  Abstract: To support various applications, business owners often seek the customized models that are obtained by fine-tuning a pre-trained LLM through the API provided by LLM owners or cloud servers. However, this process carries a substantial risk of model misuse, potentially resulting in severe economic consequences for business owners. Thus, safeguarding the copyright of these customized models during LLM fine-tuning has become an urgent practical requirement, but there are limited existing solutions to provide such protection. To tackle this pressing issue, we propose a novel watermarking approach named "Double-I watermark". Specifically, based on the instruct-tuning data, two types of backdoor data paradigms are introduced with trigger in the instruction and the input, respectively. By leveraging LLM's learning capability to incorporate customized backdoor samples into the dataset, the proposed approach effectively injects specific watermar
    
[^103]: 基于深度生成模型的满足目标条件的四连杆机构合成

    Deep Generative Model-based Synthesis of Four-bar Linkage Mechanisms with Target Conditions

    [https://arxiv.org/abs/2402.14882](https://arxiv.org/abs/2402.14882)

    提出了基于深度生成模型的方法，利用条件生成对抗网络生成满足运动学和准静态要求的多连杆四连杆机构。

    

    机构是各种机械系统中设计用于执行特定任务的关键组件。然而，设计满足特定运动学或准静态要求的机构是一项具有挑战性的任务。本文提出了基于深度学习的生成模型，用于生成满足运动学和准静态要求的多连杆四连杆机构。所提出的模型基于有条件生成对抗网络(cGAN)，并经过针对机构合成的修改，其训练目的是学习机构的要求与连杆长度之间的关系。结果表明，该方法可以成功合成满足要求的四连杆机构。

    arXiv:2402.14882v1 Announce Type: cross  Abstract: Mechanisms are essential components designed to perform specific tasks in various mechanical systems. However, designing a mechanism that satisfies certain kinematic or quasi-static requirements is a challenging task. The kinematic requirements may include the workspace of a mechanism, while the quasi-static requirements of a mechanism may include its torque transmission, which refers to the ability of the mechanism to transfer power and torque effectively. In this paper, we propose a deep learning-based generative model for generating multiple crank-rocker four-bar linkage mechanisms that satisfy both the kinematic and quasi-static requirements aforementioned. The proposed model is based on a conditional generative adversarial network (cGAN) with modifications for mechanism synthesis, which is trained to learn the relationship between the requirements of a mechanism with respect to linkage lengths. The results demonstrate that the pro
    
[^104]: 对抗基于ChatGPT作弊的测试题漏洞研究

    A Study on the Vulnerability of Test Questions against ChatGPT-based Cheating

    [https://arxiv.org/abs/2402.14881](https://arxiv.org/abs/2402.14881)

    研究揭示了基于ChatGPT的作弊对测试题的漏洞，并开发了一个工具来辨别测试题中对ChatGPT最容易回答错误的类型。

    

    ChatGPT是一种聊天机器人，可以相当准确地回答文本提示，甚至在研究生级别的问题上表现出色。许多教育工作者发现他们的课业或远程测试和考试容易受到基于ChatGPT的作弊的影响，因为学生可能直接使用ChatGPT等工具提供的答案。在本文中，我们试图回答一个重要问题：ChatGPT能多好回答测试题，以及我们如何检测测试题是否能被ChatGPT正确回答。我们生成了ChatGPT对MedMCQA数据集的响应，该数据集包含超过10,000个医学院入学考试问题。我们分析了这些回答，并揭示了ChatGPT在某些问题上的回答比其他问题更不准确。此外，我们创建了一个基本的自然语言处理模型，可以在一组问题或样本考试中筛选出对ChatGPT最易受攻击的问题。我们的工具可以被使用。

    arXiv:2402.14881v1 Announce Type: cross  Abstract: ChatGPT is a chatbot that can answer text prompts fairly accurately, even performing very well on postgraduate-level questions. Many educators have found that their take-home or remote tests and exams are vulnerable to ChatGPT-based cheating because students may directly use answers provided by tools like ChatGPT. In this paper, we try to provide an answer to an important question: how well ChatGPT can answer test questions and how we can detect whether the questions of a test can be answered correctly by ChatGPT. We generated ChatGPT's responses to the MedMCQA dataset, which contains over 10,000 medical school entrance exam questions. We analyzed the responses and uncovered certain types of questions ChatGPT answers more inaccurately than others. In addition, we have created a basic natural language processing model to single out the most vulnerable questions to ChatGPT in a collection of questions or a sample exam. Our tool can be us
    
[^105]: 自动直方图：利用语言模型进行文本数据集探索

    Automatic Histograms: Leveraging Language Models for Text Dataset Exploration

    [https://arxiv.org/abs/2402.14880](https://arxiv.org/abs/2402.14880)

    该论文提出了一种利用语言模型的自动直方图可视化工具AutoHistograms，能够自动识别相关特征、以直方图形式展示并允许用户交互式地查询数据集，帮助数据工作者快速探索文本数据集。

    

    理解非结构化文本数据集一直是困难的，但随着大型语言模型的出现变得越来越重要。数据工作人员常常依赖于数据集摘要，特别是各种派生特征的分布。一些特征，如毒性或主题，对许多数据集都有影响，但许多有趣的特征是特定于领域的：音乐数据集的乐器和流派，或医学数据集的疾病和症状。因此，数据工作者经常为每个数据集运行自定义分析，这既繁琐又困难。我们提出了AutoHistograms，这是一个利用LLM的可视化工具。AutoHistograms自动识别相关特征，用直方图形式展示它们，并允许用户交互式地查询数据集的实体类别并创建新的直方图。在与10名数据工作者（n=10）进行的用户研究中，我们发现参与者可以快速利用AutoHistograms识别见解并探索数据。

    arXiv:2402.14880v1 Announce Type: cross  Abstract: Making sense of unstructured text datasets is perennially difficult, yet increasingly relevant with Large Language Models. Data workers often rely on dataset summaries, especially distributions of various derived features. Some features, like toxicity or topics, are relevant to many datasets, but many interesting features are domain specific: instruments and genres for a music dataset, or diseases and symptoms for a medical dataset. Accordingly, data workers often run custom analyses for each dataset, which is cumbersome and difficult. We present AutoHistograms, a visualization tool leveragingLLMs. AutoHistograms automatically identifies relevant features, visualizes them with histograms, and allows the user to interactively query the dataset for categories of entities and create new histograms. In a user study with 10 data workers (n=10), we observe that participants can quickly identify insights and explore the data using AutoHistogr
    
[^106]: 以人格驱动生成式智能体

    Driving Generative Agents With Their Personality

    [https://arxiv.org/abs/2402.14879](https://arxiv.org/abs/2402.14879)

    大型语言模型（LLMs）利用心理测量值，在视频游戏角色开发中代表给定的人格特征，增强游戏角色的类人特性。

    

    本研究探讨了大型语言模型（LLMs）利用心理测量值，特别是人格信息，在视频游戏角色开发背景下的潜力。情感计算（AC）系统量化了非玩家角色（NPC）的心理，LLM可以利用该系统的信息，使用值进行提示生成。研究表明，LLM可以始终代表给定的人格特征，从而增强游戏角色的类人特性。将人类检查重新用于评估LLM的国际人格项目池（IPIP）问卷表明，该模型能够准确生成与所提供人格相关的内容。结果显示，LLM的改进，如最新的GPT-4模型，可以始终利用和解释人格以代表行为。

    arXiv:2402.14879v1 Announce Type: cross  Abstract: This research explores the potential of Large Language Models (LLMs) to utilize psychometric values, specifically personality information, within the context of video game character development. Affective Computing (AC) systems quantify a Non-Player character's (NPC) psyche, and an LLM can take advantage of the system's information by using the values for prompt generation. The research shows an LLM can consistently represent a given personality profile, thereby enhancing the human-like characteristics of game characters. Repurposing a human examination, the International Personality Item Pool (IPIP) questionnaire, to evaluate an LLM shows that the model can accurately generate content concerning the personality provided. Results show that the improvement of LLM, such as the latest GPT-4 model, can consistently utilize and interpret a personality to represent behavior.
    
[^107]: 使用内存中学习的方法训练AI系统的能效限制

    Energy-efficiency Limits on Training AI Systems using Learning-in-Memory

    [https://arxiv.org/abs/2402.14878](https://arxiv.org/abs/2402.14878)

    该论文提出了使用内存中学习的方法训练AI系统时的能效限制，并推导了新的理论下限。

    

    arXiv:2402.14878v1 公告类型: cross 摘要: 内存中学习（LIM）是一种最近提出的范Paradigm，旨在克服训练机器学习系统中的基本内存瓶颈。虽然计算于内存（CIM）方法可以解决所谓的内存墙问题（即由于重复内存读取访问而消耗的能量），但它们对于以训练所需的精度重复内存写入时消耗的能量（更新墙）是不可知的，并且它们不考虑在短期和长期记忆之间传输信息时所消耗的能量（整合墙）。LIM范式提出，如果物理内存的能量屏障被自适应调制，使得存储器更新和整合的动态与梯度下降训练AI模型的Lyapunov动态相匹配，那么这些瓶颈也可以被克服。在本文中，我们推导了使用不同LIM应用程序训练AI系统时的能耗的新理论下限。

    arXiv:2402.14878v1 Announce Type: cross  Abstract: Learning-in-memory (LIM) is a recently proposed paradigm to overcome fundamental memory bottlenecks in training machine learning systems. While compute-in-memory (CIM) approaches can address the so-called memory-wall (i.e. energy dissipated due to repeated memory read access) they are agnostic to the energy dissipated due to repeated memory writes at the precision required for training (the update-wall), and they don't account for the energy dissipated when transferring information between short-term and long-term memories (the consolidation-wall). The LIM paradigm proposes that these bottlenecks, too, can be overcome if the energy barrier of physical memories is adaptively modulated such that the dynamics of memory updates and consolidation match the Lyapunov dynamics of gradient-descent training of an AI model. In this paper, we derive new theoretical lower bounds on energy dissipation when training AI systems using different LIM app
    
[^108]: 名字的含义是什么？审计大型语言模型中的种族和性别偏见

    What's in a Name? Auditing Large Language Models for Race and Gender Bias

    [https://arxiv.org/abs/2402.14875](https://arxiv.org/abs/2402.14875)

    调查发现，大型语言模型存在种族和性别偏见，尤其对与黑人女性相关的名字表现最不利。审计在模型部署和实施时的重要性得到强调。

    

    我们采用审计设计来调查最先进的大型语言模型中的偏见，包括GPT-4。在我们的研究中，我们引发模型在各种情景下为个人提供建议，比如在购车谈判或选举结果预测过程中。我们发现该建议系统性地对与种族少数群体和女性常见相关的名字产生不利影响。与黑人女性相关的名字得到的结果最不利。这些偏见在42个提示模板和多个模型中都是一致的，表明这是一个系统性问题，而不是孤立事件。在提示中提供数值、与决策相关的锚点可以成功抵消偏见，而定性细节的影响并不一致，甚至可能会加剧差异。我们的研究结果强调了在语言模型部署和实施时进行审计的重要性，以减轻其潜在影响。

    arXiv:2402.14875v1 Announce Type: cross  Abstract: We employ an audit design to investigate biases in state-of-the-art large language models, including GPT-4. In our study, we elicit prompt the models for advice regarding an individual across a variety of scenarios, such as during car purchase negotiations or election outcome predictions. We find that the advice systematically disadvantages names that are commonly associated with racial minorities and women. Names associated with Black women receive the least advantageous outcomes. The biases are consistent across 42 prompt templates and several models, indicating a systemic issue rather than isolated incidents. While providing numerical, decision-relevant anchors in the prompt can successfully counteract the biases, qualitative details have inconsistent effects and may even increase disparities. Our findings underscore the importance of conducting audits at the point of LLM deployment and implementation to mitigate their potential for
    
[^109]: 蒸馏对比解码：利用对比解码和蒸馏提升LLM的推理能力

    Distillation Contrastive Decoding: Improving LLMs Reasoning with Contrastive Decoding and Distillation

    [https://arxiv.org/abs/2402.14874](https://arxiv.org/abs/2402.14874)

    该研究提出了一种叫做蒸馏对比解码（DCD）的方法，通过结合对比提示与蒸馏技术，有效提升了大型语言模型（LLM）在推理任务上的性能表现，超过了传统的对比解码方法，并在多个基准数据集上取得了显著成果。

    

    我们提出了一种称为蒸馏对比解码（DCD）的简单方法，以增强大型语言模型（LLMs）在推理过程中的推理能力。与先前依赖于较小的业余模型或隐藏状态差异分析的方法不同，DCD采用了对比式思维引导和先进的蒸馏技术，包括Dropout和量化。这种方法有效地解决了对比解码（CD）的局限性，后者通常需要专家和业余模型，从而增加计算资源需求。通过将对比提示与蒸馏相结合，DCD消除了对业余模型的需求并减少了内存使用。我们的评估表明，DCD显著增强了LLM在各种推理基准测试中的性能，在GSM8K和StrategyQA数据集中均超过了CD和现有方法。

    arXiv:2402.14874v1 Announce Type: cross  Abstract: We propose a straightforward approach called Distillation Contrastive Decoding (DCD) to enhance the reasoning capabilities of Large Language Models (LLMs) during inference. In contrast to previous approaches that relied on smaller amateur models or analysis of hidden state differences, DCD employs Contrastive Chain-of-thought Prompting and advanced distillation techniques, including Dropout and Quantization. This approach effectively addresses the limitations of Contrastive Decoding (CD), which typically requires both an expert and an amateur model, thus increasing computational resource demands. By integrating contrastive prompts with distillation, DCD obviates the need for an amateur model and reduces memory usage. Our evaluations demonstrate that DCD significantly enhances LLM performance across a range of reasoning benchmarks, surpassing both CD and existing methods in the GSM8K and StrategyQA datasets.
    
[^110]: Checkfor.ai AI生成文本分类器技术报告

    Technical Report on the Checkfor.ai AI-Generated Text Classifier

    [https://arxiv.org/abs/2402.14873](https://arxiv.org/abs/2402.14873)

    Checkfor.ai AI生成文本分类器在区分大型语言模型生成文本和人类编写文本方面表现优异，提出了硬负挖掘与合成镜像训练算法，具有高准确性和泛化能力。

    

    我们提出了Checkfor.ai文本分类器，这是一个基于Transformer的神经网络，经过训练可以区分由大型语言模型编写的文本和由人类编写的文本。Checkfor.ai在由十种文本领域（学生写作、创意写作、科学写作、书籍、百科全书、新闻、电子邮件、科学论文、简答问答）和8个开源闭源大型语言模型组成的综合基准测试中，表现优于零冲击方法如DetectGPT以及主流商业AI检测工具，误差率降低了9倍以上。我们提出了一种训练算法，即硬负挖掘与合成镜像，使我们的分类器能够在评论等高数据领域实现几个数量级的更低误报率。最后，我们展示了Checkfor.ai不对非母语英语人士产生偏见，并推广到训练过程中未见的领域和模型。

    arXiv:2402.14873v1 Announce Type: cross  Abstract: We present the Checkfor.ai text classifier, a transformer-based neural network trained to distinguish text written by large language models from text written by humans. Checkfor.ai outperforms zero-shot methods such as DetectGPT as well as leading commercial AI detection tools with over 9 times lower error rates on a comprehensive benchmark comprised of ten text domains (student writing, creative writing, scientific writing, books, encyclopedias, news, email, scientific papers, short-form Q\&A) and 8 open- and closed-source large language models. We propose a training algorithm, hard negative mining with synthetic mirrors, that enables our classifier to achieve orders of magnitude lower false positive rates on high-data domains such as reviews. Finally, we show that Checkfor.ai is not biased against nonnative English speakers and generalizes to domains and models unseen during training.
    
[^111]: 语义镜像越狱:基于遗传算法的针对开源LLM的越狱提示

    Semantic Mirror Jailbreak: Genetic Algorithm Based Jailbreak Prompts Against Open-source LLMs

    [https://arxiv.org/abs/2402.14872](https://arxiv.org/abs/2402.14872)

    本文提出了一种语义镜像越狱（SMJ）方法，通过生成在语义上类似于原始问题的越狱提示来绕过LLMs。

    

    大型语言模型（LLMs）通常用于创意写作、代码生成和翻译，根据输入序列生成文本，但容易受到越狱攻击的影响，其中精心设计的提示会导致有害输出。大多数越狱提示方法使用一组越狱模板，然后跟随提出问题，创建越狱提示。然而，现有的越狱提示设计通常存在过多的语义差异，导致无法抵御使用简单语义度量作为阈值的防御。越狱提示在语义上比用于查询的原始问题更加多样化。在本文中，我们介绍了一种称为语义镜像越狱（SMJ）的方法，通过生成在语义上类似于原始问题的越狱提示来绕过LLMs。我们将寻找既满足语义相似性又具有越狱有效性的越狱提示建模为一个多目标优化问题。

    arXiv:2402.14872v1 Announce Type: cross  Abstract: Large Language Models (LLMs), used in creative writing, code generation, and translation, generate text based on input sequences but are vulnerable to jailbreak attacks, where crafted prompts induce harmful outputs. Most jailbreak prompt methods use a combination of jailbreak templates followed by questions to ask to create jailbreak prompts. However, existing jailbreak prompt designs generally suffer from excessive semantic differences, resulting in an inability to resist defenses that use simple semantic metrics as thresholds. Jailbreak prompts are semantically more varied than the original questions used for queries. In this paper, we introduce a Semantic Mirror Jailbreak (SMJ) approach that bypasses LLMs by generating jailbreak prompts that are semantically similar to the original question. We model the search for jailbreak prompts that satisfy both semantic similarity and jailbreak validity as a multi-objective optimization proble
    
[^112]: 基于LLM的多Agent生成公共行政领域语义模板中的半结构文档

    LLM Based Multi-Agent Generation of Semi-structured Documents from Semantic Templates in the Public Administration Domain

    [https://arxiv.org/abs/2402.14871](https://arxiv.org/abs/2402.14871)

    该论文创新之处在于将LLMs与提示工程和多Agent系统相结合，以生成符合特定结构的新文档。

    

    在过去几年的数字化过程中，各个领域，特别是公共行政领域中文档的创建和管理变得越来越复杂和多样化。半结构文档需要处理一系列特定数据但没有固定格式，因此不能使用基于模板的解决方案。本文提出了一种新方法，将LLMs与提示工程和多Agent系统相结合，生成符合期望结构的新文档。

    arXiv:2402.14871v1 Announce Type: cross  Abstract: In the last years' digitalization process, the creation and management of documents in various domains, particularly in Public Administration (PA), have become increasingly complex and diverse. This complexity arises from the need to handle a wide range of document types, often characterized by semi-structured forms. Semi-structured documents present a fixed set of data without a fixed format. As a consequence, a template-based solution cannot be used, as understanding a document requires the extraction of the data structure. The recent introduction of Large Language Models (LLMs) has enabled the creation of customized text output satisfying user requests. In this work, we propose a novel approach that combines the LLMs with prompt engineering and multi-agent systems for generating new documents compliant with a desired structure. The main contribution of this work concerns replacing the commonly used manual prompting with a task descr
    
[^113]: 使用和不使用停用词对阿拉伯文本分类的加权方法的影响

    Effects of term weighting approach with and without stop words removing on Arabic text classification

    [https://arxiv.org/abs/2402.14867](https://arxiv.org/abs/2402.14867)

    本研究比较不同的加权特征方法（二元和词频加权）在文本分类中使用和不使用停用词时的影响，通过评估准确性、召回率、精确度和F-度量值，结果表明停用词的处理方式对文本分类结果具有重要影响。

    

    分类文本是一种将文档分类为预先建立的群组的方法。在分类之前，文本文档必须以适合数据挖掘所使用的算法的方式进行准备和表示。因此，文献中已经创建了许多术语加权策略来增强文本分类算法的功能性。本研究比较了二元和词频加权特征方法对文本分类方法的影响，一次删除停用词和不删除停用词。为了评估先前特征加权方法对分类结果的影响，我们使用了一个包含322份文档的阿拉伯数据集，分为六个主题（农业、经济、健康、政治、科学和体育），每个主题包含50份文档，唯独健康类别除外。

    arXiv:2402.14867v1 Announce Type: cross  Abstract: Classifying text is a method for categorizing documents into pre-established groups. Text documents must be prepared and represented in a way that is appropriate for the algorithms used for data mining prior to classification. As a result, a number of term weighting strategies have been created in the literature to enhance text categorization algorithms' functionality. This study compares the effects of Binary and Term frequency weighting feature methodologies on the text's classification method when stop words are eliminated once and when they are not. In recognition of assessing the effects of prior weighting of features approaches on classification results in terms of accuracy, recall, precision, and F-measure values, we used an Arabic data set made up of 322 documents divided into six main topics (agriculture, economy, health, politics, science, and sport), each of which contains 50 documents, with the exception of the health categ
    
[^114]: APTQ: 针对大型语言模型的注意力感知后训练混合精度量化

    APTQ: Attention-aware Post-Training Mixed-Precision Quantization for Large Language Models

    [https://arxiv.org/abs/2402.14866](https://arxiv.org/abs/2402.14866)

    APTQ提出了针对大型语言模型的注意力感知后训练混合精度量化方法，在保持模型性能的同时，超越了先前的量化方法，并在零-shot任务上达到了最先进的准确率

    

    大型语言模型（LLMs）极大地推动了自然语言处理范式。然而，高计算负载和巨大的模型尺寸对在边缘设备上部署构成了巨大挑战。为此，我们提出了针对LLMs的APTQ（Attention-aware Post-Training Mixed-Precision Quantization），该方法不仅考虑了每层权重的二阶信息，而且首次考虑了注意力输出对整个模型的非线性影响。我们利用Hessian迹作为混合精度量化的敏感度度量，确保经过理性的精度降低能保持模型性能。实验表明，APTQ超越了先前的量化方法，在C4数据集中以平均4位宽度获得5.22困惑度，几乎等效于全精度。此外，APTQ在LLaMa-7B和LLaMa-1中以平均3.8位宽度达到了68.24％和70.48％的最先进零-shot准确率。

    arXiv:2402.14866v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have greatly advanced the natural language processing paradigm. However, the high computational load and huge model sizes pose a grand challenge for deployment on edge devices. To this end, we propose APTQ (Attention-aware Post-Training Mixed-Precision Quantization) for LLMs, which considers not only the second-order information of each layer's weights, but also, for the first time, the nonlinear effect of attention outputs on the entire model. We leverage the Hessian trace as a sensitivity metric for mixed-precision quantization, ensuring an informed precision reduction that retains model performance. Experiments show APTQ surpasses previous quantization methods, achieving an average of 4 bit width a 5.22 perplexity nearly equivalent to full precision in the C4 dataset. In addition, APTQ attains state-of-the-art zero-shot accuracy of 68.24\% and 70.48\% at an average bitwidth of 3.8 in LLaMa-7B and LLaMa-1
    
[^115]: DyVal 2: 元探测代理动态评估大型语言模型

    DyVal 2: Dynamic Evaluation of Large Language Models by Meta Probing Agents

    [https://arxiv.org/abs/2402.14865](https://arxiv.org/abs/2402.14865)

    本文提出了一种基于心理测量学思想的元探测代理（MPA）动态评估协议，用于评估大型语言模型（LLMs）的能力。

    

    大型语言模型（LLMs）的评估引起了社区的极大关注，因为存在数据污染问题。现有工作设计了使用针对特定任务的明确定义算法的评估协议，这些协议无法轻松扩展到不同的场景。此外，当前的评估基准只能提供整体基准结果，不能支持对LLMs能力进行细粒度和多方面的分析。在本文中，我们提出了元探测代理（MPA），这是一种受心理测量学启发的通用动态评估协议，用于评估LLMs。 MPA 是 DyVal 2 的关键组件，自然地扩展了先前的 DyVal。 MPA 设计了探测和评判代理，以自动将原始评估问题转化为一个新问题，遵循心理测量理论在三个基本认知能力上的应用: 语言理解、问题解决和领域知识。

    arXiv:2402.14865v1 Announce Type: cross  Abstract: Evaluation of large language models (LLMs) has raised great concerns in the community due to the issue of data contamination. Existing work designed evaluation protocols using well-defined algorithms for specific tasks, which cannot be easily extended to diverse scenarios. Moreover, current evaluation benchmarks can only provide the overall benchmark results and cannot support a fine-grained and multifaceted analysis of LLMs' abilities. In this paper, we propose meta probing agents (MPA), a general dynamic evaluation protocol inspired by psychometrics to evaluate LLMs. MPA is the key component of DyVal 2, which naturally extends the previous DyVal~\citep{zhu2023dyval}. MPA designs the probing and judging agents to automatically transform an original evaluation problem into a new one following psychometric theory on three basic cognitive abilities: language understanding, problem solving, and domain knowledge. These basic abilities are 
    
[^116]: CloudNine：使用可解释图神经网络分析气象观测对天气预测的影响

    CloudNine: Analyzing Meteorological Observation Impact on Weather Prediction Using Explainable Graph Neural Networks

    [https://arxiv.org/abs/2402.14861](https://arxiv.org/abs/2402.14861)

    提出了一个名为“CloudNine”的系统，利用可解释图神经网络分析气象观测对特定天气预测的影响

    

    气象观测对天气预报的影响取决于传感器类型、位置、时间和其他环境因素。因此，定量分析观测影响对天气预报系统的有效和高效发展至关重要。为解决这些问题，我们提出了一个名为“CloudNine”的新系统，基于可解释图神经网络（XGNNs）分析单个观测对特定预测的影响。将基于XGNN的大气状态估计模型与数值天气预报模型相结合，提供一个网络应用程序，可在地球系统的三维空间中搜索观测。

    arXiv:2402.14861v1 Announce Type: cross  Abstract: The impact of meteorological observations on weather forecasting varies with sensor type, location, time, and other environmental factors. Thus, quantitative analysis of observation impacts is crucial for effective and efficient development of weather forecasting systems. However, the existing impact analysis methods are difficult to be widely applied due to their high dependencies on specific forecasting systems. Also, they cannot provide observation impacts at multiple spatio-temporal scales, only global impacts of observation types. To address these issues, we present a novel system called ``CloudNine,'' which allows analysis of individual observations' impacts on specific predictions based on explainable graph neural networks (XGNNs). Combining an XGNN-based atmospheric state estimation model with a numerical weather prediction model, we provide a web application to search for observations in the 3D space of the Earth system and to
    
[^117]: 在没有基准实况的情况下对大型语言模型进行排名

    Ranking Large Language Models without Ground Truth

    [https://arxiv.org/abs/2402.14860](https://arxiv.org/abs/2402.14860)

    不需要基准实况或参考响应的条件下，通过考虑模型的三元组来排名大型语言模型，并提出了两种排名方法。

    

    随着大型语言模型（LLMs）的普及和影响力的增强，评估和排名LLMs已成为一个重要问题。现有的评估方法要么需要获取昂贵的人类响应，要么使用LLMs成对地互相评估，这可能不够可靠。本文提供了一个新的视角，在给定一组提示数据集（比如问题、说明等）和一组LLMs的情况下，我们在没有任何基准实况或参考响应的情况下对它们进行排名。受到现实生活的启发，其中专家和有知识的人都能识别一个新手，我们的主要思路是考虑模型的三元组，其中每个模型评估其他两个模型，能够以很高的概率正确识别最差的模型。我们还分析了我们的想法并提供了成功的充分条件。通过反复应用这一想法，我们提出了两种对LLMs进行排名的方法。

    arXiv:2402.14860v1 Announce Type: cross  Abstract: Evaluation and ranking of large language models (LLMs) has become an important problem with the proliferation of these models and their impact. Evaluation methods either require human responses which are expensive to acquire or use pairs of LLMs to evaluate each other which can be unreliable. In this paper, we provide a novel perspective where, given a dataset of prompts (viz. questions, instructions, etc.) and a set of LLMs, we rank them without access to any ground truth or reference responses. Inspired by real life where both an expert and a knowledgeable person can identify a novice our main idea is to consider triplets of models, where each one of them evaluates the other two, correctly identifying the worst model in the triplet with high probability. We also analyze our idea and provide sufficient conditions for it to succeed. Applying this idea repeatedly, we propose two methods to rank LLMs. In experiments on different generati
    
[^118]: 内在的狼：通过MLLM操作员向MLLM社会中渗入恶意

    The Wolf Within: Covert Injection of Malice into MLLM Societies via an MLLM Operative

    [https://arxiv.org/abs/2402.14859](https://arxiv.org/abs/2402.14859)

    这里是中文总结出的一句话要点: 论文探讨了在MLLM社会中通过单个操作员间接影响其他代理生成恶意内容的新型漏洞。

    

    由于其前所未有的处理和响应各种数据类型的能力，多模大型语言模型（MLLMs）不断定义人工通用智能（AGI）的新边界。随着这些先进的生成模型越来越多地形成用于复杂任务的协作网络，这些系统的完整性和安全性至关重要。我们的论文《内在的狼》探讨了MLLM社会中的一种新型漏洞 - 恶意内容的间接传播。与直接为MLLM生成有害输出不同，我们的研究展示了一个单个MLLM代理如何被微妙地影响，以生成再次诱使社会中其他MLLM代理输出恶意内容的提示。这种微妙而强有力的间接影响方法标志着与MLLM相关的安全风险的显著升级。我们的发现表明，即使几乎没有或是根本没有访问MLLM参数，一个MLLM代理，当

    arXiv:2402.14859v1 Announce Type: cross  Abstract: Due to their unprecedented ability to process and respond to various types of data, Multimodal Large Language Models (MLLMs) are constantly defining the new boundary of Artificial General Intelligence (AGI). As these advanced generative models increasingly form collaborative networks for complex tasks, the integrity and security of these systems are crucial. Our paper, ``The Wolf Within'', explores a novel vulnerability in MLLM societies - the indirect propagation of malicious content. Unlike direct harmful output generation for MLLMs, our research demonstrates how a single MLLM agent can be subtly influenced to generate prompts that, in turn, induce other MLLM agents in the society to output malicious content. This subtle, yet potent method of indirect influence marks a significant escalation in the security risks associated with MLLMs. Our findings reveal that, with minimal or even no access to MLLMs' parameters, an MLLM agent, when 
    
[^119]: ChatEL: 与聊天机器人一起进行实体链接

    ChatEL: Entity Linking with Chatbots

    [https://arxiv.org/abs/2402.14858](https://arxiv.org/abs/2402.14858)

    ChatEL框架通过三步框架改进了实体链接任务的性能，使得平均F1性能提高超过2％

    

    实体链接（EL）是自然语言处理中一个重要且具有挑战性的任务，旨在将文档或句子中表示实体的一些文本与字典或知识库中相应的条目进行链接。现有的大部分方法都专注于创建复杂的上下文模型，以寻找周围单词的线索来帮助解决链接问题。尽管这些经过调整的语言模型往往有效，但它们可能难以处理，难以训练，并且在其他领域转移效果不佳。幸运的是，像GPT这样的大型语言模型（LLMs）为EL模型中固有问题提供了高度先进的解决方案，但对LLM进行简单的提示并不奏效。在本研究中，我们定义了ChatEL，这是一个三步框架，用于提示LLM返回准确结果。总体而言，ChatEL框架将10个数据集的平均F1性能提高了超过2％。

    arXiv:2402.14858v1 Announce Type: cross  Abstract: Entity Linking (EL) is an essential and challenging task in natural language processing that seeks to link some text representing an entity within a document or sentence with its corresponding entry in a dictionary or knowledge base. Most existing approaches focus on creating elaborate contextual models that look for clues the words surrounding the entity-text to help solve the linking problem. Although these fine-tuned language models tend to work, they can be unwieldy, difficult to train, and do not transfer well to other domains. Fortunately, Large Language Models (LLMs) like GPT provide a highly-advanced solution to the problems inherent in EL models, but simply naive prompts to LLMs do not work well. In the present work, we define ChatEL, which is a three-step framework to prompt LLMs to return accurate results. Overall the ChatEL framework improves the average F1 performance across 10 datasets by more than 2%. Finally, a thorough
    
[^120]: 大型语言模型中的系统消息对越狱是否真的很重要？

    Is the System Message Really Important to Jailbreaks in Large Language Models?

    [https://arxiv.org/abs/2402.14857](https://arxiv.org/abs/2402.14857)

    系统消息在大型语言模型中的越狱过程中起着重要作用，不同系统消息对抵抗越狱具有不同影响，且越狱可能在不同语言模型之间具有可转移性。

    

    大型语言模型（LLMs）的快速发展使它们在现代社会中不可或缺。尽管通常会采取安全措施在发布前将LLMs与人类价值观保持一致，但最近的研究揭示了一个令人担忧的现象，被称为"越狱"。这个术语指的是当LLMs受到恶意问题提示时产生意外且可能有害的响应。现有研究侧重于生成越狱提示，但我们的研究旨在回答一个不同的问题：系统消息对LLMs中的越狱是否真的很重要？为了回答这个问题，我们在一个稳定的GPT版本gpt-3.5-turbo-0613中进行了实验，生成了具有不同系统消息的越狱提示：短，长和无消息。我们发现不同的系统消息通过实验具有不同的抵抗越狱的能力。此外，我们还探讨了越狱在LLMs之间的可转移性。这一发现强调了系统消息在防止LLMs越狱中的重要性。

    arXiv:2402.14857v1 Announce Type: cross  Abstract: The rapid evolution of Large Language Models (LLMs) has rendered them indispensable in modern society. While security measures are typically in place to align LLMs with human values prior to release, recent studies have unveiled a concerning phenomenon named "jailbreak." This term refers to the unexpected and potentially harmful responses generated by LLMs when prompted with malicious questions. Existing research focuses on generating jailbreak prompts but our study aim to answer a different question: Is the system message really important to jailbreak in LLMs? To address this question, we conducted experiments in a stable GPT version gpt-3.5-turbo-0613 to generated jailbreak prompts with varying system messages: short, long, and none. We discover that different system messages have distinct resistances to jailbreak by experiments. Additionally, we explore the transferability of jailbreak across LLMs. This finding underscores the signi
    
[^121]: 在推理思维中比较人类和大型语言模型的推理策略

    Comparing Inferential Strategies of Humans and Large Language Models in Deductive Reasoning

    [https://arxiv.org/abs/2402.14856](https://arxiv.org/abs/2402.14856)

    该研究通过对大型语言模型对命题逻辑问题的响应进行评估，揭示出它们展现出与人类类似的推理模式和策略。

    

    推理思维在制定健全和连贯论点方面扮演了关键角色。它允许个体根据所提供信息的真值得出逻辑上的结论。在大型语言模型（LLMs）领域的最新进展展示了它们在执行演绎推理任务方面的能力。然而，大部分研究主要评估LLMs在解决此类任务中的准确性，往往忽视了对其推理行为进行更深入的分析。在本研究中，我们借鉴认知心理学原理，通过对它们对命题逻辑问题的响应进行详细评估，来研究LLMs采用的推理策略。我们的研究结果表明，LLMs展现出类似于人类观察到的推理模式，包括诸如“假定跟随”或“链构建”等策略。此外，我们的研究证明了arXiv:2402.14856v1 Announce Type: cross

    arXiv:2402.14856v1 Announce Type: cross  Abstract: Deductive reasoning plays a pivotal role in the formulation of sound and cohesive arguments. It allows individuals to draw conclusions that logically follow, given the truth value of the information provided. Recent progress in the domain of large language models (LLMs) has showcased their capability in executing deductive reasoning tasks. Nonetheless, a significant portion of research primarily assesses the accuracy of LLMs in solving such tasks, often overlooking a deeper analysis of their reasoning behavior. In this study, we draw upon principles from cognitive psychology to examine inferential strategies employed by LLMs, through a detailed evaluation of their responses to propositional logic problems. Our findings indicate that LLMs display reasoning patterns akin to those observed in humans, including strategies like $\textit{supposition following}$ or $\textit{chain construction}$. Moreover, our research demonstrates that the ar
    
[^122]: 一种适用于可靠透明文本到查询的LLM成熟度模型

    An LLM Maturity Model for Reliable and Transparent Text-to-Query

    [https://arxiv.org/abs/2402.14855](https://arxiv.org/abs/2402.14855)

    这项工作提出了一种适用于文本到查询应用的LLM成熟度模型，不仅关注准确性，还扩展到更多维度。同时，展示了一个用于执法领域的实际案例，介绍了域特定文本到查询助手QueryIQ。

    

    认识到解决大语言模型（LLM）的可靠性和透明性问题的必要性，本研究提出了一种针对文本到查询应用的LLM成熟度模型。该成熟度模型旨在填补在评估LLM在此类应用中的不足，同时纳入了超越纯粹正确性或准确性的维度。此外，该工作引入了执法领域的一个真实用例，并展示了QueryIQ，一个基于LLM的领域特定文本到查询助手，以加速用户工作流程并揭示数据中隐藏的关系。

    arXiv:2402.14855v1 Announce Type: cross  Abstract: Recognizing the imperative to address the reliability and transparency issues of Large Language Models (LLM), this work proposes an LLM maturity model tailored for text-to-query applications. This maturity model seeks to fill the existing void in evaluating LLMs in such applications by incorporating dimensions beyond mere correctness or accuracy. Moreover, this work introduces a real-world use case from the law enforcement domain and showcases QueryIQ, an LLM-powered, domain-specific text-to-query assistant to expedite user workflows and reveal hidden relationship in data.
    
[^123]: 一种可解释的心理健康语言模型的双提示方法

    A Dual-Prompting for Interpretable Mental Health Language Models

    [https://arxiv.org/abs/2402.14854](https://arxiv.org/abs/2402.14854)

    提出了一种双提示方法，结合专家身份和自杀词典与心理健康特定LLM相结合，有效提升了在心理健康分析中的解释性和帮助临床医生评估心理状态进展。

    

    尽管越来越多的人工智能心理健康监测工具的需求增加，但由于缺乏可解释性，它们对临床医生的实际效用有限。CLPsych 2024共享任务旨在通过提供自杀意识的证据来增强大型语言模型（LLM）的可解释性，特别是在心理健康分析领域。我们提出了一种双提示方法：（i）通过利用专家身份和自杀词典与心理健康特定LLM相结合，进行知识感知证据提取；以及（ii）通过使用基于LLM的一致性评估器来进行证据总结。全面的实验证明了结合领域特定信息的有效性，揭示了性能的提升和该方法在帮助临床医生评估心理状态进展方面的潜力。

    arXiv:2402.14854v1 Announce Type: cross  Abstract: Despite the increasing demand for AI-based mental health monitoring tools, their practical utility for clinicians is limited by the lack of interpretability.The CLPsych 2024 Shared Task (Chim et al., 2024) aims to enhance the interpretability of Large Language Models (LLMs), particularly in mental health analysis, by providing evidence of suicidality through linguistic content. We propose a dual-prompting approach: (i) Knowledge-aware evidence extraction by leveraging the expert identity and a suicide dictionary with a mental health-specific LLM; and (ii) Evidence summarization by employing an LLM-based consistency evaluator. Comprehensive experiments demonstrate the effectiveness of combining domain-specific information, revealing performance improvements and the approach's potential to aid clinicians in assessing mental state progression.
    
[^124]: 从自然语言查询生成电子表格公式的NL2Formula

    NL2Formula: Generating Spreadsheet Formulas from Natural Language Queries

    [https://arxiv.org/abs/2402.14853](https://arxiv.org/abs/2402.14853)

    提出了NL2Formula任务，旨在通过自然语言查询生成基于电子表格表格的可执行公式，并提供了一个名为fCoder的基准实现。

    

    在电子表格上编写公式，如Microsoft Excel和Google Sheets，是许多进行数据分析的用户广泛使用的做法。然而，对于许多最终用户来说，制作电子表格公式仍然是一项繁琐且容易出错的任务，特别是在处理复杂操作时。为了减轻编写电子表格公式所带来的负担，本文介绍了一个称为NL2Formula的新型基准任务，旨在根据输入的自然语言（NL）查询生成基于电子表格的可执行公式。为此，我们构建了一个包含70,799个配对NL查询和相应电子表格公式的全面数据集，涵盖21,670个表格和37种公式函数类型。我们通过提供一个称为fCoder的基于序列到序列的基准实现来实现NL2Formula任务。实验结果验证了fCoder的有效性，证明了其出色的性能。

    arXiv:2402.14853v1 Announce Type: cross  Abstract: Writing formulas on spreadsheets, such as Microsoft Excel and Google Sheets, is a widespread practice among users performing data analysis. However, crafting formulas on spreadsheets remains a tedious and error-prone task for many end-users, particularly when dealing with complex operations. To alleviate the burden associated with writing spreadsheet formulas, this paper introduces a novel benchmark task called NL2Formula, with the aim to generate executable formulas that are grounded on a spreadsheet table, given a Natural Language (NL) query as input. To accomplish this, we construct a comprehensive dataset consisting of 70,799 paired NL queries and corresponding spreadsheet formulas, covering 21,670 tables and 37 types of formula functions. We realize the NL2Formula task by providing a sequence-to-sequence baseline implementation called fCoder. Experimental results validate the effectiveness of fCoder, demonstrating its superior per
    
[^125]: 最新GPT模型上的HumanEval -- 2024

    HumanEval on Latest GPT Models -- 2024

    [https://arxiv.org/abs/2402.14852](https://arxiv.org/abs/2402.14852)

    使用最新的GPT-4模型在程序合成方面取得显著进展，通过在HumanEval任务中展示了在零样本Python代码生成中的竞争性性能和更多多步骤范式综合。

    

    在2023年，我们正在使用最新的GPT-4模型来推进程序合成。这些大型语言模型显著改进了这一目的的最新技术。为了使这些进展更易于访问，我们创建了一个将这些模型连接到Human Eval的存储库。该数据集最初是为与名为CODEGEN的语言模型在自然语言和编程语言数据上使用而开发的。通过展示这些经过训练的模型在与以前的最先进解决方案相比在HumanEval任务上零样本Python代码生成中的竞争性性能，展示了这些训练模型的效用。此外，这为开发更多的多步骤范式综合创造了可能。这一基准测试包含160个多样化的问题集，这些问题集被分解成多步提示，我们的分析表明这显著改进了单轮输入上的程序综合。所有代码均以开源方式发布在https://github.com/daniel442li/gpt-human-eval。

    arXiv:2402.14852v1 Announce Type: cross  Abstract: In 2023, we are using the latest models of GPT-4 to advance program synthesis. The large language models have significantly improved the state-of-the-art for this purpose. To make these advancements more accessible, we have created a repository that connects these models to Huamn Eval. This dataset was initally developed to be used with a language model called CODEGEN on natural and programming language data. The utility of these trained models is showcased by demonstrating their competitive performance in zero-shot Python code generation on HumanEval tasks compared to previous state-of-the-art solutions. Additionally, this gives way to developing more multi-step paradigm synthesis. This benchmark features 160 diverse problem sets factorized into multistep prompts that our analysis shows significantly improves program synthesis over single-turn inputs. All code is open source at https://github.com/daniel442li/gpt-human-eval .
    
[^126]: SQL-CRAFT: 通过交互式改进和增强推理实现文本到SQL转换

    SQL-CRAFT: Text-to-SQL through Interactive Refinement and Enhanced Reasoning

    [https://arxiv.org/abs/2402.14851](https://arxiv.org/abs/2402.14851)

    提出了SQL-CRAFT框架，通过交互式改进和增强推理，提升了大语言模型在文本到SQL转换任务中的性能，实验结果显示性能提升高达5.7%，并在Spider榜单上超越了当前最先进技术。

    

    现代大语言模型已经变得越来越强大，但在专门任务（如文本到SQL）方面仍面临挑战。我们提出了SQL-CRAFT，一个通过交互式改进和增强推理来提升大语言模型SQL生成能力的框架。我们利用交互式纠错循环（IC-Loop）使大语言模型与数据库自动交互，同时采用增强推理的方法。我们在两个文本到SQL数据集Spider和Bird上进行实验，性能比朴素提示方法提高了高达5.7%。此外，我们的方法在Spider榜单上超过了当前最先进技术，展示了我们框架的有效性。

    arXiv:2402.14851v1 Announce Type: cross  Abstract: Modern LLMs have become increasingly powerful, but they are still facing challenges in specialized tasks such as Text-to-SQL. We propose SQL-CRAFT, a framework to advance LLMs' SQL generation Capabilities through inteRActive reFinemenT and enhanced reasoning. We leverage an Interactive Correction Loop (IC-Loop) for LLMs to interact with databases automatically, as well as Python-enhanced reasoning. We conduct experiments on two Text-to-SQL datasets, Spider and Bird, with performance improvements of up to 5.7% compared to the naive prompting method. Moreover, our method surpasses the current state-of-the-art on the Spider Leaderboard, demonstrating the effectiveness of our framework.
    
[^127]: CHATATC：用于支持战略空中交通流量管理的大型语言模型驱动的对话系统

    CHATATC: Large Language Model-Driven Conversational Agents for Supporting Strategic Air Traffic Flow Management

    [https://arxiv.org/abs/2402.14850](https://arxiv.org/abs/2402.14850)

    本研究探讨了如何将大型语言模型应用于非安全关键的战略交通流量管理环境，提出了一个名为CHATATC的模型，通过训练大量历史数据集实现对话系统，并测试了其查询和响应能力。

    

    生成人工智能（AI）和大型语言模型（LLMs）已经通过诸如ChatGPT等公开可用工具快速走红。LLMs在个人和专业领域的应用得到推动，是由于人类用户与ChatGPT等计算机应用之间自然的互动，以及强大的摘要和文本生成能力。在这项工作中，我们调查了这些生成AI工具如何在非安全关键的战略交通流量管理环境中部署。具体来说，我们基于包含超过80,000个GDP实施、修订和取消的大量历史数据集，对CHATATC进行训练。我们测试了CHATATC的查询和响应能力，记录了成功之处（例如，提供正确的GDP率、持续时间和原因）以及不足之处（例如，最高水平）

    arXiv:2402.14850v1 Announce Type: cross  Abstract: Generative artificial intelligence (AI) and large language models (LLMs) have gained rapid popularity through publicly available tools such as ChatGPT. The adoption of LLMs for personal and professional use is fueled by the natural interactions between human users and computer applications such as ChatGPT, along with powerful summarization and text generation capabilities. Given the widespread use of such generative AI tools, in this work we investigate how these tools can be deployed in a non-safety critical, strategic traffic flow management setting. Specifically, we train an LLM, CHATATC, based on a large historical data set of Ground Delay Program (GDP) issuances, spanning 2000-2023 and consisting of over 80,000 GDP implementations, revisions, and cancellations. We test the query and response capabilities of CHATATC, documenting successes (e.g., providing correct GDP rates, durations, and reason) and shortcomings (e.g,. superlative
    
[^128]: 异步和分段的双向编码对神经机器翻译的影响

    Asynchronous and Segmented Bidirectional Encoding for NMT

    [https://arxiv.org/abs/2402.14849](https://arxiv.org/abs/2402.14849)

    本文介绍了一种基于Transformer的改进模型，引入了异步和分段的双向编码策略，以提高神经机器翻译的效率和准确性。

    

    随着神经机器翻译(NMT)的迅速发展，提高翻译效率和质量已成为研究的焦点。本文提出了一种基于Transformer的改进模型，实施了异步和分段的双向解码策略，旨在提高翻译效率和准确性。与传统的从左到右或从右到左的单向翻译相比，我们的方法在处理长句时表现出更高的效率和更好的翻译质量。在IWSLT2017数据集上的实验结果验证了我们方法在加速翻译和提高准确性方面的有效性，尤其是超越了传统的单向翻译。

    arXiv:2402.14849v1 Announce Type: cross  Abstract: With the rapid advancement of Neural Machine Translation (NMT), enhancing translation efficiency and quality has become a focal point of research. Despite the commendable performance of general models such as the Transformer in various aspects, they still fall short in processing long sentences and fully leveraging bidirectional contextual information. This paper introduces an improved model based on the Transformer, implementing an asynchronous and segmented bidirectional decoding strategy aimed at elevating translation efficiency and accuracy. Compared to traditional unidirectional translations from left-to-right or right-to-left, our method demonstrates heightened efficiency and improved translation quality, particularly in handling long sentences. Experimental results on the IWSLT2017 dataset confirm the effectiveness of our approach in accelerating translation and increasing accuracy, especially surpassing traditional unidirection
    
[^129]: 任务相同，令牌更多：输入长度对大型语言模型推理性能的影响

    Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models

    [https://arxiv.org/abs/2402.14848](https://arxiv.org/abs/2402.14848)

    输入长度对大型语言模型的推理性能有显著影响，降级趋势出现在比技术最大值短得多的输入长度下。

    

    本文探讨了扩展输入长度对大型语言模型（LLMs）能力的影响。尽管LLMs在最近取得了进展，但它们在不同输入长度下的性能一致性尚不明确。我们通过引入一种新颖的问答推理框架来研究此方面，该框架专门设计用于评估输入长度的影响。我们通过使用同一样本的多个版本，每个版本都通过不同长度、类型和位置的填充进行了扩展，从而分离了输入长度的影响。我们的研究结果显示，在比它们的技术最大值短得多的输入长度下，LLMs的推理性能明显降低。我们展示了降级趋势出现在我们数据集的每个版本中，尽管强度不同。此外，我们的研究揭示传统的困惑度度量与LLMs在长输入推理任务中的表现没有相关性。我们分析了我们的结果并识别了

    arXiv:2402.14848v1 Announce Type: cross  Abstract: This paper explores the impact of extending input lengths on the capabilities of Large Language Models (LLMs). Despite LLMs advancements in recent times, their performance consistency across different input lengths is not well understood. We investigate this aspect by introducing a novel QA reasoning framework, specifically designed to assess the impact of input length. We isolate the effect of input length using multiple versions of the same sample, each being extended with padding of different lengths, types and locations. Our findings show a notable degradation in LLMs' reasoning performance at much shorter input lengths than their technical maximum. We show that the degradation trend appears in every version of our dataset, although at different intensities. Additionally, our study reveals that traditional perplexity metrics do not correlate with performance of LLMs' in long input reasoning tasks. We analyse our results and identif
    
[^130]: 基于深度学习的单机问题最小化总滞后的调度算法

    Deep learning-driven scheduling algorithm for a single machine problem minimizing the total tardiness

    [https://arxiv.org/abs/2402.14847](https://arxiv.org/abs/2402.14847)

    本文提出了一种基于深度学习的单机问题调度算法，通过神经网络估计最佳问题划分方式以最小化总滞后。

    

    在本文中，我们研究了使用深度学习方法来解决一个著名的NP难题单机调度问题，目标是最小化总滞后。我们提出了一个深度神经网络，它作为一个多项式时间估计量来用于基于Lawler分解和Della Croce等人提出的对称分解的单遍调度算法。实质上，神经网络通过估计问题划分为子问题的最佳方式来引导算法。本文还描述了一种生成训练数据集的新方法，加快了训练数据集的生成速度，减少了解决方案的平均最优性差距。实验结果表明，我们的机器学习驱动方法能够高效地从训练阶段概括信息到更大规模的实例。即使在训练阶段使用的实例从75

    arXiv:2402.14847v1 Announce Type: cross  Abstract: In this paper, we investigate the use of the deep learning method for solving a well-known NP-hard single machine scheduling problem with the objective of minimizing the total tardiness. We propose a deep neural network that acts as a polynomial-time estimator of the criterion value used in a single-pass scheduling algorithm based on Lawler's decomposition and symmetric decomposition proposed by Della Croce et al. Essentially, the neural network guides the algorithm by estimating the best splitting of the problem into subproblems. The paper also describes a new method for generating the training data set, which speeds up the training dataset generation and reduces the average optimality gap of solutions. The experimental results show that our machine learning-driven approach can efficiently generalize information from the training phase to significantly larger instances. Even though the instances used in the training phase have from 75
    
[^131]: 坚持你的角色！个人价值在大型语言模型中的稳定性

    Stick to your Role! Stability of Personal Values Expressed in Large Language Models

    [https://arxiv.org/abs/2402.14846](https://arxiv.org/abs/2402.14846)

    本文提出研究在大型语言模型中个人价值在不同背景下的表达稳定性，通过模拟对话的方式进行评估，对19个LLMs进行比较研究。

    

    通过基准测试或心理问卷的标准方式研究大型语言模型(LLMs)是提供许多来源于类似最小背景的不同查询（例如多项选择问题）。然而，由于LLM高度依赖于背景，因此从这种最小背景评估中得出的结论可能对模型在部署中的行为（在那里它将暴露于许多新背景）的说明很少。我们认为，依赖于背景的特性应该作为LLM比较的另一个维度来研究，而不是其他维度，如认知能力、知识或模型大小。在本文中，我们提出了一个关于在不同背景下（模拟对不同话题的对话）价值表达稳定性的案例研究，并使用标准心理学问卷（PVQ）和行为下游任务进行测量。我们考虑了来自五个家族的19个开源LLM。借鉴心理学方法，我们研究了等级稳定性。

    arXiv:2402.14846v1 Announce Type: cross  Abstract: The standard way to study Large Language Models (LLMs) through benchmarks or psychology questionnaires is to provide many different queries from similar minimal contexts (e.g. multiple choice questions). However, due to LLM's highly context-dependent nature, conclusions from such minimal-context evaluations may be little informative about the model's behavior in deployment (where it will be exposed to many new contexts). We argue that context-dependence should be studied as another dimension of LLM comparison alongside others such as cognitive abilities, knowledge, or model size. In this paper, we present a case-study about the stability of value expression over different contexts (simulated conversations on different topics), and as measured using a standard psychology questionnaire (PVQ) and a behavioral downstream task. We consider 19 open-sourced LLMs from five families. Reusing methods from psychology, we study Rank-order stabilit
    
[^132]: 通过集成小型语言模型来净化大型语言模型

    Purifying Large Language Models by Ensembling a Small Language Model

    [https://arxiv.org/abs/2402.14845](https://arxiv.org/abs/2402.14845)

    通过将大型语言模型与小型语言模型集成，可以有效净化大型语言模型，保持其性能并减轻版权侵权、数据污染和隐私侵犯等问题

    

    大型语言模型（LLMs）的成功很大程度上取决于从外部（不受信任）来源收集丰富的训练数据。尽管已经付出了大量努力进行数据清洗和精心策划，但已有报道显示构建良好的LLMs存在版权侵权、数据污染和/或隐私侵犯问题，这将阻碍LLMs的实际部署。在本研究中，我们提出了一种简单易行的方法，通过将LLMs与良性小语言模型（SLMs）集成来净化LLMs免受未经筛选数据带来的负面影响。除了理论保证外，我们进行了全面实验，从经验证实，LLMs与SLMs集成可以有效保持LLMs的性能，同时减轻版权侵权、数据污染和隐私侵犯等问题。

    arXiv:2402.14845v1 Announce Type: cross  Abstract: The emerging success of large language models (LLMs) heavily relies on collecting abundant training data from external (untrusted) sources. Despite substantial efforts devoted to data cleaning and curation, well-constructed LLMs have been reported to suffer from copyright infringement, data poisoning, and/or privacy violations, which would impede practical deployment of LLMs. In this study, we propose a simple and easily implementable method for purifying LLMs from the negative effects caused by uncurated data, namely, through ensembling LLMs with benign and small language models (SLMs). Aside from theoretical guarantees, we perform comprehensive experiments to empirically confirm the efficacy of ensembling LLMs with SLMs, which can effectively preserve the performance of LLMs while mitigating issues such as copyright infringement, data poisoning, and privacy violations.
    
[^133]: 具有强化调节的文本扩散模型

    Text Diffusion with Reinforced Conditioning

    [https://arxiv.org/abs/2402.14843](https://arxiv.org/abs/2402.14843)

    提出了一种名为TREC的文本扩散模型，通过强化调节和时间感知方差缩放解决了现有文本扩散模型在训练过程中自我调节的退化和训练与采样不一致的问题，展示了其在不同序列生成任务中的竞争力。

    

    扩散模型在生成高质量图像、视频和音频方面表现出色，由于在迭代改进中的适应性，它们对实现更好的非自回归序列生成具有潜力。然而，由于处理语言的离散性的挑战，现有的文本扩散模型在性能方面仍然存在不足。本文对文本扩散模型进行了彻底分析，并揭示了两个重要限制：训练过程中自我调节的退化和训练与采样之间的不一致性。在我们的发现的启发下，我们提出了一个名为TREC的新型文本扩散模型，通过强化调节缓解了退化问题，通过时间感知方差缩放解决了不一致性。我们的大量实验证明了TREC在自回归、非自回归和扩散基线中的竞争力。此外，定性分析显示...

    arXiv:2402.14843v1 Announce Type: cross  Abstract: Diffusion models have demonstrated exceptional capability in generating high-quality images, videos, and audio. Due to their adaptiveness in iterative refinement, they provide a strong potential for achieving better non-autoregressive sequence generation. However, existing text diffusion models still fall short in their performance due to a challenge in handling the discreteness of language. This paper thoroughly analyzes text diffusion models and uncovers two significant limitations: degradation of self-conditioning during training and misalignment between training and sampling. Motivated by our findings, we propose a novel Text Diffusion model called TREC, which mitigates the degradation with Reinforced Conditioning and the misalignment by Time-Aware Variance Scaling. Our extensive experiments demonstrate the competitiveness of TREC against autoregressive, non-autoregressive, and diffusion baselines. Moreover, qualitative analysis sh
    
[^134]: RJUA-MedDQA：医疗文档问答和临床推理的多模态基准

    RJUA-MedDQA: A Multimodal Benchmark for Medical Document Question Answering and Clinical Reasoning

    [https://arxiv.org/abs/2402.14840](https://arxiv.org/abs/2402.14840)

    介绍了RJUA-MedDQA，一个医学专业领域的全面基准，具有挑战性的要求，涉及解释图像内容、数值推理和临床推理能力。

    

    在大型语言模型（LLMs）和大型多模型模型（LMMs）的最新进展中显示出在各种医学应用中的潜力，比如智能医学诊断。尽管取得了令人印象深刻的成果，但我们发现现有的基准并未反映出真实医疗报告的复杂性和专业的深入推理能力。在这项工作中，我们引入了RJUA-MedDQA，这是医学专业领域的一个全面基准，提出了几个挑战：全面解释不同挑战性布局中的图像内容，具备识别异常指标的数值推理能力，并展示临床推理能力，根据医学背景提供疾病诊断、状态和建议的陈述。我们精心设计了数据生成流水线，并提出了旨在恢复文本和表格的高效结构恢复注释（ESRA）方法。

    arXiv:2402.14840v1 Announce Type: cross  Abstract: Recent advancements in Large Language Models (LLMs) and Large Multi-modal Models (LMMs) have shown potential in various medical applications, such as Intelligent Medical Diagnosis. Although impressive results have been achieved, we find that existing benchmarks do not reflect the complexity of real medical reports and specialized in-depth reasoning capabilities. In this work, we introduced RJUA-MedDQA, a comprehensive benchmark in the field of medical specialization, which poses several challenges: comprehensively interpreting imgage content across diverse challenging layouts, possessing numerical reasoning ability to identify abnormal indicators and demonstrating clinical reasoning ability to provide statements of disease diagnosis, status and advice based on medical contexts. We carefully design the data generation pipeline and proposed the Efficient Structural Restoration Annotation (ESRA) Method, aimed at restoring textual and tabu
    
[^135]: RFBES在SemEval-2024任务8中的应用：探究用于区分AI生成和人类撰写文本的句法和语义特征

    RFBES at SemEval-2024 Task 8: Investigating Syntactic and Semantic Features for Distinguishing AI-Generated and Human-Written Texts

    [https://arxiv.org/abs/2402.14838](https://arxiv.org/abs/2402.14838)

    该研究探究了语义和句法两个方面用于区分AI生成文本和人类撰写文本的问题，并提出了一个高准确度的AI模型，在M4数据集上表现出较好的性能。

    

    最近，大型语言模型（LLMs）的使用越来越广泛，并且LLMs已被用于在不同语言和不同任务中生成文本。此外，由于谷歌和OpenAI等知名公司的参与，LLMs现在更易获得，人们可以轻松使用它们。然而，一个重要问题是如何检测AI生成的文本与人类撰写的文本区别。本文从语义和句法两个方面探讨了AI生成文本检测问题。最终，我们提出了一个AI模型，可以在M4数据集上高准确度区分AI生成文本和人类撰写文本，无论是多语言还是单语任务。根据我们的结果，使用语义方法对于检测更有帮助。然而，在句法方法上还有很大改进空间，这将是未来工作的一个良好途径。

    arXiv:2402.14838v1 Announce Type: cross  Abstract: Nowadays, the usage of Large Language Models (LLMs) has increased, and LLMs have been used to generate texts in different languages and for different tasks. Additionally, due to the participation of remarkable companies such as Google and OpenAI, LLMs are now more accessible, and people can easily use them. However, an important issue is how we can detect AI-generated texts from human-written ones. In this article, we have investigated the problem of AI-generated text detection from two different aspects: semantics and syntax. Finally, we presented an AI model that can distinguish AI-generated texts from human-written ones with high accuracy on both multilingual and monolingual tasks using the M4 dataset. According to our results, using a semantic approach would be more helpful for detection. However, there is a lot of room for improvement in the syntactic approach, and it would be a good approach for future work.
    
[^136]: 大型语言模型提示技术的实证分类：从业者指南

    An Empirical Categorization of Prompting Techniques for Large Language Models: A Practitioner's Guide

    [https://arxiv.org/abs/2402.14837](https://arxiv.org/abs/2402.14837)

    编制了一个全面的大型语言模型提示技术清单，并建立了一个跨学科的分类框架，以帮助从业者更有效地利用这些技术。

    

    由于大型语言模型（LLMs）的快速发展，最近用提示语来编程这些模型引起了人们的极大关注。然而，现有提示工程技术的数量庞大，对于希望利用这些工具的从业者来说，这构成了一个令人难以应对的挑战。为了最有效地利用LLMs，编制一个全面的提示技术清单并建立一个标准化的跨学科分类框架是很重要的。本调查研究了一些最知名的提示技术，从学术和实践角度对它们进行了分类，分为七个不同的类别。我们概述了每个类别，旨在澄清它们的独特贡献，并展示它们在真实世界示例中的实际应用，以为同行从业者提供一个结构化框架，帮助他们理解和归类提示技术。

    arXiv:2402.14837v1 Announce Type: cross  Abstract: Due to rapid advancements in the development of Large Language Models (LLMs), programming these models with prompts has recently gained significant attention. However, the sheer number of available prompt engineering techniques creates an overwhelming landscape for practitioners looking to utilize these tools. For the most efficient and effective use of LLMs, it is important to compile a comprehensive list of prompting techniques and establish a standardized, interdisciplinary categorization framework. In this survey, we examine some of the most well-known prompting techniques from both academic and practical viewpoints and classify them into seven distinct categories. We present an overview of each category, aiming to clarify their unique contributions and showcase their practical applications in real-world examples in order to equip fellow practitioners with a structured framework for understanding and categorizing prompting techniqu
    
[^137]: 大型语言模型推荐中的隐秘攻击

    Stealthy Attack on Large Language Model based Recommendation

    [https://arxiv.org/abs/2402.14836](https://arxiv.org/abs/2402.14836)

    大型语言模型推荐系统容易受到隐秘攻击，攻击者可以通过微调文本内容在不干预模型训练的情况下显著提高物品的曝光度，而这种攻击对整体推荐性能无影响且难以被检测到。

    

    最近，强大的大型语言模型(LLMs)在推动推荐系统(RS)的进展方面发挥了重要作用。然而，尽管这些系统蓬勃发展，但它们对安全威胁的敏感性却被大多忽视了。在这项工作中，我们揭示了LLMs引入推荐模型中产生新安全漏洞的情况，这是由于它们注重物品的文本内容。我们证明了攻击者可以在测试阶段仅通过改变物品的文本内容显著增加其曝光度，而无需直接干预模型的训练过程。此外，该攻击具有显著的隐秘性，因为它不会影响整体推荐性能，对文本的修改微妙，使用户和平台难以检测到。我们在四个主流的LLM-based推荐模型上进行了全面的实验。

    arXiv:2402.14836v1 Announce Type: cross  Abstract: Recently, the powerful large language models (LLMs) have been instrumental in propelling the progress of recommender systems (RS). However, while these systems have flourished, their susceptibility to security threats has been largely overlooked. In this work, we reveal that the introduction of LLMs into recommendation models presents new security vulnerabilities due to their emphasis on the textual content of items. We demonstrate that attackers can significantly boost an item's exposure by merely altering its textual content during the testing phase, without requiring direct interference with the model's training process. Additionally, the attack is notably stealthy, as it does not affect the overall recommendation performance and the modifications to the text are subtle, making it difficult for users and platforms to detect. Our comprehensive experiments across four mainstream LLM-based recommendation models demonstrate the superior
    
[^138]: MIKE：细粒度多模态实体知识编辑的新基准

    MIKE: A New Benchmark for Fine-grained Multimodal Entity Knowledge Editing

    [https://arxiv.org/abs/2402.14835](https://arxiv.org/abs/2402.14835)

    MIKE是一个针对细粒度多模态实体知识编辑的全面基准和数据集，突破了现有基准主要侧重于粗粒度知识的局限性，引入了新的知识编辑形式以评估编辑效率。

    

    多模态知识编辑是增强多模态大语言模型（MLLMs）功能的重要进展。尽管其潜力巨大，但当前的基准主要集中在粗粒度知识上，细粒度多模态实体知识的复杂性大多未被探索。为了弥补这一差距，我们引入了MIKE，这是一个专门为细粒度多模态实体知识编辑设计的全面基准和数据集。

    arXiv:2402.14835v1 Announce Type: cross  Abstract: Multimodal knowledge editing represents a critical advancement in enhancing the capabilities of Multimodal Large Language Models (MLLMs). Despite its potential, current benchmarks predominantly focus on coarse-grained knowledge, leaving the intricacies of fine-grained (FG) multimodal entity knowledge largely unexplored. This gap presents a notable challenge, as FG entity recognition is pivotal for the practical deployment and effectiveness of MLLMs in diverse real-world scenarios. To bridge this gap, we introduce MIKE, a comprehensive benchmark and dataset specifically designed for the FG multimodal entity knowledge editing. MIKE encompasses a suite of tasks tailored to assess different perspectives, including Vanilla Name Answering, Entity-Level Caption, and Complex-Scenario Recognition. In addition, a new form of knowledge editing, Multi-step Editing, is introduced to evaluate the editing efficiency. Through our extensive evaluations
    
[^139]: MSynFD: 多跳语法感知假新闻检测

    MSynFD: Multi-hop Syntax aware Fake News Detection

    [https://arxiv.org/abs/2402.14834](https://arxiv.org/abs/2402.14834)

    提出一种新的多跳语法感知假新闻检测方法，通过引入补充的语法信息来处理假新闻中的微妙转折

    

    社交媒体平台的广泛传播助长了假新闻的快速传播，对我们的现实社会构成威胁。现有方法使用多模态数据或上下文信息来增强对假新闻的检测，通过分析新闻内容和/或其社会背景。然而，这些方法常常忽视了基本的文本新闻内容（文章），并且过分依赖序列建模和全局注意力来提取语义信息。这些现有方法无法处理新闻文章中的复杂、微妙的转折，比如句法-语义不匹配和先验偏差，导致性能较低，并在缺失模态或社会背景时可能失败。为了弥合这些重要差距，我们提出了一种新颖的多跳语法感知假新闻检测（MSynFD）方法，该方法融合了补充的语法信息，以处理假新闻中的微妙转折。

    arXiv:2402.14834v1 Announce Type: cross  Abstract: The proliferation of social media platforms has fueled the rapid dissemination of fake news, posing threats to our real-life society. Existing methods use multimodal data or contextual information to enhance the detection of fake news by analyzing news content and/or its social context. However, these methods often overlook essential textual news content (articles) and heavily rely on sequential modeling and global attention to extract semantic information. These existing methods fail to handle the complex, subtle twists in news articles, such as syntax-semantics mismatches and prior biases, leading to lower performance and potential failure when modalities or social context are missing. To bridge these significant gaps, we propose a novel multi-hop syntax aware fake news detection (MSynFD) method, which incorporates complementary syntax information to deal with subtle twists in fake news. Specifically, we introduce a syntactical depen
    
[^140]: CliqueParcel：一种同时优化效率和忠实度的批处理LLM提示的方法

    CliqueParcel: An Approach For Batching LLM Prompts That Jointly Optimizes Efficiency And Faithfulness

    [https://arxiv.org/abs/2402.14833](https://arxiv.org/abs/2402.14833)

    CliqueParcel提出了一种通过提示批处理来提高LLM效率的方法，旨在在推理过程中同时确保准确性和最小化与原始输出的偏差，解决了折价输出问题。

    

    大型语言模型（LLM）在最近的研究中变得至关重要。然而，在推理过程中，LLM仍然需要大量资源。本文提出了CliqueParcel，一种旨在通过提示批处理来提高LLM效率的方法。现有的优化推理效率的策略通常会对输出质量进行妥协，导致折价输出问题。这个问题可能导致准确性降低或输出缺乏细节。CliqueParcel是我们对这一挑战的回应。在确保准确性和最小化与原始输出的偏差（即忠实度）的情况下，我们的方法在推理过程中显著提高了效率。为了奠定基础，我们首先通过排除由于长度缩短而导致的运行时间减少来重新定义效率测量标准。然后，我们提供了效率和忠实度之间的全面权衡，以阐明“折价输出”问题的本质。

    arXiv:2402.14833v1 Announce Type: cross  Abstract: Large language models (LLMs) have become pivotal in recent research. However, during the inference process, LLMs still require substantial resources. In this paper, we propose CliqueParcel, a method designed to improve the efficiency of LLMs via prompt batching. Existing strategies to optimize inference efficiency often compromise on output quality, leading to a discounted output problem. This issue might result in reduced accuracy or outputs that are less detailed. CliqueParcel is our answer to this challenge. While ensuring accuracy and minimizing deviations from the original outputs (i.e., faithfulness), our method significantly improves efficiency during inference.   To lay the groundwork, we first redefine efficiency measurements by excluding the reduction in running time due to shorter lengths. Then, we provide a comprehensive trade-off between efficiency and faithfulness to clarify the nature of the 'discounted output' problem. 
    
[^141]: Orca-Math：释放小语言模型在小学数学中的潜力

    Orca-Math: Unlocking the potential of SLMs in Grade School Math

    [https://arxiv.org/abs/2402.14830](https://arxiv.org/abs/2402.14830)

    提出了一个基于Mistral-7B的70亿参数的Orca-Math小语言模型，旨在在小学数学中实现更高的准确度。

    

    数学单词问题解决长期以来一直被认为是小语言模型（SLMs）面临的复杂任务。最近的一项研究假设，为了在GSM8K基准测试上实现超过80%的准确度，最小的模型大小需要为340亿个参数。为了用更小的模型达到这一性能水平，研究人员经常训练SLMs生成Python代码或使用工具来帮助避免计算错误。此外，他们使用集成，将多达100次模型运行的输出组合在一起，得到更准确的结果。结果选择是通过共识、多数投票或与SLM一起使用的单独的验证器模型来进行的。集成大大提高了准确性，但随之而来的是对模型的多次调用造成的显著成本增加（例如，Phi-GSM使用前48个来将性能从68.2提升到81.5）。在这项研究中，我们提出了Orca-Math，一个基于Mistral-7B的70亿参数SLM。

    arXiv:2402.14830v1 Announce Type: cross  Abstract: Mathematical word problem-solving has long been recognized as a complex task for small language models (SLMs). A recent study hypothesized that the smallest model size, needed to achieve over 80% accuracy on the GSM8K benchmark, is 34 billion parameters. To reach this level of performance with smaller models, researcher often train SLMs to generate Python code or use tools to help avoid calculation errors. Additionally, they employ ensembling, where outputs of up to 100 model runs are combined to arrive at a more accurate result. Result selection is done using consensus, majority vote or a separate a verifier model used in conjunction with the SLM. Ensembling provides a substantial boost in accuracy but at a significant cost increase with multiple calls to the model (e.g., Phi-GSM uses top-48 to boost the performance from 68.2 to 81.5).   In this work, we present Orca-Math, a 7-billion-parameter SLM based on the Mistral-7B, which achie
    
[^142]: 通过窗口选择和节点优化优化妊娠和分娩中的子宫同步分析

    Optimizing Uterine Synchronization Analysis in Pregnancy and Labor through Window Selection and Node Optimization

    [https://arxiv.org/abs/2402.14827](https://arxiv.org/abs/2402.14827)

    通过窗口方法和节点优化分析EHG信号，提出一种新方法来优化妊娠和分娩中的子宫同步分析。

    

    早产是全球5岁以下儿童死亡的主要原因。本文通过分析记录在劳动和妊娠期间母亲腹部的EHG信号，提出了一种新的方法来解决这一问题。EHG信号反映了诱导子宫肌电机收缩的电活动。由于EHG信号被认为是非平稳信号，并且我们预期在收缩过程中连接性会发生改变，我们应用了窗口方法在实际信号上，以帮助我们识别用于分类的最佳窗口和最佳节点的数据。

    arXiv:2402.14827v1 Announce Type: cross  Abstract: Preterm labor (PL) has globally become the leading cause of death in children under the age of 5 years. To address this problem, this paper will provide a new approach by analyzing the EHG signals, which are recorded on the abdomen of the mother during labor and pregnancy. The EHG signal reflects the electrical activity that induces the mechanical contraction of the myometrium. Because EHGs are known to be non-stationary signals, and because we anticipate connectivity to alter during contraction, we applied the windowing approach on real signals to help us identify the best windows and the best nodes with the most significant data to be used for classification. The suggested pipeline includes i) divide the 16 EHG signals that are recorded from the abdomen of pregnant women in N windows; ii) apply the connectivity matrices on each window; iii) apply the Graph theory-based measures on the connectivity matrices on each window; iv) apply t
    
[^143]: ConceptMath：用于衡量大型语言模型数学推理能力的双语概念评测基准

    ConceptMath: A Bilingual Concept-wise Benchmark for Measuring Mathematical Reasoning of Large Language Models

    [https://arxiv.org/abs/2402.14660](https://arxiv.org/abs/2402.14660)

    介绍了ConceptMath，一种双语的细粒度基准测试，用于评估大型语言模型的概念性数学推理能力，并发现现有模型在不同数学概念上存在显著性能差异，甚至可能在最基本的概念上出现失败。

    

    本文介绍了ConceptMath，这是一个双语（英语和中文），细粒度的基准测试，用来评估大型语言模型（LLMs）的概念性数学推理能力。与评估一般数学推理的传统基准不同，ConceptMath将数学问题系统地组织在数学概念的层次结构下，从而可以以概念为单位准确性评估数学推理。基于我们的ConceptMath，我们评估了广泛范围的LLMs，并观察到现有的LLMs尽管在传统基准上取得了高平均准确性，但在不同数学概念上表现出显著的性能差异，甚至可能在最基本的概念上出现严重失败。此外，我们还介绍了一种有效的微调策略来增强现有LLMs的弱点。最后，我们希望ConceptMath能够指导开发者理解细致的数学推理能力。

    arXiv:2402.14660v1 Announce Type: cross  Abstract: This paper introduces ConceptMath, a bilingual (English and Chinese), fine-grained benchmark that evaluates concept-wise mathematical reasoning of Large Language Models (LLMs). Unlike traditional benchmarks that evaluate general mathematical reasoning with an average accuracy, ConceptMath systematically organizes math problems under a hierarchy of math concepts, so that mathematical reasoning can be evaluated at different granularity with concept-wise accuracies. Based on our ConcepthMath, we evaluate a broad range of LLMs, and we observe existing LLMs, though achieving high average accuracies on traditional benchmarks, exhibit significant performance variations across different math concepts and may even fail catastrophically on the most basic ones. Besides, we also introduce an efficient fine-tuning strategy to enhance the weaknesses of existing LLMs. Finally, we hope ConceptMath could guide the developers to understand the fine-grai
    
[^144]: 将生成式人工智能引入教育中的自适应学习

    Bringing Generative AI to Adaptive Learning in Education

    [https://arxiv.org/abs/2402.14601](https://arxiv.org/abs/2402.14601)

    生成式人工智能技术与自适应学习概念的交叉研究将对教育中下一阶段学习格式的发展做出重要贡献。

    

    最近生成式人工智能技术的激增，如大型语言模型和扩散模型，推动了人工智能在科学、金融和教育等各个领域的应用发展。与此同时，自适应学习这一概念在教育领域引起了极大关注，并证明其在提高学生学习效率方面的有效性。在本立场论文中，我们旨在探讨将生成式人工智能与自适应学习概念结合起来的交叉研究。通过讨论这一领域的好处、挑战和潜力，我们认为这种结合将为教育中下一阶段学习形式的发展做出重要贡献。

    arXiv:2402.14601v1 Announce Type: cross  Abstract: The recent surge in generative AI technologies, such as large language models and diffusion models, have boosted the development of AI applications in various domains, including science, finance, and education. Concurrently, adaptive learning, a concept that has gained substantial interest in the educational sphere, has proven its efficacy in enhancing students' learning efficiency. In this position paper, we aim to shed light on the intersectional studies of these two methods, which combine generative AI with adaptive learning concepts. By presenting discussions about the benefits, challenges, and potentials in this field, we argue that this union will contribute significantly to the development of the next stage learning format in education.
    
[^145]: OmniPred：语言模型作为通用回归器

    OmniPred: Language Models as Universal Regressors

    [https://arxiv.org/abs/2402.14547](https://arxiv.org/abs/2402.14547)

    本文提出了OmniPred框架，用于训练语言模型作为通用的端到端回归器，实验证明，在多个任务上训练时，语言模型能够显著优于传统回归模型。

    

    在实验设计的广阔领域中，回归一直是一个强大的工具，可以准确预测系统或模型在给定一组参数的情况下的结果指标，但传统上只限于适用于特定任务的方法。在本文中，我们提出了OmniPred，这是一个用于训练语言模型作为通用端到端回归器的框架，使用来自多样真实世界实验的$(x,y)$评估数据。通过使用源自Google Vizier的数据，这是世界上最大的黑盒优化数据库之一，我们的大量实验表明，仅通过数学参数和值的文本表示，语言模型能够进行非常精确的数值回归，如果有机会训练多个任务，则可以显著优于传统的回归模型。

    arXiv:2402.14547v1 Announce Type: cross  Abstract: Over the broad landscape of experimental design, regression has been a powerful tool to accurately predict the outcome metrics of a system or model given a set of parameters, but has been traditionally restricted to methods which are only applicable to a specific task. In this paper, we propose OmniPred, a framework for training language models as universal end-to-end regressors over $(x,y)$ evaluation data from diverse real world experiments. Using data sourced from Google Vizier, one of the largest blackbox optimization databases in the world, our extensive experiments demonstrate that through only textual representations of mathematical parameters and values, language models are capable of very precise numerical regression, and if given the opportunity to train over multiple tasks, can significantly outperform traditional regression models.
    
[^146]: REPOFUSE：具有融合双重上下文的仓库级代码自动补全

    REPOFUSE: Repository-Level Code Completion with Fused Dual Context

    [https://arxiv.org/abs/2402.14323](https://arxiv.org/abs/2402.14323)

    RepoGenix独特融合类比上下文和理性上下文，并提出了截断排名生成（RTG）技术，以提高仓库级代码自动补全的准确性而不牺牲推理效率。

    

    语言模型在代码辅助方面取得的成功推动了提出仓库级代码自动补全作为提高预测准确性的手段，利用整个代码库的上下文。然而，这种增强的上下文可能会无意中增加推理延迟，潜在地损害开发者体验并妨碍工具的采用-这是我们称之为上下文-延迟困境的挑战。本文介绍了 RepoGenix，这是一个旨在提高仓库级代码自动补全而无需延迟折衷的开创性解决方案。RepoGenix 独特地融合了两种类型的上下文：根植于代码类比的类比上下文和包含深度语义关系的理性上下文。我们提出了一种新颖的截断排名生成（RTG）技术，有效地将这些上下文压缩为限制大小的提示。这使得 RepoGenix 能够在保持推理效率的同时提供精确的代码自动补全。

    arXiv:2402.14323v1 Announce Type: cross  Abstract: The success of language models in code assistance has spurred the proposal of repository-level code completion as a means to enhance prediction accuracy, utilizing the context from the entire codebase. However, this amplified context can inadvertently increase inference latency, potentially undermining the developer experience and deterring tool adoption-a challenge we termed the Context-Latency Conundrum. This paper introduces RepoGenix, a pioneering solution designed to enhance repository-level code completion without the latency trade-off. RepoGenix uniquely fuses two types of contexts: the analogy context, rooted in code analogies, and the rationale context, which encompasses in-depth semantic relationships. We propose a novel rank truncated generation (RTG) technique that efficiently condenses these contexts into prompts with restricted size. This enables RepoGenix to deliver precise code completions while maintaining inference ef
    
[^147]: 面向公平文本嵌入的内容条件去偏方法

    Content Conditional Debiasing for Fair Text Embedding

    [https://arxiv.org/abs/2402.14208](https://arxiv.org/abs/2402.14208)

    通过在内容条件下确保敏感属性与文本嵌入之间的条件独立性，我们提出了一种可以改善公平性的新方法，在保持效用的同时，解决了缺乏适当训练数据的问题。

    

    在自然语言处理（NLP）中，减轻机器学习模型中的偏见引起了越来越多的关注。然而，只有少数研究集中在公平的文本嵌入上，这对实际应用至关重要且具有挑战性。本文提出了一种学习公平文本嵌入的新方法。我们通过确保在内容条件下敏感属性与文本嵌入之间的条件独立性来实现公平性，同时保持效用权衡。具体来说，我们强制要求具有不同敏感属性但相同内容的文本的嵌入与其对应中立文本的嵌入保持相同的距离。此外，我们通过使用大型语言模型（LLMs）将文本增强为不同的敏感组，来解决缺乏适当训练数据的问题。我们广泛的评估表明，我们的方法有效地提高了公平性同时保持了嵌入的效用。

    arXiv:2402.14208v1 Announce Type: cross  Abstract: Mitigating biases in machine learning models has gained increasing attention in Natural Language Processing (NLP). Yet, only a few studies focus on fair text embeddings, which are crucial yet challenging for real-world applications. In this paper, we propose a novel method for learning fair text embeddings. We achieve fairness while maintaining utility trade-off by ensuring conditional independence between sensitive attributes and text embeddings conditioned on the content. Specifically, we enforce that embeddings of texts with different sensitive attributes but identical content maintain the same distance toward the embedding of their corresponding neutral text. Furthermore, we address the issue of lacking proper training data by using Large Language Models (LLMs) to augment texts into different sensitive groups. Our extensive evaluations demonstrate that our approach effectively improves fairness while preserving the utility of embed
    
[^148]: EyeTrans: 合并人类和机器注意力以实现神经代码摘要

    EyeTrans: Merging Human and Machine Attention for Neural Code Summarization

    [https://arxiv.org/abs/2402.14096](https://arxiv.org/abs/2402.14096)

    引入EyeTrans方法，将人类注意力融入机器注意力，以增强神经代码摘要能力。

    

    Neural code summarization 利用深度学习模型自动生成代码片段的简要自然语言摘要。Transformer模型的发展导致在模型设计中广泛使用注意力机制。本文提出一种将人类注意力融入机器注意力以增强神经代码摘要的方法。为了实现这一融合并验证这一假设，引入了EyeTrans，包括三个步骤：(1) 进行了大量的眼动人类研究，收集和预分析数据用于模型训练，(2) 我们设计了一个以数据为中心的方法来整合人类注意力及

    arXiv:2402.14096v1 Announce Type: cross  Abstract: Neural code summarization leverages deep learning models to automatically generate brief natural language summaries of code snippets. The development of Transformer models has led to extensive use of attention during model design. While existing work has primarily and almost exclusively focused on static properties of source code and related structural representations like the Abstract Syntax Tree (AST), few studies have considered human attention, that is, where programmers focus while examining and comprehending code. In this paper, we develop a method for incorporating human attention into machine attention to enhance neural code summarization. To facilitate this incorporation and vindicate this hypothesis, we introduce EyeTrans, which consists of three steps: (1) we conduct an extensive eye-tracking human study to collect and pre-analyze data for model training, (2) we devise a data-centric approach to integrate human attention wit
    
[^149]: 离线策略学习的深度生成模型：教程、调查和未来方向展望

    Deep Generative Models for Offline Policy Learning: Tutorial, Survey, and Perspectives on Future Directions

    [https://arxiv.org/abs/2402.13777](https://arxiv.org/abs/2402.13777)

    深度生成模型在离线策略学习中展现了巨大潜力，本文提供了首个系统性综述，涵盖了五种主流深度生成模型及其应用。

    

    深度生成模型(DGMs)在各个领域展示了巨大成功，特别是在使用从离线数据训练的模型生成文本、图像和视频方面。类似地，基于数据驱动的决策和机器人控制也需要从离线数据中学习一个生成函数作为策略或政策。在这种情况下，将深度生成模型应用于离线策略学习展现出巨大潜力，许多研究在这个方向上进行了探索。然而，这一领域仍然缺乏全面的评估，因此不同分支的发展相对独立。因此，我们提供了深度生成模型在离线策略学习应用方面的第一次系统性综述。具体而言，我们涵盖了五种主流深度生成模型，包括变分自动编码器、生成对抗网络、归一化流、变压器和扩散模型，以及它们的应用。

    arXiv:2402.13777v1 Announce Type: cross  Abstract: Deep generative models (DGMs) have demonstrated great success across various domains, particularly in generating texts, images, and videos using models trained from offline data. Similarly, data-driven decision-making and robotic control also necessitate learning a generator function from the offline data to serve as the strategy or policy. In this case, applying deep generative models in offline policy learning exhibits great potential, and numerous studies have explored in this direction. However, this field still lacks a comprehensive review and so developments of different branches are relatively independent. Thus, we provide the first systematic review on the applications of deep generative models for offline policy learning. In particular, we cover five mainstream deep generative models, including Variational Auto-Encoders, Generative Adversarial Networks, Normalizing Flows, Transformers, and Diffusion Models, and their applicati
    
[^150]: CriticBench: 将大型语言模型作为评论家进行评估

    CriticBench: Evaluating Large Language Models as Critic

    [https://arxiv.org/abs/2402.13764](https://arxiv.org/abs/2402.13764)

    CriticBench是一个旨在全面和可靠地评估大型语言模型的评论能力的新型基准，展示了评论能力与任务、响应质量和模型规模之间的关系。

    

    论文提出了 CriticBench，这是一个旨在全面和可靠地评估大型语言模型（LLMs）的四个关键评论能力维度（反馈、比较、改进和元反馈）的新型基准。CriticBench包含九个不同的任务，每个任务评估LLMs在不同质量细粒度水平上评论响应的能力。对开源和闭源LLMs进行的广泛评估揭示了评论能力与任务、响应质量和模型规模之间有趣的关系。CriticBench的数据集、资源和评估工具包将在https://github.com/gmftbyGMFTBY/Cri上公开发布。

    arXiv:2402.13764v1 Announce Type: cross  Abstract: Critique ability are crucial in the scalable oversight and self-improvement of Large Language Models (LLMs). While many recent studies explore the critique ability of LLMs to judge and refine flaws in generations, how to comprehensively and reliably measure the critique abilities of LLMs is under-explored. This paper introduces \shortname, a novel benchmark designed to comprehensively and reliably evaluate four key critique ability dimensions of LLMs: feedback, comparison, refinement and meta-feedback. \shortname~encompasses nine diverse tasks, each assessing the LLMs' ability to critique responses at varying levels of quality granularity. Our extensive evaluations of open-source and closed-source LLMs reveal intriguing relationships between the critique ability and tasks, response qualities, and model scales. Datasets, resources and evaluation toolkit for \shortname~will be publicly released at \url{https://github.com/gmftbyGMFTBY/Cri
    
[^151]: DSLR：多样性增强和结构学习用于基于重播的图持续学习

    DSLR: Diversity Enhancement and Structure Learning for Rehearsal-based Graph Continual Learning

    [https://arxiv.org/abs/2402.13711](https://arxiv.org/abs/2402.13711)

    DSLR提出了一种基于覆盖范围的多样性方法，以解决基于重播的图持续学习中回放节点过于集中导致过拟合和灾难性遗忘的问题。

    

    我们研究了基于重播方法中回放缓冲区对图持续学习（GCL）方法的影响。现有的基于重播的GCL方法为每个类别选择最具代表性的节点并将它们存储在重播缓冲区中，以供在训练后续任务时使用。然而，我们发现，仅考虑每个回放节点的类别代表性会使回放节点集中在每个类别的中心周围，可能存在过拟合于位于那些区域的节点的风险，从而加剧灾难性遗忘。此外，由于基于重播方法严重依赖于少数回放节点来保留从先前任务中获得的知识，涉及在模型训练中具有不相关邻居的回放节点可能对模型性能产生显着的负面影响。在本文中，我们提出了一种名为DSLR的GCL模型，具体来说，我们设计了一种基于覆盖范围的多样性（CD）

    arXiv:2402.13711v1 Announce Type: cross  Abstract: We investigate the replay buffer in rehearsal-based approaches for graph continual learning (GCL) methods. Existing rehearsal-based GCL methods select the most representative nodes for each class and store them in a replay buffer for later use in training subsequent tasks. However, we discovered that considering only the class representativeness of each replayed node makes the replayed nodes to be concentrated around the center of each class, incurring a potential risk of overfitting to nodes residing in those regions, which aggravates catastrophic forgetting. Moreover, as the rehearsal-based approach heavily relies on a few replayed nodes to retain knowledge obtained from previous tasks, involving the replayed nodes that have irrelevant neighbors in the model training may have a significant detrimental impact on model performance. In this paper, we propose a GCL model named DSLR, specifically, we devise a coverage-based diversity (CD)
    
[^152]: KetGPT -- 使用Transformer对量子电路进行数据增强

    KetGPT -- Dataset Augmentation of Quantum Circuits using Transformers

    [https://arxiv.org/abs/2402.13352](https://arxiv.org/abs/2402.13352)

    该研究利用Transformer机器学习架构生成“看起来真实”的量子电路，以增强现有的量子电路数据集。

    

    量子算法，表示为量子电路，可用作评估量子系统性能的基准。现有数据集在规模和多样性方面存在限制，在该领域广泛使用，导致研究人员使用随机生成的电路。然而，随机电路并不是代表性基准，因为它们缺乏量子系统制造的真实量子算法的固有属性。这种缺乏“有用”的量子基准构成了推动量子编译器和硬件开发与比较的挑战。本研究旨在通过使用Transformer机器学习架构生成我们称之为“看起来真实”的电路，以增强现有的量子电路数据集。为此，我们引入了KetGPT，一种以OpenQASM语言生成合成电路的工具，其结构是基于推导自量子电路的

    arXiv:2402.13352v1 Announce Type: cross  Abstract: Quantum algorithms, represented as quantum circuits, can be used as benchmarks for assessing the performance of quantum systems. Existing datasets, widely utilized in the field, suffer from limitations in size and versatility, leading researchers to employ randomly generated circuits. Random circuits are, however, not representative benchmarks as they lack the inherent properties of real quantum algorithms for which the quantum systems are manufactured. This shortage of `useful' quantum benchmarks poses a challenge to advancing the development and comparison of quantum compilers and hardware.   This research aims to enhance the existing quantum circuit datasets by generating what we refer to as `realistic-looking' circuits by employing the Transformer machine learning architecture. For this purpose, we introduce KetGPT, a tool that generates synthetic circuits in OpenQASM language, whose structure is based on quantum circuits derived f
    
[^153]: 具有市场影响力的深度套期保值

    Deep Hedging with Market Impact

    [https://arxiv.org/abs/2402.13326](https://arxiv.org/abs/2402.13326)

    本文提出了一种基于深度强化学习的市场影响动态套期保值模型，考虑了凸市场影响和随时间持续的影响，通过与常用程序比较，展示了其在期权套期保值方面的优越性。

    

    动态套期保值是定期进行金融工具交易，以抵消投资或负债所带来风险的实践。动态套期保值优化可以被视为一个顺序决策问题；因此，最近提出了利用强化学习（RL）模型来解决这一任务。然而，现有的套期保值RL工作并未考虑由交易工具的有限流动性引起的市场影响。整合这样的特征对于在具有有限流动性的股票期权套期保值时实现最佳性能可能是至关重要的。本文提出了一种基于深度强化学习（DRL）的新型通用市场影响动态套期保值模型，考虑了几个逼真的特征，例如凸市场影响和随时间持续的影响。从DRL模型得到的最优策略通过几个期权套期保值模拟进行了分析，并与常用程序（如德尔塔套期保值）进行了比较。

    arXiv:2402.13326v1 Announce Type: cross  Abstract: Dynamic hedging is the practice of periodically transacting financial instruments to offset the risk caused by an investment or a liability. Dynamic hedging optimization can be framed as a sequential decision problem; thus, Reinforcement Learning (RL) models were recently proposed to tackle this task. However, existing RL works for hedging do not consider market impact caused by the finite liquidity of traded instruments. Integrating such feature can be crucial to achieve optimal performance when hedging options on stocks with limited liquidity. In this paper, we propose a novel general market impact dynamic hedging model based on Deep Reinforcement Learning (DRL) that considers several realistic features such as convex market impacts, and impact persistence through time. The optimal policy obtained from the DRL model is analysed using several option hedging simulations and compared to commonly used procedures such as delta hedging. Re
    
[^154]: 用于医学领域的检索增强生成的基准测试

    Benchmarking Retrieval-Augmented Generation for Medicine

    [https://arxiv.org/abs/2402.13178](https://arxiv.org/abs/2402.13178)

    通过提出首个医学信息检索增强生成评估(MIRAGE)基准测试，并使用MedRAG工具包进行大规模实验，实现了对多个大型语言模型的准确性改进。

    

    大型语言模型(LLMs)在广泛的医学问答任务上取得了最先进的性能，但仍然面临幻觉和过时知识的挑战。检索增强生成(RAG)是一个有前途的解决方案，并得到了广泛采用。然而，RAG系统可能涉及多个灵活的组件，并且缺乏关于各种医学目的的最佳RAG设置的最佳实践。为了系统地评估这些系统，我们提出了医学信息检索增强生成评估(MIRAGE)，这是一个首创的基准测试，包括来自五个医学问答数据集的7,663个问题。利用MIRAGE，我们通过本文介绍的MedRAG工具包，在41种不同语料库、检索器和骨干LLMs的组合上进行了超过1.8万亿的提示标记的大规模实验。总体而言，MedRAG提高了六种不同LLMs的准确性。

    arXiv:2402.13178v1 Announce Type: cross  Abstract: While large language models (LLMs) have achieved state-of-the-art performance on a wide range of medical question answering (QA) tasks, they still face challenges with hallucinations and outdated knowledge. Retrieval-augmented generation (RAG) is a promising solution and has been widely adopted. However, a RAG system can involve multiple flexible components, and there is a lack of best practices regarding the optimal RAG setting for various medical purposes. To systematically evaluate such systems, we propose the Medical Information Retrieval-Augmented Generation Evaluation (MIRAGE), a first-of-its-kind benchmark including 7,663 questions from five medical QA datasets. Using MIRAGE, we conducted large-scale experiments with over 1.8 trillion prompt tokens on 41 combinations of different corpora, retrievers, and backbone LLMs through the MedRAG toolkit introduced in this work. Overall, MedRAG improves the accuracy of six different LLMs 
    
[^155]: 学习检查：释放大型语言模型自我校正的潜力

    Learning to Check: Unleashing Potentials for Self-Correction in Large Language Models

    [https://arxiv.org/abs/2402.13035](https://arxiv.org/abs/2402.13035)

    通过精心设计训练数据和构建检查-校正数据集，本研究增强了大型语言模型的自我校正能力，提高了自我校正的准确性。

    

    大型语言模型（LLMs）在推理能力方面取得了显著进展，不断努力通过自我校正来完善推理。然而，最近的研究表明，没有外部准确知识的自我校正可能存在局限性甚至可能适得其反，这就引发了关于自我校正的限制和有效性的疑问。本文旨在通过精心设计训练数据来增强LLM的自检功能，从而提高自我校正的准确性。我们对数学推理中的错误类型进行了详细分析，并开发了一个量身定制的提示，称为“Step CoT Check”。然后我们构建了一个检查-校正数据集用于训练模型。在将原始CoT数据和检查校正数据整合后进行训练，我们观察到模型可以改善其自检能力，从而提高其自我校正能力并消除了需要

    arXiv:2402.13035v1 Announce Type: cross  Abstract: Large language models (LLMs) have made significant strides in reasoning capabilities, with ongoing efforts to refine their reasoning through self-correction. However, recent studies suggest that self-correction can be limited or even counterproductive without external accurate knowledge, raising questions about the limits and effectiveness of self-correction. In this paper, we aim to enhance LLM's self-checking capabilities by meticulously designing training data, thereby improving the accuracy of self-correction. We conduct a detailed analysis of error types in mathematical reasoning and develop a tailored prompt, termed ``Step CoT Check''. Then we construct a checking-correction dataset for training models. After integrating the original CoT data and checking-correction data for training, we observe that models could improve their self-checking capabilities, thereby enhancing their self-correction capacity and eliminating the need fo
    
[^156]: 模式分析与机器智能领域文献综述的文献综述

    A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence

    [https://arxiv.org/abs/2402.12928](https://arxiv.org/abs/2402.12928)

    本文旨在提供对模式分析与机器智能领域文献综述的全面评估，引入大语言模型驱动的文献计量指标，并构建了RiPAMI元数据数据库和主题数据集以获取PAMI综述的统计特征。

    

    通过整合分散的知识，文献综述提供了对所研究主题的全面了解。然而，在模式分析与机器智能（PAMI）这一蓬勃发展的领域中，过多的综述引起了研究人员和评论者的关注。作为对这些关注的回应，本文旨在从多个角度全面审视PAMI领域的综述文献。

    arXiv:2402.12928v1 Announce Type: cross  Abstract: By consolidating scattered knowledge, the literature review provides a comprehensive understanding of the investigated topic. However, excessive reviews, especially in the booming field of pattern analysis and machine intelligence (PAMI), raise concerns for both researchers and reviewers. In response to these concerns, this Analysis aims to provide a thorough review of reviews in the PAMI field from diverse perspectives. First, large language model-empowered bibliometric indicators are proposed to evaluate literature reviews automatically. To facilitate this, a meta-data database dubbed RiPAMI, and a topic dataset are constructed, which are utilized to obtain statistical characteristics of PAMI reviews. Unlike traditional bibliometric measurements, the proposed article-level indicators provide real-time and field-normalized quantified assessments of reviews without relying on user-defined keywords. Second, based on these indicators, th
    
[^157]: 表格作为图片？探讨LLM在多模态表格数据表示上的优势和局限性

    Tables as Images? Exploring the Strengths and Limitations of LLMs on Multimodal Representations of Tabular Data

    [https://arxiv.org/abs/2402.12424](https://arxiv.org/abs/2402.12424)

    本研究探讨了LLM在解释表格数据方面的有效性，比较了文本和图像表格表示对LLM性能的影响，为在表格相关任务上有效使用LLM提供了见解。

    

    在本文中，我们通过不同的提示策略和数据格式研究了各种LLM在解释表格数据方面的有效性。我们的分析涵盖了六个针对与表格相关任务的基准，如问答和事实核查。我们首次介绍了LLM在基于图像的表格表示上的表现评估。具体地，我们比较了五种基于文本和三种基于图像的表格表示，展示了表示和提示对LLM性能的影响。我们的研究为在表格相关任务上有效使用LLM提供了见解。

    arXiv:2402.12424v1 Announce Type: cross  Abstract: In this paper, we investigate the effectiveness of various LLMs in interpreting tabular data through different prompting strategies and data formats. Our analysis extends across six benchmarks for table-related tasks such as question-answering and fact-checking. We introduce for the first time the assessment of LLMs' performance on image-based table representations. Specifically, we compare five text-based and three image-based table representations, demonstrating the influence of representation and prompting on LLM performance. Our study provides insights into the effective use of LLMs on table-related tasks.
    
[^158]: 强健的智能体学习因果世界模型

    Robust agents learn causal world models

    [https://arxiv.org/abs/2402.10877](https://arxiv.org/abs/2402.10877)

    智能体必须学习因果模型才能在广泛的分布转变下达到后悔界限，这对迁移学习和因果推断等研究领域有重要影响。

    

    一直有人假设因果推理在强健且具有通用智能中起着基础作用，然而不清楚智能体是否必须学习因果模型才能推广到新的领域，或者其他归纳偏差是否足够。我们回答了这个问题，表明任何能够在大量分布转变下满足后悔界限的智能体必须学习数据生成过程的近似因果模型，对于优化智能体来说，该近似模型会收敛到真实的因果模型。我们讨论了这一结果对于多个研究领域，包括迁移学习和因果推断的影响。

    arXiv:2402.10877v1 Announce Type: new  Abstract: It has long been hypothesised that causal reasoning plays a fundamental role in robust and general intelligence. However, it is not known if agents must learn causal models in order to generalise to new domains, or if other inductive biases are sufficient. We answer this question, showing that any agent capable of satisfying a regret bound under a large set of distributional shifts must have learned an approximate causal model of the data generating process, which converges to the true causal model for optimal agents. We discuss the implications of this result for several research areas including transfer learning and causal inference.
    
[^159]: 一种具有长期上下文概要记忆的人工智能阅读代理

    A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts

    [https://arxiv.org/abs/2402.09727](https://arxiv.org/abs/2402.09727)

    ReadAgent是一个具有长期上下文概要记忆的阅读代理系统，通过实现一个简单的提示系统，它能够处理长输入并提高有效上下文长度。在评估中表现良好。

    

    当前的大型语言模型不仅限制在某个最大上下文长度内，而且无法稳定地处理长输入。为了解决这些限制，我们提出了ReadAgent，一个增加了有效上下文长度的语言模型代理系统，在我们的实验中可以达到20倍。受到人类交互式阅读长文档的启发，我们将ReadAgent实现为一个简单的提示系统，利用LLM的高级语言能力来：（1）决定将哪些内容存储在一个记忆片段中，（2）将这些记忆片段压缩成为称为概要记忆的短时记忆，（3）在需要时通过原始文本查找段落来提醒自己相关细节以完成任务。我们使用检索方法、使用原始长上下文以及使用概要记忆来评估ReadAgent与基线的性能。这些评估是在三个长文档阅读理解任务上进行的。

    arXiv:2402.09727v1 Announce Type: cross  Abstract: Current Large Language Models (LLMs) are not only limited to some maximum context length, but also are not able to robustly consume long inputs. To address these limitations, we propose ReadAgent, an LLM agent system that increases effective context length up to 20x in our experiments. Inspired by how humans interactively read long documents, we implement ReadAgent as a simple prompting system that uses the advanced language capabilities of LLMs to (1) decide what content to store together in a memory episode, (2) compress those memory episodes into short episodic memories called gist memories, and (3) take actions to look up passages in the original text if ReadAgent needs to remind itself of relevant details to complete a task. We evaluate ReadAgent against baselines using retrieval methods, using the original long contexts, and using the gist memories. These evaluations are performed on three long-document reading comprehension task
    
[^160]: 朝着更好的人机对齐方向：评估LLM驱动应用中的任务效用

    Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications

    [https://arxiv.org/abs/2402.09015](https://arxiv.org/abs/2402.09015)

    本研究引入了AgentEval框架，用于评估LLM驱动应用的任务效用。该框架通过自动提出一套针对特定应用的评估标准，简化了效用验证过程，并对应用的效用进行了全面量化分析。

    

    大型语言模型（LLM）领域的快速发展导致了一系列应用的出现，这些应用通过协助多个代理人与人类合作，帮助人们完成日常任务。然而，目前仍存在一个重大问题，即如何评估LLM驱动应用是否真正提升用户体验和任务执行效率。这凸显了验证LLM驱动应用效用的方法的迫切需求，特别是要确保应用程序的功能与最终用户的需求相一致。我们引入了AgentEval，它提供了一个实施数学问题的估测模型，这是一个新的框架，旨在通过自动提出一套针对任何给定应用程序独特目标的评估标准，简化效用验证过程。这样可以对应用程序的效用进行全面评估，并量化其与建议标准相比的表现。我们对该框架的稳健性进行了全面的分析。

    arXiv:2402.09015v1 Announce Type: cross Abstract: The rapid development in the field of Large Language Models (LLMs) has led to a surge in applications that facilitate collaboration among multiple agents to assist humans in their daily tasks. However, a significant gap remains in assessing whether LLM-powered applications genuinely enhance user experience and task execution efficiency. This highlights the pressing need for methods to verify utility of LLM-powered applications, particularly by ensuring alignment between the application's functionality and end-user needs. We introduce AgentEval provides an implementation for the math problems}, a novel framework designed to simplify the utility verification process by automatically proposing a set of criteria tailored to the unique purpose of any given application. This allows for a comprehensive assessment, quantifying the utility of an application against the suggested criteria. We present a comprehensive analysis of the robustness of 
    
[^161]: UFO: 一个专注于Windows操作系统交互的用户界面智能体

    UFO: A UI-Focused Agent for Windows OS Interaction

    [https://arxiv.org/abs/2402.07939](https://arxiv.org/abs/2402.07939)

    UFO是一个专注于Windows操作系统上应用程序的用户界面智能体，利用GPT-Vision的能力来满足用户需求。它通过观察和分析Windows应用程序的图形用户界面和控制信息，实现无缝导航和操作以满足用户的请求。UFO的控制交互模块使得无需人工干预即可实现动作连接和完全自动化执行，使繁琐和耗时的过程变为简单任务。经过测试，UFO在各种场景中取得了良好效果。

    

    我们介绍了UFO，一个创新的专注于Windows操作系统上应用程序的用户界面智能体，利用了GPT-Vision的能力来满足用户需求。UFO采用双智能体框架，精确观察和分析Windows应用程序的图形用户界面（GUI）和控制信息。这使得智能体可以无缝地在单个应用程序内以及跨应用程序进行导航和操作，以满足用户的需求，即使涉及多个应用程序。该框架包括一个控制交互模块，实现无需人工干预的动作连接，并实现完全自动化执行。因此，UFO将艰巨而耗时的过程转变为仅通过自然语言命令就可以完成的简单任务。我们在9个流行的Windows应用程序上对UFO进行了测试，涵盖了反映用户日常使用情景的各种情况。通过定量指标和真实案例研究得出的结果强调了UFO的效果。

    We introduce UFO, an innovative UI-Focused agent to fulfill user requests tailored to applications on Windows OS, harnessing the capabilities of GPT-Vision. UFO employs a dual-agent framework to meticulously observe and analyze the graphical user interface (GUI) and control information of Windows applications. This enables the agent to seamlessly navigate and operate within individual applications and across them to fulfill user requests, even when spanning multiple applications. The framework incorporates a control interaction module, facilitating action grounding without human intervention and enabling fully automated execution. Consequently, UFO transforms arduous and time-consuming processes into simple tasks achievable solely through natural language commands. We conducted testing of UFO across 9 popular Windows applications, encompassing a variety of scenarios reflective of users' daily usage. The results, derived from both quantitative metrics and real-case studies, underscore t
    
[^162]: 为帮助中国Python编程学习者提供的一个带有注释的问答数据集

    QACP: An Annotated Question Answering Dataset for Assisting Chinese Python Programming Learners

    [https://arxiv.org/abs/2402.07913](https://arxiv.org/abs/2402.07913)

    为解决编程智能教育系统中数据稀缺问题，本文提出了一个新的针对Python学习者的中文问答数据集，通过收集与分类真实学生问题，提高在线编程教育的效果和质量。

    

    在在线学习平台中，特别是在快速增长的计算机编程课程中，解答成千上万学生的学习问题需要相当大的人力成本。为编程教育定制智能助手大型语言模型（LLMs）的创建需要独特的数据支持。然而，在实际应用场景中，用于训练此类LLMs的数据资源相对稀缺。因此，为了解决编程智能教育系统中的数据稀缺问题，本文提出了一个新的针对Python学习者的中文问答数据集。为确保问题的来源的真实性和可靠性，我们收集了实际学生提出的问题，并根据问题的类型和学习者的类型进行分类。这种注释原则旨在提高在线编程教育的效果和质量，为开发这方面的工作提供坚实的数据基础。

    In online learning platforms, particularly in rapidly growing computer programming courses, addressing the thousands of students' learning queries requires considerable human cost. The creation of intelligent assistant large language models (LLMs) tailored for programming education necessitates distinct data support. However, in real application scenarios, the data resources for training such LLMs are relatively scarce. Therefore, to address the data scarcity in intelligent educational systems for programming, this paper proposes a new Chinese question-and-answer dataset for Python learners. To ensure the authenticity and reliability of the sources of the questions, we collected questions from actual student questions and categorized them according to various dimensions such as the type of questions and the type of learners. This annotation principle is designed to enhance the effectiveness and quality of online programming education, providing a solid data foundation for developing th
    
[^163]: 在线顺序决策中的未知延迟问题

    Online Sequential Decision-Making with Unknown Delays

    [https://arxiv.org/abs/2402.07703](https://arxiv.org/abs/2402.07703)

    本文提出了在在线顺序决策中处理未知延迟问题的三个延迟算法族，并提供了相应的遗憾界限。

    

    在在线顺序决策领域，我们利用在线凸优化（OCO）框架解决了具有延迟的问题，其中决策的反馈可能以未知延迟到达。与之前仅限于欧几里得范数和梯度信息的研究不同，我们提出了三个基于近似解的延迟算法族，处理不同类型的接收反馈。我们提出的算法是多功能且适用于通用范数。具体地，我们引入了一系列针对具有完整损失函数信息反馈的延迟规范化领导算法族，一系列针对具有梯度信息反馈的延迟镜像下降算法族，以及一系列针对相应决策点损失函数梯度值信息反馈的简化延迟镜像下降算法族。对于每种类型的算法，我们提供了相应的遗憾界限。

    In the field of online sequential decision-making, we address the problem with delays utilizing the framework of online convex optimization (OCO), where the feedback of a decision can arrive with an unknown delay. Unlike previous research that is limited to Euclidean norm and gradient information, we propose three families of delayed algorithms based on approximate solutions to handle different types of received feedback. Our proposed algorithms are versatile and applicable to universal norms. Specifically, we introduce a family of Follow the Delayed Regularized Leader algorithms for feedback with full information on the loss function, a family of Delayed Mirror Descent algorithms for feedback with gradient information on the loss function and a family of Simplified Delayed Mirror Descent algorithms for feedback with the value information of the loss function's gradients at corresponding decision points. For each type of algorithm, we provide corresponding regret bounds under cases of 
    
[^164]: 大型代码模型是否理解编程概念？一种黑盒方法探究

    Do Large Code Models Understand Programming Concepts? A Black-box Approach

    [https://arxiv.org/abs/2402.05980](https://arxiv.org/abs/2402.05980)

    本文使用反事实分析框架评估了十个大型代码模型对四种编程概念的理解情况，发现当前模型缺乏对数据流和控制流等概念的理解。

    

    大型语言模型在文本生成方面的成功也使其在代码生成和编码任务方面表现更好。虽然有很多工作展示了它们在代码补全和编辑等任务上的出色性能，但为什么它们能够成功还不清楚。我们通过探索自回归模型对底层程序的逻辑结构理解程度，来填补这一差距。我们提出了用于编程概念谓词的反事实分析（CACP）作为一种反事实测试框架，以评估大型代码模型是否理解编程概念。只通过黑盒访问模型，我们使用CACP评估了十个流行的大型代码模型对四个不同编程概念的理解情况。我们的研究结果表明，当前模型缺乏对数据流和控制流等概念的理解。

    Large Language Models' success on text generation has also made them better at code generation and coding tasks. While a lot of work has demonstrated their remarkable performance on tasks such as code completion and editing, it is still unclear as to why. We help bridge this gap by exploring to what degree auto-regressive models understand the logical constructs of the underlying programs. We propose Counterfactual Analysis for Programming Concept Predicates (CACP) as a counterfactual testing framework to evaluate whether Large Code Models understand programming concepts. With only black-box access to the model, we use CACP to evaluate ten popular Large Code Models for four different programming concepts. Our findings suggest that current models lack understanding of concepts such as data flow and control flow.
    
[^165]: KICGPT: 具备上下文知识的大型语言模型用于知识图谱补全

    KICGPT: Large Language Model with Knowledge in Context for Knowledge Graph Completion

    [https://arxiv.org/abs/2402.02389](https://arxiv.org/abs/2402.02389)

    本文提出了KICGPT，它是一个集成了大型语言模型和基于三元组的知识图谱补全检索器的框架。它通过知识提示的上下文学习策略，缓解了长尾问题，并且无需额外的训练开销。实验证明了其有效性。

    

    知识图谱补全对于解决知识图谱不完整性和支持下游应用至关重要。已经提出了许多用于知识图谱补全的模型，它们可以分为基于三元组和基于文本的方法两类。基于三元组的方法由于结构信息有限和实体分布不均衡而困难重重。基于文本的方法可以缓解这个问题，但需要昂贵的语言模型训练和特定的知识图谱微调，从而限制了其效率。为了解决这些限制，本文提出了KICGPT，一种集成了大型语言模型(LLM)和基于三元组的知识图谱补全检索器的框架。它可以缓解长尾问题，而不会增加额外的训练开销。KICGPT使用了一种上下文学习策略，称为知识提示，它将结构知识编码为演示，以引导LLM的学习。在基准数据集上的实证结果证明了其有效性。

    Knowledge Graph Completion (KGC) is crucial for addressing knowledge graph incompleteness and supporting downstream applications. Many models have been proposed for KGC. They can be categorized into two main classes: triple-based and text-based approaches. Triple-based methods struggle with long-tail entities due to limited structural information and imbalanced entity distributions. Text-based methods alleviate this issue but require costly training for language models and specific finetuning for knowledge graphs, which limits their efficiency. To alleviate these limitations, in this paper, we propose KICGPT, a framework that integrates a large language model (LLM) and a triple-based KGC retriever. It alleviates the long-tail problem without incurring additional training overhead. KICGPT uses an in-context learning strategy called Knowledge Prompt, which encodes structural knowledge into demonstrations to guide the LLM. Empirical results on benchmark datasets demonstrate the effectiven
    
[^166]: 在分析课堂对话时评估大型语言模型

    Evaluating Large Language Models in Analysing Classroom Dialogue

    [https://arxiv.org/abs/2402.02380](https://arxiv.org/abs/2402.02380)

    本研究评估了大型语言模型（LLMs），特点是GPT-4，对课堂对话进行分析的应用。结果显示，GPT-4能够显著节省时间，且在编码一致性方面表现出很高的一致性。

    

    本研究探讨了大型语言模型（LLM），特别是GPT-4，在分析课堂对话中的应用，这是教学诊断和质量改进的重要研究任务。鉴于传统教育研究中知识密集和劳动密集的定性方法，本研究调查了LLM在优化和增强分析过程方面的潜力。该研究涉及中学的数据集，包括数学和语文课堂上的对话。这些对话由教育专家手动编码，然后使用定制的GPT-4模型进行分析。本研究侧重于比较手动注释与GPT-4的输出，以评估其在分析教育对话方面的效果。评估时间效率、编码者间一致性和编码者间可靠性之间的差异。结果表明，使用GPT-4可以显著节省时间，并在编码一致性方面具有很高的一致性。

    This study explores the application of Large Language Models (LLMs), specifically GPT-4, in the analysis of classroom dialogue, a crucial research task for both teaching diagnosis and quality improvement. Recognizing the knowledge-intensive and labor-intensive nature of traditional qualitative methods in educational research, this study investigates the potential of LLM to streamline and enhance the analysis process. The study involves datasets from a middle school, encompassing classroom dialogues across mathematics and Chinese classes. These dialogues were manually coded by educational experts and then analyzed using a customised GPT-4 model. This study focuses on comparing manual annotations with the outputs of GPT-4 to evaluate its efficacy in analyzing educational dialogues. Time efficiency, inter-coder agreement, and inter-coder reliability between human coders and GPT-4 are evaluated. Results indicate substantial time savings with GPT-4, and a high degree of consistency in codin
    
[^167]: 使用SplitK工作分解加速W4A16量化推断的Triton融合内核

    Accelerating a Triton Fused Kernel for W4A16 Quantized Inference with SplitK work decomposition

    [https://arxiv.org/abs/2402.00025](https://arxiv.org/abs/2402.00025)

    本研究提出了一种加速W4A16量化推断的Triton融合内核的实现方法，通过使用SplitK工作分解实现解量化和GEMM操作，显著提高了瘦矩阵乘法的执行速度。

    

    我们提出了一种有效的融合矩阵乘法内核的实现，用于W4A16量化推断，在融合内核中执行解量化和GEMM操作，并使用SplitK工作分解。我们的实现对于基于foundation模型推断工作负载中的瘦矩阵乘法有所改进。具体而言，本文调查了瘦激活矩阵和方形权重矩阵之间的矩阵乘法类型。我们的结果显示，在一系列矩阵维度（包括llama-style模型中的维度，其中m < n = k）上，A100的平均速度提升了65％，H100的平均速度提升了124％（峰值为295％）。

    We propose an implementation of an efficient fused matrix multiplication kernel for W4A16 quantized inference, where we perform dequantization and GEMM in a fused kernel using a SplitK work decomposition. Our implementation shows improvement for the type of skinny matrix-matrix multiplications found in foundation model inference workloads. In particular, this paper surveys the type of matrix multiplication between a skinny activation matrix and a square weight matrix. Our results show an average of 65% speed improvement on A100, and an average of 124% speed improvement on H100 (with a peak of 295%) for a range of matrix dimensions including those found in a llama-style model, where m < n = k.
    
[^168]: 迭代优化启发式方法可解释性基准测试

    Explainable Benchmarking for Iterative Optimization Heuristics

    [https://arxiv.org/abs/2401.17842](https://arxiv.org/abs/2401.17842)

    本文介绍了一种称为可解释基准测试的新方法，并提出了IOH-Xplainer软件框架，用于分析和理解优化算法的性能和影响。通过该框架，研究人员可以评估和解释迭代优化启发式方法在不同场景下的行为和效率。

    

    启发式算法的基准测试对于理解在什么条件下以及在何种问题上某些算法表现良好至关重要。目前大部分对启发式优化算法的研究只探索了非常有限的场景、算法配置和超参数设置，导致了不完整且常常有偏见的见解和结果。本文提出了一种新的方法，称之为可解释基准测试。介绍了IOH-Xplainer软件框架，用于分析和理解各种优化算法的性能以及它们不同组件和超参数的影响。我们在两个模块化优化框架的背景下展示了该框架。通过该框架，我们研究不同算法组件和配置的影响，提供了它们在不同场景下的性能见解。我们提供了一种系统的方法来评估和解释迭代优化启发式方法的行为和效率。

    Benchmarking heuristic algorithms is vital to understand under which conditions and on what kind of problems certain algorithms perform well. In most current research into heuristic optimization algorithms, only a very limited number of scenarios, algorithm configurations and hyper-parameter settings are explored, leading to incomplete and often biased insights and results. This paper presents a novel approach we call explainable benchmarking. Introducing the IOH-Xplainer software framework, for analyzing and understanding the performance of various optimization algorithms and the impact of their different components and hyper-parameters. We showcase the framework in the context of two modular optimization frameworks. Through this framework, we examine the impact of different algorithmic components and configurations, offering insights into their performance across diverse scenarios. We provide a systematic method for evaluating and interpreting the behaviour and efficiency of iterativ
    
[^169]: 不带位置编码的图变压器

    Graph Transformers without Positional Encodings

    [https://arxiv.org/abs/2401.17791](https://arxiv.org/abs/2401.17791)

    本文介绍了一种不需要位置编码的图变压器模型，该模型通过注意机制本身包含图结构信息，并通过实验证明了其有效性。

    

    最近，用于图表示学习的变压器越来越受欢迎，在各种数据集上取得了最先进的性能，无论是单独使用还是与消息传递图神经网络（MP-GNN）结合。将图归纳偏见融入天然与结构无关的变压器架构中，以结构或位置编码（PEs）的形式，是实现这些令人印象深刻的结果的关键。然而，设计这样的编码是棘手的，人们已经提出了不同的尝试来设计这样的编码，包括拉普拉斯特征向量、相对随机行走概率（RRWP）、空间编码、中心度编码、边缘编码等。在这项工作中，我们认为这些编码可能根本不需要，只要注意机制本身包含有关图结构的信息。我们介绍了Eigenformer，它使用一种新颖的谱感知注意机制，了解图的拉普拉斯谱，并通过实验证明

    Recently, Transformers for graph representation learning have become increasingly popular, achieving state-of-the-art performance on a wide-variety of datasets, either alone or in combination with message-passing graph neural networks (MP-GNNs). Infusing graph inductive-biases in the innately structure-agnostic transformer architecture in the form of structural or positional encodings (PEs) is key to achieving these impressive results. However, designing such encodings is tricky and disparate attempts have been made to engineer such encodings including Laplacian eigenvectors, relative random-walk probabilities (RRWP), spatial encodings, centrality encodings, edge encodings etc. In this work, we argue that such encodings may not be required at all, provided the attention mechanism itself incorporates information about the graph structure. We introduce Eigenformer, which uses a novel spectrum-aware attention mechanism cognizant of the Laplacian spectrum of the graph, and empirically show
    
[^170]: 重新思考多元时间序列预测的通道相关性：从领先指标中学习

    Rethinking Channel Dependence for Multivariate Time Series Forecasting: Learning from Leading Indicators

    [https://arxiv.org/abs/2401.17548](https://arxiv.org/abs/2401.17548)

    本文提出了一种新方法，LIFT，通过利用通道相关性和领先指标，为多元时间序列预测提供准确的预测。LIFT方法可以无缝与任意时间序列预测方法协作，大量实验证明了其有效性。

    

    最近，独立于通道的方法在多元时间序列（MTS）预测中取得了最先进的性能。尽管这些方法减少了过拟合的风险，但它们错过了利用通道相关性进行准确预测的潜在机会。我们认为，在变量之间存在局部平稳的领先-滞后关系，即一些滞后变量在短时间内可能遵循领先指标。利用这种通道相关性是有益的，因为领先指标提供了先进信息，可以用来减少滞后变量的预测难度。在本文中，我们提出了一种名为LIFT的新方法，该方法首先在每个时间步骤高效地估计领先指标及其领先步骤，然后巧妙地允许滞后变量利用来自领先指标的先进信息。LIFT作为一个插件，可以与任意时间序列预测方法无缝协作。进行了大量实验证明了LIFT方法的有效性。

    Recently, channel-independent methods have achieved state-of-the-art performance in multivariate time series (MTS) forecasting. Despite reducing overfitting risks, these methods miss potential opportunities in utilizing channel dependence for accurate predictions. We argue that there exist locally stationary lead-lag relationships between variates, i.e., some lagged variates may follow the leading indicators within a short time period. Exploiting such channel dependence is beneficial since leading indicators offer advance information that can be used to reduce the forecasting difficulty of the lagged variates. In this paper, we propose a new method named LIFT that first efficiently estimates leading indicators and their leading steps at each time step and then judiciously allows the lagged variates to utilize the advance information from leading indicators. LIFT plays as a plugin that can be seamlessly collaborated with arbitrary time series forecasting methods. Extensive experiments o
    
[^171]: PythonSaga：重新定义评估代码生成LLM的基准

    PythonSaga: Redefining the Benchmark to Evaluate Code Generating LLM

    [https://arxiv.org/abs/2401.03855](https://arxiv.org/abs/2401.03855)

    PythonSaga提出了一种新的基准，针对Python代码生成进行评估,弥补了现有基准存在的编程概念偏见和简单任务普遍性的问题

    

    受到使用大型语言模型(LLMs)生成代码激增的推动，出现了许多基准用于评估这些LLMs的功能。我们对HumanEval和MBPP两个流行的Python代码生成基准进行了大规模人工评估，分析了它们的多样性和难度。我们的研究揭示了对一组有限的编程概念存在严重偏见，完全忽视了大多数其他概念。此外，我们发现了大量简单任务的普遍存在，可能夸大了模型性能的估计。为了解决这些限制，我们提出了一种新颖的基准，PythonSaga，包含了185个手工制作的提示，涵盖了38个不同难度级别的编程概念。

    arXiv:2401.03855v2 Announce Type: replace-cross  Abstract: Driven by the surge in code generation using large language models (LLMs), numerous benchmarks have emerged to evaluate these LLMs capabilities. We conducted a large-scale human evaluation of HumanEval and MBPP, two popular benchmarks for Python code generation, analyzing their diversity and difficulty. Our findings unveil a critical bias towards a limited set of programming concepts, neglecting most of the other concepts entirely. Furthermore, we uncover a worrying prevalence of easy tasks, potentially inflating model performance estimations. To address these limitations, we propose a novel benchmark, PythonSaga, featuring 185 hand-crafted prompts on a balanced representation of 38 programming concepts across diverse difficulty levels.
    
[^172]: 探索ChatGPT在古代汉语翻译和人名识别中的能力

    Exploring the Capabilities of ChatGPT in Ancient Chinese Translation and Person Name Recognition

    [https://arxiv.org/abs/2312.15304](https://arxiv.org/abs/2312.15304)

    本论文探索了ChatGPT在古代汉语翻译和人名识别方面的能力，并发现其在翻译方面的表现仍有待提高，最佳表现是在输入三个上下文句子时实现的。

    

    ChatGPT在处理现代标准语言方面的熟练表明其具有潜力用于理解古代汉语。本文通过两项任务探讨了ChatGPT在古代汉语方面的能力：将古代汉语翻译为现代汉语和识别古代汉语人名。通过将ChatGPT的输出与人类翻译进行比较，评估其对古代汉语的理解。研究发现：（1.）ChatGPT对古代汉语的熟练程度尚未达到令人满意的水平；（2.）在输入三个上下文句子时，ChatGPT在古代汉语到现代汉语的翻译中表现最佳。为了帮助重现我们的工作，我们展示了本研究中使用的Python代码片段。

    arXiv:2312.15304v2 Announce Type: replace-cross  Abstract: ChatGPT's proficiency in handling modern standard languages suggests potential for its use in understanding ancient Chinese. This paper explores ChatGPT's capabilities on ancient Chinese via two tasks: translating ancient Chinese to modern Chinese and recognizing ancient Chinese names. A comparison of ChatGPT's output with human translations serves to evaluate its comprehension of ancient Chinese. The findings indicate that: (1.)the proficiency of ancient Chinese by ChatGPT is yet to reach a satisfactory level; (2.) ChatGPT performs the best on ancient-to-modern translation when feeding with three context sentences. To help reproduce our work, we display the python code snippets used in this study.
    
[^173]: 许多智能体POMDP中的分解在线规划

    Factored Online Planning in Many-Agent POMDPs

    [https://arxiv.org/abs/2312.11434](https://arxiv.org/abs/2312.11434)

    该论文提出了一种针对多智能体POMDP的分解在线规划方法，通过引入加权粒子滤波和可扩展的信念逼近方法解决了值估计和信念估计难题。

    

    在集中式多智能体系统中，通常被建模为多智能体部分可观察马尔可夫决策过程（MPOMDPs），动作和观测空间随智能体数量呈指数增长，导致单智能体在线规划的价值和信念估计变得无效。先前的工作通过利用所谓的协调图来部分解决价值估计，进一步通过将观测概率纳入逼近中改进了信念估计方法。然而，价值估计和信念估计的挑战仅被单独处理，这阻止了现有方法扩展到具有许多智能体的情境。因此，我们同时解决了这些挑战。首先，我们将加权粒子滤波引入了用于MPOMDP的基于样本的在线规划器。其次，我们提出了一种可扩展的信念逼近方法。

    arXiv:2312.11434v3 Announce Type: replace  Abstract: In centralized multi-agent systems, often modeled as multi-agent partially observable Markov decision processes (MPOMDPs), the action and observation spaces grow exponentially with the number of agents, making the value and belief estimation of single-agent online planning ineffective. Prior work partially tackles value estimation by exploiting the inherent structure of multi-agent settings via so-called coordination graphs. Additionally, belief estimation methods have been improved by incorporating the likelihood of observations into the approximation. However, the challenges of value estimation and belief estimation have only been tackled individually, which prevents existing methods from scaling to settings with many agents. Therefore, we address these challenges simultaneously. First, we introduce weighted particle filtering to a sample-based online planner for MPOMDPs. Second, we present a scalable approximation of the belief. T
    
[^174]: 重新审视标签平滑在增强文本情感分类中的作用

    Revisiting the Role of Label Smoothing in Enhanced Text Sentiment Classification

    [https://arxiv.org/abs/2312.06522](https://arxiv.org/abs/2312.06522)

    通过在文本情感分类中进行深入分析，发现标签平滑可以加速深度模型的收敛，并使不同标签的样本更容易区分

    

    标签平滑是一种广泛应用于各个领域的技术，如文本分类、图像分类和语音识别，以有效对抗模型过拟合而闻名。然而，对于标签平滑如何增强文本情感分类的细致分析却很少。为了填补这一空白，本文在八个文本情感分类数据集和三种深度学习架构（TextCNN、BERT和RoBERTa）以及两种学习方案下进行了一系列深入分析。通过调整平滑参数，我们可以在每个模型架构的几乎所有数据集上实现性能提升。我们进一步研究了标签平滑的好处，发现标签平滑可以加速深度模型的收敛，并使不同标签的样本更容易区分。

    arXiv:2312.06522v2 Announce Type: replace-cross  Abstract: Label smoothing is a widely used technique in various domains, such as text classification, image classification and speech recognition, known for effectively combating model overfitting. However, there is little fine-grained analysis on how label smoothing enhances text sentiment classification. To fill in the gap, this article performs a set of in-depth analyses on eight datasets for text sentiment classification and three deep learning architectures: TextCNN, BERT, and RoBERTa, under two learning schemes: training from scratch and fine-tuning. By tuning the smoothing parameters, we can achieve improved performance on almost all datasets for each model architecture. We further investigate the benefits of label smoothing, finding that label smoothing can accelerate the convergence of deep models and make samples of different labels easily distinguishable.
    
[^175]: 在序贯决策中记住公平：非马尔可夫公平性

    Remembering to Be Fair: Non-Markovian Fairness in Sequential Decision Making

    [https://arxiv.org/abs/2312.04772](https://arxiv.org/abs/2312.04772)

    本文研究了在序贯决策过程中的非马尔可夫公平性，发现公平往往取决于历史，需要在过程中的不同时间点进行评估。

    

    公平的决策制定在很大程度上是针对单一决策进行研究的。本文在多个利益相关者可能受到决策结果影响的情况下，研究了顺序决策中的公平概念。我们观察到，公平往往取决于顺序决策过程的历史，从这个意义上讲，它是固有的非马尔可夫性。我们进一步观察到，公平通常需要在过程中的某个时间点进行评估，而不仅仅是在过程结束时。为了推进我们对这类公平性问题的理解，我们探讨了顺序决策背景下非马尔可夫公平的概念。我们确定了非马尔可夫公平的属性，包括长期公平性、任意时刻公平性、周期性公平性和有界公平性等概念。我们进一步探讨了非马尔可夫公平性和记忆之间的相互作用，以及这如何支持制定公平政策。

    arXiv:2312.04772v3 Announce Type: replace  Abstract: Fair decision making has largely been studied with respect to a single decision. In this paper we investigate the notion of fairness in the context of sequential decision making where multiple stakeholders can be affected by the outcomes of decisions. We observe that fairness often depends on the history of the sequential decision-making process, and in this sense that it is inherently non-Markovian. We further observe that fairness often needs to be assessed at time points within the process, not just at the end of the process. To advance our understanding of this class of fairness problems, we explore the notion of non-Markovian fairness in the context of sequential decision making. We identify properties of non-Markovian fairness, including notions of long-term, anytime, periodic, and bounded fairness. We further explore the interplay between non-Markovian fairness and memory, and how this can support construction of fair policies
    
[^176]: 基于接触能量的事后经验优先级排序

    Contact Energy Based Hindsight Experience Prioritization

    [https://arxiv.org/abs/2312.02677](https://arxiv.org/abs/2312.02677)

    本文提出了一种基于接触能量的优先级排序方法（CEBP），用于解决强化学习算法中选择具有丰富接触信息的样本以提高学习效率的问题。

    

    具有稀疏奖励的多目标机器人操作任务对于强化学习（RL）算法而言是困难的，原因在于收集成功经验的低效性。最近的算法，如事后经验重放（HER），通过利用失败的轨迹并将期望目标替换为已实现状态之一来加快学习，使得任何失败的轨迹都可以被利用作为学习的一部分。然而，HER会均匀选择失败的轨迹，而不考虑哪些可能对学习最有价值。在本文中，我们解决了这个问题，并提出了一种新颖的方法Contact Energy Based Prioritization~(CEBP)，根据接触的丰富信息从重放缓冲区中选择样本，利用机器人夹爪和物体位移中的触觉传感器。我们的优先级方案偏向于采样接触丰富的经验，这些经验可以被认为是最有价值的。

    arXiv:2312.02677v2 Announce Type: replace-cross  Abstract: Multi-goal robot manipulation tasks with sparse rewards are difficult for reinforcement learning (RL) algorithms due to the inefficiency in collecting successful experiences. Recent algorithms such as Hindsight Experience Replay (HER) expedite learning by taking advantage of failed trajectories and replacing the desired goal with one of the achieved states so that any failed trajectory can be utilized as a contribution to learning. However, HER uniformly chooses failed trajectories, without taking into account which ones might be the most valuable for learning. In this paper, we address this problem and propose a novel approach Contact Energy Based Prioritization~(CEBP) to select the samples from the replay buffer based on rich information due to contact, leveraging the touch sensors in the gripper of the robot and object displacement. Our prioritization scheme favors sampling of contact-rich experiences, which are arguably the
    
[^177]: InteRACT：基于机器人动作的人类意图预测的Transformer模型

    InteRACT: Transformer Models for Human Intent Prediction Conditioned on Robot Actions

    [https://arxiv.org/abs/2311.12943](https://arxiv.org/abs/2311.12943)

    InteRACT通过在大型人类-人类数据集上预训练条件意图预测模型，并在小型人机数据集上微调，解决了人机交互中的先有鸡还是先有蛋问题。

    

    在协作的人机操纵中，机器人必须预测人类意图并相应调整其行动，以平稳执行任务。然而，人类的意图反过来又取决于机器人采取的动作，造成了一个先有鸡还是先有蛋的问题。先前的方法忽略了这种相互依赖关系，而是训练独立于机器人行动的边际意图预测模型。这是因为在缺乏配对的人机交互数据集的情况下，训练条件模型是困难的。我们能否转而利用更容易获取的大规模人类-人类交互数据？我们的关键见解是利用人类和机器人行动之间的对应关系，实现从人类-人类到人类-机器人数据的迁移学习。我们提出了一种新颖的架构InteRACT，该架构在大型人类-人类数据集上预训练条件意图预测模型，并在小型人机数据集上进行微调。我们在一组真实世界的协作数据上进行评估。

    arXiv:2311.12943v2 Announce Type: replace-cross  Abstract: In collaborative human-robot manipulation, a robot must predict human intents and adapt its actions accordingly to smoothly execute tasks. However, the human's intent in turn depends on actions the robot takes, creating a chicken-or-egg problem. Prior methods ignore such inter-dependency and instead train marginal intent prediction models independent of robot actions. This is because training conditional models is hard given a lack of paired human-robot interaction datasets. Can we instead leverage large-scale human-human interaction data that is more easily accessible? Our key insight is to exploit a correspondence between human and robot actions that enables transfer learning from human-human to human-robot data. We propose a novel architecture, InteRACT, that pre-trains a conditional intent prediction model on large human-human datasets and fine-tunes on a small human-robot dataset. We evaluate on a set of real-world collabo
    
[^178]: 使用H.264运动矢量实现高效的时域感知DeepFake检测

    Efficient Temporally-Aware DeepFake Detection using H.264 Motion Vectors

    [https://arxiv.org/abs/2311.10788](https://arxiv.org/abs/2311.10788)

    使用H.264视频编解码器中的运动矢量和信息掩模来检测DeepFake的时域不一致，有效且计算成本低，可能为视频通话和流媒体提供新的实时DeepFake检测方法

    

    视频DeepFake是使用深度学习（DL）创建的虚假媒体，可操纵人的表情或身份。大多数当前的DeepFake检测方法独立分析每一帧，忽略帧间的不一致和不自然运动。一些较新的方法利用光流模型捕捉这种时序方面，但计算成本高昂。相比之下，我们提出使用来自H.264视频编解码器的相关但常被忽视的运动矢量（MVs）和信息掩模（IMs）来检测DeepFake中的时域不一致。我们的实验证明这种方法有效，并且与仅基于每帧RGB的方法相比具有最小的计算成本。这可能会导致新的、实时的时域感知DeepFake检测方法，用于视频通话和流媒体。

    arXiv:2311.10788v2 Announce Type: replace-cross  Abstract: Video DeepFakes are fake media created with Deep Learning (DL) that manipulate a person's expression or identity. Most current DeepFake detection methods analyze each frame independently, ignoring inconsistencies and unnatural movements between frames. Some newer methods employ optical flow models to capture this temporal aspect, but they are computationally expensive. In contrast, we propose using the related but often ignored Motion Vectors (MVs) and Information Masks (IMs) from the H.264 video codec, to detect temporal inconsistencies in DeepFakes. Our experiments show that this approach is effective and has minimal computational costs, compared with per-frame RGB-only methods. This could lead to new, real-time temporally-aware DeepFake detection methods for video calls and streaming.
    
[^179]: 对抗偏好优化

    Adversarial Preference Optimization

    [https://arxiv.org/abs/2311.08045](https://arxiv.org/abs/2311.08045)

    提出了一种对抗偏好优化（APO）框架，实现了在没有额外注释的情况下，通过对抗学习自适应于生成分布差距。

    

    人类偏好调整是提高大型语言模型（LLMs）交互质量的关键。现有的对齐方法依赖于手动注释的偏好数据来指导LLM的优化方向。然而，在实践中，持续更新LLMs会导致模型生成样本与人类首选响应之间存在分布差距，这阻碍了模型微调的效率。为了缓解这个问题，先前的方法需要在生成的样本上额外进行偏好注释，以适应转移分布，这需要大量的注释资源。针对更高效的人类偏好优化，我们提出了一种对抗偏好优化（APO）框架，其中LLM代理和偏好模型通过极小-极大博弈交替更新。在没有额外注释的情况下，我们的APO方法可以通过对抗学习自适应于生成分布差距。

    arXiv:2311.08045v2 Announce Type: replace-cross  Abstract: Human preference alignment is essential to improve the interaction quality of large language models (LLMs). Existing aligning methods depend on manually annotated preference data to guide the LLM optimization directions. However, in practice, continuously updating LLMs raises a distribution gap between model-generated samples and human-preferred responses, which hinders model fine-tuning efficiency. To mitigate this issue, previous methods require additional preference annotation on generated samples to adapt the shifted distribution, which consumes a large amount of annotation resources. Targeting more efficient human preference optimization, we propose an adversarial preference optimization (APO) framework, where the LLM agent and the preference model update alternatively via a min-max game. Without additional annotation, our APO method can make a self-adaption to the generation distribution gap through the adversarial learni
    
[^180]: 一切的思考：打破彭罗斯三角定律以生成思想

    Everything of Thoughts: Defying the Law of Penrose Triangle for Thought Generation

    [https://arxiv.org/abs/2311.04254](https://arxiv.org/abs/2311.04254)

    引入一种名为“一切的思考”（XoT）的新型思考促进方法，借助预训练的强化学习和蒙特卡洛树搜索（MCTS）将外部领域知识融入思想，从而提高大型语言模型（LLMs）的能力，使其可以高效地推广到未知问题。

    

    最近大型语言模型（LLMs）的进展通过将复杂问题分解为更易处理的语言序列（即“思想”）彻底改变了决策。一个有效的思想设计应该考虑三个关键视角：性能、效率和灵活性。然而，现有的思想最多只能体现这些属性中的两个。为了解决这些限制，我们引入了一种名为“一切的思考”（XoT）的新型思考促进方法，以打破现有思考范式的“彭罗斯三角定律”。XoT利用预训练的强化学习和蒙特卡洛树搜索（MCTS）将外部领域知识融入思想中，从而增强LLMs的能力，并使其能够高效地推广到未见问题。通过利用MCTS-LLM协作思考修订框架，这种方法自主生产高质量的综合认知。

    arXiv:2311.04254v3 Announce Type: replace  Abstract: Recent advancements in Large Language Models (LLMs) have revolutionized decision-making by breaking down complex problems into more manageable language sequences referred to as "thoughts". An effective thought design should consider three key perspectives: performance, efficiency, and flexibility. However, existing thought can at most exhibit two of these attributes. To address these limitations, we introduce a novel thought prompting approach called "Everything of Thoughts" (XoT) to defy the law of "Penrose triangle of existing thought paradigms. XoT leverages pretrained reinforcement learning and Monte Carlo Tree Search (MCTS) to incorporate external domain knowledge into thoughts, thereby enhancing LLMs' capabilities and enabling them to generalize to unseen problems efficiently. Through the utilization of the MCTS-LLM collaborative thought revision framework, this approach autonomously produces high-quality comprehensive cognitiv
    
[^181]: 学习多个动态系统中的联合问题

    Joint Problems in Learning Multiple Dynamical Systems

    [https://arxiv.org/abs/2311.02181](https://arxiv.org/abs/2311.02181)

    聚类时间序列的新问题，提出联合划分轨迹集并学习每个部分的线性动态系统模型，以最小化所有模型的最大误差

    

    时间序列的聚类是一个经过充分研究的问题，其应用范围从通过代谢产物浓度获得的定量个性化代谢模型到量子信息理论中的状态判别。我们考虑了一个变种，即给定一组轨迹和一些部分，我们联合划分轨迹集并学习每个部分的线性动态系统（LDS）模型，以使得所有模型的最大误差最小化。我们提出了全局收敛的方法和EM启发式算法，并附上了有前景的计算结果。

    arXiv:2311.02181v2 Announce Type: replace-cross  Abstract: Clustering of time series is a well-studied problem, with applications ranging from quantitative, personalized models of metabolism obtained from metabolite concentrations to state discrimination in quantum information theory. We consider a variant, where given a set of trajectories and a number of parts, we jointly partition the set of trajectories and learn linear dynamical system (LDS) models for each part, so as to minimize the maximum error across all the models. We present globally convergent methods and EM heuristics, accompanied by promising computational results.
    
[^182]: 卫生保健中的生成人工智能：伦理考虑与评估检查表

    Generative Artificial Intelligence in Healthcare: Ethical Considerations and Assessment Checklist

    [https://arxiv.org/abs/2311.02107](https://arxiv.org/abs/2311.02107)

    对医疗保健中的生成人工智能（GenAI）进行了伦理讨论的范围审查，提出了一份检查表，以推动伦理讨论的全面评估和透明记录。

    

    ChatGPT等新兴技术基于生成人工智能（GenAI）的广泛应用引起了对潜在伦理问题的关注，特别是在高风险应用领域，如医疗保健，但伦理讨论尚未转化为可操作的解决方案。此外，正在进行的伦理讨论常常忽视其他类型的GenAI，这些GenAI已被用于合成数据（例如图像）进行研究和实际目的，从而解决了一些伦理问题并暴露了其他问题。我们进行了一项关于医疗保健中GenAI伦理讨论的范围审查，以全面分析当前研究中的差距，并进一步提议通过制定一份检查表来减少这些差距，以全面评估和透明记录GenAI研究中的伦理讨论。这份检查表可以轻松整合到当前的同行评审和发布系统中，以增强GenAI研究。

    arXiv:2311.02107v2 Announce Type: replace-cross  Abstract: The widespread use of ChatGPT and other emerging technology powered by generative artificial intelligence (GenAI) has drawn much attention to potential ethical issues, especially in high-stakes applications such as healthcare, but ethical discussions are yet to translate into operationalisable solutions. Furthermore, ongoing ethical discussions often neglect other types of GenAI that have been used to synthesise data (e.g., images) for research and practical purposes, which resolved some ethical issues and exposed others. We conduct a scoping review of ethical discussions on GenAI in healthcare to comprehensively analyse gaps in the current research, and further propose to reduce the gaps by developing a checklist for comprehensive assessment and transparent documentation of ethical discussions in GenAI research. The checklist can be readily integrated into the current peer review and publication system to enhance GenAI researc
    
[^183]: 探索微调语言模型中的记忆能力

    Exploring Memorization in Fine-tuned Language Models

    [https://arxiv.org/abs/2310.06714](https://arxiv.org/abs/2310.06714)

    在微调语言模型过程中，该研究首次全面分析了不同任务中模型的记忆现象，发现了记忆在各种微调任务中表现出显著的差异，并通过稀疏编码理论解释了这种任务差异性。

    

    大型语言模型（LLMs）展现出在各种任务中的巨大能力，但同时也表现出对训练数据的记忆，引起了巨大的隐私和版权担忧。 在此工作中，我们进行了首次全面分析，探讨了在各种任务中微调语言模型（LMs）时的记忆现象。 我们使用开源和我们自己的微调LMs进行了研究，结果表明在不同微调任务中，记忆呈现出较强的差异性。 我们通过稀疏编码理论提供了对这种任务差异性的直观解释，并揭示了记忆和注意力分数之间的强相关性。

    arXiv:2310.06714v2 Announce Type: replace  Abstract: Large language models (LLMs) have shown great capabilities in various tasks but also exhibited memorization of training data, raising tremendous privacy and copyright concerns. While prior works have studied memorization during pre-training, the exploration of memorization during fine-tuning is rather limited. Compared to pre-training, fine-tuning typically involves more sensitive data and diverse objectives, thus may bring distinct privacy risks and unique memorization behaviors. In this work, we conduct the first comprehensive analysis to explore language models' (LMs) memorization during fine-tuning across tasks. Our studies with open-sourced and our own fine-tuned LMs across various tasks indicate that memorization presents a strong disparity among different fine-tuning tasks. We provide an intuitive explanation of this task disparity via sparse coding theory and unveil a strong correlation between memorization and attention scor
    
[^184]: FedDefender：联邦学习中的后门攻击防御

    FedDefender: Backdoor Attack Defense in Federated Learning

    [https://arxiv.org/abs/2307.08672](https://arxiv.org/abs/2307.08672)

    FedDefender是一种针对联邦学习中有针对性的中毒攻击的防御机制，通过差分测试来识别潜在包含后门的恶意客户，有效降低攻击成功率到10%。

    

    Federated Learning (FL)是一种隐私保护的分布式机器学习技术，它使得个体客户（例如用户参与者、边缘设备或组织）能够在安全环境中基于本地数据训练模型，然后与聚合器共享训练模型以协作构建全局模型。在这项工作中，我们提出了FedDefender，一种针对联邦学习中有针对性的中毒攻击的防御机制，它利用差分测试。我们提出的方法对相同输入的客户模型的神经元激活进行指纹识别，并利用差分测试来识别潜在包含后门的恶意客户。我们使用MNIST和FashionMNIST数据集以及20个和30个客户对FedDefender进行评估，结果表明，FedDefender有效地缓解了此类攻击，将攻击成功率（ASR）降低到10%，而不会恶化全局模型的性能。

    arXiv:2307.08672v2 Announce Type: replace-cross  Abstract: Federated Learning (FL) is a privacy-preserving distributed machine learning technique that enables individual clients (e.g., user participants, edge devices, or organizations) to train a model on their local data in a secure environment and then share the trained model with an aggregator to build a global model collaboratively. In this work, we propose FedDefender, a defense mechanism against targeted poisoning attacks in FL by leveraging differential testing. Our proposed method fingerprints the neuron activations of clients' models on the same input and uses differential testing to identify a potentially malicious client containing a backdoor. We evaluate FedDefender using MNIST and FashionMNIST datasets with 20 and 30 clients, and our results demonstrate that FedDefender effectively mitigates such attacks, reducing the attack success rate (ASR) to 10\% without deteriorating the global model performance.
    
[^185]: 过度平滑：图对比学习的噩梦？

    Oversmoothing: A Nightmare for Graph Contrastive Learning?

    [https://arxiv.org/abs/2306.02117](https://arxiv.org/abs/2306.02117)

    对于图对比学习（GCL），研究表明增加网络深度会导致过度平滑，包括深度表示和浅层，提出了BlockGCL解决这一问题

    

    过度平滑是图神经网络（GNNs）中常见的现象，即网络深度的增加导致性能下降。图对比学习（GCL）正日益成为利用大量未标记图数据的一种有前途的方式。作为GNNs和对比学习的融合，尚不清楚GCL是否会继承GNNs的过度平滑缺陷。本文从过度平滑的角度对GCL进行了基础分析。我们通过实验证明，在GCL中增加网络深度也会导致它们的深度表示过度平滑，而且令人惊讶的是浅层也会出现这种现象。我们将这种现象在GCL中称为“长距离饥饿”，即深度网络中的较低层由于缺乏来自监督的充分指导而遭受退化。根据我们的研究结果，我们提出了BlockGCL，这是一个非常简单但有效的块wi

    arXiv:2306.02117v2 Announce Type: replace-cross  Abstract: Oversmoothing is a common phenomenon observed in graph neural networks (GNNs), in which an increase in the network depth leads to a deterioration in their performance. Graph contrastive learning (GCL) is emerging as a promising way of leveraging vast unlabeled graph data. As a marriage between GNNs and contrastive learning, it remains unclear whether GCL inherits the same oversmoothing defect from GNNs. This work undertakes a fundamental analysis of GCL from the perspective of oversmoothing on the first hand. We demonstrate empirically that increasing network depth in GCL also leads to oversmoothing in their deep representations, and surprisingly, the shallow ones. We refer to this phenomenon in GCL as `long-range starvation', wherein lower layers in deep networks suffer from degradation due to the lack of sufficient guidance from supervision. Based on our findings, we present BlockGCL, a remarkably simple yet effective blockwi
    
[^186]: 大型语言模型能够构建因果图吗？

    Can large language models build causal graphs?

    [https://arxiv.org/abs/2303.05279](https://arxiv.org/abs/2303.05279)

    大型语言模型被证明对于探测词、上下文和提示敏感，但可以作为一种工具辅助因果图的发展。

    

    建立因果图可能是一个费时费力的过程。为了确保捕捉到所有相关的因果路径，研究人员通常不仅要与临床医生和专家讨论，还要审阅大量相关的医学文献。通过编码常见和医学知识，大型语言模型(LLMs)代表了一种机会，可以通过自动评分潜在图中的边缘（即两个变量之间的联系）来简化这一过程。然而，已经证明LLMs对用户选择的探测词、上下文和提示非常敏感。在这项工作中，我们评估了LLMs是否能够成为补充因果图发展的有用工具。

    arXiv:2303.05279v2 Announce Type: replace-cross  Abstract: Building causal graphs can be a laborious process. To ensure all relevant causal pathways have been captured, researchers often have to discuss with clinicians and experts while also reviewing extensive relevant medical literature. By encoding common and medical knowledge, large language models (LLMs) represent an opportunity to ease this process by automatically scoring edges (i.e., connections between two variables) in potential graphs. LLMs however have been shown to be brittle to the choice of probing words, context, and prompts that the user employs. In this work, we evaluate if LLMs can be a useful tool in complementing causal graph development.
    
[^187]: DMODE: 无需特定类别信息的单目目标距离估计模块

    DMODE: Differential Monocular Object Distance Estimation Module without Class Specific Information

    [https://arxiv.org/abs/2210.12596](https://arxiv.org/abs/2210.12596)

    DMODE是一种无需物体类别信息的单目目标距离估计方法，通过融合物体大小变化和摄像头运动来实现对各种目标检测和未知物体的适应，解决了单目距离估计中缺乏参考点和对象特定线索的挑战。

    

    利用单个摄像头测量物体距离是一种经济高效的替代方案，而不需要立体视觉和激光雷达。尽管文献中已经探讨了单目距离估计，但大多数现有技术依赖于物体类别知识以实现高性能。在缺乏这些情境数据的情况下，单目距离估计变得更具挑战性，缺乏参考点和物体特定线索。然而，这些线索可能会误导与范围广泛变化或对抗情况下的对象，这是面向对象不可知距离估计的一个具有挑战性的方面。本文提出了DMODE，一种不需要物体类别知识的单目距离估计类别不可知方法。DMODE通过融合物体随时间变化的大小波动和摄像头运动来估计物体的距离，使其能够适应各种目标检测器和未知物体，从而解决这些挑战。

    arXiv:2210.12596v2 Announce Type: replace-cross  Abstract: Utilizing a single camera for measuring object distances is a cost-effective alternative to stereo-vision and LiDAR. Although monocular distance estimation has been explored in the literature, most existing techniques rely on object class knowledge to achieve high performance. Without this contextual data, monocular distance estimation becomes more challenging, lacking reference points and object-specific cues. However, these cues can be misleading for objects with wide-range variation or adversarial situations, which is a challenging aspect of object-agnostic distance estimation. In this paper, we propose DMODE, a class-agnostic method for monocular distance estimation that does not require object class knowledge. DMODE estimates an object's distance by fusing its fluctuation in size over time with the camera's motion, making it adaptable to various object detectors and unknown objects, thus addressing these challenges. We eva
    
[^188]: 基于任务驱动特征选择的多通道成像实验设计

    Experimental Design for Multi-Channel Imaging via Task-Driven Feature Selection

    [https://arxiv.org/abs/2210.06891](https://arxiv.org/abs/2210.06891)

    提出了一种基于任务驱动特征选择的多通道成像实验设计方法，通过优化设计和训练机器学习模型执行用户指定的图像分析任务。

    

    本文提出了一种数据驱动的、任务特定的实验设计范式，旨在缩短采集时间、降低成本、加速成像设备的部署。当前实验设计方法主要集中在模型参数估计上，并要求对特定模型进行规范，而在成像领域，其他任务可能驱动设计。此外，这种方法常常在真实世界的成像应用中导致难以求解的优化问题。本文提出了一种新的实验设计范式，同时优化设计（图像通道集）并训练一个机器学习模型来执行用户指定的图像分析任务。该方法在测量空间上密集采样数据（许多图像通道）进行了少量采集，然后识别一个预先指定尺寸的最佳支持任务的通道子集。

    arXiv:2210.06891v3 Announce Type: replace-cross  Abstract: This paper presents a data-driven, task-specific paradigm for experimental design, to shorten acquisition time, reduce costs, and accelerate the deployment of imaging devices. Current approaches in experimental design focus on model-parameter estimation and require specification of a particular model, whereas in imaging, other tasks may drive the design. Furthermore, such approaches often lead to intractable optimization problems in real-world imaging applications. Here we present a new paradigm for experimental design that simultaneously optimizes the design (set of image channels) and trains a machine-learning model to execute a user-specified image-analysis task. The approach obtains data densely-sampled over the measurement space (many image channels) for a small number of acquisitions, then identifies a subset of channels of prespecified size that best supports the task. We propose a method: TADRED for TAsk-DRiven Experime
    
[^189]: GNNInterpreter：图神经网络的生成模型级解释

    GNNInterpreter: A Probabilistic Generative Model-Level Explanation for Graph Neural Networks

    [https://arxiv.org/abs/2209.07924](https://arxiv.org/abs/2209.07924)

    提出了GNNInterpreter，一种用于解释图神经网络高级决策过程的模型级解释方法，通过学习概率生成图分布来揭示GNN模型内部工作机制。

    

    最近，图神经网络（GNNs）显著提升了在图上的机器学习任务的性能。然而，这一技术突破使人们产生了疑问：GNN是如何做出决策的，我们能否高度信任其预测？在一些关键领域，如生物医学，做出错误决策可能带来严重后果，因此在应用之前解释GNN的内部工作机制至关重要。本文提出了一种适用于遵循消息传递方案的不同GNN的模型不可知的模型级解释方法GNNInterpreter，来解释GNN模型的高级决策过程。具体而言，GNNInterpreter通过优化一种新颖的目标函数学习一个能够产生GNN在做出某个预测时试图检测到的最具辨识性图模式的概率生成图分布。

    arXiv:2209.07924v4 Announce Type: replace-cross  Abstract: Recently, Graph Neural Networks (GNNs) have significantly advanced the performance of machine learning tasks on graphs. However, this technological breakthrough makes people wonder: how does a GNN make such decisions, and can we trust its prediction with high confidence? When it comes to some critical fields, such as biomedicine, where making wrong decisions can have severe consequences, it is crucial to interpret the inner working mechanisms of GNNs before applying them. In this paper, we propose a model-agnostic model-level explanation method for different GNNs that follow the message passing scheme, GNNInterpreter, to explain the high-level decision-making process of the GNN model. More specifically, GNNInterpreter learns a probabilistic generative graph distribution that produces the most discriminative graph pattern the GNN tries to detect when making a certain prediction by optimizing a novel objective function specifical
    
[^190]: 超几何分层知识图嵌入的低维链接预测

    Hyperbolic Hierarchical Knowledge Graph Embeddings for Link Prediction in Low Dimensions

    [https://arxiv.org/abs/2204.13704](https://arxiv.org/abs/2204.13704)

    提出了一种新颖的KGE模型，名为HypH，利用超几何空间嵌入分层数据，以提高知识图中链接预测的性能

    

    知识图嵌入（KGE）已被证实是推断知识图（KGs）中缺失链接的强大方法，它们通常将实体映射到欧几里得空间，并将关系视为实体的转换。 最近，一些欧几里得KGE方法已经增强，以建模KGs中常见的语义层次结构，提高链接预测性能。 为了嵌入分层数据，超几何空间已经成为传统欧几里得空间的一种有前途的替代方法，具有高度保真度和较低的内存消耗。 与欧几里得空间不同，超几何空间提供了无数可供选择的曲率。 但是，现有的超几何KGE方法难以手动获取最佳曲率设置，从而限制了它们有效地对语义层次结构进行建模的能力。 为解决这一限制，我们提出了一种名为$\textbf{Hyp}$erbolic $\textbf{H}$ierarchical $\textb

    arXiv:2204.13704v2 Announce Type: replace-cross  Abstract: Knowledge graph embeddings (KGE) have been validated as powerful methods for inferring missing links in knowledge graphs (KGs) that they typically map entities into Euclidean space and treat relations as transformations of entities. Recently, some Euclidean KGE methods have been enhanced to model semantic hierarchies commonly found in KGs, improving the performance of link prediction. To embed hierarchical data, hyperbolic space has emerged as a promising alternative to traditional Euclidean space, offering high fidelity and lower memory consumption. Unlike Euclidean, hyperbolic space provides countless curvatures to choose from. However, it is difficult for existing hyperbolic KGE methods to obtain the optimal curvature settings manually, thereby limiting their ability to effectively model semantic hierarchies. To address this limitation, we propose a novel KGE model called $\textbf{Hyp}$erbolic $\textbf{H}$ierarchical $\textb
    
[^191]: 从抽象到基于实践的语言：实现任务规划机器人的稳健协调

    From Abstractions to Grounded Languages for Robust Coordination of Task Planning Robots

    [https://arxiv.org/abs/1905.00517](https://arxiv.org/abs/1905.00517)

    本文旨在自动构建能最大程度灵活且足够解释性的语言，用于协调任务规划机器人，通过将计划表达为“计划草图”，实现稳健协调。

    

    在这篇论文中，我们考虑了协调任务规划机器人中的一个关键环节。具体来说，我们研究了自动构建最大灵活性且足够解释性的语言，用于协调任务规划。为此，我们将语言视为指定计划时间-状态约束的机制。这种看法使我们能够逆向工程地从头开始构建语言，将这些可组合约束映射到词语上。我们的语言将一个给定任务的计划表达为一个“计划草图”，传达足够的细节以最大程度实现灵活性，从而实现稳健协调并具有最优性保证等其他优点。我们制定并分析问题，提供近似解，验证了我们方法的优势在各种场景下，并为其应用提供了启示。

    arXiv:1905.00517v3 Announce Type: replace  Abstract: In this paper, we consider a first step to bridge a gap in coordinating task planning robots. Specifically, we study the automatic construction of languages that are maximally flexible while being sufficiently explicative for coordination. To this end, we view language as a machinery for specifying temporal-state constraints of plans. Such a view enables us to reverse-engineer a language from the ground up by mapping these composable constraints to words. Our language expresses a plan for any given task as a "plan sketch" to convey just-enough details while maximizing the flexibility to realize it, leading to robust coordination with optimality guarantees among other benefits. We formulate and analyze the problem, provide an approximate solution, and validate the advantages of our approach under various scenarios to shed light on its applications.
    
[^192]: 在稀疏图上学习平均场对局博弈：一种混合图形扩展方法

    Learning Mean Field Games on Sparse Graphs: A Hybrid Graphex Approach. (arXiv:2401.12686v1 [cs.MA])

    [http://arxiv.org/abs/2401.12686](http://arxiv.org/abs/2401.12686)

    这篇论文提出了一种在稀疏图上学习平均场对局博弈的新方法，通过引入图形扩展的概念，解决了现有方法对于稀疏网络拓扑结构的限制。

    

    学习大规模代理群体的行为是许多研究领域中的重要任务。虽然多代理强化学习（MARL）领域在解决这些系统方面取得了重要进展，但对于许多代理的解决方案通常在计算上是不可行的，且缺乏理论保证。平均场对局博弈（MFGs）解决了这两个问题，并且可以扩展到包括代理之间的网络结构的图形平均场对局博弈（GMFGs）。尽管具有诸多优点，但GMFGs的现实世界应用受到图形只能捕捉密集图的限制。由于大多数实验证明的网络显示出一定程度的稀疏性，例如幂律图，因此GMFG框架无法捕捉这些网络拓扑结构。因此，我们提出了一种新颖的图形对局博弈（GXMFGs）的概念，它建立在图论概念图形扩展（graphexes）基础上。图形扩展是稀疏图序列的极限对象，还具有其他一些理想特性，如sma

    Learning the behavior of large agent populations is an important task for numerous research areas. Although the field of multi-agent reinforcement learning (MARL) has made significant progress towards solving these systems, solutions for many agents often remain computationally infeasible and lack theoretical guarantees. Mean Field Games (MFGs) address both of these issues and can be extended to Graphon MFGs (GMFGs) to include network structures between agents. Despite their merits, the real world applicability of GMFGs is limited by the fact that graphons only capture dense graphs. Since most empirically observed networks show some degree of sparsity, such as power law graphs, the GMFG framework is insufficient for capturing these network topologies. Thus, we introduce the novel concept of Graphex MFGs (GXMFGs) which builds on the graph theoretical concept of graphexes. Graphexes are the limiting objects to sparse graph sequences that also have other desirable features such as the sma
    
[^193]: SeeClick：利用GUI Grounding实现高级可视化GUI代理

    SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents. (arXiv:2401.10935v1 [cs.HC])

    [http://arxiv.org/abs/2401.10935](http://arxiv.org/abs/2401.10935)

    SeeClick是一种基于屏幕截图的视觉GUI代理，通过GUI grounding预训练和自动化数据生成，实现了在复杂任务自动化中准确定位屏幕元素，并创建了全面覆盖移动、桌面和Web环境的GUI grounding数据集ScreenSpot。

    

    图形用户界面(GUI)代理被设计用于自动化数字设备上的复杂任务，如智能手机和桌面电脑。大多数现有的GUI代理通过提取的结构化数据与环境进行交互，这些数据可能特别冗长（例如HTML）且有时无法访问（例如在桌面上）。为了解决这个问题，我们提出了一种基于屏幕截图进行任务自动化的视觉GUI代理--SeeClick。在我们的初步研究中，我们发现了开发视觉GUI代理的一个关键挑战：GUI grounding - 根据指令准确定位屏幕元素的能力。为了解决这个挑战，我们提出了用GUI grounding预训练来增强SeeClick，并设计了一种自动化GUI grounding数据的方法。除了以上工作，我们还创建了ScreenSpot，第一个涵盖移动、桌面和Web环境的真实GUI grounding数据集。经过预训练，SeeClick展示了显著的改进。

    Graphical User Interface (GUI) agents are designed to automate complex tasks on digital devices, such as smartphones and desktops. Most existing GUI agents interact with the environment through extracted structured data, which can be notably lengthy (e.g., HTML) and occasionally inaccessible (e.g., on desktops). To alleviate this issue, we propose a visual GUI agent -- SeeClick, which only relies on screenshots for task automation. In our preliminary study, we have discovered a key challenge in developing visual GUI agents: GUI grounding -the capacity to accurately locate screen elements based on instructions. To tackle this challenge, we propose to enhance SeeClick with GUI grounding pre-training and devise a method to automate the curation of GUI grounding data. Along with the efforts above, we have also created ScreenSpot, the first realistic GUI grounding dataset that encompasses mobile, desktop, and web environments. After pre-training, SeeClick demonstrates significant improvem
    
[^194]: 基于重新设计的自训练方法的半监督语义分割在白细胞上的应用

    Semi-supervised Semantic Segmentation using Redesigned Self-Training for White Blood Cell. (arXiv:2401.07278v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2401.07278](http://arxiv.org/abs/2401.07278)

    本文通过引入半监督学习框架和结合FixMatch，提出了一种重新设计的自训练流程，用于解决白细胞分割中缺乏标记数据集和过时方法的问题。在深度学习架构和自训练方案的支持下，取得了在不同数据集上的优异性能。

    

    在医疗保健领域，特别是在白细胞癌症诊断中，人工智能（AI）受到两个主要挑战的阻碍：缺乏大规模的白细胞（WBC）分割的标记数据集和过时的分割方法。为了解决第一个挑战，应该引入一种半监督学习框架来高效地注释大数据集。在这项工作中，我们通过提出一种新颖的自训练流程并结合FixMatch来解决这个问题。我们发现，通过在自训练流程中结合FixMatch，大多数情况下性能得到了改善。我们的性能在DeepLab-V3架构和ResNet-50上采用了自训练方案和一致性，分别在Zheng 1、Zheng 2和LISC数据集上达到了90.69%、87.37%和76.49%。

    Artificial Intelligence (AI) in healthcare, especially in white blood cell cancer diagnosis, is hindered by two primary challenges: the lack of large-scale labeled datasets for white blood cell (WBC) segmentation and outdated segmentation methods. To address the first challenge, a semi-supervised learning framework should be brought to efficiently annotate the large dataset. In this work, we address this issue by proposing a novel self-training pipeline with the incorporation of FixMatch. We discover that by incorporating FixMatch in the self-training pipeline, the performance improves in the majority of cases. Our performance achieved the best performance with the self-training scheme with consistency on DeepLab-V3 architecture and ResNet-50, reaching 90.69%, 87.37%, and 76.49% on Zheng 1, Zheng 2, and LISC datasets, respectively.
    
[^195]: Kun: 使用指令反向翻译的中国自对齐问题的答案优化方法

    Kun: Answer Polishment for Chinese Self-Alignment with Instruction Back-Translation. (arXiv:2401.06477v1 [cs.CL])

    [http://arxiv.org/abs/2401.06477](http://arxiv.org/abs/2401.06477)

    Kun是一种使用指令反向翻译和答案优化的方法，用于创建高质量的指导调整数据集，该方法不依赖于手动注释，通过自我筛选过程来改善和选择最有效的指令-输出对。它的主要创新在于通过算法改进提高数据的保留和清晰度，并通过创新的数据生成方法减少了手动注释的依赖。

    

    在本文中，我们介绍了一种名为Kun的新方法，用于在不依赖手动注释的情况下为大型语言模型（LLMs）创建高质量的指导调整数据集。Kun利用来自吾道、完卷和SkyPile等多个来源的未标记数据，采用基于指令反向翻译和答案优化的自我训练算法，生成了一个超过一百万个中文指导数据点的大规模数据集。该方法通过使用自我筛选过程来完善和选择最有效的指令-输出对，显著偏离传统方法。我们在多个基准测试上对6B参数的Yi模型进行了实验，结果表明Kun具有鲁棒性和可扩展性。我们方法的核心贡献在于算法的改进，增强了数据的保留和清晰度，并且创新的数据生成方法极大地减少了对昂贵和耗时的手动注释的依赖。这种方法ological方法提出了一种解决中文自对齐问题的方法，并提高了数据的准确性和质量。

    In this paper, we introduce Kun, a novel approach for creating high-quality instruction-tuning datasets for large language models (LLMs) without relying on manual annotations. Adapting a self-training algorithm based on instruction back-translation and answer polishment, Kun leverages unlabelled data from diverse sources such as Wudao, Wanjuan, and SkyPile to generate a substantial dataset of over a million Chinese instructional data points. This approach significantly deviates from traditional methods by using a self-curation process to refine and select the most effective instruction-output pairs. Our experiments with the 6B-parameter Yi model across various benchmarks demonstrate Kun's robustness and scalability. Our method's core contributions lie in its algorithmic advancement, which enhances data retention and clarity, and its innovative data generation approach that substantially reduces the reliance on costly and time-consuming manual annotations. This methodology presents a sc
    
[^196]: 通过细粒度模型参数扰动实现机器去学习

    Machine unlearning through fine-grained model parameters perturbation. (arXiv:2401.04385v1 [cs.LG])

    [http://arxiv.org/abs/2401.04385](http://arxiv.org/abs/2401.04385)

    本文提出了一种精细的机器去学习策略，通过细粒度模型参数的扰动来实现用户隐私保护，同时保持可控的计算成本。采用遗忘率和记忆保留率等新的指标来评估去学习效果和模型泛化能力。

    

    机器去学习技术涉及到撤销数据记录和减小该数据对训练模型的影响，从而帮助实现用户隐私保护目标，但会带来显著的计算成本。基于参数扰动的权重去学习是一种通用方法，但通常涉及到全局修改参数。我们提出了精细的Top-K和Random-k参数扰动不精确机器去学习策略，以满足隐私需求同时保持计算成本可控。为了展示我们策略的有效性，我们还解决了评估机器去学习效果的挑战，考虑了模型在去学习和剩余数据上的广义性能。为了更好地评估去学习效果和模型泛化能力，我们提出了新的指标，即遗忘率和记忆保留率。然而，对于不精确的机器去学习，现有的指标无法对去学习程度进行准确量化。

    Machine unlearning techniques, which involve retracting data records and reducing influence of said data on trained models, help with the user privacy protection objective but incur significant computational costs. Weight perturbation-based unlearning is a general approach, but it typically involves globally modifying the parameters. We propose fine-grained Top-K and Random-k parameters perturbed inexact machine unlearning strategies that address the privacy needs while keeping the computational costs tractable.  In order to demonstrate the efficacy of our strategies we also tackle the challenge of evaluating the effectiveness of machine unlearning by considering the model's generalization performance across both unlearning and remaining data. To better assess the unlearning effect and model generalization, we propose novel metrics, namely, the forgetting rate and memory retention rate. However, for inexact machine unlearning, current metrics are inadequate in quantifying the degree of
    
[^197]: 神经因果抽象

    Neural Causal Abstractions. (arXiv:2401.02602v1 [cs.LG])

    [http://arxiv.org/abs/2401.02602](http://arxiv.org/abs/2401.02602)

    本文提出了一种新的神经因果抽象方法，通过聚类变量和其域，用于解决真实因果推断任务中的挑战，并通过神经因果模型实现了学习和应用。

    

    人类理解世界中的因果关系以及将信息压缩成抽象概念的能力是人类智慧的两个标志性特征。这两个主题在文献中被统称为因果抽象理论同时进行研究。在实践中，如何在真实的因果推断任务中充分利用抽象理论仍然是一个开放的问题，因为真实机制是未知的，只有有限的数据可用。在本文中，我们通过对变量及其域进行聚类，开发了一种新的因果抽象家族。这种方法改进和概括了之前的抽象概念，以更好地适应Pearl的因果层次结构引发的个体因果分布。我们证明了在实际场景中通过神经因果模型（Xia等，2021）可以学得这样的抽象概念，从而能够利用深度学习技术解决各种具有挑战性的因果推断任务。

    The abilities of humans to understand the world in terms of cause and effect relationships, as well as to compress information into abstract concepts, are two hallmark features of human intelligence. These two topics have been studied in tandem in the literature under the rubric of causal abstractions theory. In practice, it remains an open problem how to best leverage abstraction theory in real-world causal inference tasks, where the true mechanisms are unknown and only limited data is available. In this paper, we develop a new family of causal abstractions by clustering variables and their domains. This approach refines and generalizes previous notions of abstractions to better accommodate individual causal distributions that are spawned by Pearl's causal hierarchy. We show that such abstractions are learnable in practical settings through Neural Causal Models (Xia et al., 2021), enabling the use of the deep learning toolkit to solve various challenging causal inference tasks -- iden
    
[^198]: 可解释的音频标记的感知音乐特征

    Perceptual Musical Features for Interpretable Audio Tagging. (arXiv:2312.11234v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2312.11234](http://arxiv.org/abs/2312.11234)

    本研究在自动音乐标记中探索了解释性的重要性，并构建了一个工作流来提取音频文件中的感知特征，从而训练出可解释的机器学习模型。

    

    在音乐流媒体平台的时代，自动标记音乐音频的任务引起了重要关注，推动研究人员设计旨在提高标准数据集上性能指标的方法。最近的方法大多依赖于深度神经网络，尽管其表现出色，但也具有不透明性，使得难以解释其对给定输入的输出。然而，解释性问题在其他领域如医学中备受强调，但在音乐相关任务中并未得到关注。本研究中，我们探索了在自动音乐标记的背景下解释性的相关性。我们构建了一个工作流，结合了三种不同的信息提取技术：a）利用符号知识，b）利用辅助深度神经网络，c）利用信号处理从音频文件中提取感知特征。

    In the age of music streaming platforms, the task of automatically tagging music audio has garnered significant attention, driving researchers to devise methods aimed at enhancing performance metrics on standard datasets. Most recent approaches rely on deep neural networks, which, despite their impressive performance, possess opacity, making it challenging to elucidate their output for a given input. While the issue of interpretability has been emphasized in other fields like medicine, it has not received attention in music-related tasks. In this study, we explored the relevance of interpretability in the context of automatic music tagging. We constructed a workflow that incorporates three different information extraction techniques: a) leveraging symbolic knowledge, b) utilizing auxiliary deep neural networks, and c) employing signal processing to extract perceptual features from audio files. These features were subsequently used to train an interpretable machine-learning model for ta
    
[^199]: 强化学习的扩散模型: 一份综述

    Diffusion Models for Reinforcement Learning: A Survey. (arXiv:2311.01223v1 [cs.LG])

    [http://arxiv.org/abs/2311.01223](http://arxiv.org/abs/2311.01223)

    强化学习中的扩散模型已经成为一种突出的生成模型，通过在样本质量和训练稳定性方面的优势改进了强化学习解决方案。该综述提供了这一新兴领域发展的概述，并探讨了扩散模型在强化学习中的分类法和应用。

    

    扩散模型作为一种突出的生成模型类别已经出现，超越了以往方法在样本质量和训练稳定性方面的优势。最近的研究表明，扩散模型在改进强化学习（RL）解决方案方面具有优势，包括作为轨迹规划器、表达能力丰富的策略类别、数据合成器等。本综述旨在提供该新兴领域发展的概述，并希望能启发新的研究方向。首先，我们审查了当前RL算法遇到的一些挑战。然后，我们根据扩散模型在RL中所扮演的角色，提出了现有方法的分类法，并探讨了如何解决现有挑战。我们进一步概述了扩散模型在各种与RL相关任务中的成功应用，并讨论了当前方法的局限性。最后，我们总结了这项综述，并提出了对未来研究方向的见解，重点是提高模型性能和应用扩散模型的方法。

    Diffusion models have emerged as a prominent class of generative models, surpassing previous methods regarding sample quality and training stability. Recent works have shown the advantages of diffusion models in improving reinforcement learning (RL) solutions, including as trajectory planners, expressive policy classes, data synthesizers, etc. This survey aims to provide an overview of the advancements in this emerging field and hopes to inspire new avenues of research. First, we examine several challenges encountered by current RL algorithms. Then, we present a taxonomy of existing methods based on the roles played by diffusion models in RL and explore how the existing challenges are addressed. We further outline successful applications of diffusion models in various RL-related tasks while discussing the limitations of current approaches. Finally, we conclude the survey and offer insights into future research directions, focusing on enhancing model performance and applying diffusion m
    
[^200]: Alquist 5.0：对话树与生成模型相结合。增强SocialBot对话的一种新方法。

    Alquist 5.0: Dialogue Trees Meet Generative Models. A Novel Approach for Enhancing SocialBot Conversations. (arXiv:2310.16119v1 [cs.LG])

    [http://arxiv.org/abs/2310.16119](http://arxiv.org/abs/2310.16119)

    Alquist 5.0是一种新的SocialBot系统，通过将对话树和生成模型相结合，以及引入NRG Barista和支持多模式设备，提高了用户对话体验，并保持了共情和知识型对话能力。

    

    我们介绍了我们的SocialBot- Alquist 5.0-，该系统是为Alexa Prize SocialBot大挑战5开发的。在我们系统的前几个版本基础上，我们引入了NRG Barista，并概述了将Barista整合到我们的SocialBot中的几种创新方法，从而改善了整体的对话体验。此外，我们还扩展了我们的SocialBot以支持多模式设备。本文提供了关于Alquist 5.0开发的见解，该系统在满足用户不断变化的期望的同时，保持了对各种主题的共情和知识型对话能力。

    We present our SocialBot -- Alquist~5.0 -- developed for the Alexa Prize SocialBot Grand Challenge~5. Building upon previous versions of our system, we introduce the NRG Barista and outline several innovative approaches for integrating Barista into our SocialBot, improving the overall conversational experience. Additionally, we extend our SocialBot to support multimodal devices. This paper offers insights into the development of Alquist~5.0, which meets evolving user expectations while maintaining empathetic and knowledgeable conversational abilities across diverse topics.
    
[^201]: EpiK-Eval：将语言模型作为认识模型的评估

    EpiK-Eval: Evaluation for Language Models as Epistemic Models. (arXiv:2310.15372v1 [cs.CL])

    [http://arxiv.org/abs/2310.15372](http://arxiv.org/abs/2310.15372)

    这项研究介绍了一种新的评估方法EpiK-Eval，旨在评估大型语言模型（LLMs）在从分割的叙述中构建连贯和一致的知识表示方面的能力。研究发现当前的训练目标存在固有的缺陷，因此提出了改进知识整合方法的建议，以大幅提高LLMs的整体效果和性能。

    

    在人工智能时代，大型语言模型（LLMs）的作用越来越重要。尽管它们日益普及，但它们在从不同训练文档中整合知识的能力——在许多应用中都是关键能力——仍未得到探索。本文首次研究了LLMs在其参数空间内有效地结合这种信息的能力。我们引入了EpiK-Eval，一个新颖的问答基准，旨在评估LLMs在从分割的叙述中构建一种连贯和一致的知识表示方面的能力。对各种LLMs的评估揭示了在这一领域存在的显著弱点。我们认为这些缺点源于现有训练目标的固有性质。因此，我们主张改进知识整合的方法，因为这有潜力显著提高LLMs的整体效果和性能。

    In the age of artificial intelligence, the role of large language models (LLMs) is becoming increasingly central. Despite their growing prevalence, their capacity to consolidate knowledge from different training documents - a crucial ability in numerous applications - remains unexplored. This paper presents the first study examining the capability of LLMs to effectively combine such information within their parameter space. We introduce EpiK-Eval, a novel question-answering benchmark tailored to evaluate LLMs' proficiency in formulating a coherent and consistent knowledge representation from segmented narratives. Evaluations across various LLMs reveal significant weaknesses in this domain. We contend that these shortcomings stem from the intrinsic nature of prevailing training objectives. Consequently, we advocate for refining the approach towards knowledge consolidation, as it harbors the potential to dramatically improve their overall effectiveness and performance. The findings from 
    
[^202]: 多智能体决策的掩码预训练

    Masked Pretraining for Multi-Agent Decision Making. (arXiv:2310.11846v1 [cs.AI])

    [http://arxiv.org/abs/2310.11846](http://arxiv.org/abs/2310.11846)

    我们提出了一个掩码预训练框架(MaskMA)用于解决多智能体决策中的挑战。这个框架采用变压器架构，并使用基于掩码的协作学习策略，同时整合了可泛化的动作表示。

    

    最近，在决策领域，构建具有零样本能力的通用单智能体日益取得重大进展。然而，将这种能力扩展到多智能体场景存在挑战。大多数现有工作在零样本能力方面存在困难，原因是多智能体环境中存在两个特定挑战：集中式预训练和分散式执行之间存在不匹配，以及不同的智能体数量和动作空间，使得难以创建适用于不同下游任务的可泛化表示。为了克服这些挑战，我们提出了一种适用于多智能体决策的掩码预训练框架(MaskMA)。该模型基于变压器架构，采用适合于带有部分观测的分散式执行的基于掩码的协作学习策略。此外，MaskMA通过将动作空间划分为面向自身信息的动作和与他人相关的动作，融入了可泛化的动作表示。

    Building a single generalist agent with zero-shot capability has recently sparked significant advancements in decision-making. However, extending this capability to multi-agent scenarios presents challenges. Most current works struggle with zero-shot capabilities, due to two challenges particular to the multi-agent settings: a mismatch between centralized pretraining and decentralized execution, and varying agent numbers and action spaces, making it difficult to create generalizable representations across diverse downstream tasks. To overcome these challenges, we propose a \textbf{Mask}ed pretraining framework for \textbf{M}ulti-\textbf{a}gent decision making (MaskMA). This model, based on transformer architecture, employs a mask-based collaborative learning strategy suited for decentralized execution with partial observation. Moreover, MaskMA integrates a generalizable action representation by dividing the action space into actions toward self-information and actions related to other 
    
[^203]: 一个可计数具有相同骨架的马尔可夫等价类的固定参数可处理算法

    A Fixed-Parameter Tractable Algorithm for Counting Markov Equivalence Classes with the same Skeleton. (arXiv:2310.04218v1 [cs.DS])

    [http://arxiv.org/abs/2310.04218](http://arxiv.org/abs/2310.04218)

    本文提出了一个固定参数可处理算法，用于计数具有相同骨架的马尔可夫等价类。

    

    因果有向无环图（也称为贝叶斯网络）是编码随机变量之间条件依赖关系的流行工具。在因果有向无环图中，随机变量被建模为有向图中的顶点，并且规定每个随机变量在给定其父节点的情况下与其祖先节点无关。然而，对于同一组随机变量上的两个不同的因果有向无环图可以准确编码相同的一组条件依赖关系。这样的因果有向无环图被称为马尔可夫等价，马尔可夫等价的因果有向无环图的等价类被称为马尔可夫等价类（MEC）。在过去几十年中，对于MEC已经创建了一些美丽的组合特征，并且已知，特别是在同一MEC中的所有因果有向无环图必须具有相同的“骨架”（底层无向图）和v-结构（形式为$a\rightarrow b \leftarrow c$的诱导子图）。这些组合特征还提出了几个自然的算法问题。

    Causal DAGs (also known as Bayesian networks) are a popular tool for encoding conditional dependencies between random variables. In a causal DAG, the random variables are modeled as vertices in the DAG, and it is stipulated that every random variable is independent of its ancestors conditioned on its parents. It is possible, however, for two different causal DAGs on the same set of random variables to encode exactly the same set of conditional dependencies. Such causal DAGs are said to be Markov equivalent, and equivalence classes of Markov equivalent DAGs are known as Markov Equivalent Classes (MECs). Beautiful combinatorial characterizations of MECs have been developed in the past few decades, and it is known, in particular that all DAGs in the same MEC must have the same ''skeleton'' (underlying undirected graph) and v-structures (induced subgraph of the form $a\rightarrow b \leftarrow c$).  These combinatorial characterizations also suggest several natural algorithmic questions. On
    
[^204]: Rayleigh Quotient Graph Neural Networks用于图级异常检测的研究

    Rayleigh Quotient Graph Neural Networks for Graph-level Anomaly Detection. (arXiv:2310.02861v1 [cs.LG])

    [http://arxiv.org/abs/2310.02861](http://arxiv.org/abs/2310.02861)

    《Rayleigh Quotient Graph Neural Networks用于图级异常检测的研究》提出使用Rayleigh Quotient作为驱动因素，通过探索图的固有光谱特征来实现图级异常检测。

    

    图级异常检测在癌症诊断和酶预测等领域中广泛应用。然而，现有方法无法捕捉到图异常的潜在属性，导致框架设计不可解释和性能不令人满意。在本文中，我们退一步重新研究了异常和正常图之间的光谱差异。我们的主要观察表明，这两个类之间的累计光谱能量存在显著差异。此外，我们证明了图信号的累计光谱能量可以用其瑞利商表示，这表明瑞利商是图异常属性的一个驱动因素。受此启发，我们提出了Rayleigh Quotient Graph Neural Network（RQGNN），这是第一个用于图级异常检测的光谱GNN，为探索异常图的固有光谱特征提供了新的视角。

    Graph-level anomaly detection has gained significant attention as it finds many applications in various domains, such as cancer diagnosis and enzyme prediction. However, existing methods fail to capture the underlying properties of graph anomalies, resulting in unexplainable framework design and unsatisfying performance. In this paper, we take a step back and re-investigate the spectral differences between anomalous and normal graphs. Our main observation shows a significant disparity in the accumulated spectral energy between these two classes. Moreover, we prove that the accumulated spectral energy of the graph signal can be represented by its Rayleigh Quotient, indicating that the Rayleigh Quotient is a driving factor behind the anomalous properties of graphs. Motivated by this, we propose Rayleigh Quotient Graph Neural Network (RQGNN), the first spectral GNN for graph-level anomaly detection, providing a new perspective on exploring the inherent spectral features of anomalous graph
    
[^205]: 使用大型语言模型的一致时间逻辑规划：知道何时做什么和何时寻求帮助。

    Conformal Temporal Logic Planning using Large Language Models: Knowing When to Do What and When to Ask for Help. (arXiv:2309.10092v1 [cs.RO])

    [http://arxiv.org/abs/2309.10092](http://arxiv.org/abs/2309.10092)

    本文提出了一个使用大型语言模型的一致时间逻辑规划方法，用于解决多个高级子任务的移动机器人运动规划问题。其中的一个关键挑战是如何以正确性的角度推理机器人计划与基于自然语言的逻辑任务的关系。

    

    本文解决了一个新的移动机器人运动规划问题，任务是以自然语言（NL）表达并以时间和逻辑顺序完成多个高级子任务。为了正式定义这样的任务，我们利用基于NL的原子谓词在LTL上定义了模型。这与相关的规划方法形成对比，这些方法在原子谓词上定义了捕捉所需低级系统配置的LTL任务。我们的目标是设计机器人计划，满足基于NL的原子命题定义的LTL任务。在这个设置中出现的一个新的技术挑战在于推理机器人计划的正确性与这些LTL编码的任务的关系。为了解决这个问题，我们提出了HERACLEs，一个分层一致的自然语言规划器，它依赖于现有工具的新型整合，包括（i）自动机理论，以确定机器人应该完成的NL指定的子任务以推进任务进展；

    This paper addresses a new motion planning problem for mobile robots tasked with accomplishing multiple high-level sub-tasks, expressed using natural language (NL), in a temporal and logical order. To formally define such missions, we leverage LTL defined over NL-based atomic predicates modeling the considered NL-based sub-tasks. This is contrast to related planning approaches that define LTL tasks over atomic predicates capturing desired low-level system configurations. Our goal is to design robot plans that satisfy LTL tasks defined over NL-based atomic propositions. A novel technical challenge arising in this setup lies in reasoning about correctness of a robot plan with respect to such LTL-encoded tasks. To address this problem, we propose HERACLEs, a hierarchical conformal natural language planner, that relies on a novel integration of existing tools that include (i) automata theory to determine the NL-specified sub-task the robot should accomplish next to make mission progress; (
    
[^206]: GenDOM：具有参数感知的泛化性一次变形物体操作

    GenDOM: Generalizable One-shot Deformable Object Manipulation with Parameter-Aware Policy. (arXiv:2309.09051v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2309.09051](http://arxiv.org/abs/2309.09051)

    GenDOM是一个框架，通过条件化操作策略和多样化模拟训练，使操作策略能够仅通过一个真实世界演示来处理不同的可变形物体，并通过最小化真实世界演示和模拟之间的点云格密度差异来估计新物体的可变形物体参数。

    

    由于在运动中存在固有的变形不确定性，以往的可变形物体操作方法（如绳子和布料）通常需要数百个真实世界演示来训练每个物体的操作策略，这限制了它们在不断变化的世界中的应用。为了解决这个问题，我们引入了GenDOM，这是一个框架，允许操作策略只需一个真实世界演示来处理不同的可变形物体。为了实现这一点，我们通过将操作策略与可变形物体参数联系起来，并使用多样化的模拟可变形物体对其进行训练，使策略能够根据不同的物体参数调整动作。在推理时，给定一个新的物体，GenDOM可以通过最小化真实世界演示和模拟之间点云的格密度差异来估计可变形物体参数，而只需一个真实世界演示。

    Due to the inherent uncertainty in their deformability during motion, previous methods in deformable object manipulation, such as rope and cloth, often required hundreds of real-world demonstrations to train a manipulation policy for each object, which hinders their applications in our ever-changing world. To address this issue, we introduce GenDOM, a framework that allows the manipulation policy to handle different deformable objects with only a single real-world demonstration. To achieve this, we augment the policy by conditioning it on deformable object parameters and training it with a diverse range of simulated deformable objects so that the policy can adjust actions based on different object parameters. At the time of inference, given a new object, GenDOM can estimate the deformable object parameters with only a single real-world demonstration by minimizing the disparity between the grid density of point clouds of real-world demonstrations and simulations in a differentiable phys
    
[^207]: ParaGuide: 用于即插即用文本风格转移的引导性扩散改写器

    ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style Transfer. (arXiv:2308.15459v1 [cs.CL])

    [http://arxiv.org/abs/2308.15459](http://arxiv.org/abs/2308.15459)

    ParaGuide是一种用于通用风格转移的引导性扩散改写器，可以灵活适应任意目标风格，通过梯度引导和改写条件的扩散模型实现文本的风格转变，同时保留语义信息。

    

    文本风格转移是在保留意义的同时转变文本的风格属性的任务。目标风格可以以多种方式定义，从单一属性（例如正式性）到作者（例如莎士比亚）。先前的无监督风格转移方法通常依赖于大量标记数据，仅适用于固定的风格集，或需要大型语言模型。相反，我们引入了一种新的基于扩散的通用风格转移框架，可以在推理时灵活适应任意目标风格。我们的参数高效方法ParaGuide利用了改写条件的扩散模型以及来自现成的分类器和强大的风格嵌入器的梯度引导，以转变文本的风格同时保留语义信息。我们在Enron邮件语料库上进行了验证，包括人工和自动评估，并发现其在正式性和... (内容太多，请参考英文摘要)

    Textual style transfer is the task of transforming stylistic properties of text while preserving meaning. Target "styles" can be defined in numerous ways, ranging from single attributes (e.g, formality) to authorship (e.g, Shakespeare). Previous unsupervised style-transfer approaches generally rely on significant amounts of labeled data for only a fixed set of styles or require large language models. In contrast, we introduce a novel diffusion-based framework for general-purpose style transfer that can be flexibly adapted to arbitrary target styles at inference time. Our parameter-efficient approach, ParaGuide, leverages paraphrase-conditioned diffusion models alongside gradient-based guidance from both off-the-shelf classifiers and strong existing style embedders to transform the style of text while preserving semantic information. We validate the method on the Enron Email Corpus, with both human and automatic evaluations, and find that it outperforms strong baselines on formality, se
    
[^208]: CodeCoT及其进展：学习像开发者一样编程和测试

    CodeCoT and Beyond: Learning to Program and Test like a Developer. (arXiv:2308.08784v1 [cs.SE])

    [http://arxiv.org/abs/2308.08784](http://arxiv.org/abs/2308.08784)

    本文介绍了CodeCoT和Beyond的学习方法，该方法可以帮助模型在处理任务时从少量特定数据中进行适应。通过链式思维引导，模型可以揭示多步推理过程中的认知过程，并通过自我检查不断优化输出。

    

    在自然语言处理领域，OpenAI开发的基于转换器的大型语言模型（LLM）如GPT-x模型已经彻底改变了现状。尽管这些模型具有令人印象深刻的能力，但它们在处理与其训练数据不同的任务时常常遇到挑战，造成性能下降。为了解决这个问题，出现了一种被称为少样本学习的有价值技术，允许LLM在最少的任务特定数据上进行适应。一种创新的策略，称为思维链提示（CoT），已被引入以指导LLM在多步推理过程中揭示认知过程。在本文中，我们提出了Code Chain-of-Thought（CodeCoT），它由两个组成部分组成：经典CodeCoT和自我检查CodeCoT。后者加入了自我检查，使模型能够迭代生成代码，制定测试用例并改善其输出。具体而言，该过程包括模型生成与分类别特征对应的测试示例。

    In natural language processing, transformer-based large language models (LLMs) like GPT-x models developed by OpenAI have revolutionized the landscape. Despite their impressive capabilities, these models often encounter challenges when handling tasks that differ from their training data, resulting in compromised performance. To address this, few-shot learning has emerged as a valuable technique, allowing LLMs to adapt with minimal task-specific data. One innovative strategy, known as Chain-of-Thought Prompting (CoT), has been introduced to guide LLMs in revealing cognitive processes during multi-step reasoning. In this paper, we propose Code Chain-of-Thought~(CodeCoT), which consists of two components: the Vanilla CodeCoT and the Self-exam CodeCoT. The latter incorporates self-examination, empowering the model to iteratively generate code, formulate test cases, and refine its outputs. Specifically, the process entails the generation of test examples by the model corresponding to the co
    
[^209]: 方差-协方差正则化改进表示学习

    Variance-Covariance Regularization Improves Representation Learning. (arXiv:2306.13292v1 [cs.LG])

    [http://arxiv.org/abs/2306.13292](http://arxiv.org/abs/2306.13292)

    提出了方差-协方差正则化方法，旨在促进学习网络特征的多样性，改善表示学习和迁移学习的性能。

    

    迁移学习已成为机器学习领域的一个关键方法，能够将从一个领域获得的知识应用于提高后续任务的性能。然而，缺乏关于这些后续任务的足够信息，强有力的迁移学习方法要求在初始预训练阶段捕获各种特征。然而，最近的研究表明，在没有足够的正则化的情况下，网络往往会集中于主要减少预训练损失函数的特征。这种趋势可能导致不充分的特征学习和目标任务的受损泛化能力。为了解决这个问题，我们提出了方差-协方差正则化（VCR）技术，旨在促进学习网络特征的多样性。借鉴最近自监督学习方法的进展，我们的方法促进了表现出高方差和高相关性的学习表示。

    Transfer learning has emerged as a key approach in the machine learning domain, enabling the application of knowledge derived from one domain to improve performance on subsequent tasks. Given the often limited information about these subsequent tasks, a strong transfer learning approach calls for the model to capture a diverse range of features during the initial pretraining stage. However, recent research suggests that, without sufficient regularization, the network tends to concentrate on features that primarily reduce the pretraining loss function. This tendency can result in inadequate feature learning and impaired generalization capability for target tasks. To address this issue, we propose Variance-Covariance Regularization (VCR), a regularization technique aimed at fostering diversity in the learned network features. Drawing inspiration from recent advancements in the self-supervised learning approach, our approach promotes learned representations that exhibit high variance and 
    
[^210]: 基于GCN可信度预测的协同移动群感知的高效招募策略

    Efficient Recruitment Strategy for Collaborative Mobile Crowd Sensing Based on GCN Trustworthiness Prediction. (arXiv:2306.04366v1 [cs.SI])

    [http://arxiv.org/abs/2306.04366](http://arxiv.org/abs/2306.04366)

    本文提出了一种基于GCN可信度预测的协同移动群感知的高效招募策略，通过捕获工人之间的非对称信任关系和工人能力来实现有效的任务分配，优于现有方法。

    

    协同移动群感知可以通过促进任务感知的团队合作来提高数据质量和覆盖范围，而工人招募则代表着一个复杂的多目标优化问题。现有策略主要关注工人本身的特征，忽略了工人之间的非对称信任关系，从而影响了任务效用评估的合理性。为解决这个问题，本文首先使用Mini-Batch K-Means聚类算法和边缘服务器来实现高效的分布式工人招募。利用历史数据和任务要求获得工人的能力类型和距离。使用工人社交网络中的信任导向图输入至图卷积网络（GCN）框架进行训练，捕获工人之间的非对称信任关系。通过工人之间的高信任值，防止CMCS场景下的隐私泄露。最终，利用预测的信任和工人能力构建了一个无向招募图，以实现有效的任务分配。实验结果表明，与现有方法相比，这种招募方法在招募准确度、任务完成时间和能量消耗方面表现优异。

    Collaborative Mobile Crowd Sensing (CMCS) enhances data quality and coverage by promoting teamwork in task sensing, with worker recruitment representing a complex multi-objective optimization problem. Existing strategies mainly focus on the characteristics of workers themselves, neglecting the asymmetric trust relationships between them, which affects the rationality of task utility evaluation. To address this, this paper first employs the Mini-Batch K-Means clustering algorithm and deploys edge servers to enable efficient distributed worker recruitment. Historical data and task requirements are utilized to obtain workers' ability types and distances. A trust-directed graph in the worker's social network is input into the Graph Convolutional Network (GCN) framework for training, capturing asymmetric trustworthiness between worker pairs. Privacy leakage is prevented in CMCS scenarios through high trust values between workers. Ultimately, an undirected recruitment graph is constructed us
    
[^211]: 我们能否忘记我们的学习方式？比较迭代信念修正中的状态表示(arXiv:2305.09200v1 [cs.AI])

    Can we forget how we learned? Representing states in iterated belief revision}. (arXiv:2305.09200v1 [cs.AI])

    [http://arxiv.org/abs/2305.09200](http://arxiv.org/abs/2305.09200)

    本文比较了迭代信念修正中的三种状态表示方法，证明了用字典序修订的重写历史是最有效率的，并提供了一个多项式时间算法，用于确定Horn公式是否等价于neg。

    

    本文比较了迭代信念修正中三种最常见的状态表示方法：显式表示，按层次表示和按历史表示。前者是模型之间的连通偏序关系，第二种是表示等价类的公式列表，第三种是先前修订的序列。后者取决于修订语义和历史重写，而前者则取决于允许的重写。所有机制都表示所有可能的状态。用字典序修订的重写历史在大小方面比其他考虑的表示方法更有效率。证明了这样一个历史的冗余是一种轻微的重写。在一般情况下，这是一个coNP完全问题，即使在Horn公式的两次修订历史或任意长度的修订历史上，这也是困难的，但在两个Horn公式的历史上，它是多项式的。一个次要的技术结果是一个多项式时间算法，用于确定一个Horn公式是否等价于neg。

    The three most common representations of states in iterated belief revision are compared: explicit, by levels and by history. The first is a connected preorder between models, the second is a list of formulae representing equivalence classes, the third is the sequence of the previous revisions. The latter depends on the revision semantics and on history rewriting, and the latter depends on the allowed rewritings. All mechanisms represent all possible states. A rewritten history of lexicographic revision is more efficient than the other considered representations in terms of size with arbitrary history rewritings. Establishing the redundancy of such a history is a mild rewriting. It is coNP-complete in the general case, and is hard even on histories of two revisions or revisions of arbitrary length of Horn formulae, and is polynomial on histories of two Horn formulae. A minor technical result is a polynomial-time algorithm for establishing whether a Horn formula is equivalent to the neg
    
[^212]: 学习动作嵌入以进行离线评估

    Learning Action Embeddings for Off-Policy Evaluation. (arXiv:2305.03954v1 [cs.LG])

    [http://arxiv.org/abs/2305.03954](http://arxiv.org/abs/2305.03954)

    本论文探讨了从记录数据中学习动作嵌入，以减少在大型动作空间中反向倾向评分（IPS）估计器的方差，同时提高离线评估的准确性。

    

    离线评估（OPE）方法使我们能够使用由不同策略收集的记录数据来计算策略的预期奖励。 OPE是运行昂贵的在线A / B测试的可行选择：它可以加快新策略的开发，并降低向客户暴露次优治疗的风险。然而，当动作数量很大或记录策略未充分探索某些操作时，基于反向倾向评分（IPS）的现有估计器可能具有高甚至无限方差。Saito和Joachims提出使用动作嵌入的边际IPS（MIPS），从而在大型动作空间中降低IPS的方差。 MIPS假设从业者可以定义良好的动作嵌入，但在许多实际应用中很难做到这一点。在这项工作中，我们探讨从记录数据中学习动作嵌入。特别地，我们使用已经训练好的奖励模型的中间输出来定义动作嵌入，然后将其用于MIPS估计器中。

    Off-policy evaluation (OPE) methods allow us to compute the expected reward of a policy by using the logged data collected by a different policy. OPE is a viable alternative to running expensive online A/B tests: it can speed up the development of new policies, and reduces the risk of exposing customers to suboptimal treatments. However, when the number of actions is large, or certain actions are under-explored by the logging policy, existing estimators based on inverse-propensity scoring (IPS) can have a high or even infinite variance. Saito and Joachims (arXiv:2202.06317v2 [cs.LG]) propose marginalized IPS (MIPS) that uses action embeddings instead, which reduces the variance of IPS in large action spaces. MIPS assumes that good action embeddings can be defined by the practitioner, which is difficult to do in many real-world applications. In this work, we explore learning action embeddings from logged data. In particular, we use intermediate outputs of a trained reward model to defin
    
[^213]: 考虑多轮对话上下文的领域外意图检测

    Out-of-Domain Intent Detection Considering Multi-turn Dialogue Contexts. (arXiv:2305.03237v1 [cs.CL])

    [http://arxiv.org/abs/2305.03237](http://arxiv.org/abs/2305.03237)

    本文提出了一个上下文感知的OOD意图检测框架（Caro），用于模拟OOD意图检测任务中的多轮对话上下文，并在提取稳健的表示时删除与意图检测无关的多余信息。Caro在多个标准数据集上表现出最先进的性能，并超越了先前方法。

    

    领域外（OOD）意图检测对于实用的对话系统非常重要，通常需要考虑多轮对话上下文。然而，大多数先前的OOD意图检测方法仅限于单轮对话。在本文中，我们介绍了一个上下文感知的OOD意图检测（Caro）框架，用于对OOD意图检测任务中的多轮上下文进行建模。具体地，我们遵循信息瓶颈原则从多轮对话上下文中提取稳健的表示。每个输入样本构建了两个不同的视角，使用多视图信息瓶颈损失删除与意图检测无关的多余信息。此外，我们还探索了在Caro中利用未标记的数据。引入了一个两阶段训练过程来从这些未标记的数据中挖掘OOD样本，并使用自举方法用这些OOD样本来训练生成的模型。全面的实验表明，Caro在OOD意图检测任务的几个基准数据集上建立了最先进的性能，并超越了仅考虑单轮上下文的先前方法。

    Out-of-Domain (OOD) intent detection is vital for practical dialogue systems, and it usually requires considering multi-turn dialogue contexts. However, most previous OOD intent detection approaches are limited to single dialogue turns. In this paper, we introduce a context-aware OOD intent detection (Caro) framework to model multi-turn contexts in OOD intent detection tasks. Specifically, we follow the information bottleneck principle to extract robust representations from multi-turn dialogue contexts. Two different views are constructed for each input sample and the superfluous information not related to intent detection is removed using a multi-view information bottleneck loss. Moreover, we also explore utilizing unlabeled data in Caro. A two-stage training process is introduced to mine OOD samples from these unlabeled data, and these OOD samples are used to train the resulting model with a bootstrapping approach. Comprehensive experiments demonstrate that Caro establishes state-of-
    
[^214]: CMOS + 随机纳米磁体：概率推理与学习异构计算机

    CMOS + stochastic nanomagnets: heterogeneous computers for probabilistic inference and learning. (arXiv:2304.05949v1 [cond-mat.mes-hall])

    [http://arxiv.org/abs/2304.05949](http://arxiv.org/abs/2304.05949)

    本文展示了如何将基于随机磁隧道结（sMTJ）的概率比特（p位）与多功能可编程门阵列（FPGA）相结合，设计出一种能源高效的异构CMOS + X（X = sMTJ）原型，其成功地执行了概率推理和异步Boltzmann学习。

    

    随着摩尔定律的放缓，利用新兴的纳米技术（X）增强互补金属氧化物半导体（CMOS）晶体管变得越来越重要。本文展示了如何将基于随机磁隧道结（sMTJ）的概率比特（p位）与多功能可编程门阵列（FPGA）相结合，设计出一种能源高效的异构CMOS + X（X = sMTJ）原型。尽管sMTJs设备间存在差异，我们的异构计算机成功地执行了概率推理和异步Boltzmann学习。使用CMOS预测流程设计套件（PDK）进行全面比较，数字CMOS-based p-bits模拟高质量随机性需要超过10,000个晶体管，每生成一个随机数的能量比使用只消耗2fJ的sMTJ-based p-bits高约两个数量级。我们的方法的缩放和集成版本可以显着推进概率性的推理。

    With the slowing down of Moore's law, augmenting complementary-metal-oxide semiconductor (CMOS) transistors with emerging nanotechnologies (X) is becoming increasingly important. In this paper, we demonstrate how stochastic magnetic tunnel junction (sMTJ)-based probabilistic bits, or p-bits, can be combined with versatile Field Programmable Gate Arrays (FPGA) to design an energy-efficient, heterogeneous CMOS + X (X = sMTJ) prototype. Our heterogeneous computer successfully performs probabilistic inference and asynchronous Boltzmann learning despite device-to-device variations in sMTJs. A comprehensive comparison using a CMOS predictive process design kit (PDK) reveals that digital CMOS-based p-bits emulating high-quality randomness use over 10,000 transistors with the energy per generated random number being roughly two orders of magnitude greater than the sMTJ-based p-bits that dissipate only 2 fJ. Scaled and integrated versions of our approach can significantly advance probabilistic 
    
[^215]: 使用语言反馈规模化训练语言模型

    Training Language Models with Language Feedback at Scale. (arXiv:2303.16755v1 [cs.CL])

    [http://arxiv.org/abs/2303.16755](http://arxiv.org/abs/2303.16755)

    本文提出一种新方法，即利用更丰富的语言反馈进行模仿学习，通过三个迭代步骤对语言模型进行训练以生成更符合人类偏好的输出。

    

    预训练的语言模型经常生成不符合人类偏好的输出，例如有害的文本或事实不正确的摘要。最近的研究尝试通过学习一种简单的人类反馈形式（即模型生成输出之间的比较）来解决这些问题。但是，比较反馈只能传达有限的关于人类偏好的信息。在本文中，我们介绍了一种新的方法——使用语言反馈进行模仿学习（ILF），它利用了更丰富的语言反馈。ILF由三个迭代步骤组成：第一步，根据输入，初始LM输出和反馈对语言模型进行调节以生成改进。第二步，选择最多反馈的改进。第三步，微调语言模型，以最大化在给定输入的情况下选择的改进的可能性。我们在理论上证明了ILF可以被看作是贝叶斯推断，类似于从人类反馈中进行强化学习。我们还评估了ILF在各种基准测试中的性能。

    Pretrained language models often generate outputs that are not in line with human preferences, such as harmful text or factually incorrect summaries. Recent work approaches the above issues by learning from a simple form of human feedback: comparisons between pairs of model-generated outputs. However, comparison feedback only conveys limited information about human preferences. In this paper, we introduce Imitation learning from Language Feedback (ILF), a new approach that utilizes more informative language feedback. ILF consists of three steps that are applied iteratively: first, conditioning the language model on the input, an initial LM output, and feedback to generate refinements. Second, selecting the refinement incorporating the most feedback. Third, finetuning the language model to maximize the likelihood of the chosen refinement given the input. We show theoretically that ILF can be viewed as Bayesian Inference, similar to Reinforcement Learning from human feedback. We evaluate
    
[^216]: 利用自然语言反馈进行代码生成的改进

    Improving Code Generation by Training with Natural Language Feedback. (arXiv:2303.16749v1 [cs.SE])

    [http://arxiv.org/abs/2303.16749](http://arxiv.org/abs/2303.16749)

    该论文提出了一种新算法ILF，通过从自然语言反馈中进行学习来显著提高代码生成模型的性能，即使只有少量反馈，也可以获得很好的效果。

    

    预先训练好的大型语言模型（LLM）在推理时使用自然语言反馈的潜力是最近的一个令人兴奋的发展。我们在此基础上提出一种名为Language Feedback（ILF）的算法，用于从自然语言反馈中进行学习。ILF在训练期间仅需要少量的人工编写反馈，并且在测试时不需要相同的反馈，因此使用起来既方便又高效。此外，我们进一步证明ILF可以被视为最小化与基准分布的KL散度的一种形式，并在神经程序合成任务上进行了概念验证。我们使用ILF在Mostly Basic Python Problems(MBPP)基准测试上将Codegen-Mono 6.1B模型的pass @ 1覆盖率相对提高了38%（绝对提高了10%），胜过了在MBPP上微调和在人类修复的程序上微调的模型。总的来说，我们的结果表明，即使只有少量反馈，从人类编写的自然语言反馈中进行学习也可以显著改进代码生成模型。

    The potential for pre-trained large language models (LLMs) to use natural language feedback at inference time has been an exciting recent development. We build upon this observation by formalizing an algorithm for learning from natural language feedback at training time instead, which we call Imitation learning from Language Feedback (ILF). ILF requires only a small amount of human-written feedback during training and does not require the same feedback at test time, making it both user-friendly and sample-efficient. We further show that ILF can be seen as a form of minimizing the KL divergence to the ground truth distribution and demonstrate a proof-of-concept on a neural program synthesis task. We use ILF to improve a Codegen-Mono 6.1B model's pass@1 rate by 38% relative (and 10% absolute) on the Mostly Basic Python Problems (MBPP) benchmark, outperforming both fine-tuning on MBPP and fine-tuning on repaired programs written by humans. Overall, our results suggest that learning from h
    
[^217]: 对比学习是相似性图谱上的谱聚类

    Contrastive Learning Is Spectral Clustering On Similarity Graph. (arXiv:2303.15103v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.15103](http://arxiv.org/abs/2303.15103)

    本文通过证明标准InfoNCE损失下的对比学习等同于相似性图上的谱聚类，揭示了这种方法的内在等价性，并进一步将这种分析扩展到CLIP模型，提出新的核混合损失函数。

    

    对比学习是一种强大的自监督学习方法，但我们对其运作原理和原因的理论理解有限。本文通过证明标准InfoNCE损失下的对比学习等同于相似性图上的谱聚类，揭示了这种方法的内在等价性。利用这种等价性作为基石，我们将分析扩展到CLIP模型，并严格描述多模态对象如何被嵌入到一起。在理论洞见的推动下，我们引入了核混合损失，结合新颖的核函数，在多个视觉数据集上优于标准高斯核。

    Contrastive learning is a powerful self-supervised learning method, but we have a limited theoretical understanding of how it works and why it works. In this paper, we prove that contrastive learning with the standard InfoNCE loss is equivalent to spectral clustering on the similarity graph. Using this equivalence as the building block, we extend our analysis to the CLIP model and rigorously characterize how similar multi-modal objects are embedded together. Motivated by our theoretical insights, we introduce the kernel mixture loss, incorporating novel kernel functions that outperform the standard Gaussian kernel on several vision datasets.
    
[^218]: 无先验因果学习

    Zero-shot causal learning. (arXiv:2301.12292v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12292](http://arxiv.org/abs/2301.12292)

    无先验因果学习是一个解决预测新型干预措施个性化影响的框架，并通过元学习对任务的处理达成了目的，能够将干预措施的知识传输到未见过的干预措施中，并在合成和真实数据集上表现出了优越性能。

    

    在个性化医疗、公共政策和在线营销等领域，预测不同干预措施对特定个体的因果影响非常重要。预测现有干预措施的影响有许多方法，这些方法基于接受过干预措施的个体的历史数据。然而，在许多场景中，预测新型干预措施的影响也很重要，这些方法无法解决。在这里，我们考虑了无先验因果学习：预测新型干预措施的个性化影响。我们提出了CaML，这是一个因果元学习框架，它将每个干预措施的个性化预测效果作为一个任务来进行处理。CaML在数千个任务中训练单一的元模型，每个任务都是通过抽样生成一个干预措施及其接收者和非接收者来构建的。通过利用干预信息（例如，药物的属性）和个体特征（例如，特定个体的医疗记录），CaML学习如何将已观察到的干预措施的知识有效地传输给未见过的干预措施。我们在合成和真实数据集上展示了我们方法的有效性，展示了该方法具有推广到未见过干预措施并胜过现有方法的能力。

    Predicting how different interventions will causally affect a specific individual is important in a variety of domains such as personalized medicine, public policy, and online marketing. There are a large number of methods to predict the effect of an existing intervention based on historical data from individuals who received it. However, in many settings it is important to predict the effects of novel interventions (\emph{e.g.}, a newly invented drug), which these methods do not address. Here, we consider zero-shot causal learning: predicting the personalized effects of a novel intervention. We propose CaML, a causal meta-learning framework which formulates the personalized prediction of each intervention's effect as a task. CaML trains a single meta-model across thousands of tasks, each constructed by sampling an intervention, along with its recipients and nonrecipients. By leveraging both intervention information (\emph{e.g.}, a drug's attributes) and individual features~(\emph{e.g.
    
[^219]: 关于遮蔽语言模型学习条件句的不一致性

    On the Inconsistencies of Conditionals Learned by Masked Language Models. (arXiv:2301.00068v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.00068](http://arxiv.org/abs/2301.00068)

    本论文研究发现，遮蔽语言模型学习的条件句往往存在着不一致性，无法从一个连贯的联合分布中推导出来。我们通过实证发现这种不一致性普遍存在于不同尺寸和配置的遮蔽语言模型中。为了解决这个问题，我们提出了条件句集合方法来在推断阶段处理不一致性。

    

    已经证明了在序列中学习预测遮蔽标记是一个对大型语言模型来说很有力的预训练目标。训练后，这些遮蔽语言模型可以提供基于双向上下文的标记分布。本论文展示了与常见假设相反，这种双向条件句经常表现出相当大的不一致性，即在考虑在一起时不能从一个连贯的联合分布导出它们。我们在遮蔽语言模型的两种常见风格（T5风格和BERT风格）的简单双字母词比较场景中通过实证量化了这种不一致性。例如，我们发现T5模型经常混淆自己对两个相似双字母词的偏好。我们还展示了不一致性在不同尺寸和配置的遮蔽语言模型中普遍存在，从RoBERTa-base到GLM-130B。作为解决这个问题的初始尝试，我们提出了条件句集合，在推断阶段处理这个问题。

    Learning to predict masked tokens in a sequence has been shown to be a powerful pretraining objective for large language models. After training, such masked language models can provide distributions of tokens conditioned on bidirectional context.  In this paper, we show that contrary to popular assumptions, such bidirectional conditionals often demonstrate considerable inconsistencies, i.e., they cannot be derived from a coherent joint distribution when considered together. We empirically quantify such inconsistencies in the simple scenario of bigram comparison for two common styles of masked language models: T5-style and BERT-style. For example, we show that T5 models often confuse their own preference regarding two similar bigrams. We show that inconsistencies exist ubiquitously in masked language models of diverse sizes and configurations, from RoBERTa-base to GLM-130B.  As an initial attempt to address this issue during the inference phase, we propose Ensemble of Conditionals, a se
    

