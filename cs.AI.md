# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [E(2)-Equivariant Graph Planning for Navigation.](http://arxiv.org/abs/2309.13043) | 本文提出了一种E(2)-对称图规划用于导航的方法，通过利用欧几里得对称性和开发等变消息传递网络，实现了高效、稳定和具有泛化能力的机器人导航学习。 |
| [^2] | [MosaicFusion: Diffusion Models as Data Augmenters for Large Vocabulary Instance Segmentation.](http://arxiv.org/abs/2309.13042) | MosaicFusion是一种用于大词汇实例分割的数据增强方法，通过将扩散模型作为数据集生成器，能够生成大量合成标记数据。在实验中，我们的方法在准确率和泛化能力方面取得了显著的提升。 |
| [^3] | [Memory-augmented conformer for improved end-to-end long-form ASR.](http://arxiv.org/abs/2309.13029) | 该论文提出了一种将记忆增强神经网络添加到Conformer模型中以解决长话语情况下性能下降的问题。实验结果表明，该系统在长话语上优于基准Conformer模型。 |
| [^4] | [A Hybrid Deep Learning-based Approach for Optimal Genotype by Environment Selection.](http://arxiv.org/abs/2309.13021) | 该论文提出了一种基于深度学习的混合方法，用于优化基于环境的基因型选择。通过整合不同作物品种的天气数据，特别是在不同气候条件下，准确地预测作物产量对于理解其适应性至关重要。论文中开发了两种新颖的卷积神经网络架构，并利用广义集成方法确定了最优的基因型与环境选择模型。 |
| [^5] | [Efficient N:M Sparse DNN Training Using Algorithm, Architecture, and Dataflow Co-Design.](http://arxiv.org/abs/2309.13015) | 本文提出了一种使用算法，架构和数据流协同设计的高效N:M稀疏DNN训练方案，该方案利用双向权重修剪方法优化计算成本，并通过稀疏加速器硬件支持实现高稀疏比的DNN训练。 |
| [^6] | [ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs.](http://arxiv.org/abs/2309.13007) | ReConcile是一个通过多轮讨论和投票机制来增强LLM推理能力的多模型多代理框架。 |
| [^7] | [Pursuing Counterfactual Fairness via Sequential Autoencoder Across Domains.](http://arxiv.org/abs/2309.13005) | 通过顺序自编码器实现反事实公平性追求的创新框架将环境信息和敏感属性与分类特征的嵌入表示分开，以提高模型在不同和陌生领域中的泛化能力，并解决公平问题。 |
| [^8] | [Audience-specific Explanations for Machine Translation.](http://arxiv.org/abs/2309.12998) | 该论文提出了一种针对机器翻译的针对特定观众的解释方法，通过从平行语料库中提取示例解释来解决翻译中的文化差异问题。实验结果表明，该方法能够有效提高句子中包含解释的比例。 |
| [^9] | [Higher-order Graph Convolutional Network with Flower-Petals Laplacians on Simplicial Complexes.](http://arxiv.org/abs/2309.12971) | 本文提出了基于花瓣拉普拉斯的高阶图卷积网络，通过利用简单复合体来建模高阶交互，在不同拓扑尺度上识别内在特征，并使用可学习的图滤波器来量化高阶交互强度。 |
| [^10] | [Trusta: Reasoning about Assurance Cases with Formal Methods and Large Language Models.](http://arxiv.org/abs/2309.12941) | Trusta是一款使用形式方法和大型语言模型推理保证论证的桌面应用程序，它可以自动构建和验证可信度推导树(TDT)，同时利用大型语言模型使论证的创建和评估更加便捷。 |
| [^11] | [Self-Explanation Prompting Improves Dialogue Understanding in Large Language Models.](http://arxiv.org/abs/2309.12940) | 本研究提出了一种自解释提示策略，可显著提高大型语言模型在多轮对话中的理解能力，实验证实其在复杂对话任务中的有效性。 |
| [^12] | [Frustrated with Code Quality Issues? LLMs can Help!.](http://arxiv.org/abs/2309.12938) | 使用大型语言模型（LLMs）协助开发者修正代码从而解决代码质量问题。提出了一个名为CORE的工具，使用一对组织为提供者和评估者的LLMs。该工具通过提供静态分析工具的推荐和生成候选的代码修订来改善代码质量。 |
| [^13] | [On Separate Normalization in Self-supervised Transformers.](http://arxiv.org/abs/2309.12931) | 在自监督变形器中，通过为标记和[CLS]符号分别使用归一化层，可以更好地捕捉它们各自的特点并提高下游任务的性能。 |
| [^14] | [A matter of attitude: Focusing on positive and active gradients to boost saliency maps.](http://arxiv.org/abs/2309.12913) | 本文研究了在显著图中考虑梯度符号和影响的作用，揭示了更好地识别卷积神经网络关注的图像像素的方法，并阐明了遮挡或改变这些像素会如何影响结果。 |
| [^15] | [KG-MDL: Mining Graph Patterns in Knowledge Graphs with the MDL Principle.](http://arxiv.org/abs/2309.12908) | KG-MDL是一种在知识图谱中挖掘图模式的方法，采用基于MDL原则，解决了模式爆炸问题，适应了KGs的特点。 |
| [^16] | [ProtoEM: A Prototype-Enhanced Matching Framework for Event Relation Extraction.](http://arxiv.org/abs/2309.12892) | 本论文提出了一种原型加强匹配框架（ProtoEM）用于联合抽取多种类型的事件关系。该框架通过获取每种类型的事件关系的原型表示，并利用图神经网络匹配这些关系，从而全面理解它们的内在语义。 |
| [^17] | [Gravity Network for end-to-end small lesion detection.](http://arxiv.org/abs/2309.12876) | 本文引入了一种新颖的重力网络架构，通过引入动态移动的重力点锚点，实现了端到端的小病灶检测，关于该方法在医学图像中的应用具有良好的检测效果。 |
| [^18] | [AnglE-Optimized Text Embeddings.](http://arxiv.org/abs/2309.12871) | 本文提出了一种名为AnglE的角度优化文本嵌入模型，通过在复杂空间中引入角度优化来缓解文本嵌入中余弦函数饱和区域造成的梯度消失问题。该模型在多个STS任务中实现了高质量的文本嵌入，并在有限标签数据的特定领域STS场景中展现出优秀的性能。 |
| [^19] | [Accurate and Fast Compressed Video Captioning.](http://arxiv.org/abs/2309.12867) | 这项研究提出了一种准确快速的压缩视频字幕生成方法，通过从压缩域进行学习，避免了手动帧采样和冗余处理，提高了性能和效率。 |
| [^20] | [Domain Adaptation for Arabic Machine Translation: The Case of Financial Texts.](http://arxiv.org/abs/2309.12863) | 这项研究旨在探索领域适应对阿拉伯机器翻译在金融领域的效果，并通过开发平行语料库进行了试验。结果显示，领域适应方法对于提高阿拉伯机器翻译的性能具有积极的影响。 |
| [^21] | [Diffusion Augmentation for Sequential Recommendation.](http://arxiv.org/abs/2309.12858) | 本研究提出了一种用于顺序推荐的扩散增强方法，通过生成高质量的增强数据集，直接用于训练顺序推荐模型，解决了长尾用户和数据稀疏的问题。 |
| [^22] | [AxOCS: Scaling FPGA-based Approximate Operators using Configuration Supersampling.](http://arxiv.org/abs/2309.12830) | 近似计算作为低成本机器学习实现的解决方案在嵌入式系统中得到广泛研究。其中，设计特定于平台的近似算术运算符成为主要问题，现有方法主要使用基于机器学习的代理函数预测性能和行为影响，缺乏更先进的方法。 |
| [^23] | [Synthetic Boost: Leveraging Synthetic Data for Enhanced Vision-Language Segmentation in Echocardiography.](http://arxiv.org/abs/2309.12829) | 本研究探讨了使用合成数据集来增强超声心动图分割的视觉-语言分割模型（VLSM），结果显示合成数据集可以提高分割模型的指标和训练速度。 |
| [^24] | [OmniDrones: An Efficient and Flexible Platform for Reinforcement Learning in Drone Control.](http://arxiv.org/abs/2309.12825) | OmniDrones是一个专为无人机控制中的强化学习而设计的高效灵活平台，采用自下而上设计方法，并提供一系列基准任务和无人机学习工具。这个平台有助于将强化学习应用于实际无人机系统的研究。 |
| [^25] | [A Spectral Theory of Neural Prediction and Alignment.](http://arxiv.org/abs/2309.12821) | 该论文提出了一个光谱理论，用于理解神经预测和对齐问题。通过研究模型激活的光谱偏差和神经响应与可学习子空间的对齐情况，我们可以获得深度神经网络的几何属性，并区分在神经预测方面表现相同的模型。 |
| [^26] | [Masking Improves Contrastive Self-Supervised Learning for ConvNets, and Saliency Tells You Where.](http://arxiv.org/abs/2309.12757) | 该论文研究了如何将遮盖操作引入卷积神经网络的对比学习框架中，以提高自监督学习的效果。同时，研究还发现遮盖操作可能存在一些副作用，作者提出了解决方案来应对这些问题。 |
| [^27] | [Towards an MLOps Architecture for XAI in Industrial Applications.](http://arxiv.org/abs/2309.12756) | 该论文提出了一种面向工业应用的XAI MLOps架构，旨在解决实际部署和管理ML模型中的解释和反馈能力的挑战，并提高模型准确性和用户体验。 |
| [^28] | [OpenAi's GPT4 as coding assistant.](http://arxiv.org/abs/2309.12732) | 本论文研究了OpenAi的GPT4作为编码助手的能力，通过测试发现其在回答问题、生成可靠代码和贡献代码调试方面表现出色。这表明GPT4能够提高程序员的生产力并重塑软件开发过程。 |
| [^29] | [Defeasible Reasoning with Knowledge Graphs.](http://arxiv.org/abs/2309.12731) | 本文介绍了一种可废弃推理的直观符号和模型，用于处理不完美知识，并将其与先前的论证理论工作相关联。进一步工作需要在陈述性术语中描述推理策略和战术，并结合AIF本体论的启示。论文还观察了大型语言模型时代符号方法的应用。 |
| [^30] | [In-context Interference in Chat-based Large Language Models.](http://arxiv.org/abs/2309.12727) | 本文研究了聊天式大型语言模型中的上下文干扰问题，发现模型在上下文中持续流动的信息之间可能会遭受干扰，导致遗忘之前学到的知识，降低性能。 |
| [^31] | [H2O+: An Improved Framework for Hybrid Offline-and-Online RL with Dynamics Gaps.](http://arxiv.org/abs/2309.12716) | H2O+是一种改进的混合离线和在线强化学习框架，通过综合考虑真实和模拟环境的动力学差距，同时利用有限的离线数据和不完美的模拟器进行策略学习，并在广泛的仿真和实际机器人实验中展示了卓越的性能和灵活性。 |
| [^32] | [The Mathematical Game.](http://arxiv.org/abs/2309.12711) | 提出使用其他游戏树搜索算法来改进Holophrasm定理证明器的性能。 |
| [^33] | [PointSSC: A Cooperative Vehicle-Infrastructure Point Cloud Benchmark for Semantic Scene Completion.](http://arxiv.org/abs/2309.12708) | PointSSC是第一个为了语义场景补全而引入的车辆基础设施点云合作基准，具备长距离感知和最小遮挡。通过使用Segment Anything进行自动化注释，我们提出了一种基于激光雷达的模型，结合补全和分割的合作模块，来推动语义点云补全在真实世界导航中的发展。 |
| [^34] | [Multi-Label Noise Transition Matrix Estimation with Label Correlations: Theory and Algorithm.](http://arxiv.org/abs/2309.12706) | 本论文提出了一种解决多标签噪声转移矩阵估计问题的方法，通过研究可辨识性，并结合标签相关性，提出了一种新的估计器，可以在噪声多标签学习中实现统计一致性算法。 |
| [^35] | [Counterfactual Conservative Q Learning for Offline Multi-agent Reinforcement Learning.](http://arxiv.org/abs/2309.12696) | 提出了一种新的多智能体离线RL算法，通过反事实保守Q学习实现保守的价值估计，在解决离线分布偏移和高维问题的同时，确保行为的分布和价值的估计不过高。 |
| [^36] | [Enhancing Graph Representation of the Environment through Local and Cloud Computation.](http://arxiv.org/abs/2309.12692) | 通过本地和云计算增强环境的图表示，提供语义化的机器人环境表示，消除了对特定工具的需求。 |
| [^37] | [QAL-BP: An Augmented Lagrangian Quantum Approach for Bin Packing Problem.](http://arxiv.org/abs/2309.12678) | QAL-BP是一种增广拉格朗日量子方法，专门用于解决装箱问题。它利用增广拉格朗日方法将装箱约束加入目标函数，并通过分析估计启发式乘数，消除了需要根据实例计算Lagrangian系数的需求。 |
| [^38] | [TrTr: A Versatile Pre-Trained Large Traffic Model based on Transformer for Capturing Trajectory Diversity in Vehicle Population.](http://arxiv.org/abs/2309.12677) | 本研究使用Transformer模型来捕捉车辆群体中轨迹的多样性，在交通任务中具有重要意义。通过分析注意力机制和设计预训练任务，实现了对车辆轨迹的学习，并提出了适用于交通任务的数据结构和噪声。 |
| [^39] | [Vision Transformers for Computer Go.](http://arxiv.org/abs/2309.12675) | 本研究探索了视觉Transformer在围棋中的应用，并通过与传统的残差网络进行比较，从预测准确性、胜率、内存、速度等多个方面展示了其在围棋中的重要作用。 |
| [^40] | [On Sparse Modern Hopfield Model.](http://arxiv.org/abs/2309.12673) | 本文介绍了稀疏的现代 Hopfield 模型，通过引入稀疏能量函数和稀疏记忆检索动力学，实现了对稀疏注意机制的一步近似。相比密集模型，稀疏模型的记忆检索误差上界更紧凑，具有明确的稀疏优势条件。同时，稀疏的现代 Hopfield 模型还保持了其密集对应物的稳健理论性质。 |
| [^41] | [How to Fine-tune the Model: Unified Model Shift and Model Bias Policy Optimization.](http://arxiv.org/abs/2309.12671) | 本文提出了一个统一模型偏移和模型偏差的优化目标，并通过微调过程实现了自适应的模型更新，以提供性能改进保证和避免模型过拟合。 |
| [^42] | [Natural revision is contingently-conditionalized revision.](http://arxiv.org/abs/2309.12655) | 自然修正是一种有条件的修正方式，它尽可能少地改变信念来融入新信息，并将修正限制在当前条件下。 |
| [^43] | [Are Deep Learning Classification Results Obtained on CT Scans Fair and Interpretable?.](http://arxiv.org/abs/2309.12632) | 深度学习在CT扫描分类中的结果往往只关注准确性，而忽视了公正性和解释性，导致模型不可信和不适用于真实场景。 |
| [^44] | [A Quantum Computing-based System for Portfolio Optimization using Future Asset Values and Automatic Reduction of the Investment Universe.](http://arxiv.org/abs/2309.12627) | 本研究提出了一种基于量子计算的投资组合优化系统Q4FuturePOP，它创新地利用未来资产价值进行建模，并引入了一个自动减少投资范围的模块。通过实验讨论了Q4FuturePOP的原型版本中不同模块的初步性能。 |
| [^45] | [Construction contract risk identification based on knowledge-augmented language model.](http://arxiv.org/abs/2309.12626) | 本文提出了一种基于增强语言模型的建筑合同风险识别方法，利用具备建筑合同知识的大型语言模型模拟人类专家的合同审查过程。该方法无需调整，能够识别建筑合同风险，并在真实环境中取得了良好性能。 |
| [^46] | [DRG-LLaMA : Tuning LLaMA Model to Predict Diagnosis-related Group for Hospitalized Patients.](http://arxiv.org/abs/2309.12625) | DRG-LLaMA是一个通过在临床笔记上细调的大型语言模型，用于改进住院患者的诊断相关分组预测。在多个评估指标上，DRG-LLaMA-7B相对于其他模型取得了显著的改进，并能够高准确度地预测基本DRG和并发症/合并症（CC）/重大并发症或合并症（MCC）的状态。 |
| [^47] | [From Text to Trends: A Unique Garden Analytics Perspective on the Future of Modern Agriculture.](http://arxiv.org/abs/2309.12579) | 这项研究引入了一个基于机器学习的框架，利用园艺领域的在线问答数据来提高农业教育和管理效果，并通过分类和时间分析来预测未来的问题趋势。 |
| [^48] | [Understanding Patterns of Deep Learning ModelEvolution in Network Architecture Search.](http://arxiv.org/abs/2309.12576) | 本文研究了网络架构搜索中深度学习模型演化的模式，揭示了正则化进化算法对模型结构演化的影响，并讨论了分布式和缓存方面的机会，以及模型架构流行度的影响因素。 |
| [^49] | [Creativity Support in the Age of Large Language Models: An Empirical Study Involving Emerging Writers.](http://arxiv.org/abs/2309.12570) | 本文通过实证研究探讨了大型语言模型（LLM）在协助专业作家方面的效用，并发现作家们更倾向于在翻译和审查阶段中寻求LLM的帮助。 |
| [^50] | [A Study on Learning Social Robot Navigation with Multimodal Perception.](http://arxiv.org/abs/2309.12568) | 本文通过利用大规模真实世界数据集，综合研究了利用多模态感知学习社交机器人导航的方法。研究结果发现，机器学习方法可以有效地捕捉复杂而微妙的社交互动，而无需手工制作简化模型或成本函数。 |
| [^51] | [Machine Learning Meets Advanced Robotic Manipulation.](http://arxiv.org/abs/2309.12560) | 该论文回顾了应用于实际操作任务的机器学习方法的前沿技术和最新趋势，并提出了改进机器学习方法在训练和部署阶段安全性、可靠性和效率的方法。 |
| [^52] | [Invariant Learning via Probability of Sufficient and Necessary Causes.](http://arxiv.org/abs/2309.12559) | 本研究通过引入充分因素和必要因素的概率（PNS）来改善在未知测试分布上的泛化问题，以解决现有方法主要关注因果性的不变性属性而忽视充分性和必要性条件的问题。 |
| [^53] | [PlanFitting: Tailoring Personalized Exercise Plans with Large Language Models.](http://arxiv.org/abs/2309.12555) | PlanFitting是一个对话型人工智能，利用大型语言模型的生成能力帮助用户定制个性化的运动计划，并在用户研究中证明了它生成个性化、可操作和有据可依的运动计划的潜力。 |
| [^54] | [Provably Robust and Plausible Counterfactual Explanations for Neural Networks via Robust Optimisation.](http://arxiv.org/abs/2309.12545) | 本文提出了一种名为PROPLACE的方法，通过鲁棒优化技术为神经网络提供可证明的鲁棒和可信的反事实解释，解决了现有方法在保持鲁棒性的同时生成不合理解释的问题。 |
| [^55] | [Curriculum Reinforcement Learning via Morphology-Environment Co-Evolution.](http://arxiv.org/abs/2309.12529) | 本文通过形态-环境共同进化的方式，优化了强化学习代理和形态，实现了一个训练具有泛化性的强化学习课程，并自动改变环境和形态。 |
| [^56] | [Knowledge Graph Embedding: An Overview.](http://arxiv.org/abs/2309.12501) | 该论文综述了知识图谱嵌入的研究状态，介绍了两个主要分支：基于距离和基于语义匹配的方法。还讨论了CompoundE和CompoundE3D模型，并揭示了一个潜在的研究趋势。 |
| [^57] | [Exploring the Impact of Training Data Distribution and Subword Tokenization on Gender Bias in Machine Translation.](http://arxiv.org/abs/2309.12491) | 这项研究探索了训练数据分布和子词标记对机器翻译中性别偏见的影响。研究发现，模型训练语料库中性别形式的不平衡是导致性别偏见的主要因素，而子词拆分的影响较小。同时，研究还发现，通过分析子词拆分可以很好地估计训练数据中性别形式的不平衡。最后，通过仅微调标记嵌入层可以减少女性和男性之间性别预测准确性的差距。 |
| [^58] | [Studying and improving reasoning in humans and machines.](http://arxiv.org/abs/2309.12485) | 本研究通过对大型语言模型（LLM）和人类的推理能力进行比较研究，发现LLM在推理中存在类似于人类启发式推理的错误，但与人类推理有重要差异，最新的LLM版本几乎消除了模型的限制。此外，人类和机器对相同的提示方案的反应不同。这些结果对我们的认识论有重大影响。 |
| [^59] | [State2Explanation: Concept-Based Explanations to Benefit Agent Learning and User Understanding.](http://arxiv.org/abs/2309.12482) | 本论文致力于开发一种基于概念的解释方法，旨在提高非AI专家对AI决策的理解。通过定义顺序决策设置中的“概念”以及探索基于概念的解释对RL agent学习效果和最终用户对agent决策理解的双重好处，我们提出了一个统一的框架。 |
| [^60] | [SAVME: Efficient Safety Validation for Autonomous Systems Using Meta-Learning.](http://arxiv.org/abs/2309.12474) | 本论文提出了一种使用元学习进行高效安全验证的方法，通过集成贝叶斯方法和多臂赌博机框架，加速验证过程。该方法学习在测试中容易引发故障的场景参数分布和能够进行快速准确模拟的保真度设置分布，并通过评估保真度设置分布是否有助于对新场景的场景参数分布进行更快的学习来进一步提高效率。 |
| [^61] | [Multimodal Deep Learning for Scientific Imaging Interpretation.](http://arxiv.org/abs/2309.12460) | 本研究提出了一种多模态深度学习框架，通过模拟人类与扫描电子显微镜图像的交互，利用文本和视觉数据进行精细数据合成和评估。该模型（GlassLLaVA）能够准确解释、识别关键特征和检测以前未见的SEM图像中的缺陷，同时引入了适用于多种科学成像应用的灵活评估指标。 |
| [^62] | [LongDocFACTScore: Evaluating the Factuality of Long Document Abstractive Summarisation.](http://arxiv.org/abs/2309.12455) | LongDocFACTScore是一种评估长文档生成摘要实证性的评估框架，可以解决传统自动评估度量标准无法评估长文档摘要事实一致性的问题。 |
| [^63] | [Ensemble Neural Networks for Remaining Useful Life (RUL) Prediction.](http://arxiv.org/abs/2309.12445) | 提出了一种使用集成神经网络的方法进行概率性剩余寿命预测，该方法解耦了来自系统和模型参数的不确定性，并且可以准确地建模和解释预测的信心。 |
| [^64] | [Can LLMs Augment Low-Resource Reading Comprehension Datasets? Opportunities and Challenges.](http://arxiv.org/abs/2309.12426) | 本研究分析了使用大型语言模型(LLMs)对低资源阅读理解数据集进行增强的可能性。结果显示，GPT-4可以用作低资源读解任务中人工注释者的替代品。这项工作突出了LLMs作为合成数据增强器的机遇和挑战，并发布了增强版本的低资源数据集。 |
| [^65] | [Event Prediction using Case-Based Reasoning over Knowledge Graphs.](http://arxiv.org/abs/2309.12423) | 本研究引入了一个基于案例推理模型EvCBR，在知识图谱中利用类似因果事件来预测新结果事件的属性。该模型不需要训练步骤，通过统计度量和基于路径的预测方法实现。研究结果表明，该方法在事件预测任务中取得了良好的效果。 |
| [^66] | [Constraints First: A New MDD-based Model to Generate Sentences Under Constraints.](http://arxiv.org/abs/2309.12415) | 本文介绍了一种基于多值决策图的新模型，用于生成强约束文本。通过将生成句子问题形式化为离散组合优化问题，并利用多值决策图来处理约束，可以得到详尽解集。应用语言模型保留最佳句子，并在英语和法语上进行了详细讨论。该方法相比传统的视力筛查测试带来了重大突破，并且具有广泛的适用性。 |
| [^67] | [SCOB: Universal Text Understanding via Character-wise Supervised Contrastive Learning with Online Text Rendering for Bridging Domain Gap.](http://arxiv.org/abs/2309.12382) | 本文提出了一种名为SCOB的新预训练模型，它通过字符级别的监督对比学习和在线文本渲染来有效地预训练文档和场景文本领域，从而弥合了领域之间的差异。SCOB还能实现弱监督学习，大大降低了注释成本。 |
| [^68] | [Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis.](http://arxiv.org/abs/2309.12368) | 本研究探索了在复杂医疗决策中重新思考人工智能与人类合作的设计要求，以脓毒症诊断为例。研究发现，在人工智能系统中，支持临床专家在决策过程的中间阶段发挥作用（如生成假设或收集数据）是至关重要的，而不仅仅关注最终决策。 |
| [^69] | [Examining the Influence of Varied Levels of Domain Knowledge Base Inclusion in GPT-based Intelligent Tutors.](http://arxiv.org/abs/2309.12367) | 本文研究了在基于GPT的智能辅导系统中将领域知识库与语言模型集成，以提高回答的可靠性。通过设计可扩展的知识库和评估实验，我们展示了该系统的有效性。学生和领域专家对于智能辅导系统的回答进行了验证和排名。 |
| [^70] | [An Efficient Intelligent Semi-Automated Warehouse Inventory Stocktaking System.](http://arxiv.org/abs/2309.12365) | 本研究提出了一个智能库存管理系统，通过结合条码和分布式flutter应用技术，以及大数据分析实现数据驱动的决策，解决了库存管理中的准确性、监测延迟和过度依赖主观经验的挑战。 |
| [^71] | [Investigating Online Financial Misinformation and Its Consequences: A Computational Perspective.](http://arxiv.org/abs/2309.12363) | 这篇论文调查了在线财经错误信息及其后果，包括错误信息的类型、来源和影响。研究强调了早期发现和缓解策略可能对保护投资者、增强市场透明度和维护金融稳定的意义。 |
| [^72] | [ChatGPT Assisting Diagnosis of Neuro-ophthalmology Diseases Based on Case Reports.](http://arxiv.org/abs/2309.12361) | 本研究评估了大型语言模型ChatGPT在神经眼科疾病诊断中的辅助效果。实验结果显示，ChatGPT在13个病例中正确诊断了59%，而ChatGPT Plus和两名神经眼科医生的正确率分别达到了82%和86%。这表明ChatGPT可以作为神经眼科疾病诊断的有用工具。 |
| [^73] | [Efficient Social Choice via NLP and Sampling.](http://arxiv.org/abs/2309.12360) | 本文通过结合自然语言处理和抽样技术，提出了一种高效的注意力感知社会选择系统，该系统使用训练有素的NLP模型估计了提案通过的概率，并通过采样多数来决定提案。 |
| [^74] | [Mapping AI Arguments in Journalism Studies.](http://arxiv.org/abs/2309.12357) | 本研究探索和提供了一种分类方法，可以用于研究新闻学和大众传播中的人工智能（AI）。通过理解每个子领域的操作原理，学者们可以在分析特定研究课题时增强他们关注特定方面的能力。 |
| [^75] | [A Critical Examination of the Ethics of AI-Mediated Peer Review.](http://arxiv.org/abs/2309.12356) | 最近人工智能系统对学术同行评审带来了希望和危险。然而，无论是AI还是人类同行评审系统都存在相关问题，例如偏见、滥用和缺乏透明度。因此，AI驱动的同行评审的合法性取决于与科学伦理的一致性。 |
| [^76] | [Establishing trust in automated reasoning.](http://arxiv.org/abs/2309.12351) | 本研究探讨了自动推理系统的可审查性和可信度问题，并提出了通过技术和社会措施相结合的方式来增加信任的可能步骤。 |
| [^77] | [Considerations for health care institutions training large language models on electronic health records.](http://arxiv.org/abs/2309.12339) | 本研究通过分析数据集大小、模型大小和使用电子病历数据进行大型语言模型（LLM）训练的成本，提供了一个思考医疗机构是否应该训练LLM以及如何在预算限制下选择合适LLM的框架。 |
| [^78] | [Artificial Intelligence and Aesthetic Judgment.](http://arxiv.org/abs/2309.12338) | 这篇论文讨论了生成型人工智能产生的创造性输出与人类审美判断之间的联系，指出人们对于生成型人工智能产生的反应是经由艺术判断来调节的。同时，论文还提到了对于生成型人工智能的反应可能源于对其未来发展的担忧，并探讨了艺术作品因为其文化条件和人类状况的双重解读难题。 |
| [^79] | [ActiveAI: Introducing AI Literacy for Middle School Learners with Goal-based Scenario Learning.](http://arxiv.org/abs/2309.12337) | ActiveAI项目为初中学生提供了一种基于AI4K12知识框架的人工智能素养学习体验，通过目标情景学习、即时反馈和项目学习等机制帮助学生有效地与人工智能系统互动，并培养他们评估人工智能生成结果的能力。 |
| [^80] | [Education in the age of Generative AI: Context and Recent Developments.](http://arxiv.org/abs/2309.12332) | 本文总结了生成式人工智能在教育领域的发展，并讨论了其潜力、应用、限制、伦理等方面的问题。 |
| [^81] | [Approaches to Generative Artificial Intelligence, A Social Justice Perspective.](http://arxiv.org/abs/2309.12331) | 本文以社会正义视角探讨生成人工智能方法，研究这些模型的训练、固有的偏见以及检测AI生成写作中的潜在不公正性。 |
| [^82] | [Ground Truth Or Dare: Factors Affecting The Creation Of Medical Datasets For Training AI.](http://arxiv.org/abs/2309.12327) | 这项研究探讨了影响医学数据集创建的外部和内部因素，包括法规限制、上下文、商业和运营压力、认识差异以及标记的局限性。 |
| [^83] | [FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare.](http://arxiv.org/abs/2309.12325) | FUTURE-AI是第一个国际共识框架，为医疗保健领域的可信AI工具开发和部署提供指导原则和最佳实践。 |
| [^84] | [A Case for AI Safety via Law.](http://arxiv.org/abs/2309.12321) | 本文主张通过法律制度来解决人工智能安全问题，认为法律是解决该问题的最佳途径。 |
| [^85] | [Use Scenarios & Practical Examples of AI Use in Education.](http://arxiv.org/abs/2309.12320) | 本报告提供了一组使用场景和实际例子，旨在帮助教师在教育中引入人工智能，以激发创造力和指导教学。 |
| [^86] | [MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models.](http://arxiv.org/abs/2309.12284) | MetaMath是一种专门用于数学推理的微调语言模型，通过从多个角度重新编写问题来生成数学问题，并在两个基准测试中取得了优于其他开源语言模型的表现。 |
| [^87] | [LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset.](http://arxiv.org/abs/2309.11998) | LMSYS-Chat-1M是一个包含一百万个实际对话的大规模数据集，通过其多样性和用例展示了其在理解和推进LLM能力方面的价值。 |
| [^88] | [Representation Abstractions as Incentives for Reinforcement Learning Agents: A Robotic Grasping Case Study.](http://arxiv.org/abs/2309.11984) | 本文研究了不同状态表示对强化学习代理在机器人抓取任务上的影响，结果显示使用数字状态的代理能够在模拟环境中成功解决问题，并在真实机器人上实现了学习策略的可转移性。 |
| [^89] | [Rethinking the Evaluating Framework for Natural Language Understanding in AI Systems: Language Acquisition as a Core for Future Metrics.](http://arxiv.org/abs/2309.11981) | 这篇论文重新思考了人工智能系统中自然语言理解的评估框架，提出了以语言习得为核心的全面框架，旨在解决传统度量方法面临的问题，并借鉴了大型语言模型的进展。 |
| [^90] | [Audio Contrastive based Fine-tuning.](http://arxiv.org/abs/2309.11895) | 本论文提出了一种基于音频对比的微调方法（AudioConFit），通过借助对比学习的可转移性，该方法在各种音频分类任务中表现出强大的泛化能力，并在不同设置下实现了最先进的结果。 |
| [^91] | [FluentEditor: Text-based Speech Editing by Considering Acoustic and Prosody Consistency.](http://arxiv.org/abs/2309.11725) | 这篇论文提出了一种名为"FluentEditor"的流畅语音编辑模型，通过考虑流畅度意识的训练准则实现文本化语音编辑。其中，声学一致性约束和韵律一致性约束用于保持语音的流畅性和整体风格一致性。 |
| [^92] | [CFGPT: Chinese Financial Assistant with Large Language Model.](http://arxiv.org/abs/2309.10654) | CFGPT是一个具有大型语言模型的中国金融助手，包括CFData用于预训练和监督微调，以及CFLLM用于处理金融文本，CFAPP用于实际金融应用。这个框架在金融领域的各个方面展现出了巨大的潜力。 |
| [^93] | [RadOnc-GPT: A Large Language Model for Radiation Oncology.](http://arxiv.org/abs/2309.10160) | RadOnc-GPT是一种专门用于放射肿瘤学的大型语言模型，通过先进的调整方法进行微调，在生成治疗方案、确定疗法和提供诊断描述等关键任务上具有显著改进，展示了利用领域特定知识进行微调的大型语言模型在高度专业化的医疗领域具有的潜力。 |
| [^94] | [Talk2Care: Facilitating Asynchronous Patient-Provider Communication with Large-Language-Model.](http://arxiv.org/abs/2309.09357) | 本研究利用大型语言模型（LLMs）来促进患者和医生之间的异步通信，通过访谈研究了解了他们对LLMs的需求，并构建了一个名为Talk2Care的LLM驱动的通信系统。 |
| [^95] | [ChatGPT v Bard v Bing v Claude 2 v Aria v human-expert. How good are AI chatbots at scientific writing? (ver. 23Q3).](http://arxiv.org/abs/2309.08636) | 本文综合分析了在人文学科和考古学领域中六个AI聊天机器人在学术写作方面的能力和局限性，发现它们在重新组合现有知识方面表现出色，但在产生原创科学内容方面存在问题。 |
| [^96] | [Efficient Reinforcement Learning for Jumping Monopods.](http://arxiv.org/abs/2309.07038) | 本论文研究了如何通过在强化学习框架中注入物理知识来解决跳跃式单脚机器人的控制问题，这样可以大幅减少学习时间并且能够学习和修正可能出现的错误。 |
| [^97] | [Modeling Recommender Ecosystems: Research Challenges at the Intersection of Mechanism Design, Reinforcement Learning and Generative Models.](http://arxiv.org/abs/2309.06375) | 建模推荐系统生态系统需要考虑参与者激励、行为以及策略引发的相互作用，通过强化学习进行长期优化，使用社会选择方法进行权衡，并减少信息不对称。 |
| [^98] | [DSLOT-NN: Digit-Serial Left-to-Right Neural Network Accelerator.](http://arxiv.org/abs/2309.06019) | DSLOT-NN是一种数字串行从左到右的神经网络加速器，可以加速深度神经网络中的卷积运算，并且通过评估和终止无效的卷积操作实现功耗和能量的大规模节省。 |
| [^99] | [Contextual Biasing of Named-Entities with Large Language Models.](http://arxiv.org/abs/2309.00723) | 本文研究了使用大型语言模型进行上下文偏倚的方法，通过在第二次打分时提供额外的上下文信息，以提高自动语音识别性能。我们利用提示信息对大型语言模型进行boosting，并采用多任务训练以预测实体类别和下一个标记。此外，我们提出了动态提示方法来提高效率。 |
| [^100] | [Efficacy of Neural Prediction-Based NAS for Zero-Shot NAS Paradigm.](http://arxiv.org/abs/2308.16775) | 这项研究提出了一种新的方法，通过深度学习进行零样本架构搜索，通过使用可学习的傅里叶正弦和求和编码来构建计算的前馈图，从而解决了基于预测的神经架构搜索中性能指标泛化的限制。 |
| [^101] | [Revisiting Scalarization in Multi-Task Learning: A Theoretical Perspective.](http://arxiv.org/abs/2308.13985) | 本论文重新审视了多任务学习中的标量化方法，并从理论的角度探讨了标量化是否能够充分探索帕累托前沿。结果显示，与最近的研究声称的经验优势相反，标量化本质上无法进行全面探索，特别是对于那些平衡了paren |
| [^102] | [Pre-gated MoE: An Algorithm-System Co-Design for Fast and Scalable Mixture-of-Expert Inference.](http://arxiv.org/abs/2308.12066) | 预门控MoE系统通过算法和系统的共同设计，有效解决了传统MoE架构的计算和存储挑战。 |
| [^103] | [Exploring Transfer Learning in Medical Image Segmentation using Vision-Language Models.](http://arxiv.org/abs/2308.07706) | 本论文提出使用视觉-语言模型进行医学图像分割的迁移学习，并评估了其在医学领域的可迁移性。通过捕捉语义信息和引入新的图像描述变化，实现了对多样化医学图像的分割。 |
| [^104] | [Developmental Bootstrapping of AIs.](http://arxiv.org/abs/2308.04586) | 传统的符号AI方法和深度学习AI方法无法满足创建强大和可信赖的AI的挑战，然而，发展脱靴法通过模仿人类儿童的能力发展过程，为创建稳健可靠的AI提供了希望。 |
| [^105] | [MiVOLO: Multi-input Transformer for Age and Gender Estimation.](http://arxiv.org/abs/2307.04616) | 本论文提出了一种简单的方法MiVOLO，使用最新的视觉变换器进行年龄和性别估计。该方法将面部信息和人物图像数据集成到一个统一的模型中，提高了模型的泛化能力，并在图像中人脸不可见的情况下仍能提供令人满意的结果。实验证明了该方法在四个基准测试上达到了最先进的性能，并具有实时处理能力。 |
| [^106] | [Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions.](http://arxiv.org/abs/2307.03941) | 本文探讨了在大型语言模型时代的被遗忘权（RTBF）面临的挑战，提供了实施技术解决方案的见解。 |
| [^107] | [Elastic Decision Transformer.](http://arxiv.org/abs/2307.02484) | 弹性决策变压器（EDT）通过在测试时间进行动作推断时调整历史长度来实现轨迹拼接，填补了决策变压器（DT）在这一方面的性能差距，并且在多任务情况下胜过基于Q-Learning的方法。 |
| [^108] | [Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research.](http://arxiv.org/abs/2307.02131) | 本研究利用反事实解释来探索医学研究中的“假如”场景，通过提供个性化和情境特定的见解，拓展了我们对现有边界的理解，并填补了机器学习算法结果解释的缺失。 |
| [^109] | [Mitigating Bias: Enhancing Image Classification by Improving Model Explanations.](http://arxiv.org/abs/2307.01473) | 本文提出了一种通过改进模型解释的方法来缓解图像分类中的偏见问题，通过引导模型的注意力向前景集中，从而提升对主要概念的学习效果。 |
| [^110] | [Personality Traits in Large Language Models.](http://arxiv.org/abs/2307.00184) | 该研究介绍了一种综合方法，用于验证大型语言模型（LLMs）生成的文本中展示的人格特质。研究发现，部分LLMs在特定提示配置下模拟的人格可靠且有效，特别是对于更大和经过指导微调的模型。此外，LLMs的输出中的人格特质可以根据需要进行塑造。 |
| [^111] | [A Survey on Datasets for Decision-making of Autonomous Vehicle.](http://arxiv.org/abs/2306.16784) | 本综述调查了自动驾驶决策的数据集，比较了车辆、环境和驾驶员相关的数据集，并总结了它们的特点。这有助于研究人员找到适合的数据集来开发数据驱动的自动驾驶决策方法。 |
| [^112] | [About the Cost of Central Privacy in Density Estimation.](http://arxiv.org/abs/2306.14535) | 本研究对于利普希茨和 Sobolev 空间中的非参数密度估计，通过考虑中心隐私的影响，发现了直方图估计器在 L2 风险下对于利普希茨分布是最优的，并且在正常差分隐私情况下也是如此；同时发现，在一些情况下，施加隐私会降低对于 Sobolev 密度的正则极小风险估计。此外，本研究还发现在纯投影估计设定下，所谓的投影估计器对于相同类密度几乎是最优的。 |
| [^113] | [The False Dawn: Reevaluating Google's Reinforcement Learning for Chip Macro Placement.](http://arxiv.org/abs/2306.09633) | 谷歌2021年在《自然》杂志上发表的一篇论文声称其使用强化学习在芯片设计领域进行了创新，但两项独立的评估表明，谷歌的方法不如人类设计师、不如一个众所周知的算法（模拟退火），并且也不如普遍可用的商业软件，文章的完整性也遭到了严重的损害。 |
| [^114] | [AVIS: Autonomous Visual Information Seeking with Large Language Models.](http://arxiv.org/abs/2306.08129) | 本文提出了一个基于大型语言模型的自主信息检索视觉问答框架AVIS，可以解决视觉问题所需的外部知识获取问题。 |
| [^115] | [TopP\&R: Robust Support Estimation Approach for Evaluating Fidelity and Diversity in Generative Models.](http://arxiv.org/abs/2306.08013) | 本文提出了一种鲁棒可靠的生成模型评估指标TopP\&R，通过引入拓扑和统计处理进行严格的支持估计。TopP\&R仅保留具有一定置信水平的具有拓扑和统计上重要性的特征，对于噪声特征具有强大的鲁棒性，并提供了统计一致性。 |
| [^116] | [Urban Spatiotemporal Data Synthesis via Neural Disaggregation.](http://arxiv.org/abs/2306.07292) | 本研究提出了一种基于神经网络的城市时空数据合成方法，旨在通过分解粗糙的低分辨率地理单元的聚合城市数据来合成细粒度，高分辨率的城市数据，以增加高度聚合的城市数据的可用性和实现价值。 |
| [^117] | [ShiftAddViT: Mixture of Multiplication Primitives Towards Efficient Vision Transformer.](http://arxiv.org/abs/2306.06446) | ShiftAddViT通过使用位移和加法等多种乘法原语对ViT进行重新参数化，实现了减少乘法操作的高效视觉变换器模型，可以在GPU上实现端到端的推理加速，无需从头训练。 |
| [^118] | [AI Art Curation: Re-imagining the city of Helsinki in occasion of its Biennial.](http://arxiv.org/abs/2306.03753) | 本研究通过AI策展和观众互动，利用机器学习模型重新构想了赫尔辛基市艺术双年展，使用视觉-文本模型将室内艺术品放置在公共空间中，生成合成的360艺术全景图，以创造出艺术品与城市空间的新视角。 |
| [^119] | [Inference-Time Intervention: Eliciting Truthful Answers from a Language Model.](http://arxiv.org/abs/2306.03341) | 本研究提出推理时间干预（ITI）技术，通过在推理过程中跨越有限数量的注意力头，显着提高大型语言模型的真实性。在TruthfulQA基准上，ITI使LLaMA模型的真实性从32.5%提高到65.1%。ITI是一种最小程度的干扰，计算廉价，且数据效率高。 |
| [^120] | [Scale Matters: Attribution Meets the Wavelet Domain to Explain Model Sensitivity to Image Corruptions.](http://arxiv.org/abs/2305.14979) | 该论文介绍了一种基于小波域的属性方法WCAM，能够解释神经网络模型对图像损坏的敏感性，确定预测的足够信息，并阐明缩放如何增加准确性。 |
| [^121] | [How to Index Item IDs for Recommendation Foundation Models.](http://arxiv.org/abs/2305.06569) | 本研究对推荐基础模型的项目索引问题进行了系统检查，提出了一种新的上下文感知索引方法，该方法在项目推荐准确性和文本生成质量方面具有优势。 |
| [^122] | [Few-shot Link Prediction on N-ary Facts.](http://arxiv.org/abs/2305.06104) | 本文提出了一个新任务——少样本N-元事实链接预测，并提出了一个名为FLEN的模型来实现。FLEN由三个模块组成，可以从有限的标记实例中预测N-元事实中的缺失实体。 |
| [^123] | [CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds.](http://arxiv.org/abs/2305.00969) | CryCeleb是一个基于婴儿哭声的说话人认证数据集，包括超过6小时的手动分割哭声，可用于研究婴儿哭声分析。 |
| [^124] | [Learning Terrain-Aware Kinodynamic Model for Autonomous Off-Road Rally Driving With Model Predictive Path Integral Control.](http://arxiv.org/abs/2305.00676) | 本研究提出了一种地形感知的运动学模型学习与预测控制法，可以生成可靠的 6 自由度运动预测，并可在无需训练时基于机器学习进行接触力估计，实现了对复杂越野场地的安全与鲁棒自主驾驶控制。 |
| [^125] | [Differentiable graph-structured models for inverse design of lattice materials.](http://arxiv.org/abs/2304.05422) | 本文提出了一种使用图形表示结构和属性的晶格材料的计算方法，使用可微分传递算法计算机械属性以实现反向设计，进而实现了可扩展的、具有前所未有的结构和功能多样性的晶格材料设计。 |
| [^126] | [Reinforce Data, Multiply Impact: Improved Model Accuracy and Robustness with Dataset Reinforcement.](http://arxiv.org/abs/2303.08983) | 提出了一种名为数据集增强的策略，一次性改进数据集，从而提高任何经过增强的数据集训练的模型的准确性、鲁棒性和校准性。例如，使用ImageDataNet+训练的ResNet-50在ImageNet验证集上的准确率提高了1.7％，在ImageNetV2上提高了3.5％，在ImageNet-R上提高了10.0％。 |
| [^127] | [Synthetic Experience Replay.](http://arxiv.org/abs/2303.06614) | 本文提出了合成经验回放方法解决深度强化学习中数据匮乏问题，通过巧妙应用生成建模技术来扩充数据效果显著。 |
| [^128] | [Deep Imbalanced Time-series Forecasting via Local Discrepancy Density.](http://arxiv.org/abs/2302.13563) | 该论文提出了一种基于局部差异密度的重新加权框架，用于解决时间序列预测中的深度不平衡问题。这个框架通过降低突发变化引起的损失，增加正常状态引起的损失，使模型能够学习可推广的模式。 |
| [^129] | [Red Teaming Deep Neural Networks with Feature Synthesis Tools.](http://arxiv.org/abs/2302.10894) | 本文提出了一个用于评估可解释性工具的基准，通过训练模型以对特定触发器产生特定输出的方式，可以解决传统可解释性方法无法分析未知特征行为的问题。 |
| [^130] | [Generalized Munchausen Reinforcement Learning using Tsallis KL Divergence.](http://arxiv.org/abs/2301.11476) | 这篇论文通过研究广义的Tsallis KL散度，扩展了Munchausen强化学习算法，并提供了一种将KL正则化纳入实际算法的方法。对于Tsallis KL，当$q > 1$时，可以获得新的策略优化选项。 |
| [^131] | [A-NeSI: A Scalable Approximate Method for Probabilistic Neurosymbolic Inference.](http://arxiv.org/abs/2212.12393) | 本文介绍了一种名为A-NeSI的新颖PNL框架，它使用神经网络实现了近似推理，能够保证概率逻辑语义的同时解决了PNL的可扩展性问题，能够在安全关键应用中保证逻辑约束的满足。 |
| [^132] | [Lessons learned from the evaluation of Spanish Language Models.](http://arxiv.org/abs/2212.08390) | 该论文对西班牙语语言模型进行了全面比较，发现先前被忽视的大公司的多语言模型优于单语言模型，在西班牙语语言模型的评估领域产生了重大变化。需要进一步研究语料库大小、质量和预训练技术的影响。 |
| [^133] | [Mean Shift Mask Transformer for Unseen Object Instance Segmentation.](http://arxiv.org/abs/2211.11679) | 本文提出了一种新的均值漂移掩模变换器，用于联合训练和推断特征提取器和聚类器，可用于未知物体实例分割，在COCO数据集上表现出竞争性的性能，并在罕见和未知物体类别上具有显着优势。 |
| [^134] | [Observable Perfect Equilibrium.](http://arxiv.org/abs/2210.16506) | 本文提出一种新的博弈均衡概念——可观测完美均衡，在顺序不完全信息博弈中可以帮助创建真正的策略代理。这种均衡概念在公开观察的行动概率方面具有鲁棒性。 |
| [^135] | [FALCON: Faithful Neural Semantic Entailment over ALC Ontologies.](http://arxiv.org/abs/2208.07628) | FALCON是一个基于ALC本体的模糊神经推理器，能够通过多个模型结构计算忠实的语义蕴涵，赋予神经网络世界模型和推理能力。在实践中，它实现了近似推理、处理不一致性推理，并通过整合ALC表达的知识改进了生物医学领域的机器学习。 |
| [^136] | [Optimising Rolling Stock Planning including Maintenance with Constraint Programming and Quantum Annealing.](http://arxiv.org/abs/2109.07212) | 本文比较了约束编程和量子退火方法在优化机车编组分配与维护任务中的应用，并发现两种方法在当前发展阶段的量子退火机器上产生相当的结果。 |

# 详细

[^1]: E(2)-对称图规划用于导航

    E(2)-Equivariant Graph Planning for Navigation. (arXiv:2309.13043v1 [cs.RO])

    [http://arxiv.org/abs/2309.13043](http://arxiv.org/abs/2309.13043)

    本文提出了一种E(2)-对称图规划用于导航的方法，通过利用欧几里得对称性和开发等变消息传递网络，实现了高效、稳定和具有泛化能力的机器人导航学习。

    

    机器人导航的学习是一项关键且具有挑战性的任务。真实世界数据集的稀缺性和昂贵性需要高效的学习方法。在本文中，我们利用二维导航规划中的欧几里得对称性，该对称性源于参考框架之间的欧几里得变换，并实现参数共享。为了解决非结构化环境的挑战，我们将导航问题规划为在几何图上的规划，并开发了一种等变消息传递网络来执行价值迭代。此外，为了处理多摄像头输入，我们提出了一个可学习的等变层将特征提升到所需空间。我们在包括结构化和非结构化环境、已知和未知地图以及给定点目标或语义目标的五个不同任务上进行了全面评估。我们的实验结果证实了训练效率、稳定性和泛化性能的显著优势。

    Learning for robot navigation presents a critical and challenging task. The scarcity and costliness of real-world datasets necessitate efficient learning approaches. In this letter, we exploit Euclidean symmetry in planning for 2D navigation, which originates from Euclidean transformations between reference frames and enables parameter sharing. To address the challenges of unstructured environments, we formulate the navigation problem as planning on a geometric graph and develop an equivariant message passing network to perform value iteration. Furthermore, to handle multi-camera input, we propose a learnable equivariant layer to lift features to a desired space. We conduct comprehensive evaluations across five diverse tasks encompassing structured and unstructured environments, along with maps of known and unknown, given point goals or semantic goals. Our experiments confirm the substantial benefits on training efficiency, stability, and generalization.
    
[^2]: MosaicFusion: 将扩散模型作为大词汇实例分割的数据增强器

    MosaicFusion: Diffusion Models as Data Augmenters for Large Vocabulary Instance Segmentation. (arXiv:2309.13042v1 [cs.CV])

    [http://arxiv.org/abs/2309.13042](http://arxiv.org/abs/2309.13042)

    MosaicFusion是一种用于大词汇实例分割的数据增强方法，通过将扩散模型作为数据集生成器，能够生成大量合成标记数据。在实验中，我们的方法在准确率和泛化能力方面取得了显著的提升。

    

    我们提出了MosaicFusion，一种简单而有效的基于扩散的数据增强方法，用于大词汇实例分割。我们的方法无需训练，也不依赖于任何标签监督。两个关键设计使我们能够将现成的文本到图像扩散模型作为有用的数据集生成器，用于对象实例和蒙版注释。首先，我们将图像画布分为几个区域，并执行一轮扩散过程，同时基于不同的文本提示生成多个实例。其次，我们通过聚合与对象提示相关联的跨注意力图在层和扩散时间步上，然后进行简单的阈值处理和边缘感知的细化处理，得到相应的实例蒙版。我们的MosaicFusion可以为稀缺和新颖类别产生大量的合成标记数据，而无需复杂的处理。在具有挑战性的LVIS长尾和开放词汇基准上进行的实验结果表明，我们的方法在准确率和泛化能力方面均取得了显著的提升。

    We present MosaicFusion, a simple yet effective diffusion-based data augmentation approach for large vocabulary instance segmentation. Our method is training-free and does not rely on any label supervision. Two key designs enable us to employ an off-the-shelf text-to-image diffusion model as a useful dataset generator for object instances and mask annotations. First, we divide an image canvas into several regions and perform a single round of diffusion process to generate multiple instances simultaneously, conditioning on different text prompts. Second, we obtain corresponding instance masks by aggregating cross-attention maps associated with object prompts across layers and diffusion time steps, followed by simple thresholding and edge-aware refinement processing. Without bells and whistles, our MosaicFusion can produce a significant amount of synthetic labeled data for both rare and novel categories. Experimental results on the challenging LVIS long-tailed and open-vocabulary benchma
    
[^3]: 增强记忆的Conformer用于改进端到端长篇ASR

    Memory-augmented conformer for improved end-to-end long-form ASR. (arXiv:2309.13029v1 [eess.AS])

    [http://arxiv.org/abs/2309.13029](http://arxiv.org/abs/2309.13029)

    该论文提出了一种将记忆增强神经网络添加到Conformer模型中以解决长话语情况下性能下降的问题。实验结果表明，该系统在长话语上优于基准Conformer模型。

    

    Conformer最近被提出作为自动语音识别（ASR）中一种有前景的建模方法，优于循环神经网络和Transformer。然而，总体而言，这些端到端模型（尤其是注意力机制的模型）在长话语的情况下性能明显下降。为了解决这个局限性，我们建议在Conformer的编码器和解码器之间添加一个完全可微分的记忆增强神经网络。这个外部记忆可以增强对长话语的泛化能力，因为它允许系统循环地存储和检索更多的信息。值得注意的是，我们探索了神经图灵机（NTM），从而提出了我们的Conformer-NTM模型架构用于ASR。使用Librispeech的train-clean-100和train-960数据集进行的实验结果表明，对于长话语，所提出的系统优于没有记忆的基准Conformer。

    Conformers have recently been proposed as a promising modelling approach for automatic speech recognition (ASR), outperforming recurrent neural network-based approaches and transformers. Nevertheless, in general, the performance of these end-to-end models, especially attention-based models, is particularly degraded in the case of long utterances. To address this limitation, we propose adding a fully-differentiable memory-augmented neural network between the encoder and decoder of a conformer. This external memory can enrich the generalization for longer utterances since it allows the system to store and retrieve more information recurrently. Notably, we explore the neural Turing machine (NTM) that results in our proposed Conformer-NTM model architecture for ASR. Experimental results using Librispeech train-clean-100 and train-960 sets show that the proposed system outperforms the baseline conformer without memory for long utterances.
    
[^4]: 基于深度学习的混合方法用于优化基于环境的基因型选择

    A Hybrid Deep Learning-based Approach for Optimal Genotype by Environment Selection. (arXiv:2309.13021v1 [cs.LG])

    [http://arxiv.org/abs/2309.13021](http://arxiv.org/abs/2309.13021)

    该论文提出了一种基于深度学习的混合方法，用于优化基于环境的基因型选择。通过整合不同作物品种的天气数据，特别是在不同气候条件下，准确地预测作物产量对于理解其适应性至关重要。论文中开发了两种新颖的卷积神经网络架构，并利用广义集成方法确定了最优的基因型与环境选择模型。

    

    准确的作物产量预测对于改善农业实践和确保作物在不同气候条件下的韧性至关重要。在MLCAS2021作物产量预测挑战中，我们利用包含93,028个训练记录的数据集，预测了10,337个测试记录的产量，在13年（2003-2015年）的时间范围内覆盖了美国28个州和加拿大省份的159个地点。该数据集包括5,838个不同基因型的详细信息和为期214天的生长季节的每日天气数据，使得综合分析成为可能。作为获胜团队之一，我们开发了两种新颖的卷积神经网络（CNN）架构：CNN-DNN模型，结合了CNN和全连接网络；以及CNN-LSTM-DNN模型，加入了LSTM层用于天气变量。利用广义集成方法（GEM），我们确定了最优的基因型与环境选择模型。

    Precise crop yield prediction is essential for improving agricultural practices and ensuring crop resilience in varying climates. Integrating weather data across the growing season, especially for different crop varieties, is crucial for understanding their adaptability in the face of climate change. In the MLCAS2021 Crop Yield Prediction Challenge, we utilized a dataset comprising 93,028 training records to forecast yields for 10,337 test records, covering 159 locations across 28 U.S. states and Canadian provinces over 13 years (2003-2015). This dataset included details on 5,838 distinct genotypes and daily weather data for a 214-day growing season, enabling comprehensive analysis. As one of the winning teams, we developed two novel convolutional neural network (CNN) architectures: the CNN-DNN model, combining CNN and fully-connected networks, and the CNN-LSTM-DNN model, with an added LSTM layer for weather variables. Leveraging the Generalized Ensemble Method (GEM), we determined opt
    
[^5]: 高效的N:M稀疏DNN训练使用算法，架构和数据流协同设计

    Efficient N:M Sparse DNN Training Using Algorithm, Architecture, and Dataflow Co-Design. (arXiv:2309.13015v1 [cs.LG])

    [http://arxiv.org/abs/2309.13015](http://arxiv.org/abs/2309.13015)

    本文提出了一种使用算法，架构和数据流协同设计的高效N:M稀疏DNN训练方案，该方案利用双向权重修剪方法优化计算成本，并通过稀疏加速器硬件支持实现高稀疏比的DNN训练。

    

    稀疏训练是减少DNN计算成本同时保持高准确性的一种有前景的技术。特别是N:M细粒度结构稀疏，其中只有连续M个元素中的N个可以是非零值，因其对硬件友好的模式和达到高稀疏比的能力而受到关注。然而，加速N:M稀疏DNN训练的潜力尚未充分利用，并且缺乏支持N:M稀疏训练的高效硬件。为了解决这些挑战，本文提出了一种使用算法，架构和数据流协同设计的计算高效的N:M稀疏DNN训练方案。在算法层面上，提出了一种双向权重修剪方法（BDWP），利用DNN训练的前向和后向传播过程中权重的N:M稀疏性，可以显著降低计算成本同时保持模型准确性。在架构层面上，提出了一种用于DNN稀疏加速的架构，该架构基于数据流协议，利用稀疏权重的结构模式优化计算性能。

    Sparse training is one of the promising techniques to reduce the computational cost of DNNs while retaining high accuracy. In particular, N:M fine-grained structured sparsity, where only N out of consecutive M elements can be nonzero, has attracted attention due to its hardware-friendly pattern and capability of achieving a high sparse ratio. However, the potential to accelerate N:M sparse DNN training has not been fully exploited, and there is a lack of efficient hardware supporting N:M sparse training. To tackle these challenges, this paper presents a computation-efficient training scheme for N:M sparse DNNs using algorithm, architecture, and dataflow co-design. At the algorithm level, a bidirectional weight pruning method, dubbed BDWP, is proposed to leverage the N:M sparsity of weights during both forward and backward passes of DNN training, which can significantly reduce the computational cost while maintaining model accuracy. At the architecture level, a sparse accelerator for DN
    
[^6]: ReConcile：圆桌会议通过多元LLM的共识改进推理能力

    ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs. (arXiv:2309.13007v1 [cs.CL])

    [http://arxiv.org/abs/2309.13007](http://arxiv.org/abs/2309.13007)

    ReConcile是一个通过多轮讨论和投票机制来增强LLM推理能力的多模型多代理框架。

    

    大型语言模型（LLM）仍然在复杂的推理任务上遇到困难。受到心智社会理论（Minsky, 1988）的启发，我们提出了ReConcile，这是一个多模型多代理的框架，旨在通过多样的LLM代理人之间的圆桌会议来促进多样的思想和讨论，从而改进一致性。ReConcile通过进行多轮讨论、学习说服其他代理人改进答案以及采用置信度加权投票机制来增强LLM的推理能力。在每一轮中，ReConcile通过“讨论提示”来启动代理人间的讨论，其中包括上一轮每个代理人生成的答案和解释的分组、它们的不确定性以及用于说服其他代理人的答案修正人类解释的演示。这个讨论提示使每个代理人能够根据其他代理人的见解修订自己的回答。一旦达成一致并结束讨论，ReConcile执行一次全体投票以确定最终答案。

    Large Language Models (LLMs) still struggle with complex reasoning tasks. Motivated by the society of minds (Minsky, 1988), we propose ReConcile, a multi-model multi-agent framework designed as a round table conference among diverse LLM agents to foster diverse thoughts and discussion for improved consensus. ReConcile enhances the reasoning capabilities of LLMs by holding multiple rounds of discussion, learning to convince other agents to improve their answers, and employing a confidence-weighted voting mechanism. In each round, ReConcile initiates discussion between agents via a 'discussion prompt' that consists of (a) grouped answers and explanations generated by each agent in the previous round, (b) their uncertainties, and (c) demonstrations of answer-rectifying human explanations, used for convincing other agents. This discussion prompt enables each agent to revise their responses in light of insights from other agents. Once a consensus is reached and the discussion ends, ReConcil
    
[^7]: 通过跨域序列自编码器实现反事实公平性追求

    Pursuing Counterfactual Fairness via Sequential Autoencoder Across Domains. (arXiv:2309.13005v1 [cs.LG])

    [http://arxiv.org/abs/2309.13005](http://arxiv.org/abs/2309.13005)

    通过顺序自编码器实现反事实公平性追求的创新框架将环境信息和敏感属性与分类特征的嵌入表示分开，以提高模型在不同和陌生领域中的泛化能力，并解决公平问题。

    

    鉴于领域转移在机器学习中普遍存在的挑战，已经开发出各种领域泛化（DG）技术，以提高处理分布外（OOD）数据时机器学习系统的性能。此外，在实际场景中，数据分布可能会在连续的序列领域中逐渐变化。虽然当前的方法主要集中在改进在这些新领域内的模型效果，但往往忽视了学习过程中的公平问题。为此，我们引入了一种创新的框架，称为具有顺序自编码器的反事实公平性感知领域泛化（CDSAE）。这种方法有效地将环境信息和敏感属性与分类特征的嵌入表示分开。这种并行分离不仅极大地提高了模型在不同和陌生的领域中的泛化能力，还有效地解决了相关挑战。

    Recognizing the prevalence of domain shift as a common challenge in machine learning, various domain generalization (DG) techniques have been developed to enhance the performance of machine learning systems when dealing with out-of-distribution (OOD) data. Furthermore, in real-world scenarios, data distributions can gradually change across a sequence of sequential domains. While current methodologies primarily focus on improving model effectiveness within these new domains, they often overlook fairness issues throughout the learning process. In response, we introduce an innovative framework called Counterfactual Fairness-Aware Domain Generalization with Sequential Autoencoder (CDSAE). This approach effectively separates environmental information and sensitive attributes from the embedded representation of classification features. This concurrent separation not only greatly improves model generalization across diverse and unfamiliar domains but also effectively addresses challenges rela
    
[^8]: 机器翻译的针对特定观众的解释

    Audience-specific Explanations for Machine Translation. (arXiv:2309.12998v1 [cs.CL])

    [http://arxiv.org/abs/2309.12998](http://arxiv.org/abs/2309.12998)

    该论文提出了一种针对机器翻译的针对特定观众的解释方法，通过从平行语料库中提取示例解释来解决翻译中的文化差异问题。实验结果表明，该方法能够有效提高句子中包含解释的比例。

    

    在机器翻译中，一个常见问题是某些词的翻译即使翻译了也会因为不同的文化背景导致目标语言观众无法理解。解决这个问题的方法是为这些词添加解释。在第一步中，我们需要识别这些词或短语。在这项工作中，我们探索了从平行语料库中提取示例解释的技术。然而，包含需要解释的词的句子的稀缺性使得构建训练数据集极其困难。在这项工作中，我们提出了一种半自动技术，可以从大型平行语料库中提取这些解释。在英语->德语语言对上的实验表明，我们的方法能够提取出超过10%的句子包含解释，而原始句子中只有1.9%包含解释。此外，在英语->法语和英语->中文语言对上的实验也显示出类似的结果。

    In machine translation, a common problem is that the translation of certain words even if translated can cause incomprehension of the target language audience due to different cultural backgrounds. A solution to solve this problem is to add explanations for these words. In a first step, we therefore need to identify these words or phrases. In this work we explore techniques to extract example explanations from a parallel corpus. However, the sparsity of sentences containing words that need to be explained makes building the training dataset extremely difficult. In this work, we propose a semi-automatic technique to extract these explanations from a large parallel corpus. Experiments on English->German language pair show that our method is able to extract sentence so that more than 10% of the sentences contain explanation, while only 1.9% of the original sentences contain explanations. In addition, experiments on English->French and English->Chinese language pairs also show similar conc
    
[^9]: 基于花瓣拉普拉斯在简单复合体上的高阶图卷积网络

    Higher-order Graph Convolutional Network with Flower-Petals Laplacians on Simplicial Complexes. (arXiv:2309.12971v1 [cs.LG])

    [http://arxiv.org/abs/2309.12971](http://arxiv.org/abs/2309.12971)

    本文提出了基于花瓣拉普拉斯的高阶图卷积网络，通过利用简单复合体来建模高阶交互，在不同拓扑尺度上识别内在特征，并使用可学习的图滤波器来量化高阶交互强度。

    

    尽管普通图神经网络（GNNs）在许多任务上取得了成功，但其基于配对交互网络的基础本质上限制了其识别复杂系统中潜在高阶交互的能力。为了弥补这种能力差距，我们提出了一种新颖的方法，利用复杂系统的高阶交互建模的丰富数学理论，即简单复合体（SCs）-一种对建模高阶交互具有鲁棒性的工具。目前基于SC的GNNs存在复杂度高和刻板的问题，并且量化高阶交互强度仍然具有挑战性。创新地，我们提出了一个高阶花瓣（FP）模型，将FP拉普拉斯引入到SC中。此外，我们引入了一个以FP拉普拉斯为基础的高阶图卷积网络（HiGCN），能够识别不同拓扑尺度上的内在特征。通过使用可学习的图滤波器，FP拉普拉斯域内的参数组，我们可以识别出具有不同模式的图案，其中滤波器的权重用作数量化高阶交互的工具。

    Despite the recent successes of vanilla Graph Neural Networks (GNNs) on many tasks, their foundation on pairwise interaction networks inherently limits their capacity to discern latent higher-order interactions in complex systems. To bridge this capability gap, we propose a novel approach exploiting the rich mathematical theory of simplicial complexes (SCs) - a robust tool for modeling higher-order interactions. Current SC-based GNNs are burdened by high complexity and rigidity, and quantifying higher-order interaction strengths remains challenging. Innovatively, we present a higher-order Flower-Petals (FP) model, incorporating FP Laplacians into SCs. Further, we introduce a Higher-order Graph Convolutional Network (HiGCN) grounded in FP Laplacians, capable of discerning intrinsic features across varying topological scales. By employing learnable graph filters, a parameter group within each FP Laplacian domain, we can identify diverse patterns where the filters' weights serve as a quan
    
[^10]: Trusta: 使用形式方法和大型语言模型推理保证论证

    Trusta: Reasoning about Assurance Cases with Formal Methods and Large Language Models. (arXiv:2309.12941v1 [cs.SE])

    [http://arxiv.org/abs/2309.12941](http://arxiv.org/abs/2309.12941)

    Trusta是一款使用形式方法和大型语言模型推理保证论证的桌面应用程序，它可以自动构建和验证可信度推导树(TDT)，同时利用大型语言模型使论证的创建和评估更加便捷。

    

    保证论证可以用于在安全工程中为产品的安全性提供论据。在安全关键领域，构建保证论证是不可或缺的。可信度推导树（TDT）通过结合形式方法加强了保证论证，使得自动推理成为可能。我们提出了Trustworthiness Derivation Tree Analyzer（Trusta），一款旨在自动构建和验证TDT的桌面应用程序。该工具在其后端具有内置的Prolog解释器，并受到约束求解器Z3和MONA的支持。因此，它可以解决涉及算术、集合、Horn子句等逻辑公式的约束问题。Trusta还利用了大型语言模型，使保证论证的创建和评估更加便捷。它允许进行交互式的人工审查和修改。我们评估了ChatGPT-3.5、ChatGPT-4和PaLM 2等顶级语言模型用于生成保证论证。我们的测试显示，其生成的保证论证的准确率为50%-80%。

    Assurance cases can be used to argue for the safety of products in safety engineering. In safety-critical areas, the construction of assurance cases is indispensable. Trustworthiness Derivation Trees (TDTs) enhance assurance cases by incorporating formal methods, rendering it possible for automatic reasoning about assurance cases. We present Trustworthiness Derivation Tree Analyzer (Trusta), a desktop application designed to automatically construct and verify TDTs. The tool has a built-in Prolog interpreter in its backend, and is supported by the constraint solvers Z3 and MONA. Therefore, it can solve constraints about logical formulas involving arithmetic, sets, Horn clauses etc. Trusta also utilizes large language models to make the creation and evaluation of assurance cases more convenient. It allows for interactive human examination and modification. We evaluated top language models like ChatGPT-3.5, ChatGPT-4, and PaLM 2 for generating assurance cases. Our tests showed a 50%-80% s
    
[^11]: 自解释提示在大型语言模型中提高对话理解能力

    Self-Explanation Prompting Improves Dialogue Understanding in Large Language Models. (arXiv:2309.12940v1 [cs.CL])

    [http://arxiv.org/abs/2309.12940](http://arxiv.org/abs/2309.12940)

    本研究提出了一种自解释提示策略，可显著提高大型语言模型在多轮对话中的理解能力，实验证实其在复杂对话任务中的有效性。

    

    任务导向的对话系统通过多轮对话帮助用户执行各种活动，但是大型语言模型（LLMs）往往难以理解这些复杂的语境。在本研究中，我们提出了一种新的“自解释”提示策略，以增强LLMs在多轮对话中的理解能力。这种任务无关的方法要求模型在执行任务之前分析每个对话话语，从而改善各种对话中心任务的性能。来自六个基准数据集的实验证据证实，我们的方法始终优于其他零样本提示，并且与少样本提示的有效性相当或超过，展示了它在提高LLMs在复杂对话任务中的理解能力方面的潜力。

    Task-oriented dialogue (TOD) systems facilitate users in executing various activities via multi-turn dialogues, but Large Language Models (LLMs) often struggle to comprehend these intricate contexts. In this study, we propose a novel "Self-Explanation" prompting strategy to enhance the comprehension abilities of LLMs in multi-turn dialogues. This task-agnostic approach requires the model to analyze each dialogue utterance before task execution, thereby improving performance across various dialogue-centric tasks. Experimental results from six benchmark datasets confirm that our method consistently outperforms other zero-shot prompts and matches or exceeds the efficacy of few-shot prompts, demonstrating its potential as a powerful tool in enhancing LLMs' comprehension in complex dialogue tasks.
    
[^12]: 受代码质量问题困扰？LLM可以帮助！

    Frustrated with Code Quality Issues? LLMs can Help!. (arXiv:2309.12938v1 [cs.AI])

    [http://arxiv.org/abs/2309.12938](http://arxiv.org/abs/2309.12938)

    使用大型语言模型（LLMs）协助开发者修正代码从而解决代码质量问题。提出了一个名为CORE的工具，使用一对组织为提供者和评估者的LLMs。该工具通过提供静态分析工具的推荐和生成候选的代码修订来改善代码质量。

    

    随着软件项目的进行，代码质量对软件的可靠性、可维护性和安全性具有至关重要的影响。因此，在开发者的工作流程中使用静态分析工具来标记代码质量问题。然而，开发者需要额外努力来修改他们的代码以改善代码质量。在这项工作中，我们研究了使用（指令跟随）大型语言模型（LLMs）来帮助开发者修正代码以解决代码质量问题的方式。我们提出了一个工具，名为CORE（COde REvisions），该工具使用一对组织为提供者和评估者的LLMs。静态分析工具的提供者推荐解决工具警告的方法，开发者遵循这些方法来修改他们的代码。CORE的\emph{提供者LLM}接受相同的推荐并将其应用于生成候选的代码修订。通过静态质量检查的候选代码被保留。

    As software projects progress, quality of code assumes paramount importance as it affects reliability, maintainability and security of software. For this reason, static analysis tools are used in developer workflows to flag code quality issues. However, developers need to spend extra efforts to revise their code to improve code quality based on the tool findings. In this work, we investigate the use of (instruction-following) large language models (LLMs) to assist developers in revising code to resolve code quality issues. We present a tool, CORE (short for COde REvisions), architected using a pair of LLMs organized as a duo comprised of a proposer and a ranker. Providers of static analysis tools recommend ways to mitigate the tool warnings and developers follow them to revise their code. The \emph{proposer LLM} of CORE takes the same set of recommendations and applies them to generate candidate code revisions. The candidates which pass the static quality checks are retained. However, 
    
[^13]: 自监督变形器中的分别归一化

    On Separate Normalization in Self-supervised Transformers. (arXiv:2309.12931v1 [cs.CL])

    [http://arxiv.org/abs/2309.12931](http://arxiv.org/abs/2309.12931)

    在自监督变形器中，通过为标记和[CLS]符号分别使用归一化层，可以更好地捕捉它们各自的特点并提高下游任务的性能。

    

    自监督变形器的训练方法在各个领域展现了显著的性能。以往的基于变形器的模型（如遮蔽自编码器）通常会为[CLS]符号和标记使用单独的归一化层。我们在本文中提出了一种简单的修改，为标记和[CLS]符号分别使用归一化层，以更好地捕捉它们各自的特点并增强下游任务的性能。我们的方法旨在缓解将相同的归一化统计数据应用于两种标记类型可能带来的负面效果，这些统计数据可能无法与它们各自的角色最佳匹配。通过使用单独的归一化层，我们经验证明[CLS]嵌入能够更好地编码全局语境信息，并在其非各向同性空间中分布更均匀。当用这两个单独的归一化层替换常规的归一化层时，我们观察到平均性能提升了2.7%。

    Self-supervised training methods for transformers have demonstrated remarkable performance across various domains. Previous transformer-based models, such as masked autoencoders (MAE), typically utilize a single normalization layer for both the [CLS] symbol and the tokens. We propose in this paper a simple modification that employs separate normalization layers for the tokens and the [CLS] symbol to better capture their distinct characteristics and enhance downstream task performance. Our method aims to alleviate the potential negative effects of using the same normalization statistics for both token types, which may not be optimally aligned with their individual roles. We empirically show that by utilizing a separate normalization layer, the [CLS] embeddings can better encode the global contextual information and are distributed more uniformly in its anisotropic space. When replacing the conventional normalization layer with the two separate layers, we observe an average 2.7% performa
    
[^14]: 态度问题：关注积极和主动梯度来提升显著图

    A matter of attitude: Focusing on positive and active gradients to boost saliency maps. (arXiv:2309.12913v1 [cs.AI])

    [http://arxiv.org/abs/2309.12913](http://arxiv.org/abs/2309.12913)

    本文研究了在显著图中考虑梯度符号和影响的作用，揭示了更好地识别卷积神经网络关注的图像像素的方法，并阐明了遮挡或改变这些像素会如何影响结果。

    

    由于其简单性和提供的见解质量，显著图已成为卷积神经网络（CNN）最广泛使用的可解释性技术之一。然而，对于这些见解是否可信仍存在一些疑问，是否真正代表CNN用于预测的信息。本文探讨了如何通过从显著图中挽救梯度的符号来更深入地理解多类别分类问题。通过使用预训练和从头开始训练的CNN，我们揭示了考虑正确类别的符号和影响，以及其他类别的影响，可以更好地识别网络真正关注的图像像素。此外，遮挡或改变这些像素预计会如何影响结果也变得更加清晰。

    Saliency maps have become one of the most widely used interpretability techniques for convolutional neural networks (CNN) due to their simplicity and the quality of the insights they provide. However, there are still some doubts about whether these insights are a trustworthy representation of what CNNs use to come up with their predictions. This paper explores how rescuing the sign of the gradients from the saliency map can lead to a deeper understanding of multi-class classification problems. Using both pretrained and trained from scratch CNNs we unveil that considering the sign and the effect not only of the correct class, but also the influence of the other classes, allows to better identify the pixels of the image that the network is really focusing on. Furthermore, how occluding or altering those pixels is expected to affect the outcome also becomes clearer.
    
[^15]: KG-MDL：使用MDL原则在知识图谱中挖掘图模式

    KG-MDL: Mining Graph Patterns in Knowledge Graphs with the MDL Principle. (arXiv:2309.12908v1 [cs.AI])

    [http://arxiv.org/abs/2309.12908](http://arxiv.org/abs/2309.12908)

    KG-MDL是一种在知识图谱中挖掘图模式的方法，采用基于MDL原则，解决了模式爆炸问题，适应了KGs的特点。

    

    如今，越来越多的数据以知识图谱（KGs）的形式可用。虽然这种数据模型支持高级推理和查询，但由于大小和复杂性，它们仍然很难进行挖掘。图挖掘方法可以用来从KGs中提取模式。然而，这存在两个主要问题。首先，图挖掘方法往往会提取出过多的模式，以至于人类分析师难以解释（模式爆炸）。其次，现实生活中的KGs往往与常规图挖掘处理的图不同：它们是多图，其顶点度数往往遵循幂律，以及它们建模知识的方式可能会产生虚假模式。最近，一种名为GraphMDL+的图挖掘方法被提出来解决模式爆炸的问题，使用了最小描述长度（MDL）原则。然而，GraphMDL+和其他图挖掘方法不适用于未经修正的KGs。在本文中，我们提出了一种基于MDL原则的KG-MDL图模式挖掘方法。

    Nowadays, increasingly more data are available as knowledge graphs (KGs). While this data model supports advanced reasoning and querying, they remain difficult to mine due to their size and complexity. Graph mining approaches can be used to extract patterns from KGs. However this presents two main issues. First, graph mining approaches tend to extract too many patterns for a human analyst to interpret (pattern explosion). Second, real-life KGs tend to differ from the graphs usually treated in graph mining: they are multigraphs, their vertex degrees tend to follow a power-law, and the way in which they model knowledge can produce spurious patterns. Recently, a graph mining approach named GraphMDL+ has been proposed to tackle the problem of pattern explosion, using the Minimum Description Length (MDL) principle. However, GraphMDL+, like other graph mining approaches, is not suited for KGs without adaptations. In this paper we propose KG-MDL, a graph pattern mining approach based on the M
    
[^16]: ProtoEM：一种用于事件关系抽取的原型加强匹配框架

    ProtoEM: A Prototype-Enhanced Matching Framework for Event Relation Extraction. (arXiv:2309.12892v1 [cs.CL])

    [http://arxiv.org/abs/2309.12892](http://arxiv.org/abs/2309.12892)

    本论文提出了一种原型加强匹配框架（ProtoEM）用于联合抽取多种类型的事件关系。该框架通过获取每种类型的事件关系的原型表示，并利用图神经网络匹配这些关系，从而全面理解它们的内在语义。

    

    事件关系抽取（ERE）旨在从文本中提取多种类型的事件关系。然而，现有方法单独将事件关系分类为不同类别，无法充分捕捉这些关系的内在语义。为了全面理解它们的内在语义，本文针对每种类型的事件关系获取原型表示，并提出了一种原型加强匹配（ProtoEM）框架，用于联合抽取多种类型的事件关系。具体而言，ProtoEM以两步方式提取事件关系，即原型表示和原型匹配。在第一步中，为了捕捉不同事件关系的内涵，ProtoEM利用示例来表示与这些关系相对应的原型。随后，为了捕捉事件关系之间的相互依赖性，它为与这些关系相对应的原型构建了一个依赖图，并利用图神经网络进行匹配。

    Event Relation Extraction (ERE) aims to extract multiple kinds of relations among events in texts. However, existing methods singly categorize event relations as different classes, which are inadequately capturing the intrinsic semantics of these relations. To comprehensively understand their intrinsic semantics, in this paper, we obtain prototype representations for each type of event relation and propose a Prototype-Enhanced Matching (ProtoEM) framework for the joint extraction of multiple kinds of event relations. Specifically, ProtoEM extracts event relations in a two-step manner, i.e., prototype representing and prototype matching. In the first step, to capture the connotations of different event relations, ProtoEM utilizes examples to represent the prototypes corresponding to these relations. Subsequently, to capture the interdependence among event relations, it constructs a dependency graph for the prototypes corresponding to these relations and utilized a Graph Neural Network (
    
[^17]: 重力网络用于端到端的小病灶检测

    Gravity Network for end-to-end small lesion detection. (arXiv:2309.12876v1 [cs.CV])

    [http://arxiv.org/abs/2309.12876](http://arxiv.org/abs/2309.12876)

    本文引入了一种新颖的重力网络架构，通过引入动态移动的重力点锚点，实现了端到端的小病灶检测，关于该方法在医学图像中的应用具有良好的检测效果。

    

    本文介绍了一种新颖的一阶段端到端检测器，专门用于检测医学图像中的小病灶。由于小病灶的外观和多样性的背景环境，精确定位小病灶存在一定的挑战。为了解决这个问题，我们的方法引入了一种新型的基于像素的锚点，它会动态地靠近目标病灶进行检测。我们将这种新的架构称为GravityNet，将这些新型锚点称为重力点，因为它们似乎被病灶所“吸引”。我们在两个已经成熟的医学问题上进行了实验，这两个问题分别涉及数字乳房X线照片中的微钙化检测和数字眼底图像中微动脉瘤的检测。我们的方法在这些医学图像任务中有效地检测小病灶，展现出了有希望的结果。

    This paper introduces a novel one-stage end-to-end detector specifically designed to detect small lesions in medical images. Precise localization of small lesions presents challenges due to their appearance and the diverse contextual backgrounds in which they are found. To address this, our approach introduces a new type of pixel-based anchor that dynamically moves towards the targeted lesion for detection. We refer to this new architecture as GravityNet, and the novel anchors as gravity points since they appear to be "attracted" by the lesions. We conducted experiments on two well-established medical problems involving small lesions to evaluate the performance of the proposed approach: microcalcifications detection in digital mammograms and microaneurysms detection in digital fundus images. Our method demonstrates promising results in effectively detecting small lesions in these medical imaging tasks.
    
[^18]: 角度优化的文本嵌入

    AnglE-Optimized Text Embeddings. (arXiv:2309.12871v1 [cs.CL])

    [http://arxiv.org/abs/2309.12871](http://arxiv.org/abs/2309.12871)

    本文提出了一种名为AnglE的角度优化文本嵌入模型，通过在复杂空间中引入角度优化来缓解文本嵌入中余弦函数饱和区域造成的梯度消失问题。该模型在多个STS任务中实现了高质量的文本嵌入，并在有限标签数据的特定领域STS场景中展现出优秀的性能。

    

    高质量的文本嵌入对于提升语义文本相似度（STS）任务至关重要，而这些任务又是大型语言模型（LLM）应用中的关键组成部分。然而，现有的文本嵌入模型面临的一个普遍挑战是渐变消失问题，主要是由于它们在优化目标中依赖余弦函数，而余弦函数具有饱和区域。为了解决这个问题，本文提出了一种称为AnglE的新型角度优化文本嵌入模型。AnglE的核心思想是在一个复杂空间中引入角度优化。这种新颖的方法有效地缓解了余弦函数饱和区域产生的不利影响，从而可以阻碍梯度并阻碍优化过程。为了建立全面的STS评估，我们在现有的短文本STS数据集和从GitHub Issues中新收集的长文本STS数据集上进行了实验。此外，我们还研究了具有有限标签数据的特定领域STS场景，并探讨了AnglE的工作原理。

    High-quality text embedding is pivotal in improving semantic textual similarity (STS) tasks, which are crucial components in Large Language Model (LLM) applications. However, a common challenge existing text embedding models face is the problem of vanishing gradients, primarily due to their reliance on the cosine function in the optimization objective, which has saturation zones. To address this issue, this paper proposes a novel angle-optimized text embedding model called AnglE. The core idea of AnglE is to introduce angle optimization in a complex space. This novel approach effectively mitigates the adverse effects of the saturation zone in the cosine function, which can impede gradient and hinder optimization processes. To set up a comprehensive STS evaluation, we experimented on existing short-text STS datasets and a newly collected long-text STS dataset from GitHub Issues. Furthermore, we examine domain-specific STS scenarios with limited labeled data and explore how AnglE works w
    
[^19]: 准确快速的压缩视频字幕生成研究

    Accurate and Fast Compressed Video Captioning. (arXiv:2309.12867v1 [cs.CV])

    [http://arxiv.org/abs/2309.12867](http://arxiv.org/abs/2309.12867)

    这项研究提出了一种准确快速的压缩视频字幕生成方法，通过从压缩域进行学习，避免了手动帧采样和冗余处理，提高了性能和效率。

    

    现有的视频字幕生成方法通常需要从解码视频中首先采样视频帧，然后进行后续处理（例如，特征提取和字幕模型学习）。在这个过程中，手动帧采样可能会忽略视频中的关键信息，从而降低性能。此外，采样帧中的冗余信息可能导致视频字幕生成推理的效率低下。针对这个问题，我们从压缩域的不同角度研究视频字幕生成，这种方法相比现有的流水线具有多重优势：1）与解码视频的原始图像相比，由I-帧、运动矢量和残差构成的压缩视频更具可识别性，这使得我们可以通过专用模型设计在学习过程中使用整个视频而不需要手动采样；2）字幕生成模型的推理效率更高，因为处理的信息更少且更少冗余。我们提出了一个简单但有效的方法。

    Existing video captioning approaches typically require to first sample video frames from a decoded video and then conduct a subsequent process (e.g., feature extraction and/or captioning model learning). In this pipeline, manual frame sampling may ignore key information in videos and thus degrade performance. Additionally, redundant information in the sampled frames may result in low efficiency in the inference of video captioning. Addressing this, we study video captioning from a different perspective in compressed domain, which brings multi-fold advantages over the existing pipeline: 1) Compared to raw images from the decoded video, the compressed video, consisting of I-frames, motion vectors and residuals, is highly distinguishable, which allows us to leverage the entire video for learning without manual sampling through a specialized model design; 2) The captioning model is more efficient in inference as smaller and less redundant information is processed. We propose a simple yet e
    
[^20]: 针对阿拉伯金融文本的领域适应机器翻译

    Domain Adaptation for Arabic Machine Translation: The Case of Financial Texts. (arXiv:2309.12863v1 [cs.CL])

    [http://arxiv.org/abs/2309.12863](http://arxiv.org/abs/2309.12863)

    这项研究旨在探索领域适应对阿拉伯机器翻译在金融领域的效果，并通过开发平行语料库进行了试验。结果显示，领域适应方法对于提高阿拉伯机器翻译的性能具有积极的影响。

    

    神经机器翻译（NMT）在训练大规模语料库时展示出了令人印象深刻的性能。然而，通用的NMT系统在领域外的翻译中表现出了较差的性能。为了缓解这个问题，最近提出了几种领域适应方法，通常比通用的NMT系统有更好的翻译质量。尽管在NMT的英语和其他欧洲语言方面取得了一些持续的进展，但在阿拉伯语方面的领域适应在文献中受到了很少的关注。因此，本研究旨在探索阿拉伯机器翻译（AMT）领域特定适应的有效性，尤其是在尚未开发的领域中，如金融新闻文章。为此，我们精心开发了一个用于阿拉伯-英语（AR-EN）金融领域翻译的平行语料库，以评估不同领域适应方法的性能。我们还在我们的数据集上对几个预训练的NMT和大型语言模型进行了微调，包括ChatGPT-3.5 Turbo。结果表明，

    Neural machine translation (NMT) has shown impressive performance when trained on large-scale corpora. However, generic NMT systems have demonstrated poor performance on out-of-domain translation. To mitigate this issue, several domain adaptation methods have recently been proposed which often lead to better translation quality than genetic NMT systems. While there has been some continuous progress in NMT for English and other European languages, domain adaption in Arabic has received little attention in the literature. The current study, therefore, aims to explore the effectiveness of domain-specific adaptation for Arabic MT (AMT), in yet unexplored domain, financial news articles. To this end, we developed carefully a parallel corpus for Arabic-English (AR- EN) translation in the financial domain for benchmarking different domain adaptation methods. We then fine-tuned several pre-trained NMT and Large Language models including ChatGPT-3.5 Turbo on our dataset. The results showed that
    
[^21]: 顺序推荐的扩散增强

    Diffusion Augmentation for Sequential Recommendation. (arXiv:2309.12858v1 [cs.IR])

    [http://arxiv.org/abs/2309.12858](http://arxiv.org/abs/2309.12858)

    本研究提出了一种用于顺序推荐的扩散增强方法，通过生成高质量的增强数据集，直接用于训练顺序推荐模型，解决了长尾用户和数据稀疏的问题。

    

    最近顺序推荐（SRS）已成为许多应用的技术基础，其目标是基于用户的历史交互来推荐下一个项目。然而，顺序推荐经常面临数据稀疏的问题，这在推荐系统中普遍存在。此外，大多数用户只与少数项目进行交互，但现有的SRS模型通常性能不佳。这个问题被称为长尾用户问题，仍待解决。数据增强是缓解这两个问题的一种方法，但它们通常需要制造训练策略或受到质量不佳的生成交互的限制。为解决这些问题，我们提出了一种用于顺序推荐的扩散增强（DiffuASR），以实现更高质量的生成。DiffuASR通过扩散产生的增强数据集可以直接用于训练顺序推荐模型，免去了复杂的训练过程。

    Sequential recommendation (SRS) has become the technical foundation in many applications recently, which aims to recommend the next item based on the user's historical interactions. However, sequential recommendation often faces the problem of data sparsity, which widely exists in recommender systems. Besides, most users only interact with a few items, but existing SRS models often underperform these users. Such a problem, named the long-tail user problem, is still to be resolved. Data augmentation is a distinct way to alleviate these two problems, but they often need fabricated training strategies or are hindered by poor-quality generated interactions. To address these problems, we propose a Diffusion Augmentation for Sequential Recommendation (DiffuASR) for a higher quality generation. The augmented dataset by DiffuASR can be used to train the sequential recommendation models directly, free from complex training procedures. To make the best of the generation ability of the diffusion 
    
[^22]: AxOCS: 使用配置超采样来扩展基于FPGA的近似运算符

    AxOCS: Scaling FPGA-based Approximate Operators using Configuration Supersampling. (arXiv:2309.12830v1 [cs.AR])

    [http://arxiv.org/abs/2309.12830](http://arxiv.org/abs/2309.12830)

    近似计算作为低成本机器学习实现的解决方案在嵌入式系统中得到广泛研究。其中，设计特定于平台的近似算术运算符成为主要问题，现有方法主要使用基于机器学习的代理函数预测性能和行为影响，缺乏更先进的方法。

    

    AI和基于机器学习的处理在各个应用领域的使用日益增加，加剧了对低成本机器学习实现的需求，特别是对资源受限的嵌入式系统而言。为此，近似计算作为一种探索功耗、性能、面积（PPA）和行为准确性（BEHAV）之间权衡的方法，已经成为在嵌入式机器学习中实现的可能解决方案之一。在机器学习中，由于MAC操作的占主导地位，设计特定于平台的近似算术运算符形成了近似计算中的主要研究问题之一。最近，越来越多的基于AI/ML的设计空间探索技术被用于实现近似运算符。然而，大多数这些方法仅限于使用基于机器学习的代理函数来预测一组相关设计决策的PPA和BEHAV影响。尽管这种方法利用了机器学习方法的回归能力，但没有充分利用更先进的方法。

    The rising usage of AI and ML-based processing across application domains has exacerbated the need for low-cost ML implementation, specifically for resource-constrained embedded systems. To this end, approximate computing, an approach that explores the power, performance, area (PPA), and behavioral accuracy (BEHAV) trade-offs, has emerged as a possible solution for implementing embedded machine learning. Due to the predominance of MAC operations in ML, designing platform-specific approximate arithmetic operators forms one of the major research problems in approximate computing. Recently there has been a rising usage of AI/ML-based design space exploration techniques for implementing approximate operators. However, most of these approaches are limited to using ML-based surrogate functions for predicting the PPA and BEHAV impact of a set of related design decisions. While this approach leverages the regression capabilities of ML methods, it does not exploit the more advanced approaches i
    
[^23]: 合成提升：利用合成数据增强超声心动图中的视觉-语言分割

    Synthetic Boost: Leveraging Synthetic Data for Enhanced Vision-Language Segmentation in Echocardiography. (arXiv:2309.12829v1 [cs.CV])

    [http://arxiv.org/abs/2309.12829](http://arxiv.org/abs/2309.12829)

    本研究探讨了使用合成数据集来增强超声心动图分割的视觉-语言分割模型（VLSM），结果显示合成数据集可以提高分割模型的指标和训练速度。

    

    准确的分割对于基于超声心动图的心血管疾病评估至关重要。然而，超声图像的变异性和固有挑战阻碍了精确的分割。通过利用图像和文本模态的联合表示，视觉-语言分割模型（VLSM）可以融入丰富的上下文信息，可能有助于精确和可解释的分割。然而，超声心动图中缺乏现成的数据阻碍了VLSM的训练。本研究中，我们探讨了使用语义扩散模型（SDM）生成的合成数据集来增强超声心动图分割的VLSM。我们使用从超声心动图图像、分割掩模和元数据中自动提取的多个属性导出的七种不同的语言提示来评估两个流行的VLSM模型（CLIPSeg和CRIS）的结果。我们的结果显示，在预训练VLSM时，转换和收敛速度更快。

    Accurate segmentation is essential for echocardiography-based assessment of cardiovascular diseases (CVDs). However, the variability among sonographers and the inherent challenges of ultrasound images hinder precise segmentation. By leveraging the joint representation of image and text modalities, Vision-Language Segmentation Models (VLSMs) can incorporate rich contextual information, potentially aiding in accurate and explainable segmentation. However, the lack of readily available data in echocardiography hampers the training of VLSMs. In this study, we explore using synthetic datasets from Semantic Diffusion Models (SDMs) to enhance VLSMs for echocardiography segmentation. We evaluate results for two popular VLSMs (CLIPSeg and CRIS) using seven different kinds of language prompts derived from several attributes, automatically extracted from echocardiography images, segmentation masks, and their metadata. Our results show improved metrics and faster convergence when pretraining VLSMs
    
[^24]: OmniDrones：一种用于无人机控制中的高效灵活的强化学习平台

    OmniDrones: An Efficient and Flexible Platform for Reinforcement Learning in Drone Control. (arXiv:2309.12825v1 [cs.RO])

    [http://arxiv.org/abs/2309.12825](http://arxiv.org/abs/2309.12825)

    OmniDrones是一个专为无人机控制中的强化学习而设计的高效灵活平台，采用自下而上设计方法，并提供一系列基准任务和无人机学习工具。这个平台有助于将强化学习应用于实际无人机系统的研究。

    

    在这项工作中，我们介绍了OmniDrones，这是一个专为无人机控制中的强化学习而设计的高效灵活的平台，建立在Nvidia的Omniverse Isaac Sim上。它采用自下而上的设计方法，使用户可以轻松地设计和实验各种应用场景，并在GPU并行化仿真之上进行模拟。它还提供一系列基准任务，涵盖单个无人机悬停到多驱动系统跟踪等各种挑战。总之，我们提出了一个开源的无人机仿真平台，配备了一套用于无人机学习的工具。它包括4个无人机模型，5种传感器模式，4种控制模式，10多个基准任务以及一些常用的强化学习基准模型。为了展示OmniDrones的能力并支持未来的研究，我们还提供了这些基准任务的初步结果。我们希望这个平台能够促进将强化学习应用于实际无人机系统的进一步研究。

    In this work, we introduce OmniDrones, an efficient and flexible platform tailored for reinforcement learning in drone control, built on Nvidia's Omniverse Isaac Sim. It employs a bottom-up design approach that allows users to easily design and experiment with various application scenarios on top of GPU-parallelized simulations. It also offers a range of benchmark tasks, presenting challenges ranging from single-drone hovering to over-actuated system tracking. In summary, we propose an open-sourced drone simulation platform, equipped with an extensive suite of tools for drone learning. It includes 4 drone models, 5 sensor modalities, 4 control modes, over 10 benchmark tasks, and a selection of widely used RL baselines. To showcase the capabilities of OmniDrones and to support future research, we also provide preliminary results on these benchmark tasks. We hope this platform will encourage further studies on applying RL to practical drone systems.
    
[^25]: 神经预测和对齐的光谱理论

    A Spectral Theory of Neural Prediction and Alignment. (arXiv:2309.12821v1 [q-bio.NC])

    [http://arxiv.org/abs/2309.12821](http://arxiv.org/abs/2309.12821)

    该论文提出了一个光谱理论，用于理解神经预测和对齐问题。通过研究模型激活的光谱偏差和神经响应与可学习子空间的对齐情况，我们可以获得深度神经网络的几何属性，并区分在神经预测方面表现相同的模型。

    

    神经网络的表示经常通过将神经网络响应与生物系统测得的响应进行回归来进行比较。许多不同的先进神经网络产生了类似的神经预测，但仍然不清楚如何区分在预测神经响应方面表现相同的模型。为了深入了解这一点，我们使用了近期提出的理论框架，该框架将回归中的泛化误差与模型激活的光谱偏差和神经响应与可学习子空间之间的对齐联系起来。我们将这个理论扩展到了模型激活和神经响应之间的回归情况，并定义了描述误差嵌入几何性质的几何属性。我们测试了大量预测视觉皮层活动的深度神经网络，并展示了多种几何形状导致低神经预测误差的情况。

    The representations of neural networks are often compared to those of biological systems by performing regression between the neural network responses and those measured from biological systems. Many different state-of-the-art deep neural networks yield similar neural predictions, but it remains unclear how to differentiate among models that perform equally well at predicting neural responses. To gain insight into this, we use a recent theoretical framework that relates the generalization error from regression to the spectral bias of the model activations and the alignment of the neural responses onto the learnable subspace of the model. We extend this theory to the case of regression between model activations and neural responses, and define geometrical properties describing the error embedding geometry. We test a large number of deep neural networks that predict visual cortical activity and show that there are multiple types of geometries that result in low neural prediction error as
    
[^26]: 对于ConvNets来说，遮盖（masking）能改善对比自监督学习，而显著性告诉你何处。（arXiv:2309.12757v1 [cs.CV]）

    Masking Improves Contrastive Self-Supervised Learning for ConvNets, and Saliency Tells You Where. (arXiv:2309.12757v1 [cs.CV])

    [http://arxiv.org/abs/2309.12757](http://arxiv.org/abs/2309.12757)

    该论文研究了如何将遮盖操作引入卷积神经网络的对比学习框架中，以提高自监督学习的效果。同时，研究还发现遮盖操作可能存在一些副作用，作者提出了解决方案来应对这些问题。

    

    图像数据开始受益于简单而有效的自监督学习方案，该方案建立在遮盖和自重构目标之上，这要归功于令牌化程序和视觉转换器骨干结构的引入。然而，作为图像数据的另一种重要且广泛采用的架构，卷积神经网络，尽管具有驱动自监督学习的对比学习技术，仍然面临将这种直接而通用的遮盖操作显著地利用于其学习过程中的困难。本研究旨在减轻将遮盖操作纳入对比学习框架的负担，作为一种额外的增强方法，以缓解ConvNets中因遮罩操作而产生的额外边缘（遮盖和未遮盖区域之间）以及其他不利影响的问题，这些问题已经在先前的研究中讨论过。

    While image data starts to enjoy the simple-but-effective self-supervised learning scheme built upon masking and self-reconstruction objective thanks to the introduction of tokenization procedure and vision transformer backbone, convolutional neural networks as another important and widely-adopted architecture for image data, though having contrastive-learning techniques to drive the self-supervised learning, still face the difficulty of leveraging such straightforward and general masking operation to benefit their learning process significantly. In this work, we aim to alleviate the burden of including masking operation into the contrastive-learning framework for convolutional neural networks as an extra augmentation method. In addition to the additive but unwanted edges (between masked and unmasked regions) as well as other adverse effects caused by the masking operations for ConvNets, which have been discussed by prior works, we particularly identify the potential problem where for 
    
[^27]: 面向工业应用的XAI MLOps架构研究

    Towards an MLOps Architecture for XAI in Industrial Applications. (arXiv:2309.12756v1 [cs.SE])

    [http://arxiv.org/abs/2309.12756](http://arxiv.org/abs/2309.12756)

    该论文提出了一种面向工业应用的XAI MLOps架构，旨在解决实际部署和管理ML模型中的解释和反馈能力的挑战，并提高模型准确性和用户体验。

    

    机器学习（ML）已经成为工业领域中的一种流行工具，它有助于改善操作、增加效率和降低成本。然而，在生产环境中部署和管理ML模型可能会很复杂。这就是机器学习运营（MLOps）的作用所在。MLOps旨在简化部署和管理过程。其中一个尚未解决的MLOps挑战是对解释的需求。这些解释对于理解ML模型的推理过程至关重要，这对于信任和接受是关键的。更好地识别错误和提高模型准确性只是其中的两个结果优势。一个经常被忽视的事实是，当准确性，尤其是可解释性不满足用户期望时，部署的模型在实践中会被绕过。我们开发了一种新颖的MLOps软件架构，以解决将解释和反馈能力整合到ML开发和部署过程中的挑战。在项目EXPLAIN中，我们的架构被应用于工业应用中。

    Machine learning (ML) has become a popular tool in the industrial sector as it helps to improve operations, increase efficiency, and reduce costs. However, deploying and managing ML models in production environments can be complex. This is where Machine Learning Operations (MLOps) comes in. MLOps aims to streamline this deployment and management process. One of the remaining MLOps challenges is the need for explanations. These explanations are essential for understanding how ML models reason, which is key to trust and acceptance. Better identification of errors and improved model accuracy are only two resulting advantages. An often neglected fact is that deployed models are bypassed in practice when accuracy and especially explainability do not meet user expectations. We developed a novel MLOps software architecture to address the challenge of integrating explanations and feedback capabilities into the ML development and deployment processes. In the project EXPLAIN, our architecture is
    
[^28]: OpenAi的GPT4作为编码助手

    OpenAi's GPT4 as coding assistant. (arXiv:2309.12732v1 [cs.AI])

    [http://arxiv.org/abs/2309.12732](http://arxiv.org/abs/2309.12732)

    本论文研究了OpenAi的GPT4作为编码助手的能力，通过测试发现其在回答问题、生成可靠代码和贡献代码调试方面表现出色。这表明GPT4能够提高程序员的生产力并重塑软件开发过程。

    

    最近，大型语言模型在代码生成方面被广泛使用。GPT4被认为是Openai最强大的大型语言模型。本文研究了GPT3.5和GPT4作为编码助手的能力。具体而言，我们构建了适当的测试来检查这两个系统是否能够a)回答在代码开发过程中可能出现的典型问题，b)生成可靠的代码，以及c)对代码调试做出贡献。测试结果令人印象深刻。GPT4的性能出色，预示着程序员的生产力提高以及基于这些新工具的软件开发程序的重新组织。

    Lately, Large Language Models have been widely used in code generation. GPT4 is considered the most potent Large Language Model from Openai. In this paper, we examine GPT3.5 and GPT4 as coding assistants. More specifically, we have constructed appropriate tests to check whether the two systems can a) answer typical questions that can arise during the code development, b) produce reliable code, and c) contribute to code debugging. The test results are impressive. The performance of GPT4 is outstanding and signals an increase in the productivity of programmers and the reorganization of software development procedures based on these new tools.
    
[^29]: 知识图谱的可废弃推理

    Defeasible Reasoning with Knowledge Graphs. (arXiv:2309.12731v1 [cs.AI])

    [http://arxiv.org/abs/2309.12731](http://arxiv.org/abs/2309.12731)

    本文介绍了一种可废弃推理的直观符号和模型，用于处理不完美知识，并将其与先前的论证理论工作相关联。进一步工作需要在陈述性术语中描述推理策略和战术，并结合AIF本体论的启示。论文还观察了大型语言模型时代符号方法的应用。

    

    人类的知识存在不确定性、不精确性、不完整性和不一致性。此外，许多日常术语的含义取决于上下文。这对语义网构成了巨大挑战。本文介绍了一种直观的符号和模型，用于处理不完美知识的可废弃推理，并将其与先前关于论证理论的工作联系起来。PKN与N3的关系类似于可废弃推理与演绎逻辑的关系。还需要进一步研究以直观的语法描述陈述性术语中的推理策略和战术，借鉴AIF本体论的启示。论文最后观察了大型语言模型时代的符号方法。

    Human knowledge is subject to uncertainties, imprecision, incompleteness and inconsistencies. Moreover, the meaning of many everyday terms is dependent on the context. That poses a huge challenge for the Semantic Web. This paper introduces work on an intuitive notation and model for defeasible reasoning with imperfect knowledge, and relates it to previous work on argumentation theory. PKN is to N3 as defeasible reasoning is to deductive logic. Further work is needed on an intuitive syntax for describing reasoning strategies and tactics in declarative terms, drawing upon the AIF ontology for inspiration. The paper closes with observations on symbolic approaches in the era of large language models.
    
[^30]: 聊天式大型语言模型的上下文干扰问题

    In-context Interference in Chat-based Large Language Models. (arXiv:2309.12727v1 [cs.AI])

    [http://arxiv.org/abs/2309.12727](http://arxiv.org/abs/2309.12727)

    本文研究了聊天式大型语言模型中的上下文干扰问题，发现模型在上下文中持续流动的信息之间可能会遭受干扰，导致遗忘之前学到的知识，降低性能。

    

    大型语言模型（LLMs）由于其卓越的能力和广泛的世界知识而对社会产生了巨大影响。创建了各种应用和工具，使用户可以以黑盒场景与这些模型交互。然而，这种场景的限制之一是用户无法修改模型的内部知识，添加或修改内部知识的唯一方法是在当前交互过程中明确提及。这种学习过程称为上下文训练，指的是限定在用户当前会话或上下文中进行的训练。上下文学习具有重要的应用，但也存在很少研究的限制。在本文中，我们展示了一项研究，说明了模型可能会遭受在上下文中不断流动的信息之间的干扰，从而导致遗忘先前学到的知识，降低模型的性能。除了展示问题，我们还提出了解决方案来解决该问题。

    Large language models (LLMs) have had a huge impact on society due to their impressive capabilities and vast knowledge of the world. Various applications and tools have been created that allow users to interact with these models in a black-box scenario. However, one limitation of this scenario is that users cannot modify the internal knowledge of the model, and the only way to add or modify internal knowledge is by explicitly mentioning it to the model during the current interaction. This learning process is called in-context training, and it refers to training that is confined to the user's current session or context. In-context learning has significant applications, but also has limitations that are seldom studied. In this paper, we present a study that shows how the model can suffer from interference between information that continually flows in the context, causing it to forget previously learned knowledge, which can reduce the model's performance. Along with showing the problem, w
    
[^31]: H2O+: 一种改进的混合离线和在线强化学习框架，用于动力学差距问题

    H2O+: An Improved Framework for Hybrid Offline-and-Online RL with Dynamics Gaps. (arXiv:2309.12716v1 [cs.LG])

    [http://arxiv.org/abs/2309.12716](http://arxiv.org/abs/2309.12716)

    H2O+是一种改进的混合离线和在线强化学习框架，通过综合考虑真实和模拟环境的动力学差距，同时利用有限的离线数据和不完美的模拟器进行策略学习，并在广泛的仿真和实际机器人实验中展示了卓越的性能和灵活性。

    

    在没有高精度模拟环境或大量离线数据的情况下，使用强化学习（RL）解决实际复杂任务可能相当具有挑战性。在非完美模拟环境中训练的在线RL代理可能会受到严重的模拟与现实问题。虽然离线RL方法可以绕过对模拟器的需求，但往往对离线数据集的大小和质量提出了苛刻的要求。最近出现的混合离线和在线RL提供了一个有吸引力的框架，可以同时使用有限的离线数据和不完美的模拟器进行可转移策略学习。本文提出了一种名为H2O+的新算法，该算法在桥接不同的离线和在线学习方法的同时，也考虑了真实和模拟环境之间的动力学差距。通过广泛的仿真和实际机器人实验，我们证明了H2O+在性能和灵活性上优于先进的跨域在线方法

    Solving real-world complex tasks using reinforcement learning (RL) without high-fidelity simulation environments or large amounts of offline data can be quite challenging. Online RL agents trained in imperfect simulation environments can suffer from severe sim-to-real issues. Offline RL approaches although bypass the need for simulators, often pose demanding requirements on the size and quality of the offline datasets. The recently emerged hybrid offline-and-online RL provides an attractive framework that enables joint use of limited offline data and imperfect simulator for transferable policy learning. In this paper, we develop a new algorithm, called H2O+, which offers great flexibility to bridge various choices of offline and online learning methods, while also accounting for dynamics gaps between the real and simulation environment. Through extensive simulation and real-world robotics experiments, we demonstrate superior performance and flexibility over advanced cross-domain online
    
[^32]: 数学游戏

    The Mathematical Game. (arXiv:2309.12711v1 [cs.AI])

    [http://arxiv.org/abs/2309.12711](http://arxiv.org/abs/2309.12711)

    提出使用其他游戏树搜索算法来改进Holophrasm定理证明器的性能。

    

    蒙特卡洛树搜索可用于自动定理证明。Holophrasm是一个使用MCTS结合神经网络来进行策略和评估的神经定理证明器。本文提出使用其他游戏树搜索算法来改进Holophrasm定理证明器的性能。

    Monte Carlo Tree Search can be used for automated theorem proving. Holophrasm is a neural theorem prover using MCTS combined with neural networks for the policy and the evaluation. In this paper we propose to improve the performance of the Holophrasm theorem prover using other game tree search algorithms.
    
[^33]: PointSSC：一个用于语义场景补全的车辆基础设施点云合作基准

    PointSSC: A Cooperative Vehicle-Infrastructure Point Cloud Benchmark for Semantic Scene Completion. (arXiv:2309.12708v1 [cs.CV])

    [http://arxiv.org/abs/2309.12708](http://arxiv.org/abs/2309.12708)

    PointSSC是第一个为了语义场景补全而引入的车辆基础设施点云合作基准，具备长距离感知和最小遮挡。通过使用Segment Anything进行自动化注释，我们提出了一种基于激光雷达的模型，结合补全和分割的合作模块，来推动语义点云补全在真实世界导航中的发展。

    

    语义场景补全旨在为复杂的3D场景生成空间占用和语义标签。大多数现有的语义场景补全模型都集中在体素表示上，对于大型室外空间来说存在内存效率低下的问题。点云提供了一种轻量级的替代方案，但现有基准缺乏带有语义标签的室外点云场景。为了解决这个问题，我们引入了第一个用于语义场景补全的车辆基础设施点云合作基准PointSSC。这些场景具有长距离感知和最小的遮挡。我们利用Segment Anything开发了一个自动化注释流程，以高效地分配语义标签。为了评估进展，我们提出了一个基于激光雷达的模型，其中包括一个空间感知变换器用于全局和局部特征提取，以及一个补全和分割合作模块用于联合补全和分割。PointSSC提供了一个具有挑战性的测试平台，推动了语义点云补全在真实世界导航中的进展。

    Semantic Scene Completion (SSC) aims to jointly generate space occupancies and semantic labels for complex 3D scenes. Most existing SSC models focus on volumetric representations, which are memory-inefficient for large outdoor spaces. Point clouds provide a lightweight alternative but existing benchmarks lack outdoor point cloud scenes with semantic labels. To address this, we introduce PointSSC, the first cooperative vehicle-infrastructure point cloud benchmark for semantic scene completion. These scenes exhibit long-range perception and minimal occlusion. We develop an automated annotation pipeline leveraging Segment Anything to efficiently assign semantics. To benchmark progress, we propose a LiDAR-based model with a Spatial-Aware Transformer for global and local feature extraction and a Completion and Segmentation Cooperative Module for joint completion and segmentation. PointSSC provides a challenging testbed to drive advances in semantic point cloud completion for real-world navi
    
[^34]: 多标签噪声转移矩阵估计与标签相关性：理论与算法

    Multi-Label Noise Transition Matrix Estimation with Label Correlations: Theory and Algorithm. (arXiv:2309.12706v1 [cs.LG])

    [http://arxiv.org/abs/2309.12706](http://arxiv.org/abs/2309.12706)

    本论文提出了一种解决多标签噪声转移矩阵估计问题的方法，通过研究可辨识性，并结合标签相关性，提出了一种新的估计器，可以在噪声多标签学习中实现统计一致性算法。

    

    由于收集大规模准确标签的挑战，噪声多标签学习引起了越来越多的关注，使得噪声标签成为更实际的选择。受到噪声多类别学习的启发，引入转移矩阵可以帮助建模多标签噪声，并实现对噪声多标签学习的统计一致性算法的开发。然而，估计多标签噪声转移矩阵仍然是一个具有挑战性的任务，因为在噪声多类别学习中的大多数现有估计器依赖于锚点和准确拟合噪声类后验概率，而在噪声多标签学习中很难满足这些条件。在本文中，我们首先研究了在噪声多标签学习中基于类别的转移矩阵的可辨识性。在可辨识性结果的基础上，我们提出了一种新的估计器，可以利用标签相关性，而无需锚点或精确拟合噪声类后验概率。

    Noisy multi-label learning has garnered increasing attention due to the challenges posed by collecting large-scale accurate labels, making noisy labels a more practical alternative. Motivated by noisy multi-class learning, the introduction of transition matrices can help model multi-label noise and enable the development of statistically consistent algorithms for noisy multi-label learning. However, estimating multi-label noise transition matrices remains a challenging task, as most existing estimators in noisy multi-class learning rely on anchor points and accurate fitting of noisy class posteriors, which is hard to satisfy in noisy multi-label learning. In this paper, we address this problem by first investigating the identifiability of class-dependent transition matrices in noisy multi-label learning. Building upon the identifiability results, we propose a novel estimator that leverages label correlations without the need for anchor points or precise fitting of noisy class posterior
    
[^35]: 离线多智能体增强学习的反事实保守Q学习

    Counterfactual Conservative Q Learning for Offline Multi-agent Reinforcement Learning. (arXiv:2309.12696v1 [cs.AI])

    [http://arxiv.org/abs/2309.12696](http://arxiv.org/abs/2309.12696)

    提出了一种新的多智能体离线RL算法，通过反事实保守Q学习实现保守的价值估计，在解决离线分布偏移和高维问题的同时，确保行为的分布和价值的估计不过高。

    

    离线多智能体增强学习面临着离线环境中的分布偏移问题和多智能体环境中的高维问题的挑战，导致行为的超出分布和价值的过高估计现象过于严重。为了缓解这个问题，我们提出了一种新的多智能体离线RL算法，命名为反事实保守Q学习（CFCQL），以进行保守的价值估计。CFCQL并不将所有智能体视为一个高维单独的智能体，并直接应用单智能体方法，而是以反事实的方式分别为每个智能体计算保守的正则化，并线性组合它们以实现整体保守价值估计。我们证明了它仍然具有单一智能体保守方法的低估性质和性能保证，但所引起的正则化和安全策略改进界限都是独立的。

    Offline multi-agent reinforcement learning is challenging due to the coupling effect of both distribution shift issue common in offline setting and the high dimension issue common in multi-agent setting, making the action out-of-distribution (OOD) and value overestimation phenomenon excessively severe. Tomitigate this problem, we propose a novel multi-agent offline RL algorithm, named CounterFactual Conservative Q-Learning (CFCQL) to conduct conservative value estimation. Rather than regarding all the agents as a high dimensional single one and directly applying single agent methods to it, CFCQL calculates conservative regularization for each agent separately in a counterfactual way and then linearly combines them to realize an overall conservative value estimation. We prove that it still enjoys the underestimation property and the performance guarantee as those single agent conservative methods do, but the induced regularization and safe policy improvement bound are independent of the
    
[^36]: 通过本地和云计算增强环境的图表示

    Enhancing Graph Representation of the Environment through Local and Cloud Computation. (arXiv:2309.12692v1 [cs.RO])

    [http://arxiv.org/abs/2309.12692](http://arxiv.org/abs/2309.12692)

    通过本地和云计算增强环境的图表示，提供语义化的机器人环境表示，消除了对特定工具的需求。

    

    丰富机器人对操作环境的表示是一项具有挑战性的任务，旨在弥合低级传感器读数与高级语义理解之间的差距。要拥有丰富的表示通常需要计算需求高的体系结构和纯点云的检测系统，而在处理机器人必须处理的日常物体时往往会遇到困难。为了解决这些问题，我们提出了一种基于图的表示，通过从多个来源提供机器人环境的语义表示来弥合这个差距。事实上，为了从环境中获取信息，该框架将传统计算机视觉工具与现代计算机视觉云服务相结合，确保在机载硬件上具备计算可行性。通过将800多个目标类别的本体层次结构纳入其中，该框架实现了跨领域的适应性，消除了环境特定工具的需要。

    Enriching the robot representation of the operational environment is a challenging task that aims at bridging the gap between low-level sensor readings and high-level semantic understanding. Having a rich representation often requires computationally demanding architectures and pure point cloud based detection systems that struggle when dealing with everyday objects that have to be handled by the robot. To overcome these issues, we propose a graph-based representation that addresses this gap by providing a semantic representation of robot environments from multiple sources. In fact, to acquire information from the environment, the framework combines classical computer vision tools with modern computer vision cloud services, ensuring computational feasibility on onboard hardware. By incorporating an ontology hierarchy with over 800 object classes, the framework achieves cross-domain adaptability, eliminating the need for environment-specific tools. The proposed approach allows us to han
    
[^37]: QAL-BP:一种用于装箱问题的增广拉格朗日量子方法

    QAL-BP: An Augmented Lagrangian Quantum Approach for Bin Packing Problem. (arXiv:2309.12678v1 [quant-ph])

    [http://arxiv.org/abs/2309.12678](http://arxiv.org/abs/2309.12678)

    QAL-BP是一种增广拉格朗日量子方法，专门用于解决装箱问题。它利用增广拉格朗日方法将装箱约束加入目标函数，并通过分析估计启发式乘数，消除了需要根据实例计算Lagrangian系数的需求。

    

    装箱问题是人工智能领域中众所周知的NP-Hard问题，寻找高效解决方案面临重大挑战。相反，量子技术的最新进展显示出在某些问题类别（如组合优化）中实现大幅计算加速的潜力。在本研究中，我们介绍了QAL-BP，一种专门针对装箱问题设计的新型二次无约束二进制优化（QUBO）公式，适用于量子计算。QAL-BP采用增广拉格朗日方法将装箱约束嵌入到目标函数中，并便于对启发式乘数进行分析估计，使得模型更加灵活和可推广，消除了在其他QUBO公式中常遇到的需要根据实例计算Lagrangian系数的需求。

    The bin packing is a well-known NP-Hard problem in the domain of artificial intelligence, posing significant challenges in finding efficient solutions. Conversely, recent advancements in quantum technologies have shown promising potential for achieving substantial computational speedup, particularly in certain problem classes, such as combinatorial optimization. In this study, we introduce QAL-BP, a novel Quadratic Unconstrained Binary Optimization (QUBO) formulation designed specifically for bin packing and suitable for quantum computation. QAL-BP utilizes the augmented Lagrangian method to incorporate the bin packing constraints into the objective function while also facilitating an analytical estimation of heuristic, but empirically robust, penalty multipliers. This approach leads to a more versatile and generalizable model that eliminates the need for empirically calculating instance-dependent Lagrangian coefficients, a requirement commonly encountered in alternative QUBO formulati
    
[^38]: TrTr：一种基于Transformer的通用预训练大型流量模型，用于捕捉车辆群体中的轨迹多样性

    TrTr: A Versatile Pre-Trained Large Traffic Model based on Transformer for Capturing Trajectory Diversity in Vehicle Population. (arXiv:2309.12677v1 [cs.AI])

    [http://arxiv.org/abs/2309.12677](http://arxiv.org/abs/2309.12677)

    本研究使用Transformer模型来捕捉车辆群体中轨迹的多样性，在交通任务中具有重要意义。通过分析注意力机制和设计预训练任务，实现了对车辆轨迹的学习，并提出了适用于交通任务的数据结构和噪声。

    

    理解轨迹多样性是解决实际交通任务的基本方面。然而，由于需要大规模参数，传统的机器学习和递归神经网络在捕捉轨迹多样性方面存在挑战。新兴的Transformer技术以其并行计算能力而闻名，可以利用具有数亿个参数的模型，为此提供了有希望的解决方案。在本研究中，我们将Transformer架构应用于交通任务，旨在学习车辆群体内的轨迹多样性。我们分析了Transformer的注意力机制以及其适应交通任务目标的能力，随后设计了特定的预训练任务。为了实现这一目标，我们创建了一个适合注意力机制的数据结构，并引入了一组与时空需求对应的噪声，这些噪声在结构化数据中被纳入。

    Understanding trajectory diversity is a fundamental aspect of addressing practical traffic tasks. However, capturing the diversity of trajectories presents challenges, particularly with traditional machine learning and recurrent neural networks due to the requirement of large-scale parameters. The emerging Transformer technology, renowned for its parallel computation capabilities enabling the utilization of models with hundreds of millions of parameters, offers a promising solution. In this study, we apply the Transformer architecture to traffic tasks, aiming to learn the diversity of trajectories within vehicle populations. We analyze the Transformer's attention mechanism and its adaptability to the goals of traffic tasks, and subsequently, design specific pre-training tasks. To achieve this, we create a data structure tailored to the attention mechanism and introduce a set of noises that correspond to spatio-temporal demands, which are incorporated into the structured data during the
    
[^39]: 计算机围棋的视觉Transformer

    Vision Transformers for Computer Go. (arXiv:2309.12675v1 [cs.AI])

    [http://arxiv.org/abs/2309.12675](http://arxiv.org/abs/2309.12675)

    本研究探索了视觉Transformer在围棋中的应用，并通过与传统的残差网络进行比较，从预测准确性、胜率、内存、速度等多个方面展示了其在围棋中的重要作用。

    

    鉴于Transformer在语言理解和图像分析等领域的成功，本研究探讨了它们在围棋中的应用。特别是，我们的研究聚焦于Transformer在视觉中的分析。通过对预测准确性、胜率、内存、速度、大小甚至学习率等多个方面进行详细分析，我们成功地突出了Transformer在围棋中可以发挥的重要作用。本研究通过与传统的残差网络进行比较进行实施。

    Motivated by the success of transformers in various fields, such as language understanding and image analysis, this investigation explores their application in the context of the game of Go. In particular, our study focuses on the analysis of the Transformer in Vision. Through a detailed analysis of numerous points such as prediction accuracy, win rates, memory, speed, size, or even learning rate, we have been able to highlight the substantial role that transformers can play in the game of Go. This study was carried out by comparing them to the usual Residual Networks.
    
[^40]: 关于稀疏的现代 Hopfield 模型

    On Sparse Modern Hopfield Model. (arXiv:2309.12673v1 [cs.LG])

    [http://arxiv.org/abs/2309.12673](http://arxiv.org/abs/2309.12673)

    本文介绍了稀疏的现代 Hopfield 模型，通过引入稀疏能量函数和稀疏记忆检索动力学，实现了对稀疏注意机制的一步近似。相比密集模型，稀疏模型的记忆检索误差上界更紧凑，具有明确的稀疏优势条件。同时，稀疏的现代 Hopfield 模型还保持了其密集对应物的稳健理论性质。

    

    我们介绍了稀疏的现代 Hopfield 模型作为现代 Hopfield 模型的一种扩展。与其密集的对应物一样，稀疏的现代 Hopfield 模型具备一种记忆检索动力学，其一步近似对应于稀疏的注意机制。从理论上讲，我们的关键贡献是通过稀疏熵正则化器的凸共轭导出了封闭形式的稀疏 Hopfield 能量。在此基础上，我们从稀疏能量函数中推导出稀疏记忆检索动力学，并展示了它的一步近似等价于稀疏结构化注意力。重要的是，我们提供了一个依赖于稀疏度的记忆检索误差上界，该上界在证明上要比其密集对应物更紧凑。因此，我们确定并讨论了稀疏优势出现的条件。此外，我们还表明稀疏的现代 Hopfield 模型保持了其密集对应物的稳健理论性质，包括快速的固定点收敛。

    We introduce the sparse modern Hopfield model as a sparse extension of the modern Hopfield model. Like its dense counterpart, the sparse modern Hopfield model equips a memory-retrieval dynamics whose one-step approximation corresponds to the sparse attention mechanism. Theoretically, our key contribution is a principled derivation of a closed-form sparse Hopfield energy using the convex conjugate of the sparse entropic regularizer. Building upon this, we derive the sparse memory retrieval dynamics from the sparse energy function and show its one-step approximation is equivalent to the sparse-structured attention. Importantly, we provide a sparsity-dependent memory retrieval error bound which is provably tighter than its dense analog. The conditions for the benefits of sparsity to arise are therefore identified and discussed. In addition, we show that the sparse modern Hopfield model maintains the robust theoretical properties of its dense counterpart, including rapid fixed point conver
    
[^41]: 如何微调模型：统一模型偏移和模型偏差策略优化

    How to Fine-tune the Model: Unified Model Shift and Model Bias Policy Optimization. (arXiv:2309.12671v1 [cs.LG])

    [http://arxiv.org/abs/2309.12671](http://arxiv.org/abs/2309.12671)

    本文提出了一个统一模型偏移和模型偏差的优化目标，并通过微调过程实现了自适应的模型更新，以提供性能改进保证和避免模型过拟合。

    

    设计和推导出具有性能改进保证的有效基于模型的强化学习（MBRL）算法具有挑战性，这主要归因于模型学习和策略优化之间的高耦合性。许多先前的方法依靠回报差异来指导模型学习，忽略了模型偏移的影响，这可能导致由于过多的模型更新而性能下降。其他方法使用性能差异边界来明确考虑模型偏移。然而，这些方法依赖于固定的阈值来限制模型偏移，导致对阈值的严重依赖，并且在训练过程中缺乏适应性。在本文中，我们从理论上推导出一个可以统一模型偏移和模型偏差的优化目标，然后制定一个微调过程。这个过程可以自适应地调整模型更新，以获得性能改进保证，同时避免模型过拟合。基于这些，我们开发了一个简单直观的方法

    Designing and deriving effective model-based reinforcement learning (MBRL) algorithms with a performance improvement guarantee is challenging, mainly attributed to the high coupling between model learning and policy optimization. Many prior methods that rely on return discrepancy to guide model learning ignore the impacts of model shift, which can lead to performance deterioration due to excessive model updates. Other methods use performance difference bound to explicitly consider model shift. However, these methods rely on a fixed threshold to constrain model shift, resulting in a heavy dependence on the threshold and a lack of adaptability during the training process. In this paper, we theoretically derive an optimization objective that can unify model shift and model bias and then formulate a fine-tuning process. This process adaptively adjusts the model updates to get a performance improvement guarantee while avoiding model overfitting. Based on these, we develop a straightforward 
    
[^42]: 自然修正是一种有条件的修正方式。

    Natural revision is contingently-conditionalized revision. (arXiv:2309.12655v1 [cs.AI])

    [http://arxiv.org/abs/2309.12655](http://arxiv.org/abs/2309.12655)

    自然修正是一种有条件的修正方式，它尽可能少地改变信念来融入新信息，并将修正限制在当前条件下。

    

    自然修正看起来很自然：它尽可能少地改变信念来融入新信息。然而，一些反例显示这是错误的。它非常保守，从不完全相信。它只在当前条件下相信。这在某些情况下是正确的，在其他情况下是错误的。哪种情况是哪种情况？回答这个问题需要将自然修正从表达普遍真理的简单公式（某物成立）扩展到表达条件真理的条件语句（某种情况下成立）。这种扩展基于自然修正遵循的基本原则，被确定为最小改变、漠不关心和天真：尽可能少地改变信念；默认情况下将场景的可能性视为相等；对所有情况持有信念，直到有矛盾发生。扩展表明自然修正将修正限制在当前条件下。与不受限制的修正进行比较可以确定当前条件。它不是当前被认为是真的，如果与新信息相矛盾的话。

    Natural revision seems so natural: it changes beliefs as little as possible to incorporate new information. Yet, some counterexamples show it wrong. It is so conservative that it never fully believes. It only believes in the current conditions. This is right in some cases and wrong in others. Which is which? The answer requires extending natural revision from simple formulae expressing universal truths (something holds) to conditionals expressing conditional truth (something holds in certain conditions). The extension is based on the basic principles natural revision follows, identified as minimal change, indifference and naivety: change beliefs as little as possible; equate the likeliness of scenarios by default; believe all until contradicted. The extension says that natural revision restricts changes to the current conditions. A comparison with an unrestricting revision shows what exactly the current conditions are. It is not what currently considered true if it contradicts the new 
    
[^43]: 深度学习在CT扫描分类中的结果是否公正可解释？

    Are Deep Learning Classification Results Obtained on CT Scans Fair and Interpretable?. (arXiv:2309.12632v1 [cs.LG])

    [http://arxiv.org/abs/2309.12632](http://arxiv.org/abs/2309.12632)

    深度学习在CT扫描分类中的结果往往只关注准确性，而忽视了公正性和解释性，导致模型不可信和不适用于真实场景。

    

    鉴于深度学习方法在图像和物体分类中的巨大成功，生物医学图像处理领域也面临着深度学习应用于各种自动诊断案例的压力。不幸的是，文献中大多数基于深度学习的分类尝试仅仅关注极高的准确性，而不考虑可解释性或者患者训练和测试数据的分离。例如，大部分使用深度学习的肺结节分类论文会对数据进行随机洗牌，并将其分为训练、验证和测试集，导致一个人的CT扫描图像中的某些图像位于训练集中，而其他图像则位于验证或测试图像集中。这可能导致误导性的准确率报告和学习到的无关特征，最终降低了这些模型在实际应用中的可用性。

    Following the great success of various deep learning methods in image and object classification, the biomedical image processing society is also overwhelmed with their applications to various automatic diagnosis cases. Unfortunately, most of the deep learning-based classification attempts in the literature solely focus on the aim of extreme accuracy scores, without considering interpretability, or patient-wise separation of training and test data. For example, most lung nodule classification papers using deep learning randomly shuffle data and split it into training, validation, and test sets, causing certain images from the CT scan of a person to be in the training set, while other images of the exact same person to be in the validation or testing image sets. This can result in reporting misleading accuracy rates and the learning of irrelevant features, ultimately reducing the real-life usability of these models. When the deep neural networks trained on the traditional, unfair data sh
    
[^44]: 基于量子计算的投资组合优化系统：利用未来资产价值和自动减少投资范围

    A Quantum Computing-based System for Portfolio Optimization using Future Asset Values and Automatic Reduction of the Investment Universe. (arXiv:2309.12627v1 [cs.AI])

    [http://arxiv.org/abs/2309.12627](http://arxiv.org/abs/2309.12627)

    本研究提出了一种基于量子计算的投资组合优化系统Q4FuturePOP，它创新地利用未来资产价值进行建模，并引入了一个自动减少投资范围的模块。通过实验讨论了Q4FuturePOP的原型版本中不同模块的初步性能。

    

    量化金融中备受关注的问题之一是投资组合优化问题。针对该问题，近年来利用量子计算的技术得到了广泛应用。本研究介绍了一种名为Q4FuturePOP的基于量子计算的投资组合优化系统，该系统通过以下创新解决了投资组合优化问题：i）该工具针对未来资产预测进行建模，而不是使用历史数据；ii）Q4FuturePOP包括一个智能减少问题复杂性的自动减少投资范围模块。此外，我们还对Q4FuturePOP的原型版本的不同模块的初步性能进行了简要讨论。

    One of the problems in quantitative finance that has received the most attention is the portfolio optimization problem. Regarding its solving, this problem has been approached using different techniques, with those related to quantum computing being especially prolific in recent years. In this study, we present a system called Quantum Computing-based System for Portfolio Optimization with Future Asset Values and Automatic Universe Reduction (Q4FuturePOP), which deals with the Portfolio Optimization Problem considering the following innovations: i) the developed tool is modeled for working with future prediction of assets, instead of historical values; and ii) Q4FuturePOP includes an automatic universe reduction module, which is conceived to intelligently reduce the complexity of the problem. We also introduce a brief discussion about the preliminary performance of the different modules that compose the prototypical version of Q4FuturePOP.
    
[^45]: 基于增强语言模型的建筑合同风险识别

    Construction contract risk identification based on knowledge-augmented language model. (arXiv:2309.12626v1 [cs.AI])

    [http://arxiv.org/abs/2309.12626](http://arxiv.org/abs/2309.12626)

    本文提出了一种基于增强语言模型的建筑合同风险识别方法，利用具备建筑合同知识的大型语言模型模拟人类专家的合同审查过程。该方法无需调整，能够识别建筑合同风险，并在真实环境中取得了良好性能。

    

    在建筑项目中，合同审查是防止潜在损失的重要步骤。然而，当前用于审查建筑合同的方法缺乏效果和可靠性，导致耗时和容易出错。虽然大型语言模型（LLMs）在改革自然语言处理（NLP）任务方面显示出潜力，但它们在处理领域特定知识和解决专门问题方面存在困难。本文提出了一种新颖的方法，利用具备建筑合同知识的LLMs来模拟人类专家的合同审查过程。我们的无调整方法将建筑合同领域知识结合到语言模型中，以识别建筑合同风险。在构建领域知识库时使用自然语言有助于实际应用。我们在真实的建筑合同上对我们的方法进行了评估，并取得了良好的性能。此外，我们还研究了大型语言模型如何应用于建筑合同的识别过程。

    Contract review is an essential step in construction projects to prevent potential losses. However, the current methods for reviewing construction contracts lack effectiveness and reliability, leading to time-consuming and error-prone processes. While large language models (LLMs) have shown promise in revolutionizing natural language processing (NLP) tasks, they struggle with domain-specific knowledge and addressing specialized issues. This paper presents a novel approach that leverages LLMs with construction contract knowledge to emulate the process of contract review by human experts. Our tuning-free approach incorporates construction contract domain knowledge to enhance language models for identifying construction contract risks. The use of a natural language when building the domain knowledge base facilitates practical implementation. We evaluated our method on real construction contracts and achieved solid performance. Additionally, we investigated how large language models employ
    
[^46]: DRG-LLaMA: 调优LLaMA模型以预测住院患者的诊断相关分组

    DRG-LLaMA : Tuning LLaMA Model to Predict Diagnosis-related Group for Hospitalized Patients. (arXiv:2309.12625v1 [cs.AI])

    [http://arxiv.org/abs/2309.12625](http://arxiv.org/abs/2309.12625)

    DRG-LLaMA是一个通过在临床笔记上细调的大型语言模型，用于改进住院患者的诊断相关分组预测。在多个评估指标上，DRG-LLaMA-7B相对于其他模型取得了显著的改进，并能够高准确度地预测基本DRG和并发症/合并症（CC）/重大并发症或合并症（MCC）的状态。

    

    在美国住院付费系统中，诊断相关分组（DRG）起着关键作用，但目前的分组过程耗时。我们引入了DRG-LLaMA，一个在临床笔记上进行细调的大型语言模型（LLM），以改善DRG预测。使用Meta的LLaMA作为基础模型，我们通过在236,192个MIMIC-IV出院摘要上进行低秩适应（LoRA）优化。在输入令牌长度为512的情况下，DRG-LLaMA-7B实现的宏平均F1分数为0.327，顶级预测准确度为52.0％，宏平均AUC为0.986。令人印象深刻的是，DRG-LLaMA-7B在这个任务上超过了之前报道的领先模型，相对于ClinicalBERT的宏平均F1分数提高了40.3％，相对于CAML提高了35.7％。当应用DRG-LLaMA来预测基本DRG和并发症/合并症（CC）/重大并发症或合并症（MCC）时，基本DRG的顶级预测准确度达到了67.8％，而CC/MCC状态的预测准确度达到了67.5％。

    In the U.S. inpatient payment system, the Diagnosis-Related Group (DRG) plays a key role but its current assignment process is time-consuming. We introduce DRG-LLaMA, a large language model (LLM) fine-tuned on clinical notes for improved DRG prediction. Using Meta's LLaMA as the base model, we optimized it with Low-Rank Adaptation (LoRA) on 236,192 MIMIC-IV discharge summaries. With an input token length of 512, DRG-LLaMA-7B achieved a macro-averaged F1 score of 0.327, a top-1 prediction accuracy of 52.0% and a macro-averaged Area Under the Curve (AUC) of 0.986. Impressively, DRG-LLaMA-7B surpassed previously reported leading models on this task, demonstrating a relative improvement in macro-averaged F1 score of 40.3% compared to ClinicalBERT and 35.7% compared to CAML. When DRG-LLaMA is applied to predict base DRGs and complication or comorbidity (CC) / major complication or comorbidity (MCC), the top-1 prediction accuracy reached 67.8% for base DRGs and 67.5% for CC/MCC status. DRG-L
    
[^47]: 从文字到趋势：园艺分析视角对现代农业的未来的独特见解

    From Text to Trends: A Unique Garden Analytics Perspective on the Future of Modern Agriculture. (arXiv:2309.12579v1 [cs.AI])

    [http://arxiv.org/abs/2309.12579](http://arxiv.org/abs/2309.12579)

    这项研究引入了一个基于机器学习的框架，利用园艺领域的在线问答数据来提高农业教育和管理效果，并通过分类和时间分析来预测未来的问题趋势。

    

    数据驱动的洞察对现代农业至关重要。本研究论文介绍了一个机器学习框架，旨在改善我们在园艺领域教育和触及人群的方式。该框架依赖于Horticulture Online Help Desk（HOHD）的数据，该数据库是园艺爱好者和大师园艺师项目（EMGP）的一系列问题。该框架有两个主要部分。首先，它使用特殊的计算机程序（机器学习模型）将问题分类。这帮助我们快速将每个问题发送给正确的专家，以更快地回答问题。其次，它根据问题的提出时间来猜测我们将来可能会收到多少问题以及它们的内容。这帮助我们计划将来真正重要的主题。就像知道未来几个月将会有哪些热门问题一样。我们还通过查看问题的来源来考虑问题的地域分布。

    Data-driven insights are essential for modern agriculture. This research paper introduces a machine learning framework designed to improve how we educate and reach out to people in the field of horticulture. The framework relies on data from the Horticulture Online Help Desk (HOHD), which is like a big collection of questions from people who love gardening and are part of the Extension Master Gardener Program (EMGP). This framework has two main parts. First, it uses special computer programs (machine learning models) to sort questions into categories. This helps us quickly send each question to the right expert, so we can answer it faster. Second, it looks at when questions are asked and uses that information to guess how many questions we might get in the future and what they will be about. This helps us plan on topics that will be really important. It's like knowing what questions will be popular in the coming months. We also take into account where the questions come from by looking
    
[^48]: 理解网络架构搜索中深度学习模型演化的模式

    Understanding Patterns of Deep Learning ModelEvolution in Network Architecture Search. (arXiv:2309.12576v1 [cs.AI])

    [http://arxiv.org/abs/2309.12576](http://arxiv.org/abs/2309.12576)

    本文研究了网络架构搜索中深度学习模型演化的模式，揭示了正则化进化算法对模型结构演化的影响，并讨论了分布式和缓存方面的机会，以及模型架构流行度的影响因素。

    

    网络架构搜索和具体来说是正则化进化是改进深度学习模型结构的常用方法。然而，我们对模型在实际演化的过程中知之甚少，这对于设计缓存策略、改进特定应用的搜索算法以及其他重要用例具有设计影响。在这项工作中，我们通过算法分析和定量描述了Candle项目和Nasbench-201搜索空间中一组模型的演化模式。我们展示了模型结构的演化受到正则化进化算法的影响。我们描述了演化模式在分布式环境和缓存和改进调度方面的机会。最后，我们描述了影响特定模型架构何时在流行度上升和下降的条件，这是基于它们在滑动窗口中充当捐献者的频率。

    Network Architecture Search and specifically Regularized Evolution is a common way to refine the structure of a deep learning model.However, little is known about how models empirically evolve over time which has design implications for designing caching policies, refining the search algorithm for particular applications, and other important use cases.In this work, we algorithmically analyze and quantitatively characterize the patterns of model evolution for a set of models from the Candle project and the Nasbench-201 search space.We show how the evolution of the model structure is influenced by the regularized evolution algorithm. We describe how evolutionary patterns appear in distributed settings and opportunities for caching and improved scheduling. Lastly, we describe the conditions that affect when particular model architectures rise and fall in popularity based on their frequency of acting as a donor in a sliding window.
    
[^49]: 大型语言模型下的创造力支持: 一项涉及新兴作家的实证研究

    Creativity Support in the Age of Large Language Models: An Empirical Study Involving Emerging Writers. (arXiv:2309.12570v1 [cs.HC])

    [http://arxiv.org/abs/2309.12570](http://arxiv.org/abs/2309.12570)

    本文通过实证研究探讨了大型语言模型（LLM）在协助专业作家方面的效用，并发现作家们更倾向于在翻译和审查阶段中寻求LLM的帮助。

    

    大型语言模型（LLM）的发展使得其能够遵循指令并参与对话互动，引发了在各种支持工具中利用它们的兴趣增加。我们通过一项实证用户研究（n=30）探讨了现代LLM在协助专业作家方面的效用。我们的合作写作界面设计基于将写作视为一个目标导向的思维过程的认知过程模型，涵盖了非线性的认知活动：规划、翻译和审查。参与者被要求提交一份后完成调查，以提供关于LLM作为写作合作者潜力和问题的反馈。通过分析作家-LLM互动,我们发现作家在三种类型的认知活动中都寻求LLM的帮助，但他们发现LLM在翻译和审查方面更有帮助。通过分析互动和调查结果，我们的发现强调了未来研究的方向。

    The development of large language models (LLMs) capable of following instructions and engaging in conversational interactions sparked increased interest in their utilization across various support tools. We investigate the utility of modern LLMs in assisting professional writers via an empirical user study (n=30). The design of our collaborative writing interface is grounded in the cognitive process model of writing that views writing as a goal-oriented thinking process encompassing non-linear cognitive activities: planning, translating, and reviewing. Participants are asked to submit a post-completion survey to provide feedback on the potential and pitfalls of LLMs as writing collaborators. Upon analyzing the writer-LLM interactions, we find that while writers seek LLM's help across all three types of cognitive activities, they find LLMs more helpful in translation and reviewing. Our findings from analyzing both the interactions and the survey responses highlight future research direc
    
[^50]: 一项关于利用多模态感知学习社交机器人导航的研究

    A Study on Learning Social Robot Navigation with Multimodal Perception. (arXiv:2309.12568v1 [cs.RO])

    [http://arxiv.org/abs/2309.12568](http://arxiv.org/abs/2309.12568)

    本文通过利用大规模真实世界数据集，综合研究了利用多模态感知学习社交机器人导航的方法。研究结果发现，机器学习方法可以有效地捕捉复杂而微妙的社交互动，而无需手工制作简化模型或成本函数。

    

    自主移动机器人需要利用其搭载的传感器（如LiDAR和RGB摄像头）感知环境，然后做出适当的导航决策。为了在人类居住的公共空间中进行导航任务，这样的导航任务不仅仅是避开障碍物，还需要考虑周围的人和他们的意图，以在对底层社会规范的响应中改变导航行为，即社会合规性。机器学习方法已被证明在以数据驱动方式捕捉这些复杂而微妙的社交互动方面是有效的，而无需显式手工制作简化模型或成本函数。考虑到多种可用的传感器模态和学习方法的效率，本文提出了一项利用大规模真实世界数据集进行多模态感知学习社交机器人导航的综合研究。该研究在全局和局部层面上探讨了社交机器人导航决策制定的问题。

    Autonomous mobile robots need to perceive the environments with their onboard sensors (e.g., LiDARs and RGB cameras) and then make appropriate navigation decisions. In order to navigate human-inhabited public spaces, such a navigation task becomes more than only obstacle avoidance, but also requires considering surrounding humans and their intentions to somewhat change the navigation behavior in response to the underlying social norms, i.e., being socially compliant. Machine learning methods are shown to be effective in capturing those complex and subtle social interactions in a data-driven manner, without explicitly hand-crafting simplified models or cost functions. Considering multiple available sensor modalities and the efficiency of learning methods, this paper presents a comprehensive study on learning social robot navigation with multimodal perception using a large-scale real-world dataset. The study investigates social robot navigation decision making on both the global and loca
    
[^51]: 机器学习与先进机器人操作相结合

    Machine Learning Meets Advanced Robotic Manipulation. (arXiv:2309.12560v1 [cs.RO])

    [http://arxiv.org/abs/2309.12560](http://arxiv.org/abs/2309.12560)

    该论文回顾了应用于实际操作任务的机器学习方法的前沿技术和最新趋势，并提出了改进机器学习方法在训练和部署阶段安全性、可靠性和效率的方法。

    

    自动化工业导致高质量生产，降低制造成本并更好地利用人力资源。机器人操纵臂在自动化过程中起着重要作用。然而，对于复杂的操作任务，编写高效且安全的轨迹是具有挑战性且耗时的。机器学习方法有潜力基于专家演示来学习这样的控制器。尽管有了一些有希望的进展，但仍需开发更好的方法来提高机器学习方法在训练和部署阶段的安全性、可靠性和效率。本综述旨在回顾应用于实际操作任务的机器学习方法的前沿技术和最新趋势。在回顾机器学习的相关背景之后，文章其余部分详细介绍了机器学习在工业、医疗、农业、空间、军事和搜救等不同领域的应用。文章最后总结了未来的重要研究方向。

    Automated industries lead to high quality production, lower manufacturing cost and better utilization of human resources. Robotic manipulator arms have major role in the automation process. However, for complex manipulation tasks, hard coding efficient and safe trajectories is challenging and time consuming. Machine learning methods have the potential to learn such controllers based on expert demonstrations. Despite promising advances, better approaches must be developed to improve safety, reliability, and efficiency of ML methods in both training and deployment phases. This survey aims to review cutting edge technologies and recent trends on ML methods applied to real-world manipulation tasks. After reviewing the related background on ML, the rest of the paper is devoted to ML applications in different domains such as industry, healthcare, agriculture, space, military, and search and rescue. The paper is closed with important research directions for future works.
    
[^52]: 通过充分因素和必要因素的概率进行不变学习

    Invariant Learning via Probability of Sufficient and Necessary Causes. (arXiv:2309.12559v1 [cs.LG])

    [http://arxiv.org/abs/2309.12559](http://arxiv.org/abs/2309.12559)

    本研究通过引入充分因素和必要因素的概率（PNS）来改善在未知测试分布上的泛化问题，以解决现有方法主要关注因果性的不变性属性而忽视充分性和必要性条件的问题。

    

    在野外学习中，对于未知的、与训练分布不同的测试分布，外部分布（OOD）泛化是不可或缺的。最近从因果性引发的方法在实现OOD泛化方面显示出了巨大的潜力。然而，现有方法主要关注因果性的不变性属性，而在很大程度上忽视了充分性和必要性条件的属性。换句话说，一个必要但不充分的原因（特征）对于分布转换是不变的，但可能没有所需的准确度。相反，一个充分但不必要的原因（特征）倾向于很好地适应特定数据，但可能存在适应新领域的风险。为了捕捉充分和必要因素的信息，我们采用了经典概念——充分和必要因素的概率（PNS），它指示了一个因素是必要和充分原因的概率。为了将PNS与OOD泛化联系起来，我们提出了一种方法

    Out-of-distribution (OOD) generalization is indispensable for learning models in the wild, where testing distribution typically unknown and different from the training. Recent methods derived from causality have shown great potential in achieving OOD generalization. However, existing methods mainly focus on the invariance property of causes, while largely overlooking the property of \textit{sufficiency} and \textit{necessity} conditions. Namely, a necessary but insufficient cause (feature) is invariant to distribution shift, yet it may not have required accuracy. By contrast, a sufficient yet unnecessary cause (feature) tends to fit specific data well but may have a risk of adapting to a new domain. To capture the information of sufficient and necessary causes, we employ a classical concept, the probability of sufficiency and necessary causes (PNS), which indicates the probability of whether one is the necessary and sufficient cause. To associate PNS with OOD generalization, we propose
    
[^53]: PlanFitting：利用大型语言模型定制个性化的运动计划

    PlanFitting: Tailoring Personalized Exercise Plans with Large Language Models. (arXiv:2309.12555v1 [cs.HC])

    [http://arxiv.org/abs/2309.12555](http://arxiv.org/abs/2309.12555)

    PlanFitting是一个对话型人工智能，利用大型语言模型的生成能力帮助用户定制个性化的运动计划，并在用户研究中证明了它生成个性化、可操作和有据可依的运动计划的潜力。

    

    个性化的运动计划对于确保足够的体育活动至关重要，但由于人们的复杂日程和考虑因素以及计划的创建通常需要与专家的反复沟通，这一过程变得具有挑战性。我们提出了PlanFitting，它是一个对话型人工智能，可以辅助个性化的运动计划。通过利用大型语言模型的生成能力，PlanFitting使用户能够用自然语言描述各种约束和查询，从而便于创建和优化适合其特定情况的每周运动计划，并保持基本原则的扎根。通过一项用户研究，参与者（N=18）使用PlanFitting生成个性化的运动计划，而专家规划者（N=3）对这些计划进行评估，我们确定了PlanFitting在生成个性化、可操作和有据可依的运动计划方面的潜力。我们还讨论了AI助手在创建计划方面的未来设计机遇。

    A personally tailored exercise regimen is crucial to ensuring sufficient physical activities, yet challenging to create as people have complex schedules and considerations and the creation of plans often requires iterations with experts. We present PlanFitting, a conversational AI that assists in personalized exercise planning. Leveraging generative capabilities of large language models, PlanFitting enables users to describe various constraints and queries in natural language, thereby facilitating the creation and refinement of their weekly exercise plan to suit their specific circumstances while staying grounded in foundational principles. Through a user study where participants (N=18) generated a personalized exercise plan using PlanFitting and expert planners (N=3) evaluated these plans, we identified the potential of PlanFitting in generating personalized, actionable, and evidence-based exercise plans. We discuss future design opportunities for AI assistants in creating plans that 
    
[^54]: 通过鲁棒优化方法为神经网络提供可证明的鲁棒和可信的反事实解释

    Provably Robust and Plausible Counterfactual Explanations for Neural Networks via Robust Optimisation. (arXiv:2309.12545v1 [cs.LG])

    [http://arxiv.org/abs/2309.12545](http://arxiv.org/abs/2309.12545)

    本文提出了一种名为PROPLACE的方法，通过鲁棒优化技术为神经网络提供可证明的鲁棒和可信的反事实解释，解决了现有方法在保持鲁棒性的同时生成不合理解释的问题。

    

    反事实解释(CEs)作为解释神经网络分类器的主要方法已经引起了越来越多的关注。通常，CEs对于输入-输出对被定义为到输入的最小距离的数据点，其与输出具有不同的标签。为了解决CEs在模型参数更新(比如重新训练)时很容易被无效的问题，研究提出了一种通过模型参数变化的范数球界限来证明CEs的鲁棒性的方法。然而，现有的针对这种鲁棒性的方法不是完全正确的，或者可能生成不合理的CEs，即与训练数据集存在离群值。事实上，目前没有一种方法能够同时优化距离和可信度，并保持鲁棒性保证。在这项工作中，我们提出了一种名为PROPLACE的方法，利用鲁棒优化技术来解决上述问题。

    Counterfactual Explanations (CEs) have received increasing interest as a major methodology for explaining neural network classifiers. Usually, CEs for an input-output pair are defined as data points with minimum distance to the input that are classified with a different label than the output. To tackle the established problem that CEs are easily invalidated when model parameters are updated (e.g. retrained), studies have proposed ways to certify the robustness of CEs under model parameter changes bounded by a norm ball. However, existing methods targeting this form of robustness are not sound or complete, and they may generate implausible CEs, i.e., outliers wrt the training dataset. In fact, no existing method simultaneously optimises for proximity and plausibility while preserving robustness guarantees. In this work, we propose Provably RObust and PLAusible Counterfactual Explanations (PROPLACE), a method leveraging on robust optimisation techniques to address the aforementioned limi
    
[^55]: 通过形态-环境共同进化的课程强化学习

    Curriculum Reinforcement Learning via Morphology-Environment Co-Evolution. (arXiv:2309.12529v1 [cs.AI])

    [http://arxiv.org/abs/2309.12529](http://arxiv.org/abs/2309.12529)

    本文通过形态-环境共同进化的方式，优化了强化学习代理和形态，实现了一个训练具有泛化性的强化学习课程，并自动改变环境和形态。

    

    在长时间的演化过程中，自然物种通过进化其身体结构以适应环境变化来学会生存。相比之下，当前的强化学习研究主要集中在训练具有固定形态（如骨架结构和关节属性）的代理在固定环境中学习，很难推广到变化的环境或新任务。本文通过“形态-环境共同进化（MECE）”来优化强化学习代理和其形态，其中形态不断更新以适应变化的环境，同时环境逐渐修改以带来新的挑战并促进形态的改善。这导致了一个训练具有泛化性的强化学习的课程，其形态和策略针对不同的环境进行优化。我们通过训练两种策略来自动改变形态和环境，而不是手工设计课程。为此，（1）我们开发了两种新颖的方法。

    Throughout long history, natural species have learned to survive by evolving their physical structures adaptive to the environment changes. In contrast, current reinforcement learning (RL) studies mainly focus on training an agent with a fixed morphology (e.g., skeletal structure and joint attributes) in a fixed environment, which can hardly generalize to changing environments or new tasks. In this paper, we optimize an RL agent and its morphology through ``morphology-environment co-evolution (MECE)'', in which the morphology keeps being updated to adapt to the changing environment, while the environment is modified progressively to bring new challenges and stimulate the improvement of the morphology. This leads to a curriculum to train generalizable RL, whose morphology and policy are optimized for different environments. Instead of hand-crafting the curriculum, we train two policies to automatically change the morphology and the environment. To this end, (1) we develop two novel and 
    
[^56]: 知识图谱嵌入：综述

    Knowledge Graph Embedding: An Overview. (arXiv:2309.12501v1 [cs.AI])

    [http://arxiv.org/abs/2309.12501](http://arxiv.org/abs/2309.12501)

    该论文综述了知识图谱嵌入的研究状态，介绍了两个主要分支：基于距离和基于语义匹配的方法。还讨论了CompoundE和CompoundE3D模型，并揭示了一个潜在的研究趋势。

    

    许多数学模型已被利用来设计嵌入，以表示知识图谱（KG）中的实体和关系，用于链接预测和许多下游任务。这些数学启发的模型不仅在大型KG中进行推理时高度可扩展，而且在建模不同关系模式方面具有很多可解释的优势，这些优势可以通过形式化证明和经验结果来验证。在本文中，我们对KG完成领域的当前研究状态进行了全面的概述。特别是，我们着重介绍了KG嵌入（KGE）设计的两个主要分支：1）基于距离的方法和2）基于语义匹配的方法。我们发现了最近提出的模型之间的联系，并提出了一个潜在的趋势，这可能有助于研究人员发明新颖且更有效的模型。接下来，我们深入探讨了从2D和3D仿射操作中汲取灵感的CompoundE和CompoundE3D。它们涵盖了包括dis在内的广泛技术谓词的范围。

    Many mathematical models have been leveraged to design embeddings for representing Knowledge Graph (KG) entities and relations for link prediction and many downstream tasks. These mathematically-inspired models are not only highly scalable for inference in large KGs, but also have many explainable advantages in modeling different relation patterns that can be validated through both formal proofs and empirical results. In this paper, we make a comprehensive overview of the current state of research in KG completion. In particular, we focus on two main branches of KG embedding (KGE) design: 1) distance-based methods and 2) semantic matching-based methods. We discover the connections between recently proposed models and present an underlying trend that might help researchers invent novel and more effective models. Next, we delve into CompoundE and CompoundE3D, which draw inspiration from 2D and 3D affine operations, respectively. They encompass a broad spectrum of techniques including dis
    
[^57]: 探索训练数据分布和子词标记对机器翻译中的性别偏见的影响

    Exploring the Impact of Training Data Distribution and Subword Tokenization on Gender Bias in Machine Translation. (arXiv:2309.12491v1 [cs.CL])

    [http://arxiv.org/abs/2309.12491](http://arxiv.org/abs/2309.12491)

    这项研究探索了训练数据分布和子词标记对机器翻译中性别偏见的影响。研究发现，模型训练语料库中性别形式的不平衡是导致性别偏见的主要因素，而子词拆分的影响较小。同时，研究还发现，通过分析子词拆分可以很好地估计训练数据中性别形式的不平衡。最后，通过仅微调标记嵌入层可以减少女性和男性之间性别预测准确性的差距。

    

    我们研究了标记化对机器翻译中性别偏见的影响，这是之前的研究中被大多数人忽视的一个方面。具体而言，我们关注的是训练数据中性别职业名称的频率、它们在子词标记器词汇表中的表示以及性别偏见之间的相互作用。我们观察到，女性和非刻板印象的性别职业名称的变形（例如，西班牙语中的"doctora"表示"女医生"）往往被拆分成多个子词标记。我们的结果表明，模型训练语料库中性别形式的不平衡是导致性别偏见的主要因素，其影响大于子词拆分。我们展示了分析子词拆分可以很好地估计训练数据中性别形式的不平衡，并且可以在语料库不公开的情况下使用。我们还证明，仅微调标记嵌入层可以减少女性和男性之间性别预测准确性的差距。

    We study the effect of tokenization on gender bias in machine translation, an aspect that has been largely overlooked in previous works. Specifically, we focus on the interactions between the frequency of gendered profession names in training data, their representation in the subword tokenizer's vocabulary, and gender bias. We observe that female and non-stereotypical gender inflections of profession names (e.g., Spanish "doctora" for "female doctor") tend to be split into multiple subword tokens. Our results indicate that the imbalance of gender forms in the model's training corpus is a major factor contributing to gender bias and has a greater impact than subword splitting. We show that analyzing subword splits provides good estimates of gender-form imbalance in the training data and can be used even when the corpus is not publicly available. We also demonstrate that fine-tuning just the token embedding layer can decrease the gap in gender prediction accuracy between female and male 
    
[^58]: 研究和改进人类和机器的推理能力

    Studying and improving reasoning in humans and machines. (arXiv:2309.12485v1 [cs.CL])

    [http://arxiv.org/abs/2309.12485](http://arxiv.org/abs/2309.12485)

    本研究通过对大型语言模型（LLM）和人类的推理能力进行比较研究，发现LLM在推理中存在类似于人类启发式推理的错误，但与人类推理有重要差异，最新的LLM版本几乎消除了模型的限制。此外，人类和机器对相同的提示方案的反应不同。这些结果对我们的认识论有重大影响。

    

    在本研究中，我们使用传统用于研究（有限）理性的认知心理学工具，研究和比较了大型语言模型（LLM）和人类的推理能力。为此，我们向人类参与者和一系列预训练的LLM呈现了新的经典认知实验的变体，并对它们的表现进行了交叉比较。我们的结果显示，大多数模型呈现出类似于常见的错误倾向于启发式人类推理的推理错误。尽管有这种表面上的相似性，人类和LLM之间的深入比较表明了人类样式推理的重要差异，随着最近LLM版本的推出，模型的限制几乎完全消失。此外，我们还展示出，虽然可能制定策略以获得更好的表现，但人类和机器对相同的提示方案的反应并不相同。我们通过讨论这一认识论的影响来总结。

    In the present study, we investigate and compare reasoning in large language models (LLM) and humans using a selection of cognitive psychology tools traditionally dedicated to the study of (bounded) rationality. To do so, we presented to human participants and an array of pretrained LLMs new variants of classical cognitive experiments, and cross-compared their performances. Our results showed that most of the included models presented reasoning errors akin to those frequently ascribed to error-prone, heuristic-based human reasoning. Notwithstanding this superficial similarity, an in-depth comparison between humans and LLMs indicated important differences with human-like reasoning, with models limitations disappearing almost entirely in more recent LLMs releases. Moreover, we show that while it is possible to devise strategies to induce better performance, humans and machines are not equally-responsive to the same prompting schemes. We conclude by discussing the epistemological implicat
    
[^59]: State2Explanation:基于概念的解释：有利于Agent学习和用户理解

    State2Explanation: Concept-Based Explanations to Benefit Agent Learning and User Understanding. (arXiv:2309.12482v1 [cs.LG])

    [http://arxiv.org/abs/2309.12482](http://arxiv.org/abs/2309.12482)

    本论文致力于开发一种基于概念的解释方法，旨在提高非AI专家对AI决策的理解。通过定义顺序决策设置中的“概念”以及探索基于概念的解释对RL agent学习效果和最终用户对agent决策理解的双重好处，我们提出了一个统一的框架。

    

    随着非AI专家使用更复杂的AI系统来完成日常任务，人们越来越努力开发能够为非AI专家理解的AI决策提供解释的方法。为了实现这个目标，利用高级概念并生成基于概念的解释已经成为一种流行的方法。大多数基于概念的解释都是为分类技术而开发的，我们认为目前关于顺序决策的方法还存在一定限制。在这项工作中，我们首先提出了在顺序决策设置中定义“概念”的愿望。受到“Protege效应”的启发，该效应说明解释知识通常会增强个体的自主学习能力，我们探索了基于概念的解释对RL agent的学习效果和最终用户对agent决策理解的双重好处。为此，我们提出了一个统一的框架，St

    With more complex AI systems used by non-AI experts to complete daily tasks, there is an increasing effort to develop methods that produce explanations of AI decision making understandable by non-AI experts. Towards this effort, leveraging higher-level concepts and producing concept-based explanations have become a popular method. Most concept-based explanations have been developed for classification techniques, and we posit that the few existing methods for sequential decision making are limited in scope. In this work, we first contribute a desiderata for defining "concepts" in sequential decision making settings. Additionally, inspired by the Protege Effect which states explaining knowledge often reinforces one's self-learning, we explore the utility of concept-based explanations providing a dual benefit to the RL agent by improving agent learning rate, and to the end-user by improving end-user understanding of agent decision making. To this end, we contribute a unified framework, St
    
[^60]: SAVME: 使用元学习进行自动系统的高效安全验证

    SAVME: Efficient Safety Validation for Autonomous Systems Using Meta-Learning. (arXiv:2309.12474v1 [cs.RO])

    [http://arxiv.org/abs/2309.12474](http://arxiv.org/abs/2309.12474)

    本论文提出了一种使用元学习进行高效安全验证的方法，通过集成贝叶斯方法和多臂赌博机框架，加速验证过程。该方法学习在测试中容易引发故障的场景参数分布和能够进行快速准确模拟的保真度设置分布，并通过评估保真度设置分布是否有助于对新场景的场景参数分布进行更快的学习来进一步提高效率。

    

    在部署前，发现自动系统的潜在故障非常重要。虚构法常被用来评估此类系统的安全性，但运行准确模拟的成本很高。我们提出了一种贝叶斯方法，将元学习策略与多臂赌博机框架相结合，加速验证过程。我们的方法涉及学习在测试中容易引发故障的场景参数分布，以及能够进行快速准确模拟的保真度设置分布。在元学习的精神下，我们还评估学习到的保真度设置分布是否有助于对新场景的场景参数分布进行更快的学习。我们使用先进的3D驾驶模拟器展示了我们的方法，并整合了16种保真度设置。

    Discovering potential failures of an autonomous system is important prior to deployment. Falsification-based methods are often used to assess the safety of such systems, but the cost of running many accurate simulation can be high. The validation can be accelerated by identifying critical failure scenarios for the system under test and by reducing the simulation runtime. We propose a Bayesian approach that integrates meta-learning strategies with a multi-armed bandit framework. Our method involves learning distributions over scenario parameters that are prone to triggering failures in the system under test, as well as a distribution over fidelity settings that enable fast and accurate simulations. In the spirit of meta-learning, we also assess whether the learned fidelity settings distribution facilitates faster learning of the scenario parameter distributions for new scenarios. We showcase our methodology using a cutting-edge 3D driving simulator, incorporating 16 fidelity settings fo
    
[^61]: 多模态深度学习用于科学成像解释

    Multimodal Deep Learning for Scientific Imaging Interpretation. (arXiv:2309.12460v1 [cs.LG])

    [http://arxiv.org/abs/2309.12460](http://arxiv.org/abs/2309.12460)

    本研究提出了一种多模态深度学习框架，通过模拟人类与扫描电子显微镜图像的交互，利用文本和视觉数据进行精细数据合成和评估。该模型（GlassLLaVA）能够准确解释、识别关键特征和检测以前未见的SEM图像中的缺陷，同时引入了适用于多种科学成像应用的灵活评估指标。

    

    在科学成像领域，解释视觉数据常常需要人类专业知识和对主题材料的深入理解的复杂组合。本研究提出了一种新的方法，通过多模态深度学习框架来模拟并评估与扫描电子显微镜（SEM）图像的人类交互，特别是玻璃材料图像。我们的方法利用从同行评议的文章中收集的文本和视觉数据，进一步借助 GPT-4 的能力进行精细数据合成和评估。尽管存在诸多挑战，如细微的解释和专业数据集的有限可用性，但我们的模型（GlassLLaVA）在制定准确的解释、识别关键特征和检测以前未见的SEM图像中的缺陷方面表现出色。此外，我们引入了适用于多种科学成像应用的灵活评估指标，使得进行综合评估成为可能。

    In the domain of scientific imaging, interpreting visual data often demands an intricate combination of human expertise and deep comprehension of the subject materials. This study presents a novel methodology to linguistically emulate and subsequently evaluate human-like interactions with Scanning Electron Microscopy (SEM) images, specifically of glass materials. Leveraging a multimodal deep learning framework, our approach distills insights from both textual and visual data harvested from peer-reviewed articles, further augmented by the capabilities of GPT-4 for refined data synthesis and evaluation. Despite inherent challenges--such as nuanced interpretations and the limited availability of specialized datasets--our model (GlassLLaVA) excels in crafting accurate interpretations, identifying key features, and detecting defects in previously unseen SEM images. Moreover, we introduce versatile evaluation metrics, suitable for an array of scientific imaging applications, which allows for
    
[^62]: LongDocFACTScore: 评估长文档生成摘要的实证性。

    LongDocFACTScore: Evaluating the Factuality of Long Document Abstractive Summarisation. (arXiv:2309.12455v1 [cs.CL])

    [http://arxiv.org/abs/2309.12455](http://arxiv.org/abs/2309.12455)

    LongDocFACTScore是一种评估长文档生成摘要实证性的评估框架，可以解决传统自动评估度量标准无法评估长文档摘要事实一致性的问题。

    

    保持事实一致性是生成性文本摘要中的一个关键问题，然而，传统的用于评估文本摘要的自动度量标准（如ROUGE得分）无法评估事实一致性。最近，人们致力于开发使用预训练语言模型来测量事实一致性的改进度量标准，但这些度量标准有限制性的令牌限制，因此不适用于评估长文档生成摘要。此外，目前有限的研究评估了现有自动评估度量标准在应用于长文档数据集时是否适用。在这项工作中，我们评估了自动度量标准在评估长文档生成摘要的事实一致性方面的功效，并提出了一种新的评估框架LongDocFACTScore。该框架允许度量标准扩展到任意长度的文档。该框架在与人类事实一致性度量的相关性方面优于现有的最先进度量标准。

    Maintaining factual consistency is a critical issue in abstractive text summarisation, however, it cannot be assessed by traditional automatic metrics used for evaluating text summarisation, such as ROUGE scoring. Recent efforts have been devoted to developing improved metrics for measuring factual consistency using pre-trained language models, but these metrics have restrictive token limits, and are therefore not suitable for evaluating long document text summarisation. Moreover, there is limited research evaluating whether existing automatic evaluation metrics are fit for purpose when applied to long document data sets. In this work, we evaluate the efficacy of automatic metrics at assessing factual consistency in long document text summarisation and propose a new evaluation framework LongDocFACTScore. This framework allows metrics to be extended to any length document. This framework outperforms existing state-of-the-art metrics in its ability to correlate with human measures of fac
    
[^63]: 基于集成神经网络的剩余寿命预测

    Ensemble Neural Networks for Remaining Useful Life (RUL) Prediction. (arXiv:2309.12445v1 [cs.LG])

    [http://arxiv.org/abs/2309.12445](http://arxiv.org/abs/2309.12445)

    提出了一种使用集成神经网络的方法进行概率性剩余寿命预测，该方法解耦了来自系统和模型参数的不确定性，并且可以准确地建模和解释预测的信心。

    

    维护计划的核心部分是一个监测系统，它提供健康和退化的良好预测，通常被表示为剩余寿命(RUL)。目前大多数的数据驱动RUL预测方法都集中在单点预测上。这些点预测方法并没有考虑到故障的概率性质。到目前为止，少数的概率性方法要么包括来自系统的aleatoric不确定性，要么包括来自模型参数的epistemic不确定性，要么同时包含两者作为总的不确定性。在这里，我们提出了集成神经网络用于概率性RUL预测，考虑了这两种不确定性并将其解耦。这些解耦的不确定性在了解和解释预测的信心方面非常重要。这个方法在NASA的涡喷式发动机CMAPSS数据集上进行了测试。我们的结果展示了如何建模这些不确定性以及如何解开不确定性。

    A core part of maintenance planning is a monitoring system that provides a good prognosis on health and degradation, often expressed as remaining useful life (RUL). Most of the current data-driven approaches for RUL prediction focus on single-point prediction. These point prediction approaches do not include the probabilistic nature of the failure. The few probabilistic approaches to date either include the aleatoric uncertainty (which originates from the system), or the epistemic uncertainty (which originates from the model parameters), or both simultaneously as a total uncertainty. Here, we propose ensemble neural networks for probabilistic RUL predictions which considers both uncertainties and decouples these two uncertainties. These decoupled uncertainties are vital in knowing and interpreting the confidence of the predictions. This method is tested on NASA's turbofan jet engine CMAPSS data-set. Our results show how these uncertainties can be modeled and how to disentangle the cont
    
[^64]: LLMs能增强低资源阅读理解数据集吗？机遇和挑战。

    Can LLMs Augment Low-Resource Reading Comprehension Datasets? Opportunities and Challenges. (arXiv:2309.12426v1 [cs.CL])

    [http://arxiv.org/abs/2309.12426](http://arxiv.org/abs/2309.12426)

    本研究分析了使用大型语言模型(LLMs)对低资源阅读理解数据集进行增强的可能性。结果显示，GPT-4可以用作低资源读解任务中人工注释者的替代品。这项工作突出了LLMs作为合成数据增强器的机遇和挑战，并发布了增强版本的低资源数据集。

    

    大型语言模型(LLMs)在广泛的NLP任务上展现出了令人印象深刻的零-shot性能，能够进行推理和应用常识。一个相关的应用是将它们用于创建高质量的合成数据集以供后续任务使用。本文探讨了是否能够使用GPT-4来增强现有的抽取式阅读理解数据集。自动化的数据注释过程有潜力节省大量时间、金钱和精力，这些都是用于手动标注数据集的。本文通过比较微调后的性能以及注释的成本，评估了GPT-4作为低资源阅读理解任务的人工注释替代者的性能。这项工作是对LLMs作为QA系统合成数据增强器的首次分析，突出了独特的机遇和挑战。此外，我们还发布了低资源数据集的增强版本，这将使研究人员能够重新评估LLMs在阅读理解任务上的性能。

    Large Language Models (LLMs) have demonstrated impressive zero shot performance on a wide range of NLP tasks, demonstrating the ability to reason and apply commonsense. A relevant application is to use them for creating high quality synthetic datasets for downstream tasks. In this work, we probe whether GPT-4 can be used to augment existing extractive reading comprehension datasets. Automating data annotation processes has the potential to save large amounts of time, money and effort that goes into manually labelling datasets. In this paper, we evaluate the performance of GPT-4 as a replacement for human annotators for low resource reading comprehension tasks, by comparing performance after fine tuning, and the cost associated with annotation. This work serves to be the first analysis of LLMs as synthetic data augmenters for QA systems, highlighting the unique opportunities and challenges. Additionally, we release augmented versions of low resource datasets, that will allow the researc
    
[^65]: 使用基于案例的推理在知识图谱中进行事件预测

    Event Prediction using Case-Based Reasoning over Knowledge Graphs. (arXiv:2309.12423v1 [cs.AI])

    [http://arxiv.org/abs/2309.12423](http://arxiv.org/abs/2309.12423)

    本研究引入了一个基于案例推理模型EvCBR，在知识图谱中利用类似因果事件来预测新结果事件的属性。该模型不需要训练步骤，通过统计度量和基于路径的预测方法实现。研究结果表明，该方法在事件预测任务中取得了良好的效果。

    

    将链接预测（LP）方法应用于知识图谱（KG）中的任务，如因果事件预测，是一个令人兴奋的机会。然而，传统的LP模型对于此任务并不适用，因为它们无法对新的、未见的事件实体进行归纳式链接预测，并且在底层KG中添加或更改知识时需要重新训练。我们引入了一个基于案例推理模型EvCBR，根据KG中存在的类似因果事件来预测关于新的结果事件的属性。EvCBR使用统计度量来识别相似事件并进行基于路径的预测，不需要训练步骤。为了将我们的方法推广到事件预测域之外，我们将我们的任务框架化为一个2-hop LP任务，其中第一跳是将原因事件与新的效果事件连接起来的因果关系，第二跳是我们希望预测的新事件的属性。我们使用一组新颖的新闻数据集证明了我们方法的有效性。

    Applying link prediction (LP) methods over knowledge graphs (KG) for tasks such as causal event prediction presents an exciting opportunity. However, typical LP models are ill-suited for this task as they are incapable of performing inductive link prediction for new, unseen event entities and they require retraining as knowledge is added or changed in the underlying KG. We introduce a case-based reasoning model, EvCBR, to predict properties about new consequent events based on similar cause-effect events present in the KG. EvCBR uses statistical measures to identify similar events and performs path-based predictions, requiring no training step. To generalize our methods beyond the domain of event prediction, we frame our task as a 2-hop LP task, where the first hop is a causal relation connecting a cause event to a new effect event and the second hop is a property about the new event which we wish to predict. The effectiveness of our method is demonstrated using a novel dataset of news
    
[^66]: 约束优先：一种基于MDD的生成受约束句子的新模型

    Constraints First: A New MDD-based Model to Generate Sentences Under Constraints. (arXiv:2309.12415v1 [cs.AI])

    [http://arxiv.org/abs/2309.12415](http://arxiv.org/abs/2309.12415)

    本文介绍了一种基于多值决策图的新模型，用于生成强约束文本。通过将生成句子问题形式化为离散组合优化问题，并利用多值决策图来处理约束，可以得到详尽解集。应用语言模型保留最佳句子，并在英语和法语上进行了详细讨论。该方法相比传统的视力筛查测试带来了重大突破，并且具有广泛的适用性。

    

    本文介绍了一种生成强约束文本的新方法。我们考虑了用于视力筛查的标准化句子生成应用。为了解决这个问题，我们将其形式化为一个离散组合优化问题，并利用多值决策图(MDD)，这是一种处理约束的著名数据结构。在我们的环境中，MDD的一个关键优势是可以计算出不需要进行任何搜索的详尽解集。一旦获得了句子，我们应用了一个语言模型(GPT-2)来保留最佳的句子。我们详细介绍了英语和法语的情况，其中一些一致和变位规则被认为更复杂。最后，借助于GPT-2，我们得到了数百个真正的候选句子。与在著名的视力筛查测试(MNREAD)中通常可用的几十个句子相比，这在标准化句子生成领域带来了重大突破。此外，由于可以轻松调整该方法适应不同的语言和约束，因此具有广泛的适用性。

    This paper introduces a new approach to generating strongly constrained texts. We consider standardized sentence generation for the typical application of vision screening. To solve this problem, we formalize it as a discrete combinatorial optimization problem and utilize multivalued decision diagrams (MDD), a well-known data structure to deal with constraints. In our context, one key strength of MDD is to compute an exhaustive set of solutions without performing any search. Once the sentences are obtained, we apply a language model (GPT-2) to keep the best ones. We detail this for English and also for French where the agreement and conjugation rules are known to be more complex. Finally, with the help of GPT-2, we get hundreds of bona-fide candidate sentences. When compared with the few dozen sentences usually available in the well-known vision screening test (MNREAD), this brings a major breakthrough in the field of standardized sentence generation. Also, as it can be easily adapted 
    
[^67]: SCOB: 通过字符级别监督对比学习和在线文本渲染进行领域间差异的通用文本理解

    SCOB: Universal Text Understanding via Character-wise Supervised Contrastive Learning with Online Text Rendering for Bridging Domain Gap. (arXiv:2309.12382v1 [cs.CV])

    [http://arxiv.org/abs/2309.12382](http://arxiv.org/abs/2309.12382)

    本文提出了一种名为SCOB的新预训练模型，它通过字符级别的监督对比学习和在线文本渲染来有效地预训练文档和场景文本领域，从而弥合了领域之间的差异。SCOB还能实现弱监督学习，大大降低了注释成本。

    

    受基于语言模型（LM）的预训练取得的巨大成功的启发，最近的研究在视觉文档理解中探索了基于LM的预训练方法来建模文档图像中的文本。其中，从图像中读取所有文本的预训练方法显示出了很大的潜力，但在应用于更广泛领域（如包括视觉文档和场景文本图像的领域）时往往具有不稳定性甚至失败。这对于现实世界的场景来说是一个重大限制，因为在各种领域中处理文本图像输入是至关重要的。在本文中，我们研究了更广泛领域中的有效预训练任务，并提出了一种新的预训练方法，名为SCOB，它利用字符级别的监督对比学习和在线文本渲染来通过弥合领域差异有效地预训练文档和场景文本领域。此外，SCOB实现了弱监督学习，大大降低了注释成本。广泛的基准测试结果证明了SCOB的优越性能。

    Inspired by the great success of language model (LM)-based pre-training, recent studies in visual document understanding have explored LM-based pre-training methods for modeling text within document images. Among them, pre-training that reads all text from an image has shown promise, but often exhibits instability and even fails when applied to broader domains, such as those involving both visual documents and scene text images. This is a substantial limitation for real-world scenarios, where the processing of text image inputs in diverse domains is essential. In this paper, we investigate effective pre-training tasks in the broader domains and also propose a novel pre-training method called SCOB that leverages character-wise supervised contrastive learning with online text rendering to effectively pre-train document and scene text domains by bridging the domain gap. Moreover, SCOB enables weakly supervised learning, significantly reducing annotation costs. Extensive benchmarks demonst
    
[^68]: 在复杂医疗决策中重新思考人工智能与人类的合作：以脓毒症诊断为案例研究

    Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis. (arXiv:2309.12368v1 [cs.HC])

    [http://arxiv.org/abs/2309.12368](http://arxiv.org/abs/2309.12368)

    本研究探索了在复杂医疗决策中重新思考人工智能与人类合作的设计要求，以脓毒症诊断为例。研究发现，在人工智能系统中，支持临床专家在决策过程的中间阶段发挥作用（如生成假设或收集数据）是至关重要的，而不仅仅关注最终决策。

    

    如今的医疗决策支持人工智能系统在研究论文中取得了成功，但在实际部署中却面临失败的问题。本研究聚焦于脓毒症的决策过程，这是一种需要临床医生早期高度不确定性诊断的急性致命全身性感染。我们的目标是探索能够支持临床专家做出更好脓毒症早期诊断决策的人工智能系统的设计要求。研究从一个形成性研究开始，调查为什么临床专家在电子病历系统中放弃了一个现有的脓毒症预测模块。我们认为，一个以人为中心的人工智能系统需要在医疗决策过程的中间阶段（如生成假设或收集数据）支持人类专家，而不仅仅关注最终决策。因此，我们基于先进的人工智能算法构建了SepsisLab，并将其扩展到预测未来趋势。

    Today's AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection o
    
[^69]: 在基于GPT的智能辅导系统中研究领域知识库不同程度的影响

    Examining the Influence of Varied Levels of Domain Knowledge Base Inclusion in GPT-based Intelligent Tutors. (arXiv:2309.12367v1 [cs.HC])

    [http://arxiv.org/abs/2309.12367](http://arxiv.org/abs/2309.12367)

    本文研究了在基于GPT的智能辅导系统中将领域知识库与语言模型集成，以提高回答的可靠性。通过设计可扩展的知识库和评估实验，我们展示了该系统的有效性。学生和领域专家对于智能辅导系统的回答进行了验证和排名。

    

    最近大型语言模型（LLM）的进展促进了具有复杂对话能力的聊天机器人的发展。然而，LLM对查询的回答经常不准确，这限制了在教育环境中的应用。本文研究了将知识库（KB）与LLM智能辅导系统集成以增加回答可靠性的效果。为了实现这一目标，我们设计了一个可扩展的知识库，教育监督员可以无缝集成课程，该课程会被智能辅导系统自动处理。然后，我们详细介绍了一个评估实验，学生参与者需要回答有关人工智能课程的问题。 GPT-4智能辅导系统具有不同层次的KB访问权限，并由人类领域专家评估这些回答。最后，学生对智能辅导系统的回答进行了与领域专家的交叉验证，并对它们的各种教学能力进行了排名。

    Recent advancements in large language models (LLMs) have facilitated the development of chatbots with sophisticated conversational capabilities. However, LLMs exhibit frequent inaccurate responses to queries, hindering applications in educational settings. In this paper, we investigate the effectiveness of integrating a knowledge base (KB) with LLM intelligent tutors to increase response reliability. To achieve this, we design a scaleable KB that affords educational supervisors seamless integration of lesson curricula, which is automatically processed by the intelligent tutoring system. We then detail an evaluation, where student participants were presented with questions about the artificial intelligence curriculum to respond to. GPT-4 intelligent tutors with varying hierarchies of KB access and human domain experts then assessed these responses. Lastly, students cross-examined the intelligent tutors' responses to the domain experts' and ranked their various pedagogical abilities. Res
    
[^70]: 一个高效的智能半自动仓库库存盘点系统

    An Efficient Intelligent Semi-Automated Warehouse Inventory Stocktaking System. (arXiv:2309.12365v1 [cs.HC])

    [http://arxiv.org/abs/2309.12365](http://arxiv.org/abs/2309.12365)

    本研究提出了一个智能库存管理系统，通过结合条码和分布式flutter应用技术，以及大数据分析实现数据驱动的决策，解决了库存管理中的准确性、监测延迟和过度依赖主观经验的挑战。

    

    在不断发展的供应链管理背景下，高效的库存管理对于企业变得越来越重要。然而，传统的手工和经验驱动的方法往往难以满足现代市场需求的复杂性。本研究引入了一种智能库存管理系统，以解决与数据不准确、监测延迟和过度依赖主观经验的预测相关的挑战。该系统结合了条码和分布式 flutter 应用技术，用于智能感知，并通过全面的大数据分析实现数据驱动的决策。通过仔细的分析、系统设计、关键技术探索和模拟验证，成功展示了所提出系统的有效性。该智能系统实现了二级监测、高频检查和人工智能驱动的预测，从而提高了自动化程度。

    In the context of evolving supply chain management, the significance of efficient inventory management has grown substantially for businesses. However, conventional manual and experience-based approaches often struggle to meet the complexities of modern market demands. This research introduces an intelligent inventory management system to address challenges related to inaccurate data, delayed monitoring, and overreliance on subjective experience in forecasting. The proposed system integrates bar code and distributed flutter application technologies for intelligent perception, alongside comprehensive big data analytics to enable data-driven decision-making. Through meticulous analysis, system design, critical technology exploration, and simulation validation, the effectiveness of the proposed system is successfully demonstrated. The intelligent system facilitates second-level monitoring, high-frequency checks, and artificial intelligence-driven forecasting, consequently enhancing the au
    
[^71]: 调查在线财经错误信息及其后果：一种计算方法

    Investigating Online Financial Misinformation and Its Consequences: A Computational Perspective. (arXiv:2309.12363v1 [cs.CY])

    [http://arxiv.org/abs/2309.12363](http://arxiv.org/abs/2309.12363)

    这篇论文调查了在线财经错误信息及其后果，包括错误信息的类型、来源和影响。研究强调了早期发现和缓解策略可能对保护投资者、增强市场透明度和维护金融稳定的意义。

    

    数字平台快速传播信息已经彻底改变了我们获取和消费新闻和信息的方式，尤其是在金融领域。然而，数字时代也催生了大量可怕的财经错误信息，这些信息对个人、市场和整体经济都会造成不利影响。这篇研究论文旨在全面调查在线财经错误信息，包括它们的类型、来源和影响。首先，我们讨论了财经错误信息的特征和表现，包括虚假声明和误导性内容。我们探索了一些案例研究，以说明财经错误信息对经济的有害后果。最后，我们强调了检测财经错误信息的潜在影响和意义。早期发现和缓解策略可以帮助保护投资者，增强市场透明度，维护金融稳定。

    The rapid dissemination of information through digital platforms has revolutionized the way we access and consume news and information, particularly in the realm of finance. However, this digital age has also given rise to an alarming proliferation of financial misinformation, which can have detrimental effects on individuals, markets, and the overall economy. This research paper aims to provide a comprehensive survey of online financial misinformation, including its types, sources, and impacts. We first discuss the characteristics and manifestations of financial misinformation, encompassing false claims and misleading content. We explore various case studies that illustrate the detrimental consequences of financial misinformation on the economy. Finally, we highlight the potential impact and implications of detecting financial misinformation. Early detection and mitigation strategies can help protect investors, enhance market transparency, and preserve financial stability. We emphasiz
    
[^72]: ChatGPT基于病例报告辅助神经眼科疾病的诊断

    ChatGPT Assisting Diagnosis of Neuro-ophthalmology Diseases Based on Case Reports. (arXiv:2309.12361v1 [cs.CY])

    [http://arxiv.org/abs/2309.12361](http://arxiv.org/abs/2309.12361)

    本研究评估了大型语言模型ChatGPT在神经眼科疾病诊断中的辅助效果。实验结果显示，ChatGPT在13个病例中正确诊断了59%，而ChatGPT Plus和两名神经眼科医生的正确率分别达到了82%和86%。这表明ChatGPT可以作为神经眼科疾病诊断的有用工具。

    

    目的：评估大型语言模型（LLM）如ChatGPT在基于详细病例描述辅助神经眼科疾病诊断方面的效果。方法：我们从一个公开可用的在线数据库中选择了22个不同的神经眼科疾病病例报告。这些病例包括神经眼科亚专科常见的慢性和急性疾病。我们把每个病例的文本作为新的提示插入到ChatGPT v3.5和ChatGPT Plus v4.0中，并询问最有可能的诊断。然后，我们将准确的信息提供给两名神经眼科医生，并记录他们的诊断结果，然后与ChatGPT的回答进行对比。结果：ChatGPT v3.5、ChatGPT Plus v4.0和两名神经眼科医生在22个病例中分别达到13个（59%）、18个（82%）、19个（86%）和19个（86%）的正确诊断。各种诊断来源之间的一致性如下：ChatGPT v3.5和ChatGPT Plus v4.0的一致性为13个...

    Objective: To evaluate the efficiency of large language models (LLMs) such as ChatGPT to assist in diagnosing neuro-ophthalmic diseases based on detailed case descriptions. Methods: We selected 22 different case reports of neuro-ophthalmic diseases from a publicly available online database. These cases included a wide range of chronic and acute diseases that are commonly seen by neuro-ophthalmic sub-specialists. We inserted the text from each case as a new prompt into both ChatGPT v3.5 and ChatGPT Plus v4.0 and asked for the most probable diagnosis. We then presented the exact information to two neuro-ophthalmologists and recorded their diagnoses followed by comparison to responses from both versions of ChatGPT. Results: ChatGPT v3.5, ChatGPT Plus v4.0, and the two neuro-ophthalmologists were correct in 13 (59%), 18 (82%), 19 (86%), and 19 (86%) out of 22 cases, respectively. The agreement between the various diagnostic sources were as follows: ChatGPT v3.5 and ChatGPT Plus v4.0, 13 (5
    
[^73]: 通过自然语言处理和抽样实现高效的社会选择

    Efficient Social Choice via NLP and Sampling. (arXiv:2309.12360v1 [cs.CY])

    [http://arxiv.org/abs/2309.12360](http://arxiv.org/abs/2309.12360)

    本文通过结合自然语言处理和抽样技术，提出了一种高效的注意力感知社会选择系统，该系统使用训练有素的NLP模型估计了提案通过的概率，并通过采样多数来决定提案。

    

    注意力感知社会选择解决了一些代理社区面临的基本冲突，即在决策过程中包括所有成员的渴望与社区成员可支配的有限时间和注意力之间的矛盾。本文研究了注意力感知社会选择的两种技术组合，即自然语言处理（NLP）和抽样。基本上，我们提出了一个系统，其中每个改变现状的治理提案首先发送到训练有素的NLP模型，该模型估计了如果所有社区成员直接对其进行投票，该提案通过的概率；然后，基于这种估计，选择一个确定大小的人群样本，并通过采样多数决定提案。我们根据上述方案开发了几种具体算法，并使用各种数据进行评估，包括多个分散自治组织（DAO）的数据。

    Attention-Aware Social Choice tackles the fundamental conflict faced by some agent communities between their desire to include all members in the decision making processes and the limited time and attention that are at the disposal of the community members. Here, we investigate a combination of two techniques for attention-aware social choice, namely Natural Language Processing (NLP) and Sampling. Essentially, we propose a system in which each governance proposal to change the status quo is first sent to a trained NLP model that estimates the probability that the proposal would pass if all community members directly vote on it; then, based on such an estimation, a population sample of a certain size is being selected and the proposal is decided upon by taking the sample majority. We develop several concrete algorithms following the scheme described above and evaluate them using various data, including such from several Decentralized Autonomous Organizations (DAOs).
    
[^74]: 在新闻学研究中绘制人工智能论点

    Mapping AI Arguments in Journalism Studies. (arXiv:2309.12357v1 [cs.CY])

    [http://arxiv.org/abs/2309.12357](http://arxiv.org/abs/2309.12357)

    本研究探索和提供了一种分类方法，可以用于研究新闻学和大众传播中的人工智能（AI）。通过理解每个子领域的操作原理，学者们可以在分析特定研究课题时增强他们关注特定方面的能力。

    

    本研究探讨和建议用于研究新闻学和大众传播的人工智能（AI）的分类方法。我们旨在通过提供具体示例和实际应用，阐明AI的七个不同子领域，包括机器学习、自然语言处理（NLP）、语音识别、专家系统、计划、调度、优化、机器人和计算机视觉。主要目标是设计一个结构化框架，可以帮助新闻领域的AI研究人员。通过理解每个子领域的操作原理，学者们可以在分析特定研究课题时增强他们关注特定方面的能力。

    This study investigates and suggests typologies for examining Artificial Intelligence (AI) within the domains of journalism and mass communication research. We aim to elucidate the seven distinct subfields of AI, which encompass machine learning, natural language processing (NLP), speech recognition, expert systems, planning, scheduling, optimization, robotics, and computer vision, through the provision of concrete examples and practical applications. The primary objective is to devise a structured framework that can help AI researchers in the field of journalism. By comprehending the operational principles of each subfield, scholars can enhance their ability to focus on a specific facet when analyzing a particular research topic.
    
[^75]: AI中介同行评审道德的关键审视

    A Critical Examination of the Ethics of AI-Mediated Peer Review. (arXiv:2309.12356v1 [cs.CY])

    [http://arxiv.org/abs/2309.12356](http://arxiv.org/abs/2309.12356)

    最近人工智能系统对学术同行评审带来了希望和危险。然而，无论是AI还是人类同行评审系统都存在相关问题，例如偏见、滥用和缺乏透明度。因此，AI驱动的同行评审的合法性取决于与科学伦理的一致性。

    

    最近人工智能（AI）系统的进展，包括像ChatGPT这样的大型语言模型，为学术同行评审带来了希望和危险。一方面，AI可以通过解决长时间发表延迟等问题来提高效率。另一方面，它也带来了伦理和社会关注，可能损害同行评审过程和结果的完整性。然而，人类同行评审系统也存在相关问题，如偏见、滥用和缺乏透明度，这已经损害了可信度。尽管越来越多的关注是关于AI在同行评审中的使用，但讨论主要集中在学术期刊出版中的抄袭和署名问题上，忽视了同行评审所处的更广泛的认知、社会、文化和社会认知环境。AI驱动的同行评审的合法性取决于与科学伦理的一致性，包括定义学术协作中适当行为的道德和认识规范。

    Recent advancements in artificial intelligence (AI) systems, including large language models like ChatGPT, offer promise and peril for scholarly peer review. On the one hand, AI can enhance efficiency by addressing issues like long publication delays. On the other hand, it brings ethical and social concerns that could compromise the integrity of the peer review process and outcomes. However, human peer review systems are also fraught with related problems, such as biases, abuses, and a lack of transparency, which already diminish credibility. While there is increasing attention to the use of AI in peer review, discussions revolve mainly around plagiarism and authorship in academic journal publishing, ignoring the broader epistemic, social, cultural, and societal epistemic in which peer review is positioned. The legitimacy of AI-driven peer review hinges on the alignment with the scientific ethos, encompassing moral and epistemic norms that define appropriate conduct in the scholarly co
    
[^76]: 在自动推理中建立信任

    Establishing trust in automated reasoning. (arXiv:2309.12351v1 [cs.CY])

    [http://arxiv.org/abs/2309.12351](http://arxiv.org/abs/2309.12351)

    本研究探讨了自动推理系统的可审查性和可信度问题，并提出了通过技术和社会措施相结合的方式来增加信任的可能步骤。

    

    自从上世纪40年代开始，计算机的自动推理已经成为科学研究中日益重要的工具。迄今为止，自动推理的规则主要由人类以程序源代码的形式制定。通过机器学习技术从大量数据中得出的规则是一种互补的方法，目前正在积极发展中。为什么我们应该信任这些系统以及与其帮助下获得的结果的问题，已经被科学哲学家们讨论过，但从实践者那里收到的关注还很少。本研究重点关注独立审查，这是科学中的一个重要信任来源，并确定影响其可审查性的自动推理系统的特性。它还讨论了通过技术和社会措施相结合来增加可审查性和可信度的可能步骤。

    Since its beginnings in the 1940s, automated reasoning by computers has become a tool of ever growing importance in scientific research. So far, the rules underlying automated reasoning have mainly been formulated by humans, in the form of program source code. Rules derived from large amounts of data, via machine learning techniques, are a complementary approach currently under intense development. The question of why we should trust these systems, and the results obtained with their help, has been discussed by philosophers of science but has so far received little attention by practitioners. The present work focuses on independent reviewing, an important source of trust in science, and identifies the characteristics of automated reasoning systems that affect their reviewability. It also discusses possible steps towards increasing reviewability and trustworthiness via a combination of technical and social measures.
    
[^77]: 对医疗机构在电子病历上使用大型语言模型进行训练的考虑

    Considerations for health care institutions training large language models on electronic health records. (arXiv:2309.12339v1 [cs.CY])

    [http://arxiv.org/abs/2309.12339](http://arxiv.org/abs/2309.12339)

    本研究通过分析数据集大小、模型大小和使用电子病历数据进行大型语言模型（LLM）训练的成本，提供了一个思考医疗机构是否应该训练LLM以及如何在预算限制下选择合适LLM的框架。

    

    大型语言模型（LLM）（如ChatGPT）引起了跨学科科学家的兴趣；在医学领域中，对LLM在电子病历数据上进行训练的潜在应用也引发了关注。然而，如果医疗机构有意让LLM在自己的数据上进行训练，我们首先必须面对一些棘手的问题：他们应该从头开始训练LLM，还是从开源模型进行微调？对于预先确定预算的医疗机构来说，他们可以负担得起的最大LLM是什么？在本研究中，我们通过分析数据集大小、模型大小和使用电子病历数据进行LLM训练的成本来对这些问题进行了初步探讨。这个分析为从数据规模、计算规模和训练预算的角度思考这些问题提供了一个框架。

    Large language models (LLMs) like ChatGPT have excited scientists across fields; in medicine, one source of excitement is the potential applications of LLMs trained on electronic health record (EHR) data. But there are tough questions we must first answer if health care institutions are interested in having LLMs trained on their own data; should they train an LLM from scratch or fine-tune it from an open-source model? For healthcare institutions with a predefined budget, what are the biggest LLMs they can afford? In this study, we take steps towards answering these questions with an analysis on dataset sizes, model sizes, and costs for LLM training using EHR data. This analysis provides a framework for thinking about these questions in terms of data scale, compute scale, and training budgets.
    
[^78]: 人工智能与审美判断

    Artificial Intelligence and Aesthetic Judgment. (arXiv:2309.12338v1 [cs.CY])

    [http://arxiv.org/abs/2309.12338](http://arxiv.org/abs/2309.12338)

    这篇论文讨论了生成型人工智能产生的创造性输出与人类审美判断之间的联系，指出人们对于生成型人工智能产生的反应是经由艺术判断来调节的。同时，论文还提到了对于生成型人工智能的反应可能源于对其未来发展的担忧，并探讨了艺术作品因为其文化条件和人类状况的双重解读难题。

    

    生成型人工智能产生以人类表达风格为基础的创造性输出。我们认为，与现代生成型人工智能模型的产出相遇是通过美学判断来调节的，这种判断方式与我们与艺术品的互动相似。我们在博物馆中对艺术品的解释过程并不是人类固有的能力，而是通过艺术史和艺术批评等学科在历史上发展起来来完成某些社会功能的。这使得我们在考虑对生成型人工智能产生的反应时感到困惑，以及我们应该如何接触这种新媒介以及为什么生成型人工智能似乎引发了对未来的许多恐惧。我们自然地继承了艺术史的因果推断难题：一部作品既可以被解读为受到了影响其创作的文化条件的症状，同时又被构建为一种永恒的、似乎非因果的对永恒人类状况的淬取。在本文中，我们关注当这一困境出现时所带来的未解决的紧张关系。

    Generative AIs produce creative outputs in the style of human expression. We argue that encounters with the outputs of modern generative AI models are mediated by the same kinds of aesthetic judgments that organize our interactions with artwork. The interpretation procedure we use on art we find in museums is not an innate human faculty, but one developed over history by disciplines such as art history and art criticism to fulfill certain social functions. This gives us pause when considering our reactions to generative AI, how we should approach this new medium, and why generative AI seems to incite so much fear about the future. We naturally inherit a conundrum of causal inference from the history of art: a work can be read as a symptom of the cultural conditions that influenced its creation while simultaneously being framed as a timeless, seemingly acausal distillation of an eternal human condition. In this essay, we focus on an unresolved tension when we bring this dilemma to bear 
    
[^79]: ActiveAI：引入基于目标情景学习的人工智能素养教育给初中学习者

    ActiveAI: Introducing AI Literacy for Middle School Learners with Goal-based Scenario Learning. (arXiv:2309.12337v1 [cs.CY])

    [http://arxiv.org/abs/2309.12337](http://arxiv.org/abs/2309.12337)

    ActiveAI项目为初中学生提供了一种基于AI4K12知识框架的人工智能素养学习体验，通过目标情景学习、即时反馈和项目学习等机制帮助学生有效地与人工智能系统互动，并培养他们评估人工智能生成结果的能力。

    

    ActiveAI项目通过提供基于AI4K12知识框架的引人入胜的人工智能素养学习体验，来解决7-9年级学生在人工智能教育中面临的关键挑战。该应用利用目标情景、即时反馈、项目学习和智能代理等学习科学机制，结合滑块、步进器、收集器等多种学习者输入方式，以增强理解能力。在这些课程中，学生们处理社交媒体评论中的情感分析等现实场景，从而帮助他们学会有效地与人工智能系统互动，并培养他们评估人工智能生成结果的能力。该项目采用了学习工程过程（LEP）来指导项目的创建和数据工具化，聚焦设计和影响。目前，该项目正处于实施阶段，利用了智能导师设计原则进行应用开发。扩展摘要介绍了项目的基础设计和开发，并进一步评估了其效果。

    The ActiveAI project addresses key challenges in AI education for grades 7-9 students by providing an engaging AI literacy learning experience based on the AI4K12 knowledge framework. Utilizing learning science mechanisms such as goal-based scenarios, immediate feedback, project-based learning, and intelligent agents, the app incorporates a variety of learner inputs like sliders, steppers, and collectors to enhance understanding. In these courses, students work on real-world scenarios like analyzing sentiment in social media comments. This helps them learn to effectively engage with AI systems and develop their ability to evaluate AI-generated output. The Learning Engineering Process (LEP) guided the project's creation and data instrumentation, focusing on design and impact. The project is currently in the implementation stage, leveraging the intelligent tutor design principles for app development. The extended abstract presents the foundational design and development, with further eva
    
[^80]: 在生成式人工智能时代的教育：背景与最新发展

    Education in the age of Generative AI: Context and Recent Developments. (arXiv:2309.12332v1 [cs.CY])

    [http://arxiv.org/abs/2309.12332](http://arxiv.org/abs/2309.12332)

    本文总结了生成式人工智能在教育领域的发展，并讨论了其潜力、应用、限制、伦理等方面的问题。

    

    随着生成式人工智能的出现，越来越多的个人和组织开始探索其在各个行业提升生产力和改善产品质量的潜力。教育领域也不例外。然而，值得注意的是，人工智能在教育领域的应用可以追溯到20世纪60年代。鉴于这个历史背景，本白皮书作为系列的首篇，阐明了人工智能在教育中的作用。该系列深入探讨了潜力、成功应用、局限性、伦理考虑和未来趋势等主题。该初始文章提供了该领域的全面概述，并突出了生成式人工智能领域的最新发展。

    With the emergence of generative artificial intelligence, an increasing number of individuals and organizations have begun exploring its potential to enhance productivity and improve product quality across various sectors. The field of education is no exception. However, it is vital to notice that artificial intelligence adoption in education dates back to the 1960s. In light of this historical context, this white paper serves as the inaugural piece in a four-part series that elucidates the role of AI in education. The series delves into topics such as its potential, successful applications, limitations, ethical considerations, and future trends. This initial article provides a comprehensive overview of the field, highlighting the recent developments within the generative artificial intelligence sphere.
    
[^81]: 以社会正义视角探索生成人工智能方法

    Approaches to Generative Artificial Intelligence, A Social Justice Perspective. (arXiv:2309.12331v1 [cs.CY])

    [http://arxiv.org/abs/2309.12331](http://arxiv.org/abs/2309.12331)

    本文以社会正义视角探讨生成人工智能方法，研究这些模型的训练、固有的偏见以及检测AI生成写作中的潜在不公正性。

    

    在2023-2024学年，ChatGPT每月1.6亿次访问的广泛普及，将对学术诚信产生影响。高中学生中有77％曾报告参与不诚实行为，由Chan（arXiv:2306.03358v2）称为“AI抄袭”的AI驱动写作辅助的兴起将使抄袭更加容易和不易检测。虽然这些问题迫在眉睫，但它们也引发了对这项技术革命性质的更广泛的问题，包括自主性、数据隐私、版权和公平性。本文旨在从社会正义的角度探讨生成人工智能，考察这些模型的训练、固有的偏见以及检测AI生成写作中的潜在不公正性。

    In the 2023-2024 academic year, the widespread availability of generative artificial intelligence, exemplified by ChatGPT's 1.6 billion monthly visits, is set to impact academic integrity. With 77% of high school students previously reporting engagement in dishonest behaviour, the rise of AI-driven writing assistance, dubbed 'AI-giarism' by Chan (arXiv:2306.03358v2), will make plagiarism more accessible and less detectable. While these concerns are urgent, they also raise broader questions about the revolutionary nature of this technology, including autonomy, data privacy, copyright, and equity. This paper aims to explore generative AI from a social justice perspective, examining the training of these models, the inherent biases, and the potential injustices in detecting AI-generated writing.
    
[^82]: 真实性与挑战：影响训练人工智能的医学数据集创建的因素

    Ground Truth Or Dare: Factors Affecting The Creation Of Medical Datasets For Training AI. (arXiv:2309.12327v1 [cs.CY])

    [http://arxiv.org/abs/2309.12327](http://arxiv.org/abs/2309.12327)

    这项研究探讨了影响医学数据集创建的外部和内部因素，包括法规限制、上下文、商业和运营压力、认识差异以及标记的局限性。

    

    负责任的人工智能开发的核心目标之一是确保高质量的训练数据集。许多研究者指出了注释步骤在创建高质量数据时的重要性，但对于使数据注释成为可能的工作却付出了较少的关注。我们将这个工作定义为真实性架构的设计，并探讨在创建医学领域的数据集之前所涉及的挑战。基于在三个卫生技术组织中的广泛工作，我们描述了影响医学数据集创建过程的五个外部和内部因素。三个外部因素包括法规限制、创建和使用的上下文以及商业和运营压力。这些因素影响医学数据采集，并形成真实性架构的设计。两个内部因素包括认识差异和标记的局限性。这些直接塑造了真实性架构的设计。关于什么构成了真实性架构的讨论。

    One of the core goals of responsible AI development is ensuring high-quality training datasets. Many researchers have pointed to the importance of the annotation step in the creation of high-quality data, but less attention has been paid to the work that enables data annotation. We define this work as the design of ground truth schema and explore the challenges involved in the creation of datasets in the medical domain even before any annotations are made. Based on extensive work in three health-tech organisations, we describe five external and internal factors that condition medical dataset creation processes. Three external factors include regulatory constraints, the context of creation and use, and commercial and operational pressures. These factors condition medical data collection and shape the ground truth schema design. Two internal factors include epistemic differences and limits of labelling. These directly shape the design of the ground truth schema. Discussions of what const
    
[^83]: FUTURE-AI：在医疗保健领域的可信和可部署人工智能的国际共识指南

    FUTURE-AI: International consensus guideline for trustworthy and deployable artificial intelligence in healthcare. (arXiv:2309.12325v1 [cs.CY])

    [http://arxiv.org/abs/2309.12325](http://arxiv.org/abs/2309.12325)

    FUTURE-AI是第一个国际共识框架，为医疗保健领域的可信AI工具开发和部署提供指导原则和最佳实践。

    

    尽管在医学和医疗保健领域人工智能（AI）取得了重大进展，但AI技术在现实临床实践中的部署和采用仍受限。近年来，人们对医疗AI的技术、临床、伦理和法律风险提出了关注。为了增加在现实世界中的采用，医疗AI工具必须得到患者、临床医生、健康组织和当局的信任和接受。本文描述了FUTURE-AI指南作为第一个用于指导医疗保健领域可信AI工具开发和部署的国际共识框架。FUTURE-AI联盟成立于2021年，目前包括来自51个国家的118位跨学科专家，代表了所有大洲，包括AI科学家、临床医生、伦理学家和社会科学家。在为期两年的时间里，联盟通过迭代过程定义了可信AI的指导原则和最佳实践，其中包括

    Despite major advances in artificial intelligence (AI) for medicine and healthcare, the deployment and adoption of AI technologies remain limited in real-world clinical practice. In recent years, concerns have been raised about the technical, clinical, ethical and legal risks associated with medical AI. To increase real world adoption, it is essential that medical AI tools are trusted and accepted by patients, clinicians, health organisations and authorities. This work describes the FUTURE-AI guideline as the first international consensus framework for guiding the development and deployment of trustworthy AI tools in healthcare. The FUTURE-AI consortium was founded in 2021 and currently comprises 118 inter-disciplinary experts from 51 countries representing all continents, including AI scientists, clinicians, ethicists, and social scientists. Over a two-year period, the consortium defined guiding principles and best practices for trustworthy AI through an iterative process comprising a
    
[^84]: 通过法律实现人工智能安全的理论支持

    A Case for AI Safety via Law. (arXiv:2309.12321v1 [cs.CY])

    [http://arxiv.org/abs/2309.12321](http://arxiv.org/abs/2309.12321)

    本文主张通过法律制度来解决人工智能安全问题，认为法律是解决该问题的最佳途径。

    

    如何使人工智能（AI）系统安全并与人类价值观保持一致是一个开放的研究问题。提出的解决方案倾向于依靠人类在不确定情况下的干预，通过训练或观察来学习人类的价值观和意图，提供关闭开关，实施隔离或模拟环境，或推断如果人们有更多知识和时间来思考，他们会想要什么。以法律为基础的方法 - 如以艾萨克·阿西莫夫为灵感 - 并不被广泛看好。本文提出了一个观点，即有效的法律制度是解决人工智能安全问题的最佳途径。法律被定义为对适用于特定代理人在特定领域/情境中的禁止和规定进行编码的任何规则，并包括制定、管理、执行和诉讼此类规则的过程。

    How to make artificial intelligence (AI) systems safe and aligned with human values is an open research question. Proposed solutions tend toward relying on human intervention in uncertain situations, learning human values and intentions through training or observation, providing off-switches, implementing isolation or simulation environments, or extrapolating what people would want if they had more knowledge and more time to think. Law-based approaches--such as inspired by Isaac Asimov--have not been well regarded. This paper makes a case that effective legal systems are the best way to address AI safety. Law is defined as any rules that codify prohibitions and prescriptions applicable to particular agents in specified domains/contexts and includes processes for enacting, managing, enforcing, and litigating such rules.
    
[^85]: 在教育中使用场景和实际例子的人工智能应用

    Use Scenarios & Practical Examples of AI Use in Education. (arXiv:2309.12320v1 [cs.CY])

    [http://arxiv.org/abs/2309.12320](http://arxiv.org/abs/2309.12320)

    本报告提供了一组使用场景和实际例子，旨在帮助教师在教育中引入人工智能，以激发创造力和指导教学。

    

    本报告提出了一组基于现有资源的使用场景，教师可以用作灵感来创建自己的场景，旨在在不同的中小学层次和目标中引入人工智能（AI）。人工智能教育领域（AIEd）非常活跃，不断涌现新的资源和工具。本文档中包含的资源已经经过学生测试，并由该领域的专家选择，但它们必须被视为指导和激发教师创造力的实际例子。

    This report presents a set of use scenarios based on existing resources that teachers can use as inspiration to create their own, with the aim of introducing artificial intelligence (AI) at different pre-university levels, and with different goals. The Artificial Intelligence Education field (AIEd) is very active, with new resources and tools arising continuously. Those included in this document have already been tested with students and selected by experts in the field, but they must be taken just as practical examples to guide and inspire teachers creativity.
    
[^86]: MetaMath：为大型语言模型创建自己的数学问题

    MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models. (arXiv:2309.12284v1 [cs.CL])

    [http://arxiv.org/abs/2309.12284](http://arxiv.org/abs/2309.12284)

    MetaMath是一种专门用于数学推理的微调语言模型，通过从多个角度重新编写问题来生成数学问题，并在两个基准测试中取得了优于其他开源语言模型的表现。

    

    大型语言模型（LLMs）推动了自然语言理解的极限，并展示了出色的问题解决能力。尽管取得了巨大的成功，但大多数现有的开源LLMs（例如LLaMA-2）在解决数学问题方面仍然远远不够令人满意，原因是复杂的推理过程。为了弥合这一鸿沟，我们提出了MetaMath，一种专门用于数学推理的微调语言模型。具体而言，我们通过在没有额外知识的情况下以多个角度重新写入问题来引导数学问题，从而产生了一个名为MetaMathQA的新数据集。然后我们在MetaMathQA上对LLaMA-2模型进行了微调。对于数学推理的两个流行基准测试（即GSM8K和MATH），实验结果表明MetaMath在性能上明显优于一套开源LLMs。我们的MetaMath-7B模型在GSM8K上达到了66.4％，在MATH上达到了19.4％，超过了相同规模的最先进模型。

    Large language models (LLMs) have pushed the limits of natural language understanding and exhibited excellent problem-solving ability. Despite the great success, most existing open-source LLMs (\eg, LLaMA-2) are still far away from satisfactory for solving mathematical problem due to the complex reasoning procedures. To bridge this gap, we propose \emph{MetaMath}, a fine-tuned language model that specializes in mathematical reasoning. Specifically, we start by bootstrapping mathematical questions by rewriting the question from multiple perspectives without extra knowledge, which results in a new dataset called {MetaMathQA}. Then we fine-tune the LLaMA-2 models on MetaMathQA. Experimental results on two popular benchmarks (\ie, GSM8K and MATH) for mathematical reasoning demonstrate that MetaMath outperforms a suite of open-source LLMs by a significant margin. Our MetaMath-7B model achieves $66.4\%$ on GSM8K and $19.4\%$ on MATH, exceeding the state-of-the-art models of the same size by 
    
[^87]: LMSYS-Chat-1M：一个大规模实际语言模型对话数据集

    LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset. (arXiv:2309.11998v1 [cs.CL])

    [http://arxiv.org/abs/2309.11998](http://arxiv.org/abs/2309.11998)

    LMSYS-Chat-1M是一个包含一百万个实际对话的大规模数据集，通过其多样性和用例展示了其在理解和推进LLM能力方面的价值。

    

    随着大规模语言模型（LLM）在各种应用中的广泛使用，研究人们如何在实际场景中与其交互变得越来越重要。在本文中，我们介绍了LMSYS-Chat-1M，这是一个包含一百万个与25个最先进的LLM进行的实际对话的大规模数据集。这个数据集是从我们的Vicuna演示和Chatbot Arena网站上的21万个独立IP地址中收集而来的。我们提供了数据集内容的概述，包括其策划过程、基本统计数据和主题分布，强调其多样性、独特性和规模。我们通过四个用例展示了它的多样性：开发与GPT-4表现相似的内容过滤模型、构建一个安全基准、训练与Vicuna表现相似的指令跟随模型、创建具有挑战性的基准问题。我们相信这个数据集将成为我们理解和推进LLM能力的宝贵资源。

    Studying how people interact with large language models (LLMs) in real-world scenarios is increasingly important due to their widespread use in various applications. In this paper, we introduce LMSYS-Chat-1M, a large-scale dataset containing one million real-world conversations with 25 state-of-the-art LLMs. This dataset is collected from 210K unique IP addresses in the wild on our Vicuna demo and Chatbot Arena website. We offer an overview of the dataset's content, including its curation process, basic statistics, and topic distribution, highlighting its diversity, originality, and scale. We demonstrate its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that perform similarly to Vicuna, and creating challenging benchmark questions. We believe that this dataset will serve as a valuable resource for understanding and advancing LLM capabilities. The dataset is pub
    
[^88]: 表示抽象作为强化学习代理的激励：基于机器人抓取的案例研究

    Representation Abstractions as Incentives for Reinforcement Learning Agents: A Robotic Grasping Case Study. (arXiv:2309.11984v1 [cs.RO])

    [http://arxiv.org/abs/2309.11984](http://arxiv.org/abs/2309.11984)

    本文研究了不同状态表示对强化学习代理在机器人抓取任务上的影响，结果显示使用数字状态的代理能够在模拟环境中成功解决问题，并在真实机器人上实现了学习策略的可转移性。

    

    选择一个适当的环境表示对于强化学习代理的决策过程并不总是简单的。状态表示应该足够包容，以便让代理能够信息地决定其行动，并且足够紧凑，以提高策略训练的样本效率。本文研究了不同状态表示对代理在特定机器人任务（对称和平面物体抓取）上解决问题的影响。从具有完整系统知识的基于模型的方法开始，通过手工数字表示到基于图像的表示，逐渐减少任务特定知识的引入量，定义了一系列状态表示抽象。我们研究了每种表示对代理在仿真环境中解决任务以及学到的策略在真实机器人上的可转移性的影响。结果表明，使用数字状态的强化学习代理能够在模拟环境中解决问题。

    Choosing an appropriate representation of the environment for the underlying decision-making process of the \gls{RL} agent is not always straightforward. The state representation should be inclusive enough to allow the agent to informatively decide on its actions and compact enough to increase sample efficiency for policy training. Given this outlook, this work examines the effect of various state representations in incentivizing the agent to solve a specific robotic task: antipodal and planar object grasping. A continuum of state representation abstractions is defined, starting from a model-based approach with complete system knowledge, through hand-crafted numerical, to image-based representations with decreasing level of induced task-specific knowledge. We examine the effects of each representation in the ability of the agent to solve the task in simulation and the transferability of the learned policy to the real robot. The results show that RL agents using numerical states can per
    
[^89]: 重新思考人工智能系统中自然语言理解的评估框架：以语言习得为未来度量的核心

    Rethinking the Evaluating Framework for Natural Language Understanding in AI Systems: Language Acquisition as a Core for Future Metrics. (arXiv:2309.11981v1 [cs.CL])

    [http://arxiv.org/abs/2309.11981](http://arxiv.org/abs/2309.11981)

    这篇论文重新思考了人工智能系统中自然语言理解的评估框架，提出了以语言习得为核心的全面框架，旨在解决传统度量方法面临的问题，并借鉴了大型语言模型的进展。

    

    在人工智能领域，大型语言模型在自然语言处理方面取得了前所未有的进展，这为重新审视传统的机器智能度量方法提供了机会。本文提出了一个新的评估框架，从传统的图灵测试转向以语言习得为核心的全面框架，并借鉴了最近在大型语言模型方面的进展。本文深受多个学科的卓越工作的影响，指出了保持跨学科桥梁开放的必要性，并勾勒了一个更加稳健和可持续的方法。

    In the burgeoning field of artificial intelligence (AI), the unprecedented progress of large language models (LLMs) in natural language processing (NLP) offers an opportunity to revisit the entire approach of traditional metrics of machine intelligence, both in form and content. As the realm of machine cognitive evaluation has already reached Imitation, the next step is an efficient Language Acquisition and Understanding. Our paper proposes a paradigm shift from the established Turing Test towards an all-embracing framework that hinges on language acquisition, taking inspiration from the recent advancements in LLMs. The present contribution is deeply tributary of the excellent work from various disciplines, point out the need to keep interdisciplinary bridges open, and delineates a more robust and sustainable approach.
    
[^90]: 基于音频对比的微调方法

    Audio Contrastive based Fine-tuning. (arXiv:2309.11895v1 [cs.SD])

    [http://arxiv.org/abs/2309.11895](http://arxiv.org/abs/2309.11895)

    本论文提出了一种基于音频对比的微调方法（AudioConFit），通过借助对比学习的可转移性，该方法在各种音频分类任务中表现出强大的泛化能力，并在不同设置下实现了最先进的结果。

    

    音频分类在语音和声音处理任务中起着至关重要的作用，具有广泛的应用。在将模型拟合到训练数据（避免过拟合）并使其能够良好地泛化到新领域之间仍然存在着平衡的挑战。借助对比学习的可转移性，我们引入了基于音频对比的微调方法（AudioConFit），这种方法具有强大的泛化能力。对各种音频分类任务的实证实验表明了我们方法的有效性和鲁棒性，在不同设置下取得了最先进的结果。

    Audio classification plays a crucial role in speech and sound processing tasks with a wide range of applications. There still remains a challenge of striking the right balance between fitting the model to the training data (avoiding overfitting) and enabling it to generalise well to a new domain. Leveraging the transferability of contrastive learning, we introduce Audio Contrastive-based Fine-tuning (AudioConFit), an efficient approach characterised by robust generalisability. Empirical experiments on a variety of audio classification tasks demonstrate the effectiveness and robustness of our approach, which achieves state-of-the-art results in various settings.
    
[^91]: FluentEditor: 考虑声学和韵律一致性的基于文本的语音编辑

    FluentEditor: Text-based Speech Editing by Considering Acoustic and Prosody Consistency. (arXiv:2309.11725v1 [cs.SD])

    [http://arxiv.org/abs/2309.11725](http://arxiv.org/abs/2309.11725)

    这篇论文提出了一种名为"FluentEditor"的流畅语音编辑模型，通过考虑流畅度意识的训练准则实现文本化语音编辑。其中，声学一致性约束和韵律一致性约束用于保持语音的流畅性和整体风格一致性。

    

    文本化语音编辑（TSE）技术旨在使用户通过修改输入的文本转录而不是音频本身来编辑生成的音频。尽管神经网络基础的TSE技术取得了很大进展，但目前的技术主要关注于减小编辑区域中生成的语音片段与参考目标之间的差异，忽视了其在上下文和原始语句中的局部和整体流畅性。为了保持语音的流畅性，我们提出了一种流畅语音编辑模型，称为“FluentEditor”，通过考虑流畅度意识的训练准则进行TSE训练。具体而言，“声学一致性约束”旨在使编辑区域与其相邻的声学片段之间的过渡变得平滑并与真实情况保持一致，“韵律一致性约束”旨在确保编辑区域内的韵律属性与原始语句的整体风格保持一致。

    Text-based speech editing (TSE) techniques are designed to enable users to edit the output audio by modifying the input text transcript instead of the audio itself. Despite much progress in neural network-based TSE techniques, the current techniques have focused on reducing the difference between the generated speech segment and the reference target in the editing region, ignoring its local and global fluency in the context and original utterance. To maintain the speech fluency, we propose a fluency speech editing model, termed \textit{FluentEditor}, by considering fluency-aware training criterion in the TSE training. Specifically, the \textit{acoustic consistency constraint} aims to smooth the transition between the edited region and its neighboring acoustic segments consistent with the ground truth, while the \textit{prosody consistency constraint} seeks to ensure that the prosody attributes within the edited regions remain consistent with the overall style of the original utterance.
    
[^92]: CFGPT: 具有大型语言模型的中国金融助手

    CFGPT: Chinese Financial Assistant with Large Language Model. (arXiv:2309.10654v1 [cs.CL])

    [http://arxiv.org/abs/2309.10654](http://arxiv.org/abs/2309.10654)

    CFGPT是一个具有大型语言模型的中国金融助手，包括CFData用于预训练和监督微调，以及CFLLM用于处理金融文本，CFAPP用于实际金融应用。这个框架在金融领域的各个方面展现出了巨大的潜力。

    

    大型语言模型（LLM）已经在金融领域的自然语言处理任务中展现出巨大的潜力。在这项工作中，我们提出了一个名为CFGPT的中国金融生成式预训练Transformer框架，该框架包括用于预训练和监督微调的数据集（CFData），用于熟练处理金融文本的金融LLM（CFLLM），以及用于实际金融应用的部署框架（CFAPP）。CFData包括一个预训练数据集和一个监督微调数据集，其中预训练数据集汇集了中国金融数据和分析，以及总共584M个文件和141B个标记的较小的通用文本子集，并且监督微调数据集针对六个不同的金融任务进行了定制，内容涵盖了金融分析和决策的各个方面，包括1.5M个指令对和总计1.5B个标记。CFLLM基于InternLM-7B进行了平衡模型能力的调整。

    Large language models (LLMs) have demonstrated great potential in natural language processing tasks within the financial domain. In this work, we present a Chinese Financial Generative Pre-trained Transformer framework, named CFGPT, which includes a dataset~(CFData) for pre-training and supervised fine-tuning, a financial LLM~(CFLLM) to adeptly manage financial texts, and a deployment framework~(CFAPP) designed to navigate real-world financial applications. The CFData comprising both a pre-training dataset and a supervised fine-tuning dataset, where the pre-training dataset collates Chinese financial data and analytics, alongside a smaller subset of general-purpose text with 584M documents and 141B tokens in total, and the supervised fine-tuning dataset is tailored for six distinct financial tasks, embodying various facets of financial analysis and decision-making with 1.5M instruction pairs and 1.5B tokens in total. The CFLLM, which is based on InternLM-7B to balance the model capabil
    
[^93]: RadOnc-GPT：一种用于放射肿瘤学的大型语言模型

    RadOnc-GPT: A Large Language Model for Radiation Oncology. (arXiv:2309.10160v1 [physics.med-ph])

    [http://arxiv.org/abs/2309.10160](http://arxiv.org/abs/2309.10160)

    RadOnc-GPT是一种专门用于放射肿瘤学的大型语言模型，通过先进的调整方法进行微调，在生成治疗方案、确定疗法和提供诊断描述等关键任务上具有显著改进，展示了利用领域特定知识进行微调的大型语言模型在高度专业化的医疗领域具有的潜力。

    

    本论文介绍了一种名为RadOnc-GPT的大型语言模型，通过先进的调整方法专门用于放射肿瘤学。RadOnc-GPT在Mayo Clinic的大量放射肿瘤学患者记录和临床笔记数据集上进行了微调。该模型通过三个关键任务进行指令调整，包括生成放射治疗方案、确定最佳放射疗法以及基于患者诊断细节提供诊断描述/ICD代码。通过将放射肿瘤学医生比较RadOnc-GPT的印象与通用大型语言模型的印象进行评估，研究表明RadOnc-GPT生成的输出在清晰度、特异度和临床相关性方面显著提高。该研究证明了利用像RadOnc-GPT这样利用领域特定知识进行微调的大型语言模型在放射肿瘤学等高度专业化的医疗领域实现变革能力的潜力。

    This paper presents RadOnc-GPT, a large language model specialized for radiation oncology through advanced tuning methods. RadOnc-GPT was finetuned on a large dataset of radiation oncology patient records and clinical notes from the Mayo Clinic. The model employs instruction tuning on three key tasks generating radiotherapy treatment regimens, determining optimal radiation modalities, and providing diagnostic descriptions/ICD codes based on patient diagnostic details. Evaluations conducted by having radiation oncologists compare RadOnc-GPT impressions to general large language model impressions showed that RadOnc-GPT generated outputs with significantly improved clarity, specificity, and clinical relevance. The study demonstrated the potential of using large language models fine-tuned using domain-specific knowledge like RadOnc-GPT to achieve transformational capabilities in highly specialized healthcare fields such as radiation oncology.
    
[^94]: Talk2Care: 利用大型语言模型促进异步患者-医生通信

    Talk2Care: Facilitating Asynchronous Patient-Provider Communication with Large-Language-Model. (arXiv:2309.09357v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.09357](http://arxiv.org/abs/2309.09357)

    本研究利用大型语言模型（LLMs）来促进患者和医生之间的异步通信，通过访谈研究了解了他们对LLMs的需求，并构建了一个名为Talk2Care的LLM驱动的通信系统。

    

    尽管有大量的远程医疗应用程序来帮助家庭中的老年人和医疗提供者，但基本的消息和电话仍然是最常见的通信方法，这些方法存在有限的可用性、信息丢失和流程效率低下的问题。促进患者-医生通信的一个有希望的解决方案是利用大型语言模型(LLMs)及其强大的自然对话和摘要能力。然而，对于LLMs在通信过程中的作用还存在有限的理解。我们首先进行了两项访谈研究，分别与老年人(N=10)和医疗提供者(N=9)进行了交流，以了解他们在患者-医生异步通信中对LLMs的需求和机会。基于这些见解，我们构建了一个LLM驱动的通信系统Talk2Care，并为两个群体设计了交互组件: (1) 对于老年人，我们利用语音助手的便利性和易于获取性，构建了一个LLM驱动的语音助手

    Despite the plethora of telehealth applications to assist home-based older adults and healthcare providers, basic messaging and phone calls are still the most common communication methods, which suffer from limited availability, information loss, and process inefficiencies. One promising solution to facilitate patient-provider communication is to leverage large language models (LLMs) with their powerful natural conversation and summarization capability. However, there is a limited understanding of LLMs' role during the communication. We first conducted two interview studies with both older adults (N=10) and healthcare providers (N=9) to understand their needs and opportunities for LLMs in patient-provider asynchronous communication. Based on the insights, we built an LLM-powered communication system, Talk2Care, and designed interactive components for both groups: (1) For older adults, we leveraged the convenience and accessibility of voice assistants (VAs) and built an LLM-powered VA i
    
[^95]: ChatGPT v Bard v Bing v Claude 2 v Aria v human-expert. AI聊天机器人在科学写作方面表现如何？（第23季第3季）。（arXiv:2309.08636v1 [cs.CL]）

    ChatGPT v Bard v Bing v Claude 2 v Aria v human-expert. How good are AI chatbots at scientific writing? (ver. 23Q3). (arXiv:2309.08636v1 [cs.CL])

    [http://arxiv.org/abs/2309.08636](http://arxiv.org/abs/2309.08636)

    本文综合分析了在人文学科和考古学领域中六个AI聊天机器人在学术写作方面的能力和局限性，发现它们在重新组合现有知识方面表现出色，但在产生原创科学内容方面存在问题。

    

    在历史上，熟练的写作被认为是人类进步的关键，创造性表达被视为人类成就的标志之一。然而，生成式AI的最新进展标志着这一叙事的一个转折点，包括在科学写作方面。本文全面分析了六个AI聊天机器人在人文学科和考古学方面学术写作中的能力和局限性。方法基于由人类专家对AI生成内容进行定量准确性和定性精确性标记。定量准确性评估了事实的正确性，而定性精确性评估了科学贡献。虽然AI聊天机器人，特别是ChatGPT-4，在重新组合现有知识方面表现出熟练性，但在生成原创科学内容方面失败了。顺便提一下，我们的结果还显示，随着ChatGPT-4，语言模型大小已经停滞不前。此外，本文强调了复杂且反复无常的生成过程。

    Historically, proficient writing was deemed essential for human advancement, with creative expression viewed as one of the hallmarks of human achievement. However, recent advances in generative AI have marked an inflection point in this narrative, including for scientific writing. This article provides a comprehensive analysis of the capabilities and limitations of six AI chatbots in scholarly writing in the humanities and archaeology. The methodology was based on tagging AI generated content for quantitative accuracy and qualitative precision by human experts. Quantitative accuracy assessed the factual correctness, while qualitative precision gauged the scientific contribution. While the AI chatbots, especially ChatGPT-4, demonstrated proficiency in recombining existing knowledge, they failed in generating original scientific content. As a side note, our results also suggest that with ChatGPT-4 the size of the LLMs has plateaued. Furthermore, the paper underscores the intricate and re
    
[^96]: 高效强化学习用于跳跃式单脚机器人

    Efficient Reinforcement Learning for Jumping Monopods. (arXiv:2309.07038v1 [cs.RO])

    [http://arxiv.org/abs/2309.07038](http://arxiv.org/abs/2309.07038)

    本论文研究了如何通过在强化学习框架中注入物理知识来解决跳跃式单脚机器人的控制问题，这样可以大幅减少学习时间并且能够学习和修正可能出现的错误。

    

    在这项工作中，我们考虑了一个复杂的控制问题，即使单脚机器人能够跳到任何方向，其脚下的地形可能是不平的，我们要使它达到目标位置。这是一个更大类别问题的模板，使用标准的基于优化的技术解决这些问题非常具有挑战性和计算开销。强化学习 (RL) 可能是一个有趣的替代方案，但完全从零开始学习的端到端方法是不切实际的。本文提出的解决方案是在 RL 框架中注入物理知识来指导学习过程。这种方法带来了广泛的好处，如大幅减少学习时间，并且能够学习和修正执行运动的低级控制器可能出现的错误。我们通过与基于优化和端到端 RL 方法的比较，证明了我们方法的优势。

    In this work, we consider the complex control problem of making a monopod reach a target with a jump. The monopod can jump in any direction and the terrain underneath its foot can be uneven. This is a template of a much larger class of problems, which are extremely challenging and computationally expensive to solve using standard optimisation-based techniques. Reinforcement Learning (RL) could be an interesting alternative, but the application of an end-to-end approach in which the controller must learn everything from scratch, is impractical. The solution advocated in this paper is to guide the learning process within an RL framework by injecting physical knowledge. This expedient brings to widespread benefits, such as a drastic reduction of the learning time, and the ability to learn and compensate for possible errors in the low-level controller executing the motion. We demonstrate the advantage of our approach with respect to both optimization-based and end-to-end RL approaches.
    
[^97]: 建模推荐系统生态系统：机制设计、强化学习和生成模型的交叉研究挑战

    Modeling Recommender Ecosystems: Research Challenges at the Intersection of Mechanism Design, Reinforcement Learning and Generative Models. (arXiv:2309.06375v1 [cs.AI])

    [http://arxiv.org/abs/2309.06375](http://arxiv.org/abs/2309.06375)

    建模推荐系统生态系统需要考虑参与者激励、行为以及策略引发的相互作用，通过强化学习进行长期优化，使用社会选择方法进行权衡，并减少信息不对称。

    

    现代推荐系统位于涵盖用户、内容提供商、广告商和其他参与者行为的复杂生态系统的核心。尽管如此，大多数推荐系统研究的重点，以及大多数重要实用推荐系统，仅限于个别用户推荐的局部、短视优化。这给推荐系统可能为用户带来的长期效用带来了重大成本。我们认为，如果要最大化系统对这些参与者的价值并提高整体生态系统的“健康”状况，有必要明确地对系统中所有参与者的激励和行为进行建模，并对其策略引发的相互作用进行建模。为此需要：使用强化学习等技术进行长期优化；使用社会选择方法为不同参与者的效用进行不可避免的权衡；减少信息不对称。

    Modern recommender systems lie at the heart of complex ecosystems that couple the behavior of users, content providers, advertisers, and other actors. Despite this, the focus of the majority of recommender research -- and most practical recommenders of any import -- is on the local, myopic optimization of the recommendations made to individual users. This comes at a significant cost to the long-term utility that recommenders could generate for its users. We argue that explicitly modeling the incentives and behaviors of all actors in the system -- and the interactions among them induced by the recommender's policy -- is strictly necessary if one is to maximize the value the system brings to these actors and improve overall ecosystem "health". Doing so requires: optimization over long horizons using techniques such as reinforcement learning; making inevitable tradeoffs in the utility that can be generated for different actors using the methods of social choice; reducing information asymm
    
[^98]: DSLOT-NN: 数字串行从左到右的神经网络加速器

    DSLOT-NN: Digit-Serial Left-to-Right Neural Network Accelerator. (arXiv:2309.06019v1 [cs.AR])

    [http://arxiv.org/abs/2309.06019](http://arxiv.org/abs/2309.06019)

    DSLOT-NN是一种数字串行从左到右的神经网络加速器，可以加速深度神经网络中的卷积运算，并且通过评估和终止无效的卷积操作实现功耗和能量的大规模节省。

    

    我们提出了一种名为DSLOT-NN的基于数字串行从左到右（DSLOT）算术处理技术，旨在加速深度神经网络（DNN）中的卷积运算推理。所提出的方法能够评估和终止无效的卷积操作，从而实现大规模的功耗和能量节省。处理引擎由低延迟的最高有效数字优先（MSDF）（也称为在线）乘法器和加法器组成，从左到右处理数据，允许后续操作以数字流水线方式执行。使用在线运算器消除了复杂的负激活识别机制的开发需求，因为首先生成具有最高权重值的输出，并且一旦生成第一个非零数字，即可识别结果的符号。在线运算器的精度可以在运行时进行调整，使其在可以牺牲精度的情况下极其有用。

    We propose a Digit-Serial Left-tO-righT (DSLOT) arithmetic based processing technique called DSLOT-NN with aim to accelerate inference of the convolution operation in the deep neural networks (DNNs). The proposed work has the ability to assess and terminate the ineffective convolutions which results in massive power and energy savings. The processing engine is comprised of low-latency most-significant-digit-first (MSDF) (also called online) multipliers and adders that processes data from left-to-right, allowing the execution of subsequent operations in digit-pipelined manner. Use of online operators eliminates the need for the development of complex mechanism of identifying the negative activation, as the output with highest weight value is generated first, and the sign of the result can be identified as soon as first non-zero digit is generated. The precision of the online operators can be tuned at run-time, making them extremely useful in situations where accuracy can be compromised 
    
[^99]: 大型语言模型中的命名实体上下文偏倚研究

    Contextual Biasing of Named-Entities with Large Language Models. (arXiv:2309.00723v1 [cs.CL])

    [http://arxiv.org/abs/2309.00723](http://arxiv.org/abs/2309.00723)

    本文研究了使用大型语言模型进行上下文偏倚的方法，通过在第二次打分时提供额外的上下文信息，以提高自动语音识别性能。我们利用提示信息对大型语言模型进行boosting，并采用多任务训练以预测实体类别和下一个标记。此外，我们提出了动态提示方法来提高效率。

    

    本文研究了在大型语言模型(LLMs)中进行上下文偏倚，即在第二次打分时为LLM提供额外的上下文信息，以提高自动语音识别(ASR)性能。我们提出了在打分期间利用提示信息对LLM进行boosting，而无需进行微调，这些提示信息包括偏倚列表和少样本示例，用于在计算假设得分时作为附加信息。除了少样本提示学习外，我们还提出了LLM的多任务训练，以预测实体类别和下一个标记。为了提高上下文偏倚的效率并避免超过LLMs的最大序列长度，我们提出了动态提示，即使用类别标签预测选择最可能的类别，并仅使用这个类别中的实体作为下一个标记预测的上下文。对内部的呼叫、消息和口述数据集以及SLUE-Voxpopuli数据集进行了词错误率(WER)评估。

    This paper studies contextual biasing with Large Language Models (LLMs), where during second-pass rescoring additional contextual information is provided to a LLM to boost Automatic Speech Recognition (ASR) performance. We propose to leverage prompts for a LLM without fine tuning during rescoring which incorporate a biasing list and few-shot examples to serve as additional information when calculating the score for the hypothesis. In addition to few-shot prompt learning, we propose multi-task training of the LLM to predict both the entity class and the next token. To improve the efficiency for contextual biasing and to avoid exceeding LLMs' maximum sequence lengths, we propose dynamic prompting, where we select the most likely class using the class tag prediction, and only use entities in this class as contexts for next token prediction. Word Error Rate (WER) evaluation is performed on i) an internal calling, messaging, and dictation dataset, and ii) the SLUE-Voxpopuli dataset. Results
    
[^100]: 基于神经预测的零样本NAS范式的有效性

    Efficacy of Neural Prediction-Based NAS for Zero-Shot NAS Paradigm. (arXiv:2308.16775v1 [cs.LG])

    [http://arxiv.org/abs/2308.16775](http://arxiv.org/abs/2308.16775)

    这项研究提出了一种新的方法，通过深度学习进行零样本架构搜索，通过使用可学习的傅里叶正弦和求和编码来构建计算的前馈图，从而解决了基于预测的神经架构搜索中性能指标泛化的限制。

    

    在基于预测的神经架构搜索（NAS）中，通过图卷积网络得到的性能指标取得了显著的成功。然而，通过one-hot编码将前馈结构表示为组件图的这些指标面临一个限制：无法在不同的搜索空间中评估架构的性能。相反，手工性能指标（零样本NAS）可以在多个搜索空间中泛化，因为它们使用相同的架构和随机初始化。为了解决这个限制，我们提出了一种新的深度学习方法，用于零样本NAS。我们的方法采用傅里叶正弦和求和编码来进行卷积核的编码，从而构建了一个计算的前馈图，其结构类似于正在评估的架构。这些编码是可学习的，并提供了架构拓扑信息的全面视图。然后，伴随的多层感知器（MLP）对架构进行排序。

    In prediction-based Neural Architecture Search (NAS), performance indicators derived from graph convolutional networks have shown significant success. These indicators, achieved by representing feed-forward structures as component graphs through one-hot encoding, face a limitation: their inability to evaluate architecture performance across varying search spaces. In contrast, handcrafted performance indicators (zero-shot NAS), which use the same architecture with random initialization, can generalize across multiple search spaces. Addressing this limitation, we propose a novel approach for zero-shot NAS using deep learning. Our method employs Fourier sum of sines encoding for convolutional kernels, enabling the construction of a computational feed-forward graph with a structure similar to the architecture under evaluation. These encodings are learnable and offer a comprehensive view of the architecture's topological information. An accompanying multi-layer perceptron (MLP) then ranks t
    
[^101]: 重新审视多任务学习中的标量化：一个理论的视角

    Revisiting Scalarization in Multi-Task Learning: A Theoretical Perspective. (arXiv:2308.13985v1 [cs.LG])

    [http://arxiv.org/abs/2308.13985](http://arxiv.org/abs/2308.13985)

    本论文重新审视了多任务学习中的标量化方法，并从理论的角度探讨了标量化是否能够充分探索帕累托前沿。结果显示，与最近的研究声称的经验优势相反，标量化本质上无法进行全面探索，特别是对于那些平衡了paren

    

    线性标量化，即通过加权总和来组合所有损失函数，自从多任务学习（MTL）的创立以来一直是文献中的默认选择。近年来，越来越多的人对开发专门的多任务优化器（SMTOs）来处理MTL作为多目标优化问题产生了兴趣。然而，目前还不清楚SMTOs是否比标量化有根本上的优势。实际上，社区中存在对比这两种算法的激烈讨论，主要是从经验角度出发。为了回答上述问题，本文从理论的角度重新审视了标量化。我们专注于线性MTL模型，并研究标量化是否能够充分探索帕累托前沿。我们的研究发现，与那些声称标量化具有经验优势的最近工作相反，标量化本质上无法进行全面探索，特别是对于那些平衡了paren

    Linear scalarization, i.e., combining all loss functions by a weighted sum, has been the default choice in the literature of multi-task learning (MTL) since its inception. In recent years, there is a surge of interest in developing Specialized Multi-Task Optimizers (SMTOs) that treat MTL as a multi-objective optimization problem. However, it remains open whether there is a fundamental advantage of SMTOs over scalarization. In fact, heated debates exist in the community comparing these two types of algorithms, mostly from an empirical perspective. To approach the above question, in this paper, we revisit scalarization from a theoretical perspective. We focus on linear MTL models and study whether scalarization is capable of fully exploring the Pareto front. Our findings reveal that, in contrast to recent works that claimed empirical advantages of scalarization, scalarization is inherently incapable of full exploration, especially for those Pareto optimal solutions that strike the balanc
    
[^102]: 预门控MoE：快速且可扩展混合专家推理的算法和系统共同设计

    Pre-gated MoE: An Algorithm-System Co-Design for Fast and Scalable Mixture-of-Expert Inference. (arXiv:2308.12066v1 [cs.LG])

    [http://arxiv.org/abs/2308.12066](http://arxiv.org/abs/2308.12066)

    预门控MoE系统通过算法和系统的共同设计，有效解决了传统MoE架构的计算和存储挑战。

    

    在最近几年中，基于transformers的大型语言模型（LLMs）取得了重大进展，其成功源于模型规模的扩大。尽管算法性能很高，但LLMs的计算和存储需求带来了前所未有的挑战。为了解决LLMs的高计算需求，引入了混合专家（MoE）架构，能够在不成比例地扩大计算需求的情况下扩展模型大小。然而，MoE的高存储需求和稀疏专家的动态激活限制了其在实际问题中的适用性。之前的解决方案将MoE的内存占用高的专家参数转移到CPU内存上，但是从CPU迁移已激活的专家到GPU的延迟导致了高性能开销。我们提出的预门控MoE系统通过算法和系统的共同设计，有效解决了传统MoE架构的计算和存储挑战。

    Large language models (LLMs) based on transformers have made significant strides in recent years, the success of which is driven by scaling up their model size. Despite their high algorithmic performance, the computational and memory requirements of LLMs present unprecedented challenges. To tackle the high compute requirements of LLMs, the Mixture-of-Experts (MoE) architecture was introduced which is able to scale its model size without proportionally scaling up its computational requirements. Unfortunately, MoE's high memory demands and dynamic activation of sparse experts restrict its applicability to real-world problems. Previous solutions that offload MoE's memory-hungry expert parameters to CPU memory fall short because the latency to migrate activated experts from CPU to GPU incurs high performance overhead. Our proposed Pre-gated MoE system effectively tackles the compute and memory challenges of conventional MoE architectures using our algorithm-system co-design. Pre-gated MoE 
    
[^103]: 利用视觉-语言模型在医学图像分割中探索迁移学习

    Exploring Transfer Learning in Medical Image Segmentation using Vision-Language Models. (arXiv:2308.07706v1 [cs.CV])

    [http://arxiv.org/abs/2308.07706](http://arxiv.org/abs/2308.07706)

    本论文提出使用视觉-语言模型进行医学图像分割的迁移学习，并评估了其在医学领域的可迁移性。通过捕捉语义信息和引入新的图像描述变化，实现了对多样化医学图像的分割。

    

    医学图像分割在医学领域的各种临床应用中至关重要。尽管最先进的分割模型已被证明有效，但在这个任务中整合文本指导以增强视觉特征仍然是一个进展有限的领域。现有利用文本指导的分割模型主要在开放领域图像上训练，这引发了在医学领域直接应用的难题，需要手动介入或进行微调。为了解决这些挑战，我们提出使用多模态的视觉-语言模型从图像描述和图像中捕捉语义信息，使得能够对多样化的医学图像进行分割。该研究全面评估了现有的视觉-语言模型在多个数据集上的可迁移性，以评估其从开放领域向医学领域的迁移能力。此外，我们对数据集中以前未见图像的图像描述引入了变化，揭示了显著的变异。

    Medical Image Segmentation is crucial in various clinical applications within the medical domain. While state-of-the-art segmentation models have proven effective, integrating textual guidance to enhance visual features for this task remains an area with limited progress. Existing segmentation models that utilize textual guidance are primarily trained on open-domain images, raising concerns about their direct applicability in the medical domain without manual intervention or fine-tuning.  To address these challenges, we propose using multimodal vision-language models for capturing semantic information from image descriptions and images, enabling the segmentation of diverse medical images. This study comprehensively evaluates existing vision language models across multiple datasets to assess their transferability from the open domain to the medical field. Furthermore, we introduce variations of image descriptions for previously unseen images in the dataset, revealing notable variations 
    
[^104]: AIs的发展脱靴法

    Developmental Bootstrapping of AIs. (arXiv:2308.04586v1 [cs.AI])

    [http://arxiv.org/abs/2308.04586](http://arxiv.org/abs/2308.04586)

    传统的符号AI方法和深度学习AI方法无法满足创建强大和可信赖的AI的挑战，然而，发展脱靴法通过模仿人类儿童的能力发展过程，为创建稳健可靠的AI提供了希望。

    

    尽管当前一些AI在封闭的世界，如棋盘游戏中超越了人类能力，但它们在混乱的现实世界中的表现有限。它们会犯奇怪的错误而且没有意识到。它们很难受到指导，不能运用常识，缺乏好奇心。它们不能成为良好的合作者。传统手动构建的符号AI方法构建的系统和使用生成和深度学习AI方法(包括大规模语言模型)构建的系统都无法应对这些挑战。它们不适合创建强大和可信赖的AI。尽管此方法不属于主流的AI方法，但发展脱靴法显示出希望。在发展脱靴法中，AI像人类儿童一样发展能力。它们从先天能力开始。像人类一样，它们与环境互动，并从互动中学习。它们通过自我发展的能力逐步扩展先天能力。它们互动并逐渐将所学应用于实际操作。

    Although some current AIs surpass human abilities especially in closed worlds such as board games, their performance in the messy real world is limited. They make strange mistakes and do not notice them. They cannot be instructed easily, fail to use common sense, and lack curiosity. They do not make good collaborators. Neither systems built using the traditional manually-constructed symbolic AI approach nor systems built using generative and deep learning AI approaches including large language models (LLMs) can meet the challenges. They are not well suited for creating robust and trustworthy AIs. Although it is outside of mainstream AI approaches, developmental bootstrapping shows promise. In developmental bootstrapping, AIs develop competences like human children do. They start with innate competences. Like humans, they interact with the environment and learn from their interactions. They incrementally extend their innate competences with self-developed competences. They interact and 
    
[^105]: MiVOLO: 多输入变换器用于年龄和性别估计

    MiVOLO: Multi-input Transformer for Age and Gender Estimation. (arXiv:2307.04616v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2307.04616](http://arxiv.org/abs/2307.04616)

    本论文提出了一种简单的方法MiVOLO，使用最新的视觉变换器进行年龄和性别估计。该方法将面部信息和人物图像数据集成到一个统一的模型中，提高了模型的泛化能力，并在图像中人脸不可见的情况下仍能提供令人满意的结果。实验证明了该方法在四个基准测试上达到了最先进的性能，并具有实时处理能力。

    

    在自然环境中进行年龄和性别识别是一项极具挑战性的任务：除了条件的可变性、姿势的复杂性和图像质量的变化之外，还存在人脸部分或完全遮挡的情况。我们提出了MiVOLO（多输入VOLO），这是一种使用最新的视觉变换器进行年龄和性别估计的简单方法。我们的方法将两个任务集成到一个统一的双输入/输出模型中，不仅利用了面部信息，还利用了人物图像数据。这提高了我们模型的泛化能力，使其即使在图像中人脸不可见的情况下也能提供令人满意的结果。为了评估我们提出的模型，我们在四个流行的基准测试上进行了实验，并取得了最先进的性能，同时展示了实时处理能力。此外，我们还引入了一个基于Open Images数据集的新基准测试。这个基准测试的真实注释由认真生成。

    Age and gender recognition in the wild is a highly challenging task: apart from the variability of conditions, pose complexities, and varying image quality, there are cases where the face is partially or completely occluded. We present MiVOLO (Multi Input VOLO), a straightforward approach for age and gender estimation using the latest vision transformer. Our method integrates both tasks into a unified dual input/output model, leveraging not only facial information but also person image data. This improves the generalization ability of our model and enables it to deliver satisfactory results even when the face is not visible in the image. To evaluate our proposed model, we conduct experiments on four popular benchmarks and achieve state-of-the-art performance, while demonstrating real-time processing capabilities. Additionally, we introduce a novel benchmark based on images from the Open Images Dataset. The ground truth annotations for this benchmark have been meticulously generated by 
    
[^106]: 在大型语言模型时代的被遗忘权：涵义、挑战和解决方案

    Right to be Forgotten in the Era of Large Language Models: Implications, Challenges, and Solutions. (arXiv:2307.03941v1 [cs.CY])

    [http://arxiv.org/abs/2307.03941](http://arxiv.org/abs/2307.03941)

    本文探讨了在大型语言模型时代的被遗忘权（RTBF）面临的挑战，提供了实施技术解决方案的见解。

    

    被遗忘权（RTBF）最初是由谷歌西班牙与埃克斯内塔索委员会(Mario Costeja Gonz\'alez)之间的官司结果而确立的，并且后来被作为欧洲联盟一般数据保护条例（GDPR）下的删除权。RTBF允许个人向组织请求删除个人数据，特别是对于搜索引擎，个人可以向组织发送请求，排除他们的信息在查询结果中出现。然而，随着大型语言模型（LLMs）的发展和其在聊天机器人中的应用，LLM启用的软件系统变得越来越受欢迎。但它们并没有被排除在RTBF之外。相比搜索引擎使用的索引方法，LLMs以一种完全不同的方式存储和处理信息，这为符合RTBF提出了新的挑战。在本文中，我们探讨了这些挑战，并提供了关于如何实施技术解决方案以符合RTBF的见解。

    The Right to be Forgotten (RTBF) was first established as the result of the ruling of Google Spain SL, Google Inc. v AEPD, Mario Costeja Gonz\'alez, and was later included as the Right to Erasure under the General Data Protection Regulation (GDPR) of European Union to allow individuals the right to request personal data be deleted by organizations. Specifically for search engines, individuals can send requests to organizations to exclude their information from the query results. With the recent development of Large Language Models (LLMs) and their use in chatbots, LLM-enabled software systems have become popular. But they are not excluded from the RTBF. Compared with the indexing approach used by search engines, LLMs store, and process information in a completely different way. This poses new challenges for compliance with the RTBF. In this paper, we explore these challenges and provide our insights on how to implement technical solutions for the RTBF, including the use of machine unle
    
[^107]: 弹性决策变压器

    Elastic Decision Transformer. (arXiv:2307.02484v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.02484](http://arxiv.org/abs/2307.02484)

    弹性决策变压器（EDT）通过在测试时间进行动作推断时调整历史长度来实现轨迹拼接，填补了决策变压器（DT）在这一方面的性能差距，并且在多任务情况下胜过基于Q-Learning的方法。

    

    本文介绍了弹性决策变压器（EDT），它是现有决策变压器（DT）及其变体的重大进展。尽管DT声称能够生成最佳轨迹，但实证证据表明它在轨迹拼接方面存在困难，轨迹拼接是指从一组次优轨迹中生成最优或接近最优轨迹的过程。提出的EDT通过在测试时间进行动作推断时调整DT中维护的历史长度来实现轨迹拼接，从而使自己与众不同。此外，当前轨迹是最优的时候，EDT通过保持较长的历史，当当前轨迹是次优的时候，EDT通过保持较短的历史来优化轨迹，使其能够与更优的轨迹进行“拼接”。广泛的实验表明，EDT能够填补基于DT和基于Q-Learning方法之间的性能差距。特别是，EDT在多任务情况下胜过基于Q-Learning的方法。

    This paper introduces Elastic Decision Transformer (EDT), a significant advancement over the existing Decision Transformer (DT) and its variants. Although DT purports to generate an optimal trajectory, empirical evidence suggests it struggles with trajectory stitching, a process involving the generation of an optimal or near-optimal trajectory from the best parts of a set of sub-optimal trajectories. The proposed EDT differentiates itself by facilitating trajectory stitching during action inference at test time, achieved by adjusting the history length maintained in DT. Further, the EDT optimizes the trajectory by retaining a longer history when the previous trajectory is optimal and a shorter one when it is sub-optimal, enabling it to "stitch" with a more optimal trajectory. Extensive experimentation demonstrates EDT's ability to bridge the performance gap between DT-based and Q Learning-based approaches. In particular, the EDT outperforms Q Learning-based methods in a multi-task regi
    
[^108]: 超越已知现实：利用反事实解释进行医学研究 (arXiv：2307.02131v2 [cs.AI] 已更新)

    Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research. (arXiv:2307.02131v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2307.02131](http://arxiv.org/abs/2307.02131)

    本研究利用反事实解释来探索医学研究中的“假如”场景，通过提供个性化和情境特定的见解，拓展了我们对现有边界的理解，并填补了机器学习算法结果解释的缺失。

    

    本研究利用反事实解释来探索医学研究中的“假如”场景，旨在拓展我们对现有边界的理解。具体而言，我们重点研究利用磁共振成像特征来诊断儿科后颅窝脑肿瘤。人工智能和可解释性领域已经见证了越来越多的研究和学术兴趣。然而，机器学习算法结果的人类友好解释的缺乏显著阻碍了这些方法在临床实践中的接受度。为了解决这个问题，我们的方法融入了反事实解释，为检查替代决策场景提供了一种新的方式。这些解释提供了个性化和情境特定的见解，使得我们可以验证预测并澄清不同情况下的差异。重要的是，我们的方法同时保持了统计学的可解释性和人类可理解性。

    This study employs counterfactual explanations to explore "what if?" scenarios in medical research, with the aim of expanding our understanding beyond existing boundaries. Specifically, we focus on utilizing MRI features for diagnosing pediatric posterior fossa brain tumors as a case study. The field of artificial intelligence and explainability has witnessed a growing number of studies and increasing scholarly interest. However, the lack of human-friendly interpretations in explaining the outcomes of machine learning algorithms has significantly hindered the acceptance of these methods by clinicians in their clinical practice. To address this, our approach incorporates counterfactual explanations, providing a novel way to examine alternative decision-making scenarios. These explanations offer personalized and context-specific insights, enabling the validation of predictions and clarification of variations under diverse circumstances. Importantly, our approach maintains both statistica
    
[^109]: 缓解偏见：通过改进模型解释来提升图像分类

    Mitigating Bias: Enhancing Image Classification by Improving Model Explanations. (arXiv:2307.01473v1 [cs.CV])

    [http://arxiv.org/abs/2307.01473](http://arxiv.org/abs/2307.01473)

    本文提出了一种通过改进模型解释的方法来缓解图像分类中的偏见问题，通过引导模型的注意力向前景集中，从而提升对主要概念的学习效果。

    

    深度学习模型在从训练数据中学习复杂模式和概念方面展示出了显著的能力。然而，最近的研究发现这些模型倾向于过分依赖于图片背景中的简单和容易识别的特征，而不是它们本应分类的主要概念或对象。这种现象给图像分类器带来了挑战，因为图片中的关键元素可能会被掩盖。在本文中，我们提出了一种新的方法来解决这个问题并改善图像分类器对主要概念的学习。我们的核心思想是在分类任务过程中同时引导模型的注意力向前景集中。通过强调前景，即主要感兴趣的对象，我们旨在将模型的注意力从背景的主导影响上转移开来。为了实现这一点，我们引入了一种机制来鼓励模型足够地分配注意力给前景。

    Deep learning models have demonstrated remarkable capabilities in learning complex patterns and concepts from training data. However, recent findings indicate that these models tend to rely heavily on simple and easily discernible features present in the background of images rather than the main concepts or objects they are intended to classify. This phenomenon poses a challenge to image classifiers as the crucial elements of interest in images may be overshadowed. In this paper, we propose a novel approach to address this issue and improve the learning of main concepts by image classifiers. Our central idea revolves around concurrently guiding the model's attention toward the foreground during the classification task. By emphasizing the foreground, which encapsulates the primary objects of interest, we aim to shift the focus of the model away from the dominant influence of the background. To accomplish this, we introduce a mechanism that encourages the model to allocate sufficient att
    
[^110]: 大型语言模型中的人格特质

    Personality Traits in Large Language Models. (arXiv:2307.00184v1 [cs.CL])

    [http://arxiv.org/abs/2307.00184](http://arxiv.org/abs/2307.00184)

    该研究介绍了一种综合方法，用于验证大型语言模型（LLMs）生成的文本中展示的人格特质。研究发现，部分LLMs在特定提示配置下模拟的人格可靠且有效，特别是对于更大和经过指导微调的模型。此外，LLMs的输出中的人格特质可以根据需要进行塑造。

    

    大型语言模型（LLMs）的出现彻底改变了自然语言处理，使得能够生成连贯且上下文相关的文本。随着LLMs越来越多地用于驱动对话代理，这些模型通过训练大量人工生成的数据获得的人格特质引起了人们的关注。由于人格是决定交流效果的重要因素，我们提出了一种全面的方法来进行验证的心理测量测试，并对从广泛使用的LLMs生成的文本中展示的人格特质进行量化、分析和塑造。我们发现：1）某些LLMs的输出中模拟的人格（在特定的提示配置下）是可靠和有效的；2）LLM模拟的人格的可靠性和有效性的证据对于更大的和经过指导微调的模型更强；3）LLM输出中的人格可以根据需要的维度进行塑造，以模仿特定的人格特点。

    The advent of large language models (LLMs) has revolutionized natural language processing, enabling the generation of coherent and contextually relevant text. As LLMs increasingly power conversational agents, the synthesized personality embedded in these models by virtue of their training on large amounts of human-generated data draws attention. Since personality is an important factor determining the effectiveness of communication, we present a comprehensive method for administering validated psychometric tests and quantifying, analyzing, and shaping personality traits exhibited in text generated from widely-used LLMs. We find that: 1) personality simulated in the outputs of some LLMs (under specific prompting configurations) is reliable and valid; 2) evidence of reliability and validity of LLM-simulated personality is stronger for larger and instruction fine-tuned models; and 3) personality in LLM outputs can be shaped along desired dimensions to mimic specific personality profiles. 
    
[^111]: 自动驾驶决策数据集综述

    A Survey on Datasets for Decision-making of Autonomous Vehicle. (arXiv:2306.16784v1 [cs.RO])

    [http://arxiv.org/abs/2306.16784](http://arxiv.org/abs/2306.16784)

    本综述调查了自动驾驶决策的数据集，比较了车辆、环境和驾驶员相关的数据集，并总结了它们的特点。这有助于研究人员找到适合的数据集来开发数据驱动的自动驾驶决策方法。

    

    自动驾驶车辆（AV）有望重塑未来的交通系统，而决策是实现高级自动驾驶的关键模块之一。为了克服那些基于规则的方法无法很好处理的复杂场景，数据驱动的决策方法引起了越来越多的关注。用于开发数据驱动方法的数据集极大地影响决策性能，因此有必要全面了解现有数据集。从采集来源的角度来看，驾驶数据可以分为车辆、环境和驾驶员相关的数据。本研究比较了这三类最先进的数据集，并总结了它们的特点，包括使用的传感器、注释和驾驶场景。基于数据集的特点，本综述还总结了数据集在AV决策各个方面的潜在应用，帮助研究者找到最适合的数据集。

    Autonomous vehicles (AV) are expected to reshape future transportation systems, and decision-making is one of the critical modules toward high-level automated driving. To overcome those complicated scenarios that rule-based methods could not cope with well, data-driven decision-making approaches have aroused more and more focus. The datasets to be used in developing data-driven methods dramatically influences the performance of decision-making, hence it is necessary to have a comprehensive insight into the existing datasets. From the aspects of collection sources, driving data can be divided into vehicle, environment, and driver related data. This study compares the state-of-the-art datasets of these three categories and summarizes their features including sensors used, annotation, and driving scenarios. Based on the characteristics of the datasets, this survey also concludes the potential applications of datasets on various aspects of AV decision-making, assisting researchers to find 
    
[^112]: 关于中心隐私在密度估计中的成本

    About the Cost of Central Privacy in Density Estimation. (arXiv:2306.14535v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.14535](http://arxiv.org/abs/2306.14535)

    本研究对于利普希茨和 Sobolev 空间中的非参数密度估计，通过考虑中心隐私的影响，发现了直方图估计器在 L2 风险下对于利普希茨分布是最优的，并且在正常差分隐私情况下也是如此；同时发现，在一些情况下，施加隐私会降低对于 Sobolev 密度的正则极小风险估计。此外，本研究还发现在纯投影估计设定下，所谓的投影估计器对于相同类密度几乎是最优的。

    

    我们研究利普希茨和 Sobolev 空间中的非参数密度估计，在中心隐私条件下进行。我们考虑了隐私预算不是常数的情况。我们考虑了经典的中心差分隐私定义，以及较新的中心集中差分隐私概念。我们证实了 Barber & Duchi (2014) 的结果，即直方图估计器在对于 L2 风险下对于利普希茨分布是最优的，并且在正常差分隐私情况下也是如此，我们将其扩展到其他范数和隐私概念。然后，我们研究更高程度的光滑性，得出两个结论：首先，与常数隐私预算需要的情况相反（Wasserman &amp; Zhou, 2010），在 Sobolev 密度上施加隐私会降低正则极小风险估计。其次，在这种新的纯投影估计设定下，所谓的投影估计器对于相同类密度是几乎最优的。

    We study non-parametric density estimation for densities in Lipschitz and Sobolev spaces, and under central privacy. In particular, we investigate regimes where the privacy budget is not supposed to be constant. We consider the classical definition of central differential privacy, but also the more recent notion of central concentrated differential privacy. We recover the result of Barber \& Duchi (2014) stating that histogram estimators are optimal against Lipschitz distributions for the L2 risk, and under regular differential privacy, and we extend it to other norms and notions of privacy. Then, we investigate higher degrees of smoothness, drawing two conclusions: First, and contrary to what happens with constant privacy budget (Wasserman \& Zhou, 2010), there are regimes where imposing privacy degrades the regular minimax risk of estimation on Sobolev densities. Second, so-called projection estimators are near-optimal against the same classes of densities in this new setup with pure
    
[^113]: 虚假黎明：重新评估谷歌强化学习在芯片宏观布局中的应用

    The False Dawn: Reevaluating Google's Reinforcement Learning for Chip Macro Placement. (arXiv:2306.09633v1 [cs.LG])

    [http://arxiv.org/abs/2306.09633](http://arxiv.org/abs/2306.09633)

    谷歌2021年在《自然》杂志上发表的一篇论文声称其使用强化学习在芯片设计领域进行了创新，但两项独立的评估表明，谷歌的方法不如人类设计师、不如一个众所周知的算法（模拟退火），并且也不如普遍可用的商业软件，文章的完整性也遭到了严重的损害。

    

    谷歌2021年在《自然》杂志上发表的有关使用强化学习设计芯片的论文，因为所声称的结果缺乏充分的文件记录和关键步骤的说明，引发争议并受到媒体的批评报道。 而两项独立的评估填补了空白，证明谷歌强化学习落后于人类设计师、落后于一种众所周知的算法（模拟退火），并且还落后于普遍可用的商业软件。交叉检查的数据表明，由于行为、分析和报告中的错误，该《自然》文章的完整性受到了严重的损害。

    Reinforcement learning (RL) for physical design of silicon chips in a Google 2021 Nature paper stirred controversy due to poorly documented claims that raised eyebrows and attracted critical media coverage. The Nature paper withheld most inputs needed to produce reported results and some critical steps in the methodology. But two independent evaluations filled in the gaps and demonstrated that Google RL lags behind human designers, behind a well-known algorithm (Simulated Annealing), and also behind generally-available commercial software. Crosschecked data indicate that the integrity of the Nature paper is substantially undermined owing to errors in the conduct, analysis and reporting.
    
[^114]: AVIS:利用大型语言模型的自主视觉信息检索

    AVIS: Autonomous Visual Information Seeking with Large Language Models. (arXiv:2306.08129v1 [cs.CV])

    [http://arxiv.org/abs/2306.08129](http://arxiv.org/abs/2306.08129)

    本文提出了一个基于大型语言模型的自主信息检索视觉问答框架AVIS，可以解决视觉问题所需的外部知识获取问题。

    

    本文提出了一种利用大型语言模型（LLM）实现自主信息检索的视觉问答框架AVIS。我们的方法利用LLM动态地制定利用外部工具的策略，并调查它们的输出，从而获取提供所提出问题所需的不可或缺的知识。回答需要外部知识的视觉问题，如“这幅图像所描绘的建筑物是为了纪念哪个事件？”，是一项复杂的任务。这个任务呈现出一个组合搜索空间，需要一系列行动，包括调用API、分析它们的响应并做出明智的决策。我们进行了一个用户研究，收集了人类面对这个任务时各种各样的决策实例。然后利用这些数据设计了一个由三个组件组成的系统：一个由LLM驱动的规划器，动态确定下一个要使用的工具；一个由LLM驱动的推理器，分析并提取关键信息。

    In this paper, we propose an autonomous information seeking visual question answering framework, AVIS. Our method leverages a Large Language Model (LLM) to dynamically strategize the utilization of external tools and to investigate their outputs, thereby acquiring the indispensable knowledge needed to provide answers to the posed questions. Responding to visual questions that necessitate external knowledge, such as "What event is commemorated by the building depicted in this image?", is a complex task. This task presents a combinatorial search space that demands a sequence of actions, including invoking APIs, analyzing their responses, and making informed decisions. We conduct a user study to collect a variety of instances of human decision-making when faced with this task. This data is then used to design a system comprised of three components: an LLM-powered planner that dynamically determines which tool to use next, an LLM-powered reasoner that analyzes and extracts key information 
    
[^115]: TopP\&R: 具有鲁棒性的支持估计方法，用于评估生成模型中的保真度和多样性

    TopP\&R: Robust Support Estimation Approach for Evaluating Fidelity and Diversity in Generative Models. (arXiv:2306.08013v1 [cs.LG])

    [http://arxiv.org/abs/2306.08013](http://arxiv.org/abs/2306.08013)

    本文提出了一种鲁棒可靠的生成模型评估指标TopP\&R，通过引入拓扑和统计处理进行严格的支持估计。TopP\&R仅保留具有一定置信水平的具有拓扑和统计上重要性的特征，对于噪声特征具有强大的鲁棒性，并提供了统计一致性。

    

    本文提出了一种鲁棒可靠的生成模型评估指标，通过引入拓扑和统计处理进行严格的支持估计。现有的度量标准，如Inception Score（IS），Fr\'echet Inception Distance（FID）以及Precision and Recall（P\&R）的变体，严重依赖于从样本特征估计的支持。然而，尽管评估的质量完全取决于其可靠性，但其估计的可靠性并没有得到严肃的讨论（并被忽视）。本文提出了拓扑精度和召回率（TopP\&R，发音为“topper”），它提供了一种系统的方法来估计支持，仅保留具有一定置信水平的具有拓扑和统计上重要性的特征。这不仅使TopP\&R对于噪声特征具有强大的鲁棒性，而且还提供了统计一致性。我们的理论和实验结果表明，TopP\&R对于离群值和非独立同分布具有鲁棒性。

    We propose a robust and reliable evaluation metric for generative models by introducing topological and statistical treatments for rigorous support estimation. Existing metrics, such as Inception Score (IS), Fr\'echet Inception Distance (FID), and the variants of Precision and Recall (P\&R), heavily rely on supports that are estimated from sample features. However, the reliability of their estimation has not been seriously discussed (and overlooked) even though the quality of the evaluation entirely depends on it. In this paper, we propose Topological Precision and Recall (TopP\&R, pronounced 'topper'), which provides a systematic approach to estimating supports, retaining only topologically and statistically important features with a certain level of confidence. This not only makes TopP\&R strong for noisy features, but also provides statistical consistency. Our theoretical and experimental results show that TopP\&R is robust to outliers and non-independent and identically distributed
    
[^116]: 基于神经网络的城市时空数据合成方法

    Urban Spatiotemporal Data Synthesis via Neural Disaggregation. (arXiv:2306.07292v1 [cs.LG])

    [http://arxiv.org/abs/2306.07292](http://arxiv.org/abs/2306.07292)

    本研究提出了一种基于神经网络的城市时空数据合成方法，旨在通过分解粗糙的低分辨率地理单元的聚合城市数据来合成细粒度，高分辨率的城市数据，以增加高度聚合的城市数据的可用性和实现价值。

    

    开放数据的细节级别常常与其所能提供的实际效益发生冲突。较不细化的数据可以保护个人隐私，但在一定程度上牺牲了开放数据促进透明度和协助研究的承诺。类似于城市环境中，高层次地理单元的聚合城市数据可能会掩盖城市动态的底层特征，低级别地理单元的变化可能更为明显。本研究旨在通过分解粗糙的低分辨率地理单元的聚合城市数据，合成细粒度，高分辨率的城市数据，以增加高度聚合的城市数据的可用性和实现价值。为了解决一些传统分解方法的简单性问题-1) 我们尝试了许多神经网络模型，这些模型能够建模特征之间复杂的非线性关系。神经方法也可以同时利用空间和时间信息。我们展示了这些神经网络方法的优点。

    The level of granularity of open data often conflicts the benefits it can provide. Less granular data can protect individual privacy, but to certain degrees, sabotage the promise of open data to promote transparency and assist research. Similar in the urban setting, aggregated urban data at high-level geographic units can mask out the underline particularities of city dynamics that may vary at lower areal levels. In this work, we aim to synthesize fine-grained, high resolution urban data, by breaking down aggregated urban data at coarse, low resolution geographic units. The goal is to increase the usability and realize the values as much as possible of highly aggregated urban data. To address the issue of simplicity of some traditional disaggregation methods -- 1) we experimented with numerous neural-based models that are capable of modeling intricate non-linear relationships among features. Neural methods can also leverage both spatial and temporal information concurrently. We showed 
    
[^117]: ShiftAddViT：多种乘法原语混合实现高效的视觉变换器

    ShiftAddViT: Mixture of Multiplication Primitives Towards Efficient Vision Transformer. (arXiv:2306.06446v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.06446](http://arxiv.org/abs/2306.06446)

    ShiftAddViT通过使用位移和加法等多种乘法原语对ViT进行重新参数化，实现了减少乘法操作的高效视觉变换器模型，可以在GPU上实现端到端的推理加速，无需从头训练。

    

    视觉变换器（ViT）展示了令人印象深刻的性能，并成为多个视觉任务的统一骨干。但是，ViTs中的注意力和多层感知器（MLPs）由于密集的乘法而不够高效，导致训练和推理代价高昂。为此，我们提出了一种将预训练的ViT以多种乘法原语（例如位移和加法）重新参数化的方法，以实现全新类型的减少乘法的模型，称为ShiftAddViT，旨在实现GPU上的端到端推理加速，无需从头开始训练。具体而言，我们将查询和键映射为汉明空间中的二进制码之后，采用加法核对查询、键和值之间的MatMul进行重新参数化。剩余的MLPs或线性层则采用位移核进行重新参数化。我们利用TVM在GPU上实施并优化这些定制核，以实现实际硬件部署。我们发现，这种重新参数化方法可以显著提高推理速度，而无需从头开始训练。

    Vision Transformers (ViTs) have shown impressive performance and have become a unified backbone for multiple vision tasks. But both attention and multi-layer perceptions (MLPs) in ViTs are not efficient enough due to dense multiplications, resulting in costly training and inference. To this end, we propose to reparameterize the pre-trained ViT with a mixture of multiplication primitives, e.g., bitwise shifts and additions, towards a new type of multiplication-reduced model, dubbed $\textbf{ShiftAddViT}$, which aims for end-to-end inference speedups on GPUs without the need of training from scratch. Specifically, all $\texttt{MatMuls}$ among queries, keys, and values are reparameterized by additive kernels, after mapping queries and keys to binary codes in Hamming space. The remaining MLPs or linear layers are then reparameterized by shift kernels. We utilize TVM to implement and optimize those customized kernels for practical hardware deployment on GPUs. We find that such a reparameter
    
[^118]: AI艺术策展：重新构想赫尔辛基市艺术双年展

    AI Art Curation: Re-imagining the city of Helsinki in occasion of its Biennial. (arXiv:2306.03753v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.03753](http://arxiv.org/abs/2306.03753)

    本研究通过AI策展和观众互动，利用机器学习模型重新构想了赫尔辛基市艺术双年展，使用视觉-文本模型将室内艺术品放置在公共空间中，生成合成的360艺术全景图，以创造出艺术品与城市空间的新视角。

    

    艺术策展实践的特点是以知识的方式展示艺术收藏品。机器过程的特点是它们能够处理和分析大量数据。本文设想了AI策展和观众互动，以探索当代机器学习模型对策展界的影响。该项目是为2023年赫尔辛基艺术双年展的场合而开发的，题为“可能出现新的方向”。我们使用赫尔辛基艺术博物馆（HAM）的藏品，通过机器感知的视角重新构想了赫尔辛基市。我们使用视觉-文本模型在公共空间中展示室内艺术品，根据相似性评分分配虚构的坐标。我们通过生成合成的360艺术全景图来改变每件艺术品在城市中的所处空间。我们通过估计每件艺术品位置的360全景图的深度值和机器生成的艺术品提示来指导生成过程。这个项目的结果就是...

    Art curatorial practice is characterized by the presentation of an art collection in a knowledgeable way. Machine processes are characterized by their capacity to manage and analyze large amounts of data. This paper envisages AI curation and audience interaction to explore the implications of contemporary machine learning models for the curatorial world. This project was developed for the occasion of the 2023 Helsinki Art Biennial, entitled New Directions May Emerge. We use the Helsinki Art Museum (HAM) collection to re-imagine the city of Helsinki through the lens of machine perception. We use visual-textual models to place indoor artworks in public spaces, assigning fictional coordinates based on similarity scores. We transform the space that each artwork inhabits in the city by generating synthetic 360 art panoramas. We guide the generation estimating depth values from 360 panoramas at each artwork location, and machine-generated prompts of the artworks. The result of this project i
    
[^119]: 推理时间干预：从语言模型中引导出真实的答案

    Inference-Time Intervention: Eliciting Truthful Answers from a Language Model. (arXiv:2306.03341v1 [cs.LG])

    [http://arxiv.org/abs/2306.03341](http://arxiv.org/abs/2306.03341)

    本研究提出推理时间干预（ITI）技术，通过在推理过程中跨越有限数量的注意力头，显着提高大型语言模型的真实性。在TruthfulQA基准上，ITI使LLaMA模型的真实性从32.5%提高到65.1%。ITI是一种最小程度的干扰，计算廉价，且数据效率高。

    

    我们介绍了推理时间干预（ITI）技术，旨在增强大型语言模型（LLMs）的真实性。ITI通过在推理过程中沿着一组方向移动模型激活，跨越有限数量的注意力头。这种干预显着提高了LLaMA模型在TruthfulQA基准上的表现。在指令微调的LLaMA Alpaca上，ITI将其真实性从32.5％提高到65.1％。我们确定了真实性和可用性之间的权衡，并演示了如何通过调整干预强度来平衡它。ITI 取得了最低程度的干扰且计算廉价。此外，该技术在数据效率上表现优异：虽然像RLHF这样的方法需要广泛注释，但是ITI仅使用了几百个例子就能定位真实的方向。我们的研究结果表明，LLMs可能具有某种内部表示方法来表示某事是真实的可能性，即使它们在表面上产生了虚假的结果。

    We introduce Inference-Time Intervention (ITI), a technique designed to enhance the truthfulness of large language models (LLMs). ITI operates by shifting model activations during inference, following a set of directions across a limited number of attention heads. This intervention significantly improves the performance of LLaMA models on the TruthfulQA benchmark. On an instruction-finetuned LLaMA called Alpaca, ITI improves its truthfulness from 32.5% to 65.1%. We identify a tradeoff between truthfulness and helpfulness and demonstrate how to balance it by tuning the intervention strength. ITI is minimally invasive and computationally inexpensive. Moreover, the technique is data efficient: while approaches like RLHF require extensive annotations, ITI locates truthful directions using only few hundred examples. Our findings suggest that LLMs may have an internal representation of the likelihood of something being true, even as they produce falsehoods on the surface.
    
[^120]: 尺度很重要：基于小波域的属性方法解释模型对图像损坏的敏感性

    Scale Matters: Attribution Meets the Wavelet Domain to Explain Model Sensitivity to Image Corruptions. (arXiv:2305.14979v1 [cs.CV])

    [http://arxiv.org/abs/2305.14979](http://arxiv.org/abs/2305.14979)

    该论文介绍了一种基于小波域的属性方法WCAM，能够解释神经网络模型对图像损坏的敏感性，确定预测的足够信息，并阐明缩放如何增加准确性。

    

    神经网络在计算机视觉方面表现出了出色的性能，但它们在实际应用中的部署由于对图像损坏的敏感性而具有挑战性。现有的属性方法对于解释对图像损坏的敏感性是无效的，而强健性领域的文献仅提供基于模型的解释。然而，在图像损坏的情况下，审查模型的行为能力对于提高用户信任至关重要。为此，我们介绍了Wavelet sCale Attribution Method (WCAM)，它是从像素域到空间尺度域的属性方法的概括。在空间尺度域中进行属性揭示了模型的关注点和尺度。我们展示WCAM解释了模型在图像破坏下的失效，确定了预测的足够信息，并解释了如何通过缩放增加准确性。

    Neural networks have shown remarkable performance in computer vision, but their deployment in real-world scenarios is challenging due to their sensitivity to image corruptions. Existing attribution methods are uninformative for explaining the sensitivity to image corruptions, while the literature on robustness only provides model-based explanations. However, the ability to scrutinize models' behavior under image corruptions is crucial to increase the user's trust. Towards this end, we introduce the Wavelet sCale Attribution Method (WCAM), a generalization of attribution from the pixel domain to the space-scale domain. Attribution in the space-scale domain reveals where and on what scales the model focuses. We show that the WCAM explains models' failures under image corruptions, identifies sufficient information for prediction, and explains how zoom-in increases accuracy.
    
[^121]: 如何为推荐基础模型索引项目ID

    How to Index Item IDs for Recommendation Foundation Models. (arXiv:2305.06569v1 [cs.IR])

    [http://arxiv.org/abs/2305.06569](http://arxiv.org/abs/2305.06569)

    本研究对推荐基础模型的项目索引问题进行了系统检查，提出了一种新的上下文感知索引方法，该方法在项目推荐准确性和文本生成质量方面具有优势。

    

    推荐基础模型将推荐任务转换为自然语言任务，利用大型语言模型（LLM）进行推荐。它通过直接生成建议的项目而不是计算传统推荐模型中每个候选项目的排名得分，简化了推荐管道，避免了多段过滤的问题。为了避免在决定要推荐哪些项目时生成过长的文本，为推荐基础模型创建LLM兼容的项目ID是必要的。本研究系统地研究了推荐基础模型的项目索引问题，以P5为代表的主干模型，并使用各种索引方法复制其结果。我们首先讨论了几种微不足道的项目索引方法（如独立索引、标题索引和随机索引）的问题，并表明它们不适用于推荐基础模型，然后提出了一种新的索引方法，称为上下文感知索引。我们表明，这种索引方法在项目推荐准确性和文本生成质量方面优于其他索引方法。

    Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text when deciding which item(s) to recommend, creating LLM-compatible item IDs is essential for recommendation foundation models. In this study, we systematically examine the item indexing problem for recommendation foundation models, using P5 as the representative backbone model and replicating its results with various indexing methods. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as independent indexing, title indexing, and random inde
    
[^122]: N-元事实的少样本链接预测

    Few-shot Link Prediction on N-ary Facts. (arXiv:2305.06104v1 [cs.AI])

    [http://arxiv.org/abs/2305.06104](http://arxiv.org/abs/2305.06104)

    本文提出了一个新任务——少样本N-元事实链接预测，并提出了一个名为FLEN的模型来实现。FLEN由三个模块组成，可以从有限的标记实例中预测N-元事实中的缺失实体。

    

    N-元事实由主要三元组（头实体、关系、尾实体）和任意数量的辅助属性值对组成，这在现实世界的知识图谱中很常见。对于N-元事实的链接预测是预测其中一个元素的缺失，填补缺失元素有助于丰富知识图谱并促进许多下游应用程序。以往的研究通常需要大量高质量的数据来理解N-元事实中的元素，但这些研究忽视了少样本关系，在现实世界的场景中却很常见。因此，本文引入一个新任务——少样本N-元事实链接预测，旨在使用有限的标记实例来预测N-元事实中的缺失实体。我们也提出了一个针对N-元事实的少样本链接预测模型FLEN，它由三个模块组成：关系学习模块、支持特定调整模块和查询推理模块。

    N-ary facts composed of a primary triple (head entity, relation, tail entity) and an arbitrary number of auxiliary attribute-value pairs, are prevalent in real-world knowledge graphs (KGs). Link prediction on n-ary facts is to predict a missing element in an n-ary fact. This helps populate and enrich KGs and further promotes numerous downstream applications. Previous studies usually require a substantial amount of high-quality data to understand the elements in n-ary facts. However, these studies overlook few-shot relations, which have limited labeled instances, yet are common in real-world scenarios. Thus, this paper introduces a new task, few-shot link prediction on n-ary facts. It aims to predict a missing entity in an n-ary fact with limited labeled instances. We further propose a model for Few-shot Link prEdict on N-ary facts, thus called FLEN, which consists of three modules: the relation learning, support-specific adjusting, and query inference modules. FLEN captures relation me
    
[^123]: CryCeleb: 基于婴儿哭声的说话人认证数据集

    CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds. (arXiv:2305.00969v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2305.00969](http://arxiv.org/abs/2305.00969)

    CryCeleb是一个基于婴儿哭声的说话人认证数据集，包括超过6小时的手动分割哭声，可用于研究婴儿哭声分析。

    

    本文描述了Ubenwa CryCeleb数据集——一个标记的婴儿哭声收集，以及附带的CryCeleb 2023任务——一个基于婴儿哭声的公共说话人验证挑战。我们释放出786名新生儿超过6小时的手动分割哭声，以鼓励婴儿哭声分析方面的研究。

    This paper describes the Ubenwa CryCeleb dataset - a labeled collection of infant cries, and the accompanying CryCeleb 2023 task - a public speaker verification challenge based on infant cry sounds. We release for academic usage more than 6 hours of manually segmented cry sounds from 786 newborns to encourage research in infant cry analysis.
    
[^124]: 面向自主越野拉力赛的地形感知运动学模型学习与预测控制法研究

    Learning Terrain-Aware Kinodynamic Model for Autonomous Off-Road Rally Driving With Model Predictive Path Integral Control. (arXiv:2305.00676v1 [cs.RO])

    [http://arxiv.org/abs/2305.00676](http://arxiv.org/abs/2305.00676)

    本研究提出了一种地形感知的运动学模型学习与预测控制法，可以生成可靠的 6 自由度运动预测，并可在无需训练时基于机器学习进行接触力估计，实现了对复杂越野场地的安全与鲁棒自主驾驶控制。

    

    在越野环境下进行高速自主驾驶具有广泛的应用前景，但由于车辆与地形交互的复杂性，也存在一定的挑战。因此，在这种环境下，车辆预测自身运动并根据环境变化，例如地形高差的变化，主动调整其控制至关重要。针对这一问题，我们提出了一种方法来学习地形感知的运动学模型，该模型以本体感知和外部感知信息为条件。该模型可生成可靠的 6 自由度运动预测，并可在无需训练时基于机器学习进行接触力估计。该模型通过适当的代价函数设计可以生成安全且鲁棒的模型预测控制器，惩罚具有不稳定运动、不安全交互和高不确定性衍生的样本轨迹。我们证明了该方法的有效性。

    High-speed autonomous driving in off-road environments has immense potential for various applications, but it also presents challenges due to the complexity of vehicle-terrain interactions. In such environments, it is crucial for the vehicle to predict its motion and adjust its controls proactively in response to environmental changes, such as variations in terrain elevation. To this end, we propose a method for learning terrain-aware kinodynamic model which is conditioned on both proprioceptive and exteroceptive information. The proposed model generates reliable predictions of 6-degree-of-freedom motion and can even estimate contact interactions without requiring ground truth force data during training. This enables the design of a safe and robust model predictive controller through appropriate cost function design which penalizes sampled trajectories with unstable motion, unsafe interactions, and high levels of uncertainty derived from the model. We demonstrate the effectiveness of o
    
[^125]: 可区分的图结构模型用于晶格材料反设计

    Differentiable graph-structured models for inverse design of lattice materials. (arXiv:2304.05422v1 [cond-mat.mtrl-sci])

    [http://arxiv.org/abs/2304.05422](http://arxiv.org/abs/2304.05422)

    本文提出了一种使用图形表示结构和属性的晶格材料的计算方法，使用可微分传递算法计算机械属性以实现反向设计，进而实现了可扩展的、具有前所未有的结构和功能多样性的晶格材料设计。

    

    处于深空恶劣环境中能够根据需要自适应的物理化学性质的材料将在定义未来的空间探索方面变得至关重要。在自然界中，微妙的微观结构和格子几何形状是设计适应于特定环境材料的令人兴奋的灵感来源。然而，由于这种不规则拓扑覆盖的巨大设计空间，在分析上进行探索是具有挑战性的。因此，迄今为止，大多数合成晶格材料都是基于周期性结构。在本文中，我们提出了一种计算方法，使用图形表示对规则和不规则晶格材料进行建模。我们的方法使用可微分传递算法计算力学性质，因此可以使用自动微分来调整单个晶格元素的几何结构和属性，从而设计具有所需属性的材料。引入对晶格结构和材料属性的隐式可学习几何表示，结合反设计框架，实现了可扩展的、具有前所未有的结构和功能多样性的晶格材料设计方法。

    Materials possessing flexible physico-chemical properties that adapt on-demand to the hostile environmental conditions of deep space will become essential in defining the future of space exploration. A promising venue for inspiration towards the design of environment-specific materials is in the intricate micro-architectures and lattice geometry found throughout nature. However, the immense design space covered by such irregular topologies is challenging to probe analytically. For this reason, most synthetic lattice materials have to date been based on periodic architectures instead. Here, we propose a computational approach using a graph representation for both regular and irregular lattice materials. Our method uses differentiable message passing algorithms to calculate mechanical properties, and therefore allows using automatic differentiation to adjust both the geometric structure and attributes of individual lattice elements to design materials with desired properties. The introdu
    
[^126]: 数据集增强：提高模型准确性和鲁棒性

    Reinforce Data, Multiply Impact: Improved Model Accuracy and Robustness with Dataset Reinforcement. (arXiv:2303.08983v1 [cs.CV])

    [http://arxiv.org/abs/2303.08983](http://arxiv.org/abs/2303.08983)

    提出了一种名为数据集增强的策略，一次性改进数据集，从而提高任何经过增强的数据集训练的模型的准确性、鲁棒性和校准性。例如，使用ImageDataNet+训练的ResNet-50在ImageNet验证集上的准确率提高了1.7％，在ImageNetV2上提高了3.5％，在ImageNet-R上提高了10.0％。

    

    我们提出了一种名为数据集增强的策略，一次性改进数据集，从而提高任何经过增强的数据集训练的模型的准确性，对用户没有额外的训练成本。我们提出了一种基于数据增强和知识蒸馏的数据集增强策略。我们的通用策略是基于广泛的CNN和基于transformer的模型的分析，以及对带有各种数据增强的最先进模型进行大规模的蒸馏研究。我们创建了ImageDataNet+的增强版本，以及增强的数据集CIFAR-100+，Flowers-102+和Food-101+。使用ImageDataNet+训练的模型更准确、更有鲁棒性和校准性，并且对下游任务（例如分割和检测）具有很好的迁移能力。例如，ResNet-50在ImageNet验证集上的准确率提高了1.7％，在ImageNetV2上提高了3.5％，在ImageNet-R上提高了10.0％。在ImageDataNet+上测量的Expected Calibration Error（ECE）也有显著改进。

    We propose Dataset Reinforcement, a strategy to improve a dataset once such that the accuracy of any model architecture trained on the reinforced dataset is improved at no additional training cost for users. We propose a Dataset Reinforcement strategy based on data augmentation and knowledge distillation. Our generic strategy is designed based on extensive analysis across CNN- and transformer-based models and performing large-scale study of distillation with state-of-the-art models with various data augmentations. We create a reinforced version of the ImageNet training dataset, called ImageNet+, as well as reinforced datasets CIFAR-100+, Flowers-102+, and Food-101+. Models trained with ImageNet+ are more accurate, robust, and calibrated, and transfer well to downstream tasks (e.g., segmentation and detection). As an example, the accuracy of ResNet-50 improves by 1.7% on the ImageNet validation set, 3.5% on ImageNetV2, and 10.0% on ImageNet-R. Expected Calibration Error (ECE) on the Ima
    
[^127]: 合成经验回放：旨在用扩充数据来提高深度强化学习的效果

    Synthetic Experience Replay. (arXiv:2303.06614v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.06614](http://arxiv.org/abs/2303.06614)

    本文提出了合成经验回放方法解决深度强化学习中数据匮乏问题，通过巧妙应用生成建模技术来扩充数据效果显著。

    

    过去十年的一个关键主题是，当大型神经网络和大型数据集相结合时，它们可以产生令人惊异的结果。在深度强化学习中，这种范式通常通过经验回放实现，其中过去的经验数据集用于训练策略或值函数。然而，与监督学习或自监督学习不同，强化学习代理必须收集自己的数据，这通常是有限的。因此，利用深度学习的好处是具有挑战性的，即使是小型神经网络在训练开始时也可能出现过拟合现象。在这项工作中，我们利用了生成建模的巨大进步，并提出了合成经验回放（SynthER），一种基于扩散的方法来灵活地上采样代理收集的经验。我们证明了SynthER是一种有效的方法，可以在离线和在线设置下训练强化学习代理，无论是在感知环境还是在像素环境中。在离线设置中，我们观察到了显着的改进。

    A key theme in the past decade has been that when large neural networks and large datasets combine they can produce remarkable results. In deep reinforcement learning (RL), this paradigm is commonly made possible through experience replay, whereby a dataset of past experiences is used to train a policy or value function. However, unlike in supervised or self-supervised learning, an RL agent has to collect its own data, which is often limited. Thus, it is challenging to reap the benefits of deep learning, and even small neural networks can overfit at the start of training. In this work, we leverage the tremendous recent progress in generative modeling and propose Synthetic Experience Replay (SynthER), a diffusion-based approach to flexibly upsample an agent's collected experience. We show that SynthER is an effective method for training RL agents across offline and online settings, in both proprioceptive and pixel-based environments. In offline settings, we observe drastic improvements 
    
[^128]: 深度不平衡时间序列预测：基于局部差异密度的方法

    Deep Imbalanced Time-series Forecasting via Local Discrepancy Density. (arXiv:2302.13563v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.13563](http://arxiv.org/abs/2302.13563)

    该论文提出了一种基于局部差异密度的重新加权框架，用于解决时间序列预测中的深度不平衡问题。这个框架通过降低突发变化引起的损失，增加正常状态引起的损失，使模型能够学习可推广的模式。

    

    时间序列预测模型通常会遇到在某个时间段内的突发变化，这些变化通常是由意外事件或未知事件导致的。尽管在训练集中发生的次数很少，但突发变化引起的损失会显著影响总损失。因此，它们作为嘈杂的训练样本阻止了模型学习可推广的模式，即正常状态。基于我们的发现，我们提出了一个重新加权的框架，降低突发变化引起的损失，增加正常状态引起的损失。对于重新加权的框架，我们首先定义了一个称为局部差异度（LD）的度量，用于衡量在给定时间段内变化的突然程度。由于训练集主要由正常状态组成，我们进一步考虑了基于LD在训练集中出现的时间变化的频率。我们的重新加权框架适用于现有的时间序列预测模型，无论其架构如何。

    Time-series forecasting models often encounter abrupt changes in a given period of time which generally occur due to unexpected or unknown events. Despite their scarce occurrences in the training set, abrupt changes incur loss that significantly contributes to the total loss. Therefore, they act as noisy training samples and prevent the model from learning generalizable patterns, namely the normal states. Based on our findings, we propose a reweighting framework that down-weights the losses incurred by abrupt changes and up-weights those by normal states. For the reweighting framework, we first define a measurement termed Local Discrepancy (LD) which measures the degree of abruptness of a change in a given period of time. Since a training set is mostly composed of normal states, we then consider how frequently the temporal changes appear in the training set based on LD. Our reweighting framework is applicable to existing time-series forecasting models regardless of the architectures. T
    
[^129]: 使用特征合成工具对深度神经网络进行红队演练

    Red Teaming Deep Neural Networks with Feature Synthesis Tools. (arXiv:2302.10894v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.10894](http://arxiv.org/abs/2302.10894)

    本文提出了一个用于评估可解释性工具的基准，通过训练模型以对特定触发器产生特定输出的方式，可以解决传统可解释性方法无法分析未知特征行为的问题。

    

    可解释的人工智能工具通常旨在理解模型在超出分布范围（OOD）的情况下的行为。尽管这个研究领域受到了关注，但在这些工具中很少有能够发现模型中的新颖、以前未知的错误的案例。我们认为，这部分原因在于许多可解释性方法的共同特点：它们使用特定的数据集分析和解释模型的行为。虽然这很有用，但这些工具只能分析用户可以事先采样或识别的特征所引发的行为。为了解决这个问题，一个不断增加的研究领域涉及使用不依赖于数据集的特征合成方法来解释模型。本文的主要贡献是提出了一个评估可解释性工具的基准。我们的关键观点是，我们可以训练模型以对特定触发器（例如，插入图像的特定补丁）产生特定输出（即标签），然后评估可解释性工具的有效性。

    Interpretable AI tools are often motivated by the goal of understanding model behavior in out-of-distribution (OOD) contexts. Despite the attention this area of study receives, there are comparatively few cases where these tools have identified novel, previously unknown, bugs in models. We argue that this is due, in part, to a common feature of many interpretability methods: they analyze and explain the behavior of a model using a particular dataset. While this is useful, such tools can only analyze behaviors induced by features that the user can sample or identify in advance. To address this, a growing body of research involves interpreting models using feature synthesis methods which do not depend on a dataset.  In this paper, our primary contribution is a benchmark to evaluate interpretability tools. Our key insight is that we can train models that respond to specific triggers (e.g., a specific patch inserted into an image) with specific outputs (i.e. a label) and then evaluate inte
    
[^130]: 使用Tsallis KL散度的广义Munchausen强化学习

    Generalized Munchausen Reinforcement Learning using Tsallis KL Divergence. (arXiv:2301.11476v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11476](http://arxiv.org/abs/2301.11476)

    这篇论文通过研究广义的Tsallis KL散度，扩展了Munchausen强化学习算法，并提供了一种将KL正则化纳入实际算法的方法。对于Tsallis KL，当$q > 1$时，可以获得新的策略优化选项。

    

    许多强化学习中的策略优化方法都采用Kullback-Leibler（KL）散度到上一个策略，以防止策略变化过快。这个想法最初是在Conservative Policy Iteration的一篇重要论文中提出的，近似算法如TRPO和Munchausen Value Iteration（MVI）给出了有限的方法。我们通过研究一种广义的KL散度 - 称为Tsallis KL散度 - 来继续这一工作，它在定义中使用了$q$-对数。这种方法是一种严格的推广，因为$q = 1$对应于标准的KL散度；$q > 1$提供了一系列新的选项。我们对在Tsallis KL下学习的策略类型进行了表征，并阐述了何时$ q > 1 $可能是有益的。为了获得一个将Tsallis KL正则化纳入实际算法的方法，我们扩展了MVI，它是一种最简单的包含KL正则化的方法之一。我们展示了这种广义MVI（$q$）获得了显著的改进。

    Many policy optimization approaches in reinforcement learning incorporate a Kullback-Leilbler (KL) divergence to the previous policy, to prevent the policy from changing too quickly. This idea was initially proposed in a seminal paper on Conservative Policy Iteration, with approximations given by algorithms like TRPO and Munchausen Value Iteration (MVI). We continue this line of work by investigating a generalized KL divergence -- called the Tsallis KL divergence -- which use the $q$-logarithm in the definition. The approach is a strict generalization, as $q = 1$ corresponds to the standard KL divergence; $q > 1$ provides a range of new options. We characterize the types of policies learned under the Tsallis KL, and motivate when $q >1$ could be beneficial. To obtain a practical algorithm that incorporates Tsallis KL regularization, we extend MVI, which is one of the simplest approaches to incorporate KL regularization. We show that this generalized MVI($q$) obtains significant improve
    
[^131]: A-NeSI: 一种可扩展的近似方法用于概率神经符号推理。

    A-NeSI: A Scalable Approximate Method for Probabilistic Neurosymbolic Inference. (arXiv:2212.12393v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.12393](http://arxiv.org/abs/2212.12393)

    本文介绍了一种名为A-NeSI的新颖PNL框架，它使用神经网络实现了近似推理，能够保证概率逻辑语义的同时解决了PNL的可扩展性问题，能够在安全关键应用中保证逻辑约束的满足。

    

    本文研究了将神经网络与符号推理相结合的问题。最近引入的概率神经符号学习（PNL）框架，如DeepProbLog，执行指数时间的精确推理，限制了PNL解决方案的可扩展性。我们介绍了近似神经符号推理（A-NeSI）：一种新的PNL框架，它使用神经网络进行可扩展的近似推理。A-NeSI 1) 在不改变概率逻辑语义的情况下，以多项式时间执行近似推理；2) 使用由背景知识生成的数据进行训练；3) 可以生成有关预测的符号解释；4) 可以在测试时间保证逻辑约束的满足，这在安全关键应用中非常重要。我们的实验表明，A-NeSI是第一个能够解决具有指数组合扩展的三种神经符号任务的端到端方法。最后，我们的实验表明，A-NeSI实现了可解释性和安全性，而没有惩罚。

    We study the problem of combining neural networks with symbolic reasoning. Recently introduced frameworks for Probabilistic Neurosymbolic Learning (PNL), such as DeepProbLog, perform exponential-time exact inference, limiting the scalability of PNL solutions. We introduce Approximate Neurosymbolic Inference (A-NeSI): a new framework for PNL that uses neural networks for scalable approximate inference. A-NeSI 1) performs approximate inference in polynomial time without changing the semantics of probabilistic logics; 2) is trained using data generated by the background knowledge; 3) can generate symbolic explanations of predictions; and 4) can guarantee the satisfaction of logical constraints at test time, which is vital in safety-critical applications. Our experiments show that A-NeSI is the first end-to-end method to solve three neurosymbolic tasks with exponential combinatorial scaling. Finally, our experiments show that A-NeSI achieves explainability and safety without a penalty in p
    
[^132]: 从西班牙语语言模型评估中得出的教训

    Lessons learned from the evaluation of Spanish Language Models. (arXiv:2212.08390v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.08390](http://arxiv.org/abs/2212.08390)

    该论文对西班牙语语言模型进行了全面比较，发现先前被忽视的大公司的多语言模型优于单语言模型，在西班牙语语言模型的评估领域产生了重大变化。需要进一步研究语料库大小、质量和预训练技术的影响。

    

    鉴于语言模型对自然语言处理领域的影响，已经训练并发布了一些仅有编码器的西班牙语掩码语言模型（即BERT）。这些模型要么是在使用非常大的私有语料库的大型项目中开发的，要么是通过利用免费可用数据的小规模学术工作开发的。本文对西班牙语语言模型进行了全面的比较，得出以下结果：（i）先前被忽视的大公司的多语言模型优于单语言模型，在西班牙语语言模型的评估领域产生了重大变化；（ii）单语言模型的结果并不明确，据说更小且更差的模型也具有竞争力。基于这些实证结果，我们主张需要更多的研究来理解其背后的因素。在这方面，语料库的大小、质量和预训练技术的影响需要进一步研究。

    Given the impact of language models on the field of Natural Language Processing, a number of Spanish encoder-only masked language models (aka BERTs) have been trained and released. These models were developed either within large projects using very large private corpora or by means of smaller scale academic efforts leveraging freely available data. In this paper we present a comprehensive head-to-head comparison of language models for Spanish with the following results: (i) Previously ignored multilingual models from large companies fare better than monolingual models, substantially changing the evaluation landscape of language models in Spanish; (ii) Results across the monolingual models are not conclusive, with supposedly smaller and inferior models performing competitively. Based on these empirical results, we argue for the need of more research to understand the factors underlying them. In this sense, the effect of corpus size, quality and pre-training techniques need to be further
    
[^133]: 用于未知物体实例分割的均值漂移掩模变换器

    Mean Shift Mask Transformer for Unseen Object Instance Segmentation. (arXiv:2211.11679v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.11679](http://arxiv.org/abs/2211.11679)

    本文提出了一种新的均值漂移掩模变换器，用于联合训练和推断特征提取器和聚类器，可用于未知物体实例分割，在COCO数据集上表现出竞争性的性能，并在罕见和未知物体类别上具有显着优势。

    

    物体实例的分割是机器人需要掌握的关键感知技能之一，它有助于机器人抓取和操作未知物体。均值漂移聚类是一种广泛用于图像分割任务的方法。然而，传统的均值漂移聚类算法不可微分，使其难以集成到端到端的神经网络训练框架中。在本文中，我们提出了均值漂移掩模变换器（MSMFormer），这是一种新的变换器体系结构，模拟 von Mises-Fisher（vMF）均值漂移聚类算法，允许联合训练和推断特征提取器和聚类器。其核心组件是超球面注意力机制，可在超球面上更新物体查询。为了说明我们方法的有效性，我们将MSMFormer应用于未知物体实例分割。实验结果表明，MSMFormer在COCO数据集上与现有方法相比取得了竞争性的性能，并且在罕见和未知物体类别上具有显着优势。

    Segmenting unseen objects from images is a critical perception skill that a robot needs to acquire. In robot manipulation, it can facilitate a robot to grasp and manipulate unseen objects. Mean shift clustering is a widely used method for image segmentation tasks. However, the traditional mean shift clustering algorithm is not differentiable, making it difficult to integrate it into an end-to-end neural network training framework. In this work, we propose the Mean Shift Mask Transformer (MSMFormer), a new transformer architecture that simulates the von Mises-Fisher (vMF) mean shift clustering algorithm, allowing for the joint training and inference of both the feature extractor and the clustering. Its central component is a hypersphere attention mechanism, which updates object queries on a hypersphere. To illustrate the effectiveness of our method, we apply MSMFormer to unseen object instance segmentation. Our experiments show that MSMFormer achieves competitive performance compared to
    
[^134]: 可观测完美均衡 (Observable Perfect Equilibrium)

    Observable Perfect Equilibrium. (arXiv:2210.16506v5 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2210.16506](http://arxiv.org/abs/2210.16506)

    本文提出一种新的博弈均衡概念——可观测完美均衡，在顺序不完全信息博弈中可以帮助创建真正的策略代理。这种均衡概念在公开观察的行动概率方面具有鲁棒性。

    

    尽管纳什均衡成为了博弈论的核心解决方案概念，许多重要的博弈包含多个纳什均衡，我们必须确定如何在其中选择，以创建真正的策略代理。为顺序不完全信息博弈提出了几个纳什均衡细化概念，其中最突出的是颤抖手完美均衡、拟完美均衡和最近提出的单侧拟完美均衡。这些概念对某些任意小的错误具有鲁棒性，并保证始终存在。但我们认为，对于发展顺序不完全信息博弈中强大的代理人，这些概念都不正确。我们为游戏树中提出了一种新的均衡概念——可观测完美均衡，在其中，解决方案在公开观察的行动概率方面具有鲁棒性（并不一定针对所有可能不可观察的行动概率具有鲁棒性）。

    While Nash equilibrium has emerged as the central game-theoretic solution concept, many important games contain several Nash equilibria and we must determine how to select between them in order to create real strategic agents. Several Nash equilibrium refinement concepts have been proposed and studied for sequential imperfect-information games, the most prominent being trembling-hand perfect equilibrium, quasi-perfect equilibrium, and recently one-sided quasi-perfect equilibrium. These concepts are robust to certain arbitrarily small mistakes, and are guaranteed to always exist; however, we argue that neither of these is the correct concept for developing strong agents in sequential games of imperfect information. We define a new equilibrium refinement concept for extensive-form games called observable perfect equilibrium in which the solution is robust over trembles in publicly-observable action probabilities (not necessarily over all action probabilities that may not be observable by
    
[^135]: FALCON：基于ALC本体的忠实神经语义蕴涵

    FALCON: Faithful Neural Semantic Entailment over ALC Ontologies. (arXiv:2208.07628v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2208.07628](http://arxiv.org/abs/2208.07628)

    FALCON是一个基于ALC本体的模糊神经推理器，能够通过多个模型结构计算忠实的语义蕴涵，赋予神经网络世界模型和推理能力。在实践中，它实现了近似推理、处理不一致性推理，并通过整合ALC表达的知识改进了生物医学领域的机器学习。

    

    许多本体，即描述逻辑（DL）知识库，已经被开发出来提供关于各种领域的丰富知识，并且其中很多基于ALC，即原型和表达力强的DL，或其扩展。探索ALC本体的主要任务是计算语义蕴涵。我们开发了FALCON，一个模糊的ALC本体神经推理器，它使用模糊逻辑运算符为任意ALC本体生成模型结构，并使用多个模型结构计算忠实的语义蕴涵。理论结果表明，FALCON能够忠实地近似计算ALC本体上的语义蕴涵，从而赋予神经网络世界模型和对其进行推理的能力。实验结果表明，FALCON能够实现近似推理，辅助推理（处理不一致性推理），并通过整合以ALC表达的知识改进生物医学领域的机器学习。

    Many ontologies, i.e., Description Logic (DL) knowledge bases, have been developed to provide rich knowledge about various domains, and a lot of them are based on ALC, i.e., a prototypical and expressive DL, or its extensions. The main task that explores ALC ontologies is to compute semantic entailment. We developed FALCON, a Fuzzy ALC Ontology Neural reasoner, which uses fuzzy logic operators to generate model structures for arbitrary ALC ontologies, and uses multiple model structures to compute faithful semantic entailments. Theoretical results show that FALCON faithfully approximates semantic entailment over ALC ontologies and therefore endows neural networks with world models and the ability to reason over them. Experimental results show that FALCON enables approximate reasoning, paraconsistent reasoning (reasoning with inconsistencies), and improves machine learning in the biomedical domain by incorporating knowledge expressed in ALC.
    
[^136]: 优化包括维护在内的机车编组计划的约束编程与量子退火方法

    Optimising Rolling Stock Planning including Maintenance with Constraint Programming and Quantum Annealing. (arXiv:2109.07212v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2109.07212](http://arxiv.org/abs/2109.07212)

    本文比较了约束编程和量子退火方法在优化机车编组分配与维护任务中的应用，并发现两种方法在当前发展阶段的量子退火机器上产生相当的结果。

    

    我们提出并比较了使用约束编程(CP)和量子退火(QA)方法来优化考虑必要维护任务的机车编组分配。在CP方法中，我们使用AllDifferent约束、Element约束的扩展以及逻辑蕴含等来建模问题。对于QA方法，我们开发了一个二次无约束二进制优化(QUBO)模型。为了评估，我们使用基于德国铁路真实数据的数据集，并在D-Wave的真实量子计算机上运行QA方法。经典计算机用于评估CP方法以及QUBO模型中的禁忌搜索。在当前物理量子退火机器的开发阶段，我们发现两种方法往往产生相当的结果。

    We propose and compare Constraint Programming (CP) and Quantum Annealing (QA) approaches for rolling stock assignment optimisation considering necessary maintenance tasks. In the CP approach, we model the problem with an Alldifferent constraint, extensions of the Element constraint, and logical implications, among others. For the QA approach, we develop a quadratic unconstrained binary optimisation (QUBO) model. For evaluation, we use data sets based on real data from Deutsche Bahn and run the QA approach on real quantum computers from D-Wave. Classical computers are used to evaluate the CP approach as well as tabu search for the QUBO model. At the current development stage of the physical quantum annealers, we find that both approaches tend to produce comparable results.
    

