# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [EGC: Image Generation and Classification via a Single Energy-Based Model.](http://arxiv.org/abs/2304.02012) | EGC是一种使用单个神经网络在图像分类和图像生成任务中实现卓越性能的方法，可以较好地生成出高质量图像，并在多项数据集上实现了领先的分类结果。 |
| [^2] | [Multi-Level Contrastive Learning for Dense Prediction Task.](http://arxiv.org/abs/2304.02010) | 本文提出了一种多层级对比学习的自监督方法，用于学习密集预测任务的区域级特征表示。该方法可通过一个新的预训练任务为神经网络学习区域语义表示，从而实现平移和尺度一致性，并将预训练轮数降至与监督预训练相同。该方法已在多个数据集上证明了其优越性能。 |
| [^3] | [Risk-Aware Distributed Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2304.02005) | 本文提出了一种分布式多智能体强化学习方法，通过学习风险意识动作解决了未知环境下的决策问题。 |
| [^4] | [MEGClass: Text Classification with Extremely Weak Supervision via Mutually-Enhancing Text Granularities.](http://arxiv.org/abs/2304.01969) | MEGClass是一种通过相互增强的文本粒度实现极弱监督文本分类的方法，利用分层关注机制从文档、句子和单词中提取连贯且多样的子文本，能够准确分类讨论多个主题的文档，并且在五个基准数据集上表现优于现有最先进的模型。 |
| [^5] | [Network Visualization of ChatGPT Research: a study based on term and keyword co-occurrence network analysis.](http://arxiv.org/abs/2304.01948) | 本研究基于术语和关键词共现网络分析，识别出ChatGPT的主要研究领域，结果表明ChatGPT和其相关术语是最常出现的关键词。 |
| [^6] | [PODIA-3D: Domain Adaptation of 3D Generative Model Across Large Domain Gap Using Pose-Preserved Text-to-Image Diffusion.](http://arxiv.org/abs/2304.01900) | 文本导向的领域自适应方法在跨越领域差异方面取得了进展，但面向具有显着领域差异的目标领域仍具有挑战性，PODIA-3D提出了一种基于姿态保留的文本图像扩散的方法，以弥补这方面的不足。 |
| [^7] | [InfluencerRank: Discovering Effective Influencers via Graph Convolutional Attentive Recurrent Neural Networks.](http://arxiv.org/abs/2304.01897) | 本文提出了InfluencerRank，通过图卷积神经网络和注意力循环神经网络结合的方法评估影响者的有效性，以帮助企业在社交影响者营销中寻找合适的影响者。 |
| [^8] | [Robustness Benchmark of Road User Trajectory Prediction Models for Automated Driving.](http://arxiv.org/abs/2304.01895) | 本文对四个道路用户轨迹预测模型进行了基准测试，评估了它们在遇到不同扰动时的性能。结果表明，这些模型的性能在各种扰动的存在下显著降低，需要通过数据扩充等策略提高模型的鲁棒性。 |
| [^9] | [Sociocultural knowledge is needed for selection of shots in hate speech detection tasks.](http://arxiv.org/abs/2304.01890) | HATELEXICON是一个包含巴西，德国，印度和肯尼亚仇恨言论的词汇表，利用其可以提高模型在训练中的性能表现。 |
| [^10] | [Deep-BIAS: Detecting Structural Bias using Explainable AI.](http://arxiv.org/abs/2304.01869) | Deep-BIAS是一种可解释的深度学习扩展工具箱，用于检测搜索算法中的结构偏差。通过训练深度学习模型，可以快速检测基于原始性能分布的偏差的强度和类型。该工具箱已被证明在各种具有结构偏差情况的实验中十分有效，并在336种最先进的优化算法中得到了广泛应用。 |
| [^11] | [SportsPose -- A Dynamic 3D sports pose dataset.](http://arxiv.org/abs/2304.01865) | 推出了一个大型的三维人体姿态数据集SportsPose，它包含一个多样和全面的3D姿态集，反映了体育运动的复杂和动态性；并引入了一个新的度量标准，局部运动，它描述了手腕和踝关节的运动。 |
| [^12] | [Grid-SD2E: A General Grid-Feedback in a System for Cognitive Learning.](http://arxiv.org/abs/2304.01844) | 本文提出了一种名为Grid-SD2E的认知学习系统，其建立在网格细胞的基础上，使用空间划分和探索利用方法实现交互和自我强化，有助于理解大脑的工作机制、治疗脑部疾病和理解智能。 |
| [^13] | [BugNIST -- A New Large Scale Volumetric 3D Image Dataset for Classification and Detection.](http://arxiv.org/abs/2304.01838) | 本文介绍了一个名为BugNIST的广泛数据集，该数据集由12种昆虫和幼虫的微-CT扫描组成。通过训练和测试检测模型，BugNIST旨在评估三维体积图像分类和检测方法，解决上下文无关的挑战。 |
| [^14] | [A Survey on Vertical Federated Learning: From a Layered Perspective.](http://arxiv.org/abs/2304.01829) | 垂直联邦学习（VFL）是一种适用于数据垂直分区情况的有前途的联邦学习方法，该方法丰富了样本描述，以提高模型容量。研究人员在硬件层到垂直联邦系统层各个方面做了贡献，VFL的应用已涵盖多个领域，尤其隐私保护是关键问题。 |
| [^15] | [HarsanyiNet: Computing Accurate Shapley Values in a Single Forward Propagation.](http://arxiv.org/abs/2304.01811) | HarsanyiNet 是一种新型的深度神经网络架构，它可以在单次前向传播中计算输入变量的精确 Shapley 值。 |
| [^16] | [Exploration of Lightweight Single Image Denoising with Transformers and Truly Fair Training.](http://arxiv.org/abs/2304.01805) | 本文研究了采用Transformer实现轻量化单图像去噪的问题，提供了七种比较基线Transformer，并探讨了在训练过程中随机剪裁补丁的部分对去噪性能的影响；而以往的研究忽略了这一问题。此外，本文以真正公平的方式训练基线Transformer，并进行了各种组件的实证分析，以确定构建轻量化去噪Transformer的关键考虑因素。 |
| [^17] | [Using Language Models For Knowledge Acquisition in Natural Language Reasoning Problems.](http://arxiv.org/abs/2304.01771) | 本文研究了使用大型语言模型在自然语言推理问题中获取知识的方法，比较了两种方式并得出后一种使用语言模型提取知识更合适的结论。 |
| [^18] | [Incorporating Unlabelled Data into Bayesian Neural Networks.](http://arxiv.org/abs/2304.01762) | 该论文提出了一种利用未标记数据学习贝叶斯神经网络（BNNs）的对比框架，通过该框架提出了一种同时具备自监督学习的标签效率和贝叶斯方法中的不确定性估计的实用BNN算法。最后，该方法在半监督和低预算主动学习问题中展现出了数据高效学习的优势。 |
| [^19] | [Learning Invariant Representation via Contrastive Feature Alignment for Clutter Robust SAR Target Recognition.](http://arxiv.org/abs/2304.01747) | 本文提出了一种名为对比特征对齐(CFA)的解决方案，旨在通过学习不变表示以实现鲁棒识别。本文方法提出了混杂杂波变体生成策略和配备通道加权均方误差(CWMSE)损失的新推断分支。实验结果表明，我们的方法在MSTAR数据集的移动和静止地面车辆基准上实现了最先进的性能。 |
| [^20] | [Towards Open-Vocabulary Video Instance Segmentation.](http://arxiv.org/abs/2304.01715) | 本文提出了新任务--开放词汇视频实例分割，并收集了大规模的LV-VIS数据集，同时提出了高效的MindVLT方法，能够以近实时的速度实现开放集视频实例分割任务，相比现有方法有显著的提升。 |
| [^21] | [Rumour Detection and Analysis on Twitter.](http://arxiv.org/abs/2304.01712) | 本文研究了社交媒体平台上的谣言检测并分析了新冠疫情相关推文的数据。研究使用最先进的自然语言处理模型通过比较语言结构和传播路径等特征来区分谣言和事实，并发现语言结构是更好的区分特征。 |
| [^22] | [HyperCUT: Video Sequence from a Single Blurry Image using Unsupervised Ordering.](http://arxiv.org/abs/2304.01686) | 本文提出了一种新的无监督排序方法来解决单模糊图像到视频序列的重建问题，显式地分配每个序列的顺序，有效提高了去模糊模型的训练质量，并在合成和真实数据集上获得了最好的结果。 |
| [^23] | [Motion-R3: Fast and Accurate Motion Annotation via Representation-based Representativeness Ranking.](http://arxiv.org/abs/2304.01672) | 本文提出了一种快速准确的动作注释方法Motion-R3，该方法基于数据中心哲学，通过学习动作表示空间中的表征性进行排名，可快速应对需求变化并实现敏捷开发。 |
| [^24] | [An Embedding-based Approach to Inconsistency-tolerant Reasoning with Inconsistent Ontologies.](http://arxiv.org/abs/2304.01664) | 本文提出了一种基于嵌入的方法来处理具有不一致性本体的容错推理问题，这种方法通过语义向量计算公理之间的关联，定义了选择最大一致子集的方法，并证明了推理关系的合理性。 |
| [^25] | [Cross-Domain Image Captioning with Discriminative Finetuning.](http://arxiv.org/abs/2304.01662) | 本文通过使用自监督鉴别式沟通目标，微调已有的神经字幕生成器，在保持语言的视觉描述性的同时，提高了对图像内容的信息提取精度。 |
| [^26] | [Multidimensional Perceptron for Efficient and Explainable Long Text Classification.](http://arxiv.org/abs/2304.01638) | 提出了一种名为SWIPE的多维感知器模型，有效地学习整个文本的标签并以无监督的方式感知段落的标签。SWIPE作为一种通用分类器，支持不同的编码器，在分类上优于现有技术。 |
| [^27] | [Spatiotemporal and Semantic Zero-inflated Urban Anomaly Prediction.](http://arxiv.org/abs/2304.01569) | 提出了STS模型来预测城市异常，解决了由于异常数据稀疏零膨胀导致的问题，并且可以统一预测多种异常，在交通事故和犯罪预测数据集上表现良好。 |
| [^28] | [G2PTL: A Pre-trained Model for Delivery Address and its Applications in Logistics System.](http://arxiv.org/abs/2304.01559) | G2PTL是一种面向物流领域的预训练模型，结合了文本预训练的语义学习能力和图建模的地理关系编码能力，能有效地编码交付地址中的位置信息，并在物流系统中具有广泛的应用前景。 |
| [^29] | [Real-time Driver Monitoring Systems on Edge AI Device.](http://arxiv.org/abs/2304.01555) | 本论文介绍了一种运行在边缘AI设备上的实时驾驶员监控系统，该系统经过模型手术，在硬件加速器的帮助下实现了高帧率的处理效果。 |
| [^30] | [\emph{MEnsA}: Mix-up Ensemble Average for Unsupervised Multi Target Domain Adaptation on 3D Point Clouds.](http://arxiv.org/abs/2304.01554) | 本文提出了一种新的MTDA方法，名为\emph{MEnsA}，利用混合集成平均方法提高了域自适应的性能。 |
| [^31] | [Regularization of the policy updates for stabilizing Mean Field Games.](http://arxiv.org/abs/2304.01547) | 本文提出了一种均场近端策略优化算法（MF-PPO），以稳定深度强化学习在均场博弈中的应用，并在OpenSpiel框架中进行了实验验证。 |
| [^32] | [A Brief Review of Explainable Artificial Intelligence in Healthcare.](http://arxiv.org/abs/2304.01543) | 这篇文章系统评估了可解释人工智能在医疗保健领域的各种挑战和方法，旨在提高AI模型的可解释性，使其对临床医生更加透明可信。 |
| [^33] | [Implementing Dynamic Programming in Computability Logic Web.](http://arxiv.org/abs/2304.01539) | CoLweb是一种优秀的算法语言，可以通过高层次、证明携带，分布式风格的方法统一多种算法设计方法，而且在Horn子句定义细化方面有很好的应用。 |
| [^34] | [Multimodal Neural Processes for Uncertainty Estimation.](http://arxiv.org/abs/2304.01518) | 本论文提出了一种新的神经过程模型，即多模态神经过程，用于对多模态数据进行不确定性估计，该模型具有动态上下文记忆、多模态贝叶斯聚合和校准预测的注意机制，经实验表明在多模态不确定性估计方面性能最先进，对于噪声样本具有良好抵抗能力，并且对于领域之外的检测是可靠的。 |
| [^35] | [Handling Concept Drift in Global Time Series Forecasting.](http://arxiv.org/abs/2304.01512) | 本文提出两种新的概念漂移处理方法，应用于全球时间序列预测，填补了处理分类领域中概念漂移方法的空白。 |
| [^36] | [EPVT: Environment-aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition.](http://arxiv.org/abs/2304.01508) | EPVT是一种基于环境感知的提示视觉Transformer，用于解决皮肤病变识别中深度神经网络可能过度依赖疾病不相关图像特征的问题，通过嵌入一组领域提示和一个共享提示来进行领域一般化，并且引入了领域提示生成器促进知识共享。 |
| [^37] | [RARE: Robust Masked Graph Autoencoder.](http://arxiv.org/abs/2304.01507) | RARE是一种鲁棒性抗干扰的掩码图自编码器，通过在高阶潜在特征空间中进行掩码和重构节点样本来提高推断掩码数据的确定性和自监督机制的可靠性，并在下游任务中优于现有的SGP方法。 |
| [^38] | [OneShotSTL: One-Shot Seasonal-Trend Decomposition For Online Time Series Anomaly Detection And Forecasting.](http://arxiv.org/abs/2304.01506) | OneShotSTL提出了一种高效准确的算法，用于在线时间序列分解，在处理时间上仅需O(1)的更新时间复杂度，并可同时保持较高的精度，解决了现有批处理方法无法支持实时分析的挑战。 |
| [^39] | [GPT-4 to GPT-3.5: 'Hold My Scalpel' -- A Look at the Competency of OpenAI's GPT on the Plastic Surgery In-Service Training Exam.](http://arxiv.org/abs/2304.01503) | 本研究评估了 OpenAI 的 GPT 在整形外科住院医师培训考试上的能力，发现相比于 GPT-3.5，GPT-4 有了显著提高。考试得分与成为获得认证的整形外科医生所需的书面考试高度相关。 |
| [^40] | [To ChatGPT, or not to ChatGPT: That is the question!.](http://arxiv.org/abs/2304.01487) | 研究评估了聊天GPT检测中的最新技术和其他AI生成文本检测工具的表现，并提出区分人工生成和AI生成文本的重要性。 |
| [^41] | [DLRover: An Elastic Deep Training Extension with Auto Job Resource Recommendation.](http://arxiv.org/abs/2304.01468) | DLRover是一个自动配置初始资源并实时调整资源的分布式深度学习框架，解决了资源共享和手动配置带来的问题。 |
| [^42] | [Time-space-frequency feature Fusion for 3-channel motor imagery classification.](http://arxiv.org/abs/2304.01461) | 本文提出了一种新网络架构TSFF-Net，将时间-空间-频率特征融合，解决了单模特征提取网络在时间序列或时间-频率模态下的限制。TSFF-Net包括时间-频率表示、时间-频率特征提取、时间-空间特征提取和特征融合与分类四个主要组件。 |
| [^43] | [Exploring Vision-Language Models for Imbalanced Learning.](http://arxiv.org/abs/2304.01457) | 本文探索了如何通过向视觉-语言模型添加轻量级解码器和利用不平衡算法来改进性能，实验表明改进后的VLM在iNaturalist18、CIFAR-100和Visual Genome数据集上分类准确度显著提高，特别是对于少数类，性能提升很大。 |
| [^44] | [Off-Policy Action Anticipation in Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2304.01447) | 本文提出了一个名为OffPA2的新框架，通过离线策略行动预测方法来提高多智能体强化学习中的学习预测效率。 |
| [^45] | [VNE: An Effective Method for Improving Deep Representation by Manipulating Eigenvalue Distribution.](http://arxiv.org/abs/2304.01434) | 本文提出了通过规范化表示的von Neumann熵( VNE ) 来改善深度表示的方法，通过操纵特征值分布来优化表示品质，广泛适用于不同的算法，可以增强其领域通用性、元学习、自监督学习和生成模型等方面。 |
| [^46] | [Reducing Discretization Error in the Frank-Wolfe Method.](http://arxiv.org/abs/2304.01432) | 本论文提出了两个改进方法：一个多步的Frank-Wolfe方法，直接应用优化的高阶离散化方案；以及一种具有较少离散化误差的LMO-平均方案，其收敛速率加速到$O(1/k^{3/2})$，从而更好地解决了Frank-Wolfe方法中的离散化误差问题。 |
| [^47] | [Divided Attention: Unsupervised Multi-Object Discovery with Contextually Separated Slots.](http://arxiv.org/abs/2304.01430) | 该论文提出了一种新的无监督多对象发现方法，通过一种上下文分隔的槽结构来将视觉场分割为独立运动区域，并用对抗性标准来保证解码器无法重构整个光流。 |
| [^48] | [Learned Tree Search for Long-Horizon Social Robot Navigation in Shared Airspace.](http://arxiv.org/abs/2304.01428) | 本文提出了一种基于学习的树搜索算法SoRTS，用于在共享空域中实现社交机器人长期导航，并通过FAA认证飞行员的评估证明了其表现与一名熟练的人类飞行员相当，明显优于基准算法。 |
| [^49] | [Scientists' Perspectives on the Potential for Generative AI in their Fields.](http://arxiv.org/abs/2304.01420) | 二十位科学家就生成式人工智能在其学科中的应用进行了讨论，并发现它有助于加速科学发现和提高科学研究的教育和沟通效率。 |
| [^50] | [Enabling A Network AI Gym for Autonomous Cyber Agents.](http://arxiv.org/abs/2304.01366) | 本文开发了一个统一的训练环境CyGIL，允许网络安全操作自主代理训练。该环境通过对于真实网络的仿真与虚拟环境下大量训练周期的平衡，成功短时间内训练出了全面性的决策能力，为实现真实世界网络安全的RL代理提供有前途的方向。 |
| [^51] | [Adaptive SpikeDeep-Classifier: Self-organizing and self-supervised machine learning algorithm for online spike sorting.](http://arxiv.org/abs/2304.01355) | Ada-SpikeDeep-Classifier是一种用于实时脑机接口信号处理的自适应自组织算法，它使用了SpikeDeeptector进行信道选择、Ada-BAR进行信号预处理、OCM进行分类，旨在提高脑-计算机接口的解码效果，并在实验中表现出高精度和强健性。 |
| [^52] | [Optimized EEG based mood detection with signal processing and deep neural networks for brain-computer interface.](http://arxiv.org/abs/2304.01349) | 本论文研究了优化EEG情绪检测模型，通过信号处理和深度神经网络进行脑机接口，通过Savitzky-Golay滤波和独立成分分析对EEG信号进行预处理，实现了 Blackman窗口的傅里叶变换算法，创新提高了分类的准确性。 |
| [^53] | [A Comparison of Document Similarity Algorithms.](http://arxiv.org/abs/2304.01330) | 本研究比较了文档相似性算法，分为三类进行探讨：统计算法、神经网络算法和基于语料库/知识的算法，通过比较最有效的算法来确定哪些算法最有用。 |
| [^54] | [Empirical Design in Reinforcement Learning.](http://arxiv.org/abs/2304.01315) | 本文是一个关于如何进行良好实验的资源，旨在解决强化学习中实证设计的挑战，并弥补实证研究中可能导致的弱的统计证据。 |
| [^55] | [Kernel Affine Hull Machines for Differentially Private Learning.](http://arxiv.org/abs/2304.01300) | 本文提出了一种基于核凸包机的方法来确保数据隐私保护，同时保留数据结构，用于数据表示学习的分类应用中。为了确保隐私保护学习，还提出了一种新颖的生成虚假数据的方法。 |
| [^56] | [Efficiently Aligned Cross-Lingual Transfer Learning for Conversational Tasks using Prompt-Tuning.](http://arxiv.org/abs/2304.01295) | 本文提出了一个平行大规模多语种会话数据集XSGD，开发了一种有效的基于提示调整的方法来学习对齐提示，同时研究了跨语言任务的NLI-based和vanilla分类器，并在插槽填充和意图分类任务上评估了模型的跨语言泛化能力。 |
| [^57] | [Belief, knowledge and evidence.](http://arxiv.org/abs/2304.01283) | 本研究提出了一个新的逻辑系统，将信念、知识和证据相结合，并以“证据产生信念和知识”的直觉原则为基础，实现了$S5$模态系统与古典认识原则的结合。 |
| [^58] | [Safety Analysis in the Era of Large Language Models: A Case Study of STPA using ChatGPT.](http://arxiv.org/abs/2304.01246) | 本文研究了大型语言模型在系统论过程分析（STPA）中的应用，并采用ChatGPT对自动紧急制动（AEB）系统进行了案例研究。结果表明，重复双工交互方法是最有效的，并显着提高了STPA的质量。本研究证明，LLMs可以应用于安全分析，并为安全关键系统提供有价值的见解。 |
| [^59] | [Unified Emulation-Simulation Training Environment for Autonomous Cyber Agents.](http://arxiv.org/abs/2304.01244) | 本文提出了一种自动生成高保真度的模拟器解决方案，在智能学习的Cyber Gym for Intelligent Learning（CyGIL）中提供高度真实的网络Cyber Operations（CyOp）训练环境，并通过集成模拟器生成和代理训练过程来降低代理训练时间。 |
| [^60] | [Enhancing Clinical Evidence Recommendation with Multi-Channel Heterogeneous Learning on Evidence Graphs.](http://arxiv.org/abs/2304.01242) | 该论文提出使用证据共指图和证据文本图表来解决临床证据推荐中的联系稀疏性问题，并介绍了一个多通道异构学习模型来支持临床决策过程。 |
| [^61] | [Spam-T5: Benchmarking Large Language Models for Few-Shot Email Spam Detection.](http://arxiv.org/abs/2304.01238) | 本文通过比较不同类型的大型语言模型和传统机器学习技术在邮件垃圾检测中的表现，发现大多数情况下，大型语言模型优于传统技术，特别是在样本有限的情况下。同时，本文还介绍了经过改进和微调的Spam-T5模型，该模型具有出色的性能表现。 |
| [^62] | [Better Language Models of Code through Self-Improvement.](http://arxiv.org/abs/2304.01228) | 本文提出了一个简单的数据增强框架来改善预训练语言模型为代码生成和代码摘要等任务微调的瓶颈问题，提高了模型性能。 |
| [^63] | [Abnormal Event Detection via Hypergraph Contrastive Learning.](http://arxiv.org/abs/2304.01226) | 本论文提出了一种基于超图对比学习的异常事件检测方法，可以完全捕捉异常事件模式，实验表明该方法在两个公共数据集上明显优于现有方法。 |
| [^64] | [Optimizing Data Shapley Interaction Calculation from O(2^n) to O(t n^2) for KNN models.](http://arxiv.org/abs/2304.01224) | 本文提出了一种名为 "STI-KNN" 的算法，可以在短时间内对 KNN 模型进行精确的配对交互 Shapley 值计算，从而有效地评估每个训练数据点的价值，提高训练结果和人工智能应用的有效性。 |
| [^65] | [NeuroDAVIS: A neural network model for data visualization.](http://arxiv.org/abs/2304.01222) | NeuroDAVIS是一种无监督深度神经网络模型，它可以在不影响数据局部和全局结构的情况下提取重要特征并在更低的维度上进行数据可视化。 |
| [^66] | [DoE2Vec: Deep-learning Based Features for Exploratory Landscape Analysis.](http://arxiv.org/abs/2304.01219) | DoE2Vec 是一种基于深度学习的方法，用于学习任何实验设计（DoE）的信息潜在表达，并可以满足优化景观特征的下游元学习任务，同时避免了经典ELA分析中的特征工程问题。在分类任务中与经典ELA特征互补使用时，可显着提高性能。 |
| [^67] | [POLAR-Express: Efficient and Precise Formal Reachability Analysis of Neural-Network Controlled Systems.](http://arxiv.org/abs/2304.01218) | POLAR-Express 是一种高效且准确的形式可达性分析工具，用于验证神经网络控制系统的安全性。它使用 Taylor 模型算术和逐层传播技术，可以分析具有连续激活功能的前馈神经网络，并在 ReLU 激活函数上提供了一种更有效的精确传播 TM 的新方法。 |
| [^68] | [Distributed Multi-Agent Deep Q-Learning for Fast Roaming in IEEE 802.11ax Wi-Fi Systems.](http://arxiv.org/abs/2304.01210) | 本文提出了 MADAR 算法，解决了 Wi-Fi 漫游问题。该算法采用多智能体深度 Q 学习，有效降低延迟。 |
| [^69] | [PromptORE -- A Novel Approach Towards Fully Unsupervised Relation Extraction.](http://arxiv.org/abs/2304.01209) | 提出了“基于提示的开放关系抽取”模型，在无监督设置下不需要超参数调整，实现了全新的无监督关系抽取方法。 |
| [^70] | [When Evolutionary Computation Meets Privacy.](http://arxiv.org/abs/2304.01205) | 进化计算结合隐私保护成为新兴的研究方向，但目前隐私问题缺乏系统性研究。该论文讨论了三种典型的优化模式并提出了BOOM来整理隐私问题。BOOM包括隐私定义、隐私问题分类、隐私感知的进化计算构建和通过案例展示隐私感知的进化计算。 |
| [^71] | [Automatic Geo-alignment of Artwork in Children's Story Books.](http://arxiv.org/abs/2304.01204) | 这项研究证明AI软件可以在没有人类干预的情况下翻译和生成插图，通过比较研究，最佳的方法是使用关键字的提示增强。这对于向广泛的文学受众提供显着的成本效益提高具有重要意义。 |
| [^72] | [Polytuplet Loss: A Reverse Approach to Training Reading Comprehension and Logical Reasoning Models.](http://arxiv.org/abs/2304.01046) | 本文研究了一种训练阅读理解和逻辑推理模型的反向方法，利用相对准确性的策略来训练模型，通过Polytuplet Loss函数来确保优先学习答案选择的相对正确性，获得了不错的成果，提出了具有一般性的训练方法和模型架构。 |
| [^73] | [Graph Mining for Cybersecurity: A Survey.](http://arxiv.org/abs/2304.00485) | 本文综述了图挖掘在网络安全中的应用，包括任务概述、技术综述和不同领域的应用。该综述对未来的研究提供了指导。 |
| [^74] | [Recover Triggered States: Protect Model Against Backdoor Attack in Reinforcement Learning.](http://arxiv.org/abs/2304.00252) | 本文提出了恢复触发状态(RTS)方法，用于保护RL代理免受反向攻击。该方法涉及构建替代网络来近似动态模型，并将触发状态恢复为干净状态来防止攻击者通过触发器激活隐藏在代理中的后门。 |
| [^75] | [oBERTa: Improving Sparse Transfer Learning via improved initialization, distillation, and pruning regimes.](http://arxiv.org/abs/2303.17612) | oBERTa是一组易于使用的语言模型，通过改进初始化、蒸馏、剪枝等技术，可以在不需要模型压缩方面的专业知识的情况下提高稀疏迁移学习的效率和准确性。 |
| [^76] | [Towards secure judgments aggregation in AHP.](http://arxiv.org/abs/2303.15099) | 本文提出了两种启发式方法用于检测和减小GAHP中操纵者的影响。第一种方法是基于操纵者提供的判断为异常值的假设，第二种方法假设不诚实的判断比群体的平均一致性少一致性。这两种方法都可以有效地保证群体共识的安全。 |
| [^77] | [Predicting Human Attention using Computational Attention.](http://arxiv.org/abs/2303.09383) | HAT是一种计算注意力模型，使用新颖的基于变换器的结构和简化的凹视网膜，实现了对于目标存在和目标缺失搜索期间注视行为的扫描路径的最新技术水平。 |
| [^78] | [Towards Practical Multi-Robot Hybrid Tasks Allocation for Autonomous Cleaning.](http://arxiv.org/abs/2303.06531) | 本文提出了一个新的鲁棒混合整数线性规划模型，用于解决多机器人自主清洁系统中的混合任务分配问题，并建立了一个包括100个实例的数据集。 |
| [^79] | [Self-tuning hyper-parameters for unsupervised cross-lingual tokenization.](http://arxiv.org/abs/2303.02427) | 本研究探讨了在多语言中进行语言无关的无监督分词的元学习可能性，并使用多种适应度函数自动确定无监督分词模型的超参数。结果表明在英语和俄语中，前三种度量的加性组合与 F1 分词得分之间有相当好的相关性，在中文中，F1 得分与压缩因子有显著的相关性。 |
| [^80] | [A Categorical Archive of ChatGPT Failures.](http://arxiv.org/abs/2302.03494) | 本研究对ChatGPT的11个失败类别进行了全面分析，其中包括推理、事实错误、数学、编码和偏见。找出失败原因以帮助研究人员和开发人员改进未来的语言模型和聊天机器人。 |
| [^81] | [Policy Expansion for Bridging Offline-to-Online Reinforcement Learning.](http://arxiv.org/abs/2302.00935) | 本文提出了一种政策扩展方案，用于离线到在线强化学习，以保留离线学习的策略并在在线学习中进行自适应扩展。 |
| [^82] | [DIFFormer: Scalable (Graph) Transformers Induced by Energy Constrained Diffusion.](http://arxiv.org/abs/2301.09474) | DIFFormer是一种能量受限扩散模型，通过逐渐融合其他实例信息的演化状态，导出了一类新的神经编码器，称为DIFFormer（基于扩散的Transformer），能够揭示真实世界中复杂的数据生成过程。 |
| [^83] | [Learning-Rate-Free Learning by D-Adaptation.](http://arxiv.org/abs/2301.07733) | D-Adaptation是一种可以自动设置学习率的方法，针对最小化凸性Lipschitz函数，用于实现最优收敛速率，而无需超参数，也无需额外对数因子改进，能够在各种机器学习问题中自动匹配手动调整的学习率。 |
| [^84] | [Hierarchical Explanations for Video Action Recognition.](http://arxiv.org/abs/2301.00436) | 本文提出了分层原型解释器，能够解释深度神经网络对视频动作的分类，同时能够将类和原型建立成更有层次的关系，可以处理不确定性。 |
| [^85] | [Towards Scalable Physically Consistent Neural Networks: an Application to Data-driven Multi-zone Thermal Building Models.](http://arxiv.org/abs/2212.12380) | 本论文研究了物理一致神经网络(PCNNs) 在模拟建筑温度动态方面的扩展性和准确性。结果发现，PCNNs既确保了物理一致性，同时又能在复杂的多区域热建筑模型中取得高精度的性能表现，且在可用数据量有限的情况下超越经典灰盒模型，具有可扩展性优势。 |
| [^86] | [Hierarchical multimodal transformers for Multi-Page DocVQA.](http://arxiv.org/abs/2212.05935) | 本文提出了一种新方法，Hi-VT5，它是一种分层 transformer 结构，能够处理多页文档 DocVQA 任务。实验表明该方法能够有效地回答问题。 |
| [^87] | [Knowledge Graph Quality Evaluation under Incomplete Information.](http://arxiv.org/abs/2212.00994) | 该论文提出一种不暴露原始数据的知识图谱质量评估框架，通过将质量评估任务转化为两个KG之间的对抗性问答游戏，解决现有方法高度依赖原始数据和更多考虑数据质量而非能力层面的缺陷。 |
| [^88] | [Collective Intelligence for 2D Push Manipulation with Mobile Robots.](http://arxiv.org/abs/2211.15136) | 本研究利用基于软体物理模拟器的规划器和基于注意力的神经网络，实现了移动机器人2D协作推动操作中的集体智能，比传统方法具有更好的性能并具备环境自适应能力。 |
| [^89] | [GAMMT: Generative Ambiguity Modeling Using Multiple Transformers.](http://arxiv.org/abs/2211.09812) | GAMMT是一种生成不确定性模型，使用多个Transformer处理模糊不确定的概率。该模型有望实现高质量和多样性的序列建模。 |
| [^90] | [Adversarial Detection: Attacking Object Detection in Real Time.](http://arxiv.org/abs/2209.01962) | 本文首次提出了针对目标检测模型的实时在线攻击，这些攻击可以在所需要的位置制造不存在的物体，攻击成功率约为90\%，揭示了目标检测模型的弱点和安全性问题。 |
| [^91] | [Lottery Pools: Winning More by Interpolating Tickets without Increasing Training or Inference Cost.](http://arxiv.org/abs/2208.10842) | 本论文提出了一种名为抽奖池（Lottery Pools）的方法，它可以通过直接平均相邻学习得到的子网络的权重或者通过简单的插值策略对迭代剪枝确定的子网络执行“集成”，从而提高抽奖票（LTs）的性能。 |
| [^92] | [Multi-scale Attentive Image De-raining Networks via Neural Architecture Search.](http://arxiv.org/abs/2207.00728) | 本文提出了一种高性能的多尺度注意神经体系结构搜索（MANAS）框架，可用于图像去雨。 该方法自动搜索去雨网络的内部多尺度注意力结构，并采用有效的多尺度训练策略确保模型的鲁棒性。 |
| [^93] | [Yankee Swap: a Fast and Simple Fair Allocation Mechanism for Matroid Rank Valuations.](http://arxiv.org/abs/2206.08495) | 本论文提出了一个基于Yankee Swap过程的简单算法，用于拟阵等级估值的无分割物品公平分配，这种方法易于理解，快速可扩展。 |
| [^94] | [A Closer Look at Rehearsal-Free Continual Learning.](http://arxiv.org/abs/2203.17269) | 本文介绍了一种新的渐进式学习方法，使用知识蒸馏和参数正则化以避免重复训练，并在不会退化已学数据的情况下实现了强大的性能。 |
| [^95] | [From SLAM to Situational Awareness: Challenges and Survey.](http://arxiv.org/abs/2110.00273) | 本文研究旨在连接广泛的多学科现有知识，为移动机器人构建完整的情境感知（SA）系统，以提升其自主能力。 |
| [^96] | [Bayesian Controller Fusion: Leveraging Control Priors in Deep Reinforcement Learning for Robotics.](http://arxiv.org/abs/2107.09822) | 本研究提出了贝叶斯控制器融合（BCF）的混合控制策略，通过融合每个系统的具有不确定性的分布输出，利用它们各自的优势，在机器人任务中获得成功。 |
| [^97] | [Over-Fit: Noisy-Label Detection based on the Overfitted Model Property.](http://arxiv.org/abs/2106.07217) | 本文提出一种基于模型过拟合特性的后训练学习方法，能够识别错误标记的样本，并逐步删除对决策边界有较高影响的样本，从而提高模型的泛化性能。 |

# 详细

[^1]: EGC: 一种通过单一能量模型生成与分类图像的方法

    EGC: Image Generation and Classification via a Single Energy-Based Model. (arXiv:2304.02012v1 [cs.CV])

    [http://arxiv.org/abs/2304.02012](http://arxiv.org/abs/2304.02012)

    EGC是一种使用单个神经网络在图像分类和图像生成任务中实现卓越性能的方法，可以较好地生成出高质量图像，并在多项数据集上实现了领先的分类结果。

    

    使用相同的网络参数学习图像分类和生成图像是一个具有挑战性的问题。最近的先进方法在一项任务上表现良好，但在另一项任务上却表现不佳。本文引入了一种名为EGC的基于能量的分类器和生成器，它可以使用单个神经网络在两个任务中实现卓越性能。与传统的分类器输出给定图像的标签（即条件分布$p(y|\mathbf{x})$）不同，EGC的前向传递器是一个分类器，它输出一个联合分布$p(\mathbf{x},y)$，在后向传递器中通过边缘化标签$y$实现生成器。在前向传递中，估计给定噪声图像的能量和分类概率，而在后向传递中，通过估计得分函数对其进行去噪。EGC在ImageNet-1k、CelebA-HQ和LSUN Church上实现了与最先进方法相当的生成结果，同时在CIFAR-10、CIFAR-100和ImageNet-1k上实现了最先进的分类结果。

    Learning image classification and image generation using the same set of network parameters is a challenging problem. Recent advanced approaches perform well in one task often exhibit poor performance in the other. This work introduces an energy-based classifier and generator, namely EGC, which can achieve superior performance in both tasks using a single neural network. Unlike a conventional classifier that outputs a label given an image (i.e., a conditional distribution $p(y|\mathbf{x})$), the forward pass in EGC is a classifier that outputs a joint distribution $p(\mathbf{x},y)$, enabling an image generator in its backward pass by marginalizing out the label $y$. This is done by estimating the energy and classification probability given a noisy image in the forward pass, while denoising it using the score function estimated in the backward pass. EGC achieves competitive generation results compared with state-of-the-art approaches on ImageNet-1k, CelebA-HQ and LSUN Church, while achi
    
[^2]: 多层级对比学习在密集预测任务中的应用

    Multi-Level Contrastive Learning for Dense Prediction Task. (arXiv:2304.02010v1 [cs.CV])

    [http://arxiv.org/abs/2304.02010](http://arxiv.org/abs/2304.02010)

    本文提出了一种多层级对比学习的自监督方法，用于学习密集预测任务的区域级特征表示。该方法可通过一个新的预训练任务为神经网络学习区域语义表示，从而实现平移和尺度一致性，并将预训练轮数降至与监督预训练相同。该方法已在多个数据集上证明了其优越性能。

    

    本文提出了一种称为MCL的自监督方法，用于学习密集预测任务的区域级特征表示。该方法考虑了目标检测的三个关键因素：定位性、尺度一致性和识别性。为了明确地编码绝对位置和尺度信息，我们提出了一种新的预训练任务，将多尺度图像以拼贴的方式组装起来，模拟多目标场景。与现有的图像级自监督方法不同，我们的方法构建了一个多层级对比损失，将拼贴图像的每个子区域视为具有单个样本。我们的方法能够使神经网络学习区域语义表示，从而实现平移和尺度一致性，并将预训练轮数降至与监督预训练相同。大量实验证明，MCL在各种数据集上始终优于最新的最先进方法。

    In this work, we present Multi-Level Contrastive Learning for Dense Prediction Task (MCL), an efficient self-supervised method for learning region-level feature representation for dense prediction tasks. Our method is motivated by the three key factors in detection: localization, scale consistency and recognition. To explicitly encode absolute position and scale information, we propose a novel pretext task that assembles multi-scale images in a montage manner to mimic multi-object scenarios. Unlike the existing image-level self-supervised methods, our method constructs a multi-level contrastive loss that considers each sub-region of the montage image as a singleton. Our method enables the neural network to learn regional semantic representations for translation and scale consistency while reducing pre-training epochs to the same as supervised pre-training. Extensive experiments demonstrate that MCL consistently outperforms the recent state-of-the-art methods on various datasets with si
    
[^3]: 面向风险的分布式多智能体强化学习

    Risk-Aware Distributed Multi-Agent Reinforcement Learning. (arXiv:2304.02005v1 [cs.AI])

    [http://arxiv.org/abs/2304.02005](http://arxiv.org/abs/2304.02005)

    本文提出了一种分布式多智能体强化学习方法，通过学习风险意识动作解决了未知环境下的决策问题。

    

    自主的网络和物理系统需要在未知环境中进行决策、学习和控制。这种决策可能会受到多种因素的影响，包括建模误差、成本变化以及概率分布尾部事件的影响。虽然多智能体强化学习为通过与环境反复交互以最小化平均成本来学习行为提供了一个框架，但它无法克服上述挑战。本文提出了一种分布式多智能体强化学习方法，在学习风险意识动作的同时解决了未知环境下的决策问题。我们使用条件风险价值（CVaR）来表征被最小化的成本函数，并定义了贝尔曼算子来表征与给定状态-动作对相关联的价值函数。我们证明了这个算子满足收缩特性，并且收敛于最优的价值函数。

    Autonomous cyber and cyber-physical systems need to perform decision-making, learning, and control in unknown environments. Such decision-making can be sensitive to multiple factors, including modeling errors, changes in costs, and impacts of events in the tails of probability distributions. Although multi-agent reinforcement learning (MARL) provides a framework for learning behaviors through repeated interactions with the environment by minimizing an average cost, it will not be adequate to overcome the above challenges. In this paper, we develop a distributed MARL approach to solve decision-making problems in unknown environments by learning risk-aware actions. We use the conditional value-at-risk (CVaR) to characterize the cost function that is being minimized, and define a Bellman operator to characterize the value function associated to a given state-action pair. We prove that this operator satisfies a contraction property, and that it converges to the optimal value function. We t
    
[^4]: MEGClass: 通过相互增强的文本粒度实现极弱监督文本分类。

    MEGClass: Text Classification with Extremely Weak Supervision via Mutually-Enhancing Text Granularities. (arXiv:2304.01969v1 [cs.CL])

    [http://arxiv.org/abs/2304.01969](http://arxiv.org/abs/2304.01969)

    MEGClass是一种通过相互增强的文本粒度实现极弱监督文本分类的方法，利用分层关注机制从文档、句子和单词中提取连贯且多样的子文本，能够准确分类讨论多个主题的文档，并且在五个基准数据集上表现优于现有最先进的模型。

    

    文本分类通常需要大量的人工标注数据作为监督，这在动态新兴领域中是昂贵的。某些方法通过仅依赖类名表面文本作为极弱监督来解决这个问题。然而，现有方法未能考虑到单一类别文档讨论多个主题的情况。主题多样性和模糊的句子可能会引入噪声到文档的底层表示，从而影响预测类别的精度。此外，当前的方法独立地关注文档、句子或单词的文本粒度，从而限制了我们联合从所有三者中提取粗粒度或细粒度上下文的能力来识别分类的重要子文本。为了解决这个问题，我们提出了MEGClass，一种利用相互增强的文本粒度进行极弱监督文本分类的方法。具体来说，MEGClass通过分层关注机制从文档、句子和单词中提取连贯且多样的子文本，使我们能够识别和整合来自多个粒度的弱信号，以准确分类文档，即使它们讨论多个主题。在五个基准数据集上的实验结果表明，我们的方法在使用极弱监督的情况下，比现有最先进的模型有着更好的表现。

    Text classification typically requires a substantial amount of human-annotated data to serve as supervision, which is costly to obtain in dynamic emerging domains. Certain methods seek to address this problem by solely relying on the surface text of class names to serve as extremely weak supervision. However, existing methods fail to account for single-class documents discussing multiple topics. Both topic diversity and vague sentences may introduce noise into the document's underlying representation and consequently the precision of the predicted class. Furthermore, current work focuses on text granularities (documents, sentences, or words) independently, which limits the degree of coarse- or fine-grained context that we can jointly extract from all three to identify significant subtext for classification. In order to address this problem, we propose MEGClass, an extremely weakly-supervised text classification method to exploit Mutually-Enhancing Text Granularities. Specifically, MEGC
    
[^5]: 基于术语和关键词共现网络分析的ChatGPT研究的网络可视化

    Network Visualization of ChatGPT Research: a study based on term and keyword co-occurrence network analysis. (arXiv:2304.01948v1 [cs.SI])

    [http://arxiv.org/abs/2304.01948](http://arxiv.org/abs/2304.01948)

    本研究基于术语和关键词共现网络分析，识别出ChatGPT的主要研究领域，结果表明ChatGPT和其相关术语是最常出现的关键词。

    

    本文旨在通过术语和关键词共现网络映射技术识别ChatGPT的主要研究领域。为进行本研究，共从Lens数据库中检索到577篇文章进行网络可视化。研究结果表明，“chatgpt”是最常出现的词，其次是其相关术语，如人工智能、大型语言模型、GPT和学习等。本研究对图书馆和信息科学以及计算机或信息技术专业人员将是有益的。

    The main objective of this paper is to identify the major research areas of ChatGPT through term and keyword co-occurrence network mapping techniques. For conducting the present study, total of 577 publications were retrieved from the Lens database for the network visualization. The findings of the study showed that chatgpt occurrence in maximum number of times followed by its related terms such as artificial intelligence, large language model, gpt, study etc. This study will be helpful to library and information science as well as computer or information technology professionals.
    
[^6]: 基于姿态保留的文本图像扩散的PODIA-3D：跨越大领域间隙的3D生成模型的领域自适应

    PODIA-3D: Domain Adaptation of 3D Generative Model Across Large Domain Gap Using Pose-Preserved Text-to-Image Diffusion. (arXiv:2304.01900v1 [cs.CV])

    [http://arxiv.org/abs/2304.01900](http://arxiv.org/abs/2304.01900)

    文本导向的领域自适应方法在跨越领域差异方面取得了进展，但面向具有显着领域差异的目标领域仍具有挑战性，PODIA-3D提出了一种基于姿态保留的文本图像扩散的方法，以弥补这方面的不足。

    

    最近，3D生成模型取得了显著进展，但跨越不同领域进行训练是具有挑战性的，并需要大量的训练数据和姿态分布知识。通过使用文本提示的文本导向领域自适应方法，使生成器能够适应目标领域，从而省去了组装大量数据的需求。我们提出了一种名为PODIA-3D的领域自适应方法，通过保留姿态的文本图像扩散来跨越大领域间隙训练3D生成模型，以往的方法由于扩散式翻译中的形状 - 姿态权衡，姿态偏见以及目标领域中的实例偏见等问题，导致生成的样本中3D形状较差，文本-图像对应度低，生成样本中内部领域多样性不足的问题得到了解决。

    Recently, significant advancements have been made in 3D generative models, however training these models across diverse domains is challenging and requires an huge amount of training data and knowledge of pose distribution. Text-guided domain adaptation methods have allowed the generator to be adapted to the target domains using text prompts, thereby obviating the need for assembling numerous data. Recently, DATID-3D presents impressive quality of samples in text-guided domain, preserving diversity in text by leveraging text-to-image diffusion. However, adapting 3D generators to domains with significant domain gaps from the source domain still remains challenging due to issues in current text-to-image diffusion models as following: 1) shape-pose trade-off in diffusion-based translation, 2) pose bias, and 3) instance bias in the target domain, resulting in inferior 3D shapes, low text-image correspondence, and low intra-domain diversity in the generated samples. To address these issues,
    
[^7]: InfluencerRank：基于图卷积注意力循环神经网络发现有效的影响者

    InfluencerRank: Discovering Effective Influencers via Graph Convolutional Attentive Recurrent Neural Networks. (arXiv:2304.01897v1 [cs.SI])

    [http://arxiv.org/abs/2304.01897](http://arxiv.org/abs/2304.01897)

    本文提出了InfluencerRank，通过图卷积神经网络和注意力循环神经网络结合的方法评估影响者的有效性，以帮助企业在社交影响者营销中寻找合适的影响者。

    

    随着影响者在社交媒体营销中扮演重要角色，企业增加了影响者营销的预算。雇用有效的影响者在社交影响者营销中至关重要，但是在数亿社交媒体用户中找到合适的影响者是具有挑战性的。本文提出了InfluencerRank，它基于影响者的发布行为和社交关系评估影响者的有效性。为了表示发布行为和社交关系，应用图卷积神经网络来在不同的历史时间段内对具有异构网络的影响者进行建模。通过学习嵌入式节点特征的网络结构，InfluencerRank可以在每个时间段为影响者派生信息丰富的表示。最终，一个注意力循环神经网络通过捕捉影响者表示的动态知识，区分高效的影响者和其他影响者。

    As influencers play considerable roles in social media marketing, companies increase the budget for influencer marketing. Hiring effective influencers is crucial in social influencer marketing, but it is challenging to find the right influencers among hundreds of millions of social media users. In this paper, we propose InfluencerRank that ranks influencers by their effectiveness based on their posting behaviors and social relations over time. To represent the posting behaviors and social relations, the graph convolutional neural networks are applied to model influencers with heterogeneous networks during different historical periods. By learning the network structure with the embedded node features, InfluencerRank can derive informative representations for influencers at each period. An attentive recurrent neural network finally distinguishes highly effective influencers from other influencers by capturing the knowledge of the dynamics of influencer representations over time. Extensiv
    
[^8]: 自动驾驶中道路用户轨迹预测模型的鲁棒性基准测试

    Robustness Benchmark of Road User Trajectory Prediction Models for Automated Driving. (arXiv:2304.01895v1 [cs.AI])

    [http://arxiv.org/abs/2304.01895](http://arxiv.org/abs/2304.01895)

    本文对四个道路用户轨迹预测模型进行了基准测试，评估了它们在遇到不同扰动时的性能。结果表明，这些模型的性能在各种扰动的存在下显著降低，需要通过数据扩充等策略提高模型的鲁棒性。

    

    准确且鲁棒的道路用户轨迹预测对于实现安全自动驾驶至关重要。为此，通常使用机器学习模型，但当遇到之前未见过的输入时，这些模型可能表现出不稳定的行为。本文对两个环境感知模型（MotionCNN和MultiPath++）以及两个常见基线模型（Constant Velocity和LSTM）进行了鲁棒性基准测试，评估这些模型在面对车辆部署期间观察到的功能不足的各种扰动时的表现。结果表明，在这些扰动的存在下，性能显著下降，通常使用的轨迹预测评估指标的误差增加了高达+1444.8％。使用类似扰动的数据训练模型有效减少了性能降低，误差增长最高可达+87.5％。本文认为，尽管数据扩充是一种有效的缓解策略，但仍需要更多工作来提高模型鲁棒性。

    Accurate and robust trajectory predictions of road users are needed to enable safe automated driving. To do this, machine learning models are often used, which can show erratic behavior when presented with previously unseen inputs. In this work, two environment-aware models (MotionCNN and MultiPath++) and two common baselines (Constant Velocity and an LSTM) are benchmarked for robustness against various perturbations that simulate functional insufficiencies observed during model deployment in a vehicle: unavailability of road information, late detections, and noise. Results show significant performance degradation under the presence of these perturbations, with errors increasing up to +1444.8\% in commonly used trajectory prediction evaluation metrics. Training the models with similar perturbations effectively reduces performance degradation, with error increases of up to +87.5\%. We argue that despite being an effective mitigation strategy, data augmentation through perturbations duri
    
[^9]: 社会文化知识在仇恨言论检测任务中对选项的选择是必要的

    Sociocultural knowledge is needed for selection of shots in hate speech detection tasks. (arXiv:2304.01890v1 [cs.CL])

    [http://arxiv.org/abs/2304.01890](http://arxiv.org/abs/2304.01890)

    HATELEXICON是一个包含巴西，德国，印度和肯尼亚仇恨言论的词汇表，利用其可以提高模型在训练中的性能表现。

    

    我们引入了HATELEXICON，这是一个包含巴西，德国，印度和肯尼亚的蔑称和仇恨言论目标的词汇表，以帮助模型的训练和可解释性。我们展示了我们的词汇表如何用于解释模型预测，表明发展用于分类极端言论的模型，在进行预测时严重依赖目标词。此外，我们提出了一种通过HATELEXICON来辅助低资源环境下训练选项的方法，选项选择在小样本学习中尤为重要。在我们的工作中，我们使用HASOC数据对德语和印地语进行了几个示范学习，并将Multilingual HateCheck（MHC）作为基准。我们展示了根据我们的词汇表选择样本，相对于随机采样的模型，能够更好地在MHC上表现。因此，当仅有少量的训练样本时，使用我们的词汇表来选择包含更多社会文化信息的样本能够更好地提高在仇恨言论检测任务中的性能。

    We introduce HATELEXICON, a lexicon of slurs and targets of hate speech for the countries of Brazil, Germany, India and Kenya, to aid training and interpretability of models. We demonstrate how our lexicon can be used to interpret model predictions, showing that models developed to classify extreme speech rely heavily on target words when making predictions. Further, we propose a method to aid shot selection for training in low-resource settings via HATELEXICON. In few-shot learning, the selection of shots is of paramount importance to model performance. In our work, we simulate a few-shot setting for German and Hindi, using HASOC data for training and the Multilingual HateCheck (MHC) as a benchmark. We show that selecting shots based on our lexicon leads to models performing better on MHC than models trained on shots sampled randomly. Thus, when given only a few training examples, using our lexicon to select shots containing more sociocultural information leads to better few-shot perf
    
[^10]: Deep-BIAS:使用可解释的人工智能技术检测结构偏差

    Deep-BIAS: Detecting Structural Bias using Explainable AI. (arXiv:2304.01869v1 [cs.NE])

    [http://arxiv.org/abs/2304.01869](http://arxiv.org/abs/2304.01869)

    Deep-BIAS是一种可解释的深度学习扩展工具箱，用于检测搜索算法中的结构偏差。通过训练深度学习模型，可以快速检测基于原始性能分布的偏差的强度和类型。该工具箱已被证明在各种具有结构偏差情况的实验中十分有效，并在336种最先进的优化算法中得到了广泛应用。

    

    评估启发式优化算法的性能对于确定它们在各种条件下的表现如何至关重要。最近，引入了BIAS工具包作为行为基准来检测搜索算法中的结构偏差（SB）。该工具包可用于识别现有算法中的偏差，以及测试新开发的算法的偏差。在本文中，我们介绍了BIAS工具箱的一种新颖且可解释的深度学习扩展，称为Deep-BIAS。原始工具箱使用39个统计测试和一个随机森林模型来预测SB的存在和类型，而Deep-BIAS方法使用训练有素的深度学习模型来立即检测基于原始性能分布的SB的强度和类型。通过一系列具有各种结构偏差情况的实验证明了Deep-BIAS的有效性。我们还展示了使用工具箱对336种最先进的优化算法的结果。

    Evaluating the performance of heuristic optimisation algorithms is essential to determine how well they perform under various conditions. Recently, the BIAS toolbox was introduced as a behaviour benchmark to detect structural bias (SB) in search algorithms. The toolbox can be used to identify biases in existing algorithms, as well as to test for bias in newly developed algorithms. In this article, we introduce a novel and explainable deep-learning expansion of the BIAS toolbox, called Deep-BIAS. Where the original toolbox uses 39 statistical tests and a Random Forest model to predict the existence and type of SB, the Deep-BIAS method uses a trained deep-learning model to immediately detect the strength and type of SB based on the raw performance distributions. Through a series of experiments with a variety of structurally biased scenarios, we demonstrate the effectiveness of Deep-BIAS. We also present the results of using the toolbox on 336 state-of-the-art optimisation algorithms, whi
    
[^11]: SportsPose -- 一种动态的三维体育姿势数据集

    SportsPose -- A Dynamic 3D sports pose dataset. (arXiv:2304.01865v1 [cs.CV])

    [http://arxiv.org/abs/2304.01865](http://arxiv.org/abs/2304.01865)

    推出了一个大型的三维人体姿态数据集SportsPose，它包含一个多样和全面的3D姿态集，反映了体育运动的复杂和动态性；并引入了一个新的度量标准，局部运动，它描述了手腕和踝关节的运动。

    

    准确的三维人体姿势估计对于体育分析、教练和预防运动伤害至关重要。然而，现有的单目姿势估计数据集无法充分捕捉到运动动作的挑战性和动态性。为了解决这个问题，我们推出了SportsPose，一个大型的三维人体姿态数据集，包括高度动态的体育运动。SportsPose提供了超过176,000个来自24个不同受试者进行5种不同体育活动的3D姿态，提供了一个多样且全面的3D姿态集，反映了体育运动的复杂和动态性。与其他无标记数据集不同，我们通过将我们的姿态与商业标记系统进行比较来定量评估了SportsPose的精度，平均误差在所有评估序列中为34.5mm。这与常用的3DPW数据集报道的误差相当。我们还引入了一个新的度量标准，称为局部运动，它描述了手腕和踝关节的运动。

    Accurate 3D human pose estimation is essential for sports analytics, coaching, and injury prevention. However, existing datasets for monocular pose estimation do not adequately capture the challenging and dynamic nature of sports movements. In response, we introduce SportsPose, a large-scale 3D human pose dataset consisting of highly dynamic sports movements. With more than 176,000 3D poses from 24 different subjects performing 5 different sports activities, SportsPose provides a diverse and comprehensive set of 3D poses that reflect the complex and dynamic nature of sports movements. Contrary to other markerless datasets we have quantitatively evaluated the precision of SportsPose by comparing our poses with a commercial marker-based system and achieve a mean error of 34.5 mm across all evaluation sequences. This is comparable to the error reported on the commonly used 3DPW dataset. We further introduce a new metric, local movement, which describes the movement of the wrist and ankle 
    
[^12]: Grid-SD2E：一种认知学习系统中的通用网格反馈方法

    Grid-SD2E: A General Grid-Feedback in a System for Cognitive Learning. (arXiv:2304.01844v1 [cs.AI])

    [http://arxiv.org/abs/2304.01844](http://arxiv.org/abs/2304.01844)

    本文提出了一种名为Grid-SD2E的认知学习系统，其建立在网格细胞的基础上，使用空间划分和探索利用方法实现交互和自我强化，有助于理解大脑的工作机制、治疗脑部疾病和理解智能。

    

    理解大脑如何通过产生神经信号与外部世界相互作用对于确定其工作机制、治疗脑部疾病和理解智能非常重要。然而，尽管已经提出了许多理论模型，但它们迄今难以整合和发展。受网格细胞启发，本研究创建了一个更通用和强大的网格模块，并与贝叶斯推理一起构建了一个互动和自我强化的认知系统。这种方法称为带有网格反馈的空间划分和探索利用（Grid-SD2E）。在这里，网格模块可以用作外部世界和系统之间的交互介质，也可以用作系统内的自我强化介质。空间划分和探索利用（SD2E）通过其空间划分（SD）模块接收网格的0/1信号。本文描述的系统也是从进行的实验得出的理论模型。

    Comprehending how the brain interacts with the external world through generated neural signals is crucial for determining its working mechanism, treating brain diseases, and understanding intelligence. Although many theoretical models have been proposed, they have thus far been difficult to integrate and develop. In this study, we were inspired in part by grid cells in creating a more general and robust grid module and constructing an interactive and self-reinforcing cognitive system together with Bayesian reasoning, an approach called space-division and exploration-exploitation with grid-feedback (Grid-SD2E). Here, a grid module can be used as an interaction medium between the outside world and a system, as well as a self-reinforcement medium within the system. The space-division and exploration-exploitation (SD2E) receives the 0/1 signals of a grid through its space-division (SD) module. The system described in this paper is also a theoretical model derived from experiments conducted
    
[^13]: BugNIST -- 一种新的大规模体积三维图像数据集，用于分类和检测

    BugNIST -- A New Large Scale Volumetric 3D Image Dataset for Classification and Detection. (arXiv:2304.01838v1 [cs.CV])

    [http://arxiv.org/abs/2304.01838](http://arxiv.org/abs/2304.01838)

    本文介绍了一个名为BugNIST的广泛数据集，该数据集由12种昆虫和幼虫的微-CT扫描组成。通过训练和测试检测模型，BugNIST旨在评估三维体积图像分类和检测方法，解决上下文无关的挑战。

    

    三维体积图像分析研究的进展受到数据集缺乏的限制，大多数针对体积图像的分析方法都基于医学数据。然而，医学数据并不一定具有其他体积图像（例如微-CT）的特征。为了促进三维体积图像分析的研究超越医学数据，我们创建了BugNIST数据集并免费提供。BugNIST是一组由12种昆虫和幼虫的微-CT扫描组成的广泛数据集。BugNIST包含9437个体积，其中9087个是单个昆虫的扫描，350个是昆虫和其他材料的混合物。BugNIST的目标是评估分类和检测方法，我们设计了检测挑战，使得检测模型在单个昆虫的扫描上训练并在昆虫混合物上进行测试。能够解决此任务的模型将独立于上下文（即周围材料），这是一个很大的优势。

    Progress in 3D volumetric image analysis research is limited by the lack of datasets and most advances in analysis methods for volumetric images are based on medical data. However, medical data do not necessarily resemble the characteristics of other volumetric images such as micro-CT. To promote research in 3D volumetric image analysis beyond medical data, we have created the BugNIST dataset and made it freely available. BugNIST is an extensive dataset of micro-CT scans of 12 types of bugs, such as insects and larvae. BugNIST contains 9437 volumes where 9087 are of individual bugs and 350 are mixtures of bugs and other material. The goal of BugNIST is to benchmark classification and detection methods, and we have designed the detection challenge such that detection models are trained on scans of individual bugs and tested on bug mixtures. Models capable of solving this task will be independent of the context, i.e., the surrounding material. This is a great advantage if the context is 
    
[^14]: 垂直联邦学习综述：以分层视角为基础

    A Survey on Vertical Federated Learning: From a Layered Perspective. (arXiv:2304.01829v1 [cs.LG])

    [http://arxiv.org/abs/2304.01829](http://arxiv.org/abs/2304.01829)

    垂直联邦学习（VFL）是一种适用于数据垂直分区情况的有前途的联邦学习方法，该方法丰富了样本描述，以提高模型容量。研究人员在硬件层到垂直联邦系统层各个方面做了贡献，VFL的应用已涵盖多个领域，尤其隐私保护是关键问题。

    

    垂直联邦学习（VFL）是一种有前途的联邦学习范畴，适用于数据垂直分区并分布在各方之间的情况。VFL使用来自不同方的特征来丰富样本描述，以提高模型容量。与水平联邦学习相比，在大多数情况下，VFL应用于公司的商业合作场景中，因此VFL包含巨大的商业价值。在过去的几年中，VFL在学术界和工业界引起了越来越多的关注。本文从分层视角系统地调查了VFL的现有研究工作。从硬件层到垂直联邦系统层，研究人员贡献了VFL的各个方面。此外，VFL的应用已覆盖了广泛的领域，例如金融、医疗等。在每个层面上，我们对现有工作进行分类并探讨了进一步研究和发展VFL的挑战。特别关注隐私保护，这是VFL中由于数据分布在各方之间而具有关键性的问题。

    Vertical federated learning (VFL) is a promising category of federated learning for the scenario where data is vertically partitioned and distributed among parties. VFL enriches the description of samples using features from different parties to improve model capacity. Compared with horizontal federated learning, in most cases, VFL is applied in the commercial cooperation scenario of companies. Therefore, VFL contains tremendous business values. In the past few years, VFL has attracted more and more attention in both academia and industry. In this paper, we systematically investigate the current work of VFL from a layered perspective. From the hardware layer to the vertical federated system layer, researchers contribute to various aspects of VFL. Moreover, the application of VFL has covered a wide range of areas, e.g., finance, healthcare, etc. At each layer, we categorize the existing work and explore the challenges for the convenience of further research and development of VFL. Espec
    
[^15]: HarsanyiNet: 在单次前向传播中计算准确的 Shapley 值

    HarsanyiNet: Computing Accurate Shapley Values in a Single Forward Propagation. (arXiv:2304.01811v1 [cs.LG])

    [http://arxiv.org/abs/2304.01811](http://arxiv.org/abs/2304.01811)

    HarsanyiNet 是一种新型的深度神经网络架构，它可以在单次前向传播中计算输入变量的精确 Shapley 值。

    

    Shapley 值被广泛认为是一种可信的属性度量方法。然而，当人们使用 Shapley 值来解释深度神经网络（DNN）的输入变量的属性时，通常需要非常高的计算成本才能在实际应用中近似计算出比较精确的 Shapley 值。因此，我们提出一种新型网络架构 HarsanyiNet，在输入样本的推理过程中同时计算输入变量的精确 Shapley 值，只需要一次前向传播即可。HarsanyiNet 是构建在 Shapley 值可以被重新构建为网络编码的 Harsanyi 交互重新分配的理论基础之上的。

    The Shapley value is widely regarded as a trustworthy attribution metric. However, when people use Shapley values to explain the attribution of input variables of a deep neural network (DNN), it usually requires a very high computational cost to approximate relatively accurate Shapley values in real-world applications. Therefore, we propose a novel network architecture, the HarsanyiNet, which makes inferences on the input sample and simultaneously computes the exact Shapley values of the input variables in a single forward propagation. The HarsanyiNet is designed on the theoretical foundation that the Shapley value can be reformulated as the redistribution of Harsanyi interactions encoded by the network.
    
[^16]: 采用Transformer实现轻量化单图像去噪并进行真正公平训练的探索

    Exploration of Lightweight Single Image Denoising with Transformers and Truly Fair Training. (arXiv:2304.01805v1 [cs.CV])

    [http://arxiv.org/abs/2304.01805](http://arxiv.org/abs/2304.01805)

    本文研究了采用Transformer实现轻量化单图像去噪的问题，提供了七种比较基线Transformer，并探讨了在训练过程中随机剪裁补丁的部分对去噪性能的影响；而以往的研究忽略了这一问题。此外，本文以真正公平的方式训练基线Transformer，并进行了各种组件的实证分析，以确定构建轻量化去噪Transformer的关键考虑因素。

    

    由于数字设备的固有缺陷，多媒体内容通常包含噪声。因此，在高级视觉识别任务中，图像去噪是重要的预处理步骤。虽然已经有一些研究采用先进的Transformer开发了去噪领域，但是这些网络对于实际应用来说过于占用内存。此外，对于采用Transformer的轻量化去噪领域的研究还缺乏。为应对这一问题，本文提供了七种轻量级去噪的比较基线Transformer，为未来的研究提供了基础。我们还展示了在训练过程中，随机剪裁补丁的部分会显著影响去噪性能，而以前的研究却忽略了这一方面。我们的目标是以真正公平的方式训练基线Transformer。此外，我们还进行了各种组件的实证分析，以确定构建轻量化去噪Transformer的关键考虑因素。代码可在 https://github.com/rami0205/LWDN 上获得。

    As multimedia content often contains noise from intrinsic defects of digital devices, image denoising is an important step for high-level vision recognition tasks. Although several studies have developed the denoising field employing advanced Transformers, these networks are too momory-intensive for real-world applications. Additionally, there is a lack of research on lightweight denosing (LWDN) with Transformers. To handle this, this work provides seven comparative baseline Transformers for LWDN, serving as a foundation for future research. We also demonstrate the parts of randomly cropped patches significantly affect the denoising performances during training. While previous studies have overlooked this aspect, we aim to train our baseline Transformers in a truly fair manner. Furthermore, we conduct empirical analyses of various components to determine the key considerations for constructing LWDN Transformers. Codes are available at https://github.com/rami0205/LWDN.
    
[^17]: 使用语言模型在自然语言推理问题中获取知识

    Using Language Models For Knowledge Acquisition in Natural Language Reasoning Problems. (arXiv:2304.01771v1 [cs.AI])

    [http://arxiv.org/abs/2304.01771](http://arxiv.org/abs/2304.01771)

    本文研究了使用大型语言模型在自然语言推理问题中获取知识的方法，比较了两种方式并得出后一种使用语言模型提取知识更合适的结论。

    

    对于需要一些非平凡推理才能解决的自然语言问题，可以使用大型语言模型（LLM）的至少两种方法进行解决。一种方法是直接要求它解决问题，另一种方法是使用它从问题文本中提取事实，然后使用定理证明器进行解决。在本研究中，我们使用ChatGPT和GPT4对一系列逻辑单词谜题进行比较，并得出了后者是正确的方法的结论。

    For a natural language problem that requires some non-trivial reasoning to solve, there are at least two ways to do it using a large language model (LLM). One is to ask it to solve it directly. The other is to use it to extract the facts from the problem text and then use a theorem prover to solve it. In this note, we compare the two methods using ChatGPT and GPT4 on a series of logic word puzzles, and conclude that the latter is the right approach.
    
[^18]: 将未标记数据纳入贝叶斯神经网络中

    Incorporating Unlabelled Data into Bayesian Neural Networks. (arXiv:2304.01762v1 [cs.LG])

    [http://arxiv.org/abs/2304.01762](http://arxiv.org/abs/2304.01762)

    该论文提出了一种利用未标记数据学习贝叶斯神经网络（BNNs）的对比框架，通过该框架提出了一种同时具备自监督学习的标签效率和贝叶斯方法中的不确定性估计的实用BNN算法。最后，该方法在半监督和低预算主动学习问题中展现出了数据高效学习的优势。

    

    我们提出了一个对贝叶斯神经网络（BNNs）中先验分布进行学习的对比框架，利用未标记数据来优化。基于该框架，我们提出了一种实用的BNN算法，同时具备自监督学习的标签效率和贝叶斯方法中的根据原则的不确定性估计。最后，我们展示了我们的方法在半监督和低预算主动学习问题中的数据高效学习优势。

    We develop a contrastive framework for learning better prior distributions for Bayesian Neural Networks (BNNs) using unlabelled data. With this framework, we propose a practical BNN algorithm that offers the label-efficiency of self-supervised learning and the principled uncertainty estimates of Bayesian methods. Finally, we demonstrate the advantages of our approach for data-efficient learning in semi-supervised and low-budget active learning problems.
    
[^19]: 通过对比特征对齐学习不变表示以实现抗混杂SAR目标识别

    Learning Invariant Representation via Contrastive Feature Alignment for Clutter Robust SAR Target Recognition. (arXiv:2304.01747v1 [cs.CV])

    [http://arxiv.org/abs/2304.01747](http://arxiv.org/abs/2304.01747)

    本文提出了一种名为对比特征对齐(CFA)的解决方案，旨在通过学习不变表示以实现鲁棒识别。本文方法提出了混杂杂波变体生成策略和配备通道加权均方误差(CWMSE)损失的新推断分支。实验结果表明，我们的方法在MSTAR数据集的移动和静止地面车辆基准上实现了最先进的性能。

    

    深度神经网络(DNNs)释放了合成孔径雷达自动目标识别(SAR ATR)使其摆脱了基于专业知识的特征设计，并证明了其优于传统解决方案的优势。在强背景相关性的形状方面，已经显示了地面车辆基准的独特缺陷，其结果在DNNs过拟合杂波且对陌生环境不具有稳健性。然而，固定背景模型训练和可变背景应用之间的差距仍未得到充分探索。受对比学习的启发，本文提出了一种名为对比特征对齐(CFA)的解决方案，旨在学习不变表示以实现鲁棒识别。本文方法提出了混杂杂波变体生成策略和配备通道加权均方误差(CWMSE)损失的新推断分支，用于学习不变表示。具体而言，生成策略经过精心设计，以更好地吸引分类器的杂波敏感性并扩大训练数据的多样性。此外，引入CWMSE损失可忽略变量背景中无关杂波的影响。实验结果表明，我们的方法在MSTAR数据集的移动和静止地面车辆基准上实现了最先进的性能。

    The deep neural networks (DNNs) have freed the synthetic aperture radar automatic target recognition (SAR ATR) from expertise-based feature designing and demonstrated superiority over conventional solutions. There has been shown the unique deficiency of ground vehicle benchmarks in shapes of strong background correlation results in DNNs overfitting the clutter and being non-robust to unfamiliar surroundings. However, the gap between fixed background model training and varying background application remains underexplored. Inspired by contrastive learning, this letter proposes a solution called Contrastive Feature Alignment (CFA) aiming to learn invariant representation for robust recognition. The proposed method contributes a mixed clutter variants generation strategy and a new inference branch equipped with channel-weighted mean square error (CWMSE) loss for invariant representation learning. In specific, the generation strategy is delicately designed to better attract clutter-sensitiv
    
[^20]: 开放词汇视频实例分割的探索

    Towards Open-Vocabulary Video Instance Segmentation. (arXiv:2304.01715v1 [cs.CV])

    [http://arxiv.org/abs/2304.01715](http://arxiv.org/abs/2304.01715)

    本文提出了新任务--开放词汇视频实例分割，并收集了大规模的LV-VIS数据集，同时提出了高效的MindVLT方法，能够以近实时的速度实现开放集视频实例分割任务，相比现有方法有显著的提升。

    

    视频实例分割（VIS）旨在从一组封闭的训练类别中对视频中的对象进行分割和分类，缺乏处理真实世界中新类别的泛化能力。为了解决这个问题，本文提出了三个方案。首先，我们引入了开放词汇视频实例分割的新任务，旨在同时从开放集类别中对视频中的对象进行分割、跟踪和分类，包括训练期间未见过的新类别。其次，为了评测开放词汇实例分割，我们收集了包含1,212个不同类别的大规模词汇视频实例分割数据集（LV-VIS），显著超出了现有数据集的类别规模一个数量级以上。第三，我们提出了一种高效的记忆驱动视觉语言变换器MindVLT，以实现近实时端到端的开放词汇视频实例分割。广泛的实验结果表明，我们提出的MindVLT在封闭集和开放集视频实例分割任务上显著优于现有方法。

    Video Instance Segmentation(VIS) aims at segmenting and categorizing objects in videos from a closed set of training categories, lacking the generalization ability to handle novel categories in real-world videos. To address this limitation, we make the following three contributions. First, we introduce the novel task of Open-Vocabulary Video Instance Segmentation, which aims to simultaneously segment, track, and classify objects in videos from open-set categories, including novel categories unseen during training. Second, to benchmark Open-Vocabulary VIS, we collect a Large-Vocabulary Video Instance Segmentation dataset(LV-VIS), that contains well-annotated objects from 1,212 diverse categories, significantly surpassing the category size of existing datasets by more than one order of magnitude. Third, we propose an efficient Memory-Induced Vision-Language Transformer, MindVLT, to first achieve Open-Vocabulary VIS in an end-to-end manner with near real-time inference speed. Extensive ex
    
[^21]: 推特谣言检测与分析

    Rumour Detection and Analysis on Twitter. (arXiv:2304.01712v1 [cs.CL])

    [http://arxiv.org/abs/2304.01712](http://arxiv.org/abs/2304.01712)

    本文研究了社交媒体平台上的谣言检测并分析了新冠疫情相关推文的数据。研究使用最先进的自然语言处理模型通过比较语言结构和传播路径等特征来区分谣言和事实，并发现语言结构是更好的区分特征。

    

    近年来，人们越来越依赖社交媒体获取新闻和信息，一些社交媒体用户发布缺乏证实的信息以获取关注，这种信息被称为谣言。本文构建了自然语言处理（NLP）系统来预测谣言。其中，最佳模型被应用于新冠疫情相关推文的探索性数据分析。本研究的贡献有两个方面：（1）通过两个维度：语言结构和传播路径，使用最先进的自然语言处理模型来比较谣言和事实。（2）通过分析谣言与事实在词汇使用和暗示的情感方面的不同，探究谣言与事实之间的不同。该研究表明，相比传播路径，语言结构是更好的特征来区分谣言和事实。

    In recent years people have become increasingly reliant on social media to read news and get information, and some social media users post unsubstantiated information to gain attention. Such information is known as rumours. Nowadays, rumour detection is receiving a growing amount of attention because of the pandemic of the New Coronavirus, which has led to a large number of rumours being spread. In this paper, a Natural Language Processing (NLP) system is built to predict rumours. The best model is applied to the COVID-19 tweets to conduct exploratory data analysis. The contribution of this study is twofold: (1) to compare rumours and facts using state-of-the-art natural language processing models in two dimensions: language structure and propagation route. (2) An analysis of how rumours differ from facts in terms of their lexical use and the emotions they imply. This study shows that linguistic structure is a better feature to distinguish rumours from facts compared to the propagation
    
[^22]: 无监督排序的单模糊图像到视频序列方法——HyperCUT

    HyperCUT: Video Sequence from a Single Blurry Image using Unsupervised Ordering. (arXiv:2304.01686v1 [cs.CV])

    [http://arxiv.org/abs/2304.01686](http://arxiv.org/abs/2304.01686)

    本文提出了一种新的无监督排序方法来解决单模糊图像到视频序列的重建问题，显式地分配每个序列的顺序，有效提高了去模糊模型的训练质量，并在合成和真实数据集上获得了最好的结果。

    

    本文研究了图像到视频去模糊的模型训练中的一个关键问题：由于前向和后向序列都可以作为模糊图像对应的清晰图像序列，因此序列顺序的模糊性极大地干扰了模型的训练效果。为解决这一问题，本文提出了一种有效的自监督排序方法，将每个视频序列映射到一个高维潜在空间中的向量，并利用超平面将其与其反向序列区分开来，显式地分配了每个序列的顺序。最后，我们在合成和真实数据集上验证了我们的方法，并与现有的图像到视频去模糊方法相比取得了最优秀的性能。

    We consider the challenging task of training models for image-to-video deblurring, which aims to recover a sequence of sharp images corresponding to a given blurry image input. A critical issue disturbing the training of an image-to-video model is the ambiguity of the frame ordering since both the forward and backward sequences are plausible solutions. This paper proposes an effective self-supervised ordering scheme that allows training high-quality image-to-video deblurring models. Unlike previous methods that rely on order-invariant losses, we assign an explicit order for each video sequence, thus avoiding the order-ambiguity issue. Specifically, we map each video sequence to a vector in a latent high-dimensional space so that there exists a hyperplane such that for every video sequence, the vectors extracted from it and its reversed sequence are on different sides of the hyperplane. The side of the vectors will be used to define the order of the corresponding sequence. Last but not 
    
[^23]: Motion-R3:基于表征相关性排名的快速准确的动作注释方法

    Motion-R3: Fast and Accurate Motion Annotation via Representation-based Representativeness Ranking. (arXiv:2304.01672v1 [cs.CV])

    [http://arxiv.org/abs/2304.01672](http://arxiv.org/abs/2304.01672)

    本文提出了一种快速准确的动作注释方法Motion-R3，该方法基于数据中心哲学，通过学习动作表示空间中的表征性进行排名，可快速应对需求变化并实现敏捷开发。

    

    本文提出了一种基于数据中心哲学的新型动作注释方法，该方法基于给定数据集中动作数据的内在相关性。具体而言，我们提出了一种称为表征相关性排名R3的方法，该方法根据动作在学习的动作表示空间中的表征性对其在给定数据集中进行排名。我们进一步提出了一种新颖的双级动作对比学习方法来以更加信息化的方式学习动作表示空间。由于其高效性，我们的方法能够更快地应对频繁的需求变化，并实现动作注释模型的敏捷开发。对HDM05数据集的实验结果表明，我们的方法优于现有的方法。

    In this paper, we follow a data-centric philosophy and propose a novel motion annotation method based on the inherent representativeness of motion data in a given dataset. Specifically, we propose a Representation-based Representativeness Ranking R3 method that ranks all motion data in a given dataset according to their representativeness in a learned motion representation space. We further propose a novel dual-level motion constrastive learning method to learn the motion representation space in a more informative way. Thanks to its high efficiency, our method is particularly responsive to frequent requirements change and enables agile development of motion annotation models. Experimental results on the HDM05 dataset against state-of-the-art methods demonstrate the superiority of our method.
    
[^24]: 一种基于嵌入的处理具有不一致性本体的容错推理方法

    An Embedding-based Approach to Inconsistency-tolerant Reasoning with Inconsistent Ontologies. (arXiv:2304.01664v1 [cs.AI])

    [http://arxiv.org/abs/2304.01664](http://arxiv.org/abs/2304.01664)

    本文提出了一种基于嵌入的方法来处理具有不一致性本体的容错推理问题，这种方法通过语义向量计算公理之间的关联，定义了选择最大一致子集的方法，并证明了推理关系的合理性。

    

    处理不一致性是知识管理中的重要问题，特别是在本体工程中，本体构建过程中可能出现逻辑不一致性。本文提出了一种基于描述逻辑的嵌入方法，通过将公理转化为分布式语义向量计算公理之间的语义关联，进而定义了一种基于嵌入的选择最大一致子集的方法，并将其用于定义容错推理关系。通过考虑某些逻辑属性，证明了推理关系的合理性。最后，在几个数据集上验证了实验效果。

    Inconsistency handling is an important issue in knowledge management. Especially in ontology engineering, logical inconsistencies may occur during ontology construction. A natural way to reason with an inconsistent ontology is to utilize the maximal consistent subsets of the ontology. However, previous studies on selecting maximum consistent subsets have rarely considered the semantics of the axioms, which may result in irrational inference. In this paper, we propose a novel approach to reasoning with inconsistent ontologies in description logics based on the embeddings of axioms. We first give a method for turning axioms into distributed semantic vectors to compute the semantic connections between the axioms. We then define an embedding-based method for selecting the maximum consistent subsets and use it to define an inconsistency-tolerant inference relation. We show the rationality of our inference relation by considering some logical properties. Finally, we conduct experiments on se
    
[^25]: 通过鉴别微调进行跨领域图像字幕生成

    Cross-Domain Image Captioning with Discriminative Finetuning. (arXiv:2304.01662v1 [cs.CV])

    [http://arxiv.org/abs/2304.01662](http://arxiv.org/abs/2304.01662)

    本文通过使用自监督鉴别式沟通目标，微调已有的神经字幕生成器，在保持语言的视觉描述性的同时，提高了对图像内容的信息提取精度。

    

    神经字幕生成器通常被训练成模仿人类生成的参考文本而没有针对特定沟通目标进行优化，导致产生模糊的字幕等问题。本文表明，使用自监督鉴别式沟通目标微调神经字幕生成器能够帮助恢复平实、视觉描述性更强、关于图像内容更丰富的语言。给定一个目标图像，系统必须学习产生一段描述，从而使一个开箱即用的文本条件图像检索器能够在一组候选图像中识别该图像。我们使用了流行的ClipCap字幕生成器进行实验，并使用BLIP复制了主要结果。就与人类描述的相似度而言，在相同的字幕数据集上训练和测试非微调模型生成的字幕略优于鉴别微调的字幕。然而，当模型未经进一步训练时，鉴别微调的字幕比以前的方法生成的参考文本更能提供关于图像视觉内容更丰富的信息。

    Neural captioners are typically trained to mimic human-generated references without optimizing for any specific communication goal, leading to problems such as the generation of vague captions. In this paper, we show that fine-tuning an out-of-the-box neural captioner with a self-supervised discriminative communication objective helps to recover a plain, visually descriptive language that is more informative about image contents. Given a target image, the system must learn to produce a description that enables an out-of-the-box text-conditioned image retriever to identify such image among a set of candidates. We experiment with the popular ClipCap captioner, also replicating the main results with BLIP. In terms of similarity to ground-truth human descriptions, the captions emerging from discriminative finetuning lag slightly behind those generated by the non-finetuned model, when the latter is trained and tested on the same caption dataset. However, when the model is used without furth
    
[^26]: 高效可解释的长文本分类的多维感知器

    Multidimensional Perceptron for Efficient and Explainable Long Text Classification. (arXiv:2304.01638v1 [cs.CL])

    [http://arxiv.org/abs/2304.01638](http://arxiv.org/abs/2304.01638)

    提出了一种名为SWIPE的多维感知器模型，有效地学习整个文本的标签并以无监督的方式感知段落的标签。SWIPE作为一种通用分类器，支持不同的编码器，在分类上优于现有技术。

    

    由于Transformer和预训练模型的不可避免的成本和复杂性，在长文本分类中引起了效率问题。同时，在高度敏感的领域，例如医疗保健和法律长文本挖掘中，潜在的模型不信任，虽然被低估和未被探索，但可能孕育重要的忧虑。现有方法通常将长文本分割，使用预训练模型对每个片段进行编码，并使用注意力或RNN来获取长文本表示以进行分类。在本文中，我们提出了一个简单而有效的模型，即Segment-aWare multIdimensional PErceptron（SWIPE），以取代上述框架中的注意力/RNN。与之前的工作不同，SWIPE可以通过有监督的训练有效地学习整个文本的标签，同时以无监督的方式感知段落的标签并估计它们对长文本标签的贡献。作为一种通用分类器，SWIPE可以支持不同的编码器，在分类上优于现有技术。

    Because of the inevitable cost and complexity of transformer and pre-trained models, efficiency concerns are raised for long text classification. Meanwhile, in the highly sensitive domains, e.g., healthcare and legal long-text mining, potential model distrust, yet underrated and underexplored, may hatch vital apprehension. Existing methods generally segment the long text, encode each piece with the pre-trained model, and use attention or RNNs to obtain long text representation for classification. In this work, we propose a simple but effective model, Segment-aWare multIdimensional PErceptron (SWIPE), to replace attention/RNNs in the above framework. Unlike prior efforts, SWIPE can effectively learn the label of the entire text with supervised training, while perceive the labels of the segments and estimate their contributions to the long-text labeling in an unsupervised manner. As a general classifier, SWIPE can endorse different encoders, and it outperforms SOTA models in terms of cla
    
[^27]: 时空语义零膨胀城市异常预测

    Spatiotemporal and Semantic Zero-inflated Urban Anomaly Prediction. (arXiv:2304.01569v1 [cs.LG])

    [http://arxiv.org/abs/2304.01569](http://arxiv.org/abs/2304.01569)

    提出了STS模型来预测城市异常，解决了由于异常数据稀疏零膨胀导致的问题，并且可以统一预测多种异常，在交通事故和犯罪预测数据集上表现良好。

    

    城市异常预测，如交通事故预测和犯罪预测，对智慧城市的安全和维护至关重要。现有的方法通常使用深度学习来捕捉空间和时间维度内的内部依赖关系。然而，仍存在许多关键挑战，例如，由于城市异常发生频率低导致的稀疏零膨胀数据（可能会在真实世界的数据集上表现不佳），以及跨越空间，时间和语义维度的异常模式的内部和互间依赖性。此外，还需要探索统一的方法来预测多种异常。在本文中，我们提出了STS来共同捕捉三个维度内的模式和影响因素之间的内部和互间依赖性。此外，我们使用一个带有定制损失函数的多任务预测模块来解决零膨胀问题。为了验证模型的有效性，我们将其应用于两个城市异常数据集：交通事故预测和犯罪预测。实验结果表明，我们的方法优于一系列基线模型。

    Urban anomaly predictions, such as traffic accident prediction and crime prediction, are of vital importance to smart city security and maintenance. Existing methods typically use deep learning to capture the intra-dependencies in spatial and temporal dimensions. However, numerous key challenges remain unsolved, for instance, sparse zero-inflated data due to urban anomalies occurring with low frequency (which can lead to poor performance on real-world datasets), and both intra- and inter-dependencies of abnormal patterns across spatial, temporal, and semantic dimensions. Moreover, a unified approach to predict multiple kinds of anomaly is left to explore. In this paper, we propose STS to jointly capture the intra- and inter-dependencies between the patterns and the influential factors in three dimensions. Further, we use a multi-task prediction module with a customized loss function to solve the zero-inflated issue. To verify the effectiveness of the model, we apply it to two urban ano
    
[^28]: G2PTL：适用于物流系统的交付地址预训练模型及其应用

    G2PTL: A Pre-trained Model for Delivery Address and its Applications in Logistics System. (arXiv:2304.01559v1 [cs.AI])

    [http://arxiv.org/abs/2304.01559](http://arxiv.org/abs/2304.01559)

    G2PTL是一种面向物流领域的预训练模型，结合了文本预训练的语义学习能力和图建模的地理关系编码能力，能有效地编码交付地址中的位置信息，并在物流系统中具有广泛的应用前景。

    

    作为物流系统的数据基础，基于文本的交付地址包含丰富且关键的位置信息。如何有效地编码交付地址是提高后续任务在物流系统中性能的核心任务。面向自然语言处理(NLP)的预训练模型(PTMs)已成为编码文本中语义信息的主要工具。虽然在许多任务中相当有前途，但这些基于NLP的PTMs未能编码交付地址中的地理知识，这在物流系统(如菜鸟系统)中大大削弱了与交付相关的任务的性能。为解决这个问题，我们提出了一种面向物流领域的域特定预训练模型，名为G2PTL，即交付地址地理关系-图预训练模型。G2PTL将文本预训练的语义学习能力与图建模的地理关系编码能力相结合。具体而言，我们首先利用真实的物流交付数据构建地理图，然后在图结构化数据上对模型进行预训练。实验结果表明，G2PTL能有效地编码基于文本的交付地址中的位置信息，并在与交付地址处理相关的任务中优于通用PTMs。

    Text-based delivery addresses, as the data foundation for logistics systems, contain abundant and crucial location information. How to effectively encode the delivery address is a core task to boost the performance of downstream tasks in the logistics system. Pre-trained Models (PTMs) designed for Natural Language Process (NLP) have emerged as the dominant tools for encoding semantic information in text. Though promising, those NLP-based PTMs fall short of encoding geographic knowledge in the delivery address, which considerably trims down the performance of delivery-related tasks in logistic systems such as Cainiao. To tackle the above problem, we propose a domain-specific pre-trained model, named G2PTL, a Geography-Graph Pre-trained model for delivery address in Logistics field. G2PTL combines the semantic learning capabilities of text pre-training with the geographical-relationship encoding abilities of graph modeling. Specifically, we first utilize real-world logistics delivery dat
    
[^29]: 边缘AI设备上的实时驾驶员监控系统

    Real-time Driver Monitoring Systems on Edge AI Device. (arXiv:2304.01555v1 [cs.CV])

    [http://arxiv.org/abs/2304.01555](http://arxiv.org/abs/2304.01555)

    本论文介绍了一种运行在边缘AI设备上的实时驾驶员监控系统，该系统经过模型手术，在硬件加速器的帮助下实现了高帧率的处理效果。

    

    随着司机不注意力导致路上事故的增加，自动化驾驶员监控系统(DMS)得到了越来越多的认可。在本报告中，我们介绍了一个运行于硬件加速器的边缘设备上的实时DMS系统。该系统由红外摄像头记录驾驶员的画面和边缘设备处理数据组成。为了在边缘设备上成功移植深度学习模型，充分利用硬件加速器，进行了模型手术。最终的DMS系统在TI-TDA4VM边缘设备上实现了63帧每秒(FPS)的效果。

    As road accident cases are increasing due to the inattention of the driver, automated driver monitoring systems (DMS) have gained an increase in acceptance. In this report, we present a real-time DMS system that runs on a hardware-accelerator-based edge device. The system consists of an InfraRed camera to record the driver footage and an edge device to process the data. To successfully port the deep learning models to run on the edge device taking full advantage of the hardware accelerators, model surgery was performed. The final DMS system achieves 63 frames per second (FPS) on the TI-TDA4VM edge device.
    
[^30]: \emph{MEnsA}: 三维点云无监督多目标域自适应的混合集成平均方法

    \emph{MEnsA}: Mix-up Ensemble Average for Unsupervised Multi Target Domain Adaptation on 3D Point Clouds. (arXiv:2304.01554v1 [cs.CV])

    [http://arxiv.org/abs/2304.01554](http://arxiv.org/abs/2304.01554)

    本文提出了一种新的MTDA方法，名为\emph{MEnsA}，利用混合集成平均方法提高了域自适应的性能。

    

    无监督域自适应（UDA）解决了标记源域和未标记目标域之间分布差异的问题。虽然单目标域自适应（STDA）已经在2D和3D视觉文献中得到了广泛研究，但是在3D数据的多目标域自适应（MTDA）方面几乎没有得到研究。本文提出了一种名为\emph{{\bf M}ixup {\bf Ens}emble {\bf A}verage}或简称{\bf \emph{MEnsA}}的混合集成平均方法，将所有领域的特征表示混合在一起，以实现更好的域自适应性能的MTDA基线。通过混合表示，我们使用域分类器在共享的潜在空间中提高了源域特征表示与目标域特征表示的区分能力。在具有挑战性的PointDA-10数据集上进行了大量实验验证。

    Unsupervised domain adaptation (UDA) addresses the problem of distribution shift between the unlabeled target domain and labelled source domain. While the single target domain adaptation (STDA) is well studied in both 2D and 3D vision literature, multi-target domain adaptation (MTDA) is barely explored for 3D data despite its wide real-world applications such as autonomous driving systems for various geographical and climatic conditions. We establish an MTDA baseline for 3D point cloud data by proposing to mix the feature representations from all domains together to achieve better domain adaptation performance by an ensemble average, which we call \emph{{\bf M}ixup {\bf Ens}emble {\bf A}verage} or {\bf \emph{MEnsA}}. With the mixed representation, we use a domain classifier to improve at distinguishing the feature representations of source domain from those of target domains in a shared latent space. In extensive empirical validations on the challenging PointDA-10 dataset, we showcase 
    
[^31]: 对策略更新的正则化以稳定均场博弈

    Regularization of the policy updates for stabilizing Mean Field Games. (arXiv:2304.01547v1 [cs.AI])

    [http://arxiv.org/abs/2304.01547](http://arxiv.org/abs/2304.01547)

    本文提出了一种均场近端策略优化算法（MF-PPO），以稳定深度强化学习在均场博弈中的应用，并在OpenSpiel框架中进行了实验验证。

    

    本文研究非合作多智能体强化学习(MARL)，其中多个智能体在同一环境中相互作用，目标是最大化个体回报。当智能体数量扩大时，由于许多智能体引入的非静止性，会产生挑战。为了解决这个问题，均场博弈（MFG）依靠对称性和同质性假设，近似具有很大群体的博弈。最近，深度强化学习被用于将MFG扩展到具有更多状态的博弈中。目前的方法依赖于平滑技术，如对q值或均场分布更新进行平均。本文提出了一种在均场策略上进行近似更新以稳定学习的不同方法。我们将我们的算法命名为均场近端策略优化（MF-PPO），并在OpenSpiel框架中经验性地展示了我们方法的有效性。

    This work studies non-cooperative Multi-Agent Reinforcement Learning (MARL) where multiple agents interact in the same environment and whose goal is to maximize the individual returns. Challenges arise when scaling up the number of agents due to the resultant non-stationarity that the many agents introduce. In order to address this issue, Mean Field Games (MFG) rely on the symmetry and homogeneity assumptions to approximate games with very large populations. Recently, deep Reinforcement Learning has been used to scale MFG to games with larger number of states. Current methods rely on smoothing techniques such as averaging the q-values or the updates on the mean-field distribution. This work presents a different approach to stabilize the learning based on proximal updates on the mean-field policy. We name our algorithm \textit{Mean Field Proximal Policy Optimization (MF-PPO)}, and we empirically show the effectiveness of our method in the OpenSpiel framework.
    
[^32]: 解析可解释人工智能在医疗保健领域的简要评论

    A Brief Review of Explainable Artificial Intelligence in Healthcare. (arXiv:2304.01543v1 [cs.AI])

    [http://arxiv.org/abs/2304.01543](http://arxiv.org/abs/2304.01543)

    这篇文章系统评估了可解释人工智能在医疗保健领域的各种挑战和方法，旨在提高AI模型的可解释性，使其对临床医生更加透明可信。

    

    XAI是指构建AI应用程序的技术和方法，可以帮助最终用户解释AI模型的输出和预测。在高风险决策情境中（如医学领域）使用黑盒AI应用程序增加了透明性和可解释性的需求，因为错误的预测可能会产生严重后果。模型的可解释性对于在医疗保健实践中成功部署AI模型至关重要。需要让临床医生透明地了解AI应用程序的基本推理过程以获得他们的信任。本文系统地评估了可解释人工智能在医疗保健领域中的方方面面和挑战。本研究的主要目标是回顾各种XAI方法、其挑战以及医疗保健中的相关机器学习模型。这些方法分为六类：特征导向方法、全局方法、概念模型、代理模型、本地像素方法和以人为中心的方法。

    XAI refers to the techniques and methods for building AI applications which assist end users to interpret output and predictions of AI models. Black box AI applications in high-stakes decision-making situations, such as medical domain have increased the demand for transparency and explainability since wrong predictions may have severe consequences. Model explainability and interpretability are vital successful deployment of AI models in healthcare practices. AI applications' underlying reasoning needs to be transparent to clinicians in order to gain their trust. This paper presents a systematic review of XAI aspects and challenges in the healthcare domain. The primary goals of this study are to review various XAI methods, their challenges, and related machine learning models in healthcare. The methods are discussed under six categories: Features-oriented methods, global methods, concept models, surrogate models, local pixel-based methods, and human-centric methods. Most importantly, th
    
[^33]: 在可计算逻辑 Web 中实现动态规划

    Implementing Dynamic Programming in Computability Logic Web. (arXiv:2304.01539v1 [cs.AI])

    [http://arxiv.org/abs/2304.01539](http://arxiv.org/abs/2304.01539)

    CoLweb是一种优秀的算法语言，可以通过高层次、证明携带，分布式风格的方法统一多种算法设计方法，而且在Horn子句定义细化方面有很好的应用。

    

    我们提出了一种新的算法定义及其相应的算法语言 CoLweb。CoLweb 的优点在于它使得算法设计更加灵活，强制我们采用高层次、证明携带，分布式风格的算法设计方法，适用于分布式与非分布式计算。我们认为，这种方法简化了算法设计，并将其他方法统一起来，包括递归逻辑/函数算法、命令式算法、面向对象的命令式算法、神经网络、交互式网络、证明携带代码等。作为应用，我们将 Horn 子句定义细化为两种类型：盲量化的全量化定义（BUQ）和并行量化的全量化定义（PUQ）。BUQ 定义对应于传统的定义，例如 Prolog 中的定义，其中知识库不会扩展，其证明过程基于向后链接。另一方面，在 PUQ 定义中，知识库正在扩展。

    We present a novel definition of an algorithm and its corresponding algorithm language called CoLweb. The merit of CoLweb [1] is that it makes algorithm design so versatile. That is, it forces us to a high-level, proof-carrying, distributed-style approach to algorithm design for both non-distributed computing and distributed one. We argue that this approach simplifies algorithm design. In addition, it unifies other approaches including recursive logical/functional algorithms, imperative algorithms, object-oriented imperative algorithms, neural-nets, interaction nets, proof-carrying code, etc. As an application, we refine Horn clause definitions into two kinds: blind-univerally-quantified (BUQ) ones and parallel-universally-quantified (PUQ) ones. BUQ definitions corresponds to the traditional ones such as those in Prolog where knowledgebase is $not$ expanding and its proof procedure is based on the backward chaining. On the other hand, in PUQ definitions, knowledgebase is $expanding$ an
    
[^34]: 多模态神经过程用于不确定性估计

    Multimodal Neural Processes for Uncertainty Estimation. (arXiv:2304.01518v1 [cs.LG])

    [http://arxiv.org/abs/2304.01518](http://arxiv.org/abs/2304.01518)

    本论文提出了一种新的神经过程模型，即多模态神经过程，用于对多模态数据进行不确定性估计，该模型具有动态上下文记忆、多模态贝叶斯聚合和校准预测的注意机制，经实验表明在多模态不确定性估计方面性能最先进，对于噪声样本具有良好抵抗能力，并且对于领域之外的检测是可靠的。

    

    神经过程( Neural Processes, NPs)将参数化深度神经网络的表示能力和非参数高斯过程可靠的不确定性估计结合在了一起。虽然最近NPs的发展已经在回归和分类方面取得了成功，但是如何将NPs适应多模态数据尚未受到仔细的研究。我们首次提出了一种新的NP家族模型，用于多模态不确定性估计，即多模态神经过程。我们通过一种整体的、基于原则的方法，开发了一个由分类误差更新的动态上下文记忆，一个聚合多模态表示的多模态贝叶斯聚合机制，以及一个用于校准预测的新的注意机制。在广泛的经验评估中，我们的方法实现了最先进的多模态不确定性估计性能，展示了它的吸引力，即能够抵抗噪声样本的干扰，并可靠地在领域之外进行检测。

    Neural processes (NPs) have brought the representation power of parametric deep neural networks and the reliable uncertainty estimation of non-parametric Gaussian processes together. Although recent development of NPs has shown success in both regression and classification, how to adapt NPs to multimodal data has not be carefully studied. For the first time, we propose a new model of NP family for multimodal uncertainty estimation, namely Multimodal Neural Processes. In a holistic and principled way, we develop a dynamic context memory updated by the classification error, a multimodal Bayesian aggregation mechanism to aggregate multimodal representations, and a new attention mechanism for calibrated predictions. In extensive empirical evaluation, our method achieves the state-of-the-art multimodal uncertainty estimation performance, showing its appealing ability of being robust against noisy samples and reliable in out-of-domain detection.
    
[^35]: 全球时间序列预测中的概念漂移处理

    Handling Concept Drift in Global Time Series Forecasting. (arXiv:2304.01512v1 [cs.LG])

    [http://arxiv.org/abs/2304.01512](http://arxiv.org/abs/2304.01512)

    本文提出两种新的概念漂移处理方法，应用于全球时间序列预测，填补了处理分类领域中概念漂移方法的空白。

    

    基于机器学习的时间序列预测模型通常需要并假设数据在产生预测时具有一定程度的平稳性。然而，在许多实际情况下，数据分布不是稳态的，而它们随着时间的推移而改变，从而降低了预测模型的准确性，这在机器学习文献中被称为概念漂移。处理预测中的概念漂移对于许多现今使用的机器学习模型至关重要。本文探讨了用于全球预测模型（GFM）中处理概念漂移的方法，并提出了两种新的概念漂移处理方法：误差贡献加权（ECW）和梯度下降加权（GDW），基于连续的自适应权重概念使用两个单独训练的预测模型。

    Machine learning (ML) based time series forecasting models often require and assume certain degrees of stationarity in the data when producing forecasts. However, in many real-world situations, the data distributions are not stationary and they can change over time while reducing the accuracy of the forecasting models, which in the ML literature is known as concept drift. Handling concept drift in forecasting is essential for many ML methods in use nowadays, however, the prior work only proposes methods to handle concept drift in the classification domain. To fill this gap, we explore concept drift handling methods in particular for Global Forecasting Models (GFM) which recently have gained popularity in the forecasting domain. We propose two new concept drift handling methods, namely: Error Contribution Weighting (ECW) and Gradient Descent Weighting (GDW), based on a continuous adaptive weighting concept. These methods use two forecasting models which are separately trained with the m
    
[^36]: EPVT: 基于环境感知的提示视觉Transformer在皮肤病变识别领域一般化中的应用

    EPVT: Environment-aware Prompt Vision Transformer for Domain Generalization in Skin Lesion Recognition. (arXiv:2304.01508v1 [cs.CV])

    [http://arxiv.org/abs/2304.01508](http://arxiv.org/abs/2304.01508)

    EPVT是一种基于环境感知的提示视觉Transformer，用于解决皮肤病变识别中深度神经网络可能过度依赖疾病不相关图像特征的问题，通过嵌入一组领域提示和一个共享提示来进行领域一般化，并且引入了领域提示生成器促进知识共享。

    

    利用深度学习进行皮肤病变识别已取得重大进展，而在现实世界场景中部署这些系统的需求不断增加。然而，最近的研究表明，用于皮肤病变识别的深度神经网络可能过度依赖于与疾病不相关的图像特征（如暗角、浓密毛发），导致在看不见的环境中表现不佳。为了解决这个问题，我们提出了一种新颖的领域一般化方法——EPVT，它将提示嵌入到Vision Transformer中，以协同学习来自不同领域的知识。具体而言，EPVT利用一组领域提示，每个领域提示都扮演领域专家的角色，以捕获领域特定的知识；以及一个共享提示来获得整个数据集的通用知识。为了促进知识共享和不同提示之间的交互，我们引入了一个领域提示生成器，它使得领域提示与共享提示之间可以进行低秩乘性更新。

    Skin lesion recognition using deep learning has made remarkable progress, and there is an increasing need for deploying these systems in real-world scenarios. However, recent research has revealed that deep neural networks for skin lesion recognition may overly depend on disease-irrelevant image artifacts (i.e. dark corners, dense hairs), leading to poor generalization in unseen environments. To address this issue, we propose a novel domain generalization method called EPVT, which involves embedding prompts into the vision transformer to collaboratively learn knowledge from diverse domains. Concretely, EPVT leverages a set of domain prompts, each of which plays as a domain expert, to capture domain-specific knowledge; and a shared prompt for general knowledge over the entire dataset. To facilitate knowledge sharing and the interaction of different prompts, we introduce a domain prompt generator that enables low-rank multiplicative updates between domain prompts and the shared prompt. A
    
[^37]: RARE：鲁棒性抗干扰的掩码图自编码器

    RARE: Robust Masked Graph Autoencoder. (arXiv:2304.01507v1 [cs.LG])

    [http://arxiv.org/abs/2304.01507](http://arxiv.org/abs/2304.01507)

    RARE是一种鲁棒性抗干扰的掩码图自编码器，通过在高阶潜在特征空间中进行掩码和重构节点样本来提高推断掩码数据的确定性和自监督机制的可靠性，并在下游任务中优于现有的SGP方法。

    

    掩码图自编码器（MGAE）由于其简单和有效的特性，在自监督图预训练（SGP）方面已成为一种很有前途的范例。然而，现有的方法在原始数据空间中执行掩码-重构操作，类似于计算机视觉（CV）和自然语言处理（NLP）领域，而忽略了图数据的重要非欧几里得属性。结果，高度不稳定的局部连接结构大大增加了推断掩码数据的不确定性，并降低了利用自监督信号的可靠性，导致下游评估中的表示效果不佳。为了解决这个问题，我们提出了一种新的SGP方法，称为Robust mAsked gRaph autoEncoder（RARE），通过高阶潜在特征空间中更多的掩码和重构节点样本来提高推断掩码数据的确定性和自监督机制的可靠性。通过理论和实证分析，我们发现RARE能够有效地捕捉图数据的内在结构，并在不同的下游任务中优于现有的SGP方法。

    Masked graph autoencoder (MGAE) has emerged as a promising self-supervised graph pre-training (SGP) paradigm due to its simplicity and effectiveness. However, existing efforts perform the mask-then-reconstruct operation in the raw data space as is done in computer vision (CV) and natural language processing (NLP) areas, while neglecting the important non-Euclidean property of graph data. As a result, the highly unstable local connection structures largely increase the uncertainty in inferring masked data and decrease the reliability of the exploited self-supervision signals, leading to inferior representations for downstream evaluations. To address this issue, we propose a novel SGP method termed Robust mAsked gRaph autoEncoder (RARE) to improve the certainty in inferring masked data and the reliability of the self-supervision mechanism by further masking and reconstructing node samples in the high-order latent feature space. Through both theoretical and empirical analyses, we have dis
    
[^38]: OneShotSTL：一种单次季节趋势分解方法，用于在线时间序列异常检测和预测

    OneShotSTL: One-Shot Seasonal-Trend Decomposition For Online Time Series Anomaly Detection And Forecasting. (arXiv:2304.01506v1 [cs.LG])

    [http://arxiv.org/abs/2304.01506](http://arxiv.org/abs/2304.01506)

    OneShotSTL提出了一种高效准确的算法，用于在线时间序列分解，在处理时间上仅需O(1)的更新时间复杂度，并可同时保持较高的精度，解决了现有批处理方法无法支持实时分析的挑战。

    

    季节趋势分解是时间序列分析中最基本的概念之一，它支持包括时间序列异常检测和预测在内的各种下游任务。然而，现有的分解方法依赖于批处理，时间复杂度为O(W)，其中W是时间窗口内的数据点数。因此，它们不能始终有效地支持需要低处理延迟的实时分析。为了解决这一挑战，我们提出了OneShotSTL，这是一种高效和准确的算法，可以在线上对时间序列进行分解，更新时间复杂度为O(1)。OneShotSTL比批处理方法快10倍以上，精度与最佳对手相当。广泛的实验在下游时间序列异常检测和预测任务的真实基准数据集上表明，OneShotSTL比现有技术快10倍以上，同时仍提供相当甚至更好的精度。

    Seasonal-trend decomposition is one of the most fundamental concepts in time series analysis that supports various downstream tasks, including time series anomaly detection and forecasting. However, existing decomposition methods rely on batch processing with a time complexity of O(W), where W is the number of data points within a time window. Therefore, they cannot always efficiently support real-time analysis that demands low processing delay. To address this challenge, we propose OneShotSTL, an efficient and accurate algorithm that can decompose time series online with an update time complexity of O(1). OneShotSTL is more than $1,000$ times faster than the batch methods, with accuracy comparable to the best counterparts. Extensive experiments on real-world benchmark datasets for downstream time series anomaly detection and forecasting tasks demonstrate that OneShotSTL is from 10 to over 1,000 times faster than the state-of-the-art methods, while still providing comparable or even be
    
[^39]: 从 GPT-4 到 GPT-3.5：“拿起我的手术刀”——评估 OpenAI 的 GPT 在整形外科住院医师培训考试中的能力

    GPT-4 to GPT-3.5: 'Hold My Scalpel' -- A Look at the Competency of OpenAI's GPT on the Plastic Surgery In-Service Training Exam. (arXiv:2304.01503v1 [cs.AI])

    [http://arxiv.org/abs/2304.01503](http://arxiv.org/abs/2304.01503)

    本研究评估了 OpenAI 的 GPT 在整形外科住院医师培训考试上的能力，发现相比于 GPT-3.5，GPT-4 有了显著提高。考试得分与成为获得认证的整形外科医生所需的书面考试高度相关。

    

    整形外科住院医师培训考试 (PSITE) 是评估住院医师熟练程度的重要指标，也是评估 OpenAI 的 GPT 的有用基准。与 GPT-4 技术文章中展示的许多模拟测试或练习题不同，这里评估的多项选择题是真实的 PSITE 问题。这些问题提供了整形外科医生在实践中经常遇到的现实临床案例，得分高度相关于通过成为获得认证的整形外科医生所需的书面考试。我们的评估显示，GPT-4（没有视觉）相对于 GPT-3.5 有了显著的提高，分别将 2022 年和 2021 年的考试得分从第 8 百分位数提高到第 88 百分位数和第 3 百分位数提高到第 99 百分位数。2023 年的 PSITE 的最终结果将于 2023 年 4 月 11 日公布，这是一个令人兴奋的时刻，我们将继续进行研究并使用新的考试进行评估。我们的评估流程已准备就绪，只要考试发布，我们就可以立刻进行评估。

    The Plastic Surgery In-Service Training Exam (PSITE) is an important indicator of resident proficiency and serves as a useful benchmark for evaluating OpenAI's GPT. Unlike many of the simulated tests or practice questions shown in the GPT-4 Technical Paper, the multiple-choice questions evaluated here are authentic PSITE questions. These questions offer realistic clinical vignettes that a plastic surgeon commonly encounters in practice and scores highly correlate with passing the written boards required to become a Board Certified Plastic Surgeon. Our evaluation shows dramatic improvement of GPT-4 (without vision) over GPT-3.5 with both the 2022 and 2021 exams respectively increasing the score from 8th to 88th percentile and 3rd to 99th percentile. The final results of the 2023 PSITE are set to be released on April 11, 2023, and this is an exciting moment to continue our research with a fresh exam. Our evaluation pipeline is ready for the moment that the exam is released so long as we 
    
[^40]: 聊天GPT，还是不聊天GPT：这是一个问题！

    To ChatGPT, or not to ChatGPT: That is the question!. (arXiv:2304.01487v1 [cs.LG])

    [http://arxiv.org/abs/2304.01487](http://arxiv.org/abs/2304.01487)

    研究评估了聊天GPT检测中的最新技术和其他AI生成文本检测工具的表现，并提出区分人工生成和AI生成文本的重要性。

    

    聊天GPT已经成为一种全球感知。随着聊天GPT和其他大型语言模型（LLM）的出现，对于他们的误用的担忧也增加了，例如传播虚假消息，抄袭，操纵公众舆论，欺骗和欺诈。因此，区分人工生成和AI生成的文本变得越来越重要。研究人员提出了各种检测方法，从基本的二元分类器到更复杂的深度学习模型。一些检测技术依赖于统计特征或句法模式，而其他一些则包含语义或上下文信息以提高准确性。本研究的主要目标是对聊天GPT检测中最新技术进行全面和现代化的评估。此外，我们还评估了其他未专门声称检测聊天GPT生成内容的AI生成文本检测工具以评估它们在检测聊天GPT生成内容方面的表现。在我们的评估中，我们使用了一个包含人工编写和聊天GPT生成的文本的大型数据集。

    ChatGPT has become a global sensation. As ChatGPT and other Large Language Models (LLMs) emerge, concerns of misusing them in various ways increase, such as disseminating fake news, plagiarism, manipulating public opinion, cheating, and fraud. Hence, distinguishing AI-generated from human-generated becomes increasingly essential. Researchers have proposed various detection methodologies, ranging from basic binary classifiers to more complex deep-learning models. Some detection techniques rely on statistical characteristics or syntactic patterns, while others incorporate semantic or contextual information to improve accuracy. The primary objective of this study is to provide a comprehensive and contemporary assessment of the most recent techniques in ChatGPT detection. Additionally, we evaluated other AI-generated text detection tools that do not specifically claim to detect ChatGPT-generated content to assess their performance in detecting ChatGPT-generated content. For our evaluation,
    
[^41]: DLRover：一种具有自动作业资源推荐的弹性深度训练扩展

    DLRover: An Elastic Deep Training Extension with Auto Job Resource Recommendation. (arXiv:2304.01468v1 [cs.DC])

    [http://arxiv.org/abs/2304.01468](http://arxiv.org/abs/2304.01468)

    DLRover是一个自动配置初始资源并实时调整资源的分布式深度学习框架，解决了资源共享和手动配置带来的问题。

    

    由于在云平台上进行资源共享可以提高资源利用率并降低总体成本，因此云仍然是分布式深度学习（DL）训练作业的流行平台。然而，此类共享也为DL训练作业带来了多重挑战，例如高优先级作业可能会影响、甚至中断低优先级作业。同时，大多数现有的分布式DL训练系统要求用户在作业提交之前手动配置作业的资源（即分配给每个节点的节点数和CPU、内存等资源），并且不能在运行时调整作业的资源。作业的资源配置会深刻影响该作业的性能（例如训练吞吐量、资源利用率和完成率）。然而，这通常会导致作业性能不佳，因为用户在大多数情况下无法提供最佳的资源配置。DLRover是一种分布式DL框架，可以自动配置DL作业的初始资源并动态调整作业的资源。

    The cloud is still a popular platform for distributed deep learning (DL) training jobs since resource sharing in the cloud can improve resource utilization and reduce overall costs. However, such sharing also brings multiple challenges for DL training jobs, e.g., high-priority jobs could impact, even interrupt, low-priority jobs. Meanwhile, most existing distributed DL training systems require users to configure the resources (i.e., the number of nodes and resources like CPU and memory allocated to each node) of jobs manually before job submission and can not adjust the job's resources during the runtime. The resource configuration of a job deeply affect this job's performance (e.g., training throughput, resource utilization, and completion rate). However, this usually leads to poor performance of jobs since users fail to provide optimal resource configuration in most cases. \system~is a distributed DL framework can auto-configure a DL job's initial resources and dynamically tune the j
    
[^42]: 时间-空间-频率特征融合的3通道运动想象分类

    Time-space-frequency feature Fusion for 3-channel motor imagery classification. (arXiv:2304.01461v1 [cs.LG])

    [http://arxiv.org/abs/2304.01461](http://arxiv.org/abs/2304.01461)

    本文提出了一种新网络架构TSFF-Net，将时间-空间-频率特征融合，解决了单模特征提取网络在时间序列或时间-频率模态下的限制。TSFF-Net包括时间-频率表示、时间-频率特征提取、时间-空间特征提取和特征融合与分类四个主要组件。

    

    低通道EEG设备对于便携和娱乐应用至关重要，然而EEG低空间分辨率存在挑战，难以解码低通道运动想象。本研究引入TSFF-Net，一种新颖的网络架构，将时间-空间-频率特征融合，在时间序列或时间-频率模态下的单模特征提取网络的限制下发挥作用。TSFF-Net包括四个主要组件：时间-频率表示、时间-频率特征提取、时间-空间特征提取和特征融合与分类。时间-频率表示和特征提取将原始EEG信号转换为时间-频率谱图并提取相关特征。时空网络将时间序列EEG试验作为输入处理，并提取时间-空间特征。特征融合采用MMD损失在再生核希尔伯特空间中约束时间-频率和时间-空间特征的分布。

    Low-channel EEG devices are crucial for portable and entertainment applications. However, the low spatial resolution of EEG presents challenges in decoding low-channel motor imagery. This study introduces TSFF-Net, a novel network architecture that integrates time-space-frequency features, effectively compensating for the limitations of single-mode feature extraction networks based on time-series or time-frequency modalities. TSFF-Net comprises four main components: time-frequency representation, time-frequency feature extraction, time-space feature extraction, and feature fusion and classification. Time-frequency representation and feature extraction transform raw EEG signals into time-frequency spectrograms and extract relevant features. The time-space network processes time-series EEG trials as input and extracts temporal-spatial features. Feature fusion employs MMD loss to constrain the distribution of time-frequency and time-space features in the Reproducing Kernel Hilbert Space, 
    
[^43]: 探索视觉-语言模型在不平衡学习中的应用

    Exploring Vision-Language Models for Imbalanced Learning. (arXiv:2304.01457v1 [cs.AI])

    [http://arxiv.org/abs/2304.01457](http://arxiv.org/abs/2304.01457)

    本文探索了如何通过向视觉-语言模型添加轻量级解码器和利用不平衡算法来改进性能，实验表明改进后的VLM在iNaturalist18、CIFAR-100和Visual Genome数据集上分类准确度显著提高，特别是对于少数类，性能提升很大。

    

    使用对比语言-图像预训练的视觉-语言模型（VLMs）已经显示出有希望的零样本分类表现。然而，在不平衡数据集上，它们的性能相对较差，在训练数据集中类的分布倾斜，导致在预测少数类方面性能不佳。我们提出向VLM添加轻量级解码器，以避免由于大量类别导致的内存不足问题，并捕捉尾部类别的微妙特征。然后，我们探索了利用提示调整、微调以及加入不平衡算法（例如Focal Loss、Balanced SoftMax和Distribution Alignment）来改进VLM。实验表明，在使用解码器和不平衡方法时，VLM的性能可以进一步提高。具体而言，我们改进的VLM在iNaturalist18、CIFAR-100和Visual Genome数据集上的分类准确度平均提高了6.58%、69.82%和10.43%。

    Vision-Language models (VLMs) that use contrastive language-image pre-training have shown promising zero-shot classification performance. However, their performance on imbalanced dataset is relatively poor, where the distribution of classes in the training dataset is skewed, leading to poor performance in predicting minority classes. For instance, CLIP achieved only 5% accuracy on the iNaturalist18 dataset. We propose to add a lightweight decoder to VLMs to avoid OOM (out of memory) problem caused by large number of classes and capture nuanced features for tail classes. Then, we explore improvements of VLMs using prompt tuning, fine-tuning, and incorporating imbalanced algorithms such as Focal Loss, Balanced SoftMax and Distribution Alignment. Experiments demonstrate that the performance of VLMs can be further boosted when used with decoder and imbalanced methods. Specifically, our improved VLMs significantly outperforms zero-shot classification by an average accuracy of 6.58%, 69.82%,
    
[^44]: 多智能体强化学习中的离线策略行动预测

    Off-Policy Action Anticipation in Multi-Agent Reinforcement Learning. (arXiv:2304.01447v1 [cs.MA])

    [http://arxiv.org/abs/2304.01447](http://arxiv.org/abs/2304.01447)

    本文提出了一个名为OffPA2的新框架，通过离线策略行动预测方法来提高多智能体强化学习中的学习预测效率。

    

    学习预测是多智能体强化学习（MARL）中的一种推理范式，其中智能体预测其他智能体的学习步骤，以提高它们之间的合作。然而，现有的基于高阶梯度（HOG）方法在非可微分博弈或状态空间较大的博弈中效率低下。为了解决这些问题，本文提出了OffPA2框架，利用离线策略行动预测方法来提高学习预测的效率。

    Learning anticipation in Multi-Agent Reinforcement Learning (MARL) is a reasoning paradigm where agents anticipate the learning steps of other agents to improve cooperation among themselves. As MARL uses gradient-based optimization, learning anticipation requires using Higher-Order Gradients (HOG), with so-called HOG methods. Existing HOG methods are based on policy parameter anticipation, i.e., agents anticipate the changes in policy parameters of other agents. Currently, however, these existing HOG methods have only been applied to differentiable games or games with small state spaces. In this work, we demonstrate that in the case of non-differentiable games with large state spaces, existing HOG methods do not perform well and are inefficient due to their inherent limitations related to policy parameter anticipation and multiple sampling stages. To overcome these problems, we propose Off-Policy Action Anticipation (OffPA2), a novel framework that approaches learning anticipation thro
    
[^45]: VNE: 通过操纵特征值分布来提高深度表示的有效方法

    VNE: An Effective Method for Improving Deep Representation by Manipulating Eigenvalue Distribution. (arXiv:2304.01434v1 [cs.CV])

    [http://arxiv.org/abs/2304.01434](http://arxiv.org/abs/2304.01434)

    本文提出了通过规范化表示的von Neumann熵( VNE ) 来改善深度表示的方法，通过操纵特征值分布来优化表示品质，广泛适用于不同的算法，可以增强其领域通用性、元学习、自监督学习和生成模型等方面。

    

    自从深度学习被引入以来，很多表示特性 (如去相关、白化、解缠、秩、等度性和互信息) 已经被研究出来，以提高表示品质。然而，操纵这些特性在实现有效性和普适适用性方面都具有挑战性。为了解决这些限制，我们提出了对表示的von Neumann熵(VNE)进行规范化。首先，我们证明了VNE的数学表述在有效操纵表示自相关矩阵的特征值方面是优越的。然后，我们通过调查领域通用性，元学习，自监督学习和生成模型等方面，证明了它在提高现有先进算法或流行基准算法中的广泛适用性。此外，我们在理论上建立了表示的秩、解缠和等度性的联系。最后，我们提供了讨论。

    Since the introduction of deep learning, a wide scope of representation properties, such as decorrelation, whitening, disentanglement, rank, isotropy, and mutual information, have been studied to improve the quality of representation. However, manipulating such properties can be challenging in terms of implementational effectiveness and general applicability. To address these limitations, we propose to regularize von Neumann entropy~(VNE) of representation. First, we demonstrate that the mathematical formulation of VNE is superior in effectively manipulating the eigenvalues of the representation autocorrelation matrix. Then, we demonstrate that it is widely applicable in improving state-of-the-art algorithms or popular benchmark algorithms by investigating domain-generalization, meta-learning, self-supervised learning, and generative models. In addition, we formally establish theoretical connections with rank, disentanglement, and isotropy of representation. Finally, we provide discuss
    
[^46]: 降低Frank-Wolfe方法中的离散化误差

    Reducing Discretization Error in the Frank-Wolfe Method. (arXiv:2304.01432v1 [math.OC])

    [http://arxiv.org/abs/2304.01432](http://arxiv.org/abs/2304.01432)

    本论文提出了两个改进方法：一个多步的Frank-Wolfe方法，直接应用优化的高阶离散化方案；以及一种具有较少离散化误差的LMO-平均方案，其收敛速率加速到$O(1/k^{3/2})$，从而更好地解决了Frank-Wolfe方法中的离散化误差问题。

    

    Frank-Wolfe算法是结构受限机器学习应用中常用的方法，因其快速迭代复杂度而受欢迎。然而，该方法的一个主要限制是收敛速度缓慢，由于步长方向的不规则震荡而难以加速，即使在接近解的渐近情况下也是如此。我们认为这是离散化的产物；也就是说，Frank-Wolfe的流（即渐近小步长情况下的轨迹）不会出现不规则震荡，因此减少离散化误差将与产生更稳定的方法和更好的收敛特性相辅相成。我们提出了两个改进：一个多步Frank-Wolfe方法，直接应用优化的高阶离散化方案；和一个具有降低离散化误差的LMO-平均方案，其在一般凸集上的局部收敛速率从$O(1/k)$加速到$O(1/k^{3/2})$ 。

    The Frank-Wolfe algorithm is a popular method in structurally constrained machine learning applications, due to its fast per-iteration complexity. However, one major limitation of the method is a slow rate of convergence that is difficult to accelerate due to erratic, zig-zagging step directions, even asymptotically close to the solution. We view this as an artifact of discretization; that is to say, the Frank-Wolfe \emph{flow}, which is its trajectory at asymptotically small step sizes, does not zig-zag, and reducing discretization error will go hand-in-hand in producing a more stabilized method, with better convergence properties. We propose two improvements: a multistep Frank-Wolfe method that directly applies optimized higher-order discretization schemes; and an LMO-averaging scheme with reduced discretization error, and whose local convergence rate over general convex sets accelerates from a rate of $O(1/k)$ to up to $O(1/k^{3/2})$.
    
[^47]: 分离的关注力：基于上下文分离槽的无监督多对象发现

    Divided Attention: Unsupervised Multi-Object Discovery with Contextually Separated Slots. (arXiv:2304.01430v1 [cs.CV])

    [http://arxiv.org/abs/2304.01430](http://arxiv.org/abs/2304.01430)

    该论文提出了一种新的无监督多对象发现方法，通过一种上下文分隔的槽结构来将视觉场分割为独立运动区域，并用对抗性标准来保证解码器无法重构整个光流。

    

    我们提出了一种将视觉场分割为独立运动区域的方法，不需要任何基础真值或监督。它由基于槽关注的对抗条件编码器-解码器架构组成，修改为使用图像作为上下文来解码光流，而不是尝试重构图像本身。在结果的多模式表示中，一种模式（流）将馈送给编码器以产生单独的潜在代码（槽），而另一种模式（图像）将决定解码器从槽生成第一个模式（流）。由于惯常的自编码基于最小化重构误差，并不能防止整个流被编码到一个槽中，因此我们将损失修改为基于上下文信息分离的对抗性标准。

    We introduce a method to segment the visual field into independently moving regions, trained with no ground truth or supervision. It consists of an adversarial conditional encoder-decoder architecture based on Slot Attention, modified to use the image as context to decode optical flow without attempting to reconstruct the image itself. In the resulting multi-modal representation, one modality (flow) feeds the encoder to produce separate latent codes (slots), whereas the other modality (image) conditions the decoder to generate the first (flow) from the slots. This design frees the representation from having to encode complex nuisance variability in the image due to, for instance, illumination and reflectance properties of the scene. Since customary autoencoding based on minimizing the reconstruction error does not preclude the entire flow from being encoded into a single slot, we modify the loss to an adversarial criterion based on Contextual Information Separation. The resulting min-m
    
[^48]: 基于学习的树搜索算法用于在共享空域中实现社交机器人长期导航

    Learned Tree Search for Long-Horizon Social Robot Navigation in Shared Airspace. (arXiv:2304.01428v1 [cs.RO])

    [http://arxiv.org/abs/2304.01428](http://arxiv.org/abs/2304.01428)

    本文提出了一种基于学习的树搜索算法SoRTS，用于在共享空域中实现社交机器人长期导航，并通过FAA认证飞行员的评估证明了其表现与一名熟练的人类飞行员相当，明显优于基准算法。

    

    近年来，对无人机在拥挤动态的共享空间中进行自主操作的需求迅速增长，因此需要开发可信的代理程序以实现无缝安全导航。本文提出了Social Robot Tree Search (SoRTS)，一种用于在社交领域中移动机器人安全导航的算法。SoRTS旨在通过Monte Carlo Tree Search规划器增强现有的社交感知轨迹预测策略，以实现更好的移动机器人下游导航效果。为了评估我们方法的性能，我们选择了一般航空领域的社交导航应用。为了促进这一评估，我们还引入了高保真度的X-Plane ROS（机载操作系统）飞行模拟器，以实现在完全自主操作上的更多研究。通过对26名FAA认证飞行员的行业评估，我们证明了SoRTS的表现与一名熟练的人类飞行员相当，明显优于我们的基准算法。我们进一步补充了这些结果。

    The fast-growing demand for fully autonomous aerial operations in shared spaces necessitates developing trustworthy agents that can safely and seamlessly navigate in crowded, dynamic spaces. In this work, we propose Social Robot Tree Search (SoRTS), an algorithm for the safe navigation of mobile robots in social domains. SoRTS aims to augment existing socially-aware trajectory prediction policies with a Monte Carlo Tree Search planner for improved downstream navigation of mobile robots. To evaluate the performance of our method, we choose the use case of social navigation for general aviation. To aid this evaluation, within this work, we also introduce X-PlaneROS, a high-fidelity aerial simulator, to enable more research in full-scale aerial autonomy. By conducting a user study based on the assessments of 26 FAA certified pilots, we show that SoRTS performs comparably to a competent human pilot, significantly outperforming our baseline algorithm. We further complement these results wit
    
[^49]: 科学家对生成式人工智能在其领域中潜在应用的看法

    Scientists' Perspectives on the Potential for Generative AI in their Fields. (arXiv:2304.01420v1 [cs.CY])

    [http://arxiv.org/abs/2304.01420](http://arxiv.org/abs/2304.01420)

    二十位科学家就生成式人工智能在其学科中的应用进行了讨论，并发现它有助于加速科学发现和提高科学研究的教育和沟通效率。

    

    生成式人工智能模型，包括大型语言模型和包括文本和其他媒体的多模型，即将改变现代生活的许多方面，包括娱乐、教育、公民生活、艺术和一系列职业。生成式人工智能有潜力对许多科学学科的方法和发现速度产生实质性影响。本研究采访了来自各个领域的二十位科学家（包括物理、生命和社会科学），以了解生成式人工智能技术是否或如何能够增加其各自学科的实践的价值，包括AI可能加速科学发现（即研究）的方式，以及其职业的其他方面，包括培养未来学者和传达科学发现。除了确定生成式人工智能增强科学家当前实践的机会外，我们还要求参与者反思

    Generative AI models, including large language models and multimodal models that include text and other media, are on the cusp of transforming many aspects of modern life, including entertainment, education, civic life, the arts, and a range of professions. There is potential for Generative AI to have a substantive impact on the methods and pace of discovery for a range of scientific disciplines. We interviewed twenty scientists from a range of fields (including the physical, life, and social sciences) to gain insight into whether or how Generative AI technologies might add value to the practice of their respective disciplines, including not only ways in which AI might accelerate scientific discovery (i.e., research), but also other aspects of their profession, including the education of future scholars and the communication of scientific findings. In addition to identifying opportunities for Generative AI to augment scientists' current practices, we also asked participants to reflect 
    
[^50]: 实现网络AI Gym，用于自主网络安全操作

    Enabling A Network AI Gym for Autonomous Cyber Agents. (arXiv:2304.01366v1 [cs.AI])

    [http://arxiv.org/abs/2304.01366](http://arxiv.org/abs/2304.01366)

    本文开发了一个统一的训练环境CyGIL，允许网络安全操作自主代理训练。该环境通过对于真实网络的仿真与虚拟环境下大量训练周期的平衡，成功短时间内训练出了全面性的决策能力，为实现真实世界网络安全的RL代理提供有前途的方向。

    

    本文旨在实现应用强化学习和深度强化学习（RL/DRL）的网络安全操作（CyOps）自主代理。所需的RL训练环境特别具有挑战性，因为它必须平衡需要高保真度的真实网络仿真和运行大量训练周期的需求，最好使用模拟器。开发了一个统一的训练环境，即智能学习的网络安全健身房(CyGIL)，其中模拟的CyGIL-S是由模拟的CyGIL-E自动生成的。从初步实验结果来看，CyGIL-S能够在几分钟内训练代理，而在CyGIL-E中需要数天。在CyGIL-S中训练的代理可以直接转移到CyGIL-E，显示了在模拟的“真实”网络中的完全决策组织能力。通过实现离线RL，CyGIL解决方案为利用RL代理在真实世界的网络中提供了一个有前途的方向。

    This work aims to enable autonomous agents for network cyber operations (CyOps) by applying reinforcement and deep reinforcement learning (RL/DRL). The required RL training environment is particularly challenging, as it must balance the need for high-fidelity, best achieved through real network emulation, with the need for running large numbers of training episodes, best achieved using simulation. A unified training environment, namely the Cyber Gym for Intelligent Learning (CyGIL) is developed where an emulated CyGIL-E automatically generates a simulated CyGIL-S. From preliminary experimental results, CyGIL-S is capable to train agents in minutes compared with the days required in CyGIL-E. The agents trained in CyGIL-S are transferrable directly to CyGIL-E showing full decision proficiency in the emulated "real" network. Enabling offline RL, the CyGIL solution presents a promising direction towards sim-to-real for leveraging RL agents in real-world cyber networks.
    
[^51]: 自适应SpikeDeep-分类器:用于实时脑机接口信号处理的自组织自监督机器学习算法

    Adaptive SpikeDeep-Classifier: Self-organizing and self-supervised machine learning algorithm for online spike sorting. (arXiv:2304.01355v1 [q-bio.NC])

    [http://arxiv.org/abs/2304.01355](http://arxiv.org/abs/2304.01355)

    Ada-SpikeDeep-Classifier是一种用于实时脑机接口信号处理的自适应自组织算法，它使用了SpikeDeeptector进行信道选择、Ada-BAR进行信号预处理、OCM进行分类，旨在提高脑-计算机接口的解码效果，并在实验中表现出高精度和强健性。

    

    本研究旨在提高脑-计算机接口的解码效果，通过针对密集微电极阵列数据的处理，提出了一种自适应自组织算法——自适应SpikeDeep-分类器(Ada-SpikeDeepClassifier)。该算法使用SpikeDeeptector进行信道选择，采用自适应背景活动拒绝器(Ada-BAR)进行信号预处理，并采用自监督在线聚类模块(OCM)进行分类。Ada-SpikeDeep-Classifier在模拟和实际数据记录中均表现出高精度和强健性，优于现有的算法。该算法可望扩展到神经科学和机器学习社区的其他神经数据分析任务中。

    Objective. Research on brain-computer interfaces (BCIs) is advancing towards rehabilitating severely disabled patients in the real world. Two key factors for successful decoding of user intentions are the size of implanted microelectrode arrays and a good online spike sorting algorithm. A small but dense microelectrode array with 3072 channels was recently developed for decoding user intentions. The process of spike sorting determines the spike activity (SA) of different sources (neurons) from recorded neural data. Unfortunately, current spike sorting algorithms are unable to handle the massively increasing amount of data from dense microelectrode arrays, making spike sorting a fragile component of the online BCI decoding framework. Approach. We proposed an adaptive and self-organized algorithm for online spike sorting, named Adaptive SpikeDeep-Classifier (Ada-SpikeDeepClassifier), which uses SpikeDeeptector for channel selection, an adaptive background activity rejector (Ada-BAR) for 
    
[^52]: 采用信号处理和深度神经网络的优化EEG情绪检测模型用于脑机接口

    Optimized EEG based mood detection with signal processing and deep neural networks for brain-computer interface. (arXiv:2304.01349v1 [q-bio.NC])

    [http://arxiv.org/abs/2304.01349](http://arxiv.org/abs/2304.01349)

    本论文研究了优化EEG情绪检测模型，通过信号处理和深度神经网络进行脑机接口，通过Savitzky-Golay滤波和独立成分分析对EEG信号进行预处理，实现了 Blackman窗口的傅里叶变换算法，创新提高了分类的准确性。

    

    电子脑图（EEG）是一种非常有前途且广泛应用的程序，通过放大并测量神经元产生的电脉冲并由特殊电极检测头皮上特定点产生的电位来研究大脑信号和活动。它可以用于检测脑部异常、头痛和其他疾病。然而，目前尚有限的研究用于建立智能决策模型以确定EEG与被试情绪的关系。在这项实验中，对28名健康人类被试的EEG信号进行了观察，并试图研究和识别情绪。采用Savitzky-Golay带通滤波和独立成分分析对数据进行了过滤。实现了不同的神经网络算法来分析和分类基于被试情绪的EEG数据。通过使用基于Blackman窗口的傅里叶变换算法，对数据不太重要的权重进行降低以提高分类的准确性。实验表明，新开发的模型在情绪检测的准确性方面胜过现有模型。

    Electroencephalogram (EEG) is a very promising and widely implemented procedure to study brain signals and activities by amplifying and measuring the post-synaptical potential arising from electrical impulses produced by neurons and detected by specialized electrodes attached to specific points in the scalp. It can be studied for detecting brain abnormalities, headaches, and other conditions. However, there are limited studies performed to establish a smart decision-making model to identify EEG's relation with the mood of the subject. In this experiment, EEG signals of 28 healthy human subjects have been observed with consent and attempts have been made to study and recognise moods. Savitzky-Golay band-pass filtering and Independent Component Analysis have been used for data filtration.Different neural network algorithms have been implemented to analyze and classify the EEG data based on the mood of the subject. The model is further optimised by the usage of Blackman window-based Fouri
    
[^53]: 文档相似性算法比较

    A Comparison of Document Similarity Algorithms. (arXiv:2304.01330v1 [cs.CL])

    [http://arxiv.org/abs/2304.01330](http://arxiv.org/abs/2304.01330)

    本研究比较了文档相似性算法，分为三类进行探讨：统计算法、神经网络算法和基于语料库/知识的算法，通过比较最有效的算法来确定哪些算法最有用。

    

    文档相似性是自然语言处理的重要组成部分，最常用于抄袭检测和文本摘要。因此，找到最有效的文档相似性算法对自然语言处理领域有很大的正面影响。本研究旨在研究众多文档相似性算法，并确定哪些算法最有用。本文通过将文档相似性算法分为三类：统计算法、神经网络算法和基于语料库/知识的算法，来探讨最有效的文档相似性算法。我们使用一系列基准数据集和评估方法来比较每个类别中最有效的算法，评估了每个算法可能用于的所有可能领域。

    Document similarity is an important part of Natural Language Processing and is most commonly used for plagiarism-detection and text summarization. Thus, finding the overall most effective document similarity algorithm could have a major positive impact on the field of Natural Language Processing. This report sets out to examine the numerous document similarity algorithms, and determine which ones are the most useful. It addresses the most effective document similarity algorithm by categorizing them into 3 types of document similarity algorithms: statistical algorithms, neural networks, and corpus/knowledge-based algorithms. The most effective algorithms in each category are also compared in our work using a series of benchmark datasets and evaluations that test every possible area that each algorithm could be used in.
    
[^54]: 强化学习中的实证设计

    Empirical Design in Reinforcement Learning. (arXiv:2304.01315v1 [cs.LG])

    [http://arxiv.org/abs/2304.01315](http://arxiv.org/abs/2304.01315)

    本文是一个关于如何进行良好实验的资源，旨在解决强化学习中实证设计的挑战，并弥补实证研究中可能导致的弱的统计证据。

    

    强化学习中的实证设计不是小任务。进行良好实验需要讲究细节，并且在某些时候需要大量计算资源。最近的研究表明，常用算法对超参数设置和实现细节敏感，并且常见的实证做法会导致弱的统计证据。本文不仅呼吁行动，而且是如何在强化学习中进行良好实验的全面资源。

    Empirical design in reinforcement learning is no small task. Running good experiments requires attention to detail and at times significant computational resources. While compute resources available per dollar have continued to grow rapidly, so have the scale of typical experiments in reinforcement learning. It is now common to benchmark agents with millions of parameters against dozens of tasks, each using the equivalent of 30 days of experience. The scale of these experiments often conflict with the need for proper statistical evidence, especially when comparing algorithms. Recent studies have highlighted how popular algorithms are sensitive to hyper-parameter settings and implementation details, and that common empirical practice leads to weak statistical evidence (Machado et al., 2018; Henderson et al., 2018). Here we take this one step further.  This manuscript represents both a call to action, and a comprehensive resource for how to do good experiments in reinforcement learning. 
    
[^55]: 基于核凸包机的差分隐私学习研究

    Kernel Affine Hull Machines for Differentially Private Learning. (arXiv:2304.01300v1 [cs.LG])

    [http://arxiv.org/abs/2304.01300](http://arxiv.org/abs/2304.01300)

    本文提出了一种基于核凸包机的方法来确保数据隐私保护，同时保留数据结构，用于数据表示学习的分类应用中。为了确保隐私保护学习，还提出了一种新颖的生成虚假数据的方法。

    

    本文探讨了通过学习再生核希尔伯特空间中的点的凸包来表示数据的方法，旨在将数据空间划分为几何体，从而隐藏有关单个数据点的隐私信息，同时保留原始学习问题的结构。为此，我们引入了核凸包机（KAHM），它提供了一种有效的方法来计算从结果有界几何体中的距离度量。KAHM是广泛和深入的自编码器的关键构建块，它们使数据表示学习用于分类应用。为了确保隐私保护学习，我们提出了一种新颖的生成虚假数据的方法，该方法涉及将差分隐私数据样本通过转换过程进行平滑处理。生成的虚假数据不仅保证差分隐私，而且确保KAHM建模误差不大于原始数据误差。

    This paper explores the use of affine hulls of points as a means of representing data via learning in Reproducing Kernel Hilbert Spaces (RKHS), with the goal of partitioning the data space into geometric bodies that conceal privacy-sensitive information about individual data points, while preserving the structure of the original learning problem. To this end, we introduce the Kernel Affine Hull Machine (KAHM), which provides an effective way of computing a distance measure from the resulting bounded geometric body. KAHM is a critical building block in wide and deep autoencoders, which enable data representation learning for classification applications. To ensure privacy-preserving learning, we propose a novel method for generating fabricated data, which involves smoothing differentially private data samples through a transformation process. The resulting fabricated data guarantees not only differential privacy but also ensures that the KAHM modeling error is not larger than that of the
    
[^56]: 有效地对齐跨语言会话任务的提示调整跨语言转移学习

    Efficiently Aligned Cross-Lingual Transfer Learning for Conversational Tasks using Prompt-Tuning. (arXiv:2304.01295v1 [cs.CL])

    [http://arxiv.org/abs/2304.01295](http://arxiv.org/abs/2304.01295)

    本文提出了一个平行大规模多语种会话数据集XSGD，开发了一种有效的基于提示调整的方法来学习对齐提示，同时研究了跨语言任务的NLI-based和vanilla分类器，并在插槽填充和意图分类任务上评估了模型的跨语言泛化能力。

    

    针对自然语言处理任务，跨语言转移的语言模型已被广泛研究，但是对于会话任务的研究相对较少。本文提出了XSGD，这是一个由Schema-Guided Dialogue（SGD）翻译成105种其他语言的平行大规模多语种会话数据集。为了实现对齐的跨语言表示方法，我们开发了一种有效的基于提示调整的方法来学习对齐提示。我们还研究了两种不同的分类器：NLI-based和vanilla分类器，并测试了对齐提示所实现的跨语言能力。我们在两个对话任务（插槽填充和意图分类）上评估了我们模型的跨语言泛化能力。

    Cross-lingual transfer of language models trained on high-resource languages like English has been widely studied for many NLP tasks, but focus on conversational tasks has been rather limited. This is partly due to the high cost of obtaining non-English conversational data, which results in limited coverage. In this work, we introduce XSGD, a parallel and large-scale multilingual conversation dataset that we created by translating the English-only Schema-Guided Dialogue (SGD) dataset (Rastogi et al., 2020) into 105 other languages. XSGD contains approximately 330k utterances per language. To facilitate aligned cross-lingual representations, we develop an efficient prompt-tuning-based method for learning alignment prompts. We also investigate two different classifiers: NLI-based and vanilla classifiers, and test cross-lingual capability enabled by the aligned prompts. We evaluate our model's cross-lingual generalization capabilities on two conversation tasks: slot-filling and intent cla
    
[^57]: 信念、知识和证据

    Belief, knowledge and evidence. (arXiv:2304.01283v1 [cs.LO])

    [http://arxiv.org/abs/2304.01283](http://arxiv.org/abs/2304.01283)

    本研究提出了一个新的逻辑系统，将信念、知识和证据相结合，并以“证据产生信念和知识”的直觉原则为基础，实现了$S5$模态系统与古典认识原则的结合。

    

    我们提出了一个逻辑系统，将众所周知的古典认识概念，即信念和知识，与证据的概念相结合，使得“证据产生信念和知识”的直觉原则得到满足。我们的方法依赖于第一作者以前的研究，他们介绍了包含用于直觉真相（即证明）推理的$S5$样式原理的模态系统，并受到\cite{artpro}的启发，将该系统与直觉主义的信念和知识概念相结合。我们考虑将这个组合系统中的建设性证明概念替换为古典证据概念。这导致逻辑将$S5$模态系统与古典认识原则结合在一起，其中$\square\varphi$在认知意义上解释为“$\varphi$是显然的”。受\cite{lewapal}的启发，与文献中通常的可能世界语义形成对比，我们在此提出一种新的语义。

    We present a logical system that combines the well-known classical epistemic concepts of belief and knowledge with a concept of evidence such that the intuitive principle \textit{`evidence yields belief and knowledge'} is satisfied. Our approach relies on previous works of the first author \cite{lewjlc2, lewigpl, lewapal} who introduced a modal system containing $S5$-style principles for the reasoning about intutionistic truth (i.e. \textit{proof}) and, inspired by \cite{artpro}, combined that system with concepts of \textit{intuitionistic} belief and knowledge. We consider that combined system and replace the constructive concept of \textit{proof} with a classical notion of \textit{evidence}. This results in a logic that combines modal system $S5$ with classical epistemic principles where $\square\varphi$ reads as `$\varphi$ is evident' in an epistemic sense. Inspired by \cite{lewapal}, and in contrast to the usual possible worlds semantics found in the literature, we propose here a r
    
[^58]: 大语言模型时代的安全分析：聊天GPT在STPA案例研究中的应用

    Safety Analysis in the Era of Large Language Models: A Case Study of STPA using ChatGPT. (arXiv:2304.01246v1 [cs.CL])

    [http://arxiv.org/abs/2304.01246](http://arxiv.org/abs/2304.01246)

    本文研究了大型语言模型在系统论过程分析（STPA）中的应用，并采用ChatGPT对自动紧急制动（AEB）系统进行了案例研究。结果表明，重复双工交互方法是最有效的，并显着提高了STPA的质量。本研究证明，LLMs可以应用于安全分析，并为安全关键系统提供有价值的见解。

    

    大型语言模型（LLMs），如ChatGPT和BERT，由于其具有类似于人类的对话，在许多知识领域中具有详细和明确的答案，正在引领一场新的人工智能热潮。虽然LLMs正在迅速应用于许多人工智能应用领域，但我们对以下问题感兴趣：安全关键系统的安全分析是否可以利用LLMs？为了回答这个问题，我们使用ChatGPT对自动紧急制动（AEB）系统的系统论过程分析（STPA）进行了案例研究。STPA是最普遍的危险分析技术之一，但它存在诸多局限性，例如高复杂性和主观性，本文旨在探讨ChatGPT的应用，以解决这些局限性。具体而言，通过考虑其与人类专家的交互，研究了三种将ChatGPT纳入STPA中的方法：一次性单工交互、重复单工交互和重复双工交互。比较结果表明：（i）在没有人类专家的情况下使用ChatGPT不能为STPA提供足够的信息；（ii）一次性单工交互对STPA有帮助，但不如重复交互有效；（iii）重复双工交互一致优于其他方法，并显着提高了STPA的质量。我们的研究表明，LLMs可以应用于安全分析，并为AEB以外的其他安全关键系统提供有价值的见解。

    Large Language Models (LLMs), such as ChatGPT and BERT, are leading a new AI heatwave due to its human-like conversations with detailed and articulate answers across many domains of knowledge. While LLMs are being quickly applied to many AI application domains, we are interested in the following question: Can safety analysis for safety-critical systems make use of LLMs? To answer, we conduct a case study of Systems Theoretic Process Analysis (STPA) on Automatic Emergency Brake (AEB) systems using ChatGPT. STPA, one of the most prevalent techniques for hazard analysis, is known to have limitations such as high complexity and subjectivity, which this paper aims to explore the use of ChatGPT to address. Specifically, three ways of incorporating ChatGPT into STPA are investigated by considering its interaction with human experts: one-off simplex interaction, recurring simplex interaction, and recurring duplex interaction. Comparative results reveal that: (i) using ChatGPT without human exp
    
[^59]: 自主网络攻击代理的统一仿真模拟训练环境

    Unified Emulation-Simulation Training Environment for Autonomous Cyber Agents. (arXiv:2304.01244v1 [cs.LG])

    [http://arxiv.org/abs/2304.01244](http://arxiv.org/abs/2304.01244)

    本文提出了一种自动生成高保真度的模拟器解决方案，在智能学习的Cyber Gym for Intelligent Learning（CyGIL）中提供高度真实的网络Cyber Operations（CyOp）训练环境，并通过集成模拟器生成和代理训练过程来降低代理训练时间。

    

    通过强化学习和深度强化学习（RL / DRL），可以开发自主网络攻击代理，并在代表性环境中对代理进行训练。训练环境必须高度真实地模拟代理所要探索的网络Cyber Operations（CyOp）。本文介绍了一种系统解决方案，在智能学习的Cyber Gym for Intelligent Learning（CyGIL）中自动生成高保真度的模拟器。通过表征学习和连续学习，CyGIL提供统一的CyOp培训环境，其中仿真的CyGIL-S由自动生成的CyGIL-E生成。将模拟器生成与代理训练过程集成，以进一步减少所需的代理训练时间。在CyGIL-S中训练的代理可以直接被传输到CyGIL-E，完全可转移至仿真的“真实”网络。实验结果展示了这些解决方案的实际应用。

    Autonomous cyber agents may be developed by applying reinforcement and deep reinforcement learning (RL/DRL), where agents are trained in a representative environment. The training environment must simulate with high-fidelity the network Cyber Operations (CyOp) that the agent aims to explore. Given the complexity of net-work CyOps, a good simulator is difficult to achieve. This work presents a systematic solution to automatically generate a high-fidelity simulator in the Cyber Gym for Intelligent Learning (CyGIL). Through representation learning and continuous learning, CyGIL provides a unified CyOp training environment where an emulated CyGIL-E automatically generates a simulated CyGIL-S. The simulator generation is integrated with the agent training process to further reduce the required agent training time. The agent trained in CyGIL-S is transferrable directly to CyGIL-E showing full transferability to the emulated "real" network. Experimental results are presented to demonstrate th
    
[^60]: 在证据图上运用多通道异构学习增强临床证据推荐

    Enhancing Clinical Evidence Recommendation with Multi-Channel Heterogeneous Learning on Evidence Graphs. (arXiv:2304.01242v1 [cs.CL])

    [http://arxiv.org/abs/2304.01242](http://arxiv.org/abs/2304.01242)

    该论文提出使用证据共指图和证据文本图表来解决临床证据推荐中的联系稀疏性问题，并介绍了一个多通道异构学习模型来支持临床决策过程。

    

    临床证据包括患者、干预（如药物或物理治疗）、问题和结果之间的关联和影响。推荐临床证据的目的是为医务人员提供相关信息，以支持他们的决策过程并生成新的证据。我们的具体任务侧重于根据临床问题推荐证据。然而，某些临床问题和相关证据之间的直接联系往往是稀疏的，这就产生了联系稀疏性的挑战。此外，为了推荐适当的证据，有必要同时利用证据之间的拓扑关系和描述它们的文本信息。为了应对这些挑战，我们定义了两个知识图表：证据共指图和证据文本图表，以表示证据元素之间的拓扑和语言关系。我们还引入了一个多通道异构学习模型。

    Clinical evidence encompasses the associations and impacts between patients, interventions (such as drugs or physiotherapy), problems, and outcomes. The goal of recommending clinical evidence is to provide medical practitioners with relevant information to support their decision-making processes and to generate new evidence. Our specific task focuses on recommending evidence based on clinical problems. However, the direct connections between certain clinical problems and related evidence are often sparse, creating a challenge of link sparsity. Additionally, to recommend appropriate evidence, it is essential to jointly exploit both topological relationships among evidence and textual information describing them. To address these challenges, we define two knowledge graphs: an Evidence Co-reference Graph and an Evidence Text Graph, to represent the topological and linguistic relations among evidential elements, respectively. We also introduce a multi-channel heterogeneous learning model a
    
[^61]: Spam-T5：基于小样本的邮件垃圾检测的大型语言模型基准测试

    Spam-T5: Benchmarking Large Language Models for Few-Shot Email Spam Detection. (arXiv:2304.01238v1 [cs.CL])

    [http://arxiv.org/abs/2304.01238](http://arxiv.org/abs/2304.01238)

    本文通过比较不同类型的大型语言模型和传统机器学习技术在邮件垃圾检测中的表现，发现大多数情况下，大型语言模型优于传统技术，特别是在样本有限的情况下。同时，本文还介绍了经过改进和微调的Spam-T5模型，该模型具有出色的性能表现。

    

    本文通过比较三种不同类型的大型语言模型（BERT-like、Sentence Transformers和Seq2Seq）以及传统机器学习技术（如朴素贝叶斯和LightGBM）在邮件垃圾检测中的有效性，研究了大型语言模型在邮件垃圾检测中的作用。同时，我们还评估了这些模型在四个公共数据集上的表现，并使用不同数量的训练样本（完整训练集和小样本）进行了测试。 发现在大多数情况下，LLMs优于基线技术，特别是在小样本情况下。这种适应性使LLMs在邮件垃圾检测任务中具有独特的优势，因为标记样本数量有限，并且模型需要经常更新。此外，我们介绍了Spam-T5模型，该模型是专门为检测电子邮件垃圾而进行了改进和微调。我们的结果表明，Spam-T5模型具有出色的性能。

    This paper investigates the effectiveness of large language models (LLMs) in email spam detection by comparing prominent models from three distinct families: BERT-like, Sentence Transformers, and Seq2Seq. Additionally, we examine well-established machine learning techniques for spam detection, such as Na\"ive Bayes and LightGBM, as baseline methods. We assess the performance of these models across four public datasets, utilizing different numbers of training samples (full training set and few-shot settings). Our findings reveal that, in the majority of cases, LLMs surpass the performance of the popular baseline techniques, particularly in few-shot scenarios. This adaptability renders LLMs uniquely suited to spam detection tasks, where labeled samples are limited in number and models require frequent updates. Additionally, we introduce Spam-T5, a Flan-T5 model that has been specifically adapted and fine-tuned for the purpose of detecting email spam. Our results demonstrate that Spam-T5 
    
[^62]: 通过自我改进的方式实现更好的代码语言模型

    Better Language Models of Code through Self-Improvement. (arXiv:2304.01228v1 [cs.CL])

    [http://arxiv.org/abs/2304.01228](http://arxiv.org/abs/2304.01228)

    本文提出了一个简单的数据增强框架来改善预训练语言模型为代码生成和代码摘要等任务微调的瓶颈问题，提高了模型性能。

    

    近期，各种预训练的代码语言模型引起了人们的广泛关注。这些模型通过多模式目标在大规模数据集上进行预训练。但是，对其进行微调需要大量监督，并且受到提供的数据集规模的限制。我们提出了一个简单的数据增强框架以改善这个问题。这个框架利用了在预训练和微调阶段获得的知识来生成伪数据，并将其用作下一步的训练数据。我们将这个框架应用到最先进的语言模型中，如CodeT5、CodeBERT和UnixCoder。结果表明，我们的框架显著提高了PLMC在与代码相关的序列生成任务中的性能，如CodeXGLUE基准测试中的代码摘要和代码生成。

    Pre-trained language models for code (PLMCs) have gained attention in recent research. These models are pre-trained on large-scale datasets using multi-modal objectives. However, fine-tuning them requires extensive supervision and is limited by the size of the dataset provided. We aim to improve this issue by proposing a simple data augmentation framework. Our framework utilizes knowledge gained during the pre-training and fine-tuning stage to generate pseudo data, which is then used as training data for the next step. We incorporate this framework into the state-of-the-art language models, such as CodeT5, CodeBERT, and UnixCoder. The results show that our framework significantly improves PLMCs' performance in code-related sequence generation tasks, such as code summarization and code generation in the CodeXGLUE benchmark.
    
[^63]: 基于超图对比学习的异常事件检测

    Abnormal Event Detection via Hypergraph Contrastive Learning. (arXiv:2304.01226v1 [cs.LG])

    [http://arxiv.org/abs/2304.01226](http://arxiv.org/abs/2304.01226)

    本论文提出了一种基于超图对比学习的异常事件检测方法，可以完全捕捉异常事件模式，实验表明该方法在两个公共数据集上明显优于现有方法。

    

    异常事件检测在许多实际应用中扮演着重要角色，它指的是挖掘涉及实体之间不寻常的相互作用。 以往的研究大多将此任务简化为检测异常的成对交互作用。 然而，现实世界中的事件可能包含多种类型的属性实体和它们之间的复杂相互作用，这形成了属性异构信息网络。随着社交网络的蓬勃发展，属性异构信息网络中的异常事件检测已成为一项重要但很少被探索的任务。

    Abnormal event detection, which refers to mining unusual interactions among involved entities, plays an important role in many real applications. Previous works mostly over-simplify this task as detecting abnormal pair-wise interactions. However, real-world events may contain multi-typed attributed entities and complex interactions among them, which forms an Attributed Heterogeneous Information Network (AHIN). With the boom of social networks, abnormal event detection in AHIN has become an important, but seldom explored task. In this paper, we firstly study the unsupervised abnormal event detection problem in AHIN. The events are considered as star-schema instances of AHIN and are further modeled by hypergraphs. A novel hypergraph contrastive learning method, named AEHCL, is proposed to fully capture abnormal event patterns. AEHCL designs the intra-event and inter-event contrastive modules to exploit self-supervised AHIN information. The intra-event contrastive module captures the pair
    
[^64]: 优化 KNN 模型的 Shapley Interaction 计算从 O(2^n) 到 O(t n^2)。

    Optimizing Data Shapley Interaction Calculation from O(2^n) to O(t n^2) for KNN models. (arXiv:2304.01224v1 [cs.LG])

    [http://arxiv.org/abs/2304.01224](http://arxiv.org/abs/2304.01224)

    本文提出了一种名为 "STI-KNN" 的算法，可以在短时间内对 KNN 模型进行精确的配对交互 Shapley 值计算，从而有效地评估每个训练数据点的价值，提高训练结果和人工智能应用的有效性。

    

    随着数据可用性和使用率的快速增长，量化每个训练数据点的附加价值已成为人工智能领域中关键的过程。Shapley 值已被公认为是一种有效的数据估值方法，使得训练集汇总、获取和异常值删除变得更加高效。本文介绍了一种创新算法 "STI-KNN"，它可以在O(t n^2)时间内计算准确的 KNN 模型的精确配对交互 Shapley 值，这是比基线方法的 O(2^n) 时间复杂度显著提高了。使用 STI-KNN，我们可以高效准确地评估单个数据点的价值，从而改善训练结果，最终增强人工智能应用的有效性。

    With the rapid growth of data availability and usage, quantifying the added value of each training data point has become a crucial process in the field of artificial intelligence. The Shapley values have been recognized as an effective method for data valuation, enabling efficient training set summarization, acquisition, and outlier removal. In this paper, we introduce "STI-KNN", an innovative algorithm that calculates the exact pair-interaction Shapley values for KNN models in O(t n^2) time, which is a significant improvement over the O(2^n)$ time complexity of baseline methods. By using STI-KNN, we can efficiently and accurately evaluate the value of individual data points, leading to improved training outcomes and ultimately enhancing the effectiveness of artificial intelligence applications.
    
[^65]: NeuroDAVIS: 用于数据可视化的神经网络模型

    NeuroDAVIS: A neural network model for data visualization. (arXiv:2304.01222v1 [cs.HC])

    [http://arxiv.org/abs/2304.01222](http://arxiv.org/abs/2304.01222)

    NeuroDAVIS是一种无监督深度神经网络模型，它可以在不影响数据局部和全局结构的情况下提取重要特征并在更低的维度上进行数据可视化。

    

    高维数据的降维和可视化一直是一个具有挑战性的问题。现代高通量技术产生了多种视图的新的高维数据集，这些数据集包含了新的数据类型。对这些数据集的可视化需要适当的方法，可以在不影响数据中的局部和全局结构的情况下发现数据中的隐藏模式。然而，能够实现这个任务的方法非常少。在这项工作中，我们介绍了一种新的无监督深度神经网络模型NeuroDAVIS，用于数据可视化。NeuroDAVIS能够从数据中提取重要特征，而不需要假设任何数据分布，并在更低的维度上进行有效的可视化。理论上证明了高维数据的邻近关系在低维空间中得到了保留。NeuroDAVIS的性能已在各种合成和实际数据集上进行了评估。

    The task of dimensionality reduction and visualization of high-dimensional datasets remains a challenging problem since long. Modern high-throughput technologies produce newer high-dimensional datasets having multiple views with relatively new data types. Visualization of these datasets require proper methodology that can uncover hidden patterns in the data without affecting the local and global structures within the data. To this end, however, very few such methodology exist, which can realise this task. In this work, we have introduced a novel unsupervised deep neural network model, called NeuroDAVIS, for data visualization. NeuroDAVIS is capable of extracting important features from the data, without assuming any data distribution, and visualize effectively in lower dimension. It has been shown theoritically that neighbourhood relationship of the data in high dimension remains preserved in lower dimension. The performance of NeuroDAVIS has been evaluated on a wide variety of synthet
    
[^66]: DoE2Vec：基于深度学习的特征用于探索性景观分析

    DoE2Vec: Deep-learning Based Features for Exploratory Landscape Analysis. (arXiv:2304.01219v1 [math.OC])

    [http://arxiv.org/abs/2304.01219](http://arxiv.org/abs/2304.01219)

    DoE2Vec 是一种基于深度学习的方法，用于学习任何实验设计（DoE）的信息潜在表达，并可以满足优化景观特征的下游元学习任务，同时避免了经典ELA分析中的特征工程问题。在分类任务中与经典ELA特征互补使用时，可显着提高性能。

    

    我们提出DoE2Vec，这是一种基于变分自编码器（VAE）的方法，用于学习优化景观特征，以用于下游元学习任务，例如自动选择优化算法。通过使用随机函数生成器生成的大型训练数据集，DoE2Vec可以自学习任何实验设计（DoE）的信息潜在表达。与经典的探索性景观分析（ELA）方法不同，我们的方法不需要任何特征工程，并且易于应用于高维搜索空间。为了验证，我们检查了潜在重建的质量，并使用不同的实验分析了潜在表达式。这些潜在表达式不仅在识别类似（易于评估）的替代函数上显示出有前途的潜力，而且在分类任务中与经典的ELA特征互补使用时也可以显着提升性能。

    We propose DoE2Vec, a variational autoencoder (VAE)-based methodology to learn optimization landscape characteristics for downstream meta-learning tasks, e.g., automated selection of optimization algorithms. Principally, using large training data sets generated with a random function generator, DoE2Vec self-learns an informative latent representation for any design of experiments (DoE). Unlike the classical exploratory landscape analysis (ELA) method, our approach does not require any feature engineering and is easily applicable for high dimensional search spaces. For validation, we inspect the quality of latent reconstructions and analyze the latent representations using different experiments. The latent representations not only show promising potentials in identifying similar (cheap-to-evaluate) surrogate functions, but also can significantly boost performances when being used complementary to the classical ELA features in classification tasks.
    
[^67]: POLAR-Express: 神经网络控制系统的高效准确形式可达性分析

    POLAR-Express: Efficient and Precise Formal Reachability Analysis of Neural-Network Controlled Systems. (arXiv:2304.01218v1 [eess.SY])

    [http://arxiv.org/abs/2304.01218](http://arxiv.org/abs/2304.01218)

    POLAR-Express 是一种高效且准确的形式可达性分析工具，用于验证神经网络控制系统的安全性。它使用 Taylor 模型算术和逐层传播技术，可以分析具有连续激活功能的前馈神经网络，并在 ReLU 激活函数上提供了一种更有效的精确传播 TM 的新方法。

    

    在挑战性的控制问题上，扮演控制器角色的神经网络 (NN) 展示出了令人印象深刻的实验性能。但神经网络控制系统 (NNCS) 在实际应用中的潜在采用也引起了日益增长的对这些 NNCS 安全性的担忧，特别是在安全关键应用中的使用。本文提出了 POLAR-Express，一种高效且准确的形式可达性分析工具，用于验证 NNCS 的安全性。POLAR-Express 使用 Taylor 模型算术，逐层横跨神经网络来传播 Taylor 模型 (TM) 以计算神经网络函数的近似值。它可以用于分析任何具有连续激活功能的前馈神经网络。我们还提出了一种在 ReLU 激活函数上更有效地精确传播 TM 的新方法。此外，POLAR-Express 为逐层传播提供了并行计算支持。

    Neural networks (NNs) playing the role of controllers have demonstrated impressive empirical performances on challenging control problems. However, the potential adoption of NN controllers in real-life applications also gives rise to a growing concern over the safety of these neural-network controlled systems (NNCSs), especially when used in safety-critical applications. In this work, we present POLAR-Express, an efficient and precise formal reachability analysis tool for verifying the safety of NNCSs. POLAR-Express uses Taylor model arithmetic to propagate Taylor models (TMs) across a neural network layer-by-layer to compute an overapproximation of the neural-network function. It can be applied to analyze any feed-forward neural network with continuous activation functions. We also present a novel approach to propagate TMs more efficiently and precisely across ReLU activation functions. In addition, POLAR-Express provides parallel computation support for the layer-by-layer propagation
    
[^68]: 论文标题：IEEE 802.11ax Wi-Fi 系统中的分布式多智能体深度 Q 学习实现快速漫游

    Distributed Multi-Agent Deep Q-Learning for Fast Roaming in IEEE 802.11ax Wi-Fi Systems. (arXiv:2304.01210v1 [cs.NI])

    [http://arxiv.org/abs/2304.01210](http://arxiv.org/abs/2304.01210)

    本文提出了 MADAR 算法，解决了 Wi-Fi 漫游问题。该算法采用多智能体深度 Q 学习，有效降低延迟。

    

    Wi-Fi 6，即 IEEE 802.11ax 的创新，通过提高延迟、吞吐量等基本性能来改进无线局域网（WLAN）的技术。 正交频分多址（OFDMA）的主要技术特点支持多个用户通过相应的接入点（AP）并发传输各自的数据。 但是，用于 Wi-Fi 漫游的传统 IEEE 802.11 协议仅根据从 AP 接收到的响应帧获取的接收信号强度指示（RSSI）选择目标 AP。 长期来看，在密集用户场景下，这可能会导致单个通道拥塞，进一步增加关联延迟和数据包丢失率，甚至降低整个系统的服务质量（QoS）。 本文提出了一种用于实现快速漫游的多智能体深度 Q 学习算法 - MADAR 算法，以有效减少站点漫游时的延迟。

    The innovation of Wi-Fi 6, IEEE 802.11ax, was be approved as the next sixth-generation (6G) technology of wireless local area networks (WLANs) by improving the fundamental performance of latency, throughput, and so on. The main technical feature of orthogonal frequency division multiple access (OFDMA) supports multi-users to transmit respective data concurrently via the corresponding access points (APs). However, the conventional IEEE 802.11 protocol for Wi-Fi roaming selects the target AP only depending on received signal strength indication (RSSI) which is obtained by the received Response frame from the APs. In the long term, it may lead to congestion in a single channel under the scenarios of dense users further increasing the association delay and packet drop rate, even reducing the quality of service (QoS) of the overall system. In this paper, we propose a multi-agent deep Q-learning for fast roaming (MADAR) algorithm to effectively minimize the latency during the station roaming
    
[^69]: PromptORE -- 一种全新的无监督关系抽取方法

    PromptORE -- A Novel Approach Towards Fully Unsupervised Relation Extraction. (arXiv:2304.01209v1 [cs.CL])

    [http://arxiv.org/abs/2304.01209](http://arxiv.org/abs/2304.01209)

    提出了“基于提示的开放关系抽取”模型，在无监督设置下不需要超参数调整，实现了全新的无监督关系抽取方法。

    

    无监督关系抽取旨在识别文本中实体之间的关系，而在训练期间没有标记的数据可用。这对于没有注释数据集的特定领域关系抽取和先验未知关系类型的开放领域关系抽取特别相关。虽然最近的方法取得了有希望的结果，但它们严重依赖于超参数，调整这些超参数通常需要标记数据。为了减轻对超参数的依赖，我们提出了PromptORE，即“基于提示的开放关系抽取”模型。我们将新的提示调整范例适应于无监督设置，并用它来嵌入表达关系的句子。然后我们对这些嵌入进行聚类，发现候选关系，并尝试不同的策略来自动估计适当的聚类数量。据我们所知，PromptORE是第一个不需要超参数调整的无监督关系抽取模型。

    Unsupervised Relation Extraction (RE) aims to identify relations between entities in text, without having access to labeled data during training. This setting is particularly relevant for domain specific RE where no annotated dataset is available and for open-domain RE where the types of relations are a priori unknown. Although recent approaches achieve promising results, they heavily depend on hyperparameters whose tuning would most often require labeled data. To mitigate the reliance on hyperparameters, we propose PromptORE, a ''Prompt-based Open Relation Extraction'' model. We adapt the novel prompt-tuning paradigm to work in an unsupervised setting, and use it to embed sentences expressing a relation. We then cluster these embeddings to discover candidate relations, and we experiment different strategies to automatically estimate an adequate number of clusters. To the best of our knowledge, PromptORE is the first unsupervised RE model that does not need hyperparameter tuning. Resul
    
[^70]: 当进化计算遇见隐私

    When Evolutionary Computation Meets Privacy. (arXiv:2304.01205v1 [cs.NE])

    [http://arxiv.org/abs/2304.01205](http://arxiv.org/abs/2304.01205)

    进化计算结合隐私保护成为新兴的研究方向，但目前隐私问题缺乏系统性研究。该论文讨论了三种典型的优化模式并提出了BOOM来整理隐私问题。BOOM包括隐私定义、隐私问题分类、隐私感知的进化计算构建和通过案例展示隐私感知的进化计算。

    

    近年来，机器学习、分布式计算和大数据技术推动了进化计算(EC)的发展，使得EC的研究方向不断拓展，比如分布式的EC和基于替代模型的EC。这些进展显著提高了EC的性能和应用范围，但也会导致隐私泄露，比如最优结果和替代模型的泄露。因此，进化计算与隐私保护成为新兴的研究方向。然而，目前进化计算中隐私问题的系统性研究尚不完善，特别是缺乏隐私保护的对象、动机、位置和方法的探索。因此，在本文中，我们讨论了三种典型的优化模式(即集中式优化、分布式优化和数据驱动优化)来表征进化计算的优化模式，并提出了BOOM来整理进化计算中的隐私问题。具体而言，BOOM包括四个部分：隐私保护的定义、隐私问题的分类、隐私感知的进化计算的构建以及通过案例展示隐私感知的进化计算。我们希望BOOM能够作为一个指南，美学地分析进化计算中的隐私问题，并在未来的研究中推动隐私感知的优化。

    Recently, evolutionary computation (EC) has been promoted by machine learning, distributed computing, and big data technologies, resulting in new research directions of EC like distributed EC and surrogate-assisted EC. These advances have significantly improved the performance and the application scope of EC, but also trigger privacy leakages, such as the leakage of optimal results and surrogate model. Accordingly, evolutionary computation combined with privacy protection is becoming an emerging topic. However, privacy concerns in evolutionary computation lack a systematic exploration, especially for the object, motivation, position, and method of privacy protection. To this end, in this paper, we discuss three typical optimization paradigms (i.e., \textit{centralized optimization, distributed optimization, and data-driven optimization}) to characterize optimization modes of evolutionary computation and propose BOOM to sort out privacy concerns in evolutionary computation. Specifically
    
[^71]: 儿童故事书中艺术作品的自动地理对准

    Automatic Geo-alignment of Artwork in Children's Story Books. (arXiv:2304.01204v1 [cs.AI])

    [http://arxiv.org/abs/2304.01204](http://arxiv.org/abs/2304.01204)

    这项研究证明AI软件可以在没有人类干预的情况下翻译和生成插图，通过比较研究，最佳的方法是使用关键字的提示增强。这对于向广泛的文学受众提供显着的成本效益提高具有重要意义。

    

    进行了一项研究，证明了可以使用AI软件在没有人类干预的情况下翻译和生成插图。这样做的目的是展示给外部客户Pratham Books并进行分发。该项目符合公司的愿景，利用机器学习算法的普适性和可扩展性，为广泛的文学受众在不同地理位置上提供显着的成本效益提高。采用比较研究方法，确定了3种方法中最佳性能的方法，包括使用关键字的提示增强，CLIP嵌入掩膜和带有编辑提示的交叉注意力控制。使用定量和定性措施完成了彻底的评估过程。每种方法都有自己的优点和缺点，但通过评估，发现方法1的产量最佳。未来有望进行有前途的进步，进一步提高图片质量。

    A study was conducted to prove AI software could be used to translate and generate illustrations without any human intervention. This was done with the purpose of showing and distributing it to the external customer, Pratham Books. The project aligns with the company's vision by leveraging the generalisation and scalability of Machine Learning algorithms, offering significant cost efficiency increases to a wide range of literary audiences in varied geographical locations. A comparative study methodology was utilised to determine the best performant method out of the 3 devised, Prompt Augmentation using Keywords, CLIP Embedding Mask, and Cross Attention Control with Editorial Prompts. A thorough evaluation process was completed using both quantitative and qualitative measures. Each method had its own strengths and weaknesses, but through the evaluation, method 1 was found to have the best yielding results. Promising future advancements may be made to further increase image quality by in
    
[^72]: “Polytuplet Loss: 训练阅读理解和逻辑推理模型的反向方法”

    Polytuplet Loss: A Reverse Approach to Training Reading Comprehension and Logical Reasoning Models. (arXiv:2304.01046v1 [cs.CL] CROSS LISTED)

    [http://arxiv.org/abs/2304.01046](http://arxiv.org/abs/2304.01046)

    本文研究了一种训练阅读理解和逻辑推理模型的反向方法，利用相对准确性的策略来训练模型，通过Polytuplet Loss函数来确保优先学习答案选择的相对正确性，获得了不错的成果，提出了具有一般性的训练方法和模型架构。

    

    在整个学校教育过程中，学生们将受到阅读理解和逻辑推理的考验。学生们已经开发了各种策略来完成此类考试，其中有些被认为是通常表现优于其他策略的。这样一种策略涉及强调相对准确性而非绝对准确性，理论上可以在不完全掌握解题所需信息的情况下得出正确答案。本文研究了应用这种策略来训练迁移学习模型以解决阅读理解和逻辑推理问题的有效性。这些模型在具有挑战性的阅读理解和逻辑推理基准数据集ReClor上进行了评估。尽管以前的研究集中于逻辑推理技能，但我们专注于一种通用的训练方法和模型架构。我们提出了Polytuplet Loss函数，是三元组损失函数的扩展，以确保优先学习答案选择的相对正确性而非学习绝对正确性。

    Throughout schooling, students are tested on reading comprehension and logical reasoning. Students have developed various strategies for completing such exams, some of which are generally thought to outperform others. One such strategy involves emphasizing relative accuracy over absolute accuracy and can theoretically produce the correct answer without full knowledge of the information required to solve the question. This paper examines the effectiveness of applying such a strategy to train transfer learning models to solve reading comprehension and logical reasoning questions. The models were evaluated on the ReClor dataset, a challenging reading comprehension and logical reasoning benchmark. While previous studies targeted logical reasoning skills, we focus on a general training method and model architecture. We propose the polytuplet loss function, an extension of the triplet loss function, to ensure prioritization of learning the relative correctness of answer choices over learning
    
[^73]: 基于图挖掘的网络安全研究综述

    Graph Mining for Cybersecurity: A Survey. (arXiv:2304.00485v1 [cs.CR] CROSS LISTED)

    [http://arxiv.org/abs/2304.00485](http://arxiv.org/abs/2304.00485)

    本文综述了图挖掘在网络安全中的应用，包括任务概述、技术综述和不同领域的应用。该综述对未来的研究提供了指导。

    

    当今网络攻击（如恶意软件、垃圾邮件和入侵等）的猛增已经对社会造成了严重后果。保障网络安全已成为组织和政府的当务之急。传统的机器学习方法虽然广泛应用于检测网络威胁，但它们难以建模现实世界网络实体之间的相关性。近年来，随着图挖掘技术的不断发展，许多研究者研究了这些技术，以捕捉网络实体之间的相关性，并取得了很高的性能。因此，总结现有基于图的网络安全解决方案，为未来研究提供指导是非常必要的。本文的主要贡献是，我们提供了一个基于图挖掘技术的网络安全研究综述，包括网络安全任务的概述，典型的图挖掘技术，应用它们到网络安全的一般过程，以及不同网络安全问题的各种解决方案。

    The explosive growth of cyber attacks nowadays, such as malware, spam, and intrusions, caused severe consequences on society. Securing cyberspace has become an utmost concern for organizations and governments. Traditional Machine Learning (ML) based methods are extensively used in detecting cyber threats, but they hardly model the correlations between real-world cyber entities. In recent years, with the proliferation of graph mining techniques, many researchers investigated these techniques for capturing correlations between cyber entities and achieving high performance. It is imperative to summarize existing graph-based cybersecurity solutions to provide a guide for future studies. Therefore, as a key contribution of this paper, we provide a comprehensive review of graph mining for cybersecurity, including an overview of cybersecurity tasks, the typical graph mining techniques, and the general process of applying them to cybersecurity, as well as various solutions for different cybers
    
[^74]: RL中的反向攻击保护：恢复触发状态方法

    Recover Triggered States: Protect Model Against Backdoor Attack in Reinforcement Learning. (arXiv:2304.00252v1 [cs.LG])

    [http://arxiv.org/abs/2304.00252](http://arxiv.org/abs/2304.00252)

    本文提出了恢复触发状态(RTS)方法，用于保护RL代理免受反向攻击。该方法涉及构建替代网络来近似动态模型，并将触发状态恢复为干净状态来防止攻击者通过触发器激活隐藏在代理中的后门。

    

    反向攻击可以使恶意用户操纵环境或破坏训练数据，并将一个隐藏的后门插入到训练代理程序中。这种攻击危及RL系统的可靠性，在各个关键领域可能会造成灾难性的影响。与此相比，对于RL中的反向攻击有效的防御措施的研究相对较少。本文提出了一种新颖的方法——恢复触发状态(RTS)，能够有效地保护受害代理免受反向攻击。 RTS需要构建一个替代网络来近似动态模型。开发人员可以通过将触发状态恢复为干净状态来防止攻击者通过触发器激活代理中隐藏的后门。在训练替代网络来预测状态时，我们将代理动作信息并入，减少代理在预测状态上采取的动作和实际状态上采取的动作之间的差异。

    A backdoor attack allows a malicious user to manipulate the environment or corrupt the training data, thus inserting a backdoor into the trained agent. Such attacks compromise the RL system's reliability, leading to potentially catastrophic results in various key fields. In contrast, relatively limited research has investigated effective defenses against backdoor attacks in RL. This paper proposes the Recovery Triggered States (RTS) method, a novel approach that effectively protects the victim agents from backdoor attacks. RTS involves building a surrogate network to approximate the dynamics model. Developers can then recover the environment from the triggered state to a clean state, thereby preventing attackers from activating backdoors hidden in the agent by presenting the trigger. When training the surrogate to predict states, we incorporate agent action information to reduce the discrepancy between the actions taken by the agent on predicted states and the actions taken on real sta
    
[^75]: oBERTa: 通过改进初始化、蒸馏和剪枝来提高稀疏迁移学习

    oBERTa: Improving Sparse Transfer Learning via improved initialization, distillation, and pruning regimes. (arXiv:2303.17612v1 [cs.CL])

    [http://arxiv.org/abs/2303.17612](http://arxiv.org/abs/2303.17612)

    oBERTa是一组易于使用的语言模型，通过改进初始化、蒸馏、剪枝等技术，可以在不需要模型压缩方面的专业知识的情况下提高稀疏迁移学习的效率和准确性。

    

    本文介绍了oBERTa语言模型的范围，它是一组易于使用的语言模型，允许自然语言处理（NLP）从业者在不需要模型压缩方面的专业知识的情况下获得3.8到24.3倍的更快速的模型。oBERTa扩展了现有的剪枝、知识蒸馏和量化工作，并利用冻结的嵌入来改进知识蒸馏，并改进模型初始化，以在广泛的传递任务上提供更高的准确性。在生成oBERTa时，我们探索了高度优化的RoBERTa与BERT在预训练和微调期间剪枝方面的不同之处，并发现它在微调期间不太适合压缩。我们探索了oBERTa在七个具有代表性的NLP任务上的使用，并发现改进的压缩技术使得经过剪枝的oBERTa模型能够匹配BERTBASE的性能，并超过SQUAD V1.1问答数据的Prune OFA Large的性能。

    In this paper, we introduce the range of oBERTa language models, an easy-to-use set of language models, which allows Natural Language Processing (NLP) practitioners to obtain between 3.8 and 24.3 times faster models without expertise in model compression. Specifically, oBERTa extends existing work on pruning, knowledge distillation, and quantization and leverages frozen embeddings to improve knowledge distillation, and improved model initialization to deliver higher accuracy on a a broad range of transfer tasks. In generating oBERTa, we explore how the highly optimized RoBERTa differs from the BERT with respect to pruning during pre-training and fine-tuning and find it less amenable to compression during fine-tuning. We explore the use of oBERTa on a broad seven representative NLP tasks and find that the improved compression techniques allow a pruned oBERTa model to match the performance of BERTBASE and exceed the performance of Prune OFA Large on the SQUAD V1.1 Question Answering data
    
[^76]: AHP中安全的决策聚合方法研究

    Towards secure judgments aggregation in AHP. (arXiv:2303.15099v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.15099](http://arxiv.org/abs/2303.15099)

    本文提出了两种启发式方法用于检测和减小GAHP中操纵者的影响。第一种方法是基于操纵者提供的判断为异常值的假设，第二种方法假设不诚实的判断比群体的平均一致性少一致性。这两种方法都可以有效地保证群体共识的安全。

    

    在决策方法中，通常假设专家诚实和专业。但是，在群体决策框架中，如群体层次分析过程（GAHP）中，一个或多个专家试图操纵结果以符合自己的利益。本文旨在介绍GAHP中的两种启发式方法，通过减小权重来检测操纵者并最小化其对群体共识的影响。第一种启发式方法基于这样的假设，即操纵者提供的判断可以被认为是相对于群体中其余专家的判断而言的异常值。第二种启发式方法假定不诚实的判断比群体的平均一致性少一致性。两种方法都通过数值和模拟示例进行了演示。

    In decision-making methods, it is common to assume that the experts are honest and professional. However, this is not the case when one or more experts in the group decision making framework, such as the group analytic hierarchy process (GAHP), try to manipulate results in their favor. The aim of this paper is to introduce two heuristics in the GAHP, setting allowing to detect the manipulators and minimize their effect on the group consensus by diminishing their weights. The first heuristic is based on the assumption that manipulators will provide judgments which can be considered outliers with respect to those of the rest of the experts in the group. The second heuristic assumes that dishonest judgments are less consistent than the average consistency of the group. Both approaches are illustrated with numerical examples and simulations.
    
[^77]: 使用计算注意力预测人类视觉注意力

    Predicting Human Attention using Computational Attention. (arXiv:2303.09383v1 [cs.CV])

    [http://arxiv.org/abs/2303.09383](http://arxiv.org/abs/2303.09383)

    HAT是一种计算注意力模型，使用新颖的基于变换器的结构和简化的凹视网膜，实现了对于目标存在和目标缺失搜索期间注视行为的扫描路径的最新技术水平。

    

    大多数视觉注意力模型旨在预测自上而下或自下而上控制，采用不同的视觉搜索和自由观看任务进行研究。我们提出了一个称为人类注意力变换器的单一模型，可以预测这两种形式的注意力控制。HAT在预测目标存在和目标缺失搜索期间进行注视行为的扫描路径方面是新的最先进技术，在预测无任务自由观看注视路径方面匹配或超过了当前技术水平。HAT通过使用新颖的基于变换器的结构和简化的凹视网膜，共同创建类似于人类动态视觉工作记忆的时空意识，实现了这种新的技术水平。与以前依赖于粗糙的注视单元格网格并由于离散化固定而经历信息丢失的方法不同，HAT具有密集预测架构，并为每个注视输出密集热图，从而避免离散注视。HAT在计算视觉注意力方面设定了一个新的标准。

    Most models of visual attention are aimed at predicting either top-down or bottom-up control, as studied using different visual search and free-viewing tasks. We propose Human Attention Transformer (HAT), a single model predicting both forms of attention control. HAT is the new state-of-the-art (SOTA) in predicting the scanpath of fixations made during target-present and target-absent search, and matches or exceeds SOTA in the prediction of taskless free-viewing fixation scanpaths. HAT achieves this new SOTA by using a novel transformer-based architecture and a simplified foveated retina that collectively create a spatio-temporal awareness akin to the dynamic visual working memory of humans. Unlike previous methods that rely on a coarse grid of fixation cells and experience information loss due to fixation discretization, HAT features a dense-prediction architecture and outputs a dense heatmap for each fixation, thus avoiding discretizing fixations. HAT sets a new standard in computati
    
[^78]: 面向自主清洁的多机器人混合任务分配的实践研究

    Towards Practical Multi-Robot Hybrid Tasks Allocation for Autonomous Cleaning. (arXiv:2303.06531v1 [cs.RO])

    [http://arxiv.org/abs/2303.06531](http://arxiv.org/abs/2303.06531)

    本文提出了一个新的鲁棒混合整数线性规划模型，用于解决多机器人自主清洁系统中的混合任务分配问题，并建立了一个包括100个实例的数据集。

    This paper proposes a novel robust mixed-integer linear programming model for multi-robot hybrid-task allocation in uncertain autonomous cleaning systems, and establishes a dataset of 100 instances.

    任务分配在多机器人自主清洁系统中起着至关重要的作用，多个机器人一起工作以清洁大面积区域。然而，迄今为止相关研究存在几个问题。大多数当前研究主要关注于确定性的单任务分配，而不考虑不确定工作环境中的混合任务。此外，缺乏相关研究的数据集和基准。在本文中，我们通过解决这些问题，为不确定的自主清洁系统的多机器人混合任务分配做出了贡献。首先，我们通过鲁棒优化模型来建模清洁环境中的不确定性，并提出了一个新的鲁棒混合整数线性规划模型，其中包括混合清洁任务顺序和机器人的能力等实际约束。其次，我们建立了一个数据集，包括100个实例，每个实例都有2D手动标记的图像和3D模型。第三，我们提供了关于所提出模型的全面结果。

    Task allocation plays a vital role in multi-robot autonomous cleaning systems, where multiple robots work together to clean a large area. However, there are several problems in relevant research to date. Most current studies mainly focus on deterministic, single-task allocation for cleaning robots, without considering hybrid tasks in uncertain working environments. Moreover, there is a lack of datasets and benchmarks for relevant research. In this paper, we contribute to multi-robot hybrid-task allocation for uncertain autonomous cleaning systems by addressing these problems. First, we model the uncertainties in the cleaning environment via robust optimization and propose a novel robust mixed-integer linear programming model with practical constraints including hybrid cleaning task order and robot's ability. Second, we establish a dataset of 100 instances made from floor plans, each of which has 2D manually-labeled images and a 3D model. Third, we provide comprehensive results on the c
    
[^79]: 自适应超参数调节在无监督跨语种分词中的应用

    Self-tuning hyper-parameters for unsupervised cross-lingual tokenization. (arXiv:2303.02427v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.02427](http://arxiv.org/abs/2303.02427)

    本研究探讨了在多语言中进行语言无关的无监督分词的元学习可能性，并使用多种适应度函数自动确定无监督分词模型的超参数。结果表明在英语和俄语中，前三种度量的加性组合与 F1 分词得分之间有相当好的相关性，在中文中，F1 得分与压缩因子有显著的相关性。

    

    本文探讨了在英语、俄语和中文等多种语言中进行语言无关的无监督分词问题的元学习可能性。我们使用不同的人类无关适应度函数，如标准化反熵、压缩因子和交叉分割 F1 得分，以及三个度量的加性和乘性组合，实现了对早期作品提出的无监督分词模型超参数的自动确定的元学习方法，并测试其与传统 F1 分词得分的关系。我们发现在英语和俄语方面，在前三种度量的加性组合与后者之间有相当好的相关性。在中文方面，我们发现 F1 得分与压缩因子之间存在显著的相关性。我们的结果表明了对于资源稀缺和死语言的坚实的无监督分词可能性，并让人们可以从效率演化的角度思考人类语言。

    We explore the possibility of meta-learning for the language-independent unsupervised tokenization problem for English, Russian, and Chinese. We implement the meta-learning approach for automatic determination of hyper-parameters of the unsupervised tokenization model proposed in earlier works, relying on various human-independent fitness functions such as normalised anti-entropy, compression factor and cross-split F1 score, as well as additive and multiplicative composite combinations of the three metrics, testing them against the conventional F1 tokenization score. We find a fairly good correlation between the latter and the additive combination of the former three metrics for English and Russian. In case of Chinese, we find a significant correlation between the F 1 score and the compression factor. Our results suggest the possibility of robust unsupervised tokenization of low-resource and dead languages and allow us to think about human languages in terms of the evolution of efficie
    
[^80]: ChatGPT失败分类存档

    A Categorical Archive of ChatGPT Failures. (arXiv:2302.03494v8 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.03494](http://arxiv.org/abs/2302.03494)

    本研究对ChatGPT的11个失败类别进行了全面分析，其中包括推理、事实错误、数学、编码和偏见。找出失败原因以帮助研究人员和开发人员改进未来的语言模型和聊天机器人。

    

    大型语言模型已经在不同领域证明了其价值。由OpenAI开发的ChatGPT使用大量数据进行训练，通过理解上下文并生成适当的响应来模拟人类对话。它因能够有效地回答广泛的人类问题而受到重视，其流利和全面的答案在安全性和实用性方面超越了先前的公共聊天机器人。然而，缺乏ChatGPT失效的全面分析，这是本研究的重点。本研究提出并讨论了11个失败类别，包括推理、事实错误、数学、编码和偏见。还突出了ChatGPT的风险、限制和社会影响。本研究的目标是帮助研究人员和开发人员增强未来的语言模型和聊天机器人。

    Large language models have been demonstrated to be valuable in different fields. ChatGPT, developed by OpenAI, has been trained using massive amounts of data and simulates human conversation by comprehending context and generating appropriate responses. It has garnered significant attention due to its ability to effectively answer a broad range of human inquiries, with fluent and comprehensive answers surpassing prior public chatbots in both security and usefulness. However, a comprehensive analysis of ChatGPT's failures is lacking, which is the focus of this study. Eleven categories of failures, including reasoning, factual errors, math, coding, and bias, are presented and discussed. The risks, limitations, and societal implications of ChatGPT are also highlighted. The goal of this study is to assist researchers and developers in enhancing future language models and chatbots.
    
[^81]: 离线到在线强化学习的政策扩展

    Policy Expansion for Bridging Offline-to-Online Reinforcement Learning. (arXiv:2302.00935v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.00935](http://arxiv.org/abs/2302.00935)

    本文提出了一种政策扩展方案，用于离线到在线强化学习，以保留离线学习的策略并在在线学习中进行自适应扩展。

    

    利用离线数据进行预训练，并使用在线强化学习进行微调，是一种学习控制策略的有希望的策略，能够在样本效率和性能方面充分利用两者的优点。一种自然的方法是使用离线训练的策略初始化在线学习的策略。本文提出了一种用于此任务的政策扩展方案。在学习离线策略后，我们将其用作策略集中的一个候选策略。然后，我们通过另一个策略来扩展策略集，该策略将负责进一步的学习。两个策略将以自适应的方式组合起来与环境进行交互。通过这种方法，先前离线学习的策略完全在在线学习过程中得以保留，因此减轻了潜在问题，例如在在线学习的初始阶段破坏离线策略的有用行为，同时允许离线策略在自适应方式下自然参与

    Pre-training with offline data and online fine-tuning using reinforcement learning is a promising strategy for learning control policies by leveraging the best of both worlds in terms of sample efficiency and performance. One natural approach is to initialize the policy for online learning with the one trained offline. In this work, we introduce a policy expansion scheme for this task. After learning the offline policy, we use it as one candidate policy in a policy set. We then expand the policy set with another policy which will be responsible for further learning. The two policies will be composed in an adaptive manner for interacting with the environment. With this approach, the policy previously learned offline is fully retained during online learning, thus mitigating the potential issues such as destroying the useful behaviors of the offline policy in the initial stage of online learning while allowing the offline policy participate in the exploration naturally in an adaptive mann
    
[^82]: DIFFormer：通过受能量限制的扩散引出的可扩展（图形）Transformer

    DIFFormer: Scalable (Graph) Transformers Induced by Energy Constrained Diffusion. (arXiv:2301.09474v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.09474](http://arxiv.org/abs/2301.09474)

    DIFFormer是一种能量受限扩散模型，通过逐渐融合其他实例信息的演化状态，导出了一类新的神经编码器，称为DIFFormer（基于扩散的Transformer），能够揭示真实世界中复杂的数据生成过程。

    

    真实世界的数据生成常常涉及实例之间的复杂相互依赖，违反了标准学习范式的IID数据假设，从而对揭示几何结构以学习所需要的实例表示形成了挑战。为此，我们引入了一种能量受限扩散模型，将一批数据集中的实例编码为逐渐融合了其他实例信息的演化状态。扩散过程受限于基于合理能量函数的下降标准，该函数表征了潜在结构上实例表示的全局一致性。我们提供了严谨的理论，该理论暗示了任意实例对之间的最优扩散强度的闭合形式估计，这导致了一类新的神经编码器的产生：DIFFormer（基于扩散的Transformer），其中包含两个版本：一个简单版本具有线性复杂度，面临着禁忌的实例。

    Real-world data generation often involves complex inter-dependencies among instances, violating the IID-data hypothesis of standard learning paradigms and posing a challenge for uncovering the geometric structures for learning desired instance representations. To this end, we introduce an energy constrained diffusion model which encodes a batch of instances from a dataset into evolutionary states that progressively incorporate other instances' information by their interactions. The diffusion process is constrained by descent criteria w.r.t.~a principled energy function that characterizes the global consistency of instance representations over latent structures. We provide rigorous theory that implies closed-form optimal estimates for the pairwise diffusion strength among arbitrary instance pairs, which gives rise to a new class of neural encoders, dubbed as DIFFormer (diffusion-based Transformers), with two instantiations: a simple version with linear complexity for prohibitive instanc
    
[^83]: 通过D适应实现学习率自由学习

    Learning-Rate-Free Learning by D-Adaptation. (arXiv:2301.07733v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.07733](http://arxiv.org/abs/2301.07733)

    D-Adaptation是一种可以自动设置学习率的方法，针对最小化凸性Lipschitz函数，用于实现最优收敛速率，而无需超参数，也无需额外对数因子改进，能够在各种机器学习问题中自动匹配手动调整的学习率。

    

    D适应是一种自动设置学习率的方法，可以渐近地实现最优收敛速率，用于最小化凸性Lipschitz函数，无需回溯或线性搜索，并且每步无需进行额外的函数值或梯度评估。我们的方法是这一类问题的第一个无超参数且收敛速率无需额外对数因子改进的方法。我们针对SGD和Adam变体展示了广泛的实验，其中该方法自动匹配手动调整的学习率，在十多个不同的机器学习问题中应用，包括大规模的视觉和语言问题。开源实现在 \url{https://github.com/facebookresearch/dadaptation}.

    D-Adaptation is an approach to automatically setting the learning rate which asymptotically achieves the optimal rate of convergence for minimizing convex Lipschitz functions, with no back-tracking or line searches, and no additional function value or gradient evaluations per step. Our approach is the first hyper-parameter free method for this class without additional multiplicative log factors in the convergence rate. We present extensive experiments for SGD and Adam variants of our method, where the method automatically matches hand-tuned learning rates across more than a dozen diverse machine learning problems, including large-scale vision and language problems.  An open-source implementation is available at \url{https://github.com/facebookresearch/dadaptation}.
    
[^84]: 视频动作识别的分层解释

    Hierarchical Explanations for Video Action Recognition. (arXiv:2301.00436v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.00436](http://arxiv.org/abs/2301.00436)

    本文提出了分层原型解释器，能够解释深度神经网络对视频动作的分类，同时能够将类和原型建立成更有层次的关系，可以处理不确定性。

    

    解释深度神经网络的主要方法之一是分解视觉输入并找到负责分类的典型部分。然而，现有方法通常忽略这些原型之间的分层关系，因此无法在更高层次（例如，水上运动）和更低层次（例如，游泳）上解释语义概念。在本文中，我们受到人类认知系统的启发，利用分层信息处理不确定性：当我们观察到水和人类活动，但没有明确的动作时，可以将其识别为水上运动的父类。只有观察到一个人在游泳后，我们才能明确将其细分为游泳动作。为此，我们提出了分层原型解释器（HIPE）来建立原型和类之间的分层关系。 HIPE通过在类层次结构的多个级别上分解输入视频帧，实现了视频动作分类的推理过程，我们的方法也适用于视频动作识别之外的其他识别任务。

    To interpret deep neural networks, one main approach is to dissect the visual input and find the prototypical parts responsible for the classification. However, existing methods often ignore the hierarchical relationship between these prototypes, and thus can not explain semantic concepts at both higher level (e.g., water sports) and lower level (e.g., swimming). In this paper inspired by human cognition system, we leverage hierarchal information to deal with uncertainty: When we observe water and human activity, but no definitive action it can be recognized as the water sports parent class. Only after observing a person swimming can we definitively refine it to the swimming action. To this end, we propose HIerarchical Prototype Explainer (HIPE) to build hierarchical relations between prototypes and classes. HIPE enables a reasoning process for video action classification by dissecting the input video frames on multiple levels of the class hierarchy, our method is also applicable to ot
    
[^85]: 面向可扩展物理一致的神经网络：在数据驱动多区域热建筑模型中的应用研究

    Towards Scalable Physically Consistent Neural Networks: an Application to Data-driven Multi-zone Thermal Building Models. (arXiv:2212.12380v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.12380](http://arxiv.org/abs/2212.12380)

    本论文研究了物理一致神经网络(PCNNs) 在模拟建筑温度动态方面的扩展性和准确性。结果发现，PCNNs既确保了物理一致性，同时又能在复杂的多区域热建筑模型中取得高精度的性能表现，且在可用数据量有限的情况下超越经典灰盒模型，具有可扩展性优势。

    

    随着越来越多的数据被收集，数据驱动建模方法近年来越来越受欢迎。虽然经典灰盒模型在物理上是可靠的，但通常很难识别和扩展，并且受其有限的表现力影响可能会影响其准确性。另一方面，常常依赖神经网络 (NNs) 的经典黑盒方法通常能够从数据中推导出统计模式，即使在扩展方面也能取得令人印象深刻的性能。然而，它们对潜在的物理定律完全无视，如果基于它们做决策用于实际物理系统，可能会导致潜在的灾难性后果。最近开发了物理一致神经网络 (PCNNs) 来解决这些问题，确保物理一致性，同时利用 NNs 实现最先进的准确性。在这项工作中，我们将 PCNN 扩展到建筑温度动态建模，并提出与经典灰盒和黑盒方法的彻底比较。特别是，我们研究多区域建筑模型，其中每个区域的热行为由能量平衡方程式统治，其参数必须通过测量数据进行识别。所得结果表明，即使涉及许多相互作用的组件构成的复杂和动态系统，PCNNs 也可以在确保物理一致性的同时实现高精度。此外，我们证明 PCNN 在经典灰盒模型上提供了可扩展性优势，在有限的可用训练数据下表现出色。

    With more and more data being collected, data-driven modeling methods have been gaining in popularity in recent years. While physically sound, classical gray-box models are often cumbersome to identify and scale, and their accuracy might be hindered by their limited expressiveness. On the other hand, classical black-box methods, typically relying on Neural Networks (NNs) nowadays, often achieve impressive performance, even at scale, by deriving statistical patterns from data. However, they remain completely oblivious to the underlying physical laws, which may lead to potentially catastrophic failures if decisions for real-world physical systems are based on them. Physically Consistent Neural Networks (PCNNs) were recently developed to address these aforementioned issues, ensuring physical consistency while still leveraging NNs to attain state-of-the-art accuracy.  In this work, we scale PCNNs to model building temperature dynamics and propose a thorough comparison with classical gray-b
    
[^86]: 多级模态变压器用于多页 DocVQA

    Hierarchical multimodal transformers for Multi-Page DocVQA. (arXiv:2212.05935v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.05935](http://arxiv.org/abs/2212.05935)

    本文提出了一种新方法，Hi-VT5，它是一种分层 transformer 结构，能够处理多页文档 DocVQA 任务。实验表明该方法能够有效地回答问题。

    

    文档视觉问答（DocVQA）是指回答文档图像中的问题的任务。现有的 DocVQA 工作仅考虑单页文档。但是，在实际场景中，文档主要由多个页面组成，应该一起处理。在本文中，我们将 DocVQA 扩展到多页面场景。为此，首先创建一个新的数据集 MP-DocVQA，其中问题是针对多页文档而非单页提出的。其次，我们提出了一种新的分层方法 Hi-VT5，基于 T5 结构，克服了处理长多页文档的当前方法的局限性。所提出的方法基于分层变压器结构，编码器对每个页面的最相关信息进行摘要，然后解码器利用这些摘要信息生成最终答案。通过广泛实验，我们证明了我们的方法能够在单个阶段中回答问题并提供

    Document Visual Question Answering (DocVQA) refers to the task of answering questions from document images. Existing work on DocVQA only considers single-page documents. However, in real scenarios documents are mostly composed of multiple pages that should be processed altogether. In this work we extend DocVQA to the multi-page scenario. For that, we first create a new dataset, MP-DocVQA, where questions are posed over multi-page documents instead of single pages. Second, we propose a new hierarchical method, Hi-VT5, based on the T5 architecture, that overcomes the limitations of current methods to process long multi-page documents. The proposed method is based on a hierarchical transformer architecture where the encoder summarizes the most relevant information of every page and then, the decoder takes this summarized information to generate the final answer. Through extensive experimentation, we demonstrate that our method is able, in a single stage, to answer the questions and provid
    
[^87]: 不完整信息下的知识图谱质量评估

    Knowledge Graph Quality Evaluation under Incomplete Information. (arXiv:2212.00994v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.00994](http://arxiv.org/abs/2212.00994)

    该论文提出一种不暴露原始数据的知识图谱质量评估框架，通过将质量评估任务转化为两个KG之间的对抗性问答游戏，解决现有方法高度依赖原始数据和更多考虑数据质量而非能力层面的缺陷。

    

    由于在许多任务中具有根本作用，知识图谱(KGs)越来越受到关注。因此，对KG的质量评估至关重要且不可或缺。然而，现有领域中的方法通过从不同的维度提出新的质量度量或在KG构建阶段衡量性能来评估KG。但是，这些方法存在两个主要问题。首先，它们高度依赖KG中的原始数据，这使得KG的内部信息在质量评估期间暴露出来。其次，它们更多地考虑数据层面的质量，而不是能力层面的质量，对于下游应用来说，后者更为重要。为了解决这些问题，我们提出了一个不完整信息下的知识图谱质量评估框架(QEII)。在评估过程中，不暴露任何原始数据，而将质量评估任务转化为两个KG之间的对抗性问答游戏。游戏胜者因此被认为具有更好的质量。

    Knowledge graphs (KGs) have attracted more and more attentions because of their fundamental roles in many tasks. Quality evaluation for KGs is thus crucial and indispensable. Existing methods in this field evaluate KGs by either proposing new quality metrics from different dimensions or measuring performances at KG construction stages. However, there are two major issues with those methods. First, they highly rely on raw data in KGs, which makes KGs' internal information exposed during quality evaluation. Second, they consider more about the quality at data level instead of ability level, where the latter one is more important for downstream applications. To address these issues, we propose a knowledge graph quality evaluation framework under incomplete information (QEII). The quality evaluation task is transformed into an adversarial Q&A game between two KGs. Winner of the game is thus considered to have better qualities. During the evaluation process, no raw data is exposed, which en
    
[^88]: 移动机器人的2D推动操作中的集体智能

    Collective Intelligence for 2D Push Manipulation with Mobile Robots. (arXiv:2211.15136v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2211.15136](http://arxiv.org/abs/2211.15136)

    本研究利用基于软体物理模拟器的规划器和基于注意力的神经网络，实现了移动机器人2D协作推动操作中的集体智能，比传统方法具有更好的性能并具备环境自适应能力。

    

    自然系统通常表现出能够自我组织和适应变化的集体智能，但大多数人工系统缺乏这种等效性。本文探讨使用移动机器人进行2D协作推动操作的集体智能系统的可能性。我们展示了将从软体物理模拟派生的规划器提炼为基于注意力的神经网络后，我们的多机器人推动操作系统相对于基线系统具有更好的性能，并可适应外部扰动和环境变化完成任务。

    While natural systems often present collective intelligence that allows them to self-organize and adapt to changes, the equivalent is missing in most artificial systems. We explore the possibility of such a system in the context of cooperative 2D push manipulations using mobile robots. Although conventional works demonstrate potential solutions for the problem in restricted settings, they have computational and learning difficulties. More importantly, these systems do not possess the ability to adapt when facing environmental changes. In this work, we show that by distilling a planner derived from a differentiable soft-body physics simulator into an attention-based neural network, our multi-robot push manipulation system achieves better performance than baselines. In addition, our system also generalizes to configurations not seen during training and is able to adapt toward task completions when external turbulence and environmental changes are applied. Supplementary videos can be foun
    
[^89]: GAMMT: 使用多个Transformer的生成不确定性建模

    GAMMT: Generative Ambiguity Modeling Using Multiple Transformers. (arXiv:2211.09812v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.09812](http://arxiv.org/abs/2211.09812)

    GAMMT是一种生成不确定性模型，使用多个Transformer处理模糊不确定的概率。该模型有望实现高质量和多样性的序列建模。

    

    我们提出了一种新的模型，称为GAMMT（使用多个Transformer的生成不确定性模型），用于基于概率集合的序列数据。与传统模型不同，我们的方法认为序列的数据生成过程不是确定性的，而是模糊的，并受到一组概率的影响。为了捕捉这种不确定性，GAMMT采用了多个并行的Transformer，通过选择机制相互关联，允许近似处理模糊不确定的概率。我们的方法的生成特性还使得输入符号和序列可以有多个表征形式。虽然我们的模型尚未经过实验验证，但我们相信我们的模型在建模具有不确定的数据生成过程的序列的高质量和多样性方面具有巨大潜力。

    We introduce a novel model called GAMMT (Generative Ambiguity Models using Multiple Transformers) for sequential data that is based on sets of probabilities. Unlike conventional models, our approach acknowledges that the data generation process of a sequence is not deterministic, but rather ambiguous and influenced by a set of probabilities. To capture this ambiguity, GAMMT employs multiple parallel transformers that are linked by a selection mechanism, allowing for the approximation of ambiguous probabilities. The generative nature of our approach also enables multiple representations of input tokens and sequences. While our models have not yet undergone experimental validation, we believe that our model has great potential to achieve high quality and diversity in modeling sequences with uncertain data generation processes.
    
[^90]: 对抗检测: 实时攻击目标检测

    Adversarial Detection: Attacking Object Detection in Real Time. (arXiv:2209.01962v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.01962](http://arxiv.org/abs/2209.01962)

    本文首次提出了针对目标检测模型的实时在线攻击，这些攻击可以在所需要的位置制造不存在的物体，攻击成功率约为90\%，揭示了目标检测模型的弱点和安全性问题。

    

    智能机器人依赖目标检测模型来感知环境。随着深度学习安全性的进步，揭示了目标检测模型易受到对抗性攻击的威胁。然而先前的研究主要侧重于攻击静态图像或离线视频。因此，仍不清楚此类攻击是否会危及动态环境下实际的机器人应用。本文通过提出针对目标检测模型的首次实时在线攻击来填补这一空白。我们设计了三种攻击方式，可以在所需位置生成不存在对象的边界框。这些攻击在约20次迭代内达到约90\%的成功率。演示视频可在https://youtu.be/zJZ1aNlXsMU上观看。

    Intelligent robots rely on object detection models to perceive the environment. Following advances in deep learning security it has been revealed that object detection models are vulnerable to adversarial attacks. However, prior research primarily focuses on attacking static images or offline videos. Therefore, it is still unclear if such attacks could jeopardize real-world robotic applications in dynamic environments. This paper bridges this gap by presenting the first real-time online attack against object detection models. We devise three attacks that fabricate bounding boxes for nonexistent objects at desired locations. The attacks achieve a success rate of about 90\% within about 20 iterations. The demo video is available at https://youtu.be/zJZ1aNlXsMU.
    
[^91]: 抽奖池：通过插值票据而不增加训练或推理成本来获胜

    Lottery Pools: Winning More by Interpolating Tickets without Increasing Training or Inference Cost. (arXiv:2208.10842v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.10842](http://arxiv.org/abs/2208.10842)

    本论文提出了一种名为抽奖池（Lottery Pools）的方法，它可以通过直接平均相邻学习得到的子网络的权重或者通过简单的插值策略对迭代剪枝确定的子网络执行“集成”，从而提高抽奖票（LTs）的性能。

    

    抽奖票（LTs）可以发现精确且稀疏的子网络，这些子网络可以被单独训练以匹配密集网络的性能。而集成（Ensemble）是机器学习中最古老的经过时间验证的技巧之一，通过组合多个独立模型的输出来提高性能。然而，在LTs的背景下，集成的好处会被稀疏子网络的预测结果所削弱。本文首先观察到直接平均相邻学习得到的次级子网络的权重可以显著提高LTs的性能。受到这一观察的鼓舞，我们进一步提出了一种通过简单的插值策略对迭代剪枝确定的子网络执行“集成”的替代方法。我们将这种方法称为抽奖池。与没有性能增益的朴素集成不同，扩展抽奖池可以提高每个单独的子网络的性能。

    Lottery tickets (LTs) is able to discover accurate and sparse subnetworks that could be trained in isolation to match the performance of dense networks. Ensemble, in parallel, is one of the oldest time-proven tricks in machine learning to improve performance by combining the output of multiple independent models. However, the benefits of ensemble in the context of LTs will be diluted since ensemble does not directly lead to stronger sparse subnetworks, but leverages their predictions for a better decision. In this work, we first observe that directly averaging the weights of the adjacent learned subnetworks significantly boosts the performance of LTs. Encouraged by this observation, we further propose an alternative way to perform an 'ensemble' over the subnetworks identified by iterative magnitude pruning via a simple interpolating strategy. We call our method Lottery Pools. In contrast to the naive ensemble which brings no performance gains to each single subnetwork, Lottery Pools yi
    
[^92]: 多尺度注意力图像去雨神经体系结构搜索

    Multi-scale Attentive Image De-raining Networks via Neural Architecture Search. (arXiv:2207.00728v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2207.00728](http://arxiv.org/abs/2207.00728)

    本文提出了一种高性能的多尺度注意神经体系结构搜索（MANAS）框架，可用于图像去雨。 该方法自动搜索去雨网络的内部多尺度注意力结构，并采用有效的多尺度训练策略确保模型的鲁棒性。

    

    多尺度架构和注意模块已经证明在许多基于深度学习的图像去雨方法中很有效。然而，手动设计和集成这两个组件到神经网络中需要大量的劳动和广泛的专业知识。在本文中，为图像去雨技术开发了一种高性能的多尺度注意神经体系结构搜索（MANAS）框架。该方法利用多个灵活的模块构建了一个新的多尺度关注搜索空间，这些模块非常适合于图像去雨任务。在该搜索空间下，构建了多尺度注意力单元，进一步用于构建一个强大的图像去雨网络。去雨网络的内部多尺度注意力结构通过基于梯度的搜索算法自动搜索，从某种程度上避免了手动设计的繁琐过程。此外，为了获得鲁棒的图像去雨模型，进一步采用了实用且有效的多尺度训练策略，确保了模型的泛化能力。

    Multi-scale architectures and attention modules have shown effectiveness in many deep learning-based image de-raining methods. However, manually designing and integrating these two components into a neural network requires a bulk of labor and extensive expertise. In this article, a high-performance multi-scale attentive neural architecture search (MANAS) framework is technically developed for image deraining. The proposed method formulates a new multi-scale attention search space with multiple flexible modules that are favorite to the image de-raining task. Under the search space, multi-scale attentive cells are built, which are further used to construct a powerful image de-raining network. The internal multiscale attentive architecture of the de-raining network is searched automatically through a gradient-based search algorithm, which avoids the daunting procedure of the manual design to some extent. Moreover, in order to obtain a robust image de-raining model, a practical and effecti
    
[^93]: Yankee Swap：用于拟阵等级估值的快速公平分配机制

    Yankee Swap: a Fast and Simple Fair Allocation Mechanism for Matroid Rank Valuations. (arXiv:2206.08495v5 [cs.DS] UPDATED)

    [http://arxiv.org/abs/2206.08495](http://arxiv.org/abs/2206.08495)

    本论文提出了一个基于Yankee Swap过程的简单算法，用于拟阵等级估值的无分割物品公平分配，这种方法易于理解，快速可扩展。

    

    当参与者具有拟阵等级估值时，我们研究无分割物品的公平分配。我们的主要贡献是基于俚语Yankee Swap过程的简单算法，它计算出可证明公平和高效的Lorenz支配分配。虽然有多项式时间算法可用于计算此类分配，但我们提出的方法有两种改进方式。 （a）我们的方法易于理解，不使用复杂的拟阵优化算法作为子例程。 （b）我们的方法是可扩展的； 它被证明比所有已知的计算Lorenz支配分配的算法更快。这两个属性对于任何真正公平分配环境中算法的采用至关重要；我们的贡献使我们离这个目标更近了一步。

    We study fair allocation of indivisible goods when agents have matroid rank valuations. Our main contribution is a simple algorithm based on the colloquial Yankee Swap procedure that computes provably fair and efficient Lorenz dominating allocations. While there exist polynomial time algorithms to compute such allocations, our proposed method improves on them in two ways. (a) Our approach is easy to understand and does not use complex matroid optimization algorithms as subroutines. (b) Our approach is scalable; it is provably faster than all known algorithms to compute Lorenz dominating allocations. These two properties are key to the adoption of algorithms in any real fair allocation setting; our contribution brings us one step closer to this goal.
    
[^94]: 《深入研究无需重复训练的渐进式学习》

    A Closer Look at Rehearsal-Free Continual Learning. (arXiv:2203.17269v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.17269](http://arxiv.org/abs/2203.17269)

    本文介绍了一种新的渐进式学习方法，使用知识蒸馏和参数正则化以避免重复训练，并在不会退化已学数据的情况下实现了强大的性能。

    

    渐进式学习是机器学习模型在不断变化的训练数据中学习新概念的一种环境，同时避免以前学习的类别出现“灾难性遗忘”现象。当前的单任务扩展性渐进式学习方法需要大量重复训练以避免知识退化，但重复训练会占用大量内存，并可能违反数据隐私。相反，我们探索了将知识蒸馏和参数正则化以新的方式结合起来，以在不进行重复训练的情况下实现强大的渐进式学习性能。

    Continual learning is a setting where machine learning models learn novel concepts from continuously shifting training data, while simultaneously avoiding degradation of knowledge on previously seen classes which may disappear from the training data for extended periods of time (a phenomenon known as the catastrophic forgetting problem). Current approaches for continual learning of a single expanding task (aka class-incremental continual learning) require extensive rehearsal of previously seen data to avoid this degradation of knowledge. Unfortunately, rehearsal comes at a cost to memory, and it may also violate data-privacy. Instead, we explore combining knowledge distillation and parameter regularization in new ways to achieve strong continual learning performance without rehearsal. Specifically, we take a deep dive into common continual learning techniques: prediction distillation, feature distillation, L2 parameter regularization, and EWC parameter regularization. We first disprove
    
[^95]: 从SLAM到情境感知：挑战与综述

    From SLAM to Situational Awareness: Challenges and Survey. (arXiv:2110.00273v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2110.00273](http://arxiv.org/abs/2110.00273)

    本文研究旨在连接广泛的多学科现有知识，为移动机器人构建完整的情境感知（SA）系统，以提升其自主能力。

    

    移动机器人能够高效、安全地执行复杂任务的能力受限于其对环境（即情况）的了解。先进的推理、决策和执行技能使智能体能够在未知环境中自主行动。情境感知（SA）是人类的一种基本能力，已在心理学、军事、航空航天和教育等各个领域深入研究。然而，在机器人领域中尚未考虑情境感知，而是专注于单一的概念，如感知、空间感知、传感器融合、状态估计和同时定位与映射（SLAM）。因此，本研究旨在连接广泛的多学科现有知识，为我们认为对于自主性至关重要的移动机器人完整的SA系统铺平道路。为此，我们定义了构建机器人SA的主要组成部分及其所涉及的领域。因此，本文

    The capability of a mobile robot to efficiently and safely perform complex missions is limited by its knowledge of the environment, namely the situation. Advanced reasoning, decision-making, and execution skills enable an intelligent agent to act autonomously in unknown environments. Situational Awareness (SA) is a fundamental capability of humans that has been deeply studied in various fields, such as psychology, military, aerospace, and education. Nevertheless, it has yet to be considered in robotics, which has focused on single compartmentalized concepts such as sensing, spatial perception, sensor fusion, state estimation, and Simultaneous Localization and Mapping (SLAM). Hence, the present research aims to connect the broad multidisciplinary existing knowledge to pave the way for a complete SA system for mobile robotics that we deem paramount for autonomy. To this aim, we define the principal components to structure a robotic SA and their area of competence. Accordingly, this paper
    
[^96]: 基于贝叶斯控制器融合的机器人深度强化学习：利用控制先验知识

    Bayesian Controller Fusion: Leveraging Control Priors in Deep Reinforcement Learning for Robotics. (arXiv:2107.09822v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2107.09822](http://arxiv.org/abs/2107.09822)

    本研究提出了贝叶斯控制器融合（BCF）的混合控制策略，通过融合每个系统的具有不确定性的分布输出，利用它们各自的优势，在机器人任务中获得成功。

    

    我们提出了一种名为贝叶斯控制器融合 (BCF) 的混合控制策略，将传统手工控制器和基于模型的深度强化学习 (RL) 的优点结合起来。BCF 在机器人领域中获得了成功，在许多任务中都存在可靠但次优的控制先验知识，但从头开始进行RL仍然不安全且数据低效。通过融合每个系统的具有不确定性的分布输出，BCF 在它们之间仲裁控制，并利用它们各自的优势。我们在两个现实世界的机器人任务中研究了BCF，这些任务涉及在广阔而长时间的环境中导航，以及一个涉及操作灵活性最大化的复杂抓取任务。对于这两个域，存在简单的手工控制器，可以以风险规避的方式解决手头的任务，但并不一定呈现出最佳解决方案，这是由于分析建模的限制、控制器调整不精确和任务的变化。由于先验在早期阶段自然地指导探索，因此BCF构成了一个马尔科夫决策过程，从而避免了RL从头开始可能面临的问题。

    We present Bayesian Controller Fusion (BCF): a hybrid control strategy that combines the strengths of traditional hand-crafted controllers and model-free deep reinforcement learning (RL). BCF thrives in the robotics domain, where reliable but suboptimal control priors exist for many tasks, but RL from scratch remains unsafe and data-inefficient. By fusing uncertainty-aware distributional outputs from each system, BCF arbitrates control between them, exploiting their respective strengths. We study BCF on two real-world robotics tasks involving navigation in a vast and long-horizon environment, and a complex reaching task that involves manipulability maximisation. For both these domains, simple handcrafted controllers exist that can solve the task at hand in a risk-averse manner but do not necessarily exhibit the optimal solution given limitations in analytical modelling, controller miscalibration and task variation. As exploration is naturally guided by the prior in the early stages of 
    
[^97]: 基于过拟合模型特性的噪声标签检测方法

    Over-Fit: Noisy-Label Detection based on the Overfitted Model Property. (arXiv:2106.07217v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2106.07217](http://arxiv.org/abs/2106.07217)

    本文提出一种基于模型过拟合特性的后训练学习方法，能够识别错误标记的样本，并逐步删除对决策边界有较高影响的样本，从而提高模型的泛化性能。

    

    由于深度神经网络具有高容量特性，即使是噪声标签，也容易过度拟合，从而降低模型的泛化性能。为了解决这个问题，我们提出了一种新的后训练学习方法，用于从含噪声标签的数据中显著提高任何预训练模型的泛化性能。具体而言，我们利用训练模型的过拟合特性来识别错误标记的样本，逐步删除对决策边界有较高影响的样本，并改善决策边界来提高泛化性能。我们的后训练方法与现有的噪声标签学习方法相结合具有很好的协同效果。在多种真实世界和合成基准数据集上的实验证明了我们方法在各种实际情况下的有效性。

    Deep neural network can easily overfit to even noisy labels due to its high capacity, which degrades the generalization performance of a model. To overcome this issue, we propose a new approach for learning from noisy labels (LNL) via post-training, which can significantly improve the generalization performance of any pre-trained model on noisy label data. To this end, we rather exploit the overfitting property of a trained model to identify mislabeled samples. Specifically, our post-training approach gradually removes samples with high influence on the decision boundary and refines the decision boundary to improve generalization performance. Our post-training approach creates great synergies when combined with the existing LNL methods. Experimental results on various real-world and synthetic benchmark datasets demonstrate the validity of our approach in diverse realistic scenarios.
    

