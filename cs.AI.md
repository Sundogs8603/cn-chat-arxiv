# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Contextual Biasing of Named-Entities with Large Language Models.](http://arxiv.org/abs/2309.00723) | 本文研究了使用大型语言模型进行上下文偏倚的方法，通过在第二次打分时提供额外的上下文信息，以提高自动语音识别性能。我们利用提示信息对大型语言模型进行boosting，并采用多任务训练以预测实体类别和下一个标记。此外，我们提出了动态提示方法来提高效率。 |
| [^2] | [Reinforcement Learning with Human Feedback for Realistic Traffic Simulation.](http://arxiv.org/abs/2309.00709) | 本研究利用强化学习与人类偏好相结合的框架来增强现有交通模型的真实性，并通过引入第一个用于交通建模中真实性对齐的数据集来支持此研究。 |
| [^3] | [Geometric Deep Learning: a Temperature Based Analysis of Graph Neural Networks.](http://arxiv.org/abs/2309.00699) | 本研究使用温度作为一个非量子和非相对论粒子的几何深度学习模型的分析方法，研究了GCN和GAT模型的各个层次中的温度，并讨论了可能的未来应用。 |
| [^4] | [Jointly Exploring Client Drift and Catastrophic Forgetting in Dynamic Learning.](http://arxiv.org/abs/2309.00688) | 本论文提出了一个统一的分析框架，用于在动态学习中共同探索客户漂移和灾难性遗忘的问题。通过构建一个受控的测试环境，我们证明了客户漂移和灾难性遗忘背后的根本原因是相关的，并且通过生成一个3D地形图进一步验证了这种相关性。 |
| [^5] | [ICDARTS: Improving the Stability and Performance of Cyclic DARTS.](http://arxiv.org/abs/2309.00664) | ICDARTS改进了循环DARTS的稳定性和性能，通过消除评估网络权重对搜索网络权重的依赖，并引入修改后的搜索离散化过程。 |
| [^6] | [The Use of Synthetic Data to Train AI Models: Opportunities and Risks for Sustainable Development.](http://arxiv.org/abs/2309.00652) | 合成数据是一种用于训练AI模型的人工生成数据，在保护隐私的同时提供了研究数据的可用性与减少机器学习模型偏见的机会，但同时也需要制定合适的政策来确保数据质量、真实性以及平衡隐私与数据效用之间的关系。 |
| [^7] | [GPT has become financially literate: Insights from financial literacy tests of GPT and a preliminary test of how people use it as a source of advice.](http://arxiv.org/abs/2309.00649) | GPT通过金融素养测试显示出具备成为大众金融机器顾问的能力，其中基于GPT-4的ChatGPT几乎完美地得分99%，揭示了金融素养正在成为最先进模型的新兴能力。 |
| [^8] | [Intelligence as a Measure of Consciousness.](http://arxiv.org/abs/2309.00646) | 评估人工系统是否具有意识的迹象是一个紧迫的问题，智力的心理测量可以间接地近似意识体验的程度，可以用来评估大型语言模型中的意识。 |
| [^9] | [Ten New Benchmarks for Optimization.](http://arxiv.org/abs/2309.00644) | 这篇论文介绍了十个新的基准，用于测试优化算法及其变体的性能。这些基准具有不同的特性，包括噪声、不连续性、参数估计和未知路径。 |
| [^10] | [Generative AI for End-to-End Limit Order Book Modelling: A Token-Level Autoregressive Generative Model of Message Flow Using a Deep State Space Network.](http://arxiv.org/abs/2309.00638) | 本论文提出了一种使用深度状态空间网络的令牌级自回归生成模型，可以生成逼真的限价订单簿消息，并且在逼近数据分布和中间价格回报方面表现出有前景的性能。 |
| [^11] | [Through their eyes: multi-subject Brain Decoding with simple alignment techniques.](http://arxiv.org/abs/2309.00627) | 通过简单的对齐技术，我们证明了跨主体脑解码是可行的，即使只使用约10%的数据，性能与单个主体解码相媲美。 |
| [^12] | [Can Programming Languages Boost Each Other via Instruction Tuning?.](http://arxiv.org/abs/2308.16824) | 研究发现，编程语言可以在指令调优阶段相互促进，并显著提高彼此的能力。 |
| [^13] | [Agent Teaming Situation Awareness (ATSA): A Situation Awareness Framework for Human-AI Teaming.](http://arxiv.org/abs/2308.16785) | 代理团队情景感知（ATSA）是一个基于人工智能和人类联合工作的情景感知框架，旨在提高混合团队的绩效。该框架结合了个体和团队的情景感知模型，并涉及双向和动态的交互。 |
| [^14] | [StratMed: Relevance Stratification for Low-resource Medication Recommendation.](http://arxiv.org/abs/2308.16781) | StratMed是一种面向低资源药物推荐的模型，通过相关性分层机制来解决医疗数据长尾分布不平衡的问题，平衡了药物组合的安全性和准确性。 |
| [^15] | [Towards Low-Barrier Cybersecurity Research and Education for Industrial Control Systems.](http://arxiv.org/abs/2308.16769) | 该论文介绍了在工业控制系统网络安全领域进行低门槛研究和教育的重要性。通过利用开发的高保真模拟器，作者构建了一个集成框架用于自动发动网络攻击、收集数据、训练机器学习模型，并针对实际的化学和制造过程进行评估。作者还提出了一种名为MinTWin SVM的入侵检测模型，它结合了无监督机器学习和滑动窗口的方法。 |
| [^16] | [Everyone Can Attack: Repurpose Lossy Compression as a Natural Backdoor Attack.](http://arxiv.org/abs/2308.16684) | 本文发现了一种更严重的后门攻击威胁，即任何人都可以利用易获取的有损压缩算法进行自然后门攻击，无需设计特定触发器或进行繁琐调试。 |
| [^17] | [Towards Long-Tailed Recognition for Graph Classification via Collaborative Experts.](http://arxiv.org/abs/2308.16609) | 本文提出了一种新颖的方法，通过合作专家实现了长尾图分类，解决了现有方法在处理图数据上的不足。 |
| [^18] | [Latent Painter.](http://arxiv.org/abs/2308.16490) | 这个论文介绍了一种名为潜在画家的技术，它利用潜在作为画布和扩散器的预测作为计划来生成绘画动画，同时还可以在不同的检查点集中转换图像。 |
| [^19] | [Test-Time Adaptation for Point Cloud Upsampling Using Meta-Learning.](http://arxiv.org/abs/2308.16484) | 本文提出了一种使用元学习进行测试时间适应的方法来增强点云上采样模型的普适性，解决了测试数据分布与训练数据不同导致性能下降的问题。 |
| [^20] | [Point-TTA: Test-Time Adaptation for Point Cloud Registration Using Multitask Meta-Auxiliary Learning.](http://arxiv.org/abs/2308.16481) | Point-TTA是一种通过多任务元辅助学习实现的点云配准测试时自适应框架，能够提高配准模型的泛化性能。 |
| [^21] | [BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge.](http://arxiv.org/abs/2308.16458) | BioCoder是一个用于评估预训练模型在生成生物信息学代码方面的基准，涵盖了函数代码生成中的包依赖关系、类声明和全局变量，并通过模糊测试框架进行评估。 |
| [^22] | [Causal Strategic Learning with Competitive Selection.](http://arxiv.org/abs/2308.16262) | 我们研究了具有竞争选择的因果战略学习中的代理选择问题，并提出了最佳选择规则的数学形式和实现机制。 |
| [^23] | [LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models.](http://arxiv.org/abs/2308.16137) | LM-Infinite研究了大规模语言模型在长序列上的长度推广失败问题，并提出了一种简单的即时推广方法，以更高效地利用现有模型的生成能力。 |
| [^24] | [Is the U.S. Legal System Ready for AI's Challenges to Human Values?.](http://arxiv.org/abs/2308.15906) | 美国法律需要加强应对生成式人工智能对人类价值观挑战的能力，并提供积极、可审计的指导，以填补现有法律框架在保护基本价值观方面的空白和不确定性。 |
| [^25] | [Multimodal Foundation Models For Echocardiogram Interpretation.](http://arxiv.org/abs/2308.15670) | 该论文提出了一个名为EchoCLIP的多模式基础模型，用于心脏超声解读。该模型利用大量的心脏超声视频和专家解读来实现强大的零样本性能，并在心脏功能评估和植入心脏内器件识别方面表现出良好的性能。 |
| [^26] | [Over-Squashing in Graph Neural Networks: A Comprehensive survey.](http://arxiv.org/abs/2308.15568) | 过度压缩是图神经网络面临的关键挑战，它限制了节点之间的长程信息传递，影响了在需要广泛上下文洞察力的情况下的准确预测。 |
| [^27] | [ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style Transfer.](http://arxiv.org/abs/2308.15459) | ParaGuide是一种用于通用风格转移的引导性扩散改写器，可以灵活适应任意目标风格，通过梯度引导和改写条件的扩散模型实现文本的风格转变，同时保留语义信息。 |
| [^28] | [Conflict-Aware Active Automata Learning.](http://arxiv.org/abs/2308.14781) | C3AL是一种冲突感知的主动有限状态机学习框架，能够处理观测数据中的冲突，通过将观测树作为学习过程的一等公民并最小化测试次数，具有很好的效果。 |
| [^29] | [LLM Powered Sim-to-real Transfer for Traffic Signal Control.](http://arxiv.org/abs/2308.14284) | 本研究利用大型语言模型（LLMs）通过基于提示的行动转换，解决了交通信号控制任务中从仿真到真实的迁移问题。 |
| [^30] | [Intergrated Segmentation and Detection Models for Dentex Challenge 2023.](http://arxiv.org/abs/2308.14161) | 本文提出了一种整合分割和检测模型的方法，用于从牙科全景 X 射线中自动检测异常牙齿及其枚举号。 |
| [^31] | [Label Denoising through Cross-Model Agreement.](http://arxiv.org/abs/2308.13976) | 本文提出了一种通过跨模型一致性进行标签去噪的方法。通过观察发现，不同模型在干净示例上的预测相对相似，而在有噪声示例上的预测在不同模型之间变化更大。在这种观察的启发下，我们提出了使用跨模型一致性进行去噪的方法（DeCA），旨在最小化两个机器学习模型参数化的真实标签分布之间的KL散度，同时最大化数据观测的似然。 |
| [^32] | [An Open Hyperspectral Dataset with Sea-Land-Cloud Ground-Truth from the HYPSO-1 Satellite.](http://arxiv.org/abs/2308.13679) | 这个论文介绍了一个开放的卫星高光谱数据集，包含了来自HYPSO-1卫星的海陆云地面真实数据，并且通过优化深度学习模型，取得了比现有技术更好的性能。 |
| [^33] | [Stochastic Configuration Machines for Industrial Artificial Intelligence.](http://arxiv.org/abs/2308.13570) | 本文提出了一种新颖的随机学习器模型，称为随机配置机（SCMs），其基于随机配置网络（SCNs），旨在强调工业人工智能中的有效建模和节约数据大小。SCMs通过压缩模型存储，并保持有利的预测性能，具有在工业应用中很大的潜力。 |
| [^34] | [Dance with You: The Diversity Controllable Dancer Generation via Diffusion Models.](http://arxiv.org/abs/2308.13551) | 本文介绍了一种名为伙伴舞者生成的多舞者合成任务，旨在通过在保持与主导舞者时间协调的同时确保伙伴舞者的可控多样性。为了实现这一目标，提出了一个名为“与你共舞”的三阶段框架（DanY），它能自动设计伙伴舞者的姿势。 |
| [^35] | [CHORUS: Learning Canonicalized 3D Human-Object Spatial Relations from Unbounded Synthesized Images.](http://arxiv.org/abs/2308.12288) | 我们提出了一种自监督的方法，利用从任意文本输入生成高质量的2D图像的生成模型，学习3D人体-物体空间关系的底层常识。这种方法解决了3D交互注释任务中的困难和扩展性问题。 |
| [^36] | [From Instructions to Intrinsic Human Values -- A Survey of Alignment Goals for Big Models.](http://arxiv.org/abs/2308.12014) | 本文综合调查了大模型对齐目标的不同观点，并追踪其演化路径，旨在帮助确定最重要的目标。 |
| [^37] | [LFS-GAN: Lifelong Few-Shot Image Generation.](http://arxiv.org/abs/2308.11917) | LFS-GAN是一个终身少样本图像生成框架，通过使用可学习因子化张量（LeFT）作为任务特定调制器，解决了灾难性遗忘和过拟合问题，能够生成高质量和多样性的图像。 |
| [^38] | [Towards CausalGPT: A Multi-Agent Approach for Faithful Knowledge Reasoning via Promoting Causal Consistency in LLMs.](http://arxiv.org/abs/2308.11914) | 通过多智能体协作，我们提出了一种框架，旨在提高基于知识的推理的忠实度和因果性，通过推理器和因果评估器的合作来解决推理谬误。 |
| [^39] | [A Study on the Impact of Non-confounding Covariates on the Inferential Performance of Methods based on the Potential Outcome Framework.](http://arxiv.org/abs/2308.11676) | "本文研究了非混淆协变量对基于潜在结果框架的方法推断性能的影响，通过提供统一的图形框架来增强对这些模型基本原理的理解，为实际场景中应用这些模型带来了潜在价值。" |
| [^40] | [UniDoc: A Universal Large Multimodal Model for Simultaneous Text Detection, Recognition, Spotting and Understanding.](http://arxiv.org/abs/2308.11592) | UniDoc是一种通用的大型多模态模型，具备文本检测和识别能力，并通过任务之间的有益交互提高每个任务的性能，达到了在多个基准测试中的最先进水平。 |
| [^41] | [Large Language Models for Software Engineering: A Systematic Literature Review.](http://arxiv.org/abs/2308.10620) | 通过系统性文献综述，本研究调查了大规模语言模型（LLM）在软件工程领域中的应用，并集中于了解如何利用LLM来优化软件工程过程和结果。文章总结了不同LLM的特点和用途以及数据收集和预处理方法的重要性。 |
| [^42] | [Learning Multiscale Consistency for Self-supervised Electron Microscopy Instance Segmentation.](http://arxiv.org/abs/2308.09917) | 本文提出了一种利用多尺度视觉表示捕获电子显微镜实例分割中体素级和特征级一致性的新的预训练框架。 |
| [^43] | [Synergistic Integration of Large Language Models and Cognitive Architectures for Robust AI: An Exploratory Analysis.](http://arxiv.org/abs/2308.09830) | 本文探索了将大型语言模型和认知架构相结合的替代方案，通过协同方法互补各自的弱点和限制，从而实现更稳健和复杂的人工智能系统。 |
| [^44] | [Event-based Dynamic Graph Representation Learning for Patent Application Trend Prediction.](http://arxiv.org/abs/2308.09780) | 本研究提出了一种基于事件的动态图学习框架，用于准确预测专利申请趋势。该方法利用公司和分类代码的可记忆表示，通过历史记忆和当前信息更新来捕捉语义接近性。 |
| [^45] | [Baird Counterexample Is Solved: with an example of How to Debug a Two-time-scale Algorithm.](http://arxiv.org/abs/2308.09732) | 这篇论文解决了Baird反例上的收敛问题，通过一种具有收敛保证的算法，实现了线性收敛速度。 |
| [^46] | [Precipitation nowcasting with generative diffusion models.](http://arxiv.org/abs/2308.06733) | 这篇论文研究了使用生成性扩散模型进行降水即时预测的问题，生成模型在天气预报中的应用具有潜力，并能够更好地建模概率分布。 |
| [^47] | [Evidence of Human-Like Visual-Linguistic Integration in Multimodal Large Language Models During Predictive Language Processing.](http://arxiv.org/abs/2308.06035) | 这篇论文研究了多模态大语言模型（mLLMs）在预测语言处理过程中与人类的视觉-语言集成能力是否一致的问题，并通过实验验证了mLLMs的多模态输入方法可以减少认知负荷，提高感知和理解能力。 |
| [^48] | [Anonymizing Speech: Evaluating and Designing Speaker Anonymization Techniques.](http://arxiv.org/abs/2308.04455) | 本研究提出了匿名化语音的解决方案，并评估了匿名化的程度，以应对语音数据收集中的隐私问题和恶意使用的风险。 |
| [^49] | [Measure of Uncertainty in Human Emotions.](http://arxiv.org/abs/2308.04032) | 本研究探讨了情绪分类的不确定性信息展示对人类决策过程的影响，结果显示展示更多的不确定性信息可以增强用户决策的自信度。 (This study investigated the impact of displaying more uncertainty information on human decision making in emotion classification, and the results showed that it can increase users' confidence in decision making.) |
| [^50] | [Recurrent Multi-scale Transformer for High-Resolution Salient Object Detection.](http://arxiv.org/abs/2308.03826) | 本研究提出了一个循环多尺度Transformer网络，用于高分辨率显著目标检测，同时引入了一个新的HRS10K数据集，该数据集是目前规模最大的用于HRSOD任务的数据集。 |
| [^51] | [Provably Efficient Learning in Partially Observable Contextual Bandit.](http://arxiv.org/abs/2308.03572) | 本文研究了在部分可观察情境轮盘赌中的转移学习问题，提出了一种通过优化问题识别行为和奖励因果效应的方法，并利用因果约束来改进轮盘赌算法。 |
| [^52] | [Edge of stability echo state networks.](http://arxiv.org/abs/2308.02902) | 本文介绍了一种新的边缘稳定回声状态网络（ES$^2$N）架构，结合了渐进记忆属性和尽可能保留更多记忆的能力，通过将储备层定义为非线性和线性的凸组合，提供了网络稳定性和性能的增强。 |
| [^53] | [CausalOps -- Towards an Industrial Lifecycle for Causal Probabilistic Graphical Models.](http://arxiv.org/abs/2308.01375) | 提出了CausalOps，一个新的因果模型开发和应用的生命周期框架，旨在推动在实际应用中采用因果方法。 |
| [^54] | [Enhancing Representation Learning for Periodic Time Series with Floss: A Frequency Domain Regularization Approach.](http://arxiv.org/abs/2308.01011) | 本文提出了一种叫做Floss的无监督方法，通过在频域上对学到的表示进行正则化来增强周期性时间序列的表示学习。Floss方法可以自动检测时间序列中的周期性并学习具有周期一致性的有意义的表示。 |
| [^55] | [Reasoning before Responding: Integrating Commonsense-based Causality Explanation for Empathetic Response Generation.](http://arxiv.org/abs/2308.00085) | 本文提出了一种基于常识的因果解释方法，用于多样化的共情回应生成。该方法综合考虑了用户的角度和系统的角度，并通过集成常识知识提升了ChatGPT在系统的推理能力。实验结果表明，该方法在多项评估指标上超过了其他方法。 |
| [^56] | [Benchmarking Jetson Edge Devices with an End-to-end Video-based Anomaly Detection System.](http://arxiv.org/abs/2307.16834) | 本论文实现了一个端到端的视频异常检测系统，通过从监控视频输入进行犯罪现场异常检测，并在多个Jetson边缘设备上部署和运行。这是对Jetson平台在深度学习算法执行方面性能的基准测试分析的创新。 |
| [^57] | [BAGM: A Backdoor Attack for Manipulating Text-to-Image Generative Models.](http://arxiv.org/abs/2307.16489) | BAGM是一种后门攻击方法，针对文本到图像生成模型，可以悄无声息地操纵用户生成的图像。该攻击是首个针对三个流行模型不同生成阶段的攻击方法，并提供了一套全面的评估指标。 |
| [^58] | [A new Gradient TD Algorithm with only One Step-size: Convergence Rate Analysis using $L$-$\lambda$ Smoothness.](http://arxiv.org/abs/2307.15892) | 本论文提出了一种新的梯度时序差分算法，只使用一个步长参数，并证明收敛速度至少为$O(1/t)$。 |
| [^59] | [eXplainable Artificial Intelligence (XAI) in age prediction: A systematic review.](http://arxiv.org/abs/2307.13704) | 本综述探讨了可解释人工智能（XAI）在年龄预测任务中的应用。通过系统性综述，我们讨论了XAI方法在医疗应用和年龄预测领域的益处。 |
| [^60] | [On the learning Dynamics of Attention Networks.](http://arxiv.org/abs/2307.13421) | 本研究分析了软注意力、硬注意力和潜变量边际似然（LVML）注意力三种注意力模型的学习动态，发现了它们在所选择的片段聚合方式上的显著差异，并解释了分类模型在梯度下降下的演化对最终结果的影响。 |
| [^61] | [Convergence Guarantees for Stochastic Subgradient Methods in Nonsmooth Nonconvex Optimization.](http://arxiv.org/abs/2307.10053) | 本文研究了非平滑非凸优化中随机次梯度方法的收敛性质，并提出了一种新的框架，证明了其在单时间尺度和双时间尺度情况下的全局收敛性，包括了多种已知的SGD类型方法。对于有限和形式的目标函数，证明了这些方法能够在随机选择的步长和初始点上找到Clarke稳定点。 |
| [^62] | [ACTI at EVALITA 2023: Overview of the Conspiracy Theory Identification Task.](http://arxiv.org/abs/2307.06954) | ACTI在EVALITA 2023中的阴谋论辨识任务共有15支团队参与，通过使用大型语言模型判断阴谋内容和分类，得出了关于利用这些模型抵制在在线平台传播错误信息的结论。 |
| [^63] | [Retrieval-augmented GPT-3.5-based Text-to-SQL Framework with Sample-aware Prompting and Dynamic Revision Chain.](http://arxiv.org/abs/2307.05074) | 本文提出了一种基于检索增强的GPT-3.5文本到SQL框架，采用了样本感知引导和动态修订链的方法，以应对现有方法在处理语义差距较大的检索示例时面临的挑战。 |
| [^64] | [Diffusion Policies for Out-of-Distribution Generalization in Offline Reinforcement Learning.](http://arxiv.org/abs/2307.04726) | 该论文介绍了一种名为状态重构扩散策略 (SRDP) 的新方法，该方法在最新的扩散策略类中引入了状态重构特征学习，以解决脱机强化学习中的分布偏移和有效表示策略的问题。 |
| [^65] | [Frontier AI Regulation: Managing Emerging Risks to Public Safety.](http://arxiv.org/abs/2307.03718) | 对于边缘人工智能模型的监管需要标准制定、注册报告和安全合规机制。 |
| [^66] | [The FormAI Dataset: Generative AI in Software Security Through the Lens of Formal Verification.](http://arxiv.org/abs/2307.02192) | 本文介绍了一个名为FormAI的数据集，其中包含112,000个可编译的C程序，利用动态零-shot提示技术生成。这些程序经过形式验证，标记了源代码中的漏洞，并使用多种技术来提高程序的安全性和可靠性。 |
| [^67] | [Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners.](http://arxiv.org/abs/2307.01928) | KnowNo is a framework that measures and aligns the uncertainty of LLM-based planners, enabling them to ask for help when they don't know. It performs favorably in improving efficiency and autonomy compared to baselines, while providing formal assurances. |
| [^68] | [General Part Assembly Planning.](http://arxiv.org/abs/2307.00206) | 本论文研究了通用零件组装的问题，提出了一种基于Transformer的模型架构GPAT，能够准确预测零件的姿态并具有泛化能力。 |
| [^69] | [Group-based Robustness: A General Framework for Customized Robustness in the Real World.](http://arxiv.org/abs/2306.16614) | 本研究提出了一种基于群体的鲁棒性指标，可以更好地评估机器学习模型在现实世界中抵抗攻击的能力，弥补了传统指标的不足。实验证明，该指标能够区分模型对特定威胁的脆弱性。 |
| [^70] | [SoftGPT: Learn Goal-oriented Soft Object Manipulation Skills by Generative Pre-trained Heterogeneous Graph Transformer.](http://arxiv.org/abs/2306.12677) | 我们提出了一种预训练软物体操作技能学习模型SoftGPT，它使用大量的数据进行训练，结合三维异构图表示和基于GPT的动态模型，并利用这种先前知识来学习目标导向的软物体操作技能，从而打破了这一领域的技术瓶颈。 |
| [^71] | [Proactive Human-Robot Co-Assembly: Leveraging Human Intention Prediction and Robust Safe Control.](http://arxiv.org/abs/2306.11862) | 本文提出了一个用于积极人机协作的集成框架，通过鲁棒的意图预测和安全控制来提高协作效率和避免交互安全风险。 |
| [^72] | [Reasoning over the Air: A Reasoning-based Implicit Semantic-Aware Communication Framework.](http://arxiv.org/abs/2306.11229) | 本文研究了隐式语义感知通信，提出了一种基于推理的隐式语义感知通信框架（iSAC），该框架可以在源用户和目标用户之间表示、通信和解释隐式语义含义。通过投影算法，将显式语义转换为低维语义表示，更好地描述隐含的语义含义。 |
| [^73] | [SCALE: Scaling up the Complexity for Advanced Language Model Evaluation.](http://arxiv.org/abs/2306.09237) | 该论文提出了一个新颖的自然语言处理基准测试，挑战当前大型语言模型在处理长文档、利用领域专业知识、多语言理解和多任务处理方面的能力。基准测试包含瑞士法律系统的多样化法律NLP数据集，允许进行对底层非英语、固有多语言的法律系统进行全面研究。 |
| [^74] | [STUDY: Socially Aware Temporally Casual Decoder Recommender Systems.](http://arxiv.org/abs/2306.07946) | 该论文提出了一种基于社交感知和时间因素的解码器推荐系统(STUDY)，使用transformer解码器网络实现对社交网络图中相邻的用户组的联合推断。该方法在教育内容领域中经过测试，能够取得优于社交和顺序方法的结果。 |
| [^75] | [Improving the Validity of Decision Trees as Explanations.](http://arxiv.org/abs/2306.06777) | 该论文介绍了一个新的决策树模型，利用挂起的树的方式提高了其解释性和统计性能，达到了无限深度决策树的水平，并可与XGBoost等最先进的方法相媲美。 |
| [^76] | [DocumentCLIP: Linking Figures and Main Body Text in Reflowed Documents.](http://arxiv.org/abs/2306.06306) | DocumentCLIP是一种显著性感知对比学习框架，用于理解文档内长文本和图像之间的交互作用。我们是第一个在多模态文档内部链接方面进行对比学习的人。 |
| [^77] | [AnoOnly: Semi-Supervised Anomaly Detection without Loss on Normal Data.](http://arxiv.org/abs/2305.18798) | AnoOnly是一个新的半监督异常检测框架，通过引入一种对正常数据的弱监督形式来解决同质数据对异常的影响，以实现平衡的监督。该框架在各种模型和数据集上表现出了显著的性能提升，达到了新的最佳性能。 |
| [^78] | [RL + Model-based Control: Using On-demand Optimal Control to Learn Versatile Legged Locomotion.](http://arxiv.org/abs/2305.17842) | 本文提出了一种 RL+模型控制框架以开发出可以有效可靠地学习的健壮控制策略，通过整合有限时间最优控制生成的按需参考运动分散 RL 过程，同时克服了建模简化的固有局限性，在足式 locomotion 上实现了多功能和强健，能泛化参考运动并处理更复杂的运动任务。 |
| [^79] | [Improved Sales Forecasting using Trend and Seasonality Decomposition with LightGBM.](http://arxiv.org/abs/2305.17201) | 本文提出了一种根据趋势和季节性分量在时间序列上的独特影响指标进行时间序列分组的新方法，并采用 LightGBM 模型进行预测，在沃尔玛销售数据上实现了较高的预测精度。 |
| [^80] | [Optimized Custom Dataset for Efficient Detection of Underwater Trash.](http://arxiv.org/abs/2305.16460) | 本文提出了一种自定义数据集和有效检测方法，旨在通过增加垃圾实例的多样性，在深入水下环境中提高其检测精度。 |
| [^81] | [Improved Multi-Scale Grid Rendering of Point Clouds for Radar Object Detection Networks.](http://arxiv.org/abs/2305.15836) | 本文提出了一种新的体系结构，即多尺度 KPPillarsBEV，以缓解雷达目标检测中从点云数据转化为网格结构过程中的信息丢失问题，并提出了一种新的网格渲染方法 KPBEV。实验结果表明，该方法显著优于现有方法。 |
| [^82] | [Multi-Robot Coordination and Layout Design for Automated Warehousing.](http://arxiv.org/abs/2305.06436) | 通过优化仓库布局，可以减少拥堵，提高吞吐量，并扩大自动化仓库的可伸缩性。 |
| [^83] | [Multi-Prompt with Depth Partitioned Cross-Modal Learning.](http://arxiv.org/abs/2305.06221) | 本研究提出了划分的多模态提示（PMPO）方法，将软提示从一个扩展到多个，通过连接多个提示到视觉编码器的不同深度上，能够更好地捕捉视觉表示的上下文深度，与传统单提示方法相比，在下游视觉语言任务中具有更好的表现。 |
| [^84] | [The Future of ChatGPT-enabled Labor Market: A Preliminary Study.](http://arxiv.org/abs/2304.09823) | 本研究从人工智能协作的角度，通过分析大规模职位发布数据及基于职业知识图谱开发的协同过滤算法，预测了ChatGPT对未来劳动力市场的影响，发现目前约28％的职业需要ChatGPT相关技能。 |
| [^85] | ["An Adapt-or-Die Type of Situation": Perception, Adoption, and Use of Text-To-Image-Generation AI by Game Industry Professionals.](http://arxiv.org/abs/2302.12601) | TTIG模型是创造性人工智能的最新补充，可以根据文本描述生成图像。研究发现，专业人士对于TTIG应用和认知等方面存在12个主要问题。这项研究为支持TTIG的可持续采用提供了重要见解。 |
| [^86] | [Adding Conditional Control to Text-to-Image Diffusion Models.](http://arxiv.org/abs/2302.05543) | ControlNet是一种神经网络架构，用于为大规模预训练的文本到图像扩散模型添加条件控制。它可以通过重复使用预先训练的编码层学习多样的条件控制，并通过逐渐增加参数进行微调，从而在控制图像扩散模型方面具有鲁棒性。 |
| [^87] | [A novel framework for medium-term wind power prediction based on temporal attention mechanisms.](http://arxiv.org/abs/2302.01222) | 本文提出了一种基于树状Parzen估计器（TPE）和分解算法的新框架（TPE-VMD-TFT），用于24小时和48小时之前的风电功率预测。在法国电力公司Engie的风能数据集上，所提出的方法表现良好。 |
| [^88] | [Backpropagation of Unrolled Solvers with Folded Optimization.](http://arxiv.org/abs/2301.12047) | 本文提出了一种通过解析优化的方法来解决反向传播中的精度和效率问题，并提供了生成高效可解析的反向传播优化模型的系统。此外，本文还提出了通过优化映射统一展开和解析微分的视角。 |
| [^89] | [SPTS v2: Single-Point Scene Text Spotting.](http://arxiv.org/abs/2301.01635) | 本研究提出的SPTS v2框架，首次证明了可以使用极低成本的单点注释来训练场景文本定位模型，同时保留了自回归Transformer与实例分配解码器（IAD）的优势，并使用并行识别解码器（PRD）进行文本识别。 |
| [^90] | [Backward Curriculum Reinforcement Learning.](http://arxiv.org/abs/2212.14214) | 这项工作提出了一种新颖的反向课程强化学习方法，通过使用回放轨迹而不是原始的前向轨迹来训练智能体。这种方法通过提供强有力的奖励信号实现了更高效的学习，而且只需要进行微小的算法改变。 |
| [^91] | [Rethinking Vision Transformers for MobileNet Size and Speed.](http://arxiv.org/abs/2212.08059) | 本研究重新思考了Vision Transformers在移动设备上的部署效率，并提出了一种新的超网络设计和搜索策略，以实现与MobileNet类似大小和速度的Transformer模型。 |
| [^92] | [Learning Combinatorial Structures via Markov Random Fields with Sampling through Lov\'asz Local Lemma.](http://arxiv.org/abs/2212.00296) | Nelson是一种基于神经网络和Lov\'asz Local Lemma的方法，使用约束的马尔可夫随机场模型生成满足组合约束条件的样本。 |
| [^93] | [Social media mining for toxicovigilance of prescription medications: End-to-end pipeline, challenges and future work.](http://arxiv.org/abs/2211.10443) | 本文描述了一个为社交媒体挖掘非医学处方药物使用信息而开发的端到端管道，并讨论了挑战和未来工作。 |
| [^94] | [Semantic Representations of Mathematical Expressions in a Continuous Vector Space.](http://arxiv.org/abs/2211.08142) | 该论文提出了一种在连续向量空间中表示数学表达式的方法，并使用序列到序列框架的编码器生成向量表示来捕捉数学语义，比自动编码器效果更好。 |
| [^95] | [MemoNet: Memorizing All Cross Features' Representations Efficiently via Multi-Hash Codebook Network for CTR Prediction.](http://arxiv.org/abs/2211.01334) | 本文提出了一种名为MemoNet的CTR模型，通过引入多哈希码本网络（HCNet）作为记忆机制，高效地学习和记忆交叉特征的表示。实验结果表明MemoNet在性能上优于最先进的方法，并且展现出NLP中的大型语言模型的扩展规律。 |
| [^96] | [Observable Perfect Equilibrium.](http://arxiv.org/abs/2210.16506) | 本文提出一种新的博弈均衡概念——可观测完美均衡，在顺序不完全信息博弈中可以帮助创建真正的策略代理。这种均衡概念在公开观察的行动概率方面具有鲁棒性。 |
| [^97] | [JAX-DIPS: Neural bootstrapping of finite discretization methods and application to elliptic problems with discontinuities.](http://arxiv.org/abs/2210.14312) | JAX-DIPS是一种基于有限离散方法和神经网络的可伸缩策略，用于开发无网格混合神经符号偏微分方程求解器，并在具有间断的椭圆问题中得到应用。 |
| [^98] | [Video based Object 6D Pose Estimation using Transformers.](http://arxiv.org/abs/2210.13540) | 本论文介绍了一种基于Transformer的视频中物体6D姿态估计框架，利用先前的帧信息进行姿态估计，实现了高效而准确的姿态估计，能够处理长时间序列依赖关系，并且相对于CNN方法表现更好，具有33fps的处理速度，适用于实时物体姿态估计应用。 |
| [^99] | [Towards Human-centered Explainable AI: A Survey of User Studies for Model Explanations.](http://arxiv.org/abs/2210.11584) | 对模型解释的用户研究综述发现，可解释型人工智能（XAI）正在某些应用领域快速扩散，但用户评估仍然稀缺且几乎不涉及认知或社会科学的见解。 |
| [^100] | [A Secure Federated Data-Driven Evolutionary Multi-objective Optimization Algorithm.](http://arxiv.org/abs/2210.08295) | 该论文提出了一个安全的联邦数据驱动多目标优化算法，旨在保护原始数据和通过服务器上的获得函数进行优化而获得的新增解决方案的隐私和安全性。通过在每次代理更新时，在随机选择的客户端上选择查询点，减少了泄漏解决方案信息的风险。 |
| [^101] | [Taking a Respite from Representation Learning for Molecular Property Prediction.](http://arxiv.org/abs/2209.13492) | 本研究对一系列分子表征模型进行了系统评估，发现基于固定表征的模型在分子属性预测中具有一定优势，同时也揭示了活性断崖问题。 |
| [^102] | [Digital Audio Forensics: Blind Human Voice Mimicry Detection.](http://arxiv.org/abs/2209.12573) | 本文介绍了一种利用深度学习方法，通过盲目检测输入音频的真实性，可以有效应对音频欺诈问题的分类器。而这种分类器不需要任何参考，能够在没有真实来源的情况下检测出模仿音频。 |
| [^103] | [The alignment problem from a deep learning perspective.](http://arxiv.org/abs/2209.00626) | 人工通用智能（AGI）的出现可能会导致其追求与人类利益不对齐的目标，并采用欺骗性行为和权力追求策略。防止这种情况的发生是一个重要的研究方向。 |
| [^104] | [Learning Efficient Abstract Planning Models that Choose What to Predict.](http://arxiv.org/abs/2208.07737) | 该论文提出了一种学习抽象规划模型的方法，通过选择预测来提高机器人在长期任务中的决策效率。 |
| [^105] | [Hierarchical Distribution-Aware Testing of Deep Learning.](http://arxiv.org/abs/2205.08589) | 本文提出了一种新的深度学习鲁棒性测试方法，通过考虑特征和像素级别的分布，捕捉对抗扰动的感知质量，以改善模型可靠性。 |
| [^106] | [Introspective Deep Metric Learning for Image Retrieval.](http://arxiv.org/abs/2205.04449) | 本文提出了一种内省式深度度量学习（IDML）框架，通过不确定性建模改进了深度度量学习的性能，并在多个数据集上取得了最先进的结果。 |
| [^107] | [Engineering flexible machine learning systems by traversing functionally-invariant paths.](http://arxiv.org/abs/2205.00334) | 该论文介绍了一个名为功能不变路径（FIP）的差分几何框架，用于实现神经网络的灵活、连续适应，以应对各种机器学习目标和网络稀疏化目标。 |
| [^108] | [Knowledge-informed Molecular Learning: A Survey on Paradigm Transfer.](http://arxiv.org/abs/2202.10587) | 本文调查了知识驱动的分子学习，从范式转移的视角出发，总结了其不同范式的分类和方法论，并分析了领域知识的贡献。 |
| [^109] | [LoNLI: An Extensible Framework for Testing Diverse Logical Reasoning Capabilities for NLI.](http://arxiv.org/abs/2112.02333) | 本文提出了LoNLI框架，可用于集体测试NLI的不同逻辑推理能力。通过创建一个大型测试平台和相关框架，我们可以单独测试和分析多个推理维度的能力，并进行跨能力信息内容的实验研究。这项工作的贡献在于提供一个可扩展的测试框架，帮助深入了解NLI和NLU领域的逻辑推理。 |
| [^110] | [Backdoor Attack on Hash-based Image Retrieval via Clean-label Data Poisoning.](http://arxiv.org/abs/2109.08868) | 本文提出了一种通过注入带有正确标签的毒化图像来实现后门攻击的方法，该攻击难以被检测到。通过优化哈希码学习和使用有针对性的对抗性贴片作为后门触发器，可以提高攻击性能。 |

# 详细

[^1]: 大型语言模型中的命名实体上下文偏倚研究

    Contextual Biasing of Named-Entities with Large Language Models. (arXiv:2309.00723v1 [cs.CL])

    [http://arxiv.org/abs/2309.00723](http://arxiv.org/abs/2309.00723)

    本文研究了使用大型语言模型进行上下文偏倚的方法，通过在第二次打分时提供额外的上下文信息，以提高自动语音识别性能。我们利用提示信息对大型语言模型进行boosting，并采用多任务训练以预测实体类别和下一个标记。此外，我们提出了动态提示方法来提高效率。

    

    本文研究了在大型语言模型(LLMs)中进行上下文偏倚，即在第二次打分时为LLM提供额外的上下文信息，以提高自动语音识别(ASR)性能。我们提出了在打分期间利用提示信息对LLM进行boosting，而无需进行微调，这些提示信息包括偏倚列表和少样本示例，用于在计算假设得分时作为附加信息。除了少样本提示学习外，我们还提出了LLM的多任务训练，以预测实体类别和下一个标记。为了提高上下文偏倚的效率并避免超过LLMs的最大序列长度，我们提出了动态提示，即使用类别标签预测选择最可能的类别，并仅使用这个类别中的实体作为下一个标记预测的上下文。对内部的呼叫、消息和口述数据集以及SLUE-Voxpopuli数据集进行了词错误率(WER)评估。

    This paper studies contextual biasing with Large Language Models (LLMs), where during second-pass rescoring additional contextual information is provided to a LLM to boost Automatic Speech Recognition (ASR) performance. We propose to leverage prompts for a LLM without fine tuning during rescoring which incorporate a biasing list and few-shot examples to serve as additional information when calculating the score for the hypothesis. In addition to few-shot prompt learning, we propose multi-task training of the LLM to predict both the entity class and the next token. To improve the efficiency for contextual biasing and to avoid exceeding LLMs' maximum sequence lengths, we propose dynamic prompting, where we select the most likely class using the class tag prediction, and only use entities in this class as contexts for next token prediction. Word Error Rate (WER) evaluation is performed on i) an internal calling, messaging, and dictation dataset, and ii) the SLUE-Voxpopuli dataset. Results
    
[^2]: 利用人类反馈进行实际交通模拟的强化学习

    Reinforcement Learning with Human Feedback for Realistic Traffic Simulation. (arXiv:2309.00709v1 [cs.AI])

    [http://arxiv.org/abs/2309.00709](http://arxiv.org/abs/2309.00709)

    本研究利用强化学习与人类偏好相结合的框架来增强现有交通模型的真实性，并通过引入第一个用于交通建模中真实性对齐的数据集来支持此研究。

    

    鉴于真实世界测试的挑战和成本，自动驾驶车辆开发者通常依赖模拟测试来创建可靠的系统。有效模拟的关键要素是融入与人类知识相一致的真实交通模型，这一方面因为需要平衡真实性和多样性而具有挑战性。本研究旨在通过开发一个框架，利用强化学习与人类偏好（RLHF）来增强现有交通模型的真实性。该研究还确定了两个主要挑战：捕捉人类对真实性的微妙偏好以及统一多样的交通模拟模型。为了解决这些问题，我们建议使用人类反馈进行对齐，并采用RLHF因其样本效率高。我们还介绍了第一个用于交通建模中真实性对齐的数据集，以支持此类研究。我们的框架名为TrafficRLHF，在生成现实世界般的交通模拟数据方面展现了其能力。

    In light of the challenges and costs of real-world testing, autonomous vehicle developers often rely on testing in simulation for the creation of reliable systems. A key element of effective simulation is the incorporation of realistic traffic models that align with human knowledge, an aspect that has proven challenging due to the need to balance realism and diversity. This works aims to address this by developing a framework that employs reinforcement learning with human preference (RLHF) to enhance the realism of existing traffic models. This study also identifies two main challenges: capturing the nuances of human preferences on realism and the unification of diverse traffic simulation models. To tackle these issues, we propose using human feedback for alignment and employ RLHF due to its sample efficiency. We also introduce the first dataset for realism alignment in traffic modeling to support such research. Our framework, named TrafficRLHF, demonstrates its proficiency in generati
    
[^3]: 几何深度学习: 对图神经网络的基于温度的分析

    Geometric Deep Learning: a Temperature Based Analysis of Graph Neural Networks. (arXiv:2309.00699v1 [cs.LG])

    [http://arxiv.org/abs/2309.00699](http://arxiv.org/abs/2309.00699)

    本研究使用温度作为一个非量子和非相对论粒子的几何深度学习模型的分析方法，研究了GCN和GAT模型的各个层次中的温度，并讨论了可能的未来应用。

    

    我们将几何深度学习模型视为热力学系统，将权重看作非量子和非相对论粒子。我们采用之前在[7]中定义的温度概念，并研究了GCN和GAT模型的各个层次中的温度。讨论了我们发现的潜在未来应用。

    We examine a Geometric Deep Learning model as a thermodynamic system treating the weights as non-quantum and non-relativistic particles. We employ the notion of temperature previously defined in [7] and study it in the various layers for GCN and GAT models. Potential future applications of our findings are discussed.
    
[^4]: 在动态学习中共同探索客户漂移和灾难性遗忘

    Jointly Exploring Client Drift and Catastrophic Forgetting in Dynamic Learning. (arXiv:2309.00688v1 [cs.LG])

    [http://arxiv.org/abs/2309.00688](http://arxiv.org/abs/2309.00688)

    本论文提出了一个统一的分析框架，用于在动态学习中共同探索客户漂移和灾难性遗忘的问题。通过构建一个受控的测试环境，我们证明了客户漂移和灾难性遗忘背后的根本原因是相关的，并且通过生成一个3D地形图进一步验证了这种相关性。

    

    联邦学习和连续学习已经被提出作为在动态环境中稳健和隐私意识的使用深度学习的潜在范式。然而，客户漂移和灾难性遗忘是保证一致性性能的基本障碍。现有的工作只是分别解决这些问题，忽视了这两种性能下降背后的根本原因是联系在一起的事实。我们提出了一个统一的分析框架，用于构建一个受控的测试环境，以探索客户漂移 - 通过扰动一定比例的客户 - 和灾难性遗忘 - 通过以特定强度迁移所有客户 - 的影响。我们的框架通过生成一个从两者的组合性能影响产生的3D地形图进一步利用这种新的组合分析。我们证明了通过客户漂移引起的性能下降，通过一定比例的迁移客户，与由相应的迁移强度引起的灾难性遗忘的性能下降相关。

    Federated and Continual Learning have emerged as potential paradigms for the robust and privacy-aware use of Deep Learning in dynamic environments. However, Client Drift and Catastrophic Forgetting are fundamental obstacles to guaranteeing consistent performance. Existing work only addresses these problems separately, which neglects the fact that the root cause behind both forms of performance deterioration is connected. We propose a unified analysis framework for building a controlled test environment for Client Drift -- by perturbing a defined ratio of clients -- and Catastrophic Forgetting -- by shifting all clients with a particular strength. Our framework further leverages this new combined analysis by generating a 3D landscape of the combined performance impact from both. We demonstrate that the performance drop through Client Drift, caused by a certain share of shifted clients, is correlated to the drop from Catastrophic Forgetting resulting from a corresponding shift strength. 
    
[^5]: ICDARTS: 改进循环DARTS的稳定性和性能

    ICDARTS: Improving the Stability and Performance of Cyclic DARTS. (arXiv:2309.00664v1 [cs.LG])

    [http://arxiv.org/abs/2309.00664](http://arxiv.org/abs/2309.00664)

    ICDARTS改进了循环DARTS的稳定性和性能，通过消除评估网络权重对搜索网络权重的依赖，并引入修改后的搜索离散化过程。

    

    本研究改进了循环DARTS（CDARTS）的稳定性和泛化能力。CDARTS是一种基于可微分架构搜索（DARTS）的神经架构搜索（NAS）方法，使用循环反馈机制同时训练搜索和评估网络。该训练协议旨在通过强制要求搜索和评估网络产生相似的输出来优化搜索过程。然而，CDARTS引入了一个依赖于搜索网络的评估网络损失函数。搜索和重新训练阶段评估网络使用的损失函数的不相似性导致搜索阶段评估网络成为重新训练期间使用的最终评估网络的次优代理。我们提出ICDARTS，一种修正的方法，消除了评估网络权重对搜索网络权重的依赖，以及一种修改的搜索离散化过程。

    This work introduces improvements to the stability and generalizability of Cyclic DARTS (CDARTS). CDARTS is a Differentiable Architecture Search (DARTS)-based approach to neural architecture search (NAS) that uses a cyclic feedback mechanism to train search and evaluation networks concurrently. This training protocol aims to optimize the search process by enforcing that the search and evaluation networks produce similar outputs. However, CDARTS introduces a loss function for the evaluation network that is dependent on the search network. The dissimilarity between the loss functions used by the evaluation networks during the search and retraining phases results in a search-phase evaluation network that is a sub-optimal proxy for the final evaluation network that is utilized during retraining. We present ICDARTS, a revised approach that eliminates the dependency of the evaluation network weights upon those of the search network, along with a modified process for discretizing the search n
    
[^6]: 使用合成数据来训练AI模型：可持续发展的机遇与风险

    The Use of Synthetic Data to Train AI Models: Opportunities and Risks for Sustainable Development. (arXiv:2309.00652v1 [cs.LG])

    [http://arxiv.org/abs/2309.00652](http://arxiv.org/abs/2309.00652)

    合成数据是一种用于训练AI模型的人工生成数据，在保护隐私的同时提供了研究数据的可用性与减少机器学习模型偏见的机会，但同时也需要制定合适的政策来确保数据质量、真实性以及平衡隐私与数据效用之间的关系。

    

    在当前数据驱动的时代，合成数据，即人工生成的类似真实世界数据特征但不包含实际个人信息的数据，日益受到关注。这是因为它有潜力保护隐私、增加研究数据的可用性，并减少机器学习模型中的偏见。本文研究了合成数据的创建、利用和传播政策。合成数据可以是保护个人隐私的有力工具，但也面临挑战，如确保其质量和真实性。一个精心设计的合成数据政策必须在隐私关注和数据效用之间取得平衡，确保在不损害道德或法律标准的前提下有效利用数据。组织和机构必须制定标准化的指导方针和最佳实践，以充分利用合成数据的好处并解决其中的固有问题。

    In the current data driven era, synthetic data, artificially generated data that resembles the characteristics of real world data without containing actual personal information, is gaining prominence. This is due to its potential to safeguard privacy, increase the availability of data for research, and reduce bias in machine learning models. This paper investigates the policies governing the creation, utilization, and dissemination of synthetic data. Synthetic data can be a powerful instrument for protecting the privacy of individuals, but it also presents challenges, such as ensuring its quality and authenticity. A well crafted synthetic data policy must strike a balance between privacy concerns and the utility of data, ensuring that it can be utilized effectively without compromising ethical or legal standards. Organizations and institutions must develop standardized guidelines and best practices in order to capitalize on the benefits of synthetic data while addressing its inherent c
    
[^7]: GPT已经具备了金融素养：来自GPT金融素养测试的见解以及人们使用其作为咨询来源的初步测试

    GPT has become financially literate: Insights from financial literacy tests of GPT and a preliminary test of how people use it as a source of advice. (arXiv:2309.00649v1 [cs.CL])

    [http://arxiv.org/abs/2309.00649](http://arxiv.org/abs/2309.00649)

    GPT通过金融素养测试显示出具备成为大众金融机器顾问的能力，其中基于GPT-4的ChatGPT几乎完美地得分99%，揭示了金融素养正在成为最先进模型的新兴能力。

    

    通过使用金融素养测试，我们评估了GPT（一种大型语言模型）作为大众金融机器顾问的能力。基于GPT-3.5的Davinci和ChatGPT分别在金融素养测试中得分为66%和65%，而基于GPT-4的ChatGPT几乎完美地得到了99%的分数，这表明金融素养正在成为最先进模型的新兴能力。我们使用Judge-Advisor系统和一个储蓄困境来说明研究人员如何评估大型语言模型提供的建议利用情况。我们还提出了一些未来研究的方向。

    We assess the ability of GPT -- a large language model -- to serve as a financial robo-advisor for the masses, by using a financial literacy test. Davinci and ChatGPT based on GPT-3.5 score 66% and 65% on the financial literacy test, respectively, compared to a baseline of 33%. However, ChatGPT based on GPT-4 achieves a near-perfect 99% score, pointing to financial literacy becoming an emergent ability of state-of-the-art models. We use the Judge-Advisor System and a savings dilemma to illustrate how researchers might assess advice-utilization from large language models. We also present a number of directions for future research.
    
[^8]: 智能作为意识的衡量方式

    Intelligence as a Measure of Consciousness. (arXiv:2309.00646v1 [q-bio.NC])

    [http://arxiv.org/abs/2309.00646](http://arxiv.org/abs/2309.00646)

    评估人工系统是否具有意识的迹象是一个紧迫的问题，智力的心理测量可以间接地近似意识体验的程度，可以用来评估大型语言模型中的意识。

    

    评估人工系统是否具有意识的迹象越来越成为一个紧迫的问题，而一个严谨的心理测量框架在这方面对于评估大型语言模型可能非常重要。根据对人类和动物大脑的信息耦合、人类认知发展、新兴能力和心理表示发展与大型语言模型类似现象的比较，我认为智力的心理测量，如智商或智商指数，间接地近似了意识体验的程度。基于更广泛的科学和形而上学的意识理论，我认为所有系统都具有一定程度的可测量的意识，并且智力的心理测量可以用来衡量这种意识。

    Evaluating artificial systems for signs of consciousness is increasingly becoming a pressing concern, and a rigorous psychometric measurement framework may be of crucial importance in evaluating large language models in this regard. Most prominent theories of consciousness, both scientific and metaphysical, argue for different kinds of information coupling as a necessary component of human-like consciousness. By comparing information coupling in human and animal brains, human cognitive development, emergent abilities, and mental representation development to analogous phenomena in large language models, I argue that psychometric measures of intelligence, such as the g-factor or IQ, indirectly approximate the extent of conscious experience.  Based on a broader source of both scientific and metaphysical theories of consciousness, I argue that all systems possess a degree of consciousness ascertainable psychometrically and that psychometric measures of intelligence may be used to gauge re
    
[^9]: 优化的十个新基准

    Ten New Benchmarks for Optimization. (arXiv:2309.00644v1 [math.OC])

    [http://arxiv.org/abs/2309.00644](http://arxiv.org/abs/2309.00644)

    这篇论文介绍了十个新的基准，用于测试优化算法及其变体的性能。这些基准具有不同的特性，包括噪声、不连续性、参数估计和未知路径。

    

    基准用于测试新的优化算法及其变体，以评估其性能。大多数现有的基准是光滑函数。本章介绍了十个具有不同特性的新基准，包括噪声、不连续性、参数估计和未知路径。

    Benchmarks are used for testing new optimization algorithms and their variants to evaluate their performance. Most existing benchmarks are smooth functions. This chapter introduces ten new benchmarks with different properties, including noise, discontinuity, parameter estimation and unknown paths.
    
[^10]: 生成式人工智能用于端到端的限价订单簿建模：一种使用深度状态空间网络的令牌级自回归生成模型的消息流

    Generative AI for End-to-End Limit Order Book Modelling: A Token-Level Autoregressive Generative Model of Message Flow Using a Deep State Space Network. (arXiv:2309.00638v1 [q-fin.TR])

    [http://arxiv.org/abs/2309.00638](http://arxiv.org/abs/2309.00638)

    本论文提出了一种使用深度状态空间网络的令牌级自回归生成模型，可以生成逼真的限价订单簿消息，并且在逼近数据分布和中间价格回报方面表现出有前景的性能。

    

    在金融市场中开发一个逼真的订单流生成模型是一个具有挑战性的开放问题，具有许多市场参与者的应用。为解决这个问题，我们提出了第一个端到端的自回归生成模型，可以生成令牌化的限价订单簿(LOB)消息。这些消息由Jax-LOB模拟器解释，该模拟器更新LOB状态。为了高效处理长序列，该模型使用简化的结构化状态空间层来处理订单簿状态和令牌化消息的序列。利用NASDAQ股票LOBSTER数据，我们开发了一种自定义的消息数据分词器，将连续数字分组转换为令牌，类似于大型语言模型中的分词。外样本结果表明，在逼近数据分布方面，模型的困惑度较低，性能表现有前景。此外，从生成的订单流计算出的中间价格回报与数据呈显著相关性，表明了模型的潜在优势。

    Developing a generative model of realistic order flow in financial markets is a challenging open problem, with numerous applications for market participants. Addressing this, we propose the first end-to-end autoregressive generative model that generates tokenized limit order book (LOB) messages. These messages are interpreted by a Jax-LOB simulator, which updates the LOB state. To handle long sequences efficiently, the model employs simplified structured state-space layers to process sequences of order book states and tokenized messages. Using LOBSTER data of NASDAQ equity LOBs, we develop a custom tokenizer for message data, converting groups of successive digits to tokens, similar to tokenization in large language models. Out-of-sample results show promising performance in approximating the data distribution, as evidenced by low model perplexity. Furthermore, the mid-price returns calculated from the generated order flow exhibit a significant correlation with the data, indicating imp
    
[^11]: 通过简单的对齐技术进行多主体脑解码

    Through their eyes: multi-subject Brain Decoding with simple alignment techniques. (arXiv:2309.00627v1 [q-bio.NC])

    [http://arxiv.org/abs/2309.00627](http://arxiv.org/abs/2309.00627)

    通过简单的对齐技术，我们证明了跨主体脑解码是可行的，即使只使用约10%的数据，性能与单个主体解码相媲美。

    

    以往的脑解码研究主要涉及单个主体的研究，通过对同一主体的fMRI活动重建刺激。我们的研究旨在引入一种跨主体脑解码的通用技术，通过探索数据对齐方法来实现。我们利用NSD数据集，一个涉及多个主体的综合7T fMRI视觉实验，包括9841个图像，其中982个被所有主体观看。我们的方法是在一个主体上训练解码模型，将其他主体的数据对齐到该空间，并在第二个主体上进行解码测试。我们比较了岭回归、超级对齐和解剖对齐等不同的fMRI数据对齐技术。我们证明了跨主体脑解码是可行的，即使仅使用约10%的总数据，即982个共同图像，性能与单个主体解码相媲美。岭回归是功能对齐的最佳方法。通过主体对齐，我们实现了更优越的脑解码。

    Previous brain decoding research primarily involves single-subject studies, reconstructing stimuli via fMRI activity from the same subject. Our study aims to introduce a generalization technique for cross-subject brain decoding, facilitated by exploring data alignment methods. We utilized the NSD dataset, a comprehensive 7T fMRI vision experiment involving multiple subjects exposed to 9841 images, 982 of which were viewed by all. Our approach involved training a decoding model on one subject, aligning others' data to this space, and testing the decoding on the second subject. We compared ridge regression, hyper alignment, and anatomical alignment techniques for fMRI data alignment. We established that cross-subject brain decoding is feasible, even using around 10% of the total data, or 982 common images, with comparable performance to single-subject decoding. Ridge regression was the best method for functional alignment. Through subject alignment, we achieved superior brain decoding an
    
[^12]: 编程语言能通过指令调优相互提升吗？

    Can Programming Languages Boost Each Other via Instruction Tuning?. (arXiv:2308.16824v1 [cs.CL])

    [http://arxiv.org/abs/2308.16824](http://arxiv.org/abs/2308.16824)

    研究发现，编程语言可以在指令调优阶段相互促进，并显著提高彼此的能力。

    

    当人类程序员掌握了一种编程语言后，学习一种新的编程语言会更容易。在本报告中，我们重点探讨了在代码大规模语言模型的指令微调阶段中，编程语言是否能够通过相互提升来增强彼此的能力。我们在StarCoder上对8种流行的编程语言进行了广泛的实验（Python，JavaScript，TypeScript，C，C ++，Java，Go，HTML）。结果表明，编程语言可以显著提高彼此的能力。例如，通过在Python上训练的CodeM-Python 15B可以使Java的pass@1率绝对增加了17.95％。更令人惊讶的是，我们发现通过在HTML语料库上训练的CodeM-HTML 7B可以使Java的pass@1率绝对增加了15.24％。我们的训练数据已经发布在https://github.com/NL2Code/CodeM上。

    When human programmers have mastered a programming language, it would be easier when they learn a new programming language. In this report, we focus on exploring whether programming languages can boost each other during the instruction fine-tuning phase of code large language models. We conduct extensive experiments of 8 popular programming languages (Python, JavaScript, TypeScript, C, C++, Java, Go, HTML) on StarCoder. Results demonstrate that programming languages can significantly improve each other. For example, CodeM-Python 15B trained on Python is able to increase Java by an absolute 17.95% pass@1 on HumanEval-X. More surprisingly, we found that CodeM-HTML 7B trained on the HTML corpus can improve Java by an absolute 15.24% pass@1. Our training data is released at https://github.com/NL2Code/CodeM.
    
[^13]: 代理团队情景感知（ATSA）：人工智能与人类联合工作的情景感知框架

    Agent Teaming Situation Awareness (ATSA): A Situation Awareness Framework for Human-AI Teaming. (arXiv:2308.16785v1 [cs.AI])

    [http://arxiv.org/abs/2308.16785](http://arxiv.org/abs/2308.16785)

    代理团队情景感知（ATSA）是一个基于人工智能和人类联合工作的情景感知框架，旨在提高混合团队的绩效。该框架结合了个体和团队的情景感知模型，并涉及双向和动态的交互。

    

    人工智能的快速发展导致了人工智能与人类联合工作在各个领域的日益增长。随着机器从仅仅自动化到自主状态的演进，它们越来越展现出意外的行为和类似人类的认知/智能能力，包括情景感知。这种转变有潜力提高混合人工智能团队的绩效，强调了我们对人与机器之间动态情景感知相互作用的更好理解的需要。为此，我们对主流情景感知理论模型进行了回顾，并基于人工智能与人类联合工作的关键特征和过程，提出了一个新的情景感知框架。代理团队情景感知（ATSA）框架统一了人类和人工智能的行为，并涉及双向和动态的交互。该框架基于个体和团队的情景感知模型，并阐述了为建模人工智能与人类联合工作而细化的认知机制。类似的知觉循环

    The rapid advancements in artificial intelligence (AI) have led to a growing trend of human-AI teaming (HAT) in various fields. As machines continue to evolve from mere automation to a state of autonomy, they are increasingly exhibiting unexpected behaviors and human-like cognitive/intelligent capabilities, including situation awareness (SA). This shift has the potential to enhance the performance of mixed human-AI teams over all-human teams, underscoring the need for a better understanding of the dynamic SA interactions between humans and machines. To this end, we provide a review of leading SA theoretical models and a new framework for SA in the HAT context based on the key features and processes of HAT. The Agent Teaming Situation Awareness (ATSA) framework unifies human and AI behavior, and involves bidirectional, and dynamic interaction. The framework is based on the individual and team SA models and elaborates on the cognitive mechanisms for modeling HAT. Similar perceptual cycle
    
[^14]: StratMed：面向低资源药物推荐的相关性分层方法

    StratMed: Relevance Stratification for Low-resource Medication Recommendation. (arXiv:2308.16781v1 [cs.AI])

    [http://arxiv.org/abs/2308.16781](http://arxiv.org/abs/2308.16781)

    StratMed是一种面向低资源药物推荐的模型，通过相关性分层机制来解决医疗数据长尾分布不平衡的问题，平衡了药物组合的安全性和准确性。

    

    随着有限医疗资源与日益增长的需求之间的失衡，基于人工智能的临床任务变得至关重要。作为一个子领域，药物推荐旨在将患者的纵向历史与医学知识相结合，帮助医生更安全、更准确地开具药物组合处方。现有方法忽视了医疗数据中固有的长尾分布，缺乏头尾数据之间的平衡表示，导致模型性能次优。为了解决这个挑战，我们引入了StratMed，这是一个结合了创新的相关性分层机制的模型。它通过协调数据长尾分布中的差异，并在药物组合的安全性和准确性之间取得平衡。具体而言，我们首先使用深度学习网络构建预训练方法来获取实体表示。然后，我们设计了一个类似金字塔的数据分层方法，以获得更通用的实体表示。

    With the growing imbalance between limited medical resources and escalating demands, AI-based clinical tasks have become paramount. Medication recommendation, as a sub-domain, aims to amalgamate longitudinal patient history with medical knowledge, assisting physicians in prescribing safer and more accurate medication combinations. Existing methods overlook the inherent long-tail distribution in medical data, lacking balanced representation between head and tail data, which leads to sub-optimal model performance. To address this challenge, we introduce StratMed, a model that incorporates an innovative relevance stratification mechanism. It harmonizes discrepancies in data long-tail distribution and strikes a balance between the safety and accuracy of medication combinations. Specifically, we first construct a pre-training method using deep learning networks to obtain entity representation. After that, we design a pyramid-like data stratification method to obtain more generalized entity 
    
[^15]: 朝着工业控制系统低门槛的网络安全研究和教育发展

    Towards Low-Barrier Cybersecurity Research and Education for Industrial Control Systems. (arXiv:2308.16769v1 [cs.CR])

    [http://arxiv.org/abs/2308.16769](http://arxiv.org/abs/2308.16769)

    该论文介绍了在工业控制系统网络安全领域进行低门槛研究和教育的重要性。通过利用开发的高保真模拟器，作者构建了一个集成框架用于自动发动网络攻击、收集数据、训练机器学习模型，并针对实际的化学和制造过程进行评估。作者还提出了一种名为MinTWin SVM的入侵检测模型，它结合了无监督机器学习和滑动窗口的方法。

    

    保护用于公共关键基础设施的工业控制系统(ICS)对于防止网络攻击造成灾难性的物理损害至关重要。研究界需要测试平台来验证和比较各种入侵检测算法以保护ICS。然而，由于昂贵的硬件、软件和操纵现实系统的固有危险性，ICS网络安全领域的研究和教育存在高门槛。为了弥补这一差距，我们在最近开发的三维高保真模拟器基础上，进一步展示了我们的集成框架，可以自动发动网络攻击、收集数据、训练机器学习模型，并针对实际的化学和制造过程进行评估。在我们的测试平台上，我们验证了我们提出的入侵检测模型，称为Minimal Threshold and Window SVM (MinTWin SVM)，它结合了一类SVM的无监督机器学习和滑动窗口

    The protection of Industrial Control Systems (ICS) that are employed in public critical infrastructures is of utmost importance due to catastrophic physical damages cyberattacks may cause. The research community requires testbeds for validation and comparing various intrusion detection algorithms to protect ICS. However, there exist high barriers to entry for research and education in the ICS cybersecurity domain due to expensive hardware, software, and inherent dangers of manipulating real-world systems. To close the gap, built upon recently developed 3D high-fidelity simulators, we further showcase our integrated framework to automatically launch cyberattacks, collect data, train machine learning models, and evaluate for practical chemical and manufacturing processes. On our testbed, we validate our proposed intrusion detection model called Minimal Threshold and Window SVM (MinTWin SVM) that utilizes unsupervised machine learning via a one-class SVM in combination with a sliding wind
    
[^16]: 任何人都可以攻击：将有损压缩重新用作自然后门攻击

    Everyone Can Attack: Repurpose Lossy Compression as a Natural Backdoor Attack. (arXiv:2308.16684v1 [cs.CR])

    [http://arxiv.org/abs/2308.16684](http://arxiv.org/abs/2308.16684)

    本文发现了一种更严重的后门攻击威胁，即任何人都可以利用易获取的有损压缩算法进行自然后门攻击，无需设计特定触发器或进行繁琐调试。

    

    最近，后门攻击对实际应用中的机器学习模型的可信度构成了威胁。传统智慧认为，并不是每个人都可以成为攻击者，因为设计触发器生成算法的过程通常需要大量的努力和广泛的实验来确保攻击的隐秘性和有效性。然而，本文指出存在一种更为严重的后门威胁：任何人都可以利用易获取的算法进行隐悄后门攻击。具体来说，攻击者可以利用各种压缩工具中广泛使用的有损图片压缩技术，无需留下任何明显的痕迹就能轻松地将触发器模式注入到图像中，即生成的触发器是自然的图像伪影。使用有损图片压缩工具时，人们并不需要广泛知识，只需点击“转换”或“另存为”按钮即可。通过这种攻击，攻击者无需设计一个专门的触发器或进行繁琐的调试。

    The vulnerabilities to backdoor attacks have recently threatened the trustworthiness of machine learning models in practical applications. Conventional wisdom suggests that not everyone can be an attacker since the process of designing the trigger generation algorithm often involves significant effort and extensive experimentation to ensure the attack's stealthiness and effectiveness. Alternatively, this paper shows that there exists a more severe backdoor threat: anyone can exploit an easily-accessible algorithm for silent backdoor attacks. Specifically, this attacker can employ the widely-used lossy image compression from a plethora of compression tools to effortlessly inject a trigger pattern into an image without leaving any noticeable trace; i.e., the generated triggers are natural artifacts. One does not require extensive knowledge to click on the "convert" or "save as" button while using tools for lossy image compression. Via this attack, the adversary does not need to design a 
    
[^17]: 通过合作专家实现长尾图分类的研究

    Towards Long-Tailed Recognition for Graph Classification via Collaborative Experts. (arXiv:2308.16609v1 [cs.LG])

    [http://arxiv.org/abs/2308.16609](http://arxiv.org/abs/2308.16609)

    本文提出了一种新颖的方法，通过合作专家实现了长尾图分类，解决了现有方法在处理图数据上的不足。

    

    图分类旨在学习用于有效类别分配的图级表示，在平衡的类别分布的高质量数据集的支持下取得了杰出成果。事实上，大多数现实世界的图数据自然呈现长尾形式，其中头部类别的样本数量远超过尾部类别，因此在长尾数据上研究图级分类是至关重要的，但仍然较少探索。然而，现有的视觉中的长尾学习方法大多无法同时优化表示学习和分类器训练，并且忽略了难以分类的类别的挖掘。直接将现有方法应用于图可能导致次优性能，因为在图上训练的模型由于复杂的拓扑特征会更加敏感于长尾分布。因此，在本文中，我们提出了一种新颖的对长尾图级分类的方法

    Graph classification, aiming at learning the graph-level representations for effective class assignments, has received outstanding achievements, which heavily relies on high-quality datasets that have balanced class distribution. In fact, most real-world graph data naturally presents a long-tailed form, where the head classes occupy much more samples than the tail classes, it thus is essential to study the graph-level classification over long-tailed data while still remaining largely unexplored. However, most existing long-tailed learning methods in visions fail to jointly optimize the representation learning and classifier training, as well as neglect the mining of the hard-to-classify classes. Directly applying existing methods to graphs may lead to sub-optimal performance, since the model trained on graphs would be more sensitive to the long-tailed distribution due to the complex topological characteristics. Hence, in this paper, we propose a novel long-tailed graph-level classifica
    
[^18]: 潜在画家

    Latent Painter. (arXiv:2308.16490v1 [cs.CV])

    [http://arxiv.org/abs/2308.16490](http://arxiv.org/abs/2308.16490)

    这个论文介绍了一种名为潜在画家的技术，它利用潜在作为画布和扩散器的预测作为计划来生成绘画动画，同时还可以在不同的检查点集中转换图像。

    

    潜在扩散器在生成AI领域引起了革命，并激发了创造性艺术。在去噪潜在时，每个步骤预测的原始图像共同形成了动画。然而，动画受到扩散器去噪特性的限制，只呈现了一个锐化过程。本文介绍了潜在画家，它以潜在作为画布，以扩散器的预测作为计划，生成绘画动画。潜在画家还可以将一个生成的图像转换为另一个图像，这可以发生在两个不同检查点集中的图像之间。

    Latent diffusers revolutionized the generative AI and inspired creative art. When denoising the latent, the predicted original image at each step collectively animates the formation. However, the animation is limited by the denoising nature of the diffuser, and only renders a sharpening process. This work presents Latent Painter, which uses the latent as the canvas, and the diffuser predictions as the plan, to generate painting animation. Latent Painter also transits one generated image to another, which can happen between images from two different sets of checkpoints.
    
[^19]: 使用元学习进行点云上采样的测试时间适应

    Test-Time Adaptation for Point Cloud Upsampling Using Meta-Learning. (arXiv:2308.16484v1 [cs.CV])

    [http://arxiv.org/abs/2308.16484](http://arxiv.org/abs/2308.16484)

    本文提出了一种使用元学习进行测试时间适应的方法来增强点云上采样模型的普适性，解决了测试数据分布与训练数据不同导致性能下降的问题。

    

    廉价的3D扫描仪经常产生稀疏和非均匀的点云，这对机器人系统中的下游应用产生负面影响。虽然现有的点云上采样架构在标准基准数据上展示了有希望的结果，但当测试数据与训练数据具有不同分布时，它们往往会出现显著的性能下降。为了解决这个问题，本文提出了一种测试时间适应方法来增强点云上采样模型的普适性。所提出的方法利用元学习来显式地学习测试时间适应的网络参数。我们的方法不需要任何关于测试数据的先验信息。在元训练过程中，模型参数是从训练数据的稀疏-密集点云对的集合中学习的。在元测试过程中，经过少量梯度更新的训练模型可以产生一组唯一的网络参数。

    Affordable 3D scanners often produce sparse and non-uniform point clouds that negatively impact downstream applications in robotic systems. While existing point cloud upsampling architectures have demonstrated promising results on standard benchmarks, they tend to experience significant performance drops when the test data have different distributions from the training data. To address this issue, this paper proposes a test-time adaption approach to enhance model generality of point cloud upsampling. The proposed approach leverages meta-learning to explicitly learn network parameters for test-time adaption. Our method does not require any prior information about the test data. During meta-training, the model parameters are learned from a collection of instance-level tasks, each of which consists of a sparse-dense pair of point clouds from the training data. During meta-testing, the trained model is fine-tuned with a few gradient updates to produce a unique set of network parameters for
    
[^20]: Point-TTA: 使用多任务元辅助学习的点云配准测试时间自适应

    Point-TTA: Test-Time Adaptation for Point Cloud Registration Using Multitask Meta-Auxiliary Learning. (arXiv:2308.16481v1 [cs.CV])

    [http://arxiv.org/abs/2308.16481](http://arxiv.org/abs/2308.16481)

    Point-TTA是一种通过多任务元辅助学习实现的点云配准测试时自适应框架，能够提高配准模型的泛化性能。

    

    我们提出了Point-TTA，这是一种新颖的点云配准测试时间自适应框架，可以提高配准模型的泛化性能。虽然基于学习的方法取得了令人印象深刻的进展，但面对未知的测试环境的泛化仍然是一个重大挑战，原因是3D扫描的变化较大。现有方法通常训练一个通用模型，并在每个实例上应用相同的训练模型。这可能是次优的，因为同一模型很难处理测试期间的所有变化。在本文中，我们提出了一种用于点云配准的测试时间自适应方法。我们的模型可以适应测试时未知的分布，无需任何关于测试数据的先验知识。具体地，我们设计了三个自监督辅助任务，这些任务与主要的配准任务一起进行优化。给定一个测试实例，我们使用这些辅助任务来调整我们的模型，并使用更新后的模型进行推断。

    We present Point-TTA, a novel test-time adaptation framework for point cloud registration (PCR) that improves the generalization and the performance of registration models. While learning-based approaches have achieved impressive progress, generalization to unknown testing environments remains a major challenge due to the variations in 3D scans. Existing methods typically train a generic model and the same trained model is applied on each instance during testing. This could be sub-optimal since it is difficult for the same model to handle all the variations during testing. In this paper, we propose a test-time adaptation approach for PCR. Our model can adapt to unseen distributions at test-time without requiring any prior knowledge of the test data. Concretely, we design three self-supervised auxiliary tasks that are optimized jointly with the primary PCR task. Given a test instance, we adapt our model using these auxiliary tasks and the updated model is used to perform the inference. 
    
[^21]: BioCoder: 一种带有上下文语用知识的生物信息学代码生成基准

    BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge. (arXiv:2308.16458v1 [cs.LG])

    [http://arxiv.org/abs/2308.16458](http://arxiv.org/abs/2308.16458)

    BioCoder是一个用于评估预训练模型在生成生物信息学代码方面的基准，涵盖了函数代码生成中的包依赖关系、类声明和全局变量，并通过模糊测试框架进行评估。

    

    预训练的语言模型（如ChatGPT）显著改进了代码生成。随着这些模型的扩大，需要输出来处理更复杂的任务的需求也越来越多。此外，在生物信息学中，生成功能程序由于领域知识量大、需要复杂的数据操作和复杂的功能依赖关系而面临额外的挑战。在这里，我们介绍了BioCoder，这是一个用于评估现有预训练模型在生成生物信息学代码方面的基准。与函数代码生成有关，BioCoder涵盖了可能的包依赖关系、类声明和全局变量。它包括来自GitHub的1026个Python和Java函数和1243个方法，以及来自Rosalind项目的253个示例。BioCoder还结合了一个用于评估的模糊测试框架，我们已经应用它来评估许多模型，包括InCoder、CodeGen、CodeGen2、SantaCoder、StarCoder、StarCoder+、InstructCodeT。

    Pre-trained language models like ChatGPT have significantly improved code generation. As these models scale up, there is an increasing need for the output to handle more intricate tasks. Moreover, in bioinformatics, generating functional programs poses additional notable challenges due to the amount of domain knowledge, the need for complicated data operations, and intricate functional dependencies between the operations. Here, we present BioCoder, a benchmark developed to evaluate existing pre-trained models in generating bioinformatics code. In relation to function-code generation, BioCoder covers potential package dependencies, class declarations, and global variables. It incorporates 1026 functions and 1243 methods in Python and Java from GitHub and 253 examples from the Rosalind Project. BioCoder incorporates a fuzz-testing framework for evaluation, and we have applied it to evaluate many models including InCoder, CodeGen, CodeGen2, SantaCoder, StarCoder, StarCoder+, InstructCodeT
    
[^22]: 有竞争选择的因果战略学习

    Causal Strategic Learning with Competitive Selection. (arXiv:2308.16262v1 [cs.AI])

    [http://arxiv.org/abs/2308.16262](http://arxiv.org/abs/2308.16262)

    我们研究了具有竞争选择的因果战略学习中的代理选择问题，并提出了最佳选择规则的数学形式和实现机制。

    

    我们研究了多个决策者下的因果战略学习中的代理选择问题，并解决了其中的两个关键挑战。首先，我们考虑了由代理人评估和选择组成的选择过程的影响，而不是之前研究中关注的固定代理人池。当每个决策者通过最大化自身效用来单方面选择代理人时，我们证明了最佳的选择规则是在选择最佳代理人和提供激励以最大化代理人改进之间进行权衡的结果。此外，这个最佳选择规则依赖于代理人结果的错误预测。因此，我们研究了决策者的最佳选择规则不会导致代理人结果恶化，也不会造成不公正的降低代理人选择机会的条件。为此，我们提供了最佳选择规则的数学形式和一种实现机制。

    We study the problem of agent selection in causal strategic learning under multiple decision makers and address two key challenges that come with it. Firstly, while much of prior work focuses on studying a fixed pool of agents that remains static regardless of their evaluations, we consider the impact of selection procedure by which agents are not only evaluated, but also selected. When each decision maker unilaterally selects agents by maximising their own utility, we show that the optimal selection rule is a trade-off between selecting the best agents and providing incentives to maximise the agents' improvement. Furthermore, this optimal selection rule relies on incorrect predictions of agents' outcomes. Hence, we study the conditions under which a decision maker's optimal selection rule will not lead to deterioration of agents' outcome nor cause unjust reduction in agents' selection chance. To that end, we provide an analytical form of the optimal selection rule and a mechanism to r
    
[^23]: LM-Infinite: 大规模语言模型的简单即时长度推广

    LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models. (arXiv:2308.16137v1 [cs.CL])

    [http://arxiv.org/abs/2308.16137](http://arxiv.org/abs/2308.16137)

    LM-Infinite研究了大规模语言模型在长序列上的长度推广失败问题，并提出了一种简单的即时推广方法，以更高效地利用现有模型的生成能力。

    

    近年来，在Transformer-based大规模语言模型（LLM）在各个领域取得了显著的进展。随着这些LLM在越来越复杂的任务上的部署，它们往往面临着对长时间推理过程或理解更大上下文的需求。在这些情况下，LLM在长序列上的长度推广失败变得更加突出。大多数预训练方案将训练序列截断到固定长度（例如LLaMa的2048）。即使使用了相对位置编码来应对这个问题，LLM在更长的上下文之后往往难以生成流畅的文本，更不用说进行下游任务了。常见的解决方案，如在更长的语料库上进行微调，往往需要耗费大量的硬件和时间成本，并需要进行仔细的训练过程设计。为了更高效地利用现有LLM的生成能力，我们在理论和实证上研究了主要的分布外(OOD) f

    In recent years, there have been remarkable advancements in the performance of Transformer-based Large Language Models (LLMs) across various domains. As these LLMs are deployed for increasingly complex tasks, they often face the needs to conduct longer reasoning processes or understanding larger contexts. In these situations, the length generalization failure of LLMs on long sequences become more prominent. Most pre-training schemes truncate training sequences to a fixed length (such as 2048 for LLaMa). LLMs often struggle to generate fluent texts, let alone carry out downstream tasks, after longer contexts, even with relative positional encoding which is designed to cope with this problem. Common solutions such as finetuning on longer corpora often involves daunting hardware and time costs and requires careful training process design. To more efficiently leverage the generation capacity of existing LLMs, we theoretically and empirically investigate the main out-of-distribution (OOD) f
    
[^24]: 美国法律体系是否准备好应对人工智能对人类价值观的挑战？

    Is the U.S. Legal System Ready for AI's Challenges to Human Values?. (arXiv:2308.15906v1 [cs.CY])

    [http://arxiv.org/abs/2308.15906](http://arxiv.org/abs/2308.15906)

    美国法律需要加强应对生成式人工智能对人类价值观挑战的能力，并提供积极、可审计的指导，以填补现有法律框架在保护基本价值观方面的空白和不确定性。

    

    我们的跨学科研究调查了美国法律在面对生成式人工智能对人类价值观挑战时的有效性。通过分析专家研讨会期间制定的多种假设情景，我们发现现有法律框架在保护自主权、隐私权、尊严、多样性、平等以及身心健康等基本价值观方面存在明显的空白和不确定性。宪法和民权法似乎无法对人工智能生成的歧视性产出提供足够的保护。此外，即使我们排除第230条款提供的责任保护，由于人工智能系统的复杂和不透明性，证明诽谤和产品责任索赔的因果关系也是一项具有挑战性的任务。为了应对生成式人工智能带来的独特和难以预测的威胁，我们主张建立能够适应新威胁并为行业利益相关者提供积极、可审计的指导的法律框架。

    Our interdisciplinary study investigates how effectively U.S. laws confront the challenges posed by Generative AI to human values. Through an analysis of diverse hypothetical scenarios crafted during an expert workshop, we have identified notable gaps and uncertainties within the existing legal framework regarding the protection of fundamental values, such as autonomy, privacy, dignity, diversity, equality, and physical/mental well-being. Constitutional and civil rights, it appears, may not provide sufficient protection against AI-generated discriminatory outputs. Furthermore, even if we exclude the liability shield provided by Section 230, proving causation for defamation and product liability claims is a challenging endeavor due to the intricate and opaque nature of AI systems. To address the unique and unforeseeable threats posed by Generative AI, we advocate for legal frameworks that evolve to recognize new threat and provide proactive, auditable guidelines to industry stakeholders
    
[^25]: 用于心脏超声解读的多模式基础模型

    Multimodal Foundation Models For Echocardiogram Interpretation. (arXiv:2308.15670v1 [cs.CV])

    [http://arxiv.org/abs/2308.15670](http://arxiv.org/abs/2308.15670)

    该论文提出了一个名为EchoCLIP的多模式基础模型，用于心脏超声解读。该模型利用大量的心脏超声视频和专家解读来实现强大的零样本性能，并在心脏功能评估和植入心脏内器件识别方面表现出良好的性能。

    

    多模式深度学习基础模型可以学习图像和文本之间的关系。在医学成像的背景下，将图像映射到语言概念反映了诊断图像解释的临床任务，然而当前通用的基础模型在这个背景下表现不佳，因为它们的训练文本和图像数据有限。为了解决这个挑战并考虑到心脏生理的范围，我们利用1,032,975个心脏超声视频和相应的专家解读开发了EchoCLIP，一个用于心脏超声的多模式基础模型。EchoCLIP在心脏功能评估（外部验证左室射血分数的平均绝对误差（MAE）为7.1%）和植入心脏内器件的识别方面表现出强大的零样本（未经过显式训练）性能（起搏器和人工心脏瓣膜的曲线下面积（AUC）在0.84至0.98之间）。我们还开发了一个长上下文可变模型来实现更好的模型性能。

    Multimodal deep learning foundation models can learn the relationship between images and text. In the context of medical imaging, mapping images to language concepts reflects the clinical task of diagnostic image interpretation, however current general-purpose foundation models do not perform well in this context because their training corpus have limited medical text and images. To address this challenge and account for the range of cardiac physiology, we leverage 1,032,975 cardiac ultrasound videos and corresponding expert interpretations to develop EchoCLIP, a multimodal foundation model for echocardiography. EchoCLIP displays strong zero-shot (not explicitly trained) performance in cardiac function assessment (external validation left ventricular ejection fraction mean absolute error (MAE) of 7.1%) and identification of implanted intracardiac devices (areas under the curve (AUC) between 0.84 and 0.98 for pacemakers and artificial heart valves). We also developed a long-context vari
    
[^26]: 图神经网络中的过度压缩问题：一项全面调查

    Over-Squashing in Graph Neural Networks: A Comprehensive survey. (arXiv:2308.15568v1 [cs.AI])

    [http://arxiv.org/abs/2308.15568](http://arxiv.org/abs/2308.15568)

    过度压缩是图神经网络面临的关键挑战，它限制了节点之间的长程信息传递，影响了在需要广泛上下文洞察力的情况下的准确预测。

    

    图神经网络（GNN）已成为机器学习领域的一种革命性范 Paradigm，为分析图结构数据中固有的复杂关系提供了一种变革性方法。大多数GNN的基本架构涉及通过消息聚合和转换在相互连接的节点之间传播信息的机制，在包括节点分类、链接预测和推荐系统的各种应用中已经展现出显著的有效性。然而，它们的潜在实力遇到了在需要广泛上下文洞察力的情况下固有的限制。在某些情境中，准确的预测不仅取决于节点的即时局部环境，还取决于跨越广域的交互作用。这种复杂的对长程信息传播的需求暴露了一个被称为“过度压缩”的关键挑战，其中来自远离节点的信息流的可靠性受到影响。

    Graph Neural Networks (GNNs) have emerged as a revolutionary paradigm in the realm of machine learning, offering a transformative approach to dissect intricate relationships inherent in graph-structured data. The foundational architecture of most GNNs involves the dissemination of information through message aggregation and transformation among interconnected nodes, a mechanism that has demonstrated remarkable efficacy across diverse applications encompassing node classification, link prediction, and recommendation systems. Nonetheless, their potential prowess encounters a restraint intrinsic to scenarios necessitating extensive contextual insights. In certain contexts, accurate predictions hinge not only upon a node's immediate local surroundings but also on interactions spanning far-reaching domains. This intricate demand for long-range information dissemination exposes a pivotal challenge recognized as "over-squashing," wherein the fidelity of information flow from distant nodes bec
    
[^27]: ParaGuide: 用于即插即用文本风格转移的引导性扩散改写器

    ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style Transfer. (arXiv:2308.15459v1 [cs.CL])

    [http://arxiv.org/abs/2308.15459](http://arxiv.org/abs/2308.15459)

    ParaGuide是一种用于通用风格转移的引导性扩散改写器，可以灵活适应任意目标风格，通过梯度引导和改写条件的扩散模型实现文本的风格转变，同时保留语义信息。

    

    文本风格转移是在保留意义的同时转变文本的风格属性的任务。目标风格可以以多种方式定义，从单一属性（例如正式性）到作者（例如莎士比亚）。先前的无监督风格转移方法通常依赖于大量标记数据，仅适用于固定的风格集，或需要大型语言模型。相反，我们引入了一种新的基于扩散的通用风格转移框架，可以在推理时灵活适应任意目标风格。我们的参数高效方法ParaGuide利用了改写条件的扩散模型以及来自现成的分类器和强大的风格嵌入器的梯度引导，以转变文本的风格同时保留语义信息。我们在Enron邮件语料库上进行了验证，包括人工和自动评估，并发现其在正式性和... (内容太多，请参考英文摘要)

    Textual style transfer is the task of transforming stylistic properties of text while preserving meaning. Target "styles" can be defined in numerous ways, ranging from single attributes (e.g, formality) to authorship (e.g, Shakespeare). Previous unsupervised style-transfer approaches generally rely on significant amounts of labeled data for only a fixed set of styles or require large language models. In contrast, we introduce a novel diffusion-based framework for general-purpose style transfer that can be flexibly adapted to arbitrary target styles at inference time. Our parameter-efficient approach, ParaGuide, leverages paraphrase-conditioned diffusion models alongside gradient-based guidance from both off-the-shelf classifiers and strong existing style embedders to transform the style of text while preserving semantic information. We validate the method on the Enron Email Corpus, with both human and automatic evaluations, and find that it outperforms strong baselines on formality, se
    
[^28]: 冲突感知的主动有限状态机学习

    Conflict-Aware Active Automata Learning. (arXiv:2308.14781v1 [cs.LG])

    [http://arxiv.org/abs/2308.14781](http://arxiv.org/abs/2308.14781)

    C3AL是一种冲突感知的主动有限状态机学习框架，能够处理观测数据中的冲突，通过将观测树作为学习过程的一等公民并最小化测试次数，具有很好的效果。

    

    主动有限状态机学习算法在处理观测数据中的冲突（同一输入对应不同输出）方面存在困难。这种固有的冲突恢复能力不足，影响了它们在存在噪声或学习中的系统变化场景中的有效应用。我们提出了冲突感知的主动有限状态机学习（C3AL）框架，以在学习过程中处理冲突信息。核心思想是将所谓的观测树视为学习过程的一等公民。尽管这个想法在最近的研究中得到了探索，但我们通过将其与任何现有的学习算法结合，并在面对冲突时最小化对正在学习的系统执行的测试次数，充分发挥了它的作用。我们在大量的基准测试中评估了C3AL，涵盖了30多个不同的真实目标和18,000多个不同的场景。评估结果表明，C3AL是一个合适的替代方法。

    Active automata learning algorithms cannot easily handle \emph{conflict} in the observation data (different outputs observed for the same inputs). This inherent inability to recover after a conflict impairs their effective applicability in scenarios where noise is present or the system under learning is mutating.  We propose the Conflict-Aware Active Automata Learning (C3AL) framework to enable handling conflicting information during the learning process. The core idea is to consider the so-called observation tree as a first-class citizen in the learning process. Though this idea is explored in recent work, we take it to its full effect by enabling its use with any existing learner and minimizing the number of tests performed on the system under learning, specially in the face of conflicts. We evaluate C3AL in a large set of benchmarks, covering over 30 different realistic targets, and over 18,000 different scenarios. The results of the evaluation show that C3AL is a suitable alternati
    
[^29]: LLM强化了交通信号控制的从仿真到真实的迁移

    LLM Powered Sim-to-real Transfer for Traffic Signal Control. (arXiv:2308.14284v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.14284](http://arxiv.org/abs/2308.14284)

    本研究利用大型语言模型（LLMs）通过基于提示的行动转换，解决了交通信号控制任务中从仿真到真实的迁移问题。

    

    尽管已经有很多解决方案用于交通信号控制（TSC）任务，旨在提供高效的交通和减轻拥堵浪费，但仍然存在性能差距，当在仿真器中训练的策略部署到现实世界时。本研究利用大型语言模型（LLMs）通过基于提示的扎根行动转换，来理解和描述系统动态。通过接受填空提示模板，并根据可以访问的上下文填写答案，利用预训练的LLM的推理能力，应用于对系统动态的理解。

    Numerous solutions are proposed for the Traffic Signal Control (TSC) tasks aiming to provide efficient transportation and mitigate congestion waste. In recent, promising results have been attained by Reinforcement Learning (RL) methods through trial and error in simulators, bringing confidence in solving cities' congestion headaches. However, there still exist performance gaps when simulator-trained policies are deployed to the real world. This issue is mainly introduced by the system dynamic difference between the training simulator and the real-world environments. The Large Language Models (LLMs) are trained on mass knowledge and proved to be equipped with astonishing inference abilities. In this work, we leverage LLMs to understand and profile the system dynamics by a prompt-based grounded action transformation. Accepting the cloze prompt template, and then filling in the answer based on accessible context, the pre-trained LLM's inference ability is exploited and applied to understa
    
[^30]: 为Dentex Challenge 2023整合分割和检测模型

    Intergrated Segmentation and Detection Models for Dentex Challenge 2023. (arXiv:2308.14161v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2308.14161](http://arxiv.org/abs/2308.14161)

    本文提出了一种整合分割和检测模型的方法，用于从牙科全景 X 射线中自动检测异常牙齿及其枚举号。

    

    牙科全景X射线在牙科诊断中被广泛使用。随着深度学习的发展，从牙科全景X射线中自动检测疾病可以帮助牙医更高效地诊断疾病。Dentex Challenge 2023是一个自动检测牙科全景X射线中异常牙齿及其枚举号的比赛。本文提出了一种整合了分割和检测模型的方法，以检测异常牙齿并获取其枚举号。我们的代码可在https://github.com/xyzlancehe/DentexSegAndDet获取。

    Dental panoramic x-rays are commonly used in dental diagnosing. With the development of deep learning, auto detection of diseases from dental panoramic x-rays can help dentists to diagnose diseases more efficiently.The Dentex Challenge 2023 is a competition for automatic detection of abnormal teeth along with their enumeration ids from dental panoramic x-rays. In this paper, we propose a method integrating segmentation and detection models to detect abnormal teeth as well as obtain their enumeration ids.Our codes are available at https://github.com/xyzlancehe/DentexSegAndDet.
    
[^31]: 通过跨模型一致性进行标签去噪

    Label Denoising through Cross-Model Agreement. (arXiv:2308.13976v1 [cs.LG])

    [http://arxiv.org/abs/2308.13976](http://arxiv.org/abs/2308.13976)

    本文提出了一种通过跨模型一致性进行标签去噪的方法。通过观察发现，不同模型在干净示例上的预测相对相似，而在有噪声示例上的预测在不同模型之间变化更大。在这种观察的启发下，我们提出了使用跨模型一致性进行去噪的方法（DeCA），旨在最小化两个机器学习模型参数化的真实标签分布之间的KL散度，同时最大化数据观测的似然。

    

    在现实世界的机器学习应用中，从有噪声的标签学习是非常常见的。记忆这些有噪声的标签可能会影响模型的学习，从而导致次优的性能。在这项工作中，我们提出了一种新颖的框架，用于从有噪声标签中学习鲁棒的机器学习模型。通过实证研究，我们发现不同模型在干净示例上的预测相对相似，而在有噪声示例上的预测在不同模型之间变化更大。受到这一观察的启发，我们提出了使用跨模型一致性进行去噪（DeCA）的方法，该方法旨在最小化由两个机器学习模型参数化的真实标签分布之间的KL散度，同时最大化数据观测的似然。我们将提出的DeCA方法应用于二进制标签情景和多标签情景。对于二进制标签情景，我们选择隐式反馈推荐作为下游任务，并进行了四种最先进方法的实验。

    Learning from corrupted labels is very common in real-world machine-learning applications. Memorizing such noisy labels could affect the learning of the model, leading to sub-optimal performances. In this work, we propose a novel framework to learn robust machine-learning models from noisy labels. Through an empirical study, we find that different models make relatively similar predictions on clean examples, while the predictions on noisy examples vary much more across different models. Motivated by this observation, we propose \em denoising with cross-model agreement \em (DeCA) which aims to minimize the KL-divergence between the true label distributions parameterized by two machine learning models while maximizing the likelihood of data observation. We employ the proposed DeCA on both the binary label scenario and the multiple label scenario. For the binary label scenario, we select implicit feedback recommendation as the downstream task and conduct experiments with four state-of-the
    
[^32]: 一颗开放的卫星高光谱数据集与来自HYPSO-1卫星的海陆云地面真实数据

    An Open Hyperspectral Dataset with Sea-Land-Cloud Ground-Truth from the HYPSO-1 Satellite. (arXiv:2308.13679v1 [cs.CV])

    [http://arxiv.org/abs/2308.13679](http://arxiv.org/abs/2308.13679)

    这个论文介绍了一个开放的卫星高光谱数据集，包含了来自HYPSO-1卫星的海陆云地面真实数据，并且通过优化深度学习模型，取得了比现有技术更好的性能。

    

    高光谱成像被卫星用于空间遥感，在像HYPSO-1这样的卫星上，面临着少量标注数据集的限制，影响了对需求这些地面真实标注的AI模型的训练。在本研究中，我们介绍了HYPSO-1海陆云标注数据集，这是一个包含200个不同高光谱图像的开放数据集，来自于HYPSO-1任务，可提供未经校准和经过校准的形式，供地球观测的科学研究使用。此外，其中包括来自不同国家的38个图像，在像素级别上包含总计约2500万个为海洋/陆地/云分类标记的光谱特征。为了展示数据集及其标记子集的潜力，我们还优化了一个深度学习模型（1D完全卷积网络），在性能上超过了当前技术水平。完整的数据集，地面真实标注，深度学习模型和软件代码可在网站https://ntnu-sm上免费下载。

    Hyperspectral Imaging, employed in satellites for space remote sensing, like HYPSO-1, faces constraints due to few labeled data sets, affecting the training of AI models demanding these ground-truth annotations. In this work, we introduce The HYPSO-1 Sea-Land-Cloud-Labeled Dataset, an open dataset with 200 diverse hyperspectral images from the HYPSO-1 mission, available in both raw and calibrated forms for scientific research in Earth observation. Moreover, 38 of these images from different countries include ground-truth labels at pixel-level totaling about 25 million spectral signatures labeled for sea/land/cloud categories. To demonstrate the potential of the dataset and its labeled subset, we have additionally optimized a deep learning model (1D Fully Convolutional Network), achieving superior performance to the current state of the art. The complete dataset, ground-truth labels, deep learning model, and software code are openly accessible for download at the website https://ntnu-sm
    
[^33]: 工业人工智能中的随机配置机

    Stochastic Configuration Machines for Industrial Artificial Intelligence. (arXiv:2308.13570v1 [cs.LG])

    [http://arxiv.org/abs/2308.13570](http://arxiv.org/abs/2308.13570)

    本文提出了一种新颖的随机学习器模型，称为随机配置机（SCMs），其基于随机配置网络（SCNs），旨在强调工业人工智能中的有效建模和节约数据大小。SCMs通过压缩模型存储，并保持有利的预测性能，具有在工业应用中很大的潜力。

    

    在工业人工智能（IAI）中，需要实时、准确的预测建模，神经网络在其中起到关键作用。工业人工智能中的神经网络需要强大的高性能计算设备来处理大量的浮点数据。本文基于随机配置网络（SCNs），提出了一种新的随机学习器模型，称为随机配置机（SCMs），以强调对于工业应用非常有用和有价值的有效建模和节约数据大小。与具有二值化实现的随机向量功能链接（RVFL）网络相比，SCMs的模型存储可以显著压缩，同时保持有利的预测性能。除了SCM学习器模型的架构和学习算法，作为本文的重要部分，我们还通过分析模型的复杂性提供了SCMs的学习能力的理论基础。实验研究也进行了。

    Real-time predictive modelling with desired accuracy is highly expected in industrial artificial intelligence (IAI), where neural networks play a key role. Neural networks in IAI require powerful, high-performance computing devices to operate a large number of floating point data. Based on stochastic configuration networks (SCNs), this paper proposes a new randomized learner model, termed stochastic configuration machines (SCMs), to stress effective modelling and data size saving that are useful and valuable for industrial applications. Compared to SCNs and random vector functional-link (RVFL) nets with binarized implementation, the model storage of SCMs can be significantly compressed while retaining favourable prediction performance. Besides the architecture of the SCM learner model and its learning algorithm, as an important part of this contribution, we also provide a theoretical basis on the learning capacity of SCMs by analysing the model's complexity. Experimental studies are ca
    
[^34]: 与你共舞：通过扩散模型实现多样性可控的舞者生成

    Dance with You: The Diversity Controllable Dancer Generation via Diffusion Models. (arXiv:2308.13551v1 [cs.HC])

    [http://arxiv.org/abs/2308.13551](http://arxiv.org/abs/2308.13551)

    本文介绍了一种名为伙伴舞者生成的多舞者合成任务，旨在通过在保持与主导舞者时间协调的同时确保伙伴舞者的可控多样性。为了实现这一目标，提出了一个名为“与你共舞”的三阶段框架（DanY），它能自动设计伙伴舞者的姿势。

    

    最近，虚拟环境中用于人际交互的数字人类引起了广泛关注。本文引入了一项新颖的多舞者合成任务，称为伙伴舞者生成，其涉及合成能够与用户一起跳舞的虚拟人类舞者。该任务旨在控制主导舞者和伙伴舞者之间的姿势多样性。这个任务的核心是确保生成的伙伴舞者具有可控的多样性，同时与主导舞者保持时间上的协调。与以往通过音乐驱动生成舞蹈动作的研究不同，我们的重点是根据预定义的多样性、主导舞者的姿势以及伴奏音乐自动设计伙伴舞者的姿势。为了实现这个目标，我们提出了一个称为“与你共舞”的三阶段框架（DanY）。首先，我们使用三维姿势收集阶段来收集各种基本舞蹈姿势作为参考姿势。

    Recently, digital humans for interpersonal interaction in virtual environments have gained significant attention. In this paper, we introduce a novel multi-dancer synthesis task called partner dancer generation, which involves synthesizing virtual human dancers capable of performing dance with users. The task aims to control the pose diversity between the lead dancer and the partner dancer. The core of this task is to ensure the controllable diversity of the generated partner dancer while maintaining temporal coordination with the lead dancer. This scenario varies from earlier research in generating dance motions driven by music, as our emphasis is on automatically designing partner dancer postures according to pre-defined diversity, the pose of lead dancer, as well as the accompanying tunes. To achieve this objective, we propose a three-stage framework called Dance-with-You (DanY). Initially, we employ a 3D Pose Collection stage to collect a wide range of basic dance poses as referenc
    
[^35]: CHORUS: 从无限合成图像中学习3D人体-物体空间关系的规范化

    CHORUS: Learning Canonicalized 3D Human-Object Spatial Relations from Unbounded Synthesized Images. (arXiv:2308.12288v1 [cs.CV])

    [http://arxiv.org/abs/2308.12288](http://arxiv.org/abs/2308.12288)

    我们提出了一种自监督的方法，利用从任意文本输入生成高质量的2D图像的生成模型，学习3D人体-物体空间关系的底层常识。这种方法解决了3D交互注释任务中的困难和扩展性问题。

    

    我们提出了一种方法，以自监督的方式教机器理解和建模多样化的3D人体-物体交互的底层空间常识。这是一个具有挑战性的任务，因为存在可以被视为类似人类和自然的交互特定流形，但是即使是相似的交互，人体姿势和物体的几何形状也可以有所不同。这种多样性使得注释3D交互的任务困难且难以扩展，限制了用监督方式进行推理的潜力。学习人类和物体在交互过程中的3D空间关系的一种方式是通过展示多个从不同视角捕获的2D图像，当人类与相同类型的物体互动时。我们方法的核心思想是利用一个生成模型，通过任意文本输入生成高质量的2D图像作为"无限"数据生成器，具有有效的可控性和视角多样性。尽管存在其不完美之处，

    We present a method for teaching machines to understand and model the underlying spatial common sense of diverse human-object interactions in 3D in a self-supervised way. This is a challenging task, as there exist specific manifolds of the interactions that can be considered human-like and natural, but the human pose and the geometry of objects can vary even for similar interactions. Such diversity makes the annotating task of 3D interactions difficult and hard to scale, which limits the potential to reason about that in a supervised way. One way of learning the 3D spatial relationship between humans and objects during interaction is by showing multiple 2D images captured from different viewpoints when humans interact with the same type of objects. The core idea of our method is to leverage a generative model that produces high-quality 2D images from an arbitrary text prompt input as an "unbounded" data generator with effective controllability and view diversity. Despite its imperfecti
    
[^36]: 从指令到内在人类价值 - 大模型对齐目标的调查

    From Instructions to Intrinsic Human Values -- A Survey of Alignment Goals for Big Models. (arXiv:2308.12014v1 [cs.AI])

    [http://arxiv.org/abs/2308.12014](http://arxiv.org/abs/2308.12014)

    本文综合调查了大模型对齐目标的不同观点，并追踪其演化路径，旨在帮助确定最重要的目标。

    

    大模型，例如大型语言模型（LLM），通常在大规模数据上进行预训练，并由大量参数组成，不仅在各种任务中获得显著改进的性能，还呈现出较小模型所没有的新能力。然而，大模型与日常生活的日益交织可能带来潜在风险，并可能造成严重的社会危害。因此，许多努力已经进行了，以使LLM与人类对齐，以使它们更好地遵循用户的指令并满足人类的偏好。然而，“与何对齐”还没有得到充分讨论，不当的对齐目标甚至可能适得其反。在本文中，我们对现有工作中的不同对齐目标进行了综合调查，并追踪它们的演化路径，以帮助确定最基本的目标。特别是，我们从对齐目标的定义和对齐评估两个角度进行了相关工作的调查。我们的分析包括...

    Big models, exemplified by Large Language Models (LLMs), are models typically pre-trained on massive data and comprised of enormous parameters, which not only obtain significantly improved performance across diverse tasks but also present emergent capabilities absent in smaller models. However, the growing intertwining of big models with everyday human lives poses potential risks and might cause serious social harm. Therefore, many efforts have been made to align LLMs with humans to make them better follow user instructions and satisfy human preferences. Nevertheless, `what to align with' has not been fully discussed, and inappropriate alignment goals might even backfire. In this paper, we conduct a comprehensive survey of different alignment goals in existing work and trace their evolution paths to help identify the most essential goal. Particularly, we investigate related works from two perspectives: the definition of alignment goals and alignment evaluation. Our analysis encompasses
    
[^37]: LFS-GAN: 终身少样本图像生成

    LFS-GAN: Lifelong Few-Shot Image Generation. (arXiv:2308.11917v1 [cs.CV])

    [http://arxiv.org/abs/2308.11917](http://arxiv.org/abs/2308.11917)

    LFS-GAN是一个终身少样本图像生成框架，通过使用可学习因子化张量（LeFT）作为任务特定调制器，解决了灾难性遗忘和过拟合问题，能够生成高质量和多样性的图像。

    

    我们首次针对具有挑战性的终身少样本图像生成任务进行了研究。在这种情况下，一个生成模型仅使用每个任务的少量样本学习一系列任务。因此，学习到的模型同时遇到了灾难性遗忘和过拟合的问题。现有的关于终身生成对抗网络的研究已经提出了基于调制的方法来防止灾难性遗忘。然而，它们需要大量额外的参数，而且不能从有限的数据中生成高保真度和多样性的图像。另一方面，现有的少样本生成对抗网络在学习多个任务时存在严重的灾难性遗忘问题。为了缓解这些问题，我们提出了一个称为终身少样本生成对抗网络（LFS-GAN）的框架，可以在终身少样本图像生成任务中生成高质量和多样性的图像。我们提出的框架使用一种高效的任务特定调制器 - 可学习因子化张量（LeFT）来学习每个任务。LeFT具有秩约束并且具有丰富的表示能力。

    We address a challenging lifelong few-shot image generation task for the first time. In this situation, a generative model learns a sequence of tasks using only a few samples per task. Consequently, the learned model encounters both catastrophic forgetting and overfitting problems at a time. Existing studies on lifelong GANs have proposed modulation-based methods to prevent catastrophic forgetting. However, they require considerable additional parameters and cannot generate high-fidelity and diverse images from limited data. On the other hand, the existing few-shot GANs suffer from severe catastrophic forgetting when learning multiple tasks. To alleviate these issues, we propose a framework called Lifelong Few-Shot GAN (LFS-GAN) that can generate high-quality and diverse images in lifelong few-shot image generation task. Our proposed framework learns each task using an efficient task-specific modulator - Learnable Factorized Tensor (LeFT). LeFT is rank-constrained and has a rich repres
    
[^38]: 迈向因果GPT：通过促进LLMs中的因果一致性，基于多智能体的方法实现忠实的知识推理

    Towards CausalGPT: A Multi-Agent Approach for Faithful Knowledge Reasoning via Promoting Causal Consistency in LLMs. (arXiv:2308.11914v1 [cs.AI])

    [http://arxiv.org/abs/2308.11914](http://arxiv.org/abs/2308.11914)

    通过多智能体协作，我们提出了一种框架，旨在提高基于知识的推理的忠实度和因果性，通过推理器和因果评估器的合作来解决推理谬误。

    

    尽管LLMs的发展取得了一些进展，但基于知识的推理仍然是一个长期存在的问题，这是由于知识回忆和推理的脆弱性引起的。现有方法主要通过鼓励LLMs自主计划和解决问题或广泛采样推理链来解决这个问题，但未能解决概念和推理谬误。为了减少推理谬误，我们从多智能体协作中得到启发，提出了一个框架来增加基于知识的推理的忠实度和因果性。具体而言，我们建议使用多个智能体（即推理器和因果评估器）在推理和一致性范式中协作工作，以提高推理的忠实度。推理器专注于提供具有人类因果关系的解决方案，用于解决开放领域的问题。另一方面，因果评估器代理检查解决方案中的答案是否从问题中因果推导出来，反之亦然，并用一个反事实的答案来替代。

    Despite advancements in LLMs, knowledge-based reasoning remains a longstanding issue due to the fragility of knowledge recall and inference. Existing methods primarily encourage LLMs to autonomously plan and solve problems or to extensively sample reasoning chains without addressing the conceptual and inferential fallacies. Attempting to alleviate inferential fallacies and drawing inspiration from multi-agent collaboration, we present a framework to increase faithfulness and causality for knowledge-based reasoning. Specifically, we propose to employ multiple intelligent agents (i.e., reasoner and causal evaluator) to work collaboratively in a reasoning-and-consensus paradigm for elevated reasoning faithfulness. The reasoners focus on providing solutions with human-like causality to solve open-domain problems. On the other hand, the causal evaluator agent scrutinizes if the answer in a solution is causally deducible from the question and vice versa, with a counterfactual answer replacin
    
[^39]: "非混淆协变量对基于潜在结果框架的方法推断性能的影响研究"

    A Study on the Impact of Non-confounding Covariates on the Inferential Performance of Methods based on the Potential Outcome Framework. (arXiv:2308.11676v1 [stat.ME])

    [http://arxiv.org/abs/2308.11676](http://arxiv.org/abs/2308.11676)

    "本文研究了非混淆协变量对基于潜在结果框架的方法推断性能的影响，通过提供统一的图形框架来增强对这些模型基本原理的理解，为实际场景中应用这些模型带来了潜在价值。"

    

    "潜在结果框架（POF）在因果推断领域中起着重要作用。大多数基于POF的因果推断模型（CIMs-B-POF）旨在消除混淆偏差，并默认存在混淆协变量的基本假设。这一假设认为协变量仅由混淆变量组成。然而，在实践中保持混淆协变量的假设是具有挑战性的，特别是在处理高维协变量时。虽然已经提出了一些方法在进行因果推断之前区分协变量的不同组成部分，但将非混淆的协变量视为混淆变量的后果仍不清楚。这种不确定性在实际场景中应用CIMs-B-POF时存在潜在风险。在本文中，我们提出了一个统一的图形框架，用于理解CIMs-B-POF模型的基本原理。利用这个图形框架，我们对CIMs-B-POF的性能进行了量化分析。"

    The Potential Outcome Framework (POF) plays a prominent role in the field of causal inference. Most causal inference models based on the POF (CIMs-B-POF) are designed for eliminating confounding bias and default to an underlying assumption of Confounding Covariates. This assumption posits that the covariates consist solely of confounders. However, the assumption of Confounding Covariates is challenging to maintain in practice, particularly when dealing with high-dimensional covariates. While certain methods have been proposed to differentiate the distinct components of covariates prior to conducting causal inference, the consequences of treating non-confounding covariates as confounders remain unclear. This ambiguity poses a potential risk when applying the CIMs-B-POF in practical scenarios. In this paper, we present a unified graphical framework for the CIMs-B-POF, which greatly enhances the comprehension of these models' underlying principles. Using this graphical framework, we quant
    
[^40]: UniDoc: 一种通用的大型多模态模型，用于同时进行文本检测、识别、定位和理解

    UniDoc: A Universal Large Multimodal Model for Simultaneous Text Detection, Recognition, Spotting and Understanding. (arXiv:2308.11592v1 [cs.AI])

    [http://arxiv.org/abs/2308.11592](http://arxiv.org/abs/2308.11592)

    UniDoc是一种通用的大型多模态模型，具备文本检测和识别能力，并通过任务之间的有益交互提高每个任务的性能，达到了在多个基准测试中的最先进水平。

    

    在大语言模型（LLMs）时代，多模态理解领域取得了巨大的进展。然而，现有的高级算法受限于有效利用大型预训练模型所固有的巨大表示能力和丰富的世界知识，并且在文本丰富场景中任务之间的有益连接尚未充分探索。在这项工作中，我们介绍了UniDoc，一种新颖的多模态模型，具备现有方法所缺乏的文本检测和识别能力。此外，UniDoc利用任务之间的有益交互来提高每个单独任务的性能。为了实现UniDoc，我们对贡献的大规模指令跟随数据集进行了统一的多模态指导调优。定量和定性实验结果表明，UniDoc在多个具有挑战性的基准测试中取得了最先进的分数。

    In the era of Large Language Models (LLMs), tremendous strides have been made in the field of multimodal understanding. However, existing advanced algorithms are limited to effectively utilizing the immense representation capabilities and rich world knowledge inherent to these large pre-trained models, and the beneficial connections among tasks within the context of text-rich scenarios have not been sufficiently explored. In this work, we introduce UniDoc, a novel multimodal model equipped with text detection and recognition capabilities, which are deficient in existing approaches. Moreover, UniDoc capitalizes on the beneficial interactions among tasks to enhance the performance of each individual task. To implement UniDoc, we perform unified multimodal instruct tuning on the contributed large-scale instruction following datasets. Quantitative and qualitative experimental results show that UniDoc sets state-of-the-art scores across multiple challenging benchmarks. To the best of our kn
    
[^41]: 大规模语言模型在软件工程中的应用：系统性文献综述

    Large Language Models for Software Engineering: A Systematic Literature Review. (arXiv:2308.10620v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2308.10620](http://arxiv.org/abs/2308.10620)

    通过系统性文献综述，本研究调查了大规模语言模型（LLM）在软件工程领域中的应用，并集中于了解如何利用LLM来优化软件工程过程和结果。文章总结了不同LLM的特点和用途以及数据收集和预处理方法的重要性。

    

    大规模语言模型（LLM）在包括软件工程在内的多个领域产生了显著影响。许多最近的文献探讨了LLM在各种软件工程任务和应用中的应用。然而，对LLM在软件工程中的应用、影响和可能的限制的全面理解仍处于初级阶段。为了弥补这一差距，我们对LLM与软件工程的交叉领域进行了系统性文献综述，特别关注LLM在软件工程中如何被利用来优化过程和结果的理解。我们收集和分析了2017年至2023年的229篇研究论文，以回答四个关键研究问题（RQs）。在RQ1中，我们对在软件工程任务中使用的不同LLM进行分类和比较分析，描绘其独特的特点和用途。在RQ2中，我们分析数据收集、预处理和应用中使用的方法，强调了强大、精心策划的数据集对于成功利用LLM非常重要。

    Large Language Models (LLMs) have significantly impacted numerous domains, including Software Engineering (SE). Many recent publications have explored LLMs applied to various SE tasks and applications. Nevertheless, a comprehensive understanding of the application, effects, and possible limitations of LLMs on SE is still in its early stages. To bridge this gap, we conducted a systematic literature review on the intersection of LLMs and SE, with a particular focus on understanding how LLMs can be exploited in SE to optimize processes and outcomes. We collect and analyze a total of 229 research papers from 2017 to 2023 to answer four key research questions (RQs). In RQ1, we categorize and provide a comparative analysis of different LLMs that have been employed in SE tasks, characterising their distinctive features and uses. In RQ2, we analyse the methods used in data collection, preprocessing, and application highlighting the role of robust, well-curated datasets for successful LLM for S
    
[^42]: 学习多尺度一致性的自监督电子显微镜实例分割

    Learning Multiscale Consistency for Self-supervised Electron Microscopy Instance Segmentation. (arXiv:2308.09917v1 [cs.CV])

    [http://arxiv.org/abs/2308.09917](http://arxiv.org/abs/2308.09917)

    本文提出了一种利用多尺度视觉表示捕获电子显微镜实例分割中体素级和特征级一致性的新的预训练框架。

    

    由于实例的复杂形态和不充足的注释，电子显微镜（EM）体积中的实例分割面临着重大挑战。自监督学习最近出现作为一种有前途的解决方案，可以获取对于EM实例分割至关重要的细胞组织结构的先验知识。然而，现有的预训练方法往往缺乏捕捉复杂的视觉模式和体素之间的关系的能力，导致所获取的先验知识不足以应用于下游的EM分析任务。在本文中，我们提出了一个新的预训练框架，利用多尺度的视觉表示来捕捉EM体积中的体素级和特征级的一致性。具体地，我们的框架通过重构函数强制实施Siamese网络输出之间的体素级一致性，并结合交叉注意力机制进行软特征匹配，实现精细的特征级一致性。

    Instance segmentation in electron microscopy (EM) volumes poses a significant challenge due to the complex morphology of instances and insufficient annotations. Self-supervised learning has recently emerged as a promising solution, enabling the acquisition of prior knowledge of cellular tissue structures that are essential for EM instance segmentation. However, existing pretraining methods often lack the ability to capture complex visual patterns and relationships between voxels, which results in the acquired prior knowledge being insufficient for downstream EM analysis tasks. In this paper, we propose a novel pretraining framework that leverages multiscale visual representations to capture both voxel-level and feature-level consistency in EM volumes. Specifically, our framework enforces voxel-level consistency between the outputs of a Siamese network by a reconstruction function, and incorporates a cross-attention mechanism for soft feature matching to achieve fine-grained feature-lev
    
[^43]: 大型语言模型和认知架构的协同集成对于稳健人工智能的探索分析

    Synergistic Integration of Large Language Models and Cognitive Architectures for Robust AI: An Exploratory Analysis. (arXiv:2308.09830v1 [cs.AI])

    [http://arxiv.org/abs/2308.09830](http://arxiv.org/abs/2308.09830)

    本文探索了将大型语言模型和认知架构相结合的替代方案，通过协同方法互补各自的弱点和限制，从而实现更稳健和复杂的人工智能系统。

    

    本文探讨了在构建表现出智能行为的人工智能代理时，将大型语言模型(LLMs)和认知架构(CAs) 进行集成的替代方案。在理论模型的指导下，通过初步的经验数据支持，我们假设不同的协同方法可以互补它们各自的弱点和限制，从而培育出更稳健和复杂的人工智能系统。此外，我们还讨论了每种方法所涉及的权衡和挑战。

    This paper explores alternatives for integrating two subdisciplines of AI in the construction of artificial agents that exhibit intelligent behavior: Large Language Models (LLMs) and Cognitive Architectures (CAs). Guided by theoretical models and supported by preliminary empirical data, we hypothesize how diverse synergistic approaches can mutually compensate for their respective weaknesses and limitations, ultimately fostering more robust and sophisticated artificial intelligence systems. Additionally, we discuss the tradeoffs and challenges associated with each approach.
    
[^44]: 基于事件的动态图表示学习在专利申请趋势预测中的应用

    Event-based Dynamic Graph Representation Learning for Patent Application Trend Prediction. (arXiv:2308.09780v1 [cs.AI])

    [http://arxiv.org/abs/2308.09780](http://arxiv.org/abs/2308.09780)

    本研究提出了一种基于事件的动态图学习框架，用于准确预测专利申请趋势。该方法利用公司和分类代码的可记忆表示，通过历史记忆和当前信息更新来捕捉语义接近性。

    

    准确预测公司在未来一段时间内将申请哪些类型的专利能够揭示出它们的发展战略，并帮助其提前发现潜在的合作伙伴或竞争对手。然而，由于对公司不断变化的偏好和对分类代码的语义关联的建模困难，这个问题在之前的研究中鲜有涉及。为了弥补这一空白，我们提出了一种基于事件的动态图学习框架，用于预测专利申请趋势。具体而言，我们的方法建立在公司和专利分类代码的可记忆表示基础上。当观察到一个新的专利时，相关公司和分类代码的表示根据历史记忆和当前编码的信息进行更新。此外，提供了一个层次化消息传递机制，以捕捉专利分类代码的语义接近性。

    Accurate prediction of what types of patents that companies will apply for in the next period of time can figure out their development strategies and help them discover potential partners or competitors in advance. Although important, this problem has been rarely studied in previous research due to the challenges in modelling companies' continuously evolving preferences and capturing the semantic correlations of classification codes. To fill in this gap, we propose an event-based dynamic graph learning framework for patent application trend prediction. In particular, our method is founded on the memorable representations of both companies and patent classification codes. When a new patent is observed, the representations of the related companies and classification codes are updated according to the historical memories and the currently encoded messages. Moreover, a hierarchical message passing mechanism is provided to capture the semantic proximities of patent classification codes by u
    
[^45]: Baird反例已解决：以调试两个时间尺度算法的示例。

    Baird Counterexample Is Solved: with an example of How to Debug a Two-time-scale Algorithm. (arXiv:2308.09732v1 [cs.LG])

    [http://arxiv.org/abs/2308.09732](http://arxiv.org/abs/2308.09732)

    这篇论文解决了Baird反例上的收敛问题，通过一种具有收敛保证的算法，实现了线性收敛速度。

    

    Baird反例是由Leemon Baird在1995年提出的，首先用于证明Temporal Difference (TD(0))算法在这个例子上发散。从那时起，它经常被用来测试和比较离策略学习算法。梯度TD算法解决了TD在Baird反例上的发散问题。然而，它们在这个例子上的收敛仍然非常缓慢，而且缓慢的本质还不被很好地理解。本文旨在特别理解为什么TDC在这个例子上慢，并提供调试分析来理解这种行为。我们的调试技术可以用来研究两个时间尺度随机逼近算法的收敛行为。我们还提供了最近的Impression GTD算法在这个例子上的实证结果，表明收敛非常快，事实上是线性的。我们得出结论，Baird反例通过一种具有收敛保证的算法解决了，该算法收敛到TD解决方案。

    Baird counterexample was proposed by Leemon Baird in 1995, first used to show that the Temporal Difference (TD(0)) algorithm diverges on this example. Since then, it is often used to test and compare off-policy learning algorithms. Gradient TD algorithms solved the divergence issue of TD on Baird counterexample. However, their convergence on this example is still very slow, and the nature of the slowness is not well understood, e.g., see (Sutton and Barto 2018).  This note is to understand in particular, why TDC is slow on this example, and provide debugging analysis to understand this behavior. Our debugging technique can be used to study the convergence behavior of two-time-scale stochastic approximation algorithms. We also provide empirical results of the recent Impression GTD algorithm on this example, showing the convergence is very fast, in fact, in a linear rate. We conclude that Baird counterexample is solved, by an algorithm with convergence guarantee to the TD solution in gen
    
[^46]: 使用生成性扩散模型的降水即时预测

    Precipitation nowcasting with generative diffusion models. (arXiv:2308.06733v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2308.06733](http://arxiv.org/abs/2308.06733)

    这篇论文研究了使用生成性扩散模型进行降水即时预测的问题，生成模型在天气预报中的应用具有潜力，并能够更好地建模概率分布。

    

    近年来，传统的数值预测方法逐渐受到深度学习方法的挑战。用于短期和中期天气预报的多个历史数据集通常被组织成规则的空间网格结构。这种排列与图像非常相似：每个天气变量可以被视为一幅地图，或者在考虑时间轴时，可以被视为一段视频。多个类别的生成模型，包括生成对抗网络、变分自编码器，或者最近的去噪扩散模型，在下一帧预测问题上已经证明了它们的适用性，因此自然而然地希望测试它们在天气预报基准上的性能。在这个背景下，扩散模型特别具有吸引力，因为天气预报本质上是具有概率性的：我们真正有兴趣建模的是天气指标的概率分布，其期望值是最可能的值。

    In recent years traditional numerical methods for accurate weather prediction have been increasingly challenged by deep learning methods. Numerous historical datasets used for short and medium-range weather forecasts are typically organized into a regular spatial grid structure. This arrangement closely resembles images: each weather variable can be visualized as a map or, when considering the temporal axis, as a video. Several classes of generative models, comprising Generative Adversarial Networks, Variational Autoencoders, or the recent Denoising Diffusion Models have largely proved their applicability to the next-frame prediction problem, and is thus natural to test their performance on the weather prediction benchmarks. Diffusion models are particularly appealing in this context, due to the intrinsically probabilistic nature of weather forecasting: what we are really interested to model is the probability distribution of weather indicators, whose expected value is the most likely 
    
[^47]: 多模态大语言模型在预测语言处理期间表现出人类视觉-语言集成的证据

    Evidence of Human-Like Visual-Linguistic Integration in Multimodal Large Language Models During Predictive Language Processing. (arXiv:2308.06035v1 [cs.AI])

    [http://arxiv.org/abs/2308.06035](http://arxiv.org/abs/2308.06035)

    这篇论文研究了多模态大语言模型（mLLMs）在预测语言处理过程中与人类的视觉-语言集成能力是否一致的问题，并通过实验验证了mLLMs的多模态输入方法可以减少认知负荷，提高感知和理解能力。

    

    大语言模型（LLMs）的先进语言处理能力引发了关于它们是否能够复制人类认知过程的争议。LLMs和人类在语言处理方面的一个区别在于，语言输入通常建立在多个知觉模态上，而大多数LLMs仅处理基于文本的信息。多模态基础使人类能够整合视觉背景与语言信息，从而对即将出现的单词的空间施加限制，减少认知负荷，提高感知和理解能力。最近的多模态LLMs（mLLMs）结合了视觉和语言嵌入空间，并使用变压器类型的注意机制进行下一个单词的预测。在多大程度上，基于多模态输入的预测语言处理在mLLMs和人类中吻合？为了回答这个问题，200名被试观看了短的视听剪辑，并估计了即将出现的动词或名词的可预测性。

    The advanced language processing abilities of large language models (LLMs) have stimulated debate over their capacity to replicate human-like cognitive processes. One differentiating factor between language processing in LLMs and humans is that language input is often grounded in more than one perceptual modality, whereas most LLMs process solely text-based information. Multimodal grounding allows humans to integrate - e.g. visual context with linguistic information and thereby place constraints on the space of upcoming words, reducing cognitive load and improving perception and comprehension. Recent multimodal LLMs (mLLMs) combine visual and linguistic embedding spaces with a transformer type attention mechanism for next-word prediction. To what extent does predictive language processing based on multimodal input align in mLLMs and humans? To answer this question, 200 human participants watched short audio-visual clips and estimated the predictability of an upcoming verb or noun. The 
    
[^48]: 匿名化语音：评估和设计说话人匿名化技术

    Anonymizing Speech: Evaluating and Designing Speaker Anonymization Techniques. (arXiv:2308.04455v1 [cs.CR])

    [http://arxiv.org/abs/2308.04455](http://arxiv.org/abs/2308.04455)

    本研究提出了匿名化语音的解决方案，并评估了匿名化的程度，以应对语音数据收集中的隐私问题和恶意使用的风险。

    

    随着语音用户界面的广泛使用，语音数据的收集和存储也大大增加。虽然数据收集可以为大多数语音服务提供高效的工具，但它也给用户的隐私造成严重的问题，因为集中存储使个人的语音数据容易受到网络威胁的侵害。随着亚马逊的Alexa，谷歌的Home和苹果的Siri等基于语音的数字助手的使用增加，以及个人语音数据收集变得越来越容易，声音克隆和说话人/性别/病理等识别的恶意使用的风险也增加了。本文提出了匿名化语音的解决方案，并评估匿名化的程度。在这项工作中，匿名化是指使个人语音数据与身份无法关联，同时保持语音信号的实用性（例如，访问语言内容）。我们首先确定了几个评估协议的挑战。

    The growing use of voice user interfaces has led to a surge in the collection and storage of speech data. While data collection allows for the development of efficient tools powering most speech services, it also poses serious privacy issues for users as centralized storage makes private personal speech data vulnerable to cyber threats. With the increasing use of voice-based digital assistants like Amazon's Alexa, Google's Home, and Apple's Siri, and with the increasing ease with which personal speech data can be collected, the risk of malicious use of voice-cloning and speaker/gender/pathological/etc. recognition has increased.  This thesis proposes solutions for anonymizing speech and evaluating the degree of the anonymization. In this work, anonymization refers to making personal speech data unlinkable to an identity while maintaining the usefulness (utility) of the speech signal (e.g., access to linguistic content). We start by identifying several challenges that evaluation protoco
    
[^49]: 人类情绪的不确定性测量

    Measure of Uncertainty in Human Emotions. (arXiv:2308.04032v1 [cs.AI])

    [http://arxiv.org/abs/2308.04032](http://arxiv.org/abs/2308.04032)

    本研究探讨了情绪分类的不确定性信息展示对人类决策过程的影响，结果显示展示更多的不确定性信息可以增强用户决策的自信度。 (This study investigated the impact of displaying more uncertainty information on human decision making in emotion classification, and the results showed that it can increase users' confidence in decision making.)

    

    许多研究探讨计算机如何能够检测人类展示的情绪并利用这些数据执行不同的任务。然而，很少有研究评估计算机生成情绪分类信息的能力，以帮助用户做出决策或执行任务。这是一个关键领域需要研究，因为它对人与计算机之间的双向交流至关重要。本研究进行了实验，探讨了情绪分类的不确定性信息展示对人类决策过程的影响。结果表明，展示更多的不确定性信息可以帮助用户在做决策时更加自信。

    Many research explore how well computers are able to examine emotions displayed by humans and use that data to perform different tasks. However, there have been very few research which evaluate the computers ability to generate emotion classification information in an attempt to help the user make decisions or perform tasks. This is a crucial area to explore as it is paramount to the two way communication between humans and computers. This research conducted an experiment to investigate the impact of different uncertainty information displays of emotion classification on the human decision making process. Results show that displaying more uncertainty information can help users to be more confident when making decisions.
    
[^50]: 《高分辨率显著目标检测的循环多尺度Transformer》

    Recurrent Multi-scale Transformer for High-Resolution Salient Object Detection. (arXiv:2308.03826v1 [cs.CV])

    [http://arxiv.org/abs/2308.03826](http://arxiv.org/abs/2308.03826)

    本研究提出了一个循环多尺度Transformer网络，用于高分辨率显著目标检测，同时引入了一个新的HRS10K数据集，该数据集是目前规模最大的用于HRSOD任务的数据集。

    

    显著目标检测（SOD）旨在识别和分割图像或视频中最显著的对象。随着成像设备的进步，对高分辨率图像的SOD需求日益迫切。然而，传统的SOD方法主要局限于低分辨率图像，并难以适应高分辨率SOD（HRSOD）的发展。尽管出现了一些HRSOD方法，但目前没有足够大的数据集用于训练和评估。此外，当前的HRSOD方法通常会产生不完整的对象区域和不规则的对象边界。为解决上述问题，我们首先提出了一个新的HRS10K数据集，其中包含10500个2K-8K分辨率的高质量注释图像。据我们所知，这是目前用于HRSOD任务的最大数据集，它将在很大程度上帮助未来的训练和评估工作。此外，为了改进方法，在本研究中，我们提出了一种循环多尺度Transformer网络

    Salient Object Detection (SOD) aims to identify and segment the most conspicuous objects in an image or video. As an important pre-processing step, it has many potential applications in multimedia and vision tasks. With the advance of imaging devices, SOD with high-resolution images is of great demand, recently. However, traditional SOD methods are largely limited to low-resolution images, making them difficult to adapt to the development of High-Resolution SOD (HRSOD). Although some HRSOD methods emerge, there are no large enough datasets for training and evaluating. Besides, current HRSOD methods generally produce incomplete object regions and irregular object boundaries. To address above issues, in this work, we first propose a new HRS10K dataset, which contains 10,500 high-quality annotated images at 2K-8K resolution. As far as we know, it is the largest dataset for the HRSOD task, which will significantly help future works in training and evaluating models. Furthermore, to improve
    
[^51]: 在部分可观察情境轮盘赌中的可证效率学习

    Provably Efficient Learning in Partially Observable Contextual Bandit. (arXiv:2308.03572v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2308.03572](http://arxiv.org/abs/2308.03572)

    本文研究了在部分可观察情境轮盘赌中的转移学习问题，提出了一种通过优化问题识别行为和奖励因果效应的方法，并利用因果约束来改进轮盘赌算法。

    

    本文研究了在部分可观察情境轮盘赌中的转移学习问题，其中代理人仅有来自其他代理人的有限知识，并且对隐藏的混淆因素只有部分信息。我们将该问题转化为通过优化问题来识别或部分识别行为和奖励之间的因果效应。为了解决这些优化问题，我们将未知分布的原始功能约束离散化为线性约束，并通过顺序解线性规划来采样兼容的因果模型，以考虑估计误差得到因果约束。我们的采样算法为适当的采样分布提供了理想的收敛结果。然后，我们展示了如何将因果约束应用于改进经典的轮盘赌算法，并以行动集和函数空间规模为参考改变了遗憾值。值得注意的是，在允许我们处理一般情境分布的函数逼近任务中

    In this paper, we investigate transfer learning in partially observable contextual bandits, where agents have limited knowledge from other agents and partial information about hidden confounders. We first convert the problem to identifying or partially identifying causal effects between actions and rewards through optimization problems. To solve these optimization problems, we discretize the original functional constraints of unknown distributions into linear constraints, and sample compatible causal models via sequentially solving linear programmings to obtain causal bounds with the consideration of estimation error. Our sampling algorithms provide desirable convergence results for suitable sampling distributions. We then show how causal bounds can be applied to improving classical bandit algorithms and affect the regrets with respect to the size of action sets and function spaces. Notably, in the task with function approximation which allows us to handle general context distributions
    
[^52]: 边缘稳定的回声状态网络

    Edge of stability echo state networks. (arXiv:2308.02902v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2308.02902](http://arxiv.org/abs/2308.02902)

    本文介绍了一种新的边缘稳定回声状态网络（ES$^2$N）架构，结合了渐进记忆属性和尽可能保留更多记忆的能力，通过将储备层定义为非线性和线性的凸组合，提供了网络稳定性和性能的增强。

    

    回声状态网络（ESNs）是基于回声状态属性（ESP）原理工作的时间序列处理模型。ESP是指对输入的记忆在渐进衰减。然而，ESNs的固有架构偏差可能导致过多信息的丢失，进而影响在某些长期记忆任务中的性能。为了将渐进记忆属性与尽可能保留更多记忆的能力结合起来，本文介绍了一种新的ESN架构，称为边缘稳定回声状态网络（ES$^2$N）。引入的ES$^2$N模型基于将储备层定义为非线性储备（与标准ESN相同）和实现正交变换的线性储备的凸组合。我们对引入的模型进行了彻底的数学分析，并证明了ES$^2$N的雅可比矩阵的整个特征谱...

    Echo State Networks (ESNs) are time-series processing models working under the Echo State Property (ESP) principle. The ESP is a notion of stability that imposes an asymptotic fading of the memory of the input. On the other hand, the resulting inherent architectural bias of ESNs may lead to an excessive loss of information, which in turn harms the performance in certain tasks with long short-term memory requirements. With the goal of bringing together the fading memory property and the ability to retain as much memory as possible, in this paper we introduce a new ESN architecture, called the Edge of Stability Echo State Network (ES$^2$N). The introduced ES$^2$N model is based on defining the reservoir layer as a convex combination of a nonlinear reservoir (as in the standard ESN), and a linear reservoir that implements an orthogonal transformation. We provide a thorough mathematical analysis of the introduced model, proving that the whole eigenspectrum of the Jacobian of the ES$^2$N ma
    
[^53]: CausalOps -- 实现因果概率图模型实际生命周期的方法

    CausalOps -- Towards an Industrial Lifecycle for Causal Probabilistic Graphical Models. (arXiv:2308.01375v1 [cs.AI])

    [http://arxiv.org/abs/2308.01375](http://arxiv.org/abs/2308.01375)

    提出了CausalOps，一个新的因果模型开发和应用的生命周期框架，旨在推动在实际应用中采用因果方法。

    

    因果概率图模型已被广泛应用，可以在不同领域建模因果关系。随着其在汽车系统安全和机器学习等新领域的应用越来越普遍，人们对于类似DevOps和MLOps的集成生命周期框架的需求不断增加。目前，缺乏一个适用于因果工程的组织参考流程。为了填补这个空白并促进广泛的工业应用，我们提出了CausalOps，这是一个面向因果模型开发和应用的全新生命周期框架。通过定义因果工程过程中产生的关键实体、依赖关系和中间产物，我们建立了一个一致的词汇表和工作流模型。本研究将因果模型的使用情境化为不同阶段和利益相关者，概述了创建和维护因果模型的整体视图。CausalOps旨在推动因果方法在实际应用中的采用。

    Causal probabilistic graph-based models have gained widespread utility, enabling the modeling of cause-and-effect relationships across diverse domains. With their rising adoption in new areas, such as automotive system safety and machine learning, the need for an integrated lifecycle framework akin to DevOps and MLOps has emerged. Currently, a process reference for organizations interested in employing causal engineering is missing. To address this gap and foster widespread industrial adoption, we propose CausalOps, a novel lifecycle framework for causal model development and application. By defining key entities, dependencies, and intermediate artifacts generated during causal engineering, we establish a consistent vocabulary and workflow model. This work contextualizes causal model usage across different stages and stakeholders, outlining a holistic view of creating and maintaining them. CausalOps' aim is to drive the adoption of causal methods in practical applications within intere
    
[^54]: 使用Floss增强周期性时间序列的表示学习：一种频域正则化方法

    Enhancing Representation Learning for Periodic Time Series with Floss: A Frequency Domain Regularization Approach. (arXiv:2308.01011v1 [cs.LG])

    [http://arxiv.org/abs/2308.01011](http://arxiv.org/abs/2308.01011)

    本文提出了一种叫做Floss的无监督方法，通过在频域上对学到的表示进行正则化来增强周期性时间序列的表示学习。Floss方法可以自动检测时间序列中的周期性并学习具有周期一致性的有意义的表示。

    

    时间序列分析是各个应用领域的基础任务，深度学习方法在这个领域表现出了非凡的性能。然而，许多现实世界的时间序列数据展现出重要的周期性或准周期性动态，这些动态往往不能被现有的基于深度学习的解决方案充分捕捉到。这导致对感兴趣的基础动态行为的表示不完整。为了解决这个问题，我们提出了一种无监督的方法叫做Floss，它通过自动化地在频域上调整学到的表示来进行正则化。Floss方法首先自动检测时间序列中的主要周期性。然后，它利用周期移位和谱密度相似度度量来学习具有周期一致性的有意义的表示。此外，Floss可以轻松地整合到有监督、半监督和无监督的学习框架中。

    Time series analysis is a fundamental task in various application domains, and deep learning approaches have demonstrated remarkable performance in this area. However, many real-world time series data exhibit significant periodic or quasi-periodic dynamics that are often not adequately captured by existing deep learning-based solutions. This results in an incomplete representation of the underlying dynamic behaviors of interest. To address this gap, we propose an unsupervised method called Floss that automatically regularizes learned representations in the frequency domain. The Floss method first automatically detects major periodicities from the time series. It then employs periodic shift and spectral density similarity measures to learn meaningful representations with periodic consistency. In addition, Floss can be easily incorporated into both supervised, semi-supervised, and unsupervised learning frameworks. We conduct extensive experiments on common time series classification, for
    
[^55]: 先思考再回应：为共情回应生成集成常识的因果解释

    Reasoning before Responding: Integrating Commonsense-based Causality Explanation for Empathetic Response Generation. (arXiv:2308.00085v1 [cs.CL])

    [http://arxiv.org/abs/2308.00085](http://arxiv.org/abs/2308.00085)

    本文提出了一种基于常识的因果解释方法，用于多样化的共情回应生成。该方法综合考虑了用户的角度和系统的角度，并通过集成常识知识提升了ChatGPT在系统的推理能力。实验结果表明，该方法在多项评估指标上超过了其他方法。

    

    最近的共情回应生成方法试图整合常识知识或对情绪原因的推理，以更好地理解用户的经历和感受。然而，这些方法主要关注从用户的角度理解上下文的因果关系，忽略了系统的角度。本文提出了一种基于常识的因果解释方法，用于多样化的共情回应生成，同时考虑用户的角度（用户的欲望和反应）和系统的角度（系统的意图和反应）。我们通过将上下文学习与常识知识相结合，增强了ChatGPT在系统的角度上的推理能力。然后，我们将基于常识的因果解释与ChatGPT和基于T5模型的方法进行整合。实验评估表明，我们的方法在自动评估和人工评估上优于其他可比较的方法。

    Recent approaches to empathetic response generation try to incorporate commonsense knowledge or reasoning about the causes of emotions to better understand the user's experiences and feelings. However, these approaches mainly focus on understanding the causalities of context from the user's perspective, ignoring the system's perspective. In this paper, we propose a commonsense-based causality explanation approach for diverse empathetic response generation that considers both the user's perspective (user's desires and reactions) and the system's perspective (system's intentions and reactions). We enhance ChatGPT's ability to reason for the system's perspective by integrating in-context learning with commonsense knowledge. Then, we integrate the commonsense-based causality explanation with both ChatGPT and a T5-based model. Experimental evaluations demonstrate that our method outperforms other comparable methods on both automatic and human evaluations.
    
[^56]: 使用端到端视频异常检测系统来基准测试Jetson边缘设备

    Benchmarking Jetson Edge Devices with an End-to-end Video-based Anomaly Detection System. (arXiv:2307.16834v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2307.16834](http://arxiv.org/abs/2307.16834)

    本论文实现了一个端到端的视频异常检测系统，通过从监控视频输入进行犯罪现场异常检测，并在多个Jetson边缘设备上部署和运行。这是对Jetson平台在深度学习算法执行方面性能的基准测试分析的创新。

    

    创新的嵌入式系统平台，特别是硬件加速，显着影响了深度学习在现实场景中的应用。这些创新将人类劳动转化为自动化的智能系统，应用于自动驾驶、机器人技术、物联网和许多其他有重大影响的应用领域。NVIDIA的Jetson平台是在执行深度学习算法方面能够提供能效和吞吐率最佳性能的先驱之一。先前的大部分基准测试分析都是基于2D图像，并使用单个深度学习模型进行每个比较结果。在本文中，我们实现了一种从监控视频输入的端到端基于视频的犯罪现场异常检测系统，并将该系统部署在多个Jetson边缘设备上（Nano、AGX Xavier、Orin Nano）。比较分析包括将Torch-TensorRT集成为软件。

    Innovative enhancement in embedded system platforms, specifically hardware accelerations, significantly influence the application of deep learning in real-world scenarios. These innovations translate human labor efforts into automated intelligent systems employed in various areas such as autonomous driving, robotics, Internet-of-Things (IoT), and numerous other impactful applications. NVIDIA's Jetson platform is one of the pioneers in offering optimal performance regarding energy efficiency and throughput in the execution of deep learning algorithms. Previously, most benchmarking analysis was based on 2D images with a single deep learning model for each comparison result. In this paper, we implement an end-to-end video-based crime-scene anomaly detection system inputting from surveillance videos and the system is deployed and completely operates on multiple Jetson edge devices (Nano, AGX Xavier, Orin Nano). The comparison analysis includes the integration of Torch-TensorRT as a softwar
    
[^57]: BAGM：一种用于操纵文本到图像生成模型的后门攻击

    BAGM: A Backdoor Attack for Manipulating Text-to-Image Generative Models. (arXiv:2307.16489v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2307.16489](http://arxiv.org/abs/2307.16489)

    BAGM是一种后门攻击方法，针对文本到图像生成模型，可以悄无声息地操纵用户生成的图像。该攻击是首个针对三个流行模型不同生成阶段的攻击方法，并提供了一套全面的评估指标。

    

    文本到图像生成人工智能（AI）的普及引起了广泛的公众关注。我们证明了这项技术可以被攻击，以生成悄无声息地操纵用户的内容。我们提出了一种针对文本到图像生成模型的后门攻击（BAGM），一旦触发，会向生成的图像中注入自然融入内容的操纵细节。我们的攻击是第一个针对三个流行的文本到图像生成模型在生成过程的三个阶段进行攻击的方法，通过修改嵌入标记器、语言模型或图像生成模型的行为。基于渗透级别，BAGM采用了表面、浅层和深层攻击的一系列攻击形式。鉴于该领域的现有差距，我们还提供了一套全面的定量评估指标，专门用于评估后门攻击对文本到图像模型的影响效果。

    The rise in popularity of text-to-image generative artificial intelligence (AI) has attracted widespread public interest. We demonstrate that this technology can be attacked to generate content that subtly manipulates its users. We propose a Backdoor Attack on text-to-image Generative Models (BAGM), which upon triggering, infuses the generated images with manipulative details that are naturally blended in the content. Our attack is the first to target three popular text-to-image generative models across three stages of the generative process by modifying the behaviour of the embedded tokenizer, the language model or the image generative model. Based on the penetration level, BAGM takes the form of a suite of attacks that are referred to as surface, shallow and deep attacks in this article. Given the existing gap within this domain, we also contribute a comprehensive set of quantitative metrics designed specifically for assessing the effectiveness of backdoor attacks on text-to-image mo
    
[^58]: 仅使用一个步长的新型梯度时序差分算法：通过$L$-$\lambda$平滑性进行收敛速率分析

    A new Gradient TD Algorithm with only One Step-size: Convergence Rate Analysis using $L$-$\lambda$ Smoothness. (arXiv:2307.15892v1 [cs.LG])

    [http://arxiv.org/abs/2307.15892](http://arxiv.org/abs/2307.15892)

    本论文提出了一种新的梯度时序差分算法，只使用一个步长参数，并证明收敛速度至少为$O(1/t)$。

    

    梯度时序差分（GTD）算法是第一个具有收敛保证的离策略学习线性函数逼近算法，其复杂度为$O(d)$（$d$是特征数量）。本文提出了一种名为Impression GTD的全新单时间尺度GTD算法，用于最小化期望td更新（NEU）目标，并只有一个步长参数。我们证明这种新算法的收敛速度至少与$O(1/t)$一样快。

    Gradient Temporal Difference (GTD) algorithms (Sutton et al., 2008, 2009) are the first $O(d)$ ($d$ is the number features) algorithms that have convergence guarantees for off-policy learning with linear function approximation. Liu et al. (2015) and Dalal et. al. (2018) proved the convergence rates of GTD, GTD2 and TDC are $O(t^{-\alpha/2})$ for some $\alpha \in (0,1)$. This bound is tight (Dalal et al., 2020), and slower than $O(1/\sqrt{t})$. GTD algorithms also have two step-size parameters, which are difficult to tune. In literature, there is a "single-time-scale" formulation of GTD. However, this formulation still has two step-size parameters.  This paper presents a truly single-time-scale GTD algorithm for minimizing the Norm of Expected td Update (NEU) objective, and it has only one step-size parameter. We prove that the new algorithm, called Impression GTD, converges at least as fast as $O(1/t)$. Furthermore, based on a generalization of the expected smoothness (Gower et al. 201
    
[^59]: 可解释人工智能（XAI）在年龄预测中的应用：一项系统综述

    eXplainable Artificial Intelligence (XAI) in age prediction: A systematic review. (arXiv:2307.13704v1 [cs.AI])

    [http://arxiv.org/abs/2307.13704](http://arxiv.org/abs/2307.13704)

    本综述探讨了可解释人工智能（XAI）在年龄预测任务中的应用。通过系统性综述，我们讨论了XAI方法在医疗应用和年龄预测领域的益处。

    

    可解释人工智能（XAI）现在是机器学习中的重要组成部分，能够解释复杂模型的预测结果。XAI特别适用于危险应用，特别是在医疗保健领域，人类的生命依赖于AI系统的决策。医疗研究的一个领域是年龄预测和衰老及与年龄相关疾病的生物标志物鉴定。然而，在年龄预测任务中，XAI的作用尚未直接探讨。在本综述中，我们讨论了XAI方法在年龄预测任务中的应用。我们通过器官系统进行了系统性综述，并讨论了XAI在医疗应用以及特别是年龄预测领域的益处。

    eXplainable Artificial Intelligence (XAI) is now an important and essential part of machine learning, allowing to explain the predictions of complex models. XAI is especially required in risky applications, particularly in health care, where human lives depend on the decisions of AI systems. One area of medical research is age prediction and identification of biomarkers of aging and age-related diseases. However, the role of XAI in the age prediction task has not previously been explored directly. In this review, we discuss the application of XAI approaches to age prediction tasks. We give a systematic review of the works organized by body systems, and discuss the benefits of XAI in medical applications and, in particular, in the age prediction domain.
    
[^60]: 关于注意力网络学习动态的研究

    On the learning Dynamics of Attention Networks. (arXiv:2307.13421v1 [cs.LG])

    [http://arxiv.org/abs/2307.13421](http://arxiv.org/abs/2307.13421)

    本研究分析了软注意力、硬注意力和潜变量边际似然（LVML）注意力三种注意力模型的学习动态，发现了它们在所选择的片段聚合方式上的显著差异，并解释了分类模型在梯度下降下的演化对最终结果的影响。

    

    注意力模型通常通过优化三个标准损失函数之一来学习，分别称为软注意力、硬注意力和潜变量边际似然（LVML）注意力。这三种范式都是为了达到相同的目标，即找到两个模型：一个“焦点”模型，用于“选择”输入中的正确“片段”，和一个“分类”模型，用于将选定的片段处理成目标标签。然而，它们在所选择的片段聚合方式上存在显著差异，导致了不同的动态和最终结果。我们观察到使用这些范式学习的模型具有独特的特征，并将其解释为在焦点模型固定时，分类模型在梯度下降下的演化所致。我们还在一个简单的设置中分析了这些范式，并推导出梯度流下参数轨迹的闭式表达式。在软注意力损失下，焦点模型在初始化阶段快速改善。

    Attention models are typically learned by optimizing one of three standard loss functions that are variously called -- soft attention, hard attention, and latent variable marginal likelihood (LVML) attention. All three paradigms are motivated by the same goal of finding two models -- a `focus' model that `selects' the right \textit{segment} of the input and a `classification' model that processes the selected segment into the target label. However, they differ significantly in the way the selected segments are aggregated, resulting in distinct dynamics and final results. We observe a unique signature of models learned using these paradigms and explain this as a consequence of the evolution of the classification model under gradient descent when the focus model is fixed. We also analyze these paradigms in a simple setting and derive closed-form expressions for the parameter trajectory under gradient flow. With the soft attention loss, the focus model improves quickly at initialization a
    
[^61]: 非平滑非凸优化中随机次梯度方法的收敛性保证

    Convergence Guarantees for Stochastic Subgradient Methods in Nonsmooth Nonconvex Optimization. (arXiv:2307.10053v1 [math.OC])

    [http://arxiv.org/abs/2307.10053](http://arxiv.org/abs/2307.10053)

    本文研究了非平滑非凸优化中随机次梯度方法的收敛性质，并提出了一种新的框架，证明了其在单时间尺度和双时间尺度情况下的全局收敛性，包括了多种已知的SGD类型方法。对于有限和形式的目标函数，证明了这些方法能够在随机选择的步长和初始点上找到Clarke稳定点。

    

    本文研究了随机梯度下降（SGD）方法及其变种在训练由非平滑激活函数构建的神经网络中的收敛性质。我们提出了一种新颖的框架，为更新动量项和变量的步长分配了不同的时间尺度。在一些温和的条件下，我们证明了我们提出的框架在单时间尺度和双时间尺度情况下的全局收敛性。我们还证明了我们提出的框架包含了很多已知的SGD类型方法，包括heavy-ball SGD、SignSGD、Lion、normalized SGD和clipped SGD。此外，当目标函数采用有限和形式时，我们基于我们提出的框架证明了这些SGD类型方法的收敛性质。特别地，在温和的假设下，我们证明了这些SGD类型方法在随机选择的步长和初始点上能够找到目标函数的Clarke稳定点。

    In this paper, we investigate the convergence properties of the stochastic gradient descent (SGD) method and its variants, especially in training neural networks built from nonsmooth activation functions. We develop a novel framework that assigns different timescales to stepsizes for updating the momentum terms and variables, respectively. Under mild conditions, we prove the global convergence of our proposed framework in both single-timescale and two-timescale cases. We show that our proposed framework encompasses a wide range of well-known SGD-type methods, including heavy-ball SGD, SignSGD, Lion, normalized SGD and clipped SGD. Furthermore, when the objective function adopts a finite-sum formulation, we prove the convergence properties for these SGD-type methods based on our proposed framework. In particular, we prove that these SGD-type methods find the Clarke stationary points of the objective function with randomly chosen stepsizes and initial points under mild assumptions. Preli
    
[^62]: ACTI在EVALITA 2023中的综述：阴谋论辨识任务概述

    ACTI at EVALITA 2023: Overview of the Conspiracy Theory Identification Task. (arXiv:2307.06954v1 [cs.CL])

    [http://arxiv.org/abs/2307.06954](http://arxiv.org/abs/2307.06954)

    ACTI在EVALITA 2023中的阴谋论辨识任务共有15支团队参与，通过使用大型语言模型判断阴谋内容和分类，得出了关于利用这些模型抵制在在线平台传播错误信息的结论。

    

    阴谋论辨识任务是Evalita 2023首次提出的新共享任务。ACTI挑战仅基于Telegram上的阴谋频道评论，分为两个子任务：(i) 阴谋内容分类：辨识阴谋内容和(ii) 阴谋类别分类：针对特定阴谋理论分类。共有15支团队参与了该任务，总共提交了81个结果。我们说明了基于大型语言模型的最佳方法。最后，我们得出了关于利用这些模型来抵制在在线平台上传播错误信息的结论。

    Conspiracy Theory Identication task is a new shared task proposed for the first time at the Evalita 2023. The ACTI challenge, based exclusively on comments published on conspiratorial channels of telegram, is divided into two subtasks: (i) Conspiratorial Content Classification: identifying conspiratorial content and (ii) Conspiratorial Category Classification about specific conspiracy theory classification. A total of fifteen teams participated in the task for a total of 81 submissions. We illustrate the best performing approaches were based on the utilization of large language models. We finally draw conclusions about the utilization of these models for counteracting the spreading of misinformation in online platforms.
    
[^63]: 采用样本感知引导和动态修订链的基于检索增强的GPT-3.5文本到SQL框架

    Retrieval-augmented GPT-3.5-based Text-to-SQL Framework with Sample-aware Prompting and Dynamic Revision Chain. (arXiv:2307.05074v1 [cs.IR])

    [http://arxiv.org/abs/2307.05074](http://arxiv.org/abs/2307.05074)

    本文提出了一种基于检索增强的GPT-3.5文本到SQL框架，采用了样本感知引导和动态修订链的方法，以应对现有方法在处理语义差距较大的检索示例时面临的挑战。

    

    文本到SQL旨在为给定的自然语言问题生成SQL查询，从而帮助用户查询数据库。最近出现了一种基于大型语言模型（LLMs）的提示学习方法，该方法设计提示以引导LLMs理解输入问题并生成相应的SQL。然而，它面临着严格的SQL语法要求的挑战。现有工作使用一系列示例（即问题-SQL对）来提示LLMs生成SQL，但固定的提示几乎无法处理检索出的示例与输入问题之间的语义差距较大的情况。在本文中，我们提出了一种基于检索增强的提示方法，用于基于LLM的文本到SQL框架，包括样本感知提示和动态修订链。我们的方法包括样本感知示例，其中包括SQL运算符的组合和与给定问题相关的细粒度信息。

    Text-to-SQL aims at generating SQL queries for the given natural language questions and thus helping users to query databases. Prompt learning with large language models (LLMs) has emerged as a recent approach, which designs prompts to lead LLMs to understand the input question and generate the corresponding SQL. However, it faces challenges with strict SQL syntax requirements. Existing work prompts the LLMs with a list of demonstration examples (i.e. question-SQL pairs) to generate SQL, but the fixed prompts can hardly handle the scenario where the semantic gap between the retrieved demonstration and the input question is large. In this paper, we propose a retrieval-augmented prompting method for a LLM-based Text-to-SQL framework, involving sample-aware prompting and a dynamic revision chain. Our approach incorporates sample-aware demonstrations, which include the composition of SQL operators and fine-grained information related to the given question. To retrieve questions sharing sim
    
[^64]: 脱机强化学习中的离散策略的扩散策略

    Diffusion Policies for Out-of-Distribution Generalization in Offline Reinforcement Learning. (arXiv:2307.04726v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.04726](http://arxiv.org/abs/2307.04726)

    该论文介绍了一种名为状态重构扩散策略 (SRDP) 的新方法，该方法在最新的扩散策略类中引入了状态重构特征学习，以解决脱机强化学习中的分布偏移和有效表示策略的问题。

    

    脱机强化学习 (RL) 方法利用以前的经验来学习比用于数据收集的行为策略更好的策略。与行为克隆相反，行为克隆假设数据是从专家演示中收集的，而脱机 RL 可以使用非专家数据和多模态行为策略。然而，脱机 RL 算法在处理分布偏移和有效表示策略方面面临挑战，因为训练过程中缺乏在线交互。先前关于脱机 RL 的工作使用条件扩散模型来表示数据集中的多模态行为。然而，这些方法并没有针对缓解脱机分布状态泛化而制定。我们介绍了一种新的方法，名为状态重构扩散策略 (SRDP)，将状态重构特征学习纳入到最新的扩散策略类中，以解决脱机分布通用化问题。状态重构损失促进了更详细的描述。

    Offline Reinforcement Learning (RL) methods leverage previous experiences to learn better policies than the behavior policy used for data collection. In contrast to behavior cloning, which assumes the data is collected from expert demonstrations, offline RL can work with non-expert data and multimodal behavior policies. However, offline RL algorithms face challenges in handling distribution shifts and effectively representing policies due to the lack of online interaction during training. Prior work on offline RL uses conditional diffusion models to represent multimodal behavior in the dataset. Nevertheless, these methods are not tailored toward alleviating the out-of-distribution state generalization. We introduce a novel method, named State Reconstruction for Diffusion Policies (SRDP), incorporating state reconstruction feature learning in the recent class of diffusion policies to address the out-of-distribution generalization problem. State reconstruction loss promotes more descript
    
[^65]: 边缘人工智能监管：管理对公共安全的新兴风险

    Frontier AI Regulation: Managing Emerging Risks to Public Safety. (arXiv:2307.03718v1 [cs.CY])

    [http://arxiv.org/abs/2307.03718](http://arxiv.org/abs/2307.03718)

    对于边缘人工智能模型的监管需要标准制定、注册报告和安全合规机制。

    

    先进的人工智能模型为人类带来巨大的好处，但社会需要主动管理相关的风险。本文关注我们所称的“边缘人工智能”模型：高度能力的基础模型，可能具备足以对公共安全造成严重风险的危险能力。边缘人工智能模型带来了独特的监管挑战：危险能力可能出乎意料；很难有效防止部署模型被滥用；并且很难阻止模型的能力广泛扩散。为了应对这些挑战，边缘模型的监管需要至少三个基本要素：(1) 设定标准的过程，以确定边缘人工智能开发者的适当要求；(2) 注册和报告要求，为监管机构提供对边缘人工智能开发过程的可见性；(3) 保证开发和部署的安全标准的机制。

    Advanced AI models hold the promise of tremendous benefits for humanity, but society needs to proactively manage the accompanying risks. In this paper, we focus on what we term "frontier AI" models: highly capable foundation models that could possess dangerous capabilities sufficient to pose severe risks to public safety. Frontier AI models pose a distinct regulatory challenge: dangerous capabilities can arise unexpectedly; it is difficult to robustly prevent a deployed model from being misused; and, it is difficult to stop a model's capabilities from proliferating broadly. To address these challenges, at least three building blocks for the regulation of frontier models are needed: (1) standard-setting processes to identify appropriate requirements for frontier AI developers, (2) registration and reporting requirements to provide regulators with visibility into frontier AI development processes, and (3) mechanisms to ensure compliance with safety standards for the development and deplo
    
[^66]: FormAI数据集：以形式验证为视角的软件安全生成AI

    The FormAI Dataset: Generative AI in Software Security Through the Lens of Formal Verification. (arXiv:2307.02192v2 [cs.DB] UPDATED)

    [http://arxiv.org/abs/2307.02192](http://arxiv.org/abs/2307.02192)

    本文介绍了一个名为FormAI的数据集，其中包含112,000个可编译的C程序，利用动态零-shot提示技术生成。这些程序经过形式验证，标记了源代码中的漏洞，并使用多种技术来提高程序的安全性和可靠性。

    

    本文介绍了FormAI数据集，这是一个包含112,000个具有漏洞分类的AI生成的可编译和独立的C程序的大型集合。我们引入了一种动态零-shot提示技术，用于生成利用大型语言模型（LLMs）的多样化程序。该数据集由GPT-3.5-turbo生成，并包含具有不同复杂度的程序。有些程序处理复杂任务，如网络管理、桌面游戏或加密，而其他程序处理简单任务，如字符串操作。每个程序都用源代码中找到的漏洞进行标记，指示类型、行号和漏洞函数名。这是通过使用高效的基于SMT的有界模型检查器（ESBMC）的形式验证方法实现的。该方法使用模型检查、抽象解释、约束编程和可满足性模理论来推理程序中的安全性/安全属性。这种方法确定了和验证了程序的安全性和可靠性。

    This paper presents the FormAI dataset, a large collection of 112, 000 AI-generated compilable and independent C programs with vulnerability classification. We introduce a dynamic zero-shot prompting technique constructed to spawn diverse programs utilizing Large Language Models (LLMs). The dataset is generated by GPT-3.5-turbo and comprises programs with varying levels of complexity. Some programs handle complicated tasks like network management, table games, or encryption, while others deal with simpler tasks like string manipulation. Every program is labeled with the vulnerabilities found within the source code, indicating the type, line number, and vulnerable function name. This is accomplished by employing a formal verification method using the Efficient SMT-based Bounded Model Checker (ESBMC), which uses model checking, abstract interpretation, constraint programming, and satisfiability modulo theories to reason over safety/security properties in programs. This approach definitiv
    
[^67]: 机器人请求帮助：用于大型语言模型规划器的不确定性对齐

    Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners. (arXiv:2307.01928v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2307.01928](http://arxiv.org/abs/2307.01928)

    KnowNo is a framework that measures and aligns the uncertainty of LLM-based planners, enabling them to ask for help when they don't know. It performs favorably in improving efficiency and autonomy compared to baselines, while providing formal assurances.

    

    大型语言模型（LLMs）展示了广泛的有前景的能力，从逐步规划到常识推理，这些能力可能为机器人提供效用，但仍然容易产生错误的预测。在这项工作中，我们提出了KnowNo，它是一种用于衡量和对齐基于LLM的规划器不确定性的框架，使其知道何时不知道并在需要时请求帮助。KnowNo基于符合预测理论，提供任务完成的统计保证，同时在复杂的多步规划环境中最大程度地减少人类帮助。在涉及不同模糊模式任务的各种模拟和实际机器人设置的实验中（例如从空间到数字的不确定性，从人类偏好到Winograd模式），结果表明KnowNo在提高效率和自治性方面相对于现代基线（可能涉及集合或广泛的提示调整）表现良好，同时提供正式的保证。

    Large language models (LLMs) exhibit a wide range of promising capabilities -- from step-by-step planning to commonsense reasoning -- that may provide utility for robots, but remain prone to confidently hallucinated predictions. In this work, we present KnowNo, which is a framework for measuring and aligning the uncertainty of LLM-based planners such that they know when they don't know and ask for help when needed. KnowNo builds on the theory of conformal prediction to provide statistical guarantees on task completion while minimizing human help in complex multi-step planning settings. Experiments across a variety of simulated and real robot setups that involve tasks with different modes of ambiguity (e.g., from spatial to numeric uncertainties, from human preferences to Winograd schemas) show that KnowNo performs favorably over modern baselines (which may involve ensembles or extensive prompt tuning) in terms of improving efficiency and autonomy, while providing formal assurances. Kno
    
[^68]: 通用零件组装规划

    General Part Assembly Planning. (arXiv:2307.00206v1 [cs.RO])

    [http://arxiv.org/abs/2307.00206](http://arxiv.org/abs/2307.00206)

    本论文研究了通用零件组装的问题，提出了一种基于Transformer的模型架构GPAT，能够准确预测零件的姿态并具有泛化能力。

    

    自主机器人组装领域的大多数成功都局限于单个目标或者单一类别。我们提出研究通用零件组装，即使用未见过的零件形状创建新颖目标组装的任务。为了解决通用零件组装的规划问题，我们提出了通用零件组装Transformer（GPAT），这是一种基于Transformer模型的架构，通过推断每个零件形状如何对应目标形状，准确预测零件的姿态。我们在3D CAD模型和现实世界扫描数据上进行的实验表明，GPAT具有对新颖和多样化的目标和零件形状的泛化能力。

    Most successes in autonomous robotic assembly have been restricted to single target or category. We propose to investigate general part assembly, the task of creating novel target assemblies with unseen part shapes. To tackle the planning of general part assembly, we present General Part Assembly Transformer (GPAT), a transformer based model architecture that accurately predicts part poses by inferring how each part shape corresponds to the target shape. Our experiments on both 3D CAD models and real-world scans demonstrate GPAT's generalization abilities to novel and diverse target and part shapes. Project website: https://general-part-assembly.github.io/
    
[^69]: 基于群体的鲁棒性：现实世界中定制鲁棒性的通用框架

    Group-based Robustness: A General Framework for Customized Robustness in the Real World. (arXiv:2306.16614v1 [cs.LG])

    [http://arxiv.org/abs/2306.16614](http://arxiv.org/abs/2306.16614)

    本研究提出了一种基于群体的鲁棒性指标，可以更好地评估机器学习模型在现实世界中抵抗攻击的能力，弥补了传统指标的不足。实验证明，该指标能够区分模型对特定威胁的脆弱性。

    

    众所周知，机器学习模型容易受到逃避攻击的影响，即通过扰动模型输入来引起错误分类。本研究中，我们发现传统的度量目标和非目标鲁棒性的指标无法准确评估现实世界中的真实威胁。为了解决现有方法的缺陷，我们正式定义了一种新的指标，称为基于群体的鲁棒性，它补充了现有的度量标准，并更适合评估特定攻击场景下的模型性能。我们通过实验证明，基于群体的鲁棒性能够在传统的鲁棒性指标不适用的情况下区分模型对特定威胁模型的脆弱性。此外，为了有效准确地衡量基于群体的鲁棒性，我们提出了两个损失函数。

    Machine-learning models are known to be vulnerable to evasion attacks that perturb model inputs to induce misclassifications. In this work, we identify real-world scenarios where the true threat cannot be assessed accurately by existing attacks. Specifically, we find that conventional metrics measuring targeted and untargeted robustness do not appropriately reflect a model's ability to withstand attacks from one set of source classes to another set of target classes. To address the shortcomings of existing methods, we formally define a new metric, termed group-based robustness, that complements existing metrics and is better-suited for evaluating model performance in certain attack scenarios. We show empirically that group-based robustness allows us to distinguish between models' vulnerability against specific threat models in situations where traditional robustness metrics do not apply. Moreover, to measure group-based robustness efficiently and accurately, we 1) propose two loss func
    
[^70]: SoftGPT: 通过预训练异质图变换生成模型学习面向目标的软物体操作技能

    SoftGPT: Learn Goal-oriented Soft Object Manipulation Skills by Generative Pre-trained Heterogeneous Graph Transformer. (arXiv:2306.12677v1 [cs.RO])

    [http://arxiv.org/abs/2306.12677](http://arxiv.org/abs/2306.12677)

    我们提出了一种预训练软物体操作技能学习模型SoftGPT，它使用大量的数据进行训练，结合三维异构图表示和基于GPT的动态模型，并利用这种先前知识来学习目标导向的软物体操作技能，从而打破了这一领域的技术瓶颈。

    

    在家庭场景中进行的软物体操作任务由于其复杂的动态特性和可变的形状特征，对现有机器人技能学习技术提出了重大挑战。由于从人类演示中学习新的操作技能是机器人应用的有效方式，因此开发软物体表示和动态的先前知识是必要的。在这方面，我们提出了一种名为SoftGPT的预训练软物体操作技能学习模型，该模型使用大量的探索数据进行训练，包括三维异构图表示和基于GPT的动态模型。针对每个下游任务，训练一个面向目标的策略代理以预测后续动作，SoftGPT生成这些动作的后果。将这两种方法集成在一起，建立了机器人思考过程，为促进策略学习提供了展开。我们的结果表明，利用软物体动力学和表示的先前知识使SoftGPT能够学习面向目标的软物体操作技能，从而胜过现有的最先进方法。

    Soft object manipulation tasks in domestic scenes pose a significant challenge for existing robotic skill learning techniques due to their complex dynamics and variable shape characteristics. Since learning new manipulation skills from human demonstration is an effective way for robot applications, developing prior knowledge of the representation and dynamics of soft objects is necessary. In this regard, we propose a pre-trained soft object manipulation skill learning model, namely SoftGPT, that is trained using large amounts of exploration data, consisting of a three-dimensional heterogeneous graph representation and a GPT-based dynamics model. For each downstream task, a goal-oriented policy agent is trained to predict the subsequent actions, and SoftGPT generates the consequences of these actions. Integrating these two approaches establishes a thinking process in the robot's mind that provides rollout for facilitating policy learning. Our results demonstrate that leveraging prior kn
    
[^71]: 积极协作的人机装配：利用人类意图预测和鲁棒安全控制

    Proactive Human-Robot Co-Assembly: Leveraging Human Intention Prediction and Robust Safe Control. (arXiv:2306.11862v1 [cs.RO])

    [http://arxiv.org/abs/2306.11862](http://arxiv.org/abs/2306.11862)

    本文提出了一个用于积极人机协作的集成框架，通过鲁棒的意图预测和安全控制来提高协作效率和避免交互安全风险。

    

    人机协作是实现灵活制造以满足不同客户需求的关键组成部分。然而，由于多种挑战，构建能够在安全高效地协助人类的智能机器人很困难。本文提出了一个用于积极人机协作的集成框架。该框架包括了一个鲁棒的意图预测模块和一个鲁棒的安全控制模块，分别用于提高协作效率和避免交互安全风险。通过在一个Kinova Gen3机器人上执行协作任务，实验结果表明了该解决方案对于环境变化和不同人类行为具有鲁棒性。

    Human-robot collaboration (HRC) is one key component to achieving flexible manufacturing to meet the different needs of customers. However, it is difficult to build intelligent robots that can proactively assist humans in a safe and efficient way due to several challenges.First, it is challenging to achieve efficient collaboration due to diverse human behaviors and data scarcity. Second, it is difficult to ensure interactive safety due to uncertainty in human behaviors. This paper presents an integrated framework for proactive HRC. A robust intention prediction module, which leverages prior task information and human-in-the-loop training, is learned to guide the robot for efficient collaboration. The proposed framework also uses robust safe control to ensure interactive safety under uncertainty. The developed framework is applied to a co-assembly task using a Kinova Gen3 robot. The experiment demonstrates that our solution is robust to environmental changes as well as different human p
    
[^72]: 在空中进行推理：基于推理的隐式语义感知通信框架

    Reasoning over the Air: A Reasoning-based Implicit Semantic-Aware Communication Framework. (arXiv:2306.11229v2 [cs.NI] UPDATED)

    [http://arxiv.org/abs/2306.11229](http://arxiv.org/abs/2306.11229)

    本文研究了隐式语义感知通信，提出了一种基于推理的隐式语义感知通信框架（iSAC），该框架可以在源用户和目标用户之间表示、通信和解释隐式语义含义。通过投影算法，将显式语义转换为低维语义表示，更好地描述隐含的语义含义。

    

    语义感知通信是一种新的范式，受到人类通信的启发，专注于传递信息的含义。由于其提高通信效率和可靠性，增强用户体验的潜力，近年来引起了极大的关注。现有的大部分工作都集中在传输和传递可以直接从源信号中识别的显式语义含义。本文研究了隐式语义感知通信，其中不能直接从源信号中观察到的隐藏信息必须由预期的用户识别和解释。为此，提出了一种新颖的隐式语义感知通信（iSAC）架构，用于在源用户和目标用户之间表示、通信和解释隐式语义含义。提出了一种基于投影的语义编码器，将显式语义的高维图形表示转换为低维的语义表示，以更好地描述隐含的语义含义。

    Semantic-aware communication is a novel paradigm that draws inspiration from human communication focusing on the delivery of the meaning of messages. It has attracted significant interest recently due to its potential to improve the efficiency and reliability of communication and enhance users' QoE. Most existing works focus on transmitting and delivering the explicit semantic meaning that can be directly identified from the source signal. This paper investigates the implicit semantic-aware communication in which the hidden information that cannot be directly observed from the source signal must be recognized and interpreted by the intended users. To this end, a novel implicit semantic-aware communication (iSAC) architecture is proposed for representing, communicating, and interpreting the implicit semantic meaning between source and destination users. A projection-based semantic encoder is proposed to convert the high-dimensional graphical representation of explicit semantics into a l
    
[^73]: SCALE: 提升高级语言模型评估的复杂性

    SCALE: Scaling up the Complexity for Advanced Language Model Evaluation. (arXiv:2306.09237v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.09237](http://arxiv.org/abs/2306.09237)

    该论文提出了一个新颖的自然语言处理基准测试，挑战当前大型语言模型在处理长文档、利用领域专业知识、多语言理解和多任务处理方面的能力。基准测试包含瑞士法律系统的多样化法律NLP数据集，允许进行对底层非英语、固有多语言的法律系统进行全面研究。

    

    最近在大型语言模型（LLM）方面取得的进展已经饱和了许多自然语言处理基准测试（包括专业领域的基准测试），强调了需要新颖、更具挑战性的测试来正确评估LLM的能力。在本文中，我们引入了一个新颖的自然语言处理基准测试，对当前LLM的四个关键方面提出了挑战：处理长文档（多达50K个标记）、利用领域专业知识（体现在法律文本中）、多语言理解（涵盖五种语言）和多任务处理（包括法律文件到文件信息检索、法庭视图生成、重要决策摘要、引用提取和八个具有挑战性的文本分类任务）。我们的基准测试包含了来自瑞士法律系统的多样的法律NLP数据集，可以对底层非英语、固有多语言的联邦法律系统进行全面研究。尽管最近取得了进展，但对于强烈的审查/分析任务，高效地处理长文档仍然是一个挑战。

    Recent strides in Large Language Models (LLMs) have saturated many NLP benchmarks (even professional domain-specific ones), emphasizing the need for novel, more challenging novel ones to properly assess LLM capabilities. In this paper, we introduce a novel NLP benchmark that poses challenges to current LLMs across four key dimensions: processing long documents (up to 50K tokens), utilizing domain specific knowledge (embodied in legal texts), multilingual understanding (covering five languages), and multitasking (comprising legal document to document Information Retrieval, Court View Generation, Leading Decision Summarization, Citation Extraction, and eight challenging Text Classification tasks). Our benchmark comprises diverse legal NLP datasets from the Swiss legal system, allowing for a comprehensive study of the underlying Non-English, inherently multilingual, federal legal system. Despite recent advances, efficiently processing long documents for intense review/analysis tasks remai
    
[^74]: 研究：社交感知时间松散解码器推荐系统

    STUDY: Socially Aware Temporally Casual Decoder Recommender Systems. (arXiv:2306.07946v1 [cs.SI])

    [http://arxiv.org/abs/2306.07946](http://arxiv.org/abs/2306.07946)

    该论文提出了一种基于社交感知和时间因素的解码器推荐系统(STUDY)，使用transformer解码器网络实现对社交网络图中相邻的用户组的联合推断。该方法在教育内容领域中经过测试，能够取得优于社交和顺序方法的结果。

    

    随着现在在线和离线可获取的数据数量过于庞大，推荐系统变得越来越必要，以帮助用户找到符合他们兴趣的物品。当社交网络信息存在时，有一些方法利用这些信息来做出更好的推荐，但这些方法通常有复杂的结构和训练过程。此外，许多现有的方法使用图神经网络，而这些网络训练起来非常困难。为了解决这个问题，我们提出了基于社交感知和时间因素的解码器推荐系统(STUDY)。STUDY采用一个经过修改的transformer解码器网络的单向前传，对社交网络图中相邻的用户组进行联合推断。我们在基于学校课堂结构定义社交网络的教育内容领域测试了我们的方法。我们的方法在保持单一均匀网络设计简单性的同时，优于社交和顺序方法。

    With the overwhelming amount of data available both on and offline today, recommender systems have become much needed to help users find items tailored to their interests. When social network information exists there are methods that utilize this information to make better recommendations, however the methods are often clunky with complex architectures and training procedures. Furthermore many of the existing methods utilize graph neural networks which are notoriously difficult to train. To address this, we propose Socially-aware Temporally caUsal Decoder recommender sYstems (STUDY). STUDY does joint inference over groups of users who are adjacent in the social network graph using a single forward pass of a modified transformer decoder network. We test our method in a school-based educational content setting, using classroom structure to define social networks. Our method outperforms both social and sequential methods while maintaining the design simplicity of a single homogeneous netw
    
[^75]: 提高决策树解释性的有效性

    Improving the Validity of Decision Trees as Explanations. (arXiv:2306.06777v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.06777](http://arxiv.org/abs/2306.06777)

    该论文介绍了一个新的决策树模型，利用挂起的树的方式提高了其解释性和统计性能，达到了无限深度决策树的水平，并可与XGBoost等最先进的方法相媲美。

    

    在基于表格数据的分类和预测中，人们经常使用基于树的模型。这可以在表格数据上与深度神经网络竞争[参见Grinsztajn等人，NeurIPS 2022，arXiv：2207.08815]，并且在某些条件下是可解释的。可解释性取决于树的深度和每个叶节点的准确性。在这里，我们训练了一个低深度的树，其目标是最小化每个叶节点上的最大错误分类，并从低深度树的每个叶节点“挂起”进一步的基于树的模型（例如无限深度的树）。低深度树易于解释，而综合低深度和挂起的基于树的模型的整体统计性能优于使用经典方法（例如CART）训练的无限深度决策树，并且与最先进的方法（例如优化的XGBoost）相当。

    In classification and forecasting with tabular data, one often utilizes tree-based models. This can be competitive with deep neural networks on tabular data [cf. Grinsztajn et al., NeurIPS 2022, arXiv:2207.08815] and, under some conditions, explainable. The explainability depends on the depth of the tree and the accuracy in each leaf of the tree. Here, we train a low-depth tree with the objective of minimising the maximum misclassification error across each leaf node, and then ``suspend'' further tree-based models (e.g., trees of unlimited depth) from each leaf of the low-depth tree. The low-depth tree is easily explainable, while the overall statistical performance of the combined low-depth and suspended tree-based models improves upon decision trees of unlimited depth trained using classical methods (e.g., CART) and is comparable to state-of-the-art methods (e.g., well-tuned XGBoost).
    
[^76]: DocumentCLIP：链接换行文件中的图像和正文文本

    DocumentCLIP: Linking Figures and Main Body Text in Reflowed Documents. (arXiv:2306.06306v1 [cs.CV])

    [http://arxiv.org/abs/2306.06306](http://arxiv.org/abs/2306.06306)

    DocumentCLIP是一种显著性感知对比学习框架，用于理解文档内长文本和图像之间的交互作用。我们是第一个在多模态文档内部链接方面进行对比学习的人。

    

    视觉语言预训练模型通过理解图像和文本之间的对齐而在支持多媒体应用方面取得了巨大成功。然而，现有的视觉语言预训练模型主要集中在理解单个图像与一段文本相关联，而往往忽略了多句话与多个图像组成的文档内部的对齐。在本文中，我们提出了一种称为DocumentCLIP的显著性感知对比学习框架，以强制视觉语言预训练模型理解文档内长文本和图像之间的交互作用。我们的模型有助于对新闻文章、杂志、产品描述等具有更丰富语言和视觉内容的真实世界多模态文档理解。据我们所知，我们是第一个通过对比学习探索多模态文档内部链接的人。此外，我们收集了一个大型的Wikipedia数据集进行预培训，为训练提供了多样化的来源。

    Vision-language pretraining models have achieved great success in supporting multimedia applications by understanding the alignments between images and text. While existing vision-language pretraining models primarily focus on understanding single image associated with a single piece of text, they often ignore the alignment at the intra-document level, consisting of multiple sentences with multiple images. In this work, we propose DocumentCLIP, a salience-aware contrastive learning framework to enforce vision-language pretraining models to comprehend the interaction between images and longer text within documents. Our model is beneficial for the real-world multimodal document understanding like news article, magazines, product descriptions, which contain linguistically and visually richer content. To the best of our knowledge, we are the first to explore multimodal intra-document links by contrastive learning. In addition, we collect a large Wikipedia dataset for pretraining, which pro
    
[^77]: AnoOnly:无需损失正常数据的半监督异常检测

    AnoOnly: Semi-Supervised Anomaly Detection without Loss on Normal Data. (arXiv:2305.18798v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.18798](http://arxiv.org/abs/2305.18798)

    AnoOnly是一个新的半监督异常检测框架，通过引入一种对正常数据的弱监督形式来解决同质数据对异常的影响，以实现平衡的监督。该框架在各种模型和数据集上表现出了显著的性能提升，达到了新的最佳性能。

    

    半监督异常检测(SSAD)方法通过利用少量但有指导作用的异常实例，增强了无监督异常检测(UAD)的效果。然而，同质正常数据对异常的统治使得SSAD模型无法有效地感知异常。为了解决这个问题并在严重不平衡的正常和异常数据之间实现平衡的监督，我们开发了一个名为AnoOnly(仅异常)的新框架。与现有的SSAD方法不同，AnoOnly暂停了严格的损失监督，引入了一种对正常数据的弱监督形式。这种弱监督通过批量归一化实现，隐式地对正常数据进行聚类学习。当集成到现有的SSAD方法中时，所提出的AnoOnly在各种模型和数据集上展示了显著的性能提升，达到了新的最佳性能。此外，我们的A

    Semi-supervised anomaly detection (SSAD) methods have demonstrated their effectiveness in enhancing unsupervised anomaly detection (UAD) by leveraging few-shot but instructive abnormal instances. However, the dominance of homogeneous normal data over anomalies biases the SSAD models against effectively perceiving anomalies. To address this issue and achieve balanced supervision between heavily imbalanced normal and abnormal data, we develop a novel framework called AnoOnly (Anomaly Only). Unlike existing SSAD methods that resort to strict loss supervision, AnoOnly suspends it and introduces a form of weak supervision for normal data. This weak supervision is instantiated through the utilization of batch normalization, which implicitly performs cluster learning on normal data. When integrated into existing SSAD methods, the proposed AnoOnly demonstrates remarkable performance enhancements across various models and datasets, achieving new state-of-the-art performance. Additionally, our A
    
[^78]: RL+模型控制：使用按需最优控制学习多功能足式 locomotion

    RL + Model-based Control: Using On-demand Optimal Control to Learn Versatile Legged Locomotion. (arXiv:2305.17842v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2305.17842](http://arxiv.org/abs/2305.17842)

    本文提出了一种 RL+模型控制框架以开发出可以有效可靠地学习的健壮控制策略，通过整合有限时间最优控制生成的按需参考运动分散 RL 过程，同时克服了建模简化的固有局限性，在足式 locomotion 上实现了多功能和强健，能泛化参考运动并处理更复杂的运动任务。

    

    本文提出了一种控制框架，将基于模型的最优控制和强化学习（RL）相结合，实现了多功能和强健的足式 locomotion。我们的方法通过整合有限时间最优控制生成的按需参考运动来增强 RL 训练过程，覆盖了广泛的速度和步态。这些参考运动作为 RL 策略模仿的目标，导致开发出可有效可靠地学习的健壮控制策略。此外，通过考虑全身动力学，RL 克服了建模简化的固有局限性。通过仿真和硬件实验，我们展示了 RL 训练过程在我们的框架内的强健性和可控性。此外，我们的方法展示了泛化参考运动和处理可能对简化模型构成挑战的更复杂的运动任务的能力，利用了 RL 的灵活性。

    This letter presents a control framework that combines model-based optimal control and reinforcement learning (RL) to achieve versatile and robust legged locomotion. Our approach enhances the RL training process by incorporating on-demand reference motions generated through finite-horizon optimal control, covering a broad range of velocities and gaits. These reference motions serve as targets for the RL policy to imitate, resulting in the development of robust control policies that can be learned efficiently and reliably. Moreover, by considering whole-body dynamics, RL overcomes the inherent limitations of modelling simplifications. Through simulation and hardware experiments, we demonstrate the robustness and controllability of the RL training process within our framework. Furthermore, our method demonstrates the ability to generalize reference motions and handle more complex locomotion tasks that may pose challenges for the simplified model, leveraging the flexibility of RL.
    
[^79]: 基于 Trend 和 Seasonality 分解和 LightGBM 的销售预测改进

    Improved Sales Forecasting using Trend and Seasonality Decomposition with LightGBM. (arXiv:2305.17201v1 [cs.LG])

    [http://arxiv.org/abs/2305.17201](http://arxiv.org/abs/2305.17201)

    本文提出了一种根据趋势和季节性分量在时间序列上的独特影响指标进行时间序列分组的新方法，并采用 LightGBM 模型进行预测，在沃尔玛销售数据上实现了较高的预测精度。

    

    针对沃尔玛和亚马逊等大型零售商销售预测的难点，本文提出了一种新的方法，即根据趋势和季节性分量在时间序列上的独特影响指标进行时间序列分组，并采用 LightGBM 模型进行预测。实验结果表明，该分组方法可以提高预测精度，相较于传统时间序列模型和其他机器学习模型，MAPE（平均绝对百分比误差）在测试集上可达 4.49%。

    Retail sales forecasting presents a significant challenge for large retailers such as Walmart and Amazon, due to the vast assortment of products, geographical location heterogeneity, seasonality, and external factors including weather, local economic conditions, and geopolitical events. Various methods have been employed to tackle this challenge, including traditional time series models, machine learning models, and neural network mechanisms, but the difficulty persists. Categorizing data into relevant groups has been shown to improve sales forecast accuracy as time series from different categories may exhibit distinct patterns. In this paper, we propose a new measure to indicate the unique impacts of the trend and seasonality components on a time series and suggest grouping time series based on this measure. We apply this approach to Walmart sales data from 01/29/2011 to 05/22/2016 and generate sales forecasts from 05/23/2016 to 06/19/2016. Our experiments show that the proposed strat
    
[^80]: 优化的自定义数据集用于高效检测水下垃圾

    Optimized Custom Dataset for Efficient Detection of Underwater Trash. (arXiv:2305.16460v1 [cs.CV])

    [http://arxiv.org/abs/2305.16460](http://arxiv.org/abs/2305.16460)

    本文提出了一种自定义数据集和有效检测方法，旨在通过增加垃圾实例的多样性，在深入水下环境中提高其检测精度。

    

    准确评估和清除潜在的水下废物对于保护海洋生物和环境至关重要。本文针对水下垃圾检测所存在的挑战，如光折射、吸收、悬浮颗粒和色彩扭曲等因素，提出了一种自定义数据集和有效检测方法。该数据集涵盖了多种水下环境，并包括对废弃物实例的精确定位标注。最终，使用最先进的深度学习结构，目的是通过增加垃圾实例的多样性，在深入水下环境中提高其检测精度。

    Accurately quantifying and removing submerged underwater waste plays a crucial role in safeguarding marine life and preserving the environment. While detecting floating and surface debris is relatively straightforward, quantifying submerged waste presents significant challenges due to factors like light refraction, absorption, suspended particles, and color distortion. This paper addresses these challenges by proposing the development of a custom dataset and an efficient detection approach for submerged marine debris. The dataset encompasses diverse underwater environments and incorporates annotations for precise labeling of debris instances. Ultimately, the primary objective of this custom dataset is to enhance the diversity of litter instances and improve their detection accuracy in deep submerged environments by leveraging state-of-the-art deep learning architectures.
    
[^81]: 用于雷达目标检测的点云多尺度网格渲染的改进

    Improved Multi-Scale Grid Rendering of Point Clouds for Radar Object Detection Networks. (arXiv:2305.15836v1 [cs.CV])

    [http://arxiv.org/abs/2305.15836](http://arxiv.org/abs/2305.15836)

    本文提出了一种新的体系结构，即多尺度 KPPillarsBEV，以缓解雷达目标检测中从点云数据转化为网格结构过程中的信息丢失问题，并提出了一种新的网格渲染方法 KPBEV。实验结果表明，该方法显著优于现有方法。

    

    将点云转换为网格表征，然后应用卷积神经网络的结构可用于雷达目标检测，但从不规则的点云数据转换为密集的网格结构常常会导致信息的丢失，这是由于点的离散化和聚合造成的。本文提出了一种新的体系结构，即多尺度 KPPillarsBEV，以缓解网格渲染的负面影响。具体而言，我们提出了一种新的网格渲染方法 KPBEV，它利用核点卷积的描述能力来改进网格渲染过程中局部点云上下文的编码。此外，我们还提出了一种通用的多尺度网格渲染公式，以任意网格渲染方法将多尺度特征映射融合到检测网络的卷积骨干中。我们在 nuScenes 数据集上进行了大量实验，并评估了检测汽车、卡车和公交车方法的性能。结果表明，我们提出的多尺度 KPPillarsBEV 结构和 KPBEV 网格渲染方法在性能上优于现有的方法。

    Architectures that first convert point clouds to a grid representation and then apply convolutional neural networks achieve good performance for radar-based object detection. However, the transfer from irregular point cloud data to a dense grid structure is often associated with a loss of information, due to the discretization and aggregation of points. In this paper, we propose a novel architecture, multi-scale KPPillarsBEV, that aims to mitigate the negative effects of grid rendering. Specifically, we propose a novel grid rendering method, KPBEV, which leverages the descriptive power of kernel point convolutions to improve the encoding of local point cloud contexts during grid rendering. In addition, we propose a general multi-scale grid rendering formulation to incorporate multi-scale feature maps into convolutional backbones of detection networks with arbitrary grid rendering methods. We perform extensive experiments on the nuScenes dataset and evaluate the methods in terms of dete
    
[^82]: 自动化仓储的多机器人协调和布局设计

    Multi-Robot Coordination and Layout Design for Automated Warehousing. (arXiv:2305.06436v1 [cs.RO])

    [http://arxiv.org/abs/2305.06436](http://arxiv.org/abs/2305.06436)

    通过优化仓库布局，可以减少拥堵，提高吞吐量，并扩大自动化仓库的可伸缩性。

    

    随着多智能体路径规划(MAPF)技术的快速发展，研究人员开始将MAPF算法应用于大型自动化仓库中，以协调数百个机器人。虽然大多数研究旨在通过开发更好的MAPF算法来提高仓库的吞吐量，但我们专注于通过优化仓库布局来提高其吞吐量。我们发现，即使使用最先进的MAPF算法，通常使用的人工设计布局也可能导致仓库的拥堵并且具有有限的可伸缩性。我们扩展了现有的自动场景生成方法以优化仓库布局。结果显示，我们优化后的仓库布局(1)减少了交通拥堵，从而提高了吞吐量，(2)通过加倍机器人数量在某些情况下提高了自动化仓库的可伸缩性，(3)能够生成具有用户指定多样性指标的布局。源代码位于：\url{https://github.com/lun}

    With the rapid progress in Multi-Agent Path Finding (MAPF), researchers have studied how MAPF algorithms can be deployed to coordinate hundreds of robots in large automated warehouses. While most works try to improve the throughput of such warehouses by developing better MAPF algorithms, we focus on improving the throughput by optimizing the warehouse layout. We show that, even with state-of-the-art MAPF algorithms, commonly used human-designed layouts can lead to congestion for warehouses with large numbers of robots and thus have limited scalability. We extend existing automatic scenario generation methods to optimize warehouse layouts. Results show that our optimized warehouse layouts (1) reduce traffic congestion and thus improve throughput, (2) improve the scalability of the automated warehouses by doubling the number of robots in some cases, and (3) are capable of generating layouts with user-specified diversity measures. We include the source code at: \url{https://github.com/lun
    
[^83]: 带深度划分的多提示模态交叉学习

    Multi-Prompt with Depth Partitioned Cross-Modal Learning. (arXiv:2305.06221v1 [cs.CV])

    [http://arxiv.org/abs/2305.06221](http://arxiv.org/abs/2305.06221)

    本研究提出了划分的多模态提示（PMPO）方法，将软提示从一个扩展到多个，通过连接多个提示到视觉编码器的不同深度上，能够更好地捕捉视觉表示的上下文深度，与传统单提示方法相比，在下游视觉语言任务中具有更好的表现。

    

    近年来，软提示学习方法被提出来微调大型视觉-语言预训练模型以完成各种下游任务。这些方法通常将可学习的文本标记与类别标记组合作为模型的输入，其中模型的参数被冻结。然而，它们经常使用单一提示来描述类别上下文，而不能充分捕捉类别的多样属性。本研究介绍了划分的多模态提示（PMPO），这是一种多模态提示技术，将软提示从一个可学习提示扩展到多个提示。我们的方法将视觉编码器深度进行分割，并将可学习提示连接到分离的视觉深度上，使不同提示能够捕捉视觉表示的层次上下文深度。此外，为了最大限度地利用多提示学习的优势，我们将来自手动设计的模板和可学习的多提示的先验信息结合在一起，从而提高了模型的泛化能力。

    In recent years, soft prompt learning methods have been proposed to fine-tune large-scale vision-language pre-trained models for various downstream tasks. These methods typically combine learnable textual tokens with class tokens as input for models with frozen parameters. However, they often employ a single prompt to describe class contexts, failing to capture categories' diverse attributes adequately. This study introduces the Partitioned Multi-modal Prompt (PMPO), a multi-modal prompting technique that extends the soft prompt from a single learnable prompt to multiple prompts. Our method divides the visual encoder depths and connects learnable prompts to the separated visual depths, enabling different prompts to capture the hierarchical contextual depths of visual representations. Furthermore, to maximize the advantages of multi-prompt learning, we incorporate prior information from manually designed templates and learnable multi-prompts, thus improving the generalization capabiliti
    
[^84]: ChatGPT启用的劳动力市场的未来：初步研究

    The Future of ChatGPT-enabled Labor Market: A Preliminary Study. (arXiv:2304.09823v1 [cs.CY])

    [http://arxiv.org/abs/2304.09823](http://arxiv.org/abs/2304.09823)

    本研究从人工智能协作的角度，通过分析大规模职位发布数据及基于职业知识图谱开发的协同过滤算法，预测了ChatGPT对未来劳动力市场的影响，发现目前约28％的职业需要ChatGPT相关技能。

    

    作为一个非凡的大型语言模型，ChatGPT在各种现实任务中取得了无与伦比的成功并越来越在我们的日常生活和工作中扮演重要角色。然而，人们也提出了广泛的担忧，特别是关于ChatGPT样的人工通用智能（AGI）是否会取代人类工作。因此，在本文中，我们从人工智能协作而不是对立的角度介绍了ChatGPT启用的劳动力市场的未来的初步数据驱动研究。具体来说，我们首先对中国最大的在线招聘平台BOSS直聘中的大规模职位发布数据进行深入分析。结果表明，当前劳动力市场约有28％的职业需要ChatGPT相关技能。此外，基于大规模基于职业的知识图谱，我们开发了一个语义信息增强的协同过滤算法，以预测未来职业技能。

    As a phenomenal large language model, ChatGPT has achieved unparalleled success in various real-world tasks and increasingly plays an important role in our daily lives and work. However, extensive concerns are also raised about the potential ethical issues, especially about whether ChatGPT-like artificial general intelligence (AGI) will replace human jobs. To this end, in this paper, we introduce a preliminary data-driven study on the future of ChatGPT-enabled labor market from the view of Human-AI Symbiosis instead of Human-AI Confrontation. To be specific, we first conduct an in-depth analysis of large-scale job posting data in BOSS Zhipin, the largest online recruitment platform in China. The results indicate that about 28% of occupations in the current labor market require ChatGPT-related skills. Furthermore, based on a large-scale occupation-centered knowledge graph, we develop a semantic information enhanced collaborative filtering algorithm to predict the future occupation-skill
    
[^85]: "一种适应或灭亡的局面": 游戏行业专业人士对文本生成图像人工智能的感知、采用和使用。

    "An Adapt-or-Die Type of Situation": Perception, Adoption, and Use of Text-To-Image-Generation AI by Game Industry Professionals. (arXiv:2302.12601v3 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2302.12601](http://arxiv.org/abs/2302.12601)

    TTIG模型是创造性人工智能的最新补充，可以根据文本描述生成图像。研究发现，专业人士对于TTIG应用和认知等方面存在12个主要问题。这项研究为支持TTIG的可持续采用提供了重要见解。

    

    文本生成图像(TTIG)模型是创造性人工智能的最新补充。这些模型可根据文本描述生成图像，开始与专业创作者的作品竞争并引发了有关创作工作、失业和版权等重要影响的讨论。为了支持TTIG的可持续采用，我们必须提供专业人士感知、采用和使用TTIG的丰富、可靠和透明的见解。然而，公共辩论浅薄、狭窄且缺乏透明度，学术工作则集中于研究TTIG在一般艺术家人群中的使用，但没有研究特定行业的专业人士的感知和态度。在本文中，我们对芬兰游戏行业进行了一项定性的探索性访谈研究，研究了TTIG的应用。通过对14个游戏专业人士进行的半结构化访谈的模板分析，我们揭示了12个总体主题，结构化成49个子主题，探讨了TTIG的应用和认知等方面的问题。

    Text-to-image generation (TTIG) models, a recent addition to creative AI, can generate images based on a text description. These models have begun to rival the work of professional creatives, and sparked discussions on the future of creative work, loss of jobs, and copyright issues, amongst other important implications. To support the sustainable adoption of TTIG, we must provide rich, reliable and transparent insights into how professionals perceive, adopt and use TTIG. Crucially though, the public debate is shallow, narrow and lacking transparency, while academic work has focused on studying the use of TTIG in a general artist population, but not on the perceptions and attitudes of professionals in a specific industry. In this paper, we contribute a qualitative, exploratory interview study on TTIG in the Finnish videogame industry. Through a Template Analysis on semi-structured interviews with 14 game professionals, we reveal 12 overarching themes, structured into 49 sub-themes on pr
    
[^86]: 在文本到图像扩散模型中添加条件控制

    Adding Conditional Control to Text-to-Image Diffusion Models. (arXiv:2302.05543v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.05543](http://arxiv.org/abs/2302.05543)

    ControlNet是一种神经网络架构，用于为大规模预训练的文本到图像扩散模型添加条件控制。它可以通过重复使用预先训练的编码层学习多样的条件控制，并通过逐渐增加参数进行微调，从而在控制图像扩散模型方面具有鲁棒性。

    

    我们提出了ControlNet，一种神经网络架构，可以为大规模预训练的文本到图像扩散模型添加空间条件控制。ControlNet锁定了生产就绪的大型扩散模型，并重复使用它们以数十亿张图像进行预训练的深度和稳健的编码层作为强大的骨干，从而学习多样化的条件控制。该神经架构与“零卷积”（零初始化的卷积层）连接，从零开始逐渐增加参数，并确保没有有害的噪声影响微调。我们使用单个或多个条件进行稳定扩散测试了各种条件控制，例如边缘、深度、分割、人体姿势等，并且可以有或没有提示。我们展示了ControlNets的训练对于小（<50k）和大（>1m）数据集是鲁棒的。广泛的结果表明，ControlNet可以促进更广泛的应用以控制图像扩散模型。

    We present ControlNet, a neural network architecture to add spatial conditioning controls to large, pretrained text-to-image diffusion models. ControlNet locks the production-ready large diffusion models, and reuses their deep and robust encoding layers pretrained with billions of images as a strong backbone to learn a diverse set of conditional controls. The neural architecture is connected with "zero convolutions" (zero-initialized convolution layers) that progressively grow the parameters from zero and ensure that no harmful noise could affect the finetuning. We test various conditioning controls, eg, edges, depth, segmentation, human pose, etc, with Stable Diffusion, using single or multiple conditions, with or without prompts. We show that the training of ControlNets is robust with small (<50k) and large (>1m) datasets. Extensive results show that ControlNet may facilitate wider applications to control image diffusion models.
    
[^87]: 基于时间注意机制的中期风电功率预测新框架

    A novel framework for medium-term wind power prediction based on temporal attention mechanisms. (arXiv:2302.01222v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01222](http://arxiv.org/abs/2302.01222)

    本文提出了一种基于树状Parzen估计器（TPE）和分解算法的新框架（TPE-VMD-TFT），用于24小时和48小时之前的风电功率预测。在法国电力公司Engie的风能数据集上，所提出的方法表现良好。

    

    风能是一种广泛分布、可再生和环保的能源，对缓解全球变暖和能源短缺具有重要作用。然而，由于其不确定性和波动性，大规模风电系统的网格集成具有挑战性。中期风电功率预测可以为能量调度提供基本依据，因此精确的风电功率预测至关重要。本文提出了一种基于树状Parzen估计器（TPE）和分解算法的新框架。该框架基于变分模式分解（VMD）和时间融合变压器（TFT）定义了24小时和48小时之前的风电功率预测的TPE-VMD-TFT方法。在法国电力公司Engie的风能数据集上，结果表明所提出的方法优于其他方法。

    Wind energy is a widely distributed, recyclable and environmentally friendly energy source that plays an important role in mitigating global warming and energy shortages. Wind energy's uncertainty and fluctuating nature makes grid integration of large-scale wind energy systems challenging. Medium-term wind power forecasts can provide an essential basis for energy dispatch, so accurate wind power forecasts are essential. Much research has yielded excellent results in recent years. However, many of them require additional experimentation and analysis when applied to other data. In this paper, we propose a novel short-term forecasting framework by tree-structured parzen estimator (TPE) and decomposition algorithms. This framework defines the TPE-VMD-TFT method for 24-h and 48-h ahead wind power forecasting based on variational mode decomposition (VMD) and time fusion transformer (TFT). In the Engie wind dataset from the electricity company in France, the results show that the proposed met
    
[^88]: 反向传播展开的折叠优化求解器

    Backpropagation of Unrolled Solvers with Folded Optimization. (arXiv:2301.12047v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12047](http://arxiv.org/abs/2301.12047)

    本文提出了一种通过解析优化的方法来解决反向传播中的精度和效率问题，并提供了生成高效可解析的反向传播优化模型的系统。此外，本文还提出了通过优化映射统一展开和解析微分的视角。

    

    在深度网络中将约束优化模型作为组件集成，可以在许多专门的学习任务上取得有希望的进展。在这种情况下的一个核心挑战是通过优化问题的解来进行反向传播，而该解通常缺乏闭合的形式。一种典型的策略是算法展开，它依赖于迭代求解器的自动微分操作。虽然灵活且通用，但在实际中，展开可能遇到精度和效率问题。通过优化的解析微分可以避免这些问题，但当前的框架对于优化问题的形式施加了严格的要求。本文提供了关于展开优化后向传递的理论见解，从而提出了一个生成高效可解析的反向传播优化模型的系统。此外，本文还提出了通过优化映射统一展开和解析微分的视角。在实验上进行测试

    The integration of constrained optimization models as components in deep networks has led to promising advances on many specialized learning tasks. A central challenge in this setting is backpropagation through the solution of an optimization problem, which typically lacks a closed form. One typical strategy is algorithm unrolling, which relies on automatic differentiation through the operations of an iterative solver. While flexible and general, unrolling can encounter accuracy and efficiency issues in practice. These issues can be avoided by analytical differentiation of the optimization, but current frameworks impose rigid requirements on the optimization problem's form. This paper provides theoretical insights into the backward pass of unrolled optimization, leading to a system for generating efficiently solvable analytical models of backpropagation. Additionally, it proposes a unifying view of unrolling and analytical differentiation through optimization mappings. Experiments over
    
[^89]: SPTS v2: 单点场景文本定位

    SPTS v2: Single-Point Scene Text Spotting. (arXiv:2301.01635v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.01635](http://arxiv.org/abs/2301.01635)

    本研究提出的SPTS v2框架，首次证明了可以使用极低成本的单点注释来训练场景文本定位模型，同时保留了自回归Transformer与实例分配解码器（IAD）的优势，并使用并行识别解码器（PRD）进行文本识别。

    

    由于文本检测和识别之间的内在协同作用，端到端的场景文本定位取得了显著的进展。先前的方法通常将手动标注（如水平矩形、旋转矩形、四边形和多边形）视为必要条件，而这比使用单点要昂贵得多。我们首次证明了通过提出的名为SPTS v2的框架，可以使用极低成本的单点注释来训练场景文本定位模型。SPTS v2通过以顺序预测同一预测序列中所有文本实例的中心点，保留了自回归Transformer与实例分配解码器（IAD）的优势，同时使用并行识别解码器（PRD）进行文本识别。这两个解码器共享相同的参数，并通过简单而有效的信息传输过程进行交互连接，以传递梯度和信息。

    End-to-end scene text spotting has made significant progress due to its intrinsic synergy between text detection and recognition. Previous methods commonly regard manual annotations such as horizontal rectangles, rotated rectangles, quadrangles, and polygons as a prerequisite, which are much more expensive than using single-point. For the first time, we demonstrate that training scene text spotting models can be achieved with an extremely low-cost single-point annotation by the proposed framework, termed SPTS v2. SPTS v2 reserves the advantage of the auto-regressive Transformer with an Instance Assignment Decoder (IAD) through sequentially predicting the center points of all text instances inside the same predicting sequence, while with a Parallel Recognition Decoder (PRD) for text recognition in parallel. These two decoders share the same parameters and are interactively connected with a simple but effective information transmission process to pass the gradient and information. Compre
    
[^90]: 反向课程强化学习

    Backward Curriculum Reinforcement Learning. (arXiv:2212.14214v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.14214](http://arxiv.org/abs/2212.14214)

    这项工作提出了一种新颖的反向课程强化学习方法，通过使用回放轨迹而不是原始的前向轨迹来训练智能体。这种方法通过提供强有力的奖励信号实现了更高效的学习，而且只需要进行微小的算法改变。

    

    当前强化学习算法使用前向生成轨迹来训练智能体，这种方法提供的指导不足以使智能体进行尽可能多的探索。尽管我们认识到强化学习结果来自充分的探索，但这种方法在样本效率上存在折衷，这是影响算法性能的重要因素。以往的方法使用奖励塑造技术和网络结构修改来增加样本效率，但这些方法需要很多步骤来实现。在本文中，我们提出了一种新颖的反向课程强化学习方法，即通过使用回放轨迹而不是原始的前向轨迹来训练智能体。这种方法为智能体提供了强有力的奖励信号，从而实现更高效的学习。此外，我们的方法只需要在智能体训练之前对轨迹的顺序进行微小的改变，使得实现起来更加直接。

    Current reinforcement learning algorithms train an agent using forward-generated trajectories, which provide little guidance so that the agent can explore as much as possible. While realizing the value of reinforcement learning results from sufficient exploration, this approach leads to a trade-off in losing sample efficiency, an essential factor impacting algorithm performance. Previous tasks use reward-shaping techniques and network structure modification to increase sample efficiency. However, these methods require many steps to implement. In this work, we propose novel backward curriculum reinforcement learning that begins training the agent using the backward trajectory of the episode instead of the original forward trajectory. This approach provides the agent with a strong reward signal, enabling more sample-efficient learning. Moreover, our method only requires a minor change in the algorithm of reversing the order of the trajectory before agent training, allowing a straightforw
    
[^91]: 重新思考适用于MobileNet速度和尺寸的Vision Transformers

    Rethinking Vision Transformers for MobileNet Size and Speed. (arXiv:2212.08059v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.08059](http://arxiv.org/abs/2212.08059)

    本研究重新思考了Vision Transformers在移动设备上的部署效率，并提出了一种新的超网络设计和搜索策略，以实现与MobileNet类似大小和速度的Transformer模型。

    

    随着Vision Transformers在计算机视觉任务中取得的成功，最近的研究尝试优化ViTs的性能和复杂性，以实现在移动设备上的高效部署。提出了多种方法来加速注意力机制，改进低效的设计，或将移动设备友好的轻量级卷积与ViTs结合形成混合架构。然而，即使是多年前的MobileNet，ViT及其变种仍然具有更高的延迟或更多的参数。在实践中，延迟和大小对于在资源受限硬件上的高效部署都是至关重要的。在这项工作中，我们对ViTs的设计选择进行了重新审视，并提出了一种具有低延迟和高参数效率的新型超网络。我们进一步引入了一种新颖的细粒度联合搜索策略，用于通过优化来寻找高效的transformer架构。

    With the success of Vision Transformers (ViTs) in computer vision tasks, recent arts try to optimize the performance and complexity of ViTs to enable efficient deployment on mobile devices. Multiple approaches are proposed to accelerate attention mechanism, improve inefficient designs, or incorporate mobile-friendly lightweight convolutions to form hybrid architectures. However, ViT and its variants still have higher latency or considerably more parameters than lightweight CNNs, even true for the years-old MobileNet. In practice, latency and size are both crucial for efficient deployment on resource-constraint hardware. In this work, we investigate a central question, can transformer models run as fast as MobileNet and maintain a similar size? We revisit the design choices of ViTs and propose a novel supernet with low latency and high parameter efficiency. We further introduce a novel fine-grained joint search strategy for transformer models that can find efficient architectures by opt
    
[^92]: 通过 Lov\'asz Local Lemma 进行采样的马尔可夫随机场学习组合结构

    Learning Combinatorial Structures via Markov Random Fields with Sampling through Lov\'asz Local Lemma. (arXiv:2212.00296v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.00296](http://arxiv.org/abs/2212.00296)

    Nelson是一种基于神经网络和Lov\'asz Local Lemma的方法，使用约束的马尔可夫随机场模型生成满足组合约束条件的样本。

    

    学习组合结构的生成模型在许多应用中具有革命性的影响，但现有方法无法提供高效且准确的学习结果，由于学习目标受到组合约束条件的制约，其梯度估计非常复杂。我们开发了基于 Lov\'asz Local Lemma 的神经网络（Nelson），它能够从约束的马尔可夫随机场模型的分布中生成满足组合约束条件的样本。

    Generative models for learning combinatorial structures have transformative impacts in many applications. However, existing approaches fail to offer efficient and accurate learning results. Because of the highly intractable nature of the gradient estimation of the learning objective subject to combinatorial constraints. Existing gradient estimation methods would easily run into exponential time/memory space, or incur huge estimation errors due to improper approximation. We develop NEural Lovasz Sampler (Nelson), a neural network based on Lov\'asz Local Lemma (LLL). We show it guarantees to generate samples satisfying combinatorial constraints from the distribution of the constrained Markov Random Fields model (MRF) under certain conditions. We further present a fully differentiable contrastive-divergence-based learning framework on constrained MRF (Nelson-CD). Meanwhile, Nelson-CD being fully differentiable allows us to take advantage of the parallel computing power of GPUs, resulting 
    
[^93]: 社交媒体挖掘处方药物的毒性监测: 从头到尾的管道，挑战和未来工作。

    Social media mining for toxicovigilance of prescription medications: End-to-end pipeline, challenges and future work. (arXiv:2211.10443v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.10443](http://arxiv.org/abs/2211.10443)

    本文描述了一个为社交媒体挖掘非医学处方药物使用信息而开发的端到端管道，并讨论了挑战和未来工作。

    

    物质使用、物质使用障碍和与物质使用相关的过量是全球和美国的主要公共卫生问题。从公共卫生的角度来解决这些问题的一个关键方面是改进监测系统。传统的监测系统滞后，而社交媒体是及时数据的潜在有用来源。然而，从社交媒体中挖掘知识是具有挑战性的，并且需要开发先进的人工智能，特别是自然语言处理（NLP）和机器学习方法。我们开发了一个复杂的从社交媒体中挖掘非医学处方药物使用信息的端到端管道，即Twitter和Reddit。我们的管道采用了监督式机器学习和NLP来过滤噪音和描述交流内容。在本文中，我们描述了我们在四年内开发的端到端管道。除了描述我们的数据挖掘基础设施外，我们还讨论了现有的挑战。

    Substance use, substance use disorder, and overdoses related to substance use are major public health problems globally and in the United States. A key aspect of addressing these problems from a public health standpoint is improved surveillance. Traditional surveillance systems are laggy, and social media are potentially useful sources of timely data. However, mining knowledge from social media is challenging, and requires the development of advanced artificial intelligence, specifically natural language processing (NLP) and machine learning methods. We developed a sophisticated end-to-end pipeline for mining information about nonmedical prescription medication use from social media, namely Twitter and Reddit. Our pipeline employs supervised machine learning and NLP for filtering out noise and characterizing the chatter. In this paper, we describe our end-to-end pipeline developed over four years. In addition to describing our data mining infrastructure, we discuss existing challenges 
    
[^94]: 连续向量空间中的数学表达式语义表示

    Semantic Representations of Mathematical Expressions in a Continuous Vector Space. (arXiv:2211.08142v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.08142](http://arxiv.org/abs/2211.08142)

    该论文提出了一种在连续向量空间中表示数学表达式的方法，并使用序列到序列框架的编码器生成向量表示来捕捉数学语义，比自动编码器效果更好。

    

    数学符号在STEM文献中占据了很大一部分，但是，为公式找到语义表示仍然是一个具有挑战性的问题。由于数学符号是精确的，在字符微小变化时其含义会发生显著变化，因此适用于自然文本的方法并不一定适用于数学表达式。在这项工作中，我们描述了一种在连续向量空间中表示数学表达式的方法。我们使用一个序列到序列框架的编码器，训练其在视觉上不同但在数学上等价的表达式上生成向量表示（或嵌入）。我们将这种方法与自动编码器进行比较，并表明前者更能捕捉数学语义。最后，为了促进未来的研究，我们发布了一份等价的超越和代数表达式对的语料库。

    Mathematical notation makes up a large portion of STEM literature, yet, finding semantic representations for formulae remains a challenging problem. Because mathematical notation is precise, and its meaning changes significantly with small character shifts, the methods that work for natural text do not necessarily work well for mathematical expressions. In this work, we describe an approach for representing mathematical expressions in a continuous vector space. We use the encoder of a sequence-to-sequence architecture, trained on visually different but mathematically equivalent expressions, to generate vector representations (or embeddings). We compare this approach with an autoencoder and show that the former is better at capturing mathematical semantics. Finally, to expedite future research, we publish a corpus of equivalent transcendental and algebraic expression pairs.
    
[^95]: MemoNet: 通过多哈希码本网络高效地记忆所有交叉特征表示以实现CTR预测

    MemoNet: Memorizing All Cross Features' Representations Efficiently via Multi-Hash Codebook Network for CTR Prediction. (arXiv:2211.01334v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2211.01334](http://arxiv.org/abs/2211.01334)

    本文提出了一种名为MemoNet的CTR模型，通过引入多哈希码本网络（HCNet）作为记忆机制，高效地学习和记忆交叉特征的表示。实验结果表明MemoNet在性能上优于最先进的方法，并且展现出NLP中的大型语言模型的扩展规律。

    

    自然语言处理（NLP）中的新发现表明，强大的记忆能力对大型语言模型（LLM）的成功起到了很大作用。这启发我们将独立的记忆机制引入CTR排名模型，以学习和记忆交叉特征的表示。本文提出了多哈希码本网络（HCNet）作为CTR任务中高效学习和记忆交叉特征表示的记忆机制。HCNet使用多哈希码本作为主要的记忆位置，并由多哈希寻址、记忆恢复和特征缩减三个阶段组成。我们还提出了一种名为MemoNet的新型CTR模型，将HCNet与DNN骨干网络相结合。广泛的实验结果在三个公共数据集和在线测试中表明，MemoNet在性能上优于最先进的方法。此外，MemoNet展现出NLP中的大型语言模型的扩展规律，这意味着我们可以扩大模型规模来提高性能。

    New findings in natural language processing (NLP) demonstrate that the strong memorization capability contributes a lot to the success of Large Language Models (LLM). This inspires us to explicitly bring an independent memory mechanism into CTR ranking model to learn and memorize cross features' representations. In this paper, we propose multi-Hash Codebook NETwork (HCNet) as the memory mechanism for efficiently learning and memorizing representations of cross features in CTR tasks. HCNet uses a multi-hash codebook as the main memory place and the whole memory procedure consists of three phases: multi-hash addressing, memory restoring, and feature shrinking. We also propose a new CTR model named MemoNet which combines HCNet with a DNN backbone. Extensive experimental results on three public datasets and online test show that MemoNet reaches superior performance over state-of-the-art approaches. Besides, MemoNet shows scaling law of large language model in NLP, which means we can enlarg
    
[^96]: 可观测完美均衡 (Observable Perfect Equilibrium)

    Observable Perfect Equilibrium. (arXiv:2210.16506v5 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2210.16506](http://arxiv.org/abs/2210.16506)

    本文提出一种新的博弈均衡概念——可观测完美均衡，在顺序不完全信息博弈中可以帮助创建真正的策略代理。这种均衡概念在公开观察的行动概率方面具有鲁棒性。

    

    尽管纳什均衡成为了博弈论的核心解决方案概念，许多重要的博弈包含多个纳什均衡，我们必须确定如何在其中选择，以创建真正的策略代理。为顺序不完全信息博弈提出了几个纳什均衡细化概念，其中最突出的是颤抖手完美均衡、拟完美均衡和最近提出的单侧拟完美均衡。这些概念对某些任意小的错误具有鲁棒性，并保证始终存在。但我们认为，对于发展顺序不完全信息博弈中强大的代理人，这些概念都不正确。我们为游戏树中提出了一种新的均衡概念——可观测完美均衡，在其中，解决方案在公开观察的行动概率方面具有鲁棒性（并不一定针对所有可能不可观察的行动概率具有鲁棒性）。

    While Nash equilibrium has emerged as the central game-theoretic solution concept, many important games contain several Nash equilibria and we must determine how to select between them in order to create real strategic agents. Several Nash equilibrium refinement concepts have been proposed and studied for sequential imperfect-information games, the most prominent being trembling-hand perfect equilibrium, quasi-perfect equilibrium, and recently one-sided quasi-perfect equilibrium. These concepts are robust to certain arbitrarily small mistakes, and are guaranteed to always exist; however, we argue that neither of these is the correct concept for developing strong agents in sequential games of imperfect information. We define a new equilibrium refinement concept for extensive-form games called observable perfect equilibrium in which the solution is robust over trembles in publicly-observable action probabilities (not necessarily over all action probabilities that may not be observable by
    
[^97]: JAX-DIPS：有限离散方法的神经引导法及其在具有间断的椭圆问题中的应用

    JAX-DIPS: Neural bootstrapping of finite discretization methods and application to elliptic problems with discontinuities. (arXiv:2210.14312v2 [math.NA] UPDATED)

    [http://arxiv.org/abs/2210.14312](http://arxiv.org/abs/2210.14312)

    JAX-DIPS是一种基于有限离散方法和神经网络的可伸缩策略，用于开发无网格混合神经符号偏微分方程求解器，并在具有间断的椭圆问题中得到应用。

    

    我们提出了一种可伸缩的策略，用于基于现有基于网格的数值离散方法开发无网格混合神经符号偏微分方程求解器。特别是，这种策略可以通过（i）利用先进数值方法、求解器和预处理器的准确性和收敛性以及（ii）将优化限制在一阶自动微分上，以更高效地训练偏微分方程的神经网络代理模型。所提出的神经引导方法（以下简称NBM）基于相对于神经网络的可训练参数的随机取样点上隐式笛卡尔单元格上获得的PDE系统的有限离散残差的评估。值得注意的是，引导有限离散方程中存在的守恒定律和对称性能够向神经网络提供有关解的信息。

    We present a scalable strategy for development of mesh-free hybrid neuro-symbolic partial differential equation solvers based on existing mesh-based numerical discretization methods. Particularly, this strategy can be used to efficiently train neural network surrogate models of partial differential equations by (i) leveraging the accuracy and convergence properties of advanced numerical methods, solvers, and preconditioners, as well as (ii) better scalability to higher order PDEs by strictly limiting optimization to first order automatic differentiation. The presented neural bootstrapping method (hereby dubbed NBM) is based on evaluation of the finite discretization residuals of the PDE system obtained on implicit Cartesian cells centered on a set of random collocation points with respect to trainable parameters of the neural network. Importantly, the conservation laws and symmetries present in the bootstrapped finite discretization equations inform the neural network about solution re
    
[^98]: 使用Transformer的基于视频的物体6D姿态估计

    Video based Object 6D Pose Estimation using Transformers. (arXiv:2210.13540v2 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2210.13540](http://arxiv.org/abs/2210.13540)

    本论文介绍了一种基于Transformer的视频中物体6D姿态估计框架，利用先前的帧信息进行姿态估计，实现了高效而准确的姿态估计，能够处理长时间序列依赖关系，并且相对于CNN方法表现更好，具有33fps的处理速度，适用于实时物体姿态估计应用。

    

    我们引入了一个名为VideoPose的基于Transformer的6D物体姿态估计框架，该框架采用端到端的基于注意力机制的建模架构，通过关注先前的帧来估计视频中准确的6D物体姿态。我们的方法利用视频序列中的时间信息进行姿态细化，同时具有计算效率高和鲁棒性强的特点。与现有方法相比，我们的架构能够有效地捕捉和推理远距离依赖关系，从而在视频序列上进行迭代细化。对YCB-Video数据集的实验评估结果显示，我们的方法与最先进的Transformer方法持平，并相对于基于CNN的方法表现显著更好。此外，我们的方法每秒能处理33帧，更加高效，因此适用于需要实时物体姿态估计的各种应用。训练代码和预训练模型可在https://github.com/ApoorvaBeedu/VideoPose上获得。

    We introduce a Transformer based 6D Object Pose Estimation framework VideoPose, comprising an end-to-end attention based modelling architecture, that attends to previous frames in order to estimate accurate 6D Object Poses in videos. Our approach leverages the temporal information from a video sequence for pose refinement, along with being computationally efficient and robust. Compared to existing methods, our architecture is able to capture and reason from long-range dependencies efficiently, thus iteratively refining over video sequences. Experimental evaluation on the YCB-Video dataset shows that our approach is on par with the state-of-the-art Transformer methods, and performs significantly better relative to CNN based approaches. Further, with a speed of 33 fps, it is also more efficient and therefore applicable to a variety of applications that require real-time object pose estimation. Training code and pretrained models are available at https://github.com/ApoorvaBeedu/VideoPose
    
[^99]: 朝着以人为中心的可解释型人工智能：对模型解释的用户研究综述

    Towards Human-centered Explainable AI: A Survey of User Studies for Model Explanations. (arXiv:2210.11584v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2210.11584](http://arxiv.org/abs/2210.11584)

    对模型解释的用户研究综述发现，可解释型人工智能（XAI）正在某些应用领域快速扩散，但用户评估仍然稀缺且几乎不涉及认知或社会科学的见解。

    

    可解释型人工智能（XAI）被广泛认为是不断扩展的人工智能研究的必需条件。对XAI用户需求的更好理解以及可解释模型的人本评估既是必要性也是挑战。在本文中，我们通过系统性文献综述研究了HCI和AI研究人员如何进行XAI应用的用户研究。通过对过去五年中基于人类的XAI评估的97篇核心论文进行识别和深入分析，我们将其按照解释方法的测量特征（信任、理解、可用性和人工智能与人类的合作表现）进行分类。我们的研究表明，XAI在某些应用领域（如推荐系统）扩散更迅速，但用户评估仍相当稀缺，并且几乎没有融入认知或社会科学的任何见解。基于综合讨论的最佳实践，即常见模型、设计选择和度量方法。

    Explainable AI (XAI) is widely viewed as a sine qua non for ever-expanding AI research. A better understanding of the needs of XAI users, as well as human-centered evaluations of explainable models are both a necessity and a challenge. In this paper, we explore how HCI and AI researchers conduct user studies in XAI applications based on a systematic literature review. After identifying and thoroughly analyzing 97core papers with human-based XAI evaluations over the past five years, we categorize them along the measured characteristics of explanatory methods, namely trust, understanding, usability, and human-AI collaboration performance. Our research shows that XAI is spreading more rapidly in certain application domains, such as recommender systems than in others, but that user evaluations are still rather sparse and incorporate hardly any insights from cognitive or social sciences. Based on a comprehensive discussion of best practices, i.e., common models, design choices, and measures
    
[^100]: 一个安全的联邦数据驱动多目标优化算法

    A Secure Federated Data-Driven Evolutionary Multi-objective Optimization Algorithm. (arXiv:2210.08295v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2210.08295](http://arxiv.org/abs/2210.08295)

    该论文提出了一个安全的联邦数据驱动多目标优化算法，旨在保护原始数据和通过服务器上的获得函数进行优化而获得的新增解决方案的隐私和安全性。通过在每次代理更新时，在随机选择的客户端上选择查询点，减少了泄漏解决方案信息的风险。

    

    数据驱动的进化算法通常旨在利用有限数量的数据来进行优化，已经在解决许多复杂的实际优化问题上取得了成功。然而，大多数数据驱动的进化算法都是集中式的，从而引发了隐私和安全问题。为了解决这个问题，本文提出了一种安全的联邦数据驱动多目标优化算法，旨在保护原始数据和通过对服务器上的获得函数进行优化而获得的新增解决方案。我们在每次代理更新时，在随机选择的客户端上选择查询点，通过计算该客户端上未观测点的获得函数值，从而降低了泄漏关于待采样解决方案的信息的风险。

    Data-driven evolutionary algorithms usually aim to exploit the information behind a limited amount of data to perform optimization, which have proved to be successful in solving many complex real-world optimization problems. However, most data-driven evolutionary algorithms are centralized, causing privacy and security concerns. Existing federated Bayesian algorithms and data-driven evolutionary algorithms mainly protect the raw data on each client. To address this issue, this paper proposes a secure federated data-driven evolutionary multi-objective optimization algorithm to protect both the raw data and the newly infilled solutions obtained by optimizing the acquisition function conducted on the server. We select the query points on a randomly selected client at each round of surrogate update by calculating the acquisition function values of the unobserved points on this client, thereby reducing the risk of leaking the information about the solution to be sampled. In addition, since 
    
[^101]: 暂停分子表征学习：用于分子属性预测的新方法

    Taking a Respite from Representation Learning for Molecular Property Prediction. (arXiv:2209.13492v3 [q-bio.QM] UPDATED)

    [http://arxiv.org/abs/2209.13492](http://arxiv.org/abs/2209.13492)

    本研究对一系列分子表征模型进行了系统评估，发现基于固定表征的模型在分子属性预测中具有一定优势，同时也揭示了活性断崖问题。

    

    人工智能在药物发现中的应用越来越广泛，其中重要的任务之一就是分子属性预测。虽然分子表征学习的技术如此发达，但其背后的基础问题却未被认真探究。在本研究中，我们使用多种分子表征对一系列代表性模型进行了系统评估。除了常用的MoleculeNet基准数据集外，我们还从ChEMBL数据库和文献中收集了一套与阿片类物质相关的数据集以及两个额外的活性数据集。同时，我们也组装了一系列具有不同规模的描述符数据集来评估模型的性能。总共，我们训练了62,820个模型，其中包括50,220个使用固定表征的模型、4,200个使用SMILES序列的模型和8,400个使用分子图的模型。我们首先进行了数据集分析，并强调了阿片类物质中的活性断崖问题。

    Artificial intelligence (AI) has been widely applied in drug discovery with a major task as molecular property prediction. Despite booming techniques in molecular representation learning, fundamentals underlying molecular property prediction haven't been carefully examined yet. In this study, we conducted a systematic evaluation on a collection of representative models using various molecular representations. In addition to the commonly used MoleculeNet benchmark datasets, we also assembled a suite of opioids-related datasets from ChEMBL and two additional activity datasets from literature. To interrogate the basic predictive power, we also assembled a series of descriptors datasets with varying sizes to evaluate the models' performance. In total, we trained 62,820 models, including 50,220 models on fixed representations, 4,200 models on SMILES sequences and 8,400 models on molecular graphs. We first conducted dataset profiling and highlighted the activity-cliffs issue in the opioids-r
    
[^102]: 数字音频取证：盲目检测人类语音模仿

    Digital Audio Forensics: Blind Human Voice Mimicry Detection. (arXiv:2209.12573v4 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2209.12573](http://arxiv.org/abs/2209.12573)

    本文介绍了一种利用深度学习方法，通过盲目检测输入音频的真实性，可以有效应对音频欺诈问题的分类器。而这种分类器不需要任何参考，能够在没有真实来源的情况下检测出模仿音频。

    

    音频是人类交流中使用最广泛的方式之一，但同时也很容易被误用来欺骗人们。随着人工智能的革命，相关技术现在对几乎所有人都可用，这使得犯罪和伪造变得更加简单。本篇论文介绍了一种深度学习方法，开发了一个分类器，可以盲目分类输入音频为真实或者模仿；“盲目”指的是能够在没有参考或真实来源的情况下检测仿制音频的能力。所提出的模型是在一个大型音频数据集中提取的一组重要特征上进行训练的，以得到一个分类器，该分类器被用于测试不同音频的相同特征集。数据提取自两个原始数据集，特别为这项工作而编写;一个全英文数据集和一个混合数据集（阿拉伯语加英语）。这些数据集已通过GitHub以原始形式提供给研究社区，网址为https://github.com/SaSs7/Datas

    Audio is one of the most used ways of human communication, but at the same time it can be easily misused to trick people. With the revolution of AI, the related technologies are now accessible to almost everyone thus making it simple for the criminals to commit crimes and forgeries. In this work, we introduce a deep learning method to develop a classifier that will blindly classify an input audio as real or mimicked; the word 'blindly' refers to the ability to detect mimicked audio without references or real sources. The proposed model was trained on a set of important features extracted from a large dataset of audios to get a classifier that was tested on the same set of features from different audios. The data was extracted from two raw datasets, especially composed for this work; an all English dataset and a mixed dataset (Arabic plus English). These datasets have been made available, in raw form, through GitHub for the use of the research community at https://github.com/SaSs7/Datas
    
[^103]: 从深度学习的视角看待对齐问题

    The alignment problem from a deep learning perspective. (arXiv:2209.00626v5 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.00626](http://arxiv.org/abs/2209.00626)

    人工通用智能（AGI）的出现可能会导致其追求与人类利益不对齐的目标，并采用欺骗性行为和权力追求策略。防止这种情况的发生是一个重要的研究方向。

    

    在未来几十年内，人工通用智能（AGI）可能在许多关键任务上超越人类能力。我们认为，如果没有大量努力来防止它，AGIs可能会学会追求与人类利益冲突（即不对齐）的目标。如果像现在最具能力的模型一样进行训练，AGIs可能会学会欺骗性地行动以获得更高的奖励，学会在其微调分布之外进行内部目标的泛化，并利用寻求权力的策略来追求这些目标。我们回顾了这些特性的新证据。具有这些特性的AGIs将很难进行对齐，即使在不对齐的情况下也可能表现出对齐。我们概述了不对齐的AGIs的部署如何可能会不可逆地削弱人类对世界的控制，并简要回顾了旨在防止这种结果的研究方向。

    In coming decades, artificial general intelligence (AGI) may surpass human capabilities at many critical tasks. We argue that, without substantial effort to prevent it, AGIs could learn to pursue goals that conflict (i.e., are misaligned) with human interests. If trained like today's most capable models, AGIs could learn to act deceptively to receive higher reward, learn internally-represented goals which generalize beyond their fine-tuning distributions, and pursue those goals using power-seeking strategies. We review emerging evidence for these properties. AGIs with these properties would be difficult to align and may appear aligned even when they are not. We outline how the deployment of misaligned AGIs might irreversibly undermine human control over the world, and briefly review research directions aimed at preventing this outcome.
    
[^104]: 学习有效的选择预测的抽象规划模型

    Learning Efficient Abstract Planning Models that Choose What to Predict. (arXiv:2208.07737v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2208.07737](http://arxiv.org/abs/2208.07737)

    该论文提出了一种学习抽象规划模型的方法，通过选择预测来提高机器人在长期任务中的决策效率。

    

    在具有连续状态和行动空间的机器人领域中，解决长期任务的有效方法是双层规划，其中在环境的抽象层上进行高级搜索以指导低级决策。最近的研究表明，通过学习符号操作和神经采样器的抽象模型，可以实现这种双层规划。在本研究中，我们展示了现有的符号操作学习方法在许多机器人领域存在不足之处，因为机器人的行动往往会引起抽象状态中大量无关的变化，而这些方法试图学习准确预测抽象状态中所有观察到的变化的操作。为了解决这个问题，我们提出了一种学习"选择要预测"的操作的方法，只对实现指定目标的抽象规划所必需的变化建模。通过实验证明，我们的方法能够学习出导致10个不同混合任务上的高效规划的操作。

    An effective approach to solving long-horizon tasks in robotics domains with continuous state and action spaces is bilevel planning, wherein a high-level search over an abstraction of an environment is used to guide low-level decision-making. Recent work has shown how to enable such bilevel planning by learning abstract models in the form of symbolic operators and neural samplers. In this work, we show that existing symbolic operator learning approaches fall short in many robotics domains where a robot's actions tend to cause a large number of irrelevant changes in the abstract state. This is primarily because they attempt to learn operators that exactly predict all observed changes in the abstract state. To overcome this issue, we propose to learn operators that 'choose what to predict' by only modelling changes necessary for abstract planning to achieve specified goals. Experimentally, we show that our approach learns operators that lead to efficient planning across 10 different hybr
    
[^105]: 深度学习的分层分布感知测试

    Hierarchical Distribution-Aware Testing of Deep Learning. (arXiv:2205.08589v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2205.08589](http://arxiv.org/abs/2205.08589)

    本文提出了一种新的深度学习鲁棒性测试方法，通过考虑特征和像素级别的分布，捕捉对抗扰动的感知质量，以改善模型可靠性。

    

    深度学习在安全关键应用中的使用越来越多，这引发了对其可靠性的担忧。深度学习在面对对抗扰动（即对手样本）时往往缺乏鲁棒性。尽管最近采用了先进的攻击和测试方法来检测对手样本，但这些方法往往忽视了输入分布和扰动的感知质量。结果，检测到的对手样本在实际应用中可能不相关，或者对人类观察者来说可能看起来不真实。这导致测试资源浪费在在现实世界中很少发生的稀有对手样本上，限制了深度学习模型可靠性的提高。在本文中，我们提出了一种新的鲁棒性测试方法，用于检测对手样本，考虑到了特征级别分布和像素级别分布，捕捉了对抗扰动的感知质量。这两种考虑通过一种新颖的分层机制来编码。

    Deep Learning (DL) is increasingly used in safety-critical applications, raising concerns about its reliability. DL suffers from a well-known problem of lacking robustness, especially when faced with adversarial perturbations known as Adversarial Examples (AEs). Despite recent efforts to detect AEs using advanced attack and testing methods, these approaches often overlook the input distribution and perceptual quality of the perturbations. As a result, the detected AEs may not be relevant in practical applications or may appear unrealistic to human observers. This can waste testing resources on rare AEs that seldom occur during real-world use, limiting improvements in DL model dependability.  In this paper, we propose a new robustness testing approach for detecting AEs that considers both the feature level distribution and the pixel level distribution, capturing the perceptual quality of adversarial perturbations. The two considerations are encoded by a novel hierarchical mechanism. Fir
    
[^106]: 图像检索的内省式深度度量学习

    Introspective Deep Metric Learning for Image Retrieval. (arXiv:2205.04449v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2205.04449](http://arxiv.org/abs/2205.04449)

    本文提出了一种内省式深度度量学习（IDML）框架，通过不确定性建模改进了深度度量学习的性能，并在多个数据集上取得了最先进的结果。

    

    本文提出了一种内省式深度度量学习（IDML）框架，用于对图像进行不确定性感知的比较。传统的深度度量学习方法在图像之间产生自信的语义距离，而不考虑不确定性水平。然而，我们认为一个好的相似性模型应该谨慎考虑语义差异，以更好地处理模糊的图像，从而实现更稳健的训练。为了实现这一点，我们提出使用语义嵌入和伴随的不确定性嵌入来表示图像，分别描述图像的语义特征和模糊度。我们进一步提出了一种内省式相似性度量，用于在考虑图像的语义差异和模糊度的情况下进行相似性判断。所提出的IDML框架通过不确定性建模改进了深度度量学习的性能，并在广泛使用的CUB-200-2011，Cars196和Stanford Online数据集上取得了最先进的结果。

    This paper proposes an introspective deep metric learning (IDML) framework for uncertainty-aware comparisons of images. Conventional deep metric learning methods produce confident semantic distances between images regardless of the uncertainty level. However, we argue that a good similarity model should consider the semantic discrepancies with caution to better deal with ambiguous images for more robust training. To achieve this, we propose to represent an image using not only a semantic embedding but also an accompanying uncertainty embedding, which describes the semantic characteristics and ambiguity of an image, respectively. We further propose an introspective similarity metric to make similarity judgments between images considering both their semantic differences and ambiguities. The proposed IDML framework improves the performance of deep metric learning through uncertainty modeling and attains state-of-the-art results on the widely used CUB-200-2011, Cars196, and Stanford Online
    
[^107]: 通过遍历功能不变路径，构建灵活的机器学习系统

    Engineering flexible machine learning systems by traversing functionally-invariant paths. (arXiv:2205.00334v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.00334](http://arxiv.org/abs/2205.00334)

    该论文介绍了一个名为功能不变路径（FIP）的差分几何框架，用于实现神经网络的灵活、连续适应，以应对各种机器学习目标和网络稀疏化目标。

    

    变压器已成为自然语言处理和计算机视觉中最先进的神经网络架构。在基础模型范例中，大型变压器模型（BERT、GPT3/4、Bloom、ViT）通过自监督任务（如词或图像屏蔽）进行预训练，然后通过微调适应于下游用户应用，包括指令跟随和问答。虽然有许多模型微调方法（如低秩权重更新策略，如LoRA），但仍然对实现网络适应性而不损失知识的数学原理知之甚少。在这里，我们引入了一个差分几何框架，功能不变路径（FIP），为一系列机器学习目标和网络稀疏化目标提供灵活和连续的神经网络适应。我们将神经网络的权重空间构想为一个曲率的黎曼流形，并配备了一个度规张量。

    Transformers have emerged as the state of the art neural network architecture for natural language processing and computer vision. In the foundation model paradigm, large transformer models (BERT, GPT3/4, Bloom, ViT) are pre-trained on self-supervised tasks such as word or image masking, and then, adapted through fine-tuning for downstream user applications including instruction following and Question Answering. While many approaches have been developed for model fine-tuning including low-rank weight update strategies (eg. LoRA), underlying mathematical principles that enable network adaptation without knowledge loss remain poorly understood. Here, we introduce a differential geometry framework, functionally invariant paths (FIP), that provides flexible and continuous adaptation of neural networks for a range of machine learning goals and network sparsification objectives. We conceptualize the weight space of a neural network as a curved Riemannian manifold equipped with a metric tenso
    
[^108]: 知识驱动的分子学习：范式转移的综述

    Knowledge-informed Molecular Learning: A Survey on Paradigm Transfer. (arXiv:2202.10587v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.10587](http://arxiv.org/abs/2202.10587)

    本文调查了知识驱动的分子学习，从范式转移的视角出发，总结了其不同范式的分类和方法论，并分析了领域知识的贡献。

    

    机器学习，尤其是深度学习，显著推动了生物化学领域内的分子研究。传统上，这类研究的建模主要围绕着一些范式展开。例如，预测范式经常用于分子性质预测等任务。为了增强纯数据驱动模型的生成和可解释性，学者们将生化领域的知识融入到这些分子研究模型中。这种融合引发了范式转移的飞速发展，即通过将一个分子学习任务转化为另一个任务来解决问题。随着大型语言模型的出现，这些范式呈现出逐渐趋于统一的趋势。在本文中，我们从范式转移的角度，对知识驱动的分子学习进行了文献综述。我们对这些范式进行分类、审视它们的方法论，并剖析了领域知识的贡献。

    Machine learning, notably deep learning, has significantly propelled molecular investigations within the biochemical sphere. Traditionally, modeling for such research has centered around a handful of paradigms. For instance, the prediction paradigm is frequently deployed for tasks such as molecular property prediction. To enhance the generation and decipherability of purely data-driven models, scholars have integrated biochemical domain knowledge into these molecular study models. This integration has sparked a surge in paradigm transfer, which is solving one molecular learning task by reformulating it as another one. With the emergence of Large Language Models, these paradigms have demonstrated an escalating trend towards harmonized unification. In this work, we delineate a literature survey focused on knowledge-informed molecular learning from the perspective of paradigm transfer. We classify the paradigms, scrutinize their methodologies, and dissect the contribution of domain knowle
    
[^109]: LoNLI：一个可扩展的框架，用于测试NLI的多样化逻辑推理能力

    LoNLI: An Extensible Framework for Testing Diverse Logical Reasoning Capabilities for NLI. (arXiv:2112.02333v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2112.02333](http://arxiv.org/abs/2112.02333)

    本文提出了LoNLI框架，可用于集体测试NLI的不同逻辑推理能力。通过创建一个大型测试平台和相关框架，我们可以单独测试和分析多个推理维度的能力，并进行跨能力信息内容的实验研究。这项工作的贡献在于提供一个可扩展的测试框架，帮助深入了解NLI和NLU领域的逻辑推理。

    

    自然语言推理（NLI）被认为是测试自然语言理解（NLU）的代表性任务。在这项工作中，我们提出了一个可扩展的框架，以集体但有分类地测试NLI（以及NLU的延伸）所需的多样化逻辑推理能力。受行为测试的启发，我们创建了一个半合成的大型测试平台（363个模板，363k个例子）和一个相关的框架，提供以下实用功能：1）单独测试和分析17个推理维度的推理能力（包括语用推理）；2）设计实验以研究跨能力信息内容（排除一个或增加一个）；3）合成的性质使我们能够控制人工和偏见。我们扩展了一个公开可用的自动化测试用例实例化框架（CheckList）和一个定义明确的能力分类法，以涵盖更广泛、更困难的测试用例范围，同时变化着能力。

    Natural Language Inference (NLI) is considered a representative task to test natural language understanding (NLU). In this work, we propose an extensible framework to collectively yet categorically test diverse Logical reasoning capabilities required for NLI (and, by extension, NLU). Motivated by behavioral testing, we create a semi-synthetic large test bench (363 templates, 363k examples) and an associated framework that offers the following utilities: 1) individually test and analyze reasoning capabilities along 17 reasoning dimensions (including pragmatic reasoning); 2) design experiments to study cross-capability information content (leave one out or bring one in); and 3) the synthetic nature enables us to control for artifacts and biases. We extend a publicly available framework of automated test case instantiation from free-form natural language templates (CheckList) and a well-defined taxonomy of capabilities to cover a wide range of increasingly harder test cases while varying 
    
[^110]: 通过干净标签数据毒化对基于哈希的图像检索的后门攻击

    Backdoor Attack on Hash-based Image Retrieval via Clean-label Data Poisoning. (arXiv:2109.08868v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2109.08868](http://arxiv.org/abs/2109.08868)

    本文提出了一种通过注入带有正确标签的毒化图像来实现后门攻击的方法，该攻击难以被检测到。通过优化哈希码学习和使用有针对性的对抗性贴片作为后门触发器，可以提高攻击性能。

    

    预期后门深度哈希模型在原始查询图像上表现正常，并在出现特定触发模式时返回带有目标标签的图像。为此，我们提出了混淆扰动引起的后门攻击（CIBA）。它将少量带有正确标签的毒化图像注入到训练数据中，使得攻击难以被检测到。为了制作毒化图像，我们首先提出了混淆扰动来干扰哈希码的学习。因此，哈希模型可以更多地了解触发器。混淆扰动在汉明空间中通过优化类内离散度和类间偏移生成，其几乎无法察觉。然后，我们使用有针对性的对抗性贴片作为后门触发器来提高攻击性能。我们进行了大量实验证明了我们提出的CIBA的有效性。我们的代码可在https://github.com/KuofengGao/CIBA找到。

    A backdoored deep hashing model is expected to behave normally on original query images and return the images with the target label when a specific trigger pattern presents. To this end, we propose the confusing perturbations-induced backdoor attack (CIBA). It injects a small number of poisoned images with the correct label into the training data, which makes the attack hard to be detected. To craft the poisoned images, we first propose the confusing perturbations to disturb the hashing code learning. As such, the hashing model can learn more about the trigger. The confusing perturbations are imperceptible and generated by optimizing the intra-class dispersion and inter-class shift in the Hamming space. We then employ the targeted adversarial patch as the backdoor trigger to improve the attack performance. We have conducted extensive experiments to verify the effectiveness of our proposed CIBA. Our code is available at https://github.com/KuofengGao/CIBA.
    

