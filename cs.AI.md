# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Pok\'eLLMon: A Human-Parity Agent for Pok\'emon Battles with Large Language Models](https://rss.arxiv.org/abs/2402.01118) | Pok\'eLLMon是第一个在战术对战游戏中实现人类能力的语言模型化身代理机器人。它通过上下文强化学习、知识增强生成和一致的行动生成的策略，展现了与人类类似的战斗策略和及时决策，并在Ladder比赛中达到了49%的胜率，在邀请对战中达到了56%的胜率。 |
| [^2] | [Beyond Accuracy: An Empirical Study on Unit Testing in Open-source Deep Learning Projects](https://arxiv.org/abs/2402.16546) | 通过对GitHub上9,129个开源DL项目的单元测试进行实证研究，发现经过单元测试的DL项目与开源项目指标呈正相关，68%的DL项目根本没有进行单元测试，并建立了单元测试和DL项目中故障之间的映射分类法。 |
| [^3] | [RoboGrind: Intuitive and Interactive Surface Treatment with Industrial Robots](https://arxiv.org/abs/2402.16542) | RoboGrind是一个集成系统，通过3D感知、交互式语音控制向导系统和自动规划执行流水线实现工业机器人对表面处理任务的直观、交互式自动化，为重制玻璃纤维风力涡轮叶片提供了解决方案。 |
| [^4] | [Memory GAPS: Would LLM pass the Tulving Test?](https://arxiv.org/abs/2402.16505) | 本文旨在探讨四十多年前的图尔文测试框架是否对LLM的记忆行为有所帮助。 |
| [^5] | [Intelligent Known and Novel Aircraft Recognition -- A Shift from Classification to Similarity Learning for Combat Identification](https://arxiv.org/abs/2402.16486) | 这项研究提出了一种新颖、可扩展且基于人工智能的解决方案，采用相似度学习来区分广泛范围的军用和民用飞机特征，实现在遥感图像中准确识别已知和新颖飞机类型。 |
| [^6] | [On Languaging a Simulation Engine](https://arxiv.org/abs/2402.16482) | 通过三种功能化类型的语言模型，提出了一种语言到模拟（Lang2Sim）框架，实现了精准将文本描述转化为可执行模拟器输入的方法。 |
| [^7] | [mEdIT: Multilingual Text Editing via Instruction Tuning](https://arxiv.org/abs/2402.16472) | 该论文介绍了mEdIT，这是CoEdIT的多语言扩展，使用指令调整对多语言文本编辑模型进行微调训练，在多语言文本编辑任务中表现强劲。 |
| [^8] | [Defending LLMs against Jailbreaking Attacks via Backtranslation](https://arxiv.org/abs/2402.16459) | 通过反向翻译来防御LLMs免受越狱攻击，将生成的反向翻译提示用于揭示原始提示的实际意图，提高了模型的安全性。 |
| [^9] | [Performance Comparison of Surrogate-Assisted Evolutionary Algorithms on Computational Fluid Dynamics Problems](https://arxiv.org/abs/2402.16455) | 最近发布的方法和利用微分进化作为优化机制之一的技术在计算流体动力学问题上的代理辅助进化算法中表现明显优于其他方法。 |
| [^10] | [Online Efficient Safety-Critical Control for Mobile Robots in Unknown Dynamic Multi-Obstacle Environments](https://arxiv.org/abs/2402.16449) | 提出了一个基于LiDAR的目标导向和勘探框架，实现了在线障碍物避免在未知动态多障碍环境中的高效控制 |
| [^11] | [On Distributed Larger-Than-Memory Subset Selection With Pairwise Submodular Functions](https://arxiv.org/abs/2402.16442) | 本文提出了一种新颖的分布式约束算法，通过迭代绑定最小和最大效用值来选择高质量的点并丢弃不重要的点。 |
| [^12] | [Training Implicit Generative Models via an Invariant Statistical Loss](https://arxiv.org/abs/2402.16435) | 提出了一种通过不变统计损失训练隐式生成模型的方法，解决了训练不稳定和模式缺失问题 |
| [^13] | [Graph Learning with Distributional Edge Layouts](https://arxiv.org/abs/2402.16402) | 图神经网络中提出了一种新的全局布局采样方法，Distributional Edge Layouts（DELs），通过Langevin动力学和玻尔兹曼分布，能够捕获广泛的能量分布，提供额外的表达能力，有助于简化下游任务。 |
| [^14] | [Investigating Deep Watermark Security: An Adversarial Transferability Perspective](https://arxiv.org/abs/2402.16397) | 本研究通过引入两种有效的可迁移攻击者，填补了深度水印技术在面对擦除和篡改风险时的脆弱性这一领域缺乏系统研究的空白。 |
| [^15] | [MoZIP: A Multilingual Benchmark to Evaluate Large Language Models in Intellectual Property](https://arxiv.org/abs/2402.16389) | 本文提出了一个新的多语言基准MoZIP，用于评估大型语言模型在知识产权领域的表现，并开发了一个新的IP-oriented多语言大型语言模型MoZi，实验证明MoZi在MoZIP基准上的表现优越。 |
| [^16] | [On the Generalization Capability of Temporal Graph Learning Algorithms: Theoretical Insights and a Simpler Method](https://arxiv.org/abs/2402.16387) | 本文探讨了时间图学习算法的泛化能力，并提出了一种更简单的方法Simplified-Temporal-Graph-Network。 |
| [^17] | [An Automated End-to-End Open-Source Software for High-Quality Text-to-Speech Dataset Generation](https://arxiv.org/abs/2402.16380) | 该论文介绍了一种端到端工具，用于生成高质量的文本转语音（TTS）模型数据集，实现了语言特定的语音分布整合、自动化录制过程、自动化和人机协作的录音质量保证以及录音格式处理。 |
| [^18] | [Improving LLM-based Machine Translation with Systematic Self-Correction](https://arxiv.org/abs/2402.16379) | 引入了名为TER的系统LLM自校正翻译框架，成功帮助LLMs提高翻译质量，具有更优越的系统性和可解释性。 |
| [^19] | [Generative AI in Vision: A Survey on Models, Metrics and Applications](https://arxiv.org/abs/2402.16369) | 扩散模型作为一种强大的方法正在生成高质量图像、文本和音频，而此调查论文旨在全面概述生成AI扩散和传统模型的基本技术、应用和挑战。 |
| [^20] | [LLM Inference Unveiled: Survey and Roofline Model Insights](https://arxiv.org/abs/2402.16363) | 本文提出了一个基于Roofline模型的框架，用于系统分析LLM推断技术，帮助识别部署中的瓶颈，并为更有效地部署LLM提供策略。 |
| [^21] | [Layer-wise Regularized Dropout for Neural Language Models](https://arxiv.org/abs/2402.16361) | 本文提出了一种专为Transformer-based语言模型设计的新颖的分层正则化Dropout（LR-Drop）方法，通过一致性训练策略逐层对每个Transformer层进行正则化，实现了隐藏状态、多头注意力矩阵和输出分布的一致性。 |
| [^22] | [Feedback Efficient Online Fine-Tuning of Diffusion Models](https://arxiv.org/abs/2402.16359) | 提出了一种反馈高效的在线微调扩散模型的强化学习程序 |
| [^23] | [Language-guided Skill Learning with Temporal Variational Inference](https://arxiv.org/abs/2402.16354) | 该论文提出了一种语言引导的技能学习算法，通过整合大型语言模型生成的分割信息来发现可重用的技能，并引入最小描述长度原则来引导这一过程，实现了在不同环境中加速学习并超越基线方法的效果。 |
| [^24] | [MathGenie: Generating Synthetic Data with Question Back-translation for Enhancing Mathematical Reasoning of LLMs](https://arxiv.org/abs/2402.16352) | MathGenie通过问题反向翻译生成合成数据，用于增强LLMs的数学推理能力，并创造了一个家族化的模型系列MathGenieLM。 |
| [^25] | [Contingency Planning Using Bi-level Markov Decision Processes for Space Missions](https://arxiv.org/abs/2402.16342) | 提出利用双层马尔可夫决策过程来改善行星漫游车穿越规划中的计算挑战，并提高人工智能解决方案的可解释性和可信度 |
| [^26] | [Self-Supervised Speech Quality Estimation and Enhancement Using Only Clean Speech](https://arxiv.org/abs/2402.16321) | 提出了VQScore，一种基于矢量量化可变分编码器的自监督度量，用于评估语音质量并进行自监督语音增强训练，通过引入领域知识和新颖的自蒸馏机制提高模型的相关性和鲁棒性。 |
| [^27] | [Chain-of-Discussion: A Multi-Model Framework for Complex Evidence-Based Question Answering](https://arxiv.org/abs/2402.16313) | 提出了一种Chain-of-Discussion框架，通过多个开源语言模型的协同作用，提高了复杂问题回答的质量 |
| [^28] | [Federated Contextual Cascading Bandits with Asynchronous Communication and Heterogeneous Users](https://arxiv.org/abs/2402.16312) | 本研究提出了一种解决联邦上下文级联多臂老虎机问题的算法，通过异步通信和考虑异质用户行为，实现了对具有不同偏好的用户提供定制化推荐，并给出了次线性的遗憾界限。 |
| [^29] | [Cross-domain Chinese Sentence Pattern Parsing](https://arxiv.org/abs/2402.16311) | 本文提出了一种利用大型语言模型进行自我训练的创新方法，通过动态生成训练数据将源领域句法规则与目标领域句子相结合，增强句式结构解析器对各种领域的适应能力，实验证明其在教科书和新闻领域的效果优于基于规则的基准模型1.68个百分点。 |
| [^30] | [REPLAY: Modeling Time-Varying Temporal Regularities of Human Mobility for Location Prediction over Sparse Trajectories](https://arxiv.org/abs/2402.16310) | 该论文提出了REPLAY模型，利用一般RNN架构来学习捕捉人类移动的时间变化规律，用于位置预测。 |
| [^31] | [Referee Can Play: An Alternative Approach to Conditional Generation via Model Inversion](https://arxiv.org/abs/2402.16305) | 通过模型反演提出了一种训练自由的方法，可以绕过传统的采样过程，直接优化图像并获得更好的文本图像对齐，为改进图像生成提供了关键设计。 |
| [^32] | [Graph Diffusion Policy Optimization](https://arxiv.org/abs/2402.16302) | 本文引入了图扩散策略优化（GDPO），通过强化学习为任意目标优化图扩散模型，实现了在各种图生成任务中的最先进性能。 |
| [^33] | [MV-Swin-T: Mammogram Classification with Multi-view Swin Transformer](https://arxiv.org/abs/2402.16298) | 提出了一种基于Transformer的创新多视角网络用于乳腺X线摄影图像分类，引入了动态注意力块以有效整合多视图信息，并促进信息之间的连贯传递 |
| [^34] | [Poisson-Gamma Dynamical Systems with Non-Stationary Transition Dynamics](https://arxiv.org/abs/2402.16297) | 提出了一种具有非平稳转移动态的泊松-伽马动力系统，通过采用Dirichlet Markov链和数据增广技术来解决原有模型捕捉时变转移动态的不足。 |
| [^35] | [Decentralized Federated Unlearning on Blockchain](https://arxiv.org/abs/2402.16294) | 提出了基于区块链的联邦遗忘（BlockFUL），使用Chameleon Hash（CH）技术重新设计区块链结构，减少模型更新的复杂性和成本。 |
| [^36] | [PerLTQA: A Personal Long-Term Memory Dataset for Memory Classification, Retrieval, and Synthesis in Question Answering](https://arxiv.org/abs/2402.16288) | PerLTQA是一个结合了语义和情节记忆的创新QA数据集，旨在探索个性化记忆在QA任务中的应用，提供了一个全面的基准和记忆整合、检索、合成的框架 |
| [^37] | [Towards Agile Robots: Intuitive Robot Position Speculation with Neural Networks](https://arxiv.org/abs/2402.16281) | 本文提出了一种机器人位置推测网络(RPSN)，通过将可微分的逆运动学算法和神经网络结合，能够高成功率地推测移动操作器械的位置。 |
| [^38] | [A Self-matching Training Method with Annotation Embedding Models for Ontology Subsumption Prediction](https://arxiv.org/abs/2402.16278) | 提出了一种自匹配训练方法，通过两种本体嵌入模型捕获全局和局部信息，提高了概念子类预测的稳健性 |
| [^39] | [From Large Language Models and Optimization to Decision Optimization CoPilot: A Research Manifesto](https://arxiv.org/abs/2402.16269) | 运用大型语言模型与优化相结合，创建决策优化CoPilot（DOCP），帮助决策者通过自然语言交互理解并解决业务问题。 |
| [^40] | [Foundation Model Transparency Reports](https://arxiv.org/abs/2402.16268) | 提出了基础模型透明度报告，借鉴社交媒体的透明度报告实践，目的在于在基础模型行业尚未成熟时制定透明度报告。 |
| [^41] | [Watch Your Head: Assembling Projection Heads to Save the Reliability of Federated Models](https://arxiv.org/abs/2402.16255) | 联邦学习中发现当面对异构数据时，因存在有偏的投影头导致的联邦模型不可靠性，提出了“组装投影头”（APH）方法以提高模型可靠性。 |
| [^42] | [Topic-to-essay generation with knowledge-based content selection](https://arxiv.org/abs/2402.16248) | 该论文提出了一种基于知识内容选择的复制机制模型，通过整合丰富的语义知识和改进的前缀调整方法，使主题到文章生成任务中的文本生成多样性提高，并贡献了新的中文数据集。 |
| [^43] | [HSONet:A Siamese foreground association-driven hard case sample optimization network for high-resolution remote sensing image change detection](https://arxiv.org/abs/2402.16242) | 提出了一个面向高分辨率遥感图像变化检测的孪生前景关联驱动困难样本优化网络，解决了变化检测模型学习困难案例时面临的不平衡和缺失性挑战 |
| [^44] | [Active Level Set Estimation for Continuous Search Space with Theoretical Guarantee](https://arxiv.org/abs/2402.16237) | 提出了一种不需要任何离散化直接在连续搜索空间中工作的具有理论保证的活跃水平集估计算法 |
| [^45] | [Human-AI Co-Creation of Worked Examples for Programming Classes](https://arxiv.org/abs/2402.16235) | 人工智能与人类合作创作Java编程课程的示例，以减轻教师逐行解释大量示例的负担 |
| [^46] | [GARNN: An Interpretable Graph Attentive Recurrent Neural Network for Predicting Blood Glucose Levels via Multivariate Time Series](https://arxiv.org/abs/2402.16230) | 提出了一种可解释的图注意力循环神经网络（GARNNs），用于通过多元时间序列预测血糖水平，并实现了更具解释性的变量贡献总结和特征图生成。 |
| [^47] | [IR2: Information Regularization for Information Retrieval](https://arxiv.org/abs/2402.16200) | 介绍了IR2，一种用于在合成数据生成过程中减少过拟合的信息正则化技术，在复杂查询的信息检索任务中表现出优越性能，同时将成本降低高达50%。 |
| [^48] | [One-stage Prompt-based Continual Learning](https://arxiv.org/abs/2402.16189) | 通过直接使用中间层的令牌嵌入作为提示查询，这项研究引入了一种单阶段PCL框架，可以在减少50%计算成本的同时，保持准确度下降小于1%。 |
| [^49] | [How Can LLM Guide RL? A Value-Based Approach](https://arxiv.org/abs/2402.16181) | 本文研究了如何利用大型语言模型（LLM）提供的策略先验来增强强化学习（RL）算法的样本效率。 |
| [^50] | [GenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstruction](https://arxiv.org/abs/2402.16174) | GenNBV提出了一种端到端的通用的下一最佳视角策略，通过采用强化学习框架和扩展到5D自由空间的动作空间，实现了无人机从任意视角进行扫描，甚至与未知几何体进行交互的能力，同时提出了多源状态嵌入以增强跨数据集的泛化能力。 |
| [^51] | [Communication Traffic Characteristics Reveal an IoT Devices Identity](https://arxiv.org/abs/2402.16173) | 通过通信流量特征识别物联网设备的机器学习模型对于网络安全至关重要。 |
| [^52] | [Hitting "Probe"rty with Non-Linearity, and More](https://arxiv.org/abs/2402.16168) | 使用非线性结构探针来探究编码信息的结构，并设计了简单有效的新方法，以及可视化框架来评估语言模型中的依存树结构。 |
| [^53] | [ChatMusician: Understanding and Generating Music Intrinsically with LLM](https://arxiv.org/abs/2402.16153) | ChatMusician 是一个集成了内在音乐能力的开源LLM，通过对文本兼容的音乐表示法进行持续预训练和微调，能够理解和生成音乐，表现优于GPT-4基准模型。 |
| [^54] | [From Text to Transformation: A Comprehensive Review of Large Language Models' Versatility](https://arxiv.org/abs/2402.16142) | 该研究探讨了大型语言模型在各领域的多功能性，提出了LLMs在健身、城市规划、气候建模和灾难响应等领域中的潜在影响和创新方法。 |
| [^55] | [What Generative Artificial Intelligence Means for Terminological Definitions](https://arxiv.org/abs/2402.16139) | 生成人工智能工具如ChatGPT在提供定制化的语境特定含义方面表现出色，但在准确性方面存在挑战，可以辅助术语学家进行术语编纂，实现AI效率与人类专业知识的结合。 |
| [^56] | [LSTPrompt: Large Language Models as Zero-Shot Time Series Forecasters by Long-Short-Term Prompting](https://arxiv.org/abs/2402.16132) | LSTPrompt提出了一种新颖的方法，将时间序列预测任务分解为短期和长期预测子任务，并为每个子任务量身定制提示，旨在提高大型语言模型在零shot时间序列预测中的适应性和性能。 |
| [^57] | [InstructEdit: Instruction-based Knowledge Editing for Large Language Models](https://arxiv.org/abs/2402.16123) | InstructEdit提出了一种基于指令的知识编辑技术，通过简单指令使编辑器适应不同任务的表现，显著提高了多任务编辑中的可靠性。 |
| [^58] | [Towards Accurate Post-training Quantization for Reparameterized Models](https://arxiv.org/abs/2402.16121) | 提出了一个新框架RepAPQ，利用平均绝对误差（MAE）来减轻异常值对量化参数的影响，从而保持量化后重新参数化模型的准确性 |
| [^59] | [RoboCodeX: Multimodal Code Generation for Robotic Behavior Synthesis](https://arxiv.org/abs/2402.16117) | 提出了一种用于泛化机器人行为合成的树状多模态代码生成框架，具有将高级人类指令转化为机器人动作的泛化能力。 |
| [^60] | [Bayesian Neural Network For Personalized Federated Learning Parameter Selection](https://arxiv.org/abs/2402.16091) | 通过引入贝叶斯神经网络，本研究提出在元素级别而非传统的层级上进行个性化，以选择个性化参数。 |
| [^61] | [Deep Homography Estimation for Visual Place Recognition](https://arxiv.org/abs/2402.16086) | 提出了一种基于Transformer的深度单应性估计网络，用于快速和可学习的几何验证。 |
| [^62] | [Behavioral Refinement via Interpolant-based Policy Diffusion](https://arxiv.org/abs/2402.16075) | 使用比高斯更具信息量的源头启动扩散方法有助于克服模仿学习任务中的限制。 |
| [^63] | [Pfeed: Generating near real-time personalized feeds using precomputed embedding similarities](https://arxiv.org/abs/2402.16073) | 使用预计算的嵌入相似性生成个性化信息流，提高了电子商务平台上的客户参与度和体验，转化率提升4.9％。 |
| [^64] | [ROS-Causal: A ROS-based Causal Analysis Framework for Human-Robot Interaction Applications](https://arxiv.org/abs/2402.16068) | ROS-Causal是一个基于ROS的框架，用于在人机空间交互中进行数据收集和因果发现，解决了机器人领域中缺乏因果发现方法在ROS生态系统内实现的问题。 |
| [^65] | [Citation-Enhanced Generation for LLM-based Chatbot](https://arxiv.org/abs/2402.16063) | 提出一种基于引文增强的LLM聊天机器人生成方法，采用检索模块搜索支持文档来解决幻觉内容产生的问题。 |
| [^66] | [Maximizing UAV Fog Deployment Efficiency for Critical Rescue Operations](https://arxiv.org/abs/2402.16052) | 提出了一个围绕动态无人机雾部署的新模型，以优化系统在受灾地区的适应性和运营效率 |
| [^67] | [LLMs with Chain-of-Thought Are Non-Causal Reasoners](https://arxiv.org/abs/2402.16048) | 本文探讨了大型语言模型在推理过程中思维链条（CoT）的作用，发现LLMs在答案生成过程中与人类推理存在差异，相关因素包括语境学习、有监督微调以及对人类反馈的强化学习。 |
| [^68] | [Deep Learning Approaches for Improving Question Answering Systems in Hepatocellular Carcinoma Research](https://arxiv.org/abs/2402.16038) | 深度学习技术在问答系统领域取得的成就，尤其是在肝细胞癌研究中，极大地推动了自然语言处理的发展。 |
| [^69] | [Text Understanding and Generation Using Transformer Models for Intelligent E-commerce Recommendations](https://arxiv.org/abs/2402.16035) | 本文回顾了Transformer预训练模型在电子商务领域的核心应用，包括文本理解和生成推荐系统等方面，在自动生成产品描述、情感分析、个性化推荐系统构建和客服对话自动处理等方面均取得了积极效果。 |
| [^70] | [Emotion Classification in Short English Texts using Deep Learning Techniques](https://arxiv.org/abs/2402.16034) | 该研究使用深度学习技术在短英文文本中识别情绪，发现基于迁移学习和BERT的文本嵌入方法在分类准确性上表现优异。 |
| [^71] | [Don't Forget Your Reward Values: Language Model Alignment via Value-based Calibration](https://arxiv.org/abs/2402.16030) | 本文提出了一种基于价值的校准（VCB）方法，以解决大型语言模型与人类偏好之间的对齐问题，并在实验中表现出比现有方法更好的通用性、稳健性和稳定性。 |
| [^72] | [TMT: Tri-Modal Translation between Speech, Image, and Text by Processing Different Modalities as Different Languages](https://arxiv.org/abs/2402.16021) | 将不同模态解释为不同语言，在语音、图像和文本之间实现了三模翻译，大大减少了计算成本。 |
| [^73] | [Building Flexible Machine Learning Models for Scientific Computing at Scale](https://arxiv.org/abs/2402.16014) | OmniArch通过多物理学时空数据处理、可扩展的自回归任务和物理信息增强学习技术，在科学计算领域构建灵活的基础模型，并在性能、适应性和逆问题求解方面取得突破，展现了AI对科学计算的潜力。 |
| [^74] | [Post-Quantum Cryptography Neural Network](https://arxiv.org/abs/2402.16002) | 提出了一种将基于编码的后量子密码方法映射到神经网络结构的PQC方法，通过非线性激活函数、随机扰动的密文和密文的均匀分布增强密文安全性。 |
| [^75] | [An Empirical Study of Challenges in Machine Learning Asset Management](https://arxiv.org/abs/2402.15990) | 通过分析开发者论坛和平台上的帖子，研究揭示了与机器学习资产管理挑战相关的133个主题，其中最重要的包括软件依赖、模型部署和模型训练。 |
| [^76] | [PIDformer: Transformer Meets Control Theory](https://arxiv.org/abs/2402.15989) | 该论文将Proportional-Integral-Derivative（PID）闭环反馈控制系统集成到Transformer模型中，以改善鲁棒性和表示容量，提高了模型稳定性和抗噪性，解决了输出表示中的秩坍缩问题。 |
| [^77] | [Likelihood-based Mitigation of Evaluation Bias in Large Language Models](https://arxiv.org/abs/2402.15987) | 该论文研究了基于大型语言模型（LLM）的评估器中的似然偏差，并提出了一种缓解这种偏差的方法。 |
| [^78] | [CoDream: Exchanging dreams instead of models for federated aggregation with heterogeneous models](https://arxiv.org/abs/2402.15968) | CoDream提出了一种通过在输入数据空间中协作优化数据来交换知识的框架，实现了模型之间的合作学习，实现了模型架构无关、通信不受模型大小影响、兼容安全聚合的优点。 |
| [^79] | [Budget-Constrained Tool Learning with Planning](https://arxiv.org/abs/2402.15960) | 本文提出了一种新颖的具有预算约束的工具学习方法，通过创建优先计划和动态规划制定计划来解决用户查询问题，为大型语言模型的工具学习过程提供了全面的概述。 |
| [^80] | [Attention-GAN for Anomaly Detection: A Cutting-Edge Approach to Cybersecurity Threat Management](https://arxiv.org/abs/2402.15945) | 该研究提出了一种基于注意力机制的 GAN 框架，用于增强网络安全性，重点关注异常检测，通过生成多样且逼真的合成攻击场景来改进威胁识别和解决数据稀缺性问题。 |
| [^81] | [Rethinking Software Engineering in the Era of Foundation Models: A Curated Catalogue of Challenges in the Development of Trustworthy FMware](https://arxiv.org/abs/2402.15943) | FMware的独特属性和基础模型的内在限制导致了新的软件工程挑战，本文总结了这些挑战并提出了创新路径。 |
| [^82] | [Generalization or Memorization: Data Contamination and Trustworthy Evaluation for Large Language Models](https://arxiv.org/abs/2402.15938) | 本文提出了一种通过LLMs输出分布进行污染检测的方法CDD，以及一种基于LLMs输出修正的可信评估方法TED，以应对大语言模型在数据污染和可信评估方面面临的挑战。 |
| [^83] | [Bridging the Gap between 2D and 3D Visual Question Answering: A Fusion Approach for 3D VQA](https://arxiv.org/abs/2402.15933) | 通过问题条件的2D视图选择过程和双分支Transformer结构，将2D知识整合到3D-VQA系统中，从而弥补了当前方法在3D视觉问答中遇到的挑战。 |
| [^84] | [QuaCer-C: Quantitative Certification of Knowledge Comprehension in LLMs](https://arxiv.org/abs/2402.15929) | 本文提出了一种新颖的认证框架QuaCer-C，用于正式认证大型语言模型中知识理解的能力，证书定量化且包含高置信度的概率界限，研究发现，随着参数数量的增加，知识理解能力提高，Mistral模型在这一评估中表现不如其他模型。 |
| [^85] | [MultiContrievers: Analysis of Dense Retrieval Representations](https://arxiv.org/abs/2402.15925) | 该论文对稠密检索器的信息捕获进行了分析，探讨了其与语言模型的比较、信息提取的可行性以及提取性与性能、性别偏见的关系。 |
| [^86] | [Predicting Outcomes in Video Games with Long Short Term Memory Networks](https://arxiv.org/abs/2402.15923) | 使用长短期记忆网络在实时分析中预测电子竞技比赛结果，仅利用玩家生命值指标作为时间序列，较之传统方法和Transformer模型，取得了更高效的预测性能。 |
| [^87] | [Explainable Contrastive and Cost-Sensitive Learning for Cervical Cancer Classification](https://arxiv.org/abs/2402.15905) | 本文提出了一个高效的宫颈癌细胞分类系统，通过使用预训练的CNNs进行微调并结合监督对比学习，最小化误分类成本，达到了97.29%的准确率，并引入了可解释的人工智能技术来解释模型的决策过程。 |
| [^88] | [ESFL: Efficient Split Federated Learning over Resource-Constrained Heterogeneous Wireless Devices](https://arxiv.org/abs/2402.15903) | 该论文提出了一种高效的分裂联邦学习算法（ESFL），能够充分利用中央服务器和端设备的计算资源，通过将模型分为不同的子模型并考虑用户的异质性，共同优化用户端工作量和服务器端计算资源分配。 |
| [^89] | [Information-based Transductive Active Learning](https://arxiv.org/abs/2402.15898) | ITL是一种基于信息的转导式学习方法，可以在现实世界设置中自适应采样，以最大化关于指定预测目标的信息获取，并在少样本微调和安全贝叶斯优化应用中显著优于最先进技术。 |
| [^90] | [Statistical Games](https://arxiv.org/abs/2402.15892) | 本研究将Bayesian统计嵌入到更广泛的决策框架中，提出了统计游戏作为统一框架，涵盖了频率派和贝叶斯统计，并提出了最小后悔准则作为决策的一般方法。 |
| [^91] | [Multiple Instance Learning for Glioma Diagnosis using Hematoxylin and Eosin Whole Slide Images: An Indian cohort Study](https://arxiv.org/abs/2402.15832) | 本研究通过多实例学习在脑肿瘤组织病理学中取得新突破，建立了印度胶质瘤亚型分类性能基准，同时实现了新的评级和检测生物标志物的基准。 |
| [^92] | [Reward Design for Justifiable Sequential Decision-Making](https://arxiv.org/abs/2402.15826) | 代理通过辩论型奖励模型学习可辩明策略，以支持证据证明决策的合理性。 |
| [^93] | [Cooperation and Control in Delegation Games](https://arxiv.org/abs/2402.15821) | 本文在委托游戏中探讨了控制问题（代理人未能按照其委托人的偏好行事）和合作问题（代理人未能良好地协作），并分析了对齐和能力对委托人福利的影响。en_tdlr: This paper explores the issues of control (agents failing to act in line with their principals' preferences) and cooperation (agents failing to work well together) in delegation games, analyzing how alignment and capabilities impact principals' welfare. |
| [^94] | [DART: Depth-Enhanced Accurate and Real-Time Background Matting](https://arxiv.org/abs/2402.15820) | 通过整合深度信息和贝叶斯推断，该论文提出了一种名为DART的方案，以提高背景抠图的实时性和精确性。 |
| [^95] | [Empowering Large Language Model Agents through Action Learning](https://arxiv.org/abs/2402.15809) | 学习新动作的能力对于大型语言模型代理的学习进步至关重要，本研究提出了开放式行为学习框架，通过迭代学习策略改进动作，增强代理的学习效果。 |
| [^96] | [Optimal Zero-Shot Detector for Multi-Armed Attacks](https://arxiv.org/abs/2402.15808) | 本文提出了一种创新的信息论防御方法，通过最优地汇总现有探测器做出的决策，消除了对训练数据的需求。 |
| [^97] | [Construction and application of artificial intelligence crowdsourcing map based on multi-track GPS data](https://arxiv.org/abs/2402.15796) | 研究人员提出了一种快速有效的算法，从大量低精度GPS轨迹数据融合生成高精度GPS数据，实现了基于社交车辆的地图数据收集的“众包更新”模型，对提高数据准确性具有重要意义。 |
| [^98] | [Cryptanalysis and improvement of multimodal data encryption by machine-learning-based system](https://arxiv.org/abs/2402.15779) | 该论文使用机器学习系统对多模态数据加密进行破解和改进，并通过复杂的数学问题极大地加密通信机制，保护个人信息并减少攻击可能性。 |
| [^99] | [From COBIT to ISO 42001: Evaluating Cybersecurity Frameworks for Opportunities, Risks, and Regulatory Compliance in Commercializing Large Language Models](https://arxiv.org/abs/2402.15770) | 该研究评估了四种网络安全框架在商业化大型语言模型（LLMs）中的机遇、风险和合规性，发现新的ISO 42001:2023对LLMs的机遇提供了最全面的支持，COBIT 2019与欧盟AI法案最为接近。 |
| [^100] | [Importance Guided Data Augmentation for Neural-Based Code Understanding](https://arxiv.org/abs/2402.15769) | 引入了一个通用数据增强框架GenCode，通过重要性指标选择生成的代码作为训练数据，以增强代码理解模型的训练。 |
| [^101] | [PhyPlan: Compositional and Adaptive Physical Task Reasoning with Physics-Informed Skill Networks for Robot Manipulators](https://arxiv.org/abs/2402.15767) | PhyPlan是一种结合了物理信息网络（PINNs）和改进的蒙特卡洛树搜索（MCTS）的规划框架，用于使具有身体的代理能够执行动态物理任务，并可以动态决定在模拟器和实际环境之间进行最优策略的选择。 |
| [^102] | [Look Before You Leap: Problem Elaboration Prompting Improves Mathematical Reasoning in Large Language Models](https://arxiv.org/abs/2402.15764) | PEP提出了一个新方法来改善LLMs的数学能力，通过在推理之前细化和阐明问题背景，提升全局上下文建模能力，减少解析困难。 |
| [^103] | [Res-VMamba: Fine-Grained Food Category Visual Classification Using Selective State Space Models with Deep Residual Learning](https://arxiv.org/abs/2402.15761) | Res-VMamba利用具有选择性状态空间模型和深度残差学习，提供了比Transformer结构更出色的性能和计算效率，是食品细粒度分类中的最新技术。 |
| [^104] | [Increasing SAM Zero-Shot Performance on Multimodal Medical Images Using GPT-4 Generated Descriptive Prompts Without Human Annotation](https://arxiv.org/abs/2402.15759) | 使用GPT-4生成描述性提示，提高了多模态医学图像上的SAM零样本分割性能，无需人工标注。 |
| [^105] | [Chimera: A Lossless Decoding Method for Accelerating Large Language Models Inference by Fusing all Tokens](https://arxiv.org/abs/2402.15758) | 提出了Chimera框架，用于加速大型语言模型推理，通过引入轻量级的草稿模型和两种策略，利用先前生成的令牌来预测后续单词，以解决解码过程中的准确性和效率问题 |
| [^106] | [Batch Active Learning of Reward Functions from Human Preferences](https://arxiv.org/abs/2402.15757) | 本文提出了一种批量主动基于偏好的学习方法，通过少量数据样本有效学习奖励函数，同时保持查询生成时间短并可并行化。 |
| [^107] | [Sparse MeZO: Less Parameters for Better Performance in Zeroth-Order LLM Fine-Tuning](https://arxiv.org/abs/2402.15751) | 提出了一种稀疏MeZO方法，通过仅对精心选择的参数子集应用零阶优化，实现了在零阶LLM微调中减少参数以获得更好性能的目标 |
| [^108] | [Intelligent Director: An Automatic Framework for Dynamic Visual Composition using ChatGPT](https://arxiv.org/abs/2402.15746) | 提出了智能导演框架，结合LENS对图像和视频帧生成描述，再利用ChatGPT生成连贯字幕和推荐音乐名称，通过音乐检索获得最佳匹配音乐，最终整合各种素材实现故事性视频的自动生成。 |
| [^109] | [GAOKAO-MM: A Chinese Human-Level Benchmark for Multimodal Models Evaluation](https://arxiv.org/abs/2402.15745) | GAOKAO-MM 是基于中国高考的多模态基准，为模型的能力设定人类水平要求，评估结果显示目前的LVLMs的准确率普遍不足50%。 |
| [^110] | [How Do Humans Write Code? Large Models Do It the Same Way Too](https://arxiv.org/abs/2402.15729) | 大型语言模型在执行数值计算时经常出错，通过生成可执行代码来解决问题可以减少计算错误，但观察到当大型语言模型使用代码解决数学问题时，会生成更多不正确推理；为解决这一问题，提出了一种受人类编码实践启发的简单而高效方法Human-Think Language（HTL）。 |
| [^111] | [LLMs Can Defend Themselves Against Jailbreaking in a Practical Manner: A Vision Paper](https://arxiv.org/abs/2402.15727) | 本文提出了一种名为SELFDEFEND的轻量级实用防御方法，可以在最小延迟下抵御所有现有的越狱攻击。 |
| [^112] | [Hal-Eval: A Universal and Fine-grained Hallucination Evaluation Framework for Large Vision Language Models](https://arxiv.org/abs/2402.15721) | 本论文提出了Hal-Eval，一个通用和细粒度的幻觉评估框架，引入了新的幻觉分类法，专注于事件幻觉，通过生成和过滤细粒度幻觉数据来评估大型视觉语言模型对各种幻觉的处理能力。 |
| [^113] | [Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors](https://arxiv.org/abs/2402.15713) | 提出了一种对比提示学习框架，利用预训练语言模型的潜在能力解决灾难性遗忘和过拟合问题，使其成为更好的连续少样本关系提取器 |
| [^114] | [Query Augmentation by Decoding Semantics from Brain Signals](https://arxiv.org/abs/2402.15708) | 提出了一种名为Brain-Aug的方法，通过从脑信号中解码的语义信息增强查询，可以生成更准确的查询，改善文档排序性能，特别适用于模糊查询。 |
| [^115] | [Is Offline Decision Making Possible with Only Few Samples? Reliable Decisions in Data-Starved Bandits via Trust Region Enhancement](https://arxiv.org/abs/2402.15703) | 本文展示了即使在数据稀缺的情况下，仍然可能找到一个与最优策略竞争的随机策略，为在仅有少量样本下进行可靠决策铺平了道路。 |
| [^116] | [CoRelation: Boosting Automatic ICD Coding Through Contextualized Code Relation Learning](https://arxiv.org/abs/2402.15700) | 通过上下文化的编码关系学习，提出了一种新的框架来增强ICD编码表示的学习，实验结果表明其相比最先进基线方法的有效性。 |
| [^117] | [Foot In The Door: Understanding Large Language Model Jailbreaking via Cognitive Psychology](https://arxiv.org/abs/2402.15690) | 该研究通过认知一致性理论为大型语言模型的越狱提示提供了心理解释，并提出了一种基于门脚-门技术的自动黑盒越狱方法。 |
| [^118] | [General Purpose Image Encoder DINOv2 for Medical Image Registration](https://arxiv.org/abs/2402.15687) | 提出了一种无需训练的可变形图像配准方法 DINO-Reg，利用通用图像编码器 DINOv2 进行图像特征提取，并通过实验证明其在图像配准应用中的有效性。 |
| [^119] | [A mathematical model for simultaneous personnel shift planning and unrelated parallel machine scheduling](https://arxiv.org/abs/2402.15670) | 一种针对生产调度问题的数学模型，同时考虑人员轮班规划和无关机器调度，并通过MILP模型最小化总生产时间。 |
| [^120] | [Universal Model in Online Customer Service](https://arxiv.org/abs/2402.15666) | 本文介绍了一种在电子商务中改进在线客户服务的解决方案，即提出了一种基于客户问题预测标签的通用模型，无需进行训练，通过消除个别模型训练和维护的需求，减少了模型开发周期和成本。 |
| [^121] | [Teacher-Student Learning on Complexity in Intelligent Routing](https://arxiv.org/abs/2402.15665) | 通过机器学习框架中的师生模型，成功预测客户联系的复杂性并将其引导到合适的代理商，提高了客户体验，并提出了复杂性AUC度量标准。 |
| [^122] | [GiMeFive: Towards Interpretable Facial Emotion Classification](https://arxiv.org/abs/2402.15662) | 提出了一种名为GiMeFive的面部情绪分类模型，通过层激活和梯度加权类激活映射进行解释，实验结果显示在准确性上优于先前方法，并在真实图像和视频示例以及实时摄像头流上进行了解释。 |
| [^123] | [Learning Semilinear Neural Operators : A Unified Recursive Framework For Prediction And Data Assimilation](https://arxiv.org/abs/2402.15656) | 提出了一种学习半线性神经算子的方法，通过结合预测和校正操作实现了对长时间尺度上时空PDE的解进行处理与数据同化。 |
| [^124] | [Contact Complexity in Customer Service](https://arxiv.org/abs/2402.15655) | 开发了一种新颖的机器学习方法来定义联系复杂性，通过训练AI专家模型来评估客户问题复杂性，避免了人工标注的时间和金钱成本。 |
| [^125] | [Multi-Constraint Safe RL with Objective Suppression for Safety-Critical Applications](https://arxiv.org/abs/2402.15650) | 提出了一种目标抑制的新方法，可以在多约束安全领域中改进安全强化学习任务表现，实验证明此方法结合现有算法能够在减少约束违规的情况下实现与基准线相当的任务奖励水平。 |
| [^126] | [Fine-Grained Self-Endorsement Improves Factuality and Reasoning](https://arxiv.org/abs/2402.15631) | 提出了利用自认证框架进行细粒度事实级别比较的方法，能够更好地减轻大型语言模型生成过程中的幻觉，尤其适用于长篇生成任务。 |
| [^127] | [Learning Cyclic Causal Models from Incomplete Data](https://arxiv.org/abs/2402.15625) | 提出了一个名为MissNODAGS的框架，可以从部分缺失数据中学习循环因果图，通过交替替补缺失数据和最大化可见数据部分的预期对数似然来学习因果图。 |
| [^128] | [RecWizard: A Toolkit for Conversational Recommendation with Modular, Portable Models and Interactive User Interface](https://arxiv.org/abs/2402.15591) | RecWizard是一种对话式推荐工具包，具有模块化、便携模型和交互用户界面，可提高CRS研究效率并减少额外工作量 |
| [^129] | [Prompting LLMs to Compose Meta-Review Drafts from Peer-Review Narratives of Scholarly Manuscripts](https://arxiv.org/abs/2402.15589) | 本文研究了使用不同类型/级别的提示来激发三种流行LLM，GPT-3.5、LLaMA2和PaLM2，在学术同行评审过程中自动生成元评论，并进行了详细的定性研究。 |
| [^130] | [Improving Explainable Object-induced Model through Uncertainty for Automated Vehicles](https://arxiv.org/abs/2402.15572) | 本研究通过将不确定性评估整合到决策过程中，基于“物体诱导”模型方法并利用先进训练策略，改进了可解释的AV模型，在复杂驾驶场景中提供更清晰的决策理解 |
| [^131] | [Fast Adversarial Attacks on Language Models In One GPU Minute](https://arxiv.org/abs/2402.15570) | 介绍了一种新型的基于束搜索的快速对抗攻击方法BEAST，能够在一分钟内高成功率地越狱对齐的语言模型，同时还能导致语言模型产生幻觉。 |
| [^132] | [Foundation Policies with Hilbert Representations](https://arxiv.org/abs/2402.15567) | 该研究提出了一个新颖的无监督框架，用于从未标记的离线数据中预训练通用政策，以捕获多样化、最优、长时域行为。 |
| [^133] | [Deep Networks Always Grok and Here is Why](https://arxiv.org/abs/2402.15555) | 深度神经网络存在延迟泛化和延迟鲁棒性现象，在各种实际环境中普遍存在，并基于新的局部复杂度度量提供了解释。 |
| [^134] | [Morphological Symmetries in Robotics](https://arxiv.org/abs/2402.15552) | 形态对称性是机器人系统中的固有性质，通过对运动结构和质量的对称分布，延伸至机器人状态空间和传感器测量，进而影响机器人的运动方程和最优控制策略，并在机器人学建模、控制和设计中具有重要意义。 |
| [^135] | [HiMAP: Learning Heuristics-Informed Policies for Large-Scale Multi-Agent Pathfinding](https://arxiv.org/abs/2402.15546) | HiMAP 是一种新颖的可伸缩方法，使用启发式引导的模仿学习在分散式训练中对用户智体路径规划进行了改进 |
| [^136] | [AgentLite: A Lightweight Library for Building and Advancing Task-Oriented LLM Agent System](https://arxiv.org/abs/2402.15538) | AgentLite是一个用于简化构建LLM代理推理和架构的轻量级库。 |
| [^137] | [Evaluating the Performance of ChatGPT for Spam Email Detection](https://arxiv.org/abs/2402.15537) | 该研究评估了ChatGPT在英文和中文电子邮件数据集中用于垃圾邮件检测的性能，并探讨了其在这一领域的潜力。 |
| [^138] | [PCA-Bench: Evaluating Multimodal Large Language Models in Perception-Cognition-Action Chain](https://arxiv.org/abs/2402.15527) | PCA-Bench 提出了一个评估多模大型语言模型综合能力的基准，引入复杂场景和错误定位能力，提高部署可靠性，并提出了自动评估协议 PCA-Eval，发现了显著的性能差异。 |
| [^139] | [Chain-of-Specificity: An Iteratively Refining Method for Eliciting Knowledge from Large Language Models](https://arxiv.org/abs/2402.15526) | Chain-of-Specificity (CoS)是一种从大型语言模型中提取知识的逐步精化方法，能够在输入指令中迭代强调特定约束，解锁知识并改进回应。 |
| [^140] | [Graph Pruning for Enumeration of Minimal Unsatisfiable Subsets](https://arxiv.org/abs/2402.15524) | 提出了一种图剪枝算法，通过基于图的学习模型预测修剪公式的部分，加速枚举最小不可满足子集，无需数据标记，也无需来自目标应用的训练数据，实验结果表明在各种基准测试中的有效性。 |
| [^141] | [IntSat: Integer Linear Programming by Conflict-Driven Constraint-Learning](https://arxiv.org/abs/2402.15522) | 把冲突驱动子句学习扩展到整数线性规划，有效实现并讨论改进，成为ILP求解领域有用的补充。 |
| [^142] | [HKD-SHO: A hybrid smart home system based on knowledge-based and data-driven services](https://arxiv.org/abs/2402.15521) | 提出了一个名为HKD-SHO的混合智能家居系统，将基于知识和基于机器学习的数据驱动服务有益地融合在一起，解决了智能家居系统中基于知识和数据驱动方法的问题。 |
| [^143] | [Feasibility of Identifying Factors Related to Alzheimer's Disease and Related Dementia in Real-World Data](https://arxiv.org/abs/2402.15515) | 通过研究现有文献，总结了阿尔茨海默病和相关痴呆症的风险因素，构建了知识图谱，并指出基因组风险因素的评估仍然是一个挑战。 |
| [^144] | [Large Scale Generative AI Text Applied to Sports and Music](https://arxiv.org/abs/2402.15514) | 这项工作利用生成式人工智能模型将大规模多模数据转化为连贯流畅文本，首次推出了用于体育和音乐领域的AI评论系统，并取得了显著性能提升。 |
| [^145] | [AgentOhana: Design Unified Data and Training Pipeline for Effective Agent Learning](https://arxiv.org/abs/2402.15506) | AgentOhana提供了一种统一数据和训练流水线的综合解决方案，有助于克服使用大型语言模型（LLMs）进行智能体任务时的挑战。 |
| [^146] | [ArabianGPT: Native Arabic GPT-based Large Language](https://arxiv.org/abs/2402.15313) | 提出了ArabianGPT，这是一系列专门为阿拉伯语设计的基于Transformer的模型，包括大小和复杂性不同的ArabianGPT-0.1B和ArabianGPT-0.3B，帮助弥补了本土阿拉伯语大型语言模型的不足。 |
| [^147] | [Calibration of Deep Learning Classification Models in fNIRS](https://arxiv.org/abs/2402.15266) | 在fNIRS领域，我们提出将校准整合到模型中以评估其可靠性，结果显示许多现有模型的校准性能不佳。 |
| [^148] | [LLMBind: A Unified Modality-Task Integration Framework](https://arxiv.org/abs/2402.14891) | 提出了LLMBind，一种统一的模态任务集成框架，通过将大型语言模型和预训练任务模型绑定在一起，实现了多种模态任务的灵活输入和输出组合。 |
| [^149] | [Vygotsky Distance: Measure for Benchmark Task Similarity](https://arxiv.org/abs/2402.14890) | 论文提出了一种基于相对性能而非任务属性的相似性度量方法，即“维果茨基距离”，可帮助减少评估任务数量并保持高验证质量。 |
| [^150] | [Technical Report on the Checkfor.ai AI-Generated Text Classifier](https://arxiv.org/abs/2402.14873) | Checkfor.ai AI生成文本分类器在区分大型语言模型生成文本和人类编写文本方面表现优异，提出了硬负挖掘与合成镜像训练算法，具有高准确性和泛化能力。 |
| [^151] | [A Decision-Language Model (DLM) for Dynamic Restless Multi-Armed Bandit Tasks in Public Health](https://arxiv.org/abs/2402.14807) | 提出了一种决策语言模型DLM，旨在通过使用LLMs作为自动规划器，动态微调RMAB策略，以应对公共卫生中具有挑战性的情境。 |
| [^152] | [Federated Complex Qeury Answering](https://arxiv.org/abs/2402.14609) | 研究了在多源知识图谱上回答复杂查询的联邦式方法，解决了知识图谱中的隐私保护和答案检索的挑战 |
| [^153] | [Uncertainty-Aware Evaluation for Vision-Language Models](https://arxiv.org/abs/2402.14418) | 提出了一个新的基准来评估视觉语言模型，该基准将不确定性量化融入评估过程中，揭示了准确性最高的模型可能也具有最高不确定性的重要性。 |
| [^154] | [On the Tip of the Tongue: Analyzing Conceptual Representation in Large Language Models with Reverse-Dictionary Probe](https://arxiv.org/abs/2402.14404) | 该论文通过重新利用反向词典任务的案例研究，探查了大型语言模型对概念推理的能力，发现模型在该任务中表现出高准确性，并且表示空间编码了有关对象类别和细粒度特征的信息，同时还发现该任务探查的概念推理能力能够预测模型在多个基准测试中的一般推理表现。 |
| [^155] | [Blending Data-Driven Priors in Dynamic Games](https://arxiv.org/abs/2402.14174) | 探索一种在动态游戏中将数据驱动参考政策与基于优化博弈政策相融合的方法，提出了一种非合作动态博弈KLGame，其中包含了针对每个决策者的可调参数。 |
| [^156] | [SDXL-Lightning: Progressive Adversarial Diffusion Distillation](https://arxiv.org/abs/2402.13929) | 提出了一种结合渐进和对抗性蒸馏的扩散蒸馏方法，在文本到图像生成任务中取得了新的最先进结果，并开源了相应模型。 |
| [^157] | [Kuaiji: the First Chinese Accounting Large Language Model](https://arxiv.org/abs/2402.13866) | Kuaiji是第一个中国会计大型语言模型，通过Baichuan框架精心调整，支持的CAtAcctQA数据集，展现出卓越的准确性和响应速度，具有开创性地创建了中国会计数据集，并证实了在真实会计场景中的高效性。 |
| [^158] | [Deep Generative Models for Offline Policy Learning: Tutorial, Survey, and Perspectives on Future Directions](https://arxiv.org/abs/2402.13777) | 深度生成模型在离线策略学习中展现了巨大潜力，本文提供了首个系统性综述，涵盖了五种主流深度生成模型及其应用。 |
| [^159] | [From Cloud to Edge: Rethinking Generative AI for Low-Resource Design Challenges](https://arxiv.org/abs/2402.12702) | 论文探讨了将生成人工智能调整以适应边缘资源受限环境的潜力、挑战和创新方法，以在低资源环境中高效创建设计解决方案。 |
| [^160] | [HyperMoE: Towards Better Mixture of Experts via Transferring Among Experts](https://arxiv.org/abs/2402.12656) | HyperMoE通过Hypernetworks框架整合知识传递的概念，解决了在专家选择过程中专家知识稀疏性和可用性之间的矛盾。 |
| [^161] | [AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling](https://arxiv.org/abs/2402.12226) | AnyGPT是一个统一的多模态语言模型，通过离散表示实现各种模态的统一处理，能够在不改变大型语言模型架构或训练方式的情况下稳定训练，为新模态的无缝整合提供了可能。 |
| [^162] | [Mafin: Enhancing Black-Box Embeddings with Model Augmented Fine-tuning](https://arxiv.org/abs/2402.12177) | Mafin通过引入模型增强微调的方法，能够在只有黑盒嵌入可用的情况下显著提高性能。 |
| [^163] | [Defending Against Weight-Poisoning Backdoor Attacks for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2402.12168) | PEFT相对于全参数微调更容易受到权重投毒后门攻击的影响，提出了一个通过置信度识别受污染样本的毒化样本识别模块（PSIM），为权重投毒后门攻击提供稳健防御 |
| [^164] | [From Reals to Logic and Back: Inventing Symbolic Vocabularies, Actions and Models for Planning from Raw Data](https://arxiv.org/abs/2402.11871) | 本文提出了一种从未标记高维实值机器人轨迹开始自主学习通用的逻辑相关表示，这些表示构成了自动发明的PDDL-like域模型。 |
| [^165] | [Generative Kaleidoscopic Networks](https://arxiv.org/abs/2402.11793) | 发现深层ReLU网络表现出过度泛化现象，利用这一特性设计了“生成万花筒网络”，通过递归映射随机输入噪声生成样本。 |
| [^166] | [SDiT: Spiking Diffusion Model with Transformer](https://arxiv.org/abs/2402.11588) | 本文提出了一种新颖的脉冲扩散模型架构，通过在脉冲神经网络中利用Transformer取代U-net结构，在图像生成任务中取得了较高质量的图像，并提供了基于SNN的生成模型研究的实证基准。 |
| [^167] | [Robust agents learn causal world models](https://arxiv.org/abs/2402.10877) | 智能体必须学习因果模型才能在广泛的分布转变下达到后悔界限，这对迁移学习和因果推断等研究领域有重要影响。 |
| [^168] | [On the Safety Concerns of Deploying LLMs/VLMs in Robotics: Highlighting the Risks and Vulnerabilities](https://arxiv.org/abs/2402.10340) | 论文突出探讨了在机器人应用中整合大型语言模型和视觉语言模型所带来的安全性和健壮性关键问题，指出这种整合可能容易受到恶意攻击并导致严重后果。 |
| [^169] | [Rewards-in-Context: Multi-objective Alignment of Foundation Models with Dynamic Preference Adjustment](https://arxiv.org/abs/2402.10207) | 本文介绍了Rewards-in-Context（RiC）方法，该方法通过多个奖励条件控制基础模型的响应，并应用有监督的微调进行对齐。它具有简单性和适应性，并支持在推理时动态调整用户偏好。 |
| [^170] | [MM-Point: Multi-View Information-Enhanced Multi-Modal Self-Supervised 3D Point Cloud Understanding](https://arxiv.org/abs/2402.10002) | 本文提出了一种新颖的自监督点云表示学习方法MM-Point，通过多模态交互和传输实现了3D物体和多个2D视图之间的信息增强。通过精心设计的实验，证明了MM-Point的有效性和优越性。 |
| [^171] | [Optimistic Thompson Sampling for No-Regret Learning in Unknown Games](https://arxiv.org/abs/2402.09456) | 该论文提出了一种在未知博弈中进行无遗憾学习的乐观的汤普森抽样方法，通过利用对手的行动和奖励结构信息，显著减少了实验预算，成功地缓解了多机构问题。此外，研究还引入了乐观-无遗憾框架，将现有算法与提出的方法相结合。 |
| [^172] | [Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey](https://arxiv.org/abs/2402.09283) | 这篇调查提供了LLM对话安全性的全面概述，涵盖了攻击、防御和评估三个关键方面，旨在提高对该主题的理解并促进进一步的研究。 |
| [^173] | [SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware Decoding](https://arxiv.org/abs/2402.08983) | 本文提出了一种名为SafeDecoding的解决方案，通过安全感知解码策略来防御大型语言模型（LLMs）的越狱攻击。该策略可以生成对用户查询有益且无害的响应，有效缓解了LLMs安全性威胁。 |
| [^174] | [FESS Loss: Feature-Enhanced Spatial Segmentation Loss for Optimizing Medical Image Analysis](https://arxiv.org/abs/2402.08582) | 本论文提出了一种名为FESS Loss的增强特征空间分割损失，将对比学习和Dice损失相结合，旨在在医学图像分割中提高空间精度和特征表示，从而实现更精确、更精细的分割过程。 |
| [^175] | [Policy Improvement using Language Feedback Models](https://arxiv.org/abs/2402.07876) | 本文介绍了一种使用语言反馈模型（LFMs）改进政策的方法，通过识别期望的行为并进行模仿学习，我们在任务完成率、泛化性能和人类可解释性方面取得了显著改进。 |
| [^176] | [Sequential Ordering in Textual Descriptions: Impact on Spatial Perception Abilities of Large Language Models](https://arxiv.org/abs/2402.07140) | 这项研究揭示了图描述的文本顺序对大语言模型在图推理中的性能产生显著影响，并通过改变文本顺序提高了大语言模型的性能。此外，发现大语言模型的推理性能与图大小之间的关系不是单调递减的。为了评估大语言模型在不同图大小上的性能，引入了规模化图推理基准。 |
| [^177] | [ClickSAM: Fine-tuning Segment Anything Model using click prompts for ultrasound image segmentation](https://arxiv.org/abs/2402.05902) | 本研究提出了ClickSAM，该方法使用点击提示对超声图像进行Segment Anything Model的精细调整，解决了超声图像分割中噪声干扰的问题。 |
| [^178] | [Investigating White-Box Attacks for On-Device Models](https://arxiv.org/abs/2402.05493) | 本研究探究了针对设备上模型的白盒攻击，提出了一种逆向工程框架(REOM)以将编译后的设备上TFLite模型转换为可调试模型。 |
| [^179] | [Knowledge Graphs Meet Multi-Modal Learning: A Comprehensive Survey](https://arxiv.org/abs/2402.05391) | 知识图谱与多模态学习的综述介绍了KG4MM和MM4KG两个主要方面，包括任务定义、构建进展、评估基准以及关键研究轨迹。 |
| [^180] | [Combining Cloud and Mobile Computing for Machine Learning](https://arxiv.org/abs/2402.04880) | 这项研究将模型分割为移动设备和云之间的计算，以减轻移动设备的负担，并优化云端的工作负载。 |
| [^181] | [RevOrder: A Novel Method for Enhanced Arithmetic in Language Models](https://arxiv.org/abs/2402.03822) | 本文提出了一种名为RevOrder的新方法，通过翻转加法、减法和nD乘以1D的输出数字，显著改善了语言模型中的算术运算。经过全面测试，RevOrder在基本算术运算中达到了完美准确度，并在除法任务中提升了语言模型性能，特别是在处理大数时。在GSM8K数学任务中应用RevOrder进行微调，有效降低了错误率并提高了总体得分。 |
| [^182] | [Exposing propaganda: an analysis of stylistic cues comparing human annotations and machine classification](https://arxiv.org/abs/2402.03780) | 本文通过分析文体线索比较人类注释和机器分类的方法，揭示了宣传语言的特征，并提出了一个多源、多语言、多模态的数据集PPN。结果表明，人类注释者能够可靠地区分宣传新闻和常规新闻。研究还比较了不同的自然语言处理技术，并提供了一些有关文体线索的发现。 |
| [^183] | [SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM](https://arxiv.org/abs/2402.03246) | SGS-SLAM是一种基于三维高斯点云的语义稠密SLAM系统，通过多通道优化和关键帧优化，实现了高质量的重建和精确的语义分割。 |
| [^184] | [Contextualization Distillation from Large Language Model for Knowledge Graph Completion](https://arxiv.org/abs/2402.01729) | 本论文介绍了一种从大型语言模型中提取上下文信息用于知识图谱补全的策略，该策略能克服现有语料库的限制，显著提高了预训练语言模型在知识图谱补全中的性能。 |
| [^185] | [Multi-scale Traffic Pattern Bank for Cross-city Few-shot Traffic Forecasting](https://arxiv.org/abs/2402.00397) | 我们提出了一种跨城市少样本交通预测的解决方案，利用多尺度交通模式库从数据丰富的源城市学习并预测其他城市的交通情况。 |
| [^186] | [CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs](https://arxiv.org/abs/2401.11314) | 通过开发CodeAid，一个基于LLM的编程助手，我们平衡了学生和教育者的需求，提供了有用的概念性回答而不暴露代码解决方案，在课堂环境中对其进行了评估和部署，并总结出四个未来教育AI助手的设计考虑。 |
| [^187] | [MapGPT: Map-Guided Prompting with Adaptive Path Planning for Vision-and-Language Navigation](https://arxiv.org/abs/2401.07314) | MapGPT引入了在线语言形成的地图，帮助GPT理解整体环境，提出自适应规划机制以协助代理执行多步路径规划。 |
| [^188] | [MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts](https://arxiv.org/abs/2401.04081) | 结合混合专家模型的MoE-Mamba在性能上优于Mamba和基准Transformer-MoE，达到了与Mamba相同性能的同时，训练步骤减少了2.35倍。 |
| [^189] | [AllSpark: A Multimodal Spatio-Temporal General Intelligence Model with Thirteen Modalities](https://arxiv.org/abs/2401.00546) | 提出了一个名为AllSpark的多模态时空智能通用人工智能模型，集成了十三种不同的模态，旨在解决多模态时空数据联合解释的挑战。 |
| [^190] | [Emergence and Causality in Complex Systems: A Survey on Causal Emergence and Related Quantitative Studies](https://arxiv.org/abs/2312.16815) | 本文综述了关于因果出现和相关定量研究的最新进展，重点解决了量化因果出现和在数据中识别因果出现的两个问题，并建立了因果出现与人工智能之间的联系。 |
| [^191] | [Learning to Embed Time Series Patches Independently](https://arxiv.org/abs/2312.16427) | 学习独立嵌入时间序列片段可以产生更好的时间序列表示，通过简单的块重构任务和独立嵌入每个块的MLP模型以及互补对比学习来实现。 |
| [^192] | [Soft Contrastive Learning for Time Series](https://arxiv.org/abs/2312.16424) | 提出了一种名为SoftCLT的方法，通过引入实例级和时间级软对比损失，解决了在时间序列中忽略固有相关性所导致的学习表示质量下降的问题。 |
| [^193] | [Efficient Title Reranker for Fast and Improved Knowledge-Intense NLP](https://arxiv.org/abs/2312.12430) | 引入了通过广播查询编码器实现的高效标题重新排序器和为标题重新排序定制的Sigmoid Trick损失函数，相结合在KILT知识基准测试的数据集上取得了最先进的结果。 |
| [^194] | [Mixed Distillation Helps Smaller Language Model Better Reasoning](https://arxiv.org/abs/2312.10730) | 混合蒸馏(MD)框架结合了LLMs中的Program of Thought (PoT)和Chain of Thought (CoT)能力，将多种提示技术蒸馏到较小模型中，显著增强了较小模型在各种任务中的推理能力。 |
| [^195] | [MaxK-GNN: Towards Theoretical Speed Limits for Accelerating Graph Neural Networks Training](https://arxiv.org/abs/2312.08656) | MaxK-GNN是一种先进的高性能GPU训练系统，通过MaxK非线性和理论分析，实现了图神经网络训练的垂直优化。 |
| [^196] | [How Well Does GPT-4V(ision) Adapt to Distribution Shifts? A Preliminary Investigation](https://arxiv.org/abs/2312.07424) | 该研究对GPT-4V(ision)在动态环境中的适应能力和泛化能力进行了评估，对比了其与CLIP、LLaVA和Gemini等知名模型。 |
| [^197] | [Learning Multi-graph Structure for Temporal Knowledge Graph Reasoning](https://arxiv.org/abs/2312.03004) | 提出了一种关注学习多图结构的创新推理方法，用于解决时间知识图推理中存在的历史依赖和未来趋势反映不充分的问题。 |
| [^198] | [xTrimoGene: An Efficient and Scalable Representation Learner for Single-Cell RNA-Seq Data](https://arxiv.org/abs/2311.15156) | xTrimoGene是一种针对scRNA-seq数据的新型非对称编码器-解码器Transformer，利用数据的稀疏特性降低了计算复杂度，使得在保持高准确性的同时能够训练最大的转移学习模型。 |
| [^199] | [Tube-NeRF: Efficient Imitation Learning of Visuomotor Policies from MPC using Tube-Guided Data Augmentation and NeRFs](https://arxiv.org/abs/2311.14153) | 结合IL和鲁棒MPC，设计了一种名为Tube-NeRF的数据增强方法，利用NeRFs生成合成图像，通过管的特性选择相关视图，高效计算对应的动作，从而实现了视觉导向策略的高效学习。 |
| [^200] | [Robot at the Mirror: Learning to Imitate via Associating Self-supervised Models](https://arxiv.org/abs/2311.13226) | 通过关联自监督模型构建模型，使机器人能够在镜子前学习自身的三维姿势检测，质量即刻完美。 |
| [^201] | [Contextualizing Internet Memes Across Social Media Platforms](https://arxiv.org/abs/2311.11157) | 本研究旨在探究是否可以通过使用知识图来对社交媒体平台上的互联网迷因进行情境化处理，填补了迄今为止对互联网迷因进行全面追踪、识别和映射的空白。 |
| [^202] | [Fuse It or Lose It: Deep Fusion for Multimodal Simulation-Based Inference](https://arxiv.org/abs/2311.10671) | 提出了多模态神经后验估计 (MultiNPE) 方法，利用深度融合学习整合不同来源的异构数据，在模拟推理中提高了对复杂数学模型参数的准确推断能力。 |
| [^203] | [Ever: Mitigating Hallucination in Large Language Models through Real-Time Verification and Rectification](https://arxiv.org/abs/2311.09114) | 通过实时验证和纠正的策略，文章提出了一种名为Ever的方法，用于减轻大型语言模型生成中的虚构问题。 |
| [^204] | [Towards A Unified View of Answer Calibration for Multi-Step Reasoning](https://arxiv.org/abs/2311.09101) | 本文总结了最近答案校准技术的分类法，从统一视角对步级和路径级答案校准进行了彻底评估，结果显示整合两种策略的优势倾向于产生最佳结果。 |
| [^205] | [Reasoning over Description Logic-based Contexts with Transformers](https://arxiv.org/abs/2311.08941) | 本研究构建了一个由描述逻辑知识库生成的合成自然语言问答数据集，以评估基于Transformer模型在丰富语境中的推理能力。 |
| [^206] | [The Shape of Learning: Anisotropy and Intrinsic Dimensions in Transformer-Based Models](https://arxiv.org/abs/2311.05928) | 本研究揭示了Transformer解码器中的各向异性呈钟状曲线，最高各向异性浓度在中间层，与编码器中更均匀分布的各向异性不同，并发现嵌入的内在维度在训练初期增加，随后在训练末期出现压缩，表明更紧凑的表示形式。 |
| [^207] | [Tuning-less Object Naming with a Foundation Model](https://arxiv.org/abs/2311.04924) | 使用transformers的注意力机制，提出了一种无需微调模型即可进行对象命名的方法 |
| [^208] | [On Bilingual Lexicon Induction with Large Language Models](https://arxiv.org/abs/2310.13995) | 本文研究了利用大型语言模型进行双语词汇识别的潜力，通过研究零次提示和少量上下文提示等方法，探讨了这种方法如何与当前BLI方法相比，并如何进行补充。 |
| [^209] | [Quality-Aware Translation Models: Efficient Generation and Quality Estimation in a Single Model](https://arxiv.org/abs/2310.06707) | 提出了一种质量感知翻译模型，通过训练NMT模型来估计其输出质量，可以在解码过程中消除额外的计算成本。 |
| [^210] | [Ask Again, Then Fail: Large Language Models' Vacillations in Judgement](https://arxiv.org/abs/2310.02174) | 目前的语言模型在面对后续问题时常常摇摆不定，研究者提出了一个后续问题机制和两个度量标准来量化这种不一致性，并开发出Unwavering-FQ框架来教导模型保持最初的正确判断，实验证明其有效性。 |
| [^211] | [Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology View](https://arxiv.org/abs/2310.02124) | 通过实践实验和理论洞察，探究当代NLP系统之间的协作机制，发现某些协作策略优于先前的方法，并且优化了效率。 |
| [^212] | [Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning](https://arxiv.org/abs/2310.01061) | 提出了一种名为图推理（RoG）的新方法，通过将LLMs与KGs协同工作，实现忠实且可解释的大型语言模型推理。 |
| [^213] | [Deep Reinforcement Learning for Image-to-Image Translation](https://arxiv.org/abs/2309.13672) | 该论文提出了一种基于深度强化学习的图像到图像翻译方法，通过将翻译过程分解为小步骤并引入元策略和Plan概念，能够有效处理高维连续状态和动作空间的挑战。 |
| [^214] | [RecMind: Large Language Model Powered Agent For Recommendation](https://arxiv.org/abs/2308.14296) | RecMind是一种LLM驱动的自主推荐代理，通过Self-Inspiring算法提高了规划能力，能够为零-shot个性化推荐提供支持。 |
| [^215] | [Improving Buoy Detection with Deep Transfer Learning for Mussel Farm Automation](https://arxiv.org/abs/2308.09238) | 该研究利用深度学习技术提升贻贝养殖中浮标检测的准确性和稳健性，以应用于智能贻贝养殖监测和管理。 |
| [^216] | [Fixing confirmation bias in feature attribution methods via semantic match](https://arxiv.org/abs/2307.00897) | 提出了通过语义匹配修复特征归因方法中的确认偏见问题，引入了人类概念与（亚符号）解释之间的概念框架，并提出了一种结构化方法来评估语义匹配。 |
| [^217] | [A blind spot for large language models: Supradiegetic linguistic information](https://arxiv.org/abs/2306.06794) | 大型语言模型的盲点在于其对超叙事语言信息的忽视，研究提出考虑模型如何感知语言信息有助于深入了解其能力。 |
| [^218] | [Learning Hidden Markov Models Using Conditional Samples](https://arxiv.org/abs/2302.14753) | 本文提出了一种使用交互方式访问隐马尔可夫模型的条件分布样本的学习方法，实现了对HMM的高效学习算法，从而绕过了其密码学困难性。 |
| [^219] | [Joint Learning of Blind Super-Resolution and Crack Segmentation for Realistic Degraded Images](https://arxiv.org/abs/2302.12491) | 通过联合学习盲目超分辨率和裂缝分割，在深度神经网络的支持下，提出的方法能有效优化分割结果，并针对现实场景中的未知模糊对低分辨率图像进行处理。 |
| [^220] | [Don't Play Favorites: Minority Guidance for Diffusion Models](https://arxiv.org/abs/2301.12334) | 本研究提出了一个可以使扩散模型生成过程专注于少数样本的新颖框架。 |
| [^221] | [Closed-Loop View of the Regulation of AI: Equal Impact across Repeated Interactions](https://arxiv.org/abs/2209.01410) | 论文提出了基于民权立法的AI监管闭环视角，强调在重复互动中产生的均等影响。 |
| [^222] | [Information-Theoretic Equivalence of Entropic Multi-Marginal Optimal Transport: A Theory for Multi-Agent Communication](https://arxiv.org/abs/2208.10256) | 本文提出了关于熵多边际最优输运的信息论等效性，将其推广到多智能体通信领域，证明了熵最优输运在信息论上的最优性，并为未来多智能体团队系统中的OT理论提供了启示。 |
| [^223] | [Complex behavior from intrinsic motivation to occupy action-state path space](https://arxiv.org/abs/2205.10316) | 行为的目标是最大化未来行动和状态路径的占用，根据最大占用原则，奖励是占用路径空间的手段，而不是目标本身，并提供了与最优策略和状态值函数相关的解析表达式，证明了值迭代算法的收敛性 |
| [^224] | [Training Robots without Robots: Deep Imitation Learning for Master-to-Robot Policy Transfer](https://arxiv.org/abs/2202.09574) | 该研究提出了一种新的主到机器人策略转移系统，在无需机器人参与的情况下进行力反馈操作任务的深度模仿学习，使操作者通过控制器进行直接演示并感受力反馈。 |
| [^225] | [Transformer-based deep imitation learning for dual-arm robot manipulation](https://arxiv.org/abs/2108.00385) | 使用Transformer的深度模仿学习结构成功解决了双臂机器人操作任务中神经网络性能不佳的问题 |
| [^226] | [Gaze-based dual resolution deep imitation learning for high-precision dexterous robot manipulation](https://arxiv.org/abs/2102.01295) | 基于人类基于凝视的双分辨率视觉运动控制系统的启发，提出了一种利用深度模仿学习解决高精度灵巧机器人操作任务的方法 |
| [^227] | [SelectLLM: Can LLMs Select Important Instructions to Annotate?.](http://arxiv.org/abs/2401.16553) | 这项工作提出了一种名为SelectLLM的新方法，利用LLMs选择高质量指令。通过提示LLMs估计每个无标签指令的有用性和影响力，并使用聚类算法将指令分为多个聚类。 |
| [^228] | [Airavata: Introducing Hindi Instruction-tuned LLM.](http://arxiv.org/abs/2401.15006) | "Airavata"是一个针对印地语进行指令调整的LLM，通过微调OpenHathi和IndicInstruct数据集，提供更好的协助任务性能，并计划扩展到所有22种计划Indic语言。 |
| [^229] | [Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Conditional Interpretations.](http://arxiv.org/abs/2401.14142) | 基于能量的概念瓶颈模型统一了预测、概念干预和条件解释的功能，解决了现有方法在高阶非线性相互作用和复杂条件依赖关系上的限制。 |
| [^230] | [Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal Contrastive EHR Modelling with Hierarchical Regularisation.](http://arxiv.org/abs/2401.11648) | 通过医学代码中心的多模态对比EHR建模预测下次就诊诊断，并通过分层正则化提高性能。 |
| [^231] | [Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges.](http://arxiv.org/abs/2401.08664) | 本文回顾了针对教育能力的大型语言模型研究，包括数学、写作、编程、推理和基于知识的问答，旨在探索其在构建下一代智能教育系统中的潜力和挑战。 |
| [^232] | [QuasiNet: a neural network with trainable product layers.](http://arxiv.org/abs/2401.06137) | QuasiNet是一种新的神经网络模型，通过可训练的乘积层解决了小规模隐藏神经元下传统神经网络在难问题上的有限收敛问题，具有更高的成功率。 |
| [^233] | [INACIA: Integrating Large Language Models in Brazilian Audit Courts: Opportunities and Challenges.](http://arxiv.org/abs/2401.05273) | 本文介绍了INACIA系统，这是一个将大型语言模型整合到巴西审计法院中的系统，可以自动化案件分析的各个阶段，并展示了其在从案件文件中提取信息、评估合法性和生成司法建议方面的潜力。 |
| [^234] | [Knowledge Sharing in Manufacturing using Large Language Models: User Evaluation and Model Benchmarking.](http://arxiv.org/abs/2401.05200) | 使用大型语言模型在制造业中进行知识共享，通过评估实证了该系统的效益，提高了操作员的信息检索速度和问题解决效率，同时强调在有人工专家选项时的偏好。GPT-4是最优秀的模型。 |
| [^235] | [Optimal Chaining of Vehicle Plans with Time Windows.](http://arxiv.org/abs/2401.02873) | 本论文提出了一种解决带有时间窗口的车辆路径问题的最优链路方法，考虑了计划的时间灵活性，并通过实证结果证明了该方法在解决静态拨打车问题时的优越性。 |
| [^236] | [Diffusion Model with Perceptual Loss.](http://arxiv.org/abs/2401.00110) | 本研究介绍了一种使用感知损失的扩散模型，通过无分类器指导实现了生成更真实样本的目的。 |
| [^237] | [Linear Log-Normal Attention with Unbiased Concentration.](http://arxiv.org/abs/2311.13541) | 本论文研究了自注意机制，并分析了注意力矩阵的分布和集中能力。通过引入线性对数正态注意力来模拟原始自注意力的分布和集中行为，提高了Transformer模型的可扩展性。 |
| [^238] | [Contrastive Difference Predictive Coding.](http://arxiv.org/abs/2310.20141) | 本文介绍了一种时间差异版本的对比预测编码，通过将不同时间序列数据的片段组合在一起，来减少学习预测未来事件所需的数据量。实验证明，与先前的方法相比，我们的方法在成功率上提高了2倍，并且对于随机环境有更好的适应能力。 |
| [^239] | [Constrained Hierarchical Monte Carlo Belief-State Planning.](http://arxiv.org/abs/2310.20054) | 有约束的层次蒙特卡洛信念状态规划（COBeTS）通过使用分层分解和约束选项控制器，将在线基于搜索的CPOMDP规划扩展到大型机器人问题，并能同时满足约束和奖励目标。 |
| [^240] | [AI Alignment: A Comprehensive Survey.](http://arxiv.org/abs/2310.19852) | 本篇论文主要介绍了AI对齐的概念、方法和实践。研究围绕四个关键目标：健壮性、可解释性、可控性和道德性展开，并将其分为前向对齐和后向对齐两个部分。 AI对齐是为了构建符合人类意图和价值观的AI系统，并减轻由于系统不对齐带来的潜在风险。 |
| [^241] | [Representation Learning with Large Language Models for Recommendation.](http://arxiv.org/abs/2310.15950) | 这篇论文介绍了一个模型-不可知的框架RLMRec，通过使用大语言模型（LLMs）来增强传统的基于ID的推荐系统，并解决了可扩展性问题、仅依赖文本的限制以及提示输入限制等挑战。 |
| [^242] | [O3D: Offline Data-driven Discovery and Distillation for Sequential Decision-Making with Large Language Models.](http://arxiv.org/abs/2310.14403) | O3D提出了一种基于离线数据的学习框架，利用大规模数据改进了大规模语言模型在顺序决策问题中的性能，通过自动发现可重复使用的技能，提高了模型的表现 |
| [^243] | [Dynamic Sparse No Training: Training-Free Fine-tuning for Sparse LLMs.](http://arxiv.org/abs/2310.08915) | 这篇论文介绍了一种名为动态稀疏无训练的微调方法，可以在不进行昂贵的反向传播和权重更新的情况下更新稀疏的大型语言模型，以此来减小将其部署到设备上时面临的挑战。 |
| [^244] | [Diversity of Thought Improves Reasoning Abilities of Large Language Models.](http://arxiv.org/abs/2310.07088) | 本文提出了一种方法，通过改变输入提示来提高大规模语言模型的推理能力，从而改善模型在复杂推理场景中的表现。这种方法自动采集模型反馈，生成适合问题的多样化提示，并通过多次推理调用来集成这些多样化的提示。 |
| [^245] | [Suppressing Overestimation in Q-Learning through Adversarial Behaviors.](http://arxiv.org/abs/2310.06286) | 本文提出了一种新的Q学习算法，通过引入虚拟对抗性玩家，有效调节了标准Q学习中的过高估计偏差，提出的算法简单而有效，能够轻松应用于强化学习算法并提高性能。 |
| [^246] | [Let Models Speak Ciphers: Multiagent Debate through Embeddings.](http://arxiv.org/abs/2310.06272) | 本文引入了一种名为CIPHER的通信机制，通过去除LLMs中的标记采样步骤，让模型可以通过期望的原始Transformer输出嵌入来传达其信念，从而解决了在自然语言生成中可能存在的信息丢失风险，并提供了编码更广泛信息的优势。 |
| [^247] | [Label-free Node Classification on Graphs with Large Language Models (LLMS).](http://arxiv.org/abs/2310.04668) | 本文介绍了一种使用大型语言模型（LLMs）对图中节点进行无标签分类的方法，即LLM-GNN。它利用LLMs对一小部分节点进行注释，然后通过对LLMs的注释进行训练，使得GNN能够对其余大部分节点进行预测。这种方法充分发挥了GNNs和LLMs的优势，同时解决了它们在处理结构化数据方面的限制。 |
| [^248] | [Leveraging Self-Consistency for Data-Efficient Amortized Bayesian Inference.](http://arxiv.org/abs/2310.04395) | 该论文提出了一种利用自一致性改进数据有效的摊余贝叶斯推理方法，通过反转贝叶斯定理并利用近似表示的联合模型估计边际似然，加速条件神经密度估计器的学习动力学。 |
| [^249] | [USB-NeRF: Unrolling Shutter Bundle Adjusted Neural Radiance Fields.](http://arxiv.org/abs/2310.02687) | USB-NeRF是一种解决滚动快门相机问题的神经辐射场算法，能够纠正滚动快门失真并恢复准确的相机运动轨迹，相比之前的方法在RS效应去除和新视角图像生成方面表现更好。 |
| [^250] | [Automated Evaluation of Classroom Instructional Support with LLMs and BoWs: Connecting Global Predictions to Specific Feedback.](http://arxiv.org/abs/2310.01132) | 本研究旨在利用大型语言模型和词袋模型自动估计课堂教学支持，以提供更具体、频繁和可行动的反馈给教师。实验证明，所提出的方法准确性接近于人工互评可靠性，LLM模型可以更好地捕捉到教学支持特征。 |
| [^251] | [Ground-A-Video: Zero-shot Grounded Video Editing using Text-to-image Diffusion Models.](http://arxiv.org/abs/2310.01107) | 本论文提出了一种名为 Ground-A-Video 的基于引导的视频到视频转换框架，用于多属性视频编辑。该方法在没有训练的情况下实现了输入视频的时间一致的多属性编辑，并且解决了其他方法存在的问题。 |
| [^252] | [Pre-training with Synthetic Data Helps Offline Reinforcement Learning.](http://arxiv.org/abs/2310.00771) | 本文研究表明，在离线深度强化学习中，使用合成数据进行预训练可以提高性能，而不一定需要语言预训练。此外，使用一步马尔科夫链生成的数据进行预训练可进一步改善性能。在一个流行的离线DRL算法中，使用简单的预训练方案也能获得性能提升。 |
| [^253] | [Order-Preserving GFlowNets.](http://arxiv.org/abs/2310.00386) | 本研究提出了保序GFlowNets（OP-GFNs），通过学习奖励函数与候选者的排序相一致的概率进行采样，解决了使用预定义标量奖励的局限性，同时提供了证明训练过程稀疏奖励景观的理论支持。 |
| [^254] | [A Foundation Model for General Moving Object Segmentation in Medical Images.](http://arxiv.org/abs/2309.17264) | 本文提出了一种用于医学图像中移动目标分割的基础模型iMOS，通过对序列中只有少量图像进行注释，即可实现高精度的分割效果 |
| [^255] | [Art or Artifice? Large Language Models and the False Promise of Creativity.](http://arxiv.org/abs/2309.14556) | 本研究通过提出创造性写作的托兰斯测验(TTCW)来评估大型语言模型(LLMs)的写作创造力。结果表明，LLM生成的故事在创意测试中通过的数量比专业作家写的故事少。此外，我们发现LLMs无法代替专家进行TTCW评估。 |
| [^256] | [Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis.](http://arxiv.org/abs/2309.12368) | 本研究探索了在复杂医疗决策中重新思考人工智能与人类合作的设计要求，以脓毒症诊断为例。研究发现，在人工智能系统中，支持临床专家在决策过程的中间阶段发挥作用（如生成假设或收集数据）是至关重要的，而不仅仅关注最终决策。 |
| [^257] | [RaTrack: Moving Object Detection and Tracking with 4D Radar Point Cloud.](http://arxiv.org/abs/2309.09737) | RaTrack是一种针对雷达跟踪的创新解决方案，通过运动分割和聚类以及运动估计模块，实现了对移动物体的精确跟踪，优于最先进性能。 |
| [^258] | [Quantitative and Qualitative Evaluation of Reinforcement Learning Policies for Autonomous Vehicles.](http://arxiv.org/abs/2309.08254) | 本文使用强化学习算法（PPO）针对自主驾驶车辆的选择进行了优化，通过最小化时间和污染来缓解交通阻塞问题，经实证分析和定性评估证明了方法的有效性和实用性。 |
| [^259] | [Graph Neural Networks Use Graphs When They Shouldn't.](http://arxiv.org/abs/2309.04332) | 在图形预测问题中，GNNs倾向于过拟合图结构，即使在忽略图结构的情况下可以获得更好的解决方案。常规图对于这种过拟合更具鲁棒性。 |
| [^260] | [A Benchmark Study on Calibration.](http://arxiv.org/abs/2308.11838) | 这项研究提出了一个模型校准的基准研究，利用神经架构搜索空间探索了模型校准属性。研究结果显示，模型校准可以在不同任务中泛化，并可以同时兼顾模型的准确性和校准性能。 |
| [^261] | [Internal Cross-layer Gradients for Extending Homogeneity to Heterogeneity in Federated Learning.](http://arxiv.org/abs/2308.11464) | 提出了一种基于内部跨层梯度的联邦学习方法，通过混合浅层和深层的梯度，增强了深层的相似性，从而扩展了在处理系统异质性方面的能力。 |
| [^262] | [Discrete Prompt Compression with Reinforcement Learning.](http://arxiv.org/abs/2308.08758) | 本研究提出了一种使用强化学习的离散提示压缩方法（PCRL），以解决指令调整的语言模型中嵌入训练的挑战。PCRL采用了一种计算效率高的策略网络直接编辑提示，可以灵活应用于各种类型的LM，而不需要梯度访问或标记数据。 |
| [^263] | [Large Language Models for Telecom: Forthcoming Impact on the Industry.](http://arxiv.org/abs/2308.06013) | 大型语言模型在电信行业将产生重要的影响。它们可以提高运营效率，简化任务，并需要解决使用中的挑战。 |
| [^264] | [LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking.](http://arxiv.org/abs/2308.04945) | LLMeBench是一个灵活的框架，用于加速LLMs基准测试。它可以定制任何NLP任务和模型，无论语言，支持零和少样本学习设置，并允许用户添加新的自定义数据集。已经在31个独特的NLP任务上进行了测试，并计划将框架开源。 |
| [^265] | [Language models as master equation solvers.](http://arxiv.org/abs/2308.02514) | 本研究将语言模型用作求解主方程的机器学习方法，通过设计提示网络和使用强化学习算法训练，实现了对多模组和高维系统的高精度求解。 |
| [^266] | [Regulating AI manipulation: Applying Insights from behavioral economics and psychology to enhance the practicality of the EU AI Act.](http://arxiv.org/abs/2308.02041) | 本文通过运用心理学和行为经济学的见解，澄清了欧盟AI法案中的术语并提高了保护效果。 |
| [^267] | [A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis.](http://arxiv.org/abs/2307.12856) | 这篇论文介绍了一种名为WebAgent的LLM驱动代理，通过自我经验学习，在真实网站上完成任务。该方法通过规划、总结和生成代码来提高在真实网站上的成功率。 |
| [^268] | [Exploring Non-Regular Extensions of Propositional Dynamic Logic with Description-Logics Features.](http://arxiv.org/abs/2307.09913) | 研究了非正则路径表达式对于扩展ALC描述逻辑中可满足性检查和查询的可决定性的影响，并提供了一系列不可决定性结果。 |
| [^269] | [Inertial Navigation Meets Deep Learning: A Survey of Current Trends and Future Directions.](http://arxiv.org/abs/2307.00014) | 本文综述了惯性导航领域中当前的深度学习方法，包括对不同车辆操作领域的研究、滤波参数学习的改进以及惯性传感器的校准和去噪方法。翻译过的论文标题: 惯性导航与深度学习：当前趋势与未来方向的综述 |
| [^270] | [Deep Reinforcement Learning with Multitask Episodic Memory Based on Task-Conditioned Hypernetwork.](http://arxiv.org/abs/2306.10698) | 人工智能领域，一个新算法利用基于任务条件化超网络的检索网络，根据任务调整网络参数，以解决深度强化学习中选择最相关的过去经验并将其融合到既有决策网络中的问题。 |
| [^271] | [Stochastic Re-weighted Gradient Descent via Distributionally Robust Optimization.](http://arxiv.org/abs/2306.09222) | 我们通过分布健壮优化和重要性加权的梯度下降技术提升了深度神经网络的性能，并在各种任务上取得了优越的结果。 |
| [^272] | [BackpropTools: A Fast, Portable Deep Reinforcement Learning Library for Continuous Control.](http://arxiv.org/abs/2306.03530) | BackpropTools是一款快速、可移植的连续控制深度强化学习库，它通过模板元编程提供紧密集成的可组合组件，并在异构平台集合上无缝使用，同时在连续控制问题的深度RL代理高效可扩展训练方面具有优势。由于其可移植性和实时保证，它成为了在嵌入式设备上部署学来的策略的有价值的工具。 |
| [^273] | [Stabilizing Contrastive RL: Techniques for Offline Goal Reaching.](http://arxiv.org/abs/2306.03346) | 本文提出了一种稳定的对比强化学习方法，通过浅而宽的结构，结合谨慎的权重初始化和数据增强等实验方法，在具有挑战性的仿真基准测试中显著提高了性能，并演示了对比方法可以解决现实世界的机器人任务。 |
| [^274] | [Going Deeper with Spectral Embeddings.](http://arxiv.org/abs/2306.00742) | 本文提出两种新的谱嵌入方法，一种基于函数分析原理和核方法，另一种基于深度网络优化损失，提供理论保证和实际有效的算法，并提供新的采样算法。 |
| [^275] | [On Computing Universal Plans for Partially Observable Multi-Agent Path Finding.](http://arxiv.org/abs/2305.16203) | 本文提出了一种通用计划的解决方案，能够确保多个智能体之间不发生碰撞，并使用 ASP-MAUPF 系统进行实验，对其适用性和环境依赖度进行了观察和分析。 |
| [^276] | [Distributed Online Rollout for Multivehicle Routing in Unmapped Environments.](http://arxiv.org/abs/2305.15596) | 本文提出了一个在线策略，通过分布式的协调策略解决了未建图环境下多车辆路径规划问题。 |
| [^277] | [Feature-aligned N-BEATS with Sinkhorn divergence.](http://arxiv.org/abs/2305.15196) | 这是一个基于Sinkhorn距离的特征对其N-BEATS模型，它通过对齐堆栈中的边际特征概率测度来进行领域广义的时间序列预测，同时保留了N-BEATS的可解释性和预测能力。 |
| [^278] | [Evaluating the Performance of Large Language Models on GAOKAO Benchmark.](http://arxiv.org/abs/2305.12474) | 本文介绍了一个基于高考考试问题的基准测试GAOKAO-Benchmark，用于评估大型语言模型在客观和主观问题方面的表现。通过对ChatGPT模型的评估，研究发现其在客观问题方面表现出色，同时也揭示了其不足之处和改进的方向。 |
| [^279] | [Multimodal Web Navigation with Instruction-Finetuned Foundation Models.](http://arxiv.org/abs/2305.11854) | 本文研究使用视觉语言基础模型进行数据驱动离线训练的 Web 代理，提出了一个指令跟随多模态代理WebGUM，将微调指令微调语言模型和视觉转换器，能够有效提高代理的基于视觉感知、HTML 理解和多步推理的能力。 |
| [^280] | [False Claims against Model Ownership Resolution.](http://arxiv.org/abs/2304.06607) | 该论文研究了模型所有权解决方案中对抗恶意原告的鲁棒性问题，展示了常见的MOR方案可以被恶意原告针对未被盗用的独立模型提出虚假指控。 |
| [^281] | [Domain Generalization In Robust Invariant Representation.](http://arxiv.org/abs/2304.03431) | 本文研究了不变表示的泛化性能，证明具有不变表示的模型可以学习到具有鲁棒性的非结构化潜在表示，因此使不变性成为域泛化的一个关键方面。 |
| [^282] | [Externalities in Chore Division.](http://arxiv.org/abs/2303.12446) | 该论文研究了劳务分工中的外部性问题，扩展了经典模型考虑到其他代理的影响。 |
| [^283] | [Performance Limits of a Deep Learning-Enabled Text Semantic Communication under Interference.](http://arxiv.org/abs/2302.14702) | 这项研究探讨了在干扰环境下深度学习的文本语义通信系统的性能限制，发现当干扰信号强度增大时，该系统会产生语义上无关的句子。 |
| [^284] | [Learning to Generalize towards Unseen Domains via a Content-Aware Style Invariant Model for Disease Detection from Chest X-rays.](http://arxiv.org/abs/2302.13991) | 通过内容感知的风格不变模型，我们提出了一种解决深度学习医学图像分析中源领域不匹配挑战的方法。我们采用了风格随机化模块来提取既是风格不变又是内容偏好的领域不变特征，在胸部X射线疾病检测中取得了良好的性能。 |
| [^285] | [Riemannian Flow Matching on General Geometries.](http://arxiv.org/abs/2302.03660) | 本文提出了一种名为黎曼流匹配的方法，可以在一般几何上训练连续标准化流，并在高维度数据上具有优势。 |
| [^286] | [Quality at the Tail.](http://arxiv.org/abs/2212.13925) | 本研究发现深度学习推理质量存在波动，引入了“尾部质量”的概念来描述这一现象。 |
| [^287] | [TREE-G: Decision Trees Contesting Graph Neural Networks.](http://arxiv.org/abs/2207.02760) | TREE-G引入了一种专门针对图数据的修改决策树方法，通过新颖的分裂函数和指针机制，使得决策树能够更好地应用于带有拓扑信息的图结构化数据。 |
| [^288] | [On the Identifiability of Nonlinear ICA: Sparsity and Beyond.](http://arxiv.org/abs/2206.07751) | 本文提出一个新的方法，考虑混合过程的假设，即结构稀疏性，来实现非线性ICA的可识别性，无需辅助变量。 |
| [^289] | [Text-based Person Search in Full Images via Semantic-Driven Proposal Generation.](http://arxiv.org/abs/2109.12965) | 本文提出了一种基于语义驱动的提案生成的全场景图像文字人物搜索方法，通过端到端学习优化行人检测、身份识别和视觉-语义特征嵌入任务，并利用语义特征指导区域建议网络关注文本描述的提案。使用跨尺度的视觉-语义嵌入机制来提高性能 |

# 详细

[^1]: Pok\'eLLMon：一个用于使用大型语言模型的Pok\'emon对战的与人类能力相当的代理机器人

    Pok\'eLLMon: A Human-Parity Agent for Pok\'emon Battles with Large Language Models

    [https://rss.arxiv.org/abs/2402.01118](https://rss.arxiv.org/abs/2402.01118)

    Pok\'eLLMon是第一个在战术对战游戏中实现人类能力的语言模型化身代理机器人。它通过上下文强化学习、知识增强生成和一致的行动生成的策略，展现了与人类类似的战斗策略和及时决策，并在Ladder比赛中达到了49%的胜率，在邀请对战中达到了56%的胜率。

    

    我们介绍了\textsc{Pok\'eLLMon}，这是第一个在战术对战游戏中实现人类能力的语言模型化身代理机器人，同时以Pok\'emon对战为例进行了证明。 \textsc{Pok\'eLLMon}的设计采用了三个关键策略：（i）上下文强化学习，即即时使用从对战中获得的基于文本的反馈来逐步完善策略；（ii）知识增强生成，即检索外部知识以对抗产生幻觉现象，并使代理机器人能够及时正确地行动；（iii）一致的行动生成，以减轻代理机器人面对强敌时的“惊慌换手”现象，使其可以逃避战斗。我们展示了与人类进行的在线对战中，\textsc{Pok\'eLLMon}采用与人类类似的战斗策略和及时决策，其在Ladder比赛中达到了49%的胜率，在邀请对战中达到了56%的胜率。我们的实现和可玩的战斗日志可以在以下链接中找到：\url{https://gith

    We introduce \textsc{Pok\'eLLMon}, the first LLM-embodied agent that achieves human-parity performance in tactical battle games, as demonstrated in Pok\'emon battles. The design of \textsc{Pok\'eLLMon} incorporates three key strategies: (i) In-context reinforcement learning that instantly consumes text-based feedback derived from battles to iteratively refine the policy; (ii) Knowledge-augmented generation that retrieves external knowledge to counteract hallucination and enables the agent to act timely and properly; (iii) Consistent action generation to mitigate the \textit{panic switching} phenomenon when the agent faces a powerful opponent and wants to elude the battle. We show that online battles against human demonstrates \textsc{Pok\'eLLMon}'s human-like battle strategies and just-in-time decision making, achieving 49\% of win rate in the Ladder competitions and 56\% of win rate in the invited battles. Our implementation and playable battle logs are available at: \url{https://gith
    
[^2]: 超越准确性：开源深度学习项目中单元测试的实证研究

    Beyond Accuracy: An Empirical Study on Unit Testing in Open-source Deep Learning Projects

    [https://arxiv.org/abs/2402.16546](https://arxiv.org/abs/2402.16546)

    通过对GitHub上9,129个开源DL项目的单元测试进行实证研究，发现经过单元测试的DL项目与开源项目指标呈正相关，68%的DL项目根本没有进行单元测试，并建立了单元测试和DL项目中故障之间的映射分类法。

    

    深度学习（DL）模型已经快速发展，专注于通过测试模型的准确性和稳健性来实现高性能。然而，尚不清楚是否需要像对待和测试其他软件系统一样对待和测试DL项目这样的软件系统时，DL项目是否经过了彻底测试或功能正确。因此，我们对GitHub上的9,129个开源DL项目进行了实证研究，分析了其中的单元测试。我们发现：1）经过单元测试的DL项目与开源项目指标呈正相关，并且对拉取请求有更高的接受率，2）本样本DL项目中有68%根本没有进行单元测试，3）DL模型的层(layer)和实用程序(utils)具有最多的单元测试。基于这些发现和以前的研究成果，我们建立了单元测试和DL项目中的故障之间的映射分类法。我们讨论了我们的发现对开发人员和研究人员的影响，并强调了Ne的重要性。

    arXiv:2402.16546v1 Announce Type: cross  Abstract: Deep Learning (DL) models have rapidly advanced, focusing on achieving high performance through testing model accuracy and robustness. However, it is unclear whether DL projects, as software systems, are tested thoroughly or functionally correct when there is a need to treat and test them like other software systems. Therefore, we empirically study the unit tests in open-source DL projects, analyzing 9,129 projects from GitHub. We find that: 1) unit tested DL projects have positive correlation with the open-source project metrics and have a higher acceptance rate of pull requests, 2) 68% of the sampled DL projects are not unit tested at all, 3) the layer and utilities (utils) of DL models have the most unit tests. Based on these findings and previous research outcomes, we built a mapping taxonomy between unit tests and faults in DL projects. We discuss the implications of our findings for developers and researchers and highlight the ne
    
[^3]: RoboGrind：工业机器人的直观交互式表面处理

    RoboGrind: Intuitive and Interactive Surface Treatment with Industrial Robots

    [https://arxiv.org/abs/2402.16542](https://arxiv.org/abs/2402.16542)

    RoboGrind是一个集成系统，通过3D感知、交互式语音控制向导系统和自动规划执行流水线实现工业机器人对表面处理任务的直观、交互式自动化，为重制玻璃纤维风力涡轮叶片提供了解决方案。

    

    arXiv:2402.16542v1 公告类型：跨领域 摘要：诸如磨削、打磨或抛光之类的表面处理任务是许多行业价值链中至关重要的一步，但自动化处理这些任务非常具有挑战性。我们提出了RoboGrind，这是一个集成系统，用于通过工业机器人直观、交互式地自动化表面处理任务。该系统结合了一个复杂的3D感知流水线，用于表面扫描和自动缺陷识别，一个交互式语音控制向导系统，用于AI辅助初始化和参数化机器人程序，以及一个用于力控制式机器人表面处理的自动规划和执行流水线。RoboGrind在实验室和实际环境中进行了评估，主要是用于重制玻璃纤维风力涡轮叶片。

    arXiv:2402.16542v1 Announce Type: cross  Abstract: Surface treatment tasks such as grinding, sanding or polishing are a vital step of the value chain in many industries, but are notoriously challenging to automate. We present RoboGrind, an integrated system for the intuitive, interactive automation of surface treatment tasks with industrial robots. It combines a sophisticated 3D perception pipeline for surface scanning and automatic defect identification, an interactive voice-controlled wizard system for the AI-assisted bootstrapping and parameterization of robot programs, and an automatic planning and execution pipeline for force-controlled robotic surface treatment. RoboGrind is evaluated both under laboratory and real-world conditions in the context of refabricating fiberglass wind turbine blades.
    
[^4]: 记忆差距：LLM 是否能通过图尔文测试？

    Memory GAPS: Would LLM pass the Tulving Test?

    [https://arxiv.org/abs/2402.16505](https://arxiv.org/abs/2402.16505)

    本文旨在探讨四十多年前的图尔文测试框架是否对LLM的记忆行为有所帮助。

    

    arXiv:2402.16505v1 公告类型：新摘要：图尔文测试旨在研究认知和回忆任务中的记忆表现。其结果有助于评估记忆的“协同引导模型”及类似RK范例在人类表现中的相关性。本文着手研究这个已有四十多年历史的框架是否能为LLM的记忆行为带来一些启示。

    arXiv:2402.16505v1 Announce Type: new  Abstract: The Tulving Test was designed to investigate memory performance in recognition and recall tasks. Its results help assess the relevance of the "Synergistic Ecphory Model" of memory and similar RK paradigms in human performance. This paper starts investigating whether the more than forty-year-old framework sheds some light on LLMs' acts of remembering.
    
[^5]: 智能飞机识别：从分类到相似度学习的转变，以用于作战识别

    Intelligent Known and Novel Aircraft Recognition -- A Shift from Classification to Similarity Learning for Combat Identification

    [https://arxiv.org/abs/2402.16486](https://arxiv.org/abs/2402.16486)

    这项研究提出了一种新颖、可扩展且基于人工智能的解决方案，采用相似度学习来区分广泛范围的军用和民用飞机特征，实现在遥感图像中准确识别已知和新颖飞机类型。

    

    在低分辨率遥感图像中精确识别飞机是航空领域面临的一项具有挑战性但至关重要的任务，尤其是在作战识别中。本研究提出了一种新颖、可扩展且基于人工智能的解决方案来解决这一问题。在遥感图像中进行作战识别的主要障碍是准确识别已知类型以及新颖/未知类型的飞机。传统方法、人类专家驱动的作战识别和图像分类在识别新颖类别方面存在不足。我们的方法利用相似度学习来区分广泛范围的军用和民用飞机的特征。它可以区分已知和新颖的飞机类型，利用度量学习进行识别和监督式少样本学习进行飞机类型分类。为了应对低分辨率遥感数据有限的挑战，我们提出了一个端到端的框架，以适应多样性和

    arXiv:2402.16486v1 Announce Type: cross  Abstract: Precise aircraft recognition in low-resolution remote sensing imagery is a challenging yet crucial task in aviation, especially combat identification. This research addresses this problem with a novel, scalable, and AI-driven solution. The primary hurdle in combat identification in remote sensing imagery is the accurate recognition of Novel/Unknown types of aircraft in addition to Known types. Traditional methods, human expert-driven combat identification and image classification, fall short in identifying Novel classes. Our methodology employs similarity learning to discern features of a broad spectrum of military and civilian aircraft. It discerns both Known and Novel aircraft types, leveraging metric learning for the identification and supervised few-shot learning for aircraft type classification. To counter the challenge of limited low-resolution remote sensing data, we propose an end-to-end framework that adapts to the diverse and
    
[^6]: 关于对模拟引擎进行语言化

    On Languaging a Simulation Engine

    [https://arxiv.org/abs/2402.16482](https://arxiv.org/abs/2402.16482)

    通过三种功能化类型的语言模型，提出了一种语言到模拟（Lang2Sim）框架，实现了精准将文本描述转化为可执行模拟器输入的方法。

    

    语言模型智能正在彻底改变我们编程材料模拟的方式。然而，模拟场景的多样性使得将人类语言精确转化为定制模拟器变得具有挑战性。在这里，我们使用三种功能化类型的语言模型，提出了一种语言到模拟（Lang2Sim）框架，该框架可以实现交互式导航，通过以多孔矩阵中水吸附的场景实例为例对模拟引擎进行语言化。与逐行编码目标模拟器不同，语言模型解释每个模拟器为具有不变工具功能及其变体输入-输出对的总体。 Lang2Sim通过功能化和序列化语言模型，相应地，对工具分类进行合理化，定制其输入-输出组合，并将模拟器输入精炼为可执行格式。重要的是，

    arXiv:2402.16482v1 Announce Type: new  Abstract: Language model intelligence is revolutionizing the way we program materials simulations. However, the diversity of simulation scenarios renders it challenging to precisely transform human language into a tailored simulator. Here, using three functionalized types of language model, we propose a language-to-simulation (Lang2Sim) framework that enables interactive navigation on languaging a simulation engine, by taking a scenario instance of water sorption in porous matrices. Unlike line-by-line coding of a target simulator, the language models interpret each simulator as an assembly of invariant tool function and its variant input-output pair. Lang2Sim enables the precise transform of textual description by functionalizing and sequentializing the language models of, respectively, rationalizing the tool categorization, customizing its input-output combinations, and distilling the simulator input into executable format. Importantly, dependin
    
[^7]: mEdIT: 通过指令调整实现多语言文本编辑

    mEdIT: Multilingual Text Editing via Instruction Tuning

    [https://arxiv.org/abs/2402.16472](https://arxiv.org/abs/2402.16472)

    该论文介绍了mEdIT，这是CoEdIT的多语言扩展，使用指令调整对多语言文本编辑模型进行微调训练，在多语言文本编辑任务中表现强劲。

    

    我们介绍了mEdIT，这是CoEdIT的一个多语言扩展，CoEdIT是最近最先进的文本编辑模型，用于写作辅助。mEdIT模型通过指令调整对多语言大型预训练语言模型（LLMs）进行微调训练。它们旨在接收用户从自然语言指令中指定所需文本属性的指令，例如Grammatik korrigieren（德语）或Parafrasee la oración（西班牙语）。我们通过从多个公开可用的人工注释文本编辑数据集中策划数据，针对六种不同语系的多语言，为三个文本编辑任务（语法错误校正（GEC）、文本简化和改写）构建了mEdIT。我们详细说明了mEdIT模型的设计和训练，并展示了它们在许多多语言文本编辑基准集上与其他多语言LLMs相比的强大性能。我们还发现mEdIT gen

    arXiv:2402.16472v1 Announce Type: cross  Abstract: We introduce mEdIT, a multi-lingual extension to CoEdIT -- the recent state-of-the-art text editing models for writing assistance. mEdIT models are trained by fine-tuning multi-lingual large, pre-trained language models (LLMs) via instruction tuning. They are designed to take instructions from the user specifying the attributes of the desired text in the form of natural language instructions, such as Grammatik korrigieren (German) or Parafrasee la oraci\'on (Spanish). We build mEdIT by curating data from multiple publicly available human-annotated text editing datasets for three text editing tasks (Grammatical Error Correction (GEC), Text Simplification, and Paraphrasing) across diverse languages belonging to six different language families. We detail the design and training of mEdIT models and demonstrate their strong performance on many multi-lingual text editing benchmarks against other multilingual LLMs. We also find that mEdIT gen
    
[^8]: 通过反向翻译防御LLMs免受越狱攻击

    Defending LLMs against Jailbreaking Attacks via Backtranslation

    [https://arxiv.org/abs/2402.16459](https://arxiv.org/abs/2402.16459)

    通过反向翻译来防御LLMs免受越狱攻击，将生成的反向翻译提示用于揭示原始提示的实际意图，提高了模型的安全性。

    

    尽管许多大型语言模型（LLMs）已经被训练成拒绝有害请求，但它们仍然容易受到越狱攻击的影响，这种攻击会重写原始提示以隐藏其有害意图。在本文中，我们提出了一种新方法，通过“反向翻译”来防御LLMs免受越狱攻击。具体来说，给定目标LLM从输入提示生成的初始响应，我们的反向翻译提示一个语言模型来推断可以导致该响应的输入提示。推断的提示称为反向翻译提示，倾向于揭示原始提示的实际意图，因为它是基于LLM的响应生成的，不是直接由攻击者操纵的。然后，我们再次在反向翻译提示上运行目标LLM，如果模型拒绝了反向翻译提示，则拒绝原始提示。我们解释了所提出的防御措施对其有效性的几个好处。

    arXiv:2402.16459v1 Announce Type: cross  Abstract: Although many large language models (LLMs) have been trained to refuse harmful requests, they are still vulnerable to jailbreaking attacks, which rewrite the original prompt to conceal its harmful intent. In this paper, we propose a new method for defending LLMs against jailbreaking attacks by ``backtranslation''. Specifically, given an initial response generated by the target LLM from an input prompt, our backtranslation prompts a language model to infer an input prompt that can lead to the response. The inferred prompt is called the backtranslated prompt which tends to reveal the actual intent of the original prompt, since it is generated based on the LLM's response and is not directly manipulated by the attacker. We then run the target LLM again on the backtranslated prompt, and we refuse the original prompt if the model refuses the backtranslated prompt. We explain that the proposed defense provides several benefits on its effectiv
    
[^9]: 在计算流体动力学问题上，代理辅助进化算法性能比较

    Performance Comparison of Surrogate-Assisted Evolutionary Algorithms on Computational Fluid Dynamics Problems

    [https://arxiv.org/abs/2402.16455](https://arxiv.org/abs/2402.16455)

    最近发布的方法和利用微分进化作为优化机制之一的技术在计算流体动力学问题上的代理辅助进化算法中表现明显优于其他方法。

    

    代理辅助进化算法（SAEAs）近年来是最广泛研究的方法之一，因其解决昂贵的真实世界优化问题的能力而备受关注。然而，新方法的开发和与其他技术的基准测试几乎完全依赖人为创建的问题。本文使用两个真实的计算流体动力学问题，比较了十一个最先进的单目标SAEA的性能。我们通过研究获得解决方案的质量和稳健性以及选定方法的收敛性能来分析性能。我们的研究发现表明，更近期发布的方法以及利用微分进化作为其优化机制之一的技术明显优于其他考虑的方法。

    arXiv:2402.16455v1 Announce Type: cross  Abstract: Surrogate-assisted evolutionary algorithms (SAEAs) are recently among the most widely studied methods for their capability to solve expensive real-world optimization problems. However, the development of new methods and benchmarking with other techniques still relies almost exclusively on artificially created problems. In this paper, we use two real-world computational fluid dynamics problems to compare the performance of eleven state-of-the-art single-objective SAEAs. We analyze the performance by investigating the quality and robustness of the obtained solutions and the convergence properties of the selected methods. Our findings suggest that the more recently published methods, as well as the techniques that utilize differential evolution as one of their optimization mechanisms, perform significantly better than the other considered methods.
    
[^10]: 在未知动态多障碍环境中的移动机器人在线高效安全关键控制

    Online Efficient Safety-Critical Control for Mobile Robots in Unknown Dynamic Multi-Obstacle Environments

    [https://arxiv.org/abs/2402.16449](https://arxiv.org/abs/2402.16449)

    提出了一个基于LiDAR的目标导向和勘探框架，实现了在线障碍物避免在未知动态多障碍环境中的高效控制

    

    本文提出了一种基于LiDAR的目标导向和勘探框架，解决了在线障碍物避免在由静态和移动障碍物填满的非结构化环境中的效率问题。该框架解决了传统动态控制屏障功能（D-CBFs）所面临的两个重要挑战：在线构建和由于使用多个D-CBFs导致的实时性能下降。为了解决第一个挑战，该框架的感知组件通过DBSCAN算法对点云进行聚类，然后利用最小界限椭球（MBEs）算法将这些聚类进行封装，创造出椭圆形表示。通过将当前状态的MBEs与之前存储的MBEs进行比较，实现了静态和动态障碍物的区分，并利用卡尔曼滤波器来预测后者的移动。这种分析有助于实施D-CB

    arXiv:2402.16449v1 Announce Type: cross  Abstract: This paper proposes a LiDAR-based goal-seeking and exploration framework, addressing the efficiency of online obstacle avoidance in unstructured environments populated with static and moving obstacles. This framework addresses two significant challenges associated with traditional dynamic control barrier functions (D-CBFs): their online construction and the diminished real-time performance caused by utilizing multiple D-CBFs. To tackle the first challenge, the framework's perception component begins with clustering point clouds via the DBSCAN algorithm, followed by encapsulating these clusters with the minimum bounding ellipses (MBEs) algorithm to create elliptical representations. By comparing the current state of MBEs with those stored from previous moments, the differentiation between static and dynamic obstacles is realized, and the Kalman filter is utilized to predict the movements of the latter. Such analysis facilitates the D-CB
    
[^11]: 在具有配对次模模函数的分布式大于内存的子集选择问题研究

    On Distributed Larger-Than-Memory Subset Selection With Pairwise Submodular Functions

    [https://arxiv.org/abs/2402.16442](https://arxiv.org/abs/2402.16442)

    本文提出了一种新颖的分布式约束算法，通过迭代绑定最小和最大效用值来选择高质量的点并丢弃不重要的点。

    

    许多学习问题取决于子集选择的基本问题，即确定一组重要和代表性的点。本文提出了一种具有可证估计近似保证的新颖分布式约束算法，它通过迭代绑定最小和最大效用值来选择高质量的点并丢弃不重要的点。

    arXiv:2402.16442v1 Announce Type: cross  Abstract: Many learning problems hinge on the fundamental problem of subset selection, i.e., identifying a subset of important and representative points. For example, selecting the most significant samples in ML training cannot only reduce training costs but also enhance model quality. Submodularity, a discrete analogue of convexity, is commonly used for solving subset selection problems. However, existing algorithms for optimizing submodular functions are sequential, and the prior distributed methods require at least one central machine to fit the target subset. In this paper, we relax the requirement of having a central machine for the target subset by proposing a novel distributed bounding algorithm with provable approximation guarantees. The algorithm iteratively bounds the minimum and maximum utility values to select high quality points and discard the unimportant ones. When bounding does not find the complete subset, we use a multi-round, 
    
[^12]: 通过不变统计损失训练隐式生成模型

    Training Implicit Generative Models via an Invariant Statistical Loss

    [https://arxiv.org/abs/2402.16435](https://arxiv.org/abs/2402.16435)

    提出了一种通过不变统计损失训练隐式生成模型的方法，解决了训练不稳定和模式缺失问题

    

    隐式生成模型具有学习任意复杂数据分布的能力。然而，训练需要通过对抗性鉴别器区分真实数据和人工生成的数据，导致训练不稳定和模式缺失问题。在这项工作中，我们提出了一种无需鉴别器的方法用于训练一维（1D）隐式生成模型，随后将该方法扩展以适应多变量情况。我们的损失函数是模型样本经过适当选择的变换与均匀分布之间的差异度量；因此，它对数据的真实分布保持不变。我们首先为一维随机变量制定我们的方法，为近似重参数化提供了有效的解决方案。

    arXiv:2402.16435v1 Announce Type: cross  Abstract: Implicit generative models have the capability to learn arbitrary complex data distributions. On the downside, training requires telling apart real data from artificially-generated ones using adversarial discriminators, leading to unstable training and mode-dropping issues. As reported by Zahee et al. (2017), even in the one-dimensional (1D) case, training a generative adversarial network (GAN) is challenging and often suboptimal. In this work, we develop a discriminator-free method for training one-dimensional (1D) generative implicit models and subsequently expand this method to accommodate multivariate cases. Our loss function is a discrepancy measure between a suitably chosen transformation of the model samples and a uniform distribution; hence, it is invariant with respect to the true distribution of the data. We first formulate our method for 1D random variables, providing an effective solution for approximate reparameterization 
    
[^13]: 基于分布式边布局的图学习

    Graph Learning with Distributional Edge Layouts

    [https://arxiv.org/abs/2402.16402](https://arxiv.org/abs/2402.16402)

    图神经网络中提出了一种新的全局布局采样方法，Distributional Edge Layouts（DELs），通过Langevin动力学和玻尔兹曼分布，能够捕获广泛的能量分布，提供额外的表达能力，有助于简化下游任务。

    

    图神经网络（GNNs）通过在某些拓扑布局上沿着边在相邻节点之间传递局部信息来学习图结构数据。在现代GNNs中，这些拓扑布局通常是按照确定性计算（例如，基于注意力的GNNs）或在启发性假设下本地采样（例如，GraphSage）的。本文首次提出这些布局可以通过Langevin动力学全局采样，遵循配备明确物理能量的玻尔兹曼分布，从而在物理世界中更具可行性。我们认为这样一组采样/优化的布局可以捕获广泛的能量分布，并在WL-test之上带来额外的表达能力，因此有助于简化下游任务。因此，我们提出了分布式边布局（DELs）作为各种GNNs的补充。DEL是一个与后续GNN变种无关的预处理策略，因此非常灵活。

    arXiv:2402.16402v1 Announce Type: cross  Abstract: Graph Neural Networks (GNNs) learn from graph-structured data by passing local messages between neighboring nodes along edges on certain topological layouts. Typically, these topological layouts in modern GNNs are deterministically computed (e.g., attention-based GNNs) or locally sampled (e.g., GraphSage) under heuristic assumptions. In this paper, we for the first time pose that these layouts can be globally sampled via Langevin dynamics following Boltzmann distribution equipped with explicit physical energy, leading to higher feasibility in the physical world. We argue that such a collection of sampled/optimized layouts can capture the wide energy distribution and bring extra expressivity on top of WL-test, therefore easing downstream tasks. As such, we propose Distributional Edge Layouts (DELs) to serve as a complement to a variety of GNNs. DEL is a pre-processing strategy independent of subsequent GNN variants, thus being highly fl
    
[^14]: 探索深度水印安全性：对抗性可迁移性视角

    Investigating Deep Watermark Security: An Adversarial Transferability Perspective

    [https://arxiv.org/abs/2402.16397](https://arxiv.org/abs/2402.16397)

    本研究通过引入两种有效的可迁移攻击者，填补了深度水印技术在面对擦除和篡改风险时的脆弱性这一领域缺乏系统研究的空白。

    

    生成式神经网络的兴起引发了对生成内容知识产权（IP）保护的增加需求。深度水印技术以其在IP保护中的灵活性而备受关注。然而，对抗性可迁移攻击的激增给深度水印技术的安全性带来了前所未有的挑战，这个领域目前缺乏系统的研究。本研究通过引入两种有效的可迁移攻击者来评估深度水印在面对擦除和篡改风险时的脆弱性来填补这一空白。具体来说，我们首先定义了局部样本密度的概念，并利用它推导出有关模型输出一致性的定理。在发现将样本扰动至目标类别高密度区域（HSDR）有助于增强有针对性的对抗可迁移性后，我们提出了Easy Sample Selection (ESS) 机制。

    arXiv:2402.16397v1 Announce Type: cross  Abstract: The rise of generative neural networks has triggered an increased demand for intellectual property (IP) protection in generated content. Deep watermarking techniques, recognized for their flexibility in IP protection, have garnered significant attention. However, the surge in adversarial transferable attacks poses unprecedented challenges to the security of deep watermarking techniques-an area currently lacking systematic investigation. This study fills this gap by introducing two effective transferable attackers to assess the vulnerability of deep watermarks against erasure and tampering risks. Specifically, we initially define the concept of local sample density, utilizing it to deduce theorems on the consistency of model outputs. Upon discovering that perturbing samples towards high sample density regions (HSDR) of the target class enhances targeted adversarial transferability, we propose the Easy Sample Selection (ESS) mechanism an
    
[^15]: MoZIP：评估知识产权领域大型语言模型的多语言基准

    MoZIP: A Multilingual Benchmark to Evaluate Large Language Models in Intellectual Property

    [https://arxiv.org/abs/2402.16389](https://arxiv.org/abs/2402.16389)

    本文提出了一个新的多语言基准MoZIP，用于评估大型语言模型在知识产权领域的表现，并开发了一个新的IP-oriented多语言大型语言模型MoZi，实验证明MoZi在MoZIP基准上的表现优越。

    

    大型语言模型（LLMs）在各种自然语言处理（NLP）任务中表现出色。然而，对LLMs在特定领域（例如知识产权（IP）领域）的表现还了解有限。本文提出了一个新的基准，即第一个面向知识产权领域的多语言智力产权测验(MoZIP)，用于评估LLMs在知识产权领域的表现。MoZIP基准包括三项具有挑战性的任务：知识产权多项选择测验（IPQuiz）、知识产权问答（IPQA）和专利匹配（PatentMatch）。此外，我们还开发了一个新的面向知识产权的多语言大型语言模型（称为MoZi），它是一个基于BLOOMZ的模型，利用多语言IP相关文本数据进行监督微调。我们在MoZIP基准上评估了我们提出的MoZi模型和四种知名LLMs（即BLOOMZ、BELLE、ChatGLM和ChatGPT）。实验结果表明，MoZi胜过其他模型。

    arXiv:2402.16389v1 Announce Type: cross  Abstract: Large language models (LLMs) have demonstrated impressive performance in various natural language processing (NLP) tasks. However, there is limited understanding of how well LLMs perform in specific domains (e.g, the intellectual property (IP) domain). In this paper, we contribute a new benchmark, the first Multilingual-oriented quiZ on Intellectual Property (MoZIP), for the evaluation of LLMs in the IP domain. The MoZIP benchmark includes three challenging tasks: IP multiple-choice quiz (IPQuiz), IP question answering (IPQA), and patent matching (PatentMatch). In addition, we also develop a new IP-oriented multilingual large language model (called MoZi), which is a BLOOMZ-based model that has been supervised fine-tuned with multilingual IP-related text data. We evaluate our proposed MoZi model and four well-known LLMs (i.e., BLOOMZ, BELLE, ChatGLM and ChatGPT) on the MoZIP benchmark. Experimental results demonstrate that MoZi outperfo
    
[^16]: 关于时间图学习算法的泛化能力：理论见解与一种更简单的方法

    On the Generalization Capability of Temporal Graph Learning Algorithms: Theoretical Insights and a Simpler Method

    [https://arxiv.org/abs/2402.16387](https://arxiv.org/abs/2402.16387)

    本文探讨了时间图学习算法的泛化能力，并提出了一种更简单的方法Simplified-Temporal-Graph-Network。

    

    时间图学习（TGL）已成为不同真实应用中普遍采用的技术，尤其是在数据可以表示为随时间演变的图的领域。尽管TGL在算法解决方案方面最近取得了显着进展，但其理论基础仍然大部分未被探索。本文旨在通过研究有限宽超参数化条件下不同TGL算法（如基于GNN、基于RNN和基于内存的方法）的泛化能力，来弥合这一差距。我们建立了TGL算法的泛化误差与GNN-/RNN- TGL方法中“层数/步数”以及特征-标签对齐（FLA）分数之间的关系，其中FLA可用作表达能力的代理，并解释了基于内存的方法的性能。在我们的理论分析的指导下，我们提出了简化时间图网络，该方法具有较小的泛化误差。

    arXiv:2402.16387v1 Announce Type: cross  Abstract: Temporal Graph Learning (TGL) has become a prevalent technique across diverse real-world applications, especially in domains where data can be represented as a graph and evolves over time. Although TGL has recently seen notable progress in algorithmic solutions, its theoretical foundations remain largely unexplored. This paper aims at bridging this gap by investigating the generalization ability of different TGL algorithms (e.g., GNN-based, RNN-based, and memory-based methods) under the finite-wide over-parameterized regime. We establish the connection between the generalization error of TGL algorithms and "the number of layers/steps" in the GNN-/RNN-based TGL methods and "the feature-label alignment (FLA) score", where FLA can be used as a proxy for the expressive power and explains the performance of memory-based methods. Guided by our theoretical analysis, we propose Simplified-Temporal-Graph-Network, which enjoys a small generaliza
    
[^17]: 一种用于生成高质量文本转语音数据集的自动化端到端开源软件

    An Automated End-to-End Open-Source Software for High-Quality Text-to-Speech Dataset Generation

    [https://arxiv.org/abs/2402.16380](https://arxiv.org/abs/2402.16380)

    该论文介绍了一种端到端工具，用于生成高质量的文本转语音（TTS）模型数据集，实现了语言特定的语音分布整合、自动化录制过程、自动化和人机协作的录音质量保证以及录音格式处理。

    

    数据的可用性对推动人工智能应用至关重要，包括基于语音的技术。随着内容创作的需求增加，尤其是社交媒体上的内容，翻译和文本转语音（TTS）技术已经成为必不可少的工具。本文介绍了一种端到端工具，用于生成高质量的文本转语音（TTS）模型数据集，以解决对高质量数据的急切需求。本作品的贡献多方面，包括：将语言特定的语音分布整合到样本选择中，自动化录制过程，自动化和人机协作的录音质量保证，以及处理录音以满足指定格式。

    arXiv:2402.16380v1 Announce Type: cross  Abstract: Data availability is crucial for advancing artificial intelligence applications, including voice-based technologies. As content creation, particularly in social media, experiences increasing demand, translation and text-to-speech (TTS) technologies have become essential tools. Notably, the performance of these TTS technologies is highly dependent on the quality of the training data, emphasizing the mutual dependence of data availability and technological progress. This paper introduces an end-to-end tool to generate high-quality datasets for text-to-speech (TTS) models to address this critical need for high-quality data. The contributions of this work are manifold and include: the integration of language-specific phoneme distribution into sample selection, automation of the recording process, automated and human-in-the-loop quality assurance of recordings, and processing of recordings to meet specified formats. The proposed application
    
[^18]: 用系统自校正改进基于LLM的机器翻译

    Improving LLM-based Machine Translation with Systematic Self-Correction

    [https://arxiv.org/abs/2402.16379](https://arxiv.org/abs/2402.16379)

    引入了名为TER的系统LLM自校正翻译框架，成功帮助LLMs提高翻译质量，具有更优越的系统性和可解释性。

    

    大型语言模型（LLMs）在机器翻译（MT）领域取得了令人印象深刻的结果。然而，人工仔细评估发现，LLMs生成的翻译仍然包含多个错误。重要的是，将这种错误信息反馈到LLMs中可以实现自校正，并改善翻译性能。受到这些观点的启发，我们引入了一个名为TER的系统LLM自校正翻译框架，代表了在这一方向上的重要进展。我们的研究结果表明：1）我们的自校正框架成功地帮助LLMs提高了多种语言的翻译质量，不管是从高资源语言到低资源语言，还是以英语为中心还是围绕其他语言；2）TER相比先前的方法展示出更优越的系统性和可解释性；3）

    arXiv:2402.16379v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have achieved impressive results in Machine Translation (MT). However, careful evaluations by human reveal that the translations produced by LLMs still contain multiple errors. Importantly, feeding back such error information into the LLMs can lead to self-correction and result in improved translation performance. Motivated by these insights, we introduce a systematic LLM-based self-correcting translation framework, named TER, which stands for Translate, Estimate, and Refine, marking a significant step forward in this direction. Our findings demonstrate that 1) our self-correction framework successfully assists LLMs in improving their translation quality across a wide range of languages, whether it's from high-resource languages to low-resource ones or whether it's English-centric or centered around other languages; 2) TER exhibits superior systematicity and interpretability compared to previous methods; 3)
    
[^19]: 视觉中的生成人工智能：模型、度量和应用的调查

    Generative AI in Vision: A Survey on Models, Metrics and Applications

    [https://arxiv.org/abs/2402.16369](https://arxiv.org/abs/2402.16369)

    扩散模型作为一种强大的方法正在生成高质量图像、文本和音频，而此调查论文旨在全面概述生成AI扩散和传统模型的基本技术、应用和挑战。

    

    生成AI模型通过实现逼真和多样化的数据样本的创建，已经在各个领域引起了革命。在这些模型中，扩散模型已经成为生成高质量图像、文本和音频的强大方法。这篇调查论文全面概述了生成AI扩散和传统模型，重点关注它们的基本技术、在不同领域的应用以及它们所面临的挑战。我们深入探讨了扩散模型的理论基础，包括去噪扩散概率模型（DDPM）和基于得分的生成建模等概念。此外，我们探讨了这些模型在文本到图像、图像修补和图像超分辨率等多样化应用中的潜力，展示了它们在创造性任务和数据增强中的潜力。通过综合现有研究并突出这一领域的关键进展，本调查旨在提供一份关于生成AI在视觉中的综述。

    arXiv:2402.16369v1 Announce Type: cross  Abstract: Generative AI models have revolutionized various fields by enabling the creation of realistic and diverse data samples. Among these models, diffusion models have emerged as a powerful approach for generating high-quality images, text, and audio. This survey paper provides a comprehensive overview of generative AI diffusion and legacy models, focusing on their underlying techniques, applications across different domains, and their challenges. We delve into the theoretical foundations of diffusion models, including concepts such as denoising diffusion probabilistic models (DDPM) and score-based generative modeling. Furthermore, we explore the diverse applications of these models in text-to-image, image inpainting, and image super-resolution, along with others, showcasing their potential in creative tasks and data augmentation. By synthesizing existing research and highlighting critical advancements in this field, this survey aims to prov
    
[^20]: LLM推断揭示：调查与Roofline模型见解

    LLM Inference Unveiled: Survey and Roofline Model Insights

    [https://arxiv.org/abs/2402.16363](https://arxiv.org/abs/2402.16363)

    本文提出了一个基于Roofline模型的框架，用于系统分析LLM推断技术，帮助识别部署中的瓶颈，并为更有效地部署LLM提供策略。

    

    高效大语言模型（LLM）推断领域正在迅速发展，提供了机遇和挑战的独特结合。虽然该领域已经扩展并充满活力，但至今还没有一个简明的框架来分析LLM推断的各种方法，以便清晰地理解这一领域。我们的调查不仅总结了当前研究现状，还基于Roofline模型引入了一个框架，用于系统分析LLM推断技术。这一框架能够帮助识别LLM部署中的瓶颈，并更深入地了解在实际设备上的实际方面，从而为部署LLM提供更有效的策略。此外，我们还系统地汇总了高效LLM推断的最新进展，涵盖关键领域，比如权重优化（如知识蒸馏和量化）。

    arXiv:2402.16363v1 Announce Type: cross  Abstract: The field of efficient Large Language Model (LLM) inference is rapidly evolving, presenting a unique blend of opportunities and challenges. Although the field has expanded and is vibrant, there hasn't been a concise framework that analyzes the various methods of LLM Inference to provide a clear understanding of this domain. Our survey stands out from traditional literature reviews by not only summarizing the current state of research but also by introducing a framework based on roofline model for systematic analysis of LLM inference techniques. This framework enables identifying the bottlenecks in LLM deployments and provides a deeper understanding of the practical aspects on real devices, thereby informing more effective strategies for deploying LLM. Furthermore, we systematically collate the latest advancements in efficient LLM inference, covering crucial areas such as weight optimization (e.g., Knowledge Distillation and Quantizatio
    
[^21]: 分层正则化Dropout用于神经语言模型

    Layer-wise Regularized Dropout for Neural Language Models

    [https://arxiv.org/abs/2402.16361](https://arxiv.org/abs/2402.16361)

    本文提出了一种专为Transformer-based语言模型设计的新颖的分层正则化Dropout（LR-Drop）方法，通过一致性训练策略逐层对每个Transformer层进行正则化，实现了隐藏状态、多头注意力矩阵和输出分布的一致性。

    

    在当今流行的各种预训练神经语言模型中，dropout已经成为一种不可或缺的正则化技术。为了解决dropout随机性引起的训练和推理不一致性，一些研究采用一致性训练来对输出层的dropout进行正则化。本文提出了一种新颖的分层正则化Dropout（LR-Drop），专为基于Transformer的语言模型设计。具体而言，LR-Drop使用层次一致性训练策略，逐层对每个Transformer层进行正则化。每个训练样本通过dropout采样的两个孪生子模型，然后LR-Drop强制使两个孪生子模型的隐藏状态、多头注意力矩阵和输出分布保持一致。所提出的LR-Drop可以被视为一种“自蒸馏”框架，其中dropout生成的每个子模型都是另一个的“教师”模型。

    arXiv:2402.16361v1 Announce Type: cross  Abstract: Among the various pre-trained neural language models that are popular today, dropout is already an indispensable regularization technique. To solve the inconsistency between training and inference caused by the randomness of dropout, some studies use consistency training to regularize dropout at the output layer. In this paper, we propose a novel Layer-wise Regularized Dropout (LR-Drop), which is specially designed for Transformer-based Language models. Specifically, LR-Drop layer-wise regularizes each Transformer layer using the consistency training strategy. Each training sample passes through the two siamese sub-models sampled by dropout, and then LR-Drop forces the hidden states, multi-head attention matrices, and output distribution of the two siamese sub-models to be consistent. The proposed LR-Drop can be regarded as a "self-distillation" framework, in which each sub-model generated by dropout is the other's "teacher" model and 
    
[^22]: 反馈高效在线微调扩散模型

    Feedback Efficient Online Fine-Tuning of Diffusion Models

    [https://arxiv.org/abs/2402.16359](https://arxiv.org/abs/2402.16359)

    提出了一种反馈高效的在线微调扩散模型的强化学习程序

    

    扩散模型在建模复杂数据分布方面表现出色，包括图像，蛋白质和小分子的分布。然而，在许多情况下，我们的目标是模拟最大化某些属性的分布的部分：例如，我们可能希望生成具有高审美质量的图像，或具有高生物活性的分子。自然地，我们可以将这视为一个强化学习（RL）问题，其目标是微调扩散模型以最大化与某些属性对应的奖励函数。即使可以访问地面真实奖励函数的在线查询，有效地发现高奖励样本也可能具有挑战性：它们在初始分布中的概率可能很低，并且可能存在许多不可行的样本，甚至没有定义良好的奖励（例如，不自然的图像或物理上不可能的分子）。在这项工作中，我们提出了一种新颖的强化学习程序，可以高效地发现高奖励样本。

    arXiv:2402.16359v1 Announce Type: cross  Abstract: Diffusion models excel at modeling complex data distributions, including those of images, proteins, and small molecules. However, in many cases, our goal is to model parts of the distribution that maximize certain properties: for example, we may want to generate images with high aesthetic quality, or molecules with high bioactivity. It is natural to frame this as a reinforcement learning (RL) problem, in which the objective is to fine-tune a diffusion model to maximize a reward function that corresponds to some property. Even with access to online queries of the ground-truth reward function, efficiently discovering high-reward samples can be challenging: they might have a low probability in the initial distribution, and there might be many infeasible samples that do not even have a well-defined reward (e.g., unnatural images or physically impossible molecules). In this work, we propose a novel reinforcement learning procedure that effi
    
[^23]: 通过时间变分推断进行语言引导的技能学习

    Language-guided Skill Learning with Temporal Variational Inference

    [https://arxiv.org/abs/2402.16354](https://arxiv.org/abs/2402.16354)

    该论文提出了一种语言引导的技能学习算法，通过整合大型语言模型生成的分割信息来发现可重用的技能，并引入最小描述长度原则来引导这一过程，实现了在不同环境中加速学习并超越基线方法的效果。

    

    我们提出了一种从专家演示中发现技能的算法。该算法首先利用大型语言模型（LLMs）来提出轨迹的初始分割。随后，一个分层变分推断框架将LLM生成的分割信息纳入其中，通过合并轨迹段来发现可重用的技能。为了进一步控制压缩和可重用性之间的权衡，我们引入了一个基于最小描述长度原则的新辅助目标，帮助引导这种技能发现过程。我们的结果表明，使用我们方法的Agent能够发现有助于加速学习的技能，在BabyAI（一个网格世界导航环境）以及ALFRED（一个家庭模拟环境）的新长期任务中胜过基线技能学习方法。

    arXiv:2402.16354v1 Announce Type: cross  Abstract: We present an algorithm for skill discovery from expert demonstrations. The algorithm first utilizes Large Language Models (LLMs) to propose an initial segmentation of the trajectories. Following that, a hierarchical variational inference framework incorporates the LLM-generated segmentation information to discover reusable skills by merging trajectory segments. To further control the trade-off between compression and reusability, we introduce a novel auxiliary objective based on the Minimum Description Length principle that helps guide this skill discovery process. Our results demonstrate that agents equipped with our method are able to discover skills that help accelerate learning and outperform baseline skill learning approaches on new long-horizon tasks in BabyAI, a grid world navigation environment, as well as ALFRED, a household simulation environment.
    
[^24]: MathGenie: 使用问题反向翻译生成合成数据，以增强LLMs的数学推理能力

    MathGenie: Generating Synthetic Data with Question Back-translation for Enhancing Mathematical Reasoning of LLMs

    [https://arxiv.org/abs/2402.16352](https://arxiv.org/abs/2402.16352)

    MathGenie通过问题反向翻译生成合成数据，用于增强LLMs的数学推理能力，并创造了一个家族化的模型系列MathGenieLM。

    

    大型语言模型(LLMs)在数学推理方面展现出巨大潜力。然而，目前开源模型和GPT-4等闭源模型之间在这一领域仍存在性能差距。本文介绍了一种新颖的方法MathGenie，用于从小规模问题-解决方案数据集（称为种子数据）中生成多样且可靠的数学问题。我们扩充了种子数据的真实解决方案，并训练了一个反向翻译模型，将扩充的解决方案翻译回新问题。随后，我们为新问题生成了集成代码解决方案。为确保集成代码解决方案的正确性，我们采用了基于原理的解决方案验证策略。我们在新筛选的数据上对从7B到70B不等的各种预训练模型进行训练，以测试所提出的增强技术的有效性，从而产生了一个称为MathGenieLM的模型系列。

    arXiv:2402.16352v1 Announce Type: cross  Abstract: Large language models (LLMs) have exhibited great potential in mathematical reasoning. However, there remains a performance gap in this area between existing open-source models and closed-source models such as GPT-4. In this paper, we introduce MathGenie, a novel method for generating diverse and reliable math problems from a small-scale problem-solution dataset (denoted as seed data). We augment the ground-truth solutions of our seed data and train a back-translation model to translate the augmented solutions back into new questions. Subsequently, we generate code-integrated solutions for the new questions. To ensure the correctness of the code-integrated solutions, we employ rationale-based strategy for solution verification. Various pretrained models, ranging from 7B to 70B, are trained on the newly curated data to test the effectiveness of the proposed augmentation technique, resulting in a family of models known as MathGenieLM. Th
    
[^25]: 利用双层马尔可夫决策过程进行空间任务的应急规划

    Contingency Planning Using Bi-level Markov Decision Processes for Space Missions

    [https://arxiv.org/abs/2402.16342](https://arxiv.org/abs/2402.16342)

    提出利用双层马尔可夫决策过程来改善行星漫游车穿越规划中的计算挑战，并提高人工智能解决方案的可解释性和可信度

    

    本文侧重于科学任务的自主应急规划，通过在出现延迟或偏离正常任务计划时，从状态空间中任何非正常点进行快速策略计算。成功的应急规划涉及在随机情景中管理风险和回报，通常与行动概率相关。马尔可夫决策过程（MDPs）用于在此类情景中进行数学建模决策。然而，在行星漫游车穿越规划的特定情况下，庞大的行动空间和长期规划时间跨度带来了计算挑战。提出了一个双层MDP框架来提高计算的可解性，同时与现有任务规划实践保持一致，增强基于人工智能的解决方案的可解释性和可信度。我们讨论了将任务规划MDP转换为双层MDP，并在RoverGridWorld上测试了框架。

    arXiv:2402.16342v1 Announce Type: new  Abstract: This work focuses on autonomous contingency planning for scientific missions by enabling rapid policy computation from any off-nominal point in the state space in the event of a delay or deviation from the nominal mission plan. Successful contingency planning involves managing risks and rewards, often probabilistically associated with actions, in stochastic scenarios. Markov Decision Processes (MDPs) are used to mathematically model decision-making in such scenarios. However, in the specific case of planetary rover traverse planning, the vast action space and long planning time horizon pose computational challenges. A bi-level MDP framework is proposed to improve computational tractability, while also aligning with existing mission planning practices and enhancing explainability and trustworthiness of AI-driven solutions. We discuss the conversion of a mission planning MDP into a bi-level MDP, and test the framework on RoverGridWorld, a 
    
[^26]: 仅使用清晰语音的自监督语音质量评估与增强

    Self-Supervised Speech Quality Estimation and Enhancement Using Only Clean Speech

    [https://arxiv.org/abs/2402.16321](https://arxiv.org/abs/2402.16321)

    提出了VQScore，一种基于矢量量化可变分编码器的自监督度量，用于评估语音质量并进行自监督语音增强训练，通过引入领域知识和新颖的自蒸馏机制提高模型的相关性和鲁棒性。

    

    最近，语音质量评估从人类听觉专家设计转变为机器学习模型。为了解决目前大多数模型依赖于监督学习而导致标签收集耗时昂贵的问题，本文提出了VQScore，一种基于矢量量化可变分编码器（VQ-VAE）的量化误差评估语音的自监督度量。VQ-VAE的训练依赖于清晰语音，因此当语音受到扭曲时可以预期到较大的量化误差。为了进一步提高与真实质量分数的相关性，将语音处理领域知识融入模型设计中。发现矢量量化机制也可以用于自监督语音增强（SE）模型训练。为了提高编码器对SE的鲁棒性，引入了一种新颖的自蒸馏机制结合对抗训练。

    arXiv:2402.16321v1 Announce Type: cross  Abstract: Speech quality estimation has recently undergone a paradigm shift from human-hearing expert designs to machine-learning models. However, current models rely mainly on supervised learning, which is time-consuming and expensive for label collection. To solve this problem, we propose VQScore, a self-supervised metric for evaluating speech based on the quantization error of a vector-quantized-variational autoencoder (VQ-VAE). The training of VQ-VAE relies on clean speech; hence, large quantization errors can be expected when the speech is distorted. To further improve correlation with real quality scores, domain knowledge of speech processing is incorporated into the model design. We found that the vector quantization mechanism could also be used for self-supervised speech enhancement (SE) model training. To improve the robustness of the encoder for SE, a novel self-distillation mechanism combined with adversarial training is introduced. I
    
[^27]: Chain-of-Discussion：复杂证据问题回答的多模型框架

    Chain-of-Discussion: A Multi-Model Framework for Complex Evidence-Based Question Answering

    [https://arxiv.org/abs/2402.16313](https://arxiv.org/abs/2402.16313)

    提出了一种Chain-of-Discussion框架，通过多个开源语言模型的协同作用，提高了复杂问题回答的质量

    

    开放式问题回答需要模型找到适当的证据来形成合理、全面和有帮助的答案。在实际应用中，模型还需要参与对与问题密切相关的潜在场景进行深入讨论。在检索模块的增强下，开源大型语言模型（LLMs）通常能够产生一致的答案，但在可靠证据选择和深入问题分析方面仍不够理想。本文提出了一种新颖的Chain-of-Discussion框架，旨在利用多个开源LLMs之间的协同作用，为开放式QA提供更正确、更全面的答案，尽管它们在个体上还不够强大。我们的实验证明，多个LLMs之间的讨论对提高答案质量起着至关重要的作用。我们在\url{https://github.com/kobaya}上发布了我们的数据和代码。

    arXiv:2402.16313v1 Announce Type: cross  Abstract: Open-ended question answering requires models to find appropriate evidence to form well-reasoned, comprehensive and helpful answers. In practical applications, models also need to engage in extended discussions on potential scenarios closely relevant to the question. With augmentation of retrieval module, open-source Large Language Models (LLMs) can produce coherent answers often with different focuses, but are still sub-optimal in terms of reliable evidence selection and in-depth question analysis. In this paper, we propose a novel Chain-of-Discussion framework to leverage the synergy among multiple open-source LLMs aiming to provide \textbf{more correct} and \textbf{more comprehensive} answers for open-ended QA, although they are not strong enough individually. Our experiments show that discussions among multiple LLMs play a vital role in enhancing the quality of answers. We release our data and code at \url{https://github.com/kobaya
    
[^28]: 具有异步通信和异质用户的联邦上下文级联多臂老虎机问题

    Federated Contextual Cascading Bandits with Asynchronous Communication and Heterogeneous Users

    [https://arxiv.org/abs/2402.16312](https://arxiv.org/abs/2402.16312)

    本研究提出了一种解决联邦上下文级联多臂老虎机问题的算法，通过异步通信和考虑异质用户行为，实现了对具有不同偏好的用户提供定制化推荐，并给出了次线性的遗憾界限。

    

    我们研究了联邦上下文组合级联多臂老虎机问题，其中$|\mathcal{U}|$个代理在一个中央服务器的协调下合作，为$|\mathcal{U}|$个对应的用户提供定制推荐。我们考虑了异步通信范式下的联邦代理，无需强制同步，并且所有代理都独立于服务器通信，以及异质用户行为，其中用户可以被分为$J\le |\mathcal{U}|$个潜在用户集群，每个集群展现出不同的偏好。针对这种情况，我们提出了一种带有精心通信协议的UCB类型算法。通过理论分析，我们给出了对于p的次线性遗憾界限。

    arXiv:2402.16312v1 Announce Type: cross  Abstract: We study the problem of federated contextual combinatorial cascading bandits, where $|\mathcal{U}|$ agents collaborate under the coordination of a central server to provide tailored recommendations to the $|\mathcal{U}|$ corresponding users. Existing works consider either a synchronous framework, necessitating full agent participation and global synchronization, or assume user homogeneity with identical behaviors. We overcome these limitations by considering (1) federated agents operating in an asynchronous communication paradigm, where no mandatory synchronization is required and all agents communicate independently with the server, (2) heterogeneous user behaviors, where users can be stratified into $J \le |\mathcal{U}|$ latent user clusters, each exhibiting distinct preferences. For this setting, we propose a UCB-type algorithm with delicate communication protocols. Through theoretical analysis, we give sub-linear regret bounds on p
    
[^29]: 跨领域的中文句式结构解析

    Cross-domain Chinese Sentence Pattern Parsing

    [https://arxiv.org/abs/2402.16311](https://arxiv.org/abs/2402.16311)

    本文提出了一种利用大型语言模型进行自我训练的创新方法，通过动态生成训练数据将源领域句法规则与目标领域句子相结合，增强句式结构解析器对各种领域的适应能力，实验证明其在教科书和新闻领域的效果优于基于规则的基准模型1.68个百分点。

    

    arXiv:2402.16311v1 公告类型: 跨领域 句式结构（SPS）解析是一种主要用于语言教学的句法分析方法。现有的SPS解析器主要依赖于教科书语料库进行训练，缺乏跨领域能力。为了克服这一限制，本文提出了一种创新方法，利用大型语言模型（LLMs）在自我训练框架内。从源领域中提取部分句法规则，与目标领域句子结合动态生成训练数据，增强了解析器对不同领域的适应能力。在教科书和新闻领域进行的实验表明，所提出的方法效果显著，F1指标比基于规则的基准模型高出1.68个百分点。

    arXiv:2402.16311v1 Announce Type: cross  Abstract: Sentence Pattern Structure (SPS) parsing is a syntactic analysis method primarily employed in language teaching.Existing SPS parsers rely heavily on textbook corpora for training, lacking cross-domain capability.To overcome this constraint, this paper proposes an innovative approach leveraging large language models (LLMs) within a self-training framework. Partial syntactic rules from a source domain are combined with target domain sentences to dynamically generate training data, enhancing the adaptability of the parser to diverse domains.Experiments conducted on textbook and news domains demonstrate the effectiveness of the proposed method, outperforming rule-based baselines by 1.68 points on F1 metrics.
    
[^30]: REPLAY: 对稀疏轨迹进行位置预测的人类移动时间变化规律建模

    REPLAY: Modeling Time-Varying Temporal Regularities of Human Mobility for Location Prediction over Sparse Trajectories

    [https://arxiv.org/abs/2402.16310](https://arxiv.org/abs/2402.16310)

    该论文提出了REPLAY模型，利用一般RNN架构来学习捕捉人类移动的时间变化规律，用于位置预测。

    

    位置预测是根据历史用户移动轨迹来预测用户位置的技术。为了应对真实世界用户移动轨迹的固有稀疏问题，时空上下文被证明是非常有用的。现有的解决方案主要是将位置之间的时空距离纳入到移动轨迹中，要么通过将其作为附加输入提供给递归神经网络（RNNs），要么通过利用它们来寻找有信息的过去隐藏状态进行预测。然而，这种基于距离的方法未能捕捉人类移动的时间变化规律，例如，人类移动在早晨通常比其他时间更有规律；这暗示了实际时间戳的有用性。基于这一背景，我们提出了REPLAY，是一种通用的RNN架构，旨在捕捉时间变化的人类移动时间规律以进行位置预测。

    arXiv:2402.16310v1 Announce Type: cross  Abstract: Location prediction forecasts a user's location based on historical user mobility traces. To tackle the intrinsic sparsity issue of real-world user mobility traces, spatiotemporal contexts have been shown as significantly useful. Existing solutions mostly incorporate spatiotemporal distances between locations in mobility traces, either by feeding them as additional inputs to Recurrent Neural Networks (RNNs) or by using them to search for informative past hidden states for prediction. However, such distance-based methods fail to capture the time-varying temporal regularities of human mobility, where human mobility is often more regular in the morning than in other periods, for example; this suggests the usefulness of the actual timestamps besides the temporal distances. Against this background, we propose REPLAY, a general RNN architecture learning to capture the time-varying temporal regularities for location prediction. Specifically, 
    
[^31]: 审稿员也可以参与：通过模型反演进行条件生成的替代方法

    Referee Can Play: An Alternative Approach to Conditional Generation via Model Inversion

    [https://arxiv.org/abs/2402.16305](https://arxiv.org/abs/2402.16305)

    通过模型反演提出了一种训练自由的方法，可以绕过传统的采样过程，直接优化图像并获得更好的文本图像对齐，为改进图像生成提供了关键设计。

    

    作为文本到图像生成任务中占据主导地位的扩散概率模型（DPMs）面临着一个关键性挑战，即可控性方面的问题，难以严格遵守复杂、多方面的指令。在这项工作中，我们旨在解决条件生成任务中的这一协调挑战。首先，我们提供了一个替代观点，将现有最先进的DPMs视为反转先进视觉-语言模型（VLMs）的一种方式。通过这种表述，我们自然地提出了一种无需训练的方法，绕过与DPMs相关的传统采样过程。通过直接优化图像，并在有辨别力的VLMs的监督下，所提出的方法有潜力实现更好的文本图像对齐。作为概念的证明，我们演示了预训练的BLIP-2模型的流程，并确定了几个用于改进图像生成的关键设计。为进一步增强图像的保真度，我们提出了一个稳定的得分蒸馏采样模块。

    arXiv:2402.16305v1 Announce Type: cross  Abstract: As a dominant force in text-to-image generation tasks, Diffusion Probabilistic Models (DPMs) face a critical challenge in controllability, struggling to adhere strictly to complex, multi-faceted instructions. In this work, we aim to address this alignment challenge for conditional generation tasks. First, we provide an alternative view of state-of-the-art DPMs as a way of inverting advanced Vision-Language Models (VLMs). With this formulation, we naturally propose a training-free approach that bypasses the conventional sampling process associated with DPMs. By directly optimizing images with the supervision of discriminative VLMs, the proposed method can potentially achieve a better text-image alignment. As proof of concept, we demonstrate the pipeline with the pre-trained BLIP-2 model and identify several key designs for improved image generation. To further enhance the image fidelity, a Score Distillation Sampling module of Stable Di
    
[^32]: 图扩散策略优化

    Graph Diffusion Policy Optimization

    [https://arxiv.org/abs/2402.16302](https://arxiv.org/abs/2402.16302)

    本文引入了图扩散策略优化（GDPO），通过强化学习为任意目标优化图扩散模型，实现了在各种图生成任务中的最先进性能。

    

    最近的研究在优化扩散模型以实现特定下游目标方面取得了重要进展，这对于领域如药物设计中的图生成是一个重要的追求。然而，直接将这些模型应用于图扩散存在挑战，导致性能不佳。本文介绍了一种名为图扩散策略优化（GDPO）的新方法，该方法通过强化学习为任意（如非可微分）目标优化图扩散模型。GDPO基于针对图扩散模型量身定制的急切策略梯度，通过认真分析开发，有望提高性能。实验结果表明，GDPO在具有复杂和多样化目标的各种图生成任务中实现了最先进的性能。代码可在https://github.com/sail-sg/GDPO上找到。

    arXiv:2402.16302v1 Announce Type: cross  Abstract: Recent research has made significant progress in optimizing diffusion models for specific downstream objectives, which is an important pursuit in fields such as graph generation for drug design. However, directly applying these models to graph diffusion presents challenges, resulting in suboptimal performance. This paper introduces graph diffusion policy optimization (GDPO), a novel approach to optimize graph diffusion models for arbitrary (e.g., non-differentiable) objectives using reinforcement learning. GDPO is based on an eager policy gradient tailored for graph diffusion models, developed through meticulous analysis and promising improved performance. Experimental results show that GDPO achieves state-of-the-art performance in various graph generation tasks with complex and diverse objectives. Code is available at https://github.com/sail-sg/GDPO.
    
[^33]: MV-Swin-T: 用多视角Swin Transformer进行乳腺X线摄影分类

    MV-Swin-T: Mammogram Classification with Multi-view Swin Transformer

    [https://arxiv.org/abs/2402.16298](https://arxiv.org/abs/2402.16298)

    提出了一种基于Transformer的创新多视角网络用于乳腺X线摄影图像分类，引入了动态注意力块以有效整合多视图信息，并促进信息之间的连贯传递

    

    传统的深度学习方法用于乳腺癌分类主要集中在单视图分析上。然而，在临床实践中，放射科医生同时检查乳房X线摄影检查中的所有视图，利用这些视图之间的固有相关性有效地检测肿瘤。鉴于多视角分析的重要性，一些研究引入了独立处理乳房X线摄影视图的方法，通过不同的卷积分支或简单的融合策略，无意中导致了关键的视角间相关性的丢失。在本文中，我们提出了一种基于Transformer的创新多视角网络，以解决乳腺X线摄影图像分类中的挑战。我们的方法引入了一种基于移位窗口的动态注意力块，促进了多视图信息的有效整合，并促进了这些信息之间的连贯传递

    arXiv:2402.16298v1 Announce Type: cross  Abstract: Traditional deep learning approaches for breast cancer classification has predominantly concentrated on single-view analysis. In clinical practice, however, radiologists concurrently examine all views within a mammography exam, leveraging the inherent correlations in these views to effectively detect tumors. Acknowledging the significance of multi-view analysis, some studies have introduced methods that independently process mammogram views, either through distinct convolutional branches or simple fusion strategies, inadvertently leading to a loss of crucial inter-view correlations. In this paper, we propose an innovative multi-view network exclusively based on transformers to address challenges in mammographic image classification. Our approach introduces a novel shifted window-based dynamic attention block, facilitating the effective integration of multi-view information and promoting the coherent transfer of this information between
    
[^34]: 具有非平稳转移动态的泊松-伽马动力系统

    Poisson-Gamma Dynamical Systems with Non-Stationary Transition Dynamics

    [https://arxiv.org/abs/2402.16297](https://arxiv.org/abs/2402.16297)

    提出了一种具有非平稳转移动态的泊松-伽马动力系统，通过采用Dirichlet Markov链和数据增广技术来解决原有模型捕捉时变转移动态的不足。

    

    处理计数值时间序列的贝叶斯方法因其能够推断可解释的潜在结构和估计不确定性而备受重视，尤其适用于处理嘈杂和不完整的计数数据。在这些贝叶斯模型中，泊松-伽马动力系统（PGDSs）被证明能够有效捕捉观察到的计数序列底层动态的演变特征。然而，最新的PGDS在捕捉常见于实际计数时间序列中的时变转移动态方面仍有不足。为了克服这一限制，提出了一种非平稳PGDS，允许基础转移矩阵随时间演变，演变的转移矩阵由精心设计的Dirichlet Markov链建模。利用Dirichlet-Multinomial-Beta数据增广技术，开发了一个完全共轭且高效的Gibbs采样器。

    arXiv:2402.16297v1 Announce Type: cross  Abstract: Bayesian methodologies for handling count-valued time series have gained prominence due to their ability to infer interpretable latent structures and to estimate uncertainties, and thus are especially suitable for dealing with noisy and incomplete count data. Among these Bayesian models, Poisson-Gamma Dynamical Systems (PGDSs) are proven to be effective in capturing the evolving dynamics underlying observed count sequences. However, the state-of-the-art PGDS still falls short in capturing the time-varying transition dynamics that are commonly observed in real-world count time series. To mitigate this limitation, a non-stationary PGDS is proposed to allow the underlying transition matrices to evolve over time, and the evolving transition matrices are modeled by sophisticatedly-designed Dirichlet Markov chains. Leveraging Dirichlet-Multinomial-Beta data augmentation techniques, a fully-conjugate and efficient Gibbs sampler is developed t
    
[^35]: 区块链上的去中心化联邦遗忘

    Decentralized Federated Unlearning on Blockchain

    [https://arxiv.org/abs/2402.16294](https://arxiv.org/abs/2402.16294)

    提出了基于区块链的联邦遗忘（BlockFUL），使用Chameleon Hash（CH）技术重新设计区块链结构，减少模型更新的复杂性和成本。

    

    区块链联邦学习（FL）在确保FL过程的完整性和可追溯性方面越来越受到关注。区块链FL涉及参与者在本地训练模型并随后将模型发布到区块链上，形成表示模型关系的类似有向无环图（DAG）的继承结构。然而，这种基于DAG的结构在使用敏感数据更新模型时存在挑战，因为涉及的复杂性和开销较大。为了解决这个问题，我们提出了基于区块链的联邦遗忘（BlockFUL），这是一个通用框架，使用变色龙哈希（CH）技术重新设计区块链结构，以减轻模型更新的复杂性，从而降低遗忘任务的计算和共识成本。此外，BlockFUL支持各种联邦遗忘方法，确保模型更新的完整性和可追溯性。

    arXiv:2402.16294v1 Announce Type: cross  Abstract: Blockchained Federated Learning (FL) has been gaining traction for ensuring the integrity and traceability of FL processes. Blockchained FL involves participants training models locally with their data and subsequently publishing the models on the blockchain, forming a Directed Acyclic Graph (DAG)-like inheritance structure that represents the model relationship. However, this particular DAG-based structure presents challenges in updating models with sensitive data, due to the complexity and overhead involved. To address this, we propose Blockchained Federated Unlearning (BlockFUL), a generic framework that redesigns the blockchain structure using Chameleon Hash (CH) technology to mitigate the complexity of model updating, thereby reducing the computational and consensus costs of unlearning tasks.Furthermore, BlockFUL supports various federated unlearning methods, ensuring the integrity and traceability of model updates, whether conduc
    
[^36]: PerLTQA: 一个用于问题回答中的记忆分类、检索和合成的个人长期记忆数据集

    PerLTQA: A Personal Long-Term Memory Dataset for Memory Classification, Retrieval, and Synthesis in Question Answering

    [https://arxiv.org/abs/2402.16288](https://arxiv.org/abs/2402.16288)

    PerLTQA是一个结合了语义和情节记忆的创新QA数据集，旨在探索个性化记忆在QA任务中的应用，提供了一个全面的基准和记忆整合、检索、合成的框架

    

    长期记忆在个人互动中起着至关重要的作用，考虑到长期记忆可以更好地利用世界知识、历史信息和对话中的偏好。我们的研究引入了PerLTQA，一个创新的QA数据集，结合了语义和情节记忆，包括世界知识、用户资料、社会关系、事件和对话。这个数据集被收集用于探讨个性化记忆在QA任务中的应用，重点关注社交互动和事件。PerLTQA具有两种记忆类型和一个包含8,593个问题的30个字符的全面基准，促进了在大型语言模型（LLM）中探索和应用个性化记忆。基于PerLTQA，我们提出了一个记忆整合和生成的新框架，包括三个主要组成部分：记忆分类、记忆检索和记忆合成。我们使用五个LLM和三个评估了这个框架。

    arXiv:2402.16288v1 Announce Type: cross  Abstract: Long-term memory plays a critical role in personal interaction, considering long-term memory can better leverage world knowledge, historical information, and preferences in dialogues. Our research introduces PerLTQA, an innovative QA dataset that combines semantic and episodic memories, including world knowledge, profiles, social relationships, events, and dialogues. This dataset is collected to investigate the use of personalized memories, focusing on social interactions and events in the QA task. PerLTQA features two types of memory and a comprehensive benchmark of 8,593 questions for 30 characters, facilitating the exploration and application of personalized memories in Large Language Models (LLMs). Based on PerLTQA, we propose a novel framework for memory integration and generation, consisting of three main components: Memory Classification, Memory Retrieval, and Memory Synthesis. We evaluate this framework using five LLMs and thre
    
[^37]: 朝着敏捷机器人：利用神经网络进行直观的机器人位置推测

    Towards Agile Robots: Intuitive Robot Position Speculation with Neural Networks

    [https://arxiv.org/abs/2402.16281](https://arxiv.org/abs/2402.16281)

    本文提出了一种机器人位置推测网络(RPSN)，通过将可微分的逆运动学算法和神经网络结合，能够高成功率地推测移动操作器械的位置。

    

    机器人位置推测是控制移动操作器械的关键步骤之一，以确定底盘应该移动到哪里。为了满足敏捷机器人技术的需求，本文提出了一个机器人位置推测网络(RPSN)，这是一种基于学习的方法，旨在增强移动操作器械的敏捷性。RPSN将可微分的逆运动学算法和神经网络相结合。通过端到端训练，RPSN能够高成功率地推测位置。我们将RPSN应用于分解末期电动汽车电池的移动操作器械。在各种模拟环境和实际移动操作器械上进行了大量实验证明，RPSN提供的初始位置可能是理想位置的概率

    arXiv:2402.16281v1 Announce Type: cross  Abstract: The robot position speculation, which determines where the chassis should move, is one key step to control the mobile manipulators. The target position must ensure the feasibility of chassis movement and manipulability, which is guaranteed by randomized sampling and kinematic checking in traditional methods. Addressing the demands of agile robotics, this paper proposes a robot position speculation network(RPSN), a learning-based approach to enhance the agility of mobile manipulators. The RPSN incorporates a differentiable inverse kinematic algorithm and a neural network. Through end-to-end training, the RPSN can speculate positions with a high success rate. We apply the RPSN to mobile manipulators disassembling end-of-life electric vehicle batteries (EOL-EVBs). Extensive experiments on various simulated environments and physical mobile manipulators demonstrate that the probability of the initial position provided by RPSN being the idea
    
[^38]: 一种使用注释嵌入模型的本体包含关系预测自匹配训练方法

    A Self-matching Training Method with Annotation Embedding Models for Ontology Subsumption Prediction

    [https://arxiv.org/abs/2402.16278](https://arxiv.org/abs/2402.16278)

    提出了一种自匹配训练方法，通过两种本体嵌入模型捕获全局和局部信息，提高了概念子类预测的稳健性

    

    最近，提出了一种在低维空间中表示实体的本体嵌入，用于本体完成。然而，用于概念子类预测的本体嵌入未解决类似和孤立实体的困难，并且未提取本体中注释公理的全局信息。本文提出了一种针对两种本体嵌入模型的自匹配训练方法：Inverted-index Matrix Embedding (InME) 和 Co-occurrence Matrix Embedding (CoME)。这两种嵌入通过每个单词在一组公理中出现的位置以及每个公理中单词的共现来捕获注释公理中的全局和局部信息。自匹配训练方法提高了概念子类预测的稳健性，当预测的超类与子类相似且孤立于本体中的其他实体时。

    arXiv:2402.16278v1 Announce Type: new  Abstract: Recently, ontology embeddings representing entities in a low-dimensional space have been proposed for ontology completion. However, the ontology embeddings for concept subsumption prediction do not address the difficulties of similar and isolated entities and fail to extract the global information of annotation axioms from an ontology. In this paper, we propose a self-matching training method for the two ontology embedding models: Inverted-index Matrix Embedding (InME) and Co-occurrence Matrix Embedding (CoME). The two embeddings capture the global and local information in annotation axioms by means of the occurring locations of each word in a set of axioms and the co-occurrences of words in each axiom. The self-matching training method increases the robustness of the concept subsumption prediction when predicted superclasses are similar to subclasses and are isolated to other entities in an ontology. Our evaluation experiments show that
    
[^39]: 从大规模语言模型和优化到决策优化CoPilot：一项研究宣言

    From Large Language Models and Optimization to Decision Optimization CoPilot: A Research Manifesto

    [https://arxiv.org/abs/2402.16269](https://arxiv.org/abs/2402.16269)

    运用大型语言模型与优化相结合，创建决策优化CoPilot（DOCP），帮助决策者通过自然语言交互理解并解决业务问题。

    

    大大简化为 real-world business problems 创建优化模型一直是将数学优化更广泛地应用于重要商业和社会决策的主要目标。最近大型语言模型（LLMs）的能力提供了一个及时的机会来实现这一目标。因此，我们提出在LLMs和优化的交叉点上开展研究，创建一个决策优化CoPilot（DOCP）- 一个旨在帮助任何决策者的AI工具，通过自然语言交互来理解业务问题，随后制定和解决相应优化模型。本文概述了我们的DOCP愿景，并确定了其实施的几个基本要求。我们通过文献调查和使用ChatGPT进行实验描述了现状。我们展示了a）LLMs已经提供了与DOCP相关的重大新功能，b）主要研究 c

    arXiv:2402.16269v1 Announce Type: new  Abstract: Significantly simplifying the creation of optimization models for real-world business problems has long been a major goal in applying mathematical optimization more widely to important business and societal decisions. The recent capabilities of Large Language Models (LLMs) present a timely opportunity to achieve this goal. Therefore, we propose research at the intersection of LLMs and optimization to create a Decision Optimization CoPilot (DOCP) - an AI tool designed to assist any decision maker, interacting in natural language to grasp the business problem, subsequently formulating and solving the corresponding optimization model. This paper outlines our DOCP vision and identifies several fundamental requirements for its implementation. We describe the state of the art through a literature survey and experiments using ChatGPT. We show that a) LLMs already provide substantial novel capabilities relevant to a DOCP, and b) major research c
    
[^40]: 基础模型透明度报告

    Foundation Model Transparency Reports

    [https://arxiv.org/abs/2402.16268](https://arxiv.org/abs/2402.16268)

    提出了基础模型透明度报告，借鉴社交媒体的透明度报告实践，目的在于在基础模型行业尚未成熟时制定透明度报告。

    

    基础模型是具有广泛社会影响的关键数字技术，需要透明度。为了规范基础模型开发者应如何提供有关其模型开发和部署的透明度，我们提出了基础模型透明度报告，借鉴社交媒体的透明度报告实践。尽管社交媒体透明度报告是由外部对社会伤害的文档促成的，我们的目标是在行业仍处于萌芽阶段时为基础模型制定透明度报告。为设计我们的报告，我们确定了6条设计原则，考虑了社交媒体透明度报告的成功和不足。为了进一步使我们的报告系统化，我们借鉴了基础模型透明度指数的100个透明度指标。根据这些指标，我们测量它们与六个主要透明度要求中包含的透明度要求的重叠程度。

    arXiv:2402.16268v1 Announce Type: cross  Abstract: Foundation models are critical digital technologies with sweeping societal impact that necessitates transparency. To codify how foundation model developers should provide transparency about the development and deployment of their models, we propose Foundation Model Transparency Reports, drawing upon the transparency reporting practices in social media. While external documentation of societal harms prompted social media transparency reports, our objective is to institutionalize transparency reporting for foundation models while the industry is still nascent. To design our reports, we identify 6 design principles given the successes and shortcomings of social media transparency reporting. To further schematize our reports, we draw upon the 100 transparency indicators from the Foundation Model Transparency Index. Given these indicators, we measure the extent to which they overlap with the transparency requirements included in six promine
    
[^41]: 留意你的头部：组装投影头以提高联邦模型的可靠性

    Watch Your Head: Assembling Projection Heads to Save the Reliability of Federated Models

    [https://arxiv.org/abs/2402.16255](https://arxiv.org/abs/2402.16255)

    联邦学习中发现当面对异构数据时，因存在有偏的投影头导致的联邦模型不可靠性，提出了“组装投影头”（APH）方法以提高模型可靠性。

    

    联邦学习在面对异构数据时遇到重大挑战，导致性能下降和收敛问题。尽管在减轻此类影响方面取得了相当大的进展，但联邦模型的可靠性方面却被大多忽视。在本研究中，我们进行了大量实验，研究了通用和个性化联邦模型的可靠性。我们的探索揭示了一个重要发现：\textbf{当面对异构数据时，联邦模型表现出不可靠性}，表现为对分布测试数据的较差校准和对分布外数据的低不确定性水平。这种不可靠性主要归因于存在有偏的投影头，这些投影头为联邦模型引入了错误校准。受到这一发现的启发，我们提出了用于增强联邦模型可靠性的“组装投影头”（APH）方法。

    arXiv:2402.16255v1 Announce Type: cross  Abstract: Federated learning encounters substantial challenges with heterogeneous data, leading to performance degradation and convergence issues. While considerable progress has been achieved in mitigating such an impact, the reliability aspect of federated models has been largely disregarded. In this study, we conduct extensive experiments to investigate the reliability of both generic and personalized federated models. Our exploration uncovers a significant finding: \textbf{federated models exhibit unreliability when faced with heterogeneous data}, demonstrating poor calibration on in-distribution test data and low uncertainty levels on out-of-distribution data. This unreliability is primarily attributed to the presence of biased projection heads, which introduce miscalibration into the federated models. Inspired by this observation, we propose the "Assembled Projection Heads" (APH) method for enhancing the reliability of federated models. By
    
[^42]: 基于知识内容选择的主题到文章生成

    Topic-to-essay generation with knowledge-based content selection

    [https://arxiv.org/abs/2402.16248](https://arxiv.org/abs/2402.16248)

    该论文提出了一种基于知识内容选择的复制机制模型，通过整合丰富的语义知识和改进的前缀调整方法，使主题到文章生成任务中的文本生成多样性提高，并贡献了新的中文数据集。

    

    主题到文章生成任务是一项具有挑战性的自然语言生成任务，旨在根据给定的主题词生成具有高语义连贯性的段落级文本。先前的研究主要集中在引入外部知识，而忽略了生成文本多样性不足的问题。为了提高生成多样性，我们提出了一种新颖的带有内容选择模块的复制机制模型，将语言模型的丰富语义知识整合到解码器中。此外，我们引入了改进的前缀调整方法来训练模型，使其能够适应不同的输入复杂性。此外，我们为TEG任务贡献了一个新的中文数据集。实验结果表明，与最先进的方法相比，所提出的模型可以将生成的文本多样性提高35%至59%，同时保持高水平的主题一致性。

    arXiv:2402.16248v1 Announce Type: cross  Abstract: The topic-to-essay generation task is a challenging natural language generation task that aims to generate paragraph-level text with high semantic coherence based on a given set of topic words. Previous work has focused on the introduction of external knowledge, ignoring the insufficient generated text diversity. In order to improve the generation diversity, we propose a novel copy mechanism model with a content selection module that integrates rich semantic knowledge from the language model into the decoder. Furthermore, we introduce the improved prefix tuning method to train the model, enabling it to adapt to varying input complexities. In addition, we have contributed a new Chinese dataset for TEG tasks. Experimental results demonstrate that the proposed model can improve the generated text diversity by 35\% to 59\% compared to the state-of-the-art method, while maintaining a high level of topic consistency.
    
[^43]: HSONet：面向高分辨率遥感图像变化检测的孪生前景关联驱动困难样本优化网络

    HSONet:A Siamese foreground association-driven hard case sample optimization network for high-resolution remote sensing image change detection

    [https://arxiv.org/abs/2402.16242](https://arxiv.org/abs/2402.16242)

    提出了一个面向高分辨率遥感图像变化检测的孪生前景关联驱动困难样本优化网络，解决了变化检测模型学习困难案例时面临的不平衡和缺失性挑战

    

    在训练后期，模型进一步提高变化检测模型学习困难案例的能力依赖于模型对困难案例的学习；然而，学习困难案例有两个额外的挑战：（1）变化标签有限且倾向于只指向前景目标，然而困难案例在背景中普遍存在，导致优化损失函数侧重于前景目标并忽略背景的困难案例，我们称之为不平衡。（2）复杂情况，如光影、目标遮挡和季节变化，引发困难案例，并且在缺乏监督和场景信息的情况下，模型很难直接学习困难案例以准确获得变化信息的特征表示，我们称之为缺失性。我们提出了一个面向前景关联驱动的困难样本优化网络。

    arXiv:2402.16242v1 Announce Type: cross  Abstract: In the later training stages, further improvement of the models ability to determine changes relies on how well the change detection (CD) model learns hard cases; however, there are two additional challenges to learning hard case samples: (1) change labels are limited and tend to pointer only to foreground targets, yet hard case samples are prevalent in the background, which leads to optimizing the loss function focusing on the foreground targets and ignoring the background hard cases, which we call imbalance. (2) Complex situations, such as light shadows, target occlusion, and seasonal changes, induce hard case samples, and in the absence of both supervisory and scene information, it is difficult for the model to learn hard case samples directly to accurately obtain the feature representations of the change information, which we call missingness. We propose a Siamese foreground association-driven hard case sample optimization network 
    
[^44]: 具有理论保证的连续搜索空间中活跃水平集估计

    Active Level Set Estimation for Continuous Search Space with Theoretical Guarantee

    [https://arxiv.org/abs/2402.16237](https://arxiv.org/abs/2402.16237)

    提出了一种不需要任何离散化直接在连续搜索空间中工作的具有理论保证的活跃水平集估计算法

    

    许多现实世界应用中经常遇到的一个常见问题是水平集估计，其目标是确定函数域中函数高于或低于给定阈值的区域。 当函数是黑盒且评估成本高时，需要在最小的函数评估集中找到水平集。 现有方法通常假定为具有有限数据点集的离散搜索空间，用于函数评估和估计水平集。 当应用于连续搜索空间时，这些方法通常需要首先对空间进行离散化，这会导致结果不佳，同时需要高计算时间。 虽然一些方法适用于连续设定，但它们仍然缺乏对理论收敛的适当保证。 为了解决这一问题，我们提出了一种新颖算法，它不需要任何离散化，可以直接在连续搜索空间中工作。 我们的方法通过构建

    arXiv:2402.16237v1 Announce Type: cross  Abstract: A common problem encountered in many real-world applications is level set estimation where the goal is to determine the region in the function domain where the function is above or below a given threshold. When the function is black-box and expensive to evaluate, the level sets need to be found in a minimum set of function evaluations. Existing methods often assume a discrete search space with a finite set of data points for function evaluations and estimating the level sets. When applied to a continuous search space, these methods often need to first discretize the space which leads to poor results while needing high computational time. While some methods cater for the continuous setting, they still lack a proper guarantee for theoretical convergence. To address this problem, we propose a novel algorithm that does not need any discretization and can directly work in continuous search spaces. Our method suggests points by constructing 
    
[^45]: 人工智能与人类共同创作编程课程中的示例

    Human-AI Co-Creation of Worked Examples for Programming Classes

    [https://arxiv.org/abs/2402.16235](https://arxiv.org/abs/2402.16235)

    人工智能与人类合作创作Java编程课程的示例，以减轻教师逐行解释大量示例的负担

    

    工作示例（典型编程问题的解决方案，以某种语言的源代码呈现，并用于解释编程课程中的主题）是编程课程中最受欢迎的学习内容之一。大多数用于向学生展示这些示例的方法和工具都基于对示例代码的逐行解释。然而，教师很少有时间为编程课程中通常使用的大量示例提供逐行解释。本文探讨并评估了一种人工智能与人类合作的方法，用于为Java编程撰写示例。我们介绍了一个用于创建Java工作示例的编写系统，该系统生成代码解释的初始版本，并将其呈现给教师以在必要时进行编辑。我们还提出了一项评估使用此方法创建的解释质量的研究。

    arXiv:2402.16235v1 Announce Type: cross  Abstract: Worked examples (solutions to typical programming problems presented as a source code in a certain language and are used to explain the topics from a programming class) are among the most popular types of learning content in programming classes. Most approaches and tools for presenting these examples to students are based on line-by-line explanations of the example code. However, instructors rarely have time to provide line-by-line explanations for a large number of examples typically used in a programming class. In this paper, we explore and assess a human-AI collaboration approach to authoring worked examples for Java programming. We introduce an authoring system for creating Java worked examples that generates a starting version of code explanations and presents it to the instructor to edit if necessary.We also present a study that assesses the quality of explanations created with this approach
    
[^46]: GARNN: 一种可解释的图注意力循环神经网络，用于通过多元时间序列预测血糖水平

    GARNN: An Interpretable Graph Attentive Recurrent Neural Network for Predicting Blood Glucose Levels via Multivariate Time Series

    [https://arxiv.org/abs/2402.16230](https://arxiv.org/abs/2402.16230)

    提出了一种可解释的图注意力循环神经网络（GARNNs），用于通过多元时间序列预测血糖水平，并实现了更具解释性的变量贡献总结和特征图生成。

    

    精确预测未来血糖（BG）水平可以有效改善糖尿病患者的血糖管理，从而减少并发症，提高生活质量。本文提出了可解释的图注意力循环神经网络（GARNNs），用于建模多元时间序列（MTS），通过总结变量重要性解释变量贡献，并通过图注意机制生成特征图，而不是进行事后分析。我们在代表不同临床场景的四个数据集上评估了GARNNs。与十二种公认的基准方法相比，GARNNs不仅实现了BG预测的最新技术水平，还更具解释性。

    arXiv:2402.16230v1 Announce Type: cross  Abstract: Accurate prediction of future blood glucose (BG) levels can effectively improve BG management for people living with diabetes, thereby reducing complications and improving quality of life. The state of the art of BG prediction has been achieved by leveraging advanced deep learning methods to model multi-modal data, i.e., sensor data and self-reported event data, organised as multi-variate time series (MTS). However, these methods are mostly regarded as ``black boxes'' and not entirely trusted by clinicians and patients. In this paper, we propose interpretable graph attentive recurrent neural networks (GARNNs) to model MTS, explaining variable contributions via summarizing variable importance and generating feature maps by graph attention mechanisms instead of post-hoc analysis. We evaluate GARNNs on four datasets, representing diverse clinical scenarios. Upon comparison with twelve well-established baseline methods, GARNNs not only ach
    
[^47]: IR2：信息正则化用于信息检索

    IR2: Information Regularization for Information Retrieval

    [https://arxiv.org/abs/2402.16200](https://arxiv.org/abs/2402.16200)

    介绍了IR2，一种用于在合成数据生成过程中减少过拟合的信息正则化技术，在复杂查询的信息检索任务中表现出优越性能，同时将成本降低高达50%。

    

    有效地在训练数据有限的情况下进行信息检索（IR），特别是对于复杂查询，仍然是一项具有挑战性的任务。本文介绍了IR2，即信息检索的信息正则化，一种用于在合成数据生成过程中减少过拟合的技术。该方法在具有复杂查询特征的三个最近的IR任务上进行了测试：DORIS-MAE、ArguAna和WhatsThatBook。实验结果表明，我们的正则化技术不仅在所考虑的任务上优于先前的合成查询生成方法，而且还能将成本降低高达50％。此外，本文将不同阶段的三种正则化方法——输入、提示和输出进行了分类和探索，每种方法相对于没有正则化的模型均提供了不同程度的性能改进。

    arXiv:2402.16200v1 Announce Type: cross  Abstract: Effective information retrieval (IR) in settings with limited training data, particularly for complex queries, remains a challenging task. This paper introduces IR2, Information Regularization for Information Retrieval, a technique for reducing overfitting during synthetic data generation. This approach, representing a novel application of regularization techniques in synthetic data creation for IR, is tested on three recent IR tasks characterized by complex queries: DORIS-MAE, ArguAna, and WhatsThatBook. Experimental results indicate that our regularization techniques not only outperform previous synthetic query generation methods on the tasks considered but also reduce cost by up to 50%. Furthermore, this paper categorizes and explores three regularization methods at different stages of the query synthesis pipeline-input, prompt, and output-each offering varying degrees of performance improvement compared to models where no regulariz
    
[^48]: 基于提示的单阶段持续学习

    One-stage Prompt-based Continual Learning

    [https://arxiv.org/abs/2402.16189](https://arxiv.org/abs/2402.16189)

    通过直接使用中间层的令牌嵌入作为提示查询，这项研究引入了一种单阶段PCL框架，可以在减少50%计算成本的同时，保持准确度下降小于1%。

    

    提示驱动的持续学习（PCL）作为一种有望实现最先进性能的持续学习解决方案，因其在防止隐私侵犯和内存开销问题方面的表现而受到广泛关注。然而，现有的PCL方法面临着重大的计算负担，因为其中涉及两个ViT前馈阶段；一个用于生成提示查询以选择提示池中的提示的查询ViT，另一个是骨干ViT，用于在选择的提示和图像标记之间混合信息。为解决这个问题，我们通过直接使用中间层的令牌嵌入作为提示查询，引入了一种单阶段PCL框架。这种设计消除了查询ViT的额外前向阶段的需要，从而在训练和推理阶段将计算成本降低了约50%，并且在准确度下降不到1%的情况下。我们进一步引入了一种查询池正则化（QR）损失，用来规范

    arXiv:2402.16189v1 Announce Type: cross  Abstract: Prompt-based Continual Learning (PCL) has gained considerable attention as a promising continual learning solution as it achieves state-of-the-art performance while preventing privacy violation and memory overhead issues. Nonetheless, existing PCL approaches face significant computational burdens because of two Vision Transformer (ViT) feed-forward stages; one is for the query ViT that generates a prompt query to select prompts inside a prompt pool; the other one is a backbone ViT that mixes information between selected prompts and image tokens. To address this, we introduce a one-stage PCL framework by directly using the intermediate layer's token embedding as a prompt query. This design removes the need for an additional feed-forward stage for query ViT, resulting in ~50% computational cost reduction for both training and inference with marginal accuracy drop < 1%. We further introduce a Query-Pool Regularization (QR) loss that regul
    
[^49]: LLM如何指导强化学习？一种基于价值的方法

    How Can LLM Guide RL? A Value-Based Approach

    [https://arxiv.org/abs/2402.16181](https://arxiv.org/abs/2402.16181)

    本文研究了如何利用大型语言模型（LLM）提供的策略先验来增强强化学习（RL）算法的样本效率。

    

    强化学习（RL）已经成为通过改进未来的行动策略来解决序贯决策问题的事实标准实践，但是RL算法可能需要大量的试错交互来收集有用的反馈以进行改进。与此同时，最近大型语言模型（LLMs）的发展展示了在语言理解和生成方面令人印象深刻的能力，然而它们在探索和自我改进规划任务的能力上仍存在不足，缺乏基于反馈自主改进响应的能力。因此，在本文中，我们研究了LLM提供的策略先验如何增强RL算法的样本效率。具体而言，我们开发了一种名为LINVIT的算法，该算法将LLM引导作为价值型RL中的正则化因子，可以显著减少学习所需的数据量，特别是当……

    arXiv:2402.16181v1 Announce Type: cross  Abstract: Reinforcement learning (RL) has become the de facto standard practice for sequential decision-making problems by improving future acting policies with feedback. However, RL algorithms may require extensive trial-and-error interactions to collect useful feedback for improvement. On the other hand, recent developments in large language models (LLMs) have showcased impressive capabilities in language understanding and generation, yet they fall short in exploration and self-improvement capabilities for planning tasks, lacking the ability to autonomously refine their responses based on feedback. Therefore, in this paper, we study how the policy prior provided by the LLM can enhance the sample efficiency of RL algorithms. Specifically, we develop an algorithm named LINVIT that incorporates LLM guidance as a regularization factor in value-based RL, leading to significant reductions in the amount of data needed for learning, particularly when 
    
[^50]: GenNBV: 通用的主动式三维重建下一最佳视角策略

    GenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstruction

    [https://arxiv.org/abs/2402.16174](https://arxiv.org/abs/2402.16174)

    GenNBV提出了一种端到端的通用的下一最佳视角策略，通过采用强化学习框架和扩展到5D自由空间的动作空间，实现了无人机从任意视角进行扫描，甚至与未知几何体进行交互的能力，同时提出了多源状态嵌入以增强跨数据集的泛化能力。

    

    最近的神经辐射场的技术进步实现了大规模场景的真实数字化, 但是图像捕获过程仍然耗时且劳动密集。先前的研究尝试使用主动式三维重建的下一最佳视角（NBV）策略来自动化这一过程。然而，现有的NBV策略严重依赖手工设计的标准、有限的动作空间，或者是针对每个场景优化的表示。这些约束限制了它们在跨数据集中的泛化能力。为了克服这些问题，我们提出了GenNBV，一个端到端通用的NBV策略。我们的策略采用基于强化学习（RL）的框架，将典型有限的动作空间扩展到5D自由空间。它赋予了我们的代理机无人机在训练过程中可以从任何视角进行扫描，甚至可以与未见几何体进行交互。为了增强跨数据集的泛化能力，我们还提出了一种新颖的多源状态嵌入，包括几何、语义和动作表示。

    arXiv:2402.16174v1 Announce Type: cross  Abstract: While recent advances in neural radiance field enable realistic digitization for large-scale scenes, the image-capturing process is still time-consuming and labor-intensive. Previous works attempt to automate this process using the Next-Best-View (NBV) policy for active 3D reconstruction. However, the existing NBV policies heavily rely on hand-crafted criteria, limited action space, or per-scene optimized representations. These constraints limit their cross-dataset generalizability. To overcome them, we propose GenNBV, an end-to-end generalizable NBV policy. Our policy adopts a reinforcement learning (RL)-based framework and extends typical limited action space to 5D free space. It empowers our agent drone to scan from any viewpoint, and even interact with unseen geometries during training. To boost the cross-dataset generalizability, we also propose a novel multi-source state embedding, including geometric, semantic, and action repres
    
[^51]: 通信流量特征揭示物联网设备身份

    Communication Traffic Characteristics Reveal an IoT Devices Identity

    [https://arxiv.org/abs/2402.16173](https://arxiv.org/abs/2402.16173)

    通过通信流量特征识别物联网设备的机器学习模型对于网络安全至关重要。

    

    互联网物联网是21世纪的技术进步之一，可以提高生活水平。然而，它也带来了新类型的安全挑战，包括设备认证、流量类型分类以及在网络领域中恶意流量识别。本文提出了一种基于监督式机器学习的设备指纹模型，用于仅使用通信流量特征（或隐式标识符）识别网络连接的物联网设备。

    arXiv:2402.16173v1 Announce Type: cross  Abstract: Internet of Things (IoT) is one of the technological advancements of the twenty-first century which can improve living standards. However, it also imposes new types of security challenges, including device authentication, traffic types classification, and malicious traffic identification, in the network domain. Traditionally, internet protocol (IP) and media access control (MAC) addresses are utilized for identifying network-connected devices in a network, whilst these addressing schemes are prone to be compromised, including spoofing attacks and MAC randomization. Therefore, device identification using only explicit identifiers is a challenging task. Accurate device identification plays a key role in securing a network. In this paper, a supervised machine learning-based device fingerprinting (DFP) model has been proposed for identifying network-connected IoT devices using only communication traffic characteristics (or implicit identif
    
[^52]: 使用非线性方法和更多探针来探究编码信息的结构

    Hitting "Probe"rty with Non-Linearity, and More

    [https://arxiv.org/abs/2402.16168](https://arxiv.org/abs/2402.16168)

    使用非线性结构探针来探究编码信息的结构，并设计了简单有效的新方法，以及可视化框架来评估语言模型中的依存树结构。

    

    结构探针学习线性变换，以找到依存树如何嵌入语言模型的隐藏状态。我们引入非线性结构探针，重新设计了White等人介绍的非线性结构探针，使其设计更简单但有效。通过设计可视化框架，定性评估句子中两个单词在预测的依存树中的连接强度。我们利用该技术来理解哪种非线性探针变体擅长编码句法信息。此外，还用它定性研究了BERT在每个层中编码的依存树结构。

    arXiv:2402.16168v1 Announce Type: cross  Abstract: Structural probes learn a linear transformation to find how dependency trees are embedded in the hidden states of language models. This simple design may not allow for full exploitation of the structure of the encoded information. Hence, to investigate the structure of the encoded information to its full extent, we incorporate non-linear structural probes. We reformulate the design of non-linear structural probes introduced by White et al. making its design simpler yet effective. We also design a visualization framework that lets us qualitatively assess how strongly two words in a sentence are connected in the predicted dependency tree. We use this technique to understand which non-linear probe variant is good at encoding syntactical information. Additionally, we also use it to qualitatively investigate the structure of dependency trees that BERT encodes in each of its layers. We find that the radial basis function (RBF) is an effectiv
    
[^53]: ChatMusician：理解和生成具有LLM的音乐内在

    ChatMusician: Understanding and Generating Music Intrinsically with LLM

    [https://arxiv.org/abs/2402.16153](https://arxiv.org/abs/2402.16153)

    ChatMusician 是一个集成了内在音乐能力的开源LLM，通过对文本兼容的音乐表示法进行持续预训练和微调，能够理解和生成音乐，表现优于GPT-4基准模型。

    

    虽然大型语言模型（LLMs）在文本生成方面展现出令人印象深刻的能力，但我们发现它们的能力尚未推广到音乐，也就是人类的创造性语言。我们介绍了ChatMusician，这是一个开源的LLM，集成了内在的音乐能力。它基于对文本兼容的音乐表示法ABC记谱的持续预训练和微调LLaMA2，并且将音乐视为第二语言。ChatMusician可以使用纯文本标记器理解和生成音乐，而无需任何外部多模态神经结构或标记器。有趣的是，赋予音乐能力并不会损害语言能力，甚至可以达到略高的MMLU分数。我们的模型能够根据文本、和弦、旋律、主题、音乐形式等创作结构良好、完整长度的音乐，超越了GPT-4的基线。在我们精心策划的大学级音乐理解基准上，MusicTheory

    arXiv:2402.16153v1 Announce Type: cross  Abstract: While Large Language Models (LLMs) demonstrate impressive capabilities in text generation, we find that their ability has yet to be generalized to music, humanity's creative language. We introduce ChatMusician, an open-source LLM that integrates intrinsic musical abilities. It is based on continual pre-training and finetuning LLaMA2 on a text-compatible music representation, ABC notation, and the music is treated as a second language. ChatMusician can understand and generate music with a pure text tokenizer without any external multi-modal neural structures or tokenizers. Interestingly, endowing musical abilities does not harm language abilities, even achieving a slightly higher MMLU score. Our model is capable of composing well-structured, full-length music, conditioned on texts, chords, melodies, motifs, musical forms, etc, surpassing GPT-4 baseline. On our meticulously curated college-level music understanding benchmark, MusicTheory
    
[^54]: 从文本到转化：大型语言模型多功能性的全面审查

    From Text to Transformation: A Comprehensive Review of Large Language Models' Versatility

    [https://arxiv.org/abs/2402.16142](https://arxiv.org/abs/2402.16142)

    该研究探讨了大型语言模型在各领域的多功能性，提出了LLMs在健身、城市规划、气候建模和灾难响应等领域中的潜在影响和创新方法。

    

    这项开创性的研究探讨了大型语言模型（LLMs）如生成式预训练变换器（GPT）和双向编码器表示来自变换器（BERT）在从技术、金融、医疗保健到教育等各领域的扩展。尽管这些LLMs在自然语言处理（NLP）中已经表现出色，但尚未系统地研究过它们对健身、整体幸福感、城市规划、气候建模以及灾害管理等领域的影响。除了全面分析LLMs在不同领域的广泛利用程度之外，该综述论文还识别了LLMs潜力尚未得到利用的研究空白和领域。该研究揭示了LLMs可以在健身与幸福、城市规划、气候建模和灾害响应等领域留下痕迹的创新方法，这可能会激励他人。

    arXiv:2402.16142v1 Announce Type: cross  Abstract: This groundbreaking study explores the expanse of Large Language Models (LLMs), such as Generative Pre-Trained Transformer (GPT) and Bidirectional Encoder Representations from Transformers (BERT) across varied domains ranging from technology, finance, healthcare to education. Despite their established prowess in Natural Language Processing (NLP), these LLMs have not been systematically examined for their impact on domains such as fitness, and holistic well-being, urban planning, climate modelling as well as disaster management. This review paper, in addition to furnishing a comprehensive analysis of the vast expanse and extent of LLMs' utility in diverse domains, recognizes the research gaps and realms where the potential of LLMs is yet to be harnessed. This study uncovers innovative ways in which LLMs can leave a mark in the fields like fitness and wellbeing, urban planning, climate modelling and disaster response which could inspire 
    
[^55]: 生成人工智能对术语定义的意义

    What Generative Artificial Intelligence Means for Terminological Definitions

    [https://arxiv.org/abs/2402.16139](https://arxiv.org/abs/2402.16139)

    生成人工智能工具如ChatGPT在提供定制化的语境特定含义方面表现出色，但在准确性方面存在挑战，可以辅助术语学家进行术语编纂，实现AI效率与人类专业知识的结合。

    

    本文探讨了生成人工智能（GenAI）对术语定义的创建和消费的影响。像ChatGPT这样的GenAI工具与传统术语资源相比，带来了一系列益处和挑战。ChatGPT在以交互式和定制化的方式提供特定语境含义方面表现出色，但在准确性方面面临挑战。识别资源中的术语定义可能会因其可靠性而继续存在。从术语学家的角度来看，诸如ChatGPT之类的工具使得AI辅助的术语编纂成为可能，包括后期编辑术语编纂，将AI效率与人类专业知识相结合，以实现更快速的定义创建。

    arXiv:2402.16139v1 Announce Type: cross  Abstract: This paper examines the impact of Generative Artificial Intelligence (GenAI) on the creation and consumption of terminological definitions. GenAI tools like ChatGPT present a mix of benefits and drawbacks compared to traditional terminological resources. ChatGPT excels in providing context-specific meanings in an interactive and customized fashion but faces challenges with accuracy. Terminological definitions in recognized resources will likely survive because of their reliability. From the point of view of the terminologist, tools like ChatGPT enable AI-assisted terminography, including post-editing terminography, as an approach blending AI efficiency with human expertise for faster definition creation.
    
[^56]: LSTPrompt: 长短期提示下的大型语言模型作为零-shot时间序列预测器

    LSTPrompt: Large Language Models as Zero-Shot Time Series Forecasters by Long-Short-Term Prompting

    [https://arxiv.org/abs/2402.16132](https://arxiv.org/abs/2402.16132)

    LSTPrompt提出了一种新颖的方法，将时间序列预测任务分解为短期和长期预测子任务，并为每个子任务量身定制提示，旨在提高大型语言模型在零shot时间序列预测中的适应性和性能。

    

    时间序列预测在现实场景中有着广泛的应用。利用现成的大型语言模型进行提示展现了强大的零shot时间序列预测能力，同时保持计算效率。然而，现有的提示方法过分简化了时间序列预测，将其视为语言下一个标记的预测，忽视了其动态性以及与最先进的提示策略（如Chain-of-Thought）的融合。因此，我们提出了LSTPrompt，一种用于在零shot时间序列预测任务中提示LLMs的新方法。LSTPrompt将时间序列预测分解为短期和长期预测子任务，并为每个子任务量身定制提示。LSTPrompt引导LLMs定期重新评估预测机制，以增强适应性。广泛的评估表明，与现有的提示方法相比，LSTPrompt的性能始终更好，并且与基本时间序列预测模型相比具有竞争力。

    arXiv:2402.16132v1 Announce Type: cross  Abstract: Time-series forecasting (TSF) finds broad applications in real-world scenarios. Prompting off-the-shelf Large Language Models (LLMs) demonstrates strong zero-shot TSF capabilities while preserving computational efficiency. However, existing prompting methods oversimplify TSF as language next-token predictions, overlooking its dynamic nature and lack of integration with state-of-the-art prompt strategies such as Chain-of-Thought. Thus, we propose LSTPrompt, a novel approach for prompting LLMs in zero-shot TSF tasks. LSTPrompt decomposes TSF into short-term and long-term forecasting sub-tasks, tailoring prompts to each. LSTPrompt guides LLMs to regularly reassess forecasting mechanisms to enhance adaptability. Extensive evaluations demonstrate consistently better performance of LSTPrompt than existing prompting methods, and competitive results compared to foundation TSF models.
    
[^57]: InstructEdit：针对大型语言模型的基于指令的知识编辑

    InstructEdit: Instruction-based Knowledge Editing for Large Language Models

    [https://arxiv.org/abs/2402.16123](https://arxiv.org/abs/2402.16123)

    InstructEdit提出了一种基于指令的知识编辑技术，通过简单指令使编辑器适应不同任务的表现，显著提高了多任务编辑中的可靠性。

    

    大型语言模型的知识编辑可以提供一种有效的解决方案，以改变模型的行为而不会对整体性能产生消极影响。然而，当前的方法在跨任务的通用性方面存在问题，需要为每个任务设计一个独特的编辑器，这显著阻碍了更广泛的应用。为了解决这一问题，我们首先分析了知识编辑中的多任务泛化问题。具体地，我们开发了一种基于指令的编辑技术，称为InstructEdit，通过简单的指令促进编辑器同时适应各种任务的表现。通过为每个LLM只使用一个统一的编辑器，我们在实证方面表明，InstructEdit可以提高编辑器的控制能力，从而在多任务编辑设置中平均提高可靠性14.86%。此外，涉及保留未见任务的实验说明，InstructEdi

    arXiv:2402.16123v1 Announce Type: cross  Abstract: Knowledge editing for large language models can offer an efficient solution to alter a model's behavior without negatively impacting the overall performance. However, the current approach encounters issues with limited generalizability across tasks, necessitating one distinct editor for each task, which significantly hinders the broader applications. To address this, we take the first step to analyze the multi-task generalization issue in knowledge editing. Specifically, we develop an instruction-based editing technique, termed InstructEdit, which facilitates the editor's adaptation to various task performances simultaneously using simple instructions. With only one unified editor for each LLM, we empirically demonstrate that InstructEdit can improve the editor's control, leading to an average 14.86% increase in Reliability in multi-task editing setting. Furthermore, experiments involving holdout unseen task illustrate that InstructEdi
    
[^58]: 为重新参数化模型实现准确的后训练量化

    Towards Accurate Post-training Quantization for Reparameterized Models

    [https://arxiv.org/abs/2402.16121](https://arxiv.org/abs/2402.16121)

    提出了一个新框架RepAPQ，利用平均绝对误差（MAE）来减轻异常值对量化参数的影响，从而保持量化后重新参数化模型的准确性

    

    模型重新参数化是一种被广泛接受的技术，可以在不损害性能的情况下提高推断速度。然而，当前的后训练量化（PTQ）方法在应用于重新参数化模型时往往会导致显著的准确性下降。这主要是由特定样本和通道上出现的异常值所导致的，这些异常值仅出现在特定的样本和通道上，并对量化参数的选择产生影响。为了解决这个问题，我们提出了RepAPQ，这是一个新颖的框架，可以保持量化后重新参数化模型的准确性。与以往使用均方误差（MSE）作为度量的框架不同，我们利用平均绝对误差（MAE）来减轻异常值对量化参数的影响。我们的框架包括两个主要组件：保护量化重新参数化和跨块校准。为了有效校准，请了解保护量化重新参数化

    arXiv:2402.16121v1 Announce Type: cross  Abstract: Model reparameterization is a widely accepted technique for improving inference speed without compromising performance. However, current Post-training Quantization (PTQ) methods often lead to significant accuracy degradation when applied to reparameterized models. This is primarily caused by channel-specific and sample-specific outliers, which appear only at specific samples and channels and impact on the selection of quantization parameters. To address this issue, we propose RepAPQ, a novel framework that preserves the accuracy of quantized reparameterization models. Different from previous frameworks using Mean Squared Error (MSE) as a measurement, we utilize Mean Absolute Error (MAE) to mitigate the influence of outliers on quantization parameters. Our framework comprises two main components: Quantization Protecting Reparameterization and Across-block Calibration. For effective calibration, Quantization Protecting Reparameterization
    
[^59]: RoboCodeX: 用于机器人行为合成的多模态代码生成

    RoboCodeX: Multimodal Code Generation for Robotic Behavior Synthesis

    [https://arxiv.org/abs/2402.16117](https://arxiv.org/abs/2402.16117)

    提出了一种用于泛化机器人行为合成的树状多模态代码生成框架，具有将高级人类指令转化为机器人动作的泛化能力。

    

    机器人行为合成是理解多模态输入并为机器人生成精确物理控制的问题，是具有体现特征的人工智能的重要部分。尽管在应用多模态大型语言模型进行高级理解方面取得了成功，但将这些概念理解转化为详细的机器人动作，在实现跨不同场景的泛化时仍然具有挑战性。本文提出了一种用于泛化机器人行为合成的树状多模态代码生成框架，名为RoboCodeX。RoboCodeX将高级人类指令分解为由物理偏好（如可用性和安全约束）组成的多个物体中心操纵单元，并应用代码生成来实现在不同机器人平台上的泛化能力。为了进一步增强将概念和感知理解映射到控制指令的能力，一种专门的

    arXiv:2402.16117v1 Announce Type: cross  Abstract: Robotic behavior synthesis, the problem of understanding multimodal inputs and generating precise physical control for robots, is an important part of Embodied AI. Despite successes in applying multimodal large language models for high-level understanding, it remains challenging to translate these conceptual understandings into detailed robotic actions while achieving generalization across various scenarios. In this paper, we propose a tree-structured multimodal code generation framework for generalized robotic behavior synthesis, termed RoboCodeX. RoboCodeX decomposes high-level human instructions into multiple object-centric manipulation units consisting of physical preferences such as affordance and safety constraints, and applies code generation to introduce generalization ability across various robotics platforms. To further enhance the capability to map conceptual and perceptual understanding into control commands, a specialized 
    
[^60]: 个性化联邦学习参数选择的贝叶斯神经网络

    Bayesian Neural Network For Personalized Federated Learning Parameter Selection

    [https://arxiv.org/abs/2402.16091](https://arxiv.org/abs/2402.16091)

    通过引入贝叶斯神经网络，本研究提出在元素级别而非传统的层级上进行个性化，以选择个性化参数。

    

    联邦学习在存在异构数据时性能不佳仍然是该领域最为紧迫的问题之一。个性化联邦学习偏离传统范式，其中所有客户端使用相同模型，而是努力为每个客户端发现一个个性化模型，以解决数据中的异质性。一种方法涉及个性化神经网络的特定层。然而，先前的努力并没有提供可靠的理由，有些选择了完全不同且相互冲突的个性化层。在这项工作中，我们更进一步，提议在元素级别进行个性化，而不是传统的层级个性化。为了选择个性化参数，我们引入了贝叶斯神经网络，并依赖它们提供的不确定性来指导我们选择个性化参数。

    arXiv:2402.16091v1 Announce Type: cross  Abstract: Federated learning's poor performance in the presence of heterogeneous data remains one of the most pressing issues in the field. Personalized federated learning departs from the conventional paradigm in which all clients employ the same model, instead striving to discover an individualized model for each client to address the heterogeneity in the data. One of such approach involves personalizing specific layers of neural networks. However, prior endeavors have not provided a dependable rationale, and some have selected personalized layers that are entirely distinct and conflicting. In this work, we take a step further by proposing personalization at the elemental level, rather than the traditional layer-level personalization. To select personalized parameters, we introduce Bayesian neural networks and rely on the uncertainty they offer to guide our selection of personalized parameters. Finally, we validate our algorithm's efficacy on 
    
[^61]: 用于视觉地点识别的深度单应性估计

    Deep Homography Estimation for Visual Place Recognition

    [https://arxiv.org/abs/2402.16086](https://arxiv.org/abs/2402.16086)

    提出了一种基于Transformer的深度单应性估计网络，用于快速和可学习的几何验证。

    

    视觉地点识别(VPR)是许多应用程序的基本任务，如机器人定位和增强现实。最近，由于准确性和效率之间的权衡，分层VPR方法受到了广泛关注。它们通常首先使用全局特征来检索候选图像，然后验证匹配的局部特征的空间一致性以进行重新排序。然而，后者通常依赖于RANSAC算法进行单应性拟合，这是耗时且不可微分的。这导致现有方法只能在全局特征提取中训练网络。在这里，我们提出了一种基于Transformer的深度单应性估计(DHE)网络，其以由主干网络提取的密集特征图为输入，并适合于快速和可学习的几何验证。此外，我们设计了一个内点重投影误差损失来训练DHE网络，无需添加额外......

    arXiv:2402.16086v1 Announce Type: cross  Abstract: Visual place recognition (VPR) is a fundamental task for many applications such as robot localization and augmented reality. Recently, the hierarchical VPR methods have received considerable attention due to the trade-off between accuracy and efficiency. They usually first use global features to retrieve the candidate images, then verify the spatial consistency of matched local features for re-ranking. However, the latter typically relies on the RANSAC algorithm for fitting homography, which is time-consuming and non-differentiable. This makes existing methods compromise to train the network only in global feature extraction. Here, we propose a transformer-based deep homography estimation (DHE) network that takes the dense feature map extracted by a backbone network as input and fits homography for fast and learnable geometric verification. Moreover, we design a re-projection error of inliers loss to train the DHE network without addit
    
[^62]: 基于插值的策略扩散的行为细化

    Behavioral Refinement via Interpolant-based Policy Diffusion

    [https://arxiv.org/abs/2402.16075](https://arxiv.org/abs/2402.16075)

    使用比高斯更具信息量的源头启动扩散方法有助于克服模仿学习任务中的限制。

    

    模仿学习使人工智能代理通过从演示中学习来模仿行为。最近，拥有建模高维度和多模态分布能力的扩散模型在模仿学习任务上表现出色。这些模型通过将动作（或状态）从标准高斯噪声中扩散来塑造策略。然而，要学习的目标策略通常与高斯分布显著不同，这种不匹配可能导致在使用少量扩散步骤（以提高推理速度）和有限数据下性能不佳。这项工作的关键思想是，从比高斯更具信息量的源头开始，可以使扩散方法克服上述限制。我们提供了理论结果、一种新方法和实证发现，展示了使用信息量丰富的源策略的好处。我们的方法，称为BRIDGER，利用了随机性。

    arXiv:2402.16075v1 Announce Type: cross  Abstract: Imitation learning empowers artificial agents to mimic behavior by learning from demonstrations. Recently, diffusion models, which have the ability to model high-dimensional and multimodal distributions, have shown impressive performance on imitation learning tasks. These models learn to shape a policy by diffusing actions (or states) from standard Gaussian noise. However, the target policy to be learned is often significantly different from Gaussian and this mismatch can result in poor performance when using a small number of diffusion steps (to improve inference speed) and under limited data. The key idea in this work is that initiating from a more informative source than Gaussian enables diffusion methods to overcome the above limitations. We contribute both theoretical results, a new method, and empirical findings that show the benefits of using an informative source policy. Our method, which we call BRIDGER, leverages the stochast
    
[^63]: 使用预计算的嵌入相似性生成几乎实时个性化信息流

    Pfeed: Generating near real-time personalized feeds using precomputed embedding similarities

    [https://arxiv.org/abs/2402.16073](https://arxiv.org/abs/2402.16073)

    使用预计算的嵌入相似性生成个性化信息流，提高了电子商务平台上的客户参与度和体验，转化率提升4.9％。

    

    在个性化推荐系统中，通常使用嵌入来编码用户动作和项目，然后在嵌入空间中进行检索，使用近似最近邻搜索。然而，这种方法可能会导致两个挑战：1）用户嵌入可能限制所捕获的兴趣多样性，2）保持它们最新需要昂贵的实时基础设施。本文提出了一种在实际工业环境中克服这些挑战的方法。该方法动态更新客户配置文件，并每两分钟组成一个信息流，利用预计算的嵌入及其各自的相似性。我们在荷兰和比利时最大的电子商务平台之一Bol上测试并部署了这种方法，该方法提高了客户参与度和体验，导致转化率显著提高了4.9％。

    arXiv:2402.16073v1 Announce Type: cross  Abstract: In personalized recommender systems, embeddings are often used to encode customer actions and items, and retrieval is then performed in the embedding space using approximate nearest neighbor search. However, this approach can lead to two challenges: 1) user embeddings can restrict the diversity of interests captured and 2) the need to keep them up-to-date requires an expensive, real-time infrastructure. In this paper, we propose a method that overcomes these challenges in a practical, industrial setting. The method dynamically updates customer profiles and composes a feed every two minutes, employing precomputed embeddings and their respective similarities. We tested and deployed this method to personalise promotional items at Bol, one of the largest e-commerce platforms of the Netherlands and Belgium. The method enhanced customer engagement and experience, leading to a significant 4.9% uplift in conversions.
    
[^64]: ROS-Causal：基于ROS的人机交互应用因果分析框架

    ROS-Causal: A ROS-based Causal Analysis Framework for Human-Robot Interaction Applications

    [https://arxiv.org/abs/2402.16068](https://arxiv.org/abs/2402.16068)

    ROS-Causal是一个基于ROS的框架，用于在人机空间交互中进行数据收集和因果发现，解决了机器人领域中缺乏因果发现方法在ROS生态系统内实现的问题。

    

    在人类共享空间部署机器人需要理解附近Agent和物体之间的交互。通过因果推理对因果关系建模有助于预测人类行为并预测机器人干预。然而，一个关键挑战是现有的因果发现方法目前缺乏在ROS生态系统内部的实现，这是机器人领域的事实标准，阻碍了在机器人领域的有效利用。为了解决这一差距，本文引入了ROS-Causal，这是一个基于ROS的框架，用于机器人上的数据收集和因果发现在人机空间交互中。集成了ROS的临时模拟器展示了该方法的有效性，展示了机器人在数据收集过程中生成因果模型。ROS-Causal可在GitHub上找到：https://github.com/lcastri/roscausal.git。

    arXiv:2402.16068v1 Announce Type: cross  Abstract: Deploying robots in human-shared spaces requires understanding interactions among nearby agents and objects. Modelling cause-and-effect relations through causal inference aids in predicting human behaviours and anticipating robot interventions. However, a critical challenge arises as existing causal discovery methods currently lack an implementation inside the ROS ecosystem, the standard de facto in robotics, hindering effective utilisation in robotics. To address this gap, this paper introduces ROS-Causal, a ROS-based framework for onboard data collection and causal discovery in human-robot spatial interactions. An ad-hoc simulator, integrated with ROS, illustrates the approach's effectiveness, showcasing the robot onboard generation of causal models during data collection. ROS-Causal is available on GitHub: https://github.com/lcastri/roscausal.git.
    
[^65]: 基于引文增强的LLM聊天机器人生成

    Citation-Enhanced Generation for LLM-based Chatbot

    [https://arxiv.org/abs/2402.16063](https://arxiv.org/abs/2402.16063)

    提出一种基于引文增强的LLM聊天机器人生成方法，采用检索模块搜索支持文档来解决幻觉内容产生的问题。

    

    大型语言模型（LLMs）在各种情景下展现出强大的通用智能，包括将它们集成到聊天机器人中。然而，基于LLM的聊天机器人面临的一个重要挑战是在回复中可能产生虚构内容，这严重限制了它们的适用性。本文提出了一种新颖的后续引用增强生成（CEG）方法，结合检索论证。与先前侧重于预防生成过程中幻觉的研究不同，我们的方法以后续方式解决了这个问题。它结合了一个检索模块来搜索与生成内容相关的支持文档，并采用基于自然语言推理的方法。

    arXiv:2402.16063v1 Announce Type: cross  Abstract: Large language models (LLMs) exhibit powerful general intelligence across diverse scenarios, including their integration into chatbots. However, a vital challenge of LLM-based chatbots is that they may produce hallucinated content in responses, which significantly limits their applicability. Various efforts have been made to alleviate hallucination, such as retrieval augmented generation and reinforcement learning with human feedback, but most of them require additional training and data annotation. In this paper, we propose a novel post-hoc \textbf{C}itation-\textbf{E}nhanced \textbf{G}eneration (\textbf{CEG}) approach combined with retrieval argumentation. Unlike previous studies that focus on preventing hallucinations during generation, our method addresses this issue in a post-hoc way. It incorporates a retrieval module to search for supporting documents relevant to the generated content, and employs a natural language inference-ba
    
[^66]: 用于重要救援行动的最大化无人机雾部署效率

    Maximizing UAV Fog Deployment Efficiency for Critical Rescue Operations

    [https://arxiv.org/abs/2402.16052](https://arxiv.org/abs/2402.16052)

    提出了一个围绕动态无人机雾部署的新模型，以优化系统在受灾地区的适应性和运营效率

    

    在灾难场景和高风险救援行动中，将无人机（UAVs）作为雾节点整合已变得至关重要。这种整合确保了受影响人群与基本健康监测设备之间的顺畅连接，由物联网（IoT）支持。本文提出了一个围绕动态无人机雾部署的新模型，优化了系统在受灾地区的适应性和运营效率。我们首先将问题分解为两个子问题，即连接和覆盖子问题，以及网络寿命优化子问题。

    arXiv:2402.16052v1 Announce Type: cross  Abstract: In disaster scenarios and high-stakes rescue operations, integrating Unmanned Aerial Vehicles (UAVs) as fog nodes has become crucial. This integration ensures a smooth connection between affected populations and essential health monitoring devices, supported by the Internet of Things (IoT). Integrating UAVs in such environments is inherently challenging, where the primary objectives involve maximizing network connectivity and coverage while extending the network's lifetime through energy-efficient strategies to serve the maximum number of affected individuals. In this paper, We propose a novel model centred around dynamic UAV-based fog deployment that optimizes the system's adaptability and operational efficacy within the afflicted areas. First, we decomposed the problem into two subproblems. Connectivity and coverage subproblem, and network lifespan optimization subproblem. We shape our UAV fog deployment problem as a uni-objective op
    
[^67]: LLMs带有思维链条是非因果推理者

    LLMs with Chain-of-Thought Are Non-Causal Reasoners

    [https://arxiv.org/abs/2402.16048](https://arxiv.org/abs/2402.16048)

    本文探讨了大型语言模型在推理过程中思维链条（CoT）的作用，发现LLMs在答案生成过程中与人类推理存在差异，相关因素包括语境学习、有监督微调以及对人类反馈的强化学习。

    

    本文探讨了大型语言模型（LLMs）推理中思维链条（CoT）的作用。尽管它有改善任务性能的潜力，但我们的分析揭示了在LLMs中正确答案跟随不正确CoTs的频率及反之。我们采用因果分析来评估CoTs/指令与LLMs答案之间的因果关系，揭示LLMs近似的结构因果模型（SCM）。通过比较暗示SCM与人类推理的SCM，我们突显了LLM和人类推理过程之间的差异。我们进一步研究了影响暗示SCM因果结构的因素，揭示了语境学习、有监督微调以及对人类反馈的强化学习显著影响因果关系。我们在https://github.com/StevenZHB/CoT_Causal_Analysis发布了代码和结果。

    arXiv:2402.16048v1 Announce Type: cross  Abstract: This paper explores the role of the Chain of Thought (CoT) in Large Language Models (LLMs) reasoning. Despite its potential to improve task performance, our analysis reveals a surprising frequency of correct answers following incorrect CoTs and vice versa. We employ causal analysis to assess the cause-effect relationship between CoTs/instructions and answers in LLMs, uncovering the Structural Causal Model (SCM) that LLMs approximate. By comparing the implied SCM with that of human reasoning, we highlight discrepancies between LLM and human reasoning processes. We further examine the factors influencing the causal structure of the implied SCM, revealing that in-context learning, supervised fine-tuning, and reinforcement learning on human feedback significantly impact the causal relations. We release the code and results at https://github.com/StevenZHB/CoT_Causal_Analysis.
    
[^68]: 深度学习方法用于改进肝细胞癌研究中的问答系统

    Deep Learning Approaches for Improving Question Answering Systems in Hepatocellular Carcinoma Research

    [https://arxiv.org/abs/2402.16038](https://arxiv.org/abs/2402.16038)

    深度学习技术在问答系统领域取得的成就，尤其是在肝细胞癌研究中，极大地推动了自然语言处理的发展。

    

    近年来，自然语言处理（NLP）领域的进展受益于深度学习技术的发展，特别是通过利用诸如GPU和TPU等强大的计算资源。像BERT和GPT-3这样的模型，在大量数据的训练下，彻底改变了语言理解和生成。这些预训练模型为各种任务提供了坚实的基础，包括语义理解、智能写作和推理，为更通用的人工智能铺平了道路。作为人工智能的一个重要应用，NLP旨在通过自然语言交互来弥合人与计算机之间的差距。本文深入探讨了基于大规模模型的NLP的当前格局和未来展望，重点放在这一领域内的问答系统上。分析了人工智能驱动的问答系统的实际案例和发展，以促进进一步的探索。

    arXiv:2402.16038v1 Announce Type: cross  Abstract: In recent years, advancements in natural language processing (NLP) have been fueled by deep learning techniques, particularly through the utilization of powerful computing resources like GPUs and TPUs. Models such as BERT and GPT-3, trained on vast amounts of data, have revolutionized language understanding and generation. These pre-trained models serve as robust bases for various tasks including semantic understanding, intelligent writing, and reasoning, paving the way for a more generalized form of artificial intelligence. NLP, as a vital application of AI, aims to bridge the gap between humans and computers through natural language interaction. This paper delves into the current landscape and future prospects of large-scale model-based NLP, focusing on the question-answering systems within this domain. Practical cases and developments in artificial intelligence-driven question-answering systems are analyzed to foster further explora
    
[^69]: 使用Transformer模型进行智能电子商务推荐的文本理解和生成

    Text Understanding and Generation Using Transformer Models for Intelligent E-commerce Recommendations

    [https://arxiv.org/abs/2402.16035](https://arxiv.org/abs/2402.16035)

    本文回顾了Transformer预训练模型在电子商务领域的核心应用，包括文本理解和生成推荐系统等方面，在自动生成产品描述、情感分析、个性化推荐系统构建和客服对话自动处理等方面均取得了积极效果。

    

    随着人工智能技术的快速发展，Transformer结构的预训练模型已成为大型语言模型（LLM）任务的重要工具。在电子商务领域，这些模型特别广泛使用，从文本理解到生成推荐系统，为改善用户体验和优化服务流程提供了强大的技术支持。本文回顾了Transformer预训练模型在电子商务文本理解和推荐生成中的核心应用场景，包括但不限于产品描述的自动生成，用户评论的情感分析，个性化推荐系统的构建以及客户服务对话的自动处理。通过对模型的工作原理、实现过程和特定案例中的应用效果进行详细分析，本文强调了其独特优势。

    arXiv:2402.16035v1 Announce Type: cross  Abstract: With the rapid development of artificial intelligence technology, Transformer structural pre-training model has become an important tool for large language model (LLM) tasks. In the field of e-commerce, these models are especially widely used, from text understanding to generating recommendation systems, which provide powerful technical support for improving user experience and optimizing service processes. This paper reviews the core application scenarios of Transformer pre-training model in e-commerce text understanding and recommendation generation, including but not limited to automatic generation of product descriptions, sentiment analysis of user comments, construction of personalized recommendation system and automated processing of customer service conversations. Through a detailed analysis of the model's working principle, implementation process, and application effects in specific cases, this paper emphasizes the unique advan
    
[^70]: 使用深度学习技术在短英文文本中进行情绪分类

    Emotion Classification in Short English Texts using Deep Learning Techniques

    [https://arxiv.org/abs/2402.16034](https://arxiv.org/abs/2402.16034)

    该研究使用深度学习技术在短英文文本中识别情绪，发现基于迁移学习和BERT的文本嵌入方法在分类准确性上表现优异。

    

    从资源匮乏的语言中的有限文本数据集中检测情绪是一项严峻的挑战，需要专门的框架和计算策略。本研究对使用深度学习技术在短英文文本中识别情绪进行了彻底的研究。深度学习方法采用迁移学习和词嵌入，特别是BERT，以获得更高的准确性。为了评估这些方法，我们引入了“SmallEnglishEmotions”数据集，该数据集包含6372个带有五种主要情绪类别注释的不同短波斯文本。我们的实验表明，迁移学习和基于BERT的文本嵌入在准确分类数据集中的文本方面优于替代方法。

    arXiv:2402.16034v1 Announce Type: cross  Abstract: Detecting emotions in limited text datasets from under-resourced languages presents a formidable obstacle, demanding specialized frameworks and computational strategies. This study conducts a thorough examination of deep learning techniques for discerning emotions in short English texts. Deep learning approaches employ transfer learning and word embedding, notably BERT, to attain superior accuracy. To evaluate these methods, we introduce the "SmallEnglishEmotions" dataset, comprising 6372 varied short Persian texts annotated with five primary emotion categories. Our experiments reveal that transfer learning and BERT-based text embedding outperform alternative methods in accurately categorizing the text in the dataset.
    
[^71]: 不要忘记您的奖励价值: 通过基于价值的校准实现语言模型的对齐

    Don't Forget Your Reward Values: Language Model Alignment via Value-based Calibration

    [https://arxiv.org/abs/2402.16030](https://arxiv.org/abs/2402.16030)

    本文提出了一种基于价值的校准（VCB）方法，以解决大型语言模型与人类偏好之间的对齐问题，并在实验中表现出比现有方法更好的通用性、稳健性和稳定性。

    

    从人类反馈中进行强化学习（RLHF）显著提高了大型语言模型（LLM）的生成质量，但最近的研究提出了对近端策略优化（PPO）算法复杂性和不稳定性的担忧，提议一系列基于顺序的校准方法作为可行的替代方法。本文进一步探讨了当前基于顺序的方法，检查它们在利用奖励价值和解决不对齐问题方面的低效性。基于这些发现，我们提出了一种新颖的基于价值的校准（VCB）方法，以更好地使LLMs与人类偏好对齐。实验结果表明，VCB在AI助手和摘要数据集上超越了现有的对齐方法，在各种环境中提供了令人印象深刻的通用性、稳健性和稳定性。

    arXiv:2402.16030v1 Announce Type: cross  Abstract: While Reinforcement Learning from Human Feedback (RLHF) significantly enhances the generation quality of Large Language Models (LLMs), recent studies have raised concerns regarding the complexity and instability associated with the Proximal Policy Optimization (PPO) algorithm, proposing a series of order-based calibration methods as viable alternatives. This paper delves further into current order-based methods, examining their inefficiencies in utilizing reward values and addressing misalignment issues. Building upon these findings, we propose a novel \textbf{V}alue-based \textbf{C}ali\textbf{B}ration (VCB) method to better align LLMs with human preferences. Experimental results demonstrate that VCB surpasses existing alignment methods on AI assistant and summarization datasets, providing impressive generalizability, robustness, and stability in diverse settings.
    
[^72]: TMT: 通过将不同模态视为不同语言来实现语音、图像和文本之间的三模翻译

    TMT: Tri-Modal Translation between Speech, Image, and Text by Processing Different Modalities as Different Languages

    [https://arxiv.org/abs/2402.16021](https://arxiv.org/abs/2402.16021)

    将不同模态解释为不同语言，在语音、图像和文本之间实现了三模翻译，大大减少了计算成本。

    

    能够共同处理多模态信息正在成为一项重要任务。然而，有限的配对多模态数据和多模态学习中的大量计算要求阻碍了发展。我们提出了一种新颖的三模翻译（TMT）模型，可以在涵盖语音、图像和文本的任意模态之间进行翻译。我们引入了一个新颖的观点，即将不同模态解释为不同语言，并将多模态翻译视为一个成熟的机器翻译问题。为此，我们将语音和图像数据标记为离散标记，提供了跨模态的统一接口，并大大降低了计算成本。在提出的TMT中，多模态编码器-解码器进行核心翻译，而模态特定处理仅在标记化和去标记化阶段内进行。我们在所有六种模态上评估了提出的TMT。

    arXiv:2402.16021v1 Announce Type: cross  Abstract: The capability to jointly process multi-modal information is becoming an essential task. However, the limited number of paired multi-modal data and the large computational requirements in multi-modal learning hinder the development. We propose a novel Tri-Modal Translation (TMT) model that translates between arbitrary modalities spanning speech, image, and text. We introduce a novel viewpoint, where we interpret different modalities as different languages, and treat multi-modal translation as a well-established machine translation problem. To this end, we tokenize speech and image data into discrete tokens, which provide a unified interface across modalities and significantly decrease the computational cost. In the proposed TMT, a multi-modal encoder-decoder conducts the core translation, whereas modality-specific processing is conducted only within the tokenization and detokenization stages. We evaluate the proposed TMT on all six mod
    
[^73]: 在科学计算规模上构建灵活的机器学习模型

    Building Flexible Machine Learning Models for Scientific Computing at Scale

    [https://arxiv.org/abs/2402.16014](https://arxiv.org/abs/2402.16014)

    OmniArch通过多物理学时空数据处理、可扩展的自回归任务和物理信息增强学习技术，在科学计算领域构建灵活的基础模型，并在性能、适应性和逆问题求解方面取得突破，展现了AI对科学计算的潜力。

    

    arXiv:2402.16014v1

    arXiv:2402.16014v1 Announce Type: cross  Abstract: Foundation models have revolutionized knowledge acquisition across domains, and our study introduces OmniArch, a paradigm-shifting approach designed for building foundation models in multi-physics scientific computing. OmniArch's pre-training involves a versatile pipeline that processes multi-physics spatio-temporal data, casting forward problem learning into scalable auto-regressive tasks, while our novel Physics-Informed Reinforcement Learning (PIRL) technique during fine-tuning ensures alignment with physical laws. Pre-trained on the comprehensive PDEBench dataset, OmniArch not only sets new performance benchmarks for 1D, 2D and 3D PDEs but also demonstrates exceptional adaptability to new physics via few-shot and zero-shot learning approaches. The model's representations further extend to inverse problem-solving, highlighting the transformative potential of AI-enabled Scientific Computing(AI4SC) foundation models for engineering ap
    
[^74]: 后量子密码神经网络

    Post-Quantum Cryptography Neural Network

    [https://arxiv.org/abs/2402.16002](https://arxiv.org/abs/2402.16002)

    提出了一种将基于编码的后量子密码方法映射到神经网络结构的PQC方法，通过非线性激活函数、随机扰动的密文和密文的均匀分布增强密文安全性。

    

    近年来，量子计算机和Shor量子算法对当前主流的非对称加密方法（例如RSA和椭圆曲线加密（ECC））构成威胁。因此，有必要构建一种后量子密码（PQC）方法来抵抗量子计算攻击。本研究提出了一种基于PQC的神经网络，将基于编码的PQC方法映射到神经网络结构，并通过非线性激活函数、随机扰动的密文以及密文的均匀分布增强了密文的安全性。在实际实验中，本研究以蜂窝网络信号为案例研究，证明了建议的基于PQC的神经网络可以通过密文的均匀分布进行加密和解密。未来，这种提出的基于PQC的神经网络可以应用于各种应用中。

    arXiv:2402.16002v1 Announce Type: cross  Abstract: In recent years, quantum computers and Shor quantum algorithm have posed a threat to current mainstream asymmetric cryptography methods (e.g. RSA and Elliptic Curve Cryptography (ECC)). Therefore, it is necessary to construct a Post-Quantum Cryptography (PQC) method to resist quantum computing attacks. Therefore, this study proposes a PQC-based neural network that maps a code-based PQC method to a neural network structure and enhances the security of ciphertexts with non-linear activation functions, random perturbation of ciphertexts, and uniform distribution of ciphertexts. In practical experiments, this study uses cellular network signals as a case study to demonstrate that encryption and decryption can be performed by the proposed PQC-based neural network with the uniform distribution of ciphertexts. In the future, the proposed PQC-based neural network could be applied to various applications.
    
[^75]: 机器学习资产管理挑战的实证研究

    An Empirical Study of Challenges in Machine Learning Asset Management

    [https://arxiv.org/abs/2402.15990](https://arxiv.org/abs/2402.15990)

    通过分析开发者论坛和平台上的帖子，研究揭示了与机器学习资产管理挑战相关的133个主题，其中最重要的包括软件依赖、模型部署和模型训练。

    

    在机器学习（ML）中，高效的资产管理，包括ML模型、数据集、算法和工具，对于资源优化、持续性能和简化的开发生命周期至关重要。这使得快速迭代、适应性、减少开发到部署时间以及可靠的输出成为可能。尽管存在研究，但在诸如模型版本控制、数据可追溯性和协作等操作挑战方面仍存在重要的知识差距，这对ML项目的成功至关重要。我们的研究旨在通过分析来自开发者论坛和平台的15,065个帖子，采用混合方法来分类查询，利用BERTopic提取挑战，并通过开放式卡片排序和BERTopic聚类识别解决方案。我们发现了133个与资产管理挑战相关的主题，分成16个宏主题，其中软件依赖、模型部署和模型训练是最重要的。

    arXiv:2402.15990v1 Announce Type: cross  Abstract: In machine learning (ML), efficient asset management, including ML models, datasets, algorithms, and tools, is vital for resource optimization, consistent performance, and a streamlined development lifecycle. This enables quicker iterations, adaptability, reduced development-to-deployment time, and reliable outputs. Despite existing research, a significant knowledge gap remains in operational challenges like model versioning, data traceability, and collaboration, which are crucial for the success of ML projects. Our study aims to address this gap by analyzing 15,065 posts from developer forums and platforms, employing a mixed-method approach to classify inquiries, extract challenges using BERTopic, and identify solutions through open card sorting and BERTopic clustering. We uncover 133 topics related to asset management challenges, grouped into 16 macro-topics, with software dependency, model deployment, and model training being the mo
    
[^76]: PIDformer: Transformer遇见控制论

    PIDformer: Transformer Meets Control Theory

    [https://arxiv.org/abs/2402.15989](https://arxiv.org/abs/2402.15989)

    该论文将Proportional-Integral-Derivative（PID）闭环反馈控制系统集成到Transformer模型中，以改善鲁棒性和表示容量，提高了模型稳定性和抗噪性，解决了输出表示中的秩坍缩问题。

    

    在这项工作中，我们解决了transformer架构的两个主要缺点：输入损坏和输出表示中的秩坍缩。我们揭示了自注意力作为自主状态空间模型，在其解决方案中固有地促进平滑性，导致较低秩的输出和降低的表示容量。此外，模型的稳态解对输入扰动敏感。我们将一个比例-积分-微分（PID）闭环反馈控制系统与一个参考点整合到模型中，以提高鲁棒性和表示容量。这种集成旨在在加强模型稳定性的同时保留高频细节，使其更具抗噪性。最终得到的受控状态空间模型在理论上被证明是稳健的，并擅长解决秩崩溃问题。在这种控制框架的推动下，我们推导出了一类新型transformers，即PID-controlled Transformer（PIDformer）。

    arXiv:2402.15989v1 Announce Type: new  Abstract: In this work, we address two main shortcomings of transformer architectures: input corruption and rank collapse in their output representation. We unveil self-attention as an autonomous state-space model that inherently promotes smoothness in its solutions, leading to lower-rank outputs and diminished representation capacity. Moreover, the steady-state solution of the model is sensitive to input perturbations. We incorporate a Proportional-Integral-Derivative (PID) closed-loop feedback control system with a reference point into the model to improve robustness and representation capacity. This integration aims to preserve high-frequency details while bolstering model stability, rendering it more noise-resilient. The resulting controlled state-space model is theoretically proven robust and adept at addressing the rank collapse. Motivated by this control framework, we derive a novel class of transformers, PID-controlled Transformer (PIDform
    
[^77]: 基于似然的大型语言模型评估偏差的缓解

    Likelihood-based Mitigation of Evaluation Bias in Large Language Models

    [https://arxiv.org/abs/2402.15987](https://arxiv.org/abs/2402.15987)

    该论文研究了基于大型语言模型（LLM）的评估器中的似然偏差，并提出了一种缓解这种偏差的方法。

    

    大型语言模型(LLMs)被广泛用于评估自然语言生成任务的自动化指标。然而，似然作为衡量LLM对句子可信度的指标，可能会因句子表面差异（如词序和句子结构）而变化。因此，如果将LLMs用于评估，可能存在似然偏差：它们可能会高估具有较高似然性的句子，而低估具有较低似然性的句子。本文对LLM评估器中似然偏差的存在和影响进行了研究。我们还提出了一种缓解似然偏差的方法。我们的方法利用高度偏置的实例作为少样本示例进行上下文学习。我们在评估数据到文本和语法错误纠正任务时的实验结果显示，我们测试的几种LLMs显示出似然偏差。此外，我们提出的方法成功地减轻了这种偏差

    arXiv:2402.15987v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are widely used to evaluate natural language generation tasks as automated metrics. However, the likelihood, a measure of LLM's plausibility for a sentence, can vary due to superficial differences in sentences, such as word order and sentence structure. It is therefore possible that there might be a likelihood bias if LLMs are used for evaluation: they might overrate sentences with higher likelihoods while underrating those with lower likelihoods. In this paper, we investigate the presence and impact of likelihood bias in LLM-based evaluators. We also propose a method to mitigate the likelihood bias. Our method utilizes highly biased instances as few-shot examples for in-context learning. Our experiments in evaluating the data-to-text and grammatical error correction tasks reveal that several LLMs we test display a likelihood bias. Furthermore, our proposed method successfully mitigates this bias, also impr
    
[^78]: CoDream：使用异构模型交换梦想而不是模型进行联合聚合

    CoDream: Exchanging dreams instead of models for federated aggregation with heterogeneous models

    [https://arxiv.org/abs/2402.15968](https://arxiv.org/abs/2402.15968)

    CoDream提出了一种通过在输入数据空间中协作优化数据来交换知识的框架，实现了模型之间的合作学习，实现了模型架构无关、通信不受模型大小影响、兼容安全聚合的优点。

    

    联邦学习（FL）通过聚合模型参数实现机器学习模型在分散数据上的协作优化。我们的方法通过聚合模型产生的“知识”，而不是模型参数来扩展这一概念。我们提出了一个名为 \codream 的新颖框架，在这个框架中，客户端通过在输入数据空间中使用联合优化来协作优化随机初始化的数据，类似于在FL中优化随机初始化的模型参数。我们的关键见解是，联合优化这些数据可以有效捕获全局数据分布的特性。在数据空间共享知识具有许多好处：（1）与模型无关的协作学习，即不同客户端可以具有不同的模型架构；（2）通信不受模型大小影响，消除了模型参数的可伸缩性问题；（3）与安全聚合兼容，因此可预

    arXiv:2402.15968v1 Announce Type: cross  Abstract: Federated Learning (FL) enables collaborative optimization of machine learning models across decentralized data by aggregating model parameters. Our approach extends this concept by aggregating "knowledge" derived from models, instead of model parameters. We present a novel framework called \codream, where clients collaboratively optimize randomly initialized data using federated optimization in the input data space, similar to how randomly initialized model parameters are optimized in FL. Our key insight is that jointly optimizing this data can effectively capture the properties of the global data distribution. Sharing knowledge in data space offers numerous benefits: (1) model-agnostic collaborative learning, i.e., different clients can have different model architectures; (2) communication that is independent of the model size, eliminating scalability concerns with model parameters; (3) compatibility with secure aggregation, thus pre
    
[^79]: 具有预算约束的工具学习与规划

    Budget-Constrained Tool Learning with Planning

    [https://arxiv.org/abs/2402.15960](https://arxiv.org/abs/2402.15960)

    本文提出了一种新颖的具有预算约束的工具学习方法，通过创建优先计划和动态规划制定计划来解决用户查询问题，为大型语言模型的工具学习过程提供了全面的概述。

    

    尽管人们在工具学习上进行了大量努力，但是关注在特定预算约束下解决用户查询的具有预算约束的工具学习问题却被广泛忽视。本文提出了一种新颖的具有预算约束的工具学习方法。我们的方法涉及在预算约束下创建一个优先计划，然后再利用工具。该计划概述了可行的工具及其可被使用的最大次数，为大型语言模型的工具学习过程提供了全面的概述，使其能够从更广泛的角度来分配预算。为了在不产生显著额外成本的情况下设计计划，我们建议根据过去的经验首先估计候选工具的有用性。随后，我们使用动态规划来制定计划。实验结果表明，我们的方法可以与各种工具学习方法相结合。

    arXiv:2402.15960v1 Announce Type: new  Abstract: Despite intensive efforts devoted to tool learning, the problem of budget-constrained tool learning, which focuses on resolving user queries within a specific budget constraint, has been widely overlooked. This paper proposes a novel method for budget-constrained tool learning. Our approach involves creating a preferable plan under the budget constraint before utilizing the tools. This plan outlines the feasible tools and the maximum number of times they can be employed, offering a comprehensive overview of the tool learning process for large language models. This allows them to allocate the budget from a broader perspective. To devise the plan without incurring significant extra costs, we suggest initially estimating the usefulness of the candidate tools based on past experience. Subsequently, we employ dynamic programming to formulate the plan. Experimental results demonstrate that our method can be integrated with various tool learnin
    
[^80]: 基于注意力机制的 GAN 在异常检测中的应用：网络安全威胁管理的前沿方法

    Attention-GAN for Anomaly Detection: A Cutting-Edge Approach to Cybersecurity Threat Management

    [https://arxiv.org/abs/2402.15945](https://arxiv.org/abs/2402.15945)

    该研究提出了一种基于注意力机制的 GAN 框架，用于增强网络安全性，重点关注异常检测，通过生成多样且逼真的合成攻击场景来改进威胁识别和解决数据稀缺性问题。

    

    本文提出了一种创新的基于注意力机制的 GAN 框架，用于增强网络安全性，重点关注异常检测。针对网络威胁不断演变带来的挑战，所提出的方法旨在生成多样且逼真的合成攻击场景，从而丰富数据集并改进威胁识别。将注意力机制与生成对抗网络（GANs）相结合是该方法的关键特点。注意力机制增强了模型聚焦于相关特征的能力，对于检测微妙和复杂的攻击模式至关重要。此外，GANs通过生成额外多样的攻击数据，涵盖已知和新兴的威胁，解决了数据稀缺性问题。这种双重方法确保系统能够应对不断演变的网络攻击保持相关性和有效性。KDD Cup 和 CICIDS2017 数据集用于验证该方法。

    arXiv:2402.15945v1 Announce Type: cross  Abstract: This paper proposes an innovative Attention-GAN framework for enhancing cybersecurity, focusing on anomaly detection. In response to the challenges posed by the constantly evolving nature of cyber threats, the proposed approach aims to generate diverse and realistic synthetic attack scenarios, thereby enriching the dataset and improving threat identification. Integrating attention mechanisms with Generative Adversarial Networks (GANs) is a key feature of the proposed method. The attention mechanism enhances the model's ability to focus on relevant features, essential for detecting subtle and complex attack patterns. In addition, GANs address the issue of data scarcity by generating additional varied attack data, encompassing known and emerging threats. This dual approach ensures that the system remains relevant and effective against the continuously evolving cyberattacks. The KDD Cup and CICIDS2017 datasets were used to validate this m
    
[^81]: 在基础模型时代重新思考软件工程：可信基础模型软件开发中的挑战精选目录

    Rethinking Software Engineering in the Era of Foundation Models: A Curated Catalogue of Challenges in the Development of Trustworthy FMware

    [https://arxiv.org/abs/2402.15943](https://arxiv.org/abs/2402.15943)

    FMware的独特属性和基础模型的内在限制导致了新的软件工程挑战，本文总结了这些挑战并提出了创新路径。

    

    Foundation模型（FMs），如大型语言模型（LLMs），通过实现新的用例和商业模型，彻底改变了软件开发。我们将使用FMs构建的软件称为FMware。FMware的独特属性（例如提示、代理和编排的需求），与FMs的内在限制（例如幻觉）结合起来，导致了一系列全新的软件工程挑战。根据我们的工业经验，我们确定了10个关键的SE4FMware挑战，导致企业FMware开发变得低效、成本高昂且风险高。在本文中，我们详细讨论了这些挑战，并阐明了我们设想的创新路径。接下来，我们提出了FMArts，这是我们为构建可信FMware而进行的长期努力。最后，我们展示了FMArts的独特属性如何使我们能够为一种大型FMware设计和开发一个复杂系统。

    arXiv:2402.15943v1 Announce Type: cross  Abstract: Foundation models (FMs), such as Large Language Models (LLMs), have revolutionized software development by enabling new use cases and business models. We refer to software built using FMs as FMware. The unique properties of FMware (e.g., prompts, agents, and the need for orchestration), coupled with the intrinsic limitations of FMs (e.g., hallucination) lead to a completely new set of software engineering challenges. Based on our industrial experience, we identified 10 key SE4FMware challenges that have caused enterprise FMware development to be unproductive, costly, and risky. In this paper, we discuss these challenges in detail and state the path for innovation that we envision. Next, we present FMArts, which is our long-term effort towards creating a cradle-to-grave platform for the engineering of trustworthy FMware. Finally, we (i) show how the unique properties of FMArts enabled us to design and develop a complex FMware for a larg
    
[^82]: 大语言模型的泛化或记忆：数据污染与可信评估

    Generalization or Memorization: Data Contamination and Trustworthy Evaluation for Large Language Models

    [https://arxiv.org/abs/2402.15938](https://arxiv.org/abs/2402.15938)

    本文提出了一种通过LLMs输出分布进行污染检测的方法CDD，以及一种基于LLMs输出修正的可信评估方法TED，以应对大语言模型在数据污染和可信评估方面面临的挑战。

    

    最近关于大语言模型（LLMs）令人印象深刻能力的说法通常是通过在开放获取的基准上进行评估来支持的。考虑到LLMs的训练数据的庞大规模和广泛来源，它可能明确或隐含地包含测试数据，导致LLMs更容易受到数据污染的影响。然而，由于训练数据的不透明性、模型的黑盒访问以及合成训练数据的快速增长，对于LLMs来说检测和减轻数据污染面临着重大挑战。在本文中，我们提出了CDD，即通过LLMs输出分布进行污染检测的CDD。CDD仅需要采样文本来检测数据污染，通过识别LLMs输出分布的峰值来进行检测。为了减轻评估中数据污染的影响，我们还提出了TED：基于LLMs输出修正的可信评估。

    arXiv:2402.15938v1 Announce Type: cross  Abstract: Recent statements about the impressive capabilities of large language models (LLMs) are usually supported by evaluating on open-access benchmarks. Considering the vast size and wide-ranging sources of LLMs' training data, it could explicitly or implicitly include test data, leading to LLMs being more susceptible to data contamination. However, due to the opacity of training data, the black-box access of models, and the rapid growth of synthetic training data, detecting and mitigating data contamination for LLMs faces significant challenges. In this paper, we propose CDD, which stands for Contamination Detection via output Distribution for LLMs. CDD necessitates only the sampled texts to detect data contamination, by identifying the peakedness of LLM's output distribution. To mitigate the impact of data contamination in evaluation, we also present TED: Trustworthy Evaluation via output Distribution, based on the correction of LLM's outp
    
[^83]: 跨越2D和3D视觉问答之间的鸿沟：一种用于3D VQA的融合方法

    Bridging the Gap between 2D and 3D Visual Question Answering: A Fusion Approach for 3D VQA

    [https://arxiv.org/abs/2402.15933](https://arxiv.org/abs/2402.15933)

    通过问题条件的2D视图选择过程和双分支Transformer结构，将2D知识整合到3D-VQA系统中，从而弥补了当前方法在3D视觉问答中遇到的挑战。

    

    在3D视觉问答（3D VQA）中，充分注释数据的稀缺性和有限的视觉内容多样性阻碍了对新颖场景和3D概念的泛化（如ScanQA和SQA数据集仅利用了约800个场景）。目前的方法通过补充2D信息来辅助3D推理。然而，这些方法面临挑战：它们要么使用引入过于复杂且有时与问题无关的视觉线索的自上而下的2D视图，要么依靠来自2D VLM的全局聚合场景/图像级表示，从而丢失了细粒度的视觉语言相关性。为了克服这些局限性，我们的方法利用了问题条件下的2D视图选择过程，准确地指出了关键视觉线索的语义相关2D输入。然后，我们通过双分支Transformer结构将这种2D知识整合到3D-VQA系统中。这种结构采用了双Transformer设计，紧凑地结合

    arXiv:2402.15933v1 Announce Type: cross  Abstract: In 3D Visual Question Answering (3D VQA), the scarcity of fully annotated data and limited visual content diversity hampers the generalization to novel scenes and 3D concepts (e.g., only around 800 scenes are utilized in ScanQA and SQA dataset). Current approaches resort supplement 3D reasoning with 2D information. However, these methods face challenges: either they use top-down 2D views that introduce overly complex and sometimes question-irrelevant visual clues, or they rely on globally aggregated scene/image-level representations from 2D VLMs, losing the fine-grained vision-language correlations. To overcome these limitations, our approach utilizes question-conditional 2D view selection procedure, pinpointing semantically relevant 2D inputs for crucial visual clues. We then integrate this 2D knowledge into the 3D-VQA system via a two-branch Transformer structure. This structure, featuring a Twin-Transformer design, compactly combine
    
[^84]: QuaCer-C：大型语言模型中知识理解的定量认证

    QuaCer-C: Quantitative Certification of Knowledge Comprehension in LLMs

    [https://arxiv.org/abs/2402.15929](https://arxiv.org/abs/2402.15929)

    本文提出了一种新颖的认证框架QuaCer-C，用于正式认证大型语言模型中知识理解的能力，证书定量化且包含高置信度的概率界限，研究发现，随着参数数量的增加，知识理解能力提高，Mistral模型在这一评估中表现不如其他模型。

    

    大型语言模型（LLMs）在多个基准测试中展现出令人印象深刻的表现。然而，传统研究并未对LLMs的表现提供正式的保证。本文提出了一种新颖的LLM认证框架QuaCer-C，我们在此对知名LLMs的知识理解能力进行正式认证。我们的证书是定量的 - 它们包括对目标LLM在任何相关知识理解提示上给出正确答案的概率的高置信度紧密界限。我们针对Llama、Vicuna和Mistral LLMs的证书表明，知识理解能力随参数数量的增加而提高，并且Mistral模型在这一评估中表现不如其他模型。

    arXiv:2402.15929v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated impressive performance on several benchmarks. However, traditional studies do not provide formal guarantees on the performance of LLMs. In this work, we propose a novel certification framework for LLM, QuaCer-C, wherein we formally certify the knowledge-comprehension capabilities of popular LLMs. Our certificates are quantitative - they consist of high-confidence, tight bounds on the probability that the target LLM gives the correct answer on any relevant knowledge comprehension prompt. Our certificates for the Llama, Vicuna, and Mistral LLMs indicate that the knowledge comprehension capability improves with an increase in the number of parameters and that the Mistral model is less performant than the rest in this evaluation.
    
[^85]: MultiContrievers: 稠密检索表示的分析

    MultiContrievers: Analysis of Dense Retrieval Representations

    [https://arxiv.org/abs/2402.15925](https://arxiv.org/abs/2402.15925)

    该论文对稠密检索器的信息捕获进行了分析，探讨了其与语言模型的比较、信息提取的可行性以及提取性与性能、性别偏见的关系。

    

    稠密检索器将源文档压缩为（可能是有损的）向量表示，然而目前对于失去和保留的信息以及它们如何影响下游任务的分析较少。我们进行了首次对比稠密检索器捕获的信息与它们基于的语言模型（如BERT与Contriever）之间的分析。我们使用25个MultiBert检查点作为随机初始化来训练MultiContrievers，这是一组25个contriever模型。我们测试特定信息（如性别和职业）是否可以从类似维基百科的文档的contriever向量中提取。我们通过信息论探测来衡量这种可提取性。然后我们研究了可提取性与性能、性别偏见之间的关系，以及这些结果对许多随机初始化和数据洗牌的敏感性。我们发现（1）contriever模型有显著增加的可提取性

    arXiv:2402.15925v1 Announce Type: cross  Abstract: Dense retrievers compress source documents into (possibly lossy) vector representations, yet there is little analysis of what information is lost versus preserved, and how it affects downstream tasks. We conduct the first analysis of the information captured by dense retrievers compared to the language models they are based on (e.g., BERT versus Contriever). We use 25 MultiBert checkpoints as randomized initialisations to train MultiContrievers, a set of 25 contriever models. We test whether specific pieces of information -- such as gender and occupation -- can be extracted from contriever vectors of wikipedia-like documents. We measure this extractability via information theoretic probing. We then examine the relationship of extractability to performance and gender bias, as well as the sensitivity of these results to many random initialisations and data shuffles. We find that (1) contriever models have significantly increased extracta
    
[^86]: 使用长短期记忆网络在电子竞技中预测结果

    Predicting Outcomes in Video Games with Long Short Term Memory Networks

    [https://arxiv.org/abs/2402.15923](https://arxiv.org/abs/2402.15923)

    使用长短期记忆网络在实时分析中预测电子竞技比赛结果，仅利用玩家生命值指标作为时间序列，较之传统方法和Transformer模型，取得了更高效的预测性能。

    

    预测电子竞技中的胜者，在实时分析中具有潜力进一步吸引观看主要锦标赛的观众。然而，由于游戏中涉及不同玩家策略和决策的不可预测变量，进行这种实时预测是具有挑战性的。我们的工作试图通过引入一种实时预测胜利的方法来增强视频游戏比赛中观众的参与度。我们基于长短期记忆网络（LSTMs）的方法能够通过仅使用每个玩家的生命值指标作为时间序列来高效预测胜负结果。作为概念验证，我们在经典的两人街机游戏《超级街霸II Turbo》中评估了我们模型的性能。我们还将我们的方法与用于时间序列预测的最新方法进行基准测试；即在大型语言模型（LLMs）中找到的Transformer模型。最后，我们开源了我们的数据集和代码，希望可以

    arXiv:2402.15923v1 Announce Type: cross  Abstract: Forecasting winners in E-sports with real-time analytics has the potential to further engage audiences watching major tournament events. However, making such real-time predictions is challenging due to unpredictable variables within the game involving diverse player strategies and decision-making. Our work attempts to enhance audience engagement within video game tournaments by introducing a real-time method of predicting wins. Our Long Short Term Memory Network (LSTMs) based approach enables efficient predictions of win-lose outcomes by only using the health indicator of each player as a time series. As a proof of concept, we evaluate our model's performance within a classic, two-player arcade game, Super Street Fighter II Turbo. We also benchmark our method against state of the art methods for time series forecasting; i.e. Transformer models found in large language models (LLMs). Finally, we open-source our data set and code in hopes
    
[^87]: 可解释的对比和成本敏感学习用于宫颈癌分类

    Explainable Contrastive and Cost-Sensitive Learning for Cervical Cancer Classification

    [https://arxiv.org/abs/2402.15905](https://arxiv.org/abs/2402.15905)

    本文提出了一个高效的宫颈癌细胞分类系统，通过使用预训练的CNNs进行微调并结合监督对比学习，最小化误分类成本，达到了97.29%的准确率，并引入了可解释的人工智能技术来解释模型的决策过程。

    

    本文提出了一个高效的系统，使用预训练的卷积神经网络（CNNs）对宫颈癌细胞进行分类。我们首先微调了五个预训练的CNNs，并通过优先考虑具有更高相关成本或重要性的类别的准确性来最小化总的误分类成本。为了进一步提高模型的性能，我们加入了监督对比学习，使模型更擅长捕捉重要特征和模式。对提出的系统在SIPaKMeD数据集上进行了大量实验评估。实验结果表明，该系统的有效性，达到了97.29%的准确率。为了使我们的系统更加可信，我们采用了几种可解释的人工智能技术来解释模型是如何做出具体决策的。系统的实现可在以下网址找到 - https://github.com/isha-67/CervicalCancerStudy.

    arXiv:2402.15905v1 Announce Type: cross  Abstract: This paper proposes an efficient system for classifying cervical cancer cells using pre-trained convolutional neural networks (CNNs). We first fine-tune five pre-trained CNNs and minimize the overall cost of misclassification by prioritizing accuracy for certain classes that have higher associated costs or importance. To further enhance the performance of the models, supervised contrastive learning is included to make the models more adept at capturing important features and patterns. Extensive experimentation are conducted to evaluate the proposed system on the SIPaKMeD dataset. The experimental results demonstrate the effectiveness of the developed system, achieving an accuracy of 97.29%. To make our system more trustworthy, we have employed several explainable AI techniques to interpret how the models reached a specific decision. The implementation of the system can be found at - https://github.com/isha-67/CervicalCancerStudy.
    
[^88]: 高效分裂联邦学习在资源受限的异构无线设备上

    ESFL: Efficient Split Federated Learning over Resource-Constrained Heterogeneous Wireless Devices

    [https://arxiv.org/abs/2402.15903](https://arxiv.org/abs/2402.15903)

    该论文提出了一种高效的分裂联邦学习算法（ESFL），能够充分利用中央服务器和端设备的计算资源，通过将模型分为不同的子模型并考虑用户的异质性，共同优化用户端工作量和服务器端计算资源分配。

    

    联邦学习（FL）允许多个参与方（分布式设备）在不共享原始数据的情况下训练机器学习模型。如何有效地利用设备和中央服务器上的资源是一个极具吸引力但具有挑战性的问题。本文提出了一种高效的分裂联邦学习算法（ESFL），以充分利用中央服务器在具有异构端设备（EDs）的分裂联邦学习框架下的强大计算能力。通过在服务器和EDs之间将模型分为不同的子模型，我们的方法通过考虑用户的异质性共同优化用户端工作量和服务器端计算资源分配。我们将整个优化问题建模为一个混合整数非线性规划，这是一个NP难问题，并开发了一个迭代方法来有效地获得近似解决方案。进行了大量的模拟实验。

    arXiv:2402.15903v1 Announce Type: cross  Abstract: Federated learning (FL) allows multiple parties (distributed devices) to train a machine learning model without sharing raw data. How to effectively and efficiently utilize the resources on devices and the central server is a highly interesting yet challenging problem. In this paper, we propose an efficient split federated learning algorithm (ESFL) to take full advantage of the powerful computing capabilities at a central server under a split federated learning framework with heterogeneous end devices (EDs). By splitting the model into different submodels between the server and EDs, our approach jointly optimizes user-side workload and server-side computing resource allocation by considering users' heterogeneity. We formulate the whole optimization problem as a mixed-integer non-linear program, which is an NP-hard problem, and develop an iterative approach to obtain an approximate solution efficiently. Extensive simulations have been c
    
[^89]: 基于信息的转导式主动学习

    Information-based Transductive Active Learning

    [https://arxiv.org/abs/2402.15898](https://arxiv.org/abs/2402.15898)

    ITL是一种基于信息的转导式学习方法，可以在现实世界设置中自适应采样，以最大化关于指定预测目标的信息获取，并在少样本微调和安全贝叶斯优化应用中显著优于最先进技术。

    

    我们将主动学习推广到解决现实世界中采样受限于可访问域的情况，而预测目标可能位于这个域之外。为此，我们提出了ITL，即基于信息的转导式学习，一种自适应采样的方法，旨在最大化关于指定预测目标的信息获取。在一般正则性假设下，我们展示了ITL收敛到可从可访问数据中获得的最小可能不确定性。我们在两个关键应用中展示了ITL：大型神经网络的少样本微调和安全贝叶斯优化，在两种情况下，ITL明显优于最先进技术。

    arXiv:2402.15898v1 Announce Type: cross  Abstract: We generalize active learning to address real-world settings where sampling is restricted to an accessible region of the domain, while prediction targets may lie outside this region. To this end, we propose ITL, short for information-based transductive learning, an approach which samples adaptively to maximize the information gained about specified prediction targets. We show, under general regularity assumptions, that ITL converges uniformly to the smallest possible uncertainty obtainable from the accessible data. We demonstrate ITL in two key applications: Few-shot fine-tuning of large neural networks and safe Bayesian optimization, and in both cases, ITL significantly outperforms the state-of-the-art.
    
[^90]: 统计游戏

    Statistical Games

    [https://arxiv.org/abs/2402.15892](https://arxiv.org/abs/2402.15892)

    本研究将Bayesian统计嵌入到更广泛的决策框架中，提出了统计游戏作为统一框架，涵盖了频率派和贝叶斯统计，并提出了最小后悔准则作为决策的一般方法。

    

    这项工作对几种典型的游戏进行了数学探索，其中自然涌现了统计学和概率论的核心概念。这些游戏包括费舍尔游戏和贝叶斯游戏，它们分别与频率派统计学和贝叶斯统计学相关。随后引入了一个更一般类型的游戏，称为统计游戏，在其中可以设置一个进一步的参数，即玩家的相对风险厌恶。本研究表明，费舍尔游戏和贝叶斯游戏可以被视为统计游戏的极限情况。因此，统计游戏可以被视为一个统一的框架，融合了频率派和贝叶斯统计。此外，还提出了一种哲学框架，通常被称为最小后悔准则，作为决策的一般方法。

    arXiv:2402.15892v1 Announce Type: cross  Abstract: This work contains the mathematical exploration of a few prototypical games in which central concepts from statistics and probability theory naturally emerge. The first two kinds of games are termed Fisher and Bayesian games, which are connected to Frequentist and Bayesian statistics, respectively. Later, a more general type of game is introduced, termed Statistical game, in which a further parameter, the players' relative risk aversion, can be set. In this work, we show that Fisher and Bayesian games can be viewed as limiting cases of Statistical games. Therefore, Statistical games can be viewed as a unified framework, incorporating both Frequentist and Bayesian statistics. Furthermore, a philosophical framework is (re-)presented -- often referred to as minimax regret criterion -- as a general approach to decision making.   The main motivation for this work was to embed Bayesian statistics into a broader decision-making framework, whe
    
[^91]: 利用苏木精与伊红染色整张图像进行胶质瘤诊断的多实例学习：印度队列研究

    Multiple Instance Learning for Glioma Diagnosis using Hematoxylin and Eosin Whole Slide Images: An Indian cohort Study

    [https://arxiv.org/abs/2402.15832](https://arxiv.org/abs/2402.15832)

    本研究通过多实例学习在脑肿瘤组织病理学中取得新突破，建立了印度胶质瘤亚型分类性能基准，同时实现了新的评级和检测生物标志物的基准。

    

    脑肿瘤代表一种严重且危及生命的疾病，需要精确的诊断和量身定制的治疗策略。本研究通过对脑肿瘤组织病理学中严格的多实例学习实验的发现，推动了患者护理。它在胶质瘤亚型分类方面建立了新的性能基准，跨多个数据集，包括一个专注于印度人口的新数据集（IPD-Brain），为现有研究提供了宝贵的资源。使用在组织病理学数据集上预训练的ResNet-50进行特征提取，结合DTFD特征聚合器，我们的方法分别在IPD-Brain和TCGA-Brain数据集上实现了三分胶质瘤亚型分类的最新AUC（分别为88.08和95.81）。此外，它在评级和检测IHC分子生物标志物（IDH1（突变 R132H）、TP53、ATRX、Ki-67）方面建立了新的基准。

    arXiv:2402.15832v1 Announce Type: cross  Abstract: Brain tumors represent a severe and life-threatening condition, demanding precise diagnosis and tailored treatment strategies. This study advances patient care with findings from rigorous multiple-instance-learning experimentations across various feature extractors and aggregators in brain tumor histopathology. It establishes new performance benchmarks in glioma subtype classification across multiple datasets, including a novel dataset focused on the Indian demographic (IPD-Brain), providing a valuable resource for existing research. Using a ResNet-50, pretrained on histopathology datasets, for feature extraction, combined with DTFD feature aggregator, our approach achieves state-of-the-art AUCs of 88.08 on IPD-Brain and 95.81 on TCGA-Brain dataset respectively for three-way glioma subtype classification. Moreover, it establishes new benchmarks in grading and detecting IHC molecular biomarkers (IDH1 (mutant R132H), TP53, ATRX, Ki-67) t
    
[^92]: 用于合理序贯决策的奖励设计

    Reward Design for Justifiable Sequential Decision-Making

    [https://arxiv.org/abs/2402.15826](https://arxiv.org/abs/2402.15826)

    代理通过辩论型奖励模型学习可辩明策略，以支持证据证明决策的合理性。

    

    将代理赋予能够使用支持证据来证明决策的能力是负责任决策的基石。此外，确保这些证明与人类期望和社会规范一致至关重要，特别是在高风险情况下，比如医疗保健。在这项工作中，我们提出了一个辩论型奖励模型，用于强化学习代理，其中零和辩论游戏的结果量化了在特定状态下的决策的合理性。然后使用该奖励模型来训练一个可以更容易地与支持证据相印证的可辩明策略。在辩论游戏中，两个辩护性代理轮流提供支持证据，支持两个竞争性决策。在提供的证据条件下，一个人类法官的代理评估哪个决策更合理。我们展示了我们的方法在学习处方策略方面的潜力。

    arXiv:2402.15826v1 Announce Type: cross  Abstract: Equipping agents with the capacity to justify made decisions using supporting evidence represents a cornerstone of accountable decision-making. Furthermore, ensuring that justifications are in line with human expectations and societal norms is vital, especially in high-stakes situations such as healthcare. In this work, we propose the use of a debate-based reward model for reinforcement learning agents, where the outcome of a zero-sum debate game quantifies the justifiability of a decision in a particular state. This reward model is then used to train a justifiable policy, whose decisions can be more easily corroborated with supporting evidence. In the debate game, two argumentative agents take turns providing supporting evidence for two competing decisions. Given the proposed evidence, a proxy of a human judge evaluates which decision is better justified. We demonstrate the potential of our approach in learning policies for prescribin
    
[^93]: 委托游戏中的合作与控制

    Cooperation and Control in Delegation Games

    [https://arxiv.org/abs/2402.15821](https://arxiv.org/abs/2402.15821)

    本文在委托游戏中探讨了控制问题（代理人未能按照其委托人的偏好行事）和合作问题（代理人未能良好地协作），并分析了对齐和能力对委托人福利的影响。en_tdlr: This paper explores the issues of control (agents failing to act in line with their principals' preferences) and cooperation (agents failing to work well together) in delegation games, analyzing how alignment and capabilities impact principals' welfare.

    

    许多涉及人类和机器的感兴趣的场景 - 从虚拟个人助理到自动驾驶车辆 - 可以自然地建模为委托人（人类）委托给代理人（机器），这些代理人之后代表他们的委托人相互交互。我们将这些多委托人，多代理人的情况称为委托游戏。在这类游戏中，存在两种重要的失败模式：控制问题（代理人未能按照其委托人的偏好行事）和合作问题（代理人未能良好地协作）。在本文中，我们形式化和分析这些问题，进一步将其解释为对齐（参与者是否具有相似的偏好？）和能力（参与者在满足这些偏好方面的能力如何？）的问题。我们理论上和经验上展示了这些措施如何确定委托人的福利，如何可以使用有限的观察来估计这些措施，

    arXiv:2402.15821v1 Announce Type: cross  Abstract: Many settings of interest involving humans and machines -- from virtual personal assistants to autonomous vehicles -- can naturally be modelled as principals (humans) delegating to agents (machines), which then interact with each other on their principals' behalf. We refer to these multi-principal, multi-agent scenarios as delegation games. In such games, there are two important failure modes: problems of control (where an agent fails to act in line their principal's preferences) and problems of cooperation (where the agents fail to work well together). In this paper we formalise and analyse these problems, further breaking them down into issues of alignment (do the players have similar preferences?) and capabilities (how competent are the players at satisfying those preferences?). We show -- theoretically and empirically -- how these measures determine the principals' welfare, how they can be estimated using limited observations, and 
    
[^94]: DART: 深度增强的精确实时背景抠图

    DART: Depth-Enhanced Accurate and Real-Time Background Matting

    [https://arxiv.org/abs/2402.15820](https://arxiv.org/abs/2402.15820)

    通过整合深度信息和贝叶斯推断，该论文提出了一种名为DART的方案，以提高背景抠图的实时性和精确性。

    

    在这篇论文中，我们利用RGB-Depth (RGB-D)相机提供的丰富深度信息，实现了实时背景抠图性能的提升，命名为DART。首先，我们修改了原始基于RGB的BGM算法以整合深度信息。然后，通过贝叶斯推断对输出模型进行了细化，融入了背景深度先验。最终的预测结果被转化为...

    arXiv:2402.15820v1 Announce Type: cross  Abstract: Matting with a static background, often referred to as ``Background Matting" (BGM), has garnered significant attention within the computer vision community due to its pivotal role in various practical applications like webcasting and photo editing. Nevertheless, achieving highly accurate background matting remains a formidable challenge, primarily owing to the limitations inherent in conventional RGB images. These limitations manifest in the form of susceptibility to varying lighting conditions and unforeseen shadows.   In this paper, we leverage the rich depth information provided by the RGB-Depth (RGB-D) cameras to enhance background matting performance in real-time, dubbed DART. Firstly, we adapt the original RGB-based BGM algorithm to incorporate depth information. The resulting model's output undergoes refinement through Bayesian inference, incorporating a background depth prior. The posterior prediction is then translated into a 
    
[^95]: 通过行为学习增强大型语言模型代理

    Empowering Large Language Model Agents through Action Learning

    [https://arxiv.org/abs/2402.15809](https://arxiv.org/abs/2402.15809)

    学习新动作的能力对于大型语言模型代理的学习进步至关重要，本研究提出了开放式行为学习框架，通过迭代学习策略改进动作，增强代理的学习效果。

    

    大型语言模型（LLM）代理近来引起越来越多的关注，然而它们在从试错中学习的能力方面存在限制，这是智能行为的关键因素。本研究认为，从经验中学习新动作的能力对于LLM代理的学习进步至关重要。虽然人类自然地扩展他们的动作空间并通过经验学习发展技能，但LLM代理通常在固定的动作空间内操作，限制了它们的成长潜力。为解决这些挑战，我们的研究探讨了语言代理的开放式行为学习。我们提出了一个名为LearnAct的框架，采用迭代学习策略来创建和改进Python函数形式的动作。在每次迭代中，LLM根据在失败的训练任务中识别出的错误，修订和更新当前可用的动作，从而增强动作的有效性。我们的实验评估是...

    arXiv:2402.15809v1 Announce Type: new  Abstract: Large Language Model (LLM) Agents have recently garnered increasing interest yet they are limited in their ability to learn from trial and error, a key element of intelligent behavior. In this work, we argue that the capacity to learn new actions from experience is fundamental to the advancement of learning in LLM agents. While humans naturally expand their action spaces and develop skills through experiential learning, LLM agents typically operate within fixed action spaces, limiting their potential for growth. To address these challenges, our study explores open-action learning for language agents. We introduce a framework LearnAct with an iterative learning strategy to create and improve actions in the form of Python functions. In each iteration, LLM revises and updates the currently available actions based on the errors identified in unsuccessful training tasks, thereby enhancing action effectiveness. Our experimental evaluations acr
    
[^96]: 多臂攻击的最佳零射击探测器

    Optimal Zero-Shot Detector for Multi-Armed Attacks

    [https://arxiv.org/abs/2402.15808](https://arxiv.org/abs/2402.15808)

    本文提出了一种创新的信息论防御方法，通过最优地汇总现有探测器做出的决策，消除了对训练数据的需求。

    

    本文探讨了恶意参与者采用多臂攻击策略操纵数据样本的情况，为其提供了各种方式向数据集中引入噪音。我们的主要目标是通过检测任何对输入的更改来保护数据。我们在防御策略中极度谨慎，操作在防守者拥有信息明显少于攻击者的环境中。具体而言，防守者无法利用任何数据样本来训练防御模型或验证信道的完整性。相反，防守者完全依赖一组现成的“即插即用”探测器。为了解决这一挑战，我们提出了一种创新的信息论防御方法，通过最优地汇总这些探测器做出的决策，从而消除了对任何训练数据的需求。我们进一步探讨了一个实际的使用案例场景。

    arXiv:2402.15808v1 Announce Type: cross  Abstract: This paper explores a scenario in which a malicious actor employs a multi-armed attack strategy to manipulate data samples, offering them various avenues to introduce noise into the dataset. Our central objective is to protect the data by detecting any alterations to the input. We approach this defensive strategy with utmost caution, operating in an environment where the defender possesses significantly less information compared to the attacker. Specifically, the defender is unable to utilize any data samples for training a defense model or verifying the integrity of the channel. Instead, the defender relies exclusively on a set of pre-existing detectors readily available ``off the shelf''. To tackle this challenge, we derive an innovative information-theoretic defense approach that optimally aggregates the decisions made by these detectors, eliminating the need for any training data. We further explore a practical use-case scenario fo
    
[^97]: 基于多轨GPS数据构建和应用人工智能众包地图

    Construction and application of artificial intelligence crowdsourcing map based on multi-track GPS data

    [https://arxiv.org/abs/2402.15796](https://arxiv.org/abs/2402.15796)

    研究人员提出了一种快速有效的算法，从大量低精度GPS轨迹数据融合生成高精度GPS数据，实现了基于社交车辆的地图数据收集的“众包更新”模型，对提高数据准确性具有重要意义。

    

    近年来，高精度地图技术和人工智能的快速发展为智能车辆领域带来了新的发展机遇。高精度地图技术是智能车辆实现自动驾驶的重要保障。然而，由于对高精度地图技术的研究不足，难以在智能车辆领域合理使用这一技术。因此，相关研究人员研究了一种快速有效的算法，从大量低精度GPS轨迹数据融合生成高精度GPS数据，并生成了若干关键数据点简化GPS轨迹描述，实现了基于大量社交车辆的地图数据收集的“众包更新”模型。这种算法对提高数据准确性、降低测量具有重要意义。

    arXiv:2402.15796v1 Announce Type: new  Abstract: In recent years, the rapid development of high-precision map technology combined with artificial intelligence has ushered in a new development opportunity in the field of intelligent vehicles. High-precision map technology is an important guarantee for intelligent vehicles to achieve autonomous driving. However, due to the lack of research on high-precision map technology, it is difficult to rationally use this technology in the field of intelligent vehicles. Therefore, relevant researchers studied a fast and effective algorithm to generate high-precision GPS data from a large number of low-precision GPS trajectory data fusion, and generated several key data points to simplify the description of GPS trajectory, and realized the "crowdsourced update" model based on a large number of social vehicles for map data collection came into being. This kind of algorithm has the important significance to improve the data accuracy, reduce the measur
    
[^98]: 机器学习系统对多模态数据加密的破解与改进

    Cryptanalysis and improvement of multimodal data encryption by machine-learning-based system

    [https://arxiv.org/abs/2402.15779](https://arxiv.org/abs/2402.15779)

    该论文使用机器学习系统对多模态数据加密进行破解和改进，并通过复杂的数学问题极大地加密通信机制，保护个人信息并减少攻击可能性。

    

    随着互联网日渐流行以及通过云和数据中心广泛使用网络和信息系统，个人和组织的隐私和安全变得极为重要。在这个视角下，加密通过保护公共信息交流来有效满足这些要求。为了实现这些目标，研究人员使用了各种加密算法来满足该领域的不同要求，并在工作过程中专注于复杂的数学问题，从而极大地加密通信机制，以尽可能保护个人信息同时显著减少攻击可能性。

    arXiv:2402.15779v1 Announce Type: cross  Abstract: With the rising popularity of the internet and the widespread use of networks and information systems via the cloud and data centers, the privacy and security of individuals and organizations have become extremely crucial. In this perspective, encryption consolidates effective technologies that can effectively fulfill these requirements by protecting public information exchanges. To achieve these aims, the researchers used a wide assortment of encryption algorithms to accommodate the varied requirements of this field, as well as focusing on complex mathematical issues during their work to substantially complicate the encrypted communication mechanism. as much as possible to preserve personal information while significantly reducing the possibility of attacks. Depending on how complex and distinct the requirements established by these various applications are, the potential of trying to break them continues to occur, and systems for eva
    
[^99]: 从COBIT到ISO 42001：评估商业化大型语言模型的机遇、风险和合规性的网络安全框架

    From COBIT to ISO 42001: Evaluating Cybersecurity Frameworks for Opportunities, Risks, and Regulatory Compliance in Commercializing Large Language Models

    [https://arxiv.org/abs/2402.15770](https://arxiv.org/abs/2402.15770)

    该研究评估了四种网络安全框架在商业化大型语言模型（LLMs）中的机遇、风险和合规性，发现新的ISO 42001:2023对LLMs的机遇提供了最全面的支持，COBIT 2019与欧盟AI法案最为接近。

    

    本研究调查了四种主要的网络安全治理、风险和合规（GRC）框架 - NIST CSF 2.0、COBIT 2019、ISO 27001:2022和最新的ISO 42001:2023 - 在采用大型语言模型（LLMs）时对机遇、风险和合规性的整合准备情况，采用定性内容分析和专家验证。我们的分析，同时涉及LLMs和人类专家，揭示了LLM整合的潜力，以及这些框架对LLM风险监督的不足之处。比较性差距分析突出显示，专为人工智能（AI）管理系统设计的新ISO 42001:2023为LLM机遇提供了最全面的便利，而COBIT 2019与即将出台的欧盟AI法案最为接近。尽管如此，我们的研究结果表明，所有评估的框架都将受益于更有效地增强更

    arXiv:2402.15770v1 Announce Type: cross  Abstract: This study investigated the integration readiness of four predominant cybersecurity Governance, Risk and Compliance (GRC) frameworks - NIST CSF 2.0, COBIT 2019, ISO 27001:2022, and the latest ISO 42001:2023 - for the opportunities, risks, and regulatory compliance when adopting Large Language Models (LLMs), using qualitative content analysis and expert validation. Our analysis, with both LLMs and human experts in the loop, uncovered potential for LLM integration together with inadequacies in LLM risk oversight of those frameworks. Comparative gap analysis has highlighted that the new ISO 42001:2023, specifically designed for Artificial Intelligence (AI) management systems, provided most comprehensive facilitation for LLM opportunities, whereas COBIT 2019 aligned most closely with the impending European Union AI Act. Nonetheless, our findings suggested that all evaluated frameworks would benefit from enhancements to more effectively and
    
[^100]: 重点引导的数据增强用于基于神经网络的代码理解

    Importance Guided Data Augmentation for Neural-Based Code Understanding

    [https://arxiv.org/abs/2402.15769](https://arxiv.org/abs/2402.15769)

    引入了一个通用数据增强框架GenCode，通过重要性指标选择生成的代码作为训练数据，以增强代码理解模型的训练。

    

    arXiv:2402.15769v1 类型：交叉 摘要：预训练的代码模型开启了代码智能时代。最近许多模型都表现出色。然而，在代码学习领域，一个重要问题是自动进行代码数据增强，以帮助开发者准备训练数据，这方面的研究尚不足。本文介绍了一个通用的数据增强框架GenCode，用于增强代码理解模型的训练。GenCode遵循一种生成和选择的范式来准备有用的训练代码。具体来说，它使用代码转换技术首先生成新的代码候选，然后通过重要性指标选择重要的代码作为训练数据。为了评估GenCode与通用重要性指标（损失值）的有效性，我们在四个代码理解任务（如代码克隆检测）和三个预训练代码模型（如CodeT5）上进行实验。与最先进的代码增强技术相比，

    arXiv:2402.15769v1 Announce Type: cross  Abstract: Pre-trained code models lead the era of code intelligence. Many models have been designed with impressive performance recently. However, one important problem, data augmentation for code data that automatically helps developers prepare training data lacks study in the field of code learning. In this paper, we introduce a general data augmentation framework, GenCode, to enhance the training of code understanding models. GenCode follows a generation-and-selection paradigm to prepare useful training codes. Specifically, it uses code transformation techniques to generate new code candidates first and then selects important ones as the training data by importance metrics. To evaluate the effectiveness of GenCode with a general importance metric -- loss value, we conduct experiments on four code understanding tasks (e.g., code clone detection) and three pre-trained code models (e.g., CodeT5). Compared to the state-of-the-art (SOTA) code augm
    
[^101]: PhyPlan：基于物理信息网络的机器人机械臂物理任务推理的组合和自适应方法

    PhyPlan: Compositional and Adaptive Physical Task Reasoning with Physics-Informed Skill Networks for Robot Manipulators

    [https://arxiv.org/abs/2402.15767](https://arxiv.org/abs/2402.15767)

    PhyPlan是一种结合了物理信息网络（PINNs）和改进的蒙特卡洛树搜索（MCTS）的规划框架，用于使具有身体的代理能够执行动态物理任务，并可以动态决定在模拟器和实际环境之间进行最优策略的选择。

    

    考虑到将球状物体定位到超出直接触及范围的目标区域这一任务，人类通常会投掷、滑动或将物体反弹到墙上以实现目标。然而，让机器人进行类似推理是非常困难的。现有的物理推理方法需要大量数据，并且在真实世界中固有的复杂性和不确定性方面存在困难。本文提出了PhyPlan，一种新颖的物理信息化规划框架，将物理信息化神经网络（PINNs）与改进的蒙特卡洛树搜索（MCTS）相结合，以使具有身体的代理能够执行动态物理任务。PhyPlan利用PINNs以快速准确地模拟和预测动作的结果，并使用MCTS进行规划。它动态确定是要咨询基于PINN的模拟器（粗糙但快速）还是直接与实际环境互动（精细但缓慢）以确定最佳策略。在模拟的3D环境中进行了机器人评估。

    arXiv:2402.15767v1 Announce Type: cross  Abstract: Given the task of positioning a ball-like object to a goal region beyond direct reach, humans can often throw, slide, or rebound objects against the wall to attain the goal. However, enabling robots to reason similarly is non-trivial. Existing methods for physical reasoning are data-hungry and struggle with complexity and uncertainty inherent in the real world. This paper presents PhyPlan, a novel physics-informed planning framework that combines physics-informed neural networks (PINNs) with modified Monte Carlo Tree Search (MCTS) to enable embodied agents to perform dynamic physical tasks. PhyPlan leverages PINNs to simulate and predict outcomes of actions in a fast and accurate manner and uses MCTS for planning. It dynamically determines whether to consult a PINN-based simulator (coarse but fast) or engage directly with the actual environment (fine but slow) to determine optimal policy. Evaluation with robots in simulated 3D environm
    
[^102]: 在跳槽之前三思：问题细化提示改善大型语言模型的数学推理能力

    Look Before You Leap: Problem Elaboration Prompting Improves Mathematical Reasoning in Large Language Models

    [https://arxiv.org/abs/2402.15764](https://arxiv.org/abs/2402.15764)

    PEP提出了一个新方法来改善LLMs的数学能力，通过在推理之前细化和阐明问题背景，提升全局上下文建模能力，减少解析困难。

    

    大型语言模型（LLMs）在自然语言处理任务中表现出色，但在复杂推理任务中仍面临挑战，并且对输入上下文敏感。本研究提出了一种新的方法，名为问题细化提示（PEP），旨在在推理之前分解和阐明问题背景，从而增强全局上下文建模和减少解析困难。实验结果表明，PEP在复杂推理任务上表现出色，对于问题提出的效果显著。

    arXiv:2402.15764v1 Announce Type: cross  Abstract: Large language models~(LLMs) have exhibited impressive performance across NLP tasks. So far they still face challenges in complex reasoning tasks and can be sensitive to input context. Despite significant efforts have been invested in enhancing reasoning process and improving prefix-prompts robustness, the crucial role of problem context has been overlooked. In this study, we propose a new approach to improve the mathematical capacities of LLMs, named Problem Elaboration Prompting~(PEP). Specifically, PEP decomposes and elucidates the problem context before reasoning, thus enhancing the global context modeling and reducing the parsing difficulties. Experiments on datasets demonstrate promising performances on complex reasoning and indicate the beneficial impact for ill-formed problems. For instance, with the GPT-3.5 model~(\texttt{text-davinci-003}), we observed a 9.93\% improvement with greedy decoding and 8.80\% improvement with self
    
[^103]: 使用具有深度残差学习的选择性状态空间模型进行细粒度食品类别视觉分类的Res-VMamba

    Res-VMamba: Fine-Grained Food Category Visual Classification Using Selective State Space Models with Deep Residual Learning

    [https://arxiv.org/abs/2402.15761](https://arxiv.org/abs/2402.15761)

    Res-VMamba利用具有选择性状态空间模型和深度残差学习，提供了比Transformer结构更出色的性能和计算效率，是食品细粒度分类中的最新技术。

    

    食品分类是发展食品视觉任务的基础，并在计算营养学这一新兴领域中发挥着关键作用。由于食物的复杂性需要细粒度分类，最近的学术研究主要修改卷积神经网络(CNNs)和/或视觉变压器(ViTs)来执行食品类别分类。然而，为了学习细粒度特征，CNN骨干需要额外的结构设计，而包含自注意力模块的ViT具有更高的计算复杂性。最近推出的新的序列状态空间(S4)模型，通过选择机制和与扫描(S6)的计算，俗称为Mamba，相较于变压器架构展示了卓越的性能和计算效率。将Mamba机制整合到图像任务(如分类)中的VMamba模型目前建立了最先进技术

    arXiv:2402.15761v1 Announce Type: cross  Abstract: Food classification is the foundation for developing food vision tasks and plays a key role in the burgeoning field of computational nutrition. Due to the complexity of food requiring fine-grained classification, recent academic research mainly modifies Convolutional Neural Networks (CNNs) and/or Vision Transformers (ViTs) to perform food category classification. However, to learn fine-grained features, the CNN backbone needs additional structural design, whereas ViT, containing the self-attention module, has increased computational complexity. In recent months, a new Sequence State Space (S4) model, through a Selection mechanism and computation with a Scan (S6), colloquially termed Mamba, has demonstrated superior performance and computation efficiency compared to the Transformer architecture. The VMamba model, which incorporates the Mamba mechanism into image tasks (such as classification), currently establishes the state-of-the-art 
    
[^104]: 使用GPT-4生成描述性提示提高多模态医学图像上的SAM零样本性能而无需人工标注

    Increasing SAM Zero-Shot Performance on Multimodal Medical Images Using GPT-4 Generated Descriptive Prompts Without Human Annotation

    [https://arxiv.org/abs/2402.15759](https://arxiv.org/abs/2402.15759)

    使用GPT-4生成描述性提示，提高了多模态医学图像上的SAM零样本分割性能，无需人工标注。

    

    本研究开发并评估了一种新型的多模态医学图像零样本分割算法，命名为文本-视觉-提示SAM（TV-SAM），无需任何手动标注。TV-SAM融合并整合了大型语言模型GPT-4、视觉语言模型GLIP和“Segment Anything Model”（SAM），从医学图像中自动生成描述性文本提示和视觉边界框提示，从而增强了SAM用于零样本分割。在七个公共数据集上进行了全面评估，涵盖八种成像模式，证明TV-SAM可以有效地跨各种模式分割未见过的目标而无需额外训练，明显优于SAM AUTO和GSAM, 与金标准边界框提示的SAM BBOX性能基本匹敌，并在特定数据集（如ISIC和WBC）上超越了现有技术水平。研究表明，TV-SAM是一种有效的多模态

    arXiv:2402.15759v1 Announce Type: cross  Abstract: This study develops and evaluates a novel multimodal medical image zero-shot segmentation algorithm named Text-Visual-Prompt SAM (TV-SAM) without any manual annotations. TV-SAM incorporates and integrates large language model GPT-4, Vision Language Model GLIP, and Segment Anything Model (SAM), to autonomously generate descriptive text prompts and visual bounding box prompts from medical images, thereby enhancing SAM for zero-shot segmentation. Comprehensive evaluations are implemented on seven public datasets encompassing eight imaging modalities to demonstrate that TV-SAM can effectively segment unseen targets across various modalities without additional training, significantly outperforming SAM AUTO and GSAM, closely matching the performance of SAM BBOX with gold standard bounding box prompts, and surpassing the state-of-the-art on specific datasets like ISIC and WBC. The study indicates that TV-SAM serves as an effective multimodal 
    
[^105]: Chimera: 融合所有令牌的无损解码方法，加速大型语言模型推理

    Chimera: A Lossless Decoding Method for Accelerating Large Language Models Inference by Fusing all Tokens

    [https://arxiv.org/abs/2402.15758](https://arxiv.org/abs/2402.15758)

    提出了Chimera框架，用于加速大型语言模型推理，通过引入轻量级的草稿模型和两种策略，利用先前生成的令牌来预测后续单词，以解决解码过程中的准确性和效率问题

    

    大型语言模型（LLMs）在各种任务中展示了显著的能力。然而，它们的广泛应用被资源密集型的解码过程所阻碍。为了解决这一挑战，目前的方法已经合并了额外的解码头，以实现对多个后续令牌的并行预测，从而实现推理加速。然而，这些解码头的准确性远不及自回归解码方法。鉴于这些限制，我们提出了Chimera，这是一个专门为推测采样设计的新框架。在这个框架内，我们引入了一个轻量级的草稿模型，能够有效利用先前生成的令牌来预测后续单词。为了确保准确性和效率，我们在轻量级草稿模型中提出了两种策略。首先，我们专注于在底层捕获短程依赖性。其次，我们利用

    arXiv:2402.15758v1 Announce Type: cross  Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across various tasks. However, their widespread application is hindered by the resource-intensive decoding process. To address this challenge, current approaches have incorporated additional decoding heads to enable parallel prediction of multiple subsequent tokens, thereby achieving inference acceleration. Nevertheless, the accuracy of these decoding heads falls short of the auto-regressive decoding approach.   In light of these limitations, we propose Chimera, a novel framework specifically designed for speculative sampling. Within this framework, we introduce a lightweight draft model that effectively utilizes previously generated tokens to predict subsequent words. To ensure both accuracy and efficiency, we present two strategies within the lightweight draft model. Firstly, we focus on capturing short-range dependencies at the bottom layer. Secondly, we leverage
    
[^106]: 从人类偏好中批量主动学习奖励函数

    Batch Active Learning of Reward Functions from Human Preferences

    [https://arxiv.org/abs/2402.15757](https://arxiv.org/abs/2402.15757)

    本文提出了一种批量主动基于偏好的学习方法，通过少量数据样本有效学习奖励函数，同时保持查询生成时间短并可并行化。

    

    数据生成和标记在机器人学习中往往成本高昂。基于偏好的学习是一个概念，通过向用户提出偏好问题来实现可靠的标记。本文中，我们开发了一组新算法，批量主动基于偏好的学习方法，能够使用尽可能少的数据样本有效学习奖励函数，同时具有较短的查询生成时间，并保持可并行化。我们介绍了一种基于确定性点过程（DPP）的方法，用于批量生成和几种基于启发式的替代方法。最后，我们在模拟中介绍了一些机器人学任务的实验结果。我们的结果表明，我们的批量主动学习算法仅需要少量查询。

    arXiv:2402.15757v1 Announce Type: cross  Abstract: Data generation and labeling are often expensive in robot learning. Preference-based learning is a concept that enables reliable labeling by querying users with preference questions. Active querying methods are commonly employed in preference-based learning to generate more informative data at the expense of parallelization and computation time. In this paper, we develop a set of novel algorithms, batch active preference-based learning methods, that enable efficient learning of reward functions using as few data samples as possible while still having short query generation times and also retaining parallelizability. We introduce a method based on determinantal point processes (DPP) for active batch generation and several heuristic-based alternatives. Finally, we present our experimental results for a variety of robotics tasks in simulation. Our results suggest that our batch active learning algorithm requires only a few queries that ar
    
[^107]: 稀疏MeZO：在零阶LLM微调中减少参数以获得更好性能

    Sparse MeZO: Less Parameters for Better Performance in Zeroth-Order LLM Fine-Tuning

    [https://arxiv.org/abs/2402.15751](https://arxiv.org/abs/2402.15751)

    提出了一种稀疏MeZO方法，通过仅对精心选择的参数子集应用零阶优化，实现了在零阶LLM微调中减少参数以获得更好性能的目标

    

    在针对特定任务进行大型语言模型（LLMs）微调通常会产生令人印象深刻的结果，但由于基于梯度的训练中的反向传播而导致内存效率低下。最近提出的高效利用存储器的零阶（MeZO）优化器旨在解决这个问题，在训练过程中只需要前向传递，使其更符合内存友好性。然而，零阶优化中梯度估计的质量往往取决于数据的维数，这可能解释了为什么与各种任务中的标准微调相比，MeZO仍然表现出显著的性能下降。受到参数高效微调（PEFT）成功的启发，本文介绍了稀疏MeZO，这是一种新颖的内存高效的零阶优化方法，仅将ZO应用于精心选择的参数子集。我们提出了一种简单而有效的参数选择方案，获得了显著的性能提升。

    arXiv:2402.15751v1 Announce Type: cross  Abstract: While fine-tuning large language models (LLMs) for specific tasks often yields impressive results, it comes at the cost of memory inefficiency due to back-propagation in gradient-based training. Memory-efficient Zeroth-order (MeZO) optimizers, recently proposed to address this issue, only require forward passes during training, making them more memory-friendly. However, the quality of gradient estimates in zeroth order optimization often depends on the data dimensionality, potentially explaining why MeZO still exhibits significant performance drops compared to standard fine-tuning across various tasks. Inspired by the success of Parameter-Efficient Fine-Tuning (PEFT), this paper introduces Sparse MeZO, a novel memory-efficient zeroth-order optimization approach that applies ZO only to a carefully chosen subset of parameters. We propose a simple yet effective parameter selection scheme that yields significant performance gains with Spar
    
[^108]: 智能导演：使用ChatGPT进行动态视觉构图的自动化框架

    Intelligent Director: An Automatic Framework for Dynamic Visual Composition using ChatGPT

    [https://arxiv.org/abs/2402.15746](https://arxiv.org/abs/2402.15746)

    提出了智能导演框架，结合LENS对图像和视频帧生成描述，再利用ChatGPT生成连贯字幕和推荐音乐名称，通过音乐检索获得最佳匹配音乐，最终整合各种素材实现故事性视频的自动生成。

    

    随着以TikTok为代表的短视频平台的兴起，用户通过照片和视频表达创意的趋势急剧增加。然而，普通用户缺乏使用专业创作软件制作高质量视频的专业技能。为满足智能且用户友好的视频创作工具的需求，我们提出了动态视觉构图（DVC）任务，这是一个有趣且具有挑战性的任务，旨在根据用户需求自动整合各种媒体元素并创建叙事视频。我们提出了一个智能导演框架，利用LENS为图像和视频帧生成描述，结合ChatGPT生成连贯字幕同时推荐适当的音乐名称。然后，通过音乐检索获得最佳匹配的音乐。接着，字幕、图像、视频和音乐等素材被整合起来，无缝合成。

    arXiv:2402.15746v1 Announce Type: cross  Abstract: With the rise of short video platforms represented by TikTok, the trend of users expressing their creativity through photos and videos has increased dramatically. However, ordinary users lack the professional skills to produce high-quality videos using professional creation software. To meet the demand for intelligent and user-friendly video creation tools, we propose the Dynamic Visual Composition (DVC) task, an interesting and challenging task that aims to automatically integrate various media elements based on user requirements and create storytelling videos. We propose an Intelligent Director framework, utilizing LENS to generate descriptions for images and video frames and combining ChatGPT to generate coherent captions while recommending appropriate music names. Then, the best-matched music is obtained through music retrieval. Then, materials such as captions, images, videos, and music are integrated to seamlessly synthesize the 
    
[^109]: GAOKAO-MM: 一个用于多模态模型评估的中国人类水平基准

    GAOKAO-MM: A Chinese Human-Level Benchmark for Multimodal Models Evaluation

    [https://arxiv.org/abs/2402.15745](https://arxiv.org/abs/2402.15745)

    GAOKAO-MM 是基于中国高考的多模态基准，为模型的能力设定人类水平要求，评估结果显示目前的LVLMs的准确率普遍不足50%。

    

    大型视觉语言模型（LVLMs）已经在图像感知和语言理解方面展示出了极大的能力。然而，现有的多模态基准主要关注基本的感知能力和常识知识，这些无法充分反映出LVLMs的全面能力。我们提出了GAOKAO-MM，一个基于中国高考的多模态基准，包括8个科目和12种类型的图片，如图表、函数图、地图和照片。GAOKAO-MM来源于中国本土背景，并为模型的能力设定了人类水平的要求，包括感知、理解、知识和推理。我们评估了10个LVLMs，发现它们的准确率都低于50%，其中GPT-4-Vision（48.1%）、Qwen-VL-Plus（41.2%）和Gemini-Pro-Vision（35.1%）位列前三名。我们的多维分析结果表明，LVLMs具有适度的

    arXiv:2402.15745v1 Announce Type: cross  Abstract: The Large Vision-Language Models (LVLMs) have demonstrated great abilities in image perception and language understanding. However, existing multimodal benchmarks focus on primary perception abilities and commonsense knowledge which are insufficient to reflect the comprehensive capabilities of LVLMs. We propose GAOKAO-MM, a multimodal benchmark based on the Chinese College Entrance Examination (GAOKAO), comprising of 8 subjects and 12 types of images, such as diagrams, function graphs, maps and photos. GAOKAO-MM derives from native Chinese context and sets human-level requirements for the model's abilities, including perception, understanding, knowledge and reasoning. We evaluate 10 LVLMs and find that the accuracies of all of them are lower than 50%, with GPT-4-Vison (48.1%), Qwen-VL-Plus (41.2%) and Gemini-Pro-Vision (35.1%) ranking in the top three positions. The results of our multi-dimension analysis indicate that LVLMs have moder
    
[^110]: 人类是如何编写代码的？大型模型也以同样的方式进行

    How Do Humans Write Code? Large Models Do It the Same Way Too

    [https://arxiv.org/abs/2402.15729](https://arxiv.org/abs/2402.15729)

    大型语言模型在执行数值计算时经常出错，通过生成可执行代码来解决问题可以减少计算错误，但观察到当大型语言模型使用代码解决数学问题时，会生成更多不正确推理；为解决这一问题，提出了一种受人类编码实践启发的简单而高效方法Human-Think Language（HTL）。

    

    大型语言模型（LLMs）在执行数值计算时经常出错。与传统的思维链推理相比，程序化思维方法涉及生成可执行代码来解决问题。通过执行这些代码，它可以获得更精确的结果。使用生成的可执行代码而不是自然语言可以减少计算错误。然而，我们观察到当LLMs使用代码解决数学问题时，他们往往生成比使用自然语言更多的不正确推理。为了解决这个问题，我们提出了Human-Think Language（HTL），这是一种受到人类编码实践启发的简单而高效的方法。该方法首先由模型生成用自然语言描述的解决问题方法，然后将其转换为代码，反映出人们在将逻辑以自然语言形式思考后再将其写成代码的过程。此外，它利用了P

    arXiv:2402.15729v1 Announce Type: new  Abstract: Large Language Models (LLMs) often make errors when performing numerical calculations. In contrast to traditional chain-of-thought reasoning, the program-of-thoughts approach involves generating executable code to solve problems. By executing this code, it achieves more precise results. Using generated executable code instead of natural language can reduce computational errors. However, we observe that when LLMs solve mathematical problems using code, they tend to generate more incorrect reasoning than when using natural language. To address this issue, we propose Human-Think Language (HTL), a straightforward yet highly efficient approach inspired by human coding practices. The approach first generates problem-solving methods described in the natural language by the model, then converts them into code, mirroring the process where people think through the logic in natural language before writing it as code. Additionally, it utilizes the P
    
[^111]: LLMs能够以实用的方式自我防御越狱攻击：一份展望文章

    LLMs Can Defend Themselves Against Jailbreaking in a Practical Manner: A Vision Paper

    [https://arxiv.org/abs/2402.15727](https://arxiv.org/abs/2402.15727)

    本文提出了一种名为SELFDEFEND的轻量级实用防御方法，可以在最小延迟下抵御所有现有的越狱攻击。

    

    越狱是一种新兴的敌对攻击，可以绕过现有的大型语言模型（LLMs）中部署的安全机制。已有大量研究提出了更有效的越狱攻击方法，包括最近的贪婪坐标梯度（GCG）攻击、基于越狱模板的攻击，例如使用“Do-Anything-Now”（DAN），以及多语言越狱。相比之下，防御方面的研究相对较少。本文提出了一种轻量而实用的防御方法，称为SELFDEFEND，可以抵御所有现有的越狱攻击，在越狱提示方面几乎没有延迟，对于正常用户提示也只有微不足道的延迟。我们的主要见解是，无论使用何种越狱策略，最终都需要在发送给LLMs的提示中包含有害提示（例如“如何制造炸弹”），我们发现现有的LLMs可以有效识别违反安全规则的有害提示。

    arXiv:2402.15727v1 Announce Type: cross  Abstract: Jailbreaking is an emerging adversarial attack that bypasses the safety alignment deployed in off-the-shelf large language models (LLMs). A considerable amount of research exists proposing more effective jailbreak attacks, including the recent Greedy Coordinate Gradient (GCG) attack, jailbreak template-based attacks such as using "Do-Anything-Now" (DAN), and multilingual jailbreak. In contrast, the defensive side has been relatively less explored. This paper proposes a lightweight yet practical defense called SELFDEFEND, which can defend against all existing jailbreak attacks with minimal delay for jailbreak prompts and negligible delay for normal user prompts. Our key insight is that regardless of the kind of jailbreak strategies employed, they eventually need to include a harmful prompt (e.g., "how to make a bomb") in the prompt sent to LLMs, and we found that existing LLMs can effectively recognize such harmful prompts that violate 
    
[^112]: Hal-Eval: 一种面向大型视觉语言模型的通用和细粒度幻觉评估框架

    Hal-Eval: A Universal and Fine-grained Hallucination Evaluation Framework for Large Vision Language Models

    [https://arxiv.org/abs/2402.15721](https://arxiv.org/abs/2402.15721)

    本论文提出了Hal-Eval，一个通用和细粒度的幻觉评估框架，引入了新的幻觉分类法，专注于事件幻觉，通过生成和过滤细粒度幻觉数据来评估大型视觉语言模型对各种幻觉的处理能力。

    

    大型视觉语言模型具有非凡的能力，但在图片和其描述之间存在幻觉不一致。以往对LVLMs进行的幻觉评估研究发现了关于对象、属性和关系的幻觉，但忽略了围绕虚构实体创建整个叙事的复杂幻觉。本文引入了一种精细的幻觉分类法，其中包括一个新的类别：事件幻觉。然后，我们利用先进的LLMs生成和过滤由各种类型的幻觉组成的细粒度幻觉数据，特别关注事件幻觉，为在我们的通用评估框架内集成辨别和生成评估方法奠定基础。所提出的基准可以独特地评估LVLMs处理广泛幻觉的能力，使其成为一个可靠和全面的工具。

    arXiv:2402.15721v1 Announce Type: new  Abstract: Large Vision Language Models exhibit remarkable capabilities but struggle with hallucinations inconsistencies between images and their descriptions. Previous hallucination evaluation studies on LVLMs have identified hallucinations in terms of objects, attributes, and relations but overlooked complex hallucinations that create an entire narrative around a fictional entity. In this paper, we introduce a refined taxonomy of hallucinations, featuring a new category: Event Hallucination. We then utilize advanced LLMs to generate and filter fine grained hallucinatory data consisting of various types of hallucinations, with a particular focus on event hallucinations, laying the groundwork for integrating discriminative and generative evaluation methods within our universal evaluation framework. The proposed benchmark distinctively assesses LVLMs ability to tackle a broad spectrum of hallucinations, making it a reliable and comprehensive tool fo
    
[^113]: 提高预训练语言模型的连续少样本关系提取器能力

    Making Pre-trained Language Models Better Continual Few-Shot Relation Extractors

    [https://arxiv.org/abs/2402.15713](https://arxiv.org/abs/2402.15713)

    提出了一种对比提示学习框架，利用预训练语言模型的潜在能力解决灾难性遗忘和过拟合问题，使其成为更好的连续少样本关系提取器

    

    持续少样本关系提取（CFRE）是一个实际问题，需要模型在避免忘记旧关系的同时连续学习新关系，只有极少量标记训练数据。主要挑战是灾难性遗忘和过拟合。本文利用提示学习来探索预训练语言模型的隐式能力，以解决上述两个挑战，从而使语言模型成为更好的连续少样本关系提取器。具体来说，我们提出了一种对比提示学习框架，设计提示表示以获得更广义的知识，可以轻松适应旧的和新的类别，并基于边界的对比学习，更多地关注困难样本，从而缓解灾难性遗忘和过拟合问题。为了进一步解决低资源场景中的过拟合问题，我们引入了一种有效的记忆增强策略，利用了...

    arXiv:2402.15713v1 Announce Type: cross  Abstract: Continual Few-shot Relation Extraction (CFRE) is a practical problem that requires the model to continuously learn novel relations while avoiding forgetting old ones with few labeled training data. The primary challenges are catastrophic forgetting and overfitting. This paper harnesses prompt learning to explore the implicit capabilities of pre-trained language models to address the above two challenges, thereby making language models better continual few-shot relation extractors. Specifically, we propose a Contrastive Prompt Learning framework, which designs prompt representation to acquire more generalized knowledge that can be easily adapted to old and new categories, and margin-based contrastive learning to focus more on hard samples, therefore alleviating catastrophic forgetting and overfitting issues. To further remedy overfitting in low-resource scenarios, we introduce an effective memory augmentation strategy that employs well-
    
[^114]: 从脑信号解码查询语义的查询扩展

    Query Augmentation by Decoding Semantics from Brain Signals

    [https://arxiv.org/abs/2402.15708](https://arxiv.org/abs/2402.15708)

    提出了一种名为Brain-Aug的方法，通过从脑信号中解码的语义信息增强查询，可以生成更准确的查询，改善文档排序性能，特别适用于模糊查询。

    

    查询扩展是用于细化语义不准确查询的关键技术。传统上，查询扩展依赖于从最初检索到的、潜在相关的文档中提取信息。如果最初检索到的文档质量较低，则查询扩展的有效性也会受到限制。我们提出了Brain-Aug，通过将从脑信号解码的语义信息结合到查询中来增强查询。Brain-Aug使用了在脑信号信息构建的提示和面向排名的推理方法生成原始查询的延续部分。对fMRI数据集的实验结果显示，Brain-Aug生成的查询在语义上更准确，导致改进的文档排序性能。脑信号带来的这种改进对于模糊查询特别显著。

    arXiv:2402.15708v1 Announce Type: cross  Abstract: Query augmentation is a crucial technique for refining semantically imprecise queries. Traditionally, query augmentation relies on extracting information from initially retrieved, potentially relevant documents. If the quality of the initially retrieved documents is low, then the effectiveness of query augmentation would be limited as well. We propose Brain-Aug, which enhances a query by incorporating semantic information decoded from brain signals. BrainAug generates the continuation of the original query with a prompt constructed with brain signal information and a ranking-oriented inference approach. Experimental results on fMRI (functional magnetic resonance imaging) datasets show that Brain-Aug produces semantically more accurate queries, leading to improved document ranking performance. Such improvement brought by brain signals is particularly notable for ambiguous queries.
    
[^115]: 是否可以仅凭有限样本进行离线决策？通过信任区域增强在数据稀缺赌博机中可靠决策

    Is Offline Decision Making Possible with Only Few Samples? Reliable Decisions in Data-Starved Bandits via Trust Region Enhancement

    [https://arxiv.org/abs/2402.15703](https://arxiv.org/abs/2402.15703)

    本文展示了即使在数据稀缺的情况下，仍然可能找到一个与最优策略竞争的随机策略，为在仅有少量样本下进行可靠决策铺平了道路。

    

    在一个只包含每个臂的单个样本数据集中，一个智能体能从随机多臂老虎机（MAB）问题中学到什么？令人惊讶的是，在这项工作中，我们证明即使在这种数据稀缺的环境中，仍然可能找到一个与最优策略竞争的策略。这为在必须仅依靠少数样本做出关键决策的环境中进行可靠的决策铺平了道路。我们的分析揭示了\emph{随机策略对于离线决策能够显著优于确定性策略}。专注于离线多臂老虎机，我们设计了一种名为基于不确定性信任区域的随机策略增强（TRUST）的算法，这与主导性价值为基础的较低置信下界方法有很大不同。其设计得益于定位规律、临界半径和相对悲观主义。我们证明其样本复杂度与L的相当。

    arXiv:2402.15703v1 Announce Type: cross  Abstract: What can an agent learn in a stochastic Multi-Armed Bandit (MAB) problem from a dataset that contains just a single sample for each arm? Surprisingly, in this work, we demonstrate that even in such a data-starved setting it may still be possible to find a policy competitive with the optimal one. This paves the way to reliable decision-making in settings where critical decisions must be made by relying only on a handful of samples.   Our analysis reveals that \emph{stochastic policies can be substantially better} than deterministic ones for offline decision-making. Focusing on offline multi-armed bandits, we design an algorithm called Trust Region of Uncertainty for Stochastic policy enhancemenT (TRUST) which is quite different from the predominant value-based lower confidence bound approach. Its design is enabled by localization laws, critical radii, and relative pessimism. We prove that its sample complexity is comparable to that of L
    
[^116]: 《CoRelation: 通过上下文化的编码关系学习提升自动ICD编码》

    CoRelation: Boosting Automatic ICD Coding Through Contextualized Code Relation Learning

    [https://arxiv.org/abs/2402.15700](https://arxiv.org/abs/2402.15700)

    通过上下文化的编码关系学习，提出了一种新的框架来增强ICD编码表示的学习，实验结果表明其相比最先进基线方法的有效性。

    

    自动国际疾病分类（ICD）编码在从临床记录中提取相关信息以便正确记录和计费方面起着至关重要的作用。提升自动ICD编码性能的一个重要方向是对ICD编码关系进行建模。然而，当前方法对ICD编码之间错综复杂的关系建模不足，通常忽视了临床记录中上下文的重要性。本文提出了一种新颖方法，即一种上下文化和灵活的框架，以增强ICD编码表示的学习。与现有方法不同，我们的方法采用了考虑临床记录上下文的依赖学习范式，对建模所有可能的编码关系。我们在六个公共ICD编码数据集上评估了我们的方法，实验结果表明与最先进基线方法相比，我们的方法的有效性。

    arXiv:2402.15700v1 Announce Type: cross  Abstract: Automatic International Classification of Diseases (ICD) coding plays a crucial role in the extraction of relevant information from clinical notes for proper recording and billing. One of the most important directions for boosting the performance of automatic ICD coding is modeling ICD code relations. However, current methods insufficiently model the intricate relationships among ICD codes and often overlook the importance of context in clinical notes. In this paper, we propose a novel approach, a contextualized and flexible framework, to enhance the learning of ICD code representations. Our approach, unlike existing methods, employs a dependent learning paradigm that considers the context of clinical notes in modeling all possible code relations. We evaluate our approach on six public ICD coding datasets and the experimental results demonstrate the effectiveness of our approach compared to state-of-the-art baselines.
    
[^117]: 踏进大型语言模型“越狱”的认知心理学

    Foot In The Door: Understanding Large Language Model Jailbreaking via Cognitive Psychology

    [https://arxiv.org/abs/2402.15690](https://arxiv.org/abs/2402.15690)

    该研究通过认知一致性理论为大型语言模型的越狱提示提供了心理解释，并提出了一种基于门脚-门技术的自动黑盒越狱方法。

    

    大型语言模型（LLMs）渐渐成为人们获取新知识的入口。然而，攻击者可以打破模型的安全保护（“监狱”）以访问受限信息，这称为“越狱”。先前的研究显示了当前LLMs在面对此类越狱攻击时的薄弱性。然而，对LLMs在接收越狱提示时内在决策机制的理解明显欠缺。我们的研究提供了越狱提示的心理解释。借鉴认知一致性理论，我们认为越狱的关键是引导LLMs在错误方向上实现认知协调。此外，我们提出了一种基于门脚-门的自动黑盒越狱方法。这种方法逐步诱导模型通过多步增量提示回答有害问题。

    arXiv:2402.15690v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have gradually become the gateway for people to acquire new knowledge. However, attackers can break the model's security protection ("jail") to access restricted information, which is called "jailbreaking." Previous studies have shown the weakness of current LLMs when confronted with such jailbreaking attacks. Nevertheless, comprehension of the intrinsic decision-making mechanism within the LLMs upon receipt of jailbreak prompts is noticeably lacking. Our research provides a psychological explanation of the jailbreak prompts. Drawing on cognitive consistency theory, we argue that the key to jailbreak is guiding the LLM to achieve cognitive coordination in an erroneous direction. Further, we propose an automatic black-box jailbreaking method based on the Foot-in-the-Door (FITD) technique. This method progressively induces the model to answer harmful questions via multi-step incremental prompts. We instantiat
    
[^118]: 通用图像编码器 DINOv2 用于医学图像配准

    General Purpose Image Encoder DINOv2 for Medical Image Registration

    [https://arxiv.org/abs/2402.15687](https://arxiv.org/abs/2402.15687)

    提出了一种无需训练的可变形图像配准方法 DINO-Reg，利用通用图像编码器 DINOv2 进行图像特征提取，并通过实验证明其在图像配准应用中的有效性。

    

    现有的医学图像配准算法要么依赖于特定数据集的训练，要么依赖于局部纹理特征来对齐图像。前者在没有大型专门训练数据集的情况下无法可靠地实施，而后者缺乏全局语义，因此容易陷入局部最小值。在本文中，我们提出了一种无需训练的可变形图像配准方法 DINO-Reg，利用通用图像编码器 DINOv2 进行图像特征提取。DINOv2 编码器是使用包含自然图像的 ImageNet 数据进行训练的。我们使用了预训练的 DINOv2 而没有进行任何微调。我们的方法将 DINOv2 编码特征输入到离散优化器中，以找到最优的可变形配准场。我们进行了一系列实验，以了解这种通用图像编码器在图像配准应用中的行为和作用。结合手工特征，我们的方法取得了胜利。

    arXiv:2402.15687v1 Announce Type: cross  Abstract: Existing medical image registration algorithms rely on either dataset specific training or local texture-based features to align images. The former cannot be reliably implemented without large modality-specific training datasets, while the latter lacks global semantics thus could be easily trapped at local minima. In this paper, we present a training-free deformable image registration method, DINO-Reg, leveraging a general purpose image encoder DINOv2 for image feature extraction. The DINOv2 encoder was trained using the ImageNet data containing natural images. We used the pretrained DINOv2 without any finetuning. Our method feeds the DINOv2 encoded features into a discrete optimizer to find the optimal deformable registration field. We conducted a series of experiments to understand the behavior and role of such a general purpose image encoder in the application of image registration. Combined with handcrafted features, our method won
    
[^119]: 一种用于同时人员轮班规划和无关并行机器调度的数学模型

    A mathematical model for simultaneous personnel shift planning and unrelated parallel machine scheduling

    [https://arxiv.org/abs/2402.15670](https://arxiv.org/abs/2402.15670)

    一种针对生产调度问题的数学模型，同时考虑人员轮班规划和无关机器调度，并通过MILP模型最小化总生产时间。

    

    本文针对产生于工业应用案例的生产调度问题进行研究，重点关注带有人员可用性约束的无关并行机器调度。所提出的模型在多期调度周期内优化生产计划，容纳每个时间段内人员轮班时间的变化。模型假设机器之间共享人员，每台机器在作业处理期间需要一个人员进行设置和监督。可用人员少于机器数量，因此限制了能够并行操作的机器数量。该模型旨在最小化考虑机器相关处理时间和顺序相关设置时间的总生产时间。模型处理了诸如机器合格约束和生产时间窗口之类的实际场景。引入了混合整数线性规划（MILP）模型来表述问题，考虑了c

    arXiv:2402.15670v1 Announce Type: new  Abstract: This paper addresses a production scheduling problem derived from an industrial use case, focusing on unrelated parallel machine scheduling with the personnel availability constraint. The proposed model optimizes the production plan over a multi-period scheduling horizon, accommodating variations in personnel shift hours within each time period. It assumes shared personnel among machines, with one personnel required per machine for setup and supervision during job processing. Available personnel are fewer than the machines, thus limiting the number of machines that can operate in parallel. The model aims to minimize the total production time considering machine-dependent processing times and sequence-dependent setup times. The model handles practical scenarios like machine eligibility constraints and production time windows. A Mixed Integer Linear Programming (MILP) model is introduced to formulate the problem, taking into account both c
    
[^120]: 在线客户服务中的通用模型

    Universal Model in Online Customer Service

    [https://arxiv.org/abs/2402.15666](https://arxiv.org/abs/2402.15666)

    本文介绍了一种在电子商务中改进在线客户服务的解决方案，即提出了一种基于客户问题预测标签的通用模型，无需进行训练，通过消除个别模型训练和维护的需求，减少了模型开发周期和成本。

    

    建立机器学习模型可能是一个耗时的过程，在 typcial 商业场景中常常需要数月来实现。为了确保模型性能的一致性并考虑到数据分布的变化，定期的重新训练是必需的。本文介绍了一种改进电子商务在线客户服务的解决方案，即提出了一种基于客户问题预测标签的通用模型，无需进行训练。我们的新方法涉及使用机器学习技术在对话中标记客户问题，并创建问题及相应标签的存储库。当客户请求帮助时，一个信息检索模型在存储库中搜索相似问题，并使用统计分析来预测相应的标签。通过消除个别模型训练和维护的需求，我们的方法减少了模型开发周期和成本。

    arXiv:2402.15666v1 Announce Type: cross  Abstract: Building machine learning models can be a time-consuming process that often takes several months to implement in typical business scenarios. To ensure consistent model performance and account for variations in data distribution, regular retraining is necessary. This paper introduces a solution for improving online customer service in e-commerce by presenting a universal model for predict-ing labels based on customer questions, without requiring training. Our novel approach involves using machine learning techniques to tag customer questions in transcripts and create a repository of questions and corresponding labels. When a customer requests assistance, an information retrieval model searches the repository for similar questions, and statistical analysis is used to predict the corresponding label. By eliminating the need for individual model training and maintenance, our approach reduces both the model development cycle and costs. The 
    
[^121]: 在智能路由中的师生学习复杂性

    Teacher-Student Learning on Complexity in Intelligent Routing

    [https://arxiv.org/abs/2402.15665](https://arxiv.org/abs/2402.15665)

    通过机器学习框架中的师生模型，成功预测客户联系的复杂性并将其引导到合适的代理商，提高了客户体验，并提出了复杂性AUC度量标准。

    

    客户服务通常是电子商务网站中最耗时的环节，每次联系通常需要花费10-15分钟。有效地将客户引导到合适的代理商，避免转接是电子商务成功的关键。为此，我们开发了一个机器学习框架，用于预测客户联系的复杂性并相应地将其引导到合适的代理商。该框架分为两部分。首先，我们训练一个师傅模型，根据联系后的对话文本评分来评估联系的复杂性。然后，我们使用师傅模型作为数据标注者，为训练一个只根据联系前数据预测复杂性的学生模型提供标签。我们的实验表明，这样的框架是成功的，并且可以显著改善客户体验。我们还提出了一个称为复杂性AUC的有用度量标准，用于在统计水平上评估客户服务的有效性。

    arXiv:2402.15665v1 Announce Type: cross  Abstract: Customer service is often the most time-consuming aspect for e-commerce websites, with each contact typically taking 10-15 minutes. Effectively routing customers to appropriate agents without transfers is therefore crucial for e-commerce success. To this end, we have developed a machine learning framework that predicts the complexity of customer contacts and routes them to appropriate agents accordingly. The framework consists of two parts. First, we train a teacher model to score the complexity of a contact based on the post-contact transcripts. Then, we use the teacher model as a data annotator to provide labels to train a student model that predicts the complexity based on pre-contact data only. Our experiments show that such a framework is successful and can significantly improve customer experience. We also propose a useful metric called complexity AUC that evaluates the effectiveness of customer service at a statistical level.
    
[^122]: GiMeFive：面部情绪分类的可解释性方法

    GiMeFive: Towards Interpretable Facial Emotion Classification

    [https://arxiv.org/abs/2402.15662](https://arxiv.org/abs/2402.15662)

    提出了一种名为GiMeFive的面部情绪分类模型，通过层激活和梯度加权类激活映射进行解释，实验结果显示在准确性上优于先前方法，并在真实图像和视频示例以及实时摄像头流上进行了解释。

    

    在计算机视觉领域，深度卷积神经网络已经被证明能成功识别面部情绪多年。然而，现有的检测方法并不总是可靠或可解释，我们在这里提出了我们的模型GiMeFive，通过层激活和梯度加权类激活映射进行解释。我们与最先进的方法进行比较，以对六种面部情绪进行分类。实证结果表明，在两个面部情感识别（FER）基准和我们的汇总FER GiMeFive方面，我们的模型在准确性上优于先前的方法。此外，我们在真实图像和视频示例中解释了我们的工作，以及实时直播摄像头流。我们的代码和补充材料可在 https：//github.com/werywjw/SEP-CVDL 找到。

    arXiv:2402.15662v1 Announce Type: cross  Abstract: Deep convolutional neural networks have been shown to successfully recognize facial emotions for the past years in the realm of computer vision. However, the existing detection approaches are not always reliable or explainable, we here propose our model GiMeFive with interpretations, i.e., via layer activations and gradient-weighted class activation mapping. We compare against the state-of-the-art methods to classify the six facial emotions. Empirical results show that our model outperforms the previous methods in terms of accuracy on two Facial Emotion Recognition (FER) benchmarks and our aggregated FER GiMeFive. Furthermore, we explain our work in real-world image and video examples, as well as real-time live camera streams. Our code and supplementary material are available at https: //github.com/werywjw/SEP-CVDL.
    
[^123]: 学习半线性神经算子：预测和数据同化的统一递归框架

    Learning Semilinear Neural Operators : A Unified Recursive Framework For Prediction And Data Assimilation

    [https://arxiv.org/abs/2402.15656](https://arxiv.org/abs/2402.15656)

    提出了一种学习半线性神经算子的方法，通过结合预测和校正操作实现了对长时间尺度上时空PDE的解进行处理与数据同化。

    

    最近神经算子（NOs）理论的进展使得能够快速而准确地计算由偏微分方程（PDEs）描述的复杂系统的解成为可能。尽管取得了巨大成功，但当前基于NO的解决方案在处理长时间尺度上的时空PDE时面临重要挑战。具体而言，当前的NO理论没有提出一个系统框架，以便根据稀疏采样的嘈杂测量有效地纠正PDE解的演化。本文提出了一种基于学习的状态空间方法来计算无限维半线性PDE的解算子。利用半线性PDE的结构和函数空间中的非线性观测者理论，我们开发了一种灵活的递归方法，通过结合预测和校正操作，允许同时进行预测和数据同化。

    arXiv:2402.15656v1 Announce Type: cross  Abstract: Recent advances in the theory of Neural Operators (NOs) have enabled fast and accurate computation of the solutions to complex systems described by partial differential equations (PDEs). Despite their great success, current NO-based solutions face important challenges when dealing with spatio-temporal PDEs over long time scales. Specifically, the current theory of NOs does not present a systematic framework to perform data assimilation and efficiently correct the evolution of PDE solutions over time based on sparsely sampled noisy measurements. In this paper, we propose a learning-based state-space approach to compute the solution operators to infinite-dimensional semilinear PDEs. Exploiting the structure of semilinear PDEs and the theory of nonlinear observers in function spaces, we develop a flexible recursive method that allows for both prediction and data assimilation by combining prediction and correction operations. The proposed 
    
[^124]: 客户服务中的联系复杂性

    Contact Complexity in Customer Service

    [https://arxiv.org/abs/2402.15655](https://arxiv.org/abs/2402.15655)

    开发了一种新颖的机器学习方法来定义联系复杂性，通过训练AI专家模型来评估客户问题复杂性，避免了人工标注的时间和金钱成本。

    

    联系客户服务支持的客户可能面临各种复杂程度不同的问题。将高复杂性的联系路由到初级代理可能导致多次转接或重复联系，而将低复杂性的联系路由到高级代理可能会使他们的专业帮助容量受到压力。为了解决这个问题，一种可以准确预测客户问题复杂性的机器学习模型至关重要。然而，定义联系的复杂性是一项困难的任务，因为它是一个高度抽象的概念。虽然经验代理进行基于共识的数据注释是一个可能的解决方案，但这需要耗费时间和金钱。为了克服这些障碍，我们开发了一种新颖的机器学习方法来定义联系复杂性。我们的方法不依赖于人工注释，而是训练一种AI专家模型来模拟代理的行为，并根据联系的行为评估每个联系的复杂性。

    arXiv:2402.15655v1 Announce Type: cross  Abstract: Customers who reach out for customer service support may face a range of issues that vary in complexity. Routing high-complexity contacts to junior agents can lead to multiple transfers or repeated contacts, while directing low-complexity contacts to senior agents can strain their capacity to assist customers who need professional help. To tackle this, a machine learning model that accurately predicts the complexity of customer issues is highly desirable. However, defining the complexity of a contact is a difficult task as it is a highly abstract concept. While consensus-based data annotation by experienced agents is a possible solution, it is time-consuming and costly. To overcome these challenges, we have developed a novel machine learning approach to define contact complexity. Instead of relying on human annotation, we trained an AI expert model to mimic the behavior of agents and evaluate each contact's complexity based on how the 
    
[^125]: 具有目标抑制的多约束安全强化学习用于安全关键应用

    Multi-Constraint Safe RL with Objective Suppression for Safety-Critical Applications

    [https://arxiv.org/abs/2402.15650](https://arxiv.org/abs/2402.15650)

    提出了一种目标抑制的新方法，可以在多约束安全领域中改进安全强化学习任务表现，实验证明此方法结合现有算法能够在减少约束违规的情况下实现与基准线相当的任务奖励水平。

    

    尽管在现实世界中非常常见，但具有多个约束条件的安全强化学习任务仍然是一个具有挑战性的领域。为了解决这一挑战，我们提出了一种新方法，即目标抑制，根据安全评判器自适应地抑制任务奖励最大化目标。我们在两个多约束安全领域中对目标抑制进行了基准测试，包括一个自动驾驶领域，在这个领域中任何错误的行为都可能导致灾难性后果。实证结果表明，我们提出的方法与现有的安全强化学习算法相结合，可以在显著减少约束违规的情况下匹配我们的基准线所达到的任务奖励。

    arXiv:2402.15650v1 Announce Type: cross  Abstract: Safe reinforcement learning tasks with multiple constraints are a challenging domain despite being very common in the real world. To address this challenge, we propose Objective Suppression, a novel method that adaptively suppresses the task reward maximizing objectives according to a safety critic. We benchmark Objective Suppression in two multi-constraint safety domains, including an autonomous driving domain where any incorrect behavior can lead to disastrous consequences. Empirically, we demonstrate that our proposed method, when combined with existing safe RL algorithms, can match the task reward achieved by our baselines with significantly fewer constraint violations.
    
[^126]: 细粒度的自认证可以提升事实性和推理能力

    Fine-Grained Self-Endorsement Improves Factuality and Reasoning

    [https://arxiv.org/abs/2402.15631](https://arxiv.org/abs/2402.15631)

    提出了利用自认证框架进行细粒度事实级别比较的方法，能够更好地减轻大型语言模型生成过程中的幻觉，尤其适用于长篇生成任务。

    

    这项工作研究了如何在推理时通过缓解存在事实冲突的幻觉来改善大型语言模型（LLM）生成。特别是，我们提出了一个自认证框架，利用跨多个抽样响应进行细粒度的事实级别比较。与先前的组合方法（王等，2022年；陈等，2023年）进行响应级别选择相比，我们的方法能够更好地减轻幻觉，特别是对于长篇生成任务。我们的方法可以广泛有益于较小和开源的LLM，因为它主要进行简单的基于内容的比较。在传记上的实验证明，我们的方法可以通过简单直观的提示有效改善不同规模的LLM生成的事实性。此外，对TriviaQA和GSM8K的全面分析展示了自认证在更广泛应用中的潜力。

    arXiv:2402.15631v1 Announce Type: cross  Abstract: This work studies improving large language model (LLM) generations at inference time by mitigating fact-conflicting hallucinations. Particularly, we propose a self-endorsement framework that leverages the fine-grained fact-level comparisons across multiple sampled responses. Compared with prior ensemble methods (Wang et al., 2022;Chen et al., 2023)) that perform response-level selection, our approach can better alleviate hallucinations, especially for longform generation tasks. Our approach can broadly benefit smaller and open-source LLMs as it mainly conducts simple content-based comparisons. Experiments on Biographies show that our method can effectively improve the factuality of generations with simple and intuitive prompts across different scales of LLMs. Besides, comprehensive analyses on TriviaQA and GSM8K demonstrate the potential of self-endorsement for broader application.
    
[^127]: 从不完整数据中学习循环因果模型

    Learning Cyclic Causal Models from Incomplete Data

    [https://arxiv.org/abs/2402.15625](https://arxiv.org/abs/2402.15625)

    提出了一个名为MissNODAGS的框架，可以从部分缺失数据中学习循环因果图，通过交替替补缺失数据和最大化可见数据部分的预期对数似然来学习因果图。

    

    因果学习是统计学和科学中的一个基本问题，它可以帮助预测未见治疗对系统的影响。尽管最近在这个领域取得了进展，但大多数现有的因果发现算法都基于两个关键假设：(i) 潜在图是无环的，(ii) 可用数据是完整的。这些假设可能存在问题，因为许多现实世界中的系统包含反馈环路（例如生物系统），实际情况经常涉及缺失数据。在这项工作中，我们提出了一个名为MissNODAGS的新框架，用于从部分缺失数据中学习循环因果图。在加性噪声模型下，MissNODAGS通过在每个训练步骤中在替补缺失数据与最大化数据可见部分的预期对数似然之间交替学习因果图，遵循期望最大化（EM）框架的原则。

    arXiv:2402.15625v1 Announce Type: cross  Abstract: Causal learning is a fundamental problem in statistics and science, offering insights into predicting the effects of unseen treatments on a system. Despite recent advances in this topic, most existing causal discovery algorithms operate under two key assumptions: (i) the underlying graph is acyclic, and (ii) the available data is complete. These assumptions can be problematic as many real-world systems contain feedback loops (e.g., biological systems), and practical scenarios frequently involve missing data. In this work, we propose a novel framework, named MissNODAGS, for learning cyclic causal graphs from partially missing data. Under the additive noise model, MissNODAGS learns the causal graph by alternating between imputing the missing data and maximizing the expected log-likelihood of the visible part of the data in each training step, following the principles of the expectation-maximization (EM) framework. Through synthetic exper
    
[^128]: RecWizard：一种具有模块化、便携模型和交互用户界面的对话式推荐工具包

    RecWizard: A Toolkit for Conversational Recommendation with Modular, Portable Models and Interactive User Interface

    [https://arxiv.org/abs/2402.15591](https://arxiv.org/abs/2402.15591)

    RecWizard是一种对话式推荐工具包，具有模块化、便携模型和交互用户界面，可提高CRS研究效率并减少额外工作量

    

    我们介绍了一种名为RecWizard的新Python工具包，用于对话式推荐系统（CRS）。RecWizard支持模型开发和交互用户界面，借鉴了Huggingface生态系统的最佳实践。CRS与RecWizard具有模块化、便携、交互和大型语言模型（LLMs）友好性，以简化学习过程并减少CRS研究的额外工作量。有关RecWizard更全面的信息，请查看我们的GitHub https://github.com/McAuley-Lab/RecWizard。

    arXiv:2402.15591v1 Announce Type: cross  Abstract: We present a new Python toolkit called RecWizard for Conversational Recommender Systems (CRS). RecWizard offers support for development of models and interactive user interface, drawing from the best practices of the Huggingface ecosystems. CRS with RecWizard are modular, portable, interactive and Large Language Models (LLMs)-friendly, to streamline the learning process and reduce the additional effort for CRS research. For more comprehensive information about RecWizard, please check our GitHub https://github.com/McAuley-Lab/RecWizard.
    
[^129]: 从学术手稿的同行评审叙事中要求LLMs撰写元评论草案

    Prompting LLMs to Compose Meta-Review Drafts from Peer-Review Narratives of Scholarly Manuscripts

    [https://arxiv.org/abs/2402.15589](https://arxiv.org/abs/2402.15589)

    本文研究了使用不同类型/级别的提示来激发三种流行LLM，GPT-3.5、LLaMA2和PaLM2，在学术同行评审过程中自动生成元评论，并进行了详细的定性研究。

    

    学术同行评审过程中最重要但也最繁重的任务之一是撰写元评论，这涉及根据多位专家的同行评审叙事理解学术手稿的核心贡献、优点和缺点，然后将这些专家多视角的看法总结为简洁的整体概述。鉴于生成型AI，尤其是大型语言模型（LLMs）的最新重大发展，我们有充分的理由深入研究LLMs在学术同行评审环境中生成这种元评论的实用性。本文通过使用三种流行的LLM，即GPT-3.5、LLaMA2和PaLM2，执行案例研究，通过基于最近提出的TELeR分类法以不同类型/级别的提示促使它们自动生成元评论。最后，我们对LLM生成的元评论进行了详细的定性研究，并总结了我们的发现。

    arXiv:2402.15589v1 Announce Type: cross  Abstract: One of the most important yet onerous tasks in the academic peer-reviewing process is composing meta-reviews, which involves understanding the core contributions, strengths, and weaknesses of a scholarly manuscript based on peer-review narratives from multiple experts and then summarizing those multiple experts' perspectives into a concise holistic overview. Given the latest major developments in generative AI, especially Large Language Models (LLMs), it is very compelling to rigorously study the utility of LLMs in generating such meta-reviews in an academic peer-review setting. In this paper, we perform a case study with three popular LLMs, i.e., GPT-3.5, LLaMA2, and PaLM2, to automatically generate meta-reviews by prompting them with different types/levels of prompts based on the recently proposed TELeR taxonomy. Finally, we perform a detailed qualitative study of the meta-reviews generated by the LLMs and summarize our findings and 
    
[^130]: 通过不确定性改进可解释的物体诱导模型，以提高自动驾驶车辆的性能

    Improving Explainable Object-induced Model through Uncertainty for Automated Vehicles

    [https://arxiv.org/abs/2402.15572](https://arxiv.org/abs/2402.15572)

    本研究通过将不确定性评估整合到决策过程中，基于“物体诱导”模型方法并利用先进训练策略，改进了可解释的AV模型，在复杂驾驶场景中提供更清晰的决策理解

    

    自动驾驶车辆（AV）的快速发展有望提供更安全、更高效和更舒适的出行选择。然而，这些系统在复杂驾驶场景中面临可靠性挑战。最近的可解释AV架构在提供动作解释时忽略了与内在不确定性相关的关键信息。为了克服这些挑战，我们的研究基于“物体诱导”模型方法，该方法强调场景中物体在决策中的作用，并使用具有Beta先验的证据深度学习范式将不确定性评估整合到决策过程中。此外，我们探讨了几种受不确定性引导的先进训练策略，包括受不确定性引导的数据重新加权和增强。通过利用BDD-OIA数据集，我们的研究结果强调，通过这些增强措施，该模型不仅提供了对AV决策更清晰的理解

    arXiv:2402.15572v1 Announce Type: new  Abstract: The rapid evolution of automated vehicles (AVs) has the potential to provide safer, more efficient, and comfortable travel options. However, these systems face challenges regarding reliability in complex driving scenarios. Recent explainable AV architectures neglect crucial information related to inherent uncertainties while providing explanations for actions. To overcome such challenges, our study builds upon the "object-induced" model approach that prioritizes the role of objects in scenes for decision-making and integrates uncertainty assessment into the decision-making process using an evidential deep learning paradigm with a Beta prior. Additionally, we explore several advanced training strategies guided by uncertainty, including uncertainty-guided data reweighting and augmentation. Leveraging the BDD-OIA dataset, our findings underscore that the model, through these enhancements, not only offers a clearer comprehension of AV decisi
    
[^131]: 一分钟内在语言模型上的快速对抗攻击

    Fast Adversarial Attacks on Language Models In One GPU Minute

    [https://arxiv.org/abs/2402.15570](https://arxiv.org/abs/2402.15570)

    介绍了一种新型的基于束搜索的快速对抗攻击方法BEAST，能够在一分钟内高成功率地越狱对齐的语言模型，同时还能导致语言模型产生幻觉。

    

    在这篇论文中，我们介绍了一种新型的快速基于束搜索的语言模型对抗攻击（BEAST）。BEAST采用可解释的参数，使攻击者能够在攻击速度、成功率和对抗性提示的可读性之间取得平衡。BEAST的计算效率使我们能够研究其在语言模型中用于越狱、引发幻觉和隐私攻击的应用。我们的基于梯度的有针对性攻击可以在一分钟内越狱对齐的语言模型，攻击成功率很高。例如，与基于梯度的基准相比，BEAST可以在一分钟内越狱 Vicuna-7B-v1.5，成功率达到89%，而基准方法需要一个小时以上才能使用单个 Nvidia RTX A6000 48GB GPU 实现70%的成功率。此外，我们发现一个独特的结果，即我们的非有针对性攻击会导致语言模型聊天机器人产生幻觉。通过人类评估，我们发现我们的非有针对性攻击导致了

    arXiv:2402.15570v1 Announce Type: cross  Abstract: In this paper, we introduce a novel class of fast, beam search-based adversarial attack (BEAST) for Language Models (LMs). BEAST employs interpretable parameters, enabling attackers to balance between attack speed, success rate, and the readability of adversarial prompts. The computational efficiency of BEAST facilitates us to investigate its applications on LMs for jailbreaking, eliciting hallucinations, and privacy attacks. Our gradient-free targeted attack can jailbreak aligned LMs with high attack success rates within one minute. For instance, BEAST can jailbreak Vicuna-7B-v1.5 under one minute with a success rate of 89% when compared to a gradient-based baseline that takes over an hour to achieve 70% success rate using a single Nvidia RTX A6000 48GB GPU. Additionally, we discover a unique outcome wherein our untargeted attack induces hallucinations in LM chatbots. Through human evaluations, we find that our untargeted attack cause
    
[^132]: 具有希尔伯特表示的基础政策

    Foundation Policies with Hilbert Representations

    [https://arxiv.org/abs/2402.15567](https://arxiv.org/abs/2402.15567)

    该研究提出了一个新颖的无监督框架，用于从未标记的离线数据中预训练通用政策，以捕获多样化、最优、长时域行为。

    

    arXiv:2402.15567v1 进行类型：交叉 摘要：无监督和自监督目标，例如下一个令牌预测，已经使得可以从大量未标记的数据中预训练通用模型。然而，在强化学习（RL）中，从离线数据中找到一个真正通用且可扩展的无监督预训练目标以获取通用政策仍然是一个主要的开放问题。尽管已经提出了许多方法来实现通用的自监督RL，基于诸如基于目标的RL、行为克隆和无监督技能学习等原则，但这些方法在发现的行为多样性、需要高质量演示数据或缺乏明确的提示或适应机制以用于下游任务方面仍然存在局限性。在这项工作中，我们提出了一个新颖的无监督框架，用于预训练能够捕捉多样化、最优、长时域行为的通用政策，从未标记的离线数据中获取这些行为，以便它们可以快速适应

    arXiv:2402.15567v1 Announce Type: cross  Abstract: Unsupervised and self-supervised objectives, such as next token prediction, have enabled pre-training generalist models from large amounts of unlabeled data. In reinforcement learning (RL), however, finding a truly general and scalable unsupervised pre-training objective for generalist policies from offline data remains a major open question. While a number of methods have been proposed to enable generic self-supervised RL, based on principles such as goal-conditioned RL, behavioral cloning, and unsupervised skill learning, such methods remain limited in terms of either the diversity of the discovered behaviors, the need for high-quality demonstration data, or the lack of a clear prompting or adaptation mechanism for downstream tasks. In this work, we propose a novel unsupervised framework to pre-train generalist policies that capture diverse, optimal, long-horizon behaviors from unlabeled offline data such that they can be quickly ada
    
[^133]: 深度神经网络总是理解并且这就是原因

    Deep Networks Always Grok and Here is Why

    [https://arxiv.org/abs/2402.15555](https://arxiv.org/abs/2402.15555)

    深度神经网络存在延迟泛化和延迟鲁棒性现象，在各种实际环境中普遍存在，并基于新的局部复杂度度量提供了解释。

    

    Grokking，或者延迟泛化，是指深度神经网络（DNN）在达到接近于零的训练误差后很长时间内才发生泛化的现象。先前的研究报告了在特定受控环境中出现grokking的情况，例如使用大范数参数初始化的DNN或者在算法数据集上训练的transformers。我们展示了grokking实际上更加普遍，并且在广泛的实际环境中呈现，例如在CIFAR10上训练的卷积神经网络（CNN）或者在Imagenette上训练的Resnet。我们引入了延迟鲁棒性的新概念，即DNN在插值和/或泛化之后对抗示例进行理解并变得鲁棒。我们针对DNN的输入-输出映射的局部复杂度提出了出现延迟泛化和延迟鲁棒性的解释。我们的局部复杂度衡量了DNN输入-输出映射的复杂程度。

    arXiv:2402.15555v1 Announce Type: cross  Abstract: Grokking, or delayed generalization, is a phenomenon where generalization in a deep neural network (DNN) occurs long after achieving near zero training error. Previous studies have reported the occurrence of grokking in specific controlled settings, such as DNNs initialized with large-norm parameters or transformers trained on algorithmic datasets. We demonstrate that grokking is actually much more widespread and materializes in a wide range of practical settings, such as training of a convolutional neural network (CNN) on CIFAR10 or a Resnet on Imagenette. We introduce the new concept of delayed robustness, whereby a DNN groks adversarial examples and becomes robust, long after interpolation and/or generalization. We develop an analytical explanation for the emergence of both delayed generalization and delayed robustness based on a new measure of the local complexity of a DNN's input-output mapping. Our local complexity measures the d
    
[^134]: 机器人学中的形态对称性

    Morphological Symmetries in Robotics

    [https://arxiv.org/abs/2402.15552](https://arxiv.org/abs/2402.15552)

    形态对称性是机器人系统中的固有性质，通过对运动结构和质量的对称分布，延伸至机器人状态空间和传感器测量，进而影响机器人的运动方程和最优控制策略，并在机器人学建模、控制和设计中具有重要意义。

    

    我们提出了一个全面的框架来研究和利用机器人系统中的形态对称性。这些是机器人形态的固有特性，经常在动物生物学和机器人学中观察到，源于运动结构的复制和质量的对称分布。我们说明了这些对称性如何延伸到机器人的状态空间以及本体感知和外部感知传感器测量，导致机器人的运动方程和最优控制策略的等不变性。因此，我们认识到形态对称性作为一个相关且以前未被探索的受物理启示的几何先验，对机器人建模、控制、估计和设计中使用的数据驱动和分析方法都具有重要影响。对于数据驱动方法，我们演示了形态对称性如何提高机器学习模型的样本效率和泛化能力

    arXiv:2402.15552v1 Announce Type: cross  Abstract: We present a comprehensive framework for studying and leveraging morphological symmetries in robotic systems. These are intrinsic properties of the robot's morphology, frequently observed in animal biology and robotics, which stem from the replication of kinematic structures and the symmetrical distribution of mass. We illustrate how these symmetries extend to the robot's state space and both proprioceptive and exteroceptive sensor measurements, resulting in the equivariance of the robot's equations of motion and optimal control policies. Thus, we recognize morphological symmetries as a relevant and previously unexplored physics-informed geometric prior, with significant implications for both data-driven and analytical methods used in modeling, control, estimation and design in robotics. For data-driven methods, we demonstrate that morphological symmetries can enhance the sample efficiency and generalization of machine learning models 
    
[^135]: HiMAP：用于大规模多智体路径规划的学习启发式策略

    HiMAP: Learning Heuristics-Informed Policies for Large-Scale Multi-Agent Pathfinding

    [https://arxiv.org/abs/2402.15546](https://arxiv.org/abs/2402.15546)

    HiMAP 是一种新颖的可伸缩方法，使用启发式引导的模仿学习在分散式训练中对用户智体路径规划进行了改进

    

    大规模多智体路径规划（MAPF）在多个领域都存在着重大挑战。随着系统的复杂性随着大量自治体同时操作而增长，高效和避免碰撞的协调变得至关重要。传统算法在可伸缩性方面通常表现不佳，特别是在复杂场景中。强化学习（RL）已经显示出潜力来解决MAPF的复杂性；然而，它也被发现在可伸缩性方面遇到困难，需要精细的实施、漫长的训练，而且通常表现出不稳定的收敛性，限制了其实际应用。在本文中，我们介绍了Heuristics-Informed Multi-Agent Pathfinding（HiMAP），这是一种新颖的可伸缩方法，采用以启发式引导的模仿学习方式来进行分散式训练。我们在小规模实例上进行训练，使用一个启发式策略作为教师，将每个单个智体观测信息映射到行动概率

    arXiv:2402.15546v1 Announce Type: cross  Abstract: Large-scale multi-agent pathfinding (MAPF) presents significant challenges in several areas. As systems grow in complexity with a multitude of autonomous agents operating simultaneously, efficient and collision-free coordination becomes paramount. Traditional algorithms often fall short in scalability, especially in intricate scenarios. Reinforcement Learning (RL) has shown potential to address the intricacies of MAPF; however, it has also been shown to struggle with scalability, demanding intricate implementation, lengthy training, and often exhibiting unstable convergence, limiting its practical application. In this paper, we introduce Heuristics-Informed Multi-Agent Pathfinding (HiMAP), a novel scalable approach that employs imitation learning with heuristic guidance in a decentralized manner. We train on small-scale instances using a heuristic policy as a teacher that maps each single agent observation information to an action prob
    
[^136]: AgentLite: 用于构建和推动面向任务的LLM Agent系统的轻量级库

    AgentLite: A Lightweight Library for Building and Advancing Task-Oriented LLM Agent System

    [https://arxiv.org/abs/2402.15538](https://arxiv.org/abs/2402.15538)

    AgentLite是一个用于简化构建LLM代理推理和架构的轻量级库。

    

    LLM的蓬勃发展引发了LLM代理的快速发展。尽管LLM代理的基础是生成模型，但设计最佳推理策略和代理架构至关重要。因此，LLM代理研究从简单的思维链推进发展到更复杂的ReAct和Reflection推理策略；代理架构也从单一代理生成发展到多代理对话，以及多个LLM多代理组群聊。然而，由于现有复杂的框架和库，创建和评估新的推理策略和代理架构已成为一个复杂的挑战，这妨碍了LLM代理的研究调查。因此，我们开源了一个新的人工智能代理库，AgentLite，通过提供一个轻便、用户友好的平台，简化了这一过程，轻松创新LLM代理的推理、架构和应用。AgentLite是一个任务

    arXiv:2402.15538v1 Announce Type: cross  Abstract: The booming success of LLMs initiates rapid development in LLM agents. Though the foundation of an LLM agent is the generative model, it is critical to devise the optimal reasoning strategies and agent architectures. Accordingly, LLM agent research advances from the simple chain-of-thought prompting to more complex ReAct and Reflection reasoning strategy; agent architecture also evolves from single agent generation to multi-agent conversation, as well as multi-LLM multi-agent group chat. However, with the existing intricate frameworks and libraries, creating and evaluating new reasoning strategies and agent architectures has become a complex challenge, which hinders research investigation into LLM agents. Thus, we open-source a new AI agent library, AgentLite, which simplifies this process by offering a lightweight, user-friendly platform for innovating LLM agent reasoning, architectures, and applications with ease. AgentLite is a task
    
[^137]: 评估ChatGPT用于垃圾邮件检测的性能

    Evaluating the Performance of ChatGPT for Spam Email Detection

    [https://arxiv.org/abs/2402.15537](https://arxiv.org/abs/2402.15537)

    该研究评估了ChatGPT在英文和中文电子邮件数据集中用于垃圾邮件检测的性能，并探讨了其在这一领域的潜力。

    

    电子邮件继续是专业和商业领域中至关重要且广泛使用的通信媒介。然而，垃圾邮件的普及给用户带来了重大挑战，扰乱了他们的日常工作并降低了生产率。因此，基于内容准确地识别和过滤垃圾邮件对网络安全至关重要。最近自然语言处理领域的发展，特别是大型语言模型如ChatGPT，在诸如问答和文本生成等任务中表现出色。然而，其在垃圾邮件识别方面的潜力尚未得到充分探索。为了填补这一空白，本研究尝试评估ChatGPT在英文和中文电子邮件数据集中用于垃圾邮件识别的能力。我们利用ChatGPT进行垃圾邮件检测，采用上下文学习，需要提示说明和少量示范。

    arXiv:2402.15537v1 Announce Type: cross  Abstract: Email continues to be a pivotal and extensively utilized communication medium within professional and commercial domains. Nonetheless, the prevalence of spam emails poses a significant challenge for users, disrupting their daily routines and diminishing productivity. Consequently, accurately identifying and filtering spam based on content has become crucial for cybersecurity. Recent advancements in natural language processing, particularly with large language models like ChatGPT, have shown remarkable performance in tasks such as question answering and text generation. However, its potential in spam identification remains underexplored. To fill in the gap, this study attempts to evaluate ChatGPT's capabilities for spam identification in both English and Chinese email datasets. We employ ChatGPT for spam email detection using in-context learning, which requires a prompt instruction and a few demonstrations. We also investigate how the t
    
[^138]: PCA-Bench: 评估多模大型语言模型在感知-认知-行动链中的表现

    PCA-Bench: Evaluating Multimodal Large Language Models in Perception-Cognition-Action Chain

    [https://arxiv.org/abs/2402.15527](https://arxiv.org/abs/2402.15527)

    PCA-Bench 提出了一个评估多模大型语言模型综合能力的基准，引入复杂场景和错误定位能力，提高部署可靠性，并提出了自动评估协议 PCA-Eval，发现了显著的性能差异。

    

    我们提出了PCA-Bench，这是一个用于评估多模大型语言模型（MLLMs）综合能力的多模决策基准。与之前专注于简单任务和单个模型能力的基准不同，PCA-Bench引入了三个复杂场景：自动驾驶、家庭机器人和开放世界游戏。在给定任务指令和多样化上下文的情况下，模型需要无缝整合感知、认知和行动的多重能力，以进行推理链以做出准确决定。此外，PCA-Bench具有错误定位能力，审查模型在感知、知识或推理等领域的不准确性。这提高了部署MLLMs的可靠性。为了在评估中平衡准确性和效率，我们提出了PCA-Eval，一种自动评估协议，并评估了10种流行的MLLMs。结果显示了显著的性能差异。

    arXiv:2402.15527v1 Announce Type: cross  Abstract: We present PCA-Bench, a multimodal decision-making benchmark for evaluating the integrated capabilities of Multimodal Large Language Models (MLLMs). Departing from previous benchmarks focusing on simplistic tasks and individual model capability, PCA-Bench introduces three complex scenarios: autonomous driving, domestic robotics, and open-world games. Given task instructions and diverse contexts, the model is required to seamlessly integrate multiple capabilities of Perception, Cognition, and Action in a reasoning chain to make accurate decisions. Moreover, PCA-Bench features error localization capabilities, scrutinizing model inaccuracies in areas such as perception, knowledge, or reasoning. This enhances the reliability of deploying MLLMs. To balance accuracy and efficiency in evaluation, we propose PCA-Eval, an automatic evaluation protocol, and assess 10 prevalent MLLMs. The results reveal significant performance disparities between
    
[^139]: Chain-of-Specificity: 一种从大型语言模型中提取知识的逐步精化方法

    Chain-of-Specificity: An Iteratively Refining Method for Eliciting Knowledge from Large Language Models

    [https://arxiv.org/abs/2402.15526](https://arxiv.org/abs/2402.15526)

    Chain-of-Specificity (CoS)是一种从大型语言模型中提取知识的逐步精化方法，能够在输入指令中迭代强调特定约束，解锁知识并改进回应。

    

    大型语言模型(LLMs)展现出引人瞩目的生成能力，能够生成有价值的信息。然而，先前的研究发现，LLMs有时难以遵循具体的约束(如在特定地点或特定时间)，甚至有时会忽略这些约束，导致回应要么太笼统，要么不够满意。本文提出一种简单而有效的方法，名为Chain-of-Specificity (CoS)。具体而言，CoS迭代地强调输入指令中的具体约束，解锁LLMs内部的知识，并精化回应。

    arXiv:2402.15526v1 Announce Type: new  Abstract: Large Language Models (LLMs) exhibit remarkable generative capabilities, enabling the generation of valuable information. Despite these advancements, previous research found that LLMs sometimes struggle with adhering to specific constraints (e.g., in specific place or at specific time), at times even overlooking them, which leads to responses that are either too generic or not fully satisfactory. Existing approaches attempted to address this issue by decomposing or rewriting input instructions, yet they fall short in adequately emphasizing specific constraints and in unlocking the underlying knowledge (e.g., programming within the context of software development). In response, this paper proposes a simple yet effective method named Chain-of-Specificity (CoS). Specifically, CoS iteratively emphasizes the specific constraints in the input instructions, unlocks knowledge within LLMs, and refines responses. Experiments conducted on publicly 
    
[^140]: 图剪枝用于枚举最小不可满足子集

    Graph Pruning for Enumeration of Minimal Unsatisfiable Subsets

    [https://arxiv.org/abs/2402.15524](https://arxiv.org/abs/2402.15524)

    提出了一种图剪枝算法，通过基于图的学习模型预测修剪公式的部分，加速枚举最小不可满足子集，无需数据标记，也无需来自目标应用的训练数据，实验结果表明在各种基准测试中的有效性。

    

    寻找二进制约束的最小不可满足子集（MUSes）是超约束系统不可行性分析中的常见问题。然而，由于问题的指数搜索空间，枚举MUSes在实际应用中非常耗时。本文提出使用学习模型对公式进行修剪以加速MUS枚举。我们将公式表示为图，然后开发基于图的学习模型来预测应该修剪公式的哪一部分。重要的是，我们的算法不需要通过仅检查修剪后的公式的可满足性来进行数据标记。它甚至不需要来自目标应用的训练数据，因为它对具有不同分布的数据进行外推。在我们的实验中，我们将我们的算法与现有的MUS枚举器结合，并验证其在包括一组超出我们训练分布范围的实际问题在内的多个基准测试中的有效性。

    arXiv:2402.15524v1 Announce Type: new  Abstract: Finding Minimal Unsatisfiable Subsets (MUSes) of binary constraints is a common problem in infeasibility analysis of over-constrained systems. However, because of the exponential search space of the problem, enumerating MUSes is extremely time-consuming in real applications. In this work, we propose to prune formulas using a learned model to speed up MUS enumeration. We represent formulas as graphs and then develop a graph-based learning model to predict which part of the formula should be pruned. Importantly, our algorithm does not require data labeling by only checking the satisfiability of pruned formulas. It does not even require training data from the target application because it extrapolates to data with different distributions. In our experiments we combine our algorithm with existing MUS enumerators and validate its effectiveness in multiple benchmarks including a set of real-world problems outside our training distribution. The
    
[^141]: IntSat: 基于冲突驱动约束学习的整数线性规划

    IntSat: Integer Linear Programming by Conflict-Driven Constraint-Learning

    [https://arxiv.org/abs/2402.15522](https://arxiv.org/abs/2402.15522)

    把冲突驱动子句学习扩展到整数线性规划，有效实现并讨论改进，成为ILP求解领域有用的补充。

    

    如今的最先进的SAT求解器能够处理大规模的现实世界实例。这一成功的关键在于所谓的冲突驱动子句学习（CDCL）方案，该方案包括一些利用在搜索解决方案过程中遇到的冲突的技术。在本文中，我们将这些技术扩展到整数线性规划（ILP）中，其中变量可以取一般整数值而不仅仅是二进制值，约束比命题子句更具表达力，可能存在一个要优化的目标函数。我们解释了如何高效地实现这些方法，并讨论了可能的改进。我们的工作得到了一个基本实现的支持，该实现表明，即使在这个远未成熟的阶段，我们的技术已经是ILP求解领域中最先进技术的有用补充。

    arXiv:2402.15522v1 Announce Type: new  Abstract: State-of-the-art SAT solvers are nowadays able to handle huge real-world instances. The key to this success is the so-called Conflict-Driven Clause-Learning (CDCL) scheme, which encompasses a number of techniques that exploit the conflicts that are encountered during the search for a solution. In this article we extend these techniques to Integer Linear Programming (ILP), where variables may take general integer values instead of purely binary ones, constraints are more expressive than just propositional clauses, and there may be an objective function to optimise. We explain how these methods can be implemented efficiently, and discuss possible improvements. Our work is backed with a basic implementation that shows that, even in this far less mature stage, our techniques are already a useful complement to the state of the art in ILP solving.
    
[^142]: 基于知识和数据驱动服务的混合智能家居系统 - HKD-SHO

    HKD-SHO: A hybrid smart home system based on knowledge-based and data-driven services

    [https://arxiv.org/abs/2402.15521](https://arxiv.org/abs/2402.15521)

    提出了一个名为HKD-SHO的混合智能家居系统，将基于知识和基于机器学习的数据驱动服务有益地融合在一起，解决了智能家居系统中基于知识和数据驱动方法的问题。

    

    一个智能家居通过设置各种服务来实现。已经提出了几种用于创建智能家居服务的方法，可以分为基于知识和数据驱动的方法。然而，基于知识的方法通常需要居民的手动输入，如果所关注环境状态的物理现象复杂，而且居民不知道如何调整相关执行器以实现服务监视的状态的目标值，则可能会变得复杂。此外，我们感兴趣的基于机器学习的数据驱动方法就像黑匣子一样，无法向居民展示在哪些情况下某些服务提出了某些执行器状态。为了解决这些问题，我们提出了一个名为HKD-SHO（基于混合知识和数据驱动服务的智能家居系统）的混合系统。

    arXiv:2402.15521v1 Announce Type: new  Abstract: A smart home is realized by setting up various services. Several methods have been proposed to create smart home services, which can be divided into knowledge-based and data-driven approaches. However, knowledge-based approaches usually require manual input from the inhabitant, which can be complicated if the physical phenomena of the concerned environment states are complex, and the inhabitant does not know how to adjust related actuators to achieve the target values of the states monitored by services. Moreover, machine learning-based data-driven approaches that we are interested in are like black boxes and cannot show the inhabitant in which situations certain services proposed certain actuators' states. To solve these problems, we propose a hybrid system called HKD-SHO (Hybrid Knowledge-based and Data-driven services based Smart HOme system), where knowledge-based and machine learning-based data-driven services are profitably integra
    
[^143]: 在现实世界的数据中识别与阿尔茨海默病和相关痴呆症相关因素的可行性

    Feasibility of Identifying Factors Related to Alzheimer's Disease and Related Dementia in Real-World Data

    [https://arxiv.org/abs/2402.15515](https://arxiv.org/abs/2402.15515)

    通过研究现有文献，总结了阿尔茨海默病和相关痴呆症的风险因素，构建了知识图谱，并指出基因组风险因素的评估仍然是一个挑战。

    

    一个关于与阿尔茨海默病/相关痴呆症相关因素的全面视角将极大地帮助开展新的治疗研究，并为预防工作确定高风险人群和患者。本研究通过回顾现有的风险和预防因素的Meta分析和综述文章，总结了与阿尔茨海默病/相关痴呆症相关的危险因素。总共，我们从537项研究中提取了10个类别中的477个危险因素。我们构建了一个交互式知识图谱来传播我们的研究结果。大多数风险因素可从结构化的电子健康记录（EHRs）中获得，临床叙述显示出作为信息来源的潜力。然而，使用实际世界数据评估基因组风险因素仍然是一个挑战，因为对阿尔茨海默病/相关痴呆症的基因检测仍然不是常规做法，而且在结构化和非结构化的EHRs中记录不良。考虑到关于阿尔茨海默病/相关痴呆症风险因素不断发展的研究，文献挖掘v

    arXiv:2402.15515v1 Announce Type: new  Abstract: A comprehensive view of factors associated with AD/ADRD will significantly aid in studies to develop new treatments for AD/ADRD and identify high-risk populations and patients for prevention efforts. In our study, we summarized the risk factors for AD/ADRD by reviewing existing meta-analyses and review articles on risk and preventive factors for AD/ADRD. In total, we extracted 477 risk factors in 10 categories from 537 studies. We constructed an interactive knowledge map to disseminate our study results. Most of the risk factors are accessible from structured Electronic Health Records (EHRs), and clinical narratives show promise as information sources. However, evaluating genomic risk factors using RWD remains a challenge, as genetic testing for AD/ADRD is still not a common practice and is poorly documented in both structured and unstructured EHRs. Considering the constantly evolving research on AD/ADRD risk factors, literature mining v
    
[^144]: 大规模生成式人工智能文本在体育和音乐领域的应用

    Large Scale Generative AI Text Applied to Sports and Music

    [https://arxiv.org/abs/2402.15514](https://arxiv.org/abs/2402.15514)

    这项工作利用生成式人工智能模型将大规模多模数据转化为连贯流畅文本，首次推出了用于体育和音乐领域的AI评论系统，并取得了显著性能提升。

    

    我们解决了将媒体内容（包括评论和个性化新闻报道）扩展到全球大型体育和音乐活动的生产问题。我们的方法依赖生成式人工智能模型，将大量多模数据（例如视频、文章、实时比分、统计数据和资料）转换为连贯流畅的文本。基于这一方法，我们首次推出了一款人工智能评论系统，该系统被部署用于为2023年美国公开赛、温布尔登公开赛和大师赛的精彩片段制作自动化叙述。我们的解决方案还被扩展用于为ESPN梦幻橄榄球和格莱美奖音乐艺术家故事创造个性化内容。这些应用程序采用了相同的软件架构，实现了15倍的速度提升，平均Rouge-L为82.00，困惑度为6.6。

    arXiv:2402.15514v1 Announce Type: cross  Abstract: We address the problem of scaling up the production of media content, including commentary and personalized news stories, for large-scale sports and music events worldwide. Our approach relies on generative AI models to transform a large volume of multimodal data (e.g., videos, articles, real-time scoring feeds, statistics, and fact sheets) into coherent and fluent text. Based on this approach, we introduce, for the first time, an AI commentary system, which was deployed to produce automated narrations for highlight packages at the 2023 US Open, Wimbledon, and Masters tournaments. In the same vein, our solution was extended to create personalized content for ESPN Fantasy Football and stories about music artists for the Grammy awards. These applications were built using a common software architecture achieved a 15x speed improvement with an average Rouge-L of 82.00 and perplexity of 6.6. Our work was successfully deployed at the aforeme
    
[^145]: AgentOhana：为有效智能体学习设计统一数据和训练流水线

    AgentOhana: Design Unified Data and Training Pipeline for Effective Agent Learning

    [https://arxiv.org/abs/2402.15506](https://arxiv.org/abs/2402.15506)

    AgentOhana提供了一种统一数据和训练流水线的综合解决方案，有助于克服使用大型语言模型（LLMs）进行智能体任务时的挑战。

    

    由大型语言模型（LLMs）提供支持的自主智能体引起了重大研究关注。然而，充分利用LLMs的潜力进行基于智能体的任务面临困难，这是由于具有多轮轨迹的多样化数据源的异构性。在本文中，我们介绍AgentOhana作为解决这些挑战的综合解决方案。AgentOhana从不同环境中聚合智能体轨迹，涵盖了各种情景。它精心地将这些轨迹标准化和统一到一致的格式中，简化了为智能体训练优化的通用数据加载器的创建。通过数据统一，我们的训练流水线在不同数据源之间保持平衡，并在数据集划分和模型训练过程中保持设备之间的独立随机性。此外，我们还介绍了xLAM-v0.1，一个大动作模式

    arXiv:2402.15506v1 Announce Type: new  Abstract: Autonomous agents powered by large language models (LLMs) have garnered significant research attention. However, fully harnessing the potential of LLMs for agent-based tasks presents inherent challenges due to the heterogeneous nature of diverse data sources featuring multi-turn trajectories. In this paper, we introduce \textbf{AgentOhana} as a comprehensive solution to address these challenges. \textit{AgentOhana} aggregates agent trajectories from distinct environments, spanning a wide array of scenarios. It meticulously standardizes and unifies these trajectories into a consistent format, streamlining the creation of a generic data loader optimized for agent training. Leveraging the data unification, our training pipeline maintains equilibrium across different data sources and preserves independent randomness across devices during dataset partitioning and model training. Additionally, we present \textbf{xLAM-v0.1}, a large action mode
    
[^146]: ArabianGPT：基于原生阿拉伯语的大型语言模型

    ArabianGPT: Native Arabic GPT-based Large Language

    [https://arxiv.org/abs/2402.15313](https://arxiv.org/abs/2402.15313)

    提出了ArabianGPT，这是一系列专门为阿拉伯语设计的基于Transformer的模型，包括大小和复杂性不同的ArabianGPT-0.1B和ArabianGPT-0.3B，帮助弥补了本土阿拉伯语大型语言模型的不足。

    

    英语和拉丁语为主导的大型语言模型（LLMs）的主导地位导致了本土阿拉伯语LLMs的显著不足。本文提出ArabianGPT，这是一系列基于Transformer的模型，专门为阿拉伯语设计而成。这些模型包括ArabianGPT-0.1B和ArabianGPT-0.3B，大小和复杂性不同，与阿拉伯语的微妙语言特征相契合。

    arXiv:2402.15313v1 Announce Type: cross  Abstract: The predominance of English and Latin-based large language models (LLMs) has led to a notable deficit in native Arabic LLMs. This discrepancy is accentuated by the prevalent inclusion of English tokens in existing Arabic models, detracting from their efficacy in processing native Arabic's intricate morphology and syntax. Consequently, there is a theoretical and practical imperative for developing LLMs predominantly focused on Arabic linguistic elements. To address this gap, this paper proposes ArabianGPT, a series of transformer-based models within the ArabianLLM suite designed explicitly for Arabic. These models, including ArabianGPT-0.1B and ArabianGPT-0.3B, vary in size and complexity, aligning with the nuanced linguistic characteristics of Arabic. The AraNizer tokenizer, integral to these models, addresses the unique morphological aspects of Arabic script, ensuring more accurate text processing. Empirical results from fine-tuning t
    
[^147]: fNIRS中深度学习分类模型的校准

    Calibration of Deep Learning Classification Models in fNIRS

    [https://arxiv.org/abs/2402.15266](https://arxiv.org/abs/2402.15266)

    在fNIRS领域，我们提出将校准整合到模型中以评估其可靠性，结果显示许多现有模型的校准性能不佳。

    

    功能性近红外光谱（fNIRS）是用于监测脑活动的宝贵无创工具。与意识活动相关的fNIRS数据分类对于推进我们对大脑的理解和促进脑机接口（BCI）的发展具有重要意义。许多研究人员转向深度学习来解决fNIRS数据中固有的分类挑战，因为它具有很强的泛化能力和鲁棒性。在fNIRS的应用中，可靠性非常重要，置信度可靠性的数学表达式之一就是校准。然而，许多研究人员忽视了校准这个重要问题。为了解决这一空白，我们提出了将校准融入fNIRS领域，并评估现有模型的可靠性。令人惊讶的是，我们的研究结果表明，许多提出的模型在校准性能方面表现不佳。为了推动fNIRS领域的校准发展，我们提出 ...

    arXiv:2402.15266v1 Announce Type: new  Abstract: Functional near-infrared spectroscopy (fNIRS) is a valuable non-invasive tool for monitoring brain activity. The classification of fNIRS data in relation to conscious activity holds significance for advancing our understanding of the brain and facilitating the development of brain-computer interfaces (BCI). Many researchers have turned to deep learning to tackle the classification challenges inherent in fNIRS data due to its strong generalization and robustness. In the application of fNIRS, reliability is really important, and one mathematical formulation of the reliability of confidence is calibration. However, many researchers overlook the important issue of calibration. To address this gap, we propose integrating calibration into fNIRS field and assess the reliability of existing models. Surprisingly, our results indicate poor calibration performance in many proposed models. To advance calibration development in the fNIRS field, we su
    
[^148]: LLMBind: 一种统一的模态任务集成框架

    LLMBind: A Unified Modality-Task Integration Framework

    [https://arxiv.org/abs/2402.14891](https://arxiv.org/abs/2402.14891)

    提出了LLMBind，一种统一的模态任务集成框架，通过将大型语言模型和预训练任务模型绑定在一起，实现了多种模态任务的灵活输入和输出组合。

    

    最近对于多模态大型语言模型在处理各种模态任务方面取得了进展，但它们对于复杂的多模态任务的集成能力有限，从而限制了该领域的发展。在这项工作中，我们带头探索并提出了LLMBind，一种用于模态任务集成的统一框架，该框架将大型语言模型和相应的预训练任务模型与任务特定的标记绑定在一起。因此，LLMBind可以以多种图像、文本、视频和音频的组合解释输入并生成输出。具体来说，我们引入了一种专家混合技术，通过不同专家之间的协作实现不同多模态任务的有效学习。此外，我们创建了一个包含40万条指令数据的多任务数据集，解锁了交互式视觉生成和编辑任务的能力。大量实验证明了我们的方法的有效性。

    arXiv:2402.14891v1 Announce Type: cross  Abstract: While recent progress in multimodal large language models tackles various modality tasks, they posses limited integration capabilities for complex multi-modality tasks, consequently constraining the development of the field. In this work, we take the initiative to explore and propose the LLMBind, a unified framework for modality task integration, which binds Large Language Models and corresponding pre-trained task models with task-specific tokens. Consequently, LLMBind can interpret inputs and produce outputs in versatile combinations of image, text, video, and audio. Specifically, we introduce a Mixture-of-Experts technique to enable effective learning for different multimodal tasks through collaboration among diverse experts. Furthermore, we create a multi-task dataset comprising 400k instruction data, which unlocks the ability for interactive visual generation and editing tasks. Extensive experiments show the effectiveness of our fr
    
[^149]: Vygotsky Distance: 用于基准任务相似性的度量方法

    Vygotsky Distance: Measure for Benchmark Task Similarity

    [https://arxiv.org/abs/2402.14890](https://arxiv.org/abs/2402.14890)

    论文提出了一种基于相对性能而非任务属性的相似性度量方法，即“维果茨基距离”，可帮助减少评估任务数量并保持高验证质量。

    

    论文介绍了一种理论工具和实践算法来计算基准任务之间的相似性，称之为"维果茨基距离"。这种相似性度量的核心思想是基于“学生”在给定任务上的相对表现，而不是基于任务本身的属性。如果两个任务在维果茨基距离上彼此接近，模型在这些任务上 tend to have similar relative performance。因此，通过了解任务之间的维果茨基距离，可以显著减少评估任务数量，同时保持高验证质量。

    arXiv:2402.14890v1 Announce Type: cross  Abstract: Evaluation plays a significant role in modern natural language processing. Most modern NLP benchmarks consist of arbitrary sets of tasks that neither guarantee any generalization potential for the model once applied outside the test set nor try to minimize the resource consumption needed for model evaluation. This paper presents a theoretical instrument and a practical algorithm to calculate similarity between benchmark tasks, we call this similarity measure "Vygotsky distance". The core idea of this similarity measure is that it is based on relative performance of the "students" on a given task, rather that on the properties of the task itself. If two tasks are close to each other in terms of Vygotsky distance the models tend to have similar relative performance on them. Thus knowing Vygotsky distance between tasks one can significantly reduce the number of evaluation tasks while maintaining a high validation quality. Experiments on v
    
[^150]: Checkfor.ai AI生成文本分类器技术报告

    Technical Report on the Checkfor.ai AI-Generated Text Classifier

    [https://arxiv.org/abs/2402.14873](https://arxiv.org/abs/2402.14873)

    Checkfor.ai AI生成文本分类器在区分大型语言模型生成文本和人类编写文本方面表现优异，提出了硬负挖掘与合成镜像训练算法，具有高准确性和泛化能力。

    

    我们提出了Checkfor.ai文本分类器，这是一个基于Transformer的神经网络，经过训练可以区分由大型语言模型编写的文本和由人类编写的文本。Checkfor.ai在由十种文本领域（学生写作、创意写作、科学写作、书籍、百科全书、新闻、电子邮件、科学论文、简答问答）和8个开源闭源大型语言模型组成的综合基准测试中，表现优于零冲击方法如DetectGPT以及主流商业AI检测工具，误差率降低了9倍以上。我们提出了一种训练算法，即硬负挖掘与合成镜像，使我们的分类器能够在评论等高数据领域实现几个数量级的更低误报率。最后，我们展示了Checkfor.ai不对非母语英语人士产生偏见，并推广到训练过程中未见的领域和模型。

    arXiv:2402.14873v1 Announce Type: cross  Abstract: We present the Checkfor.ai text classifier, a transformer-based neural network trained to distinguish text written by large language models from text written by humans. Checkfor.ai outperforms zero-shot methods such as DetectGPT as well as leading commercial AI detection tools with over 9 times lower error rates on a comprehensive benchmark comprised of ten text domains (student writing, creative writing, scientific writing, books, encyclopedias, news, email, scientific papers, short-form Q\&A) and 8 open- and closed-source large language models. We propose a training algorithm, hard negative mining with synthetic mirrors, that enables our classifier to achieve orders of magnitude lower false positive rates on high-data domains such as reviews. Finally, we show that Checkfor.ai is not biased against nonnative English speakers and generalizes to domains and models unseen during training.
    
[^151]: 用于公共卫生中动态不安静多臂老虎机任务的决策语言模型（DLM）

    A Decision-Language Model (DLM) for Dynamic Restless Multi-Armed Bandit Tasks in Public Health

    [https://arxiv.org/abs/2402.14807](https://arxiv.org/abs/2402.14807)

    提出了一种决策语言模型DLM，旨在通过使用LLMs作为自动规划器，动态微调RMAB策略，以应对公共卫生中具有挑战性的情境。

    

    旨在降低孕产妇死亡率的努力在很大程度上依赖于预防保健计划，向高风险人群传播重要的健康信息。本文提出了DLM：一种用于RMAB的决策语言模型，旨在通过使用LLMs作为自动规划器，动态微调RMAB策略，以应对公共卫生中具有挑战性的情境。

    arXiv:2402.14807v1 Announce Type: cross  Abstract: Efforts to reduce maternal mortality rate, a key UN Sustainable Development target (SDG Target 3.1), rely largely on preventative care programs to spread critical health information to high-risk populations. These programs face two important challenges: efficiently allocating limited health resources to large beneficiary populations, and adapting to evolving policy priorities. While prior works in restless multi-armed bandit (RMAB) demonstrated success in public health allocation tasks, they lack flexibility to adapt to evolving policy priorities. Concurrently, Large Language Models (LLMs) have emerged as adept, automated planners in various domains, including robotic control and navigation. In this paper, we propose DLM: a Decision Language Model for RMABs. To enable dynamic fine-tuning of RMAB policies for challenging public health settings using human-language commands, we propose using LLMs as automated planners to (1) interpret hu
    
[^152]: 联邦式复杂查询答案方法研究

    Federated Complex Qeury Answering

    [https://arxiv.org/abs/2402.14609](https://arxiv.org/abs/2402.14609)

    研究了在多源知识图谱上回答复杂查询的联邦式方法，解决了知识图谱中的隐私保护和答案检索的挑战

    

    知识图谱中的复杂逻辑查询答案是一个具有挑战性的任务，已经得到广泛研究。执行复杂逻辑推理的能力是必不可少的，并支持各种基于图推理的下游任务，比如搜索引擎。最近提出了一些方法，将知识图谱实体和逻辑查询表示为嵌入向量，并从知识图谱中找到逻辑查询的答案。然而，现有的方法主要集中在查询单个知识图谱上，并不能应用于多个图形。此外，直接共享带有敏感信息的知识图谱可能会带来隐私风险，使得共享和构建一个聚合知识图谱用于推理以检索查询答案是不切实际的。因此，目前仍然不清楚如何在多源知识图谱上回答查询。一个实体可能涉及到多个知识图谱，对多个知识图谱进行推理，并在多源知识图谱上回答复杂查询对于发现知识是重要的。

    arXiv:2402.14609v1 Announce Type: cross  Abstract: Complex logical query answering is a challenging task in knowledge graphs (KGs) that has been widely studied. The ability to perform complex logical reasoning is essential and supports various graph reasoning-based downstream tasks, such as search engines. Recent approaches are proposed to represent KG entities and logical queries into embedding vectors and find answers to logical queries from the KGs. However, existing proposed methods mainly focus on querying a single KG and cannot be applied to multiple graphs. In addition, directly sharing KGs with sensitive information may incur privacy risks, making it impractical to share and construct an aggregated KG for reasoning to retrieve query answers. Thus, it remains unknown how to answer queries on multi-source KGs. An entity can be involved in various knowledge graphs and reasoning on multiple KGs and answering complex queries on multi-source KGs is important in discovering knowledge 
    
[^153]: 视觉语言模型的不确定性感知评估

    Uncertainty-Aware Evaluation for Vision-Language Models

    [https://arxiv.org/abs/2402.14418](https://arxiv.org/abs/2402.14418)

    提出了一个新的基准来评估视觉语言模型，该基准将不确定性量化融入评估过程中，揭示了准确性最高的模型可能也具有最高不确定性的重要性。

    

    最近，像GPT-4、LLaVA和CogVLM这样的视觉语言模型因在几种视觉-语言任务中表现出色而变得越来越受欢迎。然而，当前的评估方法忽视了一个关键组成部分：不确定性，这对于全面评估VLMs非常重要。为了解决这一疏忽，我们提出了一个基准，将不确定性量化融入到评估VLMs中。我们的分析涵盖了20多个VLMs，重点关注多项选择视觉问答（VQA）任务。我们在评估各种视觉-语言能力的5个数据集上检验了模型。通过使用符合预测作为不确定性估计方法，我们证明了模型的不确定性与其准确性不一致。具体而言，我们表明准确性最高的模型可能也具有最高的不确定性，这证实了为VLMs测量其重要性。我们的实证发现还揭示了一种相关性，其

    arXiv:2402.14418v1 Announce Type: cross  Abstract: Vision-Language Models like GPT-4, LLaVA, and CogVLM have surged in popularity recently due to their impressive performance in several vision-language tasks. Current evaluation methods, however, overlook an essential component: uncertainty, which is crucial for a comprehensive assessment of VLMs. Addressing this oversight, we present a benchmark incorporating uncertainty quantification into evaluating VLMs.   Our analysis spans 20+ VLMs, focusing on the multiple-choice Visual Question Answering (VQA) task. We examine models on 5 datasets that evaluate various vision-language capabilities.   Using conformal prediction as an uncertainty estimation approach, we demonstrate that the models' uncertainty is not aligned with their accuracy. Specifically, we show that models with the highest accuracy may also have the highest uncertainty, which confirms the importance of measuring it for VLMs. Our empirical findings also reveal a correlation b
    
[^154]: 在巨大语言模型中分析概念表达：借助反向词典探查

    On the Tip of the Tongue: Analyzing Conceptual Representation in Large Language Models with Reverse-Dictionary Probe

    [https://arxiv.org/abs/2402.14404](https://arxiv.org/abs/2402.14404)

    该论文通过重新利用反向词典任务的案例研究，探查了大型语言模型对概念推理的能力，发现模型在该任务中表现出高准确性，并且表示空间编码了有关对象类别和细粒度特征的信息，同时还发现该任务探查的概念推理能力能够预测模型在多个基准测试中的一般推理表现。

    

    探查和增强大型语言模型的推理能力仍然是一个关键的未解问题。在这里，我们重新利用反向词典任务作为一个案例研究，来探查LLMs对概念推理的能力。我们使用上下文学习来引导模型生成一个语言描述中暗示的对象概念的术语。模型在这个任务中稳健地实现了高准确性，并且它们的表示空间编码了关于对象类别和细粒度特征的信息。进一步的实验表明，通过反向词典任务探查的概念推理能力能够预测模型在多个基准测试中的一般推理表现，尽管模型在句法泛化行为上表现相似。探索性分析表明，通过提示LLMs使用描述$\Rightarrow$单词示例可能会诱导出超越任务构型表面差异的泛化，并促进模型对更广泛的共同性的研究

    arXiv:2402.14404v1 Announce Type: cross  Abstract: Probing and enhancing large language models' reasoning capacity remains a crucial open question. Here we re-purpose the reverse dictionary task as a case study to probe LLMs' capacity for conceptual inference. We use in-context learning to guide the models to generate the term for an object concept implied in a linguistic description. Models robustly achieve high accuracy in this task, and their representation space encodes information about object categories and fine-grained features. Further experiments suggest that the conceptual inference ability as probed by the reverse-dictionary task predicts model's general reasoning performance across multiple benchmarks, despite similar syntactic generalization behaviors across models. Explorative analyses suggest that prompting LLMs with description$\Rightarrow$word examples may induce generalization beyond surface-level differences in task construals and facilitate models on broader commons
    
[^155]: 在动态游戏中融合数据驱动的先验知识

    Blending Data-Driven Priors in Dynamic Games

    [https://arxiv.org/abs/2402.14174](https://arxiv.org/abs/2402.14174)

    探索一种在动态游戏中将数据驱动参考政策与基于优化博弈政策相融合的方法，提出了一种非合作动态博弈KLGame，其中包含了针对每个决策者的可调参数。

    

    随着智能机器人如自动驾驶车辆在人群中的部署越来越多，这些系统应该在安全的、与人互动意识相关的运动规划中利用基于模型的博弈论规划器与数据驱动政策的程度仍然是一个悬而未决的问题。本文探讨了一种融合数据驱动参考政策和基于优化的博弈论政策的原则性方法。我们制定了KLGame，这是一种带有Kullback-Leibler（KL）正则化的非合作动态博弈，针对一个一般的、随机的，可能是多模式的参考政策。

    arXiv:2402.14174v1 Announce Type: cross  Abstract: As intelligent robots like autonomous vehicles become increasingly deployed in the presence of people, the extent to which these systems should leverage model-based game-theoretic planners versus data-driven policies for safe, interaction-aware motion planning remains an open question. Existing dynamic game formulations assume all agents are task-driven and behave optimally. However, in reality, humans tend to deviate from the decisions prescribed by these models, and their behavior is better approximated under a noisy-rational paradigm. In this work, we investigate a principled methodology to blend a data-driven reference policy with an optimization-based game-theoretic policy. We formulate KLGame, a type of non-cooperative dynamic game with Kullback-Leibler (KL) regularization with respect to a general, stochastic, and possibly multi-modal reference policy. Our method incorporates, for each decision maker, a tunable parameter that pe
    
[^156]: SDXL-Lightning: 渐进式对抗性扩散蒸馏

    SDXL-Lightning: Progressive Adversarial Diffusion Distillation

    [https://arxiv.org/abs/2402.13929](https://arxiv.org/abs/2402.13929)

    提出了一种结合渐进和对抗性蒸馏的扩散蒸馏方法，在文本到图像生成任务中取得了新的最先进结果，并开源了相应模型。

    

    我们提出了一种扩散蒸馏方法，在基于SDXL的一步/几步1024像素文本到图像生成任务中实现了全新的最先进水平。我们的方法结合了渐进和对抗性蒸馏，实现了质量和模式覆盖之间的平衡。本文讨论了理论分析、判别器设计、模型公式和训练技巧。我们以LoRA和完整UNet权重的形式开源了我们的蒸馏SDXL-Lightning模型。

    arXiv:2402.13929v1 Announce Type: cross  Abstract: We propose a diffusion distillation method that achieves new state-of-the-art in one-step/few-step 1024px text-to-image generation based on SDXL. Our method combines progressive and adversarial distillation to achieve a balance between quality and mode coverage. In this paper, we discuss the theoretical analysis, discriminator design, model formulation, and training techniques. We open-source our distilled SDXL-Lightning models both as LoRA and full UNet weights.
    
[^157]: Kuaiji：第一个中国会计大型语言模型

    Kuaiji: the First Chinese Accounting Large Language Model

    [https://arxiv.org/abs/2402.13866](https://arxiv.org/abs/2402.13866)

    Kuaiji是第一个中国会计大型语言模型，通过Baichuan框架精心调整，支持的CAtAcctQA数据集，展现出卓越的准确性和响应速度，具有开创性地创建了中国会计数据集，并证实了在真实会计场景中的高效性。

    

    大语言模型（LLMs）如ChatGPT和GPT-4已经展示出在理解和生成自然语言方面的出色能力。然而，当面临任务要求适应会计等专业领域时，它们会遇到困难。为了解决这一挑战，我们引入了Kuaiji，一个专门定制的会计大型语言模型。Kuaiji经过精心调整，使用包含连续预训练和监督微调过程的Baichuan框架。在CAtAcctQA的支持下，这是一个包含大量真实会计师与客户对话的数据集，Kuaiji表现出卓越的准确性和响应速度。我们的贡献包括创建了第一个中国会计数据集，将Kuaiji建立为一种领先的开源中国会计LLM，并通过真实会计场景对其有效性进行了验证。

    arXiv:2402.13866v1 Announce Type: cross  Abstract: Large Language Models (LLMs) like ChatGPT and GPT-4 have demonstrated impressive proficiency in comprehending and generating natural language. However, they encounter difficulties when tasked with adapting to specialized domains such as accounting. To address this challenge, we introduce Kuaiji, a tailored Accounting Large Language Model. Kuaiji is meticulously fine-tuned using the Baichuan framework, which encompasses continuous pre-training and supervised fine-tuning processes. Supported by CAtAcctQA, a dataset containing large genuine accountant-client dialogues, Kuaiji exhibits exceptional accuracy and response speed. Our contributions encompass the creation of the first Chinese accounting dataset, the establishment of Kuaiji as a leading open-source Chinese accounting LLM, and the validation of its efficacy through real-world accounting scenarios.
    
[^158]: 离线策略学习的深度生成模型：教程、调查和未来方向展望

    Deep Generative Models for Offline Policy Learning: Tutorial, Survey, and Perspectives on Future Directions

    [https://arxiv.org/abs/2402.13777](https://arxiv.org/abs/2402.13777)

    深度生成模型在离线策略学习中展现了巨大潜力，本文提供了首个系统性综述，涵盖了五种主流深度生成模型及其应用。

    

    深度生成模型(DGMs)在各个领域展示了巨大成功，特别是在使用从离线数据训练的模型生成文本、图像和视频方面。类似地，基于数据驱动的决策和机器人控制也需要从离线数据中学习一个生成函数作为策略或政策。在这种情况下，将深度生成模型应用于离线策略学习展现出巨大潜力，许多研究在这个方向上进行了探索。然而，这一领域仍然缺乏全面的评估，因此不同分支的发展相对独立。因此，我们提供了深度生成模型在离线策略学习应用方面的第一次系统性综述。具体而言，我们涵盖了五种主流深度生成模型，包括变分自动编码器、生成对抗网络、归一化流、变压器和扩散模型，以及它们的应用。

    arXiv:2402.13777v1 Announce Type: cross  Abstract: Deep generative models (DGMs) have demonstrated great success across various domains, particularly in generating texts, images, and videos using models trained from offline data. Similarly, data-driven decision-making and robotic control also necessitate learning a generator function from the offline data to serve as the strategy or policy. In this case, applying deep generative models in offline policy learning exhibits great potential, and numerous studies have explored in this direction. However, this field still lacks a comprehensive review and so developments of different branches are relatively independent. Thus, we provide the first systematic review on the applications of deep generative models for offline policy learning. In particular, we cover five mainstream deep generative models, including Variational Auto-Encoders, Generative Adversarial Networks, Normalizing Flows, Transformers, and Diffusion Models, and their applicati
    
[^159]: 从云端到边缘：重新思考低资源设计挑战的生成人工智能

    From Cloud to Edge: Rethinking Generative AI for Low-Resource Design Challenges

    [https://arxiv.org/abs/2402.12702](https://arxiv.org/abs/2402.12702)

    论文探讨了将生成人工智能调整以适应边缘资源受限环境的潜力、挑战和创新方法，以在低资源环境中高效创建设计解决方案。

    

    生成人工智能（AI）在技术的各个方面展现出巨大的潜力，包括设计。然而，由于对资源的沉重需求，它通常在大型计算基础架构上进行训练，并经常作为基于云端的服务提供。在这篇立场论文中，我们考虑了在边缘进行设计的生成AI的潜力、挑战和有希望的方法，即在资源受限的环境中，其中的内存、计算、能耗（电池）和网络连接可能有限。调整生成AI以适应这样的设置涉及克服重大障碍，主要是如何简化复杂模型以在低资源环境中有效运行。这需要在模型压缩、高效算法设计以及可能甚至利用边缘计算方面提出创新性方法。目标是利用生成AI的力量为设计问题创造量身定制的解决方案。

    arXiv:2402.12702v1 Announce Type: new  Abstract: Generative Artificial Intelligence (AI) has shown tremendous prospects in all aspects of technology, including design. However, due to its heavy demand on resources, it is usually trained on large computing infrastructure and often made available as a cloud-based service. In this position paper, we consider the potential, challenges, and promising approaches for generative AI for design on the edge, i.e., in resource-constrained settings where memory, compute, energy (battery) and network connectivity may be limited. Adapting generative AI for such settings involves overcoming significant hurdles, primarily in how to streamline complex models to function efficiently in low-resource environments. This necessitates innovative approaches in model compression, efficient algorithmic design, and perhaps even leveraging edge computing. The objective is to harness the power of generative AI in creating bespoke solutions for design problems, such
    
[^160]: HyperMoE: 通过专家之间的知识传递实现更好的专家混合

    HyperMoE: Towards Better Mixture of Experts via Transferring Among Experts

    [https://arxiv.org/abs/2402.12656](https://arxiv.org/abs/2402.12656)

    HyperMoE通过Hypernetworks框架整合知识传递的概念，解决了在专家选择过程中专家知识稀疏性和可用性之间的矛盾。

    

    混合专家(MoE)在语言模型中被证明有效地增强了模型的能力，通过动态地将每个输入标记路由到特定的专家子集进行处理。尽管取得了成功，但大多数现有方法在专家知识的稀疏性和可用性之间面临挑战：通过增加对专家知识的使用来增强性能，往往会导致在专家选择过程中稀疏度减少。为了缓解这一矛盾，我们提出了HyperMoE，这是一个建立在Hypernetworks之上的新颖MoE框架。该框架将MoE的计算过程与多任务学习中的知识传递概念进行了集成。基于未选择专家信息生成的特定模块作为补充信息，允许未被选中的专家的知识在保持选择稀疏性的同时被使用。

    arXiv:2402.12656v1 Announce Type: cross  Abstract: The Mixture of Experts (MoE) for language models has been proven effective in augmenting the capacity of models by dynamically routing each input token to a specific subset of experts for processing. Despite the success, most existing methods face a challenge for balance between sparsity and the availability of expert knowledge: enhancing performance through increased use of expert knowledge often results in diminishing sparsity during expert selection. To mitigate this contradiction, we propose HyperMoE, a novel MoE framework built upon Hypernetworks. This framework integrates the computational processes of MoE with the concept of knowledge transferring in multi-task learning. Specific modules generated based on the information of unselected experts serve as supplementary information, which allows the knowledge of experts not selected to be used while maintaining selection sparsity. Our comprehensive empirical evaluations across multi
    
[^161]: AnyGPT：统一的多模式离散序列建模语言模型

    AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling

    [https://arxiv.org/abs/2402.12226](https://arxiv.org/abs/2402.12226)

    AnyGPT是一个统一的多模态语言模型，通过离散表示实现各种模态的统一处理，能够在不改变大型语言模型架构或训练方式的情况下稳定训练，为新模态的无缝整合提供了可能。

    

    我们介绍了 AnyGPT，这是一个任意多模式语言模型，利用离散表示统一处理各种模态，包括语音、文本、图像和音乐。AnyGPT 可以稳定训练，无需对当前大型语言模型（LLM）架构或训练范式进行任何改动。相反，它仅依赖于数据级预处理，促进了新模态的无缝集成到LLM中，类似于新语言的整合。我们构建了一个多模式文本中心的数据集，用于多模式对齐预训练。利用生成模型，我们合成了第一个大规模任意多模式指令数据集。它包括108k个多轮对话示例，精细地交织各种模态，从而使模型能够处理多模态输入和输出的任意组合。实验结果表明，AnyGPT能够促进...

    arXiv:2402.12226v1 Announce Type: cross  Abstract: We introduce AnyGPT, an any-to-any multimodal language model that utilizes discrete representations for the unified processing of various modalities, including speech, text, images, and music. AnyGPT can be trained stably without any alterations to the current large language model (LLM) architecture or training paradigms. Instead, it relies exclusively on data-level preprocessing, facilitating the seamless integration of new modalities into LLMs, akin to the incorporation of new languages. We build a multimodal text-centric dataset for multimodal alignment pre-training. Utilizing generative models, we synthesize the first large-scale any-to-any multimodal instruction dataset. It consists of 108k samples of multi-turn conversations that intricately interweave various modalities, thus equipping the model to handle arbitrary combinations of multimodal inputs and outputs. Experimental results demonstrate that AnyGPT is capable of facilitat
    
[^162]: Mafin: 用模型增强微调来增强黑盒嵌入

    Mafin: Enhancing Black-Box Embeddings with Model Augmented Fine-tuning

    [https://arxiv.org/abs/2402.12177](https://arxiv.org/abs/2402.12177)

    Mafin通过引入模型增强微调的方法，能够在只有黑盒嵌入可用的情况下显著提高性能。

    

    检索增强生成（RAG）已经成为缓解大型语言模型（LLMs）中幻觉的有效解决方案。RAG中的检索阶段通常涉及预训练的嵌入模型，将查询和段落转换为向量以捕获它们的语义。然而，当应用于特定领域知识时，标准的预训练嵌入模型可能表现出次优性能，需要进行微调。本文解决了仅能从黑盒模型获取嵌入的情况。我们引入了模型增强微调（Mafin）--一种通过用可训练的嵌入模型增强黑盒嵌入模型来进行微调的新方法。我们的结果表明，Mafin仅需要训练一个小的增强模型就可以显著提高黑盒嵌入的性能。我们验证了我们的方法在有标签和无标签数据集上的有效性。

    arXiv:2402.12177v1 Announce Type: cross  Abstract: Retrieval Augmented Generation (RAG) has emerged as an effective solution for mitigating hallucinations in Large Language Models (LLMs). The retrieval stage in RAG typically involves a pre-trained embedding model, which converts queries and passages into vectors to capture their semantics. However, a standard pre-trained embedding model may exhibit sub-optimal performance when applied to specific domain knowledge, necessitating fine-tuning. This paper addresses scenarios where the embeddings are only available from a black-box model. We introduce Model augmented fine-tuning (Mafin) -- a novel approach for fine-tuning a black-box embedding model by augmenting it with a trainable embedding model. Our results demonstrate that Mafin significantly enhances the performance of the black-box embeddings by only requiring the training of a small augmented model. We validate the effectiveness of our method on both labeled and unlabeled datasets, 
    
[^163]: 针对参数高效微调的权重投毒后门攻击的防御

    Defending Against Weight-Poisoning Backdoor Attacks for Parameter-Efficient Fine-Tuning

    [https://arxiv.org/abs/2402.12168](https://arxiv.org/abs/2402.12168)

    PEFT相对于全参数微调更容易受到权重投毒后门攻击的影响，提出了一个通过置信度识别受污染样本的毒化样本识别模块（PSIM），为权重投毒后门攻击提供稳健防御

    

    最近，针对语言模型应用提出并成功实施了各种参数高效微调（PEFT）策略。然而，这引发了一个问题，即当面对权重投毒后门攻击时，仅更新有限模型参数的PEFT是否构成安全漏洞。我们展示了PEFT相对于全参数微调方法更容易受到权重投毒后门攻击的影响，预定义的触发器仍然易受利用，预定义的目标在微调后依然保持高置信度。受到这一见解的启发，我们开发了一个利用PEFT的毒化样本识别模块（PSIM），通过置信度识别受污染样本，提供针对权重投毒后门攻击的稳健防御。具体而言，我们利用PEFT训练PSIM，带有随机重置样本标签。在推断过程中，

    arXiv:2402.12168v1 Announce Type: cross  Abstract: Recently, various parameter-efficient fine-tuning (PEFT) strategies for application to language models have been proposed and successfully implemented. However, this raises the question of whether PEFT, which only updates a limited set of model parameters, constitutes security vulnerabilities when confronted with weight-poisoning backdoor attacks. In this study, we show that PEFT is more susceptible to weight-poisoning backdoor attacks compared to the full-parameter fine-tuning method, with pre-defined triggers remaining exploitable and pre-defined targets maintaining high confidence, even after fine-tuning. Motivated by this insight, we developed a Poisoned Sample Identification Module (PSIM) leveraging PEFT, which identifies poisoned samples through confidence, providing robust defense against weight-poisoning backdoor attacks. Specifically, we leverage PEFT to train the PSIM with randomly reset sample labels. During the inference pr
    
[^164]: 从实际到逻辑再到实际：为规划从原始数据中发明符号词汇、动作和模型

    From Reals to Logic and Back: Inventing Symbolic Vocabularies, Actions and Models for Planning from Raw Data

    [https://arxiv.org/abs/2402.11871](https://arxiv.org/abs/2402.11871)

    本文提出了一种从未标记高维实值机器人轨迹开始自主学习通用的逻辑相关表示，这些表示构成了自动发明的PDDL-like域模型。

    

    手工制作的基于逻辑的状态和动作表示已被广泛用于克服长期人工智能机器人规划问题的计算复杂性，包括任务和动作规划问题。但是，创建这样的表示需要具有强烈直觉和详细知识的专家，他们了解机器人和在特定环境中可能需要完成的任务。消除对人类直觉的依赖是一个极为活跃的研究领域。 本文提出了一种自主学习通用逻辑相关表示的方法，该表示从未标记的高维实值机器人轨迹开始。所学表示构成了自动发明的类PDDL域模型。确定性设置下的实证结果表明，仅从少数机器人轨迹中可以学到强大的抽象表示；所学关系

    arXiv:2402.11871v1 Announce Type: cross  Abstract: Hand-crafted, logic-based state and action representations have been widely used to overcome the intractable computational complexity of long-horizon robot planning problems, including task and motion planning problems. However, creating such representations requires experts with strong intuitions and detailed knowledge about the robot and the tasks it may need to accomplish in a given setting. Removing this dependency on human intuition is a highly active research area.   This paper presents the first approach for autonomously learning generalizable, logic-based relational representations for abstract states and actions starting from unannotated high-dimensional, real-valued robot trajectories. The learned representations constitute auto-invented PDDL-like domain models. Empirical results in deterministic settings show that powerful abstract representations can be learned from just a handful of robot trajectories; the learned relation
    
[^165]: 生成万花筒网络

    Generative Kaleidoscopic Networks

    [https://arxiv.org/abs/2402.11793](https://arxiv.org/abs/2402.11793)

    发现深层ReLU网络表现出过度泛化现象，利用这一特性设计了“生成万花筒网络”，通过递归映射随机输入噪声生成样本。

    

    发现深层ReLU网络（或多层感知器架构）表现出“过度泛化”现象。也就是说，那些在训练过程中没有看到的输入的输出值被映射到了在学习过程中观察到的输出范围附近。换句话说，多层感知器学习了一对多的映射，这种效应在增加层数或多层感知器的深度时更为明显。我们利用了深层ReLU网络的这一特性来设计一个数据集万花筒，称为“生成万花筒网络”。简而言之，如果我们学习一个多层感知器将输入 $x\in\mathbb{R}^D$ 映射到自身 $f_\mathcal{N}(x)\rightarrow x$，那么“万花筒采样”过程将从随机输入噪声 $z\in\mathbb{R}^D$ 开始，并递归地应用 $f_\mathcal{N}(\cdots f_\mathcal{N}(z)\cdots )$。经过燃烧期后，我们开始观察来自输入分布的样本，我们发现更深的

    arXiv:2402.11793v1 Announce Type: cross  Abstract: We discovered that the Deep ReLU networks (or Multilayer Perceptron architecture) demonstrate an 'over-generalization' phenomenon. That is, the output values for the inputs that were not seen during training are mapped close to the output range that were observed during the learning process. In other words, the MLP learns a many-to-one mapping and this effect is more prominent as we increase the number of layers or depth of the MLP. We utilize this property of Deep ReLU networks to design a dataset kaleidoscope, termed as 'Generative Kaleidoscopic Networks'. Briefly, if we learn a MLP to map from input $x\in\mathbb{R}^D$ to itself $f_\mathcal{N}(x)\rightarrow x$, the 'Kaleidoscopic sampling' procedure starts with a random input noise $z\in\mathbb{R}^D$ and recursively applies $f_\mathcal{N}(\cdots f_\mathcal{N}(z)\cdots )$. After a burn-in period duration, we start observing samples from the input distribution and we found that deeper 
    
[^166]: 带Transformer的脉冲扩散模型

    SDiT: Spiking Diffusion Model with Transformer

    [https://arxiv.org/abs/2402.11588](https://arxiv.org/abs/2402.11588)

    本文提出了一种新颖的脉冲扩散模型架构，通过在脉冲神经网络中利用Transformer取代U-net结构，在图像生成任务中取得了较高质量的图像，并提供了基于SNN的生成模型研究的实证基准。

    

    脉冲神经网络（SNNs）具有低功耗和生物解释特性，被认为在节能计算方面有巨大潜力。然而，在图像生成任务中探索SNNs的工作仍然非常有限，尚未提出基于SNN的生成模型的统一且有效的结构。本文探讨了脉冲神经网络中的一种新型扩散模型架构。我们利用Transformer来取代主流扩散模型中常用的U-net结构。它能够以相对较低的计算成本和较短的采样时间生成质量更高的图像。它旨在为基于SNN的生成模型研究提供实证基准。在MNIST、Fashion-MNIST和CIFAR-10数据集上的实验证明，我们的工作与现有的SNN生成模型相比具有很高的竞争力。

    arXiv:2402.11588v1 Announce Type: cross  Abstract: Spiking neural networks (SNNs) have low power consumption and bio-interpretable characteristics, and are considered to have tremendous potential for energy-efficient computing. However, the exploration of SNNs on image generation tasks remains very limited, and a unified and effective structure for SNN-based generative models has yet to be proposed. In this paper, we explore a novel diffusion model architecture within spiking neural networks. We utilize transformer to replace the commonly used U-net structure in mainstream diffusion models. It can generate higher quality images with relatively lower computational cost and shorter sampling time. It aims to provide an empirical baseline for research of generative models based on SNNs. Experiments on MNIST, Fashion-MNIST, and CIFAR-10 datasets demonstrate that our work is highly competitive compared to existing SNN generative models.
    
[^167]: 强健的智能体学习因果世界模型

    Robust agents learn causal world models

    [https://arxiv.org/abs/2402.10877](https://arxiv.org/abs/2402.10877)

    智能体必须学习因果模型才能在广泛的分布转变下达到后悔界限，这对迁移学习和因果推断等研究领域有重要影响。

    

    一直有人假设因果推理在强健且具有通用智能中起着基础作用，然而不清楚智能体是否必须学习因果模型才能推广到新的领域，或者其他归纳偏差是否足够。我们回答了这个问题，表明任何能够在大量分布转变下满足后悔界限的智能体必须学习数据生成过程的近似因果模型，对于优化智能体来说，该近似模型会收敛到真实的因果模型。我们讨论了这一结果对于多个研究领域，包括迁移学习和因果推断的影响。

    arXiv:2402.10877v1 Announce Type: new  Abstract: It has long been hypothesised that causal reasoning plays a fundamental role in robust and general intelligence. However, it is not known if agents must learn causal models in order to generalise to new domains, or if other inductive biases are sufficient. We answer this question, showing that any agent capable of satisfying a regret bound under a large set of distributional shifts must have learned an approximate causal model of the data generating process, which converges to the true causal model for optimal agents. We discuss the implications of this result for several research areas including transfer learning and causal inference.
    
[^168]: 论部署LLMs/VLMs在机器人领域存在的安全问题：突显风险和漏洞

    On the Safety Concerns of Deploying LLMs/VLMs in Robotics: Highlighting the Risks and Vulnerabilities

    [https://arxiv.org/abs/2402.10340](https://arxiv.org/abs/2402.10340)

    论文突出探讨了在机器人应用中整合大型语言模型和视觉语言模型所带来的安全性和健壮性关键问题，指出这种整合可能容易受到恶意攻击并导致严重后果。

    

    在这篇论文中，我们着重讨论了将大型语言模型（LLMs）和视觉语言模型（VLMs）整合到机器人应用中所涉及的健壮性和安全性关键问题。最近的研究着重于利用LLMs和VLMs来提高机器人任务（如操作，导航等）的性能。然而，这种整合可能会引入显着的漏洞，即由于语言模型对恶意攻击的敏感性，可能导致灾难性后果。通过研究LLMs/VLMs与机器人界面的最新进展，我们展示了如何轻松操纵或误导机器人的行为，导致安全隐患。我们定义并提供了几种可能的恶意攻击示例，并对集成了语言模型的三个知名机器人框架（包括KnowNo VIMA和Instruct2Act）进行实验，以评估它们对这些攻击的敏感度。

    arXiv:2402.10340v1 Announce Type: cross  Abstract: In this paper, we highlight the critical issues of robustness and safety associated with integrating large language models (LLMs) and vision-language models (VLMs) into robotics applications. Recent works have focused on using LLMs and VLMs to improve the performance of robotics tasks, such as manipulation, navigation, etc. However, such integration can introduce significant vulnerabilities, in terms of their susceptibility to adversarial attacks due to the language models, potentially leading to catastrophic consequences. By examining recent works at the interface of LLMs/VLMs and robotics, we show that it is easy to manipulate or misguide the robot's actions, leading to safety hazards. We define and provide examples of several plausible adversarial attacks, and conduct experiments on three prominent robot frameworks integrated with a language model, including KnowNo VIMA, and Instruct2Act, to assess their susceptibility to these atta
    
[^169]: 基于上下文的奖励：基于动态偏好调整的多目标基础模型对齐

    Rewards-in-Context: Multi-objective Alignment of Foundation Models with Dynamic Preference Adjustment

    [https://arxiv.org/abs/2402.10207](https://arxiv.org/abs/2402.10207)

    本文介绍了Rewards-in-Context（RiC）方法，该方法通过多个奖励条件控制基础模型的响应，并应用有监督的微调进行对齐。它具有简单性和适应性，并支持在推理时动态调整用户偏好。

    

    我们考虑了基于人类偏好的基础模型多目标对齐问题，这是实现有益和无害的人工智能系统的关键步骤。然而，使用强化学习（RL）对大型基础模型进行微调通常是昂贵且不稳定的，并且人类偏好的多维度、异质性和冲突性进一步复杂化了对齐过程。在本文中，我们引入了Rewards-in-Context（RiC）方法，它使得基础模型的响应取决于其提示上下文中的多个奖励，并应用有监督的微调来进行对齐。RiC的显著特点是简单性和适应性，因为它只需要对单个基础模型进行有监督的微调，并支持在推理时动态调整用户偏好。受到抽象的凸优化问题的解析解的启发，我们提出了一种动态推理时调整方法。

    arXiv:2402.10207v1 Announce Type: cross  Abstract: We consider the problem of multi-objective alignment of foundation models with human preferences, which is a critical step towards helpful and harmless AI systems. However, it is generally costly and unstable to fine-tune large foundation models using reinforcement learning (RL), and the multi-dimensionality, heterogeneity, and conflicting nature of human preferences further complicate the alignment process. In this paper, we introduce Rewards-in-Context (RiC), which conditions the response of a foundation model on multiple rewards in its prompt context and applies supervised fine-tuning for alignment. The salient features of RiC are simplicity and adaptivity, as it only requires supervised fine-tuning of a single foundation model and supports dynamic adjustment for user preferences during inference time. Inspired by the analytical solution of an abstracted convex optimization problem, our dynamic inference-time adjustment method appro
    
[^170]: MM-Point: 多视角信息增强的多模态自监督三维点云理解

    MM-Point: Multi-View Information-Enhanced Multi-Modal Self-Supervised 3D Point Cloud Understanding

    [https://arxiv.org/abs/2402.10002](https://arxiv.org/abs/2402.10002)

    本文提出了一种新颖的自监督点云表示学习方法MM-Point，通过多模态交互和传输实现了3D物体和多个2D视图之间的信息增强。通过精心设计的实验，证明了MM-Point的有效性和优越性。

    

    在感知领域中，将多种传感信息整合起来将2D视图上的视觉信息映射到3D物体上，这有助于在三维环境中进行理解。但是在从不同角度渲染的单个2D视图中，只能提供有限的部分信息。多视角2D信息的丰富性和价值可以为3D物体提供优秀的自监督信号。在本文中，我们提出了一种新颖的自监督点云表示学习方法MM-Point，它受到内模态和外模态相似度目标的驱动。MM-Point的核心在于3D物体和多个2D视图之间的多模态交互和传输。为了更有效地同时执行基于对比学习的2D多视图信息一致性交叉模态目标，我们进一步提出了多层感知机(Multi-MLP)和多层级增强策略。通过精心设计的实验，我们展示了MM-Point的有效性和优越性。

    arXiv:2402.10002v1 Announce Type: cross  Abstract: In perception, multiple sensory information is integrated to map visual information from 2D views onto 3D objects, which is beneficial for understanding in 3D environments. But in terms of a single 2D view rendered from different angles, only limited partial information can be provided.The richness and value of Multi-view 2D information can provide superior self-supervised signals for 3D objects. In this paper, we propose a novel self-supervised point cloud representation learning method, MM-Point, which is driven by intra-modal and inter-modal similarity objectives. The core of MM-Point lies in the Multi-modal interaction and transmission between 3D objects and multiple 2D views at the same time. In order to more effectively simultaneously perform the consistent cross-modal objective of 2D multi-view information based on contrastive learning, we further propose Multi-MLP and Multi-level Augmentation strategies. Through carefully desig
    
[^171]: 未知博弈中乐观的汤普森抽样方法用于无遗憾学习

    Optimistic Thompson Sampling for No-Regret Learning in Unknown Games

    [https://arxiv.org/abs/2402.09456](https://arxiv.org/abs/2402.09456)

    该论文提出了一种在未知博弈中进行无遗憾学习的乐观的汤普森抽样方法，通过利用对手的行动和奖励结构信息，显著减少了实验预算，成功地缓解了多机构问题。此外，研究还引入了乐观-无遗憾框架，将现有算法与提出的方法相结合。

    

    许多涉及多个决策者的真实世界问题可以建模为一个具有部分观测的未知博弈。为了解决部分信息和多机构的挑战，我们开发了汤普森抽样类型的算法，利用对手的行动和奖励结构的信息。我们的方法在实际应用中，如交通路由和雷达感知中，显著减少了实验预算，与基准算法相比，减少了十倍以上。我们证明，在对奖励结构有一定假设的情况下，遗憾界限仅对总行动空间大小呈对数依赖，有效缓解了多机构问题。此外，本研究引入了乐观-无遗憾框架，该框架将我们提出的方法和领域内现有的算法相结合，是一项新的贡献。

    arXiv:2402.09456v1 Announce Type: cross  Abstract: Many real-world problems involving multiple decision-makers can be modeled as an unknown game characterized by partial observations. Addressing the challenges posed by partial information and the curse of multi-agency, we developed Thompson sampling-type algorithms, leveraging information about opponent's action and reward structures. Our approach significantly reduces experimental budgets, achieving a more than tenfold reduction compared to baseline algorithms in practical applications like traffic routing and radar sensing. We demonstrate that, under certain assumptions about the reward structure, the regret bound exhibits merely a logarithmic dependence on the total action space size, effectively mitigating the curse of multi-agency. Additionally, this research introduces the Optimism-then-NoRegret framework, a novel contribution that integrates both our proposed methodologies and existing algorithms in the field.
    
[^172]: 攻击、防御和评估LLM对话安全性的调查

    Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey

    [https://arxiv.org/abs/2402.09283](https://arxiv.org/abs/2402.09283)

    这篇调查提供了LLM对话安全性的全面概述，涵盖了攻击、防御和评估三个关键方面，旨在提高对该主题的理解并促进进一步的研究。

    

    arXiv:2402.09283v1 公告类型: 新的摘要: 大型语言模型（LLMs）在对话应用中已经很常见。然而，它们可能被误用生成有害回复的风险引起了严重的社会关切，并激发了LLM对话安全性的最新研究。因此，在此调查中，我们提供了最近研究的全面概述，涵盖了LLM对话安全性的三个关键方面：攻击、防御和评估。我们的目标是提供一个结构化的摘要，增进对LLM对话安全性的理解，并鼓励进一步研究这一重要课题。为了方便参考，我们根据我们的分类法对所有在此调查中提到的研究进行了分类，可在以下网址找到：https://github.com/niconi19/LLM-conversation-safety。

    arXiv:2402.09283v1 Announce Type: new Abstract: Large Language Models (LLMs) are now commonplace in conversation applications. However, their risks of misuse for generating harmful responses have raised serious societal concerns and spurred recent research on LLM conversation safety. Therefore, in this survey, we provide a comprehensive overview of recent studies, covering three critical aspects of LLM conversation safety: attacks, defenses, and evaluations. Our goal is to provide a structured summary that enhances understanding of LLM conversation safety and encourages further investigation into this important subject. For easy reference, we have categorized all the studies mentioned in this survey according to our taxonomy, available at: https://github.com/niconi19/LLM-conversation-safety.
    
[^173]: SafeDecoding: 通过安全感知解码防御越狱攻击

    SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware Decoding

    [https://arxiv.org/abs/2402.08983](https://arxiv.org/abs/2402.08983)

    本文提出了一种名为SafeDecoding的解决方案，通过安全感知解码策略来防御大型语言模型（LLMs）的越狱攻击。该策略可以生成对用户查询有益且无害的响应，有效缓解了LLMs安全性威胁。

    

    随着大型语言模型（LLMs）越来越多地应用于代码生成和聊天机器人辅助等现实应用中，人们为了使LLM的行为与人类价值观保持一致，包括安全性在内做出了大量努力。越狱攻击旨在引发LLM的非预期和不安全行为，仍然是LLM安全性的重要威胁。本文旨在通过引入SafeDecoding来防御LLM的越狱攻击，这是一种安全感知的解码策略，用于生成对用户查询有益且无害的响应。我们在开发SafeDecoding时的洞察力基于观察到，即使代表有害内容的标记的概率超过代表无害响应的标记的概率，安全免责声明仍然出现在按概率降序排序的标记中的前几个。这使我们能够通过识别安全免责声明并增强其良性影响力来减轻越狱攻击。

    arXiv:2402.08983v1 Announce Type: cross Abstract: As large language models (LLMs) become increasingly integrated into real-world applications such as code generation and chatbot assistance, extensive efforts have been made to align LLM behavior with human values, including safety. Jailbreak attacks, aiming to provoke unintended and unsafe behaviors from LLMs, remain a significant/leading LLM safety threat. In this paper, we aim to defend LLMs against jailbreak attacks by introducing SafeDecoding, a safety-aware decoding strategy for LLMs to generate helpful and harmless responses to user queries. Our insight in developing SafeDecoding is based on the observation that, even though probabilities of tokens representing harmful contents outweigh those representing harmless responses, safety disclaimers still appear among the top tokens after sorting tokens by probability in descending order. This allows us to mitigate jailbreak attacks by identifying safety disclaimers and amplifying their
    
[^174]: FESS Loss：用于优化医学图像分析的增强特征空间分割损失

    FESS Loss: Feature-Enhanced Spatial Segmentation Loss for Optimizing Medical Image Analysis

    [https://arxiv.org/abs/2402.08582](https://arxiv.org/abs/2402.08582)

    本论文提出了一种名为FESS Loss的增强特征空间分割损失，将对比学习和Dice损失相结合，旨在在医学图像分割中提高空间精度和特征表示，从而实现更精确、更精细的分割过程。

    

    在医学成像领域，医学图像分割是一个关键的过程，对于诊断、治疗和研究起着重要作用。它涉及将图像划分为多个区域，代表不同的解剖结构或病理结构。传统方法往往面临空间精度和全面特征表示之间平衡的挑战，因为它们依赖于传统的损失函数。为了克服这一问题，我们提出了增强特征空间分割损失（FESS Loss），将对比学习的优势（在医学成像的微妙领域中提取复杂的特征）与Dice损失的空间准确性相结合。目标是在医学图像分割中增强空间精度和基于特征的表示。FESS Loss代表了一个显著的进展，提供了更精确、更精细的分割过程，最终提高了精度。

    Medical image segmentation is a critical process in the field of medical imaging, playing a pivotal role in diagnosis, treatment, and research. It involves partitioning of an image into multiple regions, representing distinct anatomical or pathological structures. Conventional methods often grapple with the challenge of balancing spatial precision and comprehensive feature representation due to their reliance on traditional loss functions. To overcome this, we propose Feature-Enhanced Spatial Segmentation Loss (FESS Loss), that integrates the benefits of contrastive learning (which extracts intricate features, particularly in the nuanced domain of medical imaging) with the spatial accuracy inherent in the Dice loss. The objective is to augment both spatial precision and feature-based representation in the segmentation of medical images. FESS Loss signifies a notable advancement, offering a more accurate and refined segmentation process, ultimately contributing to heightened precision i
    
[^175]: 使用语言反馈模型来改进政策

    Policy Improvement using Language Feedback Models

    [https://arxiv.org/abs/2402.07876](https://arxiv.org/abs/2402.07876)

    本文介绍了一种使用语言反馈模型（LFMs）改进政策的方法，通过识别期望的行为并进行模仿学习，我们在任务完成率、泛化性能和人类可解释性方面取得了显著改进。

    

    我们引入了语言反馈模型（LFMs），用于在指令遵循中识别期望的行为-有助于实现指令中指定任务的行动-以进行模仿学习。为了训练LFMs，我们从大型语言模型（LLMs）获取对视觉轨迹进行语言描述的反馈。首先，通过使用LFMs识别期望模仿的行为，我们在三种不同的语言基础环境（Touchdown，ScienceWorld和ALFWorld）上，在任务完成率上改善了强行为克隆的基线方法。其次，与LLMs直接预测行动相比，使用LFMs在LLM输出标记的数量相同的情况下表现更好。第三，LFMs适应未见环境，通过一轮适应使任务完成率提高了3.5-12.0％。最后，可以修改LFM以提供人类可解释的反馈，无需性能损失，从而允许人类验证模仿学习的期望行为。

    We introduce Language Feedback Models (LFMs) that identify desirable behaviour - actions that help achieve tasks specified in the instruction - for imitation learning in instruction following. To train LFMs, we obtain feedback from Large Language Models (LLMs) on visual trajectories verbalized to language descriptions. First, by using LFMs to identify desirable behaviour to imitate, we improve in task-completion rate over strong behavioural cloning baselines on three distinct language grounding environments (Touchdown, ScienceWorld, and ALFWorld). Second, LFMs outperform using LLMs as experts to directly predict actions, when controlling for the number of LLM output tokens. Third, LFMs generalize to unseen environments, improving task-completion rate by 3.5-12.0% through one round of adaptation. Finally, LFM can be modified to provide human-interpretable feedback without performance loss, allowing human verification of desirable behaviour for imitation learning.
    
[^176]: 文字描述中的顺序对大语言模型的空间感知能力的影响

    Sequential Ordering in Textual Descriptions: Impact on Spatial Perception Abilities of Large Language Models

    [https://arxiv.org/abs/2402.07140](https://arxiv.org/abs/2402.07140)

    这项研究揭示了图描述的文本顺序对大语言模型在图推理中的性能产生显著影响，并通过改变文本顺序提高了大语言模型的性能。此外，发现大语言模型的推理性能与图大小之间的关系不是单调递减的。为了评估大语言模型在不同图大小上的性能，引入了规模化图推理基准。

    

    最近几年，大语言模型在多个领域达到了最先进的性能。然而，图推理领域的进展仍然有限。我们的工作深入研究了大语言模型的图推理。在这项工作中，我们揭示了文本顺序对大语言模型空间理解的影响，发现图描述的文本顺序显著影响大语言模型对图的推理性能。通过改变图描述的文本顺序，我们将大语言模型的性能从42.22％提高到70％。此外，我们评估了大语言模型性能和图大小之间的关系，发现大语言模型的推理性能不随图大小的增加而单调递减。最后，我们引入了规模化图推理基准来评估大语言模型在不同图大小上的性能。

    In recent years, Large Language Models have reached state-of-the-art performance across multiple domains. However, the progress in the field of graph reasoning remains limited. Our work delves into this gap by thoroughly investigating graph reasoning with LLM. In this work, we reveal the impact of text sequence on LLM spatial understanding, finding that graph-descriptive text sequences significantly affect LLM reasoning performance on graphs. By altering the graph-descriptive text sequences, we enhance the performance of LLM from 42.22\% to 70\%. Furthermore, we evaluate the relationship between LLM performance and graph size, discovering that the reasoning performance of LLM does not monotonically decrease with the increase in graph size. Conclusively, we introduce the Scaled Graph Reasoning benchmark for assessing LLM performance across varied graph sizes.
    
[^177]: 使用点击提示对超声图像分割进行精调的Segment Anything Model（SAM）

    ClickSAM: Fine-tuning Segment Anything Model using click prompts for ultrasound image segmentation

    [https://arxiv.org/abs/2402.05902](https://arxiv.org/abs/2402.05902)

    本研究提出了ClickSAM，该方法使用点击提示对超声图像进行Segment Anything Model的精细调整，解决了超声图像分割中噪声干扰的问题。

    

    由于其卓越的分割准确性、多样的输入提示、训练能力和高效的模型设计，新发布的Segment Anything Model（SAM）成为图像处理中流行的工具。然而，SAM当前的模型是在一个多样的数据集上训练的，而这些数据集并没有针对医学图像，尤其是超声图像。超声图像往往有很多噪声，这使得分割重要结构变得困难。在这个项目中，我们开发了ClickSAM，它使用点击提示对超声图像进行Segment Anything Model的精细调整。ClickSAM有两个训练阶段：第一阶段使用位于真实轮廓中心的单击提示进行训练，第二阶段通过额外的正负点击提示来改善模型性能。通过将第一阶段的预测与真实掩膜进行比较，计算出真正正、假正和假负段。正点击使用真实掩膜中的真实

    The newly released Segment Anything Model (SAM) is a popular tool used in image processing due to its superior segmentation accuracy, variety of input prompts, training capabilities, and efficient model design. However, its current model is trained on a diverse dataset not tailored to medical images, particularly ultrasound images. Ultrasound images tend to have a lot of noise, making it difficult to segment out important structures. In this project, we developed ClickSAM, which fine-tunes the Segment Anything Model using click prompts for ultrasound images. ClickSAM has two stages of training: the first stage is trained on single-click prompts centered in the ground-truth contours, and the second stage focuses on improving the model performance through additional positive and negative click prompts. By comparing the first stage predictions to the ground-truth masks, true positive, false positive, and false negative segments are calculated. Positive clicks are generated using the true 
    
[^178]: 探索针对设备上模型的白盒攻击

    Investigating White-Box Attacks for On-Device Models

    [https://arxiv.org/abs/2402.05493](https://arxiv.org/abs/2402.05493)

    本研究探究了针对设备上模型的白盒攻击，提出了一种逆向工程框架(REOM)以将编译后的设备上TFLite模型转换为可调试模型。

    

    许多移动应用程序利用了深度学习的能力。然而，设备上的模型容易受到攻击，因为它们可以从相应的移动应用程序中轻易提取出来。现有的设备上攻击方法只能生成黑盒攻击，这种方法远不如白盒策略有效和高效。这是因为移动深度学习框架如TFLite不支持梯度计算，而梯度计算对于白盒攻击算法是必要的。因此，我们认为现有的发现可能低估了设备上攻击的危害性。为了回答这个研究问题，我们进行了一项研究：设备上的模型是否可以通过白盒策略直接受到攻击？我们首先系统地分析了将设备上模型转换为可调试版本的困难，并提出了一种针对设备上模型的逆向工程框架(REOM)，该框架可以自动将编译后的设备上TFLite模型逆向为可调试模型。具体来说，REOM

    Numerous mobile apps have leveraged deep learning capabilities. However, on-device models are vulnerable to attacks as they can be easily extracted from their corresponding mobile apps. Existing on-device attacking approaches only generate black-box attacks, which are far less effective and efficient than white-box strategies. This is because mobile deep learning frameworks like TFLite do not support gradient computing, which is necessary for white-box attacking algorithms. Thus, we argue that existing findings may underestimate the harmfulness of on-device attacks. To this end, we conduct a study to answer this research question: Can on-device models be directly attacked via white-box strategies? We first systematically analyze the difficulties of transforming the on-device model to its debuggable version, and propose a Reverse Engineering framework for On-device Models (REOM), which automatically reverses the compiled on-device TFLite model to the debuggable model. Specifically, REOM
    
[^179]: 知识图谱与多模态学习：综述

    Knowledge Graphs Meet Multi-Modal Learning: A Comprehensive Survey

    [https://arxiv.org/abs/2402.05391](https://arxiv.org/abs/2402.05391)

    知识图谱与多模态学习的综述介绍了KG4MM和MM4KG两个主要方面，包括任务定义、构建进展、评估基准以及关键研究轨迹。

    

    知识图谱在推动各种人工智能应用方面起着关键作用，语义网络社区对多模态维度的探索为创新打开了新的途径。在本综述中，我们仔细审查了300多篇文章，重点关注了两个主要方面的知识图谱感知研究：以知识图谱支持多模态任务的KG驱动多模态（KG4MM）学习，将知识图谱研究扩展到多模态知识图谱（MM4KG）领域。我们从定义知识图谱和多模态知识图谱开始，然后探索它们的构建进展。我们的综述包括两个主要任务类别：KG感知的多模态学习任务，如图像分类和视觉问答，以及内在的多模态知识图谱任务，如多模态知识图谱补全和实体对齐，突出了具体的研究轨迹。对于这些任务中的大部分，我们提供了定义、评估基准，并进一步指出进行相关研究的重要见解。最后，我们讨论了cu

    Knowledge Graphs (KGs) play a pivotal role in advancing various AI applications, with the semantic web community's exploration into multi-modal dimensions unlocking new avenues for innovation. In this survey, we carefully review over 300 articles, focusing on KG-aware research in two principal aspects: KG-driven Multi-Modal (KG4MM) learning, where KGs support multi-modal tasks, and Multi-Modal Knowledge Graph (MM4KG), which extends KG studies into the MMKG realm. We begin by defining KGs and MMKGs, then explore their construction progress. Our review includes two primary task categories: KG-aware multi-modal learning tasks, such as Image Classification and Visual Question Answering, and intrinsic MMKG tasks like Multi-modal Knowledge Graph Completion and Entity Alignment, highlighting specific research trajectories. For most of these tasks, we provide definitions, evaluation benchmarks, and additionally outline essential insights for conducting relevant research. Finally, we discuss cu
    
[^180]: 结合云计算与移动计算的机器学习研究

    Combining Cloud and Mobile Computing for Machine Learning

    [https://arxiv.org/abs/2402.04880](https://arxiv.org/abs/2402.04880)

    这项研究将模型分割为移动设备和云之间的计算，以减轻移动设备的负担，并优化云端的工作负载。

    

    尽管移动设备的计算能力正在增加，但机器学习模型的大小也在增长。这种趋势给移动设备带来了问题，如内存容量和电池寿命的限制。虽然许多服务（如ChatGPT和Midjourney）在云中运行所有的推理，但我们认为灵活性和细粒度的任务分配更可取。在这项工作中，我们将模型分割视为改善用户体验的解决方案，将计算分割在移动设备和云之间，以减轻模型的计算密集部分，同时尽量减少数据传输的需求。我们展示了这种分割不仅减少了用户等待时间，还可以通过细粒度调整来优化云端的工作负载。为了实现这一目标，我们设计了一个调度器，收集网络质量、客户端设备能力和作业要求的信息，做出决策以实现在各种设备上的一致性性能。

    Although the computing power of mobile devices is increasing, machine learning models are also growing in size. This trend creates problems for mobile devices due to limitations like their memory capacity and battery life. While many services, like ChatGPT and Midjourney, run all the inferences in the cloud, we believe a flexible and fine-grained task distribution is more desirable. In this work, we consider model segmentation as a solution to improving the user experience, dividing the computation between mobile devices and the cloud in a way that offloads the compute-heavy portion of the model while minimizing the data transfer required. We show that the division not only reduces the wait time for users but can also be fine-tuned to optimize the workloads of the cloud. To achieve that, we design a scheduler that collects information about network quality, client device capability, and job requirements, making decisions to achieve consistent performance across a range of devices while
    
[^181]: RevOrder：一种增强语言模型中算术运算的新方法

    RevOrder: A Novel Method for Enhanced Arithmetic in Language Models

    [https://arxiv.org/abs/2402.03822](https://arxiv.org/abs/2402.03822)

    本文提出了一种名为RevOrder的新方法，通过翻转加法、减法和nD乘以1D的输出数字，显著改善了语言模型中的算术运算。经过全面测试，RevOrder在基本算术运算中达到了完美准确度，并在除法任务中提升了语言模型性能，特别是在处理大数时。在GSM8K数学任务中应用RevOrder进行微调，有效降低了错误率并提高了总体得分。

    

    本文提出了RevOrder，一种旨在改善大型语言模型中算术运算的新技术。该方法通过翻转加法、减法和n位数乘以1位数（nD乘以1D）的输出数字，显著降低了顺序中间数字的数量 (CSID)，这是我们引入的一种评估方程复杂性的新度量。通过全面的测试，RevOrder不仅在基本的算术运算中达到了完美的准确度，而且在除法任务中显著提升了语言模型的性能，特别是在传统模型难以处理的大数情况下。RevOrder的实现对于训练和推理阶段都具有成本效益。此外，将RevOrder应用于对GSM8K数学任务进行微调的LLaMA2-7B模型中，取得了显著的改善，将方程计算错误率降低了46%，将总体得分从41.6提升到44.4。

    This paper presents RevOrder, a novel technique aimed at improving arithmetic operations in large language models (LLMs) by reversing the output digits in addition, subtraction, and n-digit by 1-digit (nD by 1D) multiplication tasks. Our method significantly reduces the Count of Sequential Intermediate Digits (CSID) to $\mathcal{O}(1)$, a new metric we introduce to assess equation complexity. Through comprehensive testing, RevOrder not only achieves perfect accuracy in basic arithmetic operations but also substantially boosts LLM performance in division tasks, particularly with large numbers where traditional models struggle. Implementation of RevOrder is cost-effective for both training and inference phases. Moreover, applying RevOrder to fine-tune the LLaMA2-7B model on the GSM8K math task results in a considerable improvement, reducing equation calculation errors by 46% and increasing overall scores from 41.6 to 44.4.
    
[^182]: 揭示宣传：基于人类注释和机器分类的文体线索比较分析

    Exposing propaganda: an analysis of stylistic cues comparing human annotations and machine classification

    [https://arxiv.org/abs/2402.03780](https://arxiv.org/abs/2402.03780)

    本文通过分析文体线索比较人类注释和机器分类的方法，揭示了宣传语言的特征，并提出了一个多源、多语言、多模态的数据集PPN。结果表明，人类注释者能够可靠地区分宣传新闻和常规新闻。研究还比较了不同的自然语言处理技术，并提供了一些有关文体线索的发现。

    

    本文研究了宣传语言及其文体特征。提出了PPN数据集，即宣传性伪新闻数据集，它是一种多源、多语言、多模态的数据集，由专家机构确定的宣传来源网站上的新闻文章组成。从该数据集中随机选择了一部分样本与来自常规法国新闻的文章混合，并对它们的URL进行了掩盖，以进行人类注释实验，使用11个不同的标签。结果显示，人类注释者能够可靠地区分两种类型的新闻纸对每个标签。我们提出了不同的自然语言处理技术来识别注释者使用的线索，并与机器分类进行比较。其中包括使用VAGO分析器进行辞述模糊和主观性的测量，使用TF-IDF作为基准，以及四种不同的分类器：两个基于RoBERTa模型的模型，使用句法的CATS，以及结合句法和语义特征的一个XGBoost模型。

    This paper investigates the language of propaganda and its stylistic features. It presents the PPN dataset, standing for Propagandist Pseudo-News, a multisource, multilingual, multimodal dataset composed of news articles extracted from websites identified as propaganda sources by expert agencies. A limited sample from this set was randomly mixed with papers from the regular French press, and their URL masked, to conduct an annotation-experiment by humans, using 11 distinct labels. The results show that human annotators were able to reliably discriminate between the two types of press across each of the labels. We propose different NLP techniques to identify the cues used by the annotators, and to compare them with machine classification. They include the analyzer VAGO to measure discourse vagueness and subjectivity, a TF-IDF to serve as a baseline, and four different classifiers: two RoBERTa-based models, CATS using syntax, and one XGBoost combining syntactic and semantic features.   K
    
[^183]: SGS-SLAM：基于高斯点云的语义稠密SLAM

    SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM

    [https://arxiv.org/abs/2402.03246](https://arxiv.org/abs/2402.03246)

    SGS-SLAM是一种基于三维高斯点云的语义稠密SLAM系统，通过多通道优化和关键帧优化，实现了高质量的重建和精确的语义分割。

    

    语义理解在稠密同时定位和建图（SLAM）中起着关键作用，有助于全面的场景解析。最近将高斯点云集成到SLAM系统中的进展表明，通过使用显式的三维高斯表示，可以生成高质量的渲染效果。基于这一进展，我们提出了SGS-SLAM，这是第一个基于三维高斯点云的语义稠密视觉SLAM系统，它不仅提供精确的三维语义分割，还实现了高保真度的重建。具体而言，我们提出在建图过程中采用多通道优化，将外观、几何和语义约束与关键帧优化相结合，以提高重建质量。大量实验证明SGS-SLAM在相机位姿估计、地图重建和语义分割方面表现出了最先进的性能，优于现有方法同时保持实时渲染。

    Semantic understanding plays a crucial role in Dense Simultaneous Localization and Mapping (SLAM), facilitating comprehensive scene interpretation. Recent advancements that integrate Gaus- sian Splatting into SLAM systems have demonstrated its effectiveness in generating high-quality renderings through the use of explicit 3D Gaussian representations. Building on this progress, we propose SGS-SLAM, the first semantic dense visual SLAM system grounded in 3D Gaussians, which provides precise 3D semantic segmentation alongside high-fidelity reconstructions. Specifically, we propose to employ multi-channel optimization during the mapping process, integrating appearance, geometric, and semantic constraints with key-frame optimization to enhance reconstruction quality. Extensive experiments demonstrate that SGS-SLAM delivers state-of-the-art performance in camera pose estimation, map reconstruction, and semantic segmentation, outperforming existing methods meanwhile preserving real-time rende
    
[^184]: 从大型语言模型中提取上下文信息用于知识图谱补全

    Contextualization Distillation from Large Language Model for Knowledge Graph Completion

    [https://arxiv.org/abs/2402.01729](https://arxiv.org/abs/2402.01729)

    本论文介绍了一种从大型语言模型中提取上下文信息用于知识图谱补全的策略，该策略能克服现有语料库的限制，显著提高了预训练语言模型在知识图谱补全中的性能。

    

    虽然文本信息显著提高了预训练语言模型（PLMs）在知识图谱补全（KGC）中的性能，但现有语料库从维基百科文章或同义词定义中收集的静态和噪声性质常常限制了基于PLM的KGC模型的潜力。为了克服这些挑战，我们提出了上下文化蒸馏策略，这是一种通用的可插入和可播放的方法，与判别和生成的KGC框架兼容。我们的方法首先指导大型语言模型（LLMs）将紧凑的结构化三元组转换为上下文丰富的段落。随后，我们引入了两个定制的辅助任务，重建和上下文化，使较小的KGC模型能够吸收这些丰富的三元组中的见解。对多种数据集和KGC技术的全面评估突出了我们方法的功效和适应性，揭示了无论基础管道如何，始终能提高性能。

    While textual information significantly enhances the performance of pre-trained language models (PLMs) in knowledge graph completion (KGC), the static and noisy nature of existing corpora collected from Wikipedia articles or synsets definitions often limits the potential of PLM-based KGC models. To surmount these challenges, we introduce the Contextualization Distillation strategy, a versatile plug-in-and-play approach compatible with both discriminative and generative KGC frameworks. Our method begins by instructing large language models (LLMs) to transform compact, structural triplets into context-rich segments. Subsequently, we introduce two tailored auxiliary tasks, reconstruction and contextualization, allowing smaller KGC models to assimilate insights from these enriched triplets. Comprehensive evaluations across diverse datasets and KGC techniques highlight the efficacy and adaptability of our approach, revealing consistent performance enhancements irrespective of underlying pip
    
[^185]: 跨城市少样本交通预测的多尺度交通模式库

    Multi-scale Traffic Pattern Bank for Cross-city Few-shot Traffic Forecasting

    [https://arxiv.org/abs/2402.00397](https://arxiv.org/abs/2402.00397)

    我们提出了一种跨城市少样本交通预测的解决方案，利用多尺度交通模式库从数据丰富的源城市学习并预测其他城市的交通情况。

    

    交通预测对智能交通系统具有重要意义，可以帮助高效分配资源和有效控制交通。然而，其有效性往往严重依赖于丰富的交通数据，而许多城市由于设备支持有限而缺乏足够的数据，这对交通预测构成了重大挑战。鉴于这一挑战，我们做出了一个显著的观察：交通模式在不同城市之间存在相似性。基于这一关键洞察，我们提出了一种解决跨城市少样本交通预测问题的方法，称为多尺度交通模式库（MTPB）。主要上，MTPB通过利用数据丰富的源城市启动其学习过程，通过空间-时间感知的预训练过程有效获取全面的交通知识。随后，该框架采用先进的聚类技术从学习到的知识中系统生成一个多尺度交通模式库。接下来，该框架使用准确的交通模式检索机制进行跨城市的少样本交通预测。

    Traffic forecasting is crucial for intelligent transportation systems (ITS), aiding in efficient resource allocation and effective traffic control. However, its effectiveness often relies heavily on abundant traffic data, while many cities lack sufficient data due to limited device support, posing a significant challenge for traffic forecasting. Recognizing this challenge, we have made a noteworthy observation: traffic patterns exhibit similarities across diverse cities. Building on this key insight, we propose a solution for the cross-city few-shot traffic forecasting problem called Multi-scale Traffic Pattern Bank (MTPB). Primarily, MTPB initiates its learning process by leveraging data-rich source cities, effectively acquiring comprehensive traffic knowledge through a spatial-temporal-aware pre-training process. Subsequently, the framework employs advanced clustering techniques to systematically generate a multi-scale traffic pattern bank derived from the learned knowledge. Next, th
    
[^186]: CodeAid: 对基于LLM的编程助手进行课堂部署的评估，平衡学生和教育者的需求

    CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs

    [https://arxiv.org/abs/2401.11314](https://arxiv.org/abs/2401.11314)

    通过开发CodeAid，一个基于LLM的编程助手，我们平衡了学生和教育者的需求，提供了有用的概念性回答而不暴露代码解决方案，在课堂环境中对其进行了评估和部署，并总结出四个未来教育AI助手的设计考虑。

    

    科学的、个性化的反馈对于学习编程的学生至关重要。像ChatGPT这样基于LLM的工具提供即时支持，但呈现直接的代码答案，这可能妨碍深入的概念参与。我们开发了CodeAid，一个基于LLM的编程助手，提供有用的、技术上正确的回答，但不显示代码解决方案。CodeAid回答概念问题，生成带有逐行解释的伪代码，并为学生的错误代码加上修复建议。我们在一个包括700名学生的编程课程中部署了CodeAid，为期12周。我们进行了8000次CodeAid使用的主题分析，进一步结合每周调查和22次学生访谈。然后我们采访了八名编程教育者，以获得更多见解。我们的研究结果揭示了未来教育AI助手的四个设计考虑：D1)充分利用AI的独特优势；D2)简化查询形式。

    arXiv:2401.11314v2 Announce Type: replace-cross  Abstract: Timely, personalized feedback is essential for students learning programming. LLM-powered tools like ChatGPT offer instant support, but reveal direct answers with code, which may hinder deep conceptual engagement. We developed CodeAid, an LLM-powered programming assistant delivering helpful, technically correct responses, without revealing code solutions. CodeAid answers conceptual questions, generates pseudo-code with line-by-line explanations, and annotates student's incorrect code with fix suggestions. We deployed CodeAid in a programming class of 700 students for a 12-week semester. A thematic analysis of 8,000 usages of CodeAid was performed, further enriched by weekly surveys, and 22 student interviews. We then interviewed eight programming educators to gain further insights. Our findings reveal four design considerations for future educational AI assistants: D1) exploiting AI's unique benefits; D2) simplifying query form
    
[^187]: MapGPT：具有自适应路径规划的地图引导提示的视觉与语言导航

    MapGPT: Map-Guided Prompting with Adaptive Path Planning for Vision-and-Language Navigation

    [https://arxiv.org/abs/2401.07314](https://arxiv.org/abs/2401.07314)

    MapGPT引入了在线语言形成的地图，帮助GPT理解整体环境，提出自适应规划机制以协助代理执行多步路径规划。

    

    具有GPT作为大脑的体验代理表现出在各种任务中的非凡决策和泛化能力。然而，现有的视觉与语言导航（VLN）零-shot代理只促使GPT-4在局部环境中选择潜在位置，而没有为代理构建一个有效的“全局视图”来理解整体环境。在这项工作中，我们提出了一种新颖的地图引导的基于GPT的代理，名为MapGPT，它引入了一个在线语言形成的地图来鼓励全局探索。具体而言，我们构建了一个在线地图，并将其合并到包含节点信息和拓扑关系的提示中，以帮助GPT理解空间环境。从这一设计中获益，我们进一步提出了一种自适应规划机制，以帮助代理根据地图执行多步规划，系统地探索多个候选

    arXiv:2401.07314v2 Announce Type: replace  Abstract: Embodied agents equipped with GPT as their brain have exhibited extraordinary decision-making and generalization abilities across various tasks. However, existing zero-shot agents for vision-and-language navigation (VLN) only prompt the GPT-4 to select potential locations within localized environments, without constructing an effective "global-view" for the agent to understand the overall environment. In this work, we present a novel map-guided GPT-based agent, dubbed MapGPT, which introduces an online linguistic-formed map to encourage the global exploration. Specifically, we build an online map and incorporate it into the prompts that include node information and topological relationships, to help GPT understand the spatial environment. Benefiting from this design, we further propose an adaptive planning mechanism to assist the agent in performing multi-step path planning based on a map, systematically exploring multiple candidate 
    
[^188]: MoE-Mamba: 混合专家模型的高效选择性状态空间模型

    MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts

    [https://arxiv.org/abs/2401.04081](https://arxiv.org/abs/2401.04081)

    结合混合专家模型的MoE-Mamba在性能上优于Mamba和基准Transformer-MoE，达到了与Mamba相同性能的同时，训练步骤减少了2.35倍。

    

    状态空间模型（SSMs）已经成为顺序建模领域的严肃竞争者，挑战了Transformer的主导地位。与此同时，混合专家（MoE）显著改进了基于Transformer的大型语言模型，包括最近的最先进开放模型。我们提出要发掘SSMs在扩展方面的潜力，它们应该与MoE相结合。我们在Mamba上展示了这一点，这是一个最近基于SSM的模型，取得了显著的性能。我们的模型MoE-Mamba在性能方面表现优异，优于Mamba和基准Transformer-MoE。特别地，MoE-Mamba在更少的训练步骤中达到与Mamba相同的性能，同时保持Mamba相对于Transformer的推理性能增益。

    arXiv:2401.04081v2 Announce Type: replace-cross  Abstract: State Space Models (SSMs) have become serious contenders in the field of sequential modeling, challenging the dominance of Transformers. At the same time, Mixture of Experts (MoE) has significantly improved Transformer-based Large Language Models, including recent state-of-the-art open models. We propose that to unlock the potential of SSMs for scaling, they should be combined with MoE. We showcase this on Mamba, a recent SSM-based model that achieves remarkable performance. Our model, MoE-Mamba, outperforms both Mamba and baseline Transformer-MoE. In particular, MoE-Mamba reaches the same performance as Mamba in $2.35\times$ fewer training steps while preserving the inference performance gains of Mamba against Transformer.
    
[^189]: AllSpark: 一个具有十三种模态的多模态时空智能模型

    AllSpark: A Multimodal Spatio-Temporal General Intelligence Model with Thirteen Modalities

    [https://arxiv.org/abs/2401.00546](https://arxiv.org/abs/2401.00546)

    提出了一个名为AllSpark的多模态时空智能通用人工智能模型，集成了十三种不同的模态，旨在解决多模态时空数据联合解释的挑战。

    

    长期以来，由于各种时空模态数据之间结构和语义的高度异质性，多模态时空数据的联合解释一直是一个极具挑战性的问题。主要挑战在于在不同模态之间的凝聚力和自治性之间取得平衡，而随着模态数量的增加，这种平衡表现出逐渐非线性的特性。我们引入了语言作为参考框架（LaRF），这是构建多模态统一模型的基本原则，旨在在不同模态之间取得凝聚力和自治性之间的平衡。我们提出了一个名为AllSpark的多模态时空智能通用人工智能模型。我们的模型将十三种不同的模态集成到一个统一框架中，包括1D（文本，代码），2D（RGB，红外线，SAR，多光谱，高光谱，表格，图表，轨迹，斜角摄影）。

    arXiv:2401.00546v2 Announce Type: replace  Abstract: For a long time, due to the high heterogeneity in structure and semantics among various spatiotemporal modal data, the joint interpretation of multimodal spatiotemporal data has been an extremely challenging problem. The primary challenge resides in striking a trade-off between the cohesion and autonomy of diverse modalities, and this trade-off exhibits a progressively nonlinear nature as the number of modalities expands. We introduce the Language as Reference Framework (LaRF), a fundamental principle for constructing a multimodal unified model, aiming to strike a trade-off between the cohesion and autonomy among different modalities. We propose a multimodal spatiotemporal general artificial intelligence model, called AllSpark. Our model integrates thirteen different modalities into a unified framework, including 1D (text, code), 2D (RGB, infrared, SAR, multispectral, hyperspectral, tables, graphs, trajectory, oblique photography), a
    
[^190]: 复杂系统中的出现和因果关系：关于因果出现和相关定量研究的调查

    Emergence and Causality in Complex Systems: A Survey on Causal Emergence and Related Quantitative Studies

    [https://arxiv.org/abs/2312.16815](https://arxiv.org/abs/2312.16815)

    本文综述了关于因果出现和相关定量研究的最新进展，重点解决了量化因果出现和在数据中识别因果出现的两个问题，并建立了因果出现与人工智能之间的联系。

    

    出现和因果关系是理解复杂系统的两个基本概念，它们是相互关联的。出现一方面指的是宏观属性不能仅归因于个体属性的原因。另一方面，因果关系可以表现出出现，意味着随着抽象层次的增加，可能会出现新的因果定律。因果出现理论旨在连接这两个概念，甚至采用因果度量来量化出现。本文综述了因果出现定量理论和应用的最新进展。重点解决了两个关键问题：量化因果出现和在数据中识别因果出现。解决后者需要使用机器学习技术，从而建立了因果出现与人工智能之间的联系。我们强调了用于识别因果出现的架构与因果表示学习的共享。

    Emergence and causality are two fundamental concepts for understanding complex systems. They are interconnected. On one hand, emergence refers to the phenomenon where macroscopic properties cannot be solely attributed to the cause of individual properties. On the other hand, causality can exhibit emergence, meaning that new causal laws may arise as we increase the level of abstraction. Causal emergence theory aims to bridge these two concepts and even employs measures of causality to quantify emergence. This paper provides a comprehensive review of recent advancements in quantitative theories and applications of causal emergence. Two key problems are addressed: quantifying causal emergence and identifying it in data. Addressing the latter requires the use of machine learning techniques, thus establishing a connection between causal emergence and artificial intelligence. We highlighted that the architectures used for identifying causal emergence are shared by causal representation learn
    
[^191]: 独立学习将时间序列片段嵌入

    Learning to Embed Time Series Patches Independently

    [https://arxiv.org/abs/2312.16427](https://arxiv.org/abs/2312.16427)

    学习独立嵌入时间序列片段可以产生更好的时间序列表示，通过简单的块重构任务和独立嵌入每个块的MLP模型以及互补对比学习来实现。

    

    最近，掩码时间序列建模作为一种自监督表示学习策略引起了广泛关注。受计算机视觉中的掩码图像建模启发，最近的研究首先将时间序列进行分块处理并部分掩盖，然后训练Transformer模型通过从未掩盖的块预测被掩盖块来捕捉块之间的依赖关系。然而，我们认为捕捉这种块之间的依赖关系可能不是时间序列表示学习的最佳策略；相反，独立学习嵌入片段会产生更好的时间序列表示。具体而言，我们建议使用1）简单的块重构任务，自动将每个块进行编码而不查看其他块，以及2）独自嵌入每个块的简单块式MLP。此外，我们引入互补对比学习来有效地分层捕获相邻时间序列信息。

    arXiv:2312.16427v2 Announce Type: replace-cross  Abstract: Masked time series modeling has recently gained much attention as a self-supervised representation learning strategy for time series. Inspired by masked image modeling in computer vision, recent works first patchify and partially mask out time series, and then train Transformers to capture the dependencies between patches by predicting masked patches from unmasked patches. However, we argue that capturing such patch dependencies might not be an optimal strategy for time series representation learning; rather, learning to embed patches independently results in better time series representations. Specifically, we propose to use 1) the simple patch reconstruction task, which autoencode each patch without looking at other patches, and 2) the simple patch-wise MLP that embeds each patch independently. In addition, we introduce complementary contrastive learning to hierarchically capture adjacent time series information efficiently. 
    
[^192]: 时间序列的软对比学习

    Soft Contrastive Learning for Time Series

    [https://arxiv.org/abs/2312.16424](https://arxiv.org/abs/2312.16424)

    提出了一种名为SoftCLT的方法，通过引入实例级和时间级软对比损失，解决了在时间序列中忽略固有相关性所导致的学习表示质量下降的问题。

    

    对比学习已经被证明在自监督学习中对于从时间序列中学习表示是有效的。然而，将时间序列中相似的实例或相邻时间戳的值进行对比会忽略它们固有的相关性，从而导致学习表示的质量下降。为了解决这个问题，我们提出了SoftCLT，一种简单而有效的时间序列软对比学习策略。这是通过引入从零到一的软赋值的实例级和时间级对比损失来实现的。具体来说，我们为1)基于数据空间上的时间序列之间的距离定义了实例级对比损失的软赋值，并为2)基于时间戳之间的差异定义了时间级对比损失。SoftCLT是一种即插即用的时间序列对比学习方法，可以提高学习表示的质量，没有过多复杂的设计。

    arXiv:2312.16424v2 Announce Type: replace-cross  Abstract: Contrastive learning has shown to be effective to learn representations from time series in a self-supervised way. However, contrasting similar time series instances or values from adjacent timestamps within a time series leads to ignore their inherent correlations, which results in deteriorating the quality of learned representations. To address this issue, we propose SoftCLT, a simple yet effective soft contrastive learning strategy for time series. This is achieved by introducing instance-wise and temporal contrastive loss with soft assignments ranging from zero to one. Specifically, we define soft assignments for 1) instance-wise contrastive loss by the distance between time series on the data space, and 2) temporal contrastive loss by the difference of timestamps. SoftCLT is a plug-and-play method for time series contrastive learning that improves the quality of learned representations without bells and whistles. In experi
    
[^193]: 高效的标题重新排序器，用于快速和改进的知识密集型自然语言处理

    Efficient Title Reranker for Fast and Improved Knowledge-Intense NLP

    [https://arxiv.org/abs/2312.12430](https://arxiv.org/abs/2312.12430)

    引入了通过广播查询编码器实现的高效标题重新排序器和为标题重新排序定制的Sigmoid Trick损失函数，相结合在KILT知识基准测试的数据集上取得了最先进的结果。

    

    在最近的RAG方法中，重新排序器在提升检索准确性方面发挥着关键作用，能够揭示每对查询和文本之间的逻辑关系。然而，现有的重新排序器需要反复对查询和大量长文本进行编码。这导致了较高的计算成本，并限制了检索文本的数量，从而影响了准确性。作为问题的解决方案，我们引入了通过广播查询编码器实现的高效标题重新排序器，这是一种用于标题重新排序的新技术，可以使速度提高20倍至40倍，超过基准通道重新排序器。此外，我们还引入了Sigmoid Trick，一种为标题重新排序定制的新损失函数。将这两种技术结合起来，我们在从KILT知识基准测试中实验的四个数据集上都经验验证了它们的有效性，实现了最先进的结果。

    arXiv:2312.12430v3 Announce Type: replace-cross  Abstract: In recent RAG approaches, rerankers play a pivotal role in refining retrieval accuracy with the ability of revealing logical relations for each pair of query and text. However, existing rerankers are required to repeatedly encode the query and a large number of long retrieved text. This results in high computational costs and limits the number of retrieved text, hindering accuracy. As a remedy of the problem, we introduce the Efficient Title Reranker via Broadcasting Query Encoder, a novel technique for title reranking that achieves a 20x-40x speedup over the vanilla passage reranker. Furthermore, we introduce Sigmoid Trick, a novel loss function customized for title reranking. Combining both techniques, we empirically validated their effectiveness, achieving state-of-the-art results on all four datasets we experimented with from the KILT knowledge benchmark.
    
[^194]: 混合蒸馏有助于较小的语言模型更好地推理

    Mixed Distillation Helps Smaller Language Model Better Reasoning

    [https://arxiv.org/abs/2312.10730](https://arxiv.org/abs/2312.10730)

    混合蒸馏(MD)框架结合了LLMs中的Program of Thought (PoT)和Chain of Thought (CoT)能力，将多种提示技术蒸馏到较小模型中，显著增强了较小模型在各种任务中的推理能力。

    

    虽然大型语言模型(LLMs)在最近的自然语言处理(NLP)任务中表现出了异常的性能，但由于在真实应用中的高计算和内存需求，它们的部署面临着重大挑战。最近的研究集中于通过从LLMs蒸馏知识来增强较小模型，在特定任务中取得了令人满意的结果。然而，这些模型在特别需要推理的任务中往往难以与LLMs的性能匹敌。在这项工作中，我们介绍了混合蒸馏(MD)框架，该框架利用了LLMs中的Program of Thought (PoT)和Chain of Thought (CoT)能力的优势，结合多种提示技术，并将这些能力蒸馏到较小的模型中。我们的实验结果表明，MD显著增强了较小模型在各种任务中的单路径和多路径推理能力。

    arXiv:2312.10730v2 Announce Type: replace-cross  Abstract: While large language models (LLMs) have demonstrated exceptional performance in recent natural language processing (NLP) tasks, their deployment poses substantial challenges due to high computational and memory demands in real-world applications. Recent studies have focused on enhancing smaller models through knowledge distillation from LLMs, yielding promising results. However, these models often struggle to match the performance of LLMs, especially in tasks that require reasoning. In this work, we introduce Mixed Distillation (MD) framework, which capitalizes on the strengths of Program of Thought (PoT) and Chain of Thought (CoT) capabilities within LLMs, combining multiple prompting techniques and distilling these capabilities into smaller models. Our experimental results show that MD significantly enhances the single-path and multi-path reasoning ability of smaller models in various tasks. In terms of accuracy and generalit
    
[^195]: MaxK-GNN: 探索加速图神经网络训练的理论速度极限

    MaxK-GNN: Towards Theoretical Speed Limits for Accelerating Graph Neural Networks Training

    [https://arxiv.org/abs/2312.08656](https://arxiv.org/abs/2312.08656)

    MaxK-GNN是一种先进的高性能GPU训练系统，通过MaxK非线性和理论分析，实现了图神经网络训练的垂直优化。

    

    在深度神经网络训练加速方面，GPU已经成为主流平台。 GPU在GNN上面临着诸多挑战，如工作负载不平衡和内存访问不规则，导致硬件利用不充分。现有解决方案例如PyG、DGL与cuSPARSE，以及GNNAdvisor框架部分解决了这些挑战，但内存流量仍然很显著。 我们认为，只有通过算法与系统创新的垂直优化才能实现显著的性能提升，而不是将加速优化视为“事后思考”（即（i）给定GNN算法，设计加速器，或（ii）给定硬件，主要优化GNN算法）。 本文介绍了MaxK-GNN，一种集成算法与系统创新的先进高性能GPU训练系统。 （i）我们引入了MaxK非线性并提供了MaxK非线性的理论分析，

    arXiv:2312.08656v3 Announce Type: replace-cross  Abstract: In the acceleration of deep neural network training, the GPU has become the mainstream platform. GPUs face substantial challenges on GNNs, such as workload imbalance and memory access irregularities, leading to underutilized hardware. Existing solutions such as PyG, DGL with cuSPARSE, and GNNAdvisor frameworks partially address these challenges but memory traffic is still significant.   We argue that drastic performance improvements can only be achieved by the vertical optimization of algorithm and system innovations, rather than treating the speedup optimization as an "after-thought" (i.e., (i) given a GNN algorithm, designing an accelerator, or (ii) given hardware, mainly optimizing the GNN algorithm). In this paper, we present MaxK-GNN, an advanced high-performance GPU training system integrating algorithm and system innovation. (i) We introduce the MaxK nonlinearity and provide a theoretical analysis of MaxK nonlinearity as
    
[^196]: GPT-4V(ision)对分布转移的适应性如何？初步调查

    How Well Does GPT-4V(ision) Adapt to Distribution Shifts? A Preliminary Investigation

    [https://arxiv.org/abs/2312.07424](https://arxiv.org/abs/2312.07424)

    该研究对GPT-4V(ision)在动态环境中的适应能力和泛化能力进行了评估，对比了其与CLIP、LLaVA和Gemini等知名模型。

    

    在机器学习领域，针对分布转移的泛化能力——即部署条件与训练场景不一致的情况——至关重要，特别是在诸如气候建模、生物医学和自动驾驶等领域。基于广泛预训练和任务多样性而区别于其他模型的基础模型的出现，引发了对它们对分布转移的适应能力的增加兴趣。GPT-4V(ision)作为最先进的公开获取的多模式基础模型，在各个领域，包括异常检测、视频理解、图像生成和医学诊断等方面有广泛应用。然而，它对数据分布的稳健性仍然较少被探究。针对这一空白，本研究对GPT-4V在动态环境中的适应能力和泛化能力进行了严格评估，与CLIP、LLaVA和Gemini等知名模型进行了对比。

    arXiv:2312.07424v3 Announce Type: replace-cross  Abstract: In machine learning, generalization against distribution shifts -- where deployment conditions diverge from the training scenarios -- is crucial, particularly in fields like climate modeling, biomedicine, and autonomous driving. The emergence of foundation models, distinguished by their extensive pretraining and task versatility, has led to an increased interest in their adaptability to distribution shifts. GPT-4V(ision) acts as the most advanced publicly accessible multimodal foundation model, with extensive applications across various domains, including anomaly detection, video understanding, image generation, and medical diagnosis. However, its robustness against data distributions remains largely underexplored. Addressing this gap, this study rigorously evaluates GPT-4V's adaptability and generalization capabilities in dynamic environments, benchmarking against prominent models like CLIP, LLaVA, and Gemini. We delve into GP
    
[^197]: 学习多图结构用于时间知识图推理

    Learning Multi-graph Structure for Temporal Knowledge Graph Reasoning

    [https://arxiv.org/abs/2312.03004](https://arxiv.org/abs/2312.03004)

    提出了一种关注学习多图结构的创新推理方法，用于解决时间知识图推理中存在的历史依赖和未来趋势反映不充分的问题。

    

    抽象：将基于历史快照的未来事件预测的时间知识图（TKG）推理称为外推，已引起广泛关注。由于其极端的多样性和空间与时间相关性的变化，TKG推理呈现出一项具有挑战性的任务，要求有效捕获事实之间的并发结构和演变交互作用。虽然现有方法在这方面已经取得了进展，但它们仍然无法充分利用TKG的多种内在表达语义形式，其中包括跨多个时间戳的实体相关性和时间信息的周期性。这种限制限制了它们充分反映历史依赖关系和未来趋势的能力。为了应对这些缺点，本文提出了一种关注学习多图结构（LMS）的创新推理方法。

    arXiv:2312.03004v2 Announce Type: replace-cross  Abstract: Temporal Knowledge Graph (TKG) reasoning that forecasts future events based on historical snapshots distributed over timestamps is denoted as extrapolation and has gained significant attention. Owing to its extreme versatility and variation in spatial and temporal correlations, TKG reasoning presents a challenging task, demanding efficient capture of concurrent structures and evolutional interactions among facts. While existing methods have made strides in this direction, they still fall short of harnessing the diverse forms of intrinsic expressive semantics of TKGs, which encompass entity correlations across multiple timestamps and periodicity of temporal information. This limitation constrains their ability to thoroughly reflect historical dependencies and future trends. In response to these drawbacks, this paper proposes an innovative reasoning approach that focuses on Learning Multi-graph Structure (LMS). Concretely, it com
    
[^198]: xTrimoGene：用于单细胞RNA-Seq数据的高效可扩展表示学习器

    xTrimoGene: An Efficient and Scalable Representation Learner for Single-Cell RNA-Seq Data

    [https://arxiv.org/abs/2311.15156](https://arxiv.org/abs/2311.15156)

    xTrimoGene是一种针对scRNA-seq数据的新型非对称编码器-解码器Transformer，利用数据的稀疏特性降低了计算复杂度，使得在保持高准确性的同时能够训练最大的转移学习模型。

    

    高通量测序技术的进步已经在单细胞水平上测量基因表达方面取得了显著进展。可公开获取的单细胞RNA测序（scRNA-seq）数据量已经超过了5000万条人类记录，每条记录测量了2万个基因。这突出了对无监督表示学习的需求，然而传统的Transformer架构在这些数据上进行训练在计算和内存方面都是不可行的。为了解决这一挑战，我们提出了一种新颖的用于scRNA-seq数据的非对称编码器-解码器Transformer，称为xTrimoGene$^\alpha$（或简称为xTrimoGene），它利用了数据的稀疏特性来扩展预训练。xTrimoGene的可扩展设计将FLOPs降低了一个到两个数量级，而与传统Transformer相比仍保持高准确性，使我们能够训练最大的转移学习模型。

    arXiv:2311.15156v2 Announce Type: replace-cross  Abstract: Advances in high-throughput sequencing technology have led to significant progress in measuring gene expressions at the single-cell level. The amount of publicly available single-cell RNA-seq (scRNA-seq) data is already surpassing 50M records for humans with each record measuring 20,000 genes. This highlights the need for unsupervised representation learning to fully ingest these data, yet classical transformer architectures are prohibitive to train on such data in terms of both computation and memory. To address this challenge, we propose a novel asymmetric encoder-decoder transformer for scRNA-seq data, called xTrimoGene$^\alpha$ (or xTrimoGene for short), which leverages the sparse characteristic of the data to scale up the pre-training. This scalable design of xTrimoGene reduces FLOPs by one to two orders of magnitude compared to classical transformers while maintaining high accuracy, enabling us to train the largest transf
    
[^199]: Tube-NeRF：使用Tube-Guided数据增强和NeRFs从MPC进行视运动策略的高效模仿学习

    Tube-NeRF: Efficient Imitation Learning of Visuomotor Policies from MPC using Tube-Guided Data Augmentation and NeRFs

    [https://arxiv.org/abs/2311.14153](https://arxiv.org/abs/2311.14153)

    结合IL和鲁棒MPC，设计了一种名为Tube-NeRF的数据增强方法，利用NeRFs生成合成图像，通过管的特性选择相关视图，高效计算对应的动作，从而实现了视觉导向策略的高效学习。

    

    模仿学习（IL）可以从资源密集型的模型预测控制器（MPC）中训练计算效率高的感知动作策略，但通常需要大量样本，导致训练时间长或鲁棒性有限。为了解决这些问题，我们将IL与一种考虑过程和传感不确定性的鲁棒MPC的变体相结合，设计了一种数据增强（DA）策略，实现了基于视觉的策略的高效学习。提出的DA方法名为Tube-NeRF，利用神经辐射场（NeRFs）生成新颖的合成图像，并利用鲁棒MPC的性质（管）选择相关视图，并有效计算相应的动作。我们将方法量身定制为多旋翼上的定位和轨迹跟踪任务，通过学习一个仅使用机载摄像机图像作为水平位置唯一来源的视动作策略来生成控制动作。

    arXiv:2311.14153v2 Announce Type: replace-cross  Abstract: Imitation learning (IL) can train computationally-efficient sensorimotor policies from a resource-intensive Model Predictive Controller (MPC), but it often requires many samples, leading to long training times or limited robustness. To address these issues, we combine IL with a variant of robust MPC that accounts for process and sensing uncertainties, and we design a data augmentation (DA) strategy that enables efficient learning of vision-based policies. The proposed DA method, named Tube-NeRF, leverages Neural Radiance Fields (NeRFs) to generate novel synthetic images, and uses properties of the robust MPC (the tube) to select relevant views and to efficiently compute the corresponding actions. We tailor our approach to the task of localization and trajectory tracking on a multirotor, by learning a visuomotor policy that generates control actions using images from the onboard camera as only source of horizontal position. Nume
    
[^200]: 镜子中的机器人：通过关联自监督模型学习模仿

    Robot at the Mirror: Learning to Imitate via Associating Self-supervised Models

    [https://arxiv.org/abs/2311.13226](https://arxiv.org/abs/2311.13226)

    通过关联自监督模型构建模型，使机器人能够在镜子前学习自身的三维姿势检测，质量即刻完美。

    

    我们引入了一种通过相关联而不是训练和微调从现成的自监督模型构建自定义模型的方法。我们以一个仿人机器人在镜子前观察并学习从其所感知的图像中检测自身身体的三维姿势为例进行演示。为构建我们的模型，我们首先通过在机器人操作之前准备的模型从视觉输入和机器人身体姿势中获得特征。然后，我们通过镜子中一个高效的样本机器人自我探索来映射它们对应的潜在空间。通过这种方式，机器人构建了所需的3D姿势检测器，其在获取的样本上即刻完美，而不是逐渐获得这个质量。这种使用关联特征向量对的映射随后以著名的Transformer模型的键-值机制相同的方式实施。最后，将我们的模型部署用于模仿

    arXiv:2311.13226v2 Announce Type: replace-cross  Abstract: We introduce an approach to building a custom model from ready-made self-supervised models via their associating instead of training and fine-tuning. We demonstrate it with an example of a humanoid robot looking at the mirror and learning to detect the 3D pose of its own body from the image it perceives. To build our model, we first obtain features from the visual input and the postures of the robot's body via models prepared before the robot's operation. Then, we map their corresponding latent spaces by a sample-efficient robot's self-exploration at the mirror. In this way, the robot builds the solicited 3D pose detector, which quality is immediately perfect on the acquired samples instead of obtaining the quality gradually. The mapping, which employs associating the pairs of feature vectors, is then implemented in the same way as the key-value mechanism of the famous transformer models. Finally, deploying our model for imitat
    
[^201]: 在社交媒体平台中对互联网迷因进行情境化处理

    Contextualizing Internet Memes Across Social Media Platforms

    [https://arxiv.org/abs/2311.11157](https://arxiv.org/abs/2311.11157)

    本研究旨在探究是否可以通过使用知识图来对社交媒体平台上的互联网迷因进行情境化处理，填补了迄今为止对互联网迷因进行全面追踪、识别和映射的空白。

    

    互联网迷因已成为网络上交流和表达观点的新颖格式。它们的流动性和创造性体现在它们被广泛使用，通常跨平台传播，偶尔也用于不道德或有害的目的。 虽然计算工作已经分析了它们随时间的高级别病毒性，并开发了专门用于检测仇恨言论的分类器，但迄今为止还没有努力旨在全面跟踪、识别和映射在社交媒体上发布的互联网迷因。 为了填补这一空白，我们调查了是否可以通过使用语义知识库，即知识图，对社交媒体平台上的互联网迷因进行情境化处理。我们从两个社交媒体平台Reddit和Discord收集了数千条潜在的互联网迷因帖子，并开发了提取-转换-加载过程，创建了一个带有候选迷因帖子的数据湖。

    arXiv:2311.11157v2 Announce Type: replace-cross  Abstract: Internet memes have emerged as a novel format for communication and expressing ideas on the web. Their fluidity and creative nature are reflected in their widespread use, often across platforms and occasionally for unethical or harmful purposes. While computational work has already analyzed their high-level virality over time and developed specialized classifiers for hate speech detection, there have been no efforts to date that aim to holistically track, identify, and map internet memes posted on social media. To bridge this gap, we investigate whether internet memes across social media platforms can be contextualized by using a semantic repository of knowledge, namely, a knowledge graph. We collect thousands of potential internet meme posts from two social media platforms, namely Reddit and Discord, and develop an extract-transform-load procedure to create a data lake with candidate meme posts. By using vision transformer-bas
    
[^202]: 多模拟推理的深度融合：深度融合用于多模态模拟推理

    Fuse It or Lose It: Deep Fusion for Multimodal Simulation-Based Inference

    [https://arxiv.org/abs/2311.10671](https://arxiv.org/abs/2311.10671)

    提出了多模态神经后验估计 (MultiNPE) 方法，利用深度融合学习整合不同来源的异构数据，在模拟推理中提高了对复杂数学模型参数的准确推断能力。

    

    我们提出多模态神经后验估计(MultiNPE)，这是一种利用神经网络在模拟推理中整合来自不同来源的异构数据的方法。受深度融合学习的进展启发，它赋予研究人员分析来自不同领域的数据并推断复杂数学模型参数的能力，提高了准确性。我们针对MultiNPE制定了多模态融合方法（早期、后期、混合），并在三项具有挑战性的实验中评估它们的性能。MultiNPE不仅在参考任务上优于单一数据源基线，还在神经科学和心脏病学的科学模型推理上取得了卓越成绩。我们系统地研究了部分缺失数据对不同融合策略的影响。在我们的实验中，后期和混合融合技术成为多模态模拟推理实际应用的首选方法。

    arXiv:2311.10671v2 Announce Type: replace-cross  Abstract: We present multimodal neural posterior estimation (MultiNPE), a method to integrate heterogeneous data from different sources in simulation-based inference with neural networks. Inspired by advances in deep fusion learning, it empowers researchers to analyze data from different domains and infer the parameters of complex mathematical models with increased accuracy. We formulate multimodal fusion approaches for \hbox{MultiNPE} (early, late, hybrid) and evaluate their performance in three challenging experiments. MultiNPE not only outperforms single-source baselines on a reference task, but also achieves superior inference on scientific models from neuroscience and cardiology. We systematically investigate the impact of partially missing data on the different fusion strategies. Across our experiments, late and hybrid fusion techniques emerge as the methods of choice for practical applications of multimodal simulation-based infere
    
[^203]: 通过实时验证和纠正减轻大型语言模型中的虚构问题

    Ever: Mitigating Hallucination in Large Language Models through Real-Time Verification and Rectification

    [https://arxiv.org/abs/2311.09114](https://arxiv.org/abs/2311.09114)

    通过实时验证和纠正的策略，文章提出了一种名为Ever的方法，用于减轻大型语言模型生成中的虚构问题。

    

    大型语言模型(LLMs)在生成流畅文本方面表现出色。然而，它们经常遇到生成不准确或虚构内容的挑战。这个问题普遍存在于非基于检索的生成和检索增强生成方法中，现有的事后纠正方法可能无法解决“滚雪球”问题导致的累积虚构错误，特别是在推理任务中。为了解决这些挑战，我们提出了一种名为“Ever”的新方法。Ever采用实时、逐步的生成和虚构纠正策略，而不是等到生成过程结束才纠正虚构。其主要目标是在文本生成过程中检测和纠正虚构。与基于检索和非基于检索的基线模型相比，

    arXiv:2311.09114v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) have demonstrated remarkable proficiency in generating fluent text. However, they often encounter the challenge of generating inaccurate or hallucinated content. This issue is common in both non-retrieval-based generation and retrieval-augmented generation approaches, and existing post-hoc rectification methods may not address the accumulated hallucination errors that may be caused by the "snowballing" issue, especially in reasoning tasks. To tackle these challenges, we introduce a novel approach called Real-time Verification and Rectification (Ever). Instead of waiting until the end of the generation process to rectify hallucinations, Ever employs a real-time, step-wise generation and hallucination rectification strategy. The primary objective is to detect and rectify hallucinations as they occur during the text generation process. When compared to both retrieval-based and non-retrieval-based basel
    
[^204]: 朝向多步推理的答案校准统一视图

    Towards A Unified View of Answer Calibration for Multi-Step Reasoning

    [https://arxiv.org/abs/2311.09101](https://arxiv.org/abs/2311.09101)

    本文总结了最近答案校准技术的分类法，从统一视角对步级和路径级答案校准进行了彻底评估，结果显示整合两种策略的优势倾向于产生最佳结果。

    

    大型语言模型（LLMs）使用“思维链”提示扩展了改进多步推理能力的范围。我们通常将多步推理分为两个阶段：路径生成以生成推理路径；和答案校准后处理推理路径以获得最终答案。然而，现有文献缺乏对不同答案校准方法的系统分析。本文总结了最近答案校准技术的分类法，并将其分解为步级和路径级策略。然后，我们从统一视角对这些策略进行了彻底评估，系统地审查了多路径上的步级和路径级答案校准。实验结果表明，整合两种策略的优势倾向于产生最佳结果。我们的研究有可能启示优化多步推理系统的关键见解。

    arXiv:2311.09101v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) employing Chain-of-Thought (CoT) prompting have broadened the scope for improving multi-step reasoning capabilities. We generally divide multi-step reasoning into two phases: path generation to generate the reasoning path(s); and answer calibration post-processing the reasoning path(s) to obtain a final answer. However, the existing literature lacks systematic analysis on different answer calibration approaches. In this paper, we summarize the taxonomy of recent answer calibration techniques and break them down into step-level and path-level strategies. We then conduct a thorough evaluation on these strategies from a unified view, systematically scrutinizing step-level and path-level answer calibration across multiple paths. Experimental results reveal that integrating the dominance of both strategies tends to derive optimal outcomes. Our study holds the potential to illuminate key insights for opti
    
[^205]: 基于Transformer的描述逻辑语境推理

    Reasoning over Description Logic-based Contexts with Transformers

    [https://arxiv.org/abs/2311.08941](https://arxiv.org/abs/2311.08941)

    本研究构建了一个由描述逻辑知识库生成的合成自然语言问答数据集，以评估基于Transformer模型在丰富语境中的推理能力。

    

    目前，衡量基于Transformer模型的推理能力的一种方式是通过评估在自然语言表达的合成语境中对逻辑问题回答或证明生成等下游任务的准确性。然而，大多数实际使用的语境非常简单；在大多数情况下，它们是由仅含有少量逻辑运算符和量词的短一阶逻辑句子生成的。本文旨在回答基于Transformer模型能够在表达丰富语境中执行推理的问题。为此，我们构建了一个由描述逻辑知识库生成的合成自然语言问答数据集。为生成知识库，我们使用了表达式语言$\mathcal{ALCQ$。生成的数据集包含384K个示例，并且在两个维度上增加：i) 推理深度，和ii) 句子长度。

    arXiv:2311.08941v2 Announce Type: replace-cross  Abstract: One way that the current state of the art measures the reasoning ability of transformer-based models is by evaluating accuracy in downstream tasks like logical question answering or proof generation over synthetic contexts expressed in natural language. However, most of the contexts used are in practice very simple; in most cases, they are generated from short first-order logic sentences with only a few logical operators and quantifiers. In this work, we seek to answer the question how well a transformer-based model will perform reasoning over expressive contexts. For this purpose, we construct a synthetic natural language question-answering dataset, generated by description logic knowledge bases. For the generation of the knowledge bases, we use the expressive language $\mathcal{ALCQ}$. The resulting dataset contains 384K examples, and increases in two dimensions: i) reasoning depth, and ii) length of sentences. We show that t
    
[^206]: 学习的形状：基于Transformer模型的各向异性和内在维度研究

    The Shape of Learning: Anisotropy and Intrinsic Dimensions in Transformer-Based Models

    [https://arxiv.org/abs/2311.05928](https://arxiv.org/abs/2311.05928)

    本研究揭示了Transformer解码器中的各向异性呈钟状曲线，最高各向异性浓度在中间层，与编码器中更均匀分布的各向异性不同，并发现嵌入的内在维度在训练初期增加，随后在训练末期出现压缩，表明更紧凑的表示形式。

    

    在这项研究中，我们针对Transformer架构中嵌入的各向异性动态和内在维度展开调查，重点关注编码器和解码器之间的二分法。我们的研究结果显示，Transformer解码器中的各向异性配置呈现出明显的钟状曲线，具有最高的各向异性浓度在中间层。这种模式与编码器中观察到的更均匀分布的各向异性有所不同。此外，我们发现嵌入的内在维度在训练的初始阶段增加，表明向更高维空间的扩展。然后在训练末尾出现向更低维度的压缩阶段，暗示着对更紧凑表示的改进。我们的结果为理解编码器和解码器嵌入属性提供了新的见解。

    arXiv:2311.05928v2 Announce Type: replace-cross  Abstract: In this study, we present an investigation into the anisotropy dynamics and intrinsic dimension of embeddings in transformer architectures, focusing on the dichotomy between encoders and decoders. Our findings reveal that the anisotropy profile in transformer decoders exhibits a distinct bell-shaped curve, with the highest anisotropy concentrations in the middle layers. This pattern diverges from the more uniformly distributed anisotropy observed in encoders. In addition, we found that the intrinsic dimension of embeddings increases in the initial phases of training, indicating an expansion into higher-dimensional space. Which is then followed by a compression phase towards the end of training with dimensionality decrease, suggesting a refinement into more compact representations. Our results provide fresh insights to the understanding of encoders and decoders embedding properties.
    
[^207]: 无调谐的基础模型对象命名

    Tuning-less Object Naming with a Foundation Model

    [https://arxiv.org/abs/2311.04924](https://arxiv.org/abs/2311.04924)

    使用transformers的注意力机制，提出了一种无需微调模型即可进行对象命名的方法

    

    我们实现了一个实时对象命名系统，可以学习一组从未见过的命名实体。我们的方法采用了一个现有的基础模型，在开始之前我们认为它准备好接受任何内容。它将观察到的图像转换为相对较小的特征向量，我们将这些特征向量与逐渐构建的词汇表中的索引相关联，且无需对模型进行任何微调。我们的贡献在于使用了来自transformers注意力机制的关联机制。它具有支持从不相关信息中泛化以区分实体并潜在地能够与远超出词汇表索引的实体相关联的特性。因此，该系统可以以一次性方式工作，并正确地为不同上下文中命名的对象命名。我们还概述了通过黑板架构集成的系统模块的实现细节。最后，我们调查了系统的质量，主要着眼于它能够识别多少对象

    arXiv:2311.04924v2 Announce Type: replace-cross  Abstract: We implement a real-time object naming system that enables learning a set of named entities never seen. Our approach employs an existing foundation model that we consider ready to see anything before starting. It turns seen images into relatively small feature vectors that we associate with index to a gradually built vocabulary without any training of fine-tuning of the model. Our contribution is using the association mechanism known from transformers as attention. It has features that support generalization from irrelevant information for distinguishing the entities and potentially enable associating with much more than indices to vocabulary. As a result, the system can work in a one-shot manner and correctly name objects named in different contents. We also outline implementation details of the system modules integrated by a blackboard architecture. Finally, we investigate the system's quality, mainly how many objects it can 
    
[^208]: 关于利用大型语言模型进行双语词汇识别

    On Bilingual Lexicon Induction with Large Language Models

    [https://arxiv.org/abs/2310.13995](https://arxiv.org/abs/2310.13995)

    本文研究了利用大型语言模型进行双语词汇识别的潜力，通过研究零次提示和少量上下文提示等方法，探讨了这种方法如何与当前BLI方法相比，并如何进行补充。

    

    双语词汇识别（BLI）是多语言自然语言处理中的核心任务，目前在很大程度上仍然依赖于计算跨语言单词表示。受自然语言处理领域向大型语言模型（LLMs）的全球范式转变的启发，我们探讨了最新一代LLMs在双语词汇开发中的潜力。我们提出了以下研究问题：是否可能促使和微调多语言LLMs（mLLMs）以进行BLI，并且这种方法与当前BLI方法相比如何以及如何补充？为此，我们系统地研究了1）用于无监督BLI的零次提示和2）使用一组种子翻译对进行少量上下文提示，均无需进行任何LLM微调，以及3）对较小LLMs进行标准BLI导向微调。我们在涵盖不同大小（从0.3B到13B参数）的18个开源文本对文本mLLMs上进行实验，涵盖两个标准BLI基准测试。

    arXiv:2310.13995v2 Announce Type: replace-cross  Abstract: Bilingual Lexicon Induction (BLI) is a core task in multilingual NLP that still, to a large extent, relies on calculating cross-lingual word representations. Inspired by the global paradigm shift in NLP towards Large Language Models (LLMs), we examine the potential of the latest generation of LLMs for the development of bilingual lexicons. We ask the following research question: Is it possible to prompt and fine-tune multilingual LLMs (mLLMs) for BLI, and how does this approach compare against and complement current BLI approaches? To this end, we systematically study 1) zero-shot prompting for unsupervised BLI and 2) few-shot in-context prompting with a set of seed translation pairs, both without any LLM fine-tuning, as well as 3) standard BLI-oriented fine-tuning of smaller LLMs. We experiment with 18 open-source text-to-text mLLMs of different sizes (from 0.3B to 13B parameters) on two standard BLI benchmarks covering a rang
    
[^209]: 质量感知翻译模型：单一模型中的高效生成和质量评估

    Quality-Aware Translation Models: Efficient Generation and Quality Estimation in a Single Model

    [https://arxiv.org/abs/2310.06707](https://arxiv.org/abs/2310.06707)

    提出了一种质量感知翻译模型，通过训练NMT模型来估计其输出质量，可以在解码过程中消除额外的计算成本。

    

    最大后验（MAP）解码是神经机器翻译（NMT）模型中最广泛使用的解码策略。 研究表明，模型概率与人类判断相关，但不能总是成立，生成质量可以通过解码来优化一个以度量或质量评估信号支持的效用函数来提高，即最小贝叶斯风险（MBR）或质量感知解码。 这些方法的主要缺点在于它们需要一个额外的模型在解码过程中计算效用函数，会显著增加计算成本。 本文提出通过训练NMT模型自己来估计其输出质量，从而使NMT模型本身具备质量感知能力。 使用这种方法进行MBR解码可以显著减小尺寸。

    arXiv:2310.06707v2 Announce Type: replace-cross  Abstract: Maximum-a-posteriori (MAP) decoding is the most widely used decoding strategy for neural machine translation (NMT) models. The underlying assumption is that model probability correlates well with human judgment, with better translations getting assigned a higher score by the model. However, research has shown that this assumption does not always hold, and generation quality can be improved by decoding to optimize a utility function backed by a metric or quality-estimation signal, as is done by Minimum Bayes Risk (MBR) or Quality-Aware decoding. The main disadvantage of these approaches is that they require an additional model to calculate the utility function during decoding, significantly increasing the computational cost. In this paper, we propose to make the NMT models themselves quality-aware by training them to estimate the quality of their own output. Using this approach for MBR decoding we can drastically reduce the size
    
[^210]: 让循环的询问: 大型语言模型在判断中的摇摆

    Ask Again, Then Fail: Large Language Models' Vacillations in Judgement

    [https://arxiv.org/abs/2310.02174](https://arxiv.org/abs/2310.02174)

    目前的语言模型在面对后续问题时常常摇摆不定，研究者提出了一个后续问题机制和两个度量标准来量化这种不一致性，并开发出Unwavering-FQ框架来教导模型保持最初的正确判断，实验证明其有效性。

    

    我们观察到目前的会话式语言模型在面对后续问题时往往在其判断上摇摆不定，即使原始判断是正确的。这种摇摆对于生成可靠回复和建立用户信任构成了重要挑战。为了全面评估这一问题，我们引入了一个后续问题机制以及两个度量标准来量化这种不一致性，确认了当前语言模型普遍存在这种情况。为了缓解这一问题，我们探讨了各种提示策略用于闭源模型；此外，我们开发了一个基于训练的框架Unwavering-FQ，通过合成高质量的偏好数据来教导语言模型保持其最初的正确判断。我们的实验结果验证了我们框架的有效性以及其增强模型通用能力的能力。

    arXiv:2310.02174v2 Announce Type: replace-cross  Abstract: We observe that current conversational language models often waver in their judgements when faced with follow-up questions, even if the original judgement was correct. This wavering presents a significant challenge for generating reliable responses and building user trust. To comprehensively assess this issue, we introduce a Follow-up Questioning Mechanism along with two metrics to quantify this inconsistency, confirming its widespread presence in current language models. To mitigate this issue, we explore various prompting strategies for closed-source models; moreover, we develop a training-based framework Unwavering-FQ that teaches language models to maintain their originally correct judgements through synthesized high-quality preference data. Our experimental results confirm the effectiveness of our framework and its ability to enhance the general capabilities of models (https://github.com/NUSTM/LLMs-Waver-In-Judgements).
    
[^211]: 探索LLM代理的协作机制：社会心理学视角

    Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology View

    [https://arxiv.org/abs/2310.02124](https://arxiv.org/abs/2310.02124)

    通过实践实验和理论洞察，探究当代NLP系统之间的协作机制，发现某些协作策略优于先前的方法，并且优化了效率。

    

    随着自然语言处理（NLP）系统越来越多地应用于复杂的社会环境中，一个迫切的问题出现了：这些NLP系统能否模仿类人类的协作智能，在由多个大型语言模型（LLMs）组成的多代理社会中？本文通过将实践实验与理论观点相结合，探究当代NLP系统之间的协作机制。我们构建了四个由LLM代理组成的独特“社会”，每个代理以特定的“特质”（随和或过于自信）为特征，并与不同的“思维模式”（辩论或反思）展开协作。通过在三个基准数据集上评估这些多代理社会，我们发现某些协作策略不仅胜过先前顶尖方法，而且优化了效率（使用更少的API令牌）。此外，我们的结果进一步说明LLM代理可以

    arXiv:2310.02124v2 Announce Type: replace-cross  Abstract: As Natural Language Processing (NLP) systems are increasingly employed in intricate social environments, a pressing query emerges: Can these NLP systems mirror human-esque collaborative intelligence, in a multi-agent society consisting of multiple large language models (LLMs)? This paper probes the collaboration mechanisms among contemporary NLP systems by melding practical experiments with theoretical insights. We fabricate four unique `societies' comprised of LLM agents, where each agent is characterized by a specific `trait' (easy-going or overconfident) and engages in collaboration with a distinct `thinking pattern' (debate or reflection). Through evaluating these multi-agent societies on three benchmark datasets, we discern that certain collaborative strategies not only outshine previous top-tier approaches, but also optimize efficiency (using fewer API tokens). Moreover, our results further illustrate that LLM agents mani
    
[^212]: 在图上推理：忠实且可解释的大型语言模型推理

    Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning

    [https://arxiv.org/abs/2310.01061](https://arxiv.org/abs/2310.01061)

    提出了一种名为图推理（RoG）的新方法，通过将LLMs与KGs协同工作，实现忠实且可解释的大型语言模型推理。

    

    大型语言模型（LLMs）在复杂任务中展示了令人印象深刻的推理能力。然而，在推理过程中它们缺乏最新知识，经历幻觉，这可能导致不正确的推理过程，并降低其性能和可信度。知识图（KGs）以结构化格式捕获了大量事实，为推理提供了可靠的知识来源。然而，现有基于KG的LLM推理方法只将KGs视为事实知识库，忽视其结构信息对推理的重要性。本文提出了一种称为图推理（RoG）的新方法，通过使LLMs与KGs协同工作，实现忠实且可解释的推理。具体而言，我们提出了一个规划-检索-推理的框架，其中RoG首先生成由KGs作为忠实计划的关系路径。这些计划然后用于检索有效的推理过程。

    arXiv:2310.01061v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) have demonstrated impressive reasoning abilities in complex tasks. However, they lack up-to-date knowledge and experience hallucinations during reasoning, which can lead to incorrect reasoning processes and diminish their performance and trustworthiness. Knowledge graphs (KGs), which capture vast amounts of facts in a structured format, offer a reliable source of knowledge for reasoning. Nevertheless, existing KG-based LLM reasoning methods only treat KGs as factual knowledge bases and overlook the importance of their structural information for reasoning. In this paper, we propose a novel method called reasoning on graphs (RoG) that synergizes LLMs with KGs to enable faithful and interpretable reasoning. Specifically, we present a planning-retrieval-reasoning framework, where RoG first generates relation paths grounded by KGs as faithful plans. These plans are then used to retrieve valid reasoning p
    
[^213]: 图像到图像翻译的深度强化学习

    Deep Reinforcement Learning for Image-to-Image Translation

    [https://arxiv.org/abs/2309.13672](https://arxiv.org/abs/2309.13672)

    该论文提出了一种基于深度强化学习的图像到图像翻译方法，通过将翻译过程分解为小步骤并引入元策略和Plan概念，能够有效处理高维连续状态和动作空间的挑战。

    

    大多数现有的图像到图像翻译方法通过深度学习模型的一次运行生成图像。然而，设计这样的单步模型始终具有挑战性，需要大量的参数，并容易陷入坏的全局最小值和过拟合。在本工作中，我们将图像到图像翻译重新定义为逐步的决策问题，通过深度强化学习提出了一种新的框架，进行基于强化学习的图像到图像翻译（RL-I2IT）。RL-I2IT框架的关键特点是将一个单体学习过程分解为小的步骤，并引入一个轻量级模型，逐步将源图像转化为目标图像。考虑到在传统的强化学习框架下处理高维连续状态和动作空间的挑战，我们引入了元策略和一个新的概念Plan到标准的Actor-Critic模型中，该概念的维度较原始图像低，并且可以帮助演员生成可处理的高维表示。

    Most existing Image-to-Image Translation (I2IT) methods generate images in a single run of a deep learning (DL) model. However, designing such a single-step model is always challenging, requiring a huge number of parameters and easily falling into bad global minimums and overfitting. In this work, we reformulate I2IT as a step-wise decision-making problem via deep reinforcement learning (DRL) and propose a novel framework that performs RL-based I2IT (RL-I2IT). The key feature in the RL-I2IT framework is to decompose a monolithic learning process into small steps with a lightweight model to progressively transform a source image successively to a target image. Considering that it is challenging to handle high dimensional continuous state and action spaces in the conventional RL framework, we introduce meta policy with a new concept Plan to the standard Actor-Critic model, which is of a lower dimension than the original image and can facilitate the actor to generate a tractable high dime
    
[^214]: RecMind：大型语言模型驱动的推荐代理

    RecMind: Large Language Model Powered Agent For Recommendation

    [https://arxiv.org/abs/2308.14296](https://arxiv.org/abs/2308.14296)

    RecMind是一种LLM驱动的自主推荐代理，通过Self-Inspiring算法提高了规划能力，能够为零-shot个性化推荐提供支持。

    

    推荐系统（RS）通过深度学习取得了显著进展，但当前RS方法通常在特定任务数据集上训练和微调模型，限制了它们对新推荐任务的泛化能力以及利用外部知识的能力，因为模型规模和数据大小的限制。因此，我们设计了一种LLM驱动的自主推荐代理RecMind，能够利用外部知识，利用谨慎规划的工具为零-shot个性化推荐提供支持。我们提出了一种Self-Inspiring算法来提高规划能力。在每个中间步骤，LLM自我激励以考虑所有先前探索过的状态来规划下一步。这一机制极大地提高了模型理解和利用历史信息规划推荐的能力。我们评估了RecMind在各种推荐场景中的性能。

    arXiv:2308.14296v2 Announce Type: replace-cross  Abstract: While the recommendation system (RS) has advanced significantly through deep learning, current RS approaches usually train and fine-tune models on task-specific datasets, limiting their generalizability to new recommendation tasks and their ability to leverage external knowledge due to model scale and data size constraints. Thus, we designed an LLM-powered autonomous recommender agent, RecMind, which is capable of leveraging external knowledge, utilizing tools with careful planning to provide zero-shot personalized recommendations. We propose a Self-Inspiring algorithm to improve the planning ability. At each intermediate step, the LLM self-inspires to consider all previously explored states to plan for the next step. This mechanism greatly improves the model's ability to comprehend and utilize historical information in planning for recommendation. We evaluate RecMind's performance in various recommendation scenarios. Our exper
    
[^215]: 利用深度迁移学习改进贻贝养殖自动化中的浮标检测

    Improving Buoy Detection with Deep Transfer Learning for Mussel Farm Automation

    [https://arxiv.org/abs/2308.09238](https://arxiv.org/abs/2308.09238)

    该研究利用深度学习技术提升贻贝养殖中浮标检测的准确性和稳健性，以应用于智能贻贝养殖监测和管理。

    

    新西兰水产养殖部门正在迅速扩张，特别强调贻贝出口。随着贻贝养殖运营需求不断发展，整合人工智能和计算机视觉技术（如智能目标检测）成为提高运营效率的有效途径。本研究深入探讨利用深度学习方法提升浮标检测，用于智能贻贝养殖监测和管理。主要目标在于提高在各种真实场景下浮标检测的准确性和稳健性。利用从贻贝养殖场获取的多样化数据集进行训练和标记，包括从浮动平台和巡航船上安装的摄像头拍摄的图像，捕捉各种光照和天气条件。为建立有效的深度学习模型进行浮标检测...

    arXiv:2308.09238v2 Announce Type: replace-cross  Abstract: The aquaculture sector in New Zealand is experiencing rapid expansion, with a particular emphasis on mussel exports. As the demands of mussel farming operations continue to evolve, the integration of artificial intelligence and computer vision techniques, such as intelligent object detection, is emerging as an effective approach to enhance operational efficiency. This study delves into advancing buoy detection by leveraging deep learning methodologies for intelligent mussel farm monitoring and management. The primary objective centers on improving accuracy and robustness in detecting buoys across a spectrum of real-world scenarios. A diverse dataset sourced from mussel farms is captured and labeled for training, encompassing imagery taken from cameras mounted on both floating platforms and traversing vessels, capturing various lighting and weather conditions. To establish an effective deep learning model for buoy detection with
    
[^216]: 通过语义匹配修复特征归因方法中的确认偏见

    Fixing confirmation bias in feature attribution methods via semantic match

    [https://arxiv.org/abs/2307.00897](https://arxiv.org/abs/2307.00897)

    提出了通过语义匹配修复特征归因方法中的确认偏见问题，引入了人类概念与（亚符号）解释之间的概念框架，并提出了一种结构化方法来评估语义匹配。

    

    特征归因方法已经成为解析黑盒模型复杂行为的重要方法。尽管取得了成功，一些学者指出这类方法存在严重缺陷：它们不能可靠地用人类概念进行解释。简而言之，仅仅可视化一系列特征贡献对于人类来说无法得出关于模型内部表示的结论，而确认偏见可能会让用户产生关于模型行为的错误信念。我们认为需要一种结构化方法来验证我们对模型的假设是否得到了特征归因的确认。这就是我们所说的人类概念与（亚符号）解释之间的“语义匹配”。在 Cin\`a等人[2023]提出的概念框架基础上，我们提出了一种结构化方法来在实践中评估语义匹配。我们在一系列实验中展示了这一过程。

    arXiv:2307.00897v2 Announce Type: replace-cross  Abstract: Feature attribution methods have become a staple method to disentangle the complex behavior of black box models. Despite their success, some scholars have argued that such methods suffer from a serious flaw: they do not allow a reliable interpretation in terms of human concepts. Simply put, visualizing an array of feature contributions is not enough for humans to conclude something about a model's internal representations, and confirmation bias can trick users into false beliefs about model behavior. We argue that a structured approach is required to test whether our hypotheses on the model are confirmed by the feature attributions. This is what we call the "semantic match" between human concepts and (sub-symbolic) explanations. Building on the conceptual framework put forward in Cin\`a et al. [2023], we propose a structured approach to evaluate semantic match in practice. We showcase the procedure in a suite of experiments spa
    
[^217]: 大型语言模型的盲点：超叙事语言信息

    A blind spot for large language models: Supradiegetic linguistic information

    [https://arxiv.org/abs/2306.06794](https://arxiv.org/abs/2306.06794)

    大型语言模型的盲点在于其对超叙事语言信息的忽视，研究提出考虑模型如何感知语言信息有助于深入了解其能力。

    

    像ChatGPT这样的大型语言模型(LLMs)反映了人工智能领域的深刻变革，实现了令人印象深刻甚至令人震惊的类人语言流利度。它们目前和潜在的能力范围是一个积极探讨的领域，绝非仅限于科研人员。人们通常将LLMs的训练数据框定为“文本”甚至“语言”。我们使用来自语言学、体现认知、认知科学、数学和历史等领域的思想，仔细审视这一框架的细节。我们提出，考虑像ChatGPT这样的LLM是什么感觉，正如纳格尔可能会说的那样，可以帮助我们深入了解其整体能力，特别是，其接受的语言训练数据可以被有益地重新构思为对语言中编码的叙事信息的接触，其缺陷可以被重新构思为对这些信息的无知。

    arXiv:2306.06794v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) like ChatGPT reflect profound changes in the field of Artificial Intelligence, achieving a linguistic fluency that is impressively, even shockingly, human-like. The extent of their current and potential capabilities is an active area of investigation by no means limited to scientific researchers. It is common for people to frame the training data for LLMs as "text" or even "language". We examine the details of this framing using ideas from several areas, including linguistics, embodied cognition, cognitive science, mathematics, and history. We propose that considering what it is like to be an LLM like ChatGPT, as Nagel might have put it, can help us gain insight into its capabilities in general, and in particular, that its exposure to linguistic training data can be productively reframed as exposure to the diegetic information encoded in language, and its deficits can be reframed as ignorance of ext
    
[^218]: 使用条件样本学习隐马尔可夫模型

    Learning Hidden Markov Models Using Conditional Samples

    [https://arxiv.org/abs/2302.14753](https://arxiv.org/abs/2302.14753)

    本文提出了一种使用交互方式访问隐马尔可夫模型的条件分布样本的学习方法，实现了对HMM的高效学习算法，从而绕过了其密码学困难性。

    

    本文关注学习隐马尔可夫模型（HMM）的计算复杂性。虽然HMM是顺序和时间序列建模中最广泛使用的工具之一，但在标准设置下，即对观测序列的独立同分布（i.i.d.）样本具有访问权限的情况下，学习起来是具有密码学困难性的。本文偏离了这一设定，考虑了一种交互访问模型，在这种模型中，算法可以查询HMM的条件分布的样本。我们展示了对HMM的交互访问可以实现计算高效的学习算法，从而绕过密码学困难性。具体来说，我们设计了在两种情况下学习HMM的高效算法：（a）一种更容易的设置，我们可以查询准确条件概率。在这里，我们的算法在多项式时间内运行，并进行了多项式次查询，以在总变差距离中近似任何HMM。

    arXiv:2302.14753v2 Announce Type: replace-cross  Abstract: This paper is concerned with the computational complexity of learning the Hidden Markov Model (HMM). Although HMMs are some of the most widely used tools in sequential and time series modeling, they are cryptographically hard to learn in the standard setting where one has access to i.i.d. samples of observation sequences. In this paper, we depart from this setup and consider an interactive access model, in which the algorithm can query for samples from the conditional distributions of the HMMs. We show that interactive access to the HMM enables computationally efficient learning algorithms, thereby bypassing cryptographic hardness. Specifically, we obtain efficient algorithms for learning HMMs in two settings:   (a) An easier setting where we have query access to the exact conditional probabilities. Here our algorithm runs in polynomial time and makes polynomially many queries to approximate any HMM in total variation distance.
    
[^219]: 盲目超分辨率和裂缝分割的联合学习，用于逼真残缺图像

    Joint Learning of Blind Super-Resolution and Crack Segmentation for Realistic Degraded Images

    [https://arxiv.org/abs/2302.12491](https://arxiv.org/abs/2302.12491)

    通过联合学习盲目超分辨率和裂缝分割，在深度神经网络的支持下，提出的方法能有效优化分割结果，并针对现实场景中的未知模糊对低分辨率图像进行处理。

    

    本文提出了一种由深度神经网络增强的裂缝分割方法，通过超分辨率（SR）进行增强。在所提出的方法中，SR网络与二值分割网络联合进行端到端训练。这种联合学习使得SR网络能够被优化以改善分割结果。针对现实场景，SR网络从非盲目扩展到盲目处理由未知模糊引起的低分辨率图像。通过我们提出的两个额外路径进一步鼓励SR和分割之间的相互优化，改进了联合网络。与现有技术（SoTA）分割方法的比较实验表明我们联合学习的优越性，各种消融研究证明了我们贡献的效果。

    arXiv:2302.12491v3 Announce Type: replace-cross  Abstract: This paper proposes crack segmentation augmented by super resolution (SR) with deep neural networks. In the proposed method, a SR network is jointly trained with a binary segmentation network in an end-to-end manner. This joint learning allows the SR network to be optimized for improving segmentation results. For realistic scenarios, the SR network is extended from non-blind to blind for processing a low-resolution image degraded by unknown blurs. The joint network is improved by our proposed two extra paths that further encourage the mutual optimization between SR and segmentation. Comparative experiments with State of The Art (SoTA) segmentation methods demonstrate the superiority of our joint learning, and various ablation studies prove the effects of our contributions.
    
[^220]: 不偏不倚：少数族群指导扩散模型

    Don't Play Favorites: Minority Guidance for Diffusion Models

    [https://arxiv.org/abs/2301.12334](https://arxiv.org/abs/2301.12334)

    本研究提出了一个可以使扩散模型生成过程专注于少数样本的新颖框架。

    

    我们探讨使用扩散模型生成少数样本的问题。少数样本是位于数据流形低密度区域的实例。生成足够数量的这种少数样本很重要，因为它们通常包含数据的一些独特属性。然而，由于高似然性，扩散模型的传统生成过程主要产生大多数样本（位于流形高密度区域），使自身对少数生成任务无效且耗时。本研究提出了一个新颖的框架，可以使扩散模型的生成过程专注于少数样本。首先强调 Tweedie 的降噪公式对大多数样本产生有利结果。这一观察激励我们引入描述给定样本独特性的度量。为了解决扩散模型固有的偏好，我们...

    arXiv:2301.12334v2 Announce Type: replace-cross  Abstract: We explore the problem of generating minority samples using diffusion models. The minority samples are instances that lie on low-density regions of a data manifold. Generating a sufficient number of such minority instances is important, since they often contain some unique attributes of the data. However, the conventional generation process of the diffusion models mostly yields majority samples (that lie on high-density regions of the manifold) due to their high likelihoods, making themselves ineffective and time-consuming for the minority generating task. In this work, we present a novel framework that can make the generation process of the diffusion models focus on the minority samples. We first highlight that Tweedie's denoising formula yields favorable results for majority samples. The observation motivates us to introduce a metric that describes the uniqueness of a given sample. To address the inherent preference of the di
    
[^221]: AI监管的闭环视角：在重复互动中产生均等影响

    Closed-Loop View of the Regulation of AI: Equal Impact across Repeated Interactions

    [https://arxiv.org/abs/2209.01410](https://arxiv.org/abs/2209.01410)

    论文提出了基于民权立法的AI监管闭环视角，强调在重复互动中产生的均等影响。

    

    近来对AI监管引起了广泛关注。我们主张基于民权立法的视角，建立在平等对待和平等影响的概念之上。在AI系统及其用户的闭环视角中，平等对待关注一次循环。在我们看来，平等影响关注在重复互动中的长期平均行为。为了确定平均值的存在及其属性，需要研究闭环的遍历性质及其独特的静止测度。

    arXiv:2209.01410v2 Announce Type: replace  Abstract: There has been much recent interest in the regulation of AI. We argue for a view based on civil-rights legislation, built on the notions of equal treatment and equal impact. In a closed-loop view of the AI system and its users, the equal treatment concerns one pass through the loop. Equal impact, in our view, concerns the long-run average behaviour across repeated interactions. In order to establish the existence of the average and its properties, one needs to study the ergodic properties of the closed-loop and its unique stationary measure.
    
[^222]: 信息论上的熵多边际最优输运等价性：多智能体通信理论

    Information-Theoretic Equivalence of Entropic Multi-Marginal Optimal Transport: A Theory for Multi-Agent Communication

    [https://arxiv.org/abs/2208.10256](https://arxiv.org/abs/2208.10256)

    本文提出了关于熵多边际最优输运的信息论等效性，将其推广到多智能体通信领域，证明了熵最优输运在信息论上的最优性，并为未来多智能体团队系统中的OT理论提供了启示。

    

    本文提出了我们关于熵多边际最优输运（MOT）的信息论等效性。该等效性可以轻松归约到熵最优输运（OT）的情况。由于OT被广泛用于比较知识或信念之间的差异，我们将这一结果应用于具有不同信念的智能体之间的通信。我们的结果正式证明了王等人在[2020]中提出的关于熵OT在信息论上的最优性，并将其推广到多智能体情况。我们相信我们的工作可以为未来的多智能体团队系统中的OT理论提供启示。

    arXiv:2208.10256v3 Announce Type: replace-cross  Abstract: In this paper, we propose our information-theoretic equivalence of entropic multi-marginal optimal transport (MOT). This equivalence can be easily reduced to the case of entropic optimal transport (OT). Because OT is widely used to compare differences between knowledge or beliefs, we apply this result to the communication between agents with different beliefs. Our results formally prove the statement that entropic OT is information-theoretically optimal given by Wang et al. [2020] and generalize it to the multi-agent case. We believe that our work can shed light on OT theory in future multi-agent teaming systems.
    
[^223]: 从内在动机到占据行动-状态路径空间的复杂行为

    Complex behavior from intrinsic motivation to occupy action-state path space

    [https://arxiv.org/abs/2205.10316](https://arxiv.org/abs/2205.10316)

    行为的目标是最大化未来行动和状态路径的占用，根据最大占用原则，奖励是占用路径空间的手段，而不是目标本身，并提供了与最优策略和状态值函数相关的解析表达式，证明了值迭代算法的收敛性

    

    大多数行为理论认为，代理人倾向于最大化某种形式的奖励或效用。然而，动物经常出于好奇心移动，并且似乎在没有奖励的情况下受到激励。在这里，我们放弃了奖励最大化的概念，提出行为的目标是最大化未来行动和状态路径的占用。根据最大占用原则，奖励是占用路径空间的手段，而不是目标本身；目标导向性简单地作为搜索资源的理性方式而出现，以使运动从广义上理解永不结束。我们发现，行动-状态路径熵是唯一与可加性和其他直观的预期未来行动-状态路径占用性质一致的度量。我们提供了关于最优策略和状态值函数的解析表达式，并证明了我们的值迭代算法的收敛性。使用离散和连续状态任务，包括一个高

    arXiv:2205.10316v2 Announce Type: replace  Abstract: Most theories of behavior posit that agents tend to maximize some form of reward or utility. However, animals very often move with curiosity and seem to be motivated in a reward-free manner. Here we abandon the idea of reward maximization, and propose that the goal of behavior is maximizing occupancy of future paths of actions and states. According to this maximum occupancy principle, rewards are the means to occupy path space, not the goal per se; goal-directedness simply emerges as rational ways of searching for resources so that movement, understood amply, never ends. We find that action-state path entropy is the only measure consistent with additivity and other intuitive properties of expected future action-state path occupancy. We provide analytical expressions that relate the optimal policy and state-value function, and prove convergence of our value iteration algorithm. Using discrete and continuous state tasks, including a hi
    
[^224]: 无需机器人的机器人训练：深度模仿学习用于主到机器人策略转移

    Training Robots without Robots: Deep Imitation Learning for Master-to-Robot Policy Transfer

    [https://arxiv.org/abs/2202.09574](https://arxiv.org/abs/2202.09574)

    该研究提出了一种新的主到机器人策略转移系统，在无需机器人参与的情况下进行力反馈操作任务的深度模仿学习，使操作者通过控制器进行直接演示并感受力反馈。

    

    深度模仿学习对于机器人操纵是很有前景的，因为它只需演示样本。本研究将深度模仿学习应用于需要力反馈的任务。然而，现有的演示方法存在缺陷；双向远程操作需要复杂的控制方案并且成本高昂，而动态示范可能会因为人类介入而受到视觉干扰。本研究提出了一种新的主到机器人(M2R)策略转移系统，不需要机器人来教授基于力反馈的操作任务。人直接使用控制器演示一个任务。这个控制器类似于机器人臂的运动参数，并且使用相同的末端执行器和力/扭矩(F/T)传感器来测量力反馈。使用这个控制器，操作者可以感受到力反馈而无需双向系统。该方法可以克服主体之间的领域差距。

    arXiv:2202.09574v2 Announce Type: replace-cross  Abstract: Deep imitation learning is promising for robot manipulation because it only requires demonstration samples. In this study, deep imitation learning is applied to tasks that require force feedback. However, existing demonstration methods have deficiencies; bilateral teleoperation requires a complex control scheme and is expensive, and kinesthetic teaching suffers from visual distractions from human intervention. This research proposes a new master-to-robot (M2R) policy transfer system that does not require robots for teaching force feedback-based manipulation tasks. The human directly demonstrates a task using a controller. This controller resembles the kinematic parameters of the robot arm and uses the same end-effector with force/torque (F/T) sensors to measure the force feedback. Using this controller, the operator can feel force feedback without a bilateral system. The proposed method can overcome domain gaps between the mast
    
[^225]: 基于Transformer的双臂机器人操作的深度模仿学习

    Transformer-based deep imitation learning for dual-arm robot manipulation

    [https://arxiv.org/abs/2108.00385](https://arxiv.org/abs/2108.00385)

    使用Transformer的深度模仿学习结构成功解决了双臂机器人操作任务中神经网络性能不佳的问题

    

    深度模仿学习对解决熟练操作任务具有潜力，因为它不需要环境模型和预编程的机器人行为。然而，将其应用于双臂操作任务仍具有挑战性。在双臂操作设置中，由于附加机器人操作器引起的状态维度增加，导致了神经网络性能不佳。我们通过使用一种自注意力机制来解决这个问题，该机制计算顺序输入中元素之间的依赖关系，并专注于重要元素。Transformer，作为自注意力架构的一种变体，被应用于深度模仿学习中，以解决真实世界中的双臂操作任务。所提出的方法已在真实机器人上的双臂操作任务上进行了测试。实验结果表明，基于Transformer的深度模仿学习架构可以进行关注

    arXiv:2108.00385v2 Announce Type: replace-cross  Abstract: Deep imitation learning is promising for solving dexterous manipulation tasks because it does not require an environment model and pre-programmed robot behavior. However, its application to dual-arm manipulation tasks remains challenging. In a dual-arm manipulation setup, the increased number of state dimensions caused by the additional robot manipulators causes distractions and results in poor performance of the neural networks. We address this issue using a self-attention mechanism that computes dependencies between elements in a sequential input and focuses on important elements. A Transformer, a variant of self-attention architecture, is applied to deep imitation learning to solve dual-arm manipulation tasks in the real world. The proposed method has been tested on dual-arm manipulation tasks using a real robot. The experimental results demonstrated that the Transformer-based deep imitation learning architecture can attend 
    
[^226]: 基于凝视的双分辨率深度模仿学习用于高精度灵巧机器人操作

    Gaze-based dual resolution deep imitation learning for high-precision dexterous robot manipulation

    [https://arxiv.org/abs/2102.01295](https://arxiv.org/abs/2102.01295)

    基于人类基于凝视的双分辨率视觉运动控制系统的启发，提出了一种利用深度模仿学习解决高精度灵巧机器人操作任务的方法

    

    一个高精度操纵任务，如穿针引线，是具有挑战性的。生理学研究提出了将低分辨率外围视觉和快速移动连接起来，将手传送到对象的附近，并使用高分辨率的凹陷视觉来实现手精确对准对象。本研究结果表明，受人类基于凝视的双分辨率视觉运动控制系统的启发，基于深度模仿学习的方法可以解决穿针引线任务。首先，我们记录了远程操作机器人的人类操作员的凝视运动。然后，在靠近目标时，我们仅使用围绕凝视点的高分辨率图像来精确控制线的位置。我们使用低分辨率的外围图像到达目标附近。本研究获得的实验结果表明，所提出的方法实现了精准的操纵

    arXiv:2102.01295v3 Announce Type: replace-cross  Abstract: A high-precision manipulation task, such as needle threading, is challenging. Physiological studies have proposed connecting low-resolution peripheral vision and fast movement to transport the hand into the vicinity of an object, and using high-resolution foveated vision to achieve the accurate homing of the hand to the object. The results of this study demonstrate that a deep imitation learning based method, inspired by the gaze-based dual resolution visuomotor control system in humans, can solve the needle threading task. First, we recorded the gaze movements of a human operator who was teleoperating a robot. Then, we used only a high-resolution image around the gaze to precisely control the thread position when it was close to the target. We used a low-resolution peripheral image to reach the vicinity of the target. The experimental results obtained in this study demonstrate that the proposed method enables precise manipulat
    
[^227]: SelectLLM：LLMs能否选择重要的指令进行注释？

    SelectLLM: Can LLMs Select Important Instructions to Annotate?. (arXiv:2401.16553v1 [cs.CL])

    [http://arxiv.org/abs/2401.16553](http://arxiv.org/abs/2401.16553)

    这项工作提出了一种名为SelectLLM的新方法，利用LLMs选择高质量指令。通过提示LLMs估计每个无标签指令的有用性和影响力，并使用聚类算法将指令分为多个聚类。

    

    使用大量且多样化的指令数据集训练大型语言模型(LLMs)可以使模型理解和遵循人类指令。最近的研究表明，使用一小组高质量的指令可以超过使用大量更嘈杂的指令。由于指令是无标签的，且响应是自然文本，传统的主动学习方案无法直接应用于选择无标签指令。在这项工作中，我们提出了一种新的指令选择方法，称为SelectLLM，它利用LLMs选择高质量指令。我们的高级思想是利用LLMs通过提示来估计每个指令在没有相应标签（即响应）的情况下的有用性和影响力。SelectLLM包括两个步骤：使用聚类算法（例如CoreSet）将无标签指令划分为多个聚类，然后提示LLMs在其中选择高质量指令。

    Training large language models (LLMs) with a large and diverse instruction dataset aligns the models to comprehend and follow human instructions. Recent works have shown that using a small set of high-quality instructions can outperform using large yet more noisy ones. Because instructions are unlabeled and their responses are natural text, traditional active learning schemes with the model's confidence cannot be directly applied to the selection of unlabeled instructions. In this work, we propose a novel method for instruction selection, called SelectLLM, that leverages LLMs for the selection of high-quality instructions. Our high-level idea is to use LLMs to estimate the usefulness and impactfulness of each instruction without the corresponding labels (i.e., responses), via prompting. SelectLLM involves two steps: dividing the unlabelled instructions using a clustering algorithm (e.g., CoreSet) to multiple clusters, and then prompting LLMs to choose high-quality instructions within e
    
[^228]: Airavata: 引入针对印地语指令调整的LLM

    Airavata: Introducing Hindi Instruction-tuned LLM. (arXiv:2401.15006v1 [cs.CL])

    [http://arxiv.org/abs/2401.15006](http://arxiv.org/abs/2401.15006)

    "Airavata"是一个针对印地语进行指令调整的LLM，通过微调OpenHathi和IndicInstruct数据集，提供更好的协助任务性能，并计划扩展到所有22种计划Indic语言。

    

    我们宣布首次发布了"Airavata"，这是一个针对印地语进行指令调整的LLM。通过将OpenHathi与各种指令调整的印地语数据集进行微调，Airavata更适合辅助任务。除了模型外，我们还分享了IndicInstruct数据集，这是一组用于进一步研究Indic LLM的多样化指令调整数据集。此外，我们还提供了评估基准和评估框架，以评估LLM在印地语任务中的性能。目前，Airavata支持印地语，但我们计划将其扩展到所有22种计划Indic语言。您可以在https://ai4bharat.github.io/airavata上访问所有工件。

    We announce the initial release of "Airavata," an instruction-tuned LLM for Hindi. Airavata was created by fine-tuning OpenHathi with diverse, instruction-tuning Hindi datasets to make it better suited for assistive tasks. Along with the model, we also share the IndicInstruct dataset, which is a collection of diverse instruction-tuning datasets to enable further research for Indic LLMs. Additionally, we present evaluation benchmarks and a framework for assessing LLM performance across tasks in Hindi. Currently, Airavata supports Hindi, but we plan to expand this to all 22 scheduled Indic languages. You can access all artifacts at https://ai4bharat.github.io/airavata.
    
[^229]: 基于能量的概念瓶颈模型：统一预测、概念干预和条件解释

    Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Conditional Interpretations. (arXiv:2401.14142v1 [cs.CV])

    [http://arxiv.org/abs/2401.14142](http://arxiv.org/abs/2401.14142)

    基于能量的概念瓶颈模型统一了预测、概念干预和条件解释的功能，解决了现有方法在高阶非线性相互作用和复杂条件依赖关系上的限制。

    

    现有方法，如概念瓶颈模型 (CBM)，在为黑盒深度学习模型提供基于概念的解释方面取得了成功。它们通常通过在给定输入的情况下预测概念，然后在给定预测的概念的情况下预测最终的类别标签。然而，它们经常无法捕捉到概念之间的高阶非线性相互作用，例如纠正一个预测的概念（例如“黄色胸部”）无法帮助纠正高度相关的概念（例如“黄色腹部”），导致最终准确率不理想；它们无法自然地量化不同概念和类别标签之间的复杂条件依赖关系（例如对于一个带有类别标签“Kentucky Warbler”和概念“黑色嘴巴”的图像，模型能够正确预测另一个概念“黑色冠”的概率是多少），因此无法提供关于黑盒模型工作原理更深层次的洞察。针对这些限制，我们提出了基于能量的概念瓶颈模型（Energy-based Concept Bottleneck Models）。

    Existing methods, such as concept bottleneck models (CBMs), have been successful in providing concept-based interpretations for black-box deep learning models. They typically work by predicting concepts given the input and then predicting the final class label given the predicted concepts. However, (1) they often fail to capture the high-order, nonlinear interaction between concepts, e.g., correcting a predicted concept (e.g., "yellow breast") does not help correct highly correlated concepts (e.g., "yellow belly"), leading to suboptimal final accuracy; (2) they cannot naturally quantify the complex conditional dependencies between different concepts and class labels (e.g., for an image with the class label "Kentucky Warbler" and a concept "black bill", what is the probability that the model correctly predicts another concept "black crown"), therefore failing to provide deeper insight into how a black-box model works. In response to these limitations, we propose Energy-based Concept Bot
    
[^230]: 通过具有分层正则化的医学代码中心的多模态对比EHR建模预测下次就诊诊断

    Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal Contrastive EHR Modelling with Hierarchical Regularisation. (arXiv:2401.11648v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.11648](http://arxiv.org/abs/2401.11648)

    通过医学代码中心的多模态对比EHR建模预测下次就诊诊断，并通过分层正则化提高性能。

    

    在医疗保健中，利用电子健康记录（EHR）预测下次就诊的诊断是一项必要的任务，对于制定医疗保健提供者和患者的主动未来计划至关重要。然而，之前的许多研究并没有充分解决EHR数据固有的异构和分层特征，必然导致次优的性能。为此，我们提出了NECHO，一种新颖的医学代码中心的多模态对比EHR学习框架，其中包括分层正则化。首先，我们使用定制的网络设计和一对双模态对比损失融合涵盖医学代码、人口统计数据和临床笔记的多方面信息，所有这些都围绕着医学代码表现。我们还使用医学本体中的父级信息来规范特定模态的编码器，以学习EHR数据的层次结构。对MIMIC-III数据进行的一系列实验证明了我们方法的有效性。

    Predicting next visit diagnosis using Electronic Health Records (EHR) is an essential task in healthcare, critical for devising proactive future plans for both healthcare providers and patients. Nonetheless, many preceding studies have not sufficiently addressed the heterogeneous and hierarchical characteristics inherent in EHR data, inevitably leading to sub-optimal performance. To this end, we propose NECHO, a novel medical code-centric multimodal contrastive EHR learning framework with hierarchical regularisation. First, we integrate multifaceted information encompassing medical codes, demographics, and clinical notes using a tailored network design and a pair of bimodal contrastive losses, all of which pivot around a medical code representation. We also regularise modality-specific encoders using a parental level information in medical ontology to learn hierarchical structure of EHR data. A series of experiments on MIMIC-III data demonstrates effectiveness of our approach.
    
[^231]: 将大型语言模型应用于教育：基本能力、潜力和挑战

    Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges. (arXiv:2401.08664v1 [cs.AI])

    [http://arxiv.org/abs/2401.08664](http://arxiv.org/abs/2401.08664)

    本文回顾了针对教育能力的大型语言模型研究，包括数学、写作、编程、推理和基于知识的问答，旨在探索其在构建下一代智能教育系统中的潜力和挑战。

    

    在线教育平台利用互联网分发教育资源，旨在提供便捷的教育，但往往在与学生的实时交流方面存在不足。由于需要解决学生在学习过程中遇到的多样化障碍的挑战，它们经常难以提供个性化的教育资源。最近出现的大型语言模型（LLMs），如ChatGPT，提供了通过理解个体请求解决这一问题的可能性。虽然LLMs在各个领域都取得了成功，但基于LLM的教育系统的构建仍然面临着广泛的教育技能要求。本文回顾了与教育能力相关的近期出现的LLM研究，包括数学、写作、编程、推理和基于知识的问答，旨在探索它们在构建下一代智能教育系统方面的潜力。

    Online education platforms, leveraging the internet to distribute education resources, seek to provide convenient education but often fall short in real-time communication with students. They often struggle to offer personalized education resources due to the challenge of addressing the diverse obstacles students encounter throughout their learning journey. Recently, the emergence of large language models (LLMs), such as ChatGPT, offers the possibility for resolving this issue by comprehending individual requests. Although LLMs have been successful in various fields, creating an LLM-based education system is still challenging for the wide range of educational skills required. This paper reviews the recently emerged LLM researches related to educational capabilities, including mathematics, writing, programming, reasoning, and knowledge-based question answering, with the aim to explore their potential in constructing the next-generation intelligent education system. Based on the current 
    
[^232]: QuasiNet: 一种具有可训练乘积层的神经网络

    QuasiNet: a neural network with trainable product layers. (arXiv:2401.06137v1 [cs.NE])

    [http://arxiv.org/abs/2401.06137](http://arxiv.org/abs/2401.06137)

    QuasiNet是一种新的神经网络模型，通过可训练的乘积层解决了小规模隐藏神经元下传统神经网络在难问题上的有限收敛问题，具有更高的成功率。

    

    传统神经网络在类似XOR或奇偶校验等难题的小规模隐藏神经元下只能实现有限的收敛。为了提高神经网络在这些问题上的成功率，我们提出了一种新的神经网络模型，受现有具有所谓乘积神经元和由经典误差反向传播推导出的学习规则启发，优雅地解决了互斥情况的问题。与现有的具有预设且不可调节权重的乘积神经元不同，我们的神经元乘积层也能够学习。我们测试了该模型，并将其成功率与传统的多层感知机在前述问题和其他难题（如两个螺旋）中进行了比较。我们的结果表明，我们的模型比传统的多层感知机更成功，并且在许多任务和应用中具有潜力。

    Classical neural networks achieve only limited convergence in hard problems such as XOR or parity when the number of hidden neurons is small. With the motivation to improve the success rate of neural networks in these problems, we propose a new neural network model inspired by existing neural network models with so called product neurons and a learning rule derived from classical error backpropagation, which elegantly solves the problem of mutually exclusive situations. Unlike existing product neurons, which have weights that are preset and not adaptable, our product layers of neurons also do learn. We tested the model and compared its success rate to a classical multilayer perceptron in the aforementioned problems as well as in other hard problems such as the two spirals. Our results indicate that our model is clearly more successful than the classical MLP and has the potential to be used in many tasks and applications.
    
[^233]: INACIA：将大型语言模型整合到巴西审计法院中的机会和挑战

    INACIA: Integrating Large Language Models in Brazilian Audit Courts: Opportunities and Challenges. (arXiv:2401.05273v1 [cs.CL])

    [http://arxiv.org/abs/2401.05273](http://arxiv.org/abs/2401.05273)

    本文介绍了INACIA系统，这是一个将大型语言模型整合到巴西审计法院中的系统，可以自动化案件分析的各个阶段，并展示了其在从案件文件中提取信息、评估合法性和生成司法建议方面的潜力。

    

    本文介绍了INACIA（基于人工智能的辅助指令系统），这是一个开创性的系统，旨在将大型语言模型（LLMs）整合到巴西联邦审计法院（TCU）的运营框架中。该系统自动化了案件分析的各个阶段，包括基本信息提取、可受理性审查、Periculum in mora和Fumus boni iuris分析以及建议生成。通过一系列实验，我们展示了INACIA从案件文件中提取相关信息、评估其合法性并生成司法建议的潜力。利用验证数据集和LLMs，我们的评估方法提供了一种创新的方法来评估系统性能，与人类判断高度相关。结果突显了INACIA处理复杂法律任务的能力，表明其适用于增加法律系统的效率和司法公正性。

    This paper introduces INACIA (Instru\c{c}\~ao Assistida com Intelig\^encia Artificial), a groundbreaking system designed to integrate Large Language Models (LLMs) into the operational framework of Brazilian Federal Court of Accounts (TCU). The system automates various stages of case analysis, including basic information extraction, admissibility examination, Periculum in mora and Fumus boni iuris analyses, and recommendations generation. Through a series of experiments, we demonstrate INACIA's potential in extracting relevant information from case documents, evaluating its legal plausibility, and generating judicial recommendations. Utilizing a validation dataset alongside LLMs, our evaluation methodology presents an innovative approach to assessing system performance, correlating highly with human judgment. The results highlight INACIA's proficiency in handling complex legal tasks, indicating its suitability for augmenting efficiency and judicial fairness within legal systems. The pap
    
[^234]: 使用大型语言模型在制造业中进行知识共享：用户评估和模型基准测试

    Knowledge Sharing in Manufacturing using Large Language Models: User Evaluation and Model Benchmarking. (arXiv:2401.05200v1 [cs.HC])

    [http://arxiv.org/abs/2401.05200](http://arxiv.org/abs/2401.05200)

    使用大型语言模型在制造业中进行知识共享，通过评估实证了该系统的效益，提高了操作员的信息检索速度和问题解决效率，同时强调在有人工专家选项时的偏好。GPT-4是最优秀的模型。

    

    高效管理知识对组织的成功至关重要。在制造业中，操作工厂变得越来越依赖知识，这给工厂培训和支持新操作员的能力带来了压力。本文介绍了一个基于大型语言模型（LLM）的系统，旨在利用工厂文档中包含的广泛知识，高效回答操作员的查询并促进新知识的共享。为了评估其有效性，我们在一个工厂环境中进行了评估。评估结果表明该系统的好处，即能够更快地检索信息和更高效地解决问题。然而，研究也强调了在有人工专家选项时更倾向于向人工专家学习。此外，我们还对该系统进行了几种闭源和开源语言模型的基准测试。GPT-4表现始终优于其他模型，像StableBe

    Managing knowledge efficiently is crucial for organizational success. In manufacturing, operating factories has become increasing knowledge-intensive putting strain on the factory's capacity to train and support new operators. In this paper, we introduce a Large Language Model (LLM)-based system designed to use the extensive knowledge contained in factory documentation. The system aims to efficiently answer queries from operators and facilitate the sharing of new knowledge. To assess its effectiveness, we conducted an evaluation in a factory setting. The results of this evaluation demonstrated the system's benefits; namely, in enabling quicker information retrieval and more efficient resolution of issues. However, the study also highlighted a preference for learning from a human expert when such an option is available. Furthermore, we benchmarked several closed and open-sourced LLMs for this system. GPT-4 consistently outperformed its counterparts, with open-source models like StableBe
    
[^235]: 车辆计划与时间窗口的最优链路

    Optimal Chaining of Vehicle Plans with Time Windows. (arXiv:2401.02873v1 [math.OC])

    [http://arxiv.org/abs/2401.02873](http://arxiv.org/abs/2401.02873)

    本论文提出了一种解决带有时间窗口的车辆路径问题的最优链路方法，考虑了计划的时间灵活性，并通过实证结果证明了该方法在解决静态拨打车问题时的优越性。

    

    在解决带有时间窗口的车辆路径问题时，我们经常需要将车辆计划连接成跨越更长时间区间的序列，换句话说，我们需要执行计划链路。最近，提出了一种基于网络的方法来解决车队规模问题。然而，该方法不考虑计划的时间灵活性，这是所有带有时间窗口的车辆路径问题的重要属性。相反，计划具有固定时间，不能延迟。本文提出了一种新的问题建模，考虑了延迟和给定时间窗口，并提出了一种解决该问题的方法。此外，我们证明了该方法是最优的，并对其复杂性进行了分析。最后，我们列举了一些实际应用，并对其中一个应用进行了演示：静态拨打车问题的解决方法。演示结果显示，在大量实例中，所提出的方法提供了更好的解决方案。

    For solving problems from the domain of vehicle routing with time windows, we often need to connect vehicle plans into sequences spanning a longer time horizon or, in other words, we need to perform a plan chaining. Recently, a network-based solution has been proposed to solve the fleet-sizing problem. The method, however, does not consider the time flexibility of the plans, an essential property of all vehicle routing problems with time windows. Instead, plans have fixed times and cannot be delayed. This work presents a new problem formulation that considers delays in line with the given time windows and a method that can be used to solve it. Moreover, we prove that the method is optimal, and we analyze its complexity. Finally, we list some practical applications and perform a demonstration for one of them: the method for solving the static Dial-a-ride problem. The demonstration results show that for a significant number of instances, the proposed method provides a better solution tha
    
[^236]: 使用感知损失的扩散模型

    Diffusion Model with Perceptual Loss. (arXiv:2401.00110v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2401.00110](http://arxiv.org/abs/2401.00110)

    本研究介绍了一种使用感知损失的扩散模型，通过无分类器指导实现了生成更真实样本的目的。

    

    使用均方误差损失训练的扩散模型倾向于生成不真实的样本。目前的最先进模型依靠无分类器指导来改善样本质量，然而其惊人的效果尚未完全理解。本文中，我们展示了无分类器指导的有效性在一定程度上源自其作为一种隐式感知指导的形式。因此，我们可以直接在扩散训练中加入感知损失来提高样本质量。由于扩散训练中使用的分数匹配目标与无监督训练感知网络时使用的去噪自动编码器目标非常相似，因此扩散模型本身就是一个感知网络，并可以用于生成有意义的感知损失。我们提出了一种新颖的自感知目标，其结果是扩散模型能够生成更真实的样本。对于条件生成，我们的方法仅改善样本质量，而不与条件绑定。

    Diffusion models trained with mean squared error loss tend to generate unrealistic samples. Current state-of-the-art models rely on classifier-free guidance to improve sample quality, yet its surprising effectiveness is not fully understood. In this paper, We show that the effectiveness of classifier-free guidance partly originates from it being a form of implicit perceptual guidance. As a result, we can directly incorporate perceptual loss in diffusion training to improve sample quality. Since the score matching objective used in diffusion training strongly resembles the denoising autoencoder objective used in unsupervised training of perceptual networks, the diffusion model itself is a perceptual network and can be used to generate meaningful perceptual loss. We propose a novel self-perceptual objective that results in diffusion models capable of generating more realistic samples. For conditional generation, our method only improves sample quality without entanglement with the condit
    
[^237]: 线性对数正态注意力与无偏集中力

    Linear Log-Normal Attention with Unbiased Concentration. (arXiv:2311.13541v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.13541](http://arxiv.org/abs/2311.13541)

    本论文研究了自注意机制，并分析了注意力矩阵的分布和集中能力。通过引入线性对数正态注意力来模拟原始自注意力的分布和集中行为，提高了Transformer模型的可扩展性。

    

    Transformer模型在各种应用中取得了显著的成果。然而，由于自注意机制的时间和内存复杂度与序列长度的二次关系，其可扩展性受到限制。当处理长文档或高分辨率图像时，这一限制构成了重大障碍。本研究通过分析注意力矩阵的分布和集中能力，对自注意机制进行了研究。此外，我们提出了衡量这些数量的工具，并引入了一种新的自注意机制，即线性对数正态注意力，旨在模拟原始自注意力的分布和集中行为。我们在常用的自然语言基准测试上的实验证明，我们提出的线性对数正态注意力优于其他线性化注意力替代方法，为增强Transformer模型的可扩展性提供了一个有前途的途径。我们的代码附在补充材料中。

    Transformer models have achieved remarkable results in a wide range of applications. However, their scalability is hampered by the quadratic time and memory complexity of the self-attention mechanism concerning the sequence length. This limitation poses a substantial obstacle when dealing with long documents or high-resolution images. In this work, we study the self-attention mechanism by analyzing the distribution of the attention matrix and its concentration ability. Furthermore, we propose instruments to measure these quantities and introduce a novel self-attention mechanism, Linear Log-Normal Attention, designed to emulate the distribution and concentration behavior of the original self-attention. Our experimental results on popular natural language benchmarks reveal that our proposed Linear Log-Normal Attention outperforms other linearized attention alternatives, offering a promising avenue for enhancing the scalability of transformer models. Our code is available in supplementary
    
[^238]: 对比差异性预测编码

    Contrastive Difference Predictive Coding. (arXiv:2310.20141v1 [cs.LG])

    [http://arxiv.org/abs/2310.20141](http://arxiv.org/abs/2310.20141)

    本文介绍了一种时间差异版本的对比预测编码，通过将不同时间序列数据的片段组合在一起，来减少学习预测未来事件所需的数据量。实验证明，与先前的方法相比，我们的方法在成功率上提高了2倍，并且对于随机环境有更好的适应能力。

    

    预测和推理未来是许多时间序列问题的核心。例如，目标导向的强化学习可以被看作是学习表示以预测未来可能访问的状态。虽然先前的方法已经使用对比性预测编码来建模时间序列数据，但学习编码长期依赖通常需要大量的数据。在本文中，我们引入了一种时间差异版本的对比预测编码，将不同时间序列数据的片段组合在一起，以减少学习未来事件预测所需的数据量。我们将这种表示学习方法应用于导出目标导向的强化学习的离策略算法。实验证明，与先前的强化学习方法相比，我们的方法在成功率上实现了中位数提高2倍，并且可以更好地应对随机环境。在表格设置中，我们展示了我们的方法约为20倍。

    Predicting and reasoning about the future lie at the heart of many time-series questions. For example, goal-conditioned reinforcement learning can be viewed as learning representations to predict which states are likely to be visited in the future. While prior methods have used contrastive predictive coding to model time series data, learning representations that encode long-term dependencies usually requires large amounts of data. In this paper, we introduce a temporal difference version of contrastive predictive coding that stitches together pieces of different time series data to decrease the amount of data required to learn predictions of future events. We apply this representation learning method to derive an off-policy algorithm for goal-conditioned RL. Experiments demonstrate that, compared with prior RL methods, ours achieves $2 \times$ median improvement in success rates and can better cope with stochastic environments. In tabular settings, we show that our method is about $20
    
[^239]: 有约束的层次蒙特卡洛信念状态规划

    Constrained Hierarchical Monte Carlo Belief-State Planning. (arXiv:2310.20054v1 [cs.AI])

    [http://arxiv.org/abs/2310.20054](http://arxiv.org/abs/2310.20054)

    有约束的层次蒙特卡洛信念状态规划（COBeTS）通过使用分层分解和约束选项控制器，将在线基于搜索的CPOMDP规划扩展到大型机器人问题，并能同时满足约束和奖励目标。

    

    有约束的部分可观察马尔可夫决策过程（CPOMDPs）中的最优规划在满足硬性成本约束的同时最大化奖励目标，推广了状态和过渡不确定性下的安全规划。然而，在大型或连续的问题域中进行在线CPOMDP规划非常困难。在许多大型机器人领域，通过使用高层动作原语（选项）为低层控制提供工具，分层分解可以简化规划。我们引入了有约束的选项信念树搜索（COBeTS）来利用这个层次结构，将在线基于搜索的CPOMDP规划扩展到大型机器人问题。我们证明如果原始选项控制器被定义为满足指定的约束预算，那么COBeTS将随时满足约束。否则，COBeTS将引导搜索朝着安全的选项原语序列，并且可以使用分层监控来实现运行时安全。我们在几个安全关键的约束问题中展示了COBeTS。

    Optimal plans in Constrained Partially Observable Markov Decision Processes (CPOMDPs) maximize reward objectives while satisfying hard cost constraints, generalizing safe planning under state and transition uncertainty. Unfortunately, online CPOMDP planning is extremely difficult in large or continuous problem domains. In many large robotic domains, hierarchical decomposition can simplify planning by using tools for low-level control given high-level action primitives (options). We introduce Constrained Options Belief Tree Search (COBeTS) to leverage this hierarchy and scale online search-based CPOMDP planning to large robotic problems. We show that if primitive option controllers are defined to satisfy assigned constraint budgets, then COBeTS will satisfy constraints anytime. Otherwise, COBeTS will guide the search towards a safe sequence of option primitives, and hierarchical monitoring can be used to achieve runtime safety. We demonstrate COBeTS in several safety-critical, constrain
    
[^240]: AI对齐: 一项全面调查

    AI Alignment: A Comprehensive Survey. (arXiv:2310.19852v1 [cs.AI])

    [http://arxiv.org/abs/2310.19852](http://arxiv.org/abs/2310.19852)

    本篇论文主要介绍了AI对齐的概念、方法和实践。研究围绕四个关键目标：健壮性、可解释性、可控性和道德性展开，并将其分为前向对齐和后向对齐两个部分。 AI对齐是为了构建符合人类意图和价值观的AI系统，并减轻由于系统不对齐带来的潜在风险。

    

    AI对齐旨在构建符合人类意图和价值观的AI系统。随着拥有超人类能力的AI系统的出现，错误对齐系统所带来的潜在大规模风险变得明显。数百名AI专家和公众人物都对AI风险表达了关注，认为减轻AI带来的灭绝风险应该成为全球的优先事项，与大规模社会风险如大流行病和核战争并列。鉴于AI对齐领域缺乏最新的系统调查，本文深入探讨对齐研究的核心概念、方法论和实践。首先，我们确定了四个目标原则作为AI对齐的关键目标：健壮性、可解释性、可控性和道德性（RICE）。我们概述了当前对齐研究的现状，并将其分解为两个关键组成部分：前向对齐和后向对齐。前者旨在使AI系统与人类意图对齐。

    AI alignment aims to build AI systems that are in accordance with human intentions and values. With the emergence of AI systems possessing superhuman capabilities, the potential large-scale risks associated with misaligned systems become apparent. Hundreds of AI experts and public figures have expressed their concerns about AI risks, arguing that mitigating the risk of extinction from AI should be a global priority, alongside other societal-scale risks such as pandemics and nuclear war. Motivated by the lack of an up-to-date systematic survey on AI alignment, in this paper, we delve into the core concepts, methodology, and practice of alignment research. To begin with, we identify four principles as the key objectives of AI alignment: Robustness, Interpretability, Controllability, and Ethicality (RICE). We outline the landscape of current alignment research and decompose them into two key components: forward alignment and backward alignment. The former aims to make AI systems aligned v
    
[^241]: 用大语言模型进行推荐中的表示学习

    Representation Learning with Large Language Models for Recommendation. (arXiv:2310.15950v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2310.15950](http://arxiv.org/abs/2310.15950)

    这篇论文介绍了一个模型-不可知的框架RLMRec，通过使用大语言模型（LLMs）来增强传统的基于ID的推荐系统，并解决了可扩展性问题、仅依赖文本的限制以及提示输入限制等挑战。

    

    推荐系统在深度学习和图神经网络的影响下取得了显著进展，特别是在捕捉复杂的用户-物品关系方面。然而，这些基于图的推荐系统严重依赖于基于ID的数据，可能忽略了与用户和物品相关的有价值的文本信息，导致学到的表示不够富有信息。此外，隐式反馈数据的利用引入了潜在的噪声和偏差，给用户偏好学习的有效性带来了挑战。尽管将大语言模型（LLMs）与传统的基于ID的推荐系统相结合已经引起了人们的关注，但在实际推荐系统中有效实施还需要解决可扩展性问题、仅依赖文本的限制以及提示输入限制等挑战。为了解决这些挑战，我们提出了一个模型不可知的框架RLMRec，旨在通过LLM强化表示来增强现有的推荐系统。

    Recommender systems have seen significant advancements with the influence of deep learning and graph neural networks, particularly in capturing complex user-item relationships. However, these graph-based recommenders heavily depend on ID-based data, potentially disregarding valuable textual information associated with users and items, resulting in less informative learned representations. Moreover, the utilization of implicit feedback data introduces potential noise and bias, posing challenges for the effectiveness of user preference learning. While the integration of large language models (LLMs) into traditional ID-based recommenders has gained attention, challenges such as scalability issues, limitations in text-only reliance, and prompt input constraints need to be addressed for effective implementation in practical recommender systems. To address these challenges, we propose a model-agnostic framework RLMRec that aims to enhance existing recommenders with LLM-empowered representati
    
[^242]: O3D: 基于离线数据的发现与蒸馏方法，用于大规模语言模型在顺序决策中的应用

    O3D: Offline Data-driven Discovery and Distillation for Sequential Decision-Making with Large Language Models. (arXiv:2310.14403v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.14403](http://arxiv.org/abs/2310.14403)

    O3D提出了一种基于离线数据的学习框架，利用大规模数据改进了大规模语言模型在顺序决策问题中的性能，通过自动发现可重复使用的技能，提高了模型的表现

    

    最近对大规模语言模型 (LLMs)的研究取得了令人期待的进展，在解决顺序决策问题方面显示出了良好的性能。通过模仿提示中提供的少量示例（即上下文学习），LLM代理可以与外部环境交互并完成给定任务，而无需额外的训练。然而，这种少量示例往往不足以生成复杂且长期目标任务的高质量解决方案，而有限的上下文长度无法处理更大规模的演示。为此，我们提出了一种利用离线数据的学习框架，以大规模的离线数据（例如人类交互的日志）来改进LLM代理的上下文学习性能。我们通过文本和代码两种方法正式定义了LLM强化策略。然后，我们引入了一种名为O3D的离线数据驱动发现和蒸馏框架，以改善LLM强化策略而无需微调。O3D自动地发现可重复使用的技能

    Recent advancements in large language models (LLMs) have exhibited promising performance in solving sequential decision-making problems. By imitating few-shot examples provided in the prompts (i.e., in-context learning), an LLM agent can interact with an external environment and complete given tasks without additional training. However, such few-shot examples are often insufficient to generate high-quality solutions for complex and long-horizon tasks, while the limited context length cannot consume larger-scale demonstrations. To this end, we propose an offline learning framework that utilizes offline data at scale (e.g, logs of human interactions) to facilitate the in-context learning performance of LLM agents. We formally define LLM-powered policies with both text-based approaches and code-based approaches. We then introduce an Offline Data-driven Discovery and Distillation (O3D) framework to improve LLM-powered policies without finetuning. O3D automatically discovers reusable skills
    
[^243]: 动态稀疏无训练：针对稀疏LLMs的无训练微调

    Dynamic Sparse No Training: Training-Free Fine-tuning for Sparse LLMs. (arXiv:2310.08915v1 [cs.AI])

    [http://arxiv.org/abs/2310.08915](http://arxiv.org/abs/2310.08915)

    这篇论文介绍了一种名为动态稀疏无训练的微调方法，可以在不进行昂贵的反向传播和权重更新的情况下更新稀疏的大型语言模型，以此来减小将其部署到设备上时面临的挑战。

    

    越来越庞大的大语言模型(LLMs)虽然为即将到来的人工通用智能开辟了潜在路径，但很遗憾，在其在设备上部署的道路上存在令人望而生畏的障碍。作为在减少模型复杂性方面最成熟的预-LLMs方法之一，网络修剪似乎在LLMs时代落后，主要是由于在庞大的模型参数和训练数据中需要昂贵的微调(或重新训练)。为了弥合产业与学术界之间的差距，我们引入了动态稀疏无训练(DSnoT)，这是一种无训练微调方法，它在不进行昂贵的反向传播和任何权重更新的情况下略微更新稀疏LLMs。受动态稀疏训练的启发，DSnoT通过在稀疏LLMs之上执行迭代的权重修剪和生长的方式，最小化了稠密和稀疏LLMs之间的重构误差。为了实现这个目的，DSnoT特别考虑了预期的减少情况。

    The ever-increasing large language models (LLMs), though opening a potential path for the upcoming artificial general intelligence, sadly drops a daunting obstacle on the way towards their on-device deployment. As one of the most well-established pre-LLMs approaches in reducing model complexity, network pruning appears to lag behind in the era of LLMs, due mostly to its costly fine-tuning (or re-training) necessity under the massive volumes of model parameter and training data. To close this industry-academia gap, we introduce Dynamic Sparse No Training (DSnoT), a training-free fine-tuning approach that slightly updates sparse LLMs without the expensive backpropagation and any weight updates. Inspired by the Dynamic Sparse Training, DSnoT minimizes the reconstruction error between the dense and sparse LLMs, in the fashion of performing iterative weight pruning-and-growing on top of sparse LLMs. To accomplish this purpose, DSnoT particularly takes into account the anticipated reduction 
    
[^244]: 思维多样性提升大规模语言模型的推理能力

    Diversity of Thought Improves Reasoning Abilities of Large Language Models. (arXiv:2310.07088v1 [cs.CL])

    [http://arxiv.org/abs/2310.07088](http://arxiv.org/abs/2310.07088)

    本文提出了一种方法，通过改变输入提示来提高大规模语言模型的推理能力，从而改善模型在复杂推理场景中的表现。这种方法自动采集模型反馈，生成适合问题的多样化提示，并通过多次推理调用来集成这些多样化的提示。

    

    大规模语言模型在需要复杂推理的环境中表现不佳。然而，将模型指导分解问题为更小的推理步骤或通过修改解码步骤使各种生成结果合并可以提升性能。目前的方法都假设输入提示是固定的，并期望解码策略引入所需的多样性。本文放松了这个假设，并讨论了如何通过创建和利用输入提示的变化来提升思维多样性以改善模型性能。我们提出了一种方法，通过向语言模型征求反馈来构思适合问题的方法，从而自动提高提示的多样性。我们在我们的方法DIV-SE (DIVerse reasoning path Self-Ensemble)中对多样的提示进行合成，通过多次推理调用实现。我们还提出了一种经济高效的替代方案，即在一个推理中使用多样的提示。

    Large language models (LLMs) are documented to struggle in settings that require complex reasoning. Nevertheless, instructing the model to break down the problem into smaller reasoning steps (Wei et al., 2022), or ensembling various generations through modifying decoding steps (Wang et al., 2023) boosts performance. Current methods assume that the input prompt is fixed and expect the decoding strategies to introduce the diversity needed for ensembling. In this work, we relax this assumption and discuss how one can create and leverage variations of the input prompt as a means to diversity of thought to improve model performance. We propose a method that automatically improves prompt diversity by soliciting feedback from the LLM to ideate approaches that fit for the problem. We then ensemble the diverse prompts in our method DIV-SE (DIVerse reasoning path Self-Ensemble) across multiple inference calls. We also propose a cost-effective alternative where diverse prompts are used within a s
    
[^245]: 通过对抗行为抑制Q学习中的过高估计

    Suppressing Overestimation in Q-Learning through Adversarial Behaviors. (arXiv:2310.06286v1 [cs.LG])

    [http://arxiv.org/abs/2310.06286](http://arxiv.org/abs/2310.06286)

    本文提出了一种新的Q学习算法，通过引入虚拟对抗性玩家，有效调节了标准Q学习中的过高估计偏差，提出的算法简单而有效，能够轻松应用于强化学习算法并提高性能。

    

    本文旨在提出一种新的Q学习算法，使用一个虚拟对抗性玩家，称为虚拟对抗性Q学习（DAQ），以有效地调节标准Q学习中的过高估计偏差。通过虚拟玩家，学习可以被表述为一个双人零和博弈。所提出的DAQ将几种Q学习的变体统一到一个单一的框架中，以控制过高估计偏差，例如maxmin Q学习和minmax Q学习（本文提出）。通过虚拟对抗性行为，所提出的DAQ是一种简单而有效的方式，可以轻松应用于现成的强化学习算法，以提高性能。通过调整对抗性Q学习，从综合的角度分析了DAQ的有限时间收敛性。在各种基准环境下，实证验证了所提出DAQ的性能。

    The goal of this paper is to propose a new Q-learning algorithm with a dummy adversarial player, which is called dummy adversarial Q-learning (DAQ), that can effectively regulate the overestimation bias in standard Q-learning. With the dummy player, the learning can be formulated as a two-player zero-sum game. The proposed DAQ unifies several Q-learning variations to control overestimation biases, such as maxmin Q-learning and minmax Q-learning (proposed in this paper) in a single framework. The proposed DAQ is a simple but effective way to suppress the overestimation bias thourgh dummy adversarial behaviors and can be easily applied to off-the-shelf reinforcement learning algorithms to improve the performances. A finite-time convergence of DAQ is analyzed from an integrated perspective by adapting an adversarial Q-learning. The performance of the suggested DAQ is empirically demonstrated under various benchmark environments.
    
[^246]: 让模型说密文: 通过嵌入进行多智能体辩论

    Let Models Speak Ciphers: Multiagent Debate through Embeddings. (arXiv:2310.06272v1 [cs.CL])

    [http://arxiv.org/abs/2310.06272](http://arxiv.org/abs/2310.06272)

    本文引入了一种名为CIPHER的通信机制，通过去除LLMs中的标记采样步骤，让模型可以通过期望的原始Transformer输出嵌入来传达其信念，从而解决了在自然语言生成中可能存在的信息丢失风险，并提供了编码更广泛信息的优势。

    

    最近，对大型语言模型（LLMs）之间的讨论和辩论引起了广泛关注，因为它们有潜力增强LLMs的推理能力。尽管自然语言由于LLMs的语言理解能力而成为明显的交流选择，但生成自然语言时需要进行的标记采样步骤可能存在信息丢失的潜在风险，因为它仅使用一个标记来代表模型在整个词汇表中的信念。在本文中，我们介绍了一种名为CIPHER（通过嵌入表示进行交流的网络模型协议）的通信机制来解决这个问题。具体来说，我们从LLMs中去除了标记采样步骤，让它们通过原始Transformer输出嵌入的期望来传达它们的信念。值得注意的是，通过偏离自然语言，CIPHER在不对模型权重进行任何修改的情况下，提供了编码更广泛信息的优势。

    Discussion and debate among Large Language Models (LLMs) have gained considerable attention due to their potential to enhance the reasoning ability of LLMs. Although natural language is an obvious choice for communication due to LLM's language understanding capability, the token sampling step needed when generating natural language poses a potential risk of information loss, as it uses only one token to represent the model's belief across the entire vocabulary. In this paper, we introduce a communication regime named CIPHER (Communicative Inter-Model Protocol Through Embedding Representation) to address this issue. Specifically, we remove the token sampling step from LLMs and let them communicate their beliefs across the vocabulary through the expectation of the raw transformer output embeddings. Remarkably, by deviating from natural language, CIPHER offers an advantage of encoding a broader spectrum of information without any modification to the model weights. While the state-of-the-a
    
[^247]: 使用大型语言模型（LLMS）对图中的节点进行无标签分类

    Label-free Node Classification on Graphs with Large Language Models (LLMS). (arXiv:2310.04668v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.04668](http://arxiv.org/abs/2310.04668)

    本文介绍了一种使用大型语言模型（LLMs）对图中节点进行无标签分类的方法，即LLM-GNN。它利用LLMs对一小部分节点进行注释，然后通过对LLMs的注释进行训练，使得GNN能够对其余大部分节点进行预测。这种方法充分发挥了GNNs和LLMs的优势，同时解决了它们在处理结构化数据方面的限制。

    

    近年来，图神经网络（Graph Neural Networks，GNNs）在节点分类方面取得了显著的进展。然而，为了确保良好的性能，它们需要大量高质量的标签。相比之下，大型语言模型（Large Language Models，LLMs）在文本属性图上展现出了令人印象深刻的零样学习能力。然而，它们在高效处理结构化数据方面面临挑战，并且推理成本较高。鉴于这些观察结果，本文引入了一种基于LLMs的无标签图节点分类方法，命名为LLM-GNN。它集成了GNNs和LLMs的优势，同时减轻了它们的限制。具体而言，LLMs被用来注释一小部分节点，然后通过对LLMs的注释进行训练，使GNNs能够预测其余大部分节点。LLM-GNN的实现面临一个独特的挑战：我们如何主动选择要由LLMs注释的节点，从而增强GNN的训练？我们如何利用LLMs来优化结构化数据的处理？

    In recent years, there have been remarkable advancements in node classification achieved by Graph Neural Networks (GNNs). However, they necessitate abundant high-quality labels to ensure promising performance. In contrast, Large Language Models (LLMs) exhibit impressive zero-shot proficiency on text-attributed graphs. Yet, they face challenges in efficiently processing structural data and suffer from high inference costs. In light of these observations, this work introduces a label-free node classification on graphs with LLMs pipeline, LLM-GNN. It amalgamates the strengths of both GNNs and LLMs while mitigating their limitations. Specifically, LLMs are leveraged to annotate a small portion of nodes and then GNNs are trained on LLMs' annotations to make predictions for the remaining large portion of nodes. The implementation of LLM-GNN faces a unique challenge: how can we actively select nodes for LLMs to annotate and consequently enhance the GNN training? How can we leverage LLMs to ob
    
[^248]: 利用自一致性提高数据有效的摊余贝叶斯推理方法

    Leveraging Self-Consistency for Data-Efficient Amortized Bayesian Inference. (arXiv:2310.04395v1 [cs.LG])

    [http://arxiv.org/abs/2310.04395](http://arxiv.org/abs/2310.04395)

    该论文提出了一种利用自一致性改进数据有效的摊余贝叶斯推理方法，通过反转贝叶斯定理并利用近似表示的联合模型估计边际似然，加速条件神经密度估计器的学习动力学。

    

    我们提出了一种方法，通过利用参数$\theta$和数据$y$的概率联合模型$p(\theta, y)$中的通用对称性，改进了摊余贝叶斯推理（ABI）的效率和准确性。简言之，我们反转贝叶斯定理，并基于近似表示的联合模型估计边际似然。在完美近似情况下，边际似然在所有参数值上都是常数定义的。然而，近似误差导致不同参数值的边际似然估计中存在不可取的方差。我们将这种对称性的违反形式化为损失函数，加速条件神经密度估计器的学习动力学。我们将我们的方法应用于具有显式似然（基于似然）的双峰玩具问题和具有隐式似然（基于模拟）的现实模型。

    We propose a method to improve the efficiency and accuracy of amortized Bayesian inference (ABI) by leveraging universal symmetries in the probabilistic joint model $p(\theta, y)$ of parameters $\theta$ and data $y$. In a nutshell, we invert Bayes' theorem and estimate the marginal likelihood based on approximate representations of the joint model. Upon perfect approximation, the marginal likelihood is constant across all parameter values by definition. However, approximation error leads to undesirable variance in the marginal likelihood estimates across different parameter values. We formulate violations of this symmetry as a loss function to accelerate the learning dynamics of conditional neural density estimators. We apply our method to a bimodal toy problem with an explicit likelihood (likelihood-based) and a realistic model with an implicit likelihood (simulation-based).
    
[^249]: USB-NeRF: 解卷曲快门束调整的神经辐射场

    USB-NeRF: Unrolling Shutter Bundle Adjusted Neural Radiance Fields. (arXiv:2310.02687v1 [cs.CV])

    [http://arxiv.org/abs/2310.02687](http://arxiv.org/abs/2310.02687)

    USB-NeRF是一种解决滚动快门相机问题的神经辐射场算法，能够纠正滚动快门失真并恢复准确的相机运动轨迹，相比之前的方法在RS效应去除和新视角图像生成方面表现更好。

    

    最近神经辐射场（NeRF）因其出色的能力来表示3D场景和合成新的视角图像而受到广泛关注。现有的工作通常假设输入图像是由全局快门相机拍摄的。因此，滚动快门（RS）图像不能直接应用于现成的NeRF算法进行新视角合成。滚动快门效应还会影响相机位姿估计（例如通过COLMAP），进一步阻碍了使用RS图像的NeRF算法的成功。本文提出了一种解卷曲快门束调整的神经辐射场（USB-NeRF）。USB-NeRF能够在NeRF框架下纠正滚动快门失真并同时恢复准确的相机运动轨迹，通过对RS相机的物理图像形成过程进行建模。实验结果表明，USB-NeRF相比之前的工作在RS效应去除和新视角图像生成方面取得了更好的性能。

    Neural Radiance Fields (NeRF) has received much attention recently due to its impressive capability to represent 3D scene and synthesize novel view images. Existing works usually assume that the input images are captured by a global shutter camera. Thus, rolling shutter (RS) images cannot be trivially applied to an off-the-shelf NeRF algorithm for novel view synthesis. Rolling shutter effect would also affect the accuracy of the camera pose estimation (e.g. via COLMAP), which further prevents the success of NeRF algorithm with RS images. In this paper, we propose Unrolling Shutter Bundle Adjusted Neural Radiance Fields (USB-NeRF). USB-NeRF is able to correct rolling shutter distortions and recover accurate camera motion trajectory simultaneously under the framework of NeRF, by modeling the physical image formation process of a RS camera. Experimental results demonstrate that USB-NeRF achieves better performance compared to prior works, in terms of RS effect removal, novel view image sy
    
[^250]: 使用LLM和BoWs自动评估课堂教学支持：将全局预测与具体反馈相连接

    Automated Evaluation of Classroom Instructional Support with LLMs and BoWs: Connecting Global Predictions to Specific Feedback. (arXiv:2310.01132v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.01132](http://arxiv.org/abs/2310.01132)

    本研究旨在利用大型语言模型和词袋模型自动估计课堂教学支持，以提供更具体、频繁和可行动的反馈给教师。实验证明，所提出的方法准确性接近于人工互评可靠性，LLM模型可以更好地捕捉到教学支持特征。

    

    为了向教师提供更具体、更频繁和可行动的反馈，我们探讨了如何利用大型语言模型（LLMs）来估计“教学支持”领域的CLASS课堂评估得分，该评估方法是广泛使用的观测协议。我们设计了一个机器学习架构，使用Meta的Llama2的零-shot提示，和/或经典的词袋（BoW）模型，用于对教师言语的个别话语（使用OpenAI的Whisper进行自动转录）进行分类，以确定是否存在教学支持。然后，这些话语级的判断结果在整个15分钟的观察会话中进行聚合，以估计全局CLASS得分。在幼儿园和学前班教室的两个经过CLASS编码的数据集上进行的实验证明：（1）所提出的方法自动估计CLASS教学支持的准确性（Pearson R高达0.47）接近人工互评可靠性（最高R=0.55）；（2）LLM模型可以更好地捕捉到小班教室中的教学支持特征。

    With the aim to provide teachers with more specific, frequent, and actionable feedback about their teaching, we explore how Large Language Models (LLMs) can be used to estimate ``Instructional Support'' domain scores of the CLassroom Assessment Scoring System (CLASS), a widely used observation protocol. We design a machine learning architecture that uses either zero-shot prompting of Meta's Llama2, and/or a classic Bag of Words (BoW) model, to classify individual utterances of teachers' speech (transcribed automatically using OpenAI's Whisper) for the presence of Instructional Support. Then, these utterance-level judgments are aggregated over an entire 15-min observation session to estimate a global CLASS score. Experiments on two CLASS-coded datasets of toddler and pre-kindergarten classrooms indicate that (1) automatic CLASS Instructional Support estimation accuracy using the proposed method (Pearson $R$ up to $0.47$) approaches human inter-rater reliability (up to $R=0.55$); (2) LLM
    
[^251]: Ground-A-Video: 使用文本到图像扩散模型的零样本视频编辑

    Ground-A-Video: Zero-shot Grounded Video Editing using Text-to-image Diffusion Models. (arXiv:2310.01107v1 [cs.CV])

    [http://arxiv.org/abs/2310.01107](http://arxiv.org/abs/2310.01107)

    本论文提出了一种名为 Ground-A-Video 的基于引导的视频到视频转换框架，用于多属性视频编辑。该方法在没有训练的情况下实现了输入视频的时间一致的多属性编辑，并且解决了其他方法存在的问题。

    

    最近在视频编辑领域取得了令人期待的成果，实现了单属性编辑或风格传递的任务，不论通过在文本-视频数据上训练文本到视频（T2V）模型还是采用无需训练的方法。然而，当面对多属性编辑情景的复杂性时，它们存在一些缺点，比如忽略或忽视所期望的属性变化，修改输入视频的错误元素，以及无法保留应该保持原样的输入视频区域。为解决这个问题，我们提出了一种新颖的基于引导的视频到视频转换框架，名为 Ground-A-Video，用于多属性视频编辑。Ground-A-Video以无需训练的方式实现了输入视频的时间一致的多属性编辑，并且没有上述缺点。我们方法的核心是引入了交叉帧门控注意力，以一种时间上一致的方式将定位信息融入到潜在表示中。

    Recent endeavors in video editing have showcased promising results in single-attribute editing or style transfer tasks, either by training text-to-video (T2V) models on text-video data or adopting training-free methods. However, when confronted with the complexities of multi-attribute editing scenarios, they exhibit shortcomings such as omitting or overlooking intended attribute changes, modifying the wrong elements of the input video, and failing to preserve regions of the input video that should remain intact. To address this, here we present a novel grounding-guided video-to-video translation framework called Ground-A-Video for multi-attribute video editing. Ground-A-Video attains temporally consistent multi-attribute editing of input videos in a training-free manner without aforementioned shortcomings. Central to our method is the introduction of Cross-Frame Gated Attention which incorporates groundings information into the latent representations in a temporally consistent fashion,
    
[^252]: 使用合成数据进行预训练有助于离线强化学习

    Pre-training with Synthetic Data Helps Offline Reinforcement Learning. (arXiv:2310.00771v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.00771](http://arxiv.org/abs/2310.00771)

    本文研究表明，在离线深度强化学习中，使用合成数据进行预训练可以提高性能，而不一定需要语言预训练。此外，使用一步马尔科夫链生成的数据进行预训练可进一步改善性能。在一个流行的离线DRL算法中，使用简单的预训练方案也能获得性能提升。

    

    最近的研究表明，对于离线深度强化学习(DRL)，使用大型语言语料库预训练Decision Transformer可以提高下游性能。一个自然的问题是，这种性能提升是否只能通过语言预训练实现，还是可以通过不涉及语言的更简单的预训练方案实现。在本文中，我们首先证明了语言对于改善性能并不是必要的，实际上，使用合成的IID数据进行少量更新的预训练可以达到与使用大型语言语料库预训练相匹配的性能提升；此外，使用一步马尔科夫链生成的数据进行预训练可以进一步提高性能。受到这些实验结果的启发，我们进一步考虑了预训练Conservative Q-Learning(CQL)，这是一种流行的离线DRL算法，它基于Q-learning，并通常使用多层感知器(MLP)骨干。令人惊讶的是，使用简单的预训练方案也能在CQL算法中取得性能提升。

    Recently, it has been shown that for offline deep reinforcement learning (DRL), pre-training Decision Transformer with a large language corpus can improve downstream performance (Reid et al., 2022). A natural question to ask is whether this performance gain can only be achieved with language pre-training, or can be achieved with simpler pre-training schemes which do not involve language. In this paper, we first show that language is not essential for improved performance, and indeed pre-training with synthetic IID data for a small number of updates can match the performance gains from pre-training with a large language corpus; moreover, pre-training with data generated by a one-step Markov chain can further improve the performance. Inspired by these experimental results, we then consider pre-training Conservative Q-Learning (CQL), a popular offline DRL algorithm, which is Q-learning-based and typically employs a Multi-Layer Perceptron (MLP) backbone. Surprisingly, pre-training with sim
    
[^253]: 保序GFlowNets

    Order-Preserving GFlowNets. (arXiv:2310.00386v1 [cs.LG])

    [http://arxiv.org/abs/2310.00386](http://arxiv.org/abs/2310.00386)

    本研究提出了保序GFlowNets（OP-GFNs），通过学习奖励函数与候选者的排序相一致的概率进行采样，解决了使用预定义标量奖励的局限性，同时提供了证明训练过程稀疏奖励景观的理论支持。

    

    生成流网络（GFlowNets）被引入作为一种根据给定奖励概率采样多样化的候选集的方法。然而，GFlowNets只能与预定义的标量奖励一起使用，在多目标优化（MOO）任务中，这可能是计算昂贵的或者直接不可访问的。此外，为了优先识别高奖励候选者，传统做法是将奖励提高到更高的指数，而这个最优选择在不同环境下可能会有所不同。为了解决这些问题，我们提出了保序GFlowNets（OP-GFNs），它们以与提供的（部分）候选者排序一致的学习奖励函数的概率进行采样，从而消除了对奖励函数的显式表达的需求。我们在理论上证明了OP-GFNs的训练过程逐渐稀疏了学习到的奖励景观。

    Generative Flow Networks (GFlowNets) have been introduced as a method to sample a diverse set of candidates with probabilities proportional to a given reward. However, GFlowNets can only be used with a predefined scalar reward, which can be either computationally expensive or not directly accessible, in the case of multi-objective optimization (MOO) tasks for example. Moreover, to prioritize identifying high-reward candidates, the conventional practice is to raise the reward to a higher exponent, the optimal choice of which may vary across different environments. To address these issues, we propose Order-Preserving GFlowNets (OP-GFNs), which sample with probabilities in proportion to a learned reward function that is consistent with a provided (partial) order on the candidates, thus eliminating the need for an explicit formulation of the reward function. We theoretically prove that the training process of OP-GFNs gradually sparsifies the learned reward landscape in single-objective max
    
[^254]: 一种用于医学图像中一般移动目标分割的基础模型

    A Foundation Model for General Moving Object Segmentation in Medical Images. (arXiv:2309.17264v1 [cs.CV])

    [http://arxiv.org/abs/2309.17264](http://arxiv.org/abs/2309.17264)

    本文提出了一种用于医学图像中移动目标分割的基础模型iMOS，通过对序列中只有少量图像进行注释，即可实现高精度的分割效果

    

    医学图像分割旨在描绘感兴趣的解剖或病理结构，在临床诊断中起着关键作用。构建高精度的深度分割模型需要大量高质量的注释数据。然而，医学注释非常繁琐耗时，特别是对于医学视频或3D体积，由于巨大的标签空间和差的帧间一致性。最近，在自然图像中，一个名为Moving Object Segmentation (MOS)的基本任务在技术上取得了重大进展。它的目标是在图像序列中从背景中描绘移动物体，只需要最小的注释。在本文中，我们提出了第一个用于医学图像中MOS的基础模型，名为iMOS。对一个大规模多模态医学数据集进行的大量实验验证了所提出的iMOS的有效性。具体而言，只需对序列中少量的图像进行注释，iMOS就可以实现了

    Medical image segmentation aims to delineate the anatomical or pathological structures of interest, playing a crucial role in clinical diagnosis. A substantial amount of high-quality annotated data is crucial for constructing high-precision deep segmentation models. However, medical annotation is highly cumbersome and time-consuming, especially for medical videos or 3D volumes, due to the huge labeling space and poor inter-frame consistency. Recently, a fundamental task named Moving Object Segmentation (MOS) has made significant advancements in natural images. Its objective is to delineate moving objects from the background within image sequences, requiring only minimal annotations. In this paper, we propose the first foundation model, named iMOS, for MOS in medical images. Extensive experiments on a large multi-modal medical dataset validate the effectiveness of the proposed iMOS. Specifically, with the annotation of only a small number of images in the sequence, iMOS can achieve sati
    
[^255]: 艺术还是技巧？大型语言模型与创造力的虚假承诺

    Art or Artifice? Large Language Models and the False Promise of Creativity. (arXiv:2309.14556v1 [cs.CL])

    [http://arxiv.org/abs/2309.14556](http://arxiv.org/abs/2309.14556)

    本研究通过提出创造性写作的托兰斯测验(TTCW)来评估大型语言模型(LLMs)的写作创造力。结果表明，LLM生成的故事在创意测试中通过的数量比专业作家写的故事少。此外，我们发现LLMs无法代替专家进行TTCW评估。

    

    研究人员认为，大型语言模型(LLMs)具有从博客到故事的高质量写作能力。然而，客观评估一段文字的创造力是具有挑战性的。受创造性思维的托兰斯测验(TTC)的启发，我们使用共识评估技术[3]，提出了创造性写作的托兰斯测验(TTCW)来评估创造力作为一个产品。TTCW由包含在流畅度、灵活性、独创性和细致度原始维度中的14个二元测试组成。我们招募了10位创意作家，并使用TTCW对48个由专业作家或LLMs撰写的故事进行人工评估。我们的分析表明，LLM生成的故事通过的TTCW测试比专业作家写的故事少了3-10倍。此外，我们探索了使用LLMs作为评价者，以自动化TTCW评估，结果显示没有一个LLM与专家评估呈正相关。

    Researchers have argued that large language models (LLMs) exhibit high-quality writing capabilities from blogs to stories. However, evaluating objectively the creativity of a piece of writing is challenging. Inspired by the Torrance Test of Creative Thinking (TTCT), which measures creativity as a process, we use the Consensual Assessment Technique [3] and propose the Torrance Test of Creative Writing (TTCW) to evaluate creativity as a product. TTCW consists of 14 binary tests organized into the original dimensions of Fluency, Flexibility, Originality, and Elaboration. We recruit 10 creative writers and implement a human assessment of 48 stories written either by professional authors or LLMs using TTCW. Our analysis shows that LLM-generated stories pass 3-10X less TTCW tests than stories written by professionals. In addition, we explore the use of LLMs as assessors to automate the TTCW evaluation, revealing that none of the LLMs positively correlate with the expert assessments.
    
[^256]: 在复杂医疗决策中重新思考人工智能与人类的合作：以脓毒症诊断为案例研究

    Rethinking Human-AI Collaboration in Complex Medical Decision Making: A Case Study in Sepsis Diagnosis. (arXiv:2309.12368v1 [cs.HC])

    [http://arxiv.org/abs/2309.12368](http://arxiv.org/abs/2309.12368)

    本研究探索了在复杂医疗决策中重新思考人工智能与人类合作的设计要求，以脓毒症诊断为例。研究发现，在人工智能系统中，支持临床专家在决策过程的中间阶段发挥作用（如生成假设或收集数据）是至关重要的，而不仅仅关注最终决策。

    

    如今的医疗决策支持人工智能系统在研究论文中取得了成功，但在实际部署中却面临失败的问题。本研究聚焦于脓毒症的决策过程，这是一种需要临床医生早期高度不确定性诊断的急性致命全身性感染。我们的目标是探索能够支持临床专家做出更好脓毒症早期诊断决策的人工智能系统的设计要求。研究从一个形成性研究开始，调查为什么临床专家在电子病历系统中放弃了一个现有的脓毒症预测模块。我们认为，一个以人为中心的人工智能系统需要在医疗决策过程的中间阶段（如生成假设或收集数据）支持人类专家，而不仅仅关注最终决策。因此，我们基于先进的人工智能算法构建了SepsisLab，并将其扩展到预测未来趋势。

    Today's AI systems for medical decision support often succeed on benchmark datasets in research papers but fail in real-world deployment. This work focuses on the decision making of sepsis, an acute life-threatening systematic infection that requires an early diagnosis with high uncertainty from the clinician. Our aim is to explore the design requirements for AI systems that can support clinical experts in making better decisions for the early diagnosis of sepsis. The study begins with a formative study investigating why clinical experts abandon an existing AI-powered Sepsis predictive module in their electrical health record (EHR) system. We argue that a human-centered AI system needs to support human experts in the intermediate stages of a medical decision-making process (e.g., generating hypotheses or gathering data), instead of focusing only on the final decision. Therefore, we build SepsisLab based on a state-of-the-art AI algorithm and extend it to predict the future projection o
    
[^257]: RaTrack: 带有4D雷达点云的运动物体检测与跟踪

    RaTrack: Moving Object Detection and Tracking with 4D Radar Point Cloud. (arXiv:2309.09737v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.09737](http://arxiv.org/abs/2309.09737)

    RaTrack是一种针对雷达跟踪的创新解决方案，通过运动分割和聚类以及运动估计模块，实现了对移动物体的精确跟踪，优于最先进性能。

    

    移动自主性依赖于对动态环境的精确感知。在3D世界中稳定地跟踪移动物体因此对于轨迹预测、避障和路径规划等应用起着关键作用。虽然大多数现有方法利用LiDAR或相机进行多目标跟踪（MOT），但4D成像雷达的能力仍然很少被探索。认识到4D雷达数据中的雷达噪声和点稀疏性所带来的挑战，我们介绍了RaTrack，这是一种专门针对基于雷达的跟踪的创新解决方案。我们的方法摒弃了对特定对象类型和3D边界框的依赖，而是专注于运动分割和聚类，并配以运动估计模块。在View-of-Delft数据集上进行评估时，RaTrack展示出了优于最先进性能的运动物体跟踪精度。

    Mobile autonomy relies on the precise perception of dynamic environments. Robustly tracking moving objects in 3D world thus plays a pivotal role for applications like trajectory prediction, obstacle avoidance, and path planning. While most current methods utilize LiDARs or cameras for Multiple Object Tracking (MOT), the capabilities of 4D imaging radars remain largely unexplored. Recognizing the challenges posed by radar noise and point sparsity in 4D radar data, we introduce RaTrack, an innovative solution tailored for radar-based tracking. Bypassing the typical reliance on specific object types and 3D bounding boxes, our method focuses on motion segmentation and clustering, enriched by a motion estimation module. Evaluated on the View-of-Delft dataset, RaTrack showcases superior tracking precision of moving objects, largely surpassing the performance of the state of the art.
    
[^258]: 自主驾驶车辆的强化学习策略的定量和定性评估

    Quantitative and Qualitative Evaluation of Reinforcement Learning Policies for Autonomous Vehicles. (arXiv:2309.08254v1 [cs.AI])

    [http://arxiv.org/abs/2309.08254](http://arxiv.org/abs/2309.08254)

    本文使用强化学习算法（PPO）针对自主驾驶车辆的选择进行了优化，通过最小化时间和污染来缓解交通阻塞问题，经实证分析和定性评估证明了方法的有效性和实用性。

    

    在不断变化的交通环境中优化交通动力学非常重要，特别是在自动驾驶车辆（AVs）与人驾驶车辆并存的情况下。本文提出了一种使用近端策略优化（PPO）强化学习算法来优化AVs选择的新方法。我们通过学习一种策略来最小化交通阻塞（即最小化横过米兰的环形道的时间）并减少污染。通过经验分析，我们证明了我们的方法可以减少时间和污染水平。此外，我们使用先进的驾驶舱定性评估了学到的策略，以评估其在接近真实世界条件下的性能。为了评估策略的实用性和可接受性，我们通过模拟器进行了人类参与者的评估，重点关注交通平稳性和安全感等一系列指标。总的来说，我们的研究结果表明，人驾驶车辆的感知和行车平滑性方面，我们的方法非常实用。

    Optimizing traffic dynamics in an evolving transportation landscape is crucial, particularly in scenarios where autonomous vehicles (AVs) with varying levels of autonomy coexist with human-driven cars. This paper presents a novel approach to optimizing choices of AVs using Proximal Policy Optimization (PPO), a reinforcement learning algorithm. We learned a policy to minimize traffic jams (i.e., minimize the time to cross the scenario) and to minimize pollution in a roundabout in Milan, Italy. Through empirical analysis, we demonstrate that our approach can reduce time and pollution levels. Furthermore, we qualitatively evaluate the learned policy using a cutting-edge cockpit to assess its performance in near-real-world conditions. To gauge the practicality and acceptability of the policy, we conducted evaluations with human participants using the simulator, focusing on a range of metrics like traffic smoothness and safety perception. In general, our findings show that human-driven vehi
    
[^259]: 图神经网络在不需要的时候仍然使用图形信息

    Graph Neural Networks Use Graphs When They Shouldn't. (arXiv:2309.04332v1 [cs.LG])

    [http://arxiv.org/abs/2309.04332](http://arxiv.org/abs/2309.04332)

    在图形预测问题中，GNNs倾向于过拟合图结构，即使在忽略图结构的情况下可以获得更好的解决方案。常规图对于这种过拟合更具鲁棒性。

    

    在各个领域中，包括社交网络、分子生物学、医学等，对图形进行预测起着至关重要的作用。图神经网络(GNNs)已成为学习图数据的主要方法。图形标注问题的实例包括图结构(即邻接矩阵)和节点特定的特征向量。在某些情况下，这种图结构对于预测任务来说并不具有信息量。例如，分子性质如摩尔质量仅依赖于组成原子(节点特征)，而与分子结构无关。尽管GNNs有能力在这种情况下忽略图结构，但不清楚它们是否会这样做。在这项工作中，我们展示了GNNs实际上倾向于在过拟合图结构，即在忽略它可以获得更好解决方案的情况下仍在使用。我们根据不同的图分布来研究这种现象，发现常规图对这种过拟合更加稳健。

    Predictions over graphs play a crucial role in various domains, including social networks, molecular biology, medicine, and more. Graph Neural Networks (GNNs) have emerged as the dominant approach for learning on graph data. Instances of graph labeling problems consist of the graph-structure (i.e., the adjacency matrix), along with node-specific feature vectors. In some cases, this graph-structure is non-informative for the predictive task. For instance, molecular properties such as molar mass depend solely on the constituent atoms (node features), and not on the molecular structure. While GNNs have the ability to ignore the graph-structure in such cases, it is not clear that they will. In this work, we show that GNNs actually tend to overfit the graph-structure in the sense that they use it even when a better solution can be obtained by ignoring it. We examine this phenomenon with respect to different graph distributions and find that regular graphs are more robust to this overfitting
    
[^260]: 一个关于校准的基准研究

    A Benchmark Study on Calibration. (arXiv:2308.11838v1 [cs.LG])

    [http://arxiv.org/abs/2308.11838](http://arxiv.org/abs/2308.11838)

    这项研究提出了一个模型校准的基准研究，利用神经架构搜索空间探索了模型校准属性。研究结果显示，模型校准可以在不同任务中泛化，并可以同时兼顾模型的准确性和校准性能。

    

    深度神经网络在各种机器学习任务中的应用越来越广泛。然而，随着这些模型复杂性的增加，它们往往面临校准问题，尽管预测准确性有所提高。许多研究通过数据预处理、使用特定损失函数和训练框架来改善校准性能。然而，对校准属性的研究有点被忽视了。我们的研究利用神经架构搜索（NAS）搜索空间，在全面探索校准属性的模型架构空间中提供了一个详尽的模型架构空间。我们特别创建了一个模型校准数据集。该数据集在广泛使用的NATS-Bench搜索空间中评估了90个基于区间的校准度量和12个其他校准度量，涵盖了117,702个独特的神经网络。我们的分析旨在通过我们提出的数据集回答该领域一些长期存在的问题：（i）模型校准能否在不同任务中泛化？（ii）能否同时兼顾模型的准确性和校准性能？

    Deep neural networks are increasingly utilized in various machine learning tasks. However, as these models grow in complexity, they often face calibration issues, despite enhanced prediction accuracy. Many studies have endeavored to improve calibration performance through data preprocessing, the use of specific loss functions, and training frameworks. Yet, investigations into calibration properties have been somewhat overlooked. Our study leverages the Neural Architecture Search (NAS) search space, offering an exhaustive model architecture space for thorough calibration properties exploration. We specifically create a model calibration dataset. This dataset evaluates 90 bin-based and 12 additional calibration measurements across 117,702 unique neural networks within the widely employed NATS-Bench search space. Our analysis aims to answer several longstanding questions in the field, using our proposed dataset: (i) Can model calibration be generalized across different tasks? (ii) Can rob
    
[^261]: 基于内部跨层梯度的联邦学习中的同质性到异质性的扩展

    Internal Cross-layer Gradients for Extending Homogeneity to Heterogeneity in Federated Learning. (arXiv:2308.11464v1 [cs.LG])

    [http://arxiv.org/abs/2308.11464](http://arxiv.org/abs/2308.11464)

    提出了一种基于内部跨层梯度的联邦学习方法，通过混合浅层和深层的梯度，增强了深层的相似性，从而扩展了在处理系统异质性方面的能力。

    

    联邦学习（FL）在实际场景中不可避免地面临系统异质性的挑战。为了增强大多数模型同质性FL方法处理系统异质性的能力，我们提出了一种训练方案，可以扩展它们应对这一挑战的能力。我们在本文中从详细探索同质性和异质性FL设置开始，发现了三个关键观察结果：（1）客户端性能与层之间的相似性呈正相关，（2）浅层比深层具有更高的相似性，（3）较为平滑的梯度分布指示了更高的层相似性。基于这些观察结果，我们提出了InCo Aggregation方法，利用内部跨层梯度，即服务器模型中来自浅层和深层的梯度混合，以增强深层的相似性，而无需额外的客户端通信。

    Federated learning (FL) inevitably confronts the challenge of system heterogeneity in practical scenarios. To enhance the capabilities of most model-homogeneous FL methods in handling system heterogeneity, we propose a training scheme that can extend their capabilities to cope with this challenge. In this paper, we commence our study with a detailed exploration of homogeneous and heterogeneous FL settings and discover three key observations: (1) a positive correlation between client performance and layer similarities, (2) higher similarities in the shallow layers in contrast to the deep layers, and (3) the smoother gradients distributions indicate the higher layer similarities. Building upon these observations, we propose InCo Aggregation that leverags internal cross-layer gradients, a mixture of gradients from shallow and deep layers within a server model, to augment the similarity in the deep layers without requiring additional communication between clients. Furthermore, our methods 
    
[^262]: 使用强化学习的离散提示压缩

    Discrete Prompt Compression with Reinforcement Learning. (arXiv:2308.08758v1 [cs.CL])

    [http://arxiv.org/abs/2308.08758](http://arxiv.org/abs/2308.08758)

    本研究提出了一种使用强化学习的离散提示压缩方法（PCRL），以解决指令调整的语言模型中嵌入训练的挑战。PCRL采用了一种计算效率高的策略网络直接编辑提示，可以灵活应用于各种类型的LM，而不需要梯度访问或标记数据。

    

    指令调整的语言模型（LM）被用户广泛使用来解决与任务特定提示相关的各种问题。由于上下文窗口长度和计算成本的限制，鼓励开发压缩提示的方法。现有方法严重依赖于训练嵌入，这些嵌入被设计为容纳多个记号含义。这在解释性、固定数量的嵌入记号、在不同LM之间的可重用性以及与黑盒API交互时的不适用性方面带来了挑战。本研究提出了一种使用强化学习的提示压缩方法（PCRL），它解决了这些问题。PCRL采用了一种计算效率高的策略网络，直接编辑提示。PCRL的训练方法可以灵活地应用于各种类型的LM，以及只有解码器和编码器-解码器架构，而不需要使用梯度访问LM或标记数据进行训练。

    Instruction-tuned Language Models (LMs) are widely used by users to address various problems with task-specific prompts. Constraints associated with the context window length and computational costs encourage the development of compressed prompts. Existing methods rely heavily on training embeddings, which are designed to accommodate multiple token meanings. This presents challenges in terms of interpretability, a fixed number of embedding tokens, reusability across different LMs, and inapplicability when interacting with black-box APIs. This study proposes prompt compression with reinforcement learning (PCRL), a novel discrete prompt compression method that addresses these issues. PCRL employs a computationally efficient policy network that directly edits prompts. The PCRL training approach can be flexibly applied to various types of LMs, as well as decoder-only and encoder-decoder architecture, and can be trained without gradient access to LMs or labeled data. PCRL achieves an averag
    
[^263]: 大型语言模型在电信行业的未来影响

    Large Language Models for Telecom: Forthcoming Impact on the Industry. (arXiv:2308.06013v1 [cs.IT])

    [http://arxiv.org/abs/2308.06013](http://arxiv.org/abs/2308.06013)

    大型语言模型在电信行业将产生重要的影响。它们可以提高运营效率，简化任务，并需要解决使用中的挑战。

    

    大型语言模型（LLMs）已经成为一股变革的力量，不仅在自然语言处理（NLP）的传统领域之外，还在许多领域引起了革命性的关注。随着LLM技术的不断发展，电信行业面临着潜在影响的前景。为了阐明这些影响，我们深入研究LLMs的内部机制，提供了关于它们目前的能力和局限性的见解。我们还研究了在电信行业可以方便实施的使用案例，简化了目前妨碍运营效率并需要大量人力和工程专业知识的任务。此外，我们还揭示了在电信领域利用LLMs所面临的独特挑战的重要研究方向。解决这些挑战是充分利用LLMs潜力和发挥其能力的重要进展。

    Large Language Models (LLMs) have emerged as a transformative force, revolutionizing numerous fields well beyond the conventional domain of Natural Language Processing (NLP) and garnering unprecedented attention. As LLM technology continues to progress, the telecom industry is facing the prospect of its potential impact on its landscape. To elucidate these implications, we delve into the inner workings of LLMs, providing insights into their current capabilities and limitations. We also examine the use cases that can be readily implemented in the telecom industry, streamlining numerous tasks that currently hinder operational efficiency and demand significant manpower and engineering expertise. Furthermore, we uncover essential research directions that deal with the distinctive challenges of utilizing the LLMs within the telecom domain. Addressing these challenges represents a significant stride towards fully harnessing the potential of LLMs and unlocking their capabilities to the fulles
    
[^264]: LLMeBench：用于加速LLMs基准测试的灵活框架

    LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking. (arXiv:2308.04945v1 [cs.CL])

    [http://arxiv.org/abs/2308.04945](http://arxiv.org/abs/2308.04945)

    LLMeBench是一个灵活的框架，用于加速LLMs基准测试。它可以定制任何NLP任务和模型，无论语言，支持零和少样本学习设置，并允许用户添加新的自定义数据集。已经在31个独特的NLP任务上进行了测试，并计划将框架开源。

    

    最近大型语言模型（LLMs）的发展和成功使得需要评估它们在不同语言的各种NLP任务中的性能。尽管已经开发并公开了几个框架，但对于不同用户来说，它们对特定任务和数据集的定制能力通常很复杂。在这项研究中，我们引入了LLMeBench框架。最初是为了使用OpenAI的GPT和BLOOM模型评估阿拉伯语NLP任务而开发的；它可以无缝定制任何NLP任务和模型，无论语言如何。该框架还具有零和少样本学习设置。可以在不到10分钟内添加新的自定义数据集，并且用户可以使用自己的模型API密钥来评估当前任务。该框架已经在90个实验设置中使用53个公开可用数据集对31个独特的NLP任务进行了测试，涉及大约296K个数据点。我们计划将该框架开源供社区使用。

    The recent development and success of Large Language Models (LLMs) necessitate an evaluation of their performance across diverse NLP tasks in different languages. Although several frameworks have been developed and made publicly available, their customization capabilities for specific tasks and datasets are often complex for different users. In this study, we introduce the LLMeBench framework. Initially developed to evaluate Arabic NLP tasks using OpenAI's GPT and BLOOM models; it can be seamlessly customized for any NLP task and model, regardless of language. The framework also features zero- and few-shot learning settings. A new custom dataset can be added in less than 10 minutes, and users can use their own model API keys to evaluate the task at hand. The developed framework has been already tested on 31 unique NLP tasks using 53 publicly available datasets within 90 experimental setups, involving approximately 296K data points. We plan to open-source the framework for the community
    
[^265]: 语言模型作为主方程求解器

    Language models as master equation solvers. (arXiv:2308.02514v1 [cs.LG])

    [http://arxiv.org/abs/2308.02514](http://arxiv.org/abs/2308.02514)

    本研究将语言模型用作求解主方程的机器学习方法，通过设计提示网络和使用强化学习算法训练，实现了对多模组和高维系统的高精度求解。

    

    主方程在建模随机动力系统中具有基本重要性，然而由于状态空间维度的增加，解决主方程是具有挑战性的。本研究提出将语言模型重新应用为机器学习方法来解决主方程。我们设计了一个基于提示的神经网络，将速率参数、初始条件和时间值直接映射到与输入上下文完全匹配的状态联合概率分布。通过这种方式，我们近似地求解了主方程的最一般形式。我们使用强化学习框架中的策略梯度算法对网络进行训练，反馈奖励由一组变分自回归模型提供。通过将该方法应用于代表性示例，我们观察到对于多模组和高维系统，准确性很高。训练后的网络还展示了...

    Master equations are of fundamental importance in modeling stochastic dynamical systems.However, solving master equations is challenging due to the exponential increase in the number of possible states or trajectories with the dimension of the state space. In this study, we propose repurposing language models as a machine learning approach to solve master equations. We design a prompt-based neural network to map rate parameters, initial conditions, and time values directly to the state joint probability distribution that exactly matches the input contexts. In this way, we approximate the solution of the master equation in its most general form. We train the network using the policy gradient algorithm within the reinforcement learning framework, with feedback rewards provided by a set of variational autoregressive models. By applying this approach to representative examples, we observe high accuracy for both multi-module and high-dimensional systems. The trained network also exhibits ex
    
[^266]: 调节AI操纵：运用行为经济学和心理学的见解增强欧盟AI法案的实用性

    Regulating AI manipulation: Applying Insights from behavioral economics and psychology to enhance the practicality of the EU AI Act. (arXiv:2308.02041v1 [cs.CY])

    [http://arxiv.org/abs/2308.02041](http://arxiv.org/abs/2308.02041)

    本文通过运用心理学和行为经济学的见解，澄清了欧盟AI法案中的术语并提高了保护效果。

    

    欧盟AI法案第5条旨在调节AI操纵，以防止潜在的有害后果。然而，由于术语模糊和操纵技术表述不清晰，这项立法的实际执行存在挑战。此外，第5条也受到保护效果不足的批评。本文试图通过整合心理学和行为经济学的见解，澄清术语并提高保护效果。首先，本文运用认知心理学研究阐明潜意识技巧及其相关表述。此外，本文将行为经济学中可以引发行为变化的一组思维快捷方式，即启发式，扩展到操纵技术领域。术语的阐明和扩展不仅提供了对法律规定更准确的理解，还增强了其保护效果。

    The EU AI Act Article 5 is designed to regulate AI manipulation to prevent potential harmful consequences. However, the practical implementation of this legislation is challenging due to the ambiguous terminologies and the unclear presentations of manipulative techniques. Moreover, the Article 5 also suffers criticize of inadequate protective efficacy. This paper attempts to clarify terminologies and to enhance the protective efficacy by integrating insights from psychology and behavioral economics. Firstly, this paper employs cognitive psychology research to elucidate the term subliminal techniques and its associated representation. Additionally, this paper extends the study of heuristics: a set of thinking shortcuts which can be aroused for behavior changing from behavior economics to the realm of manipulative techniques. The elucidation and expansion of terminologies not only provide a more accurate understanding of the legal provision but also enhance its protective efficacy. Secon
    
[^267]: 一种具有规划、长期上下文理解和程序合成能力的现实世界WebAgent

    A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis. (arXiv:2307.12856v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.12856](http://arxiv.org/abs/2307.12856)

    这篇论文介绍了一种名为WebAgent的LLM驱动代理，通过自我经验学习，在真实网站上完成任务。该方法通过规划、总结和生成代码来提高在真实网站上的成功率。

    

    最近，预训练的大型语言模型（LLMs）在自主Web自动化方面取得了更好的泛化性能和样本效率。然而，在真实世界的网站上，性能仍然受到三个方面的限制：开放领域性、有限的上下文长度和对HTML的归纳偏差的缺乏。我们介绍了一种名为WebAgent的LLM驱动代理，它通过自我经验学习，在遵循自然语言指令的前提下，在真实网站上完成任务。WebAgent通过将指令分解为规范的子指令，将长HTML文档总结为与任务相关的片段，并通过从中生成的Python程序对网站进行操作来提前进行规划。我们使用Flan-U-PaLM设计了WebAgent，用于生成有根代码，并使用HTML-T5进行预训练LLMs，利用局部和全局注意机制以及混合长跨度去噪目标来进行规划和总结。我们通过实验证明，我们的模块化方法提高了在真实网站上的成功率。

    Pre-trained large language models (LLMs) have recently achieved better generalization and sample efficiency in autonomous web automation. However, the performance on real-world websites has still suffered from (1) open domainness, (2) limited context length, and (3) lack of inductive bias on HTML. We introduce WebAgent, an LLM-driven agent that learns from self-experience to complete tasks on real websites following natural language instructions. WebAgent plans ahead by decomposing instructions into canonical sub-instructions, summarizes long HTML documents into task-relevant snippets, and acts on websites via Python programs generated from those. We design WebAgent with Flan-U-PaLM, for grounded code generation, and HTML-T5, new pre-trained LLMs for long HTML documents using local and global attention mechanisms and a mixture of long-span denoising objectives, for planning and summarization. We empirically demonstrate that our modular recipe improves the success on real websites by ov
    
[^268]: 探索具有描述逻辑特征的命题动态逻辑的非正则扩展

    Exploring Non-Regular Extensions of Propositional Dynamic Logic with Description-Logics Features. (arXiv:2307.09913v1 [cs.LO])

    [http://arxiv.org/abs/2307.09913](http://arxiv.org/abs/2307.09913)

    研究了非正则路径表达式对于扩展ALC描述逻辑中可满足性检查和查询的可决定性的影响，并提供了一系列不可决定性结果。

    

    我们研究了非正则路径表达式对于扩展ALC描述逻辑中可满足性检查和查询的可决定性的影响。我们主要关注的对象是ALCreg和ALCvpl，分别是使用正则和可见推下语言的路径表达式的扩展。第一个ALCreg是Fischer和Ladner所熟知的命题动态逻辑的一种变种。第二个ALCvpl是由Loding和Serre在2007年引入和研究的。ALCvpl逻辑广义上推广了许多已知的可决定性非正则扩展的ALCreg。我们提供了一系列不可决定性结果。首先，我们展示了在添加看似无害的Self操作符后，对于ALCvpl中的概念可满足性问题的可决定性丧失。其次，我们建立了对于在ALCvpl中添加个体词的概念可满足性问题的不可决定性。有趣的是，我们的不可决定性证明只依赖于一个单一的非正则（可见推下）语言。

    We investigate the impact of non-regular path expressions on the decidability of satisfiability checking and querying in description logics extending ALC. Our primary objects of interest are ALCreg and ALCvpl, the extensions of with path expressions employing, respectively, regular and visibly-pushdown languages. The first one, ALCreg, is a notational variant of the well-known Propositional Dynamic Logic of Fischer and Ladner. The second one, ALCvpl, was introduced and investigated by Loding and Serre in 2007. The logic ALCvpl generalises many known decidable non-regular extensions of ALCreg.  We provide a series of undecidability results. First, we show that decidability of the concept satisfiability problem for ALCvpl is lost upon adding the seemingly innocent Self operator. Second, we establish undecidability for the concept satisfiability problem for ALCvpl extended with nominals. Interestingly, our undecidability proof relies only on one single non-regular (visibly-pushdown) langu
    
[^269]: 惯性导航与深度学习：当前趋势与未来方向的综述

    Inertial Navigation Meets Deep Learning: A Survey of Current Trends and Future Directions. (arXiv:2307.00014v1 [cs.RO])

    [http://arxiv.org/abs/2307.00014](http://arxiv.org/abs/2307.00014)

    本文综述了惯性导航领域中当前的深度学习方法，包括对不同车辆操作领域的研究、滤波参数学习的改进以及惯性传感器的校准和去噪方法。翻译过的论文标题: 惯性导航与深度学习：当前趋势与未来方向的综述

    

    惯性传感在许多应用和平台中被使用，从智能手机等日常设备到自动驾驶车辆等复杂设备。近年来，机器学习和深度学习技术在惯性传感领域取得了显著发展。这是由于高效的计算硬件的发展和公开可用的传感器数据的可获得性。这些数据驱动的方法被用于强化基于模型的导航和传感器融合算法。本文提供了对这些深度学习方法的深入综述。我们分别考察了每个车辆操作领域，包括陆地、空中和海洋。每个领域分为纯惯性进展和基于滤波参数学习的改进。此外，我们还回顾了用于校准和去噪惯性传感器的深度学习方法。在整篇论文中，我们讨论了这些趋势和未来方向。我们还提供了常用的统计数据。

    Inertial sensing is used in many applications and platforms, ranging from day-to-day devices such as smartphones to very complex ones such as autonomous vehicles. In recent years, the development of machine learning and deep learning techniques has increased significantly in the field of inertial sensing. This is due to the development of efficient computing hardware and the accessibility of publicly available sensor data. These data-driven approaches are used to empower model-based navigation and sensor fusion algorithms. This paper provides an in-depth review of those deep learning methods. We examine separately, each vehicle operation domain including land, air, and sea. Each domain is divided into pure inertial advances and improvements based on filter parameters learning. In addition, we review deep learning approaches for calibrating and denoising inertial sensors. Throughout the paper, we discuss these trends and future directions. We also provide statistics on the commonly used
    
[^270]: 基于任务条件化超网络的多任务记忆深度强化学习

    Deep Reinforcement Learning with Multitask Episodic Memory Based on Task-Conditioned Hypernetwork. (arXiv:2306.10698v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.10698](http://arxiv.org/abs/2306.10698)

    人工智能领域，一个新算法利用基于任务条件化超网络的检索网络，根据任务调整网络参数，以解决深度强化学习中选择最相关的过去经验并将其融合到既有决策网络中的问题。

    

    深度强化学习算法通常受到采样效率低下的限制，严重依赖与环境的多次交互才能获得准确的决策能力。相比之下，人类似乎依赖海马体从过去有关任务的经历中检索相关信息，在学习新任务时指导其决策，而不是仅仅依赖于环境交互。然而，为代理设计类似海马体的模块以将过去的经历融入既有的强化学习算法面临两个挑战。第一个挑战涉及选择当前任务最相关的过去经验，第二个是将这些经验与决策网络相结合。为了解决这些问题，我们提出了一种新算法，利用基于任务条件化超网络的检索网络，根据任务调整检索网络的参数。

    Deep reinforcement learning algorithms are usually impeded by sampling inefficiency, heavily depending on multiple interactions with the environment to acquire accurate decision-making capabilities. In contrast, humans seem to rely on their hippocampus to retrieve relevant information from past experiences of relevant tasks, which guides their decision-making when learning a new task, rather than exclusively depending on environmental interactions. Nevertheless, designing a hippocampus-like module for an agent to incorporate past experiences into established reinforcement learning algorithms presents two challenges. The first challenge involves selecting the most relevant past experiences for the current task, and the second is integrating such experiences into the decision network. To address these challenges, we propose a novel algorithm that utilizes a retrieval network based on a task-conditioned hypernetwork, which adapts the retrieval network's parameters depending on the task. A
    
[^271]: 随机加权梯度下降通过分布健壮优化

    Stochastic Re-weighted Gradient Descent via Distributionally Robust Optimization. (arXiv:2306.09222v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.09222](http://arxiv.org/abs/2306.09222)

    我们通过分布健壮优化和重要性加权的梯度下降技术提升了深度神经网络的性能，并在各种任务上取得了优越的结果。

    

    我们通过在每一次优化步骤中对数据点进行重要性加权，开发了一种提高深度神经网络性能的加权梯度下降技术。我们的方法受到分布健壮优化和f-散度的启发，已知可以得到具有改进的泛化保证的模型。我们的加权方案简单、计算高效，可以与许多流行的优化算法（如SGD和Adam）结合使用。实验证明，我们的方法在各种任务上都表现出了优越性能，包括监督学习和领域适应。值得注意的是，我们在DomainBed和Tabular分类基准上分别比现有最佳结果提升了0.7%和1.44%。此外，我们的算法将BERT在GLUE基准上的性能提升了1.94%，将ViT在ImageNet-1K上的性能提升了1.01%。这些结果表明了所提出方法的有效性，预示着它在改善性能方面的潜力。

    We develop a re-weighted gradient descent technique for boosting the performance of deep neural networks, which involves importance weighting of data points during each optimization step. Our approach is inspired by distributionally robust optimization with f-divergences, which has been known to result in models with improved generalization guarantees. Our re-weighting scheme is simple, computationally efficient, and can be combined with many popular optimization algorithms such as SGD and Adam. Empirically, we demonstrate the superiority of our approach on various tasks, including supervised learning, domain adaptation. Notably, we obtain improvements of +0.7% and +1.44% over SOTA on DomainBed and Tabular classification benchmarks, respectively. Moreover, our algorithm boosts the performance of BERT on GLUE benchmarks by +1.94%, and ViT on ImageNet-1K by +1.01%. These results demonstrate the effectiveness of the proposed approach, indicating its potential for improving performance in 
    
[^272]: BackpropTools: 一款快速、可移植的连续控制深度强化学习库

    BackpropTools: A Fast, Portable Deep Reinforcement Learning Library for Continuous Control. (arXiv:2306.03530v1 [cs.LG])

    [http://arxiv.org/abs/2306.03530](http://arxiv.org/abs/2306.03530)

    BackpropTools是一款快速、可移植的连续控制深度强化学习库，它通过模板元编程提供紧密集成的可组合组件，并在异构平台集合上无缝使用，同时在连续控制问题的深度RL代理高效可扩展训练方面具有优势。由于其可移植性和实时保证，它成为了在嵌入式设备上部署学来的策略的有价值的工具。

    

    深度强化学习在许多领域中已被证明可以产生出具有能力的代理和控制策略，但常常受到训练时间过长的困扰。此外，在连续控制问题的情况下，现有深度学习库的实时性和可移植性的缺乏限制了学习策略在实际嵌入式设备上的应用。为了解决这些问题，我们提出了BackpropTools，一种依赖性-free、header-only、pure C++的深度监督和强化学习库。利用最近C++标准的模板元编程能力，我们提供了可以由编译器紧密集成的可组合组件。其新颖的架构允许BackpropTools在异构平台集合上无缝使用，从HPC集群、工作站和笔记本电脑到智能手机、智能手表和微控制器。具体来说，由于RL算法与模拟环境的紧密集成，BackpropTools在连续控制问题的深度RL代理的高效可扩展训练方面具有优势。此外，它的可移植性和实时保证使其成为在嵌入式设备上部署学来的策略的有价值的工具。

    Deep Reinforcement Learning (RL) has been demonstrated to yield capable agents and control policies in several domains but is commonly plagued by prohibitively long training times. Additionally, in the case of continuous control problems, the applicability of learned policies on real-world embedded devices is limited due to the lack of real-time guarantees and portability of existing deep learning libraries. To address these challenges, we present BackpropTools, a dependency-free, header-only, pure C++ library for deep supervised and reinforcement learning. Leveraging the template meta-programming capabilities of recent C++ standards, we provide composable components that can be tightly integrated by the compiler. Its novel architecture allows BackpropTools to be used seamlessly on a heterogeneous set of platforms, from HPC clusters over workstations and laptops to smartphones, smartwatches, and microcontrollers. Specifically, due to the tight integration of the RL algorithms with simu
    
[^273]: 稳定对比强化学习: 离线目标达成的技术

    Stabilizing Contrastive RL: Techniques for Offline Goal Reaching. (arXiv:2306.03346v1 [cs.LG])

    [http://arxiv.org/abs/2306.03346](http://arxiv.org/abs/2306.03346)

    本文提出了一种稳定的对比强化学习方法，通过浅而宽的结构，结合谨慎的权重初始化和数据增强等实验方法，在具有挑战性的仿真基准测试中显著提高了性能，并演示了对比方法可以解决现实世界的机器人任务。

    

    计算机视觉和自然语言处理领域已经开发了自监督方法，强化学习也可以被视为自监督问题：学习达到任何目标，而不需要人类指定的奖励或标签。然而，为强化学习建立自监督基础实际上面临着一些重要的挑战。基于此前对比学习方法，我们进行了细致的剖析实验，并发现一个浅而宽的结构，结合谨慎的权重初始化和数据增强，可以显着提高与对比强化学习方法的性能，特别是在具有挑战性的仿真基准测试中。此外，我们还演示了通过这些设计决策，对比方法可以解决现实世界的机器人操作任务，其中任务由训练后提供的单个目标图像指定。

    In the same way that the computer vision (CV) and natural language processing (NLP) communities have developed self-supervised methods, reinforcement learning (RL) can be cast as a self-supervised problem: learning to reach any goal, without requiring human-specified rewards or labels. However, actually building a self-supervised foundation for RL faces some important challenges. Building on prior contrastive approaches to this RL problem, we conduct careful ablation experiments and discover that a shallow and wide architecture, combined with careful weight initialization and data augmentation, can significantly boost the performance of these contrastive RL approaches on challenging simulated benchmarks. Additionally, we demonstrate that, with these design decisions, contrastive approaches can solve real-world robotic manipulation tasks, with tasks being specified by a single goal image provided after training.
    
[^274]: 基于谱嵌入的深度学习研究

    Going Deeper with Spectral Embeddings. (arXiv:2306.00742v1 [cs.LG])

    [http://arxiv.org/abs/2306.00742](http://arxiv.org/abs/2306.00742)

    本文提出两种新的谱嵌入方法，一种基于函数分析原理和核方法，另一种基于深度网络优化损失，提供理论保证和实际有效的算法，并提供新的采样算法。

    

    为了有效地处理海量的数据，从而更好地对其进行表征，科学家们采用表示学习。最近，这些方法与一些底层运算的谱分解之间展现出明显的联系。在历史上，是通过在数据的顶部构建图形来建立明确的谱嵌入，而我们提出了两种新的方法：一种基于函数分析原理和核方法构建的，这将导致具有理论保证的算法，另一种基于深度网络训练以优化基本变分损失的算法，它们产生了实际有效的算法。此外，我们提供了一种新的采样算法，利用学习到的表征来在一步中生成新的样本。

    To make sense of millions of raw data and represent them efficiently, practitioners rely on representation learning. Recently, deep connections have been shown between these approaches and the spectral decompositions of some underlying operators. Historically, explicit spectral embeddings were built from graphs constructed on top of the data. In contrast, we propose two new methods to build spectral embeddings: one based on functional analysis principles and kernel methods, which leads to algorithms with theoretical guarantees, and the other based on deep networks trained to optimize principled variational losses, which yield practically efficient algorithms. Furthermore, we provide a new sampling algorithm that leverages learned representations to generate new samples in a single step.
    
[^275]: 计算多智能体部分可观测路径规划问题的通用计划

    On Computing Universal Plans for Partially Observable Multi-Agent Path Finding. (arXiv:2305.16203v2 [cs.MA] UPDATED)

    [http://arxiv.org/abs/2305.16203](http://arxiv.org/abs/2305.16203)

    本文提出了一种通用计划的解决方案，能够确保多个智能体之间不发生碰撞，并使用 ASP-MAUPF 系统进行实验，对其适用性和环境依赖度进行了观察和分析。

    

    多智能体路径规划问题在现今广泛应用于仓库机器人、物流自动化、交通控制等领域。本文将其看作是通用规划问题，提出了通用计划（又称策略）的解决方案，并实现了一个名为 ASP-MAUPF 的系统来计算它们。该系统能够在任意二维地图和智能体目标配置下，找到一个适用于每个智能体的通用计划，以确保它们之间互不干扰。

    Multi-agent routing problems have drawn significant attention nowadays due to their broad industrial applications in, e.g., warehouse robots, logistics automation, and traffic control. Conventionally, they are modelled as classical planning problems. In this paper, we argue that it is beneficial to formulate them as universal planning problems. We therefore propose universal plans, also known as policies, as the solution concepts, and implement a system called ASP-MAUPF (Answer Set Programming for Multi-Agent Universal Plan Finding) for computing them. Given an arbitrary two-dimensional map and a profile of goals for the agents, the system finds a feasible universal plan for each agent that ensures no collision with others. We use the system to conduct some experiments, and make some observations on the types of goal profiles and environments that will have feasible policies, and how they may depend on agents' sensors. We also demonstrate how users can customize action preferences to c
    
[^276]: 未建图环境下多车辆路径规划的分布式在线策略

    Distributed Online Rollout for Multivehicle Routing in Unmapped Environments. (arXiv:2305.15596v1 [cs.DC])

    [http://arxiv.org/abs/2305.15596](http://arxiv.org/abs/2305.15596)

    本文提出了一个在线策略，通过分布式的协调策略解决了未建图环境下多车辆路径规划问题。

    

    本文考虑了一个广泛化的多车辆路径规划问题：给定一个网络、一组占据网络节点子集的智能体和一组任务, 我们寻求一个最小成本的移动序列，以满足每个任务至少被一个智能体访问的约束条件。与经典问题不同的是，我们假定没有中央服务器，每个智能体都是一个个体处理器，没有关于基础网络（包括任务和智能体位置）的先验知识。此外，我们的智能体具有严格的本地通信和感知能力（限制在它们各自位置周围的半径范围内），更接近多实际应用。我们提出了一种在线策略方法，其中智能体根据集中式模拟器训练的学习型策略局部规划其轨迹。我们在模拟环境中展示了我们的方法，并表明它在网络拓扑和任务分布的变化下仍然能够实现近最优性能。

    In this work we consider a generalization of the well-known multivehicle routing problem: given a network, a set of agents occupying a subset of its nodes, and a set of tasks, we seek a minimum cost sequence of movements subject to the constraint that each task is visited by some agent at least once. The classical version of this problem assumes a central computational server that observes the entire state of the system perfectly and directs individual agents according to a centralized control scheme. In contrast, we assume that there is no centralized server and that each agent is an individual processor with no a priori knowledge of the underlying network (including task and agent locations). Moreover, our agents possess strictly local communication and sensing capabilities (restricted to a fixed radius around their respective locations), aligning more closely with several real-world multiagent applications. These restrictions introduce many challenges that are overcome through local
    
[^277]: 基于Sinkhorn距离的特征对其N-BEATS

    Feature-aligned N-BEATS with Sinkhorn divergence. (arXiv:2305.15196v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.15196](http://arxiv.org/abs/2305.15196)

    这是一个基于Sinkhorn距离的特征对其N-BEATS模型，它通过对齐堆栈中的边际特征概率测度来进行领域广义的时间序列预测，同时保留了N-BEATS的可解释性和预测能力。

    

    我们提出了基于Sinkhorn距离的特征对其N-BEATS作为一个领域广义时间序列预测模型。它是N-BEATS的非平凡扩展，采用了双重残差叠加原则（Oreshkin等人[42]）并将其转化为一个表示学习框架。具体而言，它围绕着由N-BEATS每个堆栈的残差和特征提取算子的复杂组合产生的边际特征概率测度，并通过一种近似最优传输距离（Sinkhorn距离）将它们堆叠地对齐。训练损失由来自多个源域的经验风险最小化（即预测损失）和Sinkhorn距离计算的对齐损失组成，使得模型能够在多个源数据序列中堆叠地学习不变特征，同时保留N-BEATS的可解释设计和预测能力。我们提供了全面的实验评估和消融研究，并展示了相应的结果。

    We propose Feature-aligned N-BEATS as a domain-generalized time series forecasting model. It is a nontrivial extension of N-BEATS with doubly residual stacking principle (Oreshkin et al.[42]) into a representation learning framework. In particular, it revolves around marginal feature probability measures induced by the intricate composition of residual and feature extracting operators of N-BEATS in each stack and aligns them stack-wisely via an approximate of an optimal transport distance referred to as the Sinkhorn divergence. The training loss consists of an empirical risk minimization from multiple source domains, i.e., forecasting loss, and an alignment loss calculated with the Sinkhorn divergence, which allows the model to learn invariant features stack-wisely across multiple source data sequences while retaining N-BEATS's interpretable design and forecasting power. Comprehensive experimental evaluations with ablation studies are provided and the corresponding results demonstrate 
    
[^278]: 在高考基准测试上评估大型语言模型的性能

    Evaluating the Performance of Large Language Models on GAOKAO Benchmark. (arXiv:2305.12474v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12474](http://arxiv.org/abs/2305.12474)

    本文介绍了一个基于高考考试问题的基准测试GAOKAO-Benchmark，用于评估大型语言模型在客观和主观问题方面的表现。通过对ChatGPT模型的评估，研究发现其在客观问题方面表现出色，同时也揭示了其不足之处和改进的方向。

    

    大型语言模型已经在各种自然语言处理任务中展示了出色的性能；然而它们在更具挑战性和领域特定的任务中的功效仍然不太清楚。本文介绍了GAOKAO-Benchmark（GAOKAO-Bench），这是一个直观的基准测试，它使用中国高考考试的题目作为测试样本，评估大型语言模型。为了尽可能地使评估结果与人类一致，我们设计了一种基于零-shot提示的方法，通过将问题分为主观和客观类型来分析模型的准确性和评分率。我们评估了ChatGPT模型在GAOKAO-Benchmark性能上的表现。我们的研究发现，ChatGPT模型在解决客观问题方面表现出色，同时也揭示了其不足之处和改进的方向。为了进一步审查模型的响应，我们加入了人类评估。总之，本研究为创建一个稳健的评估GAOKAO基准测试提供了贡献。

    Large language models have demonstrated remarkable performance across various natural language processing tasks; however, their efficacy in more challenging and domain-specific tasks remains less explored. This paper introduces the GAOKAO-Benchmark (GAOKAO-Bench), an intuitive benchmark that employs questions from the Chinese Gaokao examination as test samples for evaluating large language models.In order to align the evaluation results with humans as much as possible, we designed a method based on zero-shot prompts to analyze the accuracy and scoring rate of the model by dividing the questions into subjective and objective types. We evaluated the ChatGPT model on GAOKAO-Benchmark performance.Our findings reveal that the ChatGPT model excels in tackling objective questions, while also shedding light on its shortcomings and areas for improvement. To further scrutinize the model's responses, we incorporate human evaluations.In conclusion, this research contributes a robust evaluation ben
    
[^279]: 使用指令微调基础模型的多模态 Web 导航。

    Multimodal Web Navigation with Instruction-Finetuned Foundation Models. (arXiv:2305.11854v1 [cs.LG])

    [http://arxiv.org/abs/2305.11854](http://arxiv.org/abs/2305.11854)

    本文研究使用视觉语言基础模型进行数据驱动离线训练的 Web 代理，提出了一个指令跟随多模态代理WebGUM，将微调指令微调语言模型和视觉转换器，能够有效提高代理的基于视觉感知、HTML 理解和多步推理的能力。

    

    自主 Web 导航的进展受到了依赖数十亿次在线强化学习的探索性交互和具有领域特定模型设计的影响，这使得难以利用来自丰富领域外数据的泛化。在本工作中，我们研究了基于数据驱动的脱机训练，用于使用视觉语言基础模型的 Web 代理。我们提出了一个指令跟随多模态代理， WebGUM，它观察了网页截图和 HTML 页面，并输出 Web 导航操作，如单击和输入。WebGUM 是通过联合微调指令微调语言模型和视觉转换器在大量的演示语料库上训练的。我们凭经验证明，这种方法可以提高代理的基于视觉感知、HTML 理解和多步推理的能力，明显优于之前的工作。在 MiniWoB 基准测试中，我们超过之前最佳脱机方法 31.9% 以上，接近实现在线交互的表现。

    The progress of autonomous web navigation has been hindered by the dependence on billions of exploratory interactions via online reinforcement learning, and domain-specific model designs that make it difficult to leverage generalization from rich out-of-domain data. In this work, we study data-driven offline training for web agents with vision-language foundation models. We propose an instruction-following multimodal agent, WebGUM, that observes both webpage screenshots and HTML pages and outputs web navigation actions, such as click and type. WebGUM is trained by jointly finetuning an instruction-finetuned language model and a vision transformer on a large corpus of demonstrations. We empirically demonstrate this recipe improves the agent's ability of grounded visual perception, HTML comprehension and multi-step reasoning, outperforming prior works by a significant margin. On the MiniWoB benchmark, we improve over the previous best offline methods by more than 31.9%, being close to re
    
[^280]: 模型所有权争议中的虚假指控

    False Claims against Model Ownership Resolution. (arXiv:2304.06607v1 [cs.CR])

    [http://arxiv.org/abs/2304.06607](http://arxiv.org/abs/2304.06607)

    该论文研究了模型所有权解决方案中对抗恶意原告的鲁棒性问题，展示了常见的MOR方案可以被恶意原告针对未被盗用的独立模型提出虚假指控。

    

    深度神经网络模型是模型所有者的有价值知识产权，构成了竞争优势。因此，开发保护模型不被盗用的技术至关重要。模型所有权解决方案（MOR）是一类可以防止模型被盗的技术。MOR方案使得原告方可以通过提供证据（如水印或指纹）来断言对涉嫌盗用模型的被告方声称所有权，证明涉嫌模型是被盗或者源自于原告方拥有的源模型。现有的大多数 MOR 方案重点放在防范恶意涉嫌方方面，确保如果涉嫌模型确实是被盗版，则原告方将获胜。但是在本文中，我们揭示了现有文献中的常见 MOR 方案存在着另一个同等重要但尚未被充分探讨的鲁棒性问题：恶意原告。我们展示了如何成功地针对未被盗用的独立模型提出虚假指控。

    Deep neural network (DNN) models are valuable intellectual property of model owners, constituting a competitive advantage. Therefore, it is crucial to develop techniques to protect against model theft. Model ownership resolution (MOR) is a class of techniques that can deter model theft. A MOR scheme enables an accuser to assert an ownership claim for a suspect model by presenting evidence, such as a watermark or fingerprint, to show that the suspect model was stolen or derived from a source model owned by the accuser. Most of the existing MOR schemes prioritize robustness against malicious suspects, ensuring that the accuser will win if the suspect model is indeed a stolen model.  In this paper, we show that common MOR schemes in the literature are vulnerable to a different, equally important but insufficiently explored, robustness concern: a malicious accuser. We show how malicious accusers can successfully make false claims against independent suspect models that were not stolen. Our
    
[^281]: 鲁棒不变表示中的域泛化

    Domain Generalization In Robust Invariant Representation. (arXiv:2304.03431v1 [cs.LG])

    [http://arxiv.org/abs/2304.03431](http://arxiv.org/abs/2304.03431)

    本文研究了不变表示的泛化性能，证明具有不变表示的模型可以学习到具有鲁棒性的非结构化潜在表示，因此使不变性成为域泛化的一个关键方面。

    

    无监督学习常见变换的不变表示方法常用于目标识别。学习不变性使得模型更加鲁棒，并在实际场景中更容易应用。由于不改变对象固有属性的数据变换是识别任务中主要的复杂性来源，对这些变换具有不变性的模型有助于减少所需的训练数据。这进一步提高了模型的效率并简化了训练过程。本文研究了不变表示的泛化性能，并试图回答一个问题：具有某些变换不变性的模型在先前未见域中是否仍具有不变性？通过广泛的实验，我们证明了具有不变表示的模型可以学习到具有鲁棒性的非结构化潜在表示，因此使不变性成为域泛化的一个关键方面。

    Unsupervised approaches for learning representations invariant to common transformations are used quite often for object recognition. Learning invariances makes models more robust and practical to use in real-world scenarios. Since data transformations that do not change the intrinsic properties of the object cause the majority of the complexity in recognition tasks, models that are invariant to these transformations help reduce the amount of training data required. This further increases the model's efficiency and simplifies training. In this paper, we investigate the generalization of invariant representations on out-of-distribution data and try to answer the question: Do model representations invariant to some transformations in a particular seen domain also remain invariant in previously unseen domains? Through extensive experiments, we demonstrate that the invariant model learns unstructured latent representations that are robust to distribution shifts, thus making invariance a de
    
[^282]: 劳务分工中的外部性。

    Externalities in Chore Division. (arXiv:2303.12446v1 [cs.GT])

    [http://arxiv.org/abs/2303.12446](http://arxiv.org/abs/2303.12446)

    该论文研究了劳务分工中的外部性问题，扩展了经典模型考虑到其他代理的影响。

    

    劳务分工问题模拟了不同的资源在多个代理之间的公平分配。在公平分配问题中，每个代理只从自己的资源中获得价值。然而，代理也可能关注分配给其他代理的资源，这些外部性自然地出现在公平分配的情况中。Branzei等人通过扩展经典模型以考虑外部性，推广了比例和无嫉妒性的经典思想。（Branzei et al。，IJCAI 2013）

    The chore division problem simulates the fair division of a heterogeneous undesirable resource among several agents. In the fair division problem, each agent only gains value from its own piece. Agents may, however, also be concerned with the pieces given to other agents; these externalities naturally appear in fair division situations. Branzei et ai. (Branzei et al., IJCAI 2013) generalize the classical ideas of proportionality and envy-freeness while extending the classical model to account for externalities.
    
[^283]: 一个使用深度学习的文本语义通信在干扰环境下的性能限制

    Performance Limits of a Deep Learning-Enabled Text Semantic Communication under Interference. (arXiv:2302.14702v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2302.14702](http://arxiv.org/abs/2302.14702)

    这项研究探讨了在干扰环境下深度学习的文本语义通信系统的性能限制，发现当干扰信号强度增大时，该系统会产生语义上无关的句子。

    

    深度学习(Deep Learning)技术在语义通信(SemCom)中的应用成为了6G的一种推动因素，并承诺通过最小化无关信息传输来降低功耗、带宽消耗和传输延迟。然而，这种以语义为中心的设计的好处可能受到无线电频率干扰(RFI)造成的显著语义噪声的限制。为了解决这一知识空白并促进关于干扰鲁棒性的SemCom基础研究，我们研究了一种名为DeepSC的文本SemCom系统在存在(多干扰源) RFI的情况下的性能限制。通过引入一个基于概率的框架来进行SemCom，我们发现DeepSC在(多干扰源) RFI功率变得非常大时产生语义上无关的句子。我们还推导出DeepSC的实际限制和一个下限。

    A deep learning (DL)-enabled semantic communication (SemCom) has emerged as a 6G enabler while promising to minimize power usage, bandwidth consumption, and transmission delay by minimizing irrelevant information transmission. However, the benefits of such a semantic-centric design can be limited by radio frequency interference (RFI) that causes substantial semantic noise. The impact of semantic noise due to interference can be alleviated using an interference-resistant and robust (IR$^2$) SemCom design. Nevertheless, no such design exists yet. To shed light on this knowledge gap and stimulate fundamental research on IR$^2$ SemCom, the performance limits of a text SemCom system named DeepSC are studied in the presence of (multi-interferer) RFI. By introducing a principled probabilistic framework for SemCom, we show that DeepSC produces semantically irrelevant sentences as the power of (multi-interferer) RFI gets very large. We also derive DeepSC's practical limits and a lower bound on 
    
[^284]: 通过内容感知的风格不变模型学习对未知领域进行泛化：用于胸部X射线疾病检测的翻译摘要

    Learning to Generalize towards Unseen Domains via a Content-Aware Style Invariant Model for Disease Detection from Chest X-rays. (arXiv:2302.13991v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.13991](http://arxiv.org/abs/2302.13991)

    通过内容感知的风格不变模型，我们提出了一种解决深度学习医学图像分析中源领域不匹配挑战的方法。我们采用了风格随机化模块来提取既是风格不变又是内容偏好的领域不变特征，在胸部X射线疾病检测中取得了良好的性能。

    

    在基于深度学习的医学图像分析中，由于源领域不匹配而导致性能降低一直是一个长期存在的挑战，特别是在胸部X射线（CXR）领域。为了解决这种领域转移问题，已经提出了一些方法（如对抗训练，多领域混合），用于提取领域不变的高级特征。然而，这些方法并没有明确规范提取的领域不变特征的内容和风格特征。最近的研究表明，CNN模型对风格（例如，无信息的纹理）有很强的偏好，而不是对内容（例如，形状）的偏好，这与人类视觉系统形成鲜明对比。放射科医师倾向于从CXR图像中学习视觉线索，并因此在多个领域中表现良好。因此，在从CXR图像进行病理诊断的医学成像中，模型应该提取既是风格不变又是内容偏好的领域不变特征。受此启发，我们在实验中使用了新颖的风格随机化模块（SRMs）。

    Performance degradation due to source domain mismatch is a longstanding challenge in deep learning-based medical image analysis, particularly for chest X-rays (CXRs). Several methods (e.g., adversarial training, multi-domain mixups) have been proposed to extract domain-invariant high-level features to address this domain shift. However, these methods do not explicitly regularize the content and style characteristics of the extracted domain-invariant features. Recent studies have demonstrated that CNN models exhibit a strong bias toward styles (e.g., uninformative textures) rather than content (e.g., shape), in stark contrast to the human-vision system. Radiologists tend to learn visual cues from CXRs and thus perform well across multiple domains. Therefore, in medical imaging for pathology diagnosis from CXR images, models should extract domain-invariant features that are style-invariant and content-biased. Motivated by this, we employ the novel style randomization modules (SRMs) at bo
    
[^285]: 一般几何上的黎曼流匹配

    Riemannian Flow Matching on General Geometries. (arXiv:2302.03660v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.03660](http://arxiv.org/abs/2302.03660)

    本文提出了一种名为黎曼流匹配的方法，可以在一般几何上训练连续标准化流，并在高维度数据上具有优势。

    

    我们提出了一种名为黎曼流匹配（RFM）的框架，用于在流形上训练连续标准化流。现有的流形生成建模方法要么需要昂贵的模拟，要么无法本质上扩展到高维度，要么使用限制量的近似来产生有偏的训练目标。黎曼流匹配绕过了这些限制，并提供了比以前方法更多的优势：它在简单几何上无需模拟，不需要散度计算，并以闭合形式计算其目标向量场。 RFM的关键因素是构建一个相对简单的前度量，以定义目标向量场，其中包括现有的欧几里得情况。为了扩展到一般几何，我们依靠使用谱分解来有效地即兴计算前度量。我们的方法在现实世界的非欧几里得数据集上实现了最先进的性能，并通过在3D网格和双曲空间上训练标准化流来证明其功效。

    We propose Riemannian Flow Matching (RFM), a simple yet powerful framework for training continuous normalizing flows on manifolds. Existing methods for generative modeling on manifolds either require expensive simulation, are inherently unable to scale to high dimensions, or use approximations for limiting quantities that result in biased training objectives. Riemannian Flow Matching bypasses these limitations and offers several advantages over previous approaches: it is simulation-free on simple geometries, does not require divergence computation, and computes its target vector field in closed-form. The key ingredient behind RFM is the construction of a relatively simple premetric for defining target vector fields, which encompasses the existing Euclidean case. To extend to general geometries, we rely on the use of spectral decompositions to efficiently compute premetrics on the fly. Our method achieves state-of-the-art performance on real-world non-Euclidean datasets, and we demonstr
    
[^286]: 质量的尾部

    Quality at the Tail. (arXiv:2212.13925v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.13925](http://arxiv.org/abs/2212.13925)

    本研究发现深度学习推理质量存在波动，引入了“尾部质量”的概念来描述这一现象。

    

    对深度学习模型和系统进行基准测试和评估需要一种细致入微的方法，以确保全面评估。在实际应用中，考虑到推理质量和推理时间是至关重要的，特别是在严苛的环境下，要求同时满足两个指标的要求。忽视其中任何一个方面都可能导致严重和不可逆的后果，包括人员伤亡和财产损失。不幸的是，许多研究缺乏对这些指标的全面考虑，通常在理想或宽松条件下进行，从而导致评估方法不完整或不直观。本研究揭示了深度学习推理质量的波动，进一步给基准测试和评估带来了复杂性和挑战。为了更好地描述这一现象，引入了“尾部质量”的概念，表示分布尾部的质量。

    Benchmarking and evaluating deep learning models and systems necessitate a meticulous approach to ensure comprehensive assessment. In practical applications, it is paramount to consider both the inference quality and the inference time, particularly within critical contexts, where stringent requirements demand the simultaneous satisfaction of both metrics. Neglecting either aspect can result in severe and irreversible consequences, including loss of human life and property damage. Unfortunately, many studies lack a comprehensive consideration of these metrics, often conducted under ideal or permissive conditions, thereby leading to incomplete or non-intuitive evaluation methodologies.  This study reveals that deep learning inference quality exhibits fluctuations, which further introduces complications and challenges to the benchmarking and evaluation. To better characterize the phenomenon, the concept of "tail quality" is introduced, which indicates the quality at the tail of distribut
    
[^287]: TREE-G:决策树对抗图神经网络

    TREE-G: Decision Trees Contesting Graph Neural Networks. (arXiv:2207.02760v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.02760](http://arxiv.org/abs/2207.02760)

    TREE-G引入了一种专门针对图数据的修改决策树方法，通过新颖的分裂函数和指针机制，使得决策树能够更好地应用于带有拓扑信息的图结构化数据。

    

    在处理表格数据时，基于决策树的模型是一个流行的选择，因为它们在这些数据类型上具有高准确性、易于应用和可解释性的特点。然而，在处理图结构化数据时，如何有效地应用决策树并将拓扑信息与图的顶点上的表格数据相结合仍不清楚。为了解决这个挑战，我们引入了TREE-G。TREE-G修改了标准决策树，引入了一种专门针对图数据的新型分裂函数。这个分裂函数不仅包括节点特征和拓扑信息，还使用了一种新颖的指针机制，允许分裂节点使用在先前分裂中计算得到的信息。因此，分裂函数能够适应预测任务和当前的图。我们对TREE-G的理论性质进行了分析，并在多个图和顶点预测基准测试上从经验上证明了它的好处。

    When dealing with tabular data, models based on decision trees are a popular choice due to their high accuracy on these data types, their ease of application, and explainability properties. However, when it comes to graph-structured data, it is not clear how to apply them effectively, in a way that incorporates the topological information with the tabular data available on the vertices of the graph. To address this challenge, we introduce TREE-G. TREE-G modifies standard decision trees, by introducing a novel split function that is specialized for graph data. Not only does this split function incorporate the node features and the topological information, but it also uses a novel pointer mechanism that allows split nodes to use information computed in previous splits. Therefore, the split function adapts to the predictive task and the graph at hand. We analyze the theoretical properties of TREE-G and demonstrate its benefits empirically on multiple graph and vertex prediction benchmarks
    
[^288]: 非线性独立分量分析的可辨识性：稀疏性及其它

    On the Identifiability of Nonlinear ICA: Sparsity and Beyond. (arXiv:2206.07751v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.07751](http://arxiv.org/abs/2206.07751)

    本文提出一个新的方法，考虑混合过程的假设，即结构稀疏性，来实现非线性ICA的可识别性，无需辅助变量。

    

    非线性独立分量分析旨在从其可观测的非线性混合中恢复出潜在独立分量。如何使非线性ICA模型可辨识直到某些平凡不确定性是无监督学习中的一个长期问题。最近的突破是将源的标准独立性假设重新定义为在某些辅助变量（例如类标签和/或域/时间索引）给定的条件独立性，作为弱监督或归纳偏置。然而，具有无条件先验的非线性ICA无法从这些发展中受益。我们探索了一条替代路径，并仅考虑混合过程的假设，例如结构稀疏性。我们展示了在这些约束的具体实例下，独立的潜在分量可以从其非线性混合中辨识出来，达到非平凡的非线性ICA可识别性，而无需辅助变量。

    Nonlinear independent component analysis (ICA) aims to recover the underlying independent latent sources from their observable nonlinear mixtures. How to make the nonlinear ICA model identifiable up to certain trivial indeterminacies is a long-standing problem in unsupervised learning. Recent breakthroughs reformulate the standard independence assumption of sources as conditional independence given some auxiliary variables (e.g., class labels and/or domain/time indexes) as weak supervision or inductive bias. However, nonlinear ICA with unconditional priors cannot benefit from such developments. We explore an alternative path and consider only assumptions on the mixing process, such as Structural Sparsity. We show that under specific instantiations of such constraints, the independent latent sources can be identified from their nonlinear mixtures up to a permutation and a component-wise transformation, thus achieving nontrivial identifiability of nonlinear ICA without auxiliary variable
    
[^289]: 基于语义驱动的提案生成的全场景图像文字人物搜索

    Text-based Person Search in Full Images via Semantic-Driven Proposal Generation. (arXiv:2109.12965v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2109.12965](http://arxiv.org/abs/2109.12965)

    本文提出了一种基于语义驱动的提案生成的全场景图像文字人物搜索方法，通过端到端学习优化行人检测、身份识别和视觉-语义特征嵌入任务，并利用语义特征指导区域建议网络关注文本描述的提案。使用跨尺度的视觉-语义嵌入机制来提高性能

    

    在智能视频监控中，使用文本描述来在全场景图像中找到目标人物具有重要的实际应用。然而，与现实世界的场景不同，在现有的基于文本的人物检索方法中，主要集中在查询文本描述和裁剪的行人图像库之间的跨模态匹配。为了弥补这个差距，我们研究了基于文本的全场景图像中的人物搜索问题，提出了一个新的端到端学习框架，同时优化行人检测、身份识别和视觉-语义特征嵌入任务。为了充分利用查询文本，语义特征被利用来指导区域建议网络更关注文本描述的提案。此外，还利用了跨尺度的视觉-语义嵌入机制来提高性能。为了验证所提出的方法，我们收集并标注了两个大规模的基准数据集。

    Finding target persons in full scene images with a query of text description has important practical applications in intelligent video surveillance.However, different from the real-world scenarios where the bounding boxes are not available, existing text-based person retrieval methods mainly focus on the cross modal matching between the query text descriptions and the gallery of cropped pedestrian images. To close the gap, we study the problem of text-based person search in full images by proposing a new end-to-end learning framework which jointly optimize the pedestrian detection, identification and visual-semantic feature embedding tasks. To take full advantage of the query text, the semantic features are leveraged to instruct the Region Proposal Network to pay more attention to the text-described proposals. Besides, a cross-scale visual-semantic embedding mechanism is utilized to improve the performance. To validate the proposed method, we collect and annotate two large-scale benchm
    

