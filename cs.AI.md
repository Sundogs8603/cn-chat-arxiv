# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Demographic Bias of Expert-Level Vision-Language Foundation Models in Medical Imaging](https://arxiv.org/abs/2402.14815) | 本研究调查了全球五个数据集中最先进的视觉语言基础模型在胸片诊断中的算法公平性。我们的发现表明，与董事会认证的放射科医师相比，这些基础模型在诊断边缘化群体时一贯存在低诊断率，甚至在诸如黑人女性之类的交叉亚组中看到更高的比例。 |
| [^2] | [WeakSAM: Segment Anything Meets Weakly-supervised Instance-level Recognition](https://arxiv.org/abs/2402.14812) | WeakSAM通过利用预先学习的全球知识，解决了弱监督对象检测和分割问题，提出了自适应PGT生成和RoI丢弃正则化，显著超越了先前的最先进方法。 |
| [^3] | [GeneOH Diffusion: Towards Generalizable Hand-Object Interaction Denoising via Denoising Diffusion](https://arxiv.org/abs/2402.14810) | 通过GeneOH扩散方法，实现了可泛化的手-物体交互去噪，其中关键创新包括基于接触的HOI表示和领域通用的去噪方案。 |
| [^4] | [CriticBench: Benchmarking LLMs for Critique-Correct Reasoning](https://arxiv.org/abs/2402.14809) | CriticBench是一个综合基准测试，旨在评估LLMs在批判和纠正推理方面的能力，发现批判性训练显著提升性能，逻辑任务更易于修正。 |
| [^5] | [A Decision-Language Model (DLM) for Dynamic Restless Multi-Armed Bandit Tasks in Public Health](https://arxiv.org/abs/2402.14807) | 提出了一种决策语言模型DLM，旨在通过使用LLMs作为自动规划器，动态微调RMAB策略，以应对公共卫生中具有挑战性的情境。 |
| [^6] | [Identifying Multiple Personalities in Large Language Models with External Evaluation](https://arxiv.org/abs/2402.14805) | 通过外部评估方法研究大型语言模型的人格特征 |
| [^7] | [Measuring Multimodal Mathematical Reasoning with MATH-Vision Dataset](https://arxiv.org/abs/2402.14804) | 提出了MATH-Vision（MATH-V）数据集，用于评估大型多模态模型（LMMs）的数学推理能力，通过实验证实了当前LMMs和人类在MATH-V上的表现差距。 |
| [^8] | [Not All Experts are Equal: Efficient Expert Pruning and Skipping for Mixture-of-Experts Large Language Models](https://arxiv.org/abs/2402.14800) | 引入了专家级稀疏化技术，提出了专家修剪和跳过的后训练方法，以提高MoE LLMs的部署效率，同时保持模型性能。 |
| [^9] | [Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic](https://arxiv.org/abs/2402.14798) | 本文提出了一种一致且在理论上有根据的方法来注释分解蕴涵数据集，形成RDTE数据集，该数据集在解决何为有效的组合蕴涵的问题上有显著进展。 |
| [^10] | [Snap Video: Scaled Spatiotemporal Transformers for Text-to-Video Synthesis](https://arxiv.org/abs/2402.14797) | Snap Video是一个视频优先模型，通过扩展EDM框架并提出基于Transformer的架构，解决了文本到视频合成中的动态保真度、视觉质量和可扩展性挑战。 |
| [^11] | [Self-Guided Masked Autoencoders for Domain-Agnostic Self-Supervised Learning](https://arxiv.org/abs/2402.14789) | 自导蒙面自动编码器（SMA）是一种完全领域无关的蒙面建模方法，通过学习蒙面采样而不做任何领域特定的假设，可以在各种数据模态上进行自监督学习。 |
| [^12] | [Rao-Blackwellising Bayesian Causal Inference](https://arxiv.org/abs/2402.14781) | 本文结合顺序化的MCMC结构学习技术和梯度图学习的最新进展，构建了一个有效的贝叶斯因果推断框架，将因果结构推断问题分解为变量拓扑顺序推断和变量父节点集合推断，同时使用高斯过程进行因果机制建模实现精确边缘化，引入了一个Rao-Blackwell化方案。 |
| [^13] | [Zero-shot cross-lingual transfer in instruction tuning of large language model](https://arxiv.org/abs/2402.14778) | 本研究探讨了大型语言模型在指令微调中的零次跨语言转移，发现在适当超参数调整和足够大的数据支持下，英语训练的模型能够成功生成其他语言的准确、有用回应，但存在事实准确性和流畅性错误。 |
| [^14] | [MT-Bench-101: A Fine-Grained Benchmark for Evaluating Large Language Models in Multi-Turn Dialogues](https://arxiv.org/abs/2402.14762) | 提出了MT-Bench-101用于评估大型语言模型在多轮对话中的细粒度能力，构建了包含4208轮对话数据的三级分层能力分类，并评估了21种流行的语言模型，发现它们在不同对话轮次中表现出不同的趋势。 |
| [^15] | [Generalising realisability in statistical learning theory under epistemic uncertainty](https://arxiv.org/abs/2402.14759) | 统计学习理论中的中心概念在假设训练和测试分布源自相同置信集的情况下如何推广，是对统计学习在认知不确定性下更一般处理的首要步骤。 |
| [^16] | [Batch and match: black-box variational inference with a score-based divergence](https://arxiv.org/abs/2402.14758) | BaM是一种基于分数的离散的BBVI替代方法，针对高方差梯度估计慢收敛问题，能够在高斯变分族中通过封闭形式的近端更新进行优化，在目标分布为高斯时，批处理大小趋于无穷时变分参数更新将指数快速收敛到目标均值和协方差，BaM在多种生成模型推断中表现出良好性能 |
| [^17] | [SHM-Traffic: DRL and Transfer learning based UAV Control for Structural Health Monitoring of Bridges with Traffic](https://arxiv.org/abs/2402.14757) | 该研究提出了一种基于DRL和迁移学习的无人机控制方法，用于带交通的桥梁结构健康监测，实现了在交通持续进行时对混凝土桥面进行裂缝检测和定位的具体桥面检测技术应用 |
| [^18] | [Prompting a Pretrained Transformer Can Be a Universal Approximator](https://arxiv.org/abs/2402.14753) | 这项研究表明，通过提示或前缀调整Pretrained Transformer可以成为通用逼近器，甚至比之前认为的更小的模型都可以实现这一功能。 |
| [^19] | [Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation](https://arxiv.org/abs/2402.14744) | 提出了一种将大型语言模型LLMs整合到代理框架中的新方法，用于生成个人移动生成，重点是解决将LLMs与真实城市流动数据对齐的问题，并提出了一种自洽方法和检索增强策略来实现可解释活动生成。 |
| [^20] | [Clifford-Steerable Convolutional Neural Networks](https://arxiv.org/abs/2402.14730) | 提出了Clifford-Steerable卷积神经网络（CS-CNNs），通过在伪欧几里德空间上处理多矢场，利用Clifford群等变神经网络对$\mathrm{O}(p,q)$可导核进行隐式参数化，显着且一致地优于流体动力学和相对论电动力学预测任务的基准方法 |
| [^21] | [The European Commitment to Human-Centered Technology: The Integral Role of HCI in the EU AI Act's Success](https://arxiv.org/abs/2402.14728) | 欧盟AI法案强调透明性、可解释性和人类理解能力，提出了人本AI系统的民主呼吁，同时制定了人本创新的跨学科研究议程，以避免重复GDPR的错误并避免实施混乱。 |
| [^22] | [Incorporating Expert Rules into Neural Networks in the Framework of Concept-Based Learning](https://arxiv.org/abs/2402.14726) | 本文提出了将专家规则融入神经网络的方法，通过形成约束和使用凸多面体来保证输出概率不违反专家规则，实现了归纳与演绎学习的结合。 |
| [^23] | [Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models](https://arxiv.org/abs/2402.14714) | 提出了一种高效且有效的词汇扩展方法（EEVE），可以显著提升非英语语言模型的性能，使得其在韩文文本理解方面表现出色。 |
| [^24] | [IEPile: Unearthing Large-Scale Schema-Based Information Extraction Corpus](https://arxiv.org/abs/2402.14710) | 发布了IEPile，一个包含约0.32B个标记的综合双语IE指令语料库，通过收集和清理33个现有IE数据集并引入基于模式的指令生成，可以提高大型语言模型在信息抽取领域的性能，尤其是零样本泛化。 |
| [^25] | [CaT-GNN: Enhancing Credit Card Fraud Detection via Causal Temporal Graph Neural Networks](https://arxiv.org/abs/2402.14708) | 该论文提出了一种名为CaT-GNN的新型信用卡欺诈检测方法，通过因果不变性学习揭示交易数据中的固有相关性，并引入因果混合策略来增强模型的鲁棒性和可解释性。 |
| [^26] | [On the Curses of Future and History in Future-dependent Value Functions for Off-policy Evaluation](https://arxiv.org/abs/2402.14703) | 本文提出了针对POMDP结构的新颖覆盖假设，以解决未来依赖价值函数方法中的长度指数增长问题。 |
| [^27] | [COMPASS: Computational Mapping of Patient-Therapist Alliance Strategies with Language Modeling](https://arxiv.org/abs/2402.14701) | 本文提出了一种名为COMPASS的新框架，通过分析心理治疗会话中的自然语言，直接推断治疗工作联盟，为临床精神病学提供了可解释性，并在识别与正在治疗的疾病相关的新兴模式方面发挥作用。 |
| [^28] | [Big data analytics to classify earthwork-related locations: A Chengdu study](https://arxiv.org/abs/2402.14698) | 使用大数据分析方法，研究者利用自卸车轨迹、城市兴趣点和土地覆盖数据，成功对城市灰尘污染源进行了分类，证明仅需有限数量特征即可实现高准确度分类。 |
| [^29] | [Visual Hallucinations of Multi-modal Large Language Models](https://arxiv.org/abs/2402.14683) | 多模大语言模型通过生成多样的视觉幻觉实例来检验其性能，发现现有的模型在这方面存在幻觉问题，为进一步研究和改进提供了线索。 |
| [^30] | [Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments](https://arxiv.org/abs/2402.14672) | 这项研究探索了在复杂环境中利用工具增强大型语言模型的潜力，设计了定制化工具来辅助语言代理在庞大环境中进行探索，并展示了在知识库和数据库等复杂环境中，借助工具增强语言代理的重要潜力。 |
| [^31] | [Bayesian Off-Policy Evaluation and Learning for Large Action Spaces](https://arxiv.org/abs/2402.14664) | 该论文提出了一个统一的贝叶斯框架，通过结构化和信息丰富的先验捕捉动作之间的相关性，提出了一个适用于离策略评估和学习的通用贝叶斯方法sDM，并引入了能评估算法在多问题实例中平均表现的贝叶斯指标，分析了sDM在OPE和OPL中利用动作相关性的优势，并展示了其强大性能 |
| [^32] | [ConceptMath: A Bilingual Concept-wise Benchmark for Measuring Mathematical Reasoning of Large Language Models](https://arxiv.org/abs/2402.14660) | 介绍了ConceptMath，一种双语的细粒度基准测试，用于评估大型语言模型的概念性数学推理能力，并发现现有模型在不同数学概念上存在显著性能差异，甚至可能在最基本的概念上出现失败。 |
| [^33] | [OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement](https://arxiv.org/abs/2402.14658) | OpenCodeInterpreter是一种开源代码系统，集成了执行、人类反馈和动态代码细化的功能，并在关键基准测试中表现出色，甚至与GPT-4相媲美。 |
| [^34] | [Rethinking Invariance Regularization in Adversarial Training to Improve Robustness-Accuracy Trade-off](https://arxiv.org/abs/2402.14648) | 重新审视了基于表示的不变性正则化方法，提出了Asymmetrically Representation-regularized Adversarial Training (AR-AT)来解决“梯度冲突”和混合分布问题，改善鲁棒性-准确性权衡。 |
| [^35] | [RoboScript: Code Generation for Free-Form Manipulation Tasks across Real and Simulation](https://arxiv.org/abs/2402.14623) | RoboScript是一个旨在填补“理想到实际”差距的平台，提供可部署的机器人操作流水线，并为自然语言中的机器人操作任务提供代码生成基准。 |
| [^36] | [From Keywords to Structured Summaries: Streamlining Scholarly Knowledge Access](https://arxiv.org/abs/2402.14622) | 该论文突出了信息检索引擎在科学界的重要性，并提出了一种通过结构化记录和先进信息技术工具实现的解决方案，以革新研究人员访问和过滤文章的方式。 |
| [^37] | [Federated Complex Qeury Answering](https://arxiv.org/abs/2402.14609) | 研究了在多源知识图谱上回答复杂查询的联邦式方法，解决了知识图谱中的隐私保护和答案检索的挑战 |
| [^38] | [Bringing Generative AI to Adaptive Learning in Education](https://arxiv.org/abs/2402.14601) | 生成式人工智能技术与自适应学习概念的交叉研究将对教育中下一阶段学习格式的发展做出重要贡献。 |
| [^39] | [Diffusion Model-Based Multiobjective Optimization for Gasoline Blending Scheduling](https://arxiv.org/abs/2402.14600) | 该论文介绍了一种基于扩散模型的汽油调配调度多目标优化方法，通过解决整数约束和生成可行调度，实现了同时达到多个优化目标并遵守约束条件。 |
| [^40] | [The Role of LLMs in Sustainable Smart Cities: Applications, Challenges, and Future Directions](https://arxiv.org/abs/2402.14596) | 本文探讨了LLM在优化智慧城市中的ICT流程方面的重要潜力和应用。 |
| [^41] | [Improving Assessment of Tutoring Practices using Retrieval-Augmented Generation](https://arxiv.org/abs/2402.14594) | 通过利用生成预训练变换器来自动评估辅导员使用社交情感辅导策略的能力，从而改进辅导实践评估。 |
| [^42] | [Enhancement of High-definition Map Update Service Through Coverage-aware and Reinforcement Learning](https://arxiv.org/abs/2402.14582) | 本文提出了一种Q学习覆盖时间感知算法，以优化车载网络和HD地图更新的服务质量，以克服网络拥塞。 |
| [^43] | [Savvy: Trustworthy Autonomous Vehicles Architecture](https://arxiv.org/abs/2402.14580) | 提出了一种新的可信智能自动驾驶汽车架构Savvy，通过清晰分离控制平面和数据平面，实现了安全优先原则，使得在安全时间范围内尽可能优化决策。 |
| [^44] | [Transformable Gaussian Reward Function for Socially-Aware Navigation with Deep Reinforcement Learning](https://arxiv.org/abs/2402.14569) | 引入了可变换高斯奖励函数(TGRF)来解决强化学习中社交感知导航奖励设计复杂、超参数冗余和不平衡的问题 |
| [^45] | [CLCE: An Approach to Refining Cross-Entropy and Contrastive Learning for Optimized Learning Fusion](https://arxiv.org/abs/2402.14551) | CLCE方法结合了标签感知对比学习与交叉熵损失，通过协同利用难例挖掘提高了性能表现 |
| [^46] | [OmniPred: Language Models as Universal Regressors](https://arxiv.org/abs/2402.14547) | 本文提出了OmniPred框架，用于训练语言模型作为通用的端到端回归器，实验证明，在多个任务上训练时，语言模型能够显著优于传统回归模型。 |
| [^47] | [ACE : Off-Policy Actor-Critic with Causality-Aware Entropy Regularization](https://arxiv.org/abs/2402.14528) | 该论文提出了ACE算法，通过引入因果感知熵正则化，有效评估不同行为的重要性，并分析梯度休眠现象，引入休眠引导复位机制，在多个连续控制任务中取得显著性能优势。 |
| [^48] | [Balanced Data Sampling for Language Model Training with Clustering](https://arxiv.org/abs/2402.14526) | 本文提出了一种名为ClusterClip Sampling的数据抽样方法，利用数据聚类平衡训练数据的文本分布，为更好的模型训练提供支持。 |
| [^49] | [Towards Seamless Adaptation of Pre-trained Models for Visual Place Recognition](https://arxiv.org/abs/2402.14505) | 提出了一种新颖的方法，实现了预训练模型对视觉地点识别的无缝适应 |
| [^50] | [A Collision-Aware Cable Grasping Method in Cluttered Environment](https://arxiv.org/abs/2402.14498) | 提出了一种碰撞感知的电缆抓取方法，通过CG-CNN和数据集生成技术，在复杂环境中实现稳健电缆抓取，并取得了出色的成功率。 |
| [^51] | [INSTRAUG: Automatic Instruction Augmentation for Multimodal Instruction Fine-tuning](https://arxiv.org/abs/2402.14492) | INSTRAUG是一种自动指令增强方法，可以在多模任务中显著改善多模大型语言模型的对齐，相当于增加训练规模的好处。 |
| [^52] | [Are Bounded Contracts Learnable and Approximately Optimal?](https://arxiv.org/abs/2402.14486) | 分析了在隐藏动作模型下的合同与委托-代理问题，提出了两个学习算法可以找到几乎最优的有界合同，对于一般情况的查询次数具有多项式上界，并且直接学习潜在的结果分布。 |
| [^53] | [Personalized Behavior-Aware Transformer for Multi-Behavior Sequential Recommendation](https://arxiv.org/abs/2402.14473) | 个性化行为感知Transformer框架用于多行为顺序推荐，旨在更好地探索用户的潜在意图，并解决短序列下推荐性能降低的问题。 |
| [^54] | [Reframing the Expected Free Energy: Four Formulations and a Unification](https://arxiv.org/abs/2402.14460) | 主动推断理论基于预期自由能，本文尝试通过统一根预期自由能的定义来推导四种公式，研究了两种设置，并提出了限制代理对观察具有任意先验偏好的观点。 |
| [^55] | [NLAS-multi: A Multilingual Corpus of Automatically Generated Natural Language Argumentation Schemes](https://arxiv.org/abs/2402.14458) | 该论文提出了一个多语言自动生成的自然语言论证架构语料库，包括自动生成自然语言论证的有效方法、最大的公开可用的语料库以及用于自动识别论证架构的基线和模型。 |
| [^56] | [A Language Model's Guide Through Latent Space](https://arxiv.org/abs/2402.14433) | 本文将语言模型概念引导框架扩展到更丰富的概念集，探索当前检测和引导策略在适当性、幽默、创造力和质量等挑战性环境下的适用程度。 |
| [^57] | [KoCoSa: Korean Context-aware Sarcasm Detection Dataset](https://arxiv.org/abs/2402.14428) | 该论文介绍了一个新的针对韩文对话讽刺检测任务的数据集KoCoSa，提出了一种高效的讽刺检测数据集生成流程，并提供了针对该任务的简单但有效的基线模型。 |
| [^58] | [Automating Psychological Hypothesis Generation with AI: Large Language Models Meet Causal Graph](https://arxiv.org/abs/2402.14424) | 利用大型语言模型和因果图结合的方法，在心理学假设生成中取得了突破，结果显示这种联合方法在新颖性方面明显优于仅使用大型语言模型的假设。 |
| [^59] | [Uncertainty-Aware Evaluation for Vision-Language Models](https://arxiv.org/abs/2402.14418) | 提出了一个新的基准来评估视觉语言模型，该基准将不确定性量化融入评估过程中，揭示了准确性最高的模型可能也具有最高不确定性的重要性。 |
| [^60] | [Tug-of-War Between Knowledge: Exploring and Resolving Knowledge Conflicts in Retrieval-Augmented Language Models](https://arxiv.org/abs/2402.14409) | 本文探讨了检索增强语言模型中的知识冲突，提出了评估框架，研究了RALMs对内部记忆和外部来源间的冲突，发现了它们会偏向错误的内部记忆。 |
| [^61] | [On the Tip of the Tongue: Analyzing Conceptual Representation in Large Language Models with Reverse-Dictionary Probe](https://arxiv.org/abs/2402.14404) | 该论文通过重新利用反向词典任务的案例研究，探查了大型语言模型对概念推理的能力，发现模型在该任务中表现出高准确性，并且表示空间编码了有关对象类别和细粒度特征的信息，同时还发现该任务探查的概念推理能力能够预测模型在多个基准测试中的一般推理表现。 |
| [^62] | [Ensure Timeliness and Accuracy: A Novel Sliding Window Data Stream Paradigm for Live Streaming Recommendation](https://arxiv.org/abs/2402.14399) | 提出了一种名为Sliver的滑动窗口数据流设计范式，通过减小窗口大小和实现滑动窗口来解决实时推荐系统中标签的及时性和准确性问题 |
| [^63] | [Gradual Residuals Alignment: A Dual-Stream Framework for GAN Inversion and Image Attribute Editing](https://arxiv.org/abs/2402.14398) | 本研究提出了逐步残余对齐的双流框架，通过多阶段粗到细的方式逐渐将细节注入到重构和编辑过程中，以提高细节保留和编辑性。 |
| [^64] | [Dependable Distributed Training of Compressed Machine Learning Models](https://arxiv.org/abs/2402.14346) | 提出了DepL框架，实现了可靠的学习编排，能够确保以最低训练成本达到目标学习质量。 |
| [^65] | [HyperFast: Instant Classification for Tabular Data](https://arxiv.org/abs/2402.14335) | HyperFast是一个针对表格数据的即时分类方法，通过在单次前向传递中生成特定任务的神经网络，避免了需进行模型训练的必要性，并在实验中展现出高度竞争力。 |
| [^66] | [REPOFUSE: Repository-Level Code Completion with Fused Dual Context](https://arxiv.org/abs/2402.14323) | RepoGenix独特融合类比上下文和理性上下文，并提出了截断排名生成（RTG）技术，以提高仓库级代码自动补全的准确性而不牺牲推理效率。 |
| [^67] | [Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering](https://arxiv.org/abs/2402.14320) | Triad框架利用了基于多角色LLM代理来解决知识库问答问题，通过代理的不同角色分别处理KBQA子任务，合作完成KBQA任务，并在多个基准数据集上表现出色。 |
| [^68] | [Vision-Language Navigation with Embodied Intelligence: A Survey](https://arxiv.org/abs/2402.14304) | VLN作为实现实体智能的关键研究路径，致力于探索如何使用自然语言进行有效交流，实现准确导航，并融合了人工智能、自然语言处理、计算机视觉和机器人技术。 |
| [^69] | [We Choose to Go to Space: Agent-driven Human and Multi-Robot Collaboration in Microgravity](https://arxiv.org/abs/2402.14299) | 提出了SpaceAgents-1系统，该系统使用分层异构多代理协作架构，在微重力环境下学习人类与多机器人协作策略。 |
| [^70] | [Mitigating the Linguistic Gap with Phonemic Representations for Robust Multilingual Language Understanding](https://arxiv.org/abs/2402.14279) | 通过使用音素表示，本文提出了一种新颖的解决方案来减缓高资源语言和低资源语言之间的性能差距，并通过实证研究和理论分析证明了其有效性。 |
| [^71] | [GATE X-E : A Challenge Set for Gender-Fair Translations from Weakly-Gendered Languages](https://arxiv.org/abs/2402.14277) | 引入了GATE X-E挑战集，包含了从土耳其语、匈牙利语、芬兰语和波斯语翻译成英语的人类翻译，旨在评估弱性别语言到英语的翻译中的性别偏见并提出缓解策略。 |
| [^72] | [Can Large Language Models Detect Misinformation in Scientific News Reporting?](https://arxiv.org/abs/2402.14268) | 大型语言模型探测科学报道中的错误信息的可行性，绕过生成明确标记索赔的步骤，处理现实场景中可能不存在明确标记索赔的挑战。 |
| [^73] | [Copilot Evaluation Harness: Evaluating LLM-Guided Software Programming](https://arxiv.org/abs/2402.14261) | 本文介绍了Copilot评估工具，用于评估LLM引导的IDE交互，在各种编程场景和语言中提供更为稳健和信息密集的评估。 |
| [^74] | [Word-Sequence Entropy: Towards Uncertainty Estimation in Free-Form Medical Question Answering Applications and Beyond](https://arxiv.org/abs/2402.14259) | 本论文提出了一种新方法单词序列熵（WSE），用于在自由形式医学问答任务中量化答案的不确定性，相比其他基线方法表现更优秀。 |
| [^75] | [Enhancing Robotic Manipulation with AI Feedback from Multimodal Large Language Models](https://arxiv.org/abs/2402.14245) | 利用多模态大语言模型为机器人操作提供自动偏好反馈，提升决策效果 |
| [^76] | [MENTOR: Guiding Hierarchical Reinforcement Learning with Human Feedback and Dynamic Distance Constraint](https://arxiv.org/abs/2402.14244) | 使用人类反馈和动态距离约束对层次化强化学习进行引导，解决了找到适当子目标的问题，并设计了双策略以稳定训练。 |
| [^77] | [A Self-supervised Pressure Map human keypoint Detection Approch: Optimizing Generalization and Computational Efficiency Across Datasets](https://arxiv.org/abs/2402.14241) | 提出了一种自监督压力图关键点检测方法，采用Encoder-Fuser-Decoder（EFD）模型和分类到回归权重转移（CRWT）方法，在不需要手动标注的情况下提高了人体关键点的泛化能力和计算效率。 |
| [^78] | [Automated Design and Optimization of Distributed Filtering Circuits via Reinforcement Learning](https://arxiv.org/abs/2402.14236) | 提出一种通过强化学习算法实现的自动化设计方法，显著提高了分布式滤波电路设计的效率和质量。 |
| [^79] | [MerRec: A Large-scale Multipurpose Mercari Dataset for Consumer-to-Consumer Recommendation Systems](https://arxiv.org/abs/2402.14230) | 提出了MerRec，这是首个专门针对C2C推荐而提出的大规模数据集，填补了C2C推荐数据集中物品属性、用户多样性和规模等方面的缺失。 |
| [^80] | [COPR: Continual Human Preference Learning via Optimal Policy Regularization](https://arxiv.org/abs/2402.14228) | 提出了Continual Optimal Policy Regularization (COPR) 方法，通过借鉴最优策略理论，利用采样分布作为示范和正则化约束，以动态地对当前策略进行正则化，从而使强化学习从人类反馈中学习在持续学习情境下更加稳健 |
| [^81] | [Moonwalk: Inverse-Forward Differentiation](https://arxiv.org/abs/2402.14212) | Moonwalk引入了一种基于向量-逆-Jacobian乘积的新技术，加速前向梯度计算，显著减少内存占用，并在保持真实梯度准确性的同时，将计算时间降低了几个数量级。 |
| [^82] | [Content Conditional Debiasing for Fair Text Embedding](https://arxiv.org/abs/2402.14208) | 通过在内容条件下确保敏感属性与文本嵌入之间的条件独立性，我们提出了一种可以改善公平性的新方法，在保持效用的同时，解决了缺乏适当训练数据的问题。 |
| [^83] | [Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models](https://arxiv.org/abs/2402.14207) | 提出了一种名为STORM的写作系统，用于通过检索和多视角提问合成主题概要，以辅助从头开始写类似维基百科的文章。 |
| [^84] | [From Adoption to Adaption: Tracing the Diffusion of New Emojis on Twitter](https://arxiv.org/abs/2402.14187) | 本研究通过分析英文推文数据集，探讨了新表情符号在Twitter上的传播情况，发现早期采纳者规模和表情符号语义对其流行度至关重要，并提出了一个新框架来解释新表情符号，从而改善情感分类性能。 |
| [^85] | [Do Machines and Humans Focus on Similar Code? Exploring Explainability of Large Language Models in Code Summarization](https://arxiv.org/abs/2402.14182) | 本研究通过眼动追踪指标和 SHAP 方法对比了人类与语言模型在代码总结中的关注重点，展示了语言模型解释性的负面结果。 |
| [^86] | [Bangla AI: A Framework for Machine Translation Utilizing Large Language Models for Ethnic Media](https://arxiv.org/abs/2402.14179) | 该研究探讨了如何在民族媒体领域整合大型语言模型和多语言机器翻译，以提升新闻翻译、搜索和分类的效率和准确性。 |
| [^87] | [Blending Data-Driven Priors in Dynamic Games](https://arxiv.org/abs/2402.14174) | 探索一种在动态游戏中将数据驱动参考政策与基于优化博弈政策相融合的方法，提出了一种非合作动态博弈KLGame，其中包含了针对每个决策者的可调参数。 |
| [^88] | [On Large Visual Language Models for Medical Imaging Analysis: An Empirical Study](https://arxiv.org/abs/2402.14162) | 本研究探讨了大型视觉语言模型在医学影像分析任务中的零样本和少样本鲁棒性，证实了它们在分析生物医学图像方面的有效性。 |
| [^89] | [Recursive Speculative Decoding: Accelerating LLM Inference via Sampling Without Replacement](https://arxiv.org/abs/2402.14160) | 提出了递归推测解码(RSD)方法，通过无重复抽样最大化树的多样性，从而进一步加速LLM推理过程。 |
| [^90] | [Can Similarity-Based Domain-Ordering Reduce Catastrophic Forgetting for Intent Recognition?](https://arxiv.org/abs/2402.14155) | 研究探讨了三种领域排序策略对生成式意图识别模型继续学习性能的影响，填补了现有研究中对此方面未探索的空白。 |
| [^91] | [BIRCO: A Benchmark of Information Retrieval Tasks with Complex Objectives](https://arxiv.org/abs/2402.14151) | BIRCO基准评估基于大型语言模型的信息检索系统对多方面用户目标的检索能力，发现新的检索协议和更强大的模型是解决复杂用户需求的必要条件。 |
| [^92] | [Wikibench: Community-Driven Data Curation for AI Evaluation on Wikipedia](https://arxiv.org/abs/2402.14147) | Wikibench是一个系统，使社区能够协作整理AI评估数据集，有效捕捉社区共识、分歧和不确定性。 |
| [^93] | [SecurePose: Automated Face Blurring and Human Movement Kinematics Extraction from Videos Recorded in Clinical Settings](https://arxiv.org/abs/2402.14143) | SecurePose是一个开源软件，可以可靠地实现临床录制的患者视频中的人脸模糊和动力学特征提取，提高了视频评估和患者隐私的安全性。 |
| [^94] | [DeiSAM: Segment Anything with Deictic Prompting](https://arxiv.org/abs/2402.14123) | DeiSAM提出将大型预训练神经网络与可区分逻辑推理器结合，用于指示提示性分割，实现了在复杂场景中对象的分割 |
| [^95] | [Masked Matrix Multiplication for Emergent Sparsity](https://arxiv.org/abs/2402.14118) | 提出了一种用于紧急稀疏性的掩码矩阵乘法系统，可以通过运行时评估稀疏度来消除不必要的计算和避免分支，实现了较低指令数和更高性能。 |
| [^96] | [FanOutQA: Multi-Hop, Multi-Document Question Answering for Large Language Models](https://arxiv.org/abs/2402.14116) | FanOutQA 提出了一个高质量的多跳、多文档问答数据集，用于评估大型语言模型在复杂推理能力上的表现，并发现当代模型在长篇上下文中仍有改进交叉文档依赖推理的空间。 |
| [^97] | [EyeTrans: Merging Human and Machine Attention for Neural Code Summarization](https://arxiv.org/abs/2402.14096) | 引入EyeTrans方法，将人类注意力融入机器注意力，以增强神经代码摘要能力。 |
| [^98] | [Zero-shot generalization across architectures for visual classification](https://arxiv.org/abs/2402.14095) | 不同神经网络在跨架构和层间泛化到未知类别的能力存在差异，准确性并不是泛化能力的良好预测因子，泛化能力随着层深度呈非单调变化。 |
| [^99] | [Social Environment Design](https://arxiv.org/abs/2402.14090) | 该论文提出了一种新的研究议程，介绍了社会环境设计作为一种用于自动化政策制定的AI通用框架，旨在捕捉一般经济环境，通过AI模拟系统分析政府和经济政策，并强调未来基于AI的政策制定研究中的关键挑战。 |
| [^100] | [LexC-Gen: Generating Data for Extremely Low-Resource Languages with Large Language Models and Bilingual Lexicons](https://arxiv.org/abs/2402.14086) | LexC-Gen提出了一种词典条件数据生成方法，可以以大规模生成低资源语言分类任务数据，取得了较好的效果。 |
| [^101] | [Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping](https://arxiv.org/abs/2402.14083) | 通过专家迭代训练的Searchformer模型，可以更少的搜索步骤来解决复杂规划任务，同时生成最佳计划。 |
| [^102] | [Robust Learning of Noisy Time Series Collections Using Stochastic Process Models with Motion Codes](https://arxiv.org/abs/2402.14081) | 使用具有学习谱核的混合高斯过程的潜变量模型方法，针对嘈杂时间序列数据进行鲁棒学习。 |
| [^103] | [Efficient Normalized Conformal Prediction and Uncertainty Quantification for Anti-Cancer Drug Sensitivity Prediction with Deep Regression Forests](https://arxiv.org/abs/2402.14080) | 通过深度回归森林计算样本方差，提高了抗癌药物敏感性预测中的规范化置信预测效率和覆盖率 |
| [^104] | [Generative Adversarial Models for Extreme Downscaling of Climate Datasets](https://arxiv.org/abs/2402.14049) | 该方法提出了一种基于条件GAN的地理空间数据缩放方法，可以从非常低分辨率的输入生成高分辨率准确的气候数据集，并且明确考虑了不确定性。 |
| [^105] | [PolyNet: Learning Diverse Solution Strategies for Neural Combinatorial Optimization](https://arxiv.org/abs/2402.14048) | PolyNet通过学习互补解决策略来改善解空间探索，避免了人为规则导致解决方案质量下降的问题。 |
| [^106] | [Simple and Effective Transfer Learning for Neuro-Symbolic Integration](https://arxiv.org/abs/2402.14047) | 提出了一种简单而有效的方法，通过在下游任务上预训练神经模型，然后通过迁移学习在相同任务上对NeSy模型进行训练，以实现神经符号一体化的改进。 |
| [^107] | [A new approach for solving global optimization and engineering problems based on modified Sea Horse Optimizer](https://arxiv.org/abs/2402.14044) | 该研究提出了一种名为mSHO的全新SHO算法变体，通过创新的本地搜索策略，分为邻域局部搜索、全局非邻域搜索和绕行方法，主要增强了SHO算法的开发能力。 |
| [^108] | [Protect and Extend -- Using GANs for Synthetic Data Generation of Time-Series Medical Records](https://arxiv.org/abs/2402.14042) | 本研究使用GANs生成了时间序列合成痴呆患者医疗记录的数据集，并比较了不同GAN模型在生成合成数据方面的质量，实现了在不涉及隐私问题的情况下保护用户数据并延伸数据应用。 |
| [^109] | [E2USD: Efficient-yet-effective Unsupervised State Detection for Multivariate Time Series](https://arxiv.org/abs/2402.14041) | E2USD提出了一种有效的无监督多元时间序列状态检测方法，利用了快速傅里叶变换和双视图嵌入模块进行编码，以及通过对抗学习方法消除假阴性，从而实现了SOTA准确性并显著降低了计算开销。 |
| [^110] | [Specialty detection in the context of telemedicine in a highly imbalanced multi-class distribution](https://arxiv.org/abs/2402.14039) | 提出基于机器学习模型的专业检测分类器，用于自动化检测每个问题的正确专业并将其路由到正确的医生，重点是处理阿拉伯医疗问题的多类别和高度不平衡数据集。 |
| [^111] | [An Effective Networks Intrusion Detection Approach Based on Hybrid Harris Hawks and Multi-Layer Perceptron](https://arxiv.org/abs/2402.14037) | 提出了一种利用哈里斯鹰优化算法来优化多层感知器学习的入侵检测系统，实现了在网络中最小化入侵检测错误，实验结果表明该方法有效识别恶意模式。 |
| [^112] | [Wisdom of Committee: Distilling from Foundation Model to SpecializedApplication Model](https://arxiv.org/abs/2402.14035) | 将基础模型的知识转移到专用应用模型中存在挑战，提出了通过创建教学委员会来应对这些挑战。 |
| [^113] | [AgentScope: A Flexible yet Robust Multi-Agent Platform](https://arxiv.org/abs/2402.14034) | AgentScope是一个开发者中心的多代理平台，提供了以消息交换为核心通信机制，大大降低了开发和理解的障碍，同时具备灵活的容错机制和多模态数据处理的系统级支持。 |
| [^114] | [VN Network: Embedding Newly Emerging Entities with Virtual Neighbors](https://arxiv.org/abs/2402.14033) | 提出了一个名为虚拟邻居（VN）网络的新框架，以解决实体嵌入中的邻居稀疏问题，并有效整合远距离信息。 |
| [^115] | [Partial Search in a Frozen Network is Enough to Find a Strong Lottery Ticket](https://arxiv.org/abs/2402.14029) | 提出一种方法，通过冻结随机子集的初始权重来减少强大的彩票票证（SLT）搜索空间，从而独立于所需SLT稀疏性降低了SLT搜索空间，保证了SLT在这种减少搜索空间中的存在。 |
| [^116] | [Betting on what is neither verifiable nor falsifiable](https://arxiv.org/abs/2402.14021) | 本文提出了一种通过期权或等同于对“验证-证伪游戏”的结果押注的方法，用于处理无法直接应用于固定解决标准问题的预测市场。 |
| [^117] | [Deep Generative Models for Offline Policy Learning: Tutorial, Survey, and Perspectives on Future Directions](https://arxiv.org/abs/2402.13777) | 深度生成模型在离线策略学习中展现了巨大潜力，本文提供了首个系统性综述，涵盖了五种主流深度生成模型及其应用。 |
| [^118] | [CriticBench: Evaluating Large Language Models as Critic](https://arxiv.org/abs/2402.13764) | CriticBench是一个旨在全面和可靠地评估大型语言模型的评论能力的新型基准，展示了评论能力与任务、响应质量和模型规模之间的关系。 |
| [^119] | [DSLR: Diversity Enhancement and Structure Learning for Rehearsal-based Graph Continual Learning](https://arxiv.org/abs/2402.13711) | DSLR提出了一种基于覆盖范围的多样性方法，以解决基于重播的图持续学习中回放节点过于集中导致过拟合和灾难性遗忘的问题。 |
| [^120] | [RefuteBench: Evaluating Refuting Instruction-Following for Large Language Models](https://arxiv.org/abs/2402.13463) | 本文提出了一个名为RefuteBench的基准测试，旨在评估大型语言模型对反驳指令的遵循能力，发现LLMs倾向于固执于其内部知识而无法遵从用户反馈。 |
| [^121] | [Learning and Sustaining Shared Normative Systems via Bayesian Rule Induction in Markov Games](https://arxiv.org/abs/2402.13399) | 通过贝叶斯规则归纳，新引入的智能体可以推断现有人群的规范，使智能体收敛到共享的规范，从而实现规范体系的稳定性 |
| [^122] | [KetGPT -- Dataset Augmentation of Quantum Circuits using Transformers](https://arxiv.org/abs/2402.13352) | 该研究利用Transformer机器学习架构生成“看起来真实”的量子电路，以增强现有的量子电路数据集。 |
| [^123] | [Aria Everyday Activities Dataset](https://arxiv.org/abs/2402.13349) | AEA数据集是使用Project Aria眼镜记录的第一人称多模态开放数据集，其中包含了多个佩戴者在室内不同位置记录的日常活动序列，为研究提供了3D轨迹、场景点云、眼球注视向量和语音转录等机器感知数据，支持神经场景重建和提示分割。 |
| [^124] | [Tables as Images? Exploring the Strengths and Limitations of LLMs on Multimodal Representations of Tabular Data](https://arxiv.org/abs/2402.12424) | 本研究探讨了LLM在解释表格数据方面的有效性，比较了文本和图像表格表示对LLM性能的影响，为在表格相关任务上有效使用LLM提供了见解。 |
| [^125] | [Dynamic Multi-Network Mining of Tensor Time Series](https://arxiv.org/abs/2402.11773) | 提出了一种新方法，Dynamic Multi-network Mining (DMM)，能够将张量时间序列转换为不同长度的段组，通过稀疏依赖网络提供聚类的可解释性和精确性。 |
| [^126] | [ArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs](https://arxiv.org/abs/2402.11753) | 提出了一种新颖的基于ASCII艺术的越狱攻击，以及一个用于评估LLMs在识别非纯语义提示方面能力的基准挑战。五个SOTA LLMs在识别ASCII艺术提示时存在困难。 |
| [^127] | [Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models](https://arxiv.org/abs/2402.11140) | 本文提出了一种名为Boosting of Thoughts（BoT）的自动提示框架，通过迭代地探索和自我评估多个思维树，获得一系列试错推理经验，作为解决复杂问题的新形式的提示。 |
| [^128] | [Exploring Value Biases: How LLMs Deviate Towards the Ideal](https://arxiv.org/abs/2402.11005) | 研究发现大型语言模型（LLMs）在给出响应时存在一个价值偏好的机制，倾向于偏向理想状态，这种偏差会对不同应用场景产生重要影响。 |
| [^129] | [Accelerating Semi-Asynchronous Federated Learning](https://arxiv.org/abs/2402.10991) | 提出了一种考虑贡献的异步联邦学习方法，动态调整接收到的更新的处理方式，以解决现实情况下同步上传数据可能出现的缓慢和不可靠问题。 |
| [^130] | [Brant-2: Foundation Model for Brain Signals](https://arxiv.org/abs/2402.10251) | Brant-2是脑信号领域最大的基础模型，相比于Brant，它不仅对数据变化和建模尺度具有稳健性，还能适用于更广泛范围的脑神经数据。 |
| [^131] | [MM-Point: Multi-View Information-Enhanced Multi-Modal Self-Supervised 3D Point Cloud Understanding](https://arxiv.org/abs/2402.10002) | 本文提出了一种新颖的自监督点云表示学习方法MM-Point，通过多模态交互和传输实现了3D物体和多个2D视图之间的信息增强。通过精心设计的实验，证明了MM-Point的有效性和优越性。 |
| [^132] | [Persuading a Learning Agent](https://arxiv.org/abs/2402.09721) | 在一个重复的贝叶斯说服问题中，即使没有承诺能力，委托人可以通过使用上下文无遗憾学习算法来实现与经典无学习模型中具有承诺的委托人的最优效用无限接近的效果；在代理人使用上下文无交换遗憾学习算法的情况下，委托人无法获得比具有承诺的无学习模型中的最优效用更高的效用。 |
| [^133] | [CodeMind: A Framework to Challenge Large Language Models for Code Reasoning](https://arxiv.org/abs/2402.09664) | CodeMind是一个用于挑战大型语言模型进行代码推理的框架，通过评估LLMs的代码推理能力来替代仅仅依靠测试通过来评估，对三种代码推理任务进行评估，结果显示LLMs能够公正地理解控制流结构，并且对于简单程序和复杂程序，它们通常能够推理出输入如何演变为输出。 |
| [^134] | [Step-On-Feet Tuning: Scaling Self-Alignment of LLMs via Bootstrapping](https://arxiv.org/abs/2402.07610) | 本文首次探索了自助引导自对齐对大型语言模型的影响，发现其明显优于单次循环的方法，并通过调整数据训练顺序进一步提升模型性能。 |
| [^135] | [Knowledge Graphs Meet Multi-Modal Learning: A Comprehensive Survey](https://arxiv.org/abs/2402.05391) | 知识图谱与多模态学习的综述介绍了KG4MM和MM4KG两个主要方面，包括任务定义、构建进展、评估基准以及关键研究轨迹。 |
| [^136] | [Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source LLMs](https://arxiv.org/abs/2402.03927) | 该论文研究了封闭源LLMs中的数据污染和评估不端行为。通过对255篇论文的分析和OpenAI的数据使用政策考虑，研究人员发现这些模型在第一年发布后存在泄露数据的问题。 |
| [^137] | [Large Language Models As MOOCs Graders](https://arxiv.org/abs/2402.03776) | 该研究探索了利用大型语言模型（LLMs）代替MOOCs中同伴评分的可行性，旨在解决大规模在线开放课程中评估学生写作任务的问题。 |
| [^138] | [Minds versus Machines: Rethinking Entailment Verification with Language Models](https://arxiv.org/abs/2402.03686) | 本文通过研究人类和大型语言模型在推理判断中的共性和差异，发现大型语言模型在复杂推理中具有优势，而人类在简单推理中表现出色。基于这些发现，引入了一个优化的Flan-T5模型，用于蕴含验证。 |
| [^139] | [PuzzleBench: Can LLMs Solve Challenging First-Order Combinatorial Reasoning Problems?](https://arxiv.org/abs/2402.02611) | 本研究通过PuzzleBench数据集探索了LLMs解决困难的一阶组合推理问题的能力，并提出了Puzzle-LM方法，该方法将LLMs与符号求解器和程序解释器相结合，使其能够有效地推理这类问题。 |
| [^140] | [DiffStitch: Boosting Offline Reinforcement Learning with Diffusion-based Trajectory Stitching](https://arxiv.org/abs/2402.02439) | DiffStitch是一种使用基于扩散的轨迹拼接提升离线强化学习的方法。它通过有效地连接低奖励轨迹和高奖励轨迹，形成全局最优轨迹，以提高离线强化学习算法的性能。 |
| [^141] | [Self-Imagine: Effective Unimodal Reasoning with Multimodal Models using Self-Imagination](https://arxiv.org/abs/2401.08025) | 本文提出了Self-Imagine方法，通过利用一种Vision-Language模型生成问题的结构化表示并将其渲染为图像，再使用相同的模型回答问题，从而在数学任务和通用推理任务中提高了模型性能。 |
| [^142] | [LLM-Powered Code Vulnerability Repair with Reinforcement Learning and Semantic Reward](https://arxiv.org/abs/2401.03374) | 引入了一种由大型语言模型驱动的多功能代码漏洞分析系统，旨在通过强化学习和语义奖励修复因AI驱动的自动化工具而产生的不安全代码。 |
| [^143] | [Industrial Internet of Things Intelligence Empowering Smart Manufacturing: A Literature Review](https://arxiv.org/abs/2312.16174) | 本文提供了对工业物联网智能的全面概述，弥补了现有调查偏见，为制造业的转型提供了指引。 |
| [^144] | [Do LLM Agents Exhibit Social Behavior?](https://arxiv.org/abs/2312.15198) | 研究探讨了LLM代理在与人类和其他代理互动时展示的社会行为，包括社会学习、社会偏好和合作行为，并开发了一个框架来评估它们与人类实验对象的互动。 |
| [^145] | [MaxK-GNN: Towards Theoretical Speed Limits for Accelerating Graph Neural Networks Training](https://arxiv.org/abs/2312.08656) | MaxK-GNN是一种先进的高性能GPU训练系统，通过MaxK非线性和理论分析，实现了图神经网络训练的垂直优化。 |
| [^146] | [Mitigating Open-Vocabulary Caption Hallucinations](https://arxiv.org/abs/2312.03631) | 提出了在开放词汇设置中解决图像字幕幻觉问题的框架，并提出了一种新方法MOCHa来缓解幻觉 |
| [^147] | [EduGym: An Environment and Notebook Suite for Reinforcement Learning Education](https://arxiv.org/abs/2311.10590) | EduGym是一套用于强化学习教育的环境和笔记本套件，旨在解决学生在转换理论和实践中遇到的困难。 |
| [^148] | [Monkey: Image Resolution and Text Label Are Important Things for Large Multi-modal Models](https://arxiv.org/abs/2311.06607) | Monkey通过提高图像分辨率和采用多级描述生成方法来增强大型多模态模型(LMMs)的能力，从而实现更详细的视觉捕捉和更有效的学习。 |
| [^149] | [A differentiable brain simulator bridging brain simulation and brain-inspired computing](https://arxiv.org/abs/2311.05106) | BrainPy是一个可微分的大脑模拟器，旨在通过引入JAX和XLA的功能来架设大脑模拟与脑启发计算之间的桥梁。 |
| [^150] | [Breaking the Trilemma of Privacy, Utility, Efficiency via Controllable Machine Unlearning](https://arxiv.org/abs/2310.18574) | 设计了一种名为Controllable Machine Unlearning (ConMU)的新框架，旨在平衡隐私、模型效用和运行效率之间的权衡。 |
| [^151] | [MindfulDiary: Harnessing Large Language Model to Support Psychiatric Patients' Journaling](https://arxiv.org/abs/2310.05231) | MindfulDiary利用大型语言模型帮助精神病患者通过对话记录日常体验，并在临床环境中取得积极效果 |
| [^152] | [Augmenting Black-box LLMs with Medical Textbooks for Clinical Question Answering](https://arxiv.org/abs/2309.02233) | 该研究提出了一种名为LLMs增强医学教科书（LLM-AMT）的系统，通过插入式模块将权威医学教科书集成到LLMs的框架中，显著提高了LLMs在专业领域的能力。 |
| [^153] | [LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities](https://arxiv.org/abs/2305.13168) | 本研究全面评估了LLMs在知识图谱构建和推理领域的性能，发现GPT-4更适合作为推理助手，并在某些情况下超越了精调模型。 |
| [^154] | [Everyone Can Be Picasso? A Computational Framework into the Myth of Human versus AI Painting](https://arxiv.org/abs/2304.07999) | 人类与人工智能绘画在潜在空间和部分审美特征上存在差异，但在其他方面较少差异。 |
| [^155] | [Promises and Pitfalls of Threshold-based Auto-labeling](https://arxiv.org/abs/2211.12620) | TBAL系统可以通过验证数据自动标注未标注数据，减少手动标注的依赖；研究结果展示了即使模型表现不佳也可以准确自动标记数据，并揭示了TBAL系统的潜在缺陷 |
| [^156] | [Mitigating Gender Bias in Face Recognition Using the von Mises-Fisher Mixture Model](https://arxiv.org/abs/2210.13664) | 通过引入新的度量标准BFAR和BFRR，并通过后处理方法减轻面部识别中的性别偏见，以实现公平的系统性能。 |
| [^157] | [Life in a random universe: Sciama's argument reconsidered](https://arxiv.org/abs/2109.10241) | 一个随机宇宙下的生命概率问题被重新思考，可能会导致基本常数看似被精确调整以实现生命发生的高概率。 |
| [^158] | [Learning Quadruped Locomotion Policies using Logical Rules](https://arxiv.org/abs/2107.10969) | 该论文提出了一种使用逻辑规则来学习四足动物运动策略的方法，通过奖励机器实现高层步态规范，支持在执行时调整步态频率，并且能够有效避免繁琐的运动先验。 |
| [^159] | [Adversarial Machine Learning: Bayesian Perspectives](https://arxiv.org/abs/2003.03546) | AML旨在保护机器学习系统免受安全威胁，贝叶斯视角为防御提供了新的好处 |
| [^160] | [Finetuning Large Language Models for Vulnerability Detection.](http://arxiv.org/abs/2401.17010) | 本文优化了大规模语言模型用于源代码中的漏洞检测任务，通过微调最先进的代码语言模型WizardCoder并改进其训练过程和策略，实现了对漏洞数据集的分类性能的提升。 |
| [^161] | [TAT-LLM: A Specialized Language Model for Discrete Reasoning over Tabular and Textual Data.](http://arxiv.org/abs/2401.13223) | TAT-LLM是一种专门用于离散推理的语言模型，针对混合表格和文本数据上的问答任务。该模型通过分步流水线的方式，包括提取器、推理器和执行器，利用LLMs的强大能力来解决问题。而为了应对成本、延迟和数据安全风险等挑战，我们开发了TAT-LLM，一个专门针对此任务的较小LLM。 |
| [^162] | [Quantum-Inspired Machine Learning for Molecular Docking.](http://arxiv.org/abs/2401.12999) | 量子启发的机器学习方法在分子对接中取得了显著的改进，通过结合量子特性和深度学习在编码的分子空间中学习的梯度，提高了盲目对接的成功率。 |
| [^163] | [From Understanding to Utilization: A Survey on Explainability for Large Language Models.](http://arxiv.org/abs/2401.12874) | 本综述论文研究了大规模语言模型(LLMs)可解释性的新兴领域，强调了在LLMs中增强可解释性的必要性，同时解决了广大公众对其信任和技术界对这些模型更深理解的需求。该综述对现有的可解释性方法进行分类，并讨论了它们在提高模型透明度和可靠性方面的应用，旨在弥合理论理解和实际应用之间的差距。 |
| [^164] | [Improving Machine Translation with Human Feedback: An Exploration of Quality Estimation as a Reward Model.](http://arxiv.org/abs/2401.12873) | 本研究探索了利用质量估计作为奖励模型来预测人类偏好以改善机器翻译的潜力。我们发现基于质量估计的反馈训练存在过度优化问题，采用启发式规则来检测错误翻译并对质量估计模型进行惩罚以解决该问题。 |
| [^165] | [E^2-LLM: Efficient and Extreme Length Extension of Large Language Models.](http://arxiv.org/abs/2401.06951) | E^2-LLM是一种高效和极长扩展方法，通过仅需一次训练过程和不收集长上下文数据的方式，在大规模语言模型中实现了显著减少的计算成本。基于RoPE位置嵌入，E^2-LLM只需要较短的训练数据长度，支持不同的评估上下文窗口。 |
| [^166] | [SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully.](http://arxiv.org/abs/2401.05930) | 自我突出式犹豫（SH2）是一种推理时的方法，通过选择预测概率较低的标记，并强调它们的差异，从而帮助语言模型更准确地解码。 |
| [^167] | [TREC iKAT 2023: The Interactive Knowledge Assistance Track Overview.](http://arxiv.org/abs/2401.01330) | TREC iKAT 2023是一个交互式的知识辅助任务，旨在开发适应用户交互和上下文的会话搜索代理。该任务还强调决策搜索任务，用户通过筛选数据和信息来进行决策和执行动作。 |
| [^168] | [AesFA: An Aesthetic Feature-Aware Arbitrary Neural Style Transfer.](http://arxiv.org/abs/2312.05928) | AesFA是一种轻量级但有效的神经风格转换方法，通过频率分解图像，以更好地解开美学风格，排除了预训练模型。引入了对比损失以提高风格化质量。实验证明，AesFA在stylization quality方面优于其他方法，并实现了快速转换。 |
| [^169] | [Locating Cross-Task Sequence Continuation Circuits in Transformers.](http://arxiv.org/abs/2311.04131) | 通过分析和比较Transformer模型中类似的序列继续任务的电路，研究发现共享的计算结构可以提高模型的行为预测能力、错误识别能力和编辑过程的安全性。 |
| [^170] | [Image Clustering Conditioned on Text Criteria.](http://arxiv.org/abs/2310.18297) | 本文提出了一种新的图像聚类方法，基于用户指定的文本标准，通过利用现代视觉语言模型和大型语言模型，实现了对聚类结果的直接控制。该方法需要较少的人工干预，并能在各种标准下有效地聚类图像，表现优于基准方法。 |
| [^171] | [Large Language Models for In-Context Student Modeling: Synthesizing Student's Behavior in Visual Programming from One-Shot Observation.](http://arxiv.org/abs/2310.10690) | 本研究探索在开放式学习环境中使用大型语言模型进行上下文学生建模，提出了一个新的框架LLM-SS，通过合成学生在不同任务上的尝试，为学生建模提供更准确的预测和教学策略。 |
| [^172] | [When are Bandits Robust to Misspecification?.](http://arxiv.org/abs/2310.09358) | 该论文研究了参数化的强盗算法和情境化的强盗算法在真实奖励与模型之间存在误差的情况下的稳定性，并找到了依赖于问题实例和模型类的充分条件，使得经典算法如ε-贪心和LinUCB能够在时间范围内保持次线性的遗憾保障。 |
| [^173] | [Reverse Chain: A Generic-Rule for LLMs to Master Multi-API Planning.](http://arxiv.org/abs/2310.04474) | 这项研究提出了一种名为反向链的通用规则，通过反向链思路使LLMs能够使用外部API完成复杂的函数调用任务，并通过填充参数的方式提高任务完成的准确性。 |
| [^174] | [ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs.](http://arxiv.org/abs/2309.13007) | ReConcile是一个通过多轮讨论和投票机制来增强LLM推理能力的多模型多代理框架。 |
| [^175] | [Transformers as Support Vector Machines.](http://arxiv.org/abs/2308.16898) | 这项工作建立了自注意力和硬间隔支持向量机问题之间的正式等价关系，通过转换器架构的优化几何来解决自然语言处理问题，同时揭示了梯度下降优化的转换器的隐式偏差。 |
| [^176] | [Time Travel in LLMs: Tracing Data Contamination in Large Language Models.](http://arxiv.org/abs/2308.08493) | 该论文提出了一种用于识别大型语言模型（LLMs）中数据污染的简单而有效的方法。通过对随机样本中的单个实例进行分析，以及使用“引导指令”来评估整个数据集分区的污染程度，可以准确地识别污染的实例和分区。 |
| [^177] | [TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for Time Series.](http://arxiv.org/abs/2308.08241) | 这篇论文总结了两种使用语言模型完成时间序列任务的策略，通过设计一种适用于语言模型的时间序列嵌入方法来激活语言模型对时间序列数据的能力。虽然结果没有明显超越当前最先进的模型，但可以更好地处理时间序列数据。 |
| [^178] | [Large Language Models in Cryptocurrency Securities Cases: Can ChatGPT Replace Lawyers?.](http://arxiv.org/abs/2308.06032) | 本研究探讨了在加密货币证券案件中，大型语言模型（LLMs）是否能够准确判断违法行为，并比较了由LLM和律师撰写的投诉书对陪审团决策的影响。研究发现，目前的LLMs在法律推理方面表现较弱，但随着未来模型的改进，其潜力有望提升。 |
| [^179] | [Decentralised Governance for Foundation Model based Systems: Exploring the Role of Blockchain in Responsible AI.](http://arxiv.org/abs/2308.05962) | 本文探讨了基于基金会模型的人工智能系统在整个生命周期中所面临的治理挑战，并提出了利用区块链实现去中心化治理的架构。 |
| [^180] | [Dissenting Explanations: Leveraging Disagreement to Reduce Model Overreliance.](http://arxiv.org/abs/2307.07636) | 这项研究介绍了不同解释的概念，旨在通过提供伴随冲突预测的解释来减少模型过度依赖。在模型多样性设置下，这种方法可以帮助人们从不同模型的解释中获得洞察力。 |
| [^181] | [Artificial intelligence is algorithmic mimicry: why artificial "agents" are not (and won't be) proper agents.](http://arxiv.org/abs/2307.07515) | 本研究通过对比生物系统和算法系统，指出了生物系统具有自我制造自主能力、符号和物理方面没有区分以及体验到模糊问题的大世界等特点，而算法系统则与此相反。 |
| [^182] | [Stochastic Re-weighted Gradient Descent via Distributionally Robust Optimization.](http://arxiv.org/abs/2306.09222) | 我们通过分布健壮优化和重要性加权的梯度下降技术提升了深度神经网络的性能，并在各种任务上取得了优越的结果。 |
| [^183] | [Domain-Agnostic Batch Bayesian Optimization with Diverse Constraints via Bayesian Quadrature.](http://arxiv.org/abs/2306.05843) | 本论文提出了cSOBER，一种处理多样化约束条件、离散和混合空间、未知约束以及查询拒绝问题的领域无关型贝叶斯优化算法。 |
| [^184] | [State Regularized Policy Optimization on Data with Dynamics Shift.](http://arxiv.org/abs/2306.03552) | 本文提出了一种叫做 SRPO (状态规范化策略优化) 的算法，该算法利用训练数据中的稳态分布来规范新环境中的策略，在处理具有不同动态的多个环境时表现优异。 |
| [^185] | [Doc2SoarGraph: Discrete Reasoning over Visually-Rich Table-Text Documents with Semantic-Oriented Hierarchical Graphs.](http://arxiv.org/abs/2305.01938) | 本文提出了 Doc2SoarGraph 框架，利用语义导向分层图结构中元素之间的差异和相关性，在富含视觉表格文本的TAT-DQA问题下实现了离散推理，表现出了最佳的实验结果。 |
| [^186] | [Meaningful Causal Aggregation and Paradoxical Confounding.](http://arxiv.org/abs/2304.11625) | 聚合变量上的因果性不确定性可能会使得原本不混淆的因果关系变得混淆，在实际应用中，我们需要接受宏观因果关系通常只与微观状态相关的事实。 |
| [^187] | [Exposing and Addressing Cross-Task Inconsistency in Unified Vision-Language Models.](http://arxiv.org/abs/2303.16133) | 该研究提出了一个基准数据集COCOCON，并提出度量方法来衡量模型一致性，研究发现现有的最先进系统在不同任务之间表现出高度不一致性。 |
| [^188] | [Finding Alignments Between Interpretable Causal Variables and Distributed Neural Representations.](http://arxiv.org/abs/2303.02536) | 本文提出了分布式对齐搜索（DAS）算法，可以在不使用暴力搜索的情况下找到高层因果模型和低层深度学习系统之间的对齐方法，并且DAS可以发现先前方法忽略的内部结构。DAS算法有潜力实现对复杂深度学习系统的更好解释和理解。 |
| [^189] | [Generative Invertible Quantum Neural Networks.](http://arxiv.org/abs/2302.12906) | 本论文提出了一种用于生成可逆量子神经网络的算法，并将其应用于LHC数据的处理，结果表明该算法可以在学习和生成复杂数据方面与经典算法的表现相匹配。 |
| [^190] | [Underspecification in Language Modeling Tasks: A Causality-Informed Study of Gendered Pronoun Resolution.](http://arxiv.org/abs/2210.00131) | 本研究通过提供一个因果模型，在语言建模任务中探讨了不充分规范化的作用，提出了两种轻量级黑盒评估方法来帮助检测任务的不充分规范化，并在性别代词消解任务中应用这些方法，同时发现了性别与时间、性别与位置之间的虚假相关性。 |

# 详细

[^1]: 医学影像中专家级视觉语言基础模型的人口统计偏见

    Demographic Bias of Expert-Level Vision-Language Foundation Models in Medical Imaging

    [https://arxiv.org/abs/2402.14815](https://arxiv.org/abs/2402.14815)

    本研究调查了全球五个数据集中最先进的视觉语言基础模型在胸片诊断中的算法公平性。我们的发现表明，与董事会认证的放射科医师相比，这些基础模型在诊断边缘化群体时一贯存在低诊断率，甚至在诸如黑人女性之类的交叉亚组中看到更高的比例。

    

    人工智能的进展已经在医学影像应用中实现了专家级表现。值得注意的是，自监督视觉语言基础模型可以在不依赖明确培训注释的情况下检测广泛的病理。然而，确保这些人工智能模型不反映或放大人类偏见至关重要，从而使女性或黑人患者等历史上被边缘化的群体处于不利地位。这种偏见的体现可能会系统性地延迟特定患者亚组的重要医疗护理。

    arXiv:2402.14815v1 Announce Type: cross  Abstract: Advances in artificial intelligence (AI) have achieved expert-level performance in medical imaging applications. Notably, self-supervised vision-language foundation models can detect a broad spectrum of pathologies without relying on explicit training annotations. However, it is crucial to ensure that these AI models do not mirror or amplify human biases, thereby disadvantaging historically marginalized groups such as females or Black patients. The manifestation of such biases could systematically delay essential medical care for certain patient subgroups. In this study, we investigate the algorithmic fairness of state-of-the-art vision-language foundation models in chest X-ray diagnosis across five globally-sourced datasets. Our findings reveal that compared to board-certified radiologists, these foundation models consistently underdiagnose marginalized groups, with even higher rates seen in intersectional subgroups, such as Black fem
    
[^2]: WeakSAM: 任意分割遇上弱监督实例级别识别

    WeakSAM: Segment Anything Meets Weakly-supervised Instance-level Recognition

    [https://arxiv.org/abs/2402.14812](https://arxiv.org/abs/2402.14812)

    WeakSAM通过利用预先学习的全球知识，解决了弱监督对象检测和分割问题，提出了自适应PGT生成和RoI丢弃正则化，显著超越了先前的最先进方法。

    

    弱监督的视觉识别使用不精确的监督是一个关键但具有挑战性的学习问题。它显著降低了人工标注成本，并且传统上依赖多实例学习和伪标签。本文介绍了WeakSAM，并通过利用包含在视觉基础模型中的预先学习的全球知识，即Segment Anything Model (SAM)，来解决弱监督物体检测（WSOD）和分割。WeakSAM通过自适应PGT生成和感兴趣区域（RoI）丢弃正则化，解决了传统WSOD重新训练中的两个关键限制，即伪标准地面真相（PGT）的不完整性和具有嘈杂PGT实例。它还解决了SAM在自动对象检测和分割时需要提示和类别无感知性的问题。我们的结果表明，WeakSAM在WSOD和WSIS基准测试中显著超越了先前的最先进方法。

    arXiv:2402.14812v1 Announce Type: cross  Abstract: Weakly supervised visual recognition using inexact supervision is a critical yet challenging learning problem. It significantly reduces human labeling costs and traditionally relies on multi-instance learning and pseudo-labeling. This paper introduces WeakSAM and solves the weakly-supervised object detection (WSOD) and segmentation by utilizing the pre-learned world knowledge contained in a vision foundation model, i.e., the Segment Anything Model (SAM). WeakSAM addresses two critical limitations in traditional WSOD retraining, i.e., pseudo ground truth (PGT) incompleteness and noisy PGT instances, through adaptive PGT generation and Region of Interest (RoI) drop regularization. It also addresses the SAM's problems of requiring prompts and category unawareness for automatic object detection and segmentation. Our results indicate that WeakSAM significantly surpasses previous state-of-the-art methods in WSOD and WSIS benchmarks with larg
    
[^3]: GeneOH扩散: 通过去噪扩散实现可泛化的手-物体交互去噪

    GeneOH Diffusion: Towards Generalizable Hand-Object Interaction Denoising via Denoising Diffusion

    [https://arxiv.org/abs/2402.14810](https://arxiv.org/abs/2402.14810)

    通过GeneOH扩散方法，实现了可泛化的手-物体交互去噪，其中关键创新包括基于接触的HOI表示和领域通用的去噪方案。

    

    在这项工作中，我们解决了去噪手-物体交互（HOI）的挑战性问题。在给定一个错误的交互序列的情况下，目标是对不正确的手的轨迹进行细化，以消除交互伪影，获得一个感知上真实的序列。这一挑战涉及复杂的交互噪声，包括不自然的手部姿势和不正确的手-物体关系，以及对新交互和不同噪声模式的稳健泛化的必要性。我们通过一种新颖的方法GeneOH Diffusion应对这些挑战，包括两个关键设计:一种名为GeneOH的创新的基于接触的HOI表示和一种新的领域通用的去噪方案。基于接触的表示GeneOH对HOI过程进行信息化参数化，促进在各种HOI场景中实现增强的泛化。新的去噪方案包括一个经过训练用于投影嘈杂数据样本的经典去噪模型。

    arXiv:2402.14810v1 Announce Type: cross  Abstract: In this work, we tackle the challenging problem of denoising hand-object interactions (HOI). Given an erroneous interaction sequence, the objective is to refine the incorrect hand trajectory to remove interaction artifacts for a perceptually realistic sequence. This challenge involves intricate interaction noise, including unnatural hand poses and incorrect hand-object relations, alongside the necessity for robust generalization to new interactions and diverse noise patterns. We tackle those challenges through a novel approach, GeneOH Diffusion, incorporating two key designs: an innovative contact-centric HOI representation named GeneOH and a new domain-generalizable denoising scheme. The contact-centric representation GeneOH informatively parameterizes the HOI process, facilitating enhanced generalization across various HOI scenarios. The new denoising scheme consists of a canonical denoising model trained to project noisy data sample
    
[^4]: CriticBench：为批判性-正确推理评估LLMs而设计的基准测试

    CriticBench: Benchmarking LLMs for Critique-Correct Reasoning

    [https://arxiv.org/abs/2402.14809](https://arxiv.org/abs/2402.14809)

    CriticBench是一个综合基准测试，旨在评估LLMs在批判和纠正推理方面的能力，发现批判性训练显著提升性能，逻辑任务更易于修正。

    

    大型语言模型（LLMs）批判和完善其推理的能力对于它们在评估、反馈提供和自我改进中的应用至关重要。本文引入了CriticBench，一个旨在评估LLMs在各种任务中批判和纠正其推理能力的综合基准测试。CriticBench包含五个推理领域：数学、常识、符号、编码和算法。它整合了15个数据集，并结合了三个LLM系列的响应。利用CriticBench，我们评估和剖析了17个LLMs在生成、批判和修正推理（即GQC推理）中的表现。我们的研究结果显示：（1）GQC能力呈线性关系，批判性训练显著提升了性能；（2）修正效果在任务上有所不同，以逻辑为导向的任务更容易修正；（3）GQC知识的不一致性。

    arXiv:2402.14809v1 Announce Type: cross  Abstract: The ability of Large Language Models (LLMs) to critique and refine their reasoning is crucial for their application in evaluation, feedback provision, and self-improvement. This paper introduces CriticBench, a comprehensive benchmark designed to assess LLMs' abilities to critique and rectify their reasoning across a variety of tasks. CriticBench encompasses five reasoning domains: mathematical, commonsense, symbolic, coding, and algorithmic. It compiles 15 datasets and incorporates responses from three LLM families. Utilizing CriticBench, we evaluate and dissect the performance of 17 LLMs in generation, critique, and correction reasoning, i.e., GQC reasoning. Our findings reveal: (1) a linear relationship in GQC capabilities, with critique-focused training markedly enhancing performance; (2) a task-dependent variation in correction effectiveness, with logic-oriented tasks being more amenable to correction; (3) GQC knowledge inconsisten
    
[^5]: 用于公共卫生中动态不安静多臂老虎机任务的决策语言模型（DLM）

    A Decision-Language Model (DLM) for Dynamic Restless Multi-Armed Bandit Tasks in Public Health

    [https://arxiv.org/abs/2402.14807](https://arxiv.org/abs/2402.14807)

    提出了一种决策语言模型DLM，旨在通过使用LLMs作为自动规划器，动态微调RMAB策略，以应对公共卫生中具有挑战性的情境。

    

    旨在降低孕产妇死亡率的努力在很大程度上依赖于预防保健计划，向高风险人群传播重要的健康信息。本文提出了DLM：一种用于RMAB的决策语言模型，旨在通过使用LLMs作为自动规划器，动态微调RMAB策略，以应对公共卫生中具有挑战性的情境。

    arXiv:2402.14807v1 Announce Type: cross  Abstract: Efforts to reduce maternal mortality rate, a key UN Sustainable Development target (SDG Target 3.1), rely largely on preventative care programs to spread critical health information to high-risk populations. These programs face two important challenges: efficiently allocating limited health resources to large beneficiary populations, and adapting to evolving policy priorities. While prior works in restless multi-armed bandit (RMAB) demonstrated success in public health allocation tasks, they lack flexibility to adapt to evolving policy priorities. Concurrently, Large Language Models (LLMs) have emerged as adept, automated planners in various domains, including robotic control and navigation. In this paper, we propose DLM: a Decision Language Model for RMABs. To enable dynamic fine-tuning of RMAB policies for challenging public health settings using human-language commands, we propose using LLMs as automated planners to (1) interpret hu
    
[^6]: 通过外部评估在大型语言模型中识别多重人格

    Identifying Multiple Personalities in Large Language Models with External Evaluation

    [https://arxiv.org/abs/2402.14805](https://arxiv.org/abs/2402.14805)

    通过外部评估方法研究大型语言模型的人格特征

    

    随着大型语言模型（LLMs）迅速与人类日常应用整合，关于LLMs行为的许多社会和伦理关切被提出。了解LLMs行为的一种方式是分析它们的人格。许多最近的研究使用为人类创建的自我评估测试来量化LLMs的人格。然而，许多批评质疑将这些自我评估测试应用于LLMs时的适用性和可靠性。在本文中，我们使用一种替代的人格测量方法来研究LLMs的人格，我们将其称为外部评估方法，这里我们不是通过在李克特量表上提示LLMs回答多选题，而是通过分析LLMs对外部机器学习模型提出的开放式情境问题的回答来评估LLMs的人格。我们首先对Llama2-7B模型进行微调，作为MBTI人格预测器，该预测器优于最先进的

    arXiv:2402.14805v1 Announce Type: cross  Abstract: As Large Language Models (LLMs) are integrated with human daily applications rapidly, many societal and ethical concerns are raised regarding the behavior of LLMs. One of the ways to comprehend LLMs' behavior is to analyze their personalities. Many recent studies quantify LLMs' personalities using self-assessment tests that are created for humans. Yet many critiques question the applicability and reliability of these self-assessment tests when applied to LLMs. In this paper, we investigate LLM personalities using an alternate personality measurement method, which we refer to as the external evaluation method, where instead of prompting LLMs with multiple-choice questions in the Likert scale, we evaluate LLMs' personalities by analyzing their responses toward open-ended situational questions using an external machine learning model. We first fine-tuned a Llama2-7B model as the MBTI personality predictor that outperforms the state-of-the
    
[^7]: 使用MATH-Vision数据集测量多模态数学推理

    Measuring Multimodal Mathematical Reasoning with MATH-Vision Dataset

    [https://arxiv.org/abs/2402.14804](https://arxiv.org/abs/2402.14804)

    提出了MATH-Vision（MATH-V）数据集，用于评估大型多模态模型（LMMs）的数学推理能力，通过实验证实了当前LMMs和人类在MATH-V上的表现差距。

    

    大型多模态模型（LMMs）的最新进展在视觉背景下的数学推理方面显示出令人鼓舞的结果，这些模型在现有基准测试（如MathVista）上接近人类水平的表现。然而，我们观察到这些基准测试在问题多样性和涵盖学科范围方面存在显着局限性。为了解决这一问题，我们提出了MATH-Vision（MATH-V）数据集，这是一个精心策划的收集了来自真实数学竞赛的3,040个高质量数学问题和视觉背景的数据集。跨越16个不同的数学学科，分为5个难度级别进行评分，我们的数据集为评估LMMs的数学推理能力提供了一套全面且多样化的挑战。通过广泛的实验，我们揭示了当前LMMs与MATH-V上人类表现之间的显著表现差距，并强调了进一步推进的必要性。

    arXiv:2402.14804v1 Announce Type: cross  Abstract: Recent advancements in Large Multimodal Models (LMMs) have shown promising results in mathematical reasoning within visual contexts, with models approaching human-level performance on existing benchmarks such as MathVista. However, we observe significant limitations in the diversity of questions and breadth of subjects covered by these benchmarks. To address this issue, we present the MATH-Vision (MATH-V) dataset, a meticulously curated collection of 3,040 high-quality mathematical problems with visual contexts sourced from real math competitions. Spanning 16 distinct mathematical disciplines and graded across 5 levels of difficulty, our dataset provides a comprehensive and diverse set of challenges for evaluating the mathematical reasoning abilities of LMMs. Through extensive experimentation, we unveil a notable performance gap between current LMMs and human performance on MATH-V, underscoring the imperative for further advancements i
    
[^8]: 并非所有专家都相等: 混合专家大型语言模型的高效专家修剪和跳过

    Not All Experts are Equal: Efficient Expert Pruning and Skipping for Mixture-of-Experts Large Language Models

    [https://arxiv.org/abs/2402.14800](https://arxiv.org/abs/2402.14800)

    引入了专家级稀疏化技术，提出了专家修剪和跳过的后训练方法，以提高MoE LLMs的部署效率，同时保持模型性能。

    

    大型语言模型（LLMs）进展中的一个重要进展是混合专家（MoE）LLMs的出现。与传统的LLMs相比，MoE LLMs可以在更少的参数下实现更高的性能，但由于其巨大的参数大小，仍然很难部署它们。与先前依赖于专门设计的硬件的权重剪枝方法不同，本文主要旨在通过引入即插即用的专家级稀疏化技术来提高MoE LLMs的部署效率。具体而言，我们首次提出了针对任务不可知和任务特定的MoE LLMs专家修剪和跳过的后训练方法，旨在提高在广泛任务范围内保持模型性能的同时提高部署效率。大量实验证明，我们提出的方法可以同时减小模型大小并增加推断速度，同时保持饱和

    arXiv:2402.14800v1 Announce Type: cross  Abstract: A pivotal advancement in the progress of large language models (LLMs) is the emergence of the Mixture-of-Experts (MoE) LLMs. Compared to traditional LLMs, MoE LLMs can achieve higher performance with fewer parameters, but it is still hard to deploy them due to their immense parameter sizes. Different from previous weight pruning methods that rely on specifically designed hardware, this paper mainly aims to enhance the deployment efficiency of MoE LLMs by introducing plug-and-play expert-level sparsification techniques. Specifically, we propose, for the first time to our best knowledge, post-training approaches for task-agnostic and task-specific expert pruning and skipping of MoE LLMs, tailored to improve deployment efficiency while maintaining model performance across a wide range of tasks. Extensive experiments show that our proposed methods can simultaneously reduce model sizes and increase the inference speed, while maintaining sat
    
[^9]: 利用非正式逻辑增强系统化分解的自然语言推理

    Enhancing Systematic Decompositional Natural Language Inference Using Informal Logic

    [https://arxiv.org/abs/2402.14798](https://arxiv.org/abs/2402.14798)

    本文提出了一种一致且在理论上有根据的方法来注释分解蕴涵数据集，形成RDTE数据集，该数据集在解决何为有效的组合蕴涵的问题上有显著进展。

    

    当代语言模型为使用文本进行结构化推理提供了新的机会，例如在不依赖脆弱的形式逻辑的情况下构建和评估直观的、类似证明的文本蕴涵树。然而，沿着这个方向的进展受到一个长期以来缺乏明确的确定何为有效的组合蕴涵的清晰协议的阻碍。本文提出了一个一致且在理论上有根据的方法来注释分解蕴涵数据集，并评估其对基于LLM的文本推理的影响。我们发现，我们的结果数据集RDTE (Recognizing Decompositional Textual Entailment) 的内部一致性比先前的分解蕴涵数据集高得多（+9%），表明RDTE在长期存在的关于何为有效的组合蕴涵的问题上是一个重要的进步。

    arXiv:2402.14798v1 Announce Type: cross  Abstract: Contemporary language models enable new opportunities for structured reasoning with text, such as the construction and evaluation of intuitive, proof-like textual entailment trees without relying on brittle formal logic. However, progress in this direction has been hampered by a long-standing lack of a clear protocol for determining what valid compositional entailment is. This absence causes noisy datasets and limited performance gains by modern neuro-symbolic engines. To address these problems, we formulate a consistent and theoretically grounded approach to annotating decompositional entailment datasets, and evaluate its impact on LLM-based textual inference. We find that our resulting dataset, RDTE (Recognizing Decompositional Textual Entailment), has a substantially higher internal consistency (+9%) than prior decompositional entailment datasets, suggesting that RDTE is a significant step forward in the long-standing problem of for
    
[^10]: Snap Video: 规模化时空Transformer用于文本到视频合成

    Snap Video: Scaled Spatiotemporal Transformers for Text-to-Video Synthesis

    [https://arxiv.org/abs/2402.14797](https://arxiv.org/abs/2402.14797)

    Snap Video是一个视频优先模型，通过扩展EDM框架并提出基于Transformer的架构，解决了文本到视频合成中的动态保真度、视觉质量和可扩展性挑战。

    

    当代生成图像的模型展现出卓越的质量和多功能性。受到这些优势的影响，研究团体重新运用它们来生成视频。由于视频内容高度冗余，我们认为单纯地将图像模型的进展带到视频生成领域会降低动态保真度、视觉质量并影响可扩展性。在这项研究中，我们构建了Snap Video，一个以视频为先的模型，系统地解决了这些挑战。为此，我们首先扩展EDM框架以考虑时空冗余像素并自然地支持视频生成。其次，我们展示了U-Net - 图像生成背后的得力工具 - 在生成视频时扩展性较差，需要显著的计算开销。因此，我们提出了一种新的基于Transformer的架构，训练速度比U-Nets快3.31倍（推理速度约快4.5倍）。这使我们能够高效地训练一个文本到视频的模型。

    arXiv:2402.14797v1 Announce Type: cross  Abstract: Contemporary models for generating images show remarkable quality and versatility. Swayed by these advantages, the research community repurposes them to generate videos. Since video content is highly redundant, we argue that naively bringing advances of image models to the video generation domain reduces motion fidelity, visual quality and impairs scalability. In this work, we build Snap Video, a video-first model that systematically addresses these challenges. To do that, we first extend the EDM framework to take into account spatially and temporally redundant pixels and naturally support video generation. Second, we show that a U-Net - a workhorse behind image generation - scales poorly when generating videos, requiring significant computational overhead. Hence, we propose a new transformer-based architecture that trains 3.31 times faster than U-Nets (and is ~4.5 faster at inference). This allows us to efficiently train a text-to-vid
    
[^11]: 针对领域无关自监督学习的自导蒙面自动编码器

    Self-Guided Masked Autoencoders for Domain-Agnostic Self-Supervised Learning

    [https://arxiv.org/abs/2402.14789](https://arxiv.org/abs/2402.14789)

    自导蒙面自动编码器（SMA）是一种完全领域无关的蒙面建模方法，通过学习蒙面采样而不做任何领域特定的假设，可以在各种数据模态上进行自监督学习。

    

    自监督学习在大量无标签数据中学习表示方面表现出色，并在多个数据模态上取得成功。然而，将自监督学习扩展到新的模态并不容易，因为现有方法的具体细节是针对每个领域量身定制的，比如特定领域的数据增强反映了目标任务中的不变性。 而蒙面建模作为一种领域无关的自监督学习框架很有前途，因为它不依赖于输入增强，但其蒙面采样过程仍然领域特定。我们提出了自导蒙面自动编码器（SMA），这是一种完全领域无关的蒙面建模方法。SMA使用基于注意力的模型进行训练，使用蒙面建模目标学习蒙面采样，而不做任何领域特定的假设。我们在蛋白生物学、化学性质预测和粒子物理学三个自监督学习基准上评估了SMA。

    arXiv:2402.14789v1 Announce Type: cross  Abstract: Self-supervised learning excels in learning representations from large amounts of unlabeled data, demonstrating success across multiple data modalities. Yet, extending self-supervised learning to new modalities is non-trivial because the specifics of existing methods are tailored to each domain, such as domain-specific augmentations which reflect the invariances in the target task. While masked modeling is promising as a domain-agnostic framework for self-supervised learning because it does not rely on input augmentations, its mask sampling procedure remains domain-specific. We present Self-guided Masked Autoencoders (SMA), a fully domain-agnostic masked modeling method. SMA trains an attention based model using a masked modeling objective, by learning masks to sample without any domain-specific assumptions. We evaluate SMA on three self-supervised learning benchmarks in protein biology, chemical property prediction, and particle physi
    
[^12]: Rao-Blackwellising Bayesian Causal Inference

    Rao-Blackwellising Bayesian Causal Inference

    [https://arxiv.org/abs/2402.14781](https://arxiv.org/abs/2402.14781)

    本文结合顺序化的MCMC结构学习技术和梯度图学习的最新进展，构建了一个有效的贝叶斯因果推断框架，将因果结构推断问题分解为变量拓扑顺序推断和变量父节点集合推断，同时使用高斯过程进行因果机制建模实现精确边缘化，引入了一个Rao-Blackwell化方案。

    

    贝叶斯因果推断，即推断用于下游因果推理任务中的因果模型的后验概率，构成了一个在文献中鲜有探讨的难解的计算推断问题。本文将基于顺序的MCMC结构学习技术与最近梯度图学习的进展相结合，构建了一个有效的贝叶斯因果推断框架。具体而言，我们将推断因果结构的问题分解为(i)推断变量之间的拓扑顺序以及(ii)推断每个变量的父节点集合。当限制每个变量的父节点数量时，我们可以在多项式时间内完全边缘化父节点集合。我们进一步使用高斯过程来建模未知的因果机制，从而允许其精确边缘化。这引入了一个Rao-Blackwell化方案，其中除了因果顺序之外，模型中的所有组件都被消除。

    arXiv:2402.14781v1 Announce Type: cross  Abstract: Bayesian causal inference, i.e., inferring a posterior over causal models for the use in downstream causal reasoning tasks, poses a hard computational inference problem that is little explored in literature. In this work, we combine techniques from order-based MCMC structure learning with recent advances in gradient-based graph learning into an effective Bayesian causal inference framework. Specifically, we decompose the problem of inferring the causal structure into (i) inferring a topological order over variables and (ii) inferring the parent sets for each variable. When limiting the number of parents per variable, we can exactly marginalise over the parent sets in polynomial time. We further use Gaussian processes to model the unknown causal mechanisms, which also allows their exact marginalisation. This introduces a Rao-Blackwellization scheme, where all components are eliminated from the model, except for the causal order, for whi
    
[^13]: 大型语言模型指令微调中的零次跨语言转移

    Zero-shot cross-lingual transfer in instruction tuning of large language model

    [https://arxiv.org/abs/2402.14778](https://arxiv.org/abs/2402.14778)

    本研究探讨了大型语言模型在指令微调中的零次跨语言转移，发现在适当超参数调整和足够大的数据支持下，英语训练的模型能够成功生成其他语言的准确、有用回应，但存在事实准确性和流畅性错误。

    

    指令微调（IT）被广泛用于教导预训练的大型语言模型（LLMs）遵循任意指令，但在多语言环境下尚未得到充分研究。本研究系统地研究了在IT中的零次跨语言转移，当LLM在仅英语数据上进行指令微调然后在其他语言用户提示上进行测试时。我们调查了模型配置选择的影响，并设计了一种多方面评估策略用于多语言指令遵循。我们发现即使模型训练的所有阶段都以英语为中心，跨语言转移在IT中也会成功发生，但只有在超参数调整中考虑到多语言性以及有足够大的IT数据时才会发生。经过英语训练的LLMs能够在其他语言中生成准确、全面且有帮助的回应，但缺乏事实准确性，并且偶尔可能存在流畅性错误。

    arXiv:2402.14778v1 Announce Type: cross  Abstract: Instruction tuning (IT) is widely used to teach pretrained large language models (LLMs) to follow arbitrary instructions, but is under-studied in multilingual settings. In this work, we conduct a systematic study of zero-shot cross-lingual transfer in IT, when an LLM is instruction-tuned on English-only data and then tested on user prompts in other languages. We investigate the influence of model configuration choices and devise a multi-facet evaluation strategy for multilingual instruction following. We find that cross-lingual transfer does happen successfully in IT even if all stages of model training are English-centric, but only if multiliguality is taken into account in hyperparameter tuning and with large enough IT data. English-trained LLMs are capable of generating correct-language, comprehensive and helpful responses in the other languages, but suffer from low factuality and may occasionally have fluency errors.
    
[^14]: MT-Bench-101: 用于评估大型语言模型在多轮对话中的细粒度基准

    MT-Bench-101: A Fine-Grained Benchmark for Evaluating Large Language Models in Multi-Turn Dialogues

    [https://arxiv.org/abs/2402.14762](https://arxiv.org/abs/2402.14762)

    提出了MT-Bench-101用于评估大型语言模型在多轮对话中的细粒度能力，构建了包含4208轮对话数据的三级分层能力分类，并评估了21种流行的语言模型，发现它们在不同对话轮次中表现出不同的趋势。

    

    大型语言模型（LLMs）的出现大大增强了对话系统。然而，全面评估LLMs的对话能力仍然是一个挑战。以往的基准主要集中在单轮对话或者提供粗粒度和不完整的多轮对话评估，忽视了真实对话的复杂性和细微的差异。为了解决这个问题，我们引入了MT-Bench-101，专门设计用于评估LLMs在多轮对话中的细粒度能力。通过对真实多轮对话数据进行详细分析，我们构建了一个包含13个不同任务中1388个多轮对话中的4208轮的三级分层能力分类。然后我们基于MT-Bench-101评估了21个流行的LLMs，从能力和任务两个角度进行全面分析，并观察到LLMs在对话轮次中表现出不同的趋势。

    arXiv:2402.14762v1 Announce Type: cross  Abstract: The advent of Large Language Models (LLMs) has drastically enhanced dialogue systems. However, comprehensively evaluating the dialogue abilities of LLMs remains a challenge. Previous benchmarks have primarily focused on single-turn dialogues or provided coarse-grained and incomplete assessments of multi-turn dialogues, overlooking the complexity and fine-grained nuances of real-life dialogues. To address this issue, we introduce MT-Bench-101, specifically designed to evaluate the fine-grained abilities of LLMs in multi-turn dialogues. By conducting a detailed analysis of real multi-turn dialogue data, we construct a three-tier hierarchical ability taxonomy comprising 4208 turns across 1388 multi-turn dialogues in 13 distinct tasks. We then evaluate 21 popular LLMs based on MT-Bench-101, conducting comprehensive analyses from both ability and task perspectives and observing differing trends in LLMs performance across dialogue turns with
    
[^15]: 在认知不确定性下推广统计学习理论中的可实现性

    Generalising realisability in statistical learning theory under epistemic uncertainty

    [https://arxiv.org/abs/2402.14759](https://arxiv.org/abs/2402.14759)

    统计学习理论中的中心概念在假设训练和测试分布源自相同置信集的情况下如何推广，是对统计学习在认知不确定性下更一般处理的首要步骤。

    

    本文旨在探讨统计学习理论中的中心概念，如可实现性，在假设训练和测试分布源自相同置信集，即一个概率分布的凸集的情况下如何推广。这可以被认为是在认知不确定性下对统计学习进行更一般处理的第一步。

    arXiv:2402.14759v1 Announce Type: cross  Abstract: The purpose of this paper is to look into how central notions in statistical learning theory, such as realisability, generalise under the assumption that train and test distribution are issued from the same credal set, i.e., a convex set of probability distributions. This can be considered as a first step towards a more general treatment of statistical learning under epistemic uncertainty.
    
[^16]: 批处理和匹配：基于分数的离散的黑匣子变分推断

    Batch and match: black-box variational inference with a score-based divergence

    [https://arxiv.org/abs/2402.14758](https://arxiv.org/abs/2402.14758)

    BaM是一种基于分数的离散的BBVI替代方法，针对高方差梯度估计慢收敛问题，能够在高斯变分族中通过封闭形式的近端更新进行优化，在目标分布为高斯时，批处理大小趋于无穷时变分参数更新将指数快速收敛到目标均值和协方差，BaM在多种生成模型推断中表现出良好性能

    

    大多数主要的黑匣子变分推断（BBVI）实现都是基于优化随机证据下界（ELBO）。但是，这种BBVI方法通常由于其梯度估计的高方差而收敛缓慢。在本文中，我们提出了批处理和匹配（BaM），这是一种基于分数的离散的BBVI替代方法。值得注意的是，这种基于分数的离散可以通过对具有全协方差矩阵的高斯变分族使用封闭形式的近端更新进行优化。我们分析了当目标分布为高斯分布时BaM的收敛性，并证明在批量大小趋于无穷时变分参数更新会指数收敛到目标均值和协方差。我们还评估了BaM在源自层次和深度生成模型后验推断的高斯和非高斯目标分布上的性能。在这些实验中，我们发现BaM在...

    arXiv:2402.14758v1 Announce Type: cross  Abstract: Most leading implementations of black-box variational inference (BBVI) are based on optimizing a stochastic evidence lower bound (ELBO). But such approaches to BBVI often converge slowly due to the high variance of their gradient estimates. In this work, we propose batch and match (BaM), an alternative approach to BBVI based on a score-based divergence. Notably, this score-based divergence can be optimized by a closed-form proximal update for Gaussian variational families with full covariance matrices. We analyze the convergence of BaM when the target distribution is Gaussian, and we prove that in the limit of infinite batch size the variational parameter updates converge exponentially quickly to the target mean and covariance. We also evaluate the performance of BaM on Gaussian and non-Gaussian target distributions that arise from posterior inference in hierarchical and deep generative models. In these experiments, we find that BaM ty
    
[^17]: SHM-Traffic: 基于DRL和迁移学习的无人机控制用于带交通的桥梁结构健康监测

    SHM-Traffic: DRL and Transfer learning based UAV Control for Structural Health Monitoring of Bridges with Traffic

    [https://arxiv.org/abs/2402.14757](https://arxiv.org/abs/2402.14757)

    该研究提出了一种基于DRL和迁移学习的无人机控制方法，用于带交通的桥梁结构健康监测，实现了在交通持续进行时对混凝土桥面进行裂缝检测和定位的具体桥面检测技术应用

    

    这项工作侧重于利用先进技术进行带有交通的桥梁结构健康监测（SHM）。我们提出了一种使用基于深度强化学习（DRL）的无人机（UAV）控制的方法。我们的方法在交通持续进行时进行混凝土桥面调查并检测裂缝。无人机执行裂缝检测，裂缝的位置最初是未知的。我们使用了两种边缘检测技术。首先，我们使用Canny边缘检测进行裂缝检测。我们还使用了卷积神经网络（CNN）进行裂缝检测，并将其与Canny边缘检测进行了比较。使用具有来自裂缝图像数据集的预训练权重的CNN进行迁移学习。这使模型能够适应并提高其在识别和定位裂缝方面的性能。应用Proximal Policy Optimization（PPO）进行UAV控制和桥梁调查。进行了跨不同场景的实验

    arXiv:2402.14757v1 Announce Type: new  Abstract: This work focuses on using advanced techniques for structural health monitoring (SHM) for bridges with Traffic. We propose an approach using deep reinforcement learning (DRL)-based control for Unmanned Aerial Vehicle (UAV). Our approach conducts a concrete bridge deck survey while traffic is ongoing and detects cracks. The UAV performs the crack detection, and the location of cracks is initially unknown. We use two edge detection techniques. First, we use canny edge detection for crack detection. We also use a Convolutional Neural Network (CNN) for crack detection and compare it with canny edge detection. Transfer learning is applied using CNN with pre-trained weights obtained from a crack image dataset. This enables the model to adapt and improve its performance in identifying and localizing cracks. Proximal Policy Optimization (PPO) is applied for UAV control and bridge surveys. The experimentation across various scenarios is performed
    
[^18]: Pretrained Transformer的引导可以成为通用逼近器

    Prompting a Pretrained Transformer Can Be a Universal Approximator

    [https://arxiv.org/abs/2402.14753](https://arxiv.org/abs/2402.14753)

    这项研究表明，通过提示或前缀调整Pretrained Transformer可以成为通用逼近器，甚至比之前认为的更小的模型都可以实现这一功能。

    

    尽管Prompting、Prompt调整和前缀调整transformer模型已经被广泛采用，但我们对这些微调方法的理论理解仍然有限。一个关键问题是是否可以通过提示或前缀调整预训练模型的行为。形式上，提示和前缀调整预训练模型能否普遍逼近序列到序列的函数。本文肯定回答了这个问题，并证明比先前认为的要小得多的预训练模型在添加前缀后可以成为通用逼近器。事实上，注意力机制非常适合于前缀调整，一个单一的注意力头就足以逼近任何连续函数。此外，通过在transformer的深度中添加前缀，任何序列到序列函数都可以被逼近，其深度与序列长度成线性关系。除了这些密度类型结果，我们还提供了Jack...

    arXiv:2402.14753v1 Announce Type: cross  Abstract: Despite the widespread adoption of prompting, prompt tuning and prefix-tuning of transformer models, our theoretical understanding of these fine-tuning methods remains limited. A key question is whether one can arbitrarily modify the behavior of pretrained model by prompting or prefix-tuning it. Formally, whether prompting and prefix-tuning a pretrained model can universally approximate sequence-to-sequence functions. This paper answers in the affirmative and demonstrates that much smaller pretrained models than previously thought can be universal approximators when prefixed. In fact, the attention mechanism is uniquely suited for universal approximation with prefix-tuning a single attention head being sufficient to approximate any continuous function. Moreover, any sequence-to-sequence function can be approximated by prefixing a transformer with depth linear in the sequence length. Beyond these density-type results, we also offer Jack
    
[^19]: 大型语言模型作为城市居民：用于个人移动生成的LLM代理框架

    Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation

    [https://arxiv.org/abs/2402.14744](https://arxiv.org/abs/2402.14744)

    提出了一种将大型语言模型LLMs整合到代理框架中的新方法，用于生成个人移动生成，重点是解决将LLMs与真实城市流动数据对齐的问题，并提出了一种自洽方法和检索增强策略来实现可解释活动生成。

    

    本文介绍了一种新方法，将大型语言模型(LLMs)集成到代理框架中，用于灵活高效的个人移动生成。LLMs通过高效处理语义数据并在建模各种任务中提供多功能性, 克服了以往模型的局限性。我们的方法解决了将LLMs与真实世界城市流动数据对齐的迫切需求, 重点关注三个研究问题: 将LLMs与丰富的活动数据对齐, 开发可靠的活动生成策略, 以及探索LLMs在城市移动中的应用。其关键技术贡献是一种新颖的LLM代理框架, 该框架考虑了个体活动模式和动机, 包括将LLMs与真实世界活动数据对齐的自洽方法和可解释活动生成的检索增强策略。在实验研究中, 使用真实世界数据进行了全面验证。

    arXiv:2402.14744v1 Announce Type: new  Abstract: This paper introduces a novel approach using Large Language Models (LLMs) integrated into an agent framework for flexible and efficient personal mobility generation. LLMs overcome the limitations of previous models by efficiently processing semantic data and offering versatility in modeling various tasks. Our approach addresses the critical need to align LLMs with real-world urban mobility data, focusing on three research questions: aligning LLMs with rich activity data, developing reliable activity generation strategies, and exploring LLM applications in urban mobility. The key technical contribution is a novel LLM agent framework that accounts for individual activity patterns and motivations, including a self-consistency approach to align LLMs with real-world activity data and a retrieval-augmented strategy for interpretable activity generation. In experimental studies, comprehensive validation is performed using real-world data. This 
    
[^20]: Clifford-Steerable卷积神经网络

    Clifford-Steerable Convolutional Neural Networks

    [https://arxiv.org/abs/2402.14730](https://arxiv.org/abs/2402.14730)

    提出了Clifford-Steerable卷积神经网络（CS-CNNs），通过在伪欧几里德空间上处理多矢场，利用Clifford群等变神经网络对$\mathrm{O}(p,q)$可导核进行隐式参数化，显着且一致地优于流体动力学和相对论电动力学预测任务的基准方法

    

    我们提出了Clifford-Steerable卷积神经网络（CS-CNNs），这是一种新颖的$\mathrm{E}(p, q)$等变CNN类。 CS-CNNs在伪欧几里德空间$\mathbb{R}^{p,q}$上处理多矢场。 它们涵盖了例如$\mathrm{E}(3)$在$\mathbb{R}^3$上和Poincar\'e在闵可夫斯基时空$\mathbb{R}^{1,3}$上的等变性。 我们的方法基于通过Clifford群等变神经网络对$\mathrm{O}(p,q)$可导核进行隐式参数化。 在流体动力学和相对论电动力学预测任务上，我们在基准方法上显着且一致地表现出色。

    arXiv:2402.14730v1 Announce Type: cross  Abstract: We present Clifford-Steerable Convolutional Neural Networks (CS-CNNs), a novel class of $\mathrm{E}(p, q)$-equivariant CNNs. CS-CNNs process multivector fields on pseudo-Euclidean spaces $\mathbb{R}^{p,q}$. They cover, for instance, $\mathrm{E}(3)$-equivariance on $\mathbb{R}^3$ and Poincar\'e-equivariance on Minkowski spacetime $\mathbb{R}^{1,3}$. Our approach is based on an implicit parametrization of $\mathrm{O}(p,q)$-steerable kernels via Clifford group equivariant neural networks. We significantly and consistently outperform baseline methods on fluid dynamics as well as relativistic electrodynamics forecasting tasks.
    
[^21]: 欧洲对人本科技的承诺：HCI在欧盟AI法案成功中的重要作用

    The European Commitment to Human-Centered Technology: The Integral Role of HCI in the EU AI Act's Success

    [https://arxiv.org/abs/2402.14728](https://arxiv.org/abs/2402.14728)

    欧盟AI法案强调透明性、可解释性和人类理解能力，提出了人本AI系统的民主呼吁，同时制定了人本创新的跨学科研究议程，以避免重复GDPR的错误并避免实施混乱。

    

    AI的发展将深刻重塑未来。欧盟认识到这一即将到来的重要性，已经通过了AI法案，对基于AI的系统的市场准入进行监管。该法案的一个显著特征是通过专注于透明性、可解释性以及人类理解和控制AI系统的能力，维护民主和人道主义价值观。因此，欧盟AI法案不仅仅规定了AI系统的技术要求。欧盟发出了一个民主号召，要求人本AI系统，进而制定了人本创新的跨学科研究议程，促进AI发展中的人本创新。如果没有强大的方法来评估AI系统及其对个人和社会的影响，欧盟AI法案可能会导致重复欧盟《一般数据保护条例》的错误，导致仓促、混乱、临时和模糊的实施，带来更多的困惑而不是指导。

    arXiv:2402.14728v1 Announce Type: cross  Abstract: The evolution of AI is set to profoundly reshape the future. The European Union, recognizing this impending prominence, has enacted the AI Act, regulating market access for AI-based systems. A salient feature of the Act is to guard democratic and humanistic values by focusing regulation on transparency, explainability, and the human ability to understand and control AI systems. Hereby, the EU AI Act does not merely specify technological requirements for AI systems. The EU issues a democratic call for human-centered AI systems and, in turn, an interdisciplinary research agenda for human-centered innovation in AI development. Without robust methods to assess AI systems and their effect on individuals and society, the EU AI Act may lead to repeating the mistakes of the General Data Protection Regulation of the EU and to rushed, chaotic, ad-hoc, and ambiguous implementation, causing more confusion than lending guidance. Moreover, determine
    
[^22]: 在概念学习框架中将专家规则融入神经网络

    Incorporating Expert Rules into Neural Networks in the Framework of Concept-Based Learning

    [https://arxiv.org/abs/2402.14726](https://arxiv.org/abs/2402.14726)

    本文提出了将专家规则融入神经网络的方法，通过形成约束和使用凸多面体来保证输出概率不违反专家规则，实现了归纳与演绎学习的结合。

    

    本文阐述了将专家规则融入机器学习模型中以扩展基于概念学习的问题。提出了如何将逻辑规则和预测概念概率的神经网络相结合。该组合背后的第一个想法是形成约束，以满足专家规则的所有概念值组合的联合概率分布。第二个想法是以凸多面体的形式表示概率分布的可行集，并使用其顶点或面。

    arXiv:2402.14726v1 Announce Type: cross  Abstract: A problem of incorporating the expert rules into machine learning models for extending the concept-based learning is formulated in the paper. It is proposed how to combine logical rules and neural networks predicting the concept probabilities. The first idea behind the combination is to form constraints for a joint probability distribution over all combinations of concept values to satisfy the expert rules. The second idea is to represent a feasible set of probability distributions in the form of a convex polytope and to use its vertices or faces. We provide several approaches for solving the stated problem and for training neural networks which guarantee that the output probabilities of concepts would not violate the expert rules. The solution of the problem can be viewed as a way for combining the inductive and deductive learning. Expert rules are used in a broader sense when any logical function that connects concepts and class labe
    
[^23]: 高效有效的词汇扩展方法在多语言大型语言模型中的应用

    Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models

    [https://arxiv.org/abs/2402.14714](https://arxiv.org/abs/2402.14714)

    提出了一种高效且有效的词汇扩展方法（EEVE），可以显著提升非英语语言模型的性能，使得其在韩文文本理解方面表现出色。

    

    这篇报告介绍了\texttt{EEVE-Korean-v1.0}，这是大型语言模型的韩文适配版本，展现出在英文和韩文文本理解方面的显著能力。我们提出了一种高效且有效的词汇扩展方法（EEVE），包括参数冻结和子词初始化。与先前认为新嵌入需要上万亿训练标记的努力相反，我们展示了我们的方法可以在仅20亿标记内显着提升非英语熟练度。截至2024年1月，我们的模型\texttt{EEVE-Korean-10.8B-v1.0}在Open Ko-LLM榜单上超越了大多数经过指导调整的LLMs，成为了开源社区中表现最好的韩文预训练模型，根据Hugging Face的排行榜。

    arXiv:2402.14714v1 Announce Type: cross  Abstract: This report introduces \texttt{EEVE-Korean-v1.0}, a Korean adaptation of large language models that exhibit remarkable capabilities across English and Korean text understanding. Building on recent highly capable but English-centric LLMs, such as SOLAR-10.7B and Phi-2, where non-English texts are inefficiently processed with English-centric tokenizers, we present an efficient and effective vocabulary expansion (EEVE) method, which encompasses parameter freezing and subword initialization. In contrast to previous efforts that believe new embeddings require trillions of training tokens, we show that our method can significantly boost non-English proficiency within just 2 billion tokens. Surpassing most instruction-tuned LLMs on the Open Ko-LLM Leaderboard, as of January 2024, our model \texttt{EEVE-Korean-10.8B-v1.0} ranks as the leading Korean pre-trained model in the open-source community, according to Hugging Face's leaderboard. We ope
    
[^24]: IEPile: 挖掘大规模基于模式的信息抽取语料库

    IEPile: Unearthing Large-Scale Schema-Based Information Extraction Corpus

    [https://arxiv.org/abs/2402.14710](https://arxiv.org/abs/2402.14710)

    发布了IEPile，一个包含约0.32B个标记的综合双语IE指令语料库，通过收集和清理33个现有IE数据集并引入基于模式的指令生成，可以提高大型语言模型在信息抽取领域的性能，尤其是零样本泛化。

    

    大型语言模型（LLMs）在各个领域展现出了显著的潜力；然而，在信息抽取（IE）方面表现出了显著的性能差距。高质量的指令数据是提升LLMs特定能力的关键，而当前的IE数据集往往规模较小、分散且缺乏标准化的模式。因此，我们介绍了IEPile，一个综合的双语（英文和中文）IE指令语料库，包含约0.32B个标记。我们通过收集和清理33个现有IE数据集构建IEPile，并引入基于模式的指令生成来挖掘大规模语料库。在LLaMA和Baichuan上的实验结果表明，使用IEPile可以提高LLMs在IE方面的性能，尤其是零样本泛化。我们开源了资源和预训练模型，希望为自然语言处理社区提供有价值的支持。

    arXiv:2402.14710v1 Announce Type: cross  Abstract: Large Language Models (LLMs) demonstrate remarkable potential across various domains; however, they exhibit a significant performance gap in Information Extraction (IE). Note that high-quality instruction data is the vital key for enhancing the specific capabilities of LLMs, while current IE datasets tend to be small in scale, fragmented, and lack standardized schema. To this end, we introduce IEPile, a comprehensive bilingual (English and Chinese) IE instruction corpus, which contains approximately 0.32B tokens. We construct IEPile by collecting and cleaning 33 existing IE datasets, and introduce schema-based instruction generation to unearth a large-scale corpus. Experimental results on LLaMA and Baichuan demonstrate that using IEPile can enhance the performance of LLMs for IE, especially the zero-shot generalization. We open-source the resource and pre-trained models, hoping to provide valuable support to the NLP community.
    
[^25]: 通过因果时间图神经网络增强信用卡欺诈检测

    CaT-GNN: Enhancing Credit Card Fraud Detection via Causal Temporal Graph Neural Networks

    [https://arxiv.org/abs/2402.14708](https://arxiv.org/abs/2402.14708)

    该论文提出了一种名为CaT-GNN的新型信用卡欺诈检测方法，通过因果不变性学习揭示交易数据中的固有相关性，并引入因果混合策略来增强模型的鲁棒性和可解释性。

    

    信用卡欺诈对经济构成重大威胁。尽管基于图神经网络（GNN）的欺诈检测方法表现良好，但它们经常忽视节点的本地结构对预测的因果效应。本文引入了一种新颖的信用卡欺诈检测方法——CaT-GNN（Causal Temporal Graph Neural Networks），利用因果不变性学习来揭示交易数据中的固有相关性。通过将问题分解为发现和干预阶段，CaT-GNN确定交易图中的因果节点，并应用因果混合策略来增强模型的鲁棒性和可解释性。CaT-GNN由两个关键组件组成：Causal-Inspector和Causal-Intervener。Causal-Inspector利用时间注意力机制中的注意力权重来识别因果和环境

    arXiv:2402.14708v1 Announce Type: cross  Abstract: Credit card fraud poses a significant threat to the economy. While Graph Neural Network (GNN)-based fraud detection methods perform well, they often overlook the causal effect of a node's local structure on predictions. This paper introduces a novel method for credit card fraud detection, the \textbf{\underline{Ca}}usal \textbf{\underline{T}}emporal \textbf{\underline{G}}raph \textbf{\underline{N}}eural \textbf{N}etwork (CaT-GNN), which leverages causal invariant learning to reveal inherent correlations within transaction data. By decomposing the problem into discovery and intervention phases, CaT-GNN identifies causal nodes within the transaction graph and applies a causal mixup strategy to enhance the model's robustness and interpretability. CaT-GNN consists of two key components: Causal-Inspector and Causal-Intervener. The Causal-Inspector utilizes attention weights in the temporal attention mechanism to identify causal and environm
    
[^26]: 在未来依赖价值函数中探讨未来和历史的诅咒在离线评估中的应用

    On the Curses of Future and History in Future-dependent Value Functions for Off-policy Evaluation

    [https://arxiv.org/abs/2402.14703](https://arxiv.org/abs/2402.14703)

    本文提出了针对POMDP结构的新颖覆盖假设，以解决未来依赖价值函数方法中的长度指数增长问题。

    

    我们研究了在部分可观测环境中复杂观测的离线评估(OPE)，旨在开发能够避免对时间跨度指数依赖的估计器。最近，Uehara等人（2022年）提出了未来依赖价值函数作为解决这一问题的一个有前途的框架。然而，该框架也取决于未来依赖价值函数的有界性以及其他相关数量，我们发现这些数量可能会随着长度呈指数增长，从而抹去该方法的优势。在本文中，我们发现了针对POMDP结构的新颖覆盖假设。

    arXiv:2402.14703v1 Announce Type: cross  Abstract: We study off-policy evaluation (OPE) in partially observable environments with complex observations, with the goal of developing estimators whose guarantee avoids exponential dependence on the horizon. While such estimators exist for MDPs and POMDPs can be converted to history-based MDPs, their estimation errors depend on the state-density ratio for MDPs which becomes history ratios after conversion, an exponential object. Recently, Uehara et al. (2022) proposed future-dependent value functions as a promising framework to address this issue, where the guarantee for memoryless policies depends on the density ratio over the latent state space. However, it also depends on the boundedness of the future-dependent value function and other related quantities, which we show could be exponential-in-length and thus erasing the advantage of the method. In this paper, we discover novel coverage assumptions tailored to the structure of POMDPs, such
    
[^27]: COMPASS：利用语言建模对患者-治疗师联盟策略进行计算映射

    COMPASS: Computational Mapping of Patient-Therapist Alliance Strategies with Language Modeling

    [https://arxiv.org/abs/2402.14701](https://arxiv.org/abs/2402.14701)

    本文提出了一种名为COMPASS的新框架，通过分析心理治疗会话中的自然语言，直接推断治疗工作联盟，为临床精神病学提供了可解释性，并在识别与正在治疗的疾病相关的新兴模式方面发挥作用。

    

    治疗工作联盟是预测心理治疗治疗成功的关键因素。传统上，工作联盟评估依赖于治疗师和患者填写的问卷。本文提出了COMPASS，一个新颖的框架，可直接从心理治疗课程中使用的自然语言中推断治疗工作联盟。我们的方法利用先进的大型语言模型分析心理治疗会话的转录，并将其与工作联盟清单中陈述的分布式表示进行比较。通过分析涵盖多种精神疾病的超过950个会话的数据集，我们展示了我们的方法在显微地映射患者-治疗师对齐轨迹方面的有效性，并为临床精神病学提供解释性，并在识别与正在治疗的疾病相关的新兴模式方面提供可解释性。通过使用各种神经主题模式

    arXiv:2402.14701v1 Announce Type: cross  Abstract: The therapeutic working alliance is a critical factor in predicting the success of psychotherapy treatment. Traditionally, working alliance assessment relies on questionnaires completed by both therapists and patients. In this paper, we present COMPASS, a novel framework to directly infer the therapeutic working alliance from the natural language used in psychotherapy sessions. Our approach utilizes advanced large language models to analyze transcripts of psychotherapy sessions and compare them with distributed representations of statements in the working alliance inventory. Analyzing a dataset of over 950 sessions covering diverse psychiatric conditions, we demonstrate the effectiveness of our method in microscopically mapping patient-therapist alignment trajectories and providing interpretability for clinical psychiatry and in identifying emerging patterns related to the condition being treated. By employing various neural topic mode
    
[^28]: 大数据分析用于分类与土方相关的地点：成都研究

    Big data analytics to classify earthwork-related locations: A Chengdu study

    [https://arxiv.org/abs/2402.14698](https://arxiv.org/abs/2402.14698)

    使用大数据分析方法，研究者利用自卸车轨迹、城市兴趣点和土地覆盖数据，成功对城市灰尘污染源进行了分类，证明仅需有限数量特征即可实现高准确度分类。

    

    空气污染显著加剧，导致全球范围内的严重健康后果。土方相关的地点（ERLs）是城市灰尘污染的重要来源。长期以来，ERLs的有效管理一直是政府和环境机构面临的挑战之一，主要原因包括其分类分属不同的监管部门、信息障碍、数据更新延迟，以及对不同源头灰尘污染的抑制措施的缺乏。为解决这些挑战，我们利用自卸车轨迹、城市兴趣点（POI）和土地覆盖数据对城市灰尘污染源进行分类。我们比较了几种预测模型，并利用实际数据研究了特征与灰尘污染源之间的关系。结果表明，通过有限数量的特征可以实现高准确度的分类。这种方法已成功实施在一个名为的系统中。

    arXiv:2402.14698v1 Announce Type: cross  Abstract: Air pollution has significantly intensified, leading to severe health consequences worldwide. Earthwork-related locations (ERLs) constitute significant sources of urban dust pollution. The effective management of ERLs has long posed challenges for governmental and environmental agencies, primarily due to their classification under different regulatory authorities, information barriers, delays in data updating, and a lack of dust suppression measures for various sources of dust pollution. To address these challenges, we classified urban dust pollution sources using dump truck trajectory, urban point of interest (POI), and land cover data. We compared several prediction models and investigated the relationship between features and dust pollution sources using real data. The results demonstrate that high-accuracy classification can be achieved with a limited number of features. This method was successfully implemented in the system called
    
[^29]: 多模大语言模型的视觉幻觉

    Visual Hallucinations of Multi-modal Large Language Models

    [https://arxiv.org/abs/2402.14683](https://arxiv.org/abs/2402.14683)

    多模大语言模型通过生成多样的视觉幻觉实例来检验其性能，发现现有的模型在这方面存在幻觉问题，为进一步研究和改进提供了线索。

    

    视觉幻觉（VH）意味着多模大语言模型（MLLM）在视觉问答中对图像想象出错误的细节。现有研究发现VH实例仅存在于现有图像数据集中，这导致了对MLLM在VH下的性能理解存在偏差，原因在于这类VH实例的多样性有限。在本研究中，我们提出了一个名为VHTest的工具，用于生成多样的VH实例。具体来说，VHTest在现有图像数据集（例如COCO）中找到一些初始的VH实例，为每个VH模式生成一个文本描述，并使用文本到图像生成模型（例如DALL-E-3）基于文本描述生成VH图像。我们利用VHTest收集了一个包含8个VH模式中1,200个VH实例的基准数据集。我们发现，现有的MLLM（例如GPT-4V、LLaVA-1.5和MiniGPT-v2）在我们的基准测试中对大部分实例产生幻觉。此外，我们发现使用我们的基准数据对MLLM进行微调

    arXiv:2402.14683v1 Announce Type: cross  Abstract: Visual hallucination (VH) means that a multi-modal LLM (MLLM) imagines incorrect details about an image in visual question answering. Existing studies find VH instances only in existing image datasets, which results in biased understanding of MLLMs' performance under VH due to limited diversity of such VH instances. In this work, we propose a tool called VHTest to generate a diverse set of VH instances. Specifically, VHTest finds some initial VH instances in existing image datasets (e.g., COCO), generates a text description for each VH mode, and uses a text-to-image generative model (e.g., DALL-E-3) to generate VH images based on the text descriptions. We collect a benchmark dataset with 1,200 VH instances in 8 VH modes using VHTest. We find that existing MLLMs such as GPT-4V, LLaVA-1.5, and MiniGPT-v2 hallucinate for a large fraction of the instances in our benchmark. Moreover, we find that fine-tuning an MLLM using our benchmark data
    
[^30]: 语言中间件：工具在复杂环境中对语言代理至关重要

    Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments

    [https://arxiv.org/abs/2402.14672](https://arxiv.org/abs/2402.14672)

    这项研究探索了在复杂环境中利用工具增强大型语言模型的潜力，设计了定制化工具来辅助语言代理在庞大环境中进行探索，并展示了在知识库和数据库等复杂环境中，借助工具增强语言代理的重要潜力。

    

    大型语言模型（LLMs）的应用已经远远超出了文本处理的范围，预示着一个新时代的到来，在这个时代，LLMs被设想为能够在复杂现实环境中运行的通用语言代理。这些环境通常非常广阔，使得LLM不可能在其短期记忆中处理它们。受最近关于通过工具扩展LLMs能力的研究启发，本文探讨了工具在增强LLMs处理这种复杂性方面的潜力。为此，我们设计了定制工具，以协助在这些庞大环境中进行主动探索。这些工具可以作为一个中间件层，使LLM免受环境复杂性的影响。在两个代表性的复杂环境--知识库（KBs）和数据库中，我们展示了在复杂环境中使用工具增强语言代理的重要潜力。

    arXiv:2402.14672v1 Announce Type: cross  Abstract: The applications of large language models (LLMs) have expanded well beyond the confines of text processing, signaling a new era where LLMs are envisioned as generalist language agents capable of operating within complex real-world environments. These environments are often highly expansive, making it impossible for the LLM to process them within its short-term memory. Motivated by recent research on extending the capabilities of LLMs with tools, this paper investigates the intriguing potential of tools to augment LLMs in handling such complexity. To this end, we design customized tools to aid in the proactive exploration within these massive environments. Such tools can serve as a middleware layer shielding the LLM from environmental complexity. In two representative complex environments -- knowledge bases (KBs) and databases -- we demonstrate the significant potential of augmenting language agents with tools in complex environments. N
    
[^31]: 大动作空间的贝叶斯离策略评估与学习

    Bayesian Off-Policy Evaluation and Learning for Large Action Spaces

    [https://arxiv.org/abs/2402.14664](https://arxiv.org/abs/2402.14664)

    该论文提出了一个统一的贝叶斯框架，通过结构化和信息丰富的先验捕捉动作之间的相关性，提出了一个适用于离策略评估和学习的通用贝叶斯方法sDM，并引入了能评估算法在多问题实例中平均表现的贝叶斯指标，分析了sDM在OPE和OPL中利用动作相关性的优势，并展示了其强大性能

    

    在交互式系统中，动作经常是相关的，这为大动作空间中更有效的离策略评估（OPE）和学习（OPL）提供了机会。我们引入了一个统一的贝叶斯框架，通过结构化和信息丰富的先验来捕捉这些相关性。在该框架中，我们提出了sDM，一个为OPE和OPL设计的通用贝叶斯方法，既有算法基础又有理论基础。值得注意的是，sDM利用动作相关性而不会影响计算效率。此外，受在线贝叶斯赌博机启发，我们引入了评估算法在多个问题实例中平均性能的贝叶斯指标，偏离传统的最坏情况评估。我们分析了sDM在OPE和OPL中的表现，凸显了利用动作相关性的好处。实证证据展示了sDM的强大性能。

    arXiv:2402.14664v1 Announce Type: cross  Abstract: In interactive systems, actions are often correlated, presenting an opportunity for more sample-efficient off-policy evaluation (OPE) and learning (OPL) in large action spaces. We introduce a unified Bayesian framework to capture these correlations through structured and informative priors. In this framework, we propose sDM, a generic Bayesian approach designed for OPE and OPL, grounded in both algorithmic and theoretical foundations. Notably, sDM leverages action correlations without compromising computational efficiency. Moreover, inspired by online Bayesian bandits, we introduce Bayesian metrics that assess the average performance of algorithms across multiple problem instances, deviating from the conventional worst-case assessments. We analyze sDM in OPE and OPL, highlighting the benefits of leveraging action correlations. Empirical evidence showcases the strong performance of sDM.
    
[^32]: ConceptMath：用于衡量大型语言模型数学推理能力的双语概念评测基准

    ConceptMath: A Bilingual Concept-wise Benchmark for Measuring Mathematical Reasoning of Large Language Models

    [https://arxiv.org/abs/2402.14660](https://arxiv.org/abs/2402.14660)

    介绍了ConceptMath，一种双语的细粒度基准测试，用于评估大型语言模型的概念性数学推理能力，并发现现有模型在不同数学概念上存在显著性能差异，甚至可能在最基本的概念上出现失败。

    

    本文介绍了ConceptMath，这是一个双语（英语和中文），细粒度的基准测试，用来评估大型语言模型（LLMs）的概念性数学推理能力。与评估一般数学推理的传统基准不同，ConceptMath将数学问题系统地组织在数学概念的层次结构下，从而可以以概念为单位准确性评估数学推理。基于我们的ConceptMath，我们评估了广泛范围的LLMs，并观察到现有的LLMs尽管在传统基准上取得了高平均准确性，但在不同数学概念上表现出显著的性能差异，甚至可能在最基本的概念上出现严重失败。此外，我们还介绍了一种有效的微调策略来增强现有LLMs的弱点。最后，我们希望ConceptMath能够指导开发者理解细致的数学推理能力。

    arXiv:2402.14660v1 Announce Type: cross  Abstract: This paper introduces ConceptMath, a bilingual (English and Chinese), fine-grained benchmark that evaluates concept-wise mathematical reasoning of Large Language Models (LLMs). Unlike traditional benchmarks that evaluate general mathematical reasoning with an average accuracy, ConceptMath systematically organizes math problems under a hierarchy of math concepts, so that mathematical reasoning can be evaluated at different granularity with concept-wise accuracies. Based on our ConcepthMath, we evaluate a broad range of LLMs, and we observe existing LLMs, though achieving high average accuracies on traditional benchmarks, exhibit significant performance variations across different math concepts and may even fail catastrophically on the most basic ones. Besides, we also introduce an efficient fine-tuning strategy to enhance the weaknesses of existing LLMs. Finally, we hope ConceptMath could guide the developers to understand the fine-grai
    
[^33]: OpenCodeInterpreter：集成代码生成、执行和细化

    OpenCodeInterpreter: Integrating Code Generation with Execution and Refinement

    [https://arxiv.org/abs/2402.14658](https://arxiv.org/abs/2402.14658)

    OpenCodeInterpreter是一种开源代码系统，集成了执行、人类反馈和动态代码细化的功能，并在关键基准测试中表现出色，甚至与GPT-4相媲美。

    

    大型语言模型的引入显著推动了代码生成的发展。然而，开源模型通常缺乏类似GPT-4 Code Interpreter这样的高级系统的执行能力和迭代细化能力。为了解决这一问题，我们介绍了OpenCodeInterpreter，这是一族旨在生成、执行和迭代细化代码的开源代码系统。通过Code-Feedback支持，该系统集成了执行和人类反馈，用于动态代码细化。我们对OpenCodeInterpreter在诸如HumanEval、MBPP以及它们来自EvalPlus的增强版本等关键基准上进行了全面评估，证实了其出色的性能。值得注意的是，OpenCodeInterpreter-33B在HumanEval和MBPP的平均值（以及其增强版本）上取得了83.2（76.4）的准确率，与GPT-4的84.2（76.2）紧密匹敌，并且通过合成hum

    arXiv:2402.14658v1 Announce Type: cross  Abstract: The introduction of large language models has significantly advanced code generation. However, open-source models often lack the execution capabilities and iterative refinement of advanced systems like the GPT-4 Code Interpreter. To address this, we introduce OpenCodeInterpreter, a family of open-source code systems designed for generating, executing, and iteratively refining code. Supported by Code-Feedback, a dataset featuring 68K multi-turn interactions, OpenCodeInterpreter integrates execution and human feedback for dynamic code refinement. Our comprehensive evaluation of OpenCodeInterpreter across key benchmarks such as HumanEval, MBPP, and their enhanced versions from EvalPlus reveals its exceptional performance. Notably, OpenCodeInterpreter-33B achieves an accuracy of 83.2 (76.4) on the average (and plus versions) of HumanEval and MBPP, closely rivaling GPT-4's 84.2 (76.2) and further elevates to 91.6 (84.6) with synthesized hum
    
[^34]: 在对抗训练中重新思考不变性正则化以改善鲁棒性-准确性权衡

    Rethinking Invariance Regularization in Adversarial Training to Improve Robustness-Accuracy Trade-off

    [https://arxiv.org/abs/2402.14648](https://arxiv.org/abs/2402.14648)

    重新审视了基于表示的不变性正则化方法，提出了Asymmetrically Representation-regularized Adversarial Training (AR-AT)来解决“梯度冲突”和混合分布问题，改善鲁棒性-准确性权衡。

    

    尽管对抗训练一直是抵抗对抗性样本（AEs）的最先进方法，但它们存在鲁棒性-准确性权衡问题。在这项研究中，我们重新审视基于表示的不变性正则化，学习具有辨别性却对抗性不变的表示，旨在缓解这种权衡。我们在经验上确定了妨碍不变性正则化的两个关键问题：（1）不变性损失和分类目标之间的“梯度冲突”，表明存在“崩溃解”，以及（2）由于干净和对抗性输入的分布发散而出现的混合分布问题。为了解决这些问题，我们提出了一种不对称表示正则化的对抗训练（AR-AT），该方法结合了一个停止梯度操作和一个预测器来避免“崩溃解”，灵感来自最近的非对比自监督学习。

    arXiv:2402.14648v1 Announce Type: cross  Abstract: Although adversarial training has been the state-of-the-art approach to defend against adversarial examples (AEs), they suffer from a robustness-accuracy trade-off. In this work, we revisit representation-based invariance regularization to learn discriminative yet adversarially invariant representations, aiming to mitigate this trade-off. We empirically identify two key issues hindering invariance regularization: (1) a "gradient conflict" between invariance loss and classification objectives, indicating the existence of "collapsing solutions," and (2) the mixture distribution problem arising from diverged distributions of clean and adversarial inputs. To address these issues, we propose Asymmetrically Representation-regularized Adversarial Training (AR-AT), which incorporates a stop-gradient operation and a pre-dictor in the invariance loss to avoid "collapsing solutions," inspired by a recent non-contrastive self-supervised learning a
    
[^35]: RoboScript: 跨越真实和仿真的自由形式操作任务的代码生成

    RoboScript: Code Generation for Free-Form Manipulation Tasks across Real and Simulation

    [https://arxiv.org/abs/2402.14623](https://arxiv.org/abs/2402.14623)

    RoboScript是一个旨在填补“理想到实际”差距的平台，提供可部署的机器人操作流水线，并为自然语言中的机器人操作任务提供代码生成基准。

    

    在具身人工智能领域，高级任务规划和代码生成在开放世界机器人操作中取得了快速进展。然而，先前的研究主要集中在大规模语言或多模态模型的常识推理和任务规划能力上，对于生成代码在实际机器人和其他自主机器人系统基本组件（包括机器人感知、运动规划和控制）上的部署性付出的努力相对较少。为了弥合这种“理想到实际”的差距，本文提出了RoboScript，一个平台，用于1）由代码生成驱动的可部署机器人操作流水线；和2）自由形式自然语言中机器人操作任务的代码生成基准。RoboScript平台通过强调与仿真和真实机器人的统一接口解决了这一差距，基于对机器人操作系统（ROS）的抽象实现。

    arXiv:2402.14623v1 Announce Type: cross  Abstract: Rapid progress in high-level task planning and code generation for open-world robot manipulation has been witnessed in Embodied AI. However, previous studies put much effort into general common sense reasoning and task planning capabilities of large-scale language or multi-modal models, relatively little effort on ensuring the deployability of generated code on real robots, and other fundamental components of autonomous robot systems including robot perception, motion planning, and control. To bridge this ``ideal-to-real'' gap, this paper presents \textbf{RobotScript}, a platform for 1) a deployable robot manipulation pipeline powered by code generation; and 2) a code generation benchmark for robot manipulation tasks in free-form natural language. The RobotScript platform addresses this gap by emphasizing the unified interface with both simulation and real robots, based on abstraction from the Robot Operating System (ROS), ensuring syn
    
[^36]: 从关键词到结构化摘要: 精简学术知识获取

    From Keywords to Structured Summaries: Streamlining Scholarly Knowledge Access

    [https://arxiv.org/abs/2402.14622](https://arxiv.org/abs/2402.14622)

    该论文突出了信息检索引擎在科学界的重要性，并提出了一种通过结构化记录和先进信息技术工具实现的解决方案，以革新研究人员访问和过滤文章的方式。

    

    这篇短文强调了信息检索引擎在科学界日益重要，指出传统基于关键词的搜索引擎由于出版物数量不断增加而效率低下。提出的解决方案涉及结构化记录，支持先进的信息技术工具，包括可视化仪表板，以彻底改变研究人员如何访问和过滤文章，取代传统的文本密集型方法。这一愿景通过一个以“传染病的繁殖数估计”研究主题为中心的概念验证得以体现，使用经过调整的大型语言模型(LLM)自动创建结构化记录以填充一个超越关键词的后端数据库。结果是一个下一代信息检索方法，可在https://orkg.org/usecases/r0-estimates 上访问。

    arXiv:2402.14622v1 Announce Type: cross  Abstract: This short paper highlights the growing importance of information retrieval (IR) engines in the scientific community, addressing the inefficiency of traditional keyword-based search engines due to the rising volume of publications. The proposed solution involves structured records, underpinning advanced information technology (IT) tools, including visualization dashboards, to revolutionize how researchers access and filter articles, replacing the traditional text-heavy approach. This vision is exemplified through a proof of concept centered on the ``reproductive number estimate of infectious diseases'' research theme, using a fine-tuned large language model (LLM) to automate the creation of structured records to populate a backend database that now goes beyond keywords. The result is a next-generation IR method accessible at https://orkg.org/usecases/r0-estimates.
    
[^37]: 联邦式复杂查询答案方法研究

    Federated Complex Qeury Answering

    [https://arxiv.org/abs/2402.14609](https://arxiv.org/abs/2402.14609)

    研究了在多源知识图谱上回答复杂查询的联邦式方法，解决了知识图谱中的隐私保护和答案检索的挑战

    

    知识图谱中的复杂逻辑查询答案是一个具有挑战性的任务，已经得到广泛研究。执行复杂逻辑推理的能力是必不可少的，并支持各种基于图推理的下游任务，比如搜索引擎。最近提出了一些方法，将知识图谱实体和逻辑查询表示为嵌入向量，并从知识图谱中找到逻辑查询的答案。然而，现有的方法主要集中在查询单个知识图谱上，并不能应用于多个图形。此外，直接共享带有敏感信息的知识图谱可能会带来隐私风险，使得共享和构建一个聚合知识图谱用于推理以检索查询答案是不切实际的。因此，目前仍然不清楚如何在多源知识图谱上回答查询。一个实体可能涉及到多个知识图谱，对多个知识图谱进行推理，并在多源知识图谱上回答复杂查询对于发现知识是重要的。

    arXiv:2402.14609v1 Announce Type: cross  Abstract: Complex logical query answering is a challenging task in knowledge graphs (KGs) that has been widely studied. The ability to perform complex logical reasoning is essential and supports various graph reasoning-based downstream tasks, such as search engines. Recent approaches are proposed to represent KG entities and logical queries into embedding vectors and find answers to logical queries from the KGs. However, existing proposed methods mainly focus on querying a single KG and cannot be applied to multiple graphs. In addition, directly sharing KGs with sensitive information may incur privacy risks, making it impractical to share and construct an aggregated KG for reasoning to retrieve query answers. Thus, it remains unknown how to answer queries on multi-source KGs. An entity can be involved in various knowledge graphs and reasoning on multiple KGs and answering complex queries on multi-source KGs is important in discovering knowledge 
    
[^38]: 将生成式人工智能引入教育中的自适应学习

    Bringing Generative AI to Adaptive Learning in Education

    [https://arxiv.org/abs/2402.14601](https://arxiv.org/abs/2402.14601)

    生成式人工智能技术与自适应学习概念的交叉研究将对教育中下一阶段学习格式的发展做出重要贡献。

    

    最近生成式人工智能技术的激增，如大型语言模型和扩散模型，推动了人工智能在科学、金融和教育等各个领域的应用发展。与此同时，自适应学习这一概念在教育领域引起了极大关注，并证明其在提高学生学习效率方面的有效性。在本立场论文中，我们旨在探讨将生成式人工智能与自适应学习概念结合起来的交叉研究。通过讨论这一领域的好处、挑战和潜力，我们认为这种结合将为教育中下一阶段学习形式的发展做出重要贡献。

    arXiv:2402.14601v1 Announce Type: cross  Abstract: The recent surge in generative AI technologies, such as large language models and diffusion models, have boosted the development of AI applications in various domains, including science, finance, and education. Concurrently, adaptive learning, a concept that has gained substantial interest in the educational sphere, has proven its efficacy in enhancing students' learning efficiency. In this position paper, we aim to shed light on the intersectional studies of these two methods, which combine generative AI with adaptive learning concepts. By presenting discussions about the benefits, challenges, and potentials in this field, we argue that this union will contribute significantly to the development of the next stage learning format in education.
    
[^39]: 基于扩散模型的汽油调配调度多目标优化

    Diffusion Model-Based Multiobjective Optimization for Gasoline Blending Scheduling

    [https://arxiv.org/abs/2402.14600](https://arxiv.org/abs/2402.14600)

    该论文介绍了一种基于扩散模型的汽油调配调度多目标优化方法，通过解决整数约束和生成可行调度，实现了同时达到多个优化目标并遵守约束条件。

    

    汽油混合调度利用资源分配和操作顺序满足炼油厂的生产要求。非线性、整数约束和大量决策变量的存在增加了这一问题的复杂性，使传统和进化算法面临挑战。本文介绍了一种新颖的基于扩散模型（称为DMO）的多目标优化方法，专门设计用于汽油混合调度。为了解决整数约束并生成可行调度，扩散模型在高斯噪声和可行域之间创建多个中间分布。通过迭代过程，解决方案从高斯噪声过渡到可行调度，同时使用梯度下降方法优化目标。DMO实现了同时目标优化和约束遵守。进行了比较测试以评估DMO的性能。

    arXiv:2402.14600v1 Announce Type: new  Abstract: Gasoline blending scheduling uses resource allocation and operation sequencing to meet a refinery's production requirements. The presence of nonlinearity, integer constraints, and a large number of decision variables adds complexity to this problem, posing challenges for traditional and evolutionary algorithms. This paper introduces a novel multiobjective optimization approach driven by a diffusion model (named DMO), which is designed specifically for gasoline blending scheduling. To address integer constraints and generate feasible schedules, the diffusion model creates multiple intermediate distributions between Gaussian noise and the feasible domain. Through iterative processes, the solutions transition from Gaussian noise to feasible schedules while optimizing the objectives using the gradient descent method. DMO achieves simultaneous objective optimization and constraint adherence. Comparative tests are conducted to evaluate DMO's p
    
[^40]: LLM在可持续智慧城市中的作用：应用、挑战和未来方向

    The Role of LLMs in Sustainable Smart Cities: Applications, Challenges, and Future Directions

    [https://arxiv.org/abs/2402.14596](https://arxiv.org/abs/2402.14596)

    本文探讨了LLM在优化智慧城市中的ICT流程方面的重要潜力和应用。

    

    智慧城市在提升城市生活水平的持续追求中发挥着关键作用，通过可持续且可扩展的创新高效管理资源，促进城市区域的快速扩展。随着人工智能（AI）、物联网（IoT）、大数据分析以及雾计算和边缘计算等新兴技术日益普及，智慧城市的应用面临着各种挑战，包括机密和敏感数据可能被未经授权披露的潜在风险。新兴技术的无缝整合对于维持其发展的动态步伐起着至关重要的作用。本文探讨了深度学习（DL）、联邦学习（FL）、物联网、区块链、自然语言处理（NLP）以及大型语言模型（LLMs）在优化智慧城市中的ICT流程方面的重要潜力和应用。

    arXiv:2402.14596v1 Announce Type: new  Abstract: Smart cities stand as pivotal components in the ongoing pursuit of elevating urban living standards, facilitating the rapid expansion of urban areas while efficiently managing resources through sustainable and scalable innovations. In this regard, as emerging technologies like Artificial Intelligence (AI), the Internet of Things (IoT), big data analytics, and fog and edge computing have become increasingly prevalent, smart city applications grapple with various challenges, including the potential for unauthorized disclosure of confidential and sensitive data. The seamless integration of emerging technologies has played a vital role in sustaining the dynamic pace of their development. This paper explores the substantial potential and applications of Deep Learning (DL), Federated Learning (FL), IoT, Blockchain, Natural Language Processing (NLP), and large language models (LLMs) in optimizing ICT processes within smart cities. We aim to spo
    
[^41]: 利用检索增强生成改进辅导实践评估

    Improving Assessment of Tutoring Practices using Retrieval-Augmented Generation

    [https://arxiv.org/abs/2402.14594](https://arxiv.org/abs/2402.14594)

    通过利用生成预训练变换器来自动评估辅导员使用社交情感辅导策略的能力，从而改进辅导实践评估。

    

    一对一辅导是提高学习效果的有效教学方法，然而其效力取决于辅导员的能力。新手数学辅导员通常优先考虑特定内容的指导，忽视社交情感学习等方面。社交情感学习促进了公平和包容性，并培养与学生的关系，这对于学生整体发展至关重要。准确有效地评估辅导员的能力可以推动定制的辅导员培训计划的发展。然而，在实时辅导中评估新手辅导员的能力仍然具有挑战性，因为通常需要专家参与。为解决这一挑战，本初步研究旨在利用生成预训练变换器（GPT），如GPT-3.5和GPT-4模型，自动评估辅导员使用社交情感辅导策略的能力。此外，本研究还报告了财务维度的内容。

    arXiv:2402.14594v1 Announce Type: cross  Abstract: One-on-one tutoring is an effective instructional method for enhancing learning, yet its efficacy hinges on tutor competencies. Novice math tutors often prioritize content-specific guidance, neglecting aspects such as social-emotional learning. Social-emotional learning promotes equity and inclusion and nurturing relationships with students, which is crucial for holistic student development. Assessing the competencies of tutors accurately and efficiently can drive the development of tailored tutor training programs. However, evaluating novice tutor ability during real-time tutoring remains challenging as it typically requires experts-in-the-loop. To address this challenge, this preliminary study aims to harness Generative Pre-trained Transformers (GPT), such as GPT-3.5 and GPT-4 models, to automatically assess tutors' ability of using social-emotional tutoring strategies. Moreover, this study also reports on the financial dimensions an
    
[^42]: 通过覆盖感知和强化学习增强高清地图更新服务

    Enhancement of High-definition Map Update Service Through Coverage-aware and Reinforcement Learning

    [https://arxiv.org/abs/2402.14582](https://arxiv.org/abs/2402.14582)

    本文提出了一种Q学习覆盖时间感知算法，以优化车载网络和HD地图更新的服务质量，以克服网络拥塞。

    

    高清（HD）地图系统将在提升自动驾驶到更高水平中发挥关键作用，得益于相比传统二维地图的显著改进。创建HD地图需要大量的路面和非路面数据。通常，这些原始数据集通过车载网络收集并上传到基于云的HD地图服务提供商。然而，由于动态拓扑，通过车载无线通道传输原始数据存在一定挑战。随着车辆数量的增加，对服务质量产生不利影响，成为协同驾驶中实时HD地图系统在自动驾驶车辆中的障碍。本文提出了一种Q学习覆盖时间感知算法，以优化车载网络和HD地图更新的服务质量，以克服网络拥塞。该算法在一个模拟环境中进行评估，模拟了

    arXiv:2402.14582v1 Announce Type: cross  Abstract: High-definition (HD) Map systems will play a pivotal role in advancing autonomous driving to a higher level, thanks to the significant improvement over traditional two-dimensional (2D) maps. Creating an HD Map requires a huge amount of on-road and off-road data. Typically, these raw datasets are collected and uploaded to cloud-based HD map service providers through vehicular networks. Nevertheless, there are challenges in transmitting the raw data over vehicular wireless channels due to the dynamic topology. As the number of vehicles increases, there is a detrimental impact on service quality, which acts as a barrier to a real-time HD Map system for collaborative driving in Autonomous Vehicles (AV). In this paper, to overcome network congestion, a Q-learning coverage-time-awareness algorithm is presented to optimize the quality of service for vehicular networks and HD map updates. The algorithm is evaluated in an environment that imita
    
[^43]: 精明：可信自动驾驶汽车架构

    Savvy: Trustworthy Autonomous Vehicles Architecture

    [https://arxiv.org/abs/2402.14580](https://arxiv.org/abs/2402.14580)

    提出了一种新的可信智能自动驾驶汽车架构Savvy，通过清晰分离控制平面和数据平面，实现了安全优先原则，使得在安全时间范围内尽可能优化决策。

    

    自动驾驶汽车（AV）越来越受关注，原因在于商业、安全和性能。虽然近年来AV架构取得了显著成功，依赖于AI模型的进步，但由于致命事故的增多，阻碍了全面推广AV。这需要重新审视构建安全关键AV架构的基本原则。然而，这个方向不应阻止利用人工智能的力量。因此，我们提出了Savvy，一个新的可信智能AV架构，实现了两者之间的最佳结合。Savvy在控制平面和数据平面之间进行清晰分离，以保证优先考虑安全性。前者通过设计时定义的规则来承担控制，以确保安全，同时启动后者以在安全时间界限内尽可能优化决策。通过引导的时间感知预测质量降级来实现这一目标。

    arXiv:2402.14580v1 Announce Type: new  Abstract: The increasing interest in Autonomous Vehicles (AV) is notable due to business, safety, and performance reasons. While there is salient success in recent AV architectures, hinging on the advancements in AI models, there is a growing number of fatal incidents that impedes full AVs from going mainstream. This calls for the need to revisit the fundamentals of building safety-critical AV architectures. However, this direction should not deter leveraging the power of AI. To this end, we propose Savvy, a new trustworthy intelligent AV architecture that achieves the best of both worlds. Savvy makes a clear separation between the control plane and the data plane to guarantee the safety-first principles. The former assume control to ensure safety using design-time defined rules, while launching the latter for optimizing decisions as much as possible within safety time-bounds. This is achieved through guided Time-aware predictive quality degradati
    
[^44]: 基于深度强化学习的社交感知导航的可变换高斯奖励函数

    Transformable Gaussian Reward Function for Socially-Aware Navigation with Deep Reinforcement Learning

    [https://arxiv.org/abs/2402.14569](https://arxiv.org/abs/2402.14569)

    引入了可变换高斯奖励函数(TGRF)来解决强化学习中社交感知导航奖励设计复杂、超参数冗余和不平衡的问题

    

    机器人导航已经从优先考虑避障转变为采用社交感知导航策略来适应人类存在。因此，在动态人类中心环境中的社交感知导航的认知在机器人领域中变得重要。虽然强化学习技术推动了社交感知导航的进步，但在拥挤环境中定义适当的奖励函数仍然是一个重大挑战。这些奖励在引导机器人行为时至关重要，由于其复杂性和无法自动设置的特性，需要精心设计。大量手工设计的奖励带来了超参数冗余、不平衡以及无法充分表示独特对象特征的问题。为了解决这些挑战，我们引入了可变换高斯奖励函数（TGRF）。

    arXiv:2402.14569v1 Announce Type: cross  Abstract: Robot navigation has transitioned from prioritizing obstacle avoidance to adopting socially aware navigation strategies that accommodate human presence. As a result, the recognition of socially aware navigation within dynamic human-centric environments has gained prominence in the field of robotics. Although reinforcement learning technique has fostered the advancement of socially aware navigation, defining appropriate reward functions, especially in congested environments, has posed a significant challenge. These rewards, crucial in guiding robot actions, demand intricate human-crafted design due to their complex nature and inability to be automatically set. The multitude of manually designed rewards poses issues with hyperparameter redundancy, imbalance, and inadequate representation of unique object characteristics. To address these challenges, we introduce a transformable gaussian reward function (TGRF). The TGRF significantly redu
    
[^45]: CLCE：一种优化学习融合的改进交叉熵和对比学习方法

    CLCE: An Approach to Refining Cross-Entropy and Contrastive Learning for Optimized Learning Fusion

    [https://arxiv.org/abs/2402.14551](https://arxiv.org/abs/2402.14551)

    CLCE方法结合了标签感知对比学习与交叉熵损失，通过协同利用难例挖掘提高了性能表现

    

    最先进的预训练图像模型主要采用两阶段方法：在大规模数据集上进行初始无监督预训练，然后使用交叉熵损失（CE）进行特定任务的微调。然而，已经证明CE可能会损害模型的泛化性和稳定性。为了解决这些问题，我们引入了一种名为CLCE的新方法，该方法将标签感知对比学习与CE相结合。我们的方法不仅保持了两种损失函数的优势，而且以协同方式利用难例挖掘来增强性能。

    arXiv:2402.14551v1 Announce Type: cross  Abstract: State-of-the-art pre-trained image models predominantly adopt a two-stage approach: initial unsupervised pre-training on large-scale datasets followed by task-specific fine-tuning using Cross-Entropy loss~(CE). However, it has been demonstrated that CE can compromise model generalization and stability. While recent works employing contrastive learning address some of these limitations by enhancing the quality of embeddings and producing better decision boundaries, they often overlook the importance of hard negative mining and rely on resource intensive and slow training using large sample batches. To counter these issues, we introduce a novel approach named CLCE, which integrates Label-Aware Contrastive Learning with CE. Our approach not only maintains the strengths of both loss functions but also leverages hard negative mining in a synergistic way to enhance performance. Experimental results demonstrate that CLCE significantly outperf
    
[^46]: OmniPred：语言模型作为通用回归器

    OmniPred: Language Models as Universal Regressors

    [https://arxiv.org/abs/2402.14547](https://arxiv.org/abs/2402.14547)

    本文提出了OmniPred框架，用于训练语言模型作为通用的端到端回归器，实验证明，在多个任务上训练时，语言模型能够显著优于传统回归模型。

    

    在实验设计的广阔领域中，回归一直是一个强大的工具，可以准确预测系统或模型在给定一组参数的情况下的结果指标，但传统上只限于适用于特定任务的方法。在本文中，我们提出了OmniPred，这是一个用于训练语言模型作为通用端到端回归器的框架，使用来自多样真实世界实验的$(x,y)$评估数据。通过使用源自Google Vizier的数据，这是世界上最大的黑盒优化数据库之一，我们的大量实验表明，仅通过数学参数和值的文本表示，语言模型能够进行非常精确的数值回归，如果有机会训练多个任务，则可以显著优于传统的回归模型。

    arXiv:2402.14547v1 Announce Type: cross  Abstract: Over the broad landscape of experimental design, regression has been a powerful tool to accurately predict the outcome metrics of a system or model given a set of parameters, but has been traditionally restricted to methods which are only applicable to a specific task. In this paper, we propose OmniPred, a framework for training language models as universal end-to-end regressors over $(x,y)$ evaluation data from diverse real world experiments. Using data sourced from Google Vizier, one of the largest blackbox optimization databases in the world, our extensive experiments demonstrate that through only textual representations of mathematical parameters and values, language models are capable of very precise numerical regression, and if given the opportunity to train over multiple tasks, can significantly outperform traditional regression models.
    
[^47]: ACE：具有因果感知熵正则化的离策略演员-评论家算法

    ACE : Off-Policy Actor-Critic with Causality-Aware Entropy Regularization

    [https://arxiv.org/abs/2402.14528](https://arxiv.org/abs/2402.14528)

    该论文提出了ACE算法，通过引入因果感知熵正则化，有效评估不同行为的重要性，并分析梯度休眠现象，引入休眠引导复位机制，在多个连续控制任务中取得显著性能优势。

    

    先前的无模型强化学习算法忽视了策略学习过程中不同原始行为的变化重要性。利用这一观点，我们探讨了不同动作维度和奖励之间的因果关系，以评估训练过程中各种原始行为的重要性。我们引入了一种因果感知熵项，有效地识别并优先处理具有高潜在影响的行动，以实现有效的探索。此外，为了防止对特定原始行为过度关注，我们分析了梯度休眠现象，并引入了一种休眠引导复位机制，进一步增强了我们的方法的功效。我们提出的算法ACE：具有因果感知熵正则化的离策演员-评论家，在跨7个领域的29个不同连续控制任务中，相较于无模型强化学习基线，表现出显著的性能优势。

    arXiv:2402.14528v1 Announce Type: cross  Abstract: The varying significance of distinct primitive behaviors during the policy learning process has been overlooked by prior model-free RL algorithms. Leveraging this insight, we explore the causal relationship between different action dimensions and rewards to evaluate the significance of various primitive behaviors during training. We introduce a causality-aware entropy term that effectively identifies and prioritizes actions with high potential impacts for efficient exploration. Furthermore, to prevent excessive focus on specific primitive behaviors, we analyze the gradient dormancy phenomenon and introduce a dormancy-guided reset mechanism to further enhance the efficacy of our method. Our proposed algorithm, ACE: Off-policy Actor-critic with Causality-aware Entropy regularization, demonstrates a substantial performance advantage across 29 diverse continuous control tasks spanning 7 domains compared to model-free RL baselines, which un
    
[^48]: 带聚类的语言模型训练平衡数据抽样

    Balanced Data Sampling for Language Model Training with Clustering

    [https://arxiv.org/abs/2402.14526](https://arxiv.org/abs/2402.14526)

    本文提出了一种名为ClusterClip Sampling的数据抽样方法，利用数据聚类平衡训练数据的文本分布，为更好的模型训练提供支持。

    

    数据在训练大型语言模型（LLM）中起着基础性作用。尽管人们已经关注数据集的收集和组成，但确定训练中的数据抽样策略仍然是一个悬而未决的问题。大多数LLM使用简单的随机抽样策略进行训练。然而，这种抽样策略忽视了训练数据分布的不均衡性，这可能是次优的。在本文中，我们提出了ClusterClip Sampling，以平衡训练数据的文本分布，以实现更好的模型训练。具体而言，ClusterClip Sampling利用数据聚类来反映训练集的数据分布，并根据聚类结果在训练过程中平衡常见样本和稀有样本。引入了重复裁剪操作来减轻由于来自某些聚类的样本导致的过拟合问题。大量实验证实了ClusterClip Sampling的有效性，它的表现优于

    arXiv:2402.14526v1 Announce Type: cross  Abstract: Data plays a fundamental role in the training of Large Language Models (LLMs). While attention has been paid to the collection and composition of datasets, determining the data sampling strategy in training remains an open question. Most LLMs are trained with a simple strategy, random sampling. However, this sampling strategy ignores the unbalanced nature of training data distribution, which can be sub-optimal. In this paper, we propose ClusterClip Sampling to balance the text distribution of training data for better model training. Specifically, ClusterClip Sampling utilizes data clustering to reflect the data distribution of the training set and balances the common samples and rare samples during training based on the cluster results. A repetition clip operation is introduced to mitigate the overfitting issue led by samples from certain clusters. Extensive experiments validate the effectiveness of ClusterClip Sampling, which outperfo
    
[^49]: 为实现视觉地点识别的预训练模型的无缝适应

    Towards Seamless Adaptation of Pre-trained Models for Visual Place Recognition

    [https://arxiv.org/abs/2402.14505](https://arxiv.org/abs/2402.14505)

    提出了一种新颖的方法，实现了预训练模型对视觉地点识别的无缝适应

    

    最近的研究表明，在大规模数据上用通用的视觉学习任务预训练的视觉模型可以为各种视觉感知问题提供有用的特征表示。然而，很少有尝试利用在视觉地点识别（VPR）中利用预训练的基础模型。由于模型预训练和VPR任务之间在训练目标和数据方面的固有差异，如何弥合差距并充分发挥预训练模型在VPR中的能力仍然是一个关键问题。为此，我们提出了一种新颖的方法，实现了预训练模型对VPR的无缝适应。具体而言，我们设计了一种混合适应方法，以实现全局和局部适应，从而获得既关注显著地标用于区分地点的全局和局部特征。

    arXiv:2402.14505v1 Announce Type: cross  Abstract: Recent studies show that vision models pre-trained in generic visual learning tasks with large-scale data can provide useful feature representations for a wide range of visual perception problems. However, few attempts have been made to exploit pre-trained foundation models in visual place recognition (VPR). Due to the inherent difference in training objectives and data between the tasks of model pre-training and VPR, how to bridge the gap and fully unleash the capability of pre-trained models for VPR is still a key issue to address. To this end, we propose a novel method to realize seamless adaptation of pre-trained models for VPR. Specifically, to obtain both global and local features that focus on salient landmarks for discriminating places, we design a hybrid adaptation method to achieve both global and local adaptation efficiently, in which only lightweight adapters are tuned without adjusting the pre-trained model. Besides, to gu
    
[^50]: 在复杂环境中的碰撞感知电缆抓取方法

    A Collision-Aware Cable Grasping Method in Cluttered Environment

    [https://arxiv.org/abs/2402.14498](https://arxiv.org/abs/2402.14498)

    提出了一种碰撞感知的电缆抓取方法，通过CG-CNN和数据集生成技术，在复杂环境中实现稳健电缆抓取，并取得了出色的成功率。

    

    我们介绍了一种专为在复杂环境中实现稳健电缆抓取而设计的碰撞感知卷积神经网络。利用物理仿真，我们生成一个大量数据集，模拟了电缆抓取的复杂性，考虑到电缆与机器人夹爪之间的潜在碰撞。我们使用近似凸分解技术来分析非凸电缆模型，根据模拟抓取尝试自动标记抓取质量。利用这个模拟数据集对CG-CNN进行了改进，并通过域随机化技术增强。随后，训练好的模型预测抓取质量，并将最佳抓取姿势指导给机器人控制器执行。我们评估了抓取效果在合成和真实世界设置下的表现。由于我们模型隐式的碰撞敏感性，我们取得了出色的成功率，对于已知电缆为92.3%，对于未知电缆为88.4%，超越了c。

    arXiv:2402.14498v1 Announce Type: cross  Abstract: We introduce a Cable Grasping-Convolutional Neural Network designed to facilitate robust cable grasping in cluttered environments. Utilizing physics simulations, we generate an extensive dataset that mimics the intricacies of cable grasping, factoring in potential collisions between cables and robotic grippers. We employ the Approximate Convex Decomposition technique to dissect the non-convex cable model, with grasp quality autonomously labeled based on simulated grasping attempts. The CG-CNN is refined using this simulated dataset and enhanced through domain randomization techniques. Subsequently, the trained model predicts grasp quality, guiding the optimal grasp pose to the robot controller for execution. Grasping efficacy is assessed across both synthetic and real-world settings. Given our model implicit collision sensitivity, we achieved commendable success rates of 92.3% for known cables and 88.4% for unknown cables, surpassing c
    
[^51]: INSTRAUG：用于多模指令微调的自动指令增强

    INSTRAUG: Automatic Instruction Augmentation for Multimodal Instruction Fine-tuning

    [https://arxiv.org/abs/2402.14492](https://arxiv.org/abs/2402.14492)

    INSTRAUG是一种自动指令增强方法，可以在多模任务中显著改善多模大型语言模型的对齐，相当于增加训练规模的好处。

    

    将大型语言模型（LLMs）在多任务指令跟随数据上进行微调已被证明是一种强大的学习范式，可以提高它们对新任务的零样本能力。最近关于高质量指令跟随数据生成和选择的工作需要大量人力，以为给定任务构思模型可理解的指令，并谨慎过滤LLM生成的数据。在这项工作中，我们引入了一种名为INSTRAUG的多模任务自动指令增强方法。它从一些基本和简单的元指令开始，但能将一个指令跟随数据集扩大30倍。在两个流行的多模指令跟随基准测试集MULTIINSTRUCT和InstructBLIP上的结果显示，INSTRAUG可以显著改善跨12个多模任务的多模大型语言模型（MLLMs）的对齐，甚至相当于增加训练规模的好处。

    arXiv:2402.14492v1 Announce Type: cross  Abstract: Fine-tuning large language models (LLMs) on multi-task instruction-following data has been proven to be a powerful learning paradigm for improving their zero-shot capabilities on new tasks. Recent works about high-quality instruction-following data generation and selection require amounts of human labor to conceive model-understandable instructions for the given tasks and carefully filter the LLM-generated data. In this work, we introduce an automatic instruction augmentation method named INSTRAUG in multimodal tasks. It starts from a handful of basic and straightforward meta instructions but can expand an instruction-following dataset by 30 times. Results on two popular multimodal instructionfollowing benchmarks MULTIINSTRUCT and InstructBLIP show that INSTRAUG can significantly improve the alignment of multimodal large language models (MLLMs) across 12 multimodal tasks, which is even equivalent to the benefits of scaling up training 
    
[^52]: 边界合同是否可学习并近似最优?

    Are Bounded Contracts Learnable and Approximately Optimal?

    [https://arxiv.org/abs/2402.14486](https://arxiv.org/abs/2402.14486)

    分析了在隐藏动作模型下的合同与委托-代理问题，提出了两个学习算法可以找到几乎最优的有界合同，对于一般情况的查询次数具有多项式上界，并且直接学习潜在的结果分布。

    

    本文考虑委托-代理问题的隐藏动作模型，其中委托方通过合同激励代理人按合同开展项目。我们研究了带有有界支付的合同是否可学习并近似最优。我们的主要结果是两种学习算法，可以在有界的查询次数内找到几乎最优的有界合同，基于文献中的两个标准假设：代理人的更昂贵的行动导致委托方的更好的结果分布，并且代理人的成本/努力具有递减回报。我们的多项式查询复杂度上界表明，标准假设足以实现对一般情况已知下界的指数改进。与现有的算法不同，后者依赖于对合同空间的离散化，我们的算法直接学习潜在的结果分布。

    arXiv:2402.14486v1 Announce Type: cross  Abstract: This paper considers the hidden-action model of the principal-agent problem, in which a principal incentivizes an agent to work on a project using a contract. We investigate whether contracts with bounded payments are learnable and approximately optimal. Our main results are two learning algorithms that can find a nearly optimal bounded contract using a polynomial number of queries, under two standard assumptions in the literature: a costlier action for the agent leads to a better outcome distribution for the principal, and the agent's cost/effort has diminishing returns. Our polynomial query complexity upper bound shows that standard assumptions are sufficient for achieving an exponential improvement upon the known lower bound for general instances. Unlike the existing algorithms, which relied on discretizing the contract space, our algorithms directly learn the underlying outcome distributions. As for the approximate optimality of bo
    
[^53]: 个性化行为感知Transformer用于多行为顺序推荐

    Personalized Behavior-Aware Transformer for Multi-Behavior Sequential Recommendation

    [https://arxiv.org/abs/2402.14473](https://arxiv.org/abs/2402.14473)

    个性化行为感知Transformer框架用于多行为顺序推荐，旨在更好地探索用户的潜在意图，并解决短序列下推荐性能降低的问题。

    

    Sequential Recommendation (SR)通过建模用户在物品之间转换的方式来捕捉用户的动态偏好。然而，仅利用单一类型的行为交互数据的SR模型在序列较短时性能会下降。为了解决这个问题，本文关注多行为顺序推荐(MBSR)，旨在利用时变异构行为依赖关系更好地探索用户在目标行为上的潜在意图。解决MBSR问题具有挑战性。一方面，由于个人特征，用户展现出多样化的多行为模式。另一方面，行为相关性和物品协作之间存在全面的相互影响，其强度深受时间因素影响。为了解决这些挑战，我们提出了一个针对MBSR问题的Personalized Behavior-Aware Transformer框架(PBAT)，该框架可以建模个性化模式

    arXiv:2402.14473v1 Announce Type: cross  Abstract: Sequential Recommendation (SR) captures users' dynamic preferences by modeling how users transit among items. However, SR models that utilize only single type of behavior interaction data encounter performance degradation when the sequences are short. To tackle this problem, we focus on Multi-Behavior Sequential Recommendation (MBSR) in this paper, which aims to leverage time-evolving heterogeneous behavioral dependencies for better exploring users' potential intents on the target behavior. Solving MBSR is challenging. On the one hand, users exhibit diverse multi-behavior patterns due to personal characteristics. On the other hand, there exists comprehensive co-influence between behavior correlations and item collaborations, the intensity of which is deeply affected by temporal factors. To tackle these challenges, we propose a Personalized Behavior-Aware Transformer framework (PBAT) for MBSR problem, which models personalized patterns 
    
[^54]: 重新构想预期自由能：四种公式以及一种统一观点

    Reframing the Expected Free Energy: Four Formulations and a Unification

    [https://arxiv.org/abs/2402.14460](https://arxiv.org/abs/2402.14460)

    主动推断理论基于预期自由能，本文尝试通过统一根预期自由能的定义来推导四种公式，研究了两种设置，并提出了限制代理对观察具有任意先验偏好的观点。

    

    arXiv:2402.14460v1 公告类型：新的 摘要：主动推断是感知、学习和决策的一种领先理论，可以应用于神经科学、机器人技术、心理学和机器学习。主动推断基于预期自由能，其主要由直觉可信度来证明，例如风险加不确定性、信息增益/实用价值的公式。本文旨在形式化从单一根预期自由能定义中推导这些公式的问题，即统一问题。然后，我们研究了两种设置，每种设置都有自己的根预期自由能定义。在第一个设置中，迄今为止并未提出预期自由能的理由，但可以从中恢复所有公式。然而，在这种设置中，代理无法对观察具有任意的先验偏好。实际上，只有一类有限的先验偏好与观察是兼容的。

    arXiv:2402.14460v1 Announce Type: new  Abstract: Active inference is a leading theory of perception, learning and decision making, which can be applied to neuroscience, robotics, psychology, and machine learning. Active inference is based on the expected free energy, which is mostly justified by the intuitive plausibility of its formulations, e.g., the risk plus ambiguity and information gain / pragmatic value formulations. This paper seek to formalize the problem of deriving these formulations from a single root expected free energy definition, i.e., the unification problem. Then, we study two settings, each one having its own root expected free energy definition. In the first setting, no justification for the expected free energy has been proposed to date, but all the formulations can be recovered from it. However, in this setting, the agent cannot have arbitrary prior preferences over observations. Indeed, only a limited class of prior preferences over observations is compatible wit
    
[^55]: NLAS-multi：一个多语言自动生成的自然语言论证架构语料库

    NLAS-multi: A Multilingual Corpus of Automatically Generated Natural Language Argumentation Schemes

    [https://arxiv.org/abs/2402.14458](https://arxiv.org/abs/2402.14458)

    该论文提出了一个多语言自动生成的自然语言论证架构语料库，包括自动生成自然语言论证的有效方法、最大的公开可用的语料库以及用于自动识别论证架构的基线和模型。

    

    在论证挖掘、论证生成和自然语言论证分析领域，一些主要限制涉及注释富有论证性数据的复杂性、这些语料库的有限规模，以及代表进行注释的不同语言和领域的约束。为了解决这些限制，本文提出以下贡献：(i) 在不同主题和语言中自动生成自然语言论证的有效方法论，(ii) 最大的公开可用的自然语言论证架构语料库，以及(iii) 用于自动识别论证架构的一组可靠基线和微调模型。

    arXiv:2402.14458v1 Announce Type: cross  Abstract: Some of the major limitations identified in the areas of argument mining, argument generation, and natural language argument analysis are related to the complexity of annotating argumentatively rich data, the limited size of these corpora, and the constraints that represent the different languages and domains in which these data is annotated. To address these limitations, in this paper we present the following contributions: (i) an effective methodology for the automatic generation of natural language arguments in different topics and languages, (ii) the largest publicly available corpus of natural language argumentation schemes, and (iii) a set of solid baselines and fine-tuned models for the automatic identification of argumentation schemes.
    
[^56]: 一种语言模型引导潜在空间的指南

    A Language Model's Guide Through Latent Space

    [https://arxiv.org/abs/2402.14433](https://arxiv.org/abs/2402.14433)

    本文将语言模型概念引导框架扩展到更丰富的概念集，探索当前检测和引导策略在适当性、幽默、创造力和质量等挑战性环境下的适用程度。

    

    概念引导已经成为一种廉价简单的方法，通过探究语言模型的隐藏表示中的概念向量，并在推断时使用它们来扰动激活，从而控制语言模型的行为。本文将前人工作的重点从真实性扩展到了更丰富的概念集，如恰当性、幽默、创造力和质量，探索当前检测和引导策略在这些具有挑战性的环境中的工作程度。为了方便评估，我们开发了一个考虑概念引导成功程度以及引导模型流畅性潜在退化的新度量。我们的广泛实验表明，尽管一些概念如真实性更容易通过当前技术进行引导，但像恰当性或幽默这样的新概念仍然难以引出，需要大量的

    arXiv:2402.14433v1 Announce Type: cross  Abstract: Concept guidance has emerged as a cheap and simple way to control the behavior of language models by probing their hidden representations for concept vectors and using them to perturb activations at inference time. While the focus of previous work has largely been on truthfulness, in this paper we extend this framework to a richer set of concepts such as appropriateness, humor, creativity and quality, and explore to what degree current detection and guidance strategies work in these challenging settings. To facilitate evaluation, we develop a novel metric for concept guidance that takes into account both the success of concept elicitation as well as the potential degradation in fluency of the guided model. Our extensive experiments reveal that while some concepts such as truthfulness more easily allow for guidance with current techniques, novel concepts such as appropriateness or humor either remain difficult to elicit, need extensive 
    
[^57]: KoCoSa: 韩文上下文感知讽刺检测数据集

    KoCoSa: Korean Context-aware Sarcasm Detection Dataset

    [https://arxiv.org/abs/2402.14428](https://arxiv.org/abs/2402.14428)

    该论文介绍了一个新的针对韩文对话讽刺检测任务的数据集KoCoSa，提出了一种高效的讽刺检测数据集生成流程，并提供了针对该任务的简单但有效的基线模型。

    

    讽刺是一种言语讽刺的方式，指的是有人说了和他们的本意相反的话，通常是为了嘲笑一个人、情况或想法。检测对话中的讽刺通常是困难的，因为检测讽刺应该反映上下文（即对话历史）。本文介绍了一个针对韩文对话讽刺检测任务的新数据集KoCoSa（韩文上下文感知讽刺检测数据集），包括12.8K个日常韩文对话以及该任务在最后一次回复上的标签。为了构建该数据集，我们提出了一种高效的讽刺检测数据集生成流程：1）使用大型语言模型从源对话中生成新的讽刺对话，2）自动和手动过滤异常和有毒对话，3）为讽刺检测任务进行人工注释。我们还提供了一个简单但有效的针对韩文讽刺检测任务的基线，该基线是在我们的数据集上训练的。

    arXiv:2402.14428v1 Announce Type: cross  Abstract: Sarcasm is a way of verbal irony where someone says the opposite of what they mean, often to ridicule a person, situation, or idea. It is often difficult to detect sarcasm in the dialogue since detecting sarcasm should reflect the context (i.e., dialogue history). In this paper, we introduce a new dataset for the Korean dialogue sarcasm detection task, KoCoSa (Korean Context-aware Sarcasm Detection Dataset), which consists of 12.8K daily Korean dialogues and the labels for this task on the last response. To build the dataset, we propose an efficient sarcasm detection dataset generation pipeline: 1) generating new sarcastic dialogues from source dialogues with large language models, 2) automatic and manual filtering of abnormal and toxic dialogues, and 3) human annotation for the sarcasm detection task. We also provide a simple but effective baseline for the Korean sarcasm detection task trained on our dataset. Experimental results on t
    
[^58]: 利用人工智能自动化心理学假设生成：大型语言模型结合因果图

    Automating Psychological Hypothesis Generation with AI: Large Language Models Meet Causal Graph

    [https://arxiv.org/abs/2402.14424](https://arxiv.org/abs/2402.14424)

    利用大型语言模型和因果图结合的方法，在心理学假设生成中取得了突破，结果显示这种联合方法在新颖性方面明显优于仅使用大型语言模型的假设。

    

    我们的研究利用因果知识图谱和大型语言模型（LLM）之间的协同作用，引入了一种突破性的计算方法来生成心理学假设。我们使用LLM分析了43,312篇心理学文章，提取了因果关系对，生成了一个专门针对心理学的因果图。应用链接预测算法，我们生成了130个关注“幸福”的潜在心理学假设，然后将其与博士学者构思的研究想法和仅由LLM产生的想法进行了比较。有趣的是，我们的LLM和因果图的联合方法在新颖性方面与专家水平的洞察力保持一致，明显优于仅LLM的假设（分别为t(59)=3.34，p=0.007和t(59)=4.32，p<0.001）。这种一致性进一步通过深度语义分析得到证实。我们的结果表明，将LLM与因果图等机器学习技术相结合，可以更好地生成心理学假设。

    arXiv:2402.14424v1 Announce Type: new  Abstract: Leveraging the synergy between causal knowledge graphs and a large language model (LLM), our study introduces a groundbreaking approach for computational hypothesis generation in psychology. We analyzed 43,312 psychology articles using a LLM to extract causal relation pairs. This analysis produced a specialized causal graph for psychology. Applying link prediction algorithms, we generated 130 potential psychological hypotheses focusing on `well-being', then compared them against research ideas conceived by doctoral scholars and those produced solely by the LLM. Interestingly, our combined approach of a LLM and causal graphs mirrored the expert-level insights in terms of novelty, clearly surpassing the LLM-only hypotheses (t(59) = 3.34, p=0.007 and t(59) = 4.32, p<0.001, respectively). This alignment was further corroborated using deep semantic analysis. Our results show that combining LLM with machine learning techniques such as causal k
    
[^59]: 视觉语言模型的不确定性感知评估

    Uncertainty-Aware Evaluation for Vision-Language Models

    [https://arxiv.org/abs/2402.14418](https://arxiv.org/abs/2402.14418)

    提出了一个新的基准来评估视觉语言模型，该基准将不确定性量化融入评估过程中，揭示了准确性最高的模型可能也具有最高不确定性的重要性。

    

    最近，像GPT-4、LLaVA和CogVLM这样的视觉语言模型因在几种视觉-语言任务中表现出色而变得越来越受欢迎。然而，当前的评估方法忽视了一个关键组成部分：不确定性，这对于全面评估VLMs非常重要。为了解决这一疏忽，我们提出了一个基准，将不确定性量化融入到评估VLMs中。我们的分析涵盖了20多个VLMs，重点关注多项选择视觉问答（VQA）任务。我们在评估各种视觉-语言能力的5个数据集上检验了模型。通过使用符合预测作为不确定性估计方法，我们证明了模型的不确定性与其准确性不一致。具体而言，我们表明准确性最高的模型可能也具有最高的不确定性，这证实了为VLMs测量其重要性。我们的实证发现还揭示了一种相关性，其

    arXiv:2402.14418v1 Announce Type: cross  Abstract: Vision-Language Models like GPT-4, LLaVA, and CogVLM have surged in popularity recently due to their impressive performance in several vision-language tasks. Current evaluation methods, however, overlook an essential component: uncertainty, which is crucial for a comprehensive assessment of VLMs. Addressing this oversight, we present a benchmark incorporating uncertainty quantification into evaluating VLMs.   Our analysis spans 20+ VLMs, focusing on the multiple-choice Visual Question Answering (VQA) task. We examine models on 5 datasets that evaluate various vision-language capabilities.   Using conformal prediction as an uncertainty estimation approach, we demonstrate that the models' uncertainty is not aligned with their accuracy. Specifically, we show that models with the highest accuracy may also have the highest uncertainty, which confirms the importance of measuring it for VLMs. Our empirical findings also reveal a correlation b
    
[^60]: 知识之间的拉锯战: 探索和解决检索增强语言模型中的知识冲突

    Tug-of-War Between Knowledge: Exploring and Resolving Knowledge Conflicts in Retrieval-Augmented Language Models

    [https://arxiv.org/abs/2402.14409](https://arxiv.org/abs/2402.14409)

    本文探讨了检索增强语言模型中的知识冲突，提出了评估框架，研究了RALMs对内部记忆和外部来源间的冲突，发现了它们会偏向错误的内部记忆。

    

    检索增强语言模型（RALMs）已经在通过从外部来源检索证据来优化和扩展其内部记忆方面表现出重要潜力。然而，RALMs在将内部记忆与外部来源整合时必然会遇到知识冲突。知识冲突会使RALMs陷入知识之间的拉锯战，限制其实际应用。本文着重于探索和解决RALMs中的知识冲突。首先，我们提出了一个评估框架，用于评估不同维度上的知识冲突。然后，我们从以下两个角度研究了RALMs的行为和偏好：（1）内部记忆与外部来源之间的冲突：我们发现，随着邓宁-克鲁格效应的增强，更强大的RALMs会持续偏爱其错误的内部记忆，即使提供了正确的证据。此外，RALMs还表现出一种可用性

    arXiv:2402.14409v1 Announce Type: cross  Abstract: Retrieval-augmented language models (RALMs) have demonstrated significant potential in refining and expanding their internal memory by retrieving evidence from external sources. However, RALMs will inevitably encounter knowledge conflicts when integrating their internal memory with external sources. Knowledge conflicts can ensnare RALMs in a tug-of-war between knowledge, limiting their practical applicability. In this paper, we focus on exploring and resolving knowledge conflicts in RALMs. First, we present an evaluation framework for assessing knowledge conflicts across various dimensions. Then, we investigate the behavior and preference of RALMs from the following two perspectives: (1) Conflicts between internal memory and external sources: We find that stronger RALMs emerge with the Dunning-Kruger effect, persistently favoring their faulty internal memory even when correct evidence is provided. Besides, RALMs exhibit an availability
    
[^61]: 在巨大语言模型中分析概念表达：借助反向词典探查

    On the Tip of the Tongue: Analyzing Conceptual Representation in Large Language Models with Reverse-Dictionary Probe

    [https://arxiv.org/abs/2402.14404](https://arxiv.org/abs/2402.14404)

    该论文通过重新利用反向词典任务的案例研究，探查了大型语言模型对概念推理的能力，发现模型在该任务中表现出高准确性，并且表示空间编码了有关对象类别和细粒度特征的信息，同时还发现该任务探查的概念推理能力能够预测模型在多个基准测试中的一般推理表现。

    

    探查和增强大型语言模型的推理能力仍然是一个关键的未解问题。在这里，我们重新利用反向词典任务作为一个案例研究，来探查LLMs对概念推理的能力。我们使用上下文学习来引导模型生成一个语言描述中暗示的对象概念的术语。模型在这个任务中稳健地实现了高准确性，并且它们的表示空间编码了关于对象类别和细粒度特征的信息。进一步的实验表明，通过反向词典任务探查的概念推理能力能够预测模型在多个基准测试中的一般推理表现，尽管模型在句法泛化行为上表现相似。探索性分析表明，通过提示LLMs使用描述$\Rightarrow$单词示例可能会诱导出超越任务构型表面差异的泛化，并促进模型对更广泛的共同性的研究

    arXiv:2402.14404v1 Announce Type: cross  Abstract: Probing and enhancing large language models' reasoning capacity remains a crucial open question. Here we re-purpose the reverse dictionary task as a case study to probe LLMs' capacity for conceptual inference. We use in-context learning to guide the models to generate the term for an object concept implied in a linguistic description. Models robustly achieve high accuracy in this task, and their representation space encodes information about object categories and fine-grained features. Further experiments suggest that the conceptual inference ability as probed by the reverse-dictionary task predicts model's general reasoning performance across multiple benchmarks, despite similar syntactic generalization behaviors across models. Explorative analyses suggest that prompting LLMs with description$\Rightarrow$word examples may induce generalization beyond surface-level differences in task construals and facilitate models on broader commons
    
[^62]: 确保及时性和准确性：一种新的滑动窗口数据流范式用于实时推荐

    Ensure Timeliness and Accuracy: A Novel Sliding Window Data Stream Paradigm for Live Streaming Recommendation

    [https://arxiv.org/abs/2402.14399](https://arxiv.org/abs/2402.14399)

    提出了一种名为Sliver的滑动窗口数据流设计范式，通过减小窗口大小和实现滑动窗口来解决实时推荐系统中标签的及时性和准确性问题

    

    Live streaming recommender system专为向用户推荐实时感兴趣的直播流而设计。由于直播内容动态变化，提高推荐系统的及时性是一个关键问题。本文提出了一种新的数据流设计范式，名为Sliver，通过减小窗口大小和相应实现滑动窗口来解决标签的及时性和准确性问题。

    arXiv:2402.14399v1 Announce Type: cross  Abstract: Live streaming recommender system is specifically designed to recommend real-time live streaming of interest to users. Due to the dynamic changes of live content, improving the timeliness of the live streaming recommender system is a critical problem. Intuitively, the timeliness of the data determines the upper bound of the timeliness that models can learn. However, none of the previous works addresses the timeliness problem of the live streaming recommender system from the perspective of data stream design. Employing the conventional fixed window data stream paradigm introduces a trade-off dilemma between labeling accuracy and timeliness. In this paper, we propose a new data stream design paradigm, dubbed Sliver, that addresses the timeliness and accuracy problem of labels by reducing the window size and implementing a sliding window correspondingly. Meanwhile, we propose a time-sensitive re-reco strategy reducing the latency between 
    
[^63]: 逐渐残余对齐：GAN反演和图像属性编辑的双流框架

    Gradual Residuals Alignment: A Dual-Stream Framework for GAN Inversion and Image Attribute Editing

    [https://arxiv.org/abs/2402.14398](https://arxiv.org/abs/2402.14398)

    本研究提出了逐步残余对齐的双流框架，通过多阶段粗到细的方式逐渐将细节注入到重构和编辑过程中，以提高细节保留和编辑性。

    

    GAN基础的图像属性编辑首先利用GAN反演将真实图像投影到GAN的潜在空间，然后操作相应的潜在代码。最近的反演方法主要利用额外的高比特特征来提高图像细节的保留，因为低比特代码无法忠实重构源图像，导致细节丢失。然而，在编辑过程中，现有工作未能准确补充丢失的细节，并且在编辑性上存在问题。主要原因是它们一次性注入所有丢失的细节，这在本质上导致细节的位置和数量过度拟合源图像，导致编辑后的图像中存在不一致的内容和伪影。该工作认为应该以多阶段粗到细的方式逐渐将细节注入到重构和编辑过程中，以获得更好的细节保留和高编辑性。

    arXiv:2402.14398v1 Announce Type: cross  Abstract: GAN-based image attribute editing firstly leverages GAN Inversion to project real images into the latent space of GAN and then manipulates corresponding latent codes. Recent inversion methods mainly utilize additional high-bit features to improve image details preservation, as low-bit codes cannot faithfully reconstruct source images, leading to the loss of details. However, during editing, existing works fail to accurately complement the lost details and suffer from poor editability. The main reason is they inject all the lost details indiscriminately at one time, which inherently induces the position and quantity of details to overfit source images, resulting in inconsistent content and artifacts in edited images. This work argues that details should be gradually injected into both the reconstruction and editing process in a multi-stage coarse-to-fine manner for better detail preservation and high editability. Therefore, a novel dual
    
[^64]: 可靠的分布式压缩机器学习模型训练

    Dependable Distributed Training of Compressed Machine Learning Models

    [https://arxiv.org/abs/2402.14346](https://arxiv.org/abs/2402.14346)

    提出了DepL框架，实现了可靠的学习编排，能够确保以最低训练成本达到目标学习质量。

    

    有关机器学习（ML）模型分布式训练的现有工作一直忽视了实现学习质量的分布，而是专注于其平均值。 这导致了所得ML模型的可靠性差，其性能可能比预期的要差得多。 我们通过提出DepL来填补这一空白，这是一个可靠的学习编排框架，能够就（i）用于学习的数据，（ii）要使用的模型及何时在它们之间切换，以及（iii）要利用的节点集群及其资源做出高质量高效的决策。 具体而言，我们考虑可能的可用模型为完整的DNN及其压缩版本。 与以前的研究不同，DepL保证以目标概率实现目标学习质量，同时保持训练成本最低。 我们证明DepL具有常数竞争比率和多项式复杂度。

    arXiv:2402.14346v1 Announce Type: cross  Abstract: The existing work on the distributed training of machine learning (ML) models has consistently overlooked the distribution of the achieved learning quality, focusing instead on its average value. This leads to a poor dependability}of the resulting ML models, whose performance may be much worse than expected. We fill this gap by proposing DepL, a framework for dependable learning orchestration, able to make high-quality, efficient decisions on (i) the data to leverage for learning, (ii) the models to use and when to switch among them, and (iii) the clusters of nodes, and the resources thereof, to exploit. For concreteness, we consider as possible available models a full DNN and its compressed versions. Unlike previous studies, DepL guarantees that a target learning quality is reached with a target probability, while keeping the training cost at a minimum. We prove that DepL has constant competitive ratio and polynomial complexity, and s
    
[^65]: 超快速：用于表格数据的即时分类

    HyperFast: Instant Classification for Tabular Data

    [https://arxiv.org/abs/2402.14335](https://arxiv.org/abs/2402.14335)

    HyperFast是一个针对表格数据的即时分类方法，通过在单次前向传递中生成特定任务的神经网络，避免了需进行模型训练的必要性，并在实验中展现出高度竞争力。

    

    训练深度学习模型和进行超参数调整可能需要大量计算资源和时间。与此同时，传统的梯度提升算法等机器学习方法仍然是大多数表格数据应用的首选，而神经网络方法要么需要进行大量的超参数调整，要么仅适用于在有限设置下的玩具数据集。本文介绍了HyperFast，一个为在单次前向传递中立即分类表格数据而设计的元训练的超网络。HyperFast生成一个针对未见数据集定制的特定任务神经网络，可直接用于分类推断，无需训练模型。我们使用OpenML和基因组数据进行了大量实验，将HyperFast与竞争性表格数据神经网络、传统ML方法、AutoML系统和提升机器进行了比较。HyperFast展现出极具竞争力的结果。

    arXiv:2402.14335v1 Announce Type: cross  Abstract: Training deep learning models and performing hyperparameter tuning can be computationally demanding and time-consuming. Meanwhile, traditional machine learning methods like gradient-boosting algorithms remain the preferred choice for most tabular data applications, while neural network alternatives require extensive hyperparameter tuning or work only in toy datasets under limited settings. In this paper, we introduce HyperFast, a meta-trained hypernetwork designed for instant classification of tabular data in a single forward pass. HyperFast generates a task-specific neural network tailored to an unseen dataset that can be directly used for classification inference, removing the need for training a model. We report extensive experiments with OpenML and genomic data, comparing HyperFast to competing tabular data neural networks, traditional ML methods, AutoML systems, and boosting machines. HyperFast shows highly competitive results, wh
    
[^66]: REPOFUSE：具有融合双重上下文的仓库级代码自动补全

    REPOFUSE: Repository-Level Code Completion with Fused Dual Context

    [https://arxiv.org/abs/2402.14323](https://arxiv.org/abs/2402.14323)

    RepoGenix独特融合类比上下文和理性上下文，并提出了截断排名生成（RTG）技术，以提高仓库级代码自动补全的准确性而不牺牲推理效率。

    

    语言模型在代码辅助方面取得的成功推动了提出仓库级代码自动补全作为提高预测准确性的手段，利用整个代码库的上下文。然而，这种增强的上下文可能会无意中增加推理延迟，潜在地损害开发者体验并妨碍工具的采用-这是我们称之为上下文-延迟困境的挑战。本文介绍了 RepoGenix，这是一个旨在提高仓库级代码自动补全而无需延迟折衷的开创性解决方案。RepoGenix 独特地融合了两种类型的上下文：根植于代码类比的类比上下文和包含深度语义关系的理性上下文。我们提出了一种新颖的截断排名生成（RTG）技术，有效地将这些上下文压缩为限制大小的提示。这使得 RepoGenix 能够在保持推理效率的同时提供精确的代码自动补全。

    arXiv:2402.14323v1 Announce Type: cross  Abstract: The success of language models in code assistance has spurred the proposal of repository-level code completion as a means to enhance prediction accuracy, utilizing the context from the entire codebase. However, this amplified context can inadvertently increase inference latency, potentially undermining the developer experience and deterring tool adoption-a challenge we termed the Context-Latency Conundrum. This paper introduces RepoGenix, a pioneering solution designed to enhance repository-level code completion without the latency trade-off. RepoGenix uniquely fuses two types of contexts: the analogy context, rooted in code analogies, and the rationale context, which encompasses in-depth semantic relationships. We propose a novel rank truncated generation (RTG) technique that efficiently condenses these contexts into prompts with restricted size. This enables RepoGenix to deliver precise code completions while maintaining inference ef
    
[^67]: Triad: 一个利用基于多角色LLM代理的框架来解决知识库问答问题

    Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering

    [https://arxiv.org/abs/2402.14320](https://arxiv.org/abs/2402.14320)

    Triad框架利用了基于多角色LLM代理来解决知识库问答问题，通过代理的不同角色分别处理KBQA子任务，合作完成KBQA任务，并在多个基准数据集上表现出色。

    

    最近基于LLM代理的进展在各种任务中展现出了令人期待的结果。然而，它们在回答知识库中问题的运用仍然鲜为人知。使用传统方法来实现KBQA系统具有挑战性，因为缺乏特定任务训练数据以及创建以任务为中心的模型结构的复杂性。在本文中，我们提出了Triad，一个利用具有三个角色的LLM代理的统一框架来进行KBQA任务。代理被分配三个角色来处理不同的KBQA子任务：作为掌握各种子任务的通才，作为选择候选者的决策者，以及作为回答带有知识的问题的顾问。我们的KBQA框架在四个阶段中执行，涉及代理的多重角色的协作。我们使用三个基准数据集评估了我们框架的性能，结果显示我们的框架胜过了

    arXiv:2402.14320v1 Announce Type: cross  Abstract: Recent progress with LLM-based agents has shown promising results across various tasks. However, their use in answering questions from knowledge bases remains largely unexplored. Implementing a KBQA system using traditional methods is challenging due to the shortage of task-specific training data and the complexity of creating task-focused model structures. In this paper, we present Triad, a unified framework that utilizes an LLM-based agent with three roles for KBQA tasks. The agent is assigned three roles to tackle different KBQA subtasks: agent as a generalist for mastering various subtasks, as a decision maker for the selection of candidates, and as an advisor for answering questions with knowledge. Our KBQA framework is executed in four phases, involving the collaboration of the agent's multiple roles. We evaluated the performance of our framework using three benchmark datasets, and the results show that our framework outperforms 
    
[^68]: 具有实体智能的视觉-语言导航：一项调查

    Vision-Language Navigation with Embodied Intelligence: A Survey

    [https://arxiv.org/abs/2402.14304](https://arxiv.org/abs/2402.14304)

    VLN作为实现实体智能的关键研究路径，致力于探索如何使用自然语言进行有效交流，实现准确导航，并融合了人工智能、自然语言处理、计算机视觉和机器人技术。

    

    作为人工智能领域的长期愿景，实体智能的核心目标是提高代理人和环境的感知、理解和交互能力。视觉-语言导航（VLN）作为实现实体智能的关键研究路径之一，致力于探索代理人如何使用自然语言有效地与人类交流，接收并理解指令，并最终依赖视觉信息实现准确导航。VLN融合了人工智能、自然语言处理、计算机视觉和机器人技术。尽管面临技术挑战，但具有应用潜力，例如人机交互。然而，由于从语言理解到行动执行的复杂过程，VLN面临将视觉信息与语言指令对齐、提高泛化能力等挑战。

    arXiv:2402.14304v1 Announce Type: cross  Abstract: As a long-term vision in the field of artificial intelligence, the core goal of embodied intelligence is to improve the perception, understanding, and interaction capabilities of agents and the environment. Vision-language navigation (VLN), as a critical research path to achieve embodied intelligence, focuses on exploring how agents use natural language to communicate effectively with humans, receive and understand instructions, and ultimately rely on visual information to achieve accurate navigation. VLN integrates artificial intelligence, natural language processing, computer vision, and robotics. This field faces technical challenges but shows potential for application such as human-computer interaction. However, due to the complex process involved from language understanding to action execution, VLN faces the problem of aligning visual information and language instructions, improving generalization ability, and many other challenge
    
[^69]: 我们选择去太空：微重力下的人类与多机器人协作的驱动代理

    We Choose to Go to Space: Agent-driven Human and Multi-Robot Collaboration in Microgravity

    [https://arxiv.org/abs/2402.14299](https://arxiv.org/abs/2402.14299)

    提出了SpaceAgents-1系统，该系统使用分层异构多代理协作架构，在微重力环境下学习人类与多机器人协作策略。

    

    我们提出SpaceAgents-1，这是一个在微重力条件下学习人类与多机器人协作（HMRC）策略的系统。未来的太空探索需要人类与机器人共同工作。然而，在地面实验室中获得熟练的机器人技能和在微重力条件下的熟练协作面临着重大挑战。为了解决这个问题，我们开发了一个微重力模拟环境，并展示了三种典型的舱内机器人配置。我们提出了一个分层异构多代理协作架构：在基础模型的指导下，一个决策制定代理作为人机协作的任务规划者，而各个技能专家代理管理机器人的实体控制。这种机制使SpaceAgents-1系统能够执行一系列复杂的长期视野HMRC任务。

    arXiv:2402.14299v1 Announce Type: cross  Abstract: We present SpaceAgents-1, a system for learning human and multi-robot collaboration (HMRC) strategies under microgravity conditions. Future space exploration requires humans to work together with robots. However, acquiring proficient robot skills and adept collaboration under microgravity conditions poses significant challenges within ground laboratories. To address this issue, we develop a microgravity simulation environment and present three typical configurations of intra-cabin robots. We propose a hierarchical heterogeneous multi-agent collaboration architecture: guided by foundation models, a Decision-Making Agent serves as a task planner for human-robot collaboration, while individual Skill-Expert Agents manage the embodied control of robots. This mechanism empowers the SpaceAgents-1 system to execute a range of intricate long-horizon HMRC tasks.
    
[^70]: 使用音素表示减缓语言差异，实现稳健的多语言理解

    Mitigating the Linguistic Gap with Phonemic Representations for Robust Multilingual Language Understanding

    [https://arxiv.org/abs/2402.14279](https://arxiv.org/abs/2402.14279)

    通过使用音素表示，本文提出了一种新颖的解决方案来减缓高资源语言和低资源语言之间的性能差距，并通过实证研究和理论分析证明了其有效性。

    

    为了改善多语言理解，通常需要在训练阶段使用多种语言，依赖复杂的训练技术，并且在高资源语言和低资源语言之间存在显著的性能差距。我们假设语言之间的性能差距受到这些语言之间的语言差异的影响，并通过使用音素表示（具体来说，将音素作为输入标记输入到语言模型中，而不是子词）提供了一种新颖的解决方案，以实现稳健的多语言建模。我们通过三个跨语言任务的定量证据展示了音素表示的有效性，这进一步得到了对跨语言性能差距的理论分析的证明。

    arXiv:2402.14279v1 Announce Type: cross  Abstract: Approaches to improving multilingual language understanding often require multiple languages during the training phase, rely on complicated training techniques, and -- importantly -- struggle with significant performance gaps between high-resource and low-resource languages. We hypothesize that the performance gaps between languages are affected by linguistic gaps between those languages and provide a novel solution for robust multilingual language modeling by employing phonemic representations (specifically, using phonemes as input tokens to LMs rather than subwords). We present quantitative evidence from three cross-lingual tasks that demonstrate the effectiveness of phonemic representation, which is further justified by a theoretical analysis of the cross-lingual performance gap.
    
[^71]: GATE X-E：弱性别语言的性别公平翻译挑战集

    GATE X-E : A Challenge Set for Gender-Fair Translations from Weakly-Gendered Languages

    [https://arxiv.org/abs/2402.14277](https://arxiv.org/abs/2402.14277)

    引入了GATE X-E挑战集，包含了从土耳其语、匈牙利语、芬兰语和波斯语翻译成英语的人类翻译，旨在评估弱性别语言到英语的翻译中的性别偏见并提出缓解策略。

    

    arXiv:2402.14277v1 公告类型：跨领域 摘要：神经机器翻译（NMT）在质量和采用上持续改善，但性别偏见的无意延续仍然是一个重要关注点。尽管有大量关于从弱性别语言翻译成英语的性别偏见的研究，但目前还没有用于评估这一现象或评估缓解策略的基准。为了弥补这一空白，我们引入了GATE X-E，这是GATE（Rarrick等人，2023）语料库的扩展，由人类翻译组成，从土耳其语、匈牙利语、芬兰语和波斯语翻译成英语。每种翻译都附有女性、男性和中性变体。该数据集每种语言对之间包含1250到1850个实例，包含具有各种句子长度和领域的自然句子，挑战着翻译重写者在各种语言现象上。此外，我们还提出了一个使用GPT构建的翻译性别重写解决方案。

    arXiv:2402.14277v1 Announce Type: cross  Abstract: Neural Machine Translation (NMT) continues to improve in quality and adoption, yet the inadvertent perpetuation of gender bias remains a significant concern. Despite numerous studies on gender bias in translations into English from weakly gendered-languages, there are no benchmarks for evaluating this phenomenon or for assessing mitigation strategies. To address this gap, we introduce GATE X-E, an extension to the GATE (Rarrick et al., 2023) corpus, that consists of human translations from Turkish, Hungarian, Finnish, and Persian into English. Each translation is accompanied by feminine, masculine, and neutral variants. The dataset, which contains between 1250 and 1850 instances for each of the four language pairs, features natural sentences with a wide range of sentence lengths and domains, challenging translation rewriters on various linguistic phenomena. Additionally, we present a translation gender rewriting solution built with GPT
    
[^72]: 大型语言模型能够检测科学新闻报道中的错误信息吗？

    Can Large Language Models Detect Misinformation in Scientific News Reporting?

    [https://arxiv.org/abs/2402.14268](https://arxiv.org/abs/2402.14268)

    大型语言模型探测科学报道中的错误信息的可行性，绕过生成明确标记索赔的步骤，处理现实场景中可能不存在明确标记索赔的挑战。

    

    科学事实经常被在流行媒体中操纵，意图影响公众舆论和行动，正如在COVID-19大流行期间所证实的那样。在科学领域中自动检测错误信息具有挑战性，因为这两种媒体类型的写作风格有着明显不同，并且仍处于萌芽阶段。本文的核心研究问题是是否可以利用大型语言模型(LLMs)来检测科学报道中的错误信息。

    arXiv:2402.14268v1 Announce Type: cross  Abstract: Scientific facts are often spun in the popular press with the intent to influence public opinion and action, as was evidenced during the COVID-19 pandemic. Automatic detection of misinformation in the scientific domain is challenging because of the distinct styles of writing in these two media types and is still in its nascence. Most research on the validity of scientific reporting treats this problem as a claim verification challenge. In doing so, significant expert human effort is required to generate appropriate claims. Our solution bypasses this step and addresses a more real-world scenario where such explicit, labeled claims may not be available. The central research question of this paper is whether it is possible to use large language models (LLMs) to detect misinformation in scientific reporting. To this end, we first present a new labeled dataset SciNews, containing 2.4k scientific news stories drawn from trusted and untrustwo
    
[^73]: Copilot评估工具：评估LLM引导的软件编程

    Copilot Evaluation Harness: Evaluating LLM-Guided Software Programming

    [https://arxiv.org/abs/2402.14261](https://arxiv.org/abs/2402.14261)

    本文介绍了Copilot评估工具，用于评估LLM引导的IDE交互，在各种编程场景和语言中提供更为稳健和信息密集的评估。

    

    将大型语言模型（LLMs）整合到开发环境（IDEs）已成为现代软件开发的焦点。LLMs，如OpenAI GPT-3.5/4和Code Llama，能够作为智能的、基于聊天的编程助手，显著提高开发人员的生产力。然而，直接使用LLMs可能并不适用于任何场景。相反，每个系统都需要对LLMs进行调整以适应其启发式集，以确保获得最佳性能。本文引入了Copilot评估工具：一套用于评估LLM引导的IDE交互的数据和工具，涵盖各种编程场景和语言。我们提出的度量标准比先前的最先进的评估系统更为稳健和信息密集。我们为涵盖广泛的开发人员任务范围的情景设计并计算了静态和基于执行的成功度量标准。

    arXiv:2402.14261v1 Announce Type: cross  Abstract: The integration of Large Language Models (LLMs) into Development Environments (IDEs) has become a focal point in modern software development. LLMs such as OpenAI GPT-3.5/4 and Code Llama offer the potential to significantly augment developer productivity by serving as intelligent, chat-driven programming assistants. However, utilizing LLMs out of the box is unlikely to be optimal for any given scenario. Rather, each system requires the LLM to be honed to its set of heuristics to ensure the best performance. In this paper, we introduce the Copilot evaluation harness: a set of data and tools for evaluating LLM-guided IDE interactions, covering various programming scenarios and languages. We propose our metrics as a more robust and information-dense evaluation than previous state of the art evaluation systems. We design and compute both static and execution based success metrics for scenarios encompassing a wide range of developer tasks, 
    
[^74]: 单词序列熵：走向自由形式医学问答应用及其不确定性估计

    Word-Sequence Entropy: Towards Uncertainty Estimation in Free-Form Medical Question Answering Applications and Beyond

    [https://arxiv.org/abs/2402.14259](https://arxiv.org/abs/2402.14259)

    本论文提出了一种新方法单词序列熵（WSE），用于在自由形式医学问答任务中量化答案的不确定性，相比其他基线方法表现更优秀。

    

    不确定性估计在确保安全关键的人工智能系统与人类互动的可靠性中发挥关键作用，尤其在医疗领域尤为重要。然而，在自由形式的医学问答任务中，尚未建立一种通用方法来量化答案的不确定性，其中无关的词汇和语序含有有限的语义信息可能是不确定性的主要来源，这是由于生成不平等的存在。本文提出了单词序列熵（WSE），该方法根据语义相关性在单词和序列级别上校准不确定性比例，在不确定性量化时更加强调关键词和更相关的序列。我们在5个自由形式医学问答数据集上，利用7种“现成的”大语言模型（LLMs）将WSE与6种基线方法进行比较，并展示了WSE在性能上的优越性。

    arXiv:2402.14259v1 Announce Type: cross  Abstract: Uncertainty estimation plays a pivotal role in ensuring the reliability of safety-critical human-AI interaction systems, particularly in the medical domain. However, a general method for quantifying the uncertainty of free-form answers has yet to be established in open-ended medical question-answering (QA) tasks, where irrelevant words and sequences with limited semantic information can be the primary source of uncertainty due to the presence of generative inequality. In this paper, we propose the Word-Sequence Entropy (WSE), which calibrates the uncertainty proportion at both the word and sequence levels according to the semantic relevance, with greater emphasis placed on keywords and more relevant sequences when performing uncertainty quantification. We compare WSE with 6 baseline methods on 5 free-form medical QA datasets, utilizing 7 "off-the-shelf" large language models (LLMs), and show that WSE exhibits superior performance on ac
    
[^75]: 利用多模态大语言模型的人工智能反馈增强机器人操作

    Enhancing Robotic Manipulation with AI Feedback from Multimodal Large Language Models

    [https://arxiv.org/abs/2402.14245](https://arxiv.org/abs/2402.14245)

    利用多模态大语言模型为机器人操作提供自动偏好反馈，提升决策效果

    

    最近，人们开始关注利用大型语言模型（LLMs）来增强决策过程。然而，将由LLMs生成的自然语言文本指令与执行所需的向量化操作对齐，常常需要特定于任务的细节，这是一个重要挑战。为了避免对这种特定于任务的细微之处的需求，受到基于偏好的策略学习方法的启发，我们研究利用多模态LLMs提供自动偏好反馈，仅从图像输入中引导决策。在这项研究中，我们训练了一个名为CriticGPT的多模态LLM，能够理解机器人操作任务中的轨迹视频，作为一个评论员提供分析和偏好反馈。随后，我们从奖励建模的角度验证了CriticGPT生成的偏好标签的有效性。对一种

    arXiv:2402.14245v1 Announce Type: cross  Abstract: Recently, there has been considerable attention towards leveraging large language models (LLMs) to enhance decision-making processes. However, aligning the natural language text instructions generated by LLMs with the vectorized operations required for execution presents a significant challenge, often necessitating task-specific details. To circumvent the need for such task-specific granularity, inspired by preference-based policy learning approaches, we investigate the utilization of multimodal LLMs to provide automated preference feedback solely from image inputs to guide decision-making. In this study, we train a multimodal LLM, termed CriticGPT, capable of understanding trajectory videos in robot manipulation tasks, serving as a critic to offer analysis and preference feedback. Subsequently, we validate the effectiveness of preference labels generated by CriticGPT from a reward modeling perspective. Experimental evaluation of the a
    
[^76]: MENTOR：在层次化强化学习中引导人类反馈和动态距离约束

    MENTOR: Guiding Hierarchical Reinforcement Learning with Human Feedback and Dynamic Distance Constraint

    [https://arxiv.org/abs/2402.14244](https://arxiv.org/abs/2402.14244)

    使用人类反馈和动态距离约束对层次化强化学习进行引导，解决了找到适当子目标的问题，并设计了双策略以稳定训练。

    

    层次化强化学习（HRL）为智能体的复杂任务提供了一种有前途的解决方案，其中使用了将任务分解为子目标并依次完成的层次框架。然而，当前的方法难以找到适当的子目标来确保稳定的学习过程。为了解决这个问题，我们提出了一个通用的层次强化学习框架，将人类反馈和动态距离约束整合到其中（MENTOR）。MENTOR充当“导师”，将人类反馈纳入高层策略学习中，以找到更好的子目标。至于低层策略，MENTOR设计了一个双策略以分别进行探索-开发解耦，以稳定训练。此外，尽管人类可以简单地将任务拆分成...

    arXiv:2402.14244v1 Announce Type: new  Abstract: Hierarchical reinforcement learning (HRL) provides a promising solution for complex tasks with sparse rewards of intelligent agents, which uses a hierarchical framework that divides tasks into subgoals and completes them sequentially. However, current methods struggle to find suitable subgoals for ensuring a stable learning process. Without additional guidance, it is impractical to rely solely on exploration or heuristics methods to determine subgoals in a large goal space. To address the issue, We propose a general hierarchical reinforcement learning framework incorporating human feedback and dynamic distance constraints (MENTOR). MENTOR acts as a "mentor", incorporating human feedback into high-level policy learning, to find better subgoals. As for low-level policy, MENTOR designs a dual policy for exploration-exploitation decoupling respectively to stabilize the training. Furthermore, although humans can simply break down tasks into s
    
[^77]: 一种自监督压力图人体关键点检测方法：跨数据集优化泛化和计算效率

    A Self-supervised Pressure Map human keypoint Detection Approch: Optimizing Generalization and Computational Efficiency Across Datasets

    [https://arxiv.org/abs/2402.14241](https://arxiv.org/abs/2402.14241)

    提出了一种自监督压力图关键点检测方法，采用Encoder-Fuser-Decoder（EFD）模型和分类到回归权重转移（CRWT）方法，在不需要手动标注的情况下提高了人体关键点的泛化能力和计算效率。

    

    在RGB图像无法满足需求的环境中，压力图成为一种备选方案，吸引了学术界的注意。本研究介绍了一种新颖的自监督压力图关键点检测（SPMKD）方法，解决了目前针对压力图中人体关键点提取的专门设计的空白。我们的贡献核心是编码器-融合器-解码器（EFD）模型，这是一个强大的框架，集成了精确人体关键点检测的轻量级编码器、用于高效梯度传播的融合器，以及将人体关键点转换为重构压力图的解码器。该结构通过分类到回归权重转移（CRWT）方法进一步增强，通过初始分类任务训练对精确度进行微调。这一创新不仅提高了人体关键点的泛化能力，而且展示了显着的效率和泛化能力，得到了证明。

    arXiv:2402.14241v1 Announce Type: cross  Abstract: In environments where RGB images are inadequate, pressure maps is a viable alternative, garnering scholarly attention. This study introduces a novel self-supervised pressure map keypoint detection (SPMKD) method, addressing the current gap in specialized designs for human keypoint extraction from pressure maps. Central to our contribution is the Encoder-Fuser-Decoder (EFD) model, which is a robust framework that integrates a lightweight encoder for precise human keypoint detection, a fuser for efficient gradient propagation, and a decoder that transforms human keypoints into reconstructed pressure maps. This structure is further enhanced by the Classification-to-Regression Weight Transfer (CRWT) method, which fine-tunes accuracy through initial classification task training. This innovation not only enhances human keypoint generalization without manual annotations but also showcases remarkable efficiency and generalization, evidenced by
    
[^78]: 分布式滤波电路的自动设计与优化通过强化学习

    Automated Design and Optimization of Distributed Filtering Circuits via Reinforcement Learning

    [https://arxiv.org/abs/2402.14236](https://arxiv.org/abs/2402.14236)

    提出一种通过强化学习算法实现的自动化设计方法，显著提高了分布式滤波电路设计的效率和质量。

    

    设计分布式滤波电路(DFC)复杂且耗时，电路性能严重依赖电子工程师的专业知识和经验。然而，手动设计方法效率低下。本研究提出一种新的端到端自动化方法，利用强化学习算法来改进DFC的设计。所提出的方法消除了对工程师设计经验的依赖，显著降低了与电路设计相关的主观性和约束。实验结果表明，在与传统的工程师驱动方法进行比较时，所提出的方法在设计效率和质量上都有明显改善。特别是，在设计复杂或快速发展的DFC时，所提出的方法表现出卓越的性能。

    arXiv:2402.14236v1 Announce Type: cross  Abstract: Designing distributed filtering circuits (DFCs) is complex and time-consuming, with the circuit performance relying heavily on the expertise and experience of electronics engineers. However, manual design methods tend to have exceedingly low-efficiency. This study proposes a novel end-to-end automated method for fabricating circuits to improve the design of DFCs. The proposed method harnesses reinforcement learning (RL) algorithms, eliminating the dependence on the design experience of engineers. Thus, it significantly reduces the subjectivity and constraints associated with circuit design. The experimental findings demonstrate clear improvements in both design efficiency and quality when comparing the proposed method with traditional engineer-driven methods. In particular, the proposed method achieves superior performance when designing complex or rapidly evolving DFCs. Furthermore, compared to existing circuit automation design techn
    
[^79]: MerRec：用于消费者对消费者推荐系统的大规模多功能Mercari数据集

    MerRec: A Large-scale Multipurpose Mercari Dataset for Consumer-to-Consumer Recommendation Systems

    [https://arxiv.org/abs/2402.14230](https://arxiv.org/abs/2402.14230)

    提出了MerRec，这是首个专门针对C2C推荐而提出的大规模数据集，填补了C2C推荐数据集中物品属性、用户多样性和规模等方面的缺失。

    

    在不断发展的电子商务领域中，推荐系统至关重要地塑造了用户体验和参与度。消费者对消费者（C2C）推荐系统的崛起，以其灵活性和为客户供应商提供易于访问的特点，标志着一个重要趋势。然而，学术关注主要集中在商家对消费者（B2C）模型上，留下了一个空白，即缺乏物品属性、用户多样性和规模的C2C推荐数据集。C2C推荐系统的复杂性进一步突出了用户扮演卖家和买家两种角色的双重性质，引入了一系列不那么统一和多样化的输入。为解决这一问题，我们引入了MerRec，这是第一个专门用于C2C推荐的大规模数据集，源自Mercari电子商务平台，覆盖了2023年6个月内数百万用户和产品。MerRec不仅包括标准特征，如user_id、item_id和session_id

    arXiv:2402.14230v1 Announce Type: cross  Abstract: In the evolving e-commerce field, recommendation systems crucially shape user experience and engagement. The rise of Consumer-to-Consumer (C2C) recommendation systems, noted for their flexibility and ease of access for customer vendors, marks a significant trend. However, the academic focus remains largely on Business-to-Consumer (B2C) models, leaving a gap filled by the limited C2C recommendation datasets that lack in item attributes, user diversity, and scale. The intricacy of C2C recommendation systems is further accentuated by the dual roles users assume as both sellers and buyers, introducing a spectrum of less uniform and varied inputs. Addressing this, we introduce MerRec, the first large-scale dataset specifically for C2C recommendations, sourced from the Mercari e-commerce platform, covering millions of users and products over 6 months in 2023. MerRec not only includes standard features such as user_id, item_id, and session_id
    
[^80]: COPR:通过最优策略正则化实现持续人类偏好学习

    COPR: Continual Human Preference Learning via Optimal Policy Regularization

    [https://arxiv.org/abs/2402.14228](https://arxiv.org/abs/2402.14228)

    提出了Continual Optimal Policy Regularization (COPR) 方法，通过借鉴最优策略理论，利用采样分布作为示范和正则化约束，以动态地对当前策略进行正则化，从而使强化学习从人类反馈中学习在持续学习情境下更加稳健

    

    arXiv:2402.14228v1 公告类型:跨界 摘要: 利用强化学习从人类反馈中学习（RLHF）通常用于改善大型语言模型（LLMs）与人类偏好的对齐。鉴于人类偏好的不断变化，持续对齐相对于传统静态对齐变得更加重要和实际。然而，使RLHF与持续学习（CL）兼容由于其复杂过程而具有挑战性。同时，直接学习新的人类偏好可能导致历史偏好的灾难性遗忘（CF），导致无助或有害的结果。为了克服这些挑战，我们提出了Continual Optimal Policy Regularization (COPR) 方法，该方法借鉴了最优策略理论。COPR利用采样分布作为示范和正则化约束用于持续学习。它采用Lagrange对偶（LD）方法根据历史上的最优策略动态地正则化当前策略

    arXiv:2402.14228v1 Announce Type: cross  Abstract: Reinforcement Learning from Human Feedback (RLHF) is commonly utilized to improve the alignment of Large Language Models (LLMs) with human preferences. Given the evolving nature of human preferences, continual alignment becomes more crucial and practical in comparison to traditional static alignment. Nevertheless, making RLHF compatible with Continual Learning (CL) is challenging due to its complex process. Meanwhile, directly learning new human preferences may lead to Catastrophic Forgetting (CF) of historical preferences, resulting in helpless or harmful outputs. To overcome these challenges, we propose the Continual Optimal Policy Regularization (COPR) method, which draws inspiration from the optimal policy theory. COPR utilizes a sampling distribution as a demonstration and regularization constraints for CL. It adopts the Lagrangian Duality (LD) method to dynamically regularize the current policy based on the historically optimal p
    
[^81]: Moonwalk：逆向-前向微分

    Moonwalk: Inverse-Forward Differentiation

    [https://arxiv.org/abs/2402.14212](https://arxiv.org/abs/2402.14212)

    Moonwalk引入了一种基于向量-逆-Jacobian乘积的新技术，加速前向梯度计算，显著减少内存占用，并在保持真实梯度准确性的同时，将计算时间降低了几个数量级。

    

    反向传播虽然在梯度计算方面有效，但在解决内存消耗和扩展性方面表现不佳。这项工作探索了前向梯度计算作为可逆网络中的一种替代方法，展示了它在减少内存占用的潜力，并不带来重大缺点。我们引入了一种基于向量-逆-Jacobian乘积的新技术，加速了前向梯度的计算，同时保留了减少内存和保持真实梯度准确性的优势。我们的方法Moonwalk在网络深度方面具有线性时间复杂度，与朴素前向的二次时间复杂度相比，在没有分配更多内存的情况下，从实证的角度减少了几个数量级的计算时间。我们进一步通过将Moonwalk与反向模式微分相结合来加速，以实现与反向传播相当的时间复杂度，同时保持更小的内存使用量。

    arXiv:2402.14212v1 Announce Type: cross  Abstract: Backpropagation, while effective for gradient computation, falls short in addressing memory consumption, limiting scalability. This work explores forward-mode gradient computation as an alternative in invertible networks, showing its potential to reduce the memory footprint without substantial drawbacks. We introduce a novel technique based on a vector-inverse-Jacobian product that accelerates the computation of forward gradients while retaining the advantages of memory reduction and preserving the fidelity of true gradients. Our method, Moonwalk, has a time complexity linear in the depth of the network, unlike the quadratic time complexity of na\"ive forward, and empirically reduces computation time by several orders of magnitude without allocating more memory. We further accelerate Moonwalk by combining it with reverse-mode differentiation to achieve time complexity comparable with backpropagation while maintaining a much smaller mem
    
[^82]: 面向公平文本嵌入的内容条件去偏方法

    Content Conditional Debiasing for Fair Text Embedding

    [https://arxiv.org/abs/2402.14208](https://arxiv.org/abs/2402.14208)

    通过在内容条件下确保敏感属性与文本嵌入之间的条件独立性，我们提出了一种可以改善公平性的新方法，在保持效用的同时，解决了缺乏适当训练数据的问题。

    

    在自然语言处理（NLP）中，减轻机器学习模型中的偏见引起了越来越多的关注。然而，只有少数研究集中在公平的文本嵌入上，这对实际应用至关重要且具有挑战性。本文提出了一种学习公平文本嵌入的新方法。我们通过确保在内容条件下敏感属性与文本嵌入之间的条件独立性来实现公平性，同时保持效用权衡。具体来说，我们强制要求具有不同敏感属性但相同内容的文本的嵌入与其对应中立文本的嵌入保持相同的距离。此外，我们通过使用大型语言模型（LLMs）将文本增强为不同的敏感组，来解决缺乏适当训练数据的问题。我们广泛的评估表明，我们的方法有效地提高了公平性同时保持了嵌入的效用。

    arXiv:2402.14208v1 Announce Type: cross  Abstract: Mitigating biases in machine learning models has gained increasing attention in Natural Language Processing (NLP). Yet, only a few studies focus on fair text embeddings, which are crucial yet challenging for real-world applications. In this paper, we propose a novel method for learning fair text embeddings. We achieve fairness while maintaining utility trade-off by ensuring conditional independence between sensitive attributes and text embeddings conditioned on the content. Specifically, we enforce that embeddings of texts with different sensitive attributes but identical content maintain the same distance toward the embedding of their corresponding neutral text. Furthermore, we address the issue of lacking proper training data by using Large Language Models (LLMs) to augment texts into different sensitive groups. Our extensive evaluations demonstrate that our approach effectively improves fairness while preserving the utility of embed
    
[^83]: 用大型语言模型从头开始辅助撰写类似维基百科文章

    Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models

    [https://arxiv.org/abs/2402.14207](https://arxiv.org/abs/2402.14207)

    提出了一种名为STORM的写作系统，用于通过检索和多视角提问合成主题概要，以辅助从头开始写类似维基百科的文章。

    

    我们研究如何应用大型语言模型从头开始撰写基于事实和有条理的长篇文章，使其在广度和深度上与维基百科页面可媲美。这一尚未深入研究的问题在撰写前阶段提出了新的挑战，包括如何研究主题并准备大纲以便撰写。我们提出了STORM，一个用于通过检索和多视角提问进行主题概要合成的写作系统。STORM模拟了撰写前阶段，其中（1）发现研究给定主题的多样化观点，（2）模拟会话，撰写持有不同观点的作者向基于可信互联网来源的主题专家提问，（3）整理收集到的信息以创建大纲。为了评估，我们整理了FreshWiki，一个包含最新高质量维基百科文章的数据集，并制定了大纲评估指标以评估撰写前阶段。

    arXiv:2402.14207v1 Announce Type: cross  Abstract: We study how to apply large language models to write grounded and organized long-form articles from scratch, with comparable breadth and depth to Wikipedia pages. This underexplored problem poses new challenges at the pre-writing stage, including how to research the topic and prepare an outline prior to writing. We propose STORM, a writing system for the Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking. STORM models the pre-writing stage by (1) discovering diverse perspectives in researching the given topic, (2) simulating conversations where writers carrying different perspectives pose questions to a topic expert grounded on trusted Internet sources, (3) curating the collected information to create an outline.   For evaluation, we curate FreshWiki, a dataset of recent high-quality Wikipedia articles, and formulate outline assessments to evaluate the pre-writing stage. We further gather feedback from 
    
[^84]: 从采纳到适应：追踪新表情符号在Twitter上的传播

    From Adoption to Adaption: Tracing the Diffusion of New Emojis on Twitter

    [https://arxiv.org/abs/2402.14187](https://arxiv.org/abs/2402.14187)

    本研究通过分析英文推文数据集，探讨了新表情符号在Twitter上的传播情况，发现早期采纳者规模和表情符号语义对其流行度至关重要，并提出了一个新框架来解释新表情符号，从而改善情感分类性能。

    

    在社交媒体快速发展的背景下，Unicode发布新表情符号版本提供了一个探索数字语言演变的结构化机会。通过分析大量抽样的英文推文数据集，我们研究了新发布的表情符号如何获得关注并如何在含义上演变。我们发现早期采纳者的社区规模和表情符号语义对于确定它们的受欢迎程度至关重要。在传播过程中，某些表情符号经历了显著的含义变化和情感关联的变化。此外，我们提出了一个利用语言模型提取具有语义上相似上下文的单词和既有表情符号的新框架，这有助于解释新表情符号。该框架通过用熟悉的表情符号替代未知的新表情符号，提高了情感分类性能。这项研究为我们理解新语言的采用提供了新的视角。

    arXiv:2402.14187v1 Announce Type: cross  Abstract: In the rapidly evolving landscape of social media, the introduction of new emojis in Unicode release versions presents a structured opportunity to explore digital language evolution. Analyzing a large dataset of sampled English tweets, we examine how newly released emojis gain traction and evolve in meaning. We find that community size of early adopters and emoji semantics are crucial in determining their popularity. Certain emojis experienced notable shifts in the meanings and sentiment associations during the diffusion process. Additionally, we propose a novel framework utilizing language models to extract words and pre-existing emojis with semantically similar contexts, which enhances interpretation of new emojis. The framework demonstrates its effectiveness in improving sentiment classification performance by substituting unknown new emojis with familiar ones. This study offers a new perspective in understanding how new language un
    
[^85]: 机器和人类是否关注相似的代码？探索大型语言模型在代码总结中的解释性

    Do Machines and Humans Focus on Similar Code? Exploring Explainability of Large Language Models in Code Summarization

    [https://arxiv.org/abs/2402.14182](https://arxiv.org/abs/2402.14182)

    本研究通过眼动追踪指标和 SHAP 方法对比了人类与语言模型在代码总结中的关注重点，展示了语言模型解释性的负面结果。

    

    最近的语言模型展示了在总结源代码方面的熟练能力。然而，与许多其他机器学习领域一样，代码的语言模型缺乏足够的解释性。我们非正式地缺乏对模型如何从代码中学习以及学习了什么的公式化或直觉性理解。如果语言模型学会生成更高质量的代码总结，那么它们在认为相同的代码部分重要时也与人类程序员所识别的部分相一致，可以在一定程度上提供语言模型的解释性。在本文中，我们通过人类理解的视角，报告了我们对语言模型在代码总结中解释性的调查的负面结果。我们使用眼动追踪指标（如注视次数和代码总结任务中的停留时间）来衡量人类对代码的关注。为了近似语言模型的关注重点，我们采用了一种最先进的模型无关、黑盒、基于扰动的方法——SHAP（SHapley Additive）。

    arXiv:2402.14182v1 Announce Type: cross  Abstract: Recent language models have demonstrated proficiency in summarizing source code. However, as in many other domains of machine learning, language models of code lack sufficient explainability. Informally, we lack a formulaic or intuitive understanding of what and how models learn from code. Explainability of language models can be partially provided if, as the models learn to produce higher-quality code summaries, they also align in deeming the same code parts important as those identified by human programmers. In this paper, we report negative results from our investigation of explainability of language models in code summarization through the lens of human comprehension. We measure human focus on code using eye-tracking metrics such as fixation counts and duration in code summarization tasks. To approximate language model focus, we employ a state-of-the-art model-agnostic, black-box, perturbation-based approach, SHAP (SHapley Additive
    
[^86]: 孟加拉AI：利用大型语言模型进行族裔媒体机器翻译的框架

    Bangla AI: A Framework for Machine Translation Utilizing Large Language Models for Ethnic Media

    [https://arxiv.org/abs/2402.14179](https://arxiv.org/abs/2402.14179)

    该研究探讨了如何在民族媒体领域整合大型语言模型和多语言机器翻译，以提升新闻翻译、搜索和分类的效率和准确性。

    

    民族媒体是为驻留在东道国的侨民社区提供服务的重要平台，既服务于这些社区制作内容，又让他们获取信息。与使用东道国语言不同，民族媒体以移民社区的语言发布新闻。举例来说，在美国，孟加拉族裔媒体使用孟加拉语而不是英语发布新闻。本研究探讨了在民族媒体领域潜在整合大型语言模型（LLM）和多语言机器翻译（MMT）的可能性。它着重探讨了在新闻翻译、搜索和分类的各个方面中使用LLM进行MMT的变革潜力。论文概述了一个理论框架，阐明了如何将LLM和MMT整合到民族媒体的新闻搜索和翻译过程中。此外，它还简要讨论了与LLM和MMT整合相关的潜在伦理挑战。

    arXiv:2402.14179v1 Announce Type: cross  Abstract: Ethnic media, which caters to diaspora communities in host nations, serves as a vital platform for these communities to both produce content and access information. Rather than utilizing the language of the host nation, ethnic media delivers news in the language of the immigrant community. For instance, in the USA, Bangla ethnic media presents news in Bangla rather than English. This research delves into the prospective integration of large language models (LLM) and multi-lingual machine translations (MMT) within the ethnic media industry. It centers on the transformative potential of using LLM in MMT in various facets of news translation, searching, and categorization. The paper outlines a theoretical framework elucidating the integration of LLM and MMT into the news searching and translation processes for ethnic media. Additionally, it briefly addresses the potential ethical challenges associated with the incorporation of LLM and MMT
    
[^87]: 在动态游戏中融合数据驱动的先验知识

    Blending Data-Driven Priors in Dynamic Games

    [https://arxiv.org/abs/2402.14174](https://arxiv.org/abs/2402.14174)

    探索一种在动态游戏中将数据驱动参考政策与基于优化博弈政策相融合的方法，提出了一种非合作动态博弈KLGame，其中包含了针对每个决策者的可调参数。

    

    随着智能机器人如自动驾驶车辆在人群中的部署越来越多，这些系统应该在安全的、与人互动意识相关的运动规划中利用基于模型的博弈论规划器与数据驱动政策的程度仍然是一个悬而未决的问题。本文探讨了一种融合数据驱动参考政策和基于优化的博弈论政策的原则性方法。我们制定了KLGame，这是一种带有Kullback-Leibler（KL）正则化的非合作动态博弈，针对一个一般的、随机的，可能是多模式的参考政策。

    arXiv:2402.14174v1 Announce Type: cross  Abstract: As intelligent robots like autonomous vehicles become increasingly deployed in the presence of people, the extent to which these systems should leverage model-based game-theoretic planners versus data-driven policies for safe, interaction-aware motion planning remains an open question. Existing dynamic game formulations assume all agents are task-driven and behave optimally. However, in reality, humans tend to deviate from the decisions prescribed by these models, and their behavior is better approximated under a noisy-rational paradigm. In this work, we investigate a principled methodology to blend a data-driven reference policy with an optimization-based game-theoretic policy. We formulate KLGame, a type of non-cooperative dynamic game with Kullback-Leibler (KL) regularization with respect to a general, stochastic, and possibly multi-modal reference policy. Our method incorporates, for each decision maker, a tunable parameter that pe
    
[^88]: 关于医学影像分析的大型视觉语言模型：一项实证研究

    On Large Visual Language Models for Medical Imaging Analysis: An Empirical Study

    [https://arxiv.org/abs/2402.14162](https://arxiv.org/abs/2402.14162)

    本研究探讨了大型视觉语言模型在医学影像分析任务中的零样本和少样本鲁棒性，证实了它们在分析生物医学图像方面的有效性。

    

    最近，大型语言模型（LLMs）在自然语言处理中备受关注。将LLMs与视觉相结合，使用户能够探索利用多模态数据的新兴能力。视觉语言模型（VLMs），如LLaVA、Flamingo或CLIP，在各种视觉语言任务中展现出显著的表现。因此，大型模型在生物医学影像领域有着巨大的潜在应用。沿着这个方向，目前缺乏相关工作来展示大型模型诊断疾病的能力。在这项工作中，我们研究了VLMs在医学影像分析任务中的零样本和少样本鲁棒性。我们的全面实验表明了VLMs在分析生物医学图像（如脑MRI、血细胞显微图像和胸部X光片）方面的有效性。

    arXiv:2402.14162v1 Announce Type: cross  Abstract: Recently, large language models (LLMs) have taken the spotlight in natural language processing. Further, integrating LLMs with vision enables the users to explore emergent abilities with multimodal data. Visual language models (VLMs), such as LLaVA, Flamingo, or CLIP, have demonstrated impressive performance on various visio-linguistic tasks. Consequently, there are enormous applications of large models that could be potentially used in the biomedical imaging field. Along that direction, there is a lack of related work to show the ability of large models to diagnose the diseases. In this work, we study the zero-shot and few-shot robustness of VLMs on the medical imaging analysis tasks. Our comprehensive experiments demonstrate the effectiveness of VLMs in analyzing biomedical images such as brain MRIs, microscopic images of blood cells, and chest X-rays.
    
[^89]: 递归推测解码：通过无重复抽样加速LLM推理

    Recursive Speculative Decoding: Accelerating LLM Inference via Sampling Without Replacement

    [https://arxiv.org/abs/2402.14160](https://arxiv.org/abs/2402.14160)

    提出了递归推测解码(RSD)方法，通过无重复抽样最大化树的多样性，从而进一步加速LLM推理过程。

    

    推测解码是一种用于大型语言模型(LLMs)的推理加速方法，其中一个小型语言模型生成一个草稿令牌序列，该序列进一步由目标LLM并行验证。最近的研究通过建立草稿令牌树推进了这种方法，实现了优于单序列推测解码的性能。然而，这些工作在树的每个级别独立生成令牌，没有利用整个树的多样性。此外，尽管固定序列长度已经显示出更好的性能，但这些作品在固定目标计算资源上并没有进行实证研究，这是对于资源受限设备至关重要的。我们提出了递归推测解码(RSD)，一种新的基于树的方法，它对不重复抽样的草稿令牌进行最大化，并最大限度地实现了多样性。

    arXiv:2402.14160v1 Announce Type: cross  Abstract: Speculative decoding is an inference-acceleration method for large language models (LLMs) where a small language model generates a draft-token sequence which is further verified by the target LLM in parallel. Recent works have advanced this method by establishing a draft-token tree, achieving superior performance over a single-sequence speculative decoding. However, those works independently generate tokens at each level of the tree, not leveraging the tree's entire diversifiability. Besides, their empirical superiority has been shown for fixed length of sequences, implicitly granting more computational resource to LLM for the tree-based methods. None of the existing works has conducted empirical studies with fixed target computational budgets despite its importance to resource-bounded devices. We present Recursive Speculative Decoding (RSD), a novel tree-based method that samples draft tokens without replacement and maximizes the dive
    
[^90]: 基于相似性的领域排序能够减少意图识别中的灾难性遗忘吗？

    Can Similarity-Based Domain-Ordering Reduce Catastrophic Forgetting for Intent Recognition?

    [https://arxiv.org/abs/2402.14155](https://arxiv.org/abs/2402.14155)

    研究探讨了三种领域排序策略对生成式意图识别模型继续学习性能的影响，填补了现有研究中对此方面未探索的空白。

    

    任务导向的对话系统被期望在部署后能够处理不断增长的意图和领域，甚至在支持越来越多功能的情况下也能做到。为了达到这个期望，就变得至关重要去减轻在诸如意图识别等任务的继续学习（CL）设置中发生的灾难性遗忘问题（CF）。虽然现有的对话系统研究已经探索了基于重放和正则化的方法以达到这个目的，但领域排序对意图识别模型的继续学习性能的影响尚未被探索。如果理解得当，领域排序有潜力成为一个能够与现有技术如经验重放并行使用的方法。我们的工作通过比较三种领域排序策略（最小和路径、最大和路径、随机）对生成式意图识别模型的继续学习性能的影响来填补这一空白。我们的发现表明

    arXiv:2402.14155v1 Announce Type: cross  Abstract: Task-oriented dialogue systems are expected to handle a constantly expanding set of intents and domains even after they have been deployed to support more and more functionalities. To live up to this expectation, it becomes critical to mitigate the catastrophic forgetting problem (CF) that occurs in continual learning (CL) settings for a task such as intent recognition. While existing dialogue systems research has explored replay-based and regularization-based methods to this end, the effect of domain ordering on the CL performance of intent recognition models remains unexplored. If understood well, domain ordering has the potential to be an orthogonal technique that can be leveraged alongside existing techniques such as experience replay. Our work fills this gap by comparing the impact of three domain-ordering strategies (min-sum path, max-sum path, random) on the CL performance of a generative intent recognition model. Our findings r
    
[^91]: BIRCO：具有复杂目标的信息检索任务基准

    BIRCO: A Benchmark of Information Retrieval Tasks with Complex Objectives

    [https://arxiv.org/abs/2402.14151](https://arxiv.org/abs/2402.14151)

    BIRCO基准评估基于大型语言模型的信息检索系统对多方面用户目标的检索能力，发现新的检索协议和更强大的模型是解决复杂用户需求的必要条件。

    

    我们提出了具有复杂目标的信息检索(IR)任务基准(BIRCO)。 BIRCO评估IR系统根据多方面用户目标检索文档的能力。 该基准的复杂性和紧凑大小使其适用于评估基于大型语言模型(LLM)的信息检索系统。 我们提出了一个模块化框架，用于研究可能影响LLM在检索任务上的性能的因素，并确定了一个简单的基线模型，该模型与或优于现有方法和更复杂的替代方案。 没有一种方法在所有基准任务上均达到令人满意的性能，这表明需要更强大的模型和新的检索协议来解决复杂的用户需求。

    arXiv:2402.14151v1 Announce Type: cross  Abstract: We present the Benchmark of Information Retrieval (IR) tasks with Complex Objectives (BIRCO). BIRCO evaluates the ability of IR systems to retrieve documents given multi-faceted user objectives. The benchmark's complexity and compact size make it suitable for evaluating large language model (LLM)-based information retrieval systems. We present a modular framework for investigating factors that may influence LLM performance on retrieval tasks, and identify a simple baseline model which matches or outperforms existing approaches and more complex alternatives. No approach achieves satisfactory performance on all benchmark tasks, suggesting that stronger models and new retrieval protocols are necessary to address complex user needs.
    
[^92]: Wikibench：面向维基百科的基于社区驱动的AI评估数据整理

    Wikibench: Community-Driven Data Curation for AI Evaluation on Wikipedia

    [https://arxiv.org/abs/2402.14147](https://arxiv.org/abs/2402.14147)

    Wikibench是一个系统，使社区能够协作整理AI评估数据集，有效捕捉社区共识、分歧和不确定性。

    

    AI工具越来越多地部署在社区环境中。然而，用于评估AI的数据集通常由开发人员和标注者在给定社区之外创建，这可能导致关于AI性能的误导性结论。我们如何赋予社区推动有意的设计和整理对其产生影响的AI评估数据集的能力？我们在维基百科上探讨了这个问题，维基百科是一个部署了多个基于AI的内容管理工具的在线社区。我们介绍了Wikibench，一个系统，使社区能够协作整理AI评估数据集，同时通过讨论来解决歧义和观点差异。在维基百科上进行的一项现场研究显示，使用Wikibench整理的数据集能有效捕捉社区共识、分歧和不确定性。此外，研究参与者使用Wikibench来塑造整体的数据整理流程，包括完善标签定义、定义

    arXiv:2402.14147v1 Announce Type: cross  Abstract: AI tools are increasingly deployed in community contexts. However, datasets used to evaluate AI are typically created by developers and annotators outside a given community, which can yield misleading conclusions about AI performance. How might we empower communities to drive the intentional design and curation of evaluation datasets for AI that impacts them? We investigate this question on Wikipedia, an online community with multiple AI-based content moderation tools deployed. We introduce Wikibench, a system that enables communities to collaboratively curate AI evaluation datasets, while navigating ambiguities and differences in perspective through discussion. A field study on Wikipedia shows that datasets curated using Wikibench can effectively capture community consensus, disagreement, and uncertainty. Furthermore, study participants used Wikibench to shape the overall data curation process, including refining label definitions, de
    
[^93]: SecurePose：在临床环境中录制的视频中实现自动人脸模糊和人体运动动力学特征提取

    SecurePose: Automated Face Blurring and Human Movement Kinematics Extraction from Videos Recorded in Clinical Settings

    [https://arxiv.org/abs/2402.14143](https://arxiv.org/abs/2402.14143)

    SecurePose是一个开源软件，可以可靠地实现临床录制的患者视频中的人脸模糊和动力学特征提取，提高了视频评估和患者隐私的安全性。

    

    运动障碍通常通过专家对临床获取的患者视频进行共识评估来诊断。然而，这种广泛分享患者视频会对患者隐私构成风险。人脸模糊可以用来去标识化视频，但这个过程通常是手动且耗时的。现有的自动人脸模糊技术容易出现过度、不一致或不足的人脸模糊 - 这些都可能对视频评估和患者隐私造成灾难性影响。此外，在这些视频中评估运动障碍往往是主观的。提取可量化的动力学特征可以帮助了解这些视频中的运动障碍评估，但现有的方法在使用预模糊视频时容易出现错误。我们开发了一个名为SecurePose的开源软件，可以在临床录制的患者视频中实现可靠的人脸模糊和自动动力学特征提取。

    arXiv:2402.14143v1 Announce Type: cross  Abstract: Movement disorders are typically diagnosed by consensus-based expert evaluation of clinically acquired patient videos. However, such broad sharing of patient videos poses risks to patient privacy. Face blurring can be used to de-identify videos, but this process is often manual and time-consuming. Available automated face blurring techniques are subject to either excessive, inconsistent, or insufficient facial blurring - all of which can be disastrous for video assessment and patient privacy. Furthermore, assessing movement disorders in these videos is often subjective. The extraction of quantifiable kinematic features can help inform movement disorder assessment in these videos, but existing methods to do this are prone to errors if using pre-blurred videos. We have developed an open-source software called SecurePose that can both achieve reliable face blurring and automated kinematic extraction in patient videos recorded in a clinic 
    
[^94]: DeiSAM：通过指示提示分割任何内容

    DeiSAM: Segment Anything with Deictic Prompting

    [https://arxiv.org/abs/2402.14123](https://arxiv.org/abs/2402.14123)

    DeiSAM提出将大型预训练神经网络与可区分逻辑推理器结合，用于指示提示性分割，实现了在复杂场景中对象的分割

    

    大规模、预训练的神经网络已经在各种任务中展现出强大的能力，包括零-shot图像分割。为了在复杂场景中识别具体对象，人类本能地依赖于自然语言中的指示性描述，即根据上下文指称某物，比如“在桌子上并在杯子后面的物体”。然而，深度学习方法由于在复杂场景中缺乏推理能力，无法可靠地解释这种指示性表示。为了解决这个问题，我们提出了DeiSAM——将大型预训练神经网络与可区分逻辑推理器相结合，用于指示提示性分割。给定复杂的文本分割描述，DeiSAM利用大型语言模型（LLMs）生成一阶逻辑规则，并对生成的场景图进行可区分的前向推理。随后，DeiSAM通过匹配

    arXiv:2402.14123v1 Announce Type: cross  Abstract: Large-scale, pre-trained neural networks have demonstrated strong capabilities in various tasks, including zero-shot image segmentation. To identify concrete objects in complex scenes, humans instinctively rely on deictic descriptions in natural language, i.e., referring to something depending on the context such as "The object that is on the desk and behind the cup.". However, deep learning approaches cannot reliably interpret such deictic representations due to their lack of reasoning capabilities in complex scenarios. To remedy this issue, we propose DeiSAM -- a combination of large pre-trained neural networks with differentiable logic reasoners -- for deictic promptable segmentation. Given a complex, textual segmentation description, DeiSAM leverages Large Language Models (LLMs) to generate first-order logic rules and performs differentiable forward reasoning on generated scene graphs. Subsequently, DeiSAM segments objects by match
    
[^95]: 用于紧急稀疏性的掩码矩阵乘法

    Masked Matrix Multiplication for Emergent Sparsity

    [https://arxiv.org/abs/2402.14118](https://arxiv.org/abs/2402.14118)

    提出了一种用于紧急稀疏性的掩码矩阵乘法系统，可以通过运行时评估稀疏度来消除不必要的计算和避免分支，实现了较低指令数和更高性能。

    

    人工智能工作负载，特别是变压器模型，表现出紧急稀疏性，在其中计算对稠密数据进行选择性稀疏访问。这些工作负载在为稠密计算设计的硬件上效率低下，并且无法很好地映射到稀疏数据表示上。我们构建了一个矩阵乘法系统 A X B = C，该系统通过对稀疏度的运行时评估消除了不必要的计算并避免了分支。我们使用动态代码查找和预处理 A 和 B 矩阵的稀疏图，来适应 B 矩阵中编码的具体稀疏性，并为整个计算仅计算一次条件分支。在从60%到95%的广泛稀疏度范围内，与英特尔MKL的稠密或稀疏矩阵乘法例程相比，我们的实现执行的指令更少并提高了性能。效果可以达到2倍加速和4倍费用。

    arXiv:2402.14118v1 Announce Type: cross  Abstract: Artificial intelligence workloads, especially transformer models, exhibit emergent sparsity in which computations perform selective sparse access to dense data. The workloads are inefficient on hardware designed for dense computations and do not map well onto sparse data representations. We build a vectorized and parallel matrix-multiplication system A X B = C that eliminates unnecessary computations and avoids branches based on a runtime evaluation of sparsity. We use a combination of dynamic code lookup to adapt to the specific sparsity encoded in the B matrix and preprocessing of sparsity maps of the A and B matrices to compute conditional branches once for the whole computation. For a wide range of sparsity, from 60% to 95% zeros, our implementation performs fewer instructions and increases performance when compared with Intel MKL's dense or sparse matrix multiply routines. Benefits can be as large as 2 times speedup and 4 times fe
    
[^96]: FanOutQA：用于大型语言模型的多跳、多文档问答

    FanOutQA: Multi-Hop, Multi-Document Question Answering for Large Language Models

    [https://arxiv.org/abs/2402.14116](https://arxiv.org/abs/2402.14116)

    FanOutQA 提出了一个高质量的多跳、多文档问答数据集，用于评估大型语言模型在复杂推理能力上的表现，并发现当代模型在长篇上下文中仍有改进交叉文档依赖推理的空间。

    

    一种常见于日常场景中的问题类型是“fan-out”问题，即复杂的多跳、多文档推理问题，需要找到大量实体的信息。然而，目前很少有资源可以评估大型语言模型在这种问题回答能力上的表现。为了更全面地评估LLMs中的复杂推理能力，我们提出了FanOutQA，这是一个高质量的fan-out问题-答案对数据集，包括英文维基百科作为知识库的人工注释分解。我们在数据集上制定了三种基准设置，并对7个LLMs进行了基准测试，包括GPT-4、LLaMA 2、Claude-2.1和Mixtral-8x7B，发现当代模型在长篇上下文中仍有改进推理跨文档依赖的空间。我们提供我们的数据集和开源工具来运行模型，以鼓励在https://fanoutqa.com上进行评估。

    arXiv:2402.14116v1 Announce Type: cross  Abstract: One type of question that is commonly found in day-to-day scenarios is ``fan-out'' questions, complex multi-hop, multi-document reasoning questions that require finding information about a large number of entities. However, there exist few resources to evaluate this type of question-answering capability among large language models. To evaluate complex reasoning in LLMs more fully, we present FanOutQA, a high-quality dataset of fan-out question-answer pairs and human-annotated decompositions with English Wikipedia as the knowledge base. We formulate three benchmark settings across our dataset and benchmark 7 LLMs, including GPT-4, LLaMA 2, Claude-2.1, and Mixtral-8x7B, finding that contemporary models still have room to improve reasoning over inter-document dependencies in a long context. We provide our dataset and open-source tools to run models to encourage evaluation at https://fanoutqa.com
    
[^97]: EyeTrans: 合并人类和机器注意力以实现神经代码摘要

    EyeTrans: Merging Human and Machine Attention for Neural Code Summarization

    [https://arxiv.org/abs/2402.14096](https://arxiv.org/abs/2402.14096)

    引入EyeTrans方法，将人类注意力融入机器注意力，以增强神经代码摘要能力。

    

    Neural code summarization 利用深度学习模型自动生成代码片段的简要自然语言摘要。Transformer模型的发展导致在模型设计中广泛使用注意力机制。本文提出一种将人类注意力融入机器注意力以增强神经代码摘要的方法。为了实现这一融合并验证这一假设，引入了EyeTrans，包括三个步骤：(1) 进行了大量的眼动人类研究，收集和预分析数据用于模型训练，(2) 我们设计了一个以数据为中心的方法来整合人类注意力及

    arXiv:2402.14096v1 Announce Type: cross  Abstract: Neural code summarization leverages deep learning models to automatically generate brief natural language summaries of code snippets. The development of Transformer models has led to extensive use of attention during model design. While existing work has primarily and almost exclusively focused on static properties of source code and related structural representations like the Abstract Syntax Tree (AST), few studies have considered human attention, that is, where programmers focus while examining and comprehending code. In this paper, we develop a method for incorporating human attention into machine attention to enhance neural code summarization. To facilitate this incorporation and vindicate this hypothesis, we introduce EyeTrans, which consists of three steps: (1) we conduct an extensive eye-tracking human study to collect and pre-analyze data for model training, (2) we devise a data-centric approach to integrate human attention wit
    
[^98]: 跨架构零样本泛化的视觉分类

    Zero-shot generalization across architectures for visual classification

    [https://arxiv.org/abs/2402.14095](https://arxiv.org/abs/2402.14095)

    不同神经网络在跨架构和层间泛化到未知类别的能力存在差异，准确性并不是泛化能力的良好预测因子，泛化能力随着层深度呈非单调变化。

    

    深度网络的一个关键优势是对未见数据的泛化能力，但其与分类准确性的关系尚不清楚。我们利用一种极简的视觉数据集和一种泛化度量，展示了从深度卷积网络（CNNs）到transformers的流行网络在通过层和架构泛化到未见类别方面的能力存在差异。准确性并不是泛化能力的良好预测因子，并且泛化能力随着层深度呈非单调变化。代码可在https://github.com/dyballa/zero-shot-generalization 找到。

    arXiv:2402.14095v1 Announce Type: cross  Abstract: Generalization to unseen data is a key desideratum for deep networks, but its relation to classification accuracy is unclear. Using a minimalist vision dataset and a measure of generalizability, we show that popular networks, from deep convolutional networks (CNNs) to transformers, vary in their power to extrapolate to unseen classes both across layers and across architectures. Accuracy is not a good predictor of generalizability, and generalization varies non-monotonically with layer depth. Code is available at https://github.com/dyballa/zero-shot-generalization.
    
[^99]: 社会环境设计

    Social Environment Design

    [https://arxiv.org/abs/2402.14090](https://arxiv.org/abs/2402.14090)

    该论文提出了一种新的研究议程，介绍了社会环境设计作为一种用于自动化政策制定的AI通用框架，旨在捕捉一般经济环境，通过AI模拟系统分析政府和经济政策，并强调未来基于AI的政策制定研究中的关键挑战。

    

    人工智能（AI）作为一种用于改善政府和经济政策制定的技术具有潜力。本文提出了一个新的研究议程，介绍了社会环境设计，这是一种用于自动化政策制定的AI通用框架，与强化学习、经济与计算社会选择社区相连接。该框架旨在捕捉一般经济环境，包括对政策目标的投票，并为通过AI模拟对政府和经济政策进行系统分析提供指导。我们强调了未来基于AI的政策制定研究中的关键开放问题。通过解决这些挑战，我们希望实现各种社会福利目标，从而促进更具道德和负责任的决策制定。

    arXiv:2402.14090v1 Announce Type: new  Abstract: Artificial Intelligence (AI) holds promise as a technology that can be used to improve government and economic policy-making. This paper proposes a new research agenda towards this end by introducing Social Environment Design, a general framework for the use of AI for automated policy-making that connects with the Reinforcement Learning, EconCS, and Computational Social Choice communities. The framework seeks to capture general economic environments, includes voting on policy objectives, and gives a direction for the systematic analysis of government and economic policy through AI simulation. We highlight key open problems for future research in AI-based policy-making. By solving these challenges, we hope to achieve various social welfare objectives, thereby promoting more ethical and responsible decision making.
    
[^100]: LexC-Gen: 利用大型语言模型和双语词汇表为极低资源语言生成数据

    LexC-Gen: Generating Data for Extremely Low-Resource Languages with Large Language Models and Bilingual Lexicons

    [https://arxiv.org/abs/2402.14086](https://arxiv.org/abs/2402.14086)

    LexC-Gen提出了一种词典条件数据生成方法，可以以大规模生成低资源语言分类任务数据，取得了较好的效果。

    

    低资源语言的数据匮乏可以通过利用双语词典中从高资源语言的标记任务数据进行逐字翻译来解决，然而，双语词典通常与任务数据有限的词汇重叠，导致翻译覆盖和词典利用不佳。我们提出了一种称为LexC-Gen的词典条件数据生成方法，该方法可以大规模生成低资源语言分类任务数据。具体而言，LexC-Gen首先使用双语词典中的高资源语言单词生成与词典兼容的任务数据，然后通过单词翻译将其翻译成低资源语言。在17种极低资源语言中，LexC-Gen生成的数据在性能上与专家翻译的黄金数据竞争力相当，并且在情感分析和主题分类上平均比现有的基于词典的单词翻译方法提高了5.6和8.9个分数。

    arXiv:2402.14086v1 Announce Type: cross  Abstract: Data scarcity in low-resource languages can be addressed with word-to-word translations from labeled task data in high-resource languages using bilingual lexicons. However, bilingual lexicons often have limited lexical overlap with task data, which results in poor translation coverage and lexicon utilization. We propose lexicon-conditioned data generation (LexC-Gen), a method that generates low-resource-language classification task data at scale. Specifically, LexC-Gen first uses high-resource-language words from bilingual lexicons to generate lexicon-compatible task data, and then it translates them into low-resource languages with bilingual lexicons via word translation. Across 17 extremely low-resource languages, LexC-Gen generated data is competitive with expert-translated gold data, and yields on average 5.6 and 8.9 points improvement over existing lexicon-based word translation methods on sentiment analysis and topic classificati
    
[^101]: 超越A*：通过搜索动力学引导以改进变压器规划

    Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping

    [https://arxiv.org/abs/2402.14083](https://arxiv.org/abs/2402.14083)

    通过专家迭代训练的Searchformer模型，可以更少的搜索步骤来解决复杂规划任务，同时生成最佳计划。

    

    尽管变压器在各种应用场景中取得了巨大进展，但这种架构在解决复杂决策任务方面仍落后于传统的符号规划器。在这项工作中，我们展示了如何训练变压器来解决复杂的规划任务，并提出了Searchformer，这是一个变压器模型，可以在93.7%的时间内最优地解决以前未见的Sokoban谜题，同时比标准的$A^*$搜索使用少达26.8%的搜索步骤。Searchformer是一个经过训练的编码器-解码器变压器模型，用于预测$A^*$的搜索动力学。然后通过专家迭代进行微调，以执行比$A^*$搜索更少的搜索步骤，同时生成一个最佳计划。在我们的训练方法中，$A^*$的搜索动力学被表达为一个标记序列，描述了符号规划期间任务状态何时被加入和移除到搜索树中。在我们关于迷宫导航的消融研究中，我们发现S

    arXiv:2402.14083v1 Announce Type: new  Abstract: While Transformers have enabled tremendous progress in various application settings, such architectures still lag behind traditional symbolic planners for solving complex decision making tasks. In this work, we demonstrate how to train Transformers to solve complex planning tasks and present Searchformer, a Transformer model that optimally solves previously unseen Sokoban puzzles 93.7% of the time, while using up to 26.8% fewer search steps than standard $A^*$ search. Searchformer is an encoder-decoder Transformer model trained to predict the search dynamics of $A^*$. This model is then fine-tuned via expert iterations to perform fewer search steps than $A^*$ search while still generating an optimal plan. In our training method, $A^*$'s search dynamics are expressed as a token sequence outlining when task states are added and removed into the search tree during symbolic planning. In our ablation studies on maze navigation, we find that S
    
[^102]: 使用具有运动代码的随机过程模型对嘈杂时间序列集合进行鲁棒学习

    Robust Learning of Noisy Time Series Collections Using Stochastic Process Models with Motion Codes

    [https://arxiv.org/abs/2402.14081](https://arxiv.org/abs/2402.14081)

    使用具有学习谱核的混合高斯过程的潜变量模型方法，针对嘈杂时间序列数据进行鲁棒学习。

    

    虽然时间序列分类和预测问题已经得到广泛研究，但具有任意时间序列长度的嘈杂时间序列数据的情况仍具挑战性。每个时间序列实例可以看作是嘈杂动态模型的一个样本实现，其特点是连续随机过程。对于许多应用，数据是混合的，由多个随机过程建模的几种类型的嘈杂时间序列序列组成，使得预测和分类任务变得更具挑战性。我们不是简单地将数据回归到每种时间序列类型，而是采用具有学习谱核的混合高斯过程的潜变量模型方法。更具体地说，我们为每种类型的嘈杂时间序列数据自动分配一个称为其运动代码的签名向量。然后，在每个分配的运动代码的条件下，我们推断出相关性的稀疏近似。

    arXiv:2402.14081v1 Announce Type: cross  Abstract: While time series classification and forecasting problems have been extensively studied, the cases of noisy time series data with arbitrary time sequence lengths have remained challenging. Each time series instance can be thought of as a sample realization of a noisy dynamical model, which is characterized by a continuous stochastic process. For many applications, the data are mixed and consist of several types of noisy time series sequences modeled by multiple stochastic processes, making the forecasting and classification tasks even more challenging. Instead of regressing data naively and individually to each time series type, we take a latent variable model approach using a mixtured Gaussian processes with learned spectral kernels. More specifically, we auto-assign each type of noisy time series data a signature vector called its motion code. Then, conditioned on each assigned motion code, we infer a sparse approximation of the corr
    
[^103]: 高效的规范化置信预测与不确定性量化：基于深度回归森林的抗癌药物敏感性预测

    Efficient Normalized Conformal Prediction and Uncertainty Quantification for Anti-Cancer Drug Sensitivity Prediction with Deep Regression Forests

    [https://arxiv.org/abs/2402.14080](https://arxiv.org/abs/2402.14080)

    通过深度回归森林计算样本方差，提高了抗癌药物敏感性预测中的规范化置信预测效率和覆盖率

    

    深度学习模型正在被应用于各种关键决策任务，然而它们被训练为提供点预测而没有提供信心度。如果与不确定性估计结合，深度学习模型的可信度可以得到提高。置信预测已经被证明是一种有希望的方法，可以将机器学习模型与预测区间配对，从而可以看到模型的不确定性。然而，常见的用于置信预测的不确定性估计方法未能提供对所有样本同样准确的异方差间隔。本文提出了一种方法，通过从深度回归森林获得的方差来估计每个样本的不确定性。我们展示了深度回归森林的方差如何提高药物反应预测任务上规范化诱导置信预测的效率和覆盖率。

    arXiv:2402.14080v1 Announce Type: cross  Abstract: Deep learning models are being adopted and applied on various critical decision-making tasks, yet they are trained to provide point predictions without providing degrees of confidence. The trustworthiness of deep learning models can be increased if paired with uncertainty estimations. Conformal Prediction has emerged as a promising method to pair machine learning models with prediction intervals, allowing for a view of the model's uncertainty. However, popular uncertainty estimation methods for conformal prediction fail to provide heteroskedastic intervals that are equally accurate for all samples. In this paper, we propose a method to estimate the uncertainty of each sample by calculating the variance obtained from a Deep Regression Forest. We show that the deep regression forest variance improves the efficiency and coverage of normalized inductive conformal prediction on a drug response prediction task.
    
[^104]: 用于极端数据缩放的生成对抗模型

    Generative Adversarial Models for Extreme Downscaling of Climate Datasets

    [https://arxiv.org/abs/2402.14049](https://arxiv.org/abs/2402.14049)

    该方法提出了一种基于条件GAN的地理空间数据缩放方法，可以从非常低分辨率的输入生成高分辨率准确的气候数据集，并且明确考虑了不确定性。

    

    应对气候变化的挑战需要准确和高分辨率地映射气候和天气变量。然而，许多现有的气候数据集只能以非常粗糙的空间分辨率提供，这是由于模型复杂性和极高的计算需求所致。基于深度学习的方法，特别是生成对抗网络（GAN）及其变体，已被证明在提升自然图像方面非常有效，并在改进科学数据集方面显示出巨大潜力。本文描述了一种基于条件GAN的地理空间数据缩放方法，用于极端缩放网格气候数据集。与大多数现有方法相比，这种方法可以从非常低分辨率的输入生成高分辨率准确的气候数据集。更重要的是，该方法明确考虑了不确定性。

    arXiv:2402.14049v1 Announce Type: cross  Abstract: Addressing the challenges of climate change requires accurate and high-resolution mapping of climate and weather variables. However, many existing climate datasets, such as the gridded outputs of the state-of-the-art numerical climate models (e.g., general circulation models), are only available at very coarse spatial resolutions due to the model complexity and extremely high computational demand. Deep-learning-based methods, particularly generative adversarial networks (GANs) and their variants, have proved effective for refining natural images, and have shown great promise in improving scientific datasets. In this paper, we describe a conditional GAN-based geospatial downscaling method for extreme downscaling of gridded climate datasets. Compared to most existing methods, the method can generate high-resolution accurate climate datasets from very low-resolution inputs. More importantly, the method explicitly considers the uncertainty
    
[^105]: PolyNet：学习神经组合优化的多样化解决策略

    PolyNet: Learning Diverse Solution Strategies for Neural Combinatorial Optimization

    [https://arxiv.org/abs/2402.14048](https://arxiv.org/abs/2402.14048)

    PolyNet通过学习互补解决策略来改善解空间探索，避免了人为规则导致解决方案质量下降的问题。

    

    强化学习方法用于构建组合优化问题解决方案，迅速接近人类设计的算法性能。为了进一步缩小差距，基于学习的方法在搜索过程中必须高效地探索解空间。最近的方法通过强制实施多样化解生成来人为增加探索，然而，这些规则可能损害解决方案质量，并且难以为更复杂的问题设计。本文介绍了PolyNet，一种通过学习互补解决策略来改善解空间探索的方法。与其他作品不同，PolyNet仅使用单个解码器，并且训练图式不通过人为规则强制实施多样化解生成。我们在四个组合优化问题上评估PolyNet，并观察到隐式多样性机制允许P

    arXiv:2402.14048v1 Announce Type: cross  Abstract: Reinforcement learning-based methods for constructing solutions to combinatorial optimization problems are rapidly approaching the performance of human-designed algorithms. To further narrow the gap, learning-based approaches must efficiently explore the solution space during the search process. Recent approaches artificially increase exploration by enforcing diverse solution generation through handcrafted rules, however, these rules can impair solution quality and are difficult to design for more complex problems. In this paper, we introduce PolyNet, an approach for improving exploration of the solution space by learning complementary solution strategies. In contrast to other works, PolyNet uses only a single-decoder and a training schema that does not enforce diverse solution generation through handcrafted rules. We evaluate PolyNet on four combinatorial optimization problems and observe that the implicit diversity mechanism allows P
    
[^106]: 简单而有效的神经符号一体化迁移学习

    Simple and Effective Transfer Learning for Neuro-Symbolic Integration

    [https://arxiv.org/abs/2402.14047](https://arxiv.org/abs/2402.14047)

    提出了一种简单而有效的方法，通过在下游任务上预训练神经模型，然后通过迁移学习在相同任务上对NeSy模型进行训练，以实现神经符号一体化的改进。

    

    深度学习技术近年来取得了显著成功。然而，它们在泛化和执行推理任务方面的能力仍然是一个挑战。本文提出了一种简单而有效的方法来改善这些问题，该方法涉及在下游任务上预训练神经模型，然后通过迁移学习在相同任务上对NeSy模型进行训练，其中利用神经网络将感知映射到符号，并利用逻辑推理者预测下游任务的输出。

    arXiv:2402.14047v1 Announce Type: cross  Abstract: Deep Learning (DL) techniques have achieved remarkable successes in recent years. However, their ability to generalize and execute reasoning tasks remains a challenge. A potential solution to this issue is Neuro-Symbolic Integration (NeSy), where neural approaches are combined with symbolic reasoning. Most of these methods exploit a neural network to map perceptions to symbols and a logical reasoner to predict the output of the downstream task. These methods exhibit superior generalization capacity compared to fully neural architectures. However, they suffer from several issues, including slow convergence, learning difficulties with complex perception tasks, and convergence to local minima. This paper proposes a simple yet effective method to ameliorate these problems. The key idea involves pretraining a neural model on the downstream task. Then, a NeSy model is trained on the same task via transfer learning, where the weights of the p
    
[^107]: 基于改进的海马优化器的全局优化和工程问题求解新方法

    A new approach for solving global optimization and engineering problems based on modified Sea Horse Optimizer

    [https://arxiv.org/abs/2402.14044](https://arxiv.org/abs/2402.14044)

    该研究提出了一种名为mSHO的全新SHO算法变体，通过创新的本地搜索策略，分为邻域局部搜索、全局非邻域搜索和绕行方法，主要增强了SHO算法的开发能力。

    

    海马优化器（SHO）是一种值得注意的元启发式算法，模拟了海马展示的各种智能行为，包括进食模式、雄性繁殖策略和复杂的运动模式。为了模仿海马的微妙运动，SHO集成了对数螺旋方程和Levy飞行，有效地将具有实质步长的随机移动与精细的局部开发相结合。此外，布朗运动的利用促进了对搜索空间的更全面探索。本研究引入了一种名为mSHO的强大高性能的SHO算法变体。增强主要集中在通过用创新的本地搜索策略替换其原始方法来加强SHO的开发能力，该策略包括三个不同的步骤：基于邻域的局部搜索，全局非邻域搜索以及涉及绕行的方法。

    arXiv:2402.14044v1 Announce Type: cross  Abstract: Sea Horse Optimizer (SHO) is a noteworthy metaheuristic algorithm that emulates various intelligent behaviors exhibited by sea horses, encompassing feeding patterns, male reproductive strategies, and intricate movement patterns. To mimic the nuanced locomotion of sea horses, SHO integrates the logarithmic helical equation and Levy flight, effectively incorporating both random movements with substantial step sizes and refined local exploitation. Additionally, the utilization of Brownian motion facilitates a more comprehensive exploration of the search space. This study introduces a robust and high-performance variant of the SHO algorithm named mSHO. The enhancement primarily focuses on bolstering SHO's exploitation capabilities by replacing its original method with an innovative local search strategy encompassing three distinct steps: a neighborhood-based local search, a global non-neighbor-based search, and a method involving circumnav
    
[^108]: 使用GANs生成合成数据延伸与保护——基于时间序列医疗记录

    Protect and Extend -- Using GANs for Synthetic Data Generation of Time-Series Medical Records

    [https://arxiv.org/abs/2402.14042](https://arxiv.org/abs/2402.14042)

    本研究使用GANs生成了时间序列合成痴呆患者医疗记录的数据集，并比较了不同GAN模型在生成合成数据方面的质量，实现了在不涉及隐私问题的情况下保护用户数据并延伸数据应用。

    

    arXiv:2402.14042v1 公告类型:交叉摘要: 保护私人用户数据对于高质量体验(QoE)和可接受性至关重要，尤其是对于处理敏感数据的服务，如基于IT的健康服务。尽管已经显示匿名化技术容易被数据重新识别，但合成数据生成逐渐取代了匿名化，因为它相对耗时和资源耗费较少，并且更能抵抗数据泄漏。生成对抗网络(GANs)已被用于生成合成数据集，特别是遵循差分隐私现象的GAN框架。本研究比较了用于生成时间序列合成痴呆患者医疗记录的最新GAN基模型，这些数据可以在不涉及隐私问题的情况下分发。 预测建模、自相关性和分布分析被用来评估生成数据的生成质量(QoG)。

    arXiv:2402.14042v1 Announce Type: cross  Abstract: Preservation of private user data is of paramount importance for high Quality of Experience (QoE) and acceptability, particularly with services treating sensitive data, such as IT-based health services. Whereas anonymization techniques were shown to be prone to data re-identification, synthetic data generation has gradually replaced anonymization since it is relatively less time and resource-consuming and more robust to data leakage. Generative Adversarial Networks (GANs) have been used for generating synthetic datasets, especially GAN frameworks adhering to the differential privacy phenomena. This research compares state-of-the-art GAN-based models for synthetic data generation to generate time-series synthetic medical records of dementia patients which can be distributed without privacy concerns. Predictive modeling, autocorrelation, and distribution analysis are used to assess the Quality of Generating (QoG) of the generated data. T
    
[^109]: E2USD：用于多元时间序列的高效而有效的无监督状态检测

    E2USD: Efficient-yet-effective Unsupervised State Detection for Multivariate Time Series

    [https://arxiv.org/abs/2402.14041](https://arxiv.org/abs/2402.14041)

    E2USD提出了一种有效的无监督多元时间序列状态检测方法，利用了快速傅里叶变换和双视图嵌入模块进行编码，以及通过对抗学习方法消除假阴性，从而实现了SOTA准确性并显著降低了计算开销。

    

    我们提出了E2USD方法，能够实现高效而准确的无监督多元时间序列状态检测。E2USD利用基于快速傅立叶变换的时间序列压缩器(FFTCompress)和分解的双视图嵌入模块(DDEM)，一起以低计算开销对输入的多元时间序列进行编码。此外，我们提出了一种假阴性取消对比学习方法(FNCCLearning)，以抵消假阴性的影响，并实现更友好的簇嵌入空间。为了在流式设置中进一步减少计算开销，我们引入了自适应阈值检测(ADATD)。通过使用六个基线模型和六个数据集进行全面实验，我们证明E2USD能够在显著降低计算开销的情况下达到SOTA的准确性。我们的代码可在https://github.com/AI4CTS/E2Usd 找到。

    arXiv:2402.14041v1 Announce Type: cross  Abstract: We propose E2USD that enables efficient-yet-accurate unsupervised MTS state detection. E2USD exploits a Fast Fourier Transform-based Time Series Compressor (FFTCompress) and a Decomposed Dual-view Embedding Module (DDEM) that together encode input MTSs at low computational overhead. Additionally, we propose a False Negative Cancellation Contrastive Learning method (FNCCLearning) to counteract the effects of false negatives and to achieve more cluster-friendly embedding spaces. To reduce computational overhead further in streaming settings, we introduce Adaptive Threshold Detection (ADATD). Comprehensive experiments with six baselines and six datasets offer evidence that E2USD is capable of SOTA accuracy at significantly reduced computational overhead. Our code is available at https://github.com/AI4CTS/E2Usd.
    
[^110]: 在高度不平衡的多类分布情境下的远程医疗专业检测

    Specialty detection in the context of telemedicine in a highly imbalanced multi-class distribution

    [https://arxiv.org/abs/2402.14039](https://arxiv.org/abs/2402.14039)

    提出基于机器学习模型的专业检测分类器，用于自动化检测每个问题的正确专业并将其路由到正确的医生，重点是处理阿拉伯医疗问题的多类别和高度不平衡数据集。

    

    Covid-19大流行导致了对远程医疗服务的认识和需求增加，进而需要自动化流程，并依赖机器学习（ML）来减少运营负担。本研究提出了一种基于机器学习模型的专业检测分类器，用于自动化检测每个问题的正确专业并将其路由到正确的医生。该研究专注于处理阿拉伯医疗问题的多类别和高度不平衡数据集，比较了一些过采样技术，开发了一种用于专业检测的深度神经网络（DNN）模型，并探讨了依赖于专业检测的隐藏业务领域，例如为不同专业定制和个性化咨询流程等。

    arXiv:2402.14039v1 Announce Type: cross  Abstract: The Covid-19 pandemic has led to an increase in the awareness of and demand for telemedicine services, resulting in a need for automating the process and relying on machine learning (ML) to reduce the operational load. This research proposes a specialty detection classifier based on a machine learning model to automate the process of detecting the correct specialty for each question and routing it to the correct doctor. The study focuses on handling multiclass and highly imbalanced datasets for Arabic medical questions, comparing some oversampling techniques, developing a Deep Neural Network (DNN) model for specialty detection, and exploring the hidden business areas that rely on specialty detection such as customizing and personalizing the consultation flow for different specialties. The proposed module is deployed in both synchronous and asynchronous medical consultations to provide more real-time classification, minimize the doctor 
    
[^111]: 基于混合哈里斯鹰和多层感知器的有效网络入侵检测方法

    An Effective Networks Intrusion Detection Approach Based on Hybrid Harris Hawks and Multi-Layer Perceptron

    [https://arxiv.org/abs/2402.14037](https://arxiv.org/abs/2402.14037)

    提出了一种利用哈里斯鹰优化算法来优化多层感知器学习的入侵检测系统，实现了在网络中最小化入侵检测错误，实验结果表明该方法有效识别恶意模式。

    

    本文提出了一种利用哈里斯鹰优化算法（HHO）来优化多层感知器学习的入侵检测系统（IDS），通过优化偏置和权重参数。HHO-MLP旨在在学习过程中选择最佳参数，以最小化网络中的入侵检测错误。 HHO-MLP使用EvoloPy NN框架进行实现，这是一个专门用于使用进化算法训练MLPs的开源Python工具。为了将HHO模型与当前可用的其他进化方法进行比较，使用KDD数据集计算了特异性和敏感性指标、准确性指标以及mse和rmse指标。实验表明HHO MLP方法在识别恶意模式方面是有效的。

    arXiv:2402.14037v1 Announce Type: cross  Abstract: This paper proposes an Intrusion Detection System (IDS) employing the Harris Hawks Optimization algorithm (HHO) to optimize Multilayer Perceptron learning by optimizing bias and weight parameters. HHO-MLP aims to select optimal parameters in its learning process to minimize intrusion detection errors in networks. HHO-MLP has been implemented using EvoloPy NN framework, an open-source Python tool specialized for training MLPs using evolutionary algorithms. For purposes of comparing the HHO model against other evolutionary methodologies currently available, specificity and sensitivity measures, accuracy measures, and mse and rmse measures have been calculated using KDD datasets. Experiments have demonstrated the HHO MLP method is effective at identifying malicious patterns. HHO-MLP has been tested against evolutionary algorithms like Butterfly Optimization Algorithm (BOA), Grasshopper Optimization Algorithms (GOA), and Black Widow Optimi
    
[^112]: 委员会的智慧：从基础模型到专用应用模型的提取

    Wisdom of Committee: Distilling from Foundation Model to SpecializedApplication Model

    [https://arxiv.org/abs/2402.14035](https://arxiv.org/abs/2402.14035)

    将基础模型的知识转移到专用应用模型中存在挑战，提出了通过创建教学委员会来应对这些挑战。

    

    最近基础模型的进展在各种任务上取得了令人印象深刻的性能，与此同时，为特定应用，从业者们一直在开发专门的应用模型。为了享受这两种模型的好处，一个自然的路径是将基础模型中的知识转移到专用应用模型中，后者通常更有效地提供服务。知识蒸馏的技术可以在这里应用，其中应用模型学会模仿基础模型。然而，专用应用模型和基础模型在容量上存在实质性差距，采用不同的架构，使用来自不同模态的不同输入特征，并在不同的分布上进行优化。模型特征上的这些差异导致了蒸馏方法面临重大挑战。在这项工作中，我们提出创建一个教学委员会，包括基础模型和专用应用模型。

    arXiv:2402.14035v1 Announce Type: cross  Abstract: Recent advancements in foundation models have yielded impressive performance across a wide range of tasks. Meanwhile, for specific applications, practitioners have been developing specialized application models. To enjoy the benefits of both kinds of models, one natural path is to transfer the knowledge in foundation models into specialized application models, which are generally more efficient for serving. Techniques from knowledge distillation may be applied here, where the application model learns to mimic the foundation model. However, specialized application models and foundation models have substantial gaps in capacity, employing distinct architectures, using different input features from different modalities, and being optimized on different distributions. These differences in model characteristics lead to significant challenges for distillation methods. In this work, we propose creating a teaching committee comprising both foun
    
[^113]: AgentScope: 一个灵活而又强大的多代理平台

    AgentScope: A Flexible yet Robust Multi-Agent Platform

    [https://arxiv.org/abs/2402.14034](https://arxiv.org/abs/2402.14034)

    AgentScope是一个开发者中心的多代理平台，提供了以消息交换为核心通信机制，大大降低了开发和理解的障碍，同时具备灵活的容错机制和多模态数据处理的系统级支持。

    

    随着大型语言模型（LLMs）的快速发展，多代理应用取得了显著进展。然而，在协调代理合作和LLMs的不稳定性表现方面的复杂性，给开发健壮高效的多代理应用带来了显著挑战。为了解决这些挑战，我们提出了AgentScope，一个以消息交换为核心通信机制的面向开发者的多代理平台。我们的通信机制连同丰富的句法工具、内置资源和用户友好的交互，显著降低了开发和理解的障碍。为了实现健壮和灵活的多代理应用，AgentScope提供了内置和可定制的容错机制，同时还配备用于多模态数据生成、存储和传输的系统级支持。此外，我们设计了一个基于actor的分发框架，

    arXiv:2402.14034v1 Announce Type: cross  Abstract: With the rapid advancement of Large Language Models (LLMs), significant progress has been made in multi-agent applications. However, the complexities in coordinating agents' cooperation and LLMs' erratic performance pose notable challenges in developing robust and efficient multi-agent applications. To tackle these challenges, we propose AgentScope, a developer-centric multi-agent platform with message exchange as its core communication mechanism. Together with abundant syntactic tools, built-in resources, and user-friendly interactions, our communication mechanism significantly reduces the barriers to both development and understanding. Towards robust and flexible multi-agent application, AgentScope provides both built-in and customizable fault tolerance mechanisms while it is also armed with system-level supports for multi-modal data generation, storage and transmission. Additionally, we design an actor-based distribution framework, 
    
[^114]: VN网络：利用虚拟邻居嵌入新出现的实体

    VN Network: Embedding Newly Emerging Entities with Virtual Neighbors

    [https://arxiv.org/abs/2402.14033](https://arxiv.org/abs/2402.14033)

    提出了一个名为虚拟邻居（VN）网络的新框架，以解决实体嵌入中的邻居稀疏问题，并有效整合远距离信息。

    

    将实体和关系嵌入到连续向量空间中引起了近年来的大量关注。大多数嵌入方法假定所有测试实体在训练期间均可获得，这使得为新出现的实体重新训练嵌入变得耗时。为解决这一问题，最近的研究将图神经网络应用于未知实体的现有邻居。本文提出了一种新颖的框架，即虚拟邻居（VN）网络，以解决三个关键挑战。首先，为了减少邻居稀疏问题，我们引入了通过规则推断得出的虚拟邻居的概念。我们通过解决一个受规则限制的问题为这些邻居分配软标签，而不是简单地将它们视为毫不含糊的真实。其次，许多现有方法仅使用一跳或两跳邻居进行聚合，并忽略可能有用的远距离信息。相反，我们识别了逻辑和...

    arXiv:2402.14033v1 Announce Type: cross  Abstract: Embedding entities and relations into continuous vector spaces has attracted a surge of interest in recent years. Most embedding methods assume that all test entities are available during training, which makes it time-consuming to retrain embeddings for newly emerging entities. To address this issue, recent works apply the graph neural network on the existing neighbors of the unseen entities. In this paper, we propose a novel framework, namely Virtual Neighbor (VN) network, to address three key challenges. Firstly, to reduce the neighbor sparsity problem, we introduce the concept of the virtual neighbors inferred by rules. And we assign soft labels to these neighbors by solving a rule-constrained problem, rather than simply regarding them as unquestionably true. Secondly, many existing methods only use one-hop or two-hop neighbors for aggregation and ignore the distant information that may be helpful. Instead, we identify both logic an
    
[^115]: 冻结网络中的部分搜索足以找到强大的彩票票证

    Partial Search in a Frozen Network is Enough to Find a Strong Lottery Ticket

    [https://arxiv.org/abs/2402.14029](https://arxiv.org/abs/2402.14029)

    提出一种方法，通过冻结随机子集的初始权重来减少强大的彩票票证（SLT）搜索空间，从而独立于所需SLT稀疏性降低了SLT搜索空间，保证了SLT在这种减少搜索空间中的存在。

    

    arXiv:2402.14029v1 公告类型：跨越 摘要：随机初始化的稠密网络包含可以在不进行权重学习的情况下实现高准确度的子网络--强大的彩票票证（SLTs）。最近，Gadhikar等人（2023年）在理论和实验证明，SLTs也可以在随机修剪的源网络中找到，从而减少SLT的搜索空间。然而，这限制了对甚至比源网络更稀疏的SLTs的搜索，导致由于意外的高稀疏性而准确度较差。本文提出了一种通过独立于所需SLT稀疏性的任意比率减少SLT搜索空间的方法。通过冻结一部分初始权重的随机子集，将其排除在搜索空间之外--即，通过永久修剪它们或将它们锁定为SLT的固定部分。事实上，通过我们与随机冻结变量的子集和逼近，在这种减少的搜索空间中，SLT的存在在理论上是得到保证的。除此之外，还可以减少...

    arXiv:2402.14029v1 Announce Type: cross  Abstract: Randomly initialized dense networks contain subnetworks that achieve high accuracy without weight learning -- strong lottery tickets (SLTs). Recently, Gadhikar et al. (2023) demonstrated theoretically and experimentally that SLTs can also be found within a randomly pruned source network, thus reducing the SLT search space. However, this limits the search to SLTs that are even sparser than the source, leading to worse accuracy due to unintentionally high sparsity. This paper proposes a method that reduces the SLT search space by an arbitrary ratio that is independent of the desired SLT sparsity. A random subset of the initial weights is excluded from the search space by freezing it -- i.e., by either permanently pruning them or locking them as a fixed part of the SLT. Indeed, the SLT existence in such a reduced search space is theoretically guaranteed by our subset-sum approximation with randomly frozen variables. In addition to reducin
    
[^116]: 对于既非可验证又非可证伪的事物的押注

    Betting on what is neither verifiable nor falsifiable

    [https://arxiv.org/abs/2402.14021](https://arxiv.org/abs/2402.14021)

    本文提出了一种通过期权或等同于对“验证-证伪游戏”的结果押注的方法，用于处理无法直接应用于固定解决标准问题的预测市场。

    

    预测市场对估计在某一固定时间点上将揭晓真实性的声明的概率很有用 - 这包括关于真实世界事件价值的问题（即统计不确定性），以及关于原始递归函数价值的问题（即逻辑或算法不确定性）。然而，它们不能直接应用于没有固定解决标准的问题，并且将预测市场的真实世界应用于这类问题往往仅涉及预测一个句子是否为真，而不是它是否将被证明。这类问题可以被更基本事件的可数并或交集的方式表示，或者被表示为算术层次上的一阶逻辑句子（甚至超算术句子的 FOL 之外）。在本文中，我们提出了一种通过期权对这种事件进行押注的方法，或者等效地作为对“验证-证伪游戏”的结果押注。

    arXiv:2402.14021v1 Announce Type: cross  Abstract: Prediction markets are useful for estimating probabilities of claims whose truth will be revealed at some fixed time -- this includes questions about the values of real-world events (i.e. statistical uncertainty), and questions about the values of primitive recursive functions (i.e. logical or algorithmic uncertainty). However, they cannot be directly applied to questions without a fixed resolution criterion, and real-world applications of prediction markets to such questions often amount to predicting not whether a sentence is true, but whether it will be proven. Such questions could be represented by countable unions or intersections of more basic events, or as First-Order-Logic sentences on the Arithmetical Hierarchy (or even beyond FOL, as hyperarithmetical sentences). In this paper, we propose an approach to betting on such events via options, or equivalently as bets on the outcome of a "verification-falsification game". Our work 
    
[^117]: 离线策略学习的深度生成模型：教程、调查和未来方向展望

    Deep Generative Models for Offline Policy Learning: Tutorial, Survey, and Perspectives on Future Directions

    [https://arxiv.org/abs/2402.13777](https://arxiv.org/abs/2402.13777)

    深度生成模型在离线策略学习中展现了巨大潜力，本文提供了首个系统性综述，涵盖了五种主流深度生成模型及其应用。

    

    深度生成模型(DGMs)在各个领域展示了巨大成功，特别是在使用从离线数据训练的模型生成文本、图像和视频方面。类似地，基于数据驱动的决策和机器人控制也需要从离线数据中学习一个生成函数作为策略或政策。在这种情况下，将深度生成模型应用于离线策略学习展现出巨大潜力，许多研究在这个方向上进行了探索。然而，这一领域仍然缺乏全面的评估，因此不同分支的发展相对独立。因此，我们提供了深度生成模型在离线策略学习应用方面的第一次系统性综述。具体而言，我们涵盖了五种主流深度生成模型，包括变分自动编码器、生成对抗网络、归一化流、变压器和扩散模型，以及它们的应用。

    arXiv:2402.13777v1 Announce Type: cross  Abstract: Deep generative models (DGMs) have demonstrated great success across various domains, particularly in generating texts, images, and videos using models trained from offline data. Similarly, data-driven decision-making and robotic control also necessitate learning a generator function from the offline data to serve as the strategy or policy. In this case, applying deep generative models in offline policy learning exhibits great potential, and numerous studies have explored in this direction. However, this field still lacks a comprehensive review and so developments of different branches are relatively independent. Thus, we provide the first systematic review on the applications of deep generative models for offline policy learning. In particular, we cover five mainstream deep generative models, including Variational Auto-Encoders, Generative Adversarial Networks, Normalizing Flows, Transformers, and Diffusion Models, and their applicati
    
[^118]: CriticBench: 将大型语言模型作为评论家进行评估

    CriticBench: Evaluating Large Language Models as Critic

    [https://arxiv.org/abs/2402.13764](https://arxiv.org/abs/2402.13764)

    CriticBench是一个旨在全面和可靠地评估大型语言模型的评论能力的新型基准，展示了评论能力与任务、响应质量和模型规模之间的关系。

    

    论文提出了 CriticBench，这是一个旨在全面和可靠地评估大型语言模型（LLMs）的四个关键评论能力维度（反馈、比较、改进和元反馈）的新型基准。CriticBench包含九个不同的任务，每个任务评估LLMs在不同质量细粒度水平上评论响应的能力。对开源和闭源LLMs进行的广泛评估揭示了评论能力与任务、响应质量和模型规模之间有趣的关系。CriticBench的数据集、资源和评估工具包将在https://github.com/gmftbyGMFTBY/Cri上公开发布。

    arXiv:2402.13764v1 Announce Type: cross  Abstract: Critique ability are crucial in the scalable oversight and self-improvement of Large Language Models (LLMs). While many recent studies explore the critique ability of LLMs to judge and refine flaws in generations, how to comprehensively and reliably measure the critique abilities of LLMs is under-explored. This paper introduces \shortname, a novel benchmark designed to comprehensively and reliably evaluate four key critique ability dimensions of LLMs: feedback, comparison, refinement and meta-feedback. \shortname~encompasses nine diverse tasks, each assessing the LLMs' ability to critique responses at varying levels of quality granularity. Our extensive evaluations of open-source and closed-source LLMs reveal intriguing relationships between the critique ability and tasks, response qualities, and model scales. Datasets, resources and evaluation toolkit for \shortname~will be publicly released at \url{https://github.com/gmftbyGMFTBY/Cri
    
[^119]: DSLR：多样性增强和结构学习用于基于重播的图持续学习

    DSLR: Diversity Enhancement and Structure Learning for Rehearsal-based Graph Continual Learning

    [https://arxiv.org/abs/2402.13711](https://arxiv.org/abs/2402.13711)

    DSLR提出了一种基于覆盖范围的多样性方法，以解决基于重播的图持续学习中回放节点过于集中导致过拟合和灾难性遗忘的问题。

    

    我们研究了基于重播方法中回放缓冲区对图持续学习（GCL）方法的影响。现有的基于重播的GCL方法为每个类别选择最具代表性的节点并将它们存储在重播缓冲区中，以供在训练后续任务时使用。然而，我们发现，仅考虑每个回放节点的类别代表性会使回放节点集中在每个类别的中心周围，可能存在过拟合于位于那些区域的节点的风险，从而加剧灾难性遗忘。此外，由于基于重播方法严重依赖于少数回放节点来保留从先前任务中获得的知识，涉及在模型训练中具有不相关邻居的回放节点可能对模型性能产生显着的负面影响。在本文中，我们提出了一种名为DSLR的GCL模型，具体来说，我们设计了一种基于覆盖范围的多样性（CD）

    arXiv:2402.13711v1 Announce Type: cross  Abstract: We investigate the replay buffer in rehearsal-based approaches for graph continual learning (GCL) methods. Existing rehearsal-based GCL methods select the most representative nodes for each class and store them in a replay buffer for later use in training subsequent tasks. However, we discovered that considering only the class representativeness of each replayed node makes the replayed nodes to be concentrated around the center of each class, incurring a potential risk of overfitting to nodes residing in those regions, which aggravates catastrophic forgetting. Moreover, as the rehearsal-based approach heavily relies on a few replayed nodes to retain knowledge obtained from previous tasks, involving the replayed nodes that have irrelevant neighbors in the model training may have a significant detrimental impact on model performance. In this paper, we propose a GCL model named DSLR, specifically, we devise a coverage-based diversity (CD)
    
[^120]: RefuteBench：评估用于大型语言模型的反驳指令遵循

    RefuteBench: Evaluating Refuting Instruction-Following for Large Language Models

    [https://arxiv.org/abs/2402.13463](https://arxiv.org/abs/2402.13463)

    本文提出了一个名为RefuteBench的基准测试，旨在评估大型语言模型对反驳指令的遵循能力，发现LLMs倾向于固执于其内部知识而无法遵从用户反馈。

    

    大型语言模型（LLMs）的应用范围日益扩大。在实际使用中，用户可能根据模型的输出提供反馈，希望得到一个可以根据他们的反馈完成响应的响应模型。然而，模型能否恰当地响应用户的反驳反馈并始终执行下去尚未得到彻底分析。基于这一问题，本文提出了一个全面的基准测试，RefuteBench，涵盖了诸如问答、机器翻译和电子邮件撰写等任务。评估旨在评估模型是否能够积极接受反驳指令形式的反馈，并是否能够在对话中始终遵循用户需求。我们对众多LLMs进行了评估，并发现LLMs倾向固执，即倾向于其内部知识，经常未能遵守用户反馈。

    arXiv:2402.13463v1 Announce Type: cross  Abstract: The application scope of large language models (LLMs) is increasingly expanding. In practical use, users might provide feedback based on the model's output, hoping for a responsive model that can complete responses according to their feedback. Whether the model can appropriately respond to users' refuting feedback and consistently follow through with execution has not been thoroughly analyzed. In light of this, this paper proposes a comprehensive benchmark, RefuteBench, covering tasks such as question answering, machine translation, and email writing. The evaluation aims to assess whether models can positively accept feedback in form of refuting instructions and whether they can consistently adhere to user demands throughout the conversation. We conduct evaluations on numerous LLMs and find that LLMs are stubborn, i.e. exhibit inclination to their internal knowledge, often failing to comply with user feedback. Additionally, as the leng
    
[^121]: 通过贝叶斯规则归纳在马尔科夫博弈中学习和维持共享的规范系统

    Learning and Sustaining Shared Normative Systems via Bayesian Rule Induction in Markov Games

    [https://arxiv.org/abs/2402.13399](https://arxiv.org/abs/2402.13399)

    通过贝叶斯规则归纳，新引入的智能体可以推断现有人群的规范，使智能体收敛到共享的规范，从而实现规范体系的稳定性

    

    人类社会的一个普遍特征是采用规则和规范体系来服务于合作目的。我们如何构建可以学习并遵守这一体系的智能体，以便它们可以灵活地与人类机构合作？我们假设，通过假定存在一个共享的规范集，大多数其他人会遵守这些规范，同时追求他们个人的愿望，即使他们不知道这些规范的确切内容。通过假设共享规范，新引入的智能体可以从遵守和违反的观察中推断现有人群的规范。此外，即使最初在对规范的信念上存在分歧，一组智能体也可以收敛到共享的规范，从而实现规范体系的稳定性：由于智能体可以使规范变为共识知识，这导致规范得到广泛遵守，从而使新的参与者得以加入

    arXiv:2402.13399v1 Announce Type: new  Abstract: A universal feature of human societies is the adoption of systems of rules and norms in the service of cooperative ends. How can we build learning agents that do the same, so that they may flexibly cooperate with the human institutions they are embedded in? We hypothesize that agents can achieve this by assuming there exists a shared set of norms that most others comply with while pursuing their individual desires, even if they do not know the exact content of those norms. By assuming shared norms, a newly introduced agent can infer the norms of an existing population from observations of compliance and violation. Furthermore, groups of agents can converge to a shared set of norms, even if they initially diverge in their beliefs about what the norms are. This in turn enables the stability of the normative system: since agents can bootstrap common knowledge of the norms, this leads the norms to be widely adhered to, enabling new entrants 
    
[^122]: KetGPT -- 使用Transformer对量子电路进行数据增强

    KetGPT -- Dataset Augmentation of Quantum Circuits using Transformers

    [https://arxiv.org/abs/2402.13352](https://arxiv.org/abs/2402.13352)

    该研究利用Transformer机器学习架构生成“看起来真实”的量子电路，以增强现有的量子电路数据集。

    

    量子算法，表示为量子电路，可用作评估量子系统性能的基准。现有数据集在规模和多样性方面存在限制，在该领域广泛使用，导致研究人员使用随机生成的电路。然而，随机电路并不是代表性基准，因为它们缺乏量子系统制造的真实量子算法的固有属性。这种缺乏“有用”的量子基准构成了推动量子编译器和硬件开发与比较的挑战。本研究旨在通过使用Transformer机器学习架构生成我们称之为“看起来真实”的电路，以增强现有的量子电路数据集。为此，我们引入了KetGPT，一种以OpenQASM语言生成合成电路的工具，其结构是基于推导自量子电路的

    arXiv:2402.13352v1 Announce Type: cross  Abstract: Quantum algorithms, represented as quantum circuits, can be used as benchmarks for assessing the performance of quantum systems. Existing datasets, widely utilized in the field, suffer from limitations in size and versatility, leading researchers to employ randomly generated circuits. Random circuits are, however, not representative benchmarks as they lack the inherent properties of real quantum algorithms for which the quantum systems are manufactured. This shortage of `useful' quantum benchmarks poses a challenge to advancing the development and comparison of quantum compilers and hardware.   This research aims to enhance the existing quantum circuit datasets by generating what we refer to as `realistic-looking' circuits by employing the Transformer machine learning architecture. For this purpose, we introduce KetGPT, a tool that generates synthetic circuits in OpenQASM language, whose structure is based on quantum circuits derived f
    
[^123]: Aria Everyday Activities 数据集

    Aria Everyday Activities Dataset

    [https://arxiv.org/abs/2402.13349](https://arxiv.org/abs/2402.13349)

    AEA数据集是使用Project Aria眼镜记录的第一人称多模态开放数据集，其中包含了多个佩戴者在室内不同位置记录的日常活动序列，为研究提供了3D轨迹、场景点云、眼球注视向量和语音转录等机器感知数据，支持神经场景重建和提示分割。

    

    我们介绍了Aria Everyday Activities (AEA)数据集，这是一个使用Project Aria眼镜记录的第一人称多模态开放数据集。AEA包含了由多名佩戴者在五个地理上多样的室内位置记录的143个日常活动序列。每个记录都包含通过Project Aria眼镜记录的多模态传感器数据。此外，AEA还提供了机器感知数据，包括高频全局对齐的3D轨迹，场景点云，逐帧3D眼球注视向量和时间对齐的语音转录。在本文中，我们展示了通过这一数据集实现的一些示例研究应用，包括神经场景重建和提示分割。AEA是一个可以从projectaria.com下载的开源数据集。我们还提供了如何在Project Aria Tools中使用数据集的开源实现和示例。

    arXiv:2402.13349v1 Announce Type: cross  Abstract: We present Aria Everyday Activities (AEA) Dataset, an egocentric multimodal open dataset recorded using Project Aria glasses. AEA contains 143 daily activity sequences recorded by multiple wearers in five geographically diverse indoor locations. Each of the recording contains multimodal sensor data recorded through the Project Aria glasses. In addition, AEA provides machine perception data including high frequency globally aligned 3D trajectories, scene point cloud, per-frame 3D eye gaze vector and time aligned speech transcription. In this paper, we demonstrate a few exemplar research applications enabled by this dataset, including neural scene reconstruction and prompted segmentation. AEA is an open source dataset that can be downloaded from projectaria.com. We are also providing open-source implementations and examples of how to use the dataset in Project Aria Tools.
    
[^124]: 表格作为图片？探讨LLM在多模态表格数据表示上的优势和局限性

    Tables as Images? Exploring the Strengths and Limitations of LLMs on Multimodal Representations of Tabular Data

    [https://arxiv.org/abs/2402.12424](https://arxiv.org/abs/2402.12424)

    本研究探讨了LLM在解释表格数据方面的有效性，比较了文本和图像表格表示对LLM性能的影响，为在表格相关任务上有效使用LLM提供了见解。

    

    在本文中，我们通过不同的提示策略和数据格式研究了各种LLM在解释表格数据方面的有效性。我们的分析涵盖了六个针对与表格相关任务的基准，如问答和事实核查。我们首次介绍了LLM在基于图像的表格表示上的表现评估。具体地，我们比较了五种基于文本和三种基于图像的表格表示，展示了表示和提示对LLM性能的影响。我们的研究为在表格相关任务上有效使用LLM提供了见解。

    arXiv:2402.12424v1 Announce Type: cross  Abstract: In this paper, we investigate the effectiveness of various LLMs in interpreting tabular data through different prompting strategies and data formats. Our analysis extends across six benchmarks for table-related tasks such as question-answering and fact-checking. We introduce for the first time the assessment of LLMs' performance on image-based table representations. Specifically, we compare five text-based and three image-based table representations, demonstrating the influence of representation and prompting on LLM performance. Our study provides insights into the effective use of LLMs on table-related tasks.
    
[^125]: 张量时间序列的动态多网络挖掘

    Dynamic Multi-Network Mining of Tensor Time Series

    [https://arxiv.org/abs/2402.11773](https://arxiv.org/abs/2402.11773)

    提出了一种新方法，Dynamic Multi-network Mining (DMM)，能够将张量时间序列转换为不同长度的段组，通过稀疏依赖网络提供聚类的可解释性和精确性。

    

    时间序列的子序列聚类是数据挖掘中的一个重要任务，解释结果聚类也至关重要，因为通常我们没有关于数据的先验知识。因此，面对由包含时间戳在内的多种模式组成的大量张量时间序列，我们如何为张量时间序列实现子序列聚类并提供可解释的见解？在本文中，我们提出了一种新方法，即动态多网络挖掘（DMM），它将张量时间序列转换为由l1范数约束的一组各种长度的段组（即聚类）特征化的依赖网络。我们的方法具有以下特性。(a) 可解释性：它使用多个网络对聚类进行特征描述，每个网络是相应非时间模式的稀疏依赖网络，从而提供可见且可解释的关键关系见解。 (b) 精确性：它发现了聚类。。。

    arXiv:2402.11773v1 Announce Type: cross  Abstract: Subsequence clustering of time series is an essential task in data mining, and interpreting the resulting clusters is also crucial since we generally do not have prior knowledge of the data. Thus, given a large collection of tensor time series consisting of multiple modes, including timestamps, how can we achieve subsequence clustering for tensor time series and provide interpretable insights? In this paper, we propose a new method, Dynamic Multi-network Mining (DMM), that converts a tensor time series into a set of segment groups of various lengths (i.e., clusters) characterized by a dependency network constrained with l1-norm. Our method has the following properties. (a) Interpretable: it characterizes the cluster with multiple networks, each of which is a sparse dependency network of a corresponding non-temporal mode, and thus provides visible and interpretable insights into the key relationships. (b) Accurate: it discovers the clus
    
[^126]: ArtPrompt: 基于ASCII艺术的对齐LLMs越狱攻击

    ArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs

    [https://arxiv.org/abs/2402.11753](https://arxiv.org/abs/2402.11753)

    提出了一种新颖的基于ASCII艺术的越狱攻击，以及一个用于评估LLMs在识别非纯语义提示方面能力的基准挑战。五个SOTA LLMs在识别ASCII艺术提示时存在困难。

    

    安全对于大型语言模型（LLMs）的使用至关重要。已经开发了多种技术，如数据过滤和监督微调，以加强LLMs的安全性。然而，当前已知的技术假设用于对齐LLMs安全性的语料库仅由语义进行解释。然而，这一假设在现实应用中不成立，导致LLMs存在严重漏洞。本文提出了一种新颖的基于ASCII艺术的越狱攻击，并引入了一个全面的基准Vision-in-Text Challenge（ViTC）来评估LLMs在识别不能仅通过语义进行解释的提示的能力。我们展示了五个SOTA LLMs（GPT-3.5、GPT-4、Gemini、Claude和Llama2）在识别以ASCII艺术形式提供的提示方面存在困难。基于这一观察，我们开发了

    arXiv:2402.11753v1 Announce Type: cross  Abstract: Safety is critical to the usage of large language models (LLMs). Multiple techniques such as data filtering and supervised fine-tuning have been developed to strengthen LLM safety. However, currently known techniques presume that corpora used for safety alignment of LLMs are solely interpreted by semantics. This assumption, however, does not hold in real-world applications, which leads to severe vulnerabilities in LLMs. For example, users of forums often use ASCII art, a form of text-based art, to convey image information. In this paper, we propose a novel ASCII art-based jailbreak attack and introduce a comprehensive benchmark Vision-in-Text Challenge (ViTC) to evaluate the capabilities of LLMs in recognizing prompts that cannot be solely interpreted by semantics. We show that five SOTA LLMs (GPT-3.5, GPT-4, Gemini, Claude, and Llama2) struggle to recognize prompts provided in the form of ASCII art. Based on this observation, we devel
    
[^127]: 思维的提升：使用大型语言模型进行试错问题解决

    Boosting of Thoughts: Trial-and-Error Problem Solving with Large Language Models

    [https://arxiv.org/abs/2402.11140](https://arxiv.org/abs/2402.11140)

    本文提出了一种名为Boosting of Thoughts（BoT）的自动提示框架，通过迭代地探索和自我评估多个思维树，获得一系列试错推理经验，作为解决复杂问题的新形式的提示。

    

    大型语言模型（LLMs）在各种问题上的推理性能关键取决于思维链提示，其中包括在提示中提供一些思维链示范作为示例。最近的工作（例如Thought Tree）指出了在复杂问题解决的推理步骤选择中，探索和自我评估的重要性。在本文中，我们提出了一种名为Boosting of Thoughts（BoT）的自动提示框架，用于通过迭代地探索和自我评估许多思维树来获得一系列试错推理经验，这将作为解决复杂问题的新形式的提示。BoT从一个简单提示开始，无需示例，迭代地探索和评估大量的推理步骤，更重要的是，利用LLM获得的错误分析来明确修改提示。

    arXiv:2402.11140v1 Announce Type: new  Abstract: The reasoning performance of Large Language Models (LLMs) on a wide range of problems critically relies on chain-of-thought prompting, which involves providing a few chain of thought demonstrations as exemplars in prompts. Recent work, e.g., Tree of Thoughts, has pointed out the importance of exploration and self-evaluation in reasoning step selection for complex problem solving. In this paper, we present Boosting of Thoughts (BoT), an automated prompting framework for problem solving with LLMs by iteratively exploring and self-evaluating many trees of thoughts in order to acquire an ensemble of trial-and-error reasoning experiences, which will serve as a new form of prompting to solve the complex problem. Starting from a simple prompt without requiring examples, BoT iteratively explores and evaluates a large collection of reasoning steps, and more importantly, uses error analysis obtained from the LLM on them to explicitly revise prompt
    
[^128]: 探究价值偏好：LLMs偏向理想状态的偏差

    Exploring Value Biases: How LLMs Deviate Towards the Ideal

    [https://arxiv.org/abs/2402.11005](https://arxiv.org/abs/2402.11005)

    研究发现大型语言模型（LLMs）在给出响应时存在一个价值偏好的机制，倾向于偏向理想状态，这种偏差会对不同应用场景产生重要影响。

    

    大型语言模型（LLMs）被部署在各种应用中，并且它们的响应对社会产生着越来越大的影响。理解LLMs在给出响应时的非故意机制对于解释它们的性能并辨别它们在现实世界应用中的偏差至关重要。这类似于人类研究中，这种无意识的响应被称为抽样。我们研究了LLMs的这种抽样现象，发现LLMs的抽样倾向于偏爱高价值选项。价值偏好对应于从最可能的响应向LLM中代表的理想价值的转变。实际上，即便是通过上下文提示学习到的新实体，这种效果也能够再现。我们表明这种偏差表现在意想不到的地方，并对选择典型实例等相关应用场景产生影响。结果显示，价值偏好在不同分类的LLMs中都很明显。

    arXiv:2402.11005v1 Announce Type: cross  Abstract: Large-Language-Models (LLMs) are deployed in a wide range of applications, and their response has an increasing social impact. Understanding the non-deliberate(ive) mechanism of LLMs in giving responses is essential in explaining their performance and discerning their biases in real-world applications. This is analogous to human studies, where such inadvertent responses are referred to as sampling. We study this sampling of LLMs in light of value bias and show that the sampling of LLMs tends to favour high-value options. Value bias corresponds to this shift of response from the most likely towards an ideal value represented in the LLM. In fact, this effect can be reproduced even with new entities learnt via in-context prompting. We show that this bias manifests in unexpected places and has implications on relevant application scenarios, like choosing exemplars. The results show that value bias is strong in LLMs across different categor
    
[^129]: 加速半异步联邦学习

    Accelerating Semi-Asynchronous Federated Learning

    [https://arxiv.org/abs/2402.10991](https://arxiv.org/abs/2402.10991)

    提出了一种考虑贡献的异步联邦学习方法，动态调整接收到的更新的处理方式，以解决现实情况下同步上传数据可能出现的缓慢和不可靠问题。

    

    联邦学习（FL）是一种分布式机器学习范例，允许客户端在保护隐私的同时在其数据上训练模型。现有的FL算法，如Federated Averaging（FedAvg）及其变种，在许多情况下已经被证明收敛良好。然而，这些方法需要客户端以同步方式将其本地更新上传至服务器，这在现实情况下可能会变得缓慢和不可靠。为了解决这个问题，研究人员开发了异步FL方法，允许客户端继续使用陈旧的全局模型对其本地数据进行训练。然而，大多数这些方法仅仅聚合了所有接收到的更新，而没有考虑其相对贡献，这可能导致收敛速度变慢。在本文中，我们提出了一种考虑贡献的异步FL方法，考虑了接收到的更新的陈旧程度和统计异质性。我们的方法动态调整

    arXiv:2402.10991v1 Announce Type: cross  Abstract: Federated Learning (FL) is a distributed machine learning paradigm that allows clients to train models on their data while preserving their privacy. FL algorithms, such as Federated Averaging (FedAvg) and its variants, have been shown to converge well in many scenarios. However, these methods require clients to upload their local updates to the server in a synchronous manner, which can be slow and unreliable in realistic FL settings. To address this issue, researchers have developed asynchronous FL methods that allow clients to continue training on their local data using a stale global model. However, most of these methods simply aggregate all of the received updates without considering their relative contributions, which can slow down convergence. In this paper, we propose a contribution-aware asynchronous FL method that takes into account the staleness and statistical heterogeneity of the received updates. Our method dynamically adju
    
[^130]: Brant-2：脑信号基础模型

    Brant-2: Foundation Model for Brain Signals

    [https://arxiv.org/abs/2402.10251](https://arxiv.org/abs/2402.10251)

    Brant-2是脑信号领域最大的基础模型，相比于Brant，它不仅对数据变化和建模尺度具有稳健性，还能适用于更广泛范围的脑神经数据。

    

    基础模型受益于在大量未标记数据上进行预训练，并且在少量标记数据的情况下能够在各种应用中表现出色。这种模型在分析脑信号方面特别有效，因为这一领域涵盖了众多应用场景，并且进行大规模注释是成本高昂的。在这项工作中，我们提出了脑信号领域最大的基础模型，Brant-2。与用于颅内神经信号的基础模型Brant相比，Brant-2不仅对数据变化和建模尺度表现出稳健性，而且可以应用于更广泛范围的脑神经数据。通过在大量任务上进行实验，我们展示了Brant-2对脑信号中各种应用场景的适应性。进一步分析揭示了Brant-2的可扩展性，验证了每个组件的有效性，并展示了我们模型保持的能力。

    arXiv:2402.10251v1 Announce Type: cross  Abstract: Foundational models benefit from pre-training on large amounts of unlabeled data and enable strong performance in a wide variety of applications with a small amount of labeled data. Such models can be particularly effective in analyzing brain signals, as this field encompasses numerous application scenarios, and it is costly to perform large-scale annotation. In this work, we present the largest foundation model in brain signals, Brant-2. Compared to Brant, a foundation model designed for intracranial neural signals, Brant-2 not only exhibits robustness towards data variations and modeling scales but also can be applied to a broader range of brain neural data. By experimenting on an extensive range of tasks, we demonstrate that Brant-2 is adaptive to various application scenarios in brain signals. Further analyses reveal the scalability of the Brant-2, validate each component's effectiveness, and showcase our model's ability to maintai
    
[^131]: MM-Point: 多视角信息增强的多模态自监督三维点云理解

    MM-Point: Multi-View Information-Enhanced Multi-Modal Self-Supervised 3D Point Cloud Understanding

    [https://arxiv.org/abs/2402.10002](https://arxiv.org/abs/2402.10002)

    本文提出了一种新颖的自监督点云表示学习方法MM-Point，通过多模态交互和传输实现了3D物体和多个2D视图之间的信息增强。通过精心设计的实验，证明了MM-Point的有效性和优越性。

    

    在感知领域中，将多种传感信息整合起来将2D视图上的视觉信息映射到3D物体上，这有助于在三维环境中进行理解。但是在从不同角度渲染的单个2D视图中，只能提供有限的部分信息。多视角2D信息的丰富性和价值可以为3D物体提供优秀的自监督信号。在本文中，我们提出了一种新颖的自监督点云表示学习方法MM-Point，它受到内模态和外模态相似度目标的驱动。MM-Point的核心在于3D物体和多个2D视图之间的多模态交互和传输。为了更有效地同时执行基于对比学习的2D多视图信息一致性交叉模态目标，我们进一步提出了多层感知机(Multi-MLP)和多层级增强策略。通过精心设计的实验，我们展示了MM-Point的有效性和优越性。

    arXiv:2402.10002v1 Announce Type: cross  Abstract: In perception, multiple sensory information is integrated to map visual information from 2D views onto 3D objects, which is beneficial for understanding in 3D environments. But in terms of a single 2D view rendered from different angles, only limited partial information can be provided.The richness and value of Multi-view 2D information can provide superior self-supervised signals for 3D objects. In this paper, we propose a novel self-supervised point cloud representation learning method, MM-Point, which is driven by intra-modal and inter-modal similarity objectives. The core of MM-Point lies in the Multi-modal interaction and transmission between 3D objects and multiple 2D views at the same time. In order to more effectively simultaneously perform the consistent cross-modal objective of 2D multi-view information based on contrastive learning, we further propose Multi-MLP and Multi-level Augmentation strategies. Through carefully desig
    
[^132]: 说服一位学习代理

    Persuading a Learning Agent

    [https://arxiv.org/abs/2402.09721](https://arxiv.org/abs/2402.09721)

    在一个重复的贝叶斯说服问题中，即使没有承诺能力，委托人可以通过使用上下文无遗憾学习算法来实现与经典无学习模型中具有承诺的委托人的最优效用无限接近的效果；在代理人使用上下文无交换遗憾学习算法的情况下，委托人无法获得比具有承诺的无学习模型中的最优效用更高的效用。

    

    我们研究了一个重复的贝叶斯说服问题（更一般地，任何具有完全信息的广义委托-代理问题），其中委托人没有承诺能力，代理人使用算法来学习如何对委托人的信号做出响应。我们将这个问题简化为一个一次性的广义委托-代理问题，代理人近似地最佳响应。通过这个简化，我们可以证明：如果代理人使用上下文无遗憾学习算法，则委托人可以保证其效用与经典无学习模型中具有承诺的委托人的最优效用之间可以无限接近；如果代理人使用上下文无交换遗憾学习算法，则委托人无法获得比具有承诺的无学习模型中的最优效用更高的效用。委托人在学习模型与非学习模型中可以获得的效用之间的差距是有界的。

    arXiv:2402.09721v1 Announce Type: cross  Abstract: We study a repeated Bayesian persuasion problem (and more generally, any generalized principal-agent problem with complete information) where the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal's signals. We reduce this problem to a one-shot generalized principal-agent problem with an approximately-best-responding agent. This reduction allows us to show that: if the agent uses contextual no-regret learning algorithms, then the principal can guarantee a utility that is arbitrarily close to the principal's optimal utility in the classic non-learning model with commitment; if the agent uses contextual no-swap-regret learning algorithms, then the principal cannot obtain any utility significantly more than the optimal utility in the non-learning model with commitment. The difference between the principal's obtainable utility in the learning model and the non-learning model is bound
    
[^133]: CodeMind:一个用于挑战大型语言模型进行代码推理的框架

    CodeMind: A Framework to Challenge Large Language Models for Code Reasoning

    [https://arxiv.org/abs/2402.09664](https://arxiv.org/abs/2402.09664)

    CodeMind是一个用于挑战大型语言模型进行代码推理的框架，通过评估LLMs的代码推理能力来替代仅仅依靠测试通过来评估，对三种代码推理任务进行评估，结果显示LLMs能够公正地理解控制流结构，并且对于简单程序和复杂程序，它们通常能够推理出输入如何演变为输出。

    

    仅靠测试通过来评估大型语言模型（LLMs）的代码合成能力可能会导致不公正的评估或促进具有数据泄漏的模型，作为一种替代方案，我们介绍了CodeMind，这是一个旨在评估LLMs的代码推理能力的框架。CodeMind目前支持三种代码推理任务：独立执行推理（IER）、依赖执行推理（DER）和规范推理（SR）。前两者评估模型以预测任意代码的执行输出，或者模型能够正确合成的代码。第三个任务评估LLMs实现指定预期行为的程度。我们使用CodeMind对两种不同编程语言中的五个基准下的九个LLMs进行了广泛的评估，结果表明LLMs能够公正地理解控制流结构，并且对于简单程序和复杂程序，它们通常能够推理出输入如何演变为输出。

    arXiv:2402.09664v1 Announce Type: cross  Abstract: Solely relying on test passing to evaluate Large Language Models (LLMs) for code synthesis may result in unfair assessment or promoting models with data leakage. As an alternative, we introduce CodeMind, a framework designed to gauge the code reasoning abilities of LLMs. CodeMind currently supports three code reasoning tasks: Independent Execution Reasoning (IER), Dependent Execution Reasoning (DER), and Specification Reasoning (SR). The first two evaluate models to predict the execution output of an arbitrary code or code the model could correctly synthesize. The third one evaluates the extent to which LLMs implement the specified expected behavior. Our extensive evaluation of nine LLMs across five benchmarks in two different programming languages using CodeMind shows that LLMs fairly understand control flow constructs and, in general, are capable of reasoning how inputs evolve to output, specifically for simple programs and the ones 
    
[^134]: 踩脚调校：通过自助引导扩展LLM的自对齐能力的规模化方法

    Step-On-Feet Tuning: Scaling Self-Alignment of LLMs via Bootstrapping

    [https://arxiv.org/abs/2402.07610](https://arxiv.org/abs/2402.07610)

    本文首次探索了自助引导自对齐对大型语言模型的影响，发现其明显优于单次循环的方法，并通过调整数据训练顺序进一步提升模型性能。

    

    自对齐是一种降低人工注释成本并确保模型能力的有效方法。然而，大多数当前的方法在单次循环中完成数据收集和训练步骤，可能忽视了自对齐模型不断改进的能力。这引发了一个关键问题：如果我们进行多次自助引导自对齐，会增强模型性能还是导致快速退化？本文首次探索了自助引导自对齐对大型语言模型的影响。我们的研究结果表明，通过保证从上下文学习中获得的数据多样性，自助引导自对齐明显优于单次循环的方法。为了进一步发挥自助引导的能力，我们还研究并调整了数据的训练顺序，从而提高了模型的性能。基于这些发现，我们提出了踩脚调校（SOFT）的方法，利用模型的持续增强能力。

    Self-alignment is an effective way to reduce the cost of human annotation while ensuring promising model capability. However, most current methods complete the data collection and training steps in a single round, which may overlook the continuously improving ability of self-aligned models. This gives rise to a key query: What if we do multi-time bootstrapping self-alignment? Does this strategy enhance model performance or lead to rapid degradation? In this paper, our pioneering exploration delves into the impact of bootstrapping self-alignment on large language models. Our findings reveal that bootstrapping self-alignment markedly surpasses the single-round approach, by guaranteeing data diversity from in-context learning. To further exploit the capabilities of bootstrapping, we investigate and adjust the training order of data, which yields improved performance of the model. Drawing on these findings, we propose Step-On-Feet Tuning (SOFT) which leverages model's continuously enhanced
    
[^135]: 知识图谱与多模态学习：综述

    Knowledge Graphs Meet Multi-Modal Learning: A Comprehensive Survey

    [https://arxiv.org/abs/2402.05391](https://arxiv.org/abs/2402.05391)

    知识图谱与多模态学习的综述介绍了KG4MM和MM4KG两个主要方面，包括任务定义、构建进展、评估基准以及关键研究轨迹。

    

    知识图谱在推动各种人工智能应用方面起着关键作用，语义网络社区对多模态维度的探索为创新打开了新的途径。在本综述中，我们仔细审查了300多篇文章，重点关注了两个主要方面的知识图谱感知研究：以知识图谱支持多模态任务的KG驱动多模态（KG4MM）学习，将知识图谱研究扩展到多模态知识图谱（MM4KG）领域。我们从定义知识图谱和多模态知识图谱开始，然后探索它们的构建进展。我们的综述包括两个主要任务类别：KG感知的多模态学习任务，如图像分类和视觉问答，以及内在的多模态知识图谱任务，如多模态知识图谱补全和实体对齐，突出了具体的研究轨迹。对于这些任务中的大部分，我们提供了定义、评估基准，并进一步指出进行相关研究的重要见解。最后，我们讨论了cu

    Knowledge Graphs (KGs) play a pivotal role in advancing various AI applications, with the semantic web community's exploration into multi-modal dimensions unlocking new avenues for innovation. In this survey, we carefully review over 300 articles, focusing on KG-aware research in two principal aspects: KG-driven Multi-Modal (KG4MM) learning, where KGs support multi-modal tasks, and Multi-Modal Knowledge Graph (MM4KG), which extends KG studies into the MMKG realm. We begin by defining KGs and MMKGs, then explore their construction progress. Our review includes two primary task categories: KG-aware multi-modal learning tasks, such as Image Classification and Visual Question Answering, and intrinsic MMKG tasks like Multi-modal Knowledge Graph Completion and Entity Alignment, highlighting specific research trajectories. For most of these tasks, we provide definitions, evaluation benchmarks, and additionally outline essential insights for conducting relevant research. Finally, we discuss cu
    
[^136]: 泄漏、欺骗、重复：封闭源LLMs中的数据污染和评估不端行为

    Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source LLMs

    [https://arxiv.org/abs/2402.03927](https://arxiv.org/abs/2402.03927)

    该论文研究了封闭源LLMs中的数据污染和评估不端行为。通过对255篇论文的分析和OpenAI的数据使用政策考虑，研究人员发现这些模型在第一年发布后存在泄露数据的问题。

    

    自然语言处理（NLP）研究越来越多地关注使用大型语言模型（LLMs），其中一些最受欢迎的模型是完全或部分封闭源的。对于模型细节，特别是训练数据的缺乏访问权限，使研究人员反复对数据污染提出了担忧。虽然已经进行了一些尝试来解决这个问题，但仅限于个别案例和试错方法。此外，他们忽视了“间接”数据泄漏的问题，即模型通过使用用户提供的数据进行迭代改进。本研究在OpenAI的GPT-3.5和GPT-4使用上进行了首次系统分析，这些是当今最广泛使用的LLMs，并考虑了OpenAI的数据使用政策，详细记录了模型发布后一年内泄露给这些模型的数据量。我们报告了这些模型在主要数据污染方面。

    Natural Language Processing (NLP) research is increasingly focusing on the use of Large Language Models (LLMs), with some of the most popular ones being either fully or partially closed-source. The lack of access to model details, especially regarding training data, has repeatedly raised concerns about data contamination among researchers. Several attempts have been made to address this issue, but they are limited to anecdotal evidence and trial and error. Additionally, they overlook the problem of \emph{indirect} data leaking, where models are iteratively improved by using data coming from users. In this work, we conduct the first systematic analysis of work using OpenAI's GPT-3.5 and GPT-4, the most prominently used LLMs today, in the context of data contamination. By analysing 255 papers and considering OpenAI's data usage policy, we extensively document the amount of data leaked to these models during the first year after the model's release. We report that these models have been g
    
[^137]: 大型语言模型作为MOOCs评分者

    Large Language Models As MOOCs Graders

    [https://arxiv.org/abs/2402.03776](https://arxiv.org/abs/2402.03776)

    该研究探索了利用大型语言模型（LLMs）代替MOOCs中同伴评分的可行性，旨在解决大规模在线开放课程中评估学生写作任务的问题。

    

    大规模在线开放课程（MOOCs）为拥有电脑和互联网访问权限的全球任何人提供免费教育的机会。尽管如此，这些课程的大规模注册意味着一位教师几乎不可能评估每个学生的写作任务。因此，同伴评分通常是首选方法，通常由简单明了的评分标准指导。然而，同伴评分在可靠度和有效性方面常常存在问题。在这项研究中，我们利用18个不同的场景，探索利用大型语言模型（LLMs）替代MOOCs中的同伴评分的可行性。具体而言，我们关注两种最先进的LLMs：GPT-4和GPT-3.5，并涵盖三门不同的课程：入门天文学，天体生物学以及天文学的历史与哲学。为了训练LLMs，我们使用了基于零-shot连续思考（Zero-shot-CoT）提示技术的变种的三个不同提示：结合Zero-shot-CoT的提示。

    Massive open online courses (MOOCs) unlock the doors to free education for anyone around the globe with access to a computer and the internet. Despite this democratization of learning, the massive enrollment in these courses means it is almost impossible for one instructor to assess every student's writing assignment. As a result, peer grading, often guided by a straightforward rubric, is the method of choice. While convenient, peer grading often falls short in terms of reliability and validity. In this study, using 18 distinct settings, we explore the feasibility of leveraging large language models (LLMs) to replace peer grading in MOOCs. Specifically, we focus on two state-of-the-art LLMs: GPT-4 and GPT-3.5, across three distinct courses: Introductory Astronomy, Astrobiology, and the History and Philosophy of Astronomy. To instruct LLMs, we use three different prompts based on a variant of the zero-shot chain-of-thought (Zero-shot-CoT) prompting technique: Zero-shot-CoT combined with
    
[^138]: 人类与机器：重新思考语言模型在蕴含验证中的应用

    Minds versus Machines: Rethinking Entailment Verification with Language Models

    [https://arxiv.org/abs/2402.03686](https://arxiv.org/abs/2402.03686)

    本文通过研究人类和大型语言模型在推理判断中的共性和差异，发现大型语言模型在复杂推理中具有优势，而人类在简单推理中表现出色。基于这些发现，引入了一个优化的Flan-T5模型，用于蕴含验证。

    

    人类在文本理解中进行大量的推理以理解论述。本文旨在了解人类和最先进的大型语言模型（LLM）在推理判断中的共性和差异。通过综合策划的蕴含验证基准测试，我们评估了人类和LLM在各种推理类别中的表现。我们的基准测试包含了来自三个类别（NLI、上下文QA和解释）的数据集，包括多句前提和不同的知识类型，从而评估了复杂推理情况下的推理能力。值得注意的是，我们的发现显示LLM在跨扩展上下文的多跳推理中具有优势，而人类在需要简单演绎推理的任务中表现出色。利用这些见解，我们介绍了一个经过精细调整的Flan-T5模型，其性能超过了GPT-3.5，并与GPT-4媲美，提供了一个强大的开源解决方案供蕴含验证使用。作为一个实际的应用

    Humans make numerous inferences in text comprehension to understand discourse. This paper aims to understand the commonalities and disparities in the inference judgments between humans and state-of-the-art Large Language Models (LLMs). Leveraging a comprehensively curated entailment verification benchmark, we evaluate both human and LLM performance across various reasoning categories. Our benchmark includes datasets from three categories (NLI, contextual QA, and rationales) that include multi-sentence premises and different knowledge types, thereby evaluating the inference capabilities in complex reasoning instances. Notably, our findings reveal LLMs' superiority in multi-hop reasoning across extended contexts, while humans excel in tasks necessitating simple deductive reasoning. Leveraging these insights, we introduce a fine-tuned Flan-T5 model that outperforms GPT-3.5 and rivals with GPT-4, offering a robust open-source solution for entailment verification. As a practical application
    
[^139]: PuzzleBench：LLMs能否解决困难的一阶组合推理问题？

    PuzzleBench: Can LLMs Solve Challenging First-Order Combinatorial Reasoning Problems?

    [https://arxiv.org/abs/2402.02611](https://arxiv.org/abs/2402.02611)

    本研究通过PuzzleBench数据集探索了LLMs解决困难的一阶组合推理问题的能力，并提出了Puzzle-LM方法，该方法将LLMs与符号求解器和程序解释器相结合，使其能够有效地推理这类问题。

    

    最近的研究探索了使用LLMs进行推理任务，重点是相对简单的问题，如逻辑问答。在我们的工作中，我们希望解决更复杂的问题，显著扩展这些模型的功能。特别是，我们探讨LLMs是否能够解决困难的一阶组合推理问题，一个例子是流行的数独谜题。这些问题有一个由自然语言描述的基础一阶结构，并且可以实例化为不同大小的实例。此外，这些问题在计算上是密集型的，需要多个推理步骤才能达到解决方案。我们提出了PuzzleBench，一个包含31个这样具有挑战性的谜题的数据集。我们观察到，即使在符号求解器的帮助下，LLMs在我们的基准测试中表现得相当糟糕。作为回应，我们提出了一种新的方法，Puzzle-LM，它将LLMs与符号求解器和程序解释器相结合，使它们能够推理这类问题。

    Recent works have explored the use of LLMs for reasoning tasks focussing on relatively simple problems, such as logical question answering. In our work, we wish to tackle more complicated problems, significantly expanding the capabilities of these models. Particularly, we explore whether LLMs can solve challenging first-order combinatorial reasoning problems, an example being the popular puzzle Sudoku. These problems have an underlying first-order structure described by a general description in natural language and can be instantiated to instances of varying sizes. Moreover these problems are computationally intensive requiring several reasoning steps to reach the solution. We present PuzzleBench a dataset of 31 such challenging puzzles. We observe that LLMs even when aided by symbolic solvers perform rather poorly on our benchmark. In response we propose a new approach, Puzzle-LM which combines LLMs with both symbolic solvers and program interpreters enabling them to reason about such
    
[^140]: DiffStitch: 使用基于扩散的轨迹拼接提升离线强化学习

    DiffStitch: Boosting Offline Reinforcement Learning with Diffusion-based Trajectory Stitching

    [https://arxiv.org/abs/2402.02439](https://arxiv.org/abs/2402.02439)

    DiffStitch是一种使用基于扩散的轨迹拼接提升离线强化学习的方法。它通过有效地连接低奖励轨迹和高奖励轨迹，形成全局最优轨迹，以提高离线强化学习算法的性能。

    

    在离线强化学习中，学习策略的性能高度依赖于离线数据集的质量。然而，在许多情况下，离线数据集只包含了非常有限的最佳轨迹，这给离线强化学习算法带来了挑战，因为智能体必须获得到达高奖励区域的能力。为了解决这个问题，我们引入了基于扩散的轨迹拼接（DiffStitch），这是一个新颖的基于扩散的数据增强流水线，它可以系统地生成轨迹之间的拼接转换。DiffStitch可以有效地连接低奖励轨迹和高奖励轨迹，形成全局最优轨迹，以解决离线强化学习算法所面临的挑战。在D4RL数据集上进行的实证实验表明，DiffStitch在各种强化学习方法中都具有有效性。值得注意的是，DiffStitch在一步方法（IQL）、模仿学习方法（TD3+BC）和轨迹方法（PPO）的性能方面都有显著的改进。

    In offline reinforcement learning (RL), the performance of the learned policy highly depends on the quality of offline datasets. However, in many cases, the offline dataset contains very limited optimal trajectories, which poses a challenge for offline RL algorithms as agents must acquire the ability to transit to high-reward regions. To address this issue, we introduce Diffusion-based Trajectory Stitching (DiffStitch), a novel diffusion-based data augmentation pipeline that systematically generates stitching transitions between trajectories. DiffStitch effectively connects low-reward trajectories with high-reward trajectories, forming globally optimal trajectories to address the challenges faced by offline RL algorithms. Empirical experiments conducted on D4RL datasets demonstrate the effectiveness of DiffStitch across RL methodologies. Notably, DiffStitch demonstrates substantial enhancements in the performance of one-step methods (IQL), imitation learning methods (TD3+BC), and traje
    
[^141]: 自我想象：利用自我想象进行多模型自然推理

    Self-Imagine: Effective Unimodal Reasoning with Multimodal Models using Self-Imagination

    [https://arxiv.org/abs/2401.08025](https://arxiv.org/abs/2401.08025)

    本文提出了Self-Imagine方法，通过利用一种Vision-Language模型生成问题的结构化表示并将其渲染为图像，再使用相同的模型回答问题，从而在数学任务和通用推理任务中提高了模型性能。

    

    Vision-Language模型（VLMs）的潜力在处理复杂基于文本问题时往往未被充分利用，尤其是当这些问题能够从视觉表达中获益时。本文提出了Self-Imagine，与人类通过创建问题的视觉图并推断解决步骤的能力相 resonating。我们利用单一的Vision-Language模型（VLM）使用HTML生成问题的结构化表示，然后将HTML渲染为图像，并最终使用相同的VLM根据问题和图像回答问题。我们的方法不需要任何额外的训练数据或训练。我们使用最先进的（LLAVA-1.5和GEMINI PRO）VLMs在三个数学任务和九个通用推理任务上评估了我们的方法。我们的方法提升了LLAVA-1.5和GEMINI PRO在所有数学任务上的性能。

    arXiv:2401.08025v2 Announce Type: replace  Abstract: The potential of Vision-Language Models (VLMs) often remains underutilized in handling complex text-based problems, particularly when these problems could benefit from visual representation. Resonating with humans' ability to solve complex text-based problems by (1) creating a visual diagram from the problem and (2) deducing what steps they need to take to solve it, we propose Self-Imagine. We leverage a single Vision-Language Model (VLM) to generate a structured representation of the question using HTML, then render the HTML as an image, and finally use the same VLM to answer the question using both the question and the image. Our approach does not require any additional training data or training. We evaluate our approach on three mathematics tasks and nine general-purpose reasoning tasks using state-of-the-art (LLAVA-1.5 and GEMINI PRO) VLMs. Our approach boosts the performance of LLAVA-1.5 and GEMINI PRO on all math tasks (on aver
    
[^142]: 基于LLM、强化学习和语义奖励的代码漏洞修复

    LLM-Powered Code Vulnerability Repair with Reinforcement Learning and Semantic Reward

    [https://arxiv.org/abs/2401.03374](https://arxiv.org/abs/2401.03374)

    引入了一种由大型语言模型驱动的多功能代码漏洞分析系统，旨在通过强化学习和语义奖励修复因AI驱动的自动化工具而产生的不安全代码。

    

    在软件开发中，对功能的主要强调往往超越了安全性问题，这一趋势随着GitHub Copilot等AI驱动的自动化工具的兴起而越来越明显。这些工具显着提高了开发人员在功能代码开发中的效率。然而，仍然存在一个显著的问题，即这些工具也负责创建不安全的代码，主要是因为在公开可用的具有漏洞代码的存储库上进行了预训练。此外，开发人员被称为“链条中最薄弱的一环”，因为他们对代码安全性几乎没有什么了解。尽管现有解决方案为有漏洞的代码提供了一个合理的解决方案，但它们必须充分描述和教育开发人员有关代码安全性，以确保安全问题不再重演。因此，我们引入了一个多功能的代码漏洞分析系统\texttt{SecRepair}，它由一个大型语言模型CodeGen2辅助。

    arXiv:2401.03374v2 Announce Type: replace-cross  Abstract: In software development, the predominant emphasis on functionality often supersedes security concerns, a trend gaining momentum with AI-driven automation tools like GitHub Copilot. These tools significantly improve developers' efficiency in functional code development. Nevertheless, it remains a notable concern that such tools are also responsible for creating insecure code, predominantly because of pre-training on publicly available repositories with vulnerable code. Moreover, developers are called the "weakest link in the chain" since they have very minimal knowledge of code security. Although existing solutions provide a reasonable solution to vulnerable code, they must adequately describe and educate the developers on code security to ensure that the security issues are not repeated. Therefore we introduce a multipurpose code vulnerability analysis system \texttt{SecRepair}, powered by a large language model, CodeGen2 assis
    
[^143]: 工业物联网智能赋能智能制造：一篇文献综述

    Industrial Internet of Things Intelligence Empowering Smart Manufacturing: A Literature Review

    [https://arxiv.org/abs/2312.16174](https://arxiv.org/abs/2312.16174)

    本文提供了对工业物联网智能的全面概述，弥补了现有调查偏见，为制造业的转型提供了指引。

    

    竞争激烈的商业环境和日益个性化的定制需求推动着制造业的数字化转型和升级。工业物联网智能能够为制造价值链的各个方面提供创新高效的解决方案，为制造业的转型提供指引。现在是提供工业物联网智能系统性视野的时候了。然而，现有调查往往集中在工业物联网智能的特定领域，导致研究者和读者在理解工业物联网智能时存在偏见，即认为在一个方向上的研究对工业物联网智能的发展最重要，而忽略了其他方向的贡献。因此，本文提供了工业物联网智能的全面概述。我们首先对制造业转型的必然性进行了深入分析

    arXiv:2312.16174v2 Announce Type: replace  Abstract: The fiercely competitive business environment and increasingly personalized customization needs are driving the digital transformation and upgrading of the manufacturing industry. IIoT intelligence, which can provide innovative and efficient solutions for various aspects of the manufacturing value chain, illuminates the path of transformation for the manufacturing industry. It's time to provide a systematic vision of IIoT intelligence. However, existing surveys often focus on specific areas of IIoT intelligence, leading researchers and readers to have biases in their understanding of IIoT intelligence, that is, believing that research in one direction is the most important for the development of IIoT intelligence, while ignoring contributions from other directions. Therefore, this paper provides a comprehensive overview of IIoT intelligence. We first conduct an in-depth analysis of the inevitability of manufacturing transformation an
    
[^144]: LLM代理表现出社会行为吗？

    Do LLM Agents Exhibit Social Behavior?

    [https://arxiv.org/abs/2312.15198](https://arxiv.org/abs/2312.15198)

    研究探讨了LLM代理在与人类和其他代理互动时展示的社会行为，包括社会学习、社会偏好和合作行为，并开发了一个框架来评估它们与人类实验对象的互动。

    

    大型语言模型（LLMs）的进展正在扩大它们在学术研究和实际应用中的效用。最近的社会科学研究探讨了使用这些“黑匣子”LLM代理来模拟复杂社会系统并潜在地替代人类实验对象的可能性。我们的研究深入探讨了这一新兴领域，调查了LLMs在与人类和其他代理进行互动时展示社会学习、社会偏好和合作行为（间接互惠）等关键社会交互原则的程度。我们为我们的研究制定了一个框架，其中涉及将涉及人类实验对象的经典实验调整为使用LLM代理。这种方法涉及一步一步的推理，模拟人类认知过程和零样本学习，以评估LLMs的天生偏好。我们对LLM代理行为的分析包括主要效应和次要效应。

    arXiv:2312.15198v2 Announce Type: replace  Abstract: The advances of Large Language Models (LLMs) are expanding their utility in both academic research and practical applications. Recent social science research has explored the use of these ``black-box'' LLM agents for simulating complex social systems and potentially substituting human subjects in experiments. Our study delves into this emerging domain, investigating the extent to which LLMs exhibit key social interaction principles, such as social learning, social preference, and cooperative behavior (indirect reciprocity), in their interactions with humans and other agents. We develop a framework for our study, wherein classical laboratory experiments involving human subjects are adapted to use LLM agents. This approach involves step-by-step reasoning that mirrors human cognitive processes and zero-shot learning to assess the innate preferences of LLMs. Our analysis of LLM agents' behavior includes both the primary effects and an in
    
[^145]: MaxK-GNN: 探索加速图神经网络训练的理论速度极限

    MaxK-GNN: Towards Theoretical Speed Limits for Accelerating Graph Neural Networks Training

    [https://arxiv.org/abs/2312.08656](https://arxiv.org/abs/2312.08656)

    MaxK-GNN是一种先进的高性能GPU训练系统，通过MaxK非线性和理论分析，实现了图神经网络训练的垂直优化。

    

    在深度神经网络训练加速方面，GPU已经成为主流平台。 GPU在GNN上面临着诸多挑战，如工作负载不平衡和内存访问不规则，导致硬件利用不充分。现有解决方案例如PyG、DGL与cuSPARSE，以及GNNAdvisor框架部分解决了这些挑战，但内存流量仍然很显著。 我们认为，只有通过算法与系统创新的垂直优化才能实现显著的性能提升，而不是将加速优化视为“事后思考”（即（i）给定GNN算法，设计加速器，或（ii）给定硬件，主要优化GNN算法）。 本文介绍了MaxK-GNN，一种集成算法与系统创新的先进高性能GPU训练系统。 （i）我们引入了MaxK非线性并提供了MaxK非线性的理论分析，

    arXiv:2312.08656v3 Announce Type: replace-cross  Abstract: In the acceleration of deep neural network training, the GPU has become the mainstream platform. GPUs face substantial challenges on GNNs, such as workload imbalance and memory access irregularities, leading to underutilized hardware. Existing solutions such as PyG, DGL with cuSPARSE, and GNNAdvisor frameworks partially address these challenges but memory traffic is still significant.   We argue that drastic performance improvements can only be achieved by the vertical optimization of algorithm and system innovations, rather than treating the speedup optimization as an "after-thought" (i.e., (i) given a GNN algorithm, designing an accelerator, or (ii) given hardware, mainly optimizing the GNN algorithm). In this paper, we present MaxK-GNN, an advanced high-performance GPU training system integrating algorithm and system innovation. (i) We introduce the MaxK nonlinearity and provide a theoretical analysis of MaxK nonlinearity as
    
[^146]: 缓解开放词汇描述幻觉

    Mitigating Open-Vocabulary Caption Hallucinations

    [https://arxiv.org/abs/2312.03631](https://arxiv.org/abs/2312.03631)

    提出了在开放词汇设置中解决图像字幕幻觉问题的框架，并提出了一种新方法MOCHa来缓解幻觉

    

    近年来，图像条件的文本生成取得了快速进展，但图像字幕仍然存在幻觉的基本问题，即生成与给定图像无法推断的虚假细节。现有方法在图像字幕中大多使用封闭词汇对象列表来缓解或评估幻觉，忽略了实践中发生的大多数幻觉类型。为此，我们提出了一个框架，以应对开放词汇设置中图像字幕中的幻觉，包括量化它们的存在并优化以减轻这种幻觉。我们的OpenCHAIR基准利用生成基础模型来评估开放词汇描述幻觉，在多样性和准确性方面都超过了流行的CHAIR基准。为了在序列级别上缓解开放词汇的幻觉，我们提出了MOCHa，一种利用进展的方法

    arXiv:2312.03631v2 Announce Type: replace-cross  Abstract: While recent years have seen rapid progress in image-conditioned text generation, image captioning still suffers from the fundamental issue of hallucinations, namely, the generation of spurious details that cannot be inferred from the given image. Existing methods largely use closed-vocabulary object lists to mitigate or evaluate hallucinations in image captioning, ignoring most types of hallucinations that occur in practice. To this end, we propose a framework for addressing hallucinations in image captioning in the open-vocabulary setting, including quantifying their presence and optimizing to mitigate such hallucinations. Our OpenCHAIR benchmark leverages generative foundation models to evaluate open-vocabulary caption hallucinations, surpassing the popular CHAIR benchmark in both diversity and accuracy. To mitigate open-vocabulary hallucinations at the sequence level, we propose MOCHa, an approach harnessing advancements in
    
[^147]: EduGym: 用于强化学习教育的环境和笔记本套件

    EduGym: An Environment and Notebook Suite for Reinforcement Learning Education

    [https://arxiv.org/abs/2311.10590](https://arxiv.org/abs/2311.10590)

    EduGym是一套用于强化学习教育的环境和笔记本套件，旨在解决学生在转换理论和实践中遇到的困难。

    

    由于强化学习的经验成功，越来越多的学生在学习这个课题。然而，根据我们的实际教学经验，我们发现学生在进入这个领域（本科生、硕士生和早期博士生）时常常遇到困难。一方面，教科书和（在线）讲座提供了基础知识，但学生发现很难在方程式和代码之间进行转换。另一方面，公共代码库提供了实际的例子，但实现的算法往往复杂，并且基础测试环境同时包含多个强化学习挑战。尽管这在研究角度上是现实的，但它经常阻碍了教育概念的理解。为了解决这个问题，我们推出了EduGym，这是一组专门针对教育的强化学习环境和相关交互式笔记本。

    arXiv:2311.10590v2 Announce Type: replace-cross  Abstract: Due to the empirical success of reinforcement learning, an increasing number of students study the subject. However, from our practical teaching experience, we see students entering the field (bachelor, master and early PhD) often struggle. On the one hand, textbooks and (online) lectures provide the fundamentals, but students find it hard to translate between equations and code. On the other hand, public codebases do provide practical examples, but the implemented algorithms tend to be complex, and the underlying test environments contain multiple reinforcement learning challenges at once. Although this is realistic from a research perspective, it often hinders educational conceptual understanding. To solve this issue we introduce EduGym, a set of educational reinforcement learning environments and associated interactive notebooks tailored for education. Each EduGym environment is specifically designed to illustrate a certain 
    
[^148]: Monkey: 大型多模态模型中图像分辨率和文本标签的重要性

    Monkey: Image Resolution and Text Label Are Important Things for Large Multi-modal Models

    [https://arxiv.org/abs/2311.06607](https://arxiv.org/abs/2311.06607)

    Monkey通过提高图像分辨率和采用多级描述生成方法来增强大型多模态模型(LMMs)的能力，从而实现更详细的视觉捕捉和更有效的学习。

    

    大型多模态模型(LMMs)在视觉语言任务中表现出了潜力，但在高分辨率输入和详细场景理解方面表现不佳。为了解决这些挑战，我们引入了Monkey来增强LMM的能力。首先，Monkey通过将输入图像划分为统一的补丁来处理图像，每个补丁的大小与原来训练良好的视觉编码器使用的大小(例如448x448)相匹配。配备了每个补丁的适配器，Monkey可以处理高达1344x896像素的更高分辨率，实现对复杂视觉信息的详细捕捉。其次，它采用多级描述生成方法，丰富了场景-对象关联的上下文。这种两部分策略确保了从生成数据中更有效的学习：更高的分辨率允许对视觉进行更详细的捕捉，从而增强了全面描述的效果。广泛的实验证明...

    arXiv:2311.06607v3 Announce Type: replace-cross  Abstract: Large Multimodal Models (LMMs) have shown promise in vision-language tasks but struggle with high-resolution input and detailed scene understanding. Addressing these challenges, we introduce Monkey to enhance LMM capabilities. Firstly, Monkey processes input images by dividing them into uniform patches, each matching the size (e.g., 448x448) used in the original training of the well-trained vision encoder. Equipped with individual adapter for each patch, Monkey can handle higher resolutions up to 1344x896 pixels, enabling the detailed capture of complex visual information. Secondly, it employs a multi-level description generation method, enriching the context for scene-object associations. This two-part strategy ensures more effective learning from generated data: the higher resolution allows for a more detailed capture of visuals, which in turn enhances the effectiveness of comprehensive descriptions. Extensive ablative result
    
[^149]: 一个可微分的大脑模拟器：架起大脑模拟与脑启发计算之间的桥梁

    A differentiable brain simulator bridging brain simulation and brain-inspired computing

    [https://arxiv.org/abs/2311.05106](https://arxiv.org/abs/2311.05106)

    BrainPy是一个可微分的大脑模拟器，旨在通过引入JAX和XLA的功能来架设大脑模拟与脑启发计算之间的桥梁。

    

    大脑模拟建立动力学模型以模仿大脑的结构和功能，而大脑启发计算（BIC）通过从大脑的结构和功能中学习来发展智能系统。这两个领域相互交织，应共享一个通用的编程框架以促进彼此的发展。然而，由于传统的大脑模拟器在训练方面缺乏可微分性，而现有的深度学习（DL）框架无法捕捉大脑动力学的生物物理现实性和复杂性，因此这两者之间无法实现目标。本文介绍了BrainPy，一个使用JAX和XLA开发的可微分大脑模拟器，旨在架起大脑模拟与BIC之间的鸿沟。BrainPy在JAX强大的AI框架功能基础上扩展，引入了完整的功能，用于灵活、高效和可扩展的大脑模拟。

    arXiv:2311.05106v2 Announce Type: replace-cross  Abstract: Brain simulation builds dynamical models to mimic the structure and functions of the brain, while brain-inspired computing (BIC) develops intelligent systems by learning from the structure and functions of the brain. The two fields are intertwined and should share a common programming framework to facilitate each other's development. However, none of the existing software in the fields can achieve this goal, because traditional brain simulators lack differentiability for training, while existing deep learning (DL) frameworks fail to capture the biophysical realism and complexity of brain dynamics. In this paper, we introduce BrainPy, a differentiable brain simulator developed using JAX and XLA, with the aim of bridging the gap between brain simulation and BIC. BrainPy expands upon the functionalities of JAX, a powerful AI framework, by introducing complete capabilities for flexible, efficient, and scalable brain simulation. It 
    
[^150]: 通过可控机器遗忘打破隐私、效用、效率三难题

    Breaking the Trilemma of Privacy, Utility, Efficiency via Controllable Machine Unlearning

    [https://arxiv.org/abs/2310.18574](https://arxiv.org/abs/2310.18574)

    设计了一种名为Controllable Machine Unlearning (ConMU)的新框架，旨在平衡隐私、模型效用和运行效率之间的权衡。

    

    机器遗忘（MU）算法由于对数据隐私法规的必要遵从而变得越来越关键。MU的主要目标是在不需要从头重新训练模型的情况下消除特定数据样本对给定模型的影响。现有方法主要关注于最大化用户隐私保护。然而，每个现实世界基于网络的应用程序都有不同程度的隐私法规。探索隐私、模型效用和运行效率之间的权衡全谱对于实际的遗忘场景至关重要。而且，由于固有的复杂交互作用，设计具有对上述权衡的简单控制的MU算法是可取但具有挑战性。为了解决这些挑战，我们提出了Controllable Machine Unlearning (ConMU)，这是一个旨在促进MU校准的新颖框架。ConMU框架包含三个集成

    arXiv:2310.18574v2 Announce Type: replace-cross  Abstract: Machine Unlearning (MU) algorithms have become increasingly critical due to the imperative adherence to data privacy regulations. The primary objective of MU is to erase the influence of specific data samples on a given model without the need to retrain it from scratch. Accordingly, existing methods focus on maximizing user privacy protection. However, there are different degrees of privacy regulations for each real-world web-based application. Exploring the full spectrum of trade-offs between privacy, model utility, and runtime efficiency is critical for practical unlearning scenarios. Furthermore, designing the MU algorithm with simple control of the aforementioned trade-off is desirable but challenging due to the inherent complex interaction. To address the challenges, we present Controllable Machine Unlearning (ConMU), a novel framework designed to facilitate the calibration of MU. The ConMU framework contains three integra
    
[^151]: MindfulDiary：利用大型语言模型支持精神病患者的日记记录

    MindfulDiary: Harnessing Large Language Model to Support Psychiatric Patients' Journaling

    [https://arxiv.org/abs/2310.05231](https://arxiv.org/abs/2310.05231)

    MindfulDiary利用大型语言模型帮助精神病患者通过对话记录日常体验，并在临床环境中取得积极效果

    

    在心理健康领域，大型语言模型（LLMs）提供了新的机会，然而其复杂性和低可控性引发了关于其在临床环境中适用性的质疑。我们介绍了MindfulDiary，一个移动日记应用，结合LLM帮助精神病患者通过对话记录日常体验。与心理健康专业人士（MHPs）合作设计，MindfulDiary采取基于状态的方法，安全地遵守专家指南，同时进行自由形式的对话。通过涉及28名重性抑郁障碍患者和5名精神科医生的为期四周的实地研究，我们发现MindfulDiary支持患者持续丰富其日常记录，并帮助精神科医生通过理解他们的想法和日常背景更好地同情他们的患者。根据这些发现，我们讨论了其影响。

    arXiv:2310.05231v2 Announce Type: replace-cross  Abstract: In the mental health domain, Large Language Models (LLMs) offer promising new opportunities, though their inherent complexity and low controllability have raised questions about their suitability in clinical settings. We present MindfulDiary, a mobile journaling app incorporating an LLM to help psychiatric patients document daily experiences through conversation. Designed in collaboration with mental health professionals (MHPs), MindfulDiary takes a state-based approach to safely comply with the experts' guidelines while carrying on free-form conversations. Through a four-week field study involving 28 patients with major depressive disorder and five psychiatrists, we found that MindfulDiary supported patients in consistently enriching their daily records and helped psychiatrists better empathize with their patients through an understanding of their thoughts and daily contexts. Drawing on these findings, we discuss the implicati
    
[^152]: 用医学教科书增强黑盒LLMs进行临床问题回答

    Augmenting Black-box LLMs with Medical Textbooks for Clinical Question Answering

    [https://arxiv.org/abs/2309.02233](https://arxiv.org/abs/2309.02233)

    该研究提出了一种名为LLMs增强医学教科书（LLM-AMT）的系统，通过插入式模块将权威医学教科书集成到LLMs的框架中，显著提高了LLMs在专业领域的能力。

    

    大规模语言模型（LLMs）如ChatGPT已经展示出根据人类指令生成响应的印象能力。然而，由于它们缺乏特定、深入的知识，它们在医学领域的应用可能具有挑战性。在这项研究中，我们提出了一种名为LLMs增强医学教科书（LLM-AMT）的系统，旨在增强LLMs在专业领域的能力。LLM-AMT通过插入式模块将权威医学教科书集成到LLMs的框架中。这些模块包括一个查询增强器、一个混合教科书检索器和一个知识自我完善。它们共同整合权威医学知识。此外，一个LLMs阅读器有助于上下文理解。我们在三个医学问答任务上的实验结果表明，LLMAMT显著提高了响应质量，准确率提高了11.6%到16.6%。值得注意的是，以GPT-4-Turbo为基础模型

    arXiv:2309.02233v2 Announce Type: replace-cross  Abstract: Large-scale language models (LLMs) like ChatGPT have demonstrated impressive abilities in generating responses based on human instructions. However, their use in the medical field can be challenging due to their lack of specific, in-depth knowledge. In this study, we present a system called LLMs Augmented with Medical Textbooks (LLM-AMT) designed to enhance the proficiency of LLMs in specialized domains. LLM-AMT integrates authoritative medical textbooks into the LLMs' framework using plug-and-play modules. These modules include a Query Augmenter, a Hybrid Textbook Retriever, and a Knowledge Self-Refiner. Together, they incorporate authoritative medical knowledge. Additionally, an LLM Reader aids in contextual understanding. Our experimental results on three medical QA tasks demonstrate that LLMAMT significantly improves response quality, with accuracy gains ranging from 11.6% to 16.6%. Notably, with GPT-4-Turbo as the base mod
    
[^153]: LLMs用于知识图谱构建和推理：最新功能与未来机遇

    LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities

    [https://arxiv.org/abs/2305.13168](https://arxiv.org/abs/2305.13168)

    本研究全面评估了LLMs在知识图谱构建和推理领域的性能，发现GPT-4更适合作为推理助手，并在某些情况下超越了精调模型。

    

    本文对大规模语言模型（LLMs）在知识图谱（KG）构建和推理中的数量化和质化评估进行了详尽的研究。我们在八个不同的数据集上进行了实验，重点关注涵盖实体和关系提取、事件提取、链接预测和问答四个典型任务，从而全面探索了LLMs在构建和推理领域的表现。经验性研究发现，以GPT-4为代表的LLMs更适合作为推理助手，而不是少样本信息提取器。具体而言，虽然GPT-4在与KG构建相关的任务中表现出色，但在推理任务中表现更出色，在某些情况下超越了精调模型。此外，我们的调查还扩展到LLMs在信息提取方面的潜在泛化能力，提出了虚拟知识提取的构想。

    arXiv:2305.13168v2 Announce Type: replace-cross  Abstract: This paper presents an exhaustive quantitative and qualitative evaluation of Large Language Models (LLMs) for Knowledge Graph (KG) construction and reasoning. We engage in experiments across eight diverse datasets, focusing on four representative tasks encompassing entity and relation extraction, event extraction, link prediction, and question-answering, thereby thoroughly exploring LLMs' performance in the domain of construction and inference. Empirically, our findings suggest that LLMs, represented by GPT-4, are more suited as inference assistants rather than few-shot information extractors. Specifically, while GPT-4 exhibits good performance in tasks related to KG construction, it excels further in reasoning tasks, surpassing fine-tuned models in certain cases. Moreover, our investigation extends to the potential generalization ability of LLMs for information extraction, leading to the proposition of a Virtual Knowledge Extr
    
[^154]: 每个人都可以成为毕加索？探讨人类与人工智能绘画的神话的计算框架

    Everyone Can Be Picasso? A Computational Framework into the Myth of Human versus AI Painting

    [https://arxiv.org/abs/2304.07999](https://arxiv.org/abs/2304.07999)

    人类与人工智能绘画在潜在空间和部分审美特征上存在差异，但在其他方面较少差异。

    

    AI技术的最新进展，特别是AI生成内容（AIGC），使每个人都能够通过简单的文本描述轻松生成美丽的绘画。由于人工智能绘画的惊人质量，人们普遍质疑人类与人工智能绘画之间是否仍然存在差异，以及人类艺术家是否会被人工智能代替。为了回答这些问题，我们开发了一个计算框架，将神经潜在空间和审美特征与视觉分析相结合，以探讨人类与人工智能绘画之间的差异。首先，通过对人类与人工智能绘画收藏进行分类比较，我们发现在潜在空间和一些审美特征（如笔触和清晰度）方面，人工智能作品与人类作品显示出分布差异，而在颜色和构图等其他审美特征方面差异较小。其次，通过对毕加索的个体艺术家分析，我们展示了人类

    arXiv:2304.07999v2 Announce Type: replace-cross  Abstract: The recent advances of AI technology, particularly in AI-Generated Content (AIGC), have enabled everyone to easily generate beautiful paintings with simple text description. With the stunning quality of AI paintings, it is widely questioned whether there still exists difference between human and AI paintings and whether human artists will be replaced by AI. To answer these questions, we develop a computational framework combining neural latent space and aesthetics features with visual analytics to investigate the difference between human and AI paintings. First, with categorical comparison of human and AI painting collections, we find that AI artworks show distributional difference from human artworks in both latent space and some aesthetic features like strokes and sharpness, while in other aesthetic features like color and composition there is less difference. Second, with individual artist analysis of Picasso, we show human 
    
[^155]: 基于阈值的自动标注的优势与局限性

    Promises and Pitfalls of Threshold-based Auto-labeling

    [https://arxiv.org/abs/2211.12620](https://arxiv.org/abs/2211.12620)

    TBAL系统可以通过验证数据自动标注未标注数据，减少手动标注的依赖；研究结果展示了即使模型表现不佳也可以准确自动标记数据，并揭示了TBAL系统的潜在缺陷

    

    创建大规模高质量标记数据集是监督机器学习工作流程中的一个主要瓶颈。阈值自动标注（TBAL）通过使用人类获取的验证数据来寻找一个置信阈值，高于该阈值的数据将由机器标记，从而减少了对手动注释的依赖。TBAL正逐渐成为实践中被广泛采用的解决方案。鉴于所得数据的长期有效性和多样化使用，理解这种自动标注系统获取的数据何时可以被依赖是至关重要的。这是第一项分析TBAL系统并推导需要保证机器标记数据质量的人工标记验证数据量样本复杂性界限的工作。我们的结果提供了两个关键见解。首先，表面上糟糕的模型可以自动、准确地标记合理数量的未标记数据。其次，TBAL系统的一个隐藏的缺点是潜在地

    arXiv:2211.12620v2 Announce Type: replace-cross  Abstract: Creating large-scale high-quality labeled datasets is a major bottleneck in supervised machine learning workflows. Threshold-based auto-labeling (TBAL), where validation data obtained from humans is used to find a confidence threshold above which the data is machine-labeled, reduces reliance on manual annotation. TBAL is emerging as a widely-used solution in practice. Given the long shelf-life and diverse usage of the resulting datasets, understanding when the data obtained by such auto-labeling systems can be relied on is crucial. This is the first work to analyze TBAL systems and derive sample complexity bounds on the amount of human-labeled validation data required for guaranteeing the quality of machine-labeled data. Our results provide two crucial insights. First, reasonable chunks of unlabeled data can be automatically and accurately labeled by seemingly bad models. Second, a hidden downside of TBAL systems is potentially
    
[^156]: 使用von Mises-Fisher混合模型减轻面部识别中的性别偏见

    Mitigating Gender Bias in Face Recognition Using the von Mises-Fisher Mixture Model

    [https://arxiv.org/abs/2210.13664](https://arxiv.org/abs/2210.13664)

    通过引入新的度量标准BFAR和BFRR，并通过后处理方法减轻面部识别中的性别偏见，以实现公平的系统性能。

    

    尽管深度学习算法在各种日常应用中表现出较高的性能和可靠性，但许多调查显示许多模型存在偏见，歧视特定人群子组（如性别、种族），这促使从业者开发具有一致/可比性能的公平系统。在本研究中，我们研究了深度面部识别网络的性别偏见。为了衡量这种偏见，我们引入了两个新的度量标准，BFAR和BFRR，更好地反映了面部识别系统固有的部署需求。受几何考虑的启发，我们通过一种新的后处理方法来减轻性别偏见，其通过将预训练模型的深度嵌入转换为对受歧视亚组有更多表示能力。它包括训练一个浅层神经网络，通过最小化一个Fa

    arXiv:2210.13664v2 Announce Type: replace-cross  Abstract: In spite of the high performance and reliability of deep learning algorithms in a wide range of everyday applications, many investigations tend to show that a lot of models exhibit biases, discriminating against specific subgroups of the population (e.g. gender, ethnicity). This urges the practitioner to develop fair systems with a uniform/comparable performance across sensitive groups. In this work, we investigate the gender bias of deep Face Recognition networks. In order to measure this bias, we introduce two new metrics, $\mathrm{BFAR}$ and $\mathrm{BFRR}$, that better reflect the inherent deployment needs of Face Recognition systems. Motivated by geometric considerations, we mitigate gender bias through a new post-processing methodology which transforms the deep embeddings of a pre-trained model to give more representation power to discriminated subgroups. It consists in training a shallow neural network by minimizing a Fa
    
[^157]: 一个随机宇宙中的生命：重审Sciama的论证

    Life in a random universe: Sciama's argument reconsidered

    [https://arxiv.org/abs/2109.10241](https://arxiv.org/abs/2109.10241)

    一个随机宇宙下的生命概率问题被重新思考，可能会导致基本常数看似被精确调整以实现生命发生的高概率。

    

    在高维空间中的随机抽样已成功应用于诸如核共振、神经网络和黑洞蒸发等各种现象。在此，我们重新审视了英国物理学家丹尼斯·Sciama的一个优雅论证，该论证表明，如果我们的宇宙是随机的，那么生命几乎不可能存在。在合理的假设下，我们展示了一个随机宇宙可以伪装成“智能设计”，基本常数似乎被精确调整以获得生命发生的最高概率。对于我们的宇宙，这种机制可能只需要大约一打目前未知的基本常数。我们推测我们所发现的机制可能具有更广泛的应用。

    arXiv:2109.10241v4 Announce Type: replace-cross  Abstract: Random sampling in high dimensions has successfully been applied to phenomena as diverse as nuclear resonances, neural networks and black hole evaporation. Here we revisit an elegant argument by the British physicist Dennis Sciama, which demonstrated that were our universe random, it would almost certainly have a negligible chance for life. Under plausible assumptions, we show that a random universe can masquerade as `intelligently designed,' with the fundamental constants instead appearing to be fined tuned to be achieve the highest probability for life to occur. For our universe, this mechanism may only require there to be around a dozen currently unknown fundamental constants. We speculate on broader applications for the mechanism we uncover.
    
[^158]: 使用逻辑规则学习四足动物运动策略

    Learning Quadruped Locomotion Policies using Logical Rules

    [https://arxiv.org/abs/2107.10969](https://arxiv.org/abs/2107.10969)

    该论文提出了一种使用逻辑规则来学习四足动物运动策略的方法，通过奖励机器实现高层步态规范，支持在执行时调整步态频率，并且能够有效避免繁琐的运动先验。

    

    四足动物能展示多样化的运动步态。尽管在机器人上展示了这些步态，但目前的方法依赖于运动先验、动力学模型或其他形式的大量手动工作。本文提出了一种基于奖励机器实现高层步态规范的方法，名为RM-based Locomotion Learning（RMLL），支持在执行时调整步态频率。通过使用每个步态的少量逻辑规则（例如，前脚和后脚交替移动），实现了步态规范，无需费力的运动先验。在仿真实验中，实验结果显示了学到的步态的多样性（包括两种新颖的）。

    arXiv:2107.10969v3 Announce Type: replace-cross  Abstract: Quadruped animals are capable of exhibiting a diverse range of locomotion gaits. While progress has been made in demonstrating such gaits on robots, current methods rely on motion priors, dynamics models, or other forms of extensive manual efforts. People can use natural language to describe dance moves. Could one use a formal language to specify quadruped gaits? To this end, we aim to enable easy gait specification and efficient policy learning. Leveraging Reward Machines~(RMs) for high-level gait specification over foot contacts, our approach is called RM-based Locomotion Learning~(RMLL), and supports adjusting gait frequency at execution time. Gait specification is enabled through the use of a few logical rules per gait (e.g., alternate between moving front feet and back feet) and does not require labor-intensive motion priors. Experimental results in simulation highlight the diversity of learned gaits (including two novel g
    
[^159]: 对抗机器学习：贝叶斯视角

    Adversarial Machine Learning: Bayesian Perspectives

    [https://arxiv.org/abs/2003.03546](https://arxiv.org/abs/2003.03546)

    AML旨在保护机器学习系统免受安全威胁，贝叶斯视角为防御提供了新的好处

    

    对抗机器学习(AML)正在成为一个重要的领域，旨在保护机器学习(ML)系统免受安全威胁：在某些情况下，可能存在敌对方积极操纵输入数据以欺骗学习系统。 这创造了一类新的安全漏洞，ML系统可能会面临，并引入了一种新的被称为敌对稳健性的可信操作所必需的性质。 大部分AML工作都建立在对抗学习系统和准备操纵输入数据的对手之间冲突的博弈论建模之上。 这假设每个代理都了解对手的兴趣和不确定性判断，从而促进基于Nash均衡的推理。 然而，在AML典型的安全方案中，这种共同知识假设并不现实。 在回顾了这种博弈论方法之后，我们讨论了贝叶斯视角在防御中提供的好处

    arXiv:2003.03546v2 Announce Type: replace  Abstract: Adversarial Machine Learning (AML) is emerging as a major field aimed at protecting machine learning (ML) systems against security threats: in certain scenarios there may be adversaries that actively manipulate input data to fool learning systems. This creates a new class of security vulnerabilities that ML systems may face, and a new desirable property called adversarial robustness essential to trust operations based on ML outputs. Most work in AML is built upon a game-theoretic modelling of the conflict between a learning system and an adversary, ready to manipulate input data. This assumes that each agent knows their opponent's interests and uncertainty judgments, facilitating inferences based on Nash equilibria. However, such common knowledge assumption is not realistic in the security scenarios typical of AML. After reviewing such game-theoretic approaches, we discuss the benefits that Bayesian perspectives provide when defendin
    
[^160]: 优化大规模语言模型用于漏洞检测

    Finetuning Large Language Models for Vulnerability Detection. (arXiv:2401.17010v1 [cs.CR])

    [http://arxiv.org/abs/2401.17010](http://arxiv.org/abs/2401.17010)

    本文优化了大规模语言模型用于源代码中的漏洞检测任务，通过微调最先进的代码语言模型WizardCoder并改进其训练过程和策略，实现了对漏洞数据集的分类性能的提升。

    

    本文介绍了对大规模语言模型进行微调，并将其用于源代码中的漏洞检测的结果。我们利用最先进的语言模型StarCoder的改进版本WizardCoder，并通过进一步微调将其适应于漏洞检测任务。为了加速训练，我们修改了WizardCoder的训练过程，并探究了最佳的训练策略。针对负样本远多于正样本的不平衡数据集，我们还尝试了不同的技术来提高分类性能。微调后的WizardCoder模型在平衡和不平衡的漏洞数据集上在ROC AUC和F1度量上实现了改进，证明了将预训练的语言模型用于源代码中的漏洞检测的有效性。主要贡献包括对最先进的代码语言模型WizardCoder进行微调，提高其训练速度而不影响性能，并对训练过程和策略进行了优化。

    This paper presents the results of finetuning large language models (LLMs) for the task of detecting vulnerabilities in source code. We leverage WizardCoder, a recent improvement of the state-of-the-art LLM StarCoder, and adapt it for vulnerability detection through further finetuning. To accelerate training, we modify WizardCoder's training procedure, also we investigate optimal training regimes. For the imbalanced dataset with many more negative examples than positive, we also explore different techniques to improve classification performance. The finetuned WizardCoder model achieves improvement in ROC AUC and F1 measures on balanced and imbalanced vulnerability datasets over CodeBERT-like model, demonstrating the effectiveness of adapting pretrained LLMs for vulnerability detection in source code. The key contributions are finetuning the state-of-the-art code LLM, WizardCoder, increasing its training speed without the performance harm, optimizing the training procedure and regimes, 
    
[^161]: TAT-LLM: 一种针对表格和文本数据的专用语言模型用于离散推理

    TAT-LLM: A Specialized Language Model for Discrete Reasoning over Tabular and Textual Data. (arXiv:2401.13223v1 [cs.CL])

    [http://arxiv.org/abs/2401.13223](http://arxiv.org/abs/2401.13223)

    TAT-LLM是一种专门用于离散推理的语言模型，针对混合表格和文本数据上的问答任务。该模型通过分步流水线的方式，包括提取器、推理器和执行器，利用LLMs的强大能力来解决问题。而为了应对成本、延迟和数据安全风险等挑战，我们开发了TAT-LLM，一个专门针对此任务的较小LLM。

    

    在这项工作中，我们解决了在混合表格和文本数据上进行问答的问题，这在Web上非常常见（如SEC文件），通常需要离散推理能力。最近，像GPT-4这样的大型语言模型展示了强大的多步骤推理能力。我们考虑利用LLMs的强大能力来解决我们的任务。我们提出了面向表格和文本问答的分步流水线的抽象，包括提取器、推理器和执行器三个关键步骤，并首先设计了一份指令来实例化该流水线并验证GPT-4优于所有现有方法。然而，利用像GPT-4这样的在线LLM存在成本、延迟和数据安全风险等各种挑战，这促使我们专门针对此任务开发较小的LLM。我们通过对现有专家标注数据集自动生成的训练数据对LLaMA 2进行微调，开发了TAT-LLM语言模型。

    In this work, we address question answering (QA) over a hybrid of tabular and textual data that are very common content on the Web (e.g. SEC filings), where discrete reasoning capabilities are often required. Recently, large language models (LLMs) like GPT-4 have demonstrated strong multi-step reasoning capabilities. We then consider harnessing the amazing power of LLMs to solve our task. We abstract a Step-wise Pipeline for tabular and textual QA, which consists of three key steps, including Extractor, Reasoner and Executor, and initially design an instruction to instantiate the pipeline and validate that GPT-4 outperforms all existing methods. However, utilizing an online LLM like GPT-4 holds various challenges in terms of cost, latency, and data security risk, which motivates us to specialize smaller LLMs in this task. We develop a TAT-LLM language model by fine-tuning LLaMA 2 with the training data generated automatically from existing expert-annotated datasets following the Step-w
    
[^162]: 量子启发的机器学习用于分子对接

    Quantum-Inspired Machine Learning for Molecular Docking. (arXiv:2401.12999v1 [physics.chem-ph])

    [http://arxiv.org/abs/2401.12999](http://arxiv.org/abs/2401.12999)

    量子启发的机器学习方法在分子对接中取得了显著的改进，通过结合量子特性和深度学习在编码的分子空间中学习的梯度，提高了盲目对接的成功率。

    

    分子对接是构建基于结构的药物设计的重要工具，可以加快药物开发的效率。蛋白质和小分子之间的复杂和动态结合过程需要在广泛的空间范围内进行搜索和采样。传统的对接方法通过搜索可能的结合位点和构象来实现，计算复杂度高，在盲目对接中效果不佳。受到这一点的启发，我们通过将量子启发算法与通过深度学习在编码的分子空间中学习的梯度相结合，实现了在盲目对接中的改进。数值仿真结果表明，我们的方法在传统的对接算法和基于深度学习的算法上表现出了超过10%的提升。与目前最先进的基于深度学习的对接算法DiffDock相比，Top-1（RMSD<2）的成功率从33%提高到35%。

    Molecular docking is an important tool for structure-based drug design, accelerating the efficiency of drug development. Complex and dynamic binding processes between proteins and small molecules require searching and sampling over a wide spatial range. Traditional docking by searching for possible binding sites and conformations is computationally complex and results poorly under blind docking. Quantum-inspired algorithms combining quantum properties and annealing show great advantages in solving combinatorial optimization problems. Inspired by this, we achieve an improved in blind docking by using quantum-inspired combined with gradients learned by deep learning in the encoded molecular space. Numerical simulation shows that our method outperforms traditional docking algorithms and deep learning-based algorithms over 10\%. Compared to the current state-of-the-art deep learning-based docking algorithm DiffDock, the success rate of Top-1 (RMSD<2) achieves an improvement from 33\% to 35
    
[^163]: 从理解到应用：大规模语言模型可解释性研究综述

    From Understanding to Utilization: A Survey on Explainability for Large Language Models. (arXiv:2401.12874v1 [cs.CL])

    [http://arxiv.org/abs/2401.12874](http://arxiv.org/abs/2401.12874)

    本综述论文研究了大规模语言模型(LLMs)可解释性的新兴领域，强调了在LLMs中增强可解释性的必要性，同时解决了广大公众对其信任和技术界对这些模型更深理解的需求。该综述对现有的可解释性方法进行分类，并讨论了它们在提高模型透明度和可靠性方面的应用，旨在弥合理论理解和实际应用之间的差距。

    

    本综述论文深入研究了大规模语言模型(LLMs)可解释性的新兴领域，这是自然语言处理中一个关键且具有挑战性的方面。LLMs在各种应用中发挥着关键作用，但其“黑盒”性质引发了对透明性和伦理使用的担忧。本文强调了在LLMs中增强可解释性的必要性，同时解决了广大公众对其信任和技术界对这些模型更深理解的需求。我们集中在预训练的基于Transformer的LLMs，如LLaMA，其规模和复杂性使其面临独特的可解释性挑战。我们的综述对现有的可解释性方法进行分类，并讨论了它们在提高模型透明度和可靠性方面的应用。我们还讨论了代表性的评价方法，强调了它们的优势和局限性。本综述的目标是弥合理论理解和实际应用之间的差距，提供从技术角度总结可解释性方法的全面视角。

    This survey paper delves into the burgeoning field of explainability for Large Language Models (LLMs), a critical yet challenging aspect of natural language processing. With LLMs playing a pivotal role in various applications, their "black-box" nature raises concerns about transparency and ethical use. This paper emphasizes the necessity for enhanced explainability in LLMs, addressing both the general public's trust and the technical community's need for a deeper understanding of these models. We concentrate on pre-trained Transformer-based LLMs, such as LLaMA, which present unique interpretability challenges due to their scale and complexity. Our review categorizes existing explainability methods and discusses their application in improving model transparency and reliability. We also discuss representative evaluation methods, highlighting their strengths and limitations. The goal of this survey is to bridge the gap between theoretical understanding and practical application, offering 
    
[^164]: 通过人的反馈改善机器翻译: 将质量估计作为奖励模型的探索

    Improving Machine Translation with Human Feedback: An Exploration of Quality Estimation as a Reward Model. (arXiv:2401.12873v1 [cs.CL])

    [http://arxiv.org/abs/2401.12873](http://arxiv.org/abs/2401.12873)

    本研究探索了利用质量估计作为奖励模型来预测人类偏好以改善机器翻译的潜力。我们发现基于质量估计的反馈训练存在过度优化问题，采用启发式规则来检测错误翻译并对质量估计模型进行惩罚以解决该问题。

    

    不充分建模人类偏好导致奖励模型在利用人的反馈提高翻译质量方面成为一个主要障碍。幸运的是，质量估计(QE)在过去两年中无需参考文献就能准确预测给定翻译的质量。在这项工作中，我们探讨了将QE模型作为奖励模型(基于QE的奖励模型)来预测人的偏好以进行反馈训练的潜力。我们首先发现了在基于QE的反馈训练中的过度优化问题，表现为奖励的增加而翻译质量下降。我们研究了这个问题，并认为QE模型的脆弱性可能导致错误翻译的高奖励，从而导致过度优化和错误传播。为解决这个问题，我们采用了一种简单而有效的方法，使用启发式规则检测错误翻译，并为QE模型添加了一个惩罚项。

    Insufficient modeling of human preferences within the reward model is a major obstacle for leveraging human feedback to improve translation quality. Fortunately, quality estimation (QE), which predicts the quality of a given translation without reference, has achieved impressive alignment with human evaluations in the last two years. In this work, we investigate the potential of employing the QE model as the reward model (the QE-based reward model) to predict human preferences for feedback training. We first identify the overoptimization problem during QE-based feedback training, manifested as an increase in reward while translation quality declines. We examine the problem and argue that the vulnerability of the QE model might lead to high rewards for incorrect translations, resulting in overoptimization and error propagation. To address the problem, we adopt a simple yet effective method that uses heuristic rules to detect the incorrect translations and assigns a penalty term to the Q
    
[^165]: E^2-LLM: 大规模语言模型的高效和极长扩展

    E^2-LLM: Efficient and Extreme Length Extension of Large Language Models. (arXiv:2401.06951v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.06951](http://arxiv.org/abs/2401.06951)

    E^2-LLM是一种高效和极长扩展方法，通过仅需一次训练过程和不收集长上下文数据的方式，在大规模语言模型中实现了显著减少的计算成本。基于RoPE位置嵌入，E^2-LLM只需要较短的训练数据长度，支持不同的评估上下文窗口。

    

    通常，使用长上下文大小训练LLM会消耗大量的计算资源和GPU资源，需要长时间的训练。现有的长上下文扩展方法通常需要额外的训练过程来支持相应的长上下文窗口，需要长上下文训练数据（例如32k），并且假定有高昂的GPU训练成本。为了解决上述问题，我们提出了一种名为E^2-LLM的高效和极长扩展方法，只需要一次训练过程，大大减少了计算成本，也不需要收集长上下文数据。具体而言，我们的E^2-LLM的训练数据只需要很短的长度（例如4k），大大降低了调整成本。其次，在短训练上下文窗口上的训练过程只执行一次，我们可以支持不同的评估上下文窗口。第三，在E^2-LLM中，我们基于RoPE位置嵌入。

    Typically, training LLMs with long context sizes is computationally expensive, requiring extensive training hours and GPU resources. Existing long-context extension methods usually need additional training procedures to support corresponding long-context windows, where the long-context training data (e.g., 32k) is needed, and high GPU training costs are assumed. To address the aforementioned issues, we propose an Efficient and Extreme length extension method for Large Language Models, called E 2 -LLM, with only one training procedure and dramatically reduced computation cost, which also removes the need to collect long-context data. Concretely, first, the training data of our E 2 -LLM only requires a short length (e.g., 4k), which reduces the tuning cost greatly. Second, the training procedure on the short training context window is performed only once time, and we can support different evaluation context windows at inference. Third, in E 2 - LLM, based on RoPE position embeddings, we 
    
[^166]: SH2: 自我突出式犹豫帮助您更准确解码。

    SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully. (arXiv:2401.05930v1 [cs.CL])

    [http://arxiv.org/abs/2401.05930](http://arxiv.org/abs/2401.05930)

    自我突出式犹豫（SH2）是一种推理时的方法，通过选择预测概率较低的标记，并强调它们的差异，从而帮助语言模型更准确地解码。

    

    大型语言模型(LLMs)在文本生成方面表现出色。然而，LLMs仍然存在幻觉问题。在本研究中，我们提出了一种推理时方法，即自我突出式犹豫(SH2)，以帮助LLMs更准确地解码。SH2基于信息理论中一个简单的事实，即对于LLMs而言，预测概率较低的标记往往更具信息量。我们的分析表明，LLMs给予较低概率的标记更有可能与事实信息（如名词、专有名词和形容词）密切相关。因此，我们提出通过选择概率最低的标记并将其连接到原始上下文中来“突出”事实信息，从而迫使模型在生成之前多次阅读和犹豫这些标记。在解码过程中，我们还采用对比解码的方式来强调由犹豫带来的输出概率的差异。

    Large language models (LLMs) demonstrate great performance in text generation. However, LLMs are still suffering from hallucinations. In this work, we propose an inference-time method, Self-Highlighted Hesitation (SH2), to help LLMs decode more truthfully. SH2 is based on a simple fact rooted in information theory that for an LLM, the tokens predicted with lower probabilities are prone to be more informative than others. Our analysis shows that the tokens assigned with lower probabilities by an LLM are more likely to be closely related to factual information, such as nouns, proper nouns, and adjectives. Therefore, we propose to ''highlight'' the factual information by selecting the tokens with the lowest probabilities and concatenating them to the original context, thus forcing the model to repeatedly read and hesitate on these tokens before generation. During decoding, we also adopt contrastive decoding to emphasize the difference in the output probabilities brought by the hesitation.
    
[^167]: TREC iKAT 2023: 交互式知识辅助任务概述

    TREC iKAT 2023: The Interactive Knowledge Assistance Track Overview. (arXiv:2401.01330v1 [cs.IR])

    [http://arxiv.org/abs/2401.01330](http://arxiv.org/abs/2401.01330)

    TREC iKAT 2023是一个交互式的知识辅助任务，旨在开发适应用户交互和上下文的会话搜索代理。该任务还强调决策搜索任务，用户通过筛选数据和信息来进行决策和执行动作。

    

    会话式信息查询是一个关键的研究领域，之前的工作也有很大的贡献。TREC交互式知识辅助任务（iKAT）建立在TREC会话辅助任务（CAsT）的基础上。然而，iKAT着重于创建和研究可以根据用户之前的交互和当前情境自适应响应的会话搜索代理。挑战在于使会话搜索代理能够将个性化的上下文信息融入到相应中，以高效地引导用户获取相关信息。iKAT还着重于决策搜索任务，即用户通过数据和信息筛选来衡量各种选择，以达到结论或执行动作。这些任务在日常信息搜索决策中普遍存在，无论是旅游、健康还是购物等，通常涉及一组高级信息操作符，其中查询或问题可能会

    Conversational Information Seeking stands as a pivotal research area with significant contributions from previous works. The TREC Interactive Knowledge Assistance Track (iKAT) builds on the foundational work of the TREC Conversational Assistance Track (CAsT). However, iKAT distinctively emphasizes the creation and research of conversational search agents that adapt responses based on user's prior interactions and present context. The challenge lies in enabling Conversational Search Agents (CSA) to incorporate this personalized context to efficiency and effectively guide users through the relevant information to them. iKAT also emphasizes decisional search tasks, where users sift through data and information to weigh up options in order to reach a conclusion or perform an action. These tasks, prevalent in everyday information-seeking decisions -- be it related to travel, health, or shopping -- often revolve around a subset of high-level information operators where queries or questions a
    
[^168]: AesFA:一种美学特征感知的任意神经风格转换方法

    AesFA: An Aesthetic Feature-Aware Arbitrary Neural Style Transfer. (arXiv:2312.05928v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.05928](http://arxiv.org/abs/2312.05928)

    AesFA是一种轻量级但有效的神经风格转换方法，通过频率分解图像，以更好地解开美学风格，排除了预训练模型。引入了对比损失以提高风格化质量。实验证明，AesFA在stylization quality方面优于其他方法，并实现了快速转换。

    

    神经风格转换（NST）在近年来取得了显著的发展。然而，尽管其快速进展和改进，现有的NST方法要么在有效转移风格时很难保留美学信息，要么在特征解缠和计算效率方面由于使用预训练模型而存在高计算成本和低效率。本文提出了一种轻量级但有效的模型，AesFA -- 美学特征感知的NST。其主要思想是通过频率对图像进行分解，以更好地从参考图像中解开美学风格，同时以端到端的方式训练整个模型，完全取消了推断时的预训练模型。为了提高网络提取更加独特的表示和进一步增强风格化质量的能力，本文引入了一种新的美学特征：对比损失。广泛的实验和消融研究表明，这种方法不仅在风格化质量方面优于最新的NST方法，而且实现了快速的转换。

    Neural style transfer (NST) has evolved significantly in recent years. Yet, despite its rapid progress and advancement, existing NST methods either struggle to transfer aesthetic information from a style effectively or suffer from high computational costs and inefficiencies in feature disentanglement due to using pre-trained models. This work proposes a lightweight but effective model, AesFA -- Aesthetic Feature-Aware NST. The primary idea is to decompose the image via its frequencies to better disentangle aesthetic styles from the reference image while training the entire model in an end-to-end manner to exclude pre-trained models at inference completely. To improve the network's ability to extract more distinct representations and further enhance the stylization quality, this work introduces a new aesthetic feature: contrastive loss. Extensive experiments and ablations show the approach not only outperforms recent NST methods in terms of stylization quality, but it also achieves fast
    
[^169]: 在Transformer中定位跨任务序列继续电路

    Locating Cross-Task Sequence Continuation Circuits in Transformers. (arXiv:2311.04131v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.04131](http://arxiv.org/abs/2311.04131)

    通过分析和比较Transformer模型中类似的序列继续任务的电路，研究发现共享的计算结构可以提高模型的行为预测能力、错误识别能力和编辑过程的安全性。

    

    虽然Transformer模型在语言任务上展现出强大的能力，但其复杂的架构使其难以解释。最近的研究旨在将Transformer模型还原为可读的电路表示，用于实现算法功能。我们通过分析和比较类似的序列继续任务的电路来扩展这项研究，其中包括数字、数字词和月份的递增序列。通过应用电路分析技术，我们确定了负责检测序列成员和预测序列中下一个成员的关键子电路。我们的分析揭示了语义相关序列依赖于具有类似作用的共享电路子图。总体而言，记录共享的计算结构能够更好地预测模型行为，识别错误，并进行更安全的编辑过程。这种对Transformer的机械理解是构建更健壮、调试和编辑更安全的模型的关键一步。

    While transformer models exhibit strong capabilities on linguistic tasks, their complex architectures make them difficult to interpret. Recent work has aimed to reverse engineer transformer models into human-readable representations called circuits that implement algorithmic functions. We extend this research by analyzing and comparing circuits for similar sequence continuation tasks, which include increasing sequences of digits, number words, and months. Through the application of circuit analysis techniques, we identify key sub-circuits responsible for detecting sequence members and for predicting the next member in a sequence. Our analysis reveals that semantically related sequences rely on shared circuit subgraphs with analogous roles. Overall, documenting shared computational structures enables better prediction of model behaviors, identification of errors, and safer editing procedures. This mechanistic understanding of transformers is a critical step towards building more robust,
    
[^170]: 基于文本条件的图像聚类

    Image Clustering Conditioned on Text Criteria. (arXiv:2310.18297v1 [cs.CV])

    [http://arxiv.org/abs/2310.18297](http://arxiv.org/abs/2310.18297)

    本文提出了一种新的图像聚类方法，基于用户指定的文本标准，通过利用现代视觉语言模型和大型语言模型，实现了对聚类结果的直接控制。该方法需要较少的人工干预，并能在各种标准下有效地聚类图像，表现优于基准方法。

    

    传统的聚类方法不能直接满足用户对聚类结果的控制需求，而且聚类结果可能与用户心中相关的标准不一致。本文提出了一种新的图像聚类方法，基于用户指定的文本标准，利用现代视觉语言模型和大型语言模型。我们称之为基于文本条件的图像聚类（IC|TC），它代表了一种不同的图像聚类范式。IC|TC需要较少的人工干预，并使用户能够有较大的控制权。我们的实验结果表明，IC|TC能够有效地按照各种标准（如人类行为、物理位置或人的心情）对图像进行聚类，而且表现优于基准方法。

    Classical clustering methods do not provide users with direct control of the clustering results, and the clustering results may not be consistent with the relevant criterion that a user has in mind. In this work, we present a new methodology for performing image clustering based on user-specified text criteria by leveraging modern vision-language models and large language models. We call our method Image Clustering Conditioned on Text Criteria (IC$|$TC), and it represents a different paradigm of image clustering. IC$|$TC requires a minimal and practical degree of human intervention and grants the user significant control over the clustering results in return. Our experiments show that IC$|$TC can effectively cluster images with various criteria, such as human action, physical location, or the person's mood, while significantly outperforming baselines.
    
[^171]: 在上下文中的学生建模中使用大型语言模型：从一次性观察中合成视觉编程中学生的行为

    Large Language Models for In-Context Student Modeling: Synthesizing Student's Behavior in Visual Programming from One-Shot Observation. (arXiv:2310.10690v1 [cs.CL])

    [http://arxiv.org/abs/2310.10690](http://arxiv.org/abs/2310.10690)

    本研究探索在开放式学习环境中使用大型语言模型进行上下文学生建模，提出了一个新的框架LLM-SS，通过合成学生在不同任务上的尝试，为学生建模提供更准确的预测和教学策略。

    

    学生建模对于许多教育技术来说至关重要，因为它可以预测未来的学习结果和有针对性的教学策略。然而，开放式学习环境会带来挑战，因为学生表现出多样化的行为且缺乏明确定义的学习技能集。为了应对这些挑战，我们探索在开放式学习环境中应用大型语言模型（LLMs）进行上下文学生建模。我们引入了一个新颖的框架LLM-SS，利用LLMs合成学生的行为。具体而言，给定一个特定学生在参考任务上的解决尝试作为观察，目标是合成该学生在目标任务上的尝试。我们的框架可以与不同的LLMs结合使用；而且，我们使用领域专家知识对LLMs进行微调，提高它们对领域背景和学生行为的理解。我们评估了几种具体的方法...

    Student modeling is central to many educational technologies as it enables the prediction of future learning outcomes and targeted instructional strategies. However, open-ended learning environments pose challenges for accurately modeling students due to the diverse behaviors exhibited by students and the absence of a well-defined set of learning skills. To approach these challenges, we explore the application of Large Language Models (LLMs) for in-context student modeling in open-ended learning environments. We introduce a novel framework, LLM-SS, that leverages LLMs for synthesizing student's behavior. More concretely, given a particular student's solving attempt on a reference task as observation, the goal is to synthesize the student's attempt on a target task. Our framework can be combined with different LLMs; moreover, we fine-tune LLMs using domain-specific expertise to boost their understanding of domain background and student behaviors. We evaluate several concrete methods bas
    
[^172]: 何时才能使剧本在错误规范下保持稳定? (arXiv:2310.09358v1 [cs.LG])

    When are Bandits Robust to Misspecification?. (arXiv:2310.09358v1 [cs.LG])

    [http://arxiv.org/abs/2310.09358](http://arxiv.org/abs/2310.09358)

    该论文研究了参数化的强盗算法和情境化的强盗算法在真实奖励与模型之间存在误差的情况下的稳定性，并找到了依赖于问题实例和模型类的充分条件，使得经典算法如ε-贪心和LinUCB能够在时间范围内保持次线性的遗憾保障。

    

    参数特征为基础的奖励模型广泛应用于决策问题，如强盗算法和情境化的强盗算法。通常的假设是可行性，即行为的真实奖励完全由某个参数化模型解释。然而，我们关注的是真实奖励与模型类之间存在（可能显著）的误差的情况。对于参数化的强盗和情境化的强盗，我们识别出依赖问题实例和模型类的充分条件，使得经典算法如ε-贪心和LinUCB在即使奖励存在严重误差的情况下，也能够在时间范围内保证次线性（次于时间范围）的遗憾保障。这与现有的针对错误规范的最坏情况结果形成对比，后者显示遗憾边界随时间成线性比例增长，并且说明存在一个相当大的强盗问题实例集合在错误规范下仍然稳定。

    Parametric feature-based reward models are widely employed by algorithms for decision making settings such as bandits and contextual bandits. The typical assumption under which they are analysed is realizability, i.e., that the true rewards of actions are perfectly explained by some parametric model in the class. We are, however, interested in the situation where the true rewards are (potentially significantly) misspecified with respect to the model class. For parameterized bandits and contextual bandits, we identify sufficient conditions, depending on the problem instance and model class, under which classic algorithms such as $\epsilon$-greedy and LinUCB enjoy sublinear (in the time horizon) regret guarantees under even grossly misspecified rewards. This is in contrast to existing worst-case results for misspecified bandits which show regret bounds that scale linearly with time, and shows that there can be a nontrivially large set of bandit instances that are robust to misspecificati
    
[^173]: 反向链：一种通用规则，用于使LLMs掌握多API规划

    Reverse Chain: A Generic-Rule for LLMs to Master Multi-API Planning. (arXiv:2310.04474v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2310.04474](http://arxiv.org/abs/2310.04474)

    这项研究提出了一种名为反向链的通用规则，通过反向链思路使LLMs能够使用外部API完成复杂的函数调用任务，并通过填充参数的方式提高任务完成的准确性。

    

    尽管使大型语言模型能够实现函数调用（即API）可以极大地提高LLMs的性能，但由于不同API之间的复杂关系，在没有微调的情况下，函数调用仍然是一项具有挑战性的任务。本文提出了一种简单但可控的目标驱动方法，称为反向链，以使LLMs能够仅通过提示使用外部API。在反向链中，大多数开源LLMs仅用于实现简单任务，例如API选择和参数补全，并使用通用规则实现可控的多函数调用。在这个通用规则中，选择一个最终API来处理给定任务之后，我们首先要求LLMs从用户查询和上下文中填写所需的参数。一些缺失的参数可以通过让LLMs基于API描述选择另一个API来进一步完成。

    While enabling large language models to implement function calling (known as APIs) can greatly enhance the performance of LLMs, function calling is still a challenging task due to the complicated relations between different APIs, especially in a context-learning setting without fine-tuning. This paper proposes a simple yet controllable target-driven approach called Reverse Chain to empower LLMs with capabilities to use external APIs with only prompts. Given that most open-source LLMs have limited tool-use or tool-plan capabilities, LLMs in Reverse Chain are only employed to implement simple tasks, e.g., API selection and argument completion, and a generic rule is employed to implement a controllable multiple functions calling. In this generic rule, after selecting a final API to handle a given task via LLMs, we first ask LLMs to fill the required arguments from user query and context. Some missing arguments could be further completed by letting LLMs select another API based on API desc
    
[^174]: ReConcile：圆桌会议通过多元LLM的共识改进推理能力

    ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs. (arXiv:2309.13007v1 [cs.CL])

    [http://arxiv.org/abs/2309.13007](http://arxiv.org/abs/2309.13007)

    ReConcile是一个通过多轮讨论和投票机制来增强LLM推理能力的多模型多代理框架。

    

    大型语言模型（LLM）仍然在复杂的推理任务上遇到困难。受到心智社会理论（Minsky, 1988）的启发，我们提出了ReConcile，这是一个多模型多代理的框架，旨在通过多样的LLM代理人之间的圆桌会议来促进多样的思想和讨论，从而改进一致性。ReConcile通过进行多轮讨论、学习说服其他代理人改进答案以及采用置信度加权投票机制来增强LLM的推理能力。在每一轮中，ReConcile通过“讨论提示”来启动代理人间的讨论，其中包括上一轮每个代理人生成的答案和解释的分组、它们的不确定性以及用于说服其他代理人的答案修正人类解释的演示。这个讨论提示使每个代理人能够根据其他代理人的见解修订自己的回答。一旦达成一致并结束讨论，ReConcile执行一次全体投票以确定最终答案。

    Large Language Models (LLMs) still struggle with complex reasoning tasks. Motivated by the society of minds (Minsky, 1988), we propose ReConcile, a multi-model multi-agent framework designed as a round table conference among diverse LLM agents to foster diverse thoughts and discussion for improved consensus. ReConcile enhances the reasoning capabilities of LLMs by holding multiple rounds of discussion, learning to convince other agents to improve their answers, and employing a confidence-weighted voting mechanism. In each round, ReConcile initiates discussion between agents via a 'discussion prompt' that consists of (a) grouped answers and explanations generated by each agent in the previous round, (b) their uncertainties, and (c) demonstrations of answer-rectifying human explanations, used for convincing other agents. This discussion prompt enables each agent to revise their responses in light of insights from other agents. Once a consensus is reached and the discussion ends, ReConcil
    
[^175]: Transformers作为支持向量机

    Transformers as Support Vector Machines. (arXiv:2308.16898v1 [cs.LG])

    [http://arxiv.org/abs/2308.16898](http://arxiv.org/abs/2308.16898)

    这项工作建立了自注意力和硬间隔支持向量机问题之间的正式等价关系，通过转换器架构的优化几何来解决自然语言处理问题，同时揭示了梯度下降优化的转换器的隐式偏差。

    

    自从"Attention Is All You Need"中引入转换器架构以来，它在自然语言处理领域取得了革命性的进展。转换器中的注意力层接受输入令牌序列$X$并通过计算softmax$(XQK^\top X^\top)$的成对相似性使它们相互作用，其中$(K,Q)$是可训练的键-查询参数。在这项工作中，我们建立了自注意力优化几何和一个硬间隔支持向量机问题之间的正式等价关系，通过对令牌对的外积施加线性约束，将最佳输入令牌与非最佳令牌分离。这个形式主义使我们能够表征梯度下降优化的单层转换器的隐式偏差：(1)优化注意力层，使用可变正则化参数$(K,Q)$，收敛的方向是一个最小化综合参数$W=KQ^\top$的核范数的支持向量机解决方案。而直接使用$W$进行参数化则最小化一个Frobenius范数目标。

    Since its inception in "Attention Is All You Need", transformer architecture has led to revolutionary advancements in NLP. The attention layer within the transformer admits a sequence of input tokens $X$ and makes them interact through pairwise similarities computed as softmax$(XQK^\top X^\top)$, where $(K,Q)$ are the trainable key-query parameters. In this work, we establish a formal equivalence between the optimization geometry of self-attention and a hard-margin SVM problem that separates optimal input tokens from non-optimal tokens using linear constraints on the outer-products of token pairs. This formalism allows us to characterize the implicit bias of 1-layer transformers optimized with gradient descent: (1) Optimizing the attention layer with vanishing regularization, parameterized by $(K,Q)$, converges in direction to an SVM solution minimizing the nuclear norm of the combined parameter $W=KQ^\top$. Instead, directly parameterizing by $W$ minimizes a Frobenius norm objective. 
    
[^176]: LLM中的时间旅行：追踪大型语言模型中的数据污染

    Time Travel in LLMs: Tracing Data Contamination in Large Language Models. (arXiv:2308.08493v1 [cs.CL])

    [http://arxiv.org/abs/2308.08493](http://arxiv.org/abs/2308.08493)

    该论文提出了一种用于识别大型语言模型（LLMs）中数据污染的简单而有效的方法。通过对随机样本中的单个实例进行分析，以及使用“引导指令”来评估整个数据集分区的污染程度，可以准确地识别污染的实例和分区。

    

    数据污染是指大型语言模型（LLMs）的训练数据中存在来自下游任务的测试数据，这可能是理解LLMs在其他任务上有效性的一个重要问题。我们提出了一种简单而有效的方法来识别LLMs中的数据污染。我们的方法核心是通过识别从小的随机样本中抽取的单个实例中的潜在污染，然后评估整个数据集分区是否受到污染。为了估计单个实例的污染程度，我们使用了“引导指令”：即一个由数据集名称、分区类型和参考实例的初始部分组成的提示，要求LLM完成它。如果LLM的输出与参考实例的后一部分完全或接近匹配，那么该实例被标记为受到污染。为了了解整个分区是否受到污染，我们提出了两个想法。第一个想法是标记一个数据集的分区，该分区中的实例大多数都被判断为受到污染。

    Data contamination, i.e., the presence of test data from downstream tasks in the training data of large language models (LLMs), is a potential major issue in understanding LLMs' effectiveness on other tasks. We propose a straightforward yet effective method for identifying data contamination within LLMs. At its core, our approach starts by identifying potential contamination in individual instances that are drawn from a small random sample; using this information, our approach then assesses if an entire dataset partition is contaminated. To estimate contamination of individual instances, we employ "guided instruction:" a prompt consisting of the dataset name, partition type, and the initial segment of a reference instance, asking the LLM to complete it. An instance is flagged as contaminated if the LLM's output either exactly or closely matches the latter segment of the reference. To understand if an entire partition is contaminated, we propose two ideas. The first idea marks a dataset
    
[^177]: TEST: 文本原型对齐嵌入以激活LLM对时间序列的能力

    TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for Time Series. (arXiv:2308.08241v1 [cs.CL])

    [http://arxiv.org/abs/2308.08241](http://arxiv.org/abs/2308.08241)

    这篇论文总结了两种使用语言模型完成时间序列任务的策略，通过设计一种适用于语言模型的时间序列嵌入方法来激活语言模型对时间序列数据的能力。虽然结果没有明显超越当前最先进的模型，但可以更好地处理时间序列数据。

    

    本研究总结了两种使用现代语言模型（LLM）完成时间序列（TS）任务的策略：LLM-for-TS，设计和训练一个针对TS数据的基础大模型；TS-for-LLM，使预训练的LLM能够处理TS数据。鉴于数据积累不足、资源有限和语义上下文需求，本研究侧重于TS-for-LLM方法，旨在设计一种适用于LLM的TS嵌入方法，以激活LLM对TS数据的能力。所提出的方法称为TEST。它首先对TS进行标记化处理，建立一个编码器，通过实例、特征和文本原型对齐对它们进行嵌入，然后创建提示以使LLM更容易接受嵌入，并最终实施TS任务。使用8个具有不同结构和大小的LLM对TS分类和预测任务进行了实验。尽管其结果不能显著超越当前为TS任务定制的SOTA模型，但通过将LLM视为模式机器，可以更好地处理TS数据。

    This work summarizes two strategies for completing time-series (TS) tasks using today's language model (LLM): LLM-for-TS, design and train a fundamental large model for TS data; TS-for-LLM, enable the pre-trained LLM to handle TS data. Considering the insufficient data accumulation, limited resources, and semantic context requirements, this work focuses on TS-for-LLM methods, where we aim to activate LLM's ability for TS data by designing a TS embedding method suitable for LLM. The proposed method is named TEST. It first tokenizes TS, builds an encoder to embed them by instance-wise, feature-wise, and text-prototype-aligned contrast, and then creates prompts to make LLM more open to embeddings, and finally implements TS tasks. Experiments are carried out on TS classification and forecasting tasks using 8 LLMs with different structures and sizes. Although its results cannot significantly outperform the current SOTA models customized for TS tasks, by treating LLM as the pattern machine, 
    
[^178]: 加密货币证券案件中的大型语言模型：ChatGPT能否取代律师？

    Large Language Models in Cryptocurrency Securities Cases: Can ChatGPT Replace Lawyers?. (arXiv:2308.06032v1 [cs.AI])

    [http://arxiv.org/abs/2308.06032](http://arxiv.org/abs/2308.06032)

    本研究探讨了在加密货币证券案件中，大型语言模型（LLMs）是否能够准确判断违法行为，并比较了由LLM和律师撰写的投诉书对陪审团决策的影响。研究发现，目前的LLMs在法律推理方面表现较弱，但随着未来模型的改进，其潜力有望提升。

    

    大型语言模型（LLMs）可以增强对法律系统的访问。然而，关于它们在进行法律任务方面的有效性的实证研究非常有限。我们研究涉及加密货币的证券案件，作为AI可以支持法律过程的众多情境之一，研究LLMs的法律推理和起草能力。我们检查以下两个方面：a）LLM能否准确确定事实模式中可能存在的违法行为，b）基于LLM和律师撰写的投诉书，陪审团的决策是否有所差异。我们将真实案例中的事实模式输入GPT-3.5，并评估其确定正确潜在违法行为并排除虚假违法行为的能力。其次，我们请模拟陪审员评估LLM和律师撰写的投诉书。GPT-3.5的法律推理能力较弱，但我们预期未来模型的改进，特别是考虑到它建议的违法行为往往是正确的（它仅仅过于保守）。

    Large Language Models (LLMs) could enhance access to the legal system. However, empirical research on their effectiveness in conducting legal tasks is scant. We study securities cases involving cryptocurrencies as one of numerous contexts where AI could support the legal process, studying LLMs' legal reasoning and drafting capabilities. We examine whether a) an LLM can accurately determine which laws are potentially being violated from a fact pattern, and b) whether there is a difference in juror decision-making based on complaints written by a lawyer compared to an LLM. We feed fact patterns from real-life cases to GPT-3.5 and evaluate its ability to determine correct potential violations from the scenario and exclude spurious violations. Second, we had mock jurors assess complaints written by the LLM and lawyers. GPT-3.5's legal reasoning skills proved weak, though we expect improvement in future models, particularly given the violations it suggested tended to be correct (it merely m
    
[^179]: 基于区块链的基金会模型系统的去中心化治理：探讨区块链在负责任的人工智能中的作用。

    Decentralised Governance for Foundation Model based Systems: Exploring the Role of Blockchain in Responsible AI. (arXiv:2308.05962v1 [cs.SE])

    [http://arxiv.org/abs/2308.05962](http://arxiv.org/abs/2308.05962)

    本文探讨了基于基金会模型的人工智能系统在整个生命周期中所面临的治理挑战，并提出了利用区块链实现去中心化治理的架构。

    

    基金会模型因其卓越的能力和潜力在全球范围内越来越受到关注，能够执行各种任务。然而，人们担心基于基金会模型的人工智能系统是否得到了适当的治理，以确保其可信度，并防止可能对人类、社会和环境造成伤害的滥用。在本文中，我们确定了基金会模型人工智能系统在整个生命周期中面临的八个治理挑战，涉及治理的三个基本维度：决策权、激励机制和问责制。此外，我们探讨了区块链作为解决这些挑战的潜力，通过提供分布式账本来促进去中心化的治理。我们提出了一个架构，演示了如何利用区块链实现基金会模型人工智能系统的治理。

    Foundation models are increasingly attracting interest worldwide for their distinguished capabilities and potential to perform a wide variety of tasks. Nevertheless, people are concerned about whether foundation model based AI systems are properly governed to ensure trustworthiness of foundation model based AI systems and to prevent misuse that could harm humans, society and the environment. In this paper, we identify eight governance challenges in the entire lifecycle of foundation model based AI systems regarding the three fundamental dimensions of governance: decision rights, incentives, and accountability. Furthermore, we explore the potential of blockchain as a solution to address the challenges by providing a distributed ledger to facilitate decentralised governance. We present an architecture that demonstrates how blockchain can be leveraged to realise governance in foundation model based AI systems.
    
[^180]: 不同解释: 利用分歧减少模型过度依赖

    Dissenting Explanations: Leveraging Disagreement to Reduce Model Overreliance. (arXiv:2307.07636v1 [cs.AI])

    [http://arxiv.org/abs/2307.07636](http://arxiv.org/abs/2307.07636)

    这项研究介绍了不同解释的概念，旨在通过提供伴随冲突预测的解释来减少模型过度依赖。在模型多样性设置下，这种方法可以帮助人们从不同模型的解释中获得洞察力。

    

    尽管可解释性是日益复杂的黑盒模型的一个可取特征，但现代解释方法已被证明是不一致和矛盾的。解释的语义并不总是完全理解的 - 解释在多大程度上"解释"一个决策，在多大程度上只是支持一个决策？我们能否帮助人们从伴随正确预测的解释中获得洞察力，而不是过度依赖解释所提倡的错误预测？在这个角度上，我们引入了不同的解释概念: 伴随冲突预测的解释。我们首先探讨了在模型多样性设置下不同解释的优势，其中具有相似性能的多个模型可能有不同的预测。在这种情况下，提供不同的解释可以通过调用不同模型的解释实现。通过一项试点研究，我们证明了不同解释的价值。

    While explainability is a desirable characteristic of increasingly complex black-box models, modern explanation methods have been shown to be inconsistent and contradictory. The semantics of explanations is not always fully understood - to what extent do explanations "explain" a decision and to what extent do they merely advocate for a decision? Can we help humans gain insights from explanations accompanying correct predictions and not over-rely on incorrect predictions advocated for by explanations? With this perspective in mind, we introduce the notion of dissenting explanations: conflicting predictions with accompanying explanations. We first explore the advantage of dissenting explanations in the setting of model multiplicity, where multiple models with similar performance may have different predictions. In such cases, providing dissenting explanations could be done by invoking the explanations of disagreeing models. Through a pilot study, we demonstrate that dissenting explanation
    
[^181]: 人工智能是算法模仿：为什么人工“代理”不是（也不会成为）真正的代理

    Artificial intelligence is algorithmic mimicry: why artificial "agents" are not (and won't be) proper agents. (arXiv:2307.07515v1 [cs.AI])

    [http://arxiv.org/abs/2307.07515](http://arxiv.org/abs/2307.07515)

    本研究通过对比生物系统和算法系统，指出了生物系统具有自我制造自主能力、符号和物理方面没有区分以及体验到模糊问题的大世界等特点，而算法系统则与此相反。

    

    这篇论文通过对比生物系统和算法系统，重点探讨“代理”概念，来探讨人工通用智能（AGI）的发展前景。作者指出了三个基本的差异：（1）生物系统具有自我制造的自主能力，能够设定自身的内在目标，而算法系统存在于一个由外部代理提供目标函数的计算环境中。（2）生物系统是具体体现的，即其符号和物理方面没有区分，而算法运行在计算结构上，最大限度地将软件与硬件隔离。（3）生物系统体验到一个庞大的世界，其中大多数问题是模糊的（并非全部可定义），而算法系统存在于一个小世界中，其中所有问题都是明确的。这三个差异说明了生物和算法系统具有非常不同的能力。

    What is the prospect of developing artificial general intelligence (AGI)? I investigate this question by systematically comparing living and algorithmic systems, with a special focus on the notion of "agency." There are three fundamental differences to consider: (1) Living systems are autopoietic, that is, self-manufacturing, and therefore able to set their own intrinsic goals, while algorithms exist in a computational environment with target functions that are both provided by an external agent. (2) Living systems are embodied in the sense that there is no separation between their symbolic and physical aspects, while algorithms run on computational architectures that maximally isolate software from hardware. (3) Living systems experience a large world, in which most problems are ill-defined (and not all definable), while algorithms exist in a small world, in which all problems are well-defined. These three differences imply that living and algorithmic systems have very different capab
    
[^182]: 随机加权梯度下降通过分布健壮优化

    Stochastic Re-weighted Gradient Descent via Distributionally Robust Optimization. (arXiv:2306.09222v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.09222](http://arxiv.org/abs/2306.09222)

    我们通过分布健壮优化和重要性加权的梯度下降技术提升了深度神经网络的性能，并在各种任务上取得了优越的结果。

    

    我们通过在每一次优化步骤中对数据点进行重要性加权，开发了一种提高深度神经网络性能的加权梯度下降技术。我们的方法受到分布健壮优化和f-散度的启发，已知可以得到具有改进的泛化保证的模型。我们的加权方案简单、计算高效，可以与许多流行的优化算法（如SGD和Adam）结合使用。实验证明，我们的方法在各种任务上都表现出了优越性能，包括监督学习和领域适应。值得注意的是，我们在DomainBed和Tabular分类基准上分别比现有最佳结果提升了0.7%和1.44%。此外，我们的算法将BERT在GLUE基准上的性能提升了1.94%，将ViT在ImageNet-1K上的性能提升了1.01%。这些结果表明了所提出方法的有效性，预示着它在改善性能方面的潜力。

    We develop a re-weighted gradient descent technique for boosting the performance of deep neural networks, which involves importance weighting of data points during each optimization step. Our approach is inspired by distributionally robust optimization with f-divergences, which has been known to result in models with improved generalization guarantees. Our re-weighting scheme is simple, computationally efficient, and can be combined with many popular optimization algorithms such as SGD and Adam. Empirically, we demonstrate the superiority of our approach on various tasks, including supervised learning, domain adaptation. Notably, we obtain improvements of +0.7% and +1.44% over SOTA on DomainBed and Tabular classification benchmarks, respectively. Moreover, our algorithm boosts the performance of BERT on GLUE benchmarks by +1.94%, and ViT on ImageNet-1K by +1.01%. These results demonstrate the effectiveness of the proposed approach, indicating its potential for improving performance in 
    
[^183]: 无领域偏见批量贝叶斯优化，通过贝叶斯积分处理多种约束条件

    Domain-Agnostic Batch Bayesian Optimization with Diverse Constraints via Bayesian Quadrature. (arXiv:2306.05843v1 [cs.LG])

    [http://arxiv.org/abs/2306.05843](http://arxiv.org/abs/2306.05843)

    本论文提出了cSOBER，一种处理多样化约束条件、离散和混合空间、未知约束以及查询拒绝问题的领域无关型贝叶斯优化算法。

    

    现实世界的优化问题通常具有多样的约束条件、离散和混合空间、高度可并行化等特点。同时，当存在未知约束时，例如在药物发现和动物实验安全性等领域，必须确立未知约束之后才能查询目标函数。现有工作通常仅针对上述某些特征而并非综合考虑。本文提出了cSOBER，一种基于SOBER算法的领域无关型谨慎并行主动采样器，考虑到了未知约束情况下的集成误差的影响并提出了处理方法，处理多种约束条件和未知约束查询拒绝的问题。

    Real-world optimisation problems often feature complex combinations of (1) diverse constraints, (2) discrete and mixed spaces, and are (3) highly parallelisable. (4) There are also cases where the objective function cannot be queried if unknown constraints are not satisfied, e.g. in drug discovery, safety on animal experiments (unknown constraints) must be established before human clinical trials (querying objective function) may proceed. However, most existing works target each of the above three problems in isolation and do not consider (4) unknown constraints with query rejection. For problems with diverse constraints and/or unconventional input spaces, it is difficult to apply these techniques as they are often mutually incompatible. We propose cSOBER, a domain-agnostic prudent parallel active sampler for Bayesian optimisation, based on SOBER of Adachi et al. (2023). We consider infeasibility under unknown constraints as a type of integration error that we can estimate. We propose 
    
[^184]: 数据中动态偏移的状态规范化策略优化

    State Regularized Policy Optimization on Data with Dynamics Shift. (arXiv:2306.03552v1 [cs.LG])

    [http://arxiv.org/abs/2306.03552](http://arxiv.org/abs/2306.03552)

    本文提出了一种叫做 SRPO (状态规范化策略优化) 的算法，该算法利用训练数据中的稳态分布来规范新环境中的策略，在处理具有不同动态的多个环境时表现优异。

    

    在许多实际场景中，强化学习算法使用的数据受到动态偏移的影响，即具有不同的环境动态。目前的大多数方法通过训练上下文编码器来识别环境参数来解决这个问题。根据其环境参数将带有动态漂移的数据分开以训练相应的策略。然而，这些方法可能会出现样本效率低下的问题，因为数据是“特定场景”使用的，针对某个环境训练的策略不能从收集在其他具有不同动态的所有其他环境中的数据中受益。本文发现，在许多具有相似结构和不同动态的环境中，最优策略具有类似的稳态分布。我们利用这种特性，并从具有动态漂移的数据中学习稳态分布，以实现高效的数据重用。这种分布用于规范新环境中训练的策略，导致了 SRPO（状态规范化策略优化）算法的出现。实验结果表明，SRPO 在具有动态偏移的任务上显著优于现有的方法。

    In many real-world scenarios, Reinforcement Learning (RL) algorithms are trained on data with dynamics shift, i.e., with different underlying environment dynamics. A majority of current methods address such issue by training context encoders to identify environment parameters. Data with dynamics shift are separated according to their environment parameters to train the corresponding policy. However, these methods can be sample inefficient as data are used \textit{ad hoc}, and policies trained for one dynamics cannot benefit from data collected in all other environments with different dynamics. In this paper, we find that in many environments with similar structures and different dynamics, optimal policies have similar stationary state distributions. We exploit such property and learn the stationary state distribution from data with dynamics shift for efficient data reuse. Such distribution is used to regularize the policy trained in a new environment, leading to the SRPO (\textbf{S}tat
    
[^185]: Doc2SoarGraph：基于语义导向分层图的富含视觉表格文档的离散推理

    Doc2SoarGraph: Discrete Reasoning over Visually-Rich Table-Text Documents with Semantic-Oriented Hierarchical Graphs. (arXiv:2305.01938v1 [cs.CL])

    [http://arxiv.org/abs/2305.01938](http://arxiv.org/abs/2305.01938)

    本文提出了 Doc2SoarGraph 框架，利用语义导向分层图结构中元素之间的差异和相关性，在富含视觉表格文本的TAT-DQA问题下实现了离散推理，表现出了最佳的实验结果。

    

    近两年来，对于表格文本文档（例如财务报告）的离散推理越来越受到关注。现有的工作大多通过手动选择和转换文档页面到结构化的表格和段落来简化这一挑战，从而阻碍其实际应用。在这项工作中，我们探究了一种更为现实的问题设置，即以 TAT-DQA 的形式回答富含视觉表格文本的问题。具体而言，我们提出了一种新颖的 Doc2SoarGraph 框架，通过利用语义导向分层图结构中不同元素之间的差异和相关性，提高了其离散推理能力。我们对 TAT-DQA 数据集进行了广泛的实验，结果显示，我们的提出的框架在测试集上的精确匹配（EM）和 F1 得分方面分别比最佳基线模型分别提高了 17.73% 和 16.91%，实现了新的最先进技术水平。

    Discrete reasoning over table-text documents (e.g., financial reports) gains increasing attention in recent two years. Existing works mostly simplify this challenge by manually selecting and transforming document pages to structured tables and paragraphs, hindering their practical application. In this work, we explore a more realistic problem setting in the form of TAT-DQA, i.e. to answer the question over a visually-rich table-text document. Specifically, we propose a novel Doc2SoarGraph framework with enhanced discrete reasoning capability by harnessing the differences and correlations among different elements (e.g., quantities, dates) of the given question and document with Semantic-oriented hierarchical Graph structures. We conduct extensive experiments on TAT-DQA dataset, and the results show that our proposed framework outperforms the best baseline model by 17.73% and 16.91% in terms of Exact Match (EM) and F1 score respectively on the test set, achieving the new state-of-the-art
    
[^186]: 有意义的因果聚合和悖论性混淆

    Meaningful Causal Aggregation and Paradoxical Confounding. (arXiv:2304.11625v1 [cs.AI])

    [http://arxiv.org/abs/2304.11625](http://arxiv.org/abs/2304.11625)

    聚合变量上的因果性不确定性可能会使得原本不混淆的因果关系变得混淆，在实际应用中，我们需要接受宏观因果关系通常只与微观状态相关的事实。

    

    在聚合变量中，干预的影响通常是不确定的，因为相同的宏观干预的不同微观实现可能会导致下游宏观变量的不同变化。我们表明，对于聚合变量，因果性的不确定性可以使得原本不混淆的因果关系变得混淆，并且反之亦然，这一点取决于相应的微观实现。我们认为，只有在聚合因果系统没有这种不确定性的情况下，我们才可以实际应用这种方法。否则，我们需要接受一点，就是宏观因果关系通常只与微观状态相关。在积极方面，我们表明当宏观干预的分布与观测分布中微观状态的分布相同时，因果关系可以进行聚合，并讨论了此观察的概括。

    In aggregated variables the impact of interventions is typically ill-defined because different micro-realizations of the same macro-intervention can result in different changes of downstream macro-variables. We show that this ill-definedness of causality on aggregated variables can turn unconfounded causal relations into confounded ones and vice versa, depending on the respective micro-realization. We argue that it is practically infeasible to only use aggregated causal systems when we are free from this ill-definedness. Instead, we need to accept that macro causal relations are typically defined only with reference to the micro states. On the positive side, we show that cause-effect relations can be aggregated when the macro interventions are such that the distribution of micro states is the same as in the observational distribution and also discuss generalizations of this observation.
    
[^187]: 揭示和解决统一视觉-语言模型中的跨任务不一致问题

    Exposing and Addressing Cross-Task Inconsistency in Unified Vision-Language Models. (arXiv:2303.16133v1 [cs.CV])

    [http://arxiv.org/abs/2303.16133](http://arxiv.org/abs/2303.16133)

    该研究提出了一个基准数据集COCOCON，并提出度量方法来衡量模型一致性，研究发现现有的最先进系统在不同任务之间表现出高度不一致性。

    

    随着通用的视觉模型在不同任务上变得越来越有效，保证它们在各自支持的任务中的一致性是非常重要的。人们认为不一致的人工智能模型是不可靠的，这对于依赖它们输出的大型系统来说是更具挑战性的。由于很难确定预测结果是否一致，因此，评估可能包括不同模态输出的非常异构任务之间的一致性是具有挑战性的。因此，我们提出了基准数据集COCOCON，其中我们使用对多个任务的测试实例进行小型但语义上有意义的修改来创建对比集，以更改金标签，并概述了用于通过对比接近原始和修改后的实例来衡量模型一致性的指标。我们发现，最先进的系统在任务之间表现出惊人的不一致性。

    As general purpose vision models get increasingly effective at a wide set of tasks, it is imperative that they be consistent across the tasks they support. Inconsistent AI models are considered brittle and untrustworthy by human users and are more challenging to incorporate into larger systems that take dependencies on their outputs. Measuring consistency between very heterogeneous tasks that might include outputs in different modalities is challenging since it is difficult to determine if the predictions are consistent with one another. As a solution, we introduce a benchmark dataset, COCOCON, where we use contrast sets created by modifying test instances for multiple tasks in small but semantically meaningful ways to change the gold label, and outline metrics for measuring if a model is consistent by ranking the original and perturbed instances across tasks. We find that state-of-the-art systems suffer from a surprisingly high degree of inconsistent behavior across tasks, especially 
    
[^188]: 在可解释的因果变量和分布式神经表示之间寻找对齐方法

    Finding Alignments Between Interpretable Causal Variables and Distributed Neural Representations. (arXiv:2303.02536v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.02536](http://arxiv.org/abs/2303.02536)

    本文提出了分布式对齐搜索（DAS）算法，可以在不使用暴力搜索的情况下找到高层因果模型和低层深度学习系统之间的对齐方法，并且DAS可以发现先前方法忽略的内部结构。DAS算法有潜力实现对复杂深度学习系统的更好解释和理解。

    

    因果抽象是可解释的人工智能的一个有前途的理论框架，它定义了可解释的高层因果模型何时是低层深度学习系统的可信简化。然而，现有的因果抽象方法存在两个主要限制：它们需要在高层模型和低层模型之间进行暴力搜索对齐，并且它们预设高层模型中的变量将与低层模型中的不相交的神经元集对齐。在本文中，我们提出了分布式对齐搜索（DAS），它克服了这些限制。在DAS中，我们使用梯度下降找到高层模型和低层模型之间的对齐方法，允许个体神经元在非传统基底分布表示中发挥多个不同的角色。我们的实验表明，DAS可以发现先前方法忽略的内部结构。总体而言，DAS有潜力实现对复杂深度学习系统的更好解释和理解。

    Causal abstraction is a promising theoretical framework for explainable artificial intelligence that defines when an interpretable high-level causal model is a faithful simplification of a low-level deep learning system. However, existing causal abstraction methods have two major limitations: they require a brute-force search over alignments between the high-level model and the low-level one, and they presuppose that variables in the high-level model will align with disjoint sets of neurons in the low-level one. In this paper, we present distributed alignment search (DAS), which overcomes these limitations. In DAS, we find the alignment between high-level and low-level models using gradient descent rather than conducting a brute-force search, and we allow individual neurons to play multiple distinct roles by analyzing representations in non-standard bases-distributed representations. Our experiments show that DAS can discover internal structure that prior approaches miss. Overall, DAS 
    
[^189]: 生成可逆量子神经网络

    Generative Invertible Quantum Neural Networks. (arXiv:2302.12906v2 [hep-ph] UPDATED)

    [http://arxiv.org/abs/2302.12906](http://arxiv.org/abs/2302.12906)

    本论文提出了一种用于生成可逆量子神经网络的算法，并将其应用于LHC数据的处理，结果表明该算法可以在学习和生成复杂数据方面与经典算法的表现相匹配。

    

    可逆神经网络已成为模拟和生成高度复杂数据的工具。我们提出了一种量子门算法用于量子可逆神经网络（QINN），并将其应用于将衰变为轻子的Z玻色子的喷注相关产生的LHC数据，这是粒子对撞机精密测量的标准过程。我们比较了QINN在不同损失函数和训练场景下的表现。对于这个任务，我们发现一个混合的QINN可以在学习和生成复杂数据方面与一个显著更大的完全经典的INN的表现匹配。

    Invertible Neural Networks (INN) have become established tools for the simulation and generation of highly complex data. We propose a quantum-gate algorithm for a Quantum Invertible Neural Network (QINN) and apply it to the LHC data of jet-associated production of a Z-boson that decays into leptons, a standard candle process for particle collider precision measurements. We compare the QINN's performance for different loss functions and training scenarios. For this task, we find that a hybrid QINN matches the performance of a significantly larger purely classical INN in learning and generating complex data.
    
[^190]: 语言建模任务中的不充分规范化：一个以因果关系为基础的性别代词消解研究

    Underspecification in Language Modeling Tasks: A Causality-Informed Study of Gendered Pronoun Resolution. (arXiv:2210.00131v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.00131](http://arxiv.org/abs/2210.00131)

    本研究通过提供一个因果模型，在语言建模任务中探讨了不充分规范化的作用，提出了两种轻量级黑盒评估方法来帮助检测任务的不充分规范化，并在性别代词消解任务中应用这些方法，同时发现了性别与时间、性别与位置之间的虚假相关性。

    

    现代语言建模任务常常存在不充分规范化的问题：对于给定的标记预测，在推断时可能有多个单词符合用户产生自然语言的意图，然而在训练时只有一个单词能够最小化任务的损失函数。我们提供了一个简单而合理的因果机制，描述了不充分规范化在生成虚假相关性方面的作用。尽管其简洁性，我们的因果模型直接指导了两种轻量级黑盒评估方法的开发，我们将其应用于广泛的语言模型任务中的性别代词消解上，以帮助 1) 检测推断时任务的不充分规范化，利用了 2）之前未报道的性别与时间、性别与位置的虚假相关性，涵盖了 A）不同规模的语言模型，从BERT-base到GPT 3.5，B）不同的预训练目标，从遮蔽和自回归语言建模到这些目标的混合，以及C）不同的训练阶段，从仅预训练到增强训练。

    Modern language modeling tasks are often underspecified: for a given token prediction, many words may satisfy the user's intent of producing natural language at inference time, however only one word would minimize the task's loss function at training time. We provide a simple yet plausible causal mechanism describing the role underspecification plays in the generation of spurious correlations. Despite its simplicity, our causal model directly informs the development of two lightweight black-box evaluation methods, that we apply to gendered pronoun resolution tasks on a wide range of LLMs to 1) aid in the detection of inference-time task underspecification by exploiting 2) previously unreported gender vs. time and gender vs. location spurious correlations on LLMs with a range of A) sizes: from BERT-base to GPT 3.5, B) pre-training objectives: from masked & autoregressive language modeling to a mixture of these objectives, and C) training stages: from pre-training only to reinforcement l
    

