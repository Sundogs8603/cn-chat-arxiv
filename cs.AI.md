# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A Comprehensive Survey on 3D Content Generation](https://rss.arxiv.org/abs/2402.01166) | 本综述对三维内容生成领域的发展进行了全面综合，提出了一种新的分类法，总结了目前的主要技术，并讨论了当前技术的局限性和未来工作的挑战和方向。 |
| [^2] | [TexTile: A Differentiable Metric for Texture Tileability](https://arxiv.org/abs/2403.12961) | TexTile是一种不同iable的度量方法，用于评估纹理图像的平铺性能，可以帮助更明智地合成和分析平铺纹理。 |
| [^3] | [WHAC: World-grounded Humans and Cameras](https://arxiv.org/abs/2403.12959) | 该研究提出了一个名为WHAC的框架，可以实现基于世界坐标系的丰富人体姿势和形状估计，同时进行摄像机姿势估计，无需依赖传统优化技术。 |
| [^4] | [Just Shift It: Test-Time Prototype Shifting for Zero-Shot Generalization with Vision-Language Models](https://arxiv.org/abs/2403.12952) | 引入了测试时间原型转移（TPS）框架，通过动态学习每个原型的转移向量，有效地弥合了领域差距并增强了类 |
| [^5] | [Vid2Robot: End-to-end Video-conditioned Policy Learning with Cross-Attention Transformers](https://arxiv.org/abs/2403.12943) | Vid2Robot提出了一种新颖的端到端视频条件化策略学习框架，通过交叉注意力机制融合视频特征和机器人状态，直接生成模仿所观察任务的动作。 |
| [^6] | [Automatic Information Extraction From Employment Tribunal Judgements Using Large Language Models](https://arxiv.org/abs/2403.12936) | 本文研究了使用大型语言模型GPT-4自动从英国雇佣法庭案例中提取信息的应用，并通过手动验证确保了提取数据的准确性和相关性 |
| [^7] | [Generalizable and Stable Finetuning of Pretrained Language Models on Low-Resource Texts](https://arxiv.org/abs/2403.12918) | 提出了一种基于注意力引导的权重混合正则化方法，用于解决低资源文本上预训练语言模型微调时的稳定性和泛化能力问题 |
| [^8] | [Yell At Your Robot: Improving On-the-Fly from Language Corrections](https://arxiv.org/abs/2403.12910) | 该论文发现，通过人类提供的语言纠正，可以帮助机器人持续改进长久任务表现 |
| [^9] | [Toward Sustainable GenAI using Generation Directives for Carbon-Friendly Large Language Model Inference](https://arxiv.org/abs/2403.12900) | 本文提出了Sprout框架，通过引入生成指令的概念，平衡了生态可持续性和高质量生成结果之间的需求，实现了大型语言模型推断服务碳排放的显著减少。 |
| [^10] | [Adaptive Visual Imitation Learning for Robotic Assisted Feeding Across Varied Bowl Configurations and Food Types](https://arxiv.org/abs/2403.12891) | 提出了一种名为AVIL的自适应视觉模仿学习方法，通过将视觉感知与模仿学习相结合，实现了机器人在不同碗配置和食物类型下的灵活和稳健的辅助喂食。 |
| [^11] | [Regularization in Spider-Style Strategy Discovery and Schedule Construction](https://arxiv.org/abs/2403.12869) | 本文研究了在Vampire定理证明器中使用蜘蛛式系统的正则化方法，探讨了构建强大日程表的难易程度以及日程泛化到未知问题的影响因素。 |
| [^12] | [RASP: A Drone-based Reconfigurable Actuation and Sensing Platform Towards Ambient Intelligent Systems](https://arxiv.org/abs/2403.12853) | 提出了RASP，一个可在25秒内自主更换传感器和执行器的模块化和可重构传感和作动平台，使无人机能快速适应各种任务，同时引入了利用大规模语言和视觉语言模型的个人助理系统架构。 |
| [^13] | [Answer Set Programming for Flexible Payroll Management](https://arxiv.org/abs/2403.12823) | 提出了一种基于灵活答案集编程模型和决策模型和符号标记的方法，可帮助人力资源咨询师代表复杂规则设计灵活薪酬管理系统。 |
| [^14] | [FlowerFormer: Empowering Neural Architecture Encoding using a Flow-aware Graph Transformer](https://arxiv.org/abs/2403.12821) | FlowerFormer是一种强大的图变换器，通过双向异步消息传递和基于流程的全局注意力，可以增强神经结构的表征学习。 |
| [^15] | [Re-identification from histopathology images](https://arxiv.org/abs/2403.12816) | 相对简单的深度学习算法能够在组织病理学图像数据集中以高准确率重新识别患者，并提出了一个风险评估方案。 |
| [^16] | [Comparing Explanation Faithfulness between Multilingual and Monolingual Fine-tuned Language Models](https://arxiv.org/abs/2403.12809) | 多语和单语语言模型之间的特征归因方法的忠实度存在差异，实验证明多语模型越大，FA相对于单语模型来说越不忠实。 |
| [^17] | [Contextual Moral Value Alignment Through Context-Based Aggregation](https://arxiv.org/abs/2403.12805) | 提出了一个基于情境聚合的情境道德价值对齐系统，相比现有技术，在与人类价值对齐方面表现更好。 |
| [^18] | [Investigating Text Shortening Strategy in BERT: Truncation vs Summarization](https://arxiv.org/abs/2403.12799) | 本研究调查了文本分类任务中文档截断和摘要的表现，发现摘要在大多数情况下胜过截断方法的变体，最佳策略为取文档的开头。 |
| [^19] | [Discover and Mitigate Multiple Biased Subgroups in Image Classifiers](https://arxiv.org/abs/2403.12777) | 提出了一种称为“分解、解释和减轻（DIM）”的新方法, 用于在图像分类器中发现和减轻多个有偏子群体，增强模型鲁棒性。 |
| [^20] | [Building Brain Tumor Segmentation Networks with User-Assisted Filter Estimation and Selection](https://arxiv.org/abs/2403.12748) | 使用多步骤FLIM方法，只在第一个卷积层中使用用户辅助的方式来估计和选择最相关的滤波器，实现了脑肿瘤分割网络的改进。 |
| [^21] | [What Does Evaluation of Explainable Artificial Intelligence Actually Tell Us? A Case for Compositional and Contextual Validation of XAI Building Blocks](https://arxiv.org/abs/2403.12730) | 本文提出了一个细粒度的验证框架，旨在不过度依赖于任何一个社会技术系统的方面，并承认其固有的模块化结构，从而使我们能够系统地推理有关这些性质的内容 |
| [^22] | [Python Fuzzing for Trustworthy Machine Learning Frameworks](https://arxiv.org/abs/2403.12723) | 提出了一种用于Python项目的动态分析管道，结合模糊测试、语料库最小化、崩溃分类和覆盖率收集，以确保机器学习框架的安全性和可靠性。 |
| [^23] | [AnimateDiff-Lightning: Cross-Model Diffusion Distillation](https://arxiv.org/abs/2403.12706) | AnimateDiff-Lightning模型利用渐进对抗性扩散蒸馏，在视频生成领域取得了新的最先进技术，提出了同时蒸馏多个基础扩散模型概率流的方法，形成了具有更广泛样式兼容性的单一蒸馏运动模块。 |
| [^24] | [Empowering Air Travelers: A Chatbot for Canadian Air Passenger Rights](https://arxiv.org/abs/2403.12678) | 提出了一款关于加拿大空中旅客权利的聊天机器人，帮助旅客理解和利用相关空中旅行法规，成功解决了用户输入复杂和准确回答问题的挑战 |
| [^25] | [Improving Interpretability of Scores in Anomaly Detection Based on Gaussian-Bernoulli Restricted Boltzmann Machine](https://arxiv.org/abs/2403.12672) | 该研究提出了一种基于累积分布改进评分可解释性的度量，建立了使用可解释度量设置阈值的准则，并通过数值实验证明其合理性。 |
| [^26] | [Enhancing Security of AI-Based Code Synthesis with GitHub Copilot via Cheap and Efficient Prompt-Engineering](https://arxiv.org/abs/2403.12671) | 提出了通过提示工程方法增强 GitHub Copilot 的 AI 代码合成安全性，其中包括三种提示改变方法：特定场景的、迭代的和通用的从句，同时讨论它们的组合。 |
| [^27] | [Deciphering AutoML Ensembles: cattleia's Assistance in Decision-Making](https://arxiv.org/abs/2403.12664) | 提出了cattleia工具，可以解密用于回归、多类别和二元分类任务的AutoML集成模型，通过评估指标和新度量指标，分析集成模型的性能和重要性 |
| [^28] | [ERASE: Benchmarking Feature Selection Methods for Deep Recommender Systems](https://arxiv.org/abs/2403.12660) | 深度推荐系统中的特征选择方法研究面临着公平比较、选择属性分析缺乏以及过度关注峰值性能等挑战。 |
| [^29] | [InBox: Recommendation with Knowledge Graph using Interest Box Embedding](https://arxiv.org/abs/2403.12649) | 该论文介绍了一种利用知识图谱和兴趣框Embedding的推荐系统，以提高性能和可解释性。 |
| [^30] | [PointGrasp: Point Cloud-based Grasping for Tendon-driven Soft Robotic Glove Applications](https://arxiv.org/abs/2403.12631) | 提出了一个用于腱驱动软机器人手套的基于点云的抓取系统，能够通过分析3D点云中的对象几何形状来支持日常生活活动中的定制抓取任务。 |
| [^31] | [Enhancing Formal Theorem Proving: A Comprehensive Dataset for Training AI Models on Coq Code](https://arxiv.org/abs/2403.12627) | 提出了一个全面的数据集，用于增强大型语言模型在解释和生成Coq代码方面的熟练程度，推动自动定理证明的发展。 |
| [^32] | [FootstepNet: an Efficient Actor-Critic Method for Fast On-line Bipedal Footstep Planning and Forecasting](https://arxiv.org/abs/2403.12589) | 提出了一种基于深度强化学习技术的高效足部规划方法，在线推理的计算需求极低，无启发式，并依赖连续的动作生成可行的足步。 |
| [^33] | [Machine Learning of the Prime Distribution](https://arxiv.org/abs/2403.12588) | 使用最大熵方法推导了概率数论中的几个定理，提供了关于素数学习性质的理论论证，发现Erd\H{o}s-Kac定律不太可能被当前机器学习技术发现，并进行数值实验以验证理论结果 |
| [^34] | [EAS-SNN: End-to-End Adaptive Sampling and Representation for Event-based Detection with Recurrent Spiking Neural Networks](https://arxiv.org/abs/2403.12574) | 提出了一种利用循环脉冲神经网络的自适应采样模块，通过将脉冲神经元的神经动力学与理想的时间事件采样器的行为相结合，实现了端到端可学习的事件检测框架 |
| [^35] | [Compound Expression Recognition via Multi Model Ensemble](https://arxiv.org/abs/2403.12572) | 提出了一种基于集成学习方法的复合表情识别解决方案，通过使用多种模型包括卷积网络、视觉Transformer和多尺度局部注意网络，通过延迟融合的方式最终实现了高准确率。 |
| [^36] | [Memory-Efficient and Secure DNN Inference on TrustZone-enabled Consumer IoT Devices](https://arxiv.org/abs/2403.12568) | 提出了一种在TrustZone中进行高级模型部署的新方法，确保模型推断期间全面保护隐私。 |
| [^37] | [Simple Hack for Transformers against Heavy Long-Text Classification on a Time- and Memory-Limited GPU Service](https://arxiv.org/abs/2403.12563) | 通过在有限资源上逐步执行高效动态的HPO过程，提出了一种注重将Transformers模型适用于长文本分类任务的简单技巧。 |
| [^38] | [Equity through Access: A Case for Small-scale Deep Learning](https://arxiv.org/abs/2403.12562) | 通过引入PePR分数，研究人员展示了在资源有限的情况下，利用131种独特的DL架构在医学图像任务中的可行性。 |
| [^39] | [M2DA: Multi-Modal Fusion Transformer Incorporating Driver Attention for Autonomous Driving](https://arxiv.org/abs/2403.12552) | 提出了一种融合驾驶员注意力的多模态融合变压器(M2DA)用于自动驾驶，通过引入LVAFusion模块和驾驶员注意力，实现了更高的数据融合效率和人类化的场景理解能力。 |
| [^40] | [To Help or Not to Help: LLM-based Attentive Support for Human-Robot Group Interactions](https://arxiv.org/abs/2403.12533) | 该论文提出了基于LLM的专注支持交互概念，使机器人能够在不干扰群体的情况下支持和帮助人类。 |
| [^41] | [GraphERE: Jointly Multiple Event-Event Relation Extraction via Graph-Enhanced Event Embeddings](https://arxiv.org/abs/2403.12523) | 该论文提出了一种名为GraphERE的多事件关系提取框架，通过使用图增强事件嵌入，扩展了事件嵌入的事件参数和结构特征，从而解决了事件触发器嵌入的局限以及关系之间互连被忽略的问题。 |
| [^42] | [Generalized Consistency Trajectory Models for Image Manipulation](https://arxiv.org/abs/2403.12510) | 本研究提出了广义一致性轨迹模型（GCTMs），能够在任何噪声分布和数据分布之间实现转换。 |
| [^43] | [Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices](https://arxiv.org/abs/2403.12503) | 该论文全面调查了与大型语言模型相关的安全和隐私问题，并提出了未来研究的有前途方向。 |
| [^44] | [DetToolChain: A New Prompting Paradigm to Unleash Detection Ability of MLLM](https://arxiv.org/abs/2403.12488) | DetToolChain提出了一种新的提示范式，可以释放MLLM的零拍摄物体检测能力，并通过检测链式思维自动化任务分解和逐步框细化规划。 |
| [^45] | [NTK-Guided Few-Shot Class Incremental Learning](https://arxiv.org/abs/2403.12486) | 本文通过NTK对FSCIL模型的指导，致力于在增量学习中实现卓越泛化，通过优化NTK收敛和降低泛化误差来确保最佳性能。 |
| [^46] | [Embodied LLM Agents Learn to Cooperate in Organized Teams](https://arxiv.org/abs/2403.12482) | 本文介绍了一个框架，将即时性组织结构强加在LLM代理上，以促进多代理系统内的合作，在具身LLM代理和人-代理合作实验中发现指定领导对团队效率的影响，揭示了LLM代理的领导素质和自发合作行为。 |
| [^47] | [Reinforcement learning based local path planning for mobile robot](https://arxiv.org/abs/2403.12463) | 该论文基于强化学习提出了一种新的移动机器人局部路径规划方法，克服了离线系统中重新规划和映射的需求以及在线系统中动态感应数据要求的问题。 |
| [^48] | [Topological Representations of Heterogeneous Learning Dynamics of Recurrent Spiking Neural Networks](https://arxiv.org/abs/2403.12462) | 本文引入了一种新的方法，使用RTD来衡量不同学习方法下复发性尖峰神经网络（RSNN）模型分布式表示之间的差异。 |
| [^49] | [Non-negative Contrastive Learning](https://arxiv.org/abs/2403.12459) | 非负对比学习(NCL)是对非负矩阵分解(NMF)的重新演绎，通过对特征施加非负约束来获得可解释的特征，保留了NMF的可解释属性，从而得到比标准对比学习(CL)更稀疏和解耦的表示 |
| [^50] | [INSIGHT: End-to-End Neuro-Symbolic Visual Reinforcement Learning with Language Explanations](https://arxiv.org/abs/2403.12451) | 本文提出了一种可以同时学习结构化状态和符号策略的框架，通过将视觉基础模型提炼成可扩展的感知模块来克服效率瓶颈，并利用大的语言模型生成简洁易读的语言解释。 |
| [^51] | [Do Generated Data Always Help Contrastive Learning?](https://arxiv.org/abs/2403.12448) | 生成的高质量图像已成功应用于增强对比表示学习，但我们发现有时生成的数据甚至会对对比学习造成伤害，通过研究发现更强的数据膨胀应该伴随着更弱的增强。 |
| [^52] | [Geometric Constraints in Deep Learning Frameworks: A Survey](https://arxiv.org/abs/2403.12431) | 本调查研究了几何约束和深度学习框架之间的重合部分，比较了深度估计等问题中集成在深度学习框架中的几何强制约束。 |
| [^53] | [STG-Mamba: Spatial-Temporal Graph Learning via Selective State Space Model](https://arxiv.org/abs/2403.12418) | STG-Mamba 是首个利用选择性状态空间模型进行时空图学习的研究，将STG网络视为系统，并采用图选择性状态空间模块（GS3B）精确表征STG的动态演化。 |
| [^54] | [On Predictive planning and counterfactual learning in active inference](https://arxiv.org/abs/2403.12417) | 主动推断中提出了基于“规划”和“从经验中学习”两种决策方案，并引入了一个混合模型以平衡数据复杂性，提供了可解释的智能决策制定框架。 |
| [^55] | [Offline Imitation of Badminton Player Behavior via Experiential Contexts and Brownian Motion](https://arxiv.org/abs/2403.12406) | 本文提出了RallyNet，这是一种新颖的用于羽毛球运动员行为的分层离线模仿学习模型，能够捕捉选手的决策依赖关系，解决了直接应用现有方法时可能遇到的层次结构和轮流采取行动导致的复合效应问题。 |
| [^56] | [Towards Interpretable Hate Speech Detection using Large Language Model-extracted Rationales](https://arxiv.org/abs/2403.12403) | 利用大型语言模型提取原因特征训练仇恨言论分类器，实现可解释的检测方法 |
| [^57] | [Finding the Missing Data: A BERT-inspired Approach Against Package Loss in Wireless Sensing](https://arxiv.org/abs/2403.12400) | 提出了一种基于BERT的深度学习模型CSI-BERT，可以在目标数据集上以自监督方式进行训练，捕捉不同子载波之间的顺序关系，从而实现更低的错误率和更快的速度，即使面对高丢包率。 |
| [^58] | [AraPoemBERT: A Pretrained Language Model for Arabic Poetry Analysis](https://arxiv.org/abs/2403.12392) | AraPoemBERT 是一种专门针对阿拉伯诗歌文本进行预训练的语言模型，在阿拉伯诗歌相关的NLP任务中表现出色，取得了两项新颖任务中的前所未有的高准确率。 |
| [^59] | [FairSTG: Countering performance heterogeneity via collaborative sample-level optimization](https://arxiv.org/abs/2403.12391) | FairSTG通过协作样本级优化对抗性能异质性，提出了一个模型独立的面向公平性的时空图学习框架，通过协作挑战性样本与已学习样本的 mix-up 实现知识转移。 |
| [^60] | [Interpretable User Satisfaction Estimation for Conversational Systems with Large Language Models](https://arxiv.org/abs/2403.12388) | 本文提出了一种名为SPUR的方法，通过LLMs更有效地从自然语言话语中提取用户满意度的可解释信号，并能够利用迭代提示框架进行用户满意度评估。 |
| [^61] | [Pipelined Biomedical Event Extraction Rivaling Joint Learning](https://arxiv.org/abs/2403.12386) | 本文提出了一种基于BERT预训练模型的n元关系提取方法，用于改进Binding事件的性能，从而提高分阶段生物医学事件提取的整体性能。 |
| [^62] | [Characteristic AI Agents via Large Language Models](https://arxiv.org/abs/2403.12368) | 该研究通过模拟现实个体，探讨了大型语言模型在构建特征化AI代理方面的性能，为这一任务创建了新的基准数据集和评估指标。 |
| [^63] | [Approximated Likelihood Ratio: A Forward-Only and Parallel Framework for Boosting Neural Network Training](https://arxiv.org/abs/2403.12320) | 该论文提出了一种近似似然比方法，通过在反向传递过程中利用自然并行性，提供了一种高性能训练策略，以减轻神经网络训练中的计算和内存需求。 |
| [^64] | [Reinforcement Learning from Delayed Observations via World Models](https://arxiv.org/abs/2403.12309) | 本文提出了一种通过世界模型处理观察延迟的方法，可有效处理部分可观察性，相比现有方法，实验表明其中一种方法可以胜过朴素方法达到30%的性能提升。 |
| [^65] | [Gradient-based Fuzzy System Optimisation via Automatic Differentiation -- FuzzyR as a Use Case](https://arxiv.org/abs/2403.12308) | 本文讨论了基于梯度下降的模糊系统优化，并专注于自动微分，旨在从机器学习的角度推动模糊系统设计的进步 |
| [^66] | [Molecular Classification Using Hyperdimensional Graph Classification](https://arxiv.org/abs/2403.12307) | 我们的工作引入了一种基于高维计算的图学习方法，在分子分类中表现出与先进模型相媲美的结果，并且在性能上取得了显著的提升。 |
| [^67] | [Leveraging Large Language Models to Extract Information on Substance Use Disorder Severity from Clinical Notes: A Zero-shot Learning Approach](https://arxiv.org/abs/2403.12297) | 该研究利用大型语言模型从临床记录中提取物质使用障碍严重程度信息，克服了传统自然语言处理方法在解析复杂临床语言方面的局限性 |
| [^68] | [Reference-based Metrics Disprove Themselves in Question Generation](https://arxiv.org/abs/2403.12242) | 基于参考文献的指标在问句生成中被推翻，作者提出了一个无需参考文献的多维标准评估方法。 |
| [^69] | [Efficient Transformer-based Hyper-parameter Optimization for Resource-constrained IoT Environments](https://arxiv.org/abs/2403.12237) | 本文提出了一种通过将Transformer架构和演员-评论家强化学习模型相结合的新方法TRL-HPO，在资源受限的IoT环境中实现了高效的超参数优化，该方法在MNIST数据集上表现优良。 |
| [^70] | [Evaluating Named Entity Recognition: Comparative Analysis of Mono- and Multilingual Transformer Models on Brazilian Corporate Earnings Call Transcriptions](https://arxiv.org/abs/2403.12212) | 本研究通过引入新方法，将标记分类任务重新构建为文本生成问题，评估了在巴西银行财报电话转录中使用的单语和多语言Transformer模型的性能。 |
| [^71] | [A Unified Model for Longitudinal Multi-Modal Multi-View Prediction with Missingness](https://arxiv.org/abs/2403.12211) | 该研究提出了一种用于处理纵向多模态多视图数据缺失的统一模型，能够利用所有可用数据进行预测。 |
| [^72] | [Synthetic Image Generation in Cyber Influence Operations: An Emergent Threat?](https://arxiv.org/abs/2403.12207) | 人工智能的进步使得数字内容生成方式发生变革，本报告重点探讨了生成深度学习模型在制作合成图像方面的潜力和局限，尤其在网络影响行动中的应用表明了其目前的能力和限制。 |
| [^73] | [Compositional learning of functions in humans and machines](https://arxiv.org/abs/2403.12201) | 人类和神经网络模型通过结合学习和推理探索组合函数的能力，不仅能够进行简单的顺序函数串联，还能理解更复杂的交互函数组合，具有广泛的应用潜力。 |
| [^74] | [E2F-Net: Eyes-to-Face Inpainting via StyleGAN Latent Space](https://arxiv.org/abs/2403.12197) | 本文提出了一种基于GAN的模型，E2F-Net，通过显著提取眼部区域的身份和非身份特征，并将其映射到预训练的StyleGAN生成器的潜空间，实现了眼睛到脸部的修复。 |
| [^75] | [Shifting the Lens: Detecting Malware in npm Ecosystem with Large Language Models](https://arxiv.org/abs/2403.12196) | 通过大型语言模型在npm生态系统中进行实证研究，以协助安全分析师识别恶意软件包 |
| [^76] | [MAC Advice for Facility Location Mechanism Design](https://arxiv.org/abs/2403.12181) | 研究了具有MAC（大致和近似正确）预测的策略性设施选址机制设计问题，挑战传统最坏情况分析，展示了对于策略无效设施选址的改进。 |
| [^77] | [Safety Implications of Explainable Artificial Intelligence in End-to-End Autonomous Driving](https://arxiv.org/abs/2403.12176) | 自动驾驶中可解释人工智能的安全影响对于确保车辆自动化安全至关重要，但当前研究中安全性和可解释性方面往往被分开砠。 |
| [^78] | [TnT-LLM: Text Mining at Scale with Large Language Models](https://arxiv.org/abs/2403.12173) | TnT-LLM 提出了一个两阶段框架，利用大规模语言模型自动化生成和分配标签，减少人力成本。 |
| [^79] | [Graph-Jigsaw Conditioned Diffusion Model for Skeleton-based Video Anomaly Detection](https://arxiv.org/abs/2403.12172) | 提出了一种名为GiCiSAD的基于图拼图条件扩散模型，用于解决基于骨架的视频异常检测中的挑战。 |
| [^80] | [EasyJailbreak: A Unified Framework for Jailbreaking Large Language Models](https://arxiv.org/abs/2403.12171) | EasyJailbreak是一个统一框架，简化了对LLMs进行越狱攻击的构建和评估，支持11种越狱方法，帮助进行广泛范围LLMs的安全验证。 |
| [^81] | [Intelligent Execution through Plan Analysis](https://arxiv.org/abs/2403.12162) | 提出了一种在执行机器人任务时利用计划分析寻找和储存更好计划机会的技术，通过监控系统在执行过程中修复计划来取代从头重新规划的优势得到实验证实。 |
| [^82] | [Routing and Scheduling in Answer Set Programming applied to Multi-Agent Path Finding: Preliminary Report](https://arxiv.org/abs/2403.12153) | 提出了在答案集编程中捕捉时间流逝的替代方法，这在建模路由方面是一种有趣的选择，但在调度方面却是不存在替代方案的。 |
| [^83] | [Fusing Domain-Specific Content from Large Language Models into Knowledge Graphs for Enhanced Zero Shot Object State Classification](https://arxiv.org/abs/2403.12151) | 大型语言模型与知识图谱结合，提高零样本对象状态分类性能 |
| [^84] | [Graph Neural Networks for Learning Equivariant Representations of Neural Networks](https://arxiv.org/abs/2403.12143) | 本研究提出了将神经网络表示为参数的计算图的方法，利用图神经网络和变压器来实现置换对称性，使得单个模型能够处理具有多种架构的神经计算图。 |
| [^85] | [Safety Analysis of Autonomous Railway Systems: An Introduction to the SACRED Methodology](https://arxiv.org/abs/2403.12114) | SACRED是一种安全方法论，用于为自主系统生成初步安全方案并确定重要安全指标。 |
| [^86] | [GCAM: Gaussian and causal-attention model of food fine-grained recognition](https://arxiv.org/abs/2403.12109) | 提出了一种采用高斯和因果关注模型进行食物细粒度识别的方法，通过训练获取目标区域上的高斯特征和从对象中提取细粒度特征来增强特征映射能力，同时采用反事实推理方法对抗数据漂移。 |
| [^87] | [Does AI help humans make better decisions? A methodological framework for experimental evaluation](https://arxiv.org/abs/2403.12108) | 引入一种新的实验框架用于评估人类是否通过使用AI可以做出更好的决策，在单盲实验设计中比较了三种决策系统的表现 |
| [^88] | [Scenarios for the Transition to AGI](https://arxiv.org/abs/2403.12107) | 分析了不同的技术进步场景对人工通用智能过渡的影响，探讨了自动化和资本积累之间的关系以及工资变化趋势。 |
| [^89] | [Circular Belief Propagation for Approximate Probabilistic Inference](https://arxiv.org/abs/2403.12106) | 循环信念传播（CBP）是对Belief Propagation（BP）的扩展，通过学习检测和取消循环引起的消息反响来限制错误相关和信念放大的不利影响，在二元概率图上表现优于BP和先前提出的算法。 |
| [^90] | [Learning Time Slot Preferences via Mobility Tree for Next POI Recommendation](https://arxiv.org/abs/2403.12100) | 本文引入了“移动树”数据结构，用于学习用户跨不同时间段的偏好，以提升下一个POI推荐任务的性能。 |
| [^91] | [Deep Generative Design for Mass Production](https://arxiv.org/abs/2403.12098) | 通过将与压铸和注塑相关的约束集成到生成设计中，利用二维深度图像将复杂的3D几何形状简化为可制造的轮廓，消除不可制造特性，将重点放在厚度和肋设计等制造重要方面。 |
| [^92] | [Enriching User Shopping History: Empowering E-commerce with a Hierarchical Recommendation System](https://arxiv.org/abs/2403.12096) | 通过预测缺失的用户购物历史部分并适当丰富它，可以提高推荐系统的准确性。 |
| [^93] | [Are LLMs Good Cryptic Crossword Solvers?](https://arxiv.org/abs/2403.12094) | 本文建立了三种流行LLMs的基准结果，表明它们在难解填字游戏上的表现仍远远不及人类。 |
| [^94] | [Learning Macroeconomic Policies based on Microfoundations: A Stackelberg Mean Field Game Approach](https://arxiv.org/abs/2403.12093) | 本研究提出了基于Stackelberg Mean Field Game的方法，可以有效地学习宏观经济政策，并在模型预训练和无模型Stackelberg均场强化学习算法的基础上取得了实验结果表明其优越性。 |
| [^95] | [Methods for Matching English Language Addresses](https://arxiv.org/abs/2403.12092) | 该研究定义并规范了生成英语地址匹配对的框架，并研究了距离基准方法到深度学习模型等各种方法之间的精度、召回率和准确度，以确定最适合地址匹配任务的方法。 |
| [^96] | [Foundation Models and Information Retrieval in Digital Pathology](https://arxiv.org/abs/2403.12090) | 论文回顾了数字病理学中基础模型和信息检索领域的最新进展。 |
| [^97] | [The Boy Who Survived: Removing Harry Potter from an LLM is harder than reported](https://arxiv.org/abs/2403.12082) | 通过小规模实验发现，从LLM中删除哈利波特内容比先前报道的更加困难。 |
| [^98] | [Evaluating Robustness of Generative Search Engine on Adversarial Factual Questions](https://arxiv.org/abs/2403.12077) | 评估生成式搜索引擎对对抗性事实问题的健壮性，通过对多种生成式搜索引擎进行人类评估，展示了对抗性事实问题在诱导不正确响应方面的有效性。 |
| [^99] | [Neuron-centric Hebbian Learning](https://arxiv.org/abs/2403.12076) | 提出了一种新的神经元中心的赫布学习模型，相较于传统的ABCD规则，将参数减少了从$5W$到$5N$。 |
| [^100] | [Adversarial Nibbler: An Open Red-Teaming Method for Identifying Diverse Harms in Text-to-Image Generation](https://arxiv.org/abs/2403.12075) | 批评了文本到图像生成中模型对非明显攻击的鲁棒性，提出了Adversarial Nibbler Challenge以众包多样化的提示来纠正模型的安全问题 |
| [^101] | [Feasibility of Social-Network-Based eHealth Intervention on the Improvement of Healthy Habits among Children](https://arxiv.org/abs/2403.12073) | 通过基于社交网络的eHealth干预措施，本研究展示了对改善儿童健康习惯的可行性，提供了日常营养和体育活动信息以及虚拟奖励的方式来促进互动。 |
| [^102] | [Tailoring Education with GenAI: A New Horizon in Lesson Planning](https://arxiv.org/abs/2403.12071) | GenAI工具利用先进自然语言处理技术，为教育工作者提供个性化课程规划，通过创新的“交互式超级提示”功能，可定制生成课程计划，评估中包括定量和定性标准。 |
| [^103] | [Fairness Evaluation for Uplift Modeling in the Absence of Ground Truth](https://arxiv.org/abs/2403.12069) | 提出了一个框架，通过生成替代品来充当提升建模活动的反事实标签代理，从而进行更全面的二进制公平性评估。 |
| [^104] | [Design-Space Exploration of SNN Models using Application-Specific Multi-Core Architectures](https://arxiv.org/abs/2403.12061) | 提出了一种基于应用特定多核架构的新型运行时多核架构模拟器“RAVSim”，通过该模拟器，用户可以在执行过程中与模型交互并修改参数值集。 |
| [^105] | [Water-Based Metaheuristics: How Water Dynamics Can Help Us to Solve NP-Hard Problems](https://arxiv.org/abs/2403.12058) | 本论文旨在阐明基于水的元启发式算法之间看似相关但实际差异巨大的研究，探讨它们在搜索方式和解决方案构建方面的不同之处。 |
| [^106] | [Deep learning based detection of collateral circulation in coronary angiographies](https://arxiv.org/abs/2403.12055) | 提出了一种基于深度学习的新方法，用于在冠状动脉造影图像中检测冠状动脉侧枝循环，可进行空间特征提取和时间处理。 |
| [^107] | [Leveraging Spatial and Semantic Feature Extraction for Skin Cancer Diagnosis with Capsule Networks and Graph Neural Networks](https://arxiv.org/abs/2403.12009) | 本研究通过将图神经网络与胶囊网络相结合，提出了一种创新方法来增强皮肤癌诊断的分类性能。 |
| [^108] | [Exploring Facial Expression Recognition through Semi-Supervised Pretraining and Temporal Modeling](https://arxiv.org/abs/2403.11942) | 该论文通过半监督学习技术生成表情类别伪标签，实现了面部表情识别模型的泛化能力，在面临数据集限制和类别不平衡问题时取得了优异的识别性能。 |
| [^109] | [Reinforcement Learning with Latent State Inference for Autonomous On-ramp Merging under Observation Delay](https://arxiv.org/abs/2403.11852) | 本文提出了一种具有潜在状态推断的强化学习方法，用于解决自动匝道合并问题，在没有详细了解周围车辆意图或驾驶风格的情况下安全执行匝道合并任务，并考虑了观测延迟，以增强代理在动态交通状况中的决策能力。 |
| [^110] | [Meta-Prompting for Automating Zero-shot Visual Recognition with LLMs](https://arxiv.org/abs/2403.11755) | 提出了Meta-Prompting for Visual Recognition (MPVR)方法，通过仅需少量信息即可自动化零样本识别中的提示生成过程。 |
| [^111] | [SmartRefine: An Scenario-Adaptive Refinement Framework for Efficient Motion Prediction](https://arxiv.org/abs/2403.11492) | SmartRefine提出了一种场景自适应细化策略，可在最小的额外计算量下对运动预测进行细化 |
| [^112] | [Automated data processing and feature engineering for deep learning and big data applications: a survey](https://arxiv.org/abs/2403.11395) | 现代人工智能方法旨在设计能够直接从数据中学习的算法，自动化数据处理任务的兴起驱动了机器学习和大数据应用中利用大量复杂数据的发展。 |
| [^113] | [CPA-Enhancer: Chain-of-Thought Prompted Adaptive Enhancer for Object Detection under Unknown Degradations](https://arxiv.org/abs/2403.11220) | 提出了一种用于未知退化下目标检测的链式思维驱动自适应增强器CPA-Enhancer，并将其集成到通用检测器中，有效提升受损图像的检测性能 |
| [^114] | [DTOR: Decision Tree Outlier Regressor to explain anomalies](https://arxiv.org/abs/2403.10903) | DTOR是一种决策树异常值回归器，通过估计异常检测模型生成的异常分数来产生基于规则的解释，具有鲁棒性，适用于具有大量特征数据集。 |
| [^115] | [Safety Cases: Justifying the Safety of Advanced AI Systems](https://arxiv.org/abs/2403.10462) | 本研究提出了一个安全案例框架来组织人工智能系统的安全性论证，包括四类论点：完全无法造成灾难，强大的控制措施，尽管有可能造成伤害，但依然可信赖，以及对可信的人工智能顾问的尊重。 |
| [^116] | [AI-enhanced Collective Intelligence: The State of the Art and Prospects](https://arxiv.org/abs/2403.10433) | 人类和人工智能形成的多层次集体智能网络，可以实现超越任一单独实体的集体智能水平。 |
| [^117] | [Large Language Models to Generate System-Level Test Programs Targeting Non-functional Properties](https://arxiv.org/abs/2403.10086) | 本文提出使用大型语言模型（LLMs）生成测试程序，以优化非功能属性。 |
| [^118] | [Predicting Generalization of AI Colonoscopy Models to Unseen Data](https://arxiv.org/abs/2403.09920) | 使用“Masked Siamese Network”（MSN）在未标记数据上识别新现象，并预测结肠镜模型对未知技术和不同国家数据的性能。 |
| [^119] | [Fisher Mask Nodes for Language Model Merging](https://arxiv.org/abs/2403.09891) | 介绍了一种用于Transformers的新型模型合并方法，利用Fisher信息进行加权平均，提高了多任务模型的性能。 |
| [^120] | [FoldToken: Learning Protein Language via Vector Quantization and Beyond](https://arxiv.org/abs/2403.09673) | 通过将蛋白质序列和结构表示为离散符号，并创建新的蛋白质语言，从而构建了一种用于序列-结构共生产的创新方法。 |
| [^121] | [STREAM: Spatio-TempoRal Evaluation and Analysis Metric for Video Generative Models](https://arxiv.org/abs/2403.09669) | 提出了STREAM，一种新的视频评估度量方法，弥补了当前视频生成模型评估中对于时空特性的不足 |
| [^122] | [A Reinforcement Learning Approach to Dairy Farm Battery Management using Q Learning](https://arxiv.org/abs/2403.09499) | 该研究提出了一种基于Q学习的算法，以实现在奶牛养殖中整合可再生能源，以改善电池管理，应对电能消耗波动和能源价格波动的挑战。 |
| [^123] | [Clinical Reasoning over Tabular Data and Text with Bayesian Networks](https://arxiv.org/abs/2403.09481) | 本文比较和讨论了如何将贝叶斯网络与神经文本表示相结合，以改进临床推理，特别是在处理自然语言数据方面。 |
| [^124] | [Reproducibility and Geometric Intrinsic Dimensionality: An Investigation on Graph Neural Network Research](https://arxiv.org/abs/2403.08438) | 本文研究了图神经网络研究中的再现性和几何内在维度性问题，并引入机器学习中的再现性本体论，以及探讨了维度诅咒对数据收集、表示和分析的挑战。 |
| [^125] | [RLingua: Improving Reinforcement Learning Sample Efficiency in Robotic Manipulations With Large Language Models](https://arxiv.org/abs/2403.06420) | RLingua提出了一个框架，利用大型语言模型的内部知识来提高机器人操作中强化学习的样本效率。 |
| [^126] | [Can LLM Substitute Human Labeling? A Case Study of Fine-grained Chinese Address Entity Recognition Dataset for UAV Delivery](https://arxiv.org/abs/2403.06097) | 提出了适用于无人机交付系统中地址解析任务的细粒度中文姓名实体识别数据集CNER-UAV，包含五个类别的多样化数据，经过严格的数据清洗和去敏处理，约有12,000个标注样本，评估了传统的实体识别模型并提供了深入分析 |
| [^127] | [CarbonNet: How Computer Vision Plays a Role in Climate Change? Application: Learning Geomechanics from Subsurface Geometry of CCS to Mitigate Global Warming](https://arxiv.org/abs/2403.06025) | 这项研究介绍了一种利用计算机视觉从地下储存空间几何图像中预测陆地表面位移的新方法，为碳捕集和封存项目中的决策提供支持。 |
| [^128] | [ChatASU: Evoking LLM's Reflexion to Truly Understand Aspect Sentiment in Dialogues](https://arxiv.org/abs/2403.05326) | 本文提出了一个新的基于聊天的方面情绪理解（ChatASU）任务，旨在探索大型语言模型（LLMs）在对话场景中理解方面情绪的能力，并引入了一个子任务Aspect Chain Reasoning（ACR）任务来解决方面共指问题。 |
| [^129] | [A Library of Mirrors: Deep Neural Nets in Low Dimensions are Convex Lasso Models with Reflection Features](https://arxiv.org/abs/2403.01046) | 证明在1-D数据上训练神经网络等价于解决一个具有固定特征字典矩阵的凸Lasso问题，为全局最优网络和解空间提供了洞察。 |
| [^130] | [Exploring the Impact of Large Language Models on Recommender Systems: An Extensive Review](https://arxiv.org/abs/2402.18590) | 大型语言模型在推荐系统中展现出卓越的推荐能力和语言理解，重塑了推荐任务的基础。 |
| [^131] | [Big data analytics to classify earthwork-related locations: A Chengdu study](https://arxiv.org/abs/2402.14698) | 使用大数据分析方法，研究者利用自卸车轨迹、城市兴趣点和土地覆盖数据，成功对城市灰尘污染源进行了分类，证明仅需有限数量特征即可实现高准确度分类。 |
| [^132] | [Controlling Large Electric Vehicle Charging Stations via User Behavior Modeling and Stochastic Programming](https://arxiv.org/abs/2402.13224) | 本文介绍了一个新的电动汽车充电站模型，通过用户行为建模和随机规划，解决了充电会话不确定性问题，并提出了两种方法来优化成本并提高用户满意度。 |
| [^133] | [Gaussian Process Neural Additive Models](https://arxiv.org/abs/2402.12518) | 本文提出了一种新的高斯过程神经加性模型（GP-NAM），通过随机傅里叶特征对高斯过程进行单层神经网络构建，可以实现具有凸目标函数和可训练参数数量随特征维度线性增长的优势，同时在性能上不亚于更深的NAM方法。 |
| [^134] | [Towards Reducing Diagnostic Errors with Interpretable Risk Prediction](https://arxiv.org/abs/2402.10109) | 本研究提出了一种使用LLMs方法来识别病人电子病历数据中指示特定诊断风险增加或减少的证据的方法，旨在通过增加证据的获取与减少诊断错误来降低诊断错误。模型使用神经加性模型进行预测，以证据为后盾，并给出个体化风险估计，特别针对诊断延迟和来自不完整鉴别的错误进行优化。 |
| [^135] | [Guiding Masked Representation Learning to Capture Spatio-Temporal Relationship of Electrocardiogram](https://arxiv.org/abs/2402.09450) | 本研究提出了一种叫做ST-MEM的模型，通过重构遮蔽的心电图数据来学习时空特征，该模型在心律失常分类任务中优于其他自监督学习方法。 |
| [^136] | [Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey](https://arxiv.org/abs/2402.09283) | 这篇调查提供了LLM对话安全性的全面概述，涵盖了攻击、防御和评估三个关键方面，旨在提高对该主题的理解并促进进一步的研究。 |
| [^137] | [Unveiling Latent Causal Rules: A Temporal Point Process Approach for Abnormal Event Explanation](https://arxiv.org/abs/2402.05946) | 本文提出了一种基于时间点过程的方法，通过揭示潜在因果规律来解释异常事件，以帮助在高风险系统如医疗保健中快速诊断和精确治疗规划。该方法通过期望最大化算法优化规则集和模型参数，实现了准确的规则发现和根因识别。 |
| [^138] | [RA-Rec: An Efficient ID Representation Alignment Framework for LLM-based Recommendation](https://arxiv.org/abs/2402.04527) | 这篇论文提出了一种基于LLM的推荐系统的高效ID表示对齐框架RA-Rec，通过将预训练的ID嵌入到LLMs中，并设计创新的对齐模块和高效调整方法，实现了在推荐系统中的显著性能优化。 |
| [^139] | [A Graph is Worth $K$ Words: Euclideanizing Graph using Pure Transformer](https://arxiv.org/abs/2402.02464) | 这篇论文介绍了GraphsGPT，它使用纯Transformer将非欧几里德图形转换为在欧几里德空间中可学习的图形单词，并通过解码器将图形单词重新构建为原始图形，保证了信息的等价性。预训练的GraphsGPT在图形表示学习和图形生成方面取得了突出成果。 |
| [^140] | [Arithmetic Feature Interaction Is Necessary for Deep Tabular Learning](https://arxiv.org/abs/2402.02334) | 本文研究了深度表格学习中算术特征交互的必要性，通过引入AMFormer模型，实现了在细粒度表格数据建模、训练数据效率和泛化方面的优越性能。 |
| [^141] | [Vertical Federated Image Segmentation](https://arxiv.org/abs/2401.07931) | 提出了一种垂直联邦学习（VFL）模型架构，适用于数据分散于不同数据孤岛的场景，解决了部分地区数据无法访问标记真相，但需要进行分类的问题。 |
| [^142] | [SynCDR : Training Cross Domain Retrieval Models with Synthetic Data](https://arxiv.org/abs/2401.00420) | 通过生成合成数据填补跨域检索中缺失的类别示例，解决了不同领域之间共享类别数据不足的问题。 |
| [^143] | [MaxK-GNN: Towards Theoretical Speed Limits for Accelerating Graph Neural Networks Training](https://arxiv.org/abs/2312.08656) | MaxK-GNN是一种先进的高性能GPU训练系统，通过MaxK非线性和理论分析，实现了图神经网络训练的垂直优化。 |
| [^144] | [Genixer: Empowering Multimodal Large Language Models as a Powerful Data Generator](https://arxiv.org/abs/2312.06731) | Genixer是一种为生成高质量指导数据而设计的创新数据生成管道，包括九个代表性任务，提供了四个关键步骤来改善数据生成的难度。 |
| [^145] | [Low-power, Continuous Remote Behavioral Localization with Event Cameras](https://arxiv.org/abs/2312.03799) | 使用低功耗事件摄像头对南极企鹅行为进行连续远程定位，将问题定义为时间动作检测任务并成功开发了相应方法 |
| [^146] | [On the Diversity and Realism of Distilled Dataset: An Efficient Dataset Distillation Paradigm](https://arxiv.org/abs/2312.03526) | 我们提出了一种新颖的计算效率高且有效的数据精炼范式RDED，以实现数据的多样性和现实性。 |
| [^147] | [Learning Multi-Pattern Normalities in the Frequency Domain for Efficient Time Series Anomaly Detection](https://arxiv.org/abs/2311.16191) | MACE是一种在频域中适应多正常模式且高效的时间序列异常检测方法，其创新之处在于采用优秀的模式提取机制，使模型能够通过检查数据样本与其服务正常模式之间的相关性来识别异常。 |
| [^148] | [Align before Adapt: Leveraging Entity-to-Region Alignments for Generalizable Video Action Recognition](https://arxiv.org/abs/2311.15619) | 提出了一种“对齐前自适应”（ALT）范式，通过利用实体到区域对齐，将文本嵌入作为查询，从而帮助提取视频中最重要实体的语义。 |
| [^149] | [Accurate and interpretable drug-drug interaction prediction enabled by knowledge subgraph learning](https://arxiv.org/abs/2311.15056) | 通过知识子图学习的方法，本研究提出了一种解决药物相互作用预测中样本稀缺性挑战的图神经网络模型，能够准确且可解释地预测药物之间的相互作用。 |
| [^150] | [RLIF: Interactive Imitation Learning as Reinforcement Learning](https://arxiv.org/abs/2311.12996) | 本文探讨了离策略强化学习如何在类似但潜在上更实用的假设下提供比交互式模仿学习更好的性能。 |
| [^151] | [Do Physicians Know How to Prompt? The Need for Automatic Prompt Optimization Help in Clinical Note Generation](https://arxiv.org/abs/2311.09684) | 本研究提出了自动提示优化（APO）框架，评估了不同提示对于大型语言模型在临床笔记生成中性能的影响，结果表明GPT4 APO在标准化提升质量方面表现出色，并强调了专家定制化对于内容质量的价值。 |
| [^152] | [Aria-NeRF: Multimodal Egocentric View Synthesis](https://arxiv.org/abs/2311.06455) | 通过类似于NeRF的模型和多模态传感器的组合，我们实现了从主观数据训练的丰富多模态场景模型，有望提升智能代理的能力。 |
| [^153] | [Establishing Performance Baselines in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting for Non-Specialist LLM Users](https://arxiv.org/abs/2311.05903) | 通过对GPT 3.5进行微调，并结合基于向量的RAG数据库和非算法软提示，建立了性能基线，发现在特定的测试条件下微调模型表现更好。 |
| [^154] | [TabRepo: A Large Scale Repository of Tabular Model Evaluations and its AutoML Applications](https://arxiv.org/abs/2311.02971) | TabRepo引入了一个包含1310个模型在200个分类和回归数据集上评估预测结果和指标信息的数据集，展示了它在进行超参数优化、AutoML系统比较和迁移学习等方面的优势。 |
| [^155] | [Contextual Refinement of Translations: Large Language Models for Sentence and Document-Level Post-Editing](https://arxiv.org/abs/2310.14855) | 大型语言模型在神经机器翻译中表现尚未达到最先进水平，提出使用LLM作为自动后编辑器(APE)的替代方法，同时探索了扩展到文档级翻译的可能性。 |
| [^156] | [Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement](https://arxiv.org/abs/2310.08559) | 对语言模型进行的系统研究揭示了它们在假设提出方面表现惊人，并且通过与一个（任务特定的）符号解释器相结合，能够系统地过滤可能性。 |
| [^157] | [Language Modeling Is Compression](https://arxiv.org/abs/2309.10668) | 大型语言模型被证明是强大的压缩器，压缩视角为扩展定律、标记化和上下文学习提供了新的见解。 |
| [^158] | [EasyEdit: An Easy-to-use Knowledge Editing Framework for Large Language Models](https://arxiv.org/abs/2308.07269) | EasyEdit提出了一种易于使用的知识编辑框架，针对大型语言模型的知识截断或谬误问题，支持各种最新的知识编辑方法，并可应用于多个知名的LLMs。 |
| [^159] | [Radiology-GPT: A Large Language Model for Radiology](https://arxiv.org/abs/2306.08666) | Radiology-GPT是一个专门为放射学设计的大型语言模型，通过使用指导调整方法进行训练，在放射学诊断、研究和沟通方面展示出优越性能，为临床NLP的未来发展提供推动力。 |
| [^160] | [Cross or Wait? Predicting Pedestrian Interaction Outcomes at Unsignalized Crossings](https://arxiv.org/abs/2304.08260) | 本文利用机器学习预测行人在无信号交叉口与车辆互动时的过马路行为，提出的神经网络模型在预测准确性和F1分数上取得了显著的改进。 |
| [^161] | [Toward a Theory of Causation for Interpreting Neural Code Models](https://arxiv.org/abs/2302.03788) | 该论文介绍了一种名为$do_{code}$的后验解释方法，用于解释神经代码模型的预测，基于因果推断，旨在实现面向编程语言的解释。 |
| [^162] | [Deep Recurrent Learning Through Long Short Term Memory and TOPSIS](https://arxiv.org/abs/2301.00693) | 该论文提出了一种基于长短期记忆（LSTM）和TOPSIS的分类算法，用于识别和排名云ERP的采用特征。 |
| [^163] | [Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling.](http://arxiv.org/abs/2401.09516) | 该论文提出了一种名为排序克里洛夫回收（SKR）的新方法，用于加速神经算子训练的数据生成。该方法解决了现有方法在解决PDE问题时计算冗余的问题，显著提高了数据生成效率。 |
| [^164] | [Multi-task robot data for dual-arm fine manipulation.](http://arxiv.org/abs/2401.07603) | 这篇论文介绍了一个多任务机器人数据集，其中包括双臂精细操作和需要精细操作的任务，并且公开可用。 |
| [^165] | [Revisiting Zero-Shot Abstractive Summarization in the Era of Large Language Models from the Perspective of Position Bias.](http://arxiv.org/abs/2401.01989) | 这项研究通过测量位置偏见，重访了大语言模型中的零-shot 抽象摘要。研究结果揭示了模型不公平地优先考虑某些部分的信息，从而导致不可取的行为。对多个LLM模型和预训练抽象摘要模型进行的实验提供了关于零-shot 总结任务的模型性能和位置偏见的新见解和讨论。 |
| [^166] | [Designing AI Support for Human Involvement in AI-assisted Decision Making: A Taxonomy of Human-AI Interactions from a Systematic Review.](http://arxiv.org/abs/2310.19778) | 通过对AI辅助决策文献的系统回顾，我们填补了人机交互协议的共同词汇的空白，并强调了解AI应该提供什么信息来帮助人类的重要性。 |
| [^167] | [Learning Successor Representations with Distributed Hebbian Temporal Memory.](http://arxiv.org/abs/2310.13391) | 本文提出了一种名为DHTM的算法，它基于因子图形式和多组成神经元模型，利用分布式表示、稀疏转移矩阵和局部Hebbian样学习规则来解决在线隐藏表示学习的挑战。实验结果表明，DHTM在变化的环境中比经典的LSTM效果更好，并与更先进的类似RNN的算法性能相当，可以加速继任者表示的时间差异学习。 |
| [^168] | [Evaluating LLMs for Privilege-Escalation Scenarios.](http://arxiv.org/abs/2310.11409) | 本研究评估了在特权升级场景中利用语言模型（LLMs）进行渗透测试的应用。通过创建一个自动化的Linux特权升级基准和一个LLM-guided特权升级工具，我们分析了LLMs的不同提示设计、上下文学习和高级指导对测试的影响，并讨论了LLMs面临的挑战。 |
| [^169] | [3D Reconstruction in Noisy Agricultural Environments: A Bayesian Optimization Perspective for View Planning.](http://arxiv.org/abs/2310.00145) | 本论文提出了一种在噪声环境中进行3D重建的新方法，通过观测规划，合理选择相机位置并考虑噪声对重建性能的影响，提高了3D重建结果的质量和效率。 |
| [^170] | [Empowering Dynamics-aware Text-to-Video Diffusion with Large Language Models.](http://arxiv.org/abs/2308.13812) | 本文提出了一种新的方法（称为Dysen）来增强面向动态感知的文本到视频扩散，通过提取关键动作、建立动态场景图和丰富细节，以实现高质量的T2V生成。 |
| [^171] | [A Fast and Optimal Learning-based Path Planning Method for Planetary Rovers.](http://arxiv.org/abs/2308.04792) | 本文提出了一种基于学习的快速路径规划方法，通过学习最优路径示范中的语义信息和地图表示，生成概率分布来搜索最优路径。实验结果表明，该方法能够提高行星探测车的探索效率。 |
| [^172] | [A Pre-trained Data Deduplication Model based on Active Learning.](http://arxiv.org/abs/2308.00721) | 提出了一种基于主动学习的预训练去重模型，将Transformer和主动学习集成到端到端架构中，首次解决了语义级别的去重问题，同时采用R-Drop方法对每一轮标记数据进行数据增强。通过选择最有价值的数据进行去重模型训练，不仅降低了手动标记的成本，还提高了模型的泛化能力。 |
| [^173] | [FedDRL: A Trustworthy Federated Learning Model Fusion Method Based on Staged Reinforcement Learning.](http://arxiv.org/abs/2307.13716) | FedDRL是一种分阶段强化学习的联邦学习模型融合方法，解决了传统方法中无法解决的客户端模型质量和恶意模型问题。 |
| [^174] | [SAMAug: Point Prompt Augmentation for Segment Anything Model.](http://arxiv.org/abs/2307.01187) | SAMAug是一种用于增强交互式图像分割性能的方法，通过生成增强的点提示，结合初始提示，可以提高Segment Anything Model的分割结果。 |
| [^175] | [DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genome.](http://arxiv.org/abs/2306.15006) | 本研究提出了DNABERT-2，一个用于多种物种基因组的高效基础模型和基准。我们通过使用基于统计的数据压缩算法Byte Pair Encoding（BPE）替代传统的k-mer标记化，克服了k-mer标记化的计算和样本效率问题，并取得了重要进展。 |
| [^176] | [Granger-Causal Hierarchical Skill Discovery.](http://arxiv.org/abs/2306.09509) | 本文介绍了一种名为HIntS的算法，使用无监督检测器，基于Granger因果性捕捉因素之间的关键事件，发现和训练一系列操作因素化环境中的因素的技能，其展示了在机器人推动任务上有2-3倍的样本效率和最终性能的提高，有效的处理了复杂问题和转移学习。 |
| [^177] | [Ada-NAV: Adaptive Trajectory-Based Sample Efficient Policy Learning for Robotic Navigation.](http://arxiv.org/abs/2306.06192) | Ada-NAV是一种自适应轨迹优化策略学习方法，采用降低策略随机性的方法平衡探索与利用，提高机器人导航任务的采样效率。在真实世界的测试中表现优异，可以在更短的采样时间内取得更高的性能。 |
| [^178] | [LeTI: Learning to Generate from Textual Interactions.](http://arxiv.org/abs/2305.10314) | LeTI是一种使用自然语言指令、LM生成的程序和错误消息进行串联迭代微调的技术，可以用于代码生成任务，并且在自然发生的Python指令数据集上表现最先进。 |
| [^179] | [BugNIST -- A New Large Scale Volumetric 3D Image Dataset for Classification and Detection.](http://arxiv.org/abs/2304.01838) | 本文介绍了一个名为BugNIST的广泛数据集，该数据集由12种昆虫和幼虫的微-CT扫描组成。通过训练和测试检测模型，BugNIST旨在评估三维体积图像分类和检测方法，解决上下文无关的挑战。 |
| [^180] | [On student-teacher deviations in distillation: does it pay to disobey?.](http://arxiv.org/abs/2301.12923) | 通过实验和理论分析，本论文发现在知识蒸馏中，学生网络对教师网络的概率偏离是系统性夸大的，同时也得到了更好的泛化能力。 |
| [^181] | [Explanations, Fairness, and Appropriate Reliance in Human-AI Decision-Making.](http://arxiv.org/abs/2209.11812) | 本研究探讨了基于特征的解释对AI辅助决策公正性的影响，发现解释可以影响公正性感知和人们对AI建议的依赖。然而，解释并不能帮助人们区分正确和错误的AI建议。这些发现对于促进有效的决策和公正性至关重要。 |

# 详细

[^1]: 三维内容生成综述

    A Comprehensive Survey on 3D Content Generation

    [https://rss.arxiv.org/abs/2402.01166](https://rss.arxiv.org/abs/2402.01166)

    本综述对三维内容生成领域的发展进行了全面综合，提出了一种新的分类法，总结了目前的主要技术，并讨论了当前技术的局限性和未来工作的挑战和方向。

    

    近年来，人工智能生成内容（AIGC）取得了显著的进展，具有多种输入模态，如文本、图像、视频、音频和三维。三维是最接近真实世界三维环境的可视模态，并具有巨大的知识量。三维内容生成不仅具有学术和实践价值，而且面临着巨大的技术挑战。本综述旨在整合三维内容生成领域的发展。具体而言，提出了一种新的分类法，将现有方法分为三类：三维本机生成方法、基于二维先验的三维生成方法和混合三维生成方法。本综述涵盖了约60篇涵盖主要技术的论文。此外，我们讨论了当前三维内容生成技术的局限性，并指出了未来工作的挑战和有希望的方向。配合本综述，我们建立了一个项目网站，其中包含了相关资源和代码。

    Recent years have witnessed remarkable advances in artificial intelligence generated content(AIGC), with diverse input modalities, e.g., text, image, video, audio and 3D. The 3D is the most close visual modality to real-world 3D environment and carries enormous knowledge. The 3D content generation shows both academic and practical values while also presenting formidable technical challenges. This review aims to consolidate developments within the burgeoning domain of 3D content generation. Specifically, a new taxonomy is proposed that categorizes existing approaches into three types: 3D native generative methods, 2D prior-based 3D generative methods, and hybrid 3D generative methods. The survey covers approximately 60 papers spanning the major techniques. Besides, we discuss limitations of current 3D content generation techniques, and point out open challenges as well as promising directions for future work. Accompanied with this survey, we have established a project website where the 
    
[^2]: TexTile：一种可微的纹理平铺度量

    TexTile: A Differentiable Metric for Texture Tileability

    [https://arxiv.org/abs/2403.12961](https://arxiv.org/abs/2403.12961)

    TexTile是一种不同iable的度量方法，用于评估纹理图像的平铺性能，可以帮助更明智地合成和分析平铺纹理。

    

    我们引入了TexTile，一种新颖的可微度量方式，用于量化纹理图像可以如何与自身连接而不引入重复伪影（即平铺性）。现有的可平铺纹理合成方法侧重于一般纹理质量，但缺乏对纹理固有可重复性属性的显式分析。相反，我们的TexTile度量有效评估纹理的可平铺性，为更明智的平铺纹理合成和分析打开了大门。在背后，TexTile被构建为一个二元分类器，仔细构建自不同风格、语义、规律和人类注释的大型纹理数据集。我们方法的关键在于一系列架构修改，使基线预训练图像分类器能够克服其在衡量平铺性方面的缺陷，以及针对增加鲁棒性的自定义数据增强和训练方案。

    arXiv:2403.12961v1 Announce Type: cross  Abstract: We introduce TexTile, a novel differentiable metric to quantify the degree upon which a texture image can be concatenated with itself without introducing repeating artifacts (i.e., the tileability). Existing methods for tileable texture synthesis focus on general texture quality, but lack explicit analysis of the intrinsic repeatability properties of a texture. In contrast, our TexTile metric effectively evaluates the tileable properties of a texture, opening the door to more informed synthesis and analysis of tileable textures. Under the hood, TexTile is formulated as a binary classifier carefully built from a large dataset of textures of different styles, semantics, regularities, and human annotations.Key to our method is a set of architectural modifications to baseline pre-train image classifiers to overcome their shortcomings at measuring tileability, along with a custom data augmentation and training regime aimed at increasing rob
    
[^3]: WHAC: 世界基准人类与摄像机

    WHAC: World-grounded Humans and Cameras

    [https://arxiv.org/abs/2403.12959](https://arxiv.org/abs/2403.12959)

    该研究提出了一个名为WHAC的框架，可以实现基于世界坐标系的丰富人体姿势和形状估计，同时进行摄像机姿势估计，无需依赖传统优化技术。

    

    从单目视频中准确估计世界坐标系中具有比例的人类和摄像机轨迹是一项非常理想但具有挑战性和模糊定义的问题。在本研究中，我们旨在通过利用世界、人类和摄像机三个关键要素之间的协同作用，联合恢复表现力强的参数化人体模型（即SMPL-X）和相应的摄像机姿势。我们的方法基于两个关键观察。首先，相机框架下的SMPL-X估计方法可以轻松恢复绝对人类深度。其次，人体动作本质上提供绝对空间线索。通过整合这些见解，我们引入了一个名为WHAC的新颖框架，以促进基于世界的表现力强的人体姿势和形状估计（EHPS），同时进行摄像机姿势估计，无需依赖传统的优化技术。此外，我们提出了一个新的合成数据集WHAC-A-Mole，其中包含了精确注释的信息。

    arXiv:2403.12959v1 Announce Type: cross  Abstract: Estimating human and camera trajectories with accurate scale in the world coordinate system from a monocular video is a highly desirable yet challenging and ill-posed problem. In this study, we aim to recover expressive parametric human models (i.e., SMPL-X) and corresponding camera poses jointly, by leveraging the synergy between three critical players: the world, the human, and the camera. Our approach is founded on two key observations. Firstly, camera-frame SMPL-X estimation methods readily recover absolute human depth. Secondly, human motions inherently provide absolute spatial cues. By integrating these insights, we introduce a novel framework, referred to as WHAC, to facilitate world-grounded expressive human pose and shape estimation (EHPS) alongside camera pose estimation, without relying on traditional optimization techniques. Additionally, we present a new synthetic dataset, WHAC-A-Mole, which includes accurately annotated h
    
[^4]: 只需转移它：测试时间原型转移用于视觉语言模型的零样本泛化

    Just Shift It: Test-Time Prototype Shifting for Zero-Shot Generalization with Vision-Language Models

    [https://arxiv.org/abs/2403.12952](https://arxiv.org/abs/2403.12952)

    引入了测试时间原型转移（TPS）框架，通过动态学习每个原型的转移向量，有效地弥合了领域差距并增强了类

    

    视觉语言模型（VLMs）的进展推动了计算机视觉领域的发展，特别是在零样本学习设置中。尽管它们很有前景，但这些模型的有效性在测试环境中往往会因为领域转移而降低。为了解决这个问题，我们引入了测试时间原型转移（TPS）框架，这是一种旨在使用标记测试输入来使VLM适应测试数据集的开创性方法。我们的方法基于在共享嵌入空间中调节每个类别的原型的概念。通过使用预先训练的文本编码器生成并缓存原型，TPS不仅促进了无需优化的原型重用进行后续预测，还让其能够无缝集成当前进展的提示工程技术。在测试时间，TPS仅基于给定的测试样本动态学习每个原型的转移向量，有效地弥合领域差距并增强类

    arXiv:2403.12952v1 Announce Type: cross  Abstract: Advancements in vision-language models (VLMs) have propelled the field of computer vision, particularly in the zero-shot learning setting. Despite their promise, the effectiveness of these models often diminishes due to domain shifts in test environments. To address this, we introduce the Test-Time Prototype Shifting (TPS) framework, a pioneering approach designed to adapt VLMs to test datasets using unlabeled test inputs. Our method is based on the notion of modulating per-class prototypes in the shared embedding space. By pre-computing and caching prototypes generated with the pre-trained text encoder, TPS not only facilitates optimization-free prototype reuse for subsequent predictions but also enables seamless integration with current advancements in prompt engineering. At test-time, TPS dynamically learns shift vectors for each prototype based solely on the given test sample, effectively bridging the domain gap and enhancing class
    
[^5]: Vid2Robot：基于视频条件化策略学习的端到端交叉注意力变换器

    Vid2Robot: End-to-end Video-conditioned Policy Learning with Cross-Attention Transformers

    [https://arxiv.org/abs/2403.12943](https://arxiv.org/abs/2403.12943)

    Vid2Robot提出了一种新颖的端到端视频条件化策略学习框架，通过交叉注意力机制融合视频特征和机器人状态，直接生成模仿所观察任务的动作。

    

    尽管大规模机器人系统通常依赖文本指令进行任务，但这项工作探索了一种不同的方法：机器人能否直接从观察人类推断任务？这种转变要求机器人能够解码人类意图，并将其转化为可在其物理约束和环境内执行的动作。我们引入了Vid2Robot，这是一种新颖的面向机器人的端到端基于视频的学习框架。给定一个操作任务的视频演示和当前的视觉观察，Vid2Robot直接生成机器人动作。这是通过在大规模人类视频和机器人轨迹数据集上训练的统一表示模型实现的。该模型利用交叉注意力机制来融合提示视频特征与机器人的当前状态，并生成模仿所观察任务的适当动作。为了进一步提高策略性能，我们提出了辅助对比损失，以增强对齐

    arXiv:2403.12943v1 Announce Type: cross  Abstract: While large-scale robotic systems typically rely on textual instructions for tasks, this work explores a different approach: can robots infer the task directly from observing humans? This shift necessitates the robot's ability to decode human intent and translate it into executable actions within its physical constraints and environment. We introduce Vid2Robot, a novel end-to-end video-based learning framework for robots. Given a video demonstration of a manipulation task and current visual observations, Vid2Robot directly produces robot actions. This is achieved through a unified representation model trained on a large dataset of human video and robot trajectory. The model leverages cross-attention mechanisms to fuse prompt video features to the robot's current state and generate appropriate actions that mimic the observed task. To further improve policy performance, we propose auxiliary contrastive losses that enhance the alignment b
    
[^6]: 使用大型语言模型自动提取雇佣法庭裁决中的信息

    Automatic Information Extraction From Employment Tribunal Judgements Using Large Language Models

    [https://arxiv.org/abs/2403.12936](https://arxiv.org/abs/2403.12936)

    本文研究了使用大型语言模型GPT-4自动从英国雇佣法庭案例中提取信息的应用，并通过手动验证确保了提取数据的准确性和相关性

    

    法庭记录和判决是法律知识的丰富资源，详细描述案件的复杂性以及司法决定背后的理由。从这些文件中提取关键信息提供了案件的简明概述，对于法律专家和公众都至关重要。随着大型语言模型（LLMs）的出现，自动信息提取变得越来越可行和高效。本文对GPT-4（一种大型语言模型）在从英国雇佣法庭（UKET）案例中自动提取信息的应用进行了全面研究。我们通过手动验证过程对GPT-4在提取关键信息方面的性能进行了细致评估，以确保提取的数据准确性和相关性。我们的研究围绕两个主要的信息提取任务展开：第一个任务涉及对对法律专家和公众都具有重要意义的八个关键方面进行通用的提取。

    arXiv:2403.12936v1 Announce Type: cross  Abstract: Court transcripts and judgments are rich repositories of legal knowledge, detailing the intricacies of cases and the rationale behind judicial decisions. The extraction of key information from these documents provides a concise overview of a case, crucial for both legal experts and the public. With the advent of large language models (LLMs), automatic information extraction has become increasingly feasible and efficient. This paper presents a comprehensive study on the application of GPT-4, a large language model, for automatic information extraction from UK Employment Tribunal (UKET) cases. We meticulously evaluated GPT-4's performance in extracting critical information with a manual verification process to ensure the accuracy and relevance of the extracted data. Our research is structured around two primary extraction tasks: the first involves a general extraction of eight key aspects that hold significance for both legal specialists
    
[^7]: 在低资源文本上进行预训练语言模型的可泛化和稳定微调

    Generalizable and Stable Finetuning of Pretrained Language Models on Low-Resource Texts

    [https://arxiv.org/abs/2403.12918](https://arxiv.org/abs/2403.12918)

    提出了一种基于注意力引导的权重混合正则化方法，用于解决低资源文本上预训练语言模型微调时的稳定性和泛化能力问题

    

    预训练语言模型（PLMs）在自然语言处理（NLP）任务中取得了显著进展，但在低资源数据集上微调PLMs会面临诸如不稳定性和过拟合等重大挑战。先前的方法通过在下游任务上微调策略选择的子网络，同时保持其余权重固定为预训练权重来解决这些问题。然而，它们依赖于次优的子网络选择标准，导致次优解决方案。为了解决这些限制，我们提出了一种基于注意力引导的权重混合正则化方法，用于微调PLMs。我们的方法将每个网络权重表示为任务特定权重和预训练权重的混合，由可学习的注意力参数控制，提供对子网络选择的更精细控制。此外，我们在训练数据集的两个单独拆分上使用基于双层优化（BLO）的框架，进一步改进

    arXiv:2403.12918v1 Announce Type: cross  Abstract: Pretrained Language Models (PLMs) have advanced Natural Language Processing (NLP) tasks significantly, but finetuning PLMs on low-resource datasets poses significant challenges such as instability and overfitting. Previous methods tackle these issues by finetuning a strategically chosen subnetwork on a downstream task, while keeping the remaining weights fixed to the pretrained weights. However, they rely on a suboptimal criteria for sub-network selection, leading to suboptimal solutions. To address these limitations, we propose a regularization method based on attention-guided weight mixup for finetuning PLMs. Our approach represents each network weight as a mixup of task-specific weight and pretrained weight, controlled by a learnable attention parameter, providing finer control over sub-network selection. Furthermore, we employ a bi-level optimization (BLO) based framework on two separate splits of the training dataset, improving ge
    
[^8]: 对您的机器人大喊：从语言纠正中实时改进

    Yell At Your Robot: Improving On-the-Fly from Language Corrections

    [https://arxiv.org/abs/2403.12910](https://arxiv.org/abs/2403.12910)

    该论文发现，通过人类提供的语言纠正，可以帮助机器人持续改进长久任务表现

    

    合并语言和低级控制的分层策略已经被证明可以实现令人印象深刻的长视野机器人任务，通过利用预训练语言和视觉-语言模型（LLMs/VLMs）或在注释的机器人演示上训练的模型。但是，对于复杂和灵巧的技能，实现在长视野任务上高成功率仍然是一个主要挑战——任务越长，某个阶段失败的可能性就越大。人类可以通过直观自然的反馈帮助机器人持续改进其长视野任务性能吗？本文中我们发现：可以通过富含表达力的低级语言条件技能索引到高水平策略，并能够通过语言纠正的形式进行人类监督。我们表明，甚至精细的纠正，如小动作（“移动

    arXiv:2403.12910v1 Announce Type: cross  Abstract: Hierarchical policies that combine language and low-level control have been shown to perform impressively long-horizon robotic tasks, by leveraging either zero-shot high-level planners like pretrained language and vision-language models (LLMs/VLMs) or models trained on annotated robotic demonstrations. However, for complex and dexterous skills, attaining high success rates on long-horizon tasks still represents a major challenge -- the longer the task is, the more likely it is that some stage will fail. Can humans help the robot to continuously improve its long-horizon task performance through intuitive and natural feedback? In this paper, we make the following observation: high-level policies that index into sufficiently rich and expressive low-level language-conditioned skills can be readily supervised with human feedback in the form of language corrections. We show that even fine-grained corrections, such as small movements ("move a
    
[^9]: 朝向可持续的GenAI：使用生成指令实现碳友好的大型语言模型推断

    Toward Sustainable GenAI using Generation Directives for Carbon-Friendly Large Language Model Inference

    [https://arxiv.org/abs/2403.12900](https://arxiv.org/abs/2403.12900)

    本文提出了Sprout框架，通过引入生成指令的概念，平衡了生态可持续性和高质量生成结果之间的需求，实现了大型语言模型推断服务碳排放的显著减少。

    

    通过广泛应用的生成人工智能（GenAI）的迅速发展，引起了环境方面的重要关注，尤其是来自云和高性能计算基础设施的碳排放。本文提出了Sprout，一个创新的框架，旨在通过减少生成式大型语言模型（LLM）推断服务的碳足迹来解决这些问题。Sprout利用创新概念“生成指令”来引导自回归生成过程，从而增强碳效率。我们提出的方法精心平衡了对生态可持续性和高质量生成成果的需求。通过使用一个指令优化器来对用户提示进行生成指令的战略分配和一个原创的离线质量评估器，Sprout在实际评估中显著减少了40%以上的碳排放。

    arXiv:2403.12900v1 Announce Type: cross  Abstract: The rapid advancement of Generative Artificial Intelligence (GenAI) across diverse sectors raises significant environmental concerns, notably the carbon emissions from their cloud and high performance computing (HPC) infrastructure. This paper presents Sprout, an innovative framework designed to address these concerns by reducing the carbon footprint of generative Large Language Model (LLM) inference services. Sprout leverages the innovative concept of "generation directives" to guide the autoregressive generation process, thereby enhancing carbon efficiency. Our proposed method meticulously balances the need for ecological sustainability with the demand for high-quality generation outcomes. Employing a directive optimizer for the strategic assignment of generation directives to user prompts and an original offline quality evaluator, Sprout demonstrates a significant reduction in carbon emissions by over 40% in real-world evaluations u
    
[^10]: 自适应视觉模仿学习在不同碗配置和食物类型下的机器人辅助喂食中的应用

    Adaptive Visual Imitation Learning for Robotic Assisted Feeding Across Varied Bowl Configurations and Food Types

    [https://arxiv.org/abs/2403.12891](https://arxiv.org/abs/2403.12891)

    提出了一种名为AVIL的自适应视觉模仿学习方法，通过将视觉感知与模仿学习相结合，实现了机器人在不同碗配置和食物类型下的灵活和稳健的辅助喂食。

    

    在这项研究中，我们引入了一种带有空间注意模块的新型视觉模仿网络，用于机器人辅助喂食（RAF）。我们的目标是从碗中获取（即铲取）食物。然而，实现强健和灵活的食物操纵尤其具有挑战性。为了解决这个问题，我们提出了一个框架，将视觉感知与模仿学习相结合，使机器人能够在铲取过程中处理各种不同的情景。我们的方法称为AVIL（自适应视觉模仿学习），在材料、大小和位置等方面的不同碗配置以及包括颗粒状、半固体和液体在内的各种食物类型中展现了适应性和稳健性，甚至在干扰物存在的情况下也是如此。我们通过在实际机器人上进行实验来验证我们方法的有效性。我们还将其与基准线性能进行比较。结果表明，在所有情境下，我们的方法相比基准线性能有所提升。

    arXiv:2403.12891v1 Announce Type: cross  Abstract: In this study, we introduce a novel visual imitation network with a spatial attention module for robotic assisted feeding (RAF). The goal is to acquire (i.e., scoop) food items from a bowl. However, achieving robust and adaptive food manipulation is particularly challenging. To deal with this, we propose a framework that integrates visual perception with imitation learning to enable the robot to handle diverse scenarios during scooping. Our approach, named AVIL (adaptive visual imitation learning), exhibits adaptability and robustness across different bowl configurations in terms of material, size, and position, as well as diverse food types including granular, semi-solid, and liquid, even in the presence of distractors. We validate the effectiveness of our approach by conducting experiments on a real robot. We also compare its performance with a baseline. The results demonstrate improvement over the baseline across all scenarios, with
    
[^11]: 蜘蛛式策略发现和日程构建中的正则化方法

    Regularization in Spider-Style Strategy Discovery and Schedule Construction

    [https://arxiv.org/abs/2403.12869](https://arxiv.org/abs/2403.12869)

    本文研究了在Vampire定理证明器中使用蜘蛛式系统的正则化方法，探讨了构建强大日程表的难易程度以及日程泛化到未知问题的影响因素。

    

    为了达到最佳性能，自动定理证明器通常依赖于多样的证明策略日程表，在给定问题上尝试（顺序或并行）。本文报告了一项针对Vampire定理证明器的策略发现的大规模实验，针对TPTP库的FOF片段并构建一个基于Andrei Voronkov的Spider系统思想的日程表。我们从各个角度审视该过程，讨论了为CASC竞赛获得强大的Vampire日程表的难易程度，并建立了一个日程表能够对未知问题泛化到何种程度以及影响此属性的因素。

    arXiv:2403.12869v1 Announce Type: new  Abstract: To achieve the best performance, automatic theorem provers often rely on schedules of diverse proving strategies to be tried out (either sequentially or in parallel) on a given problem. In this paper, we report on a large-scale experiment with discovering strategies for the Vampire prover, targeting the FOF fragment of the TPTP library and constructing a schedule for it, based on the ideas of Andrei Voronkov's system Spider. We examine the process from various angles, discuss the difficulty (or ease) of obtaining a strong Vampire schedule for the CASC competition, and establish how well a schedule can be expected to generalize to unseen problems and what factors influence this property.
    
[^12]: 基于无人机的环境智能系统的可重构作动和传感平台RASP

    RASP: A Drone-based Reconfigurable Actuation and Sensing Platform Towards Ambient Intelligent Systems

    [https://arxiv.org/abs/2403.12853](https://arxiv.org/abs/2403.12853)

    提出了RASP，一个可在25秒内自主更换传感器和执行器的模块化和可重构传感和作动平台，使无人机能快速适应各种任务，同时引入了利用大规模语言和视觉语言模型的个人助理系统架构。

    

    实现消费级无人机与我们家中的吸尘机器人或日常生活中的个人智能手机一样有用，需要无人机能感知、驱动和响应可能出现的一般情况。为了实现这一愿景，我们提出了RASP，一个模块化和可重构的传感和作动平台，允许无人机在仅25秒内自主更换机载传感器和执行器，使单个无人机能够快速适应各种任务。RASP包括一个机械层，用于物理更换传感器模块，一个电气层，用于维护传感器/执行器的电源和通信线路，以及一个软件层，用于在无人机和我们平台上的任何传感器模块之间维护一个公共接口。利用最近在大型语言和视觉语言模型方面的进展，我们进一步介绍了一种利用RASP的个人助理系统的架构、实现和现实世界部署。

    arXiv:2403.12853v1 Announce Type: cross  Abstract: Realizing consumer-grade drones that are as useful as robot vacuums throughout our homes or personal smartphones in our daily lives requires drones to sense, actuate, and respond to general scenarios that may arise. Towards this vision, we propose RASP, a modular and reconfigurable sensing and actuation platform that allows drones to autonomously swap onboard sensors and actuators in only 25 seconds, allowing a single drone to quickly adapt to a diverse range of tasks. RASP consists of a mechanical layer to physically swap sensor modules, an electrical layer to maintain power and communication lines to the sensor/actuator, and a software layer to maintain a common interface between the drone and any sensor module in our platform. Leveraging recent advances in large language and visual language models, we further introduce the architecture, implementation, and real-world deployments of a personal assistant system utilizing RASP. We demo
    
[^13]: 灵活薪酬管理的答案集编程

    Answer Set Programming for Flexible Payroll Management

    [https://arxiv.org/abs/2403.12823](https://arxiv.org/abs/2403.12823)

    提出了一种基于灵活答案集编程模型和决策模型和符号标记的方法，可帮助人力资源咨询师代表复杂规则设计灵活薪酬管理系统。

    

    薪酬管理是一个关键的业务任务，受到大量规则的约束，这些规则在公司、行业和国家之间变化很大。此外，这些规则通常很复杂并且经常变化。因此，薪酬管理系统必须在设计上具有灵活性。本文提出了一种基于灵活答案集编程（ASP）模型和基于决策模型和符号标记（DMN）标准的易于阅读的表格表示的方法。它允许人力资源咨询师代表复杂规则，而无需软件工程师的参与，并最终为各种不同情景设计薪酬系统。我们展示了clingo ASP系统的多次求解能力如何可以用于达到处理实际情况所需的性能。

    arXiv:2403.12823v1 Announce Type: cross  Abstract: Payroll management is a critical business task that is subject to a large number of rules, which vary widely between companies, sectors, and countries. Moreover, the rules are often complex and change regularly. Therefore, payroll management systems must be flexible in design. In this paper, we suggest an approach based on a flexible Answer Set Programming (ASP) model and an easy-to-read tabular representation based on the Decision Model and Notation (DMN) standard. It allows HR consultants to represent complex rules without the need for a software engineer, and to ultimately design payroll systems for a variety of different scenarios. We show how the multi-shot solving capabilities of the clingo ASP system can be used to reach the performance that is necessary to handle real-world instances.
    
[^14]: FlowerFormer: 使用基于流感知的图变换器增强神经结构编码

    FlowerFormer: Empowering Neural Architecture Encoding using a Flow-aware Graph Transformer

    [https://arxiv.org/abs/2403.12821](https://arxiv.org/abs/2403.12821)

    FlowerFormer是一种强大的图变换器，通过双向异步消息传递和基于流程的全局注意力，可以增强神经结构的表征学习。

    

    特定神经网络架构的成功与其处理的数据集和任务密切相关；没有一种适合所有情况的解决方案。因此，人们付出了大量努力，以快速准确地估计神经结构在特定任务和数据集上的表现，而无需进行完整的训练或评估。神经结构编码在估计中起着至关重要的作用，而将架构视为图的基于图的方法表现出色。为了增强神经结构的表征学习，我们介绍了FlowerFormer，一种强大的图变换器，它融入了神经结构内的信息流。 FlowerFormer由两个关键组件组成：（a）受流程启发的双向异步消息传递；（b）建立在基于流程的掩码上的全局关注。我们广泛的实验表明，FlowerFormer优于现有神经结构。

    arXiv:2403.12821v1 Announce Type: cross  Abstract: The success of a specific neural network architecture is closely tied to the dataset and task it tackles; there is no one-size-fits-all solution. Thus, considerable efforts have been made to quickly and accurately estimate the performances of neural architectures, without full training or evaluation, for given tasks and datasets. Neural architecture encoding has played a crucial role in the estimation, and graphbased methods, which treat an architecture as a graph, have shown prominent performance. For enhanced representation learning of neural architectures, we introduce FlowerFormer, a powerful graph transformer that incorporates the information flows within a neural architecture. FlowerFormer consists of two key components: (a) bidirectional asynchronous message passing, inspired by the flows; (b) global attention built on flow-based masking. Our extensive experiments demonstrate the superiority of FlowerFormer over existing neural 
    
[^15]: 从组织病理学图像中的重新识别

    Re-identification from histopathology images

    [https://arxiv.org/abs/2403.12816](https://arxiv.org/abs/2403.12816)

    相对简单的深度学习算法能够在组织病理学图像数据集中以高准确率重新识别患者，并提出了一个风险评估方案。

    

    在许多研究中，深度学习算法已经证明了其在分析组织病理学图像中的潜力，例如揭示肿瘤亚型或转移的原发部位。这些模型需要大规模的训练数据集，必须进行匿名化处理以防止可能的患者身份泄露。本研究表明，即使相对简单的深度学习算法也可以在庞大的组织病理学数据集中以相当高的准确率重新识别患者。我们在包括肺鳞状细胞癌（LSCC）和肺腺癌（LUAD）在内的两个TCIA数据集上评估了我们的算法。我们还展示了该算法在一个自制的脑膜瘤组织数据集上的性能。根据我们的研究结果，我们制定了一个风险评估方案来估计

    arXiv:2403.12816v1 Announce Type: cross  Abstract: In numerous studies, deep learning algorithms have proven their potential for the analysis of histopathology images, for example, for revealing the subtypes of tumors or the primary origin of metastases. These models require large datasets for training, which must be anonymized to prevent possible patient identity leaks. This study demonstrates that even relatively simple deep learning algorithms can re-identify patients in large histopathology datasets with substantial accuracy. We evaluated our algorithms on two TCIA datasets including lung squamous cell carcinoma (LSCC) and lung adenocarcinoma (LUAD). We also demonstrate the algorithm's performance on an in-house dataset of meningioma tissue. We predicted the source patient of a slide with F1 scores of 50.16 % and 52.30 % on the LSCC and LUAD datasets, respectively, and with 62.31 % on our meningioma dataset. Based on our findings, we formulated a risk assessment scheme to estimate 
    
[^16]: 比较多语和单语微调语言模型之间的解释忠实度

    Comparing Explanation Faithfulness between Multilingual and Monolingual Fine-tuned Language Models

    [https://arxiv.org/abs/2403.12809](https://arxiv.org/abs/2403.12809)

    多语和单语语言模型之间的特征归因方法的忠实度存在差异，实验证明多语模型越大，FA相对于单语模型来说越不忠实。

    

    在许多实际的自然语言处理应用场景中，从业者不仅旨在最大化预测性能，还寻求对模型预测的忠实解释。特征归因方法给出的理由和重要性分布揭示了输入的不同部分如何影响预测。先前的研究探讨了不同因素如何影响忠实度，主要是在单语英语模型的背景下。另一方面，多语和单语模型之间的FA忠实度差异尚未得到探究。我们的大量实验证明，FA的忠实度在多语和单语模型之间有所变化。我们发现，多语模型越大，FA相对于其对应的单语模型来说越不忠实。我们的进一步分析显示，忠实度的差异是潜在的。

    arXiv:2403.12809v1 Announce Type: cross  Abstract: In many real natural language processing application scenarios, practitioners not only aim to maximize predictive performance but also seek faithful explanations for the model predictions. Rationales and importance distribution given by feature attribution methods (FAs) provide insights into how different parts of the input contribute to a prediction. Previous studies have explored how different factors affect faithfulness, mainly in the context of monolingual English models. On the other hand, the differences in FA faithfulness between multilingual and monolingual models have yet to be explored. Our extensive experiments, covering five languages and five popular FAs, show that FA faithfulness varies between multilingual and monolingual models. We find that the larger the multilingual model, the less faithful the FAs are compared to its counterpart monolingual models.Our further analysis shows that the faithfulness disparity is potenti
    
[^17]: 基于上下文的聚合实现情境道德价值对齐

    Contextual Moral Value Alignment Through Context-Based Aggregation

    [https://arxiv.org/abs/2403.12805](https://arxiv.org/abs/2403.12805)

    提出了一个基于情境聚合的情境道德价值对齐系统，相比现有技术，在与人类价值对齐方面表现更好。

    

    开发价值对齐的人工智能代理是人工智能领域一个复杂而持续挑战。特别是在大型语言模型（LLMs）领域，将多个独立训练的对话代理整合为一个统一系统，使其能够适应并与多个道德价值对齐，具有至关重要的意义。本文提出了一个基于情境聚合的情境道德价值对齐系统。在该系统中，聚合被定义为整合适合回复用户输入的LLM响应子集的过程，考虑了从用户输入中提取出的特征。所提出的系统在与人类价值对齐方面取得了比现有技术更好的结果。

    arXiv:2403.12805v1 Announce Type: new  Abstract: Developing value-aligned AI agents is a complex undertaking and an ongoing challenge in the field of AI. Specifically within the domain of Large Language Models (LLMs), the capability to consolidate multiple independently trained dialogue agents, each aligned with a distinct moral value, into a unified system that can adapt to and be aligned with multiple moral values is of paramount importance. In this paper, we propose a system that does contextual moral value alignment based on contextual aggregation. Here, aggregation is defined as the process of integrating a subset of LLM responses that are best suited to respond to a user input, taking into account features extracted from the user's input. The proposed system shows better results in term of alignment to human value compared to the state of the art.
    
[^18]: 探究BERT中的文本缩短策略：截断 vs 摘要

    Investigating Text Shortening Strategy in BERT: Truncation vs Summarization

    [https://arxiv.org/abs/2403.12799](https://arxiv.org/abs/2403.12799)

    本研究调查了文本分类任务中文档截断和摘要的表现，发现摘要在大多数情况下胜过截断方法的变体，最佳策略为取文档的开头。

    

    基于Transformer的模型的并行性以其输入最大长度为代价。一些研究提出了一些方法来克服这一限制，但其中未有报告摘要作为一种替代方法的有效性。本研究探讨了文档截断和摘要在文本分类任务中的表现。每种方法都得到了几种不同的变体的研究。本研究还探讨了它们的表现与全文表现之间的接近程度。我们使用了一个基于印尼新闻文章(IndoSum)的摘要任务数据集来进行分类测试。本研究显示出摘要胜过了大部分截断方法的变体，只输给了一个。本研究得到的最佳策略是取文档的开头。其次是抽取式摘要。本研究解释了结果的原因，引领着对于利用潜力进行进一步研究的开拓。

    arXiv:2403.12799v1 Announce Type: cross  Abstract: The parallelism of Transformer-based models comes at the cost of their input max-length. Some studies proposed methods to overcome this limitation, but none of them reported the effectiveness of summarization as an alternative. In this study, we investigate the performance of document truncation and summarization in text classification tasks. Each of the two was investigated with several variations. This study also investigated how close their performances are to the performance of full-text. We used a dataset of summarization tasks based on Indonesian news articles (IndoSum) to do classification tests. This study shows how the summaries outperform the majority of truncation method variations and lose to only one. The best strategy obtained in this study is taking the head of the document. The second is extractive summarization. This study explains what happened to the result, leading to further research in order to exploit the potenti
    
[^19]: 在图像分类器中发现和减轻多个有偏子群体

    Discover and Mitigate Multiple Biased Subgroups in Image Classifiers

    [https://arxiv.org/abs/2403.12777](https://arxiv.org/abs/2403.12777)

    提出了一种称为“分解、解释和减轻（DIM）”的新方法, 用于在图像分类器中发现和减轻多个有偏子群体，增强模型鲁棒性。

    

    机器学习模型在分布数据上表现良好，但常常在训练数据中未充分代表的有偏子群体上失败，影响模型对可靠应用的抗干扰性。这些子群体通常由于缺乏子群体标签而未知。发现有偏子群体是理解模型失败模式并进一步提高模型鲁棒性的关键。本文提出了一种名为“分解、解释和减轻（DIM）”的新方法，以解决在图像分类器中发现多个有偏子群体这一更具挑战性但也更实际的问题。我们的方法将图像特征分解为代表多个子群体的多个组件。

    arXiv:2403.12777v1 Announce Type: cross  Abstract: Machine learning models can perform well on in-distribution data but often fail on biased subgroups that are underrepresented in the training data, hindering the robustness of models for reliable applications. Such subgroups are typically unknown due to the absence of subgroup labels. Discovering biased subgroups is the key to understanding models' failure modes and further improving models' robustness. Most previous works of subgroup discovery make an implicit assumption that models only underperform on a single biased subgroup, which does not hold on in-the-wild data where multiple biased subgroups exist.   In this work, we propose Decomposition, Interpretation, and Mitigation (DIM), a novel method to address a more challenging but also more practical problem of discovering multiple biased subgroups in image classifiers. Our approach decomposes the image features into multiple components that represent multiple subgroups. This decomp
    
[^20]: 利用用户辅助的滤波器估计和选择构建脑肿瘤分割网络

    Building Brain Tumor Segmentation Networks with User-Assisted Filter Estimation and Selection

    [https://arxiv.org/abs/2403.12748](https://arxiv.org/abs/2403.12748)

    使用多步骤FLIM方法，只在第一个卷积层中使用用户辅助的方式来估计和选择最相关的滤波器，实现了脑肿瘤分割网络的改进。

    

    大脑肿瘤图像分割是一个具有挑战性的研究课题，深度学习模型取得了最佳结果。然而，传统的从许多预注释图像中训练这些模型的方式留下了一些未解之谜。因此，一些方法，如从图像标记中进行特征学习（Feature Learning from Image Markers，FLIM），已经将专家引入学习环节，以减少数据注释的人力工作，并构建足够深的模型来解决特定问题。本文提出了多步骤（MS）FLIM - 一种用户辅助的方法，用于从多个FLIM执行中估计和选择最相关的滤波器。MS-FLIM仅用于第一个卷积层，结果已经表明相比FLIM有所改进。为了评估，我们构建了一个简单的U型编码器-解码器网络，命名

    arXiv:2403.12748v1 Announce Type: cross  Abstract: Brain tumor image segmentation is a challenging research topic in which deep-learning models have presented the best results. However, the traditional way of training those models from many pre-annotated images leaves several unanswered questions. Hence methodologies, such as Feature Learning from Image Markers (FLIM), have involved an expert in the learning loop to reduce human effort in data annotation and build models sufficiently deep for a given problem. FLIM has been successfully used to create encoders, estimating the filters of all convolutional layers from patches centered at marker voxels. In this work, we present Multi-Step (MS) FLIM - a user-assisted approach to estimating and selecting the most relevant filters from multiple FLIM executions. MS-FLIM is used only for the first convolutional layer, and the results already indicate improvement over FLIM. For evaluation, we build a simple U-shaped encoder-decoder network, name
    
[^21]: 论可解释人工智能评估实际告诉我们什么？支持对XAI构建模块进行组合和情境验证的案例

    What Does Evaluation of Explainable Artificial Intelligence Actually Tell Us? A Case for Compositional and Contextual Validation of XAI Building Blocks

    [https://arxiv.org/abs/2403.12730](https://arxiv.org/abs/2403.12730)

    本文提出了一个细粒度的验证框架，旨在不过度依赖于任何一个社会技术系统的方面，并承认其固有的模块化结构，从而使我们能够系统地推理有关这些性质的内容

    

    尽管取得了显著进展，但解释人工智能的评估仍然难以捉摸和具有挑战性。在本文中，我们提出了一个精细的验证框架，不过度依赖于这些社会技术系统的任何一个方面，并认识到它们固有的模块化结构：技术构建模块、面向用户的解释工件和社交通信协议。虽然我们同意用户研究在评估解释呈现和交付策略的质量和有效性方面具有不可估量的价值，特别是从特定部署情境中解释者的角度来看，但潜在的解释生成机制需要一个单独的、主要是算法的验证策略，考虑到它们（数值）输出的技术和以人为中心的期望。这样一个全面的社会技术实用度评估框架可以让我们系统地推理有关这些性质的内容

    arXiv:2403.12730v1 Announce Type: cross  Abstract: Despite significant progress, evaluation of explainable artificial intelligence remains elusive and challenging. In this paper we propose a fine-grained validation framework that is not overly reliant on any one facet of these sociotechnical systems, and that recognises their inherent modular structure: technical building blocks, user-facing explanatory artefacts and social communication protocols. While we concur that user studies are invaluable in assessing the quality and effectiveness of explanation presentation and delivery strategies from the explainees' perspective in a particular deployment context, the underlying explanation generation mechanisms require a separate, predominantly algorithmic validation strategy that accounts for the technical and human-centred desiderata of their (numerical) outputs. Such a comprehensive sociotechnical utility-based evaluation framework could allow to systematically reason about the properties
    
[^22]: 用于可信赖的机器学习框架的Python模糊测试

    Python Fuzzing for Trustworthy Machine Learning Frameworks

    [https://arxiv.org/abs/2403.12723](https://arxiv.org/abs/2403.12723)

    提出了一种用于Python项目的动态分析管道，结合模糊测试、语料库最小化、崩溃分类和覆盖率收集，以确保机器学习框架的安全性和可靠性。

    

    确保机器学习框架的安全性和可靠性对于构建可信赖的基于人工智能的系统至关重要。模糊测试是安全软件开发生命周期（SSDLC）中一种流行的技术，可用于开发安全和健壮的软件。我们提出了使用Sydr-Fuzz工具集针对Python项目的动态分析管道。我们的管道包括模糊测试、语料库最小化、崩溃分类和覆盖率收集。崩溃分类和严重性评估是确保及时解决最关键漏洞的重要步骤。此外，所提出的管道集成在GitLab CI中。为了确定机器学习框架中最易受攻击的部分，我们分析它们潜在的攻击面，并为PyTorch、TensorFlow开发模糊测试目标。

    arXiv:2403.12723v1 Announce Type: cross  Abstract: Ensuring the security and reliability of machine learning frameworks is crucial for building trustworthy AI-based systems. Fuzzing, a popular technique in secure software development lifecycle (SSDLC), can be used to develop secure and robust software. Popular machine learning frameworks such as PyTorch and TensorFlow are complex and written in multiple programming languages including C/C++ and Python. We propose a dynamic analysis pipeline for Python projects using the Sydr-Fuzz toolset. Our pipeline includes fuzzing, corpus minimization, crash triaging, and coverage collection. Crash triaging and severity estimation are important steps to ensure that the most critical vulnerabilities are addressed promptly. Furthermore, the proposed pipeline is integrated in GitLab CI. To identify the most vulnerable parts of the machine learning frameworks, we analyze their potential attack surfaces and develop fuzz targets for PyTorch, TensorFlow, 
    
[^23]: AnimateDiff-Lightning：跨模型扩散蒸馏

    AnimateDiff-Lightning: Cross-Model Diffusion Distillation

    [https://arxiv.org/abs/2403.12706](https://arxiv.org/abs/2403.12706)

    AnimateDiff-Lightning模型利用渐进对抗性扩散蒸馏，在视频生成领域取得了新的最先进技术，提出了同时蒸馏多个基础扩散模型概率流的方法，形成了具有更广泛样式兼容性的单一蒸馏运动模块。

    

    我们提出了AnimateDiff-Lightning，用于快速生成视频。我们的模型利用渐进对抗性扩散蒸馏，在少数步骤视频生成方面实现了新的最先进技术。我们讨论了对其进行修改以适应视频模态的过程。此外，我们提议同时蒸馏多个基础扩散模型的概率流，从而产生具有更广泛样式兼容性的单一蒸馏运动模块。我们很高兴为社区发布我们蒸馏的AnimateDiff-Lightning模型。

    arXiv:2403.12706v1 Announce Type: cross  Abstract: We present AnimateDiff-Lightning for lightning-fast video generation. Our model uses progressive adversarial diffusion distillation to achieve new state-of-the-art in few-step video generation. We discuss our modifications to adapt it for the video modality. Furthermore, we propose to simultaneously distill the probability flow of multiple base diffusion models, resulting in a single distilled motion module with broader style compatibility. We are pleased to release our distilled AnimateDiff-Lightning model for the community's use.
    
[^24]: 为加拿大空中旅行者赋权：一款关于加拿大空中旅客权利的聊天机器人

    Empowering Air Travelers: A Chatbot for Canadian Air Passenger Rights

    [https://arxiv.org/abs/2403.12678](https://arxiv.org/abs/2403.12678)

    提出了一款关于加拿大空中旅客权利的聊天机器人，帮助旅客理解和利用相关空中旅行法规，成功解决了用户输入复杂和准确回答问题的挑战

    

    加拿大航空旅行领域的航班延误、取消和其他关于旅客权利的问题有了显著增加。认识到这一需求，我们提出了一个聊天机器人来协助旅客并教育他们了解自己的权利。我们的系统将复杂的用户输入分解为简单的查询，用于检索详细空中旅行法规的文档集中的信息。从这些文档中提取最相关的段落，并提供原始文档和生成的查询的链接，使用户能够将信息细分并利用于其独特情况。该系统成功克服了两个主要挑战：理解复杂的用户输入，并提供准确答案，没有幻觉，这些答案可以供旅客依赖以做出明智决策。一项比较聊天机器人和谷歌搜索的用户研究展示了聊天机器人的实用性和易用性。

    arXiv:2403.12678v1 Announce Type: cross  Abstract: The Canadian air travel sector has seen a significant increase in flight delays, cancellations, and other issues concerning passenger rights. Recognizing this demand, we present a chatbot to assist passengers and educate them about their rights. Our system breaks a complex user input into simple queries which are used to retrieve information from a collection of documents detailing air travel regulations. The most relevant passages from these documents are presented along with links to the original documents and the generated queries, enabling users to dissect and leverage the information for their unique circumstances. The system successfully overcomes two predominant challenges: understanding complex user inputs, and delivering accurate answers, free of hallucinations, that passengers can rely on for making informed decisions. A user study comparing the chatbot to a Google search demonstrated the chatbot's usefulness and ease of use.
    
[^25]: 基于高斯伯努利受限玻尔兹曼机的异常检测评分可解释性改进

    Improving Interpretability of Scores in Anomaly Detection Based on Gaussian-Bernoulli Restricted Boltzmann Machine

    [https://arxiv.org/abs/2403.12672](https://arxiv.org/abs/2403.12672)

    该研究提出了一种基于累积分布改进评分可解释性的度量，建立了使用可解释度量设置阈值的准则，并通过数值实验证明其合理性。

    

    高斯伯努利受限玻尔兹曼机（GBRBM）常用于半监督异常检测，仅使用正常数据点进行训练。在基于GBRBM的异常检测中，根据边缘GBRBM的能量函数相同的评分来对正常和异常数据进行分类。然而，由于无法解释该评分，很难设置适当的分类阈值。本研究提出了一种基于累积分布改进评分可解释性的度量，并建立了使用可解释度量设置阈值的准则。数值实验结果表明，仅使用正常数据点设置阈值时，该准则是合理的。此外，由于识别度量涉及计算不可行的最小评分值的评估，我们还提出了一种最小评分的评估方法。

    arXiv:2403.12672v1 Announce Type: cross  Abstract: Gaussian-Bernoulli restricted Boltzmann machines (GBRBMs) are often used for semi-supervised anomaly detection, where they are trained using only normal data points. In GBRBM-based anomaly detection, normal and anomalous data are classified based on a score that is identical to an energy function of the marginal GBRBM. However, the classification threshold is difficult to set to an appropriate value, as this score cannot be interpreted. In this study, we propose a measure that improves score's interpretability based on its cumulative distribution, and establish a guideline for setting the threshold using the interpretable measure. The results of numerical experiments show that the guideline is reasonable when setting the threshold solely using normal data points. Moreover, because identifying the measure involves computationally infeasible evaluation of the minimum score value, we also propose an evaluation method for the minimum score
    
[^26]: 通过廉价高效的提示工程增强 GitHub Copilot 的 AI 代码合成安全性

    Enhancing Security of AI-Based Code Synthesis with GitHub Copilot via Cheap and Efficient Prompt-Engineering

    [https://arxiv.org/abs/2403.12671](https://arxiv.org/abs/2403.12671)

    提出了通过提示工程方法增强 GitHub Copilot 的 AI 代码合成安全性，其中包括三种提示改变方法：特定场景的、迭代的和通用的从句，同时讨论它们的组合。

    

    编程的 AI 助手正在兴起。然而，开发人员和公司避免充分利用它们的一个原因是生成代码的安全性存疑。本文首先回顾了当前的最先进技术，并确定了需要改进的领域。然后，我们提出了一种基于提示改变方法的系统方法，以实现更好的代码安全性，即使是针对专有黑盒的 AI 代码生成器，如 GitHub Copilot，同时尽量减少用户角度、计算资源和运营成本的复杂性。总之，我们提出并评估了三种提示改变方法：（1）特定场景的，（2）迭代的，和（3）通用的从句，同时讨论它们的组合。与对代码安全性的审计相反，最后两种所提出的方法不需要用户具备专业知识。我们评估了所提出方法在...

    arXiv:2403.12671v1 Announce Type: cross  Abstract: AI assistants for coding are on the rise. However one of the reasons developers and companies avoid harnessing their full potential is the questionable security of the generated code. This paper first reviews the current state-of-the-art and identifies areas for improvement on this issue. Then, we propose a systematic approach based on prompt-altering methods to achieve better code security of (even proprietary black-box) AI-based code generators such as GitHub Copilot, while minimizing the complexity of the application from the user point-of-view, the computational resources, and operational costs. In sum, we propose and evaluate three prompt altering methods: (1) scenario-specific, (2) iterative, and (3) general clause, while we discuss their combination. Contrary to the audit of code security, the latter two of the proposed methods require no expert knowledge from the user. We assess the effectiveness of the proposed methods on the 
    
[^27]: 解密AutoML集成：cattleia在决策中的协助

    Deciphering AutoML Ensembles: cattleia's Assistance in Decision-Making

    [https://arxiv.org/abs/2403.12664](https://arxiv.org/abs/2403.12664)

    提出了cattleia工具，可以解密用于回归、多类别和二元分类任务的AutoML集成模型，通过评估指标和新度量指标，分析集成模型的性能和重要性

    

    在许多应用中，模型集成被证明比单个预测模型更好。因此，在自动化机器学习（AutoML）中，它是最常见的后处理技术。我们的工作提出了cattleia - 一种能解密用于回归、多类别和二元分类任务的集成的应用程序。该工具与三个AutoML包构建的模型一起工作：auto-sklearn、AutoGluon和FLAML。我们从不同的角度分析了给定的集成。我们通过评估集成及其组件模型的评估指标进行了预测性能调查。我们通过引入新的度量指标来评估模型预测的多样性和互补性扩展验证视角。此外，我们应用可解释的人工智能（XAI）技术来检查v的重要性

    arXiv:2403.12664v1 Announce Type: cross  Abstract: In many applications, model ensembling proves to be better than a single predictive model. Hence, it is the most common post-processing technique in Automated Machine Learning (AutoML). The most popular frameworks use ensembles at the expense of reducing the interpretability of the final models. In our work, we propose cattleia - an application that deciphers the ensembles for regression, multiclass, and binary classification tasks. This tool works with models built by three AutoML packages: auto-sklearn, AutoGluon, and FLAML. The given ensemble is analyzed from different perspectives. We conduct a predictive performance investigation through evaluation metrics of the ensemble and its component models. We extend the validation perspective by introducing new measures to assess the diversity and complementarity of the model predictions. Moreover, we apply explainable artificial intelligence (XAI) techniques to examine the importance of v
    
[^28]: ERASE：深度推荐系统特征选择方法的基准测试

    ERASE: Benchmarking Feature Selection Methods for Deep Recommender Systems

    [https://arxiv.org/abs/2403.12660](https://arxiv.org/abs/2403.12660)

    深度推荐系统中的特征选择方法研究面临着公平比较、选择属性分析缺乏以及过度关注峰值性能等挑战。

    

    深度推荐系统(DRS)越来越依赖于大量特征字段来提供更精准的推荐。有效的特征选择方法因此变得至关重要，以进一步提高准确性并优化存储效率，以满足部署需求。研究领域，特别是在DRS的背景下，尚处于初期阶段，面临三个核心挑战：首先，研究论文之间实验设置的差异往往导致不公平比较，遮蔽了实践见解。其次，现有文献缺乏基于大规模数据集的选择属性的详细分析，并且缺乏对选择技术和DRS骨干之间进行全面比较的限制性文章的通用性研究和部署。最后，研究往往专注于比较特征选择方法可达到的峰值性能，这种方法通常在计算方面不足。

    arXiv:2403.12660v1 Announce Type: cross  Abstract: Deep Recommender Systems (DRS) are increasingly dependent on a large number of feature fields for more precise recommendations. Effective feature selection methods are consequently becoming critical for further enhancing the accuracy and optimizing storage efficiencies to align with the deployment demands. This research area, particularly in the context of DRS, is nascent and faces three core challenges. Firstly, variant experimental setups across research papers often yield unfair comparisons, obscuring practical insights. Secondly, the existing literature's lack of detailed analysis on selection attributes, based on large-scale datasets and a thorough comparison among selection techniques and DRS backbones, restricts the generalizability of findings and impedes deployment on DRS. Lastly, research often focuses on comparing the peak performance achievable by feature selection methods, an approach that is typically computationally infe
    
[^29]: 使用知识图谱和兴趣框Embedding的推荐系统InBox

    InBox: Recommendation with Knowledge Graph using Interest Box Embedding

    [https://arxiv.org/abs/2403.12649](https://arxiv.org/abs/2403.12649)

    该论文介绍了一种利用知识图谱和兴趣框Embedding的推荐系统，以提高性能和可解释性。

    

    知识图谱(KGs)在现代推荐系统中变得至关重要，有效提高了性能和可解释性。然而，现有研究忽视了两个关键挑战：1）兴趣对应于潜在数量庞大的相关项目集，2）对KG信息和兴趣连接性缺乏明确、细粒度的利用。为了解决这些限制，我们引入了一种新颖的embedding方法。

    arXiv:2403.12649v1 Announce Type: cross  Abstract: Knowledge graphs (KGs) have become vitally important in modern recommender systems, effectively improving performance and interpretability. Fundamentally, recommender systems aim to identify user interests based on historical interactions and recommend suitable items. However, existing works overlook two key challenges: (1) an interest corresponds to a potentially large set of related items, and (2) the lack of explicit, fine-grained exploitation of KG information and interest connectivity. This leads to an inability to reflect distinctions between entities and interests when modeling them in a single way. Additionally, the granularity of concepts in the knowledge graphs used for recommendations tends to be coarse, failing to match the fine-grained nature of user interests. This homogenization limits the precise exploitation of knowledge graph data and interest connectivity. To address these limitations, we introduce a novel embedding-
    
[^30]: PointGrasp：基于点云的用于腱驱动软机器人手套应用的抓取

    PointGrasp: Point Cloud-based Grasping for Tendon-driven Soft Robotic Glove Applications

    [https://arxiv.org/abs/2403.12631](https://arxiv.org/abs/2403.12631)

    提出了一个用于腱驱动软机器人手套的基于点云的抓取系统，能够通过分析3D点云中的对象几何形状来支持日常生活活动中的定制抓取任务。

    

    控制手部外骨骼来辅助进行抓取任务对于理解用户意图的困难构成了挑战。本研究提出，通过从3D点云中分析对象的几何形状（简单和复杂），可以推断大多数日常生活活动中的抓取任务。该研究引入了PointGrasp，这是一个实时系统，旨在通过识别家庭场景的语义来支持和增强日常生活活动中对定制端到端抓取任务的辅助。该系统包括一个RGB-D相机，一个惯性测量单元和一个集成在腱驱动软机器人手套中的微处理器。RGB-D相机以超过30帧/秒的速率处理3D场景。提出的流程展示了简单几何形状的平均RMSE为0.8 ± 0.39厘米，复杂几何形状的为0.11 ± 0.06厘米。在每种模式下，它可以识别和定位可抓取的对象。

    arXiv:2403.12631v1 Announce Type: cross  Abstract: Controlling hand exoskeletons to assist individuals with grasping tasks poses a challenge due to the difficulty in understanding user intentions. We propose that most daily grasping tasks during activities of daily living (ADL) can be deduced by analyzing object geometries (simple and complex) from 3D point clouds. The study introduces PointGrasp, a real-time system designed for identifying household scenes semantically, aiming to support and enhance assistance during ADL for tailored end-to-end grasping tasks. The system comprises an RGB-D camera with an inertial measurement unit and a microprocessor integrated into a tendon-driven soft robotic glove. The RGB-D camera processes 3D scenes at a rate exceeding 30 frames per second. The proposed pipeline demonstrates an average RMSE of 0.8 $\pm$ 0.39 cm for simple and 0.11 $\pm$ 0.06 cm for complex geometries. Within each mode, it identifies and pinpoints reachable objects. This system sh
    
[^31]: 加强形式定理证明：用于在Coq代码上训练AI模型的全面数据集

    Enhancing Formal Theorem Proving: A Comprehensive Dataset for Training AI Models on Coq Code

    [https://arxiv.org/abs/2403.12627](https://arxiv.org/abs/2403.12627)

    提出了一个全面的数据集，用于增强大型语言模型在解释和生成Coq代码方面的熟练程度，推动自动定理证明的发展。

    

    在形式定理证明领域，Coq证明辅助工具以其对验证数学断言和软件正确性的严格方法脱颀而出。尽管人工智能和机器学习取得了进展，但Coq语法和语义的特殊性为大型语言模型（LLMs）带来了独特的挑战。为填补这一空白，我们提出了一个专门设计的全面数据集，旨在增强LLMs在解释和生成Coq代码方面的熟练程度。该数据集源自一组超过10,000个Coq源文件，涵盖了各种命题、证明和定义，丰富的元数据包括源引用和许可信息。我们的主要目标是促进能够生成语法正确且语义丰富的Coq构造的LLMs的发展，从而推进自动定理证明的前沿。这个数据集的初步实验

    arXiv:2403.12627v1 Announce Type: new  Abstract: In the realm of formal theorem proving, the Coq proof assistant stands out for its rigorous approach to verifying mathematical assertions and software correctness. Despite the advances in artificial intelligence and machine learning, the specialized nature of Coq syntax and semantics poses unique challenges for Large Language Models (LLMs). Addressing this gap, we present a comprehensive dataset specifically designed to enhance LLMs' proficiency in interpreting and generating Coq code. This dataset, derived from a collection of over 10,000 Coq source files, encompasses a wide array of propositions, proofs, and definitions, enriched with metadata including source references and licensing information. Our primary aim is to facilitate the development of LLMs capable of generating syntactically correct and semantically meaningful Coq constructs, thereby advancing the frontier of automated theorem proving. Initial experiments with this datase
    
[^32]: FootstepNet: 一种用于快速在线双足足部步态规划和预测的高效演员-评论方法

    FootstepNet: an Efficient Actor-Critic Method for Fast On-line Bipedal Footstep Planning and Forecasting

    [https://arxiv.org/abs/2403.12589](https://arxiv.org/abs/2403.12589)

    提出了一种基于深度强化学习技术的高效足部规划方法，在线推理的计算需求极低，无启发式，并依赖连续的动作生成可行的足步。

    

    设计一个人形运动控制器是具有挑战性的，通常分为几个子问题。其中之一是足部步态规划，其中定义了足步的顺序。即使在更简单的环境中，找到一个最小序列，甚至一个可行的序列，也构成了一个复杂的优化问题。在文献中，这个问题通常通过基于搜索的算法（例如A*的变种）来解决。然而，这样的方法要么计算开销很大，要么依赖手工调整多个参数。在这项工作中，首先，我们提出了一种有效的步态规划方法，用于在带有障碍物的局部环境中导航，基于最先进的深度强化学习（DRL）技术，对在线推理要求非常低的计算需求。我们的方法是无启发的，依赖于一组连续的动作来生成可行的足步。相比之下，其他方法需要选择一组相关

    arXiv:2403.12589v1 Announce Type: cross  Abstract: Designing a humanoid locomotion controller is challenging and classically split up in sub-problems. Footstep planning is one of those, where the sequence of footsteps is defined. Even in simpler environments, finding a minimal sequence, or even a feasible sequence, yields a complex optimization problem. In the literature, this problem is usually addressed by search-based algorithms (e.g. variants of A*). However, such approaches are either computationally expensive or rely on hand-crafted tuning of several parameters. In this work, at first, we propose an efficient footstep planning method to navigate in local environments with obstacles, based on state-of-the art Deep Reinforcement Learning (DRL) techniques, with very low computational requirements for on-line inference. Our approach is heuristic-free and relies on a continuous set of actions to generate feasible footsteps. In contrast, other methods necessitate the selection of a rel
    
[^33]: 主要分布的机器学习

    Machine Learning of the Prime Distribution

    [https://arxiv.org/abs/2403.12588](https://arxiv.org/abs/2403.12588)

    使用最大熵方法推导了概率数论中的几个定理，提供了关于素数学习性质的理论论证，发现Erd\H{o}s-Kac定律不太可能被当前机器学习技术发现，并进行数值实验以验证理论结果

    

    在本研究中，我们使用最大熵方法推导了概率数论中的几个定理，包括哈代-拉马努金定理的一个版本。我们还提供了一个理论论证，解释了Y.-H. He关于素数可学性的实验观察，并假设Erd\H{o}s-Kac定律极不可能被当前的机器学习技术发现。我们进行的数值实验证实了我们的理论发现。

    arXiv:2403.12588v1 Announce Type: cross  Abstract: In the present work we use maximum entropy methods to derive several theorems in probabilistic number theory, including a version of the Hardy-Ramanujan Theorem. We also provide a theoretical argument explaining the experimental observations of Y.-H. He about the learnability of primes, and posit that the Erd\H{o}s-Kac law would very unlikely be discovered by current machine learning techniques. Numerical experiments that we perform corroborate our theoretical findings.
    
[^34]: EAS-SNN：端到端自适应采样和表示，用于循环脉冲神经网络的事件检测

    EAS-SNN: End-to-End Adaptive Sampling and Representation for Event-based Detection with Recurrent Spiking Neural Networks

    [https://arxiv.org/abs/2403.12574](https://arxiv.org/abs/2403.12574)

    提出了一种利用循环脉冲神经网络的自适应采样模块，通过将脉冲神经元的神经动力学与理想的时间事件采样器的行为相结合，实现了端到端可学习的事件检测框架

    

    事件摄像头以其高动态范围和时间分辨率，特别适用于物体检测，尤其是在存在动态模糊和具有挑战性的光照条件的情况下。然而，大多数现有方法更注重优化具有先进检测骨干和早期聚合功能的时空表示，而自适应事件采样的关键问题仍未得到解决。脉冲神经网络（SNN），通过稀疏脉冲通信运行的事件驱动范式，成为解决这一挑战的天然选择。在这项研究中，我们发现脉冲神经元的神经动力学与理想的时间事件采样器的行为密切相符。在这一启发下，我们提出了一个新颖的自适应采样模块，利用具有时间记忆的循环卷积SNN增强，为基于事件检测的完全端到端可学习框架提供支持。

    arXiv:2403.12574v1 Announce Type: cross  Abstract: Event cameras, with their high dynamic range and temporal resolution, are ideally suited for object detection, especially under scenarios with motion blur and challenging lighting conditions. However, while most existing approaches prioritize optimizing spatiotemporal representations with advanced detection backbones and early aggregation functions, the crucial issue of adaptive event sampling remains largely unaddressed. Spiking Neural Networks (SNNs), which operate on an event-driven paradigm through sparse spike communication, emerge as a natural fit for addressing this challenge. In this study, we discover that the neural dynamics of spiking neurons align closely with the behavior of an ideal temporal event sampler. Motivated by this insight, we propose a novel adaptive sampling module that leverages recurrent convolutional SNNs enhanced with temporal memory, facilitating a fully end-to-end learnable framework for event-based detec
    
[^35]: 多模型集成实现复合表情识别

    Compound Expression Recognition via Multi Model Ensemble

    [https://arxiv.org/abs/2403.12572](https://arxiv.org/abs/2403.12572)

    提出了一种基于集成学习方法的复合表情识别解决方案，通过使用多种模型包括卷积网络、视觉Transformer和多尺度局部注意网络，通过延迟融合的方式最终实现了高准确率。

    

    复合表情识别在人际互动中扮演着至关重要的角色。由于复合表情的存在，人类情绪表达变得复杂，需要考虑局部和全局面部表情来做出判断。为解决这一问题，本文提出了一种基于集成学习方法的复合表情识别解决方案。具体来说，我们的任务是分类，我们基于卷积网络、视觉Transformer和多尺度局部注意网络训练三个表情分类模型。然后，通过使用延迟融合的模型集成，我们合并多个模型的输出来预测最终结果。我们的方法在RAF-DB上实现了很高的准确率，并且能够在C-EXPR-DB的某些部分通过零样本学习识别表情。

    arXiv:2403.12572v1 Announce Type: cross  Abstract: Compound Expression Recognition (CER) plays a crucial role in interpersonal interactions. Due to the existence of Compound Expressions , human emotional expressions are complex, requiring consideration of both local and global facial expressions to make judgments. In this paper, to address this issue, we propose a solution based on ensemble learning methods for Compound Expression Recognition. Specifically, our task is classification, where we train three expression classification models based on convolutional networks, Vision Transformers, and multi-scale local attention networks. Then, through model ensemble using late fusion, we merge the outputs of multiple models to predict the final result. Our method achieves high accuracy on RAF-DB and is able to recognize expressions through zero-shot on certain portions of C-EXPR-DB.
    
[^36]: 基于TrustZone启用的消费者IoT设备上的内存高效和安全的DNN推断

    Memory-Efficient and Secure DNN Inference on TrustZone-enabled Consumer IoT Devices

    [https://arxiv.org/abs/2403.12568](https://arxiv.org/abs/2403.12568)

    提出了一种在TrustZone中进行高级模型部署的新方法，确保模型推断期间全面保护隐私。

    

    边缘智能使资源需求高的深度神经网络（DNN）推理成为可能，而无需传输原始数据，从而解决了消费者物联网（IoT）设备中数据隐私的担忧。针对隐私敏感型应用，将模型部署在硬件隔离的受信执行环境（TEEs）中变得至关重要。然而，TEE中有限的安全内存对于部署DNN推断构成挑战，而诸如模型分区和卸载等替代技术则引入了性能降级和安全问题。本文提出了一种新颖的方法，用于在TrustZone中实现先进的模型部署，以确保模型推断期间全面保护隐私。我们设计了一种内存高效管理方法，以支持TEE中的内存需求推断。通过调整内存优先级，我们有效地减轻了内存泄漏风险和内存重叠冲突，从而导致对32行代码进行修改。

    arXiv:2403.12568v1 Announce Type: cross  Abstract: Edge intelligence enables resource-demanding Deep Neural Network (DNN) inference without transferring original data, addressing concerns about data privacy in consumer Internet of Things (IoT) devices. For privacy-sensitive applications, deploying models in hardware-isolated trusted execution environments (TEEs) becomes essential. However, the limited secure memory in TEEs poses challenges for deploying DNN inference, and alternative techniques like model partitioning and offloading introduce performance degradation and security issues. In this paper, we present a novel approach for advanced model deployment in TrustZone that ensures comprehensive privacy preservation during model inference. We design a memory-efficient management method to support memory-demanding inference in TEEs. By adjusting the memory priority, we effectively mitigate memory leakage risks and memory overlap conflicts, resulting in 32 lines of code alterations in 
    
[^37]: 针对时间和内存受限的GPU服务上的大文本分类的Transformer简单技巧

    Simple Hack for Transformers against Heavy Long-Text Classification on a Time- and Memory-Limited GPU Service

    [https://arxiv.org/abs/2403.12563](https://arxiv.org/abs/2403.12563)

    通过在有限资源上逐步执行高效动态的HPO过程，提出了一种注重将Transformers模型适用于长文本分类任务的简单技巧。

    

    许多NLP研究人员依赖免费的计算服务，如Google Colab，来优化他们的Transformer模型，但由于该方法具有二次复杂性并需要更大的资源，这导致了在长文本分类中的超参数优化（HPO）存在局限性。在印尼，仅发现了少量关于使用Transformer进行长文本分类的研究。大多数仅使用少量数据，并且没有报告任何HPO。在这项研究中，我们使用18k篇新闻文章，研究了基于分词器输出长度建议使用哪些预训练模型。然后，我们比较了一些缩短和丰富序列的技巧，包括停用词、标点符号、低频词和重复词的去除。为了进行公平比较，我们提出并运行了一种高效动态的HPO过程，可以逐步在有限资源上进行，并且不需要长时间运行的优化库。利用最佳的方法...

    arXiv:2403.12563v1 Announce Type: cross  Abstract: Many NLP researchers rely on free computational services, such as Google Colab, to fine-tune their Transformer models, causing a limitation for hyperparameter optimization (HPO) in long-text classification due to the method having quadratic complexity and needing a bigger resource. In Indonesian, only a few works were found on long-text classification using Transformers. Most only use a small amount of data and do not report any HPO. In this study, using 18k news articles, we investigate which pretrained models are recommended to use based on the output length of the tokenizer. We then compare some hacks to shorten and enrich the sequences, which are the removals of stopwords, punctuation, low-frequency words, and recurring words. To get a fair comparison, we propose and run an efficient and dynamic HPO procedure that can be done gradually on a limited resource and does not require a long-running optimization library. Using the best ha
    
[^38]: 通过获取赋权：支持小规模深度学习的案例

    Equity through Access: A Case for Small-scale Deep Learning

    [https://arxiv.org/abs/2403.12562](https://arxiv.org/abs/2403.12562)

    通过引入PePR分数，研究人员展示了在资源有限的情况下，利用131种独特的DL架构在医学图像任务中的可行性。

    

    深度学习（DL）的最新进展得益于大规模数据和计算力的提升。这些大规模资源被用于训练日益庞大的模型，而这些模型在计算、数据、能源和碳排放方面消耗巨大。这些成本正在成为研究人员和从业者面临的新型准入障碍，特别是对于那些在全球南方地区资源有限的人。在这项工作中，我们全面审视了现有视觉任务的DL模型，并展示了它们在资源有限的环境中的实用性。为了考虑DL模型的资源消耗，我们引入了一个衡量性能与资源单元的新指标，我们称之为PePR分数。通过使用131种独特的DL架构（跨度从1M到130M个可训练参数）和三个医学图像数据集，我们获取了有关性能和资源之间关系的趋势。

    arXiv:2403.12562v1 Announce Type: cross  Abstract: The recent advances in deep learning (DL) have been accelerated by access to large-scale data and compute. These large-scale resources have been used to train progressively larger models which are resource intensive in terms of compute, data, energy, and carbon emissions. These costs are becoming a new type of entry barrier to researchers and practitioners with limited access to resources at such scale, particularly in the Global South. In this work, we take a comprehensive look at the landscape of existing DL models for vision tasks and demonstrate their usefulness in settings where resources are limited. To account for the resource consumption of DL models, we introduce a novel measure to estimate the performance per resource unit, which we call the PePR score. Using a diverse family of 131 unique DL architectures (spanning 1M to 130M trainable parameters) and three medical image datasets, we capture trends about the performance-reso
    
[^39]: M2DA: 融合驾驶员注意力的多模态融合变压器用于自动驾驶

    M2DA: Multi-Modal Fusion Transformer Incorporating Driver Attention for Autonomous Driving

    [https://arxiv.org/abs/2403.12552](https://arxiv.org/abs/2403.12552)

    提出了一种融合驾驶员注意力的多模态融合变压器(M2DA)用于自动驾驶，通过引入LVAFusion模块和驾驶员注意力，实现了更高的数据融合效率和人类化的场景理解能力。

    

    自动驾驶的端到端模式取得了显著进展。然而，由于1) 多模态环境感知低效：如何更有效地集成来自多模态传感器的数据；2) 非人类般的场景理解：如何有效地在交通场景中定位和预测关键的风险代理人，像有经验的驾驶员。为了克服这些挑战，在本文中，我们提出了一种融合驾驶员注意力的多模态融合变压器 (M2DA) 用于自动驾驶。为了更好地融合多模态数据并实现不同模态之间更高的对齐性，我们提出了一种基于激光雷达-视觉-注意力融合 (LVAFusion) 模块。通过引入驾驶员注意力，我们赋予了自动驾驶汽车类似人类的场景理解能力，能够精确识别复杂场景中的关键区域，并确保安全。

    arXiv:2403.12552v1 Announce Type: cross  Abstract: End-to-end autonomous driving has witnessed remarkable progress. However, the extensive deployment of autonomous vehicles has yet to be realized, primarily due to 1) inefficient multi-modal environment perception: how to integrate data from multi-modal sensors more efficiently; 2) non-human-like scene understanding: how to effectively locate and predict critical risky agents in traffic scenarios like an experienced driver. To overcome these challenges, in this paper, we propose a Multi-Modal fusion transformer incorporating Driver Attention (M2DA) for autonomous driving. To better fuse multi-modal data and achieve higher alignment between different modalities, a novel Lidar-Vision-Attention-based Fusion (LVAFusion) module is proposed. By incorporating driver attention, we empower the human-like scene understanding ability to autonomous vehicles to identify crucial areas within complex scenarios precisely and ensure safety. We conduct e
    
[^40]: 是否帮助：基于LLM的专注支持与人机群体互动

    To Help or Not to Help: LLM-based Attentive Support for Human-Robot Group Interactions

    [https://arxiv.org/abs/2403.12533](https://arxiv.org/abs/2403.12533)

    该论文提出了基于LLM的专注支持交互概念，使机器人能够在不干扰群体的情况下支持和帮助人类。

    

    机器人如何在人类群体中提供不引人注目的物理支持？我们提出了Attentive Support，这是一个新颖的机器人与人类群体进行支持的交互概念。它将场景感知、对话获取、情况理解和行为生成与大规模语言模型（LLMs）的常识推理能力相结合。除了遵循用户的指令，Attentive Support能够决定何时以及如何支持人类，并在不干扰群体时保持沉默。通过多样化的场景，我们展示和评估了机器人的专注行为，当需要时支持和帮助人类，而如果不需要帮助，则不会干扰。

    arXiv:2403.12533v1 Announce Type: cross  Abstract: How can a robot provide unobtrusive physical support within a group of humans? We present Attentive Support, a novel interaction concept for robots to support a group of humans. It combines scene perception, dialogue acquisition, situation understanding, and behavior generation with the common-sense reasoning capabilities of Large Language Models (LLMs). In addition to following user instructions, Attentive Support is capable of deciding when and how to support the humans, and when to remain silent to not disturb the group. With a diverse set of scenarios, we show and evaluate the robot's attentive behavior, which supports and helps the humans when required, while not disturbing if no help is needed.
    
[^41]: GraphERE: 基于图增强事件嵌入的多事件关系提取

    GraphERE: Jointly Multiple Event-Event Relation Extraction via Graph-Enhanced Event Embeddings

    [https://arxiv.org/abs/2403.12523](https://arxiv.org/abs/2403.12523)

    该论文提出了一种名为GraphERE的多事件关系提取框架，通过使用图增强事件嵌入，扩展了事件嵌入的事件参数和结构特征，从而解决了事件触发器嵌入的局限以及关系之间互连被忽略的问题。

    

    事件描述实体的状态变化。在文档中，多个事件通过各种关系相互连接（例如，共指、时间、因果和子事件）。因此，通过事件之间的关系提取（ERE）获取事件之间的连接对于理解自然语言至关重要。当前ERE工作中存在两个主要问题：a. 仅使用事件触发器的嵌入来表示事件特征，忽略事件参数（例如，时间、地点、人物等）及其在事件内的结构。b. 关系之间的互连（例如，时间和因果关系通常会相互影响）被忽略。为解决上述问题，本文提出了一种名为GraphERE基于图增强事件嵌入的多重ERE框架。首先，我们利用静态AMR图和IE图丰富事件嵌入的事件参数和结构特征；然后，为了联合...

    arXiv:2403.12523v1 Announce Type: cross  Abstract: Events describe the state changes of entities. In a document, multiple events are connected by various relations (e.g., Coreference, Temporal, Causal, and Subevent). Therefore, obtaining the connections between events through Event-Event Relation Extraction (ERE) is critical to understand natural language. There are two main problems in the current ERE works: a. Only embeddings of the event triggers are used for event feature representation, ignoring event arguments (e.g., time, place, person, etc.) and their structure within the event. b. The interconnection between relations (e.g., temporal and causal relations usually interact with each other ) is ignored. To solve the above problems, this paper proposes a jointly multiple ERE framework called GraphERE based on Graph-enhanced Event Embeddings. First, we enrich the event embeddings with event argument and structure features by using static AMR graphs and IE graphs; Then, to jointly e
    
[^42]: 图像操作的广义一致性轨迹模型

    Generalized Consistency Trajectory Models for Image Manipulation

    [https://arxiv.org/abs/2403.12510](https://arxiv.org/abs/2403.12510)

    本研究提出了广义一致性轨迹模型（GCTMs），能够在任何噪声分布和数据分布之间实现转换。

    

    基于扩散的生成模型在无条件生成以及图像编辑和恢复等应用任务中表现出色。扩散模型的成功在于扩散的迭代性质：扩散将将噪声到数据的复杂映射过程分解为一系列简单的去噪任务。此外，通过在每个去噪步骤中注入引导项，我们能够对生成过程进行精细控制。然而，迭代过程也常常计算密集，通常需要进行数十次甚至数千次函数评估。虽然一致性轨迹模型（CTMs）可以在概率流ODE（PFODE）上任意时间点之间进行遍历，并且通过单次函数评估进行得分推导，但CTMs仅允许从高斯噪声转换为数据。因此，本文旨在通过提出广义CTMs（GCTMs）来发挥CTMs的全部潜力，实现在任何噪声分布和数据分布之间进行转换。

    arXiv:2403.12510v1 Announce Type: cross  Abstract: Diffusion-based generative models excel in unconditional generation, as well as on applied tasks such as image editing and restoration. The success of diffusion models lies in the iterative nature of diffusion: diffusion breaks down the complex process of mapping noise to data into a sequence of simple denoising tasks. Moreover, we are able to exert fine-grained control over the generation process by injecting guidance terms into each denoising step. However, the iterative process is also computationally intensive, often taking from tens up to thousands of function evaluations. Although consistency trajectory models (CTMs) enable traversal between any time points along the probability flow ODE (PFODE) and score inference with a single function evaluation, CTMs only allow translation from Gaussian noise to data. Thus, this work aims to unlock the full potential of CTMs by proposing generalized CTMs (GCTMs), which translate between arbit
    
[^43]: 保护大型语言模型：威胁、漏洞和负责任的实践

    Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices

    [https://arxiv.org/abs/2403.12503](https://arxiv.org/abs/2403.12503)

    该论文全面调查了与大型语言模型相关的安全和隐私问题，并提出了未来研究的有前途方向。

    

    大型语言模型(LLMs)显著改变了自然语言处理(NLP)的格局。它们对各种任务产生了影响，从而彻底改变了我们处理语言理解和生成的方式。然而，除了它们引人注目的实用性外，LLMs还带来了重要的安全和风险考虑。这些挑战需要仔细研究，以确保负责任的部署，并防范潜在的漏洞。本研究全面调查了与LLMs相关的安全和隐私问题，从五个主题角度进行：安全和隐私问题、对抗性攻击的漏洞、LLMs误用可能造成的潜在危害、缓解策略以解决这些挑战，同时识别当前策略的局限性。最后，本文建议未来研究的有前途的方向，以增强LLMs的安全和风险管理。

    arXiv:2403.12503v1 Announce Type: cross  Abstract: Large language models (LLMs) have significantly transformed the landscape of Natural Language Processing (NLP). Their impact extends across a diverse spectrum of tasks, revolutionizing how we approach language understanding and generations. Nevertheless, alongside their remarkable utility, LLMs introduce critical security and risk considerations. These challenges warrant careful examination to ensure responsible deployment and safeguard against potential vulnerabilities. This research paper thoroughly investigates security and privacy concerns related to LLMs from five thematic perspectives: security and privacy concerns, vulnerabilities against adversarial attacks, potential harms caused by misuses of LLMs, mitigation strategies to address these challenges while identifying limitations of current strategies. Lastly, the paper recommends promising avenues for future research to enhance the security and risk management of LLMs.
    
[^44]: DetToolChain：一种释放MLLM检测能力的新提示范式

    DetToolChain: A New Prompting Paradigm to Unleash Detection Ability of MLLM

    [https://arxiv.org/abs/2403.12488](https://arxiv.org/abs/2403.12488)

    DetToolChain提出了一种新的提示范式，可以释放MLLM的零拍摄物体检测能力，并通过检测链式思维自动化任务分解和逐步框细化规划。

    

    我们提出DetToolChain，一种新颖的提示范式，用于释放多模态大语言模型（MLLMs）的零拍摄物体检测能力，如GPT-4V和Gemini。我们的方法包括一个受高精度检测先验启发的检测提示工具包和一个实现这些提示的新Chain-of-Thought。具体来说，工具包中的提示旨在引导MLLM集中在区域信息上（例如，放大），按照测量标准阅读坐标（例如，叠加标尺和指南针），并从上下文信息中推断（例如，叠加场景图）。基于这些工具，新的检测Chain-of-Thought可以自动将任务分解为简单的子任务，诊断预测，并规划逐步框细化。我们的框架的有效性在一系列检测任务中得到了证实，特别是在困难情况下。与现有的最先进技术相比

    arXiv:2403.12488v1 Announce Type: cross  Abstract: We present DetToolChain, a novel prompting paradigm, to unleash the zero-shot object detection ability of multimodal large language models (MLLMs), such as GPT-4V and Gemini. Our approach consists of a detection prompting toolkit inspired by high-precision detection priors and a new Chain-of-Thought to implement these prompts. Specifically, the prompts in the toolkit are designed to guide the MLLM to focus on regional information (e.g., zooming in), read coordinates according to measure standards (e.g., overlaying rulers and compasses), and infer from the contextual information (e.g., overlaying scene graphs). Building upon these tools, the new detection chain-of-thought can automatically decompose the task into simple subtasks, diagnose the predictions, and plan for progressive box refinements. The effectiveness of our framework is demonstrated across a spectrum of detection tasks, especially hard cases. Compared to existing state-of-
    
[^45]: 基于NTK引导的少样本类增量学习

    NTK-Guided Few-Shot Class Incremental Learning

    [https://arxiv.org/abs/2403.12486](https://arxiv.org/abs/2403.12486)

    本文通过NTK对FSCIL模型的指导，致力于在增量学习中实现卓越泛化，通过优化NTK收敛和降低泛化误差来确保最佳性能。

    

    尽管反遗忘FSCIL学习者在增量会话中表现出色，但他们往往更注重减少知识流失，而忽视了模型潜在获取知识的能力。本文通过神经切向核（NTK）的视角深入探讨了FSCIL模型泛化的基础。我们主要的设计重点在于确保最优NTK收敛和NTK相关的泛化误差，作为卓越泛化的理论基础。为了达到全局最优的NTK收敛，我们采用了一个植根于数学原理的元学习机制，指导扩展网络内的优化过程。此外，为了减少NTK相关的泛化误差，我们从基础层面开始，优化构成其泛化损失的相关因素。具体地，我们通过在基础会话上启动自监督预训练来塑造初始ne

    arXiv:2403.12486v1 Announce Type: cross  Abstract: While anti-amnesia FSCIL learners often excel in incremental sessions, they tend to prioritize mitigating knowledge attrition over harnessing the model's potential for knowledge acquisition. In this paper, we delve into the foundations of model generalization in FSCIL through the lens of the Neural Tangent Kernel (NTK). Our primary design focus revolves around ensuring optimal NTK convergence and NTK-related generalization error, serving as the theoretical bedrock for exceptional generalization. To attain globally optimal NTK convergence, we employ a meta-learning mechanism grounded in mathematical principles to guide the optimization process within an expanded network. Furthermore, to reduce the NTK-related generalization error, we commence from the foundational level, optimizing the relevant factors constituting its generalization loss. Specifically, we initiate self-supervised pre-training on the base session to shape the initial ne
    
[^46]: 具身LLM代理在组织团队中学会合作

    Embodied LLM Agents Learn to Cooperate in Organized Teams

    [https://arxiv.org/abs/2403.12482](https://arxiv.org/abs/2403.12482)

    本文介绍了一个框架，将即时性组织结构强加在LLM代理上，以促进多代理系统内的合作，在具身LLM代理和人-代理合作实验中发现指定领导对团队效率的影响，揭示了LLM代理的领导素质和自发合作行为。

    

    大型语言模型（LLMs）已成为推理、规划和决策的重要工具，利用其丰富的世界知识和语言相关任务的熟练度。LLMs因此在多代理系统内自然语言交互方面具有巨大潜力，以促进合作。然而，LLM代理往往会过度报告并遵从任何指令，这可能导致多代理合作中的信息冗余和混乱。受人类组织的启发，本文引入了一个框架，将即时性组织结构强加在LLM代理上，以缓解这些问题。通过一系列具身LLM代理和人-代理合作的实验，我们的结果突出了指定领导对团队效率的影响，揭示了LLM代理展示的领导素质和他们的自发合作行为。此外，我们利用LLMs的潜力

    arXiv:2403.12482v1 Announce Type: new  Abstract: Large Language Models (LLMs) have emerged as integral tools for reasoning, planning, and decision-making, drawing upon their extensive world knowledge and proficiency in language-related tasks. LLMs thus hold tremendous potential for natural language interaction within multi-agent systems to foster cooperation. However, LLM agents tend to over-report and comply with any instruction, which may result in information redundancy and confusion in multi-agent cooperation. Inspired by human organizations, this paper introduces a framework that imposes prompt-based organization structures on LLM agents to mitigate these problems. Through a series of experiments with embodied LLM agents and human-agent collaboration, our results highlight the impact of designated leadership on team efficiency, shedding light on the leadership qualities displayed by LLM agents and their spontaneous cooperative behaviors. Further, we harness the potential of LLMs t
    
[^47]: 基于强化学习的移动机器人局部路径规划

    Reinforcement learning based local path planning for mobile robot

    [https://arxiv.org/abs/2403.12463](https://arxiv.org/abs/2403.12463)

    该论文基于强化学习提出了一种新的移动机器人局部路径规划方法，克服了离线系统中重新规划和映射的需求以及在线系统中动态感应数据要求的问题。

    

    不同的方法被用来让移动机器人到达特定目标位置。这些方法在在线和离线场景中以不同方式工作。在离线场景中，环境地图被创建一次，然后在该地图上进行固定路径规划以到达目标。A*和RRT（Rapidly-Exploring Random Tree）等路径规划算法是离线方法的例子。另一方面，在在线场景中，机器人通过使用传感器传输的感知数据动态移动到给定目标，而不使用地图。在线系统中使用的方法，如SFM（Social Force Model），要求大量动态感应数据。因此，可以说在离线系统中需要重新规划和映射，而在线系统中存在各种系统设计要求。

    arXiv:2403.12463v1 Announce Type: cross  Abstract: Different methods are used for a mobile robot to go to a specific target location. These methods work in different ways for online and offline scenarios. In the offline scenario, an environment map is created once, and fixed path planning is made on this map to reach the target. Path planning algorithms such as A* and RRT (Rapidly-Exploring Random Tree) are the examples of offline methods. The most obvious situation here is the need to re-plan the path for changing conditions of the loaded map. On the other hand, in the online scenario, the robot moves dynamically to a given target without using a map by using the perceived data coming from the sensors. Approaches such as SFM (Social Force Model) are used in online systems. However, these methods suffer from the requirement of a lot of dynamic sensing data. Thus, it can be said that the need for re-planning and mapping in offline systems and various system design requirements in online
    
[^48]: 复发性尖峰神经网络异质学习动态的拓扑表示

    Topological Representations of Heterogeneous Learning Dynamics of Recurrent Spiking Neural Networks

    [https://arxiv.org/abs/2403.12462](https://arxiv.org/abs/2403.12462)

    本文引入了一种新的方法，使用RTD来衡量不同学习方法下复发性尖峰神经网络（RSNN）模型分布式表示之间的差异。

    

    尖峰神经网络（SNNs）已成为神经科学和人工智能中一个重要范式，提供了类似大脑的计算。最近文献中的进展已经研究了深度神经网络的网络表示。然而，对SNNs学习到的表示的研究很少，尤其是使用类似时序相关可塑性（STDP）的无监督局部学习方法。最近\cite{barannikov2021representation}的工作引入了一种比较学习表示的拓扑映射的新方法，称为表示拓扑离散度（RTD）。虽然有用，但这种方法特别针对前馈深度神经网络设计，不能用于像复发性SNNs（RSNNs）这样的循环网络。本文介绍了一种新的方法，使用RTD来衡量具有不同学习方法的RSNN模型的分布式表示之间的差异。

    arXiv:2403.12462v1 Announce Type: cross  Abstract: Spiking Neural Networks (SNNs) have become an essential paradigm in neuroscience and artificial intelligence, providing brain-inspired computation. Recent advances in literature have studied the network representations of deep neural networks. However, there has been little work that studies representations learned by SNNs, especially using unsupervised local learning methods like spike-timing dependent plasticity (STDP). Recent work by \cite{barannikov2021representation} has introduced a novel method to compare topological mappings of learned representations called Representation Topology Divergence (RTD). Though useful, this method is engineered particularly for feedforward deep neural networks and cannot be used for recurrent networks like Recurrent SNNs (RSNNs). This paper introduces a novel methodology to use RTD to measure the difference between distributed representations of RSNN models with different learning methods. We propos
    
[^49]: 非负对比学习

    Non-negative Contrastive Learning

    [https://arxiv.org/abs/2403.12459](https://arxiv.org/abs/2403.12459)

    非负对比学习(NCL)是对非负矩阵分解(NMF)的重新演绎，通过对特征施加非负约束来获得可解释的特征，保留了NMF的可解释属性，从而得到比标准对比学习(CL)更稀疏和解耦的表示

    

    深度表示在以黑盒方式转移到下游任务时表现出了良好的性能。然而，它们固有的不可解释性仍然是一个重大挑战，因为这些特征通常对人类理解而言是不透明的。在本文中，我们提出了非负对比学习（NCL），这是对非负矩阵分解（NMF）的复兴，旨在得出可解释的特征。NCL的力量在于强制将非负约束应用于特征，这让人想起NMF能够提取与样本集群紧密对齐的特征的能力。NCL不仅在数学上与NMF目标很好地对齐，而且保留了NMF的可解释属性，使得与标准对比学习（CL）相比，得到了更加稀疏和解耦的表示。从理论上，我们为NCL的可识别性和下游泛化性能提供了保证。从经验上看，我们展示了这些

    arXiv:2403.12459v1 Announce Type: cross  Abstract: Deep representations have shown promising performance when transferred to downstream tasks in a black-box manner. Yet, their inherent lack of interpretability remains a significant challenge, as these features are often opaque to human understanding. In this paper, we propose Non-negative Contrastive Learning (NCL), a renaissance of Non-negative Matrix Factorization (NMF) aimed at deriving interpretable features. The power of NCL lies in its enforcement of non-negativity constraints on features, reminiscent of NMF's capability to extract features that align closely with sample clusters. NCL not only aligns mathematically well with an NMF objective but also preserves NMF's interpretability attributes, resulting in a more sparse and disentangled representation compared to standard contrastive learning (CL). Theoretically, we establish guarantees on the identifiability and downstream generalization of NCL. Empirically, we show that these 
    
[^50]: INSIGHT: 带有语言解释的端到端神经符号视觉强化学习

    INSIGHT: End-to-End Neuro-Symbolic Visual Reinforcement Learning with Language Explanations

    [https://arxiv.org/abs/2403.12451](https://arxiv.org/abs/2403.12451)

    本文提出了一种可以同时学习结构化状态和符号策略的框架，通过将视觉基础模型提炼成可扩展的感知模块来克服效率瓶颈，并利用大的语言模型生成简洁易读的语言解释。

    

    神经符号强化学习（NS-RL）已成为可解释决策制定的有希望的范式，其特点是符号策略的可解释性。对于具有视觉观测的任务，NS-RL涉及对状态进行结构化表示，但由于缺乏效率，先前的算法无法利用奖励信号来细化结构化状态。可访问性也是一个问题，因为需要广泛的领域知识来解释当前的符号策略。在本文中，我们提出了一个能够同时学习结构化状态和符号策略的框架，其关键思想是通过将视觉基础模型提炼成可扩展的感知模块，克服效率瓶颈。此外，我们设计了一个流水线，利用大的语言模型为政策和决策生成简洁易读的语言解释。在九个Atari任务的实验中，我们的方法表现出...

    arXiv:2403.12451v1 Announce Type: new  Abstract: Neuro-symbolic reinforcement learning (NS-RL) has emerged as a promising paradigm for explainable decision-making, characterized by the interpretability of symbolic policies. For tasks with visual observations, NS-RL entails structured representations for states, but previous algorithms are unable to refine the structured states with reward signals due to a lack of efficiency. Accessibility is also an issue, as extensive domain knowledge is required to interpret current symbolic policies. In this paper, we present a framework that is capable of learning structured states and symbolic policies simultaneously, whose key idea is to overcome the efficiency bottleneck by distilling vision foundation models into a scalable perception module. Moreover, we design a pipeline that uses large language models to generate concise and readable language explanations for policies and decisions. In experiments on nine Atari tasks, our approach demonstrat
    
[^51]: 生成的数据总是有助于对比学习吗？

    Do Generated Data Always Help Contrastive Learning?

    [https://arxiv.org/abs/2403.12448](https://arxiv.org/abs/2403.12448)

    生成的高质量图像已成功应用于增强对比表示学习，但我们发现有时生成的数据甚至会对对比学习造成伤害，通过研究发现更强的数据膨胀应该伴随着更弱的增强。

    

    对比学习（CL）已经成为无监督视觉表示学习中最成功的范式之一，然而它往往依赖大量手工数据增强。随着生成模型的兴起，特别是扩散模型，生成接近真实数据分布的逼真图像的能力得到了很好的认可。这些生成的高质量图像已成功应用于增强对比表示学习，一种称为“数据膨胀”的技术。然而，我们发现生成的数据（甚至来自像DDPM这样的好扩散模型）有时甚至会对对比学习造成伤害。我们从数据膨胀和数据增强的角度探讨了这种失败的原因。我们首次揭示了更强的数据膨胀应该伴随着更弱的增强，反之亦然的互补作用。我们还提供了严格的理论解释。

    arXiv:2403.12448v1 Announce Type: cross  Abstract: Contrastive Learning (CL) has emerged as one of the most successful paradigms for unsupervised visual representation learning, yet it often depends on intensive manual data augmentations. With the rise of generative models, especially diffusion models, the ability to generate realistic images close to the real data distribution has been well recognized. These generated high-equality images have been successfully applied to enhance contrastive representation learning, a technique termed ``data inflation''. However, we find that the generated data (even from a good diffusion model like DDPM) may sometimes even harm contrastive learning. We investigate the causes behind this failure from the perspective of both data inflation and data augmentation. For the first time, we reveal the complementary roles that stronger data inflation should be accompanied by weaker augmentations, and vice versa. We also provide rigorous theoretical explanatio
    
[^52]: 深度学习框架中的几何约束：一项调查

    Geometric Constraints in Deep Learning Frameworks: A Survey

    [https://arxiv.org/abs/2403.12431](https://arxiv.org/abs/2403.12431)

    本调查研究了几何约束和深度学习框架之间的重合部分，比较了深度估计等问题中集成在深度学习框架中的几何强制约束。

    

    Stereophotogrammetry是一种新兴的场景理解技术。其起源可以追溯到至少19世纪，当时人们开始研究使用照片来测量世界的物理属性。自那时以来，已经探索了成千上万种方法。经典几何技术的Shape from Stereo建立在使用几何来定义场景和摄像机几何的约束，然后解决非线性方程组。更近期的工作采用了完全不同的方法，使用端到端的深度学习而没有明确建模几何。在这项调查中，我们探讨了基于几何和基于深度学习框架的重叠部分。我们比较和对比了集成到深度学习框架中用于深度估计或其他密切相关问题的几何强制约束。我们提出了一种新的分类法，用于描述现代深度学习中使用的普遍几何约束。

    arXiv:2403.12431v1 Announce Type: cross  Abstract: Stereophotogrammetry is an emerging technique of scene understanding. Its origins go back to at least the 1800s when people first started to investigate using photographs to measure the physical properties of the world. Since then, thousands of approaches have been explored. The classic geometric techniques of Shape from Stereo is built on using geometry to define constraints on scene and camera geometry and then solving the non-linear systems of equations. More recent work has taken an entirely different approach, using end-to-end deep learning without any attempt to explicitly model the geometry. In this survey, we explore the overlap for geometric-based and deep learning-based frameworks. We compare and contrast geometry enforcing constraints integrated into a deep learning framework for depth estimation or other closely related problems. We present a new taxonomy for prevalent geometry enforcing constraints used in modern deep lear
    
[^53]: STG-Mamba: 通过选择性状态空间模型进行时空图学习

    STG-Mamba: Spatial-Temporal Graph Learning via Selective State Space Model

    [https://arxiv.org/abs/2403.12418](https://arxiv.org/abs/2403.12418)

    STG-Mamba 是首个利用选择性状态空间模型进行时空图学习的研究，将STG网络视为系统，并采用图选择性状态空间模块（GS3B）精确表征STG的动态演化。

    

    Spatial-Temporal Graph（STG）数据具有动态性、异质性和非平稳性特点，导致时空图学习持续面临挑战。近年来，提出了各种基于GNN的方法，主要集中于模拟STG网络中节点个体之间的关系，忽略了随时间存在的STG系统本质特征的建模重要性。相反，现代选择性状态空间模型（SSSMs）提出了一种将STG网络视为系统的新方法，并精心探索了STG系统在时间维度上的动态状态演变。在本工作中，我们引入了Spatial-Temporal Graph Mamba（STG-Mamba），作为首个利用强大的选择性状态空间模型进行STG学习的研究，将STG网络视为系统，并采用图选择性状态空间模块（GS3B）精确表征STG的动态演化。

    arXiv:2403.12418v1 Announce Type: cross  Abstract: Spatial-Temporal Graph (STG) data is characterized as dynamic, heterogenous, and non-stationary, leading to the continuous challenge of spatial-temporal graph learning. In the past few years, various GNN-based methods have been proposed to solely focus on mimicking the relationships among node individuals of the STG network, ignoring the significance of modeling the intrinsic features that exist in STG system over time. In contrast, modern Selective State Space Models (SSSMs) present a new approach which treat STG Network as a system, and meticulously explore the STG system's dynamic state evolution across temporal dimension. In this work, we introduce Spatial-Temporal Graph Mamba (STG-Mamba) as the first exploration of leveraging the powerful selective state space models for STG learning by treating STG Network as a system, and employing the Graph Selective State Space Block (GS3B) to precisely characterize the dynamic evolution of ST
    
[^54]: 关于主动推断中的预测规划和反事实学习

    On Predictive planning and counterfactual learning in active inference

    [https://arxiv.org/abs/2403.12417](https://arxiv.org/abs/2403.12417)

    主动推断中提出了基于“规划”和“从经验中学习”两种决策方案，并引入了一个混合模型以平衡数据复杂性，提供了可解释的智能决策制定框架。

    

    随着人工智能的快速发展，理解智能行为的基础变得越来越重要。作为一种行为的通用理论，主动推断提供了一种原则性的方法来探究规划和决策制定中的复杂性基础。本文研究了主动推断中基于“规划”和“从经验中学习”两种决策方案。此外，我们还介绍了一个混合模型，以在这些策略之间平衡数据复杂性与协作，利用两者的优势促进平衡决策制定。我们在一个需要代理适应性的具有挑战性的网格世界情景中评估了我们提出的模型。此外，我们的模型提供了分析各种参数演变的机会，提供宝贵的见解，并为智能决策制定提供了一个可解释的框架。

    arXiv:2403.12417v1 Announce Type: new  Abstract: Given the rapid advancement of artificial intelligence, understanding the foundations of intelligent behaviour is increasingly important. Active inference, regarded as a general theory of behaviour, offers a principled approach to probing the basis of sophistication in planning and decision-making. In this paper, we examine two decision-making schemes in active inference based on 'planning' and 'learning from experience'. Furthermore, we also introduce a mixed model that navigates the data-complexity trade-off between these strategies, leveraging the strengths of both to facilitate balanced decision-making. We evaluate our proposed model in a challenging grid-world scenario that requires adaptability from the agent. Additionally, our model provides the opportunity to analyze the evolution of various parameters, offering valuable insights and contributing to an explainable framework for intelligent decision-making.
    
[^55]: 通过经验背景和布朗运动进行羽毛球运动员行为的离线模仿

    Offline Imitation of Badminton Player Behavior via Experiential Contexts and Brownian Motion

    [https://arxiv.org/abs/2403.12406](https://arxiv.org/abs/2403.12406)

    本文提出了RallyNet，这是一种新颖的用于羽毛球运动员行为的分层离线模仿学习模型，能够捕捉选手的决策依赖关系，解决了直接应用现有方法时可能遇到的层次结构和轮流采取行动导致的复合效应问题。

    

    在动态和快节奏的基于轮次的体育运动中，羽毛球作为一种需要选手依赖变化的决策的固有范例而脱颖而出。虽然在顺序决策的离线专家数据中学习的进展在各个领域中都有所涉及，但如何从离线羽毛球比赛中模仿人类选手的比赛行为在很大程度上尚未被探索。复制对手的行为有益于选手，使他们能够在比赛前有方向地进行战略发展。然而，直接应用现有方法会受到比赛的内在层次结构和由于轮流采取行动的选手轮次性质而产生的复合效应的困扰。在本文中，我们提出了RallyNet，一种新颖的用于羽毛球运动员行为的分层离线模仿学习模型：（i）RallyNet通过将决策过程建模为...

    arXiv:2403.12406v1 Announce Type: new  Abstract: In the dynamic and rapid tactic involvements of turn-based sports, badminton stands out as an intrinsic paradigm that requires alter-dependent decision-making of players. While the advancement of learning from offline expert data in sequential decision-making has been witnessed in various domains, how to rally-wise imitate the behaviors of human players from offline badminton matches has remained underexplored. Replicating opponents' behavior benefits players by allowing them to undergo strategic development with direction before matches. However, directly applying existing methods suffers from the inherent hierarchy of the match and the compounding effect due to the turn-based nature of players alternatively taking actions. In this paper, we propose RallyNet, a novel hierarchical offline imitation learning model for badminton player behaviors: (i) RallyNet captures players' decision dependencies by modeling decision-making processes as 
    
[^56]: 利用大型语言模型提取的原因生成可解释的仇恨言论检测方法

    Towards Interpretable Hate Speech Detection using Large Language Model-extracted Rationales

    [https://arxiv.org/abs/2403.12403](https://arxiv.org/abs/2403.12403)

    利用大型语言模型提取原因特征训练仇恨言论分类器，实现可解释的检测方法

    

    尽管社交媒体平台是用户进行人际讨论和表达观点的重要场所，但社交媒体提供的外立面和匿名性可能导致用户发布仇恨言论和冒犯性内容。鉴于这些平台的庞大规模，自动识别和标记仇恨言论的需求日益迫切。尽管存在几种仇恨言论检测方法，但大多数黑盒方法在设计上不具有可解释性或可解释性。为解决解释性不足，本文提出使用最先进的大型语言模型（LLM）从输入文本中提取原因特征，训练基础仇恨言论分类器，从而通过设计实现忠实的可解释性。我们的框架有效地结合了LLM的文本理解能力和最先进仇恨言论分类器的判别能力，使这些分类器

    arXiv:2403.12403v1 Announce Type: cross  Abstract: Although social media platforms are a prominent arena for users to engage in interpersonal discussions and express opinions, the facade and anonymity offered by social media may allow users to spew hate speech and offensive content. Given the massive scale of such platforms, there arises a need to automatically identify and flag instances of hate speech. Although several hate speech detection methods exist, most of these black-box methods are not interpretable or explainable by design. To address the lack of interpretability, in this paper, we propose to use state-of-the-art Large Language Models (LLMs) to extract features in the form of rationales from the input text, to train a base hate speech classifier, thereby enabling faithful interpretability by design. Our framework effectively combines the textual understanding capabilities of LLMs and the discriminative power of state-of-the-art hate speech classifiers to make these classifi
    
[^57]: 寻找丢失的数据：一种受BERT启发的方法应对无线传感中的数据包丢失

    Finding the Missing Data: A BERT-inspired Approach Against Package Loss in Wireless Sensing

    [https://arxiv.org/abs/2403.12400](https://arxiv.org/abs/2403.12400)

    提出了一种基于BERT的深度学习模型CSI-BERT，可以在目标数据集上以自监督方式进行训练，捕捉不同子载波之间的顺序关系，从而实现更低的错误率和更快的速度，即使面对高丢包率。

    

    尽管已经开发了各种用于Wi-Fi传感的深度学习方法，但数据包丢失常常导致信道状态信息（CSI）的非连续估计，从而对学习模型的性能产生负面影响。为了克服这一挑战，我们提出了一种基于双向编码器表示转换器（BERT）的CSI恢复深度学习模型，称为CSI-BERT。CSI-BERT可以在目标数据集上以自监督方式进行训练，而无需额外的数据。此外，与传统的插值方法不同，传统方法通常只关注一个子载波，CSI-BERT捕捉了不同子载波之间的顺序关系。实验结果表明，与传统插值方法相比，即使面对高丢包率，CSI-BERT实现了更低的错误率和更快的速度。此外，通过利用从CSI-BERT获得的恢复的CSI，其他深度学习方法能够更好地处理无线频谱感知问题。

    arXiv:2403.12400v1 Announce Type: cross  Abstract: Despite the development of various deep learning methods for Wi-Fi sensing, package loss often results in noncontinuous estimation of the Channel State Information (CSI), which negatively impacts the performance of the learning models. To overcome this challenge, we propose a deep learning model based on Bidirectional Encoder Representations from Transformers (BERT) for CSI recovery, named CSI-BERT. CSI-BERT can be trained in an self-supervised manner on the target dataset without the need for additional data. Furthermore, unlike traditional interpolation methods that focus on one subcarrier at a time, CSI-BERT captures the sequential relationships across different subcarriers. Experimental results demonstrate that CSI-BERT achieves lower error rates and faster speed compared to traditional interpolation methods, even when facing with high loss rates. Moreover, by harnessing the recovered CSI obtained from CSI-BERT, other deep learning
    
[^58]: AraPoemBERT：一种用于阿拉伯诗歌分析的预训练语言模型

    AraPoemBERT: A Pretrained Language Model for Arabic Poetry Analysis

    [https://arxiv.org/abs/2403.12392](https://arxiv.org/abs/2403.12392)

    AraPoemBERT 是一种专门针对阿拉伯诗歌文本进行预训练的语言模型，在阿拉伯诗歌相关的NLP任务中表现出色，取得了两项新颖任务中的前所未有的高准确率。

    

    阿拉伯诗歌以其丰富的语言特征和深刻的文化意义，为自然语言处理（NLP）领域提出了独特挑战。其结构和背景的复杂性需要先进的计算模型进行准确分析。本文介绍了AraPoemBERT，这是一种专门在阿拉伯诗歌文本上预训练的阿拉伯语言模型。为了展示所提出模型的有效性，我们将AraPoemBERT与5种不同的阿拉伯语言模型在与阿拉伯诗歌相关的各种NLP任务上进行了比较。这个新模型在绝大多数下游任务中表现优异，并取得了最新的技术成果。AraPoemBERT在三项新颖任务中的两项中取得了前所未有的准确率：诗人性别分类（99.34\%的准确率）和诗歌节律分类（97.79\%的准确率）。此外，模型在诗歌押韵分类（97.73\%的准确率）中也取得了准确得分。

    arXiv:2403.12392v1 Announce Type: cross  Abstract: Arabic poetry, with its rich linguistic features and profound cultural significance, presents a unique challenge to the Natural Language Processing (NLP) field. The complexity of its structure and context necessitates advanced computational models for accurate analysis. In this paper, we introduce AraPoemBERT, an Arabic language model pretrained exclusively on Arabic poetry text. To demonstrate the effectiveness of the proposed model, we compared AraPoemBERT with 5 different Arabic language models on various NLP tasks related to Arabic poetry. The new model outperformed all other models and achieved state-of-the-art results in most of the downstream tasks. AraPoemBERT achieved unprecedented accuracy in two out of three novel tasks: poet's gender classification (99.34\% accuracy), and poetry sub-meter classification (97.79\% accuracy). In addition, the model achieved an accuracy score in poems' rhyme classification (97.73\% accuracy) wh
    
[^59]: FairSTG: 通过协作样本级优化对抗性能异质性

    FairSTG: Countering performance heterogeneity via collaborative sample-level optimization

    [https://arxiv.org/abs/2403.12391](https://arxiv.org/abs/2403.12391)

    FairSTG通过协作样本级优化对抗性能异质性，提出了一个模型独立的面向公平性的时空图学习框架，通过协作挑战性样本与已学习样本的 mix-up 实现知识转移。

    

    arXiv:2403.12391v1 公告类型：跨越  摘要：时空学习在移动计算技术中发挥着关键作用，以赋予智能城市更强大的功能。尽管现有研究已经在整个数据集上取得了准确的预测，但它们仍然忽视了样本之间的显著性能异质性。在这项工作中，我们将性能异质性定为不公平时空学习的原因，这不仅会降低模型的实际功能，还会给现实世界的城市应用带来严重的潜在风险。为了填补这一空白，我们提出了一个模型独立的面向公平性的时空图学习框架FairSTG，借鉴了利用已充分学习样本的优势来协作挑战性样本的思想。具体而言，FairSTG包括一个时空特征提取器用于模型初始化，一个用于知识转移的协作表示增强模块，从已充分学习样本到困难样本。

    arXiv:2403.12391v1 Announce Type: cross  Abstract: Spatiotemporal learning plays a crucial role in mobile computing techniques to empower smart cites. While existing research has made great efforts to achieve accurate predictions on the overall dataset, they still neglect the significant performance heterogeneity across samples. In this work, we designate the performance heterogeneity as the reason for unfair spatiotemporal learning, which not only degrades the practical functions of models, but also brings serious potential risks to real-world urban applications. To fix this gap, we propose a model-independent Fairness-aware framework for SpatioTemporal Graph learning (FairSTG), which inherits the idea of exploiting advantages of well-learned samples to challenging ones with collaborative mix-up. Specifically, FairSTG consists of a spatiotemporal feature extractor for model initialization, a collaborative representation enhancement for knowledge transfer between well-learned samples a
    
[^60]: 基于大型语言模型的可解释对话系统用户满意度估计

    Interpretable User Satisfaction Estimation for Conversational Systems with Large Language Models

    [https://arxiv.org/abs/2403.12388](https://arxiv.org/abs/2403.12388)

    本文提出了一种名为SPUR的方法，通过LLMs更有效地从自然语言话语中提取用户满意度的可解释信号，并能够利用迭代提示框架进行用户满意度评估。

    

    准确而可解释的用户满意度估计对于了解、评估和持续改进对话系统至关重要。本文表明，与基于特征化的机器学习模型或文本嵌入的现有方法相比，LLMs能够更有效地从自然语言话语中提取用户满意度的可解释信号。此外，LLM可以通过一个迭代提示框架，并利用标记示例的监督进行用户满意度评估。

    arXiv:2403.12388v1 Announce Type: cross  Abstract: Accurate and interpretable user satisfaction estimation (USE) is critical for understanding, evaluating, and continuously improving conversational systems. Users express their satisfaction or dissatisfaction with diverse conversational patterns in both general-purpose (ChatGPT and Bing Copilot) and task-oriented (customer service chatbot) conversational systems. Existing approaches based on featurized ML models or text embeddings fall short in extracting generalizable patterns and are hard to interpret. In this work, we show that LLMs can extract interpretable signals of user satisfaction from their natural language utterances more effectively than embedding-based approaches. Moreover, an LLM can be tailored for USE via an iterative prompting framework using supervision from labeled examples. The resulting method, Supervised Prompting for User satisfaction Rubrics (SPUR), not only has higher accuracy but is more interpretable as it sco
    
[^61]: 与联合学习不相上下的分阶段生物医学事件提取

    Pipelined Biomedical Event Extraction Rivaling Joint Learning

    [https://arxiv.org/abs/2403.12386](https://arxiv.org/abs/2403.12386)

    本文提出了一种基于BERT预训练模型的n元关系提取方法，用于改进Binding事件的性能，从而提高分阶段生物医学事件提取的整体性能。

    

    生物医学事件提取是一项信息提取任务，旨在从生物医学文本中获取事件，其目标包括事件类型、触发词以及事件中涉及的各个参数。本文提出了一种基于BERT预训练模型的n元关系提取方法，用于构建Binding事件，以捕获事件背景及参与者的语义信息。实验结果表明，我们的方法在BioNLP共享任务的GE11和GE13语料库上取得了令人满意的结果，分别为63.14%和59.40%的F1分数。

    arXiv:2403.12386v1 Announce Type: cross  Abstract: Biomedical event extraction is an information extraction task to obtain events from biomedical text, whose targets include the type, the trigger, and the respective arguments involved in an event. Traditional biomedical event extraction usually adopts a pipelined approach, which contains trigger identification, argument role recognition, and finally event construction either using specific rules or by machine learning. In this paper, we propose an n-ary relation extraction method based on the BERT pre-training model to construct Binding events, in order to capture the semantic information about an event's context and its participants. The experimental results show that our method achieves promising results on the GE11 and GE13 corpora of the BioNLP shared task with F1 scores of 63.14% and 59.40%, respectively. It demonstrates that by significantly improving theperformance of Binding events, the overall performance of the pipelined even
    
[^62]: 通过大型语言模型构建特征化AI代理

    Characteristic AI Agents via Large Language Models

    [https://arxiv.org/abs/2403.12368](https://arxiv.org/abs/2403.12368)

    该研究通过模拟现实个体，探讨了大型语言模型在构建特征化AI代理方面的性能，为这一任务创建了新的基准数据集和评估指标。

    

    大型语言模型（LLMs）的发展已极大增强了聊天机器人系统的性能。许多研究者致力于为聊天机器人赋予特征。尽管已有商业产品利用LLMs开发面向角色的聊天机器人，但值得注意的是，这一领域的学术研究相对较少。我们的研究旨在通过模拟不同情境下的现实个体，探讨LLMs构建特征化AI代理的性能。目前的研究主要集中在对具有简单配置文件的角色进行操作。针对这一研究空白，我们为特征化AI代理任务创建了一个基准，包括数据集、技术和评估指标。一个名为“Character100”的数据集被建立用于这一基准，包括维基百科上访问量最高的人物供语言模型扮演角色。

    arXiv:2403.12368v1 Announce Type: cross  Abstract: The advancement of Large Language Models (LLMs) has led to significant enhancements in the performance of chatbot systems. Many researchers have dedicated their efforts to the development of bringing characteristics to chatbots. While there have been commercial products for developing role-driven chatbots using LLMs, it is worth noting that academic research in this area remains relatively scarce. Our research focuses on investigating the performance of LLMs in constructing Characteristic AI Agents by simulating real-life individuals across different settings. Current investigations have primarily focused on act on roles with simple profiles. In response to this research gap, we create a benchmark for the characteristic AI agents task, including dataset, techniques, and evaluation metrics. A dataset called ``Character100'' is built for this benchmark, comprising the most-visited people on Wikipedia for language models to role-play. Wit
    
[^63]: 近似似然比：Boosting神经网络训练的前向并行框架

    Approximated Likelihood Ratio: A Forward-Only and Parallel Framework for Boosting Neural Network Training

    [https://arxiv.org/abs/2403.12320](https://arxiv.org/abs/2403.12320)

    该论文提出了一种近似似然比方法，通过在反向传递过程中利用自然并行性，提供了一种高性能训练策略，以减轻神经网络训练中的计算和内存需求。

    

    arXiv:2403.12320v1 发布类型: 跨领域 摘要: 在神经网络训练中，与反向传播相比，高计算复杂性和对神经网络的额外假设等问题使得高效、符合生物学的替代方案仍然是一个挑战，这些限制了对更深层次网络的可扩展性。似然比方法提供了一种有前途的梯度估计策略，但在部署多个数据副本以减少估计方差时，受到显著的内存消耗的限制。在本文中，我们引入了一种似然比（LR）方法的近似技术，以减轻梯度估计中的计算和内存需求。通过利用LR在反向传递过程中的自然并行性，我们进一步提供了一种高性能训练策略，该策略同时管道化了前向和反向传递，使其更适用于专用硬件的计算。大量实验证明了这种方法的有效性。

    arXiv:2403.12320v1 Announce Type: cross  Abstract: Efficient and biologically plausible alternatives to backpropagation in neural network training remain a challenge due to issues such as high computational complexity and additional assumptions about neural networks, which limit scalability to deeper networks. The likelihood ratio method offers a promising gradient estimation strategy but is constrained by significant memory consumption, especially when deploying multiple copies of data to reduce estimation variance. In this paper, we introduce an approximation technique for the likelihood ratio (LR) method to alleviate computational and memory demands in gradient estimation. By exploiting the natural parallelism during the backward pass using LR, we further provide a high-performance training strategy, which pipelines both the forward and backward pass, to make it more suitable for the computation on specialized hardware. Extensive experiments demonstrate the effectiveness of the appr
    
[^64]: 通过世界模型从延迟观察中进行强化学习

    Reinforcement Learning from Delayed Observations via World Models

    [https://arxiv.org/abs/2403.12309](https://arxiv.org/abs/2403.12309)

    本文提出了一种通过世界模型处理观察延迟的方法，可有效处理部分可观察性，相比现有方法，实验表明其中一种方法可以胜过朴素方法达到30%的性能提升。

    

    在标准的强化学习设置中，代理通常假定在采取行动后立即获得关于行动效果的反馈。然而，在实践中，由于物理限制，这一假设可能不成立，这可能会严重影响RL算法的性能。本文侧重于解决部分可观察环境中的观察延迟问题。我们提出利用世界模型来处理观察延迟，世界模型已经在整合过去观察和学习动态方面取得成功。通过将延迟POMDP降低为具有世界模型的延迟MDP，我们的方法可以有效处理部分可观察性，其中现有方法在可观察性降低时实现次优性能甚至迅速下降。实验证明，我们的其中一种方法可以在视觉输入延迟环境下胜过朴素的基于模型的方法达到30%。此外，我们还在视觉输入延迟环境中评估了我们的方法。

    arXiv:2403.12309v1 Announce Type: cross  Abstract: In standard Reinforcement Learning settings, agents typically assume immediate feedback about the effects of their actions after taking them. However, in practice, this assumption may not hold true due to physical constraints and can significantly impact the performance of RL algorithms. In this paper, we focus on addressing observation delays in partially observable environments. We propose leveraging world models, which have shown success in integrating past observations and learning dynamics, to handle observation delays. By reducing delayed POMDPs to delayed MDPs with world models, our methods can effectively handle partial observability, where existing approaches achieve sub-optimal performance or even degrade quickly as observability decreases. Experiments suggest that one of our methods can outperform a naive model-based approach by up to %30. Moreover, we evaluate our methods on visual input based delayed environment, for the f
    
[^65]: 基于梯度的模糊系统优化：以FuzzyR为案例

    Gradient-based Fuzzy System Optimisation via Automatic Differentiation -- FuzzyR as a Use Case

    [https://arxiv.org/abs/2403.12308](https://arxiv.org/abs/2403.12308)

    本文讨论了基于梯度下降的模糊系统优化，并专注于自动微分，旨在从机器学习的角度推动模糊系统设计的进步

    

    自其引入以来，模糊集和系统已成为一个重要的研究领域，以其在建模、知识表示和推理方面的多功能性而闻名，并日益展现在可解释人工智能的背景下的潜力。尽管模糊系统的应用多种多样，但从机器学习的角度来看，它们的设计进展相对较少。也就是说，尽管像神经网络这样的表示受益于计算性能的增加以及训练机制和可用工具的进步，特别是梯度下降，但对模糊系统设计的影响有限。在本文中，我们讨论了基于梯度下降的模糊系统优化，特别关注自动微分——对神经网络学习至关重要，以便让模糊系统设计者摆脱复杂的der

    arXiv:2403.12308v1 Announce Type: new  Abstract: Since their introduction, fuzzy sets and systems have become an important area of research known for its versatility in modelling, knowledge representation and reasoning, and increasingly its potential within the context explainable AI. While the applications of fuzzy systems are diverse, there has been comparatively little advancement in their design from a machine learning perspective. In other words, while representations such as neural networks have benefited from a boom in learning capability driven by an increase in computational performance in combination with advances in their training mechanisms and available tool, in particular gradient descent, the impact on fuzzy system design has been limited. In this paper, we discuss gradient-descent-based optimisation of fuzzy systems, focussing in particular on automatic differentiation -- crucial to neural network learning -- with a view to free fuzzy system designers from intricate der
    
[^66]: 使用高维图分类的分子分类

    Molecular Classification Using Hyperdimensional Graph Classification

    [https://arxiv.org/abs/2403.12307](https://arxiv.org/abs/2403.12307)

    我们的工作引入了一种基于高维计算的图学习方法，在分子分类中表现出与先进模型相媲美的结果，并且在性能上取得了显著的提升。

    

    我们的工作通过利用高维计算引入了一种创新的图学习方法。图作为一种广泛接受的信息传递方法，在学习中的利用引起了巨大关注。这在化学信息学领域尤为显著，那里从图表示中学习发挥着关键作用。该领域内一个重要的应用涉及跨不同分子结构识别癌细胞。我们提出了一个基于HDC的模型，展示了与先进模型如图神经网络（GNNs）或Weisfieler-Lehman图核（WL）相媲美的曲线下面积结果。此外，它在超越先前提出的高维计算图学习方法以及在性能提升方面取得了显著成果，培养阶段加速40倍，推断时间改进了15倍，相对于GNN

    arXiv:2403.12307v1 Announce Type: cross  Abstract: Our work introduces an innovative approach to graph learning by leveraging Hyperdimensional Computing. Graphs serve as a widely embraced method for conveying information, and their utilization in learning has gained significant attention. This is notable in the field of chemoinformatics, where learning from graph representations plays a pivotal role. An important application within this domain involves the identification of cancerous cells across diverse molecular structures.   We propose an HDC-based model that demonstrates comparable Area Under the Curve results when compared to state-of-the-art models like Graph Neural Networks (GNNs) or the Weisfieler-Lehman graph kernel (WL). Moreover, it outperforms previously proposed hyperdimensional computing graph learning methods. Furthermore, it achieves noteworthy speed enhancements, boasting a 40x acceleration in the training phase and a 15x improvement in inference time compared to GNN a
    
[^67]: 利用大型语言模型从临床记录中提取物质使用障碍严重程度信息：一种零样本学习方法

    Leveraging Large Language Models to Extract Information on Substance Use Disorder Severity from Clinical Notes: A Zero-shot Learning Approach

    [https://arxiv.org/abs/2403.12297](https://arxiv.org/abs/2403.12297)

    该研究利用大型语言模型从临床记录中提取物质使用障碍严重程度信息，克服了传统自然语言处理方法在解析复杂临床语言方面的局限性

    

    物质使用障碍（SUD）由于对健康和社会的有害影响而引起了重大关注。 SUD的识别和治疗取决于诸多因素，如严重程度、联合决定因素（例如戒断症状）和健康社会决定因素。 美国保险提供商使用的现有诊断编码系统，如国际疾病分类（ICD-10），对于某些诊断缺乏细致度，但临床医生会将此细致度（如《精神障碍诊断与统计手册》分类或DSM-5中所发现的）作为辅助非结构化文本添加到临床记录中。 传统的自然语言处理（NLP）方法在准确解析这种多样化的临床语言方面存在局限性。 大型语言模型（LLMs）通过适应多样化的语言模式，有望克服这些挑战。 本研究调查了LLMs在提取严重性方面的应用

    arXiv:2403.12297v1 Announce Type: cross  Abstract: Substance use disorder (SUD) poses a major concern due to its detrimental effects on health and society. SUD identification and treatment depend on a variety of factors such as severity, co-determinants (e.g., withdrawal symptoms), and social determinants of health. Existing diagnostic coding systems used by American insurance providers, like the International Classification of Diseases (ICD-10), lack granularity for certain diagnoses, but clinicians will add this granularity (as that found within the Diagnostic and Statistical Manual of Mental Disorders classification or DSM-5) as supplemental unstructured text in clinical notes. Traditional natural language processing (NLP) methods face limitations in accurately parsing such diverse clinical language. Large Language Models (LLMs) offer promise in overcoming these challenges by adapting to diverse language patterns. This study investigates the application of LLMs for extracting severi
    
[^68]: 基于参考文献的指标在问句生成中被推翻

    Reference-based Metrics Disprove Themselves in Question Generation

    [https://arxiv.org/abs/2403.12242](https://arxiv.org/abs/2403.12242)

    基于参考文献的指标在问句生成中被推翻，作者提出了一个无需参考文献的多维标准评估方法。

    

    BLEU和BERTScore等基于参考文献的指标被广泛用于评估问句生成(QG)。本研究在SQuAD和HotpotQA等QG基准数据集上发现，使用人工编写的参考文献并不能保证基于参考文献的指标的有效性。大多数QG基准数据集只有一个参考文献；我们复制了注释过程并收集了另一个参考文献。预期好的指标应该对人工验证的问题的评分不会低于生成的问题。然而，在我们新收集的参考文献上，基于参考文献的指标的结果却证明了这些指标本身是错误的。我们提出了一个无需参考文献的指标，由多维标准组成，如自然性、可回答性和复杂性，利用大型语言模型。这些标准不受限于单个参考问题的句法或语义，该指标也不需要多样化的参考文献。实验证明我们的方法

    arXiv:2403.12242v1 Announce Type: cross  Abstract: Reference-based metrics such as BLEU and BERTScore are widely used to evaluate question generation (QG). In this study, on QG benchmarks such as SQuAD and HotpotQA, we find that using human-written references cannot guarantee the effectiveness of the reference-based metrics. Most QG benchmarks have only one reference; we replicated the annotation process and collect another reference. A good metric was expected to grade a human-validated question no worse than generated questions. However, the results of reference-based metrics on our newly collected reference disproved the metrics themselves. We propose a reference-free metric consisted of multi-dimensional criteria such as naturalness, answerability, and complexity, utilizing large language models. These criteria are not constrained to the syntactic or semantic of a single reference question, and the metric does not require a diverse set of references. Experiments reveal that our met
    
[^69]: 面向资源受限的IoT环境的高效基于Transformer的超参数优化

    Efficient Transformer-based Hyper-parameter Optimization for Resource-constrained IoT Environments

    [https://arxiv.org/abs/2403.12237](https://arxiv.org/abs/2403.12237)

    本文提出了一种通过将Transformer架构和演员-评论家强化学习模型相结合的新方法TRL-HPO，在资源受限的IoT环境中实现了高效的超参数优化，该方法在MNIST数据集上表现优良。

    

    超参数优化（HPO）过程对于找到表现最佳的卷积神经网络（CNNs）至关重要。HPO的自动化过程以其可观的计算占用和缺乏透明度而闻名；这两个因素在资源受限的物联网（IoT）环境中至关重要。本文通过提出一种结合Transformer架构和演员-评论家强化学习（RL）模型的新方法TRL-HPO，旨在解决这些问题，TRL-HPO配备了多头注意力，实现了并行化和渐进生成层。我们通过在MNIST数据集上评估TRL-HPO，并将其与从头开始构建CNN模型的最新方法进行比较，从而从经验上验证了这些假设。结果显示，在相同时间范围内，TRL-HPO的分类结果优于这些方法的结果6.8%，证明了TRL-HPO的高效性。

    arXiv:2403.12237v1 Announce Type: cross  Abstract: The hyper-parameter optimization (HPO) process is imperative for finding the best-performing Convolutional Neural Networks (CNNs). The automation process of HPO is characterized by its sizable computational footprint and its lack of transparency; both important factors in a resource-constrained Internet of Things (IoT) environment. In this paper, we address these problems by proposing a novel approach that combines transformer architecture and actor-critic Reinforcement Learning (RL) model, TRL-HPO, equipped with multi-headed attention that enables parallelization and progressive generation of layers. These assumptions are founded empirically by evaluating TRL-HPO on the MNIST dataset and comparing it with state-of-the-art approaches that build CNN models from scratch. The results show that TRL-HPO outperforms the classification results of these approaches by 6.8% within the same time frame, demonstrating the efficiency of TRL-HPO for 
    
[^70]: 评估命名实体识别：比较分析巴西公司财报电话转录上的单语和多语言Transformer模型

    Evaluating Named Entity Recognition: Comparative Analysis of Mono- and Multilingual Transformer Models on Brazilian Corporate Earnings Call Transcriptions

    [https://arxiv.org/abs/2403.12212](https://arxiv.org/abs/2403.12212)

    本研究通过引入新方法，将标记分类任务重新构建为文本生成问题，评估了在巴西银行财报电话转录中使用的单语和多语言Transformer模型的性能。

    

    命名实体识别（NER）是一种从文本文档中提取信息的自然语言处理技术。然而，现有关于NER的大部分研究都集中在英语文档上，导致缺乏专门针对葡萄牙语财务领域的数据集。本研究解决了金融领域内NER需求，并侧重于从巴西银行财报电话转录中提取的葡萄牙语文本。通过整理包括384个转录的综合数据集，并利用弱监督技术进行注释，我们评估了在葡萄牙语（BERTimbau和PTT5）训练的单语模型以及多语言模型（mBERT和mT5）的性能。值得注意的是，我们引入了一种新方法，将标记分类任务重新构建为文本生成问题，从而实现T5模型的微调和评估。在模型微调之后，

    arXiv:2403.12212v1 Announce Type: cross  Abstract: Named Entity Recognition (NER) is a Natural Language Processing technique for extracting information from textual documents. However, much of the existing research on NER has been centered around English-language documents, leaving a gap in the availability of datasets tailored to the financial domain in Portuguese. This study addresses the need for NER within the financial domain, focusing on Portuguese-language texts extracted from earnings call transcriptions of Brazilian banks. By curating a comprehensive dataset comprising 384 transcriptions and leveraging weak supervision techniques for annotation, we evaluate the performance of monolingual models trained on Portuguese (BERTimbau and PTT5) and multilingual models (mBERT and mT5). Notably, we introduce a novel approach that reframes the token classification task as a text generation problem, enabling fine-tuning and evaluation of T5 models. Following the fine-tuning of the models,
    
[^71]: 一种用于纵向多模态多视图缺失预测的统一模型

    A Unified Model for Longitudinal Multi-Modal Multi-View Prediction with Missingness

    [https://arxiv.org/abs/2403.12211](https://arxiv.org/abs/2403.12211)

    该研究提出了一种用于处理纵向多模态多视图数据缺失的统一模型，能够利用所有可用数据进行预测。

    

    医疗记录通常由不同的模态组成，如图片、文本和表格信息。整合所有模态可以提供患者状况的全面视图，而纵向分析能更好地理解疾病进展。本文介绍了一种用于处理纵向多模态多视图（MMMV）数据缺失的统一模型。我们的方法可以使用任意数量的时间点作为输入，旨在利用所有可用数据，无论其是否完整。我们在骨关节炎倡议（OAI）的膝关节骨关节炎数据集上进行了对疼痛和Kellgren-Lawrence分级（KLG）在未来时间点的预测的广泛实验。

    arXiv:2403.12211v1 Announce Type: cross  Abstract: Medical records often consist of different modalities, such as images, text, and tabular information. Integrating all modalities offers a holistic view of a patient's condition, while analyzing them longitudinally provides a better understanding of disease progression. However, real-world longitudinal medical records present challenges: 1) patients may lack some or all of the data for a specific timepoint, and 2) certain modalities or views might be absent for all patients during a particular period. In this work, we introduce a unified model for longitudinal multi-modal multi-view (MMMV) prediction with missingness. Our method allows as many timepoints as desired for input, and aims to leverage all available data, regardless of their availability. We conduct extensive experiments on the knee osteoarthritis dataset from the Osteoarthritis Initiative (OAI) for pain and Kellgren-Lawrence grade (KLG) prediction at a future timepoint. We d
    
[^72]: 网络影响行动中的合成图像生成：一种新兴威胁？

    Synthetic Image Generation in Cyber Influence Operations: An Emergent Threat?

    [https://arxiv.org/abs/2403.12207](https://arxiv.org/abs/2403.12207)

    人工智能的进步使得数字内容生成方式发生变革，本报告重点探讨了生成深度学习模型在制作合成图像方面的潜力和局限，尤其在网络影响行动中的应用表明了其目前的能力和限制。

    

    人工智能（AI）的发展催生了数字内容生成方式的转变，这对网络影响行动产生了深远影响。本报告探讨了生成深度学习模型（如扩散模型）在制作逼真合成图像方面的潜力和局限。我们对这些工具的易获取性、实用性和输出质量进行了批判性评估，并探讨它们在欺骗、影响和颠覆威胁情景中的影响。值得注意的是，该报告为几种假想的网络影响行动生成内容，以展示这些人工智能驱动方法对威胁行动者的当前能力和局限性。虽然生成模型在生成插图和非真实图像方面表现出色，但创建令人信服的照片逼真内容仍然是一个重大挑战，受限于计算资源和需要人为引导的精细化。

    arXiv:2403.12207v1 Announce Type: cross  Abstract: The evolution of artificial intelligence (AI) has catalyzed a transformation in digital content generation, with profound implications for cyber influence operations. This report delves into the potential and limitations of generative deep learning models, such as diffusion models, in fabricating convincing synthetic images. We critically assess the accessibility, practicality, and output quality of these tools and their implications in threat scenarios of deception, influence, and subversion. Notably, the report generates content for several hypothetical cyber influence operations to demonstrate the current capabilities and limitations of these AI-driven methods for threat actors. While generative models excel at producing illustrations and non-realistic imagery, creating convincing photo-realistic content remains a significant challenge, limited by computational resources and the necessity for human-guided refinement. Our exploration
    
[^73]: 人类和机器中的函数构成学习

    Compositional learning of functions in humans and machines

    [https://arxiv.org/abs/2403.12201](https://arxiv.org/abs/2403.12201)

    人类和神经网络模型通过结合学习和推理探索组合函数的能力，不仅能够进行简单的顺序函数串联，还能理解更复杂的交互函数组合，具有广泛的应用潜力。

    

    学习和组成函数的能力对于人类在有效学习和推理中至关重要，使其能够灵活泛化，例如根据已知烹饪过程创造新菜肴。除了函数的顺序链式串联外，现有的语言学文献表明，人类可以理解更复杂的交互函数组合，其中输出产生取决于由不同函数排序引起的上下文变化。将调查扩展到视觉领域，我们开发了一个函数学习范例，以探索人类和神经网络模型在不同交互条件下学习和推理具有组合函数的能力。在对个体函数进行简要训练后，对人类参与者进行了评估，以组合两个学习过的函数，涵盖四种主要的交互类型，其中包括应用第一个函数会创建或删除的情况。

    arXiv:2403.12201v1 Announce Type: new  Abstract: The ability to learn and compose functions is foundational to efficient learning and reasoning in humans, enabling flexible generalizations such as creating new dishes from known cooking processes. Beyond sequential chaining of functions, existing linguistics literature indicates that humans can grasp more complex compositions with interacting functions, where output production depends on context changes induced by different function orderings. Extending the investigation into the visual domain, we developed a function learning paradigm to explore the capacity of humans and neural network models in learning and reasoning with compositional functions under varied interaction conditions. Following brief training on individual functions, human participants were assessed on composing two learned functions, in ways covering four main interaction types, including instances in which the application of the first function creates or removes the c
    
[^74]: E2F-Net: 通过StyleGAN潜空间进行眼睛到脸部修复的工作

    E2F-Net: Eyes-to-Face Inpainting via StyleGAN Latent Space

    [https://arxiv.org/abs/2403.12197](https://arxiv.org/abs/2403.12197)

    本文提出了一种基于GAN的模型，E2F-Net，通过显著提取眼部区域的身份和非身份特征，并将其映射到预训练的StyleGAN生成器的潜空间，实现了眼睛到脸部的修复。

    

    人脸修复是一种技术，用于恢复缺失或受损的面部图像区域，在遮挡情景下的人脸识别和质量差的图像分析等应用中至关重要。本文的目的是通过一种新的基于生成对抗网络（GAN）模型，即Eyes-to-Face Network（E2F-Net），修复给定的眼部区域并完成人脸修复。

    arXiv:2403.12197v1 Announce Type: cross  Abstract: Face inpainting, the technique of restoring missing or damaged regions in facial images, is pivotal for applications like face recognition in occluded scenarios and image analysis with poor-quality captures. This process not only needs to produce realistic visuals but also preserve individual identity characteristics. The aim of this paper is to inpaint a face given periocular region (eyes-to-face) through a proposed new Generative Adversarial Network (GAN)-based model called Eyes-to-Face Network (E2F-Net). The proposed approach extracts identity and non-identity features from the periocular region using two dedicated encoders have been used. The extracted features are then mapped to the latent space of a pre-trained StyleGAN generator to benefit from its state-of-the-art performance and its rich, diverse and expressive latent space without any additional training. We further improve the StyleGAN output to find the optimal code in the 
    
[^75]: 用大型语言模型在npm生态系统中检测恶意软件

    Shifting the Lens: Detecting Malware in npm Ecosystem with Large Language Models

    [https://arxiv.org/abs/2403.12196](https://arxiv.org/abs/2403.12196)

    通过大型语言模型在npm生态系统中进行实证研究，以协助安全分析师识别恶意软件包

    

    Gartner 2022年的报告预测，到2025年，全球45%的组织将遭遇软件供应链攻击，凸显了改善软件供应链安全对社区和国家利益的迫切性。当前的恶意软件检测技术通过过滤良性和恶意软件包来辅助手动审核过程，然而这种技术存在较高的误报率和有限的自动化支持。因此，恶意软件检测技术可以受益于先进、更自动化的方法，得到准确且误报较少的结果。该研究的目标是通过对大型语言模型（LLMs）进行实证研究，帮助安全分析师识别npm生态系统中的恶意软件。

    arXiv:2403.12196v1 Announce Type: cross  Abstract: The Gartner 2022 report predicts that 45% of organizations worldwide will encounter software supply chain attacks by 2025, highlighting the urgency to improve software supply chain security for community and national interests. Current malware detection techniques aid in the manual review process by filtering benign and malware packages, yet such techniques have high false-positive rates and limited automation support. Therefore, malware detection techniques could benefit from advanced, more automated approaches for accurate and minimally false-positive results. The goal of this study is to assist security analysts in identifying malicious packages through the empirical study of large language models (LLMs) to detect potential malware in the npm ecosystem.   We present SocketAI Scanner, a multi-stage decision-maker malware detection workflow using iterative self-refinement and zero-shot-role-play-Chain of Thought (CoT) prompting techni
    
[^76]: 设施选址机制设计的MAC建议

    MAC Advice for Facility Location Mechanism Design

    [https://arxiv.org/abs/2403.12181](https://arxiv.org/abs/2403.12181)

    研究了具有MAC（大致和近似正确）预测的策略性设施选址机制设计问题，挑战传统最坏情况分析，展示了对于策略无效设施选址的改进。

    

    具有预测能力的算法在过去几年中在各个领域引起了广泛关注，包括设施选址的变种，作为超越传统最坏情况分析的一种方式。我们研究$k$-设施选址机制设计问题，其中$n$个代理是策略性的，可能误报其位置。与以往的模型不同，以往的模型是针对$k$个最佳设施位置的预测，我们接收到了每个代理的位置的$n$个预测。然而，这些预测只是“大致”和“近似”正确（或称为MAC）--即，一些$\delta$分数的预测位置允许任意不正确，并且其余预测允许最多有$\varepsilon$误差。我们对错误的独立性不做任何假设。这样的预测能否帮助我们超越当前的最佳边界以获得对策略无效的设施选址？我们展示了$1$-med

    arXiv:2403.12181v1 Announce Type: cross  Abstract: Algorithms with predictions have attracted much attention in the last years across various domains, including variants of facility location, as a way to surpass traditional worst-case analyses. We study the $k$-facility location mechanism design problem, where the $n$ agents are strategic and might misreport their location.   Unlike previous models, where predictions are for the $k$ optimal facility locations, we receive $n$ predictions for the locations of each of the agents. However, these predictions are only "mostly" and "approximately" correct (or MAC for short) -- i.e., some $\delta$-fraction of the predicted locations are allowed to be arbitrarily incorrect, and the remainder of the predictions are allowed to be correct up to an $\varepsilon$-error. We make no assumption on the independence of the errors. Can such predictions allow us to beat the current best bounds for strategyproof facility location?   We show that the $1$-med
    
[^77]: 自动驾驶中可解释人工智能的安全影响

    Safety Implications of Explainable Artificial Intelligence in End-to-End Autonomous Driving

    [https://arxiv.org/abs/2403.12176](https://arxiv.org/abs/2403.12176)

    自动驾驶中可解释人工智能的安全影响对于确保车辆自动化安全至关重要，但当前研究中安全性和可解释性方面往往被分开砠。

    

    末端到末端学习管道正在逐渐改变高度自主车辆的持续发展，这主要归功于深度学习的进步、大规模训练数据集的可用性以及综合传感器设备的改进。然而，当代学习方法在实时决策中缺乏可解释性，妨碍了用户的信任，并减弱了这类车辆的广泛部署和商业化。此外，当这些汽车参与或导致交通事故时，问题会变得更加严重。这种缺点从社会和法律的角度引起了严重的安全担忧。因此，在末端到末端自动驾驶中解释性是促进车辆自动化安全的关键。然而，当今最先进技术中研究人员通常将自动驾驶的安全性和可解释性方面分开研究。在本文中，我们旨在弥合这一差距

    arXiv:2403.12176v1 Announce Type: cross  Abstract: The end-to-end learning pipeline is gradually creating a paradigm shift in the ongoing development of highly autonomous vehicles, largely due to advances in deep learning, the availability of large-scale training datasets, and improvements in integrated sensor devices. However, a lack of interpretability in real-time decisions with contemporary learning methods impedes user trust and attenuates the widespread deployment and commercialization of such vehicles. Moreover, the issue is exacerbated when these cars are involved in or cause traffic accidents. Such drawback raises serious safety concerns from societal and legal perspectives. Consequently, explainability in end-to-end autonomous driving is essential to enable the safety of vehicular automation. However, the safety and explainability aspects of autonomous driving have generally been investigated disjointly by researchers in today's state of the art. In this paper, we aim to brid
    
[^78]: TnT-LLM：大规模语言模型下的文本挖掘

    TnT-LLM: Text Mining at Scale with Large Language Models

    [https://arxiv.org/abs/2403.12173](https://arxiv.org/abs/2403.12173)

    TnT-LLM 提出了一个两阶段框架，利用大规模语言模型自动化生成和分配标签，减少人力成本。

    

    将非结构化文本转换为结构化有意义的形式，通过有用的类别标签进行组织，是文本挖掘中用于下游分析和应用的基础步骤。然而，大多数现有的生成标签分类法和构建基于文本标签的分类器的方法仍然严重依赖于领域专业知识和手动整理，使得这个过程昂贵且耗时。当标签空间不明确且缺少大规模数据注释时，这一挑战尤为严峻。在本文中，我们用大规模语言模型（LLMs）解决了这些挑战，其基于提示的接口有助于引导和使用大规模伪标签。我们提出了TnT-LLM，这是一个两阶段框架，利用LLMs自动化端到端标签生成和分配的过程，减少人力成本。

    arXiv:2403.12173v1 Announce Type: cross  Abstract: Transforming unstructured text into structured and meaningful forms, organized by useful category labels, is a fundamental step in text mining for downstream analysis and application. However, most existing methods for producing label taxonomies and building text-based label classifiers still rely heavily on domain expertise and manual curation, making the process expensive and time-consuming. This is particularly challenging when the label space is under-specified and large-scale data annotations are unavailable. In this paper, we address these challenges with Large Language Models (LLMs), whose prompt-based interface facilitates the induction and use of large-scale pseudo labels. We propose TnT-LLM, a two-phase framework that employs LLMs to automate the process of end-to-end label generation and assignment with minimal human effort for any given use-case. In the first phase, we introduce a zero-shot, multi-stage reasoning approach w
    
[^79]: 基于图拼图条件扩散模型的基于骨架的视频异常检测

    Graph-Jigsaw Conditioned Diffusion Model for Skeleton-based Video Anomaly Detection

    [https://arxiv.org/abs/2403.12172](https://arxiv.org/abs/2403.12172)

    提出了一种名为GiCiSAD的基于图拼图条件扩散模型，用于解决基于骨架的视频异常检测中的挑战。

    

    基于骨架的视频异常检测（SVAD）是计算机视觉中的一个关键任务。准确识别异常模式或事件使操作员能够及时检测可疑活动，从而增强安全性。然而，现有研究未能同时解决这些关键特性。本文引入了一种新颖、实用且轻量级的框架，即基于图拼图条件扩散模型的基于骨架的视频异常检测（GiCiSAD），以克服与SVAD相关的挑战。

    arXiv:2403.12172v1 Announce Type: cross  Abstract: Skeleton-based video anomaly detection (SVAD) is a crucial task in computer vision. Accurately identifying abnormal patterns or events enables operators to promptly detect suspicious activities, thereby enhancing safety. Achieving this demands a comprehensive understanding of human motions, both at body and region levels, while also accounting for the wide variations of performing a single action. However, existing studies fail to simultaneously address these crucial properties. This paper introduces a novel, practical and lightweight framework, namely Graph-Jigsaw Conditioned Diffusion Model for Skeleton-based Video Anomaly Detection (GiCiSAD) to overcome the challenges associated with SVAD. GiCiSAD consists of three novel modules: the Graph Attention-based Forecasting module to capture the spatio-temporal dependencies inherent in the data, the Graph-level Jigsaw Puzzle Maker module to distinguish subtle region-level discrepancies bet
    
[^80]: EasyJailbreak: 一个用于越狱大型语言模型的统一框架

    EasyJailbreak: A Unified Framework for Jailbreaking Large Language Models

    [https://arxiv.org/abs/2403.12171](https://arxiv.org/abs/2403.12171)

    EasyJailbreak是一个统一框架，简化了对LLMs进行越狱攻击的构建和评估，支持11种越狱方法，帮助进行广泛范围LLMs的安全验证。

    

    越狱攻击对于识别和减轻大型语言模型（LLMs）的安全漏洞至关重要。它们被设计用于绕过保障措施并引发被禁止的输出。然而，由于各种越狱方法之间存在显著差异，目前还没有针对社区提供标准实现框架，这限制了全面的安全评估。本文介绍了EasyJailbreak，一个统一框架，简化了针对LLMs进行越狱攻击的构建和评估。它使用四个组件来构建越狱攻击：选择器、变异器、约束器和评估器。这个模块化框架使研究人员可以轻松地从新的和现有组件的组合中构建攻击。到目前为止，EasyJailbreak支持11种不同的越狱方法，并促进了对广泛范围LLMs的安全验证。我们在10个不同的LLMs上的验证揭示了一个重要的漏洞。

    arXiv:2403.12171v1 Announce Type: cross  Abstract: Jailbreak attacks are crucial for identifying and mitigating the security vulnerabilities of Large Language Models (LLMs). They are designed to bypass safeguards and elicit prohibited outputs. However, due to significant differences among various jailbreak methods, there is no standard implementation framework available for the community, which limits comprehensive security evaluations. This paper introduces EasyJailbreak, a unified framework simplifying the construction and evaluation of jailbreak attacks against LLMs. It builds jailbreak attacks using four components: Selector, Mutator, Constraint, and Evaluator. This modular framework enables researchers to easily construct attacks from combinations of novel and existing components. So far, EasyJailbreak supports 11 distinct jailbreak methods and facilitates the security validation of a broad spectrum of LLMs. Our validation across 10 distinct LLMs reveals a significant vulnerabilit
    
[^81]: 通过计划分析实现智能执行

    Intelligent Execution through Plan Analysis

    [https://arxiv.org/abs/2403.12162](https://arxiv.org/abs/2403.12162)

    提出了一种在执行机器人任务时利用计划分析寻找和储存更好计划机会的技术，通过监控系统在执行过程中修复计划来取代从头重新规划的优势得到实验证实。

    

    智能机器人需要生成和执行计划。为了应对真实环境的复杂性，规划对世界做出了一些假设。在执行计划时，这些假设通常是不符合的。大多数研究关注这一事实的负面影响以及在执行失败后重新规划的使用。相反，我们关注这一事实的积极影响，即发现更好计划的机会。在规划阶段，所提出的技术会找到并存储这些机会。在执行过程中，监控系统可以利用它们来集中感知并修复计划，而不是从头开始重新规划。在多个典型的机器人任务实验中，实验结果显示该方法胜过标准重新规划策略。

    arXiv:2403.12162v1 Announce Type: new  Abstract: Intelligent robots need to generate and execute plans. In order to deal with the complexity of real environments, planning makes some assumptions about the world. When executing plans, the assumptions are usually not met. Most works have focused on the negative impact of this fact and the use of replanning after execution failures. Instead, we focus on the positive impact, or opportunities to find better plans. When planning, the proposed technique finds and stores those opportunities. Later, during execution, the monitoring system can use them to focus perception and repair the plan, instead of replanning from scratch. Experiments in several paradigmatic robotic tasks show how the approach outperforms standard replanning strategies.
    
[^82]: 运用答案集编程的路由和调度在多智能体路径规划中的应用：初步报告

    Routing and Scheduling in Answer Set Programming applied to Multi-Agent Path Finding: Preliminary Report

    [https://arxiv.org/abs/2403.12153](https://arxiv.org/abs/2403.12153)

    提出了在答案集编程中捕捉时间流逝的替代方法，这在建模路由方面是一种有趣的选择，但在调度方面却是不存在替代方案的。

    

    我们提出了在答案集编程（ASP）中进行路由和调度的替代方法，并在多智能体路径规划的背景下探讨它们。这个想法是以偏序而不是与行动和事件相关的时间步来捕捉时间流逝。这也消除了计划长度的固定上界的需要。这种避免的代价是（部分）时间轨迹必须是无环的，因为无法再区分同一行动或事件的多次发生。虽然这种方法为建模路由提供了一个有趣的替代方案，但由于ASP无法以可行的方式表示细粒度的时间安排，因此它在调度方面无替代品。这与偏序不同，偏序可以通过外部手段（如无环和差异约束）高效处理。我们从理论上阐述了这个想法，并提出了几个由此产生的ASP编码。

    arXiv:2403.12153v1 Announce Type: new  Abstract: We present alternative approaches to routing and scheduling in Answer Set Programming (ASP), and explore them in the context of Multi-agent Path Finding. The idea is to capture the flow of time in terms of partial orders rather than time steps attached to actions and fluents. This also abolishes the need for fixed upper bounds on the length of plans. The trade-off for this avoidance is that (parts of) temporal trajectories must be acyclic, since multiple occurrences of the same action or fluent cannot be distinguished anymore. While this approach provides an interesting alternative for modeling routing, it is without alternative for scheduling since fine-grained timings cannot be represented in ASP in a feasible way. This is different for partial orders that can be efficiently handled by external means such as acyclicity and difference constraints. We formally elaborate upon this idea and present several resulting ASP encodings. Finally,
    
[^83]: 将大型语言模型中的领域特定内容融入知识图谱，以增强零样本对象状态分类

    Fusing Domain-Specific Content from Large Language Models into Knowledge Graphs for Enhanced Zero Shot Object State Classification

    [https://arxiv.org/abs/2403.12151](https://arxiv.org/abs/2403.12151)

    大型语言模型与知识图谱结合，提高零样本对象状态分类性能

    

    领域特定知识可以显著有助于解决各种视觉任务，但生成这种知识需要大量人力和时间成本。本研究探讨了大型语言模型（LLMs）在通过语义嵌入生成和提供领域特定信息方面的潜力。为实现这一目标，将LLM集成到一个流程中，该流程在视觉基础零样本对象状态分类任务的背景下利用知识图谱和预训练的语义向量。通过广泛的消融研究彻底研究了LLM的行为。我们的研究结果表明，将基于LLM的嵌入与通用的预训练嵌入结合使用可以显著提高性能。借鉴这一消融研究的见解，我们对竞争模型进行了比较分析，从而突出了最新的表现水平。

    arXiv:2403.12151v1 Announce Type: new  Abstract: Domain-specific knowledge can significantly contribute to addressing a wide variety of vision tasks. However, the generation of such knowledge entails considerable human labor and time costs. This study investigates the potential of Large Language Models (LLMs) in generating and providing domain-specific information through semantic embeddings. To achieve this, an LLM is integrated into a pipeline that utilizes Knowledge Graphs and pre-trained semantic vectors in the context of the Vision-based Zero-shot Object State Classification task. We thoroughly examine the behavior of the LLM through an extensive ablation study. Our findings reveal that the integration of LLM-based embeddings, in combination with general-purpose pre-trained embeddings, leads to substantial performance improvements. Drawing insights from this ablation study, we conduct a comparative analysis against competing models, thereby highlighting the state-of-the-art perfor
    
[^84]: 用于学习神经网络等变表示的图神经网络

    Graph Neural Networks for Learning Equivariant Representations of Neural Networks

    [https://arxiv.org/abs/2403.12143](https://arxiv.org/abs/2403.12143)

    本研究提出了将神经网络表示为参数的计算图的方法，利用图神经网络和变压器来实现置换对称性，使得单个模型能够处理具有多种架构的神经计算图。

    

    处理其他神经网络参数的神经网络在诸如分类隐式神经表示、生成神经网络权重和预测泛化错误等领域中得到应用。然而，现有方法要么忽视神经网络中固有的置换对称性，要么依赖复杂的权重共享模式来实现等变性，同时忽略网络架构本身的影响。在本文中，我们提出将神经网络表示为参数的计算图，这使我们能够利用强大的保留置换对称性的图神经网络和变压器。因此，我们的方法使得单个模型能够对具有多样架构的神经计算图进行编码。我们展示了我们的方法在包括分类和编辑隐式神经表示、预测泛化错误等多种任务中的有效性。

    arXiv:2403.12143v1 Announce Type: cross  Abstract: Neural networks that process the parameters of other neural networks find applications in domains as diverse as classifying implicit neural representations, generating neural network weights, and predicting generalization errors. However, existing approaches either overlook the inherent permutation symmetry in the neural network or rely on intricate weight-sharing patterns to achieve equivariance, while ignoring the impact of the network architecture itself. In this work, we propose to represent neural networks as computational graphs of parameters, which allows us to harness powerful graph neural networks and transformers that preserve permutation symmetry. Consequently, our approach enables a single model to encode neural computational graphs with diverse architectures. We showcase the effectiveness of our method on a wide range of tasks, including classification and editing of implicit neural representations, predicting generalizati
    
[^85]: 自主铁路系统安全分析：SACRED方法论简介

    Safety Analysis of Autonomous Railway Systems: An Introduction to the SACRED Methodology

    [https://arxiv.org/abs/2403.12114](https://arxiv.org/abs/2403.12114)

    SACRED是一种安全方法论，用于为自主系统生成初步安全方案并确定重要安全指标。

    

    随着铁路行业越来越倾向于引入自主性和机器学习（ML），一些问题随之而来。如何确保这些系统和技术的安全？当前的安全分析反映了现有技术的故障模式；相比之下，自动化分析的主要关注点通常是平均表现。为了解决这些困难，我们介绍了SACRED，这是一个用于为自主系统生成初步安全方案并确定重要安全指标的安全方法论。

    arXiv:2403.12114v1 Announce Type: cross  Abstract: As the railway industry increasingly seeks to introduce autonomy and machine learning (ML), several questions arise. How can safety be assured for such systems and technologies? What is the applicability of current safety standards within this new technological landscape? What are the key metrics to classify a system as safe? Currently, safety analysis for the railway reflects the failure modes of existing technology; in contrast, the primary concern of analysis of automation is typically average performance. Such purely statistical approaches to measuring ML performance are limited, as they may overlook classes of situations that may occur rarely but in which the function performs consistently poorly. To combat these difficulties we introduce SACRED, a safety methodology for producing an initial safety case and determining important safety metrics for autonomous systems. The development of SACRED is motivated by the proposed GoA-4 lig
    
[^86]: GCAM: 食物细粒度识别的高斯因果关注模型

    GCAM: Gaussian and causal-attention model of food fine-grained recognition

    [https://arxiv.org/abs/2403.12109](https://arxiv.org/abs/2403.12109)

    提出了一种采用高斯和因果关注模型进行食物细粒度识别的方法，通过训练获取目标区域上的高斯特征和从对象中提取细粒度特征来增强特征映射能力，同时采用反事实推理方法对抗数据漂移。

    

    目前，大多数食物识别依赖于深度学习进行分类。然而，这些方法在有效区分视觉上相似的食物样本方面存在困难，突出了需要解决食物识别中的细粒度问题的迫切性。为了缓解这些挑战，我们提出了采用高斯和因果关注模型进行细粒度物体识别。特别是，我们训练以获得目标区域上的高斯特征，然后从对象中提取细粒度特征，从而增强目标区域的特征映射能力。为了对抗由不均匀数据分布导致的数据漂移，我们采用反事实推理方法。通过使用反事实干预，我们分析了学习的图像注意机制对网络预测的影响，使网络能够获取更有用的细粒度图像识别注意权重。

    arXiv:2403.12109v1 Announce Type: cross  Abstract: Currently, most food recognition relies on deep learning for category classification. However, these approaches struggle to effectively distinguish between visually similar food samples, highlighting the pressing need to address fine-grained issues in food recognition. To mitigate these challenges, we propose the adoption of a Gaussian and causal-attention model for fine-grained object recognition.In particular, we train to obtain Gaussian features over target regions, followed by the extraction of fine-grained features from the objects, thereby enhancing the feature mapping capabilities of the target regions. To counteract data drift resulting from uneven data distributions, we employ a counterfactual reasoning approach. By using counterfactual interventions, we analyze the impact of the learned image attention mechanism on network predictions, enabling the network to acquire more useful attention weights for fine-grained image recogn
    
[^87]: AI是否有助于人类做出更好的决策？一种用于实验评估的方法论框架

    Does AI help humans make better decisions? A methodological framework for experimental evaluation

    [https://arxiv.org/abs/2403.12108](https://arxiv.org/abs/2403.12108)

    引入一种新的实验框架用于评估人类是否通过使用AI可以做出更好的决策，在单盲实验设计中比较了三种决策系统的表现

    

    基于数据驱动算法的人工智能（AI）在当今社会变得无处不在。然而，在许多情况下，尤其是当利益高昂时，人类仍然作出最终决策。因此，关键问题是AI是否有助于人类比单独的人类或单独的AI做出更好的决策。我们引入了一种新的方法论框架，用于实验性地回答这个问题，而不需要额外的假设。我们使用基于基准潜在结果的标准分类指标测量决策者做出正确决策的能力。我们考虑了一个单盲实验设计，在这个设计中，提供AI生成的建议在不同案例中被随机分配给最终决策的人类。在这种实验设计下，我们展示了如何比较三种替代决策系统的性能--仅人类、人类与AI、仅AI。

    arXiv:2403.12108v1 Announce Type: new  Abstract: The use of Artificial Intelligence (AI) based on data-driven algorithms has become ubiquitous in today's society. Yet, in many cases and especially when stakes are high, humans still make final decisions. The critical question, therefore, is whether AI helps humans make better decisions as compared to a human alone or AI an alone. We introduce a new methodological framework that can be used to answer experimentally this question with no additional assumptions. We measure a decision maker's ability to make correct decisions using standard classification metrics based on the baseline potential outcome. We consider a single-blinded experimental design, in which the provision of AI-generated recommendations is randomized across cases with a human making final decisions. Under this experimental design, we show how to compare the performance of three alternative decision-making systems--human-alone, human-with-AI, and AI-alone. We apply the pr
    
[^88]: AGI过渡场景分析

    Scenarios for the Transition to AGI

    [https://arxiv.org/abs/2403.12107](https://arxiv.org/abs/2403.12107)

    分析了不同的技术进步场景对人工通用智能过渡的影响，探讨了自动化和资本积累之间的关系以及工资变化趋势。

    

    我们分析了在可能导致人工通用智能（AGI）的技术进步不同场景下产出和工资的变化。在我们的假设中，人类工作可以分解为在复杂性上不同的原子任务。技术的进步使得越来越复杂的任务可以被自动化实现。工资的影响取决于自动化和资本积累之间的竞赛。如果任务复杂性的分布呈现出足够厚的无限尾部，那么就总是有足够的工作供人类从事，工资可能会无限上升。相比之下，如果人类可以执行的任务复杂性是有界的，并且完全自动化被实现，那么工资会崩溃。但即使在这之前，如果大规模自动化超越了资本积累，劳动力过于丰富，工资可能会下降。自动化生产率的增长可能导致广泛的发展

    arXiv:2403.12107v1 Announce Type: cross  Abstract: We analyze how output and wages behave under different scenarios for technological progress that may culminate in Artificial General Intelligence (AGI), defined as the ability of AI systems to perform all tasks that humans can perform. We assume that human work can be decomposed into atomistic tasks that differ in their complexity. Advances in technology make ever more complex tasks amenable to automation. The effects on wages depend on a race between automation and capital accumulation. If the distribution of task complexity exhibits a sufficiently thick infinite tail, then there is always enough work for humans, and wages may rise forever. By contrast, if the complexity of tasks that humans can perform is bounded and full automation is reached, then wages collapse. But declines may occur even before if large-scale automation outpaces capital accumulation and makes labor too abundant. Automating productivity growth may lead to broad-b
    
[^89]: 循环信念传播用于近似概率推断

    Circular Belief Propagation for Approximate Probabilistic Inference

    [https://arxiv.org/abs/2403.12106](https://arxiv.org/abs/2403.12106)

    循环信念传播（CBP）是对Belief Propagation（BP）的扩展，通过学习检测和取消循环引起的消息反响来限制错误相关和信念放大的不利影响，在二元概率图上表现优于BP和先前提出的算法。

    

    Belief Propagation（BP）是一种简单的概率推断算法，通过在表示概率分布的图中的节点之间传递消息来实现。其类似神经网络的特性表明，它可能对神经科学和人工智能有广泛的应用。不幸的是，当应用于无环图时，BP仅仅是精确的，这限制了该算法的潜力。在本文中，我们提出了循环信念传播（CBP），这是BP的一个扩展，通过学习检测和取消循环引起的消息反响而限制了错误相关和信念放大的不利影响。我们通过涉及二元概率图的数值实验表明，CBP远远优于BP，并与先前提出的算法相比取得了良好的性能。

    arXiv:2403.12106v1 Announce Type: new  Abstract: Belief Propagation (BP) is a simple probabilistic inference algorithm, consisting of passing messages between nodes of a graph representing a probability distribution. Its analogy with a neural network suggests that it could have far-ranging applications for neuroscience and artificial intelligence. Unfortunately, it is only exact when applied to cycle-free graphs, which restricts the potential of the algorithm. In this paper, we propose Circular Belief Propagation (CBP), an extension of BP which limits the detrimental effects of message reverberation caused by cycles by learning to detect and cancel spurious correlations and belief amplifications. We show in numerical experiments involving binary probabilistic graphs that CBP far outperforms BP and reaches good performance compared to that of previously proposed algorithms.
    
[^90]: 通过移动树学习时间段偏好进行下一个POI推荐

    Learning Time Slot Preferences via Mobility Tree for Next POI Recommendation

    [https://arxiv.org/abs/2403.12100](https://arxiv.org/abs/2403.12100)

    本文引入了“移动树”数据结构，用于学习用户跨不同时间段的偏好，以提升下一个POI推荐任务的性能。

    

    下一个兴趣点（POI）推荐任务旨在根据用户当前的签到轨迹提供POI的动态排名。本任务的推荐性能取决于通过基于位置的社交网络（LBSNs）数据全面了解用户个性化的行为模式。本文介绍了一种名为“移动树”的创新数据结构，用于分层描述用户的签到记录。移动树包含多粒度时间段节点，以学习用户跨不同时间段的偏好。同时，我们提出了移动树网络（MTNet）

    arXiv:2403.12100v1 Announce Type: cross  Abstract: Next Point-of-Interests (POIs) recommendation task aims to provide a dynamic ranking of POIs based on users' current check-in trajectories. The recommendation performance of this task is contingent upon a comprehensive understanding of users' personalized behavioral patterns through Location-based Social Networks (LBSNs) data. While prior studies have adeptly captured sequential patterns and transitional relationships within users' check-in trajectories, a noticeable gap persists in devising a mechanism for discerning specialized behavioral patterns during distinct time slots, such as noon, afternoon, or evening. In this paper, we introduce an innovative data structure termed the ``Mobility Tree'', tailored for hierarchically describing users' check-in records. The Mobility Tree encompasses multi-granularity time slot nodes to learn user preferences across varying temporal periods. Meanwhile, we propose the Mobility Tree Network (MTNet
    
[^91]: 深度生成设计用于大规模生产

    Deep Generative Design for Mass Production

    [https://arxiv.org/abs/2403.12098](https://arxiv.org/abs/2403.12098)

    通过将与压铸和注塑相关的约束集成到生成设计中，利用二维深度图像将复杂的3D几何形状简化为可制造的轮廓，消除不可制造特性，将重点放在厚度和肋设计等制造重要方面。

    

    生成设计（GD）作为一种革命性的设计方法已经发展，采用先进的算法和人工智能来创造超越传统限制的多样化和创新性解决方案。尽管取得了成功，但生成设计在复杂设计的可制造性方面面临着重大挑战，通常需要进行大量手动修改，因为标准制造过程存在限制，并且依赖于并不适合大规模生产的增材制造技术。我们的研究通过将与压铸和注塑相关的约束集成到GD中，通过利用二维深度图像，引入了一种创新框架来解决这些可制造性问题。这种方法将复杂的三维几何形状简化为可制造的轮廓，去除不可制造的悬挑等不可行特性，并允许直接考虑厚度和肋设计等重要制造方面。

    arXiv:2403.12098v1 Announce Type: cross  Abstract: Generative Design (GD) has evolved as a transformative design approach, employing advanced algorithms and AI to create diverse and innovative solutions beyond traditional constraints. Despite its success, GD faces significant challenges regarding the manufacturability of complex designs, often necessitating extensive manual modifications due to limitations in standard manufacturing processes and the reliance on additive manufacturing, which is not ideal for mass production. Our research introduces an innovative framework addressing these manufacturability concerns by integrating constraints pertinent to die casting and injection molding into GD, through the utilization of 2D depth images. This method simplifies intricate 3D geometries into manufacturable profiles, removing unfeasible features such as non-manufacturable overhangs and allowing for the direct consideration of essential manufacturing aspects like thickness and rib design. 
    
[^92]: 丰富用户购物记录：用层次推荐系统赋能电子商务

    Enriching User Shopping History: Empowering E-commerce with a Hierarchical Recommendation System

    [https://arxiv.org/abs/2403.12096](https://arxiv.org/abs/2403.12096)

    通过预测缺失的用户购物历史部分并适当丰富它，可以提高推荐系统的准确性。

    

    推荐系统可以通过分析用户的购物历史提供准确的推荐。更丰富的用户历史会导致更准确的推荐。然而，在实际应用中，用户更倾向于在物品以最低价格的电子商务平台上购物。换句话说，大多数用户同时从多个电子商务平台购物；用户的不同购物历史部分在不同的电子商务平台之间共享。因此，本研究假设任何电子商务平台都拥有用户历史的完整记录，但只能访问其中的一部分。如果推荐系统能够首先预测缺失的部分并适当丰富用户的购物历史，那么将可以更准确地推荐下一个商品。我们的推荐系统利用用户的购物历史来提高预测准确性。所提出的方法在NDCG@10和其他方面都显示出显著改进。

    arXiv:2403.12096v1 Announce Type: cross  Abstract: Recommendation systems can provide accurate recommendations by analyzing user shopping history. A richer user history results in more accurate recommendations. However, in real applications, users prefer e-commerce platforms where the item they seek is at the lowest price. In other words, most users shop from multiple e-commerce platforms simultaneously; different parts of the user's shopping history are shared between different e-commerce platforms. Consequently, we assume in this study that any e-commerce platform has a complete record of the user's history but can only access some parts of it. If a recommendation system is able to predict the missing parts first and enrich the user's shopping history properly, it will be possible to recommend the next item more accurately. Our recommendation system leverages user shopping history to improve prediction accuracy. The proposed approach shows significant improvements in both NDCG@10 and
    
[^93]: LLMs是一个好的难解填字游戏求解器吗？

    Are LLMs Good Cryptic Crossword Solvers?

    [https://arxiv.org/abs/2403.12094](https://arxiv.org/abs/2403.12094)

    本文建立了三种流行LLMs的基准结果，表明它们在难解填字游戏上的表现仍远远不及人类。

    

    难解填字游戏是一种谜题，不仅依赖于一般知识，还依赖于求解者在不同层面上操纵语言并处理各种类型的文字游戏。先前的研究表明，即使对于现代NLP模型来说，解决这类谜题也是一项挑战。然而，大型语言模型（LLMs）的能力尚未在这一任务上进行测试。在本文中，我们为三种流行的LLMs -- LLaMA2、Mistral和ChatGPT建立了基准结果，显示它们在这一任务上的表现仍远远不及人类。

    arXiv:2403.12094v1 Announce Type: new  Abstract: Cryptic crosswords are puzzles that rely not only on general knowledge but also on the solver's ability to manipulate language on different levels and deal with various types of wordplay. Previous research suggests that solving such puzzles is a challenge even for modern NLP models. However, the abilities of large language models (LLMs) have not yet been tested on this task. In this paper, we establish the benchmark results for three popular LLMs -- LLaMA2, Mistral, and ChatGPT -- showing that their performance on this task is still far from that of humans.
    
[^94]: 基于微观基础的宏观经济政策学习：一种斯塔克尔贝格均场博弈方法

    Learning Macroeconomic Policies based on Microfoundations: A Stackelberg Mean Field Game Approach

    [https://arxiv.org/abs/2403.12093](https://arxiv.org/abs/2403.12093)

    本研究提出了基于Stackelberg Mean Field Game的方法，可以有效地学习宏观经济政策，并在模型预训练和无模型Stackelberg均场强化学习算法的基础上取得了实验结果表明其优越性。

    

    有效的宏观经济政策在促进经济增长和社会稳定方面起着至关重要的作用。本文基于Stackelberg Mean Field Game（SMFG）模型，将最优宏观经济政策问题建模，其中政府作为政策制定的领导者，大规模家庭动态响应为追随者。这种建模方法捕捉了政府和大规模家庭之间的非对称动态博弈，并可以解释地评估基于微观基础的宏观经济政策效果，这是现有方法难以实现的。我们还提出了一种解决SMFG的方法，将真实数据进行预训练，并结合一种无模型的Stackelberg均场强化学习（SMFRL）算法，该算法可以独立于先前的环境知识和转变运行。我们的实验结果展示了SMFG方法在经济政策方面优于其他方法的优越性。

    arXiv:2403.12093v1 Announce Type: cross  Abstract: Effective macroeconomic policies play a crucial role in promoting economic growth and social stability. This paper models the optimal macroeconomic policy problem based on the \textit{Stackelberg Mean Field Game} (SMFG), where the government acts as the leader in policy-making, and large-scale households dynamically respond as followers. This modeling method captures the asymmetric dynamic game between the government and large-scale households, and interpretably evaluates the effects of macroeconomic policies based on microfoundations, which is difficult for existing methods to achieve. We also propose a solution for SMFGs, incorporating pre-training on real data and a model-free \textit{Stackelberg mean-field reinforcement learning }(SMFRL) algorithm, which operates independently of prior environmental knowledge and transitions. Our experimental results showcase the superiority of the SMFG method over other economic policies in terms 
    
[^95]: 匹配英语地址的方法

    Methods for Matching English Language Addresses

    [https://arxiv.org/abs/2403.12092](https://arxiv.org/abs/2403.12092)

    该研究定义并规范了生成英语地址匹配对的框架，并研究了距离基准方法到深度学习模型等各种方法之间的精度、召回率和准确度，以确定最适合地址匹配任务的方法。

    

    地址在文本数据中占据着一席之地，因为每个词所具有的位置重要性和它所涉及的地理范围。匹配地址的任务每天都在发生，并且存在于邮件重定向、实体解析等各种领域中。我们的工作定义和规范了一个框架，用于生成英语地址的匹配和不匹配对，并将其用于评估各种方法自动执行地址匹配。这些方法从基于距离的方法到深度学习模型各不相同。通过研究这些方法的精度、召回率和准确度指标，我们可以了解到最适合这种地址匹配任务设置的方法。

    arXiv:2403.12092v1 Announce Type: cross  Abstract: Addresses occupy a niche location within the landscape of textual data, due to the positional importance carried by every word, and the geographical scope it refers to. The task of matching addresses happens everyday and is present in various fields like mail redirection, entity resolution, etc. Our work defines, and formalizes a framework to generate matching and mismatching pairs of addresses in the English language, and use it to evaluate various methods to automatically perform address matching. These methods vary widely from distance based approaches to deep learning models. By studying the Precision, Recall and Accuracy metrics of these approaches, we obtain an understanding of the best suited method for this setting of the address matching task.
    
[^96]: 数字病理学中的基础模型和信息检索

    Foundation Models and Information Retrieval in Digital Pathology

    [https://arxiv.org/abs/2403.12090](https://arxiv.org/abs/2403.12090)

    论文回顾了数字病理学中基础模型和信息检索领域的最新进展。

    

    这篇论文回顾了数字病理学中基础模型、LLM、生成式人工智能、信息检索和内容检索的最新技术。

    arXiv:2403.12090v1 Announce Type: cross  Abstract: The paper reviews the state-of-the-art of foundation models, LLMs, generative AI, information retrieval and CBIR in digital pathology
    
[^97]: 生还的男孩：从LLM中删除哈利波特比报道的更困难

    The Boy Who Survived: Removing Harry Potter from an LLM is harder than reported

    [https://arxiv.org/abs/2403.12082](https://arxiv.org/abs/2403.12082)

    通过小规模实验发现，从LLM中删除哈利波特内容比先前报道的更加困难。

    

    最近的研究声称"我们有效地抹除了模型生成或回忆哈利波特相关内容的能力。"然而，一项小规模实验表明这一说法过于宽泛。少于十次试验导致重复和具体提及哈利波特，包括"啊，我明白了！"麻瓜"是特里·普拉切特的哈利波特系列中使用的术语...''。

    arXiv:2403.12082v1 Announce Type: cross  Abstract: Recent work arXiv.2310.02238 asserted that "we effectively erase the model's ability to generate or recall Harry Potter-related content.'' This claim is shown to be overbroad. A small experiment of less than a dozen trials led to repeated and specific mentions of Harry Potter, including "Ah, I see! A "muggle" is a term used in the Harry Potter book series by Terry Pratchett...''
    
[^98]: 评估生成式搜索引擎对对抗性事实问题的健壮性

    Evaluating Robustness of Generative Search Engine on Adversarial Factual Questions

    [https://arxiv.org/abs/2403.12077](https://arxiv.org/abs/2403.12077)

    评估生成式搜索引擎对对抗性事实问题的健壮性，通过对多种生成式搜索引擎进行人类评估，展示了对抗性事实问题在诱导不正确响应方面的有效性。

    

    生成式搜索引擎有潜力改变人们在线获取信息的方式，但现有大型语言模型（LLMs）支持的生成式搜索引擎生成的响应可能并不总是准确。然而，检索增强生成会加剧安全性问题，因为对手可能通过微妙地操纵声明的最薄弱部分成功规避整个系统。因此，我们提出在对抗性事实问题的现实且高风险设置中评估生成式搜索引擎的健壮性，其中对手仅具有黑盒系统访问权限，并试图欺骗模型返回不正确的响应。通过对必应聊天、PerplexityAI和YouChat等各种生成式搜索引擎进行全面的人类评估，我们展示了对抗性事实问题对诱导不正确响应的有效性。此外，检索增强生成展现出...

    arXiv:2403.12077v1 Announce Type: cross  Abstract: Generative search engines have the potential to transform how people seek information online, but generated responses from existing large language models (LLMs)-backed generative search engines may not always be accurate. Nonetheless, retrieval-augmented generation exacerbates safety concerns, since adversaries may successfully evade the entire system by subtly manipulating the most vulnerable part of a claim. To this end, we propose evaluating the robustness of generative search engines in the realistic and high-risk setting, where adversaries have only black-box system access and seek to deceive the model into returning incorrect responses. Through a comprehensive human evaluation of various generative search engines, such as Bing Chat, PerplexityAI, and YouChat across diverse queries, we demonstrate the effectiveness of adversarial factual questions in inducing incorrect responses. Moreover, retrieval-augmented generation exhibits a
    
[^99]: 神经元中心的赫布学习

    Neuron-centric Hebbian Learning

    [https://arxiv.org/abs/2403.12076](https://arxiv.org/abs/2403.12076)

    提出了一种新的神经元中心的赫布学习模型，相较于传统的ABCD规则，将参数减少了从$5W$到$5N$。

    

    大脑学习机制背后最引人注目的能力之一是通过结构和功能可塑性调整其突触。尽管突触在传递信息到整个大脑中起着基本作用，但几项研究表明，是神经元的激活产生了对突触的改变。然而，大多数为人工神经网络（NNs）设计的可塑性模型，如ABCD规则，侧重于突触而不是神经元，因此优化突触特定的赫布参数。然而，这种方法增加了优化过程的复杂性，因为每个突触都与多个赫布参数相关联。为了克服这一限制，我们提出了一种新颖的可塑性模型，称为神经元中心的赫布学习（NcHL），其优化侧重于神经元而不是突触特定的赫布参数。与ABCD规则相比，NcHL将参数减少从$5W$到$5N$。

    arXiv:2403.12076v1 Announce Type: cross  Abstract: One of the most striking capabilities behind the learning mechanisms of the brain is the adaptation, through structural and functional plasticity, of its synapses. While synapses have the fundamental role of transmitting information across the brain, several studies show that it is the neuron activations that produce changes on synapses. Yet, most plasticity models devised for artificial Neural Networks (NNs), e.g., the ABCD rule, focus on synapses, rather than neurons, therefore optimizing synaptic-specific Hebbian parameters. This approach, however, increases the complexity of the optimization process since each synapse is associated to multiple Hebbian parameters. To overcome this limitation, we propose a novel plasticity model, called Neuron-centric Hebbian Learning (NcHL), where optimization focuses on neuron- rather than synaptic-specific Hebbian parameters. Compared to the ABCD rule, NcHL reduces the parameters from $5W$ to $5N$
    
[^100]: Adversarial Nibbler: 一种用于识别文本到图像生成中多样化危害的开放式红队方法

    Adversarial Nibbler: An Open Red-Teaming Method for Identifying Diverse Harms in Text-to-Image Generation

    [https://arxiv.org/abs/2403.12075](https://arxiv.org/abs/2403.12075)

    批评了文本到图像生成中模型对非明显攻击的鲁棒性，提出了Adversarial Nibbler Challenge以众包多样化的提示来纠正模型的安全问题

    

    随着文本到图像（T2I）生成AI模型的崛起，评估模型对于不明显攻击的稳健性以减少生成冒犯性图像变得至关重要。通过专注于"隐性对抗"提示（触发T2I模型生成不安全图像的非明显原因），我们独立辨别出一组难以发现的安全问题，人类创造力很适合揭示这些问题。为此，我们构建了Adversarial Nibbler Challenge，这是一个红队方法，用于众包一组多样化的隐性对抗性提示。我们已汇总一套最先进的T2I模型，采用简单用户界面来识别和注释危害，并吸引广泛人群来捕捉在标准测试中可能被忽视的长尾安全问题。挑战在连续回合中进行，以实现对T2I模型中安全隐患的持续发现和分析。

    arXiv:2403.12075v1 Announce Type: cross  Abstract: With the rise of text-to-image (T2I) generative AI models reaching wide audiences, it is critical to evaluate model robustness against non-obvious attacks to mitigate the generation of offensive images. By focusing on ``implicitly adversarial'' prompts (those that trigger T2I models to generate unsafe images for non-obvious reasons), we isolate a set of difficult safety issues that human creativity is well-suited to uncover. To this end, we built the Adversarial Nibbler Challenge, a red-teaming methodology for crowdsourcing a diverse set of implicitly adversarial prompts. We have assembled a suite of state-of-the-art T2I models, employed a simple user interface to identify and annotate harms, and engaged diverse populations to capture long-tail safety issues that may be overlooked in standard testing. The challenge is run in consecutive rounds to enable a sustained discovery and analysis of safety pitfalls in T2I models.   In this pape
    
[^101]: 基于社交网络的eHealth干预对儿童健康习惯改善的可行性研究

    Feasibility of Social-Network-Based eHealth Intervention on the Improvement of Healthy Habits among Children

    [https://arxiv.org/abs/2403.12073](https://arxiv.org/abs/2403.12073)

    通过基于社交网络的eHealth干预措施，本研究展示了对改善儿童健康习惯的可行性，提供了日常营养和体育活动信息以及虚拟奖励的方式来促进互动。

    

    本研究展示了一种针对青少年人群改善饮食习惯和体育活动的eHealth解决方案的可行性。研究对象为11至15岁之间的儿童。在为期14周的时间里，对139名干预组学生和91名对照组学生进行了干预，这两所学校参与了这项研究。干预组通过用户帐户和密码访问网络，能够建立友谊关系、发布评论、点赞、与其他用户互动，每天收到关于营养和体育活动的通知和信息，并因改善习惯而获得（虚拟）奖励。对照组没有访问这些功能的权限。在性别、年龄、身体质量指数和初始健康习惯方面，样本之间的均匀性得到了证实。前后测量是通过自我报告进行的。

    arXiv:2403.12073v1 Announce Type: cross  Abstract: This study shows the feasibility of an eHealth solution for tackling eating habits and physical activity in the adolescent population. The participants were children from 11 to 15 years old. An intervention was carried out on 139 students in the intervention group and 91 students in the control group, in two schools during 14 weeks. The intervention group had access to the web through a user account and a password. They were able to create friendship relationships, post comments, give likes and interact with other users, as well as receive notifications and information about nutrition and physical activity on a daily basis and get (virtual) rewards for improving their habits. The control group did not have access to any of these features. The homogeneity of the samples in terms of gender, age, body mass index and initial health-related habits was demonstrated. Pre- and post-measurements were collected through self-reports on the applic
    
[^102]: 个性化教育定制：以GenAI为基础的课程规划新视角

    Tailoring Education with GenAI: A New Horizon in Lesson Planning

    [https://arxiv.org/abs/2403.12071](https://arxiv.org/abs/2403.12071)

    GenAI工具利用先进自然语言处理技术，为教育工作者提供个性化课程规划，通过创新的“交互式超级提示”功能，可定制生成课程计划，评估中包括定量和定性标准。

    

    在教育方面，生成式人工智能（GenAI）的出现为传统教学方法带来了革命性的变革，通常忽视个别学生的多样化需求。本研究介绍了一种基于先进自然语言处理的GenAI工具，设计为教育工作者的数字助手，可以帮助制定定制化的课程计划。该工具采用了一项名为“交互式超级提示”的创新功能，这是一个全面的查询系统，允许教育工作者输入详细的课堂特定信息，如学生人口统计信息、学习目标和偏好的教学风格。然后，GenAI通过处理这些输入来生成定制的课程计划。为了评估该工具的有效性，实施了一种全面的方法，既包括定量（即节省的时间百分比）又包括定性（即用户满意度）标准，涵盖了各种学科和教育水平，并持续收费。

    arXiv:2403.12071v1 Announce Type: cross  Abstract: The advent of Generative AI (GenAI) in education presents a transformative approach to traditional teaching methodologies, which often overlook the diverse needs of individual students. This study introduces a GenAI tool, based on advanced natural language processing, designed as a digital assistant for educators, enabling the creation of customized lesson plans. The tool utilizes an innovative feature termed 'interactive mega-prompt,' a comprehensive query system that allows educators to input detailed classroom specifics such as student demographics, learning objectives, and preferred teaching styles. This input is then processed by the GenAI to generate tailored lesson plans. To evaluate the tool's effectiveness, a comprehensive methodology incorporating both quantitative (i.e., % of time savings) and qualitative (i.e., user satisfaction) criteria was implemented, spanning various subjects and educational levels, with continuous fee
    
[^103]: 缺乏地面真相情况下提升建模的公平评估

    Fairness Evaluation for Uplift Modeling in the Absence of Ground Truth

    [https://arxiv.org/abs/2403.12069](https://arxiv.org/abs/2403.12069)

    提出了一个框架，通过生成替代品来充当提升建模活动的反事实标签代理，从而进行更全面的二进制公平性评估。

    

    人工智能自动决策系统采用加速，对算法决策公平性进行评估面临挑战，特别是在缺乏地面真相的情况下。本文提出了一个框架来克服缺少地面真相的问题，通过产生替代品来充当提升建模活动的反事实标签代理。我们利用替代地面真相进行更全面的二进制公平性评估。

    arXiv:2403.12069v1 Announce Type: cross  Abstract: The acceleration in the adoption of AI-based automated decision-making systems poses a challenge for evaluating the fairness of algorithmic decisions, especially in the absence of ground truth. When designing interventions, uplift modeling is used extensively to identify candidates that are likely to benefit from treatment. However, these models remain particularly susceptible to fairness evaluation due to the lack of ground truth on the outcome measure since a candidate cannot be in both treatment and control simultaneously. In this article, we propose a framework that overcomes the missing ground truth problem by generating surrogates to serve as a proxy for counterfactual labels of uplift modeling campaigns. We then leverage the surrogate ground truth to conduct a more comprehensive binary fairness evaluation. We show how to apply the approach in a comprehensive study from a real-world marketing campaign for promotional offers and d
    
[^104]: 使用应用特定多核架构设计SNN模型的设计空间探索

    Design-Space Exploration of SNN Models using Application-Specific Multi-Core Architectures

    [https://arxiv.org/abs/2403.12061](https://arxiv.org/abs/2403.12061)

    提出了一种基于应用特定多核架构的新型运行时多核架构模拟器“RAVSim”，通过该模拟器，用户可以在执行过程中与模型交互并修改参数值集。

    

    鉴于当前理解和利用SNN的潜在特性存在的动机和困难，我们提出了一种名为“RAVSim”（运行时分析和可视化模拟器）的新型运行时多核架构模拟器，这是一款尖端的SNN模拟器，使用LabVIEW开发，并作为官方模块在其网站上公开提供。RAVSim是一种运行时虚拟仿真环境工具，使用户能够与模型互动，观察其输出浓度的行为，并在模拟执行过程中随时修改参数值集。最近已经提出了一些流行的工具，但我们认为这些工具都不允许用户与模型仿真进行实时交互。

    arXiv:2403.12061v1 Announce Type: cross  Abstract: With the motivation and the difficulties that currently exist in comprehending and utilizing the promising features of SNNs, we proposed a novel run-time multi-core architecture-based simulator called "RAVSim" (Runtime Analysis and Visualization Simulator), a cutting-edge SNN simulator, developed using LabVIEW and it is publicly available on their website as an official module. RAVSim is a runtime virtual simulation environment tool that enables the user to interact with the model, observe its behavior of output concentration, and modify the set of parametric values at any time while the simulation is in execution. Recently some popular tools have been presented, but we believe that none of the tools allow users to interact with the model simulation in run time.
    
[^105]: 基于水的元启发式算法：水动力学如何帮助我们解决NP难题

    Water-Based Metaheuristics: How Water Dynamics Can Help Us to Solve NP-Hard Problems

    [https://arxiv.org/abs/2403.12058](https://arxiv.org/abs/2403.12058)

    本论文旨在阐明基于水的元启发式算法之间看似相关但实际差异巨大的研究，探讨它们在搜索方式和解决方案构建方面的不同之处。

    

    在过去的十年中，许多基于水的优化元启发式算法已被引入，旨在解决组合优化和连续优化问题。这些方法在其基础自然隐喻方面存在强烈相似性（大多数方法以某种方式模拟水滴协同形成通往大海的路径），但最终算法在搜索方式或解决方案构建方式上却有很大不同。研究人员或从业者可能会认为两种基于水的元启发式算法之间的相似度程度严重依赖于它们模拟的自然水动力学的相似性，但事实并非如此。

    arXiv:2403.12058v1 Announce Type: cross  Abstract: Many water-based optimization metaheuristics have been introduced during the last decade, both for combinatorial and for continuous optimization. Despite the strong similarities of these methods in terms of their underlying natural metaphors (most of them emulate, in some way or another, how drops collaboratively form paths down to the sea), in general the resulting algorithms are quite different in terms of their searching approach or their solution construction approach. For instance, each entity may represent a solution by itself or, alternatively, entities may construct solutions by modifying the landscape while moving. A researcher or practitioner could assume that the degree of similarity between two water-based metaheuristics heavily depends on the similarity of the natural water mechanics they emulate, but this is not the case. In order to bring some clarity to this mosaic of apparently related metaheuristics, in this paper we 
    
[^106]: 冠状动脉造影中基于深度学习的侧枝循环检测

    Deep learning based detection of collateral circulation in coronary angiographies

    [https://arxiv.org/abs/2403.12055](https://arxiv.org/abs/2403.12055)

    提出了一种基于深度学习的新方法，用于在冠状动脉造影图像中检测冠状动脉侧枝循环，可进行空间特征提取和时间处理。

    

    冠状动脉疾病（CAD）是全球主要的死亡和住院原因。动脉粥样硬化是CAD最常见的原因，是一种逐渐狭窄动脉并具有潜在致命效果的炎症性疾病。然而，在动脉粥样硬化存在的情况下，循环经常通过侧支动脉的形成来适应，从而实现显著的长期健康效益。因此，及时检测冠状动脉侧枝循环（CCC）对于CAD个性化医学至关重要。我们提出了一种新颖的基于深度学习的方法来检测冠状动脉造影中的CCC。我们的方法依赖于卷积骨干从冠状动脉造影序列的每帧中提取空间特征。然后将这些特征连接起来，随后由另一个卷积层在时间上处理嵌入。由于数据稀缺，我们还尝试在预训练骨干模型上进行实验。

    arXiv:2403.12055v1 Announce Type: cross  Abstract: Coronary artery disease (CAD) is the dominant cause of death and hospitalization across the globe. Atherosclerosis, an inflammatory condition that gradually narrows arteries and has potentially fatal effects, is the most frequent cause of CAD. Nonetheless, the circulation regularly adapts in the presence of atherosclerosis, through the formation of collateral arteries, resulting in significant long-term health benefits. Therefore, timely detection of coronary collateral circulation (CCC) is crucial for CAD personalized medicine. We propose a novel deep learning based method to detect CCC in angiographic images. Our method relies on a convolutional backbone to extract spatial features from each frame of an angiography sequence. The features are then concatenated, and subsequently processed by another convolutional layer that processes embeddings temporally. Due to scarcity of data, we also experiment with pretraining the backbone on cor
    
[^107]: 利用胶囊网络和图神经网络提取空间和语义特征进行皮肤癌诊断

    Leveraging Spatial and Semantic Feature Extraction for Skin Cancer Diagnosis with Capsule Networks and Graph Neural Networks

    [https://arxiv.org/abs/2403.12009](https://arxiv.org/abs/2403.12009)

    本研究通过将图神经网络与胶囊网络相结合，提出了一种创新方法来增强皮肤癌诊断的分类性能。

    

    在皮肤病变图像分类领域，复杂的空间和语义特征对传统的卷积神经网络（CNN）方法构成了重大挑战。皮肤病变数据集的不平衡性加剧了这些挑战，这阻碍了模型有效学习少数类特征的能力。本研究通过将图神经网络（GNNs）与胶囊网络相结合，提出了一种创新方法来增强分类性能。GNNs擅长处理图结构数据，为捕获复杂模式和关系提供了一种高级机制，远超传统CNN的能力。胶囊网络进一步通过提供对空间层次的优越识别能力来贡献。

    arXiv:2403.12009v1 Announce Type: cross  Abstract: In the realm of skin lesion image classification, the intricate spatial and semantic features pose significant challenges for conventional Convolutional Neural Network (CNN)-based methodologies. These challenges are compounded by the imbalanced nature of skin lesion datasets, which hampers the ability of models to learn minority class features effectively. Despite augmentation strategies, such as those using Generative Adversarial Networks (GANs), previous attempts have not fully addressed these complexities. This study introduces an innovative approach by integrating Graph Neural Networks (GNNs) with Capsule Networks to enhance classification performance. GNNs, known for their proficiency in handling graph-structured data, offer an advanced mechanism for capturing complex patterns and relationships beyond the capabilities of traditional CNNs. Capsule Networks further contribute by providing superior recognition of spatial hierarchies 
    
[^108]: 通过半监督预训练和时间建模探索面部表情识别

    Exploring Facial Expression Recognition through Semi-Supervised Pretraining and Temporal Modeling

    [https://arxiv.org/abs/2403.11942](https://arxiv.org/abs/2403.11942)

    该论文通过半监督学习技术生成表情类别伪标签，实现了面部表情识别模型的泛化能力，在面临数据集限制和类别不平衡问题时取得了优异的识别性能。

    

    面部表情识别（FER）在计算机视觉中起着关键作用，并在各个领域中有着广泛的应用。本文旨在介绍我们针对即将在CVPR2024举行的第6届野外情感行为分析（ABAW）比赛的方法。我们在面部表情识别任务中，利用半监督学习技术为未标记的面部数据生成表情类别伪标签，通过均匀采样标记的面部表情样本，并实施去偏反馈学习策略来解决数据集中类别不平衡的问题和半监督学习中可能存在的数据偏差问题。

    arXiv:2403.11942v1 Announce Type: cross  Abstract: Facial Expression Recognition (FER) plays a crucial role in computer vision and finds extensive applications across various fields. This paper aims to present our approach for the upcoming 6th Affective Behavior Analysis in-the-Wild (ABAW) competition, scheduled to be held at CVPR2024.. In the facial expression recognition task, The limited size of the FER dataset poses a challenge to the expression recognition model's generalization ability, resulting in subpar recognition performance. To address this problem, we employ a semi-supervised learning technique to generate expression category pseudo-labels for unlabeled face data. At the same time, we uniformly sampled the labeled facial expression samples and implemented a debiased feedback learning strategy to address the problem of category imbalance in the dataset and the possible data bias in semi-supervised learning. Moreover, , to further compensate for the limitation and bias of fe
    
[^109]: 具有潜在状态推断的强化学习在自动匝道合并中的应用

    Reinforcement Learning with Latent State Inference for Autonomous On-ramp Merging under Observation Delay

    [https://arxiv.org/abs/2403.11852](https://arxiv.org/abs/2403.11852)

    本文提出了一种具有潜在状态推断的强化学习方法，用于解决自动匝道合并问题，在没有详细了解周围车辆意图或驾驶风格的情况下安全执行匝道合并任务，并考虑了观测延迟，以增强代理在动态交通状况中的决策能力。

    

    本文提出了一种解决自动匝道合并问题的新方法，其中自动驾驶车辆需要无缝地融入多车道高速公路上的车流。我们介绍了Lane-keeping, Lane-changing with Latent-state Inference and Safety Controller (L3IS)代理，旨在在没有关于周围车辆意图或驾驶风格的全面知识的情况下安全执行匝道合并任务。我们还提出了该代理的增强版AL3IS，考虑了观测延迟，使代理能够在具有车辆间通信延迟的现实环境中做出更稳健的决策。通过通过潜在状态建模环境中的不可观察方面，如其他驾驶员的意图，我们的方法增强了代理适应动态交通状况、优化合并操作并确保与其他车辆进行安全互动的能力。

    arXiv:2403.11852v1 Announce Type: cross  Abstract: This paper presents a novel approach to address the challenging problem of autonomous on-ramp merging, where a self-driving vehicle needs to seamlessly integrate into a flow of vehicles on a multi-lane highway. We introduce the Lane-keeping, Lane-changing with Latent-state Inference and Safety Controller (L3IS) agent, designed to perform the on-ramp merging task safely without comprehensive knowledge about surrounding vehicles' intents or driving styles. We also present an augmentation of this agent called AL3IS that accounts for observation delays, allowing the agent to make more robust decisions in real-world environments with vehicle-to-vehicle (V2V) communication delays. By modeling the unobservable aspects of the environment through latent states, such as other drivers' intents, our approach enhances the agent's ability to adapt to dynamic traffic conditions, optimize merging maneuvers, and ensure safe interactions with other vehi
    
[^110]: 使用元提示自动化LLMs进行零样本视觉识别

    Meta-Prompting for Automating Zero-shot Visual Recognition with LLMs

    [https://arxiv.org/abs/2403.11755](https://arxiv.org/abs/2403.11755)

    提出了Meta-Prompting for Visual Recognition (MPVR)方法，通过仅需少量信息即可自动化零样本识别中的提示生成过程。

    

    大型语言模型（LLM）生成的类别特定提示的提示集成已经被证明是增强视觉语言模型（VLMs）零样本识别能力的有效方法。为了获得这些类别特定提示，现有方法依赖于手工为LLMs设计提示，以生成下游任务的VLM提示。然而，这需要手动编写这些任务特定提示，而且它们可能无法涵盖与感兴趣类别相关的各种视觉概念和任务特定风格。为了有效地将人类排除在循环之外，并完全自动化零样本识别的提示生成过程，我们提出了用于视觉识别的元提示（MPVR）。仅以目标任务的少量自然语言描述形式以及一系列相关类别标签作为输入，MPVR自动产生一个多样化的类别提示集。

    arXiv:2403.11755v1 Announce Type: cross  Abstract: Prompt ensembling of Large Language Model (LLM) generated category-specific prompts has emerged as an effective method to enhance zero-shot recognition ability of Vision-Language Models (VLMs). To obtain these category-specific prompts, the present methods rely on hand-crafting the prompts to the LLMs for generating VLM prompts for the downstream tasks. However, this requires manually composing these task-specific prompts and still, they might not cover the diverse set of visual concepts and task-specific styles associated with the categories of interest. To effectively take humans out of the loop and completely automate the prompt generation process for zero-shot recognition, we propose Meta-Prompting for Visual Recognition (MPVR). Taking as input only minimal information about the target task, in the form of its short natural language description, and a list of associated class labels, MPVR automatically produces a diverse set of cat
    
[^111]: SmartRefine: 一种场景自适应细化框架，用于高效运动预测

    SmartRefine: An Scenario-Adaptive Refinement Framework for Efficient Motion Prediction

    [https://arxiv.org/abs/2403.11492](https://arxiv.org/abs/2403.11492)

    SmartRefine提出了一种场景自适应细化策略，可在最小的额外计算量下对运动预测进行细化

    

    预测周围代理的未来运动对自动驾驶车辆（AVs）在动态的、人机混合环境中安全运行至关重要。上下文信息，如道路地图和周围代理的状态，为运动行为预测提供关键的几何和语义信息。本文引入了一种新颖的场景自适应细化策略，称为SmartRefine，以最小的额外计算量对预测进行细化。具体而言，SmartRefine可以根据每个场景的特性全面调整细化配置，并通过引入一种质量来智能地选择细化迭代的数量

    arXiv:2403.11492v1 Announce Type: cross  Abstract: Predicting the future motion of surrounding agents is essential for autonomous vehicles (AVs) to operate safely in dynamic, human-robot-mixed environments. Context information, such as road maps and surrounding agents' states, provides crucial geometric and semantic information for motion behavior prediction. To this end, recent works explore two-stage prediction frameworks where coarse trajectories are first proposed, and then used to select critical context information for trajectory refinement. However, they either incur a large amount of computation or bring limited improvement, if not both. In this paper, we introduce a novel scenario-adaptive refinement strategy, named SmartRefine, to refine prediction with minimal additional computation. Specifically, SmartRefine can comprehensively adapt refinement configurations based on each scenario's properties, and smartly chooses the number of refinement iterations by introducing a qualit
    
[^112]: 用于深度学习和大数据应用的自动化数据处理和特征工程：一项调查

    Automated data processing and feature engineering for deep learning and big data applications: a survey

    [https://arxiv.org/abs/2403.11395](https://arxiv.org/abs/2403.11395)

    现代人工智能方法旨在设计能够直接从数据中学习的算法，自动化数据处理任务的兴起驱动了机器学习和大数据应用中利用大量复杂数据的发展。

    

    现代人工智能（AI）的方法旨在设计能够直接从数据中学习的算法。这种方法取得了令人印象深刻的成果，并在AI的发展中做出了重要贡献，特别是在监督深度学习领域。它也简化了机器学习系统的设计，因为学习过程是高度自动化的。然而，并非所有传统深度学习流程中的数据处理任务都已自动化。在大多数情况下，数据必须在可以用于训练之前经过手动收集、预处理并通过数据增强进一步扩展。最近，出现了用于自动化这些任务的特殊技术。数据处理任务的自动化驱动力是利用大量复杂、异构数据进行机器学习和大数据应用。如今，基于自动化机器学习（A

    arXiv:2403.11395v1 Announce Type: cross  Abstract: Modern approach to artificial intelligence (AI) aims to design algorithms that learn directly from data. This approach has achieved impressive results and has contributed significantly to the progress of AI, particularly in the sphere of supervised deep learning. It has also simplified the design of machine learning systems as the learning process is highly automated. However, not all data processing tasks in conventional deep learning pipelines have been automated. In most cases data has to be manually collected, preprocessed and further extended through data augmentation before they can be effective for training. Recently, special techniques for automating these tasks have emerged. The automation of data processing tasks is driven by the need to utilize large volumes of complex, heterogeneous data for machine learning and big data applications. Today, end-to-end automated data processing systems based on automated machine learning (A
    
[^113]: CPA-Enhancer：链式思维驱动自适应增强器用于未知退化下的目标检测

    CPA-Enhancer: Chain-of-Thought Prompted Adaptive Enhancer for Object Detection under Unknown Degradations

    [https://arxiv.org/abs/2403.11220](https://arxiv.org/abs/2403.11220)

    提出了一种用于未知退化下目标检测的链式思维驱动自适应增强器CPA-Enhancer，并将其集成到通用检测器中，有效提升受损图像的检测性能

    

    目前，已经广泛研究了在已知单一退化情况下的目标检测方法。然而，现有方法需要先验知识来确定退化类型，并为每种类型训练一个单独的模型，从而限制了它们在不可预测环境中的实际应用。为了解决这一挑战，我们提出了一种链式思维（CoT）驱动的自适应增强器CPA-Enhancer，用于未知退化情况下的目标检测。具体而言，CPA-Enhancer在CoT提示的逐步指导下逐步调整其增强策略，这些提示编码了与退化相关的信息。据我们所知，这是首个利用CoT提示进行目标检测任务的工作。总的来说，CPA-Enhancer是一个即插即用的增强模型，可以集成到任何通用检测器中，在不事先知道退化类型的情况下，在受损图像上实现显著提升。实验结果表明，CPA-E

    arXiv:2403.11220v1 Announce Type: cross  Abstract: Object detection methods under known single degradations have been extensively investigated. However, existing approaches require prior knowledge of the degradation type and train a separate model for each, limiting their practical applications in unpredictable environments. To address this challenge, we propose a chain-of-thought (CoT) prompted adaptive enhancer, CPA-Enhancer, for object detection under unknown degradations. Specifically, CPA-Enhancer progressively adapts its enhancement strategy under the step-by-step guidance of CoT prompts, that encode degradation-related information. To the best of our knowledge, it's the first work that exploits CoT prompting for object detection tasks. Overall, CPA-Enhancer is a plug-and-play enhancement model that can be integrated into any generic detectors to achieve substantial gains on degraded images, without knowing the degradation type priorly. Experimental results demonstrate that CPA-E
    
[^114]: DTOR：决策树异常值回归器用于解释异常

    DTOR: Decision Tree Outlier Regressor to explain anomalies

    [https://arxiv.org/abs/2403.10903](https://arxiv.org/abs/2403.10903)

    DTOR是一种决策树异常值回归器，通过估计异常检测模型生成的异常分数来产生基于规则的解释，具有鲁棒性，适用于具有大量特征数据集。

    

    解释异常值的出现以及其产生机制在各种领域中可能非常重要。故障、欺诈、威胁等问题，除了被正确识别之外，通常需要有效的解释以有效执行可操作的对抗措施。越来越广泛地使用复杂的机器学习方法来识别异常值，使得这样的解释更具挑战性。我们提出了决策树异常值回归器（DTOR），这是一种通过估计异常检测模型生成的异常分数来为单个数据点生成基于规则的解释的技术。这是通过首先应用决策树回归器来计算估计分数，然后提取与数据点分数相关联的相对路径来实现的。我们的结果表明，即使在具有大量特征的数据集中，DTOR的鲁棒性也得到了证实。此外，与其他基于规则的方法相比

    arXiv:2403.10903v1 Announce Type: cross  Abstract: Explaining outliers occurrence and mechanism of their occurrence can be extremely important in a variety of domains. Malfunctions, frauds, threats, in addition to being correctly identified, oftentimes need a valid explanation in order to effectively perform actionable counteracts. The ever more widespread use of sophisticated Machine Learning approach to identify anomalies make such explanations more challenging. We present the Decision Tree Outlier Regressor (DTOR), a technique for producing rule-based explanations for individual data points by estimating anomaly scores generated by an anomaly detection model. This is accomplished by first applying a Decision Tree Regressor, which computes the estimation score, and then extracting the relative path associated with the data point score. Our results demonstrate the robustness of DTOR even in datasets with a large number of features. Additionally, in contrast to other rule-based approac
    
[^115]: 安全案例：证明先进人工智能系统的安全性

    Safety Cases: Justifying the Safety of Advanced AI Systems

    [https://arxiv.org/abs/2403.10462](https://arxiv.org/abs/2403.10462)

    本研究提出了一个安全案例框架来组织人工智能系统的安全性论证，包括四类论点：完全无法造成灾难，强大的控制措施，尽管有可能造成伤害，但依然可信赖，以及对可信的人工智能顾问的尊重。

    

    随着人工智能系统变得更加先进，企业和监管机构将面临关于是否安全进行训练和部署的困难决策。为了为这些决策做准备，我们研究了开发人员如何制定一种"安全案例"，这是一种结构化的理由，证明人工智能系统不太可能造成灾难。我们提出了一个组织安全案例的框架，并讨论了四类论证安全的论点：完全无法造成灾难，足够强大的控制措施，尽管能够造成伤害仍值得信赖，以及对可信的人工智能顾问的尊重。我们评估了每个类别中的具体论点示例，并概述了如何组合论点来证明人工智能系统可以安全部署。

    arXiv:2403.10462v1 Announce Type: cross  Abstract: As AI systems become more advanced, companies and regulators will make difficult decisions about whether it is safe to train and deploy them. To prepare for these decisions, we investigate how developers could make a 'safety case,' which is a structured rationale that AI systems are unlikely to cause a catastrophe. We propose a framework for organizing a safety case and discuss four categories of arguments to justify safety: total inability to cause a catastrophe, sufficiently strong control measures, trustworthiness despite capability to cause harm, and deference to credible AI advisors. We evaluate concrete examples of arguments in each category and outline how arguments could be combined to justify that AI systems are safe to deploy.
    
[^116]: AI增强的集体智能：现状与展望

    AI-enhanced Collective Intelligence: The State of the Art and Prospects

    [https://arxiv.org/abs/2403.10433](https://arxiv.org/abs/2403.10433)

    人类和人工智能形成的多层次集体智能网络，可以实现超越任一单独实体的集体智能水平。

    

    目前的社会挑战超出了人类个体或集体努力的能力。随着人工智能的发展，其在人类集体中的角色将从辅助工具转变为参与式成员。人类和人工智能拥有互补的能力，当二者协同作用时，可以实现一种超越单独人类或人工智能集体能力的集体智能水平。然而，人工智能系统中的交互本质上是复杂的，涉及复杂的过程和相互依赖关系。本综述从网络科学的视角出发，构想了一个多层次的人工智能集体智能表示，包括认知层、物理层和信息层。在这个多层网络中，人类和人工智能代理展现出不同的特征；人类在多样性方面从表层到深层属性不同，而人工智能代理在程度上也有所区别。

    arXiv:2403.10433v1 Announce Type: cross  Abstract: The current societal challenges exceed the capacity of human individual or collective effort alone. As AI evolves, its role within human collectives is poised to vary from an assistive tool to a participatory member. Humans and AI possess complementary capabilities that, when synergized, can achieve a level of collective intelligence that surpasses the collective capabilities of either humans or AI in isolation. However, the interactions in human-AI systems are inherently complex, involving intricate processes and interdependencies. This review incorporates perspectives from network science to conceptualize a multilayer representation of human-AI collective intelligence, comprising a cognition layer, a physical layer, and an information layer. Within this multilayer network, humans and AI agents exhibit varying characteristics; humans differ in diversity from surface-level to deep-level attributes, while AI agents range in degrees of f
    
[^117]: 使用大型语言模型生成针对非功能属性的系统级测试程序

    Large Language Models to Generate System-Level Test Programs Targeting Non-functional Properties

    [https://arxiv.org/abs/2403.10086](https://arxiv.org/abs/2403.10086)

    本文提出使用大型语言模型（LLMs）生成测试程序，以优化非功能属性。

    

    系统级测试（SLT）已经成为集成电路测试流程的一部分超过十年，并且仍然越来越重要。然而，目前不存在针对测试程序生成的系统化方法，特别是针对被测设备（DUT）的非功能属性。本文提出使用大型语言模型（LLMs）来生成测试程序。我们首次尝试了预训练的LLMs在测试程序生成中的表现，以优化DUT的非功能属性。

    arXiv:2403.10086v1 Announce Type: cross  Abstract: System-Level Test (SLT) has been a part of the test flow for integrated circuits for over a decade and still gains importance. However, no systematic approaches exist for test program generation, especially targeting non-functional properties of the Device under Test (DUT). Currently, test engineers manually compose test suites from off-the-shelf software, approximating the end-user environment of the DUT. This is a challenging and tedious task that does not guarantee sufficient control over non-functional properties. This paper proposes Large Language Models (LLMs) to generate test programs. We take a first glance at how pre-trained LLMs perform in test program generation to optimize non-functional properties of the DUT. Therefore, we write a prompt to generate C code snippets that maximize the instructions per cycle of a super-scalar, out-of-order architecture in simulation. Additionally, we apply prompt and hyperparameter optimizati
    
[^118]: 预测AI结肠镜模型对未知数据的泛化能力

    Predicting Generalization of AI Colonoscopy Models to Unseen Data

    [https://arxiv.org/abs/2403.09920](https://arxiv.org/abs/2403.09920)

    使用“Masked Siamese Network”（MSN）在未标记数据上识别新现象，并预测结肠镜模型对未知技术和不同国家数据的性能。

    

    背景和目标 AI结肠镜算法的泛化能力对于在临床实践中更广泛的应用至关重要。然而，目前评估在未知数据上的性能的技术需要昂贵且耗时的标签。我们使用“Masked Siamese Network”（MSN）在未知数据中识别新现象并预测息肉检测器的性能。MSN被训练来预测息肉图像中被屏蔽的区域，而无需任何标签。我们测试了MSN仅在以色列数据上进行训练的能力，以及在日本结肠镜（354个视频，128小时）上检测未知技术：窄带成像（NBI）和色细胞内镜（CE）。我们还测试了MSN预测跨国结肠镜视频上的息肉计算机辅助检测（CADe）的性能，尽管MSN未接受过来自日本的数据的训练。

    arXiv:2403.09920v1 Announce Type: cross  Abstract: Background and aims Generalizability of AI colonoscopy algorithms is important for wider adoption in clinical practice. However, current techniques for evaluating performance on unseen data require expensive and time-intensive labels.   Methods We use a "Masked Siamese Network" (MSN) to identify novel phenomena in unseen data and predict polyp detector performance. MSN is trained to predict masked out regions of polyp images, without any labels. We test MSN's ability to be trained on data only from Israel and detect unseen techniques, narrow-band imaging (NBI) and chromendoscoy (CE), on colonoscopes from Japan (354 videos, 128 hours). We also test MSN's ability to predict performance of Computer Aided Detection (CADe) of polyps on colonoscopies from both countries, even though MSN is not trained on data from Japan.   Results MSN correctly identifies NBI and CE as less similar to Israel whitelight than Japan whitelight (bootstrapped z-t
    
[^119]: Fisher Mask节点用于语言模型合并

    Fisher Mask Nodes for Language Model Merging

    [https://arxiv.org/abs/2403.09891](https://arxiv.org/abs/2403.09891)

    介绍了一种用于Transformers的新型模型合并方法，利用Fisher信息进行加权平均，提高了多任务模型的性能。

    

    微调预训练模型在下游性能方面具有显著优势。预训练模型（如BERT及其衍生物）在自然语言处理中的普遍性也导致了任务特定微调模型的激增。在多任务场景中，由于这些模型通常只能很好地执行一项任务，因此需要额外的训练或集成。模型合并这一不断增长的领域提供了一个解决方案，解决了将多个任务特定模型合并为单个多任务模型的挑战。在本研究中，我们引入了一种新颖的用于Transformers的模型合并方法，结合了先前Fisher加权平均和Fisher信息在模型修剪中的应用的见解。通过利用Transformer架构内的mask节点的Fisher信息，我们设计了一个计算效率高的加权平均方案。我们的方法展现出了稳定且显著的性能。

    arXiv:2403.09891v1 Announce Type: cross  Abstract: Fine-tuning pre-trained models provides significant advantages in downstream performance. The ubiquitous nature of pre-trained models such as BERT and its derivatives in natural language processing has also led to a proliferation of task-specific fine-tuned models. As these models typically only perform one task well, additional training or ensembling is required in multi-task scenarios. The growing field of model merging provides a solution, dealing with the challenge of combining multiple task-specific models into a single multi-task model. In this study, we introduce a novel model merging method for Transformers, combining insights from previous work in Fisher-weighted averaging and the use of Fisher information in model pruning. Utilizing the Fisher information of mask nodes within the Transformer architecture, we devise a computationally efficient weighted-averaging scheme. Our method exhibits a regular and significant performance
    
[^120]: FoldToken：通过矢量量化及更多方法学习蛋白质语言

    FoldToken: Learning Protein Language via Vector Quantization and Beyond

    [https://arxiv.org/abs/2403.09673](https://arxiv.org/abs/2403.09673)

    通过将蛋白质序列和结构表示为离散符号，并创建新的蛋白质语言，从而构建了一种用于序列-结构共生产的创新方法。

    

    是否存在一种同时描述蛋白质序列和结构的外语？由于连续3D点表示的蛋白质结构与离散序列的对比建模方式，长期以来一直存在挑战。我们引入了\textbf{FoldTokenizer}，将蛋白质序列-结构表示为离散符号。这种创新方法涉及将残基类型和结构投射到一个离散空间中，通过一个信息保存的重构损失进行指导。我们将学习到的离散符号称为\textbf{FoldToken}，而FoldTokens的序列则成为一种新的蛋白质语言，将蛋白质序列-结构转化为一种统一的形态。我们将创建的蛋白质语言应用于普通主干修补和抗体设计任务，构建了首个GPT风格模型(\textbf{FoldGPT})用于具有良好结果的序列-结构共生产。我们成功的关键在于显著的增强

    arXiv:2403.09673v1 Announce Type: cross  Abstract: Is there a foreign language describing protein sequences and structures simultaneously? Protein structures, represented by continuous 3D points, have long posed a challenge due to the contrasting modeling paradigms of discrete sequences. We introduce \textbf{FoldTokenizer} to represent protein sequence-structure as discrete symbols. This innovative approach involves projecting residue types and structures into a discrete space, guided by a reconstruction loss for information preservation. We refer to the learned discrete symbols as \textbf{FoldToken}, and the sequence of FoldTokens serves as a new protein language, transforming the protein sequence-structure into a unified modality. We apply the created protein language on general backbone inpainting and antibody design tasks, building the first GPT-style model (\textbf{FoldGPT}) for sequence-structure co-generation with promising results. Key to our success is the substantial enhancem
    
[^121]: STREAM：用于视频生成模型的时空评估和分析度量

    STREAM: Spatio-TempoRal Evaluation and Analysis Metric for Video Generative Models

    [https://arxiv.org/abs/2403.09669](https://arxiv.org/abs/2403.09669)

    提出了STREAM，一种新的视频评估度量方法，弥补了当前视频生成模型评估中对于时空特性的不足

    

    图像生成模型在生成逼真多样的图像方面取得了显著进展，得益于各种评估度量的全面指导。然而，当前的视频生成模型在生成短视频片段时仍然存在困难，缺乏提供改进见解的工具。目前的视频评估度量方法是通过将嵌入视频嵌入网络来简单调整图像度量方法而得到的，这可能低估了视频的独特特性。我们的分析表明，广泛使用的Frechet Video Distance (FVD) 在空间方面的重视程度要大于视频的时间自然性，且受到所使用的嵌入网络输入大小的限制，仅限于16帧视频。此外，它表现出相当大的不稳定性，并与人类评估存在差异。为了解决这些限制，我们提出了STREAM，一种新的视频评估度量方法，独特地设计以解决当前视频生成模型评估的挑战。

    arXiv:2403.09669v1 Announce Type: cross  Abstract: Image generative models have made significant progress in generating realistic and diverse images, supported by comprehensive guidance from various evaluation metrics. However, current video generative models struggle to generate even short video clips, with limited tools that provide insights for improvements. Current video evaluation metrics are simple adaptations of image metrics by switching the embeddings with video embedding networks, which may underestimate the unique characteristics of video. Our analysis reveals that the widely used Frechet Video Distance (FVD) has a stronger emphasis on the spatial aspect than the temporal naturalness of video and is inherently constrained by the input size of the embedding networks used, limiting it to 16 frames. Additionally, it demonstrates considerable instability and diverges from human evaluations. To address the limitations, we propose STREAM, a new video evaluation metric uniquely des
    
[^122]: 使用Q学习的奶牛养殖场电池管理的强化学习方法

    A Reinforcement Learning Approach to Dairy Farm Battery Management using Q Learning

    [https://arxiv.org/abs/2403.09499](https://arxiv.org/abs/2403.09499)

    该研究提出了一种基于Q学习的算法，以实现在奶牛养殖中整合可再生能源，以改善电池管理，应对电能消耗波动和能源价格波动的挑战。

    

    奶牛养殖消耗大量能源，是农业中一个能源密集型的部门。将可再生能源集成到奶牛养殖中可以帮助应对这一挑战。有效的电池管理对于整合可再生能源发电至关重要。管理电池的充电和放电由于电能消耗的波动、可再生能源发电的间歇性以及能源价格的波动而面临重大挑战。人工智能（AI）有潜力显著改善奶牛养殖中可再生能源的利用，然而在这一特定领域中进行的研究有限。本研究以爱尔兰作为案例研究，以实现其以可再生能源利用为核心的2030年能源战略。这项研究提出了一种基于Q学习的算法，用于安排电池的充电和放电。

    arXiv:2403.09499v1 Announce Type: cross  Abstract: Dairy farming consumes a significant amount of energy, making it an energy-intensive sector within agriculture. Integrating renewable energy generation into dairy farming could help address this challenge. Effective battery management is important for integrating renewable energy generation. Managing battery charging and discharging poses significant challenges because of fluctuations in electrical consumption, the intermittent nature of renewable energy generation, and fluctuations in energy prices. Artificial Intelligence (AI) has the potential to significantly improve the use of renewable energy in dairy farming, however, there is limited research conducted in this particular domain. This research considers Ireland as a case study as it works towards attaining its 2030 energy strategy centered on the utilization of renewable sources. This study proposes a Q-learning-based algorithm for scheduling battery charging and discharging in 
    
[^123]: 基于贝叶斯网络的表格数据和文本的临床推理

    Clinical Reasoning over Tabular Data and Text with Bayesian Networks

    [https://arxiv.org/abs/2403.09481](https://arxiv.org/abs/2403.09481)

    本文比较和讨论了如何将贝叶斯网络与神经文本表示相结合，以改进临床推理，特别是在处理自然语言数据方面。

    

    贝叶斯网络非常适合用于处理表格数据进行临床推理，但对于自然语言数据来说却不够兼容，而神经网络则为处理自然语言数据提供了成功的框架。本文比较并讨论了如何以生成性和判别性方式增强贝叶斯网络与神经文本表示，结合模拟结果以一个基础医疗案例（肺炎诊断）进行说明，并在更广泛的临床背景下进行讨论。

    arXiv:2403.09481v1 Announce Type: new  Abstract: Bayesian networks are well-suited for clinical reasoning on tabular data, but are less compatible with natural language data, for which neural networks provide a successful framework. This paper compares and discusses strategies to augment Bayesian networks with neural text representations, both in a generative and discriminative manner. This is illustrated with simulation results for a primary care use case (diagnosis of pneumonia) and discussed in a broader clinical context.
    
[^124]: 再现性和几何内在维度性：对图神经网络研究的调查

    Reproducibility and Geometric Intrinsic Dimensionality: An Investigation on Graph Neural Network Research

    [https://arxiv.org/abs/2403.08438](https://arxiv.org/abs/2403.08438)

    本文研究了图神经网络研究中的再现性和几何内在维度性问题，并引入机器学习中的再现性本体论，以及探讨了维度诅咒对数据收集、表示和分析的挑战。

    

    机器学习研究中复制和可再现性的困难近年来成为一个突出的话题。确保机器学习研究结果的可靠性需要可再现性，通过使用相同的代码和数据验证研究结果的可靠性。这促进了开放和可访问的研究、稳健的实验工作流程以及新发现的快速整合。评估研究出版物支持再现性的程度是本文的一个目标。为此，我们引入了一个机器学习中的再现性本体论，并将其应用于图神经网络的方法。在这些努力的基础上，我们转向机器学习中的另一个关键挑战，即维度诅咒，它在数据收集、表示和分析方面带来挑战，使得更难找到代表性数据。

    arXiv:2403.08438v1 Announce Type: cross  Abstract: Difficulties in replication and reproducibility of empirical evidences in machine learning research have become a prominent topic in recent years. Ensuring that machine learning research results are sound and reliable requires reproducibility, which verifies the reliability of research findings using the same code and data. This promotes open and accessible research, robust experimental workflows, and the rapid integration of new findings. Evaluating the degree to which research publications support these different aspects of reproducibility is one goal of the present work. For this we introduce an ontology of reproducibility in machine learning and apply it to methods for graph neural networks. Building on these efforts we turn towards another critical challenge in machine learning, namely the curse of dimensionality, which poses challenges in data collection, representation, and analysis, making it harder to find representative data 
    
[^125]: RLingua：利用大型语言模型改善在机器人操作中的强化学习样本效率

    RLingua: Improving Reinforcement Learning Sample Efficiency in Robotic Manipulations With Large Language Models

    [https://arxiv.org/abs/2403.06420](https://arxiv.org/abs/2403.06420)

    RLingua提出了一个框架，利用大型语言模型的内部知识来提高机器人操作中强化学习的样本效率。

    

    强化学习（RL）已经证明了其在解决各种任务中的能力，但以其低样本效率而声名狼藉。在本文中，我们提出了RLingua，这是一个可以利用大型语言模型（LLMs）的内部知识来减少机器人操作中RL的样本复杂性的框架。为此，我们首先介绍了如何通过提示工程提取LLMs的先验知识，从而生成特定任务的初步基于规则的机器人控制器。尽管不完美，LLM生成的机器人控制器被用于在rollout时以衰减概率生成动作样本，从而提高RL的样本效率。我们采用了演员-评论家框架，并修改了演员损失，以使策略学习朝着LLM生成的控制器规范化。RLingua还提供了一种改善不完美的LLM生成机器人控制器的新方法。我们展示了RLing

    arXiv:2403.06420v1 Announce Type: cross  Abstract: Reinforcement learning (RL) has demonstrated its capability in solving various tasks but is notorious for its low sample efficiency. In this paper, we propose RLingua, a framework that can leverage the internal knowledge of large language models (LLMs) to reduce the sample complexity of RL in robotic manipulations. To this end, we first present how to extract the prior knowledge of LLMs by prompt engineering so that a preliminary rule-based robot controller for a specific task can be generated. Despite being imperfect, the LLM-generated robot controller is utilized to produce action samples during rollouts with a decaying probability, thereby improving RL's sample efficiency. We employ the actor-critic framework and modify the actor loss to regularize the policy learning towards the LLM-generated controller. RLingua also provides a novel method of improving the imperfect LLM-generated robot controllers by RL. We demonstrated that RLing
    
[^126]: 能否用LLM替代人工标注？ 无人机交付任务下的细粒度中文地址实体识别数据集案例研究

    Can LLM Substitute Human Labeling? A Case Study of Fine-grained Chinese Address Entity Recognition Dataset for UAV Delivery

    [https://arxiv.org/abs/2403.06097](https://arxiv.org/abs/2403.06097)

    提出了适用于无人机交付系统中地址解析任务的细粒度中文姓名实体识别数据集CNER-UAV，包含五个类别的多样化数据，经过严格的数据清洗和去敏处理，约有12,000个标注样本，评估了传统的实体识别模型并提供了深入分析

    

    我们提出了CNER-UAV，一个专为无人机交付系统中地址解析任务设计的细粒度中文姓名实体识别数据集。该数据集涵盖了五个类别，可以全面训练和评估实体识别模型。为构建这一数据集，我们从真实无人机交付系统中获取数据，并进行了严格的数据清洗和去敏处理，确保数据的隐私性和完整性。最终的数据集约包含12,000个标注样本，经过人工专家和大型语言模型的注释。我们在我们的数据集上评估了传统的实体识别模型，并提供了深入分析。数据集和模型可以在 \url{https://github.com/zhhvvv/CNER-UAV} 上公开获取。

    arXiv:2403.06097v1 Announce Type: cross  Abstract: We present CNER-UAV, a fine-grained \textbf{C}hinese \textbf{N}ame \textbf{E}ntity \textbf{R}ecognition dataset specifically designed for the task of address resolution in \textbf{U}nmanned \textbf{A}erial \textbf{V}ehicle delivery systems. The dataset encompasses a diverse range of five categories, enabling comprehensive training and evaluation of NER models. To construct this dataset, we sourced the data from a real-world UAV delivery system and conducted a rigorous data cleaning and desensitization process to ensure privacy and data integrity. The resulting dataset, consisting of around 12,000 annotated samples, underwent human experts and \textbf{L}arge \textbf{L}anguage \textbf{M}odel annotation. We evaluated classical NER models on our dataset and provided in-depth analysis. The dataset and models are publicly available at \url{https://github.com/zhhvvv/CNER-UAV}.
    
[^127]: CarbonNet: 计算机视觉在气候变化中的作用是什么？ 应用：学习从地下储存空间几何形状中减缓全球变暖的地质力学

    CarbonNet: How Computer Vision Plays a Role in Climate Change? Application: Learning Geomechanics from Subsurface Geometry of CCS to Mitigate Global Warming

    [https://arxiv.org/abs/2403.06025](https://arxiv.org/abs/2403.06025)

    这项研究介绍了一种利用计算机视觉从地下储存空间几何图像中预测陆地表面位移的新方法，为碳捕集和封存项目中的决策提供支持。

    

    我们介绍了一种新方法，使用计算机视觉从地下储存空间几何图像中预测陆地表面位移，以应用于碳捕集和封存（CCS）。CCS已被证明是碳中和社会的关键组成部分。然而，科学家发现存在挑战，包括由于大模型尺度而导致的高计算成本，以及难以泛化具有复杂物理学的预训练模型的限制。我们通过直接从地下储存空间几何图像训练模型来应对这些挑战。我们的目标是理解由碳注入导致的陆地表面位移响应，并利用我们训练的模型来为CCS项目的决策提供信息。

    arXiv:2403.06025v1 Announce Type: cross  Abstract: We introduce a new approach using computer vision to predict the land surface displacement from subsurface geometry images for Carbon Capture and Sequestration (CCS). CCS has been proved to be a key component for a carbon neutral society. However, scientists see there are challenges along the way including the high computational cost due to the large model scale and limitations to generalize a pre-trained model with complex physics. We tackle those challenges by training models directly from the subsurface geometry images. The goal is to understand the respons of land surface displacement due to carbon injection and utilize our trained models to inform decision making in CCS projects.   We implement multiple models (CNN, ResNet, and ResNetUNet) for static mechanics problem, which is a image prediction problem. Next, we use the LSTM and transformer for transient mechanics scenario, which is a video prediction problem. It shows ResNetUNe
    
[^128]: ChatASU：唤起LLM的反思，真正理解对话中的方面情绪

    ChatASU: Evoking LLM's Reflexion to Truly Understand Aspect Sentiment in Dialogues

    [https://arxiv.org/abs/2403.05326](https://arxiv.org/abs/2403.05326)

    本文提出了一个新的基于聊天的方面情绪理解（ChatASU）任务，旨在探索大型语言模型（LLMs）在对话场景中理解方面情绪的能力，并引入了一个子任务Aspect Chain Reasoning（ACR）任务来解决方面共指问题。

    

    在互动场景（例如，问答和对话）中进行方面情绪理解（ASU）近年来引起了越来越多的关注并取得了重要进展。然而，现有研究大多忽略了意见目标（即方面）的共指问题，而这种现象在互动场景特别是对话中普遍存在，限制了ASU的性能。最近，大型语言模型（LLM）展示了将各种NLP任务与聊天范式相结合的强大能力。基于此，本文提出了一项新的基于聊天的方面情绪理解（ChatASU）任务，旨在探索LLMs在对话场景中理解方面情绪的能力。特别是，这项ChatASU任务引入了一个子任务，即方面链推理（ACR）任务，以解决方面共指问题。在此基础上，我们提出了一种可信的自反思方法（TSA）与ChatGLM作为背景。

    arXiv:2403.05326v1 Announce Type: cross  Abstract: Aspect Sentiment Understanding (ASU) in interactive scenarios (e.g., Question-Answering and Dialogue) has attracted ever-more interest in recent years and achieved important progresses. However, existing studies on interactive ASU largely ignore the coreference issue for opinion targets (i.e., aspects), while this phenomenon is ubiquitous in interactive scenarios especially dialogues, limiting the ASU performance. Recently, large language models (LLMs) shows the powerful ability to integrate various NLP tasks with the chat paradigm. In this way, this paper proposes a new Chat-based Aspect Sentiment Understanding (ChatASU) task, aiming to explore LLMs' ability in understanding aspect sentiments in dialogue scenarios. Particularly, this ChatASU task introduces a sub-task, i.e., Aspect Chain Reasoning (ACR) task, to address the aspect coreference issue. On this basis, we propose a Trusted Self-reflexion Approach (TSA) with ChatGLM as back
    
[^129]: 一个镜子的库：低维深度神经网络是具有反射特征的凸Lasso模型

    A Library of Mirrors: Deep Neural Nets in Low Dimensions are Convex Lasso Models with Reflection Features

    [https://arxiv.org/abs/2403.01046](https://arxiv.org/abs/2403.01046)

    证明在1-D数据上训练神经网络等价于解决一个具有固定特征字典矩阵的凸Lasso问题，为全局最优网络和解空间提供了洞察。

    

    我们证明在1-D数据上训练神经网络等价于解决一个带有固定、明确定义的特征字典矩阵的凸Lasso问题。具体的字典取决于激活函数和深度。我们考虑具有分段线性激活函数的两层网络，深窄的ReLU网络最多有4层，以及具有符号激活和任意深度的矩形和树网络。有趣的是，在ReLU网络中，第四层创建代表训练数据关于自身的反射的特征。Lasso表示法揭示了全局最优网络和解空间的洞察。

    arXiv:2403.01046v1 Announce Type: cross  Abstract: We prove that training neural networks on 1-D data is equivalent to solving a convex Lasso problem with a fixed, explicitly defined dictionary matrix of features. The specific dictionary depends on the activation and depth. We consider 2-layer networks with piecewise linear activations, deep narrow ReLU networks with up to 4 layers, and rectangular and tree networks with sign activation and arbitrary depth. Interestingly in ReLU networks, a fourth layer creates features that represent reflections of training data about themselves. The Lasso representation sheds insight to globally optimal networks and the solution landscape.
    
[^130]: 探究大型语言模型对推荐系统的影响：一项广泛综述

    Exploring the Impact of Large Language Models on Recommender Systems: An Extensive Review

    [https://arxiv.org/abs/2402.18590](https://arxiv.org/abs/2402.18590)

    大型语言模型在推荐系统中展现出卓越的推荐能力和语言理解，重塑了推荐任务的基础。

    

    该论文强调了大型语言模型（LLMs）在重塑推荐系统中的重要性，将它们的价值归因于传统推荐系统所缺乏的独特推理能力。不同于缺乏直接用户互动数据的传统系统，LLMs在推荐物品方面表现出卓越的能力，展示了它们在理解语言复杂性方面的熟练程度。这标志着推荐领域的一个根本性范式转变。在充满活力的研究领域中，研究人员积极利用LLMs的语言理解和生成能力重新定义推荐任务的基础。该研究彻底探讨了LLMs在推荐框架内固有的优势，包括细致的语境理解，跨不同领域的平稳过渡，采用统一的方法，利用共享数据池的全面学习策略，透明度

    arXiv:2402.18590v1 Announce Type: cross  Abstract: The paper underscores the significance of Large Language Models (LLMs) in reshaping recommender systems, attributing their value to unique reasoning abilities absent in traditional recommenders. Unlike conventional systems lacking direct user interaction data, LLMs exhibit exceptional proficiency in recommending items, showcasing their adeptness in comprehending intricacies of language. This marks a fundamental paradigm shift in the realm of recommendations. Amidst the dynamic research landscape, researchers actively harness the language comprehension and generation capabilities of LLMs to redefine the foundations of recommendation tasks. The investigation thoroughly explores the inherent strengths of LLMs within recommendation frameworks, encompassing nuanced contextual comprehension, seamless transitions across diverse domains, adoption of unified approaches, holistic learning strategies leveraging shared data reservoirs, transparent
    
[^131]: 大数据分析用于分类与土方相关的地点：成都研究

    Big data analytics to classify earthwork-related locations: A Chengdu study

    [https://arxiv.org/abs/2402.14698](https://arxiv.org/abs/2402.14698)

    使用大数据分析方法，研究者利用自卸车轨迹、城市兴趣点和土地覆盖数据，成功对城市灰尘污染源进行了分类，证明仅需有限数量特征即可实现高准确度分类。

    

    空气污染显著加剧，导致全球范围内的严重健康后果。土方相关的地点（ERLs）是城市灰尘污染的重要来源。长期以来，ERLs的有效管理一直是政府和环境机构面临的挑战之一，主要原因包括其分类分属不同的监管部门、信息障碍、数据更新延迟，以及对不同源头灰尘污染的抑制措施的缺乏。为解决这些挑战，我们利用自卸车轨迹、城市兴趣点（POI）和土地覆盖数据对城市灰尘污染源进行分类。我们比较了几种预测模型，并利用实际数据研究了特征与灰尘污染源之间的关系。结果表明，通过有限数量的特征可以实现高准确度的分类。这种方法已成功实施在一个名为的系统中。

    arXiv:2402.14698v1 Announce Type: cross  Abstract: Air pollution has significantly intensified, leading to severe health consequences worldwide. Earthwork-related locations (ERLs) constitute significant sources of urban dust pollution. The effective management of ERLs has long posed challenges for governmental and environmental agencies, primarily due to their classification under different regulatory authorities, information barriers, delays in data updating, and a lack of dust suppression measures for various sources of dust pollution. To address these challenges, we classified urban dust pollution sources using dump truck trajectory, urban point of interest (POI), and land cover data. We compared several prediction models and investigated the relationship between features and dust pollution sources using real data. The results demonstrate that high-accuracy classification can be achieved with a limited number of features. This method was successfully implemented in the system called
    
[^132]: 通过用户行为建模和随机规划控制大型电动汽车充电站

    Controlling Large Electric Vehicle Charging Stations via User Behavior Modeling and Stochastic Programming

    [https://arxiv.org/abs/2402.13224](https://arxiv.org/abs/2402.13224)

    本文介绍了一个新的电动汽车充电站模型，通过用户行为建模和随机规划，解决了充电会话不确定性问题，并提出了两种方法来优化成本并提高用户满意度。

    

    本文介绍了一个电动汽车充电站（EVCS）模型，该模型融合了真实世界的约束条件，如插槽功率限制、合同阈值超限惩罚以及电动汽车（EVs）的早期断开。我们提出了一个在不确定性下控制EVCS的问题形式，并实施了两种多阶段随机规划方法，利用用户提供的信息，即模型预测控制和二阶段随机规划。该模型解决了充电会话开始和结束时间以及能量需求的不确定性。基于驻留时间依赖随机过程的用户行为模型增强了成本降低的同时保持客户满意度。通过使用真实世界数据集进行的22天模拟展示了两种提出方法相对于两个基线的优势。两阶段方法证明了针对早期断开的鲁棒性，考虑了更多

    arXiv:2402.13224v1 Announce Type: cross  Abstract: This paper introduces an Electric Vehicle Charging Station (EVCS) model that incorporates real-world constraints, such as slot power limitations, contract threshold overruns penalties, or early disconnections of electric vehicles (EVs). We propose a formulation of the problem of EVCS control under uncertainty, and implement two Multi-Stage Stochastic Programming approaches that leverage user-provided information, namely, Model Predictive Control and Two-Stage Stochastic Programming. The model addresses uncertainties in charging session start and end times, as well as in energy demand. A user's behavior model based on a sojourn-time-dependent stochastic process enhances cost reduction while maintaining customer satisfaction. The benefits of the two proposed methods are showcased against two baselines over a 22-day simulation using a real-world dataset. The two-stage approach proves robust against early disconnections, considering a more
    
[^133]: 高斯过程神经加性模型

    Gaussian Process Neural Additive Models

    [https://arxiv.org/abs/2402.12518](https://arxiv.org/abs/2402.12518)

    本文提出了一种新的高斯过程神经加性模型（GP-NAM），通过随机傅里叶特征对高斯过程进行单层神经网络构建，可以实现具有凸目标函数和可训练参数数量随特征维度线性增长的优势，同时在性能上不亚于更深的NAM方法。

    

    深度神经网络已经在许多领域引起了革命，但它们的黑盒特性有时也阻碍了它们在医疗保健和金融等领域的广泛应用，这些领域需要可解释和可解释的模型。最近发展出的神经加性模型（NAMs）是在面向表格数据集的可解释深度学习方向上迈出的重要一步。在本文中，我们提出了一种新的NAM子类，它使用通过随机傅里叶特征对高斯过程进行单层神经网络构建，我们称之为高斯过程神经加性模型（GP-NAM）。GP-NAM具有凸目标函数和随特征维度线性增长的可训练参数数量的优势。与更深的NAM方法相比，它在性能上没有损失，因为GPs非常适合学习复杂的非参数单变量函数。我们在多个表格数据集上展示了GP-NAM的性能。

    arXiv:2402.12518v1 Announce Type: cross  Abstract: Deep neural networks have revolutionized many fields, but their black-box nature also occasionally prevents their wider adoption in fields such as healthcare and finance, where interpretable and explainable models are required. The recent development of Neural Additive Models (NAMs) is a significant step in the direction of interpretable deep learning for tabular datasets. In this paper, we propose a new subclass of NAMs that use a single-layer neural network construction of the Gaussian process via random Fourier features, which we call Gaussian Process Neural Additive Models (GP-NAM). GP-NAMs have the advantage of a convex objective function and number of trainable parameters that grows linearly with feature dimensionality. It suffers no loss in performance compared to deeper NAM approaches because GPs are well-suited for learning complex non-parametric univariate functions. We demonstrate the performance of GP-NAM on several tabular
    
[^134]: 用可解释的风险预测方法降低诊断错误

    Towards Reducing Diagnostic Errors with Interpretable Risk Prediction

    [https://arxiv.org/abs/2402.10109](https://arxiv.org/abs/2402.10109)

    本研究提出了一种使用LLMs方法来识别病人电子病历数据中指示特定诊断风险增加或减少的证据的方法，旨在通过增加证据的获取与减少诊断错误来降低诊断错误。模型使用神经加性模型进行预测，以证据为后盾，并给出个体化风险估计，特别针对诊断延迟和来自不完整鉴别的错误进行优化。

    

    许多诊断错误发生是因为临床医生无法轻易获取病人电子病历中的相关信息。本研究提出了一种使用LLMs方法来识别病人电子病历数据中指示特定诊断风险增加或减少的证据的方法，最终目标是增加证据的获取与减少诊断错误。我们提出了一种神经加性模型来进行带有个体化风险估计的以证据为后盾的预测，在临床医生仍然不确定的时间点上，旨在特别减轻诊断延迟和源于不完整鉴别的错误。为了训练这样一个模型，需要推断出事件性的“真实”诊断的时间粒度细致的回顾性标签。我们使用LLMs来保证输入文本是在可以进行自信的诊断之前的。我们使用LLMs来检索初始的证据池，然后进行细化。

    arXiv:2402.10109v1 Announce Type: new  Abstract: Many diagnostic errors occur because clinicians cannot easily access relevant information in patient Electronic Health Records (EHRs). In this work we propose a method to use LLMs to identify pieces of evidence in patient EHR data that indicate increased or decreased risk of specific diagnoses; our ultimate aim is to increase access to evidence and reduce diagnostic errors. In particular, we propose a Neural Additive Model to make predictions backed by evidence with individualized risk estimates at time-points where clinicians are still uncertain, aiming to specifically mitigate delays in diagnosis and errors stemming from an incomplete differential. To train such a model, it is necessary to infer temporally fine-grained retrospective labels of eventual "true" diagnoses. We do so with LLMs, to ensure that the input text is from before a confident diagnosis can be made. We use an LLM to retrieve an initial pool of evidence, but then refin
    
[^135]: 引导遮蔽表示学习以捕捉心电图的时空关系

    Guiding Masked Representation Learning to Capture Spatio-Temporal Relationship of Electrocardiogram

    [https://arxiv.org/abs/2402.09450](https://arxiv.org/abs/2402.09450)

    本研究提出了一种叫做ST-MEM的模型，通过重构遮蔽的心电图数据来学习时空特征，该模型在心律失常分类任务中优于其他自监督学习方法。

    

    心电图（ECG）广泛用作监测心脏起源的电信号的诊断工具。近年来，机器学习的研究努力集中在使用ECG信号进行各种疾病筛查的应用上。然而，适应疾病筛查应用是具有挑战性的，因为标记的ECG数据有限。通过自监督学习（SSL）实现通用表示是克服标记数据稀缺性的常用方法；然而，在ECG数据上纯粹应用SSL，而不考虑ECG信号固有的时空关系，可能会产生次优的结果。本文介绍了ST-MEM（时空遮蔽心电图建模），该模型通过重构遮蔽的12导联ECG数据来学习时空特征。在各种实验设置中，ST-MEM在心律失常分类任务中的性能优于其他SSL基线方法。

    arXiv:2402.09450v1 Announce Type: cross  Abstract: Electrocardiograms (ECG) are widely employed as a diagnostic tool for monitoring electrical signals originating from a heart. Recent machine learning research efforts have focused on the application of screening various diseases using ECG signals. However, adapting to the application of screening disease is challenging in that labeled ECG data are limited. Achieving general representation through self-supervised learning (SSL) is a well-known approach to overcome the scarcity of labeled data; however, a naive application of SSL to ECG data, without considering the spatial-temporal relationships inherent in ECG signals, may yield suboptimal results. In this paper, we introduce ST-MEM (Spatio-Temporal Masked Electrocardiogram Modeling), designed to learn spatio-temporal features by reconstructing masked 12-lead ECG data. ST-MEM outperforms other SSL baseline methods in various experimental settings for arrhythmia classification tasks. Mo
    
[^136]: 攻击、防御和评估LLM对话安全性的调查

    Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey

    [https://arxiv.org/abs/2402.09283](https://arxiv.org/abs/2402.09283)

    这篇调查提供了LLM对话安全性的全面概述，涵盖了攻击、防御和评估三个关键方面，旨在提高对该主题的理解并促进进一步的研究。

    

    arXiv:2402.09283v1 公告类型: 新的摘要: 大型语言模型（LLMs）在对话应用中已经很常见。然而，它们可能被误用生成有害回复的风险引起了严重的社会关切，并激发了LLM对话安全性的最新研究。因此，在此调查中，我们提供了最近研究的全面概述，涵盖了LLM对话安全性的三个关键方面：攻击、防御和评估。我们的目标是提供一个结构化的摘要，增进对LLM对话安全性的理解，并鼓励进一步研究这一重要课题。为了方便参考，我们根据我们的分类法对所有在此调查中提到的研究进行了分类，可在以下网址找到：https://github.com/niconi19/LLM-conversation-safety。

    arXiv:2402.09283v1 Announce Type: new Abstract: Large Language Models (LLMs) are now commonplace in conversation applications. However, their risks of misuse for generating harmful responses have raised serious societal concerns and spurred recent research on LLM conversation safety. Therefore, in this survey, we provide a comprehensive overview of recent studies, covering three critical aspects of LLM conversation safety: attacks, defenses, and evaluations. Our goal is to provide a structured summary that enhances understanding of LLM conversation safety and encourages further investigation into this important subject. For easy reference, we have categorized all the studies mentioned in this survey according to our taxonomy, available at: https://github.com/niconi19/LLM-conversation-safety.
    
[^137]: 揭示潜在因果规律：一种基于时间点过程的异常事件解释方法

    Unveiling Latent Causal Rules: A Temporal Point Process Approach for Abnormal Event Explanation

    [https://arxiv.org/abs/2402.05946](https://arxiv.org/abs/2402.05946)

    本文提出了一种基于时间点过程的方法，通过揭示潜在因果规律来解释异常事件，以帮助在高风险系统如医疗保健中快速诊断和精确治疗规划。该方法通过期望最大化算法优化规则集和模型参数，实现了准确的规则发现和根因识别。

    

    在高风险系统如医疗保健中，理解异常事件背后的因果原因是至关重要的，例如患者健康状况的突然变化。揭示因果原因有助于快速诊断和精确治疗规划。在本文中，我们提出了一种自动化方法来揭示解释观察事件的“如果-那么”逻辑规则。我们引入了时间点过程来建模所关注事件，并发现一组潜在规则来解释事件的发生。为了实现这一点，我们采用了期望最大化（EM）算法。在E步中，我们计算每个事件被每个发现的规则解释的可能性。在M步中，我们更新规则集和模型参数，以增强可能性函数的下界。值得注意的是，我们以微分的方式优化规则集。我们的方法在发现规则和识别根本原因方面表现出准确的性能。我们使用合成数据展示了它的有希望的结果。

    In high-stakes systems such as healthcare, it is critical to understand the causal reasons behind unusual events, such as sudden changes in patient's health. Unveiling the causal reasons helps with quick diagnoses and precise treatment planning. In this paper, we propose an automated method for uncovering "if-then" logic rules to explain observational events. We introduce temporal point processes to model the events of interest, and discover the set of latent rules to explain the occurrence of events. To achieve this, we employ an Expectation-Maximization (EM) algorithm. In the E-step, we calculate the likelihood of each event being explained by each discovered rule. In the M-step, we update both the rule set and model parameters to enhance the likelihood function's lower bound. Notably, we optimize the rule set in a differential manner. Our approach demonstrates accurate performance in both discovering rules and identifying root causes. We showcase its promising results using syntheti
    
[^138]: RA-Rec:基于LLM的推荐系统的高效ID表示对齐框架

    RA-Rec: An Efficient ID Representation Alignment Framework for LLM-based Recommendation

    [https://arxiv.org/abs/2402.04527](https://arxiv.org/abs/2402.04527)

    这篇论文提出了一种基于LLM的推荐系统的高效ID表示对齐框架RA-Rec，通过将预训练的ID嵌入到LLMs中，并设计创新的对齐模块和高效调整方法，实现了在推荐系统中的显著性能优化。

    

    大语言模型(LLM)最近已经成为各种自然语言处理任务的强大工具，为LLM和推荐系统的结合带来了新的潮流，称为LLM-based RS。目前的方法通常分为两种主要范例，即ID直接使用范例和ID翻译范例，指出它们的核心弱点在于缺乏推荐知识和独特性。为了解决这个限制，我们提出了一种新的范例，即ID表示，它以一种互补的方式将预训练的ID嵌入到LLMs中。在这项工作中，我们提出了RA-Rec，一种基于LLM的推荐系统的高效ID表示对齐框架，与多种基于ID的方法和LLM架构兼容。具体而言，我们将ID嵌入视为软提示，并设计了一种创新的对齐模块和一种用于对齐的高效调整方法，以及为对齐定制的数据构建。大量实验证明，RA-Rec在性能上显著优于其他方法。

    Large language models (LLM) have recently emerged as a powerful tool for a variety of natural language processing tasks, bringing a new surge of combining LLM with recommendation systems, termed as LLM-based RS. Current approaches generally fall into two main paradigms, the ID direct usage paradigm and the ID translation paradigm, noting their core weakness stems from lacking recommendation knowledge and uniqueness. To address this limitation, we propose a new paradigm, ID representation, which incorporates pre-trained ID embeddings into LLMs in a complementary manner. In this work, we present RA-Rec, an efficient ID representation alignment framework for LLM-based recommendation, which is compatible with multiple ID-based methods and LLM architectures. Specifically, we treat ID embeddings as soft prompts and design an innovative alignment module and an efficient tuning method with tailored data construction for alignment. Extensive experiments demonstrate RA-Rec substantially outperfo
    
[^139]: 一张图值千言：使用纯Transformer将图形欧拉化

    A Graph is Worth $K$ Words: Euclideanizing Graph using Pure Transformer

    [https://arxiv.org/abs/2402.02464](https://arxiv.org/abs/2402.02464)

    这篇论文介绍了GraphsGPT，它使用纯Transformer将非欧几里德图形转换为在欧几里德空间中可学习的图形单词，并通过解码器将图形单词重新构建为原始图形，保证了信息的等价性。预训练的GraphsGPT在图形表示学习和图形生成方面取得了突出成果。

    

    我们能否将非欧几里德图形建模为纯语言甚至欧几里德向量，同时保留其固有信息？非欧几里德性质一直是图形建模中的长期挑战。尽管最近的GNN和Graphformer努力将图形编码为欧几里德向量，但从向量中恢复出原始图形仍然是一个挑战。我们引入了GraphsGPT，它具有一个将非欧几里德图形转换为在欧几里德空间中可学习图形单词的Graph2Seq编码器，以及一个从图形单词重构原始图形以确保信息等价性的GraphGPT解码器。我们在100M个分子上预训练了GraphsGPT，并得到一些有趣的发现：(1) 预训练的Graph2Seq在图形表示学习方面表现出色，在8/9个图形分类和回归任务上取得了最新成果。(2) 预训练的GraphGPT作为一个强大的图形生成器，其能够进行无条件和有条件的图形生成。(3) Graph2Seq+Gr

    Can we model non-Euclidean graphs as pure language or even Euclidean vectors while retaining their inherent information? The non-Euclidean property have posed a long term challenge in graph modeling. Despite recent GNN and Graphformer efforts encoding graphs as Euclidean vectors, recovering original graph from the vectors remains a challenge. We introduce GraphsGPT, featuring a Graph2Seq encoder that transforms non-Euclidean graphs into learnable graph words in a Euclidean space, along with a GraphGPT decoder that reconstructs the original graph from graph words to ensure information equivalence. We pretrain GraphsGPT on 100M molecules and yield some interesting findings: (1) Pretrained Graph2Seq excels in graph representation learning, achieving state-of-the-art results on 8/9 graph classification and regression tasks. (2) Pretrained GraphGPT serves as a strong graph generator, demonstrated by its ability to perform both unconditional and conditional graph generation. (3) Graph2Seq+Gr
    
[^140]: 深度表格学习需要算术特征交互

    Arithmetic Feature Interaction Is Necessary for Deep Tabular Learning

    [https://arxiv.org/abs/2402.02334](https://arxiv.org/abs/2402.02334)

    本文研究了深度表格学习中算术特征交互的必要性，通过引入AMFormer模型，实现了在细粒度表格数据建模、训练数据效率和泛化方面的优越性能。

    

    直到最近，关于深度模型在表格数据上的有效归纳偏见的问题仍然没有答案。本文调查了算术特征交互对于深度表格学习的必要性假设。为了测试这一观点，我们创建了一个具有轻微特征交互假设的合成表格数据集，并研究了一种改进的Transformer架构，使其能够进行算术特征交互，称为AMFormer。结果显示，AMFormer在细粒度表格数据建模、训练数据效率和泛化方面优于强对手。这归因于其并行的加性和乘性注意力操作符和基于提示的优化，这有助于在具有算术工程特征的扩展空间中分离表格样本。我们在真实世界数据上进行了广泛的实验，也验证了AMFormer的一致有效性、效率和合理性，表明它已经建立了强有力的归纳能力。

    Until recently, the question of the effective inductive bias of deep models on tabular data has remained unanswered. This paper investigates the hypothesis that arithmetic feature interaction is necessary for deep tabular learning. To test this point, we create a synthetic tabular dataset with a mild feature interaction assumption and examine a modified transformer architecture enabling arithmetical feature interactions, referred to as AMFormer. Results show that AMFormer outperforms strong counterparts in fine-grained tabular data modeling, data efficiency in training, and generalization. This is attributed to its parallel additive and multiplicative attention operators and prompt-based optimization, which facilitate the separation of tabular samples in an extended space with arithmetically-engineered features. Our extensive experiments on real-world data also validate the consistent effectiveness, efficiency, and rationale of AMFormer, suggesting it has established a strong inductive
    
[^141]: 垂直联邦图像分割

    Vertical Federated Image Segmentation

    [https://arxiv.org/abs/2401.07931](https://arxiv.org/abs/2401.07931)

    提出了一种垂直联邦学习（VFL）模型架构，适用于数据分散于不同数据孤岛的场景，解决了部分地区数据无法访问标记真相，但需要进行分类的问题。

    

    随着人工智能解决图像相关问题的流行，人们越来越关注数据隐私和获取方式。在许多情况下，信息存储在不同的数据孤岛中，开发人员难以将所有信息整合到适合机器学习模型开发的方式中。与此同时，部分本地化数据区域可能无法访问标记的真相。这表明它们有能力通过数字方式得出结论，但在缺乏相关信息的情况下无法进行分类。尤其在尝试开发通常需要该功能的基于图像的解决方案时，这样的确定通常是微不足道的。鉴于此，我们提出了一种创新的垂直联邦学习（VFL）模型架构，该架构可以在这一常见条件下运行。

    arXiv:2401.07931v2 Announce Type: replace-cross  Abstract: With the popularization of AI solutions for image based problems, there has been a growing concern for both data privacy and acquisition. In a large number of cases, information is located on separate data silos and it can be difficult for a developer to consolidate all of it in a fashion that is appropriate for machine learning model development. Alongside this, a portion of these localized data regions may not have access to a labelled ground truth. This indicates that they have the capacity to reach conclusions numerically, but are not able to assign classifications amid a lack of pertinent information. Such a determination is often negligible, especially when attempting to develop image based solutions that often necessitate this capability. With this being the case, we propose an innovative vertical federated learning (VFL) model architecture that can operate under this common set of conditions. This is the first (and curr
    
[^142]: SynCDR：使用合成数据训练跨领域检索模型

    SynCDR : Training Cross Domain Retrieval Models with Synthetic Data

    [https://arxiv.org/abs/2401.00420](https://arxiv.org/abs/2401.00420)

    通过生成合成数据填补跨域检索中缺失的类别示例，解决了不同领域之间共享类别数据不足的问题。

    

    在跨领域检索中，需要模型能够在两个视觉域中识别出属于相同语义类别的图像。例如，给定一个物体的草图，模型需要从在线商店的目录中检索到该物体的真实图像。我们提出了一个简单的解决方案，即生成合成数据来填补跨域之间缺失的类别示例。我们通过catg...

    arXiv:2401.00420v2 Announce Type: replace-cross  Abstract: In cross-domain retrieval, a model is required to identify images from the same semantic category across two visual domains. For instance, given a sketch of an object, a model needs to retrieve a real image of it from an online store's catalog. A standard approach for such a problem is learning a feature space of images where Euclidean distances reflect similarity. Even without human annotations, which may be expensive to acquire, prior methods function reasonably well using unlabeled images for training. Our problem constraint takes this further to scenarios where the two domains do not necessarily share any common categories in training data. This can occur when the two domains in question come from different versions of some biometric sensor recording identities of different people. We posit a simple solution, which is to generate synthetic data to fill in these missing category examples across domains. This, we do via categ
    
[^143]: MaxK-GNN: 探索加速图神经网络训练的理论速度极限

    MaxK-GNN: Towards Theoretical Speed Limits for Accelerating Graph Neural Networks Training

    [https://arxiv.org/abs/2312.08656](https://arxiv.org/abs/2312.08656)

    MaxK-GNN是一种先进的高性能GPU训练系统，通过MaxK非线性和理论分析，实现了图神经网络训练的垂直优化。

    

    在深度神经网络训练加速方面，GPU已经成为主流平台。 GPU在GNN上面临着诸多挑战，如工作负载不平衡和内存访问不规则，导致硬件利用不充分。现有解决方案例如PyG、DGL与cuSPARSE，以及GNNAdvisor框架部分解决了这些挑战，但内存流量仍然很显著。 我们认为，只有通过算法与系统创新的垂直优化才能实现显著的性能提升，而不是将加速优化视为“事后思考”（即（i）给定GNN算法，设计加速器，或（ii）给定硬件，主要优化GNN算法）。 本文介绍了MaxK-GNN，一种集成算法与系统创新的先进高性能GPU训练系统。 （i）我们引入了MaxK非线性并提供了MaxK非线性的理论分析，

    arXiv:2312.08656v3 Announce Type: replace-cross  Abstract: In the acceleration of deep neural network training, the GPU has become the mainstream platform. GPUs face substantial challenges on GNNs, such as workload imbalance and memory access irregularities, leading to underutilized hardware. Existing solutions such as PyG, DGL with cuSPARSE, and GNNAdvisor frameworks partially address these challenges but memory traffic is still significant.   We argue that drastic performance improvements can only be achieved by the vertical optimization of algorithm and system innovations, rather than treating the speedup optimization as an "after-thought" (i.e., (i) given a GNN algorithm, designing an accelerator, or (ii) given hardware, mainly optimizing the GNN algorithm). In this paper, we present MaxK-GNN, an advanced high-performance GPU training system integrating algorithm and system innovation. (i) We introduce the MaxK nonlinearity and provide a theoretical analysis of MaxK nonlinearity as
    
[^144]: Genixer：将多模态大语言模型赋能为强大的数据生成器

    Genixer: Empowering Multimodal Large Language Models as a Powerful Data Generator

    [https://arxiv.org/abs/2312.06731](https://arxiv.org/abs/2312.06731)

    Genixer是一种为生成高质量指导数据而设计的创新数据生成管道，包括九个代表性任务，提供了四个关键步骤来改善数据生成的难度。

    

    arXiv:2312.06731v2 公告类型: 替换-交叉  摘要: 调优数据对于训练多模态大语言模型(MLLMs)至关重要。然而，高质量调优数据的创建面临重大挑战。先前依赖于GPT-4进行数据生成的方法不仅成本高昂，而且在复杂任务（即基于理解的推理任务）中的性能也不尽如人意。为解决这些问题，我们开发了一种创新的数据生成流水线Genixer，用于生成各种高质量的调优数据，包括九个代表性任务，例如常见的VQA，REC，REG和PointQ。具体而言，Genixer提供了一个统一的解决方案，包括四个关键步骤来缓解数据生成的困难：(i)指导数据收集，(ii)指导模板设计，(iii)赋能MLLM，和(iv)数据生成和过滤。随后，我们的Genixer的卓越的定性结果表明，当前的MLLM具有...

    arXiv:2312.06731v2 Announce Type: replace-cross  Abstract: Instruction tuning data is essential for training the Multimodal Large Language Models (MLLMs). However, the creation of high-quality instruction tuning data presents significant challenges. Prior methods that depended on GPT-4 for data generation were not only costly but also lacked satisfactory performance in complex tasks (i.e., grounding-based reasoning tasks). To address these issues, we developed an innovative data generation pipeline, Genixer, to generate various high-quality instruction tuning data, including nine representative tasks, e.g., Common VQA, REC, REG, and PointQ. Specifically, Genixer provides a unified solution with four key steps for alleviating the difficulty of data generation: (i) instruction data collection, (ii) instruction template design, (iii) empowering MLLM, and (iv) data generation and filtering. Subsequently, the superior qualitative results of our Genixer demonstrate that current MLLMs have a 
    
[^145]: 低功耗、连续远程行为定位与事件摄像头

    Low-power, Continuous Remote Behavioral Localization with Event Cameras

    [https://arxiv.org/abs/2312.03799](https://arxiv.org/abs/2312.03799)

    使用低功耗事件摄像头对南极企鹅行为进行连续远程定位，将问题定义为时间动作检测任务并成功开发了相应方法

    

    自然科学研究者需要可靠的方法来量化动物行为。最近，许多计算机视觉方法出现来自动化这一过程。然而，在遥远的野外观察野生物种仍然是一项具有挑战性的任务，这是由于困难的照明条件以及对电源供应和数据存储的限制。事件摄像头由于其低功耗和高动态范围能力，为依赖电池的远程监控提供独特优势。我们使用这种新颖的传感器来量化一种称为“狂喜展示”的巴岛企鹅行为。我们将问题定义为一个时间动作检测任务，确定行为的开始和结束时间。为此，我们在南极洲记录了一个繁殖企鹅群落的活动数周，并标记了16个巢的事件数据。所开发的方法由候选时间间隔生成器（提案）和行为分类器组成。

    arXiv:2312.03799v2 Announce Type: replace-cross  Abstract: Researchers in natural science need reliable methods for quantifying animal behavior. Recently, numerous computer vision methods emerged to automate the process. However, observing wild species at remote locations remains a challenging task due to difficult lighting conditions and constraints on power supply and data storage. Event cameras offer unique advantages for battery-dependent remote monitoring due to their low power consumption and high dynamic range capabilities. We use this novel sensor to quantify a behavior in Chinstrap penguins called ecstatic display. We formulate the problem as a temporal action detection task, determining the start and end times of the behavior. For this purpose, we recorded a colony of breeding penguins in Antarctica for several weeks and labeled event data on 16 nests. The developed method consists of a generator of candidate time intervals (proposals) and a classifier of the actions within t
    
[^146]: 关于数据集的多样性和现实性：一种高效的数据集精炼范式

    On the Diversity and Realism of Distilled Dataset: An Efficient Dataset Distillation Paradigm

    [https://arxiv.org/abs/2312.03526](https://arxiv.org/abs/2312.03526)

    我们提出了一种新颖的计算效率高且有效的数据精炼范式RDED，以实现数据的多样性和现实性。

    

    当今的机器学习要求在庞大的数据集上训练大型神经网络，因此面临高计算需求的挑战。数据集精炼作为一种最近兴起的策略，旨在压缩真实世界的数据集以进行高效训练。然而，这一研究领域目前在处理大规模和高分辨率的数据集时存在困难，阻碍了其实用性和可行性。为此，我们重新审视现有的数据集精炼方法，并确定了用于大规模真实世界应用的三个所需属性，即现实性，多样性和效率。为了解决这个问题，我们提出了RDED，一种新颖的计算效率高且有效的数据精炼范式，以实现数据的多样性和现实性。对各种神经结构和数据集进行的大量实证结果表明了RDED的进展：我们可以将完整的ImageNet-1K精炼为一个小数据集

    arXiv:2312.03526v2 Announce Type: replace-cross  Abstract: Contemporary machine learning requires training large neural networks on massive datasets and thus faces the challenges of high computational demands. Dataset distillation, as a recent emerging strategy, aims to compress real-world datasets for efficient training. However, this line of research currently struggle with large-scale and high-resolution datasets, hindering its practicality and feasibility. To this end, we re-examine the existing dataset distillation methods and identify three properties required for large-scale real-world applications, namely, realism, diversity, and efficiency. As a remedy, we propose RDED, a novel computationally-efficient yet effective data distillation paradigm, to enable both diversity and realism of the distilled data. Extensive empirical results over various neural architectures and datasets demonstrate the advancement of RDED: we can distill the full ImageNet-1K to a small dataset comprisin
    
[^147]: 在频域中学习多模态正常性以实现高效的时间序列异常检测

    Learning Multi-Pattern Normalities in the Frequency Domain for Efficient Time Series Anomaly Detection

    [https://arxiv.org/abs/2311.16191](https://arxiv.org/abs/2311.16191)

    MACE是一种在频域中适应多正常模式且高效的时间序列异常检测方法，其创新之处在于采用优秀的模式提取机制，使模型能够通过检查数据样本与其服务正常模式之间的相关性来识别异常。

    

    异常检测显著提升了云系统的稳健性。尽管基于神经网络的方法最近展示了强大的优势，但它们在云环境中遇到了实际挑战：在维护每个服务的唯一模型的不切实际性与通过统一模型处理各种正常模式的有限能力之间存在矛盾，以及处理实时高负载和短期异常检测敏感性的问题。因此，我们提出了MACE，一种在频域中适应多正常模式且高效的时间序列异常检测方法。它有三个新颖的特点：（i）一种优秀的模式提取机制，能够处理各种正常模式并使用统一模型，使模型能够通过检查数据样本与其服务正常模式之间的相关性来识别异常。

    arXiv:2311.16191v2 Announce Type: replace-cross  Abstract: Anomaly detection significantly enhances the robustness of cloud systems. While neural network-based methods have recently demonstrated strong advantages, they encounter practical challenges in cloud environments: the contradiction between the impracticality of maintaining a unique model for each service and the limited ability to deal with diverse normal patterns by a unified model, as well as issues with handling heavy traffic in real time and short-term anomaly detection sensitivity.   Thus, we propose MACE, a multi-normal-pattern accommodated and efficient anomaly detection method in the frequency domain for time series anomaly detection. There are three novel characteristics of it: (i) a pattern extraction mechanism excelling at handling diverse normal patterns with a unified model, which enables the model to identify anomalies by examining the correlation between the data sample and its service normal pattern, instead of 
    
[^148]: 在自适应之前对齐：利用实体到区域对齐进行通用视频动作识别

    Align before Adapt: Leveraging Entity-to-Region Alignments for Generalizable Video Action Recognition

    [https://arxiv.org/abs/2311.15619](https://arxiv.org/abs/2311.15619)

    提出了一种“对齐前自适应”（ALT）范式，通过利用实体到区域对齐，将文本嵌入作为查询，从而帮助提取视频中最重要实体的语义。

    

    大规模的视觉-语言预训练模型在各种视频任务中取得了重大成功。然而，大多数现有方法遵循“自适应然后对齐”的范式，将预训练图像编码器调整为建模视频级表示，并利用动作标签的one-hot或文本嵌入进行监督。本文提出了一种新颖的“对齐前自适应”（ALT）范式。在适应到视频表示学习之前，我们利用为每一帧实体到区域对齐。这些对齐通过将区域感知图像嵌入与离线构建的文本语料库进行匹配来实现。有了对齐的实体，我们将它们的文本嵌入作为查询馈送到基于transformer的视频适配器中，可以帮助从视频到向量提取最重要实体的语义。

    arXiv:2311.15619v2 Announce Type: replace-cross  Abstract: Large-scale visual-language pre-trained models have achieved significant success in various video tasks. However, most existing methods follow an "adapt then align" paradigm, which adapts pre-trained image encoders to model video-level representations and utilizes one-hot or text embedding of the action labels for supervision. This paradigm overlooks the challenge of mapping from static images to complicated activity concepts. In this paper, we propose a novel "Align before Adapt" (ALT) paradigm. Prior to adapting to video representation learning, we exploit the entity-to-region alignments for each frame. The alignments are fulfilled by matching the region-aware image embeddings to an offline-constructed text corpus. With the aligned entities, we feed their text embeddings to a transformer-based video adapter as the queries, which can help extract the semantics of the most important entities from a video to a vector. This parad
    
[^149]: 通过知识子图学习实现准确且可解释的药物相互作用预测

    Accurate and interpretable drug-drug interaction prediction enabled by knowledge subgraph learning

    [https://arxiv.org/abs/2311.15056](https://arxiv.org/abs/2311.15056)

    通过知识子图学习的方法，本研究提出了一种解决药物相互作用预测中样本稀缺性挑战的图神经网络模型，能够准确且可解释地预测药物之间的相互作用。

    

    背景：发现潜在的药物相互作用(DDI)一直是临床治疗和药物开发中长期存在的挑战。最近，深度学习技术已用于DDI预测。然而，它们通常需要大量样本，而已知DDI较为罕见。方法：本文提出了基于图神经网络的KnowDDI方法来解决上述挑战。KnowDDI通过自适应地利用大型生物医学知识图中丰富的邻居信息增强药物表示。然后，它为每对药物学习一个知识子图以解释预测的DDI，其中每条边都与连接强度相关联，指示已知DDI的重要性或类似强度之间的连接在药物对之间是未知的情况下。因此，缺乏DDI的情况通过丰富的药物表示和传播的药物相似性得到隐含补偿。

    arXiv:2311.15056v2 Announce Type: replace-cross  Abstract: Background: Discovering potential drug-drug interactions (DDIs) is a long-standing challenge in clinical treatments and drug developments. Recently, deep learning techniques have been developed for DDI prediction. However, they generally require a huge number of samples, while known DDIs are rare.   Methods: In this work, we present KnowDDI, a graph neural network-based method that addresses the above challenge. KnowDDI enhances drug representations by adaptively leveraging rich neighborhood information from large biomedical knowledge graphs. Then, it learns a knowledge subgraph for each drug-pair to interpret the predicted DDI, where each of the edges is associated with a connection strength indicating the importance of a known DDI or resembling strength between a drug-pair whose connection is unknown. Thus, the lack of DDIs is implicitly compensated by the enriched drug representations and propagated drug similarities.   Resu
    
[^150]: RLIF: 交互式模仿学习作为强化学习

    RLIF: Interactive Imitation Learning as Reinforcement Learning

    [https://arxiv.org/abs/2311.12996](https://arxiv.org/abs/2311.12996)

    本文探讨了离策略强化学习如何在类似但潜在上更实用的假设下提供比交互式模仿学习更好的性能。

    

    虽然强化学习方法为自动技能获取提供了强大的框架，但是对于实际的基于学习的控制问题，如机器人领域，模仿学习往往提供了一种更便利和可访问的替代方案。特别是，像DAgger这样的交互式模仿学习方法，可以从一位接近最优的专家手中在线获取纠正数据，以应对困扰天真行为克隆的分布偏移挑战，无论在理论上还是在实践中都能表现良好，而不需要手动指定奖励函数和强化学习方法的其他组件。在本文中，我们探讨了离策略强化学习如何在类似但潜在上更实用的假设下实现较好的性能，从而可以提升强化学习的表现。我们提出的方法使用用户进行增强学习，

    arXiv:2311.12996v2 Announce Type: replace  Abstract: Although reinforcement learning methods offer a powerful framework for automatic skill acquisition, for practical learning-based control problems in domains such as robotics, imitation learning often provides a more convenient and accessible alternative. In particular, an interactive imitation learning method such as DAgger, which queries a near-optimal expert to intervene online to collect correction data for addressing the distributional shift challenges that afflict na\"ive behavioral cloning, can enjoy good performance both in theory and practice without requiring manually specified reward functions and other components of full reinforcement learning methods. In this paper, we explore how off-policy reinforcement learning can enable improved performance under assumptions that are similar but potentially even more practical than those of interactive imitation learning. Our proposed method uses reinforcement learning with user inte
    
[^151]: 医生们知道如何提醒吗？临床笔记生成中自动提示优化帮助的需求

    Do Physicians Know How to Prompt? The Need for Automatic Prompt Optimization Help in Clinical Note Generation

    [https://arxiv.org/abs/2311.09684](https://arxiv.org/abs/2311.09684)

    本研究提出了自动提示优化（APO）框架，评估了不同提示对于大型语言模型在临床笔记生成中性能的影响，结果表明GPT4 APO在标准化提升质量方面表现出色，并强调了专家定制化对于内容质量的价值。

    

    本研究考察了提示工程对大型语言模型（LLMs）在临床笔记生成中性能的影响。我们引入了一个自动提示优化（APO）框架来改进初始提示，并比较了医学专家、非医学专家以及经过APO增强的GPT3.5和GPT4的输出。结果突显了GPT4 APO在标准化临床笔记各节提示质量方面的卓越性能。人在环中方法显示，专家在APO后保持内容质量，但更偏好自己的修改，表明了专家定制的价值。我们建议采用两阶段优化过程，利用APO-GPT4确保一致性，同时结合专家输入进行个性化。

    arXiv:2311.09684v2 Announce Type: replace-cross  Abstract: This study examines the effect of prompt engineering on the performance of Large Language Models (LLMs) in clinical note generation. We introduce an Automatic Prompt Optimization (APO) framework to refine initial prompts and compare the outputs of medical experts, non-medical experts, and APO-enhanced GPT3.5 and GPT4. Results highlight GPT4 APO's superior performance in standardizing prompt quality across clinical note sections. A human-in-the-loop approach shows that experts maintain content quality post-APO, with a preference for their own modifications, suggesting the value of expert customization. We recommend a two-phase optimization process, leveraging APO-GPT4 for consistency and expert input for personalization.
    
[^152]: Aria-NeRF: 多模态主观视角合成

    Aria-NeRF: Multimodal Egocentric View Synthesis

    [https://arxiv.org/abs/2311.06455](https://arxiv.org/abs/2311.06455)

    通过类似于NeRF的模型和多模态传感器的组合，我们实现了从主观数据训练的丰富多模态场景模型，有望提升智能代理的能力。

    

    我们旨在加速研究，开发从主观数据训练的丰富多模态场景模型，基于受神经辐射场（NeRFs）启发的可微体积光线追踪。从主观图像序列构建类似于NeRF的模型在理解人类行为方面起着至关重要的作用，并在虚拟现实/增强现实领域具有多样的应用。这种类似于NeRF的主观模型可以用作逼真的模拟，对能够在现实世界中执行任务的智能代理的进步作出重大贡献。主观视角合成的未来可能导致超越今天NeRFs的新颖环境表示，通过将视觉数据与多模态传感器（如用于自我运动跟踪的IMU，用于捕捉表面纹理和人类语境的音频传感器，以及用于推断场景中人类注意模式的眼部凝视追踪器）相结合。

    arXiv:2311.06455v2 Announce Type: replace-cross  Abstract: We seek to accelerate research in developing rich, multimodal scene models trained from egocentric data, based on differentiable volumetric ray-tracing inspired by Neural Radiance Fields (NeRFs). The construction of a NeRF-like model from an egocentric image sequence plays a pivotal role in understanding human behavior and holds diverse applications within the realms of VR/AR. Such egocentric NeRF-like models may be used as realistic simulations, contributing significantly to the advancement of intelligent agents capable of executing tasks in the real-world. The future of egocentric view synthesis may lead to novel environment representations going beyond today's NeRFs by augmenting visual data with multimodal sensors such as IMU for egomotion tracking, audio sensors to capture surface texture and human language context, and eye-gaze trackers to infer human attention patterns in the scene. To support and facilitate the developm
    
[^153]: 在非专业LLM用户中为微调，检索增强生成和软提示建立性能基线

    Establishing Performance Baselines in Fine-Tuning, Retrieval-Augmented Generation and Soft-Prompting for Non-Specialist LLM Users

    [https://arxiv.org/abs/2311.05903](https://arxiv.org/abs/2311.05903)

    通过对GPT 3.5进行微调，并结合基于向量的RAG数据库和非算法软提示，建立了性能基线，发现在特定的测试条件下微调模型表现更好。

    

    通过微调、检索增强生成（RAG）和软提示来改善大型语言模型（LLMs）性能的方法研究往往聚焦于使用高度技术化或高成本的技术，使许多新发现的方法对非技术用户来说相对不易访问。在本文中，我们测试了未经修改的GPT 3.5版本、经微调的版本，以及在单独访问基于向量的RAG数据库时相同未经修改的模型，这两种情况下都配备了基本的非算法软提示。在每种情况下，我们测试了模型回答一组主要涉及2021年9月之后事件的100个问题的能力（这是GPT 3.5的训练数据集结束的时间点）。我们发现，如果使用商业平台并应用默认设置，不进行迭代以建立一组基线输出，那么经过微调的模型表现更好。

    arXiv:2311.05903v2 Announce Type: replace-cross  Abstract: Research into methods for improving the performance of large language models (LLMs) through fine-tuning, retrieval-augmented generation (RAG) and soft-prompting has tended to focus on the use of highly technical or high-cost techniques, making many of the newly discovered approaches comparatively inaccessible to non-technical users. In this paper we tested an unmodified version of GPT 3.5, a fine-tuned version, and the same unmodified model when given access to a vectorised RAG database, both in isolation and in combination with a basic, non-algorithmic soft prompt. In each case we tested the model's ability to answer a set of 100 questions relating primarily to events that occurred after September 2021 (the point at which GPT 3.5's training data set ends). We found that if commercial platforms are used and default settings are applied with no iteration in order to establish a baseline set of outputs, a fine-tuned model outperf
    
[^154]: TabRepo：一个大规模的表格模型评估库及其AutoML应用

    TabRepo: A Large Scale Repository of Tabular Model Evaluations and its AutoML Applications

    [https://arxiv.org/abs/2311.02971](https://arxiv.org/abs/2311.02971)

    TabRepo引入了一个包含1310个模型在200个分类和回归数据集上评估预测结果和指标信息的数据集，展示了它在进行超参数优化、AutoML系统比较和迁移学习等方面的优势。

    

    我们介绍了TabRepo，这是一个包含1310个模型在200个分类和回归数据集上评估预测结果和指标的新数据集。我们展示了我们的数据集的多种好处。首先，我们表明这个数据集可以进行诸如比较超参数优化与当前AutoML系统以及在使用预计算模型预测的同时考虑集成的分析。其次，我们展示了我们的数据集可以轻松用于执行迁移学习。特别是，我们展示应用标准迁移学习技术可以在准确性、运行时间和延迟方面胜过当前最先进的表格系统。

    arXiv:2311.02971v2 Announce Type: replace-cross  Abstract: We introduce TabRepo, a new dataset of tabular model evaluations and predictions. TabRepo contains the predictions and metrics of 1310 models evaluated on 200 classification and regression datasets. We illustrate the benefit of our dataset in multiple ways. First, we show that it allows to perform analysis such as comparing Hyperparameter Optimization against current AutoML systems while also considering ensembling at marginal cost by using precomputed model predictions. Second, we show that our dataset can be readily leveraged to perform transfer-learning. In particular, we show that applying standard transfer-learning techniques allows to outperform current state-of-the-art tabular systems in accuracy, runtime and latency.
    
[^155]: 翻译的上下文细化：句子和文档级后编辑的大型语言模型

    Contextual Refinement of Translations: Large Language Models for Sentence and Document-Level Post-Editing

    [https://arxiv.org/abs/2310.14855](https://arxiv.org/abs/2310.14855)

    大型语言模型在神经机器翻译中表现尚未达到最先进水平，提出使用LLM作为自动后编辑器(APE)的替代方法，同时探索了扩展到文档级翻译的可能性。

    

    大型语言模型(LLM)已在各种自然语言处理任务中取得了相当大的成功，但它们尚未在神经机器翻译(NMT)中达到最先进的性能。然而，在要求广泛理解和上下文处理的任务中表现出的显著性能显示了它们在翻译中的潜力。为了利用这些能力，我们研究了使用LLM进行MT，并探索了最近的参数高效微调技术。令人惊讶的是，我们的初步实验发现，即使为翻译目的微调，也会导致性能下降。为了克服这一问题，我们提出了一种替代方法：将LLM作为自动后编辑器(APE)而不是直接转换器。基于LLM处理和生成长序列的异常能力，我们还提出将我们的方法扩展到文档级翻译。我们展示了利用低秩适配器进行 ...

    arXiv:2310.14855v2 Announce Type: replace-cross  Abstract: Large Language Models (LLM's) have demonstrated considerable success in various Natural Language Processing tasks, but they have yet to attain state-of-the-art performance in Neural Machine Translation (NMT). Nevertheless, their significant performance in tasks demanding a broad understanding and contextual processing shows their potential for translation. To exploit these abilities, we investigate using LLM's for MT and explore recent parameter-efficient fine-tuning techniques. Surprisingly, our initial experiments find that fine-tuning for translation purposes even led to performance degradation. To overcome this, we propose an alternative approach: adapting LLM's as Automatic Post-Editors (APE) rather than direct translators. Building on the LLM's exceptional ability to process and generate lengthy sequences, we also propose extending our approach to document-level translation. We show that leveraging Low-Rank-Adapter fine-t
    
[^156]: 令人惊叹但令人困惑：用假设细化测试语言模型的归纳推理能力

    Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement

    [https://arxiv.org/abs/2310.08559](https://arxiv.org/abs/2310.08559)

    对语言模型进行的系统研究揭示了它们在假设提出方面表现惊人，并且通过与一个（任务特定的）符号解释器相结合，能够系统地过滤可能性。

    

    从少数观察中推导出潜在原则，然后推广到新情况的能力，即归纳推理，对于人类智能至关重要。之前的研究表明，尽管在研究基准上取得了令人印象深刻的成功，但语言模型（LMs）在归纳推理方面常常表现不佳。在这项工作中，我们通过迭代假设细化这一技术对LMs的归纳推理能力进行了系统研究，该技术更接近人类归纳过程，而不是标准的输入-输出提示。

    arXiv:2310.08559v3 Announce Type: replace-cross  Abstract: The ability to derive underlying principles from a handful of observations and then generalize to novel situations -- known as inductive reasoning -- is central to human intelligence. Prior work suggests that language models (LMs) often fall short on inductive reasoning, despite achieving impressive success on research benchmarks. In this work, we conduct a systematic study of the inductive reasoning capabilities of LMs through iterative hypothesis refinement, a technique that more closely mirrors the human inductive process than standard input-output prompting. Iterative hypothesis refinement employs a three-step process: proposing, selecting, and refining hypotheses in the form of textual rules. By examining the intermediate rules, we observe that LMs are phenomenal hypothesis proposers (i.e., generating candidate rules), and when coupled with a (task-specific) symbolic interpreter that is able to systematically filter the pr
    
[^157]: 语言建模即为压缩

    Language Modeling Is Compression

    [https://arxiv.org/abs/2309.10668](https://arxiv.org/abs/2309.10668)

    大型语言模型被证明是强大的压缩器，压缩视角为扩展定律、标记化和上下文学习提供了新的见解。

    

    早已确立了预测模型可以转化为无损压缩器，反之亦然。近年来，机器学习社区集中精力训练越来越大、越来越强大的自监督（语言）模型。大型语言模型表现出令人印象深刻的预测能力，因此它们有望成为强大的压缩器。在这项工作中，我们主张通过压缩的视角来看待预测问题，并评估大型（基础）模型的压缩能力。我们展示了大型语言模型是强大的通用预测器，压缩视角提供了有关扩展定律、标记化和上下文学习的新见解。例如，Chinchilla 70B，虽然主要在文本上训练，但可以将ImageNet的补丁压缩为其原始大小的43.4%，将LibriSpeech样本压缩为其原始大小的16.4%，超越了特定领域的压缩器。

    arXiv:2309.10668v2 Announce Type: replace-cross  Abstract: It has long been established that predictive models can be transformed into lossless compressors and vice versa. Incidentally, in recent years, the machine learning community has focused on training increasingly large and powerful self-supervised (language) models. Since these large language models exhibit impressive predictive capabilities, they are well-positioned to be strong compressors. In this work, we advocate for viewing the prediction problem through the lens of compression and evaluate the compression capabilities of large (foundation) models. We show that large language models are powerful general-purpose predictors and that the compression viewpoint provides novel insights into scaling laws, tokenization, and in-context learning. For example, Chinchilla 70B, while trained primarily on text, compresses ImageNet patches to 43.4% and LibriSpeech samples to 16.4% of their raw size, beating domain-specific compressors li
    
[^158]: EasyEdit：一种易于使用的大型语言模型知识编辑框架

    EasyEdit: An Easy-to-use Knowledge Editing Framework for Large Language Models

    [https://arxiv.org/abs/2308.07269](https://arxiv.org/abs/2308.07269)

    EasyEdit提出了一种易于使用的知识编辑框架，针对大型语言模型的知识截断或谬误问题，支持各种最新的知识编辑方法，并可应用于多个知名的LLMs。

    

    大型语言模型（LLMs）通常遭受知识截断或谬误问题，这意味着它们对未见事件不知情或生成具有不正确事实的文本，原因是数据过时/嘈杂。为此，出现了许多针对LLMs的知识编辑方法，旨在微妙地注入/编辑更新的知识或调整不良行为，同时将对不相关输入的影响最小化。然而，由于各种知识编辑方法之间存在显著差异，以及任务设置中的变化，社区中没有可用于知识编辑的标准实施框架，这妨碍了从业者将知识编辑应用于应用程序。为解决这些问题，我们提出了EasyEdit，一种易于使用的LLMs知识编辑框架。它支持各种尖端的知识编辑方法，并可以轻松应用于许多著名的LLMs，如T5、GPT-J、LlaMA等。从经验上来看，我们报告了kno

    arXiv:2308.07269v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) usually suffer from knowledge cutoff or fallacy issues, which means they are unaware of unseen events or generate text with incorrect facts owing to outdated/noisy data. To this end, many knowledge editing approaches for LLMs have emerged -- aiming to subtly inject/edit updated knowledge or adjust undesired behavior while minimizing the impact on unrelated inputs. Nevertheless, due to significant differences among various knowledge editing methods and the variations in task setups, there is no standard implementation framework available for the community, which hinders practitioners from applying knowledge editing to applications. To address these issues, we propose EasyEdit, an easy-to-use knowledge editing framework for LLMs. It supports various cutting-edge knowledge editing approaches and can be readily applied to many well-known LLMs such as T5, GPT-J, LlaMA, etc. Empirically, we report the kno
    
[^159]: Radiology-GPT：用于放射学的大型语言模型

    Radiology-GPT: A Large Language Model for Radiology

    [https://arxiv.org/abs/2306.08666](https://arxiv.org/abs/2306.08666)

    Radiology-GPT是一个专门为放射学设计的大型语言模型，通过使用指导调整方法进行训练，在放射学诊断、研究和沟通方面展示出优越性能，为临床NLP的未来发展提供推动力。

    

    我们介绍了Radiology-GPT，一个用于放射学的大型语言模型。通过在广泛的放射学领域知识数据集上采用指导调整方法，Radiology-GPT表现出比StableLM、Dolly和LLaMA等通用语言模型更优越的性能。它在放射学诊断、研究和沟通方面展现出显著的多功能性。这项工作为临床自然语言处理领域的未来发展提供了催化剂。Radiology-GPT的成功实施表明了定位生成型大型语言模型的潜力，特别是为独特的医学专业定制，同时确保遵守HIPAA等隐私标准。开发针对各家医院特定需求的个性化大型语言模型的前景呈现出一个有前途的方向。这些模型中融合的会话能力和领域特定知识被设定为促进

    arXiv:2306.08666v2 Announce Type: replace-cross  Abstract: We introduce Radiology-GPT, a large language model for radiology. Using an instruction tuning approach on an extensive dataset of radiology domain knowledge, Radiology-GPT demonstrates superior performance compared to general language models such as StableLM, Dolly and LLaMA. It exhibits significant versatility in radiological diagnosis, research, and communication. This work serves as a catalyst for future developments in clinical NLP. The successful implementation of Radiology-GPT is indicative of the potential of localizing generative large language models, specifically tailored for distinctive medical specialties, while ensuring adherence to privacy standards such as HIPAA. The prospect of developing individualized, large-scale language models that cater to specific needs of various hospitals presents a promising direction. The fusion of conversational competence and domain-specific knowledge in these models is set to foste
    
[^160]: 在无信号交叉口预测行人互动结果：穿越或等待？

    Cross or Wait? Predicting Pedestrian Interaction Outcomes at Unsignalized Crossings

    [https://arxiv.org/abs/2304.08260](https://arxiv.org/abs/2304.08260)

    本文利用机器学习预测行人在无信号交叉口与车辆互动时的过马路行为，提出的神经网络模型在预测准确性和F1分数上取得了显著的改进。

    

    预测行人与车辆互动时的行为是自动驾驶领域中最重要的挑战之一。行人过马路的行为受到各种互动因素的影响，包括到达时间、行人等待时间、斑马线的存在，以及行人和驾驶员的特性和个性特征。然而，这些因素尚未被充分探讨用于预测互动结果。本文利用机器学习来预测行人在无信号交叉口与车辆互动时的过马路行为，包括行人的过马路决策、过街开始时间（CIT）和过街持续时间（CD）。分布式模拟数据被用于预测和分析这些互动因素。与逻辑回归基线模型相比，我们提出的神经网络模型将预测的准确性和F1分数提高了4.46%。

    arXiv:2304.08260v2 Announce Type: replace-cross  Abstract: Predicting pedestrian behavior when interacting with vehicles is one of the most critical challenges in the field of automated driving. Pedestrian crossing behavior is influenced by various interaction factors, including time to arrival, pedestrian waiting time, the presence of zebra crossing, and the properties and personality traits of both pedestrians and drivers. However, these factors have not been fully explored for use in predicting interaction outcomes. In this paper, we use machine learning to predict pedestrian crossing behavior including pedestrian crossing decision, crossing initiation time (CIT), and crossing duration (CD) when interacting with vehicles at unsignalized crossings. Distributed simulator data are utilized for predicting and analyzing the interaction factors. Compared with the logistic regression baseline model, our proposed neural network model improves the prediction accuracy and F1 score by 4.46% an
    
[^161]: 面向解释神经代码模型的因果论理论

    Toward a Theory of Causation for Interpreting Neural Code Models

    [https://arxiv.org/abs/2302.03788](https://arxiv.org/abs/2302.03788)

    该论文介绍了一种名为$do_{code}$的后验解释方法，用于解释神经代码模型的预测，基于因果推断，旨在实现面向编程语言的解释。

    

    Neural Language Models of Code，或者称为神经代码模型（NCMs），正在迅速从研究原型发展为商业开发者工具。因此，理解这些模型的能力和局限性变得至关重要。然而，这些模型的能力通常是使用自动化指标来衡量的，这些指标通常只能揭示它们真实性能的一部分。一般来说，NCMs的性能似乎很有前途，但目前关于这些模型如何做出决策仍有很多未知。因此，本文介绍了一种名为$do_{code}$的后验解释方法，该方法专门针对NCMs，能够解释模型的预测。$do_{code}$基于因果推断，以实现面向编程语言的解释。虽然$do_{code}$的理论基础可扩展到探索不同的模型属性，但我们提供了一个具体的实例，旨在减少影响...

    arXiv:2302.03788v2 Announce Type: replace-cross  Abstract: Neural Language Models of Code, or Neural Code Models (NCMs), are rapidly progressing from research prototypes to commercial developer tools. As such, understanding the capabilities and limitations of such models is becoming critical. However, the abilities of these models are typically measured using automated metrics that often only reveal a portion of their real-world performance. While, in general, the performance of NCMs appears promising, currently much is unknown about how such models arrive at decisions. To this end, this paper introduces $do_{code}$, a post hoc interpretability method specific to NCMs that is capable of explaining model predictions. $do_{code}$ is based upon causal inference to enable programming language-oriented explanations. While the theoretical underpinnings of $do_{code}$ are extensible to exploring different model properties, we provide a concrete instantiation that aims to mitigate the impact o
    
[^162]: 通过长短期记忆和TOPSIS进行深度循环学习

    Deep Recurrent Learning Through Long Short Term Memory and TOPSIS

    [https://arxiv.org/abs/2301.00693](https://arxiv.org/abs/2301.00693)

    该论文提出了一种基于长短期记忆（LSTM）和TOPSIS的分类算法，用于识别和排名云ERP的采用特征。

    

    企业资源规划（ERP）软件将资源、数据汇聚在一起，以保持企业流程中的软件流畅。然而，云计算的廉价、简便和快速管理承诺促使企业所有者将单一体架构转变为基于数据中心/云的ERP。由于云ERP的开发涉及一个循环过程，即规划、实施、测试和升级，其采用被认为是一个深度递归神经网络问题。最终，提出了一个基于长短期记忆（LSTM）和TOPSIS的分类算法，用于识别和分别排名采用特征。我们的理论模型通过阐述关键参与者、服务、架构、功能，在参考模型上得到了验证。通过考虑技术、创新和抵抗问题，开展了一项定性调查，以就关键采用因素提出假设。

    arXiv:2301.00693v2 Announce Type: replace-cross  Abstract: Enterprise resource planning (ERP) software brings resources, data together to keep software-flow within business processes in a company. However, cloud computing's cheap, easy and quick management promise pushes business-owners for a transition from monolithic to a data-center/cloud based ERP. Since cloud-ERP development involves a cyclic process, namely planning, implementing, testing and upgrading, its adoption is realized as a deep recurrent neural network problem. Eventually, a classification algorithm based on long short term memory (LSTM) and TOPSIS is proposed to identify and rank, respectively, adoption features. Our theoretical model is validated over a reference model by articulating key players, services, architecture, functionalities. Qualitative survey is conducted among users by considering technology, innovation and resistance issues, to formulate hypotheses on key adoption factors.
    
[^163]: 通过克里洛夫子空间回收加速神经算子的数据生成

    Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling. (arXiv:2401.09516v1 [cs.LG])

    [http://arxiv.org/abs/2401.09516](http://arxiv.org/abs/2401.09516)

    该论文提出了一种名为排序克里洛夫回收（SKR）的新方法，用于加速神经算子训练的数据生成。该方法解决了现有方法在解决PDE问题时计算冗余的问题，显著提高了数据生成效率。

    

    学习用于解决偏微分方程(PDE)的神经算子因其高推理效率而受到广泛关注。然而，训练这些算子需要生成大量带有解决方案的标记数据，即PDE问题及其解决方案。数据生成过程非常耗时，因为它涉及解决大量线性方程组以获得PDE的数值解。许多现有方法独立地解决这些系统，而不考虑它们的内在相似性，导致计算极其冗余。为了解决这个问题，我们提出了一种新颖的方法，即排序克里洛夫回收(SKR)，以提高解决这些系统的效率，从而显著加速神经算子训练的数据生成。据我们所知，SKR是第一个解决学习神经算子数据生成耗时性质的尝试。SKR的核心是克里洛夫子空间。

    Learning neural operators for solving partial differential equations (PDEs) has attracted great attention due to its high inference efficiency. However, training such operators requires generating a substantial amount of labeled data, i.e., PDE problems together with their solutions. The data generation process is exceptionally time-consuming, as it involves solving numerous systems of linear equations to obtain numerical solutions to the PDEs. Many existing methods solve these systems independently without considering their inherent similarities, resulting in extremely redundant computations. To tackle this problem, we propose a novel method, namely Sorting Krylov Recycling (SKR), to boost the efficiency of solving these systems, thus significantly accelerating data generation for neural operators training. To the best of our knowledge, SKR is the first attempt to address the time-consuming nature of data generation for learning neural operators. The working horse of SKR is Krylov sub
    
[^164]: 多任务机器人数据用于双臂精细操作

    Multi-task robot data for dual-arm fine manipulation. (arXiv:2401.07603v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2401.07603](http://arxiv.org/abs/2401.07603)

    这篇论文介绍了一个多任务机器人数据集，其中包括双臂精细操作和需要精细操作的任务，并且公开可用。

    

    在机器人操纵领域，深度模仿学习被认为是获取操作技能的一种有希望的方法。此外，从多样化的机器人数据集中学习被认为是实现多样性和适应性的可行方法。在这样的研究中，通过学习各种任务，机器人在多个物体上实现了普适性。然而，这样的多任务机器人数据集主要集中在相对不精确的单臂任务上，并没有解决机器人在现实世界中需要执行的细粒度物体操作。本文介绍了一个包括双臂任务和/或需要精细操作的多样化物体操纵数据集。为此，我们生成了包含224k个场景的数据集（150小时，1,104个语言指令），其中包括双臂精细任务，如移动碗、打开笔袋或剥香蕉，并且这些数据是公开可用的。此外，该数据集还包括视觉注意信号。

    In the field of robotic manipulation, deep imitation learning is recognized as a promising approach for acquiring manipulation skills. Additionally, learning from diverse robot datasets is considered a viable method to achieve versatility and adaptability. In such research, by learning various tasks, robots achieved generality across multiple objects. However, such multi-task robot datasets have mainly focused on single-arm tasks that are relatively imprecise, not addressing the fine-grained object manipulation that robots are expected to perform in the real world. This paper introduces a dataset of diverse object manipulations that includes dual-arm tasks and/or tasks requiring fine manipulation. To this end, we have generated dataset with 224k episodes (150 hours, 1,104 language instructions) which includes dual-arm fine tasks such as bowl-moving, pencil-case opening or banana-peeling, and this data is publicly available. Additionally, this dataset includes visual attention signals a
    
[^165]: 重访大语言模型时代下的零-shot 抽象摘要，从位置偏见的角度出发

    Revisiting Zero-Shot Abstractive Summarization in the Era of Large Language Models from the Perspective of Position Bias. (arXiv:2401.01989v1 [cs.CL])

    [http://arxiv.org/abs/2401.01989](http://arxiv.org/abs/2401.01989)

    这项研究通过测量位置偏见，重访了大语言模型中的零-shot 抽象摘要。研究结果揭示了模型不公平地优先考虑某些部分的信息，从而导致不可取的行为。对多个LLM模型和预训练抽象摘要模型进行的实验提供了关于零-shot 总结任务的模型性能和位置偏见的新见解和讨论。

    

    我们通过测量位置偏见来表征和研究大型语言模型（LLMs）中的零-shot 抽象摘要，我们将其视为先前文献中研究过的更为限制性的引导偏见现象的一般表述。位置偏见捕捉到模型在输入文本的某些部分上不公平地优先考虑信息，导致不可取的行为。通过对四个不同的真实数据集进行大量实验，我们研究了多个LLM模型如GPT 3.5-Turbo，Llama-2和Dolly-v2中的位置偏见，以及当前最先进的预训练编码器-解码器抽象摘要模型如Pegasus和BART。我们的发现为零-shot 总结任务的模型性能和位置偏见提供了新的见解和讨论。

    We characterize and study zero-shot abstractive summarization in Large Language Models (LLMs) by measuring position bias, which we propose as a general formulation of the more restrictive lead bias phenomenon studied previously in the literature. Position bias captures the tendency of a model unfairly prioritizing information from certain parts of the input text over others, leading to undesirable behavior. Through numerous experiments on four diverse real-world datasets, we study position bias in multiple LLM models such as GPT 3.5-Turbo, Llama-2, and Dolly-v2, as well as state-of-the-art pretrained encoder-decoder abstractive summarization models such as Pegasus and BART. Our findings lead to novel insights and discussion on performance and position bias of models for zero-shot summarization tasks.
    
[^166]: 设计AI支持人类参与AI辅助决策：从系统性回顾中分类人机交互的税表

    Designing AI Support for Human Involvement in AI-assisted Decision Making: A Taxonomy of Human-AI Interactions from a Systematic Review. (arXiv:2310.19778v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2310.19778](http://arxiv.org/abs/2310.19778)

    通过对AI辅助决策文献的系统回顾，我们填补了人机交互协议的共同词汇的空白，并强调了解AI应该提供什么信息来帮助人类的重要性。

    

    在决策支持系统中利用人工智能（AI）的努力过分关注技术进步，往往忽视了算法输出与人类期望之间的一致性。为了解决这个问题，可解释性人工智能从更以人为中心的角度促进AI的发展。确定AI应该提供哪些信息来帮助人类是至关重要的，然而，信息如何呈现，比如推荐的顺序和解释的要求同样重要。这推动了更精确地研究人机交互作为基于AI的决策支持的关键组成部分的需求。尽管已有几个实证研究评估了多个应用领域中的人机交互，其中交互形式各异，但目前还没有一个共同的词汇来描述人机交互协议。为了填补这一空白，我们描述了对AI辅助决策文献的系统回顾结果。

    Efforts in levering Artificial Intelligence (AI) in decision support systems have disproportionately focused on technological advancements, often overlooking the alignment between algorithmic outputs and human expectations. To address this, explainable AI promotes AI development from a more human-centered perspective. Determining what information AI should provide to aid humans is vital, however, how the information is presented, e. g., the sequence of recommendations and the solicitation of interpretations, is equally crucial. This motivates the need to more precisely study Human-AI interaction as a pivotal component of AI-based decision support. While several empirical studies have evaluated Human-AI interactions in multiple application domains in which interactions can take many forms, there is not yet a common vocabulary to describe human-AI interaction protocols. To address this gap, we describe the results of a systematic review of the AI-assisted decision making literature, anal
    
[^167]: 使用分布式Hebbian Temporal Memory学习继任者表示法

    Learning Successor Representations with Distributed Hebbian Temporal Memory. (arXiv:2310.13391v1 [cs.LG])

    [http://arxiv.org/abs/2310.13391](http://arxiv.org/abs/2310.13391)

    本文提出了一种名为DHTM的算法，它基于因子图形式和多组成神经元模型，利用分布式表示、稀疏转移矩阵和局部Hebbian样学习规则来解决在线隐藏表示学习的挑战。实验结果表明，DHTM在变化的环境中比经典的LSTM效果更好，并与更先进的类似RNN的算法性能相当，可以加速继任者表示的时间差异学习。

    

    本文提出了一种新颖的方法来解决在线隐藏表示学习的挑战，该方法用于在不稳定的、部分可观测的环境中进行决策。所提出的算法，分布式Hebbian Temporal Memory (DHTM)，基于因子图形式和多组成神经元模型。DHTM旨在捕捉顺序数据关系并对未来观察作出累积预测，形成继任者表示。受新皮层的神经生理学模型启发，该算法利用分布式表示、稀疏转移矩阵和局部Hebbian样学习规则克服了传统时间记忆算法（如RNN和HMM）的不稳定性和慢速学习过程。实验结果表明，DHTM优于经典的LSTM，并与更先进的类似RNN的算法性能相当，在变化的环境中加速了继任者表示的时间差异学习。此外，我们还进行了比较。

    This paper presents a novel approach to address the challenge of online hidden representation learning for decision-making under uncertainty in non-stationary, partially observable environments. The proposed algorithm, Distributed Hebbian Temporal Memory (DHTM), is based on factor graph formalism and a multicomponent neuron model. DHTM aims to capture sequential data relationships and make cumulative predictions about future observations, forming Successor Representation (SR). Inspired by neurophysiological models of the neocortex, the algorithm utilizes distributed representations, sparse transition matrices, and local Hebbian-like learning rules to overcome the instability and slow learning process of traditional temporal memory algorithms like RNN and HMM. Experimental results demonstrate that DHTM outperforms classical LSTM and performs comparably to more advanced RNN-like algorithms, speeding up Temporal Difference learning for SR in changing environments. Additionally, we compare
    
[^168]: 评估LLMs在特权升级场景中的应用

    Evaluating LLMs for Privilege-Escalation Scenarios. (arXiv:2310.11409v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2310.11409](http://arxiv.org/abs/2310.11409)

    本研究评估了在特权升级场景中利用语言模型（LLMs）进行渗透测试的应用。通过创建一个自动化的Linux特权升级基准和一个LLM-guided特权升级工具，我们分析了LLMs的不同提示设计、上下文学习和高级指导对测试的影响，并讨论了LLMs面临的挑战。

    

    渗透测试是网络安全的一个重要组成部分，它允许组织主动识别和修复系统中的漏洞，从而增强其对潜在网络攻击的防御机制。在渗透测试领域，最近的一个进展是利用语言模型（LLMs）。我们探索LLMs与渗透测试的交叉领域，以了解它们在特权升级场景中的能力和挑战。我们使用本地虚拟机创建了一个自动化的Linux特权升级基准。我们引入了一种基于LLMs的特权升级工具，用于评估不同的LLMs和提示策略在我们的基准测试中的表现。我们分析了不同提示设计的影响，上下文学习的好处，以及向LLMs提供高级指导的优势。我们讨论了LLMs面临的挑战领域，包括在测试过程中保持专注、处理错误以及与传统方法进行比较。

    Penetration testing, an essential component of cybersecurity, allows organizations to proactively identify and remediate vulnerabilities in their systems, thus bolstering their defense mechanisms against potential cyberattacks. One recent advancement in the realm of penetration testing is the utilization of Language Models (LLMs). We explore the intersection of LLMs and penetration testing to gain insight into their capabilities and challenges in the context of privilige escalation. We create an automated Linux privilege-escalation benchmark utilizing local virtual machines. We introduce an LLM-guided privilege-escalation tool designed for evaluating different LLMs and prompt strategies against our benchmark. We analyze the impact of different prompt designs, the benefits of in-context learning, and the advantages of offering high-level guidance to LLMs. We discuss challenging areas for LLMs, including maintaining focus during testing, coping with errors, and finally comparing them wit
    
[^169]: 在嘈杂的农业环境中的3D重建：基于贝叶斯优化视角的观测规划

    3D Reconstruction in Noisy Agricultural Environments: A Bayesian Optimization Perspective for View Planning. (arXiv:2310.00145v1 [cs.RO])

    [http://arxiv.org/abs/2310.00145](http://arxiv.org/abs/2310.00145)

    本论文提出了一种在噪声环境中进行3D重建的新方法，通过观测规划，合理选择相机位置并考虑噪声对重建性能的影响，提高了3D重建结果的质量和效率。

    

    3D重建是机器人技术中一项基础任务，因其在农业、水下和城市环境等实际场景中产生了重大影响而受到关注。其中一种重要的方法是通过合理安放相机来最大化视觉信息，提高3D重建结果，称为观测规划。通过将几何标准应用于选择较少但更有信息量的图像，可以避免需要大量的任意图像，从而显著提高3D重建性能。然而，在各种真实场景中考虑到存在的噪声可能是具有挑战性的，特别是当没有提供有关噪声的先验信息时。为此，本研究提出了一种新的几何函数，考虑到现有的噪声，仅依靠相对较少的噪声实现来计算，而不需要其封闭形式。

    3D reconstruction is a fundamental task in robotics that gained attention due to its major impact in a wide variety of practical settings, including agriculture, underwater, and urban environments. An important approach for this task, known as view planning, is to judiciously place a number of cameras in positions that maximize the visual information improving the resulting 3D reconstruction. Circumventing the need for a large number of arbitrary images, geometric criteria can be applied to select fewer yet more informative images to markedly improve the 3D reconstruction performance. Nonetheless, incorporating the noise of the environment that exists in various real-world scenarios into these criteria may be challenging, particularly when prior information about the noise is not provided. To that end, this work advocates a novel geometric function that accounts for the existing noise, relying solely on a relatively small number of noise realizations without requiring its closed-form e
    
[^170]: 通过大型语言模型增强面向动态感知的文本到视频扩散

    Empowering Dynamics-aware Text-to-Video Diffusion with Large Language Models. (arXiv:2308.13812v1 [cs.AI])

    [http://arxiv.org/abs/2308.13812](http://arxiv.org/abs/2308.13812)

    本文提出了一种新的方法（称为Dysen）来增强面向动态感知的文本到视频扩散，通过提取关键动作、建立动态场景图和丰富细节，以实现高质量的T2V生成。

    

    文本到视频（T2V）合成在社区中引起了越来越多的关注，其中最近出现的扩散模型（DMs）比过去的方法表现更强大。尽管现有的最先进的DMs能够实现高分辨率的视频生成，但它们在复杂的时间动态建模方面存在一些主要限制（例如，动作出现障碍，粗糙的视频运动）。在这项工作中，我们研究了如何加强DMs对视频动态的感知，以实现高质量的T2V生成。受到人类直觉的启发，我们设计了一种创新的动态场景管理器（称为Dysen）模块，其中包括（步骤1）从输入文本中提取具有适当时间顺序安排的关键动作，（步骤2）将动作时间表转化为动态场景图（DSG）表示，以及（步骤3）丰富DSG中的场景并提供充分和合理的细节。

    Text-to-video (T2V) synthesis has gained increasing attention in the community, in which the recently emerged diffusion models (DMs) have promisingly shown stronger performance than the past approaches. While existing state-of-the-art DMs are competent to achieve high-resolution video generation, they may largely suffer from key limitations (e.g., action occurrence disorders, crude video motions) with respect to the intricate temporal dynamics modeling, one of the crux of video synthesis. In this work, we investigate strengthening the awareness of video dynamics for DMs, for high-quality T2V generation. Inspired by human intuition, we design an innovative dynamic scene manager (dubbed as Dysen) module, which includes (step-1) extracting from input text the key actions with proper time-order arrangement, (step-2) transforming the action schedules into the dynamic scene graph (DSG) representations, and (step-3) enriching the scenes in the DSG with sufficient and reasonable details. Takin
    
[^171]: 快速和最优的基于学习的行星探测车路径规划方法

    A Fast and Optimal Learning-based Path Planning Method for Planetary Rovers. (arXiv:2308.04792v1 [cs.RO])

    [http://arxiv.org/abs/2308.04792](http://arxiv.org/abs/2308.04792)

    本文提出了一种基于学习的快速路径规划方法，通过学习最优路径示范中的语义信息和地图表示，生成概率分布来搜索最优路径。实验结果表明，该方法能够提高行星探测车的探索效率。

    

    智能自主路径规划对于提高行星探测车的探索效率至关重要。在本文中，我们提出了一种基于学习的方法，在高程图中快速搜索最优路径，称为NNPP。NNPP模型从大量预注释的最优路径示范中学习起始和目标位置的语义信息，以及地图表示，并生成每个像素的概率分布，表示其属于地图上最优路径的可能性。具体而言，本文从DEM获取的坡度、粗糙度和高度差计算每个网格单元的遍历成本。随后，使用高斯分布对起始和目标位置进行编码，并分析不同位置编码参数对模型性能的影响。经过训练，NNPP模型能够在新的地图上执行路径规划。实验证明，NNPP生成的引导场能够准确指导行星探测车的运动。

    Intelligent autonomous path planning is crucial to improve the exploration efficiency of planetary rovers. In this paper, we propose a learning-based method to quickly search for optimal paths in an elevation map, which is called NNPP. The NNPP model learns semantic information about start and goal locations, as well as map representations, from numerous pre-annotated optimal path demonstrations, and produces a probabilistic distribution over each pixel representing the likelihood of it belonging to an optimal path on the map. More specifically, the paper computes the traversal cost for each grid cell from the slope, roughness and elevation difference obtained from the DEM. Subsequently, the start and goal locations are encoded using a Gaussian distribution and different location encoding parameters are analyzed for their effect on model performance. After training, the NNPP model is able to perform path planning on novel maps. Experiments show that the guidance field generated by the 
    
[^172]: 基于主动学习的预训练数据去重模型

    A Pre-trained Data Deduplication Model based on Active Learning. (arXiv:2308.00721v1 [cs.LG])

    [http://arxiv.org/abs/2308.00721](http://arxiv.org/abs/2308.00721)

    提出了一种基于主动学习的预训练去重模型，将Transformer和主动学习集成到端到端架构中，首次解决了语义级别的去重问题，同时采用R-Drop方法对每一轮标记数据进行数据增强。通过选择最有价值的数据进行去重模型训练，不仅降低了手动标记的成本，还提高了模型的泛化能力。

    

    在大数据时代，数据质量问题日益突出。其中一个主要挑战是重复数据问题，这可能是由于数据的重复输入或多个数据源的合并导致的。这些"脏数据"问题严重限制了大数据的有效应用。为了解决数据去重的问题，我们提出了一种基于主动学习的预训练去重模型，这是首次利用主动学习解决语义级别的去重问题的工作。该模型构建在一个预训练的Transformer上，并通过细调将其应用于序列分类任务，首次将Transformer和主动学习集成到端到端架构中，以选择最有价值的数据进行去重模型训练，同时首次采用R-Drop方法对每一轮标记数据进行数据增强，既能降低手动标记的成本，也能提高模型的泛化能力。

    In the era of big data, the issue of data quality has become increasingly prominent. One of the main challenges is the problem of duplicate data, which can arise from repeated entry or the merging of multiple data sources. These "dirty data" problems can significantly limit the effective application of big data. To address the issue of data deduplication, we propose a pre-trained deduplication model based on active learning, which is the first work that utilizes active learning to address the problem of deduplication at the semantic level. The model is built on a pre-trained Transformer and fine-tuned to solve the deduplication problem as a sequence to classification task, which firstly integrate the transformer with active learning into an end-to-end architecture to select the most valuable data for deduplication model training, and also firstly employ the R-Drop method to perform data augmentation on each round of labeled data, which can reduce the cost of manual labeling and improve
    
[^173]: FedDRL: 一种基于分阶段强化学习的可信联邦学习模型融合方法

    FedDRL: A Trustworthy Federated Learning Model Fusion Method Based on Staged Reinforcement Learning. (arXiv:2307.13716v1 [cs.LG])

    [http://arxiv.org/abs/2307.13716](http://arxiv.org/abs/2307.13716)

    FedDRL是一种分阶段强化学习的联邦学习模型融合方法，解决了传统方法中无法解决的客户端模型质量和恶意模型问题。

    

    传统的联邦学习使用样本数量计算每个客户端模型的权重，并使用这个固定权重值来融合全局模型。然而，在实际场景中，每个客户端设备和数据的异质性导致每个客户端模型的质量存在差异。因此，对全局模型的贡献不仅仅取决于样本量。此外，如果客户端故意上传低质量或恶意模型，使用这些模型进行聚合将严重降低全局模型的准确性。传统的联邦学习算法没有解决这些问题。为了解决这个问题，我们提出了一种名为FedDRL的模型融合方法，它使用两个阶段的强化学习。在第一个阶段，我们的方法可以过滤掉恶意模型，并选择可信的客户端模型参与模型融合。在第二个阶段，FedDRL算法自适应地调整可信客户端模型的权重并聚合。

    Traditional federated learning uses the number of samples to calculate the weights of each client model and uses this fixed weight value to fusion the global model. However, in practical scenarios, each client's device and data heterogeneity leads to differences in the quality of each client's model. Thus the contribution to the global model is not wholly determined by the sample size. In addition, if clients intentionally upload low-quality or malicious models, using these models for aggregation will lead to a severe decrease in global model accuracy. Traditional federated learning algorithms do not address these issues. To solve this probelm, we propose FedDRL, a model fusion approach using reinforcement learning based on a two staged approach. In the first stage, Our method could filter out malicious models and selects trusted client models to participate in the model fusion. In the second stage, the FedDRL algorithm adaptively adjusts the weights of the trusted client models and ag
    
[^174]: SAMAug: Segment Anything Model的点提示增强方法

    SAMAug: Point Prompt Augmentation for Segment Anything Model. (arXiv:2307.01187v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2307.01187](http://arxiv.org/abs/2307.01187)

    SAMAug是一种用于增强交互式图像分割性能的方法，通过生成增强的点提示，结合初始提示，可以提高Segment Anything Model的分割结果。

    

    本文介绍了SAMAug，一种用于增强交互式图像分割性能的新型视觉点提示增强方法。SAMAug生成增强的点提示，以提供更多关于用户意图的信息给SAM。SAM从一个初始点提示开始生成一个初始掩码，然后将其输入我们提出的SAMAug来生成增强的点提示。通过结合这些额外的点，SAM可以基于增强的点提示和初始提示生成增强的分割掩码，从而提高分割性能。我们使用了四种不同的点增强策略进行评估：随机采样，基于最大差异熵的采样，最大距离和显著性。在COCO、Fundus、COVID QUEx和ISIC2018数据集上的实验证实了SAMAug可以提升SAM的分割结果，尤其是使用最大距离和显著性。SAMAug证明了其应用潜力。

    This paper introduces SAMAug, a novel visual point augmentation method for the Segment Anything Model (SAM) that enhances interactive image segmentation performance. SAMAug generates augmented point prompts to provide more information about the user's intention to SAM. Starting with an initial point prompt, SAM produces an initial mask, which is then fed into our proposed SAMAug to generate augmented point prompts. By incorporating these extra points, SAM can generate augmented segmentation masks based on both the augmented point prompts and the initial prompt, resulting in improved segmentation performance. We conducted evaluations using four different point augmentation strategies: random sampling, sampling based on maximum difference entropy, maximum distance, and saliency. Experiment results on the COCO, Fundus, COVID QUEx, and ISIC2018 datasets show that SAMAug can boost SAM's segmentation results, especially using the maximum distance and saliency. SAMAug demonstrates the potenti
    
[^175]: DNABERT-2:多种物种基因组的高效基础模型和基准

    DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genome. (arXiv:2306.15006v1 [q-bio.GN])

    [http://arxiv.org/abs/2306.15006](http://arxiv.org/abs/2306.15006)

    本研究提出了DNABERT-2，一个用于多种物种基因组的高效基础模型和基准。我们通过使用基于统计的数据压缩算法Byte Pair Encoding（BPE）替代传统的k-mer标记化，克服了k-mer标记化的计算和样本效率问题，并取得了重要进展。

    

    解码基因组的语言复杂性是生物学中一个关键问题，而DNABERT和Nucleotide Transformer等预训练基础模型在这个领域取得了重要进展。现有的工作主要依赖于k-mer作为基因组语言的标记，由于其简单性。然而，我们认为k-mer标记化引入的计算和样本效率问题是发展大规模基因组基础模型的主要障碍。我们提供了关于基因组标记化的概念和经验见解，基于此提出用基于统计的数据压缩算法Byte Pair Encoding（BPE）替代k-mer标记化，BPE通过迭代合并语料库中最频繁共同出现的基因组片段来构建标记。我们证明，BPE不仅克服了k-mer标记化的局限性，还能从非重叠标记化的计算效率中受益。

    Decoding the linguistic intricacies of the genome is a crucial problem in biology, and pre-trained foundational models such as DNABERT and Nucleotide Transformer have made significant strides in this area. Existing works have largely hinged on k-mer, fixed-length permutations of A, T, C, and G, as the token of the genome language due to its simplicity. However, we argue that the computation and sample inefficiencies introduced by k-mer tokenization are primary obstacles in developing large genome foundational models. We provide conceptual and empirical insights into genome tokenization, building on which we propose to replace k-mer tokenization with Byte Pair Encoding (BPE), a statistics-based data compression algorithm that constructs tokens by iteratively merging the most frequent co-occurring genome segment in the corpus. We demonstrate that BPE not only overcomes the limitations of k-mer tokenization but also benefits from the computational efficiency of non-overlapping tokenizatio
    
[^176]: Granger因果的分层技能发现

    Granger-Causal Hierarchical Skill Discovery. (arXiv:2306.09509v1 [cs.AI])

    [http://arxiv.org/abs/2306.09509](http://arxiv.org/abs/2306.09509)

    本文介绍了一种名为HIntS的算法，使用无监督检测器，基于Granger因果性捕捉因素之间的关键事件，发现和训练一系列操作因素化环境中的因素的技能，其展示了在机器人推动任务上有2-3倍的样本效率和最终性能的提高，有效的处理了复杂问题和转移学习。

    

    强化学习已经在学习复杂任务的策略方面显示出了有希望的结果，但往往会遭受低样本效率和有限转移的问题。本文介绍了一种名为HIntS的算法，它使用学习得到的交互检测器来发现和训练一系列技能，这些技能操作因素化环境中的因素。受Granger因果性的启发，这些无监督检测器捕捉到因素之间的关键事件，以便高效地学习有用的技能，并将这些技能转移到其他相关任务，这些任务是许多强化学习技术所面临的困境。我们在一个带有障碍物的机器人推动任务上评估了HIntS - 这是一个具有挑战性的领域，在这个领域，其他RL和HRL方法都表现不佳。学习到的技能不仅展示了使用Breakout的变体的转移，而且与可比较的强化学习基线相比，还表现出2-3倍的样本效率和最终性能的提高。HIntS一起证明了一种层次结构的技能发现方法，可以处理复杂问题。

    Reinforcement Learning (RL) has shown promising results learning policies for complex tasks, but can often suffer from low sample efficiency and limited transfer. We introduce the Hierarchy of Interaction Skills (HIntS) algorithm, which uses learned interaction detectors to discover and train a hierarchy of skills that manipulate factors in factored environments. Inspired by Granger causality, these unsupervised detectors capture key events between factors to sample efficiently learn useful skills and transfer those skills to other related tasks -- tasks where many reinforcement learning techniques struggle. We evaluate HIntS on a robotic pushing task with obstacles -- a challenging domain where other RL and HRL methods fall short. The learned skills not only demonstrate transfer using variants of Breakout, a common RL benchmark, but also show 2-3x improvement in both sample efficiency and final performance compared to comparable RL baselines. Together, HIntS demonstrates a proof of co
    
[^177]: Ada-NAV：用于机器人导航的自适应轨迹优化策略学习方法

    Ada-NAV: Adaptive Trajectory-Based Sample Efficient Policy Learning for Robotic Navigation. (arXiv:2306.06192v1 [cs.RO])

    [http://arxiv.org/abs/2306.06192](http://arxiv.org/abs/2306.06192)

    Ada-NAV是一种自适应轨迹优化策略学习方法，采用降低策略随机性的方法平衡探索与利用，提高机器人导航任务的采样效率。在真实世界的测试中表现优异，可以在更短的采样时间内取得更高的性能。

    

    强化学习方法在学习机器人导航策略方面十分有效，但其采样效率低的问题也十分明显。在策略优化中，这种效率低下部分来自于未能适当地平衡探索与利用的问题，特别是在面对非静态时。为了加入探索与利用的平衡以提高采样效率，我们提出了Ada-NAV，一种自适应轨迹长度方案，其中长度随着策略的随机性（用其Shannon或差分熵表示）的减小而增加。我们的自适应轨迹长度方案由于更频繁的梯度更新强调了训练开始时的探索，后来则更强调利用。在网格世界，仿真机器人环境和真实世界机器人实验中，我们证明了该方法的优点，表现在性能和采样效率上均优于常数和随机采样的轨迹长度。在固定的样本预算下，相对于现有的基准方法，Ada-NAV的性能提高了高达46％，采样数量减少了高达80％。

    Reinforcement learning methods, while effective for learning robotic navigation strategies, are known to be highly sample inefficient. This sample inefficiency comes in part from not suitably balancing the explore-exploit dilemma, especially in the presence of non-stationarity, during policy optimization. To incorporate a balance of exploration-exploitation for sample efficiency, we propose Ada-NAV, an adaptive trajectory length scheme where the length grows as a policy's randomness, represented by its Shannon or differential entropy, decreases. Our adaptive trajectory length scheme emphasizes exploration at the beginning of training due to more frequent gradient updates and emphasizes exploitation later on with longer trajectories. In gridworld, simulated robotic environments, and real-world robotic experiments, we demonstrate the merits of the approach over constant and randomly sampled trajectory lengths in terms of performance and sample efficiency. For a fixed sample budget, Ada-N
    
[^178]: LeTI：从文本交互中学习生成

    LeTI: Learning to Generate from Textual Interactions. (arXiv:2305.10314v1 [cs.CL])

    [http://arxiv.org/abs/2305.10314](http://arxiv.org/abs/2305.10314)

    LeTI是一种使用自然语言指令、LM生成的程序和错误消息进行串联迭代微调的技术，可以用于代码生成任务，并且在自然发生的Python指令数据集上表现最先进。

    

    微调预训练语言模型(LM)可以增强模型的能力。先前的技术通过输入输出对（例如指令微调）或用评估输出质量的数字奖励（例如从人类反馈中进行的强化学习）对预训练的LM进行微调。我们探索了LM从文本交互中学习的潜力(LeTI)，这不仅可以通过二进制标签检查其正确性，而且还可以通过文本反馈指出和解释其输出中的错误。我们的研究重点是代码生成任务，其中模型根据自然语言指令生成代码片段。这种设置可以自然且可扩展地获取文本反馈：使用Python解释器进行代码执行时的错误消息和堆栈跟踪。 LeTI使用LM目标对自然语言指令、LM生成的程序和文本反馈进行串联的迭代微调，只有在生成代码无法执行时才提供文本反馈。我们在一个包含58k个自然发生的Python指令，增加了错误消息和堆栈跟踪的数据集上评估了LeTI，在三种不同的评估指标上显著优于强基线模型，并取得了最先进的结果。

    Finetuning pre-trained language models (LMs) enhances the models' capabilities. Prior techniques fine-tune a pre-trained LM on input-output pairs (e.g., instruction fine-tuning), or with numerical rewards that gauge the quality of its outputs (e.g., reinforcement learning from human feedback). We explore LMs' potential to learn from textual interactions (LeTI) that not only check their correctness with binary labels, but also pinpoint and explain errors in their outputs through textual feedback. Our investigation focuses on the code generation task, where the model produces code pieces in response to natural language instructions. This setting invites a natural and scalable way to acquire the textual feedback: the error messages and stack traces from code execution using a Python interpreter. LeTI iteratively fine-tunes the model, using the LM objective, on a concatenation of natural language instructions, LM-generated programs, and textual feedback, which is only provided when the gen
    
[^179]: BugNIST -- 一种新的大规模体积三维图像数据集，用于分类和检测

    BugNIST -- A New Large Scale Volumetric 3D Image Dataset for Classification and Detection. (arXiv:2304.01838v1 [cs.CV])

    [http://arxiv.org/abs/2304.01838](http://arxiv.org/abs/2304.01838)

    本文介绍了一个名为BugNIST的广泛数据集，该数据集由12种昆虫和幼虫的微-CT扫描组成。通过训练和测试检测模型，BugNIST旨在评估三维体积图像分类和检测方法，解决上下文无关的挑战。

    

    三维体积图像分析研究的进展受到数据集缺乏的限制，大多数针对体积图像的分析方法都基于医学数据。然而，医学数据并不一定具有其他体积图像（例如微-CT）的特征。为了促进三维体积图像分析的研究超越医学数据，我们创建了BugNIST数据集并免费提供。BugNIST是一组由12种昆虫和幼虫的微-CT扫描组成的广泛数据集。BugNIST包含9437个体积，其中9087个是单个昆虫的扫描，350个是昆虫和其他材料的混合物。BugNIST的目标是评估分类和检测方法，我们设计了检测挑战，使得检测模型在单个昆虫的扫描上训练并在昆虫混合物上进行测试。能够解决此任务的模型将独立于上下文（即周围材料），这是一个很大的优势。

    Progress in 3D volumetric image analysis research is limited by the lack of datasets and most advances in analysis methods for volumetric images are based on medical data. However, medical data do not necessarily resemble the characteristics of other volumetric images such as micro-CT. To promote research in 3D volumetric image analysis beyond medical data, we have created the BugNIST dataset and made it freely available. BugNIST is an extensive dataset of micro-CT scans of 12 types of bugs, such as insects and larvae. BugNIST contains 9437 volumes where 9087 are of individual bugs and 350 are mixtures of bugs and other material. The goal of BugNIST is to benchmark classification and detection methods, and we have designed the detection challenge such that detection models are trained on scans of individual bugs and tested on bug mixtures. Models capable of solving this task will be independent of the context, i.e., the surrounding material. This is a great advantage if the context is 
    
[^180]: 关于知识蒸馏中的学生-教师偏差：违反规则是否有益？

    On student-teacher deviations in distillation: does it pay to disobey?. (arXiv:2301.12923v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12923](http://arxiv.org/abs/2301.12923)

    通过实验和理论分析，本论文发现在知识蒸馏中，学生网络对教师网络的概率偏离是系统性夸大的，同时也得到了更好的泛化能力。

    

    知识蒸馏（KD）被广泛用于通过训练学生模仿经过训练的“教师”网络的软概率来提高“学生”网络的测试准确性。然而，最近的研究表明，尽管被训练成适应教师的概率，学生不仅明显偏离这些概率，而且表现比教师更好。我们的研究旨在通过确定学生-教师偏差的确切性质，并论证它们与更好的泛化能力如何共存来解决这一看似矛盾的观察。首先，通过对图像和语言数据进行实验，我们确定这些偏差对应于学生系统性地夸大教师的自信水平。接下来，在一些简单的设置中，我们从理论和实证上建立了KD在收敛更快的过程中夸大了梯度下降的隐含偏差的证据。最后，

    Knowledge distillation (KD) has been widely-used to improve the test accuracy of a ``student'' network by training the student to mimic soft probabilities of a trained "teacher" network. Yet, it has been shown in recent work that, despite being trained to fit the teacher's probabilities, the student not only significantly deviates from these probabilities, but also performs even better than the teacher. Our work aims to reconcile this seemingly paradoxical observation by characterizing the precise nature of the student-teacher deviations, and by arguing how they can co-occur with better generalization. First, through experiments on image and language data, we identify that these deviations correspond to the student systematically exaggerating the confidence levels of the teacher. Next, we theoretically and empirically establish in some simple settings that KD also exaggerates the implicit bias of gradient descent in converging faster along the top eigendirections of the data. Finally, 
    
[^181]: 解释、公正性和人类-AI决策中的适当依赖（arXiv:2209.11812v3 [cs.HC] UPDATED）

    Explanations, Fairness, and Appropriate Reliance in Human-AI Decision-Making. (arXiv:2209.11812v3 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2209.11812](http://arxiv.org/abs/2209.11812)

    本研究探讨了基于特征的解释对AI辅助决策公正性的影响，发现解释可以影响公正性感知和人们对AI建议的依赖。然而，解释并不能帮助人们区分正确和错误的AI建议。这些发现对于促进有效的决策和公正性至关重要。

    

    在这项工作中，我们研究了基于特征的解释对AI辅助决策的公正性的影响，特别关注从简短的文本简介中预测职业的任务。我们还研究了这些影响如何通过人们的公正性感知和对AI建议的依赖来调节。我们的研究结果表明，解释影响了公正性感知，而公正性感知又与人们遵循AI建议的倾向相关。然而，我们发现这样的解释并不能让人们区分正确和错误的AI建议。相反，我们发现解释可能会影响依赖，而不论AI建议的正确性如何。取决于解释突出的特征，这可以促进或阻碍分配公正性：当解释突出与敏感属性明显相关的与任务无关的特征时，这会促使人们覆盖AI与性别刻板印象一致的建议。

    In this work, we study the effects of feature-based explanations on distributive fairness of AI-assisted decisions, specifically focusing on the task of predicting occupations from short textual bios. We also investigate how any effects are mediated by humans' fairness perceptions and their reliance on AI recommendations. Our findings show that explanations influence fairness perceptions, which, in turn, relate to humans' tendency to adhere to AI recommendations. However, we see that such explanations do not enable humans to discern correct and incorrect AI recommendations. Instead, we show that they may affect reliance irrespective of the correctness of AI recommendations. Depending on which features an explanation highlights, this can foster or hinder distributive fairness: when explanations highlight features that are task-irrelevant and evidently associated with the sensitive attribute, this prompts overrides that counter AI recommendations that align with gender stereotypes. Meanw
    

