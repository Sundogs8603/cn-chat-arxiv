# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Unsupervised anomaly detection algorithms on real-world data: how many do we need?.](http://arxiv.org/abs/2305.00735) | 对52个真实多元表格数据集上的32个无监督异常检测算法进行了评估，结果表明第kNN算法在本地数据集上优于其他算法，而EIF算法在全球数据集上表现最佳，建议实际使用这三款无监督异常检测算法的工具箱。 |
| [^2] | [What Do Self-Supervised Vision Transformers Learn?.](http://arxiv.org/abs/2305.00729) | 本文比较了对比学习和遮蔽图像建模在表示和 下游任务表现方面的差异。实验证明，自监督视觉变压器利用对比学习时能够捕捉更长程的全局模式并线性分离图像，但在自我关注力的同质性、可扩展性和密集预测性能方面存在一些问题。 |
| [^3] | [Full Scaling Automation for Sustainable Development of Green Data Centers.](http://arxiv.org/abs/2305.00706) | 提出了一种全面自动化扩展（FSA）机制来改善数据中心的能源利用效率，该机制利用深度表征学习来预测每个服务的未来负载并自动稳定相应的目标CPU使用率水平。 |
| [^4] | [On the Complexity of Multi-Agent Decision Making: From Learning in Games to Partial Monitoring.](http://arxiv.org/abs/2305.00684) | 本文研究了多智能体决策制定的样本有效、均衡计算和局部监控问题，提出了复杂度上下界和算法，并发现多智能体情况下可能呈指数级难度。 |
| [^5] | [Learning Terrain-Aware Kinodynamic Model for Autonomous Off-Road Rally Driving With Model Predictive Path Integral Control.](http://arxiv.org/abs/2305.00676) | 本研究提出了一种地形感知的运动学模型学习与预测控制法，可以生成可靠的 6 自由度运动预测，并可在无需训练时基于机器学习进行接触力估计，实现了对复杂越野场地的安全与鲁棒自主驾驶控制。 |
| [^6] | [Part Aware Contrastive Learning for Self-Supervised Action Recognition.](http://arxiv.org/abs/2305.00666) | 本文提出了一个名为SkeAttnCLR的自监督学习框架，能将局部相似性与全局特征整合到骨架动作表示中。其中采用多头注意力掩蔽学习软掩蔽特征，将相似的局部特征紧密靠近。通过利用全局特征扩展对比配对，显著提高了对比学习的效果。 |
| [^7] | [Representations and Exploration for Deep Reinforcement Learning using Singular Value Decomposition.](http://arxiv.org/abs/2305.00654) | 本文提出了一种基于奇异值分解的自动表征学习模型，可以获得保留转换结构的表示形式并捕捉状态访问的相对频率。该方法不需要转移矩阵，可以利用深度网络，适用于部分可观察领域，并且在多任务设置中表现良好。 |
| [^8] | [Procedural Content Generation via Knowledge Transformation (PCG-KT).](http://arxiv.org/abs/2305.00644) | PCG-KT是一种新的内容生成方法和框架，其通过知识转换来改变并生成新的内容，这种方法适用于缺乏训练数据或全新的游戏。 |
| [^9] | [Decomposition Enhances Reasoning via Self-Evaluation Guided Decoding.](http://arxiv.org/abs/2305.00633) | 本论文提出了一种通过自我评估引导解码提高推理的方法，使用经过校准的自动标准探索推理搜索空间，使搜索能够产生更高质量的最终预测结果；使用自我评估引导的随机束搜索在产生推理链的质量和多样性之间平衡权衡，适应多数投票，并且可以准确判断逻辑错误，提高一致性和鲁棒性。 |
| [^10] | [A Simplified Framework for Contrastive Learning for Node Representations.](http://arxiv.org/abs/2305.00623) | 本文研究了对比学习和图神经网络相结合的节点嵌入方法，通过简单的列处理嵌入矩阵取代同行处理，在提高结果嵌入质量和训练时间的同时，提高了下游分类任务的性能。 |
| [^11] | [Consolidator: Mergeable Adapter with Grouped Connections for Visual Adaptation.](http://arxiv.org/abs/2305.00603) | 本文提出了一种名为 Consolidator 的 mergeable adapter with grouped connections for visual adaptation，促进了视觉 transformer 的知识转移，实现了多个图像分类和对象检测任务的最新转移表现。 |
| [^12] | [Incremental procedural and sensorimotor learning in cognitive humanoid robots.](http://arxiv.org/abs/2305.00597) | 本文提出了一个基于CONAIM模型的认知代理，能够逐步学习程序，通过增加新功能来解决之前无法解决的任务。在模拟环境中，使用增强学习的单一程序学习机制对人形机器人进行了物体跟踪实验。 |
| [^13] | [How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model.](http://arxiv.org/abs/2305.00586) | 本研究运用机械式可解释性技术探究了GPT-2 Small的数学能力，并确定了它的计算图中的一个小电路用于计算大于符号，该电路的多层感知器提高了结束年份大于开始年份的概率，并且该电路具有广泛的适用性。 |
| [^14] | [Multimodal Graph Transformer for Multimodal Question Answering.](http://arxiv.org/abs/2305.00581) | 本文提出了一种新的多模态图转换器，它使用图神经网络将文本和视觉数据的多模态图形信息与vanilla self-attention机制相结合，以增强模型理解结构化输入数据的能力，并在两种具有挑战性的多模态问答基准上取得了性能提升。 |
| [^15] | [Scaling Pareto-Efficient Decision Making Via Offline Multi-Objective RL.](http://arxiv.org/abs/2305.00567) | 本文提出了一种新的数据驱动离线MORL设置和一个用于离线MORL的算法PEDA。PEDA通过在多个模型中选择最优模型来实现正交偏好。实验表明，PEDA在样本效率方面优于现有方法，同时还可扩展到具有更大动作空间的复杂环境中。 |
| [^16] | [Model-free Motion Planning of Autonomous Agents for Complex Tasks in Partially Observable Environments.](http://arxiv.org/abs/2305.00561) | 本文提出了一种无模型强化学习方法，利用线性时态逻辑和极限确定性广义布氏自动机来解决部分可观察环境下自主智能体复杂任务的运动规划，该方法利用深度Q学习与LSTM增强技术。 |
| [^17] | [Automated reasoning support for Standpoint-OWL 2.](http://arxiv.org/abs/2305.00559) | 该论文提出了一个用于模拟和处理来自不同立场的知识的工具，通过增强基本逻辑来实现，可以直接用于处理多元立场并提供自动推理支持。 |
| [^18] | [Deep Learning-based Spatio Temporal Facial Feature Visual Speech Recognition.](http://arxiv.org/abs/2305.00552) | 本研究提出了一种基于深度学习的时空面部特征可视化语音识别认证技术，结合面部识别和个体讲密码时的独特时空面部特征运动，成功在工业标准数据集上达到96.1％的准确率。 |
| [^19] | [Calibration Error Estimation Using Fuzzy Binning.](http://arxiv.org/abs/2305.00543) | 本文提出了一种模糊校准误差度量（FCE），利用模糊分箱方法计算校准误差，从而缓解了概率偏斜的影响并提供了更紧密的估计值。与传统指标ECE相比，FCE在多类设置中表现更好，https://github.com/srdgFHE/FCE-paper。 |
| [^20] | [Learning Achievement Structure for Structured Exploration in Domains with Sparse Reward.](http://arxiv.org/abs/2305.00508) | 本文提出了SEA算法，可在成就型环境中进行探索任务。SEA首先学习已知成就的表示和依赖关系图，然后通过构建控制器在线探索新成就。实验证明SEA能够准确地恢复成就结构并改善在一些复杂领域中的探索性能。 |
| [^21] | [Posterior Sampling for Deep Reinforcement Learning.](http://arxiv.org/abs/2305.00477) | 本文提出了用于深度强化学习的后验采样算法PSDRL，结合了高效的不确定性量化和特殊设计的持续规划算法，使其在提高样本效率的同时显著优于之前的尝试。 |
| [^22] | [Causalainer: Causal Explainer for Automatic Video Summarization.](http://arxiv.org/abs/2305.00455) | Causalainer是一个自动视频摘要的因果解释器，其引入多个有意义的随机变量及其联合分布来描述视频摘要管道中关键组件的行为，可以分析用户指定的干预的因果效应，提高了模型的透明度和可解释性。 |
| [^23] | [Multi-Task Structural Learning using Local Task Similarity induced Neuron Creation and Removal.](http://arxiv.org/abs/2305.00441) | 本文提出了一种名为“多任务结构学习（MTSL）”的方法，可以同时学习多任务架构及其参数，其主要贡献在于将局部任务相似性纳入神经元创建和移除，从而提高了神经网络的泛化能力。 |
| [^24] | [Optimized Machine Learning for CHD Detection using 3D CNN-based Segmentation, Transfer Learning and Adagrad Optimization.](http://arxiv.org/abs/2305.00411) | 本文提出了一种基于机器学习和图像处理技术相结合的新框架，用于检测冠心病。该框架包括数据分析、特征选择、基于3D CNN的分割、迁移学习和Adagrad优化。使用该框架可以提高冠心病早期检测和诊断的准确性和效率。 |
| [^25] | [Constructing a Knowledge Graph from Textual Descriptions of Software Vulnerabilities in the National Vulnerability Database.](http://arxiv.org/abs/2305.00382) | 本文提出了一种从国家漏洞数据库信息中构建漏洞知识图谱的新方法，结合了命名实体识别、关系提取和实体预测。该方法有助于解决网络安全知识图谱中缺失实体的问题。 |
| [^26] | [ReLBOT: A Transfer Learning Approach to Minimize Reinforcement Learning Risks in Smart Buildings.](http://arxiv.org/abs/2305.00365) | ReLBOT使用转移学习和深度RL技术来从现有的智能建筑中传递优化参数到新的建筑中，以减少强化学习代理引起的初始不适，有效降低了风险，并且实现了热身期时长6.2倍的提高和预测方差的132倍提高。 |
| [^27] | [MH-DETR: Video Moment and Highlight Detection with Cross-modal Transformer.](http://arxiv.org/abs/2305.00355) | 该论文提出了面向视频片段和精华部分检测的MH-DETR模型，使用跨模态Transformer来获取时间上对齐的跨模态特征，解决了现有方法中时间内部上下文不足的问题。 |
| [^28] | [POUF: Prompt-oriented unsupervised fine-tuning for large pre-trained models.](http://arxiv.org/abs/2305.00350) | 本文提出了一种基于提示的无监督微调框架，可以在未标记的目标数据上微调大型预训练模型以适应下游任务，实验结果表明该方法在图像分类、情感分析和自然语言推理等任务中表现更好。 |
| [^29] | [Fusion for Visual-Infrared Person ReID in Real-World Surveillance Using Corrupted Multimodal Data.](http://arxiv.org/abs/2305.00320) | 本篇论文提出了一种名为MMSF的模型，能够保留模态特定的知识，提高受污染多模态图像的鲁棒性。同时，还采用了三种最先进的基于注意力的多模态融合模型，在V-I ReID中适应受污染多模态数据，动态平衡每种模态的重要性。 |
| [^30] | [A preferential interpretation of MultiLayer Perceptrons in a conditional logic with typicality.](http://arxiv.org/abs/2305.00304) | 本文探究了缺陷推理的多优选语义和多层神经网络模型之间的关系，并利用提出的多优先语义，对多层感知器(MLPs)进行了优先解释，并验证了其条件属性。 |
| [^31] | [Improving Classification of Retinal Fundus Image Using Flow Dynamics Optimized Deep Learning Methods.](http://arxiv.org/abs/2305.00294) | 本论文提出了一种基于流体动力学优化的深度学习方法，用于改进糖尿病视网膜病变的分类。研究人员提出了一种新的 CNN 模型，用于确定底片图像的特征，并使用各种机器学习分类器对其进行评估。 |
| [^32] | [Students' Voices on Generative AI: Perceptions, Benefits, and Challenges in Higher Education.](http://arxiv.org/abs/2305.00290) | 本研究探讨了大学生对于高等教育中使用生成式人工智能的感知和看法。学生们普遍持积极态度，并认可GenAI提供的个性化学习支持、写作、头脑风暴和研究分析功能，但也存在一些对于准确性、隐私、伦理问题以及对个人发展、职业前景和社会价值的担忧。 |
| [^33] | [Segment Anything Model (SAM) Meets Glass: Mirror and Transparent Objects Cannot Be Easily Detected.](http://arxiv.org/abs/2305.00278) | 这项工作对段落任意模型（SAM）的能力在玻璃相关的情况下进行了实证评估，发现SAM在镜面和透明物体中往往无法检测玻璃，这引起了在具有各种形式的玻璃的安全关键情况下部署SAM的关注。 |
| [^34] | [Hierarchical Dialogue Understanding with Special Tokens and Turn-level Attention.](http://arxiv.org/abs/2305.00262) | HiDialog是一种有效的用于对话理解的分层模型，其通过插入特殊标记和提出轮次级别的注意力来建模不同轮次的语义变化，并利用异构图模块来优化所学的嵌入。在对话关系提取，对话情感识别和对话行为分类任务中，HiDialog取得了最先进的性能。 |
| [^35] | [Industry Classification Using a Novel Financial Time-Series Case Representation.](http://arxiv.org/abs/2305.00245) | 本论文提出一种新型金融时间序列案例表示法，可用于行业部门分类任务，通过对股票收益嵌入的表示，显着提高了模型性能。 |
| [^36] | [A Review of ChatGPT Applications in Education, Marketing, Software Engineering, and Healthcare: Benefits, Drawbacks, and Research Directions.](http://arxiv.org/abs/2305.00237) | 本文综述了ChatGPT在教育、营销、软件工程和医疗保健领域的潜在应用、局限性和未来方向，探讨ChatGPT作为一种高级语言交互机器人的研究现状与实践意义。 |
| [^37] | [Towards machine learning guided by best practices.](http://arxiv.org/abs/2305.00233) | 机器学习在多个领域的软件系统中得到广泛应用，但存在一些特殊的挑战和陷阱，研究显示ML使能系统具有不同于传统软件工程的开发过程。 |
| [^38] | [Local Search for Integer Linear Programming.](http://arxiv.org/abs/2305.00188) | 本论文开发了一个独立的局部搜索求解器，可用于解决一般整数线性规划，并在大型异构问题数据集上进行了验证。在搜索、改进和还原模式下，分别提出了可自适应修改变量值的算子和高效的举升算子，从而提高当前解的质量。实验表明，该方法在MIPLIB2017的异构问题集上表现优异。 |
| [^39] | [An Evidential Real-Time Multi-Mode Fault Diagnosis Approach Based on Broad Learning System.](http://arxiv.org/abs/2305.00169) | 本文提出了一种基于证据推理算法和广义学习系统的实时多模态故障诊断方法，该方法在更新模型参数和计算效率方面具有优势，并且在基准数据集上取得了比现有方法更好的故障诊断性能。 |
| [^40] | [Optimizing the AI Development Process by Providing the Best Support Environment.](http://arxiv.org/abs/2305.00136) | 本研究旨在提供人工智能（AI）和机器学习（ML）应用的最佳支持环境，具体重点研究了ML开发中数据管理阶段的障碍以及如何构建和开发一个框架，利用多种数据增强技术来解决数据管理阶段缺乏足够数据的问题。 |
| [^41] | [Optimal Scheduling in IoT-Driven Smart Isolated Microgrids Based on Deep Reinforcement Learning.](http://arxiv.org/abs/2305.00127) | 本文使用深度强化学习解决物联网驱动智能孤网微电网中柴油发电机组的调度问题，通过学习历史数据生成实时决策以确保供需平衡，并减少操作成本。 |
| [^42] | [Exploring the Zero-Shot Capabilities of the Segment Anything Model (SAM) in 2D Medical Imaging: A Comprehensive Evaluation and Practical Guideline.](http://arxiv.org/abs/2305.00109) | 本文探索了Segment Anything Model (SAM)在医学影像中的零样本能力，并通过八种不同的提示策略在六个数据集上进行评估，结果表明其性能比当前最先进技术有所提升。 |
| [^43] | [Improving Gradient Computation for Differentiable Physics Simulation with Contacts.](http://arxiv.org/abs/2305.00092) | 本文研究了接触情况下的可微分刚体模拟，发现现有的方法在接触法线方向不固定时会提供不准确的梯度，提出了一种通过连续的碰撞检测和利用碰撞时间来计算碰撞后的速度来改进梯度计算的方法TOI-Velocity。 |
| [^44] | [Exploiting the Distortion-Semantic Interaction in Fisheye Data.](http://arxiv.org/abs/2305.00079) | 本文利用畸变-语义交互作用提出了一种方法，该方法通过提取畸变类别标签，并使用加权对比损失塑造主干网络的表征空间，以限制每个物体的表征和相应的畸变类别的关系。 |
| [^45] | [Online Platt Scaling with Calibeating.](http://arxiv.org/abs/2305.00070) | 本文提出了一种在线Platt缩放及其校准方法，其理论基础强大，可以处理分布漂移和对抗性结果序列，无需超参数调整，在一系列合成和真实数据集上表现出卓越的性能。 |
| [^46] | [Logic-based similarity.](http://arxiv.org/abs/2305.00065) | 本文提出了一种基于逻辑的“定性”相似性概念，通过类型理论作为中心思想和一阶逻辑的基本概念进行了构建。 |
| [^47] | [Explainable Verbal Reasoner Plus (EVR+): A Natural Language Reasoning Framework that Supports Diverse Compositional Reasoning.](http://arxiv.org/abs/2305.00061) | EVR+是一种语言推理框架，通过允许生成和执行符号运算符以及将复杂任务分解为多个简单任务等方式增强了语言模型的组合推理能力。它支持更多种类的推理，例如嵌套循环和不同类型的递归。 |
| [^48] | [LAVA: Data Valuation without Pre-Specified Learning Algorithms.](http://arxiv.org/abs/2305.00054) | LAVA是一个学习算法无关的数据价值评估方法，它结合了学习算法的统计特性和训练数据的属性，通过迭代估计数据值来实现。LAVA比现有方法计算速度更快，精度更高，并且可以为不同的应用提供有意义的数据排名。 |
| [^49] | [Causal Reasoning and Large Language Models: Opening a New Frontier for Causality.](http://arxiv.org/abs/2305.00050) | 大型语言模型在因果推理任务中取得了新的最高准确率，但是其鲁棒性仍然存在难以预测的失败模式。 |
| [^50] | [An automated end-to-end deep learning-based framework for lung cancer diagnosis by detecting and classifying the lung nodules.](http://arxiv.org/abs/2305.00046) | 本文提出了一种基于深度学习的智能诊断框架，针对低资源环境实现早期检测和分类肺部结节，并在公共数据集上取得了较好的表现。 |
| [^51] | [SAM on Medical Images: A Comprehensive Study on Three Prompt Modes.](http://arxiv.org/abs/2305.00035) | SAM是第一种可提示的基础分割模型，在医学图像中表现出竞争力，具有强大的零样本泛化能力，提示模式对其表现影响显著。 |
| [^52] | [TorchBench: Benchmarking PyTorch with High API Surface Coverage.](http://arxiv.org/abs/2304.14226) | TorchBench是一款新型基准测试套件，可全面表征PyTorch软件栈的性能，指导模型、PyTorch框架和GPU库的性能优化。 |
| [^53] | [Ensoul: A framework for the creation of self organizing intelligent ultra low power systems (SOULS) through evolutionary enerstatic networks.](http://arxiv.org/abs/2304.13863) | Ensoul是一种框架，通过enerstatic网络和开放进化技术结合，创造了能够独立于其嵌入的基质的自组织智能超低功耗系统(SOULS)。 |
| [^54] | [Evaluation of GPT-3.5 and GPT-4 for supporting real-world information needs in healthcare delivery.](http://arxiv.org/abs/2304.13714) | 本研究评估了在临床环境中使用GPT-3.5和GPT-4解决医学问题的安全性以及与信息技术咨询服务报告的一致性。研究结果表明，两个LLMs都可以以安全和一致的方式满足医生的信息需求。 |
| [^55] | [Unlocking the Potential of Collaborative AI -- On the Socio-technical Challenges of Federated Machine Learning.](http://arxiv.org/abs/2304.13688) | 联邦机器学习是一种新的人工智能范式，可以从数据孤岛中创建AI模型，挑战在于建立多方合作业务模式。本研究系统化了联邦机器学习项目的社会技术挑战和业务模式。 |
| [^56] | [Incorporating Experts' Judgment into Machine Learning Models.](http://arxiv.org/abs/2304.11870) | 本文提出了一种新的框架，利用生成对抗网络确定未标记数据点在训练数据中的代表程度，再根据这个程度将专家的判断融入机器学习模型，以减轻预测结果与专家判断之间的冲突。 |
| [^57] | [Ensuring Trustworthy Medical Artificial Intelligencethrough Ethical and Philosophical Principles.](http://arxiv.org/abs/2304.11530) | 本文讨论了人工智能在医疗保健中的应用和考虑伦理和哲学原则以确保可靠的人工智能工具的重要性。人工智能在医疗中带来了更多挑战，必须解决偏见、透明度、自主权、责任和问责制等问题，作者提出了可能的解决办法。 |
| [^58] | [SemEval 2023 Task 6: LegalEval -- Understanding Legal Texts.](http://arxiv.org/abs/2304.09548) | SemEval 2023举办了LegalEval共享任务，即理解法律文本，包括 自动结构化和语义连贯化的法律文件（Task-A），法律命名实体识别（Task-B）以及自动预测法律案件结果和提供预测解释（Task-C）。26个团队提交了系统论文并在所有子任务中优于基准线，但仍有改进空间。 |
| [^59] | [Efficient Automation of Neural Network Design: A Survey on Differentiable Neural Architecture Search.](http://arxiv.org/abs/2304.05405) | 本文综述了最近在不同iable神经架构搜索中的研究进展，提出了一种新的基于挑战的分类法，对DARTS方法的贡献和影响进行了讨论，并探讨了未来的研究方向。 |
| [^60] | [MEDIMP: Medical Images and Prompts for renal transplant representation learning.](http://arxiv.org/abs/2303.12445) | MEDIMP是一种用于多模式学习肾移植DCE MRI的医学图像和提示模型，利用联合文本-图像嵌入的对比学习来学习有意义的表示。 |
| [^61] | [A Content Adaptive Learnable Time-Frequency Representation For Audio Signal Processing.](http://arxiv.org/abs/2303.10446) | 该论文提出了一种用于音频信号处理的内容自适应可学习时频表示法，通过学习卷积滤波器与变换器架构来将小的波形块投影到小的潜在维度上。 |
| [^62] | [Could a Large Language Model be Conscious?.](http://arxiv.org/abs/2303.07103) | 本文分析了大型语言模型是否具有意识的可能性，目前的模型存在着意识的显著障碍，但未来十年随着障碍被克服，后继的大型语言模型可能会具有意识。 |
| [^63] | [KGNv2: Separating Scale and Pose Prediction for Keypoint-based 6-DoF Grasp Synthesis on RGB-D input.](http://arxiv.org/abs/2303.05617) | 本文提出了一种基于关键点的RGB-D输入的六自由度抓取姿态合成方法，既可以从关键点检测中预测抓取姿态，也可以预测相对于相机的尺度，实验结果表明其优越性。 |
| [^64] | [Targeted demand response for flexible energy communities using clustering techniques.](http://arxiv.org/abs/2303.00186) | 本研究探讨了使用机器学习算法中的聚类技术设计并执行需求响应（DR）计划的可行性，目的是改变分布式能源社区内供应者的消费行为，以最小化反向功率流和削减系统范围内的功峰需求。 |
| [^65] | [Exposure-Based Multi-Agent Inspection of a Tumbling Target Using Deep Reinforcement Learning.](http://arxiv.org/abs/2302.14188) | 本论文提出了一种基于深度强化学习的层次化、学习式的多智能体翻转目标巡检规划方法，分为视点规划和导航规划两部分，可以自主、强韧、去中心化地完成巡检任务。 |
| [^66] | [A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT.](http://arxiv.org/abs/2302.09419) | 本文全面回顾了预训练基础模型的最新研究进展和发展历程，包括它们的架构、培训目标、预培训任务、微调策略和评估。同时，讨论了其局限性和未来研究方向。 |
| [^67] | [SHINE: Deep Learning-Based Accessible Parking Management System.](http://arxiv.org/abs/2302.00837) | SHINE是一个基于深度学习的无障碍停车管理系统，能够实时识别停放在无障碍停车位上的车辆，并具备可访问性监测功能。实验结果表明，SHINE优于现有的车牌识别系统。 |
| [^68] | [Direct Parameterization of Lipschitz-Bounded Deep Networks.](http://arxiv.org/abs/2301.11526) | 本文提出了一种直接参数化的深度神经网络，其具有拉普拉斯界限，通过标准梯度方法进行训练，避免了计算密集型的投影或障碍项。 |
| [^69] | [Knowledge-Guided Data-Centric AI in Healthcare: Progress, Shortcomings, and Future Directions.](http://arxiv.org/abs/2212.13591) | 简而言之，该论文讨论了如何使用数据中心的方法解决医学图像诊断中的“小数据”问题，介绍了数据增强、迁移学习、联邦学习和GAN的方法，并提出了使用知识引导的GAN将领域知识纳入训练数据生成过程中。 |
| [^70] | [Game Theoretic Mixed Experts for Combinational Adversarial Machine Learning.](http://arxiv.org/abs/2211.14669) | 本文提出了一种博弈论框架，用于组合对抗攻击和防御，我们的框架提出了一种混合专家模型，专门针对特定的防御攻击进行防御，并以博弈论的方式进行合作和竞争，形成一个联合防御。 |
| [^71] | [Modeling Multivariate Biosignals With Graph Neural Networks and Structured State Space Models.](http://arxiv.org/abs/2211.11176) | 本研究提出了一种基于时间依赖图的通用图神经网络结构(GraphS4mer)，用于建立多元生物信号模型。该模型结合了结构化状态空间架构和动态演变的图结构学习层来解决长时序和复杂空间相关性，能有效地提高多元生物信号分类任务性能。 |
| [^72] | [Syntax-Aware On-the-Fly Code Completion.](http://arxiv.org/abs/2211.04673) | 本文介绍了一种有关语法感知的即时代码自动补全方法 PyCoder，通过利用轻量级的语法信息（标记类型），它插入了支持任务来提高代码自动补全的性能，在不考虑语法信息的最先进即时代码自动补全方法中表现显著优于现有方法，同时与无法即时工作的语法感知代码自动补全方法相竞争。 |
| [^73] | [Changing agents and ascribing beliefs in dynamic epistemic logic.](http://arxiv.org/abs/2211.02452) | 本文在动态认知逻辑中扩展了行动框架，提出了代理更新框架，可以有选择性地添加或删除代理，并进行代理更新。这个框架可以用于模拟一些有趣的例子，并在人工智能问题的建模中得到应用。 |
| [^74] | [SAM-RL: Sensing-Aware Model-Based Reinforcement Learning via Differentiable Physics-Based Simulation and Rendering.](http://arxiv.org/abs/2210.15185) | SAM-RL使用不可导物理仿真和渲染，通过比较渲染图像和真实原始图像自动更新模型，并高效产生策略。感知感知的学习管道允许机器人选择信息丰富的视角监控任务过程。 用于完成机器人组装，工具操作和变形物体操作任务。 |
| [^75] | [Scaling up and Stabilizing Differentiable Planning with Implicit Differentiation.](http://arxiv.org/abs/2210.13542) | 本文提出了一种通过 Bellman 固定点方程进行微分的方法，实现了值迭代网络及其变体的前后传递解耦，可实现在规划视程内稳定且灵活前向预算的扩展，展示了在不同规划任务上的出色表现。 |
| [^76] | [Baby Physical Safety Monitoring in Smart Home Using Action Recognition System.](http://arxiv.org/abs/2210.12527) | 本文提出了一种新的轻量级框架，将迁移学习技术与Conv2D LSTM层相结合，用于婴儿物理安全监测的行为识别。 |
| [^77] | [Towards Better Generalization with Flexible Representation of Multi-Module Graph Neural Networks.](http://arxiv.org/abs/2209.06589) | 本研究探讨了图神经网络在推广到更大的图和从未见过的数据方面的局限，并提出了多模块GNN框架，通过推广单个规范非线性变换来适应新图。结果表明，多模块GNN在合成和实际数据集上均显著提高了GNN的泛化能力，并在几项具有挑战性的任务上实现了最先进的性能。 |
| [^78] | [Byzantines can also Learn from History: Fall of Centered Clipping in Federated Learning.](http://arxiv.org/abs/2208.09894) | 本文研究了中心化剪裁在面对不同恶意代理时的脆弱性，提出了一种称为多引用点剪裁 (MRPC) 的算法来解决这个问题。MRPC 框架利用多个参考点有效地中和专门设计的 Byzantine attacks。实验结果表明，在各种类型的 Byzantine attacks 下，MRPC 显著优于最先进的 FL 方法。 |
| [^79] | [Conformal Risk Control.](http://arxiv.org/abs/2208.02814) | 该论文提出了一种符合保序的风险控制方法，可以控制任何单调损失函数的期望值，示例证明其在计算机视觉和自然语言处理领域具有控制误报率、图形距离和令牌级F1得分的能力。 |
| [^80] | [Wasserstein Graph Distance Based on $L_1$-Approximated Tree Edit Distance between Weisfeiler-Lehman Subtrees.](http://arxiv.org/abs/2207.04216) | 本文提出一种名为Wasserstein WL子树(WWLS)距离的新型图距离，通过利用WL子树作为节点邻域的结构信息，使用节点的WL子树之间的L1-近似树编辑距离(L1-TED)定义节点度量，解决了WL测试无法捕捉轻微结构差异的问题 |
| [^81] | [Implementing Reinforcement Learning Datacenter Congestion Control in NVIDIA NICs.](http://arxiv.org/abs/2207.02295) | 本文在NVIDIA网卡中实现了强化学习数据中心拥塞控制，通过将RL-CC的复杂神经网络转化为决策树，实现了实时推理，并成功改善了网络拥塞下的尾部延迟和数据包丢失问题。 |
| [^82] | [RevBiFPN: The Fully Reversible Bidirectional Feature Pyramid Network.](http://arxiv.org/abs/2206.14098) | 本文提出了RevSilo，一个完全可逆的双向多尺度特征融合模块，它缓解了神经网络规模受限的问题。 |
| [^83] | [Integrating Symmetry into Differentiable Planning with Steerable Convolutions.](http://arxiv.org/abs/2206.03674) | 本文研究了如何在路径规划任务中使用对称性改善数据效率和泛化能力。将值迭代视为网格信号，并使用可控卷积来融合对称性。实验表明，我们的对称规划算法比非等变对应物在训练效率和泛化方面有很大提升。 |
| [^84] | [Joint Energy Dispatch and Unit Commitment in Microgrids Based on Deep Reinforcement Learning.](http://arxiv.org/abs/2206.01663) | 本文采用深度强化学习算法HAFH-DDPG来学习隔离式微电网中的联合能量分配和机组开启决策问题，并提出了柴油发电机选择策略，以降低计算复杂度。 |
| [^85] | [Machine Explanations and Human Understanding.](http://arxiv.org/abs/2202.04092) | 研究讨论了机器解释和人类理解之间的相互作用，并确定了三个核心概念。结果显示，在没有关于特定任务直觉的假设下，解释可提高人类对模型决策边界的理解，但对任务决策边界和模型错误则没有充分证据支持。 |
| [^86] | [Generate plane quad mesh with neural networks and tree search.](http://arxiv.org/abs/2111.07613) | 本论文提出了一种结合强化学习和树搜索的新方法，名为TreeMesh，用于生成高质量的平面四边形网格，可以比现有最先进的方法更快地生成。 |
| [^87] | [SelfCF: A Simple Framework for Self-supervised Collaborative Filtering.](http://arxiv.org/abs/2107.03019) | SelfCF是一种自监督协同过滤框架，用于推荐场景，通过增强现有的深度学习协同过滤模型中输出的嵌入来简化算法以及避免昂贵的计算和潜在的负样本问题。 |
| [^88] | [Graph Representation Learning via Diversity-preserving Graph Refinement.](http://arxiv.org/abs/2103.07295) | 该论文提出了一种基于多样性保持的图结构细化的图表示学习方法，它利用已学习的节点表示来逐步改善图形结构质量。在多个下游任务上，包括节点分类、链接预测和图聚类，实验表明该方法优于现有的最先进方法。 |
| [^89] | [Benchmarking Energy-Conserving Neural Networks for Learning Dynamics from Data.](http://arxiv.org/abs/2012.02334) | 本文调查了10个最近提出的能量守恒神经网络模型，并比较了它们在4个物理系统中的表现，说明了利用这些模型设计基于能量的控制器的可能性。 |
| [^90] | [Verifying Tight Logic Programs with anthem and Vampire.](http://arxiv.org/abs/2008.02025) | 本文通过使用Anthem和Vampire两个软件工具，验证了具有输入和输出的程序的正确性，并研究了该上下文中稳定模型和补完之间的关系。 |

# 详细

[^1]: 真实数据上的无监督异常检测算法：我们需要多少款算法？

    Unsupervised anomaly detection algorithms on real-world data: how many do we need?. (arXiv:2305.00735v1 [cs.LG])

    [http://arxiv.org/abs/2305.00735](http://arxiv.org/abs/2305.00735)

    对52个真实多元表格数据集上的32个无监督异常检测算法进行了评估，结果表明第kNN算法在本地数据集上优于其他算法，而EIF算法在全球数据集上表现最佳，建议实际使用这三款无监督异常检测算法的工具箱。

    

    本研究对52个真实多元表格数据集上的32个无监督异常检测算法进行了评估，是目前最大的无监督异常检测算法的比较研究。在这些数据集上，第kNN（到k个最近邻居的距离）算法的性能明显优于其他算法。通过可视化和聚类算法在所有数据集上的性能，我们发现了两个明显的簇：一个是“本地”数据集，另一个是“全局”数据集。在本地数据集中，kNN算法表现最佳，在全局数据集中，EIF算法表现最佳。综合考虑算法的计算复杂性，建议实际使用这三种无监督异常检测算法（分别是kNN、EIF和LOF算法）的工具箱。

    In this study we evaluate 32 unsupervised anomaly detection algorithms on 52 real-world multivariate tabular datasets, performing the largest comparison of unsupervised anomaly detection algorithms to date. On this collection of datasets, the $k$-thNN (distance to the $k$-nearest neighbor) algorithm significantly outperforms the most other algorithms. Visualizing and then clustering the relative performance of the considered algorithms on all datasets, we identify two clear clusters: one with ``local'' datasets, and another with ``global'' datasets. ``Local'' anomalies occupy a region with low density when compared to nearby samples, while ``global'' occupy an overall low density region in the feature space. On the local datasets the $k$NN ($k$-nearest neighbor) algorithm comes out on top. On the global datasets, the EIF (extended isolation forest) algorithm performs the best. Also taking into consideration the algorithms' computational complexity, a toolbox with these three unsupervis
    
[^2]: 自监督视觉变压器学习什么？

    What Do Self-Supervised Vision Transformers Learn?. (arXiv:2305.00729v1 [cs.CV])

    [http://arxiv.org/abs/2305.00729](http://arxiv.org/abs/2305.00729)

    本文比较了对比学习和遮蔽图像建模在表示和 下游任务表现方面的差异。实验证明，自监督视觉变压器利用对比学习时能够捕捉更长程的全局模式并线性分离图像，但在自我关注力的同质性、可扩展性和密集预测性能方面存在一些问题。

    

    本文对比了对比学习（CL）和遮蔽图像建模（MIM）在其表示和下游任务表现方面的差异，并阐述了自监督视觉变压器（ViTs）的性质。通过实验证明，CL训练自我关注力以捕捉比MIM更长程的全局模式，例如物体的形状，尤其是在ViT架构的后几层中。这使得ViTs能够在其表示空间中线性分离图像。但是，它也使得自我关注力对于所有查询标记和头部的同质性崩溃。这种自我关注力的同质性降低了表征的多样性，恶化了可扩展性和密集预测性能　。CL利用表示的低频信号，而MIM利用高频信号。由于低频和高频信息分别代表形状和质地，因此CL更加注重形状，而MIM则更加注重质地。

    We present a comparative study on how and why contrastive learning (CL) and masked image modeling (MIM) differ in their representations and in their performance of downstream tasks. In particular, we demonstrate that self-supervised Vision Transformers (ViTs) have the following properties: (1) CL trains self-attentions to capture longer-range global patterns than MIM, such as the shape of an object, especially in the later layers of the ViT architecture. This CL property helps ViTs linearly separate images in their representation spaces. However, it also makes the self-attentions collapse into homogeneity for all query tokens and heads. Such homogeneity of self-attention reduces the diversity of representations, worsening scalability and dense prediction performance. (2) CL utilizes the low-frequency signals of the representations, but MIM utilizes high-frequencies. Since low- and high-frequency information respectively represent shapes and textures, CL is more shape-oriented and MIM m
    
[^3]: 可持续发展绿色数据中心的全面自动化扩展机制

    Full Scaling Automation for Sustainable Development of Green Data Centers. (arXiv:2305.00706v1 [cs.DC])

    [http://arxiv.org/abs/2305.00706](http://arxiv.org/abs/2305.00706)

    提出了一种全面自动化扩展（FSA）机制来改善数据中心的能源利用效率，该机制利用深度表征学习来预测每个服务的未来负载并自动稳定相应的目标CPU使用率水平。

    

    云计算的快速崛起导致数据中心碳排放量惊人地增加，现在占全球温室气体排放的>3％，必须立即采取措施应对它们对全球气候日益增长的负担。这一努力的重点是提高资源利用率以节省电力消耗。我们提出的全面自动化扩展（FSA）机制是一种有效的方法，可以在大规模云计算集群中动态地适应不断变化的工作负载，使数据中心中的集群保持其所需的CPU利用率目标，从而改善能源效率。FSA利用深度表征学习的威力来准确预测每个服务的未来工作负载，并自动稳定相应的目标CPU使用率水平，不像之前的自动扩展方法，如Autopilot或FIRM，需要使用统计模型和专家知识来调整计算资源。

    The rapid rise in cloud computing has resulted in an alarming increase in data centers' carbon emissions, which now accounts for >3% of global greenhouse gas emissions, necessitating immediate steps to combat their mounting strain on the global climate. An important focus of this effort is to improve resource utilization in order to save electricity usage. Our proposed Full Scaling Automation (FSA) mechanism is an effective method of dynamically adapting resources to accommodate changing workloads in large-scale cloud computing clusters, enabling the clusters in data centers to maintain their desired CPU utilization target and thus improve energy efficiency. FSA harnesses the power of deep representation learning to accurately predict the future workload of each service and automatically stabilize the corresponding target CPU usage level, unlike the previous autoscaling methods, such as Autopilot or FIRM, that need to adjust computing resources with statistical models and expert knowle
    
[^4]: 关于多智能体决策制定的复杂性：从游戏学习到局部监控。

    On the Complexity of Multi-Agent Decision Making: From Learning in Games to Partial Monitoring. (arXiv:2305.00684v1 [cs.LG])

    [http://arxiv.org/abs/2305.00684](http://arxiv.org/abs/2305.00684)

    本文研究了多智能体决策制定的样本有效、均衡计算和局部监控问题，提出了复杂度上下界和算法，并发现多智能体情况下可能呈指数级难度。

    

    多智能体强化学习（MARL）中的一个核心问题是理解结构条件和算法原则会导致哪些样本有效的学习保证，并且在我们从少数智能体转移到多数智能体时，这些考虑如何发生变化。本文在多智能体互动决策的一般框架下研究了这个问题，包括具有函数逼近的马尔可夫博弈和带有赌徒反馈的正则式博弈。我们关注均衡计算，其中集中式学习算法旨在通过控制与未知环境交互的多个智能体来计算均衡。我们的主要贡献是：1. 我们基于由Foster等人（2021）在单智能体情况下引入的复杂度度量方法—决策-估计系数，为多智能体决策制定了最佳样本复杂度的上界和下界。与单智能体情况下的最佳结果相比，我们表明多智能体情况下的问题在智能体数量方面可能呈指数级难度。2. 我们提出了一种新颖的算法，用于在具有函数逼近的大型马尔可夫博弈中进行高效的均衡计算，该算法基于乐观镜像下降法的原理。我们为我们的方法建立了样本复杂度界限，这些界限改进了先前在带有赌徒反馈的游戏中的工作。3. 我们考虑局部监控，这是一种反馈类型，其中决策制定者只观察智能体动作的摘要信息而不是全部信息。我们开发了我们算法的一个变体，该算法实现了此设置的收敛速度最优，与先前工作建立的下界相比。

    A central problem in the theory of multi-agent reinforcement learning (MARL) is to understand what structural conditions and algorithmic principles lead to sample-efficient learning guarantees, and how these considerations change as we move from few to many agents. We study this question in a general framework for interactive decision making with multiple agents, encompassing Markov games with function approximation and normal-form games with bandit feedback. We focus on equilibrium computation, in which a centralized learning algorithm aims to compute an equilibrium by controlling multiple agents that interact with an unknown environment. Our main contributions are:  - We provide upper and lower bounds on the optimal sample complexity for multi-agent decision making based on a multi-agent generalization of the Decision-Estimation Coefficient, a complexity measure introduced by Foster et al. (2021) in the single-agent counterpart to our setting. Compared to the best results for the sin
    
[^5]: 面向自主越野拉力赛的地形感知运动学模型学习与预测控制法研究

    Learning Terrain-Aware Kinodynamic Model for Autonomous Off-Road Rally Driving With Model Predictive Path Integral Control. (arXiv:2305.00676v1 [cs.RO])

    [http://arxiv.org/abs/2305.00676](http://arxiv.org/abs/2305.00676)

    本研究提出了一种地形感知的运动学模型学习与预测控制法，可以生成可靠的 6 自由度运动预测，并可在无需训练时基于机器学习进行接触力估计，实现了对复杂越野场地的安全与鲁棒自主驾驶控制。

    

    在越野环境下进行高速自主驾驶具有广泛的应用前景，但由于车辆与地形交互的复杂性，也存在一定的挑战。因此，在这种环境下，车辆预测自身运动并根据环境变化，例如地形高差的变化，主动调整其控制至关重要。针对这一问题，我们提出了一种方法来学习地形感知的运动学模型，该模型以本体感知和外部感知信息为条件。该模型可生成可靠的 6 自由度运动预测，并可在无需训练时基于机器学习进行接触力估计。该模型通过适当的代价函数设计可以生成安全且鲁棒的模型预测控制器，惩罚具有不稳定运动、不安全交互和高不确定性衍生的样本轨迹。我们证明了该方法的有效性。

    High-speed autonomous driving in off-road environments has immense potential for various applications, but it also presents challenges due to the complexity of vehicle-terrain interactions. In such environments, it is crucial for the vehicle to predict its motion and adjust its controls proactively in response to environmental changes, such as variations in terrain elevation. To this end, we propose a method for learning terrain-aware kinodynamic model which is conditioned on both proprioceptive and exteroceptive information. The proposed model generates reliable predictions of 6-degree-of-freedom motion and can even estimate contact interactions without requiring ground truth force data during training. This enables the design of a safe and robust model predictive controller through appropriate cost function design which penalizes sampled trajectories with unstable motion, unsafe interactions, and high levels of uncertainty derived from the model. We demonstrate the effectiveness of o
    
[^6]: 基于部件感知对比学习的自监督动作识别

    Part Aware Contrastive Learning for Self-Supervised Action Recognition. (arXiv:2305.00666v1 [cs.CV])

    [http://arxiv.org/abs/2305.00666](http://arxiv.org/abs/2305.00666)

    本文提出了一个名为SkeAttnCLR的自监督学习框架，能将局部相似性与全局特征整合到骨架动作表示中。其中采用多头注意力掩蔽学习软掩蔽特征，将相似的局部特征紧密靠近。通过利用全局特征扩展对比配对，显著提高了对比学习的效果。

    

    近年来，使用对比学习与骨骼序列在自监督动作识别方面获得了显著结果。本文提出了一种基于注意力的对比学习框架，称为SkeAttnCLR，用于骨骼表示学习。该框架将局部相似性和全局特征集成到基于骨架的动作表示中，通过多头注意力掩蔽模块学习软掩蔽特征，压制非显著部位特征同时突出显著部位特征，从而在特征空间中将相似的局部特征紧密靠近。此外，通过利用全局特征扩展显著和非显著特征的对比配对，获得了充足的对比配对。

    In recent years, remarkable results have been achieved in self-supervised action recognition using skeleton sequences with contrastive learning. It has been observed that the semantic distinction of human action features is often represented by local body parts, such as legs or hands, which are advantageous for skeleton-based action recognition. This paper proposes an attention-based contrastive learning framework for skeleton representation learning, called SkeAttnCLR, which integrates local similarity and global features for skeleton-based action representations. To achieve this, a multi-head attention mask module is employed to learn the soft attention mask features from the skeletons, suppressing non-salient local features while accentuating local salient features, thereby bringing similar local features closer in the feature space. Additionally, ample contrastive pairs are generated by expanding contrastive pairs based on salient and non-salient features with global features, whic
    
[^7]: 使用奇异值分解的深度强化学习中的表征学习和探索

    Representations and Exploration for Deep Reinforcement Learning using Singular Value Decomposition. (arXiv:2305.00654v1 [cs.LG])

    [http://arxiv.org/abs/2305.00654](http://arxiv.org/abs/2305.00654)

    本文提出了一种基于奇异值分解的自动表征学习模型，可以获得保留转换结构的表示形式并捕捉状态访问的相对频率。该方法不需要转移矩阵，可以利用深度网络，适用于部分可观察领域，并且在多任务设置中表现良好。

    

    表现学习和探索是任何深度强化学习代理所面临的关键挑战。本文提供了一种基于奇异值分解的方法，可以用来获得保留域中潜在转换结构的表示形式。有趣的是，我们发现这些表示形式还捕捉了状态访问的相对频率，从而免费提供了伪计数的估计。为了将这种分解方法推广到大规模域，我们提供了一种不需要建立转移矩阵，可以利用深度网络，也允许小批量训练的算法。此外，我们从预测状态表示中吸取灵感，并扩展了我们的分解方法到部分可观察的环境。通过对部分可观察领域的多任务设置进行实验，我们展示了提出的方法不仅可以在DM-Lab-30环境中学习有用的表示形式。

    Representation learning and exploration are among the key challenges for any deep reinforcement learning agent. In this work, we provide a singular value decomposition based method that can be used to obtain representations that preserve the underlying transition structure in the domain. Perhaps interestingly, we show that these representations also capture the relative frequency of state visitations, thereby providing an estimate for pseudo-counts for free. To scale this decomposition method to large-scale domains, we provide an algorithm that never requires building the transition matrix, can make use of deep networks, and also permits mini-batch training. Further, we draw inspiration from predictive state representations and extend our decomposition method to partially observable environments. With experiments on multi-task settings with partially observable domains, we show that the proposed method can not only learn useful representation on DM-Lab-30 environments (that have inputs
    
[^8]: 基于知识转换的流程内容生成(PCG-KT)

    Procedural Content Generation via Knowledge Transformation (PCG-KT). (arXiv:2305.00644v1 [cs.AI])

    [http://arxiv.org/abs/2305.00644](http://arxiv.org/abs/2305.00644)

    PCG-KT是一种新的内容生成方法和框架，其通过知识转换来改变并生成新的内容，这种方法适用于缺乏训练数据或全新的游戏。

    

    我们引入了基于知识转换的流程内容生成(PCG-KT)的概念，这是一种新的PCG方法和框架，其中内容生成通过知识转换来实现，即将从一个领域获得的知识转变为另一个领域可以应用的知识。我们的工作是由最近许多PCG研究的需求和挑战驱动而来，这些研究侧重于通过改变派生的知识来生成新的内容。例如，针对某个游戏的模型进行迁移学习以适应另一个游戏的内容，或者重新组合不同的生成分布以融合两个或更多游戏的内容。这些方法在某种程度上产生是由于PCG通过机器学习(PCGML)的局限性，例如为缺乏训练数据的游戏生成生成模型和为全新的游戏生成内容。在本文中，我们将这些方法归类为PCG-KT的新视角。

    We introduce the concept of Procedural Content Generation via Knowledge Transformation (PCG-KT), a new lens and framework for characterizing PCG methods and approaches in which content generation is enabled by the process of knowledge transformation -- transforming knowledge derived from one domain in order to apply it in another. Our work is motivated by a substantial number of recent PCG works that focus on generating novel content via repurposing derived knowledge. Such works have involved, for example, performing transfer learning on models trained on one game's content to adapt to another game's content, as well as recombining different generative distributions to blend the content of two or more games. Such approaches arose in part due to limitations in PCG via Machine Learning (PCGML) such as producing generative models for games lacking training data and generating content for entirely new games. In this paper, we categorize such approaches under this new lens of PCG-KT by offe
    
[^9]: 分解增强推理的自我评估引导解码

    Decomposition Enhances Reasoning via Self-Evaluation Guided Decoding. (arXiv:2305.00633v1 [cs.CL])

    [http://arxiv.org/abs/2305.00633](http://arxiv.org/abs/2305.00633)

    本论文提出了一种通过自我评估引导解码提高推理的方法，使用经过校准的自动标准探索推理搜索空间，使搜索能够产生更高质量的最终预测结果；使用自我评估引导的随机束搜索在产生推理链的质量和多样性之间平衡权衡，适应多数投票，并且可以准确判断逻辑错误，提高一致性和鲁棒性。

    

    我们提出了一种有效的提示方法，通过随机束搜索结合自我评估引导。我们的方法使用经过校准的自动标准探索推理搜索空间。这使得有效搜索能够产生更高质量的最终预测结果。使用自我评估引导的随机束搜索，我们在产生推理链的质量和多样性之间平衡权衡，从而能够适应多数投票，并在GSM8K、AQUA和StrategyQA基准测试中以少量示例准确性分别超越对应的Codex-backboned基线$6.34\%$、$9.56\%$和$5.46\%$。对我们的分解式推理分析发现，它可以指出逻辑错误并导致更高的一致性和鲁棒性。

    We propose an effective prompting approach that integrates self-evaluation guidance through stochastic beam search. Our approach explores the reasoning search space using a well-calibrated automatic criterion. This enables an efficient search to produce higher-quality final predictions. With the self-evaluation guided stochastic beam search, we also balance the quality--diversity trade-off in the generation of reasoning chains. This allows our approach to adapt well with majority voting and surpass the corresponding Codex-backboned baselines by $6.34\%$, $9.56\%$, and $5.46\%$ on the GSM8K, AQUA, and StrategyQA benchmarks, respectively, in few-shot accuracy. Analysis of our decompositional reasoning finds it pinpoints logic failures and leads to higher consistency and robustness.
    
[^10]: 用于节点表示的对比学习简化框架

    A Simplified Framework for Contrastive Learning for Node Representations. (arXiv:2305.00623v1 [cs.LG])

    [http://arxiv.org/abs/2305.00623](http://arxiv.org/abs/2305.00623)

    本文研究了对比学习和图神经网络相结合的节点嵌入方法，通过简单的列处理嵌入矩阵取代同行处理，在提高结果嵌入质量和训练时间的同时，提高了下游分类任务的性能。

    

    最近对比学习已经被证明为一种提取丰富多样的数据表示的有力自监督学习框架。广义上讲，对比学习依赖于数据增强方案生成输入数据的两个版本，并通过最大化归一化温度缩放交叉熵损失（NT-Xent）来学习低维度表示以识别对应于同一原始实体的增强样本。在本文中，我们研究了将对比学习与图神经网络相结合在图中嵌入节点的潜力。具体而言，我们表明，通过简单的列处理嵌入矩阵，而不是同行处理，可以显著提高结果嵌入的质量和训练时间，而同行处理是大多数同行方法采用的多层感知器（MLPs）。这种修改可提高下游分类任务的性能。

    Contrastive learning has recently established itself as a powerful self-supervised learning framework for extracting rich and versatile data representations. Broadly speaking, contrastive learning relies on a data augmentation scheme to generate two versions of the input data and learns low-dimensional representations by maximizing a normalized temperature-scaled cross entropy loss (NT-Xent) to identify augmented samples corresponding to the same original entity. In this paper, we investigate the potential of deploying contrastive learning in combination with Graph Neural Networks for embedding nodes in a graph. Specifically, we show that the quality of the resulting embeddings and training time can be significantly improved by a simple column-wise postprocessing of the embedding matrix, instead of the row-wise postprocessing via multilayer perceptrons (MLPs) that is adopted by the majority of peer methods. This modification yields improvements in downstream classification tasks of up 
    
[^11]: Consolidator: 融合连接的可合并适配器，用于视觉领域的自适应

    Consolidator: Mergeable Adapter with Grouped Connections for Visual Adaptation. (arXiv:2305.00603v1 [cs.CV])

    [http://arxiv.org/abs/2305.00603](http://arxiv.org/abs/2305.00603)

    本文提出了一种名为 Consolidator 的 mergeable adapter with grouped connections for visual adaptation，促进了视觉 transformer 的知识转移，实现了多个图像分类和对象检测任务的最新转移表现。

    

    近年来，transformer 作为视觉特征提取器表现出超越传统卷积模型的强大能力。然而，视觉 transformer 的成功在很大程度上归功于其容纳大量参数的能力。这导致将大型模型适应下游任务面临新的挑战。为了解决这些问题，本论文提出了一种名为 "Consolidator" 的融合连接的可合并适配器，用于视觉领域的自适应，它促进了视觉 transformer 的知识转移，实现了多个图像分类和对象检测任务的最新转移表现。

    Recently, transformers have shown strong ability as visual feature extractors, surpassing traditional convolution-based models in various scenarios. However, the success of vision transformers largely owes to their capacity to accommodate numerous parameters. As a result, new challenges for adapting large models to downstream tasks arise. On the one hand, classic fine-tuning tunes all parameters in a huge model for every task and thus easily falls into overfitting, leading to inferior performance. On the other hand, on resource-limited devices, fine-tuning stores a full copy of parameters and thus is usually impracticable for the shortage of storage space. However, few works have focused on how to efficiently and effectively transfer knowledge in a vision transformer. Existing methods did not dive into the properties of visual features, leading to inferior performance. Moreover, some of them bring heavy inference cost though benefiting storage. To tackle these problems, we propose cons
    
[^12]: 认知人形机器人的增量程序和感知动作学习

    Incremental procedural and sensorimotor learning in cognitive humanoid robots. (arXiv:2305.00597v1 [cs.RO])

    [http://arxiv.org/abs/2305.00597](http://arxiv.org/abs/2305.00597)

    本文提出了一个基于CONAIM模型的认知代理，能够逐步学习程序，通过增加新功能来解决之前无法解决的任务。在模拟环境中，使用增强学习的单一程序学习机制对人形机器人进行了物体跟踪实验。

    

    自动学习日益复杂动作和行为的能力是自主系统的长期目标。本研究受Jean Piaget感知动作三个子阶段的启发，提出了一种基于CONAIM（意识注意力集成模型）的认知代理，能够逐步学习程序。本文介绍了每个子阶段需要的认知功能以及如何添加新功能来解决代理先前无法解决的任务。在Cognitive Systems Toolkit（CST）模拟环境中，使用基于增强学习的单一程序学习机制对人形机器人进行实验，执行物体跟踪任务。

    The ability to automatically learn movements and behaviors of increasing complexity is a long-term goal in autonomous systems. Indeed, this is a very complex problem that involves understanding how knowledge is acquired and reused by humans as well as proposing mechanisms that allow artificial agents to reuse previous knowledge. Inspired by Jean Piaget's theory's first three sensorimotor substages, this work presents a cognitive agent based on CONAIM (Conscious Attention-Based Integrated Model) that can learn procedures incrementally. Throughout the paper, we show the cognitive functions required in each substage and how adding new functions helps address tasks previously unsolved by the agent. Experiments were conducted with a humanoid robot in a simulated environment modeled with the Cognitive Systems Toolkit (CST) performing an object tracking task. The system is modeled using a single procedural learning mechanism based on Reinforcement Learning. The increasing agent's cognitive co
    
[^13]: GPT-2是如何计算大于符号的？解释预训练语言模型中的数学能力

    How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model. (arXiv:2305.00586v1 [cs.CL])

    [http://arxiv.org/abs/2305.00586](http://arxiv.org/abs/2305.00586)

    本研究运用机械式可解释性技术探究了GPT-2 Small的数学能力，并确定了它的计算图中的一个小电路用于计算大于符号，该电路的多层感知器提高了结束年份大于开始年份的概率，并且该电路具有广泛的适用性。

    

    预训练语言模型在未被明确训练的任务上表现出惊人的能力，但它们如何实现这些功能却不为人所知。本文通过机械式可解释性技术探究预训练语言模型通常具有的基本数学能力。具体来说，我们以GPT-2 Small为例，研究其能否通过输入"战争持续时间是从1732年到17年"，预测出有效的两位数字的截止年份 (大于32年)。我们首先确定了一个电路，即GPT-2 Small计算图的一个小子集，用于计算这个任务的输出，然后我们解释了每个电路组件的作用，显示出GPT-2 Small的最终多层感知器提高了结束年份大于开始年份的概率。最后，我们证明了我们的电路适用于其他任务，在其他大于场景中发挥作用。

    Pre-trained language models can be surprisingly adept at tasks they were not explicitly trained on, but how they implement these capabilities is poorly understood. In this paper, we investigate the basic mathematical abilities often acquired by pre-trained language models. Concretely, we use mechanistic interpretability techniques to explain the (limited) mathematical abilities of GPT-2 small. As a case study, we examine its ability to take in sentences such as "The war lasted from the year 1732 to the year 17", and predict valid two-digit end years (years > 32). We first identify a circuit, a small subset of GPT-2 small's computational graph that computes this task's output. Then, we explain the role of each circuit component, showing that GPT-2 small's final multi-layer perceptrons boost the probability of end years greater than the start year. Finally, we show that our circuit generalizes to other tasks, playing a role in other greater-than scenarios.
    
[^14]: 多模态图转换器用于多模态问答

    Multimodal Graph Transformer for Multimodal Question Answering. (arXiv:2305.00581v1 [cs.CV])

    [http://arxiv.org/abs/2305.00581](http://arxiv.org/abs/2305.00581)

    本文提出了一种新的多模态图转换器，它使用图神经网络将文本和视觉数据的多模态图形信息与vanilla self-attention机制相结合，以增强模型理解结构化输入数据的能力，并在两种具有挑战性的多模态问答基准上取得了性能提升。

    

    尽管Transformer模型在视觉和语言任务中取得了成功，但它们通常只是暗示性地学习庞大的数据，并且不能直接利用结构化输入数据。另一方面，结构化学习方法如图神经网络（GNN）可以整合先前的信息，但与Transformer模型几乎无法竞争。在这项工作中，我们旨在从两个世界中受益，并提出了一种新的多模态图转换器，用于需要在多个模态之间进行推理的问答任务。我们引入了一个涉及图形的即插即用准注意力机制，以将从文本和视觉数据中获取的多模态图形信息并入 vanilla self-attention 中作为有效先验知识。特别地，我们构建文本图、密集区域图和语义图生成邻接矩阵，然后将它们与输入的视觉和语言特征组合以执行下游推理。使用图形信息来规范self-attention机制，增强了模型理解结构化输入数据的能力，并且在两种具有挑战性的多模态问答基准(VQA和GQA)上取得了明显的性能提升。

    Despite the success of Transformer models in vision and language tasks, they often learn knowledge from enormous data implicitly and cannot utilize structured input data directly. On the other hand, structured learning approaches such as graph neural networks (GNNs) that integrate prior information can barely compete with Transformer models. In this work, we aim to benefit from both worlds and propose a novel Multimodal Graph Transformer for question answering tasks that requires performing reasoning across multiple modalities. We introduce a graph-involved plug-and-play quasi-attention mechanism to incorporate multimodal graph information, acquired from text and visual data, to the vanilla self-attention as effective prior. In particular, we construct the text graph, dense region graph, and semantic graph to generate adjacency matrices, and then compose them with input vision and language features to perform downstream reasoning. Such a way of regularizing self-attention with graph in
    
[^15]: 通过离线多目标强化学习扩展帕累托有效决策

    Scaling Pareto-Efficient Decision Making Via Offline Multi-Objective RL. (arXiv:2305.00567v1 [cs.LG])

    [http://arxiv.org/abs/2305.00567](http://arxiv.org/abs/2305.00567)

    本文提出了一种新的数据驱动离线MORL设置和一个用于离线MORL的算法PEDA。PEDA通过在多个模型中选择最优模型来实现正交偏好。实验表明，PEDA在样本效率方面优于现有方法，同时还可扩展到具有更大动作空间的复杂环境中。

    

    多目标强化学习（MORL）的目标是学习能同时优化多个竞争目标的策略。实际应用中，代理对目标的偏好可能不是先验已知的，因此我们需要在测试时能够适应任意偏好的策略。本文提出一种新的数据驱动离线MORL设置，我们希望只使用有限的离线演示数据集来学习一个偏好不敏感的策略代理。本文的两个主要贡献：第一，我们介绍了D4MORL，这是一组专门针对离线设置设计的MORL数据集。它包含180万个数据，是通过在6个MuJoCo环境中优化2-3个目标的参考策略的过程中获得的。第二，我们提出了帕累托有效决策代理（PEDA），它是一族离线MORL算法，通过构建和扩展决策转移（DT）方法来适用于新的MORL设置。 PEDS训练多个模型，每个模型都为不同的、随机选择的目标优化。在测试时，PEDA通过一种基于用户指定偏好的原则来选择模型。我们在六个MuJoCo环境下评估了PEDA的性能，并证明PEDA在样本效率方面优于最先进的MORL方法，并自然地扩展到更复杂的具有较大行动空间的环境中。

    The goal of multi-objective reinforcement learning (MORL) is to learn policies that simultaneously optimize multiple competing objectives. In practice, an agent's preferences over the objectives may not be known apriori, and hence, we require policies that can generalize to arbitrary preferences at test time. In this work, we propose a new data-driven setup for offline MORL, where we wish to learn a preference-agnostic policy agent using only a finite dataset of offline demonstrations of other agents and their preferences. The key contributions of this work are two-fold. First, we introduce D4MORL, (D)atasets for MORL that are specifically designed for offline settings. It contains 1.8 million annotated demonstrations obtained by rolling out reference policies that optimize for randomly sampled preferences on 6 MuJoCo environments with 2-3 objectives each. Second, we propose Pareto-Efficient Decision Agents (PEDA), a family of offline MORL algorithms that builds and extends Decision Tr
    
[^16]: 面向部分可观察环境中复杂任务的自主智能体无模型运动规划

    Model-free Motion Planning of Autonomous Agents for Complex Tasks in Partially Observable Environments. (arXiv:2305.00561v1 [cs.AI])

    [http://arxiv.org/abs/2305.00561](http://arxiv.org/abs/2305.00561)

    本文提出了一种无模型强化学习方法，利用线性时态逻辑和极限确定性广义布氏自动机来解决部分可观察环境下自主智能体复杂任务的运动规划，该方法利用深度Q学习与LSTM增强技术。

    

    在部分已知且信息不完备的环境中，自主智能体的运动规划是一个具有挑战性的问题，尤其是对于复杂任务而言。本文提出了一种无模型强化学习方法来解决这个问题。我们将运动规划建模为一个概率标记的部分可观测马尔可夫决策过程（PL-POMDP）问题，并使用线性时态逻辑（LTL）来表达复杂任务。然后将LTL公式转换为极限确定性广义布氏自动机（LDGBA）。基于模型检测技术，将问题重新定义为在PL-POMDP与LDGBA的乘积上找到最优策略以满足复杂任务。我们实现了深度Q学习与长短时记忆网络（LSTM）来处理观察历史和任务识别。我们的贡献包括提出的方法、LTL和LDGBA的利用以及LSTM增强的深度Q学习。我们通过进行仿真实验展示了所提出方法的适用性。

    Motion planning of autonomous agents in partially known environments with incomplete information is a challenging problem, particularly for complex tasks. This paper proposes a model-free reinforcement learning approach to address this problem. We formulate motion planning as a probabilistic-labeled partially observable Markov decision process (PL-POMDP) problem and use linear temporal logic (LTL) to express the complex task. The LTL formula is then converted to a limit-deterministic generalized B\"uchi automaton (LDGBA). The problem is redefined as finding an optimal policy on the product of PL-POMDP with LDGBA based on model-checking techniques to satisfy the complex task. We implement deep Q learning with long short-term memory (LSTM) to process the observation history and task recognition. Our contributions include the proposed method, the utilization of LTL and LDGBA, and the LSTM-enhanced deep Q learning. We demonstrate the applicability of the proposed method by conducting simul
    
[^17]: Standpoint-OWL 2的自动推理支持

    Automated reasoning support for Standpoint-OWL 2. (arXiv:2305.00559v1 [cs.AI])

    [http://arxiv.org/abs/2305.00559](http://arxiv.org/abs/2305.00559)

    该论文提出了一个用于模拟和处理来自不同立场的知识的工具，通过增强基本逻辑来实现，可以直接用于处理多元立场并提供自动推理支持。

    

    我们提出了一个工具，用于模拟和处理来自不同的立场（可能存在冲突）的知识。理论基础是通过增强基本逻辑来实现的，该逻辑是根据最近引入的形式化方法加入立场的。该工具通过将立场增强版本的描述逻辑SROIQ转换为其普通（即经典）版本来工作。现有的推理器可以直接用于提供处理不同立场的自动化支持。

    We present a tool for modelling and reasoning with knowledge from various diverse (and possibly conflicting) viewpoints. The theoretical underpinnings are provided by enhancing base logics by standpoints according to a recently introduced formalism that we also recall. The tool works by translating the standpoint-enhanced version of the description logic SROIQ to its plain (i.e. classical) version. Existing reasoners can then be directly used to provide automated support for reasoning about diverse standpoints.
    
[^18]: 基于深度学习的时空面部特征可视化语音识别

    Deep Learning-based Spatio Temporal Facial Feature Visual Speech Recognition. (arXiv:2305.00552v1 [cs.CV])

    [http://arxiv.org/abs/2305.00552](http://arxiv.org/abs/2305.00552)

    本研究提出了一种基于深度学习的时空面部特征可视化语音识别认证技术，结合面部识别和个体讲密码时的独特时空面部特征运动，成功在工业标准数据集上达到96.1％的准确率。

    

    在低资源计算环境（如智能手机和其他小型设备）中，深度学习和机器学习被用于许多身份识别系统中作为认证技术。人工智能驱动的这些面部识别技术的透明、非接触和非侵入性质使其近年来在人们中的普及度急剧上升。虽然它们大多都很成功，但仍然存在通过利用图片、面具、眼镜等方式未经许可进入的方法。在本研究中，我们提出了一种替代认证过程，利用了面部识别和个体在讲密码时的独特时空面部特征运动。由于建议的方法允许在任何语言中指定密码，因此不受语言限制。在工业标准MIRACL-VC1数据集上测试时，建议的模型达到了96.1％的准确率，展示了它作为一种可靠而强大的认证技术的有效性。

    In low-resource computing contexts, such as smartphones and other tiny devices, Both deep learning and machine learning are being used in a lot of identification systems. as authentication techniques. The transparent, contactless, and non-invasive nature of these face recognition technologies driven by AI has led to their meteoric rise in popularity in recent years. While they are mostly successful, there are still methods to get inside without permission by utilising things like pictures, masks, glasses, etc. In this research, we present an alternate authentication process that makes use of both facial recognition and the individual's distinctive temporal facial feature motions while they speak a password. Because the suggested methodology allows for a password to be specified in any language, it is not limited by language. The suggested model attained an accuracy of 96.1% when tested on the industry-standard MIRACL-VC1 dataset, demonstrating its efficacy as a reliable and powerful so
    
[^19]: 使用模糊分箱进行校准误差估计

    Calibration Error Estimation Using Fuzzy Binning. (arXiv:2305.00543v1 [cs.LG])

    [http://arxiv.org/abs/2305.00543](http://arxiv.org/abs/2305.00543)

    本文提出了一种模糊校准误差度量（FCE），利用模糊分箱方法计算校准误差，从而缓解了概率偏斜的影响并提供了更紧密的估计值。与传统指标ECE相比，FCE在多类设置中表现更好，https://github.com/srdgFHE/FCE-paper。

    

    基于神经网络的决策往往会过于自信，其原始结果的概率并不符合真实的决策概率。神经网络的校准是实现更可靠的深度学习框架的关键步骤。先前的校准误差度量主要利用清晰的分箱成员资格度量。这加剧了模型概率的偏斜，并描绘了校准误差的不完整图像。在本文中，我们提出了一种利用模糊分箱方法计算校准误差的模糊校准误差度量（FCE）。这种方法缓解了概率偏斜的影响，并在测量校准误差时提供了更紧密的估计值。我们比较了我们的指标与ECE在不同的数据群体和类别成员身份中的表现。我们的结果显示，FCE在校准误差估计方面表现更好，特别是在多类设置中，缓解了模型置信度分数偏斜对校准误差估计的影响。我们提供了我们的代码https://github.com/srdgFHE/FCE-paper，以便未来的可重复性和使用FCE进行校准误差估计。

    Neural network-based decisions tend to be overconfident, where their raw outcome probabilities do not align with the true decision probabilities. Calibration of neural networks is an essential step towards more reliable deep learning frameworks. Prior metrics of calibration error primarily utilize crisp bin membership-based measures. This exacerbates skew in model probabilities and portrays an incomplete picture of calibration error. In this work, we propose a Fuzzy Calibration Error metric (FCE) that utilizes a fuzzy binning approach to calculate calibration error. This approach alleviates the impact of probability skew and provides a tighter estimate while measuring calibration error. We compare our metric with ECE across different data populations and class memberships. Our results show that FCE offers better calibration error estimation, especially in multi-class settings, alleviating the effects of skew in model confidence scores on calibration error estimation. We make our code a
    
[^20]: 学习成就结构来在有稀疏奖励的领域进行结构化探索

    Learning Achievement Structure for Structured Exploration in Domains with Sparse Reward. (arXiv:2305.00508v1 [cs.LG])

    [http://arxiv.org/abs/2305.00508](http://arxiv.org/abs/2305.00508)

    本文提出了SEA算法，可在成就型环境中进行探索任务。SEA首先学习已知成就的表示和依赖关系图，然后通过构建控制器在线探索新成就。实验证明SEA能够准确地恢复成就结构并改善在一些复杂领域中的探索性能。

    

    本文提出了一种名为SEA的多阶段强化学习算法，旨在为基于成就的环境设计，即具有内部成就集的特定类型环境。SEA首先使用离线数据，使用确定性损失函数学习已知成就的表示，然后使用启发式算法恢复学习成就的依赖关系图，最后通过使用恢复的依赖关系图构建控制器，在线与环境交互学习掌握已知成就并探索新成就的策略。我们通过实验证明，SEA可以准确地恢复成就结构，并改善在像图像这样具有高维观察值的大型生成领域（如Crafter）中的探索能力。

    We propose Structured Exploration with Achievements (SEA), a multi-stage reinforcement learning algorithm designed for achievement-based environments, a particular type of environment with an internal achievement set. SEA first uses offline data to learn a representation of the known achievements with a determinant loss function, then recovers the dependency graph of the learned achievements with a heuristic algorithm, and finally interacts with the environment online to learn policies that master known achievements and explore new ones with a controller built with the recovered dependency graph. We empirically demonstrate that SEA can recover the achievement structure accurately and improve exploration in hard domains such as Crafter that are procedurally generated with high-dimensional observations like images.
    
[^21]: 深度强化学习的后验采样

    Posterior Sampling for Deep Reinforcement Learning. (arXiv:2305.00477v1 [cs.LG])

    [http://arxiv.org/abs/2305.00477](http://arxiv.org/abs/2305.00477)

    本文提出了用于深度强化学习的后验采样算法PSDRL，结合了高效的不确定性量化和特殊设计的持续规划算法，使其在提高样本效率的同时显著优于之前的尝试。

    

    尽管深度强化学习算法取得了显著的成功，但样本效率仍然较低：它们需要大量的试错来找到好的策略。基于模型的算法通过构建可以用于规划的环境模型来提高样本效率。后验采样强化学习是这样一种基于模型的算法，在表格设置中由于其性能而引起了广泛的兴趣。本文介绍了用于深度强化学习的后验采样（PSDRL），这是第一个真正可扩展的后验采样强化学习的近似方法，保留了其基于模型的本质特征。PSDRL将潜在状态空间模型上的高效不确定性量化与基于值函数逼近的特殊设计的持续规划算法相结合。对Atari基准测试的广泛实验表明，PSDRL在提高样本效率的同时，显著优于以前的最先进尝试。

    Despite remarkable successes, deep reinforcement learning algorithms remain sample inefficient: they require an enormous amount of trial and error to find good policies. Model-based algorithms promise sample efficiency by building an environment model that can be used for planning. Posterior Sampling for Reinforcement Learning is such a model-based algorithm that has attracted significant interest due to its performance in the tabular setting. This paper introduces Posterior Sampling for Deep Reinforcement Learning (PSDRL), the first truly scalable approximation of Posterior Sampling for Reinforcement Learning that retains its model-based essence. PSDRL combines efficient uncertainty quantification over latent state space models with a specially tailored continual planning algorithm based on value-function approximation. Extensive experiments on the Atari benchmark show that PSDRL significantly outperforms previous state-of-the-art attempts at scaling up posterior sampling while being 
    
[^22]: Causalainer: 自动视频摘要的因果解释器

    Causalainer: Causal Explainer for Automatic Video Summarization. (arXiv:2305.00455v1 [cs.CV])

    [http://arxiv.org/abs/2305.00455](http://arxiv.org/abs/2305.00455)

    Causalainer是一个自动视频摘要的因果解释器，其引入多个有意义的随机变量及其联合分布来描述视频摘要管道中关键组件的行为，可以分析用户指定的干预的因果效应，提高了模型的透明度和可解释性。

    

    视频摘要的目标是自动缩短视频，以传达整个故事而不失去相关信息。在许多应用场景中，不适当的视频摘要可能会产生重大影响。例如，在法医学中，生成的视频摘要的质量将影响调查人员的判断，而在新闻学中可能会产生不希望的偏见。因此，对建模的可解释性是一个关键问题。揭示引导过程并导致结果的因果关系是解决可解释性挑战的最佳方法之一。当前基于机器学习的视频摘要算法学习最佳参数，但不揭示因果关系。因此，它们缺乏相对解释能力。在这项工作中，提出了一种称为Causalainer的因果解释器来解决这个问题。引入多个有意义的随机变量及其联合分布来描述视频摘要管道中关键组件的行为。Causalainer使人们能够分析用户指定的干预的因果效应，并了解视频摘要过程的基本逻辑。实验表明，Causalainer不仅实现了高质量的视频摘要，还提供了有意义的见解，以提高模型的透明度和可解释性。

    The goal of video summarization is to automatically shorten videos such that it conveys the overall story without losing relevant information. In many application scenarios, improper video summarization can have a large impact. For example in forensics, the quality of the generated video summary will affect an investigator's judgment while in journalism it might yield undesired bias. Because of this, modeling explainability is a key concern. One of the best ways to address the explainability challenge is to uncover the causal relations that steer the process and lead to the result. Current machine learning-based video summarization algorithms learn optimal parameters but do not uncover causal relationships. Hence, they suffer from a relative lack of explainability. In this work, a Causal Explainer, dubbed Causalainer, is proposed to address this issue. Multiple meaningful random variables and their joint distributions are introduced to characterize the behaviors of key components in th
    
[^23]: 基于局部任务相似性启发的神经元创建和移除的多任务结构学习

    Multi-Task Structural Learning using Local Task Similarity induced Neuron Creation and Removal. (arXiv:2305.00441v1 [cs.LG])

    [http://arxiv.org/abs/2305.00441](http://arxiv.org/abs/2305.00441)

    本文提出了一种名为“多任务结构学习（MTSL）”的方法，可以同时学习多任务架构及其参数，其主要贡献在于将局部任务相似性纳入神经元创建和移除，从而提高了神经网络的泛化能力。

    

    多任务学习具有通过最大化任务间正向转移来提高泛化能力、减少任务干扰的潜力。然而，手动设计的网络架构在整个训练过程中保持静态，这限制了其发挥潜力。相比之下，大脑中的学习是通过结构性变化和突触强度变化相互作用实现的。因此，我们提出了“多任务结构学习（MTSL）”，它可以同时学习多任务架构及其参数。MTSL从每个任务的相同单任务网络开始，交替进行任务学习和结构学习。在任务学习阶段，每个网络专门处理相应的任务。在每个结构学习阶段中，从最早的层开始，局部相似的任务层首先将其知识传输到新创建的组层，然后再将其删除。然后MTSL在相应的组层中使用它们。

    Multi-task learning has the potential to improve generalization by maximizing positive transfer between tasks while reducing task interference. Fully achieving this potential is hindered by manually designed architectures that remain static throughout training. On the contrary, learning in the brain occurs through structural changes that are in tandem with changes in synaptic strength. Thus, we propose \textit{Multi-Task Structural Learning (MTSL)} that simultaneously learns the multi-task architecture and its parameters. MTSL begins with an identical single-task network for each task and alternates between a task-learning phase and a structural-learning phase. In the task learning phase, each network specializes in the corresponding task. In each of the structural learning phases, starting from the earliest layer, locally similar task layers first transfer their knowledge to a newly created group layer before being removed. MTSL then uses the group layer in place of the corresponding 
    
[^24]: 基于3D CNN分割、迁移学习和Adagrad优化的CHD检测的优化机器学习

    Optimized Machine Learning for CHD Detection using 3D CNN-based Segmentation, Transfer Learning and Adagrad Optimization. (arXiv:2305.00411v1 [cs.CV])

    [http://arxiv.org/abs/2305.00411](http://arxiv.org/abs/2305.00411)

    本文提出了一种基于机器学习和图像处理技术相结合的新框架，用于检测冠心病。该框架包括数据分析、特征选择、基于3D CNN的分割、迁移学习和Adagrad优化。使用该框架可以提高冠心病早期检测和诊断的准确性和效率。

    

    在全球范围内，冠心病是主要死亡原因之一。早期检测和诊断CHD可以提高患者预后和降低死亡率。本文提出了一种结合机器学习和图像处理技术的新框架，用于预测CHD的存在。该框架包括多个阶段，包括数据分析、使用ReliefF进行特征选择、基于3D CNN的分割、迁移学习进行特征提取、特征融合和分类以及Adagrad优化。提出框架的第一步是分析数据，以确定可能与CHD相关的模式和相关性。接下来，应用ReliefF特征选择来确定样本图像中最相关的特征。然后，使用基于3D CNN的分割技术来分割视盘和黄斑，这是CHD诊断的重要区域。使用迁移学习进行特征提取，从分割的图像中提取特征。然后将提取的特征进行融合，并使用支持向量机（SVM）进行分类。最后，使用Adagrad优化来微调SVM参数。

    Globally, Coronary Heart Disease (CHD) is one of the main causes of death. Early detection of CHD can improve patient outcomes and reduce mortality rates. We propose a novel framework for predicting the presence of CHD using a combination of machine learning and image processing techniques. The framework comprises various phases, including analyzing the data, feature selection using ReliefF, 3D CNN-based segmentation, feature extraction by means of transfer learning, feature fusion as well as classification, and Adagrad optimization. The first step of the proposed framework involves analyzing the data to identify patterns and correlations that may be indicative of CHD. Next, ReliefF feature selection is applied to decide on the most relevant features from the sample images. The 3D CNN-based segmentation technique is then used to segment the optic disc and macula, which are important regions for CHD diagnosis. Feature extraction using transfer learning is performed to extract features f
    
[^25]: 从国家漏洞数据库的文本描述中构建知识图谱

    Constructing a Knowledge Graph from Textual Descriptions of Software Vulnerabilities in the National Vulnerability Database. (arXiv:2305.00382v1 [cs.CR])

    [http://arxiv.org/abs/2305.00382](http://arxiv.org/abs/2305.00382)

    本文提出了一种从国家漏洞数据库信息中构建漏洞知识图谱的新方法，结合了命名实体识别、关系提取和实体预测。该方法有助于解决网络安全知识图谱中缺失实体的问题。

    

    知识图谱已经显示出了在多个网络安全领域，例如漏洞评估和威胁分析方面的潜力。在本文中，我们提出了一种从国家漏洞数据库的信息中构建漏洞知识图谱的新方法。我们的方法结合了命名实体识别（NER）、关系提取（RE）、以及使用神经模型、启发式规则和知识图谱嵌入的实体预测。我们演示了我们的方法如何有助于解决网络安全知识图谱中缺失实体的问题，并对其性能进行了评估。

    Knowledge graphs have shown promise for several cybersecurity tasks, such as vulnerability assessment and threat analysis. In this work, we present a new method for constructing a vulnerability knowledge graph from information in the National Vulnerability Database (NVD). Our approach combines named entity recognition (NER), relation extraction (RE), and entity prediction using a combination of neural models, heuristic rules, and knowledge graph embeddings. We demonstrate how our method helps to fix missing entities in knowledge graphs used for cybersecurity and evaluate the performance.
    
[^26]: ReLBOT：一种转移学习方法以最小化智能建筑中强化学习风险

    ReLBOT: A Transfer Learning Approach to Minimize Reinforcement Learning Risks in Smart Buildings. (arXiv:2305.00365v1 [cs.LG])

    [http://arxiv.org/abs/2305.00365](http://arxiv.org/abs/2305.00365)

    ReLBOT使用转移学习和深度RL技术来从现有的智能建筑中传递优化参数到新的建筑中，以减少强化学习代理引起的初始不适，有效降低了风险，并且实现了热身期时长6.2倍的提高和预测方差的132倍提高。

    

    智能建筑旨在通过应用人工智能算法来优化能源消耗。当智能建筑投入使用时，没有历史数据可用于训练这些算法。在线强化学习（RL）算法显示出重要的前景，但它们的部署存在重大风险，因为当RL代理最初探索其行动空间时，它可能会给建筑居民带来重大不适。在本文中，我们提出了一种名为ReLBOT的新技术，它使用转移学习结合深度RL，从现有的优化智能建筑中传递知识到新投入使用的建筑中，以减少强化学习代理的热身期对建筑物的不利影响。我们证明取得了可观的成果，热身期的持续时间可提高6.2倍，并且预测方差可提高132倍。

    Smart buildings aim to optimize energy consumption by applying artificial intelligent algorithms. When a smart building is commissioned there is no historical data that could be used to train these algorithms. On-line Reinforcement Learning (RL) algorithms have shown significant promise, but their deployment carries a significant risk, because as the RL agent initially explores its action space it could cause significant discomfort to the building residents. In this paper we present ReLBOT, a new technique that uses transfer learning in conjunction with deep RL to transfer knowledge from an existing, optimized smart building, to the newly commissioning building, to reduce the adverse impact of the reinforcement learning agent's warm-up period. We demonstrate improvements of up to 6.2 times in the duration, and up to 132 times in prediction variance for the reinforcement learning agent's warm-up period.
    
[^27]: MH-DETR: 基于跨模态 Transformer 的视频片段和精华部分检测

    MH-DETR: Video Moment and Highlight Detection with Cross-modal Transformer. (arXiv:2305.00355v1 [cs.CV])

    [http://arxiv.org/abs/2305.00355](http://arxiv.org/abs/2305.00355)

    该论文提出了面向视频片段和精华部分检测的MH-DETR模型，使用跨模态Transformer来获取时间上对齐的跨模态特征，解决了现有方法中时间内部上下文不足的问题。

    

    随着对视频理解的需求不断增长，视频片段和精华部分检测(MHD)已成为一个关键的研究主题。MHD旨在同时本地化所有时刻并预测剪辑级显著性分数。尽管现有的DETR-based方法取得了进展，我们观察到这些方法粗略地融合了来自不同模态的特征，这削弱了时间内部上下文，并导致跨模态交互不足。为了解决这个问题，我们提出了专门为MHD定制的MH-DETR (Moment and Highlight Detection Transformer)。具体地，我们在单模编码器内引入了一个简单而高效的汇集算子，以捕获全局内模上下文。此外，为了获得时间上对齐的跨模态特征，我们设计了一种插拔式的跨模态交互模块，将视觉和文本特征无缝集成在编码器和解码器之间。在QVHighlights，Charades-STA，Activity-Net和TVSum数据集上的全面实验表明，我们的模型优于现有方法。

    With the increasing demand for video understanding, video moment and highlight detection (MHD) has emerged as a critical research topic. MHD aims to localize all moments and predict clip-wise saliency scores simultaneously. Despite progress made by existing DETR-based methods, we observe that these methods coarsely fuse features from different modalities, which weakens the temporal intra-modal context and results in insufficient cross-modal interaction. To address this issue, we propose MH-DETR (Moment and Highlight Detection Transformer) tailored for MHD. Specifically, we introduce a simple yet efficient pooling operator within the uni-modal encoder to capture global intra-modal context. Moreover, to obtain temporally aligned cross-modal features, we design a plug-and-play cross-modal interaction module between the encoder and decoder, seamlessly integrating visual and textual features. Comprehensive experiments on QVHighlights, Charades-STA, Activity-Net, and TVSum datasets show that
    
[^28]: POUF: 面向提示的无监督大型预训练模型微调

    POUF: Prompt-oriented unsupervised fine-tuning for large pre-trained models. (arXiv:2305.00350v1 [cs.LG])

    [http://arxiv.org/abs/2305.00350](http://arxiv.org/abs/2305.00350)

    本文提出了一种基于提示的无监督微调框架，可以在未标记的目标数据上微调大型预训练模型以适应下游任务，实验结果表明该方法在图像分类、情感分析和自然语言推理等任务中表现更好。

    

    通过提示，大规模预训练模型在近年来变得更加表现出色和强大。虽然这些大型模型具有零-shot 能力，但通常仍需要有标签的数据来适应下游任务。为了克服这个关键限制，我们提出了一种无监督微调框架，直接在未标记的目标数据上微调模型或提示。我们演示如何将该方法应用于语言增强的视觉和掩蔽语言模型，通过对齐从提示和目标数据中提取的离散分布来实现。为了验证我们方法的适用性，我们对图像分类、情感分析和自然语言推理任务进行了广泛的实验。在 13 个与图像相关的任务和 15 个与语言相关的任务中，该方法均比基线表现更好。

    Through prompting, large-scale pre-trained models have become more expressive and powerful, gaining significant attention in recent years. Though these big models have zero-shot capabilities, in general, labeled data are still required to adapt them to downstream tasks. To overcome this critical limitation, we propose an unsupervised fine-tuning framework to directly fine-tune the model or prompt on the unlabeled target data. We demonstrate how to apply our method to both language-augmented vision and masked-language models by aligning the discrete distributions extracted from the prompts and target data. To verify our approach's applicability, we conduct extensive experiments on image classification, sentiment analysis, and natural language inference tasks. Across 13 image-related tasks and 15 language-related ones, the proposed approach achieves consistent improvements over the baselines.
    
[^29]: 在受污染的多模态数据下，用于真实世界监控的视觉-红外人员再识别的融合

    Fusion for Visual-Infrared Person ReID in Real-World Surveillance Using Corrupted Multimodal Data. (arXiv:2305.00320v1 [cs.CV])

    [http://arxiv.org/abs/2305.00320](http://arxiv.org/abs/2305.00320)

    本篇论文提出了一种名为MMSF的模型，能够保留模态特定的知识，提高受污染多模态图像的鲁棒性。同时，还采用了三种最先进的基于注意力的多模态融合模型，在V-I ReID中适应受污染多模态数据，动态平衡每种模态的重要性。

    

    可见光-红外人员再识别(V-I ReID)旨在匹配由分布式RGB和IR摄像机捕获的个体图像。由于V和I模态之间的显著差异，特别是在真实世界的条件下，图像受到模糊、噪声和天气等因素的干扰，该任务变得具有挑战性。事实上，最先进的V-I ReID模型不能利用受污染的模态信息来维持高水平的准确性。在本文中，我们提出了一种高效的多模态V-I ReID模型——名为多模态中间流融合(MMSF)，用于提高受污染多模态图像的鲁棒性，并针对在V-I ReID中出现的受污染多模态数据，适应了三种最先进的基于注意力的多模态融合模型，可动态平衡每种模态的重要性。近期已提出评估协议以评估ReID模型在具有挑战性的真实世界场景下的鲁棒性。

    Visible-infrared person re-identification (V-I ReID) seeks to match images of individuals captured over a distributed network of RGB and IR cameras. The task is challenging due to the significant differences between V and I modalities, especially under real-world conditions, where images are corrupted by, e.g, blur, noise, and weather. Indeed, state-of-art V-I ReID models cannot leverage corrupted modality information to sustain a high level of accuracy. In this paper, we propose an efficient model for multimodal V-I ReID -- named Multimodal Middle Stream Fusion (MMSF) -- that preserves modality-specific knowledge for improved robustness to corrupted multimodal images. In addition, three state-of-art attention-based multimodal fusion models are adapted to address corrupted multimodal data in V-I ReID, allowing to dynamically balance each modality importance. Recently, evaluation protocols have been proposed to assess the robustness of ReID models under challenging real-world scenarios.
    
[^30]: 一种具有典型性的条件逻辑中多层感知器的优先解释

    A preferential interpretation of MultiLayer Perceptrons in a conditional logic with typicality. (arXiv:2305.00304v1 [cs.AI])

    [http://arxiv.org/abs/2305.00304](http://arxiv.org/abs/2305.00304)

    本文探究了缺陷推理的多优选语义和多层神经网络模型之间的关系，并利用提出的多优先语义，对多层感知器(MLPs)进行了优先解释，并验证了其条件属性。

    

    本文研究了知识表示中缺陷推理的多优选语义与多层神经网络模型之间的关系。考虑了一种具有典型性的简单描述逻辑的加权知识库，在“概念层面”的多优先语义下进行。该语义被用来提供多层感知器(MLPs)的优先解释。利用模型检查和蕴含关系的方法验证MLPs的条件属性。

    In this paper we investigate the relationships between a multipreferential semantics for defeasible reasoning in knowledge representation and a multilayer neural network model. Weighted knowledge bases for a simple description logic with typicality are considered under a (many-valued) ``concept-wise" multipreference semantics. The semantics is used to provide a preferential interpretation of MultiLayer Perceptrons (MLPs). A model checking and an entailment based approach are exploited in the verification of conditional properties of MLPs.
    
[^31]: 基于流体动力学优化深度学习方法的视网膜底图像分类改进

    Improving Classification of Retinal Fundus Image Using Flow Dynamics Optimized Deep Learning Methods. (arXiv:2305.00294v1 [cs.CV])

    [http://arxiv.org/abs/2305.00294](http://arxiv.org/abs/2305.00294)

    本论文提出了一种基于流体动力学优化的深度学习方法，用于改进糖尿病视网膜病变的分类。研究人员提出了一种新的 CNN 模型，用于确定底片图像的特征，并使用各种机器学习分类器对其进行评估。

    

    糖尿病视网膜病变 (DR) 是一种损坏视网膜血管网络的障碍，如果糖尿病患者患有这种病，可能会危及他们的视力。使用彩色底片来进行 DR 诊断需要经验丰富的临床医生对影像中的肿瘤进行识别，这可能需要一些时间。自动检测 DR 可能是一项极具挑战性的任务。卷积神经网络 (CNN) 在当前情况下在分类图像方面也是非常有效的，特别是与手工制作和功能方法相比。为了确保高水平的结果，研究人员还提出了一种先进的 CNN 模型，可以确定底片图像的特征。CNN 输出的特征被用于所提出系统的各种机器学习分类器中。这个模型后来使用了不同形式的深度学习方法进行评估。

    Diabetic Retinopathy (DR) refers to a barrier that takes place in diabetes mellitus damaging the blood vessel network present in the retina. This may endanger the subjects' vision if they have diabetes. It can take some time to perform a DR diagnosis using color fundus pictures because experienced clinicians are required to identify the tumors in the imagery used to identify the illness. Automated detection of the DR can be an extremely challenging task. Convolutional Neural Networks (CNN) are also highly effective at classifying images when applied in the present situation, particularly compared to the handmade and functionality methods employed. In order to guarantee high results, the researchers also suggested a cutting-edge CNN model that might determine the characteristics of the fundus images. The features of the CNN output were employed in various classifiers of machine learning for the proposed system. This model was later evaluated using different forms of deep learning method
    
[^32]: 高等教育中生成式人工智能的学生观点：感知、益处和挑战

    Students' Voices on Generative AI: Perceptions, Benefits, and Challenges in Higher Education. (arXiv:2305.00290v1 [cs.CY])

    [http://arxiv.org/abs/2305.00290](http://arxiv.org/abs/2305.00290)

    本研究探讨了大学生对于高等教育中使用生成式人工智能的感知和看法。学生们普遍持积极态度，并认可GenAI提供的个性化学习支持、写作、头脑风暴和研究分析功能，但也存在一些对于准确性、隐私、伦理问题以及对个人发展、职业前景和社会价值的担忧。

    

    本研究探讨了大学生们对于生成式人工智能（GenAI）技术在高等教育中的感知，聚焦于熟悉程度、参与意愿、潜在益处和挑战以及有效整合等方面。一项调查显示，在香港来自不同学科的399名本科生和研究生中，学生们普遍持积极态度，认为GenAI在教学和学习中有潜力提供个性化学习支持、写作和头脑风暴帮助以及研究分析能力。然而，也有人表达了有关准确性、隐私、伦理问题以及对个人发展、职业前景和社会价值的影响的担忧。根据John Biggs的3P模型，学生的感知对学习方法和结果有重要影响。通过理解学生的观点，教育工作者和政策制定者可以量身定制GenAI技术以满足需求和关注点，同时促进有效学习。

    This study explores university students' perceptions of generative AI (GenAI) technologies, such as ChatGPT, in higher education, focusing on familiarity, their willingness to engage, potential benefits and challenges, and effective integration. A survey of 399 undergraduate and postgraduate students from various disciplines in Hong Kong revealed a generally positive attitude towards GenAI in teaching and learning. Students recognized the potential for personalized learning support, writing and brainstorming assistance, and research and analysis capabilities. However, concerns about accuracy, privacy, ethical issues, and the impact on personal development, career prospects, and societal values were also expressed. According to John Biggs' 3P model, student perceptions significantly influence learning approaches and outcomes. By understanding students' perceptions, educators and policymakers can tailor GenAI technologies to address needs and concerns while promoting effective learning o
    
[^33]: 段落任意模型（SAM）遇到玻璃：镜面和透明物体不能被轻松检测

    Segment Anything Model (SAM) Meets Glass: Mirror and Transparent Objects Cannot Be Easily Detected. (arXiv:2305.00278v1 [cs.CV])

    [http://arxiv.org/abs/2305.00278](http://arxiv.org/abs/2305.00278)

    这项工作对段落任意模型（SAM）的能力在玻璃相关的情况下进行了实证评估，发现SAM在镜面和透明物体中往往无法检测玻璃，这引起了在具有各种形式的玻璃的安全关键情况下部署SAM的关注。

    

    Meta AI研究最近发布了SAM（Segment Anything Model），它是在超过10亿个掩模的大量分割数据集上训练的。作为计算机视觉领域的基础模型，SAM在通用物体分割方面的出色性能引起了人们的关注。尽管它在各种零-shot迁移任务中具有强大的能力，但它是否能够在具有挑战性的设置中检测到透明物体仍然未知。在这项工作中，我们对两种与玻璃相关的具有挑战性的情况进行了实证评估：镜面和透明物体。我们发现SAM经常无法检测到两种情况下的玻璃，这引起了在具有各种形式的玻璃的安全关键情况下部署SAM的关注。

    Meta AI Research has recently released SAM (Segment Anything Model) which is trained on a large segmentation dataset of over 1 billion masks. As a foundation model in the field of computer vision, SAM (Segment Anything Model) has gained attention for its impressive performance in generic object segmentation. Despite its strong capability in a wide range of zero-shot transfer tasks, it remains unknown whether SAM can detect things in challenging setups like transparent objects. In this work, we perform an empirical evaluation of two glass-related challenging scenarios: mirror and transparent objects. We found that SAM often fails to detect the glass in both scenarios, which raises concern for deploying the SAM in safety-critical situations that have various forms of glass.
    
[^34]: 带有特殊标记和轮次级别注意力的分层对话理解

    Hierarchical Dialogue Understanding with Special Tokens and Turn-level Attention. (arXiv:2305.00262v1 [cs.CL])

    [http://arxiv.org/abs/2305.00262](http://arxiv.org/abs/2305.00262)

    HiDialog是一种有效的用于对话理解的分层模型，其通过插入特殊标记和提出轮次级别的注意力来建模不同轮次的语义变化，并利用异构图模块来优化所学的嵌入。在对话关系提取，对话情感识别和对话行为分类任务中，HiDialog取得了最先进的性能。

    

    相对于标准文本，机器理解对话更具挑战性，因为每个轮次中语义的动态和意外的变化。为了模拟这种不一致的语义，我们提出了一个简单但有效的分层对话理解模型HiDialog。具体而言，我们首先在对话中插入多个特殊标记，并提出轮次级别的注意力来层次学习轮次嵌入。然后，利用异构图模块来优化所学的嵌入。我们对各种对话理解任务进行评估，包括对话关系提取，对话情感识别和对话行为分类。结果表明，我们简单的方法在以上所有三个任务上都达到了最先进的性能。我们的所有源代码都公开在https://github.com/ShawX825/HiDialog上。

    Compared with standard text, understanding dialogue is more challenging for machines as the dynamic and unexpected semantic changes in each turn. To model such inconsistent semantics, we propose a simple but effective Hierarchical Dialogue Understanding model, HiDialog. Specifically, we first insert multiple special tokens into a dialogue and propose the turn-level attention to learn turn embeddings hierarchically. Then, a heterogeneous graph module is leveraged to polish the learned embeddings. We evaluate our model on various dialogue understanding tasks including dialogue relation extraction, dialogue emotion recognition, and dialogue act classification. Results show that our simple approach achieves state-of-the-art performance on all three tasks above. All our source code is publicly available at https://github.com/ShawX825/HiDialog.
    
[^35]: 一种新型金融时间序列案例表示法在行业分类中的应用

    Industry Classification Using a Novel Financial Time-Series Case Representation. (arXiv:2305.00245v1 [cs.LG])

    [http://arxiv.org/abs/2305.00245](http://arxiv.org/abs/2305.00245)

    本论文提出一种新型金融时间序列案例表示法，可用于行业部门分类任务，通过对股票收益嵌入的表示，显着提高了模型性能。

    

    金融领域已被证明是各种机器学习问题的丰富源泉，包括预测、聚类和分类。研究人员可以访问大量的时间序列数据，即使有较小的性能改进也可以转化为显著的附加价值。在本文中，我们考虑使用基于案例的推理来解决这个领域中的一个重要任务，即使用历史股票收益时间序列数据进行行业部门分类。我们讨论了为什么时间序列数据对于传统的基于案例的推理方法可能具有一些重要的表示挑战，并提出了一种基于股票收益嵌入的新型表示，可以从原始股票收益数据中轻松计算。我们认为这种表示法非常适合于基于案例的推理，并使用一个大规模的公共数据集对我们的方法进行评估，用于行业部门分类任务，展示了实质性的性能提升。

    The financial domain has proven to be a fertile source of challenging machine learning problems across a variety of tasks including prediction, clustering, and classification. Researchers can access an abundance of time-series data and even modest performance improvements can be translated into significant additional value. In this work, we consider the use of case-based reasoning for an important task in this domain, by using historical stock returns time-series data for industry sector classification. We discuss why time-series data can present some significant representational challenges for conventional case-based reasoning approaches, and in response, we propose a novel representation based on stock returns embeddings, which can be readily calculated from raw stock returns data. We argue that this representation is well suited to case-based reasoning and evaluate our approach using a large-scale public dataset for the industry sector classification task, demonstrating substantial 
    
[^36]: ChatGPT在教育、营销、软件工程和医疗保健方面的应用综述：优势、缺陷和研究方向

    A Review of ChatGPT Applications in Education, Marketing, Software Engineering, and Healthcare: Benefits, Drawbacks, and Research Directions. (arXiv:2305.00237v1 [cs.CL])

    [http://arxiv.org/abs/2305.00237](http://arxiv.org/abs/2305.00237)

    本文综述了ChatGPT在教育、营销、软件工程和医疗保健领域的潜在应用、局限性和未来方向，探讨ChatGPT作为一种高级语言交互机器人的研究现状与实践意义。

    

    ChatGPT是一种人工智能语言模型，使用深度学习算法生成类似于人类对文本提示的回复。最新的ChatGPT版本于2022年11月推出，其强大的功能、大量的可能应用以及滥用的可能性在产业和学术界引起了轰动。在撰写本文时，其他几个语言模型（例如Google Bard和Meta LLaMA）也刚刚推出，试图在庞大的潜在市场中占据一席之地。这些模型具有革命性的能力，可以应用于很多领域，包括教育、软件工程、医疗保健和营销。本文将讨论在每个领域使用先进语言交互机器人（例如ChatGPT）的可能应用、缺陷和研究方向。我们首先简要介绍了ChatGPT的发展时间线。

    ChatGPT is a type of artificial intelligence language model that uses deep learning algorithms to generate human-like responses to text-based prompts. The introduction of the latest ChatGPT version in November of 2022 has caused shockwaves in the industrial and academic communities for its powerful capabilities, plethora of possible applications, and the great possibility for abuse. At the time of writing this work, several other language models (e.g., Google Bard and Meta LLaMA) just came out in an attempt to get a foothold in the vast possible market. These models have the ability to revolutionize the way we interact with computers and have potential applications in many fields, including education, software engineering, healthcare, and marketing. In this paper, we will discuss the possible applications, drawbacks, and research directions using advanced language Chatbots (e.g., ChatGPT) in each of these fields. We first start with a brief introduction and the development timeline of 
    
[^37]: 以最佳实践为指导的机器学习

    Towards machine learning guided by best practices. (arXiv:2305.00233v1 [cs.SE])

    [http://arxiv.org/abs/2305.00233](http://arxiv.org/abs/2305.00233)

    机器学习在多个领域的软件系统中得到广泛应用，但存在一些特殊的挑战和陷阱，研究显示ML使能系统具有不同于传统软件工程的开发过程。

    

    如今，机器学习（ML）在多个领域中的软件系统中得到了广泛应用，从医学到软件工程（SE）。一方面，ML在工业中的流行可以从显示其增长和采用的统计数据中看到。另一方面，它的受欢迎程度也可以从研究中看到，尤其是在SE中，不仅在SE会议和期刊上发表了多项研究成果，还在软件工程会议中多个研讨会和共同举办的会议上发表了研究成果。同时，研究人员和实践者已经表明机器学习存在一些特殊的挑战和陷阱。特别是，研究表明，与传统的SE相比，ML使能系统具有不同的开发过程，这也描述了ML应用遇到的一些挑战。

    Nowadays, machine learning (ML) is being used in software systems with multiple application fields, from medicine to software engineering (SE). On the one hand, the popularity of ML in the industry can be seen in the statistics showing its growth and adoption. On the other hand, its popularity can also be seen in research, particularly in SE, where not only have multiple studies been published in SE conferences and journals but also in the multiple workshops and co-located conferences in software engineering conferences. At the same time, researchers and practitioners have shown that machine learning has some particular challenges and pitfalls. In particular, research has shown that ML-enabled systems have a different development process than traditional SE, which also describes some of the challenges of ML applications. In order to mitigate some of the identified challenges and pitfalls, white and gray literature has proposed a set of recommendations based on their own experiences and
    
[^38]: 整数线性规划的局部搜索方法

    Local Search for Integer Linear Programming. (arXiv:2305.00188v1 [math.OC])

    [http://arxiv.org/abs/2305.00188](http://arxiv.org/abs/2305.00188)

    本论文开发了一个独立的局部搜索求解器，可用于解决一般整数线性规划，并在大型异构问题数据集上进行了验证。在搜索、改进和还原模式下，分别提出了可自适应修改变量值的算子和高效的举升算子，从而提高当前解的质量。实验表明，该方法在MIPLIB2017的异构问题集上表现优异。

    

    整数线性规划模型适用于各种实际的组合优化问题，对于产业和管理部门具有重要影响。本论文开发了第一个独立的局部搜索求解器，可用于解决一般整数线性规划，并在大型异构问题数据集上进行了验证。我们提出一个局部搜索框架，切换三种模式，分别为搜索，改进和还原模式，并设计适应不同模式的定制算子，从而根据不同情况提高当前解的质量。对于搜索和还原模式，我们提出了一种名为“紧身动作”的算子，它可以自适应地修改变量的值，试图使某些约束变得更紧。对于改进模式，提出了一种高效的算子“举升动作”，可以在保持可行性的同时提高目标函数的质量。结合这些内容，我们开发了一个局部搜索整数线性规划求解器，称为Local-ILP。对MIPLIB2017的异构问题集进行的实验表明，Local-ILP表现优异，可以与最先进的整数线性规划求解器相竞争。

    Integer linear programming models a wide range of practical combinatorial optimization problems and has significant impacts in industry and management sectors. This work develops the first standalone local search solver for general integer linear programming validated on a large heterogeneous problem dataset. We propose a local search framework that switches in three modes, namely Search, Improve, and Restore modes, and design tailored operators adapted to different modes, thus improve the quality of the current solution according to different situations. For the Search and Restore modes, we propose an operator named tight move, which adaptively modifies variables' values trying to make some constraint tight. For the Improve mode, an efficient operator lift move is proposed to improve the quality of the objective function while maintaining feasibility. Putting these together, we develop a local search solver for integer linear programming called Local-ILP. Experiments conducted on the 
    
[^39]: 一种基于广义学习系统的证据实时多模态故障诊断方法

    An Evidential Real-Time Multi-Mode Fault Diagnosis Approach Based on Broad Learning System. (arXiv:2305.00169v1 [cs.LG])

    [http://arxiv.org/abs/2305.00169](http://arxiv.org/abs/2305.00169)

    本文提出了一种基于证据推理算法和广义学习系统的实时多模态故障诊断方法，该方法在更新模型参数和计算效率方面具有优势，并且在基准数据集上取得了比现有方法更好的故障诊断性能。

    

    由于多种工况表现出的非高斯、多模态和中心漂移特征，故障诊断是工业界研究的重要领域。目前，数据驱动方法是该领域的主要研究方向，但它们在连续故障分类和故障分类器参数更新方面提出了挑战，尤其在多种操作模式和实时环境中。因此，实现工业系统的实时多模态故障诊断是一个迫切的问题。为了解决这个问题，本文提出了一种新的方法，利用证据推理（ER）算法来融合信息并合并来自不同基分类器的输出。这些基分类器使用广义学习系统（BLS）开发，以提高良好的故障诊断性能。此外，在这种方法中，采用伪标签学习方法来实时更新模型参数。为了证明所提出方法的有效性，我们在基准数据集上进行实验并与现有方法进行比较。结果表明，我们提出的方法在准确性和计算效率方面优于现有方法。

    Fault diagnosis is a crucial area of research in the industry due to diverse operating conditions that exhibit non-Gaussian, multi-mode, and center-drift characteristics. Currently, data-driven approaches are the main focus in the field, but they pose challenges for continuous fault classification and parameter updates of fault classifiers, particularly in multiple operating modes and real-time settings. Therefore, a pressing issue is to achieve real-time multi-mode fault diagnosis for industrial systems. To address this problem, this paper proposes a novel approach that utilizes an evidence reasoning (ER) algorithm to fuse information and merge outputs from different base classifiers. These base classifiers are developed using a broad learning system (BLS) to improve good fault diagnosis performance. Moreover, in this approach, the pseudo-label learning method is employed to update model parameters in real-time. To demonstrate the effectiveness of the proposed approach, we perform exp
    
[^40]: 提供最佳支持环境优化人工智能开发过程

    Optimizing the AI Development Process by Providing the Best Support Environment. (arXiv:2305.00136v1 [cs.SE])

    [http://arxiv.org/abs/2305.00136](http://arxiv.org/abs/2305.00136)

    本研究旨在提供人工智能（AI）和机器学习（ML）应用的最佳支持环境，具体重点研究了ML开发中数据管理阶段的障碍以及如何构建和开发一个框架，利用多种数据增强技术来解决数据管理阶段缺乏足够数据的问题。

    

    本研究旨在调查人工智能（AI）和机器学习（ML）应用的开发过程，以提供最佳支持环境。ML的主要阶段包括问题理解，数据管理，模型构建，模型部署和维护。本项目重点研究了ML开发的数据管理阶段及其障碍，因为最终模型的准确性取决于输入到模型中的数据类型。发现这一阶段最大的障碍是缺乏足够的模型学习数据，尤其是在数据保密领域。本项目旨在构建和开发一个框架，帮助解决数据管理阶段缺乏足够数据的问题。该框架利用多种数据增强技术，可以从原始数据集中生成新数据。

    The purpose of this study is to investigate the development process for Artificial inelegance (AI) and machine learning (ML) applications in order to provide the best support environment. The main stages of ML are problem understanding, data management, model building, model deployment and maintenance. This project focuses on investigating the data management stage of ML development and its obstacles as it is the most important stage of machine learning development because the accuracy of the end model is relying on the kind of data fed into the model. The biggest obstacle found on this stage was the lack of sufficient data for model learning, especially in the fields where data is confidential. This project aimed to build and develop a framework for researchers and developers that can help solve the lack of sufficient data during data management stage. The framework utilizes several data augmentation techniques that can be used to generate new data from the original dataset which can 
    
[^41]: 基于深度强化学习的物联网驱动智能孤网微电网的最优调度

    Optimal Scheduling in IoT-Driven Smart Isolated Microgrids Based on Deep Reinforcement Learning. (arXiv:2305.00127v1 [cs.LG])

    [http://arxiv.org/abs/2305.00127](http://arxiv.org/abs/2305.00127)

    本文使用深度强化学习解决物联网驱动智能孤网微电网中柴油发电机组的调度问题，通过学习历史数据生成实时决策以确保供需平衡，并减少操作成本。

    

    本文研究了在物联网驱动的孤立微电网中，如何通过深度强化学习来进行柴油发电机组的调度问题。在可再生能源和负载需求不确定性下，充分利用可再生能源。通过学习并建立历史可再生资源和负载数据的最优策略模型，以便从先前小时内相应传感器接收到的过去可再生能源和负载数据的观测中生成实时决策。目标在于确保供需平衡的前提下减少操作成本。具体来说，我们构建了一个新的有限视界下马当前过程模型（POMDP），其中考虑了旋转备用。为了克服由于二进制发电机组开关决策和连续辐射（ED）决策的离散-连续混合作用空间的挑战，提出了一种混合动作有限视角RDPG（HAFH-RDPG）的DRL算法。

    In this paper, we investigate the scheduling issue of diesel generators (DGs) in an Internet of Things (IoT)-Driven isolated microgrid (MG) by deep reinforcement learning (DRL). The renewable energy is fully exploited under the uncertainty of renewable generation and load demand. The DRL agent learns an optimal policy from history renewable and load data of previous days, where the policy can generate real-time decisions based on observations of past renewable and load data of previous hours collected by connected sensors. The goal is to reduce operating cost on the premise of ensuring supply-demand balance. In specific, a novel finite-horizon partial observable Markov decision process (POMDP) model is conceived considering the spinning reserve. In order to overcome the challenge of discrete-continuous hybrid action space due to the binary DG switching decision and continuous energy dispatch (ED) decision, a DRL algorithm, namely the hybrid action finite-horizon RDPG (HAFH-RDPG), is pr
    
[^42]: 探索Segment Anything Model (SAM)在2D医学影像中的零样本能力：全面评估和实用指南

    Exploring the Zero-Shot Capabilities of the Segment Anything Model (SAM) in 2D Medical Imaging: A Comprehensive Evaluation and Practical Guideline. (arXiv:2305.00109v1 [cs.CV])

    [http://arxiv.org/abs/2305.00109](http://arxiv.org/abs/2305.00109)

    本文探索了Segment Anything Model (SAM)在医学影像中的零样本能力，并通过八种不同的提示策略在六个数据集上进行评估，结果表明其性能比当前最先进技术有所提升。

    

    医学影像中的分割在诊断、监测和治疗各种疾病和病况中起着至关重要的作用。目前，医学领域中的分割模型被众多专门针对每个分割任务和图像模态进行微调的深度学习模型占据了主导地位。最近引入了一种新的分割模型Segment Anything Model (SAM)，它利用ViT神经体系结构和广泛的训练数据集来分割几乎任何对象。然而，它在医学领域的泛化能力尚未被探索。在这项研究中，我们使用八种不同的提示策略在四种影像模态的六个数据集上评估了SAM在医学影像中的零样本能力。我们的结果表明，SAM的零样本性能与当前的最先进技术相当，在某些情况下甚至更好。基于我们的发现，我们提出了一个实用指南，需要使用较小的镜像和更多的样本来进一步提高模型性能。

    Segmentation in medical imaging plays a crucial role in diagnosing, monitoring, and treating various diseases and conditions. The current landscape of segmentation in the medical domain is dominated by numerous specialized deep learning models fine-tuned for each segmentation task and image modality. Recently, the Segment Anything Model (SAM), a new segmentation model, was introduced. SAM utilizes the ViT neural architecture and leverages a vast training dataset to segment almost any object. However, its generalizability to the medical domain remains unexplored. In this study, we assess the zero-shot capabilities of SAM 2D in medical imaging using eight different prompt strategies across six datasets from four imaging modalities: X-ray, ultrasound, dermatoscopy, and colonoscopy. Our results demonstrate that SAM's zero-shot performance is comparable and, in certain cases, superior to the current state-of-the-art. Based on our findings, we propose a practical guideline that requires mini
    
[^43]: 通过接触改进可微物理模拟的梯度计算

    Improving Gradient Computation for Differentiable Physics Simulation with Contacts. (arXiv:2305.00092v1 [cs.LG])

    [http://arxiv.org/abs/2305.00092](http://arxiv.org/abs/2305.00092)

    本文研究了接触情况下的可微分刚体模拟，发现现有的方法在接触法线方向不固定时会提供不准确的梯度，提出了一种通过连续的碰撞检测和利用碰撞时间来计算碰撞后的速度来改进梯度计算的方法TOI-Velocity。

    

    可微分模拟使梯度能够反向传播到物理模拟中。通过基于梯度的优化，可以学习物理系统的动态和属性，或者将整个可微分模拟嵌入到深度学习模型中作为下游任务（如规划和控制）的一层。然而，目前的可微分模拟并不完善，可能会提供错误的梯度，从而在学习任务中降低其性能。在本文中，我们研究接触情况下的可微分刚体模拟。我们发现，当接触法线方向不固定时，现有的可微分模拟方法会提供不准确的梯度——这是当接触是两个移动物体之间发生时的一般情况。我们提出通过连续的碰撞检测和利用碰撞时间（TOI）来计算碰撞后的速度，从而改进梯度计算。我们在两个具有联系的刚体系统上演示了我们提出的方法TOI-Velocity。

    Differentiable simulation enables gradients to be back-propagated through physics simulations. In this way, one can learn the dynamics and properties of a physics system by gradient-based optimization or embed the whole differentiable simulation as a layer in a deep learning model for downstream tasks, such as planning and control. However, differentiable simulation at its current stage is not perfect and might provide wrong gradients that deteriorate its performance in learning tasks. In this paper, we study differentiable rigid-body simulation with contacts. We find that existing differentiable simulation methods provide inaccurate gradients when the contact normal direction is not fixed - a general situation when the contacts are between two moving objects. We propose to improve gradient computation by continuous collision detection and leverage the time-of-impact (TOI) to calculate the post-collision velocities. We demonstrate our proposed method, referred to as TOI-Velocity, on tw
    
[^44]: 利用鱼眼数据中的畸变-语义相互作用

    Exploiting the Distortion-Semantic Interaction in Fisheye Data. (arXiv:2305.00079v1 [cs.CV])

    [http://arxiv.org/abs/2305.00079](http://arxiv.org/abs/2305.00079)

    本文利用畸变-语义交互作用提出了一种方法，该方法通过提取畸变类别标签，并使用加权对比损失塑造主干网络的表征空间，以限制每个物体的表征和相应的畸变类别的关系。

    

    本文提出了一种方法来塑造反映鱼眼数据特定表征空间的方法，该空间反映了此类数据中存在的畸变和语义上下文之间的交互作用。虽然之前的工作试图通过架构和训练增强来缓解这种影响，但还没有任何工作尝试引导模型学习反映固有于鱼眼数据的畸变和语义上下文之间的相互作用的表征空间。本文提出了一种方法来利用这种关系，通过首先基于物体距图像中心的距离提取畸变类别标签。然后我们使用加权对比损失来塑造主干网络的表征空间，以限制每个物体的表征和相应的畸变类别的关系。

    In this work, we present a methodology to shape a fisheye-specific representation space that reflects the interaction between distortion and semantic context present in this data modality. Fisheye data has the wider field of view advantage over other types of cameras, but this comes at the expense of high radial distortion. As a result, objects further from the center exhibit deformations that make it difficult for a model to identify their semantic context. While previous work has attempted architectural and training augmentation changes to alleviate this effect, no work has attempted to guide the model towards learning a representation space that reflects this interaction between distortion and semantic context inherent to fisheye data. We introduce an approach to exploit this relationship by first extracting distortion class labels based on an object's distance from the center of the image. We then shape a backbone's representation space with a weighted contrastive loss that constra
    
[^45]: 在线Platt缩放及其校准方法

    Online Platt Scaling with Calibeating. (arXiv:2305.00070v1 [cs.LG])

    [http://arxiv.org/abs/2305.00070](http://arxiv.org/abs/2305.00070)

    本文提出了一种在线Platt缩放及其校准方法，其理论基础强大，可以处理分布漂移和对抗性结果序列，无需超参数调整，在一系列合成和真实数据集上表现出卓越的性能。

    

    我们提出了一种在线后校准方法，称为在线Platt缩放(OPS)，它将Platt缩放技术与在线逻辑回归相结合。我们展示了OPS如何在分布漂移的i.i.d.和非i.i.d.情况下平稳适应。此外，当最佳的Platt缩放模型本身被错误校准时，我们使用一种最近开发的称为calibeating的技术来增强OPS，使其更加鲁棒。理论上，我们得到的OPS+calibeating方法对于对抗性结果序列是保证校准的。在实验上，它在一系列合成和真实数据集上均表现出卓越的性能，无需超参数调整。最后，我们将所有OPS思想扩展到beta缩放方法。

    We present an online post-hoc calibration method, called Online Platt Scaling (OPS), which combines the Platt scaling technique with online logistic regression. We demonstrate that OPS smoothly adapts between i.i.d. and non-i.i.d. settings with distribution drift. Further, in scenarios where the best Platt scaling model is itself miscalibrated, we enhance OPS by incorporating a recently developed technique called calibeating to make it more robust. Theoretically, our resulting OPS+calibeating method is guaranteed to be calibrated for adversarial outcome sequences. Empirically, it is effective on a range of synthetic and real-world datasets, with and without distribution drifts, achieving superior performance without hyperparameter tuning. Finally, we extend all OPS ideas to the beta scaling method.
    
[^46]: 基于逻辑的相似性

    Logic-based similarity. (arXiv:2305.00065v1 [cs.LO])

    [http://arxiv.org/abs/2305.00065](http://arxiv.org/abs/2305.00065)

    本文提出了一种基于逻辑的“定性”相似性概念，通过类型理论作为中心思想和一阶逻辑的基本概念进行了构建。

    

    本文从一阶逻辑的基本概念出发，以类型理论为中心，从零开始发展了一种基于逻辑的“定性”相似性概念。

    This paper develops a {\em qualitative} and logic-based notion of similarity from the ground up using only elementary concepts of first-order logic centered around the fundamental model-theoretic notion of type.
    
[^47]: 可解释的语言推理增强器：支持各种组合推理的自然语言推理框架

    Explainable Verbal Reasoner Plus (EVR+): A Natural Language Reasoning Framework that Supports Diverse Compositional Reasoning. (arXiv:2305.00061v1 [cs.CL])

    [http://arxiv.org/abs/2305.00061](http://arxiv.org/abs/2305.00061)

    EVR+是一种语言推理框架，通过允许生成和执行符号运算符以及将复杂任务分解为多个简单任务等方式增强了语言模型的组合推理能力。它支持更多种类的推理，例如嵌套循环和不同类型的递归。

    

    自然语言模型已成功应用于各种自然语言处理推理任务，但仍然面临组合推理泛化问题。本文提出了一种名为“可解释的语言推理增强器（EVR+）”的推理框架，通过以下方式增强语言模型的组合推理能力：（1）允许模型明确生成和执行符号运算符，（2）以灵活的方式将复杂任务分解为多个简单任务。与其前身Explainable Verbal Reasoner (EVR)和采用类似思路的其他方法相比，我们的框架支持更多种类的推理，例如嵌套循环和不同类型的递归。为了评估我们的推理框架，我们构建了一个合成数据集，其中包括需要组合推理的5个任务。结果表明，我们的推理框架可以提高语言模型在这5个任务中的组合推理性能。

    Languages models have been successfully applied to a variety of reasoning tasks in NLP, yet the language models still suffer from compositional generalization. In this paper we present Explainable Verbal Reasoner Plus (EVR+), a reasoning framework that enhances language models' compositional reasoning ability by (1) allowing the model to explicitly generate and execute symbolic operators, and (2) allowing the model to decompose a complex task into several simpler ones in a flexible manner. Compared with its predecessor Explainable Verbal Reasoner (EVR) and other previous approaches adopting similar ideas, our framework supports more diverse types of reasoning such as nested loops and different types of recursion. To evaluate our reasoning framework, we build a synthetic dataset with five tasks that require compositional reasoning. Results show that our reasoning framework can enhance the language model's compositional generalization performance on the five tasks, using a fine-tuned lan
    
[^48]: LAVA: 无需预定学习算法的数据价值评估

    LAVA: Data Valuation without Pre-Specified Learning Algorithms. (arXiv:2305.00054v1 [cs.LG])

    [http://arxiv.org/abs/2305.00054](http://arxiv.org/abs/2305.00054)

    LAVA是一个学习算法无关的数据价值评估方法，它结合了学习算法的统计特性和训练数据的属性，通过迭代估计数据值来实现。LAVA比现有方法计算速度更快，精度更高，并且可以为不同的应用提供有意义的数据排名。

    

    传统的数据价值评估问题是如何公平地分配学习算法的验证性能，致使计算得到的数据价值依赖于底层学习算法的许多设计选择。本文提出了一种新的框架LAVA，该框架结合了学习算法的统计特性和训练数据的属性，迭代估计数据值，使其无视下游的学习算法。我们展示了LAVA比现有方法计算速度更快，精度更高，并且它可以为不同的应用提供有意义的数据排名。

    Traditionally, data valuation is posed as a problem of equitably splitting the validation performance of a learning algorithm among the training data. As a result, the calculated data values depend on many design choices of the underlying learning algorithm. However, this dependence is undesirable for many use cases of data valuation, such as setting priorities over different data sources in a data acquisition process and informing pricing mechanisms in a data marketplace. In these scenarios, data needs to be valued before the actual analysis and the choice of the learning algorithm is still undetermined then. Another side-effect of the dependence is that to assess the value of individual points, one needs to re-run the learning algorithm with and without a point, which incurs a large computation burden.  This work leapfrogs over the current limits of data valuation methods by introducing a new framework that can value training data in a way that is oblivious to the downstream learning
    
[^49]: 因果推理与大型语言模型：开启因果研究的新篇章

    Causal Reasoning and Large Language Models: Opening a New Frontier for Causality. (arXiv:2305.00050v1 [cs.AI])

    [http://arxiv.org/abs/2305.00050](http://arxiv.org/abs/2305.00050)

    大型语言模型在因果推理任务中取得了新的最高准确率，但是其鲁棒性仍然存在难以预测的失败模式。

    

    大型语言模型的因果能力备受争议，并且对将其应用于医学、科学、法律和政策等具有社会影响力的领域具有重要意义。我们进一步探讨了LLMs及其因果推理的区别，以及潜在的建构和测量效度威胁。基于GPT-3.5和4的算法在多个因果基准测试上取得了新的最高准确率。与此同时，LLMs展示了难以预测的失败模式，我们提供了一些技术来解释它们的鲁棒性。

    The causal capabilities of large language models (LLMs) is a matter of significant debate, with critical implications for the use of LLMs in societally impactful domains such as medicine, science, law, and policy. We further our understanding of LLMs and their causal implications, considering the distinctions between different types of causal reasoning tasks, as well as the entangled threats of construct and measurement validity. LLM-based methods establish new state-of-the-art accuracies on multiple causal benchmarks. Algorithms based on GPT-3.5 and 4 outperform existing algorithms on a pairwise causal discovery task (97%, 13 points gain), counterfactual reasoning task (92%, 20 points gain), and actual causality (86% accuracy in determining necessary and sufficient causes in vignettes). At the same time, LLMs exhibit unpredictable failure modes and we provide some techniques to interpret their robustness.  Crucially, LLMs perform these causal tasks while relying on sources of knowledg
    
[^50]: 一种基于深度学习技术的肺癌诊断自动化端到端框架，用于检测和分类肺部结节

    An automated end-to-end deep learning-based framework for lung cancer diagnosis by detecting and classifying the lung nodules. (arXiv:2305.00046v1 [eess.IV])

    [http://arxiv.org/abs/2305.00046](http://arxiv.org/abs/2305.00046)

    本文提出了一种基于深度学习的智能诊断框架，针对低资源环境实现早期检测和分类肺部结节，并在公共数据集上取得了较好的表现。

    

    肺癌是全球癌症相关死亡的主要原因，在低资源环境中早期诊断对于改善患者疗效至关重要。本研究的目的是提出一种基于深度学习技术的自动化端到端框架，用于早期检测和分类肺部结节，特别是针对低资源环境。该框架由三个阶段组成：使用改进的3D Res-U-Net进行肺分割、使用YOLO-v5进行结节检测、使用基于Vision Transformer的架构进行分类。我们在开放的数据集LUNA16上对该框架进行了评估。所提出的框架的性能是使用各领域的评估指标进行衡量的。该框架在肺部分割dice系数上达到了98.82％，同时检测肺结节的平均准确度为0.76 mAP。

    Lung cancer is a leading cause of cancer-related deaths worldwide, and early detection is crucial for improving patient outcomes. Nevertheless, early diagnosis of cancer is a major challenge, particularly in low-resource settings where access to medical resources and trained radiologists is limited. The objective of this study is to propose an automated end-to-end deep learning-based framework for the early detection and classification of lung nodules, specifically for low-resource settings. The proposed framework consists of three stages: lung segmentation using a modified 3D U-Net named 3D Res-U-Net, nodule detection using YOLO-v5, and classification with a Vision Transformer-based architecture. We evaluated the proposed framework on a publicly available dataset, LUNA16. The proposed framework's performance was measured using the respective domain's evaluation matrices. The proposed framework achieved a 98.82% lung segmentation dice score while detecting the lung nodule with 0.76 mAP
    
[^51]: SAM在医学图像上：三种提示模式的全面研究

    SAM on Medical Images: A Comprehensive Study on Three Prompt Modes. (arXiv:2305.00035v1 [cs.CV])

    [http://arxiv.org/abs/2305.00035](http://arxiv.org/abs/2305.00035)

    SAM是第一种可提示的基础分割模型，在医学图像中表现出竞争力，具有强大的零样本泛化能力，提示模式对其表现影响显著。

    

    Segment Anything Model（SAM）最近引起了研究者们的关注，并启发了他们探索它在零样本泛化能力方面的潜力和限制。作为第一个用于分割任务的可提示基础模型，它在一组具有前所未有数量的图像和注释的大型数据集上进行了训练。这个大规模的数据集及其可提示的性质使得该模型具有强大的零样本泛化能力。虽然SAM在几个数据集上表现出竞争力，但我们仍希望探究它在医学图像上的零样本泛化能力。因为我们知道，医学图像的标注获取通常需要专业从业者付出很大的努力。因此，如果存在一个可以仅基于少数点提示就能给出高质量掩模预测的基础模型，那么这个模型毫无疑问将成为医学图像分析的游戏改变者。为了评估SAM成为医学图像分割基础模型的潜力，我们全面研究了其在两个公开数据集（BraTS和LiTS）上的三种提示模式下的表现。我们的实验表明，SAM的性能与专门设计用于医学图像的最先进方法相似甚至更好。此外，提示模式显著影响模型的表现，我们提供了这些差异的原因的洞察。

    The Segment Anything Model (SAM) made an eye-catching debut recently and inspired many researchers to explore its potential and limitation in terms of zero-shot generalization capability. As the first promptable foundation model for segmentation tasks, it was trained on a large dataset with an unprecedented number of images and annotations. This large-scale dataset and its promptable nature endow the model with strong zero-shot generalization. Although the SAM has shown competitive performance on several datasets, we still want to investigate its zero-shot generalization on medical images. As we know, the acquisition of medical image annotation usually requires a lot of effort from professional practitioners. Therefore, if there exists a foundation model that can give high-quality mask prediction simply based on a few point prompts, this model will undoubtedly become the game changer for medical image analysis. To evaluate whether SAM has the potential to become the foundation model fo
    
[^52]: TorchBench: 用高API表面覆盖率评估PyTorch性能的基准套件

    TorchBench: Benchmarking PyTorch with High API Surface Coverage. (arXiv:2304.14226v1 [cs.LG])

    [http://arxiv.org/abs/2304.14226](http://arxiv.org/abs/2304.14226)

    TorchBench是一款新型基准测试套件，可全面表征PyTorch软件栈的性能，指导模型、PyTorch框架和GPU库的性能优化。

    

    深度学习是多个领域中的革命性技术。为了方便模型的开发和部署，提出了许多深度学习框架，其中PyTorch是最流行的解决方案之一。PyTorch软件栈的生态性能至关重要，可节省模型训练成本并减少模型推理的响应时间。本文提出了TorchBench，一款新型基准测试套件，用于研究PyTorch软件栈的性能。与现有基准测试套件不同，TorchBench包含了许多代表性模型，覆盖了大量PyTorch API表面。TorchBench能够全面地表征PyTorch软件栈的性能，指导模型、PyTorch框架和GPU库的性能优化。我们展示了TorchBench的两个实际用例。第一，我们对TorchBench进行性能剖析，以识别PyTorch的GPU性能效率问题。我们能够优化许多性能故障并向上游提交贡献。

    Deep learning (DL) has been a revolutionary technique in various domains. To facilitate the model development and deployment, many deep learning frameworks are proposed, among which PyTorch is one of the most popular solutions. The performance of ecosystem around PyTorch is critically important, which saves the costs of training models and reduces the response time of model inferences. In this paper, we propose TorchBench, a novel benchmark suite to study the performance of PyTorch software stack. Unlike existing benchmark suites, TorchBench encloses many representative models, covering a large PyTorch API surface. TorchBench is able to comprehensively characterize the performance of the PyTorch software stack, guiding the performance optimization across models, PyTorch framework, and GPU libraries. We show two practical use cases of TorchBench. (1) We profile TorchBench to identify GPU performance inefficiencies in PyTorch. We are able to optimize many performance bugs and upstream pa
    
[^53]: Ensoul: 通过进化的enerstatic网络创建自组织智能超低功耗系统(SOULS)的框架

    Ensoul: A framework for the creation of self organizing intelligent ultra low power systems (SOULS) through evolutionary enerstatic networks. (arXiv:2304.13863v1 [cs.AI])

    [http://arxiv.org/abs/2304.13863](http://arxiv.org/abs/2304.13863)

    Ensoul是一种框架，通过enerstatic网络和开放进化技术结合，创造了能够独立于其嵌入的基质的自组织智能超低功耗系统(SOULS)。

    

    Ensoul是一个提出的框架，旨在通过能量稳态(enerstatic)回路和开放式进化技术的网络和嵌套结构的结合，创建出更多的技术。通过这种方法开发的生成技术既是热力学驱动复杂系统的简单而有洞见的模型，也是创新技术的强大源泉。 "自组织智能超低功耗系统"（SOULS）是一个能够描述此类生成技术及其产生的技术的术语。该术语旨在捕捉这些技术的抽象本质，即它们独立于其嵌入的基质。换句话说，SOULS可以是生物、人工或混合的形式。

    Ensoul is a framework proposed for the purpose of creating technologies that create more technologies through the combined use of networks, and nests, of energy homeostatic (enerstatic) loops and open-ended evolutionary techniques. Generative technologies developed by such an approach serve as both simple, yet insightful models of thermodynamically driven complex systems and as powerful sources of novel technologies. "Self Organizing intelligent Ultra Low power Systems" (SOULS) is a term that well describes the technologies produced by such a generative technology, as well as the generative technology itself. The term is meant to capture the abstract nature of such technologies as being independent of the substrate in which they are embedded. In other words, SOULS can be biological, artificial or hybrid in form.
    
[^54]: 评估GPT-3.5和GPT-4在支持医疗保健信息需求方面的实际作用

    Evaluation of GPT-3.5 and GPT-4 for supporting real-world information needs in healthcare delivery. (arXiv:2304.13714v1 [cs.AI])

    [http://arxiv.org/abs/2304.13714](http://arxiv.org/abs/2304.13714)

    本研究评估了在临床环境中使用GPT-3.5和GPT-4解决医学问题的安全性以及与信息技术咨询服务报告的一致性。研究结果表明，两个LLMs都可以以安全和一致的方式满足医生的信息需求。

    

    尽管在医疗保健领域使用大型语言模型(LLMs)越来越受关注，但当前的探索并未评估LLMs在临床环境中的实用性和安全性。我们的目标是确定两个LLM是否可以以安全和一致的方式满足由医生提交的信息需求问题。我们将66个来自信息技术咨询服务的问题通过简单的提示提交给GPT-3.5和GPT-4。12名医生评估了LLM响应对患者造成伤害的可能性以及与信息技术咨询服务的现有报告的一致性。医生的评估基于多数票汇总。对于没有任何问题，大多数医生认为任何一个LLM响应都不会造成伤害。对于GPT-3.5，8个问题的响应与信息技术咨询报告一致，20个不一致，9个无法评估。有29个响应没有多数票表示“同意”、“不同意”和“无法评估”。

    Despite growing interest in using large language models (LLMs) in healthcare, current explorations do not assess the real-world utility and safety of LLMs in clinical settings. Our objective was to determine whether two LLMs can serve information needs submitted by physicians as questions to an informatics consultation service in a safe and concordant manner. Sixty six questions from an informatics consult service were submitted to GPT-3.5 and GPT-4 via simple prompts. 12 physicians assessed the LLM responses' possibility of patient harm and concordance with existing reports from an informatics consultation service. Physician assessments were summarized based on majority vote. For no questions did a majority of physicians deem either LLM response as harmful. For GPT-3.5, responses to 8 questions were concordant with the informatics consult report, 20 discordant, and 9 were unable to be assessed. There were 29 responses with no majority on "Agree", "Disagree", and "Unable to assess". Fo
    
[^55]: 合作人工智能的潜力释放：关于联邦机器学习的社会技术挑战

    Unlocking the Potential of Collaborative AI -- On the Socio-technical Challenges of Federated Machine Learning. (arXiv:2304.13688v1 [cs.AI])

    [http://arxiv.org/abs/2304.13688](http://arxiv.org/abs/2304.13688)

    联邦机器学习是一种新的人工智能范式，可以从数据孤岛中创建AI模型，挑战在于建立多方合作业务模式。本研究系统化了联邦机器学习项目的社会技术挑战和业务模式。

    

    AI系统的颠覆性潜力源于大数据的出现，但是很大一部分数据分散在数据孤岛中，其潜力未能得到释放。联邦机器学习是一种新的人工智能范式，可以从分散的、潜在的数据孤岛中创建AI模型。因此，联邦机器学习在技术上可以打开数据孤岛，从而释放经济潜力。然而，这需要多个拥有数据孤岛的方之间的合作。建立合作业务模式是复杂的，通常是失败的原因。当前的文献缺乏成功实现合作AI项目所必须考虑的指南。本研究通过系统文献回顾、焦点小组和专家访谈，探讨了当前合作业务模式的挑战和联邦机器学习的不同方面。我们提供了一个系统化的社会技术挑战和扩展的业务模式，以实现联邦机器学习项目。

    The disruptive potential of AI systems roots in the emergence of big data. Yet, a significant portion is scattered and locked in data silos, leaving its potential untapped. Federated Machine Learning is a novel AI paradigm enabling the creation of AI models from decentralized, potentially siloed data. Hence, Federated Machine Learning could technically open data silos and therefore unlock economic potential. However, this requires collaboration between multiple parties owning data silos. Setting up collaborative business models is complex and often a reason for failure. Current literature lacks guidelines on which aspects must be considered to successfully realize collaborative AI projects. This research investigates the challenges of prevailing collaborative business models and distinct aspects of Federated Machine Learning. Through a systematic literature review, focus group, and expert interviews, we provide a systemized collection of socio-technical challenges and an extended Busin
    
[^56]: 将专家判断融入机器学习模型

    Incorporating Experts' Judgment into Machine Learning Models. (arXiv:2304.11870v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2304.11870](http://arxiv.org/abs/2304.11870)

    本文提出了一种新的框架，利用生成对抗网络确定未标记数据点在训练数据中的代表程度，再根据这个程度将专家的判断融入机器学习模型，以减轻预测结果与专家判断之间的冲突。

    

    机器学习模型在许多应用中预测结果非常成功。然而，在某些情况下，领域专家可能对预期结果有判断，这可能与机器学习模型的预测相冲突。其中一个主要原因是训练数据可能并不完全代表人群。本文提出了一个新的框架，旨在利用专家的判断来减轻冲突。我们框架的基本思想是，首先利用生成对抗网络确定未标记数据点在训练数据中的代表程度。然后，根据这个程度，我们将专家的判断融入机器学习模型，以改正其预测结果，其中代表程度越高，我们就越少地纳入专家的判断，反之亦然。我们进行了多次数字实验。

    Machine learning (ML) models have been quite successful in predicting outcomes in many applications. However, in some cases, domain experts might have a judgment about the expected outcome that might conflict with the prediction of ML models. One main reason for this is that the training data might not be totally representative of the population. In this paper, we present a novel framework that aims at leveraging experts' judgment to mitigate the conflict. The underlying idea behind our framework is that we first determine, using a generative adversarial network, the degree of representation of an unlabeled data point in the training data. Then, based on such degree, we correct the \textcolor{black}{machine learning} model's prediction by incorporating the experts' judgment into it, where the higher that aforementioned degree of representation, the less the weight we put on the expert intuition that we add to our corrected output, and vice-versa. We perform multiple numerical experimen
    
[^57]: 通过伦理和哲学原则确保可信赖的医疗人工智能

    Ensuring Trustworthy Medical Artificial Intelligencethrough Ethical and Philosophical Principles. (arXiv:2304.11530v1 [cs.AI])

    [http://arxiv.org/abs/2304.11530](http://arxiv.org/abs/2304.11530)

    本文讨论了人工智能在医疗保健中的应用和考虑伦理和哲学原则以确保可靠的人工智能工具的重要性。人工智能在医疗中带来了更多挑战，必须解决偏见、透明度、自主权、责任和问责制等问题，作者提出了可能的解决办法。

    

    人工智能方法在医疗护理方面具有极大的潜力，可以通过提高医疗专家和患者的体验来彻底改变众多医疗护理。基于人工智能的计算机辅助诊断工具如果能够表现出色甚至与临床专家的水平相当，就可以产生巨大的效益。因此，发展中国家可以提供先进的医疗护理服务，并解决缺乏专业医疗从业者的问题。基于人工智能的工具可以节省时间、资源和整体治疗成本。此外，与人类相比，人工智能可以揭示大量输入数据中的复杂关系，甚至可以为医学提供新的基于证据的知识。然而，在医疗护理中整合人工智能也带来了几个伦理和哲学上的问题，如偏见、透明度、自主权、责任和问责制，这些问题必须在将这些工具整合到临床环境之前得到解决。在本文中，我们强调了人工智能在医疗护理中的最新应用以及考虑伦理和哲学原则以确保可信赖的人工智能工具的重要性。我们讨论了与医疗护理中的人工智能相关的各种挑战，包括数据偏见、透明度的需要、自主决策的问题以及问责制。我们还提出了解决这些挑战的潜在方案，包括确保透明度和问责制的框架以及指导人工智能开发者考虑伦理原则的指南。通过解决这些挑战并实施伦理和哲学原则，我们可以确保开发出符合诊所设置的受信任的医疗人工智能。

    Artificial intelligence (AI) methods have great potential to revolutionize numerous medical care by enhancing the experience of medical experts and patients. AI based computer-assisted diagnosis tools can have a tremendous benefit if they can outperform or perform similarly to the level of a clinical expert. As a result, advanced healthcare services can be affordable in developing nations, and the problem of a lack of expert medical practitioners can be addressed. AI based tools can save time, resources, and overall cost for patient treatment. Furthermore, in contrast to humans, AI can uncover complex relations in the data from a large set of inputs and even lead to new evidence-based knowledge in medicine. However, integrating AI in healthcare raises several ethical and philosophical concerns, such as bias, transparency, autonomy, responsibility and accountability, which must be addressed before integrating such tools into clinical settings. In this article, we emphasize recent advanc
    
[^58]: SemEval 2023 任务6: LegalEval -- 理解法律文本

    SemEval 2023 Task 6: LegalEval -- Understanding Legal Texts. (arXiv:2304.09548v1 [cs.CL])

    [http://arxiv.org/abs/2304.09548](http://arxiv.org/abs/2304.09548)

    SemEval 2023举办了LegalEval共享任务，即理解法律文本，包括 自动结构化和语义连贯化的法律文件（Task-A），法律命名实体识别（Task-B）以及自动预测法律案件结果和提供预测解释（Task-C）。26个团队提交了系统论文并在所有子任务中优于基准线，但仍有改进空间。

    

    在人口众多的国家，待处理的法律案件呈指数增长。有必要开发基于自然语言处理的技术，对法律文件进行处理和自动理解。为了促进在法律自然语言处理领域的研究，我们在 SemEval 2023 上组织了共享任务 LegalEval - 理解法律文本。LegalEval 任务有三个子任务：Task-A（修辞角色标记）是自动将法律文件结构化为语义连贯的单元，Task-B（法律命名实体识别）处理在法律文件中识别相关实体，而 Task-C（法院判决预测与解释）探索了自动预测法律案件结果以及提供预测解释的可能性。共有26个团队（分布在全球的约100名参与者）提交了系统论文。在每个子任务中，所提出的系统都优于基准线；但是，仍然有很大的改进空间。本文介绍了 LegalEval 任务的组织和细节，并概述了参与系统及其性能。

    In populous countries, pending legal cases have been growing exponentially. There is a need for developing NLP-based techniques for processing and automatically understanding legal documents. To promote research in the area of Legal NLP we organized the shared task LegalEval - Understanding Legal Texts at SemEval 2023. LegalEval task has three sub-tasks: Task-A (Rhetorical Roles Labeling) is about automatically structuring legal documents into semantically coherent units, Task-B (Legal Named Entity Recognition) deals with identifying relevant entities in a legal document and Task-C (Court Judgement Prediction with Explanation) explores the possibility of automatically predicting the outcome of a legal case along with providing an explanation for the prediction. In total 26 teams (approx. 100 participants spread across the world) submitted systems paper. In each of the sub-tasks, the proposed systems outperformed the baselines; however, there is a lot of scope for improvement. This pape
    
[^59]: 不同iable神经架构搜索中神经网络设计的高效自动化:一项概述研究(arXiv: 2304.05405v1 [cs.LG])

    Efficient Automation of Neural Network Design: A Survey on Differentiable Neural Architecture Search. (arXiv:2304.05405v1 [cs.LG])

    [http://arxiv.org/abs/2304.05405](http://arxiv.org/abs/2304.05405)

    本文综述了最近在不同iable神经架构搜索中的研究进展，提出了一种新的基于挑战的分类法，对DARTS方法的贡献和影响进行了讨论，并探讨了未来的研究方向。

    

    在过去的几年中，不同iable神经架构搜索（DNAS）迅速成为自动发现深度神经网络结构的流行方法。 这种崛起主要归功于DARTS，这是第一个重要的DNAS方法之一。 与基于强化学习或进化算法的以前的作品相比，DNAS速度快了数个数量级，并且使用的计算资源更少。 在这篇全面的综述中，我们专门关注DNAS并审查了该领域的最新方法。 此外，我们提出了一种基于挑战的分类法来分类DNAS方法。 我们还讨论了过去几年对DNAS带来的贡献以及其对全球NAS领域的影响。 最后，我们通过提供一些未来研究方向的见解来做出结论。

    In the past few years, Differentiable Neural Architecture Search (DNAS) rapidly imposed itself as the trending approach to automate the discovery of deep neural network architectures. This rise is mainly due to the popularity of DARTS, one of the first major DNAS methods. In contrast with previous works based on Reinforcement Learning or Evolutionary Algorithms, DNAS is faster by several orders of magnitude and uses fewer computational resources. In this comprehensive survey, we focus specifically on DNAS and review recent approaches in this field. Furthermore, we propose a novel challenge-based taxonomy to classify DNAS methods. We also discuss the contributions brought to DNAS in the past few years and its impact on the global NAS field. Finally, we conclude by giving some insights into future research directions for the DNAS field.
    
[^60]: MEDIMP: 用于肾移植表示学习的医学图像和提示

    MEDIMP: Medical Images and Prompts for renal transplant representation learning. (arXiv:2303.12445v1 [cs.CV])

    [http://arxiv.org/abs/2303.12445](http://arxiv.org/abs/2303.12445)

    MEDIMP是一种用于多模式学习肾移植DCE MRI的医学图像和提示模型，利用联合文本-图像嵌入的对比学习来学习有意义的表示。

    

    肾移植已成为终末期肾脏疾病的最有效解决方案。由于复杂原因，移植慢性功能障碍的重大风险仍然存在，可能导致移植失败。医学影像在肾移植监测中发挥着重要作用。然而，移植监督具有多学科特点，尤其是结合了肾脏学、泌尿学和放射学，在这种高维度和复杂数据中识别强大的生物标志物用于预后是具有挑战性的。本文受到大型语言模型（LLMs）的最近成功启发，提出了MEDIMP——医学影像和提示——一种用于多模式学习肾移植动态对比增强磁共振成像（DCE MRI）有意义的表示模型，通过将结构性临床生物数据翻译成文本提示来完成。MEDIMP基于联合文本-图像嵌入的对比学习，以执行这项具有挑战性的任务。

    Renal transplantation emerges as the most effective solution for end-stage renal disease. Occurring from complex causes, a substantial risk of transplant chronic dysfunction persists and may lead to graft loss. Medical imaging plays a substantial role in renal transplant monitoring in clinical practice. However, graft supervision is multi-disciplinary, notably joining nephrology, urology, and radiology, while identifying robust biomarkers from such high-dimensional and complex data for prognosis is challenging. In this work, taking inspiration from the recent success of Large Language Models (LLMs), we propose MEDIMP -- Medical Images and Prompts -- a model to learn meaningful multi-modal representations of renal transplant Dynamic Contrast-Enhanced Magnetic Resonance Imaging (DCE MRI) by incorporating structural clinicobiological data after translating them into text prompts. MEDIMP is based on contrastive learning from joint text-image paired embeddings to perform this challenging ta
    
[^61]: 一种用于音频信号处理的内容自适应可学习时频表示法

    A Content Adaptive Learnable Time-Frequency Representation For Audio Signal Processing. (arXiv:2303.10446v1 [cs.SD])

    [http://arxiv.org/abs/2303.10446](http://arxiv.org/abs/2303.10446)

    该论文提出了一种用于音频信号处理的内容自适应可学习时频表示法，通过学习卷积滤波器与变换器架构来将小的波形块投影到小的潜在维度上。

    

    我们提出了一个可学习的内容自适应前端，用于音频信号处理。在深度学习的现代出现之前，我们使用固定表示的、不可学习的前端，如谱图或梅尔谱图，带/不带神经结构。随着卷积架构支持ASR和声学场景理解等各种应用，转向可学习前端，即从头开始学习和优化特定任务所需的基础函数和权重。在没有卷积块的变形器架构中，线性层将小的波形块投影到小的潜在维度上，然后将它们馈送到变形器架构中。在这项工作中，我们提出了一种计算内容自适应学习时频表示的方法。

    We propose a learnable content adaptive front end for audio signal processing. Before the modern advent of deep learning, we used fixed representation non-learnable front-ends like spectrogram or mel-spectrogram with/without neural architectures. With convolutional architectures supporting various applications such as ASR and acoustic scene understanding, a shift to a learnable front ends occurred in which both the type of basis functions and the weight were learned from scratch and optimized for the particular task of interest. With the shift to transformer-based architectures with no convolutional blocks present, a linear layer projects small waveform patches onto a small latent dimension before feeding them to a transformer architecture. In this work, we propose a way of computing a content-adaptive learnable time-frequency representation. We pass each audio signal through a bank of convolutional filters, each giving a fixed-dimensional vector. It is akin to learning a bank of finit
    
[^62]: 大型语言模型可能会具有意识吗？

    Could a Large Language Model be Conscious?. (arXiv:2303.07103v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.07103](http://arxiv.org/abs/2303.07103)

    本文分析了大型语言模型是否具有意识的可能性，目前的模型存在着意识的显著障碍，但未来十年随着障碍被克服，后继的大型语言模型可能会具有意识。

    

    最近普遍讨论了大型语言模型是否具有感知或意识。我们是否应该认真考虑这个想法？本文将分析支持和反对这个想法的最有力的理由。根据意识科学中的主流假设，目前的模型存在着意识的显著障碍，例如缺乏循环处理、全局的工作空间和统一的智能机构等等。与此同时，这些障碍在未来十年左右都可能被克服。作者得出的结论是，虽然目前大型语言模型具有意识的可能性较小，但我们应该认真考虑后继的大型语言模型在不久的将来可能会具有意识。

    There has recently been widespread discussion of whether large language models might be sentient or conscious. Should we take this idea seriously? I will break down the strongest reasons for and against. Given mainstream assumptions in the science of consciousness, there are significant obstacles to consciousness in current models: for example, their lack of recurrent processing, a global workspace, and unified agency. At the same time, it is quite possible that these obstacles will be overcome in the next decade or so. I conclude that while it is somewhat unlikely that current large language models are conscious, we should take seriously the possibility that successors to large language models may be conscious in the not-too-distant future.
    
[^63]: KGNv2: 基于关键点的RGB-D输入六自由度抓取合成中的尺度和姿态分离

    KGNv2: Separating Scale and Pose Prediction for Keypoint-based 6-DoF Grasp Synthesis on RGB-D input. (arXiv:2303.05617v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.05617](http://arxiv.org/abs/2303.05617)

    本文提出了一种基于关键点的RGB-D输入的六自由度抓取姿态合成方法，既可以从关键点检测中预测抓取姿态，也可以预测相对于相机的尺度，实验结果表明其优越性。

    

    本文提出了一种6自由度抓取姿态合成方法，该方法基于关键点从2D/2.5D输入中进行。在前期研究中，基于关键点的抓取检测器已经证明了良好的结果，其中彩色图像提供的额外视觉信息弥补了嘈杂的深度感知。然而，它严重依赖于准确预测图像空间中的关键点位置。因此，我们设计了一种新的抓取生成网络，既可以从关键点检测中预测抓取姿态，也可以预测相对于相机的尺度。另外，我们还重新设计了关键点输出空间，以减轻关键点预测噪声对透视n点(PnP)算法的负面影响。实验结果表明，所提出的方法在性能上比基线表现出了显著的优越性，验证了我们方法的有效性。最后，尽管是在简单的合成对象上训练的，我们的方法也可以用于真实物体上的抓取。

    We propose a new 6-DoF grasp pose synthesis approach from 2D/2.5D input based on keypoints. Keypoint-based grasp detector from image input has demonstrated promising results in the previous study, where the additional visual information provided by color images compensates for the noisy depth perception. However, it relies heavily on accurately predicting the location of keypoints in the image space. In this paper, we devise a new grasp generation network that reduces the dependency on precise keypoint estimation. Given an RGB-D input, our network estimates both the grasp pose from keypoint detection as well as scale towards the camera. We further re-design the keypoint output space in order to mitigate the negative impact of keypoint prediction noise to Perspective-n-Point (PnP) algorithm. Experiments show that the proposed method outperforms the baseline by a large margin, validating the efficacy of our approach. Finally, despite trained on simple synthetic objects, our method demons
    
[^64]: 基于聚类技术的灵活能源社区目标需求响应

    Targeted demand response for flexible energy communities using clustering techniques. (arXiv:2303.00186v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00186](http://arxiv.org/abs/2303.00186)

    本研究探讨了使用机器学习算法中的聚类技术设计并执行需求响应（DR）计划的可行性，目的是改变分布式能源社区内供应者的消费行为，以最小化反向功率流和削减系统范围内的功峰需求。

    

    本研究探讨了使用聚类技术为商业和住宅社区的能量供应者设计和执行需求响应（DR）计划的可能性。该计划的目的是改变意大利分布式能源社区内的供应者的消费行为。这种聚合旨在：a）最小化在主要变电站处产生的反向功率流，该功率流在当地电网中的太阳能电池的发电量超过消耗时会发生; b）削减系统范围内的功峰需求，该需求通常发生在傍晚时分。在聚类阶段，我们采用了三种热门的电负荷聚类机器学习算法-即k-means，k-medoids和一种聚合层次聚类-alongside两种不同的距离度量-即欧几里得距离和受限动态时间扭曲（DTW）。我们使用多个验证度量来评估这些方法，包括一项新颖的指标-即峰值性能评分（PPS）

    The present study explores the use of clustering techniques for the design and implementation of a demand response (DR) program for commercial and residential prosumers. The goal of the program is to alter the consumption behavior of the prosumers pertaining to a distributed energy community in Italy. This aggregation aims to: a) minimize the reverse power flow at the primary substation, that occurs when generation from solar panels in the local grid exceeds consumption, and b) shave the system wide peak demand, that typically occurs during the hours of late afternoon. Regarding the clustering stage, three popular machine learning algorithms for electrical load clustering are employed -namely k-means, k-medoids and an agglomerative hierarchical clustering- alongside two different distance measures -namely euclidean and constrained dynamic time warping (DTW). We evaluate the methods using multiple validation metrics including a novel metric -namely peak performance score (PPS)- that we 
    
[^65]: 基于曝光的多智能体运用深度强化学习检测翻滚目标

    Exposure-Based Multi-Agent Inspection of a Tumbling Target Using Deep Reinforcement Learning. (arXiv:2302.14188v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2302.14188](http://arxiv.org/abs/2302.14188)

    本论文提出了一种基于深度强化学习的层次化、学习式的多智能体翻转目标巡检规划方法，分为视点规划和导航规划两部分，可以自主、强韧、去中心化地完成巡检任务。

    

    随着太空垃圾日益增多，对于观察废弃卫星以规划维修或进行去轨作业的需要越来越迫切。然而，太空巡检任务本身就是一项挑战性工作，通常需要多个观测卫星的精心协调。在高度非线性的环境中，目标可能是未知的或者不可预测的，没有时间进行连续的地面指挥和控制，这使得任务复杂化之余，也迫切需要自主、强韧、去中心化的巡检方案。为了实现这一目标，我们考虑采用一种层次化的、学习型的方法来进行多智能体翻滚目标的巡检规划。我们的解决方案包括两个组成部分：一个使用深度强化学习来训练的视点或高级规划器，以及一个处理预先指定视点之间点对点导航的导航规划器。本文提出了一种适用的新问题形成和方法。

    As space becomes more congested, on orbit inspection is an increasingly relevant activity whether to observe a defunct satellite for planning repairs or to de-orbit it. However, the task of on orbit inspection itself is challenging, typically requiring the careful coordination of multiple observer satellites. This is complicated by a highly nonlinear environment where the target may be unknown or moving unpredictably without time for continuous command and control from the ground. There is a need for autonomous, robust, decentralized solutions to the inspection task. To achieve this, we consider a hierarchical, learned approach for the decentralized planning of multi-agent inspection of a tumbling target. Our solution consists of two components: a viewpoint or high-level planner trained using deep reinforcement learning and a navigation planner handling point-to-point navigation between pre-specified viewpoints. We present a novel problem formulation and methodology that is suitable no
    
[^66]: 预训练基础模型综述：从BERT到ChatGPT的历程

    A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT. (arXiv:2302.09419v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.09419](http://arxiv.org/abs/2302.09419)

    本文全面回顾了预训练基础模型的最新研究进展和发展历程，包括它们的架构、培训目标、预培训任务、微调策略和评估。同时，讨论了其局限性和未来研究方向。

    

    预训练基础模型(PFMs)被认为是各种不同数据模态下游任务的基础。PFM(例如BERT、ChatGPT和GPT-4)在大规模数据上进行训练，为各种下游应用提供了合理的参数初始化。BERT从转换器中学习双向编码器表示，这些模型作为上下文语言模型在大型数据集上进行训练。类似地，生成式预训练变压器(GPT)方法采用转换器作为特征提取器，并采用自回归范式在大型数据集上进行训练。最近，ChatGPT在大语言模型中展现了令人兴奋的成功，它采用自回归式语言模型，可以进行零射击或少射击提示。PFM的卓越成就为各种AI领域带来了重大突破。许多研究提出了不同的方法，提高了对更新调查的需求。本研究全面回顾了PFMs的最新进展，包括它们的架构、培训目标、预培训任务、微调策略和评估。此外，我们还讨论了PFMs的局限性和未来潜在的研究方向。

    Pretrained Foundation Models (PFMs) are regarded as the foundation for various downstream tasks with different data modalities. A PFM (e.g., BERT, ChatGPT, and GPT-4) is trained on large-scale data which provides a reasonable parameter initialization for a wide range of downstream applications. BERT learns bidirectional encoder representations from Transformers, which are trained on large datasets as contextual language models. Similarly, the generative pretrained transformer (GPT) method employs Transformers as the feature extractor and is trained using an autoregressive paradigm on large datasets. Recently, ChatGPT shows promising success on large language models, which applies an autoregressive language model with zero shot or few shot prompting. The remarkable achievements of PFM have brought significant breakthroughs to various fields of AI. Numerous studies have proposed different methods, raising the demand for an updated survey. This study provides a comprehensive review of rec
    
[^67]: SHINE: 基于深度学习的无障碍停车管理系统

    SHINE: Deep Learning-Based Accessible Parking Management System. (arXiv:2302.00837v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.00837](http://arxiv.org/abs/2302.00837)

    SHINE是一个基于深度学习的无障碍停车管理系统，能够实时识别停放在无障碍停车位上的车辆，并具备可访问性监测功能。实验结果表明，SHINE优于现有的车牌识别系统。

    

    科技的进步推动了城市区域的不断扩张，全世界私人车辆数量相应增加，其中韩国也不例外。这种车辆数量逐步增加也带来了与停车有关的问题，其中包括为残疾人指定的残疾人停车位被滥用。传统的车牌识别系统由于监控摄像头高帧率、自然和人为噪声的存在以及光照和天气条件的变化而导致实时检测和识别效率低下，难以有效解决这些问题。本文提出了SHINE，一个基于深度学习的无障碍停车管理系统，用于实时无障碍性监测和识别停放在无障碍停车位上的车辆。SHINE由两个主要组件组成：基于深度卷积神经网络的车牌识别系统和无障碍停车管理系统。此外，我们提供了一个数据集，包括从4个不同时段拍摄的21个无障碍停车位的4,780张图像，以评估SHINE的性能。实验结果表明，SHINE优于现有的车牌识别系统，在识别率和可访问性监测方面都达到了令人满意的结果。

    The ongoing expansion of urban areas facilitated by advancements in science and technology has resulted in a considerable increase in the number of privately owned vehicles worldwide, including in South Korea. However, this gradual increment in the number of vehicles has inevitably led to parking-related issues, including the abuse of disabled parking spaces (hereafter referred to as accessible parking spaces) designated for individuals with disabilities. Traditional license plate recognition (LPR) systems have proven inefficient in addressing such a problem in real-time due to the high frame rate of surveillance cameras, the presence of natural and artificial noise, and variations in lighting and weather conditions that impede detection and recognition by these systems. With the growing concept of parking 4.0, many sensors, IoT and deep learning-based approaches have been applied to automatic LPR and parking management systems. Nonetheless, the studies show a need for a robust and eff
    
[^68]: 拉普拉斯有界深度神经网络的直接参数化

    Direct Parameterization of Lipschitz-Bounded Deep Networks. (arXiv:2301.11526v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11526](http://arxiv.org/abs/2301.11526)

    本文提出了一种直接参数化的深度神经网络，其具有拉普拉斯界限，通过标准梯度方法进行训练，避免了计算密集型的投影或障碍项。

    

    本文引入了一种新的深度神经网络参数化方式（全连接和卷积网络），具有有限灵敏度的拉普拉斯界限。与SDP方法不同的是，我们提供了一个"直接"参数化方式，并通过标准的梯度方法进行训练，而不需要任何计算密集型的投影或障碍项。

    This paper introduces a new parameterization of deep neural networks (both fully-connected and convolutional) with guaranteed Lipschitz bounds, i.e. limited sensitivity to perturbations. The Lipschitz guarantees are equivalent to the tightest-known bounds based on certification via a semidefinite program (SDP), which does not scale to large models. In contrast to the SDP approach, we provide a ``direct'' parameterization, i.e. a smooth mapping from $\mathbb R^N$ onto the set of weights of Lipschitz-bounded networks. This enables training via standard gradient methods, without any computationally intensive projections or barrier terms. The new parameterization can equivalently be thought of as either a new layer type (the \textit{sandwich layer}), or a novel parameterization of standard feedforward networks with parameter sharing between neighbouring layers. Finally, the comprehensive set of experiments on image classification shows that sandwich layers outperform previous approaches on
    
[^69]: 知识引导下的数据中心人工智能在医疗保健中的进展、缺陷与未来方向

    Knowledge-Guided Data-Centric AI in Healthcare: Progress, Shortcomings, and Future Directions. (arXiv:2212.13591v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.13591](http://arxiv.org/abs/2212.13591)

    简而言之，该论文讨论了如何使用数据中心的方法解决医学图像诊断中的“小数据”问题，介绍了数据增强、迁移学习、联邦学习和GAN的方法，并提出了使用知识引导的GAN将领域知识纳入训练数据生成过程中。

    

    深度学习的成功很大程度上是由于大量包含特定概念或意义的训练数据的可用性。在医学领域，拥有覆盖特定疾病的多样化训练数据可以导致开发出能够准确预测该疾病的模型。然而，尽管有潜在的好处，由于缺乏高质量的注释数据，基于图像的诊断并没有取得显著进展。本文强调在数据表示方面采用数据中心的方法以提高数据质量的重要性，特别是在可用数据有限的情况下。为了解决这个“小数据”问题，我们讨论了四种生成和聚合训练数据的方法：数据增强、迁移学习、联邦学习和GAN（生成对抗网络）。我们还提出了使用知识引导的GAN来将领域知识纳入训练数据生成过程中。

    The success of deep learning is largely due to the availability of large amounts of training data that cover a wide range of examples of a particular concept or meaning. In the field of medicine, having a diverse set of training data on a particular disease can lead to the development of a model that is able to accurately predict the disease. However, despite the potential benefits, there have not been significant advances in image-based diagnosis due to a lack of high-quality annotated data. This article highlights the importance of using a data-centric approach to improve the quality of data representations, particularly in cases where the available data is limited. To address this "small-data" issue, we discuss four methods for generating and aggregating training data: data augmentation, transfer learning, federated learning, and GANs (generative adversarial networks). We also propose the use of knowledge-guided GANs to incorporate domain knowledge in the training data generation pr
    
[^70]: 博弈论混合专家用于组合对抗机器学习

    Game Theoretic Mixed Experts for Combinational Adversarial Machine Learning. (arXiv:2211.14669v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.14669](http://arxiv.org/abs/2211.14669)

    本文提出了一种博弈论框架，用于组合对抗攻击和防御，我们的框架提出了一种混合专家模型，专门针对特定的防御攻击进行防御，并以博弈论的方式进行合作和竞争，形成一个联合防御。

    

    最近在对抗机器学习方面的一些进展表明，那些被认为是强健的防御措施实际上还是容易受到针对其弱点进行定制化攻击的对抗攻击。这些防御措施包括随机变换的攻击（BaRT），有益人类的对抗训练（FAT），垃圾就是珍宝（TiT）以及由视觉转换器、大型转移模型和尖峰神经网络组成的组合模型。本文提出了一种博弈论框架，用于组合对抗攻击和防御，我们的框架提出了一种混合专家模型，每个专家专门针对特定的防御攻击进行防御。然后，这些专家会以博弈论的方式进行合作和竞争，形成一个联合防御。我们在各种数据集和攻击上展示了我们方法的有效性，并表明我们的模型优于现有的最先进的防御措施。

    Recent advances in adversarial machine learning have shown that defenses considered to be robust are actually susceptible to adversarial attacks which are specifically customized to target their weaknesses. These defenses include Barrage of Random Transforms (BaRT), Friendly Adversarial Training (FAT), Trash is Treasure (TiT) and ensemble models made up of Vision Transformers (ViTs), Big Transfer models and Spiking Neural Networks (SNNs). We first conduct a transferability analysis, to demonstrate the adversarial examples generated by customized attacks on one defense, are not often misclassified by another defense.  This finding leads to two important questions. First, how can the low transferability between defenses be utilized in a game theoretic framework to improve the robustness? Second, how can an adversary within this framework develop effective multi-model attacks? In this paper, we provide a game-theoretic framework for ensemble adversarial attacks and defenses. Our framework
    
[^71]: 用图神经网络和结构化状态空间模型建立多元生物信号模型

    Modeling Multivariate Biosignals With Graph Neural Networks and Structured State Space Models. (arXiv:2211.11176v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.11176](http://arxiv.org/abs/2211.11176)

    本研究提出了一种基于时间依赖图的通用图神经网络结构(GraphS4mer)，用于建立多元生物信号模型。该模型结合了结构化状态空间架构和动态演变的图结构学习层来解决长时序和复杂空间相关性，能有效地提高多元生物信号分类任务性能。

    

    多元生物信号在许多医学领域中都很普遍，例如脑电图、多导睡眠图和心电图。由于（1）长时间范围内的时间依赖性和（2）电极之间复杂的空间相关性，建立多元生物信号的时空依赖关系模型是具有挑战性的。为了解决这些挑战，我们建议将多元生物信号表示为时间依赖图，并介绍了GraphS4mer，这是一种通用的图神经网络（GNN）结构，通过建立生物信号中的时空依赖关系来提高生物信号分类任务的性能。具体而言，（1）我们利用结构化状态空间架构，一种最先进的深度序列模型，来捕捉生物信号中长时间范围的时间依赖关系，并（2）我们建议在GraphS4mer中添加图结构学习层，以学习数据中动态演变的图结构。我们在三个不同的生物信号分类任务上评估我们的模型，并展示它优于几种基准模型，突显了它在建立具有复杂依赖关系的多元生物信号模型方面的有效性。

    Multivariate biosignals are prevalent in many medical domains, such as electroencephalography, polysomnography, and electrocardiography. Modeling spatiotemporal dependencies in multivariate biosignals is challenging due to (1) long-range temporal dependencies and (2) complex spatial correlations between the electrodes. To address these challenges, we propose representing multivariate biosignals as time-dependent graphs and introduce GraphS4mer, a general graph neural network (GNN) architecture that improves performance on biosignal classification tasks by modeling spatiotemporal dependencies in biosignals. Specifically, (1) we leverage the Structured State Space architecture, a state-of-the-art deep sequence model, to capture long-range temporal dependencies in biosignals and (2) we propose a graph structure learning layer in GraphS4mer to learn dynamically evolving graph structures in the data. We evaluate our proposed model on three distinct biosignal classification tasks and show th
    
[^72]: 语法感知的即时代码自动补全

    Syntax-Aware On-the-Fly Code Completion. (arXiv:2211.04673v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2211.04673](http://arxiv.org/abs/2211.04673)

    本文介绍了一种有关语法感知的即时代码自动补全方法 PyCoder，通过利用轻量级的语法信息（标记类型），它插入了支持任务来提高代码自动补全的性能，在不考虑语法信息的最先进即时代码自动补全方法中表现显著优于现有方法，同时与无法即时工作的语法感知代码自动补全方法相竞争。

    

    代码自动补全旨在通过从给定上下文推荐下一个代码标记来提高开发人员的生产力。为了进行模型训练，已经提出了各种方法来融合抽象语法树（AST）信息，从而确保代码自动补全能够意识到编程语言的语法。然而，现有的语法感知代码自动补全方法并非即时，因为我们发现，在每个开发人员输入的三分之二的字符中，AST无法提取，因为它需要符合语法正确的源代码，从而限制了其在实际场景中的实用性。另一方面，现有的即时代码自动补全不考虑语法信息。在本文中，我们提出 PyCoder 来利用令人满意的轻量级的语法信息——标记类型，该信息已经可用并且与源代码的自然顺序对齐。我们的 PyCoder 是通过多任务训练的方式进行训练的，因此通过学习预测标记类型序列的支持任务，它可以提高代码自动补全中预测下一个标记的性能。实验结果表明，PyCoder 在不考虑语法信息的最先进即时代码自动补全方法方面显著优于现有方法，同时与无法即时工作的语法感知代码自动补全方法相竞争。

    Code completion aims to help improve developers' productivity by suggesting the next code tokens from a given context. Various approaches have been proposed to incorporate abstract syntax tree (AST) information for model training, ensuring that code completion is aware of the syntax of the programming languages. However, existing syntax-aware code completion approaches are not on-the-fly, as we found that for every two-thirds of characters that developers type, AST fails to be extracted because it requires the syntactically correct source code, limiting its practicality in real-world scenarios. On the other hand, existing on-the-fly code completion does not consider syntactic information yet. In this paper, we propose PyCoder to leverage token types, a kind of lightweight syntactic information, which is readily available and aligns with the natural order of source code. Our PyCoder is trained in a multi-task training manner so that by learning the supporting task of predicting token ty
    
[^73]: 动态认知逻辑中的代理更新与信念归属

    Changing agents and ascribing beliefs in dynamic epistemic logic. (arXiv:2211.02452v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.02452](http://arxiv.org/abs/2211.02452)

    本文在动态认知逻辑中扩展了行动框架，提出了代理更新框架，可以有选择性地添加或删除代理，并进行代理更新。这个框架可以用于模拟一些有趣的例子，并在人工智能问题的建模中得到应用。

    

    在动态认知逻辑中，通常使用行动框架来描述单个行动的不同视角。本文将行动框架扩展为添加或删除代理，称之为代理更新框架。可以有选择性地进行代理更新，只有某些指定的代理会获得更新的信息，这可用于模拟一些有趣的例子，如私有更新和欺骗。然后将一个Kripke模型通过代理更新框架的求和积更新进一步扩展，用于建模故事的问题。我们证明了动态认知逻辑对于人工智能问题的应用。

    In dynamic epistemic logic (Van Ditmarsch, Van Der Hoek, & Kooi, 2008) it is customary to use an action frame (Baltag & Moss, 2004; Baltag, Moss, & Solecki, 1998) to describe different views of a single action. In this article, action frames are extended to add or remove agents, we call these agent-update frames. This can be done selectively so that only some specified agents get information of the update, which can be used to model several interesting examples such as private update and deception, studied earlier by Baltag and Moss (2004); Sakama (2015); Van Ditmarsch, Van Eijck, Sietsma, and Wang (2012). The product update of a Kripke model by an action frame is an abbreviated way of describing the transformed Kripke model which is the result of performing the action. This is substantially extended to a sum-product update of a Kripke model by an agent-update frame in the new setting. These ideas are applied to an AI problem of modelling a story. We show that dynamic epistemic logics,
    
[^74]: 基于不可导物理仿真渲染的感知感知模型强化学习

    SAM-RL: Sensing-Aware Model-Based Reinforcement Learning via Differentiable Physics-Based Simulation and Rendering. (arXiv:2210.15185v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2210.15185](http://arxiv.org/abs/2210.15185)

    SAM-RL使用不可导物理仿真和渲染，通过比较渲染图像和真实原始图像自动更新模型，并高效产生策略。感知感知的学习管道允许机器人选择信息丰富的视角监控任务过程。 用于完成机器人组装，工具操作和变形物体操作任务。

    

    模型为基础的强化学习（MBRL）具有比基于模型的强化学习更高的样本效率。如何从原始感官输入（如图像）自动有效地开发准确的模型，特别是针对复杂的环境和任务，是限制MBRL在现实世界中广泛应用的挑战性问题。本文提出了一种称为SAM-RL的感知感知模型强化学习系统。利用不可导物理仿真和渲染，SAM-RL通过比较渲染图像和真实原始图像自动更新模型并高效产生策略。通过感知感知学习管道，SAM-RL允许机器人选择一个信息丰富的视角来监控任务过程。我们将我们的框架应用于实际的三个操作任务：机器人装配，工具操纵和可变形物体操纵。我们证明了其有效性。

    Model-based reinforcement learning (MBRL) is recognized with the potential to be significantly more sample-efficient than model-free RL. How an accurate model can be developed automatically and efficiently from raw sensory inputs (such as images), especially for complex environments and tasks, is a challenging problem that hinders the broad application of MBRL in the real world. In this work, we propose a sensing-aware model-based reinforcement learning system called SAM-RL. Leveraging the differentiable physics-based simulation and rendering, SAM-RL automatically updates the model by comparing rendered images with real raw images and produces the policy efficiently. With the sensing-aware learning pipeline, SAM-RL allows a robot to select an informative viewpoint to monitor the task process. We apply our framework to real world experiments for accomplishing three manipulation tasks: robotic assembly, tool manipulation, and deformable object manipulation. We demonstrate the effectivene
    
[^75]: 通过隐式微分实现可变规模稳定的可微规划

    Scaling up and Stabilizing Differentiable Planning with Implicit Differentiation. (arXiv:2210.13542v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.13542](http://arxiv.org/abs/2210.13542)

    本文提出了一种通过 Bellman 固定点方程进行微分的方法，实现了值迭代网络及其变体的前后传递解耦，可实现在规划视程内稳定且灵活前向预算的扩展，展示了在不同规划任务上的出色表现。

    

    可微规划承诺具有端到端的可微性和适应性。然而，一个问题阻止了它在更大规模的问题上的扩展：需要通过向前迭代层进行微分以计算梯度，这会将前向计算和反向传播耦合起来，并需要平衡前向规划器的性能和反向传递的计算成本。为了缓解这个问题，我们提出了通过 Bellman 固定点方程进行微分以将值迭代网络及其变体的前向和后向传递解耦的方法，这使得反向传播成本（在规划视程内）保持不变，同时前向预算更加灵活，有助于扩展到更大的问题上。我们研究了所提出的 VIN 隐式版本及其变体的收敛稳定性、可扩展性和效率，并在一系列规划任务上展示了它们的优越性：2D 导航、视觉导航以及构型空间和工作空间中的 2-DOF 操作。

    Differentiable planning promises end-to-end differentiability and adaptivity. However, an issue prevents it from scaling up to larger-scale problems: they need to differentiate through forward iteration layers to compute gradients, which couples forward computation and backpropagation, and needs to balance forward planner performance and computational cost of the backward pass. To alleviate this issue, we propose to differentiate through the Bellman fixed-point equation to decouple forward and backward passes for Value Iteration Network and its variants, which enables constant backward cost (in planning horizon) and flexible forward budget and helps scale up to large tasks. We study the convergence stability, scalability, and efficiency of the proposed implicit version of VIN and its variants and demonstrate their superiorities on a range of planning tasks: 2D navigation, visual navigation, and 2-DOF manipulation in configuration space and workspace.
    
[^76]: 智能家居中婴儿物理安全监测使用动作识别系统

    Baby Physical Safety Monitoring in Smart Home Using Action Recognition System. (arXiv:2210.12527v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.12527](http://arxiv.org/abs/2210.12527)

    本文提出了一种新的轻量级框架，将迁移学习技术与Conv2D LSTM层相结合，用于婴儿物理安全监测的行为识别。

    

    人类能够通过演绎推理直观地推断出两个状态之间发生的行为，这是因为大脑操作在双向通信模型上，这显著提高了基于与以往经验相关的特征的识别和预测的准确性。在过去的十年中，动作识别的深度学习模型有了显著的进展。然而，深度神经网络在特定的动作识别任务中面临着小型数据集的问题。与大多数动作识别任务一样，在空间-时间数据中准确描述活动的模糊性是一个缺点，可以通过策划适当的数据集来克服，包括对视频数据进行细致的注释和预处理，以分析各种识别任务。在本研究中，我们提出了一种新的轻量级框架，将迁移学习技术与Conv2D LSTM层相结合，从预训练的I3D模型中提取特征，用于婴儿物理安全监测的行为识别。

    Humans are able to intuitively deduce actions that took place between two states in observations via deductive reasoning. This is because the brain operates on a bidirectional communication model, which has radically improved the accuracy of recognition and prediction based on features connected to previous experiences. During the past decade, deep learning models for action recognition have significantly improved. However, deep neural networks struggle with these tasks on a smaller dataset for specific Action Recognition (AR) tasks. As with most action recognition tasks, the ambiguity of accurately describing activities in spatial-temporal data is a drawback that can be overcome by curating suitable datasets, including careful annotations and preprocessing of video data for analyzing various recognition tasks. In this study, we present a novel lightweight framework combining transfer learning techniques with a Conv2D LSTM layer to extract features from the pre-trained I3D model on the
    
[^77]: 多模块图神经网络的灵活表征促进更好的泛化能力

    Towards Better Generalization with Flexible Representation of Multi-Module Graph Neural Networks. (arXiv:2209.06589v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.06589](http://arxiv.org/abs/2209.06589)

    本研究探讨了图神经网络在推广到更大的图和从未见过的数据方面的局限，并提出了多模块GNN框架，通过推广单个规范非线性变换来适应新图。结果表明，多模块GNN在合成和实际数据集上均显著提高了GNN的泛化能力，并在几项具有挑战性的任务上实现了最先进的性能。

    

    图神经网络（GNN）已成为处理图结构数据的学习与推断的强大模型，但对于扩展到更大的图以及推广到从未见过的数据的基本限制的了解还不足。本文使用随机图生成器系统地研究了图的大小和结构属性如何影响GNN的预测性能，并提出多模块GNN框架，通过推广单个规范非线性变换来适应新图。结果表明，多模块GNN在合成和实际数据集上均显著提高了GNN的泛化能力，并在几项具有挑战性的任务上实现了最先进的性能。

    Graph neural networks (GNNs) have become compelling models designed to perform learning and inference on graph-structured data. However, little work has been done to understand the fundamental limitations of GNNs for scaling to larger graphs and generalizing to out-of-distribution (OOD) inputs. In this paper, we use a random graph generator to systematically investigate how the graph size and structural properties affect the predictive performance of GNNs. We present specific evidence that the average node degree is a key feature in determining whether GNNs can generalize to unseen graphs, and that the use of multiple node update functions can improve the generalization performance of GNNs when dealing with graphs of multimodal degree distributions. Accordingly, we propose a multi-module GNN framework that allows the network to adapt flexibly to new graphs by generalizing a single canonical nonlinear transformation over aggregated inputs. Our results show that the multi-module GNNs imp
    
[^78]: 拜占庭人也能从历史中学习：联邦学习中心化剪裁的衰落

    Byzantines can also Learn from History: Fall of Centered Clipping in Federated Learning. (arXiv:2208.09894v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.09894](http://arxiv.org/abs/2208.09894)

    本文研究了中心化剪裁在面对不同恶意代理时的脆弱性，提出了一种称为多引用点剪裁 (MRPC) 的算法来解决这个问题。MRPC 框架利用多个参考点有效地中和专门设计的 Byzantine attacks。实验结果表明，在各种类型的 Byzantine attacks 下，MRPC 显著优于最先进的 FL 方法。

    

    联邦学习 (FL) 框架由于在广泛的协作学习任务中的成功而越来越受欢迎，但也引起了某些安全问题。其中，拜占庭攻击的风险是特别关注的问题，这指的是恶意客户参与学习过程的可能性。因此，FL 中的一个关键目标是消除 Byzantine attacks 的潜在影响，确保最终模型是可信的。已经观察到，客户端的模型/更新之间的方差越大，隐藏 Byzantine attacks 的空间就越大。因此，通过使用动量，从而减少方差，可以削弱已知 Byzantine attacks 的力量。中心化剪裁 (CC) 框架进一步表明，上一次的动量项除了减少方差外，还可以作为一个参考点更好地消除 Byzantine attacks。在本文中，我们研究了在不同的恶意代理有不同目标时 CC 的脆弱性。我们提出了一种改进的剪裁算法称为多引用点剪裁 (MRPC)，以克服这种脆弱性。MRPC 框架有效地利用多个参考点来消除专门设计以绕过 CC 方法的 Byzantine attacks。实验结果表明，在各种类型的 Byzantine attacks 下，MRPC 显著优于最先进的 FL 方法。

    The increasing popularity of the federated learning (FL) framework due to its success in a wide range of collaborative learning tasks also induces certain security concerns. Among many vulnerabilities, the risk of Byzantine attacks is of particular concern, which refers to the possibility of malicious clients participating in the learning process. Hence, a crucial objective in FL is to neutralize the potential impact of Byzantine attacks, and to ensure that the final model is trustable. It has been observed that the higher the variance among the clients' models/updates, the more space there is for Byzantine attacks to be hidden. As a consequence, by utilizing momentum, and thus, reducing the variance, it is possible to weaken the strength of known Byzantine attacks. The centered clipping (CC) framework has further shown that, the momentum term from the previous iteration, besides reducing the variance, can be used as a reference point to neutralize Byzantine attacks better. In this wor
    
[^79]: 一种符合保序的风险控制方法

    Conformal Risk Control. (arXiv:2208.02814v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2208.02814](http://arxiv.org/abs/2208.02814)

    该论文提出了一种符合保序的风险控制方法，可以控制任何单调损失函数的期望值，示例证明其在计算机视觉和自然语言处理领域具有控制误报率、图形距离和令牌级F1得分的能力。

    

    我们将符合性预测推广至控制任何单调损失函数的期望值。该算法将分裂符合性预测及其覆盖保证进行了泛化。类似于符合性预测，符合保序的风险控制方法在$\mathcal{O}(1/n)$因子内保持紧密性。计算机视觉和自然语言处理领域的示例证明了我们算法在控制误报率、图形距离和令牌级F1得分方面的应用。

    We extend conformal prediction to control the expected value of any monotone loss function. The algorithm generalizes split conformal prediction together with its coverage guarantee. Like conformal prediction, the conformal risk control procedure is tight up to an $\mathcal{O}(1/n)$ factor. Worked examples from computer vision and natural language processing demonstrate the usage of our algorithm to bound the false negative rate, graph distance, and token-level F1-score.
    
[^80]: 基于 Weisfeiler-Lehman 子树 L1-近似树编辑距离的 Wasserstein 图距离

    Wasserstein Graph Distance Based on $L_1$-Approximated Tree Edit Distance between Weisfeiler-Lehman Subtrees. (arXiv:2207.04216v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.04216](http://arxiv.org/abs/2207.04216)

    本文提出一种名为Wasserstein WL子树(WWLS)距离的新型图距离，通过利用WL子树作为节点邻域的结构信息，使用节点的WL子树之间的L1-近似树编辑距离(L1-TED)定义节点度量，解决了WL测试无法捕捉轻微结构差异的问题

    

    Weisfeiler-Lehman (WL)测试是图机器学习中广泛使用的算法，包括图内核、图度量和图神经网络。然而，它仅关注图的一致性，无法检测轻微的结构差异。因此，这限制了它捕捉结构信息的能力，也限制了依赖WL测试的现有模型的性能。本文提出一种名为Wasserstein WL子树(WWLS)距离的新型图距离，以解决这个问题。我们的方法利用WL子树作为节点邻域的结构信息，并使用节点的WL子树之间的L1-近似树编辑距离(L1-TED)定义节点度量。随后，我们结合了Wasserstein距离和L1-TED来定义WWLS距离

    The Weisfeiler-Lehman (WL) test is a widely used algorithm in graph machine learning, including graph kernels, graph metrics, and graph neural networks. However, it focuses only on the consistency of the graph, which means that it is unable to detect slight structural differences. Consequently, this limits its ability to capture structural information, which also limits the performance of existing models that rely on the WL test. This limitation is particularly severe for traditional metrics defined by the WL test, which cannot precisely capture slight structural differences. In this paper, we propose a novel graph metric called the Wasserstein WL Subtree (WWLS) distance to address this problem. Our approach leverages the WL subtree as structural information for node neighborhoods and defines node metrics using the $L_1$-approximated tree edit distance ($L_1$-TED) between WL subtrees of nodes. Subsequently, we combine the Wasserstein distance and the $L_1$-TED to define the WWLS distan
    
[^81]: 在NVIDIA网卡中实现强化学习数据中心拥塞控制

    Implementing Reinforcement Learning Datacenter Congestion Control in NVIDIA NICs. (arXiv:2207.02295v4 [cs.NI] UPDATED)

    [http://arxiv.org/abs/2207.02295](http://arxiv.org/abs/2207.02295)

    本文在NVIDIA网卡中实现了强化学习数据中心拥塞控制，通过将RL-CC的复杂神经网络转化为决策树，实现了实时推理，并成功改善了网络拥塞下的尾部延迟和数据包丢失问题。

    

    随着通信协议的发展，数据中心网络的利用率越来越高，拥塞更为频繁，导致延迟和丢包率增加。这种情况下，人工设计拥塞控制算法变得极其困难，需要开发人工智能方法来替代人力。但是，由于网络设备计算能力有限，目前不可能在网络设备上部署AI模型。本文提出了一个解决方案，基于最新的强化学习拥塞控制算法[arXiv:2207.02295]，构建了一个基于决策树的计算轻量级解决方案，将RL-CC的复杂神经网络转化为决策树，将其推理时间降低了500倍，使其在μ秒级决策时间要求内实现实时推理，且对质量影响不大。我们在一个实时集群中部署了转换后的策略，并与现代数据中心部署的流行拥塞控制算法进行了比较。在类似的流量条件下，我们的解决方案将尾部延迟率提高了x%，将数据包丢失率降低了y%。

    As communication protocols evolve, datacenter network utilization increases. As a result, congestion is more frequent, causing higher latency and packet loss. Combined with the increasing complexity of workloads, manual design of congestion control (CC) algorithms becomes extremely difficult. This calls for the development of AI approaches to replace the human effort. Unfortunately, it is currently not possible to deploy AI models on network devices due to their limited computational capabilities. Here, we offer a solution to this problem by building a computationally-light solution based on a recent reinforcement learning CC algorithm [arXiv:2207.02295]. We reduce the inference time of RL-CC by x500 by distilling its complex neural network into decision trees. This transformation enables real-time inference within the $\mu$-sec decision-time requirement, with a negligible effect on quality. We deploy the transformed policy on NVIDIA NICs in a live cluster. Compared to popular CC algor
    
[^82]: RevBiFPN：完全可逆的双向特征金字塔网络

    RevBiFPN: The Fully Reversible Bidirectional Feature Pyramid Network. (arXiv:2206.14098v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.14098](http://arxiv.org/abs/2206.14098)

    本文提出了RevSilo，一个完全可逆的双向多尺度特征融合模块，它缓解了神经网络规模受限的问题。

    

    本文提出了RevSilo，这是第一个可逆的双向多尺度特征融合模块。与其他可逆方法一样，RevSilo通过重新计算来消除存储隐藏激活所需的内存；然而，现有方法不适用于多尺度特征融合，因此不能应用于大部分网络。双向多尺度特征融合促进了局部和全局的一致性，并已成为针对空间敏感任务的网络的设计原则。这些网络在使用高分辨率输入时，在各种计算机视觉任务中实现了最先进的结果。然而，训练这些网络需要保存大型的多分辨率激活所需的大量加速器内存。这些内存需求本质上限制了神经网络的规模，限制了由规模带来的改进。跨分辨率尺度运作的RevSilo缓解了这些问题。

    This work introduces RevSilo, the first reversible bidirectional multi-scale feature fusion module. Like other reversible methods, RevSilo eliminates the need to store hidden activations by recomputing them. However, existing reversible methods do not apply to multi-scale feature fusion and are, therefore, not applicable to a large class of networks. Bidirectional multi-scale feature fusion promotes local and global coherence and has become a de facto design principle for networks targeting spatially sensitive tasks, e.g., HRNet (Sun et al., 2019a) and EfficientDet (Tan et al., 2020). These networks achieve state-of-the-art results across various computer vision tasks when paired with high-resolution inputs. However, training them requires substantial accelerator memory for saving large, multi-resolution activations. These memory requirements inherently cap the size of neural networks, limiting improvements that come from scale. Operating across resolution scales, RevSilo alleviates th
    
[^83]: 将对称性融入可微规划中的可控卷积

    Integrating Symmetry into Differentiable Planning with Steerable Convolutions. (arXiv:2206.03674v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.03674](http://arxiv.org/abs/2206.03674)

    本文研究了如何在路径规划任务中使用对称性改善数据效率和泛化能力。将值迭代视为网格信号，并使用可控卷积来融合对称性。实验表明，我们的对称规划算法比非等变对应物在训练效率和泛化方面有很大提升。

    

    本文研究了在决策任务中出现对称性时，如何利用群对称性改善端到端可微规划算法的数据效率和泛化能力。受等变卷积网络的启发，我们将路径规划问题视为网格上的信号。我们展示了在这种情况下值迭代是一个线性等变算子，即可被（定向）卷积表示。这扩展了值迭代网络（VIN）在使用卷积网络进行路径规划时使用额外的旋转和反射对称性的方法。我们的实现基于VIN，并使用可控卷积网络来融合对称性。我们进行了四个任务的实验：2D导航，视觉导航，自由度（2DOFs）配置空间和工作空间操纵。与非等变对应物VIN和GPPN相比，我们的对称规划算法在训练效率和泛化方面有很大的提升。

    We study how group symmetry helps improve data efficiency and generalization for end-to-end differentiable planning algorithms when symmetry appears in decision-making tasks. Motivated by equivariant convolution networks, we treat the path planning problem as \textit{signals} over grids. We show that value iteration in this case is a linear equivariant operator, which is a (steerable) convolution. This extends Value Iteration Networks (VINs) on using convolutional networks for path planning with additional rotation and reflection symmetry. Our implementation is based on VINs and uses steerable convolution networks to incorporate symmetry. The experiments are performed on four tasks: 2D navigation, visual navigation, and 2 degrees of freedom (2DOFs) configuration space and workspace manipulation. Our symmetric planning algorithms improve training efficiency and generalization by large margins compared to non-equivariant counterparts, VIN and GPPN.
    
[^84]: 基于深度强化学习的微电网联合能量分配和机组开启

    Joint Energy Dispatch and Unit Commitment in Microgrids Based on Deep Reinforcement Learning. (arXiv:2206.01663v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.01663](http://arxiv.org/abs/2206.01663)

    本文采用深度强化学习算法HAFH-DDPG来学习隔离式微电网中的联合能量分配和机组开启决策问题，并提出了柴油发电机选择策略，以降低计算复杂度。

    

    如今，应用可再生能源的微电网（MG）越来越广泛，这创造了对动态能源管理的强烈需求。本文采用深度强化学习（DRL）来学习隔离式MG中联合能量分配（ED）和机组开启（UC）决策的最优策略，以在确保供需平衡的前提下降低总电力成本。为了克服由于联合ED和UC而导致的离散-连续混合行动空间的挑战，我们提出了一种DRL算法，即混合行动有限地平线DDPG（HAFH-DDPG），它基于有限地平线动态规划（DP）框架，无缝地整合了两种经典DRL算法，即深度Q网络（DQN）和深度确定性策略梯度（DDPG）。此外，提出了一种柴油发电机（DG）选择策略，以支持简化行动空间，以降低此算法的计算复杂度。

    Nowadays, the application of microgrids (MG) with renewable energy is becoming more and more extensive, which creates a strong need for dynamic energy management. In this paper, deep reinforcement learning (DRL) is applied to learn an optimal policy for making joint energy dispatch (ED) and unit commitment (UC) decisions in an isolated MG, with the aim for reducing the total power generation cost on the premise of ensuring the supply-demand balance. In order to overcome the challenge of discrete-continuous hybrid action space due to joint ED and UC, we propose a DRL algorithm, i.e., the hybrid action finite-horizon DDPG (HAFH-DDPG), that seamlessly integrates two classical DRL algorithms, i.e., deep Q-network (DQN) and deep deterministic policy gradient (DDPG), based on a finite-horizon dynamic programming (DP) framework. Moreover, a diesel generator (DG) selection strategy is presented to support a simplified action space for reducing the computation complexity of this algorithm. Fina
    
[^85]: 机器解释和人类理解

    Machine Explanations and Human Understanding. (arXiv:2202.04092v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2202.04092](http://arxiv.org/abs/2202.04092)

    研究讨论了机器解释和人类理解之间的相互作用，并确定了三个核心概念。结果显示，在没有关于特定任务直觉的假设下，解释可提高人类对模型决策边界的理解，但对任务决策边界和模型错误则没有充分证据支持。

    

    解释被假设可以提高人类对机器学习模型的理解，并实现各种有益的结果，从模型调试到增强人类决策制定。然而，实证研究发现了不一致甚至负面的结果。因此，一个开放的问题是在什么条件下解释可以提高人类的理解，并以何种方式。使用改进的因果图表，我们提供了机器解释和人类理解之间相互作用的正式特征化，并展示了人类直觉在启用人类理解中发挥了核心作用。具体而言，我们确定了三个核心概念，涵盖了所有现有量化理解的措施，即在人类与人工智能决策制定的背景下的任务决策边界、模型决策边界和模型错误。我们的关键结果是，如果没有关于特定任务直觉的假设，解释可能会潜在地提高人类对模型决策边界的理解，但对于任务决策边界和模型错误，则没有充分的证据表明解释可以提高人类理解。

    Explanations are hypothesized to improve human understanding of machine learning models and achieve a variety of desirable outcomes, ranging from model debugging to enhancing human decision making. However, empirical studies have found mixed and even negative results. An open question, therefore, is under what conditions explanations can improve human understanding and in what way. Using adapted causal diagrams, we provide a formal characterization of the interplay between machine explanations and human understanding, and show how human intuitions play a central role in enabling human understanding. Specifically, we identify three core concepts of interest that cover all existing quantitative measures of understanding in the context of human-AI decision making: task decision boundary, model decision boundary, and model error. Our key result is that without assumptions about task-specific intuitions, explanations may potentially improve human understanding of model decision boundary, bu
    
[^86]: 利用神经网络和树搜索生成平面四边形网格

    Generate plane quad mesh with neural networks and tree search. (arXiv:2111.07613v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.07613](http://arxiv.org/abs/2111.07613)

    本论文提出了一种结合强化学习和树搜索的新方法，名为TreeMesh，用于生成高质量的平面四边形网格，可以比现有最先进的方法更快地生成。

    

    在有限元方法（FEM）的历史上，网格生成的质量一直被认为是为工程师提供可靠仿真结果的重要因素。目前最健壮的元素提取方法是采用寻找优化目标函数的下一个元素的方法来加快提取速度，但这可能导致经过多次迭代后局部网格质量较差。本文提出了TreeMesh，该方法将这种方法与强化学习（也可能是监督学习）和一种新的蒙特卡罗树搜索（MCTS）相结合。该算法基于先前提出的方法，经过多次改进后，在相同的边界上性能优于以前的工作。此外，利用树搜索，我们的程序可以比现有最先进的方法更快地生成高质量的平面四边形网格。

    The quality of mesh generation has long been considered a vital aspect in providing engineers with reliable simulation results throughout the history of the Finite Element Method (FEM). The element extraction method, which is currently the most robust method, is used in business software. However, in order to speed up extraction, the approach is done by finding the next element that optimizes a target function, which can result in local mesh of bad quality after many time steps. We provide TreeMesh, a method that uses this method in conjunction with reinforcement learning (also possible with supervised learning) and a novel Monte-Carlo tree search (MCTS) (Coulom(2006), Kocsis and Szepesv\'ari(2006), Browne et~al.(2012)). The algorithm is based on a previously proposed approach (Pan et~al.(2021)). After making many improvements on DRL (algorithm, state-action-reward setting) and adding a MCTS, it outperforms the former work on the same boundary. Furthermore, using tree search, our progr
    
[^87]: SelfCF：一种简单的自监督协同过滤框架

    SelfCF: A Simple Framework for Self-supervised Collaborative Filtering. (arXiv:2107.03019v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2107.03019](http://arxiv.org/abs/2107.03019)

    SelfCF是一种自监督协同过滤框架，用于推荐场景，通过增强现有的深度学习协同过滤模型中输出的嵌入来简化算法以及避免昂贵的计算和潜在的负样本问题。

    

    协同过滤（CF）被广泛用于从观察到的交互中学习有用的用户和项目的潜在表示。现有的基于CF的方法通常采用负采样来区分不同的项目。在大型数据集上使用负采样进行训练计算成本很高。此外，必须根据定义的分布谨慎选择负项，以避免在训练数据集中选择观察到的正项。不可避免地，从训练数据集中采样的一些负项在测试集中可能是正项。我们提出了一种专门用于隐式反馈推荐场景的自监督协同过滤框架（SelfCF）。所提出的SelfCF框架简化了连体网络，并可轻松应用于现有的基于深度学习的CF模型，我们称其为骨干网络。SelfCF的主要思想是增强由骨干网络生成的输出嵌入。

    Collaborative filtering (CF) is widely used to learn informative latent representations of users and items from observed interactions. Existing CF-based methods commonly adopt negative sampling to discriminate different items. Training with negative sampling on large datasets is computationally expensive. Further, negative items should be carefully sampled under the defined distribution, in order to avoid selecting an observed positive item in the training dataset. Unavoidably, some negative items sampled from the training dataset could be positive in the test set. In this paper, we propose a self-supervised collaborative filtering framework (SelfCF), that is specially designed for recommender scenario with implicit feedback. The proposed SelfCF framework simplifies the Siamese networks and can be easily applied to existing deep-learning based CF models, which we refer to as backbone networks. The main idea of SelfCF is to augment the output embeddings generated by backbone networks, b
    
[^88]: 基于多样性保持的图结构细化的图表示学习

    Graph Representation Learning via Diversity-preserving Graph Refinement. (arXiv:2103.07295v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2103.07295](http://arxiv.org/abs/2103.07295)

    该论文提出了一种基于多样性保持的图结构细化的图表示学习方法，它利用已学习的节点表示来逐步改善图形结构质量。在多个下游任务上，包括节点分类、链接预测和图聚类，实验表明该方法优于现有的最先进方法。

    

    对于真实的图数据，节点之间的复杂关系通常被表示为硬性二进制链接。显然，这是一种离散和简化的连续关系形式，严重限制了学习到的节点表示的可表达性。另一方面，嵌入空间中获得的节点表示可以反过来揭示节点之间的内在关系。为了更好地特征化节点关系并进一步促进节点表示的学习，一种直观的方法是使用嵌入的节点表示来细化最初给定的图结构。但是，全局细化所有节点之间的关系无法区分将不可避免地导致一些噪声边缘，这可能进一步混淆节点表示学习模型的训练。此外，大型图形上也存在可扩展性问题。为了解决这些问题，我们提出了一种局部结构感知的图形细化方法，利用已经学到的节点表示逐步改善图形结构质量。具体而言，我们首先通过对图中的随机游走模拟生成一个多样化的邻域结构集。然后，对于每个模拟邻域，我们在整个细化过程中保持邻域结构的多样性，同时细化邻域内的节点关系。在各种基准数据集上进行的评估实验结果表明，所提出的方法在多个下游任务上，包括节点分类、链接预测和图聚类，均优于现有最先进的方法。

    For real-world graph data, the complex relationship between nodes is often represented as a hard binary link. Obviously, it is a discrete and simplified form of continuous relationship between nodes, which seriously limits the expressibility of the learned node representation. On the other hand, the node representation obtained in the embedding space can in turn be used to reveal the intrinsic relationship between nodes. To better characterize the node relationships and further facilitate the learning of node representation, an intuitive way is to refine the originally given graph structure with the embedded node representations. However, such global refinement of the relationships among all nodes without distinction will inevitably lead to some noisy edges, which may further confuse the training of the node representation learning model. In addition, it also has scalability problems on large graphs. To address these issues, we propose a local structure aware graph refinement to progre
    
[^89]: 基准能量守恒神经网络用于学习动力学数据的研究

    Benchmarking Energy-Conserving Neural Networks for Learning Dynamics from Data. (arXiv:2012.02334v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2012.02334](http://arxiv.org/abs/2012.02334)

    本文调查了10个最近提出的能量守恒神经网络模型，并比较了它们在4个物理系统中的表现，说明了利用这些模型设计基于能量的控制器的可能性。

    

    近年来，将物理知识作为归纳偏置引入深度学习框架，特别是在利用神经网络从观测到的时间序列数据中学习动力学方程方面引起了越来越多的关注。在本文中，我们调查了包括HNN、LNN、DeLaN、SymODEN、CHNN、CLNN及其变体在内的10个最近提出的能量守恒神经网络模型。我们提供了这些模型的理论简洁演绎，并解释了它们的相似之处和差异。我们比较了这些模型在4个物理系统中的表现。我们指出了利用这些能量守恒模型设计基于能量的控制器的可能性。

    The last few years have witnessed an increased interest in incorporating physics-informed inductive bias in deep learning frameworks. In particular, a growing volume of literature has been exploring ways to enforce energy conservation while using neural networks for learning dynamics from observed time-series data. In this work, we survey ten recently proposed energy-conserving neural network models, including HNN, LNN, DeLaN, SymODEN, CHNN, CLNN and their variants. We provide a compact derivation of the theory behind these models and explain their similarities and differences. Their performance are compared in 4 physical systems. We point out the possibility of leveraging some of these energy-conserving models to design energy-based controllers.
    
[^90]: 使用Anthem和Vampire验证紧凑逻辑程序

    Verifying Tight Logic Programs with anthem and Vampire. (arXiv:2008.02025v6 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2008.02025](http://arxiv.org/abs/2008.02025)

    本文通过使用Anthem和Vampire两个软件工具，验证了具有输入和输出的程序的正确性，并研究了该上下文中稳定模型和补完之间的关系。

    

    本文继续研究逻辑程序和一阶理论之间关系的一系列研究。我们将程序补完的定义扩展到输入和输出在ASP grounding 工具gringo的输入语言子集中的程序，并研究了该上下文中稳定模型和补完之间的关系，描述了使用两个软件工具Anthem和Vampire验证具有输入和输出的程序的正确性的初步实验。该定理的证明基于引理，该引理将本文研究的程序语义与一阶公式的稳定模型相关联。正在TLP接受考虑。

    This paper continues the line of research aimed at investigating the relationship between logic programs and first-order theories. We extend the definition of program completion to programs with input and output in a subset of the input language of the ASP grounder gringo, study the relationship between stable models and completion in this context, and describe preliminary experiments with the use of two software tools, anthem and vampire, for verifying the correctness of programs with input and output. Proofs of theorems are based on a lemma that relates the semantics of programs studied in this paper to stable models of first-order formulas. Under consideration for acceptance in TPLP.
    

