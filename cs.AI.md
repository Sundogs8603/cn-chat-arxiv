# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [ForceSight: Text-Guided Mobile Manipulation with Visual-Force Goals.](http://arxiv.org/abs/2309.12312) | ForceSight是一个使用文本引导的移动操作系统，通过深度神经网络预测视觉力导向目标。在实验中，该系统展示了在未见环境中进行精确抓取、抽屉打开和物体交接等任务的能力，并取得了较高的成功率。 |
| [^2] | [LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent.](http://arxiv.org/abs/2309.12311) | LLM-Grounder是一种零样本、开放词汇的基于大型语言模型的3D视觉定位流程，通过利用语言模型分解查询并使用视觉定位工具识别物体，实现了在没有标记训练数据的情况下对新场景和文本查询的有效定位。在ScanRefer基准上取得了最先进的零样本定位准确性。 |
| [^3] | [Rehearsal: Simulating Conflict to Teach Conflict Resolution.](http://arxiv.org/abs/2309.12309) | 演练是一个系统，通过模拟冲突和提供反馈，教授用户冲突解决的技能。利用演练，用户可以练习处理各种冲突场景，并学习如何运用冲突策略。 |
| [^4] | [LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models.](http://arxiv.org/abs/2309.12307) | LongLoRA是一种高效的精细调整方法，可以在有限的计算成本下扩展预训练的大型语言模型的上下文大小。它通过稀疏的局部注意力实现精细调整，并使用移动短注意力有效实现上下文扩展，与传统方法具有相似的性能。 |
| [^5] | [Environment-biased Feature Ranking for Novelty Detection Robustness.](http://arxiv.org/abs/2309.12301) | 本文提出了一种环境偏向特征排序的方法，用于鲁棒性的新颖性检测。通过计算特征的环境之间分布方差进行评分，并通过去除高分特征来改善性能。这种方法在真实和合成基准数据上均能提高性能。 |
| [^6] | [See to Touch: Learning Tactile Dexterity through Visual Incentives.](http://arxiv.org/abs/2309.12300) | 本文提出了一种通过视觉激励优化触觉策略的框架，以增强多指机器人的触觉灵巧性，并在多个挑战性任务中取得了良好的效果。 |
| [^7] | [Learning to Drive Anywhere.](http://arxiv.org/abs/2309.12295) | 本文提出了一种能够学习适应不同地理位置和驾驶行为的模型，该模型通过引入基于地理位置的通道注意机制，在数据驱动的方式下高效地学习并灵活地建模不同地区之间的相似性和差异性。 |
| [^8] | [The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A".](http://arxiv.org/abs/2309.12288) | LLMs模型在训练中只能学习到"A是B"的结构，无法自动推广到"B是A"。这表明模型在逻辑推断上存在基本失败和训练集中模式的推广问题。 |
| [^9] | [MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models.](http://arxiv.org/abs/2309.12284) | MetaMath是一种专门用于数学推理的微调语言模型，通过从多个角度重新编写问题来生成数学问题，并在两个基准测试中取得了优于其他开源语言模型的表现。 |
| [^10] | [LLMR: Real-time Prompting of Interactive Worlds using Large Language Models.](http://arxiv.org/abs/2309.12276) | LLMR是一个用于实时创建和修改交互式混合现实体验的框架，通过利用大型语言模型和新颖的策略，它能够解决训练数据稀缺和设计目标复杂的问题，并在性能上超过标准的GPT-4。我们展示了LLMR的跨平台互操作性，并通过评估和用户研究证明了其对于生成和编辑各种对象、工具和场景的能力。 |
| [^11] | [Enabling Quartile-based Estimated-Mean Gradient Aggregation As Baseline for Federated Image Classifications.](http://arxiv.org/abs/2309.12267) | 本文提出了一种名为估计平均聚合（EMA）的创新解决方案，旨在解决联邦学习中数据多样性和系统安全的挑战。EMA通过修剪均值处理恶意异常值，并揭示数据异质性，以确保训练模型适应不同的客户数据集。通过丰富的实验验证，EMA相对于其他方法表现出高准确性和曲线下面积（AUC），成为先进聚合技术的基准线。 |
| [^12] | [SALSA-CLRS: A Sparse and Scalable Benchmark for Algorithmic Reasoning.](http://arxiv.org/abs/2309.12253) | SALSA-CLRS是一种稀疏且可扩展的算法推理基准，优先考虑可扩展性和稀疏表示的利用。它通过引入适应于分布式算法和图神经网络的消息传递范式，解决了现有CLRS基准中内存需求高和运行时间难以扩展的问题。 |
| [^13] | [Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection.](http://arxiv.org/abs/2309.12247) | 大型语言模型对于假新闻检测的潜力仍未得到充分探索。实证研究发现，尽管复杂的大型语言模型能够揭示假新闻并提供多角度解释，但仍不如经过fine-tuned的小型语言模型表现出色。当前的大型语言模型可能无法取代小型语言模型，但可以作为一个良好的辅助顾问。 |
| [^14] | [ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events.](http://arxiv.org/abs/2309.12244) | ChaCha是一个利用大型语言模型（LLMs）的聊天机器人，鼓励儿童分享个人事件和相关情绪。通过一个探索性研究，发现儿童将ChaCha视为亲密的朋友，并愿意与其分享各种主题的故事。 |
| [^15] | [Electroencephalogram Sensor Data Compression Using An Asymmetrical Sparse Autoencoder With A Discrete Cosine Transform Layer.](http://arxiv.org/abs/2309.12201) | 本文提出了一种使用非对称稀疏自编码器和离散余弦变换层对脑电图传感器数据进行压缩的方法。实验结果表明，这种方法能有效地减少EEG信号的冗余，并在保持稀疏性的同时提高数据的准确性。 |
| [^16] | [Explainable Artificial Intelligence for Drug Discovery and Development -- A Comprehensive Survey.](http://arxiv.org/abs/2309.12177) | 可解释的人工智能在药物发现中的应用越来越受关注，为研究人员提供了对机器学习模型预测的更具解释性的理解，进一步促进了目标识别、化合物设计和毒性预测等方面的发展。 |
| [^17] | [Unsupervised Domain Adaptation for Self-Driving from Past Traversal Features.](http://arxiv.org/abs/2309.12140) | 本研究提出了一种方法，利用无标签的重复遍历来适应物体检测器到新的驾驶环境。通过结合重复的激光雷达扫描计算的统计数据，我们有效地引导自适应过程，并通过引入轻量级的回归头和自训练过程来增强检测模型。实验表明，该方法在现实世界数据集上取得了多达20个百分点的性能提升。 |
| [^18] | [On the relationship between Benchmarking, Standards and Certification in Robotics and AI.](http://arxiv.org/abs/2309.12139) | 本文研究了机器人和人工智能中基准测试、标准和认证之间的关系，并认为它们不仅有用，而且对于更广泛的负责任创新实践至关重要。 |
| [^19] | [OSN-MDAD: Machine Translation Dataset for Arabic Multi-Dialectal Conversations on Online Social Media.](http://arxiv.org/abs/2309.12137) | 该论文介绍了一个用于阿拉伯多方言在线社交媒体对话的机器翻译数据集，指出了阿拉伯语资源不足的问题以及现有机器翻译系统在处理阿拉伯方言时的困难。该研究的重点在于开发能够有效处理阿拉伯各种方言的机器翻译系统。 |
| [^20] | [A knowledge representation approach for construction contract knowledge modeling.](http://arxiv.org/abs/2309.12132) | 本论文介绍了一个用于建筑合同知识建模的知识表示方法，通过嵌套结构捕捉合同知识的复杂性。它提出了嵌套合同知识图（NCKG）和LLM-assisted合同审查流程，帮助自动化合同管理，并在合同风险审查方面取得了良好性能。 |
| [^21] | [Incentivizing Massive Unknown Workers for Budget-Limited Crowdsensing: From Off-Line and On-Line Perspectives.](http://arxiv.org/abs/2309.12113) | 本文提出了一种离线的基于上下文感知的CMAB激励（CACI）机制，通过对一个精细划分的上下文空间中的探索-开发权衡，有效地激励具有非常有限预算的大规模未知工作者。 |
| [^22] | [PEFTT: Parameter-Efficient Fine-Tuning for low-resource Tibetan pre-trained language models.](http://arxiv.org/abs/2309.12109) | 本研究在低资源语言模型如藏语中进行了高效微调策略的研究，填补了这一重要空白。 |
| [^23] | [Accelerating Thematic Investment with Prompt Tuned Pretrained Language Models.](http://arxiv.org/abs/2309.12075) | 本研究通过Benchmark测试，发现使用Prompt Tuning的预训练语言模型在多标签文本分类任务中具有较好的性能和计算效率。同时，提出了使用Trie搜索来解决生成标签匹配问题的限制。 |
| [^24] | [Benchmarking quantized LLaMa-based models on the Brazilian Secondary School Exam.](http://arxiv.org/abs/2309.12071) | 本研究对基于量化LLaMa模型的大型语言模型在巴西中学考试上进行了性能评估。评估结果表明，最佳表现的模型在原版葡萄牙语问题和其英文翻译上的准确率约为46%。同时，作者还评估了这些模型的计算效率。 |
| [^25] | [Survey of Action Recognition, Spotting and Spatio-Temporal Localization in Soccer -- Current Trends and Research Perspectives.](http://arxiv.org/abs/2309.12067) | 本文提供了足球中动作识别、定位和时空定位的综述，重点介绍了多模态方法。通过利用深度学习技术和传统方法，这些方法整合了来自多个数据源的信息，并以多种方式表示一种来源，在提高模型准确性和稳健性方面具有潜力。 |
| [^26] | [An Efficient Consolidation of Word Embedding and Deep Learning Techniques for Classifying Anticancer Peptides: FastText+BiLSTM.](http://arxiv.org/abs/2309.12058) | 本研究提出了一个整合了词嵌入和深度学习技术的高效抗癌肽分类模型，并评估了Word2Vec和FastText作为词嵌入技术，以及CNN、LSTM、BiLSTM作为深度学习模型的性能。 |
| [^27] | [BELT:Bootstrapping Electroencephalography-to-Language Decoding and Zero-Shot Sentiment Classification by Natural Language Supervision.](http://arxiv.org/abs/2309.12056) | BELT是一种通过自然语言监督进行脑电图到语言解码和零样本情感分类的引导式模型和学习框架。它利用现成的大规模预训练语言模型来改进脑电信号的理解，从而推动了大脑-计算机界面的应用和发展。 |
| [^28] | [Uncertainty-driven Exploration Strategies for Online Grasp Learning.](http://arxiv.org/abs/2309.12038) | 本文提出了一种在线抓取学习方法，通过使用有效的探索策略，提高了机器人对未知环境的适应能力和抓取预测的准确性。 |
| [^29] | [Dynamic Hypergraph Structure Learning for Traffic Flow Forecasting.](http://arxiv.org/abs/2309.12028) | 本文提出了一种名为动态超图结构学习(DyHSL)的模型，用于解决交通流量预测问题。该模型利用超图结构信息来建模复杂的交通网络，并且能够捕捉复杂的时空高阶交互作用。 |
| [^30] | [Demystifying Visual Features of Movie Posters for Multi-Label Genre Identification.](http://arxiv.org/abs/2309.12022) | 本研究通过分析电影海报图像，解密了电影海报的视觉特征，并提出了一种自动化的多标签电影类型识别方法，无需使用其他文本或元数据信息，具有推广和营销电影的实际应用意义。 |
| [^31] | [Safe Hierarchical Reinforcement Learning for CubeSat Task Scheduling Based on Energy Consumption.](http://arxiv.org/abs/2309.12004) | 本文提出了一种针对立方卫星任务调度的层次化强化学习方法，通过整合任务优先级排序和能耗预测，实现了一个安全且容错的系统，并在多个立方卫星配置下优于MADDPG模型和传统随机调度。 |
| [^32] | [LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset.](http://arxiv.org/abs/2309.11998) | LMSYS-Chat-1M是一个包含一百万个实际对话的大规模数据集，通过其多样性和用例展示了其在理解和推进LLM能力方面的价值。 |
| [^33] | [Predictability and Comprehensibility in Post-Hoc XAI Methods: A User-Centered Analysis.](http://arxiv.org/abs/2309.11987) | 通过用户研究，分析了后置解释方法中的可理解性和可预测性。发现当解释集中在模型决策边界附近的样本时，SHAP的可理解性显著降低。另外，发现反事实解释和错误分类可以显著提高用户对机器学习模型决策原理的理解。根据研究结果，提出了增强后置解释方法可理解性和可预测性的设计建议。 |
| [^34] | [Representation Abstractions as Incentives for Reinforcement Learning Agents: A Robotic Grasping Case Study.](http://arxiv.org/abs/2309.11984) | 本文研究了不同状态表示对强化学习代理在机器人抓取任务上的影响，结果显示使用数字状态的代理能够在模拟环境中成功解决问题，并在真实机器人上实现了学习策略的可转移性。 |
| [^35] | [Rethinking the Evaluating Framework for Natural Language Understanding in AI Systems: Language Acquisition as a Core for Future Metrics.](http://arxiv.org/abs/2309.11981) | 这篇论文重新思考了人工智能系统中自然语言理解的评估框架，提出了以语言习得为核心的全面框架，旨在解决传统度量方法面临的问题，并借鉴了大型语言模型的进展。 |
| [^36] | [Inferring Capabilities from Task Performance with Bayesian Triangulation.](http://arxiv.org/abs/2309.11975) | 本研究提出了一种使用贝叶斯三角测量方法从任务表现中推断系统能力的方法，并利用该方法推断了不同认知特征的代理。这种能力导向的评估方法对于机器学习模型的表征具有潜在的应用价值。 |
| [^37] | [A Comprehensive Review on Financial Explainable AI.](http://arxiv.org/abs/2309.11960) | 本文回顾了在金融领域中改善深度学习模型可解释性的各种方法，并讨论了相关的挑战和未来发展方向。 |
| [^38] | [On the Definition of Appropriate Trust and the Tools that Come with it.](http://arxiv.org/abs/2309.11937) | 本文讨论了对适当信任的定义，并提出了一种基于定义相似性的评估方法，以增强用户对模型的信任。 |
| [^39] | [Learning to Recover for Safe Reinforcement Learning.](http://arxiv.org/abs/2309.11907) | 该论文提出了一种三阶段的安全强化学习架构，通过学习来构建安全控制器，以在任务训练中确保安全性。为了缓解对抗现象，同时帮助任务策略从高风险状态中恢复，提出了辅助奖励。在机器人导航任务中进行了实验证明。 |
| [^40] | [Unlocking the Heart Using Adaptive Locked Agnostic Networks.](http://arxiv.org/abs/2309.11899) | 使用自适应锁定无知网络（ALAN）进行自我监督训练，生成解剖学上鲁棒的语义自我分割，减少对标记数据的需求。 |
| [^41] | [Audio Contrastive based Fine-tuning.](http://arxiv.org/abs/2309.11895) | 本论文提出了一种基于音频对比的微调方法（AudioConFit），通过借助对比学习的可转移性，该方法在各种音频分类任务中表现出强大的泛化能力，并在不同设置下实现了最先进的结果。 |
| [^42] | [Multi-level Asymmetric Contrastive Learning for Medical Image Segmentation Pre-training.](http://arxiv.org/abs/2309.11876) | 本论文提出了一种针对医学图像分割的自我监督预训练方法，通过多级非对称对比学习的框架，在编码器和解码器同时进行预训练，提供更好的分割模型初始化。 |
| [^43] | [Stochastic stiffness identification and response estimation of Timoshenko beams via physics-informed Gaussian processes.](http://arxiv.org/abs/2309.11875) | 本文提出了一种基于物理信息的高斯过程模型，用于Timoshenko梁的刚度识别和响应估计。通过马尔可夫链蒙特卡洛方法进行贝叶斯优化，得到结构参数的随机模型。模型还可用于概率预测未观测到的响应，并提出了一种基于熵的传感器布置优化方法。 |
| [^44] | [OSNet & MNetO: Two Types of General Reconstruction Architectures for Linear Computed Tomography in Multi-Scenarios.](http://arxiv.org/abs/2309.11858) | 本论文提出了两种通用的线性计算机断层扫描的重建架构（OSNet和MNetO），旨在解决在LCT中实现稳定内部重建和避免希尔伯特滤波旋转操作的问题。 |
| [^45] | [BitCoin: Bidirectional Tagging and Supervised Contrastive Learning based Joint Relational Triple Extraction Framework.](http://arxiv.org/abs/2309.11853) | BitCoin是一种创新的基于双向标记和监督对比学习的联合关系三元组提取框架，用于解决关系三元组提取中的问题和局限性。通过设计监督对比学习方法，考虑了每个锚点的多个正例，提高了提取的效果。 |
| [^46] | [Evaluating Large Language Models for Document-grounded Response Generation in Information-Seeking Dialogues.](http://arxiv.org/abs/2309.11838) | 本文研究了在信息搜索对话中使用大型语言模型进行基于文档的响应生成，并通过人工评估了其性能。 |
| [^47] | [Multimodal Transformers for Wireless Communications: A Case Study in Beam Prediction.](http://arxiv.org/abs/2309.11811) | 本文提出了一种多模态变压器深度学习框架，用于无线通信中的波束预测。该框架通过利用相机、LiDAR、雷达和GPS等多种感知信息，提取并学习不同模态和时间实例之间的特征关系，从而在波束管理中具有较好的性能。 |
| [^48] | [JobRecoGPT -- Explainable job recommendations using LLMs.](http://arxiv.org/abs/2309.11805) | JobRecoGPT是一个使用LLMs实现的可解释的职位推荐系统，在处理职位描述和简历中的非结构化数据时，它能够捕捉到之前丢失的信息。 |
| [^49] | [DimCL: Dimensional Contrastive Learning For Improving Self-Supervised Learning.](http://arxiv.org/abs/2309.11782) | DimCL是一种在自监督学习中改进特征多样性的维度对比学习方法。实验证明DimCL的硬样本特性是成功的关键因素。将DimCL融入SSL框架可以提高性能。 |
| [^50] | [2DDATA: 2D Detection Annotations Transmittable Aggregation for Semantic Segmentation on Point Cloud.](http://arxiv.org/abs/2309.11755) | 本论文提出了2DDATA方法，通过引入数据特定的分支和利用RGB模态信息，解决了多模态信息融合的问题，并证明了大型多模态模型融合的可行性。 |
| [^51] | [Improve the efficiency of deep reinforcement learning through semantic exploration guided by natural language.](http://arxiv.org/abs/2309.11753) | 通过自然语言引导的语义探索，提高深度强化学习的效率。通过检索语料库中相关问题来与"神"级存在交互，更新代理的策略。 |
| [^52] | [How Robust is Google's Bard to Adversarial Image Attacks?.](http://arxiv.org/abs/2309.11751) | 本文研究了Google的Bard在对抗图像攻击方面的鲁棒性，并发现它可以被攻击以输出错误的图像描述。这一攻击还可以对其他多模态语言模型产生影响。研究还发现了Bard的两种防御机制。 |
| [^53] | [Choice-75: A Dataset on Decision Branching in Script Learning.](http://arxiv.org/abs/2309.11737) | Choice-75是一个关于脚本学习中决策分支的数据集，主要挑战智能系统在描述场景下预测决策。在许多难题中仍有改进的空间。 |
| [^54] | [FluentEditor: Text-based Speech Editing by Considering Acoustic and Prosody Consistency.](http://arxiv.org/abs/2309.11725) | 这篇论文提出了一种名为"FluentEditor"的流畅语音编辑模型，通过考虑流畅度意识的训练准则实现文本化语音编辑。其中，声学一致性约束和韵律一致性约束用于保持语音的流畅性和整体风格一致性。 |
| [^55] | [Emotion-Aware Prosodic Phrasing for Expressive Text-to-Speech.](http://arxiv.org/abs/2309.11724) | 这项研究提出了一种称为“EmoPP”的情感感知韵律短语模型，通过准确挖掘话语中的情感线索，预测适当的断点，从而改进了表情化文本转语音的性能和情感表达。 |
| [^56] | [A Dynamic Domain Adaptation Deep Learning Network for EEG-based Motor Imagery Classification.](http://arxiv.org/abs/2309.11714) | 本文提出了一种动态领域适应深度学习网络，用于解决基于EEG的运动想象分类中的通道相关性和个体差异问题。 |
| [^57] | [RAI4IoE: Responsible AI for Enabling the Internet of Energy.](http://arxiv.org/abs/2309.11691) | 本文旨在开发一个RAl4IoE框架，将能源互联网与人工智能技术相结合，实现公平、可持续和可靠的能源分配。 |
| [^58] | [LLM Guided Inductive Inference for Solving Compositional Problems.](http://arxiv.org/abs/2309.11688) | LLM引导的归纳推理方法REBEL通过递归问题分解和利用外部工具进行推理，能够解决组合问题和对话环境中的深度推理任务。 |
| [^59] | [Dr. FERMI: A Stochastic Distributionally Robust Fair Empirical Risk Minimization Framework.](http://arxiv.org/abs/2309.11682) | 本文提出了一个基于随机分布鲁棒的公平性框架，解决了训练和测试数据分布不一致时公平模型表现不准确的问题，并且不需要知道因果图，也支持使用小批量数据。 |
| [^60] | [Federated Learning with Neural Graphical Models.](http://arxiv.org/abs/2309.11680) | 本研究提出了一种名为FedNGMs的联邦学习框架，利用概率神经图模型来处理多个客户端的数据，并在保持训练数据私密性的同时提升模型准确性。 |
| [^61] | [Generative AI in Mafia-like Game Simulation.](http://arxiv.org/abs/2309.11672) | 本研究探索了在污腐式游戏模拟中使用生成式人工智能模型的效果和潜力。通过对比GPT-4和GPT-3.5-turbo，在游戏环境中GPT-4展示出更好的适应性和更人类化的反应，但其在虚张声势和预测对手行动方面仍存在挑战。这些发现表明，尽管GPT-4有进一步发展的潜力，但仍需注入更多创新性和挑战性的元素。 |
| [^62] | ["It's a Fair Game'', or Is It? Examining How Users Navigate Disclosure Risks and Benefits When Using LLM-Based Conversational Agents.](http://arxiv.org/abs/2309.11653) | 本研究通过分析用户在实际对话中的敏感披露和采访LLM型对话型智能助手用户的方式，发现用户在使用LLM型对话型智能助手时面临隐私、效用和便利之间的权衡，但用户对隐私风险的认知存在问题，而人类化的互动鼓励了更多敏感的披露，加重了用户的权衡困难。 |
| [^63] | [Orbital AI-based Autonomous Refuelling Solution.](http://arxiv.org/abs/2309.11648) | 本文介绍了一种基于人工智能的导航算法，旨在通过使用轨道上的可见波长摄像头作为主要传感器，减少对激光雷达的依赖，并大大降低成本。 |
| [^64] | [Attentive VQ-VAE.](http://arxiv.org/abs/2309.11641) | 本研究提出了一种增强VQ-VAE模型能力的新方法，通过整合Attentive Residual Encoder和Residual Pixel Attention层，利用像素间的自我注意机制来高效地捕捉和利用潜在向量之间的上下文信息，并使用额外的编码级别来进一步增强模型的表示能力，在实验中取得了显著的性能改进。 |
| [^65] | [Cloud-Based Hierarchical Imitation Learning for Scalable Transfer of Construction Skills from Human Workers to Assisting Robots.](http://arxiv.org/abs/2309.11619) | 这项研究提出了一种基于云的层次化模仿学习的方法，用于将人类工人的施工技能转移到辅助机器人，并提出了一个沉浸式虚拟演示框架，用于提高施工效率。 |
| [^66] | [Hand Gesture Recognition with Two Stage Approach Using Transfer Learning and Deep Ensemble Learning.](http://arxiv.org/abs/2309.11610) | 本研究使用迁移学习和深度集成学习的两阶段方法对手势进行识别，通过评估不同模型在HG14数据集上的准确率，发现VGGNet和MobileNet模型的版本表现最好。 |
| [^67] | [Dataset Factory: A Toolchain For Generative Computer Vision Datasets.](http://arxiv.org/abs/2309.11608) | 提出了一个"数据集工厂"的方法，将计算机视觉数据集的存储和处理与元数据分开，并为机器学习团队和个人研究人员提供了规模化的数据中心操作。 |
| [^68] | [CATS: Conditional Adversarial Trajectory Synthesis for Privacy-Preserving Trajectory Data Publication Using Deep Learning Approaches.](http://arxiv.org/abs/2309.11587) | CATS是一种基于深度学习的地理人工智能方法，用于隐私保护轨迹数据的生成和发布。它采用K-匿名技术保障了分布级隐私，通过条件对抗训练和循环二部图匹配等方法实现了高质量轨迹数据的合成和重构。 |
| [^69] | [Distilling Adversarial Prompts from Safety Benchmarks: Report for the Adversarial Nibbler Challenge.](http://arxiv.org/abs/2309.11575) | 本研究为Adversarial Nibbler挑战提供了一个大型的潜在对抗输入集合，并通过对提示和图像的分析揭示了当前生成图像模型中的系统性安全问题。 |
| [^70] | [BTLM-3B-8K: 7B Parameter Performance in a 3B Parameter Model.](http://arxiv.org/abs/2309.11568) | BTLM-3B-8K是一个30亿参数的开源语言模型，相对于其他30亿和70亿参数模型，它在下游任务中表现出2-5.5%的性能提升，同时在长文本任务上也具有出色的表现。这种将70亿参数的模型压缩到30亿参数，并且性能几乎没有受到影响的方法具有重要意义。 |
| [^71] | [Learning Complete Topology-Aware Correlations Between Relations for Inductive Link Prediction.](http://arxiv.org/abs/2309.11528) | 本文提出了一种基于子图的方法TACO，用于建模高度与拓扑结构相关的关系之间的拓扑感知相关性，并展示了这种方法对于实体无关的归纳链接预测任务的潜力。 |
| [^72] | [TrueLearn: A Python Library for Personalised Informational Recommendations with (Implicit) Feedback.](http://arxiv.org/abs/2309.11527) | TrueLearn是一个Python库，用于构建个性化的信息推荐系统，并提供了丰富的文档和编码示例，可帮助开发人员和从业者使用。它采用了开放学习者的概念和人性化的用户表达方式，同时支持用户可视化和模型性能评估。 |
| [^73] | [When is a Foundation Model a Foundation Model.](http://arxiv.org/abs/2309.11510) | 这项研究发现，通过对基础模型进行微调，使用在线数据源的图片进行图像-文本建模在医学领域具有潜力。然而，这些基础模型在数字病理学的检索任务中表现不如传统的深度网络。 |
| [^74] | [Towards LLM-based Autograding for Short Textual Answers.](http://arxiv.org/abs/2309.11508) | 本文评估了大型语言模型（LLMs）在自动评分中的应用，并强调了它们如何支持教育工作者验证评分程序。研究结果表明，“开箱即用”的LLMs作为补充视角提供了有价值的工具，但仍需进一步优化其可用性和性能。 |
| [^75] | [Matching Table Metadata with Business Glossaries Using Large Language Models.](http://arxiv.org/abs/2309.11506) | 本研究探讨了将表元数据与业务词汇进行匹配的问题，通过匹配可以在不请求访问数据内容之前或之后，有效利用可用的业务词汇进行检索和分析。 |
| [^76] | [Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning.](http://arxiv.org/abs/2309.11489) | Text2Reward是一个无需数据的自动化框架，可以根据大型语言模型自动生成可解释、自由形式的密集奖励函数，广泛适用于各种任务，并允许人类反馈进行迭代改进。 |
| [^77] | [You Only Look at Screens: Multimodal Chain-of-Action Agents.](http://arxiv.org/abs/2309.11436) | 本论文提出了一种名为Auto-UI的多模态动作链机器人，通过直接与界面交互，避免了环境解析或依赖于应用程序API的需要，并引入了动作链技术来帮助模型进行决策。 |
| [^78] | [Gold-YOLO: Efficient Object Detector via Gather-and-Distribute Mechanism.](http://arxiv.org/abs/2309.11331) | 本研究提出了Gold-YOLO模型，通过先进的收集和分发机制（GD）机制以及MAE风格的预训练，解决了YOLO系列模型中的信息融合问题，实现了高效的目标检测和多尺度特征融合。 |
| [^79] | [Retrieve-Rewrite-Answer: A KG-to-Text Enhanced LLMs Framework for Knowledge Graph Question Answering.](http://arxiv.org/abs/2309.11206) | 提出了一种提高知识图谱问答任务性能的增强型LLMs框架，通过转化KG知识为文本化陈述的方式，实现了对答案敏感的KG-to-Text方法。 |
| [^80] | [Contrastive Pseudo Learning for Open-World DeepFake Attribution.](http://arxiv.org/abs/2309.11132) | 这项研究提出了一种对开放世界深度伪造归因任务的新框架，并引入了一个评估归因性能的新基准。该框架通过引入全局-局部投票模块和设计置信度-based的软伪标签策略来提高归因准确性，并缓解相似造成的伪噪声。 |
| [^81] | [A Cognitively-Inspired Neural Architecture for Visual Abstract Reasoning Using Contrastive Perceptual and Conceptual Processing.](http://arxiv.org/abs/2309.10532) | 基于人类认知启发，我们提出了一种新的神经结构，用于解决视觉抽象推理任务。该架构通过追求感知和概念处理之间的一致性，采用迭代、自对比的学习过程来模拟人类的认知过程。实验证明，该网络在RAVEN数据集上实现了比之前所有模型更高的准确性，并且使用了最弱的归纳偏置。我们还指出了原始数据集中存在的类不平衡问题，并提出了解决方案。 |
| [^82] | [Causal-Story: Local Causal Attention Utilizing Parameter-Efficient Tuning For Visual Story Synthesis.](http://arxiv.org/abs/2309.09553) | 提出了一种称为因果故事的新模型，利用局部因果注意力机制来改进视觉故事合成的全局一致性，该模型考虑了历史标题、帧和当前标题之间的因果关系，实现了更好的生成效果。 |
| [^83] | [FedGKD: Unleashing the Power of Collaboration in Federated Graph Neural Networks.](http://arxiv.org/abs/2309.09517) | FedGKD是一种新颖的联邦图神经网络框架，通过利用客户端图数据集蒸馏方法提取更好的任务特征并引入感知全局协作结构的服务器端聚合机制，解决了联邦GNN系统中图异构性问题，提高了效率和准确性。 |
| [^84] | [Compositional Foundation Models for Hierarchical Planning.](http://arxiv.org/abs/2309.08587) | 本研究提出了一种基于组合式基础模型的层次规划方法，通过利用语言、视觉和动作数据的多个专家模型，解决了长期目标任务。通过符号计划、视频扩散和逆动力学模型的结合，实现了在新环境中做出有效决策的能力。 |
| [^85] | [ConDA: Contrastive Domain Adaptation for AI-generated Text Detection.](http://arxiv.org/abs/2309.03992) | 创新点：提出了一种基于对比域适应的框架 ConDA，用于检测由大型语言模型生成的新闻文本。这种方法解决了获取标记训练数据的困难，通过利用未标记的目标数据进行无监督域适应。 |
| [^86] | [Bayesian Flow Networks.](http://arxiv.org/abs/2308.07037) | 本文介绍了贝叶斯流网络（BFNs），一种新的生成模型，它通过贝叶斯推断修改了一组独立分布的参数，并将其作为输入传递给神经网络来生成另一个相互依赖的分布。该方法不需要前向过程，适用于连续和离散数据，并具有优化数据压缩的功能。 |
| [^87] | [PubMed and Beyond: Recent Advances and Best Practices in Biomedical Literature Search.](http://arxiv.org/abs/2307.09683) | 本论文总结了生物医学文献检索领域的最新进展和最佳实践，介绍了针对不同生物医学信息需求的文献检索工具，并旨在帮助读者高效满足其信息需求。 |
| [^88] | [Synthetic is all you need: removing the auxiliary data assumption for membership inference attacks against synthetic data.](http://arxiv.org/abs/2307.01701) | 这项研究提出了一种新方法，移除了成员推断攻击对辅助数据的假设，使用只有合成数据的情况下仍然能够成功进行成员推断攻击。 |
| [^89] | [$\lambda$-AC: Learning latent decision-aware models for reinforcement learning in continuous state-spaces.](http://arxiv.org/abs/2306.17366) | 这项研究提出了一种$\lambda$-AC算法，通过学习连续状态空间中的潜在决策感知模型，实现了决策驱动的强化学习。通过理论和实证研究，确定了决策感知强化学习模型的必要组成部分，并展示了设计选择对算法性能的重要影响。 |
| [^90] | [HNO: Hyena Neural Operator for solving PDEs.](http://arxiv.org/abs/2306.16524) | 本研究使用了一种名为鬣狗的新型神经算子，它利用多层感知器参数化的长卷积滤波器来解决PDE问题。这种方法通过增强模型对输入上下文的理解，并为不同的PDE实例提供数据依赖权重，提供了一种有效的求解PDE的方式。 |
| [^91] | [A Self-supervised Contrastive Learning Method for Grasp Outcomes Prediction.](http://arxiv.org/abs/2306.14437) | 本文研究了一种自监督对比学习方法，能够有效预测抓取结果，通过公开可用的数据集的验证，证明该方法在抓取结果预测任务上表现良好，超过其他无监督方法，揭示了对比学习方法在机器人抓取领域的潜力和准确的抓取预测对于实现稳定抓取的重要性。 |
| [^92] | [Achilles' Heels: Vulnerable Record Identification in Synthetic Data Publishing.](http://arxiv.org/abs/2306.10308) | 本论文提出了基于合成数据发布的易受攻击记录识别技术，通过利用记录与最近邻之间的距离，优于以前的方法，并具有鲁棒性。 |
| [^93] | [Prodigy: An Expeditiously Adaptive Parameter-Free Learner.](http://arxiv.org/abs/2306.06101) | 本文提出了一种基于自适应算法(如Adagrad和Adam)的学习率估计方法Prodigy和Resetting，可以快速且正确地估计到达解决方案所需的距离D，从而提高了模型的收敛速度，并在多个数据集和模型上进行了测试，实验表明该方法优于D-Adaptation并可达到手动调整Adam的测试准确度值。 |
| [^94] | [Can large language models generate salient negative statements?.](http://arxiv.org/abs/2305.16755) | 本研究探讨了大型语言模型生成真实实体的显著负面陈述的能力，在不同领域中进行了评估，结果发现大型语言模型在处理否定陈述中的事实概念上仍有困难。 |
| [^95] | [Semantic-aware Transmission Scheduling: a Monotonicity-driven Deep Reinforcement Learning Approach.](http://arxiv.org/abs/2305.13706) | 这篇论文提出了一种基于单调性驱动的深度强化学习算法，用于处理在6G时代物联网系统中的大规模语义感知传输调度问题。数值结果显示所提出的算法相比基准算法可以大大减少训练时间并提高训练性能。 |
| [^96] | [Transforming Geospatial Ontologies by Homomorphisms.](http://arxiv.org/abs/2305.13135) | 本文研究了地理空间本体系统的同态变换。通过定义同态映射，我们将地理空间本体系统的合并、偏序关系和闭包进行了转化。 |
| [^97] | [AWFSD: Accelerated Wirtinger Flow with Score-based Diffusion Image Prior for Poisson-Gaussian Holographic Phase Retrieval.](http://arxiv.org/abs/2305.07712) | 本文提出了一种名为AWFSD的算法，它基于评分扩散模型作为生成先验，用于解决在实际场景中，由光学成像系统引起的测量数据被混合的泊松和高斯噪声（PG噪声）所破坏的全息相位恢复问题，并且比现有方法具有更优的性能。 |
| [^98] | [CoDi: Co-evolving Contrastive Diffusion Models for Mixed-type Tabular Synthesis.](http://arxiv.org/abs/2304.12654) | CoDi 方法使用两个共同演化的对比扩散模型单独处理离散和连续变量并相互条件化，同时引入对比学习方法进行进一步的绑定，展现了在真实世界的表格数据集上的有效性。 |
| [^99] | [Ensuring Trustworthy Medical Artificial Intelligencethrough Ethical and Philosophical Principles.](http://arxiv.org/abs/2304.11530) | 本文讨论了人工智能在医疗保健中的应用和考虑伦理和哲学原则以确保可靠的人工智能工具的重要性。人工智能在医疗中带来了更多挑战，必须解决偏见、透明度、自主权、责任和问责制等问题，作者提出了可能的解决办法。 |
| [^100] | [A Graph Neural Network Approach to Nanosatellite Task Scheduling: Insights into Learning Mixed-Integer Models.](http://arxiv.org/abs/2303.13773) | 本研究提出基于GNN的纳米卫星任务调度方法，以更好地优化服务质量，解决ONTS问题的复杂性。 |
| [^101] | [ERNIE-Music: Text-to-Waveform Music Generation with Diffusion Models.](http://arxiv.org/abs/2302.04456) | 本文提出了ERNIE-Music，一种基于扩散模型的文本到波形音乐生成模型。通过创新地利用自由形式的文本提示作为条件因素，我们成功实现了从文本到音乐波形的生成。通过利用网络资源构建数据集并采用弱监督技术，我们解决了有限的文本-音乐平行数据的挑战。我们还对比了两种不同的文本条件格式的有效性，为该领域的研究提供了实证结果。 |
| [^102] | [A Survey on Transformers in Reinforcement Learning.](http://arxiv.org/abs/2301.03044) | 这篇论文是一项调查研究，总结了在强化学习领域使用Transformers的动机、进展和未来前景。 |
| [^103] | [Towards Cooperative Flight Control Using Visual-Attention.](http://arxiv.org/abs/2212.11084) | 该论文提出了一种基于视觉注意力的协同飞行控制系统，通过眼球追踪和神经控制系统之间的合作，实现了飞行员和自动驾驶系统的并行自主。根据注意力特征的差异，系统可以让飞行员或自动驾驶系统来进行控制决策。 |
| [^104] | [Analysis and Comparison of Classification Metrics.](http://arxiv.org/abs/2209.05355) | 本文回顾并比较了常用于度量分类系统表现的各种指标，发现期望成本指标具有更广泛的适用性和直观性，并可用于解决从连续得分生成分类决策的实践问题。 |
| [^105] | [Read the Room: Adapting a Robot's Voice to Ambient and Social Contexts.](http://arxiv.org/abs/2205.04952) | 本研究描述了一种选择机器人语音风格的过程和结果，以达到社交适应性和环境感知。通过在虚拟环境中收集和验证语音数据交互，并使用投影、灯光和声音在重新创造的环境中测试机器人的语音风格，我们探索和聚类人类的语音话语以识别主要的语音风格，并以餐饮服务场景作为概念验证环境。结果表明，这种研究可以改善机器人在特定语境下的社交适应性和智能感知。 |
| [^106] | [Optimal Propagation for Graph Neural Networks.](http://arxiv.org/abs/2205.02998) | 本文提出了一种双层优化方法，通过学习个性化PageRank传播矩阵和下游半监督节点分类，来学习最优的图结构。该方法在实证评估中展现了优越的功效和鲁棒性。 |
| [^107] | [Survey of Aspect-based Sentiment Analysis Datasets.](http://arxiv.org/abs/2204.05232) | 本研究汇总了65个公开可用的ABSA数据集，包括45个英文数据集和20个其他语言数据集，提供了一个可以用于训练和评估自主ABSA系统的数据库。 |
| [^108] | [VisEvent: Reliable Object Tracking via Collaboration of Frame and Event Flows.](http://arxiv.org/abs/2108.05015) | 本论文提出了一个大规模的可见-事件基准（VisEvent），通过可见摄像机和事件摄像机的协作，实现了更可靠的物体跟踪。根据VisEvent，我们将事件流转化为事件图像，并构建了30多个... |

# 详细

[^1]: ForceSight: 使用文本引导的视觉力导向移动操作

    ForceSight: Text-Guided Mobile Manipulation with Visual-Force Goals. (arXiv:2309.12312v1 [cs.RO])

    [http://arxiv.org/abs/2309.12312](http://arxiv.org/abs/2309.12312)

    ForceSight是一个使用文本引导的移动操作系统，通过深度神经网络预测视觉力导向目标。在实验中，该系统展示了在未见环境中进行精确抓取、抽屉打开和物体交接等任务的能力，并取得了较高的成功率。

    

    我们提出了一个名为ForceSight的系统，它使用深度神经网络通过文本引导来预测视觉力导向的目标。给定一张RGBD图片和一个文本提示，ForceSight可以确定相机坐标系下的目标末端执行器位姿（运动目标）和相关的力量（力量目标）。这两个组成部分共同形成了一个视觉力导向目标。之前的研究已经表明，输出人可解释的运动目标的深度模型可以实现真实机器人的巧妙操作。力量在操作中至关重要，但在这些系统中通常被限制在较低层次的执行中。当应用于带有手臂和眼睛的移动操作装置的ForceSight时，在与训练数据差异显著的未见环境中，能够以81%的成功率完成诸如精确抓取、抽屉打开和物体交接等任务。在另一项独立实验中，ForceSight仅使用视觉伺服，不考虑力量信息，但依然显示出较高的操作成功率。

    We present ForceSight, a system for text-guided mobile manipulation that predicts visual-force goals using a deep neural network. Given a single RGBD image combined with a text prompt, ForceSight determines a target end-effector pose in the camera frame (kinematic goal) and the associated forces (force goal). Together, these two components form a visual-force goal. Prior work has demonstrated that deep models outputting human-interpretable kinematic goals can enable dexterous manipulation by real robots. Forces are critical to manipulation, yet have typically been relegated to lower-level execution in these systems. When deployed on a mobile manipulator equipped with an eye-in-hand RGBD camera, ForceSight performed tasks such as precision grasps, drawer opening, and object handovers with an 81% success rate in unseen environments with object instances that differed significantly from the training data. In a separate experiment, relying exclusively on visual servoing and ignoring force 
    
[^2]: LLM-Grounder: 利用大型语言模型作为代理的开放词汇3D视觉定位

    LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent. (arXiv:2309.12311v1 [cs.CV])

    [http://arxiv.org/abs/2309.12311](http://arxiv.org/abs/2309.12311)

    LLM-Grounder是一种零样本、开放词汇的基于大型语言模型的3D视觉定位流程，通过利用语言模型分解查询并使用视觉定位工具识别物体，实现了在没有标记训练数据的情况下对新场景和文本查询的有效定位。在ScanRefer基准上取得了最先进的零样本定位准确性。

    

    3D视觉定位是家用机器人的重要能力，可以使其在环境中导航、操作物体并根据环境回答问题。现有的方法通常依赖于大量标记的数据，或者在处理复杂语言查询时存在一定限制。我们提出了LLM-Grounder，一种新颖的零样本、开放词汇的基于大型语言模型的3D视觉定位流程。LLM-Grounder利用一个LLM将复杂的自然语言查询分解为语义成分，并使用诸如OpenScene或LERF之类的视觉定位工具来识别3D场景中的物体。然后，LLM评估所提出的物体之间的空间和常识关系，以做出最终的定位决策。我们的方法不需要任何标记的训练数据，并且可以推广到新的3D场景和任意文本查询。我们在ScanRefer基准上评估了LLM-Grounder，并展示了最先进的零样本定位准确性。我们的研究结果表明LLMs在3D视觉定位中的有效性。

    3D visual grounding is a critical skill for household robots, enabling them to navigate, manipulate objects, and answer questions based on their environment. While existing approaches often rely on extensive labeled data or exhibit limitations in handling complex language queries, we propose LLM-Grounder, a novel zero-shot, open-vocabulary, Large Language Model (LLM)-based 3D visual grounding pipeline. LLM-Grounder utilizes an LLM to decompose complex natural language queries into semantic constituents and employs a visual grounding tool, such as OpenScene or LERF, to identify objects in a 3D scene. The LLM then evaluates the spatial and commonsense relations among the proposed objects to make a final grounding decision. Our method does not require any labeled training data and can generalize to novel 3D scenes and arbitrary text queries. We evaluate LLM-Grounder on the ScanRefer benchmark and demonstrate state-of-the-art zero-shot grounding accuracy. Our findings indicate that LLMs si
    
[^3]: 演练：通过模拟冲突来教授冲突解决方法

    Rehearsal: Simulating Conflict to Teach Conflict Resolution. (arXiv:2309.12309v1 [cs.HC])

    [http://arxiv.org/abs/2309.12309](http://arxiv.org/abs/2309.12309)

    演练是一个系统，通过模拟冲突和提供反馈，教授用户冲突解决的技能。利用演练，用户可以练习处理各种冲突场景，并学习如何运用冲突策略。

    

    人际冲突是一种令人不舒服但不可避免的生活事实。成功地处理冲突是一种技能，可以通过刻意练习来学习，但是很少有人能够获得有效的培训或反馈。为了扩大这种机会，我们介绍了演练（Rehearsal）系统，该系统允许用户与可信的模拟对话者一起排练冲突，探索如果情况如何的“假设”场景以识别替代的对话路径，并通过反馈学习何时以及如何应用特定的冲突策略。用户可以使用演练来练习处理各种已定义的冲突场景，从办公室争议到情感问题，或者他们也可以选择创建自己的冲突场景。为了实现演练，我们开发了IRP提示方法，该方法通过冲突解决中具有影响力的利益-权力-能力（IRP）理论来调节大型语言模型的输出。演练使用IRP生成基于冲突解决理论的话语，引导用户实践应用冲突解决策略。

    Interpersonal conflict is an uncomfortable but unavoidable fact of life. Navigating conflict successfully is a skill -- one that can be learned through deliberate practice -- but few have access to effective training or feedback. To expand this access, we introduce Rehearsal, a system that allows users to rehearse conflicts with a believable simulated interlocutor, explore counterfactual "what if?" scenarios to identify alternative conversational paths, and learn through feedback on how and when to apply specific conflict strategies. Users can utilize Rehearsal to practice handling a variety of predefined conflict scenarios, from office disputes to relationship issues, or they can choose to create their own. To enable Rehearsal, we develop IRP prompting, a method of conditioning output of a large language model on the influential Interest-Rights-Power (IRP) theory from conflict resolution. Rehearsal uses IRP to generate utterances grounded in conflict resolution theory, guiding users t
    
[^4]: LongLoRA: 高效的长上下文大型语言模型的精细调整

    LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models. (arXiv:2309.12307v1 [cs.CL])

    [http://arxiv.org/abs/2309.12307](http://arxiv.org/abs/2309.12307)

    LongLoRA是一种高效的精细调整方法，可以在有限的计算成本下扩展预训练的大型语言模型的上下文大小。它通过稀疏的局部注意力实现精细调整，并使用移动短注意力有效实现上下文扩展，与传统方法具有相似的性能。

    

    我们提出了一种高效的精细调整方法——LongLoRA，可以在有限的计算成本下扩展预训练的大型语言模型(LLM)的上下文大小。通常，使用长上下文大小训练LLM的计算成本很高，需要大量的训练时间和GPU资源。本文中，我们在两个方面加快了LLM的上下文扩展。一方面，尽管推理过程中需要稠密的全局注意力，但模型的精细调整可以通过稀疏的局部注意力有效且高效地完成。所提出的移动短注意力有效地实现了上下文的扩展，在与使用传统注意力进行精细调整时具有相似的性能，同时可以在训练中只用两行代码实现，在推理中是可选的。另一方面，我们重新审视了参数效率问题。

    We present LongLoRA, an efficient fine-tuning approach that extends the context sizes of pre-trained large language models (LLMs), with limited computation cost. Typically, training LLMs with long context sizes is computationally expensive, requiring extensive training hours and GPU resources. For example, training on the context length of 8192 needs 16x computational costs in self-attention layers as that of 2048. In this paper, we speed up the context extension of LLMs in two aspects. On the one hand, although dense global attention is needed during inference, fine-tuning the model can be effectively and efficiently done by sparse local attention. The proposed shift short attention effectively enables context extension, leading to non-trivial computation saving with similar performance to fine-tuning with vanilla attention. Particularly, it can be implemented with only two lines of code in training, while being optional in inference. On the other hand, we revisit the parameter-effici
    
[^5]: 环境偏向特征排序用于鲁棒性的新颖性检测

    Environment-biased Feature Ranking for Novelty Detection Robustness. (arXiv:2309.12301v1 [cs.LG])

    [http://arxiv.org/abs/2309.12301](http://arxiv.org/abs/2309.12301)

    本文提出了一种环境偏向特征排序的方法，用于鲁棒性的新颖性检测。通过计算特征的环境之间分布方差进行评分，并通过去除高分特征来改善性能。这种方法在真实和合成基准数据上均能提高性能。

    

    我们解决了鲁棒性新颖性检测的问题，在该问题中，我们旨在检测语义内容方面的新颖性，同时对其他无关因素的变化具有不变性。具体来说，我们在具有多个环境的设置中操作，确定与环境更相关而不是任务相关内容的特征集合。因此，我们提出了一种方法，该方法从预训练的嵌入和多环境设置开始，成功根据其环境关注度对特征进行排序。首先，我们基于环境之间的特征分布方差计算每个特征的得分。接下来，我们证明通过舍弃得分较高的特征，我们可以去除虚假的相关性，并在正态协方差和子种群转移的情况下提高整体性能，无论是对于真实的还是对于我们为此任务引入的合成基准数据。

    We tackle the problem of robust novelty detection, where we aim to detect novelties in terms of semantic content while being invariant to changes in other, irrelevant factors. Specifically, we operate in a setup with multiple environments, where we determine the set of features that are associated more with the environments, rather than to the content relevant for the task. Thus, we propose a method that starts with a pretrained embedding and a multi-env setup and manages to rank the features based on their environment-focus. First, we compute a per-feature score based on the feature distribution variance between envs. Next, we show that by dropping the highly scored ones, we manage to remove spurious correlations and improve the overall performance by up to 6%, both in covariance and sub-population shift cases, both for a real and a synthetic benchmark, that we introduce for this task.
    
[^6]: See to Touch: 通过视觉激励学习触觉灵巧性

    See to Touch: Learning Tactile Dexterity through Visual Incentives. (arXiv:2309.12300v1 [cs.RO])

    [http://arxiv.org/abs/2309.12300](http://arxiv.org/abs/2309.12300)

    本文提出了一种通过视觉激励优化触觉策略的框架，以增强多指机器人的触觉灵巧性，并在多个挑战性任务中取得了良好的效果。

    

    为了实现人类擅长的精确、富有接触、灵巧的操作，为多指机器人配备触觉传感至关重要。然而，仅依靠触觉传感无法提供足够的线索来推理物体的空间配置，从而限制了纠正错误和适应变化情况的能力。本文提出了一种新的框架——通过视觉激励实现触觉适应（TAVI），通过使用基于视觉奖励的优化触觉策略来增强基于触觉的灵巧性。首先，我们使用对比性目标来学习视觉表示。接下来，我们利用这些视觉表示通过基于最优传输匹配的方式构建奖励函数，其中参考一个人类示范。最后，我们利用在线强化学习来优化机器人上基于触觉的策略，以最大化视觉奖励。在六个具有挑战性的任务中，如插销拿取、卸下碗和翻转细长物体等，TAVI取得了不错的成绩。

    Equipping multi-fingered robots with tactile sensing is crucial for achieving the precise, contact-rich, and dexterous manipulation that humans excel at. However, relying solely on tactile sensing fails to provide adequate cues for reasoning about objects' spatial configurations, limiting the ability to correct errors and adapt to changing situations. In this paper, we present Tactile Adaptation from Visual Incentives (TAVI), a new framework that enhances tactile-based dexterity by optimizing dexterous policies using vision-based rewards. First, we use a contrastive-based objective to learn visual representations. Next, we construct a reward function using these visual representations through optimal-transport based matching on one human demonstration. Finally, we use online reinforcement learning on our robot to optimize tactile-based policies that maximize the visual reward. On six challenging tasks, such as peg pick-and-place, unstacking bowls, and flipping slender objects, TAVI ach
    
[^7]: 学习驾驶到任何地方

    Learning to Drive Anywhere. (arXiv:2309.12295v1 [cs.CV])

    [http://arxiv.org/abs/2309.12295](http://arxiv.org/abs/2309.12295)

    本文提出了一种能够学习适应不同地理位置和驾驶行为的模型，该模型通过引入基于地理位置的通道注意机制，在数据驱动的方式下高效地学习并灵活地建模不同地区之间的相似性和差异性。

    

    人类驾驶员可以无缝地适应不同地理位置的驾驶决策，包括不同的道路条件和交通规则，例如左驾驶和右驾驶。然而，现有的自动驾驶模型只能在限定的操作领域内部署，不能考虑不同地理位置之间的驾驶行为差异和模型的可扩展性。本文提出了AnyD，一种单一的具有地理感知的条件性模仿学习（CIL）模型，能够高效地从具有动态环境、交通和社会特征的异构和全球分布的数据中进行学习。我们的关键见解是引入一个高容量的基于地理位置的通道注意机制，可以在数据驱动的方式下有效地适应本地细微差异并灵活地建模不同地区之间的相似性。通过优化对比性模仿目标，我们提出的方法可以高效地适应固有的不平衡数据分布和地理位置差异。

    Human drivers can seamlessly adapt their driving decisions across geographical locations with diverse conditions and rules of the road, e.g., left vs. right-hand traffic. In contrast, existing models for autonomous driving have been thus far only deployed within restricted operational domains, i.e., without accounting for varying driving behaviors across locations or model scalability. In this work, we propose AnyD, a single geographically-aware conditional imitation learning (CIL) model that can efficiently learn from heterogeneous and globally distributed data with dynamic environmental, traffic, and social characteristics. Our key insight is to introduce a high-capacity geo-location-based channel attention mechanism that effectively adapts to local nuances while also flexibly modeling similarities among regions in a data-driven manner. By optimizing a contrastive imitation objective, our proposed approach can efficiently scale across inherently imbalanced data distributions and loca
    
[^8]: 翻转诅咒: 在大型语言模型中训练的"A是B"无法学习"B是A"

    The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A". (arXiv:2309.12288v1 [cs.CL])

    [http://arxiv.org/abs/2309.12288](http://arxiv.org/abs/2309.12288)

    LLMs模型在训练中只能学习到"A是B"的结构，无法自动推广到"B是A"。这表明模型在逻辑推断上存在基本失败和训练集中模式的推广问题。

    

    我们揭示了自回归大型语言模型（LLM）在泛化上的令人惊讶的失败。如果一个模型是基于"A是B"形式的句子进行训练，它不会自动推广到相反的方向"B是A"。这就是翻转诅咒。例如，如果一个模型是基于"Olaf Scholz是德国第九任总理"进行训练的，它不会自动能够回答问题"谁是德国第九任总理？"。此外，正确答案（"Olaf Scholz"）的可能性不会比随机名字更高。因此，模型在逻辑推断上存在基本失败，并且不会推广到它们训练集中的普遍模式（即如果出现"A是B"，则"B是A"更可能出现）。我们通过在虚构的陈述（如"Uriah Hawthorne是'Abyssal Melodies'的作曲家"）上对GPT-3和Llama-1进行微调，并展示它们无法正确回答"谁创作了'Abyssal Melodies'?"来提供翻转诅咒的证据。

    We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form "A is B", it will not automatically generalize to the reverse direction "B is A". This is the Reversal Curse. For instance, if a model is trained on "Olaf Scholz was the ninth Chancellor of Germany", it will not automatically be able to answer the question, "Who was the ninth Chancellor of Germany?". Moreover, the likelihood of the correct answer ("Olaf Scholz") will not be higher than for a random name. Thus, models exhibit a basic failure of logical deduction and do not generalize a prevalent pattern in their training set (i.e. if "A is B'' occurs, "B is A" is more likely to occur). We provide evidence for the Reversal Curse by finetuning GPT-3 and Llama-1 on fictitious statements such as "Uriah Hawthorne is the composer of 'Abyssal Melodies'" and showing that they fail to correctly answer "Who composed 'Abyssal Melodies?'". The Reversal Cu
    
[^9]: MetaMath：为大型语言模型创建自己的数学问题

    MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models. (arXiv:2309.12284v1 [cs.CL])

    [http://arxiv.org/abs/2309.12284](http://arxiv.org/abs/2309.12284)

    MetaMath是一种专门用于数学推理的微调语言模型，通过从多个角度重新编写问题来生成数学问题，并在两个基准测试中取得了优于其他开源语言模型的表现。

    

    大型语言模型（LLMs）推动了自然语言理解的极限，并展示了出色的问题解决能力。尽管取得了巨大的成功，但大多数现有的开源LLMs（例如LLaMA-2）在解决数学问题方面仍然远远不够令人满意，原因是复杂的推理过程。为了弥合这一鸿沟，我们提出了MetaMath，一种专门用于数学推理的微调语言模型。具体而言，我们通过在没有额外知识的情况下以多个角度重新写入问题来引导数学问题，从而产生了一个名为MetaMathQA的新数据集。然后我们在MetaMathQA上对LLaMA-2模型进行了微调。对于数学推理的两个流行基准测试（即GSM8K和MATH），实验结果表明MetaMath在性能上明显优于一套开源LLMs。我们的MetaMath-7B模型在GSM8K上达到了66.4％，在MATH上达到了19.4％，超过了相同规模的最先进模型。

    Large language models (LLMs) have pushed the limits of natural language understanding and exhibited excellent problem-solving ability. Despite the great success, most existing open-source LLMs (\eg, LLaMA-2) are still far away from satisfactory for solving mathematical problem due to the complex reasoning procedures. To bridge this gap, we propose \emph{MetaMath}, a fine-tuned language model that specializes in mathematical reasoning. Specifically, we start by bootstrapping mathematical questions by rewriting the question from multiple perspectives without extra knowledge, which results in a new dataset called {MetaMathQA}. Then we fine-tune the LLaMA-2 models on MetaMathQA. Experimental results on two popular benchmarks (\ie, GSM8K and MATH) for mathematical reasoning demonstrate that MetaMath outperforms a suite of open-source LLMs by a significant margin. Our MetaMath-7B model achieves $66.4\%$ on GSM8K and $19.4\%$ on MATH, exceeding the state-of-the-art models of the same size by 
    
[^10]: LLMR：使用大型语言模型实时提示交互式世界的框架

    LLMR: Real-time Prompting of Interactive Worlds using Large Language Models. (arXiv:2309.12276v1 [cs.HC])

    [http://arxiv.org/abs/2309.12276](http://arxiv.org/abs/2309.12276)

    LLMR是一个用于实时创建和修改交互式混合现实体验的框架，通过利用大型语言模型和新颖的策略，它能够解决训练数据稀缺和设计目标复杂的问题，并在性能上超过标准的GPT-4。我们展示了LLMR的跨平台互操作性，并通过评估和用户研究证明了其对于生成和编辑各种对象、工具和场景的能力。

    

    我们提出了用于混合现实场景的大型语言模型(LLMR)，这是一个框架，用于实时创建和修改交互式混合现实体验。LLMR利用了新颖的策略来解决训练数据稀缺或设计目标需要合成内部动态、直观分析或高级交互的困难情况。我们的框架依赖于文本交互和Unity游戏引擎。通过融合场景理解、任务规划、自我调试和内存管理技术，LLMR在平均错误率上比标准的GPT-4提高了4倍。我们展示了LLMR与几个示例世界的跨平台互操作性，并通过多个创建和修改任务对其进行了评估，以展示它能够生成和编辑各种对象、工具和场景。最后，我们进行了一个有多样性的可用性研究（N=11），揭示了参与者对该系统有积极的体验，并愿意再次使用它。

    We present Large Language Model for Mixed Reality (LLMR), a framework for the real-time creation and modification of interactive Mixed Reality experiences using LLMs. LLMR leverages novel strategies to tackle difficult cases where ideal training data is scarce, or where the design goal requires the synthesis of internal dynamics, intuitive analysis, or advanced interactivity. Our framework relies on text interaction and the Unity game engine. By incorporating techniques for scene understanding, task planning, self-debugging, and memory management, LLMR outperforms the standard GPT-4 by 4x in average error rate. We demonstrate LLMR's cross-platform interoperability with several example worlds, and evaluate it on a variety of creation and modification tasks to show that it can produce and edit diverse objects, tools, and scenes. Finally, we conducted a usability study (N=11) with a diverse set that revealed participants had positive experiences with the system and would use it again.
    
[^11]: 使基于四分位数的估计平均梯度聚合成为联邦图像分类的基准线的技术

    Enabling Quartile-based Estimated-Mean Gradient Aggregation As Baseline for Federated Image Classifications. (arXiv:2309.12267v1 [cs.CR])

    [http://arxiv.org/abs/2309.12267](http://arxiv.org/abs/2309.12267)

    本文提出了一种名为估计平均聚合（EMA）的创新解决方案，旨在解决联邦学习中数据多样性和系统安全的挑战。EMA通过修剪均值处理恶意异常值，并揭示数据异质性，以确保训练模型适应不同的客户数据集。通过丰富的实验验证，EMA相对于其他方法表现出高准确性和曲线下面积（AUC），成为先进聚合技术的基准线。

    

    联邦学习（FL）通过实现分散协作、保护敏感数据并提高模型性能，彻底改变了我们训练深度神经网络的方式。然而，FL面临两个关键挑战：个体客户的数据多样性以及FL系统易受安全漏洞影响。本文引入了一种名为估计平均聚合（EMA）的创新解决方案，不仅解决了这些挑战，而且作为FL系统中先进聚合技术的基准线。EMA的重要性在于其双重作用：通过修剪均值有效处理恶意异常值，揭示数据异质性以确保训练模型适应各种客户数据集。通过大量实验，EMA始终相对于其他方法表现出高准确性和曲线下面积（AUC），确立自身地位。

    Federated Learning (FL) has revolutionized how we train deep neural networks by enabling decentralized collaboration while safeguarding sensitive data and improving model performance. However, FL faces two crucial challenges: the diverse nature of data held by individual clients and the vulnerability of the FL system to security breaches. This paper introduces an innovative solution named Estimated Mean Aggregation (EMA) that not only addresses these challenges but also provides a fundamental reference point as a $\mathsf{baseline}$ for advanced aggregation techniques in FL systems. EMA's significance lies in its dual role: enhancing model security by effectively handling malicious outliers through trimmed means and uncovering data heterogeneity to ensure that trained models are adaptable across various client datasets. Through a wealth of experiments, EMA consistently demonstrates high accuracy and area under the curve (AUC) compared to alternative methods, establishing itself as a ro
    
[^12]: SALSA-CLRS:一种稀疏且可扩展的算法推理基准

    SALSA-CLRS: A Sparse and Scalable Benchmark for Algorithmic Reasoning. (arXiv:2309.12253v1 [cs.LG])

    [http://arxiv.org/abs/2309.12253](http://arxiv.org/abs/2309.12253)

    SALSA-CLRS是一种稀疏且可扩展的算法推理基准，优先考虑可扩展性和稀疏表示的利用。它通过引入适应于分布式算法和图神经网络的消息传递范式，解决了现有CLRS基准中内存需求高和运行时间难以扩展的问题。

    

    我们介绍了CLRS算法学习基准的扩展，优先考虑可扩展性和稀疏表示的利用。CLRS中的许多算法需要全局存储器或信息交换，在其执行模型中镜像表达为基于底层问题构建完全连接（而非稀疏）图的操作。尽管CLRS的目标是评估学习算法在更大实例上的泛化能力，但现有的执行模型由于其要求高的内存需求和运行时间而成为一个重要限制（难以扩展）。然而，许多重要的算法并不需要完全连接的图；这些主要分布式算法与图神经网络采用的消息传递范式密切相关。因此，我们提出了SALSA-CLRS，一个专门考虑可扩展性和稀疏性的CLRS基准的扩展。我们的方法包括从原始CLRS基准中改编的算法，并引入了新的问题。

    We introduce an extension to the CLRS algorithmic learning benchmark, prioritizing scalability and the utilization of sparse representations. Many algorithms in CLRS require global memory or information exchange, mirrored in its execution model, which constructs fully connected (not sparse) graphs based on the underlying problem. Despite CLRS's aim of assessing how effectively learned algorithms can generalize to larger instances, the existing execution model becomes a significant constraint due to its demanding memory requirements and runtime (hard to scale). However, many important algorithms do not demand a fully connected graph; these algorithms, primarily distributed in nature, align closely with the message-passing paradigm employed by Graph Neural Networks. Hence, we propose SALSA-CLRS, an extension of the current CLRS benchmark specifically with scalability and sparseness in mind. Our approach includes adapted algorithms from the original CLRS benchmark and introduces new probl
    
[^13]: 坏角色好顾问：探索大型语言模型在假新闻检测中的作用

    Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection. (arXiv:2309.12247v1 [cs.CL])

    [http://arxiv.org/abs/2309.12247](http://arxiv.org/abs/2309.12247)

    大型语言模型对于假新闻检测的潜力仍未得到充分探索。实证研究发现，尽管复杂的大型语言模型能够揭示假新闻并提供多角度解释，但仍不如经过fine-tuned的小型语言模型表现出色。当前的大型语言模型可能无法取代小型语言模型，但可以作为一个良好的辅助顾问。

    

    检测假新闻需要对多样线索有敏锐的感知和对现实世界背景有深入的理解，对于基于小型语言模型的检测器来说，由于其知识和能力的限制，这仍然是具有挑战性的。近期大型语言模型的进步在各种任务中表现出了卓越的性能，但大型语言模型能否以及如何帮助假新闻检测仍然未经过深入研究。在本文中，我们研究了大型语言模型在假新闻检测中的潜力。首先，我们进行了实证研究，发现像GPT 3.5这样的复杂大型语言模型通常能够揭示假新闻并提供理想的多角度解释，但仍然不如基础小型语言模型fine-tuned BERT表现出色。我们随后的分析将这种差距归因于大型语言模型不能正确选择并整合证据以得出结论。基于这些发现，我们提出当前的大型语言模型可能无法取代在假新闻检测中经过fine-tuned的小型语言模型，但可以作为一个良好的辅助顾问。

    Detecting fake news requires both a delicate sense of diverse clues and a profound understanding of the real-world background, which remains challenging for detectors based on small language models (SLMs) due to their knowledge and capability limitations. Recent advances in large language models (LLMs) have shown remarkable performance in various tasks, but whether and how LLMs could help with fake news detection remains underexplored. In this paper, we investigate the potential of LLMs in fake news detection. First, we conduct an empirical study and find that a sophisticated LLM such as GPT 3.5 could generally expose fake news and provide desirable multi-perspective rationales but still underperforms the basic SLM, fine-tuned BERT. Our subsequent analysis attributes such a gap to the LLM's inability to select and integrate rationales properly to conclude. Based on these findings, we propose that current LLMs may not substitute fine-tuned SLMs in fake news detection but can be a good a
    
[^14]: ChaCha：利用大型语言模型引导儿童分享与个人事件相关的情绪

    ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events. (arXiv:2309.12244v1 [cs.HC])

    [http://arxiv.org/abs/2309.12244](http://arxiv.org/abs/2309.12244)

    ChaCha是一个利用大型语言模型（LLMs）的聊天机器人，鼓励儿童分享个人事件和相关情绪。通过一个探索性研究，发现儿童将ChaCha视为亲密的朋友，并愿意与其分享各种主题的故事。

    

    儿童通常通过与家人或他人分享故事和感受来学习辨识和表达情绪，然而，由于儿童正在发展他们的交流技能，父母或兄弟姐妹很难与他们进行情感沟通。本文介绍了ChaCha，一个鼓励和引导儿童分享个人事件和相关情绪的聊天机器人。ChaCha结合了状态机和大型语言模型（LLMs），在进行自由对话的同时保持对话的方向性。通过与20名年龄在8-12岁的儿童进行的探索性研究，我们研究了ChaCha如何促使儿童分享个人事件并引导他们描述相关情绪。参与者认为ChaCha就像一个亲密的朋友，并分享了各种主题的故事，如家庭旅行和个人成就。基于定量和定性发现，我们讨论了利用LLMs设计适合儿童的聊天机器人的机遇。

    Children typically learn to identify and express emotions through sharing their stories and feelings with others, particularly their family. However, it is challenging for parents or siblings to have emotional communication with children since children are still developing their communication skills. We present ChaCha, a chatbot that encourages and guides children to share personal events and associated emotions. ChaCha combines a state machine and large language models (LLMs) to keep the dialogue on track while carrying on free-form conversations. Through an exploratory study with 20 children (aged 8-12), we examine how ChaCha prompts children to share personal events and guides them to describe associated emotions. Participants perceived ChaCha as a close friend and shared their stories on various topics, such as family trips and personal achievements. Based on the quantitative and qualitative findings, we discuss opportunities for leveraging LLMs to design child-friendly chatbots to
    
[^15]: 使用具有离散余弦变换层的非对称稀疏自编码器对脑电图传感器数据进行压缩

    Electroencephalogram Sensor Data Compression Using An Asymmetrical Sparse Autoencoder With A Discrete Cosine Transform Layer. (arXiv:2309.12201v1 [eess.SP])

    [http://arxiv.org/abs/2309.12201](http://arxiv.org/abs/2309.12201)

    本文提出了一种使用非对称稀疏自编码器和离散余弦变换层对脑电图传感器数据进行压缩的方法。实验结果表明，这种方法能有效地减少EEG信号的冗余，并在保持稀疏性的同时提高数据的准确性。

    

    脑电图（EEG）数据压缩对于无线记录应用来说是必要的，以减少需要传输的数据量。本文提出了一种使用离散余弦变换（DCT）层的非对称稀疏自编码器来压缩EEG信号的方法。自编码器的编码器模块采用全连接线性层和DCT层的组合，使用硬阈值非线性降低冗余数据。此外，DCT层包括可训练的硬阈值参数和缩放层，可强调或减弱单个DCT系数。最后，一对一卷积层生成潜空间。在潜空间中，采用稀疏惩罚型成本函数使特征图尽可能稀疏。潜空间数据被传输到接收端。自编码器的解码器模块使用逆DCT和两个全连接线性层来提高数据的准确性。

    Electroencephalogram (EEG) data compression is necessary for wireless recording applications to reduce the amount of data that needs to be transmitted. In this paper, an asymmetrical sparse autoencoder with a discrete cosine transform (DCT) layer is proposed to compress EEG signals. The encoder module of the autoencoder has a combination of a fully connected linear layer and the DCT layer to reduce redundant data using hard-thresholding nonlinearity. Furthermore, the DCT layer includes trainable hard-thresholding parameters and scaling layers to give emphasis or de-emphasis on individual DCT coefficients. Finally, the one-by-one convolutional layer generates the latent space. The sparsity penalty-based cost function is employed to keep the feature map as sparse as possible in the latent space. The latent space data is transmitted to the receiver. The decoder module of the autoencoder is designed using the inverse DCT and two fully connected linear layers to improve the accuracy of data
    
[^16]: 可解释的人工智能在药物发现和开发中的应用 - 一项综合调查

    Explainable Artificial Intelligence for Drug Discovery and Development -- A Comprehensive Survey. (arXiv:2309.12177v1 [cs.AI])

    [http://arxiv.org/abs/2309.12177](http://arxiv.org/abs/2309.12177)

    可解释的人工智能在药物发现中的应用越来越受关注，为研究人员提供了对机器学习模型预测的更具解释性的理解，进一步促进了目标识别、化合物设计和毒性预测等方面的发展。

    

    随着人工智能（AI）和机器学习（ML）技术的出现，药物发现领域经历了显著的转变。然而，随着这些AI和ML模型变得越来越复杂，对于模型的透明性和解释能力的需求也在增加。可解释的人工智能（XAI）是一种新颖的方法，解决了这个问题，并提供了对机器学习模型所做预测的更具解释性的理解。近年来，对于将XAI技术应用于药物发现的兴趣日益增加。本综述文章全面概述了XAI在药物发现中的最新进展，包括各种XAI方法、它们在药物发现中的应用，以及XAI技术在药物发现中的挑战和限制。该文章还涵盖了XAI在药物发现中的应用，包括目标识别、化合物设计和毒性预测。

    The field of drug discovery has experienced a remarkable transformation with the advent of artificial intelligence (AI) and machine learning (ML) technologies. However, as these AI and ML models are becoming more complex, there is a growing need for transparency and interpretability of the models. Explainable Artificial Intelligence (XAI) is a novel approach that addresses this issue and provides a more interpretable understanding of the predictions made by machine learning models. In recent years, there has been an increasing interest in the application of XAI techniques to drug discovery. This review article provides a comprehensive overview of the current state-of-the-art in XAI for drug discovery, including various XAI methods, their application in drug discovery, and the challenges and limitations of XAI techniques in drug discovery. The article also covers the application of XAI in drug discovery, including target identification, compound design, and toxicity prediction. Furtherm
    
[^17]: 基于过去遍历特征的无监督领域自适应用于自动驾驶

    Unsupervised Domain Adaptation for Self-Driving from Past Traversal Features. (arXiv:2309.12140v1 [cs.CV])

    [http://arxiv.org/abs/2309.12140](http://arxiv.org/abs/2309.12140)

    本研究提出了一种方法，利用无标签的重复遍历来适应物体检测器到新的驾驶环境。通过结合重复的激光雷达扫描计算的统计数据，我们有效地引导自适应过程，并通过引入轻量级的回归头和自训练过程来增强检测模型。实验表明，该方法在现实世界数据集上取得了多达20个百分点的性能提升。

    

    现如今，针对自动驾驶汽车的三维物体检测系统的快速发展极大提高了准确性。然而，这些系统往往难以泛化到多样化的驾驶环境中，这可能导致在检测交通参与者时发生安全关键性的失败。为了解决这个问题，我们提出了一种方法，利用无标签的多个位置重复遍历来适应物体检测器到新的驾驶环境。通过结合重复的激光雷达扫描计算的统计数据，我们有效地引导自适应过程。我们的方法通过使用空间量化的历史特征来增强基于激光雷达的检测模型，并引入了一个轻量级的回归头来利用统计数据进行特征正则化。此外，我们利用统计数据进行了一种新颖的自训练过程来稳定训练。该框架适用于任何检测器模型，并在现实世界数据集上进行的实验表明，取得了多达20个百分点的性能提升。

    The rapid development of 3D object detection systems for self-driving cars has significantly improved accuracy. However, these systems struggle to generalize across diverse driving environments, which can lead to safety-critical failures in detecting traffic participants. To address this, we propose a method that utilizes unlabeled repeated traversals of multiple locations to adapt object detectors to new driving environments. By incorporating statistics computed from repeated LiDAR scans, we guide the adaptation process effectively. Our approach enhances LiDAR-based detection models using spatial quantized historical features and introduces a lightweight regression head to leverage the statistics for feature regularization. Additionally, we leverage the statistics for a novel self-training process to stabilize the training. The framework is detector model-agnostic and experiments on real-world datasets demonstrate significant improvements, achieving up to a 20-point performance gain, 
    
[^18]: 关于机器人和人工智能中基准测试、标准和认证之间关系的研究

    On the relationship between Benchmarking, Standards and Certification in Robotics and AI. (arXiv:2309.12139v1 [cs.RO])

    [http://arxiv.org/abs/2309.12139](http://arxiv.org/abs/2309.12139)

    本文研究了机器人和人工智能中基准测试、标准和认证之间的关系，并认为它们不仅有用，而且对于更广泛的负责任创新实践至关重要。

    

    基准测试、标准和认证是密切相关的过程。标准提供了机器人和人工智能系统可能（或可能不）符合的规范要求。认证通常依赖于符合一个或多个标准的程度来决定是否授予运营证书。而基准测试是对机器人和人工智能系统进行衡量的一套标准化测试。因此，可以将基准测试视为非正式的标准。本文将通过基准测试、标准和认证的实例，发展这些主题，并认为这三个相互关联的过程不仅有用，而且对于更广泛的负责任创新实践至关重要。

    Benchmarking, standards and certification are closely related processes. Standards can provide normative requirements that robotics and AI systems may or may not conform to. Certification generally relies upon conformance with one or more standards as the key determinant of granting a certificate to operate. And benchmarks are sets of standardised tests against which robots and AI systems can be measured. Benchmarks therefore can be thought of as informal standards. In this paper we will develop these themes with examples from benchmarking, standards and certification, and argue that these three linked processes are not only useful but vital to the broader practice of Responsible Innovation.
    
[^19]: OSN-MDAD：用于在线社交媒体上阿拉伯多方言对话的机器翻译数据集

    OSN-MDAD: Machine Translation Dataset for Arabic Multi-Dialectal Conversations on Online Social Media. (arXiv:2309.12137v1 [cs.CL])

    [http://arxiv.org/abs/2309.12137](http://arxiv.org/abs/2309.12137)

    该论文介绍了一个用于阿拉伯多方言在线社交媒体对话的机器翻译数据集，指出了阿拉伯语资源不足的问题以及现有机器翻译系统在处理阿拉伯方言时的困难。该研究的重点在于开发能够有效处理阿拉伯各种方言的机器翻译系统。

    

    虽然英语资源在社交媒体上理解内容相对充足，但阿拉伯语的资源仍不足够成熟。阿拉伯语资源不足的主要原因是，阿拉伯语除了标准版本（MSA）外，还有许多方言。阿拉伯人在日常交流中不使用MSA，而是使用方言版本。不幸的是，社交媒体用户也将这种现象引入到他们对社交媒体平台的使用中，这进而引发了对于构建适用于语言相关应用的合适AI模型的迫切需求。现有为MSA设计的机器翻译（MT）系统无法很好地处理阿拉伯方言。鉴于此，有必要通过开发能够有效处理阿拉伯各种方言的MT系统来适应社交网络上的非正式交流方式。与在MT系统中对MSA显示出先进进展不同，利用阿拉伯方言进行MT系统的利用所付出的努力不多。

    While resources for English language are fairly sufficient to understand content on social media, similar resources in Arabic are still immature. The main reason that the resources in Arabic are insufficient is that Arabic has many dialects in addition to the standard version (MSA). Arabs do not use MSA in their daily communications; rather, they use dialectal versions. Unfortunately, social users transfer this phenomenon into their use of social media platforms, which in turn has raised an urgent need for building suitable AI models for language-dependent applications. Existing machine translation (MT) systems designed for MSA fail to work well with Arabic dialects. In light of this, it is necessary to adapt to the informal nature of communication on social networks by developing MT systems that can effectively handle the various dialects of Arabic. Unlike for MSA that shows advanced progress in MT systems, little effort has been exerted to utilize Arabic dialects for MT systems. Whil
    
[^20]: 用于建筑合同知识建模的知识表示方法

    A knowledge representation approach for construction contract knowledge modeling. (arXiv:2309.12132v1 [cs.AI])

    [http://arxiv.org/abs/2309.12132](http://arxiv.org/abs/2309.12132)

    本论文介绍了一个用于建筑合同知识建模的知识表示方法，通过嵌套结构捕捉合同知识的复杂性。它提出了嵌套合同知识图（NCKG）和LLM-assisted合同审查流程，帮助自动化合同管理，并在合同风险审查方面取得了良好性能。

    

    大型语言模型（LLM）的出现为自动化建筑合同管理提供了前所未有的机会，减少了人为错误，并节省了大量时间和成本。然而，由于缺乏领域专业知识，LLMs可能会产生令人信服但不准确和误导性的内容。为了解决这个问题，专家驱动的合同知识可以以结构化的方式表示，以约束自动化合同管理过程。本文介绍了嵌套合同知识图（NCKG），一种使用嵌套结构来捕捉合同知识复杂性的知识表示方法。它包括一个嵌套知识表示框架、一个建立在该框架上的NCKG本体以及一种实现方法。此外，我们提出了在NCKG中增强外部知识的LLM辅助合同审查流程。我们的流程在合同风险审查方面取得了良好的性能，为LLM和KG的结合提供了启示。

    The emergence of large language models (LLMs) presents an unprecedented opportunity to automate construction contract management, reducing human errors and saving significant time and costs. However, LLMs may produce convincing yet inaccurate and misleading content due to a lack of domain expertise. To address this issue, expert-driven contract knowledge can be represented in a structured manner to constrain the automatic contract management process. This paper introduces the Nested Contract Knowledge Graph (NCKG), a knowledge representation approach that captures the complexity of contract knowledge using a nested structure. It includes a nested knowledge representation framework, a NCKG ontology built on the framework, and an implementation method. Furthermore, we present the LLM-assisted contract review pipeline enhanced with external knowledge in NCKG. Our pipeline achieves a promising performance in contract risk reviewing, shedding light on the combination of LLM and KG towards m
    
[^21]: 利用有限预算激励大规模未知工作者的众感知：从离线和在线视角考虑

    Incentivizing Massive Unknown Workers for Budget-Limited Crowdsensing: From Off-Line and On-Line Perspectives. (arXiv:2309.12113v1 [cs.AI])

    [http://arxiv.org/abs/2309.12113](http://arxiv.org/abs/2309.12113)

    本文提出了一种离线的基于上下文感知的CMAB激励（CACI）机制，通过对一个精细划分的上下文空间中的探索-开发权衡，有效地激励具有非常有限预算的大规模未知工作者。

    

    尽管现有的提案通过在探索和开发之间进行权衡来解决工作者的不确定性，标准的组合多臂赌博机（CMAB）框架可以解决工作者的不确定性，但当工作者数量巨大而预算有限时，可能无法对个体工作者进行权衡。此外，标准的CMAB通常假设工作者始终留在系统中，而工作者可能在时间上加入或离开系统，因此在工作者离开后，我们学到的对于单个工作者的知识无法应用。为了解决上述问题，本文首先提出了一种离线的基于上下文感知的CMAB激励（CACI）机制。我们创新地利用了一个精心划分的上下文空间中的探索-开发权衡，而不是针对个体工作者，以有效地激励具有非常有限预算的大规模未知工作者。

    Although the uncertainties of the workers can be addressed by the standard Combinatorial Multi-Armed Bandit (CMAB) framework in existing proposals through a trade-off between exploration and exploitation, we may not have sufficient budget to enable the trade-off among the individual workers, especially when the number of the workers is huge while the budget is limited. Moreover, the standard CMAB usually assumes the workers always stay in the system, whereas the workers may join in or depart from the system over time, such that what we have learnt for an individual worker cannot be applied after the worker leaves. To address the above challenging issues, in this paper, we first propose an off-line Context-Aware CMAB-based Incentive (CACI) mechanism. We innovate in leveraging the exploration-exploitation trade-off in a elaborately partitioned context space instead of the individual workers, to effectively incentivize the massive unknown workers with very limited budget. We also extend t
    
[^22]: PEFTT: 多参数效率的低资源藏语预训练语言模型微调

    PEFTT: Parameter-Efficient Fine-Tuning for low-resource Tibetan pre-trained language models. (arXiv:2309.12109v1 [cs.CL])

    [http://arxiv.org/abs/2309.12109](http://arxiv.org/abs/2309.12109)

    本研究在低资源语言模型如藏语中进行了高效微调策略的研究，填补了这一重要空白。

    

    在大语言模型时代，传统模型训练对于普通用户和机构而言越来越难以想象。在这些模型上，对于高资源语言的高效微调的探索是一个不可否认的趋势，而这种趋势正逐渐流行起来。然而，对于低资源语言，如藏语，目前的研究非常有限。藏语自然语言处理的研究本就稀缺而受限。尽管目前由于其低资源性质，还没有现有的大语言模型用于藏语，但这一天毫无疑问会到来。因此，对于像藏语这样的低资源语言模型的高效微调研究非常必要。我们的研究可以作为填补这一重要空白的参考。

    In this era of large language models (LLMs), the traditional training of models has become increasingly unimaginable for regular users and institutions. The exploration of efficient fine-tuning for high-resource languages on these models is an undeniable trend that is gradually gaining popularity. However, there has been very little exploration for various low-resource languages, such as Tibetan. Research in Tibetan NLP is inherently scarce and limited. While there is currently no existing large language model for Tibetan due to its low-resource nature, that day will undoubtedly arrive. Therefore, research on efficient fine-tuning for low-resource language models like Tibetan is highly necessary. Our research can serve as a reference to fill this crucial gap. Efficient fine-tuning strategies for pre-trained language models (PLMs) in Tibetan have seen minimal exploration. We conducted three types of efficient fine-tuning experiments on the publicly available TNCC-title dataset: "prompt-
    
[^23]: 使用Prompt调优的预训练语言模型加速主题投资

    Accelerating Thematic Investment with Prompt Tuned Pretrained Language Models. (arXiv:2309.12075v1 [cs.CL])

    [http://arxiv.org/abs/2309.12075](http://arxiv.org/abs/2309.12075)

    本研究通过Benchmark测试，发现使用Prompt Tuning的预训练语言模型在多标签文本分类任务中具有较好的性能和计算效率。同时，提出了使用Trie搜索来解决生成标签匹配问题的限制。

    

    Prompt Tuning作为一种可扩展且成本效益高的方法，正在成为细调预训练语言模型（PLMs）的一种流行方法。本研究基于多标签文本分类任务对Prompt Tuning和基准方法的性能和计算效率进行了基准测试。将其应用于将公司分类为投资公司专有的行业分类法，以支持其主题投资策略。在多标签分类问题中，使用PLMs进行文本到文本分类经常被报告为优于使用分类头进行分类，但在每个标签由多个令牌组成的多标签分类问题中，存在一些限制：（a）生成的标签可能不匹配行业分类法中的任何标签；（b）在细调阶段，必须以任意顺序提供多个标签；（c）模型为每个标签提供二进制决策，而不是适当的置信度分数。通过应用Trie搜索来解决限制（a）。

    Prompt Tuning is emerging as a scalable and cost-effective method to fine-tune Pretrained Language Models (PLMs). This study benchmarks the performance and computational efficiency of Prompt Tuning and baseline methods on a multi-label text classification task. This is applied to the use case of classifying companies into an investment firm's proprietary industry taxonomy, supporting their thematic investment strategy. Text-to-text classification with PLMs is frequently reported to outperform classification with a classification head, but has several limitations when applied to a multi-label classification problem where each label consists of multiple tokens: (a) Generated labels may not match any label in the industry taxonomy; (b) During fine-tuning, multiple labels must be provided in an arbitrary order; (c) The model provides a binary decision for each label, rather than an appropriate confidence score. Limitation (a) is addressed by applying constrained decoding using Trie Search,
    
[^24]: 在巴西中学考试上对基于量化LLaMa模型的基准测试

    Benchmarking quantized LLaMa-based models on the Brazilian Secondary School Exam. (arXiv:2309.12071v1 [cs.AI])

    [http://arxiv.org/abs/2309.12071](http://arxiv.org/abs/2309.12071)

    本研究对基于量化LLaMa模型的大型语言模型在巴西中学考试上进行了性能评估。评估结果表明，最佳表现的模型在原版葡萄牙语问题和其英文翻译上的准确率约为46%。同时，作者还评估了这些模型的计算效率。

    

    尽管大型语言模型(LLM)在我们与计算机交互的方式上代表了一场革命，允许构建复杂问题并能够对一系列陈述进行推理，但由于需要专门的硬件执行，它们的使用受到限制。在这项研究中，我们评估了基于70亿和130亿LLaMA模型的LLMs在量化处理和运行在家庭硬件上的性能。考虑到的模型有Alpaca、Koala和Vicuna。为了评估这些模型的有效性，我们开发了一个包含1006个问题的数据库，这些问题来自巴西国家中学考试(ENEM)。我们的分析发现，表现最佳的模型在原版葡萄牙语问题和其英文翻译上的准确率约为46%，另外，我们通过测量执行所需的时间来评估模型的计算效率。在平均情况下，70亿和130亿LLMs需要约

    Although Large Language Models (LLMs) represent a revolution in the way we interact with computers, allowing the construction of complex questions and the ability to reason over a sequence of statements, their use is restricted due to the need for dedicated hardware for execution. In this study, we evaluate the performance of LLMs based on the 7 and 13 billion LLaMA models, subjected to a quantization process and run on home hardware. The models considered were Alpaca, Koala, and Vicuna. To evaluate the effectiveness of these models, we developed a database containing 1,006 questions from the ENEM (Brazilian National Secondary School Exam). Our analysis revealed that the best performing models achieved an accuracy of approximately 46% for the original texts of the Portuguese questions and 49% on their English translations. In addition, we evaluated the computational efficiency of the models by measuring the time required for execution. On average, the 7 and 13 billion LLMs took approxi
    
[^25]: 足球中动作识别、定位和时空定位的调查--当前趋势和研究展望

    Survey of Action Recognition, Spotting and Spatio-Temporal Localization in Soccer -- Current Trends and Research Perspectives. (arXiv:2309.12067v1 [cs.CV])

    [http://arxiv.org/abs/2309.12067](http://arxiv.org/abs/2309.12067)

    本文提供了足球中动作识别、定位和时空定位的综述，重点介绍了多模态方法。通过利用深度学习技术和传统方法，这些方法整合了来自多个数据源的信息，并以多种方式表示一种来源，在提高模型准确性和稳健性方面具有潜力。

    

    由于足球比赛的复杂性和动态性以及球员之间的互动，对足球中的动作场景进行理解是一项具有挑战性的任务。本文将此任务分为动作识别、定位和时空动作定位，并重点介绍所使用的模态和多模态方法。我们探索了公开可用的数据源和用于评估模型性能的度量标准。本文回顾了利用深度学习技术和传统方法的最新研究方法。我们关注整合来自多个来源（如视频和音频数据）的信息的多模态方法，以及以多种方式表示一种来源的方法。讨论了方法的优势和局限性，以及它们改进模型准确性和稳健性的潜力。最后，本文强调了该领域的一些开放性研究问题和未来方向。

    Action scene understanding in soccer is a challenging task due to the complex and dynamic nature of the game, as well as the interactions between players. This article provides a comprehensive overview of this task divided into action recognition, spotting, and spatio-temporal action localization, with a particular emphasis on the modalities used and multimodal methods. We explore the publicly available data sources and metrics used to evaluate models' performance. The article reviews recent state-of-the-art methods that leverage deep learning techniques and traditional methods. We focus on multimodal methods, which integrate information from multiple sources, such as video and audio data, and also those that represent one source in various ways. The advantages and limitations of methods are discussed, along with their potential for improving the accuracy and robustness of models. Finally, the article highlights some of the open research questions and future directions in the field of 
    
[^26]: 一个高效整合词嵌入和深度学习技术的抗癌肽分类方法：FastText+BiLSTM

    An Efficient Consolidation of Word Embedding and Deep Learning Techniques for Classifying Anticancer Peptides: FastText+BiLSTM. (arXiv:2309.12058v1 [cs.LG])

    [http://arxiv.org/abs/2309.12058](http://arxiv.org/abs/2309.12058)

    本研究提出了一个整合了词嵌入和深度学习技术的高效抗癌肽分类模型，并评估了Word2Vec和FastText作为词嵌入技术，以及CNN、LSTM、BiLSTM作为深度学习模型的性能。

    

    抗癌肽（ACP）是一类具备抗肿瘤特性的肽。使用ACP在癌症预防中可以作为传统癌症治疗的替代品，因为它们具有更高的选择性和安全性。最近科学的进展引起了对基于肽的治疗的兴趣，它们能够高效地治疗目标细胞而不对正常细胞产生负面影响。然而，随着肽序列的数量不断增加，开发可靠和精确的预测模型变得具有挑战性。本研究旨在通过整合词嵌入和深度学习模型来提出一个高效的抗癌肽分类模型。首先，评估了Word2Vec和FastText作为提取肽序列的词嵌入技术。然后，将词嵌入模型的输出输入到深度学习方法CNN、LSTM、BiLSTM中。

    Anticancer peptides (ACPs) are a group of peptides that exhibite antineoplastic properties. The utilization of ACPs in cancer prevention can present a viable substitute for conventional cancer therapeutics, as they possess a higher degree of selectivity and safety. Recent scientific advancements generate an interest in peptide-based therapies which offer the advantage of efficiently treating intended cells without negatively impacting normal cells. However, as the number of peptide sequences continues to increase rapidly, developing a reliable and precise prediction model becomes a challenging task. In this work, our motivation is to advance an efficient model for categorizing anticancer peptides employing the consolidation of word embedding and deep learning models. First, Word2Vec and FastText are evaluated as word embedding techniques for the purpose of extracting peptide sequences. Then, the output of word embedding models are fed into deep learning approaches CNN, LSTM, BiLSTM. To
    
[^27]: BELT: 通过自然语言监督进行脑电图到语言解码和零样本情感分类的引导式模型和学习框架

    BELT:Bootstrapping Electroencephalography-to-Language Decoding and Zero-Shot Sentiment Classification by Natural Language Supervision. (arXiv:2309.12056v1 [cs.AI])

    [http://arxiv.org/abs/2309.12056](http://arxiv.org/abs/2309.12056)

    BELT是一种通过自然语言监督进行脑电图到语言解码和零样本情感分类的引导式模型和学习框架。它利用现成的大规模预训练语言模型来改进脑电信号的理解，从而推动了大脑-计算机界面的应用和发展。

    

    本文介绍了BELT，这是一个针对大脑到语言翻译研究的重要主题的新模型和学习框架。将非侵入性脑信号翻译成可读的自然语言有潜力推动大脑-计算机界面（BCI）的应用场景和发展。脑信号解码或脑-语言翻译中的关键问题是从有限规模和质量的数据集中获得语义适当且具有区分性的脑电图表示。所提出的BELT方法是一个通用且高效的框架，利用现成的大规模预训练语言模型（LM）引导脑电图表示学习。通过利用训练在互联网规模数据集上的大规模LM理解语义信息和零样本泛化能力，BELT极大改进了对脑电信号的理解。具体而言，BELT模型由一个深度神经网络组成，其中包含一个解码神经网络和一个预训练LM。

    This paper presents BELT, a novel model and learning framework for the pivotal topic of brain-to-language translation research. The translation from noninvasive brain signals into readable natural language has the potential to promote the application scenario as well as the development of brain-computer interfaces (BCI) as a whole. The critical problem in brain signal decoding or brain-to-language translation is the acquisition of semantically appropriate and discriminative EEG representation from a dataset of limited scale and quality. The proposed BELT method is a generic and efficient framework that bootstraps EEG representation learning using off-the-shelf large-scale pretrained language models (LMs). With a large LM's capacity for understanding semantic information and zero-shot generalization, BELT utilizes large LMs trained on Internet-scale datasets to bring significant improvements to the understanding of EEG signals.  In particular, the BELT model is composed of a deep confor
    
[^28]: 在线抓取学习中基于不确定性驱动的探索策略

    Uncertainty-driven Exploration Strategies for Online Grasp Learning. (arXiv:2309.12038v1 [cs.RO])

    [http://arxiv.org/abs/2309.12038](http://arxiv.org/abs/2309.12038)

    本文提出了一种在线抓取学习方法，通过使用有效的探索策略，提高了机器人对未知环境的适应能力和抓取预测的准确性。

    

    现有的抓取预测方法主要基于离线学习，而忽略了在线适应新的拾取场景时的探索性抓取学习，例如未见目标组合、摄像机和箱子设置等。本文提出了一种新颖的用于机器人箱子拾取的在线抓取预测学习方法。具体而言，使用有效的探索策略的在线学习算法可以显著提高其对未见环境设置的适应性能力。为此，我们首先将在线抓取学习建模为强化学习问题，以实现对抓取策略的自适应学习。

    Existing grasp prediction approaches are mostly based on offline learning, while, ignored the exploratory grasp learning during online adaptation to new picking scenarios, i.e., unseen object portfolio, camera and bin settings etc. In this paper, we present a novel method for online learning of grasp predictions for robotic bin picking in a principled way. Existing grasp prediction approaches are mostly based on offline learning, while, ignored the exploratory grasp learning during online adaptation to new picking scenarios, i.e., unseen object portfolio, camera and bin settings etc. In this paper, we present a novel method for online learning of grasp predictions for robotic bin picking in a principled way. Specifically, the online learning algorithm with an effective exploration strategy can significantly improve its adaptation performance to unseen environment settings. To this end, we first propose to formulate online grasp learning as a RL problem that will allow to adapt both gra
    
[^29]: 动态超图结构学习用于交通流量预测

    Dynamic Hypergraph Structure Learning for Traffic Flow Forecasting. (arXiv:2309.12028v1 [cs.LG])

    [http://arxiv.org/abs/2309.12028](http://arxiv.org/abs/2309.12028)

    本文提出了一种名为动态超图结构学习(DyHSL)的模型，用于解决交通流量预测问题。该模型利用超图结构信息来建模复杂的交通网络，并且能够捕捉复杂的时空高阶交互作用。

    

    本文研究了交通流量预测问题，旨在基于过去的道路网络和交通状况来预测未来的交通条件。通常通过使用时空图神经网络（GNN）来建模交通数据中的复杂时空相关性来解决这个问题。然而，这些方法的性能仍然不令人满意，因为当涉及到复杂的交通网络时，GNNs的表示能力通常有限。图形本质上无法捕捉非配对关系。更糟糕的是，现有的方法都遵循信息传递的范式，线性地聚合邻域信息，无法捕捉复杂的时空高阶交互作用。为了解决这些问题，本文提出了一种名为动态超图结构学习(DyHSL)的新模型用于交通流量预测。为了学习非配对关系，我们的DyHSL提取超图结构信息来进行建模。

    This paper studies the problem of traffic flow forecasting, which aims to predict future traffic conditions on the basis of road networks and traffic conditions in the past. The problem is typically solved by modeling complex spatio-temporal correlations in traffic data using spatio-temporal graph neural networks (GNNs). However, the performance of these methods is still far from satisfactory since GNNs usually have limited representation capacity when it comes to complex traffic networks. Graphs, by nature, fall short in capturing non-pairwise relations. Even worse, existing methods follow the paradigm of message passing that aggregates neighborhood information linearly, which fails to capture complicated spatio-temporal high-order interactions. To tackle these issues, in this paper, we propose a novel model named Dynamic Hypergraph Structure Learning (DyHSL) for traffic flow prediction. To learn non-pairwise relationships, our DyHSL extracts hypergraph structural information to model
    
[^30]: 解密电影海报的视觉特征，用于多标签电影类型识别

    Demystifying Visual Features of Movie Posters for Multi-Label Genre Identification. (arXiv:2309.12022v1 [cs.AI])

    [http://arxiv.org/abs/2309.12022](http://arxiv.org/abs/2309.12022)

    本研究通过分析电影海报图像，解密了电影海报的视觉特征，并提出了一种自动化的多标签电影类型识别方法，无需使用其他文本或元数据信息，具有推广和营销电影的实际应用意义。

    

    在电影行业中，电影海报多年来一直是广告和营销的重要组成部分，即使在现今的数字海报通过在线、社交媒体和OTT平台上仍然发挥着至关重要的作用。通常，电影海报能够有效地推广和传达电影的本质，例如其类型、视觉风格/调调、氛围和故事线索/主题，这些对吸引潜在观众非常重要。对电影类型进行识别常常在向目标观众推荐电影时具有重要的实际应用。之前的电影类型识别研究仅限于字幕、剧情简介和电影场景，这些大多数在电影发布后才能获取。海报通常包含在发行前隐含的信息来引起大量兴趣。在本文中，我们从电影海报图像中自动进行多标签电影类型识别，而无需任何关于电影的附加文本/元数据信息的帮助，这是其中之一。

    In the film industry, movie posters have been an essential part of advertising and marketing for many decades, and continue to play a vital role even today in the form of digital posters through online, social media and OTT platforms. Typically, movie posters can effectively promote and communicate the essence of a film, such as its genre, visual style/ tone, vibe and storyline cue/ theme, which are essential to attract potential viewers. Identifying the genres of a movie often has significant practical applications in recommending the film to target audiences. Previous studies on movie genre identification are limited to subtitles, plot synopses, and movie scenes that are mostly accessible after the movie release. Posters usually contain pre-release implicit information to generate mass interest. In this paper, we work for automated multi-label genre identification only from movie poster images, without any aid of additional textual/meta-data information about movies, which is one of 
    
[^31]: 基于能耗的立方卫星任务调度的安全层次化强化学习

    Safe Hierarchical Reinforcement Learning for CubeSat Task Scheduling Based on Energy Consumption. (arXiv:2309.12004v1 [cs.LG])

    [http://arxiv.org/abs/2309.12004](http://arxiv.org/abs/2309.12004)

    本文提出了一种针对立方卫星任务调度的层次化强化学习方法，通过整合任务优先级排序和能耗预测，实现了一个安全且容错的系统，并在多个立方卫星配置下优于MADDPG模型和传统随机调度。

    

    本文提出了一种针对低地球轨道（LEO）中立方卫星任务调度进行优化的层次化强化学习方法。该方法包括用于全局任务分配的高级策略和用于实时调整的低级策略作为安全机制，整合了基于相似度注意力编码器（SABE）进行任务优先级排序以及用于能耗预测的多层感知器（MLP）估计器。该机制的整合为立方卫星任务调度创建了一个安全且容错的系统。仿真结果证明了层次化强化学习具有更好的收敛性和任务成功率，优于MADDPG模型和传统随机调度在多个立方卫星配置下的表现。

    This paper presents a Hierarchical Reinforcement Learning methodology tailored for optimizing CubeSat task scheduling in Low Earth Orbits (LEO). Incorporating a high-level policy for global task distribution and a low-level policy for real-time adaptations as a safety mechanism, our approach integrates the Similarity Attention-based Encoder (SABE) for task prioritization and an MLP estimator for energy consumption forecasting. Integrating this mechanism creates a safe and fault-tolerant system for CubeSat task scheduling. Simulation results validate the Hierarchical Reinforcement Learning superior convergence and task success rate, outperforming both the MADDPG model and traditional random scheduling across multiple CubeSat configurations.
    
[^32]: LMSYS-Chat-1M：一个大规模实际语言模型对话数据集

    LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset. (arXiv:2309.11998v1 [cs.CL])

    [http://arxiv.org/abs/2309.11998](http://arxiv.org/abs/2309.11998)

    LMSYS-Chat-1M是一个包含一百万个实际对话的大规模数据集，通过其多样性和用例展示了其在理解和推进LLM能力方面的价值。

    

    随着大规模语言模型（LLM）在各种应用中的广泛使用，研究人们如何在实际场景中与其交互变得越来越重要。在本文中，我们介绍了LMSYS-Chat-1M，这是一个包含一百万个与25个最先进的LLM进行的实际对话的大规模数据集。这个数据集是从我们的Vicuna演示和Chatbot Arena网站上的21万个独立IP地址中收集而来的。我们提供了数据集内容的概述，包括其策划过程、基本统计数据和主题分布，强调其多样性、独特性和规模。我们通过四个用例展示了它的多样性：开发与GPT-4表现相似的内容过滤模型、构建一个安全基准、训练与Vicuna表现相似的指令跟随模型、创建具有挑战性的基准问题。我们相信这个数据集将成为我们理解和推进LLM能力的宝贵资源。

    Studying how people interact with large language models (LLMs) in real-world scenarios is increasingly important due to their widespread use in various applications. In this paper, we introduce LMSYS-Chat-1M, a large-scale dataset containing one million real-world conversations with 25 state-of-the-art LLMs. This dataset is collected from 210K unique IP addresses in the wild on our Vicuna demo and Chatbot Arena website. We offer an overview of the dataset's content, including its curation process, basic statistics, and topic distribution, highlighting its diversity, originality, and scale. We demonstrate its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that perform similarly to Vicuna, and creating challenging benchmark questions. We believe that this dataset will serve as a valuable resource for understanding and advancing LLM capabilities. The dataset is pub
    
[^33]: 后置解释方法中的可预测性和可理解性：一项以用户为中心的分析

    Predictability and Comprehensibility in Post-Hoc XAI Methods: A User-Centered Analysis. (arXiv:2309.11987v1 [cs.LG])

    [http://arxiv.org/abs/2309.11987](http://arxiv.org/abs/2309.11987)

    通过用户研究，分析了后置解释方法中的可理解性和可预测性。发现当解释集中在模型决策边界附近的样本时，SHAP的可理解性显著降低。另外，发现反事实解释和错误分类可以显著提高用户对机器学习模型决策原理的理解。根据研究结果，提出了增强后置解释方法可理解性和可预测性的设计建议。

    

    后置解释方法旨在澄清黑盒机器学习模型的预测结果。然而，用户对提供的解释有多好理解以及这些解释是否增强了用户对模型行为的预测能力仍然不清楚。我们通过进行用户研究来解决这个问题，评估了两种广泛使用的工具（LIME和SHAP）的可理解性和可预测性。此外，我们还研究了反事实解释和错误分类对用户理解和预测模型行为能力的影响。我们发现，当为接近模型决策边界的样本提供解释时，SHAP的可理解性显著降低。此外，我们还发现，反事实解释和错误分类可以显著增加用户对机器学习模型决策原理的理解。根据我们的研究结果，我们还提出了未来后置解释方法的设计建议，以增强其可理解性和可预测性。

    Post-hoc explainability methods aim to clarify predictions of black-box machine learning models. However, it is still largely unclear how well users comprehend the provided explanations and whether these increase the users ability to predict the model behavior. We approach this question by conducting a user study to evaluate comprehensibility and predictability in two widely used tools: LIME and SHAP. Moreover, we investigate the effect of counterfactual explanations and misclassifications on users ability to understand and predict the model behavior. We find that the comprehensibility of SHAP is significantly reduced when explanations are provided for samples near a model's decision boundary. Furthermore, we find that counterfactual explanations and misclassifications can significantly increase the users understanding of how a machine learning model is making decisions. Based on our findings, we also derive design recommendations for future post-hoc explainability methods with increas
    
[^34]: 表示抽象作为强化学习代理的激励：基于机器人抓取的案例研究

    Representation Abstractions as Incentives for Reinforcement Learning Agents: A Robotic Grasping Case Study. (arXiv:2309.11984v1 [cs.RO])

    [http://arxiv.org/abs/2309.11984](http://arxiv.org/abs/2309.11984)

    本文研究了不同状态表示对强化学习代理在机器人抓取任务上的影响，结果显示使用数字状态的代理能够在模拟环境中成功解决问题，并在真实机器人上实现了学习策略的可转移性。

    

    选择一个适当的环境表示对于强化学习代理的决策过程并不总是简单的。状态表示应该足够包容，以便让代理能够信息地决定其行动，并且足够紧凑，以提高策略训练的样本效率。本文研究了不同状态表示对代理在特定机器人任务（对称和平面物体抓取）上解决问题的影响。从具有完整系统知识的基于模型的方法开始，通过手工数字表示到基于图像的表示，逐渐减少任务特定知识的引入量，定义了一系列状态表示抽象。我们研究了每种表示对代理在仿真环境中解决任务以及学到的策略在真实机器人上的可转移性的影响。结果表明，使用数字状态的强化学习代理能够在模拟环境中解决问题。

    Choosing an appropriate representation of the environment for the underlying decision-making process of the \gls{RL} agent is not always straightforward. The state representation should be inclusive enough to allow the agent to informatively decide on its actions and compact enough to increase sample efficiency for policy training. Given this outlook, this work examines the effect of various state representations in incentivizing the agent to solve a specific robotic task: antipodal and planar object grasping. A continuum of state representation abstractions is defined, starting from a model-based approach with complete system knowledge, through hand-crafted numerical, to image-based representations with decreasing level of induced task-specific knowledge. We examine the effects of each representation in the ability of the agent to solve the task in simulation and the transferability of the learned policy to the real robot. The results show that RL agents using numerical states can per
    
[^35]: 重新思考人工智能系统中自然语言理解的评估框架：以语言习得为未来度量的核心

    Rethinking the Evaluating Framework for Natural Language Understanding in AI Systems: Language Acquisition as a Core for Future Metrics. (arXiv:2309.11981v1 [cs.CL])

    [http://arxiv.org/abs/2309.11981](http://arxiv.org/abs/2309.11981)

    这篇论文重新思考了人工智能系统中自然语言理解的评估框架，提出了以语言习得为核心的全面框架，旨在解决传统度量方法面临的问题，并借鉴了大型语言模型的进展。

    

    在人工智能领域，大型语言模型在自然语言处理方面取得了前所未有的进展，这为重新审视传统的机器智能度量方法提供了机会。本文提出了一个新的评估框架，从传统的图灵测试转向以语言习得为核心的全面框架，并借鉴了最近在大型语言模型方面的进展。本文深受多个学科的卓越工作的影响，指出了保持跨学科桥梁开放的必要性，并勾勒了一个更加稳健和可持续的方法。

    In the burgeoning field of artificial intelligence (AI), the unprecedented progress of large language models (LLMs) in natural language processing (NLP) offers an opportunity to revisit the entire approach of traditional metrics of machine intelligence, both in form and content. As the realm of machine cognitive evaluation has already reached Imitation, the next step is an efficient Language Acquisition and Understanding. Our paper proposes a paradigm shift from the established Turing Test towards an all-embracing framework that hinges on language acquisition, taking inspiration from the recent advancements in LLMs. The present contribution is deeply tributary of the excellent work from various disciplines, point out the need to keep interdisciplinary bridges open, and delineates a more robust and sustainable approach.
    
[^36]: 从任务表现中推断能力的贝叶斯三角测量方法

    Inferring Capabilities from Task Performance with Bayesian Triangulation. (arXiv:2309.11975v1 [cs.AI])

    [http://arxiv.org/abs/2309.11975](http://arxiv.org/abs/2309.11975)

    本研究提出了一种使用贝叶斯三角测量方法从任务表现中推断系统能力的方法，并利用该方法推断了不同认知特征的代理。这种能力导向的评估方法对于机器学习模型的表征具有潜在的应用价值。

    

    随着机器学习模型变得更加通用，我们需要以更丰富、更有意义的方式对其进行表征。我们描述了一种从多样化实验数据中推断系统的认知特征的方法。为此，我们引入了测量布局，模拟了任务实例特征如何与系统能力相互作用以影响性能。这些特征必须以复杂的方式进行三角测量，以便从非群体数据中推断能力，这对于传统的心理测量和推理工具是一个挑战。利用贝叶斯概率编程库PyMC，我们推断了两种情景中代理的不同认知特征：动物智能奥林匹克竞赛中的68名实际参赛选手和O-PIAAGETS的30个合成代理，其中O-PIAAGETS是一个物体恒常性测验。我们展示了以能力为导向的评估的潜力。

    As machine learning models become more general, we need to characterise them in richer, more meaningful ways. We describe a method to infer the cognitive profile of a system from diverse experimental data. To do so, we introduce measurement layouts that model how task-instance features interact with system capabilities to affect performance. These features must be triangulated in complex ways to be able to infer capabilities from non-populational data -- a challenge for traditional psychometric and inferential tools. Using the Bayesian probabilistic programming library PyMC, we infer different cognitive profiles for agents in two scenarios: 68 actual contestants in the AnimalAI Olympics and 30 synthetic agents for O-PIAAGETS, an object permanence battery. We showcase the potential for capability-oriented evaluation.
    
[^37]: 对可解释性人工智能在金融领域的综合回顾

    A Comprehensive Review on Financial Explainable AI. (arXiv:2309.11960v1 [cs.AI])

    [http://arxiv.org/abs/2309.11960](http://arxiv.org/abs/2309.11960)

    本文回顾了在金融领域中改善深度学习模型可解释性的各种方法，并讨论了相关的挑战和未来发展方向。

    

    人工智能（AI）的成功，特别是深度学习模型的成功，使其在各个行业得到了广泛应用，因为它们能够处理大量数据和学习复杂模式。然而，由于缺乏可解释性，人们对于在金融和医疗等重要行业中使用这些模型存在重大担忧，因为决策透明性至关重要。在本文中，我们对在金融背景下改善深度学习模型可解释性的方法进行了对比调查。我们根据各种可解释性人工智能方法的特点对其进行分类，并回顾了采用可解释性人工智能方法的关切和挑战，以及我们认为适当和重要的未来方向。

    The success of artificial intelligence (AI), and deep learning models in particular, has led to their widespread adoption across various industries due to their ability to process huge amounts of data and learn complex patterns. However, due to their lack of explainability, there are significant concerns regarding their use in critical sectors, such as finance and healthcare, where decision-making transparency is of paramount importance. In this paper, we provide a comparative survey of methods that aim to improve the explainability of deep learning models within the context of finance. We categorize the collection of explainable AI methods according to their corresponding characteristics, and we review the concerns and challenges of adopting explainable AI methods, together with future directions we deemed appropriate and important.
    
[^38]: 对适当信任的定义及其相关工具

    On the Definition of Appropriate Trust and the Tools that Come with it. (arXiv:2309.11937v1 [cs.AI])

    [http://arxiv.org/abs/2309.11937](http://arxiv.org/abs/2309.11937)

    本文讨论了对适当信任的定义，并提出了一种基于定义相似性的评估方法，以增强用户对模型的信任。

    

    评估人工智能与人类之间的交互效率是具有挑战性的，包括主观和客观的质量方面。专注于解释的人类体验，解释方法的评估主要是主观的，使得比较评估几乎不可能，并且与个体用户高度相关。然而，普遍认为解释质量的一个方面是用户能否有效地检测预测的可信度和正确性，即解释是否能增强用户对模型的适当信任。本文从文献中开始对适当信任的定义进行讨论。同时将定义与模型性能评估进行比较，展示了适当信任和模型性能评估之间的强大相似之处。本文的主要创新是通过利用这些定义之间的相似性来评估适当信任的一种新方法。本文提供了几种简单直观的评估方法。

    Evaluating the efficiency of human-AI interactions is challenging, including subjective and objective quality aspects. With the focus on the human experience of the explanations, evaluations of explanation methods have become mostly subjective, making comparative evaluations almost impossible and highly linked to the individual user. However, it is commonly agreed that one aspect of explanation quality is how effectively the user can detect if the predictions are trustworthy and correct, i.e., if the explanations can increase the user's appropriate trust in the model. This paper starts with the definitions of appropriate trust from the literature. It compares the definitions with model performance evaluation, showing the strong similarities between appropriate trust and model performance evaluation. The paper's main contribution is a novel approach to evaluating appropriate trust by taking advantage of the likenesses between definitions. The paper offers several straightforward evaluat
    
[^39]: 学习恢复以实现安全强化学习

    Learning to Recover for Safe Reinforcement Learning. (arXiv:2309.11907v1 [cs.AI])

    [http://arxiv.org/abs/2309.11907](http://arxiv.org/abs/2309.11907)

    该论文提出了一种三阶段的安全强化学习架构，通过学习来构建安全控制器，以在任务训练中确保安全性。为了缓解对抗现象，同时帮助任务策略从高风险状态中恢复，提出了辅助奖励。在机器人导航任务中进行了实验证明。

    

    安全控制器被广泛用于实现安全强化学习。大多数应用安全控制器的方法都使用手工制定的安全约束来构建安全控制器。然而，当环境动态复杂时，手工制定的安全约束变得不可用。因此，有必要研究通过学习算法构建安全控制器。我们提出了一个三阶段的安全强化学习架构，即TU恢复架构。在任务训练之前学习安全评估器和恢复策略。它们形成一个安全控制器，以确保任务训练的安全性。然后，描述了一种由任务策略和恢复策略之间的不一致引起的现象，称为对抗现象，该现象降低了学习效率和模型性能。我们提出了辅助奖励来缓解对抗现象，同时帮助任务策略学习从高风险状态中恢复。在机器人导航任务中进行了一系列实验。

    Safety controllers is widely used to achieve safe reinforcement learning. Most methods that apply a safety controller are using handcrafted safety constraints to construct the safety controller. However, when the environment dynamics are sophisticated, handcrafted safety constraints become unavailable. Therefore, it worth to research on constructing safety controllers by learning algorithms. We propose a three-stage architecture for safe reinforcement learning, namely TU-Recovery Architecture. A safety critic and a recovery policy is learned before task training. They form a safety controller to ensure safety in task training. Then a phenomenon induced by disagreement between task policy and recovery policy, called adversarial phenomenon, which reduces learning efficiency and model performance, is described. Auxiliary reward is proposed to mitigate adversarial phenomenon, while help the task policy to learn to recover from high-risk states. A series of experiments are conducted in a ro
    
[^40]: 使用自适应锁定无知网络解锁心脏

    Unlocking the Heart Using Adaptive Locked Agnostic Networks. (arXiv:2309.11899v1 [cs.CV])

    [http://arxiv.org/abs/2309.11899](http://arxiv.org/abs/2309.11899)

    使用自适应锁定无知网络（ALAN）进行自我监督训练，生成解剖学上鲁棒的语义自我分割，减少对标记数据的需求。

    

    对于医学图像应用的深度学习模型的监督训练需要大量标记数据。这对于需要医学专业人员进行注释的图像来说是一个挑战。为了解决这个限制，我们引入了自适应锁定无知网络（ALAN），这是一个涉及使用大型骨干模型进行自我监督视觉特征提取的概念，以产生解剖学上鲁棒的语义自我分割。在ALAN方法中，这种自我监督训练仅在大型和多样化的数据集上进行一次。由于分割的直观可解释性，可以使用少量参数的白盒模型轻松设计用于特定任务的下游模型。这反过来意味着与完全监督方法相比，下游模型对数据的需求较少。这些特性

    Supervised training of deep learning models for medical imaging applications requires a significant amount of labeled data. This is posing a challenge as the images are required to be annotated by medical professionals. To address this limitation, we introduce the Adaptive Locked Agnostic Network (ALAN), a concept involving self-supervised visual feature extraction using a large backbone model to produce anatomically robust semantic self-segmentation. In the ALAN methodology, this self-supervised training occurs only once on a large and diverse dataset. Due to the intuitive interpretability of the segmentation, downstream models tailored for specific tasks can be easily designed using white-box models with few parameters. This, in turn, opens up the possibility of communicating the inner workings of a model with domain experts and introducing prior knowledge into it. It also means that the downstream models become less data-hungry compared to fully supervised approaches. These characte
    
[^41]: 基于音频对比的微调方法

    Audio Contrastive based Fine-tuning. (arXiv:2309.11895v1 [cs.SD])

    [http://arxiv.org/abs/2309.11895](http://arxiv.org/abs/2309.11895)

    本论文提出了一种基于音频对比的微调方法（AudioConFit），通过借助对比学习的可转移性，该方法在各种音频分类任务中表现出强大的泛化能力，并在不同设置下实现了最先进的结果。

    

    音频分类在语音和声音处理任务中起着至关重要的作用，具有广泛的应用。在将模型拟合到训练数据（避免过拟合）并使其能够良好地泛化到新领域之间仍然存在着平衡的挑战。借助对比学习的可转移性，我们引入了基于音频对比的微调方法（AudioConFit），这种方法具有强大的泛化能力。对各种音频分类任务的实证实验表明了我们方法的有效性和鲁棒性，在不同设置下取得了最先进的结果。

    Audio classification plays a crucial role in speech and sound processing tasks with a wide range of applications. There still remains a challenge of striking the right balance between fitting the model to the training data (avoiding overfitting) and enabling it to generalise well to a new domain. Leveraging the transferability of contrastive learning, we introduce Audio Contrastive-based Fine-tuning (AudioConFit), an efficient approach characterised by robust generalisability. Empirical experiments on a variety of audio classification tasks demonstrate the effectiveness and robustness of our approach, which achieves state-of-the-art results in various settings.
    
[^42]: 多级非对称对比学习在医学图像分割预训练中的应用

    Multi-level Asymmetric Contrastive Learning for Medical Image Segmentation Pre-training. (arXiv:2309.11876v1 [cs.CV])

    [http://arxiv.org/abs/2309.11876](http://arxiv.org/abs/2309.11876)

    本论文提出了一种针对医学图像分割的自我监督预训练方法，通过多级非对称对比学习的框架，在编码器和解码器同时进行预训练，提供更好的分割模型初始化。

    

    对比学习是一种从无标签数据中学习图像级表示的强大技术，为解决大规模预训练和有限标注数据之间的困境提供了一种有前途的方法。然而，大多数现有的对比学习策略主要针对自然图像的下游任务设计，因此当直接应用于医学图像（其下游任务通常是分割）时，它们往往是次优的甚至不如从头开始训练。在这项工作中，我们提出了一种名为JCL的新型非对称对比学习框架，用于医学图像分割的自我监督预训练。具体来说，（1）我们提出了一种新颖的非对称对比学习策略，同时在一阶段内对编码器和解码器进行预训练，以提供更好的分割模型初始化。 （2）我们设计了一个多级对比损失，用于考虑特征级别、图像级别和像素级别投影的对应关系。

    Contrastive learning, which is a powerful technique for learning image-level representations from unlabeled data, leads a promising direction to dealing with the dilemma between large-scale pre-training and limited labeled data. However, most existing contrastive learning strategies are designed mainly for downstream tasks of natural images, therefore they are sub-optimal and even worse than learning from scratch when directly applied to medical images whose downstream tasks are usually segmentation. In this work, we propose a novel asymmetric contrastive learning framework named JCL for medical image segmentation with self-supervised pre-training. Specifically, (1) A novel asymmetric contrastive learning strategy is proposed to pre-train both encoder and decoder simultaneously in one-stage to provide better initialization for segmentation models. (2) A multi-level contrastive loss is designed to take the correspondence among feature-level, image-level and pixel-level projections, resp
    
[^43]: 基于物理信息高斯过程的Timoshenko梁的随机刚度识别和响应估计

    Stochastic stiffness identification and response estimation of Timoshenko beams via physics-informed Gaussian processes. (arXiv:2309.11875v1 [cs.LG])

    [http://arxiv.org/abs/2309.11875](http://arxiv.org/abs/2309.11875)

    本文提出了一种基于物理信息的高斯过程模型，用于Timoshenko梁的刚度识别和响应估计。通过马尔可夫链蒙特卡洛方法进行贝叶斯优化，得到结构参数的随机模型。模型还可用于概率预测未观测到的响应，并提出了一种基于熵的传感器布置优化方法。

    

    使用结构健康监测数据训练的机器学习模型已成为系统识别的强大工具。本文提出了一种基于物理信息的高斯过程模型，用于Timoshenko梁元素。该模型是一个多输出高斯过程，其协方差和交叉协方差核根据挠度、转动、应变、弯矩、剪力和施加载荷的微分方程解析地推导而来。通过马尔可夫链蒙特卡洛方法在贝叶斯格式下进行刚度识别，最大化后验模型，得到结构参数的随机模型。优化后的高斯过程模型进一步用于对未观测到的响应进行概率预测。此外，还提出了一种基于熵的物理信息传感器布置优化方法，利用异质传感器位置信息和嵌入高斯过程模型的结构边界条件。结果表明，所提出的方法能有效识别刚度并预测未观测到的响应。

    Machine learning models trained with structural health monitoring data have become a powerful tool for system identification. This paper presents a physics-informed Gaussian process (GP) model for Timoshenko beam elements. The model is constructed as a multi-output GP with covariance and cross-covariance kernels analytically derived based on the differential equations for deflections, rotations, strains, bending moments, shear forces and applied loads. Stiffness identification is performed in a Bayesian format by maximising a posterior model through a Markov chain Monte Carlo method, yielding a stochastic model for the structural parameters. The optimised GP model is further employed for probabilistic predictions of unobserved responses. Additionally, an entropy-based method for physics-informed sensor placement optimisation is presented, exploiting heterogeneous sensor position information and structural boundary conditions built into the GP model. Results demonstrate that the propose
    
[^44]: OSNet和MNetO：适用于多种场景的线性计算机断层扫描的两种通用重建架构

    OSNet & MNetO: Two Types of General Reconstruction Architectures for Linear Computed Tomography in Multi-Scenarios. (arXiv:2309.11858v1 [cs.CV])

    [http://arxiv.org/abs/2309.11858](http://arxiv.org/abs/2309.11858)

    本论文提出了两种通用的线性计算机断层扫描的重建架构（OSNet和MNetO），旨在解决在LCT中实现稳定内部重建和避免希尔伯特滤波旋转操作的问题。

    

    最近，线性计算机断层扫描（LCT）系统引起了人们的广泛关注。为了减弱LCT中的投影截断并对感兴趣区域（ROI）进行成像，反投影滤波（BPF）算法是一个有效的解决方案。然而，在LCT的BPF中，很难实现稳定的内部重建，并且对于LCT的不同反投影（DBP）图像，多个旋转有限反演的希尔伯特变换（希尔伯特滤波）-反转操作将使图像模糊。为了满足LCT的多种重建场景，包括内部ROI、完整对象和超出视野范围的外部区域，并避免希尔伯特滤波的旋转操作，我们提出了两种重建架构。第一种是叠加多个DBP图像以获得完整的DBP图像，然后使用网络学习叠加的希尔伯特滤波函数，称为叠加单一网络（OSNet）。第二种是使用多个网络训练不同的反投影重构器网络（MNetO）。

    Recently, linear computed tomography (LCT) systems have actively attracted attention. To weaken projection truncation and image the region of interest (ROI) for LCT, the backprojection filtration (BPF) algorithm is an effective solution. However, in BPF for LCT, it is difficult to achieve stable interior reconstruction, and for differentiated backprojection (DBP) images of LCT, multiple rotation-finite inversion of Hilbert transform (Hilbert filtering)-inverse rotation operations will blur the image. To satisfy multiple reconstruction scenarios for LCT, including interior ROI, complete object, and exterior region beyond field-of-view (FOV), and avoid the rotation operations of Hilbert filtering, we propose two types of reconstruction architectures. The first overlays multiple DBP images to obtain a complete DBP image, then uses a network to learn the overlying Hilbert filtering function, referred to as the Overlay-Single Network (OSNet). The second uses multiple networks to train diffe
    
[^45]: BitCoin: 基于双向标记和监督对比学习的联合关系三元组提取框架

    BitCoin: Bidirectional Tagging and Supervised Contrastive Learning based Joint Relational Triple Extraction Framework. (arXiv:2309.11853v1 [cs.CL])

    [http://arxiv.org/abs/2309.11853](http://arxiv.org/abs/2309.11853)

    BitCoin是一种创新的基于双向标记和监督对比学习的联合关系三元组提取框架，用于解决关系三元组提取中的问题和局限性。通过设计监督对比学习方法，考虑了每个锚点的多个正例，提高了提取的效果。

    

    关系三元组提取是信息提取和知识图谱构建中的一项关键任务。尽管最近有了一些进展，但现有方法仍存在一定的局限性。它们仅使用泛化的预训练模型，并未考虑RTE任务的特殊性。此外，现有的基于标记的方法通常将RTE任务分解为两个子任务，首先识别主体，然后识别客体和关系。它们仅关注从主体到客体的关系三元组的提取，忽视了一旦主体提取失败，就无法提取与该主体相关的所有三元组的情况。为了解决这些问题，我们提出了BitCoin，这是一种创新的基于双向标记和监督对比学习的联合关系三元组提取框架。具体而言，我们设计了一种监督对比学习方法，该方法考虑了每个锚点的多个正例，而不仅仅限于一个正例。

    Relation triple extraction (RTE) is an essential task in information extraction and knowledge graph construction. Despite recent advancements, existing methods still exhibit certain limitations. They just employ generalized pre-trained models and do not consider the specificity of RTE tasks. Moreover, existing tagging-based approaches typically decompose the RTE task into two subtasks, initially identifying subjects and subsequently identifying objects and relations. They solely focus on extracting relational triples from subject to object, neglecting that once the extraction of a subject fails, it fails in extracting all triples associated with that subject. To address these issues, we propose BitCoin, an innovative Bidirectional tagging and supervised Contrastive learning based joint relational triple extraction framework. Specifically, we design a supervised contrastive learning method that considers multiple positives per anchor rather than restricting it to just one positive. Furt
    
[^46]: 在信息搜索对话中评估大型语言模型用于基于文档的响应生成

    Evaluating Large Language Models for Document-grounded Response Generation in Information-Seeking Dialogues. (arXiv:2309.11838v1 [cs.CL])

    [http://arxiv.org/abs/2309.11838](http://arxiv.org/abs/2309.11838)

    本文研究了在信息搜索对话中使用大型语言模型进行基于文档的响应生成，并通过人工评估了其性能。

    

    本文研究了在信息搜索对话的背景下，使用类似ChatGPT的大型语言模型（LLM）进行基于文档的响应生成。我们使用了先前在DialDoc 2022共享任务中使用的四个社会服务领域的任务导向对话的MultiDoc2Dial语料库进行评估。信息搜索对话的转换以多个提供相关信息的文档为基础。我们通过使用两种方法Chat-Completion和LlamaIndex，通过激发ChatGPT模型来生成对话完成响应。ChatCompletion使用ChatGPT模型的预训练知识，而LlamaIndex还从文档中提取相关信息。我们观察到，通过LLM进行基于文档的响应生成不能通过自动评估指标充分评估，因为它们更加冗长，所以我们进行了人工评估，其中评估员对共享任务的获奖系统、两个Chat-GPT变体的输出以及人类响应进行评级。

    In this paper, we investigate the use of large language models (LLMs) like ChatGPT for document-grounded response generation in the context of information-seeking dialogues. For evaluation, we use the MultiDoc2Dial corpus of task-oriented dialogues in four social service domains previously used in the DialDoc 2022 Shared Task. Information-seeking dialogue turns are grounded in multiple documents providing relevant information. We generate dialogue completion responses by prompting a ChatGPT model, using two methods: Chat-Completion and LlamaIndex. ChatCompletion uses knowledge from ChatGPT model pretraining while LlamaIndex also extracts relevant information from documents. Observing that document-grounded response generation via LLMs cannot be adequately assessed by automatic evaluation metrics as they are significantly more verbose, we perform a human evaluation where annotators rate the output of the shared task winning system, the two Chat-GPT variants outputs, and human responses.
    
[^47]: 多模态变压器用于无线通信：一种基于波束预测的案例研究

    Multimodal Transformers for Wireless Communications: A Case Study in Beam Prediction. (arXiv:2309.11811v1 [eess.SP])

    [http://arxiv.org/abs/2309.11811](http://arxiv.org/abs/2309.11811)

    本文提出了一种多模态变压器深度学习框架，用于无线通信中的波束预测。该框架通过利用相机、LiDAR、雷达和GPS等多种感知信息，提取并学习不同模态和时间实例之间的特征关系，从而在波束管理中具有较好的性能。

    

    在高频段和大天线阵列的无线通信中，波束管理面临着挑战，可以通过来自相机、LiDAR、雷达和GPS的多模态感知信息进行改进。本文提出了一种多模态变压器深度学习框架用于辅助波束预测。我们采用卷积神经网络从一系列图像、点云和雷达原始数据中提取特征。在每个卷积层中，我们使用变压器编码器学习不同模态和时间实例之间特征标记的隐藏关系，以在抽象空间中生成编码向量以便进行下一级的特征提取。我们使用有监督学习训练模型，结合不同模态的组合。我们尝试通过使用焦点损失和指数移动平均来增强模型对不平衡数据的处理。我们还评估了图像增强、数据处理和增强技术。

    Wireless communications at high-frequency bands with large antenna arrays face challenges in beam management, which can potentially be improved by multimodality sensing information from cameras, LiDAR, radar, and GPS. In this paper, we present a multimodal transformer deep learning framework for sensing-assisted beam prediction. We employ a convolutional neural network to extract the features from a sequence of images, point clouds, and radar raw data sampled over time. At each convolutional layer, we use transformer encoders to learn the hidden relations between feature tokens from different modalities and time instances over abstraction space and produce encoded vectors for the next-level feature extraction. We train the model on a combination of different modalities with supervised learning. We try to enhance the model over imbalanced data by utilizing focal loss and exponential moving average. We also evaluate data processing and augmentation techniques such as image enhancement, s
    
[^48]: JobRecoGPT -- 使用LLMs进行可解释的职位推荐

    JobRecoGPT -- Explainable job recommendations using LLMs. (arXiv:2309.11805v1 [cs.AI])

    [http://arxiv.org/abs/2309.11805](http://arxiv.org/abs/2309.11805)

    JobRecoGPT是一个使用LLMs实现的可解释的职位推荐系统，在处理职位描述和简历中的非结构化数据时，它能够捕捉到之前丢失的信息。

    

    在当今快速发展的就业市场中，找到合适的机会可能是一项艰巨的挑战。随着人工智能领域的进步，计算机现在可以向候选人推荐适合的工作。然而，推荐工作的任务与向观众推荐电影并不相同。除了技能和经验等必备条件外，一个工作是否适合给定候选人还取决于许多微妙的方面。传统的方法可以捕捉到工作和候选人的可量化方面，但在将数据从非结构化形式（如工作描述和简历）转化为结构化形式的过程中，数据的很大一部分会丢失。最近，大型语言模型（LLMs）以其在文本数据可用的领域表现出的卓越性能席卷了人工智能领域。受到LLMs出色表现的启发，我们利用它们理解自然语言的能力，以捕捉到先前在非结构化数据中丢失的信息。

    In today's rapidly evolving job market, finding the right opportunity can be a daunting challenge. With advancements in the field of AI, computers can now recommend suitable jobs to candidates. However, the task of recommending jobs is not same as recommending movies to viewers. Apart from must-have criteria, like skills and experience, there are many subtle aspects to a job which can decide if it is a good fit or not for a given candidate. Traditional approaches can capture the quantifiable aspects of jobs and candidates, but a substantial portion of the data that is present in unstructured form in the job descriptions and resumes is lost in the process of conversion to structured format. As of late, Large Language Models (LLMs) have taken over the AI field by storm with extraordinary performance in fields where text-based data is available. Inspired by the superior performance of LLMs, we leverage their capability to understand natural language for capturing the information that was 
    
[^49]: DimCL: 用于改进自监督学习的维度对比学习

    DimCL: Dimensional Contrastive Learning For Improving Self-Supervised Learning. (arXiv:2309.11782v1 [cs.CV])

    [http://arxiv.org/abs/2309.11782](http://arxiv.org/abs/2309.11782)

    DimCL是一种在自监督学习中改进特征多样性的维度对比学习方法。实验证明DimCL的硬样本特性是成功的关键因素。将DimCL融入SSL框架可以提高性能。

    

    自监督学习（SSL）取得了显著的成功，其中对比学习（CL）起到了关键作用。然而，最近发展起来的新的非CL框架已经取得了可比甚至更好的性能，并且有很大的改进潜力，这促使研究人员进一步提升这些框架。将CL融入非CL框架被认为是有益的，但经验证据表明没有明显的改进。基于此，本文提出了一种在维度方向上执行CL而不是以传统的批次方向进行对比学习的策略，命名为Dimensional Contrastive Learning（DimCL）。DimCL旨在增强特征的多样性，并且可以作为先前的SSL框架的正则化器。结果发现DimCL是有效的，并且硬样本对其成功起到了关键作用。广泛的实验结果表明将DimCL融入SSL框架可以提高性能。

    Self-supervised learning (SSL) has gained remarkable success, for which contrastive learning (CL) plays a key role. However, the recent development of new non-CL frameworks has achieved comparable or better performance with high improvement potential, prompting researchers to enhance these frameworks further. Assimilating CL into non-CL frameworks has been thought to be beneficial, but empirical evidence indicates no visible improvements. In view of that, this paper proposes a strategy of performing CL along the dimensional direction instead of along the batch direction as done in conventional contrastive learning, named Dimensional Contrastive Learning (DimCL). DimCL aims to enhance the feature diversity, and it can serve as a regularizer to prior SSL frameworks. DimCL has been found to be effective, and the hardness-aware property is identified as a critical reason for its success. Extensive experimental results reveal that assimilating DimCL into SSL frameworks leads to performance 
    
[^50]: 2DDATA: 基于点云的语义分割的二维检测注释传输聚合

    2DDATA: 2D Detection Annotations Transmittable Aggregation for Semantic Segmentation on Point Cloud. (arXiv:2309.11755v1 [cs.CV])

    [http://arxiv.org/abs/2309.11755](http://arxiv.org/abs/2309.11755)

    本论文提出了2DDATA方法，通过引入数据特定的分支和利用RGB模态信息，解决了多模态信息融合的问题，并证明了大型多模态模型融合的可行性。

    

    最近，由于不同传感器（如LiDAR和摄像头）提供的互补信息，多模态模型受到关注。然而，这需要准确校准的配对数据以及模态之间复杂的校准，从而增加了高质量数据集的收集成本，并限制了其在实际场景中的应用。鉴于此前的工作，我们不仅解决了多模态信息融合的问题，还充分利用了RGB模态中的信息。我们引入了2D Detection Annotations Transmittable Aggregation（2DDATA），设计了一个数据特定的分支，称为Local Object Branch，旨在处理某个边界框内的点云，因为获取2D边界框注释相对容易。我们证明了我们的简单设计可以将边界框先验信息传输给3D编码器模型，从而验证了大型多模态模型融合的可行性。

    Recently, multi-modality models have been introduced because of the complementary information from different sensors such as LiDAR and cameras. It requires paired data along with precise calibrations for all modalities, the complicated calibration among modalities hugely increases the cost of collecting such high-quality datasets, and hinder it from being applied to practical scenarios. Inherit from the previous works, we not only fuse the information from multi-modality without above issues, and also exhaust the information in the RGB modality. We introduced the 2D Detection Annotations Transmittable Aggregation(\textbf{2DDATA}), designing a data-specific branch, called \textbf{Local Object Branch}, which aims to deal with points in a certain bounding box, because of its easiness of acquiring 2D bounding box annotations. We demonstrate that our simple design can transmit bounding box prior information to the 3D encoder model, proving the feasibility of large multi-modality models fuse
    
[^51]: 通过自然语言引导的语义探索，提高深度强化学习的效率

    Improve the efficiency of deep reinforcement learning through semantic exploration guided by natural language. (arXiv:2309.11753v1 [cs.AI])

    [http://arxiv.org/abs/2309.11753](http://arxiv.org/abs/2309.11753)

    通过自然语言引导的语义探索，提高深度强化学习的效率。通过检索语料库中相关问题来与"神"级存在交互，更新代理的策略。

    

    强化学习是一种从试错中学习的强大技术，但通常需要大量的交互才能达到良好的性能。在某些领域中，如稀疏奖励任务，一个能在学习过程中为代理提供有用反馈或指导的"神"级存在是非常重要的。然而，过于频繁地查询"神"级存在可能是昂贵或不切实际的，而且"神"级存在可能并不总是对每个情况都有明确的答案。因此，我们提出了一种基于检索的方法，以选择性和高效的方式与"神"级存在进行交互。我们假设交互可以被建模为一系列模板化的问题和答案，并且存在大量以前的交互的语料库。我们使用神经网络对代理和"神"级存在的当前状态进行编码，并从语料库中检索出最相关的问题来问"神"级存在。然后，我们使用"神"级存在的答案来更新代理的策略。

    Reinforcement learning is a powerful technique for learning from trial and error, but it often requires a large number of interactions to achieve good performance. In some domains, such as sparse-reward tasks, an oracle that can provide useful feedback or guidance to the agent during the learning process is really of great importance. However, querying the oracle too frequently may be costly or impractical, and the oracle may not always have a clear answer for every situation. Therefore, we propose a novel method for interacting with the oracle in a selective and efficient way, using a retrieval-based approach. We assume that the interaction can be modeled as a sequence of templated questions and answers, and that there is a large corpus of previous interactions available. We use a neural network to encode the current state of the agent and the oracle, and retrieve the most relevant question from the corpus to ask the oracle. We then use the oracle's answer to update the agent's policy
    
[^52]: Google的Bard在对抗图像攻击方面有多强大？

    How Robust is Google's Bard to Adversarial Image Attacks?. (arXiv:2309.11751v1 [cs.CV])

    [http://arxiv.org/abs/2309.11751](http://arxiv.org/abs/2309.11751)

    本文研究了Google的Bard在对抗图像攻击方面的鲁棒性，并发现它可以被攻击以输出错误的图像描述。这一攻击还可以对其他多模态语言模型产生影响。研究还发现了Bard的两种防御机制。

    

    结合文本和其他模态（尤其是视觉）的多模态大型语言模型（MLLM）在各种多模态任务中取得了前所未有的性能。然而，由于视觉模型的未解决的对抗鲁棒性问题，引入视觉输入可能使MLLM面临更严重的安全风险和安全风险。在这项工作中，我们研究了Google的Bard的对抗鲁棒性，它是一个竞争性的聊天机器人，最近发布了其多模态能力，以更好地了解商业MLLM的漏洞。通过攻击白盒子代理视觉编码器或MLLM，生成的对抗性示例可以使Bard以22％的成功率仅基于可转移性输出错误的图像描述。我们还表明，对抗性示例还可以攻击其他MLLM，例如，对Bing Chat的成功攻击率为26％，对ERNIE bot的成功攻击率为86％。此外，我们确定了Bard的两种防御机制，包括面部检测。

    Multimodal Large Language Models (MLLMs) that integrate text and other modalities (especially vision) have achieved unprecedented performance in various multimodal tasks. However, due to the unsolved adversarial robustness problem of vision models, MLLMs can have more severe safety and security risks by introducing the vision inputs. In this work, we study the adversarial robustness of Google's Bard, a competitive chatbot to ChatGPT that released its multimodal capability recently, to better understand the vulnerabilities of commercial MLLMs. By attacking white-box surrogate vision encoders or MLLMs, the generated adversarial examples can mislead Bard to output wrong image descriptions with a 22% success rate based solely on the transferability. We show that the adversarial examples can also attack other MLLMs, e.g., a 26% attack success rate against Bing Chat and a 86% attack success rate against ERNIE bot. Moreover, we identify two defense mechanisms of Bard, including face detection
    
[^53]: Choice-75：一个关于脚本学习中决策分支的数据集

    Choice-75: A Dataset on Decision Branching in Script Learning. (arXiv:2309.11737v1 [cs.AI])

    [http://arxiv.org/abs/2309.11737](http://arxiv.org/abs/2309.11737)

    Choice-75是一个关于脚本学习中决策分支的数据集，主要挑战智能系统在描述场景下预测决策。在许多难题中仍有改进的空间。

    

    脚本学习研究日常事件的展开方式。以往的研究往往将脚本视为线性的事件序列，忽略了人们在特定情境中所做出的选择可能带来的分支。因此，我们提出了Choice-75，这是第一个挑战智能系统根据描述场景预测决策的基准，包含75个脚本和600多个场景。尽管大型语言模型在整体上表现不错，但在许多困难的场景中仍有明显的改进空间。

    Script learning studies how daily events unfold. Previous works tend to consider a script as a linear sequence of events while ignoring the potential branches that arise due to people's circumstantial choices. We hence propose Choice-75, the first benchmark that challenges intelligent systems to predict decisions given descriptive scenarios, containing 75 scripts and more than 600 scenarios. While large language models demonstrate overall decent performances, there is still notable room for improvement in many hard scenarios.
    
[^54]: FluentEditor: 考虑声学和韵律一致性的基于文本的语音编辑

    FluentEditor: Text-based Speech Editing by Considering Acoustic and Prosody Consistency. (arXiv:2309.11725v1 [cs.SD])

    [http://arxiv.org/abs/2309.11725](http://arxiv.org/abs/2309.11725)

    这篇论文提出了一种名为"FluentEditor"的流畅语音编辑模型，通过考虑流畅度意识的训练准则实现文本化语音编辑。其中，声学一致性约束和韵律一致性约束用于保持语音的流畅性和整体风格一致性。

    

    文本化语音编辑（TSE）技术旨在使用户通过修改输入的文本转录而不是音频本身来编辑生成的音频。尽管神经网络基础的TSE技术取得了很大进展，但目前的技术主要关注于减小编辑区域中生成的语音片段与参考目标之间的差异，忽视了其在上下文和原始语句中的局部和整体流畅性。为了保持语音的流畅性，我们提出了一种流畅语音编辑模型，称为“FluentEditor”，通过考虑流畅度意识的训练准则进行TSE训练。具体而言，“声学一致性约束”旨在使编辑区域与其相邻的声学片段之间的过渡变得平滑并与真实情况保持一致，“韵律一致性约束”旨在确保编辑区域内的韵律属性与原始语句的整体风格保持一致。

    Text-based speech editing (TSE) techniques are designed to enable users to edit the output audio by modifying the input text transcript instead of the audio itself. Despite much progress in neural network-based TSE techniques, the current techniques have focused on reducing the difference between the generated speech segment and the reference target in the editing region, ignoring its local and global fluency in the context and original utterance. To maintain the speech fluency, we propose a fluency speech editing model, termed \textit{FluentEditor}, by considering fluency-aware training criterion in the TSE training. Specifically, the \textit{acoustic consistency constraint} aims to smooth the transition between the edited region and its neighboring acoustic segments consistent with the ground truth, while the \textit{prosody consistency constraint} seeks to ensure that the prosody attributes within the edited regions remain consistent with the overall style of the original utterance.
    
[^55]: 基于情感的韵律短语化用于表情化文本转语音

    Emotion-Aware Prosodic Phrasing for Expressive Text-to-Speech. (arXiv:2309.11724v1 [cs.AI])

    [http://arxiv.org/abs/2309.11724](http://arxiv.org/abs/2309.11724)

    这项研究提出了一种称为“EmoPP”的情感感知韵律短语模型，通过准确挖掘话语中的情感线索，预测适当的断点，从而改进了表情化文本转语音的性能和情感表达。

    

    韵律短语对于端到端的文本转语音(TTS)的自然性和可懂性至关重要。自然语音中存在着语言和情感的韵律。由于韵律短语研究一直以来以语言学为动力，因此表情化韵律短语化的研究还不够充分。在本文中，我们提出了一种称为“EmoPP”的情感感知韵律短语模型，准确地挖掘了话语中的情感线索，并预测了适当的短语断点。我们首先对ESD数据集进行客观观察，验证了情感和韵律短语之间的强相关性。然后，客观和主观评估表明，EmoPP优于所有基准线，并在情感表达方面取得了显著的性能。音频样本和代码可在\url{https://github.com/AI-S2-Lab/EmoPP}找到。

    Prosodic phrasing is crucial to the naturalness and intelligibility of end-to-end Text-to-Speech (TTS). There exist both linguistic and emotional prosody in natural speech. As the study of prosodic phrasing has been linguistically motivated, prosodic phrasing for expressive emotion rendering has not been well studied. In this paper, we propose an emotion-aware prosodic phrasing model, termed \textit{EmoPP}, to mine the emotional cues of utterance accurately and predict appropriate phrase breaks. We first conduct objective observations on the ESD dataset to validate the strong correlation between emotion and prosodic phrasing. Then the objective and subjective evaluations show that the EmoPP outperforms all baselines and achieves remarkable performance in terms of emotion expressiveness. The audio samples and the code are available at \url{https://github.com/AI-S2-Lab/EmoPP}.
    
[^56]: 一种用于基于EEG的运动想象分类的动态领域适应深度学习网络

    A Dynamic Domain Adaptation Deep Learning Network for EEG-based Motor Imagery Classification. (arXiv:2309.11714v1 [eess.SP])

    [http://arxiv.org/abs/2309.11714](http://arxiv.org/abs/2309.11714)

    本文提出了一种动态领域适应深度学习网络，用于解决基于EEG的运动想象分类中的通道相关性和个体差异问题。

    

    电脑脑电图（EEG）相邻通道之间存在相关性，如何表示这种相关性是当前研究的一个问题。此外，由于EEG信号在不同个体之间存在差异，这种差异导致新主体需要花费大量校准时间用于基于EEG的运动想象脑机接口。为了解决上述问题，我们提出了一种基于动态领域适应的深度学习网络（DADL-Net）。首先，将EEG数据映射到三维几何空间，并通过3D卷积模块学习其时空特征，然后使用空间通道注意机制强化特征，最后的卷积模块可以进一步学习特征的时空信息。最后，为了考虑个体间和跨会话的差异，我们采用动态领域自适应策略，通过引入最大化距离来减小特征之间的差异。

    There is a correlation between adjacent channels of electroencephalogram (EEG), and how to represent this correlation is an issue that is currently being explored. In addition, due to inter-individual differences in EEG signals, this discrepancy results in new subjects need spend a amount of calibration time for EEG-based motor imagery brain-computer interface. In order to solve the above problems, we propose a Dynamic Domain Adaptation Based Deep Learning Network (DADL-Net). First, the EEG data is mapped to the three-dimensional geometric space and its temporal-spatial features are learned through the 3D convolution module, and then the spatial-channel attention mechanism is used to strengthen the features, and the final convolution module can further learn the spatial-temporal information of the features. Finally, to account for inter-subject and cross-sessions differences, we employ a dynamic domain-adaptive strategy, the distance between features is reduced by introducing a Maximum
    
[^57]: RAI4IoE: 负责任的人工智能推动能源互联网发展

    RAI4IoE: Responsible AI for Enabling the Internet of Energy. (arXiv:2309.11691v1 [cs.AI])

    [http://arxiv.org/abs/2309.11691](http://arxiv.org/abs/2309.11691)

    本文旨在开发一个RAl4IoE框架，将能源互联网与人工智能技术相结合，实现公平、可持续和可靠的能源分配。

    

    本文旨在发展一个公平、负责任的人工智能框架，以推动能源互联网（IoE）。能源行业正面临两个重要的驱动因素：建设零碳能源行业和能源基础设施的数字化转型。我们预计这两个驱动因素的融合将实现能源互联网，通过利用先进的5G-6G网络和人工智能技术，将可再生分布式能源资源（如电动汽车、储能电池、风力涡轮和光伏发电）连接和集成，实现可靠的能源分配。这使得分布式能源资源的拥有者（即能源生产者和消费者）能够参与能源市场并获得经济激励。然而，分布式能源资源存在固有的资产驱动特征，并面临平等的挑战（即公平、多样和包容）。如果没有平等的获取机会，特权个体、群体和组织可能会以排斥其他人为代价参与和受益。

    This paper plans to develop an Equitable and Responsible AI framework with enabling techniques and algorithms for the Internet of Energy (IoE), in short, RAI4IoE. The energy sector is going through substantial changes fueled by two key drivers: building a zero-carbon energy sector and the digital transformation of the energy infrastructure. We expect to see the convergence of these two drivers resulting in the IoE, where renewable distributed energy resources (DERs), such as electric cars, storage batteries, wind turbines and photovoltaics (PV), can be connected and integrated for reliable energy distribution by leveraging advanced 5G-6G networks and AI technology. This allows DER owners as prosumers to participate in the energy market and derive economic incentives. DERs are inherently asset-driven and face equitable challenges (i.e., fair, diverse and inclusive). Without equitable access, privileged individuals, groups and organizations can participate and benefit at the cost of disa
    
[^58]: LLM引导的归纳推理解决组合问题

    LLM Guided Inductive Inference for Solving Compositional Problems. (arXiv:2309.11688v1 [cs.CL])

    [http://arxiv.org/abs/2309.11688](http://arxiv.org/abs/2309.11688)

    LLM引导的归纳推理方法REBEL通过递归问题分解和利用外部工具进行推理，能够解决组合问题和对话环境中的深度推理任务。

    

    虽然大型语言模型（LLMs）在问答任务中表现出令人印象深刻的性能，但当问题需要通过直接观察或与真实世界的交互来获取模型训练数据中不包括的知识时，它们的性能受到限制。现有的方法通过顺序调用模块来对推理任务进行分解，限制了它们回答深度推理任务的能力。我们引入了一种方法，基于递归的可扩展LLM（REBEL），通过使用动态规划和前向链接策略等自动推理技术处理开放世界的深度推理任务。REBEL通过递归问题分解和利用外部工具进行推理。REBEL使用的工具仅通过自然语言描述来指定。我们进一步在组合和对话环境中的一组需要深度嵌套的外部工具使用问题上展示了REBEL的能力。

    While large language models (LLMs) have demonstrated impressive performance in question-answering tasks, their performance is limited when the questions require knowledge that is not included in the model's training data and can only be acquired through direct observation or interaction with the real world. Existing methods decompose reasoning tasks through the use of modules invoked sequentially, limiting their ability to answer deep reasoning tasks. We introduce a method, Recursion based extensible LLM (REBEL), which handles open-world, deep reasoning tasks by employing automated reasoning techniques like dynamic planning and forward-chaining strategies. REBEL allows LLMs to reason via recursive problem decomposition and utilization of external tools. The tools that REBEL uses are specified only by natural language description. We further demonstrate REBEL capabilities on a set of problems that require a deeply nested use of external tools in a compositional and conversational settin
    
[^59]: Dr. FERMI：一种基于随机分布鲁棒的公平经验风险最小化框架

    Dr. FERMI: A Stochastic Distributionally Robust Fair Empirical Risk Minimization Framework. (arXiv:2309.11682v1 [cs.LG])

    [http://arxiv.org/abs/2309.11682](http://arxiv.org/abs/2309.11682)

    本文提出了一个基于随机分布鲁棒的公平性框架，解决了训练和测试数据分布不一致时公平模型表现不准确的问题，并且不需要知道因果图，也支持使用小批量数据。

    

    虽然最近几年已经广泛研究了训练公平机器学习模型的方法，但大多数方法都依赖于训练和测试数据具有相似的分布的假设。在分布发生变化的情况下，公平模型可能在测试数据上表现不公平。为了解决这个问题，已经提出了一些针对分布变化的公平学习方法。然而，大多数现有的解决方案都基于具有描述不同特征交互的因果图的假设。此外，现有的算法需要完全访问数据，不能在使用小批量（随机/批量实现）时使用。本文提出了第一个具有收敛保证的随机分布鲁棒公平性框架，不需要对因果图有任何知识。具体而言，我们将在分布发生变化的情况下的公平推断问题制定为$L_p$-范的分布鲁棒优化问题。

    While training fair machine learning models has been studied extensively in recent years, most developed methods rely on the assumption that the training and test data have similar distributions. In the presence of distribution shifts, fair models may behave unfairly on test data. There have been some developments for fair learning robust to distribution shifts to address this shortcoming. However, most proposed solutions are based on the assumption of having access to the causal graph describing the interaction of different features. Moreover, existing algorithms require full access to data and cannot be used when small batches are used (stochastic/batch implementation). This paper proposes the first stochastic distributionally robust fairness framework with convergence guarantees that do not require knowledge of the causal graph. More specifically, we formulate the fair inference in the presence of the distribution shift as a distributionally robust optimization problem under $L_p$ n
    
[^60]: 具有神经图模型的联邦学习

    Federated Learning with Neural Graphical Models. (arXiv:2309.11680v1 [cs.LG])

    [http://arxiv.org/abs/2309.11680](http://arxiv.org/abs/2309.11680)

    本研究提出了一种名为FedNGMs的联邦学习框架，利用概率神经图模型来处理多个客户端的数据，并在保持训练数据私密性的同时提升模型准确性。

    

    联邦学习（FL）解决了在多个客户端保留对数据的独占控制的同时，基于专有数据创建模型的需求。近期提出的神经图模型（NGMs）是概率图模型，利用神经网络的表达能力学习输入特征之间的复杂非线性依赖关系。它们学会捕捉底层的数据分布，并具有高效的推理和采样算法。我们开发了一个FL框架，它维护一个全局的NGM模型，从本地NGM模型中学习到平均信息，同时保持训练数据在客户端的环境中。我们的设计FedNGMs避免了神经元匹配框架（如联邦匹配平均）中模型参数爆炸的缺点和不足。我们的全局模型大小在整个过程中保持不变。

    Federated Learning (FL) addresses the need to create models based on proprietary data in such a way that multiple clients retain exclusive control over their data, while all benefit from improved model accuracy due to pooled resources. Recently proposed Neural Graphical Models (NGMs) are Probabilistic Graphical models that utilize the expressive power of neural networks to learn complex non-linear dependencies between the input features. They learn to capture the underlying data distribution and have efficient algorithms for inference and sampling. We develop a FL framework which maintains a global NGM model that learns the averaged information from the local NGM models while keeping the training data within the client's environment. Our design, FedNGMs, avoids the pitfalls and shortcomings of neuron matching frameworks like Federated Matched Averaging that suffers from model parameter explosion. Our global model size remains constant throughout the process. In the cases where clients 
    
[^61]: 污腐游戏模拟中的生成式人工智能

    Generative AI in Mafia-like Game Simulation. (arXiv:2309.11672v1 [cs.AI])

    [http://arxiv.org/abs/2309.11672](http://arxiv.org/abs/2309.11672)

    本研究探索了在污腐式游戏模拟中使用生成式人工智能模型的效果和潜力。通过对比GPT-4和GPT-3.5-turbo，在游戏环境中GPT-4展示出更好的适应性和更人类化的反应，但其在虚张声势和预测对手行动方面仍存在挑战。这些发现表明，尽管GPT-4有进一步发展的潜力，但仍需注入更多创新性和挑战性的元素。

    

    在这项研究中，我们探索了生成式人工智能模型的功效和潜力，特别关注它们在角色扮演模拟中的应用，具体体现在著名的污腐式游戏Spyfall中。通过利用GPT-4先进的能力，本研究旨在展示该模型在游戏场景中的理解、决策和互动潜力。对比GPT-4与其前任GPT-3.5-turbo的分析表明，GPT-4在游戏环境中的适应能力得到了改善，提出了相关问题并形成人类般的回答方面有显著改进。然而，该模型在虚张声势和预测对手行动方面仍存在挑战。对游戏开发、财务限制和研究的非言语限制进行了反思和讨论。研究发现表明，尽管GPT-4相对早期模型有着令人期待的进展，但仍有进一步发展的潜力，特别是在注入更多创新性和挑战性的元素方面。

    In this research, we explore the efficacy and potential of Generative AI models, specifically focusing on their application in role-playing simulations exemplified through Spyfall, a renowned mafia-style game. By leveraging GPT-4's advanced capabilities, the study aimed to showcase the model's potential in understanding, decision-making, and interaction during game scenarios. Comparative analyses between GPT-4 and its predecessor, GPT-3.5-turbo, demonstrated GPT-4's enhanced adaptability to the game environment, with significant improvements in posing relevant questions and forming human-like responses. However, challenges such as the model;s limitations in bluffing and predicting opponent moves emerged. Reflections on game development, financial constraints, and non-verbal limitations of the study were also discussed. The findings suggest that while GPT-4 exhibits promising advancements over earlier models, there remains potential for further development, especially in instilling more
    
[^62]: "公平游戏"，还是吗？研究用户在使用基于LLM的对话型智能助手时如何处理披露风险和效益

    "It's a Fair Game'', or Is It? Examining How Users Navigate Disclosure Risks and Benefits When Using LLM-Based Conversational Agents. (arXiv:2309.11653v1 [cs.HC])

    [http://arxiv.org/abs/2309.11653](http://arxiv.org/abs/2309.11653)

    本研究通过分析用户在实际对话中的敏感披露和采访LLM型对话型智能助手用户的方式，发现用户在使用LLM型对话型智能助手时面临隐私、效用和便利之间的权衡，但用户对隐私风险的认知存在问题，而人类化的互动鼓励了更多敏感的披露，加重了用户的权衡困难。

    

    基于大型语言模型（LLM）的对话型智能助手在高风险领域的广泛使用引发了许多隐私问题。构建尊重用户隐私的道德LLM型对话型智能助手需要深入了解最关注用户的隐私风险。然而，现有的研究主要以模型为中心，无法提供用户的观点。为了弥补这一差距，我们分析了实际的ChatGPT对话中的敏感披露，并对19名LLM型对话型智能助手用户进行了半结构化采访。我们发现，在使用LLM型对话型智能助手时，用户不断面临隐私、效用和便利之间的权衡。然而，用户错误的心智模式和系统设计中的黑暗模式限制了他们对隐私风险的认识和理解。此外，人类化的互动鼓励了更多敏感的披露，这使得用户在权衡中更加困难。我们讨论了实际的设计指南。

    The widespread use of Large Language Model (LLM)-based conversational agents (CAs), especially in high-stakes domains, raises many privacy concerns. Building ethical LLM-based CAs that respect user privacy requires an in-depth understanding of the privacy risks that concern users the most. However, existing research, primarily model-centered, does not provide insight into users' perspectives. To bridge this gap, we analyzed sensitive disclosures in real-world ChatGPT conversations and conducted semi-structured interviews with 19 LLM-based CA users. We found that users are constantly faced with trade-offs between privacy, utility, and convenience when using LLM-based CAs. However, users' erroneous mental models and the dark patterns in system design limited their awareness and comprehension of the privacy risks. Additionally, the human-like interactions encouraged more sensitive disclosures, which complicated users' ability to navigate the trade-offs. We discuss practical design guideli
    
[^63]: 基于轨道人工智能的自主加油解决方案

    Orbital AI-based Autonomous Refuelling Solution. (arXiv:2309.11648v1 [cs.CV])

    [http://arxiv.org/abs/2309.11648](http://arxiv.org/abs/2309.11648)

    本文介绍了一种基于人工智能的导航算法，旨在通过使用轨道上的可见波长摄像头作为主要传感器，减少对激光雷达的依赖，并大大降低成本。

    

    由于其小型尺寸和低成本的功率、质量和体积，摄像头正迅速成为太空交会的选择机载传感器。然而，在对接方面，它们通常起到次要作用，而主要工作由激光雷达等主动传感器完成。本文介绍了一种提出的基于人工智能的导航算法的开发，旨在使船载可见波长摄像头作为对接和轨道服务的主要传感器成熟起来，减少对激光雷达的依赖并大大降低成本。具体来说，利用人工智能使得相对导航解决方案能够扩展到多种情况，例如目标或照明条件，在传统图像处理方法中，这些情况都必须进行个案处理。在合成生成的数据上对多个卷积神经网络(CNN)骨干架构进行了基准测试。

    Cameras are rapidly becoming the choice for on-board sensors towards space rendezvous due to their small form factor and inexpensive power, mass, and volume costs. When it comes to docking, however, they typically serve a secondary role, whereas the main work is done by active sensors such as lidar. This paper documents the development of a proposed AI-based (artificial intelligence) navigation algorithm intending to mature the use of on-board visible wavelength cameras as a main sensor for docking and on-orbit servicing (OOS), reducing the dependency on lidar and greatly reducing costs. Specifically, the use of AI enables the expansion of the relative navigation solution towards multiple classes of scenarios, e.g., in terms of targets or illumination conditions, which would otherwise have to be crafted on a case-by-case manner using classical image processing methods. Multiple convolutional neural network (CNN) backbone architectures are benchmarked on synthetically generated data of 
    
[^64]: Attentive VQ-VAE：一种增强VQ-VAE模型能力的新方法

    Attentive VQ-VAE. (arXiv:2309.11641v1 [cs.CV])

    [http://arxiv.org/abs/2309.11641](http://arxiv.org/abs/2309.11641)

    本研究提出了一种增强VQ-VAE模型能力的新方法，通过整合Attentive Residual Encoder和Residual Pixel Attention层，利用像素间的自我注意机制来高效地捕捉和利用潜在向量之间的上下文信息，并使用额外的编码级别来进一步增强模型的表示能力，在实验中取得了显著的性能改进。

    

    本文通过整合Attentive Residual Encoder（AREN）和Residual Pixel Attention层，提出了一种增强VQ-VAE模型能力的新方法。我们的研究目标是在保持实用的参数水平的同时改进VQ-VAE的性能。AREN编码器被设计成能够有效地在多个级别上操作，适应不同的架构复杂性。关键创新在于将像素间的自我注意机制整合到AREN编码器中。这种方法使我们能够高效地捕捉和利用潜在向量之间的上下文信息。此外，我们的模型使用了额外的编码级别来进一步增强模型的表示能力。我们的注意力层采用最小参数方法，确保只有在其他像素的相关信息可用时才修改潜在向量。实验结果表明，我们提出的修改显著提高了数据的处理效果。

    We present a novel approach to enhance the capabilities of VQVAE models through the integration of an Attentive Residual Encoder (AREN) and a Residual Pixel Attention layer. The objective of our research is to improve the performance of VQVAE while maintaining practical parameter levels. The AREN encoder is designed to operate effectively at multiple levels, accommodating diverse architectural complexities. The key innovation is the integration of an inter-pixel auto-attention mechanism into the AREN encoder. This approach allows us to efficiently capture and utilize contextual information across latent vectors. Additionally, our models uses additional encoding levels to further enhance the model's representational power. Our attention layer employs a minimal parameter approach, ensuring that latent vectors are modified only when pertinent information from other pixels is available. Experimental results demonstrate that our proposed modifications lead to significant improvements in dat
    
[^65]: 基于云的层次化模仿学习，实现从人类工人到辅助机器人的施工技能的可扩展转移

    Cloud-Based Hierarchical Imitation Learning for Scalable Transfer of Construction Skills from Human Workers to Assisting Robots. (arXiv:2309.11619v1 [cs.RO])

    [http://arxiv.org/abs/2309.11619](http://arxiv.org/abs/2309.11619)

    这项研究提出了一种基于云的层次化模仿学习的方法，用于将人类工人的施工技能转移到辅助机器人，并提出了一个沉浸式虚拟演示框架，用于提高施工效率。

    

    将重复和体力要求高的施工任务分配给机器人可以减轻人类工人的职业伤害。将工人的巧妙和适应性的手工艺施工技能转移到机器人对于成功委托施工任务和实现高质量机器人施工工作至关重要。预定义的运动规划脚本往往会在非结构化的施工现场环境中生成僵硬且易碰撞的机器人行为。相比之下，模仿学习（IL）提供了一种更健壮和灵活的技能转移方案。然而，大多数IL算法依赖于人类工人反复展示完整的任务性能，这对于建筑工作来说可能是适得其反且不可行的。为了解决这个问题，本文提出了一种沉浸式的基于云机器人的虚拟演示框架，具备两个主要目的。第一，它数字化了演示过程，消除了时间和地点的限制，并提供了灵活的时间表以提高工人效率。

    Assigning repetitive and physically-demanding construction tasks to robots can alleviate human workers's exposure to occupational injuries. Transferring necessary dexterous and adaptive artisanal construction craft skills from workers to robots is crucial for the successful delegation of construction tasks and achieving high-quality robot-constructed work. Predefined motion planning scripts tend to generate rigid and collision-prone robotic behaviors in unstructured construction site environments. In contrast, Imitation Learning (IL) offers a more robust and flexible skill transfer scheme. However, the majority of IL algorithms rely on human workers to repeatedly demonstrate task performance at full scale, which can be counterproductive and infeasible in the case of construction work. To address this concern, this paper proposes an immersive, cloud robotics-based virtual demonstration framework that serves two primary purposes. First, it digitalizes the demonstration process, eliminati
    
[^66]: 使用迁移学习和深度集成学习的两阶段方法进行手势识别

    Hand Gesture Recognition with Two Stage Approach Using Transfer Learning and Deep Ensemble Learning. (arXiv:2309.11610v1 [cs.CV])

    [http://arxiv.org/abs/2309.11610](http://arxiv.org/abs/2309.11610)

    本研究使用迁移学习和深度集成学习的两阶段方法对手势进行识别，通过评估不同模型在HG14数据集上的准确率，发现VGGNet和MobileNet模型的版本表现最好。

    

    人机交互 (HCI) 是多年来的研究主题，最近的研究聚焦于通过各种技术提高其性能。在过去的十年中，深度学习研究在各个领域表现出高性能，引发了研究人员对其在HCI中的应用进行探索。卷积神经网络可以使用深度结构从图像中识别手势。在本研究中，我们评估了预训练的高性能深度结构在HG14数据集上的表现，该数据集包含14个不同的手势类别。在22个不同的模型中，VGGNet和MobileNet模型的版本达到了最高的准确率。具体而言，VGG16和VGG19模型的准确率分别为94.64%和94.36%，而MobileNet和MobileNetV2模型的准确率分别为96.79%和94.43%。我们使用集成学习技术在数据集上进行手势识别。

    Human-Computer Interaction (HCI) has been the subject of research for many years, and recent studies have focused on improving its performance through various techniques. In the past decade, deep learning studies have shown high performance in various research areas, leading researchers to explore their application to HCI. Convolutional neural networks can be used to recognize hand gestures from images using deep architectures. In this study, we evaluated pre-trained high-performance deep architectures on the HG14 dataset, which consists of 14 different hand gesture classes. Among 22 different models, versions of the VGGNet and MobileNet models attained the highest accuracy rates. Specifically, the VGG16 and VGG19 models achieved accuracy rates of 94.64% and 94.36%, respectively, while the MobileNet and MobileNetV2 models achieved accuracy rates of 96.79% and 94.43%, respectively. We performed hand gesture recognition on the dataset using an ensemble learning technique, which combined 
    
[^67]: 数据集工厂：一个生成计算机视觉数据集的工具链

    Dataset Factory: A Toolchain For Generative Computer Vision Datasets. (arXiv:2309.11608v1 [cs.AI])

    [http://arxiv.org/abs/2309.11608](http://arxiv.org/abs/2309.11608)

    提出了一个"数据集工厂"的方法，将计算机视觉数据集的存储和处理与元数据分开，并为机器学习团队和个人研究人员提供了规模化的数据中心操作。

    

    生成式人工智能工作流程在很大程度上依赖于以数据为中心的任务，如通过注释字段、向量距离或自定义分类器产生的分数来过滤样本。同时，计算机视觉数据集的容量迅速接近PB级，使得数据整理变得困难。此外，数据准备的迭代特性需要实现强大的数据集共享和版本控制机制，这两者都难以自适应实现。为了解决这些挑战，我们提出了一种"数据集工厂"的方法，将样本的存储和处理与元数据分开，并为机器学习团队和个人研究人员提供了规模化的数据中心操作。

    Generative AI workflows heavily rely on data-centric tasks - such as filtering samples by annotation fields, vector distances, or scores produced by custom classifiers. At the same time, computer vision datasets are quickly approaching petabyte volumes, rendering data wrangling difficult. In addition, the iterative nature of data preparation necessitates robust dataset sharing and versioning mechanisms, both of which are hard to implement ad-hoc. To solve these challenges, we propose a "dataset factory" approach that separates the storage and processing of samples from metadata and enables data-centric operations at scale for machine learning teams and individual researchers.
    
[^68]: CATS: 基于深度学习方法的条件对抗轨迹合成，用于隐私保护轨迹数据发布

    CATS: Conditional Adversarial Trajectory Synthesis for Privacy-Preserving Trajectory Data Publication Using Deep Learning Approaches. (arXiv:2309.11587v1 [cs.LG])

    [http://arxiv.org/abs/2309.11587](http://arxiv.org/abs/2309.11587)

    CATS是一种基于深度学习的地理人工智能方法，用于隐私保护轨迹数据的生成和发布。它采用K-匿名技术保障了分布级隐私，通过条件对抗训练和循环二部图匹配等方法实现了高质量轨迹数据的合成和重构。

    

    随着无处不在的定位感知设备和移动互联网的普及，我们能够从用户那里收集大规模的个体级轨迹数据集。这些轨迹大数据为人类移动性研究带来了新的机遇，但也引发了关于位置隐私的公众关切。在这项工作中，我们提出了一种基于深度学习的地理人工智能方法论框架，名为 Conditional Adversarial Trajectory Synthesis (CATS)，用于隐私保护轨迹数据的生成和发布。CATS 将 K-匿名应用于人类移动性的时空分布，提供了强大的分布级隐私保障。通过利用条件对抗训练技术、基于注意力机制的轨迹全局上下文学习，以及相邻轨迹点的循环二部图匹配，CATS 能够从条件采样位置中重构轨迹拓扑，并生成高质量的个体轨迹数据。

    The prevalence of ubiquitous location-aware devices and mobile Internet enables us to collect massive individual-level trajectory dataset from users. Such trajectory big data bring new opportunities to human mobility research but also raise public concerns with regard to location privacy. In this work, we present the Conditional Adversarial Trajectory Synthesis (CATS), a deep-learning-based GeoAI methodological framework for privacy-preserving trajectory data generation and publication. CATS applies K-anonymity to the underlying spatiotemporal distributions of human movements, which provides a distributional-level strong privacy guarantee. By leveraging conditional adversarial training on K-anonymized human mobility matrices, trajectory global context learning using the attention-based mechanism, and recurrent bipartite graph matching of adjacent trajectory points, CATS is able to reconstruct trajectory topology from conditionally sampled locations and generate high-quality individual-
    
[^69]: 从安全基准中提炼对抗性提示：对对抗性Nibbler挑战报告

    Distilling Adversarial Prompts from Safety Benchmarks: Report for the Adversarial Nibbler Challenge. (arXiv:2309.11575v1 [cs.CV])

    [http://arxiv.org/abs/2309.11575](http://arxiv.org/abs/2309.11575)

    本研究为Adversarial Nibbler挑战提供了一个大型的潜在对抗输入集合，并通过对提示和图像的分析揭示了当前生成图像模型中的系统性安全问题。

    

    最近，基于文本的图像生成模型取得了惊人的图像质量和对齐结果。因此，它们被应用于越来越多的应用程序中。由于这些模型高度依赖于从网络随机爬取的数十亿个数据集，它们也会产生不安全的内容。作为对Adversarial Nibbler挑战的贡献，我们从现有的安全基准中提炼了一组超过1000个潜在的对抗输入。我们对收集到的提示和相应的图像进行分析，展示了输入过滤器的脆弱性，并进一步揭示了当前生成图像模型中的系统性安全问题。

    Text-conditioned image generation models have recently achieved astonishing image quality and alignment results. Consequently, they are employed in a fast-growing number of applications. Since they are highly data-driven, relying on billion-sized datasets randomly scraped from the web, they also produce unsafe content. As a contribution to the Adversarial Nibbler challenge, we distill a large set of over 1,000 potential adversarial inputs from existing safety benchmarks. Our analysis of the gathered prompts and corresponding images demonstrates the fragility of input filters and provides further insights into systematic safety issues in current generative image models.
    
[^70]: BTLM-3B-8K: 一个3B参数模型中使用7B参数性能的研究

    BTLM-3B-8K: 7B Parameter Performance in a 3B Parameter Model. (arXiv:2309.11568v1 [cs.AI])

    [http://arxiv.org/abs/2309.11568](http://arxiv.org/abs/2309.11568)

    BTLM-3B-8K是一个30亿参数的开源语言模型，相对于其他30亿和70亿参数模型，它在下游任务中表现出2-5.5%的性能提升，同时在长文本任务上也具有出色的表现。这种将70亿参数的模型压缩到30亿参数，并且性能几乎没有受到影响的方法具有重要意义。

    

    我们介绍了Bittensor语言模型, 名为"BTLM-3B-8K", 这是一个新的、拥有30亿参数的开源语言模型. BTLM-3B-8K在SlimPajama数据集上进行了训练，训练数据为627B个token，采用了2048和8192的混合上下文长度. BTLM-3B-8K在下游任务中的表现比所有现有的30亿参数模型提高了2-5.5% ，甚至与一些70亿参数模型相媲美. 另外，BTLM-3B-8K在长文本上的表现也很好，在长度为8192的任务上超过了MPT-7B-8K和XGen-7B-8K. 我们在清理和去重的SlimPajama数据集上训练了模型，对µP超参数和调度进行了调优，使用了ALiBi位置嵌入和SwiGLU非线性. 在Hugging Face上，最受欢迎的模型是70亿参数，这表明用户更倾向于质量大小比为70亿参数的模型. 将70亿参数模型压缩为30亿参数，性能几乎没有影响，这是一个重要的里程碑.

    We introduce the Bittensor Language Model, called "BTLM-3B-8K", a new state-of-the-art 3 billion parameter open-source language model. BTLM-3B-8K was trained on 627B tokens from the SlimPajama dataset with a mixture of 2,048 and 8,192 context lengths. BTLM-3B-8K outperforms all existing 3B parameter models by 2-5.5% across downstream tasks. BTLM-3B-8K is even competitive with some 7B parameter models. Additionally, BTLM-3B-8K provides excellent long context performance, outperforming MPT-7B-8K and XGen-7B-8K on tasks up to 8,192 context length. We trained the model on a cleaned and deduplicated SlimPajama dataset; aggressively tuned the \textmu P hyperparameters and schedule; used ALiBi position embeddings; and adopted the SwiGLU nonlinearity.  On Hugging Face, the most popular models have 7B parameters, indicating that users prefer the quality-size ratio of 7B models. Compacting the 7B parameter model to one with 3B parameters, with little performance impact, is an important milestone
    
[^71]: 学习关系之间的完整拓扑感知相关性以进行归纳链接预测

    Learning Complete Topology-Aware Correlations Between Relations for Inductive Link Prediction. (arXiv:2309.11528v1 [cs.AI])

    [http://arxiv.org/abs/2309.11528](http://arxiv.org/abs/2309.11528)

    本文提出了一种基于子图的方法TACO，用于建模高度与拓扑结构相关的关系之间的拓扑感知相关性，并展示了这种方法对于实体无关的归纳链接预测任务的潜力。

    

    归纳链接预测——在训练和推理阶段实体可能不同——已经显示出了以实体无关的方式完成演化知识图谱的巨大潜力。许多流行的方法主要关注建模图级特征，而边级交互——尤其是关系之间的语义相关性——则被较少探索。然而，我们注意到语义相关性之间的一个理想特性是它们在本质上是边级和实体无关的。这意味着语义相关性对于实体无关的归纳链接预测任务具有巨大的潜力。受到这一观察的启发，我们提出了一种新颖的基于子图的方法，即TACO，来建模与其子图内的拓扑结构高度相关的关系之间的拓扑感知相关性。

    Inductive link prediction -- where entities during training and inference stages can be different -- has shown great potential for completing evolving knowledge graphs in an entity-independent manner. Many popular methods mainly focus on modeling graph-level features, while the edge-level interactions -especially the semantic correlations between relations -- have been less explored. However, we notice a desirable property of semantic correlations between relations is that they are inherently edge-level and entity-independent. This implies the great potential of the semantic correlations for the entity-independent inductive link prediction task. Inspired by this observation, we propose a novel subgraph-based method, namely TACO, to model Topology-Aware COrrelations between relations that are highly correlated to their topological structures within subgraphs. Specifically, we prove that semantic correlations between any two relations can be categorized into seven topological patterns,
    
[^72]: TrueLearn: 一种用于个性化信息推荐的Python库（带有（隐式）反馈）

    TrueLearn: A Python Library for Personalised Informational Recommendations with (Implicit) Feedback. (arXiv:2309.11527v1 [cs.IR])

    [http://arxiv.org/abs/2309.11527](http://arxiv.org/abs/2309.11527)

    TrueLearn是一个Python库，用于构建个性化的信息推荐系统，并提供了丰富的文档和编码示例，可帮助开发人员和从业者使用。它采用了开放学习者的概念和人性化的用户表达方式，同时支持用户可视化和模型性能评估。

    

    本文介绍了TrueLearn Python库，其中包含一组在线学习贝叶斯模型，用于构建教育（或更一般地说，信息）推荐系统。这组模型是根据“开放学习者”的概念设计的，使用直观的用户表达。为了可解释性和让用户有控制感，TrueLearn库还包含不同的表示形式，以帮助最终用户可视化学习者模型，这可能有助于将来用户与自己的模型进行交互。与该库一起，我们还提供了一个先前公开发布的隐式反馈教育数据集和评估指标，以衡量模型的性能。丰富的文档和编码示例使该库对机器学习开发人员和教育数据挖掘和学习分析从业者都非常易于使用。该库和带有示例的支持文档可在https：//获得。

    This work describes the TrueLearn Python library, which contains a family of online learning Bayesian models for building educational (or more generally, informational) recommendation systems. This family of models was designed following the "open learner" concept, using humanly-intuitive user representations. For the sake of interpretability and putting the user in control, the TrueLearn library also contains different representations to help end-users visualise the learner models, which may in the future facilitate user interaction with their own models. Together with the library, we include a previously publicly released implicit feedback educational dataset with evaluation metrics to measure the performance of the models. The extensive documentation and coding examples make the library highly accessible to both machine learning developers and educational data mining and learning analytic practitioners. The library and the support documentation with examples are available at https:/
    
[^73]: 何时算是基础模型？（arXiv:2309.11510v1 [cs.IR]）

    When is a Foundation Model a Foundation Model. (arXiv:2309.11510v1 [cs.IR])

    [http://arxiv.org/abs/2309.11510](http://arxiv.org/abs/2309.11510)

    这项研究发现，通过对基础模型进行微调，使用在线数据源的图片进行图像-文本建模在医学领域具有潜力。然而，这些基础模型在数字病理学的检索任务中表现不如传统的深度网络。

    

    最近，有几项研究报道了在医学领域利用来自Twitter和PubMed等在线数据源的图片进行基金会模型的微调，用于图像-文本建模。基金会模型是大型、深度的人工神经网络，能够通过在异常广泛的数据集上进行训练来学习特定领域的上下文。通过验证，我们发现这些模型生成的表示在数字病理学的检索任务中的性能较差，与较小的传统深度网络相比。

    Recently, several studies have reported on the fine-tuning of foundation models for image-text modeling in the field of medicine, utilizing images from online data sources such as Twitter and PubMed. Foundation models are large, deep artificial neural networks capable of learning the context of a specific domain through training on exceptionally extensive datasets. Through validation, we have observed that the representations generated by such models exhibit inferior performance in retrieval tasks within digital pathology when compared to those generated by significantly smaller, conventional deep networks.
    
[^74]: 基于LLM的短文本答案自动评分方法研究

    Towards LLM-based Autograding for Short Textual Answers. (arXiv:2309.11508v1 [cs.CL])

    [http://arxiv.org/abs/2309.11508](http://arxiv.org/abs/2309.11508)

    本文评估了大型语言模型（LLMs）在自动评分中的应用，并强调了它们如何支持教育工作者验证评分程序。研究结果表明，“开箱即用”的LLMs作为补充视角提供了有价值的工具，但仍需进一步优化其可用性和性能。

    

    考试的评分是一项重要的、劳动密集的、主观的、重复的且常常具有挑战性的任务。大型语言模型（LLMs）如ChatGPT的可用性和数字化带来的大量数据的涌入， greatly increased autograding textual responses的可行性。然而，将决策角色交给AI模型引起了伦理考虑，主要源于潜在偏见和生成虚假信息的问题。因此，在本文中，我们评估了一个大型语言模型用于自动评分，同时强调了LLMs如何支持教育工作者验证其评分程序。我们的评估针对自动短文本答案评分（ASAG），涵盖了两个不同课程的各种语言和考试。我们的研究结果表明，“开箱即用”的LLMs提供了一个有价值的工具，可以提供补充的视角，但它们的可用性和性能在实际应用中还需进一步优化。

    Grading of exams is an important, labor intensive, subjective, repetitive and frequently challenging task. The feasibility of autograding textual responses has greatly increased thanks to the availability of large language models (LLMs) such as ChatGPT and because of the substantial influx of data brought about by digitalization. However, entrusting AI models with decision-making roles raises ethical considerations, mainly stemming from potential biases and issues related to generating false information. Thus, in this manuscript we provide an evaluation of a large language model for the purpose of autograding, while also highlighting how LLMs can support educators in validating their grading procedures. Our evaluation is targeted towards automatic short textual answers grading (ASAG), spanning various languages and examinations from two distinct courses. Our findings suggest that while "out-of-the-box" LLMs provide a valuable tool to provide a complementary perspective, their readiness
    
[^75]: 使用大型语言模型将表元数据与业务词汇匹配

    Matching Table Metadata with Business Glossaries Using Large Language Models. (arXiv:2309.11506v1 [cs.IR])

    [http://arxiv.org/abs/2309.11506](http://arxiv.org/abs/2309.11506)

    本研究探讨了将表元数据与业务词汇进行匹配的问题，通过匹配可以在不请求访问数据内容之前或之后，有效利用可用的业务词汇进行检索和分析。

    

    企业通常拥有大量的结构化数据，以大型数据库或企业数据湖的形式存在。这些数据集往往具有有限的元数据和严格的访问策略，这可能限制对数据内容的访问，并因此限制了经典的检索和分析解决方案的应用。因此，需要能够有效利用可用元数据的解决方案。本文研究了将表元数据与包含数据标签和描述的业务词汇匹配的问题。通过匹配，可以在不请求访问数据内容之前或之后，利用可用或策划的业务词汇进行检索和分析。解决这个问题的一种方法是使用手动定义的规则或相似度度量在列名和词汇描述（或它们的向量嵌入）之间找到最匹配的项。然而，这种方法需要通过手动标注进行调整，并且不能处理许多业务词汇。

    Enterprises often own large collections of structured data in the form of large databases or an enterprise data lake. Such data collections come with limited metadata and strict access policies that could limit access to the data contents and, therefore, limit the application of classic retrieval and analysis solutions. As a result, there is a need for solutions that can effectively utilize the available metadata. In this paper, we study the problem of matching table metadata to a business glossary containing data labels and descriptions. The resulting matching enables the use of an available or curated business glossary for retrieval and analysis without or before requesting access to the data contents. One solution to this problem is to use manually-defined rules or similarity measures on column names and glossary descriptions (or their vector embeddings) to find the closest match. However, such approaches need to be tuned through manual labeling and cannot handle many business gloss
    
[^76]: Text2Reward：针对强化学习的自动生成密集奖励函数的自动化框架

    Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning. (arXiv:2309.11489v1 [cs.LG])

    [http://arxiv.org/abs/2309.11489](http://arxiv.org/abs/2309.11489)

    Text2Reward是一个无需数据的自动化框架，可以根据大型语言模型自动生成可解释、自由形式的密集奖励函数，广泛适用于各种任务，并允许人类反馈进行迭代改进。

    

    设计奖励函数是强化学习中长期以来的挑战；它需要专业知识或领域数据，导致开发成本高。为了解决这个问题，我们引入了Text2Reward，一个无需数据的框架，可基于大型语言模型（LLM）自动生成密集奖励函数。给定自然语言描述的目标，Text2Reward生成作为环境紧凑表示的可执行程序的密集奖励函数。与逆强化学习和最近使用LLM编写稀疏奖励代码的工作不同，Text2Reward生成可解释的、自由形式的密集奖励代码，可涵盖各种任务，利用现有软件包，并允许通过人类反馈进行迭代改进。我们在两个机器人操作基准（ManiSkill2，MetaWorld）和两个MuJoCo的运动环境上评估了Text2Reward。在17个操作任务中的13个任务中，使用生成的奖励代码训练的政策实现了类似或更好的性能。

    Designing reward functions is a longstanding challenge in reinforcement learning (RL); it requires specialized knowledge or domain data, leading to high costs for development. To address this, we introduce Text2Reward, a data-free framework that automates the generation of dense reward functions based on large language models (LLMs). Given a goal described in natural language, Text2Reward generates dense reward functions as an executable program grounded in a compact representation of the environment. Unlike inverse RL and recent work that uses LLMs to write sparse reward codes, Text2Reward produces interpretable, free-form dense reward codes that cover a wide range of tasks, utilize existing packages, and allow iterative refinement with human feedback. We evaluate Text2Reward on two robotic manipulation benchmarks (ManiSkill2, MetaWorld) and two locomotion environments of MuJoCo. On 13 of the 17 manipulation tasks, policies trained with generated reward codes achieve similar or better
    
[^77]: 你仅关注屏幕：多模态动作链机器人

    You Only Look at Screens: Multimodal Chain-of-Action Agents. (arXiv:2309.11436v1 [cs.CL])

    [http://arxiv.org/abs/2309.11436](http://arxiv.org/abs/2309.11436)

    本论文提出了一种名为Auto-UI的多模态动作链机器人，通过直接与界面交互，避免了环境解析或依赖于应用程序API的需要，并引入了动作链技术来帮助模型进行决策。

    

    自主用户界面（UI）机器人旨在通过与用户界面进行交互，实现任务自动化，无需手动干预。最近的研究探讨了利用大型语言模型（LLM）的能力，以在多样环境中有效参与。为了符合LLM的输入-输出要求，现有方法在沙盒环境中开发，依赖于外部工具和应用程序特定的API将环境解析为文本元素，并解释预测的动作。因此，这些方法常常受到推理效率低和错误传播风险的困扰。为了缓解这些挑战，我们引入了Auto-UI，一种多模态解决方案，它直接与界面交互，避免了对环境解析或依赖于应用程序相关的API的需求。此外，我们提出了一种动作链技术，利用一系列中间先前动作历史和未来动作计划，以帮助模型进行决策。

    Autonomous user interface (UI) agents aim to facilitate task automation by interacting with the user interface without manual intervention. Recent studies have investigated eliciting the capabilities of large language models (LLMs) for effective engagement in diverse environments. To align with the input-output requirement of LLMs, existing approaches are developed under a sandbox setting where they rely on external tools and application-specific APIs to parse the environment into textual elements and interpret the predicted actions. Consequently, those approaches often grapple with inference inefficiency and error propagation risks. To mitigate the challenges, we introduce Auto-UI, a multimodal solution that directly interacts with the interface, bypassing the need for environment parsing or reliance on application-dependent APIs. Moreover, we propose a chain-of-action technique -leveraging a series of intermediate previous action histories and future action plans -- to help the age
    
[^78]: Gold-YOLO: 通过收集和分发机制实现高效目标检测器

    Gold-YOLO: Efficient Object Detector via Gather-and-Distribute Mechanism. (arXiv:2309.11331v1 [cs.CV])

    [http://arxiv.org/abs/2309.11331](http://arxiv.org/abs/2309.11331)

    本研究提出了Gold-YOLO模型，通过先进的收集和分发机制（GD）机制以及MAE风格的预训练，解决了YOLO系列模型中的信息融合问题，实现了高效的目标检测和多尺度特征融合。

    

    过去几年中，YOLO系列模型已成为实时目标检测领域的领先方法。许多研究通过修改架构、增加数据和设计新的损失函数将基线提升到了更高水平。然而，我们发现之前的模型仍然存在信息融合问题，虽然特征金字塔网络（FPN）和路径聚合网络（PANet）已经缓解了这个问题。因此，本研究提出了一种先进的收集和分发机制（GD）机制，通过卷积和自注意力操作实现。这个新设计的模型名为Gold-YOLO，提升了多尺度特征融合能力，并在所有模型尺度上实现了延迟和准确性的理想平衡。此外，我们首次在YOLO系列中实现了MAE风格的预训练，使得YOLO系列模型可以从无监督预训练中受益。Gold-YOLO-N在COCO val2017数据集上达到了出色的39.9%平均精度（AP）。

    In the past years, YOLO-series models have emerged as the leading approaches in the area of real-time object detection. Many studies pushed up the baseline to a higher level by modifying the architecture, augmenting data and designing new losses. However, we find previous models still suffer from information fusion problem, although Feature Pyramid Network (FPN) and Path Aggregation Network (PANet) have alleviated this. Therefore, this study provides an advanced Gatherand-Distribute mechanism (GD) mechanism, which is realized with convolution and self-attention operations. This new designed model named as Gold-YOLO, which boosts the multi-scale feature fusion capabilities and achieves an ideal balance between latency and accuracy across all model scales. Additionally, we implement MAE-style pretraining in the YOLO-series for the first time, allowing YOLOseries models could be to benefit from unsupervised pretraining. Gold-YOLO-N attains an outstanding 39.9% AP on the COCO val2017 datas
    
[^79]: 提取-改写-回答：一种用于知识图谱问答的增强型LLMs框架

    Retrieve-Rewrite-Answer: A KG-to-Text Enhanced LLMs Framework for Knowledge Graph Question Answering. (arXiv:2309.11206v1 [cs.CL])

    [http://arxiv.org/abs/2309.11206](http://arxiv.org/abs/2309.11206)

    提出了一种提高知识图谱问答任务性能的增强型LLMs框架，通过转化KG知识为文本化陈述的方式，实现了对答案敏感的KG-to-Text方法。

    

    尽管大型语言模型（LLMs）在知识密集型任务上表现出色，但仍然存在在记忆所有世界知识，尤其是长尾知识方面的局限性。本文研究了基于知识图谱增强语言模型的方法，用于解决需要丰富世界知识的知识图谱问答（KGQA）任务。现有的工作表明，检索知识图谱（KG）以增强LLMs提示可以显著改善KGQA中LLMs的性能。然而，他们的方法缺乏基于文本的合理表述KG知识，即忽略了KG表示和文本表示之间的差距。为此，我们提出了一种对答案敏感的KG-to-Text方法，可以将KG知识转化为最具信息量的文本化陈述，用于KGQA。基于该方法，我们提出了一种用于解决KGQA任务的增强型KG-to-Text LLMS框架。在几个KGQA基准上的实验表明，所提出的KG-to-Text增强LLMs方法在性能上表现优异。

    Despite their competitive performance on knowledge-intensive tasks, large language models (LLMs) still have limitations in memorizing all world knowledge especially long tail knowledge. In this paper, we study the KG-augmented language model approach for solving the knowledge graph question answering (KGQA) task that requires rich world knowledge. Existing work has shown that retrieving KG knowledge to enhance LLMs prompting can significantly improve LLMs performance in KGQA. However, their approaches lack a well-formed verbalization of KG knowledge, i.e., they ignore the gap between KG representations and textual representations. To this end, we propose an answer-sensitive KG-to-Text approach that can transform KG knowledge into well-textualized statements most informative for KGQA. Based on this approach, we propose a KG-to-Text enhanced LLMs framework for solving the KGQA task. Experiments on several KGQA benchmarks show that the proposed KG-to-Text augmented LLMs approach outperfor
    
[^80]: 对开放世界深度伪造归因的对比伪学习

    Contrastive Pseudo Learning for Open-World DeepFake Attribution. (arXiv:2309.11132v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2309.11132](http://arxiv.org/abs/2309.11132)

    这项研究提出了一种对开放世界深度伪造归因任务的新框架，并引入了一个评估归因性能的新基准。该框架通过引入全局-局部投票模块和设计置信度-based的软伪标签策略来提高归因准确性，并缓解相似造成的伪噪声。

    

    由于生成技术的快速发展，为伪造面部进行归因的挑战引起了广泛关注。尽管最近的许多研究已经在GAN生成的面部方面迈出了重要的一步，但与身份交换或表情转移相关的更具威胁性的攻击仍然被忽视。而在开放世界的未标记面部中隐藏的伪造痕迹仍然没有得到充分的探索。为了推动相关的前沿研究，我们引入了一个名为Open-World DeepFake Attribution (OW-DFA)的新基准，旨在评估在开放世界场景下对各种类型伪造面部的归因性能。与此同时，我们提出了一种名为对比伪学习(Contrastive Pseudo Learning, CPL)的新框架，用于OW-DFA任务，通过1)引入全局-局部投票模块来引导不同操纵区域的伪造面部特征对齐，2)设计一种基于置信度的软伪标签策略来缓解由相似造成的伪噪声。

    The challenge in sourcing attribution for forgery faces has gained widespread attention due to the rapid development of generative techniques. While many recent works have taken essential steps on GAN-generated faces, more threatening attacks related to identity swapping or expression transferring are still overlooked. And the forgery traces hidden in unknown attacks from the open-world unlabeled faces still remain under-explored. To push the related frontier research, we introduce a new benchmark called Open-World DeepFake Attribution (OW-DFA), which aims to evaluate attribution performance against various types of fake faces under open-world scenarios. Meanwhile, we propose a novel framework named Contrastive Pseudo Learning (CPL) for the OW-DFA task through 1) introducing a Global-Local Voting module to guide the feature alignment of forged faces with different manipulated regions, 2) designing a Confidence-based Soft Pseudo-label strategy to mitigate the pseudo-noise caused by simi
    
[^81]: 基于对比感知和概念处理的认知启发神经结构用于视觉抽象推理

    A Cognitively-Inspired Neural Architecture for Visual Abstract Reasoning Using Contrastive Perceptual and Conceptual Processing. (arXiv:2309.10532v1 [cs.AI])

    [http://arxiv.org/abs/2309.10532](http://arxiv.org/abs/2309.10532)

    基于人类认知启发，我们提出了一种新的神经结构，用于解决视觉抽象推理任务。该架构通过追求感知和概念处理之间的一致性，采用迭代、自对比的学习过程来模拟人类的认知过程。实验证明，该网络在RAVEN数据集上实现了比之前所有模型更高的准确性，并且使用了最弱的归纳偏置。我们还指出了原始数据集中存在的类不平衡问题，并提出了解决方案。

    

    我们引入了一种新的神经结构，用于解决视觉抽象推理任务，受人类认知的启发，具体来说是由人类抽象推理通常将感知和概念处理交替进行作为灵活、迭代和动态认知过程的一部分的观察所启发。受此原理的启发，我们的架构将视觉抽象推理建模为一种迭代的、自对比的学习过程，追求视觉刺激的感知和概念处理之间的一致性。我们解释了这个新的对比感知-概念网络（CPCNet）如何通过模拟鸦文进阶矩阵智力测试的矩阵推理问题来工作。在机器学习数据集RAVEN上进行的实验证明，CPCNet在使用最弱的归纳偏置的同时实现了比之前所有已发表模型更高的精度。我们还指出了原始RAVEN数据集中存在的大量且以前没有被注意到的类不平衡问题，并提出了一个新的解决方案。

    We introduce a new neural architecture for solving visual abstract reasoning tasks inspired by human cognition, specifically by observations that human abstract reasoning often interleaves perceptual and conceptual processing as part of a flexible, iterative, and dynamic cognitive process. Inspired by this principle, our architecture models visual abstract reasoning as an iterative, self-contrasting learning process that pursues consistency between perceptual and conceptual processing of visual stimuli. We explain how this new Contrastive Perceptual-Conceptual Network (CPCNet) works using matrix reasoning problems in the style of the well-known Raven's Progressive Matrices intelligence test. Experiments on the machine learning dataset RAVEN show that CPCNet achieves higher accuracy than all previously published models while also using the weakest inductive bias. We also point out a substantial and previously unremarked class imbalance in the original RAVEN dataset, and we propose a new
    
[^82]: 因果故事：利用参数高效调整的局部因果注意力实现视觉故事合成

    Causal-Story: Local Causal Attention Utilizing Parameter-Efficient Tuning For Visual Story Synthesis. (arXiv:2309.09553v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.09553](http://arxiv.org/abs/2309.09553)

    提出了一种称为因果故事的新模型，利用局部因果注意力机制来改进视觉故事合成的全局一致性，该模型考虑了历史标题、帧和当前标题之间的因果关系，实现了更好的生成效果。

    

    演化模型在文本到图像合成方面具有出色的能力，推动了连贯视觉故事的合成进展。目前最先进的方法将历史标题、历史帧和当前标题的特征作为生成当前帧的条件进行组合。然而，该方法将每个历史帧和标题都视为同样的贡献，并以相等的权重将它们连接起来，忽视了并非所有历史条件都与生成当前帧相关。为了解决这个问题，我们提出了因果故事。该模型引入了一种考虑先前标题、帧和当前标题之间因果关系的局部因果注意机制。通过根据这种关系分配权重，因果故事生成当前帧，从而提高了故事生成的全局一致性。我们在PororoSV和FlintstonesSV数据集上评估了我们的模型，并获得了最先进的FID分数。

    The excellent text-to-image synthesis capability of diffusion models has driven progress in synthesizing coherent visual stories. The current state-of-the-art method combines the features of historical captions, historical frames, and the current captions as conditions for generating the current frame. However, this method treats each historical frame and caption as the same contribution. It connects them in order with equal weights, ignoring that not all historical conditions are associated with the generation of the current frame. To address this issue, we propose Causal-Story. This model incorporates a local causal attention mechanism that considers the causal relationship between previous captions, frames, and current captions. By assigning weights based on this relationship, Causal-Story generates the current frame, thereby improving the global consistency of story generation. We evaluated our model on the PororoSV and FlintstonesSV datasets and obtained state-of-the-art FID score
    
[^83]: FedGKD:在联邦图神经网络中释放协作的力量

    FedGKD: Unleashing the Power of Collaboration in Federated Graph Neural Networks. (arXiv:2309.09517v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.09517](http://arxiv.org/abs/2309.09517)

    FedGKD是一种新颖的联邦图神经网络框架，通过利用客户端图数据集蒸馏方法提取更好的任务特征并引入感知全局协作结构的服务器端聚合机制，解决了联邦GNN系统中图异构性问题，提高了效率和准确性。

    

    最近几年来，由于联邦图神经网络（GNN）能够在数据隔离场景下执行与图相关的任务并保护数据隐私，联邦训练已经变得流行起来。然而，联邦GNN系统中的图异构性问题仍然存在挑战。现有的框架通过使用不同的统计量来表示局部任务，并通过简单的聚合机制将它们联系起来来解决这个问题。然而，这些方法在两个方面都效率有限：任务相关性量化的质量低和利用协作结构的无效性。为了解决这些问题，我们提出了FedGKD，一种新颖的联邦GNN框架，它利用一种新颖的客户端图数据集蒸馏方法提取更好地描述任务相关性的任务特征，并引入一个新颖的服务器端聚合机制，该机制能够感知到全局的协作结构。我们在六个真实世界的数据集上进行了大量实验证明了FedGKD框架的有效性。

    Federated training of Graph Neural Networks (GNN) has become popular in recent years due to its ability to perform graph-related tasks under data isolation scenarios while preserving data privacy. However, graph heterogeneity issues in federated GNN systems continue to pose challenges. Existing frameworks address the problem by representing local tasks using different statistics and relating them through a simple aggregation mechanism. However, these approaches suffer from limited efficiency from two aspects: low quality of task-relatedness quantification and inefficacy of exploiting the collaboration structure. To address these issues, we propose FedGKD, a novel federated GNN framework that utilizes a novel client-side graph dataset distillation method to extract task features that better describe task-relatedness, and introduces a novel server-side aggregation mechanism that is aware of the global collaboration structure. We conduct extensive experiments on six real-world datasets of
    
[^84]: 基于组合式基础模型的层次规划

    Compositional Foundation Models for Hierarchical Planning. (arXiv:2309.08587v1 [cs.LG])

    [http://arxiv.org/abs/2309.08587](http://arxiv.org/abs/2309.08587)

    本研究提出了一种基于组合式基础模型的层次规划方法，通过利用语言、视觉和动作数据的多个专家模型，解决了长期目标任务。通过符号计划、视频扩散和逆动力学模型的结合，实现了在新环境中做出有效决策的能力。

    

    在新环境中做出有效决策需要进行跨空间和时间尺度的层次推理。本文提出了一种基于组合式基础模型的层次规划方法，利用多个专家模型分别对语言、视觉和动作数据进行训练，共同解决长期目标任务。我们利用一个大型语言模型构建在环境中扎根的符号计划，并通过大型视频扩散模型来实现。生成的视频计划通过逆动力学模型与视觉-动作控制相结合。为了在此层次结构中进行有效推理，我们通过迭代改进强制保持模型的一致性。

    To make effective decisions in novel environments with long-horizon goals, it is crucial to engage in hierarchical reasoning across spatial and temporal scales. This entails planning abstract subgoal sequences, visually reasoning about the underlying plans, and executing actions in accordance with the devised plan through visual-motor control. We propose Compositional Foundation Models for Hierarchical Planning (HiP), a foundation model which leverages multiple expert foundation model trained on language, vision and action data individually jointly together to solve long-horizon tasks. We use a large language model to construct symbolic plans that are grounded in the environment through a large video diffusion model. Generated video plans are then grounded to visual-motor control, through an inverse dynamics model that infers actions from generated videos. To enable effective reasoning within this hierarchy, we enforce consistency between the models via iterative refinement. We illustr
    
[^85]: ConDA: 基于对比域适应的AI生成文本检测

    ConDA: Contrastive Domain Adaptation for AI-generated Text Detection. (arXiv:2309.03992v1 [cs.CL])

    [http://arxiv.org/abs/2309.03992](http://arxiv.org/abs/2309.03992)

    创新点：提出了一种基于对比域适应的框架 ConDA，用于检测由大型语言模型生成的新闻文本。这种方法解决了获取标记训练数据的困难，通过利用未标记的目标数据进行无监督域适应。

    

    大型语言模型（LLMs）越来越多地被用于各种用途的文本生成，包括新闻报道。鉴于这些LLMs可能被恶意使用来大规模生成虚假信息，构建有效的检测AI生成文本的工具显得尤为重要。由于新的LLMs不断被开发，获取用于监督式检测器的标记训练数据成为一个瓶颈。然而，可能存在大量未标记的文本数据，没有关于其生成器的信息。在这项工作中，我们解决了此数据问题，即检测AI生成的新闻文本，并将问题框架化为无监督域适应任务。这里的域是不同的文本生成器，即LLMs，我们假设只能访问标记的源数据和未标记的目标数据。我们开发了一个名为ConDA的对比域适应框架，将标准的域适应技术与表示能力相结合。

    Large language models (LLMs) are increasingly being used for generating text in a variety of use cases, including journalistic news articles. Given the potential malicious nature in which these LLMs can be used to generate disinformation at scale, it is important to build effective detectors for such AI-generated text. Given the surge in development of new LLMs, acquiring labeled training data for supervised detectors is a bottleneck. However, there might be plenty of unlabeled text data available, without information on which generator it came from. In this work we tackle this data problem, in detecting AI-generated news text, and frame the problem as an unsupervised domain adaptation task. Here the domains are the different text generators, i.e. LLMs, and we assume we have access to only the labeled source data and unlabeled target data. We develop a Contrastive Domain Adaptation framework, called ConDA, that blends standard domain adaptation techniques with the representation power 
    
[^86]: 贝叶斯流网络

    Bayesian Flow Networks. (arXiv:2308.07037v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2308.07037](http://arxiv.org/abs/2308.07037)

    本文介绍了贝叶斯流网络（BFNs），一种新的生成模型，它通过贝叶斯推断修改了一组独立分布的参数，并将其作为输入传递给神经网络来生成另一个相互依赖的分布。该方法不需要前向过程，适用于连续和离散数据，并具有优化数据压缩的功能。

    

    本文介绍了贝叶斯流网络（BFNs），一种新的生成模型。在BFNs中，独立分布的参数会在嘈杂的数据样本的影响下通过贝叶斯推断进行修改，然后作为输入传递给神经网络，该神经网络输出一个相互依赖的分布。从简单的先验开始，通过迭代更新这两个分布可以得到一个类似于扩散模型反向过程的生成过程；不过，这个过程在概念上更简单，无需前向过程。对于连续、离散化和离散数据，推导出了离散和连续时间的损失函数，以及样本生成过程。值得注意的是，对于离散数据，网络的输入位于概率单纯形上，因此本质上是可微分的，为基于梯度的样本引导和在语言建模等离散领域进行少量步骤生成铺平了道路。损失函数直接优化了数据压缩，并且不放置限制。

    This paper introduces Bayesian Flow Networks (BFNs), a new class of generative model in which the parameters of a set of independent distributions are modified with Bayesian inference in the light of noisy data samples, then passed as input to a neural network that outputs a second, interdependent distribution. Starting from a simple prior and iteratively updating the two distributions yields a generative procedure similar to the reverse process of diffusion models; however it is conceptually simpler in that no forward process is required. Discrete and continuous-time loss functions are derived for continuous, discretised and discrete data, along with sample generation procedures. Notably, the network inputs for discrete data lie on the probability simplex, and are therefore natively differentiable, paving the way for gradient-based sample guidance and few-step generation in discrete domains such as language modelling. The loss function directly optimises data compression and places no
    
[^87]: PubMed及其他：生物医学文献检索的最新进展和最佳实践

    PubMed and Beyond: Recent Advances and Best Practices in Biomedical Literature Search. (arXiv:2307.09683v1 [cs.IR])

    [http://arxiv.org/abs/2307.09683](http://arxiv.org/abs/2307.09683)

    本论文总结了生物医学文献检索领域的最新进展和最佳实践，介绍了针对不同生物医学信息需求的文献检索工具，并旨在帮助读者高效满足其信息需求。

    

    生物医学研究产生了丰富的信息，其中很多只能通过文献获取。因此，文献检索是临床和生物医学研究中建立在先前知识基础上的重要工具。尽管人工智能的最新进展已经将功能扩展到了超越基于关键字的搜索，但这些进展可能对临床医生和研究人员来说还比较陌生。为了解决这个问题，本文介绍了一些特定于生物医学领域信息需求的文献检索工具，旨在帮助读者高效地满足他们的信息需求。我们首先对广泛使用的PubMed搜索引擎进行了讨论，包括最新的改进和仍然存在的挑战。然后，我们描述了五种特定信息需求的文献检索工具：1.为循证医学寻找高质量临床研究。2.为精准医学和基因组学检索基因相关信息。3.根据意义搜索。

    Biomedical research yields a wealth of information, much of which is only accessible through the literature. Consequently, literature search is an essential tool for building on prior knowledge in clinical and biomedical research. Although recent improvements in artificial intelligence have expanded functionality beyond keyword-based search, these advances may be unfamiliar to clinicians and researchers. In response, we present a survey of literature search tools tailored to both general and specific information needs in biomedicine, with the objective of helping readers efficiently fulfill their information needs. We first examine the widely used PubMed search engine, discussing recent improvements and continued challenges. We then describe literature search tools catering to five specific information needs: 1. Identifying high-quality clinical research for evidence-based medicine. 2. Retrieving gene-related information for precision medicine and genomics. 3. Searching by meaning, inc
    
[^88]: 合成就是你需要的：移除针对合成数据的成员推断攻击的辅助数据假设

    Synthetic is all you need: removing the auxiliary data assumption for membership inference attacks against synthetic data. (arXiv:2307.01701v1 [cs.CR])

    [http://arxiv.org/abs/2307.01701](http://arxiv.org/abs/2307.01701)

    这项研究提出了一种新方法，移除了成员推断攻击对辅助数据的假设，使用只有合成数据的情况下仍然能够成功进行成员推断攻击。

    

    合成数据正在成为在保护隐私的同时共享个体级数据的最有希望的解决方案。基于影子建模的成员推断攻击已经成为评估合成数据隐私的标准。然而，这些攻击目前假设攻击者可以访问与训练数据集的类似分布的辅助数据集。这往往是一个非常强的假设，在实践中很难发生攻击。我们在这里展示了如何移除这个假设，以及如何仅使用合成数据进行成员推断攻击。具体而言，在三种不同的攻击场景中仅使用合成数据，我们的结果表明，成员推断攻击仍然成功，涉及两个真实世界数据集和两个合成数据生成器。这些结果表明，在审计合成数据发布访问辅助数据集的强假设可以放松以进行实际攻击。

    Synthetic data is emerging as the most promising solution to share individual-level data while safeguarding privacy. Membership inference attacks (MIAs), based on shadow modeling, have become the standard to evaluate the privacy of synthetic data. These attacks, however, currently assume the attacker to have access to an auxiliary dataset sampled from a similar distribution as the training dataset. This often is a very strong assumption that would make an attack unlikely to happen in practice. We here show how this assumption can be removed and how MIAs can be performed using only the synthetic data. More specifically, in three different attack scenarios using only synthetic data, our results demonstrate that MIAs are still successful, across two real-world datasets and two synthetic data generators. These results show how the strong hypothesis made when auditing synthetic data releases access to an auxiliary dataset - can be relaxed to perform an actual attack.
    
[^89]: $\lambda$-AC：学习连续状态空间强化学习中的潜在决策感知模型

    $\lambda$-AC: Learning latent decision-aware models for reinforcement learning in continuous state-spaces. (arXiv:2306.17366v1 [cs.LG])

    [http://arxiv.org/abs/2306.17366](http://arxiv.org/abs/2306.17366)

    这项研究提出了一种$\lambda$-AC算法，通过学习连续状态空间中的潜在决策感知模型，实现了决策驱动的强化学习。通过理论和实证研究，确定了决策感知强化学习模型的必要组成部分，并展示了设计选择对算法性能的重要影响。

    

    决策感知模型学习的思想，在模型驱动的强化学习中变得越来越重要，即模型在决策制定时应该是准确的。尽管已经建立了一些有希望的理论结果，但是在连续控制问题中，利用决策感知损失的算法的实际性能仍然不足。本文研究了决策感知强化学习模型所需的必要组成部分，并展示了能够实现良好算法性能的设计选择。为此，我们对该领域的重要算法思想进行了理论和实证研究。我们强调，在MuZero系列工作中所建立的经验性设计决策对于相关算法的良好性能至关重要，并展示了在随机环境中，不同的价值感知算法实例之间行为差异。在这些见解的基础上，我们提出了潜在模型驱动决策的算法，称为$\lambda$-AC。

    The idea of decision-aware model learning, that models should be accurate where it matters for decision-making, has gained prominence in model-based reinforcement learning. While promising theoretical results have been established, the empirical performance of algorithms leveraging a decision-aware loss has been lacking, especially in continuous control problems. In this paper, we present a study on the necessary components for decision-aware reinforcement learning models and we showcase design choices that enable well-performing algorithms. To this end, we provide a theoretical and empirical investigation into prominent algorithmic ideas in the field. We highlight that empirical design decisions established in the MuZero line of works are vital to achieving good performance for related algorithms, and we showcase differences in behavior between different instantiations of value-aware algorithms in stochastic environments. Using these insights, we propose the Latent Model-Based Decisio
    
[^90]: HNO：用于解决PDE的鬣狗神经算子

    HNO: Hyena Neural Operator for solving PDEs. (arXiv:2306.16524v1 [cs.LG])

    [http://arxiv.org/abs/2306.16524](http://arxiv.org/abs/2306.16524)

    本研究使用了一种名为鬣狗的新型神经算子，它利用多层感知器参数化的长卷积滤波器来解决PDE问题。这种方法通过增强模型对输入上下文的理解，并为不同的PDE实例提供数据依赖权重，提供了一种有效的求解PDE的方式。

    

    数值求解偏微分方程（PDE）通常需要精细离散化以解析必要的时空尺度，这可能会耗费大量计算资源。深度学习的最新进展提供了一种新方法来解决PDE，该方法涉及使用神经算子。神经算子是一种神经网络架构，可以学习函数空间之间的映射，并能够基于数据解决偏微分方程。本研究利用了一种称为鬣狗（Hyena）的新型神经算子，该算子采用由多层感知器参数化的长卷积滤波器。鬣狗算子是一种具有次线性复杂性的操作，它使用状态空间模型来参数化具有全局感受野的长卷积。这种机制增强了模型对输入上下文的理解，并能够为不同的PDE实例提供数据依赖权重。为了衡量各个层在解决PDE中的有效性，我们进行实验评估。

    Numerically solving partial differential equations (PDEs) typically requires fine discretization to resolve necessary spatiotemporal scales, which can be computationally expensive. Recent advances in deep learning have provided a new approach to solving PDEs that involves the use of neural operators. Neural operators are neural network architectures that learn mappings between function spaces and have the capability to solve partial differential equations based on data. This study utilizes a novel neural operator called Hyena, which employs a long convolutional filter that is parameterized by a multilayer perceptron. The Hyena operator is an operation that enjoys sub-quadratic complexity and state space model to parameterize long convolution that enjoys global receptive field. This mechanism enhances the model's comprehension of the input's context and enables data-dependent weight for different PDE instances. To measure how effective the layers are in solving PDEs, we conduct experime
    
[^91]: 一种自监督对比学习方法用于抓取结果预测

    A Self-supervised Contrastive Learning Method for Grasp Outcomes Prediction. (arXiv:2306.14437v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2306.14437](http://arxiv.org/abs/2306.14437)

    本文研究了一种自监督对比学习方法，能够有效预测抓取结果，通过公开可用的数据集的验证，证明该方法在抓取结果预测任务上表现良好，超过其他无监督方法，揭示了对比学习方法在机器人抓取领域的潜力和准确的抓取预测对于实现稳定抓取的重要性。

    

    本文研究了对比学习方法在无监督情况下预测抓取结果的有效性。通过利用一份公开可用的数据集，我们展示了对比学习方法在抓取结果预测任务上的表现良好。具体来说，基于动态字典和动量更新技术的方法使用来自单个触觉传感器的数据，达到了81.83%的满意准确率，超越了其他无监督方法。我们的结果揭示了对比学习方法在机器人抓取领域的应用潜力，并突出了准确的抓取预测对于实现稳定抓取的重要性。

    In this paper, we investigate the effectiveness of contrastive learning methods for predicting grasp outcomes in an unsupervised manner. By utilizing a publicly available dataset, we demonstrate that contrastive learning methods perform well on the task of grasp outcomes prediction. Specifically, the dynamic-dictionary-based method with the momentum updating technique achieves a satisfactory accuracy of 81.83% using data from one single tactile sensor, outperforming other unsupervised methods. Our results reveal the potential of contrastive learning methods for applications in the field of robot grasping and highlight the importance of accurate grasp prediction for achieving stable grasps.
    
[^92]: Achilles' Heels: 合成数据发布中易受攻击的记录识别

    Achilles' Heels: Vulnerable Record Identification in Synthetic Data Publishing. (arXiv:2306.10308v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2306.10308](http://arxiv.org/abs/2306.10308)

    本论文提出了基于合成数据发布的易受攻击记录识别技术，通过利用记录与最近邻之间的距离，优于以前的方法，并具有鲁棒性。

    

    合成数据被认为是在保护隐私的同时共享个人级别数据的最有前途的解决方案。基于影子建模的成员推断攻击(MIAs)已经成为评估合成数据隐私风险的标准方法。虽然非常有效，但是它们需要创建大量的数据集和训练模型来评估单个记录的风险。因此，目前通过在选定的少数记录上运行MIAs来评估数据集的隐私风险。我们这里提出了我们认为是目前为止第一个基于原则的合成数据发布易受攻击记录识别技术，利用记录与最近邻之间的距离。我们展示了我们的方法在数据集和生成器之间明显优于以前的特定方法。我们还展示了我们的方法对于MIA选择和特定参数选择具有鲁棒性。最后，我们展示了它能够准确地识别易受攻击的记录。

    Synthetic data is seen as the most promising solution to share individual-level data while preserving privacy. Shadow modeling-based Membership Inference Attacks (MIAs) have become the standard approach to evaluate the privacy risk of synthetic data. While very effective, they require a large number of datasets to be created and models trained to evaluate the risk posed by a single record. The privacy risk of a dataset is thus currently evaluated by running MIAs on a handful of records selected using ad-hoc methods. We here propose what is, to the best of our knowledge, the first principled vulnerable record identification technique for synthetic data publishing, leveraging the distance to a record's closest neighbors. We show our method to strongly outperform previous ad-hoc methods across datasets and generators. We also show evidence of our method to be robust to the choice of MIA and to specific choice of parameters. Finally, we show it to accurately identify vulnerable records whe
    
[^93]: Prodigy: 一种快速自适应零参数学习算法

    Prodigy: An Expeditiously Adaptive Parameter-Free Learner. (arXiv:2306.06101v1 [cs.LG])

    [http://arxiv.org/abs/2306.06101](http://arxiv.org/abs/2306.06101)

    本文提出了一种基于自适应算法(如Adagrad和Adam)的学习率估计方法Prodigy和Resetting，可以快速且正确地估计到达解决方案所需的距离D，从而提高了模型的收敛速度，并在多个数据集和模型上进行了测试，实验表明该方法优于D-Adaptation并可达到手动调整Adam的测试准确度值。

    

    本文研究自适应算法(如Adagrad和Adam)中的学习率估计问题，描述了两种技术Prodigy和Resetting，可以证明地估计到达解决方案所需的距离D，以便最优设置学习率。我们的技术是基于学习率自由的D-Adaptation方法的修改，并通过$O(\sqrt{\log(D/d_0)})$的因子提高了D-Adaptation的收敛速度，其中$d_0$是$D$的初始估计值。我们在12个常见的逻辑回归基准数据集、在CIFAR10上训练的VGG11和ResNet-50、在Imagenet上训练的ViT、在IWSLT14上训练的LSTM、在Criteo数据集上训练的DLRM、在Knee MRI数据集上的VarNet，以及在BookWiki上训练的RoBERTa和GPT transformer上测试了我们的方法。我们的实验结果表明，我们的方法始终优于D-Adaptation，并达到手动调整Adam的测试准确度值。

    We consider the problem of estimating the learning rate in adaptive methods, such as Adagrad and Adam. We describe two techniques, Prodigy and Resetting, to provably estimate the distance to the solution $D$, which is needed to set the learning rate optimally. Our techniques are modifications of the D-Adaptation method for learning-rate-free learning. Our methods improve upon the convergence rate of D-Adaptation by a factor of $O(\sqrt{\log(D/d_0)})$, where $d_0$ is the initial estimate of $D$. We test our methods on 12 common logistic-regression benchmark datasets, VGG11 and ResNet-50 training on CIFAR10, ViT training on Imagenet, LSTM training on IWSLT14, DLRM training on Criteo dataset, VarNet on Knee MRI dataset, as well as RoBERTa and GPT transformer training on BookWiki. Our experimental results show that our approaches consistently outperform D-Adaptation and reach test accuracy values close to that of hand-tuned Adam.
    
[^94]: 大型语言模型能够生成显著的负面声明吗？

    Can large language models generate salient negative statements?. (arXiv:2305.16755v1 [cs.CL])

    [http://arxiv.org/abs/2305.16755](http://arxiv.org/abs/2305.16755)

    本研究探讨了大型语言模型生成真实实体的显著负面陈述的能力，在不同领域中进行了评估，结果发现大型语言模型在处理否定陈述中的事实概念上仍有困难。

    

    我们研究了大型语言模型（LLMs）生成关于现实世界实体的显著（有趣的）负面陈述的能力; 这是过去几年中涌现出的一个研究课题。我们使用零点和k次无约束探针来探测LLMs，并与传统的否定生成方法，即基于模式的文本提取和基于知识图的推理以及众包金标语句进行比较。我们评估了来自不同领域的主题生成列表的正确性和显着性。我们的评估表明，有指导的探针确实提高了生成的负面陈述的质量，与无指导的变体相比。然而，使用这两个提示，LLMs仍然难以处理负面事实的概念，常常生成许多含糊不清的陈述，或者带有负面关键词但具有积极意义的陈述。

    We examine the ability of large language models (LLMs) to generate salient (interesting) negative statements about real-world entities; an emerging research topic of the last few years. We probe the LLMs using zero- and k-shot unconstrained probes, and compare with traditional methods for negation generation, i.e., pattern-based textual extractions and knowledge-graph-based inferences, as well as crowdsourced gold statements. We measure the correctness and salience of the generated lists about subjects from different domains. Our evaluation shows that guided probes do in fact improve the quality of generated negatives, compared to the zero-shot variant. Nevertheless, using both prompts, LLMs still struggle with the notion of factuality of negatives, frequently generating many ambiguous statements, or statements with negative keywords but a positive meaning.
    
[^95]: 语义感知的传输调度：一种基于单调性驱动的深度强化学习方法

    Semantic-aware Transmission Scheduling: a Monotonicity-driven Deep Reinforcement Learning Approach. (arXiv:2305.13706v1 [cs.LG])

    [http://arxiv.org/abs/2305.13706](http://arxiv.org/abs/2305.13706)

    这篇论文提出了一种基于单调性驱动的深度强化学习算法，用于处理在6G时代物联网系统中的大规模语义感知传输调度问题。数值结果显示所提出的算法相比基准算法可以大大减少训练时间并提高训练性能。

    

    在6G时代的物联网系统中，需要语义传输来连接分布式设备，以保证应用层性能，不仅仅是集中于通信层性能。语义在这里是信息传输有用性的衡量。大规模系统的语义感知传输调度常常涉及庞大的决策空间，现有算法无法有效地获得最优策略。本文首先研究最优语义感知调度策略的基本属性，然后根据理论指导原则开发了先进的深度强化学习算法。我们的数值结果显示，相比基准算法，所提出的算法可以大大减少训练时间并提高训练性能。

    For cyber-physical systems in the 6G era, semantic communications connecting distributed devices for dynamic control and remote state estimation are required to guarantee application-level performance, not merely focus on communication-centric performance. Semantics here is a measure of the usefulness of information transmissions. Semantic-aware transmission scheduling of a large system often involves a large decision-making space, and the optimal policy cannot be obtained by existing algorithms effectively. In this paper, we first investigate the fundamental properties of the optimal semantic-aware scheduling policy and then develop advanced deep reinforcement learning (DRL) algorithms by leveraging the theoretical guidelines. Our numerical results show that the proposed algorithms can substantially reduce training time and enhance training performance compared to benchmark algorithms.
    
[^96]: 通过同态变换转化地理空间本体

    Transforming Geospatial Ontologies by Homomorphisms. (arXiv:2305.13135v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.13135](http://arxiv.org/abs/2305.13135)

    本文研究了地理空间本体系统的同态变换。通过定义同态映射，我们将地理空间本体系统的合并、偏序关系和闭包进行了转化。

    

    本文研究了地理空间本体系统，将一组地理空间本体和一组地理空间本体操作作为一个整体进行研究，而不需要关注地理空间本体和操作的内部细节。我们定义了地理空间本体系统之间的同态映射，即保持地理空间本体操作的函数。我们将对本体集合进行聚类，即将集合划分为等价类或形成商集，然后通过嵌入操作将地理空间本体系统的同态映射分解为商集和嵌入映射的组合。接下来，我们将地理空间本体合并系统、系统中的自然偏序关系以及本体合并闭包进行了转化。

    In this paper, we study the geospatial ontologies that we are interested in together as a geospatial ontology system, consisting of a set of the geospatial ontologies and a set of geospatial ontology operations, without any internal details of the geospatial ontologies and their operations being needed, algebraically. A homomorphism between two geospatial ontology systems is a function between two sets of geospatial ontologies in the systems, which preserves the geospatial ontology operations. We view clustering a set of the ontologies as partitioning the set or defining an equivalence relation on the set or forming a quotient set of the set or obtaining the surjective image of the set. Each geospatial ontology system homomorphism can be factored as a surjective clustering to a quotient space, followed by an embedding. Geospatial ontology merging systems, natural partial orders on the systems, and geospatial ontology merging closures in the systems are then transformed under geospatial
    
[^97]: AWFSD:基于评分扩散图像先验的加速Wirtinger流用于泊松高斯全息相位恢复问题

    AWFSD: Accelerated Wirtinger Flow with Score-based Diffusion Image Prior for Poisson-Gaussian Holographic Phase Retrieval. (arXiv:2305.07712v1 [eess.SP])

    [http://arxiv.org/abs/2305.07712](http://arxiv.org/abs/2305.07712)

    本文提出了一种名为AWFSD的算法，它基于评分扩散模型作为生成先验，用于解决在实际场景中，由光学成像系统引起的测量数据被混合的泊松和高斯噪声（PG噪声）所破坏的全息相位恢复问题，并且比现有方法具有更优的性能。

    

    相位恢复是许多相干成像系统中的一个重要问题。本文旨在解决在实际场景中，由光学成像系统引起的测量数据被混合的泊松和高斯噪声（PG噪声）所破坏的全息相位恢复问题。为了解决这个问题，我们开发了一种基于加速Wirtinger流的新算法，使用评分扩散模型作为生成先验（AWFSD）。特别地，我们将相位恢复问题构建为一个包含数据适配项和正则化项的优化任务。我们导出了PG对数似然函数的梯度及其相应的Lipschitz常数，从而保证实际测量的更准确的数据一致性项。我们通过使用评分扩散模型来捕获（梯度）图像先验分布，将生成先验作为我们正则化方法的一部分引入。我们提供了理论分析，建立了所提出的生成先验与图像相位信息之间的关键联系，并展示了它相对于现有方法的卓越性能。

    Phase retrieval (PR) is an essential problem in a number of coherent imaging systems. This work aims at resolving the holographic phase retrieval problem in real world scenarios where the measurements are corrupted by a mixture of Poisson and Gaussian (PG) noise that stems from optical imaging systems. To solve this problem, we develop a novel algorithm based on Accelerated Wirtinger Flow that uses Score-based Diffusion models as the generative prior (AWFSD). In particular, we frame the PR problem as an optimization task that involves both a data fidelity term and a regularization term. We derive the gradient of the PG log-likelihood function along with its corresponding Lipschitz constant, ensuring a more accurate data consistency term for practical measurements. We introduce a generative prior as part of our regularization approach by using a score-based diffusion model to capture (the gradient of) the image prior distribution. We provide theoretical analysis that establishes a criti
    
[^98]: CoDi: 混合类型表格生成的共同演化对比扩散模型

    CoDi: Co-evolving Contrastive Diffusion Models for Mixed-type Tabular Synthesis. (arXiv:2304.12654v1 [cs.LG])

    [http://arxiv.org/abs/2304.12654](http://arxiv.org/abs/2304.12654)

    CoDi 方法使用两个共同演化的对比扩散模型单独处理离散和连续变量并相互条件化，同时引入对比学习方法进行进一步的绑定，展现了在真实世界的表格数据集上的有效性。

    

    随着越来越多的注意力被放在表格数据上，将综合表格应用于各种任务的尝试已经向各种场景扩展。由于生成建模的最新进展，通过表格数据综合模型生成的虚假数据变得复杂而真实。但是，建模表格数据的离散变量（列）仍然存在困难。在本研究中，我们提出通过两个对比扩散模型单独处理连续和离散变量（但相互条件化）。两个扩散模型通过彼此读取条件在训练中共同演化。此外，为了进一步绑定扩散模型，我们引入了一个负采样的对比学习方法。在11个真实世界的表格数据集和8个基准方法的实验中，我们证明了所提出的方法 CoDi 的有效性。

    With growing attention to tabular data these days, the attempt to apply a synthetic table to various tasks has been expanded toward various scenarios. Owing to the recent advances in generative modeling, fake data generated by tabular data synthesis models become sophisticated and realistic. However, there still exists a difficulty in modeling discrete variables (columns) of tabular data. In this work, we propose to process continuous and discrete variables separately (but being conditioned on each other) by two diffusion models. The two diffusion models are co-evolved during training by reading conditions from each other. In order to further bind the diffusion models, moreover, we introduce a contrastive learning method with a negative sampling method. In our experiments with 11 real-world tabular datasets and 8 baseline methods, we prove the efficacy of the proposed method, called CoDi.
    
[^99]: 通过伦理和哲学原则确保可信赖的医疗人工智能

    Ensuring Trustworthy Medical Artificial Intelligencethrough Ethical and Philosophical Principles. (arXiv:2304.11530v1 [cs.AI])

    [http://arxiv.org/abs/2304.11530](http://arxiv.org/abs/2304.11530)

    本文讨论了人工智能在医疗保健中的应用和考虑伦理和哲学原则以确保可靠的人工智能工具的重要性。人工智能在医疗中带来了更多挑战，必须解决偏见、透明度、自主权、责任和问责制等问题，作者提出了可能的解决办法。

    

    人工智能方法在医疗护理方面具有极大的潜力，可以通过提高医疗专家和患者的体验来彻底改变众多医疗护理。基于人工智能的计算机辅助诊断工具如果能够表现出色甚至与临床专家的水平相当，就可以产生巨大的效益。因此，发展中国家可以提供先进的医疗护理服务，并解决缺乏专业医疗从业者的问题。基于人工智能的工具可以节省时间、资源和整体治疗成本。此外，与人类相比，人工智能可以揭示大量输入数据中的复杂关系，甚至可以为医学提供新的基于证据的知识。然而，在医疗护理中整合人工智能也带来了几个伦理和哲学上的问题，如偏见、透明度、自主权、责任和问责制，这些问题必须在将这些工具整合到临床环境之前得到解决。在本文中，我们强调了人工智能在医疗护理中的最新应用以及考虑伦理和哲学原则以确保可信赖的人工智能工具的重要性。我们讨论了与医疗护理中的人工智能相关的各种挑战，包括数据偏见、透明度的需要、自主决策的问题以及问责制。我们还提出了解决这些挑战的潜在方案，包括确保透明度和问责制的框架以及指导人工智能开发者考虑伦理原则的指南。通过解决这些挑战并实施伦理和哲学原则，我们可以确保开发出符合诊所设置的受信任的医疗人工智能。

    Artificial intelligence (AI) methods have great potential to revolutionize numerous medical care by enhancing the experience of medical experts and patients. AI based computer-assisted diagnosis tools can have a tremendous benefit if they can outperform or perform similarly to the level of a clinical expert. As a result, advanced healthcare services can be affordable in developing nations, and the problem of a lack of expert medical practitioners can be addressed. AI based tools can save time, resources, and overall cost for patient treatment. Furthermore, in contrast to humans, AI can uncover complex relations in the data from a large set of inputs and even lead to new evidence-based knowledge in medicine. However, integrating AI in healthcare raises several ethical and philosophical concerns, such as bias, transparency, autonomy, responsibility and accountability, which must be addressed before integrating such tools into clinical settings. In this article, we emphasize recent advanc
    
[^100]: 基于图神经网络的纳米卫星任务调度方法：学习混合整数模型的洞见

    A Graph Neural Network Approach to Nanosatellite Task Scheduling: Insights into Learning Mixed-Integer Models. (arXiv:2303.13773v1 [cs.LG])

    [http://arxiv.org/abs/2303.13773](http://arxiv.org/abs/2303.13773)

    本研究提出基于GNN的纳米卫星任务调度方法，以更好地优化服务质量，解决ONTS问题的复杂性。

    

    本研究探讨如何利用图神经网络（GNN）更有效地调度纳米卫星任务。在离线纳米卫星任务调度（ONTS）问题中，目标是找到在轨道上执行任务的最佳安排，同时考虑服务质量（QoS）方面的考虑因素，如优先级，最小和最大激活事件，执行时间框架，周期和执行窗口，以及卫星电力资源和能量收集和管理的复杂性的约束。ONTS问题已经使用传统的数学公式和精确方法进行了处理，但是它们在问题的挑战性案例中的适用性有限。本研究考察了在这种情况下使用GNN的方法，该方法已经成功应用于许多优化问题，包括旅行商问题，调度问题和设施放置问题。在本文中，我们将ONTS问题的MILP实例完全表示成二分图网络结构来应用GNN。

    This study investigates how to schedule nanosatellite tasks more efficiently using Graph Neural Networks (GNN). In the Offline Nanosatellite Task Scheduling (ONTS) problem, the goal is to find the optimal schedule for tasks to be carried out in orbit while taking into account Quality-of-Service (QoS) considerations such as priority, minimum and maximum activation events, execution time-frames, periods, and execution windows, as well as constraints on the satellite's power resources and the complexity of energy harvesting and management. The ONTS problem has been approached using conventional mathematical formulations and precise methods, but their applicability to challenging cases of the problem is limited. This study examines the use of GNNs in this context, which has been effectively applied to many optimization problems, including traveling salesman problems, scheduling problems, and facility placement problems. Here, we fully represent MILP instances of the ONTS problem in biparti
    
[^101]: ERNIE-Music: 使用扩散模型的文本到波形音乐生成

    ERNIE-Music: Text-to-Waveform Music Generation with Diffusion Models. (arXiv:2302.04456v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2302.04456](http://arxiv.org/abs/2302.04456)

    本文提出了ERNIE-Music，一种基于扩散模型的文本到波形音乐生成模型。通过创新地利用自由形式的文本提示作为条件因素，我们成功实现了从文本到音乐波形的生成。通过利用网络资源构建数据集并采用弱监督技术，我们解决了有限的文本-音乐平行数据的挑战。我们还对比了两种不同的文本条件格式的有效性，为该领域的研究提供了实证结果。

    

    近年来，对扩散模型的兴趣日益增加，这导致了图像和语音生成方面的重大进展。然而，从无限制的文本提示直接合成音乐波形仍然是一个相对未被充分探索的领域。为了填补这一空白，本文介绍了一种创新性贡献，即以扩散模型为基础的文本到波形音乐生成模型。我们的方法依赖于将自由形式的文本提示作为有条件的因素，以指导扩散模型框架内的波形生成过程。为了解决有限的文本-音乐平行数据的挑战，我们通过利用网络资源来创建一个数据集，这一任务得到了弱监督技术的帮助。此外，我们进行了严格的实证调查，对比了两种不同的文本条件格式的有效性，即音乐标签和无约束的文本描述。

    In recent years, the burgeoning interest in diffusion models has led to significant advances in image and speech generation. Nevertheless, the direct synthesis of music waveforms from unrestricted textual prompts remains a relatively underexplored domain. In response to this lacuna, this paper introduces a pioneering contribution in the form of a text-to-waveform music generation model, underpinned by the utilization of diffusion models. Our methodology hinges on the innovative incorporation of free-form textual prompts as conditional factors to guide the waveform generation process within the diffusion model framework. Addressing the challenge of limited text-music parallel data, we undertake the creation of a dataset by harnessing web resources, a task facilitated by weak supervision techniques. Furthermore, a rigorous empirical inquiry is undertaken to contrast the efficacy of two distinct prompt formats for text conditioning, namely, music tags and unconstrained textual description
    
[^102]: 关于强化学习中Transformers的调查

    A Survey on Transformers in Reinforcement Learning. (arXiv:2301.03044v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.03044](http://arxiv.org/abs/2301.03044)

    这篇论文是一项调查研究，总结了在强化学习领域使用Transformers的动机、进展和未来前景。

    

    Transformer已被认为是自然语言处理（NLP）和计算机视觉（CV）领域中的主导神经架构，主要应用于监督学习任务。最近，在强化学习（RL）领域中也出现了类似的使用Transformers的潮流，但面临着RL的特殊设计选择和挑战。然而，Transformers在RL中的发展尚未被充分揭示。在本文中，我们系统地回顾了在RL中使用Transformers的动机和进展，提供了一个现有工作的分类体系，讨论了每个子领域，并总结了未来的前景。

    Transformer has been considered the dominating neural architecture in NLP and CV, mostly under supervised settings. Recently, a similar surge of using Transformers has appeared in the domain of reinforcement learning (RL), but it is faced with unique design choices and challenges brought by the nature of RL. However, the evolution of Transformers in RL has not yet been well unraveled. In this paper, we seek to systematically review motivations and progress on using Transformers in RL, provide a taxonomy on existing works, discuss each sub-field, and summarize future prospects.
    
[^103]: 基于视觉注意力的协同飞行控制

    Towards Cooperative Flight Control Using Visual-Attention. (arXiv:2212.11084v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2212.11084](http://arxiv.org/abs/2212.11084)

    该论文提出了一种基于视觉注意力的协同飞行控制系统，通过眼球追踪和神经控制系统之间的合作，实现了飞行员和自动驾驶系统的并行自主。根据注意力特征的差异，系统可以让飞行员或自动驾驶系统来进行控制决策。

    

    在飞行控制中，人类飞行员与自动驾驶系统的协同合作实现了并行自主。我们提出了一种空中守护系统，通过眼球追踪技术实现了飞行员与并行端到端神经控制系统之间的合作。我们的基于视觉的空中守护系统将因果连续深度神经网络模型与协作层相结合，通过感知其注意力特征差异实现了飞行员与控制系统之间的并行自主。神经网络的注意力特征通过VisualBackProp算法计算得到，而人类的注意力特征则通过飞行员的眼球追踪或模仿人类飞行员训练得到的网络的显著性图进行获取。当飞行员和空中守护系统的注意力特征一致时，飞行员进行控制决策；否则，空中守护系统进行干预并接管飞行器的控制。

    The cooperation of a human pilot with an autonomous agent during flight control realizes parallel autonomy. We propose an air-guardian system that facilitates cooperation between a pilot with eye tracking and a parallel end-to-end neural control system. Our vision-based air-guardian system combines a causal continuous-depth neural network model with a cooperation layer to enable parallel autonomy between a pilot and a control system based on perceived differences in their attention profiles. The attention profiles for neural networks are obtained by computing the networks' saliency maps (feature importance) through the VisualBackProp algorithm, while the attention profiles for humans are either obtained by eye tracking of human pilots or saliency maps of networks trained to imitate human pilots. When the attention profile of the pilot and guardian agents align, the pilot makes control decisions. Otherwise, the air-guardian makes interventions and takes over the control of the aircraft.
    
[^104]: 分类指标的分析与比较

    Analysis and Comparison of Classification Metrics. (arXiv:2209.05355v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.05355](http://arxiv.org/abs/2209.05355)

    本文回顾并比较了常用于度量分类系统表现的各种指标，发现期望成本指标具有更广泛的适用性和直观性，并可用于解决从连续得分生成分类决策的实践问题。

    

    在机器学习领域，常用各种性能指标来评估分类系统的表现。本文介绍了一些最常用的用于衡量硬决策质量的标准和平衡准确率、标准和平衡错误率、F-beta分数和Matthews相关系数（MCC）等指标。我们回顾了这些和其他指标的定义，并将它们与期望成本（EC）进行比较，后者是每个统计学习课程中都介绍但在机器学习文献中很少使用的指标。我们表明标准和平衡错误率都是EC的特殊情况，进一步展示了EC与F分数和MCC的关系，并认为EC指标优于传统指标，因其更具有优雅性、通用性和直观性，且基于统计学的基本原理。本文中介绍的指标均用于度量硬决策的质量。然而，大多数现代分类系统输出连续得分，而有一个重要的实践问题是如何从这些连续得分中生成分类决策。

    A variety of different performance metrics are commonly used in the machine learning literature for the evaluation of classification systems. Some of the most common ones for measuring quality of hard decisions are standard and balanced accuracy, standard and balanced error rate, F-beta score, and Matthews correlation coefficient (MCC). In this document, we review the definition of these and other metrics and compare them with the expected cost (EC), a metric introduced in every statistical learning course but rarely used in the machine learning literature. We show that both the standard and balanced error rates are special cases of the EC. Further, we show its relation with F-score and MCC and argue that EC is superior to these traditional metrics, being more elegant, general, and intuitive, as well as being based on basic principles from statistics.  The metrics above measure the quality of hard decisions. Yet, most modern classification systems output continuous scores for the class
    
[^105]: 分析环境和社交语境，使机器人的语音适应环境

    Read the Room: Adapting a Robot's Voice to Ambient and Social Contexts. (arXiv:2205.04952v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2205.04952](http://arxiv.org/abs/2205.04952)

    本研究描述了一种选择机器人语音风格的过程和结果，以达到社交适应性和环境感知。通过在虚拟环境中收集和验证语音数据交互，并使用投影、灯光和声音在重新创造的环境中测试机器人的语音风格，我们探索和聚类人类的语音话语以识别主要的语音风格，并以餐饮服务场景作为概念验证环境。结果表明，这种研究可以改善机器人在特定语境下的社交适应性和智能感知。

    

    机器人在正式、安静、黑暗的环境或明亮、热闹、嘈杂的环境中应该如何说话？通过设计机器人以更社交和适应环境的方式说话，我们可以提高人们对这些代理人的感知意识和智能程度。我们描述了一种选择机器人语音风格以达到社交适应性和环境感知的过程和结果。由于野外语音获取的困难，理解人类在不同声学环境中如何调整自己的声音可能具有挑战性。我们的方法包括三个步骤：(a) 在虚拟的Zoom环境中收集和验证语音数据交互，(b) 探索和聚类人类的语音话语以识别主要的语音风格，以及(c) 使用投影、灯光和声音在再现的环境中测试机器人的语音风格。我们以餐饮服务场景作为概念验证环境。我们提供了使用Pepper机器人的不同风格的语音的结果，朝着在特定语境下说话的机器人。

    How should a robot speak in a formal, quiet and dark, or a bright, lively and noisy environment? By designing robots to speak in a more social and ambient-appropriate manner we can improve perceived awareness and intelligence for these agents. We describe a process and results toward selecting robot voice styles for perceived social appropriateness and ambiance awareness. Understanding how humans adapt their voices in different acoustic settings can be challenging due to difficulties in voice capture in the wild. Our approach includes 3 steps: (a) Collecting and validating voice data interactions in virtual Zoom ambiances, (b) Exploration and clustering human vocal utterances to identify primary voice styles, and (c) Testing robot voice styles in recreated ambiances using projections, lighting and sound. We focus on food service scenarios as a proof-of-concept setting. We provide results using the Pepper robot's voice with different styles, towards robots that speak in a contextually a
    
[^106]: 图神经网络的最优传播策略

    Optimal Propagation for Graph Neural Networks. (arXiv:2205.02998v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.02998](http://arxiv.org/abs/2205.02998)

    本文提出了一种双层优化方法，通过学习个性化PageRank传播矩阵和下游半监督节点分类，来学习最优的图结构。该方法在实证评估中展现了优越的功效和鲁棒性。

    

    图神经网络通过使用固定的图数据作为输入，在各种实际应用中取得了巨大的成功。然而，由于信息稀缺、噪声、对抗性攻击或图拓扑、特征和真实标签分布之间的差异，初始输入图可能在特定下游任务上并不是最优的。在本文中，我们提出了一种双层优化方法，通过直接学习个性化PageRank传播矩阵以及下游半监督节点分类的方法来学习最优图结构。我们还探索了一种低秩逼近模型，进一步减少时间复杂度。实证评估表明，所提出的模型在所有基准方法上具有优越的功效和鲁棒性。

    Graph Neural Networks (GNNs) have achieved tremendous success in a variety of real-world applications by relying on the fixed graph data as input. However, the initial input graph might not be optimal in terms of specific downstream tasks, because of information scarcity, noise, adversarial attacks, or discrepancies between the distribution in graph topology, features, and groundtruth labels. In this paper, we propose a bi-level optimization approach for learning the optimal graph structure via directly learning the Personalized PageRank propagation matrix as well as the downstream semi-supervised node classification simultaneously. We also explore a low-rank approximation model for further reducing the time complexity. Empirical evaluations show the superior efficacy and robustness of the proposed model over all baseline methods.
    
[^107]: 面向方面的情感分析数据集调查

    Survey of Aspect-based Sentiment Analysis Datasets. (arXiv:2204.05232v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.05232](http://arxiv.org/abs/2204.05232)

    本研究汇总了65个公开可用的ABSA数据集，包括45个英文数据集和20个其他语言数据集，提供了一个可以用于训练和评估自主ABSA系统的数据库。

    

    面向方面的情感分析(ABSA)是一个自然语言处理问题，需要分析用户生成的评论以确定：a)正在审查的目标实体，b)属于哪个高级方面，c)对目标和方面表达的情感。ABSA的众多但分散的语料库使研究人员很难快速确定最适合特定ABSA子任务的语料库。本研究旨在提供一个可以用于训练和评估自主ABSA系统的数据库。此外，我们提供了ABSA和其子任务的主要语料库概述，并强调研究人员在选择语料库时应考虑的几个特征。最后，我们讨论了当前收集方法的优缺点并为未来语料库创建提出建议。本调查审核了65个公开可用的ABSA数据集，涵盖25个领域，包括45个英语和20个其他语言的数据集。

    Aspect-based sentiment analysis (ABSA) is a natural language processing problem that requires analyzing user-generated reviews to determine: a) The target entity being reviewed, b) The high-level aspect to which it belongs, and c) The sentiment expressed toward the targets and the aspects. Numerous yet scattered corpora for ABSA make it difficult for researchers to identify corpora best suited for a specific ABSA subtask quickly. This study aims to present a database of corpora that can be used to train and assess autonomous ABSA systems. Additionally, we provide an overview of the major corpora for ABSA and its subtasks and highlight several features that researchers should consider when selecting a corpus. Finally, we discuss the advantages and disadvantages of current collection approaches and make recommendations for future corpora creation. This survey examines 65 publicly available ABSA datasets covering over 25 domains, including 45 English and 20 other languages datasets.
    
[^108]: VisEvent：通过帧和事件流的协作实现可靠的物体跟踪

    VisEvent: Reliable Object Tracking via Collaboration of Frame and Event Flows. (arXiv:2108.05015v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2108.05015](http://arxiv.org/abs/2108.05015)

    本论文提出了一个大规模的可见-事件基准（VisEvent），通过可见摄像机和事件摄像机的协作，实现了更可靠的物体跟踪。根据VisEvent，我们将事件流转化为事件图像，并构建了30多个...

    

    不同于记录逐帧强度图像的可见摄像机，生物启发式事件摄像机产生一系列异步和稀疏事件，具有更低的延迟。在实践中，可见摄像机可以更好地感知纹理细节和慢动作，而事件摄像机可以摆脱运动模糊，并具有更大的动态范围，使其在快速运动和低照明条件下表现良好。因此，这两种传感器可以相互合作，实现更可靠的物体跟踪。在这项工作中，我们提出了一个大规模的可见-事件基准（称为VisEvent），因为此任务缺乏一个真实且具有规模的数据集。我们的数据集包含820个视频对，涵盖了低照明、高速和背景杂乱场景，并分为训练子集和测试子集，分别包含500个和320个视频。

    Different from visible cameras which record intensity images frame by frame, the biologically inspired event camera produces a stream of asynchronous and sparse events with much lower latency. In practice, visible cameras can better perceive texture details and slow motion, while event cameras can be free from motion blurs and have a larger dynamic range which enables them to work well under fast motion and low illumination. Therefore, the two sensors can cooperate with each other to achieve more reliable object tracking. In this work, we propose a large-scale Visible-Event benchmark (termed VisEvent) due to the lack of a realistic and scaled dataset for this task. Our dataset consists of 820 video pairs captured under low illumination, high speed, and background clutter scenarios, and it is divided into a training and a testing subset, each of which contains 500 and 320 videos, respectively. Based on VisEvent, we transform the event flows into event images and construct more than 30 b
    

