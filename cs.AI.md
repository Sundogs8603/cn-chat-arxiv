# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [SHACIRA: Scalable HAsh-grid Compression for Implicit Neural Representations.](http://arxiv.org/abs/2309.15848) | SHACIRA提出了一种简单但有效的通用框架，用于对神经表示中的特征网格进行高水平压缩，通过量化潜在权重和应用熵正则化来实现压缩。这种方法在多样化数据集上取得了定量和定性上的好结果。 |
| [^2] | [Disinformation Detection: An Evolving Challenge in the Age of LLMs.](http://arxiv.org/abs/2309.15847) | 这项研究探讨了生成型大型语言模型（LLM）所带来的虚假信息传播问题以及如何对抗这一威胁。研究旨在回答三个问题：目前虚假信息检测技术对LLM生成的虚假信息是否可靠？如果传统技术无效，LLM是否能作为一个强大的防御手段？如果前两种策略失败，可以提出什么新的方法来对抗这一威胁？ |
| [^3] | [How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions.](http://arxiv.org/abs/2309.15840) | 本文提出了一个简单但高精确度的谎言检测器，通过在怀疑有谎言的情况下问一组无关的后续问题，并将LLM的是/否答案输入到一个逻辑回归分类器中，该检测器能够推广到不同的LLM架构和实际场景中的谎言情况。 |
| [^4] | [Examining the Values Reflected by Children during AI Problem Formulation.](http://arxiv.org/abs/2309.15839) | 研究通过观察儿童在AI问题构思中的活动，揭示了儿童如何向自己设计的AI系统中融入价值观，为日常活动提供支持，包括对高级系统智能的需求和对情感检测的需求。 |
| [^5] | [OrthoPlanes: A Novel Representation for Better 3D-Awareness of GANs.](http://arxiv.org/abs/2309.15830) | 本论文提出了一种新的表示方法OrthoPlanes，通过在特征图中编码细粒度的3D信息来生成真实且视图一致的图像。与以前的方法相比，OrthoPlanes具有更好的可扩展性和表达能力，可以处理更具挑战性的视角和合成具有高度空间自由度的关节对象。实验证明，该方法在FFHQ和SHHQ数据集上取得了最先进的结果。 |
| [^6] | [Identifying the Risks of LM Agents with an LM-Emulated Sandbox.](http://arxiv.org/abs/2309.15817) | 通过使用LM模拟工具执行和开发基于LM的自动安全评估器，该论文提出了一种解决测试LM代理的高成本和寻找高风险问题的方法。 |
| [^7] | [Lyra: Orchestrating Dual Correction in Automated Theorem Proving.](http://arxiv.org/abs/2309.15806) | Lyra是一种新的框架，通过引入工具修正和猜想修正两种机制，增强了大规模语言模型在形式化定理证明领域的有效性，减轻了幻觉，并提高了证明的准确性。 |
| [^8] | [ANNCRIPS: Artificial Neural Networks for Cancer Research In Prediction & Survival.](http://arxiv.org/abs/2309.15803) | 本研究通过开发和验证一种智能数学模型，利用人工神经网络提高前列腺癌的早期检测，降低假阳性率，改善患者预后。预计该模型经过进一步改进和验证后，可以成为一个可靠的、市场化的前列腺癌检测解决方案。 |
| [^9] | [AI in Software Engineering: Case Studies and Prospects.](http://arxiv.org/abs/2309.15768) | 本文分析了IBM Watson和Google AlphaGo两个案例研究，并得出结论：在软件系统中使用深度学习和机器学习等AI技术有助于实现智能化系统。 |
| [^10] | [Latent Graph Powered Semi-Supervised Learning on Biomedical Tabular Data.](http://arxiv.org/abs/2309.15757) | 本文提出了一种基于潜在图的半监督学习方法，通过利用图的表示来捕捉数据之间的关系，并实现了全局和局部知识的有效融合。在生物医学数据集上的评估中，我们的方法表现出了最先进的结果。 |
| [^11] | [Experience and Evidence are the eyes of an excellent summarizer! Towards Knowledge Infused Multi-modal Clinical Conversation Summarization.](http://arxiv.org/abs/2309.15739) | 本文提出了一种利用知识融入的多模态多任务框架，用于生成临床对话的摘要。通过适配器注入知识和视觉特征，并采用门控机制统一融合的特征向量。实验证明了该方法的重要性。 |
| [^12] | [MindGPT: Interpreting What You See with Non-invasive Brain Recordings.](http://arxiv.org/abs/2309.15729) | 这篇论文介绍了一种非侵入性神经解码器MindGPT，它能够从脑信号中解析所见的视觉刺激并转化为自然语言表达。 |
| [^13] | [Where Are We So Far? Understanding Data Storytelling Tools from the Perspective of Human-AI Collaboration.](http://arxiv.org/abs/2309.15723) | 本文通过研究现有数据叙事工具，从人工智能协作的角度出发，总结了关于不同阶段和角色的共同协作模式，以促进人类和人工智能的优势并减少不足。 |
| [^14] | [Model Share AI: An Integrated Toolkit for Collaborative Machine Learning Model Development, Provenance Tracking, and Deployment in Python.](http://arxiv.org/abs/2309.15719) | Model Share AI是一个用于协作式机器学习模型开发、来源追踪和部署的集成工具包，提供了协作项目空间、标准化的模型评估流程和自动化的模型部署功能。 |
| [^15] | [ChatGPT-BCI: Word-Level Neural State Classification Using GPT, EEG, and Eye-Tracking Biomarkers in Semantic Inference Reading Comprehension.](http://arxiv.org/abs/2309.15714) | 本研究通过联合分析大型语言模型（LLMs）、眼动和脑电图（EEG）数据，研究了大脑在阅读过程中处理与关键字相关度不同的单词的神经状态，并提供了关于语义推理阅读理解中神经状态的洞察。 |
| [^16] | [HyPoradise: An Open Baseline for Generative Speech Recognition with Large Language Models.](http://arxiv.org/abs/2309.15701) | 本文引入了第一个开源基准测试，利用大型语言模型进行自动语音识别错误修正，实现了与人类水平相当的性能，具有重要的实际应用价值。 |
| [^17] | [Deep Model Fusion: A Survey.](http://arxiv.org/abs/2309.15698) | 深度模型融合是一种新兴技术，将多个深度学习模型的参数或预测合并到单个模型中，以实现更好的性能。在大规模深度学习模型上面临许多挑战，如高计算成本、高维参数空间、不同异构模型之间的干扰等。本论文为了更好地了解模型融合方法并推动其发展，提出了一项综合调查，总结了最近的进展。 |
| [^18] | [Generative Speech Recognition Error Correction with Large Language Models.](http://arxiv.org/abs/2309.15649) | 本研究探讨了大型语言模型（LLMs）作为ASR后处理器的能力，通过重新评分和错误校正来提高系统性能。通过使用指令提示和任务激活提示方法，结合上下文学习和微调技术，我们展示了LLMs的泛化能力和有效性。 |
| [^19] | [Hedging Properties of Algorithmic Investment Strategies using Long Short-Term Memory and Time Series models for Equity Indices.](http://arxiv.org/abs/2309.15640) | 本文提出了一种使用长短期记忆和时间序列模型构建算法投资策略的对冲方法，并通过利用不同类型的投资策略来对冲风险资产组合。实证结果显示，该方法在金融市场的动荡时期具有多样化的潜力。 |
| [^20] | [Perception for Humanoid Robots.](http://arxiv.org/abs/2309.15616) | 这项科学研究调查了人形机器人中使用的各种感知模式和技术，并研究了最新的方法来感知和理解内部状态、环境、物体和人类活动。最重要的创新是在内部状态估计中使用贝叶斯滤波方法和最大后验公式的优化技术，并在外部环境理解中利用多传感器融合和机器学习来增强鲁棒性和适应性。 |
| [^21] | [Developing automatic verbatim transcripts for international multilingual meetings: an end-to-end solution.](http://arxiv.org/abs/2309.15609) | 本文提出了一种端到端的解决方案，用于创建全自动的会议记录和多语言翻译，解决了会议管理文档中现有工作流程的替代和改善问题。 |
| [^22] | [An Evaluation of ChatGPT-4's Qualitative Spatial Reasoning Capabilities in RCC-8.](http://arxiv.org/abs/2309.15577) | 本文评估了ChatGPT-4在RCC-8中的定性空间推理能力，并探讨了大型语言模型在经典定性空间推理任务中的表现。 |
| [^23] | [Identifiability Matters: Revealing the Hidden Recoverable Condition in Unbiased Learning to Rank.](http://arxiv.org/abs/2309.15560) | 研究揭示在无偏学习排名中，当点击数据不能完全拟合时，无法恢复真实相关性，导致排名性能显著降低，提出了可识别性图模型作为解决方案。 |
| [^24] | [Direct Models for Simultaneous Translation and Automatic Subtitling: FBK@IWSLT2023.](http://arxiv.org/abs/2309.15554) | 本文描述了FBK的研究成果，他们使用直接模型来实现同时翻译和自动字幕生成任务，并在计算感知延迟方面取得了突破性的进展，同时在自动字幕生成任务中也优于现有解决方案。 |
| [^25] | [Identifying confounders in deep-learning-based model predictions using DeepRepViz.](http://arxiv.org/abs/2309.15551) | 这项研究提出了DeepRepViz框架，用于帮助研究人员在深度学习模型预测中识别混淆因素，并通过度量和可视化工具来解决这个问题。实验证明使用DeepRepViz与DL模型结合能够带来明显的益处。 |
| [^26] | [From LAION-5B to LAION-EO: Filtering Billions of Images Using Anchor Datasets for Satellite Image Extraction.](http://arxiv.org/abs/2309.15535) | 本文提出了一种基于锚定数据集和进一步过滤的提取方法，用于从大型图像库中提取卫星图像。这导致了发布了一个高分辨率的文本和卫星图像对应的数据集LAION-EO。 |
| [^27] | [Cyber Security Requirements for Platforms Enhancing AI Reproducibility.](http://arxiv.org/abs/2309.15525) | 本研究针对人工智能研究领域，提出了一个新的框架来评估人工智能平台的可复制性和网络安全性。经过评估，发现目前流行的可复制性平台中没有一个完全整合了必要的网络安全措施，但Kaggle和Codalab在实施网络安全措施方面表现较好。本研究还根据用户的不同情况提供了相应的建议，强调整合网络安全措施的重要性。 |
| [^28] | [Robust Internal Representations for Domain Generalization.](http://arxiv.org/abs/2309.15522) | 本文综合调查了作者利用嵌入空间进行转移学习研究的成果，主要讨论了持续学习和有限标记数据可用性所带来的挑战，为未来领域的进展铺平道路。 |
| [^29] | [Raij\=u: Reinforcement Learning-Guided Post-Exploitation for Automating Security Assessment of Network Systems.](http://arxiv.org/abs/2309.15518) | Raij\=u是一种使用强化学习的自动化框架，可以帮助渗透测试员快速实施网络系统的后渗透过程，以评估系统的安全级别。 |
| [^30] | [Residual Scheduling: A New Reinforcement Learning Approach to Solving Job Shop Scheduling Problem.](http://arxiv.org/abs/2309.15517) | 残差调度是一种新的强化学习方法，用于解决工作车间调度问题。通过移除不相关的机器和作业，该方法能够达到最先进的水平。 |
| [^31] | [Teaching Text-to-Image Models to Communicate.](http://arxiv.org/abs/2309.15516) | 本文提出了一种针对对话生成图像的高效方法，通过微调预训练的文本到图像模型，实现在给定对话背景下生成一致逼真的图像。 |
| [^32] | [High-Fidelity Speech Synthesis with Minimal Supervision: All Using Diffusion Models.](http://arxiv.org/abs/2309.15512) | 提出一种使用最少监督的扩散模型实现高保真度语音合成的方法，通过组合离散语音表示和利用序列到序列任务进行训练，解决了语义表示中的信息冗余和维度爆炸以及离散声学表示中的高频波形失真等问题。该方法中的非自回归框架增强了可控性，而持续时间扩散模型实现了音频的多样化控制。 |
| [^33] | [Towards Human-Like RL: Taming Non-Naturalistic Behavior in Deep RL via Adaptive Behavioral Costs in 3D Games.](http://arxiv.org/abs/2309.15484) | 本文提出了一种名为自适应行为成本强化学习（ABC-RL）的新方法，通过在强化学习中引入行为限制作为成本信号，并动态调整权重，训练出人类化的智能体。这种方法可以处理深度强化学习中出现的非自然行为问题，使智能体在游戏中更像人类，并保持相似的性能。 |
| [^34] | [Enabling Resource-efficient AIoT System with Cross-level Optimization: A survey.](http://arxiv.org/abs/2309.15467) | 该论文调查了资源高效的AIoT系统的跨级别优化，提出了一种算法-系统共同设计的方法，通过优化DL模型和系统调度，改善了运行时资源可用性，推动AIoT性能的进一步提升。 |
| [^35] | [LogicMP: A Neuro-symbolic Approach for Encoding First-order Logic Constraints.](http://arxiv.org/abs/2309.15458) | 本文提出了一种名为LogicMP的新颖神经层，该层通过均场变分推断将一阶逻辑约束编码进神经网络中。通过有效缓解一阶逻辑模型的推断困难，LogicMP在图形、图像和文本任务中表现出比竞争对手更好的性能和效率。 |
| [^36] | [Local Compressed Video Stream Learning for Generic Event Boundary Detection.](http://arxiv.org/abs/2309.15431) | 提出了一种基于局部压缩视频流学习的方法用于通用事件边界的检测，该方法能够在不完全解码视频情况下，利用压缩域中的丰富信息进行端到端的学习。使用轻量级ConvNets提取GOP中的P帧特征，并通过设计的空间-通道注意力模块进行特征细化，最终实现了准确的事件边界检测。 |
| [^37] | [Graph Neural Prompting with Large Language Models.](http://arxiv.org/abs/2309.15427) | 本文提出了一种名为图神经提示（GNP）的方法，可以帮助大型语言模型从知识图中学习有益的知识，以弥补它们在准确捕捉和返回基于知识的信息方面的固有限制。 |
| [^38] | [The Triad of Failure Modes and a Possible Way Out.](http://arxiv.org/abs/2309.15420) | 本文提出了一个新颖的目标函数，用于解决聚类自监督学习中的表示崩溃、聚类崩溃和对聚类分配的置换不变性的问题。该目标函数具有简单性和理论基础，适用于标准的主干结构训练，无需使用非对称元素。 |
| [^39] | [A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future.](http://arxiv.org/abs/2309.15402) | 本文首次全面调查了思维链推理领域的研究，涵盖了构建、结构变体和增强技术等方法分类，以及规划、工具使用和提炼等前沿应用。同时讨论了挑战和未来发展方向。这份调查报告对于在思维链推理领域寻求创新的研究人员来说是一个有价值的资源。 |
| [^40] | [Neural Stochastic Differential Equations for Robust and Explainable Analysis of Electromagnetic Unintended Radiated Emissions.](http://arxiv.org/abs/2309.15386) | 本研究对ResNet-like模型在非意图辐射发射（URE）分类中的鲁棒性和可解释性进行了全面评估，并通过提出神经随机微分方程（SDEs）的应用，解决了模型对噪声的脆弱性以及解释不准确的问题。 |
| [^41] | [Seeing Beyond the Patch: Scale-Adaptive Semantic Segmentation of High-resolution Remote Sensing Imagery based on Reinforcement Learning.](http://arxiv.org/abs/2309.15372) | 本文提出了一个动态尺度感知框架GeoAgent，用于解决遥感图像分析中基于补丁的方法的局限性，该框架通过自适应地捕捉图像补丁之外的适当尺度上下文信息来处理复杂和多变的地理对象，从而提高了语义分割的一致性。 |
| [^42] | [C3Net: interatomic potential neural network for prediction of physicochemical properties in heterogenous systems.](http://arxiv.org/abs/2309.15334) | C3Net是一种面向异质系统中物理化学性质预测的神经网络，能嵌入原子类型在分子环境中并遵循基本物理定律的原子间势。该模型在预测物理化学性质上具有良好的泛化能力，并优于基于量子力学和神经网络的最新方法。 |
| [^43] | [joint prediction and denoising for large-scale multilingual self-supervised learning.](http://arxiv.org/abs/2309.15317) | 这项研究提出了WavLabLM，它通过联合预测和去噪的方法，实现了在136种语言的40k小时数据上进行大规模多语言自监督学习。WavLabLM的多阶段预训练方法解决了多语言数据的语言失衡问题，使其在ML-SUPERB上达到了与XLS-R相当的性能，同时仅使用不到10%的训练数据，这使得SSL在学术高性能计算上可行。 |
| [^44] | [MAPTree: Beating "Optimal" Decision Trees with Bayesian Decision Trees.](http://arxiv.org/abs/2309.15312) | MAPTree是一种通过贝叶斯方法对决策树进行归纳的算法，通过AND/OR搜索实现最大后验树的恢复。在实验中，MAPTree在多个数据集上表现出更好的性能，并且能够以更小的树来实现可比较的性能。在合成数据和实际场景中，MAPTree还展示出更强的抗噪声能力和更好的泛化能力。 |
| [^45] | [The Importance of Multimodal Emotion Conditioning and Affect Consistency for Embodied Conversational Agents.](http://arxiv.org/abs/2309.15311) | 本研究提出了一个概念性框架ACTOR，通过生成以一致驱动情感为条件的多模态行为，旨在增强感知情感。研究发现，在具备表达行为的具身对话智能体中，多模态情感调节和情感一致性至关重要。 |
| [^46] | [Self-Supervised Terrain Representation Learning from Unconstrained Robot Experience.](http://arxiv.org/abs/2309.15302) | 提出一种名为STERLING的自我监督地形表示学习方法，通过无约束的机器人经验学习有关地形的相关表示，以实现地形感知导航。 |
| [^47] | [Maximum Diffusion Reinforcement Learning.](http://arxiv.org/abs/2309.15293) | 最大扩散强化学习是一种克服强化学习中数据相关性问题的方法，通过解耦代理的经验实现持续学习，并在各种测试中表现出色。 |
| [^48] | [Out of Sight, Still in Mind: Reasoning and Planning about Unobserved Objects with Video Tracking Enabled Memory Models.](http://arxiv.org/abs/2309.15278) | 本文研究了如何对先前观察到但当前被遮挡的对象进行推理和规划，提出了利用转换器关系动力学编码轨迹历史的方法，并在多个挑战性任务中表现出色。 |
| [^49] | [Efficient Low-rank Backpropagation for Vision Transformer Adaptation.](http://arxiv.org/abs/2309.15275) | 本论文提出了一种名为LBP-WHT的新方法，用于解决视觉变换器（ViT）在反向传播中对计算资源的需求过高的问题。LBP-WHT方法通过将梯度投影到低秩空间并进行反向传播，显著减少了适应ViT所需的计算量。实验结果表明，LBP-WHT在多个数据集上对不同模型的适应性能都表现出色。 |
| [^50] | [Memory-Efficient Continual Learning Object Segmentation for Long Video.](http://arxiv.org/abs/2309.15274) | 提出了两种新技术，以减少在线VOS方法的内存需求，并在提高建模准确性和泛化能力的同时进行目标分割。 |
| [^51] | [STARC: A General Framework For Quantifying Differences Between Reward Functions.](http://arxiv.org/abs/2309.15257) | 这篇论文提出了一个通用框架（STARC），用于评估奖励函数之间的差异，填补了奖励学习理论基础的空白。 |
| [^52] | [VPA: Fully Test-Time Visual Prompt Adaptation.](http://arxiv.org/abs/2309.15251) | VPA是首个将视觉提示与测试时间适应相结合的框架，通过引入可学习令牌实现了完全测试时间和存储高效的适应。实验证明，VPA能够有效提升超出分布泛化能力。 |
| [^53] | [SeMAnD: Self-Supervised Anomaly Detection in Multimodal Geospatial Datasets.](http://arxiv.org/abs/2309.15245) | 提出了一种名为SeMAnD的自监督异常检测技术，可用于检测多模态地理空间数据中的几何异常。该技术通过数据增强和自监督训练目标实现，能够有效地表示和识别不同模态数据中的局部变化和缺陷。 |
| [^54] | [PlotMap: Automated Layout Design for Building Game Worlds.](http://arxiv.org/abs/2309.15242) | 本研究提出了一种独立于底层地图生成方法的故事情节布局设计，以解决设计支持所期望叙事的游戏地图的挑战。 |
| [^55] | [Learning Using Generated Privileged Information by Text-to-Image Diffusion Models.](http://arxiv.org/abs/2309.15238) | 本研究提出了一种利用生成的特权信息进行学习的框架，通过文本到图像扩散模型生成合成数据作为特权信息，进一步提升了学生模型在文本分类任务中的性能。 |
| [^56] | [User Experience Design Professionals' Perceptions of Generative Artificial Intelligence.](http://arxiv.org/abs/2309.15237) | 经验丰富的设计师认为生成性人工智能（GenAI）在用户体验设计（UXD）实践中具有辅助作用。然而，初级设计师可能会面临技能退化、工作替代和创造力枯竭等问题。这篇论文讨论了人-GenAI协作的一些影响，包括版权与所有权、人类创造力和代理性以及AI素养和获取。 |
| [^57] | [Collaborative Watermarking for Adversarial Speech Synthesis.](http://arxiv.org/abs/2309.15224) | 本文提出了一种对抗性语音合成的协同水印技术，通过与现有对策模型合作进行训练，实现了对生成语音的有效检测和水印识别。 |
| [^58] | [Low-rank Adaptation of Large Language Model Rescoring for Parameter-Efficient Speech Recognition.](http://arxiv.org/abs/2309.15223) | 这篇论文介绍了一种基于低秩适应技术的神经语言建模系统，用于语音识别的输出重评分。通过使用低秩分解方法和优化插入矩阵，该系统能够以更高效的方式将BERT模型适应到新领域，大大减少了训练时间。 |
| [^59] | [Conservative World Models.](http://arxiv.org/abs/2309.15178) | 在零样本强化学习中，研究人员探索了在小样本数据集上训练时，前向-后向算法性能下降的问题，并使用保守性算法来缓解此问题。实验证明，保守的前向-后向算法在总体上表现更好，甚至超过了特定任务的基准算法。 |
| [^60] | [Revealing the Power of Spatial-Temporal Masked Autoencoders in Multivariate Time Series Forecasting.](http://arxiv.org/abs/2309.15169) | 提出了一个利用空间-时间掩蔽自动编码器（STMAE）来提高多元时间序列（MTS）预测性能的框架，通过新颖的双掩蔽策略处理部分可见的MTS数据，包括空间掩蔽和时间掩蔽。 |
| [^61] | [3D Reconstruction with Generalizable Neural Fields using Scene Priors.](http://arxiv.org/abs/2309.15164) | 使用场景先验的可推广神经场方法，利用单个RGB-D图像映射场景，无需融合模块即可重建完整的场景，具有较好的灵活性和扩展性。 |
| [^62] | [A Review on AI Algorithms for Energy Management in E-Mobility Services.](http://arxiv.org/abs/2309.15140) | 本文综述了AI算法在电动汽车能量管理中的应用，并探讨了其在解决各种挑战和实现能量管理的有效性方面的作用。 |
| [^63] | [PINF: Continuous Normalizing Flows for Physics-Constrained Deep Learning.](http://arxiv.org/abs/2309.15139) | 本文提出了PINF，这是物理约束深度学习的连续标准化流的一种扩展。该方法通过特征值法则和扩散来解决高维时变和稳态福克-普朗克方程。 |
| [^64] | [Deep Generative Methods for Producing Forecast Trajectories in Power Systems.](http://arxiv.org/abs/2309.15137) | 该论文研究了深度生成方法在发电系统预测轨迹中的应用，通过adapt autoregressive networks和normalizing flows捕捉多变量时间序列的时空相关性，相比当前的copula-based统计方法表现出更好的有效性。实验结果基于法国TSO RTE风力预测数据。 |
| [^65] | [Contrastive Continual Multi-view Clustering with Filtered Structural Fusion.](http://arxiv.org/abs/2309.15135) | 提出了一种名为对比度连续多视角聚类与过滤结构融合（CCMVC-FSF）的新方法，用于解决多视角聚类在实时数据收集中的困难。该方法旨在防止先前知识遗忘和利用数据相关性指导新视图的聚类过程。 |
| [^66] | [From Asset Flow to Status, Action and Intention Discovery: Early Malice Detection in Cryptocurrency.](http://arxiv.org/abs/2309.15133) | 本文提出了一种用于比特币的早期恶意检测的意图监控系统，通过定义资产转移路径和提取状态和行动，实现了对不同恶意类型的检测和发现。 |
| [^67] | [Evaluating Cognitive Maps and Planning in Large Language Models with CogEval.](http://arxiv.org/abs/2309.15129) | 这项研究提出了CogEval协议，用于系统评估大型语言模型的认知能力，并使用该协议对八个LLMs的认知地图和规划能力进行了评估。 |
| [^68] | [Explainable Sustainability for AI in the Arts.](http://arxiv.org/abs/2309.14877) | 这篇论文介绍了为AI艺术开发环境可持续性反思系统的两个实证研究，并引入了可解释的AI艺术中的可持续性。 |
| [^69] | [Era Splitting.](http://arxiv.org/abs/2309.14496) | 本研究提出了两种新的分裂准则，使得决策树模型能够利用时代信息进行优化，从而将超分布泛化研究中的思想应用于决策树模型。 |
| [^70] | [Self-Recovery Prompting: Promptable General Purpose Service Robot System with Foundation Models and Self-Recovery.](http://arxiv.org/abs/2309.14425) | 本文研究开发了一个通用服务机器人系统，该系统可以根据不同任务和环境的变化进行自适应，并通过自恢复机制解决信息不足、计划生成错误和执行失败等问题，实现了任务的成功完成。 |
| [^71] | [Seeing and hearing what has not been said; A multimodal client behavior classifier in Motivational Interviewing with interpretable fusion.](http://arxiv.org/abs/2309.14398) | 本文提出了一个多模态分类器，在动机性访谈中准确区分了变化话语、持续话语和跟随/中立话语三种类别。该分类器利用文本、声调、面部表情和身体表现等多模态特征，并对AnnoMI数据集进行了注释和训练。研究还找到了决策过程中最重要的模态，提供了宝贵的洞察。 |
| [^72] | [Enhancing data efficiency in reinforcement learning: a novel imagination mechanism based on mesh information propagation.](http://arxiv.org/abs/2309.14243) | 这项研究提出了一种基于网格信息传播的想象机制，在强化学习算法中显著提高了数据效率。通过使信息在不同状态间广播，而不仅仅是在同一状态集中传输，这种机制促进了模型对状态间相互依赖性的理解，并提高了对有限样本信息的学习效率。 |
| [^73] | [Explainable Machine Learning for ICU Readmission Prediction.](http://arxiv.org/abs/2309.13781) | 本研究提出了一个标准化且可解释的机器学习流程，用于在多中心数据库中预测加护病房患者的再入院情况。 |
| [^74] | [ALLURE: Auditing and Improving LLM-based Evaluation of Text using Iterative In-Context-Learning.](http://arxiv.org/abs/2309.13701) | ALLURE是一种基于迭代上下文学习的文本评估的审计和改进方法，通过与注释数据进行比较并纳入重大偏差的实例，使用上下文学习提高LLM对文本的评估能力。 |
| [^75] | [Decoding Radiologists Intense Focus for Accurate CXR Diagnoses: A Controllable and Interpretable AI System.](http://arxiv.org/abs/2309.13550) | 这项研究提出了一个新的、统一的、可控且可解释的人工智能系统，用于解码放射科医生在胸部X光诊断中的专注焦点，从而揭示放射学解释过程的认知过程。 |
| [^76] | [A Quantum Computing-based System for Portfolio Optimization using Future Asset Values and Automatic Reduction of the Investment Universe.](http://arxiv.org/abs/2309.12627) | 本研究提出了一种基于量子计算的投资组合优化系统Q4FuturePOP，它创新地利用未来资产价值进行建模，并引入了一个自动减少投资范围的模块。通过实验讨论了Q4FuturePOP的原型版本中不同模块的初步性能。 |
| [^77] | [Are Large Language Models Really Robust to Word-Level Perturbations?.](http://arxiv.org/abs/2309.11166) | 该论文提出了一种用于评估大型语言模型（LLMs）鲁棒性的新颖方法，使用预训练的奖励模型作为诊断工具。实验证明这种方法在评估LLM鲁棒性方面表现准确。 |
| [^78] | [Estimating Contamination via Perplexity: Quantifying Memorisation in Language Model Evaluation.](http://arxiv.org/abs/2309.10677) | 本文提出了一种新方法，通过困惑度来量化语言模型评估中的污染，而不需要访问完整的训练数据。研究表明，最近的基础模型在阅读理解和摘要基准中存在显著的记忆化，而多项选择问题则受污染较少。 |
| [^79] | [AstroPortal: An ontology repository concept for astronomy, astronautics and other space topics.](http://arxiv.org/abs/2309.10288) | 本文介绍了一个用于天文学、航天学和其他空间主题的本体库概念，该库可提供一个集中平台用于搜索、审核和创建与天文相关的本体，以减少研究时间并支持知识组织系统和语义资源的研究。 |
| [^80] | [Promoting Research Collaboration with Open Data Driven Team Recommendation in Response to Call for Proposals.](http://arxiv.org/abs/2309.09404) | 通过利用开放数据和人工智能方法，我们设计了一个系统来推荐团队，使得每个团队能够满足项目要求的技能覆盖，并且平衡候选成员之间的工作分配。 |
| [^81] | [A Geometric Perspective on Autoencoders.](http://arxiv.org/abs/2309.08247) | 本文从几何角度研究了自编码器框架，并提出了解决多解和畸变表示问题的几何方法。 |
| [^82] | [Enhancing Keyphrase Generation by BART Finetuning with Splitting and Shuffling.](http://arxiv.org/abs/2309.06726) | 本文提出了关注关键短语的BART模型(Keyphrase-Focused BART)，通过拆分和重排的方式来增强关键短语生成的性能。在不出现的关键短语生成任务中，该模型在两个关键短语生成基准数据集上取得了新的最佳得分。 |
| [^83] | [Cognitive Architectures for Language Agents.](http://arxiv.org/abs/2309.02427) | 本文提出了一种称为CoALA的认知架构，用于组织语言代理的现有研究并规划未来的发展方向。CoALA描述了一个具有模块化记忆组件、结构化行动空间和通用决策过程的语言代理。通过这一框架，有望发展出更强大的语言代理。 |
| [^84] | [CPSP: Learning Speech Concepts From Phoneme Supervision.](http://arxiv.org/abs/2309.00424) | 论文提出了一种名为CPSP的方法，通过对比学习来从语音中提取细粒度的中间表示，使得提取的信息既包含语言内容又去除了发言人身份和声学细节，适用于TTS、VC和ASR等任务。 |
| [^85] | [Quantum-Noise-driven Generative Diffusion Models.](http://arxiv.org/abs/2308.12013) | 该论文提出了三种量子噪声驱动的生成扩散模型，利用了量子特性以克服传统模型的主要计算困难，并建议将量子噪声视为可利用的特性而非问题。 |
| [^86] | [Enhancing Agent Communication and Learning through Action and Language.](http://arxiv.org/abs/2308.10842) | 通过行动和语言相结合的方式，我们引入了一种新型智能体，其能够同时作为教师和学习者，通过行动演示和语言指令增强了沟通效率，并探索了结合行动和语言沟通模式对学习结果的积极影响。 |
| [^87] | [Advancing Beyond Identification: Multi-bit Watermark for Language Models.](http://arxiv.org/abs/2308.00221) | 本研究提出了一种用于语言模型的多位水印技术——COLOR，可在语言模型生成过程中嵌入可追踪的多位信息，实现了提取水印、即时嵌入和维持文本质量等功能，同时允许零位检测。初步实验显示成功在中等长度的文本中嵌入了32位消息，准确率为91.9％。这项研究有效推进了对语言模型滥用的反制策略。 |
| [^88] | [Beyond Scale: the Diversity Coefficient as a Data Quality Metric Demonstrates LLMs are Pre-trained on Formally Diverse Data.](http://arxiv.org/abs/2306.13840) | 本论文提出使用多样性系数作为LLM预训练数据质量的指标，研究表明公开可用的LLM数据集的多样性系数很高。 |
| [^89] | [Range-Restricted Interpolation through Clausal Tableaux.](http://arxiv.org/abs/2306.03572) | 通过Clausal Tableaux证明系统实现可行的范围限制插值算法。 |
| [^90] | [Learning Sampling Dictionaries for Efficient and Generalizable Robot Motion Planning with Transformers.](http://arxiv.org/abs/2306.00851) | 提出了一种名为VQ-MPT的方法，通过学习采样字典和Transformer模型，使机器人运动规划更高效且具有普适性。此方法将规划空间分割为离散集合，并选择性地选择采样区域，以克服现有规划方法的缺点。 |
| [^91] | [Optimized Custom Dataset for Efficient Detection of Underwater Trash.](http://arxiv.org/abs/2305.16460) | 本文提出了一种自定义数据集和有效检测方法，旨在通过增加垃圾实例的多样性，在深入水下环境中提高其检测精度。 |
| [^92] | [GRACE++: Loss-Resilient Real-Time Video through Neural Codecs.](http://arxiv.org/abs/2305.12333) | GRACE++是一个抗丢包的实时视频系统，通过神经视频编解码器实现了在各种丢包情况下保持用户体验质量的目标。 |
| [^93] | [Structural Pruning for Diffusion Models.](http://arxiv.org/abs/2305.10924) | 本文提出了一种名为Diff-Pruning的高效压缩方法，通过一个Taylor展开过程来识别重要权重，从而从预先存在的模型中学习轻量级扩散模型，性能稳定，并在训练效率上显著提高。 |
| [^94] | [Meaningful Causal Aggregation and Paradoxical Confounding.](http://arxiv.org/abs/2304.11625) | 聚合变量上的因果性不确定性可能会使得原本不混淆的因果关系变得混淆，在实际应用中，我们需要接受宏观因果关系通常只与微观状态相关的事实。 |
| [^95] | [LLM+P: Empowering Large Language Models with Optimal Planning Proficiency.](http://arxiv.org/abs/2304.11477) | 本论文引入了LLM+P框架，将经典规划器的优点融入大型语言模型（LLM），通过将语言描述转换为用规划领域定义语言（PDDL）编写的文件来解决计划问题，旨在综合两者的优势，赋能LLMs最优规划能力。 |
| [^96] | [Adaptive Gated Graph Convolutional Network for Explainable Diagnosis of Alzheimer's Disease using EEG Data.](http://arxiv.org/abs/2304.05874) | 本文提出了一种自适应门控图卷积网络(AGGCN)，该网络结合卷积节点特征增强和功能连接度量自适应学习图结构，实现了高精度的阿尔茨海默病诊断，并提供了重要的脑区信息。 |
| [^97] | [TraffNet: Learning Causality of Traffic Generation for Road Network Digital Twins.](http://arxiv.org/abs/2303.15954) | TraffNet是一个学习交通量生成原因的深度学习框架，将车辆轨迹数据表示为异构图，利用递归神经网络结构实现了对交通生成原因的预测。 |
| [^98] | [Sigmoid Loss for Language Image Pre-Training.](http://arxiv.org/abs/2303.15343) | 本论文提出了适用于语言图像预训练的成对Sigmoid损失函数，可以有效地提高训练批量大小，同时不需要全局查看配对相似性进行归一化，其训练出来的模型在ImageNet上表现良好。 |
| [^99] | [Fantasia3D: Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation.](http://arxiv.org/abs/2303.13873) | Fantasia3D是一种新的文本生成3D内容的方法，通过分离几何和外观建模和学习，提高了几何细节和逼真渲染，并更有效和高效。 |
| [^100] | [Replay Buffer With Local Forgetting for Adaptive Deep Model-Based Reinforcement Learning.](http://arxiv.org/abs/2303.08690) | 提出了一种带有局部遗忘的新型重放缓冲区，可以在状态空间的相关部分快速遗忘过时的经验。实验证明该方法提高了自适应深度模型强化学习代理对环境变化的适应能力，加速了学习速度并改善了策略。 |
| [^101] | [Uncertainty-Aware Off-Policy Learning.](http://arxiv.org/abs/2303.06389) | 本文提出了一种不确定性感知的倒数概率分数估计器（UIPS），用于改进离线学习，通过明确模拟估计的记录策略中的不确定性，相对于广泛的最先进基线具有优越的样本效率。 |
| [^102] | [Taming Contrast Maximization for Learning Sequential, Low-latency, Event-based Optical Flow.](http://arxiv.org/abs/2303.05214) | 本文提出了一种用于顺序估计基于事件的光流的自监督学习流程，该流程通过新型的对比度最大化公式训练持续运行的神经模型，以适应非线性和变化统计的输入事件。实验结果表明，该方法在多个数据集上取得了新的技术水平。 |
| [^103] | [Dexterous In-hand Manipulation by Guiding Exploration with Simple Sub-skill Controllers.](http://arxiv.org/abs/2303.03533) | 该论文提出了一种使用简单的子技能控制器引导探索的框架，从而提高了学习手部灵巧操作技能的样本效率。这是第一个在没有使用探索性重置分布的情况下，演示学习难以探索的手指步态手部操作技能。 |
| [^104] | [Memory-augmented Online Video Anomaly Detection.](http://arxiv.org/abs/2302.10719) | 本文提出了一种基于记忆的在线视频异常检测系统，能够在自动驾驶汽车周围的异常情况出现时迅速响应，利用仪表盘摄像头捕获的视频数据，并采用了短期和长期记忆模块来提取相关信息。该系统具有出色的性能和简单直观的架构，并且利用RGB帧进行了端到端训练。 |
| [^105] | [Distillation Policy Optimization.](http://arxiv.org/abs/2302.00533) | 本文展示了一种演员-评论家的学习框架，该框架通过蒸馏优势在利用过去经验的同时遵循稳定的在线策略，实现了快速学习并可以适用于广泛的算法类别。 |
| [^106] | [Noise-aware Learning from Web-crawled Image-Text Data for Image Captioning.](http://arxiv.org/abs/2212.13563) | 提出了一种噪声感知字幕生成框架（NoC），它利用网络爬取的数据学习丰富的知识，同时减少噪声的影响。通过对齐级别可控的字幕生成器，模型能够生成高质量的字幕。 |
| [^107] | [UnICLAM:Contrastive Representation Learning with Adversarial Masking for Unified and Interpretable Medical Vision Question Answering.](http://arxiv.org/abs/2212.10729) | UnICLAM是一种统一和可解释的医学视觉问答模型，通过对比表示学习和对抗性屏蔽，实现了图像和文本之间的对齐和语义表示。 |
| [^108] | [Active Classification of Moving Targets with Learned Control Policies.](http://arxiv.org/abs/2212.03068) | 本文提出了一种使用学习控制策略的方法，通过强化学习训练一种基于注意力的架构来指导无人机选择下一个视点，以收集尽可能多未分类目标的证据，并考虑目标的运动、方向和遮挡情况。该方法不仅提高了分类准确率，还在多目标环境中取得了良好效果。 |
| [^109] | [One-shot Implicit Animatable Avatars with Model-based Priors.](http://arxiv.org/abs/2212.02469) | 本文提出了ELICIT，一种从单张图片学习人类特定神经辐射场的方法，同时利用3D几何先验和视觉语义先验实现了一次性数据高效的逼真可动3D人体的创建。 |
| [^110] | [Vertical Federated Learning: Concepts, Advances and Challenges.](http://arxiv.org/abs/2211.12814) | 垂直联合学习（VFL）是一种联合学习设置，多个具有关于同一组用户不同特征的参与方共同训练机器学习模型，而不公开原始数据或模型参数。本文提供了对VFL概念、算法以及各个方面的进展和挑战的综合回顾，深入分析了隐私保护协议的分类、隐私攻击和防御策略，并提出了考虑多个约束条件的统一框架VFLow。此外，还回顾了工业应用中的最新进展和VFL面临的未来挑战和方向。 |
| [^111] | [GeONet: a neural operator for learning the Wasserstein geodesic.](http://arxiv.org/abs/2209.14440) | GeONet是一个不受网格影响的深度神经算子网络，学习了从初始和终端分布到连接两个端点分布的Wasserstein测地的非线性映射。通过学习鞍点优化条件，GeONet可以快速进行实时预测，并在仿真示例和测试数据上取得了与标准OT求解器相当的准确性。 |
| [^112] | [Discovering and Exploiting Sparse Rewards in a Learned Behavior Space.](http://arxiv.org/abs/2111.01919) | 这项研究介绍了一种名为STAX的算法，能够在学习行为空间时实时探索，并且能够有效优化任何发现的奖励。 |
| [^113] | [On Exploiting Hitting Sets for Model Reconciliation.](http://arxiv.org/abs/2012.09274) | 本文提出了一个基于逻辑的模型调和框架，通过利用命中集对偶关系来寻找解释，以解决在人类感知规划中对代理计划最优性进行解释的问题。 |
| [^114] | [MimicNorm: Weight Mean and Last BN Layer Mimic the Dynamic of Batch Normalization.](http://arxiv.org/abs/2010.09278) | 本文提出了一种名为MimicNorm的归一化方法，通过简化批归一化（BN）的正则化方法并保持其核心影响，即数据去相关性和自适应学习率，来提高网络训练的收敛性和效率。MimicNorm仅包含两个轻量级操作，可与BN相媲美。 |

# 详细

[^1]: SHACIRA: 可扩展的哈希网格压缩技术用于隐式神经表示

    SHACIRA: Scalable HAsh-grid Compression for Implicit Neural Representations. (arXiv:2309.15848v1 [cs.CV])

    [http://arxiv.org/abs/2309.15848](http://arxiv.org/abs/2309.15848)

    SHACIRA提出了一种简单但有效的通用框架，用于对神经表示中的特征网格进行高水平压缩，通过量化潜在权重和应用熵正则化来实现压缩。这种方法在多样化数据集上取得了定量和定性上的好结果。

    

    隐式神经表示（INR）或神经场已成为编码多媒体信号（如图像和辐射场）并保持高质量的流行框架。最近，由Instant-NGP提出的可学习特征网格在训练和采样INR方面提供了显著的加速，它通过用一个多分辨率查找表的特征向量和一个更小的神经网络来替代一个大型神经网络。然而，这些特征网格的内存消耗很大，这可能成为存储和流媒体应用的瓶颈。本研究提出了SHACIRA，一种简单但有效的通用框架，用于对这些特征网格进行压缩，而无需额外的后处理修剪/量化阶段。我们使用量化的潜在权重对特征网格重新参数化，并在潜在空间应用熵正则化，以实现在不同领域间的高水平压缩。对多样化数据集的定量和定性结果验证了我们的方法。

    Implicit Neural Representations (INR) or neural fields have emerged as a popular framework to encode multimedia signals such as images and radiance fields while retaining high-quality. Recently, learnable feature grids proposed by Instant-NGP have allowed significant speed-up in the training as well as the sampling of INRs by replacing a large neural network with a multi-resolution look-up table of feature vectors and a much smaller neural network. However, these feature grids come at the expense of large memory consumption which can be a bottleneck for storage and streaming applications. In this work, we propose SHACIRA, a simple yet effective task-agnostic framework for compressing such feature grids with no additional post-hoc pruning/quantization stages. We reparameterize feature grids with quantized latent weights and apply entropy regularization in the latent space to achieve high levels of compression across various domains. Quantitative and qualitative results on diverse datase
    
[^2]: 虚假信息检测：在LLM时代面临的持续挑战

    Disinformation Detection: An Evolving Challenge in the Age of LLMs. (arXiv:2309.15847v1 [cs.CL])

    [http://arxiv.org/abs/2309.15847](http://arxiv.org/abs/2309.15847)

    这项研究探讨了生成型大型语言模型（LLM）所带来的虚假信息传播问题以及如何对抗这一威胁。研究旨在回答三个问题：目前虚假信息检测技术对LLM生成的虚假信息是否可靠？如果传统技术无效，LLM是否能作为一个强大的防御手段？如果前两种策略失败，可以提出什么新的方法来对抗这一威胁？

    

    生成型大型语言模型（LLM）的出现，如ChatGPT，在多个领域催生了变革性的进展。然而，随着这些进展的同时，它们也引入了潜在的威胁。其中一个关键问题是滥用LLM生成虚假信息的传播者，利用这些模型生成高度有说服力但具有误导性的内容，挑战虚假信息检测系统。此项工作旨在通过回答三个研究问题来解决这个问题：（1）现有的虚假信息检测技术能够可靠地检测LLM生成的虚假信息的程度是多少？ （2）如果传统技术证明效果较差，LLM本身是否可以被利用作为对抗先进虚假信息的强大防御？ （3）如果这两种策略都失效，可以提出什么新的方法来有效应对这个日益严重的威胁？对于虚假信息的形成和检测进行了整体探索来推动这一行

    The advent of generative Large Language Models (LLMs) such as ChatGPT has catalyzed transformative advancements across multiple domains. However, alongside these advancements, they have also introduced potential threats. One critical concern is the misuse of LLMs by disinformation spreaders, leveraging these models to generate highly persuasive yet misleading content that challenges the disinformation detection system. This work aims to address this issue by answering three research questions: (1) To what extent can the current disinformation detection technique reliably detect LLM-generated disinformation? (2) If traditional techniques prove less effective, can LLMs themself be exploited to serve as a robust defense against advanced disinformation? and, (3) Should both these strategies falter, what novel approaches can be proposed to counter this burgeoning threat effectively? A holistic exploration for the formation and detection of disinformation is conducted to foster this line of 
    
[^3]: 如何捕捉AI谎言：通过问无关问题在黑盒LLMs中进行谎言检测

    How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions. (arXiv:2309.15840v1 [cs.CL])

    [http://arxiv.org/abs/2309.15840](http://arxiv.org/abs/2309.15840)

    本文提出了一个简单但高精确度的谎言检测器，通过在怀疑有谎言的情况下问一组无关的后续问题，并将LLM的是/否答案输入到一个逻辑回归分类器中，该检测器能够推广到不同的LLM架构和实际场景中的谎言情况。

    

    大型语言模型（LLMs）会“说谎”，也就是在明知道真相的情况下输出虚假陈述。当指示输出错误信息时，LLMs可能会“说谎”。在这里，我们开发了一个简单的谎言检测器，既不需要访问LLM的激活（黑盒），也不需要事实问题的真相知识。这个检测器通过在怀疑有谎言的情况下问一组预定义的无关后续问题，并将LLM的是/否答案输入到逻辑回归分类器中来工作。尽管简单，这个谎言检测器非常准确并且令人惊讶地通用。当在单一情境的示例上进行训练 - 促使GPT-3.5在事实问题上撒谎 - 该检测器可以推广到以下情况：（1）其他LLM架构，（2）细调为说谎的LLMs，（3）谄媚的谎言，和（4）出现在实际场景中的谎言，比如销售。这些结果表明，LLMs具有特殊的与谎言相关的行为模式。

    Large language models (LLMs) can "lie", which we define as outputting false statements despite "knowing" the truth in a demonstrable sense. LLMs might "lie", for example, when instructed to output misinformation. Here, we develop a simple lie detector that requires neither access to the LLM's activations (black-box) nor ground-truth knowledge of the fact in question. The detector works by asking a predefined set of unrelated follow-up questions after a suspected lie, and feeding the LLM's yes/no answers into a logistic regression classifier. Despite its simplicity, this lie detector is highly accurate and surprisingly general. When trained on examples from a single setting -prompting GPT-3.5 to lie about factual questions -- the detector generalises out-of-distribution to (1) other LLM architectures, (2) LLMs fine-tuned to lie, (3) sycophantic lies, and (4) lies emerging in real-life scenarios such as sales. These results indicate that LLMs have distinctive lie-related behavioural pa
    
[^4]: 检视儿童在AI问题构思中体现的价值观

    Examining the Values Reflected by Children during AI Problem Formulation. (arXiv:2309.15839v1 [cs.HC])

    [http://arxiv.org/abs/2309.15839](http://arxiv.org/abs/2309.15839)

    研究通过观察儿童在AI问题构思中的活动，揭示了儿童如何向自己设计的AI系统中融入价值观，为日常活动提供支持，包括对高级系统智能的需求和对情感检测的需求。

    

    了解儿童在诸如可教授机器等AI界面设计中的设计过程和价值观，有助于增加这些活动的影响力，并指导未来技术的设计。通过一个改编的故事板设计会话，一个由5名年龄在7-13岁的儿童和成人共同设计者组成的团队，参与了AI问题构思活动，他们想象了自己的可教授机器。我们的研究结果利用了一个已经建立的心理价值框架（Rokeach价值调查）, 揭示了儿童如何在他们自己设计的AI系统中概念化和融入他们的价值观，以支持他们的日常活动。具体来说，我们发现儿童提出的想法需要先进的系统智能，例如情感检测和理解用户的社交关系。底层模型可以在多种模式下进行训练，通过添加更多数据或预测负面事件来修复任何错误。

    Understanding how children design and what they value in AI interfaces that allow them to explicitly train their models such as teachable machines, could help increase such activities' impact and guide the design of future technologies. In a co-design session using a modified storyboard, a team of 5 children (aged 7-13 years) and adult co-designers, engaged in AI problem formulation activities where they imagine their own teachable machines. Our findings, leveraging an established psychological value framework (the Rokeach Value Survey), illuminate how children conceptualize and embed their values in AI systems that they themselves devise to support their everyday activities. Specifically, we find that children's proposed ideas require advanced system intelligence, e.g. emotion detection and understanding the social relationships of a user. The underlying models could be trained under multiple modalities and any errors would be fixed by adding more data or by anticipating negative exam
    
[^5]: OrthoPlanes: 一种改进 GANs 三维感知能力的新型表示方法

    OrthoPlanes: A Novel Representation for Better 3D-Awareness of GANs. (arXiv:2309.15830v1 [cs.CV])

    [http://arxiv.org/abs/2309.15830](http://arxiv.org/abs/2309.15830)

    本论文提出了一种新的表示方法OrthoPlanes，通过在特征图中编码细粒度的3D信息来生成真实且视图一致的图像。与以前的方法相比，OrthoPlanes具有更好的可扩展性和表达能力，可以处理更具挑战性的视角和合成具有高度空间自由度的关节对象。实验证明，该方法在FFHQ和SHHQ数据集上取得了最先进的结果。

    

    我们提出了一种新的方法，用于从2D图像集合中生成具有精细几何结构的真实且视图一致的图像。我们的方法提出了一种混合的显式-隐式表示，称为OrthoPlanes，它在特征图中编码了细粒度的3D信息，可以通过修改2D StyleGANs高效生成。与以前的表示方法相比，我们的方法在可扩展性和表达能力方面具有更好的性能，并提供了清晰明确的信息。因此，我们的方法能够处理更具挑战性的视角，并合成具有高度空间自由度的关节对象。实验证明，我们的方法在FFHQ和SHHQ数据集上在定量和定性方面都取得了最先进的结果。

    We present a new method for generating realistic and view-consistent images with fine geometry from 2D image collections. Our method proposes a hybrid explicit-implicit representation called \textbf{OrthoPlanes}, which encodes fine-grained 3D information in feature maps that can be efficiently generated by modifying 2D StyleGANs. Compared to previous representations, our method has better scalability and expressiveness with clear and explicit information. As a result, our method can handle more challenging view-angles and synthesize articulated objects with high spatial degree of freedom. Experiments demonstrate that our method achieves state-of-the-art results on FFHQ and SHHQ datasets, both quantitatively and qualitatively. Project page: \url{https://orthoplanes.github.io/}.
    
[^6]: 使用LM模拟沙盒识别LM代理的风险

    Identifying the Risks of LM Agents with an LM-Emulated Sandbox. (arXiv:2309.15817v1 [cs.AI])

    [http://arxiv.org/abs/2309.15817](http://arxiv.org/abs/2309.15817)

    通过使用LM模拟工具执行和开发基于LM的自动安全评估器，该论文提出了一种解决测试LM代理的高成本和寻找高风险问题的方法。

    

    最近的语言模型（LM）代理和工具使用的技术进步，例如ChatGPT插件，使得代理具备了丰富的功能，但也放大了潜在的风险，如泄露私人数据或引发财务损失。识别这些风险是一项耗时的工作，需要实施工具，手动设置每个测试场景的环境，并找到风险案例。随着工具和代理变得越来越复杂，测试这些代理的高成本将使寻找高风险、长尾风险变得越来越困难。为了解决这些挑战，我们引入了ToolEmu：一个使用LM来模拟工具执行的框架，可以在不需要手动实例化的情况下对LM代理进行各种工具和场景的测试。除了模拟器，我们还开发了一个基于LM的自动安全评估器，用于检查代理的失败并量化相关风险。我们通过人工评估测试了工具模拟器和评估器，并发现了6个...

    Recent advances in Language Model (LM) agents and tool use, exemplified by applications like ChatGPT Plugins, enable a rich set of capabilities but also amplify potential risks - such as leaking private data or causing financial losses. Identifying these risks is labor-intensive, necessitating implementing the tools, manually setting up the environment for each test scenario, and finding risky cases. As tools and agents become more complex, the high cost of testing these agents will make it increasingly difficult to find high-stakes, long-tailed risks. To address these challenges, we introduce ToolEmu: a framework that uses an LM to emulate tool execution and enables the testing of LM agents against a diverse range of tools and scenarios, without manual instantiation. Alongside the emulator, we develop an LM-based automatic safety evaluator that examines agent failures and quantifies associated risks. We test both the tool emulator and evaluator through human evaluation and find that 6
    
[^7]: Lyra: 自动定理证明中的双重修正策略的编排

    Lyra: Orchestrating Dual Correction in Automated Theorem Proving. (arXiv:2309.15806v1 [cs.CL])

    [http://arxiv.org/abs/2309.15806](http://arxiv.org/abs/2309.15806)

    Lyra是一种新的框架，通过引入工具修正和猜想修正两种机制，增强了大规模语言模型在形式化定理证明领域的有效性，减轻了幻觉，并提高了证明的准确性。

    

    大规模语言模型（LLMs）为形式化定理证明领域提供了一个有趣的探索途径。然而，它们的全部潜力，尤其是关于幻觉的减轻和通过证明器错误消息的细化，仍然是一个尚未深入研究的领域。为了增强LLMs在该领域的有效性，我们引入了Lyra，一种采用两种不同修正机制的新框架：工具修正（TC）和猜想修正（CC）。为了在形式证明的后处理中实现工具修正，我们利用先前的知识来利用预定义的证明工具（如Sledgehammer）来指导替换不正确的工具。工具修正显著减轻了幻觉，从而提高了证明的整体准确性。此外，我们引入了猜想修正，一种错误反馈机制，旨在与证明器互动，通过证明器的错误消息进一步完善形式证明的猜想。

    Large Language Models (LLMs) present an intriguing avenue for exploration in the field of formal theorem proving. Nevertheless, their full potential, particularly concerning the mitigation of hallucinations and refinement through prover error messages, remains an area that has yet to be thoroughly investigated. To enhance the effectiveness of LLMs in the field, we introduce the Lyra, a new framework that employs two distinct correction mechanisms: Tool Correction (TC) and Conjecture Correction (CC). To implement Tool Correction in the post-processing of formal proofs, we leverage prior knowledge to utilize predefined prover tools (e.g., Sledgehammer) for guiding the replacement of incorrect tools. Tool Correction significantly contributes to mitigating hallucinations, thereby improving the overall accuracy of the proof. In addition, we introduce Conjecture Correction, an error feedback mechanism designed to interact with prover to refine formal proof conjectures with prover error messa
    
[^8]: ANNCRIPS:癌症研究中的人工神经网络在预测和生存中的应用

    ANNCRIPS: Artificial Neural Networks for Cancer Research In Prediction & Survival. (arXiv:2309.15803v1 [cs.LG])

    [http://arxiv.org/abs/2309.15803](http://arxiv.org/abs/2309.15803)

    本研究通过开发和验证一种智能数学模型，利用人工神经网络提高前列腺癌的早期检测，降低假阳性率，改善患者预后。预计该模型经过进一步改进和验证后，可以成为一个可靠的、市场化的前列腺癌检测解决方案。

    

    前列腺癌是50岁及以上男性中常见的恶性肿瘤。目前的诊断方法主要依靠血液测试、前列腺特异性抗原(PSA)水平和直肠指检(DRE)。然而，这些方法存在显著的假阳性率。该研究关注开发和验证一种利用人工神经网络(ANNs)的智能数学模型，以提高前列腺癌的早期检测。本研究的主要目标是展示一种设计用于帮助早期发现前列腺癌、促进医疗专业人员及时干预的新型数学模型。该模型的实施展示了降低假阳性发生率、改善患者预后的潜力。此外，我们预见在进一步改进、广泛测试和验证的情况下，该模型可以成为一个可靠的、市场化的前列腺癌检测解决方案。

    Prostate cancer is a prevalent malignancy among men aged 50 and older. Current diagnostic methods primarily rely on blood tests, PSA:Prostate-Specific Antigen levels, and Digital Rectal Examinations (DRE). However, these methods suffer from a significant rate of false positive results. This study focuses on the development and validation of an intelligent mathematical model utilizing Artificial Neural Networks (ANNs) to enhance the early detection of prostate cancer. The primary objective of this research paper is to present a novel mathematical model designed to aid in the early detection of prostate cancer, facilitating prompt intervention by healthcare professionals. The model's implementation demonstrates promising potential in reducing the incidence of false positives, thereby improving patient outcomes. Furthermore, we envision that, with further refinement, extensive testing, and validation, this model can evolve into a robust, marketable solution for prostate cancer detection. 
    
[^9]: 软件工程中的人工智能：案例研究与展望

    AI in Software Engineering: Case Studies and Prospects. (arXiv:2309.15768v1 [cs.SE])

    [http://arxiv.org/abs/2309.15768](http://arxiv.org/abs/2309.15768)

    本文分析了IBM Watson和Google AlphaGo两个案例研究，并得出结论：在软件系统中使用深度学习和机器学习等AI技术有助于实现智能化系统。

    

    人工智能（AI）和软件工程（SE）是计算机科学中的重要领域。近年来，研究人员试图在软件开发的各个阶段应用AI技术，以提高软件产品的整体质量。此外，也有一些研究人员关注SE和AI的交集。事实上，SE和AI之间的关系非常微弱；然而，一种领域中的方法和技术已经在另一种领域中被采用。越来越多的软件产品能够像人类一样具有智能行为。本文分析、评估和比较了使用不同AI技术解决现实世界挑战性问题的两个案例研究，即IBM Watson和Google AlphaGo。基于对两个案例研究的分析，使用诸如深度学习和机器学习的AI技术在软件系统中有助于智能化系统。Watson采用“决策支持”策略来帮助人

    Artificial intelligence (AI) and software engineering (SE) are two important areas in computer science. In recent years, researchers are trying to apply AI techniques in various stages of software development to improve the overall quality of software products. Moreover, there are also some researchers focus on the intersection between SE and AI. In fact, the relationship between SE and AI is very weak; however, methods and techniques in one area have been adopted in another area. More and more software products are capable of performing intelligent behaviour like human beings. In this paper, two cases studies which are IBM Watson and Google AlphaGo that use different AI techniques in solving real world challenging problems have been analysed, evaluated and compared. Based on the analysis of both case studies, using AI techniques such as deep learning and machine learning in software systems contributes to intelligent systems. Watson adopts 'decision making support' strategy to help hu
    
[^10]: 基于潜在图的生物医学表格数据半监督学习

    Latent Graph Powered Semi-Supervised Learning on Biomedical Tabular Data. (arXiv:2309.15757v1 [cs.LG])

    [http://arxiv.org/abs/2309.15757](http://arxiv.org/abs/2309.15757)

    本文提出了一种基于潜在图的半监督学习方法，通过利用图的表示来捕捉数据之间的关系，并实现了全局和局部知识的有效融合。在生物医学数据集上的评估中，我们的方法表现出了最先进的结果。

    

    在半监督学习领域中，现有方法未充分利用（有）标记数据之间的实例间关系的潜力。本文通过提供一种推断捕捉内在数据关系的潜在图的方法来解决这个限制。通过利用基于图的表示，我们的方法促进了信息在整个图中的无缝传播，能够有效地融合全局和局部知识。通过在生物医学表格数据集上的评估，我们比较了我们的方法与其他当代方法的能力。我们的工作证明了发现实例间关系作为构建强化半监督学习技术的鲁棒潜在图的实际手段的重要性。我们的方法在三个生物医学数据集上取得了最先进的结果。

    In the domain of semi-supervised learning, the current approaches insufficiently exploit the potential of considering inter-instance relationships among (un)labeled data. In this work, we address this limitation by providing an approach for inferring latent graphs that capture the intrinsic data relationships. By leveraging graph-based representations, our approach facilitates the seamless propagation of information throughout the graph, enabling the effective incorporation of global and local knowledge. Through evaluations on biomedical tabular datasets, we compare the capabilities of our approach to other contemporary methods. Our work demonstrates the significance of inter-instance relationship discovery as practical means for constructing robust latent graphs to enhance semi-supervised learning techniques. Our method achieves state-of-the-art results on three biomedical datasets.
    
[^11]: 体验和证据是出色摘要机器人的眼睛！朝着知识融入的多模态临床对话摘要化。

    Experience and Evidence are the eyes of an excellent summarizer! Towards Knowledge Infused Multi-modal Clinical Conversation Summarization. (arXiv:2309.15739v1 [cs.CL])

    [http://arxiv.org/abs/2309.15739](http://arxiv.org/abs/2309.15739)

    本文提出了一种利用知识融入的多模态多任务框架，用于生成临床对话的摘要。通过适配器注入知识和视觉特征，并采用门控机制统一融合的特征向量。实验证明了该方法的重要性。

    

    随着远程医疗的发展，研究人员和医疗从业者正共同努力开发各种技术来自动化各种医疗操作，如诊断报告生成。本文首先提出了一种多模态临床对话摘要生成任务，它根据临床医生和患者的交互（文本和视觉信息）生成对话的简洁概述。我们提出了一种融入知识的多模态多任务医学领域识别和临床对话摘要生成（MM-CliConSummation）框架。它利用适配器来注入知识和视觉特征，并使用门控机制统一融合的特征向量。此外，我们还开发了一个带有意图、症状和摘要注释的多模态多意图临床对话摘要语料库。通过大量定量和定性实验，得出以下发现：(a)关键的重要性

    With the advancement of telemedicine, both researchers and medical practitioners are working hand-in-hand to develop various techniques to automate various medical operations, such as diagnosis report generation. In this paper, we first present a multi-modal clinical conversation summary generation task that takes a clinician-patient interaction (both textual and visual information) and generates a succinct synopsis of the conversation. We propose a knowledge-infused, multi-modal, multi-tasking medical domain identification and clinical conversation summary generation (MM-CliConSummation) framework. It leverages an adapter to infuse knowledge and visual features and unify the fused feature vector using a gated mechanism. Furthermore, we developed a multi-modal, multi-intent clinical conversation summarization corpus annotated with intent, symptom, and summary. The extensive set of experiments, both quantitatively and qualitatively, led to the following findings: (a) critical significan
    
[^12]: MindGPT：利用非侵入性脑记录解读所见图像

    MindGPT: Interpreting What You See with Non-invasive Brain Recordings. (arXiv:2309.15729v1 [cs.CV])

    [http://arxiv.org/abs/2309.15729](http://arxiv.org/abs/2309.15729)

    这篇论文介绍了一种非侵入性神经解码器MindGPT，它能够从脑信号中解析所见的视觉刺激并转化为自然语言表达。

    

    利用非侵入性脑记录解读所见的视觉内容具有重要的科学和实践价值。已经做出了努力来从脑信号中恢复所见图像。然而，由于图像质量不足或语义不匹配，大多数现有方法无法真实反映视觉内容。与重建像素级视觉图像相比，讲话是一种更高效、更有效的解释视觉信息的方式。在这里，我们介绍了一种名为MindGPT的非侵入性神经解码器，它将感知到的视觉刺激解释为自然语言，通过fMRI信号。具体而言，我们的模型基于一个带有交叉注意机制的视觉引导神经编码器，通过协同使用大型语言模型GPT，可以以端到端的方式将潜在的神经表示引导到所需的语言语义方向。通过这样做，我们发现MindGPT的神经表示是可解释的，可以用于

    Decoding of seen visual contents with non-invasive brain recordings has important scientific and practical values. Efforts have been made to recover the seen images from brain signals. However, most existing approaches cannot faithfully reflect the visual contents due to insufficient image quality or semantic mismatches. Compared with reconstructing pixel-level visual images, speaking is a more efficient and effective way to explain visual information. Here we introduce a non-invasive neural decoder, termed as MindGPT, which interprets perceived visual stimuli into natural languages from fMRI signals. Specifically, our model builds upon a visually guided neural encoder with a cross-attention mechanism, which permits us to guide latent neural representations towards a desired language semantic direction in an end-to-end manner by the collaborative use of the large language model GPT. By doing so, we found that the neural representations of the MindGPT are explainable, which can be used 
    
[^13]: 我们目前处于哪个阶段？从人工智能协作的角度理解数据叙事工具

    Where Are We So Far? Understanding Data Storytelling Tools from the Perspective of Human-AI Collaboration. (arXiv:2309.15723v1 [cs.HC])

    [http://arxiv.org/abs/2309.15723](http://arxiv.org/abs/2309.15723)

    本文通过研究现有数据叙事工具，从人工智能协作的角度出发，总结了关于不同阶段和角色的共同协作模式，以促进人类和人工智能的优势并减少不足。

    

    数据叙事在传达数据洞察力方面非常强大，但它需要人类创作者具备多样化的技能和相当大的工作量。最近的研究广泛探讨了人工智能支持和增强人类在数据叙事中的作用潜力。然而，缺乏一个系统性的综述来理解从人工智能协作的角度来看数据叙事工具，这阻碍了研究人员对现有的协作工具设计的思考，以促进人类和人工智能的优势并减少他们的不足。本文采用一个框架来研究现有工具，从两个角度来看：其服务于叙事工作流程的阶段，包括分析、规划、实施和沟通；以及在每个阶段人类和人工智能的角色，如创作者、助手、优化器和评审员。通过我们的分析，我们认识到现有工具中的共同协作模式，并总结了从这些模式中得到的经验教训。

    Data storytelling is powerful for communicating data insights, but it requires diverse skills and considerable effort from human creators. Recent research has widely explored the potential for artificial intelligence (AI) to support and augment humans in data storytelling. However, there lacks a systematic review to understand data storytelling tools from the perspective of human-AI collaboration, which hinders researchers from reflecting on the existing collaborative tool designs that promote humans' and AI's advantages and mitigate their shortcomings. This paper investigated existing tools with a framework from two perspectives: the stages in the storytelling workflow where a tool serves, including analysis, planning, implementation, and communication, and the roles of humans and AI in each stage, such as creators, assistants, optimizers, and reviewers. Through our analysis, we recognize the common collaboration patterns in existing tools, summarize lessons learned from these pattern
    
[^14]: Model Share AI: 一个集成的Python工具包，用于协作式机器学习模型开发、来源追踪和部署

    Model Share AI: An Integrated Toolkit for Collaborative Machine Learning Model Development, Provenance Tracking, and Deployment in Python. (arXiv:2309.15719v1 [cs.SE])

    [http://arxiv.org/abs/2309.15719](http://arxiv.org/abs/2309.15719)

    Model Share AI是一个用于协作式机器学习模型开发、来源追踪和部署的集成工具包，提供了协作项目空间、标准化的模型评估流程和自动化的模型部署功能。

    

    机器学习（ML）有潜力彻底改变许多研究领域和行业，但许多ML项目从概念验证阶段就无法进一步发展。为了解决这个问题，我们引入了Model Share AI（AIMS），这是一个易于使用的MLOps平台，旨在简化协作模型开发、模型来源追踪和模型部署，以及一系列其他功能，以最大化ML研究的实际影响。AIMS具有协作项目空间和标准化的模型评估流程，根据模型在未见过的评估数据上的表现对模型提交进行排名，实现了协作模型开发和众包。自动捕获模型性能和各种模型元数据，以促进来源追踪并允许用户学习和借鉴之前的提交。此外，AIMS允许用户将在Scikit-Learn、TensorFlow Keras、PyTorch和ONNX中构建的ML模型部署到实时的REST API和au

    Machine learning (ML) has the potential to revolutionize a wide range of research areas and industries, but many ML projects never progress past the proof-of-concept stage. To address this issue, we introduce Model Share AI (AIMS), an easy-to-use MLOps platform designed to streamline collaborative model development, model provenance tracking, and model deployment, as well as a host of other functions aiming to maximize the real-world impact of ML research. AIMS features collaborative project spaces and a standardized model evaluation process that ranks model submissions based on their performance on unseen evaluation data, enabling collaborative model development and crowd-sourcing. Model performance and various model metadata are automatically captured to facilitate provenance tracking and allow users to learn from and build on previous submissions. Additionally, AIMS allows users to deploy ML models built in Scikit-Learn, TensorFlow Keras, PyTorch, and ONNX into live REST APIs and au
    
[^15]: ChatGPT-BCI：使用GPT、EEG和眼动生物标记器在语义推理阅读理解中进行单词级神经状态分类

    ChatGPT-BCI: Word-Level Neural State Classification Using GPT, EEG, and Eye-Tracking Biomarkers in Semantic Inference Reading Comprehension. (arXiv:2309.15714v1 [cs.CL])

    [http://arxiv.org/abs/2309.15714](http://arxiv.org/abs/2309.15714)

    本研究通过联合分析大型语言模型（LLMs）、眼动和脑电图（EEG）数据，研究了大脑在阅读过程中处理与关键字相关度不同的单词的神经状态，并提供了关于语义推理阅读理解中神经状态的洞察。

    

    随着大型语言模型（LLM）（如GPT）的迅猛发展，人类和机器理解语义语言意义的能力已经进入了一个新阶段。这需要跨认知科学和自然语言处理（NLP）领域的跨学科研究。本文的目标是通过联合分析LLMs、眼动和脑电图（EEG）数据，研究大脑在阅读过程中如何处理与关键字相关程度不同的单词，从而提供关于个体神经状态在语义关系阅读理解任务中的洞察。我们还使用特征工程方法改进了与关键字高相关度和低相关度的单词阅读过程中与注视相关的EEG数据的分类。在12名受试者中，此单词级别分类的最佳验证准确率超过了60％。

    With the recent explosion of large language models (LLMs), such as Generative Pretrained Transformers (GPT), the need to understand the ability of humans and machines to comprehend semantic language meaning has entered a new phase. This requires interdisciplinary research that bridges the fields of cognitive science and natural language processing (NLP). This pilot study aims to provide insights into individuals' neural states during a semantic relation reading-comprehension task. We propose jointly analyzing LLMs, eye-gaze, and electroencephalographic (EEG) data to study how the brain processes words with varying degrees of relevance to a keyword during reading. We also use a feature engineering approach to improve the fixation-related EEG data classification while participants read words with high versus low relevance to the keyword. The best validation accuracy in this word-level classification is over 60\% across 12 subjects. Words of high relevance to the inference keyword had sig
    
[^16]: HyPoradise：基于大语言模型的生成式语音识别的开放基准线

    HyPoradise: An Open Baseline for Generative Speech Recognition with Large Language Models. (arXiv:2309.15701v1 [cs.CL])

    [http://arxiv.org/abs/2309.15701](http://arxiv.org/abs/2309.15701)

    本文引入了第一个开源基准测试，利用大型语言模型进行自动语音识别错误修正，实现了与人类水平相当的性能，具有重要的实际应用价值。

    

    深度神经网络的进展使得自动语音识别系统在几个公开的干净语音数据集上达到了人类水平。然而，即使是最先进的自动语音识别系统在面对逆境时也会出现性能下降，因为良好训练的声学模型对于语音领域的变异性很敏感，如背景噪声。受到这一观察的启发，我们引入了第一个开源基准测试，利用外部的大型语言模型（LLMs）来进行自动语音识别错误修正，其中N最佳解码假设为真实转录预测提供了有信息量的元素。这种方法与传统的语言模型重评分策略不同，后者只能选择一个候选假设作为最终预测。

    Advancements in deep neural networks have allowed automatic speech recognition (ASR) systems to attain human parity on several publicly available clean speech datasets. However, even state-of-the-art ASR systems experience performance degradation when confronted with adverse conditions, as a well-trained acoustic model is sensitive to variations in the speech domain, e.g., background noise. Intuitively, humans address this issue by relying on their linguistic knowledge: the meaning of ambiguous spoken terms is usually inferred from contextual cues thereby reducing the dependency on the auditory system. Inspired by this observation, we introduce the first open-source benchmark to utilize external large language models (LLMs) for ASR error correction, where N-best decoding hypotheses provide informative elements for true transcription prediction. This approach is a paradigm shift from the traditional language model rescoring strategy that can only select one candidate hypothesis as the o
    
[^17]: 深度模型融合：一项综述

    Deep Model Fusion: A Survey. (arXiv:2309.15698v1 [cs.LG])

    [http://arxiv.org/abs/2309.15698](http://arxiv.org/abs/2309.15698)

    深度模型融合是一种新兴技术，将多个深度学习模型的参数或预测合并到单个模型中，以实现更好的性能。在大规模深度学习模型上面临许多挑战，如高计算成本、高维参数空间、不同异构模型之间的干扰等。本论文为了更好地了解模型融合方法并推动其发展，提出了一项综合调查，总结了最近的进展。

    

    深度模型融合是一种新兴技术，将多个深度学习模型的参数或预测合并到单个模型中。它结合了不同模型的能力，弥补了单个模型的偏差和误差，从而实现更好的性能。然而，在大规模深度学习模型（如LLMs和基础模型）上进行深度模型融合面临着许多挑战，包括高计算成本、高维参数空间、不同异构模型之间的干扰等。尽管模型融合由于其解决复杂实际任务的潜力而受到广泛关注，但对该技术的完整和详细调查研究仍然不足。因此，为了更好地了解模型融合方法并推动其发展，我们提出了一项综合调查，总结了最近的进展。具体而言，我们将现有的深度模型融合方法分为四个类别：（1）"模式连接"，即将多个模型通过连接方式融合。

    Deep model fusion/merging is an emerging technique that merges the parameters or predictions of multiple deep learning models into a single one. It combines the abilities of different models to make up for the biases and errors of a single model to achieve better performance. However, deep model fusion on large-scale deep learning models (e.g., LLMs and foundation models) faces several challenges, including high computational cost, high-dimensional parameter space, interference between different heterogeneous models, etc. Although model fusion has attracted widespread attention due to its potential to solve complex real-world tasks, there is still a lack of complete and detailed survey research on this technique. Accordingly, in order to understand the model fusion method better and promote its development, we present a comprehensive survey to summarize the recent progress. Specifically, we categorize existing deep model fusion methods as four-fold: (1) "Mode connectivity", which conne
    
[^18]: 用大型语言模型进行生成式语音识别错误校正

    Generative Speech Recognition Error Correction with Large Language Models. (arXiv:2309.15649v1 [cs.CL])

    [http://arxiv.org/abs/2309.15649](http://arxiv.org/abs/2309.15649)

    本研究探讨了大型语言模型（LLMs）作为ASR后处理器的能力，通过重新评分和错误校正来提高系统性能。通过使用指令提示和任务激活提示方法，结合上下文学习和微调技术，我们展示了LLMs的泛化能力和有效性。

    

    我们研究了大型语言模型（LLM）作为ASR后处理器的能力，用于重新评分和错误校正。我们的重点是使用指令提示让LLMs执行这些任务而无需微调，我们评估了不同的提示方案，包括零-shot和少-shot的上下文学习，以及一种新颖的任务激活提示（TAP）方法，结合指令和演示。通过在两个领域之外的任务（ATIS和WSJ）上使用预先训练的第一次扫描系统和重新评分输出，我们证明仅通过冻结LLMs的上下文学习进行重新评分可以达到与领域调优的LMs重新评分相竞争的结果。通过将提示技术与微调相结合，我们实现了低于N-best Oracle水平的错误率，展示了LLMs的泛化能力。

    We explore the ability of large language models (LLMs) to act as ASR post-processors that perform rescoring and error correction. Our focus is on instruction prompting to let LLMs perform these task without fine-tuning, for which we evaluate different prompting schemes, both zero- and few-shot in-context learning, and a novel task-activating prompting (TAP) method that combines instruction and demonstration. Using a pre-trained first-pass system and rescoring output on two out-of-domain tasks (ATIS and WSJ), we show that rescoring only by in-context learning with frozen LLMs achieves results that are competitive with rescoring by domain-tuned LMs. By combining prompting techniques with fine-tuning we achieve error rates below the N-best oracle level, showcasing the generalization power of the LLMs.
    
[^19]: 用长短期记忆和时间序列模型进行算法投资策略对冲的对冲特性

    Hedging Properties of Algorithmic Investment Strategies using Long Short-Term Memory and Time Series models for Equity Indices. (arXiv:2309.15640v1 [q-fin.PM])

    [http://arxiv.org/abs/2309.15640](http://arxiv.org/abs/2309.15640)

    本文提出了一种使用长短期记忆和时间序列模型构建算法投资策略的对冲方法，并通过利用不同类型的投资策略来对冲风险资产组合。实证结果显示，该方法在金融市场的动荡时期具有多样化的潜力。

    

    本文提出了一种在金融市场受金融动荡影响时对冲风险资产组合的新方法。我们引入了一种全新的多元算法投资策略（AIS）的分散化方法，该方法不是在单个资产的级别上进行，而是在基于这些资产的价格的级别上进行。我们采用四种不同的理论模型（LSTM - 长短期记忆、ARIMA-GARCH - 自回归移动平均 - 广义自回归条件异方差、动量和反向交易）来生成价格预测，然后利用这些预测产生单个和复合的AIS的投资信号。通过这种方式，我们能够验证由各种资产（能源商品、贵金属、加密货币或软商品）组成的不同类型的投资策略在对冲用于股票指数（S&P 500指数）的组合AIS中的多样化潜力。

    This paper proposes a novel approach to hedging portfolios of risky assets when financial markets are affected by financial turmoils. We introduce a completely novel approach to diversification activity not on the level of single assets but on the level of ensemble algorithmic investment strategies (AIS) built based on the prices of these assets. We employ four types of diverse theoretical models (LSTM - Long Short-Term Memory, ARIMA-GARCH Autoregressive Integrated Moving Average - Generalized Autoregressive Conditional Heteroskedasticity, momentum, and contrarian) to generate price forecasts, which are then used to produce investment signals in single and complex AIS. In such a way, we are able to verify the diversification potential of different types of investment strategies consisting of various assets (energy commodities, precious metals, cryptocurrencies, or soft commodities) in hedging ensemble AIS built for equity indices (S&P 500 index). Empirical data used in this study cov
    
[^20]: 人形机器人的感知

    Perception for Humanoid Robots. (arXiv:2309.15616v1 [cs.RO])

    [http://arxiv.org/abs/2309.15616](http://arxiv.org/abs/2309.15616)

    这项科学研究调查了人形机器人中使用的各种感知模式和技术，并研究了最新的方法来感知和理解内部状态、环境、物体和人类活动。最重要的创新是在内部状态估计中使用贝叶斯滤波方法和最大后验公式的优化技术，并在外部环境理解中利用多传感器融合和机器学习来增强鲁棒性和适应性。

    

    复审目的：在人形机器人领域，感知在使机器人与人类和环境无缝互动方面起着基础性作用，从而提高安全性、效率和用户体验。本科学研究调查了人形机器人中使用的各种感知模式和技术，包括视觉、听觉和触觉感知，通过探索最新的感知和理解内部状态、环境、物体和人类活动的最新方法。最新发现：内部状态估计广泛使用基于贝叶斯滤波方法和基于最大后验公式的优化技术，利用本体感知。在外部环境理解方面，重点是对动态、不可预见的环境变化具有鲁棒性和适应性，本研究中讨论的新一批研究主要集中在多传感器融合和机器学习上。

    Purpose of Review: The field of humanoid robotics, perception plays a fundamental role in enabling robots to interact seamlessly with humans and their surroundings, leading to improved safety, efficiency, and user experience. This scientific study investigates various perception modalities and techniques employed in humanoid robots, including visual, auditory, and tactile sensing by exploring recent state-of-the-art approaches for perceiving and understanding the internal state, the environment, objects, and human activities.  Recent Findings: Internal state estimation makes extensive use of Bayesian filtering methods and optimization techniques based on maximum a-posteriori formulation by utilizing proprioceptive sensing. In the area of external environment understanding, with an emphasis on robustness and adaptability to dynamic, unforeseen environmental changes, the new slew of research discussed in this study have focused largely on multi-sensor fusion and machine learning in contr
    
[^21]: 发展国际多语种会议的自动逐字转录：一种端到端的解决方案

    Developing automatic verbatim transcripts for international multilingual meetings: an end-to-end solution. (arXiv:2309.15609v1 [cs.CL])

    [http://arxiv.org/abs/2309.15609](http://arxiv.org/abs/2309.15609)

    本文提出了一种端到端的解决方案，用于创建全自动的会议记录和多语言翻译，解决了会议管理文档中现有工作流程的替代和改善问题。

    

    本文提出了一种完整的端到端解决方案，用于创建全自动的会议记录和对它们进行多种语言的机器翻译。该工具是在世界知识产权组织（WIPO）开发的、使用其内部开发的语音转文本（S2T）和机器翻译（MT）组件的系统。除了描述数据收集和优化过程，生成高度定制和稳健的系统外，本文还描述了技术组件的架构和演变，并突出了用户方面的商业影响和收益。同时，我们还指出了系统在演进和采用过程中的特殊挑战，并介绍了这种新方法如何创造了一种新产品，并取代了会议管理文档中现有的工作流程。

    This paper presents an end-to-end solution for the creation of fully automated conference meeting transcripts and their machine translations into various languages. This tool has been developed at the World Intellectual Property Organization (WIPO) using in-house developed speech-to-text (S2T) and machine translation (MT) components. Beyond describing data collection and fine-tuning, resulting in a highly customized and robust system, this paper describes the architecture and evolution of the technical components as well as highlights the business impact and benefits from the user side. We also point out particular challenges in the evolution and adoption of the system and how the new approach created a new product and replaced existing established workflows in conference management documentation.
    
[^22]: 对ChatGPT-4在RCC-8中的定性空间推理能力的评估

    An Evaluation of ChatGPT-4's Qualitative Spatial Reasoning Capabilities in RCC-8. (arXiv:2309.15577v1 [cs.AI])

    [http://arxiv.org/abs/2309.15577](http://arxiv.org/abs/2309.15577)

    本文评估了ChatGPT-4在RCC-8中的定性空间推理能力，并探讨了大型语言模型在经典定性空间推理任务中的表现。

    

    定性空间推理（QSR）是常识推理的一个广泛研究领域，并且具有从地理信息系统到机器人和计算机视觉等多种应用。最近，对于大型语言模型（LLMs）的能力提出了许多声称。本文研究了一个特定LLM在RCC-8的经典定性空间推理任务中的表现程度。

    Qualitative Spatial Reasoning (QSR) is well explored area of Commonsense Reasoning and has multiple applications ranging from Geographical Information Systems to Robotics and Computer Vision. Recently many claims have been made for the capabilities of Large Language Models (LLMs). In this paper we investigate the extent to which one particular LLM can perform classical qualitative spatial reasoning tasks on the mereotopological calculus, RCC-8.
    
[^23]: 识别性很重要：揭示无偏学习排名中隐藏的可恢复条件

    Identifiability Matters: Revealing the Hidden Recoverable Condition in Unbiased Learning to Rank. (arXiv:2309.15560v1 [cs.IR])

    [http://arxiv.org/abs/2309.15560](http://arxiv.org/abs/2309.15560)

    研究揭示在无偏学习排名中，当点击数据不能完全拟合时，无法恢复真实相关性，导致排名性能显著降低，提出了可识别性图模型作为解决方案。

    

    无偏学习排名(Unbiased Learning to Rank, ULTR)在从有偏点击日志训练无偏排名模型的现代系统中被广泛应用。关键在于明确地建模用户行为的生成过程，并基于检验假设对点击数据进行拟合。先前的研究经验性地发现只要点击完全拟合，大多数情况下可以恢复出真实潜在相关性。然而，我们证明并非总是能够实现这一点，从而导致排名性能显著降低。在本工作中，我们旨在回答真实相关性是否能够从点击数据恢复出来的问题，这是ULTR领域的一个基本问题。我们首先将一个排名模型定义为可识别的，如果它可以恢复出真实相关性，最多只有一个缩放变换，这对于成对排名目标来说已足够。然后，我们探讨了一个等价的可识别条件，可以新颖地表达为一个图连通性测试问题：当且仅当一个图（即可识别性图）连通时，该排名模型是可识别的。

    The application of Unbiased Learning to Rank (ULTR) is widespread in modern systems for training unbiased ranking models from biased click logs. The key is to explicitly model a generation process for user behavior and fit click data based on examination hypothesis. Previous research found empirically that the true latent relevance can be recovered in most cases as long as the clicks are perfectly fitted. However, we demonstrate that this is not always achievable, resulting in a significant reduction in ranking performance. In this work, we aim to answer if or when the true relevance can be recovered from click data, which is a foundation issue for ULTR field. We first define a ranking model as identifiable if it can recover the true relevance up to a scaling transformation, which is enough for pairwise ranking objective. Then we explore an equivalent condition for identifiability that can be novely expressed as a graph connectivity test problem: if and only if a graph (namely identifi
    
[^24]: 直接模型用于同时翻译和自动字幕生成：FBK在IWSLT2023中的参与

    Direct Models for Simultaneous Translation and Automatic Subtitling: FBK@IWSLT2023. (arXiv:2309.15554v1 [cs.CL])

    [http://arxiv.org/abs/2309.15554](http://arxiv.org/abs/2309.15554)

    本文描述了FBK的研究成果，他们使用直接模型来实现同时翻译和自动字幕生成任务，并在计算感知延迟方面取得了突破性的进展，同时在自动字幕生成任务中也优于现有解决方案。

    

    本文描述了FBK在IWSLT 2023评估活动的同时翻译和自动字幕生成任务中的参与。我们的提交关注于使用直接模型来执行这两个任务：对于同时翻译任务，我们利用已经训练好的离线模型的知识，并直接应用策略来进行实时推理；对于字幕生成任务，我们将直接ST模型调整为生成符合规范的字幕，并利用相同的架构生成与音视频内容同步所需的时间戳。我们的英德SimulST系统在计算感知延迟方面比2021年和2022年的任务中排名靠前的系统有所减少，并获得了高达3.5 BLEU的增益。我们的自动字幕生成系统在英德和英西文对中优于基于直接系统的唯一现有解决方案，分别获得了3.7和1.7的SubER增益。

    This paper describes the FBK's participation in the Simultaneous Translation and Automatic Subtitling tracks of the IWSLT 2023 Evaluation Campaign. Our submission focused on the use of direct architectures to perform both tasks: for the simultaneous one, we leveraged the knowledge already acquired by offline-trained models and directly applied a policy to obtain the real-time inference; for the subtitling one, we adapted the direct ST model to produce well-formed subtitles and exploited the same architecture to produce timestamps needed for the subtitle synchronization with audiovisual content. Our English-German SimulST system shows a reduced computational-aware latency compared to the one achieved by the top-ranked systems in the 2021 and 2022 rounds of the task, with gains of up to 3.5 BLEU. Our automatic subtitling system outperforms the only existing solution based on a direct system by 3.7 and 1.7 SubER in English-German and English-Spanish respectively.
    
[^25]: 使用DeepRepViz来识别基于深度学习模型预测中的混淆因素

    Identifying confounders in deep-learning-based model predictions using DeepRepViz. (arXiv:2309.15551v1 [cs.LG])

    [http://arxiv.org/abs/2309.15551](http://arxiv.org/abs/2309.15551)

    这项研究提出了DeepRepViz框架，用于帮助研究人员在深度学习模型预测中识别混淆因素，并通过度量和可视化工具来解决这个问题。实验证明使用DeepRepViz与DL模型结合能够带来明显的益处。

    

    越来越多地使用深度学习模型分析神经影像数据，揭示大脑、大脑病理和心理特征的见解。然而，诸如参与者年龄、性别或影像伪影等外部的“混淆因素”变量可能会偏导致模型预测，从而阻碍模型学习相关的脑-表型关系。在本研究中，我们提出了一种名为“DeepRepViz”的解决方案，使研究人员能够系统地检测DL模型预测中的混淆因素。该框架包括(1)度量可能混淆因素的影响程度的指标和(2)允许研究人员定性检查DL模型学习内容的可视化工具。通过在模拟和神经影像数据集上进行实验证明了使用DeepRepViz与DL模型结合的益处。例如，神经影像数据集的实验揭示了性别是DL模型预测中的一个显著混淆因素。

    Deep Learning (DL) models are increasingly used to analyze neuroimaging data and uncover insights about the brain, brain pathologies, and psychological traits. However, extraneous `confounders' variables such as the age of the participants, sex, or imaging artifacts can bias model predictions, preventing the models from learning relevant brain-phenotype relationships. In this study, we provide a solution called the `DeepRepViz' framework that enables researchers to systematically detect confounders in their DL model predictions. The framework consists of (1) a metric that quantifies the effect of potential confounders and (2) a visualization tool that allows researchers to qualitatively inspect what the DL model is learning. By performing experiments on simulated and neuroimaging datasets, we demonstrate the benefits of using DeepRepViz in combination with DL models. For example, experiments on the neuroimaging datasets reveal that sex is a significant confounder in a DL model predicti
    
[^26]: 从LAION-5B到LAION-EO：使用锚定数据集过滤数十亿张图片进行卫星图像提取

    From LAION-5B to LAION-EO: Filtering Billions of Images Using Anchor Datasets for Satellite Image Extraction. (arXiv:2309.15535v1 [cs.CV])

    [http://arxiv.org/abs/2309.15535](http://arxiv.org/abs/2309.15535)

    本文提出了一种基于锚定数据集和进一步过滤的提取方法，用于从大型图像库中提取卫星图像。这导致了发布了一个高分辨率的文本和卫星图像对应的数据集LAION-EO。

    

    大型数据集，如LAION-5B，包含在线共享的各种图像。然而，提取大型图像库的领域特定子集是具有挑战性的。本文提出了一种基于锚定数据集的提取方法，结合进一步的过滤，用于卫星图像领域。这导致了LAION-EO的发布，该数据集是从网络中获取的高（逐像素）分辨率的文本和卫星图像对。本文概述了采集过程以及数据集的一些特点。

    Large datasets, such as LAION-5B, contain a diverse distribution of images shared online. However, extraction of domain-specific subsets of large image corpora is challenging. The extraction approach based on an anchor dataset, combined with further filtering, is proposed here and demonstrated for the domain of satellite imagery. This results in the release of LAION-EO, a dataset sourced from the web containing pairs of text and satellite images in high (pixel-wise) resolution. The paper outlines the acquisition procedure as well as some of the features of the dataset.
    
[^27]: 增强人工智能可复制性的平台的网络安全要求

    Cyber Security Requirements for Platforms Enhancing AI Reproducibility. (arXiv:2309.15525v1 [cs.CR])

    [http://arxiv.org/abs/2309.15525](http://arxiv.org/abs/2309.15525)

    本研究针对人工智能研究领域，提出了一个新的框架来评估人工智能平台的可复制性和网络安全性。经过评估，发现目前流行的可复制性平台中没有一个完全整合了必要的网络安全措施，但Kaggle和Codalab在实施网络安全措施方面表现较好。本研究还根据用户的不同情况提供了相应的建议，强调整合网络安全措施的重要性。

    

    科学研究越来越依赖计算方法，这给确保研究可复制性带来了挑战。本研究聚焦于人工智能领域，并介绍了一个新的从网络安全角度评估人工智能平台可复制性的框架，以解决与人工智能研究相关的安全挑战。利用这个框架，评估了五个流行的人工智能可复制性平台：Floydhub、BEAT、Codalab、Kaggle和OpenML。分析发现，这些平台都没有完全整合必要的网络安全措施，这些措施对于稳健的可复制性至关重要。然而，Kaggle和Codalab在实施涵盖安全性、隐私、易用性和信任等方面的网络安全措施方面表现较好。因此，本研究针对不同的用户情况提供了量身定制的建议，包括个人研究者、小型实验室和大型企业。研究强调整合网络安全措施的重要性。

    Scientific research is increasingly reliant on computational methods, posing challenges for ensuring research reproducibility. This study focuses on the field of artificial intelligence (AI) and introduces a new framework for evaluating AI platforms for reproducibility from a cyber security standpoint to address the security challenges associated with AI research. Using this framework, five popular AI reproducibility platforms; Floydhub, BEAT, Codalab, Kaggle, and OpenML were assessed. The analysis revealed that none of these platforms fully incorporates the necessary cyber security measures essential for robust reproducibility. Kaggle and Codalab, however, performed better in terms of implementing cyber security measures covering aspects like security, privacy, usability, and trust. Consequently, the study provides tailored recommendations for different user scenarios, including individual researchers, small laboratories, and large corporations. It emphasizes the importance of integra
    
[^28]: 鲁棒的内部表示在领域泛化中的应用

    Robust Internal Representations for Domain Generalization. (arXiv:2309.15522v1 [cs.LG])

    [http://arxiv.org/abs/2309.15522](http://arxiv.org/abs/2309.15522)

    本文综合调查了作者利用嵌入空间进行转移学习研究的成果，主要讨论了持续学习和有限标记数据可用性所带来的挑战，为未来领域的进展铺平道路。

    

    本文是我在转移学习中利用嵌入空间进行研究的综合调查。本文主要讨论了持续学习和有限标记数据可用性所带来的固有挑战。通过总结我过去和正在进行中的贡献，本文旨在呈现我研究的整体理解，为未来领域的探索和进展铺平道路。我的研究涉及了转移学习的各种设置，包括少样本学习、零样本学习、持续学习、领域自适应和分布式学习。我希望这个调查提供给那些希望专注于类似研究方向的研究者一个前瞻性的视角。

    This paper which is part of the New Faculty Highlights Invited Speaker Program of AAAI'23, serves as a comprehensive survey of my research in transfer learning by utilizing embedding spaces. The work reviewed in this paper specifically revolves around the inherent challenges associated with continual learning and limited availability of labeled data. By providing an overview of my past and ongoing contributions, this paper aims to present a holistic understanding of my research, paving the way for future explorations and advancements in the field. My research delves into the various settings of transfer learning, including, few-shot learning, zero-shot learning, continual learning, domain adaptation, and distributed learning. I hope this survey provides a forward-looking perspective for researchers who would like to focus on similar research directions.
    
[^29]: Raij\=u: 强化学习指导的后渗透自动化安全评估网络系统

    Raij\=u: Reinforcement Learning-Guided Post-Exploitation for Automating Security Assessment of Network Systems. (arXiv:2309.15518v1 [cs.CR])

    [http://arxiv.org/abs/2309.15518](http://arxiv.org/abs/2309.15518)

    Raij\=u是一种使用强化学习的自动化框架，可以帮助渗透测试员快速实施网络系统的后渗透过程，以评估系统的安全级别。

    

    为了评估网络系统的风险，必须调查攻击者在成功入侵后的行为，这被称为后渗透。尽管有许多高效的工具支持后渗透实施，但没有应用程序能够自动化此过程。这个过程的大部分步骤由深入了解安全的专家完成，被称为渗透测试员或pen-testers。为此，我们的研究提出了Raij\=u框架，一种强化学习（RL）驱动的自动化方法，可帮助pen-testers快速实施网络系统安全评估的后渗透过程。我们实现了两个RL算法，Advantage Actor-Critic（A2C）和Proximal Policy Optimization（PPO），来训练能够进行智能动作的专用代理，这些动作是Metasploit模块，用于自动发起特权升级、收集hashdump和横向移动的攻击。通过利用

    In order to assess the risks of a network system, it is important to investigate the behaviors of attackers after successful exploitation, which is called post-exploitation. Although there are various efficient tools supporting post-exploitation implementation, no application can automate this process. Most of the steps of this process are completed by experts who have profound knowledge of security, known as penetration testers or pen-testers. To this end, our study proposes the Raij\=u framework, a Reinforcement Learning (RL)-driven automation approach that assists pen-testers in quickly implementing the process of post-exploitation for security-level evaluation in network systems. We implement two RL algorithms, Advantage Actor-Critic (A2C) and Proximal Policy Optimization (PPO), to train specialized agents capable of making intelligent actions, which are Metasploit modules to automatically launch attacks of privileges escalation, gathering hashdump, and lateral movement. By leverag
    
[^30]: 残差调度：解决工作车间调度问题的一种新的强化学习方法

    Residual Scheduling: A New Reinforcement Learning Approach to Solving Job Shop Scheduling Problem. (arXiv:2309.15517v1 [cs.AI])

    [http://arxiv.org/abs/2309.15517](http://arxiv.org/abs/2309.15517)

    残差调度是一种新的强化学习方法，用于解决工作车间调度问题。通过移除不相关的机器和作业，该方法能够达到最先进的水平。

    

    工作车间调度问题（JSP）是一种在制造业等行业广泛应用的数学优化问题，而灵活的JSP（FJSP）则是一种常见的变体。由于它们是NP-hard问题，很难在合理时间内找到所有情况的最优解，因此开发高效的启发式算法来解决JSP/FJSP问题变得非常重要。最近，很多构建启发式算法的方法都使用了深度强化学习（DRL）和图神经网络（GNN）。在本文中，我们提出了一种名为残差调度的新方法来解决JSP/FJSP问题。在这种新方法中，我们移除了不相关的机器和作业，例如已完成的机器和作业，以便状态仅包含剩下的（或相关的）机器和作业。我们的实验证明，我们的方法在大多数知名的构建启发式算法中达到了最先进的水平。

    Job-shop scheduling problem (JSP) is a mathematical optimization problem widely used in industries like manufacturing, and flexible JSP (FJSP) is also a common variant. Since they are NP-hard, it is intractable to find the optimal solution for all cases within reasonable times. Thus, it becomes important to develop efficient heuristics to solve JSP/FJSP. A kind of method of solving scheduling problems is construction heuristics, which constructs scheduling solutions via heuristics. Recently, many methods for construction heuristics leverage deep reinforcement learning (DRL) with graph neural networks (GNN). In this paper, we propose a new approach, named residual scheduling, to solving JSP/FJSP. In this new approach, we remove irrelevant machines and jobs such as those finished, such that the states include the remaining (or relevant) machines and jobs only. Our experiments show that our approach reaches state-of-the-art (SOTA) among all known construction heuristics on most well-known
    
[^31]: 教授文本到图像模型进行交流

    Teaching Text-to-Image Models to Communicate. (arXiv:2309.15516v1 [cs.CL])

    [http://arxiv.org/abs/2309.15516](http://arxiv.org/abs/2309.15516)

    本文提出了一种针对对话生成图像的高效方法，通过微调预训练的文本到图像模型，实现在给定对话背景下生成一致逼真的图像。

    

    在文本到图像生成的研究中，各种工作已经得到广泛研究。虽然现有模型在文本到图像生成方面表现良好，但是在直接应用于对话生成图像时存在重大挑战。在本文中，我们首先突出了一个新的问题：对话到图像生成，即在给定对话背景的情况下，模型应该生成一个与指定对话内容一致的逼真图像作为回应。为了解决这个问题，我们提出了一种无需中间转换的高效方法，该方法最大程度地提取对话中包含的语义信息。考虑到对话结构的特点，我们在对话中的每个说话回合之前放置分割标记，以区分不同的发言者。然后，我们对预训练的文本到图像模型进行微调，使其能够根据处理后的对话背景生成图像。经过微调后，我们的方法可以生成与处理后对话环境相一致的图像。

    Various works have been extensively studied in the research of text-to-image generation. Although existing models perform well in text-to-image generation, there are significant challenges when directly employing them to generate images in dialogs. In this paper, we first highlight a new problem: dialog-to-image generation, that is, given the dialog context, the model should generate a realistic image which is consistent with the specified conversation as response. To tackle the problem, we propose an efficient approach for dialog-to-image generation without any intermediate translation, which maximizes the extraction of the semantic information contained in the dialog. Considering the characteristics of dialog structure, we put segment token before each sentence in a turn of a dialog to differentiate different speakers. Then, we fine-tune pre-trained text-to-image models to enable them to generate images conditioning on processed dialog context. After fine-tuning, our approach can con
    
[^32]: 使用最少监督的扩散模型实现高保真度语音合成

    High-Fidelity Speech Synthesis with Minimal Supervision: All Using Diffusion Models. (arXiv:2309.15512v1 [cs.SD])

    [http://arxiv.org/abs/2309.15512](http://arxiv.org/abs/2309.15512)

    提出一种使用最少监督的扩散模型实现高保真度语音合成的方法，通过组合离散语音表示和利用序列到序列任务进行训练，解决了语义表示中的信息冗余和维度爆炸以及离散声学表示中的高频波形失真等问题。该方法中的非自回归框架增强了可控性，而持续时间扩散模型实现了音频的多样化控制。

    

    文字转语音（TTS）方法在语音克隆方面取得了有希望的结果，但需要大量标记的文本-语音对。最小监督的语音合成通过组合两种类型的离散语音表示（语义和声学），并使用两种序列到序列任务，以实现最少监督的训练。然而，现有方法存在语义表示中的信息冗余和维度爆炸，以及离散声学表示中的高频波形失真。自回归框架具有典型的不稳定性和不可控性问题。非自回归框架受到持续预测模型引起的韵律平均化的影响。为了解决这些问题，我们提出了一种最小监督的高保真度语音合成方法，其中所有模块基于扩散模型构建。非自回归框架增强了可控性，而持续时间扩散模型实现了音频的多样化控制。

    Text-to-speech (TTS) methods have shown promising results in voice cloning, but they require a large number of labeled text-speech pairs. Minimally-supervised speech synthesis decouples TTS by combining two types of discrete speech representations(semantic \& acoustic) and using two sequence-to-sequence tasks to enable training with minimal supervision. However, existing methods suffer from information redundancy and dimension explosion in semantic representation, and high-frequency waveform distortion in discrete acoustic representation. Autoregressive frameworks exhibit typical instability and uncontrollability issues. And non-autoregressive frameworks suffer from prosodic averaging caused by duration prediction models. To address these issues, we propose a minimally-supervised high-fidelity speech synthesis method, where all modules are constructed based on the diffusion models. The non-autoregressive framework enhances controllability, and the duration diffusion model enables diver
    
[^33]: 迈向人类化强化学习：通过3D游戏中的自适应行为成本控制深度强化学习中的非自然行为

    Towards Human-Like RL: Taming Non-Naturalistic Behavior in Deep RL via Adaptive Behavioral Costs in 3D Games. (arXiv:2309.15484v1 [cs.AI])

    [http://arxiv.org/abs/2309.15484](http://arxiv.org/abs/2309.15484)

    本文提出了一种名为自适应行为成本强化学习（ABC-RL）的新方法，通过在强化学习中引入行为限制作为成本信号，并动态调整权重，训练出人类化的智能体。这种方法可以处理深度强化学习中出现的非自然行为问题，使智能体在游戏中更像人类，并保持相似的性能。

    

    本文提出一种新的方法，称为自适应行为成本强化学习（ABC-RL），用于训练具有竞争力强人类化智能体。尽管深度强化学习智能体在各种视频游戏中最近实现了超人类的表现，但其中一些不受限制的智能体可能表现出不符合人类行为的动作，例如摇晃和旋转，导致奇特的游戏体验。为了像人类那样行为，并保持相似的表现，ABC-RL在强化学习中增加了行为限制作为成本信号，并动态调整权重。与传统的受限策略优化不同，我们提出了一种新的公式，最小化行为成本，同时约束价值函数。通过利用增广拉格朗日乘子法，我们的方法是拉格朗日调整的近似，处理性能与人类化行为之间的权衡。通过实验

    In this paper, we propose a new approach called Adaptive Behavioral Costs in Reinforcement Learning (ABC-RL) for training a human-like agent with competitive strength. While deep reinforcement learning agents have recently achieved superhuman performance in various video games, some of these unconstrained agents may exhibit actions, such as shaking and spinning, that are not typically observed in human behavior, resulting in peculiar gameplay experiences. To behave like humans and retain similar performance, ABC-RL augments behavioral limitations as cost signals in reinforcement learning with dynamically adjusted weights. Unlike traditional constrained policy optimization, we propose a new formulation that minimizes the behavioral costs subject to a constraint of the value function. By leveraging the augmented Lagrangian, our approach is an approximation of the Lagrangian adjustment, which handles the trade-off between the performance and the human-like behavior. Through experiments co
    
[^34]: 通过跨级别优化实现资源高效的AIoT系统: 一项调查

    Enabling Resource-efficient AIoT System with Cross-level Optimization: A survey. (arXiv:2309.15467v1 [cs.LG])

    [http://arxiv.org/abs/2309.15467](http://arxiv.org/abs/2309.15467)

    该论文调查了资源高效的AIoT系统的跨级别优化，提出了一种算法-系统共同设计的方法，通过优化DL模型和系统调度，改善了运行时资源可用性，推动AIoT性能的进一步提升。

    

    随着智能基础设施的广泛使用和深度学习（DL）的令人瞩目的成功，人工智能物联网（AIoT，AI+IoT）这一新兴领域得到了推动。DL模型资源密集，因此现有研究努力在资源有限的基础设施上实现AIoT实时推理和低成本训练。为此，通过联合优化资源友好的DL模型和模型自适应系统调度的算法-系统共同设计改进了运行时资源可用性，从而推动了由独立级别设定的性能界限。

    The emerging field of artificial intelligence of things (AIoT, AI+IoT) is driven by the widespread use of intelligent infrastructures and the impressive success of deep learning (DL). With the deployment of DL on various intelligent infrastructures featuring rich sensors and weak DL computing capabilities, a diverse range of AIoT applications has become possible. However, DL models are notoriously resource-intensive. Existing research strives to realize near-/realtime inference of AIoT live data and low-cost training using AIoT datasets on resource-scare infrastructures. Accordingly, the accuracy and responsiveness of DL models are bounded by resource availability. To this end, the algorithm-system co-design that jointly optimizes the resource-friendly DL models and model-adaptive system scheduling improves the runtime resource availability and thus pushes the performance boundary set by the standalone level. Unlike previous surveys on resource-friendly DL models or hand-crafted DL com
    
[^35]: LogicMP: 一种将一阶逻辑约束编码的神经符号方法

    LogicMP: A Neuro-symbolic Approach for Encoding First-order Logic Constraints. (arXiv:2309.15458v1 [cs.AI])

    [http://arxiv.org/abs/2309.15458](http://arxiv.org/abs/2309.15458)

    本文提出了一种名为LogicMP的新颖神经层，该层通过均场变分推断将一阶逻辑约束编码进神经网络中。通过有效缓解一阶逻辑模型的推断困难，LogicMP在图形、图像和文本任务中表现出比竞争对手更好的性能和效率。

    

    将一阶逻辑约束与神经网络集成是一个关键但具有挑战性的问题，因为它涉及建模复杂的相关性以满足约束。本文提出了一种新颖的神经层LogicMP，其层对MLN进行均场变分推断。它可以插入任何现成的神经网络以编码一阶逻辑约束，同时保持模块化和效率。通过利用MLN中的结构和对称性，我们从理论上证明了我们设计良好、高效的均场迭代能够有效缓解MLN推断的困难，将推断从顺序计算降低为一系列并行的张量操作。在图形、图像和文本的三类任务上的实证结果表明，LogicMP在性能和效率上都优于先进的竞争对手。

    Integrating first-order logic constraints (FOLCs) with neural networks is a crucial but challenging problem since it involves modeling intricate correlations to satisfy the constraints. This paper proposes a novel neural layer, LogicMP, whose layers perform mean-field variational inference over an MLN. It can be plugged into any off-the-shelf neural network to encode FOLCs while retaining modularity and efficiency. By exploiting the structure and symmetries in MLNs, we theoretically demonstrate that our well-designed, efficient mean-field iterations effectively mitigate the difficulty of MLN inference, reducing the inference from sequential calculation to a series of parallel tensor operations. Empirical results in three kinds of tasks over graphs, images, and text show that LogicMP outperforms advanced competitors in both performance and efficiency.
    
[^36]: 基于局部压缩视频流学习的通用事件边界检测

    Local Compressed Video Stream Learning for Generic Event Boundary Detection. (arXiv:2309.15431v1 [cs.CV])

    [http://arxiv.org/abs/2309.15431](http://arxiv.org/abs/2309.15431)

    提出了一种基于局部压缩视频流学习的方法用于通用事件边界的检测，该方法能够在不完全解码视频情况下，利用压缩域中的丰富信息进行端到端的学习。使用轻量级ConvNets提取GOP中的P帧特征，并通过设计的空间-通道注意力模块进行特征细化，最终实现了准确的事件边界检测。

    

    通用事件边界检测旨在将视频分段为块，定位通用且无分类的事件边界。现有方法通常需要在将视频帧解码后才将其输入网络，这其中存在较大的时空冗余，并且需要较大的计算能力和存储空间。为了解决这些问题，我们提出了一种全新的压缩视频表示学习方法，用于事件边界检测，它完全基于压缩域中丰富的信息，包括RGB、运动向量、残差和图像组（GOP）结构，而无需完全解码视频。具体而言，我们使用轻量级的ConvNets提取GOP中的P帧的特征，并设计了一种空间-通道注意力模块（SCAM），根据双向信息流使用压缩信息来细化P帧的特征表示。为了学习适合边界检测的表示，我们通过联合最小切割（JLC）和中心切割（CFC）来执行事件边界优化。

    Generic event boundary detection aims to localize the generic, taxonomy-free event boundaries that segment videos into chunks. Existing methods typically require video frames to be decoded before feeding into the network, which contains significant spatio-temporal redundancy and demands considerable computational power and storage space. To remedy these issues, we propose a novel compressed video representation learning method for event boundary detection that is fully end-to-end leveraging rich information in the compressed domain, i.e., RGB, motion vectors, residuals, and the internal group of pictures (GOP) structure, without fully decoding the video. Specifically, we use lightweight ConvNets to extract features of the P-frames in the GOPs and spatial-channel attention module (SCAM) is designed to refine the feature representations of the P-frames based on the compressed information with bidirectional information flow. To learn a suitable representation for boundary detection, we co
    
[^37]: 使用大型语言模型的图神经提示

    Graph Neural Prompting with Large Language Models. (arXiv:2309.15427v1 [cs.CL])

    [http://arxiv.org/abs/2309.15427](http://arxiv.org/abs/2309.15427)

    本文提出了一种名为图神经提示（GNP）的方法，可以帮助大型语言模型从知识图中学习有益的知识，以弥补它们在准确捕捉和返回基于知识的信息方面的固有限制。

    

    大型语言模型（LLMs）在各种语言建模任务中表现出了卓越的泛化能力和出色的性能，但它们在准确捕捉和返回基于知识的信息方面仍存在固有限制。现有的研究已经探索了利用知识图来通过联合训练和定制模型架构增强语言建模，但是将此应用于LLMs存在参数数量庞大和计算成本高的问题。此外，如何利用预训练的LLMs并避免从头开始训练自定义模型仍然是一个开放的问题。在这项工作中，我们提出了图神经提示（GNP），一种新颖的即插即用方法，可以帮助预训练的LLMs从知识图中学习有益的知识。GNP包括各种设计，包括标准的图神经网络编码器、跨模态汇聚模块、域投影器和自监督链接预测目标。在多个实验中展示了GNP的有效性。

    Large Language Models (LLMs) have shown remarkable generalization capability with exceptional performance in various language modeling tasks. However, they still exhibit inherent limitations in precisely capturing and returning grounded knowledge. While existing work has explored utilizing knowledge graphs to enhance language modeling via joint training and customized model architectures, applying this to LLMs is problematic owing to their large number of parameters and high computational cost. In addition, how to leverage the pre-trained LLMs and avoid training a customized model from scratch remains an open question. In this work, we propose Graph Neural Prompting (GNP), a novel plug-and-play method to assist pre-trained LLMs in learning beneficial knowledge from KGs. GNP encompasses various designs, including a standard graph neural network encoder, a cross-modality pooling module, a domain projector, and a self-supervised link prediction objective. Extensive experiments on multiple
    
[^38]: 失败模式三元组及可能的解决方法

    The Triad of Failure Modes and a Possible Way Out. (arXiv:2309.15420v1 [cs.LG])

    [http://arxiv.org/abs/2309.15420](http://arxiv.org/abs/2309.15420)

    本文提出了一个新颖的目标函数，用于解决聚类自监督学习中的表示崩溃、聚类崩溃和对聚类分配的置换不变性的问题。该目标函数具有简单性和理论基础，适用于标准的主干结构训练，无需使用非对称元素。

    

    我们提出了一个新颖的聚类自监督学习（SSL）的目标函数，旨在解决表示崩溃、聚类崩溃和对聚类分配的置换不变性等三种失败模式。这个目标函数由三个关键组成部分构成：（i）惩罚表示崩溃的生成项，（ii）促进对数据增强的不变性的项，从而解决标签置换的问题，以及（ii）惩罚聚类崩溃的均匀性项。此外，我们提出的目标函数具有两个显著优势。首先，它可以从贝叶斯的角度解释为数据对数似然的下界。其次，它可以训练一个标准的主干结构，无需使用非对称元素，如停止梯度、动量编码器或专门的聚类层。由于其简单性和理论基础，我们提出的目标函数非常适合

    We present a novel objective function for cluster-based self-supervised learning (SSL) that is designed to circumvent the triad of failure modes, namely representation collapse, cluster collapse, and the problem of invariance to permutations of cluster assignments. This objective consists of three key components: (i) A generative term that penalizes representation collapse, (ii) a term that promotes invariance to data augmentations, thereby addressing the issue of label permutations and (ii) a uniformity term that penalizes cluster collapse. Additionally, our proposed objective possesses two notable advantages. Firstly, it can be interpreted from a Bayesian perspective as a lower bound on the data log-likelihood. Secondly, it enables the training of a standard backbone architecture without the need for asymmetric elements like stop gradients, momentum encoders, or specialized clustering layers. Due to its simplicity and theoretical foundation, our proposed objective is well-suited for 
    
[^39]: 关于思维链推理：进展、前沿和未来的调查

    A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future. (arXiv:2309.15402v1 [cs.CL])

    [http://arxiv.org/abs/2309.15402](http://arxiv.org/abs/2309.15402)

    本文首次全面调查了思维链推理领域的研究，涵盖了构建、结构变体和增强技术等方法分类，以及规划、工具使用和提炼等前沿应用。同时讨论了挑战和未来发展方向。这份调查报告对于在思维链推理领域寻求创新的研究人员来说是一个有价值的资源。

    

    思维链推理是人类智能的基本认知过程，在人工智能和自然语言处理领域引起了广泛关注。然而，目前仍缺乏一份全面的调查报告。为此，我们迈出了第一步，仔细广泛地概述了这个研究领域。我们用“X-of-Thought”来指代广义上的思维链推理。具体而言，我们根据方法的分类体系对当前的研究进行了系统组织，包括思维链的构建、结构变体和增强技术。此外，我们描述了思维链在规划、工具使用和提炼等领域的前沿应用。此外，我们还讨论了一些挑战和未来的方向，包括忠实度、多模态和理论等。我们希望这份调查报告能成为寻求在思维链推理领域创新的研究人员的宝贵资源。

    Chain-of-thought reasoning, a cognitive process fundamental to human intelligence, has garnered significant attention in the realm of artificial intelligence and natural language processing. However, there still remains a lack of a comprehensive survey for this arena. To this end, we take the first step and present a thorough survey of this research field carefully and widely. We use X-of-Thought to refer to Chain-of-Thought in a broad sense. In detail, we systematically organize the current research according to the taxonomies of methods, including XoT construction, XoT structure variants, and enhanced XoT. Additionally, we describe XoT with frontier applications, covering planning, tool use, and distillation. Furthermore, we address challenges and discuss some future directions, including faithfulness, multi-modal, and theory. We hope this survey serves as a valuable resource for researchers seeking to innovate within the domain of chain-of-thought reasoning.
    
[^40]: 神经随机微分方程用于鲁棒性和可解释性电磁非意图辐射发射分析

    Neural Stochastic Differential Equations for Robust and Explainable Analysis of Electromagnetic Unintended Radiated Emissions. (arXiv:2309.15386v1 [cs.LG])

    [http://arxiv.org/abs/2309.15386](http://arxiv.org/abs/2309.15386)

    本研究对ResNet-like模型在非意图辐射发射（URE）分类中的鲁棒性和可解释性进行了全面评估，并通过提出神经随机微分方程（SDEs）的应用，解决了模型对噪声的脆弱性以及解释不准确的问题。

    

    我们在非意图辐射发射（URE）分类的背景下，对ResNet-like模型的鲁棒性和可解释性进行了全面评估，并提出了一种利用神经随机微分方程（SDEs）来解决已发现限制的新方法。我们通过实验证明了ResNet-like模型对高斯噪声扰动的脆弱性，当高斯噪声仅为0.5标准差时，模型性能急剧下降，其F1-score降至接近无意义的0.008。我们还强调了一个令人担忧的不一致性，即ResNet-like模型提供的解释不反映输入数据中固有的周期性，在稳定设备中进行URE检测时这是一个关键属性。针对这些发现，我们提出了一种新的应用神经SDEs构建URE分类模型的方法，这些模型不仅对噪声具有鲁棒性，还能提供更有意义和直观的解释。

    We present a comprehensive evaluation of the robustness and explainability of ResNet-like models in the context of Unintended Radiated Emission (URE) classification and suggest a new approach leveraging Neural Stochastic Differential Equations (SDEs) to address identified limitations. We provide an empirical demonstration of the fragility of ResNet-like models to Gaussian noise perturbations, where the model performance deteriorates sharply and its F1-score drops to near insignificance at 0.008 with a Gaussian noise of only 0.5 standard deviation. We also highlight a concerning discrepancy where the explanations provided by ResNet-like models do not reflect the inherent periodicity in the input data, a crucial attribute in URE detection from stable devices. In response to these findings, we propose a novel application of Neural SDEs to build models for URE classification that are not only robust to noise but also provide more meaningful and intuitive explanations. Neural SDE models mai
    
[^41]: 超越补丁：基于强化学习的高分辨率遥感图像的自适应语义分割

    Seeing Beyond the Patch: Scale-Adaptive Semantic Segmentation of High-resolution Remote Sensing Imagery based on Reinforcement Learning. (arXiv:2309.15372v1 [cs.CV])

    [http://arxiv.org/abs/2309.15372](http://arxiv.org/abs/2309.15372)

    本文提出了一个动态尺度感知框架GeoAgent，用于解决遥感图像分析中基于补丁的方法的局限性，该框架通过自适应地捕捉图像补丁之外的适当尺度上下文信息来处理复杂和多变的地理对象，从而提高了语义分割的一致性。

    

    在遥感图像分析中，基于补丁的方法在捕捉滑动窗口之外的信息方面存在局限性。这个缺点在处理复杂和多变的地理对象时带来了显著的挑战，导致分割结果中的语义不一致。为了解决这个挑战，我们提出了一个动态尺度感知框架GeoAgent，根据不同的地理对象自适应地捕捉图像补丁之外的适当尺度上下文信息。在GeoAgent中，每个图像补丁的状态通过全局缩略图和位置掩码来表示。全局缩略图提供了补丁之外的上下文，位置掩码指导了感知到的空间关系。尺度选择动作是通过尺度控制Agent(SCA)执行的。提出了一个特征索引模块来增强Agent区分当前图像补丁位置的能力。该动作切换了双分支分割网络的补丁尺度和上下文分支。

    In remote sensing imagery analysis, patch-based methods have limitations in capturing information beyond the sliding window. This shortcoming poses a significant challenge in processing complex and variable geo-objects, which results in semantic inconsistency in segmentation results. To address this challenge, we propose a dynamic scale perception framework, named GeoAgent, which adaptively captures appropriate scale context information outside the image patch based on the different geo-objects. In GeoAgent, each image patch's states are represented by a global thumbnail and a location mask. The global thumbnail provides context beyond the patch, and the location mask guides the perceived spatial relationships. The scale-selection actions are performed through a Scale Control Agent (SCA). A feature indexing module is proposed to enhance the ability of the agent to distinguish the current image patch's location. The action switches the patch scale and context branch of a dual-branch seg
    
[^42]: C3Net: 面向异质系统中物理化学性质预测的原子间势神经网络

    C3Net: interatomic potential neural network for prediction of physicochemical properties in heterogenous systems. (arXiv:2309.15334v1 [cs.LG])

    [http://arxiv.org/abs/2309.15334](http://arxiv.org/abs/2309.15334)

    C3Net是一种面向异质系统中物理化学性质预测的神经网络，能嵌入原子类型在分子环境中并遵循基本物理定律的原子间势。该模型在预测物理化学性质上具有良好的泛化能力，并优于基于量子力学和神经网络的最新方法。

    

    理解溶质与其环境的相互作用在化学和生物学中具有基本重要性。本研究提出了一种深度神经网络架构，用于原子类型在分子环境中的嵌入和遵循基本物理定律的原子间势。该架构被应用于预测异质系统中的物理化学性质，包括溶解在不同溶剂中、1-辛醇-水分配和PAMPA。我们展示了我们的架构在物理化学性质上具有良好的泛化能力，并在溶解自由能预测任务中优于基于量子力学和神经网络的最新方法。从模型中获得的溶质中每个原子的原子间势允许进行符合化学和物理推理的原子分辨率的物理化学性质定量分析。该软件可在https://github.com/SehanLee/C3Net上获取。

    Understanding the interactions of a solute with its environment is of fundamental importance in chemistry and biology. In this work, we propose a deep neural network architecture for atom type embeddings in its molecular context and interatomic potential that follows fundamental physical laws. The architecture is applied to predict physicochemical properties in heterogeneous systems including solvation in diverse solvents, 1-octanol-water partitioning, and PAMPA with a single set of network weights. We show that our architecture is generalized well to the physicochemical properties and outperforms state-of-the-art approaches based on quantum mechanics and neural networks in the task of solvation free energy prediction. The interatomic potentials at each atom in a solute obtained from the model allow quantitative analysis of the physicochemical properties at atomic resolution consistent with chemical and physical reasoning. The software is available at https://github.com/SehanLee/C3Net.
    
[^43]: 大规模多语言自监督学习的联合预测和去噪

    joint prediction and denoising for large-scale multilingual self-supervised learning. (arXiv:2309.15317v1 [cs.CL])

    [http://arxiv.org/abs/2309.15317](http://arxiv.org/abs/2309.15317)

    这项研究提出了WavLabLM，它通过联合预测和去噪的方法，实现了在136种语言的40k小时数据上进行大规模多语言自监督学习。WavLabLM的多阶段预训练方法解决了多语言数据的语言失衡问题，使其在ML-SUPERB上达到了与XLS-R相当的性能，同时仅使用不到10%的训练数据，这使得SSL在学术高性能计算上可行。

    

    多语言自监督学习(SSL)由于处理多种语言所需的费用和复杂性而经常落后于最先进的方法。这进一步影响了SSL的可重复性，由于资源使用的限制，SSL已经仅限于少数研究团队。我们展示了更强大的技术实际上可以导致更高效的预训练，从而使更多的研究团队能够加入SSL。我们提出了WavLabLM，将WavLM的联合预测和去噪扩展到136种语言的40k小时数据。为了构建WavLabLM，我们设计了一种新颖的多阶段预训练方法，旨在解决多语言数据的语言失衡问题。WavLabLM在ML-SUPERB上实现了与XLS-R相当的性能，仅使用不到10%的训练数据，使得SSL在学术高性能计算上可实现。我们还展示了vanilla HuBERT Base模型可以实现进一步的效率提升，仅使用3%的数据、4个GPU和有限的试验次数，就能保持94%的XLS-R性能。

    Multilingual self-supervised learning (SSL) has often lagged behind state-of-the-art (SOTA) methods due to the expenses and complexity required to handle many languages. This further harms the reproducibility of SSL, which is already limited to few research groups due to its resource usage. We show that more powerful techniques can actually lead to more efficient pre-training, opening SSL to more research groups. We propose WavLabLM, which extends WavLM's joint prediction and denoising to 40k hours of data across 136 languages. To build WavLabLM, we devise a novel multi-stage pre-training method, designed to address the language imbalance of multilingual data. WavLabLM achieves comparable performance to XLS-R on ML-SUPERB with less than 10% of the training data, making SSL realizable with academic compute. We show that further efficiency can be achieved with a vanilla HuBERT Base model, which can maintain 94% of XLS-R's performance with only 3% of the data, 4 GPUs, and limited trials. 
    
[^44]: MAPTree: 用贝叶斯决策树击败“最优”决策树

    MAPTree: Beating "Optimal" Decision Trees with Bayesian Decision Trees. (arXiv:2309.15312v1 [cs.LG])

    [http://arxiv.org/abs/2309.15312](http://arxiv.org/abs/2309.15312)

    MAPTree是一种通过贝叶斯方法对决策树进行归纳的算法，通过AND/OR搜索实现最大后验树的恢复。在实验中，MAPTree在多个数据集上表现出更好的性能，并且能够以更小的树来实现可比较的性能。在合成数据和实际场景中，MAPTree还展示出更强的抗噪声能力和更好的泛化能力。

    

    决策树仍然是当今最流行的机器学习模型之一，主要是因为其开箱即用的性能和可解释性。在这项工作中，我们通过对树上的后验分布进行最大后验推理，提出了一种贝叶斯决策树归纳的方法。我们首先展示了决策树的最大后验推理与AND/OR搜索之间的关联。利用这一关联，我们提出了一种称为MAPTree的AND/OR搜索算法，能够恢复出最大后验树。最后，我们通过在合成数据和实际世界场景中展示最大后验树的经验性能。在16个实际数据集上，MAPTree要么优于基准线，要么在性能相当的情况下具有更小的树。在一个合成数据集上，MAPTree表现出比现有方法更强的抗噪声能力和更好的泛化能力。最后，MAPTree比其他方法更快地恢复出最大后验树。

    Decision trees remain one of the most popular machine learning models today, largely due to their out-of-the-box performance and interpretability. In this work, we present a Bayesian approach to decision tree induction via maximum a posteriori inference of a posterior distribution over trees. We first demonstrate a connection between maximum a posteriori inference of decision trees and AND/OR search. Using this connection, we propose an AND/OR search algorithm, dubbed MAPTree, which is able to recover the maximum a posteriori tree. Lastly, we demonstrate the empirical performance of the maximum a posteriori tree both on synthetic data and in real world settings. On 16 real world datasets, MAPTree either outperforms baselines or demonstrates comparable performance but with much smaller trees. On a synthetic dataset, MAPTree also demonstrates greater robustness to noise and better generalization than existing approaches. Finally, MAPTree recovers the maxiumum a posteriori tree faster tha
    
[^45]: 多模态情感调节和情感一致性对于具身对话智能体的重要性

    The Importance of Multimodal Emotion Conditioning and Affect Consistency for Embodied Conversational Agents. (arXiv:2309.15311v1 [cs.HC])

    [http://arxiv.org/abs/2309.15311](http://arxiv.org/abs/2309.15311)

    本研究提出了一个概念性框架ACTOR，通过生成以一致驱动情感为条件的多模态行为，旨在增强感知情感。研究发现，在具备表达行为的具身对话智能体中，多模态情感调节和情感一致性至关重要。

    

    先前有关对于具身虚拟智能体情感感知的研究表明，使用虚拟角色通过与人类的互动传达情感的有效性。然而，创建一个具有表达行为的自主具身对话智能体面临着两个主要挑战。第一个挑战是合成每种模态的对话行为非常表达性，像真实人类行为一样具有表达性的困难。第二个挑战是情感被独立建模，这使得难以生成在所有模态上具有一致情感的多模态响应。在这项工作中，我们提出了一个概念性框架ACTOR（一致性情感多模态行为生成），旨在通过生成以一致驱动情感为条件的多模态行为来增强情感感知。我们进行了一项用户研究，并招募了199名参与者，以评估普通人如何判断从多模态状态下感知到的情感。

    Previous studies regarding the perception of emotions for embodied virtual agents have shown the effectiveness of using virtual characters in conveying emotions through interactions with humans. However, creating an autonomous embodied conversational agent with expressive behaviors presents two major challenges. The first challenge is the difficulty of synthesizing the conversational behaviors for each modality that are as expressive as real human behaviors. The second challenge is that the affects are modeled independently, which makes it difficult to generate multimodal responses with consistent emotions across all modalities. In this work, we propose a conceptual framework, ACTOR (Affect-Consistent mulTimodal behaviOR generation), that aims to increase the perception of affects by generating multimodal behaviors conditioned on a consistent driving affect. We have conducted a user study with 199 participants to assess how the average person judges the affects perceived from multimoda
    
[^46]: 自我监督的无约束机器人经验中的地形表示学习

    Self-Supervised Terrain Representation Learning from Unconstrained Robot Experience. (arXiv:2309.15302v1 [cs.RO])

    [http://arxiv.org/abs/2309.15302](http://arxiv.org/abs/2309.15302)

    提出一种名为STERLING的自我监督地形表示学习方法，通过无约束的机器人经验学习有关地形的相关表示，以实现地形感知导航。

    

    地形认知，即辨别和区分不同类型的地形，是机器人在自主越野导航中必须具备的关键能力。目前提供机器人这种认知能力的方法要么依赖昂贵的标记数据收集，要么依赖无法泛化的工程特征和成本函数，或者依赖可能无法获得的专家人类示范。为了使机器人不受这些限制地具备地形认知能力，我们引入了自我监督地形表示学习（STERLING），这是一种新颖的学习地形表示的方法，仅依赖于易于收集的、无约束（例如，非专家的）和未标记的机器人经验，对数据采集没有额外的限制。STERLING采用了一种新颖的多模态自我监督目标，通过非对比度表示学习来学习地形相关的表示以用于地形感知导航。通过实物机器人实验

    Terrain awareness, i.e., the ability to identify and distinguish different types of terrain, is a critical ability that robots must have to succeed at autonomous off-road navigation. Current approaches that provide robots with this awareness either rely on labeled data which is expensive to collect, engineered features and cost functions that may not generalize, or expert human demonstrations which may not be available. Towards endowing robots with terrain awareness without these limitations, we introduce Self-supervised TErrain Representation LearnING (STERLING), a novel approach for learning terrain representations that relies solely on easy-to-collect, unconstrained (e.g., non-expert), and unlabelled robot experience, with no additional constraints on data collection. STERLING employs a novel multi-modal self-supervision objective through non-contrastive representation learning to learn relevant terrain representations for terrain-aware navigation. Through physical robot experiments
    
[^47]: 最大扩散强化学习

    Maximum Diffusion Reinforcement Learning. (arXiv:2309.15293v1 [cs.LG])

    [http://arxiv.org/abs/2309.15293](http://arxiv.org/abs/2309.15293)

    最大扩散强化学习是一种克服强化学习中数据相关性问题的方法，通过解耦代理的经验实现持续学习，并在各种测试中表现出色。

    

    所有机器学习都建立在数据独立且同分布的假设上。然而，在强化学习中，当数据是依次从代理经验中收集而来时，这一假设通常不成立。因此，我们提出了一种名为最大扩散强化学习的方法，利用统计力学中的遍历过程来克服这些限制。我们的方法通过解耦代理的经验，可证明地使代理在单次部署中能够持续学习，而不受初始化方式的影响。此外，我们证明了我们的方法推广了众所周知的最大熵技术，并且通过在流行的基准测试中稳定超过了最先进的性能水平。我们的研究成果极大地促进了物理学、学习和控制的交叉领域，为强化学习代理（如行走机器人和自动驾驶汽车）的透明可靠决策提供了一条道路。

    The assumption that data are independent and identically distributed underpins all machine learning. When data are collected sequentially from agent experiences this assumption does not generally hold, as in reinforcement learning. Here, we derive a method that overcomes these limitations by exploiting the statistical mechanics of ergodic processes, which we term maximum diffusion reinforcement learning. By decorrelating agent experiences, our approach provably enables agents to learn continually in single-shot deployments regardless of how they are initialized. Moreover, we prove our approach generalizes well-known maximum entropy techniques, and show that it robustly exceeds state-of-the-art performance across popular benchmarks. Our results at the nexus of physics, learning, and control pave the way towards more transparent and reliable decision-making in reinforcement learning agents, such as locomoting robots and self-driving cars.
    
[^48]: 眼不见心不念：利用视频跟踪启用的记忆模型对未被观察到的对象进行推理和规划

    Out of Sight, Still in Mind: Reasoning and Planning about Unobserved Objects with Video Tracking Enabled Memory Models. (arXiv:2309.15278v1 [cs.RO])

    [http://arxiv.org/abs/2309.15278](http://arxiv.org/abs/2309.15278)

    本文研究了如何对先前观察到但当前被遮挡的对象进行推理和规划，提出了利用转换器关系动力学编码轨迹历史的方法，并在多个挑战性任务中表现出色。

    

    机器人需要具有对先前观察到但当前被遮挡的对象的记忆，以在现实环境中可靠地工作。我们研究了将面向对象的记忆编码到多对象操纵推理和规划框架中的问题。我们提出了DOOM和LOOM，它们利用转换器关系动力学来编码给定部分视点云和对象发现与跟踪引擎的轨迹历史。我们的方法可以执行多个具有挑战性的任务，包括处理被遮挡的对象，新出现的对象，以及物体重新出现。通过广泛的仿真和真实世界实验，我们发现我们的方法在不同数量的对象和不同数量的干扰动作方面表现良好。此外，我们展示了我们的方法优于隐式记忆基线。

    Robots need to have a memory of previously observed, but currently occluded objects to work reliably in realistic environments. We investigate the problem of encoding object-oriented memory into a multi-object manipulation reasoning and planning framework. We propose DOOM and LOOM, which leverage transformer relational dynamics to encode the history of trajectories given partial-view point clouds and an object discovery and tracking engine. Our approaches can perform multiple challenging tasks including reasoning with occluded objects, novel objects appearance, and object reappearance. Throughout our extensive simulation and real-world experiments, we find that our approaches perform well in terms of different numbers of objects and different numbers of distractor actions. Furthermore, we show our approaches outperform an implicit memory baseline.
    
[^49]: Vision Transformer适应的高效低秩反向传播

    Efficient Low-rank Backpropagation for Vision Transformer Adaptation. (arXiv:2309.15275v1 [cs.CV])

    [http://arxiv.org/abs/2309.15275](http://arxiv.org/abs/2309.15275)

    本论文提出了一种名为LBP-WHT的新方法，用于解决视觉变换器（ViT）在反向传播中对计算资源的需求过高的问题。LBP-WHT方法通过将梯度投影到低秩空间并进行反向传播，显著减少了适应ViT所需的计算量。实验结果表明，LBP-WHT在多个数据集上对不同模型的适应性能都表现出色。

    

    视觉变换器（ViT）的规模不断增大，使得为特定需求对这些大模型进行高效微调成为各种应用中的重大挑战。这个问题源于ViT的线性层中需要的计算量大的矩阵乘法在反向传播过程中。在本文中，我们通过提出一种新的基于Walsh-Hadamard变换的低秩反向传播（LBP-WHT）方法来解决这个问题。直观地说，LBP-WHT将梯度投影到低秩空间，并进行反向传播。这种方法大大减少了适应ViT所需的计算量，因为低秩空间中的矩阵乘法较少占用资源。我们在多个数据集上使用不同模型（ViT、混合卷积-ViT模型）进行了广泛实验证明了我们方法的有效性。例如，在对CIFAR100上的EfficientFormer-L1模型进行适应时，我们的LBP-WHT相比标准方法提高了10.4%的准确率。

    The increasing scale of vision transformers (ViT) has made the efficient fine-tuning of these large models for specific needs a significant challenge in various applications. This issue originates from the computationally demanding matrix multiplications required during the backpropagation process through linear layers in ViT. In this paper, we tackle this problem by proposing a new Low-rank BackPropagation via Walsh-Hadamard Transformation (LBP-WHT) method. Intuitively, LBP-WHT projects the gradient into a low-rank space and carries out backpropagation. This approach substantially reduces the computation needed for adapting ViT, as matrix multiplication in the low-rank space is far less resource-intensive. We conduct extensive experiments with different models (ViT, hybrid convolution-ViT model) on multiple datasets to demonstrate the effectiveness of our method. For instance, when adapting an EfficientFormer-L1 model on CIFAR100, our LBP-WHT achieves 10.4% higher accuracy than the st
    
[^50]: 内存高效的连续学习长视频目标分割方法

    Memory-Efficient Continual Learning Object Segmentation for Long Video. (arXiv:2309.15274v1 [cs.CV])

    [http://arxiv.org/abs/2309.15274](http://arxiv.org/abs/2309.15274)

    提出了两种新技术，以减少在线VOS方法的内存需求，并在提高建模准确性和泛化能力的同时进行目标分割。

    

    最近的半监督视频目标分割方法在利用前几帧的信息进行当前帧分割时显示出显著的目标对象分割准确性改进。特别地，这种基于记忆的方法可以帮助模型更有效地处理外观变化（表达漂移）或遮挡。理想情况下，为了达到最佳性能，在线视频目标分割（VOS）方法需要将所有或大部分前几帧（或其提取的信息）存储在内存中，并用于连续帧的在线学习。然而，对于长视频来说，这种解决方案是不可行的，因为所需的内存大小会无限增长。另一方面，在内存有限且目标对象在视频中重复发生表达漂移的情况下，这些方法可能会失败。我们提出了两种新技术来减少在线VOS方法的内存需求，同时提高建模准确性和泛化能力。

    Recent state-of-the-art semi-supervised Video Object Segmentation (VOS) methods have shown significant improvements in target object segmentation accuracy when information from preceding frames is used in undertaking segmentation on the current frame. In particular, such memory-based approaches can help a model to more effectively handle appearance changes (representation drift) or occlusions. Ideally, for maximum performance, online VOS methods would need all or most of the preceding frames (or their extracted information) to be stored in memory and be used for online learning in consecutive frames. Such a solution is not feasible for long videos, as the required memory size would grow without bound. On the other hand, these methods can fail when memory is limited and a target object experiences repeated representation drifts throughout a video.  We propose two novel techniques to reduce the memory requirement of online VOS methods while improving modeling accuracy and generalization 
    
[^51]: STARC:评估奖励函数之间差异的通用框架

    STARC: A General Framework For Quantifying Differences Between Reward Functions. (arXiv:2309.15257v1 [cs.LG])

    [http://arxiv.org/abs/2309.15257](http://arxiv.org/abs/2309.15257)

    这篇论文提出了一个通用框架（STARC），用于评估奖励函数之间的差异，填补了奖励学习理论基础的空白。

    

    为了使用强化学习解决任务，需要将任务的目标形式化为奖励函数。然而，对于许多现实世界的任务来说，手动指定一个永不激励不良行为的奖励函数非常困难。因此，使用奖励学习算法来从数据中学习奖励函数变得越来越流行。然而，奖励学习的理论基础尚未完善。特别地，通常不知道给定的奖励学习算法在高概率下是否会学习到一个安全优化的奖励函数。这意味着奖励学习算法通常必须经过经验评估，这是昂贵的，并且很难预测其失效模式。其中一个阻碍获得更好理论保证的障碍是缺乏较好的方法来量化奖励函数之间的差异。在本文中，我们提供了一种解决方案。

    In order to solve a task using reinforcement learning, it is necessary to first formalise the goal of that task as a reward function. However, for many real-world tasks, it is very difficult to manually specify a reward function that never incentivises undesirable behaviour. As a result, it is increasingly popular to use reward learning algorithms, which attempt to learn a reward function from data. However, the theoretical foundations of reward learning are not yet well-developed. In particular, it is typically not known when a given reward learning algorithm with high probability will learn a reward function that is safe to optimise. This means that reward learning algorithms generally must be evaluated empirically, which is expensive, and that their failure modes are difficult to predict in advance. One of the roadblocks to deriving better theoretical guarantees is the lack of good methods for quantifying the difference between reward functions. In this paper we provide a solution t
    
[^52]: VPA: 全面测试时间视觉提示适应

    VPA: Fully Test-Time Visual Prompt Adaptation. (arXiv:2309.15251v1 [cs.CV])

    [http://arxiv.org/abs/2309.15251](http://arxiv.org/abs/2309.15251)

    VPA是首个将视觉提示与测试时间适应相结合的框架，通过引入可学习令牌实现了完全测试时间和存储高效的适应。实验证明，VPA能够有效提升超出分布泛化能力。

    

    文本提示调整已经展示出了显著的性能改进，通过将手工调整的提示作为可训练参数，将自然语言处理模型适应到各种下游任务中。受到文本提示成功的启发，一些研究探索了视觉提示调整的有效性。在这项工作中，我们提出了Visual Prompt Adaptation（VPA），这是第一个将视觉提示与测试时间适应相结合的框架。VPA引入了少量的可学习令牌，实现了完全测试时间和存储高效的适应，而不需要源域信息。我们在不同的适应设置下检验了VPA设计，包括单图像、批次图像和伪标签适应。我们在多个任务上评估了VPA，包括超出分布（OOD）泛化、损坏鲁棒性和领域适应。实验结果表明，VPA通过3.3%有效提高了超出分布泛化的能力。

    Textual prompt tuning has demonstrated significant performance improvements in adapting natural language processing models to a variety of downstream tasks by treating hand-engineered prompts as trainable parameters. Inspired by the success of textual prompting, several studies have investigated the efficacy of visual prompt tuning. In this work, we present Visual Prompt Adaptation (VPA), the first framework that generalizes visual prompting with test-time adaptation. VPA introduces a small number of learnable tokens, enabling fully test-time and storage-efficient adaptation without necessitating source-domain information. We examine our VPA design under diverse adaptation settings, encompassing single-image, batched-image, and pseudo-label adaptation. We evaluate VPA on multiple tasks, including out-of-distribution (OOD) generalization, corruption robustness, and domain adaptation. Experimental results reveal that VPA effectively enhances OOD generalization by 3.3% across various mode
    
[^53]: SeMAnD:自监督多模式地理空间数据异常检测

    SeMAnD: Self-Supervised Anomaly Detection in Multimodal Geospatial Datasets. (arXiv:2309.15245v1 [cs.AI])

    [http://arxiv.org/abs/2309.15245](http://arxiv.org/abs/2309.15245)

    提出了一种名为SeMAnD的自监督异常检测技术，可用于检测多模态地理空间数据中的几何异常。该技术通过数据增强和自监督训练目标实现，能够有效地表示和识别不同模态数据中的局部变化和缺陷。

    

    我们提出了一种自监督异常检测技术，称为SeMAnD，用于检测多模态地理空间数据中的几何异常。地理空间数据包括获取和衍生的异构数据模态，我们将其转换为语义上有意义的、类似图像的张量，以解决多模态数据的表示、对齐和融合的挑战。SeMAnD由两部分组成：（i）一种简单的数据增强策略，称为RandPolyAugment，能够生成多样化的矢量几何增强，以及（ii）具有三个组件的自监督训练目标，激励学习对一种模态中的局部变化具有区别性的多模态数据表示，这种变化在其他模态中没有得到证实。在地理空间异常检测中，检测局部缺陷至关重要，即使是小的异常（如移位、错误连接、畸形或缺失的多边形矢量几何，如道路、建筑物、地表覆盖等）也是有害的。

    We propose a Self-supervised Anomaly Detection technique, called SeMAnD, to detect geometric anomalies in Multimodal geospatial datasets. Geospatial data comprises of acquired and derived heterogeneous data modalities that we transform to semantically meaningful, image-like tensors to address the challenges of representation, alignment, and fusion of multimodal data. SeMAnD is comprised of (i) a simple data augmentation strategy, called RandPolyAugment, capable of generating diverse augmentations of vector geometries, and (ii) a self-supervised training objective with three components that incentivize learning representations of multimodal data that are discriminative to local changes in one modality which are not corroborated by the other modalities. Detecting local defects is crucial for geospatial anomaly detection where even small anomalies (e.g., shifted, incorrectly connected, malformed, or missing polygonal vector geometries like roads, buildings, landcover, etc.) are detrimenta
    
[^54]: PlotMap：用于构建游戏世界的自动布局设计

    PlotMap: Automated Layout Design for Building Game Worlds. (arXiv:2309.15242v1 [cs.AI])

    [http://arxiv.org/abs/2309.15242](http://arxiv.org/abs/2309.15242)

    本研究提出了一种独立于底层地图生成方法的故事情节布局设计，以解决设计支持所期望叙事的游戏地图的挑战。

    

    游戏世界构建是开发游戏的叙事和物理世界的过程，在游戏体验中起着至关重要的作用。备受好评的独立游戏和AAA级视频游戏被赞赏其优秀的世界构建，其中游戏地图与叙事紧密融合并提升了游戏体验，吸引了玩家并留下了深刻的印象。然而，设计支持所期望叙事的游戏地图是具有挑战性的，因为它需要满足各种考虑因素的复杂约束。大多数现有的地图生成方法侧重于游戏机制或地图地形的考虑，而忽视了支持故事的需求。因此，仍然需要进行大量手动调整才能设计出适应特定故事的游戏世界。在这项工作中，我们通过在游戏世界构建流程中引入一个与底层地图生成方法无关的故事情节布局设计额外层面来解决这个问题。

    World-building, the process of developing both the narrative and physical world of a game, plays a vital role in the game's experience. Critically acclaimed independent and AAA video games are praised for strong world building, with game maps that masterfully intertwine with and elevate the narrative, captivating players and leaving a lasting impression. However, designing game maps that support a desired narrative is challenging, as it requires satisfying complex constraints from various considerations. Most existing map generation methods focus on considerations about gameplay mechanics or map topography, while the need to support the story is typically neglected. As a result, extensive manual adjustment is still required to design a game world that facilitates particular stories. In this work, we approach this problem by introducing an extra layer of plot facility layout design that is independent of the underlying map generation method in a world-building pipeline. Concretely, we p
    
[^55]: 使用生成的特权信息学习通过文本到图像扩散模型

    Learning Using Generated Privileged Information by Text-to-Image Diffusion Models. (arXiv:2309.15238v1 [cs.CL])

    [http://arxiv.org/abs/2309.15238](http://arxiv.org/abs/2309.15238)

    本研究提出了一种利用生成的特权信息进行学习的框架，通过文本到图像扩散模型生成合成数据作为特权信息，进一步提升了学生模型在文本分类任务中的性能。

    

    使用生成的特权信息进行学习是一种特殊类型的知识蒸馏，其中教师模型在训练过程中从额外的数据表示中获益，这被称为特权信息，并改善了不看到额外表示的学生模型。然而，在实践中很少可获得特权信息。为此，我们提出了一种文本分类框架，利用文本到图像扩散模型生成人工特权信息。生成的图像和原始文本样本进一步用于基于最先进的基于转换器的架构来训练多模态教师模型。最后，多模态教师的知识被蒸馏到基于文本的（单模态）学生模型中。因此，通过使用生成模型产生合成数据作为特权信息，我们引导学生模型的训练。我们的框架称为利用生成的特权信息进行学习（LUGPI），可以显著提高性能。

    Learning Using Privileged Information is a particular type of knowledge distillation where the teacher model benefits from an additional data representation during training, called privileged information, improving the student model, which does not see the extra representation. However, privileged information is rarely available in practice. To this end, we propose a text classification framework that harnesses text-to-image diffusion models to generate artificial privileged information. The generated images and the original text samples are further used to train multimodal teacher models based on state-of-the-art transformer-based architectures. Finally, the knowledge from multimodal teachers is distilled into a text-based (unimodal) student. Hence, by employing a generative model to produce synthetic data as privileged information, we guide the training of the student model. Our framework, called Learning Using Generated Privileged Information (LUGPI), yields noticeable performance g
    
[^56]: 用户体验设计专业人员对生成性人工智能的感知

    User Experience Design Professionals' Perceptions of Generative Artificial Intelligence. (arXiv:2309.15237v1 [cs.CY])

    [http://arxiv.org/abs/2309.15237](http://arxiv.org/abs/2309.15237)

    经验丰富的设计师认为生成性人工智能（GenAI）在用户体验设计（UXD）实践中具有辅助作用。然而，初级设计师可能会面临技能退化、工作替代和创造力枯竭等问题。这篇论文讨论了人-GenAI协作的一些影响，包括版权与所有权、人类创造力和代理性以及AI素养和获取。

    

    在创意专业人员中，生成性人工智能（GenAI）引起了对其能力的兴奋和对未预期后果的担忧。GenAI如何影响用户体验设计（UXD）实践，并且这些担忧是否合理？我们采访了20位UX设计师，他们拥有丰富的经验，来自各种公司（创业公司到大型企业）。我们询问他们的实践特征，并了解他们的态度、关注点和期望。我们发现，经验丰富的设计师对他们的原创性、创造力和共情能力充满信心，并认为GenAI的角色是辅助性的。他们强调了"享受"和"代理"这两个独特的人类因素，在这两个方面人类仍然是"AI对齐"的仲裁者。然而，技能退化、工作替代和创造力枯竭可能对初级设计师产生负面影响。我们讨论了人-GenAI协作的影响，特别是版权和所有权、人类创造力和代理性，以及AI素养和获取方面。通过这个视角，我们将我们的发现与前人研究进行了比较。

    Among creative professionals, Generative Artificial Intelligence (GenAI) has sparked excitement over its capabilities and fear over unanticipated consequences. How does GenAI impact User Experience Design (UXD) practice, and are fears warranted? We interviewed 20 UX Designers, with diverse experience and across companies (startups to large enterprises). We probed them to characterize their practices, and sample their attitudes, concerns, and expectations. We found that experienced designers are confident in their originality, creativity, and empathic skills, and find GenAI's role as assistive. They emphasized the unique human factors of "enjoyment" and "agency", where humans remain the arbiters of "AI alignment". However, skill degradation, job replacement, and creativity exhaustion can adversely impact junior designers. We discuss implications for human-GenAI collaboration, specifically copyright and ownership, human creativity and agency, and AI literacy and access. Through the lens 
    
[^57]: 对抗性语音合成的协同水印技术

    Collaborative Watermarking for Adversarial Speech Synthesis. (arXiv:2309.15224v1 [eess.AS])

    [http://arxiv.org/abs/2309.15224](http://arxiv.org/abs/2309.15224)

    本文提出了一种对抗性语音合成的协同水印技术，通过与现有对策模型合作进行训练，实现了对生成语音的有效检测和水印识别。

    

    神经语音合成的进展使得技术不仅接近人类的自然度，而且能够以少量数据进行即时语音克隆，并且借助预训练模型具有高度可访问性。当然，生成内容的潜在泛滥引起了对合成语音检测和水印技术的需求。最近，合成语音检测的研究工作主要集中在自动说话人验证和欺骗对策挑战（ASVspoof）上，该挑战专注于被动对策。本文从另一角度出发，针对生成语音的检测，提出了一种协同训练方案，以在不干扰人类听众的情况下，能够通过协同机器检测到生成语音的水印。我们提出了一种与ASVspoof 2021基线对策模型合作的HiFi-GAN神经声码器的合作训练方案，并展示了其有效性。

    Advances in neural speech synthesis have brought us technology that is not only close to human naturalness, but is also capable of instant voice cloning with little data, and is highly accessible with pre-trained models available. Naturally, the potential flood of generated content raises the need for synthetic speech detection and watermarking. Recently, considerable research effort in synthetic speech detection has been related to the Automatic Speaker Verification and Spoofing Countermeasure Challenge (ASVspoof), which focuses on passive countermeasures. This paper takes a complementary view to generated speech detection: a synthesis system should make an active effort to watermark the generated speech in a way that aids detection by another machine, but remains transparent to a human listener. We propose a collaborative training scheme for synthetic speech watermarking and show that a HiFi-GAN neural vocoder collaborating with the ASVspoof 2021 baseline countermeasure models consis
    
[^58]: 大规模语言模型重评分的低秩适应技术在参数高效的语音识别中的应用

    Low-rank Adaptation of Large Language Model Rescoring for Parameter-Efficient Speech Recognition. (arXiv:2309.15223v1 [cs.CL])

    [http://arxiv.org/abs/2309.15223](http://arxiv.org/abs/2309.15223)

    这篇论文介绍了一种基于低秩适应技术的神经语言建模系统，用于语音识别的输出重评分。通过使用低秩分解方法和优化插入矩阵，该系统能够以更高效的方式将BERT模型适应到新领域，大大减少了训练时间。

    

    我们提出了一种基于低秩适应（LoRA）的神经语言建模系统，用于语音识别输出重评分。尽管预训练的语言模型（如BERT）在第二次重评分中表现出优越的性能，但将预训练阶段扩展和将预训练模型适应到特定领域的高计算成本限制了它们在重评分中的实际应用。我们提出了一种基于低秩分解的方法，仅使用预训练参数的一小部分（0.08%）来训练重评分的BERT模型并将其适应到新领域。这些插入的矩阵通过相关性正则化损失和判别性训练目标进行优化。所提出的低秩适应Rescore-BERT（LoRB）体系结构在LibriSpeech和内部数据集上评估，训练时间减少了5.4至3.6倍。

    We propose a neural language modeling system based on low-rank adaptation (LoRA) for speech recognition output rescoring. Although pretrained language models (LMs) like BERT have shown superior performance in second-pass rescoring, the high computational cost of scaling up the pretraining stage and adapting the pretrained models to specific domains limit their practical use in rescoring. Here we present a method based on low-rank decomposition to train a rescoring BERT model and adapt it to new domains using only a fraction (0.08%) of the pretrained parameters. These inserted matrices are optimized through a discriminative training objective along with a correlation-based regularization loss. The proposed low-rank adaptation Rescore-BERT (LoRB) architecture is evaluated on LibriSpeech and internal datasets with decreased training times by factors between 5.4 and 3.6.
    
[^59]: 保守的世界模型

    Conservative World Models. (arXiv:2309.15178v1 [cs.LG])

    [http://arxiv.org/abs/2309.15178](http://arxiv.org/abs/2309.15178)

    在零样本强化学习中，研究人员探索了在小样本数据集上训练时，前向-后向算法性能下降的问题，并使用保守性算法来缓解此问题。实验证明，保守的前向-后向算法在总体上表现更好，甚至超过了特定任务的基准算法。

    

    零样本强化学习承诺在离线预训练阶段后，提供能够在任何环境中执行任何任务的代理。前向-后向（FB）表示在这个理想的实现上取得了显著进展，可以在这种设置中达到特定任务代理的85%的性能。然而，这样的性能取决于对于大规模且多样化的数据集的访问，而大多数真实问题无法期望这样的数据集。在这里，我们探讨了在训练集缺乏多样性的情况下FB性能如何降低，并通过保守性来减轻这种情况，这是一个成熟的离线RL算法的特点。我们在各种数据集、领域和任务上评估了我们的方法家族，在总体上达到了150%的普通FB性能。有些令人惊讶的是，保守的FB算法在没有访问奖励标签且需要维护所有任务策略的情况下，也优于特定任务基线。

    Zero-shot reinforcement learning (RL) promises to provide agents that can perform any task in an environment after an offline pre-training phase. Forward-backward (FB) representations represent remarkable progress towards this ideal, achieving 85% of the performance of task-specific agents in this setting. However, such performance is contingent on access to large and diverse datasets for pre-training, which cannot be expected for most real problems. Here, we explore how FB performance degrades when trained on small datasets that lack diversity, and mitigate it with conservatism, a well-established feature of performant offline RL algorithms. We evaluate our family of methods across various datasets, domains and tasks, reaching 150% of vanilla FB performance in aggregate. Somewhat surprisingly, conservative FB algorithms also outperform the task-specific baseline, despite lacking access to reward labels and being required to maintain policies for all tasks. Conservative FB algorithms p
    
[^60]: 揭示空间-时间掩蔽自动编码器在多元时间序列预测中的力量

    Revealing the Power of Spatial-Temporal Masked Autoencoders in Multivariate Time Series Forecasting. (arXiv:2309.15169v1 [cs.LG])

    [http://arxiv.org/abs/2309.15169](http://arxiv.org/abs/2309.15169)

    提出了一个利用空间-时间掩蔽自动编码器（STMAE）来提高多元时间序列（MTS）预测性能的框架，通过新颖的双掩蔽策略处理部分可见的MTS数据，包括空间掩蔽和时间掩蔽。

    

    多元时间序列（MTS）预测涉及基于历史观测来预测未来时间序列数据。现有研究主要强调开发能够明确捕捉时间序列变量之间的空间依赖性和时间相关性的复杂空间-时间模型。然而，最近的进展受到了数据稀缺性和模型鲁棒性的挑战。为了解决这些问题，我们提出了空间-时间掩蔽自动编码器（STMAE），这是一个MTS预测框架，利用掩蔽自动编码器来提高空间-时间基线模型的性能。STMAE包括两个学习阶段。在预训练阶段，采用编码器-解码器架构。编码器通过一种新颖的双掩蔽策略处理部分可见的MTS数据，包括基于偏置随机游走的空间掩蔽和基于补丁的时间掩蔽。随后，解码器旨在重构两个掩蔽对应物。

    Multivariate time series (MTS) forecasting involves predicting future time series data based on historical observations. Existing research primarily emphasizes the development of complex spatial-temporal models that capture spatial dependencies and temporal correlations among time series variables explicitly. However, recent advances have been impeded by challenges relating to data scarcity and model robustness. To address these issues, we propose Spatial-Temporal Masked Autoencoders (STMAE), an MTS forecasting framework that leverages masked autoencoders to enhance the performance of spatial-temporal baseline models. STMAE consists of two learning stages. In the pretraining stage, an encoder-decoder architecture is employed. The encoder processes the partially visible MTS data produced by a novel dual-masking strategy, including biased random walk-based spatial masking and patch-based temporal masking. Subsequently, the decoders aim to reconstruct the masked counterparts from both spa
    
[^61]: 使用场景先验的可推广神经场进行3D重建

    3D Reconstruction with Generalizable Neural Fields using Scene Priors. (arXiv:2309.15164v1 [cs.CV])

    [http://arxiv.org/abs/2309.15164](http://arxiv.org/abs/2309.15164)

    使用场景先验的可推广神经场方法，利用单个RGB-D图像映射场景，无需融合模块即可重建完整的场景，具有较好的灵活性和扩展性。

    

    最近神经场的进展极大地推动了高保真度的3D场景重建。然而，大多数现有方法对每个场景都要从头开始训练一个独立的网络，这种方法不具有可扩展性，效率低下，且在有限视角下无法产生良好的结果。而基于学习的多视图立体方法在一定程度上解决了这个问题，但其多视图设置使得它在扩展和广泛应用方面不太灵活。相反，我们引入了训练可推广的融入场景先验的神经场（NFPs）方法。NFP网络将任何单视角的RGB-D图像映射成有符号距离和辐射值。通过在体积空间中合并单帧，可以重建完整的场景，无需融合模块，从而提供更好的灵活性。场景先验可以在大规模数据集上进行训练，使得能够快速适应使用较少视角重建新场景。NFP不仅展示了SOTA场景重建性能，

    High-fidelity 3D scene reconstruction has been substantially advanced by recent progress in neural fields. However, most existing methods train a separate network from scratch for each individual scene. This is not scalable, inefficient, and unable to yield good results given limited views. While learning-based multi-view stereo methods alleviate this issue to some extent, their multi-view setting makes it less flexible to scale up and to broad applications. Instead, we introduce training generalizable Neural Fields incorporating scene Priors (NFPs). The NFP network maps any single-view RGB-D image into signed distance and radiance values. A complete scene can be reconstructed by merging individual frames in the volumetric space WITHOUT a fusion module, which provides better flexibility. The scene priors can be trained on large-scale datasets, allowing for fast adaptation to the reconstruction of a new scene with fewer views. NFP not only demonstrates SOTA scene reconstruction performa
    
[^62]: AI算法在电动汽车能量管理中的应用综述

    A Review on AI Algorithms for Energy Management in E-Mobility Services. (arXiv:2309.15140v1 [cs.LG])

    [http://arxiv.org/abs/2309.15140](http://arxiv.org/abs/2309.15140)

    本文综述了AI算法在电动汽车能量管理中的应用，并探讨了其在解决各种挑战和实现能量管理的有效性方面的作用。

    

    电动出行作为解决交通部门紧迫的环境和可持续性问题的关键解决方案已经崛起。化石燃料的消耗、不断上升的温室气体排放以及对抗气候变化的迫切需求凸显了向电动汽车发展的重要性。本文旨在探索人工智能在电动汽车能量管理中面临的各种挑战，并提出解决方案。这些挑战涉及关键因素如续航焦虑、充电速率优化以及电动汽车能量存储的寿命。通过分析现有文献，我们深入探讨了人工智能在解决这些问题和实现电动汽车能量管理有效性方面的作用。我们的目标是提供当前研究领域的最新发展概述，并提出未来研究的有效途径。

    E-mobility, or electric mobility, has emerged as a pivotal solution to address pressing environmental and sustainability concerns in the transportation sector. The depletion of fossil fuels, escalating greenhouse gas emissions, and the imperative to combat climate change underscore the significance of transitioning to electric vehicles (EVs). This paper seeks to explore the potential of artificial intelligence (AI) in addressing various challenges related to effective energy management in e-mobility systems (EMS). These challenges encompass critical factors such as range anxiety, charge rate optimization, and the longevity of energy storage in EVs. By analyzing existing literature, we delve into the role that AI can play in tackling these challenges and enabling efficient energy management in EMS. Our objectives are twofold: to provide an overview of the current state-of-the-art in this research domain and propose effective avenues for future investigations. Through this analysis, we a
    
[^63]: PINF：物理约束深度学习的连续标准化流

    PINF: Continuous Normalizing Flows for Physics-Constrained Deep Learning. (arXiv:2309.15139v1 [cs.LG])

    [http://arxiv.org/abs/2309.15139](http://arxiv.org/abs/2309.15139)

    本文提出了PINF，这是物理约束深度学习的连续标准化流的一种扩展。该方法通过特征值法则和扩散来解决高维时变和稳态福克-普朗克方程。

    

    概率密度的标准化约束对于解决福克-普朗克方程构成了重大挑战。标准化流是一种可逆生成模型，利用变量变换公式确保概率密度守恒，并能够学习复杂数据分布。本文介绍了连续标准化流的新颖扩展——物理约束标准化流（PINF），通过特征值法则结合扩散，实现了无网格和无因果性的高效解决高维时变和稳态福克-普朗克方程。

    The normalization constraint on probability density poses a significant challenge for solving the Fokker-Planck equation. Normalizing Flow, an invertible generative model leverages the change of variables formula to ensure probability density conservation and enable the learning of complex data distributions. In this paper, we introduce Physics-Informed Normalizing Flows (PINF), a novel extension of continuous normalizing flows, incorporating diffusion through the method of characteristics. Our method, which is mesh-free and causality-free, can efficiently solve high dimensional time-dependent and steady-state Fokker-Planck equations.
    
[^64]: 深度生成方法用于发电系统预测轨迹的生成

    Deep Generative Methods for Producing Forecast Trajectories in Power Systems. (arXiv:2309.15137v1 [cs.LG])

    [http://arxiv.org/abs/2309.15137](http://arxiv.org/abs/2309.15137)

    该论文研究了深度生成方法在发电系统预测轨迹中的应用，通过adapt autoregressive networks和normalizing flows捕捉多变量时间序列的时空相关性，相比当前的copula-based统计方法表现出更好的有效性。实验结果基于法国TSO RTE风力预测数据。

    

    随着可再生能源在电力混合中的扩张，电网的变化性将增加，因此需要加强系统以保证其安全性。因此，输电系统运营商必须进行分析，模拟未来发电系统的运行情况。然后，这些模拟结果被用作决策过程的输入。在这种情况下，我们研究使用深度学习模型来生成能源产量和负荷预测轨迹。为了捕捉这些多变量时间序列中的时空相关性，我们改进了自回归网络和归一化流模型，并证明它们对比当前基于copula的统计方法的有效性。我们对法国输电系统运营商RTE的风力预测数据进行了大量实验，并使用特定的时间序列生成评估指标比较了不同的模型。

    With the expansion of renewables in the electricity mix, power grid variability will increase, hence a need to robustify the system to guarantee its security. Therefore, Transport System Operators (TSOs) must conduct analyses to simulate the future functioning of power systems. Then, these simulations are used as inputs in decision-making processes. In this context, we investigate using deep learning models to generate energy production and load forecast trajectories. To capture the spatiotemporal correlations in these multivariate time series, we adapt autoregressive networks and normalizing flows, demonstrating their effectiveness against the current copula-based statistical approach. We conduct extensive experiments on the French TSO RTE wind forecast data and compare the different models with \textit{ad hoc} evaluation metrics for time series generation.
    
[^65]: 对比度连续多视角聚类与过滤结构融合

    Contrastive Continual Multi-view Clustering with Filtered Structural Fusion. (arXiv:2309.15135v1 [cs.LG])

    [http://arxiv.org/abs/2309.15135](http://arxiv.org/abs/2309.15135)

    提出了一种名为对比度连续多视角聚类与过滤结构融合（CCMVC-FSF）的新方法，用于解决多视角聚类在实时数据收集中的困难。该方法旨在防止先前知识遗忘和利用数据相关性指导新视图的聚类过程。

    

    多视角聚类适用于先前收集视图并提取一致和互补信息的应用，但忽略了数据视图按顺序收集的实时数据的情况。为了解决这个问题，我们提出了一种名为对比度连续多视角聚类与过滤结构融合（CCMVC-FSF）的新方法，以应对先前知识遗忘和新视图聚类的问题。

    Multi-view clustering thrives in applications where views are collected in advance by extracting consistent and complementary information among views. However, it overlooks scenarios where data views are collected sequentially, i.e., real-time data. Due to privacy issues or memory burden, previous views are not available with time in these situations. Some methods are proposed to handle it but are trapped in a stability-plasticity dilemma. In specific, these methods undergo a catastrophic forgetting of prior knowledge when a new view is attained. Such a catastrophic forgetting problem (CFP) would cause the consistent and complementary information hard to get and affect the clustering performance. To tackle this, we propose a novel method termed Contrastive Continual Multi-view Clustering with Filtered Structural Fusion (CCMVC-FSF). Precisely, considering that data correlations play a vital role in clustering and prior knowledge ought to guide the clustering process of a new view, we de
    
[^66]: 从资产流到状态、行动和意图的发现：加密货币中的早期恶意检测

    From Asset Flow to Status, Action and Intention Discovery: Early Malice Detection in Cryptocurrency. (arXiv:2309.15133v1 [cs.LG])

    [http://arxiv.org/abs/2309.15133](http://arxiv.org/abs/2309.15133)

    本文提出了一种用于比特币的早期恶意检测的意图监控系统，通过定义资产转移路径和提取状态和行动，实现了对不同恶意类型的检测和发现。

    

    由于加密货币交易主体的伪匿名性质，加密货币往往比传统金融资产更容易受到非法活动的影响。理想的检测模型应该满足早期检测、良好可解释性和适用于各种非法活动的三个关键属性。然而，现有的解决方案无法满足所有这些要求，因为它们大多依赖于深度学习而缺乏可解释性，并且只适用于特定非法类型的回顾性分析。为了解决所有这些挑战，我们提出了一种用于比特币 (BTC) 的早期恶意检测的意图监控系统，其中某个地址的链上记录数据比其他加密货币平台更稀缺。我们首先使用基于决策树的特征选择和补充（DT-SC）来定义资产转移路径，为不同的恶意类型构建不同的特征集。然后，通过状态/行动提案模块（S/A-PM）获取可能的状态和行动，进一步发现恶意意图。

    Cryptocurrency has been subject to illicit activities probably more often than traditional financial assets due to the pseudo-anonymous nature of its transacting entities. An ideal detection model is expected to achieve all three critical properties of (I) early detection, (II) good interpretability, and (III) versatility for various illicit activities. However, existing solutions cannot meet all these requirements, as most of them heavily rely on deep learning without interpretability and are only available for retrospective analysis of a specific illicit type. To tackle all these challenges, we propose Intention-Monitor for early malice detection in Bitcoin (BTC), where the on-chain record data for a certain address are much scarcer than other cryptocurrency platforms. We first define asset transfer paths with the Decision-Tree based feature Selection and Complement (DT-SC) to build different feature sets for different malice types. Then, the Status/Action Proposal Module (S/A-PM) an
    
[^67]: 用CogEval评估大型语言模型中的认知地图和规划能力

    Evaluating Cognitive Maps and Planning in Large Language Models with CogEval. (arXiv:2309.15129v1 [cs.AI])

    [http://arxiv.org/abs/2309.15129](http://arxiv.org/abs/2309.15129)

    这项研究提出了CogEval协议，用于系统评估大型语言模型的认知能力，并使用该协议对八个LLMs的认知地图和规划能力进行了评估。

    

    最近，大量的研究声称大型语言模型（LLMs）具有新兴的认知能力。然而，大多数研究依赖于案例，忽视了训练集的污染，或者缺乏涉及多个任务、控制条件、多次迭代和统计鲁棒性测试的系统评估。在这里，我们做出了两个重大贡献。首先，我们提出了CogEval，这是一个受认知科学启发的协议，用于对大型语言模型的认知能力进行系统评估。CogEval协议可以用于评估各种能力。其次，我们使用CogEval协议对八个LLMs（OpenAI GPT-4、GPT-3.5-turbo-175B、davinci-003-175B、Google Bard、Cohere-xlarge-52.4B、Anthropic Claude-1-52B、LLaMA-13B和Alpaca-7B）的认知地图和规划能力进行了系统评估。我们的任务提示基于人类实验，既具有评估规划的已建立构造效度，又不存在于LLM的训练集中。我们发现，尽管LLMs展示了一些

    Recently an influx of studies claim emergent cognitive abilities in large language models (LLMs). Yet, most rely on anecdotes, overlook contamination of training sets, or lack systematic Evaluation involving multiple tasks, control conditions, multiple iterations, and statistical robustness tests. Here we make two major contributions. First, we propose CogEval, a cognitive science-inspired protocol for the systematic evaluation of cognitive capacities in Large Language Models. The CogEval protocol can be followed for the evaluation of various abilities. Second, here we follow CogEval to systematically evaluate cognitive maps and planning ability across eight LLMs (OpenAI GPT-4, GPT-3.5-turbo-175B, davinci-003-175B, Google Bard, Cohere-xlarge-52.4B, Anthropic Claude-1-52B, LLaMA-13B, and Alpaca-7B). We base our task prompts on human experiments, which offer both established construct validity for evaluating planning, and are absent from LLM training sets. We find that, while LLMs show a
    
[^68]: 可解释的AI艺术中的可持续性

    Explainable Sustainability for AI in the Arts. (arXiv:2309.14877v1 [cs.HC])

    [http://arxiv.org/abs/2309.14877](http://arxiv.org/abs/2309.14877)

    这篇论文介绍了为AI艺术开发环境可持续性反思系统的两个实证研究，并引入了可解释的AI艺术中的可持续性。

    

    AI在艺术实践中越来越受欢迎，但是用于通知从业者有关AI的环境影响（以及其他可持续性问题）的工具适用于其他背景环境，而非创意实践背景，这使得艺术家和创意从业者无法获取AI工具和可持续性问题的相关信息。在这篇立场论文中，我描述了两个旨在为AI艺术开发环境可持续性反思系统的经验研究，并讨论和介绍了可解释的AI艺术中的可持续性。

    AI is becoming increasingly popular in artistic practices, but the tools for informing practitioners about the environmental impact (and other sustainability implications) of AI are adapted for other contexts than creative practices -- making the tools and sustainability implications of AI not accessible for artists and creative practitioners. In this position paper, I describe two empirical studies that aim to develop environmental sustainability reflection systems for AI Arts, and discuss and introduce Explainable Sustainability in for AI Arts.
    
[^69]: Era Splitting.（arXiv:2309.14496v1 [cs.LG]）

    Era Splitting. (arXiv:2309.14496v1 [cs.LG])

    [http://arxiv.org/abs/2309.14496](http://arxiv.org/abs/2309.14496)

    本研究提出了两种新的分裂准则，使得决策树模型能够利用时代信息进行优化，从而将超分布泛化研究中的思想应用于决策树模型。

    

    现实生活中的机器学习问题在时间和空间上会呈现出数据的分布变化。这种行为超出了传统的经验风险最小化范式的范围，该范式假设数据在时间和地点上是独立同分布的。新兴的超分布泛化领域通过将环境或时代信息融入算法中，来应对这个现实。迄今为止，大部分研究都集中在线性模型和/或神经网络上。在本研究中，我们针对决策树模型，包括随机森林和梯度提升决策树，开发了两种新的分裂准则，使得树模型能够利用与每个数据点相关的时代信息，来找到在数据的所有不相交时代中都是最优的切分点，从而将超分布泛化研究中的思想应用于决策树模型。

    Real life machine learning problems exhibit distributional shifts in the data from one time to another or from on place to another. This behavior is beyond the scope of the traditional empirical risk minimization paradigm, which assumes i.i.d. distribution of data over time and across locations. The emerging field of out-of-distribution (OOD) generalization addresses this reality with new theory and algorithms which incorporate environmental, or era-wise information into the algorithms. So far, most research has been focused on linear models and/or neural networks. In this research we develop two new splitting criteria for decision trees, which allow us to apply ideas from OOD generalization research to decision tree models, including random forest and gradient-boosting decision trees. The new splitting criteria use era-wise information associated with each data point to allow tree-based models to find split points that are optimal across all disjoint eras in the data, instead of optim
    
[^70]: 自恢复提示：基于基础模型和自恢复的通用服务机器人系统

    Self-Recovery Prompting: Promptable General Purpose Service Robot System with Foundation Models and Self-Recovery. (arXiv:2309.14425v1 [cs.RO])

    [http://arxiv.org/abs/2309.14425](http://arxiv.org/abs/2309.14425)

    本文研究开发了一个通用服务机器人系统，该系统可以根据不同任务和环境的变化进行自适应，并通过自恢复机制解决信息不足、计划生成错误和执行失败等问题，实现了任务的成功完成。

    

    通用服务机器人（GPSR）能够在各种环境中执行多种任务，需要一个具有高通用性和适应性的系统来应对不同的任务和环境。本文首先基于多个基础模型开发了一个顶层GPSR系统，用于全球竞赛（RoboCup@Home 2023）。该系统既可以适应多种变化，又可以通过提示每个模型来实现自适应。然后，通过分析所开发系统的性能，我们发现在更加现实的GPSR应用设置中存在三种失败类型：信息不足、错误的计划生成和计划执行失败。我们提出了自恢复提示管道，该管道探索必要的信息，并修改其提示来从失败中恢复。我们通过实验证实，具有自恢复机制的系统可以通过解决各种失败案例来完成任务。供补充的视频可在https://sites.google.com/view/srgpsr上找到。

    A general-purpose service robot (GPSR), which can execute diverse tasks in various environments, requires a system with high generalizability and adaptability to tasks and environments. In this paper, we first developed a top-level GPSR system for worldwide competition (RoboCup@Home 2023) based on multiple foundation models. This system is both generalizable to variations and adaptive by prompting each model. Then, by analyzing the performance of the developed system, we found three types of failure in more realistic GPSR application settings: insufficient information, incorrect plan generation, and plan execution failure. We then propose the self-recovery prompting pipeline, which explores the necessary information and modifies its prompts to recover from failure. We experimentally confirm that the system with the self-recovery mechanism can accomplish tasks by resolving various failure cases. Supplementary videos are available at https://sites.google.com/view/srgpsr .
    
[^71]: 看见和听到没被说的话：可解释融合的多模态动机性访谈客户行为分类器

    Seeing and hearing what has not been said; A multimodal client behavior classifier in Motivational Interviewing with interpretable fusion. (arXiv:2309.14398v1 [cs.LG])

    [http://arxiv.org/abs/2309.14398](http://arxiv.org/abs/2309.14398)

    本文提出了一个多模态分类器，在动机性访谈中准确区分了变化话语、持续话语和跟随/中立话语三种类别。该分类器利用文本、声调、面部表情和身体表现等多模态特征，并对AnnoMI数据集进行了注释和训练。研究还找到了决策过程中最重要的模态，提供了宝贵的洞察。

    

    动机性访谈（MI）是一种强调合作并鼓励行为改变的治疗方法。为了评估MI对话的质量，可以利用MISC代码将客户话语分类为变化话语、持续话语或跟随/中立话语。MI对话中变化话语的比例与治疗结果呈正相关，因此准确分类客户话语至关重要。本文提出了一个分类器，利用文本、声调、面部表情和身体表现等多模态特征准确区分三个MISC类别（变化话语、持续话语和跟随/中立话语）。为了训练我们的模型，我们对公开可用的AnnoMI数据集进行注释，收集了文本、音频、面部表情和身体表现等多模态信息。此外，我们还确定了决策过程中最重要的模态，提供了宝贵的洞察。

    Motivational Interviewing (MI) is an approach to therapy that emphasizes collaboration and encourages behavioral change. To evaluate the quality of an MI conversation, client utterances can be classified using the MISC code as either change talk, sustain talk, or follow/neutral talk. The proportion of change talk in a MI conversation is positively correlated with therapy outcomes, making accurate classification of client utterances essential. In this paper, we present a classifier that accurately distinguishes between the three MISC classes (change talk, sustain talk, and follow/neutral talk) leveraging multimodal features such as text, prosody, facial expressivity, and body expressivity. To train our model, we perform annotations on the publicly available AnnoMI dataset to collect multimodal information, including text, audio, facial expressivity, and body expressivity. Furthermore, we identify the most important modalities in the decision-making process, providing valuable insights i
    
[^72]: 增强强化学习中的数据效率：基于网格信息传播的新型想象机制

    Enhancing data efficiency in reinforcement learning: a novel imagination mechanism based on mesh information propagation. (arXiv:2309.14243v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.14243](http://arxiv.org/abs/2309.14243)

    这项研究提出了一种基于网格信息传播的想象机制，在强化学习算法中显著提高了数据效率。通过使信息在不同状态间广播，而不仅仅是在同一状态集中传输，这种机制促进了模型对状态间相互依赖性的理解，并提高了对有限样本信息的学习效率。

    

    强化学习算法在处理高维状态空间和大规模问题时面临数据效率有限的挑战。大多数强化学习方法在更新智能体的评论家时往往仅依赖于同一集中的状态转换信息，这可能导致数据效率低和训练时间消耗亚优。受到人类类比推理能力的启发，我们引入了一种名为“想象机制（IM）”的新型网格信息传播机制，旨在显著提高强化学习算法的数据效率。具体而言，IM使得由单个样本生成的信息能够有效地广播到不同的集中状态，而不仅仅是在同一集中传输。这种能力增强了模型对状态间相互依赖性的理解，并促进了对有限样本信息更高效的学习。为了提高多功能性，我们将IM扩展为一种可以作为

    Reinforcement learning(RL) algorithms face the challenge of limited data efficiency, particularly when dealing with high-dimensional state spaces and large-scale problems. Most of RL methods often rely solely on state transition information within the same episode when updating the agent's Critic, which can lead to low data efficiency and sub-optimal training time consumption. Inspired by human-like analogical reasoning abilities, we introduce a novel mesh information propagation mechanism, termed the 'Imagination Mechanism (IM)', designed to significantly enhance the data efficiency of RL algorithms. Specifically, IM enables information generated by a single sample to be effectively broadcasted to different states across episodes, instead of simply transmitting in the same episode. This capability enhances the model's comprehension of state interdependencies and facilitates more efficient learning of limited sample information. To promote versatility, we extend the IM to function as a
    
[^73]: ICU 重新入院预测的可解释机器学习

    Explainable Machine Learning for ICU Readmission Prediction. (arXiv:2309.13781v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.13781](http://arxiv.org/abs/2309.13781)

    本研究提出了一个标准化且可解释的机器学习流程，用于在多中心数据库中预测加护病房患者的再入院情况。

    

    加护病房（ICU）是一个复杂的医院环境，医生的决策对患者的生命构成高风险。必须遵循一条全面的护理路径来减少并发症。在这种环境中，不确定性、竞争性和非计划性的因素增加了统一实施护理路径的困难。再入院是该路径的困难之一，即患者在短时间内再次入住ICU，导致高死亡率和高资源利用率。一些研究尝试通过患者的医疗信息来预测再入院情况。尽管它们在预测再入院时有一定的成功，但这些研究并未对再入院预测进行适当的评估、描述和理解。本研究提出了一个标准化且可解释的机器学习流程，用于在多中心数据库（即包含166,355名患者的eICU队列，200,859名...）

    The intensive care unit (ICU) comprises a complex hospital environment, where decisions made by clinicians have a high level of risk for the patients' lives. A comprehensive care pathway must then be followed to reduce p complications. Uncertain, competing and unplanned aspects within this environment increase the difficulty in uniformly implementing the care pathway. Readmission contributes to this pathway's difficulty, occurring when patients are admitted again to the ICU in a short timeframe, resulting in high mortality rates and high resource utilisation. Several works have tried to predict readmission through patients' medical information. Although they have some level of success while predicting readmission, those works do not properly assess, characterise and understand readmission prediction. This work proposes a standardised and explainable machine learning pipeline to model patient readmission on a multicentric database (i.e., the eICU cohort with 166,355 patients, 200,859 ad
    
[^74]: ALLURE: 基于迭代上下文学习的文本评估的审计和改进

    ALLURE: Auditing and Improving LLM-based Evaluation of Text using Iterative In-Context-Learning. (arXiv:2309.13701v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.13701](http://arxiv.org/abs/2309.13701)

    ALLURE是一种基于迭代上下文学习的文本评估的审计和改进方法，通过与注释数据进行比较并纳入重大偏差的实例，使用上下文学习提高LLM对文本的评估能力。

    

    从评分论文到总结医疗文件，大型语言模型（LLM）越来越多地用于评估由人类和人工智能生成的文本。然而，尽管它们具有广泛的实用性，LLM存在着明显的失败模式，需要对其文本评估能力进行彻底审计和改进。在这里，我们介绍了ALLURE，一种系统的方法，用于审计大型语言模型的理解和推理错误。ALLURE涉及将LLM生成的评估与注释数据进行比较，并迭代地将重大偏差的实例纳入评估器中，利用上下文学习（ICL）提高和改进LLM对文本的鲁棒评估。通过这个迭代过程，我们改善了评估器LLM的性能，从而减少了在评估过程中对人工标注者的依赖。我们预计ALLURE将在与文本数据评估相关的各个领域，如医学概括等，为LLM的各种应用提供服务。

    From grading papers to summarizing medical documents, large language models (LLMs) are evermore used for evaluation of text generated by humans and AI alike. However, despite their extensive utility, LLMs exhibit distinct failure modes, necessitating a thorough audit and improvement of their text evaluation capabilities. Here we introduce ALLURE, a systematic approach to Auditing Large Language Models Understanding and Reasoning Errors. ALLURE involves comparing LLM-generated evaluations with annotated data, and iteratively incorporating instances of significant deviation into the evaluator, which leverages in-context learning (ICL) to enhance and improve robust evaluation of text by LLMs. Through this iterative process, we refine the performance of the evaluator LLM, ultimately reducing reliance on human annotators in the evaluation process. We anticipate ALLURE to serve diverse applications of LLMs in various domains related to evaluation of textual data, such as medical summarizatio
    
[^75]: 解码放射科医生在准确胸部X光诊断中的集中注意力：一个可控且可解释的人工智能系统。 （arXiv:2309.13550v2 [cs.CV]已更新）

    Decoding Radiologists Intense Focus for Accurate CXR Diagnoses: A Controllable and Interpretable AI System. (arXiv:2309.13550v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.13550](http://arxiv.org/abs/2309.13550)

    这项研究提出了一个新的、统一的、可控且可解释的人工智能系统，用于解码放射科医生在胸部X光诊断中的专注焦点，从而揭示放射学解释过程的认知过程。

    

    在胸部X光（CXR）诊断领域中，现有的研究往往仅关注放射科医生的注视位置，通常通过检测、分割或分类等任务来实现。然而，这些方法常常被设计为黑盒模型，缺乏可解释性。本文引入了一种新颖且统一的可控解释性管道，用于解码放射科医生在CXR诊断中的专注焦点。我们的方法解决了三个关键问题：放射科医生的注视位置、他们在特定区域的注意时长以及他们的诊断结果。通过捕捉放射科医生注视的强度，我们提供了一种统一的解决方案，可以洞察放射学解释过程的认知过程。与当前依赖于黑盒机器学习模型的方法不同，这些模型在诊断过程中容易从整个输入图像中提取错误信息，我们通过有效地屏蔽无关信息来解决这个问题。

    In the field of chest X-ray (CXR) diagnosis, existing works often focus solely on determining where a radiologist looks, typically through tasks such as detection, segmentation, or classification. However, these approaches are often designed as black-box models, lacking interpretability. In this paper, we introduce a novel and unified controllable interpretable pipeline for decoding the intense focus of radiologists in CXR diagnosis. Our approach addresses three key questions: where a radiologist looks, how long they focus on specific areas, and what findings they diagnose. By capturing the intensity of the radiologist's gaze, we provide a unified solution that offers insights into the cognitive process underlying radiological interpretation. Unlike current methods that rely on black-box machine learning models, which can be prone to extracting erroneous information from the entire input image during the diagnosis process, we tackle this issue by effectively masking out irrelevant info
    
[^76]: 基于量子计算的投资组合优化系统：利用未来资产价值和自动减少投资范围

    A Quantum Computing-based System for Portfolio Optimization using Future Asset Values and Automatic Reduction of the Investment Universe. (arXiv:2309.12627v1 [cs.AI])

    [http://arxiv.org/abs/2309.12627](http://arxiv.org/abs/2309.12627)

    本研究提出了一种基于量子计算的投资组合优化系统Q4FuturePOP，它创新地利用未来资产价值进行建模，并引入了一个自动减少投资范围的模块。通过实验讨论了Q4FuturePOP的原型版本中不同模块的初步性能。

    

    量化金融中备受关注的问题之一是投资组合优化问题。针对该问题，近年来利用量子计算的技术得到了广泛应用。本研究介绍了一种名为Q4FuturePOP的基于量子计算的投资组合优化系统，该系统通过以下创新解决了投资组合优化问题：i）该工具针对未来资产预测进行建模，而不是使用历史数据；ii）Q4FuturePOP包括一个智能减少问题复杂性的自动减少投资范围模块。此外，我们还对Q4FuturePOP的原型版本的不同模块的初步性能进行了简要讨论。

    One of the problems in quantitative finance that has received the most attention is the portfolio optimization problem. Regarding its solving, this problem has been approached using different techniques, with those related to quantum computing being especially prolific in recent years. In this study, we present a system called Quantum Computing-based System for Portfolio Optimization with Future Asset Values and Automatic Universe Reduction (Q4FuturePOP), which deals with the Portfolio Optimization Problem considering the following innovations: i) the developed tool is modeled for working with future prediction of assets, instead of historical values; and ii) Q4FuturePOP includes an automatic universe reduction module, which is conceived to intelligently reduce the complexity of the problem. We also introduce a brief discussion about the preliminary performance of the different modules that compose the prototypical version of Q4FuturePOP.
    
[^77]: 大型语言模型对单词级扰动真的具有鲁棒性吗？

    Are Large Language Models Really Robust to Word-Level Perturbations?. (arXiv:2309.11166v1 [cs.CL])

    [http://arxiv.org/abs/2309.11166](http://arxiv.org/abs/2309.11166)

    该论文提出了一种用于评估大型语言模型（LLMs）鲁棒性的新颖方法，使用预训练的奖励模型作为诊断工具。实验证明这种方法在评估LLM鲁棒性方面表现准确。

    

    大型语言模型（LLMs）在规模和能力上的快速发展使它们成为各种下游任务的有前途的工具。除了追求更好的性能和避免对特定提示的激烈反馈外，确保LLM的责任性还需要关注LLMs的鲁棒性。然而，现有的评估方法大多依赖于具有预定义监督标签的传统问答数据集，这与当代LLMs的出色生成能力不一致。为了解决这个问题，我们提出了一种新颖的合理评估方法，利用预训练的奖励模型作为诊断工具来评估LLMs的鲁棒性，我们将其称为合理鲁棒性评估的奖励模型（TREvaL）。我们广泛的实证实验表明，TREval提供了一种准确评估LLM鲁棒性的方法，特别是面对更具挑战性的开放式问题时。

    The swift advancement in the scale and capabilities of Large Language Models (LLMs) positions them as promising tools for a variety of downstream tasks. In addition to the pursuit of better performance and the avoidance of violent feedback on a certain prompt, to ensure the responsibility of the LLM, much attention is drawn to the robustness of LLMs. However, existing evaluation methods mostly rely on traditional question answering datasets with predefined supervised labels, which do not align with the superior generation capabilities of contemporary LLMs. To address this issue, we propose a novel rational evaluation approach that leverages pre-trained reward models as diagnostic tools to evaluate the robustness of LLMs, which we refer to as the Reward Model for Reasonable Robustness Evaluation (TREvaL). Our extensive empirical experiments have demonstrated that TREval provides an accurate method for evaluating the robustness of an LLM, especially when faced with more challenging open 
    
[^78]: 通过困惑度估计污染：量化语言模型评估中的记忆化

    Estimating Contamination via Perplexity: Quantifying Memorisation in Language Model Evaluation. (arXiv:2309.10677v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.10677](http://arxiv.org/abs/2309.10677)

    本文提出了一种新方法，通过困惑度来量化语言模型评估中的污染，而不需要访问完整的训练数据。研究表明，最近的基础模型在阅读理解和摘要基准中存在显著的记忆化，而多项选择问题则受污染较少。

    

    在模型评估中，数据污染变得越来越普遍，因为大型语言模型的大规模训练语料库经常无意中包含基准样本。因此，污染分析已成为可靠模型评估不可避免的一部分。然而，现有的污染分析方法需要访问整个训练数据，这通常对于最新模型来说是保密的。这阻止了社区对这些模型进行严格审计和准确评估其能力。在本文中，我们提出了一种新的方法来在不访问完整训练集的情况下量化污染，即用困惑度来衡量污染的程度。我们的分析提供了证据，表明最近的基础模型在受欢迎的阅读理解和摘要基准中存在显著的记忆化，而多项选择似乎没有那么受污染。

    Data contamination in model evaluation is getting increasingly prevalent as the massive training corpora of large language models often unintentionally include benchmark samples. Therefore, contamination analysis has became an inevitable part of reliable model evaluation. However, existing method of contamination analysis requires the access of the entire training data which is often confidential for recent models. This prevent the community to rigorously audit these models and conduct accurate assessment of their capability. In this paper, we propose a novel method to quantify contamination without the access of the full training set, that measure the extent of contamination with perplexity. Our analysis provides evidence of significant memorisation of recent foundation models in popular reading comprehension, summarisation benchmarks, while multiple choice appears less contaminated.
    
[^79]: AstroPortal: 一个用于天文学、航天学和其他空间主题的本体库概念

    AstroPortal: An ontology repository concept for astronomy, astronautics and other space topics. (arXiv:2309.10288v1 [astro-ph.IM])

    [http://arxiv.org/abs/2309.10288](http://arxiv.org/abs/2309.10288)

    本文介绍了一个用于天文学、航天学和其他空间主题的本体库概念，该库可提供一个集中平台用于搜索、审核和创建与天文相关的本体，以减少研究时间并支持知识组织系统和语义资源的研究。

    

    本文描述了一个用于天文学、航天学和其他空间相关主题的本体库。该库可称为AstroPortal（或SpacePortal）、AstroHub（或SpaceHub）等。创建该库将适用于学术、研究和其他数据密集型领域。它对于太空科学（包括天文学）、地球科学和航天学（航天飞行）等数据密集型学科具有重要意义。该库应提供一个集中的平台，用于搜索、审核和创建与天文相关主题的本体。它可以减少研究时间，同时提供一个用户友好的方式来研究和比较目标领域的知识组织系统或语义资源。由于目标领域中目前不存在可用的库，本文也提出了一个新颖的概念。

    This paper describes a repository for ontologies of astronomy, astronautics, and other space-related topics. It may be called AstroPortal (or SpacePortal), AstroHub (or SpaceHub), etc. The creation of this repository will be applicable to academic, research and other data-intensive sectors. It is relevant for space sciences (including astronomy), Earth science, and astronautics (spaceflight), among other data-intensive disciplines. The repository should provide a centralized platform to search, review and create ontologies for astro-related topics. It thereby can decrease research time, while also providing a user-friendly means to study and compare knowledge organization systems or semantic resources of the target domains. With no apparent repository available on the target domain, this paper also expresses a novel concept.
    
[^80]: 用开放数据驱动的团队推荐促进研究合作

    Promoting Research Collaboration with Open Data Driven Team Recommendation in Response to Call for Proposals. (arXiv:2309.09404v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2309.09404](http://arxiv.org/abs/2309.09404)

    通过利用开放数据和人工智能方法，我们设计了一个系统来推荐团队，使得每个团队能够满足项目要求的技能覆盖，并且平衡候选成员之间的工作分配。

    

    团队建设和促进合作是非常常见的商业活动。一个例子就是TeamingForFunding问题，研究机构和研究人员在向资助机构申请时，希望能够找到合作机会以回应后者的项目申请。我们描述了一个新颖的系统，利用各种人工智能方法来推荐团队，使得每个团队都能够达到机会要求的最高技能覆盖，并且候选成员之间的工作分配是平衡的。我们通过提取开放数据中的项目申请（需求）和研究人员简介（供给）中的技能潜力，使用分类法对其进行归一化，创建了有效的算法来匹配需求和供给。我们创建团队以最大化一个新的衡量短期和长期目标的度量的优势。我们定量验证了我们算法的成功，通过…

    Building teams and promoting collaboration are two very common business activities. An example of these are seen in the TeamingForFunding problem, where research institutions and researchers are interested to identify collaborative opportunities when applying to funding agencies in response to latter's calls for proposals. We describe a novel system to recommend teams using a variety of AI methods, such that (1) each team achieves the highest possible skill coverage that is demanded by the opportunity, and (2) the workload of distributing the opportunities is balanced amongst the candidate members. We address these questions by extracting skills latent in open data of proposal calls (demand) and researcher profiles (supply), normalizing them using taxonomies, and creating efficient algorithms that match demand to supply. We create teams to maximize goodness along a novel metric balancing short- and long-term objectives. We validate the success of our algorithms (1) quantitatively, by e
    
[^81]: 对自编码器的几何角度的研究

    A Geometric Perspective on Autoencoders. (arXiv:2309.08247v1 [cs.LG])

    [http://arxiv.org/abs/2309.08247](http://arxiv.org/abs/2309.08247)

    本文从几何角度研究了自编码器框架，并提出了解决多解和畸变表示问题的几何方法。

    

    本文提出了自编码器框架的几何方面，尽管其重要性，但被相对较少地认识到。给定一组几乎位于某个较低维度流形上的高维数据点，自编码器同时学习流形和其坐标图。这种几何角度自然引发了一些问题，比如“有限的数据点对应于单一的流形吗？”或者“只有一个坐标图可以表示流形吗？”对这些问题的回答是否定的，这意味着给定一个数据集，有多个解的自编码器。因此，它们有时会产生具有严重畸变的潜在空间表示的错误流形。在本文中，我们介绍了解决这些问题的最近的几何方法。

    This paper presents the geometric aspect of the autoencoder framework, which, despite its importance, has been relatively less recognized. Given a set of high-dimensional data points that approximately lie on some lower-dimensional manifold, an autoencoder learns the \textit{manifold} and its \textit{coordinate chart}, simultaneously. This geometric perspective naturally raises inquiries like "Does a finite set of data points correspond to a single manifold?" or "Is there only one coordinate chart that can represent the manifold?". The responses to these questions are negative, implying that there are multiple solution autoencoders given a dataset. Consequently, they sometimes produce incorrect manifolds with severely distorted latent space representations. In this paper, we introduce recent geometric approaches that address these issues.
    
[^82]: 通过拆分和重排BART微调来增强关键短语生成

    Enhancing Keyphrase Generation by BART Finetuning with Splitting and Shuffling. (arXiv:2309.06726v1 [cs.CL])

    [http://arxiv.org/abs/2309.06726](http://arxiv.org/abs/2309.06726)

    本文提出了关注关键短语的BART模型(Keyphrase-Focused BART)，通过拆分和重排的方式来增强关键短语生成的性能。在不出现的关键短语生成任务中，该模型在两个关键短语生成基准数据集上取得了新的最佳得分。

    

    关键短语生成是一项识别最佳代表给定文本主题或主题的短语集的任务。关键短语分为出现和不在出现的关键短语。最近利用序列到序列模型的方法在不出现的关键短语生成上显示出了效果。然而，由于找到不出现的关键短语的难度，性能仍然有限。在本文中，我们提出了关注关键短语的BART模型(Keyphrase-Focused BART)，利用了出现和不出现关键短语生成之间的差异，并对出现和不出现关键短语分别进行了两个独立BART模型的微调。我们进一步展示了关键短语的重排和候选关键短语排序的有效方法。对于不出现的关键短语，在五个关键短语生成基准数据集中，我们的关注关键短语的BART在F1@5上取得了新的最佳得分。

    Keyphrase generation is a task of identifying a set of phrases that best repre-sent the main topics or themes of a given text. Keyphrases are dividend int pre-sent and absent keyphrases. Recent approaches utilizing sequence-to-sequence models show effectiveness on absent keyphrase generation. However, the per-formance is still limited due to the hardness of finding absent keyphrases. In this paper, we propose Keyphrase-Focused BART, which exploits the differ-ences between present and absent keyphrase generations, and performs fine-tuning of two separate BART models for present and absent keyphrases. We further show effective approaches of shuffling keyphrases and candidate keyphrase ranking. For absent keyphrases, our Keyphrase-Focused BART achieved new state-of-the-art score on F1@5 in two out of five keyphrase gen-eration benchmark datasets.
    
[^83]: 语言代理的认知架构

    Cognitive Architectures for Language Agents. (arXiv:2309.02427v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2309.02427](http://arxiv.org/abs/2309.02427)

    本文提出了一种称为CoALA的认知架构，用于组织语言代理的现有研究并规划未来的发展方向。CoALA描述了一个具有模块化记忆组件、结构化行动空间和通用决策过程的语言代理。通过这一框架，有望发展出更强大的语言代理。

    

    最近的研究在大规模语言模型（LLMs）中增加了外部资源（例如互联网）或内部控制流（例如提示链），用于需要基于语境或推理的任务，从而产生了一类新的语言代理。尽管这些代理取得了实证成功，但我们缺乏一个系统的框架来组织现有代理并规划未来的发展。在本文中，我们借鉴了认知科学和符号人工智能的丰富历史，提出了语言代理的认知架构（CoALA）。CoALA描述了一个具有模块化记忆组件、用于与内部记忆和外部环境交互的结构化行动空间以及选择行动的通用决策过程的语言代理。我们使用CoALA对最近的大量研究进行了回顾和组织，并展望了更强大代理的可行方向。总的来说，CoALA将当今的语言代理置于上下文中。

    Recent efforts have augmented large language models (LLMs) with external resources (e.g., the Internet) or internal control flows (e.g., prompt chaining) for tasks requiring grounding or reasoning, leading to a new class of language agents. While these agents have achieved substantial empirical success, we lack a systematic framework to organize existing agents and plan future developments. In this paper, we draw on the rich history of cognitive science and symbolic artificial intelligence to propose Cognitive Architectures for Language Agents (CoALA). CoALA describes a language agent with modular memory components, a structured action space to interact with internal memory and external environments, and a generalized decision-making process to choose actions. We use CoALA to retrospectively survey and organize a large body of recent work, and prospectively identify actionable directions towards more capable agents. Taken together, CoALA contextualizes today's language agents within th
    
[^84]: CPSP: 从音素监督中学习语音概念

    CPSP: Learning Speech Concepts From Phoneme Supervision. (arXiv:2309.00424v1 [eess.AS])

    [http://arxiv.org/abs/2309.00424](http://arxiv.org/abs/2309.00424)

    论文提出了一种名为CPSP的方法，通过对比学习来从语音中提取细粒度的中间表示，使得提取的信息既包含语言内容又去除了发言人身份和声学细节，适用于TTS、VC和ASR等任务。

    

    对于诸如最小监督的文本转语音（TTS）、语音转换（VC）和自动语音识别（ASR）等细粒度生成和识别任务，从语音中提取的中间表示应包含介于文本编码和声学编码之间的信息。语言内容突出，而发言人身份和声学细节等语音信息应该被去除。然而，现有的从语音中提取细粒度中间表示的方法存在冗余性过高和维度爆炸的问题。此外，音频领域中现有的对比学习方法主要关注提取用于下游音频分类任务的全局描述信息，不适合TTS、VC和ASR任务。为了解决这些问题，我们提出了一种名为对比音素-语音预训练（CPSP）的方法，该方法使用三个编码器、一个解码器和对比学习来将音素和语音信息相结合。

    For fine-grained generation and recognition tasks such as minimally-supervised text-to-speech (TTS), voice conversion (VC), and automatic speech recognition (ASR), the intermediate representation extracted from speech should contain information that is between text coding and acoustic coding. The linguistic content is salient, while the paralinguistic information such as speaker identity and acoustic details should be removed. However, existing methods for extracting fine-grained intermediate representations from speech suffer from issues of excessive redundancy and dimension explosion. Additionally, existing contrastive learning methods in the audio field focus on extracting global descriptive information for downstream audio classification tasks, making them unsuitable for TTS, VC, and ASR tasks. To address these issues, we propose a method named Contrastive Phoneme-Speech Pretraining (CPSP), which uses three encoders, one decoder, and contrastive learning to bring phoneme and speech
    
[^85]: 量子噪声驱动的生成扩散模型

    Quantum-Noise-driven Generative Diffusion Models. (arXiv:2308.12013v1 [quant-ph])

    [http://arxiv.org/abs/2308.12013](http://arxiv.org/abs/2308.12013)

    该论文提出了三种量子噪声驱动的生成扩散模型，利用了量子特性以克服传统模型的主要计算困难，并建议将量子噪声视为可利用的特性而非问题。

    

    通过机器学习技术实现的生成模型是从有限的训练样本中推断出复杂和未知数据分布并产生新的合成数据的强大工具。扩散模型是一种新兴的框架，最近在创建合成文本和高质量图像方面已经超越了生成对抗性网络的性能。在这里，我们提出并讨论了扩散模型的量子推generalization，即三种可能在实际量子系统上进行实验的量子噪声驱动的生成扩散模型。我们的想法是利用独特的量子特性，特别是目前可用的有噪声量子处理器不可避免地受到的相干性、纠缠性和噪声之间的非平凡相互作用，以克服传统扩散模型在推断过程中的主要计算负担。因此，我们建议将量子噪声不作为需要检测和解决的问题，而是作为一种可利用的特性，使得扩散模型能够更好地工作。

    Generative models realized with machine learning techniques are powerful tools to infer complex and unknown data distributions from a finite number of training samples in order to produce new synthetic data. Diffusion models are an emerging framework that have recently overcome the performance of the generative adversarial networks in creating synthetic text and high-quality images. Here, we propose and discuss the quantum generalization of diffusion models, i.e., three quantum-noise-driven generative diffusion models that could be experimentally tested on real quantum systems. The idea is to harness unique quantum features, in particular the non-trivial interplay among coherence, entanglement and noise that the currently available noisy quantum processors do unavoidably suffer from, in order to overcome the main computational burdens of classical diffusion models during inference. Hence, we suggest to exploit quantum noise not as an issue to be detected and solved but instead as a ver
    
[^86]: 通过行动和语言提升智能体的沟通和学习能力

    Enhancing Agent Communication and Learning through Action and Language. (arXiv:2308.10842v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.10842](http://arxiv.org/abs/2308.10842)

    通过行动和语言相结合的方式，我们引入了一种新型智能体，其能够同时作为教师和学习者，通过行动演示和语言指令增强了沟通效率，并探索了结合行动和语言沟通模式对学习结果的积极影响。

    

    我们引入了一种新型的GC智能体类别，能够同时充当教师和学习者的角色。借助基于行动的演示和基于语言的指令，这些智能体增强了沟通效率。我们研究了在人类沟通和目标实现中的重要元素——教育学和实用主义的融入，提升了智能体的教学和学习能力。此外，我们探讨了结合行动和语言沟通模式对学习结果的影响，强调了多模式方法的优势。

    We introduce a novel category of GC-agents capable of functioning as both teachers and learners. Leveraging action-based demonstrations and language-based instructions, these agents enhance communication efficiency. We investigate the incorporation of pedagogy and pragmatism, essential elements in human communication and goal achievement, enhancing the agents' teaching and learning capabilities. Furthermore, we explore the impact of combining communication modes (action and language) on learning outcomes, highlighting the benefits of a multi-modal approach.
    
[^87]: 超越识别：用于语言模型的多位水印技术

    Advancing Beyond Identification: Multi-bit Watermark for Language Models. (arXiv:2308.00221v1 [cs.CL])

    [http://arxiv.org/abs/2308.00221](http://arxiv.org/abs/2308.00221)

    本研究提出了一种用于语言模型的多位水印技术——COLOR，可在语言模型生成过程中嵌入可追踪的多位信息，实现了提取水印、即时嵌入和维持文本质量等功能，同时允许零位检测。初步实验显示成功在中等长度的文本中嵌入了32位消息，准确率为91.9％。这项研究有效推进了对语言模型滥用的反制策略。

    

    本研究旨在积极应对大型语言模型在检测机器生成文本方面的滥用。尽管现有方法侧重于检测，但某些恶意滥用需要跟踪对手用户以进行反制。为了解决这个问题，我们提出了“多位水印通过颜色编码”（COLOR）的方法，在语言模型生成过程中嵌入可追踪的多位信息。利用零位水印技术的优势（Kirchenbauer等，2023a），COLOR实现了在没有模型访问权限的情况下提取水印、即时嵌入和维持文本质量的能力，同时允许零位检测。初步实验表明，在中等长度的文本（约500个标记）中成功嵌入了32位消息，准确率为91.9％。这项工作有效地推进了对语言模型滥用进行反制的策略。

    This study aims to proactively tackle misuse of large language models beyond identification of machine-generated text. While existing methods focus on detection, some malicious misuses demand tracing the adversary user for counteracting them. To address this, we propose "Multi-bit Watermark through Color-listing" (COLOR), embedding traceable multi-bit information during language model generation. Leveraging the benefits of zero-bit watermarking (Kirchenbauer et al., 2023a), COLOR enables extraction without model access, on-the-fly embedding, and maintains text quality, while allowing zero-bit detection all at the same time. Preliminary experiments demonstrates successful embedding of 32-bit messages with 91.9% accuracy in moderate-length texts ($\sim$500 tokens). This work advances strategies to counter language model misuse effectively.
    
[^88]: 超越规模：多样性系数作为数据质量指标证明了LLMs是在形式多样的数据上预先训练的

    Beyond Scale: the Diversity Coefficient as a Data Quality Metric Demonstrates LLMs are Pre-trained on Formally Diverse Data. (arXiv:2306.13840v1 [cs.CL])

    [http://arxiv.org/abs/2306.13840](http://arxiv.org/abs/2306.13840)

    本论文提出使用多样性系数作为LLM预训练数据质量的指标，研究表明公开可用的LLM数据集的多样性系数很高。

    

    当前，预先训练强大的大语言模型(LLMs)的趋势主要集中在模型和数据集规模的扩大。然而，预先训练数据的质量对于训练强大的LLMs来说是一个重要因素，但它是一个模糊的概念，尚未完全表征。因此，我们使用最近提出的Task2Vec多样性系数来基于数据质量的形式方面，超越规模本身。具体而言，我们测量公开可用的预先训练数据集的多样性系数，以证明它们的形式多样性高于理论的下限和上限。此外，为了建立对多样性系数的信心，我们进行可解释性实验，并发现该系数与多样性的直观属性相吻合，例如，随着潜在概念数量的增加，它增加。我们得出结论，多样性系数是可靠的，表明公开可用的LLM数据集的多样性系数很高，并推测它可以作为预训练LLMs模型的数据质量指标。

    Current trends to pre-train capable Large Language Models (LLMs) mostly focus on scaling of model and dataset size. However, the quality of pre-training data is an important factor for training powerful LLMs, yet it is a nebulous concept that has not been fully characterized. Therefore, we use the recently proposed Task2Vec diversity coefficient to ground and understand formal aspects of data quality, to go beyond scale alone. Specifically, we measure the diversity coefficient of publicly available pre-training datasets to demonstrate that their formal diversity is high when compared to theoretical lower and upper bounds. In addition, to build confidence in the diversity coefficient, we conduct interpretability experiments and find that the coefficient aligns with intuitive properties of diversity, e.g., it increases as the number of latent concepts increases. We conclude the diversity coefficient is reliable, show it's high for publicly available LLM datasets, and conjecture it can be
    
[^89]: 通过Clausal Tableaux实现范围限制插值

    Range-Restricted Interpolation through Clausal Tableaux. (arXiv:2306.03572v1 [cs.LO])

    [http://arxiv.org/abs/2306.03572](http://arxiv.org/abs/2306.03572)

    通过Clausal Tableaux证明系统实现可行的范围限制插值算法。

    

    本文展示了如何通过一阶逻辑的Clausal Tableaux证明系统，从输入到输出传递变化的范围限制和Horn性质。本文的重点是将证明结构的操作与高度优化的一阶证明器结合起来，实现可行的实现方法。主要应用于查询合成和插值重构。

    We show how variations of range-restriction and also the Horn property can be passed from inputs to outputs of Craig interpolation in first-order logic. The proof system is clausal tableaux, which stems from first-order ATP. Our results are induced by a restriction of the clausal tableau structure, which can be achieved in general by a proof transformation, also if the source proof is by resolution/paramodulation. Primarily addressed applications are query synthesis and reformulation with interpolation. Our methodical approach combines operations on proof structures with the immediate perspective of feasible implementation through incorporating highly optimized first-order provers.
    
[^90]: 学习采样字典以实现高效且具有普适性的机器人运动规划（使用Transformer）

    Learning Sampling Dictionaries for Efficient and Generalizable Robot Motion Planning with Transformers. (arXiv:2306.00851v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2306.00851](http://arxiv.org/abs/2306.00851)

    提出了一种名为VQ-MPT的方法，通过学习采样字典和Transformer模型，使机器人运动规划更高效且具有普适性。此方法将规划空间分割为离散集合，并选择性地选择采样区域，以克服现有规划方法的缺点。

    

    运动规划是机器人应用中不可或缺的部分，比如自动驾驶、外科手术机器人和工业手臂。现有的规划方法在高维空间中缺乏可扩展性，而最近的基于学习的规划器在加速基于采样的运动规划器方面显示出了潜力，但在适用于分布外环境方面缺乏普适性。为了解决这个问题，我们提出了一种新方法，即矢量量化运动规划Transformer（VQ-MPT），克服了以前学习方法的关键普适性和扩展性缺点。VQ-MPT包括两个阶段。第一阶段是矢量量化—变分自动编码器模型，通过有限数量的采样分布学习表示规划空间，第二阶段是自回归模型，通过从学习的采样分布集中选择来构建SMP的采样区域。通过将大规划空间分割为离散集合并选择性地选择采样区域，我们的方法能够提高普适性和可扩展性。

    Motion planning is integral to robotics applications such as autonomous driving, surgical robots, and industrial manipulators. Existing planning methods lack scalability to higher-dimensional spaces, while recent learning based planners have shown promise in accelerating sampling-based motion planners (SMP) but lack generalizability to out-of-distribution environments. To address this, we present a novel approach, Vector Quantized-Motion Planning Transformers (VQ-MPT) that overcomes the key generalization and scaling drawbacks of previous learning-based methods. VQ-MPT consists of two stages. Stage 1 is a Vector Quantized-Variational AutoEncoder model that learns to represent the planning space using a finite number of sampling distributions, and stage 2 is an Auto-Regressive model that constructs a sampling region for SMPs by selecting from the learned sampling distribution sets. By splitting large planning spaces into discrete sets and selectively choosing the sampling regions, our p
    
[^91]: 优化的自定义数据集用于高效检测水下垃圾

    Optimized Custom Dataset for Efficient Detection of Underwater Trash. (arXiv:2305.16460v1 [cs.CV])

    [http://arxiv.org/abs/2305.16460](http://arxiv.org/abs/2305.16460)

    本文提出了一种自定义数据集和有效检测方法，旨在通过增加垃圾实例的多样性，在深入水下环境中提高其检测精度。

    

    准确评估和清除潜在的水下废物对于保护海洋生物和环境至关重要。本文针对水下垃圾检测所存在的挑战，如光折射、吸收、悬浮颗粒和色彩扭曲等因素，提出了一种自定义数据集和有效检测方法。该数据集涵盖了多种水下环境，并包括对废弃物实例的精确定位标注。最终，使用最先进的深度学习结构，目的是通过增加垃圾实例的多样性，在深入水下环境中提高其检测精度。

    Accurately quantifying and removing submerged underwater waste plays a crucial role in safeguarding marine life and preserving the environment. While detecting floating and surface debris is relatively straightforward, quantifying submerged waste presents significant challenges due to factors like light refraction, absorption, suspended particles, and color distortion. This paper addresses these challenges by proposing the development of a custom dataset and an efficient detection approach for submerged marine debris. The dataset encompasses diverse underwater environments and incorporates annotations for precise labeling of debris instances. Ultimately, the primary objective of this custom dataset is to enhance the diversity of litter instances and improve their detection accuracy in deep submerged environments by leveraging state-of-the-art deep learning architectures.
    
[^92]: GRACE++：通过神经编解码器实现抗丢包的实时视频

    GRACE++: Loss-Resilient Real-Time Video through Neural Codecs. (arXiv:2305.12333v2 [cs.MM] UPDATED)

    [http://arxiv.org/abs/2305.12333](http://arxiv.org/abs/2305.12333)

    GRACE++是一个抗丢包的实时视频系统，通过神经视频编解码器实现了在各种丢包情况下保持用户体验质量的目标。

    

    在实时视频通信中，由于严格的延迟要求，重新传输丢失的数据包在高延迟网络下是不可行的。为了应对没有重传的丢包情况，使用了两种主要策略--基于编码器的前向差错纠正（FEC）和基于解码器的错误隐藏。前者在传输之前用冗余编码数据，但提前确定最佳冗余级别是具有挑战性的。后者从部分收到的帧中重建视频，但将帧划分为独立编码的分区会降低压缩效率，并且丢失的信息在没有适应编码器的情况下无法有效地被解码器恢复。我们提出了一种名为GRACE++的抗丢包实时视频系统，通过一种新的神经视频编解码器，它能够在各种丢包情况下保持用户的体验质量（QoE）。

    In real-time video communication, retransmitting lost packets over high-latency networks is not viable due to strict latency requirements. To counter packet losses without retransmission, two primary strategies are employed -- encoder-based forward error correction (FEC) and decoder-based error concealment. The former encodes data with redundancy before transmission, yet determining the optimal redundancy level in advance proves challenging. The latter reconstructs video from partially received frames, but dividing a frame into independently coded partitions inherently compromises compression efficiency, and the lost information cannot be effectively recovered by the decoder without adapting the encoder.  We present a loss-resilient real-time video system called GRACE++, which preserves the user's quality of experience (QoE) across a wide range of packet losses through a new neural video codec. Central to GRACE++'s enhanced loss resilience is its joint training of the neural encoder an
    
[^93]: 扩散模型的结构剪枝

    Structural Pruning for Diffusion Models. (arXiv:2305.10924v1 [cs.LG])

    [http://arxiv.org/abs/2305.10924](http://arxiv.org/abs/2305.10924)

    本文提出了一种名为Diff-Pruning的高效压缩方法，通过一个Taylor展开过程来识别重要权重，从而从预先存在的模型中学习轻量级扩散模型，性能稳定，并在训练效率上显著提高。

    

    生成建模最近取得了显著的进展，主要是因为扩散概率模型（DPM）的转型意义。然而，这些模型的令人印象深刻的能力通常涉及到显著的计算开销，在训练和推理期间都是如此。为了应对这一挑战，我们提出了Diff-Pruning，一种专为从预先存在的模型中学习轻量级扩散模型而设计的高效压缩方法，无需进行大量的重新训练。Diff-Pruning的本质是通过剪枝时间步长的Taylor展开，在过滤掉无贡献扩散步骤和整合有信息的梯度来识别重要权重的过程。我们在四个不同数据集上进行的实证评估突出了我们所提出方法的两个主要优点：1）效率：它可以以原始训练投入的仅10％到20％的代价实现约50％的FLOPs减少; 2）一致性: 剪枝后的扩散模型产生的效果与原始模型相当，不会影响生成建模的质量。

    Generative modeling has recently undergone remarkable advancements, primarily propelled by the transformative implications of Diffusion Probabilistic Models (DPMs). The impressive capability of these models, however, often entails significant computational overhead during both training and inference. To tackle this challenge, we present Diff-Pruning, an efficient compression method tailored for learning lightweight diffusion models from pre-existing ones, without the need for extensive re-training. The essence of Diff-Pruning is encapsulated in a Taylor expansion over pruned timesteps, a process that disregards non-contributory diffusion steps and ensembles informative gradients to identify important weights. Our empirical assessment, undertaken across four diverse datasets highlights two primary benefits of our proposed method: 1) Efficiency: it enables approximately a 50% reduction in FLOPs at a mere 10% to 20% of the original training expenditure; 2) Consistency: the pruned diffusio
    
[^94]: 有意义的因果聚合和悖论性混淆

    Meaningful Causal Aggregation and Paradoxical Confounding. (arXiv:2304.11625v1 [cs.AI])

    [http://arxiv.org/abs/2304.11625](http://arxiv.org/abs/2304.11625)

    聚合变量上的因果性不确定性可能会使得原本不混淆的因果关系变得混淆，在实际应用中，我们需要接受宏观因果关系通常只与微观状态相关的事实。

    

    在聚合变量中，干预的影响通常是不确定的，因为相同的宏观干预的不同微观实现可能会导致下游宏观变量的不同变化。我们表明，对于聚合变量，因果性的不确定性可以使得原本不混淆的因果关系变得混淆，并且反之亦然，这一点取决于相应的微观实现。我们认为，只有在聚合因果系统没有这种不确定性的情况下，我们才可以实际应用这种方法。否则，我们需要接受一点，就是宏观因果关系通常只与微观状态相关。在积极方面，我们表明当宏观干预的分布与观测分布中微观状态的分布相同时，因果关系可以进行聚合，并讨论了此观察的概括。

    In aggregated variables the impact of interventions is typically ill-defined because different micro-realizations of the same macro-intervention can result in different changes of downstream macro-variables. We show that this ill-definedness of causality on aggregated variables can turn unconfounded causal relations into confounded ones and vice versa, depending on the respective micro-realization. We argue that it is practically infeasible to only use aggregated causal systems when we are free from this ill-definedness. Instead, we need to accept that macro causal relations are typically defined only with reference to the micro states. On the positive side, we show that cause-effect relations can be aggregated when the macro interventions are such that the distribution of micro states is the same as in the observational distribution and also discuss generalizations of this observation.
    
[^95]: LLM+P：赋能大型语言模型最优规划能力

    LLM+P: Empowering Large Language Models with Optimal Planning Proficiency. (arXiv:2304.11477v1 [cs.AI])

    [http://arxiv.org/abs/2304.11477](http://arxiv.org/abs/2304.11477)

    本论文引入了LLM+P框架，将经典规划器的优点融入大型语言模型（LLM），通过将语言描述转换为用规划领域定义语言（PDDL）编写的文件来解决计划问题，旨在综合两者的优势，赋能LLMs最优规划能力。

    

    大型语言模型（LLM）展示了惊人的零样本泛化能力：最先进的聊天机器人可以提供对许多日常生活中常见问题的合理答案。然而，迄今为止，LLM不能可靠地解决长时程规划问题。相比之下，经典规划器一旦以格式化的方式提供问题，则可以使用高效的搜索算法快速识别正确或甚至最优的计划。为了综合两者的优势，本论文引入了LLM+P，这是第一个将经典规划器的优点融入LLM的框架。LLM+P接收一个计划问题的自然语言描述，然后以自然语言返回解决该问题的正确（或最优）计划。LLM+P首先将语言描述转换为用规划领域定义语言（PDDL）编写的文件，然后利用经典规划器快速找到解决方案，最后将找到的解决方案翻译回自然语言。

    Large language models (LLMs) have demonstrated remarkable zero-shot generalization abilities: state-of-the-art chatbots can provide plausible answers to many common questions that arise in daily life. However, so far, LLMs cannot reliably solve long-horizon planning problems. By contrast, classical planners, once a problem is given in a formatted way, can use efficient search algorithms to quickly identify correct, or even optimal, plans. In an effort to get the best of both worlds, this paper introduces LLM+P, the first framework that incorporates the strengths of classical planners into LLMs. LLM+P takes in a natural language description of a planning problem, then returns a correct (or optimal) plan for solving that problem in natural language. LLM+P does so by first converting the language description into a file written in the planning domain definition language (PDDL), then leveraging classical planners to quickly find a solution, and then translating the found solution back into
    
[^96]: 自适应门控图卷积网络用于基于EEG数据的阿尔茨海默病可解释诊断

    Adaptive Gated Graph Convolutional Network for Explainable Diagnosis of Alzheimer's Disease using EEG Data. (arXiv:2304.05874v1 [q-bio.NC])

    [http://arxiv.org/abs/2304.05874](http://arxiv.org/abs/2304.05874)

    本文提出了一种自适应门控图卷积网络(AGGCN)，该网络结合卷积节点特征增强和功能连接度量自适应学习图结构，实现了高精度的阿尔茨海默病诊断，并提供了重要的脑区信息。

    

    近来，图神经网络(GNN)模型越来越多地被用于分类脑电图(EEG)数据，然而，基于GNN的神经系统疾病，如阿尔茨海默病(AD)的诊断仍然是相对未开发的领域。因此，本文提出了一种新颖的自适应门控图卷积网络(AGGCN)，该网络可以提供可解释的预测结果。AGGCN通过将基于卷积的节点特征增强与基于功能连接性的著名相关度量相结合来自适应学习图结构。此外，门控图卷积可以动态地加权考虑各种空间尺度的贡献。实验结果表明，该模型在闭眼和睁眼状态下均能取得较高的精度，表明学习到的表征结果的稳定性。最后，我们证明了所提出的AGGCN模型可以提供有关AD最受影响的脑区的重要见解。

    Graph neural network (GNN) models are increasingly being used for the classification of electroencephalography (EEG) data. However, GNN-based diagnosis of neurological disorders, such as Alzheimer's disease (AD), remains a relatively unexplored area of research. Previous studies have relied on functional connectivity methods to infer brain graph structures and used simple GNN architectures for the diagnosis of AD. In this work, we propose a novel adaptive gated graph convolutional network (AGGCN) that can provide explainable predictions. AGGCN adaptively learns graph structures by combining convolution-based node feature enhancement with a well-known correlation-based measure of functional connectivity. Furthermore, the gated graph convolution can dynamically weigh the contribution of various spatial scales. The proposed model achieves high accuracy in both eyes-closed and eyes-open conditions, indicating the stability of learned representations. Finally, we demonstrate that the propos
    
[^97]: TraffNet：学习道路网络数字孪生交通生成因果关系

    TraffNet: Learning Causality of Traffic Generation for Road Network Digital Twins. (arXiv:2303.15954v1 [cs.LG])

    [http://arxiv.org/abs/2303.15954](http://arxiv.org/abs/2303.15954)

    TraffNet是一个学习交通量生成原因的深度学习框架，将车辆轨迹数据表示为异构图，利用递归神经网络结构实现了对交通生成原因的预测。

    

    道路网络数字孪生（RNDT）在开发下一代智能交通系统中发挥着关键作用，可以实现更精确的交通规划和控制。为了支持实时决策，RNDT需要一个模型，从在线传感器数据中动态学习交通模式并生成高保真模拟结果。尽管基于图神经网络的当前交通预测技术已经实现了最先进的性能，但是这些技术仅通过挖掘历史交通数据中的相关性来预测未来交通，而忽略了交通生成的原因，例如交通需求和路径选择。因此，它们的性能对于实时决策是不可靠的。为了填补这一差距，我们引入了一个新的深度学习框架称为 TraffNet，该框架从车辆轨迹数据中学习交通量的因果性。首先，我们使用异构图来表示道路网络，使模型能够并入预测所需的其他数据，然后我们提出了一种新颖的递归神经网络结构，从而能够预测交通量的因果联系。

    Road network digital twins (RNDTs) play a critical role in the development of next-generation intelligent transportation systems, enabling more precise traffic planning and control. To support just-in-time (JIT) decision making, RNDTs require a model that dynamically learns the traffic patterns from online sensor data and generates high-fidelity simulation results. Although current traffic prediction techniques based on graph neural networks have achieved state-of-the-art performance, these techniques only predict future traffic by mining correlations in historical traffic data, disregarding the causes of traffic generation, such as traffic demands and route selection. Therefore, their performance is unreliable for JIT decision making. To fill this gap, we introduce a novel deep learning framework called TraffNet that learns the causality of traffic volume from vehicle trajectory data. First, we use a heterogeneous graph to represent the road network, allowing the model to incorporate 
    
[^98]: Sigmoid Loss用于语言图像预训练

    Sigmoid Loss for Language Image Pre-Training. (arXiv:2303.15343v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.15343](http://arxiv.org/abs/2303.15343)

    本论文提出了适用于语言图像预训练的成对Sigmoid损失函数，可以有效地提高训练批量大小，同时不需要全局查看配对相似性进行归一化，其训练出来的模型在ImageNet上表现良好。

    

    我们提出了一种简单的成对Sigmoid损失函数，用于图像-文本预训练。与标准的具有softmax归一化的对比学习不同，Sigmoid损失只操作图像-文本对，不需要全局查看配对相似性以进行归一化。Sigmoid损失同时使批量大小进一步增加，并可在较小的批量大小下表现更好。仅使用四个TPUv4芯片，我们就能在4k批量大小下训练出一个Base CLIP模型和在20k批量大小下训练出一个大规模LiT模型，后者在两天内实现了84.5%的ImageNet零样本准确率。这种损失函数将批量大小与损失函数分离，使我们能够研究示例与对之间、负-正例比率的影响。最后，我们将批量大小推到极限，高达一百万，发现扩大批量大小的好处很快就会减弱，32k批量大小已经足够。我们希望我们的研究能够激发进一步探索如何提高质量的研究。

    We propose a simple pairwise sigmoid loss for image-text pre-training. Unlike standard contrastive learning with softmax normalization, the sigmoid loss operates solely on image-text pairs and does not require a global view of the pairwise similarities for normalization. The sigmoid loss simultaneously allows further scaling up the batch size, while also performing better at smaller batch sizes. With only four TPUv4 chips, we can train a Base CLIP model at 4k batch size and a Large LiT model at 20k batch size, the latter achieves 84.5% ImageNet zero-shot accuracy in two days. This disentanglement of the batch size from the loss further allows us to study the impact of examples vs pairs and negative to positive ratio. Finally, we push the batch size to the extreme, up to one million, and find that the benefits of growing batch size quickly diminish, with a more reasonable batch size of 32k being sufficient. We hope our research motivates further explorations in improving the quality and
    
[^99]: Fantasia3D: 用于高质量文本生成3D内容的几何和外观分离方法

    Fantasia3D: Disentangling Geometry and Appearance for High-quality Text-to-3D Content Creation. (arXiv:2303.13873v1 [cs.CV])

    [http://arxiv.org/abs/2303.13873](http://arxiv.org/abs/2303.13873)

    Fantasia3D是一种新的文本生成3D内容的方法，通过分离几何和外观建模和学习，提高了几何细节和逼真渲染，并更有效和高效。

    

    最近，由于预训练的大型语言模型和图像扩散模型的提供，自动3D内容的创建取得了快速进展，形成了文本生成3D内容的新兴话题。现有的文本生成3D方法通常使用隐式场景表示，这些表示使用体积渲染将几何和外观耦合在一起，对于恢复更精细的几何和实现照片般逼真的渲染是次优的；因此，它们在产生高质量3D资产方面不够有效。在这项工作中，我们提出了一种名为Fantasia3D的新方法，用于高质量文本生成3D内容。Fantasia3D的关键在于几何和外观的分离建模和学习。对于几何学习，我们依靠混合场景表示，并建议将从表示中提取的表面法线编码作为图像扩散模型的输入。对于外观建模，我们引入了空间可变双向反射率分布函数（SVBRDF）来分离材料和光照属性。实验结果表明，我们的方法在几何细节和逼真渲染方面超越了现有技术，并且在从自然语言文本中生成高质量的3D内容方面更为有效和高效。

    Automatic 3D content creation has achieved rapid progress recently due to the availability of pre-trained, large language models and image diffusion models, forming the emerging topic of text-to-3D content creation. Existing text-to-3D methods commonly use implicit scene representations, which couple the geometry and appearance via volume rendering and are suboptimal in terms of recovering finer geometries and achieving photorealistic rendering; consequently, they are less effective for generating high-quality 3D assets. In this work, we propose a new method of Fantasia3D for high-quality text-to-3D content creation. Key to Fantasia3D is the disentangled modeling and learning of geometry and appearance. For geometry learning, we rely on a hybrid scene representation, and propose to encode surface normal extracted from the representation as the input of the image diffusion model. For appearance modeling, we introduce the spatially varying bidirectional reflectance distribution function 
    
[^100]: 带有局部遗忘的重放缓冲区用于自适应深度模型强化学习

    Replay Buffer With Local Forgetting for Adaptive Deep Model-Based Reinforcement Learning. (arXiv:2303.08690v1 [cs.LG])

    [http://arxiv.org/abs/2303.08690](http://arxiv.org/abs/2303.08690)

    提出了一种带有局部遗忘的新型重放缓冲区，可以在状态空间的相关部分快速遗忘过时的经验。实验证明该方法提高了自适应深度模型强化学习代理对环境变化的适应能力，加速了学习速度并改善了策略。

    

    神经科学中用于确定所研究的对象（无论是啮齿动物还是人类）是否表现出模型为基础的学习的关键行为特征之一是对环境中局部变化的有效适应。然而，在强化学习中，最近的研究表明，现代深度模型强化学习（MBRL）方法较难适应这种变化。本文提出了一种新的重放缓冲区，带有局部遗忘，可以快速地在状态空间中的相关部分遗忘过时的经验而在其他地方保留旧数据。通过在一系列具有挑战性的导航任务上进行实验，我们证明了该方法改善了对环境变化的适应能力，加快了学习速度并改善了策略。

    One of the key behavioral characteristics used in neuroscience to determine whether the subject of study -- be it a rodent or a human -- exhibits model-based learning is effective adaptation to local changes in the environment. In reinforcement learning, however, recent work has shown that modern deep model-based reinforcement-learning (MBRL) methods adapt poorly to such changes. An explanation for this mismatch is that MBRL methods are typically designed with sample-efficiency on a single task in mind and the requirements for effective adaptation are substantially higher, both in terms of the learned world model and the planning routine. One particularly challenging requirement is that the learned world model has to be sufficiently accurate throughout relevant parts of the state-space. This is challenging for deep-learning-based world models due to catastrophic forgetting. And while a replay buffer can mitigate the effects of catastrophic forgetting, the traditional first-in-first-out
    
[^101]: 不确定性感知的离线学习

    Uncertainty-Aware Off-Policy Learning. (arXiv:2303.06389v1 [cs.LG])

    [http://arxiv.org/abs/2303.06389](http://arxiv.org/abs/2303.06389)

    本文提出了一种不确定性感知的倒数概率分数估计器（UIPS），用于改进离线学习，通过明确模拟估计的记录策略中的不确定性，相对于广泛的最先进基线具有优越的样本效率。

    This paper proposes an Uncertainty-aware Inverse Propensity Score estimator (UIPS) for improved off-policy learning, which explicitly models the uncertainty in the estimated logging policy and demonstrates advantageous sample efficiency against an extensive list of state-of-the-art baselines on synthetic and three real-world recommendation datasets.

    离线学习是指仅通过记录的反馈数据进行策略优化的过程，在各种实际应用中显示出重要性，例如搜索引擎、推荐系统等。虽然生成记录数据的真实记录策略通常是未知的，但以前的工作仅在离线学习中采用其估计值，忽略了由于这种估计器导致的高偏差和高方差，特别是在具有小且估计不准确的记录概率的样本上。在这项工作中，我们明确地模拟了估计的记录策略中的不确定性，并提出了一种不确定性感知的倒数概率分数估计器（UIPS）来改进离线学习。在合成和三个真实的推荐数据集上的实验结果表明，所提出的UIPS估计器相对于广泛的最先进基线具有优越的样本效率。

    Off-policy learning, referring to the procedure of policy optimization with access only to logged feedback data, has shown importance in various real-world applications, such as search engines, recommender systems, and etc. While the ground-truth logging policy, which generates the logged data, is usually unknown, previous work simply takes its estimated value in off-policy learning, ignoring both high bias and high variance resulted from such an estimator, especially on samples with small and inaccurately estimated logging probabilities. In this work, we explicitly model the uncertainty in the estimated logging policy and propose a Uncertainty-aware Inverse Propensity Score estimator (UIPS) for improved off-policy learning. Experiment results on synthetic and three real-world recommendation datasets demonstrate the advantageous sample efficiency of the proposed UIPS estimator against an extensive list of state-of-the-art baselines.
    
[^102]: 驯服对比度最大化以学习顺序、低延迟、基于事件的光流

    Taming Contrast Maximization for Learning Sequential, Low-latency, Event-based Optical Flow. (arXiv:2303.05214v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.05214](http://arxiv.org/abs/2303.05214)

    本文提出了一种用于顺序估计基于事件的光流的自监督学习流程，该流程通过新型的对比度最大化公式训练持续运行的神经模型，以适应非线性和变化统计的输入事件。实验结果表明，该方法在多个数据集上取得了新的技术水平。

    

    事件相机最近受到了广泛关注，因为它们为复杂的计算机视觉问题提供了低延迟和低功率的解决方案。为了实现这些解决方案，需要开发能够利用事件数据的独特性质的算法。然而，目前的最新技术仍然受到基于帧的文献的影响，并且往往无法兑现这些承诺。在这项工作中，我们考虑到了这一点，并提出了一种新颖的自监督学习流程，用于顺序估计基于事件的光流，使得模型能够扩展到高推理频率。核心是一个持续运行的带状态神经模型，使用对比度最大化的新型公式进行训练，使其对输入事件中的非线性和变化统计保持稳健。多个数据集上的结果证实了我们方法的有效性，从而在精度方面创造了新的技术水平。

    Event cameras have recently gained significant traction since they open up new avenues for low-latency and low-power solutions to complex computer vision problems. To unlock these solutions, it is necessary to develop algorithms that can leverage the unique nature of event data. However, the current state-of-the-art is still highly influenced by the frame-based literature, and usually fails to deliver on these promises. In this work, we take this into consideration and propose a novel self-supervised learning pipeline for the sequential estimation of event-based optical flow that allows for the scaling of the models to high inference frequencies. At its core, we have a continuously-running stateful neural model that is trained using a novel formulation of contrast maximization that makes it robust to nonlinearities and varying statistics in the input events. Results across multiple datasets confirm the effectiveness of our method, which establishes a new state of the art in terms of ac
    
[^103]: 通过简单的子技能控制器指导探索，实现手部灵巧操作

    Dexterous In-hand Manipulation by Guiding Exploration with Simple Sub-skill Controllers. (arXiv:2303.03533v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.03533](http://arxiv.org/abs/2303.03533)

    该论文提出了一种使用简单的子技能控制器引导探索的框架，从而提高了学习手部灵巧操作技能的样本效率。这是第一个在没有使用探索性重置分布的情况下，演示学习难以探索的手指步态手部操作技能。

    

    最近，强化学习在提高复杂性方面取得了手部灵巧操作技能。然而，尽管在模拟环境中学习这些技能，但其样本效率仍然较低，这是因为这些技能是从零开始学习的，没有受益于任何领域专业知识。在这项工作中，我们旨在通过使用领域知识可用的控制器来提高学习手部灵巧操作技能的样本效率。为此，我们设计了简单的子技能控制器，并通过遵循这些控制器的动作，通过一个框架将探索引导到相关状态空间而展示了提高的样本效率。我们是第一个在没有使用探索性重置分布的情况下，演示了学习难以探索的手指步态手部操作技能。视频结果可以在https://roamlab.github.io/vge找到。

    Recently, reinforcement learning has led to dexterous manipulation skills of increasing complexity. Nonetheless, learning these skills in simulation still exhibits poor sample-efficiency which stems from the fact these skills are learned from scratch without the benefit of any domain expertise. In this work, we aim to improve the sample efficiency of learning dexterous in-hand manipulation skills using controllers available via domain knowledge. To this end, we design simple sub-skill controllers and demonstrate improved sample efficiency using a framework that guides exploration toward relevant state space by following actions from these controllers. We are the first to demonstrate learning hard-to-explore finger-gaiting in-hand manipulation skills without the use of an exploratory reset distribution. Video results can be found at https://roamlab.github.io/vge
    
[^104]: 基于记忆的在线视频异常检测

    Memory-augmented Online Video Anomaly Detection. (arXiv:2302.10719v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.10719](http://arxiv.org/abs/2302.10719)

    本文提出了一种基于记忆的在线视频异常检测系统，能够在自动驾驶汽车周围的异常情况出现时迅速响应，利用仪表盘摄像头捕获的视频数据，并采用了短期和长期记忆模块来提取相关信息。该系统具有出色的性能和简单直观的架构，并且利用RGB帧进行了端到端训练。

    

    对于自动驾驶汽车来说，理解周围环境的能力非常重要。本文介绍了一种能够在线工作的系统，以立即响应围绕自动驾驶汽车出现的异常情况，仅利用由仪表盘摄像头捕获的视频。我们的架构名为MOVAD，依赖于两个主要模块：短期记忆模块，用于提取与正在进行的操作相关的信息，由视频Swing Transformer (VST) 实现，以及嵌入在分类器内部的长期记忆模块，通过使用长短期记忆 (LSTM) 网络考虑远程过去的信息和操作背景。MOVAD的优势不仅在于其出色的性能，还在于其简单直观和模块化的架构，仅使用RGB帧以尽可能少的假设进行端到端训练，使其易于实施和应用。我们在...

    The ability to understand the surrounding scene is of paramount importance for Autonomous Vehicles (AVs). This paper presents a system capable to work in an online fashion, giving an immediate response to the arise of anomalies surrounding the AV, exploiting only the videos captured by a dash-mounted camera. Our architecture, called MOVAD, relies on two main modules: a Short-Term Memory Module to extract information related to the ongoing action, implemented by a Video Swin Transformer (VST), and a Long-Term Memory Module injected inside the classifier that considers also remote past information and action context thanks to the use of a Long-Short Term Memory (LSTM) network. The strengths of MOVAD are not only linked to its excellent performance, but also to its straightforward and modular architecture, trained in a end-to-end fashion with only RGB frames with as less assumptions as possible, which makes it easy to implement and play with. We evaluated the performance of our method on 
    
[^105]: 蒸馏策略优化

    Distillation Policy Optimization. (arXiv:2302.00533v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00533](http://arxiv.org/abs/2302.00533)

    本文展示了一种演员-评论家的学习框架，该框架通过蒸馏优势在利用过去经验的同时遵循稳定的在线策略，实现了快速学习并可以适用于广泛的算法类别。

    

    本文提出了一个演员-评论家学习框架，它借鉴了分布式学习的视角和两种策略改进数据的交叉融合，实现了快速学习并可应用于广泛的算法类别。在该框架中，首先提出了方差减少机制，例如统一优势估计器 (UAE) 和一个学习的基线，不仅是连接到动作值函数的桥梁，还能提炼优势。

    On-policy algorithms are supposed to be stable, however, sample-intensive yet. Off-policy algorithms utilizing past experiences are deemed to be sample-efficient, nevertheless, unstable in general. Can we design an algorithm that can employ the off-policy data, while exploit the stable learning by sailing along the course of the on-policy walkway? In this paper, we present an actor-critic learning framework that borrows the distributional perspective of interest to evaluate, and cross-breeds two sources of the data for policy improvement, which enables fast learning and can be applied to a wide class of algorithms. In its backbone, the variance reduction mechanisms, such as unified advantage estimator (UAE), that extends generalized advantage estimator (GAE) to be applicable on any state-dependent baseline, and a learned baseline, that is competent to stabilize the policy gradient, are firstly put forward to not merely be a bridge to the action-value function but also distill the advan
    
[^106]: 从网络爬取的图像-文本数据中的噪声感知学习用于图像字幕生成

    Noise-aware Learning from Web-crawled Image-Text Data for Image Captioning. (arXiv:2212.13563v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.13563](http://arxiv.org/abs/2212.13563)

    提出了一种噪声感知字幕生成框架（NoC），它利用网络爬取的数据学习丰富的知识，同时减少噪声的影响。通过对齐级别可控的字幕生成器，模型能够生成高质量的字幕。

    

    图像字幕生成是一项直观的任务，可以利用大规模网络爬取数据，为生成模型提供丰富的关于视觉世界的知识。然而，由于网络爬取数据包含不同级别对齐的图像-文本对，固有的噪声（例如不对齐的对）使得学习一个精确的字幕生成模型变得困难。虽然过滤策略可以有效去除噪声数据，但它会导致可学习知识的减少，并有时带来数据不足的新问题。为了兼顾两者的优势，我们提出了一种噪声感知字幕生成（NoC）框架，它能够从整个网络爬取的数据中学习丰富的知识，同时较少受到噪声的影响。这是通过所提出的对齐级别可控的字幕生成器实现的，该生成器在训练过程中使用图像-文本对的对齐级别作为控制信号进行学习。对齐级别条件的训练使得模型能够产生高质量的字幕。

    Image captioning is one of the straightforward tasks that can take advantage of large-scale web-crawled data which provides rich knowledge about the visual world for a captioning model. However, since web-crawled data contains image-text pairs that are aligned at different levels, the inherent noises (e.g., misaligned pairs) make it difficult to learn a precise captioning model. While the filtering strategy can effectively remove noisy data, it leads to a decrease in learnable knowledge and sometimes brings about a new problem of data deficiency. To take the best of both worlds, we propose a Noise-aware Captioning (NoC) framework, which learns rich knowledge from the whole web-crawled data while being less affected by the noises. This is achieved by the proposed alignment-level-controllable captioner, which is learned using alignment levels of the image-text pairs as a control signal during training. The alignment-level-conditioned training allows the model to generate high-quality cap
    
[^107]: UnICLAM：对抗性屏蔽的对比表示学习用于统一和可解释的医学视觉问答

    UnICLAM:Contrastive Representation Learning with Adversarial Masking for Unified and Interpretable Medical Vision Question Answering. (arXiv:2212.10729v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.10729](http://arxiv.org/abs/2212.10729)

    UnICLAM是一种统一和可解释的医学视觉问答模型，通过对比表示学习和对抗性屏蔽，实现了图像和文本之间的对齐和语义表示。

    

    医学视觉问答（Medical-VQA）旨在回答有关放射学图像的临床问题，为医生提供决策选项。然而，当前的Medical-VQA模型通过将视觉和纹理编码器分别放置在双独立空间中来学习跨模态表示，这导致间接的语义对齐。在本文中，我们提出了UnICLAM，一种通过对比表示学习和对抗性屏蔽实现统一和可解释的医学视觉问答模型。具体来说，为了学习对齐的图像-文本表示，我们首先建立了一个统一的双流预训练结构，采用逐渐软参数共享策略。技术上，所提出的策略学习了一个约束，使得视觉和纹理编码器在同一空间中接近，随着层数的增加，逐渐放松。此外，为了把握统一的语义表示，我们将对抗性屏蔽数据增强拓展到对比表示中。

    Medical Visual Question Answering (Medical-VQA) aims to to answer clinical questions regarding radiology images, assisting doctors with decision-making options. Nevertheless, current Medical-VQA models learn cross-modal representations through residing vision and texture encoders in dual separate spaces, which lead to indirect semantic alignment. In this paper, we propose UnICLAM, a Unified and Interpretable Medical-VQA model through Contrastive Representation Learning with Adversarial Masking. Specifically, to learn an aligned image-text representation, we first establish a unified dual-stream pre-training structure with the gradually soft-parameter sharing strategy. Technically, the proposed strategy learns a constraint for the vision and texture encoders to be close in a same space, which is gradually loosened as the higher number of layers. Moreover, for grasping the unified semantic representation, we extend the adversarial masking data augmentation to the contrastive representati
    
[^108]: 使用学习控制策略主动对移动目标进行分类

    Active Classification of Moving Targets with Learned Control Policies. (arXiv:2212.03068v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2212.03068](http://arxiv.org/abs/2212.03068)

    本文提出了一种使用学习控制策略的方法，通过强化学习训练一种基于注意力的架构来指导无人机选择下一个视点，以收集尽可能多未分类目标的证据，并考虑目标的运动、方向和遮挡情况。该方法不仅提高了分类准确率，还在多目标环境中取得了良好效果。

    

    本文研究了一个问题，在该问题中，一架无人机必须收集语义信息以对多个移动目标进行分类。我们特别解决了使用“黑盒”分类器（如深度学习神经网络）提取信息时的控制输入计算挑战。这些算法通常缺乏视点与其关联输出之间的分析关系，导致无法在信息收集方案中使用。为了填补这个空白，我们提出了一种基于注意力机制的新型架构，通过强化学习（RL）进行训练，并输出下一个视点，以便无人机能够有利地获取尽可能多未分类目标的证据，并推理其运动、方向和遮挡情况。然后，我们使用低级MPC控制器将无人机移动到所需视点，考虑到其实际动态。我们展示了我们的方法不仅会分类准确率得到提高，还能提高目标分类所需的视点数量，并且在多目标环境中也能取得良好效果。

    In this paper, we consider the problem where a drone has to collect semantic information to classify multiple moving targets. In particular, we address the challenge of computing control inputs that move the drone to informative viewpoints, position and orientation, when the information is extracted using a "black-box" classifier, e.g., a deep learning neural network. These algorithms typically lack of analytical relationships between the viewpoints and their associated outputs, preventing their use in information-gathering schemes. To fill this gap, we propose a novel attention-based architecture, trained via Reinforcement Learning (RL), that outputs the next viewpoint for the drone favoring the acquisition of evidence from as many unclassified targets as possible while reasoning about their movement, orientation, and occlusions. Then, we use a low-level MPC controller to move the drone to the desired viewpoint taking into account its actual dynamics. We show that our approach not onl
    
[^109]: 带有基于模型先验的一次性隐式动画化头像制作方法

    One-shot Implicit Animatable Avatars with Model-based Priors. (arXiv:2212.02469v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.02469](http://arxiv.org/abs/2212.02469)

    本文提出了ELICIT，一种从单张图片学习人类特定神经辐射场的方法，同时利用3D几何先验和视觉语义先验实现了一次性数据高效的逼真可动3D人体的创建。

    

    现有的创建人类头像的神经渲染方法通常要么需要稠密输入信号（如视频或多视角图像），要么利用从大规模特定3D人体数据集中学到的先验，使得可以使用稀疏视角输入进行重建。大多数这些方法在仅有一张图像时无法实现逼真重建。为了实现数据高效的逼真可动3D人体的创建，我们提出了ELICIT，这是一种从一张图片学习人体特定神经辐射场的新方法。受到人类可以轻松估计身体几何形状并从一张图片中想象造型完整的衣柜的启示，我们在ELICIT中利用了两个先验：3D几何先验和视觉语义先验。具体来说，ELICIT利用一个蒙皮顶点模板模型（即SMPL）的3D身体形状几何先验，并通过基于CLIP的预训练模型实现了视觉服装语义先验。这两个先验均用于从单个图像进行逼真的可动3D重建。

    Existing neural rendering methods for creating human avatars typically either require dense input signals such as video or multi-view images, or leverage a learned prior from large-scale specific 3D human datasets such that reconstruction can be performed with sparse-view inputs. Most of these methods fail to achieve realistic reconstruction when only a single image is available. To enable the data-efficient creation of realistic animatable 3D humans, we propose ELICIT, a novel method for learning human-specific neural radiance fields from a single image. Inspired by the fact that humans can effortlessly estimate the body geometry and imagine full-body clothing from a single image, we leverage two priors in ELICIT: 3D geometry prior and visual semantic prior. Specifically, ELICIT utilizes the 3D body shape geometry prior from a skinned vertex-based template model (i.e., SMPL) and implements the visual clothing semantic prior with the CLIP-based pre-trained models. Both priors are used 
    
[^110]: 垂直联合学习：概念、进展和挑战

    Vertical Federated Learning: Concepts, Advances and Challenges. (arXiv:2211.12814v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.12814](http://arxiv.org/abs/2211.12814)

    垂直联合学习（VFL）是一种联合学习设置，多个具有关于同一组用户不同特征的参与方共同训练机器学习模型，而不公开原始数据或模型参数。本文提供了对VFL概念、算法以及各个方面的进展和挑战的综合回顾，深入分析了隐私保护协议的分类、隐私攻击和防御策略，并提出了考虑多个约束条件的统一框架VFLow。此外，还回顾了工业应用中的最新进展和VFL面临的未来挑战和方向。

    

    垂直联合学习（VFL）是一种联合学习设置，多个具有关于同一组用户不同特征的参与方共同训练机器学习模型，而不公开原始数据或模型参数。受VFL研究和实际应用的快速增长的推动，我们全面回顾了VFL的概念和算法，以及各个方面的当前进展和挑战，包括有效性、效率和隐私。我们提供了对VFL设置和隐私保护协议的详尽分类，并对每个协议的隐私攻击和防御策略进行了全面分析。最后，我们提出了一个统一的框架，称为VFLow，它考虑了VFL问题在通信、计算、隐私以及有效性和公平性约束下的情况。最后，我们回顾了工业应用中最新的进展，突出了VFL面临的开放性挑战和未来方向。

    Vertical Federated Learning (VFL) is a federated learning setting where multiple parties with different features about the same set of users jointly train machine learning models without exposing their raw data or model parameters. Motivated by the rapid growth in VFL research and real-world applications, we provide a comprehensive review of the concept and algorithms of VFL, as well as current advances and challenges in various aspects, including effectiveness, efficiency, and privacy. We provide an exhaustive categorization for VFL settings and privacy-preserving protocols and comprehensively analyze the privacy attacks and defense strategies for each protocol. In the end, we propose a unified framework, termed VFLow, which considers the VFL problem under communication, computation, privacy, as well as effectiveness and fairness constraints. Finally, we review the most recent advances in industrial applications, highlighting open challenges and future directions for VFL.
    
[^111]: GeONet：一种学习Wasserstein测地的神经算子

    GeONet: a neural operator for learning the Wasserstein geodesic. (arXiv:2209.14440v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.14440](http://arxiv.org/abs/2209.14440)

    GeONet是一个不受网格影响的深度神经算子网络，学习了从初始和终端分布到连接两个端点分布的Wasserstein测地的非线性映射。通过学习鞍点优化条件，GeONet可以快速进行实时预测，并在仿真示例和测试数据上取得了与标准OT求解器相当的准确性。

    

    最优传输(OT)提供了一种将复杂数据分布进行几何上有意义比较的通用框架。传统的计算概率测度的Wasserstein距离和测地的方法需要网格依赖的域离散化，同时受到维度灾难的影响。我们提出了GeONet，一种不受网格影响的深度神经算子网络，它学习了将输入的初始和终端分布映射到连接两个端点分布的Wasserstein测地的非线性映射。在脱机训练阶段，GeONet通过耦合的PDE系统表征的原始和对偶空间中的动态最优条件学习了OT问题的鞍点优化条件。后续的推理阶段是瞬时完成的，并可以在在线学习设置中用于实时预测。我们证明了GeONet在仿真示例和...

    Optimal transport (OT) offers a versatile framework to compare complex data distributions in a geometrically meaningful way. Traditional methods for computing the Wasserstein distance and geodesic between probability measures require mesh-dependent domain discretization and suffer from the curse-of-dimensionality. We present GeONet, a mesh-invariant deep neural operator network that learns the non-linear mapping from the input pair of initial and terminal distributions to the Wasserstein geodesic connecting the two endpoint distributions. In the offline training stage, GeONet learns the saddle point optimality conditions for the dynamic formulation of the OT problem in the primal and dual spaces that are characterized by a coupled PDE system. The subsequent inference stage is instantaneous and can be deployed for real-time predictions in the online learning setting. We demonstrate that GeONet achieves comparable testing accuracy to the standard OT solvers on simulation examples and the
    
[^112]: 在学习行为空间中发现和利用稀疏奖励

    Discovering and Exploiting Sparse Rewards in a Learned Behavior Space. (arXiv:2111.01919v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.01919](http://arxiv.org/abs/2111.01919)

    这项研究介绍了一种名为STAX的算法，能够在学习行为空间时实时探索，并且能够有效优化任何发现的奖励。

    

    在稀疏奖励的环境中学习最优策略是困难的，因为学习代理几乎没有关于行为质量的反馈。在这种情况下，一个好的策略是专注于探索，希望能发现一个奖励信号以进行改进。一个能够处理这种情况的学习算法必须能够（1）探索可能的代理行为和（2）利用可能发现的任何奖励。已经提出了高效的探索算法，需要定义一个行为空间，将代理与其在可以探索的空间中表现出的行为相关联。需要定义这个空间是这些算法的一个限制。在这项工作中，我们介绍了STAX，一种设计用于实时学习行为空间并在有效地优化任何发现的奖励的算法。它通过将行为空间的探索和学习与奖励的利用分开，以替代的方式实现。

    Learning optimal policies in sparse rewards settings is difficult as the learning agent has little to no feedback on the quality of its actions. In these situations, a good strategy is to focus on exploration, hopefully leading to the discovery of a reward signal to improve on. A learning algorithm capable of dealing with this kind of settings has to be able to (1) explore possible agent behaviors and (2) exploit any possible discovered reward. Efficient exploration algorithms have been proposed that require to define a behavior space, that associates to an agent its resulting behavior in a space that is known to be worth exploring. The need to define this space is a limitation of these algorithms. In this work, we introduce STAX, an algorithm designed to learn a behavior space on-the-fly and to explore it while efficiently optimizing any reward discovered. It does so by separating the exploration and learning of the behavior space from the exploitation of the reward through an alterna
    
[^113]: 关于利用命中集进行模型调和的研究

    On Exploiting Hitting Sets for Model Reconciliation. (arXiv:2012.09274v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2012.09274](http://arxiv.org/abs/2012.09274)

    本文提出了一个基于逻辑的模型调和框架，通过利用命中集对偶关系来寻找解释，以解决在人类感知规划中对代理计划最优性进行解释的问题。

    

    在人类感知规划中，规划代理可能需要向人类用户解释为什么它的计划是最优的。一种流行的方法是通过模型调和来实现，其中代理尝试协调其模型与人类模型中的差异，使得计划在人类模型中也是最优的。在本文中，我们提出了一个基于逻辑的模型调和框架，扩展到规划领域之外。具体而言，给定一个包含命题公式 $\varphi$ 的知识库 $KB_1$ 和一个不包含它的知识库 $KB_2$，模型调和寻求一个解释，即 $KB_1$ 的基数最小的子集，将其整合到 $KB_2$ 中使得包含成立。我们的方法利用了在矛盾分析领域中产生的最小修正集（MCSes）和最小不可满足集（MUSes）之间的命中集对偶关系，以找到合适的解释。

    In human-aware planning, a planning agent may need to provide an explanation to a human user on why its plan is optimal. A popular approach to do this is called model reconciliation, where the agent tries to reconcile the differences in its model and the human's model such that the plan is also optimal in the human's model. In this paper, we present a logic-based framework for model reconciliation that extends beyond the realm of planning. More specifically, given a knowledge base $KB_1$ entailing a formula $\varphi$ and a second knowledge base $KB_2$ not entailing it, model reconciliation seeks an explanation, in the form of a cardinality-minimal subset of $KB_1$, whose integration into $KB_2$ makes the entailment possible. Our approach, based on ideas originating in the context of analysis of inconsistencies, exploits the existing hitting set duality between minimal correction sets (MCSes) and minimal unsatisfiable sets (MUSes) in order to identify an appropriate explanation. However
    
[^114]: MimicNorm: 权重均值和最后一层批归一化层模仿批归一化的动态

    MimicNorm: Weight Mean and Last BN Layer Mimic the Dynamic of Batch Normalization. (arXiv:2010.09278v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2010.09278](http://arxiv.org/abs/2010.09278)

    本文提出了一种名为MimicNorm的归一化方法，通过简化批归一化（BN）的正则化方法并保持其核心影响，即数据去相关性和自适应学习率，来提高网络训练的收敛性和效率。MimicNorm仅包含两个轻量级操作，可与BN相媲美。

    

    大量实验证实了批归一化（BN）层在收敛和泛化效果上的成功。然而，BN需要额外的内存和浮点计算。此外，在微小批次上，BN会变得不准确，因为它依赖于批次统计信息。在本文中，我们通过简化BN的正则化方法来解决这些问题，同时保持BN层的两个基本影响，即数据去相关性和自适应学习率。我们提出了一种新的归一化方法，称为MimicNorm，来改善网络训练中的收敛性和效率。 MimicNorm仅包含两个轻量级操作，包括修改的权重均值操作（从权重参数张量中减去均值值）和损失函数（最后的BN层）之前的一个BN层。我们利用神经切线核（NTK）理论证明了我们的权重均值操作可以白化激活，使网络转化为类似BN层的混沌状态，从而导致了收敛性的提升。

    Substantial experiments have validated the success of Batch Normalization (BN) Layer in benefiting convergence and generalization. However, BN requires extra memory and float-point calculation. Moreover, BN would be inaccurate on micro-batch, as it depends on batch statistics. In this paper, we address these problems by simplifying BN regularization while keeping two fundamental impacts of BN layers, i.e., data decorrelation and adaptive learning rate. We propose a novel normalization method, named MimicNorm, to improve the convergence and efficiency in network training. MimicNorm consists of only two light operations, including modified weight mean operations (subtract mean values from weight parameter tensor) and one BN layer before loss function (last BN layer). We leverage the neural tangent kernel (NTK) theory to prove that our weight mean operation whitens activations and transits network into the chaotic regime like BN layer, and consequently, leads to an enhanced convergence. T
    

