# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Prodigy: An Expeditiously Adaptive Parameter-Free Learner.](http://arxiv.org/abs/2306.06101) | 本文提出了一种基于自适应算法(如Adagrad和Adam)的学习率估计方法Prodigy和Resetting，可以快速且正确地估计到达解决方案所需的距离D，从而提高了模型的收敛速度，并在多个数据集和模型上进行了测试，实验表明该方法优于D-Adaptation并可达到手动调整Adam的测试准确度值。 |
| [^2] | [Leveraging Large Language Models for Scalable Vector Graphics-Driven Image Understanding.](http://arxiv.org/abs/2306.06094) | 本文介绍了一种新方法，通过使用可伸缩矢量图(SVG)格式处理图像，使得大型语言模型(LLMs)能够直接理解和操作图像，而无需使用参数化的视觉组件。在图像分类、生成和上下文学习等任务上，该方法表现良好，具有鲁棒性和显著的性能提升。 |
| [^3] | [Learning Not to Spoof.](http://arxiv.org/abs/2306.06087) | 该论文提出了学习不进行欺骗的方法，并考虑了智能股票交易代理的欺诈行为识别和避免。 |
| [^4] | [Trapping LLM Hallucinations Using Tagged Context Prompts.](http://arxiv.org/abs/2306.06085) | 本文提出一种使用标记的上下文提示的新方法，可以显著减少生成语言模型中的妄想症，提高对话代理的准确性和有效性。 |
| [^5] | [CARSO: Counter-Adversarial Recall of Synthetic Observations.](http://arxiv.org/abs/2306.06081) | 本文提出了一种新的图像分类的对抗性防御机制CARSO，该方法可以比最先进的对抗性训练更好地保护分类器，通过利用生成模型进行对抗净化来进行最终分类，并成功地保护自己免受未预见的威胁和最终攻击。 |
| [^6] | [Visually-Grounded Descriptions Improve Zero-Shot Image Classification.](http://arxiv.org/abs/2306.06077) | 本文提出了一种称为V-GLOSS的新方法，它利用现代语言模型和语义知识库生成具有视觉基础的类别描述，提高了零样本图像分类的准确性，并引入了一个带有类别描述的银标准数据集。 |
| [^7] | [Improved flood mapping for efficient policy design by fusion of Sentinel-1, Sentinel-2, and Landsat-9 imagery to identify population and infrastructure exposed to floods.](http://arxiv.org/abs/2306.06074) | 通过融合光学和SAR数据，提出了一种新方法进行洪水图制作，并在巴基斯坦2022年的洪水中应用，可准确识别受灾人口和基础设施，以帮助制定理智的政策。 |
| [^8] | [Combining a Meta-Policy and Monte-Carlo Planning for Scalable Type-Based Reasoning in Partially Observable Environments.](http://arxiv.org/abs/2306.06067) | 本文提出了基于元策略和蒙特卡罗规划的POTMMCP算法，在部分可观测环境中实现了可扩展的基于类型的推理。 |
| [^9] | [SNeL: A Structured Neuro-Symbolic Language for Entity-Based Multimodal Scene Understanding.](http://arxiv.org/abs/2306.06036) | SNeL是一种结构化神经符号语言，通过将高级符号推理与低级神经处理对齐，有效地弥合了神经符号学分歧，可以广泛的应用于多种数据类型，是一种有价值的用于实体驱动的多模态场景理解工具。 |
| [^10] | [HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine.](http://arxiv.org/abs/2306.06029) | HiTZ@Antidote采用深度学习和论证理论，提供数字医疗领域高质量的可解释AI预测解释。 |
| [^11] | [A Dynamic Partial Computation Offloading for the Metaverse in In-Network Computing.](http://arxiv.org/abs/2306.06022) | 该论文提出了一个基于网络计算的Metaverse动态部分计算卸载方案，能够在动态调整卸载策略的同时最小化能耗和延迟，解决了多个子任务的部分计算卸载问题，并将其分解为了两个子问题，分别针对用户端的任务切分问题和COIN端的任务卸载问题。这需要使用序数潜在博弈（OPG）和马尔可夫决策过程（MDP）来提出模型，并使用双重深度Q网络（DDQN）来解决最优卸载策略的问题。 |
| [^12] | [Causal Effect Estimation from Observational and Interventional Data Through Matrix Weighted Linear Estimators.](http://arxiv.org/abs/2306.06002) | 本研究提出了一种通过矩阵加权线性估计器结合观测数据和干预数据来推断因果效应的方法，并证明其在无限样本极限下是渐近无偏的。在混淆严重且观测数据和干预数据的比例大的情况下，该方法具有良好的效果。 |
| [^13] | [S$^{3}$: Increasing GPU Utilization during Generative Inference for Higher Throughput.](http://arxiv.org/abs/2306.06000) | 该论文提出了一种名为S$^{3}$的方法，通过预测输出序列长度并调度生成查询，以提高设备资源利用率和吞吐量，该方法比其他方法提高了6.49倍的吞吐量。 |
| [^14] | [Query Rewriting with Disjunctive Existential Rules and Mappings.](http://arxiv.org/abs/2306.05973) | 本研究提出了一种完备的查询重写算子，同时证明了存在一些连接查询无法进行UCQ重写。对于映射问题，则发现其判定是否需要经过UC﻿Q重写通常是个coNP难问题。 |
| [^15] | [Automating Model Comparison in Factor Graphs.](http://arxiv.org/abs/2306.05965) | 本文基于自定义混合节点 Forney 样式的因子图消息传递，实现了高效自动化贝叶斯模型平均、选择和组合，并缩短了模型设计周期。 |
| [^16] | [Evaluating the Social Impact of Generative AI Systems in Systems and Society.](http://arxiv.org/abs/2306.05949) | 提出了一种标准方法来评估任何模态的生成AI系统的社会影响，分为基础系统和社会方面的评估，涵盖7个社会影响类别，包括偏见、隐私保护、环境成本等。 |
| [^17] | [Time Series Continuous Modeling for Imputation and Forecasting with Implicit Neural Representations.](http://arxiv.org/abs/2306.05880) | 该论文提出了基于INR的时间序列连续建模方法，解决了处理缺失数据、不规则采样和多传感器不对准观测等重复建模问题，并在预测和插值任务中取得了最新的性能表现，具有很好的泛化能力。 |
| [^18] | [Is Normalization Indispensable for Multi-domain Federated Learning?.](http://arxiv.org/abs/2306.05879) | 本研究旨在解决联邦学习中的多领域问题。我们提出一种新的方法，FedWon，通过消除规范化步骤来有效地处理来自不同领域的数据。 |
| [^19] | [Detecting Adversarial Directions in Deep Reinforcement Learning to Make Robust Decisions.](http://arxiv.org/abs/2306.05873) | 该论文提出了一种检测非鲁棒方向的新方法，通过局域二次逼近来检测对抗性攻击，并为安全观测和对抗性观测之间的基本截止提供了理论基础。并且该方法是非常有效的，能成功检测到对抗性方向并做出鲁棒决策。 |
| [^20] | [Motion-DVAE: Unsupervised learning for fast human motion denoising.](http://arxiv.org/abs/2306.05846) | 该文章介绍Motion-DVAE，一种用于人体运动依赖关系的运动先验，以实现快速的人体运动去噪。其无监督学习的去噪方法结合了回归和基于优化的方法。 |
| [^21] | [Domain-Agnostic Batch Bayesian Optimization with Diverse Constraints via Bayesian Quadrature.](http://arxiv.org/abs/2306.05843) | 本论文提出了cSOBER，一种处理多样化约束条件、离散和混合空间、未知约束以及查询拒绝问题的领域无关型贝叶斯优化算法。 |
| [^22] | [Can Large Language Models Infer Causation from Correlation?.](http://arxiv.org/abs/2306.05836) | 本文提出了一个新的任务（Corr2Cause），用于测量大型语言模型的因果推断能力，并通过实验发现这些模型在这个任务上表现很差。 |
| [^23] | [How Can Recommender Systems Benefit from Large Language Models: A Survey.](http://arxiv.org/abs/2306.05817) | 本文对将大型语言模型（LLM）应用于推荐系统进行了全面的调查研究，从两个角度总结了现有的研究工作：如何在推荐系统中调整LLM和调整LLM时在哪里调整。最后，我们提出了一些潜在的研究方向和挑战。 |
| [^24] | [Incorporating Prior Knowledge in Deep Learning Models via Pathway Activity Autoencoders.](http://arxiv.org/abs/2306.05813) | 本研究提出了一种基于先验知识的深度自编码框架PAAE，将生物通路信息融入深度学习模型，可提高对疾病的预测建模和个性化治疗策略。 |
| [^25] | [Interactive Explanation with Varying Level of Details in an Explainable Scientific Literature Recommender System.](http://arxiv.org/abs/2306.05809) | 本文旨在采用以用户为中心的交互式解释模型，在推荐系统中为用户提供不同细节级别的解释，赋予用户个性化解释的能力。 |
| [^26] | [Strategies to exploit XAI to improve classification systems.](http://arxiv.org/abs/2306.05801) | 本文研究了利用XAI方法改进分类系统的策略，探究了两种使用解释来提高模型性能的方法，并在三个数据集上进行实证评估，结果表明，Integrated Gradients方法创建的解释可以突出输入特征从而提高模型性能。 |
| [^27] | [Adaptivity Complexity for Causal Graph Discovery.](http://arxiv.org/abs/2306.05781) | 研究了因果图发现的适应性复杂度，提供了一个r-adaptive算法在最小化总干预次数的同时正确学习出因果图。 |
| [^28] | [Fair yet Asymptotically Equal Collaborative Learning.](http://arxiv.org/abs/2306.05764) | 本文探讨了一种公平的协作学习激励设计，避免了“富者越富”的现象，并为较少资源的节点提供了长期平等的机会。 |
| [^29] | [From psychological traits to safety warnings: three studies on recommendations in a smart home environment.](http://arxiv.org/abs/2306.05752) | 本文研究了智能居家环境中基于心理特征的安全警告建议，发现认知需求等特征影响建议使用方式，易懂的安全说明比警告更具说服力。 |
| [^30] | [An End-to-End Reinforcement Learning Approach for Job-Shop Scheduling Problems Based on Constraint Programming.](http://arxiv.org/abs/2306.05747) | 本文提出了一种新颖的基于约束编程和强化学习的端到端方法，通过通用CP编码、约束条件和反映JSSP最优标准的奖励函数，可为大型作业车间调度问题产生最优或近似最优解。 |
| [^31] | [Challenges and Opportunities for the Design of Smart Speakers.](http://arxiv.org/abs/2306.05741) | 本文通过对35篇论文的文献综述以及15名智能音箱用户的访谈，总结出了智能音箱设计中的五个主题和四个设计挑战，同时提出了四个设计机遇空间，如提供信息支持，在设计中融入用户的心理模型以及整合平静的设计原则等。 |
| [^32] | [Multimodal Explainable Artificial Intelligence: A Comprehensive Review of Methodological Advances and Future Research Directions.](http://arxiv.org/abs/2306.05731) | 本文系统地分析了多模态可解释人工智能（MXAI）领域的最新进展和未来研究方向，从预测任务和数据集到MXAI方法和评估度量标准进行了全面介绍和讨论。 |
| [^33] | [In-Sample Policy Iteration for Offline Reinforcement Learning.](http://arxiv.org/abs/2306.05726) | 本文提出了一种采用样本内策略迭代的算法来增强离线强化学习中的行为规则方法，在实验中取得了显著的改进。 |
| [^34] | [Beyond Surface Statistics: Scene Representations in a Latent Diffusion Model.](http://arxiv.org/abs/2306.05720) | 本文探究了潜在扩散模型内部是否创建和使用简单场景几何内部表示，使用线性探针发现LDM内部激活提供了关于3D深度数据和突出对象/背景分离的线性表示，在图像合成中具有因果作用, 可用于LDM输出的简单高级编辑。 |
| [^35] | [Pave the Way to Grasp Anything: Transferring Foundation Models for Universal Pick-Place Robots.](http://arxiv.org/abs/2306.05716) | 本研究提出了一种基于语言分割掩模的新方法，用于解决通用型机器人的泛化能力问题，提高了在开放域场景中新对象的抓取操作的学习效率和推广效果。 |
| [^36] | [Exploring the Responses of Large Language Models to Beginner Programmers' Help Requests.](http://arxiv.org/abs/2306.05715) | 研究探究了大型语言模型（LLMs）对学生程序员求助请求的回应能力，评估了其在识别学生问题代码方面的表现。GPT-3.5在大多数方面表现优于Codex，两个LLM经常在每个学生程序中找到至少一个实际问题，但都未能找到全部问题。 |
| [^37] | [Judging LLM-as-a-judge with MT-Bench and Chatbot Arena.](http://arxiv.org/abs/2306.05685) | 研究使用强大的LLM作为评判员，通过引入两个基准测试来确认LLM评判员和人类偏好之间的一致性，并可调整聊天助手的模型架构和微调方法来提高其性能。 |
| [^38] | [Lightweight Monocular Depth Estimation via Token-Sharing Transformer.](http://arxiv.org/abs/2306.05682) | 本文提出了一种使用Transformer和全局令牌共享的轻量级单目深度估计方法，针对嵌入式设备进行了优化。 |
| [^39] | [RePaint-NeRF: NeRF Editting via Semantic Masks and Diffusion Models.](http://arxiv.org/abs/2306.05668) | 本文提出了一个新框架，利用现有的扩散模型来指导指定的 3D 内容的变化，并能够接受 RGB 图像作为输入并改变神经场景中的 3D 内容。 |
| [^40] | [COVER: A Heuristic Greedy Adversarial Attack on Prompt-based Learning in Language Models.](http://arxiv.org/abs/2306.05659) | 本文提出了一种启发式贪心对抗攻击，针对基于提示的模板在PLMs中可能存在的漏洞，通过字符级和单词级的破坏方法进行攻击，取得了较高的攻击成功率。 |
| [^41] | [Privacy Aware Question-Answering System for Online Mental Health Risk Assessment.](http://arxiv.org/abs/2306.05652) | 本研究提出了一种利用问答（QA）方法进行心理健康风险评估的技术，在保护用户数据的前提下，通过预训练的语言模型对用户社交媒体数据进行分类，并且应用于两个大型心理健康数据集。结果表明，该方法对于心理健康用例尤其有效。 |
| [^42] | [Differentially Private Sharpness-Aware Training.](http://arxiv.org/abs/2306.05651) | 本文提出了一种能够缓解隐私-优化制约关系的锐化感知训练方法。 |
| [^43] | [Customizing General-Purpose Foundation Models for Medical Report Generation.](http://arxiv.org/abs/2306.05642) | 这项工作中，我们提出了一种自定义通用基础模型以用于医疗报告生成的方法，其利用轻量级查询Transformer连接两个FMs，并在三个基准数据集上实现了最先进的结果。 |
| [^44] | [Revisiting Permutation Symmetry for Merging Models between Different Datasets.](http://arxiv.org/abs/2306.05641) | 本研究通过理论和实证分析表明，不同数据集合并模型的准确性下降更为显著，因为每个数据集的不同损失函数使得合并更加困难。此外，通过数据集压缩创建的压缩数据集可以作为原数据集的替代品。 |
| [^45] | [A Unified Generative Approach to Product Attribute-Value Identification.](http://arxiv.org/abs/2306.05605) | 本文探索了一种生成式方法来统一处理电子商务平台上产品属性值识别任务，实验结果表明该方法在大规模真实世界数据集上的表现优于现有的基于提取和分类的方法。 |
| [^46] | [The Viability of Domain Constrained Coalition Formation for Robotic Collectives.](http://arxiv.org/abs/2306.05590) | 该论文研究了如何在领域约束下，设计适用于大规模机器人集群的联盟形成算法，提出了一种基于拍卖算法的混合改进方法，可提高任务分配效率，并有应用前景。 |
| [^47] | [Multi-body SE(3) Equivariance for Unsupervised Rigid Segmentation and Motion Estimation.](http://arxiv.org/abs/2306.05584) | 本文提出了一种基于SE（3）等变结构和非监督训练策略的方法，可以实现刚性分割和运动估计，不需要类别信息且具有极高的模型效率。 |
| [^48] | [A newborn embodied Turing test for view-invariant object recognition.](http://arxiv.org/abs/2306.05582) | 本文提出了一种新的实验方法 - “新生儿身体图灵测试”，能够在相同环境中比较新生动物和机器的学习能力。研究结果表明，实验中的机器能够自发地发展视觉能力。 |
| [^49] | [AircraftVerse: A Large-Scale Multimodal Dataset of Aerial Vehicle Designs.](http://arxiv.org/abs/2306.05562) | AircraftVerse是一个公开可用的飞行器设计数据集，包含27,714个不同的设计，是具有此复杂程度的工程设计最大的语料库。每个设计都涵盖了飞行器设计领域的多个物理领域和多种表示形式。 |
| [^50] | [Simulation and Prediction of Countercurrent Spontaneous Imbibition at Early and Late Times Using Physics-Informed Neural Networks.](http://arxiv.org/abs/2306.05554) | 本文通过物理信息神经网络模型对多孔材料中的逆流自发渗透过程进行了早期和晚期的模拟和预测，并使用改变变量技术来改进模型性能。 |
| [^51] | [Bias Against 93 Stigmatized Groups in Masked Language Models and Downstream Sentiment Classification Tasks.](http://arxiv.org/abs/2306.05550) | 本研究研究了英语预训练的Masked Language Models（MLMs）以及它们的下游情感分类任务对美国93个社会污名化群体的偏见，为了评估93个污名化条件的偏见存在，我们对它们进行了比较分析，找到了偏见存在的表现。 |
| [^52] | [DetectLLM: Leveraging Log Rank Information for Zero-Shot Detection of Machine-Generated Text.](http://arxiv.org/abs/2306.05540) | 作者提出了两种零样本方法，DetectLLM-LRR和DetectLLM-NPR，可以通过利用日志排名信息来检测机器生成的文本，实验表明这些方法在检测效果上超过了现有的最佳方法。 |
| [^53] | [Detecting Check-Worthy Claims in Political Debates, Speeches, and Interviews Using Audio Data.](http://arxiv.org/abs/2306.05535) | 政治辩论、演讲和访谈中的值得核实的论断可以使用音频数据进行检测和确认，这可帮助主持人、记者和事实核查组织进行工作。 |
| [^54] | [FACTIFY3M: A Benchmark for Multimodal Fact Verification with Explainability through 5W Question-Answering.](http://arxiv.org/abs/2306.05523) | FACTIFY3M是一个以多模式虚假信息验证为目标的数据集。虚假信息如今已成为当下重大的社会问题，这一数据集旨在通过多模式验证来及时识别和缓解虚假信息。 |
| [^55] | [Word-Level Explanations for Analyzing Bias in Text-to-Image Models.](http://arxiv.org/abs/2306.05500) | 本文探讨了文本到图像模型中存在的少数族裔偏见，提出了一种利用屏蔽语言模型计算提示中单词得分的方法，并通过实验证明其可以识别生成的图像中存在的社会刻板印象。 |
| [^56] | [Prompt Injection attack against LLM-integrated Applications.](http://arxiv.org/abs/2306.05499) | 本研究分析了LLM集成应用中的提示注入攻击的复杂性和影响，提出了一种新颖的黑盒提示注入攻击技术HouYi，并揭示了应用程序提示机制中以前未知和严重低估的漏洞。我们的研究呼吁进一步开发全面的防御措施，以抵御LLM集成应用中的提示注入攻击。 |
| [^57] | [Reevaluating Loss Functions: Enhancing Robustness to Label Noise in Deep Learning Models.](http://arxiv.org/abs/2306.05497) | 本文研究了使用噪声鲁棒损失函数增强深度学习模型对标签噪声的鲁棒性，并提出了一种无需超参数调整的新技术：包括输出偏置。 |
| [^58] | [Multi-Modal Classifiers for Open-Vocabulary Object Detection.](http://arxiv.org/abs/2306.05493) | 本文提出了一种开放词汇物体检测的多模态分类器，能够在推断过程中检测超出训练范畴的目标，并优于传统基线模型。 |
| [^59] | [Learnability with PAC Semantics for Multi-agent Beliefs.](http://arxiv.org/abs/2306.05490) | 本文提供了一种新的技术基础，以证明可以用PAC学习算法来学习多智能体认知逻辑，并实现了隐式学习来应对PAC语义强健学习困难。 |
| [^60] | [Artificial General Intelligence for Medical Imaging.](http://arxiv.org/abs/2306.05480) | 本文探讨了人工通用智能模型在医学成像中的应用，重点关注基础的大型语言、视觉和多模态模型。通过整合临床专业知识、领域知识和多模态能力来开发和部署AGI能够解决医学领域面临的挑战和问题。 |
| [^61] | [Latent Phrase Matching for Dysarthric Speech.](http://arxiv.org/abs/2306.05446) | 患有语言障碍的人在现有消费类语音识别系统中表现不佳，作者提出了一种基于个性化短语识别系统用于适应其非典型的语音模式，其具有很好的泛化性能，并在数据集上有很好的表现。 |
| [^62] | [PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark for Finance.](http://arxiv.org/abs/2306.05443) | 本文介绍了PIXIU框架，其中包括基于Fine-tuning LLaMA的第一个金融语言模型、包含136K数据样本用于Fine-tuning的第一个指令数据，以及具有5个任务和9个数据集的评估基准。通过对各种金融任务、金融文档类型和金融数据模态考虑，构建了大规模的多任务指令数据集，利用该数据集提出了名为FinMA的金融语言模型，以便对各种金融任务进行指令跟随。 |
| [^63] | [CLC: Cluster Assignment via Contrastive Representation Learning.](http://arxiv.org/abs/2306.05439) | 本文提出了一种基于对比学习的聚类方法（CLC），它使用对比学习直接学习聚类分配，并在大规模数据集上取得了更好的聚类性能。 |
| [^64] | [One-step Multi-view Clustering with Diverse Representation.](http://arxiv.org/abs/2306.05437) | 本文提出了一种一步多视角聚类与多样性表征的方法，将多视角学习和k-means聚类融合到一个统一框架中，实验结果表明其在各种标准的多视角数据集上都优于现有算法。 |
| [^65] | [Towards End-to-end Speech-to-text Summarization.](http://arxiv.org/abs/2306.05432) | 该论文提出了一种迈向端到端语音到文本摘要技术的方法，这种技术可以用于过滤和跟踪每天上传在线的广播新闻，并能够产生丰富的潜在表示，但需要进一步的研究来提高其有效性和鲁棒性。 |
| [^66] | [RRWKV: Capturing Long-range Dependencies in RWKV.](http://arxiv.org/abs/2306.05176) | 本文介绍了一种新的RRWKV架构，它在保持记忆和计算效率的同时，通过加入回顾能力有效地捕捉长距离依赖关系。 |
| [^67] | [Is AI the better programming partner? Human-Human Pair Programming vs. Human-AI pAIr Programming.](http://arxiv.org/abs/2306.05153) | 人工智能与人类程序员共同开发可以通过设计良好的AI编程助手，增强双方合作的生产力。 |
| [^68] | [Generalizable Low-Resource Activity Recognition with Diverse and Discriminative Representation Learning.](http://arxiv.org/abs/2306.04641) | 提出了一种新方法DDLearn，通过构建自监督学习任务，在考虑多样化和区分化学习的基础上提高通用低资源人类活动识别的性能。 |
| [^69] | [Integrating Geometric Control into Text-to-Image Diffusion Models for High-Quality Detection Data Generation via Text Prompt.](http://arxiv.org/abs/2306.04607) | GeoDiffusion使用文本提示将各种几何条件转化为图像，生成高质量的检测数据，性能优于现有方法。 |
| [^70] | [Your Value Function is a Control Barrier Function: Verification of Learned Policies using Control Theory.](http://arxiv.org/abs/2306.04026) | 本研究将控制理论中的验证方法应用于强化学习中的价值函数，提出了新的度量方法以验证安全控制任务中的价值函数，并代表了通用、可伸缩和可验证的控制系统设计框架的第一步。 |
| [^71] | [Towards Fairness in Personalized Ads Using Impression Variance Aware Reinforcement Learning.](http://arxiv.org/abs/2306.03293) | 本文提出了一个名为VRS的框架，通过印象方差感知的方式对广告进行重新排序，以实现更公平的个性化广告结果。 |
| [^72] | [SERT: A Transfomer Based Model for Spatio-Temporal Sensor Data with Missing Values for Environmental Monitoring.](http://arxiv.org/abs/2306.03042) | 该论文提出了两种模型用于处理具有缺失值的多变量不对齐稀疏时间序列数据，其中一种是基于Transformer的模型SERT，另一种是提供可解释结果的简单模型SST-ANN |
| [^73] | [Action-Evolution Petri Nets: a Framework for Modeling and Solving Dynamic Task Assignment Problems.](http://arxiv.org/abs/2306.02910) | 本文提出了一种新的建模和解决动态任务分配问题的框架—行动演变Petri网格。它提供了一种统一的建模技术，可以表示动态任务分配问题的所有要素。而且，该模型是可执行的，并且可以用于强化学习，以学习接近最优的分配策略。 |
| [^74] | [A Novel Correlation-optimized Deep Learning Method for Wind Speed Forecast.](http://arxiv.org/abs/2306.01986) | 该论文提出了一种基于深度知识学习的新方法，通过混合预训练和自编码器结构，同时利用基于相关性优化模型构建多层网络和序列到序列模型来提高风速预测的准确性和建模效果。 |
| [^75] | [Bigger, Better, Faster: Human-level Atari with human-level efficiency.](http://arxiv.org/abs/2305.19452) | 引入BBF基于价值函数的RL代理，在Atari 100K基准测试上实现超人类表现，具有人类效率，提出了在样本高效RL研究的ALE中更新目标的可能。 |
| [^76] | [BigVideo: A Large-scale Video Subtitle Translation Dataset for Multimodal Machine Translation.](http://arxiv.org/abs/2305.18326) | 提出了一个大规模的视频字幕翻译数据集BigVideo， 集成了4.5 million句子对和9981小时视频，设计了有歧义和明确的测试集，引入了一种对比学习方法，实验结果表明，视觉信息可以提高NMT模型的BLEU、BLEURT和COMET得分，有助于消除歧义，数据集和翻译模型公开可用。 |
| [^77] | [COMCAT: Towards Efficient Compression and Customization of Attention-Based Vision Models.](http://arxiv.org/abs/2305.17235) | 本文提出了一种高效的 Vision Transformer 压缩方法，在多头注意力层上进行了新的探究，相比当前最先进的剪枝方法表现更优，能够在使用更少参数的情况下提高模型精度。 |
| [^78] | [Learning to Act through Evolution of Neural Diversity in Random Neural Networks.](http://arxiv.org/abs/2305.15945) | 本文提出一种通过演化神经元中心参数来获得一组多样化的神经元，从而执行复杂计算的方法。研究显示，演化神经参数就足以使代理在不优化任何突触权重的情况下解决强化学习任务。 |
| [^79] | [LaDI-VTON: Latent Diffusion Textual-Inversion Enhanced Virtual Try-On.](http://arxiv.org/abs/2305.13501) | 本文介绍了LaDI-VTON，一种利用潜在扩散模型和文本反演组件增强虚拟试穿任务的解决方案，该模型是第一个将这两种方法相结合的模型，能够高质量还原商店服装的细节。 |
| [^80] | [The First Proven Performance Guarantees for the Non-Dominated Sorting Genetic Algorithm II (NSGA-II) on a Combinatorial Optimization Problem.](http://arxiv.org/abs/2305.13459) | 本论文对遗传算法在经典优化问题中的应用进行了研究，首次提供了经过验证的NSGA-II性能保证。 |
| [^81] | [Speech-Text Dialog Pre-training for Spoken Dialog Understanding with Explicit Cross-Modal Alignment.](http://arxiv.org/abs/2305.11579) | 本文提出了SPECTRA语音文本对话预训练模型，应用了新的时间位置预测任务来捕捉语音文本对齐，同时将回答选择任务推广到服务于口语对话理解，用于丰富话语表示。 |
| [^82] | [Demonstration-free Autonomous Reinforcement Learning via Implicit and Bidirectional Curriculum.](http://arxiv.org/abs/2305.09943) | 本文提出了一种无需演示的自主强化学习算法（IBC），通过辅助代理和基于最优输运的双向目标课程，能够在无需先前数据依赖的情况下，实现从非周期性交互中学习，并在稀疏任务相关交互的环境中取得更好的表现。 |
| [^83] | [How Do In-Context Examples Affect Compositional Generalization?.](http://arxiv.org/abs/2305.04835) | 本文提出了CoFe测试套件来调查上下文组合泛化。实验结果表明，上下文示例应该在结构上与测试用例类似，相互之间应该不同，而且单独地简单。 |
| [^84] | [SEGA: Structural Entropy Guided Anchor View for Graph Contrastive Learning.](http://arxiv.org/abs/2305.04501) | 本文提出了一种名为SEGA的锚点视图用于图形对比学习，该视图通过结构熵引导以保持输入图的基本信息，达到了较好的表现。 |
| [^85] | [How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?.](http://arxiv.org/abs/2305.01555) | 本文通过使用GPT-3.5模型在少样本关系抽取中，实现在四个不同数据集上的新的最优性能，并提出了与任务相关的指导说明和约束模式下的数据生成方法。 |
| [^86] | [Queer In AI: A Case Study in Community-Led Participatory AI.](http://arxiv.org/abs/2303.16972) | Queer in AI是一个基于社区参与的AI设计案例研究，通过拒绝等级制度而选择去中心化，在酷儿社群内部建立了援助和项目，同时努力改变酷儿社群外的参与者和机构。通过培育AI参与文化，欢迎和赋权边缘化参与者，为AI的参与式设计做出了更广泛的贡献。 |
| [^87] | [Interactive Explanations by Conflict Resolution via Argumentative Exchanges.](http://arxiv.org/abs/2303.15022) | 本文介绍了一种利用计算论证实现代理间冲突解决的交互式解释方法，适用于XAI，能够动态共享代理的信息以解决代理之间的冲突。 |
| [^88] | [Visual Abstraction and Reasoning through Language.](http://arxiv.org/abs/2303.04091) | 本论文提出了一种通过自然语言描述任务的通用框架来解决Abstraction and Reasoning Corpus（ARC）问题，虽然还没有在ARC上击败最先进的DSL模型，但我们展示了我们的方法具有巨大的潜力，可以解决先前未解决的任务。 |
| [^89] | [ExplainableFold: Understanding AlphaFold Prediction with Explainable AI.](http://arxiv.org/abs/2301.11765) | 本文提出了可解释AI框架ExplainableFold，用于对AlphaFold蛋白质结构预测进行解释。提供了接近实验的对氨基酸对3D蛋白质结构影响的理解，有潜力促进对蛋白质结构的更深入理解。 |
| [^90] | [Deep Laplacian-based Options for Temporally-Extended Exploration.](http://arxiv.org/abs/2301.11181) | 本文提出了一种基于深度学习的选项方法，以处理强化学习中的探索性动作选择问题，并利用最近的结果来拓展至可伸缩性更好的领域。 |
| [^91] | [An Energy-aware and Fault-tolerant Deep Reinforcement Learning based approach for Multi-agent Patrolling Problems.](http://arxiv.org/abs/2212.08230) | 本论文提出了一种基于无模型、深度多智能体强化学习的方法，以解决复杂巡逻环境中多个自主车辆协同执行任务的问题，该方法还考虑了能量消耗和容错等因素，以确保系统连续自适应地运行。 |
| [^92] | [Huber-energy measure quantization.](http://arxiv.org/abs/2212.08162) | 该论文提出了一种Huber能量量化的算法，用于找到目标概率定律的最佳逼近，通过最小化原测度与量化版本之间的统计距离来实现。该算法已在多维高斯混合物、维纳空间魔方等几个数据库上进行了测试。 |
| [^93] | [ViT-CX: Causal Explanation of Vision Transformers.](http://arxiv.org/abs/2211.03064) | 本文提出了一种新方法ViT-CX，通过基于补丁嵌入的因果影响来解释视觉Transformer(ViTs)，并考虑了ViTs的因果过决定性等特性，相比以前的方法更有意义且更忠实于模型。 |
| [^94] | [Unsupervised Video Domain Adaptation for Action Recognition: A Disentanglement Perspective.](http://arxiv.org/abs/2208.07365) | 本文基于解缠视角处理视频领域无监督自适应问题，通过逐步解缠静态和动态信息并使用多种约束方法，有效地移除空间领域特定信息和减少时间领域差异，实验结果验证了该方法的有效性和优越性。 |
| [^95] | [Graph Generative Model for Benchmarking Graph Neural Networks.](http://arxiv.org/abs/2207.04396) | 本文提出了一个名为计算图转换器（CGT）的图生成模型，可通过保护数据隐私的方式学习和复制真实世界图的分布，从而生成有代表性的基准测试图，让GNNs在其上展示与源图相似的任务性能。 |
| [^96] | [DGraph: A Large-Scale Financial Dataset for Graph Anomaly Detection.](http://arxiv.org/abs/2207.03579) | 本文介绍了一个名为DGraph的大规模金融数据集，提供了全面观察和广泛实验，揭示了异常节点和正常节点不同的特征和结构，标记和未标记节点都是检测欺诈者的必不可少的信息。 |
| [^97] | [Exploring Local Explanations of Nonlinear Models Using Animated Linear Projections.](http://arxiv.org/abs/2205.05359) | 本文介绍了一种使用动态线性投影方法来分析流行的非线性模型的局部解释的方法，探索预测变量之间的交互如何影响变量重要性估计，这对于理解模型的可解释性非常有用。 |
| [^98] | [Achieving the Pareto Frontier of Regret Minimization and Best Arm Identification in Multi-Armed Bandits.](http://arxiv.org/abs/2110.08627) | 本文研究了多臂老虎机中后悔最小化和最佳臂识别的帕累托前沿,设计了BoBW-lil'UCB $(\gamma)$算法，证明了没有算法能同时为RM和BAI目标表现最佳，BoBW-lil'UCB $(\gamma)$可在不同的$\gamma$值下实现RM或BAI的最优性能。 |
| [^99] | [Machine Semiotics.](http://arxiv.org/abs/2008.10522) | 本文提出机器符号学的思想，即机器不需要理解话语的传统意义，而是能够以格里斯语用学的方式绘制会话蕴涵说明。这个过程可以形式化为话语-意义对（UMP）的强化学习。 |

# 详细

[^1]: Prodigy: 一种快速自适应零参数学习算法

    Prodigy: An Expeditiously Adaptive Parameter-Free Learner. (arXiv:2306.06101v1 [cs.LG])

    [http://arxiv.org/abs/2306.06101](http://arxiv.org/abs/2306.06101)

    本文提出了一种基于自适应算法(如Adagrad和Adam)的学习率估计方法Prodigy和Resetting，可以快速且正确地估计到达解决方案所需的距离D，从而提高了模型的收敛速度，并在多个数据集和模型上进行了测试，实验表明该方法优于D-Adaptation并可达到手动调整Adam的测试准确度值。

    

    本文研究自适应算法(如Adagrad和Adam)中的学习率估计问题，描述了两种技术Prodigy和Resetting，可以证明地估计到达解决方案所需的距离D，以便最优设置学习率。我们的技术是基于学习率自由的D-Adaptation方法的修改，并通过$O(\sqrt{\log(D/d_0)})$的因子提高了D-Adaptation的收敛速度，其中$d_0$是$D$的初始估计值。我们在12个常见的逻辑回归基准数据集、在CIFAR10上训练的VGG11和ResNet-50、在Imagenet上训练的ViT、在IWSLT14上训练的LSTM、在Criteo数据集上训练的DLRM、在Knee MRI数据集上的VarNet，以及在BookWiki上训练的RoBERTa和GPT transformer上测试了我们的方法。我们的实验结果表明，我们的方法始终优于D-Adaptation，并达到手动调整Adam的测试准确度值。

    We consider the problem of estimating the learning rate in adaptive methods, such as Adagrad and Adam. We describe two techniques, Prodigy and Resetting, to provably estimate the distance to the solution $D$, which is needed to set the learning rate optimally. Our techniques are modifications of the D-Adaptation method for learning-rate-free learning. Our methods improve upon the convergence rate of D-Adaptation by a factor of $O(\sqrt{\log(D/d_0)})$, where $d_0$ is the initial estimate of $D$. We test our methods on 12 common logistic-regression benchmark datasets, VGG11 and ResNet-50 training on CIFAR10, ViT training on Imagenet, LSTM training on IWSLT14, DLRM training on Criteo dataset, VarNet on Knee MRI dataset, as well as RoBERTa and GPT transformer training on BookWiki. Our experimental results show that our approaches consistently outperform D-Adaptation and reach test accuracy values close to that of hand-tuned Adam.
    
[^2]: 利用大型语言模型进行可伸缩矢量图驱动的图像理解

    Leveraging Large Language Models for Scalable Vector Graphics-Driven Image Understanding. (arXiv:2306.06094v1 [cs.CV])

    [http://arxiv.org/abs/2306.06094](http://arxiv.org/abs/2306.06094)

    本文介绍了一种新方法，通过使用可伸缩矢量图(SVG)格式处理图像，使得大型语言模型(LLMs)能够直接理解和操作图像，而无需使用参数化的视觉组件。在图像分类、生成和上下文学习等任务上，该方法表现良好，具有鲁棒性和显著的性能提升。

    

    最近，大型语言模型(LLMs)在自然语言理解和生成方面取得了显著进展。然而，它们在计算机视觉领域的潜力仍然很大程度上没有被开发。本文介绍了一种新的探索性方法，使得LLMs能够使用可伸缩矢量图(SVG)格式处理图像。通过利用基于XML的SVG表述的文本描述而不是光栅图像，我们旨在弥合视觉和文本模态之间的差距，使LLMs能够直接理解和操作图像，而无需使用参数化的视觉组件。我们的方法仅利用LLMs的能力进行简单的图像分类、生成和上下文学习。我们展示了方法在判别和生成任务中的优异表现，重点介绍了它(i)对分布转移的鲁棒性，(ii)通过利用LLMs的上下文学习能力实现的显著改进，以及(iii)图像杂乱程度上的显著性能提高。

    Recently, large language models (LLMs) have made significant advancements in natural language understanding and generation. However, their potential in computer vision remains largely unexplored. In this paper, we introduce a new, exploratory approach that enables LLMs to process images using the Scalable Vector Graphics (SVG) format. By leveraging the XML-based textual descriptions of SVG representations instead of raster images, we aim to bridge the gap between the visual and textual modalities, allowing LLMs to directly understand and manipulate images without the need for parameterized visual components. Our method facilitates simple image classification, generation, and in-context learning using only LLM capabilities. We demonstrate the promise of our approach across discriminative and generative tasks, highlighting its (i) robustness against distribution shift, (ii) substantial improvements achieved by tapping into the in-context learning abilities of LLMs, and (iii) image unders
    
[^3]: 学会不进行欺骗

    Learning Not to Spoof. (arXiv:2306.06087v1 [cs.LG])

    [http://arxiv.org/abs/2306.06087](http://arxiv.org/abs/2306.06087)

    该论文提出了学习不进行欺骗的方法，并考虑了智能股票交易代理的欺诈行为识别和避免。

    

    随着基于强化学习（RL）的智能交易代理越来越普及，确保RL代理遵守法律、法规和人类行为期望变得更加重要。本文考虑了一系列实验，其中智能股票交易代理最大化利润，但可能无意中学会欺骗其参与的市场。本文首先引入手动编码的欺诈代理到一个多代理市场模拟中，并学习识别欺诈活动序列。然后，本文将手动编码的欺骗交易员替换为一个简单的最大化利润的RL代理，观察它是否会独立地学习欺诈行为，并尝试避免它。

    As intelligent trading agents based on reinforcement learning (RL) gain prevalence, it becomes more important to ensure that RL agents obey laws, regulations, and human behavioral expectations. There is substantial literature concerning the aversion of obvious catastrophes like crashing a helicopter or bankrupting a trading account, but little around the avoidance of subtle non-normative behavior for which there are examples, but no programmable definition. Such behavior may violate legal or regulatory, rather than physical or monetary, constraints.  In this article, I consider a series of experiments in which an intelligent stock trading agent maximizes profit but may also inadvertently learn to spoof the market in which it participates. I first inject a hand-coded spoofing agent to a multi-agent market simulation and learn to recognize spoofing activity sequences. Then I replace the hand-coded spoofing trader with a simple profit-maximizing RL agent and observe that it independently 
    
[^4]: 使用标记的上下文提示捕捉LLM妄想症

    Trapping LLM Hallucinations Using Tagged Context Prompts. (arXiv:2306.06085v1 [cs.CL])

    [http://arxiv.org/abs/2306.06085](http://arxiv.org/abs/2306.06085)

    本文提出一种使用标记的上下文提示的新方法，可以显著减少生成语言模型中的妄想症，提高对话代理的准确性和有效性。

    

    大型语言模型（LLM）的最新进展，例如ChatGPT，已经导致高度复杂的对话代理。但是，这些模型受到“妄想症”的困扰，即模型生成虚假或捏造的信息。解决这一挑战非常关键，特别是在各个领域采用AI驱动的平台时。本文提出了一种新方法，用于识别和标记LLM在其领域知识范围之外的问题，确保用户获得准确的信息。我们发现，结合嵌入的标记和上下文来对抗生成语言模型中的妄想症可以成功地应对。为此，我们使用生成的URL作为易于测试的捏造数据指标，在没有上下文提示-响应对的情况下基线依赖性妄想频率。我们观察到，在为测试的生成引擎提供问题提示时提供上下文可以显著减少总体妄想症。最后，我们评估了在上下文提示中放置标记如何影响检测妄想症。我们的实验表明，在LLM中标记的上下文提示提高了检测妄想症的准确性和有效性。

    Recent advances in large language models (LLMs), such as ChatGPT, have led to highly sophisticated conversation agents. However, these models suffer from "hallucinations," where the model generates false or fabricated information. Addressing this challenge is crucial, particularly with AI-driven platforms being adopted across various sectors. In this paper, we propose a novel method to recognize and flag instances when LLMs perform outside their domain knowledge, and ensuring users receive accurate information.  We find that the use of context combined with embedded tags can successfully combat hallucinations within generative language models. To do this, we baseline hallucination frequency in no-context prompt-response pairs using generated URLs as easily-tested indicators of fabricated data. We observed a significant reduction in overall hallucination when context was supplied along with question prompts for tested generative engines. Lastly, we evaluated how placing tags within cont
    
[^5]: CARSO: 对抗性合成观测的反对抗性召回

    CARSO: Counter-Adversarial Recall of Synthetic Observations. (arXiv:2306.06081v1 [cs.CV])

    [http://arxiv.org/abs/2306.06081](http://arxiv.org/abs/2306.06081)

    本文提出了一种新的图像分类的对抗性防御机制CARSO，该方法可以比最先进的对抗性训练更好地保护分类器，通过利用生成模型进行对抗净化来进行最终分类，并成功地保护自己免受未预见的威胁和最终攻击。

    

    本文提出了一种新的对抗性防御机制CARSO，用于图像分类，灵感来自认知神经科学的线索。该方法与对抗训练具有协同互补性，并依赖于被攻击分类器的内部表示的知识。通过利用生成模型进行对抗净化，该方法采样输入的重构来进行最终分类。在各种图像数据集和分类器体系结构上进行的实验评估表明，CARSO能够比最先进的对抗性训练更好地保护分类器——同时具有可接受的清洁准确度损失。此外，防御体系结构成功地保护自己免受未预见的威胁和最终攻击。代码和预训练模型可在https://github.com/获得。

    In this paper, we propose a novel adversarial defence mechanism for image classification -- CARSO -- inspired by cues from cognitive neuroscience. The method is synergistically complementary to adversarial training and relies on knowledge of the internal representation of the attacked classifier. Exploiting a generative model for adversarial purification, conditioned on such representation, it samples reconstructions of inputs to be finally classified. Experimental evaluation by a well-established benchmark of varied, strong adaptive attacks, across diverse image datasets and classifier architectures, shows that CARSO is able to defend the classifier significantly better than state-of-the-art adversarial training alone -- with a tolerable clean accuracy toll. Furthermore, the defensive architecture succeeds in effectively shielding itself from unforeseen threats, and end-to-end attacks adapted to fool stochastic defences. Code and pre-trained models are available at https://github.com/
    
[^6]: 视觉词汇描述提升零样本图像分类

    Visually-Grounded Descriptions Improve Zero-Shot Image Classification. (arXiv:2306.06077v1 [cs.CV])

    [http://arxiv.org/abs/2306.06077](http://arxiv.org/abs/2306.06077)

    本文提出了一种称为V-GLOSS的新方法，它利用现代语言模型和语义知识库生成具有视觉基础的类别描述，提高了零样本图像分类的准确性，并引入了一个带有类别描述的银标准数据集。

    

    语言视觉模型如CLIP在零样本视觉任务（例如零样本图像分类ZSIC）方面取得了显著进展。然而，生成具体和富有表现力的类别描述仍然是一个主要挑战。现有方法存在粒度和标签歧义等问题。为了解决这些挑战，我们提出了一种新方法V-GLOSS：Visual Glosses，它利用现代语言模型和语义知识库来生成具有视觉基础的类别描述。我们通过在基准ZSIC数据集（包括ImageNet和STL-10）上实现最先进的结果来展示V-GLOSS的有效性。此外，我们引入了一个由V-GLOSS生成的带有类别描述的银标准数据集，并展示其用于视觉任务的有用性。我们提供了源代码和数据集。

    Language-vision models like CLIP have made significant progress in zero-shot vision tasks, such as zero-shot image classification (ZSIC). However, generating specific and expressive class descriptions remains a major challenge. Existing approaches suffer from granularity and label ambiguity issues. To tackle these challenges, we propose V-GLOSS: Visual Glosses, a novel method leveraging modern language models and semantic knowledge bases to produce visually-grounded class descriptions. We demonstrate V-GLOSS's effectiveness by achieving state-of-the-art results on benchmark ZSIC datasets including ImageNet and STL-10. In addition, we introduce a silver dataset with class descriptions generated by V-GLOSS, and show its usefulness for vision tasks. We make available our code and dataset.
    
[^7]: 使用Sentinel-1, Sentinel-2和Landsat-9图像融合改进洪水图制作以识别受灾人口和基础设施

    Improved flood mapping for efficient policy design by fusion of Sentinel-1, Sentinel-2, and Landsat-9 imagery to identify population and infrastructure exposed to floods. (arXiv:2306.06074v1 [cs.CV])

    [http://arxiv.org/abs/2306.06074](http://arxiv.org/abs/2306.06074)

    通过融合光学和SAR数据，提出了一种新方法进行洪水图制作，并在巴基斯坦2022年的洪水中应用，可准确识别受灾人口和基础设施，以帮助制定理智的政策。

    

    可靠且廉价的洪水水位估计工具有助于有效的灾害管理。光学和SAR图像的应用提供了一种扩展可用性和增强洪水图制作可靠性的手段。我们提出了一种将这两种图像合并到一个共同数据空间中的方法，并展示了其在巴基斯坦2022年洪水中识别受灾人口和基础设施方面的应用。光学和SAR数据的合并为我们在云层密集区域提供了改进的观测，然后用于获得更多的洪水图制作应用见解。使用WorldPop和OSM的开放源数据集，分别用于人口和道路，使该练习具有全球复制的能力。洪水图与人口和基础设施的空间数据的整合有助于制定明智的政策。我们已经表明，在巴基斯坦信德省五个受洪水影响最严重的地区中，受影响的人口和基础设施涵盖率的前五名区域有很大的顺序差异。

    A reliable yet inexpensive tool for the estimation of flood water spread is conducive for efficient disaster management. The application of optical and SAR imagery in tandem provides a means of extended availability and enhanced reliability of flood mapping. We propose a methodology to merge these two types of imagery into a common data space and demonstrate its use in the identification of affected populations and infrastructure for the 2022 floods in Pakistan. The merging of optical and SAR data provides us with improved observations in cloud-prone regions; that is then used to gain additional insights into flood mapping applications. The use of open source datasets from WorldPop and OSM for population and roads respectively makes the exercise globally replicable. The integration of flood maps with spatial data on population and infrastructure facilitates informed policy design. We have shown that within the top five flood-affected districts in Sindh province, Pakistan, the affected 
    
[^8]: 结合元策略和蒙特卡罗规划，实现在部分可观测环境中可扩展的基于类型的推理

    Combining a Meta-Policy and Monte-Carlo Planning for Scalable Type-Based Reasoning in Partially Observable Environments. (arXiv:2306.06067v1 [cs.AI])

    [http://arxiv.org/abs/2306.06067](http://arxiv.org/abs/2306.06067)

    本文提出了基于元策略和蒙特卡罗规划的POTMMCP算法，在部分可观测环境中实现了可扩展的基于类型的推理。

    

    在多智能体系统中，设计能够与其他代理有效交互而无需事先协调的自主代理是一个核心问题。基于类型的推理方法通过维护对其他代理的一组潜在行为信念来实现这一目标。然而，当前的方法存在一定局限性，它们认为其他代理的状态和行动是完全可观测的，或者在处理更大的问题和更长的计划时缺乏高效性。我们提出了部分可观测类型的元蒙特卡罗规划(POTMMCP)，这是一种基于在线蒙特卡罗树搜索的类型推理大规模部分可观测环境规划方法。POTMMCP结合了一种新颖的元策略来指导搜索和评估信念，使其能够以更少的规划时间更有效地搜索更长的时间间隔。我们展示了我们的方法在极限状态下收敛到最优解，并通过实验证明它能够有效适应。

    The design of autonomous agents that can interact effectively with other agents without prior coordination is a core problem in multi-agent systems. Type-based reasoning methods achieve this by maintaining a belief over a set of potential behaviours for the other agents. However, current methods are limited in that they assume full observability of the state and actions of the other agent or do not scale efficiently to larger problems with longer planning horizons. Addressing these limitations, we propose Partially Observable Type-based Meta Monte-Carlo Planning (POTMMCP) - an online Monte-Carlo Tree Search based planning method for type-based reasoning in large partially observable environments. POTMMCP incorporates a novel meta-policy for guiding search and evaluating beliefs, allowing it to search more effectively to longer horizons using less planning time. We show that our method converges to the optimal solution in the limit and empirically demonstrate that it effectively adapts 
    
[^9]: SNeL：用于基于实体的多模态场景理解的结构化神经符号语言

    SNeL: A Structured Neuro-Symbolic Language for Entity-Based Multimodal Scene Understanding. (arXiv:2306.06036v1 [cs.AI])

    [http://arxiv.org/abs/2306.06036](http://arxiv.org/abs/2306.06036)

    SNeL是一种结构化神经符号语言，通过将高级符号推理与低级神经处理对齐，有效地弥合了神经符号学分歧，可以广泛的应用于多种数据类型，是一种有价值的用于实体驱动的多模态场景理解工具。

    

    在人工智能不断发展的今天，多模态和神经符号学范式处于前沿地位，特别强调在不同模态下识别和交互实体及其关系。为了解决这个背景下复杂查询和交互的需求，我们介绍了SNeL（结构化神经符号语言），这是一种多功能查询语言，旨在促进神经网络处理多模态数据的微妙交互。SNeL的表达接口可以构建复杂查询，支持逻辑和算术运算符、比较器、嵌套等。这允许用户定位特定实体、指定其属性并限制结果，从而有效地从场景中提取信息。通过将高级符号推理与低级神经处理对齐，SNeL有效地弥合了神经符号学分歧。该语言的多功能性扩展到多种数据类型，包括图像、文本和语音，使其成为基于实体的多模态场景理解的有价值的工具。

    In the evolving landscape of artificial intelligence, multimodal and Neuro-Symbolic paradigms stand at the forefront, with a particular emphasis on the identification and interaction with entities and their relations across diverse modalities. Addressing the need for complex querying and interaction in this context, we introduce SNeL (Structured Neuro-symbolic Language), a versatile query language designed to facilitate nuanced interactions with neural networks processing multimodal data. SNeL's expressive interface enables the construction of intricate queries, supporting logical and arithmetic operators, comparators, nesting, and more. This allows users to target specific entities, specify their properties, and limit results, thereby efficiently extracting information from a scene. By aligning high-level symbolic reasoning with low-level neural processing, SNeL effectively bridges the Neuro-Symbolic divide. The language's versatility extends to a variety of data types, including imag
    
[^10]: HiTZ@Antidote: 面向数字医疗的基于论证的可解释人工智能

    HiTZ@Antidote: Argumentation-driven Explainable Artificial Intelligence for Digital Medicine. (arXiv:2306.06029v1 [cs.CL])

    [http://arxiv.org/abs/2306.06029](http://arxiv.org/abs/2306.06029)

    HiTZ@Antidote采用深度学习和论证理论，提供数字医疗领域高质量的可解释AI预测解释。

    

    基于机器学习的AI预测提供高质量的解释是一个具有挑战性和复杂性的任务。要使其正常工作，需要选择适当的解释泛化/细化水平；考虑解释受益者对所考虑的AI任务的熟悉程度的假设；涉及到对促成决策的具体元素的引用；利用可能不是预测过程的一部分的其他知识（例如专家证据）；并以清晰易懂、可能具说服力的方式表述解释。鉴于这些考虑因素，ANTIDOTE在可解释AI方面培育了一个综合的视角，将深度学习过程的低级特征与人类论证能力的更高级别方案相结合。ANTIDOTE将利用深度学习和论证理论的跨学科竞争优势，解决数字医学领域提供高质量AI预测解释的挑战。

    Providing high quality explanations for AI predictions based on machine learning is a challenging and complex task. To work well it requires, among other factors: selecting a proper level of generality/specificity of the explanation; considering assumptions about the familiarity of the explanation beneficiary with the AI task under consideration; referring to specific elements that have contributed to the decision; making use of additional knowledge (e.g. expert evidence) which might not be part of the prediction process; and providing evidence supporting negative hypothesis. Finally, the system needs to formulate the explanation in a clearly interpretable, and possibly convincing, way. Given these considerations, ANTIDOTE fosters an integrated vision of explainable AI, where low-level characteristics of the deep learning process are combined with higher level schemes proper of the human argumentation capacity. ANTIDOTE will exploit cross-disciplinary competences in deep learning and a
    
[^11]: 一个基于网络计算的Metaverse动态部分计算卸载方案

    A Dynamic Partial Computation Offloading for the Metaverse in In-Network Computing. (arXiv:2306.06022v1 [cs.DC])

    [http://arxiv.org/abs/2306.06022](http://arxiv.org/abs/2306.06022)

    该论文提出了一个基于网络计算的Metaverse动态部分计算卸载方案，能够在动态调整卸载策略的同时最小化能耗和延迟，解决了多个子任务的部分计算卸载问题，并将其分解为了两个子问题，分别针对用户端的任务切分问题和COIN端的任务卸载问题。这需要使用序数潜在博弈（OPG）和马尔可夫决策过程（MDP）来提出模型，并使用双重深度Q网络（DDQN）来解决最优卸载策略的问题。

    

    基于网络计算（COIN）范式是一个利用未使用的网络资源来执行某些任务以满足计算密集型应用程序（如Metaverse）的有前途的解决方案。在此基础上，我们考虑在COIN环境中针对Metaverse的多个子任务的部分计算卸载问题，以在动态调整卸载策略的同时最小化能耗和延迟。我们证明了该问题是NP难题，将其转化为两个子问题：用户端的任务切分问题（TSP）和COIN端的任务卸载问题（TOP）。我们将TSP建模为序数潜在博弈（OPG），并提出了一种分散算法来获取其纳什平衡（NE）。然后，我们将TOP建模为马尔可夫决策过程（MDP），提出了双重深度Q网络（DDQN）来解决最优卸载策略的问题。与传统的DDQN算法不同，智能代理在此不以随机方式抽样卸载决策

    The In-Network Computing (COIN) paradigm is a promising solution that leverages unused network resources to perform some tasks to meet up with computation-demanding applications, such as metaverse. In this vein, we consider the metaverse partial computation offloading problem for multiple subtasks in a COIN environment to minimise energy consumption and delay while dynamically adjusting the offloading policy based on the changing computation resources status. We prove that the problem is NP and thus transformed it into two subproblems: task splitting problem (TSP) on the user side and task offloading problem (TOP) on the COIN side. We modelled the TSP as an ordinal potential game (OPG) and proposed a decentralised algorithm to obtain its Nash Equilibrium (NE). Then, we model the TOP as Markov Decision Process (MDP) proposed double deep Q-network (DDQN) to solve for the optimal offloading policy. Unlike the conventional DDQN algorithm, where intelligent agents sample offloading decision
    
[^12]: 通过矩阵加权线性估计器从观测数据和干预数据推断因果效应

    Causal Effect Estimation from Observational and Interventional Data Through Matrix Weighted Linear Estimators. (arXiv:2306.06002v1 [stat.ME])

    [http://arxiv.org/abs/2306.06002](http://arxiv.org/abs/2306.06002)

    本研究提出了一种通过矩阵加权线性估计器结合观测数据和干预数据来推断因果效应的方法，并证明其在无限样本极限下是渐近无偏的。在混淆严重且观测数据和干预数据的比例大的情况下，该方法具有良好的效果。

    

    我们研究了多元治疗的混合观测数据和干预数据在混淆线性回归模型中的因果效应估计。我们表明，通过结合从观测和干预状态下得出的估计器，期望均方误差的统计效率可以得到提高。为此，我们基于矩阵加权线性估计器推导了方法，并证明了我们的方法在无限样本极限下是渐近无偏的。相比于使用干预数据和观测数据并集作为汇总估计器的情况，我们的方法具有重要的改进，因为只有当观测干预数据比的比例趋近于零时，其偏差才会消失。针对合成数据的研究进一步证明了我们的理论发现。在混淆严重且观测数据和干预数据的比例大的情况下，我们的估计器优于Stein型估计器和其他基准估计器。

    We study causal effect estimation from a mixture of observational and interventional data in a confounded linear regression model with multivariate treatments. We show that the statistical efficiency in terms of expected squared error can be improved by combining estimators arising from both the observational and interventional setting. To this end, we derive methods based on matrix weighted linear estimators and prove that our methods are asymptotically unbiased in the infinite sample limit. This is an important improvement compared to the pooled estimator using the union of interventional and observational data, for which the bias only vanishes if the ratio of observational to interventional data tends to zero. Studies on synthetic data confirm our theoretical findings. In settings where confounding is substantial and the ratio of observational to interventional data is large, our estimators outperform a Stein-type estimator and various other baselines.
    
[^13]: S$^{3}$: 提高生成推断 GPU 利用率的方法以达到更高的吞吐量

    S$^{3}$: Increasing GPU Utilization during Generative Inference for Higher Throughput. (arXiv:2306.06000v1 [cs.AR])

    [http://arxiv.org/abs/2306.06000](http://arxiv.org/abs/2306.06000)

    该论文提出了一种名为S$^{3}$的方法，通过预测输出序列长度并调度生成查询，以提高设备资源利用率和吞吐量，该方法比其他方法提高了6.49倍的吞吐量。

    

    利用大型语言模型生成文本需要消耗大量的内存。除了大型模型参数外，保存序列中前面标记信息的键/值（KV）缓存也可能比模型本身更大。在当前的LLM服务框架中，这个问题被加剧，因为其将最大序列长度的内存保留给KV缓存，以确保生成完整的序列，但输出序列长度是未知的。这限制了我们使用较小的批量大小，导致GPU利用率降低，吞吐量也降低。我们认为，设计一个具有先验输出序列长度的系统可以缓解这个问题。因此，我们提出了 S$^{3}$，它预测输出序列长度，基于预测调度生成查询以提高设备资源利用率和吞吐量，并处理预测错误。我们提出的方法使吞吐量比其他方法提高了6.49倍。

    Generating texts with a large language model (LLM) consumes massive amounts of memory. Apart from the already-large model parameters, the key/value (KV) cache that holds information about previous tokens in a sequence can grow to be even larger than the model itself. This problem is exacerbated in one of the current LLM serving frameworks which reserves the maximum sequence length of memory for the KV cache to guarantee generating a complete sequence as they do not know the output sequence length. This restricts us to use a smaller batch size leading to lower GPU utilization and above all, lower throughput. We argue that designing a system with a priori knowledge of the output sequence can mitigate this problem. To this end, we propose S$^{3}$, which predicts the output sequence length, schedules generation queries based on the prediction to increase device resource utilization and throughput, and handle mispredictions. Our proposed method achieves 6.49$\times$ throughput over those sy
    
[^14]: 带有分离存在规则和映射的查询重写

    Query Rewriting with Disjunctive Existential Rules and Mappings. (arXiv:2306.05973v1 [cs.DB])

    [http://arxiv.org/abs/2306.05973](http://arxiv.org/abs/2306.05973)

    本研究提出了一种完备的查询重写算子，同时证明了存在一些连接查询无法进行UCQ重写。对于映射问题，则发现其判定是否需要经过UC﻿Q重写通常是个coNP难问题。

    

    本文讨论了在带有分离存在规则和映射的情况下回答联合的连接查询的问题。我们首先提出了一个完备的查询重写算子，并且建立了一个追踪步骤和重写步骤之间的紧密联系。第二，我们表明对于任何“真正的分离”非递归规则，都存在一种连接查询没有UCQ重写的情况。最后，针对映射问题，我们证明了通过分离映射来确定UCQ是否通过UCQ重写的问题通常是一个coNP难问题，因此不太可能有一个多项式时间的算法。

    We consider the issue of answering unions of conjunctive queries (UCQs) with disjunctive existential rules and mappings. While this issue has already been well studied from a chase perspective, query rewriting within UCQs has hardly been addressed yet. We first propose a sound and complete query rewriting operator, which has the advantage of establishing a tight relationship between a chase step and a rewriting step. The associated breadth-first query rewriting algorithm outputs a minimal UCQ-rewriting when one exists. Second, we show that for any ``truly disjunctive'' nonrecursive rule, there exists a conjunctive query that has no UCQ-rewriting. It follows that the notion of finite unification sets (fus), which denotes sets of existential rules such that any UCQ admits a UCQ-rewriting, seems to have little relevance in this setting. Finally, turning our attention to mappings, we show that the problem of determining whether a UCQ admits a UCQ-rewriting through a disjunctive mapping is 
    
[^15]: 在因子图中自动进行模型比较

    Automating Model Comparison in Factor Graphs. (arXiv:2306.05965v1 [cs.LG])

    [http://arxiv.org/abs/2306.05965](http://arxiv.org/abs/2306.05965)

    本文基于自定义混合节点 Forney 样式的因子图消息传递，实现了高效自动化贝叶斯模型平均、选择和组合，并缩短了模型设计周期。

    

    在文献中，贝叶斯状态和参数估计已经被有效自动化，但对于模型比较尚未如此，因此仍需要容易出错和耗时的手动推导。因此，模型比较经常被忽视和忽略，尽管它很重要。本文通过在Forney样式的因子图上使用自定义混合节点上的消息传递来高效地自动化贝叶斯模型平均、选择和组合。进而可使用缩放因子同时执行参数和状态推断以及模型比较。这种方法缩短了模型设计周期，同时允许简单地扩展到分层和时间模型先验，以适应建模复杂的时变过程。

    Bayesian state and parameter estimation have been automated effectively in the literature, however, this has not yet been the case for model comparison, which therefore still requires error-prone and time-consuming manual derivations. As a result, model comparison is often overlooked and ignored, despite its importance. This paper efficiently automates Bayesian model averaging, selection, and combination by message passing on a Forney-style factor graph with a custom mixture node. Parameter and state inference, and model comparison can then be executed simultaneously using message passing with scale factors. This approach shortens the model design cycle and allows for the straightforward extension to hierarchical and temporal model priors to accommodate for modeling complicated time-varying processes.
    
[^16]: 评估生成AI系统在系统和社会中的社会影响

    Evaluating the Social Impact of Generative AI Systems in Systems and Society. (arXiv:2306.05949v1 [cs.CY])

    [http://arxiv.org/abs/2306.05949](http://arxiv.org/abs/2306.05949)

    提出了一种标准方法来评估任何模态的生成AI系统的社会影响，分为基础系统和社会方面的评估，涵盖7个社会影响类别，包括偏见、隐私保护、环境成本等。

    

    生成AI系统跨越文本、图像、音频、视频等多种模态，具有广泛的社会影响，但目前不存在官方标准来评估这些影响和应该评估哪些影响。本文提出了一种标准方法来评估任何模态的生成AI系统，分为两大类别：对于没有预定应用的基础系统可以评估什么，以及可以在社会中评估什么。我们描述了具体的社会影响类别以及如何评估基础技术系统、人民和社会。我们的基础系统框架定义了七个社会影响类别：偏见、刻板印象和表现性伤害；文化价值和敏感内容；不对等的性能；隐私和数据保护；财务成本；环境成本；以及数据和内容监管劳动成本。建议的评估方法适用于所有模态和分析。

    Generative AI systems across modalities, ranging from text, image, audio, and video, have broad social impacts, but there exists no official standard for means of evaluating those impacts and which impacts should be evaluated. We move toward a standard approach in evaluating a generative AI system for any modality, in two overarching categories: what is able to be evaluated in a base system that has no predetermined application and what is able to be evaluated in society. We describe specific social impact categories and how to approach and conduct evaluations in the base technical system, then in people and society. Our framework for a base system defines seven categories of social impact: bias, stereotypes, and representational harms; cultural values and sensitive content; disparate performance; privacy and data protection; financial costs; environmental costs; and data and content moderation labor costs. Suggested methods for evaluation apply to all modalities and analyses of the li
    
[^17]: 基于Implicit Neural Representations的时间序列连续建模用于插值和预测

    Time Series Continuous Modeling for Imputation and Forecasting with Implicit Neural Representations. (arXiv:2306.05880v1 [cs.LG])

    [http://arxiv.org/abs/2306.05880](http://arxiv.org/abs/2306.05880)

    该论文提出了基于INR的时间序列连续建模方法，解决了处理缺失数据、不规则采样和多传感器不对准观测等重复建模问题，并在预测和插值任务中取得了最新的性能表现，具有很好的泛化能力。

    

    尽管时间序列建模已被广泛探索，但在面对真实世界的数据时仍面临重大挑战。我们提出了一种新颖的建模方法，利用Implicit Neural Representations (INR)。该方法使我们能够有效地捕捉时间序列的连续性，并提供了自然的解决方案，以处理缺失数据、处理不规则采样或来自多个传感器的不对准观测等重复建模问题。通过引入条件调制INR参数并利用元学习技术，我们解决了模型泛化到未见样本和时间窗口移位的问题。通过大量实验，我们的模型展示了在预测和插值任务中领先的性能，同时在处理许多竞争模型无法处理的各种具有挑战性的场景方面展现了灵活性。

    Although widely explored, time series modeling continues to encounter significant challenges when confronted with real-world data. We propose a novel modeling approach leveraging Implicit Neural Representations (INR). This approach enables us to effectively capture the continuous aspect of time series and provides a natural solution to recurring modeling issues such as handling missing data, dealing with irregular sampling, or unaligned observations from multiple sensors. By introducing conditional modulation of INR parameters and leveraging meta-learning techniques, we address the issue of generalization to both unseen samples and time window shifts. Through extensive experimentation, our model demonstrates state-of-the-art performance in forecasting and imputation tasks, while exhibiting flexibility in handling a wide range of challenging scenarios that competing models cannot.
    
[^18]: 多领域联邦学习是否离不开标准化?

    Is Normalization Indispensable for Multi-domain Federated Learning?. (arXiv:2306.05879v1 [cs.LG])

    [http://arxiv.org/abs/2306.05879](http://arxiv.org/abs/2306.05879)

    本研究旨在解决联邦学习中的多领域问题。我们提出一种新的方法，FedWon，通过消除规范化步骤来有效地处理来自不同领域的数据。

    

    联邦学习通过分散在客户端上的协作式内部训练增强了数据隐私。然而，联邦学习面临诸多挑战，其中包括非独立同分布数据（non-i.i.d）导致的潜在性能下降和收敛受阻问题。我们的研究解决了一个关键但常常被忽视的问题——多领域联邦学习。在这种情况下，客户端数据来源于具有不同特征分布的各种领域，而不是标签分布。为了解决联邦学习中的多领域问题，我们提出了一种新方法称为不使用规范化的联邦学习（FedWon）。FedWon从一个观察出发，即批量归一化（BN）在有效地建模多个领域的统计信息方面面临挑战，而替代规范化技术具有自身的局限性。FedWon通过消除规范化步骤来解决这些问题。

    Federated learning (FL) enhances data privacy with collaborative in-situ training on decentralized clients. Nevertheless, FL encounters challenges due to non-independent and identically distributed (non-i.i.d) data, leading to potential performance degradation and hindered convergence. While prior studies predominantly addressed the issue of skewed label distribution, our research addresses a crucial yet frequently overlooked problem known as multi-domain FL. In this scenario, clients' data originate from diverse domains with distinct feature distributions, as opposed to label distributions. To address the multi-domain problem in FL, we propose a novel method called Federated learning Without normalizations (FedWon). FedWon draws inspiration from the observation that batch normalization (BN) faces challenges in effectively modeling the statistics of multiple domains, while alternative normalization techniques possess their own limitations. In order to address these issues, FedWon elimi
    
[^19]: 检测深度强化学习中的对抗性方向以做出鲁棒决策

    Detecting Adversarial Directions in Deep Reinforcement Learning to Make Robust Decisions. (arXiv:2306.05873v1 [cs.LG])

    [http://arxiv.org/abs/2306.05873](http://arxiv.org/abs/2306.05873)

    该论文提出了一种检测非鲁棒方向的新方法，通过局域二次逼近来检测对抗性攻击，并为安全观测和对抗性观测之间的基本截止提供了理论基础。并且该方法是非常有效的，能成功检测到对抗性方向并做出鲁棒决策。

    

    随着强化学习算法的不断发展，现在可以在具有高度复杂状态表示的MDPs中进行学习。然而，这种复杂度的增加以及观测空间维度的增加都带来了易受对抗性攻击的波动。为了解决这个策略不稳定性问题，我们提出了一种新方法，通过对深度神经策略损失的局域二次逼近来检测这些非鲁棒方向的存在。我们的方法为安全观测和对抗性观测之间的基本截止提供了理论基础。此外，我们的技术具有计算上的效率，并且不依赖于生成最坏情况方向的方法。我们在Arcade Learning Environment中进行了大量的实验，使用了多种不同的对抗性攻击技术。最显着的是，我们的方法是非常有效的，能够成功检测到对抗性方向并做出相应的鲁棒决策。

    Learning in MDPs with highly complex state representations is currently possible due to multiple advancements in reinforcement learning algorithm design. However, this incline in complexity, and furthermore the increase in the dimensions of the observation came at the cost of volatility that can be taken advantage of via adversarial attacks (i.e. moving along worst-case directions in the observation space). To solve this policy instability problem we propose a novel method to detect the presence of these non-robust directions via local quadratic approximation of the deep neural policy loss. Our method provides a theoretical basis for the fundamental cut-off between safe observations and adversarial observations. Furthermore, our technique is computationally efficient, and does not depend on the methods used to produce the worst-case directions. We conduct extensive experiments in the Arcade Learning Environment with several different adversarial attack techniques. Most significantly, w
    
[^20]: Motion-DVAE: 面向快速人体运动去噪的无监督学习

    Motion-DVAE: Unsupervised learning for fast human motion denoising. (arXiv:2306.05846v1 [cs.CV])

    [http://arxiv.org/abs/2306.05846](http://arxiv.org/abs/2306.05846)

    该文章介绍Motion-DVAE，一种用于人体运动依赖关系的运动先验，以实现快速的人体运动去噪。其无监督学习的去噪方法结合了回归和基于优化的方法。

    

    在从嘈杂的观测中恢复真实准确的人体运动中，姿态和运动先验至关重要。 在图像中进行姿态和形状估计已经取得了实质性进展，并且最近的研究表明，使用先验来提炼逐帧预测的结果取得了令人印象深刻的成果。 然而，许多运动先验仅模拟相邻姿态之间的过渡，并在耗时的优化过程中使用，这对许多需要实时运动捕捉的应用程序是有问题的。我们引入Motion-DVAE，这是一种运动先验，用于捕获人类运动的短期依赖关系。 作为动态变分自编码器（DVAE）模型系列的一部分，Motion-DVAE结合了VAE模型的生成能力和循环结构的时间建模。除此之外，我们提出了一种无监督学习的去噪方法，结合回归和基于优化的方法于一个框架中，用于实时的3D人体姿态估计。实验证明

    Pose and motion priors are crucial for recovering realistic and accurate human motion from noisy observations. Substantial progress has been made on pose and shape estimation from images, and recent works showed impressive results using priors to refine frame-wise predictions. However, a lot of motion priors only model transitions between consecutive poses and are used in time-consuming optimization procedures, which is problematic for many applications requiring real-time motion capture. We introduce Motion-DVAE, a motion prior to capture the short-term dependencies of human motion. As part of the dynamical variational autoencoder (DVAE) models family, Motion-DVAE combines the generative capability of VAE models and the temporal modeling of recurrent architectures. Together with Motion-DVAE, we introduce an unsupervised learned denoising method unifying regression- and optimization-based approaches in a single framework for real-time 3D human pose estimation. Experiments show that the
    
[^21]: 无领域偏见批量贝叶斯优化，通过贝叶斯积分处理多种约束条件

    Domain-Agnostic Batch Bayesian Optimization with Diverse Constraints via Bayesian Quadrature. (arXiv:2306.05843v1 [cs.LG])

    [http://arxiv.org/abs/2306.05843](http://arxiv.org/abs/2306.05843)

    本论文提出了cSOBER，一种处理多样化约束条件、离散和混合空间、未知约束以及查询拒绝问题的领域无关型贝叶斯优化算法。

    

    现实世界的优化问题通常具有多样的约束条件、离散和混合空间、高度可并行化等特点。同时，当存在未知约束时，例如在药物发现和动物实验安全性等领域，必须确立未知约束之后才能查询目标函数。现有工作通常仅针对上述某些特征而并非综合考虑。本文提出了cSOBER，一种基于SOBER算法的领域无关型谨慎并行主动采样器，考虑到了未知约束情况下的集成误差的影响并提出了处理方法，处理多种约束条件和未知约束查询拒绝的问题。

    Real-world optimisation problems often feature complex combinations of (1) diverse constraints, (2) discrete and mixed spaces, and are (3) highly parallelisable. (4) There are also cases where the objective function cannot be queried if unknown constraints are not satisfied, e.g. in drug discovery, safety on animal experiments (unknown constraints) must be established before human clinical trials (querying objective function) may proceed. However, most existing works target each of the above three problems in isolation and do not consider (4) unknown constraints with query rejection. For problems with diverse constraints and/or unconventional input spaces, it is difficult to apply these techniques as they are often mutually incompatible. We propose cSOBER, a domain-agnostic prudent parallel active sampler for Bayesian optimisation, based on SOBER of Adachi et al. (2023). We consider infeasibility under unknown constraints as a type of integration error that we can estimate. We propose 
    
[^22]: 大型语言模型能否从相关性中推断出因果关系?

    Can Large Language Models Infer Causation from Correlation?. (arXiv:2306.05836v1 [cs.CL])

    [http://arxiv.org/abs/2306.05836](http://arxiv.org/abs/2306.05836)

    本文提出了一个新的任务（Corr2Cause），用于测量大型语言模型的因果推断能力，并通过实验发现这些模型在这个任务上表现很差。

    

    因果推断是人类智慧的标志之一。虽然CausalNLP领域近年来引起了广泛关注，但NLP中现有的因果推断数据集主要依赖于从经验知识（例如常识知识）中发现因果关系。在本文中，我们提出了第一个基准数据集，用于测试大型语言模型（LLM）的纯因果推断能力。具体而言，我们制定了一个新的任务Corr2Cause，它采用一组相关语句并确定变量之间的因果关系。我们策划了一个大规模的数据集，其中包含超过400K个样本，我们在其中评估了17个现有的LLMs。通过我们的实验，我们确定了LLMs在因果推断技能方面的一个关键缺陷，并表明这些模型在该任务上的表现几乎接近随机。当我们尝试通过微调将LLMs重新用于这种技能时，这种缺陷在某种程度上得到了缓解，但我们发现这些模型仍然失败了。

    Causal inference is one of the hallmarks of human intelligence. While the field of CausalNLP has attracted much interest in the recent years, existing causal inference datasets in NLP primarily rely on discovering causality from empirical knowledge (e.g., commonsense knowledge). In this work, we propose the first benchmark dataset to test the pure causal inference skills of large language models (LLMs). Specifically, we formulate a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables. We curate a large-scale dataset of more than 400K samples, on which we evaluate seventeen existing LLMs. Through our experiments, we identify a key shortcoming of LLMs in terms of their causal inference skills, and show that these models achieve almost close to random performance on the task. This shortcoming is somewhat mitigated when we try to re-purpose LLMs for this skill via finetuning, but we find that these models still fa
    
[^23]: 推荐系统如何从大型语言模型中受益：一项调查研究

    How Can Recommender Systems Benefit from Large Language Models: A Survey. (arXiv:2306.05817v1 [cs.IR])

    [http://arxiv.org/abs/2306.05817](http://arxiv.org/abs/2306.05817)

    本文对将大型语言模型（LLM）应用于推荐系统进行了全面的调查研究，从两个角度总结了现有的研究工作：如何在推荐系统中调整LLM和调整LLM时在哪里调整。最后，我们提出了一些潜在的研究方向和挑战。

    

    推荐系统在匹配互联网应用程序用户的信息需求方面发挥着重要作用。在自然语言处理领域中，大型语言模型已经展现出了惊人的新兴能力（例如指令跟踪、推理），从而为将LLM调整到推荐系统中以提高性能和改善用户体验的研究方向带来了希望。在本文中，我们从应用导向的角度对此研究方向进行了全面的调查。我们首先从两个正交的角度总结了现有的研究工作：如何在推荐系统中调整LLM和调整LLM时在哪里调整。对于“在哪里”这个问题，我们讨论了LLM在推荐流程的不同阶段中可能发挥的作用，即特征工程、特征编码器、评分/排名函数和流程控制器。对于“如何”这个问题，我们调查了训练和推理策略，从而得出两个细粒度的分类标准，即是否调整LLM和是否将LLM作为独立模型或混合模型组件使用。最后，我们提出了在将LLM调整到RS中的一些挑战和潜在方向，包括与现有系统的集成、用户反馈、评估度量和知识蒸馏。

    Recommender systems (RS) play important roles to match users' information needs for Internet applications. In natural language processing (NLP) domains, large language model (LLM) has shown astonishing emergent abilities (e.g., instruction following, reasoning), thus giving rise to the promising research direction of adapting LLM to RS for performance enhancements and user experience improvements. In this paper, we conduct a comprehensive survey on this research direction from an application-oriented view. We first summarize existing research works from two orthogonal perspectives: where and how to adapt LLM to RS. For the "WHERE" question, we discuss the roles that LLM could play in different stages of the recommendation pipeline, i.e., feature engineering, feature encoder, scoring/ranking function, and pipeline controller. For the "HOW" question, we investigate the training and inference strategies, resulting in two fine-grained taxonomy criteria, i.e., whether to tune LLMs or not, a
    
[^24]: 基于通路活性自编码器的深度学习模型中融入先验知识

    Incorporating Prior Knowledge in Deep Learning Models via Pathway Activity Autoencoders. (arXiv:2306.05813v1 [cs.LG])

    [http://arxiv.org/abs/2306.05813](http://arxiv.org/abs/2306.05813)

    本研究提出了一种基于先验知识的深度自编码框架PAAE，将生物通路信息融入深度学习模型，可提高对疾病的预测建模和个性化治疗策略。

    

    鉴于高通量分子分析技术（例如转录组学）的计算分析取得的进展，方法的简单性和可解释性与方法的复杂性和可解释性较低之间存在一种二分法。此外，很少有方法试图将解释性转化为生物学相关术语，例如已知的通路级联。生物学通路反映信号事件或代谢转化。通过确定哪些通路涉及疾病并将此类通路数据作为先验知识纳入可能增强预测建模和个性化诊断治疗和预防疾病策略的能力。

    Motivation: Despite advances in the computational analysis of high-throughput molecular profiling assays (e.g. transcriptomics), a dichotomy exists between methods that are simple and interpretable, and ones that are complex but with lower degree of interpretability. Furthermore, very few methods deal with trying to translate interpretability in biologically relevant terms, such as known pathway cascades. Biological pathways reflecting signalling events or metabolic conversions are Small improvements or modifications of existing algorithms will generally not be suitable, unless novel biological results have been predicted and verified. Determining which pathways are implicated in disease and incorporating such pathway data as prior knowledge may enhance predictive modelling and personalised strategies for diagnosis, treatment and prevention of disease.  Results: We propose a novel prior-knowledge-based deep auto-encoding framework, PAAE, together with its accompanying generative varian
    
[^25]: 在可解释的科学文献推荐系统中采用不同细节级别的交互式解释

    Interactive Explanation with Varying Level of Details in an Explainable Scientific Literature Recommender System. (arXiv:2306.05809v1 [cs.IR])

    [http://arxiv.org/abs/2306.05809](http://arxiv.org/abs/2306.05809)

    本文旨在采用以用户为中心的交互式解释模型，在推荐系统中为用户提供不同细节级别的解释，赋予用户个性化解释的能力。

    

    传统上，可解释的推荐系统采用一种“一刀切”的方法，向每个用户提供相同程度的解释，而不考虑他们的个体需求和目标。此外，推荐系统中的解释大多以静态和非交互方式呈现。为填补这些研究空白，本文旨在采用以用户为中心的交互式解释模型，为用户提供不同细节级别的解释，并赋予用户基于其需求和偏好进行交互、控制和个性化解释的能力。我们采用以用户为中心的方法，设计了三个细节级别的交互式解释（基本、中级和高级），并在透明的推荐和兴趣建模应用（RIMA）中实现了它们。我们进行了一个定性用户研究（N=14），以调查提供不同细节级别的交互式解释对用户对系统可解释性的感知的影响。

    Explainable recommender systems (RS) have traditionally followed a one-size-fits-all approach, delivering the same explanation level of detail to each user, without considering their individual needs and goals. Further, explanations in RS have so far been presented mostly in a static and non-interactive manner. To fill these research gaps, we aim in this paper to adopt a user-centered, interactive explanation model that provides explanations with different levels of detail and empowers users to interact with, control, and personalize the explanations based on their needs and preferences. We followed a user-centered approach to design interactive explanations with three levels of detail (basic, intermediate, and advanced) and implemented them in the transparent Recommendation and Interest Modeling Application (RIMA). We conducted a qualitative user study (N=14) to investigate the impact of providing interactive explanations with varying level of details on the users' perception of the e
    
[^26]: 利用XAI改进分类系统的策略

    Strategies to exploit XAI to improve classification systems. (arXiv:2306.05801v1 [cs.AI])

    [http://arxiv.org/abs/2306.05801](http://arxiv.org/abs/2306.05801)

    本文研究了利用XAI方法改进分类系统的策略，探究了两种使用解释来提高模型性能的方法，并在三个数据集上进行实证评估，结果表明，Integrated Gradients方法创建的解释可以突出输入特征从而提高模型性能。

    

    可解释的人工智能（XAI）旨在向用户呈现AI模型决策过程的详细信息，使用户可以了解AI模型的结果并超越其决策。 XAI的一个重要目标是通过提供决策过程的解释来改进AI模型的性能。然而，大多数XAI文献都集中在如何解释AI系统，而较少关注如何利用XAI方法改进AI系统。本研究调查了一组通常用于机器学习（ML）分类任务的知名XAI方法，以验证它们是否可以被利用，不仅为模型提供解释，而且还可以改进其性能。为此，在三个数据集Fashion-MNIST、CIFAR10和STL10上报告了两种使用解释来改进分类系统的策略，并进行了实证评估。结果表明，通过综合渐变创建的解释突出了输入特征。

    Explainable Artificial Intelligence (XAI) aims to provide insights into the decision-making process of AI models, allowing users to understand their results beyond their decisions. A significant goal of XAI is to improve the performance of AI models by providing explanations for their decision-making processes. However, most XAI literature focuses on how to explain an AI system, while less attention has been given to how XAI methods can be exploited to improve an AI system. In this work, a set of well-known XAI methods typically used with Machine Learning (ML) classification tasks are investigated to verify if they can be exploited, not just to provide explanations but also to improve the performance of the model itself. To this aim, two strategies to use the explanation to improve a classification system are reported and empirically evaluated on three datasets: Fashion-MNIST, CIFAR10, and STL10. Results suggest that explanations built by Integrated Gradients highlight input features t
    
[^27]: 因果图发现的适应性复杂度

    Adaptivity Complexity for Causal Graph Discovery. (arXiv:2306.05781v1 [cs.LG])

    [http://arxiv.org/abs/2306.05781](http://arxiv.org/abs/2306.05781)

    研究了因果图发现的适应性复杂度，提供了一个r-adaptive算法在最小化总干预次数的同时正确学习出因果图。

    

    因果发现是一个重要的问题，其中任务是设计一个干预策略，在最小化执行干预的数量的同时学习包含n个节点的因果图。本文研究了对于总共$r$个顺序回合，算法设计师如何在最小化总干预次数的同时恢复因果图的$r$适应性问题。对于这个问题，我们提供了一个$r$-adaptive算法，该算法在$O(n^2 2^r)$的总干预次数下，以高概率正确地学习$n$个节点的因果图，并证明了这个界限是最佳的。

    Causal discovery from interventional data is an important problem, where the task is to design an interventional strategy that learns the hidden ground truth causal graph $G(V,E)$ on $|V| = n$ nodes while minimizing the number of performed interventions. Most prior interventional strategies broadly fall into two categories: non-adaptive and adaptive. Non-adaptive strategies decide on a single fixed set of interventions to be performed while adaptive strategies can decide on which nodes to intervene on sequentially based on past interventions. While adaptive algorithms may use exponentially fewer interventions than their non-adaptive counterparts, there are practical concerns that constrain the amount of adaptivity allowed. Motivated by this trade-off, we study the problem of $r$-adaptivity, where the algorithm designer recovers the causal graph under a total of $r$ sequential rounds whilst trying to minimize the total number of interventions. For this problem, we provide a $r$-adaptive
    
[^28]: 公平但渐近相等的协作学习

    Fair yet Asymptotically Equal Collaborative Learning. (arXiv:2306.05764v1 [cs.LG])

    [http://arxiv.org/abs/2306.05764](http://arxiv.org/abs/2306.05764)

    本文探讨了一种公平的协作学习激励设计，避免了“富者越富”的现象，并为较少资源的节点提供了长期平等的机会。

    

    在流数据的协作学习中，节点（例如组织）通过共享从其最新流数据计算出的最新模型更新来共同持续学习机器学习（ML）模型。为了更有资源的节点愿意共享其模型更新，他们需要得到公平的激励。本文探讨了一种激励设计，保证公平，使节点获得与其贡献相称的奖励。我们的方法利用探索-利用的形式估计节点的贡献（即探索），实现了理论上保证的公正激励（即利用）。然而，我们观察到现有的保证公平的方法中出现了“富者越富”的现象，这阻碍了资源较少的节点的参与。为了解决这个问题，我们另外保持渐近平等，即较少资源的节点最终实现与较有资源的“富”节点相等的性能。

    In collaborative learning with streaming data, nodes (e.g., organizations) jointly and continuously learn a machine learning (ML) model by sharing the latest model updates computed from their latest streaming data. For the more resourceful nodes to be willing to share their model updates, they need to be fairly incentivized. This paper explores an incentive design that guarantees fairness so that nodes receive rewards commensurate to their contributions. Our approach leverages an explore-then-exploit formulation to estimate the nodes' contributions (i.e., exploration) for realizing our theoretically guaranteed fair incentives (i.e., exploitation). However, we observe a "rich get richer" phenomenon arising from the existing approaches to guarantee fairness and it discourages the participation of the less resourceful nodes. To remedy this, we additionally preserve asymptotic equality, i.e., less resourceful nodes achieve equal performance eventually to the more resourceful/"rich" nodes. 
    
[^29]: 智能居家环境中基于心理特征的安全警告建议：三项研究

    From psychological traits to safety warnings: three studies on recommendations in a smart home environment. (arXiv:2306.05752v1 [cs.HC])

    [http://arxiv.org/abs/2306.05752](http://arxiv.org/abs/2306.05752)

    本文研究了智能居家环境中基于心理特征的安全警告建议，发现认知需求等特征影响建议使用方式，易懂的安全说明比警告更具说服力。

    

    本文报告了 EMPATHY 项目中进行的三项实验，旨在帮助用户在智能家居环境中做出更好的配置选择，并讨论了我们的结果。我们发现，存在心理特征，例如认知需求，影响个体使用建议的方式；在不同领域中，对建议的感知有着非显而易见的关系，个体利用建议进行配置选择的能力因人而异；对于可能引起隐私和安全风险的规则的适用性决策，详细易懂的安全说明比简单的安全警告更具有说服力。

    In this paper, we report on three experiments we have carried out in the context of the EMPATHY project, with the aim of helping users make better configuration choices in a smart home environment, and discuss our results. We found that there are psychological traits, such as Need for Cognition, which influence the way individuals tend to use recommendations, that there are non obvious relationships between the perceived usefulness of recommendations in different domains and individuals' ability to exploit suggestions on configuration choices, and that detailed, easy-to-understand security explanations are more persuasive than simple security warnings, when it comes to make decisions on the applicability of rules which might cause privacy and security risks.
    
[^30]: 基于约束编程的作业车间调度问题的端到端强化学习方法

    An End-to-End Reinforcement Learning Approach for Job-Shop Scheduling Problems Based on Constraint Programming. (arXiv:2306.05747v1 [cs.AI])

    [http://arxiv.org/abs/2306.05747](http://arxiv.org/abs/2306.05747)

    本文提出了一种新颖的基于约束编程和强化学习的端到端方法，通过通用CP编码、约束条件和反映JSSP最优标准的奖励函数，可为大型作业车间调度问题产生最优或近似最优解。

    

    约束编程(CP)是一种声明式编程范例，可用于建模和解决组合优化问题，如作业车间调度问题(JSSP)。虽然CP求解器能够找到小实例的最优或近似最优解，但它们不适用于大实例，即需要长时间计算或产生低质量解。因此，实际调度应用经常采用快速手工制作的基于优先级的调度启发式方法以找到良好的初始解，并使用优化方法对其进行优化。本文提出了一种新颖的端到端方法，通过CP和强化学习(RL)来解决调度问题。与先前针对特定问题定制的RL方法不同，包括过程模拟算法、复杂的特征工程或手工制作的奖励函数，我们的神经网络架构和训练算法仅需要某些调度问题的通用CP编码、一小组问题特定约束条件和反映JSSP最优标准的奖励函数。对几个JSSP基准测试结果表明，我们的方法与最先进的RL和CP方法竞争，并且通常可以在很短时间内为大型实例产生最优或近似最优解。

    Constraint Programming (CP) is a declarative programming paradigm that allows for modeling and solving combinatorial optimization problems, such as the Job-Shop Scheduling Problem (JSSP). While CP solvers manage to find optimal or near-optimal solutions for small instances, they do not scale well to large ones, i.e., they require long computation times or yield low-quality solutions. Therefore, real-world scheduling applications often resort to fast, handcrafted, priority-based dispatching heuristics to find a good initial solution and then refine it using optimization methods.  This paper proposes a novel end-to-end approach to solving scheduling problems by means of CP and Reinforcement Learning (RL). In contrast to previous RL methods, tailored for a given problem by including procedural simulation algorithms, complex feature engineering, or handcrafted reward functions, our neural-network architecture and training algorithm merely require a generic CP encoding of some scheduling pr
    
[^31]: 智能音箱设计的挑战与机遇

    Challenges and Opportunities for the Design of Smart Speakers. (arXiv:2306.05741v1 [cs.HC])

    [http://arxiv.org/abs/2306.05741](http://arxiv.org/abs/2306.05741)

    本文通过对35篇论文的文献综述以及15名智能音箱用户的访谈，总结出了智能音箱设计中的五个主题和四个设计挑战，同时提出了四个设计机遇空间，如提供信息支持，在设计中融入用户的心理模型以及整合平静的设计原则等。

    

    语音技术和语音用户界面（VUI），如Alexa、Siri和Google Home等的进步，为许多新类型的交互提供了潜力。然而，尽管市场越来越大，VUI研究越来越多，但人们仍然感到这项技术被低估了。在本文中，我们对35篇论文进行了系统性的文献综述，将127个VUI设计指南综合成了五个主题。此外，我们还对15名智能音箱用户进行了半结构化访谈，以了解他们对技术的使用和不使用情况。通过访谈，我们总结出了四个对不使用技术做出最大贡献的设计挑战。基于他们的使用情况，我们确定了四个设计机遇空间，例如专注于在多任务（烹饪、驾驶、育儿等）中提供信息支持，将用户的智能音箱心理模型融入设计当中，以及整合平静的设计原则。

    Advances in voice technology and voice user interfaces (VUIs) -- such as Alexa, Siri, and Google Home -- have opened up the potential for many new types of interaction. However, despite the potential of these devices reflected by the growing market and body of VUI research, there is a lingering sense that the technology is still underused. In this paper, we conducted a systematic literature review of 35 papers to identify and synthesize 127 VUI design guidelines into five themes. Additionally, we conducted semi-structured interviews with 15 smart speaker users to understand their use and non-use of the technology. From the interviews, we distill four design challenges that contribute the most to non-use. Based on their (non-)use, we identify four opportunity spaces for designers to explore such as focusing on information support while multitasking (cooking, driving, childcare, etc), incorporating users' mental models for smart speakers, and integrating calm design principles.
    
[^32]: 多模态可解释人工智能：方法学进展和未来研究方向的综述

    Multimodal Explainable Artificial Intelligence: A Comprehensive Review of Methodological Advances and Future Research Directions. (arXiv:2306.05731v1 [cs.AI])

    [http://arxiv.org/abs/2306.05731](http://arxiv.org/abs/2306.05731)

    本文系统地分析了多模态可解释人工智能（MXAI）领域的最新进展和未来研究方向，从预测任务和数据集到MXAI方法和评估度量标准进行了全面介绍和讨论。

    

    本研究系统地分析了多模态可解释人工智能（MXAI）领域的最新进展。特别是，首先描述了相关的主要预测任务和公开可用数据集。随后，提供了文献中MXAI方法的结构化介绍，考虑到以下标准：a）涉及的模态数量，b）产生解释的阶段，以及c）采用的方法论类型（即数学形式化）。然后，讨论了用于MXAI评估的度量标准。最后，提供了当前挑战和未来研究方向的全面分析。

    The current study focuses on systematically analyzing the recent advances in the field of Multimodal eXplainable Artificial Intelligence (MXAI). In particular, the relevant primary prediction tasks and publicly available datasets are initially described. Subsequently, a structured presentation of the MXAI methods of the literature is provided, taking into account the following criteria: a) The number of the involved modalities, b) The stage at which explanations are produced, and c) The type of the adopted methodology (i.e. mathematical formalism). Then, the metrics used for MXAI evaluation are discussed. Finally, a comprehensive analysis of current challenges and future research directions is provided.
    
[^33]: 离线强化学习的样本内政策迭代方法

    In-Sample Policy Iteration for Offline Reinforcement Learning. (arXiv:2306.05726v1 [cs.LG])

    [http://arxiv.org/abs/2306.05726](http://arxiv.org/abs/2306.05726)

    本文提出了一种采用样本内策略迭代的算法来增强离线强化学习中的行为规则方法，在实验中取得了显著的改进。

    

    离线强化学习通过利用以前收集到的数据来推导出有效的控制策略。为了解决由于数据覆盖不足而导致的错误，行为规则方法优化控制策略的同时，同时最小化偏离数据收集策略的误差。然而，当离线数据集由次优策略收集时，这些方法经常表现出不佳的实际性能。在本文中，我们提出了一种采用样本内策略迭代的新算法，它在离线强化学习中显著增强了行为规则方法。核心见解是通过不断改进用于行为规则的策略，样本内政策迭代逐渐改进自身，同时隐式避免查询样本外的行动，以避免灾难性的学习失败。我们的理论分析验证了其学习仅利用数据集中良好覆盖的行动学习样本内最优策略的能力。此外，我们在四个任务上进行了广泛的实验，证明我们的算法在现实世界的离线强化学习应用中能够显著改进现有方法。

    Offline reinforcement learning (RL) seeks to derive an effective control policy from previously collected data. To circumvent errors due to inadequate data coverage, behavior-regularized methods optimize the control policy while concurrently minimizing deviation from the data collection policy. Nevertheless, these methods often exhibit subpar practical performance, particularly when the offline dataset is collected by sub-optimal policies. In this paper, we propose a novel algorithm employing in-sample policy iteration that substantially enhances behavior-regularized methods in offline RL. The core insight is that by continuously refining the policy used for behavior regularization, in-sample policy iteration gradually improves itself while implicitly avoids querying out-of-sample actions to avert catastrophic learning failures. Our theoretical analysis verifies its ability to learn the in-sample optimal policy, exclusively utilizing actions well-covered by the dataset. Moreover, we pr
    
[^34]: 超越表面统计学：潜在扩散模型中的场景表示

    Beyond Surface Statistics: Scene Representations in a Latent Diffusion Model. (arXiv:2306.05720v1 [cs.CV])

    [http://arxiv.org/abs/2306.05720](http://arxiv.org/abs/2306.05720)

    本文探究了潜在扩散模型内部是否创建和使用简单场景几何内部表示，使用线性探针发现LDM内部激活提供了关于3D深度数据和突出对象/背景分离的线性表示，在图像合成中具有因果作用, 可用于LDM输出的简单高级编辑。

    

    潜在扩散模型（LDM）展现了产生逼真图像的惊人能力，但这些模型的内在机制仍然神秘。即使在没有显式深度信息的图像上进行训练，它们通常也会输出一致的3D场景图片。在这项工作中，我们探讨了一个基本的可解释性问题：LDM是否创建并使用一个简单的场景几何内部表示？使用线性探针，我们发现LDM的内部激活编码了线性表示，既包括3D深度数据，又包括突出对象/背景区别。这些表示似乎在去噪过程的早期就出现了——在人类能轻易理解嘈杂的图像之前。干预性实验进一步表明，这些表示在图像合成中扮演因果作用，并且可能用于LDM输出的简单高级编辑。

    Latent diffusion models (LDMs) exhibit an impressive ability to produce realistic images, yet the inner workings of these models remain mysterious. Even when trained purely on images without explicit depth information, they typically output coherent pictures of 3D scenes. In this work, we investigate a basic interpretability question: does an LDM create and use an internal representation of simple scene geometry? Using linear probes, we find evidence that the internal activations of the LDM encode linear representations of both 3D depth data and a salient-object / background distinction. These representations appear surprisingly early in the denoising process$-$well before a human can easily make sense of the noisy images. Intervention experiments further indicate these representations play a causal role in image synthesis, and may be used for simple high-level editing of an LDM's output.
    
[^35]: 为抓住任何物品铺平道路：基于迁移学习的通用抓取放置机器人模型

    Pave the Way to Grasp Anything: Transferring Foundation Models for Universal Pick-Place Robots. (arXiv:2306.05716v1 [cs.RO])

    [http://arxiv.org/abs/2306.05716](http://arxiv.org/abs/2306.05716)

    本研究提出了一种基于语言分割掩模的新方法，用于解决通用型机器人的泛化能力问题，提高了在开放域场景中新对象的抓取操作的学习效率和推广效果。

    

    提高通用型机器人的泛化能力一直是研究社区长期追求的重要挑战。现有的方法通常依赖于收集大规模现实世界机器人数据，如 RT-1 数据集。然而，这些方法通常效率低下，限制了它们在具有新对象和多样背景的开放域场景中的能力。本文提出了一种新的范例，有效地利用最先进的基础模型生成的基于语言的分割掩模，以解决日常场景中广泛的拾放机器人操作任务。通过将掩模传达的精确语义和几何形状集成到我们的多视角策略模型中，我们的方法可以感知准确的物体姿态并实现高效学习，同时也有助于有效的新对象的推广。我们的方法同时可以实现在训练时观察到相似形状的新物体的抓取操作。

    Improving the generalization capabilities of general-purpose robotic agents has long been a significant challenge actively pursued by research communities. Existing approaches often rely on collecting large-scale real-world robotic data, such as the RT-1 dataset. However, these approaches typically suffer from low efficiency, limiting their capability in open-domain scenarios with new objects, and diverse backgrounds. In this paper, we propose a novel paradigm that effectively leverages language-grounded segmentation masks generated by state-of-the-art foundation models, to address a wide range of pick-and-place robot manipulation tasks in everyday scenarios. By integrating precise semantics and geometries conveyed from masks into our multi-view policy model, our approach can perceive accurate object poses and enable sample-efficient learning. Besides, such design facilitates effective generalization for grasping new objects with similar shapes observed during training. Our approach co
    
[^36]: 探究大型语言模型对初学者程序员求助请求的回应

    Exploring the Responses of Large Language Models to Beginner Programmers' Help Requests. (arXiv:2306.05715v1 [cs.CY])

    [http://arxiv.org/abs/2306.05715](http://arxiv.org/abs/2306.05715)

    研究探究了大型语言模型（LLMs）对学生程序员求助请求的回应能力，评估了其在识别学生问题代码方面的表现。GPT-3.5在大多数方面表现优于Codex，两个LLM经常在每个学生程序中找到至少一个实际问题，但都未能找到全部问题。

    

    背景和背景：在过去的一年中，大型语言模型（LLM）席卷全球。在计算机教育中，就像在生活的其他方面一样，许多机遇和威胁出现了。目标：本文中，我们探讨了一个特定领域中的机遇和威胁：回应学生程序员的求助请求。更具体地说，我们评估了LLM在识别学生请求帮助的问题代码方面的能力。方法：我们从在线编程课程中收集了求助请求和代码样本。然后促使两个不同的LLM（OpenAI Codex和GPT-3.5）识别和解释学生代码中的问题，并定量和定性评估了LLM生成的答案。发现：GPT-3.5在大多数方面表现优于Codex。两个LLM经常在每个学生程序中找到至少一个实际问题（GPT-3.5在90％的情况下） 。

    Background and Context: Over the past year, large language models (LLMs) have taken the world by storm. In computing education, like in other walks of life, many opportunities and threats have emerged as a consequence.  Objectives: In this article, we explore such opportunities and threats in a specific area: responding to student programmers' help requests. More specifically, we assess how good LLMs are at identifying issues in problematic code that students request help on.  Method: We collected a sample of help requests and code from an online programming course. We then prompted two different LLMs (OpenAI Codex and GPT-3.5) to identify and explain the issues in the students' code and assessed the LLM-generated answers both quantitatively and qualitatively.  Findings: GPT-3.5 outperforms Codex in most respects. Both LLMs frequently find at least one actual issue in each student program (GPT-3.5 in 90% of the cases). Neither LLM excels at finding all the issues (GPT-3.5 finding them 
    
[^37]: 用MT-Bench和Chatbot Arena评估以LLM为基础的聊天助手

    Judging LLM-as-a-judge with MT-Bench and Chatbot Arena. (arXiv:2306.05685v1 [cs.CL])

    [http://arxiv.org/abs/2306.05685](http://arxiv.org/abs/2306.05685)

    研究使用强大的LLM作为评判员，通过引入两个基准测试来确认LLM评判员和人类偏好之间的一致性，并可调整聊天助手的模型架构和微调方法来提高其性能。

    

    评估基于大语言模型（LLM）的聊天助手会面临挑战，因为它们具有广泛的功能，而现有的基准无法衡量人类偏好。为了解决这个问题，我们探索使用强大的LLM作为评判员，在更加开放的问题上评估这些模型。我们研究了LLM作为评判员的使用和局限性，如位置和冗余偏见以及有限的推理能力，并提出解决方案来迁移其中一些问题。然后，我们通过引入两个基准测试（一个多轮问答集和一个众包竞技平台）来确认LLM评判员和人类偏好之间的一致性。我们的结果显示，像GPT-4这样的强大LLM评判员可以很好地匹配受控和众包人类偏好，达到了80％以上的一致性，与人类一致性水平相同。因此，LLM作为评判员是一种可扩展且可解释的逼近人类偏好的方式，而这些偏好是非常昂贵获取的。此外，我们证明，通过使用LLM作为评判员，可以通过调整聊天助手的模型架构和微调方法来提高其性能。

    Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, such as position and verbosity biases and limited reasoning ability, and propose solutions to migrate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80\% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we
    
[^38]: 通过令牌共享Transformer实现轻量级单目深度估计

    Lightweight Monocular Depth Estimation via Token-Sharing Transformer. (arXiv:2306.05682v1 [cs.CV])

    [http://arxiv.org/abs/2306.05682](http://arxiv.org/abs/2306.05682)

    本文提出了一种使用Transformer和全局令牌共享的轻量级单目深度估计方法，针对嵌入式设备进行了优化。

    

    深度估计是各种机器人系统和应用中的重要任务，单目深度估计是一种理想的选择，然而大多数方法使用卷积神经网络，而本文提出了一种Token-Sharing Transformer体系结构来优化在嵌入式设备中的单目深度估计。

    Depth estimation is an important task in various robotics systems and applications. In mobile robotics systems, monocular depth estimation is desirable since a single RGB camera can be deployable at a low cost and compact size. Due to its significant and growing needs, many lightweight monocular depth estimation networks have been proposed for mobile robotics systems. While most lightweight monocular depth estimation methods have been developed using convolution neural networks, the Transformer has been gradually utilized in monocular depth estimation recently. However, massive parameters and large computational costs in the Transformer disturb the deployment to embedded devices. In this paper, we present a Token-Sharing Transformer (TST), an architecture using the Transformer for monocular depth estimation, optimized especially in embedded devices. The proposed TST utilizes global token sharing, which enables the model to obtain an accurate depth prediction with high throughput in emb
    
[^39]: RePaint-NeRF：基于语义掩码和扩散模型的 NeRF 编辑.

    RePaint-NeRF: NeRF Editting via Semantic Masks and Diffusion Models. (arXiv:2306.05668v1 [cs.CV])

    [http://arxiv.org/abs/2306.05668](http://arxiv.org/abs/2306.05668)

    本文提出了一个新框架，利用现有的扩散模型来指导指定的 3D 内容的变化，并能够接受 RGB 图像作为输入并改变神经场景中的 3D 内容。

    

    神经辐射场（NeRF）的出现促进了对复杂真实世界的高保真视图的合成的发展。然而，在 NeRF 中重新绘制内容仍然是一项非常苛刻的任务。在本文中，我们提出了一个能够接受 RGB 图像作为输入并改变神经场景中的 3D 内容的新颖框架。我们的工作利用现有的扩散模型来指导指定的 3D 内容的变化。具体而言，我们语义地选择目标对象，预先训练的扩散模型将指导 NeRF 模型生成新的 3D 对象，这可以提高 NeRF 的可编辑性，多样性和应用范围。实验结果表明，我们的算法对于在不同的文本提示下编辑 NeRF 中的 3D 对象是有效的，包括编辑外观、形状等。我们在真实世界数据集和合成世界数据集上验证了我们的方法以完成这些编辑任务。请访问 https://repaintnerf.github.io 以查看更好的结果。

    The emergence of Neural Radiance Fields (NeRF) has promoted the development of synthesized high-fidelity views of the intricate real world. However, it is still a very demanding task to repaint the content in NeRF. In this paper, we propose a novel framework that can take RGB images as input and alter the 3D content in neural scenes. Our work leverages existing diffusion models to guide changes in the designated 3D content. Specifically, we semantically select the target object and a pre-trained diffusion model will guide the NeRF model to generate new 3D objects, which can improve the editability, diversity, and application range of NeRF. Experiment results show that our algorithm is effective for editing 3D objects in NeRF under different text prompts, including editing appearance, shape, and more. We validate our method on both real-world datasets and synthetic-world datasets for these editing tasks. Please visit https://repaintnerf.github.io for a better view of our results.
    
[^40]: COVER：一种启发式贪心对抗攻击预训练语言模型中的基于提示学习

    COVER: A Heuristic Greedy Adversarial Attack on Prompt-based Learning in Language Models. (arXiv:2306.05659v1 [cs.CL])

    [http://arxiv.org/abs/2306.05659](http://arxiv.org/abs/2306.05659)

    本文提出了一种启发式贪心对抗攻击，针对基于提示的模板在PLMs中可能存在的漏洞，通过字符级和单词级的破坏方法进行攻击，取得了较高的攻击成功率。

    

    基于提示的学习已被证明是预训练语言模型（PLMs）中一种有效的方式，特别是在像少量样本场景这样的低资源情况下。然而，PLMs的可信度至关重要，并且在基于模板的提示中已经显示出了潜在的漏洞，可能会误导语言模型的预测，引起严重的安全问题。本文通过在黑盒场景中提出基于提示的对抗攻击手段，揭示了PLMs的一些漏洞。首先，我们设计了字符级别和单词级别的启发式方法来破坏手动模板。然后，我们基于上述启发式破坏方法提出了一种贪心算法进行攻击。最后，我们使用BERT系列模型的三个变种和八个数据集的分类任务评估了我们的方法。广泛的实验结果证明了我们的方法在攻击成功率方面的有效性。

    Prompt-based learning has been proved to be an effective way in pre-trained language models (PLMs), especially in low-resource scenarios like few-shot settings. However, the trustworthiness of PLMs is of paramount significance and potential vulnerabilities have been shown in prompt-based templates that could mislead the predictions of language models, causing serious security concerns. In this paper, we will shed light on some vulnerabilities of PLMs, by proposing a prompt-based adversarial attack on manual templates in black box scenarios. First of all, we design character-level and word-level heuristic approaches to break manual templates separately. Then we present a greedy algorithm for the attack based on the above heuristic destructive approaches. Finally, we evaluate our approach with the classification tasks on three variants of BERT series models and eight datasets. And comprehensive experimental results justify the effectiveness of our approach in terms of attack success rate
    
[^41]: 在线心理健康风险评估的隐私感知问答系统

    Privacy Aware Question-Answering System for Online Mental Health Risk Assessment. (arXiv:2306.05652v1 [cs.CL])

    [http://arxiv.org/abs/2306.05652](http://arxiv.org/abs/2306.05652)

    本研究提出了一种利用问答（QA）方法进行心理健康风险评估的技术，在保护用户数据的前提下，通过预训练的语言模型对用户社交媒体数据进行分类，并且应用于两个大型心理健康数据集。结果表明，该方法对于心理健康用例尤其有效。

    

    社交媒体平台使患有精神疾病的人分享生活经历并找到在线支持以应对疾病。然而，许多用户未能获得真正的临床支持，从而加剧了他们的症状。基于用户在网上发布的内容进行筛选可以帮助提供者进行有针对性的医疗保健，并尽量减少虚假阳性。预训练的语言模型（LMs）可以评估用户的社交媒体数据，并将其分类为其心理健康风险。我们提出了一种使用统一问答（Unified-QA）模型的问答方法来评估心理健康风险，应用于两个大型心理健康数据集。为了保护用户数据，我们扩展了Unified-QA，并使用差分隐私对模型训练过程进行了匿名化处理。我们的结果表明，将风险评估建模为问答任务对于心理健康用例特别有效。此外，包含差分隐私后，模型性能下降不到1%。

    Social media platforms have enabled individuals suffering from mental illnesses to share their lived experiences and find the online support necessary to cope. However, many users fail to receive genuine clinical support, thus exacerbating their symptoms. Screening users based on what they post online can aid providers in administering targeted healthcare and minimize false positives. Pre-trained Language Models (LMs) can assess users' social media data and classify them in terms of their mental health risk. We propose a Question-Answering (QA) approach to assess mental health risk using the Unified-QA model on two large mental health datasets. To protect user data, we extend Unified-QA by anonymizing the model training process using differential privacy. Our results demonstrate the effectiveness of modeling risk assessment as a QA task, specifically for mental health use cases. Furthermore, the model's performance decreases by less than 1% with the inclusion of differential privacy. T
    
[^42]: 差分隐私锐化感知训练

    Differentially Private Sharpness-Aware Training. (arXiv:2306.05651v1 [cs.LG])

    [http://arxiv.org/abs/2306.05651](http://arxiv.org/abs/2306.05651)

    本文提出了一种能够缓解隐私-优化制约关系的锐化感知训练方法。

    

    使用差分隐私进行训练会导致深度学习模型性能下降。本文研究了私有学习的几何属性，提出了一种新的锐化感知的训练方法，以缓解隐私-优化的制约关系。

    Training deep learning models with differential privacy (DP) results in a degradation of performance. The training dynamics of models with DP show a significant difference from standard training, whereas understanding the geometric properties of private learning remains largely unexplored. In this paper, we investigate sharpness, a key factor in achieving better generalization, in private learning. We show that flat minima can help reduce the negative effects of per-example gradient clipping and the addition of Gaussian noise. We then verify the effectiveness of Sharpness-Aware Minimization (SAM) for seeking flat minima in private learning. However, we also discover that SAM is detrimental to the privacy budget and computational time due to its two-step optimization. Thus, we propose a new sharpness-aware training method that mitigates the privacy-optimization trade-off. Our experimental results demonstrate that the proposed method improves the performance of deep learning models with 
    
[^43]: 面向医疗报告生成的通用基础模型自定义

    Customizing General-Purpose Foundation Models for Medical Report Generation. (arXiv:2306.05642v1 [cs.CV])

    [http://arxiv.org/abs/2306.05642](http://arxiv.org/abs/2306.05642)

    这项工作中，我们提出了一种自定义通用基础模型以用于医疗报告生成的方法，其利用轻量级查询Transformer连接两个FMs，并在三个基准数据集上实现了最先进的结果。

    

    医疗字幕预测，也被视为医疗报告生成（MRG）的任务，需要为给定的医疗图像自动生成连贯准确的字幕。然而，标记的医疗图像-报告对的稀缺性在深度和大规模神经网络的开发中提出了巨大挑战，这些网络可以利用大型语言模型（LLM）这样的人工智能潜力。在这项工作中，我们建议将通用的面向计算机视觉和自然语言处理的基础模型进行定制，特别关注医疗报告生成。具体来说，我们根据BLIP-2提出了基于编码器-解码器的MRG模型，该模型利用轻量级查询Transformer连接两个FMs：巨型视觉Transformer EVA-ViT-g和双语LLM，该LLM被训练用于与人类意图对齐（称为T5-base-CN）。实验结果表明，我们提出的方法在三个医疗报告生成基准数据集上实现了最先进的结果，这表明了将基础模型适应于此任务的有效性。

    Medical caption prediction which can be regarded as a task of medical report generation (MRG), requires the automatic generation of coherent and accurate captions for the given medical images. However, the scarcity of labelled medical image-report pairs presents great challenges in the development of deep and large-scale neural networks capable of harnessing the potential artificial general intelligence power like large language models (LLMs). In this work, we propose customizing off-the-shelf general-purpose large-scale pre-trained models, i.e., foundation models (FMs), in computer vision and natural language processing with a specific focus on medical report generation. Specifically, following BLIP-2, a state-of-the-art vision-language pre-training approach, we introduce our encoder-decoder-based MRG model. This model utilizes a lightweight query Transformer to connect two FMs: the giant vision Transformer EVA-ViT-g and a bilingual LLM trained to align with human intentions (referred
    
[^44]: 重新思考置换对不同数据集间模型合并的作用

    Revisiting Permutation Symmetry for Merging Models between Different Datasets. (arXiv:2306.05641v1 [cs.LG])

    [http://arxiv.org/abs/2306.05641](http://arxiv.org/abs/2306.05641)

    本研究通过理论和实证分析表明，不同数据集合并模型的准确性下降更为显著，因为每个数据集的不同损失函数使得合并更加困难。此外，通过数据集压缩创建的压缩数据集可以作为原数据集的替代品。

    

    模型合并是一种通过组合不同训练模型的权重来创建新模型的新方法。以往的研究表明，模型合并对于不同随机数训练模型的单一数据集非常有效，但是在不同数据集之间进行模型合并却很困难。将不同数据集的知识合并具有实际意义，但尚未得到很好的研究。本文通过理论和实证分析探讨了不同数据集间合并模型的特性。我们发现随着数据集的差异越大，合并模型的准确性下降得更为显著，而每个数据集的不同损失函数使得不同数据集之间的模型合并更加困难。我们还表明合并的模型需要数据集才能实现高精度合并。此外，我们还表明当合并模型时，通过数据集压缩创建的压缩数据集可以作为原数据集的替代品。

    Model merging is a new approach to creating a new model by combining the weights of different trained models. Previous studies report that model merging works well for models trained on a single dataset with different random seeds, while model merging between different datasets is difficult. Merging knowledge from different datasets has practical significance, but it has not been well investigated. In this paper, we investigate the properties of merging models between different datasets. Through theoretical and empirical analyses, we find that the accuracy of the merged model decreases more significantly as the datasets diverge more and that the different loss landscapes for each dataset make model merging between different datasets difficult. We also show that merged models require datasets for merging in order to achieve a high accuracy. Furthermore, we show that condensed datasets created by dataset condensation can be used as substitutes for the original datasets when merging model
    
[^45]: 产品属性值识别的统一生成方法

    A Unified Generative Approach to Product Attribute-Value Identification. (arXiv:2306.05605v1 [cs.CL])

    [http://arxiv.org/abs/2306.05605](http://arxiv.org/abs/2306.05605)

    本文探索了一种生成式方法来统一处理电子商务平台上产品属性值识别任务，实验结果表明该方法在大规模真实世界数据集上的表现优于现有的基于提取和分类的方法。

    

    产品属性值识别（PAVI）旨在使用产品文本作为线索将电子商务网站上的产品与其属性值（例如<Material，Cotton>）链接起来。现实世界电子商务平台的技术需求要求PAVI方法处理未见过的值、多属性值和规范化的值，而这些仅在现有的基于提取和分类的方法中部分得到解决。因此，我们提出了一种生成式方法来处理PAVI任务。

    Product attribute-value identification (PAVI) has been studied to link products on e-commerce sites with their attribute values (e.g., <Material, Cotton>) using product text as clues. Technical demands from real-world e-commerce platforms require PAVI methods to handle unseen values, multi-attribute values, and canonicalized values, which are only partly addressed in existing extraction- and classification-based approaches. Motivated by this, we explore a generative approach to the PAVI task. We finetune a pre-trained generative model, T5, to decode a set of attribute-value pairs as a target sequence from the given product text. Since the attribute value pairs are unordered set elements, how to linearize them will matter; we, thus, explore methods of composing an attribute-value pair and ordering the pairs for the task. Experimental results confirm that our generation-based approach outperforms the existing extraction and classification-based methods on large-scale real-world datasets 
    
[^46]: 有领域约束的联合编队在机器人集群中的应用前景探讨

    The Viability of Domain Constrained Coalition Formation for Robotic Collectives. (arXiv:2306.05590v1 [cs.MA])

    [http://arxiv.org/abs/2306.05590](http://arxiv.org/abs/2306.05590)

    该论文研究了如何在领域约束下，设计适用于大规模机器人集群的联盟形成算法，提出了一种基于拍卖算法的混合改进方法，可提高任务分配效率，并有应用前景。

    

    军事和灾难响应等领域中，机器人集群的协同能力可以在大范围内高效执行多种合作任务（如监视、损伤评估）。然而，联盟形成算法的大多数设计都是针对小型机器人系统（即2-50个机器人），而大规模集群和领域相关的约束条件（如高效分配、实时性、最小通信）使得联盟形成变得更加具有挑战性。本文发现，拍卖和愉悦博弈可能是最有可转移性的，提出了一种混合改进拍卖算法来解决机器人集群协作搜索和收集问题。通过模拟实验表明，分布式执行的拍卖算法可以提高任务分配效率，有领域约束的联合编队算法显示出适用于大规模机器人集群的前景。

    Applications, such as military and disaster response, can benefit from robotic collectives' ability to perform multiple cooperative tasks (e.g., surveillance, damage assessments) efficiently across a large spatial area. Coalition formation algorithms can potentially facilitate collective robots' assignment to appropriate task teams; however, most coalition formation algorithms were designed for smaller multiple robot systems (i.e., 2-50 robots). Collectives' scale and domain-relevant constraints (i.e., distribution, near real-time, minimal communication) make coalition formation more challenging. This manuscript identifies the challenges inherent to designing coalition formation algorithms for very large collectives (e.g., 1000 robots). A survey of multiple robot coalition formation algorithms finds that most are unable to transfer directly to collectives, due to the identified system differences; however, auctions and hedonic games may be the most transferable. A simulation-based eval
    
[^47]: 多体SE（3）等变性用于无监督的刚体分割和运动估计

    Multi-body SE(3) Equivariance for Unsupervised Rigid Segmentation and Motion Estimation. (arXiv:2306.05584v1 [cs.CV])

    [http://arxiv.org/abs/2306.05584](http://arxiv.org/abs/2306.05584)

    本文提出了一种基于SE（3）等变结构和非监督训练策略的方法，可以实现刚性分割和运动估计，不需要类别信息且具有极高的模型效率。

    

    实现刚体分割和运动估计的真正通用方法对于理解关节物体和移动场景的三维影像至关重要。鉴于分割和运动估计之间密切的关系，我们提出了一种SE（3）等变体系结构和培训策略，以无监督的方式解决这个任务。我们的体系结构包括两个轻量级和相互连接的头部，使用点级不变特征和来自SE（3）等变特征的运动估计来预测分割掩模，而不需要类别信息。我们的统一培训策略可以在线执行，通过利用场景流，分割掩模和刚性变换之间的相互关系来同时优化两个预测。我们在四个数据集上的实验表明，我们的方法在模型性能和计算效率方面均表现出优越性，只有0.25M参数和0.92G FLOPs。

    A truly generalizable approach to rigid segmentation and motion estimation is fundamental to 3D understanding of articulated objects and moving scenes. In view of the tightly coupled relationship between segmentation and motion estimates, we present an SE(3) equivariant architecture and a training strategy to tackle this task in an unsupervised manner. Our architecture comprises two lightweight and inter-connected heads that predict segmentation masks using point-level invariant features and motion estimates from SE(3) equivariant features without the prerequisites of category information. Our unified training strategy can be performed online while jointly optimizing the two predictions by exploiting the interrelations among scene flow, segmentation mask, and rigid transformations. We show experiments on four datasets as evidence of the superiority of our method both in terms of model performance and computational efficiency with only 0.25M parameters and 0.92G FLOPs. To the best of ou
    
[^48]: 一种面向视角不变物体识别的新生儿身体图灵测试

    A newborn embodied Turing test for view-invariant object recognition. (arXiv:2306.05582v1 [cs.AI])

    [http://arxiv.org/abs/2306.05582](http://arxiv.org/abs/2306.05582)

    本文提出了一种新的实验方法 - “新生儿身体图灵测试”，能够在相同环境中比较新生动物和机器的学习能力。研究结果表明，实验中的机器能够自发地发展视觉能力。

    

    最近人工智能领域的进展使得人们重新关注起像动物一样学习的机器。然而，目前对比生物和人工系统学习能力的研究，大部分比较的是动物和机器接收不同的训练数据，这种对比掩盖了动物和机器的差异是否来自于学习机制的异同或训练数据的不同。本文提出了一种实验方法-“新生儿身体图灵测试”，允许新生动物和机器在相同的环境中接受相同的任务测试，直接比较它们的学习能力。为了构建这个平台，我们首先收集了新生小鸟的受控饲养数据，然后进行了“数字双胞胎”实验，让机器在模拟小鸟饲养条件下的虚拟环境中成长。我们发现，（1）机器（具有固有动机的深度强化学习代理）可以自发地发展视觉知识

    Recent progress in artificial intelligence has renewed interest in building machines that learn like animals. Almost all of the work comparing learning across biological and artificial systems comes from studies where animals and machines received different training data, obscuring whether differences between animals and machines emerged from differences in learning mechanisms versus training data. We present an experimental approach-a "newborn embodied Turing Test"-that allows newborn animals and machines to be raised in the same environments and tested with the same tasks, permitting direct comparison of their learning abilities. To make this platform, we first collected controlled-rearing data from newborn chicks, then performed "digital twin" experiments in which machines were raised in virtual environments that mimicked the rearing conditions of the chicks. We found that (1) machines (deep reinforcement learning agents with intrinsic motivation) can spontaneously develop visually 
    
[^49]: 飞行器设计的大规模多模态数据集：AircraftVerse

    AircraftVerse: A Large-Scale Multimodal Dataset of Aerial Vehicle Designs. (arXiv:2306.05562v1 [cs.RO])

    [http://arxiv.org/abs/2306.05562](http://arxiv.org/abs/2306.05562)

    AircraftVerse是一个公开可用的飞行器设计数据集，包含27,714个不同的设计，是具有此复杂程度的工程设计最大的语料库。每个设计都涵盖了飞行器设计领域的多个物理领域和多种表示形式。

    

    我们呈现了一个公开可用的飞行器设计数据集，即AircraftVerse。飞行器设计涵盖不同的物理领域和多种表示形式。评估这些智能物理系统设计需要使用科学分析和仿真模型，从结构和制造分析的计算机辅助设计工具，到计算流体力学工具的阻力和升力计算，再到能源估计的电池模型和飞行控制与动力学的仿真模型。AircraftVerse包含27,714种不同的飞行器设计，是具有此复杂程度的工程设计最大的语料库。每个设计包括以下构件：描述拓扑、推进子系统、电池子系统和其他设计细节的符号设计树；以STandard for the Exchange of Product (STEP) 模型数据为基础的 3D CAD设计；以立体光刻（STL）文件格式为基础的3D点云，用于描述设计的形状。

    We present AircraftVerse, a publicly available aerial vehicle design dataset. Aircraft design encompasses different physics domains and, hence, multiple modalities of representation. The evaluation of these cyber-physical system (CPS) designs requires the use of scientific analytical and simulation models ranging from computer-aided design tools for structural and manufacturing analysis, computational fluid dynamics tools for drag and lift computation, battery models for energy estimation, and simulation models for flight control and dynamics. AircraftVerse contains 27,714 diverse air vehicle designs - the largest corpus of engineering designs with this level of complexity. Each design comprises the following artifacts: a symbolic design tree describing topology, propulsion subsystem, battery subsystem, and other design details; a STandard for the Exchange of Product (STEP) model data; a 3D CAD design using a stereolithography (STL) file format; a 3D point cloud for the shape of the de
    
[^50]: 物理信息神经网络在逆流自发渗透中的应用和预测：早期和晚期的模拟

    Simulation and Prediction of Countercurrent Spontaneous Imbibition at Early and Late Times Using Physics-Informed Neural Networks. (arXiv:2306.05554v1 [physics.comp-ph])

    [http://arxiv.org/abs/2306.05554](http://arxiv.org/abs/2306.05554)

    本文通过物理信息神经网络模型对多孔材料中的逆流自发渗透过程进行了早期和晚期的模拟和预测，并使用改变变量技术来改进模型性能。

    

    逆流自发渗透（COUCSI）是一种多孔材料中的过程，其中润湿相取代了非润湿相的位置。本文首次探讨了物理信息神经网络（PINNs）在解决早期（ET）和晚期（LT）COUCSI问题中的应用。同时，我们还研究了改变变量技术以改进PINNs的性能。我们通过改变自变量将COUCSI问题分别用XT-，XY-和Z-三种等效形式进行描述：第一个描述了饱和度作为规范化位置X和时间T的函数;第二个描述了X和Y=T^0.5作为函数的饱和度;第三个作为Z=X/T^0.5的唯一函数（仅在ET下有效）。该PINN模型使用前馈神经网络生成，并基于最小化加权损失函数进行训练，包括物理信息丢失项和与初始边界条件相对应的项。没有合成或实验数据被调用。

    Countercurrent spontaneous imbibition (COUCSI) is a process in porous materials in which a wetting phase displaces non-wetting phase. In this work, we investigate for the first time the application of Physics-Informed Neural Networks (PINNs) in solving the 1D COUCSI problem in both early (ET) and late (LT) times. Also novel, we examine the Change-of-Variables technique for improving the performance of PINNs. We formulated the COUCSI problem in three equivalent forms by changing the independent variables: XT-, XY-, and Z-formulations. The first describes saturation as function of normalized position X and time T; the second as function of X and Y=T^0.5; and the third as a sole function of Z=X/T^0.5 (valid only at ET). The PINN model was generated using a feed-forward neural network and trained based on minimizing a weighted loss function, including the physics-informed loss term and terms corresponding to the initial and boundary conditions. No synthetical or experimental data were invo
    
[^51]: 对带“标记语言模型”中93个受歧视群体的偏见及其对下游情感分类任务的影响

    Bias Against 93 Stigmatized Groups in Masked Language Models and Downstream Sentiment Classification Tasks. (arXiv:2306.05550v1 [cs.CY])

    [http://arxiv.org/abs/2306.05550](http://arxiv.org/abs/2306.05550)

    本研究研究了英语预训练的Masked Language Models（MLMs）以及它们的下游情感分类任务对美国93个社会污名化群体的偏见，为了评估93个污名化条件的偏见存在，我们对它们进行了比较分析，找到了偏见存在的表现。

    

    人工智能模型的快速部署需要对这些模型固有的偏见和风险进行彻底的调查，以了解它们对个人和社会的影响。本研究通过对大规模社会污名化的偏见进行研究，扩展了已有工作对偏见评估的焦点。它关注美国93个社会污名化群体，包括与疾病、残疾、药物使用、心理疾病、宗教、性取向、社会经济地位和其他相关因素有关的一系列情况。我们研究了英语预训练的Masked Language Models（MLMs）以及它们的下游情感分类任务对这些群体的偏见。为了评估93个污名化条件的偏见存在，我们确定了29个非污名化条件进行比较分析。基于社会排斥的心理学尺度-社会距离量表，我们对六个MLMs进行了提示：RoBERTa-base、RoBERTa-large、XLNet-large、BERTweet-base、BERTweet-la。

    The rapid deployment of artificial intelligence (AI) models demands a thorough investigation of biases and risks inherent in these models to understand their impact on individuals and society. This study extends the focus of bias evaluation in extant work by examining bias against social stigmas on a large scale. It focuses on 93 stigmatized groups in the United States, including a wide range of conditions related to disease, disability, drug use, mental illness, religion, sexuality, socioeconomic status, and other relevant factors. We investigate bias against these groups in English pre-trained Masked Language Models (MLMs) and their downstream sentiment classification tasks. To evaluate the presence of bias against 93 stigmatized conditions, we identify 29 non-stigmatized conditions to conduct a comparative analysis. Building upon a psychology scale of social rejection, the Social Distance Scale, we prompt six MLMs: RoBERTa-base, RoBERTa-large, XLNet-large, BERTweet-base, BERTweet-la
    
[^52]: DetectLLM：基于对数秩信息的零样本检测机器生成文本

    DetectLLM: Leveraging Log Rank Information for Zero-Shot Detection of Machine-Generated Text. (arXiv:2306.05540v1 [cs.CL])

    [http://arxiv.org/abs/2306.05540](http://arxiv.org/abs/2306.05540)

    作者提出了两种零样本方法，DetectLLM-LRR和DetectLLM-NPR，可以通过利用日志排名信息来检测机器生成的文本，实验表明这些方法在检测效果上超过了现有的最佳方法。

    

    随着大型语言模型（LLM）的快速进展和所生成的文本数量的巨大增加，人工区分文本是否为机器生成变得越来越不切实际。考虑到LLM在社交媒体和教育中的广泛应用，促使我们开发检测机器生成文本的方法，以防止恶意使用，如抄袭、虚假信息和宣传。以前的研究已经研究了几种零样本的方法，这些方法不需要训练数据。这些方法取得了良好的性能，但还有很大的改进空间。本文介绍了两种新的零样本方法，用于利用对数秩信息检测机器生成文本。其中一个称为DetectLLM-LRR，快速高效，另一个称为DetectLLM-NPR，更精确，但需要扰动，因此速度更慢。我们在三个数据集和七个语言模型上的实验表明，我们提出的方法在零样本检测机器生成文本方面超过了现有的最佳效果。

    With the rapid progress of large language models (LLMs) and the huge amount of text they generated, it becomes more and more impractical to manually distinguish whether a text is machine-generated. Given the growing use of LLMs in social media and education, it prompts us to develop methods to detect machine-generated text, preventing malicious usage such as plagiarism, misinformation, and propaganda. Previous work has studied several zero-shot methods, which require no training data. These methods achieve good performance, but there is still a lot of room for improvement. In this paper, we introduce two novel zero-shot methods for detecting machine-generated text by leveraging the log rank information. One is called DetectLLM-LRR, which is fast and efficient, and the other is called DetectLLM-NPR, which is more accurate, but slower due to the need for perturbations. Our experiments on three datasets and seven language models show that our proposed methods improve over the state of the
    
[^53]: 使用音频数据检测政治辩论、演讲和访谈中值得核实的论断

    Detecting Check-Worthy Claims in Political Debates, Speeches, and Interviews Using Audio Data. (arXiv:2306.05535v1 [cs.CL])

    [http://arxiv.org/abs/2306.05535](http://arxiv.org/abs/2306.05535)

    政治辩论、演讲和访谈中的值得核实的论断可以使用音频数据进行检测和确认，这可帮助主持人、记者和事实核查组织进行工作。

    

    社会的一大部分团结在相同的愿景和思想周围，具有巨大的能量。这正是政治人物希望为他们的事业所累积的。为了达到这个目标，他们有时会使用扭曲或隐藏真相的手段，无论是无意的还是有意的，这为错误信息和误导开了大门。自动检测值得核实的论断的工具将对辩论主持人、记者和事实核查组织有很大帮助。虽然以前关于检测值得核实的论断的工作重点是文本，但在这里，我们探讨了音频信号作为额外信息源的实用性。我们创建了一个新的多模态数据集（英语文本和音频），包含48小时的演讲。我们的评估结果表明，在多个演讲者的情况下，音频模态与文本结合使用比仅使用文本具有改进效果。此外，单声道音频模型可以胜过单声道文本模型。

    A large portion of society united around the same vision and ideas carries enormous energy. That is precisely what political figures would like to accumulate for their cause. With this goal in mind, they can sometimes resort to distorting or hiding the truth, unintentionally or on purpose, which opens the door for misinformation and disinformation. Tools for automatic detection of check-worthy claims would be of great help to moderators of debates, journalists, and fact-checking organizations. While previous work on detecting check-worthy claims has focused on text, here we explore the utility of the audio signal as an additional information source. We create a new multimodal dataset (text and audio in English) containing 48 hours of speech. Our evaluation results show that the audio modality together with text yields improvements over text alone in the case of multiple speakers. Moreover, an audio-only model could outperform a text-only one for a single speaker.
    
[^54]: FACTIFY3M: 通过5W问答解释的多模式事实验证基准

    FACTIFY3M: A Benchmark for Multimodal Fact Verification with Explainability through 5W Question-Answering. (arXiv:2306.05523v1 [cs.CL])

    [http://arxiv.org/abs/2306.05523](http://arxiv.org/abs/2306.05523)

    FACTIFY3M是一个以多模式虚假信息验证为目标的数据集。虚假信息如今已成为当下重大的社会问题，这一数据集旨在通过多模式验证来及时识别和缓解虚假信息。

    

    打击虚假信息是当前亟待解决的社会危机之一——大约67%的美国人认为虚假信息会产生大量的不确定性，其中有10%的人有意识地传播虚假信息。证据表明，虚假信息可以操纵民主进程和公众舆论，并在危机期间引起股市动荡、社会恐慌甚至死亡。因此，应及时识别并尽可能缓解虚假信息。然而，由于社交媒体平台每天分享大约32亿张图像和720,000 小时的视频，因此对于多模式虚假信息的可扩展性检测需要高效的事实验证。尽管在文本模式下自动事实验证取得了进展(例如，FEVER, LIAR)，但学术界在多模式事实验证方面缺乏实质性的努力。为了填补这一空白，我们引入了FACTIFY3M数据集，该数据集包含300万个样本，通过多种模式和5W问答提高了事实验证领域的极限。

    Combating disinformation is one of the burning societal crises -- about 67% of the American population believes that disinformation produces a lot of uncertainty, and 10% of them knowingly propagate disinformation. Evidence shows that disinformation can manipulate democratic processes and public opinion, causing disruption in the share market, panic and anxiety in society, and even death during crises. Therefore, disinformation should be identified promptly and, if possible, mitigated. With approximately 3.2 billion images and 720,000 hours of video shared online daily on social media platforms, scalable detection of multimodal disinformation requires efficient fact verification. Despite progress in automatic text-based fact verification (e.g., FEVER, LIAR), the research community lacks substantial effort in multimodal fact verification. To address this gap, we introduce FACTIFY 3M, a dataset of 3 million samples that pushes the boundaries of the domain of fact verification via a multi
    
[^55]: 文本到图像模型中分析偏见的单词级解释

    Word-Level Explanations for Analyzing Bias in Text-to-Image Models. (arXiv:2306.05500v1 [cs.CL])

    [http://arxiv.org/abs/2306.05500](http://arxiv.org/abs/2306.05500)

    本文探讨了文本到图像模型中存在的少数族裔偏见，提出了一种利用屏蔽语言模型计算提示中单词得分的方法，并通过实验证明其可以识别生成的图像中存在的社会刻板印象。

    

    文本到图像模型接收一句话（即提示）并生成与该输入提示相关联的图像。但是，这些模型可以生成基于种族和性别而偏袒少数族裔的图像。本文研究了输入提示中哪个单词导致生成图像出现偏见。我们引入了一种计算提示中每个单词得分的方法；这些得分代表其在模型输出偏差中的影响。我们的方法遵循“删除解释”的原则，利用屏蔽语言模型计算影响得分。我们在稳定扩散上进行实验，证明我们的方法可以识别生成的图像中复制社会刻板印象。

    Text-to-image models take a sentence (i.e., prompt) and generate images associated with this input prompt. These models have created award wining-art, videos, and even synthetic datasets. However, text-to-image (T2I) models can generate images that underrepresent minorities based on race and sex. This paper investigates which word in the input prompt is responsible for bias in generated images. We introduce a method for computing scores for each word in the prompt; these scores represent its influence on biases in the model's output. Our method follows the principle of \emph{explaining by removing}, leveraging masked language models to calculate the influence scores. We perform experiments on Stable Diffusion to demonstrate that our method identifies the replication of societal stereotypes in generated images.
    
[^56]: LLM集成应用中的提示注入攻击研究

    Prompt Injection attack against LLM-integrated Applications. (arXiv:2306.05499v1 [cs.CR])

    [http://arxiv.org/abs/2306.05499](http://arxiv.org/abs/2306.05499)

    本研究分析了LLM集成应用中的提示注入攻击的复杂性和影响，提出了一种新颖的黑盒提示注入攻击技术HouYi，并揭示了应用程序提示机制中以前未知和严重低估的漏洞。我们的研究呼吁进一步开发全面的防御措施，以抵御LLM集成应用中的提示注入攻击。

    

    大语言模型(LLM)因其卓越的语言理解和生成能力而在它们周围刺激了一个充满活力的应用生态系统。然而，它们在各种服务中的广泛融合带来了重大的安全风险。本研究将解构实际LLM集成应用中的提示注入攻击的复杂性和影响。最初，我们对十个商业应用程序进行了探索性分析，突出了目前攻击策略在实践中的约束条件。受这些限制的启发，我们随后制定了HouYi，一种新颖的黑盒提示注入攻击技术，它借鉴了传统的Web注入攻击。HouYi分为三个关键元素: 一个无缝集成的预构建提示、一个注入提示诱导上下文分区以及一个恶意载荷，旨在实现攻击目标。利用HouYi，我们揭示了应用程序提示机制中以前未知和严重低估的漏洞，并演示了绕过最先进的检测机制的可行性。我们的研究呼吁进一步研究开发全面的防御措施，以抵御LLM集成应用中的提示注入攻击。

    Large Language Models (LLMs), renowned for their superior proficiency in language comprehension and generation, stimulate a vibrant ecosystem of applications around them. However, their extensive assimilation into various services introduces significant security risks. This study deconstructs the complexities and implications of prompt injection attacks on actual LLM-integrated applications. Initially, we conduct an exploratory analysis on ten commercial applications, highlighting the constraints of current attack strategies in practice. Prompted by these limitations, we subsequently formulate HouYi, a novel black-box prompt injection attack technique, which draws inspiration from traditional web injection attacks. HouYi is compartmentalized into three crucial elements: a seamlessly-incorporated pre-constructed prompt, an injection prompt inducing context partition, and a malicious payload designed to fulfill the attack objectives. Leveraging HouYi, we unveil previously unknown and sev
    
[^57]: 重新评估损失函数：增强深度学习模型对标签噪声的鲁棒性

    Reevaluating Loss Functions: Enhancing Robustness to Label Noise in Deep Learning Models. (arXiv:2306.05497v1 [cs.LG])

    [http://arxiv.org/abs/2306.05497](http://arxiv.org/abs/2306.05497)

    本文研究了使用噪声鲁棒损失函数增强深度学习模型对标签噪声的鲁棒性，并提出了一种无需超参数调整的新技术：包括输出偏置。

    

    大规模标注的数据集中难免会出现错误的标签，这给深度神经网络的训练带来了极大的挑战，因为它们很容易适应这些错误的标签。只有使用不受噪声干扰的鲁棒模型进行训练，才能获得良好的泛化性能。创建噪声鲁棒模型的一种简单而有效的方式是使用噪声鲁棒损失函数。然而，提出的损失函数数量众多，它们通常伴随着超参数，而且可能学习速度比广泛使用但对噪声敏感的交叉熵损失要慢。通过启发式考虑和广泛的数值实验，我们研究了在哪些情况下提出的损失函数适用，并提出了如何选择合适的损失的建议。此外，我们提出了一种新的技术来增强带有有界损失函数的学习：包括输出偏置，即略微增加与正确标签相对应的神经元预激活。令人惊讶的是，我们发现这种技术在无需超参数调整的情况下表现与最先进的方法类似。

    Large annotated datasets inevitably contain incorrect labels, which poses a major challenge for the training of deep neural networks as they easily fit the labels. Only when training with a robust model that is not easily distracted by the noise, a good generalization performance can be achieved. A simple yet effective way to create a noise robust model is to use a noise robust loss function. However, the number of proposed loss functions is large, they often come with hyperparameters, and may learn slower than the widely used but noise sensitive Cross Entropy loss. By heuristic considerations and extensive numerical experiments, we study in which situations the proposed loss functions are applicable and give suggestions on how to choose an appropriate loss. Additionally, we propose a novel technique to enhance learning with bounded loss functions: the inclusion of an output bias, i.e. a slight increase in the neuron pre-activation corresponding to the correct label. Surprisingly, we f
    
[^58]: 开放词汇物体检测的多模态分类器

    Multi-Modal Classifiers for Open-Vocabulary Object Detection. (arXiv:2306.05493v1 [cs.CV])

    [http://arxiv.org/abs/2306.05493](http://arxiv.org/abs/2306.05493)

    本文提出了一种开放词汇物体检测的多模态分类器，能够在推断过程中检测超出训练范畴的目标，并优于传统基线模型。

    

    本文的目标在于实现开放词汇物体检测（OVOD），提出了通过语言描述、图像实例或两者的组合，指定新类别的三种方式，并构建了基于文本和基于视觉的强大分类器，最终提出一种融合了多模态信息的分类器。在评估中，我们的方法优于基线。

    The goal of this paper is open-vocabulary object detection (OVOD) $\unicode{x2013}$ building a model that can detect objects beyond the set of categories seen at training, thus enabling the user to specify categories of interest at inference without the need for model retraining. We adopt a standard two-stage object detector architecture, and explore three ways for specifying novel categories: via language descriptions, via image exemplars, or via a combination of the two. We make three contributions: first, we prompt a large language model (LLM) to generate informative language descriptions for object classes, and construct powerful text-based classifiers; second, we employ a visual aggregator on image exemplars that can ingest any number of images as input, forming vision-based classifiers; and third, we provide a simple method to fuse information from language descriptions and image exemplars, yielding a multi-modal classifier. When evaluating on the challenging LVIS open-vocabulary
    
[^59]: 多智能体信念的PAC语义可学习性

    Learnability with PAC Semantics for Multi-agent Beliefs. (arXiv:2306.05490v1 [cs.AI])

    [http://arxiv.org/abs/2306.05490](http://arxiv.org/abs/2306.05490)

    本文提供了一种新的技术基础，以证明可以用PAC学习算法来学习多智能体认知逻辑，并实现了隐式学习来应对PAC语义强健学习困难。

    

    演绎和归纳之间的紧张关系可能是哲学、认知和人工智能等领域中最基本的问题。作者提出了一种语义来捕捉PAC学习算法输出的性质，使其与演绎融为一体，以便为回答查询提供强大的模型理论框架。本文提供了一个新的技术基础，以证明可以用PAC学习算法来学习多智能体认知逻辑，并且考虑了一种称为隐式学习的方法，以应对文献中关于PAC语义强健学习困难的负面结果，即我们能够将观察结果整合到背景理论中，以帮助决定认知查询的蕴含性。我们证明了学习过程的正确性。

    The tension between deduction and induction is perhaps the most fundamental issue in areas such as philosophy, cognition and artificial intelligence. In an influential paper, Valiant recognised that the challenge of learning should be integrated with deduction. In particular, he proposed a semantics to capture the quality possessed by the output of Probably Approximately Correct (PAC) learning algorithms when formulated in a logic. Although weaker than classical entailment, it allows for a powerful model-theoretic framework for answering queries. In this paper, we provide a new technical foundation to demonstrate PAC learning with multi-agent epistemic logics. To circumvent the negative results in the literature on the difficulty of robust learning with the PAC semantics, we consider so-called implicit learning where we are able to incorporate observations to the background theory in service of deciding the entailment of an epistemic query. We prove correctness of the learning procedur
    
[^60]: 医学成像的人工通用智能

    Artificial General Intelligence for Medical Imaging. (arXiv:2306.05480v1 [cs.AI])

    [http://arxiv.org/abs/2306.05480](http://arxiv.org/abs/2306.05480)

    本文探讨了人工通用智能模型在医学成像中的应用，重点关注基础的大型语言、视觉和多模态模型。通过整合临床专业知识、领域知识和多模态能力来开发和部署AGI能够解决医学领域面临的挑战和问题。

    

    本文探讨了人工通用智能模型在医疗保健中的潜在应用，重点关注基础的大型语言模型、大型视觉模型和大型多模态模型。我们强调将临床专业知识、领域知识和多模态能力整合到AGI模型中的重要性。此外，我们提出了指导医疗保健AGI模型开发和部署的路线图。在整个综述过程中，我们提供了关于在医学领域部署大规模AGI模型可能面临的潜在挑战和缺陷的关键观点。这篇综合性的综述旨在提供有关AGI对医学成像、医疗保健和其他领域未来影响的见解。

    In this review, we explore the potential applications of Artificial General Intelligence (AGI) models in healthcare, focusing on foundational Large Language Models (LLMs), Large Vision Models, and Large Multimodal Models. We emphasize the importance of integrating clinical expertise, domain knowledge, and multimodal capabilities into AGI models. In addition, we lay out key roadmaps that guide the development and deployment of healthcare AGI models. Throughout the review, we provide critical perspectives on the potential challenges and pitfalls associated with deploying large-scale AGI models in the medical field. This comprehensive review aims to offer insights into the future implications of AGI in medical imaging, healthcare and beyond.
    
[^61]: 患语言障碍者的潜在短语匹配系统

    Latent Phrase Matching for Dysarthric Speech. (arXiv:2306.05446v1 [eess.AS])

    [http://arxiv.org/abs/2306.05446](http://arxiv.org/abs/2306.05446)

    患有语言障碍的人在现有消费类语音识别系统中表现不佳，作者提出了一种基于个性化短语识别系统用于适应其非典型的语音模式，其具有很好的泛化性能，并在数据集上有很好的表现。

    

    很多消费类语音识别系统不能为语言障碍患者提供良好的体验和识别效果，尤其是对于语言障碍情况更为严重的人。最近的研究集中于个性化语音模型的探索，以便更好地适应非典型的语音模式。我们提出了一种基于示例的个性化短语识别系统，该系统使用少量的语音进行训练，不依赖于传统发音词典，不受不同语言影响，且在各种语音障碍情况下具有很好的泛化性能。在32名患有言语困难的人员的内部数据集上，该方法不受严重程度影响，与商业语音识别系统相比，召回率提高了60%。在公共EasyCall数据集上，我们的方法将精度提高了30.5%。当训练50个独特短语时，性能随短语数量增加而下降，但始终优于ASR系统。

    Many consumer speech recognition systems are not tuned for people with speech disabilities, resulting in poor recognition and user experience, especially for severe speech differences. Recent studies have emphasized interest in personalized speech models from people with atypical speech patterns. We propose a query-by-example-based personalized phrase recognition system that is trained using small amounts of speech, is language agnostic, does not assume a traditional pronunciation lexicon, and generalizes well across speech difference severities. On an internal dataset collected from 32 people with dysarthria, this approach works regardless of severity and shows a 60% improvement in recall relative to a commercial speech recognition system. On the public EasyCall dataset of dysarthric speech, our approach improves accuracy by 30.5%. Performance degrades as the number of phrases increases, but consistently outperforms ASR systems when trained with 50 unique phrases.
    
[^62]: PIXIU：面向金融领域的大型语言模型、指令数据和评估基准

    PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark for Finance. (arXiv:2306.05443v1 [cs.CL])

    [http://arxiv.org/abs/2306.05443](http://arxiv.org/abs/2306.05443)

    本文介绍了PIXIU框架，其中包括基于Fine-tuning LLaMA的第一个金融语言模型、包含136K数据样本用于Fine-tuning的第一个指令数据，以及具有5个任务和9个数据集的评估基准。通过对各种金融任务、金融文档类型和金融数据模态考虑，构建了大规模的多任务指令数据集，利用该数据集提出了名为FinMA的金融语言模型，以便对各种金融任务进行指令跟随。

    

    虽然大型语言模型在金融领域的自然语言处理方面表现出色，但缺乏公开的面向金融的语言模型、指令调优数据集和评估基准，这对于不断推进金融人工智能开源发展至关重要。本文提出了PIXIU框架，其中包括基于Fine-tuning LLaMA的第一个金融语言模型、包含136K数据样本用于Fine-tuning的第一个指令数据，以及具有5个任务和9个数据集的评估基准。我们首先考虑各种金融任务、金融文档类型和金融数据模态，构建了大规模的多任务指令数据集。然后，我们利用构建的数据集通过Fine-tuning LLaMA提出了名为FinMA的金融语言模型，以便对各种金融任务进行指令跟随。为了支持金融语言模型的评估

    Although large language models (LLMs) has shown great performance on natural language processing (NLP) in the financial domain, there are no publicly available financial tailtored LLMs, instruction tuning datasets, and evaluation benchmarks, which is critical for continually pushing forward the open-source development of financial artificial intelligence (AI). This paper introduces PIXIU, a comprehensive framework including the first financial LLM based on fine-tuning LLaMA with instruction data, the first instruction data with 136K data samples to support the fine-tuning, and an evaluation benchmark with 5 tasks and 9 datasets. We first construct the large-scale multi-task instruction data considering a variety of financial tasks, financial document types, and financial data modalities. We then propose a financial LLM called FinMA by fine-tuning LLaMA with the constructed dataset to be able to follow instructions for various financial tasks. To support the evaluation of financial LLMs
    
[^63]: CLC: 基于对比表示学习的聚类分配方法

    CLC: Cluster Assignment via Contrastive Representation Learning. (arXiv:2306.05439v1 [cs.LG])

    [http://arxiv.org/abs/2306.05439](http://arxiv.org/abs/2306.05439)

    本文提出了一种基于对比学习的聚类方法（CLC），它使用对比学习直接学习聚类分配，并在大规模数据集上取得了更好的聚类性能。

    

    聚类是一项重要而具有挑战性的任务，旨在将样本分组，而不需要手动注释。最近的研究通过对自监督学习得到的特征表示进行聚类，在小型数据集上取得了出色的结果。然而，对于包含大量聚类的数据集，如ImageNet，当前的方法仍然无法实现高聚类性能。在本文中，我们提出了基于对比学习的聚类方法（CLC），它使用对比学习直接学习聚类分配。我们将表示分解为两部分：一部分对类别信息进行编码，并采用等分约束，另一部分捕捉实例因素。我们提出了一种对比损失，使用表示的两个部分。我们在理论上分析了所提出的对比损失，并揭示了CLC在学习聚类分配时为负样本设置不同的权重。进一步的梯度分析表明，当使用CLC时，在大规模数据集上取得了更好的聚类性能。

    Clustering remains an important and challenging task of grouping samples into clusters without manual annotations. Recent works have achieved excellent results on small datasets by performing clustering on feature representations learned from self-supervised learning. However, for datasets with a large number of clusters, such as ImageNet, current methods still can not achieve high clustering performance. In this paper, we propose Contrastive Learning-based Clustering (CLC), which uses contrastive learning to directly learn cluster assignment. We decompose the representation into two parts: one encodes the categorical information under an equipartition constraint, and the other captures the instance-wise factors. We propose a contrastive loss using both parts of the representation. We theoretically analyze the proposed contrastive loss and reveal that CLC sets different weights for the negative samples while learning cluster assignments. Further gradient analysis shows that the larger 
    
[^64]: 多视角聚类方法：一步多视角聚类与多样性表征

    One-step Multi-view Clustering with Diverse Representation. (arXiv:2306.05437v1 [cs.LG])

    [http://arxiv.org/abs/2306.05437](http://arxiv.org/abs/2306.05437)

    本文提出了一种一步多视角聚类与多样性表征的方法，将多视角学习和k-means聚类融合到一个统一框架中，实验结果表明其在各种标准的多视角数据集上都优于现有算法。

    

    多视角聚类因其能够利用不同视角的信息来提高效果而备受关注。本文提出了一种一步多视角聚类与多样性表征的方法，将多视角学习和k-means聚类融合到一个统一框架中。实验结果表明，在各种标准的多视角数据集上，我们的方法在效果和效率方面都优于现有的同类算法。

    Multi-view clustering has attracted broad attention due to its capacity to utilize consistent and complementary information among views. Although tremendous progress has been made recently, most existing methods undergo high complexity, preventing them from being applied to large-scale tasks. Multi-view clustering via matrix factorization is a representative to address this issue. However, most of them map the data matrices into a fixed dimension, which limits the expressiveness of the model. Moreover, a range of methods suffer from a two-step process, i.e., multimodal learning and the subsequent $k$-means, inevitably causing a sub-optimal clustering result. In light of this, we propose a one-step multi-view clustering with diverse representation method, which incorporates multi-view learning and $k$-means into a unified framework. Specifically, we first project original data matrices into various latent spaces to attain comprehensive information and auto-weight them in a self-supervis
    
[^65]: 迈向端到端语音到文本摘要技术

    Towards End-to-end Speech-to-text Summarization. (arXiv:2306.05432v1 [cs.CL])

    [http://arxiv.org/abs/2306.05432](http://arxiv.org/abs/2306.05432)

    该论文提出了一种迈向端到端语音到文本摘要技术的方法，这种技术可以用于过滤和跟踪每天上传在线的广播新闻，并能够产生丰富的潜在表示，但需要进一步的研究来提高其有效性和鲁棒性。

    

    语音到文本（S2T）摘要是一种节省时间的技术，可用于过滤和跟踪每天上传在线的广播新闻。最近深度学习中出现了具有出色文本生成能力的大型语言模型，引起了对产生简洁文档版本的摘要系统的研究重点，也称为抽象摘要。端到端（E2E）建模的S2T抽象摘要是一种有前途的方法，它提供了产生丰富潜在表示的可能性，这些表示利用了非语言和声学信息，而不是仅使用级联系统中自动生成的转录文本的语言信息。然而，文献中关于这项任务的E2E建模很少探索不同的领域，特别是广播新闻是一个具有挑战性的领域，每天向用户呈现大量和多样化的数据。我们采用级联翻译方法和端到端方法建模S2T摘要，并在广播新闻的新数据集上进行了评估。我们的结果显示，E2E方法具有更好的表现潜力，但需要进一步的研究来提高其在不同领域中的有效性和鲁棒性。

    Speech-to-text (S2T) summarization is a time-saving technique for filtering and keeping up with the broadcast news uploaded online on a daily basis. The rise of large language models from deep learning with impressive text generation capabilities has placed the research focus on summarization systems that produce paraphrased compact versions of the document content, also known as abstractive summaries. End-to-end (E2E) modelling of S2T abstractive summarization is a promising approach that offers the possibility of generating rich latent representations that leverage non-verbal and acoustic information, as opposed to the use of only linguistic information from automatically generated transcripts in cascade systems. However, the few literature on E2E modelling of this task fails on exploring different domains, namely broadcast news, which is challenging domain where large and diversified volumes of data are presented to the user every day. We model S2T summarization both with a cascade 
    
[^66]: RRWKV：在RWKV中捕捉长距离依赖关系

    RRWKV: Capturing Long-range Dependencies in RWKV. (arXiv:2306.05176v1 [cs.CL])

    [http://arxiv.org/abs/2306.05176](http://arxiv.org/abs/2306.05176)

    本文介绍了一种新的RRWKV架构，它在保持记忆和计算效率的同时，通过加入回顾能力有效地捕捉长距离依赖关系。

    

    由于Transformer惊人的点积注意力，它已经成为各种自然语言处理（NLP）任务中的主要架构。最近，Receptance Weighted Key Value（RWKV）架构遵循非Transformer架构，消除了点积注意力的缺点，其中存储和计算复杂度随着序列长度呈二次扩展。尽管RWKV利用了线性张量积注意机制并通过部署时间序列模式实现了并行计算，但与标准Transformer中直接交互获得的完整信息相比，它无法捕捉长距离依赖关系，因为其受限于向后查看先前信息的能力。因此，本文通过将回顾能力纳入RWKV中来设计Retrospected Receptance Weighted Key Value（RRWKV）架构，以有效地吸收信息，同时保持记忆和计算效率。

    Owing to the impressive dot-product attention, the Transformers have been the dominant architectures in various natural language processing (NLP) tasks. Recently, the Receptance Weighted Key Value (RWKV) architecture follows a non-transformer architecture to eliminate the drawbacks of dot-product attention, where memory and computational complexity exhibits quadratic scaling with sequence length. Although RWKV has exploited a linearly tensor-product attention mechanism and achieved parallelized computations by deploying the time-sequential mode, it fails to capture long-range dependencies because of its limitation on looking back at previous information, compared with full information obtained by direct interactions in the standard transformer. Therefore, the paper devises the Retrospected Receptance Weighted Key Value (RRWKV) architecture via incorporating the retrospecting ability into the RWKV to effectively absorb information, which maintains memory and computational efficiency as 
    
[^67]: 人工智能是否是更好的编程伙伴？人人对编程 vs 人工智能对编程

    Is AI the better programming partner? Human-Human Pair Programming vs. Human-AI pAIr Programming. (arXiv:2306.05153v1 [cs.HC])

    [http://arxiv.org/abs/2306.05153](http://arxiv.org/abs/2306.05153)

    人工智能与人类程序员共同开发可以通过设计良好的AI编程助手，增强双方合作的生产力。

    

    随着掌握代码生成能力的大型语言模型(LLMs)的出现以及商业产品，如GitHub的Copilot，人工智能与人类程序员的合作(pAIr编程)引起了人们的兴趣。虽然传统的人人对编程已经被广泛研究，但仍然不确定其研究结果是否能适用于人工智能对编程。我们比较了人人对编程和人工智能对编程，探讨了它们在交互、衡量、优点和挑战方面的相似之处和差异之处。我们发现，两种方法的有效性在文献中各不相同（尽管用于pAIr编程的度量不太全面）。我们总结了影响人人对编程成功的调节因素，为pAIr编程研究提供了机会。例如，不匹配的专业知识会使对编程缺乏生产力，因此设计良好的AI编程助手可以潜在地解决这个问题。

    The emergence of large-language models (LLMs) that excel at code generation and commercial products such as GitHub's Copilot has sparked interest in human-AI pair programming (referred to as "pAIr programming") where an AI system collaborates with a human programmer. While traditional pair programming between humans has been extensively studied, it remains uncertain whether its findings can be applied to human-AI pair programming. We compare human-human and human-AI pair programming, exploring their similarities and differences in interaction, measures, benefits, and challenges. We find that the effectiveness of both approaches is mixed in the literature (though the measures used for pAIr programming are not as comprehensive). We summarize moderating factors on the success of human-human pair programming, which provides opportunities for pAIr programming research. For example, mismatched expertise makes pair programming less productive, therefore well-designed AI programming assistants
    
[^68]: 多样化和区分化表示学习的通用低资源活动识别

    Generalizable Low-Resource Activity Recognition with Diverse and Discriminative Representation Learning. (arXiv:2306.04641v1 [cs.CV])

    [http://arxiv.org/abs/2306.04641](http://arxiv.org/abs/2306.04641)

    提出了一种新方法DDLearn，通过构建自监督学习任务，在考虑多样化和区分化学习的基础上提高通用低资源人类活动识别的性能。

    

    人类活动识别是一项时间序列分类任务，重点是从人类传感器读数中识别动作模式。然而，获取充足的数据是训练通用人类活动识别模型的关键难点，这有助于在线网络应用程序的定制和优化。本文提出了一种新的方法DDLearn，通过构建自监督学习任务，同时考虑差异性和歧视性学习，从而实现了通用低资源人类活动识别。

    Human activity recognition (HAR) is a time series classification task that focuses on identifying the motion patterns from human sensor readings. Adequate data is essential but a major bottleneck for training a generalizable HAR model, which assists customization and optimization of online web applications. However, it is costly in time and economy to collect large-scale labeled data in reality, i.e., the low-resource challenge. Meanwhile, data collected from different persons have distribution shifts due to different living habits, body shapes, age groups, etc. The low-resource and distribution shift challenges are detrimental to HAR when applying the trained model to new unseen subjects. In this paper, we propose a novel approach called Diverse and Discriminative representation Learning (DDLearn) for generalizable low-resource HAR. DDLearn simultaneously considers diversity and discrimination learning. With the constructed self-supervised learning task, DDLearn enlarges the data dive
    
[^69]: 将几何控制集成到文本到图像扩散模型中以通过文本提示生成高质量的检测数据

    Integrating Geometric Control into Text-to-Image Diffusion Models for High-Quality Detection Data Generation via Text Prompt. (arXiv:2306.04607v1 [cs.CV])

    [http://arxiv.org/abs/2306.04607](http://arxiv.org/abs/2306.04607)

    GeoDiffusion使用文本提示将各种几何条件转化为图像，生成高质量的检测数据，性能优于现有方法。

    

    扩散模型因其在创建内容和生成数据方面的显着能力而受到重视，例如图像分类。然而，使用扩散模型生成高质量的物体检测数据仍然是一个不被充分探索的领域，其中不仅图像水平的感知质量，而且边界框和相机视图等几何条件也是至关重要的。前期研究使用模块编码语义布局来实现复制粘贴合成或布局到图像(L2I)生成。本文提出了GeoDiffusion，一种简单的框架，可以灵活地将各种几何条件转化为文本提示，并使用预训练的文本到图像(T2I)扩散模型生成高质量的检测数据。与以往的L2I方法不同，我们的GeoDiffusion不仅能够编码边界框，还能够编码自驾场景中的额外几何条件，如摄像头视图。广泛的实验结果表明，GeoDiffusion在物体检测准确性方面优于最先进的方法，并针对各种几何条件生成具有更高感知质量的图像。

    Diffusion models have attracted significant attention due to their remarkable ability to create content and generate data for tasks such as image classification. However, the usage of diffusion models to generate high-quality object detection data remains an underexplored area, where not only the image-level perceptual quality but also geometric conditions such as bounding boxes and camera views are essential. Previous studies have utilized either copy-paste synthesis or layout-to-image (L2I) generation with specifically designed modules to encode semantic layouts. In this paper, we propose GeoDiffusion, a simple framework that can flexibly translate various geometric conditions into text prompts and empower the pre-trained text-to-image (T2I) diffusion models for high-quality detection data generation. Unlike previous L2I methods, our GeoDiffusion is able to encode not only bounding boxes but also extra geometric conditions such as camera views in self-driving scenes. Extensive experi
    
[^70]: 价值函数即控制障碍函数：使用控制理论验证学习策略

    Your Value Function is a Control Barrier Function: Verification of Learned Policies using Control Theory. (arXiv:2306.04026v1 [cs.LG])

    [http://arxiv.org/abs/2306.04026](http://arxiv.org/abs/2306.04026)

    本研究将控制理论中的验证方法应用于强化学习中的价值函数，提出了新的度量方法以验证安全控制任务中的价值函数，并代表了通用、可伸缩和可验证的控制系统设计框架的第一步。

    

    尽管强化学习具有高度的通用性和可伸缩性，但验证策略行为的难度对于安全关键应用程序构成了挑战。为了解决这个问题，我们建议将控制理论中使用的验证方法应用于学习的价值函数。通过分析安全维护的简单任务结构，我们推导出将值函数与控制障碍函数相联系的原始定理。受此启发，我们提出了新的度量方法，以验证安全控制任务中的价值函数，并提出了改善学习的实际实施细节。除了提出证书学习的新方法外，我们的工作为RL策略解锁了丰富的控制理论验证方法，并代表了通用、可伸缩和可验证的控制系统设计框架的第一步。

    Although RL is highly general and scalable, the difficulty of verifying policy behaviours poses challenges for safety-critical applications. To remedy this, we propose to apply verification methods used in control theory to learned value functions. By analyzing a simple task structure for safety preservation, we derive original theorems linking value functions to control barrier functions. Inspired by this, we propose novel metrics for verification of value functions in safe control tasks, and practical implementation details that improve learning. Besides proposing a novel method for certificate learning, our work unlocks a wealth of verification methods in control theory for RL policies, and represents a first step towards a framework for general, scalable, and verifiable design of control systems.
    
[^71]: 采用印象方差感知强化学习实现个性化广告中的公平性

    Towards Fairness in Personalized Ads Using Impression Variance Aware Reinforcement Learning. (arXiv:2306.03293v1 [cs.AI])

    [http://arxiv.org/abs/2306.03293](http://arxiv.org/abs/2306.03293)

    本文提出了一个名为VRS的框架，通过印象方差感知的方式对广告进行重新排序，以实现更公平的个性化广告结果。

    

    在个性化广告系统中，不同人口群体的广告印象结果差异被越来越多地视为算法偏见的可能标志。本文提出了称为VRS（Variance Reduction System）的框架，旨在以保护隐私的方式实现更公平的Meta广告系统结果，同时通过印象方差感知的方式对广告进行重新排序。

    Variances in ad impression outcomes across demographic groups are increasingly considered to be potentially indicative of algorithmic bias in personalized ads systems. While there are many definitions of fairness that could be applicable in the context of personalized systems, we present a framework which we call the Variance Reduction System (VRS) for achieving more equitable outcomes in Meta's ads systems. VRS seeks to achieve a distribution of impressions with respect to selected protected class (PC) attributes that more closely aligns the demographics of an ad's eligible audience (a function of advertiser targeting criteria) with the audience who sees that ad, in a privacy-preserving manner. We first define metrics to quantify fairness gaps in terms of ad impression variances with respect to PC attributes including gender and estimated race. We then present the VRS for re-ranking ads in an impression variance-aware manner. We evaluate VRS via extensive simulations over different pa
    
[^72]: SERT: 基于Transformer的缺失空间-时间传感器数据模型用于环境监测

    SERT: A Transfomer Based Model for Spatio-Temporal Sensor Data with Missing Values for Environmental Monitoring. (arXiv:2306.03042v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.03042](http://arxiv.org/abs/2306.03042)

    该论文提出了两种模型用于处理具有缺失值的多变量不对齐稀疏时间序列数据，其中一种是基于Transformer的模型SERT，另一种是提供可解释结果的简单模型SST-ANN

    

    环境监测对于我们理解气候变化、生物多样性丧失和污染等方面具有关键作用。来自传感器和卫星等数据源的大规模空间-时间数据的可用性使我们能够开发复杂的预测模型，并了解主要的驱动因素。但由于设备问题或维护问题，从传感器收集到的数据往往包含缺失值。缺失值很少同时发生，导致数据是多变量不对齐的稀疏时间序列数据。我们提出了两种模型，能够在处理缺失数据时自然地执行多变量空间-时间预测，而不需要插补。第一个模型是基于Transformer的模型，我们将其命名为SERT（来自Transformer的空间-时间编码表示）。第二个模型是一个更简单的模型，被命名为SST-ANN（稀疏空间-时间人工神经网络），能够提供可解释的结果。我们进行了大量实验...

    Environmental monitoring is crucial to our understanding of climate change, biodiversity loss and pollution. The availability of large-scale spatio-temporal data from sources such as sensors and satellites allows us to develop sophisticated models for forecasting and understanding key drivers. However, the data collected from sensors often contain missing values due to faulty equipment or maintenance issues. The missing values rarely occur simultaneously leading to data that are multivariate misaligned sparse time series. We propose two models that are capable of performing multivariate spatio-temporal forecasting while handling missing data naturally without the need for imputation. The first model is a transformer-based model, which we name SERT (Spatio-temporal Encoder Representations from Transformers). The second is a simpler model named SST-ANN (Sparse Spatio-Temporal Artificial Neural Network) which is capable of providing interpretable results. We conduct extensive experiments 
    
[^73]: 动态任务分配问题的建模和解决框架：行动演变Petri网格

    Action-Evolution Petri Nets: a Framework for Modeling and Solving Dynamic Task Assignment Problems. (arXiv:2306.02910v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.02910](http://arxiv.org/abs/2306.02910)

    本文提出了一种新的建模和解决动态任务分配问题的框架—行动演变Petri网格。它提供了一种统一的建模技术，可以表示动态任务分配问题的所有要素。而且，该模型是可执行的，并且可以用于强化学习，以学习接近最优的分配策略。

    

    动态任务分配涉及将到达的任务分配给有限的资源，以最小化分配的总成本。为了达到最优的任务分配，必须先对分配问题进行建模。虽然存在用于模拟、执行和解决问题不同方面的形式化方法，如马尔可夫决策过程和Petri网格，但不存在一种集成建模技术。为填补这一空白，本文提出了Action-Evolution Petri网格(A-E PN)作为一种建模和解决动态任务分配问题的框架。A-E PN提供了一种统一的建模技术，可以表示动态任务分配问题的所有要素。此外，A-E PN模型是可执行的，这意味着它们可以用于强化学习(RL)学习接近最优的分配策略，无需额外的建模工作。为了评估框架，我们定义了一个原型分配问题的分类法。

    Dynamic task assignment involves assigning arriving tasks to a limited number of resources in order to minimize the overall cost of the assignments. To achieve optimal task assignment, it is necessary to model the assignment problem first. While there exist separate formalisms, specifically Markov Decision Processes and (Colored) Petri Nets, to model, execute, and solve different aspects of the problem, there is no integrated modeling technique. To address this gap, this paper proposes Action-Evolution Petri Nets (A-E PN) as a framework for modeling and solving dynamic task assignment problems. A-E PN provides a unified modeling technique that can represent all elements of dynamic task assignment problems. Moreover, A-E PN models are executable, which means they can be used to learn close-to-optimal assignment policies through Reinforcement Learning (RL) without additional modeling effort. To evaluate the framework, we define a taxonomy of archetypical assignment problems. We show for 
    
[^74]: 一种基于相关性优化的风速预测深度学习新方法

    A Novel Correlation-optimized Deep Learning Method for Wind Speed Forecast. (arXiv:2306.01986v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.01986](http://arxiv.org/abs/2306.01986)

    该论文提出了一种基于深度知识学习的新方法，通过混合预训练和自编码器结构，同时利用基于相关性优化模型构建多层网络和序列到序列模型来提高风速预测的准确性和建模效果。

    

    随着风力发电装机率的增加，给全球能源系统带来了巨大的挑战。为了确保电力系统的可靠运行，需要准确预测风力涡轮机的风速和功率。目前，深度学习被逐渐应用于风速预测，但由于模型可解释性和硬件限制等问题，这些方法在实际应用中仍存在尴尬之处。因此，本文提出了一种新颖的基于深度知识学习的方法。该方法混合了预训练方法和自编码器结构，以提高深度知识学习框架的数据表现和建模。为了形成知识和对应吸收器，原始数据经由基于相关性的优化模型预处理，构建多层网络（知识），被序列到序列（Seq2Seq）模型吸收。

    The increasing installation rate of wind power poses great challenges to the global power system. In order to ensure the reliable operation of the power system, it is necessary to accurately forecast the wind speed and power of the wind turbines. At present, deep learning is progressively applied to the wind speed prediction. Nevertheless, the recent deep learning methods still reflect the embarrassment for practical applications due to model interpretability and hardware limitation. To this end, a novel deep knowledge-based learning method is proposed in this paper. The proposed method hybridizes pre-training method and auto-encoder structure to improve data representation and modeling of the deep knowledge-based learning framework. In order to form knowledge and corresponding absorbers, the original data is preprocessed by an optimization model based on correlation to construct multi-layer networks (knowledge) which are absorbed by sequence to sequence (Seq2Seq) models. Specifically,
    
[^75]: 更大、更好、更快：具有人类效率的人类级Atari游戏

    Bigger, Better, Faster: Human-level Atari with human-level efficiency. (arXiv:2305.19452v1 [cs.LG])

    [http://arxiv.org/abs/2305.19452](http://arxiv.org/abs/2305.19452)

    引入BBF基于价值函数的RL代理，在Atari 100K基准测试上实现超人类表现，具有人类效率，提出了在样本高效RL研究的ALE中更新目标的可能。

    

    我们引入了一个名为BBF的基于价值函数的强化学习代理来实现Atari 100K基准测试的超人类表现。BBF依靠神经网络的价值估计扩展以及其他设计选择，在遵循样本高效的情况下，能够实现这种扩展。我们对这些设计选择进行了广泛的分析并为未来的工作提供了洞见。最后，我们讨论了更新ALE上样本高效的RL研究目标的问题。我们将我们的代码和数据公开在https://github.com/google-research/google-research/tree/master/bigger_better_faster。

    We introduce a value-based RL agent, which we call BBF, that achieves super-human performance in the Atari 100K benchmark. BBF relies on scaling the neural networks used for value estimation, as well as a number of other design choices that enable this scaling in a sample-efficient manner. We conduct extensive analyses of these design choices and provide insights for future work. We end with a discussion about updating the goalposts for sample-efficient RL research on the ALE. We make our code and data publicly available at https://github.com/google-research/google-research/tree/master/bigger_better_faster.
    
[^76]: BigVideo:一个用于多模式机器翻译的大规模视频字幕翻译数据集

    BigVideo: A Large-scale Video Subtitle Translation Dataset for Multimodal Machine Translation. (arXiv:2305.18326v1 [cs.CV])

    [http://arxiv.org/abs/2305.18326](http://arxiv.org/abs/2305.18326)

    提出了一个大规模的视频字幕翻译数据集BigVideo， 集成了4.5 million句子对和9981小时视频，设计了有歧义和明确的测试集，引入了一种对比学习方法，实验结果表明，视觉信息可以提高NMT模型的BLEU、BLEURT和COMET得分，有助于消除歧义，数据集和翻译模型公开可用。

    

    我们提出了一个大规模的视频字幕翻译数据集BigVideo，以促进多模式机器翻译的研究。与广泛使用的How2和VaTeX数据集相比，BigVideo超过10倍，包括450万个句子对和9981小时的视频。我们还引入了两个有意设计的测试集来验证视觉信息的必要性：一个是一个有歧义词的不确定集合，另一个是在其中文本上下文对于翻译是自包含的明确集合。为了更好地建模文本和视频共享的共同语义，我们在跨模态编码器中引入了一种对比学习方法。在BigVideo上进行的广泛实验表明：a）视觉信息在歧义和明确的测试集上始终提高NMT模型的BLEU、BLEURT和COMET得分。b）视觉信息对于术语定位得分和人工评估而言，有助于消除歧义，与强文本基线相比。数据集和我们的翻译模型都是公开可用的。

    We present a large-scale video subtitle translation dataset, BigVideo, to facilitate the study of multi-modality machine translation. Compared with the widely used How2 and VaTeX datasets, BigVideo is more than 10 times larger, consisting of 4.5 million sentence pairs and 9,981 hours of videos. We also introduce two deliberately designed test sets to verify the necessity of visual information: Ambiguous with the presence of ambiguous words, and Unambiguous in which the text context is self-contained for translation. To better model the common semantics shared across texts and videos, we introduce a contrastive learning method in the cross-modal encoder. Extensive experiments on the BigVideo show that: a) Visual information consistently improves the NMT model in terms of BLEU, BLEURT, and COMET on both Ambiguous and Unambiguous test sets. b) Visual information helps disambiguation, compared to the strong text baseline on terminology-targeted scores and human evaluation. Dataset and our 
    
[^77]: COMCAT：高效压缩和自定义注意力视觉模型

    COMCAT: Towards Efficient Compression and Customization of Attention-Based Vision Models. (arXiv:2305.17235v1 [cs.CV])

    [http://arxiv.org/abs/2305.17235](http://arxiv.org/abs/2305.17235)

    本文提出了一种高效的 Vision Transformer 压缩方法，在多头注意力层上进行了新的探究，相比当前最先进的剪枝方法表现更优，能够在使用更少参数的情况下提高模型精度。

    

    基于注意力机制的视觉模型，例如Vision Transformer（ViT）及其变体，在各种计算机视觉任务中表现出有希望的性能。然而，这些新兴的架构存在着模型尺寸大和高计算成本的问题，需要高效的模型压缩解决方案。本文探究了一种高效的压缩方法，以丰富获取紧凑的基于注意力机制的视觉模型的工具集。基于对多头注意力层的新见解，我们开发出了一种高效的ViT压缩解决方案，其表现优于最先进的剪枝方法。在ImageNet上对DeiT-small和DeiT-base模型进行压缩，我们的提议方法即使使用更少的参数，仍然能够实现比现有方法高0.45％和0.76％的top-1精度。

    Attention-based vision models, such as Vision Transformer (ViT) and its variants, have shown promising performance in various computer vision tasks. However, these emerging architectures suffer from large model sizes and high computational costs, calling for efficient model compression solutions. To date, pruning ViTs has been well studied, while other compression strategies that have been widely applied in CNN compression, e.g., model factorization, is little explored in the context of ViT compression. This paper explores an efficient method for compressing vision transformers to enrich the toolset for obtaining compact attention-based vision models. Based on the new insight on the multi-head attention layer, we develop a highly efficient ViT compression solution, which outperforms the state-of-the-art pruning methods. For compressing DeiT-small and DeiT-base models on ImageNet, our proposed approach can achieve 0.45% and 0.76% higher top-1 accuracy even with fewer parameters. Our fin
    
[^78]: 随机神经网络中通过神经元多样性的演化学习行为

    Learning to Act through Evolution of Neural Diversity in Random Neural Networks. (arXiv:2305.15945v1 [cs.NE])

    [http://arxiv.org/abs/2305.15945](http://arxiv.org/abs/2305.15945)

    本文提出一种通过演化神经元中心参数来获得一组多样化的神经元，从而执行复杂计算的方法。研究显示，演化神经参数就足以使代理在不优化任何突触权重的情况下解决强化学习任务。

    

    生物神经系统由不同类别神经元组成的网络构成，它们是多样化、复杂的信息处理器。在大多数人工神经网络中，神经计算被抽象为一个激活函数，通常是在整个网络或同一层中的所有神经元之间共享的；神经网络的训练主要关注突触权重的优化。本文推荐通过优化神经元中心参数来获得一组多样化的神经元，从而执行复杂计算。我们展示了这种方法的潜力，证明仅通过演化神经参数即可使代理在不优化任何突触权重的情况下解决各种强化学习任务。虽然不致力于精确的生物模型，但通过比当前常见的做法更大程度地对神经元参数化，我们能够探讨随机神经网络中神经多样性提供的计算能力。这些结果引起了人们的极大兴趣。

    Biological nervous systems consist of networks of diverse, sophisticated information processors in the form of neurons of different classes. In most artificial neural networks (ANNs), neural computation is abstracted to an activation function that is usually shared between all neurons within a layer or even the whole network; training of ANNs focuses on synaptic optimization. In this paper, we propose the optimization of neuro-centric parameters to attain a set of diverse neurons that can perform complex computations. Demonstrating the promise of the approach, we show that evolving neural parameters alone allows agents to solve various reinforcement learning tasks without optimizing any synaptic weights. While not aiming to be an accurate biological model, parameterizing neurons to a larger degree than the current common practice, allows us to ask questions about the computational abilities afforded by neural diversity in random neural networks. The presented results open up interestin
    
[^79]: LaDI-VTON: 潜在扩散文本反演增强虚拟试穿

    LaDI-VTON: Latent Diffusion Textual-Inversion Enhanced Virtual Try-On. (arXiv:2305.13501v1 [cs.CV])

    [http://arxiv.org/abs/2305.13501](http://arxiv.org/abs/2305.13501)

    本文介绍了LaDI-VTON，一种利用潜在扩散模型和文本反演组件增强虚拟试穿任务的解决方案，该模型是第一个将这两种方法相结合的模型，能够高质量还原商店服装的细节。

    

    电子商务和元宇宙这两个不断发展变化的领域继续寻求创新方法来增强消费者体验。同时，最近扩散模型开发的进展使得生成网络能够创造出非常逼真的图像。在这种情况下，基于图像的虚拟试穿，就是生成一个目标模型穿着商店中的某件服装的新图片，尚未充分利用这些强大的生成解决方案的潜力。本研究介绍了LaDI-VTON，这是第一个潜在扩散文本反演增强的虚拟试穿模型。所提出的架构依赖于一个扩散模型，扩展了一个新的附加自动编码器模块，利用可学习的跳过连接来增强生成过程，保持模型的特征。为了有效地保持商店服装的质地和细节，我们提出了一个文本反演组件，可以将视觉特征映射到潜在扩散空间，实现服装的高质量细节还原。

    The rapidly evolving fields of e-commerce and metaverse continue to seek innovative approaches to enhance the consumer experience. At the same time, recent advancements in the development of diffusion models have enabled generative networks to create remarkably realistic images. In this context, image-based virtual try-on, which consists in generating a novel image of a target model wearing a given in-shop garment, has yet to capitalize on the potential of these powerful generative solutions. This work introduces LaDI-VTON, the first Latent Diffusion textual Inversion-enhanced model for the Virtual Try-ON task. The proposed architecture relies on a latent diffusion model extended with a novel additional autoencoder module that exploits learnable skip connections to enhance the generation process preserving the model's characteristics. To effectively maintain the texture and details of the in-shop garment, we propose a textual inversion component that can map the visual features of the 
    
[^80]: 遗传算法在组合优化问题中的应用

    The First Proven Performance Guarantees for the Non-Dominated Sorting Genetic Algorithm II (NSGA-II) on a Combinatorial Optimization Problem. (arXiv:2305.13459v1 [cs.AI])

    [http://arxiv.org/abs/2305.13459](http://arxiv.org/abs/2305.13459)

    本论文对遗传算法在经典优化问题中的应用进行了研究，首次提供了经过验证的NSGA-II性能保证。

    

    非支配排序遗传算法II（NSGA-II）是解决多目标优化问题的最突出算法之一。最近，该算法的第一个数学运行时间保证已被证明，但仅适用于合成基准问题。在本研究中，我们针对NP完全的双目最小生成树问题提供了首个经过验证的NSGA-II性能保证。具体而言，我们展示NSGA-II使用种群大小$N \ge 4((n-1) w_\max + 1)$，能够在望在$O(m^2 n w_\max \log(n w_\max))$次迭代中，计算出帕累托前沿的所有极端点，其中$n$是顶点数，$m$是边数，$w_\max$是问题实例中的最大边权。该结果通过数学手段证实了NSGA-II的良好效果并且表明可以将此算法用于解决经典优化问题。

    The Non-dominated Sorting Genetic Algorithm-II (NSGA-II) is one of the most prominent algorithms to solve multi-objective optimization problems. Recently, the first mathematical runtime guarantees have been obtained for this algorithm, however only for synthetic benchmark problems.  In this work, we give the first proven performance guarantees for a classic optimization problem, the NP-complete bi-objective minimum spanning tree problem. More specifically, we show that the NSGA-II with population size $N \ge 4((n-1) w_{\max} + 1)$ computes all extremal points of the Pareto front in an expected number of $O(m^2 n w_{\max} \log(n w_{\max}))$ iterations, where $n$ is the number of vertices, $m$ the number of edges, and $w_{\max}$ is the maximum edge weight in the problem instance. This result confirms, via mathematical means, the good performance of the NSGA-II observed empirically. It also shows that mathematical analyses of this algorithm are not only possible for synthetic benchmark pr
    
[^81]: 带有显式跨模态对齐的语音文本对话预训练用于口语对话理解

    Speech-Text Dialog Pre-training for Spoken Dialog Understanding with Explicit Cross-Modal Alignment. (arXiv:2305.11579v1 [cs.CL])

    [http://arxiv.org/abs/2305.11579](http://arxiv.org/abs/2305.11579)

    本文提出了SPECTRA语音文本对话预训练模型，应用了新的时间位置预测任务来捕捉语音文本对齐，同时将回答选择任务推广到服务于口语对话理解，用于丰富话语表示。

    

    最近，语音文本预训练方法在许多语音和自然语言处理任务中展现出了惊人的成功。然而，大多数先前的预训练模型通常针对一个或两个特定任务进行了定制，但未能征服各种语音文本任务。此外，现有的语音文本预训练方法未能探索对话中的情境信息以丰富话语表示。在本文中，我们提出了具有显式跨模态对齐的语音文本对话预训练模型SPECTRA，这是第一个语音文本对话预训练模型。具体而言，为了考虑语音模态的时间性，我们设计了一项新的时间位置预测任务来捕捉语音文本对齐。这种预训练任务旨在预测相应语音波形中每个文本单词的开始和结束时间。此外，为了学习口语对话的特征，我们将回答选择任务推广到服务于口语对话理解。

    Recently, speech-text pre-training methods have shown remarkable success in many speech and natural language processing tasks. However, most previous pre-trained models are usually tailored for one or two specific tasks, but fail to conquer a wide range of speech-text tasks. In addition, existing speech-text pre-training methods fail to explore the contextual information within a dialogue to enrich utterance representations. In this paper, we propose Speech-text dialog Pre-training for spoken dialog understanding with ExpliCiT cRoss-Modal Alignment (SPECTRA), which is the first-ever speech-text dialog pre-training model. Concretely, to consider the temporality of speech modality, we design a novel temporal position prediction task to capture the speech-text alignment. This pre-training task aims to predict the start and end time of each textual word in the corresponding speech waveform. In addition, to learn the characteristics of spoken dialogs, we generalize a response selection task
    
[^82]: 无需演示的自主增强学习：隐式双向课程法

    Demonstration-free Autonomous Reinforcement Learning via Implicit and Bidirectional Curriculum. (arXiv:2305.09943v1 [cs.LG])

    [http://arxiv.org/abs/2305.09943](http://arxiv.org/abs/2305.09943)

    本文提出了一种无需演示的自主强化学习算法（IBC），通过辅助代理和基于最优输运的双向目标课程，能够在无需先前数据依赖的情况下，实现从非周期性交互中学习，并在稀疏任务相关交互的环境中取得更好的表现。

    

    虽然强化学习在仅通过与环境交互来获得复杂技能方面取得了巨大成功，但它假设在每个周期结束时都可以轻易地回到初始状态。这种假设妨碍了具身代理的自主学习，因为在物理世界中进行重置需要耗费时间和繁琐的解决方案。因此，对于能够从非周期性交互中学习的自主强化学习（ARL）方法越来越受到关注。然而，现有的ARL方法受到其对先前数据的依赖的限制，无法在任务相关交互稀疏的环境中学习。相反，我们提出了一种通过隐式和双向课程的无演示ARL算法（IBC）。通过辅助代理以及基于最优输运的双向目标课程，我们的方法表现优于以前的方法，甚至比利用演示的方法还要好。

    While reinforcement learning (RL) has achieved great success in acquiring complex skills solely from environmental interactions, it assumes that resets to the initial state are readily available at the end of each episode. Such an assumption hinders the autonomous learning of embodied agents due to the time-consuming and cumbersome workarounds for resetting in the physical world. Hence, there has been a growing interest in autonomous RL (ARL) methods that are capable of learning from non-episodic interactions. However, existing works on ARL are limited by their reliance on prior data and are unable to learn in environments where task-relevant interactions are sparse. In contrast, we propose a demonstration-free ARL algorithm via Implicit and Bi-directional Curriculum (IBC). With an auxiliary agent that is conditionally activated upon learning progress and a bidirectional goal curriculum based on optimal transport, our method outperforms previous methods, even the ones that leverage dem
    
[^83]: 如何影响上下文范例在组合通用性中的作用？

    How Do In-Context Examples Affect Compositional Generalization?. (arXiv:2305.04835v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.04835](http://arxiv.org/abs/2305.04835)

    本文提出了CoFe测试套件来调查上下文组合泛化。实验结果表明，上下文示例应该在结构上与测试用例类似，相互之间应该不同，而且单独地简单。

    

    组合泛化——理解看不见的已知原始组合——是人类智能中的一个重要推理能力。AI社区主要通过在许多训练样本上微调神经网络来研究这种能力，然而还不清楚上下文学习——基于大型语言模型的主要少样本范式——是否展示组合泛化。在本文中，我们提出了CoFe，一个测试套件来调查上下文组合泛化。我们发现，组合泛化性能很容易受到上下文示例选择的影响，因此提出了研究问题：什么是在组合泛化中制作好的上下文示例的关键因素。我们研究了三个潜在因素：相似性、多样性和复杂性。我们的系统实验表明，在组合通用性中，上下文示例应该在结构上与测试用例类似，相互之间应该不同，而且单独地简单。

    Compositional generalization--understanding unseen combinations of seen primitives--is an essential reasoning capability in human intelligence. The AI community mainly studies this capability by fine-tuning neural networks on lots of training samples, while it is still unclear whether and how in-context learning--the prevailing few-shot paradigm based on large language models--exhibits compositional generalization. In this paper, we present CoFe, a test suite to investigate in-context compositional generalization. We find that the compositional generalization performance can be easily affected by the selection of in-context examples, thus raising the research question what the key factors are to make good in-context examples for compositional generalization. We study three potential factors: similarity, diversity and complexity. Our systematic experiments indicate that in-context examples should be structurally similar to the test case, diverse from each other, and individually simple.
    
[^84]: SEGA：用于图形对比学习的结构熵引导的锚点视图

    SEGA: Structural Entropy Guided Anchor View for Graph Contrastive Learning. (arXiv:2305.04501v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.04501](http://arxiv.org/abs/2305.04501)

    本文提出了一种名为SEGA的锚点视图用于图形对比学习，该视图通过结构熵引导以保持输入图的基本信息，达到了较好的表现。

    

    在对比学习中，“视图”的选择控制着表示捕获的信息并影响模型的性能。然而，主要的图像对比学习方法通常通过随机损坏或学习来产生视图，这可能导致关键信息的丢失和语义信息的变化。对于对比学习来说，保持输入图形的基本信息的锚点视图很少受到研究。在本文中，基于图信息瓶颈理论，我们推导了这个锚点视图的定义；换句话说，“具有输入图的基本信息的锚点视图应该具有最小的结构不确定性”。此外，我们通过结构熵实现了该锚点视图，称为SEGA，用于图对比学习。我们对各种基准测试进行了广泛的验证，包括在无监督、半监督和监督下的图分类。

    In contrastive learning, the choice of ``view'' controls the information that the representation captures and influences the performance of the model. However, leading graph contrastive learning methods generally produce views via random corruption or learning, which could lead to the loss of essential information and alteration of semantic information. An anchor view that maintains the essential information of input graphs for contrastive learning has been hardly investigated. In this paper, based on the theory of graph information bottleneck, we deduce the definition of this anchor view; put differently, \textit{the anchor view with essential information of input graph is supposed to have the minimal structural uncertainty}. Furthermore, guided by structural entropy, we implement the anchor view, termed \textbf{SEGA}, for graph contrastive learning. We extensively validate the proposed anchor view on various benchmarks regarding graph classification under unsupervised, semi-supervise
    
[^85]: 如何发挥大语言模型在少样本关系抽取中的能力？

    How to Unleash the Power of Large Language Models for Few-shot Relation Extraction?. (arXiv:2305.01555v1 [cs.CL])

    [http://arxiv.org/abs/2305.01555](http://arxiv.org/abs/2305.01555)

    本文通过使用GPT-3.5模型在少样本关系抽取中，实现在四个不同数据集上的新的最优性能，并提出了与任务相关的指导说明和约束模式下的数据生成方法。

    

    语言模型的扩展已经彻底改变了广泛的自然语言处理任务，但是使用大型语言模型进行少样本关系抽取还没有得到全面探索。本文通过详细实验，研究了使用GPT-3.5进行少样本关系抽取的基本方法——上下文学习和数据生成。为了增强少样本性能，我们进一步提出了与任务相关的指导说明和约束模式下的数据生成。我们观察到，在上下文学习的情况下，可以实现与以前的提示学习方法相当的性能，而使用大型语言模型的数据生成可以推动以前的解决方案以在四个广泛研究的关系抽取数据集上获得新的最先进的少样本结果。我们希望我们的工作可以激发未来对大型语言模型在少样本关系抽取中的能力的研究。代码可以在 \url{https://github.com/zjunlp/DeepKE/tree/main/example/llm} 中找到。

    Scaling language models have revolutionized widespread NLP tasks, yet little comprehensively explored few-shot relation extraction with large language models. In this paper, we investigate principal methodologies, in-context learning and data generation, for few-shot relation extraction via GPT-3.5 through exhaustive experiments. To enhance few-shot performance, we further propose task-related instructions and schema-constrained data generation. We observe that in-context learning can achieve performance on par with previous prompt learning approaches, and data generation with the large language model can boost previous solutions to obtain new state-of-the-art few-shot results on four widely-studied relation extraction datasets. We hope our work can inspire future research for the capabilities of large language models in few-shot relation extraction. Code is available in \url{https://github.com/zjunlp/DeepKE/tree/main/example/llm.
    
[^86]: Queer In AI:基于社区参与的AI案例研究

    Queer In AI: A Case Study in Community-Led Participatory AI. (arXiv:2303.16972v1 [cs.CY])

    [http://arxiv.org/abs/2303.16972](http://arxiv.org/abs/2303.16972)

    Queer in AI是一个基于社区参与的AI设计案例研究，通过拒绝等级制度而选择去中心化，在酷儿社群内部建立了援助和项目，同时努力改变酷儿社群外的参与者和机构。通过培育AI参与文化，欢迎和赋权边缘化参与者，为AI的参与式设计做出了更广泛的贡献。

    

    本文以Queer in AI为案例研究，探讨社区参与式AI设计的实践。我们分析了社区参与设计和交叉性原则如何在多年里在这个社群中萌芽和塑造了其项目。本文探讨了该组织在此过程中面临的不同挑战，审视了该组织在实现参与性与交叉性原则方面的不足，并评估了该组织的影响。Queer in AI通过拒绝等级制度而选择去中心化，通过将援助和项目建设建立在酷儿社群内部、由酷儿社群内成员来负责的方式，以及努力改变酷儿社群外的参与者和机构，为参与式方法的从业者和理论家提供了重要的经验和见解。最后，我们推测像Queer in AI这样的社区如何通过培育AI的参与文化，欢迎和赋权边缘化的参与者，批评贫瘠和剥削性表述等方面，为AI的参与式设计做出了更广泛的贡献。

    We present Queer in AI as a case study for community-led participatory design in AI. We examine how participatory design and intersectional tenets started and shaped this community's programs over the years. We discuss different challenges that emerged in the process, look at ways this organization has fallen short of operationalizing participatory and intersectional principles, and then assess the organization's impact. Queer in AI provides important lessons and insights for practitioners and theorists of participatory methods broadly through its rejection of hierarchy in favor of decentralization, success at building aid and programs by and for the queer community, and effort to change actors and institutions outside of the queer community. Finally, we theorize how communities like Queer in AI contribute to the participatory design in AI more broadly by fostering cultures of participation in AI, welcoming and empowering marginalized participants, critiquing poor or exploitative parti
    
[^87]: 通过争论交换实现交互式解释

    Interactive Explanations by Conflict Resolution via Argumentative Exchanges. (arXiv:2303.15022v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.15022](http://arxiv.org/abs/2303.15022)

    本文介绍了一种利用计算论证实现代理间冲突解决的交互式解释方法，适用于XAI，能够动态共享代理的信息以解决代理之间的冲突。

    

    随着可解释性人工智能（XAI）领域的成熟，要求为（人工智能模型的）输出提供交互式解释的呼声正在增加，但现有技术主要集中在静态解释上。本文着重介绍了将交互式解释框架化为代理之间的冲突解决，并借助计算论证来实现。具体而言，我们定义了Argumentative eXchanges（AXs），以在多代理系统中动态共享个体代理的双极论证框架中的信息，以解决代理之间的冲突。然后，我们将AXs部署在XAI设置中，其中机器和人类互动讨论机器的预测。我们确定并评估了几个理论属性，这些属性适用于XAI的AXs。最后，我们通过定义各种代理行为（例如，捕获机器中的反事实推理模式并突出其影响）来实例化XAI的AXs。

    As the field of explainable AI (XAI) is maturing, calls for interactive explanations for (the outputs of) AI models are growing, but the state-of-the-art predominantly focuses on static explanations. In this paper, we focus instead on interactive explanations framed as conflict resolution between agents (i.e. AI models and/or humans) by leveraging on computational argumentation. Specifically, we define Argumentative eXchanges (AXs) for dynamically sharing, in multi-agent systems, information harboured in individual agents' quantitative bipolar argumentation frameworks towards resolving conflicts amongst the agents. We then deploy AXs in the XAI setting in which a machine and a human interact about the machine's predictions. We identify and assess several theoretical properties characterising AXs that are suitable for XAI. Finally, we instantiate AXs for XAI by defining various agent behaviours, e.g. capturing counterfactual patterns of reasoning in machines and highlighting the effects
    
[^88]: 通过语言实现视觉抽象和推理技术

    Visual Abstraction and Reasoning through Language. (arXiv:2303.04091v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.04091](http://arxiv.org/abs/2303.04091)

    本论文提出了一种通过自然语言描述任务的通用框架来解决Abstraction and Reasoning Corpus（ARC）问题，虽然还没有在ARC上击败最先进的DSL模型，但我们展示了我们的方法具有巨大的潜力，可以解决先前未解决的任务。

    

    尽管人工智能（AI）模型在局限应用中已经达到了人类甚至超越人类的性能，但它们仍然难以展现更广泛和更灵活的智能。Abstraction and Reasoning Corpus（ARC）旨在评估AI系统与人类类似的认知能力。目前大多数方法依赖于精心设计的特定领域语言（DSL），用于暴力解决ARC中的任务。在这项工作中，我们提出了一个基于任务自然语言描述的通用框架来解决ARC问题。虽然还没有在ARC上击败最先进的DSL模型，但我们展示了我们的方法具有巨大的潜力，可以解决先前未解决的任务。

    While Artificial Intelligence (AI) models have achieved human or even superhuman performance in narrowly defined applications, they still struggle to show signs of broader and more flexible intelligence. The Abstraction and Reasoning Corpus (ARC), introduced by Fran\c{c}ois Chollet, aims to assess how close AI systems are to human-like cognitive abilities. Most current approaches rely on carefully handcrafted domain-specific languages (DSLs), which are used to brute-force solutions to the tasks present in ARC. In this work, we propose a general framework for solving ARC based on natural language descriptions of the tasks. While not yet beating state-of-the-art DSL models on ARC, we demonstrate the immense potential of our approach hinted at by the ability to solve previously unsolved tasks.
    
[^89]: ExplainableFold：利用可解释AI理解AlphaFold蛋白质结构预测

    ExplainableFold: Understanding AlphaFold Prediction with Explainable AI. (arXiv:2301.11765v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.11765](http://arxiv.org/abs/2301.11765)

    本文提出了可解释AI框架ExplainableFold，用于对AlphaFold蛋白质结构预测进行解释。提供了接近实验的对氨基酸对3D蛋白质结构影响的理解，有潜力促进对蛋白质结构的更深入理解。

    

    本文提出了ExplainableFold，一种用于蛋白质结构预测的可解释AI框架。尽管像AlphaFold这样的基于AI的方法在该领域取得了成功，但由于深度学习模型的黑盒特性，其预测的基本原因仍不清楚。为解决这个问题，我们提出了一个受生物学原理启发的反事实学习框架，用于生成反事实解释，从而实现一个干实验的方法。我们的实验结果表明，ExplainableFold能够生成高质量的AlphaFold预测解释，提供接近实验的对氨基酸对3D蛋白质结构影响的理解。这一框架有潜力促进对蛋白质结构的更深入理解。

    This paper presents ExplainableFold, an explainable AI framework for protein structure prediction. Despite the success of AI-based methods such as AlphaFold in this field, the underlying reasons for their predictions remain unclear due to the black-box nature of deep learning models. To address this, we propose a counterfactual learning framework inspired by biological principles to generate counterfactual explanations for protein structure prediction, enabling a dry-lab experimentation approach. Our experimental results demonstrate the ability of ExplainableFold to generate high-quality explanations for AlphaFold's predictions, providing near-experimental understanding of the effects of amino acids on 3D protein structure. This framework has the potential to facilitate a deeper understanding of protein structures.
    
[^90]: 基于拉普拉斯算子的深度选项方法用于时间扩展探索

    Deep Laplacian-based Options for Temporally-Extended Exploration. (arXiv:2301.11181v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11181](http://arxiv.org/abs/2301.11181)

    本文提出了一种基于深度学习的选项方法，以处理强化学习中的探索性动作选择问题，并利用最近的结果来拓展至可伸缩性更好的领域。

    

    在强化学习中，选择具有丰富经验流的探索性动作以进行更好学习是一项基本挑战。解决此问题的一种方法是根据特定的策略在一段时间内选择动作，也称为选项。最近一种用于获取此类探索选项的工作基于图拉普拉斯算子的本征函数。重要的是，直到现在，这些方法在图表领域中大多被限制在以下方面：(1)图拉普拉斯矩阵已给出或可以完全估计，(2)在该矩阵上进行特征分解是可计算的，(3)值函数可以被完全学习。此外，这些方法需要一个单独的选项发现阶段。这些假设在根本上是不可扩展的。在本文中，我们解决了这些限制，并展示了如何利用最近直接逼近拉普拉斯算子本征函数的结果，真正实现选项方法的可伸缩性。

    Selecting exploratory actions that generate a rich stream of experience for better learning is a fundamental challenge in reinforcement learning (RL). An approach to tackle this problem consists in selecting actions according to specific policies for an extended period of time, also known as options. A recent line of work to derive such exploratory options builds upon the eigenfunctions of the graph Laplacian. Importantly, until now these methods have been mostly limited to tabular domains where (1) the graph Laplacian matrix was either given or could be fully estimated, (2) performing eigendecomposition on this matrix was computationally tractable, and (3) value functions could be learned exactly. Additionally, these methods required a separate option discovery phase. These assumptions are fundamentally not scalable. In this paper we address these limitations and show how recent results for directly approximating the eigenfunctions of the Laplacian can be leveraged to truly scale up o
    
[^91]: 基于深度强化学习的多智能体巡逻问题的能量感知和容错方法

    An Energy-aware and Fault-tolerant Deep Reinforcement Learning based approach for Multi-agent Patrolling Problems. (arXiv:2212.08230v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.08230](http://arxiv.org/abs/2212.08230)

    本论文提出了一种基于无模型、深度多智能体强化学习的方法，以解决复杂巡逻环境中多个自主车辆协同执行任务的问题，该方法还考虑了能量消耗和容错等因素，以确保系统连续自适应地运行。

    

    自主车辆适用于连续区域巡逻问题。然而，由于众多原因，寻找最优巡逻策略可能具有挑战性。首先，巡逻环境通常较为复杂，可能会包含诸如风或景观等未知环境因素。其次，自主车辆可能会出现故障或硬件限制，例如电池寿命有限。重要的是，巡逻大区域通常需要多个智能体协同执行任务。在本文中，我们考虑了这些限制，并提出了一种基于无模型、深度多智能体强化学习的方法。在该方法中，智能体被训练在具有各种未知动态和因素的环境中进行巡逻。它们可以自动充电以支持连续集体巡逻。我们提出了一种分布式的同构多智能体架构，其中所有巡逻智能体基于其本地观察和共享通信在本地执行相同的策略。此外，所提出的方法考虑了能量消耗和容错等因素，以确保系统连续自适应地运行。

    Autonomous vehicles are suited for continuous area patrolling problems. However, finding an optimal patrolling strategy can be challenging for many reasons. Firstly, patrolling environments are often complex and can include unknown environmental factors, such as wind or landscape. Secondly, autonomous vehicles can have failures or hardware constraints, such as limited battery life. Importantly, patrolling large areas often requires multiple agents that need to collectively coordinate their actions. In this work, we consider these limitations and propose an approach based on model-free, deep multi-agent reinforcement learning. In this approach, the agents are trained to patrol an environment with various unknown dynamics and factors. They can automatically recharge themselves to support continuous collective patrolling. A distributed homogeneous multi-agent architecture is proposed, where all patrolling agents execute identical policies locally based on their local observations and shar
    
[^92]: Huber能量量化

    Huber-energy measure quantization. (arXiv:2212.08162v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2212.08162](http://arxiv.org/abs/2212.08162)

    该论文提出了一种Huber能量量化的算法，用于找到目标概率定律的最佳逼近，通过最小化原测度与量化版本之间的统计距离来实现。该算法已在多维高斯混合物、维纳空间魔方等几个数据库上进行了测试。

    

    我们描述了一种测量量化过程，即一种算法，它通过$Q$个狄拉克函数的总和（$Q$为量化参数），找到目标概率定律（更一般地，为有限变差测度）的最佳逼近。该过程通过将原测度与其量化版本之间的统计距离最小化来实现；该距离基于负定核构建，并且如果必要，可以实时计算并输入随机优化算法（如SGD，Adam等）。我们在理论上研究了最优测量量化器的存在的基本问题，并确定了需要保证合适行为的核属性。我们提出了两个最佳线性无偏（BLUE）估计器，用于平方统计距离，并将它们用于无偏程序HEMQ中，以找到最佳量化。我们在多维高斯混合物、维纳空间魔方等几个数据库上测试了HEMQ

    We describe a measure quantization procedure i.e., an algorithm which finds the best approximation of a target probability law (and more generally signed finite variation measure) by a sum of $Q$ Dirac masses ($Q$ being the quantization parameter). The procedure is implemented by minimizing the statistical distance between the original measure and its quantized version; the distance is built from a negative definite kernel and, if necessary, can be computed on the fly and feed to a stochastic optimization algorithm (such as SGD, Adam, ...). We investigate theoretically the fundamental questions of existence of the optimal measure quantizer and identify what are the required kernel properties that guarantee suitable behavior. We propose two best linear unbiased (BLUE) estimators for the squared statistical distance and use them in an unbiased procedure, called HEMQ, to find the optimal quantization. We test HEMQ on several databases: multi-dimensional Gaussian mixtures, Wiener space cub
    
[^93]: ViT-CX: 视觉Transformer的因果解释

    ViT-CX: Causal Explanation of Vision Transformers. (arXiv:2211.03064v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.03064](http://arxiv.org/abs/2211.03064)

    本文提出了一种新方法ViT-CX，通过基于补丁嵌入的因果影响来解释视觉Transformer(ViTs)，并考虑了ViTs的因果过决定性等特性，相比以前的方法更有意义且更忠实于模型。

    

    尽管视觉Transformer(ViTs)和可解释人工智能(XAI)很受欢迎，但目前为止只有少数专门为ViTs设计的解释方法。它们主要使用对补丁嵌入的[CLS]令牌的注意权重，通常会产生不令人满意的显著性图。本文提出了一种称为ViT-CX的解释ViTs的新方法。它基于补丁嵌入，而不是注重它们的注意力，以及它们对模型输出的因果影响。ViTs的其他特性，如因果过决定性，在ViT-CX的设计中也考虑了。实证结果表明，ViT-CX产生的显著性图更有意义，能更好地揭示预测的所有重要证据比以前的方法。ViT-CX产生的解释也显示出与模型显著更好的忠实性。代码和附录可在https://github.com/vaynexie/CausalX-ViT上找到。

    Despite the popularity of Vision Transformers (ViTs) and eXplainable AI (XAI), only a few explanation methods have been designed specially for ViTs thus far. They mostly use attention weights of the [CLS] token on patch embeddings and often produce unsatisfactory saliency maps. This paper proposes a novel method for explaining ViTs called ViT-CX. It is based on patch embeddings, rather than attentions paid to them, and their causal impacts on the model output. Other characteristics of ViTs such as causal overdetermination are also considered in the design of ViT-CX. The empirical results show that ViT-CX produces more meaningful saliency maps and does a better job revealing all important evidence for the predictions than previous methods. The explanation generated by ViT-CX also shows significantly better faithfulness to the model. The codes and appendix are available at https://github.com/vaynexie/CausalX-ViT.
    
[^94]: 无监督视频领域自适应动作识别：一个解缠视角

    Unsupervised Video Domain Adaptation for Action Recognition: A Disentanglement Perspective. (arXiv:2208.07365v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2208.07365](http://arxiv.org/abs/2208.07365)

    本文基于解缠视角处理视频领域无监督自适应问题，通过逐步解缠静态和动态信息并使用多种约束方法，有效地移除空间领域特定信息和减少时间领域差异，实验结果验证了该方法的有效性和优越性。

    

    无监督视频领域自适应是一项实践性而又具有挑战性的任务。本文首次从解缠视角入手处理该问题。我们的主要思路是通过解缠来分别处理空间和时间领域的差异。具体而言，我们考虑从包含静态信息的一组潜在因素和包含动态信息的另一组潜在因素中生成跨领域视频。我们开发了一个转移时序VAE（TranSVAE）框架来建模这种生成过程。为了更好地进行自适应，我们提出了几个约束潜在因素的目标。通过这些约束，静态领域特定信息的解缠可以轻松移除，通过对抗性学习从帧和视频层面进一步减少了时间差异。在UCF-HMDB、Jester和Epic-Kitchens数据集上进行的广泛实验验证了TranSVAE相比其他方法的有效性和优越性。

    Unsupervised video domain adaptation is a practical yet challenging task. In this work, for the first time, we tackle it from a disentanglement view. Our key idea is to handle the spatial and temporal domain divergence separately through disentanglement. Specifically, we consider the generation of cross-domain videos from two sets of latent factors, one encoding the static information and another encoding the dynamic information. A Transfer Sequential VAE (TranSVAE) framework is then developed to model such generation. To better serve for adaptation, we propose several objectives to constrain the latent factors. With these constraints, the spatial divergence can be readily removed by disentangling the static domain-specific information out, and the temporal divergence is further reduced from both frame- and video-levels through adversarial learning. Extensive experiments on the UCF-HMDB, Jester, and Epic-Kitchens datasets verify the effectiveness and superiority of TranSVAE compared wi
    
[^95]: 用于基准测试图神经网络的图生成模型

    Graph Generative Model for Benchmarking Graph Neural Networks. (arXiv:2207.04396v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.04396](http://arxiv.org/abs/2207.04396)

    本文提出了一个名为计算图转换器（CGT）的图生成模型，可通过保护数据隐私的方式学习和复制真实世界图的分布，从而生成有代表性的基准测试图，让GNNs在其上展示与源图相似的任务性能。

    

    随着图神经网络（GNN）领域的不断发展，对于训练和测试新的GNN模型以解决实际问题，需要使用大量的真实世界图数据集。然而，这样的数据集通常来自于在线、高度限制隐私的生态系统，这使得在这些数据集上进行研究和开发变得困难。为了解决这个问题，我们引入一种新颖的图生成模型，计算图转换器（CGT），该模型可通过保护数据隐私的方式学习和复制真实世界图的分布，从而生成有代表性的基准测试图，让GNNs在其上展示与源图相似的任务性能。

    As the field of Graph Neural Networks (GNN) continues to grow, it experiences a corresponding increase in the need for large, real-world datasets to train and test new GNN models on challenging, realistic problems. Unfortunately, such graph datasets are often generated from online, highly privacy-restricted ecosystems, which makes research and development on these datasets hard, if not impossible. This greatly reduces the amount of benchmark graphs available to researchers, causing the field to rely only on a handful of publicly-available datasets. To address this problem, we introduce a novel graph generative model, Computation Graph Transformer (CGT) that learns and reproduces the distribution of real-world graphs in a privacy-controlled way. More specifically, CGT (1) generates effective benchmark graphs on which GNNs show similar task performance as on the source graphs, (2) scales to process large-scale graphs, (3) incorporates off-the-shelf privacy modules to guarantee end-user p
    
[^96]: DGraph: 用于图异常检测的大规模金融数据集

    DGraph: A Large-Scale Financial Dataset for Graph Anomaly Detection. (arXiv:2207.03579v3 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2207.03579](http://arxiv.org/abs/2207.03579)

    本文介绍了一个名为DGraph的大规模金融数据集，提供了全面观察和广泛实验，揭示了异常节点和正常节点不同的特征和结构，标记和未标记节点都是检测欺诈者的必不可少的信息。

    

    图异常检测（GAD）由于其实用性和理论价值而成为近期热门研究领域。由于GAD强调应用和异常样本的罕见性，丰富其数据集的变化是基础性的工作。因此，本文提出了DGraph，它是金融领域中的实际动态图。DGraph克服了当前GAD数据集的许多限制。它包含约3百万个节点、4百万个动态边缘和1百万个地面真实节点。我们提供了对DGraph的全面观察，揭示了异常节点和正常节点通常具有不同的结构、邻居分布和时间动态。此外，它表明标记节点对于检测欺诈者也是必不可少的。此外，我们在DGraph上进行了广泛的实验。观察和实验表明，DGraph是推动GAD研究的有力工具，可以深入探索异常节点。

    Graph Anomaly Detection (GAD) has recently become a hot research spot due to its practicability and theoretical value. Since GAD emphasizes the application and the rarity of anomalous samples, enriching the varieties of its datasets is fundamental work. Thus, this paper present DGraph, a real-world dynamic graph in the finance domain. DGraph overcomes many limitations of current GAD datasets. It contains about 3M nodes, 4M dynamic edges, and 1M ground-truth nodes. We provide a comprehensive observation of DGraph, revealing that anomalous nodes and normal nodes generally have different structures, neighbor distribution, and temporal dynamics. Moreover, it suggests that unlabeled nodes are also essential for detecting fraudsters. Furthermore, we conduct extensive experiments on DGraph. Observation and experiments demonstrate that DGraph is propulsive to advance GAD research and enable in-depth exploration of anomalous nodes.
    
[^97]: 使用动态线性投影方法探索非线性模型的局部解释

    Exploring Local Explanations of Nonlinear Models Using Animated Linear Projections. (arXiv:2205.05359v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.05359](http://arxiv.org/abs/2205.05359)

    本文介绍了一种使用动态线性投影方法来分析流行的非线性模型的局部解释的方法，探索预测变量之间的交互如何影响变量重要性估计，这对于理解模型的可解释性非常有用。

    

    机器学习模型的预测能力日益增强，但与参数统计模型相比，其复杂性和可解释性下降。这种折衷导致了可解释的人工智能（XAI）的出现，提供了诸如局部解释（LE）和局部变量归因（LVA）之类的方法，以揭示模型如何使用预测变量进行预测。然而，LVA通常不能有效处理预测变量之间的关联。为了理解预测变量之间的交互如何影响变量重要性估计，可以将LVA转换为线性投影，并使用径向游览。这对于学习模型如何犯错，或异常值的影响，或观测值的聚类也非常有用。本文使用各种流行的非线性模型（包括随机森林和神经网络）的示例来说明这种方法。

    The increased predictive power of machine learning models comes at the cost of increased complexity and loss of interpretability, particularly in comparison to parametric statistical models. This trade-off has led to the emergence of eXplainable AI (XAI) which provides methods, such as local explanations (LEs) and local variable attributions (LVAs), to shed light on how a model use predictors to arrive at a prediction. These provide a point estimate of the linear variable importance in the vicinity of a single observation. However, LVAs tend not to effectively handle association between predictors. To understand how the interaction between predictors affects the variable importance estimate, we can convert LVAs into linear projections and use the radial tour. This is also useful for learning how a model has made a mistake, or the effect of outliers, or the clustering of observations. The approach is illustrated with examples from categorical (penguin species, chocolate types) and quant
    
[^98]: 在多臂老虎机中实现后悔最小化和最佳臂识别的帕累托前沿

    Achieving the Pareto Frontier of Regret Minimization and Best Arm Identification in Multi-Armed Bandits. (arXiv:2110.08627v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.08627](http://arxiv.org/abs/2110.08627)

    本文研究了多臂老虎机中后悔最小化和最佳臂识别的帕累托前沿,设计了BoBW-lil'UCB $(\gamma)$算法，证明了没有算法能同时为RM和BAI目标表现最佳，BoBW-lil'UCB $(\gamma)$可在不同的$\gamma$值下实现RM或BAI的最优性能。

    

    本文研究了多臂老虎机中两个典型目标的帕累托前沿，即固定时间内的后悔最小化和最佳臂识别。平衡探索和利用对于后悔最小化和最佳臂识别都至关重要，但对于后者来说，探索更关键。本文设计和分析了BoBW-lil'UCB $(\gamma)$算法，通过建立基于BAI失败概率的可达到遗憾下限，我们展示了(i)没有算法能同时为RM和BAI目标表现最佳，(ii)BoBW-lil'UCB $(\gamma)$可在不同的$\gamma$值下实现RM或BAI的最优性能。我们的工作通过展示先前作品中的常数如何依赖某些难度参数，更精确地阐明了此类算法中的权衡。最后，我们展示BoBW-lil'UCB优于其最接近的竞争者UCB$_\alpha$。

    We study the Pareto frontier of two archetypal objectives in multi-armed bandits, namely, regret minimization (RM) and best arm identification (BAI) with a fixed horizon. It is folklore that the balance between exploitation and exploration is crucial for both RM and BAI, but exploration is more critical in achieving the optimal performance for the latter objective. To this end, we design and analyze the BoBW-lil'UCB$(\gamma)$ algorithm. Complementarily, by establishing lower bounds on the regret achievable by any algorithm with a given BAI failure probability, we show that (i) no algorithm can simultaneously perform optimally for both the RM and BAI objectives, and (ii) BoBW-lil'UCB$(\gamma)$ achieves order-wise optimal performance for RM or BAI under different values of $\gamma$. Our work elucidates the trade-off more precisely by showing how the constants in previous works depend on certain hardness parameters. Finally, we show that BoBW-lil'UCB outperforms a close competitor UCB$_\a
    
[^99]: 机器符号学

    Machine Semiotics. (arXiv:2008.10522v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2008.10522](http://arxiv.org/abs/2008.10522)

    本文提出机器符号学的思想，即机器不需要理解话语的传统意义，而是能够以格里斯语用学的方式绘制会话蕴涵说明。这个过程可以形式化为话语-意义对（UMP）的强化学习。

    

    认识到人类和机器符号学的基本差异为克服当前语音辅助设备的缺点提供了可能。对于机器而言，（人类）话语的意义由其自身的行动范围定义。因此，机器不需要理解话语的传统意义。相反，它们以（新）格里斯语用学的意义绘制会话蕴涵说明。对于语音辅助设备而言，学习人类话语的机器特定含义，即通过词汇化的尝试和误差将会话蕴涵说明变成传统化的含义，似乎已经足够了。通过一个相当琐碎的认知加热设备的例子，我们展示了，基于动态语义学，这个过程可以形式化为话语-意义对（UMP）的强化学习。

    Recognizing a basic difference between the semiotics of humans and machines presents a possibility to overcome the shortcomings of current speech assistive devices. For the machine, the meaning of a (human) utterance is defined by its own scope of actions. Machines, thus, do not need to understand the conventional meaning of an utterance. Rather, they draw conversational implicatures in the sense of (neo-)Gricean pragmatics. For speech assistive devices, the learning of machine-specific meanings of human utterances, i.e. the fossilization of conversational implicatures into conventionalized ones by trial and error through lexicalization appears to be sufficient. Using the quite trivial example of a cognitive heating device, we show that - based on dynamic semantics - this process can be formalized as the reinforcement learning of utterance-meaning pairs (UMP).
    

