# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Where to Move Next: Zero-shot Generalization of LLMs for Next POI Recommendation](https://arxiv.org/abs/2404.01855) | 设计了新颖的提示策略和进行了实证研究以探索LLMs用于下一个POI推荐的零样本泛化能力 |
| [^2] | [Aurora-M: The First Open Source Multilingual Language Model Red-teamed according to the U.S. Executive Order](https://arxiv.org/abs/2404.00399) | Aurora-M 是第一个根据美国行政命令进行红队测试的开源多语言模型，通过在英语、芬兰语、印地语、日语、越南语和代码上训练，不断预训练，包括了人工审核的安全说明，总训练 token 数超过 2 万亿个 |
| [^3] | [ReflectSumm: A Benchmark for Course Reflection Summarization](https://arxiv.org/abs/2403.19012) | ReflectSumm是一个旨在总结学生反思性写作的数据集，可以帮助开发和评估针对现实场景的新型摘要技术，为进一步研究提供了基准。 |
| [^4] | [Convergence of a model-free entropy-regularized inverse reinforcement learning algorithm](https://arxiv.org/abs/2403.16829) | 提出一个无模型的算法来解决熵正则化的逆强化学习问题，该算法能够使用有限样本恢复出专家表现最佳的奖励，并且最终得到的最优策略与专家策略非常接近。 |
| [^5] | [WangchanLion and WangchanX MRC Eval](https://arxiv.org/abs/2403.16127) | WangchanLion是一个专注于泰语机器阅读理解的指令微调模型，在0-shot和1-shot设置下能够理解上下文并产生与参考答案一致的回答，同时提出了新的评估方案。 |
| [^6] | [Non-negative Contrastive Learning](https://arxiv.org/abs/2403.12459) | 非负对比学习(NCL)是对非负矩阵分解(NMF)的重新演绎，通过对特征施加非负约束来获得可解释的特征，保留了NMF的可解释属性，从而得到比标准对比学习(CL)更稀疏和解耦的表示 |
| [^7] | [Problem space structural adversarial attacks for Network Intrusion Detection Systems based on Graph Neural Networks](https://arxiv.org/abs/2403.11830) | 本文首次提出了针对基于图神经网络的网络入侵检测系统的形式化对抗攻击，并模拟了攻击者在现实场景中执行可行结构攻击所需考虑的问题空间约束。 |
| [^8] | [Improving Dialogue Agents by Decomposing One Global Explicit Annotation with Local Implicit Multimodal Feedback](https://arxiv.org/abs/2403.11330) | 通过将全局明确标注拆解成本地隐式多模态反馈，提出了一种改进对话代理的方法，并在各种对话度量方面展现出一致的改进 |
| [^9] | [Enhancing Trust in Autonomous Agents: An Architecture for Accountability and Explainability through Blockchain and Large Language Models](https://arxiv.org/abs/2403.09567) | 通过区块链和大型语言模型实现责任和可解释性的架构，提高自主代理的信任和安全性，增强代理与用户之间的沟通效果。 |
| [^10] | [Representing Anatomical Trees by Denoising Diffusion of Implicit Neural Fields](https://arxiv.org/abs/2403.08974) | 提出了一种使用隐式神经表示和去噪扩散来准确捕捉解剖树几何和拓扑结构的新方法 |
| [^11] | [DAM: Dynamic Adapter Merging for Continual Video QA Learning](https://arxiv.org/abs/2403.08755) | 提出了一种用于持续视频问答学习的动态适配器合并方法DAM，能够减轻灾难性遗忘、有效适应不断到来的数据集、处理未知数据集输入，并允许在类似数据集领域之间共享知识。 |
| [^12] | [$\widetilde{O}(T^{-1})$ Convergence to (Coarse) Correlated Equilibria in Full-Information General-Sum Markov Games](https://arxiv.org/abs/2403.07890) | 本研究通过使用乐观的前瞻性领导者算法（OFTRL）和适当的数值更新程序，在全信息一般和马尔可夫博弈中找到了$\widetilde{O}(T^{-1})$-approximate（粗糙）相关均衡，这在$T$次迭代内得以实现。 |
| [^13] | [The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning](https://arxiv.org/abs/2403.03218) | WMDP基准是一个公开发布的数据集，包含4157个多项选择问题，用作生物安全、网络安全和化学安全危险知识的代理测量。 |
| [^14] | [NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models](https://arxiv.org/abs/2403.03100) | NaturalSpeech 3利用分解设计的扩散模型实现零-shot方式生成自然语音 |
| [^15] | [Seeing is Believing: Mitigating Hallucination in Large Vision-Language Models via CLIP-Guided Decoding](https://arxiv.org/abs/2402.15300) | CLIP相似性作为更强大和更稳健的幻觉指标，研究提出了CLIP引导解码（CGD）方法，在大型视觉-语言模型中有效减少对象幻觉。 |
| [^16] | [MPIrigen: MPI Code Generation through Domain-Specific Language Models](https://arxiv.org/abs/2402.09126) | 本文研究了使用领域特定语言模型生成MPI代码的性能，并提出了使用预训练模型MonoCoder进行MPI-based程序生成的方法。 |
| [^17] | [Are Semi-Dense Detector-Free Methods Good at Matching Local Features?](https://arxiv.org/abs/2402.08671) | 本研究首次尝试研究半稠密无检测器方法（SDF）建立对应关系能力和估计位姿质量之间的联系。作者提出了一种新颖的图像匹配架构SAM，并发现SAM在位姿估计方面表现优秀，而SDF方法在匹配准确度方面表现更好。作者建议将匹配准确度的计算限制在纹理区域。 |
| [^18] | [You Only Need One Color Space: An Efficient Network for Low-light Image Enhancement](https://arxiv.org/abs/2402.05809) | 本文提出了一种用于低光图像增强的高效网络，通过引入可训练的水平/垂直强度（HVI）颜色空间来解耦亮度和颜色，并设计了颜色和强度解耦网络（CIDNet）以改善增强过程中的稳定性。结果显示，该方法可以减少增强图像中的颜色和亮度伪影。 |
| [^19] | [Beyond Text: Improving LLM's Decision Making for Robot Navigation via Vocal Cues](https://arxiv.org/abs/2402.03494) | 本论文通过将语音转录和语音非言语特征整合到LLM决策中来改善机器人导航中的决策能力，超越了仅使用文字的限制。 |
| [^20] | [SWEA: Changing Factual Knowledge in Large Language Models via Subject Word Embedding Altering](https://arxiv.org/abs/2401.17809) | 提出了一种主题词嵌入修改框架（SWEA），通过在推理阶段修改主题的表示来编辑知识，保护模型的原始权重，避免不可逆的损害和额外的推理开销。 |
| [^21] | [RMS: Redundancy-Minimizing Point Cloud Sampling for Real-Time Pose Estimation](https://arxiv.org/abs/2312.07337) | 提出了一种名为RMS的点云采样方法，通过最小化冗余优化了3D点云的翻译空间可观测性，解决了移动机器人状态估计中潜在的问题。 |
| [^22] | [VT-Former: A Transformer-based Vehicle Trajectory Prediction Approach For Intelligent Highway Transportation Systems](https://arxiv.org/abs/2311.06623) | 本文介绍了一种基于Transformer的车辆轨迹预测方法，名为VT-Former，在智能公路交通系统中具有重要的应用价值。 |
| [^23] | [PPNet: A Novel Neural Network Structure for End-to-End Near-Optimal Path Planning.](http://arxiv.org/abs/2401.09819) | PPNet是一种新颖的神经网络结构，用于解决端到端近似最优路径规划问题。通过将路径规划问题分为两个子问题，并使用两级级联神经网络进行求解，同时引入了一种高效的数据生成方法EDaGe-PP。实验结果表明，PPNet在计算时间和成功率方面比其他方法有显著提升。 |
| [^24] | [Hidden Flaws Behind Expert-Level Accuracy of GPT-4 Vision in Medicine.](http://arxiv.org/abs/2401.08396) | GPT-4 Vision在医学领域中具有专家级准确度，但在图像理解方面存在缺陷。 |
| [^25] | [Can ChatGPT Rival Neural Machine Translation? A Comparative Study.](http://arxiv.org/abs/2401.05176) | 本文比较了对话式语言模型ChatGPT和神经机器翻译引擎在将中文外交文本翻译为英文方面的能力，发现自动评价指标和人工评估方法之间存在差异。 |
| [^26] | [Improving Intrinsic Exploration by Creating Stationary Objectives.](http://arxiv.org/abs/2310.18144) | 该论文提出了一个新的方法：通过创建固定目标，将原始的非固定奖励转化为固定奖励，从而改善了强化学习中的内在探索。 |
| [^27] | [One-Shot Sensitivity-Aware Mixed Sparsity Pruning for Large Language Models.](http://arxiv.org/abs/2310.09499) | 我们提出了一种基于敏感度感知混合稀疏化剪枝的方法，可以在不重新训练的情况下将大型语言模型剪枝至至少50％的稀疏性，同时保持稀疏性水平和减少剪枝引起的误差。此外，该方法还与量化兼容，可以进一步压缩语言模型。 |
| [^28] | [VAL: Interactive Task Learning with GPT Dialog Parsing.](http://arxiv.org/abs/2310.01627) | VAL是一种交互式任务学习系统，通过结合大型语言模型（LLM）和符号集成的理念，实现了从自然语言中进行交互式学习的分层任务知识的获取。所获得的知识可解释并能够推广到执行新任务。在视频游戏环境中的用户交互实验表明，VAL能够从有限的指令中成功学到有效的任务知识。 |
| [^29] | [Neuro-Inspired Hierarchical Multimodal Learning.](http://arxiv.org/abs/2309.15877) | 这项研究提出了一种神经启发的分层多模态学习方法，利用信息瓶颈理论构建了一种有效且紧凑的信息流，实现了对真实世界的全面和准确的感知。 |
| [^30] | [Masked Transformer for Electrocardiogram Classification.](http://arxiv.org/abs/2309.07136) | 提出了一种基于掩码Transformer的ECG分类方法，命名为MTECG，扩展了掩码自动编码器在ECG时间序列上的应用，该方法在广泛的掩码比例下表现稳定良好，并进行了消融实验验证了重构目标的波动性、训练计划长度、逐层学习率衰减和DropPath率的重要性。 |
| [^31] | [MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training.](http://arxiv.org/abs/2306.00107) | 提出了一个带有大规模自监督训练的音乐理解模型MERT，利用了教师模型并采用了一种优于传统的语音和音频方法的组合方式。 |
| [^32] | [On Dynamic Program Decompositions of Static Risk Measures.](http://arxiv.org/abs/2304.12477) | 本文证明了现有的CVaR和EVaR风险度量动态分解是真实风险值的严格高估计，然而VaR存在精确的动态分解。 |
| [^33] | [RETVec: Resilient and Efficient Text Vectorizer.](http://arxiv.org/abs/2302.09207) | RETVec是一种高效、弹性和多语言的文本向量化器，通过采用新颖的字符编码和对抗攻击鲁棒的嵌入模型，实现了对拼写错误和对抗性攻击的更好适应性。与其他向量化器和词嵌入模型相比，RETVec在各种模型架构和数据集上表现出竞争力和显著的弹性。 |

# 详细

[^1]: 下一个去哪里：基于零样本泛化的LLMs用于下一个POI推荐

    Where to Move Next: Zero-shot Generalization of LLMs for Next POI Recommendation

    [https://arxiv.org/abs/2404.01855](https://arxiv.org/abs/2404.01855)

    设计了新颖的提示策略和进行了实证研究以探索LLMs用于下一个POI推荐的零样本泛化能力

    

    下一个兴趣点（POI）推荐为用户提供了探索周边环境的宝贵建议。现有研究依赖于从大规模用户签到数据构建推荐模型，这是任务特定的，并需要大量的计算资源。最近，预训练的大型语言模型（LLMs）在各种NLP任务中取得了显著进展，并且已经被研究用于推荐场景。然而，LLMs的泛化能力在解决下一个POI推荐问题时仍未被探索，其中应提取用户的地理移动模式。虽然有研究利用LLMs进行下一个项目推荐，但它们未能考虑地理影响和顺序转换。因此，它们无法有效解决下一个POI推荐任务。为此，我们设计了新颖的提示策略，并进行了实证研究以验证

    arXiv:2404.01855v1 Announce Type: cross  Abstract: Next Point-of-interest (POI) recommendation provides valuable suggestions for users to explore their surrounding environment. Existing studies rely on building recommendation models from large-scale users' check-in data, which is task-specific and needs extensive computational resources. Recently, the pretrained large language models (LLMs) have achieved significant advancements in various NLP tasks and have also been investigated for recommendation scenarios. However, the generalization abilities of LLMs still are unexplored to address the next POI recommendations, where users' geographical movement patterns should be extracted. Although there are studies that leverage LLMs for next-item recommendations, they fail to consider the geographical influence and sequential transitions. Hence, they cannot effectively solve the next POI recommendation task. To this end, we design novel prompting strategies and conduct empirical studies to ass
    
[^2]: Aurora-M: 根据美国行政命令，第一个开源的多语言语言模型进行了红队测试

    Aurora-M: The First Open Source Multilingual Language Model Red-teamed according to the U.S. Executive Order

    [https://arxiv.org/abs/2404.00399](https://arxiv.org/abs/2404.00399)

    Aurora-M 是第一个根据美国行政命令进行红队测试的开源多语言模型，通过在英语、芬兰语、印地语、日语、越南语和代码上训练，不断预训练，包括了人工审核的安全说明，总训练 token 数超过 2 万亿个

    

    预训练语言模型支持多种人工智能应用，但是它们在训练时高昂的计算成本限制了可访问性。BLOOM 和 StarCoder 等倡议旨在使预训练模型对于协作社区开发更具民主性。然而，目前存在的模型面临一些挑战：多语言能力有限，持续的预训练会导致灾难性遗忘，而从头开始预训练又具有高昂的计算成本，并且需要遵守人工智能安全和发展法律。本文介绍了 Aurora-M，一个包含 15B 参数的多语言开源模型，训练语言包括英语、芬兰语、印地语、日语、越南语和代码。Aurora-M 不断从 StarCoderPlus 上预训练，额外训练了 4350 亿个 token，总训练 token 数超过了 2 万亿个。它是第一个在人工审核的安全说明上进行微调的开源多语言模型，使其开发与传统

    arXiv:2404.00399v1 Announce Type: cross  Abstract: Pretrained language models underpin several AI applications, but their high computational cost for training limits accessibility. Initiatives such as BLOOM and StarCoder aim to democratize access to pretrained models for collaborative community development. However, such existing models face challenges: limited multilingual capabilities, continual pretraining causing catastrophic forgetting, whereas pretraining from scratch is computationally expensive, and compliance with AI safety and development laws. This paper presents Aurora-M, a 15B parameter multilingual open-source model trained on English, Finnish, Hindi, Japanese, Vietnamese, and code. Continually pretrained from StarCoderPlus on 435 billion additional tokens, Aurora-M surpasses 2 trillion tokens in total training token count. It is the first open-source multilingual model fine-tuned on human-reviewed safety instructions, thus aligning its development not only with conventio
    
[^3]: ReflectSumm: 一个用于课程反思摘要的基准数据集

    ReflectSumm: A Benchmark for Course Reflection Summarization

    [https://arxiv.org/abs/2403.19012](https://arxiv.org/abs/2403.19012)

    ReflectSumm是一个旨在总结学生反思性写作的数据集，可以帮助开发和评估针对现实场景的新型摘要技术，为进一步研究提供了基准。

    

    这篇论文介绍了ReflectSumm，一个专门设计用于总结学生反思性写作的新型摘要数据集。ReflectSumm的目标是促进开发和评估针对现实场景的新型摘要技术，这些场景具有少量训练数据，%具有潜在在意见总结领域和特别是教育领域中的影响。该数据集涵盖了各种摘要任务，并包括全面的元数据，可以探索各种研究问题并支持不同的应用。为展示其效用，我们使用多个最先进的基准进行了广泛评估。结果为促进这一领域的进一步研究提供了基准。

    arXiv:2403.19012v1 Announce Type: cross  Abstract: This paper introduces ReflectSumm, a novel summarization dataset specifically designed for summarizing students' reflective writing. The goal of ReflectSumm is to facilitate developing and evaluating novel summarization techniques tailored to real-world scenarios with little training data, %practical tasks with potential implications in the opinion summarization domain in general and the educational domain in particular. The dataset encompasses a diverse range of summarization tasks and includes comprehensive metadata, enabling the exploration of various research questions and supporting different applications. To showcase its utility, we conducted extensive evaluations using multiple state-of-the-art baselines. The results provide benchmarks for facilitating further research in this area.
    
[^4]: 一个无模型的熵正则化逆强化学习算法的收敛性

    Convergence of a model-free entropy-regularized inverse reinforcement learning algorithm

    [https://arxiv.org/abs/2403.16829](https://arxiv.org/abs/2403.16829)

    提出一个无模型的算法来解决熵正则化的逆强化学习问题，该算法能够使用有限样本恢复出专家表现最佳的奖励，并且最终得到的最优策略与专家策略非常接近。

    

    在给定一组专家演示数据集的情况下，逆强化学习旨在恢复一个专家表现最佳的奖励。本文提出了一个无模型的算法来解决熵正则化逆强化学习问题。具体而言，我们采用随机梯度下降更新奖励，采用随机软策略迭代更新策略。假设可以访问一个生成模型，我们证明了我们的算法能够保证使用$\mathcal{O}(1/\varepsilon^{2})$个马尔可夫决策过程（MDP）样本恢复出一个使专家表现最佳的奖励。此外，通过$\mathcal{O}(1/\varepsilon^{4})$个样本，我们证明了与恢复奖励对应的最优策略在总变差距离上与专家策略$\varepsilon$-接近。

    arXiv:2403.16829v1 Announce Type: cross  Abstract: Given a dataset of expert demonstrations, inverse reinforcement learning (IRL) aims to recover a reward for which the expert is optimal. This work proposes a model-free algorithm to solve entropy-regularized IRL problem. In particular, we employ a stochastic gradient descent update for the reward and a stochastic soft policy iteration update for the policy. Assuming access to a generative model, we prove that our algorithm is guaranteed to recover a reward for which the expert is $\varepsilon$-optimal using $\mathcal{O}(1/\varepsilon^{2})$ samples of the Markov decision process (MDP). Furthermore, with $\mathcal{O}(1/\varepsilon^{4})$ samples we prove that the optimal policy corresponding to the recovered reward is $\varepsilon$-close to the expert policy in total variation distance.
    
[^5]: WangchanLion与WangchanX MRC评估

    WangchanLion and WangchanX MRC Eval

    [https://arxiv.org/abs/2403.16127](https://arxiv.org/abs/2403.16127)

    WangchanLion是一个专注于泰语机器阅读理解的指令微调模型，在0-shot和1-shot设置下能够理解上下文并产生与参考答案一致的回答，同时提出了新的评估方案。

    

    本技术报告描述了WangchanLion的开发过程，这是一个专注于泰语机器阅读理解（MRC）的指令微调模型。我们的模型基于SEA-LION和一系列指令跟随数据集。为了促进开放研究和可重复性，我们公开发布了所有训练数据、代码和最终模型权重，采用Apache-2许可证。为了评估上下文理解能力，我们使用两个泰语MRC数据集XQuAD和Iapp_wiki_qa_squad进行了广泛的实验研究。实验结果表明，在0-shot和1-shot设置下，模型能够理解上下文并产生与参考答案一致的回答。此外，我们的评估超越了传统的MRC。我们提出了一个新的评估方案，评估答案的正确性、帮助性、简洁性和上下文性。评估结果揭示了我们如何改进模型的见解。

    arXiv:2403.16127v1 Announce Type: cross  Abstract: This technical report describes the development of WangchanLion, an instruction fine-tuned model focusing on Machine Reading Comprehension (MRC) in the Thai language. Our model is based on SEA-LION and a collection of instruction following datasets. To promote open research and reproducibility, we publically release all training data, code, and the final model weights under the Apache-2 license. To assess the contextual understanding capability, we conducted extensive experimental studies using two Thai MRC datasets, XQuAD and Iapp_wiki_qa_squad. Experimental results demonstrate the model's ability to comprehend the context and produce an answer faithful to the reference one in 0-shot and 1-shot settings. In addition, our evaluation goes beyond the traditional MRC. We propose a new evaluation scheme assessing the answer's correctness, helpfulness, conciseness, and contextuality. Evaluation results provide insight into how we can improv
    
[^6]: 非负对比学习

    Non-negative Contrastive Learning

    [https://arxiv.org/abs/2403.12459](https://arxiv.org/abs/2403.12459)

    非负对比学习(NCL)是对非负矩阵分解(NMF)的重新演绎，通过对特征施加非负约束来获得可解释的特征，保留了NMF的可解释属性，从而得到比标准对比学习(CL)更稀疏和解耦的表示

    

    深度表示在以黑盒方式转移到下游任务时表现出了良好的性能。然而，它们固有的不可解释性仍然是一个重大挑战，因为这些特征通常对人类理解而言是不透明的。在本文中，我们提出了非负对比学习（NCL），这是对非负矩阵分解（NMF）的复兴，旨在得出可解释的特征。NCL的力量在于强制将非负约束应用于特征，这让人想起NMF能够提取与样本集群紧密对齐的特征的能力。NCL不仅在数学上与NMF目标很好地对齐，而且保留了NMF的可解释属性，使得与标准对比学习（CL）相比，得到了更加稀疏和解耦的表示。从理论上，我们为NCL的可识别性和下游泛化性能提供了保证。从经验上看，我们展示了这些

    arXiv:2403.12459v1 Announce Type: cross  Abstract: Deep representations have shown promising performance when transferred to downstream tasks in a black-box manner. Yet, their inherent lack of interpretability remains a significant challenge, as these features are often opaque to human understanding. In this paper, we propose Non-negative Contrastive Learning (NCL), a renaissance of Non-negative Matrix Factorization (NMF) aimed at deriving interpretable features. The power of NCL lies in its enforcement of non-negativity constraints on features, reminiscent of NMF's capability to extract features that align closely with sample clusters. NCL not only aligns mathematically well with an NMF objective but also preserves NMF's interpretability attributes, resulting in a more sparse and disentangled representation compared to standard contrastive learning (CL). Theoretically, we establish guarantees on the identifiability and downstream generalization of NCL. Empirically, we show that these 
    
[^7]: 基于图神经网络的网络入侵检测系统的问题空间结构对抗攻击

    Problem space structural adversarial attacks for Network Intrusion Detection Systems based on Graph Neural Networks

    [https://arxiv.org/abs/2403.11830](https://arxiv.org/abs/2403.11830)

    本文首次提出了针对基于图神经网络的网络入侵检测系统的形式化对抗攻击，并模拟了攻击者在现实场景中执行可行结构攻击所需考虑的问题空间约束。

    

    机器学习算法已经越来越受欢迎地用于支持网络入侵检测系统（NIDS）。然而，大量研究已经表明它们对于对抗性攻击的脆弱性，这些攻击涉及对模型输入的微小扰动，旨在危害其性能。最近的提议有效地利用图神经网络（GNN）来产生基于入侵展示的结构模式的预测，以增强检测的稳健性。然而，采用基于GNN的NIDS引入了新类型的风险。本文首次提出了专门针对GNN在网络入侵检测中形成对抗攻击的形式化。此外，我们概述并模拟了攻击者需要考虑的问题空间约束，以在现实场景中执行可行的结构攻击。作为最终贡献，我们进行了广泛的实验活动。

    arXiv:2403.11830v1 Announce Type: cross  Abstract: Machine Learning (ML) algorithms have become increasingly popular for supporting Network Intrusion Detection Systems (NIDS). Nevertheless, extensive research has shown their vulnerability to adversarial attacks, which involve subtle perturbations to the inputs of the models aimed at compromising their performance. Recent proposals have effectively leveraged Graph Neural Networks (GNN) to produce predictions based also on the structural patterns exhibited by intrusions to enhance the detection robustness. However, the adoption of GNN-based NIDS introduces new types of risks. In this paper, we propose the first formalization of adversarial attacks specifically tailored for GNN in network intrusion detection. Moreover, we outline and model the problem space constraints that attackers need to consider to carry out feasible structural attacks in real-world scenarios. As a final contribution, we conduct an extensive experimental campaign in 
    
[^8]: 通过将一个全局明确标注拆解成本地隐式多模态反馈来改进对话代理

    Improving Dialogue Agents by Decomposing One Global Explicit Annotation with Local Implicit Multimodal Feedback

    [https://arxiv.org/abs/2403.11330](https://arxiv.org/abs/2403.11330)

    通过将全局明确标注拆解成本地隐式多模态反馈，提出了一种改进对话代理的方法，并在各种对话度量方面展现出一致的改进

    

    我们描述了一种方法，通过全局（即，对话级）奖励对齐基于LLM的对话代理，同时考虑到自然发生的多模态信号。在高层次上，我们的方法（名为GELI）通过将人类提供的全局明确（GE）会话级奖励拆分，利用本地隐式（LI）多模态奖励信号来跨模态地塑造奖励分解步骤。然后将这种分解的奖励模型作为标准RHLF流程的一部分，来改进基于LLM的对话代理。我们进行了定量和定性的人类研究，评估了我们的GELI方法的性能，并发现与基线方法相比，它在各种对话度量方面都表现出一致的改进。

    arXiv:2403.11330v1 Announce Type: cross  Abstract: We describe an approach for aligning an LLM-based dialogue agent based on global (i.e., dialogue-level) rewards, while also taking into account naturally-occurring multimodal signals. At a high level, our approach (dubbed GELI) learns a local, turn-level reward model by decomposing the human-provided Global Explicit (GE) session-level reward, using Local Implicit (LI} multimodal reward signals to crossmodally shape the reward decomposition step. This decomposed reward model is then used as part of the standard RHLF pipeline improve an LLM-based dialog agent. We run quantitative and qualitative human studies to evaluate the performance of our GELI approach, and find that it shows consistent improvements across various conversational metrics compared to baseline methods.
    
[^9]: 通过区块链和大型语言模型增强自主代理的信任：一种通过区块链和大型语言模型实现责任和可解释性的架构

    Enhancing Trust in Autonomous Agents: An Architecture for Accountability and Explainability through Blockchain and Large Language Models

    [https://arxiv.org/abs/2403.09567](https://arxiv.org/abs/2403.09567)

    通过区块链和大型语言模型实现责任和可解释性的架构，提高自主代理的信任和安全性，增强代理与用户之间的沟通效果。

    

    自主代理在涉及人类互动的环境中的部署日益引起安全关注。因此，了解事件背后的情况变得至关重要，需要开发能够向非专家用户解释其行为的能力。这些解释在提高可信度和安全性方面至关重要，作为防范失败、错误和误解的措施。此外，它们有助于改善沟通，弥合代理和用户之间的差距，从而提高它们相互作用的效果。这项工作提出了一种为基于ROS的移动机器人实施的责任和可解释性架构。所提出的解决方案包括两个主要组件。首先，一个类似黑盒的元素用于提供问责制，具有通过区块链技术实现的防篡改属性。其次，一个负责的组件

    arXiv:2403.09567v1 Announce Type: cross  Abstract: The deployment of autonomous agents in environments involving human interaction has increasingly raised security concerns. Consequently, understanding the circumstances behind an event becomes critical, requiring the development of capabilities to justify their behaviors to non-expert users. Such explanations are essential in enhancing trustworthiness and safety, acting as a preventive measure against failures, errors, and misunderstandings. Additionally, they contribute to improving communication, bridging the gap between the agent and the user, thereby improving the effectiveness of their interactions. This work presents an accountability and explainability architecture implemented for ROS-based mobile robots. The proposed solution consists of two main components. Firstly, a black box-like element to provide accountability, featuring anti-tampering properties achieved through blockchain technology. Secondly, a component in charge of 
    
[^10]: 用去噪扩散隐式神经场表示解剖树

    Representing Anatomical Trees by Denoising Diffusion of Implicit Neural Fields

    [https://arxiv.org/abs/2403.08974](https://arxiv.org/abs/2403.08974)

    提出了一种使用隐式神经表示和去噪扩散来准确捕捉解剖树几何和拓扑结构的新方法

    

    解剖树在临床诊断和治疗规划中起着核心作用。然而，由于解剖树的拓扑结构和几何形状多样且复杂，准确表示解剖树具有挑战性。我们提出了一种使用隐式神经表示（INRs）来表示解剖树的新方法，同时通过在INR空间中进行去噪扩散来捕捉一组树的分布。我们可以在任何所需分辨率下准确捕捉解剖树的复杂几何和拓扑结构。

    arXiv:2403.08974v1 Announce Type: cross  Abstract: Anatomical trees play a central role in clinical diagnosis and treatment planning. However, accurately representing anatomical trees is challenging due to their varying and complex topology and geometry. Traditional methods for representing tree structures, captured using medical imaging, while invaluable for visualizing vascular and bronchial networks, exhibit drawbacks in terms of limited resolution, flexibility, and efficiency. Recently, implicit neural representations (INRs) have emerged as a powerful tool for representing shapes accurately and efficiently. We propose a novel approach for representing anatomical trees using INR, while also capturing the distribution of a set of trees via denoising diffusion in the space of INRs. We accurately capture the intricate geometries and topologies of anatomical trees at any desired resolution. Through extensive qualitative and quantitative evaluation, we demonstrate high-fidelity tree reco
    
[^11]: DAM:用于持续视频问答学习的动态适配器合并

    DAM: Dynamic Adapter Merging for Continual Video QA Learning

    [https://arxiv.org/abs/2403.08755](https://arxiv.org/abs/2403.08755)

    提出了一种用于持续视频问答学习的动态适配器合并方法DAM，能够减轻灾难性遗忘、有效适应不断到来的数据集、处理未知数据集输入，并允许在类似数据集领域之间共享知识。

    

    我们提出了一种参数高效的方法，用于持续视频问答（VidQA）学习。我们的方法名为DAM，使用所提出的动态适配器合并来（i）减轻灾难性遗忘，（ii）实现对持续到达的数据集的高效适应，（iii）在推理过程中处理来自未知数据集的输入，（iv）实现跨相似数据集领域的知识共享。在给定一组持续流式传输的VidQA数据集的情况下，我们为每个数据集顺序训练特定于数据集的适配器，同时冻结大型预训练视频语言骨干的参数。在推理过程中，给定来自未知领域的视频问题示例，我们的方法首先使用所提出的非参数路由器函数计算每个适配器的概率，反映出该适配器与当前视频问题输入实例的相关性。随后，所提出的动态适配器合并方案聚合所有适配器权重。

    arXiv:2403.08755v1 Announce Type: cross  Abstract: We present a parameter-efficient method for continual video question-answering (VidQA) learning. Our method, named DAM, uses the proposed Dynamic Adapter Merging to (i) mitigate catastrophic forgetting, (ii) enable efficient adaptation to continually arriving datasets, (iii) handle inputs from unknown datasets during inference, and (iv) enable knowledge sharing across similar dataset domains. Given a set of continually streaming VidQA datasets, we sequentially train dataset-specific adapters for each dataset while freezing the parameters of a large pretrained video-language backbone. During inference, given a video-question sample from an unknown domain, our method first uses the proposed non-parametric router function to compute a probability for each adapter, reflecting how relevant that adapter is to the current video-question input instance. Subsequently, the proposed dynamic adapter merging scheme aggregates all the adapter weight
    
[^12]: $\widetilde{O}(T^{-1})$ 收敛到（粗糙）相关均衡在全信息一般和马尔可夫博弈中的问题

    $\widetilde{O}(T^{-1})$ Convergence to (Coarse) Correlated Equilibria in Full-Information General-Sum Markov Games

    [https://arxiv.org/abs/2403.07890](https://arxiv.org/abs/2403.07890)

    本研究通过使用乐观的前瞻性领导者算法（OFTRL）和适当的数值更新程序，在全信息一般和马尔可夫博弈中找到了$\widetilde{O}(T^{-1})$-approximate（粗糙）相关均衡，这在$T$次迭代内得以实现。

    

    No-regret学习与博弈论密切相关，最近的研究提出了非耦合的无悔学习动态，当所有玩家在正则形式游戏中采用时，以$\widetilde{O}(T^{-1})$的接近最优速率收敛到各种均衡解，这显着改进了经典无悔学习者的$O(1/\sqrt{T})$速率。然而，在马尔可夫博弈中类似的收敛结果很少见，这是一个更通用的设置，为多智能体强化学习奠定了基础。在这项工作中，我们通过展示乐观的前瞻性领导者算法（OFTRL），连同适当的数值更新程序，可以在$T$次迭代内找到全信息一般和马尔可夫博弈中的$\widetilde{O}(T^{-1})$近似（粗糙）相关均衡。数值结果也包括以证实我们的理论发现。

    arXiv:2403.07890v1 Announce Type: cross  Abstract: No-regret learning has a long history of being closely connected to game theory. Recent works have devised uncoupled no-regret learning dynamics that, when adopted by all the players in normal-form games, converge to various equilibrium solutions at a near-optimal rate of $\widetilde{O}(T^{-1})$, a significant improvement over the $O(1/\sqrt{T})$ rate of classic no-regret learners. However, analogous convergence results are scarce in Markov games, a more generic setting that lays the foundation for multi-agent reinforcement learning. In this work, we close this gap by showing that the optimistic-follow-the-regularized-leader (OFTRL) algorithm, together with appropriate value update procedures, can find $\widetilde{O}(T^{-1})$-approximate (coarse) correlated equilibria in full-information general-sum Markov games within $T$ iterations. Numerical results are also included to corroborate our theoretical findings.
    
[^13]: WMDP基准：通过遗忘测量和减少恶意使用

    The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning

    [https://arxiv.org/abs/2403.03218](https://arxiv.org/abs/2403.03218)

    WMDP基准是一个公开发布的数据集，包含4157个多项选择问题，用作生物安全、网络安全和化学安全危险知识的代理测量。

    

    arXiv:2403.03218v1 公告类型：交叉领域 摘要：白宫关于人工智能的行政命令强调了大型语言模型(LLMs)赋予恶意行为者开发生物、网络和化学武器的风险。为了衡量这些恶意使用的风险，政府机构和主要人工智能实验室正在开发LLMs的危险能力评估。然而，当前的评估是私人的，阻碍了进一步研究如何减少风险。此外，它们仅专注于几条高度特定的恶意使用途径。为了填补这些空白，我们公开发布了大规模杀伤性武器代理（WMDP）基准，这是一个包含4157个多项选择问题的数据集，作为生物安全、网络安全和化学安全危险知识的代理测量。WMDP由一组学术界和技术顾问联合开发，并在公开发布前严格过滤以消除敏感信息。WMDP有两个服务

    arXiv:2403.03218v1 Announce Type: cross  Abstract: The White House Executive Order on Artificial Intelligence highlights the risks of large language models (LLMs) empowering malicious actors in developing biological, cyber, and chemical weapons. To measure these risks of malicious use, government institutions and major AI labs are developing evaluations for hazardous capabilities in LLMs. However, current evaluations are private, preventing further research into mitigating risk. Furthermore, they focus on only a few, highly specific pathways for malicious use. To fill these gaps, we publicly release the Weapons of Mass Destruction Proxy (WMDP) benchmark, a dataset of 4,157 multiple-choice questions that serve as a proxy measurement of hazardous knowledge in biosecurity, cybersecurity, and chemical security. WMDP was developed by a consortium of academics and technical consultants, and was stringently filtered to eliminate sensitive information prior to public release. WMDP serves two r
    
[^14]: NaturalSpeech 3: 利用分解编解码器和扩散模型实现零-shot语音合成

    NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models

    [https://arxiv.org/abs/2403.03100](https://arxiv.org/abs/2403.03100)

    NaturalSpeech 3利用分解设计的扩散模型实现零-shot方式生成自然语音

    

    近期大规模文本到语音（TTS）模型取得了显著进展，然而在语音质量、相似度和韵律方面仍存在不足。鉴于语音复杂地包含各种属性（例如内容、韵律、音色和声学细节），给生成带来了重大挑战，一个自然的想法是将语音因子分解为代表不同属性的各个子空间，并单独生成它们。在此基础上，我们提出了NaturalSpeech 3，这是一个具有新颖的分解扩散模型的TTS系统，可以以零-shot方式生成自然语音。具体来说，1) 我们设计了一个具有分解向量量化（FVQ）的神经编解码器，将语音波形分解为内容、韵律、音色和声学细节的子空间；2) 我们提出了一个分解扩散模型，根据其相应的提示生成每个子空间中的属性。借助这种分解设计，NaturalSpeech 3能够ef

    arXiv:2403.03100v1 Announce Type: cross  Abstract: While recent large-scale text-to-speech (TTS) models have achieved significant progress, they still fall short in speech quality, similarity, and prosody. Considering speech intricately encompasses various attributes (e.g., content, prosody, timbre, and acoustic details) that pose significant challenges for generation, a natural idea is to factorize speech into individual subspaces representing different attributes and generate them individually. Motivated by it, we propose NaturalSpeech 3, a TTS system with novel factorized diffusion models to generate natural speech in a zero-shot way. Specifically, 1) we design a neural codec with factorized vector quantization (FVQ) to disentangle speech waveform into subspaces of content, prosody, timbre, and acoustic details; 2) we propose a factorized diffusion model to generate attributes in each subspace following its corresponding prompt. With this factorization design, NaturalSpeech 3 can ef
    
[^15]: 见证为信：通过CLIP引导解码缓解大型视觉-语言模型中的幻觉

    Seeing is Believing: Mitigating Hallucination in Large Vision-Language Models via CLIP-Guided Decoding

    [https://arxiv.org/abs/2402.15300](https://arxiv.org/abs/2402.15300)

    CLIP相似性作为更强大和更稳健的幻觉指标，研究提出了CLIP引导解码（CGD）方法，在大型视觉-语言模型中有效减少对象幻觉。

    

    大型视觉-语言模型(LVLMs)容易出现对象幻觉，即生成的文本包含不存在的对象，严重限制了它们的可靠性和实用性。我们首先对句子级LVLM幻觉进行实证分析，发现与图像的CLIP相似性作为一个比单词可能性更强大、更稳健的幻觉指示器。基于这一发现，我们提出了CLIP引导解码（CGD）方法，这是一种简单但有效的无需训练的方法，用于减少解码时的对象幻觉。CGD利用CLIP来引导模型的解码过程，通过增强生成文本与图像的视觉联系。实验表明，CGD有效地减轻了对象幻觉。

    arXiv:2402.15300v1 Announce Type: cross  Abstract: Large Vision-Language Models (LVLMs) are susceptible to object hallucinations, an issue in which their generated text contains non-existent objects, greatly limiting their reliability and practicality. Current approaches often rely on the model's token likelihoods or other internal information, instruction tuning on additional datasets, or incorporating complex external tools. We first perform empirical analysis on sentence-level LVLM hallucination, finding that CLIP similarity to the image acts as a stronger and more robust indicator of hallucination compared to token likelihoods. Motivated by this, we introduce our CLIP-Guided Decoding (CGD) approach, a straightforward but effective training-free approach to reduce object hallucination at decoding time. CGD uses CLIP to guide the model's decoding process by enhancing visual grounding of generated text with the image. Experiments demonstrate that CGD effectively mitigates object hallu
    
[^16]: MPIrigen: 通过领域特定语言模型生成MPI代码

    MPIrigen: MPI Code Generation through Domain-Specific Language Models

    [https://arxiv.org/abs/2402.09126](https://arxiv.org/abs/2402.09126)

    本文研究了使用领域特定语言模型生成MPI代码的性能，并提出了使用预训练模型MonoCoder进行MPI-based程序生成的方法。

    

    在大规模并行计算中，高效的并行计算尤为重要，特别是在消息传递接口（MPI）集成领域。生成基于MPI的并行程序是一个具有挑战性的并行编程任务，尚未被探索。本研究首先探讨了先进的语言模型在生成基于MPI的并行程序方面的性能。发现广泛使用的模型，如GPT-3.5和PolyCoder（专门的多语言代码模型），在生成基于MPI的程序时表现出明显的性能下降，相比通用程序。相比之下，基于MPI相关编程语言C和C++预训练的领域特定模型MonoCoder的性能更好。随后，我们通过在HPCorpusMPI上对MonoCoder进行微调，引入了一个专门的MPI-based程序生成任务。

    arXiv:2402.09126v1 Announce Type: cross Abstract: The imperative need to scale computation across numerous nodes highlights the significance of efficient parallel computing, particularly in the realm of Message Passing Interface (MPI) integration. The challenging parallel programming task of generating MPI-based parallel programs has remained unexplored. This study first investigates the performance of state-of-the-art language models in generating MPI-based parallel programs. Findings reveal that widely used models such as GPT-3.5 and PolyCoder (specialized multi-lingual code models) exhibit notable performance degradation, when generating MPI-based programs compared to general-purpose programs. In contrast, domain-specific models such as MonoCoder, which are pretrained on MPI-related programming languages of C and C++, outperform larger models. Subsequently, we introduce a dedicated downstream task of MPI-based program generation by fine-tuning MonoCoder on HPCorpusMPI. We call the r
    
[^17]: 半稠密无检测器方法在匹配局部特征方面表现如何？

    Are Semi-Dense Detector-Free Methods Good at Matching Local Features?

    [https://arxiv.org/abs/2402.08671](https://arxiv.org/abs/2402.08671)

    本研究首次尝试研究半稠密无检测器方法（SDF）建立对应关系能力和估计位姿质量之间的联系。作者提出了一种新颖的图像匹配架构SAM，并发现SAM在位姿估计方面表现优秀，而SDF方法在匹配准确度方面表现更好。作者建议将匹配准确度的计算限制在纹理区域。

    

    半稠密无检测器方法（SDF），如LoFTR，目前是最受欢迎的图像匹配方法之一。虽然SDF方法被训练用于在两幅图像之间建立对应关系，但它们的性能几乎只使用相对位姿估计指标进行评估。因此，迄今为止，它们在建立对应关系的能力和估计位姿质量之间的联系得到的关注甚少。本文首次尝试研究这种联系。我们首先提出了一种新颖的基于结构化注意力的图像匹配架构（SAM）。它使我们能够在两个数据集（MegaDepth和HPatches）上展示一个逆直觉的结果：一方面，SAM在位姿/单应性估计指标方面要么优于SDF方法，要么与之相当；另一方面，SDF方法在匹配准确度方面明显优于SAM。然后，我们建议将匹配准确度的计算限制在纹理区域，并展示了在...

    Semi-dense detector-free approaches (SDF), such as LoFTR, are currently among the most popular image matching methods. While SDF methods are trained to establish correspondences between two images, their performances are almost exclusively evaluated using relative pose estimation metrics. Thus, the link between their ability to establish correspondences and the quality of the resulting estimated pose has thus far received little attention. This paper is a first attempt to study this link. We start with proposing a novel structured attention-based image matching architecture (SAM). It allows us to show a counter-intuitive result on two datasets (MegaDepth and HPatches): on the one hand SAM either outperforms or is on par with SDF methods in terms of pose/homography estimation metrics, but on the other hand SDF approaches are significantly better than SAM in terms of matching accuracy. We then propose to limit the computation of the matching accuracy to textured regions, and show that in
    
[^18]: 只需一个颜色空间：一种用于低光图像增强的高效网络

    You Only Need One Color Space: An Efficient Network for Low-light Image Enhancement

    [https://arxiv.org/abs/2402.05809](https://arxiv.org/abs/2402.05809)

    本文提出了一种用于低光图像增强的高效网络，通过引入可训练的水平/垂直强度（HVI）颜色空间来解耦亮度和颜色，并设计了颜色和强度解耦网络（CIDNet）以改善增强过程中的稳定性。结果显示，该方法可以减少增强图像中的颜色和亮度伪影。

    

    低光图像增强（Low-Light Image Enhancement，LLIE）任务旨在从受损的低光图像中恢复细节和视觉信息。大多数现有方法通过深度神经网络（DNNs）在sRGB和HSV颜色空间上学习低/正常光图像之间的映射函数。然而，增强涉及放大图像信号，并且将这些颜色空间应用于信噪比低的低光图像可能会引入灵敏度和不稳定性，从而导致增强图像中存在颜色伪影和亮度伪影。为了缓解这个问题，我们提出了一种新的可训练颜色空间，称为水平/垂直强度（HVI）。它不仅将亮度和颜色从RGB通道分离出来以减轻增强过程中的不稳定性，而且由于可训练参数，它还适应不同光照范围的低光图像。此外，我们设计了一种新颖的颜色和强度解耦网络（CIDNet），含有两个部分。

    Low-Light Image Enhancement (LLIE) task tends to restore the details and visual information from corrupted low-light images. Most existing methods learn the mapping function between low/normal-light images by Deep Neural Networks (DNNs) on sRGB and HSV color space. Nevertheless, enhancement involves amplifying image signals, and applying these color spaces to low-light images with a low signal-to-noise ratio can introduce sensitivity and instability into the enhancement process. Consequently, this results in the presence of color artifacts and brightness artifacts in the enhanced images. To alleviate this problem, we propose a novel trainable color space, named Horizontal/Vertical-Intensity (HVI). It not only decouples brightness and color from RGB channels to mitigate the instability during enhancement but also adapts to low-light images in different illumination ranges due to the trainable parameters. Further, we design a novel Color and Intensity Decoupling Network (CIDNet) with two
    
[^19]: 超越文字：通过语音线索改善LLM在机器人导航中的决策能力

    Beyond Text: Improving LLM's Decision Making for Robot Navigation via Vocal Cues

    [https://arxiv.org/abs/2402.03494](https://arxiv.org/abs/2402.03494)

    本论文通过将语音转录和语音非言语特征整合到LLM决策中来改善机器人导航中的决策能力，超越了仅使用文字的限制。

    

    这项工作强调了基于文本的大规模语言模型（LLM）在人机交互中的关键缺点，表明仅使用文本作为对话的模态在此类应用中存在不足之处。虽然LLM在处理文本方面在这些人机对话中非常出色，但在社交导航等情境下，他们在处理口头指令的细微之处时遇到了困难，其中的歧义和不确定性可能会削弱对机器人和其他人工智能系统的信任。我们可以通过超越文字，并重点关注这些音频回应的语音非言语特征来解决这个问题。这些特征是口头交流中不涉及文字措辞的方面，通过表达方式传达意义和细微差别。我们提出了“超越文字”；一种通过集成音频转录以及这些特征的部分来改善LLM决策能力的方法，这些特征侧重情感和更与人机对话相关。

    This work highlights a critical shortcoming in text-based Large Language Models (LLMs) used for human-robot interaction, demonstrating that text alone as a conversation modality falls short in such applications. While LLMs excel in processing text in these human conversations, they struggle with the nuances of verbal instructions in scenarios like social navigation, where ambiguity and uncertainty can erode trust in robotic and other AI systems. We can address this shortcoming by moving beyond text and additionally focusing on the paralinguistic features of these audio responses. These features are the aspects of spoken communication that do not involve the literal wording (lexical content) but convey meaning and nuance through how something is said. We present "Beyond Text"; an approach that improves LLM decision-making by integrating audio transcription along with a subsection of these features, which focus on the affect and more relevant in human-robot conversations. This approach n
    
[^20]: SWEA:通过主题词嵌入修改改变大型语言模型中的事实知识

    SWEA: Changing Factual Knowledge in Large Language Models via Subject Word Embedding Altering

    [https://arxiv.org/abs/2401.17809](https://arxiv.org/abs/2401.17809)

    提出了一种主题词嵌入修改框架（SWEA），通过在推理阶段修改主题的表示来编辑知识，保护模型的原始权重，避免不可逆的损害和额外的推理开销。

    

    模型编辑近来引起了广泛关注。目前的模型编辑方法主要涉及修改模型参数或向现有模型添加附加模块。然而，前者会对LLM造成不可逆的影响，而后者会产生额外的推理开销，并且模糊的向量匹配并不总是可靠的。为了解决这些问题，我们提出了一种可扩展的主题词嵌入修改（SWEA）框架，它在推理阶段修改主题的表示，并实现编辑知识的目标。SWEA在模型外部使用精确的关键匹配，并进行可靠的主题词嵌入修改，从而保护模型的原始权重而不增加推理开销。然后，我们提出优化抑制融合方法，首先优化编辑目标的嵌入向量，然后抑制知识嵌入维度（KED）以获得最终融合的嵌入。我们因此提出了SWEAOS元方法。

    Model editing has recently gained widespread attention. Current model editing methods primarily involve modifying model parameters or adding additional modules to the existing model. However, the former causes irreversible damage to LLMs, while the latter incurs additional inference overhead and fuzzy vector matching is not always reliable. To address these issues, we propose an expandable Subject Word Embedding Altering (SWEA) framework, which modifies the representation of subjects and achieve the goal of editing knowledge during the inference stage. SWEA uses precise key matching outside the model and performs reliable subject word embedding altering, thus protecting the original weights of the model without increasing inference overhead. We then propose optimizing then suppressing fusion method, which first optimizes the embedding vector for the editing target and then suppresses the Knowledge Embedding Dimension (KED) to obtain the final fused embedding. We thus propose SWEAOS met
    
[^21]: RMS：实时姿态估计的最小冗余点云采样

    RMS: Redundancy-Minimizing Point Cloud Sampling for Real-Time Pose Estimation

    [https://arxiv.org/abs/2312.07337](https://arxiv.org/abs/2312.07337)

    提出了一种名为RMS的点云采样方法，通过最小化冗余优化了3D点云的翻译空间可观测性，解决了移动机器人状态估计中潜在的问题。

    

    在移动机器人状态估计中使用的典型点云采样方法保留了高水平的点冗余。这种冗余不必要地减慢了估计流程并可能在实时约束下导致漂移。这种不必要的延迟成为资源受限的机器人（尤其是无人机）的瓶颈，需要最小的延迟以进行敏捷和准确的操作。我们提出了一种名为RMS的新颖、确定性、未知和单参数点云采样方法，它最小化了3D点云中的冗余。

    arXiv:2312.07337v2 Announce Type: replace-cross  Abstract: The typical point cloud sampling methods used in state estimation for mobile robots preserve a high level of point redundancy. This redundancy unnecessarily slows down the estimation pipeline and may cause drift under real-time constraints. Such undue latency becomes a bottleneck for resource-constrained robots (especially UAVs), requiring minimal delay for agile and accurate operation. We propose a novel, deterministic, uninformed, and single-parameter point cloud sampling method named RMS that minimizes redundancy within a 3D point cloud. In contrast to the state of the art, RMS balances the translation-space observability by leveraging the fact that linear and planar surfaces inherently exhibit high redundancy propagated into iterative estimation pipelines. We define the concept of gradient flow, quantifying the local surface underlying a point. We also show that maximizing the entropy of the gradient flow minimizes point re
    
[^22]: VT-Former: 基于Transformer的智能公路交通系统中的车辆轨迹预测方法

    VT-Former: A Transformer-based Vehicle Trajectory Prediction Approach For Intelligent Highway Transportation Systems

    [https://arxiv.org/abs/2311.06623](https://arxiv.org/abs/2311.06623)

    本文介绍了一种基于Transformer的车辆轨迹预测方法，名为VT-Former，在智能公路交通系统中具有重要的应用价值。

    

    加强道路安全和交通管理已成为现代网络物理系统和智能交通系统的重点领域。车辆轨迹预测在公路和道路安全的众多应用中起着关键作用。这些应用包括交通管理、事故预防、工地安全和能源优化等各种用例。在人工智能领域的发展以及监控摄像头在道路网络上的增加部署推动下，智能管理在这一背景下得到了很大进展。本文介绍了一种新颖的基于Transformer的车辆轨迹预测方法，称为VT-Former。除了利用Transformer捕捉长期时间模式外，还提出了一种新的图注意力分词（GAT）模块。

    Enhancing roadway safety and traffic management has become an essential focus area for a broad range of modern cyber-physical systems and intelligent transportation systems. Vehicle Trajectory Prediction is a pivotal element within numerous applications for highway and road safety. These applications encompass a wide range of use cases, spanning from traffic management and accident prevention to enhancing work-zone safety and optimizing energy conservation. The ability to implement intelligent management in this context has been greatly advanced by the developments in the field of Artificial Intelligence (AI), alongside the increasing deployment of surveillance cameras across road networks. In this paper, we introduce a novel transformer-based approach for vehicle trajectory prediction for highway safety and surveillance, denoted as VT-Former. In addition to utilizing transformers to capture long-range temporal patterns, a new Graph Attentive Tokenization (GAT) module has been proposed
    
[^23]: PPNet: 一种用于端到端近似最优路径规划的新颖神经网络结构

    PPNet: A Novel Neural Network Structure for End-to-End Near-Optimal Path Planning. (arXiv:2401.09819v1 [cs.RO])

    [http://arxiv.org/abs/2401.09819](http://arxiv.org/abs/2401.09819)

    PPNet是一种新颖的神经网络结构，用于解决端到端近似最优路径规划问题。通过将路径规划问题分为两个子问题，并使用两级级联神经网络进行求解，同时引入了一种高效的数据生成方法EDaGe-PP。实验结果表明，PPNet在计算时间和成功率方面比其他方法有显著提升。

    

    传统的路径规划器，如基于采样的路径规划器，在初始解敏感性和收敛到最优解速度上具有局限性。然而，在许多应用中，如具有有限功率/燃料的自动驾驶车辆中，在短时间内找到近似最优解是具有挑战性的。为了实现端到端近似最优路径规划器，我们首先将路径规划问题分为两个子问题，即路径空间分段和给定路径空间中的航点生成。我们进一步提出了一个名为路径规划网络（PPNet）的两级级联神经网络来解决路径规划问题，通过解决上述子问题。此外，我们提出了一种名为EDaGe-PP的用于路径规划的高效数据生成方法。结果显示，PPNet训练集由EDaGe-PP生成的成功率相比其他方法提升了$2\times$，总计算时间少于1/33。我们验证了PPNet的性能。

    The classical path planners, such as sampling-based path planners, have the limitations of sensitivity to the initial solution and slow convergence to the optimal solution. However, finding a near-optimal solution in a short period is challenging in many applications such as the autonomous vehicle with limited power/fuel. To achieve an end-to-end near-optimal path planner, we first divide the path planning problem into two subproblems, which are path's space segmentation and waypoints generation in the given path's space. We further propose a two-level cascade neural network named Path Planning Network (PPNet) to solve the path planning problem by solving the abovementioned subproblems. Moreover, we propose a novel efficient data generation method for path planning named EDaGe-PP. The results show the total computation time is less than 1/33 and the success rate of PPNet trained by the dataset that is generated by EDaGe-PP is about $2 \times$ compared to other methods. We validate PPNe
    
[^24]: GPT-4 Vision在医学领域中专家级准确度背后的隐藏缺陷

    Hidden Flaws Behind Expert-Level Accuracy of GPT-4 Vision in Medicine. (arXiv:2401.08396v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2401.08396](http://arxiv.org/abs/2401.08396)

    GPT-4 Vision在医学领域中具有专家级准确度，但在图像理解方面存在缺陷。

    

    最近的研究表明，具有Vision功能的GPT-4在医学挑战任务中表现优于人类医生。然而，这些评估主要关注多项选择题的准确度。本研究通过对GPT-4V在解决新英格兰医学杂志图像挑战中的图像理解、医学知识回忆和逐步多模态推理的原理进行全面分析，扩展了当前的研究范围。评估结果证实，GPT-4V在多项选择准确度上优于人类医生（88.0% vs. 77.0%，p=0.034）。GPT-4V在医生回答错误的情况下，也能表现出超过80%的准确度。然而，我们发现，GPT-4V在最终做出正确选择的情况下，经常提供有缺陷的推理（27.3%），其中最突出的是图像理解（21.6%）。

    Recent studies indicate that Generative Pre-trained Transformer 4 with Vision (GPT-4V) outperforms human physicians in medical challenge tasks. However, these evaluations primarily focused on the accuracy of multi-choice questions alone. Our study extends the current scope by conducting a comprehensive analysis of GPT-4V's rationales of image comprehension, recall of medical knowledge, and step-by-step multimodal reasoning when solving New England Journal of Medicine (NEJM) Image Challenges - an imaging quiz designed to test the knowledge and diagnostic capabilities of medical professionals. Evaluation results confirmed that GPT-4V outperforms human physicians regarding multi-choice accuracy (88.0% vs. 77.0%, p=0.034). GPT-4V also performs well in cases where physicians incorrectly answer, with over 80% accuracy. However, we discovered that GPT-4V frequently presents flawed rationales in cases where it makes the correct final choices (27.3%), most prominent in image comprehension (21.6
    
[^25]: 对话式语言模型ChatGPT与神经机器翻译在翻译中的竞争性研究

    Can ChatGPT Rival Neural Machine Translation? A Comparative Study. (arXiv:2401.05176v1 [cs.CL])

    [http://arxiv.org/abs/2401.05176](http://arxiv.org/abs/2401.05176)

    本文比较了对话式语言模型ChatGPT和神经机器翻译引擎在将中文外交文本翻译为英文方面的能力，发现自动评价指标和人工评估方法之间存在差异。

    

    在对越来越多地利用大型语言模型进行翻译的兴趣不断增加的背景下，本文评估了ChatGPT等大型语言模型（LLM）与主流神经机器翻译（NMT）引擎在将中文外交文本翻译为英文方面的能力。具体而言，我们通过四个自动评价指标和基于错误类型和六个分析细则的人工评估，考察了ChatGPT和NMT引擎的翻译质量。研究结果表明，自动评价指标对于ChatGPT在不同提示和NMT系统下的表现得出了类似的结果，而当ChatGPT提供示例或翻译任务的上下文信息时，人工评估者往往会给予明显较高的评分。自动评价指标与人工评估维度之间的两两相关性结果较弱且不显著，这表明了两种翻译质量评估方法之间的差异。

    Inspired by the increasing interest in leveraging large language models for translation, this paper evaluates the capabilities of large language models (LLMs) represented by ChatGPT in comparison to the mainstream neural machine translation (NMT) engines in translating Chinese diplomatic texts into English. Specifically, we examine the translation quality of ChatGPT and NMT engines as measured by four automated metrics and human evaluation based on an error-typology and six analytic rubrics. Our findings show that automated metrics yield similar results for ChatGPT under different prompts and NMT systems, while human annotators tend to assign noticeably higher scores to ChatGPT when it is provided an example or contextual information about the translation task. Pairwise correlation between automated metrics and dimensions of human evaluation produces weak and non-significant results, suggesting the divergence between the two methods of translation quality assessment. These findings pro
    
[^26]: 通过创建固定目标来改进内在探索

    Improving Intrinsic Exploration by Creating Stationary Objectives. (arXiv:2310.18144v1 [cs.LG])

    [http://arxiv.org/abs/2310.18144](http://arxiv.org/abs/2310.18144)

    该论文提出了一个新的方法：通过创建固定目标，将原始的非固定奖励转化为固定奖励，从而改善了强化学习中的内在探索。

    

    强化学习中的探索奖励通过定义自定义的内在目标来引导长期探索。基于计数的方法使用状态访问频率来获得探索奖励。本文发现，任何从基于计数的方法导出的内在奖励函数都是非固定的，因此为代理人构建了一个难以优化的目标。我们工作的关键贡献在于通过增强状态表示将原始的非固定奖励转化为固定奖励。为此，我们引入了用于探索的固定目标（SOFE）框架。SOFE需要识别不同探索奖励的足够统计量，并找到一种将这些统计量高效编码作为深度网络输入的方法。SOFE基于提出扩展状态空间的状态增强，但有希望简化代理目标的优化。我们的实验结果表明，SOFE改善了探索效果。

    Exploration bonuses in reinforcement learning guide long-horizon exploration by defining custom intrinsic objectives. Count-based methods use the frequency of state visits to derive an exploration bonus. In this paper, we identify that any intrinsic reward function derived from count-based methods is non-stationary and hence induces a difficult objective to optimize for the agent. The key contribution of our work lies in transforming the original non-stationary rewards into stationary rewards through an augmented state representation. For this purpose, we introduce the Stationary Objectives For Exploration (SOFE) framework. SOFE requires identifying sufficient statistics for different exploration bonuses and finding an efficient encoding of these statistics to use as input to a deep network. SOFE is based on proposing state augmentations that expand the state space but hold the promise of simplifying the optimization of the agent's objective. Our experiments show that SOFE improves the
    
[^27]: 一种用于大型语言模型的一次敏感度感知混合稀疏化剪枝方法

    One-Shot Sensitivity-Aware Mixed Sparsity Pruning for Large Language Models. (arXiv:2310.09499v1 [cs.CL])

    [http://arxiv.org/abs/2310.09499](http://arxiv.org/abs/2310.09499)

    我们提出了一种基于敏感度感知混合稀疏化剪枝的方法，可以在不重新训练的情况下将大型语言模型剪枝至至少50％的稀疏性，同时保持稀疏性水平和减少剪枝引起的误差。此外，该方法还与量化兼容，可以进一步压缩语言模型。

    

    从生成预训练变压器（GPT）系列中的各种大型语言模型（LLMs）在各种文本生成任务中取得了卓越的性能。然而，由于高推理延迟，巨大的模型大小阻碍了它们在实际应用中的实用性。因此，通过量化、剪枝和其他方法提高LLMs的效率成为LLM研究的一个关键问题。在这项工作中，我们提出了一种基于Hessian敏感度感知混合稀疏化剪枝的方法，可以将LLMs剪枝至至少50%的稀疏性，而无需重新训练。它根据敏感度自适应地分配稀疏性，使我们能够降低剪枝引起的误差，同时保持整体稀疏性水平。当稀疏度非常高时，所提出的方法的优势更加明显。此外，我们的方法与量化兼容，可以进一步压缩LLMs。

    Various Large Language Models(LLMs) from the Generative Pretrained Transformer~(GPT) family have achieved outstanding performances in a wide range of text generation tasks. However, the enormous model sizes have hindered their practical use in real-world applications due to high inference latency. Therefore, improving the efficiencies of LLMs through quantization, pruning, and other means has been a key issue in LLM studies. In this work, we propose a method based on Hessian sensitivity-aware mixed sparsity pruning to prune LLMs to at least 50\% sparsity without the need of any retraining. It allocates sparsity adaptively based on sensitivity, allowing us to reduce pruning-induced error while maintaining the overall sparsity level. The advantages of the proposed method exhibit even more when the sparsity is extremely high. Furthermore, our method is compatible with quantization, enabling further compression of LLMs.
    
[^28]: VAL：带有GPT对话解析的交互式任务学习

    VAL: Interactive Task Learning with GPT Dialog Parsing. (arXiv:2310.01627v1 [cs.HC])

    [http://arxiv.org/abs/2310.01627](http://arxiv.org/abs/2310.01627)

    VAL是一种交互式任务学习系统，通过结合大型语言模型（LLM）和符号集成的理念，实现了从自然语言中进行交互式学习的分层任务知识的获取。所获得的知识可解释并能够推广到执行新任务。在视频游戏环境中的用户交互实验表明，VAL能够从有限的指令中成功学到有效的任务知识。

    

    强化学习通常需要数百万个样本来生成静态的黑箱模型。相比之下，交互式任务学习（ITL）强调从人类提供的有限指令中逐步获得知识，这些指令以自然语言等形式出现。然而，在实践中，ITL系统往往受到脆弱、容易出错的语言解析的困扰。大型语言模型（LLMs）对脆弱性有一定的抵抗能力，但不具备可解释性，也无法进行增量学习。我们提出了VAL，一种具有新的LLM/符号集成理念的ITL系统。通过仅在特定任务中使用LLMs（例如谓词和参数选择），在算法框架内，VAL利用LLMs的优势，支持从自然语言中交互式学习分层任务知识。所获得的知识是人类可解释的，并能够推广到支持执行新任务而不需要额外的训练。我们在一个视频游戏环境中研究了用户与VAL的交互，发现大部分用户能够从有限的指令中成功学到有效的任务知识。

    Reinforcement learning often requires millions of examples to produce static, black-box models. In contrast, interactive task learning (ITL) emphasizes incremental knowledge acquisition from limited instruction provided by humans in modalities such as natural language. However, in practice, ITL systems often suffers from brittle, error-prone language parsing. Large language models (LLMs) are resistant to brittleness but are not interpretable and cannot learn incrementally. We present VAL, an ITL system with a new philosophy for LLM/symbolic integration. By using LLMs only for specific tasks -- such as predicate and argument selection -- within an algorithmic framework, VAL reaps the benefits of LLMs to support interactive learning of hierarchical task knowledge from natural language. Acquired knowledge is human interpretable and generalizes to support execution of novel tasks without additional training. We studied users' interactions with VAL in a video game setting, finding that most
    
[^29]: 神经启发的分层多模态学习

    Neuro-Inspired Hierarchical Multimodal Learning. (arXiv:2309.15877v1 [cs.LG])

    [http://arxiv.org/abs/2309.15877](http://arxiv.org/abs/2309.15877)

    这项研究提出了一种神经启发的分层多模态学习方法，利用信息瓶颈理论构建了一种有效且紧凑的信息流，实现了对真实世界的全面和准确的感知。

    

    整合和处理来自多种信息源或模态对于获得对真实世界的全面和准确的感知至关重要。受到神经科学的启发，我们开发了信息论分层感知(ITHP)模型，该模型利用了信息瓶颈的概念。与大多数旨在将所有模态纳入输入的传统融合模型不同，我们的模型将主要模态指定为输入，而其余模态则作为信息路径中的检测器。我们提出的感知模型的重点是通过在潜在状态和输入模态状态之间最小化相互信息并在潜在状态和其余模态之间最大化相互信息的平衡，构建一种有效且紧凑的信息流。这种方法导致了保留相关信息并最小化冗余的紧凑潜在状态表示，从而实现更好的感知。

    Integrating and processing information from various sources or modalities are critical for obtaining a comprehensive and accurate perception of the real world. Drawing inspiration from neuroscience, we develop the Information-Theoretic Hierarchical Perception (ITHP) model, which utilizes the concept of information bottleneck. Distinct from most traditional fusion models that aim to incorporate all modalities as input, our model designates the prime modality as input, while the remaining modalities act as detectors in the information pathway. Our proposed perception model focuses on constructing an effective and compact information flow by achieving a balance between the minimization of mutual information between the latent state and the input modal state, and the maximization of mutual information between the latent states and the remaining modal states. This approach leads to compact latent state representations that retain relevant information while minimizing redundancy, thereby sub
    
[^30]: 基于掩码Transformer的心电图分类研究

    Masked Transformer for Electrocardiogram Classification. (arXiv:2309.07136v1 [eess.SP])

    [http://arxiv.org/abs/2309.07136](http://arxiv.org/abs/2309.07136)

    提出了一种基于掩码Transformer的ECG分类方法，命名为MTECG，扩展了掩码自动编码器在ECG时间序列上的应用，该方法在广泛的掩码比例下表现稳定良好，并进行了消融实验验证了重构目标的波动性、训练计划长度、逐层学习率衰减和DropPath率的重要性。

    

    心电图（ECG）是临床应用中最重要的诊断工具之一。随着先进算法的出现，各种深度学习模型已被应用于ECG任务。然而，尽管Transformer在计算机视觉和自然语言处理领域取得了广泛成功，但其在ECG数据上的潜力尚未得到实现。在本研究中，我们提出了一种有用的基于掩码Transformer的ECG分类方法，称为MTECG，它将掩码自动编码器的应用扩展到了ECG时间序列上。我们构建了一个包含220,251个ECG记录的数据集，这些记录由医学专家进行了广泛的诊断注释，以探索MTECG的特性。在提出的训练策略下，一个只有5.7M参数的轻量级模型在广泛的掩码比例（5%-75%）下表现稳定良好。消融研究突出了波动重构目标、训练计划长度、逐层学习率衰减和DropPath率的重要性。实验发现MTECG耗时较少且能够有效分类各种心电图。

    Electrocardiogram (ECG) is one of the most important diagnostic tools in clinical applications. With the advent of advanced algorithms, various deep learning models have been adopted for ECG tasks. However, the potential of Transformers for ECG data is not yet realized, despite their widespread success in computer vision and natural language processing. In this work, we present a useful masked Transformer method for ECG classification referred to as MTECG, which expands the application of masked autoencoders to ECG time series. We construct a dataset comprising 220,251 ECG recordings with a broad range of diagnoses annoated by medical experts to explore the properties of MTECG. Under the proposed training strategies, a lightweight model with 5.7M parameters performs stably well on a broad range of masking ratios (5%-75%). The ablation studies highlight the importance of fluctuated reconstruction targets, training schedule length, layer-wise LR decay and DropPath rate. The experiments o
    
[^31]: MERT:带有大规模自监督训练的声学音乐理解模型

    MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training. (arXiv:2306.00107v1 [cs.SD])

    [http://arxiv.org/abs/2306.00107](http://arxiv.org/abs/2306.00107)

    提出了一个带有大规模自监督训练的音乐理解模型MERT，利用了教师模型并采用了一种优于传统的语音和音频方法的组合方式。

    

    自监督学习（SSL）最近在视觉、文本和语音领域中已被证明是训练通用模型的一种很有前景的范例，对于跨越音乐领域的应用，尤其是对于调性和音高这样的特殊音乐知识的建模颇具挑战性。为了解决这一问题，我们提出了一个基于大规模自监督训练的声学音乐理解模型，即MERT。在我们的探索中，我们确定了更优秀的教师模型组合，这种组合方法在性能方面优于传统的语音和音频方法。

    Self-supervised learning (SSL) has recently emerged as a promising paradigm for training generalisable models on large-scale data in the fields of vision, text, and speech. Although SSL has been proven effective in speech and audio, its application to music audio has yet to be thoroughly explored. This is primarily due to the distinctive challenges associated with modelling musical knowledge, particularly its tonal and pitched characteristics of music. To address this research gap, we propose an acoustic Music undERstanding model with large-scale self-supervised Training (MERT), which incorporates teacher models to provide pseudo labels in the masked language modelling (MLM) style acoustic pre-training. In our exploration, we identified a superior combination of teacher models, which outperforms conventional speech and audio approaches in terms of performance. This combination includes an acoustic teacher based on Residual Vector Quantization - Variational AutoEncoder (RVQ-VAE) and a m
    
[^32]: 关于静态风险度量的动态规划分解

    On Dynamic Program Decompositions of Static Risk Measures. (arXiv:2304.12477v1 [math.OC])

    [http://arxiv.org/abs/2304.12477](http://arxiv.org/abs/2304.12477)

    本文证明了现有的CVaR和EVaR风险度量动态分解是真实风险值的严格高估计，然而VaR存在精确的动态分解。

    

    在马尔科夫决策过程中优化静态风险规避目标具有一定挑战性，因为它们不容易接受动态规划分解。先前的研究建议使用风险度量的动态分解来制定扩展状态空间上的动态规划。本文表明几种现有的分解本质上是不精确的，这与文献中的几个声明相矛盾。特别地，我们举出了一些例子，证明了CVaR和EVaR风险度量的流行分解是真实风险值的严格高估计。然而，VaR确实存在精确的分解，我们提供一个简单的证明，阐明了VaR和CVaR动态规划属性之间的基本差异。

    Optimizing static risk-averse objectives in Markov decision processes is challenging because they do not readily admit dynamic programming decompositions. Prior work has proposed to use a dynamic decomposition of risk measures that help to formulate dynamic programs on an augmented state space. This paper shows that several existing decompositions are inherently inexact, contradicting several claims in the literature. In particular, we give examples that show that popular decompositions for CVaR and EVaR risk measures are strict overestimates of the true risk values. However, an exact decomposition is possible for VaR, and we give a simple proof that illustrates the fundamental difference between VaR and CVaR dynamic programming properties.
    
[^33]: RETVec：弹性和高效的文本向量化

    RETVec: Resilient and Efficient Text Vectorizer. (arXiv:2302.09207v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.09207](http://arxiv.org/abs/2302.09207)

    RETVec是一种高效、弹性和多语言的文本向量化器，通过采用新颖的字符编码和对抗攻击鲁棒的嵌入模型，实现了对拼写错误和对抗性攻击的更好适应性。与其他向量化器和词嵌入模型相比，RETVec在各种模型架构和数据集上表现出竞争力和显著的弹性。

    

    本文介绍了RETVec，一种专为基于神经网络的文本处理而设计的高效、弹性和多语言的文本向量化器。RETVec采用了一种新颖的字符编码和可选的小型嵌入模型，将词语嵌入到256维向量空间中。RETVec的嵌入模型使用对比度学习进行预训练，以针对拼写错误和字符级对抗攻击具有鲁棒性。在本文中，我们对RETVec在流行的模型架构和数据集上进行了评估和比较。这些比较表明，RETVec能够产生具有竞争力的多语言模型，对拼写错误和对抗性文本攻击具有显著的弹性。RETVec在Apache 2许可下可在https://github.com/google-research/retvec获取。

    This paper describes RETVec, an efficient, resilient, and multilingual text vectorizer designed for neural-based text processing. RETVec combines a novel character encoding with an optional small embedding model to embed words into a 256-dimensional vector space. The RETVec embedding model is pre-trained using pair-wise metric learning to be robust against typos and character-level adversarial attacks. In this paper, we evaluate and compare RETVec to state-of-the-art vectorizers and word embeddings on popular model architectures and datasets. These comparisons demonstrate that RETVec leads to competitive, multilingual models that are significantly more resilient to typos and adversarial text attacks. RETVec is available under the Apache 2 license at https://github.com/google-research/retvec.
    

