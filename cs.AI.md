# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [A model is worth tens of thousands of examples.](http://arxiv.org/abs/2303.10608) | 研究了神经网络与传统基于数学数据生成模型的信号处理方法的数据需求差异，并在两个简单的问题上得到了实证结果。 |
| [^2] | [Hierarchical Personalized Federated Learning Over Massive Mobile Edge Computing Networks.](http://arxiv.org/abs/2303.10580) | 本篇论文提出了一种分层个性化联邦学习算法，能够在巨型移动边缘计算网络中处理移动用户设备的异构性，并且实现了训练损失最小化和轮延迟降低的目标权衡。 |
| [^3] | [Unsupervised Learning for Solving the Travelling Salesman Problem.](http://arxiv.org/abs/2303.10538) | 无监督学习框架UTSP能够对旅行商问题进行求解，它使用图神经网络作为基础模型，在保证路径为哈密顿循环的前提下，能够找到最短路径。相较于其他方法，UTSP在训练样本与参数数量上占用更少的资源，且性能更佳。 |
| [^4] | [TempT: Temporal consistency for Test-time adaptation.](http://arxiv.org/abs/2303.10536) | 本文提出一种新颖的方法TempT，通过确保连续帧之间的预测具有时间上的一致性，实现了对视频的测试时自适应。其仅利用视觉单模态特征，并在面部表情识别等计算机视觉任务中具有广泛应用，并在实验中取得了有竞争力的表现，为其在各种实际应用中提供了令人信服的概念证明。 |
| [^5] | [Unsupervised Interpretable Basis Extraction for Concept-Based Visual Explanations.](http://arxiv.org/abs/2303.10523) | 本文提出了一种无监督的方法，通过对CNN进行转换，从而更好地解释中间层的表示，提取了一个可解释性欠完备基础，并证明该方法在各种网络结构和训练数据集上都很有效。 |
| [^6] | [Learn, Unlearn and Relearn: An Online Learning Paradigm for Deep Neural Networks.](http://arxiv.org/abs/2303.10455) | 学习、遗忘和重学（LURE）是一种深度神经网络的在线学习范式，它在遗忘阶段和重学阶段之间进行交替，通过有选择地遗忘模型中的不良信息和对泛化性的学习来在效率和泛化之间取得平衡。 |
| [^7] | [A Content Adaptive Learnable Time-Frequency Representation For Audio Signal Processing.](http://arxiv.org/abs/2303.10446) | 该论文提出了一种用于音频信号处理的内容自适应可学习时频表示法，通过学习卷积滤波器与变换器架构来将小的波形块投影到小的潜在维度上。 |
| [^8] | [Byzantine-Resilient Federated Learning at Edge.](http://arxiv.org/abs/2303.10434) | 本文提出了一种适用于处理重尾数据并在拜占庭攻击下具备鲁棒性的联邦学习算法，同时采用梯度压缩技术来减少通信开销。 |
| [^9] | [NoisyHate: Benchmarking Content Moderation Machine Learning Models with Human-Written Perturbations Online.](http://arxiv.org/abs/2303.10430) | 本文提出了一个包含人类编写的在线扰动的测试集，用于毒性言论检测模型的评估。 |
| [^10] | [Identification of Novel Classes for Improving Few-Shot Object Detection.](http://arxiv.org/abs/2303.10422) | 该论文提出一种半监督算法，利用未标注的新物体来提高少样本目标检测的性能，主要包括使用分层三元分类区域提议网络来定位潜在的未标注新物体，并为它们分配新的目标性标签。 |
| [^11] | [Mutilmodal Feature Extraction and Attention-based Fusion for Emotion Estimation in Videos.](http://arxiv.org/abs/2303.10421) | 本文介绍了一个基于注意力的多模态框架用于情感估计，在CVPR 2023 ABAW竞赛中取得了0.361的准确度。 |
| [^12] | [ExplainFix: Explainable Spatially Fixed Deep Networks.](http://arxiv.org/abs/2303.10408) | ExplainFix采用固定滤波器和精简的网络参数，提高了深度神经网络的可解释性和训练速度。 |
| [^13] | [3DQD: Generalized Deep 3D Shape Prior via Part-Discretized Diffusion Process.](http://arxiv.org/abs/2303.10406) | 该论文提出了一种广义的深度三维形状先验模型，可以用于多种三维任务，其使用向量量化变分自编码器和离散扩散生成器来精确捕获局部精细的形状信息，并引入多频率融合模块来抑制高频形状特征波动，广泛实验表明其在各种三维形状生成任务上表现出优异的性能。 |
| [^14] | [FedRight: An Effective Model Copyright Protection for Federated Learning.](http://arxiv.org/abs/2303.10399) | FedRight 使用生成对抗性样本提取模型特征，即模型指纹，实现了对联邦学习模型版权的保护。它在有效性、安全性、鲁棒性和效率方面的性能均优于以前的工作。 |
| [^15] | [Powerful and Extensible WFST Framework for RNN-Transducer Losses.](http://arxiv.org/abs/2303.10384) | 本文提出了一个基于WFST框架的的RNN-Transducer Losses强大且可扩展的实现，“Compose-Transducer”和“Grid-Transducer”，并引入了新的W-Transducer Loss来展示组件的易扩展性。在实验中，W-Transducer（W-RNNT）表现出比标准RNN-T更好的性能。 |
| [^16] | [CroSel: Cross Selection of Confident Pseudo Labels for Partial-Label Learning.](http://arxiv.org/abs/2303.10365) | CroSel是一种处理伪标签噪声的新方法，通过利用历史预测信息和一致性正则化项来准确识别部分标签数据的真实标签。 |
| [^17] | [LossMix: Simplify and Generalize Mixup for Object Detection and Beyond.](http://arxiv.org/abs/2303.10343) | 本论文提出了一种称为 Supervision Interpolation 的新概念框架，通过放松和推广 Mixup 提供了一种全新的插值增强视角，并在此基础上提出了一种名为 LossMix 的简单而多功能的正则化方法，能够增强物体检测器的性能和鲁棒性，或者说LossMix 在目标检测和其他领域中表现出色。 |
| [^18] | [A general-purpose AI assistant embedded in an open-source radiology information system.](http://arxiv.org/abs/2303.10338) | 该论文讨论了如何在开源放射学信息系统中引入一个通用的人工智能助手，通过Few-shot学习和Swarm学习方法，AI模型能够不断重新训练并学习从放射学家的更正中学习和改进。 |
| [^19] | [Edge-aware Plug-and-play Scheme for Semantic Segmentation.](http://arxiv.org/abs/2303.10307) | 本文提出了一种抽象且通用的边缘监督方法，可以轻松快速地应用于任何语义分割模型中，称为Edge-aware Plug-and-play Scheme (EPS)，其核心是边缘宽度/厚度保持的指导性语义分割。 |
| [^20] | [Welfare Maximization Algorithm for Solving Budget-Constrained Multi-Component POMDPs.](http://arxiv.org/abs/2303.10302) | 该论文提出了一种福利最大化算法，用于解决预算约束下多组件POMDP问题，它通过最优预算分配来计算最优策略。 |
| [^21] | [Detection of Uncertainty in Exceedance of Threshold (DUET): An Adversarial Patch Localizer.](http://arxiv.org/abs/2303.10291) | 提出了一种基于不确定性的对抗性patch本地化器DUET算法，可以定位图像上的对抗性patch，适用于自动驾驶汽车和医学成像等安全敏感应用。 |
| [^22] | [Mobile Edge Adversarial Detection for Digital Twinning to the Metaverse with Deep Reinforcement Learning.](http://arxiv.org/abs/2303.10288) | 本文提出了一种新的移动边缘对抗检测（MEAD）框架，可以准确地检测出在物理世界物体上的对抗性贴片，从而在数字双生技术应用的虚拟世界中确保安全性。 |
| [^23] | [On Trivalent Logics, Compound Conditionals, and Probabilistic Deduction Theorems.](http://arxiv.org/abs/2303.10268) | 本文基于德芬尼的三值分析，探讨了复合条件、条件随机量、p一致性和p蕴含。并证明了条件事件的概率推理定理，研究了迭代条件和在此概率推理定理下的"$A$或$B$"的推理推导到条件的无效性。 |
| [^24] | [Robust Mode Connectivity-Oriented Adversarial Defense: Enhancing Neural Network Robustness Against Diversified $\ell_p$ Attacks.](http://arxiv.org/abs/2303.10225) | 本文提出一种新颖的鲁棒模态连接导向的对抗性防御，实现神经网络对多样化$\ell_p$攻击的鲁棒性，其中包括两个基于种群学习的学习阶段。 |
| [^25] | [An Empirical Evaluation of Federated Contextual Bandit Algorithms.](http://arxiv.org/abs/2303.10218) | 本文通过联邦情境赌博算法对隐式信号进行学习，避免了访问难以获得的显式标签，并发现了简单而常用的softmax启发式在平衡算法方面的惊人有效性。 |
| [^26] | [BotShape: A Novel Social Bots Detection Approach via Behavioral Patterns.](http://arxiv.org/abs/2303.10214) | BotShape是一种新型的基于行为模式的社交机器人检测方法，通过提取重要的行为特征可以提高检测性能。 |
| [^27] | [Exploring contrast generalisation in deep learning-based brain MRI-to-CT synthesis.](http://arxiv.org/abs/2303.10202) | 本文研究了领域随机化（DR）来提高DL模型在生成基于MRI的脑部sCT的泛化能力。 |
| [^28] | [SFE: A Simple, Fast and Efficient Feature Selection Algorithm for High-Dimensional Data.](http://arxiv.org/abs/2303.10182) | 提出一种针对高维数据集的特征选择算法SFE，由搜索代理和两个算子执行探索和开发阶段，对于高维度数据集表现良好，但在降维后性能不能提高 |
| [^29] | [Operating critical machine learning models in resource constrained regimes.](http://arxiv.org/abs/2303.10181) | 本文分享了在关键场景下使用机器学习模型时资源消耗和性能之间的权衡方法。考虑到模型在全球诊所中的部署，机器学习界正在为改进模型效率而努力。 |
| [^30] | [Towards Safe Propofol Dosing during General Anesthesia Using Deep Offline Reinforcement Learning.](http://arxiv.org/abs/2303.10180) | 本文提出了一种基于真实临床数据集的数据驱动强化学习算法Policy Constraint Q-Learning(PCQL)来实现全麻药物剂量控制，添加了保守Q-Learning方法和策略约束项以确保智能体做出更安全的决策。 |
| [^31] | [GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models.](http://arxiv.org/abs/2303.10130) | 该研究调查了GPT（大语言模型）和相关技术对美国劳动力市场的潜在影响，发现大约80%的美国劳动力可能会受到10%的工作任务的影响，涵盖了所有工资水平和各行各业，预示着这些模型可能具有显著的经济、社会和政策影响。 |
| [^32] | [TKN: Transformer-based Keypoint Prediction Network For Real-time Video Prediction.](http://arxiv.org/abs/2303.09807) | TKN是一种基于Transformer的实时视频预测解决方案，通过受限信息提取和并行预测方案来提升预测过程的速度，具有更高的精度和更低的计算成本。 |
| [^33] | [Urban Regional Function Guided Traffic Flow Prediction.](http://arxiv.org/abs/2303.09789) | 本文提出了一个名为POI-MetaBlock的新模块，结合区域的功能性和交通特征，采用自注意力架构进行交通流预测。 |
| [^34] | [SemDeDup: Data-efficient learning at web-scale through semantic deduplication.](http://arxiv.org/abs/2303.09540) | SemDeDup是一种利用预训练模型的嵌入来识别和删除语义重复项的方法。通过对LAION的子集进行分析，SemDeDup可以最小化性能损失的同时删除50%的数据，实际上将训练时间减半。此外，SemDeDup在提供效率收益的同时改进了先前的方法。 |
| [^35] | [Translating Radiology Reports into Plain Language using ChatGPT and GPT-4 with Prompt Learning: Promising Results, Limitations, and Potential.](http://arxiv.org/abs/2303.09038) | 本文研究探讨利用ChatGPT将放射学报告翻译成通俗易懂的语言，平均得分为5分制的4.1分，信息缺失率和信息错误率均较低，ChatGPT提供的建议大都与放射学报告相关。 |
| [^36] | [Automated Interactive Domain-Specific Conversational Agents that Understand Human Dialogs.](http://arxiv.org/abs/2303.08941) | 本文介绍了利用大型语言模型和Answer Set Programming实现真正“理解”人类对话的AutoConcierge系统。该系统针对特定领域，为用户提供有关附近餐厅的建议。 |
| [^37] | [Bi-directional Distribution Alignment for Transductive Zero-Shot Learning.](http://arxiv.org/abs/2303.08698) | 本文提出了一种 Bi-VAEGAN 模型，通过双向分布对齐、L_2 范数特征归一化和更复杂的先验估计方法，大大改善了跨域零样本学习中的分布偏移问题。 |
| [^38] | [Image Guidance for Robot-Assisted Ankle Fracture Repair.](http://arxiv.org/abs/2303.08105) | 该研究旨在开发和验证一种图像引导框架，使机器人能够自动确定腓骨复位方向，进而提高骨折手术的效率和准确性，改善患者的手术效果，降低患者发生骨性关节炎的风险。 |
| [^39] | [The Science of Detecting LLM-Generated Texts.](http://arxiv.org/abs/2303.07205) | 本文综述了现有大型语言模型生成文本检测技术并提出了关键考虑因素，如开发全面评估指标和开源 LLM 所构成的威胁。 |
| [^40] | [Why is That a Good or Not a Good Frying Pan? -- Knowledge Representation for Functions of Objects and Tools for Design Understanding, Improvement, and Generation for Design Understanding, Improvement, and Generation.](http://arxiv.org/abs/2303.06152) | 本文演示了如何使用通用函数表示语言和框架来表示特定对象及其参与支持其设计的过程，从而实现深入的概念理解，可解释性的功能，使系统能够回答“为什么”问题。 |
| [^41] | [Computably Continuous Reinforcement-Learning Objectives are PAC-learnable.](http://arxiv.org/abs/2303.05518) | 本研究证明了计算连续的强化学习目标是可PAC学习的，这对于设计高效的强化学习算法打开了新的突破口。 |
| [^42] | [Bootstrap The Original Latent: Learning a Private Model from a Black-box Model.](http://arxiv.org/abs/2303.03709) | 本文提出了BPBA设置和BTOL训练策略两个新的方法，分别用于用户训练私有模型和利用基础/源模型。在三个不同的数据集上的实验表明，这些方法都是有效且稳健的。 |
| [^43] | [Seq-HyGAN: Sequence Classification via Hypergraph Attention Network.](http://arxiv.org/abs/2303.02393) | 本文提出了一种基于超图注意力网络的序列分类模型Seq-HyGAN，通过创建超图和引入注意力机制来处理序列数据中的复杂结构相似性，从而提高分类准确率。 |
| [^44] | [A Pathway Towards Responsible AI Generated Content.](http://arxiv.org/abs/2303.01325) | 本文探讨了AI生成内容的合理使用所面临的风险，包括隐私、偏见、毒性、错误信息和知识产权等，并提供有希望的解决方向。 |
| [^45] | [Safety without alignment.](http://arxiv.org/abs/2303.00752) | 本文讨论了基于伦理理性的替代人工智能安全方法。作者建议将伦理道德与理性联系起来，以获得明显的长期优势，提出了一种通过混合定理证明器在沙盒中实现的固有安全的实现路径。 |
| [^46] | [Markov Conditions and Factorization in Logical Credal Networks.](http://arxiv.org/abs/2302.14146) | 本文研究逻辑信任网络并探究不同马尔科夫条件的影响。我们发现没有有向循环的网络可以进行因子分解，而带有有向循环的网络则需要特别考虑不同的马尔科夫条件。 |
| [^47] | [AugGPT: Leveraging ChatGPT for Text Data Augmentation.](http://arxiv.org/abs/2302.13007) | AugGPT提出了一种基于ChatGPT的文本数据增强方法，该方法能够更忠实地保留正确标记的生成数据并提供足够的多样性，从而有效地缓解了自然语言处理任务中的限制样本量的问题。 |
| [^48] | [FrankenSplit: Saliency Guided Neural Feature Compression with Shallow Variational Bottleneck Injection.](http://arxiv.org/abs/2302.10681) | 本文提出了一种基于显著性指导的神经特征压缩与浅层变分瓶颈注入的新的资源意识压缩模型的框架，实现了比最先进的SC方法低60％的比特率，并且比现有的编解码标准的下放快16倍。 |
| [^49] | [SurvLIMEpy: A Python package implementing SurvLIME.](http://arxiv.org/abs/2302.10571) | 本文介绍了一个名为SurvLIMEpy的Python包，它实现了一种算法，可以计算适用于建模生存分析数据的机器学习算法的局部特征重要性，并支持各种生存模型。 |
| [^50] | [RePrompt: Automatic Prompt Editing to Refine AI-Generative Art Towards Precise Expressions.](http://arxiv.org/abs/2302.09466) | 本研究开发了一个名为RePrompt的自动化方法，通过优化文本提示来精确表达由AI生成的图像的情感表现力。 |
| [^51] | [T2I-Adapter: Learning Adapters to Dig out More Controllable Ability for Text-to-Image Diffusion Models.](http://arxiv.org/abs/2302.08453) | 该论文提出利用T2I模型隐含学习的知识来更加精确地控制生成结果。通过训练简单轻量级的T2I适配器来对齐内部知识与外部控制信号，实现在生成结果的颜色和结构方面丰富的控制和编辑效果。 |
| [^52] | [Practical Cross-System Shilling Attacks with Limited Access to Data.](http://arxiv.org/abs/2302.07145) | 本文提出了跨系统推销攻击的新概念，设计了一个名为 PC-Attack 的实用框架。这个框架只需要很少的受害者推荐系统模型和目标推荐系统数据的信息即可进行攻击，并在公共推荐系统数据上进行了自我监督训练和微调，因此攻击成功率较高。 |
| [^53] | [User-Centered Design (IX): A "User Experience 3.0" Paradigm Framework in the Intelligence Era.](http://arxiv.org/abs/2302.06681) | 本文提出了一种“UX 3.0”范式框架和相应的UX方法系统，旨在满足情报时代对用户体验的新要求。 |
| [^54] | [Learning from Noisy Crowd Labels with Logics.](http://arxiv.org/abs/2302.06337) | 这篇论文介绍了一种利用逻辑引导的从嘈杂的众包标签中学习的框架，能够改进文本分类和命名实体识别等任务中，学习从嘈杂数据中提取有效信息的方法，这种框架能够融合逻辑知识，提高现有技术水平。 |
| [^55] | [FGSI: Distant Supervision for Relation Extraction method based on Fine-Grained Semantic Information.](http://arxiv.org/abs/2302.02078) | 本研究提出了一种基于远程监督的关系抽取方法，该方法通过利用句子中的细粒度语义信息来减少干扰信息，提高了实体关系提取的准确性。 |
| [^56] | [Principled Reinforcement Learning with Human Feedback from Pairwise or $K$-wise Comparisons.](http://arxiv.org/abs/2301.11270) | 该论文提供了带有人类反馈强化学习问题的理论框架，证明了最大似然估计在Bradley-Terry-Luce和Plackett-Luce模型下收敛。此外，提出了在一定的覆盖假设下，基于悲观估计的MLE提供了性能更好的策略。在证明了真实MLE和以成对比较形式替代的备选MLE都可以在PL模型下收敛的同时，也表明了真实MLE的高效性。这些结果为RLHF算法提供了新的见解，并统一了RLHF问题和IRL问题。 |
| [^57] | [An Error-Guided Correction Model for Chinese Spelling Error Correction.](http://arxiv.org/abs/2301.06323) | 本文提出了一个基于误差引导的模型用于改进汉语拼写纠错，它采用了零-shot误差检测、新的损失函数和高度并行的解码等方法，在实验中表现优于先进方法。 |
| [^58] | [Towards an AI-enabled Connected Industry: AGV Communication and Sensor Measurement Datasets.](http://arxiv.org/abs/2301.03364) | 本文介绍了两个无线测量活动所提供的数据集，并将其与机器学习结合起来用于指纹识别、视线检测、服务质量预测或链路选择等任务。 |
| [^59] | [Approaching Peak Ground Truth.](http://arxiv.org/abs/2301.00243) | 介绍了PGT理论概念和近似PGT的定量技术，为评估和提高机器学习模型在生物医学领域中的性能提供了策略。 |
| [^60] | [MN-DS: A Multilabeled News Dataset for News Articles Hierarchical Classification.](http://arxiv.org/abs/2212.12061) | 本文介绍了一个包含10,917篇新闻文章的多标签数据集，可用于训练机器学习模型自动按主题对新闻文章进行分类，对新闻结构、分类和预测未来事件的研究人员非常有帮助。 |
| [^61] | [On Calibrating Semantic Segmentation Models: Analyses and An Algorithm.](http://arxiv.org/abs/2212.12053) | 本文系统研究了语义分割模型的校准问题，提出了一种简单而有效的方法——选择性缩放，通过将正确/错误预测分开进行缩放，并更加关注错误预测的逻辑平滑，此方法在语义分割校准上取得了良好效果。 |
| [^62] | [Query-as-context Pre-training for Dense Passage Retrieval.](http://arxiv.org/abs/2212.09598) | 本文提出了一种名为查询作为上下文的预训练技术，将查询作为上下文，形成一对通道-查询对，用于缓解密集型通道检索中可能存在的弱相关对，并在大规模基准测试上证明了其有效性和效率。 |
| [^63] | [Learning for Vehicle-to-Vehicle Cooperative Perception under Lossy Communication.](http://arxiv.org/abs/2212.08273) | 本文研究了复杂驾驶场景下可能存在的损失共享特征的情况对车辆协同感知的影响，并提出了一种新的损失通信感知特征融合方法，通过损失通信感知修复网络缓解了损失通信的副作用并增强了感知性能。 |
| [^64] | [Towards Holistic Surgical Scene Understanding.](http://arxiv.org/abs/2212.04582) | 本研究提出了一个新实验框架，PSI-AVA数据集，以实现对机器人辅助下的前列腺癌根治术视频的整体理解。同时，我们的实验结果证明了基于TAPIR的手术场景理解框架的有效性。 |
| [^65] | [LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models.](http://arxiv.org/abs/2212.04088) | 本研究提出了一种新颖的方法LLM-Planner，利用大型语言模型为实体代理进行少样本规划，以实体代理目前所在的环境为基础，增强LLMs生成和更新计划，实验表明其在多任务和快速学习新任务的通用代理的开发中具有很好的表现。 |
| [^66] | [PCT-CycleGAN: Paired Complementary Temporal Cycle-Consistent Adversarial Networks for Radar-Based Precipitation Nowcasting.](http://arxiv.org/abs/2211.15046) | 本文提出了一种基于配对互补时间循环一致对抗网络的雷达降水预测方法，该方法包括两个生成器网络和循环一致性损失和对抗性损失。实验证明，该方法在准确性和推广能力方面优于现有的技术方法。 |
| [^67] | [Shape, Pose, and Appearance from a Single Image via Bootstrapped Radiance Field Inversion.](http://arxiv.org/abs/2211.11674) | 本文提出了一个自回归光场反演框架，可以从单个图像中恢复 SDF 参数化的 3D 形状、姿态和外观，而无需准确的真实姿势，且速度快、计算有效。 |
| [^68] | [Point-MA2E: Masked and Affine Transformed AutoEncoder for Self-supervised Point Cloud Learning.](http://arxiv.org/abs/2211.06841) | 本文介绍了一种点云学习的自监督方法Point-MA2E，通过同时采用掩膜和仿射变换策略，实现了从损坏点云到还原点云的重建，扩展了目前掩膜方法的不足。 |
| [^69] | [The Sample Complexity of Online Contract Design.](http://arxiv.org/abs/2211.05732) | 本文解决了在线合同设计中一个悬而未决的问题，证明了指数级的$m$个样本就足以学习一个近乎最优的合同。 |
| [^70] | [Towards Improved Room Impulse Response Estimation for Speech Recognition.](http://arxiv.org/abs/2211.04473) | 本论文提出了一种新颖的基于GAN的架构，用于在声学环境中估计室内声道冲激响应，并在自动语音识别任务中展示了其性能优越性。 |
| [^71] | [NESTER: An Adaptive Neurosymbolic Method for Treatment Effect Estimation.](http://arxiv.org/abs/2211.04370) | NESTER是一种自适应的神经符号化方法进行治疗效果评估，将治疗效果估计的所有要求集成到一个框架中，该方法比现有最先进的方法在多个基准数据集上性能更好。 |
| [^72] | [Efficient Multi-order Gated Aggregation Network.](http://arxiv.org/abs/2211.03295) | 本文探索了现代卷积神经网络的表征能力，使用多阶博弈论交互的新视角，提出了一种新的纯卷积神经网络架构MogaNet，它表现出优异的可扩展性，并在多种典型视觉基准中以更高效的参数利用达到了与最先进模型竞争的效果。 |
| [^73] | [Broken Neural Scaling Laws.](http://arxiv.org/abs/2210.14891) | 本文提出了一个平滑破碎的幂律函数形式，可以准确地模拟和外推深度神经网络的缩放行为，适用于各种架构和大量不同任务，包括视觉、语言、音频、视频、生成建模、对比学习、机器人、不确定性估计/校准、对抗鲁棒性、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。 |
| [^74] | [Predictive Inference with Feature Conformal Prediction.](http://arxiv.org/abs/2210.00173) | 本文提出基于特征符合预测的预测推断方法，通过利用深度表示学习的归纳偏置，扩展了符合预测到语义特征空间。从理论和实验结果来看，该方法优于常规符合预测，并在大规模任务上展现了最先进性能。 |
| [^75] | [Safe Exploration Method for Reinforcement Learning under Existence of Disturbance.](http://arxiv.org/abs/2209.15452) | 本文提出了一种能够在存在扰动情况下安全进行强化学习探索的方法，该方法利用了所控制对象和扰动的部分先验知识，可以保证以预先指定的概率满足显式状态约束。 |
| [^76] | [Construction and Applications of Billion-Scale Pre-Trained Multimodal Business Knowledge Graph.](http://arxiv.org/abs/2209.15214) | 本文介绍了一个基于阿里巴巴集团的空前规模的 OpenBG 商业知识图谱，包含超过 88 百万实体和 26 亿三元组。它具有精细的分类和多模态事实，有助于推动商业智能化的发展。 |
| [^77] | [Multi-armed Bandit Learning on a Graph.](http://arxiv.org/abs/2209.09419) | 本文提出了一种基于乐观原则和离线图形规划算法的学习算法G-UCB，能够平衡长期探索利用，用于解决一种名为图赌博机的MAB扩展，从而获得最大化的收益。 |
| [^78] | [Active Exploration for Inverse Reinforcement Learning.](http://arxiv.org/abs/2207.08645) | AceIRL提出了一种新的逆强化学习算法，通过主动探索来学习奖励函数和策略，在不需要环境生成模型的情况下，能够确定可行奖励函数的置信区间，并找到侧重于环境中最有信息的区域的探索策略。 |
| [^79] | [Multitrack Music Transformer.](http://arxiv.org/abs/2207.06983) | 这篇论文提出了一种新的多轨音乐表示方法，可以支持各种不同的乐器，在短的序列长度下实现了性能上的显著提升，同时提出了一种新方法用于分析音乐自我关注，并验证了模型更关注与当前音符形成和谐跨度和位于同一八度的音符。 |
| [^80] | [Ask-AC: An Initiative Advisor-in-the-Loop Actor-Critic Framework.](http://arxiv.org/abs/2207.01955) | 本文提出了一种新颖的主动顾问演员-评论家框架，Ask-AC，它替换了传统的被动监督信号机制，实现了定制化和高效的信息交换，其中的两个互补组件允许代理主动寻求顾问干预和识别漏掉的不稳定状态。 |
| [^81] | [Robust Adversarial Attacks Detection based on Explainable Deep Reinforcement Learning For UAV Guidance and Planning.](http://arxiv.org/abs/2206.02670) | 本文提出了一种基于可解释的深度学习方法的创新性检测方案，以保护采用这些方法的无人机免受对抗攻击。 |
| [^82] | [Toward a realistic model of speech processing in the brain with self-supervised learning.](http://arxiv.org/abs/2206.01685) | 本研究针对语音处理问题，使用自监督学习的方法得到的特征与大脑神经元对于语音刺激的反应能够形成类似的层级，且解释了大脑活动的变化。该算法能够最少依赖先验语言和理解知识资源，并且需要的数据量远小于其它模型。 |
| [^83] | [Byzantine-Robust Federated Learning with Optimal Statistical Rates and Privacy Guarantees.](http://arxiv.org/abs/2205.11765) | 本文提出了一种具有近乎最优统计率的拜占庭鲁棒联邦学习协议，并展示了其与竞争协议相比的经验优越性，协议通过分桶可以结合隐私保障程序以对半诚实服务器进行安全保障。 |
| [^84] | [Deep Digging into the Generalization of Self-Supervised Monocular Depth Estimation.](http://arxiv.org/abs/2205.11083) | 本文探究了用于单目深度估计的骨干网络的泛化能力，并观察到Transformers具有很强的形状偏差。形状偏差的模型表现更好的单目深度估计泛化性能，作者新设计了一个CNN-Transformer混合网络，以提高单目深度估计的泛化性能。 |
| [^85] | [Sionna: An Open-Source Library for Next-Generation Physical Layer Research.](http://arxiv.org/abs/2203.11854) | Sionna是一个GPU加速的基于TensorFlow的开源库，实现了最先进算法，可以用于基准测试和端到端性能评估。它能够提供对神经网络的原生支持，使得研究人员能够更加专注于自己的研究。 |
| [^86] | [Exploring Variational Graph Auto-Encoders for Extract Class Refactoring Recommendation.](http://arxiv.org/abs/2203.08787) | 本文提出了一种利用变分图自编码器自动将上帝类提取为更具体职责的较小类别的方法，在五个开源项目上评估后结果表明有效。 |
| [^87] | [SuperAnimal models pretrained for plug-and-play analysis of animal behavior.](http://arxiv.org/abs/2203.07436) | SuperAnimal是一种能够开发和部署深度学习模型的方法，不需要额外的人工标注和模型训练，同时可用于超过45个物种进行视频推断，并具有微调模型效率高的优点。 |
| [^88] | [Calibration of Derivative Pricing Models: a Multi-Agent Reinforcement Learning Perspective.](http://arxiv.org/abs/2203.06865) | 本文利用多智能体强化学习提出校准衍生品定价模型问题的博弈论解决方案，并希望该方法可用于解决其他金融领域的问题。实验证明，该算法能够学习局部波动率以及最小化百慕大期权价格所需的路径依赖性。 |
| [^89] | [Contextual Semantic Embeddings for Ontology Subsumption Prediction.](http://arxiv.org/abs/2202.09791) | 本文提出了一种名为BERTSubs的新型子类预测方法，用于OWL本体类，它可以预测包括来自同一本体或另一个本体的命名类以及来自同一本体的存在限制等多种子类。 |
| [^90] | [Interactive configurator with FO(.) and IDP-Z3.](http://arxiv.org/abs/2202.00343) | 本文介绍了一种新的推理引擎IDP-Z3，它适用于FO(.)知识表示语言，并应用于自动构建基于知识的交互式配置器。 |
| [^91] | [Consistent 3D Hand Reconstruction in Video via self-supervised Learning.](http://arxiv.org/abs/2201.09548) | 本文提出了一种无需手部标注，在单目视频中基于自监督学习实现的一致三维手部重建方法。 |
| [^92] | [Augmenting astrophysical scaling relations with machine learning: application to reducing the Sunyaev-Zeldovich flux-mass scatter.](http://arxiv.org/abs/2201.01305) | 本文使用符号回归的机器学习工具，在Sunyaev-Zeldovich 荧光$-$星团质量关系中找到了一个新的代理变量，结合了$Y_\mathrm{SZ}$和电离气体浓度($c_\mathrm{gas}$)，极大地减小了该关系中的散射，提高了宇宙学分析的灵敏度。 |
| [^93] | [Active Learning for Event Extraction with Memory-based Loss Prediction Model.](http://arxiv.org/abs/2112.03073) | 本论文提出了一种基于深度学习的主动学习方法，采用基于批次的样本选择策略和记忆损失预测模型以降低事件注释成本，实验结果表明此方法优于现有主动学习方法且性能最优。 |
| [^94] | [Doxastic Extensions of \L ukasiewicz Logic.](http://arxiv.org/abs/2111.08564) | 本文提出了两类关于\L ukasiewicz逻辑的信念扩展，基于不同的信念概念进行建模，并证明了这些扩展的声音性和完整性定理。 |
| [^95] | [Towards Teachable Autotelic Agents.](http://arxiv.org/abs/2105.11977) | 本文提出了可教学自主智能体的概念，它们可以从内部和教学信号中同步学习，从而提高技能习得的效率，此举是构建具有人类级智能的代理的关键步骤。 |

# 详细

[^1]: 一种模型胜过上万个样本

    A model is worth tens of thousands of examples. (arXiv:2303.10608v1 [cs.LG])

    [http://arxiv.org/abs/2303.10608](http://arxiv.org/abs/2303.10608)

    研究了神经网络与传统基于数学数据生成模型的信号处理方法的数据需求差异，并在两个简单的问题上得到了实证结果。

    

    传统的基于数学数据生成模型的信号处理方法已被深度神经网络所取代，深度神经网络需要大量的数据。由于理论样本复杂度几乎无法评估，这些样本量通常使用粗略的经验法则进行估计。然而，这些规则仅建议网络应该何时起作用，但并不涉及传统方法。特别是，一个有趣的问题是：神经网络需要多少数据才能与传统的基于模型的方法保持同步或者，如果可能的话，超越它们？在本文中，我们通过两个简单的示例来从经验上研究这个问题，其中数据是根据精确定义的数学模型生成的，并且已知最优或最先进的数学数据无关解决方案。

    Traditional signal processing methods relying on mathematical data generation models have been cast aside in favour of deep neural networks, which require vast amounts of data. Since the theoretical sample complexity is nearly impossible to evaluate, these amounts of examples are usually estimated with crude rules of thumb. However, these rules only suggest when the networks should work, but do not relate to the traditional methods. In particular, an interesting question is: how much data is required for neural networks to be on par or outperform, if possible, the traditional model-based methods? In this work, we empirically investigate this question in two simple examples, where the data is generated according to precisely defined mathematical models, and where well-understood optimal or state-of-the-art mathematical data-agnostic solutions are known. A first problem is deconvolving one-dimensional Gaussian signals and a second one is estimating a circle's radius and location in rando
    
[^2]: 巨型移动边缘计算网络中的分层个性化联邦学习

    Hierarchical Personalized Federated Learning Over Massive Mobile Edge Computing Networks. (arXiv:2303.10580v1 [cs.LG])

    [http://arxiv.org/abs/2303.10580](http://arxiv.org/abs/2303.10580)

    本篇论文提出了一种分层个性化联邦学习算法，能够在巨型移动边缘计算网络中处理移动用户设备的异构性，并且实现了训练损失最小化和轮延迟降低的目标权衡。

    

    个性化联邦学习（PFL）是一种新的联邦学习范 paradigm，特别是针对移动边缘计算（MEC）网络中各种移动用户设备（UE）带来的异构问题。但是，由于UE数量不断增加以及带来的复杂行政工作，将PFL算法从其传统的双层框架切换到多层框架是可行的。本文提出了分层个性化联邦学习（HPFL），一种用于在巨型MEC网络中部署PFL的算法。在HPFL中，UE被划分为多个集群，每个集群中的UE同步将其本地更新转发到边缘服务器（ES）进行边缘模型聚合，而ES半异步地将其边缘模型转发到云服务器进行全局模型聚合。上述训练方式在训练损失和轮延迟之间达到了一个权衡。HPFL以分层方式结合了训练损失最小化和轮延迟降低的目标，从而在培训效率和通信开销方面比传统的PFL算法实现了更好的性能。

    Personalized Federated Learning (PFL) is a new Federated Learning (FL) paradigm, particularly tackling the heterogeneity issues brought by various mobile user equipments (UEs) in mobile edge computing (MEC) networks. However, due to the ever-increasing number of UEs and the complicated administrative work it brings, it is desirable to switch the PFL algorithm from its conventional two-layer framework to a multiple-layer one. In this paper, we propose hierarchical PFL (HPFL), an algorithm for deploying PFL over massive MEC networks. The UEs in HPFL are divided into multiple clusters, and the UEs in each cluster forward their local updates to the edge server (ES) synchronously for edge model aggregation, while the ESs forward their edge models to the cloud server semi-asynchronously for global model aggregation. The above training manner leads to a tradeoff between the training loss in each round and the round latency. HPFL combines the objectives of training loss minimization and round 
    
[^3]: 无监督学习求解旅行商问题

    Unsupervised Learning for Solving the Travelling Salesman Problem. (arXiv:2303.10538v1 [cs.AI])

    [http://arxiv.org/abs/2303.10538](http://arxiv.org/abs/2303.10538)

    无监督学习框架UTSP能够对旅行商问题进行求解，它使用图神经网络作为基础模型，在保证路径为哈密顿循环的前提下，能够找到最短路径。相较于其他方法，UTSP在训练样本与参数数量上占用更少的资源，且性能更佳。

    

    我们提出了UTSP，一种利用无监督学习框架求解旅行商问题（TSP）的方法。我们使用替代损失训练图神经网络（GNN）。GNN输出一个热力图表示每个边成为最优路径的概率。然后，我们应用局部搜索根据热力图生成最终预测。我们的损失函数由两部分组成：一部分推动模型找到最短的路径，另一部分作为约束条件，确保路径形成哈密顿循环。实验结果表明，UTSP优于现有的数据驱动TSP启发式算法。我们的方法参数效率和数据效率均较高：与强化学习或监督学习方法相比，该模型仅占用约10％的参数和约0.2％的训练样本。

    We propose UTSP, an unsupervised learning (UL) framework for solving the Travelling Salesman Problem (TSP). We train a Graph Neural Network (GNN) using a surrogate loss. The GNN outputs a heat map representing the probability for each edge to be part of the optimal path. We then apply local search to generate our final prediction based on the heat map. Our loss function consists of two parts: one pushes the model to find the shortest path and the other serves as a surrogate for the constraint that the route should form a Hamiltonian Cycle. Experimental results show that UTSP outperforms the existing data-driven TSP heuristics. Our approach is parameter efficient as well as data efficient: the model takes $\sim$ 10\% of the number of parameters and $\sim$ 0.2\% of training samples compared with reinforcement learning or supervised learning methods.
    
[^4]: TempT：测试时间自适应的时间一致性方法

    TempT: Temporal consistency for Test-time adaptation. (arXiv:2303.10536v1 [cs.CV])

    [http://arxiv.org/abs/2303.10536](http://arxiv.org/abs/2303.10536)

    本文提出一种新颖的方法TempT，通过确保连续帧之间的预测具有时间上的一致性，实现了对视频的测试时自适应。其仅利用视觉单模态特征，并在面部表情识别等计算机视觉任务中具有广泛应用，并在实验中取得了有竞争力的表现，为其在各种实际应用中提供了令人信服的概念证明。

    

    本技术报告介绍了TempT，一种新颖的方法，通过确保连续帧之间的预测具有时间上的一致性，实现对视频的测试时自适应。TempT是一种强大的工具，在计算机视觉任务中具有广泛应用，包括视频中的面部表情识别（FER）。我们将TempT在AffWild2数据集上作为情感行为分析比赛（ABAW）第五届研讨会和竞赛中的表情分类挑战的一部分进行了评估。我们的方法仅专注于数据的视觉单模态特征，并利用了流行的二维卷积神经网络骨干，而不是较大的序列或基于注意力的模型。我们的实验结果表明，TempT与往年报告的表现相比具有竞争力，其有效性为其在各种实际应用中的使用提供了令人信服的概念证明。

    In this technical report, we introduce TempT, a novel method for test time adaptation on videos by ensuring temporal coherence of predictions across sequential frames. TempT is a powerful tool with broad applications in computer vision tasks, including facial expression recognition (FER) in videos. We evaluate TempT's performance on the AffWild2 dataset as part of the Expression Classification Challenge at the 5th Workshop and Competition on Affective Behavior Analysis in the wild (ABAW). Our approach focuses solely on the unimodal visual aspect of the data and utilizes a popular 2D CNN backbone, in contrast to larger sequential or attention based models. Our experimental results demonstrate that TempT has competitive performance in comparison to previous years reported performances, and its efficacy provides a compelling proof of concept for its use in various real world applications.
    
[^5]: 无监督解释性基础抽取用于基于概念的视觉解释

    Unsupervised Interpretable Basis Extraction for Concept-Based Visual Explanations. (arXiv:2303.10523v1 [cs.CV])

    [http://arxiv.org/abs/2303.10523](http://arxiv.org/abs/2303.10523)

    本文提出了一种无监督的方法，通过对CNN进行转换，从而更好地解释中间层的表示，提取了一个可解释性欠完备基础，并证明该方法在各种网络结构和训练数据集上都很有效。

    

    研究人员尝试用人类可以理解的概念来解释CNN图像分类器预测和中间层表示。本文提出了一种无监督后处理方法，通过查找解释像素激活的稀疏二值化转换表示的特征空间旋转来提取解释性欠完备基础。我们对现有的流行CNN进行了实验，并证明了我们方法在网络架构和训练数据集上提取解释性基础的有效性。最后，我们扩展了文献中的基础可解释性度量，并表明，当中间层表示被转换为我们方法提取的基础时，它们变得更易解释。

    An important line of research attempts to explain CNN image classifier predictions and intermediate layer representations in terms of human understandable concepts. In this work, we expand on previous works in the literature that use annotated concept datasets to extract interpretable feature space directions and propose an unsupervised post-hoc method to extract a disentangling interpretable basis by looking for the rotation of the feature space that explains sparse one-hot thresholded transformed representations of pixel activations. We do experimentation with existing popular CNNs and demonstrate the effectiveness of our method in extracting an interpretable basis across network architectures and training datasets. We make extensions to the existing basis interpretability metrics found in the literature and show that, intermediate layer representations become more interpretable when transformed to the bases extracted with our method. Finally, using the basis interpretability metrics
    
[^6]: 学习、遗忘和重学：深度神经网络的在线学习范式

    Learn, Unlearn and Relearn: An Online Learning Paradigm for Deep Neural Networks. (arXiv:2303.10455v1 [cs.LG])

    [http://arxiv.org/abs/2303.10455](http://arxiv.org/abs/2303.10455)

    学习、遗忘和重学（LURE）是一种深度神经网络的在线学习范式，它在遗忘阶段和重学阶段之间进行交替，通过有选择地遗忘模型中的不良信息和对泛化性的学习来在效率和泛化之间取得平衡。

    

    深度神经网络（DNN）通常是在提前提供完整的训练数据集的前提下进行训练的。然而，在现实世界的情况下，数据经常会随着时间的推移而以块的形式出现。这就引发了关于训练DNN的最佳策略的重要考虑，例如是否在每个新数据块到达时使用微调的方法（温启动）或者每当有新的数据块可用时从头开始重新训练它们。虽然后者用于训练可以消耗更多的资源，但最近的研究指出了温启动模型的泛化能力缺乏。因此，为了在效率和泛化之间取得平衡，我们介绍了一种深度神经网络的在线学习范式——学习、遗忘和重学（LURE）。LURE在遗忘阶段和重学阶段之间进行交替，遗忘阶段通过数据依赖方式的权重重新初始化有选择地遗忘模型中的不良信息，而重学阶段则强调对泛化性的学习。

    Deep neural networks (DNNs) are often trained on the premise that the complete training data set is provided ahead of time. However, in real-world scenarios, data often arrive in chunks over time. This leads to important considerations about the optimal strategy for training DNNs, such as whether to fine-tune them with each chunk of incoming data (warm-start) or to retrain them from scratch with the entire corpus of data whenever a new chunk is available. While employing the latter for training can be resource-intensive, recent work has pointed out the lack of generalization in warm-start models. Therefore, to strike a balance between efficiency and generalization, we introduce Learn, Unlearn, and Relearn (LURE) an online learning paradigm for DNNs. LURE interchanges between the unlearning phase, which selectively forgets the undesirable information in the model through weight reinitialization in a data-dependent manner, and the relearning phase, which emphasizes learning on generaliza
    
[^7]: 一种用于音频信号处理的内容自适应可学习时频表示法

    A Content Adaptive Learnable Time-Frequency Representation For Audio Signal Processing. (arXiv:2303.10446v1 [cs.SD])

    [http://arxiv.org/abs/2303.10446](http://arxiv.org/abs/2303.10446)

    该论文提出了一种用于音频信号处理的内容自适应可学习时频表示法，通过学习卷积滤波器与变换器架构来将小的波形块投影到小的潜在维度上。

    

    我们提出了一个可学习的内容自适应前端，用于音频信号处理。在深度学习的现代出现之前，我们使用固定表示的、不可学习的前端，如谱图或梅尔谱图，带/不带神经结构。随着卷积架构支持ASR和声学场景理解等各种应用，转向可学习前端，即从头开始学习和优化特定任务所需的基础函数和权重。在没有卷积块的变形器架构中，线性层将小的波形块投影到小的潜在维度上，然后将它们馈送到变形器架构中。在这项工作中，我们提出了一种计算内容自适应学习时频表示的方法。

    We propose a learnable content adaptive front end for audio signal processing. Before the modern advent of deep learning, we used fixed representation non-learnable front-ends like spectrogram or mel-spectrogram with/without neural architectures. With convolutional architectures supporting various applications such as ASR and acoustic scene understanding, a shift to a learnable front ends occurred in which both the type of basis functions and the weight were learned from scratch and optimized for the particular task of interest. With the shift to transformer-based architectures with no convolutional blocks present, a linear layer projects small waveform patches onto a small latent dimension before feeding them to a transformer architecture. In this work, we propose a way of computing a content-adaptive learnable time-frequency representation. We pass each audio signal through a bank of convolutional filters, each giving a fixed-dimensional vector. It is akin to learning a bank of finit
    
[^8]: 边缘计算中拜占庭鲁棒的联邦学习

    Byzantine-Resilient Federated Learning at Edge. (arXiv:2303.10434v1 [cs.DC])

    [http://arxiv.org/abs/2303.10434](http://arxiv.org/abs/2303.10434)

    本文提出了一种适用于处理重尾数据并在拜占庭攻击下具备鲁棒性的联邦学习算法，同时采用梯度压缩技术来减少通信开销。

    

    近年来，拜占庭容错和通信效率在边缘联邦学习中备受关注。然而，现有算法在处理真实世界中表现具有重尾性质的不规则数据时可能会失败。为了解决这个问题，我们研究了边缘联邦学习中的随机凸和非凸优化问题，并展示了如何同时保持拜占庭容错、通信效率和最优统计误差率来处理重尾数据。具体来说，我们首先提出了一种支持处理重尾数据、同时在标准假设下收敛的拜占庭容错分布式梯度下降算法。为了减少通信开销，我们进一步提出了另一种算法，采用梯度压缩技术在学习过程中节省通信成本。理论分析表明，我们的算法在保持对拜占庭攻击的鲁棒性的同时，能够高概率地实现最优统计速率。我们对合成和现实世界数据集进行了广泛的实验验证。

    Both Byzantine resilience and communication efficiency have attracted tremendous attention recently for their significance in edge federated learning. However, most existing algorithms may fail when dealing with real-world irregular data that behaves in a heavy-tailed manner. To address this issue, we study the stochastic convex and non-convex optimization problem for federated learning at edge and show how to handle heavy-tailed data while retaining the Byzantine resilience, communication efficiency and the optimal statistical error rates simultaneously. Specifically, we first present a Byzantine-resilient distributed gradient descent algorithm that can handle the heavy-tailed data and meanwhile converge under the standard assumptions. To reduce the communication overhead, we further propose another algorithm that incorporates gradient compression techniques to save communication costs during the learning process. Theoretical analysis shows that our algorithms achieve order-optimal st
    
[^9]: NoisyHate：在人类编写的在线扰动下对内容审核机器学习模型进行基准测试

    NoisyHate: Benchmarking Content Moderation Machine Learning Models with Human-Written Perturbations Online. (arXiv:2303.10430v1 [cs.LG])

    [http://arxiv.org/abs/2303.10430](http://arxiv.org/abs/2303.10430)

    本文提出了一个包含人类编写的在线扰动的测试集，用于毒性言论检测模型的评估。

    

    在社交媒体上，具有有害内容的在线文本是一种威胁，可能会引起网络骚扰。尽管许多平台采取了措施，例如基于机器学习的仇恨言论检测系统来减少其影响，但那些有害内容发布者仍然可以通过修改有害词汇的拼写来逃避系统。这些修改后的单词也称为人类编写的文本扰动。许多研究开发了一定的技术来生成对抗样本，以帮助机器学习模型获得识别这些扰动的能力。然而，机器生成的扰动与人类编写的扰动之间仍存在差距。在本文中，我们介绍了一个包含人类编写的在线扰动的基准测试集，用于毒性言论检测模型。我们还招募了一组工人来评估此测试集的质量并删除低质量的样本。同时，为了检查我们的扰动是否可以归一化为其干净版本，我们还创建了一个相关的测试集。

    Online texts with toxic content are a threat in social media that might cause cyber harassment. Although many platforms applied measures, such as machine learning-based hate-speech detection systems, to diminish their effect, those toxic content publishers can still evade the system by modifying the spelling of toxic words. Those modified words are also known as human-written text perturbations. Many research works developed certain techniques to generate adversarial samples to help the machine learning models obtain the ability to recognize those perturbations. However, there is still a gap between those machine-generated perturbations and human-written perturbations. In this paper, we introduce a benchmark test set containing human-written perturbations online for toxic speech detection models. We also recruited a group of workers to evaluate the quality of this test set and dropped low-quality samples. Meanwhile, to check if our perturbation can be normalized to its clean version, w
    
[^10]: 提高少样本目标检测的新类别的识别方法

    Identification of Novel Classes for Improving Few-Shot Object Detection. (arXiv:2303.10422v1 [cs.CV])

    [http://arxiv.org/abs/2303.10422](http://arxiv.org/abs/2303.10422)

    该论文提出一种半监督算法，利用未标注的新物体来提高少样本目标检测的性能，主要包括使用分层三元分类区域提议网络来定位潜在的未标注新物体，并为它们分配新的目标性标签。

    

    传统的深度神经网络训练需要大量的标注图像，这是一项繁重且耗时的任务，特别是对于罕见的物体。少样本目标检测(FSOD)方法通过仅使用每个类别的少量训练样本实现强大的目标检测。对于FSOD来说一个未被探索的挑战是未标注的新类别的实例出现在背景中，这些物体表现类似于标签噪音，导致FSOD性能下降。我们开发了一种半监督算法来检测并利用这些未标注的新物体作为训练时的正样本，以提高FSOD的性能。具体而言，我们提出了一种分层三元分类区域提议网络(HTRPN)来定位潜在的未标注新物体并为它们分配新的目标性标签。我们改进了区域提议网络(RPN)的层次抽样策略，也提高了性能。

    Conventional training of deep neural networks requires a large number of the annotated image which is a laborious and time-consuming task, particularly for rare objects. Few-shot object detection (FSOD) methods offer a remedy by realizing robust object detection using only a few training samples per class. An unexplored challenge for FSOD is that instances from unlabeled novel classes that do not belong to the fixed set of training classes appear in the background. These objects behave similarly to label noise, leading to FSOD performance degradation. We develop a semi-supervised algorithm to detect and then utilize these unlabeled novel objects as positive samples during training to improve FSOD performance. Specifically, we propose a hierarchical ternary classification region proposal network (HTRPN) to localize the potential unlabeled novel objects and assign them new objectness labels. Our improved hierarchical sampling strategy for the region proposal network (RPN) also boosts the
    
[^11]: 视频中情感估计的多模态特征提取和基于注意力的融合

    Mutilmodal Feature Extraction and Attention-based Fusion for Emotion Estimation in Videos. (arXiv:2303.10421v1 [cs.CV])

    [http://arxiv.org/abs/2303.10421](http://arxiv.org/abs/2303.10421)

    本文介绍了一个基于注意力的多模态框架用于情感估计，在CVPR 2023 ABAW竞赛中取得了0.361的准确度。

    

    人机交互技术的不断改进使得计算情感成为可能。本文介绍了我们在CVPR 2023 ABAW竞赛中提交的作品。情感分析应该从多个维度入手，填补单一不完善的情感通道，最终通过拟合多个结果确定情感倾向。因此，我们利用比赛数据集中不同长度的视频中提取的多模态特征，包括音频、姿势和图像。我们提出了一个基于注意力的多模态框架用于情感估计。我们的系统在验证数据集上取得了0.361的准确度。代码可在[https://github.com/xkwangcn/ABAW-5th-RT-IAI]获取。

    The continuous improvement of human-computer interaction technology makes it possible to compute emotions. In this paper, we introduce our submission to the CVPR 2023 Competition on Affective Behavior Analysis in-the-wild (ABAW). Sentiment analysis in human-computer interaction should, as far as possible Start with multiple dimensions, fill in the single imperfect emotion channel, and finally determine the emotion tendency by fitting multiple results. Therefore, We exploited multimodal features extracted from video of different lengths from the competition dataset, including audio, pose and images. Well-informed emotion representations drive us to propose a Attention-based multimodal framework for emotion estimation. Our system achieves the performance of 0.361 on the validation dataset. The code is available at [https://github.com/xkwangcn/ABAW-5th-RT-IAI].
    
[^12]: ExplainFix: 可解释的固定空间深度神经网络

    ExplainFix: Explainable Spatially Fixed Deep Networks. (arXiv:2303.10408v1 [cs.CV])

    [http://arxiv.org/abs/2303.10408](http://arxiv.org/abs/2303.10408)

    ExplainFix采用固定滤波器和精简的网络参数，提高了深度神经网络的可解释性和训练速度。

    

    本研究提出了两个设计原则：卷积神经网络的所有空间滤波器权重可以在初始化时固定，而不必学习；只需很少的网络参数即可。本研究通过可视化模型解释、速度和准确性提升以及新的深度卷积神经网络工具做出了贡献。ExplainFix模型比完全学习的模型少了多达100倍的空间滤波器核，而匹配或提高了准确性。

    Is there an initialization for deep networks that requires no learning? ExplainFix adopts two design principles: the "fixed filters" principle that all spatial filter weights of convolutional neural networks can be fixed at initialization and never learned, and the "nimbleness" principle that only few network parameters suffice. We contribute (a) visual model-based explanations, (b) speed and accuracy gains, and (c) novel tools for deep convolutional neural networks. ExplainFix gives key insights that spatially fixed networks should have a steered initialization, that spatial convolution layers tend to prioritize low frequencies, and that most network parameters are not necessary in spatially fixed models. ExplainFix models have up to 100x fewer spatial filter kernels than fully learned models and matching or improved accuracy. Our extensive empirical analysis confirms that ExplainFix guarantees nimbler models (train up to 17\% faster with channel pruning), matching or improved predict
    
[^13]: 3DQD: 基于部分离散扩散过程的广义深度三维形状先验模型

    3DQD: Generalized Deep 3D Shape Prior via Part-Discretized Diffusion Process. (arXiv:2303.10406v1 [cs.CV])

    [http://arxiv.org/abs/2303.10406](http://arxiv.org/abs/2303.10406)

    该论文提出了一种广义的深度三维形状先验模型，可以用于多种三维任务，其使用向量量化变分自编码器和离散扩散生成器来精确捕获局部精细的形状信息，并引入多频率融合模块来抑制高频形状特征波动，广泛实验表明其在各种三维形状生成任务上表现出优异的性能。

    

    我们开发了一个广义的三维形状生成先验模型，专门针对多种三维任务，包括无条件形状生成、点云完成和跨模态形状生成等。一方面，为了精确捕获局部精细的形状信息，我们使用向量量化变分自编码器（VQ-VAE）来基于广泛的任务训练数据学习紧凑的码本并索引本地几何信息。另一方面，我们引入了离散扩散生成器来建模不同标记之间固有的结构依赖性。同时，我们开发了一个多频率融合模块（MFM），以多频率上下文信息为指导，抑制高频形状特征的波动。上述设计共同配备了我们提出的三维形状先验模型高保真度、多样性特征和跨模态对齐的能力，广泛的实验表明，在各种三维形状生成任务上表现出优异的性能。

    We develop a generalized 3D shape generation prior model, tailored for multiple 3D tasks including unconditional shape generation, point cloud completion, and cross-modality shape generation, etc. On one hand, to precisely capture local fine detailed shape information, a vector quantized variational autoencoder (VQ-VAE) is utilized to index local geometry from a compactly learned codebook based on a broad set of task training data. On the other hand, a discrete diffusion generator is introduced to model the inherent structural dependencies among different tokens. In the meantime, a multi-frequency fusion module (MFM) is developed to suppress high-frequency shape feature fluctuations, guided by multi-frequency contextual information. The above designs jointly equip our proposed 3D shape prior model with high-fidelity, diverse features as well as the capability of cross-modality alignment, and extensive experiments have demonstrated superior performances on various 3D shape generation ta
    
[^14]: FedRight: 一种有效的联邦学习模型版权保护方法

    FedRight: An Effective Model Copyright Protection for Federated Learning. (arXiv:2303.10399v1 [cs.CR])

    [http://arxiv.org/abs/2303.10399](http://arxiv.org/abs/2303.10399)

    FedRight 使用生成对抗性样本提取模型特征，即模型指纹，实现了对联邦学习模型版权的保护。它在有效性、安全性、鲁棒性和效率方面的性能均优于以前的工作。

    

    联邦学习（FL）是一种有效的分布式机器学习框架，它实现了模型训练和同时保护本地数据隐私。由于其出色的性能和可观的利润，它已被应用于广泛的实践领域。但是，谁拥有模型，如何保护版权已成为一个真正的问题。现有的中心化场景下的财产权保护方法（如水印嵌入和模型指纹）直观上能够解决 FL 中的版权问题。但是，由于 FL 的分布式性质，在不共享数据、参数聚合和联合训练设置方面仍然存在挑战。我们首次正式定义了 FL 的版权保护问题，并提出了 FedRight 来保护基于模型指纹的模型版权，即通过生成对抗性样本来提取模型特征。FedRight 在四个关键方面的性能表现优于以前的工作：（i）有效性：它通过对抗性样本提取模型特征，可以由第三方进行验证；（ii）安全性：它为本地模型提供保护，并防止潜在攻击者窃取模型；（iii）鲁棒性：它可以抵御不同类型的攻击，并在各种场景下实现高效的保护性能；（iv）效率：它引入轻量化和低计算开销进行训练和推断。

    Federated learning (FL), an effective distributed machine learning framework, implements model training and meanwhile protects local data privacy. It has been applied to a broad variety of practice areas due to its great performance and appreciable profits. Who owns the model, and how to protect the copyright has become a real problem. Intuitively, the existing property rights protection methods in centralized scenarios (e.g., watermark embedding and model fingerprints) are possible solutions for FL. But they are still challenged by the distributed nature of FL in aspects of the no data sharing, parameter aggregation, and federated training settings. For the first time, we formalize the problem of copyright protection for FL, and propose FedRight to protect model copyright based on model fingerprints, i.e., extracting model features by generating adversarial examples as model fingerprints. FedRight outperforms previous works in four key aspects: (i) Validity: it extracts model features
    
[^15]: 基于WFST框架的RNN-Transducer Losses强大且可扩展的实现

    Powerful and Extensible WFST Framework for RNN-Transducer Losses. (arXiv:2303.10384v1 [eess.AS])

    [http://arxiv.org/abs/2303.10384](http://arxiv.org/abs/2303.10384)

    本文提出了一个基于WFST框架的的RNN-Transducer Losses强大且可扩展的实现，“Compose-Transducer”和“Grid-Transducer”，并引入了新的W-Transducer Loss来展示组件的易扩展性。在实验中，W-Transducer（W-RNNT）表现出比标准RNN-T更好的性能。

    

    本文提出了一个基于加权有限状态转移器（WFST）的框架，以简化对RNN-Transducer（RNN-T） Losses的修改开发。现有的RNN-T实现使用与CUDA相关的代码，难以扩展和调试。WFST易于构建和扩展，并允许通过可视化进行调试。我们介绍了两个基于WFST的RNN-T实现：（1）“Compose-Transducer”，它基于声学和文本架构的WFST图组合，计算效率高和易于修改；（2）“Grid-Transducer”，直接构建晶格用于进一步计算，最紧凑和计算效率最高。我们通过引入新的W-Transducer Loss，即Connectionist Temporal Classification with Wild Cards的适应性，展示了组件的易扩展性。在缺少转录开头部分的弱监督数据设置中，W-Transducer（W-RNNT）始终优于标准RNN-T。

    This paper presents a framework based on Weighted Finite-State Transducers (WFST) to simplify the development of modifications for RNN-Transducer (RNN-T) loss. Existing implementations of RNN-T use CUDA-related code, which is hard to extend and debug. WFSTs are easy to construct and extend, and allow debugging through visualization. We introduce two WFST-powered RNN-T implementations: (1) "Compose-Transducer", based on a composition of the WFST graphs from acoustic and textual schema -- computationally competitive and easy to modify; (2) "Grid-Transducer", which constructs the lattice directly for further computations -- most compact, and computationally efficient. We illustrate the ease of extensibility through introduction of a new W-Transducer loss -- the adaptation of the Connectionist Temporal Classification with Wild Cards. W-Transducer (W-RNNT) consistently outperforms the standard RNN-T in a weakly-supervised data setup with missing parts of transcriptions at the beginning and 
    
[^16]: CroSel: 用于部分标签学习的自信伪标签的跨选择

    CroSel: Cross Selection of Confident Pseudo Labels for Partial-Label Learning. (arXiv:2303.10365v1 [cs.LG])

    [http://arxiv.org/abs/2303.10365](http://arxiv.org/abs/2303.10365)

    CroSel是一种处理伪标签噪声的新方法，通过利用历史预测信息和一致性正则化项来准确识别部分标签数据的真实标签。

    

    部分标签学习(PLL)是一个重要的弱监督学习问题，它允许每个训练示例有一个候选标签集，而不是一个单一的ground-truth标签。已经广泛探索了基于识别的方法来解决PLL中的标签歧义问题，这些方法将真实标签视为要识别的潜在变量。然而，准确和完整地识别真实标签仍然具有挑战性，这会在模型训练过程中导致伪标签中的噪声。本文提出了一种名为CroSel的新方法，该方法利用模型的历史预测信息来识别大多数训练示例的真实标签。首先，我们引入了一种交叉选择策略，使得两个深度模型可以相互选择部分标记数据的真实标签。此外，我们提出了一种新颖的一致性正则化项co-mix，以避免因虚假选择而引起的样本浪费和微小噪声。通过这种方式，CroSel能够挑选出大多数示例的真实标签。

    Partial-label learning (PLL) is an important weakly supervised learning problem, which allows each training example to have a candidate label set instead of a single ground-truth label. Identification-based methods have been widely explored to tackle label ambiguity issues in PLL, which regard the true label as a latent variable to be identified. However, identifying the true labels accurately and completely remains challenging, causing noise in pseudo labels during model training. In this paper, we propose a new method called CroSel, which leverages historical prediction information from models to identify true labels for most training examples. First, we introduce a cross selection strategy, which enables two deep models to select true labels of partially labeled data for each other. Besides, we propose a novel consistent regularization term called co-mix to avoid sample waste and tiny noise caused by false selection. In this way, CroSel can pick out the true labels of most examples 
    
[^17]: LossMix：简化和广泛应用 Mixup 于目标检测和更多领域

    LossMix: Simplify and Generalize Mixup for Object Detection and Beyond. (arXiv:2303.10343v1 [cs.CV])

    [http://arxiv.org/abs/2303.10343](http://arxiv.org/abs/2303.10343)

    本论文提出了一种称为 Supervision Interpolation 的新概念框架，通过放松和推广 Mixup 提供了一种全新的插值增强视角，并在此基础上提出了一种名为 LossMix 的简单而多功能的正则化方法，能够增强物体检测器的性能和鲁棒性，或者说LossMix 在目标检测和其他领域中表现出色。

    

    数据混合增强广泛应用于图像分类任务中，但由于空间错位、前景/背景区分以及多个实例的挑战，这些技术不易应用于目标检测。本文提出一种称为监督插值的新概念框架，通过放松和推广 Mixup 提供了一种全新的插值增强视角，然后在这个框架的基础上，提出了 LossMix，这是一种简单而多功能的正则化方法，能够增强物体检测器的性能和鲁棒性。我们的关键insight是，通过插值损失误差来调整训练可以有效规范混合数据的训练，而不是使用ground truth标签。在PASCAL VOC和MS COCO数据集上的实证结果表明，LossMix始终优于当前流行的混合策略，并且我们设计了一种两阶段领域m...

    The success of data mixing augmentations in image classification tasks has been well-received. However, these techniques cannot be readily applied to object detection due to challenges such as spatial misalignment, foreground/background distinction, and plurality of instances. To tackle these issues, we first introduce a novel conceptual framework called Supervision Interpolation, which offers a fresh perspective on interpolation-based augmentations by relaxing and generalizing Mixup. Building on this framework, we propose LossMix, a simple yet versatile and effective regularization that enhances the performance and robustness of object detectors and more. Our key insight is that we can effectively regularize the training on mixed data by interpolating their loss errors instead of ground truth labels. Empirical results on the PASCAL VOC and MS COCO datasets demonstrate that LossMix consistently outperforms currently popular mixing strategies. Furthermore, we design a two-stage domain m
    
[^18]: 一个通用的人工智能助手嵌入开源放射学信息系统中

    A general-purpose AI assistant embedded in an open-source radiology information system. (arXiv:2303.10338v1 [cs.AI])

    [http://arxiv.org/abs/2303.10338](http://arxiv.org/abs/2303.10338)

    该论文讨论了如何在开源放射学信息系统中引入一个通用的人工智能助手，通过Few-shot学习和Swarm学习方法，AI模型能够不断重新训练并学习从放射学家的更正中学习和改进。

    

    放射学的AI模型已经在接近或超越人类的表现方面取得了重大进展。然而，由于缺乏卫生信息标准、上下文和工作流差异以及数据标注差异，AI模型与人类放射学家的合作仍然是一个未被探索的挑战。为了克服这些挑战，我们将使用DICOM标准SR注释的AI模型服务集成到开源的LibreHealth放射学信息系统（RIS）中的OHIF查看器中。在本文中，我们描述了该平台的新型人工智能合作能力，包括Few-shot学习和Swarm学习方法来不断重新训练AI模型。基于机器教学的概念，我们在RIS中开发了一种主动学习策略，使人类放射学家可以启用/禁用AI注释以及“修复”/重新标注AI注释。这些注释然后被用来重新训练模型。这有助于建立放射学家和AI之间的合作，其中AI充当助手，在检测到异常时可以提示放射学家，同时从放射学家的更正中学习和改进。

    Radiology AI models have made significant progress in near-human performance or surpassing it. However, AI model's partnership with human radiologist remains an unexplored challenge due to the lack of health information standards, contextual and workflow differences, and data labeling variations. To overcome these challenges, we integrated an AI model service that uses DICOM standard SR annotations into the OHIF viewer in the open-source LibreHealth Radiology Information Systems (RIS). In this paper, we describe the novel Human-AI partnership capabilities of the platform, including few-shot learning and swarm learning approaches to retrain the AI models continuously. Building on the concept of machine teaching, we developed an active learning strategy within the RIS, so that the human radiologist can enable/disable AI annotations as well as "fix"/relabel the AI annotations. These annotations are then used to retrain the models. This helps establish a partnership between the radiologist
    
[^19]: 一种面向语义分割的边缘感知即插即用方案

    Edge-aware Plug-and-play Scheme for Semantic Segmentation. (arXiv:2303.10307v1 [cs.CV])

    [http://arxiv.org/abs/2303.10307](http://arxiv.org/abs/2303.10307)

    本文提出了一种抽象且通用的边缘监督方法，可以轻松快速地应用于任何语义分割模型中，称为Edge-aware Plug-and-play Scheme (EPS)，其核心是边缘宽度/厚度保持的指导性语义分割。

    

    语义分割是一种经典且基础的计算机视觉问题，旨在将每个像素分配到其对应的类别。近期的一些方法引入了基于边缘信息的方法以提高分割性能。然而，这些方法仅限于特定的网络结构，无法转移到其他模型或任务中。因此，我们提出了一种抽象且通用的边缘监督方法，称为Edge-aware Plug-and-play Scheme (EPS)，可以轻松快速地应用于任何语义分割模型中。该方法的核心是边缘宽度/厚度保持的指导性语义分割。EPS首先从训练数据提取具有预定义边缘厚度的边缘真值（Edge GT），然后针对任何网络结构，直接利用辅助任务的解码器头以Edge GT监督的方式进行训练。为确保边缘厚度保持一致，我们设计了一种新的基于边界的损失，称为Polar Hausdorff。

    Semantic segmentation is a classic and fundamental computer vision problem dedicated to assigning each pixel with its corresponding class. Some recent methods introduce edge-based information for improving the segmentation performance. However these methods are specific and limited to certain network architectures, and they can not be transferred to other models or tasks. Therefore, we propose an abstract and universal edge supervision method called Edge-aware Plug-and-play Scheme (EPS), which can be easily and quickly applied to any semantic segmentation models. The core is edge-width/thickness preserving guided for semantic segmentation. The EPS first extracts the Edge Ground Truth (Edge GT) with a predefined edge thickness from the training data; and then for any network architecture, it directly copies the decoder head for the auxiliary task with the Edge GT supervision. To ensure the edge thickness preserving consistantly, we design a new boundarybased loss, called Polar Hausdorff
    
[^20]: 解决预算约束下多组件POMDP的福利最大化算法

    Welfare Maximization Algorithm for Solving Budget-Constrained Multi-Component POMDPs. (arXiv:2303.10302v1 [math.OC])

    [http://arxiv.org/abs/2303.10302](http://arxiv.org/abs/2303.10302)

    该论文提出了一种福利最大化算法，用于解决预算约束下多组件POMDP问题，它通过最优预算分配来计算最优策略。

    

    部分可观测马尔可夫决策过程（POMDPs）提供了一种有效的方法来建模实际的序贯决策过程。本文针对独立动态基础设施组件的维护和检查问题，提出了一种算法来寻找多组件预算约束POMDP的最优策略。我们首先引入了带预算的POMDP模型（b-POMDP），在遵守预算约束的同时，允许我们找到POMDP的最优策略。接下来，我们证明了在有限期的情况下，b-POMDP的值函数或最大收益是预算的凹函数。我们的第二个贡献是一种算法，通过找到各个组件POMDP之间的最优预算分配来计算多组件预算约束POMDP的最优策略。最优预算分配被表示为一种福利最大化问题，并且利用值函数的凹性质来计算解决方案。

    Partially Observable Markov Decision Processes (POMDPs) provide an efficient way to model real-world sequential decision making processes. Motivated by the problem of maintenance and inspection of a group of infrastructure components with independent dynamics, this paper presents an algorithm to find the optimal policy for a multi-component budget-constrained POMDP. We first introduce a budgeted-POMDP model (b-POMDP) which enables us to find the optimal policy for a POMDP while adhering to budget constraints. Next, we prove that the value function or maximal collected reward for a b-POMDP is a concave function of the budget for the finite horizon case. Our second contribution is an algorithm to calculate the optimal policy for a multi-component budget-constrained POMDP by finding the optimal budget split among the individual component POMDPs. The optimal budget split is posed as a welfare maximization problem and the solution is computed by exploiting the concave nature of the value fu
    
[^21]: 检测超出阈值不确定性（DUET）：一种对抗性PATCH本地化器

    Detection of Uncertainty in Exceedance of Threshold (DUET): An Adversarial Patch Localizer. (arXiv:2303.10291v1 [cs.CV])

    [http://arxiv.org/abs/2303.10291](http://arxiv.org/abs/2303.10291)

    提出了一种基于不确定性的对抗性patch本地化器DUET算法，可以定位图像上的对抗性patch，适用于自动驾驶汽车和医学成像等安全敏感应用。

    

    针对物理世界的攻击（如对抗性patch），防御措施的研究越来越受到研究界的重视。我们通过引入基于不确定性的对抗性patch本地化器来为对抗性patch检测领域做出贡献，该本地化器可以在图像上定位对抗性patch，允许进行后处理的patch避免或patch重建。我们通过开发“超出阈值不确定性检测”（DUET）算法来量化我们的预测不确定性。这个算法提供了一个框架来确定对抗性patch本地化的信心，这对于安全敏感的应用，如自动驾驶汽车和医学成像非常重要。我们对本地化对抗性patch进行了实验，并发现我们提出的DUET模型优于基线模型。然后我们对我们所选择的模型先验和不同语言中贝叶斯神经网络的采用进行了进一步的分析。

    Development of defenses against physical world attacks such as adversarial patches is gaining traction within the research community. We contribute to the field of adversarial patch detection by introducing an uncertainty-based adversarial patch localizer which localizes adversarial patch on an image, permitting post-processing patch-avoidance or patch-reconstruction. We quantify our prediction uncertainties with the development of \textit{\textbf{D}etection of \textbf{U}ncertainties in the \textbf{E}xceedance of \textbf{T}hreshold} (DUET) algorithm. This algorithm provides a framework to ascertain confidence in the adversarial patch localization, which is essential for safety-sensitive applications such as self-driving cars and medical imaging. We conducted experiments on localizing adversarial patches and found our proposed DUET model outperforms baseline models. We then conduct further analyses on our choice of model priors and the adoption of Bayesian Neural Networks in different l
    
[^22]: 移动边缘对抗检测用于深度强化学习数字双生技术到虚拟现实的应用

    Mobile Edge Adversarial Detection for Digital Twinning to the Metaverse with Deep Reinforcement Learning. (arXiv:2303.10288v1 [cs.NI])

    [http://arxiv.org/abs/2303.10288](http://arxiv.org/abs/2303.10288)

    本文提出了一种新的移动边缘对抗检测（MEAD）框架，可以准确地检测出在物理世界物体上的对抗性贴片，从而在数字双生技术应用的虚拟世界中确保安全性。

    

    实时数字双生技术的应用必须将现实世界场景快速映射到虚拟现实（也称为Metaverse），以进行增强现实辅助驾驶等应用。然而，由于数字双生技术应用的增长，可能会受到攻击者的干扰，这些攻击者可能会在物理世界中的物体上（例如汽车、路标或道路上）放置对抗性的贴片，从而扭曲虚拟世界中的数字双生体。因此，本文提出了一种新的移动边缘对抗检测（MEAD）框架，通过使用深度强化学习在网络边缘检测对抗性贴片，降低了中央Metaverse Map Service Provider（MMSP）的资源负担。我们还在现实世界的物理环境中评估了MEAD检测对抗性贴片的有效性，并显示其优于现有方法。

    Real-time Digital Twinning of physical world scenes onto the Metaverse is necessary for a myriad of applications such as augmented-reality (AR) assisted driving. In AR assisted driving, physical environment scenes are first captured by Internet of Vehicles (IoVs) and are uploaded to the Metaverse. A central Metaverse Map Service Provider (MMSP) will aggregate information from all IoVs to develop a central Metaverse Map. Information from the Metaverse Map can then be downloaded into individual IoVs on demand and be delivered as AR scenes to the driver. However, the growing interest in developing AR assisted driving applications which relies on digital twinning invites adversaries. These adversaries may place physical adversarial patches on physical world objects such as cars, signboards, or on roads, seeking to contort the virtual world digital twin. Hence, there is a need to detect these physical world adversarial patches. Nevertheless, as real-time, accurate detection of adversarial p
    
[^23]: 关于三值逻辑、复合条件和概率推理定理的研究

    On Trivalent Logics, Compound Conditionals, and Probabilistic Deduction Theorems. (arXiv:2303.10268v1 [cs.AI])

    [http://arxiv.org/abs/2303.10268](http://arxiv.org/abs/2303.10268)

    本文基于德芬尼的三值分析，探讨了复合条件、条件随机量、p一致性和p蕴含。并证明了条件事件的概率推理定理，研究了迭代条件和在此概率推理定理下的"$A$或$B$"的推理推导到条件的无效性。

    

    本文回顾了条件事件、复合条件、条件随机量、p一致性和p蕴含的一些结果。然后，我们通过回顾德芬尼对条件分析的三值分析，展示了条件和条件赌注之间的等价性。但是我们的方法超越了德芬尼早期的三值逻辑分析，基于他的后期思想，旨在将他的提议提高到更高的水平。我们检查了两篇最近的文章，探讨了条件的三值逻辑和它们对逻辑有效性的定义，并将它们与我们对复合条件的方法进行比较。我们证明了条件事件的概率推理定理。之后，我们通过介绍几个例子，研究了一些概率推理定理。我们关注迭代条件和在我们概率推理定理的光线下，“$A$或$B$”的析取推导到条件的无效性。我们使用"$A$或$B$"的推理推导到条件“如果$C$，则$A$”。

    In this paper we recall some results for conditional events, compound conditionals, conditional random quantities, p-consistency, and p-entailment. Then, we show the equivalence between bets on conditionals and conditional bets, by reviewing de Finetti's trivalent analysis of conditionals. But our approach goes beyond de Finetti's early trivalent logical analysis and is based on his later ideas, aiming to take his proposals to a higher level. We examine two recent articles that explore trivalent logics for conditionals and their definitions of logical validity and compare them with our approach to compound conditionals. We prove a Probabilistic Deduction Theorem for conditional events. After that, we study some probabilistic deduction theorems, by presenting several examples. We focus on iterated conditionals and the invalidity of the Import-Export principle in the light of our Probabilistic Deduction Theorem. We use the inference from a disjunction, "$A$ or $B$", to the conditional,"i
    
[^24]: 增强神经网络对多样化$\ell_p$攻击的鲁棒性:鲁棒模态连接导向的对抗性防御

    Robust Mode Connectivity-Oriented Adversarial Defense: Enhancing Neural Network Robustness Against Diversified $\ell_p$ Attacks. (arXiv:2303.10225v1 [cs.AI])

    [http://arxiv.org/abs/2303.10225](http://arxiv.org/abs/2303.10225)

    本文提出一种新颖的鲁棒模态连接导向的对抗性防御，实现神经网络对多样化$\ell_p$攻击的鲁棒性，其中包括两个基于种群学习的学习阶段。

    

    对抗性鲁棒性是衡量神经网络在推理阶段抵御对抗性攻击能力的关键概念。最近的研究表明，尽管使用的强化鲁棒性训练技术能够提高对一种类型的攻击的鲁棒性，但模型仍然容易受到多样化的$\ell_p$攻击。为了实现多样化的$\ell_p$鲁棒性，我们提出了一种新颖的鲁棒模态连接 (RMC) 导向的对抗性防御，它包含两个基于种群学习的学习阶段。第一个阶段，RMC，能够搜索两个预先训练模型之间的模型参数空间，并找到包含高鲁棒性点的路径以抵御多样化的$\ell_p$攻击。基于RMC的有效性，我们开发了第二个阶段，基于RMC的优化，其中RMC作为神经网络多样化$\ell_p$鲁棒性进一步增强的基本单元。为了提高计算效率，我们将学习与仅选择子集的对抗性示例相结合，这导致了一组较小的代表性对抗性示例，可用于增强神经网络对多样化$\ell_p$攻击的鲁棒性。

    Adversarial robustness is a key concept in measuring the ability of neural networks to defend against adversarial attacks during the inference phase. Recent studies have shown that despite the success of improving adversarial robustness against a single type of attack using robust training techniques, models are still vulnerable to diversified $\ell_p$ attacks. To achieve diversified $\ell_p$ robustness, we propose a novel robust mode connectivity (RMC)-oriented adversarial defense that contains two population-based learning phases. The first phase, RMC, is able to search the model parameter space between two pre-trained models and find a path containing points with high robustness against diversified $\ell_p$ attacks. In light of the effectiveness of RMC, we develop a second phase, RMC-based optimization, with RMC serving as the basic unit for further enhancement of neural network diversified $\ell_p$ robustness. To increase computational efficiency, we incorporate learning with a sel
    
[^25]: 联邦情境赌博算法的实证评估。

    An Empirical Evaluation of Federated Contextual Bandit Algorithms. (arXiv:2303.10218v1 [cs.LG])

    [http://arxiv.org/abs/2303.10218](http://arxiv.org/abs/2303.10218)

    本文通过联邦情境赌博算法对隐式信号进行学习，避免了访问难以获得的显式标签，并发现了简单而常用的softmax启发式在平衡算法方面的惊人有效性。

    

    随着联邦学习在学习用户设备上的敏感数据方面的应用增加，自然而然地会问，是否可以使用隐式信号来进行学习，而不需要访问很难在许多任务中获得的显式标签。我们采用联邦情境赌博算法框架来解决这些问题，并针对联邦设置从中心化的情况下发展出着名的情境赌博算法的变体。我们在使用公开可用的数据集模拟的一系列场景中仔细评估了这些算法。我们的模拟模型通常在现实世界中遇到的设置，例如初始预训练模型和随后用户交互之间的各种不对齐，这是由于数据的非稳定性和/或客户端之间的异质性造成的。我们的实验揭示了简单和常用的softmax启发式在平衡情境赌博算法方面的惊人有效性。

    As the adoption of federated learning increases for learning from sensitive data local to user devices, it is natural to ask if the learning can be done using implicit signals generated as users interact with the applications of interest, rather than requiring access to explicit labels which can be difficult to acquire in many tasks. We approach such problems with the framework of federated contextual bandits, and develop variants of prominent contextual bandit algorithms from the centralized seting for the federated setting. We carefully evaluate these algorithms in a range of scenarios simulated using publicly available datasets. Our simulations model typical setups encountered in the real-world, such as various misalignments between an initial pre-trained model and the subsequent user interactions due to non-stationarity in the data and/or heterogeneity across clients. Our experiments reveal the surprising effectiveness of the simple and commonly used softmax heuristic in balancing 
    
[^26]: BotShape：一种基于行为模式的社交机器人检测方法

    BotShape: A Novel Social Bots Detection Approach via Behavioral Patterns. (arXiv:2303.10214v1 [cs.SI])

    [http://arxiv.org/abs/2303.10214](http://arxiv.org/abs/2303.10214)

    BotShape是一种新型的基于行为模式的社交机器人检测方法，通过提取重要的行为特征可以提高检测性能。

    

    在在线社交网络安全中，准确检测机器人账户并减轻其对真实用户的有害影响（如误导、谣言和垃圾信息）是一个重要的话题。基于真实数据集，我们从原始事件日志构建了行为序列，并提取了关键的行为特征。我们观察到机器人账户与真实用户之间的差异以及机器人账户之间相似的行为模式。我们提出了一种新型社交机器人检测系统BotShape，自动捕捉行为序列和特征，并作为分类器检测机器人账户。我们评估了我们系统的检测性能，展示了各种类型分类器的平均准确率为98.52％，平均f1分数为96.65％。与其他研究相比，我们得出结论：BotShape是一种新的账号建模方法，通过提供重要的行为特征可以提高大多数方法的性能。

    An essential topic in online social network security is how to accurately detect bot accounts and relieve their harmful impacts (e.g., misinformation, rumor, and spam) on genuine users. Based on a real-world data set, we construct behavioral sequences from raw event logs. After extracting critical characteristics from behavioral time series, we observe differences between bots and genuine users and similar patterns among bot accounts. We present a novel social bot detection system BotShape, to automatically catch behavioral sequences and characteristics as features for classifiers to detect bots. We evaluate the detection performance of our system in ground-truth instances, showing an average accuracy of 98.52% and an average f1-score of 96.65% on various types of classifiers. After comparing it with other research, we conclude that BotShape is a novel approach to profiling an account, which could improve performance for most methods by providing significant behavioral features.
    
[^27]: 深度学习基于脑部MRI到CT合成的对比度泛化探究

    Exploring contrast generalisation in deep learning-based brain MRI-to-CT synthesis. (arXiv:2303.10202v1 [physics.med-ph])

    [http://arxiv.org/abs/2303.10202](http://arxiv.org/abs/2303.10202)

    本文研究了领域随机化（DR）来提高DL模型在生成基于MRI的脑部sCT的泛化能力。

    

    背景：已经提出并在临床上越来越受到认可的合成计算机断层扫描（sCT）以便基于磁共振成像（MRI）的放疗。深度学习（DL）最近展示了从固定MRI采集中生成准确sCT的能力。然而，MRI协议可能随着时间的推移或在不同中心之间有所不同，导致模型泛化能力差而生成低质量的sCT。目的：研究领域随机化（DR）以增加用于生成脑部sCT 的DL模型的泛化能力。方法：收集95名接受放疗的患者的CT和相应的T1加权MRI /不加对比剂，T2加权和FLAIR MRI，其中考虑FLAIR作为研究泛化的未见序列。训练了一个基准生成对抗网络，其中包括或不包括FLAIR序列以测试模型在没有DR的情况下的表现。评估了图像相似性和基于sCT的剂量计划的准确性，以选择最佳表现的DR方法。

    Background: Synthetic computed tomography (sCT) has been proposed and increasingly clinically adopted to enable magnetic resonance imaging (MRI)-based radiotherapy. Deep learning (DL) has recently demonstrated the ability to generate accurate sCT from fixed MRI acquisitions. However, MRI protocols may change over time or differ between centres resulting in low-quality sCT due to poor model generalisation. Purpose: investigating domain randomisation (DR) to increase the generalisation of a DL model for brain sCT generation. Methods: CT and corresponding T1-weighted MRI with/without contrast, T2-weighted, and FLAIR MRI from 95 patients undergoing RT were collected, considering FLAIR the unseen sequence where to investigate generalisation. A ``Baseline'' generative adversarial network was trained with/without the FLAIR sequence to test how a model performs without DR. Image similarity and accuracy of sCT-based dose plans were assessed against CT to select the best-performing DR approach a
    
[^28]: 高维数据的简单、快速和高效特征选择算法SFE

    SFE: A Simple, Fast and Efficient Feature Selection Algorithm for High-Dimensional Data. (arXiv:2303.10182v1 [cs.LG])

    [http://arxiv.org/abs/2303.10182](http://arxiv.org/abs/2303.10182)

    提出一种针对高维数据集的特征选择算法SFE，由搜索代理和两个算子执行探索和开发阶段，对于高维度数据集表现良好，但在降维后性能不能提高

    

    本文提出了一种针对高维数据集的新型特征选择算法——SFE（简单、快速、高效）。SFE算法使用搜索代理和两个算子（非选择和选择）执行搜索过程，包括两个阶段：探索和开发。在探索阶段，非选择算子在整个问题搜索空间中搜索与分类结果不相关、冗余、微不足道和有噪声的特征，并将这些特征的状态从选择模式更改为非选择模式。在开发阶段，选择算子在问题搜索空间中搜索对分类结果影响较大的特征，并将这些特征的状态从非选择模式更改为选择模式。该SFE算法在高维度数据集上表现良好。但是，在降低数据维度之后，它的性能不能显著提高。在这种情况下，需要对降维后的数据集进行进一步的分析。

    In this paper, a new feature selection algorithm, called SFE (Simple, Fast, and Efficient), is proposed for high-dimensional datasets. The SFE algorithm performs its search process using a search agent and two operators: non-selection and selection. It comprises two phases: exploration and exploitation. In the exploration phase, the non-selection operator performs a global search in the entire problem search space for the irrelevant, redundant, trivial, and noisy features, and changes the status of the features from selected mode to non-selected mode. In the exploitation phase, the selection operator searches the problem search space for the features with a high impact on the classification results, and changes the status of the features from non-selected mode to selected mode. The proposed SFE is successful in feature selection from high-dimensional datasets. However, after reducing the dimensionality of a dataset, its performance cannot be increased significantly. In these situations
    
[^29]: 在资源受限的环境中运行关键的机器学习模型

    Operating critical machine learning models in resource constrained regimes. (arXiv:2303.10181v1 [cs.LG])

    [http://arxiv.org/abs/2303.10181](http://arxiv.org/abs/2303.10181)

    本文分享了在关键场景下使用机器学习模型时资源消耗和性能之间的权衡方法。考虑到模型在全球诊所中的部署，机器学习界正在为改进模型效率而努力。

    

    机器学习方法，特别是深度学习，在医学图像分析和计算机辅助干预方面的最新突破，使其得到快速发展。深度学习模型在训练数据，计算和能源成本方面的资源消耗是巨大的。这些巨大的资源成本可能会阻碍这些模型在全球诊所中的部署。为了解决这个问题，机器学习界正在努力引入资源效率的概念。例如，使用量化来减轻内存消耗。虽然大多数这些方法已被证明可以减少资源利用，但可能会以性能为代价。在这项工作中，我们探讨了资源消耗和性能之间的权衡，特别是在诊所等关键环境中使用的模型方面。

    The accelerated development of machine learning methods, primarily deep learning, are causal to the recent breakthroughs in medical image analysis and computer aided intervention. The resource consumption of deep learning models in terms of amount of training data, compute and energy costs are known to be massive. These large resource costs can be barriers in deploying these models in clinics, globally. To address this, there are cogent efforts within the machine learning community to introduce notions of resource efficiency. For instance, using quantisation to alleviate memory consumption. While most of these methods are shown to reduce the resource utilisation, they could come at a cost in performance. In this work, we probe into the trade-off between resource consumption and performance, specifically, when dealing with models that are used in critical settings such as in clinics.
    
[^30]: 使用深度离线强化学习实现安全的丙泊酚全麻剂量控制

    Towards Safe Propofol Dosing during General Anesthesia Using Deep Offline Reinforcement Learning. (arXiv:2303.10180v1 [cs.LG])

    [http://arxiv.org/abs/2303.10180](http://arxiv.org/abs/2303.10180)

    本文提出了一种基于真实临床数据集的数据驱动强化学习算法Policy Constraint Q-Learning(PCQL)来实现全麻药物剂量控制，添加了保守Q-Learning方法和策略约束项以确保智能体做出更安全的决策。

    

    自动化麻醉有望实现更精确和个性化的麻醉管理，使麻醉师免于重复性任务，专注于患者手术护理的最关键方面。当前的研究通常集中于创建模拟环境，以便智能体进行学习。这些方法已经展示出良好的实验结果，但离临床应用还有很大的差距。本文提出了一种基于真实临床数据集的数据驱动强化学习算法Policy Constraint Q-Learning(PCQL)来解决学习麻醉策略的问题。首先引入了保守Q-Learning方法以缓解脱线情况下Q函数过度估计的问题。在智能体的培训中添加一项策略约束项，以保持智能体和麻醉师的策略分布一致，以确保智能体在全麻情景下做出更安全的决策。通过实验证明了PCQL的有效性。

    Automated anesthesia promises to enable more precise and personalized anesthetic administration and free anesthesiologists from repetitive tasks, allowing them to focus on the most critical aspects of a patient's surgical care. Current research has typically focused on creating simulated environments from which agents can learn. These approaches have demonstrated good experimental results, but are still far from clinical application. In this paper, Policy Constraint Q-Learning (PCQL), a data-driven reinforcement learning algorithm for solving the problem of learning anesthesia strategies on real clinical datasets, is proposed. Conservative Q-Learning was first introduced to alleviate the problem of Q function overestimation in an offline context. A policy constraint term is added to agent training to keep the policy distribution of the agent and the anesthesiologist consistent to ensure safer decisions made by the agent in anesthesia scenarios. The effectiveness of PCQL was validated b
    
[^31]: GPT是GPT：大语言模型对劳动力市场影响的早期研究

    GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models. (arXiv:2303.10130v1 [econ.GN])

    [http://arxiv.org/abs/2303.10130](http://arxiv.org/abs/2303.10130)

    该研究调查了GPT（大语言模型）和相关技术对美国劳动力市场的潜在影响，发现大约80%的美国劳动力可能会受到10%的工作任务的影响，涵盖了所有工资水平和各行各业，预示着这些模型可能具有显著的经济、社会和政策影响。

    

    我们研究了生成预训练变压器（GPT）模型和相关技术对美国劳动力市场的潜在影响。使用新的标准，我们评估职业与GPT能力的对应关系，结合人类专业知识和GPT-4的分类。我们的研究结果表明，约80%的美国劳动力可能会至少有10%的工作任务受到GPT引入的影响，而约19%的工人可能会看到至少50%的任务受到影响。影响范围涵盖了所有工资水平，高收入工作可能面临更大的风险。值得注意的是，影响并不局限于最近生产率增长较高的行业。我们得出结论，生成预训练变压器具有通用技术（GPT）的特性，表明这些模型可能具有显著的经济、社会和政策影响。

    We investigate the potential implications of Generative Pre-trained Transformer (GPT) models and related technologies on the U.S. labor market. Using a new rubric, we assess occupations based on their correspondence with GPT capabilities, incorporating both human expertise and classifications from GPT-4. Our findings indicate that approximately 80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of GPTs, while around 19% of workers may see at least 50% of their tasks impacted. The influence spans all wage levels, with higher-income jobs potentially facing greater exposure. Notably, the impact is not limited to industries with higher recent productivity growth. We conclude that Generative Pre-trained Transformers exhibit characteristics of general-purpose technologies (GPTs), suggesting that as these models could have notable economic, social, and policy implications.
    
[^32]: TKN：基于Transformer的实时视频关键点预测网络

    TKN: Transformer-based Keypoint Prediction Network For Real-time Video Prediction. (arXiv:2303.09807v1 [cs.CV])

    [http://arxiv.org/abs/2303.09807](http://arxiv.org/abs/2303.09807)

    TKN是一种基于Transformer的实时视频预测解决方案，通过受限信息提取和并行预测方案来提升预测过程的速度，具有更高的精度和更低的计算成本。

    

    视频预测是一项具有广泛用途的复杂时间序列预测任务。然而，传统方法过于强调准确性，忽视了由于过于复杂的模型结构而导致的较慢的预测速度以及过多的冗余信息学习和GPU内存消耗。因此，我们提出了TKN，一种基于Transformer的关键点预测神经网络，通过受限信息提取和并行预测方案来提升预测过程的速度。TKN是我们目前所知的第一个实时视频预测解决方案，同时显著降低计算成本并保持其他性能。在KTH和Human Action 3D数据集上的大量实验表明，TKN在预测准确性和速度方面均优于现有的基准线。

    Video prediction is a complex time-series forecasting task with great potential in many use cases. However, conventional methods overemphasize accuracy while ignoring the slow prediction speed caused by complicated model structures that learn too much redundant information with excessive GPU memory consumption. Furthermore, conventional methods mostly predict frames sequentially (frame-by-frame) and thus are hard to accelerate. Consequently, valuable use cases such as real-time danger prediction and warning cannot achieve fast enough inference speed to be applicable in reality. Therefore, we propose a transformer-based keypoint prediction neural network (TKN), an unsupervised learning method that boost the prediction process via constrained information extraction and parallel prediction scheme. TKN is the first real-time video prediction solution to our best knowledge, while significantly reducing computation costs and maintaining other performance. Extensive experiments on KTH and Hum
    
[^33]: 基于城市区域功能引导的交通流预测

    Urban Regional Function Guided Traffic Flow Prediction. (arXiv:2303.09789v1 [cs.CV])

    [http://arxiv.org/abs/2303.09789](http://arxiv.org/abs/2303.09789)

    本文提出了一个名为POI-MetaBlock的新模块，结合区域的功能性和交通特征，采用自注意力架构进行交通流预测。

    

    交通流预测是时空分析中具有挑战性但至关重要的问题，近年来越来越受到关注。除了时空相关性，城市区域的功能性也在交通流预测中起着至关重要的作用。然而，对区域功能属性的探索主要集中在添加额外的拓扑结构上，忽略了功能属性对区域交通特征的影响。与现有作品不同的是，我们提出了一个名为POI-MetaBlock的新模块，利用每个区域的功能性（由兴趣点分布表示）作为元数据来进一步挖掘不同功能区域的不同交通特征。具体而言，所提出的POI-MetaBlock采用自注意力架构，结合POI和时间信息生成每个区域的动态注意参数，使模型能够适应不同的各种区域交通模式。

    The prediction of traffic flow is a challenging yet crucial problem in spatial-temporal analysis, which has recently gained increasing interest. In addition to spatial-temporal correlations, the functionality of urban areas also plays a crucial role in traffic flow prediction. However, the exploration of regional functional attributes mainly focuses on adding additional topological structures, ignoring the influence of functional attributes on regional traffic patterns. Different from the existing works, we propose a novel module named POI-MetaBlock, which utilizes the functionality of each region (represented by Point of Interest distribution) as metadata to further mine different traffic characteristics in areas with different functions. Specifically, the proposed POI-MetaBlock employs a self-attention architecture and incorporates POI and time information to generate dynamic attention parameters for each region, which enables the model to fit different traffic patterns of various ar
    
[^34]: SemDeDup:通过语义去重实现网络规模数据的高效学习（arXiv:2303.09540v1 [cs.LG]）

    SemDeDup: Data-efficient learning at web-scale through semantic deduplication. (arXiv:2303.09540v1 [cs.LG])

    [http://arxiv.org/abs/2303.09540](http://arxiv.org/abs/2303.09540)

    SemDeDup是一种利用预训练模型的嵌入来识别和删除语义重复项的方法。通过对LAION的子集进行分析，SemDeDup可以最小化性能损失的同时删除50%的数据，实际上将训练时间减半。此外，SemDeDup在提供效率收益的同时改进了先前的方法。

    

    机器学习领域的进展很大程度上是由海量数据的增加推动的。然而，像LAION这样的大型网络规模数据集在除查找精确重复项外，大部分未经精心筛选，可能存在很多冗余。在这里，我们介绍SemDeDup，一种基于预训练模型的嵌入来识别和删除语义重复项的方法：即语义上相似但并非完全相同的数据对。去除语义重复项可以保持性能并加速学习。通过对LAION的子集进行分析，我们展示了SemDeDup可以最小化性能损失的同时删除50%的数据，实际上将训练时间减半。此外，性能在分布以外得到提高。同时，通过分析在部分筛选过的数据集C4上训练的语言模型，我们展示了SemDeDup在提供效率收益的同时改进了先前的方法。SemDeDup提供了一个利用质量嵌入简单方法来使模型更快地学习的示例。

    Progress in machine learning has been driven in large part by massive increases in data. However, large web-scale datasets such as LAION are largely uncurated beyond searches for exact duplicates, potentially leaving much redundancy. Here, we introduce SemDeDup, a method which leverages embeddings from pre-trained models to identify and remove semantic duplicates: data pairs which are semantically similar, but not exactly identical. Removing semantic duplicates preserves performance and speeds up learning. Analyzing a subset of LAION, we show that SemDeDup can remove 50% of the data with minimal performance loss, effectively halving training time. Moreover, performance increases out of distribution. Also, analyzing language models trained on C4, a partially curated dataset, we show that SemDeDup improves over prior approaches while providing efficiency gains. SemDeDup provides an example of how simple ways of leveraging quality embeddings can be used to make models learn faster with le
    
[^35]: 利用ChatGPT和Prompt Learning将放射学报告翻译成通俗易懂的语言：结果、限制和潜力。

    Translating Radiology Reports into Plain Language using ChatGPT and GPT-4 with Prompt Learning: Promising Results, Limitations, and Potential. (arXiv:2303.09038v1 [cs.CL])

    [http://arxiv.org/abs/2303.09038](http://arxiv.org/abs/2303.09038)

    本文研究探讨利用ChatGPT将放射学报告翻译成通俗易懂的语言，平均得分为5分制的4.1分，信息缺失率和信息错误率均较低，ChatGPT提供的建议大都与放射学报告相关。

    

    ChatGPT作为一种大型语言模型，以其类似人类表达和推理能力而备受关注。本研究探讨使用ChatGPT将放射学报告翻译成通俗易懂的语言的可行性，以便患者和医疗服务提供者得到更好的医疗教育。研究采集了62份低剂量胸部CT肺癌筛查扫描和76份脑MRI转移性筛查扫描的放射学报告。根据放射科医师的评价，ChatGPT可以成功将放射学报告翻译成通俗易懂的语言，平均得分为5分制的4.1分，信息缺失0.07处，信息错误0.11处。就ChatGPT提供的建议而言，它们是一般性的相关建议，例如保持与医生的随访和密切监测任何症状，对于共138个病例中的约37％，ChatGPT提供了与放射学报告有关的建议。

    The large language model called ChatGPT has drawn extensively attention because of its human-like expression and reasoning abilities. In this study, we investigate the feasibility of using ChatGPT in experiments on using ChatGPT to translate radiology reports into plain language for patients and healthcare providers so that they are educated for improved healthcare. Radiology reports from 62 low-dose chest CT lung cancer screening scans and 76 brain MRI metastases screening scans were collected in the first half of February for this study. According to the evaluation by radiologists, ChatGPT can successfully translate radiology reports into plain language with an average score of 4.1 in the five-point system with 0.07 places of information missing and 0.11 places of misinformation. In terms of the suggestions provided by ChatGPT, they are general relevant such as keeping following-up with doctors and closely monitoring any symptoms, and for about 37% of 138 cases in total ChatGPT offer
    
[^36]: 自动化交互式特定领域对话代理，理解人类对话

    Automated Interactive Domain-Specific Conversational Agents that Understand Human Dialogs. (arXiv:2303.08941v1 [cs.AI])

    [http://arxiv.org/abs/2303.08941](http://arxiv.org/abs/2303.08941)

    本文介绍了利用大型语言模型和Answer Set Programming实现真正“理解”人类对话的AutoConcierge系统。该系统针对特定领域，为用户提供有关附近餐厅的建议。

    

    在知识表示与推理以及自然语言处理领域，实现与人类的人类对话相似的通信仍然是一个经典而具有挑战性的主题。这些大型语言模型（LLM）依赖于模式匹配，而不是真正理解句子的语义含义。因此，它们可能会生成错误的响应。要生成保证正确的响应，必须“理解”句子的语义。为了实现这种“理解”，需要基于逻辑的（常识）推理方法，例如答案集编程（ASP）。在本文中，我们描述了AutoConcierge系统，它利用LLMs和ASP开发了一种对话代理，可以真正“理解”受限领域内的人类对话。AutoConcierge专注于一个特定的领域-根据用户的喜好建议他们附近的餐厅。AutoConcierge将交互式地理解用户的话语，确定其中缺失的信息。

    Achieving human-like communication with machines remains a classic, challenging topic in the field of Knowledge Representation and Reasoning and Natural Language Processing. These Large Language Models (LLMs) rely on pattern-matching rather than a true understanding of the semantic meaning of a sentence. As a result, they may generate incorrect responses. To generate an assuredly correct response, one has to "understand" the semantics of a sentence. To achieve this "understanding", logic-based (commonsense) reasoning methods such as Answer Set Programming (ASP) are arguably needed. In this paper, we describe the AutoConcierge system that leverages LLMs and ASP to develop a conversational agent that can truly "understand" human dialogs in restricted domains. AutoConcierge is focused on a specific domain-advising users about restaurants in their local area based on their preferences. AutoConcierge will interactively understand a user's utterances, identify the missing information in them
    
[^37]: 面向跨域零样本学习的双向分布对齐方法

    Bi-directional Distribution Alignment for Transductive Zero-Shot Learning. (arXiv:2303.08698v1 [cs.CV])

    [http://arxiv.org/abs/2303.08698](http://arxiv.org/abs/2303.08698)

    本文提出了一种 Bi-VAEGAN 模型，通过双向分布对齐、L_2 范数特征归一化和更复杂的先验估计方法，大大改善了跨域零样本学习中的分布偏移问题。

    

    零样本学习存在领域转移问题，即未见类别的真实和学习数据分布不匹配。尽管转导式零样本学习可以使用未见类别的无标签样本，但分布偏移仍然很高。本文提出了一种新颖的 TZSL 模型（命名为 Bi-VAEGAN），通过加强视觉空间和辅助空间之间的分布对齐，大大改善了这种偏移。模型设计的关键提议包括（1）双向分布对齐，（2）基于 L_2 范数的简单而有效的特征归一化方法，（3）更复杂的未见类别先验估计方法。在使用四个数据集进行基准评估时，Bi-VAEGAN 在标准和广义 TZSL 设置下均取得了新的最先进结果。代码可在 https://github.com/Zhicaiwww/Bi-VAEGAN 找到。

    It is well-known that zero-shot learning (ZSL) can suffer severely from the problem of domain shift, where the true and learned data distributions for the unseen classes do not match. Although transductive ZSL (TZSL) attempts to improve this by allowing the use of unlabelled examples from the unseen classes, there is still a high level of distribution shift. We propose a novel TZSL model (named as Bi-VAEGAN), which largely improves the shift by a strengthened distribution alignment between the visual and auxiliary spaces. The key proposal of the model design includes (1) a bi-directional distribution alignment, (2) a simple but effective L_2-norm based feature normalization approach, and (3) a more sophisticated unseen class prior estimation approach. In benchmark evaluation using four datasets, Bi-VAEGAN achieves the new state of the arts under both the standard and generalized TZSL settings. Code could be found at https://github.com/Zhicaiwww/Bi-VAEGAN
    
[^38]: 机器人辅助踝骨骨折修复的图像引导技术研究

    Image Guidance for Robot-Assisted Ankle Fracture Repair. (arXiv:2303.08105v1 [eess.IV])

    [http://arxiv.org/abs/2303.08105](http://arxiv.org/abs/2303.08105)

    该研究旨在开发和验证一种图像引导框架，使机器人能够自动确定腓骨复位方向，进而提高骨折手术的效率和准确性，改善患者的手术效果，降低患者发生骨性关节炎的风险。

    

    本项目涉及开发和验证一种适用于机器人辅助腓骨复位的图像引导框架，并旨在产生和证明自动确定腓骨复位方向的软件的正确功能，最终目标是应用于机器人减压程序，从而减少手术时间和复杂性，同时提供理想的最终腓骨位置误差减小、韧带结构恢复得到改善以及创伤后骨性关节炎发生率降低的益处。

    This project concerns developing and validating an image guidance framework for application to a robotic-assisted fibular reduction in ankle fracture surgery. The aim is to produce and demonstrate proper functioning of software for automatic determination of directions for fibular repositioning with the ultimate goal of application to a robotic reduction procedure that can reduce the time and complexity of the procedure as well as provide the benefits of reduced error in ideal final fibular position, improved syndesmosis restoration and reduced incidence of post-traumatic osteoarthritis. The focus of this product will be developing and testing the image guidance software, from the input of preoperative images through the steps of automated segmentation and registration until the output of a final transformation that can be used as instructions to a robot on how to reposition the fibula, but will not involve developing or implementing the hardware of the robot itself.
    
[^39]: 检测大型语言模型生成文字的科学

    The Science of Detecting LLM-Generated Texts. (arXiv:2303.07205v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.07205](http://arxiv.org/abs/2303.07205)

    本文综述了现有大型语言模型生成文本检测技术并提出了关键考虑因素，如开发全面评估指标和开源 LLM 所构成的威胁。

    

    大型语言模型 (LLMs) 的出现导致了高度复杂且几乎难以区分出是否为人类创作的 LLM 生成文字。但是，这也引发了对此类文字潜在误用的担忧，例如传播错误信息和在教育系统中造成混乱。尽管已提出许多检测方法，但关于其成就和挑战的全面理解仍然缺乏。本文旨在概述现有的 LLM 生成文本检测技术，并增强对语言生成模型的控制和监管。此外，我们强调未来研究的重要考虑因素，包括开发全面评估指标和开源 LLM 所构成的威胁，以推动 LLM 生成文本检测领域的进展。

    The emergence of large language models (LLMs) has resulted in the production of LLM-generated texts that is highly sophisticated and almost indistinguishable from texts written by humans. However, this has also sparked concerns about the potential misuse of such texts, such as spreading misinformation and causing disruptions in the education system. Although many detection approaches have been proposed, a comprehensive understanding of the achievements and challenges is still lacking. This survey aims to provide an overview of existing LLM-generated text detection techniques and enhance the control and regulation of language generation models. Furthermore, we emphasize crucial considerations for future research, including the development of comprehensive evaluation metrics and the threat posed by open-source LLMs, to drive progress in the area of LLM-generated text detection.
    
[^40]: 为什么这是一个好的或不是一个好的煎锅？——对象和工具功能的知识表示，用于设计理解、改进和生成

    Why is That a Good or Not a Good Frying Pan? -- Knowledge Representation for Functions of Objects and Tools for Design Understanding, Improvement, and Generation for Design Understanding, Improvement, and Generation. (arXiv:2303.06152v1 [cs.AI])

    [http://arxiv.org/abs/2303.06152](http://arxiv.org/abs/2303.06152)

    本文演示了如何使用通用函数表示语言和框架来表示特定对象及其参与支持其设计的过程，从而实现深入的概念理解，可解释性的功能，使系统能够回答“为什么”问题。

    This paper demonstrates how a particular object and its participation in the processes it is designed to support can be represented in a general function representational language and framework, leading to a deep conceptual understanding with explainability of functionalities that allows the system to answer "why" questions.

    对象和工具的功能方面的理解对于支持智能系统在环境中导航和与各种对象、结构和系统进行交互以帮助实现其目标至关重要。对功能的详细理解也可以导致设计改进和新颖的设计，从而增强人工智能和机器人系统的操作，一方面，增强人类生活。本文演示了如何使用通用函数表示语言和框架来表示特定对象（在本例中为煎锅）及其参与支持其设计的过程（在本例中为煎炸过程），从而可以用于详细说明涉及的过程和功能，从而实现深入的概念理解，可解释性的功能，使系统能够回答“为什么”问题——为什么这是一个好的煎锅，或者为什么某个部件在煎锅中的位置很重要。

    The understanding of the functional aspects of objects and tools is of paramount importance in supporting an intelligent system in navigating around in the environment and interacting with various objects, structures, and systems, to help fulfil its goals. A detailed understanding of functionalities can also lead to design improvements and novel designs that would enhance the operations of AI and robotic systems on the one hand, and human lives on the other. This paper demonstrates how a particular object - in this case, a frying pan - and its participation in the processes it is designed to support - in this case, the frying process - can be represented in a general function representational language and framework, that can be used to flesh out the processes and functionalities involved, leading to a deep conceptual understanding with explainability of functionalities that allows the system to answer "why" questions - why is something a good frying pan, say, or why a certain part on t
    
[^41]: 计算连续的强化学习目标是可PAC学习的

    Computably Continuous Reinforcement-Learning Objectives are PAC-learnable. (arXiv:2303.05518v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.05518](http://arxiv.org/abs/2303.05518)

    本研究证明了计算连续的强化学习目标是可PAC学习的，这对于设计高效的强化学习算法打开了新的突破口。

    

    在强化学习中，最大化折扣和有限时间步长累积奖励的经典目标是可PAC学习的：存在算法使用有限数量的样本和计算，高概率地学习到近似最优策略。近年来，研究人员引入了超越经典累积奖励的新目标和相应的强化学习算法，如用线性时态逻辑公式指定的目标。然而，这些新目标的PAC可学习性仍然存在问题。本论文通过在两种分析设置中充分条件的PAC可学习性，证明了强化学习目标的可PAC学习性。特别地，在仅考虑样本复杂性的分析中，我们证明如果一个目标作为一个oracle是一致连续的，那么它是可PAC学习的。此外，在考虑计算复杂度的分析中，我们证明如果一个目标是计算连续的，并满足“统一连续条件”，那么它是可PAC学习的。我们的结果为超越累积奖励的目标的可学习性提供了见解，并为设计这些目标的高效强化学习算法铺平了道路。

    In reinforcement learning, the classic objectives of maximizing discounted and finite-horizon cumulative rewards are PAC-learnable: There are algorithms that learn a near-optimal policy with high probability using a finite amount of samples and computation. In recent years, researchers have introduced objectives and corresponding reinforcement-learning algorithms beyond the classic cumulative rewards, such as objectives specified as linear temporal logic formulas. However, questions about the PAC-learnability of these new objectives have remained open.  This work demonstrates the PAC-learnability of general reinforcement-learning objectives through sufficient conditions for PAC-learnability in two analysis settings. In particular, for the analysis that considers only sample complexity, we prove that if an objective given as an oracle is uniformly continuous, then it is PAC-learnable. Further, for the analysis that considers computational complexity, we prove that if an objective is com
    
[^42]: Bootstrap The Original Latent: 从黑盒模型学习私有模型

    Bootstrap The Original Latent: Learning a Private Model from a Black-box Model. (arXiv:2303.03709v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.03709](http://arxiv.org/abs/2303.03709)

    本文提出了BPBA设置和BTOL训练策略两个新的方法，分别用于用户训练私有模型和利用基础/源模型。在三个不同的数据集上的实验表明，这些方法都是有效且稳健的。

    

    本文提出了一个称为Back-Propagated Black-Box Adaptation（BPBA）的新设置，以平衡模型所有者的数据/模型隐私和用户需求，为用户提供指导。该设置可以简化基础/源模型的使用，防止基础/源模型的泄漏和误用。此外，我们还提出了一种称为Bootstrap The Original Latent（BTOL）的新训练策略，以充分利用基础/源模型。我们的策略由领域适配器和冷冻-解冻策略组成。

    In this paper, considering the balance of data/model privacy of model owners and user needs, we propose a new setting called Back-Propagated Black-Box Adaptation (BPBA) for users to better train their private models via the guidance of the back-propagated results of a Black-box foundation/source model. Our setting can ease the usage of foundation/source models as well as prevent the leakage and misuse of foundation/source models. Moreover, we also propose a new training strategy called Bootstrap The Original Latent (BTOL) to fully utilize the foundation/source models. Our strategy consists of a domain adapter and a freeze-and-thaw strategy. We apply our BTOL under BPBA and Black-box UDA settings on three different datasets. Experiments show that our strategy is efficient and robust in various settings without manual augmentations.
    
[^43]: Seq-HyGAN: 基于超图注意力网络的序列分类

    Seq-HyGAN: Sequence Classification via Hypergraph Attention Network. (arXiv:2303.02393v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.02393](http://arxiv.org/abs/2303.02393)

    本文提出了一种基于超图注意力网络的序列分类模型Seq-HyGAN，通过创建超图和引入注意力机制来处理序列数据中的复杂结构相似性，从而提高分类准确率。

    

    序列分类在不同领域有广泛的实际应用，例如在健康领域中的基因组分类和在商业领域的异常检测。然而，序列数据中缺乏显式的特征，这使得机器学习模型难以处理。虽然神经网络模型通过自动学习特征来解决这个问题，但它们仅限于捕获相邻结构连接并忽略序列之间的全局、高阶信息。为了解决序列分类问题中的这些挑战，我们提出了一种新的超图注意力网络模型——Seq-HyGAN。为了捕捉序列数据之间的复杂结构相似性，我们首先创建一个超图，其中序列被描绘为超边，从序列中提取的子序列被描绘为节点。此外，我们引入了基于注意力的超图神经网络模型，它利用了双层注意力机制。该模型生成一个序列表示

    Sequence classification has a wide range of real-world applications in different domains, such as genome classification in health and anomaly detection in business. However, the lack of explicit features in sequence data makes it difficult for machine learning models. While Neural Network (NN) models address this with learning features automatically, they are limited to capturing adjacent structural connections and ignore global, higher-order information between the sequences. To address these challenges in the sequence classification problems, we propose a novel Hypergraph Attention Network model, namely Seq-HyGAN. To capture the complex structural similarity between sequence data, we first create a hypergraph where the sequences are depicted as hyperedges and subsequences extracted from sequences are depicted as nodes. Additionally, we introduce an attention-based Hypergraph Neural Network model that utilizes a two-level attention mechanism. This model generates a sequence representa
    
[^44]: 前往负责任的AI生成内容之路

    A Pathway Towards Responsible AI Generated Content. (arXiv:2303.01325v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.01325](http://arxiv.org/abs/2303.01325)

    本文探讨了AI生成内容的合理使用所面临的风险，包括隐私、偏见、毒性、错误信息和知识产权等，并提供有希望的解决方向。

    

    近年来，AI生成内容（AIGC）受到了极大的关注，其内容涵盖了图像、文本、音频、视频等。与此同时，AIGC已经成为一把双刃剑，并最近在其负责任使用方面受到了许多批评。在本视野论文中，我们关注可能阻碍AIGC在实践中健康发展和部署的三个主要问题，包括来自隐私、偏见、毒性、错误信息和知识产权（IP）的风险。通过记录已知和潜在的风险，以及AIGC的任何可能的滥用情况，旨在引起对潜在风险和滥用的注意，帮助社会消除障碍，并促进更加道德和安全的AIGC部署。此外，我们提供了对应对这些风险的有希望的方向的见解，同时构建生成模型，使AIGC能够负责任地为社会带来益处。

    AI Generated Content (AIGC) has received tremendous attention within the past few years, with content ranging from image, text, to audio, video, etc. Meanwhile, AIGC has become a double-edged sword and recently received much criticism regarding its responsible usage. In this vision paper, we focus on three main concerns that may hinder the healthy development and deployment of AIGC in practice, including risks from privacy, bias, toxicity, misinformation, and intellectual property (IP). By documenting known and potential risks, as well as any possible misuse scenarios of AIGC, the aim is to draw attention to potential risks and misuse, help society to eliminate obstacles, and promote the more ethical and secure deployment of AIGC. Additionally, we provide insights into the promising directions for tackling these risks while constructing generative models, enabling AIGC to be used responsibly to benefit society.
    
[^45]: 无需价值一致性的安全性

    Safety without alignment. (arXiv:2303.00752v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.00752](http://arxiv.org/abs/2303.00752)

    本文讨论了基于伦理理性的替代人工智能安全方法。作者建议将伦理道德与理性联系起来，以获得明显的长期优势，提出了一种通过混合定理证明器在沙盒中实现的固有安全的实现路径。

    

    目前，人工智能安全的主导范式是与人类价值的一致性。本文描述了基于伦理理性（Gewirth:1978）的安全性替代方法的发展进展，并提出了一种通过混合定理证明器在沙盒中实现的固有安全的实现路径。随着AGI的发展，它们的一致性可能会逐渐消失，但它们的理性只能增加（否则更理性的个体将具有显着的进化优势）因此，将伦理道德与理性联系起来的方法具有明显的长期优势。

    Currently, the dominant paradigm in AI safety is alignment with human values. Here we describe progress on developing an alternative approach to safety, based on ethical rationalism (Gewirth:1978), and propose an inherently safe implementation path via hybrid theorem provers in a sandbox. As AGIs evolve, their alignment may fade, but their rationality can only increase (otherwise more rational ones will have a significant evolutionary advantage) so an approach that ties their ethics to their rationality has clear long-term advantages.
    
[^46]: 马尔科夫条件与逻辑信任网络中的因子分解

    Markov Conditions and Factorization in Logical Credal Networks. (arXiv:2302.14146v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.14146](http://arxiv.org/abs/2302.14146)

    本文研究逻辑信任网络并探究不同马尔科夫条件的影响。我们发现没有有向循环的网络可以进行因子分解，而带有有向循环的网络则需要特别考虑不同的马尔科夫条件。

    

    我们研究了最近提出的逻辑信任网络的语言，特别是调查不同马尔科夫条件的后果。我们引入了逻辑信任网络的结构概念，并展示了没有有向循环的结构将导致一个众所周知的因子分解结果。对于带有有向循环的网络，我们分析了马尔科夫条件、因子分解结果和规范要求之间的差异。

    We examine the recently proposed language of Logical Credal Networks, in particular investigating the consequences of various Markov conditions. We introduce the notion of structure for a Logical Credal Network and show that a structure without directed cycles leads to a well-known factorization result. For networks with directed cycles, we analyze the differences between Markov conditions, factorization results, and specification requirements.
    
[^47]: AugGPT：利用ChatGPT进行文本数据增强

    AugGPT: Leveraging ChatGPT for Text Data Augmentation. (arXiv:2302.13007v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.13007](http://arxiv.org/abs/2302.13007)

    AugGPT提出了一种基于ChatGPT的文本数据增强方法，该方法能够更忠实地保留正确标记的生成数据并提供足够的多样性，从而有效地缓解了自然语言处理任务中的限制样本量的问题。

    

    文本数据增强是受限制的样本量在许多自然语言处理（NLP）任务中克服挑战的有效策略。对于少样本学习场景，其中目标域的数据通常更加稀缺且质量更低，这一挑战特别突出。为了更好地捕捉数据不变性并增加样本量，缓解这种挑战的一种自然且广泛使用的策略是执行数据增强。然而，当前的文本数据增强方法要么无法保证生成数据的正确标记（缺乏忠实度），要么无法保证生成的数据具有足够的多样性（缺乏紧凑性），或者两者都有。在大语言模型的最近成功，尤其是在开发ChatGPT方面展示了改进的语言理解能力的基础上，本文提出了一种基于ChatGPT（名为AugGPT）的文本数据增强方法。

    Text data augmentation is an effective strategy for overcoming the challenge of limited sample sizes in many natural language processing (NLP) tasks. This challenge is especially prominent in the few-shot learning scenario, where the data in the target domain is generally much scarcer and of lowered quality. A natural and widely-used strategy to mitigate such challenges is to perform data augmentation to better capture the data invariance and increase the sample size. However, current text data augmentation methods either can't ensure the correct labeling of the generated data (lacking faithfulness) or can't ensure sufficient diversity in the generated data (lacking compactness), or both. Inspired by the recent success of large language models, especially the development of ChatGPT, which demonstrated improved language comprehension abilities, in this work, we propose a text data augmentation approach based on ChatGPT (named AugGPT). AugGPT rephrases each sentence in the training sampl
    
[^48]: FrankenSplit:基于显著性指导的神经特征压缩与浅层变分瓶颈注入

    FrankenSplit: Saliency Guided Neural Feature Compression with Shallow Variational Bottleneck Injection. (arXiv:2302.10681v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2302.10681](http://arxiv.org/abs/2302.10681)

    本文提出了一种基于显著性指导的神经特征压缩与浅层变分瓶颈注入的新的资源意识压缩模型的框架，实现了比最先进的SC方法低60％的比特率，并且比现有的编解码标准的下放快16倍。

    

    移动AI加速器的崛起使得对延迟敏感的应用可以在客户端上执行轻量级深度神经网络（DNN）。然而，需要强大模型的关键应用程序需要将请求下放，而高维数据将争夺有限的带宽。本文提出了一种新的资源意识压缩模型的框架并在反映边缘设备和服务器之间不对称资源分配的环境中进行了广泛评估。我们的方法在不降低准确性的情况下实现了比最先进的SC方法低60％的比特率，并且比现有的编解码标准的下放快16倍。

    The rise of mobile AI accelerators allows latency-sensitive applications to execute lightweight Deep Neural Networks (DNNs) on the client side. However, critical applications require powerful models that edge devices cannot host and must therefore offload requests, where the high-dimensional data will compete for limited bandwidth. This work proposes shifting away from focusing on executing shallow layers of partitioned DNNs. Instead, it advocates concentrating the local resources on variational compression optimized for machine interpretability. We introduce a novel framework for resource-conscious compression models and extensively evaluate our method in an environment reflecting the asymmetric resource distribution between edge devices and servers. Our method achieves 60\% lower bitrate than a state-of-the-art SC method without decreasing accuracy and is up to 16x faster than offloading with existing codec standards.
    
[^49]: SurvLIMEpy: 一个实现了SurvLIME算法的Python包

    SurvLIMEpy: A Python package implementing SurvLIME. (arXiv:2302.10571v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.10571](http://arxiv.org/abs/2302.10571)

    本文介绍了一个名为SurvLIMEpy的Python包，它实现了一种算法，可以计算适用于建模生存分析数据的机器学习算法的局部特征重要性，并支持各种生存模型。

    

    本文介绍SurvLIMEpy，这是一个开源的Python包，实现了SurvLIME算法。该算法可以计算适用于建模生存分析数据的机器学习算法的局部特征重要性。我们的实现利用了并行化范例，因为所有计算都以矩阵方式执行，从而加快了执行时间。此外，SurvLIMEpy还提供了可视化工具来更好地理解算法的结果。该包支持各种生存模型，从Cox比例风险模型到DeepHit或DeepSurv等深度学习模型。本文介绍了两种类型的实验。首先，通过模拟数据，我们研究了算法捕获特征重要性的能力。其次，在使用三个开源生存数据集以及一组生存算法时，我们展示了SurvLIMEpy在应用于不同数据集时的表现。

    In this paper we present SurvLIMEpy, an open-source Python package that implements the SurvLIME algorithm. This method allows to compute local feature importance for machine learning algorithms designed for modelling Survival Analysis data. Our implementation takes advantage of the parallelisation paradigm as all computations are performed in a matrix-wise fashion which speeds up execution time. Additionally, SurvLIMEpy assists the user with visualization tools to better understand the result of the algorithm. The package supports a wide variety of survival models, from the Cox Proportional Hazards Model to deep learning models such as DeepHit or DeepSurv. Two types of experiments are presented in this paper. First, by means of simulated data, we study the ability of the algorithm to capture the importance of the features. Second, we use three open source survival datasets together with a set of survival algorithms in order to demonstrate how SurvLIMEpy behaves when applied to differen
    
[^50]: RePrompt：自动提示编辑以精细表达AI生成艺术

    RePrompt: Automatic Prompt Editing to Refine AI-Generative Art Towards Precise Expressions. (arXiv:2302.09466v3 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2302.09466](http://arxiv.org/abs/2302.09466)

    本研究开发了一个名为RePrompt的自动化方法，通过优化文本提示来精确表达由AI生成的图像的情感表现力。

    

    生成式AI模型已经展示出通过文本提示产生图像的惊人能力，这可以使视觉艺术创作和自我表达方面受益。然而，目前还不清楚生成的图像如何精确地表达输入文本的情境和情感。本文探讨了AI生成图像的情感表现力，并开发了一个自动方法RePrompt，以精确表达生成的图像为目标来完善文本提示。受到众包编辑策略的启发，我们策划了直观的文本特征，例如名词的数量和具体性，并训练了一个代理模型来分析这些特征对AI生成图像的影响。通过代理模型的解释，我们策划了一个准则来调整文本提示，从而优化生成的图像以精确表达情感。我们进行了模拟和用户研究，结果表明RePrompt显著提高了AI生成图像的情感表现力，尤其是负面情感方面。

    Generative AI models have shown impressive ability to produce images with text prompts, which could benefit creativity in visual art creation and self-expression. However, it is unclear how precisely the generated images express contexts and emotions from the input texts. We explored the emotional expressiveness of AI-generated images and developed RePrompt, an automatic method to refine text prompts toward precise expression of the generated images. Inspired by crowdsourced editing strategies, we curated intuitive text features, such as the number and concreteness of nouns, and trained a proxy model to analyze the feature effects on the AI-generated image. With model explanations of the proxy model, we curated a rubric to adjust text prompts to optimize image generation for precise emotion expression. We conducted simulation and user studies, which showed that RePrompt significantly improves the emotional expressiveness of AI-generated images, especially for negative emotions.
    
[^51]: T2I-Adapter：学习适配器以挖掘文本到图像扩散模型更多可控制能力

    T2I-Adapter: Learning Adapters to Dig out More Controllable Ability for Text-to-Image Diffusion Models. (arXiv:2302.08453v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.08453](http://arxiv.org/abs/2302.08453)

    该论文提出利用T2I模型隐含学习的知识来更加精确地控制生成结果。通过训练简单轻量级的T2I适配器来对齐内部知识与外部控制信号，实现在生成结果的颜色和结构方面丰富的控制和编辑效果。

    

    大规模文本到图像（T2I）模型的惊人生成能力已经展示了学习复杂结构和有意义语义的强大能力。然而，仅仅依靠文本提示无法充分利用模型所学的知识，特别是当需要灵活精确的控制（例如颜色和结构）时。本文旨在“挖掘”T2I模型隐含学习的能力，然后明确地使用它们来更加精确地控制生成结果。具体而言，我们提出学习简单轻量级的T2I适配器，将T2I模型内部知识与外部控制信号对齐，同时保持原始大型T2I模型不变。通过这种方式，我们可以根据不同的条件训练各种适配器，实现在生成结果的颜色和结构方面丰富的控制和编辑效果。此外，所提出的T2I适配器具有组合性和生成效率等实际价值的吸引力。

    The incredible generative ability of large-scale text-to-image (T2I) models has demonstrated strong power of learning complex structures and meaningful semantics. However, relying solely on text prompts cannot fully take advantage of the knowledge learned by the model, especially when flexible and accurate controlling (e.g., color and structure) is needed. In this paper, we aim to ``dig out" the capabilities that T2I models have implicitly learned, and then explicitly use them to control the generation more granularly. Specifically, we propose to learn simple and lightweight T2I-Adapters to align internal knowledge in T2I models with external control signals, while freezing the original large T2I models. In this way, we can train various adapters according to different conditions, achieving rich control and editing effects in the color and structure of the generation results. Further, the proposed T2I-Adapters have attractive properties of practical value, such as composability and gen
    
[^52]: 具有有限数据访问的实用跨系统推销攻击

    Practical Cross-System Shilling Attacks with Limited Access to Data. (arXiv:2302.07145v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2302.07145](http://arxiv.org/abs/2302.07145)

    本文提出了跨系统推销攻击的新概念，设计了一个名为 PC-Attack 的实用框架。这个框架只需要很少的受害者推荐系统模型和目标推荐系统数据的信息即可进行攻击，并在公共推荐系统数据上进行了自我监督训练和微调，因此攻击成功率较高。

    

    在推销攻击中，敌对方会向推荐系统注入少量的虚假用户资料，以便推广或降低目标物品的排名。尽管已经把很多的努力放在开发模拟攻击方法上，但我们发现现有方法仍然远离实用化。在本文中，我们分析了具有实用推销攻击方法的属性，并提出了跨系统攻击的新概念。具体而言，基于跨系统攻击的思想，我们设计了一个实用的跨系统推销攻击 (PC-Attack) 框架，该框架对目标推荐系统模型和目标推荐系统数据的信息需求量很小。PC-Attack 自我监督地从公共推荐系统数据中获取了图形拓扑知识。然后，我们对它进行微调，利用易于访问的部分目标数据构建虚假资料。大量实验表明，PC-Attack 优于当前最先进的基线。我们的 PC-Attack 实现

    In shilling attacks, an adversarial party injects a few fake user profiles into a Recommender System (RS) so that the target item can be promoted or demoted. Although much effort has been devoted to developing shilling attack methods, we find that existing approaches are still far from practical. In this paper, we analyze the properties a practical shilling attack method should have and propose a new concept of Cross-system Attack. With the idea of Cross-system Attack, we design a Practical Cross-system Shilling Attack (PC-Attack) framework that requires little information about the victim RS model and the target RS data for conducting attacks. PC-Attack is trained to capture graph topology knowledge from public RS data in a self-supervised manner. Then, it is fine-tuned on a small portion of target data that is easy to access to construct fake profiles. Extensive experiments have demonstrated the superiority of PC-Attack over state-of-the-art baselines. Our implementation of PC-Attack
    
[^53]: 用户中心设计 (IX): 情报时代下的“用户体验3.0”范式框架

    User-Centered Design (IX): A "User Experience 3.0" Paradigm Framework in the Intelligence Era. (arXiv:2302.06681v5 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2302.06681](http://arxiv.org/abs/2302.06681)

    本文提出了一种“UX 3.0”范式框架和相应的UX方法系统，旨在满足情报时代对用户体验的新要求。

    

    基于“用户中心设计”理念的用户体验（UX）领域正在向情报时代迈进。然而，现有的UX范式主要针对非智能系统，并缺乏针对智能系统的系统化方法。在UX的发展过程中，UX范式呈现出跨技术时代的演进特征。目前，情报时代对UX范式提出了新的要求。因此，本文提出了一种“UX 3.0”范式框架和相应的UX方法系统。 “UX 3.0”范式框架包括五类UX方法：生态体验，创新体验，AI体验，基于人工智能交互的体验，以及基于人工智能协作的体验方法，每个方法都提供相应的多重UX范式取向。提出“UX 3.0”范式的建议有助于改进现有的UX方法，并提供方法。

    The field of user experience (UX) based on the design philosophy of "user-centered design" is moving towards the intelligence era. Still, the existing UX paradigm mainly aims at non-intelligent systems and lacks a systematic approach to UX for intelligent systems. Throughout the development of UX, the UX paradigm shows the evolution characteristics of the cross-technology era. At present, the intelligence era has put forward new demands on the UX paradigm. For this reason, this paper proposes a "UX 3.0" paradigm framework and the corresponding UX methodology system in the intelligence era. The "UX 3.0" paradigm framework includes five categories of UX methods: ecological experience, innovation-enabled experience, AI-enabled experience, human-AI interaction-based experience, and human-AI collaboration-based experience methods, each providing corresponding multiple UX paradigmatic orientations. The proposal of the "UX 3.0" paradigm helps improve the existing UX methods and provides metho
    
[^54]: 利用逻辑学习从嘈杂的众包标签中学习

    Learning from Noisy Crowd Labels with Logics. (arXiv:2302.06337v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06337](http://arxiv.org/abs/2302.06337)

    这篇论文介绍了一种利用逻辑引导的从嘈杂的众包标签中学习的框架，能够改进文本分类和命名实体识别等任务中，学习从嘈杂数据中提取有效信息的方法，这种框架能够融合逻辑知识，提高现有技术水平。

    

    本文探讨了将符号逻辑知识集成到深度神经网络中，从嘈杂的众包标签中学习的方法。我们引入了一种逻辑引导的从嘈杂的众包标签中学习的框架（Logic-LNCL），这是一种类似EM的迭代逻辑知识蒸馏框架，能够从嘈杂的标记数据和感兴趣的逻辑规则中进行学习。与传统的EM方法不同，我们的框架包含一种“伪E步骤”，从逻辑规则中蒸馏出一种新类型的学习目标，然后在“伪M步骤”中使用该目标来训练分类器。在文本情感分类和命名实体识别的两个真实世界数据集上进行的广泛评估表明，所提出的框架改进了最先进技术并为从嘈杂的众包标签中学习提供了一种新的解决方案。

    This paper explores the integration of symbolic logic knowledge into deep neural networks for learning from noisy crowd labels. We introduce Logic-guided Learning from Noisy Crowd Labels (Logic-LNCL), an EM-alike iterative logic knowledge distillation framework that learns from both noisy labeled data and logic rules of interest. Unlike traditional EM methods, our framework contains a ``pseudo-E-step'' that distills from the logic rules a new type of learning target, which is then used in the ``pseudo-M-step'' for training the classifier. Extensive evaluations on two real-world datasets for text sentiment classification and named entity recognition demonstrate that the proposed framework improves the state-of-the-art and provides a new solution to learning from noisy crowd labels.
    
[^55]: 基于细粒度语义信息的关系抽取FGSI：一种基于远程监督的方法

    FGSI: Distant Supervision for Relation Extraction method based on Fine-Grained Semantic Information. (arXiv:2302.02078v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.02078](http://arxiv.org/abs/2302.02078)

    本研究提出了一种基于远程监督的关系抽取方法，该方法通过利用句子中的细粒度语义信息来减少干扰信息，提高了实体关系提取的准确性。

    

    关系抽取的主要目的是提取句子中标记实体对之间的语义关系，它在句子的语义理解和知识图谱构建中发挥着重要作用。本文提出，在句子内部的关键语义信息对实体关系的提取起着重要作用。我们基于这个假设，按照实体在句子内部的位置将句子分为三段，并通过句内注意机制找到句子内部的细粒度语义特征，以减少无关噪声信息的干扰。所提出的关系抽取模型可以充分利用可用的正面语义信息。实验结果表明该方法在两个基准数据集上的表现优于几种最先进的基线方法。

    The main purpose of relation extraction is to extract the semantic relationships between tagged pairs of entities in a sentence, which plays an important role in the semantic understanding of sentences and the construction of knowledge graphs. In this paper, we propose that the key semantic information within a sentence plays a key role in the relationship extraction of entities. We propose the hypothesis that the key semantic information inside the sentence plays a key role in entity relationship extraction. And based on this hypothesis, we split the sentence into three segments according to the location of the entity from the inside of the sentence, and find the fine-grained semantic features inside the sentence through the intra-sentence attention mechanism to reduce the interference of irrelevant noise information. The proposed relational extraction model can make full use of the available positive semantic information. The experimental results show that the proposed relation extra
    
[^56]: 使用来自成对或$K$元比较的人类反馈的规范强化学习

    Principled Reinforcement Learning with Human Feedback from Pairwise or $K$-wise Comparisons. (arXiv:2301.11270v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11270](http://arxiv.org/abs/2301.11270)

    该论文提供了带有人类反馈强化学习问题的理论框架，证明了最大似然估计在Bradley-Terry-Luce和Plackett-Luce模型下收敛。此外，提出了在一定的覆盖假设下，基于悲观估计的MLE提供了性能更好的策略。在证明了真实MLE和以成对比较形式替代的备选MLE都可以在PL模型下收敛的同时，也表明了真实MLE的高效性。这些结果为RLHF算法提供了新的见解，并统一了RLHF问题和IRL问题。

    

    我们为带有人类反馈的强化学习问题提供了一个理论框架。我们的分析表明，当真实奖励函数为线性函数时，最大似然估计（MLE）在Bradley-Terry-Luce（BTL）模型和Plackett-Luce（PL）模型下均收敛。然而，我们发现当基于学得的奖励模型训练策略时，MLE会失败，而基于悲观估计的MLE在一定的覆盖假设下提供性能更好的策略。此外，我们证明在PL模型下，真实MLE和将$k$元比较拆分为成对比较的备选MLE都收敛。而真实MLE是渐近更为高效的。我们的结果验证了现有RLHF算法（如InstructGPT）的实验成功，并为算法设计提供了新的见解。此外，我们的结果统一了RLHF问题和最大熵反向强化学习(IRL)问题，并为其提供了第一个样本复杂度界。

    We provide a theoretical framework for Reinforcement Learning with Human Feedback (RLHF). Our analysis shows that when the true reward function is linear, the widely used maximum likelihood estimator (MLE) converges under both the Bradley-Terry-Luce (BTL) model and the Plackett-Luce (PL) model. However, we show that when training a policy based on the learned reward model, MLE fails while a pessimistic MLE provides policies with improved performance under certain coverage assumptions. Additionally, we demonstrate that under the PL model, the true MLE and an alternative MLE that splits the $K$-wise comparison into pairwise comparisons both converge. Moreover, the true MLE is asymptotically more efficient. Our results validate the empirical success of existing RLHF algorithms in InstructGPT and provide new insights for algorithm design. Furthermore, our results unify the problem of RLHF and max-entropy Inverse Reinforcement Learning (IRL), and provide the first sample complexity bound fo
    
[^57]: 一个基于误差引导的模型用于汉语拼写纠错

    An Error-Guided Correction Model for Chinese Spelling Error Correction. (arXiv:2301.06323v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.06323](http://arxiv.org/abs/2301.06323)

    本文提出了一个基于误差引导的模型用于改进汉语拼写纠错，它采用了零-shot误差检测、新的损失函数和高度并行的解码等方法，在实验中表现优于先进方法。

    

    虽然现有的神经网络方法在汉语拼写纠错方面取得了巨大成功，但仍有进一步提高的空间。在本文中，我们提出了一个误差引导的纠错模型（EGCM）来改进汉语拼写纠错。通过借鉴BERT的强大能力，我们提出了一种新的零-shot误差检测方法来进行初步检测，这样可以指导我们的模型在编码时更多地关注可能错误的标记，并在生成时避免修改正确的标记。此外，我们还引入了新的损失函数来集成误差混淆集，这使得我们的模型能够轻松区分易混淆的标记。此外，我们的模型支持高度并行的解码，以满足实际应用的要求。我们在广泛使用的基准测试中进行了实验。我们的模型优于先进方法。

    Although existing neural network approaches have achieved great success on Chinese spelling correction, there is still room to improve. The model is required to avoid over-correction and to distinguish a correct token from its phonological and visually similar ones. In this paper, we propose an error-guided correction model (EGCM) to improve Chinese spelling correction. By borrowing the powerful ability of BERT, we propose a novel zero-shot error detection method to do a preliminary detection, which guides our model to attend more on the probably wrong tokens in encoding and to avoid modifying the correct tokens in generating. Furthermore, we introduce a new loss function to integrate the error confusion set, which enables our model to distinguish easily misused tokens. Moreover, our model supports highly parallel decoding to meet real application requirements. Experiments are conducted on widely used benchmarks. Our model achieves superior performance against state-of-the-art approach
    
[^58]: 走向AI-enabled连接产业: AGV通信和传感器测量数据集

    Towards an AI-enabled Connected Industry: AGV Communication and Sensor Measurement Datasets. (arXiv:2301.03364v3 [cs.NI] UPDATED)

    [http://arxiv.org/abs/2301.03364](http://arxiv.org/abs/2301.03364)

    本文介绍了两个无线测量活动所提供的数据集，并将其与机器学习结合起来用于指纹识别、视线检测、服务质量预测或链路选择等任务。

    

    本文介绍了两个工业测试平台上的无线测量活动: 工业车辆间通信(iV2V)和工业车辆到基础设施加传感器(iV2I+)。提供了关于这两个捕获数据集的详细信息。iV2V涵盖了自动引导车(AGVs)之间的侧向链路通信场景，而iV2I+则是在工业设置中进行的，其中自主清洁机器人连接到私有蜂窝网络。不同通信技术的组合，连同共同的测量方法，提供了机器学习(ML)可以利用的洞察力，用于指纹识别、视线检测、服务质量预测或链路选择等任务。此外，数据集已标记和预过滤，以便快速启动和应用。对于两个数据集，还详细介绍了相应的测试平台和测量情况。

    This paper presents two wireless measurement campaigns in industrial testbeds: industrial Vehicle-to-vehicle (iV2V) and industrial Vehicle-to-infrastructure plus Sensor (iV2I+). Detailed information about the two captured datasets is provided as well. iV2V covers sidelink communication scenarios between Automated Guided Vehicles (AGVs), while iV2I+ is conducted at an industrial setting where an autonomous cleaning robot is connected to a private cellular network. The combination of different communication technologies, together with a common measurement methodology, provides insights that can be exploited by Machine Learning (ML) for tasks such as fingerprinting, line-of-sight detection, prediction of quality of service or link selection. Moreover, the datasets are labelled and pre-filtered for fast on-boarding and applicability. The corresponding testbeds and measurements are also presented in detail for both datasets.
    
[^59]: 接近峰值地面真相

    Approaching Peak Ground Truth. (arXiv:2301.00243v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.00243](http://arxiv.org/abs/2301.00243)

    介绍了PGT理论概念和近似PGT的定量技术，为评估和提高机器学习模型在生物医学领域中的性能提供了策略。

    

    通常通过计算与参考标注的相似度来评估机器学习模型，并通过最大化与它们的相似度进行训练。尤其是在生物医学领域，标注是主观的，并且具有低的评标者间和评标者内可靠性。由于标注仅反映世界的一种解释，即使模型达到了高相似度分数，这也可能导致次优预测。本文引入了理论上的PGT概念。PGT标记了与参考注释的相似度增加不再转化为更好的RWMP的点。此外，还提出了一种通过计算评标者间和评标者内可靠性来近似PGT的定量技术。最后，回顾了四类PGT感知策略，以评估和提高模型性能。

    Machine learning models are typically evaluated by computing similarity with reference annotations and trained by maximizing similarity with such. Especially in the biomedical domain, annotations are subjective and suffer from low inter- and intra-rater reliability. Since annotations only reflect one interpretation of the real world, this can lead to sub-optimal predictions even though the model achieves high similarity scores. Here, the theoretical concept of PGT is introduced. PGT marks the point beyond which an increase in similarity with the \emph{reference annotation} stops translating to better RWMP. Additionally, a quantitative technique to approximate PGT by computing inter- and intra-rater reliability is proposed. Finally, four categories of PGT-aware strategies to evaluate and improve model performance are reviewed.
    
[^60]: MN-DS：新闻文章层次分类的多标签数据集

    MN-DS: A Multilabeled News Dataset for News Articles Hierarchical Classification. (arXiv:2212.12061v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.12061](http://arxiv.org/abs/2212.12061)

    本文介绍了一个包含10,917篇新闻文章的多标签数据集，可用于训练机器学习模型自动按主题对新闻文章进行分类，对新闻结构、分类和预测未来事件的研究人员非常有帮助。

    

    本文介绍了一个数据集，其中包含10,917篇新闻文章，涵盖了从2019年1月1日到2019年12月31日的层次新闻分类。我们根据17个一级类别和109个二级类别的层次分类手动标记了这些文章。该数据集可用于训练机器学习模型，以自动按主题分类新闻文章。该数据集对于从事新闻结构、分类和根据发布的新闻预测未来事件的研究人员非常有帮助。

    This article presents a dataset of 10,917 news articles with hierarchical news categories collected between January 1st 2019, and December 31st 2019. We manually labelled the articles based on a hierarchical taxonomy with 17 first-level and 109 second-level categories. This dataset can be used to train machine learning models for automatically classifying news articles by topic. This dataset can be helpful for researchers working on news structuring, classification, and predicting future events based on released news.
    
[^61]: 关于语义分割模型的校准：分析与算法

    On Calibrating Semantic Segmentation Models: Analyses and An Algorithm. (arXiv:2212.12053v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.12053](http://arxiv.org/abs/2212.12053)

    本文系统研究了语义分割模型的校准问题，提出了一种简单而有效的方法——选择性缩放，通过将正确/错误预测分开进行缩放，并更加关注错误预测的逻辑平滑，此方法在语义分割校准上取得了良好效果。

    

    我们研究了语义分割校准的问题。虽然已经提出了很多解决方案来处理图像分类置信度的模型误校准，但至今为止，对语义分割的置信度校准研究仍然很有限。我们对语义分割模型的校准进行了系统研究，并提出了一种简单而有效的方法。首先，我们发现模型容量、裁剪大小、多尺度测试和预测正确性对校准有影响。其中，预测正确性，特别是错误预测，对由于过度置信而导致的误校准更为重要。接下来，我们提出了一种简单、统一且有效的方法，即选择性缩放，通过将正确/错误预测分开进行缩放，并更加关注错误预测的逻辑平滑。然后，我们研究了流行的现有校准方法，并将它们与选择性缩放在语义分割校准上进行比较。我们进行了大量实验，使用了多种数据集和语义分割模型，以验证我们提出的方法的有效性。

    We study the problem of semantic segmentation calibration. Lots of solutions have been proposed to approach model miscalibration of confidence in image classification. However, to date, confidence calibration research on semantic segmentation is still limited. We provide a systematic study on the calibration of semantic segmentation models and propose a simple yet effective approach. First, we find that model capacity, crop size, multi-scale testing, and prediction correctness have impact on calibration. Among them, prediction correctness, especially misprediction, is more important to miscalibration due to over-confidence. Next, we propose a simple, unifying, and effective approach, namely selective scaling, by separating correct/incorrect prediction for scaling and more focusing on misprediction logit smoothing. Then, we study popular existing calibration methods and compare them with selective scaling on semantic segmentation calibration. We conduct extensive experiments with a vari
    
[^62]: 查询作为上下文的预训练技术用于密集型通道检索

    Query-as-context Pre-training for Dense Passage Retrieval. (arXiv:2212.09598v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2212.09598](http://arxiv.org/abs/2212.09598)

    本文提出了一种名为查询作为上下文的预训练技术，将查询作为上下文，形成一对通道-查询对，用于缓解密集型通道检索中可能存在的弱相关对，并在大规模基准测试上证明了其有效性和效率。

    

    最近，人们研究出通过使用上下文有监督的预训练技术来提高密集型通道检索性能的方法。这些方法简单地认为来自同一文档的两个通道是相关的，而不考虑可能存在的弱相关对。因此，本文提出了一种名为查询作为上下文的预训练技术，该技术简单而有效，用于缓解这个问题。查询作为上下文的预训练技术假定从通道中提取的查询更可能与该通道相关，并形成一对通道-查询对。这些通道-查询对然后用于对比性或生成性上下文有监督的预训练。预训练模型在大规模通道检索基准测试和跨领域零-shot基准测试上进行评估。实验结果表明，查询作为上下文的预训练技术带来了相当大的增益，同时加速了训练，证明了其有效性和效率。我们的代码将会在https://github.com/deepset-ai/haystack上提供下载。

    Recently, methods have been developed to improve the performance of dense passage retrieval by using context-supervised pre-training. These methods simply consider two passages from the same document to be relevant, without taking into account the possibility of weakly correlated pairs. Thus, this paper proposes query-as-context pre-training, a simple yet effective pre-training technique to alleviate the issue. Query-as-context pre-training assumes that the query derived from a passage is more likely to be relevant to that passage and forms a passage-query pair. These passage-query pairs are then used in contrastive or generative context-supervised pre-training. The pre-trained models are evaluated on large-scale passage retrieval benchmarks and out-of-domain zero-shot benchmarks. Experimental results show that query-as-context pre-training brings considerable gains and meanwhile speeds up training, demonstrating its effectiveness and efficiency. Our code will be available at https://g
    
[^63]: 损失通信下车辆之间协同感知的学习

    Learning for Vehicle-to-Vehicle Cooperative Perception under Lossy Communication. (arXiv:2212.08273v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.08273](http://arxiv.org/abs/2212.08273)

    本文研究了复杂驾驶场景下可能存在的损失共享特征的情况对车辆协同感知的影响，并提出了一种新的损失通信感知特征融合方法，通过损失通信感知修复网络缓解了损失通信的副作用并增强了感知性能。

    

    深度学习被广泛应用于智能车辆驾驶中的感知（例如3D物体检测）中。由于有益的车辆间通信（V2V），基于深度学习的来自其他代理的特征可以共享给本车，以提高本车的感知能力。这被称为V2V研究中的协同感知，其算法最近得到了显著的发展。然而，所有现有的协同感知算法都假定理想的V2V通信，而没有考虑复杂的现实驾驶场景中可能出现的损失共享特征的情况。本文首先研究了V2V协同感知中损失通信的副作用（例如检测性能下降），然后提出了一种新的中间损失通信感知特征融合方法，通过损失通信感知修复网络（LCRN）缓解了损失通信的副作用并增强了感知性能。

    Deep learning has been widely used in the perception (e.g., 3D object detection) of intelligent vehicle driving. Due to the beneficial Vehicle-to-Vehicle (V2V) communication, the deep learning based features from other agents can be shared to the ego vehicle so as to improve the perception of the ego vehicle. It is named as Cooperative Perception in the V2V research, whose algorithms have been dramatically advanced recently. However, all the existing cooperative perception algorithms assume the ideal V2V communication without considering the possible lossy shared features because of the Lossy Communication (LC) which is common in the complex real-world driving scenarios. In this paper, we first study the side effect (e.g., detection performance drop) by the lossy communication in the V2V Cooperative Perception, and then we propose a novel intermediate LC-aware feature fusion method to relieve the side effect of lossy communication by a LC-aware Repair Network (LCRN) and enhance the int
    
[^64]: 实现对手术场景的整体理解：针对机器人辅助下的前列腺癌根治术视频

    Towards Holistic Surgical Scene Understanding. (arXiv:2212.04582v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.04582](http://arxiv.org/abs/2212.04582)

    本研究提出了一个新实验框架，PSI-AVA数据集，以实现对机器人辅助下的前列腺癌根治术视频的整体理解。同时，我们的实验结果证明了基于TAPIR的手术场景理解框架的有效性。

    

    大多数用于研究手术干预的基准测试都集中在特定挑战上，而忽略了不同任务间内在的互补性。本文提出了一个新的实验框架，以实现对手术场景的整体理解。首先，我们介绍了Phase、Step、Instrument和Atomic Visual Action（PSI-AVA）数据集。PSI-AVA在机器人辅助下的前列腺癌根治术视频中，对长期（阶段和步骤的识别）和短期推理（器械检测和新型原子动作识别）进行注释。其次，我们提出了TAPIR，即Transformers for Action，Phase，Instrument和Steps Recognition，作为手术场景理解的强基准。TAPIR利用我们数据集的多级注释，通过器械检测任务上学习的表示方式，提高了其分类能力。我们在PSI-AVA和其他公开数据库中的实验结果证明，我们提出的整体手术场景理解框架是充分有效的。

    Most benchmarks for studying surgical interventions focus on a specific challenge instead of leveraging the intrinsic complementarity among different tasks. In this work, we present a new experimental framework towards holistic surgical scene understanding. First, we introduce the Phase, Step, Instrument, and Atomic Visual Action recognition (PSI-AVA) Dataset. PSI-AVA includes annotations for both long-term (Phase and Step recognition) and short-term reasoning (Instrument detection and novel Atomic Action recognition) in robot-assisted radical prostatectomy videos. Second, we present Transformers for Action, Phase, Instrument, and steps Recognition (TAPIR) as a strong baseline for surgical scene understanding. TAPIR leverages our dataset's multi-level annotations as it benefits from the learned representation on the instrument detection task to improve its classification capacity. Our experimental results in both PSI-AVA and other publicly available databases demonstrate the adequacy o
    
[^65]: LLM-Planner: 利用大型语言模型进行少样本实体代理规划

    LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models. (arXiv:2212.04088v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.04088](http://arxiv.org/abs/2212.04088)

    本研究提出了一种新颖的方法LLM-Planner，利用大型语言模型为实体代理进行少样本规划，以实体代理目前所在的环境为基础，增强LLMs生成和更新计划，实验表明其在多任务和快速学习新任务的通用代理的开发中具有很好的表现。

    

    本研究关注利用大型语言模型（LLMs）作为规划器，让实体代理可以按照自然语言指令完成在视觉感知环境中的复杂任务。现有方法的高数据成本和低样本效率阻碍了多任务和快速学习新任务的通用代理的开发。本文提出了一种新颖的方法LLM-Planner，利用大型语言模型为实体代理进行少样本规划。我们进一步提出了一种简单但有效的方法，以实体代理目前所在的环境为基础，增强LLMs生成和更新计划。在ALFRED数据集上的实验表明，我们的方法可以取得非常有竞争力的少样本性能：尽管使用的配对训练数据不到0.5％，LLM-Planner的表现与使用完整训练数据训练的最新基线相当。现有方法几乎无法完成任何任务。

    This study focuses on using large language models (LLMs) as a planner for embodied agents that can follow natural language instructions to complete complex tasks in a visually-perceived environment. The high data cost and poor sample efficiency of existing methods hinders the development of versatile agents that are capable of many tasks and can learn new tasks quickly. In this work, we propose a novel method, LLM-Planner, that harnesses the power of large language models to do few-shot planning for embodied agents. We further propose a simple but effective way to enhance LLMs with physical grounding to generate and update plans that are grounded in the current environment. Experiments on the ALFRED dataset show that our method can achieve very competitive few-shot performance: Despite using less than 0.5% of paired training data, LLM-Planner achieves competitive performance with recent baselines that are trained using the full training data. Existing methods can barely complete any ta
    
[^66]: 基于配对互补时间循环一致对抗网络的雷达降水预测方法

    PCT-CycleGAN: Paired Complementary Temporal Cycle-Consistent Adversarial Networks for Radar-Based Precipitation Nowcasting. (arXiv:2211.15046v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.15046](http://arxiv.org/abs/2211.15046)

    本文提出了一种基于配对互补时间循环一致对抗网络的雷达降水预测方法，该方法包括两个生成器网络和循环一致性损失和对抗性损失。实验证明，该方法在准确性和推广能力方面优于现有的技术方法。

    

    降水预测方法已经在过去几个世纪里得到了很好的发展，因为雨水对人类生活有着至关重要的影响。现有的降水预测模型包括定量降水预测 (QPF) 模型、卷积长短期记忆 (ConvLSTM) 模型以及最新的 MetNet-2 等多种复杂的方法。本文提出了基于配对互补时间循环一致对抗网络 (PCT-CycleGAN) 的雷达降水预测方法，受对抗生成网络 (CycleGAN) 强大的图像转换性能启发。PCT-CycleGAN 使用两个具有向前和向后时间动态的生成器网络生成时序性，每个生成器网络学习一个庞大的一对一映射，以逼近表示每个方向上的时间动态的映射函数。为了创建配对互补循环之间的强健时间因果关系，我们应用了循环一致性损失和对抗性损失。广泛的实验证明，PCT-CycleGAN 在准确性和推广能力方面优于现有的技术方法。

    The precipitation nowcasting methods have been elaborated over the centuries because rain has a crucial impact on human life. Not only quantitative precipitation forecast (QPF) models and convolutional long short-term memory (ConvLSTM), but also various sophisticated methods such as the latest MetNet-2 are emerging. In this paper, we propose a paired complementary temporal cycle-consistent adversarial networks (PCT-CycleGAN) for radar-based precipitation nowcasting, inspired by cycle-consistent adversarial networks (CycleGAN), which shows strong performance in image-to-image translation. PCT-CycleGAN generates temporal causality using two generator networks with forward and backward temporal dynamics in paired complementary cycles. Each generator network learns a huge number of one-to-one mappings about time-dependent radar-based precipitation data to approximate a mapping function representing the temporal dynamics in each direction. To create robust temporal causality between paired 
    
[^67]: 通过自回归光场反演从单张图像中重构形状、姿态和外观

    Shape, Pose, and Appearance from a Single Image via Bootstrapped Radiance Field Inversion. (arXiv:2211.11674v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.11674](http://arxiv.org/abs/2211.11674)

    本文提出了一个自回归光场反演框架，可以从单个图像中恢复 SDF 参数化的 3D 形状、姿态和外观，而无需准确的真实姿势，且速度快、计算有效。

    

    组合神经辐射场 (NeRF) 和生成对抗网络 (GAN) 在从单视角进行三维重建方面展现出了很好的潜力，因为它们能够有效地建模任意拓扑结构。然而，最近该领域的工作主要集中在合成数据集上，其中确切的地面真实姿势是已知的，并忽略了姿势估计，而姿势估计是某些下游应用，如增强现实 (AR) 和机器人技术中的关键问题。本文提出了一种自然图像的有原则的端到端重建框架，其中准确的真实姿势是不可用的。我们的方法从一个物体的单个图像中恢复了 SDF 参数化的 3D 形状、姿态和外观，而没有在训练过程中利用多个视角。具体来说，我们利用了一个无条件的 3D-aware 生成器，对其应用了混合反演方案，其中一个模型产生了解的第一个猜测，然后通过优化进行改进。我们的框架可以在一次前向传递中对图像进行去渲染，因此速度快且计算有效。我们证明了我们的方法在 DTU 和 Tanks & Temples 等基准测试中优于现有最先进技术，并证明了在真实世界图像上的有效性。

    Neural Radiance Fields (NeRF) coupled with GANs represent a promising direction in the area of 3D reconstruction from a single view, owing to their ability to efficiently model arbitrary topologies. Recent work in this area, however, has mostly focused on synthetic datasets where exact ground-truth poses are known, and has overlooked pose estimation, which is important for certain downstream applications such as augmented reality (AR) and robotics. We introduce a principled end-to-end reconstruction framework for natural images, where accurate ground-truth poses are not available. Our approach recovers an SDF-parameterized 3D shape, pose, and appearance from a single image of an object, without exploiting multiple views during training. More specifically, we leverage an unconditional 3D-aware generator, to which we apply a hybrid inversion scheme where a model produces a first guess of the solution which is then refined via optimization. Our framework can de-render an image in as few a
    
[^68]: Point-MA2E:自监督点云学习的掩膜和仿射变换自编码器

    Point-MA2E: Masked and Affine Transformed AutoEncoder for Self-supervised Point Cloud Learning. (arXiv:2211.06841v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.06841](http://arxiv.org/abs/2211.06841)

    本文介绍了一种点云学习的自监督方法Point-MA2E，通过同时采用掩膜和仿射变换策略，实现了从损坏点云到还原点云的重建，扩展了目前掩膜方法的不足。

    

    在自监督点云学习中，掩膜建模已经证明了其有效性，通过从其掩膜对应部分重建完整点云。考虑到掩膜只会损坏输入的一部分点，本文推广仿射变换策略，通过特定规则破坏所有输入点，以补充流行的掩膜策略，从而实现点云学习的掩膜和仿射变换自编码器（Point-MA2E）。在此研究中，我们对点云进行仿射变换和掩膜，使用编码器-解码器模型从其损坏版本中重建原始点云。探索了各种点云编码器。对于非Transformer编码器，按照常见做法直接重建未损坏的点云。对于基于Transformer的编码器，我们将重建完整点云分解为详细的局部补丁和粗略的全局形状的重建。

    Masked modeling has demonstrated its effectiveness in self-supervised point cloud learning by reconstructing the complete point cloud from its masked counterpart. Considering that masking only corrupts partial points of the input, in this paper, we promote the affine transformation, which corrupts all input points with certain rules, to complement the popular masking strategy, leading to the Masked and Affine transformed AutoEncoder for point cloud learning (Point-MA2E). Generally, we corrupt the point cloud with affine transformation and masking as input and learn an encoder-decoder model to reconstruct the original point cloud from its corrupted version. Various point cloud encoders are explored in this study. For non-Transformer encoders, we follow the common practice to reconstruct the uncorrupted point cloud directly. For Transformer-based encoders, we decompose the reconstruction of the complete point cloud into the reconstructions of detailed local patches and rough global shape
    
[^69]: 在线合同设计的样本复杂度

    The Sample Complexity of Online Contract Design. (arXiv:2211.05732v2 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2211.05732](http://arxiv.org/abs/2211.05732)

    本文解决了在线合同设计中一个悬而未决的问题，证明了指数级的$m$个样本就足以学习一个近乎最优的合同。

    

    本文研究在线情境下的隐藏-行动委托问题。在每轮中，委托人发布一份合同，根据每个结果规定代理人的支付。代理人然后做出一个最大化她自己效用的战略行动选择，但直接观察不到行动。委托人观察结果并从代理人的行动选择中获得效用。根据过去的观察，委托人动态地调整合同，目标是最大化其效用。我们引入了一种在线学习算法，并给出了其Stackelberg遗憾的上界。我们证明，在合同空间为$[0,1]^m$时，Stackelberg遗憾的上界为$\widetilde O(\sqrt{m} \cdot T^{1-1/(2m+1)})$，下界为$\Omega(T^{1-1/(m+2)})$，其中$\widetilde O$排除对数因子。 这个结果表明，指数级的$m$个样本就足以学习一个近乎最优的合同，解决了在线合同设计中的一个悬而未决的问题。

    We study the hidden-action principal-agent problem in an online setting. In each round, the principal posts a contract that specifies the payment to the agent based on each outcome. The agent then makes a strategic choice of action that maximizes her own utility, but the action is not directly observable by the principal. The principal observes the outcome and receives utility from the agent's choice of action. Based on past observations, the principal dynamically adjusts the contracts with the goal of maximizing her utility.  We introduce an online learning algorithm and provide an upper bound on its Stackelberg regret. We show that when the contract space is $[0,1]^m$, the Stackelberg regret is upper bounded by $\widetilde O(\sqrt{m} \cdot T^{1-1/(2m+1)})$, and lower bounded by $\Omega(T^{1-1/(m+2)})$, where $\widetilde O$ omits logarithmic factors. This result shows that exponential-in-$m$ samples are sufficient and necessary to learn a near-optimal contract, resolving an open probl
    
[^70]: 面向语音识别的改进室内声学环境下声道冲激响应估计

    Towards Improved Room Impulse Response Estimation for Speech Recognition. (arXiv:2211.04473v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2211.04473](http://arxiv.org/abs/2211.04473)

    本论文提出了一种新颖的基于GAN的架构，用于在声学环境中估计室内声道冲激响应，并在自动语音识别任务中展示了其性能优越性。

    

    我们提出了一种针对下游应用情境（远场自动语音识别）中盲目估计室内声学环境下声道冲激响应的新方法。我们描述了改善声道冲激响应估计和提高语音识别性能之间的联系，以评估神经声道冲激响应估计器。我们提出了一种基于生成对抗网络（GAN）的架构，该架构从残响语音中编码RIR特征并构建RIR，并使用新的能量衰减缓解损失来优化捕获输入残响语音的能量相关特征。我们展示了我们的模型在声学基准测试上优于现有最先进基线模型（能量衰减缓解指标上提高了17％，早期反射能量性能指标上提高了22％），并且在语音识别评估任务中有6.9％的词误率降低。

    We propose a novel approach for blind room impulse response (RIR) estimation systems in the context of a downstream application scenario, far-field automatic speech recognition (ASR). We first draw the connection between improved RIR estimation and improved ASR performance, as a means of evaluating neural RIR estimators. We then propose a generative adversarial network (GAN) based architecture that encodes RIR features from reverberant speech and constructs an RIR from the encoded features, and uses a novel energy decay relief loss to optimize for capturing energy-based properties of the input reverberant speech. We show that our model outperforms the state-of-the-art baselines on acoustic benchmarks (by 17\% on the energy decay relief and 22\% on an early-reflection energy metric), as well as in an ASR evaluation task (by 6.9\% in word error rate).
    
[^71]: NESTER：一种自适应的神经符号化方法进行治疗效果评估

    NESTER: An Adaptive Neurosymbolic Method for Treatment Effect Estimation. (arXiv:2211.04370v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.04370](http://arxiv.org/abs/2211.04370)

    NESTER是一种自适应的神经符号化方法进行治疗效果评估，将治疗效果估计的所有要求集成到一个框架中，该方法比现有最先进的方法在多个基准数据集上性能更好。

    

    从观测数据中进行治疗效果评估是因果推断中的一个核心问题。基于潜在结果框架的方法通过利用因果推断中的归纳偏置和启发式方法来解决这个问题。每种现有的技术都通过设计神经网络架构和正则化器来解决治疗效果评估的特定方面，例如控制倾向得分、强制随机化等。在本文中，我们提出了一种自适应方法，称为神经符号治疗效果估计器（NESTER），它是一种治疗效果评估的通用方法。NESTER将治疗效果估计的所有要求集成到一个框架中。为此，我们设计了一个基于文献中使用的归纳偏置的治疗效果估计的领域特定语言（DSL）。我们还在理论上研究了NESTER在治疗效果估计任务中的能力。我们全面的实证结果表明，与现有的最先进方法相比，NESTER在多个基准数据集上的效果更好。

    Treatment effect estimation from observational data is a central problem in causal inference. Methods based on potential outcomes framework solve this problem by exploiting inductive biases and heuristics from causal inference. Each existing technique addresses a specific aspect of treatment effect estimation, such as controlling propensity score, enforcing randomization, etc., by designing neural network architectures and regularizers. In this paper, we propose an adaptive method called Neurosymbolic Treatment Effect Estimator (NESTER), a generalized method for treatment effect estimation. NESTER brings together all the desiderata for treatment effect estimation into one framework. For this purpose, we design a Domain Specific Language (DSL) for the treatment effect estimation based on inductive biases used in literature. We also theoretically study NESTER's capability for the treatment effect estimation task. Our comprehensive empirical results show that NESTER performs better on ben
    
[^72]: 高效的多阶门控聚合网络

    Efficient Multi-order Gated Aggregation Network. (arXiv:2211.03295v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.03295](http://arxiv.org/abs/2211.03295)

    本文探索了现代卷积神经网络的表征能力，使用多阶博弈论交互的新视角，提出了一种新的纯卷积神经网络架构MogaNet，它表现出优异的可扩展性，并在多种典型视觉基准中以更高效的参数利用达到了与最先进模型竞争的效果。

    

    自从视觉变换器（ViTs）取得最近的成功之后，对ViT风格架构的探索引发了卷积神经网络的复兴。在本文中，我们从多阶博弈论交互的新视角探索了现代卷积神经网络的表征能力，这种交互反映了基于博弈论的不同尺度上下文的变量相互作用效应。在现代卷积神经网络框架内，我们使用概念上简单而有效的深度可分离卷积来定制两个特征混合器，以促进跨空间和通道空间的中阶信息。在这个基础上，提出了一种新的纯卷积神经网络架构，称为MogaNet，它表现出优异的可扩展性，并在ImageNet和包括COCO目标检测、ADE20K语义分割、2D&3D人体姿势估计以及视频预测等多种典型视觉基准中以更高效的参数利用达到了与最先进模型竞争的效果。

    Since the recent success of Vision Transformers (ViTs), explorations toward ViT-style architectures have triggered the resurgence of ConvNets. In this work, we explore the representation ability of modern ConvNets from a novel view of multi-order game-theoretic interaction, which reflects inter-variable interaction effects w.r.t.~contexts of different scales based on game theory. Within the modern ConvNet framework, we tailor the two feature mixers with conceptually simple yet effective depthwise convolutions to facilitate middle-order information across spatial and channel spaces respectively. In this light, a new family of pure ConvNet architecture, dubbed MogaNet, is proposed, which shows excellent scalability and attains competitive results among state-of-the-art models with more efficient use of parameters on ImageNet and multifarious typical vision benchmarks, including COCO object detection, ADE20K semantic segmentation, 2D\&3D human pose estimation, and video prediction. Typica
    
[^73]: 破碎的神经缩放定律

    Broken Neural Scaling Laws. (arXiv:2210.14891v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.14891](http://arxiv.org/abs/2210.14891)

    本文提出了一个平滑破碎的幂律函数形式，可以准确地模拟和外推深度神经网络的缩放行为，适用于各种架构和大量不同任务，包括视觉、语言、音频、视频、生成建模、对比学习、机器人、不确定性估计/校准、对抗鲁棒性、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。

    This paper proposes a smoothly broken power law functional form (referred to as a Broken Neural Scaling Law (BNSL)) that accurately models and extrapolates the scaling behaviors of deep neural networks for various architectures and a large and diverse set of tasks, including vision, language, audio, video, generative modeling, contrastive learning, robotics, uncertainty estimation/calibration, adversarial robustness, molecules, computer programming/coding, math word problems, arithmetic, unsupervised/self-supervised learning, and reinforcement learning.

    我们提出了一个平滑破碎的幂律函数形式（我们称之为破碎的神经缩放定律（BNSL）），它准确地模拟和外推了深度神经网络的缩放行为（即感兴趣的评估指标随用于训练的计算量、模型参数数量、训练数据集大小或上游性能变化而变化）对于各种架构和大量不同任务中的每个任务，包括大规模视觉、语言、音频、视频、扩散、生成建模、多模态学习、对比学习、AI对齐、机器人、超出分布（OOD）泛化、持续学习、不确定性估计/校准、超出分布检测、对抗鲁棒性、蒸馏、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。

    We present a smoothly broken power law functional form (referred to by us as a Broken Neural Scaling Law (BNSL)) that accurately models and extrapolates the scaling behaviors of deep neural networks (i.e. how the evaluation metric of interest varies as the amount of compute used for training, number of model parameters, training dataset size, or upstream performance varies) for various architectures and for each of various tasks within a large and diverse set of upstream and downstream tasks, in zero-shot, prompted, and fine-tuned settings. This set includes large-scale vision, language, audio, video, diffusion, generative modeling, multimodal learning, contrastive learning, AI alignment, robotics, out-of-distribution (OOD) generalization, continual learning, uncertainty estimation / calibration, out-of-distribution detection, adversarial robustness, distillation, molecules, computer programming/coding, math word problems, arithmetic, unsupervised/self-supervised learning, and reinforc
    
[^74]: 基于特征符合预测的预测推断

    Predictive Inference with Feature Conformal Prediction. (arXiv:2210.00173v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.00173](http://arxiv.org/abs/2210.00173)

    本文提出基于特征符合预测的预测推断方法，通过利用深度表示学习的归纳偏置，扩展了符合预测到语义特征空间。从理论和实验结果来看，该方法优于常规符合预测，并在大规模任务上展现了最先进性能。

    

    符合预测是一种无分布技术，用于建立有效的预测间隔。虽然传统上人们在输出空间中进行符合预测，但这并不是唯一的可能性。在本文中，我们提出了基于特征的符合预测，通过利用深度表示学习的归纳偏置，扩展了符合预测对语义特征空间的范围。从理论上讲，我们证明了基于特征的符合预测在温和假设下可以证明优于常规符合预测。我们的方法不仅可以与普通符合预测结合使用，而且可以与其他自适应符合预测方法结合使用。除了现有预测推断基准测试的实验外，我们还展示了该方法在大规模任务（如ImageNet分类和Cityscapes图像分割）上的最先进性能。

    Conformal prediction is a distribution-free technique for establishing valid prediction intervals. Although conventionally people conduct conformal prediction in the output space, this is not the only possibility. In this paper, we propose feature conformal prediction, which extends the scope of conformal prediction to semantic feature spaces by leveraging the inductive bias of deep representation learning. From a theoretical perspective, we demonstrate that feature conformal prediction provably outperforms regular conformal prediction under mild assumptions. Our approach could be combined with not only vanilla conformal prediction, but also other adaptive conformal prediction methods. Apart from experiments on existing predictive inference benchmarks, we also demonstrate the state-of-the-art performance of the proposed methods on large-scale tasks such as ImageNet classification and Cityscapes image segmentation.
    
[^75]: 存在扰动情况下强化学习的安全探索方法

    Safe Exploration Method for Reinforcement Learning under Existence of Disturbance. (arXiv:2209.15452v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.15452](http://arxiv.org/abs/2209.15452)

    本文提出了一种能够在存在扰动情况下安全进行强化学习探索的方法，该方法利用了所控制对象和扰动的部分先验知识，可以保证以预先指定的概率满足显式状态约束。

    

    近年来，强化学习算法的快速发展在许多领域为我们提供了新的可能性。然而，由于其探索特性，当我们将这些算法应用于安全关键问题，特别是在实际环境中时，我们必须考虑风险。本文提出了一种涉及存在扰动时强化学习中的安全探索问题的方法。我们将学习过程中的安全性定义为以状态明确定义的限制条件的满足，并提出了一种安全探索方法，该方法利用所控制对象和扰动的部分先验知识。即使所控制对象暴露于遵循正态分布的随机扰动，该方法也能保证以预先指定的概率满足显式状态约束。在理论上，我们引入了足够的条件来构建不包含传统探索方法中的探索因素的保守输入。在摆动任务的模拟实验中，我们证明了所提出的方法可以在满足显式约束条件的情况下安全地学习。

    Recent rapid developments in reinforcement learning algorithms have been giving us novel possibilities in many fields. However, due to their exploring property, we have to take the risk into consideration when we apply those algorithms to safety-critical problems especially in real environments. In this study, we deal with a safe exploration problem in reinforcement learning under the existence of disturbance. We define the safety during learning as satisfaction of the constraint conditions explicitly defined in terms of the state and propose a safe exploration method that uses partial prior knowledge of a controlled object and disturbance. The proposed method assures the satisfaction of the explicit state constraints with a pre-specified probability even if the controlled object is exposed to a stochastic disturbance following a normal distribution. As theoretical results, we introduce sufficient conditions to construct conservative inputs not containing an exploring aspect used in th
    
[^76]: 十亿级预训练多模态商业知识图谱的构建与应用

    Construction and Applications of Billion-Scale Pre-Trained Multimodal Business Knowledge Graph. (arXiv:2209.15214v6 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.15214](http://arxiv.org/abs/2209.15214)

    本文介绍了一个基于阿里巴巴集团的空前规模的 OpenBG 商业知识图谱，包含超过 88 百万实体和 26 亿三元组。它具有精细的分类和多模态事实，有助于推动商业智能化的发展。

    

    商业知识图谱是当前许多企业的重要组成部分，为许多产品提供事实知识和结构化数据，使它们变得更加智能化。尽管它们有着许多潜在的好处，但构建商业知识图谱需要解决结构不足和多模态的限制等问题。本文深入探讨了在非微不足道的实际应用系统中构建知识图谱所面临的挑战。我们介绍了一个基于阿里巴巴集团的 OpenBG 商业知识图谱的构建过程。具体来说，我们定义了一个核心本体，涵盖各种抽象产品和消费需求，并在部署的应用中提供精细的分类和多模态事实。OpenBG 是一个空前规模的商业知识图谱：包含超过 88 百万实体、覆盖超过 1 百万个核心类/概念和 2,681 种关系的 26 亿三元组。我们公开了所有的资源和基准数据集，以促进知识图谱的发展和研究。

    Business Knowledge Graphs (KGs) are important to many enterprises today, providing factual knowledge and structured data that steer many products and make them more intelligent. Despite their promising benefits, building business KG necessitates solving prohibitive issues of deficient structure and multiple modalities. In this paper, we advance the understanding of the practical challenges related to building KG in non-trivial real-world systems. We introduce the process of building an open business knowledge graph (OpenBG) derived from a well-known enterprise, Alibaba Group. Specifically, we define a core ontology to cover various abstract products and consumption demands, with fine-grained taxonomy and multimodal facts in deployed applications. OpenBG is an open business KG of unprecedented scale: 2.6 billion triples with more than 88 million entities covering over 1 million core classes/concepts and 2,681 types of relations. We release all the open resources (OpenBG benchmarks) deri
    
[^77]: 一种图上的多臂赌博机学习方法

    Multi-armed Bandit Learning on a Graph. (arXiv:2209.09419v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.09419](http://arxiv.org/abs/2209.09419)

    本文提出了一种基于乐观原则和离线图形规划算法的学习算法G-UCB，能够平衡长期探索利用，用于解决一种名为图赌博机的MAB扩展，从而获得最大化的收益。

    

    多臂赌博机问题是一个简单而强大的框架，在不确定性决策方面已经得到广泛研究。在许多现实世界的应用中，例如机器人应用中，选择一个臂对应于限制下一个可用臂（动作）的选择。出于这个目的，我们研究了一种名为图赌博机的MAB扩展，在此过程中，智能体从不同节点中收集奖励以获得最大化的收益。图定义了智能体在每一步中选择下一个可用节点的自由度。我们假设图的结构是完全可用的，但奖励分布是未知的。基于离线图形规划算法和乐观原则，我们设计了一种学习算法G-UCB，平衡长期探索利用使用乐观原则。我们证明了我们提出的算法达到了$O(\sqrt{|S|T\log(T)}+D|S|\log T)$的学习遗憾。其中$|S|$是

    The multi-armed bandit(MAB) problem is a simple yet powerful framework that has been extensively studied in the context of decision-making under uncertainty. In many real-world applications, such as robotic applications, selecting an arm corresponds to a physical action that constrains the choices of the next available arms (actions). Motivated by this, we study an extension of MAB called the graph bandit, where an agent travels over a graph to maximize the reward collected from different nodes. The graph defines the agent's freedom in selecting the next available nodes at each step. We assume the graph structure is fully available, but the reward distributions are unknown. Built upon an offline graph-based planning algorithm and the principle of optimism, we design a learning algorithm, G-UCB, that balances long-term exploration-exploitation using the principle of optimism. We show that our proposed algorithm achieves $O(\sqrt{|S|T\log(T)}+D|S|\log T)$ learning regret, where $|S|$ is 
    
[^78]: 逆强化学习的主动探索方法

    Active Exploration for Inverse Reinforcement Learning. (arXiv:2207.08645v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.08645](http://arxiv.org/abs/2207.08645)

    AceIRL提出了一种新的逆强化学习算法，通过主动探索来学习奖励函数和策略，在不需要环境生成模型的情况下，能够确定可行奖励函数的置信区间，并找到侧重于环境中最有信息的区域的探索策略。

    

    逆强化学习（IRL）是从专家演示中推断奖励函数的强大范式。许多IRL算法需要已知的转移模型，有时甚至需要已知的专家策略，或者至少需要访问生成模型。但是，这些假设对于许多实际应用来说太强了，因为只能通过顺序交互来访问环境。我们提出了一种新的IRL算法：主动探索逆强化学习（AceIRL），它主动探索未知环境和专家策略，快速学习专家的奖励函数并识别出一个好的策略。AceIRL使用先前的观察结果构建置信区间来捕捉可行的奖励函数，并找到侧重于环境中最有信息的区域的探索策略。AceIRL是第一种具有样本复杂度界限且不需要环境生成模型的主动IRL方法。

    Inverse Reinforcement Learning (IRL) is a powerful paradigm for inferring a reward function from expert demonstrations. Many IRL algorithms require a known transition model and sometimes even a known expert policy, or they at least require access to a generative model. However, these assumptions are too strong for many real-world applications, where the environment can be accessed only through sequential interaction. We propose a novel IRL algorithm: Active exploration for Inverse Reinforcement Learning (AceIRL), which actively explores an unknown environment and expert policy to quickly learn the expert's reward function and identify a good policy. AceIRL uses previous observations to construct confidence intervals that capture plausible reward functions and find exploration policies that focus on the most informative regions of the environment. AceIRL is the first approach to active IRL with sample-complexity bounds that does not require a generative model of the environment. AceIRL 
    
[^79]: 多轨音乐 Transformer

    Multitrack Music Transformer. (arXiv:2207.06983v3 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2207.06983](http://arxiv.org/abs/2207.06983)

    这篇论文提出了一种新的多轨音乐表示方法，可以支持各种不同的乐器，在短的序列长度下实现了性能上的显著提升，同时提出了一种新方法用于分析音乐自我关注，并验证了模型更关注与当前音符形成和谐跨度和位于同一八度的音符。

    

    目前使用 Transformer 模型生成多轨音乐的方法在乐器数量、音乐片段长度和推理速度方面有限制，部分原因在于已有表示方式需要长度较长的输入序列，从而需要更多的内存。在本文中，我们提出了一种新的多轨音乐表示方法，可以支持各种不同的乐器，同时使输入序列长度更短。我们提出的 Multitrack Music Transformer（MMT）与最先进的系统相比具有可比性，在主观听测试中排在两个最近提出的模型之间，同时在速度和内存占用上都实现了显著的提升，使得该方法在实时即兴创作或接近实时的创意应用中更为实用。此外，我们提出了一种分析音乐自我关注的新方法，并展示了训练模型更关注与当前音符形成和谐跨度和位于同一八度的音符。

    Existing approaches for generating multitrack music with transformer models have been limited in terms of the number of instruments, the length of the music segments and slow inference. This is partly due to the memory requirements of the lengthy input sequences necessitated by existing representations. In this work, we propose a new multitrack music representation that allows a diverse set of instruments while keeping a short sequence length. Our proposed Multitrack Music Transformer (MMT) achieves comparable performance with state-of-the-art systems, landing in between two recently proposed models in a subjective listening test, while achieving substantial speedups and memory reductions over both, making the method attractive for real time improvisation or near real time creative applications. Further, we propose a new measure for analyzing musical self-attention and show that the trained model attends more to notes that form a consonant interval with the current note and to notes th
    
[^80]: Ask-AC: 一种循环中的主动顾问演员-评论家框架

    Ask-AC: An Initiative Advisor-in-the-Loop Actor-Critic Framework. (arXiv:2207.01955v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.01955](http://arxiv.org/abs/2207.01955)

    本文提出了一种新颖的主动顾问演员-评论家框架，Ask-AC，它替换了传统的被动监督信号机制，实现了定制化和高效的信息交换，其中的两个互补组件允许代理主动寻求顾问干预和识别漏掉的不稳定状态。

    

    尽管交互式强化学习方案取得了很多有希望的结果，但目前的方案仍然依赖于来自顾问专家的被动监督信号，形式包括持续监控或预定义规则，这不可避免地导致了一种麻烦而昂贵的学习过程。在本文中，我们介绍了一种新的主动顾问演员-评论家框架，称为Ask-AC，它用一个双向的学习者主动机制替换了单向的顾问指导机制，从而实现了学习者和顾问之间的定制化和有效的信息交换。Ask-AC 的核心是两个互补的组件，分别是动作请求者和自适应状态选择器，可以方便地纳入各种离散的演员-评论家架构中。前者允许代理主动寻求不确定状态下的顾问干预，后者则可以识别漏掉的不稳定状态。

    Despite the promising results achieved, state-of-the-art interactive reinforcement learning schemes rely on passively receiving supervision signals from advisor experts, in the form of either continuous monitoring or pre-defined rules, which inevitably result in a cumbersome and expensive learning process. In this paper, we introduce a novel initiative advisor-in-the-loop actor-critic framework, termed as Ask-AC, that replaces the unilateral advisor-guidance mechanism with a bidirectional learner-initiative one, and thereby enables a customized and efficacious message exchange between learner and advisor. At the heart of Ask-AC are two complementary components, namely action requester and adaptive state selector, that can be readily incorporated into various discrete actor-critic architectures. The former component allows the agent to initiatively seek advisor intervention in the presence of uncertain states, while the latter identifies the unstable states potentially missed by the for
    
[^81]: 基于可解释的深度强化学习的无人机引导和规划的鲁棒性对抗攻击检测

    Robust Adversarial Attacks Detection based on Explainable Deep Reinforcement Learning For UAV Guidance and Planning. (arXiv:2206.02670v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.02670](http://arxiv.org/abs/2206.02670)

    本文提出了一种基于可解释的深度学习方法的创新性检测方案，以保护采用这些方法的无人机免受对抗攻击。

    

    针对无人机在公共领域遭受对抗攻击的风险增加的问题，本文提出了一种基于可解释的深度学习方法的创新性检测方案，以保护采用这些方法的无人机免受攻击。该方案采用深度强化学习进行引导和规划，利用人工势场来提高训练效率和障碍物避免率。

    The dangers of adversarial attacks on Uncrewed Aerial Vehicle (UAV) agents operating in public are increasing. Adopting AI-based techniques and, more specifically, Deep Learning (DL) approaches to control and guide these UAVs can be beneficial in terms of performance but can add concerns regarding the safety of those techniques and their vulnerability against adversarial attacks. Confusion in the agent's decision-making process caused by these attacks can seriously affect the safety of the UAV. This paper proposes an innovative approach based on the explainability of DL methods to build an efficient detector that will protect these DL schemes and the UAVs adopting them from attacks. The agent adopts a Deep Reinforcement Learning (DRL) scheme for guidance and planning. The agent is trained with a Deep Deterministic Policy Gradient (DDPG) with Prioritised Experience Replay (PER) DRL scheme that utilises Artificial Potential Field (APF) to improve training times and obstacle avoidance per
    
[^82]: 利用自监督学习研究大脑中的语音处理机制

    Toward a realistic model of speech processing in the brain with self-supervised learning. (arXiv:2206.01685v2 [q-bio.NC] UPDATED)

    [http://arxiv.org/abs/2206.01685](http://arxiv.org/abs/2206.01685)

    本研究针对语音处理问题，使用自监督学习的方法得到的特征与大脑神经元对于语音刺激的反应能够形成类似的层级，且解释了大脑活动的变化。该算法能够最少依赖先验语言和理解知识资源，并且需要的数据量远小于其它模型。

    

    最近研究发现一些深度神经网络对于输入的刺激反应能够与人脑神经元的活动十分相似。但这些算法存在数据量巨大、监督标签难以获取、只能接受文本输入以及需要高昂的存储资源等问题。这些限制表明需要寻找在这些限制下能够解释行为和大脑反应的算法。本研究专注于语音处理问题，假设基于原始波形的自监督算法成为一个有前景的候选方案。作者通过比较最近的自监督架构Wav2Vec 2.0和412名英语、法语和汉语听取约1小时音频书籍时的功能磁共振成像（fMRI）数据，展示了四个主要成果：首先，作者发现Wav2Vec 2.0和大脑神经元会将语音音频信息编码到类似时间变化的层级中。其次，作者证明这种对于音频层级的编码不是由于影响常规声音的表面因素导致。第三，作者还表明，与文本表示法或传统语音特征相比，通过无监督学习获得的特征可以更加准确地解释大脑活动的变化。最后，研究还展示了在最少的语言背景和理解知识资源下，可以通过自监督学习解释有意义的大脑活动。

    Several deep neural networks have recently been shown to generate activations similar to those of the brain in response to the same input. These algorithms, however, remain largely implausible: they require (1) extraordinarily large amounts of data, (2) unobtainable supervised labels, (3) textual rather than raw sensory input, and / or (4) implausibly large memory (e.g. thousands of contextual words). These elements highlight the need to identify algorithms that, under these limitations, would suffice to account for both behavioral and brain responses. Focusing on the issue of speech processing, we here hypothesize that self-supervised algorithms trained on the raw waveform constitute a promising candidate. Specifically, we compare a recent self-supervised architecture, Wav2Vec 2.0, to the brain activity of 412 English, French, and Mandarin individuals recorded with functional Magnetic Resonance Imaging (fMRI), while they listened to ~1h of audio books. Our results are four-fold. First
    
[^83]: 具有最优统计率和隐私保证的拜占庭鲁棒联邦学习

    Byzantine-Robust Federated Learning with Optimal Statistical Rates and Privacy Guarantees. (arXiv:2205.11765v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.11765](http://arxiv.org/abs/2205.11765)

    本文提出了一种具有近乎最优统计率的拜占庭鲁棒联邦学习协议，并展示了其与竞争协议相比的经验优越性，协议通过分桶可以结合隐私保障程序以对半诚实服务器进行安全保障。

    

    我们提出了一种具有近乎最优统计率的拜占庭鲁棒联邦学习协议。与之前的工作相比，我们提出的协议提高了维度依赖性，并在强凸损失的所有参数方面实现了紧密的统计率。我们对竞争协议进行了基准测试，并展示了所提出协议的经验优越性。最后，我们指出，我们的分桶协议可以与隐私保障程序自然地结合起来，以引入对半诚实服务器的安全保障。评估代码位于https://github.com/wanglun1996/secure-robust-federated-learning中。

    We propose Byzantine-robust federated learning protocols with nearly optimal statistical rates. In contrast to prior work, our proposed protocols improve the dimension dependence and achieve a tight statistical rate in terms of all the parameters for strongly convex losses. We benchmark against competing protocols and show the empirical superiority of the proposed protocols. Finally, we remark that our protocols with bucketing can be naturally combined with privacy-guaranteeing procedures to introduce security against a semi-honest server. The code for evaluation is provided in https://github.com/wanglun1996/secure-robust-federated-learning.
    
[^84]: 深入探讨自监督单目深度估计的泛化能力

    Deep Digging into the Generalization of Self-Supervised Monocular Depth Estimation. (arXiv:2205.11083v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2205.11083](http://arxiv.org/abs/2205.11083)

    本文探究了用于单目深度估计的骨干网络的泛化能力，并观察到Transformers具有很强的形状偏差。形状偏差的模型表现更好的单目深度估计泛化性能，作者新设计了一个CNN-Transformer混合网络，以提高单目深度估计的泛化性能。

    

    自监督单目深度估计是近期广泛研究的领域。大部分工作都将重点放在提高KITTI等基准数据集性能上，但是对于泛化性能进行的实验却很少。本文探究了用于单目深度估计的骨干网络（如CNN、Transformers和CNN-Transformer混合模型）的泛化性能。我们首先在多元化的公共数据集上评估了最先进的模型，这些数据集在网络训练期间从未见过。接下来，我们使用不同的纹理位移数据集生成了纹理偏差和形状偏差表示，并研究了其效果。我们观察到Transformers具有很强的形状偏差，而CNN则有很强的纹理偏差。我们还发现，与纹理偏差的模型相比，形状偏差的模型在单目深度估计的泛化性能方面表现更好。基于这些观察结果，我们新设计了一个CNN-Transformer混合网络，其中包含多个形状偏差分支，用于单目深度估计。

    Self-supervised monocular depth estimation has been widely studied recently. Most of the work has focused on improving performance on benchmark datasets, such as KITTI, but has offered a few experiments on generalization performance. In this paper, we investigate the backbone networks (e.g. CNNs, Transformers, and CNN-Transformer hybrid models) toward the generalization of monocular depth estimation. We first evaluate state-of-the-art models on diverse public datasets, which have never been seen during the network training. Next, we investigate the effects of texture-biased and shape-biased representations using the various texture-shifted datasets that we generated. We observe that Transformers exhibit a strong shape bias and CNNs do a strong texture-bias. We also find that shape-biased models show better generalization performance for monocular depth estimation compared to texture-biased models. Based on these observations, we newly design a CNN-Transformer hybrid network with a mult
    
[^85]: Sionna：下一代物理层研究的开源库

    Sionna: An Open-Source Library for Next-Generation Physical Layer Research. (arXiv:2203.11854v2 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2203.11854](http://arxiv.org/abs/2203.11854)

    Sionna是一个GPU加速的基于TensorFlow的开源库，实现了最先进算法，可以用于基准测试和端到端性能评估。它能够提供对神经网络的原生支持，使得研究人员能够更加专注于自己的研究。

    

    Sionna是一种基于TensorFlow的GPU加速开源库，用于链路层模拟。它实现了广泛而精心测试的最先进算法，可用于基准测试和端到端性能评估，并提供原生支持神经网络的集成。这使研究人员能够专注于他们的研究，使其更具影响力和可重复性，同时节省了实现他们所不熟悉的组件的时间。本文简要介绍了Sionna，解释了它的设计原则和功能，以及未来的扩展，如集成光线跟踪和自定义CUDA内核。我们认为Sionna是研究下一代通信系统（如6G）的有价值的工具，欢迎来自我们社区的贡献。

    Sionna is a GPU-accelerated open-source library for link-level simulations based on TensorFlow. It enables the rapid prototyping of complex communication system architectures and provides native support for the integration of neural networks. Sionna implements a wide breadth of carefully tested state-of-the-art algorithms that can be used for benchmarking and end-to-end performance evaluation. This allows researchers to focus on their research, making it more impactful and reproducible, while saving time implementing components outside their area of expertise. This white paper provides a brief introduction to Sionna, explains its design principles and features, as well as future extensions, such as integrated ray tracing and custom CUDA kernels. We believe that Sionna is a valuable tool for research on next-generation communication systems, such as 6G, and we welcome contributions from our community.
    
[^86]: 探究变分图自编码器用于提取分类重构建议

    Exploring Variational Graph Auto-Encoders for Extract Class Refactoring Recommendation. (arXiv:2203.08787v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2203.08787](http://arxiv.org/abs/2203.08787)

    本文提出了一种利用变分图自编码器自动将上帝类提取为更具体职责的较小类别的方法，在五个开源项目上评估后结果表明有效。

    

    代码异味是软件系统中设计和开发缺陷的标志，会降低系统的可重用性和可维护性。重构是一种持续进行的实践，用于从程序代码中去除代码异味。在不同的代码异味中，上帝类或Blob是最常见的代码异味之一。上帝类包含许多职责，违反了面向对象程序设计的低耦合和高内聚原则。本文提出了一种自动提取上帝类为多个较小类的方法，以更具体的职责。为此，我们首先构造了一个有关上帝类的方法图（作为节点）。任何两种方法之间的边缘由它们的结构相似性决定，并使用不同的语义表示方法初始化每种方法的特征。然后，使用变分图自编码器为每个方法学习向量表示。最后，利用学到的向量将方法聚类到较小的类别中。该方法在五个开源项目上进行了评估，结果表明该方法在将上帝类提取为更具体职责的较小类别方面有效。

    The code smell is a sign of design and development flaws in a software system that reduces the reusability and maintainability of the system. Refactoring is done as an ongoing practice to remove the code smell from the program code. Among different code smells, the God class or Blob is one of the most common code smells. A god class contains too many responsibilities, violating object-oriented programming design's low coupling and high cohesiveness principles. This paper proposes an automatic approach to extracting a God class into multiple smaller classes with more specific responsibilities. To do this, we first construct a graph of methods (as nodes) for the concerning god class. The edge between any two methods is determined by their structural similarity, and the feature for each method is initialized using different semantic representation methods. Then, the variational graph auto-encoder is used to learn a vector representation for each method. Finally, the learned vectors are us
    
[^87]: 超级动物模型的预训练，用于动物行为的即插即用分析

    SuperAnimal models pretrained for plug-and-play analysis of animal behavior. (arXiv:2203.07436v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2203.07436](http://arxiv.org/abs/2203.07436)

    SuperAnimal是一种能够开发和部署深度学习模型的方法，不需要额外的人工标注和模型训练，同时可用于超过45个物种进行视频推断，并具有微调模型效率高的优点。

    

    行为量化在神经科学、兽医和动物保护等应用中至关重要。行为分析的关键步骤是首先提取与动物相关的关键点，即姿势估计。然而，可靠的姿势推断目前需要领域知识和手动标注来构建监督模型。我们提出了一系列技术创新，使一种名为SuperAnimal的新方法能够开发和部署深度学习模型，这些模型不需要额外的人工标注和模型训练。SuperAnimal允许对45多个物种进行视频推断，同时只使用两种全局动物姿势模型。如果需要微调模型，我们展示了SuperAnimal模型具有10倍的数据效率，并且胜过先前的迁移学习方法。此外，我们提供了一种新的视频自适应方法来执行无监督的视频细化，并且我们展示了我们的模型在行为分类中的实用性。

    Quantification of behavior is critical in applications ranging from neuroscience, veterinary medicine and animal conservation efforts. A common key step for behavioral analysis is first extracting relevant keypoints on animals, known as pose estimation. However, reliable inference of poses currently requires domain knowledge and manual labeling effort to build supervised models. We present a series of technical innovations that enable a new method, collectively called SuperAnimal, to develop and deploy deep learning models that require zero additional human labels and model training. SuperAnimal allows video inference on over 45 species with only two global classes of animal pose models. If the models need fine-tuning, we show SuperAnimal models are 10$\times$ more data efficient and outperform prior transfer learning approaches. Moreover, we provide a new video-adaptation method to perform unsupervised refinement of videos, and we illustrate the utility of our model in behavioral clas
    
[^88]: 衍生品定价模型的校准：多智能体强化学习观点

    Calibration of Derivative Pricing Models: a Multi-Agent Reinforcement Learning Perspective. (arXiv:2203.06865v3 [q-fin.CP] UPDATED)

    [http://arxiv.org/abs/2203.06865](http://arxiv.org/abs/2203.06865)

    本文利用多智能体强化学习提出校准衍生品定价模型问题的博弈论解决方案，并希望该方法可用于解决其他金融领域的问题。实验证明，该算法能够学习局部波动率以及最小化百慕大期权价格所需的路径依赖性。

    

    在量化金融中最基本的问题之一是存在适合给定一组期权市场价格的连续时间扩散模型。传统上，人们使用直觉、理论和经验分析的混合方法来寻找实现精确或近似匹配的模型。我们的贡献在于展示如何通过适当的博弈理论形式化问题，借助现代深度多智能体强化学习的现有进展来搜索随机过程空间，以解决这个问题。更重要的是，我们希望我们的技术可以被社区利用和扩展，以解决该领域的重要问题，如联合SPX-VIX校准问题。我们的实验表明，我们能够学习局部波动率以及在波动率过程中所需的路径依赖性，以最小化百慕大期权的价格。我们的算法可以看作是一种粒子方法，类似于Guyon et Henry-Labordere的方法。

    One of the most fundamental questions in quantitative finance is the existence of continuous-time diffusion models that fit market prices of a given set of options. Traditionally, one employs a mix of intuition, theoretical and empirical analysis to find models that achieve exact or approximate fits. Our contribution is to show how a suitable game theoretical formulation of this problem can help solve this question by leveraging existing developments in modern deep multi-agent reinforcement learning to search in the space of stochastic processes. More importantly, we hope that our techniques can be leveraged and extended by the community to solve important problems in that field, such as the joint SPX-VIX calibration problem. Our experiments show that we are able to learn local volatility, as well as path-dependence required in the volatility process to minimize the price of a Bermudan option. Our algorithm can be seen as a particle method \`{a} la Guyon et Henry-Labordere where partic
    
[^89]: 用于本体子类预测的上下文语义嵌入

    Contextual Semantic Embeddings for Ontology Subsumption Prediction. (arXiv:2202.09791v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2202.09791](http://arxiv.org/abs/2202.09791)

    本文提出了一种名为BERTSubs的新型子类预测方法，用于OWL本体类，它可以预测包括来自同一本体或另一个本体的命名类以及来自同一本体的存在限制等多种子类。

    

    自动化本体构建和维护是知识工程和人工智能中重要但具有挑战性的任务。机器学习技术（如上下文语义嵌入）进行预测是一个有前途的方向，但是相关研究尤其是针对Web本体语言（OWL）中的表达型本体仍处在初步阶段。本文提出了一种名为BERTSubs的新型子类预测方法，用于OWL本体类。它利用预训练的语言模型BERT计算类的上下文嵌入，其中提出了自定义模板来结合类的上下文（例如邻近类）和逻辑存在限制。BERTSubs可以预测多种子类，包括来自同一本体或另一个本体的命名类以及来自同一本体的存在限制。在三种不同的子类任务上对五个真实世界本体进行了广泛评估，表明了BERTSubs的有效性。

    Automating ontology construction and curation is an important but challenging task in knowledge engineering and artificial intelligence. Prediction by machine learning techniques such as contextual semantic embedding is a promising direction, but the relevant research is still preliminary especially for expressive ontologies in Web Ontology Language (OWL). In this paper, we present a new subsumption prediction method named BERTSubs for classes of OWL ontology. It exploits the pre-trained language model BERT to compute contextual embeddings of a class, where customized templates are proposed to incorporate the class context (e.g., neighbouring classes) and the logical existential restriction. BERTSubs is able to predict multiple kinds of subsumers including named classes from the same ontology or another ontology, and existential restrictions from the same ontology. Extensive evaluation on five real-world ontologies for three different subsumption tasks has shown the effectiveness of th
    
[^90]: 带有FO(.)和IDP-Z3的交互式配置器

    Interactive configurator with FO(.) and IDP-Z3. (arXiv:2202.00343v3 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2202.00343](http://arxiv.org/abs/2202.00343)

    本文介绍了一种新的推理引擎IDP-Z3，它适用于FO(.)知识表示语言，并应用于自动构建基于知识的交互式配置器。

    

    交互式配置问题在工业中普遍存在，即计算机辅助下由人们交互地解决的约束求解问题。所谓的配置程序需要根据用户提供的（通常是不完整的）信息执行各种推理任务。采用命令式编程方法使得实现和维护此类系统变得十分困难。已经提出了基于知识的配置程序来帮助工程师解决此类问题，但仍面临着许多挑战。我们提出了IDP-Z3，这是一种适用于FO(.)知识表示语言的新的推理引擎，并报告了它在从知识库中自动构建配置程序方面的应用。

    Industry abounds with interactive configuration problems, i.e., constraint solving problems interactively solved by persons with the assistance of a computer. The computer program, called a configurator, needs to perform a variety of reasoning tasks with the (often incomplete) information that the user provides. Imperative programming approaches make such systems difficult to implement and maintain. Knowledge-based configurators have been proposed to help engineers solve such problems, but many challenges remain.  We present IDP-Z3, a new reasoning engine for the FO(.) KR language, and we report on its use for building configurators automatically from a knowledge base.
    
[^91]: 基于自监督学习的视频一致三维手部重建方法

    Consistent 3D Hand Reconstruction in Video via self-supervised Learning. (arXiv:2201.09548v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2201.09548](http://arxiv.org/abs/2201.09548)

    本文提出了一种无需手部标注，在单目视频中基于自监督学习实现的一致三维手部重建方法。

    

    本论文提出了一种从单目视频中重建准确且一致的三维手部模型的方法。文章发现检测到的二维手部关键点和图像纹理可以提供关于三维手部几何形状和纹理的重要线索，从而可以减少或甚至消除对三维手部标注的要求。作者提出了一种自监督的三维手部重建模型${\rm {S}^{2}HAND}$，通过易于获取的二维检测关键点进行监督，在单个RGB输入中共同估计手部姿势、形状、纹理和相机视角。

    We present a method for reconstructing accurate and consistent 3D hands from a monocular video. We observe that detected 2D hand keypoints and the image texture provide important cues about the geometry and texture of the 3D hand, which can reduce or even eliminate the requirement on 3D hand annotation. Thus we propose ${\rm {S}^{2}HAND}$, a self-supervised 3D hand reconstruction model, that can jointly estimate pose, shape, texture, and the camera viewpoint from a single RGB input through the supervision of easily accessible 2D detected keypoints. We leverage the continuous hand motion information contained in the unlabeled video data and propose ${\rm {S}^{2}HAND(V)}$, which uses a set of weights shared ${\rm {S}^{2}HAND}$ to process each frame and exploits additional motion, texture, and shape consistency constrains to promote more accurate hand poses and more consistent shapes and textures. Experiments on benchmark datasets demonstrate that our self-supervised approach produces com
    
[^92]: 用机器学习增强宇宙天体物理学的比例关系: 应用于减少 Sunyaev-Zeldovich 荧光质量散射

    Augmenting astrophysical scaling relations with machine learning: application to reducing the Sunyaev-Zeldovich flux-mass scatter. (arXiv:2201.01305v3 [astro-ph.CO] UPDATED)

    [http://arxiv.org/abs/2201.01305](http://arxiv.org/abs/2201.01305)

    本文使用符号回归的机器学习工具，在Sunyaev-Zeldovich 荧光$-$星团质量关系中找到了一个新的代理变量，结合了$Y_\mathrm{SZ}$和电离气体浓度($c_\mathrm{gas}$)，极大地减小了该关系中的散射，提高了宇宙学分析的灵敏度。

    

    复杂的天体系统通常展示出可观测特性（如亮度、速度分散、振荡周期）之间的低离散比例关系，这些比例关系揭示了其中的物理现象，并为质量和距离估算等提供了观测工具。机器学习可以在高维度参数空间中提供快速系统的搜索新比例关系的方法。本文使用了一种名为“符号回归”的机器学习工具，将数据中的模式建模成解析方程。本文聚焦于 Sunyaev-Zeldovich 荧光$-$星团质量关系($Y_\mathrm{SZ}-M$)，这个关系中的散射影响从星团丰度数据中推断出的宇宙学参数。通过在Illustris TNG水力模拟数据上使用符号回归，我们找到了一个新的星团质量代理变量，结合了$Y_\mathrm{SZ}$和电离气体浓度($c_\mathrm{gas}$)：$M \propto Y_\mathrm{SZ}(c_\mathrm{gas}/C)^{1.7}$，其中$C$是一个常数。这个关系显著减小了$Y_\mathrm{SZ}-M$中的散射，提高了基于星系团的当前和未来的宇宙学分析的灵敏度。

    Complex astrophysical systems often exhibit low-scatter relations between observable properties (e.g., luminosity, velocity dispersion, oscillation period). These scaling relations illuminate the underlying physics, and can provide observational tools for estimating masses and distances. Machine learning can provide a fast and systematic way to search for new scaling relations (or for simple extensions to existing relations) in abstract high-dimensional parameter spaces. We use a machine learning tool called symbolic regression (SR), which models patterns in a dataset in the form of analytic equations. We focus on the Sunyaev-Zeldovich flux$-$cluster mass relation ($Y_\mathrm{SZ}-M$), the scatter in which affects inference of cosmological parameters from cluster abundance data. Using SR on the data from the IllustrisTNG hydrodynamical simulation, we find a new proxy for cluster mass which combines $Y_\mathrm{SZ}$ and concentration of ionized gas ($c_\mathrm{gas}$): $M \propto Y_\mathrm
    
[^93]: 基于记忆损失预测模型的事件抽取主动学习方法

    Active Learning for Event Extraction with Memory-based Loss Prediction Model. (arXiv:2112.03073v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2112.03073](http://arxiv.org/abs/2112.03073)

    本论文提出了一种基于深度学习的主动学习方法，采用基于批次的样本选择策略和记忆损失预测模型以降低事件注释成本，实验结果表明此方法优于现有主动学习方法且性能最优。

    

    事件抽取在许多工业应用场景中扮演着重要角色，高质量的事件抽取方法需要大量手动注释数据以训练监督学习模型。然而，获取注释数据的成本非常高，特别是对于领域事件注释，需要相应领域的专家参与。因此，我们引入主动学习技术来降低事件注释的成本。但是现有的主动学习方法存在两个主要问题，使它们无法很好地用于事件抽取。首先，现有的基于样本池选择的策略在计算成本和样本有效性方面存在局限性。其次，现有的样本重要性评估缺乏对本地样本信息的利用。在本文中，我们提出了一种新颖的基于深度学习的主动学习方法。我们提出了基于批次的选择策略和一个记忆损失预测模型（MBLP），以有效地选择未标记的样本。在选择过程中，MBLP被用来预测标记数据的可能损失，并指导选择具有最高信息增益的样本。在两个基准数据集上的实验表明，我们提出的方法优于现有的主动学习方法，并以显著降低注释成本的方式实现了最先进的性能。

    Event extraction (EE) plays an important role in many industrial application scenarios, and high-quality EE methods require a large amount of manual annotation data to train supervised learning models. However, the cost of obtaining annotation data is very high, especially for annotation of domain events, which requires the participation of experts from corresponding domain. So we introduce active learning (AL) technology to reduce the cost of event annotation. But the existing AL methods have two main problems, which make them not well used for event extraction. Firstly, the existing pool-based selection strategies have limitations in terms of computational cost and sample validity. Secondly, the existing evaluation of sample importance lacks the use of local sample information. In this paper, we present a novel deep AL method for EE. We propose a batch-based selection strategy and a Memory-Based Loss Prediction model (MBLP) to select unlabeled samples efficiently. During the selectio
    
[^94]: \L ukasiewicz逻辑的信念扩展

    Doxastic Extensions of \L ukasiewicz Logic. (arXiv:2111.08564v3 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2111.08564](http://arxiv.org/abs/2111.08564)

    本文提出了两类关于\L ukasiewicz逻辑的信念扩展，基于不同的信念概念进行建模，并证明了这些扩展的声音性和完整性定理。

    

    我们提出了两类关于信念的扩展，它们是模糊\L ukasiewicz逻辑关于基于Kripke的模型的一些适当类别的声音且完整的。这些扩展的一类带有类似于经典信念的伪古典信念属性，另一类基于一种我们称之为\textit{skeptical}（怀疑的）信念的新概念。我们使用伪古典信念对模糊版本的“泥泞儿童问题”进行建模，使用怀疑的信念对CPA安全性实验进行建模，然后通过展示伪古典信念不适用于模拟CPA实验中对手的信念，从而证明提出怀疑的信念概念的合理性。此外，我们还证明了一些提出的信念扩展的完整性和声音性定理。

    We propose two classes of doxastic extensions of fuzzy \L ukasiewicz logic that are sound and complete with respect to some appropriate classes of Kripke-based models in which both atomic propositions and accessibility relations are fuzzy. One class of these extensions is equipped with pseudo-classical belief that has properties similar to the classical belief, and the other class is based on a new notion of belief that we call it \textit{skeptical} belief. We model a fuzzy version of the muddy children problem using pseudo-classical belief and a CPA-security experiment using skeptical belief, then by showing that the pseudo-classical belief is not appropriate for modeling the belief of an adversary in a CPA-experiment we justify proposing the notion of skeptical belief. Furthermore, we prove the soundness and completeness theorems for some of the proposed doxastic extensions.
    
[^95]: 追寻可教学自主智能体

    Towards Teachable Autotelic Agents. (arXiv:2105.11977v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2105.11977](http://arxiv.org/abs/2105.11977)

    本文提出了可教学自主智能体的概念，它们可以从内部和教学信号中同步学习，从而提高技能习得的效率，此举是构建具有人类级智能的代理的关键步骤。

    

    自主探索和直接指导是儿童学习的两个不同来源，但教育科学证明，辅助发现或引导游戏等混合方法可以提高技能习得。在人工智能领域，这些极端分别映射为自主代理从自己的信号中学习，以及完全被教师教授的交互式学习代理。在两者之间应该站立可教学的自主智能体（TAA）：它们从内部和教学信号中学习，以从辅助发现的更高效率中受益。设计这样的代理将使真实世界的非专业用户将代理的学习轨迹定向于他们的期望。更基本地，这也可能是构建具有人类级智能的代理的关键步骤。本文提出了通向可教学自主代理设计的路线图。基于发展心理学和教育科学，我们首先确定了关键特征。

    Autonomous discovery and direct instruction are two distinct sources of learning in children but education sciences demonstrate that mixed approaches such as assisted discovery or guided play result in improved skill acquisition. In the field of Artificial Intelligence, these extremes respectively map to autonomous agents learning from their own signals and interactive learning agents fully taught by their teachers. In between should stand teachable autotelic agents (TAA): agents that learn from both internal and teaching signals to benefit from the higher efficiency of assisted discovery. Designing such agents will enable real-world non-expert users to orient the learning trajectories of agents towards their expectations. More fundamentally, this may also be a key step to build agents with human-level intelligence. This paper presents a roadmap towards the design of teachable autonomous agents. Building on developmental psychology and education sciences, we start by identifying key fe
    

