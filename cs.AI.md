# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Breaking the Metric Voting Distortion Barrier.](http://arxiv.org/abs/2306.17838) | 这篇论文研究了社会选择中的度量扭曲问题，提出了一个新的投票规则，该规则可以选择距离选民平均距离较小的候选人。之前的研究发现确定性投票规则的度量扭曲限制为3，但在无限制的情况下，我们对该问题仍然了解有限。 |
| [^2] | [Resetting the Optimizer in Deep RL: An Empirical Study.](http://arxiv.org/abs/2306.17833) | 在深度强化学习中，当优化问题的风景在不同迭代中差异较大时，重置优化器的内部参数可以避免污染和提高性能。 |
| [^3] | [Understanding Unfairness via Training Concept Influence.](http://arxiv.org/abs/2306.17828) | 通过观察训练数据的作用，研究模型不公平性的来源和影响，并通过改变样本的属性来计算训练样本对模型的不公平性的影响。 |
| [^4] | [Act3D: Infinite Resolution Action Detection Transformer for Robotic Manipulation.](http://arxiv.org/abs/2306.17817) | Act3D是一种基于Transformer的操作策略，将6自由度关键姿势预测作为3D检测任务，并以自适应空间计算的方式进行处理。它在高度精确的机器人操纵任务中取得了显著的性能改进。 |
| [^5] | [Comparing Reinforcement Learning and Human Learning using the Game of Hidden Rules.](http://arxiv.org/abs/2306.17766) | 本文研究了利用隐藏规则游戏比较强化学习和人类学习，在一个特定的学习环境中通过任务结构的实验发现了人类和强化学习算法的性能差异。 |
| [^6] | [Discriminatory or Samaritan -- which AI is needed for humanity? An Evolutionary Game Theory Analysis of Hybrid Human-AI populations.](http://arxiv.org/abs/2306.17747) | 这项研究通过进化博弈理论的分析发现，相比于只帮助符合条件的人的歧视性人工智能，撒马利亚式人工智能可以更好地促进人类间的合作。这对于缓慢发展的社会尤为重要，因为在这种社会中，变化被视为谨慎和抵抗。 |
| [^7] | [Token-Event-Role Structure-based Multi-Channel Document-Level Event Extraction.](http://arxiv.org/abs/2306.17733) | 本文提出了一种基于Token-Event-Role结构的多通道文档级事件抽取框架，通过引入新的数据结构和预测模块，能够更全面地理解事件之间的关系，并通过预测token-event对的方式，实现了实体和多事件抽取的集成，减少了模型复杂性。 |
| [^8] | [Multimodal Prompt Retrieval for Generative Visual Question Answering.](http://arxiv.org/abs/2306.17675) | 本研究提出了一种基于多模态提示检索的生成式视觉问答模型，通过整合检索到的提示和多模态特征，实现了在自由文本中生成答案。该模型具有快速零样本自适应能力，并在医学视觉问答任务中比非检索模型高出30%的准确率。 |
| [^9] | [Point-based Value Iteration for Neuro-Symbolic POMDPs.](http://arxiv.org/abs/2306.17639) | 本文提出了一种基于点的神经符号POMDP值迭代算法，结合了传统符号技术和神经网络，解决了连续状态置信度函数的问题，实现了优化折扣累积回报的连续状态决策问题。 |
| [^10] | [Achieving RGB-D level Segmentation Performance from a Single ToF Camera.](http://arxiv.org/abs/2306.17636) | 本文使用单个ToF相机的红外和深度图像，在语义分割任务上表现出与RGB-D相机相当的准确性，通过引入深度专用卷积的多任务学习方法，展示了在车内分割数据集上的竞争力。 |
| [^11] | [Design of Induction Machines using Reinforcement Learning.](http://arxiv.org/abs/2306.17626) | 该论文介绍了一种使用强化学习算法设计定制的感应电动机的方法，通过模拟多个电机设计实例进行离线训练，使得电机设计自动化并满足特定的操作要求。 |
| [^12] | [Sphere2Vec: A General-Purpose Location Representation Learning over a Spherical Surface for Large-Scale Geospatial Predictions.](http://arxiv.org/abs/2306.17624) | Sphere2Vec是一种多尺度位置编码器，用于在球面上编码点坐标时保持球面距离，解决了大规模真实世界GPS坐标数据集中的距离度量问题。 |
| [^13] | [Mixed Integer Programming for Time-Optimal Multi-Robot Coverage Path Planning with Efficient Heuristics.](http://arxiv.org/abs/2306.17609) | 本文研究了时间优化多机器人覆盖路径规划问题，并通过混合整数规划模型提出了一个最优解决方案，该方案的覆盖时间最多为最优解的四倍。此外，我们还提出了两个有效的启发式算法来减少问题的规模，并通过模型优化方法进一步提高了效率。 |
| [^14] | [S.T.A.R.-Track: Latent Motion Models for End-to-End 3D Object Tracking with Adaptive Spatio-Temporal Appearance Representations.](http://arxiv.org/abs/2306.17602) | 本文提出了S.T.A.R.-Track，一个采用物体为中心的Transformer框架，用于端到端3D物体跟踪。通过新颖的潜在运动模型和学习型跟踪嵌入，该框架能够准确建模物体的几何运动和变化，并在nuScenes数据集上取得了优秀的性能。 |
| [^15] | [Navigation of micro-robot swarms for targeted delivery using reinforcement learning.](http://arxiv.org/abs/2306.17598) | 通过强化学习算法控制微型机器人群体，实现了针对性的药物输送，具有很大的应用潜力。 |
| [^16] | [Razor SNN: Efficient Spiking Neural Network with Temporal Embeddings.](http://arxiv.org/abs/2306.17597) | Razor SNN是一种基于时间嵌入的高效脉冲神经网络框架，能够从稀疏的事件流中提取时空特征，并实现了竞争性的性能表现。 |
| [^17] | [ChatGPT for Robotics: Design Principles and Model Abilities.](http://arxiv.org/abs/2306.17582) | 本文介绍了使用ChatGPT进行机器人应用的实验研究，通过设计原则和函数库的结合，ChatGPT能够适应不同的机器人任务，并展示了在各种机器人任务中的有效性和多样性。 |
| [^18] | [Augmenting Holistic Review in University Admission using Natural Language Processing for Essays and Recommendation Letters.](http://arxiv.org/abs/2306.17575) | 这项研究通过机器学习模型的实证评估发现，在大学录取过程中排除受保护属性会导致预测表现下降，而通过使用文本信息可以部分恢复模型的性能。 |
| [^19] | [The most likely common cause.](http://arxiv.org/abs/2306.17557) | 对于因果不充分的情况下的共同原因问题，我们使用广义最大似然方法来识别共同原因C，与最大熵原则密切相关。对于两个二元对称变量的研究揭示了类似于二阶相变的条件概率非解析行为。 |
| [^20] | [TTSWING: a Dataset for Table Tennis Swing Analysis.](http://arxiv.org/abs/2306.17550) | TTSWING是一种专为乒乓球挥拍分析设计的数据集，通过集成传感器获取详细信息并与运动员数据一起发布。对于乒乓球分析的创新研究具有巨大潜力，对科学界来说是宝贵的资源。 |
| [^21] | [DisPlacing Objects: Improving Dynamic Vehicle Detection via Visual Place Recognition under Adverse Conditions.](http://arxiv.org/abs/2306.17536) | 本研究通过利用先验地图来改进动态车辆检测，无需使用3D地图或像素级地图查询对应。通过视觉场所识别和二进制分类神经网络，我们成功优化了初始的候选物体检测，产生了更准确的检测结果。该方法在恶劣的天气和光照条件下表现出优异的性能。 |
| [^22] | [Locking On: Leveraging Dynamic Vehicle-Imposed Motion Constraints to Improve Visual Localization.](http://arxiv.org/abs/2306.17529) | 该论文提出了一种利用动态车辆施加的运动约束来改善视觉定位的方法，通过在自动驾驶车辆的背景下使用动态车辆在定位流程中提供有限姿态约束信息，优化姿态估计并计算未来姿态估计质量，从而提高了定位的鲁棒性和准确性。 |
| [^23] | [A behaviouristic approach to representing processes and procedures in the OASIS 2 ontology.](http://arxiv.org/abs/2306.17514) | 该论文提出了一种在OASIS 2本体中表示过程和程序的行为主义方法，该方法通过将代理和行为的能力与过程和程序的概念化相结合，旨在提供一个处理代理平台、过程和程序的基础OWL本体。 |
| [^24] | [Systematic Investigation of Sparse Perturbed Sharpness-Aware Minimization Optimizer.](http://arxiv.org/abs/2306.17504) | 本论文系统研究了一种稀疏扰动的锐化感知最小化优化器（Sparse SAM），该优化器通过二进制掩码实现稀疏扰动，有效地平滑了深度神经网络的损失景观。 |
| [^25] | [Empirical Interpretation of the Relationship Between Speech Acoustic Context and Emotion Recognition.](http://arxiv.org/abs/2306.17500) | 本研究通过使用基于注意力的方法，探讨了声学背景和音位边界对语音情感识别中局部标记的影响，并发现使用分布式方法进行语音情感理解的好处。 |
| [^26] | [Preference Ranking Optimization for Human Alignment.](http://arxiv.org/abs/2306.17492) | 本文提出了Preference Ranking Optimization (PRO)方法，通过扩展布拉德利-特里比较，采用偏好排序的方式来直接对齐大型语言模型（LLMs），解决了强化学习从人类反馈中学习的复杂性、不稳定性和对超参数的敏感性的问题。 |
| [^27] | [Graphtester: Exploring Theoretical Boundaries of GNNs on Graph Datasets.](http://arxiv.org/abs/2306.17482) | 本文提出了一个名为Graphtester的新工具，用于探索图数据集上GNNs的理论边界。通过分析40多个不同的图数据集，我们确定了各种GNNs性能的上限，并展示了该工具对图变换器的适用性。最后，我们证明了Graphtester生成的特征可以用于实际应用。 |
| [^28] | [Harnessing LLMs in Curricular Design: Using GPT-4 to Support Authoring of Learning Objectives.](http://arxiv.org/abs/2306.17459) | 本论文评估了使用GPT-4在人工智能课程中自动生成高质量学习目标的能力，强调了学习目标的重要性和撰写高质量目标的挑战性。 |
| [^29] | [GMM: Delving into Gradient Aware and Model Perceive Depth Mining for Monocular 3D Detection.](http://arxiv.org/abs/2306.17450) | 本论文提出了一种基于取样挖掘技术的简单而有效的深度感知挖掘策略，通过对深度预测质量的评估和挖掘，改进了单目3D检测中的深度感知，提高了深度预测的准确性。 |
| [^30] | [Decentralized Motor Skill Learning for Complex Robotic Systems.](http://arxiv.org/abs/2306.17411) | 这项研究提出了一种去中心化运动技能（DEMOS）学习算法，通过分散控制电机组来提高机器人策略的鲁棒性和泛化能力，而不降低性能。 |
| [^31] | [LMBot: Distilling Graph Knowledge into Language Model for Graph-less Deployment in Twitter Bot Detection.](http://arxiv.org/abs/2306.17408) | LMBot是一种新颖的推特机器人检测框架，将图神经网络的知识融入到语言模型中，实现了无图形部署，以解决数据依赖性的挑战。 |
| [^32] | [HVTSurv: Hierarchical Vision Transformer for Patient-Level Survival Prediction from Whole Slide Image.](http://arxiv.org/abs/2306.17373) | HVTSurv是一种基于层次化视觉Transformer的方法，用于从全幻灯图像预测患者的生存情况。其通过特征预处理和逐层编码的方式，能够捕捉到局部空间信息、增强上下文感知，建立患者级别的层次交互。 |
| [^33] | [Differential Privacy May Have a Potential Optimization Effect on Some Swarm Intelligence Algorithms besides Privacy-preserving.](http://arxiv.org/abs/2306.17370) | 该论文首次尝试将差分隐私和群体智能算法结合，提出了一种通用的差分隐私群体智能算法框架（DPSIAF），通过该框架可以将现有的群体智能算法轻松改造为私有版本。实验结果表明，该私有算法的性能不严格受到隐私预算的影响。 |
| [^34] | [$\lambda$-AC: Learning latent decision-aware models for reinforcement learning in continuous state-spaces.](http://arxiv.org/abs/2306.17366) | 这项研究提出了一种$\lambda$-AC算法，通过学习连续状态空间中的潜在决策感知模型，实现了决策驱动的强化学习。通过理论和实证研究，确定了决策感知强化学习模型的必要组成部分，并展示了设计选择对算法性能的重要影响。 |
| [^35] | [iSCAN: Identifying Causal Mechanism Shifts among Nonlinear Additive Noise Models.](http://arxiv.org/abs/2306.17361) | 本文提出了一种识别非线性加性噪声模型中因果机制转变的方法，该方法专注于在相关的结构因果模型中识别功能机制的变化，而不需要估计整个有向无环图(DAG)的结构。 |
| [^36] | [Diagnosis Uncertain Models For Medical Risk Prediction.](http://arxiv.org/abs/2306.17337) | 研究提出了一种具有诊断不确定性的医疗风险预测模型，解决了当相同的特征可以对应不同风险的诊断时风险低估的问题。 |
| [^37] | [A Neural Separation Algorithm for the Rounded Capacity Inequalities.](http://arxiv.org/abs/2306.17283) | 本论文提出了一种基于学习的分割启发式算法，使用图神经网络学习精确分割问题的解，通过嵌入切平面法找到了容量VRP的下限。 |
| [^38] | [Modeling Parallel Programs using Large Language Models.](http://arxiv.org/abs/2306.17281) | 本文展示了如何利用大型语言模型（LLMs）在高性能计算和科学代码的开发和分析中自动化更复杂的任务。 |
| [^39] | [Probabilistic Constraint for Safety-Critical Reinforcement Learning.](http://arxiv.org/abs/2306.17279) | 本文研究了概率约束下的安全关键强化学习问题，提出了具有明确梯度表达式的Safe Policy Gradient-REINFORCE（SPG-REINFORCE）算法，并通过理论界限证明了概率约束设置在最优性和安全性之间具有更好的权衡。 |
| [^40] | [Suffering Toasters.](http://arxiv.org/abs/2306.17258) | 本文旨在为人工智能、自我意识和代理问题提供更清晰的定义，我们提出了一种新的启发式方法来测试人工自我意识，并讨论了这种方法引发的一些问题。 |
| [^41] | [Prediction of COVID-19 Patients' Emergency Room Revisit using Multi-Source Transfer Learning.](http://arxiv.org/abs/2306.17257) | 本研究利用迁移学习和自然语言处理技术，预测COVID-19患者出院后在急诊室的再访情况，早期识别有助于医生专注于危及生命的病例。 |
| [^42] | [Towards Personalized Cold-Start Recommendation with Prompts.](http://arxiv.org/abs/2306.17256) | 本研究旨在解决个性化冷启动推荐问题，通过利用预训练语言模型的能力，将推荐过程转化为自然语言情感分析，提供适用于创业企业和用户参与历史不足的平台的个性化推荐。 |
| [^43] | [A Hybrid System for Systematic Generalization in Simple Arithmetic Problems.](http://arxiv.org/abs/2306.17249) | 本研究提出了一个混合系统，可以解决需要组合性和系统性推理的算术问题。该系统通过学习适当的替换规则来获得能力，在只训练最简单情况的情况下，可以准确地解决嵌套算术表达式，优于其他模型。 |
| [^44] | [An Intelligent Mechanism for Monitoring and Detecting Intrusions in IoT Devices.](http://arxiv.org/abs/2306.17187) | 本研究提出了一种基于主机的入侵检测系统，利用联邦学习和多层感知机神经网络来提高对物联网设备上网络攻击的准确性，并增强数据隐私保护。 |
| [^45] | [Blockchain-based Federated Learning for Decentralized Energy Management Systems.](http://arxiv.org/abs/2306.17186) | 本论文对区块链、智能合约和联邦学习在能源互联网中的应用进行了全面分析和分类，提出了四种典型的系统模型，并讨论了它们的关键方面。 |
| [^46] | [Replace and Report: NLP Assisted Radiology Report Generation.](http://arxiv.org/abs/2306.17180) | 本研究提出了一种模板化的方法，利用NLP技术辅助生成放射学报告。该方法通过使用图像分类器生成图像标签，然后通过基于变压器的模型生成病理描述，并使用BERT模型替换正常报告模板中的相应部分，最终生成完整的放射学报告。 |
| [^47] | [Integrating Tick-level Data and Periodical Signal for High-frequency Market Making.](http://arxiv.org/abs/2306.17179) | 该论文提出了一种融合滴级数据和周期预测信号的深度强化学习方法，用于开发更准确、更稳健的高频市场做市策略。实验证明，该方法在盈利能力和风险管理方面优于现有方法。 |
| [^48] | [News Verifiers Showdown: A Comparative Performance Evaluation of ChatGPT 3.5, ChatGPT 4.0, Bing AI, and Bard in News Fact-Checking.](http://arxiv.org/abs/2306.17176) | 本研究通过对比实验评估了ChatGPT 3.5、ChatGPT 4.0、Bing AI和Bard在新闻事实检查中的表现，结果显示它们的熟练程度普遍居中，其中OpenAI的GPT-4.0在区分真相和欺骗方面具有一定优势。 |
| [^49] | [RECAP-KG: Mining Knowledge Graphs from Raw GP Notes for Remote COVID-19 Assessment in Primary Care.](http://arxiv.org/abs/2306.17175) | 本研究提出了一个从原始GP笔记中提取信息并构建知识图谱的框架，用于解决临床决策过程中现有技术无法处理的问题。 |
| [^50] | [Empowering NLG: Offline Reinforcement Learning for Informal Summarization in Online Domains.](http://arxiv.org/abs/2306.17174) | 该论文介绍了一种离线强化学习的自然语言生成方法，用于在在线领域生成非正式摘要，并通过該方法在用户体验和负载减轻方面取得了显著改进。 |
| [^51] | [An Overview on Generative AI at Scale with Edge-Cloud Computing.](http://arxiv.org/abs/2306.17170) | 边缘云计算下规模化生成型人工智能的发展和挑战进行了综述，讨论了利用边缘云计算范式构建GenAI系统的吸引力。 |
| [^52] | [Enterprise Disk Drive Scrubbing Based on Mondrian Conformal Predictors.](http://arxiv.org/abs/2306.17169) | 提出了一种基于Mondrian Conformal预测器的企业磁盘驱动刷新方法，通过使用机器学习模型识别需要刷新的磁盘，并提前预测其健康状态，从而提高整体可靠性和功率效率。 |
| [^53] | [Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors.](http://arxiv.org/abs/2306.17156) | 该论文系统评估了ChatGPT、GPT-4和人类导师在不同的编程教育场景中的表现，并发现GPT-4优于ChatGPT，接近于人类导师。 |
| [^54] | [Harnessing the Power of Hugging Face Transformers for Predicting Mental Health Disorders in Social Networks.](http://arxiv.org/abs/2306.16891) | 该研究通过使用社交媒体和预训练的语言模型，探索了使用用户生成的数据预测精神障碍症状的方法，并发现新模型的准确度高达97%。这表明社交媒体数据是进行精神健康筛查的一个重要资源，预训练模型能够有效地自动化这一任务。 |
| [^55] | [Elastically-Constrained Meta-Learner for Federated Learning.](http://arxiv.org/abs/2306.16703) | 这项研究提出了一种弹性约束的元学习方法，用于解决联邦学习中由于非独立同分布数据导致元学习的不稳定目标的收敛问题。 |
| [^56] | [DUET: 2D Structured and Approximately Equivariant Representations.](http://arxiv.org/abs/2306.16058) | DUET是一种2D结构化且近似等变表示方法，相比于其他方法，可以在保留输入变换信息的同时具有更好的可控性和更高的准确性。 |
| [^57] | [Categorical Approach to Conflict Resolution: Integrating Category Theory into the Graph Model for Conflict Resolution.](http://arxiv.org/abs/2306.13961) | 本论文介绍了一种新型的冲突解决框架，称为C-GMCR，它将范畴论整合到传统的图模型中，能够提供更抽象和通用的分析冲突解决的方式。通过应用到囚徒困境和其他案例中，发现分类方法提供了新的视角和可能导致更有效的冲突解决策略的发展。 |
| [^58] | [Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering.](http://arxiv.org/abs/2306.00526) | 该论文提出了一种布局和任务感知的指导提示模型，称为LATIN-Prompt，通过将文档图像问答对齐到现成的指导调优语言基础模型，利用其零样本能力来提高效果。该模型包括布局感知的文档内容和任务感知的描述，能够恢复文本片段之间的布局信息，并生成符合任务需求的答案。 |
| [^59] | [Faithfulness Tests for Natural Language Explanations.](http://arxiv.org/abs/2305.18029) | 该论文研究了评估自然语言解释真实性的问题，并提出了两个测试方法：反事实输入编辑器和重建输入测试。这些测试对于评估新兴的NLE模型，对开发真实的NLEs具有重要意义。 |
| [^60] | [Sim2real and Digital Twins in Autonomous Driving: A Survey.](http://arxiv.org/abs/2305.01263) | 本文综述了自主驾驶中的sim2real和数字孪生方法，它们分别解决了从模拟到现实的知识转移和从真实世界数据中学习以提高仿真精度的问题，但也存在各自的优缺点和限制。 |
| [^61] | [Federated Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering.](http://arxiv.org/abs/2304.13911) | 本论文提出一种名为Fed-SP-SC和Fed-DP-CoT的技术，通过联邦提示和链式推理改进分布式同义问题的准确性，从而提高基于云的大型语言模型（LLMs）回答常见问题的精度，并进行了充分实验验证。 |
| [^62] | [Multiobjective Logistics Optimization for Automated ATM Cash Replenishment Process.](http://arxiv.org/abs/2304.13671) | 本文研究了自动化ATM现金补充流程，提出了一个数学模型并给出了一个工具来评估各种不同的情况。在模拟数据集上，该模型与方法可以削减ATM现金运营成本。 |
| [^63] | [GRIL: A $2$-parameter Persistence Based Vectorization for Machine Learning.](http://arxiv.org/abs/2304.04970) | 本文提出一种名为GRIL的方法，用于将拓扑特征表示散度到机器学习模型中，该方法可以稳定地用于不同的过滤函数。 |
| [^64] | [Uncertainty Estimation by Fisher Information-based Evidential Deep Learning.](http://arxiv.org/abs/2303.02045) | 本文提出了一种基于Fisher信息的证据深度学习方法，用于解决高数据不确定性样本但注释为one-hot标签的情况下证据学习过程被过度惩罚并受到阻碍的问题。 |
| [^65] | [Solving QMLTP Problems by Translation to Higher-order Logic.](http://arxiv.org/abs/2212.09570) | 本文研究了将 QMLTP 问题翻译成高阶逻辑并解决的方法，发现嵌入过程可靠且成功，后端 ATP 系统的选择会显著影响嵌入方法的性能，本地模态逻辑 ATP 系统优于嵌入方法。 |
| [^66] | [GEC: A Unified Framework for Interactive Decision Making in MDP, POMDP, and Beyond.](http://arxiv.org/abs/2211.01962) | 本研究在交互式决策的框架下，提出了一种新的复杂度度量GEC，用于样本高效强化学习。该方法能够捕捉到探索和开发之间的权衡，将RL问题划分为低GEC和高GEC两个类别，并展示了低GEC类别的丰富性质。 |
| [^67] | [MAGIC: Mask-Guided Image Synthesis by Inverting a Quasi-Robust Classifier.](http://arxiv.org/abs/2209.11549) | 本论文提出了一种名为MAGIC的方法，通过反转准鲁棒分类器进行一次性掩码引导的图像合成。它通过聚合梯度并利用强空间先验的指导二进制掩码，实现了形状和位置控制、非刚性形状变形以及复制/移动操作，并可简单指定二进制引导掩码来提供强大的合成控制。 |
| [^68] | [Enhanced Methods for the Weight Constrained Shortest Path Problem.](http://arxiv.org/abs/2207.14744) | 本文提出了两种基于A*搜索的新解法，用于解决权重约束最短路径问题（WCSPP），在大规模图上表现出优越性能。 |
| [^69] | [Sequential Recommendation Model for Next Purchase Prediction.](http://arxiv.org/abs/2207.06225) | 本文提出了一种顺序推荐系统，考虑了用户的购买顺序以预测他们的下一次购买，该模型利用大规模的信用卡交易数据集进行了验证和排名，展现了其在准确性和效果上的优势。 |
| [^70] | [Plurality Veto: A Simple Voting Rule Achieving Optimal Metric Distortion.](http://arxiv.org/abs/2206.07098) | Plurality Veto是一种实现最优度量畸变的简单投票规则，每个候选人的得分等于他的第一名选票数，并通过逐步的否决过程逐渐降低得分，在其得票数达到一半时退出。 |

# 详细

[^1]: 打破度量投票扭曲的障碍

    Breaking the Metric Voting Distortion Barrier. (arXiv:2306.17838v1 [cs.GT])

    [http://arxiv.org/abs/2306.17838](http://arxiv.org/abs/2306.17838)

    这篇论文研究了社会选择中的度量扭曲问题，提出了一个新的投票规则，该规则可以选择距离选民平均距离较小的候选人。之前的研究发现确定性投票规则的度量扭曲限制为3，但在无限制的情况下，我们对该问题仍然了解有限。

    

    我们考虑社会选择中度量扭曲的经典问题。假设我们有一个选举，有n名选民和m名候选人，他们位于一个共享的度量空间中。我们希望设计一个投票规则，选择一个平均距离选民较小的候选人。然而，我们不能直接获得度量空间中的距离信息，每个选民只能给出候选人的排序列表。我们能否设计一条规则，无论选举实例和底层度量空间如何，都能选择出一个与真正最优解的代价只相差一个小因子（称为扭曲度）的候选人？许多研究的成果将确定性投票规则的度量扭曲限制为3，这是确定性规则和许多其他投票规则类别的最佳结果。然而，在没有任何限制的情况下，我们对该问题仍然了解有限：尽管最佳下界已经降低到2.112，但现有规则的扭曲度仍然相对较高。

    We consider the following well studied problem of metric distortion in social choice. Suppose we have an election with $n$ voters and $m$ candidates who lie in a shared metric space. We would like to design a voting rule that chooses a candidate whose average distance to the voters is small. However, instead of having direct access to the distances in the metric space, each voter gives us a ranked list of the candidates in order of distance. Can we design a rule that regardless of the election instance and underlying metric space, chooses a candidate whose cost differs from the true optimum by only a small factor (known as the distortion)?  A long line of work culminated in finding deterministic voting rules with metric distortion $3$, which is the best possible for deterministic rules and many other classes of voting rules. However, without any restrictions, there is still a significant gap in our understanding: Even though the best lower bound is substantially lower at $2.112$, the b
    
[^2]: 重置深度强化学习中的优化器：一个实证研究

    Resetting the Optimizer in Deep RL: An Empirical Study. (arXiv:2306.17833v1 [cs.LG])

    [http://arxiv.org/abs/2306.17833](http://arxiv.org/abs/2306.17833)

    在深度强化学习中，当优化问题的风景在不同迭代中差异较大时，重置优化器的内部参数可以避免污染和提高性能。

    

    我们关注的是在深度强化学习中近似计算最优值函数的任务。这个迭代过程包括在每个迭代中解决一系列不同迭代中目标函数可能改变的优化问题。解决这个问题的常见方法是使用现代变种的随机梯度下降算法，如Adam。这些优化器保持自己的内部参数，如梯度的一阶和二阶矩估计，并随时间更新这些参数。因此，之前迭代的信息被用来在当前迭代中解决优化问题。我们假设在之前迭代的优化风景与当前迭代相差较大的情况下，这可能会污染所使用优化器的内部参数。为了避免这种影响，一个简单的想法是在开始新的迭代时重置优化器的内部参数。

    We focus on the task of approximating the optimal value function in deep reinforcement learning. This iterative process is comprised of approximately solving a sequence of optimization problems where the objective function can change per iteration. The common approach to solving the problem is to employ modern variants of the stochastic gradient descent algorithm such as Adam. These optimizers maintain their own internal parameters such as estimates of the first and the second moment of the gradient, and update these parameters over time. Therefore, information obtained in previous iterations is being used to solve the optimization problem in the current iteration. We hypothesize that this can contaminate the internal parameters of the employed optimizer in situations where the optimization landscape of the previous iterations is quite different from the current iteration. To hedge against this effect, a simple idea is to reset the internal parameters of the optimizer when starting a n
    
[^3]: 通过训练概念影响理解不公平性

    Understanding Unfairness via Training Concept Influence. (arXiv:2306.17828v1 [cs.LG])

    [http://arxiv.org/abs/2306.17828](http://arxiv.org/abs/2306.17828)

    通过观察训练数据的作用，研究模型不公平性的来源和影响，并通过改变样本的属性来计算训练样本对模型的不公平性的影响。

    

    了解模型不公平性的原因有助于从业人员更好地理解他们的数据和算法。我们通过培训数据这一主要不公平来源的视角来研究这个问题。我们提出以下问题：如果在训练数据中有些样本（1）来自不同的（例如人口统计学）群体，（2）标记方式不同，或者（3）某些特征发生了变化，那么模型的公平性表现会发生怎样的变化？换句话说，我们通过反事实地对基于预定义概念的样本进行干预和改变，量化训练样本对模型的不公平性的影响。计算训练样本对模型相对于概念的不公平性的影响时，我们首先基于概念生成反事实版本的样本，即如果概念发生变化，样本的反事实版本。然后我们计算重新

    Knowing the causes of a model's unfairness helps practitioners better understand their data and algorithms. This is an important yet relatively unexplored task. We look into this problem through the lens of the training data - one of the major sources of unfairness. We ask the following questions: how would a model's fairness performance change if, in its training data, some samples (1) were collected from a different (e.g. demographic) group, (2) were labeled differently, or (3) some features were changed? In other words, we quantify the fairness influence of training samples by counterfactually intervening and changing samples based on predefined concepts, i.e. data attributes such as features (X), labels (Y), or sensitive attributes (A). To calculate a training sample's influence on the model's unfairness w.r.t a concept, we first generate counterfactual samples based on the concept, i.e. the counterfactual versions of the sample if the concept were changed. We then calculate the re
    
[^4]: Act3D：无限分辨率的机器人操作检测Transformer

    Act3D: Infinite Resolution Action Detection Transformer for Robotic Manipulation. (arXiv:2306.17817v1 [cs.RO])

    [http://arxiv.org/abs/2306.17817](http://arxiv.org/abs/2306.17817)

    Act3D是一种基于Transformer的操作策略，将6自由度关键姿势预测作为3D检测任务，并以自适应空间计算的方式进行处理。它在高度精确的机器人操纵任务中取得了显著的性能改进。

    

    3D感知表征非常适用于机器人操纵，因为它们可以轻松编码遮挡情况并简化空间推理。许多操纵任务需要对末端执行器姿势预测进行高空间精度，通常需要高分辨率的3D感知网格进行计算，这在处理上非常耗时。因此，大多数操作策略直接在2D中运作，放弃了3D的归纳偏差。本文提出了Act3D，一种将6自由度关键姿势预测视为自适应空间计算的操作策略Transformer。它以一个或多个摄像机视图的未投影3D特征云作为输入，以粗-精方式在自由空间中迭代采样3D点网格，使用相对空间注意力将其特征化为物理特征云，并选择最佳特征点进行末端执行器姿势预测。Act3D在已建立的操纵基准RLbench中取得了最新的最好成绩。我们的模型在该基准中实现了10%的绝对改进。

    3D perceptual representations are well suited for robot manipulation as they easily encode occlusions and simplify spatial reasoning. Many manipulation tasks require high spatial precision in end-effector pose prediction, typically demanding high-resolution 3D perceptual grids that are computationally expensive to process. As a result, most manipulation policies operate directly in 2D, foregoing 3D inductive biases. In this paper, we propose Act3D, a manipulation policy Transformer that casts 6-DoF keypose prediction as 3D detection with adaptive spatial computation. It takes as input 3D feature clouds unprojected from one or more camera views, iteratively samples 3D point grids in free space in a coarse-to-fine manner, featurizes them using relative spatial attention to the physical feature cloud, and selects the best feature point for end-effector pose prediction. Act3D sets a new state-of-the-art in RLbench, an established manipulation benchmark. Our model achieves 10% absolute impr
    
[^5]: 利用隐藏规则游戏比较强化学习和人类学习

    Comparing Reinforcement Learning and Human Learning using the Game of Hidden Rules. (arXiv:2306.17766v1 [cs.AI])

    [http://arxiv.org/abs/2306.17766](http://arxiv.org/abs/2306.17766)

    本文研究了利用隐藏规则游戏比较强化学习和人类学习，在一个特定的学习环境中通过任务结构的实验发现了人类和强化学习算法的性能差异。

    

    可靠地部署强化学习方法在现实世界中需要对它们的优点和缺点以及与人类的比较进行细致的理解。人机系统越来越普遍，而这些系统的设计依赖于对人类学习和强化学习的任务导向理解。因此，一个重要的研究方向是对学习任务结构如何影响学习性能进行表征。虽然越来越复杂的基准环境已经提高了强化学习能力，但这些环境很难用来专门研究任务结构。为了解决这个挑战，我们提供了一个支持严密研究任务结构对人类学习和强化学习影响的学习环境。通过任务结构的示例实验，我们展示了这个环境在这方面研究中的实用性，显示出人类和强化学习算法之间的性能差异。

    Reliable real-world deployment of reinforcement learning (RL) methods requires a nuanced understanding of their strengths and weaknesses and how they compare to those of humans. Human-machine systems are becoming more prevalent and the design of these systems relies on a task-oriented understanding of both human learning (HL) and RL. Thus, an important line of research is characterizing how the structure of a learning task affects learning performance. While increasingly complex benchmark environments have led to improved RL capabilities, such environments are difficult to use for the dedicated study of task structure. To address this challenge we present a learning environment built to support rigorous study of the impact of task structure on HL and RL. We demonstrate the environment's utility for such study through example experiments in task structure that show performance differences between humans and RL algorithms.
    
[^6]: 歧视性或撒马利亚式 -- 人类需要哪种人工智能？混合人工智能人口的进化博弈论分析

    Discriminatory or Samaritan -- which AI is needed for humanity? An Evolutionary Game Theory Analysis of Hybrid Human-AI populations. (arXiv:2306.17747v1 [cs.MA])

    [http://arxiv.org/abs/2306.17747](http://arxiv.org/abs/2306.17747)

    这项研究通过进化博弈理论的分析发现，相比于只帮助符合条件的人的歧视性人工智能，撒马利亚式人工智能可以更好地促进人类间的合作。这对于缓慢发展的社会尤为重要，因为在这种社会中，变化被视为谨慎和抵抗。

    

    随着人工智能系统越来越嵌入我们的生活，它们的存在导致了塑造我们的行为、决策和社会互动的相互作用。现有的理论研究主要集中在人与人之间的互动上，忽视了人工智能存在导致的独特动态。在本文中，我们采用进化博弈理论的方法，研究了不同形式的人工智能对在混合人工智能人口中进行一次性囚徒困境游戏的合作演化的影响，包括完全混合人口和结构化人口。我们发现，无论是向每个人都无条件提供帮助，包括叛徒，还是只帮助被认为值得或合作的人的撒马利亚人工智能代理人，对于推动人类合作的水平来说，后者要比前者更有利，特别是在变化被谨慎或抵抗视为的缓慢发展的社会中（选择的强度较小）。直观上，在变化快速的社会中（选择的强度较高），歧视性人工智能可以更好地推动合作。

    As artificial intelligence (AI) systems are increasingly embedded in our lives, their presence leads to interactions that shape our behaviour, decision-making, and social interactions. Existing theoretical research has primarily focused on human-to-human interactions, overlooking the unique dynamics triggered by the presence of AI. In this paper, resorting to methods from evolutionary game theory, we study how different forms of AI influence the evolution of cooperation in a human population playing the one-shot Prisoner's Dilemma game in both well-mixed and structured populations. We found that Samaritan AI agents that help everyone unconditionally, including defectors, can promote higher levels of cooperation in humans than Discriminatory AI that only help those considered worthy/cooperative, especially in slow-moving societies where change is viewed with caution or resistance (small intensities of selection). Intuitively, in fast-moving societies (high intensities of selection), Dis
    
[^7]: 基于Token-Event-Role结构的多通道文档级事件抽取

    Token-Event-Role Structure-based Multi-Channel Document-Level Event Extraction. (arXiv:2306.17733v1 [cs.CL])

    [http://arxiv.org/abs/2306.17733](http://arxiv.org/abs/2306.17733)

    本文提出了一种基于Token-Event-Role结构的多通道文档级事件抽取框架，通过引入新的数据结构和预测模块，能够更全面地理解事件之间的关系，并通过预测token-event对的方式，实现了实体和多事件抽取的集成，减少了模型复杂性。

    

    文档级事件抽取是一个历史悠久且具有挑战性的信息检索问题，涉及一系列子任务：实体抽取、事件类型判断和特定事件类型的多事件抽取。然而，将问题视为多个学习任务会增加模型复杂性。此外，现有方法未充分利用跨越不同事件的实体的相关性，导致事件抽取性能有限。本文引入了一种新的文档级事件抽取框架，其中包括一个称为token-event-role的新数据结构和一个多通道参数角色预测模块。所提出的数据结构使得我们的模型能够揭示多个事件中token的主要作用，从而更全面地理解事件之间的关系。通过利用多通道预测模块，我们将实体和多事件抽取转化为预测token-event对的单一任务，从而减少了模型复杂性。

    Document-level event extraction is a long-standing challenging information retrieval problem involving a sequence of sub-tasks: entity extraction, event type judgment, and event type-specific multi-event extraction. However, addressing the problem as multiple learning tasks leads to increased model complexity. Also, existing methods insufficiently utilize the correlation of entities crossing different events, resulting in limited event extraction performance. This paper introduces a novel framework for document-level event extraction, incorporating a new data structure called token-event-role and a multi-channel argument role prediction module. The proposed data structure enables our model to uncover the primary role of tokens in multiple events, facilitating a more comprehensive understanding of event relationships. By leveraging the multi-channel prediction module, we transform entity and multi-event extraction into a single task of predicting token-event pairs, thereby reducing the 
    
[^8]: 多模态提示检索用于生成式视觉问答

    Multimodal Prompt Retrieval for Generative Visual Question Answering. (arXiv:2306.17675v1 [cs.CV])

    [http://arxiv.org/abs/2306.17675](http://arxiv.org/abs/2306.17675)

    本研究提出了一种基于多模态提示检索的生成式视觉问答模型，通过整合检索到的提示和多模态特征，实现了在自由文本中生成答案。该模型具有快速零样本自适应能力，并在医学视觉问答任务中比非检索模型高出30%的准确率。

    

    近年来，预训练的视觉语言模型在知识密集型任务（如视觉问答）上取得了令人瞩目的成果。尽管在视觉问答方面已取得了一些进展，但现有方法主要采用判别式公式，在预定义的标签集内预测答案，导致在有限标注数据（如医学领域）的低资源领域容易过拟合，且在领域转移到另一个数据集时泛化能力较差。为了解决这个问题，我们提出了一种新颖的生成模型，通过多模态提示检索（MPR）来增强，它将检索到的提示和多模态特征结合起来以生成自由文本答案。我们的生成模型能够快速进行零样本数据集自适应，适应未见过的数据分布和跨数据集的开放式答案标签。我们在医学视觉问答任务上的实验证明，在少样本领域自适应设置中，MPR在准确率上优于非检索模型最多30个百分点。

    Recent years have witnessed impressive results of pre-trained vision-language models on knowledge-intensive tasks such as visual question answering (VQA). Despite the recent advances in VQA, existing methods mainly adopt a discriminative formulation that predicts answers within a pre-defined label set, leading to easy overfitting on low-resource domains with limited labeled data (e.g., medicine) and poor generalization under domain shift to another dataset. To tackle this limitation, we propose a novel generative model enhanced by multimodal prompt retrieval (MPR) that integrates retrieved prompts and multimodal features to generate answers in free text. Our generative model enables rapid zero-shot dataset adaptation to unseen data distributions and open-set answer labels across datasets. Our experiments on medical VQA tasks show that MPR outperforms its non-retrieval counterpart by up to 30% accuracy points in a few-shot domain adaptation setting.
    
[^9]: 基于点的神经符号POMDP值迭代

    Point-based Value Iteration for Neuro-Symbolic POMDPs. (arXiv:2306.17639v1 [eess.SY])

    [http://arxiv.org/abs/2306.17639](http://arxiv.org/abs/2306.17639)

    本文提出了一种基于点的神经符号POMDP值迭代算法，结合了传统符号技术和神经网络，解决了连续状态置信度函数的问题，实现了优化折扣累积回报的连续状态决策问题。

    

    神经符号人工智能是结合传统符号技术和神经网络的新兴领域。本文考虑其在不确定性下顺序决策中的应用。我们引入了神经符号部分可观察马尔可夫决策过程（NS-POMDPs），该模型描述了一个使用神经网络感知连续状态环境并进行符号决策的代理，并研究了优化折扣累积回报的问题。针对连续状态置信度函数，我们提出了一种新的分段线性和凸表示（P-PWLC），通过覆盖连续状态空间的多面体和值向量实现，并将Bellman backups扩展到该表示。我们证明了值函数的凸性和连续性，并提出了两种值迭代算法，通过利用连续状态模型和神经感知机制的底层结构来保证有限表示能力。

    Neuro-symbolic artificial intelligence is an emerging area that combines traditional symbolic techniques with neural networks. In this paper, we consider its application to sequential decision making under uncertainty. We introduce neuro-symbolic partially observable Markov decision processes (NS-POMDPs), which model an agent that perceives a continuous-state environment using a neural network and makes decisions symbolically, and study the problem of optimising discounted cumulative rewards. This requires functions over continuous-state beliefs, for which we propose a novel piecewise linear and convex representation (P-PWLC) in terms of polyhedra covering the continuous-state space and value vectors, and extend Bellman backups to this representation. We prove the convexity and continuity of value functions and present two value iteration algorithms that ensure finite representability by exploiting the underlying structure of the continuous-state model and the neural perception mechani
    
[^10]: 用单个ToF相机实现与RGB-D相机相当的分割性能

    Achieving RGB-D level Segmentation Performance from a Single ToF Camera. (arXiv:2306.17636v1 [cs.CV])

    [http://arxiv.org/abs/2306.17636](http://arxiv.org/abs/2306.17636)

    本文使用单个ToF相机的红外和深度图像，在语义分割任务上表现出与RGB-D相机相当的准确性，通过引入深度专用卷积的多任务学习方法，展示了在车内分割数据集上的竞争力。

    

    深度是计算机视觉中非常重要的一种模态，通常作为RGB的补充信息由RGB-D相机提供。在本文中，我们展示了使用单个ToF相机的红外（IR）和深度图像可以在语义分割任务上获得与RGB-D相机相同水平的准确性。为了融合ToF相机的红外和深度模态，我们引入了一种在多任务学习框架中利用深度专用卷积的方法。在我们对车内分割数据集的评估中，我们展示了我们的方法与更昂贵的RGB-D方法的竞争力。

    Depth is a very important modality in computer vision, typically used as complementary information to RGB, provided by RGB-D cameras. In this work, we show that it is possible to obtain the same level of accuracy as RGB-D cameras on a semantic segmentation task using infrared (IR) and depth images from a single Time-of-Flight (ToF) camera. In order to fuse the IR and depth modalities of the ToF camera, we introduce a method utilizing depth-specific convolutions in a multi-task learning framework. In our evaluation on an in-car segmentation dataset, we demonstrate the competitiveness of our method against the more costly RGB-D approaches.
    
[^11]: 使用强化学习设计感应电机

    Design of Induction Machines using Reinforcement Learning. (arXiv:2306.17626v1 [cs.LG])

    [http://arxiv.org/abs/2306.17626](http://arxiv.org/abs/2306.17626)

    该论文介绍了一种使用强化学习算法设计定制的感应电动机的方法，通过模拟多个电机设计实例进行离线训练，使得电机设计自动化并满足特定的操作要求。

    

    由于电磁和热约束的不同，感应电机的设计是一项具有挑战性的任务。在销售工具中快速估算机器的尺寸对于根据特定要求给客户提供快速报价非常重要。这个过程的关键部分是选择不同的设计参数，如长度、直径、齿尖高度和绕组匝数，以实现机器的特定扭矩、电流和温度。电机设计师通过他们的经验知道如何改变不同的机器设计参数，以满足客户的特定操作要求。我们提出了一种强化学习算法来设计定制的感应电动机。神经网络模型通过模拟电机设计游戏的不同实例进行离线训练，当做出良好或不良设计选择时，使用奖励或惩罚函数。结果表明，所提出的方法可以自动化电机设计，而无需应用任何人为制约。

    The design of induction machine is a challenging task due to different electromagnetic and thermal constraints. Quick estimation of machine's dimensions is important in the sales tool to provide quick quotations to customers based on specific requirements. The key part of this process is to select different design parameters like length, diameter, tooth tip height and winding turns to achieve certain torque, current and temperature of the machine. Electrical machine designers, with their experience know how to alter different machine design parameters to achieve a customer specific operation requirements. We propose a reinforcement learning algorithm to design a customised induction motor. The neural network model is trained off-line by simulating different instances of of electrical machine design game with a reward or penalty function when a good or bad design choice is made. The results demonstrate that the suggested method automates electrical machine design without applying any hu
    
[^12]: Sphere2Vec：一种适用于大规模地理空间预测的球面上通用位置表示学习方法

    Sphere2Vec: A General-Purpose Location Representation Learning over a Spherical Surface for Large-Scale Geospatial Predictions. (arXiv:2306.17624v1 [cs.CV])

    [http://arxiv.org/abs/2306.17624](http://arxiv.org/abs/2306.17624)

    Sphere2Vec是一种多尺度位置编码器，用于在球面上编码点坐标时保持球面距离，解决了大规模真实世界GPS坐标数据集中的距离度量问题。

    

    在机器学习中，为空间中的点生成适合学习的表示是一个基本且长期存在的问题。最近，提出了多尺度编码方案（如Space2Vec和NeRF），可以直接将二维/三维欧几里得空间中的任意点编码为高维向量，并成功应用于各种地理空间预测和生成任务。然而，目前所有的二维和三维位置编码器都是设计用来模拟欧几里得空间中的点距离。因此，在应用于需要在球面上进行距离度量学习的大规模真实世界GPS坐标数据集时，这两种类型的模型都会出现问题，原因是地图投影失真问题（2D）和球面到欧几里得距离近似误差（3D）。为了解决这些问题，我们提出了一种称为Sphere2Vec的多尺度位置编码器，可以在球面上编码点坐标时保持球面距离。我们在球面上的位置编码的距离保持编码的统一视角上进行了探索。

    Generating learning-friendly representations for points in space is a fundamental and long-standing problem in ML. Recently, multi-scale encoding schemes (such as Space2Vec and NeRF) were proposed to directly encode any point in 2D/3D Euclidean space as a high-dimensional vector, and has been successfully applied to various geospatial prediction and generative tasks. However, all current 2D and 3D location encoders are designed to model point distances in Euclidean space. So when applied to large-scale real-world GPS coordinate datasets, which require distance metric learning on the spherical surface, both types of models can fail due to the map projection distortion problem (2D) and the spherical-to-Euclidean distance approximation error (3D). To solve these problems, we propose a multi-scale location encoder called Sphere2Vec which can preserve spherical distances when encoding point coordinates on a spherical surface. We developed a unified view of distance-reserving encoding on sph
    
[^13]: 混合整数规划用于高效启发式算法的时间优化多机器人覆盖路径规划

    Mixed Integer Programming for Time-Optimal Multi-Robot Coverage Path Planning with Efficient Heuristics. (arXiv:2306.17609v1 [cs.RO])

    [http://arxiv.org/abs/2306.17609](http://arxiv.org/abs/2306.17609)

    本文研究了时间优化多机器人覆盖路径规划问题，并通过混合整数规划模型提出了一个最优解决方案，该方案的覆盖时间最多为最优解的四倍。此外，我们还提出了两个有效的启发式算法来减少问题的规模，并通过模型优化方法进一步提高了效率。

    

    我们研究了旨在最小化覆盖时间（定义为所有机器人的最大行程时间）的未加权和加权地形的时间优化多机器人覆盖路径规划（MCPP）。具体而言，我们将MCPP减少到了根最小最大树覆盖（RMMTC）。首次，我们提出了一个混合整数规划（MIP）模型来最优解决RMMTC问题，从而得到一个MCPP解决方案，其覆盖时间最多为最优解的四倍。此外，我们提出了两个次优但有效的启发式算法，用于减少MIP模型中的变量数量，从而提高其在大规模MCPP实例上的效率。我们展示了这两种启发式算法导致了缩小后的MIP模型，对于所有RMMTC实例来说仍然是完整的（即保证找到解决方案）。此外，我们还探索了模型优化的热启动方法，进一步提高了原始MIP模型和缩小后的MIP模型的效率。

    We investigate time-optimal Multi-Robot Coverage Path Planning (MCPP) for both unweighted and weighted terrains, which aims to minimize the coverage time, defined as the maximum travel time of all robots. Specifically, we focus on a reduction from MCPP to Rooted Min-Max Tree Cover (RMMTC). For the first time, we propose a Mixed Integer Programming (MIP) model to optimally solve RMMTC, resulting in an MCPP solution with a coverage time that is provably at most four times the optimal. Moreover, we propose two suboptimal yet effective heuristics that reduce the number of variables in the MIP model, thus improving its efficiency for large-scale MCPP instances. We show that both heuristics result in reduced-size MIP models that remain complete (i.e., guarantee to find a solution if one exists) for all RMMTC instances. Additionally, we explore the use of model optimization warm-startup to further improve the efficiency of both the original MIP model and the reduced-size MIP models. We valida
    
[^14]: S.T.A.R.-Track：自适应时空外貌表示的端到端3D物体跟踪的潜在运动模型

    S.T.A.R.-Track: Latent Motion Models for End-to-End 3D Object Tracking with Adaptive Spatio-Temporal Appearance Representations. (arXiv:2306.17602v1 [cs.CV])

    [http://arxiv.org/abs/2306.17602](http://arxiv.org/abs/2306.17602)

    本文提出了S.T.A.R.-Track，一个采用物体为中心的Transformer框架，用于端到端3D物体跟踪。通过新颖的潜在运动模型和学习型跟踪嵌入，该框架能够准确建模物体的几何运动和变化，并在nuScenes数据集上取得了优秀的性能。

    

    本文基于跟踪-注意力模式，引入了一个以物体为中心的基于Transformer的3D跟踪框架。传统的基于模型的跟踪方法通过几何运动模型融合帧之间的物体和自运动的几何效应。受此启发，我们提出了S.T.A.R.-Track，使用一种新颖的潜在运动模型来调整对象查询，以在潜在空间中直接考虑视角和光照条件的变化，同时明确建模几何运动。结合一种新颖的可学习的跟踪嵌入，有助于建模轨迹的存在概率，这导致了一个通用的跟踪框架，可以与任何基于查询的检测器集成。在nuScenes基准测试上进行了大量实验，证明了我们方法的优势，展示了基于DETR3D的跟踪器的最先进性能，同时大大减少了轨迹的身份转换次数。

    Following the tracking-by-attention paradigm, this paper introduces an object-centric, transformer-based framework for tracking in 3D. Traditional model-based tracking approaches incorporate the geometric effect of object- and ego motion between frames with a geometric motion model. Inspired by this, we propose S.T.A.R.-Track, which uses a novel latent motion model (LMM) to additionally adjust object queries to account for changes in viewing direction and lighting conditions directly in the latent space, while still modeling the geometric motion explicitly. Combined with a novel learnable track embedding that aids in modeling the existence probability of tracks, this results in a generic tracking framework that can be integrated with any query-based detector. Extensive experiments on the nuScenes benchmark demonstrate the benefits of our approach, showing state-of-the-art performance for DETR3D-based trackers while drastically reducing the number of identity switches of tracks at the s
    
[^15]: 微型机器人群体导航以实现有针对性的药物输送的强化学习方法

    Navigation of micro-robot swarms for targeted delivery using reinforcement learning. (arXiv:2306.17598v1 [cs.RO])

    [http://arxiv.org/abs/2306.17598](http://arxiv.org/abs/2306.17598)

    通过强化学习算法控制微型机器人群体，实现了针对性的药物输送，具有很大的应用潜力。

    

    微型机器人在有针对性的药物输送中具有很大的潜力。然而，由于其微小的尺寸，单独控制每个机器人是困难的。因此，使用单一控制器控制多个机器人非常重要，而人工智能可以帮助我们成功完成这个任务。在本研究中，我们使用强化学习算法Proximal Policy Optimization (PPO)和Robust Policy Optimization (RPO)来控制一群微型游泳机器人，在受水动力学效应控制的情况下，将它们的方向朝向一个圆形吸收目标。我们考查了PPO和RPO在有限状态信息情景下的表现，并测试了它们在随机目标位置和大小的情况下的鲁棒性。我们使用课程学习来提高性能，并在学习控制一群25个游泳机器人并将它们导航到一个展示目标的实验中证明了这一点。

    Micro robotics is quickly emerging to be a promising technological solution to many medical treatments with focus on targeted drug delivery. They are effective when working in swarms whose individual control is mostly infeasible owing to their minute size. Controlling a number of robots with a single controller is thus important and artificial intelligence can help us perform this task successfully. In this work, we use the Reinforcement Learning (RL) algorithms Proximal Policy Optimization (PPO) and Robust Policy Optimization (RPO) to navigate a swarm of 4, 9 and 16 microswimmers under hydrodynamic effects, controlled by their orientation, towards a circular absorbing target. We look at both PPO and RPO performances with limited state information scenarios and also test their robustness for random target location and size. We use curriculum learning to improve upon the performance and demonstrate the same in learning to navigate a swarm of 25 swimmers and steering the swarm to exempli
    
[^16]: Razor SNN: 基于时间嵌入的高效脉冲神经网络

    Razor SNN: Efficient Spiking Neural Network with Temporal Embeddings. (arXiv:2306.17597v1 [cs.CV])

    [http://arxiv.org/abs/2306.17597](http://arxiv.org/abs/2306.17597)

    Razor SNN是一种基于时间嵌入的高效脉冲神经网络框架，能够从稀疏的事件流中提取时空特征，并实现了竞争性的性能表现。

    

    动态视觉传感器(DVS)生成的事件流在空间域中是稀疏和非均匀的，而在时间域中却是密集且冗余的。虽然脉冲神经网络(SNN)作为一种事件驱动的神经形态模型有潜力从事件流中提取时空特征，但目前仍不够有效和高效。基于以上原因，我们提出了一种称为Razor SNN的事件稀疏化脉冲框架，逐步修剪无意义的事件帧。具体地，我们扩展了基于全局时间嵌入的动态机制，重构特征，并在训练阶段自适应地强调事件的影响。在推理阶段，根据训练得到的时间嵌入生成的二进制掩码，层次化地消除无用的帧。全面的实验结果表明，我们的Razor SNN在四个基于事件的基准数据集上始终实现了具有竞争力的性能：DVS 128手势、N-Caltech 101、CIFAR10-DVS和...

    The event streams generated by dynamic vision sensors (DVS) are sparse and non-uniform in the spatial domain, while still dense and redundant in the temporal domain. Although spiking neural network (SNN), the event-driven neuromorphic model, has the potential to extract spatio-temporal features from the event streams, it is not effective and efficient. Based on the above, we propose an events sparsification spiking framework dubbed as Razor SNN, pruning pointless event frames progressively. Concretely, we extend the dynamic mechanism based on the global temporal embeddings, reconstruct the features, and emphasize the events effect adaptively at the training stage. During the inference stage, eliminate fruitless frames hierarchically according to a binary mask generated by the trained temporal embeddings. Comprehensive experiments demonstrate that our Razor SNN achieves competitive performance consistently on four events-based benchmarks: DVS 128 Gesture, N-Caltech 101, CIFAR10-DVS and 
    
[^17]: ChatGPT用于机器人技术：设计原则和模型能力

    ChatGPT for Robotics: Design Principles and Model Abilities. (arXiv:2306.17582v1 [cs.AI])

    [http://arxiv.org/abs/2306.17582](http://arxiv.org/abs/2306.17582)

    本文介绍了使用ChatGPT进行机器人应用的实验研究，通过设计原则和函数库的结合，ChatGPT能够适应不同的机器人任务，并展示了在各种机器人任务中的有效性和多样性。

    

    本文介绍了使用OpenAI的ChatGPT进行机器人应用的实验研究。我们概述了一种策略，将提示工程的设计原则与高级函数库的创建相结合，使ChatGPT能够适应不同的机器人任务、模拟器和形态。我们重点评估了不同的提示工程技术和对话策略对执行各种类型机器人任务的效果。我们探讨了ChatGPT使用自由形式对话、解析XML标记和合成代码的能力，以及使用任务特定提示函数和通过对话进行闭环推理的能力。我们的研究涵盖了机器人领域的一系列任务，从基本的逻辑、几何和数学推理到复杂的领域，如空中导航、操纵和具身代理。我们证明了ChatGPT在解决这些任务方面可以取得有效结果，同时使我们能够进行探索。

    This paper presents an experimental study regarding the use of OpenAI's ChatGPT for robotics applications. We outline a strategy that combines design principles for prompt engineering and the creation of a high-level function library which allows ChatGPT to adapt to different robotics tasks, simulators, and form factors. We focus our evaluations on the effectiveness of different prompt engineering techniques and dialog strategies towards the execution of various types of robotics tasks. We explore ChatGPT's ability to use free-form dialog, parse XML tags, and to synthesize code, in addition to the use of task-specific prompting functions and closed-loop reasoning through dialogues. Our study encompasses a range of tasks within the robotics domain, from basic logical, geometrical, and mathematical reasoning all the way to complex domains such as aerial navigation, manipulation, and embodied agents. We show that ChatGPT can be effective at solving several of such tasks, while allowing us
    
[^18]: 使用自然语言处理增强大学录取中的整体评估，以分析论文和推荐信

    Augmenting Holistic Review in University Admission using Natural Language Processing for Essays and Recommendation Letters. (arXiv:2306.17575v1 [cs.CL])

    [http://arxiv.org/abs/2306.17575](http://arxiv.org/abs/2306.17575)

    这项研究通过机器学习模型的实证评估发现，在大学录取过程中排除受保护属性会导致预测表现下降，而通过使用文本信息可以部分恢复模型的性能。

    

    在许多高度选择性的机构中，大学录取采用全面评估过程，考虑申请的所有方面，包括隐私属性（如种族、性别）、成绩、论文和推荐信，以组成一支优秀和多样化的班级。在本研究中，我们使用机器学习（ML）模型实证评估受保护属性对预测录取决策的影响，并探讨文本信息（如个人论文、教师推荐信）在模型中代替受保护属性的程度。通过使用2022-2023学年在一所具有选择性的美国本科入学办公室的14,915名申请人的数据，我们发现从ML模型中排除受保护属性会显著降低预测录取表现。通过TF-IDF表示和隐狄利克雷分配（LDA）模型，文本信息的包含部分恢复了模型的性能。

    University admission at many highly selective institutions uses a holistic review process, where all aspects of the application, including protected attributes (e.g., race, gender), grades, essays, and recommendation letters are considered, to compose an excellent and diverse class. In this study, we empirically evaluate how influential protected attributes are for predicting admission decisions using a machine learning (ML) model, and in how far textual information (e.g., personal essay, teacher recommendation) may substitute for the loss of protected attributes in the model. Using data from 14,915 applicants to an undergraduate admission office at a selective U.S. institution in the 2022-2023 cycle, we find that the exclusion of protected attributes from the ML model leads to substantially reduced admission-prediction performance. The inclusion of textual information via both a TF-IDF representation and a Latent Dirichlet allocation (LDA) model partially restores model performance, b
    
[^19]: 最可能的共同原因

    The most likely common cause. (arXiv:2306.17557v1 [physics.data-an])

    [http://arxiv.org/abs/2306.17557](http://arxiv.org/abs/2306.17557)

    对于因果不充分的情况下的共同原因问题，我们使用广义最大似然方法来识别共同原因C，与最大熵原则密切相关。对于两个二元对称变量的研究揭示了类似于二阶相变的条件概率非解析行为。

    

    对于两个随机变量A和B的共同原因原则在因果不充分的情况下进行了研究，当它们的共同原因C被认为已经存在，但只观测到了A和B的联合概率。因此，C不能被唯一确定（潜在混杂因子问题）。我们展示了广义最大似然方法可以应用于这种情况，并且允许识别与共同原因原则一致的C。它与最大熵原则密切相关。对两个二元对称变量的研究揭示了条件概率的非解析行为，类似于二阶相变。这发生在观察到的概率分布从相关到反相关的过渡期间。讨论了广义似然方法与其他方法（如预测似然和最小共同原因熵）之间的关系。

    The common cause principle for two random variables $A$ and $B$ is examined in the case of causal insufficiency, when their common cause $C$ is known to exist, but only the joint probability of $A$ and $B$ is observed. As a result, $C$ cannot be uniquely identified (the latent confounder problem). We show that the generalized maximum likelihood method can be applied to this situation and allows identification of $C$ that is consistent with the common cause principle. It closely relates to the maximum entropy principle. Investigation of the two binary symmetric variables reveals a non-analytic behavior of conditional probabilities reminiscent of a second-order phase transition. This occurs during the transition from correlation to anti-correlation in the observed probability distribution. The relation between the generalized likelihood approach and alternative methods, such as predictive likelihood and the minimum common cause entropy, is discussed. The consideration of the common cause
    
[^20]: TTSWING：一种用于乒乓球挥拍分析的数据集

    TTSWING: a Dataset for Table Tennis Swing Analysis. (arXiv:2306.17550v1 [cs.LG])

    [http://arxiv.org/abs/2306.17550](http://arxiv.org/abs/2306.17550)

    TTSWING是一种专为乒乓球挥拍分析设计的数据集，通过集成传感器获取详细信息并与运动员数据一起发布。对于乒乓球分析的创新研究具有巨大潜力，对科学界来说是宝贵的资源。

    

    我们介绍了TTSWING，这是一个专门用于乒乓球挥拍分析的新型数据集。该数据集通过集成到定制的球拍握把上的9轴传感器获取了详细的挥拍信息，并附带了运动员的匿名人口统计数据。我们详细介绍了数据收集和注释的过程。此外，我们还利用多种机器学习模型进行了初步的挥拍分析研究。TTSWING在促进乒乓球分析的创新研究方面具有巨大潜力，并且对科学界来说是一个宝贵的资源。我们在https://github.com/DEPhantom/TTSWING上发布了数据集和实验代码。

    We introduce TTSWING, a novel dataset designed for table tennis swing analysis. This dataset comprises comprehensive swing information obtained through 9-axis sensors integrated into custom-made racket grips, accompanied by anonymized demographic data of the players. We detail the data collection and annotation procedures. Furthermore, we conduct pilot studies utilizing diverse machine learning models for swing analysis. TTSWING holds tremendous potential to facilitate innovative research in table tennis analysis and is a valuable resource for the scientific community. We release the dataset and experimental codes at https://github.com/DEPhantom/TTSWING.
    
[^21]: 通过恶劣情况下的视觉场所识别改进动态车辆检测——迁移对象位置

    DisPlacing Objects: Improving Dynamic Vehicle Detection via Visual Place Recognition under Adverse Conditions. (arXiv:2306.17536v1 [cs.CV])

    [http://arxiv.org/abs/2306.17536](http://arxiv.org/abs/2306.17536)

    本研究通过利用先验地图来改进动态车辆检测，无需使用3D地图或像素级地图查询对应。通过视觉场所识别和二进制分类神经网络，我们成功优化了初始的候选物体检测，产生了更准确的检测结果。该方法在恶劣的天气和光照条件下表现出优异的性能。

    

    在恶劣的天气和光照条件下，知道自己所处的位置是否有助于感知周围的物体？本研究探讨了是否可以利用先验地图来帮助检测场景中的动态物体，而无需使用3D地图或像素级地图查询对应。我们提出了一种算法，通过先验地图优化初始的候选物体检测，并产生一个经过精确修正的子集。我们首先使用视觉场所识别（VPR）来为给定的查询图像检索参考地图图像，然后使用一个二进制分类神经网络比较查询和参考图像区域以验证查询检测。当我们的分类网络经过训练，在大约1000对查询-地图图像对上，与现有的现成车辆检测器结合起来，它能够提高车辆检测的性能。我们使用标准数据集演示了我们的方法。

    Can knowing where you are assist in perceiving objects in your surroundings, especially under adverse weather and lighting conditions? In this work we investigate whether a prior map can be leveraged to aid in the detection of dynamic objects in a scene without the need for a 3D map or pixel-level map-query correspondences. We contribute an algorithm which refines an initial set of candidate object detections and produces a refined subset of highly accurate detections using a prior map. We begin by using visual place recognition (VPR) to retrieve a reference map image for a given query image, then use a binary classification neural network that compares the query and mapping image regions to validate the query detection. Once our classification network is trained, on approximately 1000 query-map image pairs, it is able to improve the performance of vehicle detection when combined with an existing off-the-shelf vehicle detector. We demonstrate our approach using standard datasets across
    
[^22]: 锁定：利用动态车辆施加的运动约束改善视觉定位

    Locking On: Leveraging Dynamic Vehicle-Imposed Motion Constraints to Improve Visual Localization. (arXiv:2306.17529v1 [cs.RO])

    [http://arxiv.org/abs/2306.17529](http://arxiv.org/abs/2306.17529)

    该论文提出了一种利用动态车辆施加的运动约束来改善视觉定位的方法，通过在自动驾驶车辆的背景下使用动态车辆在定位流程中提供有限姿态约束信息，优化姿态估计并计算未来姿态估计质量，从而提高了定位的鲁棒性和准确性。

    

    大多数6自由度的定位和SLAM系统使用静态地标，但忽略动态物体，因为它们无法有用地纳入到典型的流程中。在已经纳入动态物体的情况下，典型的方法尝试着相对复杂地识别和定位这些物体，限制了它们的鲁棒性或通用性。在这项研究中，我们提出了一个折中的方法，在自动驾驶车辆的背景下进行演示，利用动态车辆在6自由度逐帧PnP-RANSAC定位流程中提供有限的姿态约束信息。我们通过运动模型对初始姿态估计进行优化，并提出了一种计算未来姿态估计质量的方法，根据自动驾驶车辆在环境中相对帧间位置的运动是否受到动态车辆的约束来触发。我们的方法检测和识别适合的动态车辆来定义这些姿态约束，以修改姿态。

    Most 6-DoF localization and SLAM systems use static landmarks but ignore dynamic objects because they cannot be usefully incorporated into a typical pipeline. Where dynamic objects have been incorporated, typical approaches have attempted relatively sophisticated identification and localization of these objects, limiting their robustness or general utility. In this research, we propose a middle ground, demonstrated in the context of autonomous vehicles, using dynamic vehicles to provide limited pose constraint information in a 6-DoF frame-by-frame PnP-RANSAC localization pipeline. We refine initial pose estimates with a motion model and propose a method for calculating the predicted quality of future pose estimates, triggered based on whether or not the autonomous vehicle's motion is constrained by the relative frame-to-frame location of dynamic vehicles in the environment. Our approach detects and identifies suitable dynamic vehicles to define these pose constraints to modify a pose f
    
[^23]: 在OASIS 2本体中表示过程和程序的行为主义方法

    A behaviouristic approach to representing processes and procedures in the OASIS 2 ontology. (arXiv:2306.17514v1 [cs.AI])

    [http://arxiv.org/abs/2306.17514](http://arxiv.org/abs/2306.17514)

    该论文提出了一种在OASIS 2本体中表示过程和程序的行为主义方法，该方法通过将代理和行为的能力与过程和程序的概念化相结合，旨在提供一个处理代理平台、过程和程序的基础OWL本体。

    

    当前对于有效表示过程和程序的基础本体不受广泛研究，从而限制了在需要考虑准确指示的实际情景中语义方法的实际采用。此外，表示应包括代理应如何执行与过程关联的操作，无论代理能否执行这些操作，以及可能发挥的角色和相关事件。OASIS本体提供了一个捕捉代理和其交互的成熟模型，但缺乏表示由代理执行的过程和程序的方法。这激发了本文中所提出的研究，其提供了OASIS 2本体的扩展，将表示代理和其行为的能力与过程和程序的完整概念化相结合。总体目标是提供一个处理代理平台、过程和程序的基础OWL本体。

    Foundational ontologies devoted to the effective representation of processes and procedures are not widely investigated at present, thereby limiting the practical adoption of semantic approaches in real scenarios where the precise instructions to follow must be considered. Also, the representation ought to include how agents should carry out the actions associated with the process, whether or not agents are able to perform those actions, the possible roles played as well as the related events.  The OASIS ontology provides an established model to capture agents and their interactions but lacks means for representing processes and procedures carried out by agents. This motivates the research presented in this article, which delivers an extension of the OASIS 2 ontology to combine the capabilities for representing agents and their behaviours with the full conceptualization of processes and procedures. The overarching goal is to deliver a foundational OWL ontology that deals with agent pla
    
[^24]: 稀疏扰动的锐化感知最小化优化器的系统研究

    Systematic Investigation of Sparse Perturbed Sharpness-Aware Minimization Optimizer. (arXiv:2306.17504v1 [cs.AI])

    [http://arxiv.org/abs/2306.17504](http://arxiv.org/abs/2306.17504)

    本论文系统研究了一种稀疏扰动的锐化感知最小化优化器（Sparse SAM），该优化器通过二进制掩码实现稀疏扰动，有效地平滑了深度神经网络的损失景观。

    

    深度神经网络由于复杂且非凸的损失景观而经常在泛化上表现不佳。锐化感知最小化（SAM）是一种流行的解决方案，通过最小化权重添加扰动时训练损失的最大化变化来平滑损失景观。然而，SAM对所有参数的不加区分的扰动是次优的，并且导致计算过多，两倍于常见优化器如随机梯度下降（SGD）的开销。在本文中，我们提出了一种高效和有效的训练方案Sparse SAM（SSAM），通过二进制掩码实现稀疏扰动。为了获得稀疏掩码，我们提供了基于Fisher信息和动态稀疏训练的两种解决方案。我们研究了不同掩码的影响，包括非结构化、结构化和N:M结构化模式，以及实现稀疏扰动的显式和隐式形式。我们在理论上证明了SSAM可以以相同的速度收敛。

    Deep neural networks often suffer from poor generalization due to complex and non-convex loss landscapes. Sharpness-Aware Minimization (SAM) is a popular solution that smooths the loss landscape by minimizing the maximized change of training loss when adding a perturbation to the weight. However, indiscriminate perturbation of SAM on all parameters is suboptimal and results in excessive computation, double the overhead of common optimizers like Stochastic Gradient Descent (SGD). In this paper, we propose Sparse SAM (SSAM), an efficient and effective training scheme that achieves sparse perturbation by a binary mask. To obtain the sparse mask, we provide two solutions based on Fisher information and dynamic sparse training, respectively. We investigate the impact of different masks, including unstructured, structured, and $N$:$M$ structured patterns, as well as explicit and implicit forms of implementing sparse perturbation. We theoretically prove that SSAM can converge at the same rate
    
[^25]: 语音声学背景和情感识别关系的经验解释

    Empirical Interpretation of the Relationship Between Speech Acoustic Context and Emotion Recognition. (arXiv:2306.17500v1 [cs.SD])

    [http://arxiv.org/abs/2306.17500](http://arxiv.org/abs/2306.17500)

    本研究通过使用基于注意力的方法，探讨了声学背景和音位边界对语音情感识别中局部标记的影响，并发现使用分布式方法进行语音情感理解的好处。

    

    语音情感识别（SER）对于获取情感智能和理解语音的语境含义至关重要。辅音-元音（CV）音位边界的变化可以通过语言线索丰富声学背景，从而影响SER。在实践中，语音情感被视为给定时间段内的一个声学片段的单个标签。然而，语音中的音位边界不是离散的事件，因此感知到的情感状态也应在潜在连续的时间窗口上分布。本研究使用基于注意力的方法探讨了声学背景和音位边界对SER中的局部标记的影响。通过交叉数据集分析实验的结果支持使用分布式方法进行语音情感理解的好处。实验中，将音位和词语映射到注意力向量以及基频，以观察重叠分布和因此的关系。

    Speech emotion recognition (SER) is vital for obtaining emotional intelligence and understanding the contextual meaning of speech. Variations of consonant-vowel (CV) phonemic boundaries can enrich acoustic context with linguistic cues, which impacts SER. In practice, speech emotions are treated as single labels over an acoustic segment for a given time duration. However, phone boundaries within speech are not discrete events, therefore the perceived emotion state should also be distributed over potentially continuous time-windows.  This research explores the implication of acoustic context and phone boundaries on local markers for SER using an attention-based approach. The benefits of using a distributed approach to speech emotion understanding are supported by the results of cross-corpora analysis experiments. Experiments where phones and words are mapped to the attention vectors along with the fundamental frequency to observe the overlapping distributions and thereby the relationship
    
[^26]: 人类对齐的偏好排序优化

    Preference Ranking Optimization for Human Alignment. (arXiv:2306.17492v1 [cs.CL])

    [http://arxiv.org/abs/2306.17492](http://arxiv.org/abs/2306.17492)

    本文提出了Preference Ranking Optimization (PRO)方法，通过扩展布拉德利-特里比较，采用偏好排序的方式来直接对齐大型语言模型（LLMs），解决了强化学习从人类反馈中学习的复杂性、不稳定性和对超参数的敏感性的问题。

    

    大型语言模型（LLMs）经常包含误导性内容，强调了将其与人类价值观对齐以确保安全的AI系统的必要性。采用从人类反馈中学习强化学习（RLHF）来实现这种对齐，通过将基于布拉德利-特里配对比较的奖励模型与Proximal Policy Optimization（PPO）等RL算法结合起来来优化LLM的响应。然而，RLHF表现出复杂性、不稳定性和对超参数的敏感性。在本文中，我们提出了Preference Ranking Optimization（PRO）作为PPO的另一种直接将LLM与布拉德利-特里比较对齐的方法。PRO将配对的布拉德利-特里比较扩展到适应任意长度的偏好排序。通过反复对比生成响应的可能性，PRO指导LLM优先考虑最佳响应，并逐渐对剩余的响应进行排序。通过这种方式，PRO将人类对齐有效地转化为概率对齐。

    Large language models (LLMs) often contain misleading content, emphasizing the need to align them with human values to ensure secur AI systems. Reinforcement learning from human feedback (RLHF) has been employed to achieve this alignment by combining a reward model, typically based on Bradley-Terry paired comparison, with an RL algorithm such as Proximal Policy Optimization (PPO) to optimize LLM responses. However, RLHF exhibits complexity, instability, and sensitivity to hyperparameters. In this paper, we propose Preference Ranking Optimization (PRO) as an alternative to PPO for directly aligning LLMs with the Bradley-Terry comparison. PRO extends the pairwise Bradley-Terry comparison to accommodate preference rankings of any length. By iteratively contrasting the likelihood of generating responses, PRO instructs the LLM to prioritize the best response while progressively ranking the remaining responses. In this manner, PRO effectively transforms human alignment into aligning the prob
    
[^27]: Graphtester： 在图数据集上探索GNNs的理论边界

    Graphtester: Exploring Theoretical Boundaries of GNNs on Graph Datasets. (arXiv:2306.17482v1 [cs.LG])

    [http://arxiv.org/abs/2306.17482](http://arxiv.org/abs/2306.17482)

    本文提出了一个名为Graphtester的新工具，用于探索图数据集上GNNs的理论边界。通过分析40多个不同的图数据集，我们确定了各种GNNs性能的上限，并展示了该工具对图变换器的适用性。最后，我们证明了Graphtester生成的特征可以用于实际应用。

    

    图神经网络（GNNs）已经成为学习图结构数据的强大工具。然而，即使是最先进的架构在可以区分的结构方面也有限制，限制了网络在不同数据集上的实现能力。在本文中，我们提供了一个名为Graphtester的新工具，用于对不同数据集、任务和得分的GNNs的理论能力进行全面分析。我们使用Graphtester分析了40多个不同的图数据集，根据层数确定了各种GNNs性能的上限。此外，我们还展示了该工具对使用位置节点编码的图变换器的适用性，从而扩大了其范围。最后，我们证明了Graphtester生成的特征可以用于实际应用，例如图变换器，并提供了一个用于基准测试节点和边特征（如位置编码）的合成数据集。该软件包可以免费获取。

    Graph Neural Networks (GNNs) have emerged as a powerful tool for learning from graph-structured data. However, even state-of-the-art architectures have limitations on what structures they can distinguish, imposing theoretical limits on what the networks can achieve on different datasets. In this paper, we provide a new tool called Graphtester for a comprehensive analysis of the theoretical capabilities of GNNs for various datasets, tasks, and scores. We use Graphtester to analyze over 40 different graph datasets, determining upper bounds on the performance of various GNNs based on the number of layers. Further, we show that the tool can also be used for Graph Transformers using positional node encodings, thereby expanding its scope. Finally, we demonstrate that features generated by Graphtester can be used for practical applications such as Graph Transformers, and provide a synthetic dataset to benchmark node and edge features, such as positional encodings. The package is freely availa
    
[^28]: 在课程设计中利用LLMs: 使用GPT-4支持学习目标的创作

    Harnessing LLMs in Curricular Design: Using GPT-4 to Support Authoring of Learning Objectives. (arXiv:2306.17459v1 [cs.AI])

    [http://arxiv.org/abs/2306.17459](http://arxiv.org/abs/2306.17459)

    本论文评估了使用GPT-4在人工智能课程中自动生成高质量学习目标的能力，强调了学习目标的重要性和撰写高质量目标的挑战性。

    

    我们评估了生成式预训练转换器（GPT-4）在实践导向的人工智能大学课程中自动生成高质量学习目标（LOs）的能力。对于教育中这一新兴技术的机会（例如内容生成，解释）和风险（例如作弊）的讨论日益加强，但到目前为止还没有一项研究评估模型在课程设计和LOs撰写方面的能力。LOs清晰表达了学习者通过参与课程所期望获得的知识和技能。为了有效，LOs必须专注于学生的预期成就，专注于特定的认知过程，并且可以衡量。因此，撰写高质量LOs是一项具有挑战性且耗时（即昂贵）的工作。我们对127个LOs进行了评估，这些LOs是基于精心设计的提示（关于高质量LOs撰写的详细指南）自动生成的。

    We evaluated the capability of a generative pre-trained transformer (GPT-4) to automatically generate high-quality learning objectives (LOs) in the context of a practically oriented university course on Artificial Intelligence. Discussions of opportunities (e.g., content generation, explanation) and risks (e.g., cheating) of this emerging technology in education have intensified, but to date there has not been a study of the models' capabilities in supporting the course design and authoring of LOs. LOs articulate the knowledge and skills learners are intended to acquire by engaging with a course. To be effective, LOs must focus on what students are intended to achieve, focus on specific cognitive processes, and be measurable. Thus, authoring high-quality LOs is a challenging and time consuming (i.e., expensive) effort. We evaluated 127 LOs that were automatically generated based on a carefully crafted prompt (detailed guidelines on high-quality LOs authoring) submitted to GPT-4 for con
    
[^29]: GMM：深入研究梯度感知和模型感知深度挖掘用于单目3D检测

    GMM: Delving into Gradient Aware and Model Perceive Depth Mining for Monocular 3D Detection. (arXiv:2306.17450v1 [cs.CV])

    [http://arxiv.org/abs/2306.17450](http://arxiv.org/abs/2306.17450)

    本论文提出了一种基于取样挖掘技术的简单而有效的深度感知挖掘策略，通过对深度预测质量的评估和挖掘，改进了单目3D检测中的深度感知，提高了深度预测的准确性。

    

    深度感知是单目3D检测任务中至关重要的组成部分，通常涉及到不适定问题。鉴于在2D物体检测中取样挖掘技术的成功，我们提出了一种简单而有效的挖掘策略，用于改进3D物体检测中的深度感知。具体来说，我们引入了一个简单的度量来评估深度预测的质量，选择挖掘样本用于模型。此外，我们提出了一种梯度感知和模型感知挖掘策略（GMM）用于深度学习，通过简单挖掘利用预测的深度质量来实现更好的深度学习。GMM是一种通用策略，可以方便地应用于多个最先进的单目3D检测器，从而提高深度预测的准确性。在nuScenes数据集上的大量实验表明，所提出的方法显著提高了3D物体检测的性能，同时在相当大程度上优于其他最先进的取样挖掘技术。

    Depth perception is a crucial component of monoc-ular 3D detection tasks that typically involve ill-posed problems. In light of the success of sample mining techniques in 2D object detection, we propose a simple yet effective mining strategy for improving depth perception in 3D object detection. Concretely, we introduce a plain metric to evaluate the quality of depth predictions, which chooses the mined sample for the model. Moreover, we propose a Gradient-aware and Model-perceive Mining strategy (GMM) for depth learning, which exploits the predicted depth quality for better depth learning through easy mining. GMM is a general strategy that can be readily applied to several state-of-the-art monocular 3D detectors, improving the accuracy of depth prediction. Extensive experiments on the nuScenes dataset demonstrate that the proposed methods significantly improve the performance of 3D object detection while outperforming other state-of-the-art sample mining techniques by a considerable m
    
[^30]: 复杂机器人系统的去中心化运动技能学习

    Decentralized Motor Skill Learning for Complex Robotic Systems. (arXiv:2306.17411v1 [cs.RO])

    [http://arxiv.org/abs/2306.17411](http://arxiv.org/abs/2306.17411)

    这项研究提出了一种去中心化运动技能（DEMOS）学习算法，通过分散控制电机组来提高机器人策略的鲁棒性和泛化能力，而不降低性能。

    

    强化学习在复杂机器人系统（例如四足动作）中取得了显著的成功。在以前的研究中，基于强化学习的控制器通常被实现为一个具有连接观察输入的单一神经网络。然而，所对应的学习策略高度依赖于特定任务。由于所有电机以集中的方式进行控制，超出分布范围的局部观察可以通过单一耦合的神经网络策略影响全局电机。相反，动物和人类可以分别控制他们的肢体。受到这一生物现象的启发，我们提出了一种名为分散式运动技能（DEMOS）学习算法，自动发现可以相互解耦的电机组，并学习一个去中心化的运动控制策略。我们的方法提高了策略的鲁棒性和泛化能力，同时不牺牲性能。对四足和人形机器人的实验表明，学习到的策略在性能上得到了改进。

    Reinforcement learning (RL) has achieved remarkable success in complex robotic systems (eg. quadruped locomotion). In previous works, the RL-based controller was typically implemented as a single neural network with concatenated observation input. However, the corresponding learned policy is highly task-specific. Since all motors are controlled in a centralized way, out-of-distribution local observations can impact global motors through the single coupled neural network policy. In contrast, animals and humans can control their limbs separately. Inspired by this biological phenomenon, we propose a Decentralized motor skill (DEMOS) learning algorithm to automatically discover motor groups that can be decoupled from each other while preserving essential connections and then learn a decentralized motor control policy. Our method improves the robustness and generalization of the policy without sacrificing performance. Experiments on quadruped and humanoid robots demonstrate that the learned
    
[^31]: LMBot: 将图形知识融入语言模型以进行无图形部署的推特机器人检测

    LMBot: Distilling Graph Knowledge into Language Model for Graph-less Deployment in Twitter Bot Detection. (arXiv:2306.17408v1 [cs.AI])

    [http://arxiv.org/abs/2306.17408](http://arxiv.org/abs/2306.17408)

    LMBot是一种新颖的推特机器人检测框架，将图神经网络的知识融入到语言模型中，实现了无图形部署，以解决数据依赖性的挑战。

    

    随着恶意行为者使用越来越先进和广泛的机器人来传播错误信息和操纵舆论，推特机器人的检测已成为一项至关重要的任务。尽管基于图形的推特机器人检测方法取得了最先进的性能，但我们发现它们的推理依赖于距离目标用户多跳的邻居用户，并且获取邻居用户是耗时的，并可能引入偏差。与此同时，我们发现在推特机器人检测上微调后，预训练的语言模型在竞争性性能方面取得了良好的表现，并且在部署过程中不需要图形结构。受到这一发现的启发，我们提出了一种新颖的机器人检测框架LMBot，它将图神经网络(GNNs)的知识融入语言模型(LMs)，以在推特机器人检测中进行无图形部署，以应对数据依赖性的挑战。此外，LMBot对基于图形和不使用图形的数据集兼容。具体而言，我们首先将每个用户表示为一段文本

    As malicious actors employ increasingly advanced and widespread bots to disseminate misinformation and manipulate public opinion, the detection of Twitter bots has become a crucial task. Though graph-based Twitter bot detection methods achieve state-of-the-art performance, we find that their inference depends on the neighbor users multi-hop away from the targets, and fetching neighbors is time-consuming and may introduce bias. At the same time, we find that after finetuning on Twitter bot detection, pretrained language models achieve competitive performance and do not require a graph structure during deployment. Inspired by this finding, we propose a novel bot detection framework LMBot that distills the knowledge of graph neural networks (GNNs) into language models (LMs) for graph-less deployment in Twitter bot detection to combat the challenge of data dependency. Moreover, LMBot is compatible with graph-based and graph-less datasets. Specifically, we first represent each user as a tex
    
[^32]: HVTSurv: 基于层次化视觉Transformer的全幻灯图像患者水平生存预测

    HVTSurv: Hierarchical Vision Transformer for Patient-Level Survival Prediction from Whole Slide Image. (arXiv:2306.17373v1 [cs.CV])

    [http://arxiv.org/abs/2306.17373](http://arxiv.org/abs/2306.17373)

    HVTSurv是一种基于层次化视觉Transformer的方法，用于从全幻灯图像预测患者的生存情况。其通过特征预处理和逐层编码的方式，能够捕捉到局部空间信息、增强上下文感知，建立患者级别的层次交互。

    

    基于全幻灯图像（WSIs）进行患者水平的生存预测是一项具有挑战性的任务，涉及到患者的大量数据（单个或多个千兆像素WSIs）和WSI的不规则形状特性，因此很难完全探索患者水平背包中的空间、上下文和层次交互。许多研究采用随机采样预处理策略和WSI级别的聚合模型，但不可避免地丢失了患者水平背包中的关键预后信息。在本文中，我们提出了一种名为HVTSurv的层次化视觉Transformer框架，可以编码局部级别的相对空间信息，增强WSI级别的上下文感知通信，并建立患者级别的层次交互。

    Survival prediction based on whole slide images (WSIs) is a challenging task for patient-level multiple instance learning (MIL). Due to the vast amount of data for a patient (one or multiple gigapixels WSIs) and the irregularly shaped property of WSI, it is difficult to fully explore spatial, contextual, and hierarchical interaction in the patient-level bag. Many studies adopt random sampling pre-processing strategy and WSI-level aggregation models, which inevitably lose critical prognostic information in the patient-level bag. In this work, we propose a hierarchical vision Transformer framework named HVTSurv, which can encode the local-level relative spatial information, strengthen WSI-level context-aware communication, and establish patient-level hierarchical interaction. Firstly, we design a feature pre-processing strategy, including feature rearrangement and random window masking. Then, we devise three layers to progressively obtain patient-level representation, including a local-l
    
[^33]: 差分隐私可能在除了保护隐私之外对一些群体智能算法产生潜在的优化效果

    Differential Privacy May Have a Potential Optimization Effect on Some Swarm Intelligence Algorithms besides Privacy-preserving. (arXiv:2306.17370v1 [cs.NE])

    [http://arxiv.org/abs/2306.17370](http://arxiv.org/abs/2306.17370)

    该论文首次尝试将差分隐私和群体智能算法结合，提出了一种通用的差分隐私群体智能算法框架（DPSIAF），通过该框架可以将现有的群体智能算法轻松改造为私有版本。实验结果表明，该私有算法的性能不严格受到隐私预算的影响。

    

    继隐私保护模型差分隐私（DP）近年来吸引了研究人员的极大关注后，目前机器学习与差分隐私的结合研究十分活跃。相比之下，另一种广泛使用的人工智能技术——群体智能算法，虽然也引发了隐私关切，但在差分隐私的背景下却鲜有研究关注。因此，本文首次尝试将差分隐私与群体智能结合，提出了一种通用的差分隐私群体智能算法框架（DPSIAF）。该框架基于指数机制，可以将现有的群体智能算法轻松发展为私有版本。作为示例，我们将提出的DPSIAF应用于四种常见的群体智能算法，并进行了相应的分析，证明了其有效性。更有趣的是，实验结果表明，对于我们的私有算法来说，其性能并不严格受到隐私预算的影响，

    Differential privacy (DP), as a promising privacy-preserving model, has attracted great interest from researchers in recent years. Currently, the study on combination of machine learning and DP is vibrant. In contrast, another widely used artificial intelligence technique, the swarm intelligence (SI) algorithm, has received little attention in the context of DP even though it also triggers privacy concerns. For this reason, this paper attempts to combine DP and SI for the first time, and proposes a general differentially private swarm intelligence algorithm framework (DPSIAF). Based on the exponential mechanism, this framework can easily develop existing SI algorithms into the private versions. As examples, we apply the proposed DPSIAF to four popular SI algorithms, and corresponding analyses demonstrate its effectiveness. More interestingly, the experimental results show that, for our private algorithms, their performance is not strictly affected by the privacy budget, and one of the 
    
[^34]: $\lambda$-AC：学习连续状态空间强化学习中的潜在决策感知模型

    $\lambda$-AC: Learning latent decision-aware models for reinforcement learning in continuous state-spaces. (arXiv:2306.17366v1 [cs.LG])

    [http://arxiv.org/abs/2306.17366](http://arxiv.org/abs/2306.17366)

    这项研究提出了一种$\lambda$-AC算法，通过学习连续状态空间中的潜在决策感知模型，实现了决策驱动的强化学习。通过理论和实证研究，确定了决策感知强化学习模型的必要组成部分，并展示了设计选择对算法性能的重要影响。

    

    决策感知模型学习的思想，在模型驱动的强化学习中变得越来越重要，即模型在决策制定时应该是准确的。尽管已经建立了一些有希望的理论结果，但是在连续控制问题中，利用决策感知损失的算法的实际性能仍然不足。本文研究了决策感知强化学习模型所需的必要组成部分，并展示了能够实现良好算法性能的设计选择。为此，我们对该领域的重要算法思想进行了理论和实证研究。我们强调，在MuZero系列工作中所建立的经验性设计决策对于相关算法的良好性能至关重要，并展示了在随机环境中，不同的价值感知算法实例之间行为差异。在这些见解的基础上，我们提出了潜在模型驱动决策的算法，称为$\lambda$-AC。

    The idea of decision-aware model learning, that models should be accurate where it matters for decision-making, has gained prominence in model-based reinforcement learning. While promising theoretical results have been established, the empirical performance of algorithms leveraging a decision-aware loss has been lacking, especially in continuous control problems. In this paper, we present a study on the necessary components for decision-aware reinforcement learning models and we showcase design choices that enable well-performing algorithms. To this end, we provide a theoretical and empirical investigation into prominent algorithmic ideas in the field. We highlight that empirical design decisions established in the MuZero line of works are vital to achieving good performance for related algorithms, and we showcase differences in behavior between different instantiations of value-aware algorithms in stochastic environments. Using these insights, we propose the Latent Model-Based Decisio
    
[^35]: iSCAN：识别非线性加性噪声模型中的因果机制转变

    iSCAN: Identifying Causal Mechanism Shifts among Nonlinear Additive Noise Models. (arXiv:2306.17361v1 [cs.LG])

    [http://arxiv.org/abs/2306.17361](http://arxiv.org/abs/2306.17361)

    本文提出了一种识别非线性加性噪声模型中因果机制转变的方法，该方法专注于在相关的结构因果模型中识别功能机制的变化，而不需要估计整个有向无环图(DAG)的结构。

    

    结构因果模型(SCM)被广泛应用于各个领域，以表示复杂系统中变量之间的因果关系。然而，真正的底层有向无环图(DAG)结构通常是未知的，并且从观测数据或干预数据中确定它仍然是一项具有挑战性的任务。然而，在许多情况下，目标是识别相关SCM之间的因果机制的变化(转变)而不是恢复整个底层DAG结构。例子包括分析健康和癌症患者之间的基因调控网络结构变化，或者在不同细胞环境下理解生物途径的变化。本文重点研究了在相同的变量集上识别两个或多个相关SCM中的$\textit{功能}$机制转变，而不需要估计每个SCM的整个DAG结构。在这种设置下，先前的工作假设使用了具有高斯噪声的线性模型；而本文中我们则考虑了非线性加性噪声模型。

    Structural causal models (SCMs) are widely used in various disciplines to represent causal relationships among variables in complex systems. Unfortunately, the true underlying directed acyclic graph (DAG) structure is often unknown, and determining it from observational or interventional data remains a challenging task. However, in many situations, the end goal is to identify changes (shifts) in causal mechanisms between related SCMs rather than recovering the entire underlying DAG structure. Examples include analyzing gene regulatory network structure changes between healthy and cancerous individuals or understanding variations in biological pathways under different cellular contexts. This paper focuses on identifying $\textit{functional}$ mechanism shifts in two or more related SCMs over the same set of variables -$\textit{without estimating the entire DAG structure of each SCM}$. Prior work under this setting assumed linear models with Gaussian noises; instead, in this work we ass
    
[^36]: 诊断不确定模型用于医疗风险预测

    Diagnosis Uncertain Models For Medical Risk Prediction. (arXiv:2306.17337v1 [cs.AI])

    [http://arxiv.org/abs/2306.17337](http://arxiv.org/abs/2306.17337)

    研究提出了一种具有诊断不确定性的医疗风险预测模型，解决了当相同的特征可以对应不同风险的诊断时风险低估的问题。

    

    我们考虑了一个患者风险模型，该模型可以获得患者的生命体征、实验室指标和先前病史等特征，但无法获得患者的诊断结果。例如，在入院时用于分诊的模型中就会遇到这种情况。我们展示了这种"全因素"风险模型在各种诊断中具有良好的泛化能力，但存在可预测的失败模式。当相同的实验室/生命体征/病史配置可以导致具有不同风险轮廓的诊断时（例如，E.coli与MRSA），风险估计是这两个轮廓的概率加权平均值。这导致对于罕见但高风险的诊断风险的低估。我们提出了解决此问题的方法，即通过明确地模拟由患者诊断不确定性引起的风险预测的不确定性。这为临床医生提供了一种可解释的方式来理解患者的风险，而不仅仅是一个风险数值。

    We consider a patient risk models which has access to patient features such as vital signs, lab values, and prior history but does not have access to a patient's diagnosis. For example, this occurs in a model deployed at intake time for triage purposes. We show that such `all-cause' risk models have good generalization across diagnoses but have a predictable failure mode. When the same lab/vital/history profiles can result from diagnoses with different risk profiles (e.g. E.coli vs. MRSA) the risk estimate is a probability weighted average of these two profiles. This leads to an under-estimation of risk for rare but highly risky diagnoses. We propose a fix for this problem by explicitly modeling the uncertainty in risk prediction coming from uncertainty in patient diagnoses. This gives practitioners an interpretable way to understand patient risk beyond a single risk number.
    
[^37]: 一种用于Rounded Capacity Inequalities的神经分割算法

    A Neural Separation Algorithm for the Rounded Capacity Inequalities. (arXiv:2306.17283v1 [cs.AI])

    [http://arxiv.org/abs/2306.17283](http://arxiv.org/abs/2306.17283)

    本论文提出了一种基于学习的分割启发式算法，使用图神经网络学习精确分割问题的解，通过嵌入切平面法找到了容量VRP的下限。

    

    切平面法是成功的分支定价法和分支切割法算法的关键技术，适用于各种车辆路径问题（VRPs）的确切最优解。在各种切割中，圆角容量不等式（RCIs）是最基本的。生成RCIs需要解决分割问题，其精确解需要较长的时间获取，因此广泛使用启发式方法。我们设计了一种基于学习的带有图粗化的分割启发式算法，该算法使用图神经网络（GNN）学习精确分割问题的解，经过50到100个客户的小实例训练。我们将分割算法嵌入切平面法中，以找到容量VRP（CVRP）的下限，其中包括高达1,000个客户。我们将我们的方法与CVRPSEP进行了性能比较，CVRPSEP是用于解决VRP中各种切割问题的流行分割软件包。我们的计算结果表明，我们的方法的性能优于CVRPSEP。

    The cutting plane method is a key technique for successful branch-and-cut and branch-price-and-cut algorithms that find the exact optimal solutions for various vehicle routing problems (VRPs). Among various cuts, the rounded capacity inequalities (RCIs) are the most fundamental. To generate RCIs, we need to solve the separation problem, whose exact solution takes a long time to obtain; therefore, heuristic methods are widely used. We design a learning-based separation heuristic algorithm with graph coarsening that learns the solutions of the exact separation problem with a graph neural network (GNN), which is trained with small instances of 50 to 100 customers. We embed our separation algorithm within the cutting plane method to find a lower bound for the capacitated VRP (CVRP) with up to 1,000 customers. We compare the performance of our approach with CVRPSEP, a popular separation software package for various cuts used in solving VRPs. Our computational results show that our approach 
    
[^38]: 使用大型语言模型建模并行程序

    Modeling Parallel Programs using Large Language Models. (arXiv:2306.17281v1 [cs.DC])

    [http://arxiv.org/abs/2306.17281](http://arxiv.org/abs/2306.17281)

    本文展示了如何利用大型语言模型（LLMs）在高性能计算和科学代码的开发和分析中自动化更复杂的任务。

    

    随着我们进入异构计算时代，高性能计算（HPC）中的并行软件代码在复杂性和规模上不断增长。新兴的硬件和编程范式使得开发、优化和维护并行软件对开发人员来说变得繁重。缓解这些负担的一种方式是使用自动化开发和分析工具。这些工具可以为开发人员执行复杂和/或补救性的任务，提高他们的生产力并减少错误的可能性。迄今为止，用于代码开发和性能分析的这些工具在执行任务的复杂度方面受到限制。然而，随着语言建模的最新进展和现在在线上可用的大量与代码相关的数据，这些工具开始利用预测性语言模型来自动完成更复杂的任务。在本文中，我们展示了如何将大型语言模型（LLMs）应用于高性能和科学代码的特定任务中。我们训练了LLM模型

    Parallel software codes in high performance computing (HPC) continue to grow in complexity and scale as we enter the exascale era. A diverse set of emerging hardware and programming paradigms make developing, optimizing, and maintaining parallel software burdensome for developers. One way to alleviate some of these burdens is with automated development and analysis tools. Such tools can perform complex and/or remedial tasks for developers that increase their productivity and decrease the chance for error. So far, such tools for code development and performance analysis have been limited in the complexity of tasks they can perform. However, with recent advancements in language modeling, and the wealth of code related data that is now available online, these tools have started to utilize predictive language models to automate more complex tasks. In this paper, we show how large language models (LLMs) can be applied to tasks specific to high performance and scientific codes. We train LLMs
    
[^39]: 安全关键强化学习的概率约束

    Probabilistic Constraint for Safety-Critical Reinforcement Learning. (arXiv:2306.17279v1 [cs.LG])

    [http://arxiv.org/abs/2306.17279](http://arxiv.org/abs/2306.17279)

    本文研究了概率约束下的安全关键强化学习问题，提出了具有明确梯度表达式的Safe Policy Gradient-REINFORCE（SPG-REINFORCE）算法，并通过理论界限证明了概率约束设置在最优性和安全性之间具有更好的权衡。

    

    本文考虑了概率约束强化学习中学习安全策略的问题。具体来说，安全策略或控制器是指以高概率保持代理在给定安全集合中的轨迹。我们在现有文献中频繁探索的累积约束问题和这种概率约束问题之间建立了联系。我们提供了理论界限，阐明概率约束设置在最优性和安全性（约束满足）方面具有更好的权衡。在处理概率约束时遇到的挑战，正如我们在这项工作中所探索的那样，源于没有明确的梯度表达式。我们之前的工作提供了这种明确的梯度表达式，称之为Safe Policy Gradient-REINFORCE（SPG-REINFORCE）。在这项工作中，我们提供了一个改进的梯度SPG-Actor-Critic

    In this paper, we consider the problem of learning safe policies for probabilistic-constrained reinforcement learning (RL). Specifically, a safe policy or controller is one that, with high probability, maintains the trajectory of the agent in a given safe set. We establish a connection between this probabilistic-constrained setting and the cumulative-constrained formulation that is frequently explored in the existing literature. We provide theoretical bounds elucidating that the probabilistic-constrained setting offers a better trade-off in terms of optimality and safety (constraint satisfaction). The challenge encountered when dealing with the probabilistic constraints, as explored in this work, arises from the absence of explicit expressions for their gradients. Our prior work provides such an explicit gradient expression for probabilistic constraints which we term Safe Policy Gradient-REINFORCE (SPG-REINFORCE). In this work, we provide an improved gradient SPG-Actor-Critic that lead
    
[^40]: 遭受苦难的烤面包机

    Suffering Toasters. (arXiv:2306.17258v1 [cs.AI])

    [http://arxiv.org/abs/2306.17258](http://arxiv.org/abs/2306.17258)

    本文旨在为人工智能、自我意识和代理问题提供更清晰的定义，我们提出了一种新的启发式方法来测试人工自我意识，并讨论了这种方法引发的一些问题。

    

    在人工智能（AI）领域，智能的广泛接受的定义仍然难以找到。由于我们对AI范式、架构和工具的快速发展，人们普遍认为自然产生的AI意识比以往更有可能。在本文中，我们声称所有当前的智能测试都不足以指出存在或缺乏象人类直觉感知的智能。我们借鉴科学哲学、心理学和其他领域的思想，提供了对人工智能、自我意识和代理问题的更清晰定义。我们进一步提出了一种测试人工自我意识的新启发式方法，并概述了可能的实现。最后，我们讨论了这种新启发式方法引发的一些问题，无论是哲学问题还是实现问题。

    A widely accepted definition of intelligence in the context of Artificial Intelligence (AI) still eludes us. Due to our exceedingly rapid development of AI paradigms, architectures, and tools, the prospect of naturally arising AI consciousness seems more likely than ever. In this paper, we claim that all current intelligence tests are insufficient to point to the existence or lack of intelligence \textbf{as humans intuitively perceive it}. We draw from ideas in the philosophy of science, psychology, and other areas of research to provide a clearer definition of the problems of artificial intelligence, self-awareness, and agency. We furthermore propose a new heuristic approach to test for artificial self-awareness and outline a possible implementation. Finally, we discuss some of the questions that arise from this new heuristic, be they philosophical or implementation-oriented.
    
[^41]: 使用多源迁移学习预测COVID-19患者的急诊室再访

    Prediction of COVID-19 Patients' Emergency Room Revisit using Multi-Source Transfer Learning. (arXiv:2306.17257v1 [cs.LG])

    [http://arxiv.org/abs/2306.17257](http://arxiv.org/abs/2306.17257)

    本研究利用迁移学习和自然语言处理技术，预测COVID-19患者出院后在急诊室的再访情况，早期识别有助于医生专注于危及生命的病例。

    

    2019冠状病毒病（COVID-19）导致了一场全球范围内的严重大流行。除了具有高传染性外，COVID-19的临床进展可以有很大差异，从无症状携带者到严重且潜在危及生命的健康并发症。许多患者在出院后的短时间内需要再次就诊急诊室（ER），这极大增加了医务人员的工作负担。及早识别此类患者对于帮助医生专注于治疗危及生命的病例至关重要。在本研究中，我们获取了2020年3月至2021年1月期间匹兹堡大学医学中心13个附属急诊室的3,210个患者就诊电子健康记录（EHR）。我们利用自然语言处理技术ScispaCy提取临床概念，并使用出现最频繁的1001个概念为COVID-19患者在急诊室中建立了7天再访模型。我们从13个急诊室收集的研究数据可能具有

    The coronavirus disease 2019 (COVID-19) has led to a global pandemic of significant severity. In addition to its high level of contagiousness, COVID-19 can have a heterogeneous clinical course, ranging from asymptomatic carriers to severe and potentially life-threatening health complications. Many patients have to revisit the emergency room (ER) within a short time after discharge, which significantly increases the workload for medical staff. Early identification of such patients is crucial for helping physicians focus on treating life-threatening cases. In this study, we obtained Electronic Health Records (EHRs) of 3,210 encounters from 13 affiliated ERs within the University of Pittsburgh Medical Center between March 2020 and January 2021. We leveraged a Natural Language Processing technique, ScispaCy, to extract clinical concepts and used the 1001 most frequent concepts to develop 7-day revisit models for COVID-19 patients in ERs. The research data we collected from 13 ERs may have 
    
[^42]: 以提示为基础的个性化冷启动推荐的研究

    Towards Personalized Cold-Start Recommendation with Prompts. (arXiv:2306.17256v1 [cs.IR])

    [http://arxiv.org/abs/2306.17256](http://arxiv.org/abs/2306.17256)

    本研究旨在解决个性化冷启动推荐问题，通过利用预训练语言模型的能力，将推荐过程转化为自然语言情感分析，提供适用于创业企业和用户参与历史不足的平台的个性化推荐。

    

    推荐系统在根据用户过去的行为帮助用户发现与其兴趣相符的信息方面发挥着关键作用。然而，当用户和物品之间的历史交互记录不可用时，开发个性化推荐系统变得具有挑战性，这就是所谓的系统冷启动推荐问题。此问题在创业企业或用户参与历史不足的平台中尤为突出。以往的研究集中在用户或物品的冷启动场景，其中系统仍然通过在同一领域中的历史用户和物品交互进行训练来为新用户或物品提供推荐，而无法解决我们的问题。为了弥合这一鸿沟，我们的研究引入了一种创新且有效的方法，利用预训练语言模型的能力。我们将推荐过程转化为自然语言情感分析，其中包含用户资料和物品属性的信息。

    Recommender systems play a crucial role in helping users discover information that aligns with their interests based on their past behaviors. However, developing personalized recommendation systems becomes challenging when historical records of user-item interactions are unavailable, leading to what is known as the system cold-start recommendation problem. This issue is particularly prominent in start-up businesses or platforms with insufficient user engagement history. Previous studies focus on user or item cold-start scenarios, where systems could make recommendations for new users or items but are still trained with historical user-item interactions in the same domain, which cannot solve our problem. To bridge the gap, our research introduces an innovative and effective approach, capitalizing on the capabilities of pre-trained language models. We transform the recommendation process into sentiment analysis of natural languages containing information of user profiles and item attribu
    
[^43]: 一个用于简单算术问题中系统化泛化的混合系统

    A Hybrid System for Systematic Generalization in Simple Arithmetic Problems. (arXiv:2306.17249v1 [cs.NE])

    [http://arxiv.org/abs/2306.17249](http://arxiv.org/abs/2306.17249)

    本研究提出了一个混合系统，可以解决需要组合性和系统性推理的算术问题。该系统通过学习适当的替换规则来获得能力，在只训练最简单情况的情况下，可以准确地解决嵌套算术表达式，优于其他模型。

    

    解决需要组合性和系统性的符号推理问题被认为是人类智能的关键因素之一。然而，符号推理对于深度学习模型仍然是一个巨大的挑战，它们往往无法将推理模式推广到超出分布范围的测试案例。在这项工作中，我们提出了一个混合系统，能够解决需要对符号序列进行组合和系统推理的算术问题。该模型通过学习适当的替换规则来获得这种技能，这些规则被迭代地应用于输入字符串，直到表达式完全解析。我们展示了该系统能够准确地解决嵌套算术表达式，即使仅在包括最简单情况的子集上进行训练，其性能也显著优于端到端训练的序列到序列模型和最先进的大型语言模型。

    Solving symbolic reasoning problems that require compositionality and systematicity is considered one of the key ingredients of human intelligence. However, symbolic reasoning is still a great challenge for deep learning models, which often cannot generalize the reasoning pattern to out-of-distribution test cases. In this work, we propose a hybrid system capable of solving arithmetic problems that require compositional and systematic reasoning over sequences of symbols. The model acquires such a skill by learning appropriate substitution rules, which are applied iteratively to the input string until the expression is completely resolved. We show that the proposed system can accurately solve nested arithmetical expressions even when trained only on a subset including the simplest cases, significantly outperforming both a sequence-to-sequence model trained end-to-end and a state-of-the-art large language model.
    
[^44]: 一个用于监测和检测物联网设备入侵的智能机制

    An Intelligent Mechanism for Monitoring and Detecting Intrusions in IoT Devices. (arXiv:2306.17187v1 [cs.DC])

    [http://arxiv.org/abs/2306.17187](http://arxiv.org/abs/2306.17187)

    本研究提出了一种基于主机的入侵检测系统，利用联邦学习和多层感知机神经网络来提高对物联网设备上网络攻击的准确性，并增强数据隐私保护。

    

    当前物联网设备的数量及其限制已经成为恶意实体利用这些设备并将其用于自己获利的动机。为了防止物联网设备的网络攻击，可以将机器学习技术应用于入侵检测系统。此外，与集中式方法相关的隐私问题可以通过联邦学习得到缓解。本研究提出了一种基于主机的入侵检测系统，利用联邦学习和多层感知机神经网络来高准确度地检测物联网设备上的网络攻击，并增强数据隐私保护。

    The current amount of IoT devices and their limitations has come to serve as a motivation for malicious entities to take advantage of such devices and use them for their own gain. To protect against cyberattacks in IoT devices, Machine Learning techniques can be applied to Intrusion Detection Systems. Moreover, privacy related issues associated with centralized approaches can be mitigated through Federated Learning. This work proposes a Host-based Intrusion Detection Systems that leverages Federated Learning and Multi-Layer Perceptron neural networks to detected cyberattacks on IoT devices with high accuracy and enhancing data privacy protection.
    
[^45]: 基于区块链的联邦学习用于分布式能源管理系统

    Blockchain-based Federated Learning for Decentralized Energy Management Systems. (arXiv:2306.17186v1 [cs.DC])

    [http://arxiv.org/abs/2306.17186](http://arxiv.org/abs/2306.17186)

    本论文对区块链、智能合约和联邦学习在能源互联网中的应用进行了全面分析和分类，提出了四种典型的系统模型，并讨论了它们的关键方面。

    

    能源互联网是一种利用智能网络和分布式系统技术实现分散能源系统的分布式模式。相对于传统的集中式能源系统，分布式能源互联网系统涵盖了多个组件和通信要求，需要创新技术实现去中心化、可靠性、高效性和安全性。区块链架构、智能合约和分布式联邦学习技术的最新进展为实现分布式能源互联网服务提供了新的机遇。本文对当前最先进的应用区块链、智能合约和联邦学习于能源互联网领域的解决方案进行了全面分析和分类。具体来说，我们确定了四种典型的系统模型并讨论了它们的关键方面。这些模型展示了区块链、智能合约和联邦学习在能源互联网中的多样化应用方式。

    The Internet of Energy (IoE) is a distributed paradigm that leverages smart networks and distributed system technologies to enable decentralized energy systems. In contrast to the traditional centralized energy systems, distributed Energy Internet systems comprise multiple components and communication requirements that demand innovative technologies for decentralization, reliability, efficiency, and security. Recent advances in blockchain architectures, smart contracts, and distributed federated learning technologies have opened up new opportunities for realizing decentralized Energy Internet services. In this paper, we present a comprehensive analysis and classification of state-of-the-art solutions that employ blockchain, smart contracts, and federated learning for the IoE domains. Specifically, we identify four representative system models and discuss their key aspects. These models demonstrate the diverse ways in which blockchain, smart contracts, and federated learning can be inte
    
[^46]: 替换和报告：NLP辅助的放射学报告生成

    Replace and Report: NLP Assisted Radiology Report Generation. (arXiv:2306.17180v1 [cs.CL])

    [http://arxiv.org/abs/2306.17180](http://arxiv.org/abs/2306.17180)

    本研究提出了一种模板化的方法，利用NLP技术辅助生成放射学报告。该方法通过使用图像分类器生成图像标签，然后通过基于变压器的模型生成病理描述，并使用BERT模型替换正常报告模板中的相应部分，最终生成完整的放射学报告。

    

    临床实践经常使用医学成像来进行诊断和治疗。自动生成放射学报告的一个重要挑战是，放射学报告是由多个句子组成的长篇叙述，包括异常和正常的发现。因此，将传统的图像标题生成方法应用于生成整个报告是不足够的，因为这些方法是设计用于简要描述图像的短句子。我们提出了一种基于模板的方法，从放射图像中生成放射学报告。我们的方法包括以下步骤：i）使用多标签图像分类器，为输入的放射图生成标签；ii）使用基于变压器的模型，根据步骤（i）中生成的标签生成病理描述（放射图像上的异常发现的描述）；iii）使用基于BERT的多标签文本分类器，找到正常报告模板中要替换为生成的病理描述的部分；iv）使用基于规则的模型来生成最终的放射学报告。

    Clinical practice frequently uses medical imaging for diagnosis and treatment. A significant challenge for automatic radiology report generation is that the radiology reports are long narratives consisting of multiple sentences for both abnormal and normal findings. Therefore, applying conventional image captioning approaches to generate the whole report proves to be insufficient, as these are designed to briefly describe images with short sentences. We propose a template-based approach to generate radiology reports from radiographs. Our approach involves the following: i) using a multilabel image classifier, produce the tags for the input radiograph; ii) using a transformer-based model, generate pathological descriptions (a description of abnormal findings seen on radiographs) from the tags generated in step (i); iii) using a BERT-based multi-label text classifier, find the spans in the normal report template to replace with the generated pathological descriptions; and iv) using a rul
    
[^47]: 高频市场做市的整合滴策略和周期信号

    Integrating Tick-level Data and Periodical Signal for High-frequency Market Making. (arXiv:2306.17179v1 [q-fin.TR])

    [http://arxiv.org/abs/2306.17179](http://arxiv.org/abs/2306.17179)

    该论文提出了一种融合滴级数据和周期预测信号的深度强化学习方法，用于开发更准确、更稳健的高频市场做市策略。实验证明，该方法在盈利能力和风险管理方面优于现有方法。

    

    我们关注高频交易中的市场做市问题。市场做市是金融市场中提供流动性的关键功能，涉及通过买卖资产提供流动性。然而，金融市场的日益复杂化和滴级交易所产生的大量数据使得开发有效的市场做市策略具有挑战性。为了应对这一挑战，我们提出了一种深度强化学习方法，将滴级数据与周期预测信号融合，以开发更准确、更稳健的市场做市策略。我们基于不同的深度强化学习算法在模拟场景和加密货币市场的真实数据实验中得到的市场做市策略的结果表明，所提出的框架在盈利能力和风险管理方面优于现有方法。

    We focus on the problem of market making in high-frequency trading. Market making is a critical function in financial markets that involves providing liquidity by buying and selling assets. However, the increasing complexity of financial markets and the high volume of data generated by tick-level trading makes it challenging to develop effective market making strategies. To address this challenge, we propose a deep reinforcement learning approach that fuses tick-level data with periodic prediction signals to develop a more accurate and robust market making strategy. Our results of market making strategies based on different deep reinforcement learning algorithms under the simulation scenarios and real data experiments in the cryptocurrency markets show that the proposed framework outperforms existing methods in terms of profitability and risk management.
    
[^48]: 新闻验证者的对决：ChatGPT 3.5、ChatGPT 4.0、Bing AI和Bard在新闻事实检查中的比较性能评估

    News Verifiers Showdown: A Comparative Performance Evaluation of ChatGPT 3.5, ChatGPT 4.0, Bing AI, and Bard in News Fact-Checking. (arXiv:2306.17176v1 [cs.CL])

    [http://arxiv.org/abs/2306.17176](http://arxiv.org/abs/2306.17176)

    本研究通过对比实验评估了ChatGPT 3.5、ChatGPT 4.0、Bing AI和Bard在新闻事实检查中的表现，结果显示它们的熟练程度普遍居中，其中OpenAI的GPT-4.0在区分真相和欺骗方面具有一定优势。

    

    本研究旨在评估知名大型语言模型（LLMs），包括OpenAI的ChatGPT 3.5和4.0、谷歌的Bard（LaMDA）和微软的Bing AI，在使用黑盒测试区分新闻真实性方面的熟练程度。总共提供了100条经过事实核查的新闻，所有新闻均来自独立的事实核查机构，在受控条件下向每个LLMs提供。它们的回答被归类为三类：真实、错误和部分真实/错误。基于独立机构提供的核实事实，评估了LLMs的分类准确性来衡量其有效性。结果显示，所有模型的熟练程度都属于中等水平，平均得分为65.25/100。在这些模型中，OpenAI的GPT-4.0以71分的得分脱颖而出，表明较新的LLMs在区分真相和欺骗方面具有优势。然而，与人类事实核查员的表现相比，尽管AI模型表现出一定的熟练度，但仍有改进空间。

    This study aimed to evaluate the proficiency of prominent Large Language Models (LLMs), namely OpenAI's ChatGPT 3.5 and 4.0, Google's Bard(LaMDA), and Microsoft's Bing AI in discerning the truthfulness of news items using black box testing. A total of 100 fact-checked news items, all sourced from independent fact-checking agencies, were presented to each of these LLMs under controlled conditions. Their responses were classified into one of three categories: True, False, and Partially True/False. The effectiveness of the LLMs was gauged based on the accuracy of their classifications against the verified facts provided by the independent agencies. The results showed a moderate proficiency across all models, with an average score of 65.25 out of 100. Among the models, OpenAI's GPT-4.0 stood out with a score of 71, suggesting an edge in newer LLMs' abilities to differentiate fact from deception. However, when juxtaposed against the performance of human fact-checkers, the AI models, despite
    
[^49]: 从原始的GP笔记中挖掘知识图谱，用于远程COVID-19初级保健评估

    RECAP-KG: Mining Knowledge Graphs from Raw GP Notes for Remote COVID-19 Assessment in Primary Care. (arXiv:2306.17175v1 [cs.CL])

    [http://arxiv.org/abs/2306.17175](http://arxiv.org/abs/2306.17175)

    本研究提出了一个从原始GP笔记中提取信息并构建知识图谱的框架，用于解决临床决策过程中现有技术无法处理的问题。

    

    临床决策是向患者提供适当护理的基本阶段。近年来，为了帮助临床医生在这个过程中做出决策，已经开发了几个决策系统。然而，目前使用的技术解决方案基于简单的回归模型，只能考虑简单的预定义多选特征，如患者年龄、既往病史、吸烟者状况等。决策系统当前无法处理的一个特定患者数据来源是患者会诊的GP笔记的收集。这些笔记包含了临床医生用来做出最终决策并将患者引导到适当护理的关键体征和症状。从GP笔记中提取信息是一个技术上具有挑战性的问题，因为它们往往包含缩写、打字错误和不完整的句子。本文解决了这个公开挑战。我们提出了一个框架，可以执行从原始GP笔记中提取出关键信息，并构建知识图谱的任务。

    Clinical decision-making is a fundamental stage in delivering appropriate care to patients. In recent years several decision-making systems designed to aid the clinician in this process have been developed. However, technical solutions currently in use are based on simple regression models and are only able to take into account simple pre-defined multiple-choice features, such as patient age, pre-existing conditions, smoker status, etc. One particular source of patient data, that available decision-making systems are incapable of processing is the collection of patient consultation GP notes. These contain crucial signs and symptoms - the information used by clinicians in order to make a final decision and direct the patient to the appropriate care. Extracting information from GP notes is a technically challenging problem, as they tend to include abbreviations, typos, and incomplete sentences.  This paper addresses this open challenge. We present a framework that performs knowledge grap
    
[^50]: 在在线领域中强化离线学习的方法：增强自然语言生成算法的能力

    Empowering NLG: Offline Reinforcement Learning for Informal Summarization in Online Domains. (arXiv:2306.17174v1 [cs.CL])

    [http://arxiv.org/abs/2306.17174](http://arxiv.org/abs/2306.17174)

    该论文介绍了一种离线强化学习的自然语言生成方法，用于在在线领域生成非正式摘要，并通过該方法在用户体验和负载减轻方面取得了显著改进。

    

    我们的研究引入了一种创新的自然语言生成（NLG）方法，旨在优化用户体验并减轻人工客服代理的工作负担。我们的主要目标是使用离线强化学习技术为在线文章和帖子生成非正式摘要。在我们的研究中，我们将我们提出的方法与现有的文本生成方法进行了比较，并全面介绍了我们的架构设计，包括爬虫、强化学习和文本生成模块。通过提出这种原创方法，我们的论文为NLG领域作出了有价值的贡献，为在线内容生成自然语言摘要提供了新的视角。通过实施“增强NLG”，我们能够在在线领域生成更高质量的回复。实验结果显示，平均“喜欢”评分显著提高，从0.09954378增加到0.5000152。

    Our research introduces an innovative Natural Language Generation (NLG) approach that aims to optimize user experience and alleviate the workload of human customer support agents. Our primary objective is to generate informal summaries for online articles and posts using an offline reinforcement learning technique. In our study, we compare our proposed method with existing approaches to text generation and provide a comprehensive overview of our architectural design, which incorporates crawling, reinforcement learning, and text generation modules. By presenting this original approach, our paper makes a valuable contribution to the field of NLG by offering a fresh perspective on generating natural language summaries for online content. Through the implementation of Empowering NLG, we are able to generate higher-quality replies in the online domain. The experimental results demonstrate a significant improvement in the average "like" score, increasing from 0.09954378 to 0.5000152. This ad
    
[^51]: 边缘云计算下规模化生成型人工智能的综述

    An Overview on Generative AI at Scale with Edge-Cloud Computing. (arXiv:2306.17170v1 [cs.DC])

    [http://arxiv.org/abs/2306.17170](http://arxiv.org/abs/2306.17170)

    边缘云计算下规模化生成型人工智能的发展和挑战进行了综述，讨论了利用边缘云计算范式构建GenAI系统的吸引力。

    

    作为人工智能的一个特定类别，生成型人工智能（GenAI）生成类似于人类创造的新内容。GenAI系统的快速发展已经在互联网上产生了大量的新数据，给当前的计算和通信框架带来了新的挑战。目前，由于需要大量的计算资源，GenAI服务依赖于传统的云计算框架。然而，由于数据传输和大量请求，这种服务将遇到高延迟的问题。另一方面，通过边缘和云之间的协同，边缘云计算可以提供足够的计算能力和低延迟。因此，在边缘云计算范式的支持下构建规模化的GenAI系统具有吸引力。在本综述论文中，我们分别回顾了GenAI和边缘云计算的最新发展。然后，我们使用两个示例性的GenAI应用来讨论技术挑战和未来研究方向。

    As a specific category of artificial intelligence (AI), generative artificial intelligence (GenAI) generates new content that resembles what is created by humans. The rapid development of GenAI systems has created a huge amount of new data on the Internet, posing new challenges to current computing and communication frameworks. Currently, GenAI services rely on the traditional cloud computing framework due to the need for large computation resources. However, such services will encounter high latency because of data transmission and a high volume of requests. On the other hand, edge-cloud computing can provide adequate computation power and low latency at the same time through the collaboration between edges and the cloud. Thus, it is attractive to build GenAI systems at scale by leveraging the edge-cloud computing paradigm. In this overview paper, we review recent developments in GenAI and edge-cloud computing, respectively. Then, we use two exemplary GenAI applications to discuss tec
    
[^52]: 基于Mondrian Conformal预测器的企业磁盘驱动刷新

    Enterprise Disk Drive Scrubbing Based on Mondrian Conformal Predictors. (arXiv:2306.17169v1 [cs.DC])

    [http://arxiv.org/abs/2306.17169](http://arxiv.org/abs/2306.17169)

    提出了一种基于Mondrian Conformal预测器的企业磁盘驱动刷新方法，通过使用机器学习模型识别需要刷新的磁盘，并提前预测其健康状态，从而提高整体可靠性和功率效率。

    

    磁盘刷新是一种通过从磁盘读取数据来解决读错误的过程。然而，一次性刷新整个存储数组可能会对系统性能产生不利影响，尤其是在高输入/输出操作期间。此外，刷新时连续从磁盘读取数据可能会导致磁盘的磨损，特别是对于更大容量的磁盘，因为这涉及到显著的时间和能量消耗。为了解决这些问题，我们提出了一种选择性磁盘刷新方法，提高数据中心的整体可靠性和功率效率。我们的方法基于Mondrian Conformal预测模型，通过预测存储池中每个磁盘的健康状态，提前n天进行预测，并使用开源数据集来识别需要刷新的特定磁盘。对于预测为不健康的磁盘，我们标记它们进行替换，无需进一步操作。对于健康的驱动器，我们创建一个集合和数量评估的指标

    Disk scrubbing is a process aimed at resolving read errors on disks by reading data from the disk. However, scrubbing the entire storage array at once can adversely impact system performance, particularly during periods of high input/output operations. Additionally, the continuous reading of data from disks when scrubbing can result in wear and tear, especially on larger capacity disks, due to the significant time and energy consumption involved. To address these issues, we propose a selective disk scrubbing method that enhances the overall reliability and power efficiency in data centers. Our method employs a Machine Learning model based on Mondrian Conformal prediction to identify specific disks for scrubbing, by proactively predicting the health status of each disk in the storage pool, forecasting n-days in advance, and using an open-source dataset. For disks predicted as non-healthy, we mark them for replacement without further action. For healthy drives, we create a set and quanti
    
[^53]: 编程教育的生成AI：比较ChatGPT、GPT-4和人类导师的表现

    Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors. (arXiv:2306.17156v1 [cs.CY])

    [http://arxiv.org/abs/2306.17156](http://arxiv.org/abs/2306.17156)

    该论文系统评估了ChatGPT、GPT-4和人类导师在不同的编程教育场景中的表现，并发现GPT-4优于ChatGPT，接近于人类导师。

    

    生成AI和大型语言模型在提高计算机教育方面具有很大的潜力，通过为初级编程提供下一代教育技术。最近的研究已经研究了这些模型在与编程教育相关的不同场景中的应用；然而，这些研究由于多种原因而受限，因为它们通常考虑的是已经过时的模型或仅仅特定的场景。因此，缺乏一个系统的研究来对最先进的模型进行全面的编程教育场景基准测试。在我们的工作中，我们系统地评估了两个模型，ChatGPT（基于GPT-3.5）和GPT-4，并将其在各种场景下与人类导师的表现进行了比较。我们使用五个初级Python编程问题和来自在线平台的真实错误程序进行评估，并使用专家评注来评估性能。我们的结果表明，GPT-4明显优于ChatGPT（基于GPT-3.5），并且接近于人类导师。

    Generative AI and large language models hold great promise in enhancing computing education by powering next-generation educational technologies for introductory programming. Recent works have studied these models for different scenarios relevant to programming education; however, these works are limited for several reasons, as they typically consider already outdated models or only specific scenario(s). Consequently, there is a lack of a systematic study that benchmarks state-of-the-art models for a comprehensive set of programming education scenarios. In our work, we systematically evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human tutors for a variety of scenarios. We evaluate using five introductory Python programming problems and real-world buggy programs from an online platform, and assess performance using expert-based annotations. Our results show that GPT-4 drastically outperforms ChatGPT (based on GPT-3.5) and comes close to hu
    
[^54]: 利用Hugging Face Transformers预测社交网络中的精神健康障碍的力量

    Harnessing the Power of Hugging Face Transformers for Predicting Mental Health Disorders in Social Networks. (arXiv:2306.16891v1 [cs.IR])

    [http://arxiv.org/abs/2306.16891](http://arxiv.org/abs/2306.16891)

    该研究通过使用社交媒体和预训练的语言模型，探索了使用用户生成的数据预测精神障碍症状的方法，并发现新模型的准确度高达97%。这表明社交媒体数据是进行精神健康筛查的一个重要资源，预训练模型能够有效地自动化这一任务。

    

    早期诊断精神障碍并进行干预可以促进预防严重伤害和改善治疗效果。本研究利用社交媒体和预训练的语言模型，探讨用户生成的数据如何用于预测精神障碍症状。我们的研究比较了Hugging Face的四种不同BERT模型和近期文献中用于自动抑郁症诊断的标准机器学习技术。结果显示，新模型的准确率高达97%，超过了以前的方法。通过补充先前的发现，对结果进行分析，我们发现即使是微小的数据量（如用户的个人简介描述）也有预测精神障碍的潜力。我们得出结论，社交媒体数据是进行精神健康筛查的一个极好的来源，并且预训练模型可以有效自动化这一关键任务。

    Early diagnosis of mental disorders and intervention can facilitate the prevention of severe injuries and the improvement of treatment results. Using social media and pre-trained language models, this study explores how user-generated data can be used to predict mental disorder symptoms. Our study compares four different BERT models of Hugging Face with standard machine learning techniques used in automatic depression diagnosis in recent literature. The results show that new models outperform the previous approach with an accuracy rate of up to 97%. Analyzing the results while complementing past findings, we find that even tiny amounts of data (like users' bio descriptions) have the potential to predict mental disorders. We conclude that social media data is an excellent source of mental health screening, and pre-trained models can effectively automate this critical task.
    
[^55]: 弹性约束下的元学习器用于联邦学习

    Elastically-Constrained Meta-Learner for Federated Learning. (arXiv:2306.16703v1 [cs.LG])

    [http://arxiv.org/abs/2306.16703](http://arxiv.org/abs/2306.16703)

    这项研究提出了一种弹性约束的元学习方法，用于解决联邦学习中由于非独立同分布数据导致元学习的不稳定目标的收敛问题。

    

    联邦学习是一种协作训练机器学习模型的方法，用于多个参与方之间禁止数据共享。在联邦学习中的一个挑战是客户端之间的非独立同分布数据，因为单个模型无法适应所有客户端的数据分布。为了解决这个问题，介绍了元学习（如Per-FedAvg）。元学习学习适用于所有客户端的共享初始参数。每个客户端使用梯度下降法将初始化快速调整到本地数据分布，实现模型个性化。然而，由于非凸损失函数和采样更新的随机性，元学习方法在本地适应同一客户端时具有不稳定的目标。这种不同适应方向的波动阻碍了元学习的收敛。为了克服这个挑战，我们使用了历史本地调整的模型来限制内循环的方向，并提出了一种弹性约束方法。

    Federated learning is an approach to collaboratively training machine learning models for multiple parties that prohibit data sharing. One of the challenges in federated learning is non-IID data between clients, as a single model can not fit the data distribution for all clients. Meta-learning, such as Per-FedAvg, is introduced to cope with the challenge. Meta-learning learns shared initial parameters for all clients. Each client employs gradient descent to adapt the initialization to local data distributions quickly to realize model personalization. However, due to non-convex loss function and randomness of sampling update, meta-learning approaches have unstable goals in local adaptation for the same client. This fluctuation in different adaptation directions hinders the convergence in meta-learning. To overcome this challenge, we use the historical local adapted model to restrict the direction of the inner loop and propose an elastic-constrained method. As a result, the current round
    
[^56]: DUET: 2D结构化且近似等变表示

    DUET: 2D Structured and Approximately Equivariant Representations. (arXiv:2306.16058v1 [cs.LG])

    [http://arxiv.org/abs/2306.16058](http://arxiv.org/abs/2306.16058)

    DUET是一种2D结构化且近似等变表示方法，相比于其他方法，可以在保留输入变换信息的同时具有更好的可控性和更高的准确性。

    

    多视图自监督学习(MSSL)基于学习相对于一组输入变换的不变性。然而，不变性从表示中部分或完全移除与变换相关的信息，这可能对需要这些信息的特定下游任务的性能造成损害。我们提出了2D结构化和等变表示，称为DUET，它们是以矩阵结构组织的2D表示，并且对作用于输入数据的变换具有等变性。DUET表示保留有关输入变换的信息，同时保持语义表达能力。与SimCLR（Chen等，2020）（无结构和不变性）和ESSL（Dangovski等，2022）（无结构和等变性）相比，DUET表示的结构化和等变性使得生成具有更低的重建误差的可控性成为可能，而SimCLR或ESSL则无法实现可控性。DUET还实现了更高的准确性。

    Multiview Self-Supervised Learning (MSSL) is based on learning invariances with respect to a set of input transformations. However, invariance partially or totally removes transformation-related information from the representations, which might harm performance for specific downstream tasks that require such information. We propose 2D strUctured and EquivarianT representations (coined DUET), which are 2d representations organized in a matrix structure, and equivariant with respect to transformations acting on the input data. DUET representations maintain information about an input transformation, while remaining semantically expressive. Compared to SimCLR (Chen et al., 2020) (unstructured and invariant) and ESSL (Dangovski et al., 2022) (unstructured and equivariant), the structured and equivariant nature of DUET representations enables controlled generation with lower reconstruction error, while controllability is not possible with SimCLR or ESSL. DUET also achieves higher accuracy fo
    
[^57]: 利用范畴论整合到冲突解决中的图模型的分类方法

    Categorical Approach to Conflict Resolution: Integrating Category Theory into the Graph Model for Conflict Resolution. (arXiv:2306.13961v1 [cs.AI])

    [http://arxiv.org/abs/2306.13961](http://arxiv.org/abs/2306.13961)

    本论文介绍了一种新型的冲突解决框架，称为C-GMCR，它将范畴论整合到传统的图模型中，能够提供更抽象和通用的分析冲突解决的方式。通过应用到囚徒困境和其他案例中，发现分类方法提供了新的视角和可能导致更有效的冲突解决策略的发展。

    

    本文介绍了冲突解决中的范畴图模型（C-GMCR），这是一种将范畴论整合到传统的图模型中的新型框架。C-GMCR框架提供了更抽象和通用的方式来建模和分析冲突解决，使研究人员能够发现更深层次的见解和联系。本文介绍了C-GMCR框架的基本概念、方法和应用到著名的囚徒困境和其他代表性案例中。结果表明，分类方法为稳定概念提供了新的视角，并有可能导致更有效的冲突解决策略的发展。

    This paper introduces the Categorical Graph Model for Conflict Resolution (C-GMCR), a novel framework that integrates category theory into the traditional Graph Model for Conflict Resolution (GMCR). The C-GMCR framework provides a more abstract and general way to model and analyze conflict resolution, enabling researchers to uncover deeper insights and connections. We present the basic concepts, methods, and application of the C-GMCR framework to the well-known Prisoner's Dilemma and other representative cases. The findings suggest that the categorical approach offers new perspectives on stability concepts and can potentially lead to the development of more effective conflict resolution strategies.
    
[^58]: 布局和任务感知的零样本文档图像问答指导模型

    Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering. (arXiv:2306.00526v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.00526](http://arxiv.org/abs/2306.00526)

    该论文提出了一种布局和任务感知的指导提示模型，称为LATIN-Prompt，通过将文档图像问答对齐到现成的指导调优语言基础模型，利用其零样本能力来提高效果。该模型包括布局感知的文档内容和任务感知的描述，能够恢复文本片段之间的布局信息，并生成符合任务需求的答案。

    

    基于布局感知多模态预训练模型的预训练-微调范式在文档图像问答方面取得了显著进展。然而，领域预训练和任务微调对于额外的视觉、布局和任务模块阻止了其直接利用现成的指导调优语言基础模型，而这些模型最近在零样本学习方面显示出了良好的潜力。与将语言模型与文档图像问答领域对齐相反，我们将文档图像问答与现成的指导调优语言基础模型对齐，利用其零样本能力。具体而言，我们提出了布局和任务感知的指导提示模型，称为LATIN-Prompt，它包括布局感知的文档内容和任务感知的描述。前者通过适当的空格和换行符从OCR工具中恢复文本片段之间的布局信息。后者确保模型生成符合任务需求的答案。

    The pre-training-fine-tuning paradigm based on layout-aware multimodal pre-trained models has achieved significant progress on document image question answering. However, domain pre-training and task fine-tuning for additional visual, layout, and task modules prevent them from directly utilizing off-the-shelf instruction-tuning language foundation models, which have recently shown promising potential in zero-shot learning. Contrary to aligning language models to the domain of document image question answering, we align document image question answering to off-the-shell instruction-tuning language foundation models to utilize their zero-shot capability. Specifically, we propose layout and task aware instruction prompt called LATIN-Prompt, which consists of layout-aware document content and task-aware descriptions. The former recovers the layout information among text segments from OCR tools by appropriate spaces and line breaks. The latter ensures that the model generates answers that m
    
[^59]: 自然语言解释的真实性测试

    Faithfulness Tests for Natural Language Explanations. (arXiv:2305.18029v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18029](http://arxiv.org/abs/2305.18029)

    该论文研究了评估自然语言解释真实性的问题，并提出了两个测试方法：反事实输入编辑器和重建输入测试。这些测试对于评估新兴的NLE模型，对开发真实的NLEs具有重要意义。

    

    神经模型的解释旨在揭示模型预测的决策过程。然而，最近的研究表明，诸如显著性地图或反事实解释等当前的解释方法可能会误导，因为它们容易呈现与模型内部机制不一致的原因。本研究探讨了评估自然语言解释（NLEs）真实性的挑战性问题。为此，我们提出了两个测试。首先，我们提出了一种反事实输入编辑器，用于插入导致反事实预测但不被NLEs反映的原因。其次，我们根据生成的NLEs中所述的原因重建输入，并检查它们导致相同预测的频率。我们的测试可以评估新兴的NLE模型，为开发真实的NLEs提供了基本工具。

    Explanations of neural models aim to reveal a model's decision-making process for its predictions. However, recent work shows that current methods giving explanations such as saliency maps or counterfactuals can be misleading, as they are prone to present reasons that are unfaithful to the model's inner workings. This work explores the challenging question of evaluating the faithfulness of natural language explanations (NLEs). To this end, we present two tests. First, we propose a counterfactual input editor for inserting reasons that lead to counterfactual predictions but are not reflected by the NLEs. Second, we reconstruct inputs from the reasons stated in the generated NLEs and check how often they lead to the same predictions. Our tests can evaluate emerging NLE models, proving a fundamental tool in the development of faithful NLEs.
    
[^60]: 自主驾驶中的sim2real和数字孪生：综述

    Sim2real and Digital Twins in Autonomous Driving: A Survey. (arXiv:2305.01263v1 [cs.RO])

    [http://arxiv.org/abs/2305.01263](http://arxiv.org/abs/2305.01263)

    本文综述了自主驾驶中的sim2real和数字孪生方法，它们分别解决了从模拟到现实的知识转移和从真实世界数据中学习以提高仿真精度的问题，但也存在各自的优缺点和限制。

    

    安全和成本是自主驾驶技术开发的两个重要问题。从学术研究到商业应用，都需要充分的模拟和真实世界测试。通常会在模拟环境中进行大规模的测试，然后将学习到的驾驶知识转移到真实世界，因此如何将在模拟中学习到的驾驶知识适应现实成为一个关键问题。然而，虚拟仿真世界与现实世界在许多方面（如照明、纹理、车辆动力学和代理行为等）存在差异，这使得弥合虚拟和真实世界之间的差距变得困难。这个差距通常被称为现实差距（RG）。近年来，研究人员探索了各种方法来解决现实差距问题，这些方法可以广泛地分为两类：从模拟到现实的知识转移（sim2real）和从真实世界数据中学习以提高仿真精度（数字孪生）。本文综述了自主驾驶中的sim2real和数字孪生方法，审查了当前的技术和应用，以及它们的优点和局限性。

    Safety and cost are two important concerns for the development of autonomous driving technologies. From the academic research to commercial applications of autonomous driving vehicles, sufficient simulation and real world testing are required. In general, a large scale of testing in simulation environment is conducted and then the learned driving knowledge is transferred to the real world, so how to adapt driving knowledge learned in simulation to reality becomes a critical issue. However, the virtual simulation world differs from the real world in many aspects such as lighting, textures, vehicle dynamics, and agents' behaviors, etc., which makes it difficult to bridge the gap between the virtual and real worlds. This gap is commonly referred to as the reality gap (RG). In recent years, researchers have explored various approaches to address the reality gap issue, which can be broadly classified into two categories: transferring knowledge from simulation to reality (sim2real) and learn
    
[^61]: 提高LLM答案准确度的联邦提示和链式推理

    Federated Prompting and Chain-of-Thought Reasoning for Improving LLMs Answering. (arXiv:2304.13911v1 [cs.AI])

    [http://arxiv.org/abs/2304.13911](http://arxiv.org/abs/2304.13911)

    本论文提出一种名为Fed-SP-SC和Fed-DP-CoT的技术，通过联邦提示和链式推理改进分布式同义问题的准确性，从而提高基于云的大型语言模型（LLMs）回答常见问题的精度，并进行了充分实验验证。

    

    本文研究如何使用基于云的大型语言模型（LLMs）增强分布式用户提出的常见问题的回答精度。我们的研究侧重于典型情况，即用户询问涉及相同的数学推理步骤和问题解决过程的相似查询。由于LLMs独立问题的零-shot提示的准确性不尽如人意，我们提出了使用自洽性（SC）和链式思考（CoT）技术来改进分布式同义问题的方法。具体而言，我们首先从众包数据库中检索同义问题，并创建一个联邦问题池。我们称这些具有相同或不同参数的联邦同义问题为SP问题或DP问题，分别。我们将我们的方法称为Fed-SP-SC和Fed-DP-CoT，它们可以为所有用户查询生成更准确的答案，而不需要复杂的模型调整。通过大量实验证明

    We investigate how to enhance answer precision in frequently asked questions posed by distributed users using cloud-based Large Language Models (LLMs). Our study focuses on a typical situations where users ask similar queries that involve identical mathematical reasoning steps and problem-solving procedures. Due to the unsatisfactory accuracy of LLMs' zero-shot prompting with standalone questions, we propose to improve the distributed synonymous questions using Self-Consistency (SC) and Chain-of-Thought (CoT) techniques. Specifically, we first retrieve synonymous questions from a crowd-sourced database and create a federated question pool. We call these federated synonymous questions with the same or different parameters SP-questions or DP-questions, respectively. We refer to our methods as Fed-SP-SC and Fed-DP-CoT, which can generate significantly more accurate answers for all user queries without requiring sophisticated model-tuning. Through extensive experiments, we demonstrate that
    
[^62]: 自动化ATM现金补充流程的多目标物流优化

    Multiobjective Logistics Optimization for Automated ATM Cash Replenishment Process. (arXiv:2304.13671v1 [math.OC])

    [http://arxiv.org/abs/2304.13671](http://arxiv.org/abs/2304.13671)

    本文研究了自动化ATM现金补充流程，提出了一个数学模型并给出了一个工具来评估各种不同的情况。在模拟数据集上，该模型与方法可以削减ATM现金运营成本。

    

    在数字化转型的时代，将数字技术整合到银行运营的各个方面可以改善流程自动化、成本效益和服务水平提升。虽然ATM现金物流是影响运营成本和消费者满意度的重要任务，但却很少有努力来加以改进。特别是在越南，拥有超过2万台ATM的市场上，解决这个问题的研究和技术解决方案仍然较少。在本文中，我们将ATM现金补充的车辆路径问题进行了概括，提出了一个数学模型，然后提供了一个工具来评估各种不同的情况。在模拟数据集上进行评估时，我们提出的模型和方法产生了令人鼓舞的结果，可以削减ATM现金运营成本。

    In the digital transformation era, integrating digital technology into every aspect of banking operations improves process automation, cost efficiency, and service level improvement. Although logistics for ATM cash is a crucial task that impacts operating costs and consumer satisfaction, there has been little effort to enhance it. Specifically, in Vietnam, with a market of more than 20,000 ATMs nationally, research and technological solutions that can resolve this issue remain scarce. In this paper, we generalized the vehicle routing problem for ATM cash replenishment, suggested a mathematical model and then offered a tool to evaluate various situations. When being evaluated on the simulated dataset, our proposed model and method produced encouraging results with the benefits of cutting ATM cash operating costs.
    
[^63]: GRIL：一种二参数持久性基于向量化的机器学习方法

    GRIL: A $2$-parameter Persistence Based Vectorization for Machine Learning. (arXiv:2304.04970v1 [cs.LG])

    [http://arxiv.org/abs/2304.04970](http://arxiv.org/abs/2304.04970)

    本文提出一种名为GRIL的方法，用于将拓扑特征表示散度到机器学习模型中，该方法可以稳定地用于不同的过滤函数。

    

    一参数持久性同Topology Data Analysis (TDA)相关，可研究数据中隐藏着的连通分量和循环等拓扑特征。已应用于提高图神经网络（GNNs）等深度学习模型的表示能力。为了丰富拓扑特征的表示，本研究提出了研究双过滤函数诱导的二参数持久性模块的方法。为了将这些表示信息加入到机器学习模型中，我们引入了一个新的向量表示称为Generalized Rank Invariant Landscape \textsc{Gril}，并将其证明为在Lipschitz稳定条件下可微分，并且通过对基础过滤函数的编码可以容易地融入到机器学习模型中。我们提出了一个高效计算向量表示的算法。本研究还对我们的方法进行了测试。

    $1$-parameter persistent homology, a cornerstone in Topological Data Analysis (TDA), studies the evolution of topological features such as connected components and cycles hidden in data. It has been applied to enhance the representation power of deep learning models, such as Graph Neural Networks (GNNs). To enrich the representations of topological features, here we propose to study $2$-parameter persistence modules induced by bi-filtration functions. In order to incorporate these representations into machine learning models, we introduce a novel vector representation called Generalized Rank Invariant Landscape \textsc{Gril} for $2$-parameter persistence modules. We show that this vector representation is $1$-Lipschitz stable and differentiable with respect to underlying filtration functions and can be easily integrated into machine learning models to augment encoding topological features. We present an algorithm to compute the vector representation efficiently. We also test our method
    
[^64]: 基于Fisher信息的证据深度学习方法用于不确定性估计

    Uncertainty Estimation by Fisher Information-based Evidential Deep Learning. (arXiv:2303.02045v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.02045](http://arxiv.org/abs/2303.02045)

    本文提出了一种基于Fisher信息的证据深度学习方法，用于解决高数据不确定性样本但注释为one-hot标签的情况下证据学习过程被过度惩罚并受到阻碍的问题。

    This paper proposes a Fisher Information-based Evidential Deep Learning method to address the problem of over-penalization and hindrance in evidence learning for high data uncertainty samples annotated with one-hot labels.

    不确定性估计是使深度学习在实际应用中可靠的关键因素。最近提出的证据神经网络通过将网络输出视为证据来参数化狄利克雷分布，明确考虑不同的不确定性，并在不确定性估计方面取得了令人印象深刻的性能。然而，对于高数据不确定性样本但注释为one-hot标签的情况，这些错误标记的类别的证据学习过程会被过度惩罚并受到阻碍。为了解决这个问题，我们提出了一种新的方法，基于Fisher信息的证据深度学习（$\mathcal{I}$-EDL）。特别地，我们引入Fisher信息矩阵（FIM）来衡量每个样本所携带的证据的信息量，根据这个信息量，我们可以动态地重新加权目标损失项，使网络更加专注于不确定类别的表示学习。我们的网络的泛化能力通过优化进一步提高。

    Uncertainty estimation is a key factor that makes deep learning reliable in practical applications. Recently proposed evidential neural networks explicitly account for different uncertainties by treating the network's outputs as evidence to parameterize the Dirichlet distribution, and achieve impressive performance in uncertainty estimation. However, for high data uncertainty samples but annotated with the one-hot label, the evidence-learning process for those mislabeled classes is over-penalized and remains hindered. To address this problem, we propose a novel method, Fisher Information-based Evidential Deep Learning ($\mathcal{I}$-EDL). In particular, we introduce Fisher Information Matrix (FIM) to measure the informativeness of evidence carried by each sample, according to which we can dynamically reweight the objective loss terms to make the network more focused on the representation learning of uncertain classes. The generalization ability of our network is further improved by opt
    
[^65]: 将 QMLTP 问题翻译成高阶逻辑并解决的方法研究

    Solving QMLTP Problems by Translation to Higher-order Logic. (arXiv:2212.09570v2 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2212.09570](http://arxiv.org/abs/2212.09570)

    本文研究了将 QMLTP 问题翻译成高阶逻辑并解决的方法，发现嵌入过程可靠且成功，后端 ATP 系统的选择会显著影响嵌入方法的性能，本地模态逻辑 ATP 系统优于嵌入方法。

    

    本文描述了对自动定理证明 (ATP) 系统在从 QMLTP 一阶模态逻辑问题库中取出的问题上的评估。主要是将问题使用嵌入方法翻译为 TPTP 语言中的高阶逻辑，并使用高阶逻辑 ATP 系统进行求解。此外，还考虑了来自本地模态逻辑 ATP 系统的结果，并与嵌入方法的结果进行了比较。研究发现，嵌入过程可靠且成功，后端 ATP 系统的选择会显著影响嵌入方法的性能，本地模态逻辑 ATP 系统优于嵌入方法，而嵌入方法可以处理比所考虑的本地模态系统更广泛的模态逻辑问题。

    This paper describes an evaluation of Automated Theorem Proving (ATP) systems on problems taken from the QMLTP library of first-order modal logic problems. Principally, the problems are translated to higher-order logic in the TPTP language using an embedding approach, and solved using higher-order logic ATP systems. Additionally, the results from native modal logic ATP systems are considered, and compared with those from the embedding approach. The findings are that the embedding process is reliable and successful, the choice of backend ATP system can significantly impact the performance of the embedding approach, native modal logic ATP systems outperform the embedding approach, and the embedding approach can cope with a wider range modal logics than the native modal systems considered.
    
[^66]: GEC: 一种在MDP、POMDP和更多情况下交互式决策的统一框架

    GEC: A Unified Framework for Interactive Decision Making in MDP, POMDP, and Beyond. (arXiv:2211.01962v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.01962](http://arxiv.org/abs/2211.01962)

    本研究在交互式决策的框架下，提出了一种新的复杂度度量GEC，用于样本高效强化学习。该方法能够捕捉到探索和开发之间的权衡，将RL问题划分为低GEC和高GEC两个类别，并展示了低GEC类别的丰富性质。

    

    我们研究了在交互式决策的普遍框架下的样本高效强化学习（RL），该框架包括马尔可夫决策过程（MDP）、部分可观测马尔可夫决策过程（POMDP）和预测状态表示（PSR）作为特殊情况。为了找到赋予样本高效学习的最小假设，我们提出了一种新的复杂度度量，广义eluder系数（GEC），它表征了在线交互式决策中探索和开发之间的基本权衡。具体而言，GEC通过比较预测更新策略性能的误差与基于历史数据评估的样本内训练误差，来衡量探索的难度。我们展示了低GEC的RL问题形成了一个非常丰富的类别，其中包括低Bellman eluder维度问题、双线性类、低证人秩问题、PO-双线性类和广义正则PSR等。

    We study sample efficient reinforcement learning (RL) under the general framework of interactive decision making, which includes Markov decision process (MDP), partially observable Markov decision process (POMDP), and predictive state representation (PSR) as special cases. Toward finding the minimum assumption that empowers sample efficient learning, we propose a novel complexity measure, generalized eluder coefficient (GEC), which characterizes the fundamental tradeoff between exploration and exploitation in online interactive decision making. In specific, GEC captures the hardness of exploration by comparing the error of predicting the performance of the updated policy with the in-sample training error evaluated on the historical data. We show that RL problems with low GEC form a remarkably rich class, which subsumes low Bellman eluder dimension problems, bilinear class, low witness rank problems, PO-bilinear class, and generalized regular PSR, where generalized regular PSR, a new tr
    
[^67]: MAGIC: 通过反转准鲁棒分类器实现基于掩码的图像合成

    MAGIC: Mask-Guided Image Synthesis by Inverting a Quasi-Robust Classifier. (arXiv:2209.11549v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.11549](http://arxiv.org/abs/2209.11549)

    本论文提出了一种名为MAGIC的方法，通过反转准鲁棒分类器进行一次性掩码引导的图像合成。它通过聚合梯度并利用强空间先验的指导二进制掩码，实现了形状和位置控制、非刚性形状变形以及复制/移动操作，并可简单指定二进制引导掩码来提供强大的合成控制。

    

    我们提供了一种一次性掩码引导图像合成的方法，通过反转带有强正则化器的准鲁棒分类器来控制对单个图像的操作。我们提出的方法名为MAGIC，利用来自预训练的准鲁棒分类器的结构化梯度，可以更好地保留输入的语义，并保持其分类准确性，从而保证合成的可信度。与目前使用复杂原语来监督过程或使用注意力图作为弱监督信号的方法不同，MAGIC通过在输入上聚合梯度，由强空间先验的指导二进制掩码推动。MAGIC以单个框架实现了一系列操作，实现了形状和位置控制、强烈的非刚性形状变形以及在重复物体存在的情况下的复制/移动操作，并通过简单指定二进制引导掩码来给用户提供强大的合成控制。

    We offer a method for one-shot mask-guided image synthesis that allows controlling manipulations of a single image by inverting a quasi-robust classifier equipped with strong regularizers. Our proposed method, entitled MAGIC, leverages structured gradients from a pre-trained quasi-robust classifier to better preserve the input semantics while preserving its classification accuracy, thereby guaranteeing credibility in the synthesis. Unlike current methods that use complex primitives to supervise the process or use attention maps as a weak supervisory signal, MAGIC aggregates gradients over the input, driven by a guide binary mask that enforces a strong, spatial prior. MAGIC implements a series of manipulations with a single framework achieving shape and location control, intense non-rigid shape deformations, and copy/move operations in the presence of repeating objects and gives users firm control over the synthesis by requiring to simply specify binary guide masks. Our study and findin
    
[^68]: 加强权重约束最短路径问题的方法

    Enhanced Methods for the Weight Constrained Shortest Path Problem. (arXiv:2207.14744v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2207.14744](http://arxiv.org/abs/2207.14744)

    本文提出了两种基于A*搜索的新解法，用于解决权重约束最短路径问题（WCSPP），在大规模图上表现出优越性能。

    

    权重约束最短路径问题（WCSPP）是一种具有挑战性的人工智能问题，被广泛应用于通信和交通等领域。本文结合约束路径规划和双目标搜索的最新技术，提出了两种基于A*搜索的新解法，用于解决WCSPP问题。实验结果表明，我们的算法在大规模图上能够解决困难的WCSPP实例，并且相比现有算法具有优势。

    The classic problem of constrained pathfinding is a well-studied, yet challenging, topic in AI with a broad range of applications in various areas such as communication and transportation. The Weight Constrained Shortest Path Problem (WCSPP), the base form of constrained pathfinding with only one side constraint, aims to plan a cost-optimum path with limited weight/resource usage. Given the bi-criteria nature of the problem (i.e., dealing with the cost and weight of paths), methods addressing the WCSPP have some common properties with bi-objective search. This paper leverages the recent state-of-the-art techniques in both constrained pathfinding and bi-objective search and presents two new solution approaches to the WCSPP on the basis of A* search, both capable of solving hard WCSPP instances on very large graphs. We empirically evaluate the performance of our algorithms on a set of large and realistic problem instances and show their advantages over the state-of-the-art algorithms in 
    
[^69]: 针对下一次购买预测的顺序推荐模型

    Sequential Recommendation Model for Next Purchase Prediction. (arXiv:2207.06225v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2207.06225](http://arxiv.org/abs/2207.06225)

    本文提出了一种顺序推荐系统，考虑了用户的购买顺序以预测他们的下一次购买，该模型利用大规模的信用卡交易数据集进行了验证和排名，展现了其在准确性和效果上的优势。

    

    在提供当代数字营销体验时，推荐的时效性和上下文准确性变得越来越重要。传统的推荐系统通过考虑用户的过去购买记录向用户推荐相关但不受时间影响的物品。这些推荐只是符合用户的一般偏好，而不是用户在购买之前的具体需求。相反，考虑交易、购买或体验顺序来衡量用户演化偏好的推荐系统能够为用户提供更准确和有效的推荐：顺序推荐系统不仅能更好地理解用户当前需求的行为，还具有更好的预测能力。在本文中，我们利用一份包含超过2.7百万信用卡交易数据和46K个持卡人的生产数据集，展示并排名了顺序推荐系统的效果。该方法首先使用自编码器对原始的交易数据进行处理，然后提交观测数据进行预测。

    Timeliness and contextual accuracy of recommendations are increasingly important when delivering contemporary digital marketing experiences. Conventional recommender systems (RS) suggest relevant but time-invariant items to users by accounting for their past purchases. These recommendations only map to customers' general preferences rather than a customer's specific needs immediately preceding a purchase. In contrast, RSs that consider the order of transactions, purchases, or experiences to measure evolving preferences can offer more salient and effective recommendations to customers: Sequential RSs not only benefit from a better behavioral understanding of a user's current needs but also better predictive power. In this paper, we demonstrate and rank the effectiveness of a sequential recommendation system by utilizing a production dataset of over 2.7 million credit card transactions for 46K cardholders. The method first employs an autoencoder on raw transaction data and submits observ
    
[^70]: Plurality Veto：一种实现最优度量畸变的简单投票规则

    Plurality Veto: A Simple Voting Rule Achieving Optimal Metric Distortion. (arXiv:2206.07098v2 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2206.07098](http://arxiv.org/abs/2206.07098)

    Plurality Veto是一种实现最优度量畸变的简单投票规则，每个候选人的得分等于他的第一名选票数，并通过逐步的否决过程逐渐降低得分，在其得票数达到一半时退出。

    

    度量畸变框架假设n个选民和m个候选人共同嵌入在一个度量空间中，选民按照离他们更近的候选人进行排名。一个投票规则的目的是在只知道排名而不知道实际距离的情况下选择一个与选民的总距离最小的候选人。结果是，在最坏情况下，每个确定性规则选择的候选人的总距离至少是最优规则的三倍，即具有至少3的度量畸变。最近的突破性结果表明，实现这个3的界限是可能的；然而，证明是非构造性的，并且投票规则本身是一个复杂的穷举搜索。我们的主要结果是一种非常简单的投票规则，称为多数否决制，它实现了相同的最优畸变度为3。每个候选人的得分开始等于他的第一名选票数。然后通过一个n轮的否决过程逐渐降低这些得分，在此过程中，候选人在其得票数达到n的一半时退出。

    The metric distortion framework posits that n voters and m candidates are jointly embedded in a metric space such that voters rank candidates that are closer to them higher. A voting rule's purpose is to pick a candidate with minimum total distance to the voters, given only the rankings, but not the actual distances. As a result, in the worst case, each deterministic rule picks a candidate whose total distance is at least three times larger than that of an optimal one, i.e., has distortion at least 3. A recent breakthrough result showed that achieving this bound of 3 is possible; however, the proof is non-constructive, and the voting rule itself is a complicated exhaustive search.  Our main result is an extremely simple voting rule, called Plurality Veto, which achieves the same optimal distortion of 3. Each candidate starts with a score equal to his number of first-place votes. These scores are then gradually decreased via an n-round veto process in which a candidate drops out when hi
    

