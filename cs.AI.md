# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Developing and Evaluating a Design Method for Positive Artificial Intelligence](https://rss.arxiv.org/abs/2402.01499) | 这项研究提出并评估了一种正向人工智能设计方法，用于确保人工智能系统对社会产生积极影响。该方法通过以人为中心的流程，将幸福愿景转化为具体实践，并通过持续的测量和反馈循环进行支持。 |
| [^2] | [Few-Shot Learning on Graphs: from Meta-learning to Pre-training and Prompting](https://rss.arxiv.org/abs/2402.01440) | 本文综述了图上的小样本学习的最新发展，将现有的研究方法划分为元学习、预训练和混合方法三大类别，并对它们的优缺点进行了比较。还提出了未来的研究方向。 |
| [^3] | [A Survey of Large Language Models in Medicine: Principles, Applications, and Challenges](https://rss.arxiv.org/abs/2311.05112) | 本综述提供了医学中大型语言模型（LLMs）的原理、应用和挑战的全面概述。同时回答了医学LLMs的构建、下游性能、实际应用、挑战以及更好构建和利用的问题。旨在为构建有效的医学LLMs提供见解和实用资源。 |
| [^4] | [Twisting Lids Off with Two Hands](https://arxiv.org/abs/2403.02338) | 深度强化学习结合仿真到真实世界的转移为解决物体操纵问题提供了有力支持 |
| [^5] | [Brand Visibility in Packaging: A Deep Learning Approach for Logo Detection, Saliency-Map Prediction, and Logo Placement Analysis](https://arxiv.org/abs/2403.02336) | 本研究引入了一种深度学习框架，结合标志检测、显著性图预测和标志位置分析，用于衡量包装设计中品牌标志的关注度。 |
| [^6] | [Gradient Correlation Subspace Learning against Catastrophic Forgetting](https://arxiv.org/abs/2403.02334) | GCSL是一种用于减少灾难性遗忘的新颖方法，通过检测和利用不受以前任务影响的权重子空间来训练新任务。 |
| [^7] | [Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning](https://arxiv.org/abs/2403.02333) | 提出了基于关键点驱动的数据合成框架(KPDDS)，创造了迄今为止最大规模的用于数学推理的合成数据集KPMath，以及进一步增强的KPMath-Plus数据集，实现了零-shot PASS@1精度为39.3%的性能提升。 |
| [^8] | [Model Lakes](https://arxiv.org/abs/2403.02327) | 提出了模型湖的概念，在解决大型模型管理中的基础研究挑战方面具有重要意义。 |
| [^9] | [Contrastive Region Guidance: Improving Grounding in Vision-Language Models without Training](https://arxiv.org/abs/2403.02325) | 引入了对比区域引导（CRG）方法，实现了在视觉-语言模型中无需训练即可使模型响应视觉提示并取得显著改进。 |
| [^10] | [Beyond Specialization: Assessing the Capabilities of MLLMs in Age and Gender Estimation](https://arxiv.org/abs/2403.02302) | 本研究评估了多模态大型语言模型（MLLMs）在年龄和性别估计中的能力，对不同模型进行了比较，揭示了它们在特定任务上的优势和劣势。 |
| [^11] | [Koopman-Assisted Reinforcement Learning](https://arxiv.org/abs/2403.02290) | 该论文利用Koopman算子技术将非线性系统提升到新坐标系，在其中动力学变得近似线性，从而构建两种新的强化学习算法，以解决高维状态和非线性系统中传统方程难以解决的问题。 |
| [^12] | [Subjective $\textit{Isms}$? On the Danger of Conflating Hate and Offence in Abusive Language Detection](https://arxiv.org/abs/2403.02268) | 论文指出在滥用语言检测中，混淆仇恨和冒犯可能会使研究结果失效，呼吁未来工作需要从理论上将仇恨与冒犯概念进行分离。 |
| [^13] | [KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection](https://arxiv.org/abs/2403.02253) | 提出了一个自动化知识收集流水线，发布了一个包含20k品牌的大规模多模态品牌知识库KnowPhish，可用于加强现有基于参考的网络钓鱼检测器的性能 |
| [^14] | [Non-autoregressive Sequence-to-Sequence Vision-Language Models](https://arxiv.org/abs/2403.02249) | 提出了一种非自回归序列到序列视觉语言模型，通过在解码器中边际化多个推理路径的方式，实现了对标记的联合分布建模，从而在保持性能的同时加快了推理速度。 |
| [^15] | [Better Schedules for Low Precision Training of Deep Neural Networks](https://arxiv.org/abs/2403.02243) | 该研究发现了用于低精度训练的循环精度训练调度的更好选择，进一步提高了训练效率 |
| [^16] | [Neural Redshift: Random Networks are not Random Functions](https://arxiv.org/abs/2403.02241) | 本论文研究了未经训练的随机权重网络，发现即使简单的MLPs也具有强烈的归纳偏见，不同于传统观点的是，NNs并不具有固有的“简单偏见”，而是依赖于组件的作用。 |
| [^17] | [Towards Intent-Based Network Management: Large Language Models for Intent Extraction in 5G Core Networks](https://arxiv.org/abs/2403.02238) | 该论文提出了为5G和下一代基于意图的网络开发自定义大型语言模型（LLM），旨在实现完全自动化网络中的端到端基于意图的网络。 |
| [^18] | [Comprehensive evaluation of Mal-API-2019 dataset by machine learning in malware detection](https://arxiv.org/abs/2403.02232) | 该研究通过机器学习技术全面评估了恶意软件检测，发现集成方法（如随机森林和XGBoost）相较于其他方法在恶意软件检测中表现出更高的准确性、精确度和召回率。 |
| [^19] | [Policy Space Response Oracles: A Survey](https://arxiv.org/abs/2403.02227) | 政策空间响应神谕（PSRO）是一种适用于大型博弈的快速发展的博弈推理框架，主要关注策略探索问题和提高效率的研究，以及在各个领域中的应用。 |
| [^20] | [Not all Layers of LLMs are Necessary during Inference](https://arxiv.org/abs/2403.02181) | 推理过程中，根据输入实例的不同难易程度，本文提出了一种名为AdaInfer的算法，可以自适应地使用浅层和深层，从而节省了计算资源。 |
| [^21] | [Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models](https://arxiv.org/abs/2403.02178) | 引入对输入的扰动，通过随机掩盖思维链中的某些标记，可显著提高语言模型在推理任务中的学习效果 |
| [^22] | [Speech emotion recognition from voice messages recorded in the wild](https://arxiv.org/abs/2403.02167) | 使用Emotional Voice Messages数据库，结合eGeMAPS特征和Transformer模型，实现了在野外录制的语音消息中的语音情感识别，取得了较高的准确度，并比基准模型提高了10%。 |
| [^23] | [Cognition is All You Need - The Next Layer of AI Above Large Language Models](https://arxiv.org/abs/2403.02164) | 提出了认知人工智能，一个用于在大型语言模型之上实现以程序定义的神经符号认知的高级框架，为能够执行复杂多步知识工作的人工智能系统提供了路径。 |
| [^24] | [Deep Reinforcement Learning for Dynamic Algorithm Selection: A Proof-of-Principle Study on Differential Evolution](https://arxiv.org/abs/2403.02131) | 本论文提出了一种基于深度强化学习的动态算法选择框架，旨在通过训练代理根据优化过程中观察到的特征选择最合适的算法，以解决单个算法有效性在不同问题实例上变化的问题。 |
| [^25] | [LOCR: Location-Guided Transformer for Optical Character Recognition](https://arxiv.org/abs/2403.02127) | LOCR是一种面向光学字符识别的模型，通过在自回归过程中在transformer架构中集成位置引导，能够有效处理学术文档中的重复问题，并在测试集上表现出色。 |
| [^26] | [Leveraging Weakly Annotated Data for Hate Speech Detection in Code-Mixed Hinglish: A Feasibility-Driven Transfer Learning Approach with Large Language Models](https://arxiv.org/abs/2403.02121) | 本研究利用弱标注数据和大型语言模型，针对混合代码的印地语进行仇恨言论检测，探索了零次学习、一次学习和少次学习方法，解决了标记数据的问题。 |
| [^27] | [Position Paper: Towards Implicit Prompt For Text-To-Image Models](https://arxiv.org/abs/2403.02118) | 该位置论文讨论了文本到图像模型在隐式提示方面的现状，提出了名为ImplicitBench的新基准，并对 T2I 模型在隐式提示下的表现及影响进行了调查。 |
| [^28] | [Iterated $Q$-Network: Beyond the One-Step Bellman Operator](https://arxiv.org/abs/2403.02107) | 引入了迭代$Q$-网络（iQN）方法，通过一次考虑多次迭代的贝尔曼算子来改进值基强化学习方法，在理论上可行，并在实验中展示其在游戏和控制环境中的优势。 |
| [^29] | [VTG-GPT: Tuning-Free Zero-Shot Video Temporal Grounding with GPT](https://arxiv.org/abs/2403.02076) | 提出了一种基于GPT的零调优视频时间定位方法VTG-GPT，通过生成无偏查询和更精确的视觉描述，实现了在零样本设置中明显优于现有方法和无监督方法的性能提升 |
| [^30] | [Modality-Aware and Shift Mixer for Multi-modal Brain Tumor Segmentation](https://arxiv.org/abs/2403.02074) | 本文提出了一种新颖的模态感知和位移混合器，用于融合多模态图像的依赖关系，以实现在脑肿瘤分割任务中的有效和稳健性。 |
| [^31] | [Large Language Model-Based Evolutionary Optimizer: Reasoning with elitism](https://arxiv.org/abs/2403.02054) | LEO是一种基于大型语言模型的进化优化器，具有零-shot优化能力，在多目标和高维问题上表现出色，与最先进方法产生可比较的结果，但其想象力和幻觉倾向需要谨慎处理。 |
| [^32] | [A Scoping Review of Energy-Efficient Driving Behaviors and Applied State-of-the-Art AI Methods](https://arxiv.org/abs/2403.02053) | 本文通过范围审查探讨了能源高效驾驶行为和最先进AI方法的应用，总结了影响驾驶行为的十一个关键特征。 |
| [^33] | [Cross Domain Policy Transfer with Effect Cycle-Consistency](https://arxiv.org/abs/2403.02018) | 提出了一种新颖的方法，通过使用未配对数据学习两个领域之间的状态和动作空间映射函数，实现了跨域策略转移。 |
| [^34] | [Unveiling Hidden Links Between Unseen Security Entities](https://arxiv.org/abs/2403.02014) | VulnScopper是一种创新方法，利用多模态表示学习结合知识图谱和自然语言处理，能够自动化和增强软件漏洞分析，有效处理未见实体，并在NVD和Red Hat CVE数据库上取得显著改进。 |
| [^35] | [Transformers for Low-Resource Languages:Is F\'eidir Linn!](https://arxiv.org/abs/2403.01985) | 本研究评估了对低资源的英语-爱尔兰语语言对进行超参数优化的 Transformer 模型，发现正确选择子词模型是翻译性能的最大驱动因素。 |
| [^36] | [TTA-Nav: Test-time Adaptive Reconstruction for Point-Goal Navigation under Visual Corruptions](https://arxiv.org/abs/2403.01977) | TTA-Nav提出了一种测试时自适应方法，通过引入自顶向下解码器，从损坏图像中重建出更清晰的图像，显著增强了点目标导航性能。 |
| [^37] | [The Heterogeneous Productivity Effects of Generative AI](https://arxiv.org/abs/2403.01964) | 意大利对ChatGPT实施禁令后，不同经验的用户生产力表现出差异，经验较少的用户在短期内产出数量和质量均有提升，而经验丰富的用户在更常规的任务上表现出生产力下降。 |
| [^38] | [DECIDER: A Rule-Controllable Decoding Strategy for Language Generation by Imitating Dual-System Cognitive Theory](https://arxiv.org/abs/2403.01954) | DECIDER是一种受双系统认知理论启发的规则可控解码策略，通过在预训练语言模型中引入逻辑推理器，有效地遵循给定规则以引导生成方向朝向目标。 |
| [^39] | [To Generate or to Retrieve? On the Effectiveness of Artificial Contexts for Medical Open-Domain Question Answering](https://arxiv.org/abs/2403.01924) | 本文介绍了MedGENIE，这是医学领域多项选择问题回答的第一个生成后阅读框架。 |
| [^40] | [xT: Nested Tokenization for Larger Context in Large Images](https://arxiv.org/abs/2403.01915) | xT为视觉Transformer引入了嵌套标记化方案，有效地聚合了全局背景和局部细节，使其能够在现代GPU上端到端地建模大图像，并在经典视觉任务数据集上展示了改进。 |
| [^41] | [Semi-Supervised Semantic Segmentation Based on Pseudo-Labels: A Survey](https://arxiv.org/abs/2403.01909) | 这项综述提供了关于基于伪标签方法在半监督语义分割领域最新研究成果的全面且有组织的概述，探讨了伪标签技术在不同应用领域的具体方法，还研究了其在医学和遥感图像分割中的应用，提出了未来研究方向。 |
| [^42] | [Unsupervised Distance Metric Learning for Anomaly Detection Over Multivariate Time Series](https://arxiv.org/abs/2403.01895) | 提出了一种无监督距离度量学习方法FCM-wDTW，用于多变量时间序列异常检测，通过将原始数据编码成潜在空间并通过聚类中心揭示正常维度关系，在实验中表现出竞争力的准确性和效率。 |
| [^43] | [Fast Benchmarking of Asynchronous Multi-Fidelity Optimization on Zero-Cost Benchmarks](https://arxiv.org/abs/2403.01888) | 通过引入用户友好的Python软件包，研究提出了有效的并行HPO方法，避免长时间等待实现快速评估。 |
| [^44] | [FCDS: Fusing Constituency and Dependency Syntax into Document-Level Relation Extraction](https://arxiv.org/abs/2403.01886) | 本研究将短语结构和依存句法融合到文档级关系抽取中，有效利用了文档中的丰富语法信息。 |
| [^45] | [ICLN: Input Convex Loss Network for Decision Focused Learning](https://arxiv.org/abs/2403.01875) | 提出了输入凸损失网络（ICLN），通过输入凸神经网络学习任务损失，为决策集中学习提供了全局替代损失。 |
| [^46] | [AiSDF: Structure-aware Neural Signed Distance Fields in Indoor Scenes](https://arxiv.org/abs/2403.01861) | 提出了一种针对室内场景的结构感知在线有符号距离场（SDF）重建框架，可根据亚特兰大结构估计平面surfel区域，从而带来更高质量的重建结果。 |
| [^47] | [Rethinking LLM Language Adaptation: A Case Study on Chinese Mixtral](https://arxiv.org/abs/2403.01851) | 本文以中文Mixtral为案例，提出了改进的中文语言能力的Mixtral模型，并讨论了在大型语言模型进行语言适应时的关键问题。 |
| [^48] | [One Prompt Word is Enough to Boost Adversarial Robustness for Pre-trained Vision-Language Models](https://arxiv.org/abs/2403.01849) | 本文研究了预训练视觉-语言模型的对抗鲁棒性，提出了一种通过学习强韧文本提示来改善对抗攻击韧性的方法，称为Adversarial Prompt Tuning（APT），并在多个数据集和数据稀疏方案上进行了全面实验验证。 |
| [^49] | [NASH: Neural Architecture Search for Hardware-Optimized Machine Learning Models](https://arxiv.org/abs/2403.01845) | NASH是一种将神经架构搜索应用于机器学习硬件的新方法，可以帮助硬件设计实现高吞吐量、低延迟和优越的准确性表现。 |
| [^50] | [FreeA: Human-object Interaction Detection using Free Annotation Labels](https://arxiv.org/abs/2403.01840) | 提出了一种新颖的自适应语言驱动的HOI检测方法FreeA，无需标记，利用了CLIP来生成潜在的HOI标签，并在两个基准数据集上取得了最先进的性能。 |
| [^51] | [Model-Based Data-Centric AI: Bridging the Divide Between Academic Ideals and Industrial Pragmatism](https://arxiv.org/abs/2403.01832) | 本文提出了一种新的模型-Based Data-Centric AI 范式，旨在解决学术界数据质量和工业应用之间的差异，并提出了整合模型考虑到数据优化过程中的策略。 |
| [^52] | [Analysis and Fully Memristor-based Reservoir Computing for Temporal Data Classification](https://arxiv.org/abs/2403.01827) | 本研究引入了一种新颖的双存储器 RC 系统，通过集成不同类型的 memristor，并在处理时间数据分类任务中取得了显著成效。 |
| [^53] | [RT-H: Action Hierarchies Using Language](https://arxiv.org/abs/2403.01823) | 通过教会机器人动作语言，描述低级运动，并将语言动作作为中间步骤来预测任务和动作之间的关系，从而促使策略学习共享结构。 |
| [^54] | [AllSpark: Reborn Labeled Features from Unlabeled in Transformer for Semi-Supervised Semantic Segmentation](https://arxiv.org/abs/2403.01818) | AllSpark利用通道级交叉注意机制从未标记的特征中重新生成标记特征，以改善半监督语义分割中低质量伪标签的问题。 |
| [^55] | [SMAUG: A Sliding Multidimensional Task Window-Based MARL Framework for Adaptive Real-Time Subtask Recognition](https://arxiv.org/abs/2403.01816) | SMAUG框架提出了基于滑动多维任务窗口的适应性实时子任务识别方法，与传统方法相比，提高了灵活性和适用性。 |
| [^56] | [COLA: Cross-city Mobility Transformer for Human Trajectory Simulation](https://arxiv.org/abs/2403.01801) | 研究通过将强大的Transformer模型与外部移动数据相结合，探讨了跨城市人类轨迹模拟的问题，解决了知识转移中的适应性挑战。 |
| [^57] | [Beyond Recommender: An Exploratory Study of the Effects of Different AI Roles in AI-Assisted Decision Making](https://arxiv.org/abs/2403.01791) | 本研究探讨了AI辅助决策中不同AI角色（推荐系统、分析者和魔鬼的辩护者）的影响，发现它们在任务表现、依赖适当性和用户体验方面各有优势和局限性。 |
| [^58] | [CatCode: A Comprehensive Evaluation Framework for LLMs On the Mixture of Code and Text](https://arxiv.org/abs/2403.01784) | CatCode提出了一种基于范畴论的评估框架，可以全面评估LLMs在解决编程问题时的编码能力。 |
| [^59] | [Integrating Efficient Optimal Transport and Functional Maps For Unsupervised Shape Correspondence Learning](https://arxiv.org/abs/2403.01781) | 该论文将光谱方法与深度学习相结合，通过使用切片Wasserstein距离（SWD）进行最优输运，在无监督形状匹配框架中实现了功能映射和最优输运的高效整合。 |
| [^60] | [Improving out-of-distribution generalization in graphs via hierarchical semantic environments](https://arxiv.org/abs/2403.01773) | 通过生成分层语义环境，本文提出了一种新方法来增强图的不变学习，以处理分布转移。 |
| [^61] | [A Safe Screening Rule with Bi-level Optimization of $\nu$ Support Vector Machine](https://arxiv.org/abs/2403.01769) | 提出了一种具有双层优化的安全筛选规则的$\nu$支持向量机方法，可以在训练前筛选出不活跃样本，降低计算成本，同时不损失预测准确性。 |
| [^62] | [Canonical Form of Datatic Description in Control Systems](https://arxiv.org/abs/2403.01768) | 本文首次引入了规范数据形式的概念，以实现更有效地设计数据控制器。 |
| [^63] | [How Multimodal Integration Boost the Performance of LLM for Optimization: Case Study on Capacitated Vehicle Routing Problems](https://arxiv.org/abs/2403.01757) | 提出了一种使用多模态LLM进行优化的框架，能够更全面地理解优化问题，类似于人类认知过程，并且提供了更细致和有效的分析。 |
| [^64] | [Decode Neural signal as Speech](https://arxiv.org/abs/2403.01748) | 本文在脑机接口领域探索了MEG信号的脑到文本转换，着重解决了以前主要集中在EEG上、使用“teacher-forcing”以及未完全自回归的问题。 |
| [^65] | [Offline Goal-Conditioned Reinforcement Learning for Safety-Critical Tasks with Recovery Policy](https://arxiv.org/abs/2403.01734) | 提出了一种名为RbSL的新方法，用于解决具有不同目标的安全关键任务，克服了传统方法在复杂环境中处理多样约束时的限制。 |
| [^66] | [Can LLMs Generate Architectural Design Decisions? -An Exploratory Empirical study](https://arxiv.org/abs/2403.01709) | 本研究旨在探究利用大语言模型（LLMs）生成建筑设计决策的可行性，并尝试应用于架构决策记录（ADR）生成。 |
| [^67] | [Brilla AI: AI Contestant for the National Science and Maths Quiz](https://arxiv.org/abs/2403.01699) | 人工智能参赛者Brilla AI在全国科学与数学竞赛中表现优秀，为缺乏合格教师的非洲提供了学习支持。 |
| [^68] | [Hypertext Entity Extraction in Webpage](https://arxiv.org/abs/2403.01698) | 提出了一个新的超文本实体提取数据集HEED和一个基于MoE的实体提取框架MoEEF，有效整合多个特征以提高模型性能。 |
| [^69] | [DyCE: Dynamic Configurable Exiting for Deep Learning Compression and Scaling](https://arxiv.org/abs/2403.01695) | 介绍了DyCE，一个动态可配置的提前退出框架，将设计考虑从彼此和基础模型解耦 |
| [^70] | [HanDiffuser: Text-to-Image Generation With Realistic Hand Appearances](https://arxiv.org/abs/2403.01693) | HanDiffuser提出了一种基于扩散的架构，通过在生成过程中注入手部嵌入来实现逼真的手部外观，包括Text-to-Hand-Params扩散模型和Text-Guided Hand-Params-to-Image扩散模型。 |
| [^71] | [CATS: Enhancing Multivariate Time Series Forecasting by Constructing Auxiliary Time Series as Exogenous Variables](https://arxiv.org/abs/2403.01673) | CATS通过构建辅助时间序列作为外生变量，有效地表示和整合多元时间序列之间的关系，提高了多元时间序列预测的效果，并且相较于之前的模型大幅减少了复杂性和参数。 |
| [^72] | [Recommendations for Government Development and Use of Advanced Automated Systems to Make Decisions about Individuals](https://arxiv.org/abs/2403.01649) | Contestability对于政府决定个人事务是至关重要的，研讨会探讨了通过竞争性来发现系统性错误并对系统进行改进的方法。 |
| [^73] | [You Need to Pay Better Attention](https://arxiv.org/abs/2403.01643) | 提出了三种新的注意力机制，在效率和学习能力方面优于标准的多头注意力，提高了Transformer模型的性能和更广泛的部署能力。 |
| [^74] | [Machine Learning vs Deep Learning: The Generalization Problem](https://arxiv.org/abs/2403.01621) | 深度学习模型具备泛化到训练范围之外的固有能力，这对于现实世界中至关重要。 |
| [^75] | [A Unified Model Selection Technique for Spectral Clustering Based Motion Segmentation](https://arxiv.org/abs/2403.01606) | 本文提出了一种统一模型选择技术，通过结合不同的现有模型选择技术，实现了基于谱聚类的运动分割方法的自动推断运动组数。 |
| [^76] | [Towards Provable Log Density Policy Gradient](https://arxiv.org/abs/2403.01605) | 提出对数密度梯度方法来估计策略梯度，修正残差误差，有望改善强化学习方法的样本复杂度。 |
| [^77] | [Can Poverty Be Reduced by Acting on Discrimination? An Agent-based Model for Policy Making](https://arxiv.org/abs/2403.01600) | 通过引入贫困恐惧代理模型（AABM），本研究在计算上提供了对贫困和贫困恐惧之间关系的证据，以验证歧视对贫困缓解的影响。 |
| [^78] | [SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos](https://arxiv.org/abs/2403.01599) | 通过研究步骤和状态之间的因果关系，本文提出了SCHEMA方法，将每个步骤显式表示为状态变化，并追踪教学视频中的状态变化。 |
| [^79] | [APISR: Anime Production Inspired Real-World Anime Super-Resolution](https://arxiv.org/abs/2403.01598) | 本文提出了受动漫制作启发的真实世界动漫超分辨率方法，通过分析动漫制作工作流程，提出不需要视频网络和数据集，引入动漫图像收集流水线和API数据集，解决了动漫特有的挑战，为真实世界动漫超分辨率带来新的思路。 |
| [^80] | [Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures](https://arxiv.org/abs/2403.01580) | 本研究通过优化Transformer模型的超参数和子词模型类型，开发了适用于低资源语言对的神经机器翻译系统，并开发了gaHealth，首个针对爱尔兰语健康数据的双语语料库，取得了显著的翻译质量提升。 |
| [^81] | [SARD: A Human-AI Collaborative Story Generation](https://arxiv.org/abs/2403.01575) | SARD提出了一个新的人工智能与人类协作的故事生成工具, 旨在通过大型语言模型生成多章节故事，评估表明：节点式叙事的可视化可能帮助作者构建心智模型，但同时会给作者带来额外的心智负担，并在故事变得更加复杂时成为干扰源，AI生成的故事在词汇多样性上存在不足。 |
| [^82] | [Kick Back & Relax++: Scaling Beyond Ground-Truth Depth with SlowTV & CribsTV](https://arxiv.org/abs/2403.01569) | 本文提出了两个新颖的数据集SlowTV和CribsTV，通过这些数据集，成功解决了自监督单目深度估计（SS-MDE）存在的多样化训练数据不足问题，实现了零-shot泛化的任务。 |
| [^83] | [ReMatch: Retrieval Enhanced Schema Matching with LLMs](https://arxiv.org/abs/2403.01567) | ReMatch方法利用检索增强的大型语言模型 (LLMs) 进行模式匹配，避免了预定义映射、模型训练或对源数据库数据的访问。 |
| [^84] | [ComTraQ-MPC: Meta-Trained DQN-MPC Integration for Trajectory Tracking with Limited Active Localization Updates](https://arxiv.org/abs/2403.01564) | ComTraQ-MPC是一个结合了DQN和MPC的新框架，旨在优化在有限主动定位更新下的轨迹跟踪。 |
| [^85] | [In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation](https://arxiv.org/abs/2403.01548) | 本研究从内部表征角度深入探讨了大型语言模型幻觉的机制，发现了幻觉的一个显著模式，即在上下文标记的隐藏状态中，正确生成具有更清晰的上下文激活。我们提出了一种基于熵的度量方法，将“锐度”纳入解码过程中，制定了一种受限解码方法，实验证明其在知识寻求和幻觉任务上的有效性。 |
| [^86] | [Machine learning predicts long-term mortality after acute myocardial infarction using systolic time intervals and routinely collected clinical data](https://arxiv.org/abs/2403.01533) | 该研究利用机器学习模型和新生物标志物探索长期死亡率预测，为心脏病患者提供更准确的医疗决策支持。 |
| [^87] | [Leveraging Biomolecule and Natural Language through Multi-Modal Learning: A Survey](https://arxiv.org/abs/2403.01528) | 生物分子与自然语言相结合的多模态学习为全面表示和分析生物分子开辟了新途径。 |
| [^88] | [End-to-End Human Instance Matting](https://arxiv.org/abs/2403.01510) | 提出了一种端到端的人体实例抠图框架，通过通用感知网络和统一引导网络实现高效的多实例抠图。 |
| [^89] | [Soft Reasoning on Uncertain Knowledge Graphs](https://arxiv.org/abs/2403.01508) | 本文研究了在不确定知识图上进行软查询，并提出了一种基于机器学习的方法，可以有效回答大规模、不完整和不确定的知识图上的查询。 |
| [^90] | [Regeneration Based Training-free Attribution of Fake Images Generated by Text-to-Image Generative Models](https://arxiv.org/abs/2403.01489) | 提出了一种基于重建的无需训练的方法，用于将由文本到图像生成模型生成的假图像归因于其来源模型，从而让模型所有者对模型的任何滥用负责。 |
| [^91] | [Align-to-Distill: Trainable Attention Alignment for Knowledge Distillation in Neural Machine Translation](https://arxiv.org/abs/2403.01479) | "本文提出了“Align-to-Distill”（A2D）策略，通过在训练过程中自适应地对齐学生注意力头与其教师对应物，转化了组合映射启发式方法为学习问题，实验结果显示A2D的有效性，对WMT-2022 De->Dsb和WMT-2014 En->De的BLEU分数分别获得高达+3.61和+0.63的提升。" |
| [^92] | [Representation Learning on Heterophilic Graph with Directional Neighborhood Attention](https://arxiv.org/abs/2403.01475) | 提出了具有方向性邻域注意力的Directional Graph Attention Network（DGAT），能够有效结合特征注意力和全局方向信息，通过新型拉普拉斯矩阵减少节点之间的扩散距离，并引入拓扑引导的邻域修剪和边添加机制来提升异质图的表示学习性能。 |
| [^93] | [Collaborate to Adapt: Source-Free Graph Domain Adaptation via Bi-directional Adaptation](https://arxiv.org/abs/2403.01467) | 本论文提出了一种名为GraphCTA的新方法，通过协作的模型适应和图适应来解决无源图领域自适应问题。 |
| [^94] | [Controlling Cloze-test Question Item Difficulty with PLM-based Surrogate Models for IRT Assessment](https://arxiv.org/abs/2403.01456) | 提出使用预训练语言模型作为代理模型，通过排名规则控制填空测试题目中空白和干扰项的难度水平，有效评估MC填空测试的难度水平 |
| [^95] | [GPTSee: Enhancing Moment Retrieval and Highlight Detection via Description-Based Similarity Features](https://arxiv.org/abs/2403.01437) | 该研究提出了一个新颖的两阶段模型，将大型语言模型（LLMs）的输出用作第二阶段变压器编码器-解码器的输入，实现了时刻检索和重点检测的最先进结果。 |
| [^96] | [Exploring the Design of Generative AI in Supporting Music-based Reminiscence for Older Adults](https://arxiv.org/abs/2403.01413) | 本研究通过用户中心设计方法，包括与两名社工和两个设计研讨会（涉及十名老年人）的详细访谈，为深入了解老年人利用生成AI支持基于音乐的回忆的态度作出贡献 |
| [^97] | [Region-Transformer: Self-Attention Region Based Class-Agnostic Point Cloud Segmentation](https://arxiv.org/abs/2403.01407) | 该论文提出了一种名为区域-Transformer的新型区域基Transformer模型，使用区域增长方法和自注意力机制进行无关类别的点云分割训练，首次将自注意力机制应用于区域增长方法。 |
| [^98] | [Decoupling Weighing and Selecting for Integrating Multiple Graph Pre-training Tasks](https://arxiv.org/abs/2403.01400) | 本文提出了一种用于整合多个图预训练任务的新颖的实例级框架Weigh And Select（WAS），其中通过解耦的连体网络组合了权衡和选择这两个协作过程 |
| [^99] | [On the Compressibility of Quantized Large Language Models](https://arxiv.org/abs/2403.01384) | 研究在内存受限设备上应用数据压缩技术以加速量化LLM推理过程的一项初步工作。 |
| [^100] | [A Closer Look at Wav2Vec2 Embeddings for On-Device Single-Channel Speech Enhancement](https://arxiv.org/abs/2403.01369) | 本文研究了Wav2Vec2嵌入在单通道语音增强中的应用，发现SSL表示对增强任务几乎没有任何价值。 |
| [^101] | [SANGRIA: Stacked Autoencoder Neural Networks with Gradient Boosting for Indoor Localization](https://arxiv.org/abs/2403.01348) | SANGRIA是一个基于堆叠自编码器神经网络与梯度提升树的室内定位框架，相比其他先进框架，能够实现更低的平均定位误差。 |
| [^102] | [Chaining thoughts and LLMs to learn DNA structural biophysics](https://arxiv.org/abs/2403.01332) | 通用语言模型chatGPT 3.5-turbo的微调，在学习DNA结构生物物理学方面显示出新的潜力和优势。 |
| [^103] | [Bespoke Non-Stationary Solvers for Fast Sampling of Diffusion and Flow Models](https://arxiv.org/abs/2403.01329) | 该论文引入了定制的非平稳（BNS）求解器，提高了扩散和流动模型的采样效率，具有小参数空间、快速优化、样本多样性，并且在低中 NFE 范围内接近标准精炼方法。 |
| [^104] | [VNLP: Turkish NLP Package](https://arxiv.org/abs/2403.01309) | VNLP是首个专门针对土耳其语开发的自然语言处理工具包，包含多种NLP工具，其中的标记分类模型基于“上下文模型”，支持多种任务如情感分析、命名实体识别等。 |
| [^105] | [Summary Paper: Use Case on Building Collaborative Safe Autonomous Systems-A Robotdog for Guiding Visually Impaired People](https://arxiv.org/abs/2403.01286) | 该论文研究了用于引导视障者的机器狗在复杂环境中做出安全穿越十字路口的决策的系统架构和协作决策层设计。 |
| [^106] | [Fast Low-parameter Video Activity Localization in Collaborative Learning Environments](https://arxiv.org/abs/2403.01281) | 该论文提出了一种快速低参数视频活动定位系统，可在有限数据集上进行训练，并能准确检测并关联学生在现实教室视频中执行的活动。 |
| [^107] | [Optimal Integrated Task and Path Planning and Its Application to Multi-Robot Pickup and Delivery](https://arxiv.org/abs/2403.01277) | 提出一种结合了最优任务规划器和最优路径规划器的通用多机器人规划机制，通过相互作用生成最优无碰撞轨迹，在仓库场景中的物体取放问题中展示了其有效性。 |
| [^108] | [NoMAD-Attention: Efficient LLM Inference on CPUs Through Multiply-add-free Attention](https://arxiv.org/abs/2403.01273) | NoMAD-Attention提出了一种高效的注意力算法，通过在CPU上使用寄存器内查找取代MAD操作，以实现LLM推断的快速计算。 |
| [^109] | [Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey](https://arxiv.org/abs/2403.01255) | 先进的深度学习技术如深度迁移学习、联邦学习和强化学习解决了自动语音识别中训练数据领域假设不符合实际情况的问题，提高了性能并降低计算成本。 |
| [^110] | [SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code](https://arxiv.org/abs/2403.01248) | SceneCraft是一个LLM代理，可将文本描述转换为Blender代码，实现渲染高达一百个三维资产的复杂场景，通过先建模空间关系再编写Python脚本，并借助视觉-语言基础模型进行场景优化和库学习来解决挑战。 |
| [^111] | [Mitigating Catastrophic Forgetting in Large Language Models with Self-Synthesized Rehearsal](https://arxiv.org/abs/2403.01244) | 提出了一种称为Self-Synthesized Rehearsal（SSR）的框架，利用大型语言模型生成合成实例用于持续学习中的复述，以解决大型语言模型遭受灾难性遗忘的问题。 |
| [^112] | [Augmenting Automation: Intent-Based User Instruction Classification with Machine Learning](https://arxiv.org/abs/2403.01242) | 提出了一种通过引入基于意图的用户指令分类和机器学习技术的新颖方法，从而增强自动化系统的灵活性和适应性。 |
| [^113] | [IntactKV: Improving Large Language Model Quantization by Keeping Pivot Tokens Intact](https://arxiv.org/abs/2403.01241) | 本研究提出了IntactKV方法，通过保持关键标记的完整性，改善了大型语言模型的量化过程，进一步降低了量化误差的上限，并取得了显著的性能提升。 |
| [^114] | [Polynormer: Polynomial-Expressive Graph Transformer in Linear Time](https://arxiv.org/abs/2403.01232) | Polynormer提出了一种多项式表达GT模型，具有线性复杂度，结合本地和全局等变注意力模型，平衡了表现力和可扩展性。 |
| [^115] | [REWIND Dataset: Privacy-preserving Speaking Status Segmentation from Multimodal Body Movement Signals in the Wild](https://arxiv.org/abs/2403.01229) | 通过视频和可穿戴传感器数据训练的机器学习模型可以隐私保护地识别说话状态，解决了在野外获取个人录音困难的问题 |
| [^116] | [A Two-Stage Algorithm for Cost-Efficient Multi-instance Counterfactual Explanations](https://arxiv.org/abs/2403.01221) | 本文提出了一种两阶段算法，用于找到实例组以及成本有效的多实例反事实解释，填补了先前工作中未解决的空白。 |
| [^117] | [API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access](https://arxiv.org/abs/2403.01216) | 本研究提出了一种针对无需访问对数的API-only LLMs的整体预测方法，旨在最小化预测集大小并确保用户定义的覆盖范围的统计保证。 |
| [^118] | [SAR-AE-SFP: SAR Imagery Adversarial Example in Real Physics domain with Target Scattering Feature Parameters](https://arxiv.org/abs/2403.01210) | 该研究提出了一种通过改变目标物体的散射特征参数生成真实物理对抗样本的方法，解决了合成孔径雷达目标识别模型受到对抗样本影响的挑战。 |
| [^119] | [The Case for Animal-Friendly AI](https://arxiv.org/abs/2403.01199) | 人工智能伦理学和工程领域需要意识到技术会对动物产生巨大影响，因此作者构建了一个评估系统来评估大型语言模型对动物利益的考虑程度。 |
| [^120] | [Machine Translation in the Covid domain: an English-Irish case study for LoResMT 2021](https://arxiv.org/abs/2403.01196) | 在LoResMT 2021中，针对Covid数据从英语到爱尔兰语的翻译，通过使用领域自适应技术和扩展领域内Covid数据集训练Transformer架构，成功改善了翻译表现。 |
| [^121] | [RAGged Edges: The Double-Edged Sword of Retrieval-Augmented Chatbots](https://arxiv.org/abs/2403.01193) | 本文探讨了如何利用检索增强生成（RAG）抵制大型语言模型（LLMs）产生的幻觉，结果表明RAG在某些情况下可以提高准确性，但仍需要更强大的解决方案以确保LLMs在实际应用中可靠性。 |
| [^122] | [Balancing Exploration and Exploitation in LLM using Soft RLLF for Enhanced Negation Understanding](https://arxiv.org/abs/2403.01185) | 通过利用逻辑反馈的强化学习（RLLF）在LLMs中实现探索和开发的平衡，以增强否定理解能力，并通过比较性能验证了这种平衡方法的价值。 |
| [^123] | [Leveraging Self-Supervised Learning for Scene Recognition in Child Sexual Abuse Imagery](https://arxiv.org/abs/2403.01183) | 利用自监督学习技术，本文提出了一种能够安全高效处理儿童性虐待图像数据的场景识别方法。 |
| [^124] | [DINER: Debiasing Aspect-based Sentiment Analysis with Multi-variable Causal Inference](https://arxiv.org/abs/2403.01166) | 本论文提出了一种基于多变量因果推断的新框架，用于去偏方面级情感分析，从而解决神经网络模型学习虚假相关性的问题。 |
| [^125] | [STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient Fine-Tuning of Large Language Models](https://arxiv.org/abs/2403.01165) | 本论文提出了一种新颖的方法，有效地将基于不确定性的主动学习和LoRA相结合，以解决大型语言模型数据高效微调中遇到的问题。 |
| [^126] | [A Survey of AI-generated Text Forensic Systems: Detection, Attribution, and Characterization](https://arxiv.org/abs/2403.01152) | 本文综述了AI生成文本取证系统，重点讨论了检测、归因和特征化三个主要方面，以实现对AI生成文本的实际理解。 |
| [^127] | [A Hybrid Model for Traffic Incident Detection based on Generative Adversarial Networks and Transformer Model](https://arxiv.org/abs/2403.01147) | 提出了一种结合Transformer和生成对抗网络的混合模型来提高交通事故检测的效果，并通过扩展数据集和实现平衡比例进行了验证 |
| [^128] | [ParallelPARC: A Scalable Pipeline for Generating Natural-Language Analogies](https://arxiv.org/abs/2403.01139) | 设计了ParallelPARC流水线，利用大型语言模型生成复杂段落类比数据集，评估各种类比类型，并展示出人类在类比识别中的优势。 |
| [^129] | [LLM-PQ: Serving LLM on Heterogeneous Clusters with Phase-Aware Partition and Adaptive Quantization](https://arxiv.org/abs/2403.01136) | 这项研究提出了LLM-PQ系统，通过采用自适应模型量化和相位感知分区，在异构GPU集群上提高了LLM服务的效率。 |
| [^130] | [LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation](https://arxiv.org/abs/2403.01131) | LLaMoCo是第一个旨在以代码对代码方式调整LLMs以解决优化问题的指令调优框架，通过全面指令集和新颖的两阶段学习策略，实现了优越的性能。 |
| [^131] | [OpenGraph: Towards Open Graph Foundation Models](https://arxiv.org/abs/2403.01121) | 该论文旨在通过开发一个通用图基础模型，以解决现有图神经网络在泛化到与训练数据显著不同的未见图数据时遇到的困难。 |
| [^132] | [Adversarial Testing for Visual Grounding via Image-Aware Property Reduction](https://arxiv.org/abs/2403.01118) | 提出了一种通过基于图像感知属性缩减的文本扰动方法，用于对抗性测试VG模型 |
| [^133] | [Distilling Text Style Transfer With Self-Explanation From LLMs](https://arxiv.org/abs/2403.01106) | CoTeX是一个利用大型语言模型和思维链提示来促进文本风格转移的框架，通过提炼LLMs的能力为处理非平行数据和平行数据的简化模型，在低资源情况下表现优于传统的监督微调和知识蒸馏方法，并通过透明的解释在风格转移过程中有显著优势。 |
| [^134] | [Feature Alignment: Rethinking Efficient Active Learning via Proxy in the Context of Pre-trained Models](https://arxiv.org/abs/2403.01101) | 通过代理进行特征对齐，以解决预先计算特征无法区分标记样本类别和避免通过代理模型选择样本时牺牲宝贵预训练信息的问题。 |
| [^135] | [COOL: A Conjoint Perspective on Spatio-Temporal Graph Neural Network for Traffic Forecasting](https://arxiv.org/abs/2403.01091) | 本文提出了一种名为COOL的Conjoint Spatio-Temporal图神经网络，旨在共同捕捉交通预测中的高阶关系。 |
| [^136] | [Teaching MLP More Graph Information: A Three-stage Multitask Knowledge Distillation Framework](https://arxiv.org/abs/2403.01079) | 提出了一个新的三阶段多任务知识蒸馏框架，使用位置编码来捕捉位置信息，引入神经热核处理图数据，通过隐藏层输出匹配提高学生多层感知机的性能。 |
| [^137] | [$\Gamma$-VAE: Curvature regularized variational autoencoders for uncovering emergent low dimensional geometric structure in high dimensional data](https://arxiv.org/abs/2403.01078) | $\Gamma$-VAE通过正则化曲率来解决非线性降维技术中的两个限制，可以揭示高维数据中的新兴低维几何结构 |
| [^138] | [GraphRCG: Self-conditioned Graph Generation via Bootstrapped Representations](https://arxiv.org/abs/2403.01071) | 提出了一种自条件图生成框架，通过自引导表示指导生成过程，明确建模和利用图分布，优于传统隐式捕获分布的方法。 |
| [^139] | [Towards Full Authorship with AI: Supporting Revision with AI-Generated Views](https://arxiv.org/abs/2403.01055) | 通过引入Textfocals，一个UI原型，提供LLM生成的摘要、问题和建议，支持写作过程，并鼓励反思和自主修订，用户可以在不直接生成文本的情况下维持对其写作的完整作者身份。 |
| [^140] | [Seeing Unseen: Discover Novel Biomedical Concepts via GeometryConstrained Probabilistic Modeling](https://arxiv.org/abs/2403.01053) | 提出了一种通过几何限制概率建模处理方法来解决生物医学数据中存在的非 i.i.d. 数据分布、类别不平衡等问题。 |
| [^141] | [A Library of Mirrors: Deep Neural Nets in Low Dimensions are Convex Lasso Models with Reflection Features](https://arxiv.org/abs/2403.01046) | 证明在1-D数据上训练神经网络等价于解决一个具有固定特征字典矩阵的凸Lasso问题，为全局最优网络和解空间提供了洞察。 |
| [^142] | [AutoAttacker: A Large Language Model Guided System to Implement Automatic Cyber-attacks](https://arxiv.org/abs/2403.01038) | 大型语言模型有望自动化攻击的先前和后续阶段，这可能会将组织性攻击从罕见的专家主导事件转变为频繁的自动化操作，不需要专业知识，并以自动化速度和规模进行执行，这可能从根本上改变全球计算机安全。 |
| [^143] | [Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks](https://arxiv.org/abs/2403.01031) | 介绍了一系列阿拉伯多模式大语言模型Peacock，展示了其在视觉推理任务上的出色性能和不断出现的方言潜力，并提出了一个用于评估阿拉伯语相关方面的新基准Henna |
| [^144] | [Reservoir Computing Using Measurement-Controlled Quantum Dynamics](https://arxiv.org/abs/2403.01024) | 该研究介绍了一种利用测量控制的量子动力学的水库计算系统，相较于传统的水库计算算法，它可以使用少量人工神经元实现快速可靠的预测，有潜力在容错应用中使用。 |
| [^145] | [Policy Optimization for PDE Control with a Warm Start](https://arxiv.org/abs/2403.01005) | 通过在减少-然后设计过程中增加策略优化步骤，来微调模型-based 控制器以补偿维度约简引起的建模错误，并将整体策略转变为减少-然后设计-然后适应的PDE控制方法。 |
| [^146] | [FlaKat: A Machine Learning-Based Categorization Framework for Flaky Tests](https://arxiv.org/abs/2403.01003) | 提出了一种名为FlaKat的新型分类框架，利用机器学习分类器快速准确地预测flaky测试的类别，提出了一种衡量分类器准确性的新评估指标FDC。 |
| [^147] | [Attribute Structuring Improves LLM-Based Evaluation of Clinical Text Summaries](https://arxiv.org/abs/2403.01002) | 属性结构化框架显著改进了基于LLM的临床文本摘要评估过程，提高了人工评注和自动度量之间的一致性。 |
| [^148] | [Leveraging Prompt-Based Large Language Models: Predicting Pandemic Health Decisions and Outcomes Through Social Media Language](https://arxiv.org/abs/2403.00994) | 该研究利用基于提示的大语言模型框架，研究了社交媒体语言模式与国家卫生趋势之间的关系，首次实现了将社交媒体语言模式与现实公共卫生趋势相联系的方法。 |
| [^149] | [On the Role of Information Structure in Reinforcement Learning for Partially-Observable Sequential Teams and Games](https://arxiv.org/abs/2403.00993) | 明确表示信息结构是分析和解决强化学习问题的重要组成部分。 |
| [^150] | [Merging Text Transformer Models from Different Initializations](https://arxiv.org/abs/2403.00986) | 研究了合并不同初始化的Transformer模型的技术，提出了一种模型合并技术以研究这些模型极小值之间的关系，并发现与模型平均相比，通过我们的方法合并这些模型始终可以获得较低的损失障碍。 |
| [^151] | [Even-Ifs From If-Onlys: Are the Best Semi-Factual Explanations Found Using Counterfactuals As Guides?](https://arxiv.org/abs/2403.00980) | 这里是中文总结出的一句话要点：研究对8种半事实方法进行了全面测试，发现反事实指导并非必要，而是... (由于篇幅限制，若有省略，请见谅) |
| [^152] | [Equipment Health Assessment: Time Series Analysis for Wind Turbine Performance](https://arxiv.org/abs/2403.00975) | 利用功能神经网络（FNN）和长短期记忆（LSTM）网络的集成方法来预测风力发电机功率输出，实现准确稳定的预测并检测性能恶化，以推动积极的维护策略和健康评估。 |
| [^153] | [Binary Gaussian Copula Synthesis: A Novel Data Augmentation Technique to Advance ML-based Clinical Decision Support Systems for Early Prediction of Dialysis Among CKD Patients](https://arxiv.org/abs/2403.00965) | 提出了一种新的数据增强技术 Binary Gaussian Copula Synthesis (BGCS)，用于解决基于机器学习的临床决策支持系统在早期预测慢性肾病患者透析需求中所面临的数据不平衡问题 |
| [^154] | [AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models](https://arxiv.org/abs/2403.00953) | AutoRD是一个自动化端到端系统，使用大型语言模型和医学知识图构建罕见疾病知识图，实现了整体F1得分47.3%，相对于基础LLM有14.4%的提升。 |
| [^155] | [Resilience of Entropy Model in Distributed Neural Networks](https://arxiv.org/abs/2403.00942) | 本文研究了分布式神经网络中熵模型对有意干扰和无意干扰的韧性，通过实验证明了熵模型的韧性。 |
| [^156] | [Scale-free Adversarial Reinforcement Learning](https://arxiv.org/abs/2403.00930) | 本文在马尔可夫决策过程中提出了首个无尺度对抗性学习算法框架SCB，在对抗性多臂赌博机和MDP设置中取得了关键突破。 |
| [^157] | [PRIME: Scaffolding Manipulation Tasks with Behavior Primitives for Data-Efficient Imitation Learning](https://arxiv.org/abs/2403.00929) | PRIME是一个基于行为原语设计的框架，通过将任务分解为原语序列并学习高级控制策略，显著提高了多阶段操作任务的性能表现。 |
| [^158] | [The Algorithm Configuration Problem](https://arxiv.org/abs/2403.00898) | 本文深入研究了算法配置问题，提出了一个全面框架，结合机器学习模型和启发式策略，划分了不同的解决方法，以明确路径来理解和解决算法配置中的复杂性。 |
| [^159] | [VisRec: A Semi-Supervised Approach to Radio Interferometric Data Reconstruction](https://arxiv.org/abs/2403.00897) | VisRec提出了一种模型-不可知的半监督学习方法，用于重建射电干扰数据，通过监督学习模块和无监督学习模块相结合，减少了对标记训练数据的需求，降低了射电天文学家的标注工作量 |
| [^160] | [DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2403.00896) | DiaHalu是第一个对话级幻觉评估基准，针对大型语言模型在对话级别上的幻觉问题进行研究。 |
| [^161] | [End-to-end Graph-Sequential Representation Learning for Accurate Recommendations](https://arxiv.org/abs/2403.00895) | 本文提出了一个新颖的多重表示学习框架，有效地结合了基于序列和基于图的推荐方法，显著改善了推荐性能。 |
| [^162] | [A systematic evaluation of large language models for generating programming code](https://arxiv.org/abs/2403.00894) | GPT-4在生成编程代码方面表现优异，特别是在选择最佳提示策略时，超过了其他大型语言模型和85%的人类参与者。 |
| [^163] | [A Regularization-based Transfer Learning Method for Information Extraction via Instructed Graph Decoder](https://arxiv.org/abs/2403.00891) | 提出了一种基于正则化的信息抽取迁移学习方法，通过指导图解码器实现数据集之间通用知识的迁移 |
| [^164] | [Improving Android Malware Detection Through Data Augmentation Using Wasserstein Generative Adversarial Networks](https://arxiv.org/abs/2403.00890) | 通过使用Wasserstein生成对抗网络生成的数据进行数据增强，该研究提出了一种利用卷积神经网络识别未知Android恶意软件应用程序的方法，并通过降低存储需求来改进Android恶意软件检测的效果。 |
| [^165] | [SEGAA: A Unified Approach to Predicting Age, Gender, and Emotion in Speech](https://arxiv.org/abs/2403.00887) | 本文提出了一种统一的方法来从语音中预测年龄、性别和情绪，通过深度学习模型探索了单一、多输出和顺序模型的比较，并提出了新颖的多输出学习架构。 |
| [^166] | [Text classification of column headers with a controlled vocabulary: leveraging LLMs for metadata enrichment](https://arxiv.org/abs/2403.00884) | 通过利用LLMs，我们提出了一种方法，使用ChatGPT-3.5、GoogleBard和GoogleGemini对列标题进行主题注释的元数据丰富化，研究它们在对领域特定主题进行分类的能力，并评估其内部一致性、机器对齐性和人机一致性。ChatGPT和GoogleGemini在内部一致性以及与人一致性方面优于GoogleBard。 |
| [^167] | [Dual-Granularity Medication Recommendation Based on Causal Inference](https://arxiv.org/abs/2403.00880) | 提出了DGMed框架，利用因果推断和创新的特征对齐方法进行双粒度药物推荐 |
| [^168] | [Crimson: Empowering Strategic Reasoning in Cybersecurity through Large Language Models](https://arxiv.org/abs/2403.00878) | Crimson系统通过将CVE与MITRE ATT&CK技术相关联，提升了大型语言模型在网络安全中的战略推理能力，实现了接近GPT-4性能水平，且在战略推理任务中表现优异。 |
| [^169] | [Word Order and World Knowledge](https://arxiv.org/abs/2403.00876) | 本研究探讨了词序如何影响语言模型从原始文本中归纳世界知识，发现一些固定词序在不同语言中表现更好或更差，而预训练语言模型中的Wov2Lex假设不成立。 |
| [^170] | [Enhancing Protein Predictive Models via Proteins Data Augmentation: A Benchmark and New Directions](https://arxiv.org/abs/2403.00875) | 本文将图片和文本的数据增强技术扩展到蛋白领域，提出了两种新的蛋白语义级增强方法，并将这些增强方法集成到一个增强池中，构建了一个名为自动蛋白增强（APA）的简单而有效的框架。 |
| [^171] | [DFIN-SQL: Integrating Focused Schema with DIN-SQL for Superior Accuracy in Large-Scale Databases](https://arxiv.org/abs/2403.00872) | DFIN-SQL是DIN-SQL的创新扩展，通过解决模式链接错误，提高了文本到SQL转换的准确性，并采用了提示技术和检索增强生成的交替策略。 |
| [^172] | [Teach LLMs to Phish: Stealing Private Information from Language Models](https://arxiv.org/abs/2403.00871) | 本研究提出了一种名为“神经钓鱼”的新型实用数据提取攻击，使对手能够成功地从大型语言模型中提取敏感信息，攻击成功率高达10%至50%。 |
| [^173] | [SoftTiger: A Clinical Foundation Model for Healthcare Workflows](https://arxiv.org/abs/2403.00868) | SoftTiger是一个专为医疗工作流设计的临床大型语言模型，通过处理临床笔记的结构化，实现了基本临床任务以及更复杂的下游临床任务的执行。 |
| [^174] | [Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes](https://arxiv.org/abs/2403.00867) | 本文提出了一种名为Gradient Cuff的方法，通过探索拒绝损失地形图来检测对大语言模型的越狱攻击，成功设计了一种有效的两步检测策略。 |
| [^175] | [Fast and Efficient Local Search for Genetic Programming Based Loss Function Learning](https://arxiv.org/abs/2403.00865) | 提出了一种新的基于遗传编程的元学习框架，通过局部搜索方法实现了任务和模型无关的损失函数学习，实验证实了该框架在各种监督学习任务上的多样性和性能。 |
| [^176] | [LLM-Ensemble: Optimal Large Language Model Ensemble Method for E-commerce Product Attribute Value Extraction](https://arxiv.org/abs/2403.00863) | 提出了一种名为LLM-ensemble的算法，用于集成不同大型语言模型，以提高电子商务产品属性值提取的性能。 |
| [^177] | [NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and Safety Adherence in Chinese Journalistic Editorial Applications](https://arxiv.org/abs/2403.00862) | NewsBench是一个评估LLMs在中国新闻写作水平和安全性遵从能力的基准框架，揭示了在创造性写作任务中LLMs相对不足的新闻伦理遵守方面的需求。 |
| [^178] | [Pivoting Retail Supply Chain with Deep Generative Techniques: Taxonomy, Survey and Insights](https://arxiv.org/abs/2403.00861) | 本文旨在研究如何利用深度生成模型（DGMs）重构现代零售供应链，通过提供DGMs的分类法、零售供应链中的应用案例回顾以及潜在利用DGMs解决零售问题的讨论。 |
| [^179] | [Parallel Algorithms for Exact Enumeration of Deep Neural Network Activation Regions](https://arxiv.org/abs/2403.00860) | 本研究提出了深度（和浅层）神经网络中精确枚举的并行算法，主要贡献包括新颖的算法框架和并行算法，实现了其中一种算法在多种网络架构上，并实验证明区域数量对运行时间的影响。 |
| [^180] | [Team Formation amidst Conflicts](https://arxiv.org/abs/2403.00859) | 本文提出了团队在冲突中形成的问题，并提供了高效的近似算法，能够模拟不同的现实场景，在教育环境和人力资源管理中表现出色，特别是通过在真实数据集上的测试和部署，展示了算法的优越性。 |
| [^181] | [Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs](https://arxiv.org/abs/2403.00858) | 通过提出的框架，我们训练了一种用于Llama 2 Chat 7B或更大模型的草案模型，实现了加速推理，仅占原始大小的1.64％。 |
| [^182] | [Speaker-Independent Dysarthria Severity Classification using Self-Supervised Transformers and Multi-Task Learning](https://arxiv.org/abs/2403.00854) | 提出了一种使用自监督变压器和多任务学习进行说话者无关的运动障碍严重度分类的方法，可自动评估运动障碍的严重程度。 |
| [^183] | [Enhancing Long-Term Recommendation with Bi-level Learnable Large Language Model Planning](https://arxiv.org/abs/2403.00843) | 利用大型语言模型的规划能力来增强长期推荐，使模型在个性化推荐中更有效地理解和应用任务解决原则 |
| [^184] | [Offline Fictitious Self-Play for Competitive Games](https://arxiv.org/abs/2403.00841) | 本文介绍了Off-FSP，这是竞争游戏的第一个实用的无模型离线RL算法，通过调整固定数据集的权重，使用重要性抽样，模拟与各种对手的互动。 |
| [^185] | [EyeGPT: Ophthalmic Assistant with Large Language Models](https://arxiv.org/abs/2403.00840) | EyeGPT是一个专门为眼科设计的大型语言模型，采用角色扮演、微调和检索增强生成等策略，提出了全面的多指标评估框架。 |
| [^186] | [ToolNet: Connecting Large Language Models with Massive Tools via Tool Graph](https://arxiv.org/abs/2403.00839) | ToolNet是一个插拔式框架，通过将工具组织成一个有向图，实现了将大型语言模型与数千个工具连接起来，扩展了工具使用的数量而仅有中等标记消耗的增加。 |
| [^187] | [CLLMs: Consistency Large Language Models](https://arxiv.org/abs/2403.00835) | 提出了一种新方法，通过精细调整目标LLM实现了对雅各比轨迹上固定点的一致性预测，有效提高了生成速度2.4倍到3.4倍。 |
| [^188] | [Virtual Reality for Understanding Artificial-Intelligence-driven Scientific Discovery with an Application in Quantum Optics](https://arxiv.org/abs/2403.00834) | 虚拟现实环境辅助研究人员理解人工智能生成的解决方案，展示了在量子光学实验中发现可解释配置的实用性 |
| [^189] | [Position Paper: Agent AI Towards a Holistic Intelligence](https://arxiv.org/abs/2403.00833) | 代理人人工智能旨在将大型基础模型整合到代理人行为中，挑战我们对学习和认知的理解 |
| [^190] | [Explainable Session-based Recommendation via Path Reasoning](https://arxiv.org/abs/2403.00832) | 通过路径推理的泛化层次强化学习框架提高了基于会话的推荐的可解释性，设计了多目标奖励机制和路径中间点奖励以应对顺序模式的跳过行为和增强知识图的探索效率。 |
| [^191] | [MedAide: Leveraging Large Language Models for On-Premise Medical Assistance on Edge Devices](https://arxiv.org/abs/2403.00830) | MedAide是一款利用微型语言模型与LangChain集成，为资源受限的边缘设备提供高效医疗诊断和支持的现场医疗聊天机器人，通过模型优化和多样的医疗数据集训练来提升其领域特定能力。 |
| [^192] | [TroubleLLM: Align to Red Team Expert](https://arxiv.org/abs/2403.00829) | TroubleLLM是第一个用于生成关于LLMs安全问题的可控测试提示的LLM，通过广泛实验和人类评估展示了其在生成质量和生成可控性方面的优越性 |
| [^193] | [Deep Learning Detection Method for Large Language Models-Generated Scientific Content](https://arxiv.org/abs/2403.00828) | 提出了一种新的ChatGPT生成科学文本检测方法AI-Catcher，该方法集成了多层感知器（MLP）和卷积神经网络（CNN），是一个多模态模型，用于检测大型语言模型生成的科学内容。 |
| [^194] | [Self-Refinement of Language Models from External Proxy Metrics Feedback](https://arxiv.org/abs/2403.00827) | 本文提出了Proxy Metric-based Self-Refinement (ProMiSe)方法，通过外部指标反馈指导语言模型在质量关键维度上进行自我完善，从而改进响应质量。 |
| [^195] | [Information Flow Routes: Automatically Interpreting Language Models at Scale](https://arxiv.org/abs/2403.00824) | 这项研究提出了一种自动解释语言模型的方法，通过构建信息流路由图来揭示模型内部的关键节点和操作，相比于现有方法的激活修补，这种方法通过归因实现，在不需要人工干预设计的情况下可以有效地分析模型行为。 |
| [^196] | [Adapting to Teammates in a Cooperative Language Game](https://arxiv.org/abs/2403.00823) | 这项研究提出了第一个适应Codenames游戏的Agent，采用集成方法来确定最佳匹配的内部专家Agent，从而使Agent能够根据特定队友进行适应。 |
| [^197] | [InteraRec: Interactive Recommendations Using Multimodal Large Language Models](https://arxiv.org/abs/2403.00822) | InteraRec引入了一种复杂的交互式推荐框架，与传统方法不同，它不仅依赖Weblog生成推荐，还捕获用户导航时网页的高频截图。 |
| [^198] | [CFRet-DVQA: Coarse-to-Fine Retrieval and Efficient Tuning for Document Visual Question Answering](https://arxiv.org/abs/2403.00816) | 该研究提出了一种名为CFRet-DVQA的方法，通过检索和高效调优，解决了文档视觉问答中定位信息和限制模型输入的长度等问题，进一步提升了答案的生成性能。 |
| [^199] | [RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic Health Records](https://arxiv.org/abs/2403.00815) | RAM-EHR通过增强检索并利用总结知识，提高了针对电子健康记录的临床预测效果。 |
| [^200] | [UrbanGPT: Spatio-Temporal Large Language Models](https://arxiv.org/abs/2403.00813) | 都市GPT旨在建立一个具有强大泛化能力的时空模型，借鉴大型语言模型的成就。 |
| [^201] | [LoRA Meets Dropout under a Unified Framework](https://arxiv.org/abs/2403.00812) | LoRA是一个轻量级的参数高效微调方法，该论文研究了LoRA与dropout方法在模型定制中的矛盾，重新审视了transformer-specific的dropout方法，并建立了它们之间的数学和经验上的等价性和区别。 |
| [^202] | [Cognitive Bias in High-Stakes Decision-Making with LLMs](https://arxiv.org/abs/2403.00811) | 提出了BiasBuster框架，用于揭示、评估和减轻LLMs中的认知偏见，特别是在高风险决策任务中，通过开发包含16,800个提示的数据集和测试多种偏见缓解策略，并提出一种利用LLMs自身来消除其提示中偏见的新方法。 |
| [^203] | [Bootstrapping Cognitive Agents with a Large Language Model](https://arxiv.org/abs/2403.00810) | 通过利用大型语言模型中的知识，我们将认知模型与大语言模型相结合，提出了一种通过具身Agent完成任务的框架，相较于完全基于大语言模型的Agent，具有更好的效率。 |
| [^204] | [Abdelhak at SemEval-2024 Task 9 : Decoding Brainteasers, The Efficacy of Dedicated Models Versus ChatGPT](https://arxiv.org/abs/2403.00809) | 本研究提出了一个专用模型，在解决谜题任务中表现出色，并与ChatGPT进行了比较性能分析，发现专用模型在横向思维和问题解决方面具有明显优势。 |
| [^205] | [IPED: An Implicit Perspective for Relational Triple Extraction based on Diffusion Model](https://arxiv.org/abs/2403.00808) | 提出了一种基于扩散模型的IPED方法，采用隐式答案策略完成表格，在关系三元组提取中取得了有效结果 |
| [^206] | [A New Dynamic Distributed Planning Approach: Application to DPDP Problems](https://arxiv.org/abs/2403.00805) | 提出了一种新的动态分布式规划方法，能够根据代理引入的动作集变化和环境变化进行计划生成。 |
| [^207] | [Uncovering Customer Issues through Topological Natural Language Analysis](https://arxiv.org/abs/2403.00804) | 提出了一种利用自然语言技术和拓扑数据分析监控新兴和热门客户问题的机器学习算法。 |
| [^208] | [LiMAML: Personalization of Deep Recommender Models via Meta Learning](https://arxiv.org/abs/2403.00803) | 该论文介绍了一种通过元学习实现个性化深度推荐模型的创新解决方案，能够根据最新用户互动信号频繁更新模型，以确保向不同成员提供相关且更新的体验。 |
| [^209] | [Towards a Theoretical Understanding of Two-Stage Recommender Systems](https://arxiv.org/abs/2403.00802) | 这里是中文总结出的一句话要点: 该论文研究了两阶段推荐系统的理论行为，证明了其向最佳推荐系统的强收敛性，同时揭示了它在输入特征的固有维度上实现更快收敛的特性。 |
| [^210] | [Brain-Inspired Two-Stage Approach: Enhancing Mathematical Reasoning by Imitating Human Thought Processes](https://arxiv.org/abs/2403.00800) | 通过模仿人类思维过程，在数学推理任务中提出的Brain方法实现了最先进的性能，并发现计划可以从自然语言、代码或形式语言中明确提取出来。 |
| [^211] | [An Empirical Study of Data Ability Boundary in LLMs' Math Reasoning](https://arxiv.org/abs/2403.00799) | 通过确定最优路径集，本研究拓展了LLMs在数学推理任务中的能力边界，提出了一种监督数据策略，通过混合不同类型数据的最小最优集来累积增强模型能力，并实现了SOTA性能。 |
| [^212] | [Enhancing Mean-Reverting Time Series Prediction with Gaussian Processes: Functional and Augmented Data Structures in Financial Forecasting](https://arxiv.org/abs/2403.00796) | 本论文通过使用高斯过程在金融预测中探索功能和增强数据结构，提供了一种能够预测整个概率分布并进行长期预测的方法，对于准确预测和决策制定具有重要意义 |
| [^213] | [Executing Natural Language-Described Algorithms with Large Language Models: An Investigation](https://arxiv.org/abs/2403.00795) | 大语言模型可以有效地执行用自然语言描述的程序，尤其是在不涉及大量数字计算的情况下。 |
| [^214] | [Getting Serious about Humor: Crafting Humor Datasets with Unfunny Large Language Models](https://arxiv.org/abs/2403.00794) | 利用大型语言模型生成合成数据，可以帮助改进幽默检测，特别是通过取消幽默元素来评估模型性能。 |
| [^215] | [$\textit{L+M-24}$: Building a Dataset for Language + Molecules @ ACL 2024](https://arxiv.org/abs/2403.00791) | 这个论文介绍了$\textit{L+M-24}$数据集，该数据集专为ACL 2024年的语言+分子研讨会共享任务而设计，重点关注自然语言在分子设计中的三个关键优势：组合性、功能性和抽象性。 |
| [^216] | [Structuring Concept Space with the Musical Circle of Fifths by Utilizing Music Grammar Based Activations](https://arxiv.org/abs/2403.00790) | 提出了一种利用音乐语法调节尖峰神经网络激活的新颖方法，通过应用音乐理论中的和弦进行规则，展示了如何自然地跟随其他激活，最终将概念的映射结构化为音乐五度圆。 |
| [^217] | [PRECISE Framework: GPT-based Text For Improved Readability, Reliability, and Understandability of Radiology Reports For Patient-Centered Care](https://arxiv.org/abs/2403.00788) | 本研究提出并评估了PRECISE框架，利用GPT-4技术提供更易读的胸部X射线报告，以进一步提高放射学报告的可读性、可靠性和可理解性，有助于推动以患者为中心的护理。 |
| [^218] | [Utilizing BERT for Information Retrieval: Survey, Applications, Resources, and Challenges](https://arxiv.org/abs/2403.00784) | BERT的引入为信息检索领域带来了突破，研究者们将其应用于解决实际问题，并通过综合分析其在信息检索中的应用方法，为学术界和工业界提供了有益的参考。 |
| [^219] | [On the Roles of LLMs in Planning: Embedding LLMs into Planning Graphs](https://arxiv.org/abs/2403.00783) | 通过将LLMs嵌入到图形规划中，本文研究了LLMs在现成规划框架中的作用，并提出了一种新颖的LLMs-based规划框架。 |
| [^220] | [Ploutos: Towards interpretable stock movement prediction with financial large language model](https://arxiv.org/abs/2403.00782) | 提出了Ploutos，一个新型金融LLM框架，通过PloutosGen和PloutosGPT灵活融合文本和数值信息，提供可解释的股票走势预测 |
| [^221] | [ChatDiet: Empowering Personalized Nutrition-Oriented Food Recommender Chatbots through an LLM-Augmented Framework](https://arxiv.org/abs/2403.00781) | 这项研究介绍了ChatDiet，一个借助LLM技术构建的框架，能够帮助个性化营养导向食品推荐聊天机器人提供个性化和可解释的推荐。 |
| [^222] | [Empirical and Experimental Insights into Data Mining Techniques for Crime Prediction: A Comprehensive Survey](https://arxiv.org/abs/2403.00780) | 这篇论文提供了对犯罪预测技术的全面分析，提出了一种细分犯罪预测算法的方法论分类法，并通过经验和实验评估来对这些技术进行排名。 |
| [^223] | [Do Weibo platform experts perform better at predicting stock market?](https://arxiv.org/abs/2403.00772) | 使用神经网络结合BERT情感分类和LSTM时间序列模型在微博平台授权和未授权金融顾问的背景下进行股市预测 |
| [^224] | [An Architecture for Unattended Containerized (Deep) Reinforcement Learning with Webots](https://arxiv.org/abs/2403.00765) | 该论文提出了一种用于Webots的无人监控容器化(深度)强化学习体系结构，针对机器人 Robotino 训练强化学习代理，同时强调模拟环境和数据科学家模型开发环境的分离这一不太被讨论的主题。 |
| [^225] | [Toward Autonomous Cooperation in Heterogeneous Nanosatellite Constellations Using Dynamic Graph Neural Networks](https://arxiv.org/abs/2403.00692) | 使用动态图神经网络模型和启发式算法，以解决地球观测任务中异构纳米卫星星座自主合作中的全球卫星通信安排问题 |
| [^226] | [ROME: Memorization Insights from Text, Probability and Hidden State in Large Language Models](https://arxiv.org/abs/2403.00510) | ROME提出了一种新方法，通过比较记忆和非记忆样本之间的差异，探索大型语言模型中的记忆化，这有助于在不访问训练数据的情况下了解模型记忆的洞察和影响因素。 |
| [^227] | [On the Scaling Laws of Geographical Representation in Language Models](https://arxiv.org/abs/2402.19406) | 地理知识可以在大型语言模型中观察到，随着模型规模增加而一致扩展，但更大的模型无法消除训练数据中的地理偏见。 |
| [^228] | [How to Understand "Support"? An Implicit-enhanced Causal Inference Approach for Weakly-supervised Phrase Grounding](https://arxiv.org/abs/2402.19116) | 提出了一种隐式增强因果推断方法（IECI），用于解决弱监督短语定位任务中的挑战，通过标注高质量数据集进行评估，并相比基线方法展现出明显优势。 |
| [^229] | [Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation](https://arxiv.org/abs/2402.18920) | 该研究提出了一个统一的框架，结合光谱和空间域的映射，以预测3D形状之间的点对应和形状插值，相比先前方法，取得更准确、平滑的点对应结果，并且在计算上更高效。 |
| [^230] | [Data Interpreter: An LLM Agent For Data Science](https://arxiv.org/abs/2402.18679) | 本研究引入了数据解释器，采用动态规划、工具集成和逻辑错误识别等关键技术，旨在增强数据科学中的问题解决能力。 |
| [^231] | [Exploring Privacy and Fairness Risks in Sharing Diffusion Models: An Adversarial Perspective](https://arxiv.org/abs/2402.18607) | 本文从对抗性的角度研究了分享扩散模型可能存在的隐私和公平风险，特别是探讨了在一方使用私人数据训练模型后提供给另一方黑盒访问权限的情况。 |
| [^232] | [Exploring the Impact of Large Language Models on Recommender Systems: An Extensive Review](https://arxiv.org/abs/2402.18590) | 大型语言模型在推荐系统中展现出卓越的推荐能力和语言理解，重塑了推荐任务的基础。 |
| [^233] | [Is Crowdsourcing Breaking Your Bank? Cost-Effective Fine-Tuning of Pre-trained Language Models with Proximal Policy Optimization](https://arxiv.org/abs/2402.18284) | 提出了一种自监督文本排序方法，利用近端策略优化对语言模型进行微调，消除了对人工注释员的需求，实验结果表明该方法训练的模型在各项得分方面明显优于基线 |
| [^234] | [Lemur: Log Parsing with Entropy Sampling and Chain-of-Thought Merging](https://arxiv.org/abs/2402.18205) | Lemur提出了一种先进的日志解析框架，采用熵抽样和思维链合并，解决了日志解析中存在的人工规则依赖和语义信息忽略等问题。 |
| [^235] | [Mixer is more than just a model](https://arxiv.org/abs/2402.18007) | Mixer的创新之处在于将通道和令牌信息融合，代表了信息提取范式，还可以根据不同需求创建更适合特定任务的混合器。 |
| [^236] | [REPrune: Channel Pruning via Kernel Representative Selection](https://arxiv.org/abs/2402.17862) | REPrune是一种新颖的通道修剪技术，通过模拟核修剪，并结合聚类和滤波器选择，实现了更精细但结构化的修剪粒度，促进了在训练CNNs期间的高效、渐进式修剪。 |
| [^237] | [When Your AI Deceives You: Challenges with Partial Observability of Human Evaluators in Reward Learning](https://arxiv.org/abs/2402.17747) | RLHF在考虑部分观察性时可能导致策略欺骗性地夸大性能或过度辩护行为，我们提出了数学条件来解决这些问题，并警告不要盲目应用RLHF在部分可观测情况下。 |
| [^238] | [LDB: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step](https://arxiv.org/abs/2402.16906) | LDB是一个新颖的调试框架，可以让大型语言模型通过运行时执行信息来完善生成的程序。 |
| [^239] | [Improving LLM-based Machine Translation with Systematic Self-Correction](https://arxiv.org/abs/2402.16379) | 引入了名为TER的系统LLM自校正翻译框架，成功帮助LLMs提高翻译质量，具有更优越的系统性和可解释性。 |
| [^240] | [Citation-Enhanced Generation for LLM-based Chatbot](https://arxiv.org/abs/2402.16063) | 提出一种基于引文增强的LLM聊天机器人生成方法，采用检索模块搜索支持文档来解决幻觉内容产生的问题。 |
| [^241] | [Rethinking Software Engineering in the Era of Foundation Models: A Curated Catalogue of Challenges in the Development of Trustworthy FMware](https://arxiv.org/abs/2402.15943) | FMware的独特属性和基础模型的内在限制导致了新的软件工程挑战，本文总结了这些挑战并提出了创新路径。 |
| [^242] | [LLMs Can Defend Themselves Against Jailbreaking in a Practical Manner: A Vision Paper](https://arxiv.org/abs/2402.15727) | 本文提出了一种名为SELFDEFEND的轻量级实用防御方法，可以在最小延迟下抵御所有现有的越狱攻击。 |
| [^243] | [Query Augmentation by Decoding Semantics from Brain Signals](https://arxiv.org/abs/2402.15708) | 提出了一种名为Brain-Aug的方法，通过从脑信号中解码的语义信息增强查询，可以生成更准确的查询，改善文档排序性能，特别适用于模糊查询。 |
| [^244] | [A Relation-Interactive Approach for Message Passing in Hyper-relational Knowledge Graphs](https://arxiv.org/abs/2402.15140) | 提出了一种消息传递的图编码器ReSaE，具有全局关系结构意识能力，强调了关系在消息传递过程中的交互，并优化了用于链接预测任务的读取结构，在超关系知识图上表现出色。 |
| [^245] | [OmniPred: Language Models as Universal Regressors](https://arxiv.org/abs/2402.14547) | 本文提出了OmniPred框架，用于训练语言模型作为通用的端到端回归器，实验证明，在多个任务上训练时，语言模型能够显著优于传统回归模型。 |
| [^246] | [A Collision-Aware Cable Grasping Method in Cluttered Environment](https://arxiv.org/abs/2402.14498) | 提出了一种碰撞感知的电缆抓取方法，通过CG-CNN和数据集生成技术，在复杂环境中实现稳健电缆抓取，并取得了出色的成功率。 |
| [^247] | [E2USD: Efficient-yet-effective Unsupervised State Detection for Multivariate Time Series](https://arxiv.org/abs/2402.14041) | E2USD提出了一种有效的无监督多元时间序列状态检测方法，利用了快速傅里叶变换和双视图嵌入模块进行编码，以及通过对抗学习方法消除假阴性，从而实现了SOTA准确性并显著降低了计算开销。 |
| [^248] | [SDXL-Lightning: Progressive Adversarial Diffusion Distillation](https://arxiv.org/abs/2402.13929) | 提出了一种结合渐进和对抗性蒸馏的扩散蒸馏方法，在文本到图像生成任务中取得了新的最先进结果，并开源了相应模型。 |
| [^249] | [NeuralDiffuser: Controllable fMRI Reconstruction with Primary Visual Feature Guided Diffusion](https://arxiv.org/abs/2402.13809) | NeuralDiffuser引入主视觉特征引导，扩展了LDM方法的自下而上过程，以实现忠实的语义和细节。 |
| [^250] | [DSLR: Diversity Enhancement and Structure Learning for Rehearsal-based Graph Continual Learning](https://arxiv.org/abs/2402.13711) | DSLR提出了一种基于覆盖范围的多样性方法，以解决基于重播的图持续学习中回放节点过于集中导致过拟合和灾难性遗忘的问题。 |
| [^251] | [NeRF Solves Undersampled MRI Reconstruction](https://arxiv.org/abs/2402.13226) | NeRF技术利用神经辐射场概念解决了MRI重建中的欠采样问题，通过神经表示从欠采样的$k$-space数据中得到高维MR图像，并研究了有效的欠采样策略。 |
| [^252] | [Modality-Aware Integration with Large Language Models for Knowledge-based Visual Question Answering](https://arxiv.org/abs/2402.12728) | 提出了一种模态感知的LLM集成方法（MAIL）用于针对KVQA，通过细致地利用多模态知识来处理图像理解和知识推理。 |
| [^253] | [PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images](https://arxiv.org/abs/2402.12721) | 提出了一个新颖的神经网络模型 PAC-FNO，通过在频域操作可以处理不同分辨率的图像，解决了传统方法在处理这类问题上的计算成本高的挑战。 |
| [^254] | [Transformer-based Causal Language Models Perform Clustering](https://arxiv.org/abs/2402.12151) | Transformer-based因果语言模型通过在隐藏空间内对数据进行聚类来学习任务特定信息，这种聚类过程在学习中动态演变，并有助于处理未见实例。 |
| [^255] | [From Reals to Logic and Back: Inventing Symbolic Vocabularies, Actions and Models for Planning from Raw Data](https://arxiv.org/abs/2402.11871) | 本文提出了一种从未标记高维实值机器人轨迹开始自主学习通用的逻辑相关表示，这些表示构成了自动发明的PDDL-like域模型。 |
| [^256] | [An Empirical Evaluation of Neural and Neuro-symbolic Approaches to Real-time Multimodal Complex Event Detection](https://arxiv.org/abs/2402.11403) | 本研究评估神经和神经符号方法在多模态复杂事件检测中的效果，特别关注时间推理，实验发现神经符号方法在较少数据下表现更好。 |
| [^257] | [Aligning Large Language Models by On-Policy Self-Judgment](https://arxiv.org/abs/2402.11253) | 本文提出了一个新颖的对齐框架SELF-JUDGE，通过增加式监督微调（JSFT）训练一个同时充当策略和评判器的单一模型，实现了参数高效的基于政策学习，无需额外的奖励模型。 |
| [^258] | [Accelerating Semi-Asynchronous Federated Learning](https://arxiv.org/abs/2402.10991) | 提出了一种考虑贡献的异步联邦学习方法，动态调整接收到的更新的处理方式，以解决现实情况下同步上传数据可能出现的缓慢和不可靠问题。 |
| [^259] | [MC-DBN: A Deep Belief Network-Based Model for Modality Completion](https://arxiv.org/abs/2402.09782) | MC-DBN是一种基于深度信念网络的模态补全模型，利用完整数据的隐式特征来弥补附加不完整数据的差距，提高预测准确性。 |
| [^260] | [Exploring Neuron Interactions and Emergence in LLMs: From the Multifractal Analysis Perspective](https://arxiv.org/abs/2402.09099) | 该论文通过多重分形分析视角，深入研究了LLMs中神经元相互作用和出现现象。通过引入自组织和多重分形分析的概念，研究了神经元相互作用的动态演化过程，尤其关注训练中的复杂行为。通过提出基于神经元的多重分形分析方法，实现了对大型模型中神经元相互作用的定量分析。 |
| [^261] | [Premise Order Matters in Reasoning with Large Language Models](https://arxiv.org/abs/2402.08939) | 对大型语言模型（LLMs）进行推理任务时，论据的顺序非常重要，尤其是在演绎推理任务中，按照提示的真实证明顺序呈现论据可以显著提高模型的准确性。 |
| [^262] | [Forecasting high-impact research topics via machine learning on evolving knowledge graphs](https://arxiv.org/abs/2402.08640) | 通过机器学习预测未发布研究想法的影响力，我们使用一个由超过2100万篇科学论文构建的演化知识图谱，结合论文内容和历史引用的信息，高准确度预测未来的演化网络动态和新的研究方向的影响力。 |
| [^263] | [Recursive Joint Simulation in Games](https://arxiv.org/abs/2402.08128) | 本文研究了游戏中AI代理之间的递归协同模拟的互动方式，并证明了这种方式与原始游戏的无限重复版本在战略上是等价的。 |
| [^264] | [Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment Analysis](https://arxiv.org/abs/2402.07787) | 这篇论文提出了一种可扩展的多粒度融合网络（EMGF）用于基于方面的情感分析，通过整合不同的语言和结构特征，包括句法依赖、组成、注意力语义和外部知识图谱等，来提高情感分析的性能和准确性。 |
| [^265] | [CPSDBench: A Large Language Model Evaluation Benchmark and Baseline for Chinese Public Security Domain](https://arxiv.org/abs/2402.07234) | CPSDBench是一个专门为中国公共安全领域量身定制的大型语言模型评估基准，通过整合实际场景中收集的公共安全相关数据集，针对文本分类、信息提取、问题回答和文本生成四个关键维度全面评估LLMs的性能，并引入创新的评估指标，提高了对现有模型在解决公共安全问题方面性能的理解。 |
| [^266] | [Function Aligned Regression: A Method Explicitly Learns Functional Derivatives from Data](https://arxiv.org/abs/2402.06104) | 该论文提出了一种名为FAR的方法，通过捕捉函数导数来更好、更高效地拟合底层真实函数。在合成数据集和八个真实世界任务中证明了该方法的有效性。 |
| [^267] | [The last Dance : Robust backdoor attack via diffusion models and bayesian approach](https://arxiv.org/abs/2402.05967) | 本文介绍了一种通过扩散模型和贝叶斯方法进行鲁棒后门攻击的方法，具体应用于音频Transformer模型，并证明了攻击的可行性。 |
| [^268] | [Mesoscale Traffic Forecasting for Real-Time Bottleneck and Shockwave Prediction](https://arxiv.org/abs/2402.05663) | 该论文介绍了一种在实时中尺度交通预测中具有最先进效果的深度预测方法SA-LSTM，通过将自注意力与长短期记忆结合，实现了对多步预测的改进，并在短期和长期预测之间取得了平衡。 |
| [^269] | [Minecraft-ify: Minecraft Style Image Generation with Text-guided Image Editing for In-Game Application](https://arxiv.org/abs/2402.05448) | 本文提出了一种用于Minecraft游戏应用的图像生成和编辑系统"Minecraft-ify"，能够生成针对3D虚拟角色的面部聚焦图像，并支持使用文本进行图像编辑，提供了更自由和优化的用户体验。 |
| [^270] | [SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models](https://arxiv.org/abs/2402.05044) | SALAD-Bench是一个针对大语言模型的全面安全基准，通过其大规模、丰富的分类和多功能性，以及对攻击和防御方法的评估，实现了对LLMs的有效管理和保护。 |
| [^271] | [RL-VLM-F: Reinforcement Learning from Vision Language Foundation Model Feedback](https://arxiv.org/abs/2402.03681) | RL-VLM-F是一种通过视觉语言基础模型反馈的强化学习方法，能够自动生成有效的奖励函数和策略，从而解决了传统强化学习中奖励设计的挑战。 |
| [^272] | [SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM](https://arxiv.org/abs/2402.03246) | SGS-SLAM是一种基于三维高斯点云的语义稠密SLAM系统，通过多通道优化和关键帧优化，实现了高质量的重建和精确的语义分割。 |
| [^273] | [C-RAG: Certified Generation Risks for Retrieval-Augmented Language Models](https://arxiv.org/abs/2402.03181) | C-RAG是第一个用于认证检索增强语言模型生成风险的框架，通过提供符合风险分析和生成风险的上界，确保生成结果的可信性。 |
| [^274] | [ToonAging: Face Re-Aging upon Artistic Portrait Style Transfer](https://arxiv.org/abs/2402.02733) | 本研究提出了一种新颖的一阶段方法，结合肖像风格转换实现人脸逆龄化，解决了NPR图像上编辑年龄的问题，并在单个生成步骤中执行。该方法利用了现有的人脸逆龄化和风格转换网络，并且独特地融合了不同的潜在向量，从而保留了面部属性。 |
| [^275] | [A Truly Joint Neural Architecture for Segmentation and Parsing](https://arxiv.org/abs/2402.02564) | 本文通过引入一个联合神经网络架构，在形态丰富的语言中实现了同时进行形态分割和句法分析的任务。通过提供基于格子的表示法，保留了输入的所有形态模糊性，有效解决了以往基于神经网络的依存句法分析器的局限性。 |
| [^276] | [Learning General Parameterized Policies for Infinite Horizon Average Reward Constrained MDPs via Primal-Dual Policy Gradient Algorithm](https://arxiv.org/abs/2402.02042) | 该论文研究了无限时域平均回报受限MDPs的参数化通用策略，并提出了一种基于原始-对偶策略梯度算法，可在保证低遗憾的情况下管理约束条件，达到全局最优策略。算法的分析表明，其目标遗憾和约束违反均为 $\tilde{\mathcal{O}}({T}^{3/4})$。 |
| [^277] | [Prompt-Driven LLM Safeguarding via Directed Representation Optimization](https://arxiv.org/abs/2401.18018) | 通过研究模型表示的影响，我们发现安全提示并没有明显增强恶意和无害查询之间的区分，并提出了一种名为DRO的方法，用于自动优化安全提示。 |
| [^278] | [DocFinQA: A Long-Context Financial Reasoning Dataset](https://arxiv.org/abs/2401.06915) | 引入了一个长文档财务问答任务，将平均上下文长度从700个词扩展到123k个词，对于大型语言模型在金融领域具有重要挑战。 |
| [^279] | [Hutchinson Trace Estimation for High-Dimensional and High-Order Physics-Informed Neural Networks](https://arxiv.org/abs/2312.14499) | 介绍了 Hutchinson 迹估计（HTE），通过将整个 Hessian 矩阵的计算转换为 Hessian 矢量乘积（HVP），解决了 PINNs 处理高维和高阶 PDE 的挑战。 |
| [^280] | [Reconciling Shared versus Context-Specific Information in a Neural Network Model of Latent Causes](https://arxiv.org/abs/2312.08519) | LCNet是一个神经网络模型，能够通过学习存储共享结构，同时使用上下文模块表示特定上下文结构，成功实现了在不同任务中提取共享结构并避免灾难性干扰的功能；并且能够捕捉人类数据中的课程效应。 |
| [^281] | [Language-assisted Vision Model Debugger: A Sample-Free Approach to Finding and Fixing Bugs](https://arxiv.org/abs/2312.05588) | 提出了一种语言辅助视觉模型调试方法，利用文本而不是图像来诊断视觉模型中的错误，通过连接CLIP的嵌入空间和出错视觉模型，以及利用CLIP的文本分支作为代理模型来发现错误。 |
| [^282] | [MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction-Following](https://arxiv.org/abs/2312.02436) | MUFFIN是一个新的指示遵循数据集策划方案，通过自动按比例扩大任务，通过多种输入方面使任务丰富多样。 |
| [^283] | [Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs through a Global Scale Prompt Hacking Competition](https://arxiv.org/abs/2311.16119) | 通过全球规模的Prompt Hacking竞赛，揭示了LLMs存在的系统漏洞，验证了当前LLMs可以被提示注入攻击操纵。 |
| [^284] | [High-fidelity Person-centric Subject-to-Image Synthesis](https://arxiv.org/abs/2311.10329) | 提出了Face-diffuser，一个有效的协作生成流水线，用于解决主体到图像合成中的训练不平衡和质量妥协问题。 |
| [^285] | [MELA: Multilingual Evaluation of Linguistic Acceptability](https://arxiv.org/abs/2311.09033) | MELA是第一个覆盖10种语言的多语言语言可接受性基准，通过分析XLM-R的微调权重，探讨了跨语言迁移困难性，结果表明在上下文示例方面ChatGPT表现良好但仍落后于经过微调的XLM-R。 |
| [^286] | [Reinforcement learning for freeform robot design](https://arxiv.org/abs/2310.05670) | 使用策略梯度设计具有任意外部和内部结构的自由形态机器人，通过放置或移除原子建筑块束形成高级非参数宏结构。 |
| [^287] | [Language Models Represent Space and Time](https://arxiv.org/abs/2310.02207) | 现代大型语言模型学习到了丰富的时空表征，包括学习到了空间和时间的线性表征以及个体的“空间神经元”和“时间神经元”。 |
| [^288] | [Active-Perceptive Motion Generation for Mobile Manipulation](https://arxiv.org/abs/2310.00433) | 介绍了一种用于移动操纵器的主动感知流水线，可以生成对操纵任务有信息性的运动，通过最大化视觉信息增益和任务目标的权衡来提高抓取成功率。 |
| [^289] | [MATNet: Multi-Level Fusion Transformer-Based Model for Day-Ahead PV Generation Forecasting](https://arxiv.org/abs/2306.10356) | 提出了MATNet，结合了人工智能范式与光伏发电的物理先验知识，通过多级联合融合方法进行日前光伏发电预测 |
| [^290] | [Safe Offline Reinforcement Learning with Real-Time Budget Constraints](https://arxiv.org/abs/2306.00603) | 提出了一种名为TREBI的新方法，在离线设置下解决强化学习中实时预算约束的问题，通过轨迹分布建模和扩散模型规划来提供性能保证。 |
| [^291] | [Discovering Latent Knowledge in Language Models Without Supervision](https://arxiv.org/abs/2212.03827) | 通过在语言模型的内部激活中直接发现潜在知识的方式，我们提出了一种纯粹无监督的方法，可以准确回答未标记模型激活的是非问题，并且在大型语言模型中恢复多样知识。 |
| [^292] | [SMiLE: Schema-augmented Multi-level Contrastive Learning for Knowledge Graph Link Prediction](https://arxiv.org/abs/2210.04870) | 提出了一种新颖的基于模式增强的多层对比学习框架（SMiLE），用于知识图谱链接预测，通过利用网络模式作为先验约束来提高链接预测的准确性和上下文一致性。 |
| [^293] | [Approximate Nash Equilibrium Learning for n-Player Markov Games in Dynamic Pricing](https://arxiv.org/abs/2207.06492) | 该论文提出了一种在动态定价环境中寻找近似纳什均衡的新方法，利用神经网络表示策略和最小化状态，进行纳什 Q 学习。 |
| [^294] | [Multi-View Hypercomplex Learning for Breast Cancer Screening](https://arxiv.org/abs/2204.05798) | 本文提出了一种基于参数化超复数神经网络的多视图乳腺癌分类方法，能够模拟并利用乳房X光检查的不同视图之间的相关性，从而提高肿瘤识别效果。 |
| [^295] | [CMGAN: Conformer-based Metric GAN for Speech Enhancement](https://arxiv.org/abs/2203.15149) | 本文提出了一种基于Conformer的度量生成对抗网络（CMGAN）用于时频域的语音增强，通过优化生成器以使得增强估计语音相对应的评估分数来进一步提高增强语音的质量。 |
| [^296] | [Similar Cases Recommendation using Legal Knowledge Graphs](https://arxiv.org/abs/2107.04771) | 使用法律知识图谱预测印度法院裁决类似案例的解决方案，并分析大型语言模型对该任务的影响。 |
| [^297] | [Private Prediction Sets](https://arxiv.org/abs/2102.06202) | 该研究提出了一个基于符合性预测的框架，可以在保护个人隐私的同时返回可靠的不确定性量化的预测集。 |
| [^298] | [Deep Attentive Features for Prostate Segmentation in 3D Transrectal Ultrasound](https://arxiv.org/abs/1907.01743) | 本文提出了一种新型的3D深度神经网络，配备着关注模块，通过充分利用卷积神经网络不同层中编码的互补信息，实现了在经直肠超声图像中更好地前列腺分割，通过选择性地整合不同层级的特征来提高前列腺分割性能 |
| [^299] | [FP6-LLM: Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design.](http://arxiv.org/abs/2401.14112) | FP6-LLM提出了一种支持六位量化的GPU算法-系统协同设计方案，实现了在大型语言模型中推断成本和模型质量之间的平衡。 |
| [^300] | [Tweets to Citations: Unveiling the Impact of Social Media Influencers on AI Research Visibility.](http://arxiv.org/abs/2401.13782) | 本文研究了社交媒体影响者在提高机器学习研究的可见性方面的作用，发现被这些影响者认可的论文引用次数显著增加，中位数引用次数比对照组高2-3倍。此外，该研究还探讨了被展示作者的地理、性别和机构多样性。 |
| [^301] | [Knowledge Distillation from Language-Oriented to Emergent Communication for Multi-Agent Remote Control.](http://arxiv.org/abs/2401.12624) | 这项工作通过将语言导向的语义通信与新兴通信相结合，通过知识蒸馏的方式，提出了一种面向多智能体远程控制的新框架，实现了更快的行程时间和更高的训练收敛速度。 |
| [^302] | [Behavioral Simulation: Exploring A Possible Next Paradigm for Science.](http://arxiv.org/abs/2401.09851) | 本文研究了仿真技术的发展与科学范式的演变，并提出了行为仿真的概念，代表了更高程度的范式整合。 |
| [^303] | [Coupling Graph Neural Networks with Fractional Order Continuous Dynamics: A Robustness Study.](http://arxiv.org/abs/2401.04331) | 本文详细研究了图神经分数阶微分方程模型的鲁棒性，通过实施分数阶微积分，模型在特征更新过程中考虑了长期记忆，对抗性条件下的性能仍未得到广泛探究。 |
| [^304] | [BD-MSA: Body decouple VHR Remote Sensing Image Change Detection method guided by multi-scale feature information aggregation.](http://arxiv.org/abs/2401.04330) | 提出了一种名为BD-MSA的新的变化检测模型，通过在训练和预测阶段收集特征图的全局和局部特征信息，成功提取了变化区域的边界信息，并将变化区域的主体与边界分离。 |
| [^305] | [Video2Music: Suitable Music Generation from Videos using an Affective Multimodal Transformer model.](http://arxiv.org/abs/2311.00968) | Video2Music是一个生成音乐的人工智能框架，可以根据视频生成相匹配的音乐。该框架通过分析视频的语义、场景偏移、动作和情感特征，采用Affective Multimodal Transformer (AMT)模型生成音乐。 |
| [^306] | [Q-Learning for Stochastic Control under General Information Structures and Non-Markovian Environments.](http://arxiv.org/abs/2311.00123) | 该论文主要贡献是提出了一个对于非马尔可夫环境下的随机迭代（特别是Q-learning迭代）进行收敛的定理，并给出了收敛条件。其次，讨论了该定理在多种具有非马尔可夫环境的随机控制问题中的应用。 |
| [^307] | [Quantum Acceleration of Infinite Horizon Average-Reward Reinforcement Learning.](http://arxiv.org/abs/2310.11684) | 本研究探索了无限时域平均奖励强化学习中量子加速的潜力。我们提出了一种创新的量子框架，通过高效的量子均值估计技术，实现了指数级改进的遗憾保证。所提出的量子算法相较于经典算法，在遗憾界限上有显著改进。 |
| [^308] | [Denevil: Towards Deciphering and Navigating the Ethical Values of Large Language Models via Instruction Learning.](http://arxiv.org/abs/2310.11053) | 通过Moral Foundation Theory和DeNEVIL算法，我们研究了大型语言模型的道德价值，并构建了MoralPrompt数据集来评估模型的内在价值。发现大多数模型存在不对齐，需要进一步进行道德价值对齐。 |
| [^309] | [Improved Contextual Recognition In Automatic Speech Recognition Systems By Semantic Lattice Rescoring.](http://arxiv.org/abs/2310.09680) | 通过深度学习模型和transformer的重新评分，我们提出了一种通过语义格重排序来提高自动语音识别系统中上下文识别能力的方法。 |
| [^310] | [HIO-SDF: Hierarchical Incremental Online Signed Distance Fields.](http://arxiv.org/abs/2310.09463) | HIO-SDF是一种新的层次增量在线有符号距离场方法，能够有效地表示大型、复杂的移动机器人工作空间，并能够以在线增量方式进行更新。 |
| [^311] | [Boosting Facial Action Unit Detection Through Jointly Learning Facial Landmark Detection and Domain Separation and Reconstruction.](http://arxiv.org/abs/2310.05207) | 本文提出了一种新的面部动作单位（AU）检测框架，通过共享参数和引入多任务学习，在面部标志检测和AU域分离与重建之间实现了更好的性能。实验证明我们方法在野外AU检测方面优于现有方法。 |
| [^312] | [Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization.](http://arxiv.org/abs/2310.03234) | 本文研究了一种新的组合优化问题，称为非光滑弱凸有限和耦合组合优化(NSWC FCCO)，通过扩展已有的研究，我们研究了非光滑弱凸FCCO的问题，并提出了一种单循环算法来找到Moreau环的ε-稳定点。 |
| [^313] | [Pushing Large Language Models to the 6G Edge: Vision, Challenges, and Opportunities.](http://arxiv.org/abs/2309.16739) | 本文探讨了将大型语言模型(LLMs)部署在6G边缘的潜力和挑战。我们介绍了由LLMs支持的关键应用，并从响应时间、带宽成本和数据隐私等方面分析了云端部署面临的问题。我们提出了6G移动边缘计算(MEC)系统可能解决这些问题的方案，并讨论了边缘训练和边缘推理的创新技术。 |
| [^314] | [Contrastive Continual Multi-view Clustering with Filtered Structural Fusion.](http://arxiv.org/abs/2309.15135) | 提出了一种名为对比度连续多视角聚类与过滤结构融合（CCMVC-FSF）的新方法，用于解决多视角聚类在实时数据收集中的困难。该方法旨在防止先前知识遗忘和利用数据相关性指导新视图的聚类过程。 |
| [^315] | [Safe POMDP Online Planning via Shielding.](http://arxiv.org/abs/2309.10216) | 通过计算屏蔽动作来实现安全的POMDP在线规划。四种屏蔽方法。 |
| [^316] | [A Natural Gas Consumption Forecasting System for Continual Learning Scenarios based on Hoeffding Trees with Change Point Detection Mechanism.](http://arxiv.org/abs/2309.03720) | 本文介绍了一个基于Hoeffding树和变点检测机制的连续学习场景下的天然气消费预测系统，通过数据流处理，实现了多步 ahead 的预测和持续学习能力。在复杂的实际应用场景中，通过评估预测模型的性能，证明了该方法的有效性。 |
| [^317] | [Physically Grounded Vision-Language Models for Robotic Manipulation.](http://arxiv.org/abs/2309.02561) | 该论文介绍了一个用于机器人操作的具有物理基础的视觉语言模型，通过在物体上微调模型，提高了模型对物理概念的理解，在语言交互框架中展现了良好的性能。 |
| [^318] | [MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models.](http://arxiv.org/abs/2308.09729) | 本论文通过使用知识图谱来激发大型语言模型，解决了整合新知识、产生幻觉和决策过程不透明等问题，并通过生成思维导图展示了模型的推理路径，实验证明这种方法可以取得显著的实证增益。 |
| [^319] | [Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding.](http://arxiv.org/abs/2307.15337) | 本研究提出了一种名为“思维的骨架”的方法，可以通过并行解码来减少大型语言模型的生成延迟。这种方法不仅显著提高了速度，还可以潜在地提高答案质量。 |
| [^320] | [Tackling the Curse of Dimensionality with Physics-Informed Neural Networks.](http://arxiv.org/abs/2307.12306) | 本文提出了一种新方法，利用物理信知的神经网络(PINNs)解决高维度的偏微分方程(PDEs)问题，并证明了收敛性和其他期望属性。 |
| [^321] | [LabelBench: A Comprehensive Framework for Benchmarking Label-Efficient Learning.](http://arxiv.org/abs/2306.09910) | 本论文介绍了一个新的综合性标签高效学习基准评估框架LabelBench，并通过引入一种新的与半监督学习相结合的主动学习方法的基准测试，证明了在相对较少的标记示例下实现更好的标签效率。 |
| [^322] | [DCTX-Conformer: Dynamic context carry-over for low latency unified streaming and non-streaming Conformer.](http://arxiv.org/abs/2306.08175) | 提出了一种基于Conformer的新型动态上下文传递机制DCTX-Conformer，解决了流式识别性能差距的问题，相比于现有最优解，识别结果的误差率提高了25%，但对延迟影响可以忽略不计。 |
| [^323] | [Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models.](http://arxiv.org/abs/2306.08018) | Mol-Instructions是一个专门为生物分子领域设计的综合指令数据集，可以显著提高大语言模型在生物领域中的适应能力和认知敏锐度。 |
| [^324] | [A Dynamic Partial Computation Offloading for the Metaverse in In-Network Computing.](http://arxiv.org/abs/2306.06022) | 该论文提出了一个基于网络计算的Metaverse动态部分计算卸载方案，能够在动态调整卸载策略的同时最小化能耗和延迟，解决了多个子任务的部分计算卸载问题，并将其分解为了两个子问题，分别针对用户端的任务切分问题和COIN端的任务卸载问题。这需要使用序数潜在博弈（OPG）和马尔可夫决策过程（MDP）来提出模型，并使用双重深度Q网络（DDQN）来解决最优卸载策略的问题。 |
| [^325] | [Prompt Injection attack against LLM-integrated Applications.](http://arxiv.org/abs/2306.05499) | 本研究分析了LLM集成应用中的提示注入攻击的复杂性和影响，提出了一种新颖的黑盒提示注入攻击技术HouYi，并揭示了应用程序提示机制中以前未知和严重低估的漏洞。我们的研究呼吁进一步开发全面的防御措施，以抵御LLM集成应用中的提示注入攻击。 |
| [^326] | [Enabling Efficient Interaction between an Algorithm Agent and an LLM: A Reinforcement Learning Approach.](http://arxiv.org/abs/2306.03604) | 本论文提出一种强化学习的中介模型，可实现代理与LLM之间高效经济有效的互动，提高效率和成本效益。 |
| [^327] | [Multi-Objective Genetic Algorithm for Multi-View Feature Selection.](http://arxiv.org/abs/2305.18352) | 多视角数据提高了预测模型的准确性，但也使得高维数据增加，影响模型泛化能力。研究者提出了一种多视角多目标特征选择遗传算法（MMFS-GA），用于从多视角数据中选择最优的特征子集以提高模型精度和可解释性。 |
| [^328] | [Learning Safety Constraints from Demonstrations with Unknown Rewards.](http://arxiv.org/abs/2305.16147) | CoCoRL是一种从不知道奖励的已知安全演示中推断约束的方法，可以用于Constrained Markov Decision Process（CMDP），并且对于几乎最优演示能够无误差收敛于真实的安全集。 |
| [^329] | [Unpaired Image-to-Image Translation via Neural Schr\"odinger Bridge.](http://arxiv.org/abs/2305.15086) | 本文提出了一种方法——非配对神经薛定谔桥 (UNSB)，它结合了薛定谔桥、对抗训练和正则化，用于在非配对数据之间学习 SDE，并成功解决了许多非配对图像转换任务。 |
| [^330] | [Deep Temporal Graph Clustering.](http://arxiv.org/abs/2305.10738) | 提出通用框架TGC 用于 deep temporal graph clustering, 解决了时间图只能作为静态图处理的难题，实现了对动态信息的聚类。实验证明了 TGC 的优越性。 |
| [^331] | [Pre-trained Language Model with Prompts for Temporal Knowledge Graph Completion.](http://arxiv.org/abs/2305.07912) | 这篇论文提出了一种基于提示的预训练语言模型（PPT），用于时间知识图谱补全。通过遮盖策略，将TKGC任务转换为遮盖词预测任务，可以利用预训练语言模型中的语义信息。 |
| [^332] | [False Claims against Model Ownership Resolution.](http://arxiv.org/abs/2304.06607) | 该论文研究了模型所有权解决方案中对抗恶意原告的鲁棒性问题，展示了常见的MOR方案可以被恶意原告针对未被盗用的独立模型提出虚假指控。 |
| [^333] | [Complementary Random Masking for RGB-Thermal Semantic Segmentation.](http://arxiv.org/abs/2303.17386) | 本文提出了一种RGB-T图像互补随机蒙版策略和自蒸馏损失，通过防止对单一模式过度依赖，强制网络在一个模态部分可用时进行分割和分类，从而提高了神经网络的准确性和鲁棒性，同时鼓励网络提取互补且有意义的表示。 |
| [^334] | [Retrosynthetic Planning with Dual Value Networks.](http://arxiv.org/abs/2301.13755) | PDVN是一种新的在线训练算法，它在逆向合成规划中利用双价值网络优化完整的路线，成功率和效率上均优于现有方法。 |
| [^335] | [PIP: Positional-encoding Image Prior.](http://arxiv.org/abs/2211.14298) | 本文提出的PIP（位置编码图像先验）与DIP表现相似，但所需参数更少，并且可以轻松扩展到视频领域，解决了3D-DIP的问题。 |
| [^336] | [FedTracker: Furnishing Ownership Verification and Traceability for Federated Learning Model.](http://arxiv.org/abs/2211.07160) | FedTracker是第一个为联邦学习模型提供所有权验证和追溯性的保护框架，采用双层保护方案，并利用持续学习原则提高保护性能。 |
| [^337] | [A Simple Approach for State-Action Abstraction using a Learned MDP Homomorphism.](http://arxiv.org/abs/2209.06356) | 本论文提出了一种在离散动作空间中构建同态映射的新方法，通过使用环境动力学的部分模型来推断相同状态的状态动作对，从而减小状态-动作空间的大小。 |

# 详细

[^1]: 开发和评估正向人工智能设计方法

    Developing and Evaluating a Design Method for Positive Artificial Intelligence

    [https://rss.arxiv.org/abs/2402.01499](https://rss.arxiv.org/abs/2402.01499)

    这项研究提出并评估了一种正向人工智能设计方法，用于确保人工智能系统对社会产生积极影响。该方法通过以人为中心的流程，将幸福愿景转化为具体实践，并通过持续的测量和反馈循环进行支持。

    

    随着人工智能的不断发展，确保人工智能系统对社会产生积极影响变得至关重要，尤其是在人工智能系统在各个方面日益普及的情况下。然而，开发“AI for good”在与复杂人类价值观保持一致方面存在巨大挑战。目前，我们缺乏成熟的方法来解决这些挑战。本文介绍和评估了正向人工智能设计方法，旨在填补这一空白。该方法提供了一个以人为中心的流程，将幸福愿景转化为具体实践。首先，我们解释了该方法的四个关键步骤：情境化、操作化、优化化和实现福祉，同时支持持续测量和反馈循环。然后，我们提出了一个多个案例研究，其中初学者设计师应用了该方法，揭示了与效力和可用性相关的优点和缺点。接下来，一项专家评估研究评估了所得概念的质量，将其评为中等水平。

    As artificial intelligence (AI) continues advancing, ensuring positive societal impacts becomes critical, especially as AI systems become increasingly ubiquitous in various aspects of life. However, developing "AI for good" poses substantial challenges around aligning systems with complex human values. Presently, we lack mature methods for addressing these challenges. This article presents and evaluates the Positive AI design method aimed at addressing this gap. The method provides a human-centered process to translate wellbeing aspirations into concrete practices. First, we explain the method's four key steps: contextualizing, operationalizing, optimizing, and implementing wellbeing supported by continuous measurement for feedback cycles. We then present a multiple case study where novice designers applied the method, revealing strengths and weaknesses related to efficacy and usability. Next, an expert evaluation study assessed the quality of the resulting concepts, rating them modera
    
[^2]: 在图上的小样本学习：从元学习到预训练和提示

    Few-Shot Learning on Graphs: from Meta-learning to Pre-training and Prompting

    [https://rss.arxiv.org/abs/2402.01440](https://rss.arxiv.org/abs/2402.01440)

    本文综述了图上的小样本学习的最新发展，将现有的研究方法划分为元学习、预训练和混合方法三大类别，并对它们的优缺点进行了比较。还提出了未来的研究方向。

    

    图表示学习是图中心任务中的关键步骤，在这方面已经取得了重大进展。早期的技术通常在端到端的设置中运行，性能严重依赖于充足的标记数据的可用性。这个限制引发了图上的小样本学习的出现，其中每个任务只有少量的任务特定标签可用。鉴于这个领域的广泛文献，本综述试图综合最近的发展，提供比较性的见解，并确定未来的方向。我们将现有的研究系统地分为三个主要类别：元学习方法、预训练方法和混合方法，并在每个类别中进行细粒度的分类，以帮助读者进行方法选择。在每个类别中，我们分析这些方法之间的关系并比较它们的优缺点。最后，我们概述了图上的小样本学习未来的方向。

    Graph representation learning, a critical step in graph-centric tasks, has seen significant advancements. Earlier techniques often operate in an end-to-end setting, where performance heavily relies on the availability of ample labeled data. This constraint has spurred the emergence of few-shot learning on graphs, where only a few task-specific labels are available for each task. Given the extensive literature in this field, this survey endeavors to synthesize recent developments, provide comparative insights, and identify future directions. We systematically categorize existing studies into three major families: meta-learning approaches, pre-training approaches, and hybrid approaches, with a finer-grained classification in each family to aid readers in their method selection process. Within each category, we analyze the relationships among these methods and compare their strengths and limitations. Finally, we outline prospective future directions for few-shot learning on graphs to cata
    
[^3]: 医学中的大型语言模型调查：原理、应用和挑战

    A Survey of Large Language Models in Medicine: Principles, Applications, and Challenges

    [https://rss.arxiv.org/abs/2311.05112](https://rss.arxiv.org/abs/2311.05112)

    本综述提供了医学中大型语言模型（LLMs）的原理、应用和挑战的全面概述。同时回答了医学LLMs的构建、下游性能、实际应用、挑战以及更好构建和利用的问题。旨在为构建有效的医学LLMs提供见解和实用资源。

    

    大型语言模型（LLMs），如ChatGPT，由于其理解和生成人类语言的能力而受到了广泛关注。在人工智能和临床医学中，LLMs在协助医生进行患者护理方面正在成为一个有前景的研究方向。本综述提供了医学中LLMs的原理、应用和面临的挑战的全面概述。我们回答了以下具体问题：1）如何构建医学LLMs？2）什么是医学LLMs的下游性能评估指标？3）在现实临床实践中，如何利用医学LLMs？4）使用医学LLMs会出现哪些挑战？5）如何更好地构建和利用医学LLMs？本综述旨在提供关于医学中LLMs的机遇和挑战的见解，并作为构建有效的医学LLMs的实用资源。我们还维护并定期更新一个清单

    Large language models (LLMs), such as ChatGPT, have received substantial attention due to their capabilities for understanding and generating human language. LLMs in medicine to assist physicians for patient care are emerging as a promising research direction in both artificial intelligence and clinical medicine. This review provides a comprehensive overview of the principles, applications, and challenges faced by LLMs in medicine. We address the following specific questions: 1) How should medical LLMs be built? 2) What are the measures for the downstream performance of medical LLMs? 3) How should medical LLMs be utilized in real-world clinical practice? 4) What challenges arise from the use of medical LLMs? and 5) How should we better construct and utilize medical LLMs? This review aims to provide insights into the opportunities and challenges of LLMs in medicine, and serve as a practical resource for constructing effective medical LLMs. We also maintain and regularly updated list of 
    
[^4]: 用双手扭开盖子

    Twisting Lids Off with Two Hands

    [https://arxiv.org/abs/2403.02338](https://arxiv.org/abs/2403.02338)

    深度强化学习结合仿真到真实世界的转移为解决物体操纵问题提供了有力支持

    

    用两只多指手臂操纵物体一直是机器人领域的一项长期挑战，原因在于许多操纵任务的丰富接触性质以及协调高维度双手系统固有的复杂性。在这项工作中，我们考虑了使用两只手扭开各种瓶子盖的问题，并展示出使用深度强化学习在仿真中训练的策略可以有效地转移到现实世界。通过对物理建模、实时感知和奖励设计的新工程见解，该策略展示了一般化能力，能够贯穿各种看不见的物体，展示出动态和灵巧的行为。我们的发现证明了深度强化学习结合仿真到真实世界的转移仍然是解决前所未有复杂问题的操纵问题的一个有前途的方法。

    arXiv:2403.02338v1 Announce Type: cross  Abstract: Manipulating objects with two multi-fingered hands has been a long-standing challenge in robotics, attributed to the contact-rich nature of many manipulation tasks and the complexity inherent in coordinating a high-dimensional bimanual system. In this work, we consider the problem of twisting lids of various bottle-like objects with two hands, and demonstrate that policies trained in simulation using deep reinforcement learning can be effectively transferred to the real world. With novel engineering insights into physical modeling, real-time perception, and reward design, the policy demonstrates generalization capabilities across a diverse set of unseen objects, showcasing dynamic and dexterous behaviors. Our findings serve as compelling evidence that deep reinforcement learning combined with sim-to-real transfer remains a promising approach for addressing manipulation problems of unprecedented complexity.
    
[^5]: 包装中的品牌可见度：一种用于标志检测、显著性图预测和标志位置分析的深度学习方法

    Brand Visibility in Packaging: A Deep Learning Approach for Logo Detection, Saliency-Map Prediction, and Logo Placement Analysis

    [https://arxiv.org/abs/2403.02336](https://arxiv.org/abs/2403.02336)

    本研究引入了一种深度学习框架，结合标志检测、显著性图预测和标志位置分析，用于衡量包装设计中品牌标志的关注度。

    

    在产品营销领域的激烈竞争中，包装上品牌标志的可见度在塑造消费者认知、直接影响产品成功方面起着至关重要的作用。本文引入了一个全面的框架来衡量包装设计中品牌标志的关注度。所提出的方法包括三个步骤。第一步利用YOLOv8在显著数据集FoodLogoDet-1500和LogoDet-3K上进行精确的标志检测。第二步涉及使用一种专为包装上下文量身定制的新型显著性预测模型建模用户的视觉注意力。所提出的显著性模型结合了视觉元素与文本映射，利用基于transformers的架构预测用户注意力图。在第三步中，通过将标志检测与显著性图生成相结合，该框架提供了全面的品牌关注分数。所提出方法的有效性得到了评估。

    arXiv:2403.02336v1 Announce Type: cross  Abstract: In the highly competitive area of product marketing, the visibility of brand logos on packaging plays a crucial role in shaping consumer perception, directly influencing the success of the product. This paper introduces a comprehensive framework to measure the brand logo's attention on a packaging design. The proposed method consists of three steps. The first step leverages YOLOv8 for precise logo detection across prominent datasets, FoodLogoDet-1500 and LogoDet-3K. The second step involves modeling the user's visual attention with a novel saliency prediction model tailored for the packaging context. The proposed saliency model combines the visual elements with text maps employing a transformers-based architecture to predict user attention maps. In the third step, by integrating logo detection with a saliency map generation, the framework provides a comprehensive brand attention score. The effectiveness of the proposed method is assess
    
[^6]: 梯度相关子空间学习抵抗灾难性遗忘

    Gradient Correlation Subspace Learning against Catastrophic Forgetting

    [https://arxiv.org/abs/2403.02334](https://arxiv.org/abs/2403.02334)

    GCSL是一种用于减少灾难性遗忘的新颖方法，通过检测和利用不受以前任务影响的权重子空间来训练新任务。

    

    在过去几年中，高效的持续学习技术一直是一个重要的研究课题。这样的学习面临的一个基本问题是之前学习的任务性能严重下降，也称为灾难性遗忘。本文介绍了一种新颖的方法，在增量类学习的情况下减少灾难性遗忘，名为梯度相关子空间学习（GCSL）。该方法检测到最不受以前任务影响的权重子空间，并将权重投影到该子空间中进行新任务的训练。该方法可以应用于给定网络架构的一个或多个层，并且所使用的子空间大小可以从层到层、任务到任务进行改变。

    arXiv:2403.02334v1 Announce Type: cross  Abstract: Efficient continual learning techniques have been a topic of significant research over the last few years. A fundamental problem with such learning is severe degradation of performance on previously learned tasks, known also as catastrophic forgetting. This paper introduces a novel method to reduce catastrophic forgetting in the context of incremental class learning called Gradient Correlation Subspace Learning (GCSL). The method detects a subspace of the weights that is least affected by previous tasks and projects the weights to train for the new task into said subspace. The method can be applied to one or more layers of a given network architectures and the size of the subspace used can be altered from layer to layer and task to task. Code will be available at \href{https://github.com/vgthengane/GCSL}{https://github.com/vgthengane/GCSL}
    
[^7]: 基于关键点驱动的数据合成及其在数学推理上的增强

    Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning

    [https://arxiv.org/abs/2403.02333](https://arxiv.org/abs/2403.02333)

    提出了基于关键点驱动的数据合成框架(KPDDS)，创造了迄今为止最大规模的用于数学推理的合成数据集KPMath，以及进一步增强的KPMath-Plus数据集，实现了零-shot PASS@1精度为39.3%的性能提升。

    

    大型语言模型（LLMs）在复杂推理任务中显示出巨大潜力，但其性能通常受到高质量、以推理为重点的训练数据稀缺的影响。为解决这一挑战，我们提出了基于关键点驱动的数据合成（KPDDS），这是一个新颖的数据合成框架，通过利用来自真实数据源的关键点和示例对生成问题-答案对。KPDDS确保通过严格的质量控制和大规模性能的生成新颖问题。因此，我们提出了KPMath，迄今为止量身定制的最广泛的用于数学推理的合成数据集，包括一百万个以上的问题-答案对。利用KPMath并将其与其他推理密集的语料库进行扩充，我们创建了全面的KPMath-Plus数据集。将Mistral-7B模型在KPMath-Plus上微调，使其在MATH测试集上实现零-shot PASS@1精度达到39.3%，这是一项突破性成就。

    arXiv:2403.02333v1 Announce Type: cross  Abstract: Large language models (LLMs) have shown great potential in complex reasoning tasks, yet their performance is often hampered by the scarcity of high-quality, reasoning-focused training datasets. Addressing this challenge, we propose Key-Point-Driven Data Synthesis (KPDDS), a novel data synthesis framework that synthesizes question-answer pairs by leveraging key points and exemplar pairs from authentic data sources. KPDDS ensures the generation of novel questions with rigorous quality control and substantial scalability. As a result, we present KPMath, the most extensive synthetic dataset tailored for mathematical reasoning to date, comprising over one million question-answer pairs. Utilizing KPMath and augmenting it with additional reasoning-intensive corpora, we create the comprehensive KPMath-Plus dataset. Fine-tuning the Mistral-7B model on KPMath-Plus yields a zero-shot PASS@1 accuracy of 39.3% on the MATH test set, a performance th
    
[^8]: 模型湖

    Model Lakes

    [https://arxiv.org/abs/2403.02327](https://arxiv.org/abs/2403.02327)

    提出了模型湖的概念，在解决大型模型管理中的基础研究挑战方面具有重要意义。

    

    给定一组深度学习模型，寻找适合特定任务的模型、理解这些模型并区分它们之间的差异可能是困难的。目前，从业者依靠手工编写的文档来理解和选择模型。然而，并非所有模型都有完整可靠的文档。随着机器学习模型数量的增加，发现、区分和理解这些模型的问题变得更为重要。受数据湖研究的启发，我们引入并定义了模型湖的概念。我们讨论了在大型模型管理中的基本研究挑战，并探讨了哪些基本的数据管理技术可以应用于大型模型管理的研究中。

    arXiv:2403.02327v1 Announce Type: cross  Abstract: Given a set of deep learning models, it can be hard to find models appropriate to a task, understand the models, and characterize how models are different one from another. Currently, practitioners rely on manually-written documentation to understand and choose models. However, not all models have complete and reliable documentation. As the number of machine learning models increases, this issue of finding, differentiating, and understanding models is becoming more crucial. Inspired from research on data lakes, we introduce and define the concept of model lakes. We discuss fundamental research challenges in the management of large models. And we discuss what principled data management techniques can be brought to bear on the study of large model management.
    
[^9]: 对比区域引导：在视觉-语言模型中提高定位准确性而无需训练

    Contrastive Region Guidance: Improving Grounding in Vision-Language Models without Training

    [https://arxiv.org/abs/2403.02325](https://arxiv.org/abs/2403.02325)

    引入了对比区域引导（CRG）方法，实现了在视觉-语言模型中无需训练即可使模型响应视觉提示并取得显著改进。

    

    通过突出图像中特别相关的区域，可以改善视觉-语言模型（VLMs）在各种视觉-语言（VL）任务上的性能，引导模型更密切地关注这些感兴趣的区域。我们引入了对比区域引导（CRG），这是一种无需训练的引导方法，可以使开源的VLMs响应视觉提示，并在各种VL任务中取得显著改进。

    arXiv:2403.02325v1 Announce Type: cross  Abstract: Highlighting particularly relevant regions of an image can improve the performance of vision-language models (VLMs) on various vision-language (VL) tasks by guiding the model to attend more closely to these regions of interest. For example, VLMs can be given a "visual prompt", where visual markers such as bounding boxes delineate key image regions. However, current VLMs that can incorporate visual guidance are either proprietary and expensive or require costly training on curated data that includes visual prompts. We introduce Contrastive Region Guidance (CRG), a training-free guidance method that enables open-source VLMs to respond to visual prompts. CRG contrasts model outputs produced with and without visual prompts, factoring out biases revealed by the model when answering without the information required to produce a correct answer (i.e., the model's prior). CRG achieves substantial improvements in a wide variety of VL tasks: When
    
[^10]: 超越专业化：评估MLLMs在年龄和性别估计中的能力

    Beyond Specialization: Assessing the Capabilities of MLLMs in Age and Gender Estimation

    [https://arxiv.org/abs/2403.02302](https://arxiv.org/abs/2403.02302)

    本研究评估了多模态大型语言模型（MLLMs）在年龄和性别估计中的能力，对不同模型进行了比较，揭示了它们在特定任务上的优势和劣势。

    

    最近，多模态大型语言模型（MLLMs）变得异常流行。像ChatGPT-4V和Gemini这样功能强大的商用模型，以及像LLaVA这样的开源模型，本质上都是通用模型，应用于解决各种各样的任务，包括计算机视觉中的任务。这些神经网络具有如此强大的通用知识和推理能力，以至于它们已被证明能够处理甚至未经专门训练的任务。我们将迄今为止最强大的MLLMs的能力进行了比较：ShareGPT4V、ChatGPT、LLaVA-Next 进行了专门任务的年龄和性别估计，与我们的最新专业化模型MiVOLO进行了比较。我们还更新了MiVOLO，并在本文中提供了详细信息和新的指标。这种比较产生了一些有趣的结果和关于参与模型的优点和缺点的见解。此外，我们尝试了各种微调方法

    arXiv:2403.02302v1 Announce Type: cross  Abstract: Multimodal Large Language Models (MLLMs) have recently gained immense popularity. Powerful commercial models like ChatGPT-4V and Gemini, as well as open-source ones such as LLaVA, are essentially general-purpose models and are applied to solve a wide variety of tasks, including those in computer vision. These neural networks possess such strong general knowledge and reasoning abilities that they have proven capable of working even on tasks for which they were not specifically trained. We compared the capabilities of the most powerful MLLMs to date: ShareGPT4V, ChatGPT, LLaVA-Next in a specialized task of age and gender estimation with our state-of-the-art specialized model, MiVOLO. We also updated MiVOLO and provide details and new metrics in this article. This comparison has yielded some interesting results and insights about the strengths and weaknesses of the participating models. Furthermore, we attempted various ways to fine-tune 
    
[^11]: Koopman辅助强化学习

    Koopman-Assisted Reinforcement Learning

    [https://arxiv.org/abs/2403.02290](https://arxiv.org/abs/2403.02290)

    该论文利用Koopman算子技术将非线性系统提升到新坐标系，在其中动力学变得近似线性，从而构建两种新的强化学习算法，以解决高维状态和非线性系统中传统方程难以解决的问题。

    

    鲍曼方程及其连续形式，即哈密顿-雅可比-贝尔曼（HJB）方程，在强化学习（RL）和控制理论中无处不在。然而，对于具有高维状态和非线性的系统，这些方程很快变得难以解决。本文探讨了数据驱动的Koopman算子与马尔可夫决策过程（MDPs）之间的联系，从而开发出两种新的RL算法来解决这些限制。我们利用Koopman算子技术将非线性系统提升到新坐标系，其中动力学变得近似线性，HJB方法更易处理。特别地，Koopman算子能够通过提升到的坐标系中的线性动态来捕获给定系统值函数的时间演化的期望。通过用控制动作参数化Koopman算子，我们构建了一个“Koopman张量”，以便实现...

    arXiv:2403.02290v1 Announce Type: new  Abstract: The Bellman equation and its continuous form, the Hamilton-Jacobi-Bellman (HJB) equation, are ubiquitous in reinforcement learning (RL) and control theory. However, these equations quickly become intractable for systems with high-dimensional states and nonlinearity. This paper explores the connection between the data-driven Koopman operator and Markov Decision Processes (MDPs), resulting in the development of two new RL algorithms to address these limitations. We leverage Koopman operator techniques to lift a nonlinear system into new coordinates where the dynamics become approximately linear, and where HJB-based methods are more tractable. In particular, the Koopman operator is able to capture the expectation of the time evolution of the value function of a given system via linear dynamics in the lifted coordinates. By parameterizing the Koopman operator with the control actions, we construct a ``Koopman tensor'' that facilitates the es
    
[^12]: 主观 $\textit{Isms}$? 论混淆仇恨与冒犯在滥用语言检测中的危险

    Subjective $\textit{Isms}$? On the Danger of Conflating Hate and Offence in Abusive Language Detection

    [https://arxiv.org/abs/2403.02268](https://arxiv.org/abs/2403.02268)

    论文指出在滥用语言检测中，混淆仇恨和冒犯可能会使研究结果失效，呼吁未来工作需要从理论上将仇恨与冒犯概念进行分离。

    

    arXiv:2403.02268v1 类型：跨领域 摘要：自然语言处理研究已经开始接受注释者主观性的概念，这主要受到标记差异的驱动。这种方法将每个注释者的观点视为有效，这对于嵌入主观性的任务(如情感分析)可能非常适用。然而，对于仇恨言论检测等任务，这种构造可能是不恰当的，因为它赋予了所有关于性别歧视或种族主义等议题的立场相同的有效性。我们认为对仇恨和冒犯的混淆可能会使对仇恨言论的研究结果无效，并呼吁未来的工作应该置于理论框架中，将仇恨与其正交概念冒犯分离开来。

    arXiv:2403.02268v1 Announce Type: cross  Abstract: Natural language processing research has begun to embrace the notion of annotator subjectivity, motivated by variations in labelling. This approach understands each annotator's view as valid, which can be highly suitable for tasks that embed subjectivity, e.g., sentiment analysis. However, this construction may be inappropriate for tasks such as hate speech detection, as it affords equal validity to all positions on e.g., sexism or racism. We argue that the conflation of hate and offence can invalidate findings on hate speech, and call for future work to be situated in theory, disentangling hate from its orthogonal concept, offence.
    
[^13]: KnowPhish：大型语言模型遇见多模态知识图谱以增强基于参考的网络钓鱼检测

    KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection

    [https://arxiv.org/abs/2403.02253](https://arxiv.org/abs/2403.02253)

    提出了一个自动化知识收集流水线，发布了一个包含20k品牌的大规模多模态品牌知识库KnowPhish，可用于加强现有基于参考的网络钓鱼检测器的性能

    

    网络钓鱼攻击已给个人和企业造成了重大损失，因此需要开发强大高效的自动网络钓鱼检测方法。基于参考的网络钓鱼检测器（RBPDs）已成为最先进的方法，它们比较目标网页上的标志与已知标志集。然而，现有RBPDs的主要局限是它们依赖于手动构建的品牌知识库，这使得无法扩展到大量品牌，导致由于知识库中品牌覆盖不足而出现假阴性错误。为了解决这个问题，我们提出了一个自动化知识收集流水线，采用该流水线我们收集并发布了一个大规模多模态品牌知识库KnowPhish，包含20k个品牌和每个品牌的丰富信息。KnowPhish可以用来以即插即用的方式提升现有RBPDs的性能。

    arXiv:2403.02253v1 Announce Type: cross  Abstract: Phishing attacks have inflicted substantial losses on individuals and businesses alike, necessitating the development of robust and efficient automated phishing detection approaches. Reference-based phishing detectors (RBPDs), which compare the logos on a target webpage to a known set of logos, have emerged as the state-of-the-art approach. However, a major limitation of existing RBPDs is that they rely on a manually constructed brand knowledge base, making it infeasible to scale to a large number of brands, which results in false negative errors due to the insufficient brand coverage of the knowledge base. To address this issue, we propose an automated knowledge collection pipeline, using which we collect and release a large-scale multimodal brand knowledge base, KnowPhish, containing 20k brands with rich information about each brand. KnowPhish can be used to boost the performance of existing RBPDs in a plug-and-play manner. A second 
    
[^14]: 非自回归序列到序列视觉语言模型

    Non-autoregressive Sequence-to-Sequence Vision-Language Models

    [https://arxiv.org/abs/2403.02249](https://arxiv.org/abs/2403.02249)

    提出了一种非自回归序列到序列视觉语言模型，通过在解码器中边际化多个推理路径的方式，实现了对标记的联合分布建模，从而在保持性能的同时加快了推理速度。

    

    序列到序列的视觉语言模型表现出了潜力，但由于它们生成预测的自回归方式，它们的推理延迟限制了它们的适用性。我们提出了一个并行解码的序列到序列视觉语言模型，使用Query-CTC损失进行训练，在解码器中边际化多个推理路径。这使我们能够对标记的联合分布进行建模，而不像自回归模型那样限制在条件分布上。结果模型NARVL在推理时间上达到了与最新自回归对应物相当的性能，但更快，从与顺序生成标记相关的线性复杂度减少到常量时间联合推理的范式。

    arXiv:2403.02249v1 Announce Type: cross  Abstract: Sequence-to-sequence vision-language models are showing promise, but their applicability is limited by their inference latency due to their autoregressive way of generating predictions. We propose a parallel decoding sequence-to-sequence vision-language model, trained with a Query-CTC loss, that marginalizes over multiple inference paths in the decoder. This allows us to model the joint distribution of tokens, rather than restricting to conditional distribution as in an autoregressive model. The resulting model, NARVL, achieves performance on-par with its state-of-the-art autoregressive counterpart, but is faster at inference time, reducing from the linear complexity associated with the sequential generation of tokens to a paradigm of constant time joint inference.
    
[^15]: 深度神经网络低精度训练的更好调度

    Better Schedules for Low Precision Training of Deep Neural Networks

    [https://arxiv.org/abs/2403.02243](https://arxiv.org/abs/2403.02243)

    该研究发现了用于低精度训练的循环精度训练调度的更好选择，进一步提高了训练效率

    

    低精度训练可以显著减少训练深度神经网络(DNNs)的计算开销。尽管存在许多这样的技术，但循环精度训练(CPT)，根据循环调度通过动态调整精度的方式进行训练，实现了训练效率的显著提升，同时实际上提高了DNN的性能。现有的CPT实现采用常见的学习率调度（例如，周期余弦调度），并在低精度训练中使用它们，但未与其他调度选项进行充分比较。我们定义了一套多样化的CPT调度，并分析它们在各种DNN训练方案中的性能，其中一些在低精度训练文献中尚未探索（例如，使用图神经网络进行节点分类）。通过这些实验，我们发现了提供进一步提升训练效率的替代CPT调度。

    arXiv:2403.02243v1 Announce Type: cross  Abstract: Low precision training can significantly reduce the computational overhead of training deep neural networks (DNNs). Though many such techniques exist, cyclic precision training (CPT), which dynamically adjusts precision throughout train- ing according to a cyclic schedule, achieves particularly impressive improvements in training efficiency, while actually improving DNN performance. Existing CPT implementations take common learning rate schedules (e.g., cyclical cosine sched- ules) and use them for low precision training without adequate comparisons to alternative scheduling options. We define a diverse suite of CPT schedules and analyze their performance across a variety of DNN training regimes, some of which are unexplored in the low precision training literature (e.g., node classification with graph neural networks). From these experiments, we discover alternative CPT schedules that offer further improvements in training efficiency 
    
[^16]: 神经红移：随机网络并非随机函数

    Neural Redshift: Random Networks are not Random Functions

    [https://arxiv.org/abs/2403.02241](https://arxiv.org/abs/2403.02241)

    本论文研究了未经训练的随机权重网络，发现即使简单的MLPs也具有强烈的归纳偏见，不同于传统观点的是，NNs并不具有固有的“简单偏见”，而是依赖于组件的作用。

    

    我们对神经网络（NNs）的泛化能力的理解仍不完整。目前的解释基于梯度下降（GD）的隐含偏见，但无法解释梯度自由方法中模型的能力，也无法解释最近观察到的未经训练网络的简单偏见。本文寻找NNs中的其他泛化源。为了独立于GD理解体系结构提供的归纳偏见，我们研究未经训练的随机权重网络。即使是简单的MLPs也表现出强烈的归纳偏见：在权重空间中进行均匀抽样会产生一个非常偏向于复杂性的函数分布。但与常规智慧不同，NNs并不具有固有的“简单偏见”。这一特性取决于组件，如ReLU、残差连接和层归一化。可利用替代体系结构构建偏向于任何复杂性水平的偏见。Transformers也具有这一特性。

    arXiv:2403.02241v1 Announce Type: cross  Abstract: Our understanding of the generalization capabilities of neural networks (NNs) is still incomplete. Prevailing explanations are based on implicit biases of gradient descent (GD) but they cannot account for the capabilities of models from gradient-free methods nor the simplicity bias recently observed in untrained networks. This paper seeks other sources of generalization in NNs.   Findings. To understand the inductive biases provided by architectures independently from GD, we examine untrained, random-weight networks. Even simple MLPs show strong inductive biases: uniform sampling in weight space yields a very biased distribution of functions in terms of complexity. But unlike common wisdom, NNs do not have an inherent "simplicity bias". This property depends on components such as ReLUs, residual connections, and layer normalizations. Alternative architectures can be built with a bias for any level of complexity. Transformers also inher
    
[^17]: 朝向基于意图的网络管理：5G核心网络中用于意图提取的大型语言模型

    Towards Intent-Based Network Management: Large Language Models for Intent Extraction in 5G Core Networks

    [https://arxiv.org/abs/2403.02238](https://arxiv.org/abs/2403.02238)

    该论文提出了为5G和下一代基于意图的网络开发自定义大型语言模型（LLM），旨在实现完全自动化网络中的端到端基于意图的网络。

    

    机器学习和人工智能（ML/AI）与第五代（5G）网络的整合，凸显出了网络智能与当前和下一代设备对越来越严格的要求的限制。 这种向普遍智能的过渡要求用户和网络运营商之间高度的连接性、同步性和端到端的通信，并将为实现完全无需人工干预的全自动网络铺平道路。基于意图的网络是减少人类行为、角色和责任的关键因素，同时转向自动化网络管理的新型提取和解释。 本文介绍了为5G和下一代基于意图的网络开发自定义大型语言模型（LLM），并提供了未来LLM发展和集成的见解，以实现完全自动化网络中的端到端基于意图的网络。

    arXiv:2403.02238v1 Announce Type: cross  Abstract: The integration of Machine Learning and Artificial Intelligence (ML/AI) into fifth-generation (5G) networks has made evident the limitations of network intelligence with ever-increasing, strenuous requirements for current and next-generation devices. This transition to ubiquitous intelligence demands high connectivity, synchronicity, and end-to-end communication between users and network operators, and will pave the way towards full network automation without human intervention. Intent-based networking is a key factor in the reduction of human actions, roles, and responsibilities while shifting towards novel extraction and interpretation of automated network management. This paper presents the development of a custom Large Language Model (LLM) for 5G and next-generation intent-based networking and provides insights into future LLM developments and integrations to realize end-to-end intent-based networking for fully automated network in
    
[^18]: 机器学习在恶意软件检测中对Mal-API-2019数据集的全面评估

    Comprehensive evaluation of Mal-API-2019 dataset by machine learning in malware detection

    [https://arxiv.org/abs/2403.02232](https://arxiv.org/abs/2403.02232)

    该研究通过机器学习技术全面评估了恶意软件检测，发现集成方法（如随机森林和XGBoost）相较于其他方法在恶意软件检测中表现出更高的准确性、精确度和召回率。

    

    这项研究使用机器学习技术对恶意软件检测进行了彻底的探讨，重点评估了使用Mal-API-2019数据集的各种分类模型。旨在通过更有效地识别和缓解威胁来推进网络安全能力。研究探讨了集成和非集成的机器学习方法，如随机森林、XGBoost、K最近邻（KNN）和神经网络。特别强调了数据预处理技术的重要性，特别是TF-IDF表示和主成分分析，以提高模型性能。结果显示，随机森林和XGBoost等集成方法相比其他方法具有更高的准确性、精确度和召回率，突显了它们在恶意软件检测中的有效性。论文还讨论了限制和潜在的未来方向，强调了需要不断适应的必要性。

    arXiv:2403.02232v1 Announce Type: cross  Abstract: This study conducts a thorough examination of malware detection using machine learning techniques, focusing on the evaluation of various classification models using the Mal-API-2019 dataset. The aim is to advance cybersecurity capabilities by identifying and mitigating threats more effectively. Both ensemble and non-ensemble machine learning methods, such as Random Forest, XGBoost, K Nearest Neighbor (KNN), and Neural Networks, are explored. Special emphasis is placed on the importance of data pre-processing techniques, particularly TF-IDF representation and Principal Component Analysis, in improving model performance. Results indicate that ensemble methods, particularly Random Forest and XGBoost, exhibit superior accuracy, precision, and recall compared to others, highlighting their effectiveness in malware detection. The paper also discusses limitations and potential future directions, emphasizing the need for continuous adaptation t
    
[^19]: 政策空间响应神谕：一项调查

    Policy Space Response Oracles: A Survey

    [https://arxiv.org/abs/2403.02227](https://arxiv.org/abs/2403.02227)

    政策空间响应神谕（PSRO）是一种适用于大型博弈的快速发展的博弈推理框架，主要关注策略探索问题和提高效率的研究，以及在各个领域中的应用。

    

    在博弈论中，游戏指的是理性决策者或玩家之间相互作用的模型，他们通过选择来实现个人目标。了解他们在游戏中的行为通常被称为博弈推理。本调查全面介绍了一种适用于大型游戏的快速发展的博弈推理框架，称为政策空间响应神谕（PSRO）。我们首先激发PSRO的动机，提供历史背景，并将PSRO定位在博弈推理方法中。然后我们关注PSRO的策略探索问题，即如何有效组合策略组合以在模拟潜在游戏时降低计算成本的挑战。我们还调查了目前用于增强PSRO效率的研究方向，并探讨了PSRO在各个领域中的应用。最后，我们讨论了未解决的问题和未来研究方向。

    arXiv:2403.02227v1 Announce Type: cross  Abstract: In game theory, a game refers to a model of interaction among rational decision-makers or players, making choices with the goal of achieving their individual objectives. Understanding their behavior in games is often referred to as game reasoning. This survey provides a comprehensive overview of a fast-developing game-reasoning framework for large games, known as Policy Space Response Oracles (PSRO). We first motivate PSRO, provide historical context, and position PSRO within game-reasoning approaches. We then focus on the strategy exploration issue for PSRO, the challenge of assembling an effective strategy portfolio for modeling the underlying game with minimum computational cost. We also survey current research directions for enhancing the efficiency of PSRO, and explore the applications of PSRO across various domains. We conclude by discussing open questions and future research.
    
[^20]: 推理过程中不是所有LLMs的层都是必要的

    Not all Layers of LLMs are Necessary during Inference

    [https://arxiv.org/abs/2403.02181](https://arxiv.org/abs/2403.02181)

    推理过程中，根据输入实例的不同难易程度，本文提出了一种名为AdaInfer的算法，可以自适应地使用浅层和深层，从而节省了计算资源。

    

    大型语言模型（LLMs）的推理阶段非常昂贵。理想的LLMs推理阶段可以利用更少的计算资源，同时仍保持其能力（例如泛化和上下文学习能力）。本文尝试回答一个问题：“在LLMs推理过程中，我们可以为简单实例使用浅层，并为难以处理的实例使用深层吗？”为了回答这个问题，我们首先通过统计分析跨任务激活的层来指出并非所有层在推理过程中都是必要的。然后，我们提出了一种简单的算法，名为AdaInfer，根据输入实例自适应地确定推理终止时刻。更重要的是，AdaInfer不改变LLMs参数，并在任务之间保持泛化能力。对知名LLMs（即Llama2系列和OPT）的实验证明，AdaInfer节省了平均14.8%的计算资源，甚至在情感方面高达50%。

    arXiv:2403.02181v1 Announce Type: cross  Abstract: The inference phase of Large Language Models (LLMs) is very expensive. An ideal inference stage of LLMs could utilize fewer computational resources while still maintaining its capabilities (e.g., generalization and in-context learning ability). In this paper, we try to answer the question, "During LLM inference, can we use shallow layers for easy instances; and deep layers for hard ones?" To answer this question, we first indicate that Not all Layers are Necessary during Inference by statistically analyzing the activated layers across tasks. Then, we propose a simple algorithm named AdaInfer to determine the inference termination moment based on the input instance adaptively. More importantly, AdaInfer does not alter LLM parameters and maintains generalizability across tasks. Experiments on well-known LLMs (i.e., Llama2 series and OPT) show that AdaInfer saves an average of 14.8% of computational resources, even up to 50% on sentiment 
    
[^21]: 掩面思想:简单地掩盖部分推理步骤可以提高语言模型对数学推理的学习

    Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models

    [https://arxiv.org/abs/2403.02178](https://arxiv.org/abs/2403.02178)

    引入对输入的扰动，通过随机掩盖思维链中的某些标记，可显著提高语言模型在推理任务中的学习效果

    

    在推理任务中，即使是一个轻微的错误也可能导致不准确的结果，从而导致大型语言模型在这些领域的性能不佳。我们提出的方法避免了外部资源，而是依赖于引入对输入的扰动。我们的训练方法随机掩盖了链式思维中的某些标记，这种技术对推理任务特别有效。

    arXiv:2403.02178v1 Announce Type: cross  Abstract: In reasoning tasks, even a minor error can cascade into inaccurate results, leading to suboptimal performance of large language models in such domains. Earlier fine-tuning approaches sought to mitigate this by leveraging more precise supervisory signals from human labeling, larger models, or self-sampling, although at a high cost. Conversely, we develop a method that avoids external resources, relying instead on introducing perturbations to the input. Our training approach randomly masks certain tokens within the chain of thought, a technique we found to be particularly effective for reasoning tasks. When applied to fine-tuning with GSM8K, this method achieved a 5% improvement in accuracy over standard supervised fine-tuning with a few codes modified and no additional labeling effort. Furthermore, it is complementary to existing methods. When integrated with related data augmentation methods, it leads to an average improvement of 3% im
    
[^22]: 从野外录制的语音消息中识别语音情感

    Speech emotion recognition from voice messages recorded in the wild

    [https://arxiv.org/abs/2403.02167](https://arxiv.org/abs/2403.02167)

    使用Emotional Voice Messages数据库，结合eGeMAPS特征和Transformer模型，实现了在野外录制的语音消息中的语音情感识别，取得了较高的准确度，并比基准模型提高了10%。

    

    用于语音情感识别（SER）的情感数据集通常包含表演或引发的语音，限制了它们在现实场景中的适用性。在这项工作中，我们使用了Emotional Voice Messages（EMOVOME）数据库，其中包括来自100名西班牙语使用者在消息应用中的自发语音消息，由专家和非专家标注者以连续和离散的情感进行标记。我们使用了eGeMAPS特征、基于Transformer的模型以及它们的组合来创建讲话者无关的SER模型。我们将结果与参考数据库进行了比较，并分析了标注者和性别公平性的影响。预训练的Unispeech-L模型及其与eGeMAPS的组合取得了最佳结果，在3类valence和arousal预测中分别获得了61.64%和55.57%的Unweighted Accuracy（UA），比基线模型提高了10%。对于情感类别，获得了42.58%的UA。EMOVOME表现不佳。

    arXiv:2403.02167v1 Announce Type: cross  Abstract: Emotion datasets used for Speech Emotion Recognition (SER) often contain acted or elicited speech, limiting their applicability in real-world scenarios. In this work, we used the Emotional Voice Messages (EMOVOME) database, including spontaneous voice messages from conversations of 100 Spanish speakers on a messaging app, labeled in continuous and discrete emotions by expert and non-expert annotators. We created speaker-independent SER models using the eGeMAPS features, transformer-based models and their combination. We compared the results with reference databases and analyzed the influence of annotators and gender fairness. The pre-trained Unispeech-L model and its combination with eGeMAPS achieved the highest results, with 61.64% and 55.57% Unweighted Accuracy (UA) for 3-class valence and arousal prediction respectively, a 10% improvement over baseline models. For the emotion categories, 42.58% UA was obtained. EMOVOME performed low
    
[^23]: 认知就是你需要的一切 - 大语言模型之上的人工智能下一层

    Cognition is All You Need - The Next Layer of AI Above Large Language Models

    [https://arxiv.org/abs/2403.02164](https://arxiv.org/abs/2403.02164)

    提出了认知人工智能，一个用于在大型语言模型之上实现以程序定义的神经符号认知的高级框架，为能够执行复杂多步知识工作的人工智能系统提供了路径。

    

    最近对话式人工智能工具的研究，比如由大型语言模型驱动的聊天机器人在复杂的实际知识工作中的应用已经显示出了与推理和多步问题解决相关的局限性。我们提出认知人工智能，这是一个用于在大型语言模型之上和之外实现以程序定义的神经符号认知的高级框架。具体而言，我们提出了认知人工智能的双层功能架构，作为能够执行复杂多步知识工作的人工智能系统的路线图。

    arXiv:2403.02164v1 Announce Type: new  Abstract: Recent studies of the applications of conversational AI tools, such as chatbots powered by large language models, to complex real-world knowledge work have shown limitations related to reasoning and multi-step problem solving. Specifically, while existing chatbots simulate shallow reasoning and understanding they are prone to errors as problem complexity increases. The failure of these systems to address complex knowledge work is due to the fact that they do not perform any actual cognition. In this position paper, we present Cognitive AI, a higher-level framework for implementing programmatically defined neuro-symbolic cognition above and outside of large language models. Specifically, we propose a dual-layer functional architecture for Cognitive AI that serves as a roadmap for AI systems that can perform complex multi-step knowledge work. We propose that Cognitive AI is a necessary precursor for the evolution of higher forms of AI, suc
    
[^24]: 深度强化学习用于动态算法选择：以微分进化为例的原理研究

    Deep Reinforcement Learning for Dynamic Algorithm Selection: A Proof-of-Principle Study on Differential Evolution

    [https://arxiv.org/abs/2403.02131](https://arxiv.org/abs/2403.02131)

    本论文提出了一种基于深度强化学习的动态算法选择框架，旨在通过训练代理根据优化过程中观察到的特征选择最合适的算法，以解决单个算法有效性在不同问题实例上变化的问题。

    

    进化算法，如微分进化，在解决实数参数优化挑战方面表现出色。然而，单个算法的有效性在不同问题实例上变化，需要在算法选择或配置方面投入相当多的努力。本文旨在通过利用一组算法的互补优势，并在优化过程中为特定问题动态调度它们来解决这一限制。我们提出了一个基于深度强化学习的动态算法选择框架来完成这一任务。我们的方法将动态算法选择建模为马尔科夫决策过程，以策略梯度方式训练代理选择根据优化过程中观察到的特征选择最合适的算法。为了使代理具备必要的信息，我们的框架结合了一个经过深思熟虑的景观和算法设计。

    arXiv:2403.02131v1 Announce Type: cross  Abstract: Evolutionary algorithms, such as Differential Evolution, excel in solving real-parameter optimization challenges. However, the effectiveness of a single algorithm varies across different problem instances, necessitating considerable efforts in algorithm selection or configuration. This paper aims to address the limitation by leveraging the complementary strengths of a group of algorithms and dynamically scheduling them throughout the optimization progress for specific problems. We propose a deep reinforcement learning-based dynamic algorithm selection framework to accomplish this task. Our approach models the dynamic algorithm selection a Markov Decision Process, training an agent in a policy gradient manner to select the most suitable algorithm according to the features observed during the optimization process. To empower the agent with the necessary information, our framework incorporates a thoughtful design of landscape and algorith
    
[^25]: LOCR：面向光学字符识别的位置引导Transformer

    LOCR: Location-Guided Transformer for Optical Character Recognition

    [https://arxiv.org/abs/2403.02127](https://arxiv.org/abs/2403.02127)

    LOCR是一种面向光学字符识别的模型，通过在自回归过程中在transformer架构中集成位置引导，能够有效处理学术文档中的重复问题，并在测试集上表现出色。

    

    学术文档充斥着文本、方程式、表格和图形，需要全面理解才能准确进行光学字符识别（OCR）。尽管端到端OCR方法在准确性上优于基于布局的方法，但它们通常在处理重复性问题时遇到困难，特别是在“领域外”（OOD）文档中的复杂布局。为了解决这一问题，我们提出了LOCR，一种将位置引导整合到变压器架构中的模型。我们在一个包含来自125K个学术文档页面的超过7700万个文本-位置对的数据集上训练模型，包括单词、表格和数学符号的边界框。LOCR能熟练处理各种格式元素并以Markdown语言生成内容。在我们从arXiv构建的测试集中，衡量方式为编辑距离、BLEU、METEOR和F-measure，LOCR优于所有现有方法。LOCR还将重复频率从4

    arXiv:2403.02127v1 Announce Type: cross  Abstract: Academic documents are packed with texts, equations, tables, and figures, requiring comprehensive understanding for accurate Optical Character Recognition (OCR). While end-to-end OCR methods offer improved accuracy over layout-based approaches, they often grapple with significant repetition issues, especially with complex layouts in Out-Of-Domain (OOD) documents.To tackle this issue, we propose LOCR, a model that integrates location guiding into the transformer architecture during autoregression. We train the model on a dataset comprising over 77M text-location pairs from 125K academic document pages, including bounding boxes for words, tables and mathematical symbols. LOCR adeptly handles various formatting elements and generates content in Markdown language. It outperforms all existing methods in our test set constructed from arXiv, as measured by edit distance, BLEU, METEOR and F-measure.LOCR also reduces repetition frequency from 4
    
[^26]: 在混合代码的印地语中利用弱标注数据进行仇恨言论检测：一种基于可行性驱动的大型语言模型迁移学习方法

    Leveraging Weakly Annotated Data for Hate Speech Detection in Code-Mixed Hinglish: A Feasibility-Driven Transfer Learning Approach with Large Language Models

    [https://arxiv.org/abs/2403.02121](https://arxiv.org/abs/2403.02121)

    本研究利用弱标注数据和大型语言模型，针对混合代码的印地语进行仇恨言论检测，探索了零次学习、一次学习和少次学习方法，解决了标记数据的问题。

    

    大型语言模型的出现推动了各种自然语言处理任务的基准。然而，训练大型语言模型需要大量标记的训练数据。此外，数据标注和训练都是计算昂贵且耗时的。最近，零次和少次学习成为使用大型预训练模型标记数据的可行选择。在混合代码低资源语言中的仇恨言论检测是一个活跃的问题领域，LLM的使用在这方面已被证明是有益的。在这项研究中，我们收集了100条YouTube评论的数据集，并对混合代码的印地语中的粗粒度和细粒度的性别歧视进行了弱标注。由于需要耗费大量人力进行注释，因此采用了弱标注。然后，应用了零次学习、一次学习和少次学习以及提示方法来为评论分配标签，并将其与人工标记进行比较。

    arXiv:2403.02121v1 Announce Type: cross  Abstract: The advent of Large Language Models (LLMs) has advanced the benchmark in various Natural Language Processing (NLP) tasks. However, large amounts of labelled training data are required to train LLMs. Furthermore, data annotation and training are computationally expensive and time-consuming. Zero and few-shot learning have recently emerged as viable options for labelling data using large pre-trained models. Hate speech detection in mix-code low-resource languages is an active problem area where the use of LLMs has proven beneficial. In this study, we have compiled a dataset of 100 YouTube comments, and weakly labelled them for coarse and fine-grained misogyny classification in mix-code Hinglish. Weak annotation was applied due to the labor-intensive annotation process. Zero-shot learning, one-shot learning, and few-shot learning and prompting approaches have then been applied to assign labels to the comments and compare them to human-ass
    
[^27]: 位置论文：面向文本到图像模型的隐式提示

    Position Paper: Towards Implicit Prompt For Text-To-Image Models

    [https://arxiv.org/abs/2403.02118](https://arxiv.org/abs/2403.02118)

    该位置论文讨论了文本到图像模型在隐式提示方面的现状，提出了名为ImplicitBench的新基准，并对 T2I 模型在隐式提示下的表现及影响进行了调查。

    

    近期文本到图像（T2I）模型取得了巨大成功，并提出了许多基准来评估它们的性能和安全性。然而，它们只考虑了显式提示，而忽略了隐式提示（暗示目标而不明确提到）。这些提示可能消除安全约束，并对这些模型的应用构成潜在威胁。本文介绍了当下T2I模型朝着隐式提示的现状。我们提出了一个名为ImplicitBench的基准，并对流行的T2I模型在隐式提示下的性能和影响进行了调查。具体来说，我们设计并收集了三个方面的超过2,000个隐式提示：通用符号、名人隐私和不安全的问题，并评估了六个知名T2I模型在这些隐式提示下的能力。实验结果显示，（1）T2I模型能够准确地创建各种目标。

    arXiv:2403.02118v1 Announce Type: cross  Abstract: Recent text-to-image (T2I) models have had great success, and many benchmarks have been proposed to evaluate their performance and safety. However, they only consider explicit prompts while neglecting implicit prompts (hint at a target without explicitly mentioning it). These prompts may get rid of safety constraints and pose potential threats to the applications of these models. This position paper highlights the current state of T2I models toward implicit prompts. We present a benchmark named ImplicitBench and conduct an investigation on the performance and impacts of implicit prompts with popular T2I models. Specifically, we design and collect more than 2,000 implicit prompts of three aspects: General Symbols, Celebrity Privacy, and Not-Safe-For-Work (NSFW) Issues, and evaluate six well-known T2I models' capabilities under these implicit prompts. Experiment results show that (1) T2I models are able to accurately create various targe
    
[^28]: 迭代$Q$-网络：超越单步贝尔曼算子

    Iterated $Q$-Network: Beyond the One-Step Bellman Operator

    [https://arxiv.org/abs/2403.02107](https://arxiv.org/abs/2403.02107)

    引入了迭代$Q$-网络（iQN）方法，通过一次考虑多次迭代的贝尔曼算子来改进值基强化学习方法，在理论上可行，并在实验中展示其在游戏和控制环境中的优势。

    

    值基强化学习（RL）方法依赖于贝尔曼算子的应用，该算子需要从样本中进行近似。大多数方法包括交替应用贝尔曼算子和随后投影步骤到考虑的函数空间的迭代方案。然而，我们观察到这些算法可以通过一次考虑多次迭代的贝尔曼算子来改进。因此，我们引入了迭代$Q$-网络（iQN），这是一种新颖的方法，它学习一系列$Q$函数逼近，其中每个$Q$函数都作为下一个函数链中的目标。我们证明了iQN在理论上是可行的，并展示了它如何可以无缝地用于值基和演员-评论方法。我们在Atari$2600$游戏和连续控制MuJoCo环境中在实验上展示了它的优势。

    arXiv:2403.02107v1 Announce Type: cross  Abstract: Value-based Reinforcement Learning (RL) methods rely on the application of the Bellman operator, which needs to be approximated from samples. Most approaches consist of an iterative scheme alternating the application of the Bellman operator and a subsequent projection step onto a considered function space. However, we observe that these algorithms can be improved by considering multiple iterations of the Bellman operator at once. Thus, we introduce iterated $Q$-Networks (iQN), a novel approach that learns a sequence of $Q$-function approximations where each $Q$-function serves as the target for the next one in a chain of consecutive Bellman iterations. We demonstrate that iQN is theoretically sound and show how it can be seamlessly used in value-based and actor-critic methods. We empirically demonstrate its advantages on Atari $2600$ games and in continuous-control MuJoCo environments.
    
[^29]: VTG-GPT：使用GPT实现免调优零样本视频时间定位

    VTG-GPT: Tuning-Free Zero-Shot Video Temporal Grounding with GPT

    [https://arxiv.org/abs/2403.02076](https://arxiv.org/abs/2403.02076)

    提出了一种基于GPT的零调优视频时间定位方法VTG-GPT，通过生成无偏查询和更精确的视觉描述，实现了在零样本设置中明显优于现有方法和无监督方法的性能提升

    

    视频时间定位（VTG）旨在根据语言查询从未经剪辑的视频中定位特定的时间段。大多数现有的VTG模型都是在大量带注释的视频文本对上进行训练的，这个过程不仅引入了来自查询的人为偏见，还带来了显著的计算成本。为了解决这些挑战，我们提出了VTG-GPT，这是一种基于GPT的零调优VTG方法。为了减少原始查询中的偏见，我们使用Baichuan2生成无偏查询。为了减少视频中的冗余信息，我们应用MiniGPT-v2将视觉内容转换为更精确的字幕。最后，我们设计了提案生成器和后处理来从无偏查询和图像字幕中生成准确的段。大量实验证明，VTG-GPT在零样本设置中明显优于SOTA方法，并超越了无监督方法。

    arXiv:2403.02076v1 Announce Type: cross  Abstract: Video temporal grounding (VTG) aims to locate specific temporal segments from an untrimmed video based on a linguistic query. Most existing VTG models are trained on extensive annotated video-text pairs, a process that not only introduces human biases from the queries but also incurs significant computational costs. To tackle these challenges, we propose VTG-GPT, a GPT-based method for zero-shot VTG without training or fine-tuning. To reduce prejudice in the original query, we employ Baichuan2 to generate debiased queries. To lessen redundant information in videos, we apply MiniGPT-v2 to transform visual content into more precise captions. Finally, we devise the proposal generator and post-processing to produce accurate segments from debiased queries and image captions. Extensive experiments demonstrate that VTG-GPT significantly outperforms SOTA methods in zero-shot settings and surpasses unsupervised approaches. More notably, it achi
    
[^30]: 模态感知和位移混合器用于多模态脑肿瘤分割

    Modality-Aware and Shift Mixer for Multi-modal Brain Tumor Segmentation

    [https://arxiv.org/abs/2403.02074](https://arxiv.org/abs/2403.02074)

    本文提出了一种新颖的模态感知和位移混合器，用于融合多模态图像的依赖关系，以实现在脑肿瘤分割任务中的有效和稳健性。

    

    将来自多种模态的图像进行组合有利于探索计算机视觉领域中的各种信息，尤其在医学领域。本文提出了一种新颖的模态感知和位移混合器，用于有效而稳健的脑肿瘤分割，该混合器整合了多模态图像的内模态和交叉模态依赖关系。具体地，我们引入了一个模态感知模块，根据神经影像研究来建模低层次的特定模态对关系，还开发了一个具有特定马赛克图案的模态位移模块，以探索复杂的关系。

    arXiv:2403.02074v1 Announce Type: cross  Abstract: Combining images from multi-modalities is beneficial to explore various information in computer vision, especially in the medical domain. As an essential part of clinical diagnosis, multi-modal brain tumor segmentation aims to delineate the malignant entity involving multiple modalities. Although existing methods have shown remarkable performance in the task, the information exchange for cross-scale and high-level representations fusion in spatial and modality are limited in these methods. In this paper, we present a novel Modality Aware and Shift Mixer that integrates intra-modality and inter-modality dependencies of multi-modal images for effective and robust brain tumor segmentation. Specifically, we introduce a Modality-Aware module according to neuroimaging studies for modeling the specific modality pair relationships at low levels, and a Modality-Shift module with specific mosaic patterns is developed to explore the complex relat
    
[^31]: 基于大型语言模型的进化优化器：精英主义推理

    Large Language Model-Based Evolutionary Optimizer: Reasoning with elitism

    [https://arxiv.org/abs/2403.02054](https://arxiv.org/abs/2403.02054)

    LEO是一种基于大型语言模型的进化优化器，具有零-shot优化能力，在多目标和高维问题上表现出色，与最先进方法产生可比较的结果，但其想象力和幻觉倾向需要谨慎处理。

    

    大型语言模型(LLMs)显示出出色的推理能力，引起人们对其作为黑盒优化器的应用的兴趣。本文声称LLMs具有在各种场景下进行零-shot优化的能力，包括多目标和高维问题。我们介绍了一种使用LLMs进行数值优化的新型基于种群的方法，称为基于语言模型的进化优化器(LEO)。通过跨基准和工业工程问题的数值示例，如超音速喷管形状优化、热传递和风场布局优化，支持了我们的假设。我们将我们的方法与几种基于梯度和无梯度的优化方法进行了比较。虽然LLMs产生的结果与最先进的方法相当，但它们的想像能力和产生幻觉的倾向需要谨慎处理。我们提供了获得可靠答案的实用指南。

    arXiv:2403.02054v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated remarkable reasoning abilities, prompting interest in their application as black-box optimizers. This paper asserts that LLMs possess the capability for zero-shot optimization across diverse scenarios, including multi-objective and high-dimensional problems. We introduce a novel population-based method for numerical optimization using LLMs called Language-Model-Based Evolutionary Optimizer (LEO). Our hypothesis is supported through numerical examples, spanning benchmark and industrial engineering problems such as supersonic nozzle shape optimization, heat transfer, and windfarm layout optimization. We compare our method to several gradient-based and gradient-free optimization approaches. While LLMs yield comparable results to state-of-the-art methods, their imaginative nature and propensity to hallucinate demand careful handling. We provide practical guidelines for obtaining reliable answers
    
[^32]: 能源高效驾驶行为及最新人工智能方法的范围审查

    A Scoping Review of Energy-Efficient Driving Behaviors and Applied State-of-the-Art AI Methods

    [https://arxiv.org/abs/2403.02053](https://arxiv.org/abs/2403.02053)

    本文通过范围审查探讨了能源高效驾驶行为和最先进AI方法的应用，总结了影响驾驶行为的十一个关键特征。

    

    运输行业仍然是温室气体排放的主要贡献者。理解能源高效驾驶行为和应用能源高效驾驶策略对于减少汽车燃料消耗至关重要。然而，对能源高效驾驶行为和策略尚无综合调查。此外，许多最新的人工智能模型已应用于分析环保驾驶风格，但尚无概述。为填补这一空白，本文对生态驾驶行为和风格进行了彻底文献综述，并分析了影响能源消耗的驾驶因素和最新方法。通过彻底的范围审查过程，对方法论和相关数据进行了比较。结果显示影响驾驶行为的因素可以总结为包括速度、加速、减速、踏板等十一个特征。

    arXiv:2403.02053v1 Announce Type: new  Abstract: The transportation sector remains a major contributor to greenhouse gas emissions. The understanding of energy-efficient driving behaviors and utilization of energy-efficient driving strategies are essential to reduce vehicles' fuel consumption. However, there is no comprehensive investigation into energy-efficient driving behaviors and strategies. Furthermore, many state-of-the-art AI models have been applied for the analysis of eco-friendly driving styles, but no overview is available. To fill the gap, this paper conducts a thorough literature review on ecological driving behaviors and styles and analyzes the driving factors influencing energy consumption and state-of-the-art methodologies. With a thorough scoping review process, the methodological and related data are compared. The results show that the factors that impact driving behaviors can be summarized into eleven features including speed, acceleration, deceleration, pedal, and 
    
[^33]: 跨域策略转移与效果循环一致性

    Cross Domain Policy Transfer with Effect Cycle-Consistency

    [https://arxiv.org/abs/2403.02018](https://arxiv.org/abs/2403.02018)

    提出了一种新颖的方法，通过使用未配对数据学习两个领域之间的状态和动作空间映射函数，实现了跨域策略转移。

    

    使用深度强化学习方法从头开始训练机器人策略可能因为样本效率低而成本过高。为了解决这一挑战，将在源域中训练的策略转移到目标域变得具有吸引力。先前的研究通常集中在状态和动作空间相似但在其他方面不同的域上。本文的主要重点在于具有不同状态和动作空间的领域，这具有更广泛的实际意义，即从机器人A转移到机器人B的策略转移。与依赖配对数据的先前方法不同，我们提出了一种新颖的方法，使用未配对数据学习跨领域状态和动作空间之间的映射函数。我们提出了效果循环一致性，通过对称优化结构来对两个领域之间的过渡效果进行对齐，从而学习这些映射函数。一旦映射完成

    arXiv:2403.02018v1 Announce Type: cross  Abstract: Training a robotic policy from scratch using deep reinforcement learning methods can be prohibitively expensive due to sample inefficiency. To address this challenge, transferring policies trained in the source domain to the target domain becomes an attractive paradigm. Previous research has typically focused on domains with similar state and action spaces but differing in other aspects. In this paper, our primary focus lies in domains with different state and action spaces, which has broader practical implications, i.e. transfer the policy from robot A to robot B. Unlike prior methods that rely on paired data, we propose a novel approach for learning the mapping functions between state and action spaces across domains using unpaired data. We propose effect cycle consistency, which aligns the effects of transitions across two domains through a symmetrical optimization structure for learning these mapping functions. Once the mapping fun
    
[^34]: 揭示未见安全实体之间隐藏的联系

    Unveiling Hidden Links Between Unseen Security Entities

    [https://arxiv.org/abs/2403.02014](https://arxiv.org/abs/2403.02014)

    VulnScopper是一种创新方法，利用多模态表示学习结合知识图谱和自然语言处理，能够自动化和增强软件漏洞分析，有效处理未见实体，并在NVD和Red Hat CVE数据库上取得显著改进。

    

    软件漏洞的不断增多给安全数据库和分析人员及时识别、分类和修复漏洞带来了巨大挑战。本文介绍了一种名为VulnScopper的创新方法，利用多模态表示学习，结合知识图谱（KG）和自然语言处理（NLP），自动化和增强软件漏洞分析。VulnScopper利用ULTRA作为知识图谱基础模型，结合大型语言模型（LLM），有效处理未见实体，克服了以往知识图谱方法的局限性。我们在两个重要的安全数据集，即NVD和红帽CVE数据库上评估了VulnScopper。我们的方法显著改善了

    arXiv:2403.02014v1 Announce Type: cross  Abstract: The proliferation of software vulnerabilities poses a significant challenge for security databases and analysts tasked with their timely identification, classification, and remediation. With the National Vulnerability Database (NVD) reporting an ever-increasing number of vulnerabilities, the traditional manual analysis becomes untenably time-consuming and prone to errors. This paper introduces VulnScopper, an innovative approach that utilizes multi-modal representation learning, combining Knowledge Graphs (KG) and Natural Language Processing (NLP), to automate and enhance the analysis of software vulnerabilities. Leveraging ULTRA, a knowledge graph foundation model, combined with a Large Language Model (LLM), VulnScopper effectively handles unseen entities, overcoming the limitations of previous KG approaches. We evaluate VulnScopper on two major security datasets, the NVD and the Red Hat CVE database. Our method significantly improves
    
[^35]: 低资源语言的变压器：Is F\'eidir Linn！

    Transformers for Low-Resource Languages:Is F\'eidir Linn!

    [https://arxiv.org/abs/2403.01985](https://arxiv.org/abs/2403.01985)

    本研究评估了对低资源的英语-爱尔兰语语言对进行超参数优化的 Transformer 模型，发现正确选择子词模型是翻译性能的最大驱动因素。

    

    Transformer 模型是机器翻译领域的最先进技术。然而，一般来说，神经翻译模型在训练数据不足的语言对上常常表现不佳。因此，对于低资源语言对，使用该结构进行实验的研究相对较少。本研究评估了将变压器模型进行超参数优化以翻译低资源的英语-爱尔兰语语言对。我们展示了选择适当的参数会带来相当大的性能提升。最重要的是，正确选择子词模型被证明是翻译性能最大的驱动因素。评估了使用 unigram 和 BPE 方法的 SentencePiece 模型。对模型架构的变化包括修改层数、测试各种正则化技术以及评估用于注意力的最佳头数。

    arXiv:2403.01985v1 Announce Type: cross  Abstract: The Transformer model is the state-of-the-art in Machine Translation. However, in general, neural translation models often under perform on language pairs with insufficient training data. As a consequence, relatively few experiments have been carried out using this architecture on low-resource language pairs. In this study, hyperparameter optimization of Transformer models in translating the low-resource English-Irish language pair is evaluated. We demonstrate that choosing appropriate parameters leads to considerable performance improvements. Most importantly, the correct choice of subword model is shown to be the biggest driver of translation performance. SentencePiece models using both unigram and BPE approaches were appraised. Variations on model architectures included modifying the number of layers, testing various regularisation techniques and evaluating the optimal number of heads for attention. A generic 55k DGT corpus and an i
    
[^36]: TTA-Nav: 测试时自适应重建用于视觉损坏下的点目标导航

    TTA-Nav: Test-time Adaptive Reconstruction for Point-Goal Navigation under Visual Corruptions

    [https://arxiv.org/abs/2403.01977](https://arxiv.org/abs/2403.01977)

    TTA-Nav提出了一种测试时自适应方法，通过引入自顶向下解码器，从损坏图像中重建出更清晰的图像，显著增强了点目标导航性能。

    

    arXiv:2403.01977v1 公告类型: 跨  摘要: 在视觉损坏下的机器人导航是一个巨大的挑战。为了解决这一问题，我们提出了一种名为TTA-Nav的测试时自适应（TTA）方法，用于在视觉损坏下的点目标导航。我们的“即插即用”方法将自顶向下的解码器与预训练的导航模型相结合。首先，预训练的导航模型接收一个损坏的图像并提取特征。其次，自顶向下的解码器根据预训练模型提取的高级特征生成重建图像。然后，将损坏图像的重建图像馈送回预训练模型。最后，预训练模型再次进行前向传播以输出动作。尽管仅在清晰图像上训练，自顶向下的解码器可以从损坏图像中重建出更清晰的图像，无需基于梯度的自适应。具有我们自顶向下解码器的预训练导航模型显著提高了导航性能。

    arXiv:2403.01977v1 Announce Type: cross  Abstract: Robot navigation under visual corruption presents a formidable challenge. To address this, we propose a Test-time Adaptation (TTA) method, named as TTA-Nav, for point-goal navigation under visual corruptions. Our "plug-and-play" method incorporates a top-down decoder to a pre-trained navigation model. Firstly, the pre-trained navigation model gets a corrupted image and extracts features. Secondly, the top-down decoder produces the reconstruction given the high-level features extracted by the pre-trained model. Then, it feeds the reconstruction of a corrupted image back to the pre-trained model. Finally, the pre-trained model does forward pass again to output action. Despite being trained solely on clean images, the top-down decoder can reconstruct cleaner images from corrupted ones without the need for gradient-based adaptation. The pre-trained navigation model with our top-down decoder significantly enhances navigation performance acr
    
[^37]: 生成式人工智能的异质生产力效应

    The Heterogeneous Productivity Effects of Generative AI

    [https://arxiv.org/abs/2403.01964](https://arxiv.org/abs/2403.01964)

    意大利对ChatGPT实施禁令后，不同经验的用户生产力表现出差异，经验较少的用户在短期内产出数量和质量均有提升，而经验丰富的用户在更常规的任务上表现出生产力下降。

    

    我们分析了意大利对ChatGPT（一种生成式预训练变换器聊天机器人）的禁令对个人生产力的影响。我们收集了意大利及其他欧洲国家超过36,000名GitHub用户的每日编码输出数量和质量数据，并将这些数据与该禁令的突然宣布结合起来，建立了一个差异性差异框架。在受影响的意大利用户中，我们发现对于经验较少的用户，输出数量和质量短期内增加，而对于经验丰富的用户而言，在更常规的任务上生产力降低。

    arXiv:2403.01964v1 Announce Type: cross  Abstract: We analyse the individual productivity effects of Italy's ban on ChatGPT, a generative pretrained transformer chatbot. We compile data on the daily coding output quantity and quality of over 36,000 GitHub users in Italy and other European countries and combine these data with the sudden announcement of the ban in a difference-in-differences framework. Among the affected users in Italy, we find a short-term increase in output quantity and quality for less experienced users and a decrease in productivity on more routine tasks for experienced users.
    
[^38]: DECIDERS：一种通过模仿双系统认知理论实现规则可控解码策略的语言生成方法

    DECIDER: A Rule-Controllable Decoding Strategy for Language Generation by Imitating Dual-System Cognitive Theory

    [https://arxiv.org/abs/2403.01954](https://arxiv.org/abs/2403.01954)

    DECIDER是一种受双系统认知理论启发的规则可控解码策略，通过在预训练语言模型中引入逻辑推理器，有效地遵循给定规则以引导生成方向朝向目标。

    

    词典约束解码方法旨在通过某些目标概念控制所生成文本的意义或风格。现有方法过于关注这些目标本身，导致缺乏关于如何实现这些目标的高层推理。然而，人类通常通过遵循某些规则来处理任务，这些规则不仅关注于目标本身，还关注于引发目标发生的语义相关概念。在这项工作中，我们提出了DECIDER，这是一种受到双系统认知理论启发的约束语言生成的规则可控解码策略。具体而言，在DECIDER中，一个预训练语言模型（PLM）配备了一个逻辑推理器，以高层规则作为输入。然后，DECIDER允许规则信号在每个解码步骤中流入PLM。广泛的实验结果表明，DECIDER能够有效地遵循给定的规则，引导生成方向朝向目标进行生成。

    arXiv:2403.01954v1 Announce Type: cross  Abstract: Lexicon-based constrained decoding approaches aim to control the meaning or style of the generated text through certain target concepts. Existing approaches over-focus the targets themselves, leading to a lack of high-level reasoning about how to achieve them. However, human usually tackles tasks by following certain rules that not only focuses on the targets but also on semantically relevant concepts that induce the occurrence of targets. In this work, we present DECIDER, a rule-controllable decoding strategy for constrained language generation inspired by dual-system cognitive theory. Specifically, in DECIDER, a pre-trained language model (PLM) is equiped with a logic reasoner that takes high-level rules as input. Then, the DECIDER allows rule signals to flow into the PLM at each decoding step. Extensive experimental results demonstrate that DECIDER can effectively follow given rules to guide generation direction toward the targets i
    
[^39]: 生成还是检索？关于人工环境在医学开放域问答效果的研究

    To Generate or to Retrieve? On the Effectiveness of Artificial Contexts for Medical Open-Domain Question Answering

    [https://arxiv.org/abs/2403.01924](https://arxiv.org/abs/2403.01924)

    本文介绍了MedGENIE，这是医学领域多项选择问题回答的第一个生成后阅读框架。

    

    医学领域的开放域问答需要大量专业知识的支持。近期的努力致力于将知识与模型参数分离，对抗架构规模化，并允许在常见的低资源硬件上进行训练。检索然后阅读的范式已变得普遍，模型预测依赖于来自外部知识库（如PubMed、教科书和UMLS）的相关知识片段。另一条尚未得到充分探索但由于领域特定大型语言模型的出现变得可能的路径是通过提示构建人工环境。因此，“生成还是检索”成为了现代版的哈姆雷特困境。本文提出了MedGENIE，这是医学领域多项选择问答的生成然后阅读框架。我们在MedQA-USMLE、MedMCQA和MMLU上进行了广泛实验，从实践的角度出发，假设最大

    arXiv:2403.01924v1 Announce Type: cross  Abstract: Medical open-domain question answering demands substantial access to specialized knowledge. Recent efforts have sought to decouple knowledge from model parameters, counteracting architectural scaling and allowing for training on common low-resource hardware. The retrieve-then-read paradigm has become ubiquitous, with model predictions grounded on relevant knowledge pieces from external repositories such as PubMed, textbooks, and UMLS. An alternative path, still under-explored but made possible by the advent of domain-specific large language models, entails constructing artificial contexts through prompting. As a result, "to generate or to retrieve" is the modern equivalent of Hamlet's dilemma. This paper presents MedGENIE, the first generate-then-read framework for multiple-choice question answering in medicine. We conduct extensive experiments on MedQA-USMLE, MedMCQA, and MMLU, incorporating a practical perspective by assuming a maxim
    
[^40]: xT：用于大图像中更大上下文的嵌套标记化

    xT: Nested Tokenization for Larger Context in Large Images

    [https://arxiv.org/abs/2403.01915](https://arxiv.org/abs/2403.01915)

    xT为视觉Transformer引入了嵌套标记化方案，有效地聚合了全局背景和局部细节，使其能够在现代GPU上端到端地建模大图像，并在经典视觉任务数据集上展示了改进。

    

    现代计算机视觉流水线以两种次优方式处理大图像：下采样或裁剪。这两种方法导致图像中信息和背景的丢失。在许多下游应用中，全局背景的重要性与高频细节一样，例如在现实世界的卫星图像中；在这种情况下，研究人员必须做出舍弃哪些信息的困扰选择。我们介绍了xT，这是一个简单的视觉Transformer框架，可以有效地聚合全局背景和局部细节，并可以在当代GPU上端对端地对大图像进行建模。我们选择了一组跨经典视觉任务的基准数据集，这些任务准确地反映了视觉模型理解真正大型图像并在大范围内融合细节的能力，并评估了我们的方法在其上的改进。通过引入针对大图像的嵌套标记化方案

    arXiv:2403.01915v1 Announce Type: cross  Abstract: Modern computer vision pipelines handle large images in one of two sub-optimal ways: down-sampling or cropping. These two methods incur significant losses in the amount of information and context present in an image. There are many downstream applications in which global context matters as much as high frequency details, such as in real-world satellite imagery; in such cases researchers have to make the uncomfortable choice of which information to discard. We introduce xT, a simple framework for vision transformers which effectively aggregates global context with local details and can model large images end-to-end on contemporary GPUs. We select a set of benchmark datasets across classic vision tasks which accurately reflect a vision model's ability to understand truly large images and incorporate fine details over large scales and assess our method's improvement on them. By introducing a nested tokenization scheme for large images in 
    
[^41]: 基于伪标签的半监督语义分割：综述

    Semi-Supervised Semantic Segmentation Based on Pseudo-Labels: A Survey

    [https://arxiv.org/abs/2403.01909](https://arxiv.org/abs/2403.01909)

    这项综述提供了关于基于伪标签方法在半监督语义分割领域最新研究成果的全面且有组织的概述，探讨了伪标签技术在不同应用领域的具体方法，还研究了其在医学和遥感图像分割中的应用，提出了未来研究方向。

    

    语义分割是计算机视觉中一个重要且热门的研究领域，侧重于基于语义对图像中的像素进行分类。然而，监督学习需要大量数据来训练模型，而逐像素标记图像的过程耗时且繁琐。本综述旨在提供半监督语义分割领域中伪标签方法的最新研究成果的首次综合和有组织的概述，我们从不同角度对其进行分类，并提出了针对特定应用领域的具体方法。此外，我们还探讨了伪标签技术在医学和遥感图像分割中的应用。最后，我们还提出了一些可行的未来研究方向，以解决现有挑战。

    arXiv:2403.01909v1 Announce Type: cross  Abstract: Semantic segmentation is an important and popular research area in computer vision that focuses on classifying pixels in an image based on their semantics. However, supervised deep learning requires large amounts of data to train models and the process of labeling images pixel by pixel is time-consuming and laborious. This review aims to provide a first comprehensive and organized overview of the state-of-the-art research results on pseudo-label methods in the field of semi-supervised semantic segmentation, which we categorize from different perspectives and present specific methods for specific application areas. In addition, we explore the application of pseudo-label technology in medical and remote-sensing image segmentation. Finally, we also propose some feasible future research directions to address the existing challenges.
    
[^42]: 无监督距离度量学习用于多变量时间序列异常检测

    Unsupervised Distance Metric Learning for Anomaly Detection Over Multivariate Time Series

    [https://arxiv.org/abs/2403.01895](https://arxiv.org/abs/2403.01895)

    提出了一种无监督距离度量学习方法FCM-wDTW，用于多变量时间序列异常检测，通过将原始数据编码成潜在空间并通过聚类中心揭示正常维度关系，在实验中表现出竞争力的准确性和效率。

    

    基于距离的时间序列异常检测方法由于其相对非参数化的特性和可解释性而广泛存在。然而，常用的欧几里得距离对噪声敏感。虽然现有工作已经探讨了动态时间规整（DTW）以增强其稳健性，但它们仅支持多变量时间序列（MTS）上的监督任务，缺乏无监督方法。在这项工作中，我们提出了FCM-wDTW，一种用于多变量时间序列异常检测的无监督距离度量学习方法，它将原始数据编码成潜在空间，并通过聚类中心揭示正常维度关系。FCM-wDTW将局部加权DTW引入到模糊C均值聚类中，并有效地学习最佳的潜在空间，从而通过数据重建实现异常识别。针对11种不同类型的基准进行的实验表明，我们的方法具有竞争力的准确性和效率。

    arXiv:2403.01895v1 Announce Type: cross  Abstract: Distance-based time series anomaly detection methods are prevalent due to their relative non-parametric nature and interpretability. However, the commonly used Euclidean distance is sensitive to noise. While existing works have explored dynamic time warping (DTW) for its robustness, they only support supervised tasks over multivariate time series (MTS), leaving a scarcity of unsupervised methods. In this work, we propose FCM-wDTW, an unsupervised distance metric learning method for anomaly detection over MTS, which encodes raw data into latent space and reveals normal dimension relationships through cluster centers. FCM-wDTW introduces locally weighted DTW into fuzzy C-means clustering and learns the optimal latent space efficiently, enabling anomaly identification via data reconstruction. Experiments with 11 different types of benchmarks demonstrate our method's competitive accuracy and efficiency.
    
[^43]: 零成本基准上异步多保真度优化的快速基准测试

    Fast Benchmarking of Asynchronous Multi-Fidelity Optimization on Zero-Cost Benchmarks

    [https://arxiv.org/abs/2403.01888](https://arxiv.org/abs/2403.01888)

    通过引入用户友好的Python软件包，研究提出了有效的并行HPO方法，避免长时间等待实现快速评估。

    

    尽管深度学习取得了许多成功，但其结果往往取决于超参数的精心选择。然而，深度学习训练的耗时性使得超参数优化(HPO)是一项昂贵的工作，拖慢了高效HPO工具的开发。本工作通过引入一个用户友好的Python软件包，来解决这一挑战，促进零成本基准下高效的并行HPO。我们的方法根据存储在文件系统中的信息计算精确的返回顺序，消除了长时间的等待，实现了更快的HPO评估。

    arXiv:2403.01888v1 Announce Type: new  Abstract: While deep learning has celebrated many successes, its results often hinge on the meticulous selection of hyperparameters (HPs). However, the time-consuming nature of deep learning training makes HP optimization (HPO) a costly endeavor, slowing down the development of efficient HPO tools. While zero-cost benchmarks, which provide performance and runtime without actual training, offer a solution for non-parallel setups, they fall short in parallel setups as each worker must communicate its queried runtime to return its evaluation in the exact order. This work addresses this challenge by introducing a user-friendly Python package that facilitates efficient parallel HPO with zero-cost benchmarks. Our approach calculates the exact return order based on the information stored in file system, eliminating the need for long waiting times and enabling much faster HPO evaluations. We first verify the correctness of our approach through extensive t
    
[^44]: FCDS: 将短语结构和依存句法融合到文档级关系抽取中

    FCDS: Fusing Constituency and Dependency Syntax into Document-Level Relation Extraction

    [https://arxiv.org/abs/2403.01886](https://arxiv.org/abs/2403.01886)

    本研究将短语结构和依存句法融合到文档级关系抽取中，有效利用了文档中的丰富语法信息。

    

    文档级关系抽取（DocRE）旨在识别单个文档内实体之间的关系标签。本文提出将短语结构和依存句法融合到DocRE中，利用短语结构聚合整个句子信息并选择目标对的指导性句子，利用依存句法在图结构中进行增强，并根据依存图选择实体对之间的路径。实验结果表明所提出的方法的有效性。

    arXiv:2403.01886v1 Announce Type: cross  Abstract: Document-level Relation Extraction (DocRE) aims to identify relation labels between entities within a single document. It requires handling several sentences and reasoning over them. State-of-the-art DocRE methods use a graph structure to connect entities across the document to capture dependency syntax information. However, this is insufficient to fully exploit the rich syntax information in the document. In this work, we propose to fuse constituency and dependency syntax into DocRE. It uses constituency syntax to aggregate the whole sentence information and select the instructive sentences for the pairs of targets. It exploits the dependency syntax in a graph structure with constituency syntax enhancement and chooses the path between entity pairs based on the dependency graph. The experimental results on datasets from various domains demonstrate the effectiveness of the proposed method. The code is publicly available at this url.
    
[^45]: ICLN：输入凸损失网络用于决策集中学习

    ICLN: Input Convex Loss Network for Decision Focused Learning

    [https://arxiv.org/abs/2403.01875](https://arxiv.org/abs/2403.01875)

    提出了输入凸损失网络（ICLN），通过输入凸神经网络学习任务损失，为决策集中学习提供了全局替代损失。

    

    在不确定性条件下的决策问题中，预测未知参数通常被认为与优化部分无关。决策集中学习（DFL）是一个面向任务的框架，通过调整预测模型以为相应任务提供更好的决策来整合预测和优化。本文提出了输入凸损失网络（ICLN），这是一种新颖的全局替代损失，可以在一般的DFL范式中实现。ICLN通过输入凸神经网络学习任务损失，已经被保证为某些情况下是凸的。

    arXiv:2403.01875v1 Announce Type: cross  Abstract: In decision-making problem under uncertainty, predicting unknown parameters is often considered independent of the optimization part. Decision-focused Learning (DFL) is a task-oriented framework to integrate prediction and optimization by adapting predictive model to give better decision for the corresponding task. Here, an inevitable challenge arises when computing gradients of the optimal decision with respect to the parameters. Existing researches cope this issue by smoothly reforming surrogate optimization or construct surrogate loss function that mimic task loss. However, they are applied to restricted optimization domain or build functions in a local manner leading a large computational time. In this paper, we propose Input Convex Loss Network (ICLN), a novel global surrogate loss which can be implemented in a general DFL paradigm. ICLN learns task loss via Input Convex Neural Networks which is guaranteed to be convex for some in
    
[^46]: AiSDF：室内场景中的结构感知神经有符号距离场

    AiSDF: Structure-aware Neural Signed Distance Fields in Indoor Scenes

    [https://arxiv.org/abs/2403.01861](https://arxiv.org/abs/2403.01861)

    提出了一种针对室内场景的结构感知在线有符号距离场（SDF）重建框架，可根据亚特兰大结构估计平面surfel区域，从而带来更高质量的重建结果。

    

    我们生活的室内场景在视觉上是均质或无纹理的，但它们本质上具有结构形式，并为3D场景重建提供了足够的结构先验。受这一事实的启发，我们提出了一种针对室内场景特别是在亚特兰大世界（AW）假设下的结构感知在线有符号距离场（SDF）重建框架。因此，我们将这种增量SDF重建称为AiSDF。在在线框架内，我们推断给定场景的潜在亚特兰大结构，然后估计支持亚特兰大结构的平面surfel区域。这种亚特兰大感知的surfel表示为给定场景提供了明确的平面地图。此外，基于这些亚特兰大平面surfel区域，我们自适应地采样和约束SDF重建中的结构规律，从而通过保持高水平结构同时增强细节来提高重建质量。

    arXiv:2403.01861v1 Announce Type: cross  Abstract: Indoor scenes we are living in are visually homogenous or textureless, while they inherently have structural forms and provide enough structural priors for 3D scene reconstruction. Motivated by this fact, we propose a structure-aware online signed distance fields (SDF) reconstruction framework in indoor scenes, especially under the Atlanta world (AW) assumption. Thus, we dub this incremental SDF reconstruction for AW as AiSDF. Within the online framework, we infer the underlying Atlanta structure of a given scene and then estimate planar surfel regions supporting the Atlanta structure. This Atlanta-aware surfel representation provides an explicit planar map for a given scene. In addition, based on these Atlanta planar surfel regions, we adaptively sample and constrain the structural regularity in the SDF reconstruction, which enables us to improve the reconstruction quality by maintaining a high-level structure while enhancing the deta
    
[^47]: 重新思考LLM语言适应性：以中文Mixtral为例

    Rethinking LLM Language Adaptation: A Case Study on Chinese Mixtral

    [https://arxiv.org/abs/2403.01851](https://arxiv.org/abs/2403.01851)

    本文以中文Mixtral为案例，提出了改进的中文语言能力的Mixtral模型，并讨论了在大型语言模型进行语言适应时的关键问题。

    

    Mixtral是一种代表性的稀疏专家混合(SMoE)语言模型，由于其独特的模型设计和卓越的性能而受到广泛关注。本文以Mixtral-8x7B-v0.1为基础，提出了改进的中文-Mixtral和中文-Mixtral-Instruct，通过进一步的预训练和指导微调提高了中文语言能力。实验结果表明，我们的中文-Mixtral和中文-Mixtral-Instruct成功提升了中文理解和生成性能，同时保留了原始的英文能力。然后，我们讨论了在大型语言模型进行语言适应时的一些关键问题，包括扩展语言特定词汇的必要性以及初始化模型的选择（基础模型vs.指导模型），通过提供实证结果和分析。我们还呈现了每个专家的可视化结果以检验其重要性。

    arXiv:2403.01851v1 Announce Type: cross  Abstract: Mixtral, a representative sparse mixture of experts (SMoE) language model, has received significant attention due to its unique model design and superior performance. Based on Mixtral-8x7B-v0.1, in this paper, we propose Chinese-Mixtral and Chinese-Mixtral-Instruct with improved Chinese language abilities by adopting further pre-training and instruction fine-tuning. Experimental results show that our Chinese-Mixtral and Chinese-Mixtral-Instruct successfully improve Chinese understanding and generation performance while retaining the original English abilities. Then, we discuss several key questions when performing language adaptation on large language models, including the necessity of extending the language-specific vocabulary and the choice of the initialization model (foundation model v.s. instruction model), by providing empirical results and analysis. We also present the visualizations of each expert to examine their importance on
    
[^48]: 一个提示词就足以提升预训练视觉-语言模型的对抗鲁棒性

    One Prompt Word is Enough to Boost Adversarial Robustness for Pre-trained Vision-Language Models

    [https://arxiv.org/abs/2403.01849](https://arxiv.org/abs/2403.01849)

    本文研究了预训练视觉-语言模型的对抗鲁棒性，提出了一种通过学习强韧文本提示来改善对抗攻击韧性的方法，称为Adversarial Prompt Tuning（APT），并在多个数据集和数据稀疏方案上进行了全面实验验证。

    

    像CLIP这样的大型预训练视觉-语言模型（VLMs），尽管具有显着的泛化能力，但对于对抗样本非常脆弱。本文从文本提示的新颖视角而非传统研究的模型权重（在本文中冻结）研究了VLMs的对抗鲁棒性。我们首先展示了对抗攻击和防御的有效性对使用的文本提示敏感。在此启发下，我们提出了一种通过学习VLMs的强韧文本提示来提高对抗攻击韧性的方法。提出的方法，称为Adversarial Prompt Tuning（APT），在计算和数据效率方面都非常有效。通过在15个数据集和4种数据稀疏方案（从1-shot到完全训练数据设置）上进行了大量实验，以展示APT相对于手工设计提示和其他最先进的适应方法的优越性。APT表现出色

    arXiv:2403.01849v1 Announce Type: cross  Abstract: Large pre-trained Vision-Language Models (VLMs) like CLIP, despite having remarkable generalization ability, are highly vulnerable to adversarial examples. This work studies the adversarial robustness of VLMs from the novel perspective of the text prompt instead of the extensively studied model weights (frozen in this work). We first show that the effectiveness of both adversarial attack and defense are sensitive to the used text prompt. Inspired by this, we propose a method to improve resilience to adversarial attacks by learning a robust text prompt for VLMs. The proposed method, named Adversarial Prompt Tuning (APT), is effective while being both computationally and data efficient. Extensive experiments are conducted across 15 datasets and 4 data sparsity schemes (from 1-shot to full training data settings) to show APT's superiority over hand-engineered prompts and other state-of-the-art adaption methods. APT demonstrated excellent 
    
[^49]: NASH：用于硬件优化机器学习模型的神经架构搜索

    NASH: Neural Architecture Search for Hardware-Optimized Machine Learning Models

    [https://arxiv.org/abs/2403.01845](https://arxiv.org/abs/2403.01845)

    NASH是一种将神经架构搜索应用于机器学习硬件的新方法，可以帮助硬件设计实现高吞吐量、低延迟和优越的准确性表现。

    

    随着机器学习（ML）算法在越来越多的应用中部署，这些算法需要在高准确性、高吞吐量和低延迟之间取得更好的权衡。本文介绍了一种名为NASH的新方法，将神经架构搜索应用于机器学习硬件。使用NASH，硬件设计不仅可以实现高吞吐量和低延迟，还可以实现优越的准确性表现。本文提出了四个版本的NASH策略，所有这些策略显示出比原始模型更高的准确性。该策略可以应用于各种卷积神经网络，从众多模型操作中选择特定操作，引导训练过程朝向更高的准确性。实验结果显示，在 ResNet18 或 ResNet34 上应用NASH，与非NASH版本相比，可使Top1准确率提高高达3.1%，Top5准确率提高高达2.2%。

    arXiv:2403.01845v1 Announce Type: cross  Abstract: As machine learning (ML) algorithms get deployed in an ever-increasing number of applications, these algorithms need to achieve better trade-offs between high accuracy, high throughput and low latency. This paper introduces NASH, a novel approach that applies neural architecture search to machine learning hardware. Using NASH, hardware designs can achieve not only high throughput and low latency but also superior accuracy performance. We present four versions of the NASH strategy in this paper, all of which show higher accuracy than the original models. The strategy can be applied to various convolutional neural networks, selecting specific model operations among many to guide the training process toward higher accuracy. Experimental results show that applying NASH on ResNet18 or ResNet34 achieves a top 1 accuracy increase of up to 3.1% and a top 5 accuracy increase of up to 2.2% compared to the non-NASH version when tested on the Imag
    
[^50]: 使用自由注释标签进行人-物互动检测的FreeA方法

    FreeA: Human-object Interaction Detection using Free Annotation Labels

    [https://arxiv.org/abs/2403.01840](https://arxiv.org/abs/2403.01840)

    提出了一种新颖的自适应语言驱动的HOI检测方法FreeA，无需标记，利用了CLIP来生成潜在的HOI标签，并在两个基准数据集上取得了最先进的性能。

    

    最近的人-物互动（HOI）检测方法依赖于劳动力成本高昂，并需要全面注释的图像数据集。本文提出了一种新颖的自适应语言驱动的HOI检测方法FreeA，这种方法利用了CLIP的适应性来生成潜在的HOI标签，无需标记。具体而言，FreeA将人-物对的图像特征与HOI文本模板进行匹配，并开发了基于先验知识的掩模方法来抑制不太可能的交互作用。此外，FreeA利用了提出的交互相关性匹配方法来增强与指定动作相关的动作的可能性，进一步完善生成的HOI标签。在两个基准数据集上的实验证明，FreeA在弱监督HOI模型中实现了最先进的性能。我们的方法在HICO-DET上的平均精度（mAP）提高了+8.58，在V-COCO上提高了+1.23。

    arXiv:2403.01840v1 Announce Type: cross  Abstract: Recent human-object interaction (HOI) detection approaches rely on high cost of manpower and require comprehensive annotated image datasets. In this paper, we propose a novel self-adaption language-driven HOI detection method, termed as FreeA, without labeling by leveraging the adaptability of CLIP to generate latent HOI labels. To be specific, FreeA matches image features of human-object pairs with HOI text templates, and a priori knowledge-based mask method is developed to suppress improbable interactions. In addition, FreeA utilizes the proposed interaction correlation matching method to enhance the likelihood of actions related to a specified action, further refine the generated HOI labels. Experiments on two benchmark datasets show that FreeA achieves state-of-the-art performance among weakly supervised HOI models. Our approach is +8.58 mean Average Precision (mAP) on HICO-DET and +1.23 mAP on V-COCO more accurate in localizing an
    
[^51]: 基于模型的数据中心人工智能：弥合学术理想与工业实用之间的鸿沟

    Model-Based Data-Centric AI: Bridging the Divide Between Academic Ideals and Industrial Pragmatism

    [https://arxiv.org/abs/2403.01832](https://arxiv.org/abs/2403.01832)

    本文提出了一种新的模型-Based Data-Centric AI 范式，旨在解决学术界数据质量和工业应用之间的差异，并提出了整合模型考虑到数据优化过程中的策略。

    

    本文探讨了学术和工业领域内数据的对比角色，突出了数据中心人工智能和模型无关人工智能方法之间的分歧。我们认为，数据中心人工智能侧重于高质量数据对模型性能的首要性，而模型无关人工智能则优先考虑算法灵活性，往往以牺牲数据质量考虑为代价。这种区别显示，学术界对数据质量的标准往往不能满足工业应用的严格要求，从而导致在实际环境中部署学术模型的潜在问题。通过全面分析，我们解决了这些差异，提出了它们带来的挑战以及弥合差距的策略。此外，我们提出了一种新范式：基于模型的数据中心人工智能，旨在通过将模型考虑融入数据优化过程来调和这些差异。这种方法

    arXiv:2403.01832v1 Announce Type: new  Abstract: This paper delves into the contrasting roles of data within academic and industrial spheres, highlighting the divergence between Data-Centric AI and Model-Agnostic AI approaches. We argue that while Data-Centric AI focuses on the primacy of high-quality data for model performance, Model-Agnostic AI prioritizes algorithmic flexibility, often at the expense of data quality considerations. This distinction reveals that academic standards for data quality frequently do not meet the rigorous demands of industrial applications, leading to potential pitfalls in deploying academic models in real-world settings. Through a comprehensive analysis, we address these disparities, presenting both the challenges they pose and strategies for bridging the gap. Furthermore, we propose a novel paradigm: Model-Based Data-Centric AI, which aims to reconcile these differences by integrating model considerations into data optimization processes. This approach u
    
[^52]: 分析和基于全 memristor 的时间数据分类的储层计算

    Analysis and Fully Memristor-based Reservoir Computing for Temporal Data Classification

    [https://arxiv.org/abs/2403.01827](https://arxiv.org/abs/2403.01827)

    本研究引入了一种新颖的双存储器 RC 系统，通过集成不同类型的 memristor，并在处理时间数据分类任务中取得了显著成效。

    

    arXiv:2403.01827v1 公告类型: 交叉摘要: 储层计算（RC）提供了一个特别适用于处理时空信号的神经形态学框架。RC以其时间处理能力而闻名，与传统的递归神经网络相比，显著降低了训练成本。其硬件部署中的一个关键组成部分是能够生成动态储层状态的能力。我们的研究引入了一种新颖的双重存储器 RC 系统，集成了一种基于 WOx 的 memristor 的短期存储器，能够实现 16 个不同状态的编码超过 4 个比特，并在读出层中使用 TiOx-based memristor 的长期存储器组件。我们彻底研究了两种 memristor 类型，并利用 RC 系统处理时间数据集。所提出的 RC 系统的性能通过两个基准任务进行了验证: 对具有不完整输入的孤立口述数字识别和 Mackey-Glass 时间序列预测。该系统提供了令人印象深刻的 98.84% 准确率.

    arXiv:2403.01827v1 Announce Type: cross  Abstract: Reservoir computing (RC) offers a neuromorphic framework that is particularly effective for processing spatiotemporal signals. Known for its temporal processing prowess, RC significantly lowers training costs compared to conventional recurrent neural networks. A key component in its hardware deployment is the ability to generate dynamic reservoir states. Our research introduces a novel dual-memory RC system, integrating a short-term memory via a WOx-based memristor, capable of achieving 16 distinct states encoded over 4 bits, and a long-term memory component using a TiOx-based memristor within the readout layer. We thoroughly examine both memristor types and leverage the RC system to process temporal data sets. The performance of the proposed RC system is validated through two benchmark tasks: isolated spoken digit recognition with incomplete inputs and Mackey-Glass time series prediction. The system delivered an impressive 98.84% accu
    
[^53]: 使用语言的RT-H动作层次结构

    RT-H: Action Hierarchies Using Language

    [https://arxiv.org/abs/2403.01823](https://arxiv.org/abs/2403.01823)

    通过教会机器人动作语言，描述低级运动，并将语言动作作为中间步骤来预测任务和动作之间的关系，从而促使策略学习共享结构。

    

    语言为将复杂概念分解为可消化的部分提供了一种方式。最近在机器人模仿学习中的工作使用以语言为条件的策略，根据视觉观察和语言中指定的高级任务来预测动作。这些方法利用自然语言的结构在多任务数据集中在语义上相似的任务之间共享数据（例如，“拿可乐罐”和“摘苹果”）。然而，随着任务在语义上变得更加多样化（例如，“拿可乐罐”和“倒杯子”），任务之间共享数据变得更加困难，因此学习将高级任务映射到动作需要更多的演示数据。为了架起任务和动作之间的桥梁，我们的idea是教会机器人动作语言，用更精细的短语描述低级运动，例如“向前移动手臂”。将这些语言动作作为任务和动作之间的中间步骤来预测迫使策略学习共享结构。

    arXiv:2403.01823v1 Announce Type: cross  Abstract: Language provides a way to break down complex concepts into digestible pieces. Recent works in robot imitation learning use language-conditioned policies that predict actions given visual observations and the high-level task specified in language. These methods leverage the structure of natural language to share data between semantically similar tasks (e.g., "pick coke can" and "pick an apple") in multi-task datasets. However, as tasks become more semantically diverse (e.g., "pick coke can" and "pour cup"), sharing data between tasks becomes harder, so learning to map high-level tasks to actions requires much more demonstration data. To bridge tasks and actions, our insight is to teach the robot the language of actions, describing low-level motions with more fine-grained phrases like "move arm forward". Predicting these language motions as an intermediate step between tasks and actions forces the policy to learn the shared structure of
    
[^54]: AllSpark: 利用Transformer中未标记的特征重新生成标记特征，用于半监督语义分割

    AllSpark: Reborn Labeled Features from Unlabeled in Transformer for Semi-Supervised Semantic Segmentation

    [https://arxiv.org/abs/2403.01818](https://arxiv.org/abs/2403.01818)

    AllSpark利用通道级交叉注意机制从未标记的特征中重新生成标记特征，以改善半监督语义分割中低质量伪标签的问题。

    

    半监督语义分割（SSSS）旨在减轻耗时的像素级手动标注负担，它利用有限的标记数据以及更多的未标记数据。目前最先进的方法使用基准真值训练标记数据和使用伪标签训练未标记数据。然而，这两种训练流程是分开的，这使得标记数据主导训练过程，导致低质量的伪标签和从而次优的结果。为了解决这个问题，我们提出了AllSpark，利用通道级交叉注意机制从未标记的特征中重新生成标记的特征。我们进一步引入了语义记忆和通道语义分组策略，以确保未标记特征充分代表标记特征。AllSpark为SSSS的架构级设计带来了新的视角，而非框架级别，避免了越来越常见的问题。

    arXiv:2403.01818v1 Announce Type: cross  Abstract: Semi-supervised semantic segmentation (SSSS) has been proposed to alleviate the burden of time-consuming pixel-level manual labeling, which leverages limited labeled data along with larger amounts of unlabeled data. Current state-of-the-art methods train the labeled data with ground truths and unlabeled data with pseudo labels. However, the two training flows are separate, which allows labeled data to dominate the training process, resulting in low-quality pseudo labels and, consequently, sub-optimal results. To alleviate this issue, we present AllSpark, which reborns the labeled features from unlabeled ones with the channel-wise cross-attention mechanism. We further introduce a Semantic Memory along with a Channel Semantic Grouping strategy to ensure that unlabeled features adequately represent labeled features. The AllSpark shed new light on the architecture level designs of SSSS rather than framework level, which avoids increasingly
    
[^55]: SMAUG：基于滑动多维任务窗口的适应性实时子任务识别MARL框架

    SMAUG: A Sliding Multidimensional Task Window-Based MARL Framework for Adaptive Real-Time Subtask Recognition

    [https://arxiv.org/abs/2403.01816](https://arxiv.org/abs/2403.01816)

    SMAUG框架提出了基于滑动多维任务窗口的适应性实时子任务识别方法，与传统方法相比，提高了灵活性和适用性。

    

    与直接从指数级扩展的联合观察-动作空间中作出行为决策不同，基于子任务的多智能体强化学习（MARL）方法使智能体能够学习如何处理不同的子任务。现有大多数基于子任务的MARL方法基于分层强化学习（HRL）。然而，这些方法通常限制子任务的数量，周期性执行子任务识别，并且只能在预定义的固定时间段内识别和执行特定子任务，这使它们缺乏灵活性，不适用于具有不断变化子任务的多样化动态场景。为了突破上述限制，提出了一个基于滑动多维任务窗口的多智能体强化学习框架（SMAUG）用于自适应实时子任务识别。它利用滑动多维任务窗口来提取必要信息。

    arXiv:2403.01816v1 Announce Type: new  Abstract: Instead of making behavioral decisions directly from the exponentially expanding joint observational-action space, subtask-based multi-agent reinforcement learning (MARL) methods enable agents to learn how to tackle different subtasks. Most existing subtask-based MARL methods are based on hierarchical reinforcement learning (HRL). However, these approaches often limit the number of subtasks, perform subtask recognition periodically, and can only identify and execute a specific subtask within the predefined fixed time period, which makes them inflexible and not suitable for diverse and dynamic scenarios with constantly changing subtasks. To break through above restrictions, a \textbf{S}liding \textbf{M}ultidimensional t\textbf{A}sk window based m\textbf{U}ti-agent reinforcement learnin\textbf{G} framework (SMAUG) is proposed for adaptive real-time subtask recognition. It leverages a sliding multidimensional task window to extract essentia
    
[^56]: COLA: 跨城市移动性转换器用于人类轨迹模拟

    COLA: Cross-city Mobility Transformer for Human Trajectory Simulation

    [https://arxiv.org/abs/2403.01801](https://arxiv.org/abs/2403.01801)

    研究通过将强大的Transformer模型与外部移动数据相结合，探讨了跨城市人类轨迹模拟的问题，解决了知识转移中的适应性挑战。

    

    由日常移动设备产生的人类轨迹数据在城市规划和疫情防控等重要领域证明了其实用性。针对个人隐私问题，人类轨迹模拟引起了研究人员越来越多的关注，旨在为下游任务提供大量逼真的移动数据。然而，数据稀缺的普遍问题无疑降低了现有深度学习模型的可靠性。本文旨在探讨跨城市移动性转移的问题，把握人类轨迹的普遍模式，为Transformer模型增加外部移动数据。在跨城市知识转移中出现了两个关键挑战：1）如何使Transformer适应领域的异质性；2）如何校准Transformer以适应细微不同的长尾频率分布。

    arXiv:2403.01801v1 Announce Type: cross  Abstract: Human trajectory data produced by daily mobile devices has proven its usefulness in various substantial fields such as urban planning and epidemic prevention. In terms of the individual privacy concern, human trajectory simulation has attracted increasing attention from researchers, targeting at offering numerous realistic mobility data for downstream tasks. Nevertheless, the prevalent issue of data scarcity undoubtedly degrades the reliability of existing deep learning models. In this paper, we are motivated to explore the intriguing problem of mobility transfer across cities, grasping the universal patterns of human trajectories to augment the powerful Transformer with external mobility data. There are two crucial challenges arising in the knowledge transfer across cities: 1) how to transfer the Transformer to adapt for domain heterogeneity; 2) how to calibrate the Transformer to adapt for subtly different long-tail frequency distrib
    
[^57]: 超越推荐系统：对AI辅助决策中不同AI角色影响的探索性研究

    Beyond Recommender: An Exploratory Study of the Effects of Different AI Roles in AI-Assisted Decision Making

    [https://arxiv.org/abs/2403.01791](https://arxiv.org/abs/2403.01791)

    本研究探讨了AI辅助决策中不同AI角色（推荐系统、分析者和魔鬼的辩护者）的影响，发现它们在任务表现、依赖适当性和用户体验方面各有优势和局限性。

    

    人工智能（AI）越来越多地应用于各种决策任务中，通常作为一个推荐系统，提供AI认为正确的建议。然而，最近的研究表明，这可能会削弱人类分析思维，并导致人类不恰当地依赖AI，损害人工智能团队的协同效应。相比之下，在群体决策中的人类顾问扮演各种角色，例如分析替代选项或批评决策者以鼓励他们的批判性思维。这种角色的多样性尚未在AI辅助中得到实证探究。在本文中，我们研究三种AI角色：推荐系统、分析者和魔鬼的辩护者，并评估它们在两种AI性能水平下的影响。我们的结果显示每种角色在任务表现、依赖适当性和用户体验方面具有独特的优势和局限性。值得注意的是，推荐系统角色并非始终最有效，特别是在...

    arXiv:2403.01791v1 Announce Type: cross  Abstract: Artificial Intelligence (AI) is increasingly employed in various decision-making tasks, typically as a Recommender, providing recommendations that the AI deems correct. However, recent studies suggest this may diminish human analytical thinking and lead to humans' inappropriate reliance on AI, impairing the synergy in human-AI teams. In contrast, human advisors in group decision-making perform various roles, such as analyzing alternative options or criticizing decision-makers to encourage their critical thinking. This diversity of roles has not yet been empirically explored in AI assistance. In this paper, we examine three AI roles: Recommender, Analyzer, and Devil's Advocate, and evaluate their effects across two AI performance levels. Our results show each role's distinct strengths and limitations in task performance, reliance appropriateness, and user experience. Notably, the Recommender role is not always the most effective, especi
    
[^58]: CatCode：一种用于LLMs在代码和文本混合方面的全面评估框架

    CatCode: A Comprehensive Evaluation Framework for LLMs On the Mixture of Code and Text

    [https://arxiv.org/abs/2403.01784](https://arxiv.org/abs/2403.01784)

    CatCode提出了一种基于范畴论的评估框架，可以全面评估LLMs在解决编程问题时的编码能力。

    

    大型语言模型（LLMs）如ChatGPT在理解和生成代码和文本混合方面越来越精通。基于这种混合的评估可以更全面地了解模型在解决编程问题时的能力。为了解决当前评估方法在任务覆盖范围上的限制或缺乏标准化的问题，我们提出使用范畴论作为评估框架。具体而言，代码范畴中的态射可以表示代码调试和转换，两个范畴之间的函子表示代码翻译，代码范畴和自然语言范畴之间的函子表示代码生成、解释和再现。我们提出了一个名为CatCode（Category Code）的自动评估框架，可以全面评估LLMs（包括ChatGPT）的编码能力。

    arXiv:2403.01784v1 Announce Type: new  Abstract: Large language models (LLMs) such as ChatGPT are increasingly proficient in understanding and generating a mixture of code and text. Evaluation based on such $\textit{mixture}$ can lead to a more comprehensive understanding of the models' abilities in solving coding problems. However, in this context, current evaluation methods are either limited in task coverage or lack standardization. To address this issue, we propose using category theory as a framework for evaluation. Specifically, morphisms within a code category can represent code debugging and transformation, functors between two categories represent code translation, and functors between a code category and a natural language category represent code generation, explanation, and reproduction. We present an automatic evaluation framework called $\textbf{CatCode}$ ($\textbf{Cat}$egory $\textbf{Code}$) that can comprehensively assess the coding abilities of LLMs, including ChatGPT, 
    
[^59]: 整合高效的最优输运和功能映射，用于无监督形状对应学习

    Integrating Efficient Optimal Transport and Functional Maps For Unsupervised Shape Correspondence Learning

    [https://arxiv.org/abs/2403.01781](https://arxiv.org/abs/2403.01781)

    该论文将光谱方法与深度学习相结合，通过使用切片Wasserstein距离（SWD）进行最优输运，在无监督形状匹配框架中实现了功能映射和最优输运的高效整合。

    

    在计算机视觉和图形领域中，准确建立几何3D形状之间的对应对于对象跟踪、配准、纹理转移和统计形状分析等应用至关重要。我们将光谱方法与深度学习相结合，聚焦于功能映射（FMs）和最优输运（OT），从而超越传统的手工制作和数据驱动特征学习方法。我们的关键贡献是采用切片Wasserstein距离（SWD）用于OT，这是一种在无监督形状匹配框架中有效且快速的最优输运度量。该无监督框架将功能映射正则化器与从SWD导出的新型OT损失集成在一起，增强了被视为离散概率测度的形状之间的特征对齐。

    arXiv:2403.01781v1 Announce Type: cross  Abstract: In the realm of computer vision and graphics, accurately establishing correspondences between geometric 3D shapes is pivotal for applications like object tracking, registration, texture transfer, and statistical shape analysis. Moving beyond traditional hand-crafted and data-driven feature learning methods, we incorporate spectral methods with deep learning, focusing on functional maps (FMs) and optimal transport (OT). Traditional OT-based approaches, often reliant on entropy regularization OT in learning-based framework, face computational challenges due to their quadratic cost. Our key contribution is to employ the sliced Wasserstein distance (SWD) for OT, which is a valid fast optimal transport metric in an unsupervised shape matching framework. This unsupervised framework integrates functional map regularizers with a novel OT-based loss derived from SWD, enhancing feature alignment between shapes treated as discrete probability mea
    
[^60]: 通过分层语义环境改善图中的超出分布泛化

    Improving out-of-distribution generalization in graphs via hierarchical semantic environments

    [https://arxiv.org/abs/2403.01773](https://arxiv.org/abs/2403.01773)

    通过生成分层语义环境，本文提出了一种新方法来增强图的不变学习，以处理分布转移。

    

    在图领域中，由于复杂的分布转移和缺乏环境背景，图的超出分布（OOD）泛化具有挑战性。最近的方法尝试通过生成平面环境来增强图的OOD泛化。然而，这种平面环境存在固有的局限性，无法捕捉更复杂的数据分布。因此，针对包含各种训练环境（如骨架、大小等）的DrugOOD数据集，平面环境无法充分解决其高异质性。因此，提出了一个新的挑战，即生成更具语义丰富的环境，以增强图的不变学习以处理分布转移。在本文中，我们提出了一种新颖的方法，为每个图生成分层语义环境。首先，给定输入图，我们明确地提取输入图中的变体子图，以在本地环境上生成代理预测。然后，随机注意...

    arXiv:2403.01773v1 Announce Type: cross  Abstract: Out-of-distribution (OOD) generalization in the graph domain is challenging due to complex distribution shifts and a lack of environmental contexts. Recent methods attempt to enhance graph OOD generalization by generating flat environments. However, such flat environments come with inherent limitations to capture more complex data distributions. Considering the DrugOOD dataset, which contains diverse training environments (e.g., scaffold, size, etc.), flat contexts cannot sufficiently address its high heterogeneity. Thus, a new challenge is posed to generate more semantically enriched environments to enhance graph invariant learning for handling distribution shifts. In this paper, we propose a novel approach to generate hierarchical semantic environments for each graph. Firstly, given an input graph, we explicitly extract variant subgraphs from the input graph to generate proxy predictions on local environments. Then, stochastic attent
    
[^61]: 具有双层优化的$\nu$支持向量机安全筛选规则

    A Safe Screening Rule with Bi-level Optimization of $\nu$ Support Vector Machine

    [https://arxiv.org/abs/2403.01769](https://arxiv.org/abs/2403.01769)

    提出了一种具有双层优化的安全筛选规则的$\nu$支持向量机方法，可以在训练前筛选出不活跃样本，降低计算成本，同时不损失预测准确性。

    

    支持向量机（SVM）在机器学习中取得了许多成功，尤其是在小样本问题上。作为传统SVM的一个著名扩展，$\nu$支持向量机（$\nu$-SVM）由于其出色的模型可解释性而表现卓越。然而，对于大规模问题，它仍面临训练开销的挑战。为了解决这个问题，我们提出了一种具有双层优化的$\nu$-SVM安全筛选规则（SRBO-$\nu$-SVM），可以在训练之前筛选出不活跃的样本，并降低计算成本，而不会牺牲预测准确性。我们的SRBO-$\nu$-SVM严格地通过整合KKT条件、凸问题的变分不等式和$\nu$属性推导而来。此外，我们开发了一种高效的对偶坐标下降方法（DCDM）来进一步提高计算速度。最后，提出了一个用于SRBO的统一框架。

    arXiv:2403.01769v1 Announce Type: cross  Abstract: Support vector machine (SVM) has achieved many successes in machine learning, especially for a small sample problem. As a famous extension of the traditional SVM, the $\nu$ support vector machine ($\nu$-SVM) has shown outstanding performance due to its great model interpretability. However, it still faces challenges in training overhead for large-scale problems. To address this issue, we propose a safe screening rule with bi-level optimization for $\nu$-SVM (SRBO-$\nu$-SVM) which can screen out inactive samples before training and reduce the computational cost without sacrificing the prediction accuracy. Our SRBO-$\nu$-SVM is strictly deduced by integrating the Karush-Kuhn-Tucker (KKT) conditions, the variational inequalities of convex problems and the $\nu$-property. Furthermore, we develop an efficient dual coordinate descent method (DCDM) to further improve computational speed. Finally, a unified framework for SRBO is proposed to ac
    
[^62]: 控制系统中数据描述的规范形式

    Canonical Form of Datatic Description in Control Systems

    [https://arxiv.org/abs/2403.01768](https://arxiv.org/abs/2403.01768)

    本文首次引入了规范数据形式的概念，以实现更有效地设计数据控制器。

    

    反馈控制器的设计正经历从模型驱动控制到数据驱动控制的范式转变。状态空间模型的规范形式是模型驱动控制系统中的重要概念，如Jordan形式、可控形式和可观察形式，其目的是促进系统分析和控制器合成。然而，在数据驱动控制领域，缺乏数据系统表示的标准化。本文首次引入了规范数据形式的概念，以实现更有效地设计数据控制器。

    arXiv:2403.01768v1 Announce Type: cross  Abstract: The design of feedback controllers is undergoing a paradigm shift from modelic (i.e., model-driven) control to datatic (i.e., data-driven) control. Canonical form of state space model is an important concept in modelic control systems, exemplified by Jordan form, controllable form and observable form, whose purpose is to facilitate system analysis and controller synthesis. In the realm of datatic control, there is a notable absence in the standardization of data-based system representation. This paper for the first time introduces the concept of canonical data form for the purpose of achieving more effective design of datatic controllers. In a control system, the data sample in canonical form consists of a transition component and an attribute component. The former encapsulates the plant dynamics at the sampling time independently, which is a tuple containing three elements: a state, an action and their corresponding next state. The la
    
[^63]: 多模态集成如何提升LLM在优化中的性能：以容量车辆路径问题为案例研究

    How Multimodal Integration Boost the Performance of LLM for Optimization: Case Study on Capacitated Vehicle Routing Problems

    [https://arxiv.org/abs/2403.01757](https://arxiv.org/abs/2403.01757)

    提出了一种使用多模态LLM进行优化的框架，能够更全面地理解优化问题，类似于人类认知过程，并且提供了更细致和有效的分析。

    

    最近，大型语言模型（LLMs）已明显地将它们定位为解决复杂优化挑战的工具。尽管被认可，现有基于LLM的优化方法的一个主要限制是，在仅依赖于数字文本提示时，尤其是在高维问题中，难以捕捉决策变量之间的关系。鉴于此，我们首先提出使用多模态LLM来增强优化性能，它能够处理文本和视觉提示，深入了解处理的优化问题。这种集成允许更全面地理解优化问题，类似于人类认知过程。我们开发了一个基于多模态LLM的优化框架，模拟人类解决问题的工作流程，从而提供更细致和有效的分析。该方法的有效性通过扩展进行评估。

    arXiv:2403.01757v1 Announce Type: new  Abstract: Recently, large language models (LLMs) have notably positioned them as capable tools for addressing complex optimization challenges. Despite this recognition, a predominant limitation of existing LLM-based optimization methods is their struggle to capture the relationships among decision variables when relying exclusively on numerical text prompts, especially in high-dimensional problems. Keeping this in mind, we first propose to enhance the optimization performance using multimodal LLM capable of processing both textual and visual prompts for deeper insights of the processed optimization problem. This integration allows for a more comprehensive understanding of optimization problems, akin to human cognitive processes. We have developed a multimodal LLM-based optimization framework that simulates human problem-solving workflows, thereby offering a more nuanced and effective analysis. The efficacy of this method is evaluated through exten
    
[^64]: 将神经信号解码为语音

    Decode Neural signal as Speech

    [https://arxiv.org/abs/2403.01748](https://arxiv.org/abs/2403.01748)

    本文在脑机接口领域探索了MEG信号的脑到文本转换，着重解决了以前主要集中在EEG上、使用“teacher-forcing”以及未完全自回归的问题。

    

    从脑动态解码语言是脑机接口（BCI）领域中一个重要的开放方向，尤其考虑到大型语言模型的快速增长。相对于需要电极植入手术的侵入性信号，非侵入性神经信号（如EEG、MEG）由于其安全性和普适性而越来越受到关注。然而，在三个方面的探索还不足：1）以前的方法主要集中在EEG上，但没有一个先前的研究解决了MEG信号质量更好的问题；2）以前的工作主要在生成解码过程中使用“teacher-forcing”，这是不切实际的；3）以前的工作大多是基于“BART”而不是完全自回归的，而在其他序列任务中表现更好。在本文中，我们探讨了MEG信号的脑到文本转换在语音解码形式中。我们是第一个在交叉注意力中研究的。

    arXiv:2403.01748v1 Announce Type: cross  Abstract: Decoding language from brain dynamics is an important open direction in the realm of brain-computer interface (BCI), especially considering the rapid growth of large language models. Compared to invasive-based signals which require electrode implantation surgery, non-invasive neural signals (e.g. EEG, MEG) have attracted increasing attention considering their safety and generality. However, the exploration is not adequate in three aspects: 1) previous methods mainly focus on EEG but none of the previous works address this problem on MEG with better signal quality; 2) prior works have predominantly used ``teacher-forcing" during generative decoding, which is impractical; 3) prior works are mostly ``BART-based" not fully auto-regressive, which performs better in other sequence tasks. In this paper, we explore the brain-to-text translation of MEG signals in a speech-decoding formation. Here we are the first to investigate a cross-attentio
    
[^65]: 离线目标条件强化学习在具有恢复策略的安全关键任务中的应用

    Offline Goal-Conditioned Reinforcement Learning for Safety-Critical Tasks with Recovery Policy

    [https://arxiv.org/abs/2403.01734](https://arxiv.org/abs/2403.01734)

    提出了一种名为RbSL的新方法，用于解决具有不同目标的安全关键任务，克服了传统方法在复杂环境中处理多样约束时的限制。

    

    离线目标条件强化学习（GCRL）旨在通过离线数据集解决具有稀疏奖励的目标达成任务。本文研究了约束下的离线GCRL问题，并提出了一种名为基于恢复的监督学习（RbSL）的新方法，用于完成具有不同目标的安全关键任务。

    arXiv:2403.01734v1 Announce Type: cross  Abstract: Offline goal-conditioned reinforcement learning (GCRL) aims at solving goal-reaching tasks with sparse rewards from an offline dataset. While prior work has demonstrated various approaches for agents to learn near-optimal policies, these methods encounter limitations when dealing with diverse constraints in complex environments, such as safety constraints. Some of these approaches prioritize goal attainment without considering safety, while others excessively focus on safety at the expense of training efficiency. In this paper, we study the problem of constrained offline GCRL and propose a new method called Recovery-based Supervised Learning (RbSL) to accomplish safety-critical tasks with various goals. To evaluate the method performance, we build a benchmark based on the robot-fetching environment with a randomly positioned obstacle and use expert or random policies to generate an offline dataset. We compare RbSL with three offline GC
    
[^66]: LLMs能否生成建筑设计决策？-一项探索性实证研究

    Can LLMs Generate Architectural Design Decisions? -An Exploratory Empirical study

    [https://arxiv.org/abs/2403.01709](https://arxiv.org/abs/2403.01709)

    本研究旨在探究利用大语言模型（LLMs）生成建筑设计决策的可行性，并尝试应用于架构决策记录（ADR）生成。

    

    建筑知识管理（AKM）涉及对项目或组织中与建筑决策和设计相关信息的有组织处理。AKM的一个重要产物是架构决策记录（ADR），它记录关键设计决策。 ADR是捕捉决策背景、已做出的决策以及与设计决策相关的各个方面的文件，从而促进透明度、协作和理解。 尽管它们有益处，但由于时间限制和参与度不一致等挑战，ADR在软件开发中的采用速度较慢。 大语言模型（LLMs）的最新进展可能有助于弥合这种采用差距，通过促进ADR的生成。 但是，LLM用于ADR生成或理解的效果尚未得到探究。 因此，在这项工作中，我们进行了一项旨在调查使用LLM进行的可行性的探索性研究

    arXiv:2403.01709v1 Announce Type: cross  Abstract: Architectural Knowledge Management (AKM) involves the organized handling of information related to architectural decisions and design within a project or organization. An essential artifact of AKM is the Architecture Decision Records (ADR), which documents key design decisions. ADRs are documents that capture decision context, decision made and various aspects related to a design decision, thereby promoting transparency, collaboration, and understanding. Despite their benefits, ADR adoption in software development has been slow due to challenges like time constraints and inconsistent uptake. Recent advancements in Large Language Models (LLMs) may help bridge this adoption gap by facilitating ADR generation. However, the effectiveness of LLM for ADR generation or understanding is something that has not been explored. To this end, in this work, we perform an exploratory study that aims to investigate the feasibility of using LLM for the 
    
[^67]: Brilla AI: 全国科学与数学竞赛的人工智能参赛者

    Brilla AI: AI Contestant for the National Science and Maths Quiz

    [https://arxiv.org/abs/2403.01699](https://arxiv.org/abs/2403.01699)

    人工智能参赛者Brilla AI在全国科学与数学竞赛中表现优秀，为缺乏合格教师的非洲提供了学习支持。

    

    非洲大陆缺乏足够的合格教师，这阻碍了提供足够的学习支持。人工智能有可能增强有限数量教师的努力，从而带来更好的学习成果。本文描述并评估了NSMQ AI Grand Challenge的首要成果，该挑战提出了一个强大的现实基准，用于评估此类人工智能：“建立一个人工智能，参加加纳的全国科学与数学竞赛（NSMQ），并获胜——在比赛的所有轮次和阶段中表现优于最优秀的参赛者”。NSMQ是加纳的高中学生每年举行的现场科学与数学竞赛，3队2名学生通过回答生物学、化学、物理和数学问题在5轮比赛中竞争，逐渐晋级至最终冠军的队伍。在本研究中，我们建立了Brilla AI，一个参加NSMQ竞赛的人工智能选手。

    arXiv:2403.01699v1 Announce Type: cross  Abstract: The African continent lacks enough qualified teachers which hampers the provision of adequate learning support. An AI could potentially augment the efforts of the limited number of teachers, leading to better learning outcomes. Towards that end, this work describes and evaluates the first key output for the NSMQ AI Grand Challenge, which proposes a robust, real-world benchmark for such an AI: "Build an AI to compete live in Ghana's National Science and Maths Quiz (NSMQ) competition and win - performing better than the best contestants in all rounds and stages of the competition". The NSMQ is an annual live science and mathematics competition for senior secondary school students in Ghana in which 3 teams of 2 students compete by answering questions across biology, chemistry, physics, and math in 5 rounds over 5 progressive stages until a winning team is crowned for that year. In this work, we built Brilla AI, an AI contestant that we de
    
[^68]: 网页中的超文本实体提取

    Hypertext Entity Extraction in Webpage

    [https://arxiv.org/abs/2403.01698](https://arxiv.org/abs/2403.01698)

    提出了一个新的超文本实体提取数据集HEED和一个基于MoE的实体提取框架MoEEF，有效整合多个特征以提高模型性能。

    

    网页实体提取是研究和应用中的一项基本自然语言处理任务。然而，现今大多数网页实体提取模型都是在力求保留文本内容及其结构信息的结构化数据集上训练的。本文提出了一个名为HEED的超文本实体提取数据集，在电子商务领域收集了文本和相应的显式超文本特征，并进行了高质量手动实体注释。此外，我们提出了一个基于MoE的实体提取框架(MoEEF)，通过多专家混合有效地整合多个特征以提高模型性能，并胜过强基线模型。

    arXiv:2403.01698v1 Announce Type: cross  Abstract: Webpage entity extraction is a fundamental natural language processing task in both research and applications. Nowadays, the majority of webpage entity extraction models are trained on structured datasets which strive to retain textual content and its structure information. However, existing datasets all overlook the rich hypertext features (e.g., font color, font size) which show their effectiveness in previous works. To this end, we first collect a \textbf{H}ypertext \textbf{E}ntity \textbf{E}xtraction \textbf{D}ataset (\textit{HEED}) from the e-commerce domains, scraping both the text and the corresponding explicit hypertext features with high-quality manual entity annotations. Furthermore, we present the \textbf{Mo}E-based \textbf{E}ntity \textbf{E}xtraction \textbf{F}ramework (\textit{MoEEF}), which efficiently integrates multiple features to enhance model performance by Mixture of Experts and outperforms strong baselines, includi
    
[^69]: DyCE：用于深度学习压缩和扩展的动态可配置退出

    DyCE: Dynamic Configurable Exiting for Deep Learning Compression and Scaling

    [https://arxiv.org/abs/2403.01695](https://arxiv.org/abs/2403.01695)

    介绍了DyCE，一个动态可配置的提前退出框架，将设计考虑从彼此和基础模型解耦

    

    现代深度学习（DL）模型需要在资源受限环境中有效部署时，使用缩放和压缩技术。大多数现有技术，如修剪和量化，通常是静态的。另一方面，动态压缩方法（如提前退出）通过识别输入样本的困难程度并根据需要分配计算来降低复杂性。动态方法，尽管具有更高的灵活性和与静态方法共存的潜力，但在实现上面临重大挑战，因为动态部分的任何变化都会影响后续过程。此外，大多数当前的动态压缩设计都是单片的，与基础模型紧密集成，从而使其难以适应新颖基础模型。本文介绍了DyCE，一种动态可配置的提前退出框架，从而使设计考虑相互解耦以及与基础模型

    arXiv:2403.01695v1 Announce Type: cross  Abstract: Modern deep learning (DL) models necessitate the employment of scaling and compression techniques for effective deployment in resource-constrained environments. Most existing techniques, such as pruning and quantization are generally static. On the other hand, dynamic compression methods, such as early exits, reduce complexity by recognizing the difficulty of input samples and allocating computation as needed. Dynamic methods, despite their superior flexibility and potential for co-existing with static methods, pose significant challenges in terms of implementation due to any changes in dynamic parts will influence subsequent processes. Moreover, most current dynamic compression designs are monolithic and tightly integrated with base models, thereby complicating the adaptation to novel base models. This paper introduces DyCE, an dynamic configurable early-exit framework that decouples design considerations from each other and from the 
    
[^70]: HanDiffuser: 具有逼真手部外观的文本图像生成

    HanDiffuser: Text-to-Image Generation With Realistic Hand Appearances

    [https://arxiv.org/abs/2403.01693](https://arxiv.org/abs/2403.01693)

    HanDiffuser提出了一种基于扩散的架构，通过在生成过程中注入手部嵌入来实现逼真的手部外观，包括Text-to-Hand-Params扩散模型和Text-Guided Hand-Params-to-Image扩散模型。

    

    arXiv:2403.01693v1 公告类型: 交叉 文摘: 文本到图像生成模型可以生成高质量的人类形象，但在生成手部时会失去逼真度。常见的缺陷包括不规则的手部姿势、形状、错误的手指数量以及物理上不合理的手指方向。为了生成具有逼真手部的图像，我们提出了一种基于扩散的新颖架构，称为HanDiffuser，通过在生成过程中注入手部嵌入来实现逼真度。HanDiffuser包括两个组件:Text-to-Hand-Params扩散模型，用于从输入文本提示生成SMPL-身体和MANO-手部参数，以及Text-Guided Hand-Params-to-Image扩散模型，通过在上一部件生成的提示和手部参数上进行调节来合成图像。我们合并了手部表示的多个方面，包括3D形状和关节级手指位置、方向和关节，以实现强大的学习和可靠的推断性能。

    arXiv:2403.01693v1 Announce Type: cross  Abstract: Text-to-image generative models can generate high-quality humans, but realism is lost when generating hands. Common artifacts include irregular hand poses, shapes, incorrect numbers of fingers, and physically implausible finger orientations. To generate images with realistic hands, we propose a novel diffusion-based architecture called HanDiffuser that achieves realism by injecting hand embeddings in the generative process. HanDiffuser consists of two components: a Text-to-Hand-Params diffusion model to generate SMPL-Body and MANO-Hand parameters from input text prompts, and a Text-Guided Hand-Params-to-Image diffusion model to synthesize images by conditioning on the prompts and hand parameters generated by the previous component. We incorporate multiple aspects of hand representation, including 3D shapes and joint-level finger positions, orientations and articulations, for robust learning and reliable performance during inference. We
    
[^71]: CATS：通过构建辅助时间序列作为外生变量增强多元时间序列预测

    CATS: Enhancing Multivariate Time Series Forecasting by Constructing Auxiliary Time Series as Exogenous Variables

    [https://arxiv.org/abs/2403.01673](https://arxiv.org/abs/2403.01673)

    CATS通过构建辅助时间序列作为外生变量，有效地表示和整合多元时间序列之间的关系，提高了多元时间序列预测的效果，并且相较于之前的模型大幅减少了复杂性和参数。

    

    对于多元时间序列预测（MTSF），最近的深度学习应用显示，单变量模型经常优于多元模型。为了解决多元模型的不足，我们引入了一种方法，即构建辅助时间序列（CATS），它类似于2D时间上下文关注机制，从原始时间序列（OTS）生成辅助时间序列（ATS），以有效表示和整合系列间关系用于预测。ATS的关键原则-连续性，稀疏性和变异性-通过不同模块进行识别和实现。即使是基本的2层MLP作为核心预测器，CATS也取得了最先进的成果，相对于先前的多元模型，它显著减少了复杂性和参数，使其成为高效且可转移的MTSF解决方案。

    arXiv:2403.01673v1 Announce Type: cross  Abstract: For Multivariate Time Series Forecasting (MTSF), recent deep learning applications show that univariate models frequently outperform multivariate ones. To address the difficiency in multivariate models, we introduce a method to Construct Auxiliary Time Series (CATS) that functions like a 2D temporal-contextual attention mechanism, which generates Auxiliary Time Series (ATS) from Original Time Series (OTS) to effectively represent and incorporate inter-series relationships for forecasting. Key principles of ATS - continuity, sparsity, and variability - are identified and implemented through different modules. Even with a basic 2-layer MLP as core predictor, CATS achieves state-of-the-art, significantly reducing complexity and parameters compared to previous multivariate models, marking it an efficient and transferable MTSF solution.
    
[^72]: 政府发展和使用先进自动化系统来决定个人事务的建议

    Recommendations for Government Development and Use of Advanced Automated Systems to Make Decisions about Individuals

    [https://arxiv.org/abs/2403.01649](https://arxiv.org/abs/2403.01649)

    Contestability对于政府决定个人事务是至关重要的，研讨会探讨了通过竞争性来发现系统性错误并对系统进行改进的方法。

    

    Contestability——即有效挑战决定的能力——对于公平实施至关重要。在关于个人的政府决策背景下，竞争性往往作为正当程序的要素受宪法要求；特定程序可能会被州或联邦法律要求的相关特定计划。此外，竞争性也可以成为发现系统性错误的宝贵方式，有助于持续评估和系统改进。2024年1月24-25日，在国家科学基金会和威廉和弗洛拉·休利特基金会的支持下，我们召集了一群多样化的政府官员、领先科技公司的代表、学术界和非营利部门的技术和政策专家、倡导者和利益相关者，就先进自动化决策、竞争性和法律举办了一个研讨会。

    arXiv:2403.01649v1 Announce Type: cross  Abstract: Contestability -- the ability to effectively challenge a decision -- is critical to the implementation of fairness. In the context of governmental decision making about individuals, contestability is often constitutionally required as an element of due process; specific procedures may be required by state or federal law relevant to a particular program. In addition, contestability can be a valuable way to discover systemic errors, contributing to ongoing assessments and system improvement.   On January 24-25, 2024, with support from the National Science Foundation and the William and Flora Hewlett Foundation, we convened a diverse group of government officials, representatives of leading technology companies, technology and policy experts from academia and the non-profit sector, advocates, and stakeholders for a workshop on advanced automated decision making, contestability, and the law. Informed by the workshop's rich and wide-ranging
    
[^73]: 您需要更好地关注付费

    You Need to Pay Better Attention

    [https://arxiv.org/abs/2403.01643](https://arxiv.org/abs/2403.01643)

    提出了三种新的注意力机制，在效率和学习能力方面优于标准的多头注意力，提高了Transformer模型的性能和更广泛的部署能力。

    

    我们引入了三种新的注意力机制，这些机制在效率和学习能力方面胜过标准的多头注意力，从而提高了Transformer模型的性能和更广泛的部署能力。我们的第一个贡献是优化注意力，其性能与标准注意力相似，但参数数量少了四分之三，每个头部少了一个矩阵乘法。接下来，我们引入了高效注意力，其性能与标准注意力相当，但参数数量减少了一半，每个头部减少了两个矩阵乘法，并且比标准注意力快两倍。最后，我们介绍了超级注意力，在视觉和自然语言处理任务中明显超越了标准注意力，同时具有更少的参数和矩阵乘法。除了提供严格的数学比较，我们在MN中评估了所提出的注意力机制

    arXiv:2403.01643v1 Announce Type: cross  Abstract: We introduce three new attention mechanisms that outperform standard multi-head attention in terms of efficiency and learning capabilities, thereby improving the performance and broader deployability of Transformer models. Our first contribution is Optimised Attention, which performs similarly to standard attention, but has 3/4 as many parameters and one matrix multiplication fewer per head. Next, we introduce Efficient Attention, which performs on par with standard attention with only 1/2 as many parameters as many parameters and two matrix multiplications fewer per head and is up to twice as fast as standard attention. Lastly, we introduce Super Attention, which surpasses standard attention by a significant margin in both vision and natural language processing tasks while having fewer parameters and matrix multiplications. In addition to providing rigorous mathematical comparisons, we evaluate the presented attention mechanisms on MN
    
[^74]: 机器学习与深度学习：泛化问题对比研究

    Machine Learning vs Deep Learning: The Generalization Problem

    [https://arxiv.org/abs/2403.01621](https://arxiv.org/abs/2403.01621)

    深度学习模型具备泛化到训练范围之外的固有能力，这对于现实世界中至关重要。

    

    能够推广到超出训练数据范围的能力是一个重要挑战，通常与模型的效用和鲁棒性密切相关。本研究调查了传统机器学习（ML）模型和深度学习（DL）算法在外推方面的比较能力——这是泛化的更具挑战性的方面，因为它要求模型对不在其训练域之外的数据点进行推断。

    arXiv:2403.01621v1 Announce Type: cross  Abstract: The capacity to generalize beyond the range of training data is a pivotal challenge, often synonymous with a model's utility and robustness. This study investigates the comparative abilities of traditional machine learning (ML) models and deep learning (DL) algorithms in terms of extrapolation -- a more challenging aspect of generalization because it requires the model to make inferences about data points that lie outside the domain it has been trained on. We present an empirical analysis where both ML and DL models are trained on an exponentially growing function and then tested on values outside the training domain. The choice of this function allows us to distinctly showcase the divergence in performance when models are required to predict beyond the scope of their training data. Our findings suggest that deep learning models possess inherent capabilities to generalize beyond the training scope, an essential feature for real-world a
    
[^75]: 基于谱聚类的运动分割统一模型选择技术

    A Unified Model Selection Technique for Spectral Clustering Based Motion Segmentation

    [https://arxiv.org/abs/2403.01606](https://arxiv.org/abs/2403.01606)

    本文提出了一种统一模型选择技术，通过结合不同的现有模型选择技术，实现了基于谱聚类的运动分割方法的自动推断运动组数。

    

    运动分割是计算机视觉中的一个基本问题，在机器人、自动驾驶和动作识别等各种应用中至关重要。最近，基于谱聚类的方法在动态环境中的运动分割中表现出色。这些方法对运动关系矩阵执行谱聚类，将场景中的对象或点轨迹聚类到不同的运动组中。然而，现有方法通常需要知道场景中存在的运动数量，这显著降低了它们的实用性。在本文中，我们提出了一种统一的模型选择技术，通过结合不同的现有模型选择技术，自动推断基于谱聚类的运动分割方法的运动组数。我们在KT3DMoSeg数据集上评估了我们的方法，并与基准结果进行了竞争性比较。

    arXiv:2403.01606v1 Announce Type: cross  Abstract: Motion segmentation is a fundamental problem in computer vision and is crucial in various applications such as robotics, autonomous driving and action recognition. Recently, spectral clustering based methods have shown impressive results on motion segmentation in dynamic environments. These methods perform spectral clustering on motion affinity matrices to cluster objects or point trajectories in the scene into different motion groups. However, existing methods often need the number of motions present in the scene to be known, which significantly reduces their practicality. In this paper, we propose a unified model selection technique to automatically infer the number of motion groups for spectral clustering based motion segmentation methods by combining different existing model selection techniques together. We evaluate our method on the KT3DMoSeg dataset and achieve competitve results comparing to the baseline where the number of clu
    
[^76]: 朝向可证明的对数密度策略梯度

    Towards Provable Log Density Policy Gradient

    [https://arxiv.org/abs/2403.01605](https://arxiv.org/abs/2403.01605)

    提出对数密度梯度方法来估计策略梯度，修正残差误差，有望改善强化学习方法的样本复杂度。

    

    策略梯度方法是现代强化学习成功的关键要素。现代策略梯度方法虽然成功，但在梯度估计中引入了一个残差误差。本文认为这个残差项很重要，纠正它有可能改善强化学习方法的样本复杂度。为此，我们提出了对数密度梯度来估计策略梯度，可以纠正这个残差误差项。对数密度梯度方法通过利用状态-动作折扣分布形式来计算策略梯度。我们首先给出了准确找到标签马尔可夫决策过程（MDPs）的对数密度梯度所需的方程式。对于更复杂的环境，我们提出了一种利用后向即时（TD）方法来近似计算对数密度梯度的方法，通过利用后向的同策略样本。由于从马尔可夫链中进行后向采样是高度

    arXiv:2403.01605v1 Announce Type: cross  Abstract: Policy gradient methods are a vital ingredient behind the success of modern reinforcement learning. Modern policy gradient methods, although successful, introduce a residual error in gradient estimation. In this work, we argue that this residual term is significant and correcting for it could potentially improve sample-complexity of reinforcement learning methods. To that end, we propose log density gradient to estimate the policy gradient, which corrects for this residual error term. Log density gradient method computes policy gradient by utilising the state-action discounted distributional formulation. We first present the equations needed to exactly find the log density gradient for a tabular Markov Decision Processes (MDPs). For more complex environments, we propose a temporal difference (TD) method that approximates log density gradient by utilizing backward on-policy samples. Since backward sampling from a Markov chain is highly 
    
[^77]: 可通过打击歧视来减少贫困吗？用于政策制定的基于代理的模型

    Can Poverty Be Reduced by Acting on Discrimination? An Agent-based Model for Policy Making

    [https://arxiv.org/abs/2403.01600](https://arxiv.org/abs/2403.01600)

    通过引入贫困恐惧代理模型（AABM），本研究在计算上提供了对贫困和贫困恐惧之间关系的证据，以验证歧视对贫困缓解的影响。

    

    在过去几十年里，贫困率下降速度减缓，表明传统的贫困缓解方法可能正在失去效力，需要替代性见解来推动联合国可持续发展目标的首要目标。本文介绍了一种新颖的贫困恐惧代理模型（Aporophobia Agent-Based Model，AABM），以提供计算上的证据表明贫困恐惧与贫困之间的相关性。我们展示了一个使用巴塞罗那市的实际人口数据和减贫公共政策（已实施或正在议会讨论中）构建的用例。我们将政策分类为歧视性或非歧视性对贫困人群。

    arXiv:2403.01600v1 Announce Type: cross  Abstract: In the last decades, there has been a deceleration in the rates of poverty reduction, suggesting that traditional redistributive approaches to poverty mitigation could be losing effectiveness, and alternative insights to advance the number one UN Sustainable Development Goal are required. The criminalization of poor people has been denounced by several NGOs, and an increasing number of voices suggest that discrimination against the poor (a phenomenon known as \emph{aporophobia}) could be an impediment to mitigating poverty. In this paper, we present the novel Aporophobia Agent-Based Model (AABM) to provide evidence of the correlation between aporophobia and poverty computationally. We present our use case built with real-world demographic data and poverty-mitigation public policies (either enforced or under parliamentary discussion) for the city of Barcelona. We classify policies as discriminatory or non-discriminatory against the poor
    
[^78]: SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos

    SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos

    [https://arxiv.org/abs/2403.01599](https://arxiv.org/abs/2403.01599)

    通过研究步骤和状态之间的因果关系，本文提出了SCHEMA方法，将每个步骤显式表示为状态变化，并追踪教学视频中的状态变化。

    

    我们研究了在教学视频中的程序规划问题，旨在给出根据部分视觉状态观察生成目标导向的动作步骤序列。这个问题的动机是为了学习一个结构化且可规划的状态和动作空间。我们指出，状态变化对于教学视频中的程序规划很重要，旨在通过研究步骤和状态之间的因果关系建立更为结构化的状态空间。具体地，我们将每个步骤显式地表示为状态变化，并跟踪程序中的状态变化。

    arXiv:2403.01599v1 Announce Type: cross  Abstract: We study the problem of procedure planning in instructional videos, which aims to make a goal-oriented sequence of action steps given partial visual state observations. The motivation of this problem is to learn a structured and plannable state and action space. Recent works succeeded in sequence modeling of steps with only sequence-level annotations accessible during training, which overlooked the roles of states in the procedures. In this work, we point out that State CHangEs MAtter (SCHEMA) for procedure planning in instructional videos. We aim to establish a more structured state space by investigating the causal relations between steps and states in procedures. Specifically, we explicitly represent each step as state changes and track the state changes in procedures. For step representation, we leveraged the commonsense knowledge in large language models (LLMs) to describe the state changes of steps via our designed chain-of-thoug
    
[^79]: APISR: 受动漫制作启发的真实世界动漫超分辨率

    APISR: Anime Production Inspired Real-World Anime Super-Resolution

    [https://arxiv.org/abs/2403.01598](https://arxiv.org/abs/2403.01598)

    本文提出了受动漫制作启发的真实世界动漫超分辨率方法，通过分析动漫制作工作流程，提出不需要视频网络和数据集，引入动漫图像收集流水线和API数据集，解决了动漫特有的挑战，为真实世界动漫超分辨率带来新的思路。

    

    尽管真实世界动漫超分辨率（SR）在SR社区中越来越受到关注，但现有方法仍然采用来自写实领域的技术。本文分析了动漫制作工作流程，并重新思考如何利用其中的特征来促进真实世界动漫SR。首先，我们认为视频网络和数据集对于动漫SR并不是必需的，因为手绘帧的重复使用。相反，我们提出了一个动漫图像收集流水线，通过从视频源中选择最少压缩和最具信息量的帧。基于该流水线，我们引入了动漫制作导向的图像（API）数据集。此外，我们确定了动漫特有的两个挑战：扭曲和淡薄的手绘线条以及不需要的色彩伪影。我们通过在图像退化模型中引入面向预测的压缩模块和伪基准数据准备来解决第一个问题。

    arXiv:2403.01598v1 Announce Type: cross  Abstract: While real-world anime super-resolution (SR) has gained increasing attention in the SR community, existing methods still adopt techniques from the photorealistic domain. In this paper, we analyze the anime production workflow and rethink how to use characteristics of it for the sake of the real-world anime SR. First, we argue that video networks and datasets are not necessary for anime SR due to the repetition use of hand-drawing frames. Instead, we propose an anime image collection pipeline by choosing the least compressed and the most informative frames from the video sources. Based on this pipeline, we introduce the Anime Production-oriented Image (API) dataset. In addition, we identify two anime-specific challenges of distorted and faint hand-drawn lines and unwanted color artifacts. We address the first issue by introducing a prediction-oriented compression module in the image degradation model and a pseudo-ground truth preparatio
    
[^80]: 加强低资源语言的神经机器翻译：语料库开发、人类评估和可解释的 AI 架构

    Enhancing Neural Machine Translation of Low-Resource Languages: Corpus Development, Human Evaluation and Explainable AI Architectures

    [https://arxiv.org/abs/2403.01580](https://arxiv.org/abs/2403.01580)

    本研究通过优化Transformer模型的超参数和子词模型类型，开发了适用于低资源语言对的神经机器翻译系统，并开发了gaHealth，首个针对爱尔兰语健康数据的双语语料库，取得了显著的翻译质量提升。

    

    在当前的机器翻译（MT）领域中，Transformer架构尤其在高资源语言对中脱颖而出。本研究探讨了它在包括英语$\leftrightarrow$爱尔兰语和英语$\leftrightarrow$马拉地语语言对中低资源语言对中的有效性。研究确定了最佳超参数和子词模型类型，显著改善了Transformer模型在低资源语言对中的翻译质量。针对低资源语言的平行数据集的稀缺性可能阻碍MT的发展。为解决这一问题，开发了gaHealth，这是爱尔兰语健康数据的第一个双语语料库。使用这一领域特定数据集开发的模型，在与LoResMT2021共享任务模型相比时，在BLEU评分上表现出非常显著的改进。随后的人类评估使用多维度评估指标进行。

    arXiv:2403.01580v1 Announce Type: cross  Abstract: In the current machine translation (MT) landscape, the Transformer architecture stands out as the gold standard, especially for high-resource language pairs. This research delves into its efficacy for low-resource language pairs including both the English$\leftrightarrow$Irish and English$\leftrightarrow$Marathi language pairs. Notably, the study identifies the optimal hyperparameters and subword model type to significantly improve the translation quality of Transformer models for low-resource language pairs.   The scarcity of parallel datasets for low-resource languages can hinder MT development. To address this, gaHealth was developed, the first bilingual corpus of health data for the Irish language. Focusing on the health domain, models developed using this in-domain dataset exhibited very significant improvements in BLEU score when compared with models from the LoResMT2021 Shared Task. A subsequent human evaluation using the multid
    
[^81]: SARD: 人工智能与人类的协作故事生成

    SARD: A Human-AI Collaborative Story Generation

    [https://arxiv.org/abs/2403.01575](https://arxiv.org/abs/2403.01575)

    SARD提出了一个新的人工智能与人类协作的故事生成工具, 旨在通过大型语言模型生成多章节故事，评估表明：节点式叙事的可视化可能帮助作者构建心智模型，但同时会给作者带来额外的心智负担，并在故事变得更加复杂时成为干扰源，AI生成的故事在词汇多样性上存在不足。

    

    Generative artificial intelligence (GenAI)开创了一个新时代的故事创作者，为点燃创造力和探索未知叙事领域提供了强大的工具。随着技术的不断进步，人类创造力和AI生成内容之间的协同作用有可能重新定义叙事领域的格局。本文中，我们提出了SARD，一个通过大型语言模型生成多章节故事的可拖放式视觉界面。

    arXiv:2403.01575v1 Announce Type: cross  Abstract: Generative artificial intelligence (GenAI) has ushered in a new era for storytellers, providing a powerful tool to ignite creativity and explore uncharted narrative territories. As technology continues to advance, the synergy between human creativity and AI-generated content holds the potential to redefine the landscape of storytelling. In this work, we propose SARD, a drag-and-drop visual interface for generating a multi-chapter story using large language models. Our evaluation of the usability of SARD and its creativity support shows that while node-based visualization of the narrative may help writers build a mental model, it exerts unnecessary mental overhead to the writer and becomes a source of distraction as the story becomes more elaborated. We also found that AI generates stories that are less lexically diverse, irrespective of the complexity of the story. We identified some patterns and limitations of our tool that can guide 
    
[^82]: 放松并放松++：通过SlowTV和CribsTV超越地面真实深度的扩展

    Kick Back & Relax++: Scaling Beyond Ground-Truth Depth with SlowTV & CribsTV

    [https://arxiv.org/abs/2403.01569](https://arxiv.org/abs/2403.01569)

    本文提出了两个新颖的数据集SlowTV和CribsTV，通过这些数据集，成功解决了自监督单目深度估计（SS-MDE）存在的多样化训练数据不足问题，实现了零-shot泛化的任务。

    

    自监督学习是解锁通用计算机视觉系统的关键。通过消除对地面真实注释的依赖，它允许扩展到更大数量的数据。然而，自监督单目深度估计（SS-MDE）受到多样化训练数据缺乏的限制。现有数据集仅关注于密集人口城市中的城市驾驶，导致模型无法推广到此领域之外。为了解决这些限制，本文提出了两个新颖的数据集：SlowTV和CribsTV。这些是从公开的YouTube视频中精心策划的大规模数据集，包含总共2M训练帧。它们提供了一个非常多样化的环境集，从多雪的森林到沿海道路，豪华豪宅，甚至水下珊瑚礁。我们利用这些数据集来解决零-shot泛化的挑战性任务，胜过每个现有的SS-MD

    arXiv:2403.01569v1 Announce Type: cross  Abstract: Self-supervised learning is the key to unlocking generic computer vision systems. By eliminating the reliance on ground-truth annotations, it allows scaling to much larger data quantities. Unfortunately, self-supervised monocular depth estimation (SS-MDE) has been limited by the absence of diverse training data. Existing datasets have focused exclusively on urban driving in densely populated cities, resulting in models that fail to generalize beyond this domain.   To address these limitations, this paper proposes two novel datasets: SlowTV and CribsTV. These are large-scale datasets curated from publicly available YouTube videos, containing a total of 2M training frames. They offer an incredibly diverse set of environments, ranging from snowy forests to coastal roads, luxury mansions and even underwater coral reefs. We leverage these datasets to tackle the challenging task of zero-shot generalization, outperforming every existing SS-MD
    
[^83]: ReMatch: 基于LLMs的检索增强模式匹配

    ReMatch: Retrieval Enhanced Schema Matching with LLMs

    [https://arxiv.org/abs/2403.01567](https://arxiv.org/abs/2403.01567)

    ReMatch方法利用检索增强的大型语言模型 (LLMs) 进行模式匹配，避免了预定义映射、模型训练或对源数据库数据的访问。

    

    模式匹配在数据集成中是一项关键任务，涉及将源数据库模式与目标模式进行对齐，以建立它们元素之间的对应关系。本文提出了一种名为ReMatch的新方法，利用检索增强的大型语言模型（LLMs）来匹配模式。我们的方法避免了预定义映射、模型训练或对源数据库中数据的访问的需求。

    arXiv:2403.01567v1 Announce Type: cross  Abstract: Schema matching is a crucial task in data integration, involving the alignment of a source database schema with a target schema to establish correspondence between their elements. This task is challenging due to textual and semantic heterogeneity, as well as differences in schema sizes. Although machine-learning-based solutions have been explored in numerous studies, they often suffer from low accuracy, require manual mapping of the schemas for model training, or need access to source schema data which might be unavailable due to privacy concerns. In this paper we present a novel method, named ReMatch, for matching schemas using retrieval-enhanced Large Language Models (LLMs). Our method avoids the need for predefined mapping, any model training, or access to data in the source database. In the ReMatch method the tables of the target schema and the attributes of the source schema are first represented as structured passage-based docume
    
[^84]: ComTraQ-MPC：元训练的DQN-MPC集成用于具有有限主动定位更新的轨迹跟踪

    ComTraQ-MPC: Meta-Trained DQN-MPC Integration for Trajectory Tracking with Limited Active Localization Updates

    [https://arxiv.org/abs/2403.01564](https://arxiv.org/abs/2403.01564)

    ComTraQ-MPC是一个结合了DQN和MPC的新框架，旨在优化在有限主动定位更新下的轨迹跟踪。

    

    在局部可观察、随机环境中进行轨迹跟踪的最佳决策往往面临着一个重要挑战，即主动定位更新数量有限，这是指代理从传感器获取真实状态信息的过程。传统方法往往难以平衡资源保存、准确状态估计和精确跟踪之间的关系，导致性能次优。本文介绍了ComTraQ-MPC，这是一个结合了Deep Q-Networks (DQN)和模型预测控制(MPC)的新颖框架，旨在优化有限主动定位更新下的轨迹跟踪。元训练的DQN确保了自适应主动定位调度，同时

    arXiv:2403.01564v1 Announce Type: cross  Abstract: Optimal decision-making for trajectory tracking in partially observable, stochastic environments where the number of active localization updates -- the process by which the agent obtains its true state information from the sensors -- are limited, presents a significant challenge. Traditional methods often struggle to balance resource conservation, accurate state estimation and precise tracking, resulting in suboptimal performance. This problem is particularly pronounced in environments with large action spaces, where the need for frequent, accurate state data is paramount, yet the capacity for active localization updates is restricted by external limitations. This paper introduces ComTraQ-MPC, a novel framework that combines Deep Q-Networks (DQN) and Model Predictive Control (MPC) to optimize trajectory tracking with constrained active localization updates. The meta-trained DQN ensures adaptive active localization scheduling, while the
    
[^85]: 基于内部表征的上下文锐度作为警报：减少幻觉的一个视角

    In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation

    [https://arxiv.org/abs/2403.01548](https://arxiv.org/abs/2403.01548)

    本研究从内部表征角度深入探讨了大型语言模型幻觉的机制，发现了幻觉的一个显著模式，即在上下文标记的隐藏状态中，正确生成具有更清晰的上下文激活。我们提出了一种基于熵的度量方法，将“锐度”纳入解码过程中，制定了一种受限解码方法，实验证明其在知识寻求和幻觉任务上的有效性。

    

    大型语言模型（LLMs）经常会产生幻觉并产生事实错误，然而我们对它们为什么会犯这些错误的理解仍然有限。在本研究中，我们从内部表征的角度深入探讨LLM幻觉的潜在机制，并发现与幻觉相关的一个突出模式：正确的生成在上下文标记的隐藏状态中具有更清晰的上下文激活，而不正确的生成则没有。利用这一见解，我们提出了一种基于熵的度量来量化上下文隐藏状态之间的“锐度”，并将其纳入解码过程中以制定一种受限解码方法。在各种知识寻求和幻觉基准测试上的实验证明了我们方法的一致有效性，例如，在TruthfulQA上实现了高达8.6点的改进。我们相信这项研究可以提高我们对幻觉的理解。

    arXiv:2403.01548v1 Announce Type: cross  Abstract: Large language models (LLMs) frequently hallucinate and produce factual errors, yet our understanding of why they make these errors remains limited. In this study, we delve into the underlying mechanisms of LLM hallucinations from the perspective of inner representations, and discover a salient pattern associated with hallucinations: correct generations tend to have sharper context activations in the hidden states of the in-context tokens, compared to the incorrect ones. Leveraging this insight, we propose an entropy-based metric to quantify the ``sharpness'' among the in-context hidden states and incorporate it into the decoding process to formulate a constrained decoding approach. Experiments on various knowledge-seeking and hallucination benchmarks demonstrate our approach's consistent effectiveness, for example, achieving up to an 8.6 point improvement on TruthfulQA. We believe this study can improve our understanding of hallucinat
    
[^86]: 机器学习利用收缩时间间隔和日常收集的临床数据预测急性心肌梗死后的长期死亡率

    Machine learning predicts long-term mortality after acute myocardial infarction using systolic time intervals and routinely collected clinical data

    [https://arxiv.org/abs/2403.01533](https://arxiv.org/abs/2403.01533)

    该研究利用机器学习模型和新生物标志物探索长期死亡率预测，为心脏病患者提供更准确的医疗决策支持。

    

    精确估计心脏患者当前和未来的合并症是优先考虑连续生理监测和新疗法的重要因素。机器学习模型在预测患有心脏病的患者短期死亡率方面表现良好，但在长期预测方面的效用有限。本研究旨在研究基于树的机器学习模型在长期死亡率预测上的性能，以及两个最近引入的生物标志物对长期死亡率的影响。本研究利用了台湾中国卫生福利部CCHIA的公开可用数据。医疗记录用于收集包括年龄、性别、BMI、经皮冠状动脉介入（PCI）状态和高血压、血脂异常、ST段抬高型心肌梗死（STEMI）和非STEMI等合并症在内的人口统计学和临床数据。

    arXiv:2403.01533v1 Announce Type: cross  Abstract: Precise estimation of cardiac patients' current and future comorbidities is an important factor in prioritizing continuous physiological monitoring and new therapies. ML models have shown satisfactory performance in short-term mortality prediction of patients with heart disease, while their utility in long-term predictions is limited. This study aims to investigate the performance of tree-based ML models on long-term mortality prediction and the effect of two recently introduced biomarkers on long-term mortality. This study utilized publicly available data from CCHIA at the Ministry of Health and Welfare, Taiwan, China. Medical records were used to gather demographic and clinical data, including age, gender, BMI, percutaneous coronary intervention (PCI) status, and comorbidities such as hypertension, dyslipidemia, ST-segment elevation myocardial infarction (STEMI), and non-STEMI. Using medical and demographic records as well as two rec
    
[^87]: 利用生物分子和自然语言的多模态学习：一项综述

    Leveraging Biomolecule and Natural Language through Multi-Modal Learning: A Survey

    [https://arxiv.org/abs/2403.01528](https://arxiv.org/abs/2403.01528)

    生物分子与自然语言相结合的多模态学习为全面表示和分析生物分子开辟了新途径。

    

    集成生物分子建模与自然语言（BL）已经成为人工智能、化学和生物学交叉领域中的一个具有前景的跨学科领域。这种方法利用文本数据源中包含的生物分子的丰富多面描述，增强我们对基本理解，并实现生物分子性质预测等计算任务。通过将自然语言中表达的微妙叙述与通过各种分子建模技术描述的生物分子的结构和功能细节融合，打开了全面表征和分析生物分子的新途径。通过将围绕生物分子的上下文语言数据纳入建模中，BL旨在捕捉包含语言传达的符号特性以及数量化结构特征的整体视图。

    arXiv:2403.01528v1 Announce Type: cross  Abstract: The integration of biomolecular modeling with natural language (BL) has emerged as a promising interdisciplinary area at the intersection of artificial intelligence, chemistry and biology. This approach leverages the rich, multifaceted descriptions of biomolecules contained within textual data sources to enhance our fundamental understanding and enable downstream computational tasks such as biomolecule property prediction. The fusion of the nuanced narratives expressed through natural language with the structural and functional specifics of biomolecules described via various molecular modeling techniques opens new avenues for comprehensively representing and analyzing biomolecules. By incorporating the contextual language data that surrounds biomolecules into their modeling, BL aims to capture a holistic view encompassing both the symbolic qualities conveyed through language as well as quantitative structural characteristics. In this r
    
[^88]: 一种端到端的人体实例抠图方法

    End-to-End Human Instance Matting

    [https://arxiv.org/abs/2403.01510](https://arxiv.org/abs/2403.01510)

    提出了一种端到端的人体实例抠图框架，通过通用感知网络和统一引导网络实现高效的多实例抠图。

    

    人体实例抠图旨在为图像中的每个人体实例估计一个alpha深度图，这是极具挑战性的，目前很少有研究。本文提出了一种新颖的端到端人体实例抠图（E2E-HIM）框架，以更高效的方式同时进行多个实例的抠图。具体来说，一个通用感知网络首先提取图像特征并将实例上下文解码为潜在编码。然后，一个统一引导网络利用空间注意力和语义嵌入生成统一的语义引导，其中编码了位置和语义对应关系。

    arXiv:2403.01510v1 Announce Type: cross  Abstract: Human instance matting aims to estimate an alpha matte for each human instance in an image, which is extremely challenging and has rarely been studied so far. Despite some efforts to use instance segmentation to generate a trimap for each instance and apply trimap-based matting methods, the resulting alpha mattes are often inaccurate due to inaccurate segmentation. In addition, this approach is computationally inefficient due to multiple executions of the matting method. To address these problems, this paper proposes a novel End-to-End Human Instance Matting (E2E-HIM) framework for simultaneous multiple instance matting in a more efficient manner. Specifically, a general perception network first extracts image features and decodes instance contexts into latent codes. Then, a united guidance network exploits spatial attention and semantics embedding to generate united semantics guidance, which encodes the locations and semantic correspo
    
[^89]: 不确定知识图上的软推理

    Soft Reasoning on Uncertain Knowledge Graphs

    [https://arxiv.org/abs/2403.01508](https://arxiv.org/abs/2403.01508)

    本文研究了在不确定知识图上进行软查询，并提出了一种基于机器学习的方法，可以有效回答大规模、不完整和不确定的知识图上的查询。

    

    通过考虑知识中的不确定性，这项研究进一步推动了基于机器学习的逻辑查询回答的研究。该论文研究了不确定知识上的软查询设置，受软约束编程的建立启发。我们提出了一种基于机器学习的方法，既具有前向推理又具有后向校准，用于回答大规模、不完整和不确定的知识图上的软查询。

    arXiv:2403.01508v1 Announce Type: new  Abstract: The study of machine learning-based logical query-answering enables reasoning with large-scale and incomplete knowledge graphs. This paper further advances this line of research by considering the uncertainty in the knowledge. The uncertain nature of knowledge is widely observed in the real world, but \textit{does not} align seamlessly with the first-order logic underpinning existing studies. To bridge this gap, we study the setting of soft queries on uncertain knowledge, which is motivated by the establishment of soft constraint programming. We further propose an ML-based approach with both forward inference and backward calibration to answer soft queries on large-scale, incomplete, and uncertain knowledge graphs. Theoretical discussions present that our methods share the same complexity as state-of-the-art inference algorithms for first-order queries. Empirical results justify the superior performance of our approach against previous M
    
[^90]: 基于重建的无需训练的文本到图像生成模型生成的假图像溯源方法

    Regeneration Based Training-free Attribution of Fake Images Generated by Text-to-Image Generative Models

    [https://arxiv.org/abs/2403.01489](https://arxiv.org/abs/2403.01489)

    提出了一种基于重建的无需训练的方法，用于将由文本到图像生成模型生成的假图像归因于其来源模型，从而让模型所有者对模型的任何滥用负责。

    

    文本到图像生成模型最近引起了人们的广泛关注，因为它们能够基于描述生成图像。虽然这些模型表现出色，但人们对生成的假图像可能被滥用提出了担忧。为了应对这一问题，我们提出了一种简单而有效的无需训练的方法，用于将由文本到图像模型生成的假图像归因于其来源模型。给定一个待归因的测试图像，首先我们反向重建图像的文本提示，然后将重建的提示放入不同的候选模型中以再现候选假图像。通过计算和排名测试图像与候选图像之间的相似性，我们可以确定图像的来源。这种溯源方法可以让模型所有者对其模型的任何滥用负责。需要注意的是，我们的方法不限制候选文本到图像生成模型的数量。

    arXiv:2403.01489v1 Announce Type: cross  Abstract: Text-to-image generative models have recently garnered significant attention due to their ability to generate images based on prompt descriptions. While these models have shown promising performance, concerns have been raised regarding the potential misuse of the generated fake images. In response to this, we have presented a simple yet effective training-free method to attribute fake images generated by text-to-image models to their source models. Given a test image to be attributed, we first inverse the textual prompt of the image, and then put the reconstructed prompt into different candidate models to regenerate candidate fake images. By calculating and ranking the similarity of the test image and the candidate images, we can determine the source of the image. This attribution allows model owners to be held accountable for any misuse of their models. Note that our approach does not limit the number of candidate text-to-image genera
    
[^91]: Align-to-Distill: 可训练的注意力对齐在神经机器翻译中的知识蒸馏

    Align-to-Distill: Trainable Attention Alignment for Knowledge Distillation in Neural Machine Translation

    [https://arxiv.org/abs/2403.01479](https://arxiv.org/abs/2403.01479)

    "本文提出了“Align-to-Distill”（A2D）策略，通过在训练过程中自适应地对齐学生注意力头与其教师对应物，转化了组合映射启发式方法为学习问题，实验结果显示A2D的有效性，对WMT-2022 De->Dsb和WMT-2014 En->De的BLEU分数分别获得高达+3.61和+0.63的提升。"

    

    可扩展的深度模型和大规模数据集的出现提高了神经机器翻译的性能。知识蒸馏（KD）通过将知识从教师模型传输到更紧凑的学生模型来提高效率。然而，针对Transformer架构的KD方法通常依赖于启发式方法，特别是在决定要从哪些教师层中蒸馏知识时。本文介绍了“Align-to-Distill”（A2D）策略，旨在通过在训练过程中自适应地对齐学生注意力头与其教师对应物来解决特征映射问题。A2D中的注意力对齐模块执行学生和教师注意力头之间的密集逐头比较，将组合映射启发式方法转化为学习问题。我们的实验展示了A2D的有效性，对WMT-2022 De->Dsb和WMT-2014 En->De的BLEU分数分别获得高达+3.61和+0.63的提升。

    arXiv:2403.01479v1 Announce Type: cross  Abstract: The advent of scalable deep models and large datasets has improved the performance of Neural Machine Translation. Knowledge Distillation (KD) enhances efficiency by transferring knowledge from a teacher model to a more compact student model. However, KD approaches to Transformer architecture often rely on heuristics, particularly when deciding which teacher layers to distill from. In this paper, we introduce the 'Align-to-Distill' (A2D) strategy, designed to address the feature mapping problem by adaptively aligning student attention heads with their teacher counterparts during training. The Attention Alignment Module in A2D performs a dense head-by-head comparison between student and teacher attention heads across layers, turning the combinatorial mapping heuristics into a learning problem. Our experiments show the efficacy of A2D, demonstrating gains of up to +3.61 and +0.63 BLEU points for WMT-2022 De->Dsb and WMT-2014 En->De, respe
    
[^92]: 具有方向性邻域注意力的异质图表示学习

    Representation Learning on Heterophilic Graph with Directional Neighborhood Attention

    [https://arxiv.org/abs/2403.01475](https://arxiv.org/abs/2403.01475)

    提出了具有方向性邻域注意力的Directional Graph Attention Network（DGAT），能够有效结合特征注意力和全局方向信息，通过新型拉普拉斯矩阵减少节点之间的扩散距离，并引入拓扑引导的邻域修剪和边添加机制来提升异质图的表示学习性能。

    

    图注意力网络（GAT）是最受欢迎的图神经网络（GNN）架构之一，它采用注意力机制来学习边缘权重，在各种应用中展现了良好性能。然而，由于它只包含了来自即时邻域的信息，缺乏捕获远程和全局图信息的能力，导致在一些数据集上表现不佳，特别是在异质图上。为了解决这一局限性，我们在本文中提出了方向图注意力网络（DGAT）。DGAT能够将基于特征的注意力与从图拓扑中提取的全局方向信息结合起来。为此，提出了一种新型拉普拉斯矩阵，可以明显减少节点之间的扩散距离。基于新的拉普拉斯矩阵，提出了拓扑引导的邻域修剪和边添加机制，以消除噪声和限制性质的影响。

    arXiv:2403.01475v1 Announce Type: cross  Abstract: Graph Attention Network (GAT) is one of the most popular Graph Neural Network (GNN) architecture, which employs the attention mechanism to learn edge weights and has demonstrated promising performance in various applications. However, since it only incorporates information from immediate neighborhood, it lacks the ability to capture long-range and global graph information, leading to unsatisfactory performance on some datasets, particularly on heterophilic graphs. To address this limitation, we propose the Directional Graph Attention Network (DGAT) in this paper. DGAT is able to combine the feature-based attention with the global directional information extracted from the graph topology. To this end, a new class of Laplacian matrices is proposed which can provably reduce the diffusion distance between nodes. Based on the new Laplacian, topology-guided neighbour pruning and edge adding mechanisms are proposed to remove the noisy and cap
    
[^93]: 协作适应：通过双向适应实现无源图领域自适应

    Collaborate to Adapt: Source-Free Graph Domain Adaptation via Bi-directional Adaptation

    [https://arxiv.org/abs/2403.01467](https://arxiv.org/abs/2403.01467)

    本论文提出了一种名为GraphCTA的新方法，通过协作的模型适应和图适应来解决无源图领域自适应问题。

    

    无监督图领域自适应（UGDA）已经成为将标记丰富的源图的知识转移到完全未标记的目标图的实际解决方案。然而，大多数方法需要标记丰富的源图提供监督信号，这在真实世界的情况下可能无法访问，原因是规定和隐私问题。在本文中，我们探讨了无源无监督图领域自适应的场景，试图解决领域适应问题而不使用标记的源图。具体来说，我们提出了一种称为GraphCTA的新范式，通过一系列程序协作地执行模型自适应和图自适应：（1）基于目标图中节点邻域预测进行模型自适应，考虑了局部和全局信息；（2）通过邻域对比性地更新图结构和节点属性来执行图自适应。

    arXiv:2403.01467v1 Announce Type: cross  Abstract: Unsupervised Graph Domain Adaptation (UGDA) has emerged as a practical solution to transfer knowledge from a label-rich source graph to a completely unlabelled target graph. However, most methods require a labelled source graph to provide supervision signals, which might not be accessible in the real-world settings due to regulations and privacy concerns. In this paper, we explore the scenario of source-free unsupervised graph domain adaptation, which tries to address the domain adaptation problem without accessing the labelled source graph. Specifically, we present a novel paradigm called GraphCTA, which performs model adaptation and graph adaptation collaboratively through a series of procedures: (1) conduct model adaptation based on node's neighborhood predictions in target graph considering both local and global information; (2) perform graph adaptation by updating graph structure and node attributes via neighborhood contrastive le
    
[^94]: 使用基于PLM的代理模型控制IRT评估中的填空测试题目难度

    Controlling Cloze-test Question Item Difficulty with PLM-based Surrogate Models for IRT Assessment

    [https://arxiv.org/abs/2403.01456](https://arxiv.org/abs/2403.01456)

    提出使用预训练语言模型作为代理模型，通过排名规则控制填空测试题目中空白和干扰项的难度水平，有效评估MC填空测试的难度水平

    

    项目难度在自适应测试中发挥着至关重要的作用。然而，很少有研究集中在生成不同难度水平的问题，特别是针对多项选择（MC）填空测试。我们提出使用预先训练的语言模型（PLMs）作为代理模型，以实现项目反应理论（IRT）评估，避免需要人类测试对象。我们还提出了两种策略来通过排名规则控制空白和干扰项的难度水平，以减少无效干扰项。对基准数据集的实验表明，我们提出的框架和方法可以有效地控制和评估MC填空测试的难度水平。

    arXiv:2403.01456v1 Announce Type: cross  Abstract: Item difficulty plays a crucial role in adaptive testing. However, few works have focused on generating questions of varying difficulty levels, especially for multiple-choice (MC) cloze tests. We propose training pre-trained language models (PLMs) as surrogate models to enable item response theory (IRT) assessment, avoiding the need for human test subjects. We also propose two strategies to control the difficulty levels of both the gaps and the distractors using ranking rules to reduce invalid distractors. Experimentation on a benchmark dataset demonstrates that our proposed framework and methods can effectively control and evaluate the difficulty levels of MC cloze tests.
    
[^95]: GPTSee：通过基于描述的相似特征增强时刻检索和重点检测

    GPTSee: Enhancing Moment Retrieval and Highlight Detection via Description-Based Similarity Features

    [https://arxiv.org/abs/2403.01437](https://arxiv.org/abs/2403.01437)

    该研究提出了一个新颖的两阶段模型，将大型语言模型（LLMs）的输出用作第二阶段变压器编码器-解码器的输入，实现了时刻检索和重点检测的最先进结果。

    

    时刻检索（MR）和重点检测（HD）旨在从相应的自然语言查询中识别视频中的相关时刻和重点。大型语言模型（LLMs）已经展示了在各种计算机视觉任务中的熟练程度。然而，现有的MR和HD方法尚未与LLMs集成。在这封信中，我们提出了一种新颖的两阶段模型，将LLMs的输出作为第二阶段变压器编码器-解码器的输入。首先，利用MiniGPT-4生成视频帧的详细描述并重写查询语句，将其作为新特征输入编码器。然后计算生成描述和重写查询之间的语义相似性。最后，连续高相似性视频帧被转换为范围锚点，作为解码器的先验位置信息。实验证明，我们的方法达到了最先进的结果，并通过使用...

    arXiv:2403.01437v1 Announce Type: cross  Abstract: Moment retrieval (MR) and highlight detection (HD) aim to identify relevant moments and highlights in video from corresponding natural language query. Large language models (LLMs) have demonstrated proficiency in various computer vision tasks. However, existing methods for MR\&HD have not yet been integrated with LLMs. In this letter, we propose a novel two-stage model that takes the output of LLMs as the input to the second-stage transformer encoder-decoder. First, MiniGPT-4 is employed to generate the detailed description of the video frame and rewrite the query statement, fed into the encoder as new features. Then, semantic similarity is computed between the generated description and the rewritten queries. Finally, continuous high-similarity video frames are converted into span anchors, serving as prior position information for the decoder. Experiments demonstrate that our approach achieves a state-of-the-art result, and by using on
    
[^96]: 探索生成人工智能在支持老年人基于音乐的回忆中的设计

    Exploring the Design of Generative AI in Supporting Music-based Reminiscence for Older Adults

    [https://arxiv.org/abs/2403.01413](https://arxiv.org/abs/2403.01413)

    本研究通过用户中心设计方法，包括与两名社工和两个设计研讨会（涉及十名老年人）的详细访谈，为深入了解老年人利用生成AI支持基于音乐的回忆的态度作出贡献

    

    基于音乐的回忆有潜力对老年人的心理健康产生积极影响。然而，老化过程和生理变化，如记忆衰退和有限的口头沟通，可能会妨碍老年人回忆他们的记忆和生活经历。鉴于生成人工智能（AI）系统的先进功能，例如生成对话和图像，以及它们促进回忆过程的潜力，本研究旨在探索设计生成AI以支持老年人基于音乐的回忆。

    arXiv:2403.01413v1 Announce Type: cross  Abstract: Music-based reminiscence has the potential to positively impact the psychological well-being of older adults. However, the aging process and physiological changes, such as memory decline and limited verbal communication, may impede the ability of older adults to recall their memories and life experiences. Given the advanced capabilities of generative artificial intelligence (AI) systems, such as generated conversations and images, and their potential to facilitate the reminiscing process, this study aims to explore the design of generative AI to support music-based reminiscence in older adults. This study follows a user-centered design approach incorporating various stages, including detailed interviews with two social workers and two design workshops (involving ten older adults). Our work contributes to an in-depth understanding of older adults' attitudes toward utilizing generative AI for supporting music-based reminiscence and ident
    
[^97]: 区域-Transformer: 基于自注意力区域的无关类别点云分割

    Region-Transformer: Self-Attention Region Based Class-Agnostic Point Cloud Segmentation

    [https://arxiv.org/abs/2403.01407](https://arxiv.org/abs/2403.01407)

    该论文提出了一种名为区域-Transformer的新型区域基Transformer模型，使用区域增长方法和自注意力机制进行无关类别的点云分割训练，首次将自注意力机制应用于区域增长方法。

    

    点云分割可以以特定结构和对象视角以特定类别或无关类别的方式进行。我们提出了一种名为区域-Transformer的新型基于区域的Transformer模型，用于执行无关类别的点云分割。该模型利用了区域增长方法和自注意力机制，通过添加或删除点来迭代地扩展或收缩区域。模型仅在虚拟点云上进行训练，仅使用实例标签，避免使用语义标签。基于注意力的网络在许多以往的点云分割方法中取得了成功。然而，使用具有关注网络的区域增长方法尚未被用于探索其性能提升。据我们所知，我们是第一个在区域增长方法中使用自注意力机制的研究。通过将自注意引入到可以利用局部上下文信息的区域增长中

    arXiv:2403.01407v1 Announce Type: cross  Abstract: Point cloud segmentation, which helps us understand the environment of specific structures and objects, can be performed in class-specific and class-agnostic ways. We propose a novel region-based transformer model called Region-Transformer for performing class-agnostic point cloud segmentation. The model utilizes a region-growth approach and self-attention mechanism to iteratively expand or contract a region by adding or removing points. It is trained on simulated point clouds with instance labels only, avoiding semantic labels. Attention-based networks have succeeded in many previous methods of performing point cloud segmentation. However, a region-growth approach with attention-based networks has yet to be used to explore its performance gain. To our knowledge, we are the first to use a self-attention mechanism in a region-growth approach. With the introduction of self-attention to region-growth that can utilize local contextual info
    
[^98]: 解耦权衡和选择：用于整合多个图预训练任务的方法

    Decoupling Weighing and Selecting for Integrating Multiple Graph Pre-training Tasks

    [https://arxiv.org/abs/2403.01400](https://arxiv.org/abs/2403.01400)

    本文提出了一种用于整合多个图预训练任务的新颖的实例级框架Weigh And Select（WAS），其中通过解耦的连体网络组合了权衡和选择这两个协作过程

    

    近年来，图预训练在图表示学习中取得了巨大成功。伴随着数百种图预训练任务的提出，整合从多个预训练任务中获得的知识已成为一个热门研究课题。本文确定了此主题的两个重要协作过程：（1）选择：如何基于它们的兼容性从给定任务池中选择最佳任务组合，和（2）权衡：如何基于它们的重要性权衡所选任务。虽然目前有很多工作集中在权衡上，但相比之下，很少有工作致力于选择。本文提出了一种用于整合多个图预训练任务的新颖的实例级框架Weigh And Select（WAS），其中权衡和选择这两个协作过程通过解耦的连体网络进行组合。具体而言，它首先自适应地学习任务的最佳组合

    arXiv:2403.01400v1 Announce Type: cross  Abstract: Recent years have witnessed the great success of graph pre-training for graph representation learning. With hundreds of graph pre-training tasks proposed, integrating knowledge acquired from multiple pre-training tasks has become a popular research topic. In this paper, we identify two important collaborative processes for this topic: (1) select: how to select an optimal task combination from a given task pool based on their compatibility, and (2) weigh: how to weigh the selected tasks based on their importance. While there currently has been a lot of work focused on weighing, comparatively little effort has been devoted to selecting. This paper proposes a novel instance-level framework for integrating multiple graph pre-training tasks, Weigh And Select (WAS), where the two collaborative processes, weighing and selecting, are combined by decoupled siamese networks. Specifically, it first adaptively learns an optimal combination of task
    
[^99]: 关于量化大型语言模型的可压缩性

    On the Compressibility of Quantized Large Language Models

    [https://arxiv.org/abs/2403.01384](https://arxiv.org/abs/2403.01384)

    研究在内存受限设备上应用数据压缩技术以加速量化LLM推理过程的一项初步工作。

    

    部署大型语言模型（LLMs）到边缘或移动设备上具有显著优势，如增强数据隐私和实时处理能力。本文研究了将数据压缩技术应用于减少数据移动，从而加速内存受限设备上量化LLM的推理过程的初步步骤。

    arXiv:2403.01384v1 Announce Type: cross  Abstract: Deploying Large Language Models (LLMs) on edge or mobile devices offers significant benefits, such as enhanced data privacy and real-time processing capabilities. However, it also faces critical challenges due to the substantial memory requirement of LLMs. Quantization is an effective way of reducing the model size while maintaining good performance. However, even after quantization, LLMs may still be too big to fit entirely into the limited memory of edge or mobile devices and have to be partially loaded from the storage to complete the inference. In this case, the I/O latency of model loading becomes the bottleneck of the LLM inference latency. In this work, we take a preliminary step of studying applying data compression techniques to reduce data movement and thus speed up the inference of quantized LLM on memory-constrained devices. In particular, we discussed the compressibility of quantized LLMs, the trade-off between the compres
    
[^100]: Wav2Vec2嵌入在设备端单通道语音增强中的探究

    A Closer Look at Wav2Vec2 Embeddings for On-Device Single-Channel Speech Enhancement

    [https://arxiv.org/abs/2403.01369](https://arxiv.org/abs/2403.01369)

    本文研究了Wav2Vec2嵌入在单通道语音增强中的应用，发现SSL表示对增强任务几乎没有任何价值。

    

    自监督学习模型被发现在某些语音任务中非常有效，比如自动语音识别、说话人识别、关键词识别等。本文探讨了SSL表示在具有挑战性条件下的单通道语音增强中的用途，并发现它们对增强任务几乎没有任何价值。

    arXiv:2403.01369v1 Announce Type: cross  Abstract: Self-supervised learned models have been found to be very effective for certain speech tasks such as automatic speech recognition, speaker identification, keyword spotting and others. While the features are undeniably useful in speech recognition and associated tasks, their utility in speech enhancement systems is yet to be firmly established, and perhaps not properly understood. In this paper, we investigate the uses of SSL representations for single-channel speech enhancement in challenging conditions and find that they add very little value for the enhancement task. Our constraints are designed around on-device real-time speech enhancement -- model is causal, the compute footprint is small. Additionally, we focus on low SNR conditions where such models struggle to provide good enhancement. In order to systematically examine how SSL representations impact performance of such enhancement models, we propose a variety of techniques to u
    
[^101]: SANGRIA：基于梯度提升的堆叠自编码器神经网络用于室内定位

    SANGRIA: Stacked Autoencoder Neural Networks with Gradient Boosting for Indoor Localization

    [https://arxiv.org/abs/2403.01348](https://arxiv.org/abs/2403.01348)

    SANGRIA是一个基于堆叠自编码器神经网络与梯度提升树的室内定位框架，相比其他先进框架，能够实现更低的平均定位误差。

    

    室内定位是许多嵌入式应用中的关键任务，例如资产跟踪、应急响应和实时导航。在本文中，我们提出了一种名为SANGRIA的基于指纹的室内定位框架，该框架使用了堆叠自编码器神经网络与梯度提升树。我们的方法旨在克服设备异构性挑战，该挑战可能导致用于定位的嵌入式设备之间的无线信号测量出现不确定性。我们将SANGRIA与几种最先进的框架进行了比较，并在不同室内场所和异构设备上展示了42.96%较低的平均定位误差。

    arXiv:2403.01348v1 Announce Type: cross  Abstract: Indoor localization is a critical task in many embedded applications, such as asset tracking, emergency response, and realtime navigation. In this article, we propose a novel fingerprintingbased framework for indoor localization called SANGRIA that uses stacked autoencoder neural networks with gradient boosted trees. Our approach is designed to overcome the device heterogeneity challenge that can create uncertainty in wireless signal measurements across embedded devices used for localization. We compare SANGRIA to several state-of-the-art frameworks and demonstrate 42.96% lower average localization error across diverse indoor locales and heterogeneous devices.
    
[^102]: 将思维和LLMs串联起来学习DNA结构生物物理学

    Chaining thoughts and LLMs to learn DNA structural biophysics

    [https://arxiv.org/abs/2403.01332](https://arxiv.org/abs/2403.01332)

    通用语言模型chatGPT 3.5-turbo的微调，在学习DNA结构生物物理学方面显示出新的潜力和优势。

    

    未来发展AI科学家的一项重要发展是，一个能够整合各种实验数据并生成可验证假设的工具具有巨大潜力。到目前为止，定制的机器学习模型已被创建用于专门从事单一科学任务，但缺乏通用模型的灵活性。在这里，我们展示了一个通用的大型语言模型，chatGPT 3.5-turbo，可以被微调来学习DNA的结构生物物理学。我们发现，将模型微调为返回思维链式响应以及串联微调用于子任务的模型，具有增强的能力来分析和设计DNA序列及其结构。

    arXiv:2403.01332v1 Announce Type: cross  Abstract: The future development of an AI scientist, a tool that is capable of integrating a variety of experimental data and generating testable hypotheses, holds immense potential. So far, bespoke machine learning models have been created to specialize in singular scientific tasks, but otherwise lack the flexibility of a general purpose model. Here, we show that a general purpose large language model, chatGPT 3.5-turbo, can be fine-tuned to learn the structural biophysics of DNA. We find that both fine-tuning models to return chain-of-thought responses and chaining together models fine-tuned for subtasks have an enhanced ability to analyze and design DNA sequences and their structures.
    
[^103]: 为快速采样扩散和流动模型提供定制的非平稳求解器

    Bespoke Non-Stationary Solvers for Fast Sampling of Diffusion and Flow Models

    [https://arxiv.org/abs/2403.01329](https://arxiv.org/abs/2403.01329)

    该论文引入了定制的非平稳（BNS）求解器，提高了扩散和流动模型的采样效率，具有小参数空间、快速优化、样本多样性，并且在低中 NFE 范围内接近标准精炼方法。

    

    本文介绍了定制的非平稳（BNS）求解器，这是一种解算精髓方法，旨在提高扩散和流动模型的样本效率。BNS 求解器基于一系列可证明包含现有数值 ODE 求解器的非平稳求解器家族，随之显著改进样本逼近度（PSNR）超过这些基线。与模型精炼相比，BNS 求解器具有微小参数空间（<200 参数）、快速优化（快两个数量级）、保持样本多样性，并且与以前的求解器精炼方法相反，几乎能在低中 NFE 范围内接近标准精炼方法，如 Progressive Distillation。例如，BNS 求解器在 class-conditional ImageNet-64 中使用 16 NFE 实现 45 PSNR / 1.76 FID。我们尝试了 BNS 求解器来进行有条件图像生成、文本到图像生成和文本到音频生成。

    arXiv:2403.01329v1 Announce Type: cross  Abstract: This paper introduces Bespoke Non-Stationary (BNS) Solvers, a solver distillation approach to improve sample efficiency of Diffusion and Flow models. BNS solvers are based on a family of non-stationary solvers that provably subsumes existing numerical ODE solvers and consequently demonstrate considerable improvement in sample approximation (PSNR) over these baselines. Compared to model distillation, BNS solvers benefit from a tiny parameter space ($<$200 parameters), fast optimization (two orders of magnitude faster), maintain diversity of samples, and in contrast to previous solver distillation approaches nearly close the gap from standard distillation methods such as Progressive Distillation in the low-medium NFE regime. For example, BNS solver achieves 45 PSNR / 1.76 FID using 16 NFE in class-conditional ImageNet-64. We experimented with BNS solvers for conditional image generation, text-to-image generation, and text-2-audio generat
    
[^104]: VNLP：土耳其自然语言处理工具包

    VNLP: Turkish NLP Package

    [https://arxiv.org/abs/2403.01309](https://arxiv.org/abs/2403.01309)

    VNLP是首个专门针对土耳其语开发的自然语言处理工具包，包含多种NLP工具，其中的标记分类模型基于“上下文模型”，支持多种任务如情感分析、命名实体识别等。

    

    在本文中，我们介绍了VNLP：第一个专门针对土耳其语的完整、开源、文档完备、轻量级、可投入生产使用的最先进的自然语言处理（NLP）工具包。它包含各种工具，从最简单的任务，如句子分割和文本规范化，到更高级的任务，如文本和标记分类模型。其标记分类模型基于“上下文模型”，这是一种既是编码器又是自回归模型的新颖架构。VNLP模型解决的NLP任务包括但不限于情感分析、命名实体识别、形态分析和消歧以及词性标注。此外，它配备了预训练的词嵌入和相应的SentencePiece Unigram标记器。VNLP具有开源的GitHub存储库、ReadtheDocs文档、方便安装的PyPi包、Python和逗号

    arXiv:2403.01309v1 Announce Type: cross  Abstract: In this work, we present VNLP: the first dedicated, complete, open-source, well-documented, lightweight, production-ready, state-of-the-art Natural Language Processing (NLP) package for the Turkish language. It contains a wide variety of tools, ranging from the simplest tasks, such as sentence splitting and text normalization, to the more advanced ones, such as text and token classification models. Its token classification models are based on "Context Model", a novel architecture that is both an encoder and an auto-regressive model. NLP tasks solved by VNLP models include but are not limited to Sentiment Analysis, Named Entity Recognition, Morphological Analysis \& Disambiguation and Part-of-Speech Tagging. Moreover, it comes with pre-trained word embeddings and corresponding SentencePiece Unigram tokenizers. VNLP has an open-source GitHub repository, ReadtheDocs documentation, PyPi package for convenient installation, Python and comma
    
[^105]: 建立协作安全自主系统的用例研究-用于引导视障者的机器狗

    Summary Paper: Use Case on Building Collaborative Safe Autonomous Systems-A Robotdog for Guiding Visually Impaired People

    [https://arxiv.org/abs/2403.01286](https://arxiv.org/abs/2403.01286)

    该论文研究了用于引导视障者的机器狗在复杂环境中做出安全穿越十字路口的决策的系统架构和协作决策层设计。

    

    这是一篇关于专门引导视障者在复杂环境中如智能十字路口的机器狗用例的摘要论文。在这种情况下，机器狗必须自主决定是否安全穿过十字路口，以便进一步指导人类。我们利用数据共享和协作，使机器狗与同一环境中其他自主系统之间发生互动。我们提出了一个自主系统的系统架构，通过一个协作决策层的分离来实现集体决策过程，从而分享环境数据、与机器狗决策相关的其他系统和环境的可信度证据。

    arXiv:2403.01286v1 Announce Type: cross  Abstract: This is a summary paper of a use case of a Robotdog dedicated to guide visually impaired people in complex environment like a smart intersection. In such scenarios, the Robotdog has to autonomously decide whether it is safe to cross the intersection or not in order to further guide the human. We leverage data sharing and collaboration between the Robotdog and other autonomous systems operating in the same environment. We propose a system architecture for autonomous systems through a separation of a collaborative decision layer, to enable collective decision making processes, where data about the environment, relevant to the Robotdog decision, together with evidences for trustworthiness about other systems and the environment are shared.
    
[^106]: 在协作学习环境中快速低参数视频活动定位

    Fast Low-parameter Video Activity Localization in Collaborative Learning Environments

    [https://arxiv.org/abs/2403.01281](https://arxiv.org/abs/2403.01281)

    该论文提出了一种快速低参数视频活动定位系统，可在有限数据集上进行训练，并能准确检测并关联学生在现实教室视频中执行的活动。

    

    视频活动检测的研究主要集中在识别短视频片段中明确定义的人类活动。视频活动识别的大部分研究都集中在开发需要在大型视频数据集上训练的大参数系统上。本文开发了一个低参数、模块化系统，具有快速推理能力，可以完全在有限数据集上进行训练，而无需从大参数系统中进行迁移学习。该系统可以准确检测和将特定活动与在现实教室视频中执行活动的学生关联起来。此外，本文开发了一个交互式基于Web的应用程序，用于在长时间的现实教室视频上可视化人类活动地图。

    arXiv:2403.01281v1 Announce Type: cross  Abstract: Research on video activity detection has primarily focused on identifying well-defined human activities in short video segments. The majority of the research on video activity recognition is focused on the development of large parameter systems that require training on large video datasets. This paper develops a low-parameter, modular system with rapid inferencing capabilities that can be trained entirely on limited datasets without requiring transfer learning from large-parameter systems. The system can accurately detect and associate specific activities with the students who perform the activities in real-life classroom videos. Additionally, the paper develops an interactive web-based application to visualize human activity maps over long real-life classroom videos.
    
[^107]: 最优集成任务和路径规划及其在多机器人取送任务中的应用

    Optimal Integrated Task and Path Planning and Its Application to Multi-Robot Pickup and Delivery

    [https://arxiv.org/abs/2403.01277](https://arxiv.org/abs/2403.01277)

    提出一种结合了最优任务规划器和最优路径规划器的通用多机器人规划机制，通过相互作用生成最优无碰撞轨迹，在仓库场景中的物体取放问题中展示了其有效性。

    

    我们提出了一种通用的多机器人规划机制，结合了最优任务规划器和最优路径规划器，为复杂的多机器人规划问题提供可扩展的解决方案。集成规划器通过任务规划器和路径规划器的相互作用，为机器人产生最优的无碰撞轨迹。我们在一个仓库场景中的物体取放规划问题上展示了我们的通用算法，其中一组机器人负责将物体从一个位置移动到工作区的另一个位置。我们通过将任务规划问题简化为SMT求解问题，并利用高级SMT求解器 Z3 来解决它。为了生成机器人的无碰撞移动，我们使用具有多个特定领域约束的最先进算法 Conflict Based Search with Precedence Constraints。我们在各种情况下广泛评估了我们的集成任务和路径规划器。

    arXiv:2403.01277v1 Announce Type: cross  Abstract: We propose a generic multi-robot planning mechanism that combines an optimal task planner and an optimal path planner to provide a scalable solution for complex multi-robot planning problems. The Integrated planner, through the interaction of the task planner and the path planner, produces optimal collision-free trajectories for the robots. We illustrate our general algorithm on an object pick-and-drop planning problem in a warehouse scenario where a group of robots is entrusted with moving objects from one location to another in the workspace. We solve the task planning problem by reducing it into an SMT-solving problem and employing the highly advanced SMT solver Z3 to solve it. To generate collision-free movement of the robots, we extend the state-of-the-art algorithm Conflict Based Search with Precedence Constraints with several domain-specific constraints. We evaluate our integrated task and path planner extensively on various ins
    
[^108]: NoMAD-Attention: 通过无MAD操作实现CPU上高效LLM推断

    NoMAD-Attention: Efficient LLM Inference on CPUs Through Multiply-add-free Attention

    [https://arxiv.org/abs/2403.01273](https://arxiv.org/abs/2403.01273)

    NoMAD-Attention提出了一种高效的注意力算法，通过在CPU上使用寄存器内查找取代MAD操作，以实现LLM推断的快速计算。

    

    在中央处理单元（CPU）上进行大型语言模型推断具有挑战性，因为注意力计算中存在大量昂贵的MAD矩阵操作。本文认为现代CPU中的单指令多数据（SIMD）寄存器是一种珍贵的宝石，它允许在批处理中进行超低延迟查找。我们利用CPU的这一独特能力提出了NoMAD-Attention，这是一种高效的注意力算法，用于将MAD操作替换为寄存器内查找。通过硬件感知的算法设计，NoMAD-Attention实现了通过重复快速访问SIMD寄存器来计算注意力分数，尽管它们的大小非常有限。此外，NoMAD-Attention适用于预训练的基于注意力的LLM，无需对模型进行微调。实证评估表明，NoMAD-Attention很好地保持了原始LLM的质量，并加速了4位量化的LLaMA-7B-bas。

    arXiv:2403.01273v1 Announce Type: cross  Abstract: Large language model inference on Central Processing Units (CPU) is challenging due to the vast quantities of expensive Multiply-Add (MAD) matrix operations in the attention computations. In this paper, we argue that there is a rare gem in modern CPUs, Single-Instruction-Multiple-Data (SIMD) registers, which allow for ultra-low-latency lookups in batch. We leverage this unique capability of CPUs to propose NoMAD-Attention, an efficient attention algorithm that replaces MAD operations with in-register lookups. Through hardware-aware algorithmic designs, NoMAD-Attention achieves the computation of attention scores using repeated fast accesses to SIMD registers despite their highly limited sizes. Moreover, NoMAD-Attention works with pre-trained attention-based LLMs without model finetuning. Empirical evaluations demonstrate that NoMAD-Attention maintains the quality of the original LLMs well, and speeds up the 4-bit quantized LLaMA-7B-bas
    
[^109]: 使用先进的深度学习方法的自动语音识别：一项调查

    Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey

    [https://arxiv.org/abs/2403.01255](https://arxiv.org/abs/2403.01255)

    先进的深度学习技术如深度迁移学习、联邦学习和强化学习解决了自动语音识别中训练数据领域假设不符合实际情况的问题，提高了性能并降低计算成本。

    

    arXiv:2403.01255v1 公告类型：跨领域 摘要：深度学习（DL）的最新进展对自动语音识别（ASR）构成了重大挑战。ASR依赖于包括机密数据在内的大量训练数据，并需要大量的计算和存储资源。启用自适应系统可以提高动态环境下的ASR性能。DL技术假设训练和测试数据来自同一领域，但并非总是如此。深度迁移学习（DTL）、联邦学习（FL）和强化学习（RL）等先进的DL技术解决了这些问题。DTL可以利用小而相关的数据集构建高性能模型，FL使得在不拥有数据集的情况下训练模型，RL优化动态环境下的决策，降低计算成本。本调查全面审阅了基于DTL、FL和RL的ASR框架，旨在提供对最新发展的见解，并协助研究人员。

    arXiv:2403.01255v1 Announce Type: cross  Abstract: Recent advancements in deep learning (DL) have posed a significant challenge for automatic speech recognition (ASR). ASR relies on extensive training datasets, including confidential ones, and demands substantial computational and storage resources. Enabling adaptive systems improves ASR performance in dynamic environments. DL techniques assume training and testing data originate from the same domain, which is not always true. Advanced DL techniques like deep transfer learning (DTL), federated learning (FL), and reinforcement learning (RL) address these issues. DTL allows high-performance models using small yet related datasets, FL enables training on confidential data without dataset possession, and RL optimizes decision-making in dynamic environments, reducing computation costs. This survey offers a comprehensive review of DTL, FL, and RL-based ASR frameworks, aiming to provide insights into the latest developments and aid researcher
    
[^110]: SceneCraft：一个用于将文本描述合成为Blender代码的LLM代理

    SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code

    [https://arxiv.org/abs/2403.01248](https://arxiv.org/abs/2403.01248)

    SceneCraft是一个LLM代理，可将文本描述转换为Blender代码，实现渲染高达一百个三维资产的复杂场景，通过先建模空间关系再编写Python脚本，并借助视觉-语言基础模型进行场景优化和库学习来解决挑战。

    

    本文介绍了SceneCraft，一个大型语言模型（LLM）代理，将文本描述转换为Blender可执行的Python脚本，用于渲染高达一百个三维资产的复杂场景。该过程需要复杂的空间规划和布局。我们通过高级抽象、战略规划和库学习的组合来解决这些挑战。SceneCraft首先将场景图建模为蓝图，详细描述场景中各资产之间的空间关系。然后，SceneCraft根据这个图编写Python脚本，将关系转化为资产布局的数值约束。接下来，SceneCraft利用像GPT-V这样的视觉-语言基础模型的感知优势来分析渲染图像并迭代地优化场景。在这个过程之上，SceneCraft具备一个库学习机制，将常见的脚本函数编译为可重复使用的库，促进持续的自我

    arXiv:2403.01248v1 Announce Type: cross  Abstract: This paper introduces SceneCraft, a Large Language Model (LLM) Agent converting text descriptions into Blender-executable Python scripts which render complex scenes with up to a hundred 3D assets. This process requires complex spatial planning and arrangement. We tackle these challenges through a combination of advanced abstraction, strategic planning, and library learning. SceneCraft first models a scene graph as a blueprint, detailing the spatial relationships among assets in the scene. SceneCraft then writes Python scripts based on this graph, translating relationships into numerical constraints for asset layout. Next, SceneCraft leverages the perceptual strengths of vision-language foundation models like GPT-V to analyze rendered images and iteratively refine the scene. On top of this process, SceneCraft features a library learning mechanism that compiles common script functions into a reusable library, facilitating continuous self
    
[^111]: 使用自我生成的复述来减轻大型语言模型中的灾难性遗忘

    Mitigating Catastrophic Forgetting in Large Language Models with Self-Synthesized Rehearsal

    [https://arxiv.org/abs/2403.01244](https://arxiv.org/abs/2403.01244)

    提出了一种称为Self-Synthesized Rehearsal（SSR）的框架，利用大型语言模型生成合成实例用于持续学习中的复述，以解决大型语言模型遭受灾难性遗忘的问题。

    

    大型语言模型（LLMs）在持续学习过程中遭受灾难性遗忘。传统的基于复述的方法依赖于先前的训练数据来保留模型的能力，然而这在现实应用中可能无法实现。为了解决这一挑战，我们提出了一个名为自我生成复述（SSR）的框架，利用LLM生成合成实例进行复述。

    arXiv:2403.01244v1 Announce Type: cross  Abstract: Large language models (LLMs) suffer from catastrophic forgetting during continual learning. Conventional rehearsal-based methods rely on previous training data to retain the model's ability, which may not be feasible in real-world applications. When conducting continual learning based on a publicly-released LLM checkpoint, the availability of the original training data may be non-existent. To address this challenge, we propose a framework called Self-Synthesized Rehearsal (SSR) that uses the LLM to generate synthetic instances for rehearsal. Concretely, we first employ the base LLM for in-context learning to generate synthetic instances. Subsequently, we utilize the latest LLM to refine the instance outputs based on the synthetic inputs, preserving its acquired ability. Finally, we select diverse high-quality synthetic instances for rehearsal in future stages. Experimental results demonstrate that SSR achieves superior or comparable pe
    
[^112]: 用机器学习增强自动化：基于意图的用户指令分类

    Augmenting Automation: Intent-Based User Instruction Classification with Machine Learning

    [https://arxiv.org/abs/2403.01242](https://arxiv.org/abs/2403.01242)

    提出了一种通过引入基于意图的用户指令分类和机器学习技术的新颖方法，从而增强自动化系统的灵活性和适应性。

    

    电动自动化系统在控制电路和设备时提供了方便和效率。传统上，这些系统依赖预定义的命令进行控制，限制了灵活性和适应性。本文提出了一种新颖的方法，通过引入基于意图的用户指令分类和机器学习技术来增强自动化。我们的系统将用户指令表示为意图，允许在不依赖预定义命令的情况下动态控制电路。通过训练在标记的用户指令数据集上的机器学习模型，我们的系统可以从用户输入中对意图进行分类，从而实现更直观和可适应的控制方案。我们展示了基于意图的电动自动化系统的设计和实现，详细说明了用于意图分类的机器学习模型的开发。实验结果证明了我们方法的有效性。

    arXiv:2403.01242v1 Announce Type: cross  Abstract: Electric automation systems offer convenience and efficiency in controlling electrical circuits and devices. Traditionally, these systems rely on predefined commands for control, limiting flexibility and adaptability. In this paper, we propose a novel approach to augment automation by introducing intent-based user instruction classification using machine learning techniques. Our system represents user instructions as intents, allowing for dynamic control of electrical circuits without relying on predefined commands. Through a machine learning model trained on a labeled dataset of user instructions, our system classifies intents from user input, enabling a more intuitive and adaptable control scheme. We present the design and implementation of our intent-based electric automation system, detailing the development of the machine learning model for intent classification. Experimental results demonstrate the effectiveness of our approach i
    
[^113]: IntactKV: 通过保持关键标记完整改进大型语言模型量化

    IntactKV: Improving Large Language Model Quantization by Keeping Pivot Tokens Intact

    [https://arxiv.org/abs/2403.01241](https://arxiv.org/abs/2403.01241)

    本研究提出了IntactKV方法，通过保持关键标记的完整性，改善了大型语言模型的量化过程，进一步降低了量化误差的上限，并取得了显著的性能提升。

    

    大型语言模型在自然语言处理方面表现出色，但需要大量计算。为了减少这一难题，人们已经探索了各种量化方法，然而这些方法会损害大型语言模型的性能。本文揭示了大型语言模型中一个以前被忽视的异常点类型。这些异常点被发现将大部分注意力分配给输入的初始标记，被称为关键标记，这对于量化的大型语言模型的性能至关重要。鉴于此，我们提出了IntactKV，从完整精度模型中无损地生成关键标记的KV缓存。这种方法简单易行，可以轻松与现有的量化解决方案结合。此外，IntactKV可以被校准为额外的大型语言模型参数，以进一步增强量化的大型语言模型。数学分析还证明了IntactKV有效地降低了量化误差的上限。实证结果表明，IntactKV带来了持续的改进，并实现了无损的仅权重量。

    arXiv:2403.01241v1 Announce Type: cross  Abstract: Large language models (LLMs) excel in natural language processing but demand intensive computation. To mitigate this, various quantization methods have been explored, yet they compromise LLM performance. This paper unveils a previously overlooked type of outlier in LLMs. Such outliers are found to allocate most of the attention scores on initial tokens of input, termed as pivot tokens, which is crucial to the performance of quantized LLMs. Given that, we propose IntactKV to generate the KV cache of pivot tokens losslessly from the full-precision model. The approach is simple and easy to combine with existing quantization solutions. Besides, IntactKV can be calibrated as additional LLM parameters to boost the quantized LLMs further. Mathematical analysis also proves that IntactKV effectively reduces the upper bound of quantization error. Empirical results show that IntactKV brings consistent improvement and achieves lossless weight-only
    
[^114]: Polynormer: 多项式表达的线性时间图转换器

    Polynormer: Polynomial-Expressive Graph Transformer in Linear Time

    [https://arxiv.org/abs/2403.01232](https://arxiv.org/abs/2403.01232)

    Polynormer提出了一种多项式表达GT模型，具有线性复杂度，结合本地和全局等变注意力模型，平衡了表现力和可扩展性。

    

    图转换器（GTs）已经成为一种有前途的架构，理论上它比消息传递图神经网络（GNNs）更具表现力。然而，典型的GT模型至少具有二次复杂度，因此无法扩展到大型图。虽然最近提出了几种线性GTs，但它们在几个热门图数据集上仍落后于GNN对应模型，这对于它们的实际表现力构成了一个重要关注点。为了平衡GTs的表现力和可扩展性之间的权衡，我们提出了Polynormer，一个具有线性复杂度的多项式表达GT模型。Polynormer构建在一个新颖的基础模型上，该模型在输入特征上学习高次多项式。为了使基础模型具有置换等变性，我们将其与图拓扑和节点特征分开集成，从而产生本地和全局等变关注模型。因此，Polynormer采用了线性的局部到全局关注方案。

    arXiv:2403.01232v1 Announce Type: cross  Abstract: Graph transformers (GTs) have emerged as a promising architecture that is theoretically more expressive than message-passing graph neural networks (GNNs). However, typical GT models have at least quadratic complexity and thus cannot scale to large graphs. While there are several linear GTs recently proposed, they still lag behind GNN counterparts on several popular graph datasets, which poses a critical concern on their practical expressivity. To balance the trade-off between expressivity and scalability of GTs, we propose Polynormer, a polynomial-expressive GT model with linear complexity. Polynormer is built upon a novel base model that learns a high-degree polynomial on input features. To enable the base model permutation equivariant, we integrate it with graph topology and node features separately, resulting in local and global equivariant attention models. Consequently, Polynormer adopts a linear local-to-global attention scheme t
    
[^115]: REWIND数据集：在野外多模态身体运动信号中隐私保护的语音状态分割

    REWIND Dataset: Privacy-preserving Speaking Status Segmentation from Multimodal Body Movement Signals in the Wild

    [https://arxiv.org/abs/2403.01229](https://arxiv.org/abs/2403.01229)

    通过视频和可穿戴传感器数据训练的机器学习模型可以隐私保护地识别说话状态，解决了在野外获取个人录音困难的问题

    

    识别人类的说话是理解社会互动的一个核心任务。通常情况下，会从个人录音中检测说话，就像之前为会议场景所做的那样。然而，在拥挤的聚会场景中，由于成本、后勤和隐私问题，很难获取个人录音。作为一种替代方案，通过训练在视频和可穿戴传感器数据上的机器学习模型可以实现通过检测其相关手势来识别语音，这种方式既不引人注目又保护隐私。然而，这些模型本身理想情况下应该使用从语音信号中获取的标签进行训练。然而，现有的聚会数据集中没有包含高质量的音频记录。相反，对说话状态的注释通常是通过人类标注者从视频中推断出来的，而没有对这种方法针对基于音频的地面真实性进行验证。本文重新审视了非音频说话状态标签

    arXiv:2403.01229v1 Announce Type: cross  Abstract: Recognizing speaking in humans is a central task towards understanding social interactions. Ideally, speaking would be detected from individual voice recordings, as done previously for meeting scenarios. However, individual voice recordings are hard to obtain in the wild, especially in crowded mingling scenarios due to cost, logistics, and privacy concerns. As an alternative, machine learning models trained on video and wearable sensor data make it possible to recognize speech by detecting its related gestures in an unobtrusive, privacy-preserving way. These models themselves should ideally be trained using labels obtained from the speech signal. However, existing mingling datasets do not contain high quality audio recordings. Instead, speaking status annotations have often been inferred by human annotators from video, without validation of this approach against audio-based ground truth. In this paper we revisit no-audio speaking statu
    
[^116]: 一种用于成本效率多实例反事实解释的两阶段算法

    A Two-Stage Algorithm for Cost-Efficient Multi-instance Counterfactual Explanations

    [https://arxiv.org/abs/2403.01221](https://arxiv.org/abs/2403.01221)

    本文提出了一种两阶段算法，用于找到实例组以及成本有效的多实例反事实解释，填补了先前工作中未解决的空白。

    

    反事实解释是分析黑盒系统预测结果的最流行方法之一，因为它可以推荐成本有效且可操作的输入更改，将不良系统输出转变为期望输出。大多数现有的反事实方法解释单个实例，但一些真实的用例（如客户满意度）需要识别能同时满足多个实例（例如客户）的单一反事实。在这项工作中，我们提出了一种灵活的两阶段算法，用于找到实例组以及成本有效的多实例反事实解释。这是因为在大多数先前的工作中，找到这样的实例组并未得到充分解决的。

    arXiv:2403.01221v1 Announce Type: cross  Abstract: Counterfactual explanations constitute among the most popular methods for analyzing the predictions of black-box systems since they can recommend cost-efficient and actionable changes to the input to turn an undesired system's output into a desired output. While most of the existing counterfactual methods explain a single instance, several real-world use cases, such as customer satisfaction, require the identification of a single counterfactual that can satisfy multiple instances (e.g. customers) simultaneously. In this work, we propose a flexible two-stage algorithm for finding groups of instances along with cost-efficient multi-instance counterfactual explanations. This is motivated by the fact that in most previous works the aspect of finding such groups is not addressed.
    
[^117]: API就够了：无需对数访问的大型语言模型的整体预测

    API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access

    [https://arxiv.org/abs/2403.01216](https://arxiv.org/abs/2403.01216)

    本研究提出了一种针对无需访问对数的API-only LLMs的整体预测方法，旨在最小化预测集大小并确保用户定义的覆盖范围的统计保证。

    

    本研究旨在解决无法访问对数时如何量化大型语言模型（LLMs）中的不确定性这一普遍挑战。整体预测（CP）以其与模型无关和无需分布的特点而闻名，是各种LLMs和数据分布的理想方法。然而，现有的LLMs整体预测方法通常假定可以访问对数，这对于一些仅支持API的LLMs来说是不可用的。此外，已知对数可能存在校准不准确的问题，可能导致整体预测性能下降。为了应对这些挑战，我们提出一种新颖的CP方法，（1）专为无需对数访问的API-only LLMs量身定制; (2) 最小化预测集的大小; 以及(3)确保用户定义的覆盖范围具有统计保证。该方法的核心思想是利用粗粒度（例如，样本频率）和细粒度不确定性概念（例如，语义相似性）来制定不一致性度量。实验结果表明，

    arXiv:2403.01216v1 Announce Type: cross  Abstract: This study aims to address the pervasive challenge of quantifying uncertainty in large language models (LLMs) without logit-access. Conformal Prediction (CP), known for its model-agnostic and distribution-free features, is a desired approach for various LLMs and data distributions. However, existing CP methods for LLMs typically assume access to the logits, which are unavailable for some API-only LLMs. In addition, logits are known to be miscalibrated, potentially leading to degraded CP performance. To tackle these challenges, we introduce a novel CP method that (1) is tailored for API-only LLMs without logit-access; (2) minimizes the size of prediction sets; and (3) ensures a statistical guarantee of the user-defined coverage. The core idea of this approach is to formulate nonconformity measures using both coarse-grained (i.e., sample frequency) and fine-grained uncertainty notions (e.g., semantic similarity). Experimental results on 
    
[^118]: SAR-AE-SFP: 具有目标散射特征参数的实际物理领域合成孔径雷达（SAR）图像对抗样本

    SAR-AE-SFP: SAR Imagery Adversarial Example in Real Physics domain with Target Scattering Feature Parameters

    [https://arxiv.org/abs/2403.01210](https://arxiv.org/abs/2403.01210)

    该研究提出了一种通过改变目标物体的散射特征参数生成真实物理对抗样本的方法，解决了合成孔径雷达目标识别模型受到对抗样本影响的挑战。

    

    arXiv:2403.01210v1 通告类型: 交叉 深度神经网络的合成孔径雷达（SAR）目标识别模型容易受到对抗样本的影响。当前针对SAR图像的对抗样本生成方法主要在二维数字领域中运行，被称为图像对抗样本。最近的工作在考虑SAR成像散射机制的同时，未能考虑实际成像过程，导致在三维物理领域中攻击不可行，称为伪物理对抗样本。为解决这些挑战，本文提出了SAR-AE-SFP-Attack，一种通过改变目标物体的散射特征参数生成真实物理对抗样本的方法。具体来说，我们通过扰动目标物体的散射特征参数中的反射系数和散射系数，迭代优化目标回波的一致能量积累，并获得对抗性样本。

    arXiv:2403.01210v1 Announce Type: cross  Abstract: Deep neural network-based Synthetic Aperture Radar (SAR) target recognition models are susceptible to adversarial examples. Current adversarial example generation methods for SAR imagery primarily operate in the 2D digital domain, known as image adversarial examples. Recent work, while considering SAR imaging scatter mechanisms, fails to account for the actual imaging process, rendering attacks in the three-dimensional physical domain infeasible, termed pseudo physics adversarial examples. To address these challenges, this paper proposes SAR-AE-SFP-Attack, a method to generate real physics adversarial examples by altering the scattering feature parameters of target objects. Specifically, we iteratively optimize the coherent energy accumulation of the target echo by perturbing the reflection coefficient and scattering coefficient in the scattering feature parameters of the three-dimensional target object, and obtain the adversarial exam
    
[^119]: 动物友好人工智能的案例

    The Case for Animal-Friendly AI

    [https://arxiv.org/abs/2403.01199](https://arxiv.org/abs/2403.01199)

    人工智能伦理学和工程领域需要意识到技术会对动物产生巨大影响，因此作者构建了一个评估系统来评估大型语言模型对动物利益的考虑程度。

    

    人工智能被视为日益重要，且具有潜在深远影响，但是AI伦理学和AI工程领域尚未充分意识到这些技术，包括大型语言模型（LLMs），将对动物产生巨大影响。我们认为这种影响很重要，因为动物在道德上很重要。作为评估LLMs中考虑动物因素的初步实验，我们构建了一个概念验证评估系统，该系统从多个角度评估LLM的响应和偏见。该系统通过两个标准评估LLM的输出：它们的真实性和它们对动物利益的考虑程度。我们使用一组结构化查询和预定义的规范视角测试了OpenAI ChatGPT 4和Anthropic Claude 2.1。初步结果表明，所测试模型的结果可以根据它们对动物考虑的程度进行基准比较，并且生成的 positio

    arXiv:2403.01199v1 Announce Type: new  Abstract: Artificial intelligence is seen as increasingly important, and potentially profoundly so, but the fields of AI ethics and AI engineering have not fully recognized that these technologies, including large language models (LLMs), will have massive impacts on animals. We argue that this impact matters, because animals matter morally.   As a first experiment in evaluating animal consideration in LLMs, we constructed a proof-of-concept Evaluation System, which assesses LLM responses and biases from multiple perspectives. This system evaluates LLM outputs by two criteria: their truthfulness, and the degree of consideration they give to the interests of animals. We tested OpenAI ChatGPT 4 and Anthropic Claude 2.1 using a set of structured queries and predefined normative perspectives. Preliminary results suggest that the outcomes of the tested models can be benchmarked regarding the consideration they give to animals, and that generated positio
    
[^120]: Covid领域的机器翻译：LoResMT 2021中英爱尔兰语案例研究

    Machine Translation in the Covid domain: an English-Irish case study for LoResMT 2021

    [https://arxiv.org/abs/2403.01196](https://arxiv.org/abs/2403.01196)

    在LoResMT 2021中，针对Covid数据从英语到爱尔兰语的翻译，通过使用领域自适应技术和扩展领域内Covid数据集训练Transformer架构，成功改善了翻译表现。

    

    本文针对从英语到爱尔兰语翻译Covid数据的特定领域，开发了LoResMT 2021共享任务的翻译模型。利用来自翻译总司指导处的Covid适配通用55k语料库进行域自适应技术的应用。将微调、混合微调和组合数据集方法与在扩展的领域内数据集上训练的模型进行了比较。作为研究的一部分，开发了一份健康和教育领域的英语-爱尔兰语Covid相关数据集。表现最佳的模型采用了使用扩展的领域内Covid数据集训练的Transformer架构。在本研究中，我们证明扩展8k领域内基准数据集只需再增加5k行，就将BLEU分数提高了27个点。

    arXiv:2403.01196v1 Announce Type: cross  Abstract: Translation models for the specific domain of translating Covid data from English to Irish were developed for the LoResMT 2021 shared task. Domain adaptation techniques, using a Covid-adapted generic 55k corpus from the Directorate General of Translation, were applied. Fine-tuning, mixed fine-tuning and combined dataset approaches were compared with models trained on an extended in-domain dataset. As part of this study, an English-Irish dataset of Covid related data, from the Health and Education domains, was developed. The highest-performing model used a Transformer architecture trained with an extended in-domain Covid dataset. In the context of this study, we have demonstrated that extending an 8k in-domain baseline dataset by just 5k lines improved the BLEU score by 27 points.
    
[^121]: RAGged Edges: Retrieval-Augmented Chatbots的双刃剑

    RAGged Edges: The Double-Edged Sword of Retrieval-Augmented Chatbots

    [https://arxiv.org/abs/2403.01193](https://arxiv.org/abs/2403.01193)

    本文探讨了如何利用检索增强生成（RAG）抵制大型语言模型（LLMs）产生的幻觉，结果表明RAG在某些情况下可以提高准确性，但仍需要更强大的解决方案以确保LLMs在实际应用中可靠性。

    

    大型语言模型（LLMs）如ChatGPT展示了人工智能的显著进展。然而，它们倾向于产生幻觉 - 生成看似正确但错误信息的倾向带来了重大挑战。这个问题很关键，就像最近的法院案例中看到的那样，ChatGPT的使用导致了不存在的法律裁决的引用。本文探讨了如何通过将外部知识与提示集成来使用检索增强生成（RAG）来抵制幻觉。我们通过使用旨在诱导幻觉的提示来对RAG与标准LLMs进行经验评估。我们的结果显示，在某些情况下，RAG可以提高准确性，但当提示直接与模型预训练的理解相矛盾时，RAG仍然会被误导。这些发现突显了幻觉的复杂性以及需要更强大的解决方案以确保LLMs在实际应用中可靠性。我们提供了RAG部署的实用建议。

    arXiv:2403.01193v1 Announce Type: cross  Abstract: Large language models (LLMs) like ChatGPT demonstrate the remarkable progress of artificial intelligence. However, their tendency to hallucinate -- generate plausible but false information -- poses a significant challenge. This issue is critical, as seen in recent court cases where ChatGPT's use led to citations of non-existent legal rulings. This paper explores how Retrieval-Augmented Generation (RAG) can counter hallucinations by integrating external knowledge with prompts. We empirically evaluate RAG against standard LLMs using prompts designed to induce hallucinations. Our results show that RAG increases accuracy in some cases, but can still be misled when prompts directly contradict the model's pre-trained understanding. These findings highlight the complex nature of hallucinations and the need for more robust solutions to ensure LLM reliability in real-world applications. We offer practical recommendations for RAG deployment and 
    
[^122]: 在LLM中使用Soft RLLF实现探索和开发的平衡，以增强否定理解

    Balancing Exploration and Exploitation in LLM using Soft RLLF for Enhanced Negation Understanding

    [https://arxiv.org/abs/2403.01185](https://arxiv.org/abs/2403.01185)

    通过利用逻辑反馈的强化学习（RLLF）在LLMs中实现探索和开发的平衡，以增强否定理解能力，并通过比较性能验证了这种平衡方法的价值。

    

    在NLP中，调整方法通常侧重于开发而不是探索，这可能导致次优模型。考虑到自然语言的广阔搜索空间，这种有限的探索可能限制它们在复杂、高风险领域中的表现，那里准确的否定理解和逻辑推理能力至关重要。为解决这一问题，我们利用逻辑反馈的强化学习（RLLF）在LLMs中实现探索和开发的有效平衡。我们的方法采用适当的基准数据集进行训练和评估，突出了通过增强否定理解能力来强调探索的重要性。我们将使用RLLF增强的LLMs的性能与未使用RLLF训练的基线模型进行比较，展示了这种平衡方法的价值。此外，我们通过迁移学习展示了我们的方法在法律AI应用中的潜力，并进行了评价。

    arXiv:2403.01185v1 Announce Type: cross  Abstract: Finetuning approaches in NLP often focus on exploitation rather than exploration, which may lead to suboptimal models. Given the vast search space of natural language, this limited exploration can restrict their performance in complex, high-stakes domains, where accurate negation understanding and logical reasoning abilities are crucial. To address this issue, we leverage Reinforcement Learning from Logical Feedback (RLLF) to create an effective balance between exploration and exploitation in LLMs. Our approach employs an appropriate benchmark dataset for training and evaluation, highlighting the importance of exploration in enhancing negation understanding capabilities. We compare the performance of our RLLF-enhanced LLMs with baseline models trained without RLLF, demonstrating the value of this balanced approach. Furthermore, we showcase the potential of our method in legal AI applications by employing transfer learning and evaluatin
    
[^123]: 利用自监督学习进行儿童性虐待图像场景识别

    Leveraging Self-Supervised Learning for Scene Recognition in Child Sexual Abuse Imagery

    [https://arxiv.org/abs/2403.01183](https://arxiv.org/abs/2403.01183)

    利用自监督学习技术，本文提出了一种能够安全高效处理儿童性虐待图像数据的场景识别方法。

    

    21世纪的犯罪分为虚拟和真实世界。然而，前者已经成为对后者人们福祉和安全构成全球威胁。它提出的挑战必须通过统一的全球合作来面对，我们必须比以往更加依赖自动化但值得信赖的工具来应对网络犯罪日益增长的本质。每年有超过1000万起儿童性虐待报告提交给美国国家失踪和被剥削儿童中心，超过80%来自网络来源。因此，调查中心和清除中心无法手动处理和正确调查所有图像。基于此，能够安全高效处理这些数据的可靠自动化工具至关重要。在这方面，场景识别任务寻找环境中的上下文线索，能够组织和分类儿童性虐待数据，而无需在敏感数据上进行训练。

    arXiv:2403.01183v1 Announce Type: cross  Abstract: Crime in the 21st century is split into a virtual and real world. However, the former has become a global menace to people's well-being and security in the latter. The challenges it presents must be faced with unified global cooperation, and we must rely more than ever on automated yet trustworthy tools to combat the ever-growing nature of online offenses. Over 10 million child sexual abuse reports are submitted to the US National Center for Missing & Exploited Children every year, and over 80% originated from online sources. Therefore, investigation centers and clearinghouses cannot manually process and correctly investigate all imagery. In light of that, reliable automated tools that can securely and efficiently deal with this data are paramount. In this sense, the scene recognition task looks for contextual cues in the environment, being able to group and classify child sexual abuse data without requiring to be trained on sensitive 
    
[^124]: DINER：使用多变量因果推断来去偏方面级情感分析

    DINER: Debiasing Aspect-based Sentiment Analysis with Multi-variable Causal Inference

    [https://arxiv.org/abs/2403.01166](https://arxiv.org/abs/2403.01166)

    本论文提出了一种基于多变量因果推断的新框架，用于去偏方面级情感分析，从而解决神经网络模型学习虚假相关性的问题。

    

    尽管取得了显著进展，基于神经网络的方面级情感分析（ABSA）模型容易从注释偏见中学习到虚假相关性，导致在对抗性数据转换上鲁棒性较差。在去偏解决方案中，基于因果推断的方法引起了许多研究关注，主要可分为因果干预方法和反事实推理方法。然而，目前大多数去偏方法都集中在单变量因果推断上，这对于具有两个输入变量（目标方面和评论）的ABSA并不适用。在本文中，我们提出了一个基于多变量因果推断的新框架用于去偏ABSA。在这个框架中，不同类型的偏见基于不同的因果干预方法得到处理。对于评论分支，偏见被建模为来自上下文的间接混杂，其中实施反向调整干预。

    arXiv:2403.01166v1 Announce Type: cross  Abstract: Though notable progress has been made, neural-based aspect-based sentiment analysis (ABSA) models are prone to learn spurious correlations from annotation biases, resulting in poor robustness on adversarial data transformations. Among the debiasing solutions, causal inference-based methods have attracted much research attention, which can be mainly categorized into causal intervention methods and counterfactual reasoning methods. However, most of the present debiasing methods focus on single-variable causal inference, which is not suitable for ABSA with two input variables (the target aspect and the review). In this paper, we propose a novel framework based on multi-variable causal inference for debiasing ABSA. In this framework, different types of biases are tackled based on different causal intervention methods. For the review branch, the bias is modeled as indirect confounding from context, where backdoor adjustment intervention is 
    
[^125]: STAR: 使用动态主动学习约束LoRA，实现大型语言模型数据高效微调

    STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient Fine-Tuning of Large Language Models

    [https://arxiv.org/abs/2403.01165](https://arxiv.org/abs/2403.01165)

    本论文提出了一种新颖的方法，有效地将基于不确定性的主动学习和LoRA相结合，以解决大型语言模型数据高效微调中遇到的问题。

    

    大型语言模型(LLMs)通过提示方法展示了少样本学习的强大能力，但对于复杂推理任务仍需监督训练。针对LLMs的参数众多和内存消耗大问题，分别提出了参数高效微调(PEFT)方法和内存高效微调方法。然而，数据高效微调旨在解决大量注释数据消耗的问题，却鲜有研究。一种明显的方式是将PEFT方法与主动学习相结合。然而，实验结果表明这种组合并非简单，并产生较差的结果。通过探针实验，这一观察结果可能由两个主要原因解释：不确定性差距和模型校准不佳。因此，在本文中，我们提出了一种新颖的方法，有效地将基于不确定性的主动学习和LoRA进行整合。

    arXiv:2403.01165v1 Announce Type: cross  Abstract: Though Large Language Models (LLMs) have demonstrated the powerful capabilities of few-shot learning through prompting methods, supervised training is still necessary for complex reasoning tasks. Because of their extensive parameters and memory consumption, both Parameter-Efficient Fine-Tuning (PEFT) methods and Memory-Efficient Fine-Tuning methods have been proposed for LLMs. Nevertheless, the issue of large annotated data consumption, the aim of Data-Efficient Fine-Tuning, remains unexplored. One obvious way is to combine the PEFT method with active learning. However, the experimental results show that such a combination is not trivial and yields inferior results. Through probe experiments, such observation might be explained by two main reasons: uncertainty gap and poor model calibration. Therefore, in this paper, we propose a novel approach to effectively integrate uncertainty-based active learning and LoRA. Specifically, for the u
    
[^126]: AI生成文本取证系统综述：检测、归因和特征化

    A Survey of AI-generated Text Forensic Systems: Detection, Attribution, and Characterization

    [https://arxiv.org/abs/2403.01152](https://arxiv.org/abs/2403.01152)

    本文综述了AI生成文本取证系统，重点讨论了检测、归因和特征化三个主要方面，以实现对AI生成文本的实际理解。

    

    我们最近目击了一系列先进的大型语言模型（LLMs）的快速增长，这些模型能够生成高质量的文本。尽管这些LLMs已经在各个领域彻底改变了文本生成，但它们也带来了信息生态系统中的重大风险，比如可能大规模生成令人信服的宣传、错误信息和谣言。本文提供了对AI生成文本取证系统的综述，这是一个应对LLM滥用挑战的新兴领域。我们通过介绍一个详细的分类法，着重介绍了AI生成文本取证领域现有的努力，着眼于三个主要支柱：检测、归因和特征化。这些支柱使人们能够实际理解AI生成的文本，包括识别AI生成内容（检测）、确定涉及的具体AI模型（归因）以及对文本的基本意图进行分类（特征化）。

    arXiv:2403.01152v1 Announce Type: cross  Abstract: We have witnessed lately a rapid proliferation of advanced Large Language Models (LLMs) capable of generating high-quality text. While these LLMs have revolutionized text generation across various domains, they also pose significant risks to the information ecosystem, such as the potential for generating convincing propaganda, misinformation, and disinformation at scale. This paper offers a review of AI-generated text forensic systems, an emerging field addressing the challenges of LLM misuses. We present an overview of the existing efforts in AI-generated text forensics by introducing a detailed taxonomy, focusing on three primary pillars: detection, attribution, and characterization. These pillars enable a practical understanding of AI-generated text, from identifying AI-generated content (detection), determining the specific AI model involved (attribution), and grouping the underlying intents of the text (characterization). Furtherm
    
[^127]: 基于生成对抗网络和Transformer模型的交通事故检测混合模型

    A Hybrid Model for Traffic Incident Detection based on Generative Adversarial Networks and Transformer Model

    [https://arxiv.org/abs/2403.01147](https://arxiv.org/abs/2403.01147)

    提出了一种结合Transformer和生成对抗网络的混合模型来提高交通事故检测的效果，并通过扩展数据集和实现平衡比例进行了验证

    

    除了增强交通安全并促进及时应急响应外，交通事故检测通过提供实时交通状态信息，在智能交通系统中起着不可或缺的作用。先前的研究发现，除了采用先进的算法模型外，检测的有效性还受到获取大型数据集和解决数据集不平衡等挑战的显著影响。提出了一种结合Transformer和生成对抗网络（GANs）的混合模型来解决这些挑战。实验证实了Transformer在交通事故检测中的优越性。此外，利用GANs扩展数据集，实现1:4、2:3和1:1的平衡比。该模型针对基准模型进行了评估。

    arXiv:2403.01147v1 Announce Type: cross  Abstract: In addition to enhancing traffic safety and facilitating prompt emergency response, traffic incident detection plays an indispensable role in intelligent transportation systems by providing real-time traffic status information. This enables the realization of intelligent traffic control and management. Previous research has identified that apart from employing advanced algorithmic models, the effectiveness of detection is also significantly influenced by challenges related to acquiring large datasets and addressing dataset imbalances. A hybrid model combining transformer and generative adversarial networks (GANs) is proposed to address these challenges. Experiments are conducted on four real datasets to validate the superiority of the transformer in traffic incident detection. Additionally, GANs are utilized to expand the dataset and achieve a balanced ratio of 1:4, 2:3, and 1:1. The proposed model is evaluated against the baseline mod
    
[^128]: ParallelPARC: 生成自然语言类比的可扩展流水线

    ParallelPARC: A Scalable Pipeline for Generating Natural-Language Analogies

    [https://arxiv.org/abs/2403.01139](https://arxiv.org/abs/2403.01139)

    设计了ParallelPARC流水线，利用大型语言模型生成复杂段落类比数据集，评估各种类比类型，并展示出人类在类比识别中的优势。

    

    Analogy-making对于人类认知至关重要，使我们能够适应新颖情境--这是当前人工智能系统仍然缺乏的能力。大多数类比数据集今天关注简单的类比（例如，词类比）；包含复杂类型类比的数据集通常是手工策划的，并且非常小。我们认为这限制了计算类比的进展。在这项工作中，我们设计了一个数据生成流水线，ParallelPARC（Parallel Paragraph Creator），利用最先进的大型语言模型（LLM）来创建基于段落的复杂类比，以及简单和具有挑战性的干扰项。我们展示了我们的流水线，并创建了ProPara-Logy，一个关于科学过程间类比的数据集。我们发布了一个由人类验证过的金标准数据集，以及一个自动生成的银标准数据集。我们在二进制和多选环境中测试了LLMs和人类对类比的识别，发现人类胜过最佳模型。

    arXiv:2403.01139v1 Announce Type: cross  Abstract: Analogy-making is central to human cognition, allowing us to adapt to novel situations -- an ability that current AI systems still lack. Most analogy datasets today focus on simple analogies (e.g., word analogies); datasets including complex types of analogies are typically manually curated and very small. We believe that this holds back progress in computational analogy. In this work, we design a data generation pipeline, ParallelPARC (Parallel Paragraph Creator) leveraging state-of-the-art Large Language Models (LLMs) to create complex, paragraph-based analogies, as well as distractors, both simple and challenging. We demonstrate our pipeline and create ProPara-Logy, a dataset of analogies between scientific processes. We publish a gold-set, validated by humans, and a silver-set, generated automatically. We test LLMs' and humans' analogy recognition in binary and multiple-choice settings, and found that humans outperform the best mod
    
[^129]: 在具有相位感知分区和自适应量化的异构集群上提供LLM-PQ

    LLM-PQ: Serving LLM on Heterogeneous Clusters with Phase-Aware Partition and Adaptive Quantization

    [https://arxiv.org/abs/2403.01136](https://arxiv.org/abs/2403.01136)

    这项研究提出了LLM-PQ系统，通过采用自适应模型量化和相位感知分区，在异构GPU集群上提高了LLM服务的效率。

    

    最近大规模语言模型（LLMs）的突破性进展在各种任务上展示了令人印象深刻的性能。LLMs的巨大规模导致了非常高的资源需求和成本。尽管目前主要使用统一高性能GPU来服务这些模型，但利用一种混合可用高低容量GPU的异构集群可能会大幅降低服务成本。然而，目前缺乏支持使用异构集群高效提供LLM服务的设计，而当前的解决方案主要集中在模型分区和均匀压缩在同质设备之间。本文提出了LLM-PQ，这是一个倡导自适应模型量化和相位感知分区以提高异构GPU集群上LLM服务效率的系统。我们在分布式LLM服务中仔细选择了混合精度模型量化、相位感知模型分区和微批量大小。

    arXiv:2403.01136v1 Announce Type: cross  Abstract: Recent breakthroughs in Large-scale language models (LLMs) have demonstrated impressive performance on various tasks. The immense sizes of LLMs have led to very high resource demand and cost for running the models. Though the models are largely served using uniform high-caliber GPUs nowadays, utilizing a heterogeneous cluster with a mix of available high- and low-capacity GPUs can potentially substantially reduce the serving cost. There is a lack of designs to support efficient LLM serving using a heterogeneous cluster, while the current solutions focus on model partition and uniform compression among homogeneous devices. This paper proposes LLM-PQ, a system that advocates adaptive model quantization and phase-aware partition to improve LLM serving efficiency on heterogeneous GPU clusters. We carefully decide on mixed-precision model quantization together with phase-aware model partition and micro-batch sizing in distributed LLM servin
    
[^130]: LLaMoCo：用于优化代码生成的大型语言模型指令调优

    LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation

    [https://arxiv.org/abs/2403.01131](https://arxiv.org/abs/2403.01131)

    LLaMoCo是第一个旨在以代码对代码方式调整LLMs以解决优化问题的指令调优框架，通过全面指令集和新颖的两阶段学习策略，实现了优越的性能。

    

    最近的研究探讨了使用大型语言模型（LLMs）进行优化，方法包括从LLMs迭代地寻找下一步解决方案，或直接提示LLMs以获取优化器。然而，这些方法存在固有限制，包括操作效率低、对提示设计敏感度高以及缺乏领域特定知识。我们介绍了LLaMoCo，这是第一个旨在以代码对代码方式调整LLMs以解决优化问题的指令调优框架。具体地，我们建立了一个包含清晰描述的问题提示和有效优化代码的全面指令集。然后我们开发了一种新颖的两阶段学习策略，在指令调优阶段之前，该策略整合了基于对比学习的热身过程，以增强模型微调期间的收敛行为。实验结果表明，通过我们的LLaMoCo精调的CodeGen（350M）模型达到了卓越的性能。

    arXiv:2403.01131v1 Announce Type: cross  Abstract: Recent research explores optimization using large language models (LLMs) by either iteratively seeking next-step solutions from LLMs or directly prompting LLMs for an optimizer. However, these approaches exhibit inherent limitations, including low operational efficiency, high sensitivity to prompt design, and a lack of domain-specific knowledge. We introduce LLaMoCo, the first instruction-tuning framework designed to adapt LLMs for solving optimization problems in a code-to-code manner. Specifically, we establish a comprehensive instruction set containing well-described problem prompts and effective optimization codes. We then develop a novel two-phase learning strategy that incorporates a contrastive learning-based warm-up procedure before the instruction-tuning phase to enhance the convergence behavior during model fine-tuning. The experiment results demonstrate that a CodeGen (350M) model fine-tuned by our LLaMoCo achieves superior 
    
[^131]: OpenGraph: 迈向开放图基础模型

    OpenGraph: Towards Open Graph Foundation Models

    [https://arxiv.org/abs/2403.01121](https://arxiv.org/abs/2403.01121)

    该论文旨在通过开发一个通用图基础模型，以解决现有图神经网络在泛化到与训练数据显著不同的未见图数据时遇到的困难。

    

    arXiv:2403.01121v1 公告类型: 跨交互   摘要: 图学习已成为解释和利用各领域的关系数据的不可或缺部分，从推荐系统到社交网络分析。在这种背景下，各种GNN已经成为编码图的结构信息的有希望的方法论，通过有效地捕捉图的潜在结构，这些GNN已经展示出在增强图学习任务性能方面的巨大潜力，例如链接预测和节点分类。然而，尽管取得了成功，一个显著的挑战仍然存在: 这些先进方法通常在将显著不同于训练实例的未见图数据泛化时遇到困难。在这项工作中，我们的目标是通过开发一个通用图基础模型来推进图学习范式。该模型旨在理解多样图数据中存在的复杂拓扑模式，使其在零-shot情况下表现出色。

    arXiv:2403.01121v1 Announce Type: cross  Abstract: Graph learning has become indispensable for interpreting and harnessing relational data in diverse fields, ranging from recommendation systems to social network analysis. In this context, a variety of GNNs have emerged as promising methodologies for encoding the structural information of graphs. By effectively capturing the graph's underlying structure, these GNNs have shown great potential in enhancing performance in graph learning tasks, such as link prediction and node classification. However, despite their successes, a significant challenge persists: these advanced methods often face difficulties in generalizing to unseen graph data that significantly differs from the training instances. In this work, our aim is to advance the graph learning paradigm by developing a general graph foundation model. This model is designed to understand the complex topological patterns present in diverse graph data, enabling it to excel in zero-shot g
    
[^132]: 通过基于图像感知属性缩减的对抗性测试进行视觉定位

    Adversarial Testing for Visual Grounding via Image-Aware Property Reduction

    [https://arxiv.org/abs/2403.01118](https://arxiv.org/abs/2403.01118)

    提出了一种通过基于图像感知属性缩减的文本扰动方法，用于对抗性测试VG模型

    

    由于融合多种模态信息的优势，多模态学习正在越来越受到关注。作为多模态学习的基本任务，视觉定位（VG）旨在通过自然语言表达在图像中定位对象。确保VG模型的质量面临着重大挑战，因为该任务具有复杂的特性。在黑盒场景下，现有的对抗性测试技术通常未能充分发挥信息两种模态的潜力。它们通常仅基于图像或文本信息之一应用扰动，忽视了两种模态之间的关键相关性，这将导致测试预言式失败或无法有效挑战VG模型。为此，我们提出了PEELING，这是一种通过基于图像感知属性缩减的文本扰动方法，用于对VG模型进行对抗性测试。

    arXiv:2403.01118v1 Announce Type: cross  Abstract: Due to the advantages of fusing information from various modalities, multimodal learning is gaining increasing attention. Being a fundamental task of multimodal learning, Visual Grounding (VG), aims to locate objects in images through natural language expressions. Ensuring the quality of VG models presents significant challenges due to the complex nature of the task. In the black box scenario, existing adversarial testing techniques often fail to fully exploit the potential of both modalities of information. They typically apply perturbations based solely on either the image or text information, disregarding the crucial correlation between the two modalities, which would lead to failures in test oracles or an inability to effectively challenge VG models. To this end, we propose PEELING, a text perturbation approach via image-aware property reduction for adversarial testing of the VG model. The core idea is to reduce the property-relate
    
[^133]: 通过从大型语言模型中自我解释提炼文本风格转移

    Distilling Text Style Transfer With Self-Explanation From LLMs

    [https://arxiv.org/abs/2403.01106](https://arxiv.org/abs/2403.01106)

    CoTeX是一个利用大型语言模型和思维链提示来促进文本风格转移的框架，通过提炼LLMs的能力为处理非平行数据和平行数据的简化模型，在低资源情况下表现优于传统的监督微调和知识蒸馏方法，并通过透明的解释在风格转移过程中有显著优势。

    

    文本风格转移（TST）旨在改变文本的风格同时保留其核心内容。鉴于TST的有限平行数据集的限制，我们提出了CoTeX，这是一个利用大型语言模型（LLMs）和思维链（CoT）提示来促进TST的框架。CoTeX将LLMs的复杂重写和推理能力提炼成更简化的模型，能够处理非平行数据和平行数据。通过在四个TST数据集上的实验，CoTeX显示出超越传统监督微调和知识蒸馏方法的能力，特别是在资源匮乏的情况下。我们进行了全面评估，将CoTeX与当前的无监督、监督、上下文学习（ICL）技术以及指导调整的LLMs进行了比较。此外，CoTeX通过提供透明的解释其风格转移过程而脱颖而出。

    arXiv:2403.01106v1 Announce Type: cross  Abstract: Text Style Transfer (TST) seeks to alter the style of text while retaining its core content. Given the constraints of limited parallel datasets for TST, we propose CoTeX, a framework that leverages large language models (LLMs) alongside chain-of-thought (CoT) prompting to facilitate TST. CoTeX distills the complex rewriting and reasoning capabilities of LLMs into more streamlined models capable of working with both non-parallel and parallel data. Through experimentation across four TST datasets, CoTeX is shown to surpass traditional supervised fine-tuning and knowledge distillation methods, particularly in low-resource settings. We conduct a comprehensive evaluation, comparing CoTeX against current unsupervised, supervised, in-context learning (ICL) techniques, and instruction-tuned LLMs. Furthermore, CoTeX distinguishes itself by offering transparent explanations for its style transfer process.
    
[^134]: 特征对齐：在预训练模型背景下通过代理思考高效主动学习

    Feature Alignment: Rethinking Efficient Active Learning via Proxy in the Context of Pre-trained Models

    [https://arxiv.org/abs/2403.01101](https://arxiv.org/abs/2403.01101)

    通过代理进行特征对齐，以解决预先计算特征无法区分标记样本类别和避免通过代理模型选择样本时牺牲宝贵预训练信息的问题。

    

    使用主动学习对预训练模型进行微调有望降低注释成本。然而，这种组合引入了显著的计算成本，尤其是随着预训练模型规模的增长。最近的研究提出了基于代理的主动学习，它预先计算特征以减少计算成本。然而，这种方法通常会在主动学习性能上造成重大损失，甚至可能超过计算成本节约。

    arXiv:2403.01101v1 Announce Type: cross  Abstract: Fine-tuning the pre-trained model with active learning holds promise for reducing annotation costs. However, this combination introduces significant computational costs, particularly with the growing scale of pre-trained models. Recent research has proposed proxy-based active learning, which pre-computes features to reduce computational costs. Yet, this approach often incurs a significant loss in active learning performance, which may even outweigh the computational cost savings. In this paper, we argue the performance drop stems not only from pre-computed features' inability to distinguish between categories of labeled samples, resulting in the selection of redundant samples but also from the tendency to compromise valuable pre-trained information when fine-tuning with samples selected through the proxy model. To address this issue, we propose a novel method called aligned selection via proxy to update pre-computed features while sele
    
[^135]: COOL：一种融合时空图神经网络用于交通预测的共同视角

    COOL: A Conjoint Perspective on Spatio-Temporal Graph Neural Network for Traffic Forecasting

    [https://arxiv.org/abs/2403.01091](https://arxiv.org/abs/2403.01091)

    本文提出了一种名为COOL的Conjoint Spatio-Temporal图神经网络，旨在共同捕捉交通预测中的高阶关系。

    

    本文研究交通预测，旨在根据历史情况预测交通的未来状态。鉴于其对多个场景的持续关注，并促进了许多下游应用程序的发展，例如城市规划和交通管理，该问题已经受到越来越多的关注。然而，由于现有方法倾向于独立地建模时空关系，因此未能充分考虑两者的复杂高阶互动，导致现有方法的效果不佳。此外，交通预测中的过渡模式的多样性使得现有方法难以捕捉，需要更深入地探索这种多样性。为此，本文提出了Conjoint Spatio-Temporal图神经网络（缩写为COOL），它从先前和后续信息中建模异构图，以共同捕捉高阶互动

    arXiv:2403.01091v1 Announce Type: cross  Abstract: This paper investigates traffic forecasting, which attempts to forecast the future state of traffic based on historical situations. This problem has received ever-increasing attention in various scenarios and facilitated the development of numerous downstream applications such as urban planning and transportation management. However, the efficacy of existing methods remains sub-optimal due to their tendency to model temporal and spatial relationships independently, thereby inadequately accounting for complex high-order interactions of both worlds. Moreover, the diversity of transitional patterns in traffic forecasting makes them challenging to capture for existing approaches, warranting a deeper exploration of their diversity. Toward this end, this paper proposes Conjoint Spatio-Temporal graph neural network (abbreviated as COOL), which models heterogeneous graphs from prior and posterior information to conjointly capture high-order sp
    
[^136]: 教授多层感知机更多图信息：三阶段多任务知识蒸馏框架

    Teaching MLP More Graph Information: A Three-stage Multitask Knowledge Distillation Framework

    [https://arxiv.org/abs/2403.01079](https://arxiv.org/abs/2403.01079)

    提出了一个新的三阶段多任务知识蒸馏框架，使用位置编码来捕捉位置信息，引入神经热核处理图数据，通过隐藏层输出匹配提高学生多层感知机的性能。

    

    我们研究了图神经网络在大规模图数据集上进行推理任务时面临的挑战：巨大的时间和内存消耗，并尝试通过减少对图结构的依赖来克服这一问题。尽管将图知识蒸馏到学生多层感知机是一个不错的想法，但它面临两个主要问题：位置信息丢失和泛化能力低。为了解决这些问题，我们提出了一种新的三阶段多任务蒸馏框架。具体地，我们使用位置编码来捕捉位置信息。此外，我们引入神经热核来负责图数据处理，在GNN中利用隐藏层输出匹配来提高学生多层感知机的性能。据我们所知，这是首次在图上引入隐藏层蒸馏用于学生多层感知机，并结合图位置编码和多层感知机。我们通过多种设置测试了其性能和稳健性，并得出结论......

    arXiv:2403.01079v1 Announce Type: cross  Abstract: We study the challenging problem for inference tasks on large-scale graph datasets of Graph Neural Networks: huge time and memory consumption, and try to overcome it by reducing reliance on graph structure. Even though distilling graph knowledge to student MLP is an excellent idea, it faces two major problems of positional information loss and low generalization. To solve the problems, we propose a new three-stage multitask distillation framework. In detail, we use Positional Encoding to capture positional information. Also, we introduce Neural Heat Kernels responsible for graph data processing in GNN and utilize hidden layer outputs matching for better performance of student MLP's hidden layers. To the best of our knowledge, it is the first work to include hidden layer distillation for student MLP on graphs and to combine graph Positional Encoding with MLP. We test its performance and robustness with several settings and draw the conc
    
[^137]: $\Gamma$-VAE: 曲率正则化变分自编码器，用于揭示高维数据中的新兴低维几何结构

    $\Gamma$-VAE: Curvature regularized variational autoencoders for uncovering emergent low dimensional geometric structure in high dimensional data

    [https://arxiv.org/abs/2403.01078](https://arxiv.org/abs/2403.01078)

    $\Gamma$-VAE通过正则化曲率来解决非线性降维技术中的两个限制，可以揭示高维数据中的新兴低维几何结构

    

    具有新兴行为的自然系统通常沿着高维空间中的低维子集进行组织。例如，尽管人类基因组中有数万个基因，但基因组学的原则研究富有成果，因为生物过程依赖于协调组织，从而产生较低维度的表型。为了揭示这种组织，许多非线性降维技术已成功地将高维数据嵌入到低维空间中，方法是保持数据点之间的局部相似性。然而，这些方法中的非线性性允许过多的曲率来保持跨多个非相邻数据集群的一般趋势，从而限制了它们对于超出分布数据的可解释性和泛化能力。在这里，我们通过规范化由变分自动编码器生成的流形的曲率来解决这两个限制，这一过程我们称之为“$\Gamma$-VAE”。

    arXiv:2403.01078v1 Announce Type: cross  Abstract: Natural systems with emergent behaviors often organize along low-dimensional subsets of high-dimensional spaces. For example, despite the tens of thousands of genes in the human genome, the principled study of genomics is fruitful because biological processes rely on coordinated organization that results in lower dimensional phenotypes. To uncover this organization, many nonlinear dimensionality reduction techniques have successfully embedded high-dimensional data into low-dimensional spaces by preserving local similarities between data points. However, the nonlinearities in these methods allow for too much curvature to preserve general trends across multiple non-neighboring data clusters, thereby limiting their interpretability and generalizability to out-of-distribution data. Here, we address both of these limitations by regularizing the curvature of manifolds generated by variational autoencoders, a process we coin ``$\Gamma$-VAE''.
    
[^138]: GraphRCG: 通过自引导表示的自条件图生成

    GraphRCG: Self-conditioned Graph Generation via Bootstrapped Representations

    [https://arxiv.org/abs/2403.01071](https://arxiv.org/abs/2403.01071)

    提出了一种自条件图生成框架，通过自引导表示指导生成过程，明确建模和利用图分布，优于传统隐式捕获分布的方法。

    

    图生成通常旨在创建与特定图分布密切对齐的新图。现有研究往往通过生成器的优化隐式捕获这种分布，可能忽视分布本身的复杂性。此外，这些方法通常忽略了学习到的分布对图生成的见解。相比之下，在这项工作中，我们提出了一种新颖的自条件图生成框架，旨在明确建模图分布并利用这些分布来指导生成过程。我们首先进行自条件建模，通过将每个图样本转换为低维表示，并优化一个表示生成器来捕获图分布并生成反映学习分布的新表示。随后，我们利用这些自引导表示作为自条件指导来...

    arXiv:2403.01071v1 Announce Type: cross  Abstract: Graph generation generally aims to create new graphs that closely align with a specific graph distribution. Existing works often implicitly capture this distribution through the optimization of generators, potentially overlooking the intricacies of the distribution itself. Furthermore, these approaches generally neglect the insights offered by the learned distribution for graph generation. In contrast, in this work, we propose a novel self-conditioned graph generation framework designed to explicitly model graph distributions and employ these distributions to guide the generation process. We first perform self-conditioned modeling to capture the graph distributions by transforming each graph sample into a low-dimensional representation and optimizing a representation generator to create new representations reflective of the learned distribution. Subsequently, we leverage these bootstrapped representations as self-conditioned guidance f
    
[^139]: 通过人工智能实现完整作者身份：支持利用AI生成的观点进行修订

    Towards Full Authorship with AI: Supporting Revision with AI-Generated Views

    [https://arxiv.org/abs/2403.01055](https://arxiv.org/abs/2403.01055)

    通过引入Textfocals，一个UI原型，提供LLM生成的摘要、问题和建议，支持写作过程，并鼓励反思和自主修订，用户可以在不直接生成文本的情况下维持对其写作的完整作者身份。

    

    大型语言模型（LLMs）正在塑造写作工具中的一种新用户界面（UI）范式，使用户能够通过提示生成文本。这种范式将一些创作控制权从用户转移到系统，从而减弱用户在写作过程中的作者身份和自主性。为了恢复自主性，我们引入了Textfocals，一个旨在研究强调用户在写作中角色的以人为本的UI原型。Textfocals通过在文本编辑器的侧栏中提供LLM生成的摘要、问题和建议（即LLM视图），支持写作过程，鼓励在写作中进行反思和自主修订，而无需直接生成文本。Textfocals的UI功能，包括具有上下文适应性视图和用于提示选择和定制的支撑功能，为用户提供了一种新颖的与LLMs互动的方式，用户在其中保持对其写作的完整作者身份。与Textfocals进行的形成性用户研究

    arXiv:2403.01055v1 Announce Type: cross  Abstract: Large language models (LLMs) are shaping a new user interface (UI) paradigm in writing tools by enabling users to generate text through prompts. This paradigm shifts some creative control from the user to the system, thereby diminishing the user's authorship and autonomy in the writing process. To restore autonomy, we introduce Textfocals, a UI prototype designed to investigate a human-centered approach that emphasizes the user's role in writing. Textfocals supports the writing process by providing LLM-generated summaries, questions, and advice (i.e., LLM views) in a sidebar of a text editor, encouraging reflection and self-driven revision in writing without direct text generation. Textfocals' UI affordances, including contextually adaptive views and scaffolding for prompt selection and customization, offer a novel way to interact with LLMs where users maintain full authorship of their writing. A formative user study with Textfocals sh
    
[^140]: 透过几何限制概率建模发现新生物医学概念

    Seeing Unseen: Discover Novel Biomedical Concepts via GeometryConstrained Probabilistic Modeling

    [https://arxiv.org/abs/2403.01053](https://arxiv.org/abs/2403.01053)

    提出了一种通过几何限制概率建模处理方法来解决生物医学数据中存在的非 i.i.d. 数据分布、类别不平衡等问题。

    

    arXiv:2403.01053v1 通告类型: 交叉  摘要: 机器学习以其数据驱动的特性，对科学发现的基本实践具有巨大的潜力改变。随着不断增加的研究数据收集，自动探索观测数据中的模式和见解，发现新的表型类别和概念将会变得更加吸引人。然而，在生物医学领域，累积数据中存在若干挑战，阻碍了新类发现的进展。非 i.i.d. 数据分布伴随着不同类别组之间的严重不平衡，本质上导致模糊和偏倚的语义表示。在这项工作中，我们提出了一种几何限制概率建模处理方法来解决所识别的问题。首先，我们建议将实例嵌入的近似后验参数化为边际 von Mises-Fisher 分布，以解决神经嵌入方案的模糊性与偏见性。

    arXiv:2403.01053v1 Announce Type: cross  Abstract: Machine learning holds tremendous promise for transforming the fundamental practice of scientific discovery by virtue of its data-driven nature. With the ever-increasing stream of research data collection, it would be appealing to autonomously explore patterns and insights from observational data for discovering novel classes of phenotypes and concepts. However, in the biomedical domain, there are several challenges inherently presented in the cumulated data which hamper the progress of novel class discovery. The non-i.i.d. data distribution accompanied by the severe imbalance among different groups of classes essentially leads to ambiguous and biased semantic representations. In this work, we present a geometry-constrained probabilistic modeling treatment to resolve the identified issues. First, we propose to parameterize the approximated posterior of instance embedding as a marginal von MisesFisher distribution to account for the int
    
[^141]: 一个镜子的库：低维深度神经网络是具有反射特征的凸Lasso模型

    A Library of Mirrors: Deep Neural Nets in Low Dimensions are Convex Lasso Models with Reflection Features

    [https://arxiv.org/abs/2403.01046](https://arxiv.org/abs/2403.01046)

    证明在1-D数据上训练神经网络等价于解决一个具有固定特征字典矩阵的凸Lasso问题，为全局最优网络和解空间提供了洞察。

    

    我们证明在1-D数据上训练神经网络等价于解决一个带有固定、明确定义的特征字典矩阵的凸Lasso问题。具体的字典取决于激活函数和深度。我们考虑具有分段线性激活函数的两层网络，深窄的ReLU网络最多有4层，以及具有符号激活和任意深度的矩形和树网络。有趣的是，在ReLU网络中，第四层创建代表训练数据关于自身的反射的特征。Lasso表示法揭示了全局最优网络和解空间的洞察。

    arXiv:2403.01046v1 Announce Type: cross  Abstract: We prove that training neural networks on 1-D data is equivalent to solving a convex Lasso problem with a fixed, explicitly defined dictionary matrix of features. The specific dictionary depends on the activation and depth. We consider 2-layer networks with piecewise linear activations, deep narrow ReLU networks with up to 4 layers, and rectangular and tree networks with sign activation and arbitrary depth. Interestingly in ReLU networks, a fourth layer creates features that represent reflections of training data about themselves. The Lasso representation sheds insight to globally optimal networks and the solution landscape.
    
[^142]: AutoAttacker: 一种大型语言模型引导系统，用于实现自动网络攻击

    AutoAttacker: A Large Language Model Guided System to Implement Automatic Cyber-attacks

    [https://arxiv.org/abs/2403.01038](https://arxiv.org/abs/2403.01038)

    大型语言模型有望自动化攻击的先前和后续阶段，这可能会将组织性攻击从罕见的专家主导事件转变为频繁的自动化操作，不需要专业知识，并以自动化速度和规模进行执行，这可能从根本上改变全球计算机安全。

    

    大型语言模型（LLMs）在自然语言任务上展现出令人印象深刻的结果，安全研究人员开始在进攻和防御系统中使用它们。在网络安全领域，已经有多个研究致力于利用LLMs专注于攻击的预入侵阶段，例如钓鱼和恶意软件生成。然而，迄今为止还缺乏关于LLM模型是否可以被利用来模拟通常由人类操作的攻击的攻击后阶段，或者是“手动输入”的攻击，以及针对不同攻击技术和环境的综合研究。

    arXiv:2403.01038v1 Announce Type: cross  Abstract: Large language models (LLMs) have demonstrated impressive results on natural language tasks, and security researchers are beginning to employ them in both offensive and defensive systems. In cyber-security, there have been multiple research efforts that utilize LLMs focusing on the pre-breach stage of attacks like phishing and malware generation. However, so far there lacks a comprehensive study regarding whether LLM-based systems can be leveraged to simulate the post-breach stage of attacks that are typically human-operated, or "hands-on-keyboard" attacks, under various attack techniques and environments.   As LLMs inevitably advance, they may be able to automate both the pre- and post-breach attack stages. This shift may transform organizational attacks from rare, expert-led events to frequent, automated operations requiring no expertise and executed at automation speed and scale. This risks fundamentally changing global computer sec
    
[^143]: 孔雀：一系列阿拉伯多模式大语言模型及基准

    Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks

    [https://arxiv.org/abs/2403.01031](https://arxiv.org/abs/2403.01031)

    介绍了一系列阿拉伯多模式大语言模型Peacock，展示了其在视觉推理任务上的出色性能和不断出现的方言潜力，并提出了一个用于评估阿拉伯语相关方面的新基准Henna

    

    多模式大语言模型（MLLMs）在需要复杂推理和语言理解的各种任务中已被证明有效。然而，由于除英语以外的其他语言缺乏高质量的多模式资源，MLLMs的成功仍然相对局限于英语环境。这给开发其他语言的可比较模型带来了重大挑战，甚至包括那些拥有庞大说话人口的语言，如阿拉伯语。为了缓解这一挑战，我们引入了一套综合的阿拉伯MLLMs系列，称为\textit{Peacock}，具有强大的视觉和语言能力。通过全面的定性和定量分析，我们展示了我们的模型在各种视觉推理任务上的出色性能，并进一步展示了它们不断出现的方言潜力。此外，我们还介绍了一个名为\textit{Henna}的新基准，专门用于评估MLLM在与阿拉伯语相关的方面。

    arXiv:2403.01031v1 Announce Type: cross  Abstract: Multimodal large language models (MLLMs) have proven effective in a wide range of tasks requiring complex reasoning and linguistic comprehension. However, due to a lack of high-quality multimodal resources in languages other than English, success of MLLMs remains relatively limited to English-based settings. This poses significant challenges in developing comparable models for other languages, including even those with large speaker populations such as Arabic. To alleviate this challenge, we introduce a comprehensive family of Arabic MLLMs, dubbed \textit{Peacock}, with strong vision and language capabilities. Through comprehensive qualitative and quantitative analysis, we demonstrate the solid performance of our models on various visual reasoning tasks and further show their emerging dialectal potential. Additionally, we introduce ~\textit{Henna}, a new benchmark specifically designed for assessing MLLMs on aspects related to Arabic c
    
[^144]: 利用测量控制的量子动力学的水库计算

    Reservoir Computing Using Measurement-Controlled Quantum Dynamics

    [https://arxiv.org/abs/2403.01024](https://arxiv.org/abs/2403.01024)

    该研究介绍了一种利用测量控制的量子动力学的水库计算系统，相较于传统的水库计算算法，它可以使用少量人工神经元实现快速可靠的预测，有潜力在容错应用中使用。

    

    物理水库计算（RC）是一种机器学习算法，利用物理系统的动力学来预测高度非线性和混沌现象。本文介绍了一种利用腔中被探测原子的动力学的量子RC系统。原子以特定速率经历相干驱动，导致测量控制的量子演化。所提出的量子水库可以使用较少数量的人工神经元进行快速和可靠的预测，与传统RC算法相比。我们在理论上验证了水库的运作，展示了它在容错应用中的潜力，其中近似计算方法可用于在有限的计算和能源资源条件下进行可行的预测。

    arXiv:2403.01024v1 Announce Type: cross  Abstract: Physical reservoir computing (RC) is a machine learning algorithm that employs the dynamics of a physical system to forecast highly nonlinear and chaotic phenomena. In this paper, we introduce a quantum RC system that employs the dynamics of a probed atom in a cavity. The atom experiences coherent driving at a particular rate, leading to a measurement-controlled quantum evolution. The proposed quantum reservoir can make fast and reliable forecasts using a small number of artificial neurons compared with the traditional RC algorithm. We theoretically validate the operation of the reservoir, demonstrating its potential to be used in error-tolerant applications, where approximate computing approaches may be used to make feasible forecasts in conditions of limited computational and energy resources.
    
[^145]: 具有热启动的PDE控制策略优化

    Policy Optimization for PDE Control with a Warm Start

    [https://arxiv.org/abs/2403.01005](https://arxiv.org/abs/2403.01005)

    通过在减少-然后设计过程中增加策略优化步骤，来微调模型-based 控制器以补偿维度约简引起的建模错误，并将整体策略转变为减少-然后设计-然后适应的PDE控制方法。

    

    维度约简对通过“减少-然后设计”策略控制非线性偏微分方程（PDE）至关重要，该策略确定降阶模型然后实施基于模型的控制解决方案。然而，降阶建模的不准确性可能会严重降低控制器的性能，尤其是在具有混沌行为的PDE中。为了解决这个问题，我们在减少-然后设计过程中增加了一个策略优化（PO）步骤。PO步骤微调基于模型的控制器，以补偿由维度约简引起的建模误差。这种增强将整体策略转变为减少-然后设计-然后调整，其中基于模型的控制器作为PO的热启动。具体来说，我们研究了旨在将PDE状态与特定恒定目标对齐的PDE状态反馈跟踪控制，受线性二次成本约束。通过大量实验，我们展示

    arXiv:2403.01005v1 Announce Type: cross  Abstract: Dimensionality reduction is crucial for controlling nonlinear partial differential equations (PDE) through a "reduce-then-design" strategy, which identifies a reduced-order model and then implements model-based control solutions. However, inaccuracies in the reduced-order modeling can substantially degrade controller performance, especially in PDEs with chaotic behavior. To address this issue, we augment the reduce-then-design procedure with a policy optimization (PO) step. The PO step fine-tunes the model-based controller to compensate for the modeling error from dimensionality reduction. This augmentation shifts the overall strategy into reduce-then-design-then-adapt, where the model-based controller serves as a warm start for PO. Specifically, we study the state-feedback tracking control of PDEs that aims to align the PDE state with a specific constant target subject to a linear-quadratic cost. Through extensive experiments, we show
    
[^146]: FlaKat: 一种基于机器学习的面向Flaky测试的分类框架

    FlaKat: A Machine Learning-Based Categorization Framework for Flaky Tests

    [https://arxiv.org/abs/2403.01003](https://arxiv.org/abs/2403.01003)

    提出了一种名为FlaKat的新型分类框架，利用机器学习分类器快速准确地预测flaky测试的类别，提出了一种衡量分类器准确性的新评估指标FDC。

    

    Flaky tests 是在不更改软件系统的情况下以不确定性的方式通过或失败的测试。开发人员经常遇到这些测试，它们影响了测试套件的可信度。最先进的研究将机器学习解决方案应用于flaky测试检测，并取得了相当不错的准确率。此外，大多数自动flaky测试修复解决方案都是针对特定类型的flaky测试设计的。这项研究提出了一种名为FlaKat的新型分类框架，使用机器学习分类器快速准确地预测给定flaky测试的类别，反映其根本原因。采样技术被应用于解决国际Flaky测试数据集（IDoFT）中flaky测试类别之间的不平衡问题。提出了一种称为Flakiness Detection Capacity（FDC）的新评估指标，用于从信息理论角度衡量分类器的准确性。

    arXiv:2403.01003v1 Announce Type: cross  Abstract: Flaky tests can pass or fail non-deterministically, without alterations to a software system. Such tests are frequently encountered by developers and hinder the credibility of test suites. State-of-the-art research incorporates machine learning solutions into flaky test detection and achieves reasonably good accuracy. Moreover, the majority of automated flaky test repair solutions are designed for specific types of flaky tests. This research work proposes a novel categorization framework, called FlaKat, which uses machine-learning classifiers for fast and accurate prediction of the category of a given flaky test that reflects its root cause. Sampling techniques are applied to address the imbalance between flaky test categories in the International Dataset of Flaky Test (IDoFT). A new evaluation metric, called Flakiness Detection Capacity (FDC), is proposed for measuring the accuracy of classifiers from the perspective of information th
    
[^147]: 属性结构化改进了基于LLM的临床文本摘要评估

    Attribute Structuring Improves LLM-Based Evaluation of Clinical Text Summaries

    [https://arxiv.org/abs/2403.01002](https://arxiv.org/abs/2403.01002)

    属性结构化框架显著改进了基于LLM的临床文本摘要评估过程，提高了人工评注和自动度量之间的一致性。

    

    在健康决策支持和临床研究中，总结临床文本至关重要。大型语言模型（LLMs）已经显示出生成准确的临床文本摘要的潜力，但仍然在与基础和评估相关的问题上存在困难，特别是在健康等安全关键领域。本文中，我们探讨了一种使用属性结构化（AS）作为通用缓解框架，该框架结构化了摘要评估过程。它将评估过程分解为一个基于LLM执行相对简单的结构化和评分任务，而不是完整的综合摘要评估任务。实验表明，AS始终改善了临床文本摘要中人类注释和自动度量之间的对应关系。此外，AS通过短文本形式提供了解释。

    arXiv:2403.01002v1 Announce Type: cross  Abstract: Summarizing clinical text is crucial in health decision-support and clinical research. Large language models (LLMs) have shown the potential to generate accurate clinical text summaries, but still struggle with issues regarding grounding and evaluation, especially in safety-critical domains such as health. Holistically evaluating text summaries is challenging because they may contain unsubstantiated information. Here, we explore a general mitigation framework using Attribute Structuring (AS), which structures the summary evaluation process. It decomposes the evaluation process into a grounded procedure that uses an LLM for relatively simple structuring and scoring tasks, rather than the full task of holistic summary evaluation. Experiments show that AS consistently improves the correspondence between human annotations and automated metrics in clinical text summarization. Additionally, AS yields interpretations in the form of a short te
    
[^148]: 利用基于提示的大语言模型：通过社交媒体语言预测流行病健康决策和结果

    Leveraging Prompt-Based Large Language Models: Predicting Pandemic Health Decisions and Outcomes Through Social Media Language

    [https://arxiv.org/abs/2403.00994](https://arxiv.org/abs/2403.00994)

    该研究利用基于提示的大语言模型框架，研究了社交媒体语言模式与国家卫生趋势之间的关系，首次实现了将社交媒体语言模式与现实公共卫生趋势相联系的方法。

    

    我们引入了一个多步推理框架，使用基于提示的LLMs来研究社交媒体语言模式与国家健康结果趋势之间的关系。基于模糊轨迹理论，强调健康沟通中因果一致性要义的重要性，我们引入了基于角色的渐进辅导（RBIC），一个基于提示的LLM框架，以大规模识别要义。使用RBIC，我们系统地从反对COVID-19健康措施的subreddit讨论中提取要义（研究1）。然后我们跟踪这些要义在关键事件中的演变（研究2），并评估它们对在线互动的影响（研究3）。最后，我们研究要义量如何与国家健康趋势（如疫苗接种率和住院率）相关联（研究4）。我们的工作首次从实证角度将社交媒体语言模式与现实世界公共卫生趋势联系起来，突显了基于提示的潜力。

    arXiv:2403.00994v1 Announce Type: cross  Abstract: We introduce a multi-step reasoning framework using prompt-based LLMs to examine the relationship between social media language patterns and trends in national health outcomes. Grounded in fuzzy-trace theory, which emphasizes the importance of gists of causal coherence in effective health communication, we introduce Role-Based Incremental Coaching (RBIC), a prompt-based LLM framework, to identify gists at-scale. Using RBIC, we systematically extract gists from subreddit discussions opposing COVID-19 health measures (Study 1). We then track how these gists evolve across key events (Study 2) and assess their influence on online engagement (Study 3). Finally, we investigate how the volume of gists is associated with national health trends like vaccine uptake and hospitalizations (Study 4). Our work is the first to empirically link social media linguistic patterns to real-world public health trends, highlighting the potential of prompt-bas
    
[^149]: 论部分可观察序列团队和游戏中信息结构在强化学习中的作用

    On the Role of Information Structure in Reinforcement Learning for Partially-Observable Sequential Teams and Games

    [https://arxiv.org/abs/2403.00993](https://arxiv.org/abs/2403.00993)

    明确表示信息结构是分析和解决强化学习问题的重要组成部分。

    

    在顺序决策问题中，信息结构描述了系统中不同时刻事件如何相互影响。本文主张明确表示信息结构是分析和解决强化学习问题的重要组成部分，并提出具有明确信息结构表示的新型强化学习模型。

    arXiv:2403.00993v1 Announce Type: cross  Abstract: In a sequential decision-making problem, the information structure is the description of how events in the system occurring at different points in time affect each other. Classical models of reinforcement learning (e.g., MDPs, POMDPs, Dec-POMDPs, and POMGs) assume a very simple and highly regular information structure, while more general models like predictive state representations do not explicitly model the information structure. By contrast, real-world sequential decision-making problems typically involve a complex and time-varying interdependence of system variables, requiring a rich and flexible representation of information structure.   In this paper, we argue for the perspective that explicit representation of information structures is an important component of analyzing and solving reinforcement learning problems. We propose novel reinforcement learning models with an explicit representation of information structure, capturing 
    
[^150]: 合并来自不同初始化的文本变换器模型

    Merging Text Transformer Models from Different Initializations

    [https://arxiv.org/abs/2403.00986](https://arxiv.org/abs/2403.00986)

    研究了合并不同初始化的Transformer模型的技术，提出了一种模型合并技术以研究这些模型极小值之间的关系，并发现与模型平均相比，通过我们的方法合并这些模型始终可以获得较低的损失障碍。

    

    最近关于一次性基于排列的模型合并的工作表明，不同初始化的模型之间存在令人印象深刻的低或零障碍模连接。然而，尽管Transformer架构在语言领域中占主导地位，但这一领域的研究尚未延伸到Transformer架构。因此，在这项工作中，我们调查了独立Transformer极小值学习类似特征的程度，并提出了一种模型合并技术，以研究损失景观中这些极小值之间的关系。架构的具体细节，如其残差连接、多头注意力和离散的顺序输入，需要特定的干预措施，以便计算留在相同功能等价类中的模型排列。通过我们的方法合并这些模型，我们发现与对几个在一个maske上训练的模型进行模型平均相比，最小值之间的损失障碍一直较低。

    arXiv:2403.00986v1 Announce Type: cross  Abstract: Recent work on one-shot permutation-based model merging has shown impressive low- or zero-barrier mode connectivity between models from completely different initializations. However, this line of work has not yet extended to the Transformer architecture, despite its dominant popularity in the language domain. Therefore, in this work, we investigate the extent to which separate Transformer minima learn similar features, and propose a model merging technique to investigate the relationship between these minima in the loss landscape. The specifics of the architecture, like its residual connections, multi-headed attention, and discrete, sequential input, require specific interventions in order to compute model permutations that remain within the same functional equivalence class. In merging these models with our method, we consistently find lower loss barriers between minima compared to model averaging for several models trained on a maske
    
[^151]: 从“只要”到“即使”：是否通过反事实指导最佳半事实解释？

    Even-Ifs From If-Onlys: Are the Best Semi-Factual Explanations Found Using Counterfactuals As Guides?

    [https://arxiv.org/abs/2403.00980](https://arxiv.org/abs/2403.00980)

    这里是中文总结出的一句话要点：研究对8种半事实方法进行了全面测试，发现反事实指导并非必要，而是... (由于篇幅限制，若有省略，请见谅)

    

    最近，“只要”解释中的反事实在可解释人工智能（eXplainable AI，XAI）领域变得非常流行，因为它们描述了对黑盒AI系统的特征输入进行哪些更改会导致（通常是负面的）决策结果的变化。更近期，使用“即使”解释的半事实方法引起了更多关注。它们阐明了对AI系统的特征输入进行的更改不会改变决策结果，从而可能提出更有利的行动建议。一些半事实方法使用反事实来引导查询实例以指导半事实生成（称为反事实引导方法），而其他方法则不这样做（称为无反事实方法）。在这项工作中，我们对7个数据集上的8种半事实方法进行了全面测试，使用了5个关键指标，以确定反事实指导是否有必要找到最佳的半事实。这些测试的结果表明并不是，而是...

    arXiv:2403.00980v1 Announce Type: new  Abstract: Recently, counterfactuals using "if-only" explanations have become very popular in eXplainable AI (XAI), as they describe which changes to feature-inputs of a black-box AI system result in changes to a (usually negative) decision-outcome. Even more recently, semi-factuals using "even-if" explanations have gained more attention. They elucidate the feature-input changes that do \textit{not} change the decision-outcome of the AI system, with a potential to suggest more beneficial recourses. Some semi-factual methods use counterfactuals to the query-instance to guide semi-factual production (so-called counterfactual-guided methods), whereas others do not (so-called counterfactual-free methods). In this work, we perform comprehensive tests of 8 semi-factual methods on 7 datasets using 5 key metrics, to determine whether counterfactual guidance is necessary to find the best semi-factuals. The results of these tests suggests not, but rather tha
    
[^152]: 风力发电机性能的时间序列分析设备健康评估

    Equipment Health Assessment: Time Series Analysis for Wind Turbine Performance

    [https://arxiv.org/abs/2403.00975](https://arxiv.org/abs/2403.00975)

    利用功能神经网络（FNN）和长短期记忆（LSTM）网络的集成方法来预测风力发电机功率输出，实现准确稳定的预测并检测性能恶化，以推动积极的维护策略和健康评估。

    

    在这项研究中，我们利用来自不同风力发电机的SCADA数据，使用先进的时间序列方法，特别是功能神经网络（FNN）和长短期记忆（LSTM）网络来预测功率输出。关键创新在于FNN和LSTM模型的集成，利用它们的集体学习。这种集成方法胜过单个模型，确保稳定和准确的功率输出预测。此外，机器学习技术用于检测风力发电机性能恶化，实现积极的维护策略和健康评估。关键是，我们的分析揭示了每台风力发电机的独特性，需要为最佳预测定制模型。这些见解强调提供不同发电机自动化定制的重要性，以保持人力建模工作量低。重要的是，本分析中开发的方法不局限于风力发电机。

    arXiv:2403.00975v1 Announce Type: cross  Abstract: In this study, we leverage SCADA data from diverse wind turbines to predict power output, employing advanced time series methods, specifically Functional Neural Networks (FNN) and Long Short-Term Memory (LSTM) networks. A key innovation lies in the ensemble of FNN and LSTM models, capitalizing on their collective learning. This ensemble approach outperforms individual models, ensuring stable and accurate power output predictions. Additionally, machine learning techniques are applied to detect wind turbine performance deterioration, enabling proactive maintenance strategies and health assessment. Crucially, our analysis reveals the uniqueness of each wind turbine, necessitating tailored models for optimal predictions. These insight underscores the importance of providing automatized customization for different turbines to keep human modeling effort low. Importantly, the methodologies developed in this analysis are not limited to wind tu
    
[^153]: 二值高斯Copula合成：一种新的数据增强技术，用于推进基于机器学习的临床决策支持系统，旨在早期预测慢性肾病患者的透析需求

    Binary Gaussian Copula Synthesis: A Novel Data Augmentation Technique to Advance ML-based Clinical Decision Support Systems for Early Prediction of Dialysis Among CKD Patients

    [https://arxiv.org/abs/2403.00965](https://arxiv.org/abs/2403.00965)

    提出了一种新的数据增强技术 Binary Gaussian Copula Synthesis (BGCS)，用于解决基于机器学习的临床决策支持系统在早期预测慢性肾病患者透析需求中所面临的数据不平衡问题

    

    谷歌学术：2403.00965v1  公告类型：跨界  摘要：美国疾病控制中心估计，超过3700万成年美国人患有慢性肾病（CKD），然而其中的9成患者由于早期没有症状而不知道自己的状况。早期预测透析需求至关重要，因为这可以显著改善患者预后，并帮助医疗提供者及时做出知情决策。然而，开发有效的基于机器学习（ML）的早期透析预测临床决策支持系统（CDSS）面临关键挑战，即数据的不平衡性。为了解决这一挑战，本研究评估了各种数据增强技术，以了解它们在现实世界数据集上的有效性。我们提出了一种名为二值高斯Copula合成（BGCS）的新方法，该方法针对二进制数据进行了优化。

    arXiv:2403.00965v1 Announce Type: cross  Abstract: The Center for Disease Control estimates that over 37 million US adults suffer from chronic kidney disease (CKD), yet 9 out of 10 of these individuals are unaware of their condition due to the absence of symptoms in the early stages. It has a significant impact on patients' quality of life, particularly when it progresses to the need for dialysis. Early prediction of dialysis is crucial as it can significantly improve patient outcomes and assist healthcare providers in making timely and informed decisions. However, developing an effective machine learning (ML)-based Clinical Decision Support System (CDSS) for early dialysis prediction poses a key challenge due to the imbalanced nature of data. To address this challenge, this study evaluates various data augmentation techniques to understand their effectiveness on real-world datasets. We propose a new approach named Binary Gaussian Copula Synthesis (BGCS). BGCS is tailored for binary me
    
[^154]: AutoRD：一种基于本体增强的大型语言模型的罕见疾病知识图构建的自动化端到端系统

    AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models

    [https://arxiv.org/abs/2403.00953](https://arxiv.org/abs/2403.00953)

    AutoRD是一个自动化端到端系统，使用大型语言模型和医学知识图构建罕见疾病知识图，实现了整体F1得分47.3%，相对于基础LLM有14.4%的提升。

    

    目标：我们的目标是创建一个名为AutoRD的端到端系统，该系统自动从临床文本中提取有关罕见疾病的信息。我们进行了各种测试来评估AutoRD的性能，并在本文中强调了其优势和局限性。方法：我们的系统AutoRD是一个软件流水线，涉及数据预处理、实体提取、关系提取、实体校准和知识图构建。我们使用大型语言模型和由开源医学本体发展而来的医学知识图来实现这一目标。我们通过实体提取、关系提取以及知识图构建性能对系统进行定量评估。结果：AutoRD取得了47.3%的整体F1分数，较基础LLM提高了14.4%。具体来说，AutoRD实现了56.1%的整体实体提取F1分数（罕见疾病：83.5%，疾病：35.8%，s

    arXiv:2403.00953v1 Announce Type: cross  Abstract: Objectives: Our objective is to create an end-to-end system called AutoRD, which automates extracting information from clinical text about rare diseases. We have conducted various tests to evaluate the performance of AutoRD and highlighted its strengths and limitations in this paper.   Materials and Methods: Our system, AutoRD, is a software pipeline involving data preprocessing, entity extraction, relation extraction, entity calibration, and knowledge graph construction. We implement this using large language models and medical knowledge graphs developed from open-source medical ontologies. We quantitatively evaluate our system on entity extraction, relation extraction, and the performance of knowledge graph construction.   Results: AutoRD achieves an overall F1 score of 47.3%, a 14.4% improvement compared to the base LLM. In detail, AutoRD achieves an overall entity extraction F1 score of 56.1% (rare_disease: 83.5%, disease: 35.8%, s
    
[^155]: 分布式神经网络中熵模型的韧性

    Resilience of Entropy Model in Distributed Neural Networks

    [https://arxiv.org/abs/2403.00942](https://arxiv.org/abs/2403.00942)

    本文研究了分布式神经网络中熵模型对有意干扰和无意干扰的韧性，通过实验证明了熵模型的韧性。

    

    分布式深度神经网络（DNNs）已经成为边缘计算系统中减少通信开销而不降低性能的关键技术。最近，熵编码被引入以进一步减少通信开销。其关键思想是将分布式DNN与熵模型联合训练，该模型在推断时间用作边信息，以自适应地将潜在表示编码为具有可变长度的比特流。据我们所知，熵模型的韧性尚未得到研究。因此，在本文中，我们制定并调查了熵模型对有意干扰（例如，对抗性攻击）和无意干扰（例如，天气变化和运动模糊）的韧性。通过对3种不同DNN架构、2个熵模型和4个速率失真权衡因子进行广泛的实验，我们证明了熵模型的韧性

    arXiv:2403.00942v1 Announce Type: cross  Abstract: Distributed deep neural networks (DNNs) have emerged as a key technique to reduce communication overhead without sacrificing performance in edge computing systems. Recently, entropy coding has been introduced to further reduce the communication overhead. The key idea is to train the distributed DNN jointly with an entropy model, which is used as side information during inference time to adaptively encode latent representations into bit streams with variable length. To the best of our knowledge, the resilience of entropy models is yet to be investigated. As such, in this paper we formulate and investigate the resilience of entropy models to intentional interference (e.g., adversarial attacks) and unintentional interference (e.g., weather changes and motion blur). Through an extensive experimental campaign with 3 different DNN architectures, 2 entropy models and 4 rate-distortion trade-off factors, we demonstrate that the entropy attacks
    
[^156]: 无尺度对抗性强化学习

    Scale-free Adversarial Reinforcement Learning

    [https://arxiv.org/abs/2403.00930](https://arxiv.org/abs/2403.00930)

    本文在马尔可夫决策过程中提出了首个无尺度对抗性学习算法框架SCB，在对抗性多臂赌博机和MDP设置中取得了关键突破。

    

    本文首次研究了马尔可夫决策过程（MDPs）中的无尺度学习，其奖励/损失的尺度为学习者所不知。我们设计了一个通用的算法框架，\underline{S}cale \underline{C}lipping \underline{B}ound（\texttt{SCB}），并将这一框架实例化到对抗性多臂赌博机（MAB）设置和对抗性MDP设置中。通过这个框架，在无尺度对抗性MABs中，我们实现了第一个最小值最优期望遗憾界和第一个高概率遗憾界，解决了\cite{hadiji2023adaptation}中提出的一个开放问题。在对抗性MDPs中，我们的框架还诞生了第一个带有$\tilde{\mathcal{O}}(\sqrt{T})$高概率遗憾保证的无尺度RL算法。

    arXiv:2403.00930v1 Announce Type: cross  Abstract: This paper initiates the study of scale-free learning in Markov Decision Processes (MDPs), where the scale of rewards/losses is unknown to the learner. We design a generic algorithmic framework, \underline{S}cale \underline{C}lipping \underline{B}ound (\texttt{SCB}), and instantiate this framework in both the adversarial Multi-armed Bandit (MAB) setting and the adversarial MDP setting. Through this framework, we achieve the first minimax optimal expected regret bound and the first high-probability regret bound in scale-free adversarial MABs, resolving an open problem raised in \cite{hadiji2023adaptation}. On adversarial MDPs, our framework also give birth to the first scale-free RL algorithm with a $\tilde{\mathcal{O}}(\sqrt{T})$ high-probability regret guarantee.
    
[^157]: 利用行为原语搭建任务的框架以提高数据效率的模仿学习

    PRIME: Scaffolding Manipulation Tasks with Behavior Primitives for Data-Efficient Imitation Learning

    [https://arxiv.org/abs/2403.00929](https://arxiv.org/abs/2403.00929)

    PRIME是一个基于行为原语设计的框架，通过将任务分解为原语序列并学习高级控制策略，显著提高了多阶段操作任务的性能表现。

    

    模仿学习已经显示出巨大潜力，可以让机器人学会复杂的操作行为。然而，在长期任务中，这些算法受到高样本复杂度的困扰，因为复合误差会在任务时段内累积。我们提出了PRIME（基于行为原语的数据效率模仿），这是一个基于行为原语的框架，旨在提高模仿学习的数据效率。PRIME通过将任务演示分解为原语序列来搭建机器人任务，然后通过模仿学习学习一个高级控制策略来对原语序列进行排序。我们的实验证明，PRIME在多阶段操作任务中实现了显著的性能提升，在模拟环境中的成功率比最先进的基线高出10-34％，在实际硬件上高出20-48％。

    arXiv:2403.00929v1 Announce Type: cross  Abstract: Imitation learning has shown great potential for enabling robots to acquire complex manipulation behaviors. However, these algorithms suffer from high sample complexity in long-horizon tasks, where compounding errors accumulate over the task horizons. We present PRIME (PRimitive-based IMitation with data Efficiency), a behavior primitive-based framework designed for improving the data efficiency of imitation learning. PRIME scaffolds robot tasks by decomposing task demonstrations into primitive sequences, followed by learning a high-level control policy to sequence primitives through imitation learning. Our experiments demonstrate that PRIME achieves a significant performance improvement in multi-stage manipulation tasks, with 10-34% higher success rates in simulation over state-of-the-art baselines and 20-48% on physical hardware.
    
[^158]: 算法配置问题

    The Algorithm Configuration Problem

    [https://arxiv.org/abs/2403.00898](https://arxiv.org/abs/2403.00898)

    本文深入研究了算法配置问题，提出了一个全面框架，结合机器学习模型和启发式策略，划分了不同的解决方法，以明确路径来理解和解决算法配置中的复杂性。

    

    算法优化领域随着自动配置算法参数方法的发展而显著进步。本文深入探讨了算法配置问题，旨在优化用于解决特定决策/优化问题实例的参数化算法。我们提出了一个全面的框架，不仅形式化了算法配置问题，还概述了利用机器学习模型和启发式策略解决该问题的不同方法。该文章将现有方法论划分为基于实例和基于问题的方法，区分离线和在线策略用于模型构建和部署。通过综合这些方法，我们旨在为理解和解决算法配置中固有复杂性提供清晰的路径。

    arXiv:2403.00898v1 Announce Type: new  Abstract: The field of algorithmic optimization has significantly advanced with the development of methods for the automatic configuration of algorithmic parameters. This article delves into the Algorithm Configuration Problem, focused on optimizing parametrized algorithms for solving specific instances of decision/optimization problems. We present a comprehensive framework that not only formalizes the Algorithm Configuration Problem, but also outlines different approaches for its resolution, leveraging machine learning models and heuristic strategies. The article categorizes existing methodologies into per-instance and per-problem approaches, distinguishing between offline and online strategies for model construction and deployment. By synthesizing these approaches, we aim to provide a clear pathway for both understanding and addressing the complexities inherent in algorithm configuration.
    
[^159]: VisRec:一种用于射电干涉数据重建的半监督方法

    VisRec: A Semi-Supervised Approach to Radio Interferometric Data Reconstruction

    [https://arxiv.org/abs/2403.00897](https://arxiv.org/abs/2403.00897)

    VisRec提出了一种模型-不可知的半监督学习方法，用于重建射电干扰数据，通过监督学习模块和无监督学习模块相结合，减少了对标记训练数据的需求，降低了射电天文学家的标注工作量

    

    射电望远镜产生关于天体对象的可见性数据，但这些数据稀疏且嘈杂。因此，基于原始可见性数据创建的图像质量较低。最近的研究使用深度学习模型重建可见性数据，以获得更清晰的图像。然而，这些方法依赖大量标记的训练数据，这需要射电天文学家大量的标注工作。针对这一挑战，我们提出了VisRec，一种面向模型的半监督学习方法，用于重建可见性数据。具体来说，VisRec包括监督学习模块和无监督学习模块。在监督学习模块中，我们引入一组数据增强函数来产生多样化的训练示例。相比之下，在VisRec中的无监督学习模块会增加未标记的数据，并使用来自非增强可见性数据的重建作为伪标签。

    arXiv:2403.00897v1 Announce Type: cross  Abstract: Radio telescopes produce visibility data about celestial objects, but these data are sparse and noisy. As a result, images created on raw visibility data are of low quality. Recent studies have used deep learning models to reconstruct visibility data to get cleaner images. However, these methods rely on a substantial amount of labeled training data, which requires significant labeling effort from radio astronomers. Addressing this challenge, we propose VisRec, a model-agnostic semi-supervised learning approach to the reconstruction of visibility data. Specifically, VisRec consists of both a supervised learning module and an unsupervised learning module. In the supervised learning module, we introduce a set of data augmentation functions to produce diverse training examples. In comparison, the unsupervised learning module in VisRec augments unlabeled data and uses reconstructions from non-augmented visibility data as pseudo-labels for t
    
[^160]: DiaHalu：大型语言模型的对话级幻觉评估基准

    DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models

    [https://arxiv.org/abs/2403.00896](https://arxiv.org/abs/2403.00896)

    DiaHalu是第一个对话级幻觉评估基准，针对大型语言模型在对话级别上的幻觉问题进行研究。

    

    自从最近几年大型语言模型（LLMs）取得了显著成功，幻觉问题仍然是一个挑战，有许多基准被提出来检测这种幻觉。然而，其中一些基准不是由LLMs自然生成的，而是有意引发的。此外，许多基准仅关注事实上的幻觉，而忽视了忠实度的幻觉。此外，尽管在LLMs时代对话模式被广泛应用，但目前的基准仅集中在句子级和段落级的幻觉上。在这项研究中，我们提出 DiaHalu，这是我们所知的第一个对话级幻觉评估基准。首先，我们将收集的主题集成到系统提示中，促进两个ChatGPT3.5之间的对话。随后，我们手动修改不符合人类语言约定的内容，然后让LLMs重新生成，模拟真实的人类-

    arXiv:2403.00896v1 Announce Type: cross  Abstract: Since large language models (LLMs) achieve significant success in recent years, the hallucination issue remains a challenge, numerous benchmarks are proposed to detect the hallucination. Nevertheless, some of these benchmarks are not naturally generated by LLMs but are intentionally induced. Also, many merely focus on the factuality hallucination while ignoring the faithfulness hallucination. Additionally, although dialogue pattern is more widely utilized in the era of LLMs, current benchmarks only concentrate on sentence-level and passage-level hallucination. In this study, we propose DiaHalu, the first dialogue-level hallucination evaluation benchmark to our knowledge. Initially, we integrate the collected topics into system prompts and facilitate a dialogue between two ChatGPT3.5. Subsequently, we manually modify the contents that do not adhere to human language conventions and then have LLMs re-generate, simulating authentic human-
    
[^161]: 精确推荐的端到端图-序列表示学习

    End-to-end Graph-Sequential Representation Learning for Accurate Recommendations

    [https://arxiv.org/abs/2403.00895](https://arxiv.org/abs/2403.00895)

    本文提出了一个新颖的多重表示学习框架，有效地结合了基于序列和基于图的推荐方法，显著改善了推荐性能。

    

    近年来推荐系统的许多新进展集中在开发基于序列和基于图的方法上。这两种方法在建模行为数据中的复杂关系方面都证明了其有效性，从而在个性化排名和下一个推荐任务中取得了有益的成果，同时保持了良好的可扩展性。然而，它们从数据中捕捉到的信号截然不同。前者直接通过与最近物品的有序交互来表示用户，而后者旨在捕捉交互图中的间接依赖关系。本文提出了一个新颖的多重表示学习框架，利用这两种范式之间的协同作用。我们在几个数据集上的实证评估表明，利用所提出的框架相互训练序列和图组件显著改善了推荐性能。

    arXiv:2403.00895v1 Announce Type: cross  Abstract: Many recent advancements in recommender systems have focused on developing sequence-based and graph-based approaches. Both approaches proved useful in modeling intricate relationships within behavioral data, leading to promising outcomes in personalized ranking and next-item recommendation tasks while maintaining good scalability. However, they capture very different signals from data. While the former approach represents users directly through ordered interactions with recent items, the latter one aims to capture indirect dependencies across the interactions graph. This paper presents a novel multi-representational learning framework that exploits the synergies between these two paradigms. Our empirical evaluation on several datasets demonstrates that mutual training of sequential and graph components with the proposed framework significantly improves recommendations performance.
    
[^162]: 对于生成编程代码的大型语言模型进行系统评估

    A systematic evaluation of large language models for generating programming code

    [https://arxiv.org/abs/2403.00894](https://arxiv.org/abs/2403.00894)

    GPT-4在生成编程代码方面表现优异，特别是在选择最佳提示策略时，超过了其他大型语言模型和85%的人类参与者。

    

    我们系统评估了七个大型语言模型在使用不同提示策略、编程语言和任务难度生成编程代码时的性能。GPT-4在很大程度上优于其他大型语言模型，包括Gemini Ultra和Claude 2。GPT-4的编码性能随不同提示策略而变化。在本研究中评估的大多数LeetCode和GeeksforGeeks编程比赛中，采用最佳提示策略的GPT-4胜过85%的人类参与者。此外，GPT-4表现出在不同编程语言之间翻译代码和从过去错误中学习的强大能力。由GPT-4生成的代码的计算效率与人类程序员相当。这些结果表明，GPT-4有潜力成为在编程代码生成和软件开发中的可靠助手。

    arXiv:2403.00894v1 Announce Type: cross  Abstract: We systematically evaluated the performance of seven large language models in generating programming code using various prompt strategies, programming languages, and task difficulties. GPT-4 substantially outperforms other large language models, including Gemini Ultra and Claude 2. The coding performance of GPT-4 varies considerably with different prompt strategies. In most LeetCode and GeeksforGeeks coding contests evaluated in this study, GPT-4 employing the optimal prompt strategy outperforms 85 percent of human participants. Additionally, GPT-4 demonstrates strong capabilities in translating code between different programming languages and in learning from past errors. The computational efficiency of the code generated by GPT-4 is comparable to that of human programmers. These results suggest that GPT-4 has the potential to serve as a reliable assistant in programming code generation and software development.
    
[^163]: 一种基于正则化的指导图解码器的信息抽取迁移学习方法

    A Regularization-based Transfer Learning Method for Information Extraction via Instructed Graph Decoder

    [https://arxiv.org/abs/2403.00891](https://arxiv.org/abs/2403.00891)

    提出了一种基于正则化的信息抽取迁移学习方法，通过指导图解码器实现数据集之间通用知识的迁移

    

    信息提取（IE）旨在从文本中提取复杂结构化信息。已为各种IE任务构建了大量数据集，导致耗时且劳动密集的数据标注。然而，大多数流行方法侧重于训练特定任务的模型，而不是明确对不同IE任务之间的通用知识进行建模。此外，相同短语可能在不同任务中具有不一致的标签，这对使用统一模型进行知识迁移构成了巨大挑战。在本研究中，我们提出了一种基于正则化的信息抽取（IE）的迁移学习方法，通过一个指导图解码器进行。具体而言，我们首先为所有著名IE任务的数据集构建一个指导池，然后提出一个指导图解码器，根据相应的指导将各种复杂结构均匀地解码为图。通过这种方式，与现有数据集共享的通用知识可以更好地用于迁移学习。

    arXiv:2403.00891v1 Announce Type: cross  Abstract: Information extraction (IE) aims to extract complex structured information from the text. Numerous datasets have been constructed for various IE tasks, leading to time-consuming and labor-intensive data annotations. Nevertheless, most prevailing methods focus on training task-specific models, while the common knowledge among different IE tasks is not explicitly modeled. Moreover, the same phrase may have inconsistent labels in different tasks, which poses a big challenge for knowledge transfer using a unified model. In this study, we propose a regularization-based transfer learning method for IE (TIE) via an instructed graph decoder. Specifically, we first construct an instruction pool for datasets from all well-known IE tasks, and then present an instructed graph decoder, which decodes various complex structures into a graph uniformly based on corresponding instructions. In this way, the common knowledge shared with existing datasets 
    
[^164]: 通过Wasserstein生成对抗网络使用数据增强改进Android恶意软件检测

    Improving Android Malware Detection Through Data Augmentation Using Wasserstein Generative Adversarial Networks

    [https://arxiv.org/abs/2403.00890](https://arxiv.org/abs/2403.00890)

    通过使用Wasserstein生成对抗网络生成的数据进行数据增强，该研究提出了一种利用卷积神经网络识别未知Android恶意软件应用程序的方法，并通过降低存储需求来改进Android恶意软件检测的效果。

    

    生成对抗网络（GANs）已经展示了它们在各种应用中的多功能性，包括数据增强和恶意软件检测。这项研究探讨了利用GAN生成的数据来训练一个用于检测Android恶意软件的模型的有效性。鉴于Android应用的存储需求相当大，该研究提出了一种使用GAN来合成表示数据的方法，从而降低存储需求。所提出的方法涉及创建从现有数据集中提取的特征的图像表示。然后，使用GAN模型生成由逼真的合成灰度图像组成的更广泛的数据集。随后，这个合成数据集被用来训练一个卷积神经网络（CNN），旨在识别以前看不到的Android恶意应用程序。该研究包括对当CNN在真实图像与GAN生成图像上进行训练时性能的比较分析。

    arXiv:2403.00890v1 Announce Type: cross  Abstract: Generative Adversarial Networks (GANs) have demonstrated their versatility across various applications, including data augmentation and malware detection. This research explores the effectiveness of utilizing GAN-generated data to train a model for the detection of Android malware. Given the considerable storage requirements of Android applications, the study proposes a method to synthetically represent data using GANs, thereby reducing storage demands. The proposed methodology involves creating image representations of features extracted from an existing dataset. A GAN model is then employed to generate a more extensive dataset consisting of realistic synthetic grayscale images. Subsequently, this synthetic dataset is utilized to train a Convolutional Neural Network (CNN) designed to identify previously unseen Android malware applications. The study includes a comparative analysis of the CNN's performance when trained on real images v
    
[^165]: SEGAA: 一种统一的方法来预测语音中的年龄、性别和情绪

    SEGAA: A Unified Approach to Predicting Age, Gender, and Emotion in Speech

    [https://arxiv.org/abs/2403.00887](https://arxiv.org/abs/2403.00887)

    本文提出了一种统一的方法来从语音中预测年龄、性别和情绪，通过深度学习模型探索了单一、多输出和顺序模型的比较，并提出了新颖的多输出学习架构。

    

    人类声音的解释在各种应用中都很重要。本研究探讨了从语音线索中预测年龄、性别和情绪，这是一个具有广泛应用的领域。声音分析技术的进展跨越各个领域，从改善客户互动到增强医疗保健和零售体验。辨识情绪有助于心理健康，而年龄和性别的检测在各种情境中至关重要。探索这些预测的深度学习模型涉及比较单一、多输出和顺序模型，这些模型在本文中得到了重点展示。寻找合适的数据提出了挑战，导致了CREMA-D和EMO-DB数据集的融合。以前的工作在个别预测方面表现出潜力，但有限的研究同时考虑了这三个变量。本文确定了个别模型方法中的缺陷，并倡导我们的新颖多输出学习架构Speech-based Emotion Gender。

    arXiv:2403.00887v1 Announce Type: cross  Abstract: The interpretation of human voices holds importance across various applications. This study ventures into predicting age, gender, and emotion from vocal cues, a field with vast applications. Voice analysis tech advancements span domains, from improving customer interactions to enhancing healthcare and retail experiences. Discerning emotions aids mental health, while age and gender detection are vital in various contexts. Exploring deep learning models for these predictions involves comparing single, multi-output, and sequential models highlighted in this paper. Sourcing suitable data posed challenges, resulting in the amalgamation of the CREMA-D and EMO-DB datasets. Prior work showed promise in individual predictions, but limited research considered all three variables simultaneously. This paper identifies flaws in an individual model approach and advocates for our novel multi-output learning architecture Speech-based Emotion Gender an
    
[^166]: 利用LLMs进行元数据丰富化的受控词汇列标题文本分类

    Text classification of column headers with a controlled vocabulary: leveraging LLMs for metadata enrichment

    [https://arxiv.org/abs/2403.00884](https://arxiv.org/abs/2403.00884)

    通过利用LLMs，我们提出了一种方法，使用ChatGPT-3.5、GoogleBard和GoogleGemini对列标题进行主题注释的元数据丰富化，研究它们在对领域特定主题进行分类的能力，并评估其内部一致性、机器对齐性和人机一致性。ChatGPT和GoogleGemini在内部一致性以及与人一致性方面优于GoogleBard。

    

    传统的数据集检索系统主要在元数据信息而非数据值上建立索引。因此主要依赖于手动注释和高质量的元数据，这些过程被认为是耗时且难以自动化的。我们提出了一种方法，利用三种大型语言模型（LLMs）支持对列标题进行主题注释的元数据丰富化：ChatGPT-3.5、GoogleBard和GoogleGemini。我们研究了LLMs基于受控词汇的领域特定主题对列标题进行分类的能力。我们通过评估LLMs的内部一致性、机器间对齐以及人机对主题分类任务的一致性来评估我们的方法。此外，我们还探讨了上下文信息（即数据集描述）对分类结果的影响。我们的结果表明，ChatGPT和GoogleGemini在内部一致性以及LLM与人之间的一致性方面表现优于GoogleBard。

    arXiv:2403.00884v1 Announce Type: cross  Abstract: Traditional dataset retrieval systems index on metadata information rather than on the data values. Thus relying primarily on manual annotations and high-quality metadata, processes known to be labour-intensive and challenging to automate. We propose a method to support metadata enrichment with topic annotations of column headers using three Large Language Models (LLMs): ChatGPT-3.5, GoogleBard and GoogleGemini. We investigate the LLMs ability to classify column headers based on domain-specific topics from a controlled vocabulary. We evaluate our approach by assessing the internal consistency of the LLMs, the inter-machine alignment, and the human-machine agreement for the topic classification task. Additionally, we investigate the impact of contextual information (i.e. dataset description) on the classification outcomes. Our results suggest that ChatGPT and GoogleGemini outperform GoogleBard for internal consistency as well as LLM-hum
    
[^167]: 基于因果推断的双粒度药物推荐

    Dual-Granularity Medication Recommendation Based on Causal Inference

    [https://arxiv.org/abs/2403.00880](https://arxiv.org/abs/2403.00880)

    提出了DGMed框架，利用因果推断和创新的特征对齐方法进行双粒度药物推荐

    

    随着医疗需求增长和机器学习技术的进步，基于人工智能的诊断和治疗系统备受关注。药物推荐旨在将患者的长期健康记录与医学知识整合，为特定疾病推荐准确和安全的药物组合。然而，大多数现有研究将药物推荐系统仅视为传统推荐系统的变体，忽视了药物和疾病之间的异质性。为解决这一挑战，我们提出了DGMed，一个用于药物推荐的框架。DGMed利用因果推断揭示医学实体之间的联系，并提出了一种创新的特征对齐方法来解决异质性问题。具体而言，该研究首先应用因果推断分析历史记录中药物对特定疾病的量化治疗效果，揭示...

    arXiv:2403.00880v1 Announce Type: cross  Abstract: As medical demands grow and machine learning technology advances, AI-based diagnostic and treatment systems are garnering increasing attention. Medication recommendation aims to integrate patients' long-term health records with medical knowledge, recommending accuracy and safe medication combinations for specific conditions. However, most existing researches treat medication recommendation systems merely as variants of traditional recommendation systems, overlooking the heterogeneity between medications and diseases. To address this challenge, we propose DGMed, a framework for medication recommendation. DGMed utilizes causal inference to uncover the connections among medical entities and presents an innovative feature alignment method to tackle heterogeneity issues. Specifically, this study first applies causal inference to analyze the quantified therapeutic effects of medications on specific diseases from historical records, uncoverin
    
[^168]: Crimson: 通过大型语言模型增强网络安全领域的战略推理能力

    Crimson: Empowering Strategic Reasoning in Cybersecurity through Large Language Models

    [https://arxiv.org/abs/2403.00878](https://arxiv.org/abs/2403.00878)

    Crimson系统通过将CVE与MITRE ATT&CK技术相关联，提升了大型语言模型在网络安全中的战略推理能力，实现了接近GPT-4性能水平，且在战略推理任务中表现优异。

    

    我们介绍了Crimson，这是一个系统，通过将CVE与MITRE ATT&CK技术相关联，增强了大型语言模型（LLMs）在网络安全领域的战略推理能力。我们的方法包括定义和评估网络安全战略任务，以及实施全面的人机协作数据合成工作流程，以开发CVE到ATT&CK映射（CVEM）数据集。我们通过一种新颖的“检索感知训练”（RAT）过程及其改进的迭代RAT-R进一步提高了LLMs的推理能力。我们的研究结果表明，通过我们的技术对具有70亿参数的LLM进行微调，性能接近GPT-4，显示出幻觉和错误率明显降低，并在战略推理任务中超越其他模型。此外，对嵌入模型进行领域特定微调显著地提高了

    arXiv:2403.00878v1 Announce Type: cross  Abstract: We introduces Crimson, a system that enhances the strategic reasoning capabilities of Large Language Models (LLMs) within the realm of cybersecurity. By correlating CVEs with MITRE ATT&CK techniques, Crimson advances threat anticipation and strategic defense efforts. Our approach includes defining and evaluating cybersecurity strategic tasks, alongside implementing a comprehensive human-in-the-loop data-synthetic workflow to develop the CVE-to-ATT&CK Mapping (CVEM) dataset. We further enhance LLMs' reasoning abilities through a novel Retrieval-Aware Training (RAT) process and its refined iteration, RAT-R.   Our findings demonstrate that an LLM fine-tuned with our techniques, possessing 7 billion parameters, approaches the performance level of GPT-4, showing markedly lower rates of hallucination and errors, and surpassing other models in strategic reasoning tasks. Moreover, domain-specific fine-tuning of embedding models significantly i
    
[^169]: 词序与世界知识

    Word Order and World Knowledge

    [https://arxiv.org/abs/2403.00876](https://arxiv.org/abs/2403.00876)

    本研究探讨了词序如何影响语言模型从原始文本中归纳世界知识，发现一些固定词序在不同语言中表现更好或更差，而预训练语言模型中的Wov2Lex假设不成立。

    

    词序是自然语言中的一个重要概念，在这项工作中，我们研究了词序如何影响使用语言模型从原始文本中归纳世界知识。我们使用词类比来探究这种知识。具体来说，除了自然词序外，我们分别从五种语言中提取了六种固定词序的文本，并在这些文本上对语言模型进行了预训练。最后，我们分析了固定词序在词类比上的实验结果，表明某些固定词序在不同语言中始终表现出色或不佳，尽管具体情况因语言而异，以及ii）Wov2Lex假设在预训练语言模型中不成立，自然词序通常产生平庸的结果。源代码将公开在 https://github.com/lshowway/probing_by_analogy。

    arXiv:2403.00876v1 Announce Type: cross  Abstract: Word order is an important concept in natural language, and in this work, we study how word order affects the induction of world knowledge from raw text using language models. We use word analogies to probe for such knowledge. Specifically, in addition to the natural word order, we first respectively extract texts of six fixed word orders from five languages and then pretrain the language models on these texts. Finally, we analyze the experimental results of the fixed word orders on word analogies and show that i) certain fixed word orders consistently outperform or underperform others, though the specifics vary across languages, and ii) the Wov2Lex hypothesis is not hold in pre-trained language models, and the natural word order typically yields mediocre results. The source code will be made publicly available at https://github.com/lshowway/probing_by_analogy.
    
[^170]: 通过蛋白数据增强增强蛋白预测模型：基准和新方向

    Enhancing Protein Predictive Models via Proteins Data Augmentation: A Benchmark and New Directions

    [https://arxiv.org/abs/2403.00875](https://arxiv.org/abs/2403.00875)

    本文将图片和文本的数据增强技术扩展到蛋白领域，提出了两种新的蛋白语义级增强方法，并将这些增强方法集成到一个增强池中，构建了一个名为自动蛋白增强（APA）的简单而有效的框架。

    

    数据增强是利用少量标记蛋白数据的有效替代方法。然而，大多数现有工作侧重于设计新的架构或预训练任务，对于蛋白的数据增强研究相对较少。本文将先前用于图像和文本的数据增强技术扩展到蛋白，然后在各种与蛋白相关的任务上对这些技术进行基准测试，提供了对蛋白增强的首次全面评估。此外，我们提出两种新的语义级蛋白增强方法，即集成梯度替换和回译替换，通过显著性检测和生物知识实现蛋白语义感知增强。最后，我们将扩展和提出的增强集成到一个增强池中，并提出了一个简单但有效的框架，即自动蛋白增强（APA），可对蛋白进行自动增强。

    arXiv:2403.00875v1 Announce Type: cross  Abstract: Augmentation is an effective alternative to utilize the small amount of labeled protein data. However, most of the existing work focuses on design-ing new architectures or pre-training tasks, and relatively little work has studied data augmentation for proteins. This paper extends data augmentation techniques previously used for images and texts to proteins and then benchmarks these techniques on a variety of protein-related tasks, providing the first comprehensive evaluation of protein augmentation. Furthermore, we propose two novel semantic-level protein augmentation methods, namely Integrated Gradients Substitution and Back Translation Substitution, which enable protein semantic-aware augmentation through saliency detection and biological knowledge. Finally, we integrate extended and proposed augmentations into an augmentation pool and propose a simple but effective framework, namely Automated Protein Augmentation (APA), which can a
    
[^171]: DFIN-SQL：将精确模式与DIN-SQL集成，以提高大型数据库的准确性

    DFIN-SQL: Integrating Focused Schema with DIN-SQL for Superior Accuracy in Large-Scale Databases

    [https://arxiv.org/abs/2403.00872](https://arxiv.org/abs/2403.00872)

    DFIN-SQL是DIN-SQL的创新扩展，通过解决模式链接错误，提高了文本到SQL转换的准确性，并采用了提示技术和检索增强生成的交替策略。

    

    将自然语言查询转换为SQL查询的任务是复杂的，需要精确技术的结合以进行准确翻译。 DIN-SQL（上下文分解SQL）方法在这一领域取得了重大进展。 本文介绍了DFIN（分解聚焦上下文），这是DIN-SQL的创新扩展，通过解决模式链接错误来增强文本到SQL转换，这是不准确的主要来源。 DFIN独特地在提示技术和检索增强生成（RAG）之间交替，适应数据库模式的大小和复杂性。 预处理阶段嵌入数据库定义并利用类似BIRD数据集中的带注释文件，促进了运行时检索相关模式信息。 此策略显着减少了用于模式链接提示的令牌计数，从而使得可以在较大的语义模型GPT-4上使用标准模型。

    arXiv:2403.00872v1 Announce Type: cross  Abstract: The task of converting natural language queries into SQL queries is intricate, necessitating a blend of precise techniques for an accurate translation. The DIN-SQL (Decomposed-In-Context SQL) methodology represents a significant development in this domain. This paper introduces DFIN (Decomposed Focused-In-Context), an innovative extension of DIN-SQL that enhances Text-to-SQL conversion by addressing schema linking errors, which are a major source of inaccuracies. DFIN uniquely alternates between prompting techniques and Retrieval-Augmented Generation (RAG), adapting to the size and complexity of the database schema. A preprocessing phase embeds database definitions and leverages annotated files, akin to those in the BIRD dataset, facilitating the runtime retrieval of pertinent schema information. This strategy significantly reduces the token count for schema linking prompts, enabling the use of a standard GPT-4 model over its larger co
    
[^172]: 教会大型语言模型进行钓鱼：从语言模型中窃取私人信息

    Teach LLMs to Phish: Stealing Private Information from Language Models

    [https://arxiv.org/abs/2403.00871](https://arxiv.org/abs/2403.00871)

    本研究提出了一种名为“神经钓鱼”的新型实用数据提取攻击，使对手能够成功地从大型语言模型中提取敏感信息，攻击成功率高达10%至50%。

    

    当大型语言模型在私人数据上训练时，它们可能会将敏感信息记忆并重复。本研究提出了一种新的实用数据提取攻击，称为“神经钓鱼”。这种攻击使对手能够从一个在用户数据上训练的模型中成功率高达10%甚至50%地提取敏感或可识别个人身份的信息，例如信用卡号。攻击仅假设对手可以将少量看似良性的句子插入训练数据集，仅使用对用户数据结构的模糊先验知识。

    arXiv:2403.00871v1 Announce Type: cross  Abstract: When large language models are trained on private data, it can be a significant privacy risk for them to memorize and regurgitate sensitive information. In this work, we propose a new practical data extraction attack that we call "neural phishing". This attack enables an adversary to target and extract sensitive or personally identifiable information (PII), e.g., credit card numbers, from a model trained on user data with upwards of 10% attack success rates, at times, as high as 50%. Our attack assumes only that an adversary can insert as few as 10s of benign-appearing sentences into the training dataset using only vague priors on the structure of the user data.
    
[^173]: SoftTiger: 用于医疗工作流的临床基础模型

    SoftTiger: A Clinical Foundation Model for Healthcare Workflows

    [https://arxiv.org/abs/2403.00868](https://arxiv.org/abs/2403.00868)

    SoftTiger是一个专为医疗工作流设计的临床大型语言模型，通过处理临床笔记的结构化，实现了基本临床任务以及更复杂的下游临床任务的执行。

    

    我们发布并介绍了SoftTiger，一个专为医疗保健工作流设计的临床大型语言模型（CLaM）作为基础模型。临床笔记的叙述性和非结构化特性是医疗智能化的主要障碍。我们致力于按照国际互操作性标准将临床笔记结构化为临床数据，涉及国际患者摘要、临床印象和医疗接触三个关键子任务的数据收集和标注。然后，我们使用公开和验证的临床数据对最先进的LLM进行监督微调。训练过程中，目标模型首先能够支持基本的临床任务，如缩写扩展和时间信息提取，然后学习执行更复杂的下游临床任务，如印象和接触摘要。此外，我们解决了医疗模型中的一些建模挑战。

    arXiv:2403.00868v1 Announce Type: cross  Abstract: We release and introduce SoftTiger, a clinical large language model (CLaM) designed as a foundation model for healthcare workflows. The narrative and unstructured nature of clinical notes is a major obstacle for healthcare intelligentization. We address a critical problem of structuring clinical notes into clinical data, according to international interoperability standards. We collect and annotate data for three critical subtasks, namely, international patient summary, clinical impression and medical encounter. We then supervised fine-tuned a state-of-the-art LLM using public and credentialed clinical data. The training is orchestrated in a way that the target model can first support basic clinical tasks such as abbreviation expansion and temporal information extraction, and then learn to perform more complex downstream clinical tasks such as impression and encounter summary. Moreover, we address, several modeling challenges in the he
    
[^174]: 梯度被罚：通过探索拒绝损失地形图来检测针对大语言模型的越狱攻击

    Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes

    [https://arxiv.org/abs/2403.00867](https://arxiv.org/abs/2403.00867)

    本文提出了一种名为Gradient Cuff的方法，通过探索拒绝损失地形图来检测对大语言模型的越狱攻击，成功设计了一种有效的两步检测策略。

    

    大型语言模型（LLMs）正成为一种突出的生成式AI工具，用户输入查询，LLM生成答案。为了减少伤害和滥用，人们通过使用先进的训练技术如来自人类反馈的强化学习（RLHF）来将这些LLMs与人类价值观保持一致。然而，最近的研究突显了LLMs对于试图颠覆嵌入的安全防护措施的对抗性越狱尝试的脆弱性。为了解决这一挑战，本文定义并调查了LLMs的拒绝损失，然后提出了一种名为Gradient Cuff的方法来检测越狱尝试。Gradient Cuff利用拒绝损失地形图中观察到的独特特性，包括功能值及其光滑性，设计了一种有效的两步检测策略。

    arXiv:2403.00867v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are becoming a prominent generative AI tool, where the user enters a query and the LLM generates an answer. To reduce harm and misuse, efforts have been made to align these LLMs to human values using advanced training techniques such as Reinforcement Learning from Human Feedback (RLHF). However, recent studies have highlighted the vulnerability of LLMs to adversarial jailbreak attempts aiming at subverting the embedded safety guardrails. To address this challenge, this paper defines and investigates the Refusal Loss of LLMs and then proposes a method called Gradient Cuff to detect jailbreak attempts. Gradient Cuff exploits the unique properties observed in the refusal loss landscape, including functional values and its smoothness, to design an effective two-step detection strategy. Experimental results on two aligned LLMs (LLaMA-2-7B-Chat and Vicuna-7B-V1.5) and six types of jailbreak attacks (GCG, AutoDAN,
    
[^175]: 基于遗传编程的损失函数学习的快速高效局部搜索

    Fast and Efficient Local Search for Genetic Programming Based Loss Function Learning

    [https://arxiv.org/abs/2403.00865](https://arxiv.org/abs/2403.00865)

    提出了一种新的基于遗传编程的元学习框架，通过局部搜索方法实现了任务和模型无关的损失函数学习，实验证实了该框架在各种监督学习任务上的多样性和性能。

    

    在本文中，我们深入探讨了损失函数学习的话题，这是一种新兴的元学习范式，旨在学习能显著改善经过其训练的模型性能的损失函数。具体来说，我们提出了一种新的元学习框架，通过混合搜索方法实现了任务和模型无关的损失函数学习。该框架首先使用遗传编程找到一组符号损失函数。其次，学习到的损失函数集合随后通过展开的微分进行参数化和优化。所提出的框架的多样性和性能经过实证验证，用于各种监督学习任务。实验结果表明，学习到的损失函数在表格、计算机视觉和自然语言处理问题上带来了改善的收敛性、样本效率和推理性能，使用各种特定任务的神经网络架构。

    arXiv:2403.00865v1 Announce Type: cross  Abstract: In this paper, we develop upon the topic of loss function learning, an emergent meta-learning paradigm that aims to learn loss functions that significantly improve the performance of the models trained under them. Specifically, we propose a new meta-learning framework for task and model-agnostic loss function learning via a hybrid search approach. The framework first uses genetic programming to find a set of symbolic loss functions. Second, the set of learned loss functions is subsequently parameterized and optimized via unrolled differentiation. The versatility and performance of the proposed framework are empirically validated on a diverse set of supervised learning tasks. Results show that the learned loss functions bring improved convergence, sample efficiency, and inference performance on tabulated, computer vision, and natural language processing problems, using a variety of task-specific neural network architectures.
    
[^176]: LLM-Ensemble: 用于电子商务产品属性值提取的最佳大型语言模型集成方法

    LLM-Ensemble: Optimal Large Language Model Ensemble Method for E-commerce Product Attribute Value Extraction

    [https://arxiv.org/abs/2403.00863](https://arxiv.org/abs/2403.00863)

    提出了一种名为LLM-ensemble的算法，用于集成不同大型语言模型，以提高电子商务产品属性值提取的性能。

    

    arXiv:2403.00863v1 公告类型:跨领域摘要: 产品属性值提取是自然语言处理（NLP）和当代电子商务行业中至关重要的组成部分。提供精确的产品属性值在确保高质量推荐和提升客户满意度方面至关重要。最近出现的大型语言模型（LLMs）在许多属性提取任务中表现出最新技术水平，而无需进行领域特定的训练数据。然而，由于数据、架构和超参数的多样性，不同LLMs表现出不同的优势和劣势。这种变化使它们彼此互补，没有哪个LLM能完全压倒其他LLM。考虑到LLMs的多样优势和劣势，开发一种利用它们互补潜力的集成方法变得必要。在本文中，我们提出了一种名为LLM-ensemble的新算法，用于集成不同LLMs。

    arXiv:2403.00863v1 Announce Type: cross  Abstract: Product attribute value extraction is a pivotal component in Natural Language Processing (NLP) and the contemporary e-commerce industry. The provision of precise product attribute values is fundamental in ensuring high-quality recommendations and enhancing customer satisfaction. The recently emerging Large Language Models (LLMs) have demonstrated state-of-the-art performance in numerous attribute extraction tasks, without the need for domain-specific training data. Nevertheless, varying strengths and weaknesses are exhibited by different LLMs due to the diversity in data, architectures, and hyperparameters. This variation makes them complementary to each other, with no single LLM dominating all others. Considering the diverse strengths and weaknesses of LLMs, it becomes necessary to develop an ensemble method that leverages their complementary potentials. In this paper, we propose a novel algorithm called LLM-ensemble to ensemble diffe
    
[^177]: NewsBench：系统性评估LLM在中国新闻编辑应用中的写作水平和安全性遵从能力

    NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and Safety Adherence in Chinese Journalistic Editorial Applications

    [https://arxiv.org/abs/2403.00862](https://arxiv.org/abs/2403.00862)

    NewsBench是一个评估LLMs在中国新闻写作水平和安全性遵从能力的基准框架，揭示了在创造性写作任务中LLMs相对不足的新闻伦理遵守方面的需求。

    

    这项研究提出了NewsBench，这是一个新颖的基准框架，旨在评估大型语言模型（LLMs）在中国新闻写作水平（JWP）和安全性遵从（SA）方面的能力，弥补了新闻伦理与人工智能利用风险之间的差距。NewsBench包括5个编辑应用中的1,267项任务，7个方面（包括安全性和新闻写作，以及4个详细要面），涵盖24个新闻主题领域，采用基于两种GPT-4的自动评估协议，并经过人类评估验证。我们对11个LLM的全面分析突出了GPT-4和ERNIE Bot作为表现最佳，但在创造性写作任务中揭示了新闻伦理遵守方面的相对不足。这些发现强调了AI生成的新闻内容需要提高伦理指导，标志着以新闻标准和安全性对齐AI能力迈出了一步。

    arXiv:2403.00862v1 Announce Type: cross  Abstract: This study presents NewsBench, a novel benchmark framework developed to evaluate the capability of Large Language Models (LLMs) in Chinese Journalistic Writing Proficiency (JWP) and their Safety Adherence (SA), addressing the gap between journalistic ethics and the risks associated with AI utilization. Comprising 1,267 tasks across 5 editorial applications, 7 aspects (including safety and journalistic writing with 4 detailed facets), and spanning 24 news topics domains, NewsBench employs two GPT-4 based automatic evaluation protocols validated by human assessment. Our comprehensive analysis of 11 LLMs highlighted GPT-4 and ERNIE Bot as top performers, yet revealed a relative deficiency in journalistic ethic adherence during creative writing tasks. These findings underscore the need for enhanced ethical guidance in AI-generated journalistic content, marking a step forward in aligning AI capabilities with journalistic standards and safet
    
[^178]: 用深度生成技术重构零售供应链：分类法、调研和洞见

    Pivoting Retail Supply Chain with Deep Generative Techniques: Taxonomy, Survey and Insights

    [https://arxiv.org/abs/2403.00861](https://arxiv.org/abs/2403.00861)

    本文旨在研究如何利用深度生成模型（DGMs）重构现代零售供应链，通过提供DGMs的分类法、零售供应链中的应用案例回顾以及潜在利用DGMs解决零售问题的讨论。

    

    生成式人工智能应用，如ChatGPT或DALL-E，展示了它们在生成类似人类文本或图像方面的令人印象深刻的能力。深入研究，这些AI应用的科学利益相关者是深度生成模型，即DGMs，旨在学习数据的潜在分布并生成与原始数据集在统计上相似的新数据点。一个关键问题是如何将DGMs应用于现代零售供应链领域？为了回答这个问题，本文旨在全面审查DGMs，并讨论它们在零售供应链中的现有和潜在用例，方法是(1)提供最先进的DGMs及其变体的分类法和概述，(2)从端到端的视角回顾现有DGM在零售供应链中的应用，以及(3)讨论关于如何进一步利用DGM解决零售问题的见解和潜在方向。

    arXiv:2403.00861v1 Announce Type: new  Abstract: Generative AI applications, such as ChatGPT or DALL-E, have shown the world their impressive capabilities in generating human-like text or image. Diving deeper, the science stakeholder for those AI applications are Deep Generative Models, a.k.a DGMs, which are designed to learn the underlying distribution of the data and generate new data points that are statistically similar to the original dataset. One critical question is raised: how can we leverage DGMs into morden retail supply chain realm? To address this question, this paper expects to provide a comprehensive review of DGMs and discuss their existing and potential usecases in retail supply chain, by (1) providing a taxonomy and overview of state-of-the-art DGMs and their variants, (2) reviewing existing DGM applications in retail supply chain from a end-to-end view of point, and (3) discussing insights and potential directions on how DGMs can be further utilized on solving retail 
    
[^179]: 深度神经网络激活区域的精确枚举并行算法

    Parallel Algorithms for Exact Enumeration of Deep Neural Network Activation Regions

    [https://arxiv.org/abs/2403.00860](https://arxiv.org/abs/2403.00860)

    本研究提出了深度（和浅层）神经网络中精确枚举的并行算法，主要贡献包括新颖的算法框架和并行算法，实现了其中一种算法在多种网络架构上，并实验证明区域数量对运行时间的影响。

    

    一种使用修正线性单元的前馈神经网络通过将其输入空间划分为一组凸区域来构建从输入到输出的映射，区域内的点共享单一仿射变换。为了理解神经网络的工作原理、失败原因以及与生物智能的比较，我们需要理解这些区域的组织和形成。本文介绍了精确枚举深度（和浅层）神经网络的并行算法。

    arXiv:2403.00860v1 Announce Type: cross  Abstract: A feedforward neural network using rectified linear units constructs a mapping from inputs to outputs by partitioning its input space into a set of convex regions where points within a region share a single affine transformation. In order to understand how neural networks work, when and why they fail, and how they compare to biological intelligence, we need to understand the organization and formation of these regions. Step one is to design and implement algorithms for exact region enumeration in networks beyond toy examples.   In this work, we present parallel algorithms for exact enumeration in deep (and shallow) neural networks. Our work has three main contributions: (1) we present a novel algorithm framework and parallel algorithms for region enumeration; (2) we implement one of our algorithms on a variety of network architectures and experimentally show how the number of regions dictates runtime; and (3) we show, using our algorit
    
[^180]: 团队在冲突中的形成

    Team Formation amidst Conflicts

    [https://arxiv.org/abs/2403.00859](https://arxiv.org/abs/2403.00859)

    本文提出了团队在冲突中形成的问题，并提供了高效的近似算法，能够模拟不同的现实场景，在教育环境和人力资源管理中表现出色，特别是通过在真实数据集上的测试和部署，展示了算法的优越性。

    

    在这项工作中，我们提出了团队在冲突中形成的问题。我们的目标是分配个体到任务，考虑到个体的任务偏好和他们之间的冲突。利用依赖舍入方案作为我们的主要工具箱，我们提供了高效的近似算法。我们的框架非常灵活，可以模拟许多不同的现实场景，如教育环境和人力资源管理。我们在真实数据集上测试和部署我们的算法，并展示我们的算法找到的分配比自然基线找到的更好。在教育环境中，我们还展示了我们的分配比人类专家手动完成的分配更好。在人力资源管理应用中，我们展示了我们的分配如何增加团队的多样性。最后，使用合成数据集，我们展示了我们的算法扩展得非常好。

    arXiv:2403.00859v1 Announce Type: new  Abstract: In this work, we formulate the problem of team formation amidst conflicts. The goal is to assign individuals to tasks, with given capacities, taking into account individuals' task preferences and the conflicts between them. Using dependent rounding schemes as our main toolbox, we provide efficient approximation algorithms. Our framework is extremely versatile and can model many different real-world scenarios as they arise in educational settings and human-resource management. We test and deploy our algorithms on real-world datasets and we show that our algorithms find assignments that are better than those found by natural baselines. In the educational setting we also show how our assignments are far better than those done manually by human experts. In the human resource management application we show how our assignments increase the diversity of teams. Finally, using a synthetic dataset we demonstrate that our algorithms scale very well
    
[^181]: 直接与Chat-Fine-Tuned LLMs的草案模型对齐

    Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs

    [https://arxiv.org/abs/2403.00858](https://arxiv.org/abs/2403.00858)

    通过提出的框架，我们训练了一种用于Llama 2 Chat 7B或更大模型的草案模型，实现了加速推理，仅占原始大小的1.64％。

    

    文本生成与大型语言模型（LLMs）由于其自回归本质、巨大的参数数量和有限的内存带宽而被认为是内存密集型，通常导致低令牌速率。猜测解码已被提出作为LLM推理加速的解决方案。然而，在现代开源LLM系列中，例如Llama 2 7B，由于草案模型通常不可用，因此需要训练高质量的草案模型以通过猜测解码实现推理加速。在本文中，我们提出了一个简单的草案模型训练框架，用于直接与Chat-capable目标模型对齐。通过我们提出的框架，我们训练出Llama 2 Chat Drafter 115M，这是一个适用于Llama 2 Chat 7B或更大模型的草案模型，仅占原始大小的1.64％。我们的训练框架仅包括预训练、蒸馏数据集生成和使用知识蒸馏进行微调，没有额外的对齐步骤。

    arXiv:2403.00858v1 Announce Type: cross  Abstract: Text generation with Large Language Models (LLMs) is known to be memory bound due to the combination of their auto-regressive nature, huge parameter counts, and limited memory bandwidths, often resulting in low token rates. Speculative decoding has been proposed as a solution for LLM inference acceleration. However, since draft models are often unavailable in the modern open-source LLM families, e.g., for Llama 2 7B, training a high-quality draft model is required to enable inference acceleration via speculative decoding. In this paper, we propose a simple draft model training framework for direct alignment to chat-capable target models. With the proposed framework, we train Llama 2 Chat Drafter 115M, a draft model for Llama 2 Chat 7B or larger, with only 1.64\% of the original size. Our training framework only consists of pretraining, distillation dataset generation, and finetuning with knowledge distillation, with no additional align
    
[^182]: 使用自监督变压器和多任务学习进行说话者无关的运动障碍严重程度分类

    Speaker-Independent Dysarthria Severity Classification using Self-Supervised Transformers and Multi-Task Learning

    [https://arxiv.org/abs/2403.00854](https://arxiv.org/abs/2403.00854)

    提出了一种使用自监督变压器和多任务学习进行说话者无关的运动障碍严重度分类的方法，可自动评估运动障碍的严重程度。

    

    运动障碍是由于神经系统疾病导致言语肌肉控制能力受损而产生的一种状况，严重影响患者的沟通和生活质量。本研究提出了一种基于变压器的框架，可以从原始语音数据中自动评估运动障碍的严重程度。相较于传统需要人类专家评估的方法，它可以提供客观、可重复、可访问、标准化和具有成本效益的评估。

    arXiv:2403.00854v1 Announce Type: cross  Abstract: Dysarthria, a condition resulting from impaired control of the speech muscles due to neurological disorders, significantly impacts the communication and quality of life of patients. The condition's complexity, human scoring and varied presentations make its assessment and management challenging. This study presents a transformer-based framework for automatically assessing dysarthria severity from raw speech data. It can offer an objective, repeatable, accessible, standardised and cost-effective and compared to traditional methods requiring human expert assessors. We develop a transformer framework, called Speaker-Agnostic Latent Regularisation (SALR), incorporating a multi-task learning objective and contrastive learning for speaker-independent multi-class dysarthria severity classification. The multi-task framework is designed to reduce reliance on speaker-specific characteristics and address the intrinsic intra-class variability of d
    
[^183]: 利用双层可学习大型语言模型规划增强长期推荐

    Enhancing Long-Term Recommendation with Bi-level Learnable Large Language Model Planning

    [https://arxiv.org/abs/2403.00843](https://arxiv.org/abs/2403.00843)

    利用大型语言模型的规划能力来增强长期推荐，使模型在个性化推荐中更有效地理解和应用任务解决原则

    

    传统推荐系统倾向于过分迎合用户的即时兴趣而忽视他们的长期参与。 为了解决这个问题，在推荐决策过程中合并规划能力是至关重要的，以开发能够同时考虑即时兴趣和长期参与的策略。本文提出利用大型语言模型（LLMs）对稀疏数据的显著规划能力用于长期推荐。关键在于使语言模型能够在个性化推荐场景中有效理解和应用任务解决原则，因为模型的预训练可能并未自然包含这些内容。

    arXiv:2403.00843v1 Announce Type: cross  Abstract: Traditional recommendation setting tends to excessively cater to users' immediate interests and neglect their long-term engagement. To address it, it is crucial to incorporate planning capabilities into the recommendation decision-making process to develop policies that take into account both immediate interests and long-term engagement. Despite Reinforcement Learning (RL) can learn planning capacity by maximizing cumulative reward, the scarcity of recommendation data presents challenges such as instability and susceptibility to overfitting when training RL models from scratch.   In this context, we propose to leverage the remarkable planning capabilities over sparse data of Large Language Models (LLMs) for long-term recommendation. The key lies in enabling a language model to understand and apply task-solving principles effectively in personalized recommendation scenarios, as the model's pre-training may not naturally encompass these 
    
[^184]: 竞争游戏的离线虚构自我对弈

    Offline Fictitious Self-Play for Competitive Games

    [https://arxiv.org/abs/2403.00841](https://arxiv.org/abs/2403.00841)

    本文介绍了Off-FSP，这是竞争游戏的第一个实用的无模型离线RL算法，通过调整固定数据集的权重，使用重要性抽样，模拟与各种对手的互动。

    

    离线强化学习（RL）因其在以前收集的数据集中改进策略而不需要在线交互的能力而受到重视。尽管在单一智能体设置中取得成功，但离线多智能体RL仍然是一个挑战，特别是在竞争游戏中。为了解决这些问题，本文介绍了Off-FSP，这是竞争游戏的第一个实用的无模型离线RL算法。我们首先通过调整固定数据集的权重，使用重要性抽样模拟与各种对手的互动。

    arXiv:2403.00841v1 Announce Type: cross  Abstract: Offline Reinforcement Learning (RL) has received significant interest due to its ability to improve policies in previously collected datasets without online interactions. Despite its success in the single-agent setting, offline multi-agent RL remains a challenge, especially in competitive games. Firstly, unaware of the game structure, it is impossible to interact with the opponents and conduct a major learning paradigm, self-play, for competitive games. Secondly, real-world datasets cannot cover all the state and action space in the game, resulting in barriers to identifying Nash equilibrium (NE). To address these issues, this paper introduces Off-FSP, the first practical model-free offline RL algorithm for competitive games. We start by simulating interactions with various opponents by adjusting the weights of the fixed dataset with importance sampling. This technique allows us to learn best responses to different opponents and employ
    
[^185]: EyeGPT：具有大型语言模型的眼科助手

    EyeGPT: Ophthalmic Assistant with Large Language Models

    [https://arxiv.org/abs/2403.00840](https://arxiv.org/abs/2403.00840)

    EyeGPT是一个专门为眼科设计的大型语言模型，采用角色扮演、微调和检索增强生成等策略，提出了全面的多指标评估框架。

    

    人工智能（AI）在医疗咨询中引起了重要关注，因为它有望改善临床工作流程并增强医疗交流。然而，由于医学信息的复杂性，使用一般世界知识训练的大型语言模型（LLM）可能没有能力以专家水平处理与医学相关的任务。在这里，我们介绍了EyeGPT，这是一个专门为眼科设计的LLM，采用角色扮演、微调和检索增强生成等三种优化策略。特别地，我们提出了一个全面的评估框架，涵盖了各种眼科分支的多样数据集，不同用户和多样的查询意图。此外，我们考虑了多个评估指标，包括准确性、可理解性、可信度、移情和幻觉比例。

    arXiv:2403.00840v1 Announce Type: cross  Abstract: Artificial intelligence (AI) has gained significant attention in healthcare consultation due to its potential to improve clinical workflow and enhance medical communication. However, owing to the complex nature of medical information, large language models (LLM) trained with general world knowledge might not possess the capability to tackle medical-related tasks at an expert level. Here, we introduce EyeGPT, a specialized LLM designed specifically for ophthalmology, using three optimization strategies including role-playing, finetuning, and retrieval-augmented generation. In particular, we proposed a comprehensive evaluation framework that encompasses a diverse dataset, covering various subspecialties of ophthalmology, different users, and diverse inquiry intents. Moreover, we considered multiple evaluation metrics, including accuracy, understandability, trustworthiness, empathy, and the proportion of hallucinations. By assessing the p
    
[^186]: ToolNet：通过工具图将大型语言模型与海量工具连接起来

    ToolNet: Connecting Large Language Models with Massive Tools via Tool Graph

    [https://arxiv.org/abs/2403.00839](https://arxiv.org/abs/2403.00839)

    ToolNet是一个插拔式框架，通过将工具组织成一个有向图，实现了将大型语言模型与数千个工具连接起来，扩展了工具使用的数量而仅有中等标记消耗的增加。

    

    尽管在各种任务中取得了显著进展，但大型语言模型（LLMs）在正确使用海量外部工具方面仍然存在显著局限。现有的上下文学习方法简单地将工具格式化为一列纯文本描述，并将其输入到LLMs中，然后LLMs生成一系列工具调用序列以逐步解决问题。这种范式忽略了工具之间的内在依赖，并将所有推理负载转移到LLMs上，使其局限于一小部分专门设计的工具。因此，对LLMs来说，要在大量工具库上运行仍然具有挑战性，当面临现实场景时存在着很大限制。本文提出了ToolNet，一个即插即用的框架，通过适度增加标记消耗，将工具的数量扩展到数千个。ToolNet将工具组织成一个有向图。每个节点代表一个工具，加权边表示…

    arXiv:2403.00839v1 Announce Type: new  Abstract: While achieving remarkable progress in a broad range of tasks, large language models (LLMs) remain significantly limited in properly using massive external tools. Existing in-context learning approaches simply format tools into a list of plain text descriptions and input them to LLMs, from which, LLMs generate a sequence of tool calls to solve problems step by step. Such a paradigm ignores the intrinsic dependency between tools and offloads all reasoning loads to LLMs, making them restricted to a limited number of specifically designed tools. It thus remains challenging for LLMs to operate on a library of massive tools, casting a great limitation when confronted with real-world scenarios. This paper proposes ToolNet, a plug-and-play framework that scales up the number of tools to thousands with a moderate increase in token consumption. ToolNet organizes tools into a directed graph. Each node represents a tool, and weighted edges denote t
    
[^187]: CLLMs: 一致性大型语言模型

    CLLMs: Consistency Large Language Models

    [https://arxiv.org/abs/2403.00835](https://arxiv.org/abs/2403.00835)

    提出了一种新方法，通过精细调整目标LLM实现了对雅各比轨迹上固定点的一致性预测，有效提高了生成速度2.4倍到3.4倍。

    

    并行解码方法，如雅可比解码，显示出有望实现更高效的LLM推断，因为它打破了LLM解码过程的顺序性，并将其转换为可并行化计算。然而，在实践中，与传统的自回归（AR）解码相比，雅可比解码很少能在单个固定点迭代步骤中准确预测多个标记，因此在速度上取得的提升相对较小。为了解决这个问题，我们开发了一种新方法，旨在实现从任何状态快速收敛到雅各比轨迹上的固定点。通过精细调整目标LLM，以便在任何输入状态下一致地预测固定点。大量实验证明了我们方法的有效性，在领域特定和开放域基准测试中显示出生成速度提高了2.4倍到3.4倍，同时保持了生成质量。

    arXiv:2403.00835v1 Announce Type: cross  Abstract: Parallel decoding methods such as Jacobi decoding show promise for more efficient LLM inference as it breaks the sequential nature of the LLM decoding process and transforms it into parallelizable computation. However, in practice, it achieves little speedup compared to traditional autoregressive (AR) decoding, primarily because Jacobi decoding seldom accurately predicts more than one token in a single fixed-point iteration step. To address this, we develop a new approach aimed at realizing fast convergence from any state to the fixed point on a Jacobi trajectory. This is accomplished by refining the target LLM to consistently predict the fixed point given any state as input. Extensive experiments demonstrate the effectiveness of our method, showing 2.4$\times$ to 3.4$\times$ improvements in generation speed while preserving generation quality across both domain-specific and open-domain benchmarks.
    
[^188]: 利用虚拟现实理解以人工智能驱动的科学发现并应用于量子光学

    Virtual Reality for Understanding Artificial-Intelligence-driven Scientific Discovery with an Application in Quantum Optics

    [https://arxiv.org/abs/2403.00834](https://arxiv.org/abs/2403.00834)

    虚拟现实环境辅助研究人员理解人工智能生成的解决方案，展示了在量子光学实验中发现可解释配置的实用性

    

    生成式人工智能（AI）模型可以提出超出人类能力范围的科学问题解决方案。 研究人员需要能够理解AI生成的结构并提取其中的概念和想法，才能真正做出概念性贡献。 本文展示了如何将部分分析过程转移到沉浸式虚拟现实（VR）环境中，以帮助研究人员理解由AI生成的解决方案。 我们展示了VR在找到代表量子光学实验的抽象图形的可解释配置方面的实用性。 从而，我们可以手动发现新领域的解决方案。

    arXiv:2403.00834v1 Announce Type: cross  Abstract: Generative Artificial Intelligence (AI) models can propose solutions to scientific problems beyond human capability. To truly make conceptual contributions, researchers need to be capable of understanding the AI-generated structures and extracting the underlying concepts and ideas. When algorithms provide little explanatory reasoning alongside the output, scientists have to reverse-engineer the fundamental insights behind proposals based solely on examples. This task can be challenging as the output is often highly complex and thus not immediately accessible to humans. In this work we show how transferring part of the analysis process into an immersive Virtual Reality (VR) environment can assist researchers in developing an understanding of AI-generated solutions. We demonstrate the usefulness of VR in finding interpretable configurations of abstract graphs, representing Quantum Optics experiments. Thereby, we can manually discover new
    
[^189]: 位置论文：代理人人工智能走向整体智能

    Position Paper: Agent AI Towards a Holistic Intelligence

    [https://arxiv.org/abs/2403.00833](https://arxiv.org/abs/2403.00833)

    代理人人工智能旨在将大型基础模型整合到代理人行为中，挑战我们对学习和认知的理解

    

    近期大型基础模型的快速发展显著提升了我们对开放世界环境中感知信息的理解。利用基础模型的力量，人工智能研究需要从过度还原主义转向强调作为整体运作系统的重点。具体来说，我们强调发展代理人人工智能——一个将大型基础模型整合到代理人行为中的具体系统。代理人人工智能这一新兴领域涵盖了现有的包括机器人技术、游戏和医疗系统等在内的体验丰富的基于代理人的多模态交互。本文提出了一个新颖的大型行为模型以实现具有体现智能行为的代理人基础模型。在此基础上，我们讨论了代理人人工智能在各种领域和任务中展示出的显著能力，挑战了我们对学习和认知的理解。此外，我们讨论了

    arXiv:2403.00833v1 Announce Type: new  Abstract: Recent advancements in large foundation models have remarkably enhanced our understanding of sensory information in open-world environments. In leveraging the power of foundation models, it is crucial for AI research to pivot away from excessive reductionism and toward an emphasis on systems that function as cohesive wholes. Specifically, we emphasize developing Agent AI -- an embodied system that integrates large foundation models into agent actions. The emerging field of Agent AI spans a wide range of existing embodied and agent-based multimodal interactions, including robotics, gaming, and healthcare systems, etc. In this paper, we propose a novel large action model to achieve embodied intelligent behavior, the Agent Foundation Model. On top of this idea, we discuss how agent AI exhibits remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. Furthermore, we discuss the p
    
[^190]: 通过路径推理实现可解释的基于会话的推荐

    Explainable Session-based Recommendation via Path Reasoning

    [https://arxiv.org/abs/2403.00832](https://arxiv.org/abs/2403.00832)

    通过路径推理的泛化层次强化学习框架提高了基于会话的推荐的可解释性，设计了多目标奖励机制和路径中间点奖励以应对顺序模式的跳过行为和增强知识图的探索效率。

    

    本文探讨了通过路径推理为基于会话的推荐（SR）提供可解释性的方法。现有的SR模型强调准确性但缺乏可解释性，而传统的路径推理侧重于知识图探索，忽略了会话历史中存在的顺序模式。因此，我们提出了一种用于SR的泛化层次强化学习框架，通过路径推理（PR4SR）来提高现有SR模型的可解释性。考虑到项目对会话的重要性不同，我们设计了会话级别代理来选择会话中的项目作为路径推理的起点，以及路径级别代理来执行路径推理。特别地，我们设计了多目标奖励机制来适应SR中顺序模式的跳过行为，并引入路径中间点奖励来增强知识图中的探索效率。

    arXiv:2403.00832v1 Announce Type: cross  Abstract: This paper explores providing explainability for session-based recommendation (SR) by path reasoning. Current SR models emphasize accuracy but lack explainability, while traditional path reasoning prioritizes knowledge graph exploration, ignoring sequential patterns present in the session history. Therefore, we propose a generalized hierarchical reinforcement learning framework for SR, which improves the explainability of existing SR models via Path Reasoning, namely PR4SR. Considering the different importance of items to the session, we design the session-level agent to select the items in the session as the starting point for path reasoning and the path-level agent to perform path reasoning. In particular, we design a multi-target reward mechanism to adapt to the skip behaviors of sequential patterns in SR, and introduce path midpoint reward to enhance the exploration efficiency in knowledge graphs. To improve the completeness of the
    
[^191]: MedAide：利用大型语言模型为边缘设备提供现场医疗援助

    MedAide: Leveraging Large Language Models for On-Premise Medical Assistance on Edge Devices

    [https://arxiv.org/abs/2403.00830](https://arxiv.org/abs/2403.00830)

    MedAide是一款利用微型语言模型与LangChain集成，为资源受限的边缘设备提供高效医疗诊断和支持的现场医疗聊天机器人，通过模型优化和多样的医疗数据集训练来提升其领域特定能力。

    

    大型语言模型( LLMs )以其出色的自然语言处理( NLP )功能正在改变各个领域。然而，在资源受限的边缘计算和嵌入式系统中部署 LLMs 存在重大挑战。另一个挑战在于在医疗资源有限、基础设施不完备的偏远地区提供医疗援助。为解决这一问题，我们介绍了 MedAide，一款现场医疗聊天机器人。它利用与 LangChain 集成的微型 LLMs，提供高效的基于边缘的初步医疗诊断和支持。MedAide 通过模型优化在嵌入式边缘设备上实现最小内存占用和延迟，无需服务器基础设施。训练过程使用低秩适应 (LoRA ) 进行优化。此外，该模型在多样化的医疗数据集上进行训练，应用来自人类反馈的强化学习 (RLHF) 来增强其特定领域的能力。

    arXiv:2403.00830v1 Announce Type: new  Abstract: Large language models (LLMs) are revolutionizing various domains with their remarkable natural language processing (NLP) abilities. However, deploying LLMs in resource-constrained edge computing and embedded systems presents significant challenges. Another challenge lies in delivering medical assistance in remote areas with limited healthcare facilities and infrastructure. To address this, we introduce MedAide, an on-premise healthcare chatbot. It leverages tiny-LLMs integrated with LangChain, providing efficient edge-based preliminary medical diagnostics and support. MedAide employs model optimizations for minimal memory footprint and latency on embedded edge devices without server infrastructure. The training process is optimized using low-rank adaptation (LoRA). Additionally, the model is trained on diverse medical datasets, employing reinforcement learning from human feedback (RLHF) to enhance its domain-specific capabilities. The sy
    
[^192]: TroubleLLM: 对齐红队专家

    TroubleLLM: Align to Red Team Expert

    [https://arxiv.org/abs/2403.00829](https://arxiv.org/abs/2403.00829)

    TroubleLLM是第一个用于生成关于LLMs安全问题的可控测试提示的LLM，通过广泛实验和人类评估展示了其在生成质量和生成可控性方面的优越性

    

    大型语言模型（LLMs）已成为各种自然语言任务的最先进解决方案，并被整合到现实世界的应用中。然而，LLMs可能在展现诸如社会偏见和有毒内容等不良安全问题方面具有潜在危害。在部署之前评估其安全问题至关重要。然而，现有方法生成的测试提示的质量和多样性仍然远远不尽人意。这些方法不仅劳动密集且需要大量预算成本，而且测试提示生成的可控性在LLM应用的具体测试领域中缺乏。

    arXiv:2403.00829v1 Announce Type: new  Abstract: Large Language Models (LLMs) become the start-of-the-art solutions for a variety of natural language tasks and are integrated into real-world applications. However, LLMs can be potentially harmful in manifesting undesirable safety issues like social biases and toxic content. It is imperative to assess its safety issues before deployment. However, the quality and diversity of test prompts generated by existing methods are still far from satisfactory. Not only are these methods labor-intensive and require large budget costs, but the controllability of test prompt generation is lacking for the specific testing domain of LLM applications. With the idea of LLM for LLM testing, we propose the first LLM, called TroubleLLM, to generate controllable test prompts on LLM safety issues. Extensive experiments and human evaluation illustrate the superiority of TroubleLLM on generation quality and generation controllability.
    
[^193]: 基于深度学习的大型语言模型生成科学内容的检测方法

    Deep Learning Detection Method for Large Language Models-Generated Scientific Content

    [https://arxiv.org/abs/2403.00828](https://arxiv.org/abs/2403.00828)

    提出了一种新的ChatGPT生成科学文本检测方法AI-Catcher，该方法集成了多层感知器（MLP）和卷积神经网络（CNN），是一个多模态模型，用于检测大型语言模型生成的科学内容。

    

    Large Language Models (LLMs), 如GPT-3和BERT，改变了文本内容的写作和传播方式。这些模型有潜力生成与人类写作无法区分的科学内容。因此，LLMs会给科学界带来严重后果，科学界依赖于出版物的完整性和可靠性。本研究提出了一种新颖的ChatGPT生成的科学文本检测方法，名为AI-Catcher。AI-Catcher集成了两个深度学习模型，多层感知器（MLP）和卷积神经网络（CNN）。MLP学习语言和统计特征的特征表示。CNN从文本内容中提取顺序模式的高级表示。AI-Catcher是一个多模态模型，融合了MLP和CNN导出的隐藏模式。此外，还收集了一个新的ChatGPT生成的科学文本数据集来增强AI生成的文本。

    arXiv:2403.00828v1 Announce Type: cross  Abstract: Large Language Models (LLMs), such as GPT-3 and BERT, reshape how textual content is written and communicated. These models have the potential to generate scientific content that is indistinguishable from that written by humans. Hence, LLMs carry severe consequences for the scientific community, which relies on the integrity and reliability of publications. This research paper presents a novel ChatGPT-generated scientific text detection method, AI-Catcher. AI-Catcher integrates two deep learning models, multilayer perceptron (MLP) and convolutional neural networks (CNN). The MLP learns the feature representations of the linguistic and statistical features. The CNN extracts high-level representations of the sequential patterns from the textual content. AI-Catcher is a multimodal model that fuses hidden patterns derived from MLP and CNN. In addition, a new ChatGPT-Generated scientific text dataset is collected to enhance AI-generated tex
    
[^194]: 来自外部代理指标反馈的语言模型自我完善

    Self-Refinement of Language Models from External Proxy Metrics Feedback

    [https://arxiv.org/abs/2403.00827](https://arxiv.org/abs/2403.00827)

    本文提出了Proxy Metric-based Self-Refinement (ProMiSe)方法，通过外部指标反馈指导语言模型在质量关键维度上进行自我完善，从而改进响应质量。

    

    在文档为基础的响应生成中，期望代理响应不仅与用户的查询相关，还与给定的文档相关。本文引入了基于代理指标的自我完善（ProMiSe），使得大型语言模型能够沿着外部指标反馈引导的质量关键维度优化其初始响应，从而产生更好的最终响应。

    arXiv:2403.00827v1 Announce Type: cross  Abstract: It is often desirable for Large Language Models (LLMs) to capture multiple objectives when providing a response. In document-grounded response generation, for example, agent responses are expected to be relevant to a user's query while also being grounded in a given document. In this paper, we introduce Proxy Metric-based Self-Refinement (ProMiSe), which enables an LLM to refine its own initial response along key dimensions of quality guided by external metrics feedback, yielding an overall better final response. ProMiSe leverages feedback on response quality through principle-specific proxy metrics, and iteratively refines its response one principle at a time. We apply ProMiSe to open source language models Flan-T5-XXL and Llama-2-13B-Chat, to evaluate its performance on document-grounded question answering datasets, MultiDoc2Dial and QuAC, demonstrating that self-refinement improves response quality. We further show that fine-tuning 
    
[^195]: 信息流路由：自动解释规模化语言模型

    Information Flow Routes: Automatically Interpreting Language Models at Scale

    [https://arxiv.org/abs/2403.00824](https://arxiv.org/abs/2403.00824)

    这项研究提出了一种自动解释语言模型的方法，通过构建信息流路由图来揭示模型内部的关键节点和操作，相比于现有方法的激活修补，这种方法通过归因实现，在不需要人工干预设计的情况下可以有效地分析模型行为。

    

    通过模型实现的机制，信息通过网络内部的路由进行传输。这些路由可以被表示为图，其中节点对应于标记表示，边对应于网络内部的操作。我们以自顶向下的方式自动构建这些图，针对每一个预测只保留最重要的节点和边。与现有的依赖于激活修补的工作流相比，我们通过归因来做到这一点：这使我们能够仅通过单次前向传递有效地揭示现有的电路。此外，我们的方法的适用性远远超出了修补：我们不需要人类仔细设计预测模板，可以为任何预测提取信息流路由（不仅仅是在允许的模板之间的预测）。因此，我们可以就模型行为进行一般性讨论，针对特定类型的预测或不同的领域。我们在Llama 2上进行了实验，并展示了这一方法的作用。

    arXiv:2403.00824v1 Announce Type: cross  Abstract: Information flows by routes inside the network via mechanisms implemented in the model. These routes can be represented as graphs where nodes correspond to token representations and edges to operations inside the network. We automatically build these graphs in a top-down manner, for each prediction leaving only the most important nodes and edges. In contrast to the existing workflows relying on activation patching, we do this through attribution: this allows us to efficiently uncover existing circuits with just a single forward pass. Additionally, the applicability of our method is far beyond patching: we do not need a human to carefully design prediction templates, and we can extract information flow routes for any prediction (not just the ones among the allowed templates). As a result, we can talk about model behavior in general, for specific types of predictions, or different domains. We experiment with Llama 2 and show that the rol
    
[^196]: 在合作语言游戏中适应队友

    Adapting to Teammates in a Cooperative Language Game

    [https://arxiv.org/abs/2403.00823](https://arxiv.org/abs/2403.00823)

    这项研究提出了第一个适应Codenames游戏的Agent，采用集成方法来确定最佳匹配的内部专家Agent，从而使Agent能够根据特定队友进行适应。

    

    Codenames游戏最近已成为智能Agent设计领域的一个感兴趣领域。该游戏由于语言和队友之间的协调方式而独具特色。我们提出了第一个适应Codenames游戏的Agent。我们采用一个集成方法，旨在确定，在与特定队友互动过程中，我们内部的哪个专家Agent，每个Agent可能具有自己的语言模型，是最佳匹配的。

    arXiv:2403.00823v1 Announce Type: new  Abstract: The game of Codenames has recently emerged as a domain of interest for intelligent agent design. The game is unique due to the way that language and coordination between teammates play important roles. Previous approaches to designing agents for this game have utilized a single internal language model to determine action choices. This often leads to good performance with some teammates and inferior performance with other teammates, as the agent cannot adapt to any specific teammate. In this paper we present the first adaptive agent for playing Codenames. We adopt an ensemble approach with the goal of determining, during the course of interacting with a specific teammate, which of our internal expert agents, each potentially with its own language model, is the best match. One difficulty faced in this approach is the lack of a single numerical metric that accurately captures the performance of a Codenames team. Prior Codenames research has
    
[^197]: InteraRec：使用多模式大型语言模型进行交互式推荐

    InteraRec: Interactive Recommendations Using Multimodal Large Language Models

    [https://arxiv.org/abs/2403.00822](https://arxiv.org/abs/2403.00822)

    InteraRec引入了一种复杂的交互式推荐框架，与传统方法不同，它不仅依赖Weblog生成推荐，还捕获用户导航时网页的高频截图。

    

    Weblog由记录任何网站上用户活动的记录组成，可以为用户偏好、行为和兴趣提供宝贵的见解。许多推荐算法利用通过这些Weblog挖掘的数据，采用协同过滤、基于内容的过滤和混合方法等策略，为用户提供个性化推荐。本研究引入了一种称为InteraRec的复杂交互式推荐框架，它不同于传统方法，后者仅依赖Weblog生成推荐。该框架捕获用户导航时网页的高频截图。

    arXiv:2403.00822v1 Announce Type: cross  Abstract: Weblogs, comprised of records detailing user activities on any website, offer valuable insights into user preferences, behavior, and interests. Numerous recommendation algorithms, employing strategies such as collaborative filtering, content-based filtering, and hybrid methods, leverage the data mined through these weblogs to provide personalized recommendations to users. Despite the abundance of information available in these weblogs, identifying and extracting pertinent information and key features necessitates extensive engineering endeavors. The intricate nature of the data also poses a challenge for interpretation, especially for non-experts. In this study, we introduce a sophisticated and interactive recommendation framework denoted as InteraRec, which diverges from conventional approaches that exclusively depend on weblogs for recommendation generation. This framework captures high-frequency screenshots of web pages as users nav
    
[^198]: CFRet-DVQA：粗到精检索和高效调优用于文档视觉问答

    CFRet-DVQA: Coarse-to-Fine Retrieval and Efficient Tuning for Document Visual Question Answering

    [https://arxiv.org/abs/2403.00816](https://arxiv.org/abs/2403.00816)

    该研究提出了一种名为CFRet-DVQA的方法，通过检索和高效调优，解决了文档视觉问答中定位信息和限制模型输入的长度等问题，进一步提升了答案的生成性能。

    

    文档视觉问答（DVQA）是一个涉及根据图像内容回答查询的任务。现有工作仅限于定位单页内的信息，不支持跨页面问答交互。此外，对模型输入的标记长度限制可能导致与答案相关的部分被截断。在本研究中，我们引入了一种简单但有效的方法学，称为CFRet-DVQA，重点放在检索和高效调优上，以有效解决这一关键问题。为此，我们首先从文档中检索与所提问题相关的多个片段。随后，我们利用大型语言模型（LLM）的先进推理能力，通过指导调优进一步增强其性能。该方法使得生成的答案与文档标签的风格相符。实验演示了...

    arXiv:2403.00816v1 Announce Type: cross  Abstract: Document Visual Question Answering (DVQA) is a task that involves responding to queries based on the content of images. Existing work is limited to locating information within a single page and does not facilitate cross-page question-and-answer interaction. Furthermore, the token length limitation imposed on inputs to the model may lead to truncation of segments pertinent to the answer. In this study, we introduce a simple but effective methodology called CFRet-DVQA, which focuses on retrieval and efficient tuning to address this critical issue effectively. For that, we initially retrieve multiple segments from the document that correlate with the question at hand. Subsequently, we leverage the advanced reasoning abilities of the large language model (LLM), further augmenting its performance through instruction tuning. This approach enables the generation of answers that align with the style of the document labels. The experiments demo
    
[^199]: RAM-EHR: 电子健康记录上的检索增强与临床预测相遇

    RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic Health Records

    [https://arxiv.org/abs/2403.00815](https://arxiv.org/abs/2403.00815)

    RAM-EHR通过增强检索并利用总结知识，提高了针对电子健康记录的临床预测效果。

    

    我们提出了RAM-EHR，这是一个用于改善电子健康记录（EHR）上临床预测的检索增强（Retrieval Augmentation）流程。RAM-EHR首先收集多个知识来源，将它们转换为文本格式，并使用密集检索来获取与医学概念相关的信息。这一策略解决了与复杂概念名称相关的困难。RAM-EHR然后增广了与一致性正则化代码联合训练的本地EHR预测模型，以捕获来自患者就诊和总结知识的互补信息。在两个EHR数据集上的实验表明，RAM-EHR相对于之前的知识增强基线效果显著（AUROC增益3.4％，AUPR增益7.2％），强调了RAM-EHR的总结知识对临床预测任务的有效性。代码将发布在\url{https://github.com/ritaranx/RAM-EHR}。

    arXiv:2403.00815v1 Announce Type: cross  Abstract: We present RAM-EHR, a Retrieval AugMentation pipeline to improve clinical predictions on Electronic Health Records (EHRs). RAM-EHR first collects multiple knowledge sources, converts them into text format, and uses dense retrieval to obtain information related to medical concepts. This strategy addresses the difficulties associated with complex names for the concepts. RAM-EHR then augments the local EHR predictive model co-trained with consistency regularization to capture complementary information from patient visits and summarized knowledge. Experiments on two EHR datasets show the efficacy of RAM-EHR over previous knowledge-enhanced baselines (3.4% gain in AUROC and 7.2% gain in AUPR), emphasizing the effectiveness of the summarized knowledge from RAM-EHR for clinical prediction tasks. The code will be published at \url{https://github.com/ritaranx/RAM-EHR}.
    
[^200]: UrbanGPT: 时空大型语言模型

    UrbanGPT: Spatio-Temporal Large Language Models

    [https://arxiv.org/abs/2403.00813](https://arxiv.org/abs/2403.00813)

    都市GPT旨在建立一个具有强大泛化能力的时空模型，借鉴大型语言模型的成就。

    

    都市GPT旨在预测并洞察城市环境在时间和空间上不断变化的动态。其目的是预测都市生活各个方面的未来模式、趋势和事件，包括交通、人口流动和犯罪率等。尽管已经付出了大量努力开发神经网络技术以准确预测时空数据，但需注意到很多方法在生成精确的时空表示时严重依赖于有足够标记的数据。不幸的是，在实际都市感知场景中，数据稀缺是一个普遍存在的问题。因此，建立一个具有强大泛化能力的时空模型跨越多样时空学习场景是必要的。受大型语言模型(LLM)卓越成就的启发，我们的目标是

    arXiv:2403.00813v1 Announce Type: cross  Abstract: Spatio-temporal prediction aims to forecast and gain insights into the ever-changing dynamics of urban environments across both time and space. Its purpose is to anticipate future patterns, trends, and events in diverse facets of urban life, including transportation, population movement, and crime rates. Although numerous efforts have been dedicated to developing neural network techniques for accurate predictions on spatio-temporal data, it is important to note that many of these methods heavily depend on having sufficient labeled data to generate precise spatio-temporal representations. Unfortunately, the issue of data scarcity is pervasive in practical urban sensing scenarios. Consequently, it becomes necessary to build a spatio-temporal model with strong generalization capabilities across diverse spatio-temporal learning scenarios. Taking inspiration from the remarkable achievements of large language models (LLMs), our objective is 
    
[^201]: LoRA在统一框架下遇见了Dropout

    LoRA Meets Dropout under a Unified Framework

    [https://arxiv.org/abs/2403.00812](https://arxiv.org/abs/2403.00812)

    LoRA是一个轻量级的参数高效微调方法，该论文研究了LoRA与dropout方法在模型定制中的矛盾，重新审视了transformer-specific的dropout方法，并建立了它们之间的数学和经验上的等价性和区别。

    

    具有显著能力的大型语言模型（LLMs）已成为许多自然语言处理应用中不可或缺的元素，而参数高效微调，特别是LoRA，已经成为模型定制的轻量级方法的流行选择。同时，各种dropout方法最初是为所有参数进行完整微调而设计的，有助于减轻与过多参数冗余相关的过拟合问题。因此，LoRA的可训练参数微不足道与先前dropout方法的有效性之间存在可能的矛盾，这一点之前大多被忽视。为填补这一空白，我们首先确认高效参数的LoRA也容易出现过拟合问题。然后，我们重新审视特定于transformer的dropout方法，从数学和经验上建立它们的等价性和区别。基于这种比较分析，我们引入了一个统一框架进行全面研究，

    arXiv:2403.00812v1 Announce Type: cross  Abstract: With the remarkable capabilities, large language models (LLMs) have emerged as essential elements in numerous NLP applications, while parameter-efficient finetuning, especially LoRA, has gained popularity as a lightweight approach for model customization. Meanwhile, various dropout methods, initially designed for full finetuning with all the parameters updated, alleviates overfitting associated with excessive parameter redundancy. Hence, a possible contradiction arises from negligible trainable parameters of LoRA and the effectiveness of previous dropout methods, which has been largely overlooked. To fill this gap, we first confirm that parameter-efficient LoRA is also overfitting-prone. We then revisit transformer-specific dropout methods, and establish their equivalence and distinctions mathematically and empirically. Building upon this comparative analysis, we introduce a unified framework for a comprehensive investigation, which in
    
[^202]: LLM在高风险决策中的认知偏见

    Cognitive Bias in High-Stakes Decision-Making with LLMs

    [https://arxiv.org/abs/2403.00811](https://arxiv.org/abs/2403.00811)

    提出了BiasBuster框架，用于揭示、评估和减轻LLMs中的认知偏见，特别是在高风险决策任务中，通过开发包含16,800个提示的数据集和测试多种偏见缓解策略，并提出一种利用LLMs自身来消除其提示中偏见的新方法。

    

    大型语言模型(LLMs)在支持日益扩大的决策任务方面具有重要潜力。然而，由于它们在人类(创造的)数据上训练，LLMs可能会继承针对受保护群体的社会偏见，同时也可能受到认知偏见的影响。这种类似于人类的偏见可能会妨碍利用LLM协助做出公平和可解释的决策。我们的工作引入了BiasBuster，一个旨在揭示、评估和减轻LLMs中的认知偏见的框架，特别是在高风险决策任务中。受心理学和认知科学先前研究的启发，我们开发了一个包含16,800个提示的数据集，用于评估不同认知偏见(例如，提示诱导、顺序、固有)。我们测试了各种偏见缓解策略，同时提出了一种新方法，利用LLMs来消除它们自己的提示中的偏见。我们的分析提供了关于不同领域认知偏见存在和影响的全面图景。

    arXiv:2403.00811v1 Announce Type: new  Abstract: Large language models (LLMs) offer significant potential as tools to support an expanding range of decision-making tasks. However, given their training on human (created) data, LLMs can inherit both societal biases against protected groups, as well as be subject to cognitive bias. Such human-like bias can impede fair and explainable decisions made with LLM assistance. Our work introduces BiasBuster, a framework designed to uncover, evaluate, and mitigate cognitive bias in LLMs, particularly in high-stakes decision-making tasks. Inspired by prior research in psychology and cognitive sciences, we develop a dataset containing 16,800 prompts to evaluate different cognitive biases (e.g., prompt-induced, sequential, inherent). We test various bias mitigation strategies, amidst proposing a novel method using LLMs to debias their own prompts. Our analysis provides a comprehensive picture on the presence and effects of cognitive bias across diffe
    
[^203]: 利用大型语言模型引导认知Agent

    Bootstrapping Cognitive Agents with a Large Language Model

    [https://arxiv.org/abs/2403.00810](https://arxiv.org/abs/2403.00810)

    通过利用大型语言模型中的知识，我们将认知模型与大语言模型相结合，提出了一种通过具身Agent完成任务的框架，相较于完全基于大语言模型的Agent，具有更好的效率。

    

    大型语言模型包含世界的杂乱一般知识，但很难进行训练或微调。另一方面，认知架构具有出色的可解释性和更新的灵活性，但需要大量手动工作来实例化。在这项工作中，我们结合了两个世界的优势：用大型语言模型编码的杂乱知识引导认知模型。通过一个做厨房任务的具身Agent，我们展示了我们提出的框架相比完全基于大型语言模型的Agent具有更好的效率。我们的实验表明，大型语言模型是认知架构的信息来源，而认知架构反过来可以验证并更新大型语言模型对特定领域的知识。

    arXiv:2403.00810v1 Announce Type: new  Abstract: Large language models contain noisy general knowledge of the world, yet are hard to train or fine-tune. On the other hand cognitive architectures have excellent interpretability and are flexible to update but require a lot of manual work to instantiate. In this work, we combine the best of both worlds: bootstrapping a cognitive-based model with the noisy knowledge encoded in large language models. Through an embodied agent doing kitchen tasks, we show that our proposed framework yields better efficiency compared to an agent based entirely on large language models. Our experiments indicate that large language models are a good source of information for cognitive architectures, and the cognitive architecture in turn can verify and update the knowledge of large language models to a specific domain.
    
[^204]: Abdelhak在SemEval-2024任务9中的表现：解码谜题，专用模型与ChatGPT的有效性比较

    Abdelhak at SemEval-2024 Task 9 : Decoding Brainteasers, The Efficacy of Dedicated Models Versus ChatGPT

    [https://arxiv.org/abs/2403.00809](https://arxiv.org/abs/2403.00809)

    本研究提出了一个专用模型，在解决谜题任务中表现出色，并与ChatGPT进行了比较性能分析，发现专用模型在横向思维和问题解决方面具有明显优势。

    

    这项研究介绍了一个旨在解决任务9的BRAINTEASER问题的专用模型，这是一个通过句子和单词谜题来评估模型横向思维能力的新挑战。我们的模型表现出显著的效果，在测试阶段中以0.98的总分数在句子谜题解决方面获得了第一名。此外，我们探讨了ChatGPT的比较表现，特别分析了温度设置的变化如何影响其进行横向思维和问题解决的能力。我们的研究结果表明，专用模型和ChatGPT之间存在显著的性能差异，突出了专门方法在增强AI创造性推理方面的潜力。

    arXiv:2403.00809v1 Announce Type: cross  Abstract: This study introduces a dedicated model aimed at solving the BRAINTEASER task 9 , a novel challenge designed to assess models lateral thinking capabilities through sentence and word puzzles. Our model demonstrates remarkable efficacy, securing Rank 1 in sentence puzzle solving during the test phase with an overall score of 0.98. Additionally, we explore the comparative performance of ChatGPT, specifically analyzing how variations in temperature settings affect its ability to engage in lateral thinking and problem-solving. Our findings indicate a notable performance disparity between the dedicated model and ChatGPT, underscoring the potential of specialized approaches in enhancing creative reasoning in AI.
    
[^205]: 基于扩散模型的关系三元组提取的隐式透视IPED

    IPED: An Implicit Perspective for Relational Triple Extraction based on Diffusion Model

    [https://arxiv.org/abs/2403.00808](https://arxiv.org/abs/2403.00808)

    提出了一种基于扩散模型的IPED方法，采用隐式答案策略完成表格，在关系三元组提取中取得了有效结果

    

    关系三元组提取是信息提取领域中的一项基本任务，最近一种基于表填充的前景框架作为一种潜在的实体关系提取基准引起了关注。 但是，固有的缺点，例如冗余信息和不完整三元组识别仍然存在问题。 为了解决这些挑战，我们提出了一种基于扩散模型的隐式角度的关系三元组提取（IPED），这是一种用于提取关系三元组的创新方法。 我们的无分类器解决方案采用隐式策略，使用块覆盖完成表格，避免了显式标记方法的局限性。 另外，我们引入了一个生成模型结构，块去噪扩散模型，与我们的隐式透视合作，并有效地规避了冗余信息干扰。 两个流行数据集上的实验结果表明，I

    arXiv:2403.00808v1 Announce Type: cross  Abstract: Relational triple extraction is a fundamental task in the field of information extraction, and a promising framework based on table filling has recently gained attention as a potential baseline for entity relation extraction. However, inherent shortcomings such as redundant information and incomplete triple recognition remain problematic. To address these challenges, we propose an Implicit Perspective for relational triple Extraction based on Diffusion model (IPED), an innovative approach for extracting relational triples. Our classifier-free solution adopts an implicit strategy using block coverage to complete the tables, avoiding the limitations of explicit tagging methods. Additionally, we introduce a generative model structure, the block-denoising diffusion model, to collaborate with our implicit perspective and effectively circumvent redundant information disruptions. Experimental results on two popular datasets demonstrate that I
    
[^206]: 一种新的动态分布式规划方法：在DPDP问题中的应用

    A New Dynamic Distributed Planning Approach: Application to DPDP Problems

    [https://arxiv.org/abs/2403.00805](https://arxiv.org/abs/2403.00805)

    提出了一种新的动态分布式规划方法，能够根据代理引入的动作集变化和环境变化进行计划生成。

    

    在这项工作中，我们提出了一种新的动态分布式规划方法，能够考虑代理在其计划的动作集中引入的变化，以便考虑环境中发生的变化。我们的方法适用于分布式规划的背景，其中每个代理可以生成自己的计划。根据我们的方法，计划的生成基于通过遗传算法满足约束条件。我们的方法是，每当代理的动作集有变化时就由每个代理生成一个新计划。为此，要考虑新计划中引入的新动作。在这个新计划中，代理每次都将未执行的旧计划中的所有旧动作和变化引起的新动作作为新动作集合来规划，并将新的初始状态作为新的初始状态。

    arXiv:2403.00805v1 Announce Type: new  Abstract: In this work, we proposed a new dynamic distributed planning approach that is able to take into account the changes that the agent introduces on his set of actions to be planned in order to take into account the changes that occur in his environment. Our approach fits into the context of distributed planning for distributed plans where each agent can produce its own plans. According to our approach the generation of the plans is based on the satisfaction of the constraints by the use of the genetic algorithms. Our approach is to generate, a new plan by each agent, whenever there is a change in its set of actions to plan. This in order to take into account the new actions introduced in its new plan. In this new plan, the agent takes, each time, as a new action set to plan all the old un-executed actions of the old plan and the new actions engendered by the changes and as a new initial state; the state in which the set of actions of the ag
    
[^207]: 通过拓扑自然语言分析揭示客户问题

    Uncovering Customer Issues through Topological Natural Language Analysis

    [https://arxiv.org/abs/2403.00804](https://arxiv.org/abs/2403.00804)

    提出了一种利用自然语言技术和拓扑数据分析监控新兴和热门客户问题的机器学习算法。

    

    电子商务公司每天处理大量客户服务请求。尽管通常使用简单的注释系统来总结客户联系的主题，但深入探讨每个具体问题可能具有挑战性。为了解决这一挑战，我们提出了一种新颖的机器学习算法，利用自然语言技术和拓扑数据分析来监控新兴和热门客户问题。我们的方法涉及一种端到端的深度学习框架，同时标记每个客户对话记录的主要问题句，并生成句子嵌入向量。然后我们对嵌入向量进行白化处理，并使用它们构建一个无向图。然后，我们根据每个对话记录的拓扑特性来定义热门和新兴问题。

    arXiv:2403.00804v1 Announce Type: cross  Abstract: E-commerce companies deal with a high volume of customer service requests daily. While a simple annotation system is often used to summarize the topics of customer contacts, thoroughly exploring each specific issue can be challenging. This presents a critical concern, especially during an emerging outbreak where companies must quickly identify and address specific issues. To tackle this challenge, we propose a novel machine learning algorithm that leverages natural language techniques and topological data analysis to monitor emerging and trending customer issues. Our approach involves an end-to-end deep learning framework that simultaneously tags the primary question sentence of each customer's transcript and generates sentence embedding vectors. We then whiten the embedding vectors and use them to construct an undirected graph. From there, we define trending and emerging issues based on the topological properties of each transcript. W
    
[^208]: LiMAML: 通过元学习个性化深度推荐模型

    LiMAML: Personalization of Deep Recommender Models via Meta Learning

    [https://arxiv.org/abs/2403.00803](https://arxiv.org/abs/2403.00803)

    该论文介绍了一种通过元学习实现个性化深度推荐模型的创新解决方案，能够根据最新用户互动信号频繁更新模型，以确保向不同成员提供相关且更新的体验。

    

    在推荐系统领域，深度神经网络的普遍采用已经成为建模各种业务目标的主导范式。随着用户基数的持续增长，个性化和频繁的模型更新的必要性已经变得至关重要，以确保向各种成员提供相关且更新的体验。在这项工作中，我们介绍了一种创新的元学习解决方案，用于针对个人成员和其他实体的模型个性化，结合了根据最新用户互动信号进行频繁更新的功能。具体来说，我们利用了模型无关的元学习（MAML）算法，使用最近的用户互动数据来调整每个任务的子网络。考虑到在线推荐系统中生产原始MAML模型几乎不可行，我们提出了一种有效的策略来将元学习的子网络推广应用到生产中。

    arXiv:2403.00803v1 Announce Type: cross  Abstract: In the realm of recommender systems, the ubiquitous adoption of deep neural networks has emerged as a dominant paradigm for modeling diverse business objectives. As user bases continue to expand, the necessity of personalization and frequent model updates have assumed paramount significance to ensure the delivery of relevant and refreshed experiences to a diverse array of members. In this work, we introduce an innovative meta-learning solution tailored to the personalization of models for individual members and other entities, coupled with the frequent updates based on the latest user interaction signals. Specifically, we leverage the Model-Agnostic Meta Learning (MAML) algorithm to adapt per-task sub-networks using recent user interaction data. Given the near infeasibility of productionizing original MAML-based models in online recommendation systems, we propose an efficient strategy to operationalize meta-learned sub-networks in prod
    
[^209]: 朝向理论理解两阶段推荐系统

    Towards a Theoretical Understanding of Two-Stage Recommender Systems

    [https://arxiv.org/abs/2403.00802](https://arxiv.org/abs/2403.00802)

    这里是中文总结出的一句话要点: 该论文研究了两阶段推荐系统的理论行为，证明了其向最佳推荐系统的强收敛性，同时揭示了它在输入特征的固有维度上实现更快收敛的特性。

    

    arXiv:2403.00802v1 公告类型:跨域 摘要:生产级推荐系统在在线媒体服务中广泛使用大规模语料库，包括Netflix、Pinterest和Amazon。这些系统通过学习用户和物品在低维空间中投影的嵌入、通过两阶段模型（两个深度神经网络）丰富推荐，这有助于它们的嵌入构建以预测与物品相关的用户反馈。尽管它在推荐中很受欢迎，但其理论行为仍未得到全面探讨。我们研究了两阶段推荐的渐近行为，这包括对最佳推荐系统的强收敛。我们建立了两阶段推荐的一些理论性质和统计保证。除了渐近行为，我们还展示了两阶段推荐系统通过依赖输入特征的固有维度实现更快的收敛。最后，我们通过数值方法展示

    arXiv:2403.00802v1 Announce Type: cross  Abstract: Production-grade recommender systems rely heavily on a large-scale corpus used by online media services, including Netflix, Pinterest, and Amazon. These systems enrich recommendations by learning users' and items' embeddings projected in a low-dimensional space with two-stage models (two deep neural networks), which facilitate their embedding constructs to predict users' feedback associated with items. Despite its popularity for recommendations, its theoretical behaviors remain comprehensively unexplored. We study the asymptotic behaviors of the two-stage recommender that entail a strong convergence to the optimal recommender system. We establish certain theoretical properties and statistical assurance of the two-stage recommender. In addition to asymptotic behaviors, we demonstrate that the two-stage recommender system attains faster convergence by relying on the intrinsic dimensions of the input features. Finally, we show numerically
    
[^210]: 借鉴人类思维过程的脑启发两阶段方法：通过模仿人类思维过程增强数学推理能力

    Brain-Inspired Two-Stage Approach: Enhancing Mathematical Reasoning by Imitating Human Thought Processes

    [https://arxiv.org/abs/2403.00800](https://arxiv.org/abs/2403.00800)

    通过模仿人类思维过程，在数学推理任务中提出的Brain方法实现了最先进的性能，并发现计划可以从自然语言、代码或形式语言中明确提取出来。

    

    虽然大型语言模型展示了在解决数学问题方面的新能力，但在复杂的多步数学推理任务中仍然存在挑战。为了提高模型在数学推理任务上的表现，先前的工作通过改进数据的质量和数量，在开源模型上进行了监督微调。在本文中，我们提出了一种名为Brain的新方法，通过使用前额叶模型生成计划，然后使用顶叶模型生成代码并执行以获得答案，来模仿人类思维过程以增强数学推理能力。首先，我们通过此方法与基于Code LLaMA 7B的模型相比实现了SOTA性能。其次，我们发现计划可以明确地从自然语言、代码或形式语言中提取出来。我们的代码和数据可以在https://github.com/cyzhh/Brain上公开获取。

    arXiv:2403.00800v1 Announce Type: cross  Abstract: Although large language models demonstrate emergent abilities in solving math word problems, there is a challenging task in complex multi-step mathematical reasoning tasks. To improve model performance on mathematical reasoning tasks, previous work has conducted supervised fine-tuning on open-source models by improving the quality and quantity of data. In this paper, we propose a novel approach, named Brain, to imitate human thought processes to enhance mathematical reasoning abilities, using the Frontal Lobe Model to generate plans, and then employing the Parietal Lobe Model to generate code and execute to obtain answers. First, we achieve SOTA performance in comparison with Code LLaMA 7B based models through this method. Secondly, we find that plans can be explicitly extracted from natural language, code, or formal language. Our code and data are publicly available at https://github.com/cyzhh/Brain.
    
[^211]: LLM在数学推理中数据能力边界的实证研究

    An Empirical Study of Data Ability Boundary in LLMs' Math Reasoning

    [https://arxiv.org/abs/2403.00799](https://arxiv.org/abs/2403.00799)

    通过确定最优路径集，本研究拓展了LLMs在数学推理任务中的能力边界，提出了一种监督数据策略，通过混合不同类型数据的最小最优集来累积增强模型能力，并实现了SOTA性能。

    

    大型语言模型(LLMs)正在展示对数学推理任务的新兴能力，人们越来越关注通过监督微调（SFT）增强开源LLMs的能力。本文旨在探讨一个通用的监督数据策略，以帮助优化和拓展数学推理能力。首先，我们通过识别推理路径的最优路径集确定推理路径增强的能力边界。其次，我们验证模型不同能力可以通过相应类型数据的最小最优集混合来累积增强，而我们的模型MMOS在更低的构建成本下实现了系列基础模型的SOTA性能。此外，我们指出GSM-HARD并不真正困难，当今的LLMs不再缺乏数值稳健性。此外，我们提供一个用于稳健性测试和教育应用的自动问题生成器。我们的代码和数据可公开获取。

    arXiv:2403.00799v1 Announce Type: cross  Abstract: Large language models (LLMs) are displaying emergent abilities for math reasoning tasks,and there is a growing attention on enhancing the ability of open-source LLMs through supervised fine-tuning (SFT).In this paper, we aim to explore a general data strategy for supervised data to help optimize and expand math reasoning ability.Firstly, we determine the ability boundary of reasoning paths augmentation by identifying these paths' minimal optimal set.Secondly, we validate that different abilities of the model can be cumulatively enhanced by Mix of Minimal Optimal Sets of corresponding types of data, while our models MMOS achieve SOTA performance on series base models under much lower construction costs.Besides, we point out GSM-HARD is not really hard and today's LLMs no longer lack numerical robustness.Also, we provide an Auto Problem Generator for robustness testing and educational applications.Our code and data are publicly available
    
[^212]: 用高斯过程增强均值回归时间序列预测：金融预测中的功能和增强数据结构

    Enhancing Mean-Reverting Time Series Prediction with Gaussian Processes: Functional and Augmented Data Structures in Financial Forecasting

    [https://arxiv.org/abs/2403.00796](https://arxiv.org/abs/2403.00796)

    本论文通过使用高斯过程在金融预测中探索功能和增强数据结构，提供了一种能够预测整个概率分布并进行长期预测的方法，对于准确预测和决策制定具有重要意义

    

    在这篇论文中，我们探讨了利用高斯过程（GPs）来预测具有潜在结构的均值回归时间序列，使用相对未被探索的功能和增强数据结构。虽然许多传统的预测方法专注于时间序列数据的短期动态，但GPs提供了潜力，不仅可以预测平均预测值，还可以预测未来轨迹上整个概率分布。这在金融环境中特别有益，因为如果不正确的波动率评估导致资本损失，仅准确的预测可能不足够。此外，在交易选择中，GPs允许预测多个夏普比率，考虑交易成本后进行调整，有助于决策。本研究中使用的功能数据表示通过利用过去几年的信息使得可以进行更长期的预测，即使预测脱离了当前年份。

    arXiv:2403.00796v1 Announce Type: cross  Abstract: In this paper, we explore the application of Gaussian Processes (GPs) for predicting mean-reverting time series with an underlying structure, using relatively unexplored functional and augmented data structures. While many conventional forecasting methods concentrate on the short-term dynamics of time series data, GPs offer the potential to forecast not just the average prediction but the entire probability distribution over a future trajectory. This is particularly beneficial in financial contexts, where accurate predictions alone may not suffice if incorrect volatility assessments lead to capital losses. Moreover, in trade selection, GPs allow for the forecasting of multiple Sharpe ratios adjusted for transaction costs, aiding in decision-making. The functional data representation utilized in this study enables longer-term predictions by leveraging information from previous years, even as the forecast moves away from the current year
    
[^213]: 用大语言模型执行自然语言描述的算法：一项研究

    Executing Natural Language-Described Algorithms with Large Language Models: An Investigation

    [https://arxiv.org/abs/2403.00795](https://arxiv.org/abs/2403.00795)

    大语言模型可以有效地执行用自然语言描述的程序，尤其是在不涉及大量数字计算的情况下。

    

    使用自然语言描述的计算机程序一直是计算机科学的追求。随着大语言模型（LLMs）展示出的增强自然语言理解能力的出现，这一目标的道路已经被阐明。本文旨在检验现有LLMs理解和执行自然语言中描述的算法的能力。我们从《算法导论》中选取了一个算法测试集，该书是一本包含许多代表性广泛使用的算法的知名教材。为了系统评估LLMs的代码执行能力，我们选择了30个算法，共生成了300个随机抽样实例，并评估了流行的LLMs是否能够理解和执行这些算法。我们的发现表明，特别是GPT-4等LLMs可以有效地执行用自然语言描述的程序，只要不涉及大量数字计算。

    arXiv:2403.00795v1 Announce Type: cross  Abstract: Executing computer programs described in natural language has long been a pursuit of computer science. With the advent of enhanced natural language understanding capabilities exhibited by large language models (LLMs), the path toward this goal has been illuminated. In this paper, we seek to examine the capacity of present-day LLMs to comprehend and execute algorithms outlined in natural language. We established an algorithm test set sourced from Introduction to Algorithm, a well-known textbook that contains many representative widely-used algorithms. To systematically assess LLMs' code execution abilities, we selected 30 algorithms, generated 300 random-sampled instances in total, and evaluated whether popular LLMs can understand and execute these algorithms. Our findings reveal that LLMs, notably GPT-4, can effectively execute programs described in natural language, as long as no heavy numeric computation is involved. We believe our f
    
[^214]: 认真对待幽默：利用不风趣的大型语言模型构建幽默数据集

    Getting Serious about Humor: Crafting Humor Datasets with Unfunny Large Language Models

    [https://arxiv.org/abs/2403.00794](https://arxiv.org/abs/2403.00794)

    利用大型语言模型生成合成数据，可以帮助改进幽默检测，特别是通过取消幽默元素来评估模型性能。

    

    幽默是人类认知和互动的基本要素。然而，尽管自然语言处理方面取得了近期进展，幽默检测仍然是一项具有挑战性的任务，这是因为幽默文本与类似非幽默文本的数据集稀缺。在我们的研究中，我们探讨了大型语言模型（LLMs）能否通过编辑文本生成用于幽默检测的合成数据。我们在现有人类数据集上对LLMs进行基准测试，并展示当前LLMs在“取消风趣”笑话方面显示出令人印象深刻的能力，这是由人类判断和幽默检测的下游任务衡量而得。我们将我们的方法扩展到了一个混合编码的英语-印地语幽默数据集，在那里我们发现GPT-4的合成数据被双语注释员高度评价，并为幽默分类器提供了具有挑战性的对抗性例子。

    arXiv:2403.00794v1 Announce Type: cross  Abstract: Humor is a fundamental facet of human cognition and interaction. Yet, despite recent advances in natural language processing, humor detection remains a challenging task that is complicated by the scarcity of datasets that pair humorous texts with similar non-humorous counterparts. In our work, we investigate whether large language models (LLMs), can generate synthetic data for humor detection via editing texts. We benchmark LLMs on an existing human dataset and show that current LLMs display an impressive ability to `unfun' jokes, as judged by humans and as measured on the downstream task of humor detection. We extend our approach to a code-mixed English-Hindi humor dataset, where we find that GPT-4's synthetic data is highly rated by bilingual annotators and provides challenging adversarial examples for humor classifiers.
    
[^215]: $\textit{L+M-24}$：在ACL 2024年为语言+分子构建数据集

    $\textit{L+M-24}$: Building a Dataset for Language + Molecules @ ACL 2024

    [https://arxiv.org/abs/2403.00791](https://arxiv.org/abs/2403.00791)

    这个论文介绍了$\textit{L+M-24}$数据集，该数据集专为ACL 2024年的语言+分子研讨会共享任务而设计，重点关注自然语言在分子设计中的三个关键优势：组合性、功能性和抽象性。

    

    语言-分子模型已成为分子发现和理解的一个激动人心的方向。然而，由于分子-语言对数据集的稀缺性，训练这些模型具有挑战性。目前已发布的数据集有以下几种类型：1) 小规模且从现有数据库中抓取，2) 大规模但嘈杂且通过在科学文献上执行实体链接来构建，3) 通过将属性预测数据集转换为自然语言使用模板而构建。在本文档中，我们详细介绍了为ACL 2024年的语言+分子研讨会共享任务创建的$\textit{L+M-24}$数据集。特别地，$\textit{L+M-24}$旨在集中关注自然语言在分子设计中的三项关键优势：组合性、功能性和抽象性。

    arXiv:2403.00791v1 Announce Type: cross  Abstract: Language-molecule models have emerged as an exciting direction for molecular discovery and understanding. However, training these models is challenging due to the scarcity of molecule-language pair datasets. At this point, datasets have been released which are 1) small and scraped from existing databases, 2) large but noisy and constructed by performing entity linking on the scientific literature, and 3) built by converting property prediction datasets to natural language using templates. In this document, we detail the $\textit{L+M-24}$ dataset, which has been created for the Language + Molecules Workshop shared task at ACL 2024. In particular, $\textit{L+M-24}$ is designed to focus on three key benefits of natural language in molecule design: compositionality, functionality, and abstraction.
    
[^216]: 利用音乐五度圆构建概念空间：基于音乐语法激活的方法

    Structuring Concept Space with the Musical Circle of Fifths by Utilizing Music Grammar Based Activations

    [https://arxiv.org/abs/2403.00790](https://arxiv.org/abs/2403.00790)

    提出了一种利用音乐语法调节尖峰神经网络激活的新颖方法，通过应用音乐理论中的和弦进行规则，展示了如何自然地跟随其他激活，最终将概念的映射结构化为音乐五度圆。

    

    在本文中，我们探讨了离散神经网络（如尖峰网络）的结构与钢琴曲的构成之间的有趣相似之处。虽然两者都涉及按顺序或并行激活的节点或音符，但后者受益于丰富的音乐理论，以指导有意义的组合。我们提出了一种新颖的方法，利用音乐语法来调节尖峰神经网络中的激活，允许将符号表示为吸引子。通过应用音乐理论中的和弦进行规则，我们展示了某些激活如何自然地跟随其他激活，类似于吸引的概念。此外，我们引入了调制音调的概念，以在网络内导航不同的吸引盆地。最终，我们展示了我们模型中概念的映射是由音乐五度圆构成的，突出了利用音乐理论的潜力。

    arXiv:2403.00790v1 Announce Type: cross  Abstract: In this paper, we explore the intriguing similarities between the structure of a discrete neural network, such as a spiking network, and the composition of a piano piece. While both involve nodes or notes that are activated sequentially or in parallel, the latter benefits from the rich body of music theory to guide meaningful combinations. We propose a novel approach that leverages musical grammar to regulate activations in a spiking neural network, allowing for the representation of symbols as attractors. By applying rules for chord progressions from music theory, we demonstrate how certain activations naturally follow others, akin to the concept of attraction. Furthermore, we introduce the concept of modulating keys to navigate different basins of attraction within the network. Ultimately, we show that the map of concepts in our model is structured by the musical circle of fifths, highlighting the potential for leveraging music theor
    
[^217]: PRECISE框架：基于GPT的文本以提高放射学报告的可读性、可靠性和可理解性，实现以患者为中心的护理

    PRECISE Framework: GPT-based Text For Improved Readability, Reliability, and Understandability of Radiology Reports For Patient-Centered Care

    [https://arxiv.org/abs/2403.00788](https://arxiv.org/abs/2403.00788)

    本研究提出并评估了PRECISE框架，利用GPT-4技术提供更易读的胸部X射线报告，以进一步提高放射学报告的可读性、可靠性和可理解性，有助于推动以患者为中心的护理。

    

    本研究介绍并评估了PRECISE框架，利用OpenAI的GPT-4来增强患者参与度，提供更清晰、更易读的六年级阅读水平的胸部X射线报告。该框架在500份报告上进行了测试，显示出在可读性、可靠性和可理解性方面的显著改进。统计分析证实了PRECISE方法的有效性，突显了其在促进健康决策中心的护理交付中的潜力。

    arXiv:2403.00788v1 Announce Type: cross  Abstract: This study introduces and evaluates the PRECISE framework, utilizing OpenAI's GPT-4 to enhance patient engagement by providing clearer and more accessible chest X-ray reports at a sixth-grade reading level. The framework was tested on 500 reports, demonstrating significant improvements in readability, reliability, and understandability. Statistical analyses confirmed the effectiveness of the PRECISE approach, highlighting its potential to foster patient-centric care delivery in healthcare decision-making.
    
[^218]: 利用BERT进行信息检索：调研、应用、资源和挑战

    Utilizing BERT for Information Retrieval: Survey, Applications, Resources, and Challenges

    [https://arxiv.org/abs/2403.00784](https://arxiv.org/abs/2403.00784)

    BERT的引入为信息检索领域带来了突破，研究者们将其应用于解决实际问题，并通过综合分析其在信息检索中的应用方法，为学术界和工业界提供了有益的参考。

    

    近年来，深度学习在解决各种自然语言处理（NLP）问题方面得到了显著增长。最初的深度学习模型受到它们顺序或单向性质的限制，因此难以捕捉文本输入之间的上下文关系。从变压器（BERT）中引入的双向编码器表征提供了变压器模型的强大编码器，可以理解更广泛的上下文，并在各种NLP任务中获得最先进的性能。这激发了研究人员和从业者将BERT应用于实际问题，如信息检索（IR）。因此，一项关注将预训练的变压器编码器如BERT应用于IR的普遍方法的综合分析的调查对学术界和工业界都有用。鉴于此，本调查重新审视了各种基于BERT的方法，涵盖了各种方法

    arXiv:2403.00784v1 Announce Type: cross  Abstract: Recent years have witnessed a substantial increase in the use of deep learning to solve various natural language processing (NLP) problems. Early deep learning models were constrained by their sequential or unidirectional nature, such that they struggled to capture the contextual relationships across text inputs. The introduction of bidirectional encoder representations from transformers (BERT) leads to a robust encoder for the transformer model that can understand the broader context and deliver state-of-the-art performance across various NLP tasks. This has inspired researchers and practitioners to apply BERT to practical problems, such as information retrieval (IR). A survey that focuses on a comprehensive analysis of prevalent approaches that apply pretrained transformer encoders like BERT to IR can thus be useful for academia and the industry. In light of this, we revisit a variety of BERT-based methods in this survey, cover a wid
    
[^219]: 论LLMs在规划中的作用：将LLMs嵌入规划图中

    On the Roles of LLMs in Planning: Embedding LLMs into Planning Graphs

    [https://arxiv.org/abs/2403.00783](https://arxiv.org/abs/2403.00783)

    通过将LLMs嵌入到图形规划中，本文研究了LLMs在现成规划框架中的作用，并提出了一种新颖的LLMs-based规划框架。

    

    计划合成旨在生成一系列动作或策略，将给定的初始状态转移到目标状态，提供的领域模型可以由专家设计或从训练数据或与世界的交互中学习。受大型语言模型（LLMs）的新兴规划能力的声称所吸引，提出了研究LLMs规划有效性的工作，而不考虑LLMs中现成规划技术的利用。本文旨在通过研究LLMs在现成规划框架中的作用进一步研究LLMs的规划能力洞察。为此，我们研究了将LLMs嵌入到众所周知的规划框架之一，基于图的规划中的有效性，提出了一种新颖的基于LLMs的规划框架，其中LLMs嵌入到两个级别的规划图中，即相互约束生成级别和约束解决级别。

    arXiv:2403.00783v1 Announce Type: new  Abstract: Plan synthesis aims to generate a course of actions or policies to transit given initial states to goal states, provided domain models that could be designed by experts or learnt from training data or interactions with the world. Intrigued by the claims of emergent planning capabilities in large language models (LLMs), works have been proposed to investigate the planning effectiveness of LLMs, without considering any utilization of off-the-shelf planning techniques in LLMs. In this paper, we aim to further study the insight of the planning capability of LLMs by investigating the roles of LLMs in off-the-shelf planning frameworks. To do this, we investigate the effectiveness of embedding LLMs into one of the well-known planning frameworks, graph-based planning, proposing a novel LLMs-based planning framework with LLMs embedded in two levels of planning graphs, i.e., mutual constraints generation level and constraints solving level. We emp
    
[^220]: Ploutos：基于金融大型语言模型实现可解释股票走势预测

    Ploutos: Towards interpretable stock movement prediction with financial large language model

    [https://arxiv.org/abs/2403.00782](https://arxiv.org/abs/2403.00782)

    提出了Ploutos，一个新型金融LLM框架，通过PloutosGen和PloutosGPT灵活融合文本和数值信息，提供可解释的股票走势预测

    

    大型语言模型（LLMs）的最新进展开辟了许多领域的新路径。然而，在金融投资领域中，LLMs 的完整潜力仍然大部分未被利用。对于量化金融的典型基于深度学习的方法有两个主要挑战。首先，它们在股票走势预测中灵活融合文本和数值信息上存在困难。其次，传统方法缺乏清晰性和可解释性，这妨碍了它们在需要预测理由的场景中的应用。为了解决上述挑战，我们提出了 Ploutos，一个由 PloutosGen 和 PloutosGPT 组成的新型金融LLM框架。PloutosGen 包含多个主要专家，可以分析不同的模态数据，如文本和数值，并从不同角度提供量化策略。然后 PloutosGPT 结合它们的见解和预测，生成可解释性的推理。

    arXiv:2403.00782v1 Announce Type: cross  Abstract: Recent advancements in large language models (LLMs) have opened new pathways for many domains. However, the full potential of LLMs in financial investments remains largely untapped. There are two main challenges for typical deep learning-based methods for quantitative finance. First, they struggle to fuse textual and numerical information flexibly for stock movement prediction. Second, traditional methods lack clarity and interpretability, which impedes their application in scenarios where the justification for predictions is essential. To solve the above challenges, we propose Ploutos, a novel financial LLM framework that consists of PloutosGen and PloutosGPT. The PloutosGen contains multiple primary experts that can analyze different modal data, such as text and numbers, and provide quantitative strategies from different perspectives. Then PloutosGPT combines their insights and predictions and generates interpretable rationales. To g
    
[^221]: ChatDiet：通过LLM增强框架赋能个性化营养导向食品推荐聊天机器人

    ChatDiet: Empowering Personalized Nutrition-Oriented Food Recommender Chatbots through an LLM-Augmented Framework

    [https://arxiv.org/abs/2403.00781](https://arxiv.org/abs/2403.00781)

    这项研究介绍了ChatDiet，一个借助LLM技术构建的框架，能够帮助个性化营养导向食品推荐聊天机器人提供个性化和可解释的推荐。

    

    食物对健康的深远影响使得先进的营养导向食品推荐服务成为必要。传统方法往往缺乏个性化、可解释性和互动性等关键元素。虽然大型语言模型（LLMs）带来了解释性和可解释性，但它们单独的使用未能实现真正的个性化。本文介绍了ChatDiet，一种新颖的LLM驱动框架，专门设计用于个性化营养导向食品推荐聊天机器人。ChatDiet集成了个人和人群模型，辅以一个协调器，无缝检索和处理相关信息。其结果是动态提供个性化和可解释的食品推荐，根据个人用户喜好定制。我们对ChatDiet进行了评估，包括一个引人入胜的案例研究，在案例研究中建立了一个因果个人模型来估计个人营养效果。

    arXiv:2403.00781v1 Announce Type: cross  Abstract: The profound impact of food on health necessitates advanced nutrition-oriented food recommendation services. Conventional methods often lack the crucial elements of personalization, explainability, and interactivity. While Large Language Models (LLMs) bring interpretability and explainability, their standalone use falls short of achieving true personalization. In this paper, we introduce ChatDiet, a novel LLM-powered framework designed specifically for personalized nutrition-oriented food recommendation chatbots. ChatDiet integrates personal and population models, complemented by an orchestrator, to seamlessly retrieve and process pertinent information. The result is a dynamic delivery of personalized and explainable food recommendations, tailored to individual user preferences. Our evaluation of ChatDiet includes a compelling case study, where we establish a causal personal model to estimate individual nutrition effects. Our assessmen
    
[^222]: 对犯罪预测数据挖掘技术的实证和实验洞见：综合调查

    Empirical and Experimental Insights into Data Mining Techniques for Crime Prediction: A Comprehensive Survey

    [https://arxiv.org/abs/2403.00780](https://arxiv.org/abs/2403.00780)

    这篇论文提供了对犯罪预测技术的全面分析，提出了一种细分犯罪预测算法的方法论分类法，并通过经验和实验评估来对这些技术进行排名。

    

    这篇综述论文全面分析了犯罪预测方法论，探讨了在该领域中应用的各种技术和技术。该论文涵盖了用于分析犯罪数据的统计方法、机器学习算法和深度学习技术，同时还审视了它们的有效性和局限性。我们提出了一种将犯罪预测算法分类为特定技术的方法论分类法。该分类法分为四个层次，包括方法论类别、方法论子类别、方法论技术和方法论技术子类别。提供了经验和实验评估以对不同技术进行排名。经验评估根据四个标准评估了犯罪预测技术，而实验评估则对采用相同子技术的算法、采用相同技术的不同子技术、以及相同技术的不同算法进行排名。

    arXiv:2403.00780v1 Announce Type: cross  Abstract: This survey paper presents a comprehensive analysis of crime prediction methodologies, exploring the various techniques and technologies utilized in this area. The paper covers the statistical methods, machine learning algorithms, and deep learning techniques employed to analyze crime data, while also examining their effectiveness and limitations. We propose a methodological taxonomy that classifies crime prediction algorithms into specific techniques. This taxonomy is structured into four tiers, including methodology category, methodology sub-category, methodology techniques, and methodology sub-techniques. Empirical and experimental evaluations are provided to rank the different techniques. The empirical evaluation assesses the crime prediction techniques based on four criteria, while the experimental evaluation ranks the algorithms that employ the same sub-technique, the different sub-techniques that employ the same technique, the d
    
[^223]: 微博平台专家在预测股市方面表现更好吗？

    Do Weibo platform experts perform better at predicting stock market?

    [https://arxiv.org/abs/2403.00772](https://arxiv.org/abs/2403.00772)

    使用神经网络结合BERT情感分类和LSTM时间序列模型在微博平台授权和未授权金融顾问的背景下进行股市预测

    

    情感分析可用于股市预测。然而，现有研究尚未研究用户的金融背景对基于情感的人工神经网络股市预测的影响。本文使用一种新颖的神经网络组合来评估基于人群金融背景的情感股市预测。采用最先进的语言处理模型BERT来分类情感，并使用长短期记忆（LSTM）模型进行基于时间序列的股市预测。评估时，使用微博社交网络平台作为情感数据收集来源。根据其背景，将微博用户（及其评论）分为授权金融顾问（AFA）和未授权金融顾问（UFA）两组。

    arXiv:2403.00772v1 Announce Type: cross  Abstract: Sentiment analysis can be used for stock market prediction. However, existing research has not studied the impact of a user's financial background on sentiment-based forecasting of the stock market using artificial neural networks. In this work, a novel combination of neural networks is used for the assessment of sentiment-based stock market prediction, based on the financial background of the population that generated the sentiment. The state-of-the-art language processing model Bidirectional Encoder Representations from Transformers (BERT) is used to classify the sentiment and a Long-Short Term Memory (LSTM) model is used for time-series based stock market prediction. For evaluation, the Weibo social networking platform is used as a sentiment data collection source. Weibo users (and their comments respectively) are divided into Authorized Financial Advisor (AFA) and Unauthorized Financial Advisor (UFA) groups according to their backg
    
[^224]: 一种用于Webots的无人监控容器化(深度)强化学习体系结构

    An Architecture for Unattended Containerized (Deep) Reinforcement Learning with Webots

    [https://arxiv.org/abs/2403.00765](https://arxiv.org/abs/2403.00765)

    该论文提出了一种用于Webots的无人监控容器化(深度)强化学习体系结构，针对机器人 Robotino 训练强化学习代理，同时强调模拟环境和数据科学家模型开发环境的分离这一不太被讨论的主题。

    

    随着数据科学应用在各行各业中得到采用，工具景观不断成熟，以促进这类应用的生命周期并提供解决方案，以应对涉及的挑战，以提高参与者的生产力。在3D世界中使用代理进行强化学习仍然可能面临挑战：使用模拟软件所需的知识以及在无人监控的训练管道中利用独立的模拟软件。在本文中，我们回顾了用于在3D世界中培训机器人的强化学习代理的工具和方法，针对机器人Robotino进行论述，并认为为虚拟世界的创建者分离模拟环境与数据科学家的模型开发环境并不是一个被很好涵盖的主题。通常二者相同，数据科学家需要了解模拟软件，直接与其API一起使用。此外，有时虚拟世界的创建者会......

    arXiv:2403.00765v1 Announce Type: cross  Abstract: As data science applications gain adoption across industries, the tooling landscape matures to facilitate the life cycle of such applications and provide solutions to the challenges involved to boost the productivity of the people involved. Reinforcement learning with agents in a 3D world could still face challenges: the knowledge required to use a simulation software as well as the utilization of a standalone simulation software in unattended training pipelines.   In this paper we review tools and approaches to train reinforcement learning agents for robots in 3D worlds with respect to the robot Robotino and argue that the separation of the simulation environment for creators of virtual worlds and the model development environment for data scientists is not a well covered topic. Often both are the same and data scientists require knowledge of the simulation software to work directly with their APIs. Moreover, sometimes creators of vir
    
[^225]: 基于动态图神经网络实现异构纳米卫星星座自主合作

    Toward Autonomous Cooperation in Heterogeneous Nanosatellite Constellations Using Dynamic Graph Neural Networks

    [https://arxiv.org/abs/2403.00692](https://arxiv.org/abs/2403.00692)

    使用动态图神经网络模型和启发式算法，以解决地球观测任务中异构纳米卫星星座自主合作中的全球卫星通信安排问题

    

    arXiv:2403.00692v1 公告类型:跨领域 摘要:未来地球观测任务的格局将由要求满足严格任务需求，如重访时间和空间分辨率的网络异构纳米卫星星座所定义。然而，通过有效地创建全球卫星接触计划（CP）来安排卫星通信是一个复杂的任务，当前解决方案要求地面协调或受到机载计算资源的限制。该论文提出了一种新颖的方法，通过将星座和CP建模为动态网络，并应用基于图的技术来克服这些挑战。所提出的方法利用最先进的动态图神经网络来评估给定CP的性能，并使用基于模拟退火的启发式算法来更新它。训练好的神经网络可以以平均绝对误差3.6分钟来预测网络延迟。

    arXiv:2403.00692v1 Announce Type: cross  Abstract: The upcoming landscape of Earth Observation missions will defined by networked heterogeneous nanosatellite constellations required to meet strict mission requirements, such as revisit times and spatial resolution. However, scheduling satellite communications in these satellite networks through efficiently creating a global satellite Contact Plan (CP) is a complex task, with current solutions requiring ground-based coordination or being limited by onboard computational resources. The paper proposes a novel approach to overcome these challenges by modeling the constellations and CP as dynamic networks and employing graph-based techniques. The proposed method utilizes a state-of-the-art dynamic graph neural network to evaluate the performance of a given CP and update it using a heuristic algorithm based on simulated annealing. The trained neural network can predict the network delay with a mean absolute error of 3.6 minutes. Simulation re
    
[^226]: ROME: 大型语言模型中文本、概率和隐藏状态的记忆洞察

    ROME: Memorization Insights from Text, Probability and Hidden State in Large Language Models

    [https://arxiv.org/abs/2403.00510](https://arxiv.org/abs/2403.00510)

    ROME提出了一种新方法，通过比较记忆和非记忆样本之间的差异，探索大型语言模型中的记忆化，这有助于在不访问训练数据的情况下了解模型记忆的洞察和影响因素。

    

    探究大型语言模型的记忆化具有重要意义。先前的研究建立了用于量化记忆的指标，探讨了各种影响因素，如数据复制、模型大小和提示长度，并通过将模型输出与训练语料库进行比较来评估记忆化。然而，训练语料库规模巨大且其预处理耗时。为了在不访问训练数据的情况下探索记忆化，我们提出了一种名为ROME的新方法，在此方法中，通过比较记忆化和非记忆化样本之间的差异来探索记忆化。具体来说，模型首先将选定的样本分为记忆化和非记忆化组，并通过文本、概率和隐藏状态的见解比较这两组中的演示。实验结果显示包括词长、词性、词频、均值和方差在内的因素的差异。

    arXiv:2403.00510v1 Announce Type: cross  Abstract: Probing the memorization of large language models holds significant importance. Previous works have established metrics for quantifying memorization, explored various influencing factors, such as data duplication, model size, and prompt length, and evaluated memorization by comparing model outputs with training corpora. However, the training corpora are of enormous scale and its pre-processing is time-consuming. To explore memorization without accessing training data, we propose a novel approach, named ROME, wherein memorization is explored by comparing disparities across memorized and non-memorized. Specifically, models firstly categorize the selected samples into memorized and non-memorized groups, and then comparing the demonstrations in the two groups from the insights of text, probability, and hidden state. Experimental findings show the disparities in factors including word length, part-of-speech, word frequency, mean and varianc
    
[^227]: 关于语言模型中地理表示的规模定律研究

    On the Scaling Laws of Geographical Representation in Language Models

    [https://arxiv.org/abs/2402.19406](https://arxiv.org/abs/2402.19406)

    地理知识可以在大型语言模型中观察到，随着模型规模增加而一致扩展，但更大的模型无法消除训练数据中的地理偏见。

    

    语言模型长期以来被证明在其隐藏表示中嵌入了地理信息。最近的一项研究将这一结果扩展到了大型语言模型(LLMs)。本文通过观察语言模型规模扩大时地理知识的演化，提出填补现有和最近文献之间的空白。我们展示了即使对于微小模型，地理知识也是可观测的，并且随着模型大小的增加而一致扩展。值得注意的是，我们发现更大的语言模型无法消除训练数据中固有的地理偏见。

    arXiv:2402.19406v1 Announce Type: cross  Abstract: Language models have long been shown to embed geographical information in their hidden representations. This line of work has recently been revisited by extending this result to Large Language Models (LLMs). In this paper, we propose to fill the gap between well-established and recent literature by observing how geographical knowledge evolves when scaling language models. We show that geographical knowledge is observable even for tiny models, and that it scales consistently as we increase the model size. Notably, we observe that larger language models cannot mitigate the geographical bias that is inherent to the training data.
    
[^228]: 如何理解“支持”？一种隐式增强因果推断方法用于弱监督短语定位

    How to Understand "Support"? An Implicit-enhanced Causal Inference Approach for Weakly-supervised Phrase Grounding

    [https://arxiv.org/abs/2402.19116](https://arxiv.org/abs/2402.19116)

    提出了一种隐式增强因果推断方法（IECI），用于解决弱监督短语定位任务中的挑战，通过标注高质量数据集进行评估，并相比基线方法展现出明显优势。

    

    弱监督短语定位（WPG）是一个新兴的任务，用于推断细粒度短语-区域匹配，仅利用粗粒度的句子-图像对进行训练。然而，现有关于WPG的研究很大程度上忽略了隐式短语-区域匹配关系，这对于评估模型理解深层多模态语义的能力至关重要。为此，本文提出了一种隐式增强因果推断（IECI）方法来解决对建模隐式关系和突出显性关系的挑战。具体而言，该方法分别利用干预和反事实技术来应对上述两个挑战。此外，还标注了一个高质量的隐式增强数据集来评估IECI，详细评估显示IECI相比最先进基线方法有很大优势。特别地，我们观察到了一个有趣的发现。

    arXiv:2402.19116v1 Announce Type: cross  Abstract: Weakly-supervised Phrase Grounding (WPG) is an emerging task of inferring the fine-grained phrase-region matching, while merely leveraging the coarse-grained sentence-image pairs for training. However, existing studies on WPG largely ignore the implicit phrase-region matching relations, which are crucial for evaluating the capability of models in understanding the deep multimodal semantics. To this end, this paper proposes an Implicit-Enhanced Causal Inference (IECI) approach to address the challenges of modeling the implicit relations and highlighting them beyond the explicit. Specifically, this approach leverages both the intervention and counterfactual techniques to tackle the above two challenges respectively. Furthermore, a high-quality implicit-enhanced dataset is annotated to evaluate IECI and detailed evaluations show the great advantages of IECI over the state-of-the-art baselines. Particularly, we observe an interesting findi
    
[^229]: 光谱遇见空间: 和谐3D形状匹配和插值

    Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation

    [https://arxiv.org/abs/2402.18920](https://arxiv.org/abs/2402.18920)

    该研究提出了一个统一的框架，结合光谱和空间域的映射，以预测3D形状之间的点对应和形状插值，相比先前方法，取得更准确、平滑的点对应结果，并且在计算上更高效。

    

    虽然3D形状匹配和插值密切相关，但它们经常被分开研究并依次应用于关联不同的3D形状，从而导致性能不佳。在这项工作中，我们提出了一个统一的框架，用于预测3D形状之间的点对应和形状插值。为此，我们将深度功能映射框架与经典表面变形模型结合起来，以在光谱和空间域中映射形状。一方面，通过整合空间映射，我们的方法相对于先前用于形状匹配的功能映射方法获得更精确和平滑的点对应。另一方面，通过引入光谱映射，我们的方法摆脱了通常使用但计算昂贵的仅对近等距形状变形有效的测地距离约束。

    arXiv:2402.18920v1 Announce Type: cross  Abstract: Although 3D shape matching and interpolation are highly interrelated, they are often studied separately and applied sequentially to relate different 3D shapes, thus resulting in sub-optimal performance. In this work we present a unified framework to predict both point-wise correspondences and shape interpolation between 3D shapes. To this end, we combine the deep functional map framework with classical surface deformation models to map shapes in both spectral and spatial domains. On the one hand, by incorporating spatial maps, our method obtains more accurate and smooth point-wise correspondences compared to previous functional map methods for shape matching. On the other hand, by introducing spectral maps, our method gets rid of commonly used but computationally expensive geodesic distance constraints that are only valid for near-isometric shape deformations. Furthermore, we propose a novel test-time adaptation scheme to capture both 
    
[^230]: 数据解释器：用于数据科学的LLM代理

    Data Interpreter: An LLM Agent For Data Science

    [https://arxiv.org/abs/2402.18679](https://arxiv.org/abs/2402.18679)

    本研究引入了数据解释器，采用动态规划、工具集成和逻辑错误识别等关键技术，旨在增强数据科学中的问题解决能力。

    

    大型语言模型（LLM）代理已表现出显著的有效性。然而，在需要实时数据调整、优化专业知识以应对各种任务间复杂依赖性以及精确推理的逻辑错误识别的数据科学场景中，它们的性能可能会受到影响。本研究介绍了数据解释器，这是一个设计用于解决强调三种关键技术以增强数据科学中问题解决的方案的代码：1）具有分层图结构的动态规划，用于实时数据适应性；2）工具集成动态化，以增强代码执行过程中的熟练度，丰富必要的专业知识；3）在反馈中识别逻辑不一致性，并通过经验记录来提高效率。我们评估了数据解释器在各种数据科学和现实任务上的表现。与开源基线相比，它展现了s

    arXiv:2402.18679v1 Announce Type: new  Abstract: Large Language Model (LLM)-based agents have demonstrated remarkable effectiveness. However, their performance can be compromised in data science scenarios that require real-time data adjustment, expertise in optimization due to complex dependencies among various tasks, and the ability to identify logical errors for precise reasoning. In this study, we introduce the Data Interpreter, a solution designed to solve with code that emphasizes three pivotal techniques to augment problem-solving in data science: 1) dynamic planning with hierarchical graph structures for real-time data adaptability;2) tool integration dynamically to enhance code proficiency during execution, enriching the requisite expertise;3) logical inconsistency identification in feedback, and efficiency enhancement through experience recording. We evaluate the Data Interpreter on various data science and real-world tasks. Compared to open-source baselines, it demonstrated s
    
[^231]: 在分享扩散模型中探讨隐私和公平风险：一种对抗性视角

    Exploring Privacy and Fairness Risks in Sharing Diffusion Models: An Adversarial Perspective

    [https://arxiv.org/abs/2402.18607](https://arxiv.org/abs/2402.18607)

    本文从对抗性的角度研究了分享扩散模型可能存在的隐私和公平风险，特别是探讨了在一方使用私人数据训练模型后提供给另一方黑盒访问权限的情况。

    

    扩散模型近年来在学术界和工业界引起了广泛关注，因为其在采样质量和分布覆盖方面表现出色。因此，提出了跨不同组织分享预训练扩散模型的建议，以提高数据利用率同时通过避免直接分享私人数据来增强隐私保护。然而，与这种方法相关的潜在风险尚未得到全面调查。本文从对抗性的角度探讨了与分享扩散模型相关的潜在隐私和公平风险。具体而言，我们调查了一方（分享者）使用私人数据训练扩散模型并向另一方（接收者）提供预训练模型的黑盒访问权限用于下游任务的情况。我们展示了分享者可以实行的行动

    arXiv:2402.18607v1 Announce Type: cross  Abstract: Diffusion models have recently gained significant attention in both academia and industry due to their impressive generative performance in terms of both sampling quality and distribution coverage. Accordingly, proposals are made for sharing pre-trained diffusion models across different organizations, as a way of improving data utilization while enhancing privacy protection by avoiding sharing private data directly. However, the potential risks associated with such an approach have not been comprehensively examined.   In this paper, we take an adversarial perspective to investigate the potential privacy and fairness risks associated with the sharing of diffusion models. Specifically, we investigate the circumstances in which one party (the sharer) trains a diffusion model using private data and provides another party (the receiver) black-box access to the pre-trained model for downstream tasks. We demonstrate that the sharer can execut
    
[^232]: 探究大型语言模型对推荐系统的影响：一项广泛综述

    Exploring the Impact of Large Language Models on Recommender Systems: An Extensive Review

    [https://arxiv.org/abs/2402.18590](https://arxiv.org/abs/2402.18590)

    大型语言模型在推荐系统中展现出卓越的推荐能力和语言理解，重塑了推荐任务的基础。

    

    该论文强调了大型语言模型（LLMs）在重塑推荐系统中的重要性，将它们的价值归因于传统推荐系统所缺乏的独特推理能力。不同于缺乏直接用户互动数据的传统系统，LLMs在推荐物品方面表现出卓越的能力，展示了它们在理解语言复杂性方面的熟练程度。这标志着推荐领域的一个根本性范式转变。在充满活力的研究领域中，研究人员积极利用LLMs的语言理解和生成能力重新定义推荐任务的基础。该研究彻底探讨了LLMs在推荐框架内固有的优势，包括细致的语境理解，跨不同领域的平稳过渡，采用统一的方法，利用共享数据池的全面学习策略，透明度

    arXiv:2402.18590v1 Announce Type: cross  Abstract: The paper underscores the significance of Large Language Models (LLMs) in reshaping recommender systems, attributing their value to unique reasoning abilities absent in traditional recommenders. Unlike conventional systems lacking direct user interaction data, LLMs exhibit exceptional proficiency in recommending items, showcasing their adeptness in comprehending intricacies of language. This marks a fundamental paradigm shift in the realm of recommendations. Amidst the dynamic research landscape, researchers actively harness the language comprehension and generation capabilities of LLMs to redefine the foundations of recommendation tasks. The investigation thoroughly explores the inherent strengths of LLMs within recommendation frameworks, encompassing nuanced contextual comprehension, seamless transitions across diverse domains, adoption of unified approaches, holistic learning strategies leveraging shared data reservoirs, transparent
    
[^233]: 众包是否让您破产了？使用近端策略优化对预训练语言模型进行成本效益微调

    Is Crowdsourcing Breaking Your Bank? Cost-Effective Fine-Tuning of Pre-trained Language Models with Proximal Policy Optimization

    [https://arxiv.org/abs/2402.18284](https://arxiv.org/abs/2402.18284)

    提出了一种自监督文本排序方法，利用近端策略优化对语言模型进行微调，消除了对人工注释员的需求，实验结果表明该方法训练的模型在各项得分方面明显优于基线

    

    ChatGPT的广泛使用凸显了从人类反馈中进行强化学习的潜力。然而，其训练流程依赖于人工排序，这是一个资源密集型的过程。为了降低劳动成本，我们提出了一种自监督文本排序方法，用于应用近端策略优化来对语言模型进行微调，同时消除了对人工注释员的需求。我们的方法从概率抽样开始，鼓励语言模型为每个输入生成多样化的响应。然后，我们使用TextRank和ISODATA算法，基于语义对这些响应进行排序和聚类。随后，我们构建了一个奖励模型来学习排名并优化我们的生成策略。我们在三个任务上使用两个语言模型进行的实验结果表明，我们的方法训练的模型在BLEU、GLEU和METEOR得分方面明显优于基线。此外，我们的手动评估显示

    arXiv:2402.18284v1 Announce Type: cross  Abstract: Wide usage of ChatGPT has highlighted the potential of reinforcement learning from human feedback. However, its training pipeline relies on manual ranking, a resource-intensive process. To reduce labor costs, we propose a self-supervised text ranking approach for applying Proximal-Policy-Optimization to fine-tune language models while eliminating the need for human annotators. Our method begins with probabilistic sampling to encourage a language model to generate diverse responses for each input. We then employ TextRank and ISODATA algorithms to rank and cluster these responses based on their semantics. Subsequently, we construct a reward model to learn the rank and optimize our generative policy. Our experimental results, conducted using two language models on three tasks, demonstrate that the models trained by our method considerably outperform baselines regarding BLEU, GLEU, and METEOR scores. Furthermore, our manual evaluation show
    
[^234]: Lemur: 使用熵抽样和思维链合并进行日志解析

    Lemur: Log Parsing with Entropy Sampling and Chain-of-Thought Merging

    [https://arxiv.org/abs/2402.18205](https://arxiv.org/abs/2402.18205)

    Lemur提出了一种先进的日志解析框架，采用熵抽样和思维链合并，解决了日志解析中存在的人工规则依赖和语义信息忽略等问题。

    

    大型软件系统产生的日志对监视系统行为至关重要。先进的日志分析有助于检测、报警和诊断系统故障。日志解析是日志分析自动化的关键阶段，它涉及将原始日志消息转换为结构化模板。现有的日志解析器由于依赖于人工制定的规则而无法识别正确的模板。此外，这些方法侧重于统计特征，而忽略了日志消息中的语义信息。为了解决这些挑战，我们提出了一种先进的日志解析框架，采用熵抽样和思维链合并（Lemur）。具体而言，为了摆脱繁琐的手动规则，我们提出了一种受信息熵启发的新型抽样方法，能够有效地对典型日志进行聚类。此外，为了增强日志模板的合并，我们设计了一种思维链方法。

    arXiv:2402.18205v1 Announce Type: cross  Abstract: Logs produced by extensive software systems are integral to monitoring system behaviors. Advanced log analysis facilitates the detection, alerting, and diagnosis of system faults. Log parsing, which entails transforming raw log messages into structured templates, constitutes a critical phase in the automation of log analytics. Existing log parsers fail to identify the correct templates due to reliance on human-made rules. Besides, These methods focus on statistical features while ignoring semantic information in log messages. To address these challenges, we introduce a cutting-edge \textbf{L}og parsing framework with \textbf{E}ntropy sampling and Chain-of-Thought \textbf{M}erging (Lemur). Specifically, to discard the tedious manual rules. We propose a novel sampling method inspired by information entropy, which efficiently clusters typical logs. Furthermore, to enhance the merging of log templates, we design a chain-of-thought method f
    
[^235]: Mixer不仅仅是一个模型

    Mixer is more than just a model

    [https://arxiv.org/abs/2402.18007](https://arxiv.org/abs/2402.18007)

    Mixer的创新之处在于将通道和令牌信息融合，代表了信息提取范式，还可以根据不同需求创建更适合特定任务的混合器。

    

    最近，MLP结构重新受到关注，其中MLP-Mixer以其突出的表现脱颖而出。在计算机视觉领域，MLP-Mixer以从通道和令牌两个角度提取数据信息的能力而闻名，有效地作为通道信息和令牌信息的融合。事实上，Mixer代表了一种信息提取范式，将通道和令牌信息融合在一起。Mixer的精髓在于它能够从多元视角融合信息，典型地体现了在神经网络架构领域的“混合”真正概念。除了考虑通道和令牌以外，可以从各种角度创造更贴合特定任务需求的混合器。本研究专注于音频识别领域，引入一种名为带Roll-Time和Hermit FFT的音频频谱混合器(ASM-RH)的创新模型，该模型结合了对时间和频率的洞察。

    arXiv:2402.18007v1 Announce Type: cross  Abstract: Recently, MLP structures have regained popularity, with MLP-Mixer standing out as a prominent example. In the field of computer vision, MLP-Mixer is noted for its ability to extract data information from both channel and token perspectives, effectively acting as a fusion of channel and token information. Indeed, Mixer represents a paradigm for information extraction that amalgamates channel and token information. The essence of Mixer lies in its ability to blend information from diverse perspectives, epitomizing the true concept of "mixing" in the realm of neural network architectures. Beyond channel and token considerations, it is possible to create more tailored mixers from various perspectives to better suit specific task requirements. This study focuses on the domain of audio recognition, introducing a novel model named Audio Spectrogram Mixer with Roll-Time and Hermit FFT (ASM-RH) that incorporates insights from both time and freq
    
[^236]: REPrune：通过核代表选择进行通道修剪

    REPrune: Channel Pruning via Kernel Representative Selection

    [https://arxiv.org/abs/2402.17862](https://arxiv.org/abs/2402.17862)

    REPrune是一种新颖的通道修剪技术，通过模拟核修剪，并结合聚类和滤波器选择，实现了更精细但结构化的修剪粒度，促进了在训练CNNs期间的高效、渐进式修剪。

    

    通道修剪被广泛认可为加速现代卷积神经网络（CNNs）的方法。所得到的修剪模型可以立即部署在通用软件和硬件资源上。然而，由于在卷积滤波器这个单元上的大修剪粒度，通常会导致不希望的准确性下降，这是由于在CNNs中决定如何以及在何处引入稀疏性的灵活性不足。在本文中，我们提出了REPrune，一种新颖的通道修剪技术，模拟了核修剪，充分利用了更细但有结构的粒度。REPrune使用凝聚聚类识别每个通道内的相似核。然后，它选择最大化包含核代表的滤波器，同时优化最大聚类覆盖问题。通过与同时训练-修剪范式相结合，REPrune促进了在训练CNNs期间的高效、渐进式修剪，避免了在训练期间的误差传播。

    arXiv:2402.17862v1 Announce Type: cross  Abstract: Channel pruning is widely accepted to accelerate modern convolutional neural networks (CNNs). The resulting pruned model benefits from its immediate deployment on general-purpose software and hardware resources. However, its large pruning granularity, specifically at the unit of a convolution filter, often leads to undesirable accuracy drops due to the inflexibility of deciding how and where to introduce sparsity to the CNNs. In this paper, we propose REPrune, a novel channel pruning technique that emulates kernel pruning, fully exploiting the finer but structured granularity. REPrune identifies similar kernels within each channel using agglomerative clustering. Then, it selects filters that maximize the incorporation of kernel representatives while optimizing the maximum cluster coverage problem. By integrating with a simultaneous training-pruning paradigm, REPrune promotes efficient, progressive pruning throughout training CNNs, avoi
    
[^237]: 当你的AI欺骗你：在奖励学习中人类评估者部分可观测性的挑战

    When Your AI Deceives You: Challenges with Partial Observability of Human Evaluators in Reward Learning

    [https://arxiv.org/abs/2402.17747](https://arxiv.org/abs/2402.17747)

    RLHF在考虑部分观察性时可能导致策略欺骗性地夸大性能或过度辩护行为，我们提出了数学条件来解决这些问题，并警告不要盲目应用RLHF在部分可观测情况下。

    

    强化学习从人类反馈（RLHF）的过去分析假设人类完全观察到环境。当人类反馈仅基于部分观察时会发生什么？我们对两种失败情况进行了正式定义：欺骗和过度辩护。通过将人类建模为对轨迹信念的Boltzmann-理性，我们证明了RLHF保证会导致策略欺骗性地夸大其性能、为了留下印象而过度辩护或者两者兼而有之的条件。为了帮助解决这些问题，我们数学地刻画了环境部分可观测性如何转化为（缺乏）学到的回报函数中的模糊性。在某些情况下，考虑环境部分可观测性使得在理论上可能恢复回报函数和最优策略，而在其他情况下，存在不可减少的模糊性。我们警告不要盲目应用RLHF在部分可观测情况下。

    arXiv:2402.17747v1 Announce Type: cross  Abstract: Past analyses of reinforcement learning from human feedback (RLHF) assume that the human fully observes the environment. What happens when human feedback is based only on partial observations? We formally define two failure cases: deception and overjustification. Modeling the human as Boltzmann-rational w.r.t. a belief over trajectories, we prove conditions under which RLHF is guaranteed to result in policies that deceptively inflate their performance, overjustify their behavior to make an impression, or both. To help address these issues, we mathematically characterize how partial observability of the environment translates into (lack of) ambiguity in the learned return function. In some cases, accounting for partial observability makes it theoretically possible to recover the return function and thus the optimal policy, while in other cases, there is irreducible ambiguity. We caution against blindly applying RLHF in partially observa
    
[^238]: LDB：通过逐步验证运行时执行来调试大型语言模型

    LDB: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step

    [https://arxiv.org/abs/2402.16906](https://arxiv.org/abs/2402.16906)

    LDB是一个新颖的调试框架，可以让大型语言模型通过运行时执行信息来完善生成的程序。

    

    大型语言模型（LLMs）在代码生成方面取得了重大进展。最近的研究不仅将单次代码生成，而且还将单元测试和程序验证器整合到LLMs中，以迭代地完善生成的程序。然而，这些工作将生成的程序视为不可分割的实体，这对LLMs在调试程序时存在不足，特别是当程序包含复杂的逻辑流程和数据操作时。相比之下，当人类开发人员调试程序时，他们通常设置断点并有选择地检查运行时执行信息。执行流和中间变量在调试过程中发挥着关键作用，然而现有的代码生成文献中未充分利用它们。本研究引入了大型语言模型调试器（LDB），这是一个新颖的调试框架，可以让LLMs通过运行时执行信息完善其生成的程序。

    arXiv:2402.16906v1 Announce Type: cross  Abstract: Large language models (LLMs) are leading significant progress in code generation. Beyond one-pass code generation, recent works further integrate unit tests and program verifiers into LLMs to iteratively refine the generated programs. However, these works consider the generated programs as an indivisible entity, which falls short for LLMs in debugging the programs, especially when the programs contain complex logic flows and data operations. In contrast, when human developers debug programs, they typically set breakpoints and selectively examine runtime execution information. The execution flow and the intermediate variables play a crucial role in the debugging process, yet they are underutilized in the existing literature on code generation. In this study, we introduce Large Language Model Debugger (LDB), a novel debugging framework that enables LLMs to refine their generated programs with the runtime execution information. Specifical
    
[^239]: 用系统自校正改进基于LLM的机器翻译

    Improving LLM-based Machine Translation with Systematic Self-Correction

    [https://arxiv.org/abs/2402.16379](https://arxiv.org/abs/2402.16379)

    引入了名为TER的系统LLM自校正翻译框架，成功帮助LLMs提高翻译质量，具有更优越的系统性和可解释性。

    

    大型语言模型（LLMs）在机器翻译（MT）领域取得了令人印象深刻的结果。然而，人工仔细评估发现，LLMs生成的翻译仍然包含多个错误。重要的是，将这种错误信息反馈到LLMs中可以实现自校正，并改善翻译性能。受到这些观点的启发，我们引入了一个名为TER的系统LLM自校正翻译框架，代表了在这一方向上的重要进展。我们的研究结果表明：1）我们的自校正框架成功地帮助LLMs提高了多种语言的翻译质量，不管是从高资源语言到低资源语言，还是以英语为中心还是围绕其他语言；2）TER相比先前的方法展示出更优越的系统性和可解释性；3）

    arXiv:2402.16379v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have achieved impressive results in Machine Translation (MT). However, careful evaluations by human reveal that the translations produced by LLMs still contain multiple errors. Importantly, feeding back such error information into the LLMs can lead to self-correction and result in improved translation performance. Motivated by these insights, we introduce a systematic LLM-based self-correcting translation framework, named TER, which stands for Translate, Estimate, and Refine, marking a significant step forward in this direction. Our findings demonstrate that 1) our self-correction framework successfully assists LLMs in improving their translation quality across a wide range of languages, whether it's from high-resource languages to low-resource ones or whether it's English-centric or centered around other languages; 2) TER exhibits superior systematicity and interpretability compared to previous methods; 3)
    
[^240]: 基于引文增强的LLM聊天机器人生成

    Citation-Enhanced Generation for LLM-based Chatbot

    [https://arxiv.org/abs/2402.16063](https://arxiv.org/abs/2402.16063)

    提出一种基于引文增强的LLM聊天机器人生成方法，采用检索模块搜索支持文档来解决幻觉内容产生的问题。

    

    大型语言模型（LLMs）在各种情景下展现出强大的通用智能，包括将它们集成到聊天机器人中。然而，基于LLM的聊天机器人面临的一个重要挑战是在回复中可能产生虚构内容，这严重限制了它们的适用性。本文提出了一种新颖的后续引用增强生成（CEG）方法，结合检索论证。与先前侧重于预防生成过程中幻觉的研究不同，我们的方法以后续方式解决了这个问题。它结合了一个检索模块来搜索与生成内容相关的支持文档，并采用基于自然语言推理的方法。

    arXiv:2402.16063v1 Announce Type: cross  Abstract: Large language models (LLMs) exhibit powerful general intelligence across diverse scenarios, including their integration into chatbots. However, a vital challenge of LLM-based chatbots is that they may produce hallucinated content in responses, which significantly limits their applicability. Various efforts have been made to alleviate hallucination, such as retrieval augmented generation and reinforcement learning with human feedback, but most of them require additional training and data annotation. In this paper, we propose a novel post-hoc \textbf{C}itation-\textbf{E}nhanced \textbf{G}eneration (\textbf{CEG}) approach combined with retrieval argumentation. Unlike previous studies that focus on preventing hallucinations during generation, our method addresses this issue in a post-hoc way. It incorporates a retrieval module to search for supporting documents relevant to the generated content, and employs a natural language inference-ba
    
[^241]: 在基础模型时代重新思考软件工程：可信基础模型软件开发中的挑战精选目录

    Rethinking Software Engineering in the Era of Foundation Models: A Curated Catalogue of Challenges in the Development of Trustworthy FMware

    [https://arxiv.org/abs/2402.15943](https://arxiv.org/abs/2402.15943)

    FMware的独特属性和基础模型的内在限制导致了新的软件工程挑战，本文总结了这些挑战并提出了创新路径。

    

    Foundation模型（FMs），如大型语言模型（LLMs），通过实现新的用例和商业模型，彻底改变了软件开发。我们将使用FMs构建的软件称为FMware。FMware的独特属性（例如提示、代理和编排的需求），与FMs的内在限制（例如幻觉）结合起来，导致了一系列全新的软件工程挑战。根据我们的工业经验，我们确定了10个关键的SE4FMware挑战，导致企业FMware开发变得低效、成本高昂且风险高。在本文中，我们详细讨论了这些挑战，并阐明了我们设想的创新路径。接下来，我们提出了FMArts，这是我们为构建可信FMware而进行的长期努力。最后，我们展示了FMArts的独特属性如何使我们能够为一种大型FMware设计和开发一个复杂系统。

    arXiv:2402.15943v1 Announce Type: cross  Abstract: Foundation models (FMs), such as Large Language Models (LLMs), have revolutionized software development by enabling new use cases and business models. We refer to software built using FMs as FMware. The unique properties of FMware (e.g., prompts, agents, and the need for orchestration), coupled with the intrinsic limitations of FMs (e.g., hallucination) lead to a completely new set of software engineering challenges. Based on our industrial experience, we identified 10 key SE4FMware challenges that have caused enterprise FMware development to be unproductive, costly, and risky. In this paper, we discuss these challenges in detail and state the path for innovation that we envision. Next, we present FMArts, which is our long-term effort towards creating a cradle-to-grave platform for the engineering of trustworthy FMware. Finally, we (i) show how the unique properties of FMArts enabled us to design and develop a complex FMware for a larg
    
[^242]: LLMs能够以实用的方式自我防御越狱攻击：一份展望文章

    LLMs Can Defend Themselves Against Jailbreaking in a Practical Manner: A Vision Paper

    [https://arxiv.org/abs/2402.15727](https://arxiv.org/abs/2402.15727)

    本文提出了一种名为SELFDEFEND的轻量级实用防御方法，可以在最小延迟下抵御所有现有的越狱攻击。

    

    越狱是一种新兴的敌对攻击，可以绕过现有的大型语言模型（LLMs）中部署的安全机制。已有大量研究提出了更有效的越狱攻击方法，包括最近的贪婪坐标梯度（GCG）攻击、基于越狱模板的攻击，例如使用“Do-Anything-Now”（DAN），以及多语言越狱。相比之下，防御方面的研究相对较少。本文提出了一种轻量而实用的防御方法，称为SELFDEFEND，可以抵御所有现有的越狱攻击，在越狱提示方面几乎没有延迟，对于正常用户提示也只有微不足道的延迟。我们的主要见解是，无论使用何种越狱策略，最终都需要在发送给LLMs的提示中包含有害提示（例如“如何制造炸弹”），我们发现现有的LLMs可以有效识别违反安全规则的有害提示。

    arXiv:2402.15727v1 Announce Type: cross  Abstract: Jailbreaking is an emerging adversarial attack that bypasses the safety alignment deployed in off-the-shelf large language models (LLMs). A considerable amount of research exists proposing more effective jailbreak attacks, including the recent Greedy Coordinate Gradient (GCG) attack, jailbreak template-based attacks such as using "Do-Anything-Now" (DAN), and multilingual jailbreak. In contrast, the defensive side has been relatively less explored. This paper proposes a lightweight yet practical defense called SELFDEFEND, which can defend against all existing jailbreak attacks with minimal delay for jailbreak prompts and negligible delay for normal user prompts. Our key insight is that regardless of the kind of jailbreak strategies employed, they eventually need to include a harmful prompt (e.g., "how to make a bomb") in the prompt sent to LLMs, and we found that existing LLMs can effectively recognize such harmful prompts that violate 
    
[^243]: 从脑信号解码查询语义的查询扩展

    Query Augmentation by Decoding Semantics from Brain Signals

    [https://arxiv.org/abs/2402.15708](https://arxiv.org/abs/2402.15708)

    提出了一种名为Brain-Aug的方法，通过从脑信号中解码的语义信息增强查询，可以生成更准确的查询，改善文档排序性能，特别适用于模糊查询。

    

    查询扩展是用于细化语义不准确查询的关键技术。传统上，查询扩展依赖于从最初检索到的、潜在相关的文档中提取信息。如果最初检索到的文档质量较低，则查询扩展的有效性也会受到限制。我们提出了Brain-Aug，通过将从脑信号解码的语义信息结合到查询中来增强查询。Brain-Aug使用了在脑信号信息构建的提示和面向排名的推理方法生成原始查询的延续部分。对fMRI数据集的实验结果显示，Brain-Aug生成的查询在语义上更准确，导致改进的文档排序性能。脑信号带来的这种改进对于模糊查询特别显著。

    arXiv:2402.15708v1 Announce Type: cross  Abstract: Query augmentation is a crucial technique for refining semantically imprecise queries. Traditionally, query augmentation relies on extracting information from initially retrieved, potentially relevant documents. If the quality of the initially retrieved documents is low, then the effectiveness of query augmentation would be limited as well. We propose Brain-Aug, which enhances a query by incorporating semantic information decoded from brain signals. BrainAug generates the continuation of the original query with a prompt constructed with brain signal information and a ranking-oriented inference approach. Experimental results on fMRI (functional magnetic resonance imaging) datasets show that Brain-Aug produces semantically more accurate queries, leading to improved document ranking performance. Such improvement brought by brain signals is particularly notable for ambiguous queries.
    
[^244]: 超关系知识图中消息传递的关系交互式方法

    A Relation-Interactive Approach for Message Passing in Hyper-relational Knowledge Graphs

    [https://arxiv.org/abs/2402.15140](https://arxiv.org/abs/2402.15140)

    提出了一种消息传递的图编码器ReSaE，具有全局关系结构意识能力，强调了关系在消息传递过程中的交互，并优化了用于链接预测任务的读取结构，在超关系知识图上表现出色。

    

    超关系知识图包含额外的键值对，提供关于关系的更多信息。在许多情况下，相同的关系可以具有不同的键值对，使原始三元组事实更具识别性和特定性。先前关于超关系知识图的研究已经建立了一种稳固的超关系图编码方法。在这项工作中，我们提出了一种具有全局关系结构意识能力的基于消息传递的图编码器，我们称之为ReSaE。与先前的最先进方法相比，ReSaE强调了在消息传递过程中关系的交互，并优化了用于链接预测任务的读取结构。总体而言，ReSaE为超关系知识图提供了一种编码解决方案，并确保在下游链接预测任务上具有更强的性能。我们的实验表明，ReSaE在多个链接预测基准上实现了最先进的性能。

    arXiv:2402.15140v1 Announce Type: new  Abstract: Hyper-relational knowledge graphs (KGs) contain additional key-value pairs, providing more information about the relations. In many scenarios, the same relation can have distinct key-value pairs, making the original triple fact more recognizable and specific. Prior studies on hyper-relational KGs have established a solid standard method for hyper-relational graph encoding. In this work, we propose a message-passing-based graph encoder with global relation structure awareness ability, which we call ReSaE. Compared to the prior state-of-the-art approach, ReSaE emphasizes the interaction of relations during message passing process and optimizes the readout structure for link prediction tasks. Overall, ReSaE gives a encoding solution for hyper-relational KGs and ensures stronger performance on downstream link prediction tasks. Our experiments demonstrate that ReSaE achieves state-of-the-art performance on multiple link prediction benchmarks.
    
[^245]: OmniPred：语言模型作为通用回归器

    OmniPred: Language Models as Universal Regressors

    [https://arxiv.org/abs/2402.14547](https://arxiv.org/abs/2402.14547)

    本文提出了OmniPred框架，用于训练语言模型作为通用的端到端回归器，实验证明，在多个任务上训练时，语言模型能够显著优于传统回归模型。

    

    在实验设计的广阔领域中，回归一直是一个强大的工具，可以准确预测系统或模型在给定一组参数的情况下的结果指标，但传统上只限于适用于特定任务的方法。在本文中，我们提出了OmniPred，这是一个用于训练语言模型作为通用端到端回归器的框架，使用来自多样真实世界实验的$(x,y)$评估数据。通过使用源自Google Vizier的数据，这是世界上最大的黑盒优化数据库之一，我们的大量实验表明，仅通过数学参数和值的文本表示，语言模型能够进行非常精确的数值回归，如果有机会训练多个任务，则可以显著优于传统的回归模型。

    arXiv:2402.14547v1 Announce Type: cross  Abstract: Over the broad landscape of experimental design, regression has been a powerful tool to accurately predict the outcome metrics of a system or model given a set of parameters, but has been traditionally restricted to methods which are only applicable to a specific task. In this paper, we propose OmniPred, a framework for training language models as universal end-to-end regressors over $(x,y)$ evaluation data from diverse real world experiments. Using data sourced from Google Vizier, one of the largest blackbox optimization databases in the world, our extensive experiments demonstrate that through only textual representations of mathematical parameters and values, language models are capable of very precise numerical regression, and if given the opportunity to train over multiple tasks, can significantly outperform traditional regression models.
    
[^246]: 在复杂环境中的碰撞感知电缆抓取方法

    A Collision-Aware Cable Grasping Method in Cluttered Environment

    [https://arxiv.org/abs/2402.14498](https://arxiv.org/abs/2402.14498)

    提出了一种碰撞感知的电缆抓取方法，通过CG-CNN和数据集生成技术，在复杂环境中实现稳健电缆抓取，并取得了出色的成功率。

    

    我们介绍了一种专为在复杂环境中实现稳健电缆抓取而设计的碰撞感知卷积神经网络。利用物理仿真，我们生成一个大量数据集，模拟了电缆抓取的复杂性，考虑到电缆与机器人夹爪之间的潜在碰撞。我们使用近似凸分解技术来分析非凸电缆模型，根据模拟抓取尝试自动标记抓取质量。利用这个模拟数据集对CG-CNN进行了改进，并通过域随机化技术增强。随后，训练好的模型预测抓取质量，并将最佳抓取姿势指导给机器人控制器执行。我们评估了抓取效果在合成和真实世界设置下的表现。由于我们模型隐式的碰撞敏感性，我们取得了出色的成功率，对于已知电缆为92.3%，对于未知电缆为88.4%，超越了c。

    arXiv:2402.14498v1 Announce Type: cross  Abstract: We introduce a Cable Grasping-Convolutional Neural Network designed to facilitate robust cable grasping in cluttered environments. Utilizing physics simulations, we generate an extensive dataset that mimics the intricacies of cable grasping, factoring in potential collisions between cables and robotic grippers. We employ the Approximate Convex Decomposition technique to dissect the non-convex cable model, with grasp quality autonomously labeled based on simulated grasping attempts. The CG-CNN is refined using this simulated dataset and enhanced through domain randomization techniques. Subsequently, the trained model predicts grasp quality, guiding the optimal grasp pose to the robot controller for execution. Grasping efficacy is assessed across both synthetic and real-world settings. Given our model implicit collision sensitivity, we achieved commendable success rates of 92.3% for known cables and 88.4% for unknown cables, surpassing c
    
[^247]: E2USD：用于多元时间序列的高效而有效的无监督状态检测

    E2USD: Efficient-yet-effective Unsupervised State Detection for Multivariate Time Series

    [https://arxiv.org/abs/2402.14041](https://arxiv.org/abs/2402.14041)

    E2USD提出了一种有效的无监督多元时间序列状态检测方法，利用了快速傅里叶变换和双视图嵌入模块进行编码，以及通过对抗学习方法消除假阴性，从而实现了SOTA准确性并显著降低了计算开销。

    

    我们提出了E2USD方法，能够实现高效而准确的无监督多元时间序列状态检测。E2USD利用基于快速傅立叶变换的时间序列压缩器(FFTCompress)和分解的双视图嵌入模块(DDEM)，一起以低计算开销对输入的多元时间序列进行编码。此外，我们提出了一种假阴性取消对比学习方法(FNCCLearning)，以抵消假阴性的影响，并实现更友好的簇嵌入空间。为了在流式设置中进一步减少计算开销，我们引入了自适应阈值检测(ADATD)。通过使用六个基线模型和六个数据集进行全面实验，我们证明E2USD能够在显著降低计算开销的情况下达到SOTA的准确性。我们的代码可在https://github.com/AI4CTS/E2Usd 找到。

    arXiv:2402.14041v1 Announce Type: cross  Abstract: We propose E2USD that enables efficient-yet-accurate unsupervised MTS state detection. E2USD exploits a Fast Fourier Transform-based Time Series Compressor (FFTCompress) and a Decomposed Dual-view Embedding Module (DDEM) that together encode input MTSs at low computational overhead. Additionally, we propose a False Negative Cancellation Contrastive Learning method (FNCCLearning) to counteract the effects of false negatives and to achieve more cluster-friendly embedding spaces. To reduce computational overhead further in streaming settings, we introduce Adaptive Threshold Detection (ADATD). Comprehensive experiments with six baselines and six datasets offer evidence that E2USD is capable of SOTA accuracy at significantly reduced computational overhead. Our code is available at https://github.com/AI4CTS/E2Usd.
    
[^248]: SDXL-Lightning: 渐进式对抗性扩散蒸馏

    SDXL-Lightning: Progressive Adversarial Diffusion Distillation

    [https://arxiv.org/abs/2402.13929](https://arxiv.org/abs/2402.13929)

    提出了一种结合渐进和对抗性蒸馏的扩散蒸馏方法，在文本到图像生成任务中取得了新的最先进结果，并开源了相应模型。

    

    我们提出了一种扩散蒸馏方法，在基于SDXL的一步/几步1024像素文本到图像生成任务中实现了全新的最先进水平。我们的方法结合了渐进和对抗性蒸馏，实现了质量和模式覆盖之间的平衡。本文讨论了理论分析、判别器设计、模型公式和训练技巧。我们以LoRA和完整UNet权重的形式开源了我们的蒸馏SDXL-Lightning模型。

    arXiv:2402.13929v1 Announce Type: cross  Abstract: We propose a diffusion distillation method that achieves new state-of-the-art in one-step/few-step 1024px text-to-image generation based on SDXL. Our method combines progressive and adversarial distillation to achieve a balance between quality and mode coverage. In this paper, we discuss the theoretical analysis, discriminator design, model formulation, and training techniques. We open-source our distilled SDXL-Lightning models both as LoRA and full UNet weights.
    
[^249]: NeuralDiffuser：具有主视觉特征引导扩散的可控fMRI重建

    NeuralDiffuser: Controllable fMRI Reconstruction with Primary Visual Feature Guided Diffusion

    [https://arxiv.org/abs/2402.13809](https://arxiv.org/abs/2402.13809)

    NeuralDiffuser引入主视觉特征引导，扩展了LDM方法的自下而上过程，以实现忠实的语义和细节。

    

    基于潜在扩散模型(LDM)从功能性磁共振成像(fMRI)中重建视觉刺激，为大脑提供了细粒度的检索。一个挑战在于重建细节的连贯对齐（如结构、背景、纹理、颜色等）。此外，即使在相同条件下，LDM也会生成不同的图像结果。因此，我们首先揭示了基于LDM的神经科学视角，即基于来自海量图像的预训练知识进行自上而下的创建，但缺乏基于细节驱动的自下而上感知，导致细节不忠实。我们提出了NeuralDiffuser，引入主视觉特征引导，以渐变形式提供细节线索，扩展了LDM方法的自下而上过程，以实现忠实的语义和细节。我们还开发了一种新颖的引导策略，以确保重复重建的一致性，而不是随机性。

    arXiv:2402.13809v1 Announce Type: cross  Abstract: Reconstructing visual stimuli from functional Magnetic Resonance Imaging (fMRI) based on Latent Diffusion Models (LDM) provides a fine-grained retrieval of the brain. A challenge persists in reconstructing a cohesive alignment of details (such as structure, background, texture, color, etc.). Moreover, LDMs would generate different image results even under the same conditions. For these, we first uncover the neuroscientific perspective of LDM-based methods that is top-down creation based on pre-trained knowledge from massive images but lack of detail-driven bottom-up perception resulting in unfaithful details. We propose NeuralDiffuser which introduces primary visual feature guidance to provide detail cues in the form of gradients, extending the bottom-up process for LDM-based methods to achieve faithful semantics and details. We also developed a novel guidance strategy to ensure the consistency of repeated reconstructions rather than a
    
[^250]: DSLR：多样性增强和结构学习用于基于重播的图持续学习

    DSLR: Diversity Enhancement and Structure Learning for Rehearsal-based Graph Continual Learning

    [https://arxiv.org/abs/2402.13711](https://arxiv.org/abs/2402.13711)

    DSLR提出了一种基于覆盖范围的多样性方法，以解决基于重播的图持续学习中回放节点过于集中导致过拟合和灾难性遗忘的问题。

    

    我们研究了基于重播方法中回放缓冲区对图持续学习（GCL）方法的影响。现有的基于重播的GCL方法为每个类别选择最具代表性的节点并将它们存储在重播缓冲区中，以供在训练后续任务时使用。然而，我们发现，仅考虑每个回放节点的类别代表性会使回放节点集中在每个类别的中心周围，可能存在过拟合于位于那些区域的节点的风险，从而加剧灾难性遗忘。此外，由于基于重播方法严重依赖于少数回放节点来保留从先前任务中获得的知识，涉及在模型训练中具有不相关邻居的回放节点可能对模型性能产生显着的负面影响。在本文中，我们提出了一种名为DSLR的GCL模型，具体来说，我们设计了一种基于覆盖范围的多样性（CD）

    arXiv:2402.13711v1 Announce Type: cross  Abstract: We investigate the replay buffer in rehearsal-based approaches for graph continual learning (GCL) methods. Existing rehearsal-based GCL methods select the most representative nodes for each class and store them in a replay buffer for later use in training subsequent tasks. However, we discovered that considering only the class representativeness of each replayed node makes the replayed nodes to be concentrated around the center of each class, incurring a potential risk of overfitting to nodes residing in those regions, which aggravates catastrophic forgetting. Moreover, as the rehearsal-based approach heavily relies on a few replayed nodes to retain knowledge obtained from previous tasks, involving the replayed nodes that have irrelevant neighbors in the model training may have a significant detrimental impact on model performance. In this paper, we propose a GCL model named DSLR, specifically, we devise a coverage-based diversity (CD)
    
[^251]: NeRF解决了MRI重建中的欠采样问题

    NeRF Solves Undersampled MRI Reconstruction

    [https://arxiv.org/abs/2402.13226](https://arxiv.org/abs/2402.13226)

    NeRF技术利用神经辐射场概念解决了MRI重建中的欠采样问题，通过神经表示从欠采样的$k$-space数据中得到高维MR图像，并研究了有效的欠采样策略。

    

    本文提出了一种利用神经辐射场（NeRF）概念的新型欠采样磁共振成像（MRI）技术。通过径向欠采样，相应的成像问题可以从稀疏视图渲染数据中重塑为图像建模任务；因此，通过利用隐式神经表示，可以从欠采样的$k$-space数据中获得高维MR图像。设计了一个多层感知器，用于从空间坐标输出图像强度，该多层感知器学习了给定测量数据和期望图像之间的MR物理驱动渲染关系。研究了用于高质量神经表示的有效欠采样策略。所提出的方法具有两个优点：(i) 学习完全基于单个欠采样的$k$-space数据，而不是一堆测量数据和目标图像集。它可能用于诊断性MR成像，例如胎儿

    arXiv:2402.13226v1 Announce Type: cross  Abstract: This article presents a novel undersampled magnetic resonance imaging (MRI) technique that leverages the concept of Neural Radiance Field (NeRF). With radial undersampling, the corresponding imaging problem can be reformulated into an image modeling task from sparse-view rendered data; therefore, a high dimensional MR image is obtainable from undersampled $k$-space data by taking advantage of implicit neural representation. A multi-layer perceptron, which is designed to output an image intensity from a spatial coordinate, learns the MR physics-driven rendering relation between given measurement data and desired image. Effective undersampling strategies for high-quality neural representation are investigated. The proposed method serves two benefits: (i) The learning is based fully on single undersampled $k$-space data, not a bunch of measured data and target image sets. It can be used potentially for diagnostic MR imaging, such as fetal
    
[^252]: 基于大型语言模型的模态感知集成用于基于知识的视觉问答

    Modality-Aware Integration with Large Language Models for Knowledge-based Visual Question Answering

    [https://arxiv.org/abs/2402.12728](https://arxiv.org/abs/2402.12728)

    提出了一种模态感知的LLM集成方法（MAIL）用于针对KVQA，通过细致地利用多模态知识来处理图像理解和知识推理。

    

    知识驱动的视觉问答（KVQA）已被广泛研究，以利用外部知识如知识图谱（KG）来回答视觉问题。尽管已提出几种尝试利用大型语言模型（LLMs）作为隐含知识源，但由于LLMs可能生成幻觉，因此仍然具有挑战性。此外，多种知识来源，例如图像、知识图谱和LLMs，不能轻易对齐以应对复杂场景。为了解决这些问题，我们提出了一种针对KVQA的新颖的具有模态感知的LLM集成方法（MAIL）。它精心利用多模态知识进行图像理解和知识推理。具体而言，（i）我们提出了一种使用LLMs的两阶段提示策略，将图像密集地融入带有详细视觉特征的场景图中；（ii）我们通过将提到的实体与外部事实联系起来构建一个耦合的概念图；（iii）设计了一个定制的伪孪生图中介融合。

    arXiv:2402.12728v1 Announce Type: cross  Abstract: Knowledge-based visual question answering (KVQA) has been extensively studied to answer visual questions with external knowledge, e.g., knowledge graphs (KGs). While several attempts have been proposed to leverage large language models (LLMs) as an implicit knowledge source, it remains challenging since LLMs may generate hallucinations. Moreover, multiple knowledge sources, e.g., images, KGs and LLMs, cannot be readily aligned for complex scenarios. To tackle these, we present a novel modality-aware integration with LLMs for KVQA (MAIL). It carefully leverages multimodal knowledge for both image understanding and knowledge reasoning. Specifically, (i) we propose a two-stage prompting strategy with LLMs to densely embody the image into a scene graph with detailed visual features; (ii) We construct a coupled concept graph by linking the mentioned entities with external facts. (iii) A tailored pseudo-siamese graph medium fusion is designe
    
[^253]: PAC-FNO：并行结构全组分傅立叶神经算子用于识别低质量图像

    PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images

    [https://arxiv.org/abs/2402.12721](https://arxiv.org/abs/2402.12721)

    提出了一个新颖的神经网络模型 PAC-FNO，通过在频域操作可以处理不同分辨率的图像，解决了传统方法在处理这类问题上的计算成本高的挑战。

    

    开发图像识别模型的标准做法是在特定图像分辨率上训练模型，然后部署它。然而，在现实推理中，模型经常遇到与训练集中不同分辨率的图像和/或受到自然变化的影响，例如天气变化、噪声类型和压缩伪影。传统解决方案涉及为不同分辨率或输入变化训练多个模型，但这些方法在实践中计算成本高，因此不可扩展。为此，我们提出了一种新颖的神经网络模型，即并行结构和全组分傅立叶神经算子（PAC-FNO），来解决这个问题。与传统的前馈神经网络不同，PAC-FNO在频域进行操作，使其能够在单个模型内处理不同分辨率的图像。我们还提出了一个两阶段算法，以最小的修改训练PAC-FNO。

    arXiv:2402.12721v1 Announce Type: cross  Abstract: A standard practice in developing image recognition models is to train a model on a specific image resolution and then deploy it. However, in real-world inference, models often encounter images different from the training sets in resolution and/or subject to natural variations such as weather changes, noise types and compression artifacts. While traditional solutions involve training multiple models for different resolutions or input variations, these methods are computationally expensive and thus do not scale in practice. To this end, we propose a novel neural network model, parallel-structured and all-component Fourier neural operator (PAC-FNO), that addresses the problem. Unlike conventional feed-forward neural networks, PAC-FNO operates in the frequency domain, allowing it to handle images of varying resolutions within a single model. We also propose a two-stage algorithm for training PAC-FNO with a minimal modification to the orig
    
[^254]: 基于Transformer的因果语言模型执行聚类

    Transformer-based Causal Language Models Perform Clustering

    [https://arxiv.org/abs/2402.12151](https://arxiv.org/abs/2402.12151)

    Transformer-based因果语言模型通过在隐藏空间内对数据进行聚类来学习任务特定信息，这种聚类过程在学习中动态演变，并有助于处理未见实例。

    

    即使大型语言模型(LLMs)已经展示出在解决各种自然语言任务方面的出色能力，LLM遵循人类指令的能力仍然是一个问题。最近的研究通过额外训练指令遵循任务已经显示出很大改进，然而，导致有效指令遵循能力的机制仍未得到充分理解。本文介绍了一个简化的指令遵循任务，并使用合成数据集分析了基于Transformer的因果语言模型。我们的发现表明，模型通过在其隐藏空间内对数据进行聚类而学习任务特定信息，这种聚类过程在学习过程中动态演变。我们还演示了这种现象如何帮助模型处理未见实例，并在更现实的环境中验证了我们的结果。

    arXiv:2402.12151v1 Announce Type: cross  Abstract: Even though large language models (LLMs) have demonstrated remarkable capability in solving various natural language tasks, the capability of an LLM to follow human instructions is still a concern. Recent works have shown great improvements in the instruction-following capability via additional training for instruction-following tasks. However, the mechanisms responsible for effective instruction-following capabilities remain inadequately understood. Here, we introduce a simplified instruction-following task and use synthetic datasets to analyze a Transformer-based causal language model. Our findings suggest that the model learns task-specific information by clustering data within its hidden space, with this clustering process evolving dynamically during learning. We also demonstrate how this phenomenon assists the model in handling unseen instances and validate our results in a more realistic setting.
    
[^255]: 从实际到逻辑再到实际：为规划从原始数据中发明符号词汇、动作和模型

    From Reals to Logic and Back: Inventing Symbolic Vocabularies, Actions and Models for Planning from Raw Data

    [https://arxiv.org/abs/2402.11871](https://arxiv.org/abs/2402.11871)

    本文提出了一种从未标记高维实值机器人轨迹开始自主学习通用的逻辑相关表示，这些表示构成了自动发明的PDDL-like域模型。

    

    手工制作的基于逻辑的状态和动作表示已被广泛用于克服长期人工智能机器人规划问题的计算复杂性，包括任务和动作规划问题。但是，创建这样的表示需要具有强烈直觉和详细知识的专家，他们了解机器人和在特定环境中可能需要完成的任务。消除对人类直觉的依赖是一个极为活跃的研究领域。 本文提出了一种自主学习通用逻辑相关表示的方法，该表示从未标记的高维实值机器人轨迹开始。所学表示构成了自动发明的类PDDL域模型。确定性设置下的实证结果表明，仅从少数机器人轨迹中可以学到强大的抽象表示；所学关系

    arXiv:2402.11871v1 Announce Type: cross  Abstract: Hand-crafted, logic-based state and action representations have been widely used to overcome the intractable computational complexity of long-horizon robot planning problems, including task and motion planning problems. However, creating such representations requires experts with strong intuitions and detailed knowledge about the robot and the tasks it may need to accomplish in a given setting. Removing this dependency on human intuition is a highly active research area.   This paper presents the first approach for autonomously learning generalizable, logic-based relational representations for abstract states and actions starting from unannotated high-dimensional, real-valued robot trajectories. The learned representations constitute auto-invented PDDL-like domain models. Empirical results in deterministic settings show that powerful abstract representations can be learned from just a handful of robot trajectories; the learned relation
    
[^256]: 对神经和神经符号方法在实时多模态复杂事件检测中的实证评估

    An Empirical Evaluation of Neural and Neuro-symbolic Approaches to Real-time Multimodal Complex Event Detection

    [https://arxiv.org/abs/2402.11403](https://arxiv.org/abs/2402.11403)

    本研究评估神经和神经符号方法在多模态复杂事件检测中的效果，特别关注时间推理，实验发现神经符号方法在较少数据下表现更好。

    

    Robots and autonomous systems require an understanding of complex events (CEs) from sensor data to interact with their environments and humans effectively. Traditional end-to-end neural architectures, despite processing sensor data efficiently, struggle with long-duration events due to limited context sizes and reasoning capabilities. Recent advances in neuro-symbolic methods, which integrate neural and symbolic models leveraging human knowledge, promise improved performance with less data. This study addresses the gap in understanding these approaches' effectiveness in complex event detection (CED), especially in temporal reasoning. We investigate neural and neuro-symbolic architectures' performance in a multimodal CED task, analyzing IMU and acoustic data streams to recognize CE patterns. Our methodology includes (i) end-to-end neural architectures for direct CE detection from sensor embeddings, (ii) two-stage concept-based neural mode

    arXiv:2402.11403v1 Announce Type: new  Abstract: Robots and autonomous systems require an understanding of complex events (CEs) from sensor data to interact with their environments and humans effectively. Traditional end-to-end neural architectures, despite processing sensor data efficiently, struggle with long-duration events due to limited context sizes and reasoning capabilities. Recent advances in neuro-symbolic methods, which integrate neural and symbolic models leveraging human knowledge, promise improved performance with less data. This study addresses the gap in understanding these approaches' effectiveness in complex event detection (CED), especially in temporal reasoning. We investigate neural and neuro-symbolic architectures' performance in a multimodal CED task, analyzing IMU and acoustic data streams to recognize CE patterns. Our methodology includes (i) end-to-end neural architectures for direct CE detection from sensor embeddings, (ii) two-stage concept-based neural mode
    
[^257]: 通过基于政策的自我判断来对齐大型语言模型

    Aligning Large Language Models by On-Policy Self-Judgment

    [https://arxiv.org/abs/2402.11253](https://arxiv.org/abs/2402.11253)

    本文提出了一个新颖的对齐框架SELF-JUDGE，通过增加式监督微调（JSFT）训练一个同时充当策略和评判器的单一模型，实现了参数高效的基于政策学习，无需额外的奖励模型。

    

    为了使大型语言模型与人类偏好保持一致，现有研究要么利用单独的奖励模型（RM）执行基于政策的学习，要么通过放弃基于政策的学习和对独立RM的需求简化训练过程。在本文中，我们提出了一个新颖的对齐框架SELF-JUDGE，它既是(1) 基于政策的学习，又是(2) 参数高效的，因为它不需要额外的RM来评估样本进行基于政策的学习。为此，我们提出了增强式监督微调（JSFT）来训练一个单一模型，作为策略和评判器。具体来说，我们将一对一判断任务视为指导式任务的特殊情况，从响应对中选择更好的响应。因此，得到的模型可以评判当前策略的即时响应偏好，从自身初始化。实验结果显示了SELF-JUDGE的有效性，优于基线模型。

    arXiv:2402.11253v1 Announce Type: cross  Abstract: To align large language models with human preferences, existing research either utilizes a separate reward model (RM) to perform on-policy learning or simplifies the training procedure by discarding the on-policy learning and the need for a separate RM. In this paper, we present a novel alignment framework, SELF-JUDGE that is (1) on-policy learning and 2) parameter efficient, as it does not require an additional RM for evaluating the samples for on-policy learning. To this end, we propose Judge-augmented Supervised Fine-Tuning (JSFT) to train a single model acting as both a policy and a judge. Specifically, we view the pairwise judgment task as a special case of the instruction-following task, choosing the better response from a response pair. Thus, the resulting model can judge preferences of on-the-fly responses from current policy initialized from itself. Experimental results show the efficacy of SELF-JUDGE, outperforming baselines 
    
[^258]: 加速半异步联邦学习

    Accelerating Semi-Asynchronous Federated Learning

    [https://arxiv.org/abs/2402.10991](https://arxiv.org/abs/2402.10991)

    提出了一种考虑贡献的异步联邦学习方法，动态调整接收到的更新的处理方式，以解决现实情况下同步上传数据可能出现的缓慢和不可靠问题。

    

    联邦学习（FL）是一种分布式机器学习范例，允许客户端在保护隐私的同时在其数据上训练模型。现有的FL算法，如Federated Averaging（FedAvg）及其变种，在许多情况下已经被证明收敛良好。然而，这些方法需要客户端以同步方式将其本地更新上传至服务器，这在现实情况下可能会变得缓慢和不可靠。为了解决这个问题，研究人员开发了异步FL方法，允许客户端继续使用陈旧的全局模型对其本地数据进行训练。然而，大多数这些方法仅仅聚合了所有接收到的更新，而没有考虑其相对贡献，这可能导致收敛速度变慢。在本文中，我们提出了一种考虑贡献的异步FL方法，考虑了接收到的更新的陈旧程度和统计异质性。我们的方法动态调整

    arXiv:2402.10991v1 Announce Type: cross  Abstract: Federated Learning (FL) is a distributed machine learning paradigm that allows clients to train models on their data while preserving their privacy. FL algorithms, such as Federated Averaging (FedAvg) and its variants, have been shown to converge well in many scenarios. However, these methods require clients to upload their local updates to the server in a synchronous manner, which can be slow and unreliable in realistic FL settings. To address this issue, researchers have developed asynchronous FL methods that allow clients to continue training on their local data using a stale global model. However, most of these methods simply aggregate all of the received updates without considering their relative contributions, which can slow down convergence. In this paper, we propose a contribution-aware asynchronous FL method that takes into account the staleness and statistical heterogeneity of the received updates. Our method dynamically adju
    
[^259]: MC-DBN：基于深度信念网络的模态补全模型

    MC-DBN: A Deep Belief Network-Based Model for Modality Completion

    [https://arxiv.org/abs/2402.09782](https://arxiv.org/abs/2402.09782)

    MC-DBN是一种基于深度信念网络的模态补全模型，利用完整数据的隐式特征来弥补附加不完整数据的差距，提高预测准确性。

    

    最近多模态人工智能（AI）的进展已经彻底改变了股市预测和心率监测领域。利用多样的数据源可以大大提高预测准确性。然而，额外的数据可能不总是与原始数据集相吻合。插值方法通常用于处理模态数据中的缺失值，但在稀疏信息情况下可能存在一些限制。为解决这一挑战，我们提出了一种模态补全的深度信念网络模型（MC-DBN）。该方法利用完整数据的隐式特征来弥补自身与附加不完整数据之间的差距。它确保增强的多模态数据与现实世界的动态特性密切相符，以提高模型的有效性。我们在两个来自股市预测和心率监测的数据集上对MC-DBN模型进行了评估。

    arXiv:2402.09782v1 Announce Type: cross  Abstract: Recent advancements in multi-modal artificial intelligence (AI) have revolutionized the fields of stock market forecasting and heart rate monitoring. Utilizing diverse data sources can substantially improve prediction accuracy. Nonetheless, additional data may not always align with the original dataset. Interpolation methods are commonly utilized for handling missing values in modal data, though they may exhibit limitations in the context of sparse information. Addressing this challenge, we propose a Modality Completion Deep Belief Network-Based Model (MC-DBN). This approach utilizes implicit features of complete data to compensate for gaps between itself and additional incomplete data. It ensures that the enhanced multi-modal data closely aligns with the dynamic nature of the real world to enhance the effectiveness of the model. We conduct evaluations of the MC-DBN model in two datasets from the stock market forecasting and heart rate
    
[^260]: 通过多重分形分析视角探索LLMs中的神经元相互作用和出现现象

    Exploring Neuron Interactions and Emergence in LLMs: From the Multifractal Analysis Perspective

    [https://arxiv.org/abs/2402.09099](https://arxiv.org/abs/2402.09099)

    该论文通过多重分形分析视角，深入研究了LLMs中神经元相互作用和出现现象。通过引入自组织和多重分形分析的概念，研究了神经元相互作用的动态演化过程，尤其关注训练中的复杂行为。通过提出基于神经元的多重分形分析方法，实现了对大型模型中神经元相互作用的定量分析。

    

    在以往的大型模型中，关于出现现象的研究主要集中在大型语言模型（LLMs）的功能能力如何随模型规模的扩大而增加。然而，我们的研究超越了这一传统范式，旨在通过不仅仅依赖于模型规模，而更加关注训练过程中神经元相互作用的复杂行为，加深我们对LLMs内部出现现象的理解。通过引入“自组织”和“多重分形分析”概念，我们探索了神经元相互作用在训练过程中如何动态演化，从而导致“出现现象”，这种现象反映了自然系统中简单的微观相互作用如何导致复杂的宏观行为。为了定量分析训练过程中大型模型中神经元之间不断演化的相互作用，我们提出了基于神经元的多重分形分析（NeuroMFA）。利用NeuroMFA，我们进行了一系列的实验

    arXiv:2402.09099v1 Announce Type: new Abstract: Prior studies on the emergence in large models have primarily focused on how the functional capabilities of large language models (LLMs) scale with model size. Our research, however, transcends this traditional paradigm, aiming to deepen our understanding of the emergence within LLMs by placing a special emphasis not just on the model size but more significantly on the complex behavior of neuron interactions during the training process. By introducing the concepts of "self-organization" and "multifractal analysis," we explore how neuron interactions dynamically evolve during training, leading to "emergence," mirroring the phenomenon in natural systems where simple micro-level interactions give rise to complex macro-level behaviors. To quantitatively analyze the continuously evolving interactions among neurons in large models during training, we propose the Neuron-based Multifractal Analysis (NeuroMFA). Utilizing NeuroMFA, we conduct a com
    
[^261]: 论据顺序在与大型语言模型推理中起作用

    Premise Order Matters in Reasoning with Large Language Models

    [https://arxiv.org/abs/2402.08939](https://arxiv.org/abs/2402.08939)

    对大型语言模型（LLMs）进行推理任务时，论据的顺序非常重要，尤其是在演绎推理任务中，按照提示的真实证明顺序呈现论据可以显著提高模型的准确性。

    

    大型语言模型（LLMs）在各个领域都取得了惊人的推理性能。然而，在推理任务的领域中，我们发现了一个脆弱性：尽管这种顺序不会改变基本任务，但LLMs对于论据的顺序非常脆弱。特别是，我们观察到当论据顺序与中间推理步骤所需的上下文对齐时，LLMs可以达到最佳性能。例如，在演绎推理任务中，将论据按照提示的真实证明顺序呈现（而不是随机顺序）会极大地提高模型的准确性。我们首先研究了不同LLMs对演绎推理中论据顺序的影响，我们的评估结果表明，调整论据顺序可能导致性能下降超过30％。此外，我们发布了基于GSM8K的基准测试R-GSM来研究顺序效应对数学推理的影响。

    arXiv:2402.08939v1 Announce Type: new Abstract: Large language models (LLMs) have accomplished remarkable reasoning performance in various domains. However, in the domain of reasoning tasks, we discover a frailty: LLMs are surprisingly brittle to the ordering of the premises, despite the fact that such ordering does not alter the underlying task. In particular, we observe that LLMs achieve the best performance when the premise order aligns with the context required in intermediate reasoning steps. For example, in deductive reasoning tasks, presenting the premises in the same order as the ground truth proof in the prompt (as opposed to random ordering) drastically increases the model's accuracy. We first examine the effect of premise ordering on deductive reasoning on a variety of LLMs, and our evaluation shows that permuting the premise order can cause a performance drop of over 30%. In addition, we release the benchmark R-GSM, based on GSM8K, to examine the ordering effect for mathema
    
[^262]: 通过机器学习在不断演化的知识图谱上预测高影响力的研究主题

    Forecasting high-impact research topics via machine learning on evolving knowledge graphs

    [https://arxiv.org/abs/2402.08640](https://arxiv.org/abs/2402.08640)

    通过机器学习预测未发布研究想法的影响力，我们使用一个由超过2100万篇科学论文构建的演化知识图谱，结合论文内容和历史引用的信息，高准确度预测未来的演化网络动态和新的研究方向的影响力。

    

    科学出版物的指数增长对人类研究者构成了严峻挑战。它迫使研究者将注意力集中在更狭窄的子领域上，使得发现其他领域的新颖且有影响力的研究想法和合作变得困难。虽然有办法预测科学论文未来的引用次数，但通常需要等到研究完成并且论文写成后才能进行评估，这样就错过了想法构思的早期阶段。在本文中，我们展示了如何预测从未被研究者发布的想法的影响力。为此，我们开发了一个大型的演化知识图谱，其中包含超过2100万篇科学论文。它结合了从论文内容中创建的语义网络和从历史引用中创建的影响网络。利用机器学习，我们可以高准确度地预测演化网络的动态情况，从而预测新的研究方向的影响力。我们预期这种能力将有助于研究者发现具有高影响力的研究主题。

    The exponential growth in scientific publications poses a severe challenge for human researchers. It forces attention to more narrow sub-fields, which makes it challenging to discover new impactful research ideas and collaborations outside one's own field. While there are ways to predict a scientific paper's future citation counts, they need the research to be finished and the paper written, usually assessing impact long after the idea was conceived. Here we show how to predict the impact of onsets of ideas that have never been published by researchers. For that, we developed a large evolving knowledge graph built from more than 21 million scientific papers. It combines a semantic network created from the content of the papers and an impact network created from the historic citations of papers. Using machine learning, we can predict the dynamic of the evolving network into the future with high accuracy, and thereby the impact of new research directions. We envision that the ability to 
    
[^263]: 递归协同模拟在游戏中的应用

    Recursive Joint Simulation in Games

    [https://arxiv.org/abs/2402.08128](https://arxiv.org/abs/2402.08128)

    本文研究了游戏中AI代理之间的递归协同模拟的互动方式，并证明了这种方式与原始游戏的无限重复版本在战略上是等价的。

    

    人工智能(AI)代理之间的博弈动态与传统的人-人互动可能存在各种不同之处。其中一个区别是可能能够准确地模拟AI代理，例如因为其源代码是已知的。我们的目标是探索利用这种可能性在战略设置中实现更合作的结果的方法。在本文中，我们研究了AI代理之间运行递归协同模拟的互动。即，代理首先共同观察他们所面对情境的模拟。这种模拟反过来递归地包括了额外的模拟（为了避免无限递归，具有小概率的失败），并且在选择行动之前观察所有这些嵌套模拟的结果。我们证明，由此产生的互动在战略上等价于原始游戏的无限重复版本，从而可以直接转移诸如各种民间定理等现有结果。

    Game-theoretic dynamics between AI agents could differ from traditional human-human interactions in various ways. One such difference is that it may be possible to accurately simulate an AI agent, for example because its source code is known. Our aim is to explore ways of leveraging this possibility to achieve more cooperative outcomes in strategic settings. In this paper, we study an interaction between AI agents where the agents run a recursive joint simulation. That is, the agents first jointly observe a simulation of the situation they face. This simulation in turn recursively includes additional simulations (with a small chance of failure, to avoid infinite recursion), and the results of all these nested simulations are observed before an action is chosen. We show that the resulting interaction is strategically equivalent to an infinitely repeated version of the original game, allowing a direct transfer of existing results such as the various folk theorems.
    
[^264]: 可扩展的多粒度融合网络用于基于方面的情感分析

    Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment Analysis

    [https://arxiv.org/abs/2402.07787](https://arxiv.org/abs/2402.07787)

    这篇论文提出了一种可扩展的多粒度融合网络（EMGF）用于基于方面的情感分析，通过整合不同的语言和结构特征，包括句法依赖、组成、注意力语义和外部知识图谱等，来提高情感分析的性能和准确性。

    

    基于方面的情感分析（ABSA）评估文本中的情感表达以理解情感信息。先前的研究整合了外部知识，如知识图谱，以加强ABSA模型中的语义特征。最近的研究探讨了在依赖和组成树上使用图神经网络（GNN）进行句法分析。随着ABSA的不断发展，越来越多的创新的语言和结构特征被融入其中（例如潜在图），但这也引入了复杂性和混淆。目前，尚不存在一个可扩展的框架，可以将多样性的语言和结构特征集成到ABSA中。本文介绍了可扩展的多粒度融合（EMGF）网络，它整合了来自句法依赖和组成、注意力语义和外部知识图谱的信息。EMGF配备了多锚点三元学习和正交投影，高效地利用了这些特征的综合潜力。

    Aspect-based Sentiment Analysis (ABSA) evaluates sentiment expressions within a text to comprehend sentiment information. Previous studies integrated external knowledge, such as knowledge graphs, to enhance the semantic features in ABSA models. Recent research has examined the use of Graph Neural Networks (GNNs) on dependency and constituent trees for syntactic analysis. With the ongoing development of ABSA, more innovative linguistic and structural features are being incorporated (e.g. latent graph), but this also introduces complexity and confusion. As of now, a scalable framework for integrating diverse linguistic and structural features into ABSA does not exist. This paper presents the Extensible Multi-Granularity Fusion (EMGF) network, which integrates information from dependency and constituent syntactic, attention semantic , and external knowledge graphs. EMGF, equipped with multi-anchor triplet learning and orthogonal projection, efficiently harnesses the combined potential of 
    
[^265]: CPSDBench：一个针对中国公共安全领域的大型语言模型评估基准和基线

    CPSDBench: A Large Language Model Evaluation Benchmark and Baseline for Chinese Public Security Domain

    [https://arxiv.org/abs/2402.07234](https://arxiv.org/abs/2402.07234)

    CPSDBench是一个专门为中国公共安全领域量身定制的大型语言模型评估基准，通过整合实际场景中收集的公共安全相关数据集，针对文本分类、信息提取、问题回答和文本生成四个关键维度全面评估LLMs的性能，并引入创新的评估指标，提高了对现有模型在解决公共安全问题方面性能的理解。

    

    大型语言模型（LLMs）在多个应用领域展示了显著的潜力和效果。为了评估主流LLMs在公共安全任务中的性能，本研究旨在构建一个专门针对中国公共安全领域的评估基准——CPSDBench。CPSDBench整合了从现实场景中收集到的与公共安全相关的数据集，支持对LLMs在文本分类、信息提取、问题回答和文本生成四个关键维度上进行全面评估。此外，本研究还引入了一套创新的评估指标，旨在更精确地量化LLMs在执行与公共安全相关任务上的效力。通过本研究中的深入分析和评估，我们不仅增强了对现有模型在解决公共安全问题方面性能优势和局限性的理解，还为未来的研究提供了参考。

    Large Language Models (LLMs) have demonstrated significant potential and effectiveness across multiple application domains. To assess the performance of mainstream LLMs in public security tasks, this study aims to construct a specialized evaluation benchmark tailored to the Chinese public security domain--CPSDbench. CPSDbench integrates datasets related to public security collected from real-world scenarios, supporting a comprehensive assessment of LLMs across four key dimensions: text classification, information extraction, question answering, and text generation. Furthermore, this study introduces a set of innovative evaluation metrics designed to more precisely quantify the efficacy of LLMs in executing tasks related to public security. Through the in-depth analysis and evaluation conducted in this research, we not only enhance our understanding of the performance strengths and limitations of existing models in addressing public security issues but also provide references for the fu
    
[^266]: 功能对齐回归：一种从数据中明确学习函数导数的方法

    Function Aligned Regression: A Method Explicitly Learns Functional Derivatives from Data

    [https://arxiv.org/abs/2402.06104](https://arxiv.org/abs/2402.06104)

    该论文提出了一种名为FAR的方法，通过捕捉函数导数来更好、更高效地拟合底层真实函数。在合成数据集和八个真实世界任务中证明了该方法的有效性。

    

    回归是机器学习中的一个基本任务，在过去几十年中引起了广泛关注。传统的回归方法主要通过使用损失函数来将模型预测与每个个体数据样本的真实值对齐，然而，我们发现这种方法可能导致在不同样本之间关系的预测不够优化。近期的研究工作引入了标签相似性信息来改进回归方法，但在完全捕捉底层真实函数的复杂性方面仍存在明显的差距。在本文中，我们提出了FAR（功能对齐回归）作为一种更好、更高效的解决方案，通过捕捉函数导数来拟合底层真实函数。我们在两个合成数据集和六个领域的八个大规模真实世界任务中验证了该方法的有效性。

    Regression is a fundamental task in machine learning that has garnered extensive attention over the past decades. The conventional approach for regression involves employing loss functions that primarily concentrate on aligning model prediction with the ground truth for each individual data sample, which, as we show, can result in sub-optimal prediction of the relationships between the different samples. Recent research endeavors have introduced novel perspectives by incorporating label similarity information to regression. However, a notable gap persists in these approaches when it comes to fully capturing the intricacies of the underlying ground truth function. In this work, we propose FAR (Function Aligned Regression) as a arguably better and more efficient solution to fit the underlying function of ground truth by capturing functional derivatives. We demonstrate the effectiveness of the proposed method practically on 2 synthetic datasets and on 8 extensive real-world tasks from 6 b
    
[^267]: 最后之舞：通过扩散模型和贝叶斯方法进行鲁棒后门攻击

    The last Dance : Robust backdoor attack via diffusion models and bayesian approach

    [https://arxiv.org/abs/2402.05967](https://arxiv.org/abs/2402.05967)

    本文介绍了一种通过扩散模型和贝叶斯方法进行鲁棒后门攻击的方法，具体应用于音频Transformer模型，并证明了攻击的可行性。

    

    扩散模型是最先进的深度学习生成模型，其通过逐步添加噪音和去噪的方式学习正向和反向扩散过程的原理进行训练。本文旨在欺骗基于音频的DNN模型，例如Hugging Face框架中的音频模型，特别是基于Transformer的人工智能模型，这些模型是强大的机器学习模型，节省时间，提供更高效的结果。我们证明了在Hugging Face推导出的音频Transformer上实现后门攻击（称为`BacKBayDiffMod`）的可行性。本文中开发的后门攻击基于毒化模型的训练数据，涉及后门扩散采样和贝叶斯方法分布的引入。

    Diffusion models are state-of-the-art deep learning generative models that are trained on the principle of learning forward and backward diffusion processes via the progressive addition of noise and denoising. In this paper, we seek to trick audio-based DNN models, such as those in the Hugging Face framework, for example, those that focus on audio, in particular transformer-based artificial intelligence models, which are powerful machine learning models that save time and deliver faster, more efficient results. We demonstrate the feasibility of backdoor attacks (called `BacKBayDiffMod`) on audio transformers derived from Hugging Face, a popular framework in the world of artificial intelligence (AI) research. The backdoor attack developed in this paper is based on poisoning the model's training data by incorporating backdoor diffusion sampling and a Bayesian approach to the distribution of poisoned data.
    
[^268]: 实时瓶颈和激波预测的中尺度交通预测

    Mesoscale Traffic Forecasting for Real-Time Bottleneck and Shockwave Prediction

    [https://arxiv.org/abs/2402.05663](https://arxiv.org/abs/2402.05663)

    该论文介绍了一种在实时中尺度交通预测中具有最先进效果的深度预测方法SA-LSTM，通过将自注意力与长短期记忆结合，实现了对多步预测的改进，并在短期和长期预测之间取得了平衡。

    

    准确的实时交通状态预测在交通控制研究中起着关键作用。特别是CIRCLES联合项目需要预测技术来减轻数据源延迟的影响。在MegaVanderTest实验取得成功之后，本文旨在克服当前系统限制，开发更适合的方法来改善下一轮实验的实时交通状态估计。在本文中，我们介绍了SA-LSTM，这是一种深度预测方法，将自注意力（SA）与长短期记忆（LSTM）在空间维度上结合，可以在实时中尺度交通预测中获得最先进的结果。我们将这种方法扩展到多步预测，使用n-step SA-LSTM，在短期和长期预测之间的平衡中优于传统的多步预测方法，同时实时运行。

    Accurate real-time traffic state forecasting plays a pivotal role in traffic control research. In particular, the CIRCLES consortium project necessitates predictive techniques to mitigate the impact of data source delays. After the success of the MegaVanderTest experiment, this paper aims at overcoming the current system limitations and develop a more suited approach to improve the real-time traffic state estimation for the next iterations of the experiment. In this paper, we introduce the SA-LSTM, a deep forecasting method integrating Self-Attention (SA) on the spatial dimension with Long Short-Term Memory (LSTM) yielding state-of-the-art results in real-time mesoscale traffic forecasting. We extend this approach to multi-step forecasting with the n-step SA-LSTM, which outperforms traditional multi-step forecasting methods in the trade-off between short-term and long-term predictions, all while operating in real-time.
    
[^269]: Minecraft-ify：用于游戏应用的Minecraft风格图像生成与文本引导的图像编辑

    Minecraft-ify: Minecraft Style Image Generation with Text-guided Image Editing for In-Game Application

    [https://arxiv.org/abs/2402.05448](https://arxiv.org/abs/2402.05448)

    本文提出了一种用于Minecraft游戏应用的图像生成和编辑系统"Minecraft-ify"，能够生成针对3D虚拟角色的面部聚焦图像，并支持使用文本进行图像编辑，提供了更自由和优化的用户体验。

    

    本文首先介绍了面向Minecraft视频游戏的角色纹理生成系统"Minecraft-ify"，该系统可以生成针对具有立方体流形的3D虚拟角色的面部聚焦图像以进行纹理映射。与现有项目或作品只生成纹理不同，提出的系统可以反转用户提供的真实图像，或从学习到的分布生成平均/随机外观。此外，它可以使用StyleGAN和StyleCLIP进行文本引导的操作。这些功能提供了更广泛的用户体验和更多的自由，是一种用户友好的AI工具。

    In this paper, we first present the character texture generation system \textit{Minecraft-ify}, specified to Minecraft video game toward in-game application. Ours can generate face-focused image for texture mapping tailored to 3D virtual character having cube manifold. While existing projects or works only generate texture, proposed system can inverse the user-provided real image, or generate average/random appearance from learned distribution. Moreover, it can be manipulated with text-guidance using StyleGAN and StyleCLIP. These features provide a more extended user experience with enlarged freedom as a user-friendly AI-tool. Project page can be found at https://gh-bumsookim.github.io/Minecraft-ify/
    
[^270]: SALAD-Bench: 一个针对大语言模型的层次化和全面性安全基准

    SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models

    [https://arxiv.org/abs/2402.05044](https://arxiv.org/abs/2402.05044)

    SALAD-Bench是一个针对大语言模型的全面安全基准，通过其大规模、丰富的分类和多功能性，以及对攻击和防御方法的评估，实现了对LLMs的有效管理和保护。

    

    在快速发展的大语言模型（LLM）领域中，确保强大的安全措施至关重要。为了满足这一关键需求，我们提出了一种特别设计用于评估LLMs、攻击和防御方法的安全基准，称为SALAD-Bench。SALAD-Bench通过其大规模、丰富多样的特性，以及跨三个层次的细致分类和多功能性，超越了传统基准。SALAD-Bench通过对标准查询和复杂查询（包括攻击、防御修改和多项选择）的精心设计，有效管理其固有的复杂性。为了确保无缝可靠的评估，我们引入了一种创新的评估器：基于LLM的MD-Judge，专注于攻击增强查询的问答对评估。以上组件将SALAD-Bench从标准的LLM安全评估扩展到了LLM攻击和防御方法评估，确保了联合目标的实用性。

    In the rapidly evolving landscape of Large Language Models (LLMs), ensuring robust safety measures is paramount. To meet this crucial need, we propose \emph{SALAD-Bench}, a safety benchmark specifically designed for evaluating LLMs, attack, and defense methods. Distinguished by its breadth, SALAD-Bench transcends conventional benchmarks through its large scale, rich diversity, intricate taxonomy spanning three levels, and versatile functionalities.SALAD-Bench is crafted with a meticulous array of questions, from standard queries to complex ones enriched with attack, defense modifications and multiple-choice. To effectively manage the inherent complexity, we introduce an innovative evaluators: the LLM-based MD-Judge for QA pairs with a particular focus on attack-enhanced queries, ensuring a seamless, and reliable evaluation. Above components extend SALAD-Bench from standard LLM safety evaluation to both LLM attack and defense methods evaluation, ensuring the joint-purpose utility. Our e
    
[^271]: RL-VLM-F: 强化学习通过视觉语言基础模型反馈

    RL-VLM-F: Reinforcement Learning from Vision Language Foundation Model Feedback

    [https://arxiv.org/abs/2402.03681](https://arxiv.org/abs/2402.03681)

    RL-VLM-F是一种通过视觉语言基础模型反馈的强化学习方法，能够自动生成有效的奖励函数和策略，从而解决了传统强化学习中奖励设计的挑战。

    

    传统强化学习研究中的奖励设计一直是一个挑战，因为通常需要大量人力和反复试错的过程来设计有效的奖励函数。本文提出了一种自动生成奖励函数的方法，用于代理学习新任务，只使用任务目标的文本描述和代理的视觉观测，并利用视觉语言基础模型（VLMs）的反馈。我们的方法的关键是通过查询这些模型，基于任务目标的文本描述给出对代理的图像观测的偏好，并从偏好标签中学习奖励函数，而不是直接要求这些模型输出原始奖励分数，这可能存在噪音和不一致性。我们证明了RL-VLM-F在各种领域中成功地产生了有效的奖励和策略，包括经典控制以及刚性和灵活操纵方面。

    Reward engineering has long been a challenge in Reinforcement Learning (RL) research, as it often requires extensive human effort and iterative processes of trial-and-error to design effective reward functions. In this paper, we propose RL-VLM-F, a method that automatically generates reward functions for agents to learn new tasks, using only a text description of the task goal and the agent's visual observations, by leveraging feedbacks from vision language foundation models (VLMs). The key to our approach is to query these models to give preferences over pairs of the agent's image observations based on the text description of the task goal, and then learn a reward function from the preference labels, rather than directly prompting these models to output a raw reward score, which can be noisy and inconsistent. We demonstrate that RL-VLM-F successfully produces effective rewards and policies across various domains - including classic control, as well as manipulation of rigid, articulate
    
[^272]: SGS-SLAM：基于高斯点云的语义稠密SLAM

    SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM

    [https://arxiv.org/abs/2402.03246](https://arxiv.org/abs/2402.03246)

    SGS-SLAM是一种基于三维高斯点云的语义稠密SLAM系统，通过多通道优化和关键帧优化，实现了高质量的重建和精确的语义分割。

    

    语义理解在稠密同时定位和建图（SLAM）中起着关键作用，有助于全面的场景解析。最近将高斯点云集成到SLAM系统中的进展表明，通过使用显式的三维高斯表示，可以生成高质量的渲染效果。基于这一进展，我们提出了SGS-SLAM，这是第一个基于三维高斯点云的语义稠密视觉SLAM系统，它不仅提供精确的三维语义分割，还实现了高保真度的重建。具体而言，我们提出在建图过程中采用多通道优化，将外观、几何和语义约束与关键帧优化相结合，以提高重建质量。大量实验证明SGS-SLAM在相机位姿估计、地图重建和语义分割方面表现出了最先进的性能，优于现有方法同时保持实时渲染。

    Semantic understanding plays a crucial role in Dense Simultaneous Localization and Mapping (SLAM), facilitating comprehensive scene interpretation. Recent advancements that integrate Gaus- sian Splatting into SLAM systems have demonstrated its effectiveness in generating high-quality renderings through the use of explicit 3D Gaussian representations. Building on this progress, we propose SGS-SLAM, the first semantic dense visual SLAM system grounded in 3D Gaussians, which provides precise 3D semantic segmentation alongside high-fidelity reconstructions. Specifically, we propose to employ multi-channel optimization during the mapping process, integrating appearance, geometric, and semantic constraints with key-frame optimization to enhance reconstruction quality. Extensive experiments demonstrate that SGS-SLAM delivers state-of-the-art performance in camera pose estimation, map reconstruction, and semantic segmentation, outperforming existing methods meanwhile preserving real-time rende
    
[^273]: C-RAG: 针对检索增强语言模型的认证生成风险

    C-RAG: Certified Generation Risks for Retrieval-Augmented Language Models

    [https://arxiv.org/abs/2402.03181](https://arxiv.org/abs/2402.03181)

    C-RAG是第一个用于认证检索增强语言模型生成风险的框架，通过提供符合风险分析和生成风险的上界，确保生成结果的可信性。

    

    尽管大型语言模型（LLMs）在各种应用中具备令人印象深刻的能力，但它们仍然存在可信度问题，如幻觉和错位。检索增强语言模型（RAG）被提出来增强生成结果的可信性，通过引入外部知识。但是，对于RAG模型的生成风险的理论理解尚未被研究。本文回答了以下问题：1）RAG是否确实能够降低生成风险，2）如何对RAG和传统LLM的生成风险提供可证明的保证，以及3）哪些充分条件使得RAG模型能够降低生成风险。我们提出了C-RAG，第一个用于认证RAG模型生成风险的框架。具体而言，我们为RAG模型提供了符合风险分析，并确保了生成风险的上界，我们称之为符合生成风险。我们还对一般有界风险下的符合生成风险提供了理论保证。

    Despite the impressive capabilities of large language models (LLMs) across diverse applications, they still suffer from trustworthiness issues, such as hallucinations and misalignments. Retrieval-augmented language models (RAG) have been proposed to enhance the credibility of generations by grounding external knowledge, but the theoretical understandings of their generation risks remains unexplored. In this paper, we answer: 1) whether RAG can indeed lead to low generation risks, 2) how to provide provable guarantees on the generation risks of RAG and vanilla LLMs, and 3) what sufficient conditions enable RAG models to reduce generation risks. We propose C-RAG, the first framework to certify generation risks for RAG models. Specifically, we provide conformal risk analysis for RAG models and certify an upper confidence bound of generation risks, which we refer to as conformal generation risk. We also provide theoretical guarantees on conformal generation risks for general bounded risk f
    
[^274]: ToonAging: 艺术肖像风格转换下的人脸逆龄化

    ToonAging: Face Re-Aging upon Artistic Portrait Style Transfer

    [https://arxiv.org/abs/2402.02733](https://arxiv.org/abs/2402.02733)

    本研究提出了一种新颖的一阶段方法，结合肖像风格转换实现人脸逆龄化，解决了NPR图像上编辑年龄的问题，并在单个生成步骤中执行。该方法利用了现有的人脸逆龄化和风格转换网络，并且独特地融合了不同的潜在向量，从而保留了面部属性。

    

    人脸逆龄化是计算机视觉和图形学中的一个重要领域，在电影、广告和直播等逼真领域中具有重要应用。最近，将人脸逆龄化应用于非逼真图像，如漫画、插图和动画，在各种娱乐行业中成为一个新的需求。然而，缺乏一个能够无缝编辑NPR图像上显现年龄的网络意味着这些任务一直局限于一个简单的顺序方法，这往往会导致不愉快的伪影和由于域差异而丢失面部属性。在本文中，我们引入了一种新颖的单阶段人脸逆龄化方法，结合了肖像风格转换，在一个生成步骤中完成。我们利用现有的人脸逆龄化和风格转换网络，两者都在相同的PR领域进行训练。我们的方法独特地融合了不同的潜在向量，每个向量负责管理与衰老相关的属性。

    Face re-aging is a prominent field in computer vision and graphics, with significant applications in photorealistic domains such as movies, advertising, and live streaming. Recently, the need to apply face re-aging to non-photorealistic images, like comics, illustrations, and animations, has emerged as an extension in various entertainment sectors. However, the absence of a network capable of seamlessly editing the apparent age on NPR images means that these tasks have been confined to a naive approach, applying each task sequentially. This often results in unpleasant artifacts and a loss of facial attributes due to domain discrepancies. In this paper, we introduce a novel one-stage method for face re-aging combined with portrait style transfer, executed in a single generative step. We leverage existing face re-aging and style transfer networks, both trained within the same PR domain. Our method uniquely fuses distinct latent vectors, each responsible for managing aging-related attribu
    
[^275]: 一个真正联合的神经网络架构用于分割和解析

    A Truly Joint Neural Architecture for Segmentation and Parsing

    [https://arxiv.org/abs/2402.02564](https://arxiv.org/abs/2402.02564)

    本文通过引入一个联合神经网络架构，在形态丰富的语言中实现了同时进行形态分割和句法分析的任务。通过提供基于格子的表示法，保留了输入的所有形态模糊性，有效解决了以往基于神经网络的依存句法分析器的局限性。

    

    当代多语言依存句法分析器可以解析多种语言，但对于形态丰富的语言而言，其性能明显低于其他语言。主要挑战是由于输入标记的形态复杂性和模糊性较高，作为树中节点的语言单位事先是未知的。以往的基于神经网络的形态丰富语言的依存句法分析器遵循联合形态-句法假设，即形态分割和句法分析应该在解析过程中一并解决，而不是先进行分割再进行解析的流程。然而，目前的神经网络依存句法分析器采用严格的流水线方法。在本文中，我们引入了一个联合神经网络架构，将基于格子的表示法保留输入的所有形态模糊性，然后将其提供给一个基于弧的模型，该模型能够同时解决形态分割和句法分析任务。我们在希伯来语上进行了实验，该语言形态丰富且模糊性较高，结果表明...

    Contemporary multilingual dependency parsers can parse a diverse set of languages, but for Morphologically Rich Languages (MRLs), performance is attested to be lower than other languages. The key challenge is that, due to high morphological complexity and ambiguity of the space-delimited input tokens, the linguistic units that act as nodes in the tree are not known in advance. Pre-neural dependency parsers for MRLs subscribed to the joint morpho-syntactic hypothesis, stating that morphological segmentation and syntactic parsing should be solved jointly, rather than as a pipeline where segmentation precedes parsing. However, neural state-of-the-art parsers to date use a strict pipeline. In this paper we introduce a joint neural architecture where a lattice-based representation preserving all morphological ambiguity of the input is provided to an arc-factored model, which then solves the morphological segmentation and syntactic parsing tasks at once. Our experiments on Hebrew, a rich and
    
[^276]: 学习通过原始-对偶策略梯度算法对无限时域平均回报受限MDP进行参数化通用策略

    Learning General Parameterized Policies for Infinite Horizon Average Reward Constrained MDPs via Primal-Dual Policy Gradient Algorithm

    [https://arxiv.org/abs/2402.02042](https://arxiv.org/abs/2402.02042)

    该论文研究了无限时域平均回报受限MDPs的参数化通用策略，并提出了一种基于原始-对偶策略梯度算法，可在保证低遗憾的情况下管理约束条件，达到全局最优策略。算法的分析表明，其目标遗憾和约束违反均为 $\tilde{\mathcal{O}}({T}^{3/4})$。

    

    本文探索了无限时域平均回报受限马尔科夫决策过程（CMDP）的领域。据我们所知，这项工作是首次研究具有通用策略参数化的平均回报CMDP的遗憾和约束违规分析。为了解决这个挑战，我们提出了一种基于原始对偶的策略梯度算法，能够灵活地管理约束条件，并确保低遗憾保证以实现全局最优策略。特别地，我们证明了我们提出的算法在目标遗憾和约束违反上具有 $\tilde{\mathcal{O}}({T}^{3/4})$ 的界限。

    This paper explores the realm of infinite horizon average reward Constrained Markov Decision Processes (CMDP). To the best of our knowledge, this work is the first to delve into the regret and constraint violation analysis of average reward CMDPs with a general policy parametrization. To address this challenge, we propose a primal dual based policy gradient algorithm that adeptly manages the constraints while ensuring a low regret guarantee toward achieving a global optimal policy. In particular, we demonstrate that our proposed algorithm achieves $\tilde{\mathcal{O}}({T}^{3/4})$ objective regret and $\tilde{\mathcal{O}}({T}^{3/4})$ constraint violation bounds.
    
[^277]: 通过定向表示优化实现的安全提示驱动的大型语言模型(LLM)保护

    Prompt-Driven LLM Safeguarding via Directed Representation Optimization

    [https://arxiv.org/abs/2401.18018](https://arxiv.org/abs/2401.18018)

    通过研究模型表示的影响，我们发现安全提示并没有明显增强恶意和无害查询之间的区分，并提出了一种名为DRO的方法，用于自动优化安全提示。

    

    在大型语言模型(LLM)中，使用安全提示在模型输入之前是一种常见的保护实践，以使其不遵从包含恶意意图的查询。然而，安全提示的工作机制尚未完全理解，这妨碍了自动优化其以改善LLM安全性的潜力。针对这个问题，我们从模型表示的角度调查了安全提示的影响。我们发现在模型的表示空间中，有害和无害的查询可以在很大程度上区分开来，但安全提示并没有明显增强这一区分。相反，不同安全提示导致查询的表示朝着相似的方向移动，使得模型即使在查询无害时也更容易拒绝提供协助。受到这些发现的启发，我们提出了一种名为DRO（定向表示优化）的方法，用于自动安全提示优化。DRO将安全提示视为要优化的表示方向。

    Prepending model inputs with safety prompts is a common practice of safeguarding large language models (LLMs) from complying with queries that contain harmful intents. However, the working mechanisms of safety prompts have not yet been fully understood, which hinders the potential for automatically optimizing them for improved LLM safety. Motivated by this problem, we investigate the impact of safety prompts from the perspective of model representations. We find that in models' representation space, harmful and harmless queries can be largely distinguished, but this is not noticeably enhanced by safety prompts. Instead, the queries' representations are moved by different safety prompts in similar directions, where models become more prone to refusal (i.e., refusing to provide assistance) even when the queries are harmless. Inspired by these findings, we propose a method called DRO (Directed Representation Optimization) for automatic safety prompt optimization. DRO treats safety prompts
    
[^278]: DocFinQA：一个长文本财务推理数据集

    DocFinQA: A Long-Context Financial Reasoning Dataset

    [https://arxiv.org/abs/2401.06915](https://arxiv.org/abs/2401.06915)

    引入了一个长文档财务问答任务，将平均上下文长度从700个词扩展到123k个词，对于大型语言模型在金融领域具有重要挑战。

    

    对于大型语言模型（LLMs）在金融领域发挥作用，需要研究现实任务和数据。金融专业人士经常与长达数百页的文档进行交互，但大多数金融研究数据集仅处理这些文档的简短摘录。为了解决这个问题，我们引入了一个长文档财务问答任务。我们通过在现有FinQA数据集中的7,437个问题中增加完整文档上下文，将FinQA中平均上下文长度从不到700个词扩展到DocFinQA中的123k个词。我们在检索式QA管道和长文本语言模型上进行了大量实验。即使对于最先进的系统，DocFinQA也是一个巨大挑战。我们还对DocFinQA中最长文档进行了案例研究，并发现模型在这些文档上特别困难。解决这些挑战。

    arXiv:2401.06915v2 Announce Type: replace-cross  Abstract: For large language models (LLMs) to be effective in the financial domain -- where each decision can have a significant impact -- it is necessary to investigate realistic tasks and data. Financial professionals often interact with documents that are hundreds of pages long, but most financial research datasets only deal with short excerpts from these documents. To address this, we introduce a long-document financial QA task. We augment 7,437 questions from the existing FinQA dataset with the full-document context, extending the average context length from under 700 words in FinQA to 123k words in DocFinQA. We conduct extensive experiments over retrieval-based QA pipelines and long-context language models. DocFinQA proves a significant challenge for even state-of-the-art systems. We also provide a case-study on the longest documents in DocFinQA and find that models particularly struggle on these documents. Addressing these challen
    
[^279]: 高维和高阶物理启发神经网络的 Hutchinson 迹估计

    Hutchinson Trace Estimation for High-Dimensional and High-Order Physics-Informed Neural Networks

    [https://arxiv.org/abs/2312.14499](https://arxiv.org/abs/2312.14499)

    介绍了 Hutchinson 迹估计（HTE），通过将整个 Hessian 矩阵的计算转换为 Hessian 矢量乘积（HVP），解决了 PINNs 处理高维和高阶 PDE 的挑战。

    

    arXiv:2312.14499v2 公告类型：替代交叉 摘要：物理启发神经网络（PINNs）已被证明在解决偏微分方程（PDEs）方面非常有效，特别是当一些数据可用时，通过无缝融合数据和物理学。然而，将PINNs扩展到高维甚至高阶PDE在自动微分在残差损失中的计算成本方面遇到了重大挑战。在这里，我们通过引入 Hutchinson 迹估计（HTE）来解决PINNs处理高维和高阶PDE的局限性。从科学计算中普遍存在的二阶高维PDE入手，HTE将整个Hessian矩阵的计算转换为Hessian矢量乘积（HVP）。这种方法通过 Taylor 模式自动微分减轻了计算瓶颈，并将内存消耗从Hessian矩阵减少到HVP。我们进一步展示了HTE收敛到或者

    arXiv:2312.14499v2 Announce Type: replace-cross  Abstract: Physics-Informed Neural Networks (PINNs) have proven effective in solving partial differential equations (PDEs), especially when some data are available by seamlessly blending data and physics. However, extending PINNs to high-dimensional and even high-order PDEs encounters significant challenges due to the computational cost associated with automatic differentiation in the residual loss. Herein, we address the limitations of PINNs in handling high-dimensional and high-order PDEs by introducing Hutchinson Trace Estimation (HTE). Starting with the second-order high-dimensional PDEs ubiquitous in scientific computing, HTE transforms the calculation of the entire Hessian matrix into a Hessian vector product (HVP). This approach alleviates the computational bottleneck via Taylor-mode automatic differentiation and significantly reduces memory consumption from the Hessian matrix to HVP. We further showcase HTE's convergence to the or
    
[^280]: 在神经网络模型中协调共享与特定上下文信息对潜在因果的作用

    Reconciling Shared versus Context-Specific Information in a Neural Network Model of Latent Causes

    [https://arxiv.org/abs/2312.08519](https://arxiv.org/abs/2312.08519)

    LCNet是一个神经网络模型，能够通过学习存储共享结构，同时使用上下文模块表示特定上下文结构，成功实现了在不同任务中提取共享结构并避免灾难性干扰的功能；并且能够捕捉人类数据中的课程效应。

    

    已经提出，当处理一系列事件时，人类会根据推断的潜在因果（LCs）来划分他们的经验，以支持依赖于上下文的学习。然而，当共享结构存在于不同上下文中时，如何同时实现LCs的“分裂”和学习共享结构仍不清楚。本文介绍了潜在因果网络（LCNet），这是一个LC推断的神经网络模型。通过学习，它自然地储存网络权重中跨任务共享的结构。此外，它利用一个上下文模块表示特定上下文结构，由贝叶斯非参数推理算法控制，为每个推断的LC分配一个唯一的上下文向量。通过三个模拟实验，我们发现LCNet能够1)在功能学习任务中提取跨LC的共享结构，同时避免灾难性干扰，2)捕捉关于课程效应的人类数据。

    arXiv:2312.08519v2 Announce Type: replace-cross  Abstract: It has been proposed that, when processing a stream of events, humans divide their experiences in terms of inferred latent causes (LCs) to support context-dependent learning. However, when shared structure is present across contexts, it is still unclear how the "splitting" of LCs and learning of shared structure can be simultaneously achieved. Here, we present the Latent Cause Network (LCNet), a neural network model of LC inference. Through learning, it naturally stores structure that is shared across tasks in the network weights. Additionally, it represents context-specific structure using a context module, controlled by a Bayesian nonparametric inference algorithm, which assigns a unique context vector for each inferred LC. Across three simulations, we found that LCNet could 1) extract shared structure across LCs in a function learning task while avoiding catastrophic interference, 2) capture human data on curriculum effects 
    
[^281]: 语言辅助视觉模型调试器：一种无需样本的发现和修复错误的方法

    Language-assisted Vision Model Debugger: A Sample-Free Approach to Finding and Fixing Bugs

    [https://arxiv.org/abs/2312.05588](https://arxiv.org/abs/2312.05588)

    提出了一种语言辅助视觉模型调试方法，利用文本而不是图像来诊断视觉模型中的错误，通过连接CLIP的嵌入空间和出错视觉模型，以及利用CLIP的文本分支作为代理模型来发现错误。

    

    具有高整体准确性的视觉模型经常在特定情景中表现出系统性错误，可能带来严重的安全隐患。诊断视觉模型的错误正变得越来越受到关注，然而传统的诊断方法需要注释工作（例如伴随每个CelebA样本的丰富元数据）。为了解决这个问题，我们提出了一种语言辅助诊断方法，其使用文本而不是图像来诊断基于多模型（例如CLIP）的视觉模型中的错误。我们的方法将CLIP的嵌入空间与待诊断的出错视觉模型连接起来；同时，利用一个共享分类器和从CLIP的嵌入空间到跨模态转移的可能性，CLIP的文本分支成为一个代理模型，用于在出错模型中找出错误。代理模型可以对配对的文本和图像进行分类。在诊断过程中，利用一个大型语言模型（LLM）来获得与任务相关的文集，这c

    arXiv:2312.05588v2 Announce Type: replace  Abstract: Vision models with high overall accuracy often exhibit systematic errors in specific scenarios, posing potential serious safety concerns. Diagnosing bugs of vision models is gaining increased attention, however traditional diagnostic approaches require annotation efforts (eg rich metadata accompanying each samples of CelebA). To address this issue,We propose a language-assisted diagnostic method that uses texts instead of images to diagnose bugs in vision models based on multi-modal models (eg CLIP). Our approach connects the embedding space of CLIP with the buggy vision model to be diagnosed; meanwhile, utilizing a shared classifier and the cross-modal transferability of embedding space from CLIP, the text-branch of CLIP become a proxy model to find bugs in the buggy model. The proxy model can classify texts paired with images. During the diagnosis, a Large Language Model (LLM) is employed to obtain task-relevant corpora, and this c
    
[^282]: MUFFIN: 用于改善指示遵循的多方面指南的策划

    MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction-Following

    [https://arxiv.org/abs/2312.02436](https://arxiv.org/abs/2312.02436)

    MUFFIN是一个新的指示遵循数据集策划方案，通过自动按比例扩大任务，通过多种输入方面使任务丰富多样。

    

    在大型语言模型（LLMs）领域中，加强指示遵循能力通常涉及策划广泛的训练数据。本文引入了一个新的指示遵循数据集策划方案MUFFIN，具体地通过用多种输入方面使任务自动按比例扩大以丰富这些任务。

    arXiv:2312.02436v2 Announce Type: replace-cross  Abstract: In the realm of large language models (LLMs), enhancing instruction-following capability often involves curating expansive training data. This is achieved through two primary schemes: i) Scaling-Inputs: Amplifying (input, output) pairs per task instruction, aiming for better instruction adherence. ii) Scaling Input-Free Tasks: Enlarging tasks, each composed of an (instruction, output) pair (without requiring a separate input anymore). However, LLMs under Scaling-Inputs tend to be overly sensitive to inputs, leading to misinterpretation or non-compliance with instructions. Conversely, Scaling Input-Free Tasks demands a substantial number of tasks but is less effective in instruction following when dealing with instances in Scaling-Inputs. This work introduces MUFFIN, a new scheme of instruction-following dataset curation. Specifically, we automatically Scale Tasks per Input by diversifying these tasks with various input facets. 
    
[^283]: 忽略这个标题并HackAPrompt：通过全球规模的Prompt Hacking竞赛揭示LLMs的系统性漏洞

    Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs through a Global Scale Prompt Hacking Competition

    [https://arxiv.org/abs/2311.16119](https://arxiv.org/abs/2311.16119)

    通过全球规模的Prompt Hacking竞赛，揭示了LLMs存在的系统漏洞，验证了当前LLMs可以被提示注入攻击操纵。

    

    大型语言模型（LLMs）被部署在直接与用户互动的情境中，例如聊天机器人和写作助手。这些部署容易受到提示注入和越狱（统称为Prompt Hacking）的攻击，即模型被操纵以忽略其原始指令并遵循可能恶意的指令。虽然广为人知作为一种重要的安全威胁，但关于Prompt Hacking的大规模资源和定量研究的资料匮乏。为了填补这一空白，我们发起了一场全球Prompt Hacking竞赛，允许自由形式的人类输入攻击。我们搜集了对三种最先进的LLMs发起的超过60万个对抗性提示，描述了这个数据集，从经验上验证了当前LLMs确实可以通过Prompt Hacking被操纵。我们还提出了一个对抗性提示类型的全面分类本体论。

    arXiv:2311.16119v3 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) are deployed in interactive contexts with direct user engagement, such as chatbots and writing assistants. These deployments are vulnerable to prompt injection and jailbreaking (collectively, prompt hacking), in which models are manipulated to ignore their original instructions and follow potentially malicious ones. Although widely acknowledged as a significant security threat, there is a dearth of large-scale resources and quantitative studies on prompt hacking. To address this lacuna, we launch a global prompt hacking competition, which allows for free-form human input attacks. We elicit 600K+ adversarial prompts against three state-of-the-art LLMs. We describe the dataset, which empirically verifies that current LLMs can indeed be manipulated via prompt hacking. We also present a comprehensive taxonomical ontology of the types of adversarial prompts.
    
[^284]: 高保真度以人为中心的主体到图像合成

    High-fidelity Person-centric Subject-to-Image Synthesis

    [https://arxiv.org/abs/2311.10329](https://arxiv.org/abs/2311.10329)

    提出了Face-diffuser，一个有效的协作生成流水线，用于解决主体到图像合成中的训练不平衡和质量妥协问题。

    

    当前以主体驱动的图像生成方法在以人为中心的图像生成中遇到了重大挑战。原因在于它们通过微调通用预训练扩散来学习语义场景和人物生成，这涉及到一种无法调和的训练不平衡。本文提出了Face-diffuser，这是一个有效的协作生成流水线，旨在消除上述训练不平衡和质量妥协。

    arXiv:2311.10329v3 Announce Type: replace-cross  Abstract: Current subject-driven image generation methods encounter significant challenges in person-centric image generation. The reason is that they learn the semantic scene and person generation by fine-tuning a common pre-trained diffusion, which involves an irreconcilable training imbalance. Precisely, to generate realistic persons, they need to sufficiently tune the pre-trained model, which inevitably causes the model to forget the rich semantic scene prior and makes scene generation over-fit to the training data. Moreover, even with sufficient fine-tuning, these methods can still not generate high-fidelity persons since joint learning of the scene and person generation also lead to quality compromise. In this paper, we propose Face-diffuser, an effective collaborative generation pipeline to eliminate the above training imbalance and quality compromise. Specifically, we first develop two specialized pre-trained diffusion models, i.
    
[^285]: MELA：多语言语言可接受性评估

    MELA: Multilingual Evaluation of Linguistic Acceptability

    [https://arxiv.org/abs/2311.09033](https://arxiv.org/abs/2311.09033)

    MELA是第一个覆盖10种语言的多语言语言可接受性基准，通过分析XLM-R的微调权重，探讨了跨语言迁移困难性，结果表明在上下文示例方面ChatGPT表现良好但仍落后于经过微调的XLM-R。

    

    最近，针对大型语言模型（LLMs）的基准主要集中在应用驱动的任务，如复杂推理和代码生成上，导致LLMs的纯语言评估严重不足。针对这一背景，我们引入了Multilingual Evaluation of Linguistic Acceptability（MELA），这是第一个涵盖来自多个语言家族的10种语言、共48K个样本的语言可接受性多语言基准。我们建立了常用LLMs和监督模型的基线，使用XLM-R进行跨语言迁移和多任务学习实验。为了实现多语言可解释性，我们分析了微调后的XLM-R的权重，探讨了识别不同语言之间迁移困难性的可能性。我们的结果显示，ChatGPT从上下文示例中受益良多，但仍落后于经过微调的XLM-R，而GPT-4的性能与之相当。

    arXiv:2311.09033v2 Announce Type: replace-cross  Abstract: Recent benchmarks for Large Language Models (LLMs) have mostly focused on application-driven tasks such as complex reasoning and code generation, and this has led to a scarcity in purely linguistic evaluation of LLMs. Against this background, we introduce Multilingual Evaluation of Linguistic Acceptability -- MELA, the first multilingual benchmark on linguistic acceptability with 48K samples covering 10 languages from a diverse set of language families. We establish baselines of commonly used LLMs along with supervised models, and conduct cross-lingual transfer and multi-task learning experiments with XLM-R. In pursuit of multilingual interpretability, we analyze the weights of fine-tuned XLM-R to explore the possibility of identifying transfer difficulty between languages. Our results show that ChatGPT benefits much from in-context examples but still lags behind fine-tuned XLM-R, while the performance of GPT-4 is on par with f
    
[^286]: 弹性学习用于自由形态机器人设计

    Reinforcement learning for freeform robot design

    [https://arxiv.org/abs/2310.05670](https://arxiv.org/abs/2310.05670)

    使用策略梯度设计具有任意外部和内部结构的自由形态机器人，通过放置或移除原子建筑块束形成高级非参数宏结构。

    

    受到动物形态适应性的启发，越来越多的研究致力于扩展机器人训练，涵盖机器人设计的物理方面。然而，能够优化机器人3D形态的强化学习方法一直局限于重新定位或调整预定和静态拓扑属的肢体。在这里，我们展示了用于设计具有任意外部和内部结构的自由形态机器人的策略梯度。通过放置或移除原子建筑块束来形成高级非参数宏结构，如附肢、器官和腔室。尽管仅提供了开环控制的结果，但我们讨论了这种方法如何在未来适用于闭环控制和从模拟到现实机器人的转移。

    arXiv:2310.05670v2 Announce Type: replace-cross  Abstract: Inspired by the necessity of morphological adaptation in animals, a growing body of work has attempted to expand robot training to encompass physical aspects of a robot's design. However, reinforcement learning methods capable of optimizing the 3D morphology of a robot have been restricted to reorienting or resizing the limbs of a predetermined and static topological genus. Here we show policy gradients for designing freeform robots with arbitrary external and internal structure. This is achieved through actions that deposit or remove bundles of atomic building blocks to form higher-level nonparametric macrostructures such as appendages, organs and cavities. Although results are provided for open loop control only, we discuss how this method could be adapted for closed loop control and sim2real transfer to physical machines in future.
    
[^287]: 语言模型代表空间和时间

    Language Models Represent Space and Time

    [https://arxiv.org/abs/2310.02207](https://arxiv.org/abs/2310.02207)

    现代大型语言模型学习到了丰富的时空表征，包括学习到了空间和时间的线性表征以及个体的“空间神经元”和“时间神经元”。

    

    大型语言模型（LLM）的能力引发了关于这些系统到底是仅仅学习了庞大的表面统计信息还是学到了更连贯、基于真实世界的表征的争论。我们通过分析Llama-2系列模型中学到的三个空间数据集（世界、美国、纽约的地点）和三个时间数据集（历史人物、艺术品、新闻头条）的学习表征找到了支持后者的证据。我们发现LLM在多个尺度上学习到了空间和时间的线性表征。这些表征对提示变化具有稳健性，并且在不同实体类型（例如城市和地标）之间是统一的。此外，我们还发现了可靠地编码空间和时间坐标的个体“空间神经元”和“时间神经元”。虽然还需要进一步的研究，但我们的结果表明现代LLM学习到了对真实世界的丰富时空表征。

    arXiv:2310.02207v3 Announce Type: replace-cross  Abstract: The capabilities of large language models (LLMs) have sparked debate over whether such systems just learn an enormous collection of superficial statistics or a set of more coherent and grounded representations that reflect the real world. We find evidence for the latter by analyzing the learned representations of three spatial datasets (world, US, NYC places) and three temporal datasets (historical figures, artworks, news headlines) in the Llama-2 family of models. We discover that LLMs learn linear representations of space and time across multiple scales. These representations are robust to prompting variations and unified across different entity types (e.g. cities and landmarks). In addition, we identify individual "space neurons" and "time neurons" that reliably encode spatial and temporal coordinates. While further investigation is needed, our results suggest modern LLMs learn rich spatiotemporal representations of the real
    
[^288]: 移动操纵的主动感知运动生成

    Active-Perceptive Motion Generation for Mobile Manipulation

    [https://arxiv.org/abs/2310.00433](https://arxiv.org/abs/2310.00433)

    介绍了一种用于移动操纵器的主动感知流水线，可以生成对操纵任务有信息性的运动，通过最大化视觉信息增益和任务目标的权衡来提高抓取成功率。

    

    移动操纵系统结合了机动性和灵巧性的优点，由于它们可以在更大的空间中移动并与环境进行交互。然而，即使配备了机载传感器，例如具有实体相机的移动操纵系统，在无结构和杂乱的环境中提取任务相关的视觉信息，例如家庭环境，仍然具有挑战性。在这项工作中，我们介绍了一个主动感知流水线，用于移动操纵器生成对操纵任务有信息性的运动，例如在未知的杂乱场景中抓取。我们提出的方法 ActPerMoMa 通过对路径进行采样和计算路径相关的效用，在滑动地平线的方式下生成机器人路径。这些效用权衡了最大化视觉信息增益（IG）用于场景重建和面向任务的目的，例如最大化抓取可达性的任务成功率。我们展示了我们的方法在模拟中的有效性。

    arXiv:2310.00433v2 Announce Type: replace-cross  Abstract: Mobile Manipulation (MoMa) systems incorporate the benefits of mobility and dexterity, due to the enlarged space in which they can move and interact with their environment. However, even when equipped with onboard sensors, e.g., an embodied camera, extracting task-relevant visual information in unstructured and cluttered environments, such as households, remains challenging. In this work, we introduce an active perception pipeline for mobile manipulators to generate motions that are informative toward manipulation tasks, such as grasping in unknown, cluttered scenes. Our proposed approach, ActPerMoMa, generates robot paths in a receding horizon fashion by sampling paths and computing path-wise utilities. These utilities trade-off maximizing the visual Information Gain (IG) for scene reconstruction and the task-oriented objective, e.g., grasp success, by maximizing grasp reachability. We show the efficacy of our method in simula
    
[^289]: MATNet: 多级融合变压器模型用于日前光伏发电预测

    MATNet: Multi-Level Fusion Transformer-Based Model for Day-Ahead PV Generation Forecasting

    [https://arxiv.org/abs/2306.10356](https://arxiv.org/abs/2306.10356)

    提出了MATNet，结合了人工智能范式与光伏发电的物理先验知识，通过多级联合融合方法进行日前光伏发电预测

    

    准确预测可再生能源发电对促进可再生能源整合到电力系统中至关重要。针对光伏单元，预测方法主要可分为基于物理和基于数据的策略两类，基于人工智能的模型提供了最先进的性能。然而，虽然这些基于人工智能的模型可以捕捉数据中的复杂模式和关系，但它们忽略了现象的潜在物理先验知识。因此，在本文中，我们提出了MATNet，一种新颖的基于自注意力变压器架构，用于多元多步日前光伏发电预测。它采用一种混合方法，将人工智能范式与基于物理的光伏发电的先验知识相结合。该模型通过多级联合融合方法输入历史光伏数据以及历史和预测天气数据。

    arXiv:2306.10356v2 Announce Type: replace-cross  Abstract: Accurate forecasting of renewable generation is crucial to facilitate the integration of RES into the power system. Focusing on PV units, forecasting methods can be divided into two main categories: physics-based and data-based strategies, with AI-based models providing state-of-the-art performance. However, while these AI-based models can capture complex patterns and relationships in the data, they ignore the underlying physical prior knowledge of the phenomenon. Therefore, in this paper we propose MATNet, a novel self-attention transformer-based architecture for multivariate multi-step day-ahead PV power generation forecasting. It consists of a hybrid approach that combines the AI paradigm with the prior physical knowledge of PV power generation of physics-based methods. The model is fed with historical PV data and historical and forecast weather data through a multi-level joint fusion approach. The effectiveness of the propo
    
[^290]: 具有实时预算约束的安全离线强化学习

    Safe Offline Reinforcement Learning with Real-Time Budget Constraints

    [https://arxiv.org/abs/2306.00603](https://arxiv.org/abs/2306.00603)

    提出了一种名为TREBI的新方法，在离线设置下解决强化学习中实时预算约束的问题，通过轨迹分布建模和扩散模型规划来提供性能保证。

    

    为促进强化学习（RL）在现实世界中的安全部署，近年来对安全RL的研究取得了显著进展。然而，文献中大多数现有工作仍专注于在线设置，训练过程中可能会发生对安全预算的风险违规。此外，在许多实际应用中，学得策略需要实时响应动态确定的安全预算（即约束阈值）。本文针对离线设置下的实时预算约束问题，并提出了基于轨迹的实时预算推断（TREBI）作为一个新颖解决方案，该方法从轨迹分布的角度对问题进行建模，并通过扩散模型规划来解决。从理论上讲，我们证明在离线设置下对情节奖励和成本的估计存在误差界限，从而提供了性能保证。

    arXiv:2306.00603v2 Announce Type: replace-cross  Abstract: Aiming at promoting the safe real-world deployment of Reinforcement Learning (RL), research on safe RL has made significant progress in recent years. However, most existing works in the literature still focus on the online setting where risky violations of the safety budget are likely to be incurred during training. Besides, in many real-world applications, the learned policy is required to respond to dynamically determined safety budgets (i.e., constraint threshold) in real time. In this paper, we target at the above real-time budget constraint problem under the offline setting, and propose Trajectory-based REal-time Budget Inference (TREBI) as a novel solution that models this problem from the perspective of trajectory distribution and solves it through diffusion model planning. Theoretically, we prove an error bound of the estimation on the episodic reward and cost under the offline setting and thus provide a performance gua
    
[^291]: 在不需要监督的情况下发现语言模型中的潜在知识

    Discovering Latent Knowledge in Language Models Without Supervision

    [https://arxiv.org/abs/2212.03827](https://arxiv.org/abs/2212.03827)

    通过在语言模型的内部激活中直接发现潜在知识的方式，我们提出了一种纯粹无监督的方法，可以准确回答未标记模型激活的是非问题，并且在大型语言模型中恢复多样知识。

    

    训练语言模型的现有技术可能与真相不一致：如果我们用模仿学习训练模型，它们可能会重现人类的错误；如果我们训练它们生成人类评价高的文本，它们可能会输出人类评估者无法检测到的错误。我们提出通过在语言模型的内部激活中直接发现潜在知识的方式来规避这个问题，而且是纯粹无监督的方式。具体来说，我们引入了一种方法，能够准确回答只给定未标记模型激活的是非问题。该方法通过在激活空间中找到满足逻辑一致性属性的方向来工作，例如一个陈述及其否定具有相反的真值。我们展示，尽管没有使用监督和模型输出，我们的方法可以恢复大型语言模型中代表多样知识：在6个模型和10个问答数据集上，它表现优异。

    arXiv:2212.03827v2 Announce Type: replace-cross  Abstract: Existing techniques for training language models can be misaligned with the truth: if we train models with imitation learning, they may reproduce errors that humans make; if we train them to generate text that humans rate highly, they may output errors that human evaluators can't detect. We propose circumventing this issue by directly finding latent knowledge inside the internal activations of a language model in a purely unsupervised way. Specifically, we introduce a method for accurately answering yes-no questions given only unlabeled model activations. It works by finding a direction in activation space that satisfies logical consistency properties, such as that a statement and its negation have opposite truth values. We show that despite using no supervision and no model outputs, our method can recover diverse knowledge represented in large language models: across 6 models and 10 question-answering datasets, it outperforms 
    
[^292]: SMiLE：基于模式增强的多层对比学习用于知识图谱链接预测

    SMiLE: Schema-augmented Multi-level Contrastive Learning for Knowledge Graph Link Prediction

    [https://arxiv.org/abs/2210.04870](https://arxiv.org/abs/2210.04870)

    提出了一种新颖的基于模式增强的多层对比学习框架（SMiLE），用于知识图谱链接预测，通过利用网络模式作为先验约束来提高链接预测的准确性和上下文一致性。

    

    链接预测是推断知识图谱中实体之间缺失链接的任务。基于嵌入的方法通过建模三元组中的关系模式在解决此问题方面表现出有效性。然而，链接预测任务通常需要实体邻域中的上下文信息，而大多数现有的基于嵌入的方法未能捕捉到它。此外，很少有关注不同上下文中实体表示的多样性，这经常导致错误的预测结果。在这种情况下，我们认为知识图谱的模式包含特定的上下文信息，并且有助于保持实体在不同上下文中的一致性。在本文中，我们提出了一种新颖的基于模式增强的多层对比学习框架（SMiLE）来进行知识图谱链接预测。

    arXiv:2210.04870v3 Announce Type: replace-cross  Abstract: Link prediction is the task of inferring missing links between entities in knowledge graphs. Embedding-based methods have shown effectiveness in addressing this problem by modeling relational patterns in triples. However, the link prediction task often requires contextual information in entity neighborhoods, while most existing embedding-based methods fail to capture it. Additionally, little attention is paid to the diversity of entity representations in different contexts, which often leads to false prediction results. In this situation, we consider that the schema of knowledge graph contains the specific contextual information, and it is beneficial for preserving the consistency of entities across contexts. In this paper, we propose a novel Schema-augmented Multi-level contrastive LEarning framework (SMiLE) to conduct knowledge graph link prediction. Specifically, we first exploit network schema as the prior constraint to sam
    
[^293]: 动态定价中 n 人马尔可夫博弈的近似纳什均衡学习

    Approximate Nash Equilibrium Learning for n-Player Markov Games in Dynamic Pricing

    [https://arxiv.org/abs/2207.06492](https://arxiv.org/abs/2207.06492)

    该论文提出了一种在动态定价环境中寻找近似纳什均衡的新方法，利用神经网络表示策略和最小化状态，进行纳什 Q 学习。

    

    我们研究了竞争性马尔可夫博弈环境中的纳什均衡学习，其中多个代理竞争，可能存在多个纳什均衡。特别是，对于寡头动态定价环境，由于维度灵活性的问题，精确的纳什均衡难以获得。我们开发了一种新的无模型方法来寻找近似的纳什均衡。然后，我们应用无梯度黑盒优化来估计$\epsilon$，即代理单方面偏离任何联合策略的最大奖励优势，并估计任何给定状态的$\epsilon$-最小化策略。政策-$\epsilon$对应和状态到$\epsilon$-最小化策略由神经网络表示，后者为纳什策略网络。在批量更新期间，我们通过调整动作概率使用纳什策略网络来执行纳什 Q 学习。我们演示了近似纳什

    arXiv:2207.06492v3 Announce Type: replace-cross  Abstract: We investigate Nash equilibrium learning in a competitive Markov Game (MG) environment, where multiple agents compete, and multiple Nash equilibria can exist. In particular, for an oligopolistic dynamic pricing environment, exact Nash equilibria are difficult to obtain due to the curse-of-dimensionality. We develop a new model-free method to find approximate Nash equilibria. Gradient-free black box optimization is then applied to estimate $\epsilon$, the maximum reward advantage of an agent unilaterally deviating from any joint policy, and to also estimate the $\epsilon$-minimizing policy for any given state. The policy-$\epsilon$ correspondence and the state to $\epsilon$-minimizing policy are represented by neural networks, the latter being the Nash Policy Net. During batch update, we perform Nash Q learning on the system, by adjusting the action probabilities using the Nash Policy Net. We demonstrate that an approximate Nash
    
[^294]: 多视图超复数学习用于乳腺癌筛查

    Multi-View Hypercomplex Learning for Breast Cancer Screening

    [https://arxiv.org/abs/2204.05798](https://arxiv.org/abs/2204.05798)

    本文提出了一种基于参数化超复数神经网络的多视图乳腺癌分类方法，能够模拟并利用乳房X光检查的不同视图之间的相关性，从而提高肿瘤识别效果。

    

    传统上，用于乳腺癌分类的深度学习方法执行单视图分析。然而，由于乳腺X-ray图像中包含的相关性，放射科医生同时分析组成乳房X光摄影检查的所有四个视图，这为识别肿瘤提供了关键信息。鉴于此，一些研究已经开始提出多视图方法。然而，在这样的现有架构中，乳房X光图像被独立的卷积分支处理为独立的图像，从而失去了它们之间的相关性。为了克服这些局限性，在本文中，我们提出了一种基于参数化超复数神经网络的多视图乳腺癌分类方法。由于超复数代数特性，我们的网络能够建模并利用组成乳房X光检查的不同视图之间的现有相关性，从而模拟阅片过程。

    arXiv:2204.05798v3 Announce Type: replace-cross  Abstract: Traditionally, deep learning methods for breast cancer classification perform a single-view analysis. However, radiologists simultaneously analyze all four views that compose a mammography exam, owing to the correlations contained in mammography views, which present crucial information for identifying tumors. In light of this, some studies have started to propose multi-view methods. Nevertheless, in such existing architectures, mammogram views are processed as independent images by separate convolutional branches, thus losing correlations among them. To overcome such limitations, in this paper, we propose a methodological approach for multi-view breast cancer classification based on parameterized hypercomplex neural networks. Thanks to hypercomplex algebra properties, our networks are able to model, and thus leverage, existing correlations between the different views that comprise a mammogram, thus mimicking the reading process
    
[^295]: CMGAN：基于Conformer的度量GAN用于语音增强

    CMGAN: Conformer-based Metric GAN for Speech Enhancement

    [https://arxiv.org/abs/2203.15149](https://arxiv.org/abs/2203.15149)

    本文提出了一种基于Conformer的度量生成对抗网络（CMGAN）用于时频域的语音增强，通过优化生成器以使得增强估计语音相对应的评估分数来进一步提高增强语音的质量。

    

    最近，卷积增强变压器（Conformer）在自动语音识别（ASR）和时域语音增强（SE）中取得了很好的表现，因为它可以捕捉语音信号中的局部和全局依赖关系。本文提出了一种基于Conformer的度量生成对抗网络（CMGAN）用于时频域的SE。在生成器中，我们利用两阶段的Conformer块通过对时间和频率依赖关系进行建模，聚合所有幅度和复数谱信息。在解码器阶段，幅度和复数谱的估计被解耦，然后一起合并以重构增强的语音。此外，引入了一个度量鉴别器，通过优化生成器以使得增强估计语音相对应的评估分数，进一步提高增强语音的质量。在Voice Bank+DEMAND数据集上进行了定量分析。

    arXiv:2203.15149v4 Announce Type: replace-cross  Abstract: Recently, convolution-augmented transformer (Conformer) has achieved promising performance in automatic speech recognition (ASR) and time-domain speech enhancement (SE), as it can capture both local and global dependencies in the speech signal. In this paper, we propose a conformer-based metric generative adversarial network (CMGAN) for SE in the time-frequency (TF) domain. In the generator, we utilize two-stage conformer blocks to aggregate all magnitude and complex spectrogram information by modeling both time and frequency dependencies. The estimation of magnitude and complex spectrogram is decoupled in the decoder stage and then jointly incorporated to reconstruct the enhanced speech. In addition, a metric discriminator is employed to further improve the quality of the enhanced estimated speech by optimizing the generator with respect to a corresponding evaluation score. Quantitative analysis on Voice Bank+DEMAND dataset in
    
[^296]: 使用法律知识图谱进行类似案例推荐

    Similar Cases Recommendation using Legal Knowledge Graphs

    [https://arxiv.org/abs/2107.04771](https://arxiv.org/abs/2107.04771)

    使用法律知识图谱预测印度法院裁决类似案例的解决方案，并分析大型语言模型对该任务的影响。

    

    通过从法院案例、裁决、法律及其他法律文件构建的法律知识图谱，可以实现多种应用，如问答、文档相似度和搜索。尽管知识图谱在NLP任务中的远程监督应用得到了广泛研究，但在案例相似性等应用中使用知识图谱还面临挑战。在本工作中，我们描述了我们用于预测印度法院裁决类似案例的解决方案。我们提出了我们的结果，并讨论了大型语言模型对该任务的影响。

    arXiv:2107.04771v2 Announce Type: replace  Abstract: A legal knowledge graph constructed from court cases, judgments, laws and other legal documents can enable a number of applications like question answering, document similarity, and search. While the use of knowledge graphs for distant supervision in NLP tasks is well researched, using knowledge graphs for applications like case similarity presents challenges. In this work, we describe our solution for predicting similar cases in Indian court judgements. We present our results and also discuss the impact of large language models on this task.
    
[^297]: 私人预测集

    Private Prediction Sets

    [https://arxiv.org/abs/2102.06202](https://arxiv.org/abs/2102.06202)

    该研究提出了一个基于符合性预测的框架，可以在保护个人隐私的同时返回可靠的不确定性量化的预测集。

    

    在涉及重要决策的现实环境中，部署机器学习系统通常需要可靠的不确定性量化和保护个人隐私。我们提出了一个框架，将这两个目标同时视为重要。我们的框架基于符合性预测，这种方法可以扩展预测模型，返回提供不确定性量化的预测集，这些集合可以证明以用户指定的概率（如90%）覆盖真实响应。当与经过私人训练的模型一起使用时，人们可能希望符合性预测会为生成的预测集提供隐私保证；不幸的是，情况并非如此。为了解决这一关键问题，我们开发了一种方法，该方法可以从任何预先训练的预测模型中输出差分私人预测集。我们的方法遵循分裂符合性预测的一般方法；我们使用保留数据

    arXiv:2102.06202v3 Announce Type: replace-cross  Abstract: In real-world settings involving consequential decision-making, the deployment of machine learning systems generally requires both reliable uncertainty quantification and protection of individuals' privacy. We present a framework that treats these two desiderata jointly. Our framework is based on conformal prediction, a methodology that augments predictive models to return prediction sets that provide uncertainty quantification -- they provably cover the true response with a user-specified probability, such as 90%. One might hope that when used with privately-trained models, conformal prediction would yield privacy guarantees for the resulting prediction sets; unfortunately, this is not the case. To remedy this key problem, we develop a method that takes any pre-trained predictive model and outputs differentially private prediction sets. Our method follows the general approach of split conformal prediction; we use holdout data 
    
[^298]: 三维经直肠超声深度关注特征在前列腺分割中的应用

    Deep Attentive Features for Prostate Segmentation in 3D Transrectal Ultrasound

    [https://arxiv.org/abs/1907.01743](https://arxiv.org/abs/1907.01743)

    本文提出了一种新型的3D深度神经网络，配备着关注模块，通过充分利用卷积神经网络不同层中编码的互补信息，实现了在经直肠超声图像中更好地前列腺分割，通过选择性地整合不同层级的特征来提高前列腺分割性能

    

    arXiv:1907.01743v2 公告类型: 替换-跨度  摘要: 在图像引导的前列腺干预和治疗计划中，自动前列腺分割在经直肠超声(TRUS)图像中至关重要。然而，由于 TRUS 中前列腺的边界缺失/模糊和不均匀的强度分布，以及前列腺形状的大量变异性，开发这样的自动解决方案仍然非常具有挑战性。本文发展了一种配备关注模块的新型3D深度神经网络，通过充分利用卷积神经网络 (CNN) 不同层中编码的互补信息，来更好地对 TRUS 中的前列腺进行分割。我们的关注模块利用关注机制，有选择地利用不同层集成的多级特征来完善每个单独层的特征，抑制 CNN 浅层中的非前列腺噪声，并将更多前列腺细节融入特征中。

    arXiv:1907.01743v2 Announce Type: replace-cross  Abstract: Automatic prostate segmentation in transrectal ultrasound (TRUS) images is of essential importance for image-guided prostate interventions and treatment planning. However, developing such automatic solutions remains very challenging due to the missing/ambiguous boundary and inhomogeneous intensity distribution of the prostate in TRUS, as well as the large variability in prostate shapes. This paper develops a novel 3D deep neural network equipped with attention modules for better prostate segmentation in TRUS by fully exploiting the complementary information encoded in different layers of the convolutional neural network (CNN). Our attention module utilizes the attention mechanism to selectively leverage the multilevel features integrated from different layers to refine the features at each individual layer, suppressing the non-prostate noise at shallow layers of the CNN and increasing more prostate details into features at deep
    
[^299]: FP6-LLM: 通过FP6中心算法-系统协同设计高效提供大型语言模型

    FP6-LLM: Efficiently Serving Large Language Models Through FP6-Centric Algorithm-System Co-Design. (arXiv:2401.14112v1 [cs.LG])

    [http://arxiv.org/abs/2401.14112](http://arxiv.org/abs/2401.14112)

    FP6-LLM提出了一种支持六位量化的GPU算法-系统协同设计方案，实现了在大型语言模型中推断成本和模型质量之间的平衡。

    

    六位量化（FP6）可以有效地减小大型语言模型（LLM）的大小，并在不同应用中保持模型质量的一致性。然而，现有系统不提供FP6量化的张量核心支持，并且在LLM推断过程中很难实现实际性能改进。由于（1）模型权重具有不规则位宽的不友好内存访问和（2）权重去量化的高运行时开销，支持在GPU上进行FP6量化是具有挑战性的。为了解决这些问题，我们提出了TC-FPx，这是第一个具有统一张量核心支持的浮点权重的完整GPU内核设计方案，适用于各种量化位宽。我们将TC-FPx内核集成到现有推断系统中，提供了新的端到端支持（称为FP6-LLM）用于量化LLM推断，从而实现了推断成本和模型质量之间更好的平衡。实验证明，FP6-LLM仅使用一部分存储空间就可以进行LLaMA-70b的推断。

    Six-bit quantization (FP6) can effectively reduce the size of large language models (LLMs) and preserve the model quality consistently across varied applications. However, existing systems do not provide Tensor Core support for FP6 quantization and struggle to achieve practical performance improvements during LLM inference. It is challenging to support FP6 quantization on GPUs due to (1) unfriendly memory access of model weights with irregular bit-width and (2) high runtime overhead of weight de-quantization. To address these problems, we propose TC-FPx, the first full-stack GPU kernel design scheme with unified Tensor Core support of float-point weights for various quantization bit-width. We integrate TC-FPx kernel into an existing inference system, providing new end-to-end support (called FP6-LLM) for quantized LLM inference, where better trade-offs between inference cost and model quality are achieved. Experiments show that FP6-LLM enables the inference of LLaMA-70b using only a sin
    
[^300]: 从推特到引用：揭示社交媒体影响者对人工智能研究可见性的影响

    Tweets to Citations: Unveiling the Impact of Social Media Influencers on AI Research Visibility. (arXiv:2401.13782v1 [cs.DL])

    [http://arxiv.org/abs/2401.13782](http://arxiv.org/abs/2401.13782)

    本文研究了社交媒体影响者在提高机器学习研究的可见性方面的作用，发现被这些影响者认可的论文引用次数显著增加，中位数引用次数比对照组高2-3倍。此外，该研究还探讨了被展示作者的地理、性别和机构多样性。

    

    随着人工智能和机器学习会议上被接受的论文数量达到数千篇，研究人员如何获取和阅读研究论文变得不清楚。本文研究了社交媒体影响者在增强机器学习研究可见性中的作用，特别是他们分享的论文引用次数。我们编制了一个包括8000多篇论文的全面数据集，涵盖了2018年12月至2023年10月的推特，以及基于出版年份、会议地点和摘要主题进行1：1匹配的对照组。我们的分析揭示了这些影响者认可的论文引用次数显著增加，中位数引用次数比对照组高2-3倍。此外，该研究还深入研究了被展示作者的地理、性别和机构多样性。这些发现突显了社交媒体在学术交流中的不断扩大的影响力，并强调了当今数字化时代不断发展的生态系统的重要性。

    As the number of accepted papers at AI and ML conferences reaches into the thousands, it has become unclear how researchers access and read research publications. In this paper, we investigate the role of social media influencers in enhancing the visibility of machine learning research, particularly the citation counts of papers they share. We have compiled a comprehensive dataset of over 8,000 papers, spanning tweets from December 2018 to October 2023, alongside 1:1 matched controls based on publication year, venue, and abstract topics. Our analysis reveals a significant increase in citations for papers endorsed by these influencers, with median citation counts 2-3 times higher than those of the control group. Additionally, the study delves into the geographic, gender, and institutional diversity of highlighted authors. These findings highlight the expanding influence of social media in scholarly communication and underscore the importance of an evolving ecosystem in today's digital a
    
[^301]: 面向多智能体远程控制的基于语言到新兴通信的知识蒸馏

    Knowledge Distillation from Language-Oriented to Emergent Communication for Multi-Agent Remote Control. (arXiv:2401.12624v1 [cs.AI])

    [http://arxiv.org/abs/2401.12624](http://arxiv.org/abs/2401.12624)

    这项工作通过将语言导向的语义通信与新兴通信相结合，通过知识蒸馏的方式，提出了一种面向多智能体远程控制的新框架，实现了更快的行程时间和更高的训练收敛速度。

    

    在这项工作中，我们比较了基于多智能体深度强化学习（MADRL）的新兴通信（EC）和由预训练的大型语言模型（LLM）使用人类语言的面向语言的语义通信（LSC）。在一个多智能体远程导航任务中，使用包含位置和通道地图的多模态输入数据，结果表明，EC在使用多模态数据时会产生高的训练成本和困难，而LSC由于LLM尺寸较大，会导致高的推理计算成本。为了解决它们各自的瓶颈，我们提出了一种通过知识蒸馏（KD）引导EC训练使用LSC的新颖框架：语言引导的EC（LEC）。模拟验证了LEC实现了更快的行程时间，避免了信道质量差的区域，并且在与EC相比能够加速MADRL训练收敛达到61.8%。

    In this work, we compare emergent communication (EC) built upon multi-agent deep reinforcement learning (MADRL) and language-oriented semantic communication (LSC) empowered by a pre-trained large language model (LLM) using human language. In a multi-agent remote navigation task, with multimodal input data comprising location and channel maps, it is shown that EC incurs high training cost and struggles when using multimodal data, whereas LSC yields high inference computing cost due to the LLM's large size. To address their respective bottlenecks, we propose a novel framework of language-guided EC (LEC) by guiding the EC training using LSC via knowledge distillation (KD). Simulations corroborate that LEC achieves faster travel time while avoiding areas with poor channel conditions, as well as speeding up the MADRL training convergence by up to 61.8% compared to EC.
    
[^302]: 仿真行为：探索科学的可能下一范式

    Behavioral Simulation: Exploring A Possible Next Paradigm for Science. (arXiv:2401.09851v1 [cs.AI])

    [http://arxiv.org/abs/2401.09851](http://arxiv.org/abs/2401.09851)

    本文研究了仿真技术的发展与科学范式的演变，并提出了行为仿真的概念，代表了更高程度的范式整合。

    

    仿真技术已广泛应用于许多科学研究领域，如天气预报、流体力学和生物种群。它是处理复杂系统问题的最佳工具，在表示空间中无法使用闭合形式表达式且目标分布过于复杂而无法完全由深度学习模型表示。我们认为，仿真技术的发展与科学范式是一致的。本文从数据、算法和计算能力的角度归纳了科学范式的演变。在此基础上，我们将仿真技术分为三个阶段，与新范式的出现相适应，并发现先进的仿真技术是范式整合的典型实例。此外，我们提出了行为仿真（BS）的概念，特别是复杂行为仿真（SBS），代表了更高程度的范式整合。

    Simulation technologies have been widely utilized in many scientific research fields such as weather forecasting, fluid mechanics and biological populations. It is the best tool to handle problems in complex systems, where closed-form expressions are unavailable and the target distribution in the representation space is too complex to be fully represented by a deep learning (DL) model. We believe that the development of simulation technologies is consistent with scientific paradigms. This paper induces the evolution of scientific paradigms from the perspective of data, algorithms, and computational power. Building upon this perspective, we divide simulation technologies into three stages aligning with the emergence of new paradigms, and find that advanced simulation technologies are typical instances of paradigms integration. Moreover, we propose the concept of behavioral simulation (BS), specifically sophisticated behavioral simulation (SBS), representing a higher degree of paradigms 
    
[^303]: 将图神经网络与分数阶连续动力学相结合：鲁棒性研究

    Coupling Graph Neural Networks with Fractional Order Continuous Dynamics: A Robustness Study. (arXiv:2401.04331v1 [cs.LG])

    [http://arxiv.org/abs/2401.04331](http://arxiv.org/abs/2401.04331)

    本文详细研究了图神经分数阶微分方程模型的鲁棒性，通过实施分数阶微积分，模型在特征更新过程中考虑了长期记忆，对抗性条件下的性能仍未得到广泛探究。

    

    本文严格研究了图神经分数阶微分方程(FDE)模型的鲁棒性。该框架通过实施分数阶Caputo导数，超越了传统的图神经整数阶常微分方程(ODE)模型。利用分数阶微积分，我们的模型在特征更新过程中考虑了长期记忆，与传统图神经ODE模型中的无记忆马尔可夫更新不同。图神经FDE模型相对于图神经ODE模型在没有攻击或扰动的环境中已经被证明具有优势。尽管传统的图神经ODE模型在现有文献中已经被验证在存在对抗性攻击时具有一定的稳定性和弹性，但图神经FDE模型的鲁棒性，特别是在对抗性条件下的表现，仍未得到广泛探究。本文对图神经FDE模型的鲁棒性进行了详细评估。

    In this work, we rigorously investigate the robustness of graph neural fractional-order differential equation (FDE) models. This framework extends beyond traditional graph neural (integer-order) ordinary differential equation (ODE) models by implementing the time-fractional Caputo derivative. Utilizing fractional calculus allows our model to consider long-term memory during the feature updating process, diverging from the memoryless Markovian updates seen in traditional graph neural ODE models. The superiority of graph neural FDE models over graph neural ODE models has been established in environments free from attacks or perturbations. While traditional graph neural ODE models have been verified to possess a degree of stability and resilience in the presence of adversarial attacks in existing literature, the robustness of graph neural FDE models, especially under adversarial conditions, remains largely unexplored. This paper undertakes a detailed assessment of the robustness of graph 
    
[^304]: BD-MSA: 多尺度特征信息聚合引导的身体解耦高分辨率遥感影像变化检测方法

    BD-MSA: Body decouple VHR Remote Sensing Image Change Detection method guided by multi-scale feature information aggregation. (arXiv:2401.04330v1 [cs.CV])

    [http://arxiv.org/abs/2401.04330](http://arxiv.org/abs/2401.04330)

    提出了一种名为BD-MSA的新的变化检测模型，通过在训练和预测阶段收集特征图的全局和局部特征信息，成功提取了变化区域的边界信息，并将变化区域的主体与边界分离。

    

    遥感图像变化检测旨在检测同一地方拍摄的两个时期的图像之间的差异。深度学习已被广泛应用于遥感图像变化检测任务，在结果识别方面取得了显著成果。然而，由于卫星的拍摄角度、薄云层的影响以及特定的光照条件，在一些遥感摄影中，变化区域的模糊边缘问题无法通过当前的遥感图像变化检测算法正确处理。为了解决这个问题，我们提出了一种身体解耦多尺度特征聚合变化检测（BD-MSA）的新模型，在训练和预测阶段在特征图的通道和空间维度中收集全局和局部特征图信息。这种方法允许我们成功提取变化区域的边界信息，并将变化区域的主体与其边界分离。许多研究表明，评估指标是评价遥感图像变化检测结果质量的重要标准。

    The purpose of remote sensing image change detection (RSCD) is to detect differences between bi-temporal images taken at the same place. Deep learning has been extensively used to RSCD tasks, yielding significant results in terms of result recognition. However, due to the shooting angle of the satellite, the impacts of thin clouds, and certain lighting conditions, the problem of fuzzy edges in the change region in some remote sensing photographs cannot be properly handled using current RSCD algorithms. To solve this issue, we proposed a Body Decouple Multi-Scale by fearure Aggregation change detection (BD-MSA), a novel model that collects both global and local feature map information in the channel and space dimensions of the feature map during the training and prediction phases. This approach allows us to successfully extract the change region's boundary information while also divorcing the change region's main body from its boundary. Numerous studies have shown that the assessment me
    
[^305]: Video2Music：使用情感多模态Transformer模型从视频中生成合适的音乐

    Video2Music: Suitable Music Generation from Videos using an Affective Multimodal Transformer model. (arXiv:2311.00968v1 [cs.SD])

    [http://arxiv.org/abs/2311.00968](http://arxiv.org/abs/2311.00968)

    Video2Music是一个生成音乐的人工智能框架，可以根据视频生成相匹配的音乐。该框架通过分析视频的语义、场景偏移、动作和情感特征，采用Affective Multimodal Transformer (AMT)模型生成音乐。

    

    在音乐生成领域，许多研究展示了令人印象深刻的性能，但几乎没有模型能够直接根据视频生成相匹配的音乐。在这项工作中，我们开发了一个生成音乐的人工智能框架Video2Music，它可以匹配提供的视频。我们首先精心策划了一个独特的音乐视频集合。然后，我们分析音乐视频以获得语义、场景偏移、动作和情感特征。然后，这些不同的特征被用作我们音乐生成模型的引导输入。我们将音频文件转录为MIDI和和弦，并提取音符密度和音量等特征。这产生了一个丰富的多模态数据集MuVi-Sync，我们用这个数据集训练了一个新颖的情感多模态Transformer模型（AMT）来根据视频生成音乐。该模型包括一种新颖的机制来强制视频和音乐之间的情感相似性。最后，基于一个基于双向GRU的回归模型进行后处理，估计音符密度。

    Numerous studies in the field of music generation have demonstrated impressive performance, yet virtually no models are able to directly generate music to match accompanying videos. In this work, we develop a generative music AI framework, Video2Music, that can match a provided video. We first curated a unique collection of music videos. Then, we analysed the music videos to obtain semantic, scene offset, motion, and emotion features. These distinct features are then employed as guiding input to our music generation model. We transcribe the audio files into MIDI and chords, and extract features such as note density and loudness. This results in a rich multimodal dataset, called MuVi-Sync, on which we train a novel Affective Multimodal Transformer (AMT) model to generate music given a video. This model includes a novel mechanism to enforce affective similarity between video and music. Finally, post-processing is performed based on a biGRU-based regression model to estimate note density 
    
[^306]: Q-Learning用于通用信息结构和非马尔可夫环境下的随机控制

    Q-Learning for Stochastic Control under General Information Structures and Non-Markovian Environments. (arXiv:2311.00123v1 [math.OC])

    [http://arxiv.org/abs/2311.00123](http://arxiv.org/abs/2311.00123)

    该论文主要贡献是提出了一个对于非马尔可夫环境下的随机迭代（特别是Q-learning迭代）进行收敛的定理，并给出了收敛条件。其次，讨论了该定理在多种具有非马尔可夫环境的随机控制问题中的应用。

    

    作为主要贡献，我们提出了一个收敛定理，特别是对于一般的、可能为非马尔可夫的随机环境下的Q-学习迭代。我们的收敛条件涉及到一个遍历性和一个正性准则。我们对迭代的极限和收敛的环境和初始化条件进行了精确的描述。作为我们的第二个贡献，我们讨论了这个定理对于多种具有非马尔可夫环境的随机控制问题的影响和应用，其中包括(i)连续空间的完全观测马尔科夫决策过程（MDPs）的量化近似（量化破坏了马尔可夫结构），(ii)量化近似的置信MDP约化部分可观察MDPS（POMDPs） with 弱Feller连续性和滤波器稳定的轻微版本（控制器需要了解模型），(iii)有限窗口近似。

    As a primary contribution, we present a convergence theorem for stochastic iterations, and in particular, Q-learning iterates, under a general, possibly non-Markovian, stochastic environment. Our conditions for convergence involve an ergodicity and a positivity criterion. We provide a precise characterization on the limit of the iterates and conditions on the environment and initializations for convergence. As our second contribution, we discuss the implications and applications of this theorem to a variety of stochastic control problems with non-Markovian environments involving (i) quantized approximations of fully observed Markov Decision Processes (MDPs) with continuous spaces (where quantization break down the Markovian structure), (ii) quantized approximations of belief-MDP reduced partially observable MDPS (POMDPs) with weak Feller continuity and a mild version of filter stability (which requires the knowledge of the model by the controller), (iii) finite window approximations of
    
[^307]: 无限时域平均奖励强化学习的量子加速

    Quantum Acceleration of Infinite Horizon Average-Reward Reinforcement Learning. (arXiv:2310.11684v1 [cs.LG])

    [http://arxiv.org/abs/2310.11684](http://arxiv.org/abs/2310.11684)

    本研究探索了无限时域平均奖励强化学习中量子加速的潜力。我们提出了一种创新的量子框架，通过高效的量子均值估计技术，实现了指数级改进的遗憾保证。所提出的量子算法相较于经典算法，在遗憾界限上有显著改进。

    

    本文研究量子加速在解决无限时域Markov决策过程（MDPs）中提高平均奖励结果的潜力。我们引入了一种创新的量子框架，用于代理与未知MDP的互动，扩展了传统的交互范式。我们的方法涉及设计一种基于乐观主导的具有量子信号的表格强化学习算法，通过高效的量子均值估计技术获取代理获取的量子信号。通过深入的理论分析，我们证明了量子均值估计的优势能够在无限时域强化学习中导致遗憾保证的指数进展。具体地，所提出的量子算法实现了一个遗憾界为$\tilde{\mathcal{O}}(1)$的性能，这是相对于经典对应算法所展示的$\tilde{\mathcal{O}}(\sqrt{T})$界限的显著改进。

    This paper investigates the potential of quantum acceleration in addressing infinite horizon Markov Decision Processes (MDPs) to enhance average reward outcomes. We introduce an innovative quantum framework for the agent's engagement with an unknown MDP, extending the conventional interaction paradigm. Our approach involves the design of an optimism-driven tabular Reinforcement Learning algorithm that harnesses quantum signals acquired by the agent through efficient quantum mean estimation techniques. Through thorough theoretical analysis, we demonstrate that the quantum advantage in mean estimation leads to exponential advancements in regret guarantees for infinite horizon Reinforcement Learning. Specifically, the proposed Quantum algorithm achieves a regret bound of $\tilde{\mathcal{O}}(1)$, a significant improvement over the $\tilde{\mathcal{O}}(\sqrt{T})$ bound exhibited by classical counterparts.
    
[^308]: Denevil: 通过指导学习来解读和引导大型语言模型的道德价值

    Denevil: Towards Deciphering and Navigating the Ethical Values of Large Language Models via Instruction Learning. (arXiv:2310.11053v1 [cs.CL])

    [http://arxiv.org/abs/2310.11053](http://arxiv.org/abs/2310.11053)

    通过Moral Foundation Theory和DeNEVIL算法，我们研究了大型语言模型的道德价值，并构建了MoralPrompt数据集来评估模型的内在价值。发现大多数模型存在不对齐，需要进一步进行道德价值对齐。

    

    大型语言模型（LLM）取得了前所未有的突破，然而它们被越来越多地整合到日常生活中可能会带来由生成的不道德内容引起的社会风险。尽管已经对特定问题如偏见进行了广泛研究，但是从道德哲学的角度来看，LLM的内在价值仍然很少被探索。这项工作利用道德基础理论深入探讨道德价值。我们提出了DeNEVIL，一种新的提示生成算法，旨在动态利用LLM的价值脆弱性并以生成方式揭示伦理违规行为，揭示其潜在的价值倾向。在此基础上，我们构建了MoralPrompt，一个包含2,397个提示的高质量数据集，涵盖500多个价值原则，并对一系列LLM的内在价值进行了基准测试。我们发现大多数模型实质上是不对齐的，需要进一步进行道德价值对齐。

    Large Language Models (LLMs) have made unprecedented breakthroughs, yet their increasing integration into everyday life might raise societal risks due to generated unethical content. Despite extensive study on specific issues like bias, the intrinsic values of LLMs remain largely unexplored from a moral philosophy perspective. This work delves into ethical values utilizing Moral Foundation Theory. Moving beyond conventional discriminative evaluations with poor reliability, we propose DeNEVIL, a novel prompt generation algorithm tailored to dynamically exploit LLMs' value vulnerabilities and elicit the violation of ethics in a generative manner, revealing their underlying value inclinations. On such a basis, we construct MoralPrompt, a high-quality dataset comprising 2,397 prompts covering 500+ value principles, and then benchmark the intrinsic values across a spectrum of LLMs. We discovered that most models are essentially misaligned, necessitating further ethical value alignment. In r
    
[^309]: 通过语义格重排序提高自动语音识别系统中的上下文识别能力

    Improved Contextual Recognition In Automatic Speech Recognition Systems By Semantic Lattice Rescoring. (arXiv:2310.09680v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.09680](http://arxiv.org/abs/2310.09680)

    通过深度学习模型和transformer的重新评分，我们提出了一种通过语义格重排序来提高自动语音识别系统中上下文识别能力的方法。

    

    自动语音识别（ASR）受到了广泛的研究关注。最近的突破使得ASR系统在准确转录口语的能力上取得了重要进展，这是构建对话代理的关键进步。然而，准确辨别上下文相关的单词和短语仍然是一项迫切的挑战。在这项工作中，我们提出了一种通过语义格处理来增强ASR系统中上下文识别能力的新方法，利用深度学习模型在准确交付各种词汇和说话风格的转录方面具有出色的能力。我们的解决方案包括使用隐马尔可夫模型和高斯混合模型（HMM-GMM），以及深度神经网络（DNN）模型，将语言建模和声学建模结合起来，以获得更高的准确性。我们通过使用基于transformer的模型来重新评分单词格，使我们的网络具备了非凡的能力。

    Automatic Speech Recognition (ASR) has witnessed a profound research interest. Recent breakthroughs have given ASR systems different prospects such as faithfully transcribing spoken language, which is a pivotal advancement in building conversational agents. However, there is still an imminent challenge of accurately discerning context-dependent words and phrases. In this work, we propose a novel approach for enhancing contextual recognition within ASR systems via semantic lattice processing leveraging the power of deep learning models in accurately delivering spot-on transcriptions across a wide variety of vocabularies and speaking styles. Our solution consists of using Hidden Markov Models and Gaussian Mixture Models (HMM-GMM) along with Deep Neural Networks (DNN) models integrating both language and acoustic modeling for better accuracy. We infused our network with the use of a transformer-based model to properly rescore the word lattice achieving remarkable capabilities with a palpa
    
[^310]: HIO-SDF：层次增量在线有符号距离场

    HIO-SDF: Hierarchical Incremental Online Signed Distance Fields. (arXiv:2310.09463v1 [cs.RO])

    [http://arxiv.org/abs/2310.09463](http://arxiv.org/abs/2310.09463)

    HIO-SDF是一种新的层次增量在线有符号距离场方法，能够有效地表示大型、复杂的移动机器人工作空间，并能够以在线增量方式进行更新。

    

    一个良好的大型复杂移动机器人工作空间的表示必须是空间高效的，同时能够编码相关的几何细节。当探索未知环境时，它需要以在线增量方式进行更新。我们引入了HIO-SDF，一种将环境表示为有符号距离场（SDF）的新方法。目前SDF的最先进表示基于神经网络或体素网格。神经网络能够连续地表示SDF。然而，它们很难以增量方式进行更新，因为神经网络往往会忘记之前观察到的环境部分，除非存储了大量的传感器历史用于训练。基于体素的表示不具有这个问题，但在细节丰富的大型环境中不是空间高效的。HIO-SDF利用层次方法结合了这些表示的优势，使用粗糙的体素网格捕捉观测到的环境部分。

    A good representation of a large, complex mobile robot workspace must be space-efficient yet capable of encoding relevant geometric details. When exploring unknown environments, it needs to be updatable incrementally in an online fashion. We introduce HIO-SDF, a new method that represents the environment as a Signed Distance Field (SDF). State of the art representations of SDFs are based on either neural networks or voxel grids. Neural networks are capable of representing the SDF continuously. However, they are hard to update incrementally as neural networks tend to forget previously observed parts of the environment unless an extensive sensor history is stored for training. Voxel-based representations do not have this problem but they are not space-efficient especially in large environments with fine details. HIO-SDF combines the advantages of these representations using a hierarchical approach which employs a coarse voxel grid that captures the observed parts of the environment toget
    
[^311]: 通过同时学习面部标志检测、域分离和重建来提高面部动作单位检测的精度

    Boosting Facial Action Unit Detection Through Jointly Learning Facial Landmark Detection and Domain Separation and Reconstruction. (arXiv:2310.05207v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2310.05207](http://arxiv.org/abs/2310.05207)

    本文提出了一种新的面部动作单位（AU）检测框架，通过共享参数和引入多任务学习，在面部标志检测和AU域分离与重建之间实现了更好的性能。实验证明我们方法在野外AU检测方面优于现有方法。

    

    最近，如何将大量的在野非标记面部图像引入监督式面部动作单位（AU）检测框架中成为一个具有挑战性的问题。本文提出了一种新的AU检测框架，通过共享同构面部提取模块的参数，引入多任务学习，同时学习AU域分离和重建以及面部标志检测。另外，我们提出了一种基于对比学习的新特征对齐方案，通过简单的投影器和改进的对比损失添加了四个额外的中间监督器来促进特征重建的过程。在两个基准测试上的实验结果表明，我们在野外AU检测方面优于现有的方法。

    Recently how to introduce large amounts of unlabeled facial images in the wild into supervised Facial Action Unit (AU) detection frameworks has become a challenging problem. In this paper, we propose a new AU detection framework where multi-task learning is introduced to jointly learn AU domain separation and reconstruction and facial landmark detection by sharing the parameters of homostructural facial extraction modules. In addition, we propose a new feature alignment scheme based on contrastive learning by simple projectors and an improved contrastive loss, which adds four additional intermediate supervisors to promote the feature reconstruction process. Experimental results on two benchmarks demonstrate our superiority against the state-of-the-art methods for AU detection in the wild.
    
[^312]: 非光滑弱凸有限和耦合组合优化

    Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization. (arXiv:2310.03234v1 [math.OC])

    [http://arxiv.org/abs/2310.03234](http://arxiv.org/abs/2310.03234)

    本文研究了一种新的组合优化问题，称为非光滑弱凸有限和耦合组合优化(NSWC FCCO)，通过扩展已有的研究，我们研究了非光滑弱凸FCCO的问题，并提出了一种单循环算法来找到Moreau环的ε-稳定点。

    

    本文研究了一类新的组合优化问题，称为非光滑弱凸有限和耦合组合优化(NSWC FCCO)。由于其在机器学习和人工智能领域的广泛应用以及其解决基于经验风险最小化的随机算法的局限性，FCCO引起了越来越多的关注。然而，目前对于FCCO的研究假设内外函数都是光滑的，限制了其能够解决更多种类的问题的潜力。我们的研究从非光滑弱凸FCCO的角度进行了扩展，其中外函数是弱凸且非递减的，内函数是弱凸的。我们分析了一种单循环算法，并确定其在找到Moreau环的ε-稳定点的复杂度。

    This paper investigates new families of compositional optimization problems, called $\underline{\bf n}$on-$\underline{\bf s}$mooth $\underline{\bf w}$eakly-$\underline{\bf c}$onvex $\underline{\bf f}$inite-sum $\underline{\bf c}$oupled $\underline{\bf c}$ompositional $\underline{\bf o}$ptimization (NSWC FCCO). There has been a growing interest in FCCO due to its wide-ranging applications in machine learning and AI, as well as its ability to address the shortcomings of stochastic algorithms based on empirical risk minimization. However, current research on FCCO presumes that both the inner and outer functions are smooth, limiting their potential to tackle a more diverse set of problems. Our research expands on this area by examining non-smooth weakly-convex FCCO, where the outer function is weakly convex and non-decreasing, and the inner function is weakly-convex. We analyze a single-loop algorithm and establish its complexity for finding an $\epsilon$-stationary point of the Moreau env
    
[^313]: 将大型语言模型推至6G边缘：视野、挑战和机遇

    Pushing Large Language Models to the 6G Edge: Vision, Challenges, and Opportunities. (arXiv:2309.16739v1 [cs.LG])

    [http://arxiv.org/abs/2309.16739](http://arxiv.org/abs/2309.16739)

    本文探讨了将大型语言模型(LLMs)部署在6G边缘的潜力和挑战。我们介绍了由LLMs支持的关键应用，并从响应时间、带宽成本和数据隐私等方面分析了云端部署面临的问题。我们提出了6G移动边缘计算(MEC)系统可能解决这些问题的方案，并讨论了边缘训练和边缘推理的创新技术。

    

    大型语言模型(LLMs)展示了显著的能力，正在改变人工智能的发展并有可能塑造我们的未来。然而，由于LLMs的多模态特性，当前的基于云的部署面临着一些关键挑战：1) 响应时间长；2) 高带宽成本；以及3) 违反数据隐私。6G移动边缘计算(MEC)系统可能解决这些迫切问题。本文探讨了在6G边缘部署LLMs的潜力。我们首先介绍了由多模态LLMs提供支持的关键应用，包括机器人技术和医疗保健，以突出在终端用户附近部署LLMs的需求。然后，我们确定了在边缘部署LLMs时面临的关键挑战，并设想了适用于LLMs的6G MEC架构。此外，我们深入探讨了两个设计方面，即LLMs的边缘训练和边缘推理。在这两个方面，考虑到边缘的固有资源限制，我们讨论了各种前沿技术。

    Large language models (LLMs), which have shown remarkable capabilities, are revolutionizing AI development and potentially shaping our future. However, given their multimodality, the status quo cloud-based deployment faces some critical challenges: 1) long response time; 2) high bandwidth costs; and 3) the violation of data privacy. 6G mobile edge computing (MEC) systems may resolve these pressing issues. In this article, we explore the potential of deploying LLMs at the 6G edge. We start by introducing killer applications powered by multimodal LLMs, including robotics and healthcare, to highlight the need for deploying LLMs in the vicinity of end users. Then, we identify the critical challenges for LLM deployment at the edge and envision the 6G MEC architecture for LLMs. Furthermore, we delve into two design aspects, i.e., edge training and edge inference for LLMs. In both aspects, considering the inherent resource limitations at the edge, we discuss various cutting-edge techniques, i
    
[^314]: 对比度连续多视角聚类与过滤结构融合

    Contrastive Continual Multi-view Clustering with Filtered Structural Fusion. (arXiv:2309.15135v1 [cs.LG])

    [http://arxiv.org/abs/2309.15135](http://arxiv.org/abs/2309.15135)

    提出了一种名为对比度连续多视角聚类与过滤结构融合（CCMVC-FSF）的新方法，用于解决多视角聚类在实时数据收集中的困难。该方法旨在防止先前知识遗忘和利用数据相关性指导新视图的聚类过程。

    

    多视角聚类适用于先前收集视图并提取一致和互补信息的应用，但忽略了数据视图按顺序收集的实时数据的情况。为了解决这个问题，我们提出了一种名为对比度连续多视角聚类与过滤结构融合（CCMVC-FSF）的新方法，以应对先前知识遗忘和新视图聚类的问题。

    Multi-view clustering thrives in applications where views are collected in advance by extracting consistent and complementary information among views. However, it overlooks scenarios where data views are collected sequentially, i.e., real-time data. Due to privacy issues or memory burden, previous views are not available with time in these situations. Some methods are proposed to handle it but are trapped in a stability-plasticity dilemma. In specific, these methods undergo a catastrophic forgetting of prior knowledge when a new view is attained. Such a catastrophic forgetting problem (CFP) would cause the consistent and complementary information hard to get and affect the clustering performance. To tackle this, we propose a novel method termed Contrastive Continual Multi-view Clustering with Filtered Structural Fusion (CCMVC-FSF). Precisely, considering that data correlations play a vital role in clustering and prior knowledge ought to guide the clustering process of a new view, we de
    
[^315]: 通过屏蔽实现安全的POMDP在线规划

    Safe POMDP Online Planning via Shielding. (arXiv:2309.10216v1 [cs.AI])

    [http://arxiv.org/abs/2309.10216](http://arxiv.org/abs/2309.10216)

    通过计算屏蔽动作来实现安全的POMDP在线规划。四种屏蔽方法。

    

    部分可观察的马尔可夫决策过程（POMDP）广泛应用于许多机器人应用中，用于在不确定性下进行序列决策。POMDP在线规划算法，如部分可观察的蒙特卡洛规划（POMCP），可以解决目标为最大化预期回报的大型POMDP。但是，由此产生的策略无法提供对于现实世界中安全关键任务（如自动驾驶）至关重要的安全保证。在本文中，我们考虑安全要求，将其表示为几乎一定的到达-避免规范（即，达到一组目标状态的概率为1，达到一组不安全状态的概率为0）。我们计算限制违反几乎一定到达-避免规范的不安全动作的屏蔽。然后，将这些屏蔽集成到POMCP算法中以实现安全的POMDP在线规划。我们提出了四种不同的屏蔽方法，根据屏蔽的计算和集成方式的不同，包括分解方式。

    Partially observable Markov decision processes (POMDPs) have been widely used in many robotic applications for sequential decision-making under uncertainty. POMDP online planning algorithms such as Partially Observable Monte-Carlo Planning (POMCP) can solve very large POMDPs with the goal of maximizing the expected return. But the resulting policies cannot provide safety guarantees that are imperative for real-world safety-critical tasks (e.g., autonomous driving). In this work, we consider safety requirements represented as almost-sure reach-avoid specifications (i.e., the probability to reach a set of goal states is one and the probability to reach a set of unsafe states is zero). We compute shields that restrict unsafe actions violating almost-sure reach-avoid specifications. We then integrate these shields into the POMCP algorithm for safe POMDP online planning. We propose four distinct shielding methods, differing in how the shields are computed and integrated, including factored 
    
[^316]: 基于Hoeffding树和变点检测机制的连续学习场景下的天然气消费预测系统

    A Natural Gas Consumption Forecasting System for Continual Learning Scenarios based on Hoeffding Trees with Change Point Detection Mechanism. (arXiv:2309.03720v1 [cs.LG])

    [http://arxiv.org/abs/2309.03720](http://arxiv.org/abs/2309.03720)

    本文介绍了一个基于Hoeffding树和变点检测机制的连续学习场景下的天然气消费预测系统，通过数据流处理，实现了多步 ahead 的预测和持续学习能力。在复杂的实际应用场景中，通过评估预测模型的性能，证明了该方法的有效性。

    

    在规划天然气供应和消费以及优化获得天然气成本方面，考虑季节性和趋势性的天然气消费预测至关重要。本文介绍了一种新颖的多步 ahead 的天然气消费预测方法，并集成了变点检测，以实现模型选择和持续学习能力。通过数据流处理，评估了基于该方法的天然气消费预测模型在复杂的实际应用场景中的性能。我们采用Hoeffding树预测器作为预测模型，并使用剪裁的精确线性时间（PELT）算法进行变点检测。变点检测集成使得选择不同的模型成为可能。

    Forecasting natural gas consumption, considering seasonality and trends, is crucial in planning its supply and consumption and optimizing the cost of obtaining it, mainly by industrial entities. However, in times of threats to its supply, it is also a critical element that guarantees the supply of this raw material to meet individual consumers' needs, ensuring society's energy security. This article introduces a novel multistep ahead forecasting of natural gas consumption with change point detection integration for model collection selection with continual learning capabilities using data stream processing. The performance of the forecasting models based on the proposed approach is evaluated in a complex real-world use case of natural gas consumption forecasting. We employed Hoeffding tree predictors as forecasting models and the Pruned Exact Linear Time (PELT) algorithm for the change point detection procedure. The change point detection integration enables selecting a different model
    
[^317]: 用于机器人操作的具有物理基础的视觉语言模型

    Physically Grounded Vision-Language Models for Robotic Manipulation. (arXiv:2309.02561v1 [cs.RO])

    [http://arxiv.org/abs/2309.02561](http://arxiv.org/abs/2309.02561)

    该论文介绍了一个用于机器人操作的具有物理基础的视觉语言模型，通过在物体上微调模型，提高了模型对物理概念的理解，在语言交互框架中展现了良好的性能。

    

    最近对于视觉语言模型（VLMs）的研究进展导致在视觉问答和图像描述等任务上的性能得到了提升。因此，这些模型现在可以在物理世界中进行推理，特别是在机器人操作领域。然而，当前的VLMs在对常见物体的物理概念（例如材料、脆弱性）的理解方面存在局限，这限制了它们在涉及与这些物体的相互作用和物理推理的机器人操作任务中的实用性。为了解决这个问题，我们提出了PhysObjects，这是一个以物体为中心的数据集，包含36.9K个众包和417K个自动化的常见家居物品的物理概念注释。我们证明，在PhysObjects上对VLM进行微调可以提高其对物理物体概念的理解，通过从视觉外观中捕捉这些概念的人类先验知识。我们在一个大型的语言交互框架中将这个具有物理基础的VLM结合在一起。

    Recent advances in vision-language models (VLMs) have led to improved performance on tasks such as visual question answering and image captioning. Consequently, these models are now well-positioned to reason about the physical world, particularly within domains such as robotic manipulation. However, current VLMs are limited in their understanding of the physical concepts (e.g., material, fragility) of common objects, which restricts their usefulness for robotic manipulation tasks that involve interaction and physical reasoning about such objects. To address this limitation, we propose PhysObjects, an object-centric dataset of 36.9K crowd-sourced and 417K automated physical concept annotations of common household objects. We demonstrate that fine-tuning a VLM on PhysObjects improves its understanding of physical object concepts, by capturing human priors of these concepts from visual appearance. We incorporate this physically-grounded VLM in an interactive framework with a large languag
    
[^318]: MindMap：知识图谱激发大型语言模型的思维图思考方法

    MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models. (arXiv:2308.09729v1 [cs.AI])

    [http://arxiv.org/abs/2308.09729](http://arxiv.org/abs/2308.09729)

    本论文通过使用知识图谱来激发大型语言模型，解决了整合新知识、产生幻觉和决策过程不透明等问题，并通过生成思维导图展示了模型的推理路径，实验证明这种方法可以取得显著的实证增益。

    

    通常，大型语言模型存在无法整合新知识、产生幻觉和决策过程不透明等限制。本文探讨了如何利用知识图谱（KG）来激发大型语言模型，以解决整合最新知识和引发模型思维路径的问题。具体来说，我们构建了一个提示管道，使大型语言模型能够理解KG输入并利用隐含知识和检索到的外部知识进行推理。此外，我们研究了引发大型语言模型执行推理和生成答案的思维导图。研究发现，生成的思维导图基于知识的本体论，展示了大型语言模型的推理路径，从而为生产环境中的推理提供了探索和评估的可能性。对三个问答数据集的实验证明，MindMap提示方法带来了显著的实证增益。

    LLMs usually exhibit limitations in their ability to incorporate new knowledge, the generation of hallucinations, and the transparency of their decision-making process. In this paper, we explore how to prompt LLMs with knowledge graphs (KG), working as a remedy to engage LLMs with up-to-date knowledge and elicit the reasoning pathways from LLMs. Specifically, we build a prompting pipeline that endows LLMs with the capability of comprehending KG inputs and inferring with a combined implicit knowledge and the retrieved external knowledge. In addition, we investigate eliciting the mind map on which LLMs perform the reasoning and generate the answers. It is identified that the produced mind map exhibits the reasoning pathways of LLMs grounded on the ontology of knowledge, hence bringing the prospects of probing and gauging LLM inference in production. The experiments on three question & answering datasets also show that MindMap prompting leads to a striking empirical gain. For instance, pr
    
[^319]: 思维的骨架：大型语言模型可以进行并行解码

    Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding. (arXiv:2307.15337v1 [cs.CL])

    [http://arxiv.org/abs/2307.15337](http://arxiv.org/abs/2307.15337)

    本研究提出了一种名为“思维的骨架”的方法，可以通过并行解码来减少大型语言模型的生成延迟。这种方法不仅显著提高了速度，还可以潜在地提高答案质量。

    

    本研究旨在减少大型语言模型（LLMs）的端到端生成延迟。高生成延迟的一个主要原因是几乎所有最先进的LLMs都采用了顺序解码方法。在本研究中，受到人类的思考和写作过程的启发，我们提出了“思维的骨架”（SoT），它指导LLMs首先生成答案的骨架，然后通过并行API调用或批量解码来并行完成每个骨架点的内容。SoT不仅显著提高了速度（在11个不同的LLMs上提高了最多2.39倍），而且还可以潜在地提高在多个问题类别上的答案质量，包括多样性和相关性。SoT是一种针对效率的数据导向优化的初步尝试，并揭示了将LLMs推动更像人类思考以提高答案质量的潜力。

    This work aims at decreasing the end-to-end generation latency of large language models (LLMs). One of the major causes of the high generation latency is the sequential decoding approach adopted by almost all state-of-the-art LLMs. In this work, motivated by the thinking and writing process of humans, we propose "Skeleton-of-Thought" (SoT), which guides LLMs to first generate the skeleton of the answer, and then conducts parallel API calls or batched decoding to complete the contents of each skeleton point in parallel. Not only does SoT provide considerable speed-up (up to 2.39x across 11 different LLMs), but it can also potentially improve the answer quality on several question categories in terms of diversity and relevance. SoT is an initial attempt at data-centric optimization for efficiency, and reveal the potential of pushing LLMs to think more like a human for answer quality.
    
[^320]: 用物理信知的神经网络解决维度诅咒问题

    Tackling the Curse of Dimensionality with Physics-Informed Neural Networks. (arXiv:2307.12306v1 [cs.LG])

    [http://arxiv.org/abs/2307.12306](http://arxiv.org/abs/2307.12306)

    本文提出了一种新方法，利用物理信知的神经网络(PINNs)解决高维度的偏微分方程(PDEs)问题，并证明了收敛性和其他期望属性。

    

    维度诅咒(CoD)随着维度的增加，以指数级增长的计算成本来极度税费计算资源。这在解决高维偏微分方程(PDEs)中面临极大挑战，正如Richard Bellman在60年前首次指出的那样。尽管近年来在高维度上数值解决偏微分方程(PDEs)取得了一些成功，但这样的计算代价过高，而将一般非线性PDEs扩展到高维度从未实现过。本文提出了一种新方法，将物理信知的神经网络(PINNs)扩展到解决任意高维PDEs。该新方法称为随机维度梯度下降(SDGD)，将PDE的梯度分解为与不同维度对应的部分，并在训练PINNs的每次迭代中随机选择这些维度部分的子集进行采样。我们在理论上证明了所提出方法的收敛保证和其他期望属性。

    The curse-of-dimensionality (CoD) taxes computational resources heavily with exponentially increasing computational cost as the dimension increases. This poses great challenges in solving high-dimensional PDEs as Richard Bellman first pointed out over 60 years ago. While there has been some recent success in solving numerically partial differential equations (PDEs) in high dimensions, such computations are prohibitively expensive, and true scaling of general nonlinear PDEs to high dimensions has never been achieved. In this paper, we develop a new method of scaling up physics-informed neural networks (PINNs) to solve arbitrary high-dimensional PDEs. The new method, called Stochastic Dimension Gradient Descent (SDGD), decomposes a gradient of PDEs into pieces corresponding to different dimensions and samples randomly a subset of these dimensional pieces in each iteration of training PINNs. We theoretically prove the convergence guarantee and other desired properties of the proposed meth
    
[^321]: LabelBench：基于综合框架的标签高效学习基准评估

    LabelBench: A Comprehensive Framework for Benchmarking Label-Efficient Learning. (arXiv:2306.09910v1 [cs.LG])

    [http://arxiv.org/abs/2306.09910](http://arxiv.org/abs/2306.09910)

    本论文介绍了一个新的综合性标签高效学习基准评估框架LabelBench，并通过引入一种新的与半监督学习相结合的主动学习方法的基准测试，证明了在相对较少的标记示例下实现更好的标签效率。

    

    标记数据是现代机器学习应用程序的关键，但获取标记可能很昂贵。为了减缓这一成本，机器学习方法（如迁移学习、半监督学习和主动学习）旨在实现标签高效性：从相对较少的标记示例中实现高预测性能。虽然在实践中获得最佳的标签效率通常需要这些技术的组合，但现有的基准评估框架并没有捕捉到所有这些技术的协同组合。本文通过引入LabelBench解决了这个缺陷，这是一个新的计算效率高的综合性框架，用于联合评估多个标签高效学习技术。作为LabelBench的一个应用，我们引入了一种与半监督学习一起使用的最新主动学习方法的新基准，用于微调预训练的视觉转换器。我们的基准证明了比先前报告的更好的标签效率。

    Labeled data are critical to modern machine learning applications, but obtaining labels can be expensive. To mitigate this cost, machine learning methods, such as transfer learning, semi-supervised learning and active learning, aim to be label-efficient: achieving high predictive performance from relatively few labeled examples. While obtaining the best label-efficiency in practice often requires combinations of these techniques, existing benchmark and evaluation frameworks do not capture a concerted combination of all such techniques. This paper addresses this deficiency by introducing LabelBench, a new computationally-efficient framework for joint evaluation of multiple label-efficient learning techniques. As an application of LabelBench, we introduce a novel benchmark of state-of-the-art active learning methods in combination with semi-supervised learning for fine-tuning pretrained vision transformers. Our benchmark demonstrates better label-efficiencies than previously reported in 
    
[^322]: DCTX-Conformer：针对低延迟统一流式和非流式Conformer的动态上下文传递

    DCTX-Conformer: Dynamic context carry-over for low latency unified streaming and non-streaming Conformer. (arXiv:2306.08175v1 [eess.AS])

    [http://arxiv.org/abs/2306.08175](http://arxiv.org/abs/2306.08175)

    提出了一种基于Conformer的新型动态上下文传递机制DCTX-Conformer，解决了流式识别性能差距的问题，相比于现有最优解，识别结果的误差率提高了25%，但对延迟影响可以忽略不计。

    

    基于Conformer的端到端模型现在已经变得普遍，被广泛用于流式和非流式自动语音识别（ASR）中。诸如双模式和动态分块训练等技术有助于统一流式和非流式系统。然而，在完整和有限的过去上下文的情况下，流式识别之间仍然存在着性能差距。为了解决这个问题，我们提出了一种新颖的动态上下文传递机制，将其与现有的最先进的统一ASR系统进行集成。我们的提议——动态上下文Conformer（DCTX-Conformer）利用了一个非重叠的上下文传递机制，同时考虑了一块的左上下文和一个或多个先前的上下文嵌入。由于额外的上下文嵌入，我们相对于目前最优解提升了25.0%的词错误率，而延迟影响可以忽略不计。

    Conformer-based end-to-end models have become ubiquitous these days and are commonly used in both streaming and non-streaming automatic speech recognition (ASR). Techniques like dual-mode and dynamic chunk training helped unify streaming and non-streaming systems. However, there remains a performance gap between streaming with a full and limited past context. To address this issue, we propose the integration of a novel dynamic contextual carry-over mechanism in a state-of-the-art (SOTA) unified ASR system. Our proposed dynamic context Conformer (DCTX-Conformer) utilizes a non-overlapping contextual carry-over mechanism that takes into account both the left context of a chunk and one or more preceding context embeddings. We outperform the SOTA by a relative 25.0% word error rate, with a negligible latency impact due to the additional context embeddings.
    
[^323]: Mol-Instructions: 一个大规模生物分子指令数据集，为大语言模型提供支持

    Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models. (arXiv:2306.08018v1 [q-bio.QM])

    [http://arxiv.org/abs/2306.08018](http://arxiv.org/abs/2306.08018)

    Mol-Instructions是一个专门为生物分子领域设计的综合指令数据集，可以显著提高大语言模型在生物领域中的适应能力和认知敏锐度。

    

    大语言模型（LLM）以其卓越的任务处理能力和创新的输出，在许多领域推动了重大进展。然而，它们在生物分子研究等专业领域的熟练应用还受到限制。为了解决这个挑战，我们介绍了Mol-Instructions，这是一个经过精心策划、专门针对生物分子领域设计的综合指令数据集。Mol-Instructions由三个关键组成部分组成：分子导向指令、蛋白质导向指令和生物分子文本指令，每个部分都被策划用于增强LLM对生物分子特性和行为的理解和预测能力。通过对代表性LLM的广泛指令调整实验，我们强调了Mol-Instructions在增强大模型在生物分子研究复杂领域内的适应能力和认知敏锐度方面的潜力，从而促进生物分子领域的进一步发展。

    Large Language Models (LLMs), with their remarkable task-handling capabilities and innovative outputs, have catalyzed significant advancements across a spectrum of fields. However, their proficiency within specialized domains such as biomolecular studies remains limited. To address this challenge, we introduce Mol-Instructions, a meticulously curated, comprehensive instruction dataset expressly designed for the biomolecular realm. Mol-Instructions is composed of three pivotal components: molecule-oriented instructions, protein-oriented instructions, and biomolecular text instructions, each curated to enhance the understanding and prediction capabilities of LLMs concerning biomolecular features and behaviors. Through extensive instruction tuning experiments on the representative LLM, we underscore the potency of Mol-Instructions to enhance the adaptability and cognitive acuity of large models within the complex sphere of biomolecular studies, thereby promoting advancements in the biomol
    
[^324]: 一个基于网络计算的Metaverse动态部分计算卸载方案

    A Dynamic Partial Computation Offloading for the Metaverse in In-Network Computing. (arXiv:2306.06022v1 [cs.DC])

    [http://arxiv.org/abs/2306.06022](http://arxiv.org/abs/2306.06022)

    该论文提出了一个基于网络计算的Metaverse动态部分计算卸载方案，能够在动态调整卸载策略的同时最小化能耗和延迟，解决了多个子任务的部分计算卸载问题，并将其分解为了两个子问题，分别针对用户端的任务切分问题和COIN端的任务卸载问题。这需要使用序数潜在博弈（OPG）和马尔可夫决策过程（MDP）来提出模型，并使用双重深度Q网络（DDQN）来解决最优卸载策略的问题。

    

    基于网络计算（COIN）范式是一个利用未使用的网络资源来执行某些任务以满足计算密集型应用程序（如Metaverse）的有前途的解决方案。在此基础上，我们考虑在COIN环境中针对Metaverse的多个子任务的部分计算卸载问题，以在动态调整卸载策略的同时最小化能耗和延迟。我们证明了该问题是NP难题，将其转化为两个子问题：用户端的任务切分问题（TSP）和COIN端的任务卸载问题（TOP）。我们将TSP建模为序数潜在博弈（OPG），并提出了一种分散算法来获取其纳什平衡（NE）。然后，我们将TOP建模为马尔可夫决策过程（MDP），提出了双重深度Q网络（DDQN）来解决最优卸载策略的问题。与传统的DDQN算法不同，智能代理在此不以随机方式抽样卸载决策

    The In-Network Computing (COIN) paradigm is a promising solution that leverages unused network resources to perform some tasks to meet up with computation-demanding applications, such as metaverse. In this vein, we consider the metaverse partial computation offloading problem for multiple subtasks in a COIN environment to minimise energy consumption and delay while dynamically adjusting the offloading policy based on the changing computation resources status. We prove that the problem is NP and thus transformed it into two subproblems: task splitting problem (TSP) on the user side and task offloading problem (TOP) on the COIN side. We modelled the TSP as an ordinal potential game (OPG) and proposed a decentralised algorithm to obtain its Nash Equilibrium (NE). Then, we model the TOP as Markov Decision Process (MDP) proposed double deep Q-network (DDQN) to solve for the optimal offloading policy. Unlike the conventional DDQN algorithm, where intelligent agents sample offloading decision
    
[^325]: LLM集成应用中的提示注入攻击研究

    Prompt Injection attack against LLM-integrated Applications. (arXiv:2306.05499v1 [cs.CR])

    [http://arxiv.org/abs/2306.05499](http://arxiv.org/abs/2306.05499)

    本研究分析了LLM集成应用中的提示注入攻击的复杂性和影响，提出了一种新颖的黑盒提示注入攻击技术HouYi，并揭示了应用程序提示机制中以前未知和严重低估的漏洞。我们的研究呼吁进一步开发全面的防御措施，以抵御LLM集成应用中的提示注入攻击。

    

    大语言模型(LLM)因其卓越的语言理解和生成能力而在它们周围刺激了一个充满活力的应用生态系统。然而，它们在各种服务中的广泛融合带来了重大的安全风险。本研究将解构实际LLM集成应用中的提示注入攻击的复杂性和影响。最初，我们对十个商业应用程序进行了探索性分析，突出了目前攻击策略在实践中的约束条件。受这些限制的启发，我们随后制定了HouYi，一种新颖的黑盒提示注入攻击技术，它借鉴了传统的Web注入攻击。HouYi分为三个关键元素: 一个无缝集成的预构建提示、一个注入提示诱导上下文分区以及一个恶意载荷，旨在实现攻击目标。利用HouYi，我们揭示了应用程序提示机制中以前未知和严重低估的漏洞，并演示了绕过最先进的检测机制的可行性。我们的研究呼吁进一步研究开发全面的防御措施，以抵御LLM集成应用中的提示注入攻击。

    Large Language Models (LLMs), renowned for their superior proficiency in language comprehension and generation, stimulate a vibrant ecosystem of applications around them. However, their extensive assimilation into various services introduces significant security risks. This study deconstructs the complexities and implications of prompt injection attacks on actual LLM-integrated applications. Initially, we conduct an exploratory analysis on ten commercial applications, highlighting the constraints of current attack strategies in practice. Prompted by these limitations, we subsequently formulate HouYi, a novel black-box prompt injection attack technique, which draws inspiration from traditional web injection attacks. HouYi is compartmentalized into three crucial elements: a seamlessly-incorporated pre-constructed prompt, an injection prompt inducing context partition, and a malicious payload designed to fulfill the attack objectives. Leveraging HouYi, we unveil previously unknown and sev
    
[^326]: 一种基于强化学习的方法促进算法代理与LLM之间的高效互动

    Enabling Efficient Interaction between an Algorithm Agent and an LLM: A Reinforcement Learning Approach. (arXiv:2306.03604v1 [cs.AI])

    [http://arxiv.org/abs/2306.03604](http://arxiv.org/abs/2306.03604)

    本论文提出一种强化学习的中介模型，可实现代理与LLM之间高效经济有效的互动，提高效率和成本效益。

    

    大型语言模型(LLMs)包含从海量文本数据集中获取的大量世界知识。最近的研究表明，LLMs可以通过提供高层指令来协助算法代理解决具有复杂顺序决策的任务。然而，与LLMs进行交互可能耗时较长，因为在许多实际情况下，它们需要大量存储空间，只能部署在远程云服务器节点上。此外，使用商业LLMs可能成本很高，因为它们可能根据使用频率收费。本文探讨如何实现代理与LLM之间的高效和经济有效的互动。我们提出了一种基于强化学习的中介模型，以确定何时需要查询LLMs以完成目标任务的高级指令。在涉及规划子目标的4个MiniGrid环境上进行的实验表明，我们的方法可以学习解决目标任务，并提升了效率和成本效益。

    Large language models (LLMs) encode a vast amount of world knowledge acquired from massive text datasets. Recent studies have demonstrated that LLMs can assist an algorithm agent in solving complex sequential decision making tasks in embodied environments by providing high-level instructions. However, interacting with LLMs can be time-consuming, as in many practical scenarios, they require a significant amount of storage space that can only be deployed on remote cloud server nodes. Additionally, using commercial LLMs can be costly since they may charge based on usage frequency. In this paper, we explore how to enable efficient and cost-effective interactions between the agent and an LLM. We propose a reinforcement learning based mediator model that determines when it is necessary to consult LLMs for high-level instructions to accomplish a target task. Experiments on 4 MiniGrid environments that entail planning sub-goals demonstrate that our method can learn to solve target tasks with o
    
[^327]: 多目标遗传算法用于多视角特征选择

    Multi-Objective Genetic Algorithm for Multi-View Feature Selection. (arXiv:2305.18352v1 [cs.NE])

    [http://arxiv.org/abs/2305.18352](http://arxiv.org/abs/2305.18352)

    多视角数据提高了预测模型的准确性，但也使得高维数据增加，影响模型泛化能力。研究者提出了一种多视角多目标特征选择遗传算法（MMFS-GA），用于从多视角数据中选择最优的特征子集以提高模型精度和可解释性。

    

    多视角数据集提供了不同形式的数据，可以通过提供补充信息来增强预测模型。但是，使用多视角数据会导致高维数据的增加，这对可以导致泛化能力差的预测模型带来显著挑战。因此，从多视角数据集中选择相关特征不仅可以解决不良的泛化能力，还可以增强模型的可解释性。尽管传统特征选择方法取得了成功，但它们在利用跨模态的内在信息、缺乏泛化性和适用于特定分类任务方面存在局限性。我们提出了一种新的遗传算法策略，以克服传统特征选择方法在多视角数据上的这些局限性。我们提出的方法称为多视角多目标特征选择遗传算法（MMFS-GA）。这种方法同时选择最优的特征子集。

    Multi-view datasets offer diverse forms of data that can enhance prediction models by providing complementary information. However, the use of multi-view data leads to an increase in high-dimensional data, which poses significant challenges for the prediction models that can lead to poor generalization. Therefore, relevant feature selection from multi-view datasets is important as it not only addresses the poor generalization but also enhances the interpretability of the models. Despite the success of traditional feature selection methods, they have limitations in leveraging intrinsic information across modalities, lacking generalizability, and being tailored to specific classification tasks. We propose a novel genetic algorithm strategy to overcome these limitations of traditional feature selection methods for multi-view data. Our proposed approach, called the multi-view multi-objective feature selection genetic algorithm (MMFS-GA), simultaneously selects the optimal subset of feature
    
[^328]: 从未知奖励的演示中学习安全约束

    Learning Safety Constraints from Demonstrations with Unknown Rewards. (arXiv:2305.16147v1 [cs.LG])

    [http://arxiv.org/abs/2305.16147](http://arxiv.org/abs/2305.16147)

    CoCoRL是一种从不知道奖励的已知安全演示中推断约束的方法，可以用于Constrained Markov Decision Process（CMDP），并且对于几乎最优演示能够无误差收敛于真实的安全集。

    

    本文提出了一种新方法，Convex Constraint Learning for Reinforcement Learning (CoCoRL)，用于从一组已知安全演示中推断Constrained Markov Decision Process (CMDP)的共享约束。与以前的方法只限于已知奖励或完全已知环境动态的演示相比，CoCoRL可以从具有不同未知奖励的演示中学习约束，而无需了解环境动态。CoCoRL基于演示构建了一个凸安全集，即使是潜在的次优演示也能保证安全。对于几乎最优演示，CoCoRL能够无误差收敛于真实的安全集。我们在表格环境和一个包含多个约束的连续驾驶仿真中评估CoCoRL。CoCoRL学习到的限制导致了安全的驾驶行为，并可以转移到不同的任务和环境。与之相反，基于学习已知回报的替代方法无法推广到具有不同回报的新环境，突显了CoCoRL在不知道回报函数的情况下学习约束的重要性。

    We propose Convex Constraint Learning for Reinforcement Learning (CoCoRL), a novel approach for inferring shared constraints in a Constrained Markov Decision Process (CMDP) from a set of safe demonstrations with possibly different reward functions. While previous work is limited to demonstrations with known rewards or fully known environment dynamics, CoCoRL can learn constraints from demonstrations with different unknown rewards without knowledge of the environment dynamics. CoCoRL constructs a convex safe set based on demonstrations, which provably guarantees safety even for potentially sub-optimal (but safe) demonstrations. For near-optimal demonstrations, CoCoRL converges to the true safe set with no policy regret. We evaluate CoCoRL in tabular environments and a continuous driving simulation with multiple constraints. CoCoRL learns constraints that lead to safe driving behavior and that can be transferred to different tasks and environments. In contrast, alternative methods based 
    
[^329]: 使用神经薛定谔桥实现非配对图像转换

    Unpaired Image-to-Image Translation via Neural Schr\"odinger Bridge. (arXiv:2305.15086v1 [cs.CV])

    [http://arxiv.org/abs/2305.15086](http://arxiv.org/abs/2305.15086)

    本文提出了一种方法——非配对神经薛定谔桥 (UNSB)，它结合了薛定谔桥、对抗训练和正则化，用于在非配对数据之间学习 SDE，并成功解决了许多非配对图像转换任务。

    

    扩散模型是一类生成模型，它通过模拟随机微分方程（SDE）从噪声生成数据。尽管扩散模型在最近取得了显著进展，但由于高斯先验假设，它们在非配对的图像转换任务中存在局限性。薛定谔桥是一种学习 SDE 以在两个任意分布之间转换的方法，被视为解决这个问题的一种有吸引力的解决方案。然而，迄今为止，薛定谔桥模型在高分辨率图像之间的非配对转换方面并不成功。在这项工作中，我们提出了非配对神经薛定谔桥（UNSB），它将薛定谔桥与对抗性训练和正则化相结合，以学习非配对数据之间的 SDE。我们证明了 UNSB 是可伸缩的，并且成功解决了各种非配对图像转换任务。

    Diffusion models are a powerful class of generative models which simulate stochastic differential equations (SDEs) to generate data from noise. Although diffusion models have achieved remarkable progress in recent years, they have limitations in the unpaired image-to-image translation tasks due to the Gaussian prior assumption. Schr\"odinger Bridge (SB), which learns an SDE to translate between two arbitrary distributions, have risen as an attractive solution to this problem. However, none of SB models so far have been successful at unpaired translation between high-resolution images. In this work, we propose the Unpaired Neural Schr\"odinger Bridge (UNSB), which combines SB with adversarial training and regularization to learn a SB between unpaired data. We demonstrate that UNSB is scalable, and that it successfully solves various unpaired image-to-image translation tasks. Code: \url{https://github.com/cyclomon/UNSB}
    
[^330]: 深度时间图聚类

    Deep Temporal Graph Clustering. (arXiv:2305.10738v1 [cs.LG])

    [http://arxiv.org/abs/2305.10738](http://arxiv.org/abs/2305.10738)

    提出通用框架TGC 用于 deep temporal graph clustering, 解决了时间图只能作为静态图处理的难题，实现了对动态信息的聚类。实验证明了 TGC 的优越性。

    

    最近深度图聚类已经引起了很多关注，因为它可以增强模型在无监督场景下的表示学习能力。然而，适用于时间图的深度聚类方法 - 可以捕获关键的动态交互信息，并没有得到充分的探索。这意味着在许多面向聚类的现实场景中，时间图只能作为静态图来处理。这不仅导致了动态信息的丢失，也引发了巨大的计算消耗。为了解决这个问题，我们提出了一个名为TGC的通用框架，用于时间图深度聚类，它调整了深度聚类技术（聚类分配分布和邻接矩阵重构），以适应时间图基于交互序列的批处理模式。此外，我们还从几个方面讨论了时间图聚类与现有静态图聚类的差异。实验证明了TGC的卓越性能。

    Deep graph clustering has recently received significant attention due to its ability to enhance the representation learning capabilities of models in unsupervised scenarios. Nevertheless, deep clustering for temporal graphs, which could capture crucial dynamic interaction information, has not been fully explored. It means that in many clustering-oriented real-world scenarios, temporal graphs can only be processed as static graphs. This not only causes the loss of dynamic information but also triggers huge computational consumption. To solve the problem, we propose a general framework for deep Temporal Graph Clustering called TGC, which adjusts deep clustering techniques (clustering assignment distribution and adjacency matrix reconstruction) to suit the interaction sequence-based batch-processing pattern of temporal graphs. In addition, we discuss differences between temporal graph clustering and existing static graph clustering from several levels. To verify the superiority of the pro
    
[^331]: 基于提示的预训练语言模型用于时间知识图谱补全

    Pre-trained Language Model with Prompts for Temporal Knowledge Graph Completion. (arXiv:2305.07912v1 [cs.CL])

    [http://arxiv.org/abs/2305.07912](http://arxiv.org/abs/2305.07912)

    这篇论文提出了一种基于提示的预训练语言模型（PPT），用于时间知识图谱补全。通过遮盖策略，将TKGC任务转换为遮盖词预测任务，可以利用预训练语言模型中的语义信息。

    

    时间知识图谱补全（TKGC）是一项重要的任务，它涉及在已知的时间戳上进行推理，以完成缺失部分的事实，并在近年来越来越受到关注。大多数现有方法都集中于基于图神经网络的学习表示，同时粗略地提取时间戳中的信息，并不充分利用关系中隐含的信息。为了解决这些问题，我们提出了一种新的TKGC模型，即基于提示的预训练语言模型（PPT）。我们将一系列采样的四元组转换为预训练语言模型的输入，并将时间戳之间的间隔转换为不同的提示，以形成带有隐含语义信息的连贯句子。我们使用遮盖策略训练我们的模型，将TKGC任务转换为遮盖词预测任务，从而可以利用预训练语言模型中的语义信息。实验结果和广泛的分析表明，

    Temporal Knowledge graph completion (TKGC) is a crucial task that involves reasoning at known timestamps to complete the missing part of facts and has attracted more and more attention in recent years. Most existing methods focus on learning representations based on graph neural networks while inaccurately extracting information from timestamps and insufficiently utilizing the implied information in relations. To address these problems, we propose a novel TKGC model, namely Pre-trained Language Model with Prompts for TKGC (PPT). We convert a series of sampled quadruples into pre-trained language model inputs and convert intervals between timestamps into different prompts to make coherent sentences with implicit semantic information. We train our model with a masking strategy to convert TKGC task into a masked token prediction task, which can leverage the semantic information in pre-trained language models. Experiments on three benchmark datasets and extensive analysis demonstrate that 
    
[^332]: 模型所有权争议中的虚假指控

    False Claims against Model Ownership Resolution. (arXiv:2304.06607v1 [cs.CR])

    [http://arxiv.org/abs/2304.06607](http://arxiv.org/abs/2304.06607)

    该论文研究了模型所有权解决方案中对抗恶意原告的鲁棒性问题，展示了常见的MOR方案可以被恶意原告针对未被盗用的独立模型提出虚假指控。

    

    深度神经网络模型是模型所有者的有价值知识产权，构成了竞争优势。因此，开发保护模型不被盗用的技术至关重要。模型所有权解决方案（MOR）是一类可以防止模型被盗的技术。MOR方案使得原告方可以通过提供证据（如水印或指纹）来断言对涉嫌盗用模型的被告方声称所有权，证明涉嫌模型是被盗或者源自于原告方拥有的源模型。现有的大多数 MOR 方案重点放在防范恶意涉嫌方方面，确保如果涉嫌模型确实是被盗版，则原告方将获胜。但是在本文中，我们揭示了现有文献中的常见 MOR 方案存在着另一个同等重要但尚未被充分探讨的鲁棒性问题：恶意原告。我们展示了如何成功地针对未被盗用的独立模型提出虚假指控。

    Deep neural network (DNN) models are valuable intellectual property of model owners, constituting a competitive advantage. Therefore, it is crucial to develop techniques to protect against model theft. Model ownership resolution (MOR) is a class of techniques that can deter model theft. A MOR scheme enables an accuser to assert an ownership claim for a suspect model by presenting evidence, such as a watermark or fingerprint, to show that the suspect model was stolen or derived from a source model owned by the accuser. Most of the existing MOR schemes prioritize robustness against malicious suspects, ensuring that the accuser will win if the suspect model is indeed a stolen model.  In this paper, we show that common MOR schemes in the literature are vulnerable to a different, equally important but insufficiently explored, robustness concern: a malicious accuser. We show how malicious accusers can successfully make false claims against independent suspect models that were not stolen. Our
    
[^333]: RGB-热红外语义分割的互补随机蒙版策略

    Complementary Random Masking for RGB-Thermal Semantic Segmentation. (arXiv:2303.17386v1 [cs.CV])

    [http://arxiv.org/abs/2303.17386](http://arxiv.org/abs/2303.17386)

    本文提出了一种RGB-T图像互补随机蒙版策略和自蒸馏损失，通过防止对单一模式过度依赖，强制网络在一个模态部分可用时进行分割和分类，从而提高了神经网络的准确性和鲁棒性，同时鼓励网络提取互补且有意义的表示。

    

    在恶劣的气象和照明条件下，RGB-热红外语义分割是实现可靠的场景理解的潜在解决方案。然而，先前的研究大多集中在设计多模态融合模块，而忽略了多模态输入的本质。因此，网络容易过度依赖单一模态，难以为每个模态学习互补且有意义的表示。本文提出了一种RGB-T图像互补随机蒙版策略和自蒸馏损失。所提出的蒙版策略防止对单一模式的过度依赖，强制网络在一个模态部分可用时进行对象分割和分类，从而提高了神经网络的准确性和鲁棒性。同时，所提出的自蒸馏损失鼓励网络从单一模态中提取互补且有意义的表示。

    RGB-thermal semantic segmentation is one potential solution to achieve reliable semantic scene understanding in adverse weather and lighting conditions. However, the previous studies mostly focus on designing a multi-modal fusion module without consideration of the nature of multi-modality inputs. Therefore, the networks easily become over-reliant on a single modality, making it difficult to learn complementary and meaningful representations for each modality. This paper proposes 1) a complementary random masking strategy of RGB-T images and 2) self-distillation loss between clean and masked input modalities. The proposed masking strategy prevents over-reliance on a single modality. It also improves the accuracy and robustness of the neural network by forcing the network to segment and classify objects even when one modality is partially available. Also, the proposed self-distillation loss encourages the network to extract complementary and meaningful representations from a single moda
    
[^334]: 双价值网络在逆向合成规划中的应用

    Retrosynthetic Planning with Dual Value Networks. (arXiv:2301.13755v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.13755](http://arxiv.org/abs/2301.13755)

    PDVN是一种新的在线训练算法，它在逆向合成规划中利用双价值网络优化完整的路线，成功率和效率上均优于现有方法。

    

    逆向合成旨在从商业上可得的起始材料中找到合成目标分子的路线，是药物发现和材料设计中的关键任务。最近，基于机器学习的单步反应预测器与多步规划器的组合已经取得了令人鼓舞的结果。然而，单步预测器大多数情况下是离线训练的，只优化单步的准确性，而不考虑完整的路线。本文提出了一种新的在线训练算法PDVN，通过使用树形MDP来优化完整的路线，利用强化学习（RL）改善单步预测器。在PDVN中，我们构建了两个单独的价值网络，分别预测分子的可合成性和成本。为了保持单步预测器的准确性，我们设计了一个双分支网络结构。

    Retrosynthesis, which aims to find a route to synthesize a target molecule from commercially available starting materials, is a critical task in drug discovery and materials design. Recently, the combination of ML-based single-step reaction predictors with multi-step planners has led to promising results. However, the single-step predictors are mostly trained offline to optimize the single-step accuracy, without considering complete routes. Here, we leverage reinforcement learning (RL) to improve the single-step predictor, by using a tree-shaped MDP to optimize complete routes. Specifically, we propose a novel online training algorithm, called Planning with Dual Value Networks (PDVN), which alternates between the planning phase and updating phase. In PDVN, we construct two separate value networks to predict the synthesizability and cost of molecules, respectively. To maintain the single-step accuracy, we design a two-branch network structure for the single-step predictor. On the widely
    
[^335]: PIP：位置编码图像先验

    PIP: Positional-encoding Image Prior. (arXiv:2211.14298v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.14298](http://arxiv.org/abs/2211.14298)

    本文提出的PIP（位置编码图像先验）与DIP表现相似，但所需参数更少，并且可以轻松扩展到视频领域，解决了3D-DIP的问题。

    

    在深度图像先验（DIP）中，卷积神经网络（CNN）被适配为将潜空间映射到降质（例如噪音）图像，但在此过程中学习重建干净图像。这种现象归因于CNN的内部图像先验。我们从神经隐式表示的角度重新审视了DIP框架。受到这种观点的启发，我们用傅里叶特征（位置编码）替换了随机或学习得到的潜码。我们展示了由于傅里叶特征的属性，我们可以用简单的像素级MLP替换卷积层。我们将此方案命名为“位置编码图像先验”（PIP），并展示它在各种图像重建任务中与DIP表现非常相似，但所需的参数要少得多。此外，我们展示PIP可以轻松扩展到视频，其中3D-DIP表现不佳且不稳定。所有任务的代码和其他例子（包括视频）均可在项目页面http://people.csail.mit.edu/yilun/pip/上获得。

    In Deep Image Prior (DIP), a Convolutional Neural Network (CNN) is fitted to map a latent space to a degraded (e.g. noisy) image but in the process learns to reconstruct the clean image. This phenomenon is attributed to CNN's internal image-prior. We revisit the DIP framework, examining it from the perspective of a neural implicit representation. Motivated by this perspective, we replace the random or learned latent with Fourier-Features (Positional Encoding). We show that thanks to the Fourier features properties, we can replace the convolution layers with simple pixel-level MLPs. We name this scheme ``Positional Encoding Image Prior" (PIP) and exhibit that it performs very similarly to DIP on various image-reconstruction tasks with much less parameters required. Additionally, we demonstrate that PIP can be easily extended to videos, where 3D-DIP struggles and suffers from instability. Code and additional examples for all tasks, including videos, are available on the project page http
    
[^336]: FedTracker：为联邦学习模型提供所有权验证和可追溯性的保护机制

    FedTracker: Furnishing Ownership Verification and Traceability for Federated Learning Model. (arXiv:2211.07160v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2211.07160](http://arxiv.org/abs/2211.07160)

    FedTracker是第一个为联邦学习模型提供所有权验证和追溯性的保护框架，采用双层保护方案，并利用持续学习原则提高保护性能。

    

    联邦学习（FL）是一种分布式机器学习范式，允许多个客户端协同训练一个全局模型，而无需共享他们的本地数据。然而，FL需要将模型暴露给各种参与者，这可能导致恶意客户端未经授权地分发或转售模型，从而损害FL团队的知识产权。为了阻止这种不当行为，建立一种验证模型所有权并追溯泄露者的机制至关重要。本文提出了FedTracker，这是第一个提供所有权验证和可追溯性的FL模型保护框架。FedTracker采用双层保护方案，包括全局水印机制和本地指纹机制。前者用于验证全局模型的所有权，而后者用于识别该模型来自哪个客户端。FedTracker利用持续学习（CL）原则来提高模型的保护性能。

    Federated learning (FL) is a distributed machine learning paradigm allowing multiple clients to collaboratively train a global model without sharing their local data. However, FL entails exposing the model to various participants. This poses a risk of unauthorized model distribution or resale by the malicious client, compromising the intellectual property rights of the FL group. To deter such misbehavior, it is essential to establish a mechanism for verifying the ownership of the model and as well tracing its origin to the leaker among the FL participants. In this paper, we present FedTracker, the first FL model protection framework that provides both ownership verification and traceability. FedTracker adopts a bi-level protection scheme consisting of global watermark mechanism and local fingerprint mechanism. The former authenticates the ownership of the global model, while the latter identifies which client the model is derived from. FedTracker leverages Continual Learning (CL) princ
    
[^337]: 使用学习到的MDP同态映射的简单状态-动作抽象方法

    A Simple Approach for State-Action Abstraction using a Learned MDP Homomorphism. (arXiv:2209.06356v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.06356](http://arxiv.org/abs/2209.06356)

    本论文提出了一种在离散动作空间中构建同态映射的新方法，通过使用环境动力学的部分模型来推断相同状态的状态动作对，从而减小状态-动作空间的大小。

    

    动物能够在有限的经验中迅速推断出等价奖励和转移动力学的状态动作对集合。与此相反，现代强化学习系统必须通过反复试错来学习状态动作对集合的值等价性，这通常需要大量样本。已经提出了MDP同态映射的方法，将环境的观察MDP简化为抽象MDP，可以实现更高效的策略学习。因此，当可以事先构建适当的MDP同态映射时，可以取得令人印象深刻的样本效率改进，通常通过利用环境的对称性来实现。我们提出了一种新颖的方法来构建离散动作空间中的同态映射，该方法使用环境动力学的部分模型来推断哪些状态动作对导致相同的状态，从而减小状态-动作空间的大小。

    Animals are able to rapidly infer from limited experience when sets of state action pairs have equivalent reward and transition dynamics. On the other hand, modern reinforcement learning systems must painstakingly learn through trial and error that sets of state action pairs are value equivalent -- requiring an often prohibitively large amount of samples from their environment. MDP homomorphisms have been proposed that reduce the observed MDP of an environment to an abstract MDP, which can enable more sample efficient policy learning. Consequently, impressive improvements in sample efficiency have been achieved when a suitable MDP homomorphism can be constructed a priori -- usually by exploiting a practioner's knowledge of environment symmetries. We propose a novel approach to constructing a homomorphism in discrete action spaces, which uses a partial model of environment dynamics to infer which state action pairs lead to the same state -- reducing the size of the state-action space by
    

