# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Credal Learning Theory](https://rss.arxiv.org/abs/2402.00957) | 本文提出了一种信任学习理论，通过使用凸集的概率来建模数据生成分布的变异性，从有限样本的训练集中推断出信任集，并推导出bounds。 |
| [^2] | [Mitigating Reversal Curse via Semantic-aware Permutation Training](https://arxiv.org/abs/2403.00758) | 逆转诅咒问题是导致因果语言模型无法进行双向推理的根本原因之一，在这篇论文中，我们提出了通过语义感知的置换训练来缓解这一问题。 |
| [^3] | [Dialect prejudice predicts AI decisions about people's character, employability, and criminality](https://arxiv.org/abs/2403.00742) | 语言模型对非裔美国英语说话者持有负面的潜在刻板印象，展现了方言偏见。 |
| [^4] | [Defining Expertise: Applications to Treatment Effect Estimation](https://arxiv.org/abs/2403.00694) | 专家决策者的行动自然地编码了其领域知识的一部分，可以帮助在同一领域内进行推断，从而在治疗效果估计中利用专业知识作为归纳偏差可能是有益的。 |
| [^5] | [Toward Autonomous Cooperation in Heterogeneous Nanosatellite Constellations Using Dynamic Graph Neural Networks](https://arxiv.org/abs/2403.00692) | 使用动态图神经网络模型和启发式算法，以解决地球观测任务中异构纳米卫星星座自主合作中的全球卫星通信安排问题 |
| [^6] | [Tri-Modal Motion Retrieval by Learning a Joint Embedding Space](https://arxiv.org/abs/2403.00691) | 通过引入人为中心的视频作为额外模态，该文章提出了一个新颖的三模态学习框架LAVIMO，有效地减少了文本和运动之间的差距，同时利用特别设计的注意机制促进了增强的对齐。 |
| [^7] | [Playing NetHack with LLMs: Potential & Limitations as Zero-Shot Agents](https://arxiv.org/abs/2403.00690) | NetHack是一个具有挑战性的游戏环境，该论文提出了NetPlay作为第一个应用于NetHack的LLM零-shot代理，克服了简单环境和复杂互动的限制，为动态机器人环境的高级规划者带来潜力和启示。 |
| [^8] | [Know your exceptions: Towards an Ontology of Exceptions in Knowledge Representation](https://arxiv.org/abs/2403.00685) | 提出了基于异常性和可辩识性的框架，用于比较形式化体系并揭示其本体论承诺，应用框架比较了四个系统，展示了从本体论角度可能发生的差异。 |
| [^9] | [Rethinking The Uniformity Metric in Self-Supervised Learning](https://arxiv.org/abs/2403.00642) | 通过识别并满足现有均匀性度量未能达标的五个基本性质，本文引入了一个对维度崩溃敏感的新均匀性度量。 |
| [^10] | [Improving Explicit Spatial Relationships in Text-to-Image Generation through an Automatically Derived Dataset](https://arxiv.org/abs/2403.00587) | 该论文提出了一种自动生成包含明确空间关系的合成标题的方法，介绍了用于训练和评估的SR4G数据集，以及展示了通过微调稳定扩散模型可以获得高达9分的改进。 |
| [^11] | [Rethinking cluster-conditioned diffusion models](https://arxiv.org/abs/2403.00570) | 通过结合最新的图片聚类和扩散模型技术，本文提出了一种在考虑最佳聚类粒度的情况下实现最先进FID并具有较强训练样本效率的聚类条件扩散模型，并提出了一种新颖方法来减少视觉组搜索空间。 |
| [^12] | [Flatten Long-Range Loss Landscapes for Cross-Domain Few-Shot Learning](https://arxiv.org/abs/2403.00567) | 将分析损失景观从参数空间扩展到表示空间，观察到尖锐极小值导致难以转移和微调的表示，引入一种简单而有效的方法以增强可转移性和促进微调。 |
| [^13] | [Predicting UAV Type: An Exploration of Sampling and Data Augmentation for Time Series Classification](https://arxiv.org/abs/2403.00565) | 本文提出了一个用于分类无人机类型的机器学习模型，通过长短期记忆神经网络进行时间序列分类，并优化了时间戳采样和类别不平衡修复方法。 |
| [^14] | [EfficientZero V2: Mastering Discrete and Continuous Control with Limited Data](https://arxiv.org/abs/2403.00564) | EfficientZero V2在有限数据情况下通过一系列改进，在多个任务中超越了当前最先进水平，并且相比于通用算法DreamerV3有显著提升 |
| [^15] | [Multi-Task Learning Using Uncertainty to Weigh Losses for Heterogeneous Face Attribute Estimation](https://arxiv.org/abs/2403.00561) | 提出了一种使用不确定性加权损失进行多任务学习的通用框架，通过硬参数共享解决了异构属性之间的相关性问题，取得了对多个人脸属性的最佳估计效果，并降低了训练成本。 |
| [^16] | [Imitation Learning Datasets: A Toolkit For Creating Datasets, Training Agents and Benchmarking](https://arxiv.org/abs/2403.00550) | 本研究提出了模仿学习数据集，通过专家政策的组织、现成数据集和技术的提供以及常见模仿学习技术实现的分享，解决了模仿学习中缺乏可用数据和评估一致性的问题。 |
| [^17] | [ROME: Memorization Insights from Text, Probability and Hidden State in Large Language Models](https://arxiv.org/abs/2403.00510) | ROME提出了一种新方法，通过比较记忆和非记忆样本之间的差异，探索大型语言模型中的记忆化，这有助于在不访问训练数据的情况下了解模型记忆的洞察和影响因素。 |
| [^18] | [Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese](https://arxiv.org/abs/2403.00509) | 基于上下文构建表示（CCR）的历史心理文本分析流程结合了心理测量学和自然语言处理技术，用于从古典中文语料库中提取心理构建，采用间接监督对比学习方法。 |
| [^19] | [Learning and Leveraging World Models in Visual Representation Learning](https://arxiv.org/abs/2403.00504) | 通过联合嵌入预测架构（JEPA）以及引入图像世界模型（IWM），本研究探讨了如何将JEPA预测任务概括为更广泛的数据损坏形式，并研究了学习性能良好的IWM的关键方面。此外，通过微调可以将IWM学到的预测世界模型用于解决各种任务，最终控制所学习表示的抽象级别。 |
| [^20] | [Parallel Hyperparameter Optimization Of Spiking Neural Network](https://arxiv.org/abs/2403.00450) | 该研究通过引入静默网络的概念，并设计特定约束，实现了更大更灵活的脉冲神经网络超参数的优化搜索空间，并应用了并行化的受约束贝叶斯优化技术。 |
| [^21] | [Authors' Values and Attitudes Towards AI-bridged Scalable Personalization of Creative Language Arts](https://arxiv.org/abs/2403.00439) | 作者们通过对人工智能桥接的创意语言艺术进行了价值观和态度的研究，发现了AI如何影响作者、作品和观众之间的利益关系，以及作者的担忧。 |
| [^22] | [LoMOE: Localized Multi-Object Editing via Multi-Diffusion](https://arxiv.org/abs/2403.00437) | 通过多扩散过程实现零样本局部多对象编辑，赋予用户在图像中一次性添加、替换或编辑多对象的能力。 |
| [^23] | [Abductive Ego-View Accident Video Understanding for Safe Driving Perception](https://arxiv.org/abs/2403.00436) | 提出了MM-AU数据集，用于多模态事故视频理解，支持各种事故理解任务，特别是多模态视频扩散以理解安全驾驶的事故因果链。 |
| [^24] | [HALC: Object Hallucination Reduction via Adaptive Focal-Contrast Decoding](https://arxiv.org/abs/2403.00425) | HALC是一种旨在减少大型视觉-语言模型中对象幻觉的新颖解码算法，通过局部的自动聚焦基准机制和全局的波束搜索算法，成功减少OH而保持文本生成质量，同时可以作为即插即用模块集成到任何LVLMs中。 |
| [^25] | [Robust Deep Reinforcement Learning Through Adversarial Attacks and Training : A Survey](https://arxiv.org/abs/2403.00420) | 通过对抗性训练来改进DRL对条件变化的鲁棒性，研究者系统分析了当代对抗攻击方法，提供了详细见解。 |
| [^26] | [GLFNET: Global-Local (frequency) Filter Networks for efficient medical image segmentation](https://arxiv.org/abs/2403.00396) | GLFNET提出了全局-局部滤波器网络（GLFNet）用于医学图像分割，采用全局-局部滤波块的组合替换自注意力机制，实现了高效的特征提取，提高了模型的性能。 |
| [^27] | [Invariant Test-Time Adaptation for Vision-Language Model Generalization](https://arxiv.org/abs/2403.00376) | 本文提出了一个测试时提示调优范式，通过优化可学习的提示，迫使模型利用真正的因果不变特征，以解决视觉-语言模型在特定任务需求上无法有效利用预训练特征的挑战。 |
| [^28] | [MS-Net: A Multi-Path Sparse Model for Motion Prediction in Multi-Scenes](https://arxiv.org/abs/2403.00353) | MS-Net是一个多路径稀疏模型，通过进化过程进行训练，针对不同场景选择性激活其参数子集进行预测。这种方法解决了多场景下运动预测问题的挑战。 |
| [^29] | [Never-Ending Embodied Robot Learning](https://arxiv.org/abs/2403.00336) | 提出了一种具身机器人学习代理NBCagent，通过技能特定的演化规划器和技能共享的语义渲染模块，实现从视觉观测中连续学习新的机器人操作技能知识。 |
| [^30] | [Learning with Logical Constraints but without Shortcut Satisfaction](https://arxiv.org/abs/2403.00329) | 引入了逻辑连接词的双重变量来解决捷径满足问题，提出了一个新的学习逻辑约束的框架，实验证明其在模型的普适性和约束满足方面性能优越。 |
| [^31] | [Softened Symbol Grounding for Neuro-symbolic Systems](https://arxiv.org/abs/2403.00323) | 提出了一种软化符号接地过程，有效地桥接了神经网络训练和符号约束求解，形成了一个高效的神经符号学习框架 |
| [^32] | [Deep Reinforcement Learning for Solving Management Problems: Towards A Large Management Mode](https://arxiv.org/abs/2403.00318) | 该论文介绍了一种基于深度强化学习的方法，旨在解决管理问题，如库存管理、动态定价和推荐，提出了一种基于变压器神经网络结构的大型管理模型，能够超越传统启发式方法解决管理任务，实现跨领域决策协调，证明了在复杂动态商业环境中DRL框架的有效性。 |
| [^33] | [Axe the X in XAI: A Plea for Understandable AI](https://arxiv.org/abs/2403.00315) | 论文辩护了采用“可理解的人工智能”标签作为替代“XAI”，以避免围绕XAI目标和目的的混乱，并主张采用更适合的实用理解概念。 |
| [^34] | [Embedded Multi-label Feature Selection via Orthogonal Regression](https://arxiv.org/abs/2403.00307) | 提出了一种新颖的嵌入式多标签特征选择方法，GRROOR，利用正交回归和特征加权以保留足够的统计和结构信息，进一步提高多标签数据的分类性能。 |
| [^35] | [Universal Auto-encoder Framework for MIMO CSI Feedback](https://arxiv.org/abs/2403.00299) | 该论文提出了一个通用的自编码器框架，可以支持不同输入大小和多种压缩比，相比于朴素和最先进方法，在降低硬件复杂度的同时提供了可比的性能表现。 |
| [^36] | [Semantic Text Transmission via Prediction with Small Language Models: Cost-Similarity Trade-off](https://arxiv.org/abs/2403.00290) | 该研究通过使用小型语言模型进行预测，实现了在语义文本传输中的成本和相似度之间的权衡。 |
| [^37] | [A Survey of Route Recommendations: Methods, Applications, and Opportunities](https://arxiv.org/abs/2403.00284) | 基于城市计算的路线推荐综述对路线推荐研究中的传统机器学习和现代深度学习方法进行了分类，展示了与城市计算场景相关的新应用，并揭示了最新进展。 |
| [^38] | [Cloud-based Federated Learning Framework for MRI Segmentation](https://arxiv.org/abs/2403.00254) | 提出了一个针对农村医疗环境的脑组织分割的新型框架，结合了深度强化学习环境和本地的精调模型，采用联邦学习进行模型训练，以维护数据隐私并增强模型泛化能力。 |
| [^39] | [EUROPA: A Legal Multilingual Keyphrase Generation Dataset](https://arxiv.org/abs/2403.00252) | 提出了一个用于法律领域多语关键词生成的数据集EUROPA，包含所有24种欧盟官方语言，表明在特定领域多语言语料库上仍有改进空间。 |
| [^40] | [Rethinking Classifier Re-Training in Long-Tailed Recognition: A Simple Logits Retargeting Approach](https://arxiv.org/abs/2403.00250) | 在长尾识别中，重新评估了基于统一特征表示的分类器重训练方法，提出了Logits Magnitude作为更佳的性能度量标准。 |
| [^41] | [Benchmarking zero-shot stance detection with FlanT5-XXL: Insights from training data, prompting, and decoding strategies into its near-SoTA performance](https://arxiv.org/abs/2403.00236) | 通过使用FlanT5-XXL和SemEval 2016数据集，研究了零-shot立场检测在推特上的性能表现及其对提示和解码策略的敏感性，揭示了其能够匹敌或超越最先进基准测试的能力，并识别了其中的潜在偏见。 |
| [^42] | [AXOLOTL: Fairness through Assisted Self-Debiasing of Large Language Model Outputs](https://arxiv.org/abs/2403.00198) | AXOLOTL是一个新颖的后处理框架，通过零样本学习的三步过程，识别和解决偏见，指导模型自我去偏见其输出，从而实现公平性并保持模型性能。 |
| [^43] | [Learning to Find Missing Video Frames with Synthetic Data Augmentation: A General Framework and Application in Generating Thermal Images Using RGB Cameras](https://arxiv.org/abs/2403.00196) | 通过引入生成模型的方法解决了由于传感器帧率不匹配而导致数据缺失的问题，利用有条件的生成对抗网络（cGANs）中的pix2pix架构比CycleGAN表现更好，多视角输入风格特别是堆叠视图可以增强热图像生成的准确性 |
| [^44] | [Identification of important nodes in the information propagation network based on the artificial intelligence method](https://arxiv.org/abs/2403.00190) | 该研究提出了一种综合方法，利用先进的人工智能方法来识别信息传播网络中的关键节点，揭示了对网络行为全面的理解，对战略网络分析和优化有重要贡献。 |
| [^45] | [Causal Graph ODE: Continuous Treatment Effect Modeling in Multi-agent Dynamical Systems](https://arxiv.org/abs/2403.00178) | 提出了Causal Graph Ordinary Differential Equations (CAG-ODE) 模型，能够捕捉多智能体系统中处理的连续动态影响，利用图神经网络作为ODE函数。 |
| [^46] | [SoD$^2$: Statically Optimizing Dynamic Deep Neural Network](https://arxiv.org/abs/2403.00176) | 本文提出了SoD$^2$框架，用于静态优化动态深度神经网络，通过秩和维度传播（RDP）方法实现了操作符的形状静态确定，进而进行一系列优化，包括融合代码生成、执行计划和运行时内存分配计划生成。 |
| [^47] | [FusionVision: A comprehensive approach of 3D object reconstruction and segmentation from RGB-D cameras using YOLO and fast segment anything](https://arxiv.org/abs/2403.00175) | FusionVision提出了一种综合方法，将YOLO和快速分割任何物体的技术整合到RGB-D相机处理中，实现了对3D物体的鲁棒分割 |
| [^48] | [Go Beyond Black-box Policies: Rethinking the Design of Learning Agent for Interpretable and Verifiable HVAC Control](https://arxiv.org/abs/2403.00172) | 通过从现有热动力学模型和历史数据提取的决策树重新设计HVAC控制器，克服了可靠性瓶颈，并实现了更节能的策略。 |
| [^49] | [LLMs in Political Science: Heralding a New Era of Visual Analysis](https://arxiv.org/abs/2403.00154) | 本文旨在提高使用Gemini进行政治科学图像内容分析的可行性意识，并展示Gemini在对象检测方面的高准确性。 |
| [^50] | [EBBS: An Ensemble with Bi-Level Beam Search for Zero-Shot Machine Translation](https://arxiv.org/abs/2403.00144) | 提出了一种集成方法EBBS，配合新颖的双层束搜索算法，能够优于直接和通过第三语言进行的翻译，并实现知识蒸馏来提高推理效率。 |
| [^51] | [Ensemble-Based Unsupervised Discontinuous Constituency Parsing by Tree Averaging](https://arxiv.org/abs/2403.00143) | 通过树平均法构建集成解析器，稳定并提升无监督不连续成分句法分析性能，实验结果表明该方法在所有指标上均优于基准线 |
| [^52] | [EROS: Entity-Driven Controlled Policy Document Summarization](https://arxiv.org/abs/2403.00141) | 通过使用受控抽象摘要，提出了一种名为EROS的模型，用于显著改善隐私政策文件的可解释性和可读性，强调了包含关键隐私相关实体和组织理由的重要性。 |
| [^53] | [UniTS: Building a Unified Time Series Model](https://arxiv.org/abs/2403.00131) | UNITS是一种统一的时间序列模型，通过独特的统一网络骨干实现了通用任务规范，并成功支持多种任务，包括分类、预测、插补和异常检测。 |
| [^54] | [Federated Linear Contextual Bandits with Heterogeneous Clients](https://arxiv.org/abs/2403.00116) | 提出了一种适用于异构客户的联邦赌臂学习方法，通过在联邦学习设置下为客户进行聚类，实现了非平凡次线性后悔和通信成本的优化 |
| [^55] | [LoRA-as-an-Attack! Piercing LLM Safety Under The Share-and-Play Scenario](https://arxiv.org/abs/2403.00108) | LoRA作为攻击者渗透LLM安全，研究探讨了在共享与玩耍场景下可能实现的攻击机会。 |
| [^56] | [Resonance RoPE: Improving Context Length Generalization of Large Language Models](https://arxiv.org/abs/2403.00071) | Resonance RoPE是一种新颖方法，通过调整RoPE特征的插值来缩小训练短-测试长场景下的泛化差距，在不增加额外在线计算成本的情况下显著提高模型性能。 |
| [^57] | [SEED: Customize Large Language Models with Sample-Efficient Adaptation for Code Generation](https://arxiv.org/abs/2403.00046) | SEED提出了一种名为Sample-Efficient adaptation with Error-Driven learning的新颖适应方法，利用LLMs产生的错误作为学习机会，从而实现对代码生成任务的高效学习。 |
| [^58] | [Scaling up Dynamic Edge Partition Models via Stochastic Gradient MCMC](https://arxiv.org/abs/2403.00044) | 该论文通过引入Dirichlet先验规范和Dirichlet马尔可夫链构建，扩展了边缘划分模型（EPM）以适应动态环境，并提出了一个简单的Gibbs采样器来处理后验计算。 |
| [^59] | [Global and Local Prompts Cooperation via Optimal Transport for Federated Learning](https://arxiv.org/abs/2403.00041) | 提出了联邦提示合作 via Optimal Transport（FedOTP）方法，通过最优输运实现全局和本地提示的合作，针对数据异质性设计了高效的协作提示学习策略。 |
| [^60] | [FhGenie: A Custom, Confidentiality-preserving Chat AI for Corporate and Scientific Use](https://arxiv.org/abs/2403.00039) | FhGenie是一款专为确保保密性而定制的聊天人工智能，可以帮助知识工作者提高生产力，成为其他组织效仿的先驱。 |
| [^61] | [Evolving to the Future: Unseen Event Adaptive Fake News Detection on Social Media](https://arxiv.org/abs/2403.00037) | 提出了面向未知事件的适应性假新闻检测框架FADE，通过自适应增强和图对比学习训练目标预测器，同时独立训练事件预测器，最终减轻事件偏见。 |
| [^62] | [Influencing Bandits: Arm Selection for Preference Shaping](https://arxiv.org/abs/2403.00036) | 该论文考虑了在非静态多臂赌博机中，通过观察奖励来积极和消极地强化人群偏好，并提出了用于最大化支持预定手臂的人口比例的算法。对于不同意见动态，提出了不同的策略并分析了后悔，最后讨论了多个推荐系统共存的情况。 |
| [^63] | [Time to Cite: Modeling Citation Networks using the Dynamic Impact Single-Event Embedding Model](https://arxiv.org/abs/2403.00032) | 提出了一个新颖的方法，利用动态影响单事件嵌入模型对引用网络进行建模 |
| [^64] | [GraphPub: Generation of Differential Privacy Graph with High Availability](https://arxiv.org/abs/2403.00030) | 提出了一种名为GraphPub的新型图边保护框架，通过反向学习和编码器-解码器机制，在保护图拓扑结构的同时保证数据的可用性基本不变。 |
| [^65] | [Learning to Deliver: a Foundation Model for the Montreal Capacitated Vehicle Routing Problem](https://arxiv.org/abs/2403.00026) | 提出了蒙特利尔容量车辆路径问题的基础模型（FM-MCVRP），将MCVRP视为类似自然语言处理任务，并利用Transformer架构嵌入大型语言模型框架进行训练。 |
| [^66] | [On the Challenges and Opportunities in Generative AI](https://arxiv.org/abs/2403.00025) | 现代生成人工智能范例中存在关键的未解决挑战，如何解决这些挑战将进一步增强它们的能力、多功能性和可靠性，并为研究方向提供有价值的见解。 |
| [^67] | [Auditable Homomorphic-based Decentralized Collaborative AI with Attribute-based Differential Privacy](https://arxiv.org/abs/2403.00023) | 提出了一种名为AerisAI的可审计同态协作人工智能框架，利用同态加密和细粒度差分隐私提高安全性，通过基于区块链的智能合约直接聚合加密参数，消除了对于模型性能的负面影响 |
| [^68] | [Towards Interpreting Multi-Objective Feature Associations](https://arxiv.org/abs/2403.00017) | 提出一种使用多标签的客观特征交互设计，结合全局敏感性分析，以在农业环境中找到最佳组合的新方法。 |
| [^69] | [Deep Sensitivity Analysis for Objective-Oriented Combinatorial Optimization](https://arxiv.org/abs/2403.00016) | 本研究提出了一种深度敏感性分析方法，结合神经网络反馈和全局敏感性分析，以在家禽管理中最优化降低多种病原体水平。 |
| [^70] | [GIN-SD: Source Detection in Graphs with Incomplete Nodes via Positional Encoding and Attentive Fusion](https://arxiv.org/abs/2403.00014) | 本文提出了GIN-SD框架，通过位置编码和关注融合解决了在图中检测具有不完整节点的来源的挑战。 |
| [^71] | [Introducing User Feedback-based Counterfactual Explanations (UFCE)](https://arxiv.org/abs/2403.00011) | 本研究引入了一种名为基于用户反馈的反事实解释（UFCE）的新方法，旨在解决当前反事实解释算法的局限性，并增强提供的解释的可信度。 |
| [^72] | [TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning](https://arxiv.org/abs/2402.19467) | TV-TREES是第一个多模态蕴涵树生成器，通过生成视频直接蕴涵的简单前提与高级结论之间的蕴涵关系树，实现了可解释联合模态推理，并在挑战性的TVQA数据集上展示了最先进的零-shot性能。 |
| [^73] | [$\texttt{COSMIC}$: Mutual Information for Task-Agnostic Summarization Evaluation](https://arxiv.org/abs/2402.19457) | $\texttt{COSMIC}$是一种以相互信息为基础的新的摘要评估方法，有效预测下游任务表现，并与人类判断相关性强。竞争性能优于$\texttt{BERTScore}$和$\texttt{ROUGE}$。 |
| [^74] | [PEM: Prototype-based Efficient MaskFormer for Image Segmentation](https://arxiv.org/abs/2402.19422) | PEM提出了基于原型的高效MaskFormer，通过引入原型交叉注意力和多尺度特征金字塔网络，实现了在多个分割任务中的高效运行。 |
| [^75] | [Navigating Beyond Dropout: An Intriguing Solution Towards Generalizable Image Super Resolution](https://arxiv.org/abs/2402.18929) | 本文探讨了超越Dropout的图像超分辨率新解决方案，提出了一种能够改善模型泛化能力的训练策略，同时避免了Dropout引入的不良副作用。 |
| [^76] | [The Machine Can't Replace the Human Heart](https://arxiv.org/abs/2402.18826) | 人工智能和虚拟治疗技术的发展带来了更广泛的接触机会，但在实施中需要平衡效率和同理心，以确保技术始终是由医护人员的智慧指导的辅助工具。 |
| [^77] | [ICE-SEARCH: A Language Model-Driven Feature Selection Approach](https://arxiv.org/abs/2402.18609) | ICE-SEARCH是首个将语言模型与进化算法相结合用于特征选择任务的方法，在医学预测分析应用中取得了State-of-the-Art(SOTA)表现。 |
| [^78] | [Imagine, Initialize, and Explore: An Effective Exploration Method in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2402.17978) | 提出了一种名为Imagine, Initialize, and Explore (IIE)的新方法，利用变压器模型在复杂场景中实现多智能体的有效探索。 |
| [^79] | [DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLM Jailbreakers](https://arxiv.org/abs/2402.16914) | 将恶意提示分解为独立的子提示使得LLM越狱攻击更难被检测 |
| [^80] | [Likelihood-based Mitigation of Evaluation Bias in Large Language Models](https://arxiv.org/abs/2402.15987) | 该论文研究了基于大型语言模型（LLM）的评估器中的似然偏差，并提出了一种缓解这种偏差的方法。 |
| [^81] | [Spatially-Aware Transformer Memory for Embodied Agents](https://arxiv.org/abs/2402.15160) | 本文探讨了利用包含空间信息的面向空间感知变压器模型，以改善记忆利用效率。 |
| [^82] | [AI-Augmented Brainwriting: Investigating the use of LLMs in group ideation](https://arxiv.org/abs/2402.14978) | 本文探讨了在团体构思中将LLMs整合到创意过程中的两个方面，并发现将LLMs整合到Brainwriting中可以增强构思过程及其结果，并提供了支持想法评估的证据。 |
| [^83] | [What's in a Name? Auditing Large Language Models for Race and Gender Bias](https://arxiv.org/abs/2402.14875) | 调查发现，大型语言模型存在种族和性别偏见，尤其对与黑人女性相关的名字表现最不利。审计在模型部署和实施时的重要性得到强调。 |
| [^84] | [Protect and Extend -- Using GANs for Synthetic Data Generation of Time-Series Medical Records](https://arxiv.org/abs/2402.14042) | 本研究使用GANs生成了时间序列合成痴呆患者医疗记录的数据集，并比较了不同GAN模型在生成合成数据方面的质量，实现了在不涉及隐私问题的情况下保护用户数据并延伸数据应用。 |
| [^85] | [E2USD: Efficient-yet-effective Unsupervised State Detection for Multivariate Time Series](https://arxiv.org/abs/2402.14041) | E2USD提出了一种有效的无监督多元时间序列状态检测方法，利用了快速傅里叶变换和双视图嵌入模块进行编码，以及通过对抗学习方法消除假阴性，从而实现了SOTA准确性并显著降低了计算开销。 |
| [^86] | [Incentive Compatibility for AI Alignment in Sociotechnical Systems: Positions and Prospects](https://arxiv.org/abs/2402.12907) | 该论文提出了激励兼容性社会技术对齐问题（ICSAP），旨在探讨如何利用博弈论中的激励兼容性原则来维持AI与人类社会的共识。 |
| [^87] | [PIP-Net: Pedestrian Intention Prediction in the Wild](https://arxiv.org/abs/2402.12810) | PIP-Net是一个新型框架，通过综合利用动态学数据和场景空间特征，采用循环和时间注意力机制解决方案，成功预测行人通过马路的意图，性能优于现有技术。 |
| [^88] | [UFO: A UI-Focused Agent for Windows OS Interaction](https://arxiv.org/abs/2402.07939) | UFO是一个专注于Windows操作系统上应用程序的用户界面智能体，利用GPT-Vision的能力来满足用户需求。它通过观察和分析Windows应用程序的图形用户界面和控制信息，实现无缝导航和操作以满足用户的请求。UFO的控制交互模块使得无需人工干预即可实现动作连接和完全自动化执行，使繁琐和耗时的过程变为简单任务。经过测试，UFO在各种场景中取得了良好效果。 |
| [^89] | [Investigating White-Box Attacks for On-Device Models](https://arxiv.org/abs/2402.05493) | 本研究探究了针对设备上模型的白盒攻击，提出了一种逆向工程框架(REOM)以将编译后的设备上TFLite模型转换为可调试模型。 |
| [^90] | [Direct Language Model Alignment from Online AI Feedback](https://arxiv.org/abs/2402.04792) | 本论文提出了一种名为OAIF的方法，通过在线反馈来改善DAP方法，该方法使用LLM作为标注器，从而在多个任务中展示出优于离线DAP和RLHF的性能 |
| [^91] | [Large Language Models As MOOCs Graders](https://arxiv.org/abs/2402.03776) | 该研究探索了利用大型语言模型（LLMs）代替MOOCs中同伴评分的可行性，旨在解决大规模在线开放课程中评估学生写作任务的问题。 |
| [^92] | [Understanding the Reasoning Ability of Language Models From the Perspective of Reasoning Paths Aggregation](https://arxiv.org/abs/2402.03268) | 本文研究了预训练语言模型的推理能力，并提出了从聚合间接推理路径的角度理解语言模型如何产生推理能力。通过对知识图谱和数学问题数据集进行实验和分析，发现增加无标签的随机游走推理路径可以提高实际应用中的多步推理能力。 |
| [^93] | [Chain-of-Feedback: Mitigating the Effects of Inconsistency in Responses](https://arxiv.org/abs/2402.02648) | 本文提出了链式反馈（CoF）方法，以缓解大型语言模型在回答问题中出现不一致性的问题。同时，作者还提出了递归链式反馈（R-CoF）方法，并提到了进一步的研究。这些方法可以提高回答的可靠性和有效性。 |
| [^94] | [Messenger RNA Design via Expected Partition Function and Continuous Optimization](https://arxiv.org/abs/2401.00037) | 将RNA设计问题转化为连续优化，并提出了基于期望分区函数的通用优化框架，将候选序列的分布逐步优化为单一序列。 |
| [^95] | [Towards an end-to-end artificial intelligence driven global weather forecasting system](https://arxiv.org/abs/2312.12462) | 提出了一种端到端基于人工智能的全球天气预报系统，通过将AI技术应用于数据同化和天气预报模型，实现了从数据处理到预测全过程的自动化。 |
| [^96] | [LatestEval: Addressing Data Contamination in Language Model Evaluation through Dynamic and Time-Sensitive Test Construction](https://arxiv.org/abs/2312.12343) | LatestEval提出了一种自动方法，通过动态和时间敏感的测试构建不受数据污染的阅读理解评估，避免了使用预先训练语言模型的训练语料库，从而鼓励模型更好地推断答案。 |
| [^97] | [Fortify the Shortest Stave in Attention: Enhancing Context Awareness of Large Language Models for Effective Tool Use](https://arxiv.org/abs/2312.04455) | 本文证明了大型语言模型中关注分配的波形模式对其在需要高度上下文意识的任务中的性能有显著影响。我们提出了一种名为“Attention Buckets”的推理方法，通过多个并行过程和不同的旋转位置嵌入角度，增强了模型对不同上下文位置的意识，从而减轻了忽视关键信息的风险。 |
| [^98] | [ARIA: On the Interaction Between Architectures, Initialization and Aggregation Methods for Federated Visual Classification](https://arxiv.org/abs/2311.14625) | ARIA元素必须共同选择才能实现最佳性能，揭示了不同任务下每个元素的良好选择和标准化效果的影响。 |
| [^99] | [Imitation Bootstrapped Reinforcement Learning](https://arxiv.org/abs/2311.02198) | 提出了一种模仿引导式强化学习（IBRL）的框架，用于高效的样本-efficient RL，通过先在提供的示范上训练IL策略，然后使用它提出替代动作进行在线探索和引导目标值。 |
| [^100] | [Search to Fine-tune Pre-trained Graph Neural Networks for Graph-level Tasks](https://arxiv.org/abs/2308.06960) | 设计更好的微调策略以在下游任务中更好地利用转移的知识并提高性能。 |
| [^101] | [Multimodality Representation Learning: A Survey on Evolution, Pretraining and Its Applications](https://arxiv.org/abs/2302.00389) | 多模态表示学习涉及学习将不同模态信息嵌入并处理跨模态任务，在不同应用上取得显著成功，研究人员提出多种方法来实现这一目标。 |
| [^102] | [Structural Estimation of Markov Decision Processes in High-Dimensional State Space with Finite-Time Guarantees](https://arxiv.org/abs/2210.01282) | 本论文提出了一种单循环估计算法，具有有限时间保证，能够处理高维状态空间的马尔可夫决策过程的结构估计问题，而不会损害奖励估计精度。 |
| [^103] | [META-GUI: Towards Multi-modal Conversational Agents on Mobile GUI](https://arxiv.org/abs/2205.11029) | 提出了一种基于GUI的任务导向对话系统（GUI-TOD）架构，并发布了用于在移动GUI上训练多模态对话代理的数据集META-GUI。 |
| [^104] | [Towards Interpretable Deep Reinforcement Learning Models via Inverse Reinforcement Learning](https://arxiv.org/abs/2203.16464) | 本研究提出了一个新颖的框架，利用对抗逆强化学习，可以为强化学习模型所作出的决策提供全局解释，并捕捉直观的倾向。 |
| [^105] | [Memory-Efficient Sequential Pattern Mining with Hybrid Tries](https://arxiv.org/abs/2202.06834) | 提出了一种基于混合trie的内存高效序列模式挖掘方法，在内存消耗和计算时间方面相比现有技术有显著改善，且是唯一一个能够处理256GB系统内存下大数据集的方法。 |
| [^106] | [InceptionXML: A Lightweight Framework with Synchronized Negative Sampling for Short Text Extreme Classification](https://arxiv.org/abs/2109.07319) | 提出了一种轻量级框架InceptionXML，通过在embedding维度上重新分配卷积操作，应对短文本查询中的单词顺序缺失，同时提出了InceptionXML+框架，通过同步标签筛选器和极端分类器，改进了动态硬负采样技术。 |
| [^107] | [Deep learning insights into cosmological structure formation](https://arxiv.org/abs/2011.10577) | 通过构建深度学习框架，研究了各向异性信息在初始条件中如何影响暗物质暗团的最终质量，并发现各向异性添加了一些额外信息量。 |
| [^108] | [Finetuning Large Language Models for Vulnerability Detection.](http://arxiv.org/abs/2401.17010) | 本文优化了大规模语言模型用于源代码中的漏洞检测任务，通过微调最先进的代码语言模型WizardCoder并改进其训练过程和策略，实现了对漏洞数据集的分类性能的提升。 |
| [^109] | [The Definitive Guide to Policy Gradients in Deep Reinforcement Learning: Theory, Algorithms and Implementations.](http://arxiv.org/abs/2401.13662) | 本文提供了一个深度强化学习中策略梯度算法的综合指南，包括理论基础、实际实现和比较结果，并对正则化的益处进行了讨论。 |
| [^110] | [Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior.](http://arxiv.org/abs/2401.10910) | 本文介绍了一个使用内省的元认知模块，可以让生成式智能体观察自己的思考过程和行动，并通过修改策略来显著提高性能。通过在多种场景下测试，我们观察到该系统在与其他系统的比较中取得了优势，智能体能够适应和改进策略以完成任务。 |
| [^111] | [GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse.](http://arxiv.org/abs/2401.01523) | 通过基于迷因的社交虐待研究对大型多模态模型的安全洞察，我们引入了综合的迷因基准测试集GOAT-Bench，评估各种LMMs在识别和回应迷因中体现的微妙社交虐待方面的能力。 |
| [^112] | [SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation.](http://arxiv.org/abs/2310.12508) | 这篇论文提出了一种名为SalUn的机器遗忘方法，通过引入"权重显著性"的概念，将关注点从整个模型引导到具体的模型权重上，提高了遗忘的效果和效率。这是第一个能够有效消除遗忘数据、类别或概念影响的有原则的机器遗忘方法。 |
| [^113] | [Fast Graph Condensation with Structure-based Neural Tangent Kernel.](http://arxiv.org/abs/2310.11046) | 本文提出了一种以数据为中心的解决方案，将大型图数据集压缩为较小的集合而不会损失GNN的预测性能。通过将图结构压缩问题转化为核岭回归任务，利用基于结构的神经切线内核来捕捉图的拓扑结构。 |
| [^114] | [Concise and Organized Perception Facilitates Large Language Models for Deductive Reasoning.](http://arxiv.org/abs/2310.03309) | 利用大型语言模型进行演绎推理是一个具有挑战性的问题。这篇论文提出了一个简明有序的方法，将任务分解为子任务并且人类化地组织思维，以提高演绎推理的效果。 |
| [^115] | [Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation.](http://arxiv.org/abs/2310.02304) | 本文提出了一种自学优化器（STOP），通过递归自我改进的代码生成，使用融合了语言模型的脚手架程序来改进自身，从而生成性能更好的程序。 |
| [^116] | [Pushing Large Language Models to the 6G Edge: Vision, Challenges, and Opportunities.](http://arxiv.org/abs/2309.16739) | 本文探讨了将大型语言模型(LLMs)部署在6G边缘的潜力和挑战。我们介绍了由LLMs支持的关键应用，并从响应时间、带宽成本和数据隐私等方面分析了云端部署面临的问题。我们提出了6G移动边缘计算(MEC)系统可能解决这些问题的方案，并讨论了边缘训练和边缘推理的创新技术。 |
| [^117] | [Anonymizing Speech: Evaluating and Designing Speaker Anonymization Techniques.](http://arxiv.org/abs/2308.04455) | 本研究提出了匿名化语音的解决方案，并评估了匿名化的程度，以应对语音数据收集中的隐私问题和恶意使用的风险。 |
| [^118] | [$\lambda$-AC: Learning latent decision-aware models for reinforcement learning in continuous state-spaces.](http://arxiv.org/abs/2306.17366) | 这项研究提出了一种$\lambda$-AC算法，通过学习连续状态空间中的潜在决策感知模型，实现了决策驱动的强化学习。通过理论和实证研究，确定了决策感知强化学习模型的必要组成部分，并展示了设计选择对算法性能的重要影响。 |
| [^119] | [Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects.](http://arxiv.org/abs/2306.10125) | 自监督学习（SSL）在时间序列分析中的应用取得了显著性能，通过减少对标注数据的依赖，即使只有少量标注数据，也能实现高性能。 |
| [^120] | [Survey on Sociodemographic Bias in Natural Language Processing.](http://arxiv.org/abs/2306.08158) | 本文调查了209篇关于NLP模型偏见的论文，其中大部分涉及社会人口统计偏见。研究者提出了社会人口统计偏见的定义，并确定了NLP偏见研究的三个主要类别。当前去偏见技术只是隐藏了偏见而不是真正去除它，需要进一步改进。 |
| [^121] | [Federated Domain Generalization: A Survey.](http://arxiv.org/abs/2306.01334) | 该论文调查了联邦领域泛化的研究领域，提到了联邦学习和领域泛化技术的优势，以及在泛化联邦模型时面临的挑战。 |
| [^122] | [Critical Appraisal of Artificial Intelligence-Mediated Communication.](http://arxiv.org/abs/2305.11897) | 本文探讨了人工智能在语言教育中介交流的优缺点，并强调语言教师积极参与CALL教师教育和专业发展的重要性。 |
| [^123] | [Local Search for Integer Linear Programming.](http://arxiv.org/abs/2305.00188) | 本论文开发了一个独立的局部搜索求解器，可用于解决一般整数线性规划，并在大型异构问题数据集上进行了验证。在搜索、改进和还原模式下，分别提出了可自适应修改变量值的算子和高效的举升算子，从而提高当前解的质量。实验表明，该方法在MIPLIB2017的异构问题集上表现优异。 |
| [^124] | [GPT-4 Technical Report.](http://arxiv.org/abs/2303.08774) | GPT-4是一个大规模多模态模型，可以接收图像和文本输入并产生文本输出，能够在各种专业和学术基准测试中表现出人类水平的表现，包括通过模拟的律师考试。该项目的核心组件是开发基础设施和优化方法，可在广泛的规模范围内表现预测性。 |
| [^125] | [Regularised neural networks mimic human insight.](http://arxiv.org/abs/2302.11351) | 本文研究了正则化神经网络是否具有类似于人类洞察力的行为。研究发现，正则化神经网络在学习动态和行为特征上密切模仿了人类的洞察力，表现出洞察力的延迟、突然性和选择性发生。 |

# 详细

[^1]: 信任学习理论

    Credal Learning Theory

    [https://rss.arxiv.org/abs/2402.00957](https://rss.arxiv.org/abs/2402.00957)

    本文提出了一种信任学习理论，通过使用凸集的概率来建模数据生成分布的变异性，从有限样本的训练集中推断出信任集，并推导出bounds。

    

    统计学习理论是机器学习的基础，为从未知概率分布中学习到的模型的风险提供理论边界。然而，在实际部署中，数据分布可能会变化，导致领域适应/泛化问题。在本文中，我们建立了一个“信任”学习理论的基础，使用概率的凸集（信任集）来建模数据生成分布的变异性。我们认为，这样的信任集可以从有限样本的训练集中推断出来。对于有限假设空间（无论是否可实现）和无限模型空间，推导出界限，这直接推广了经典结果。

    Statistical learning theory is the foundation of machine learning, providing theoretical bounds for the risk of models learnt from a (single) training set, assumed to issue from an unknown probability distribution. In actual deployment, however, the data distribution may (and often does) vary, causing domain adaptation/generalization issues. In this paper we lay the foundations for a `credal' theory of learning, using convex sets of probabilities (credal sets) to model the variability in the data-generating distribution. Such credal sets, we argue, may be inferred from a finite sample of training sets. Bounds are derived for the case of finite hypotheses spaces (both assuming realizability or not) as well as infinite model spaces, which directly generalize classical results.
    
[^2]: 通过语义感知置换训练来缓解逆转诅咒

    Mitigating Reversal Curse via Semantic-aware Permutation Training

    [https://arxiv.org/abs/2403.00758](https://arxiv.org/abs/2403.00758)

    逆转诅咒问题是导致因果语言模型无法进行双向推理的根本原因之一，在这篇论文中，我们提出了通过语义感知的置换训练来缓解这一问题。

    

    大型语言模型（LLM）在各种任务中取得了令人印象深刻的表现，然而最近的研究表明，因果关系的LLM遭遇了“逆转诅咒”。一个典型的例子是，模型知道“A的父亲是B”，但无法推理出“B的孩子是A”。这一局限性对人工通用智能（AGI）的进展构成了挑战，因为它暗示了模型在理解和应用双向推理方面存在差距。本文首先进行了大量评估，并确定了逆转诅咒的根本原因在于训练和推断阶段之间的词序不同，即因果语言模型在训练数据中预测先行词的能力不足。因此，考虑到在训练数据上进行排列可以被视为潜在解决方案，因为这可以使模型预测先行词或标记。然而，先前的排列方法可能受到截断影响。

    arXiv:2403.00758v1 Announce Type: cross  Abstract: While large language models (LLMs) have achieved impressive performance across diverse tasks, recent studies showcase that causal LLMs suffer from the "reversal curse". It is a typical example that the model knows "A's father is B", but is unable to reason "B's child is A". This limitation poses a challenge to the advancement of artificial general intelligence (AGI), as it suggests a gap in the models' ability to comprehend and apply bidirectional reasoning. In this paper, we first conduct substantial evaluation and identify that the root cause of the reversal curse lies in the different word order between the training and inference stage, namely, the poor ability of causal language models to predict antecedent words within the training data. Accordingly, permutation on the training data is considered as a potential solution, since this can make the model predict antecedent words or tokens. However, previous permutation methods may dis
    
[^3]: 方言偏见预测人工智能对人物性格、就业能力和犯罪倾向的决策

    Dialect prejudice predicts AI decisions about people's character, employability, and criminality

    [https://arxiv.org/abs/2403.00742](https://arxiv.org/abs/2403.00742)

    语言模型对非裔美国英语说话者持有负面的潜在刻板印象，展现了方言偏见。

    

    数亿人现在与语言模型互动，其用途从作为写作辅助到影响招聘决策。然而，已知这些语言模型会传播系统性种族偏见，使它们对像非洲裔美国人这样的群体做出有问题的偏见判断。本文展示了语言模型体现了一种潜在的种族文化偏见，即方言偏见：我们扩展了关于美国人对非裔美国英语说话者持有种族语言刻板印象的研究，并发现语言模型也有同样的偏见，表现出潜在的刻板印象，这种刻板印象比实验中记录的任何人类关于非裔美国人的刻板印象都更为负面。

    arXiv:2403.00742v1 Announce Type: cross  Abstract: Hundreds of millions of people now interact with language models, with uses ranging from serving as a writing aid to informing hiring decisions. Yet these language models are known to perpetuate systematic racial prejudices, making their judgments biased in problematic ways about groups like African Americans. While prior research has focused on overt racism in language models, social scientists have argued that racism with a more subtle character has developed over time. It is unknown whether this covert racism manifests in language models. Here, we demonstrate that language models embody covert racism in the form of dialect prejudice: we extend research showing that Americans hold raciolinguistic stereotypes about speakers of African American English and find that language models have the same prejudice, exhibiting covert stereotypes that are more negative than any human stereotypes about African Americans ever experimentally recorde
    
[^4]: 定义专业知识：在治疗效果估计中的应用

    Defining Expertise: Applications to Treatment Effect Estimation

    [https://arxiv.org/abs/2403.00694](https://arxiv.org/abs/2403.00694)

    专家决策者的行动自然地编码了其领域知识的一部分，可以帮助在同一领域内进行推断，从而在治疗效果估计中利用专业知识作为归纳偏差可能是有益的。

    

    决策者通常是其领域的专家，并基于其领域知识采取行动。本文讨论了在治疗效果估计领域中专业知识的重要性，以及利用专业知识作为归纳偏差的潜力。

    arXiv:2403.00694v1 Announce Type: cross  Abstract: Decision-makers are often experts of their domain and take actions based on their domain knowledge. Doctors, for instance, may prescribe treatments by predicting the likely outcome of each available treatment. Actions of an expert thus naturally encode part of their domain knowledge, and can help make inferences within the same domain: Knowing doctors try to prescribe the best treatment for their patients, we can tell treatments prescribed more frequently are likely to be more effective. Yet in machine learning, the fact that most decision-makers are experts is often overlooked, and "expertise" is seldom leveraged as an inductive bias. This is especially true for the literature on treatment effect estimation, where often the only assumption made about actions is that of overlap. In this paper, we argue that expertise - particularly the type of expertise the decision-makers of a domain are likely to have - can be informative in designin
    
[^5]: 基于动态图神经网络实现异构纳米卫星星座自主合作

    Toward Autonomous Cooperation in Heterogeneous Nanosatellite Constellations Using Dynamic Graph Neural Networks

    [https://arxiv.org/abs/2403.00692](https://arxiv.org/abs/2403.00692)

    使用动态图神经网络模型和启发式算法，以解决地球观测任务中异构纳米卫星星座自主合作中的全球卫星通信安排问题

    

    arXiv:2403.00692v1 公告类型:跨领域 摘要:未来地球观测任务的格局将由要求满足严格任务需求，如重访时间和空间分辨率的网络异构纳米卫星星座所定义。然而，通过有效地创建全球卫星接触计划（CP）来安排卫星通信是一个复杂的任务，当前解决方案要求地面协调或受到机载计算资源的限制。该论文提出了一种新颖的方法，通过将星座和CP建模为动态网络，并应用基于图的技术来克服这些挑战。所提出的方法利用最先进的动态图神经网络来评估给定CP的性能，并使用基于模拟退火的启发式算法来更新它。训练好的神经网络可以以平均绝对误差3.6分钟来预测网络延迟。

    arXiv:2403.00692v1 Announce Type: cross  Abstract: The upcoming landscape of Earth Observation missions will defined by networked heterogeneous nanosatellite constellations required to meet strict mission requirements, such as revisit times and spatial resolution. However, scheduling satellite communications in these satellite networks through efficiently creating a global satellite Contact Plan (CP) is a complex task, with current solutions requiring ground-based coordination or being limited by onboard computational resources. The paper proposes a novel approach to overcome these challenges by modeling the constellations and CP as dynamic networks and employing graph-based techniques. The proposed method utilizes a state-of-the-art dynamic graph neural network to evaluate the performance of a given CP and update it using a heuristic algorithm based on simulated annealing. The trained neural network can predict the network delay with a mean absolute error of 3.6 minutes. Simulation re
    
[^6]: 通过学习联合嵌入空间实现三模态运动检索

    Tri-Modal Motion Retrieval by Learning a Joint Embedding Space

    [https://arxiv.org/abs/2403.00691](https://arxiv.org/abs/2403.00691)

    通过引入人为中心的视频作为额外模态，该文章提出了一个新颖的三模态学习框架LAVIMO，有效地减少了文本和运动之间的差距，同时利用特别设计的注意机制促进了增强的对齐。

    

    信息检索是一个不断发展且至关重要的研究领域。对高质量人体运动数据的巨大需求尤其在在线获取方面导致了人体运动研究工作的激增。以往的研究主要集中在双模态学习上，如文本和运动任务，但很少探索三模态学习。直觉上，引入额外的模态可以丰富模型的应用场景，更重要的是，对额外模态的充分选择还可以作为中介并增强其他两个不同模态之间的对齐。在这项工作中，我们提出了LAVIMO（LAnguage-VIdeo-MOtion对齐），这是一个新颖的三模态学习框架，将以人为中心的视频作为额外的模态集成，从而有效地弥合文本和运动之间的差距。此外，我们的方法利用了一个特别设计的注意机制来促进增强的对齐。

    arXiv:2403.00691v1 Announce Type: cross  Abstract: Information retrieval is an ever-evolving and crucial research domain. The substantial demand for high-quality human motion data especially in online acquirement has led to a surge in human motion research works. Prior works have mainly concentrated on dual-modality learning, such as text and motion tasks, but three-modality learning has been rarely explored. Intuitively, an extra introduced modality can enrich a model's application scenario, and more importantly, an adequate choice of the extra modality can also act as an intermediary and enhance the alignment between the other two disparate modalities. In this work, we introduce LAVIMO (LAnguage-VIdeo-MOtion alignment), a novel framework for three-modality learning integrating human-centric videos as an additional modality, thereby effectively bridging the gap between text and motion. Moreover, our approach leverages a specially designed attention mechanism to foster enhanced alignme
    
[^7]: 用大型语言模型(LLMs)玩NetHack：作为零-shot代理的潜力与限制

    Playing NetHack with LLMs: Potential & Limitations as Zero-Shot Agents

    [https://arxiv.org/abs/2403.00690](https://arxiv.org/abs/2403.00690)

    NetHack是一个具有挑战性的游戏环境，该论文提出了NetPlay作为第一个应用于NetHack的LLM零-shot代理，克服了简单环境和复杂互动的限制，为动态机器人环境的高级规划者带来潜力和启示。

    

    大型语言模型(LLMs)作为高级规划者在零-shot游戏代理中表现出很大成功。然而，这些代理主要在Minecraft上进行评估，那里的长期规划相对简单。相比之下，在动态机器人环境中测试的代理面临限制，因为环境简单，只有少量物体和互动。为填补文献中的这一空白，我们提出NetPlay，这是用于具有挑战性的roguelike游戏NetHack的第一个LLM动引擎零-shot代理。NetHack由于其多样的物品和怪物、复杂的互动以及死亡的多种方式而被认为是一个特别具有挑战性的环境。NetPlay使用为动态机器人环境而设计的体系结构，经过修改以适应NetHack。与以前的方法类似，它提示LLM从预定义的技能中进行选择，并跟踪过去的互动以增强决策能力。鉴于NetHack的不可预测性，NetPlay检测到重要的游戏事件

    arXiv:2403.00690v1 Announce Type: new  Abstract: Large Language Models (LLMs) have shown great success as high-level planners for zero-shot game-playing agents. However, these agents are primarily evaluated on Minecraft, where long-term planning is relatively straightforward. In contrast, agents tested in dynamic robot environments face limitations due to simplistic environments with only a few objects and interactions. To fill this gap in the literature, we present NetPlay, the first LLM-powered zero-shot agent for the challenging roguelike NetHack. NetHack is a particularly challenging environment due to its diverse set of items and monsters, complex interactions, and many ways to die.   NetPlay uses an architecture designed for dynamic robot environments, modified for NetHack. Like previous approaches, it prompts the LLM to choose from predefined skills and tracks past interactions to enhance decision-making. Given NetHack's unpredictable nature, NetPlay detects important game event
    
[^8]: 认识你的异常：走向知识表示中的异常本体论

    Know your exceptions: Towards an Ontology of Exceptions in Knowledge Representation

    [https://arxiv.org/abs/2403.00685](https://arxiv.org/abs/2403.00685)

    提出了基于异常性和可辩识性的框架，用于比较形式化体系并揭示其本体论承诺，应用框架比较了四个系统，展示了从本体论角度可能发生的差异。

    

    可辩驳推理是一种推理形式，其中一些概括在某些情况下可能无效，也就是通常情况下的一般性结论在某些情况下可能会失败。已经开发了各种形式化体系来模拟这种推理，这是普通常识背景下的特征。然而，对于一个模型者来说，从本体论的角度选择最适合其领域的体系并不容易。在本文中，我们首先提出了一个基于异常性和可辩识性的框架，以便比较形式化体系并揭示其本体论承诺。然后，我们应用该框架来比较四个系统，展示了从本体论角度可能发生的差异。

    arXiv:2403.00685v1 Announce Type: new  Abstract: Defeasible reasoning is a kind of reasoning where some generalisations may not be valid in all circumstances, that is general conclusions may fail in some cases. Various formalisms have been developed to model this kind of reasoning, which is characteristic of common-sense contexts. However, it is not easy for a modeller to choose among these systems the one that better fits its domain from an ontological point of view. In this paper we first propose a framework based on the notions of exceptionality and defeasibility in order to be able to compare formalisms and reveal their ontological commitments. Then, we apply this framework to compare four systems, showing the differences that may occur from an ontological perspective.
    
[^9]: 重新审视自监督学习中的均匀性度量

    Rethinking The Uniformity Metric in Self-Supervised Learning

    [https://arxiv.org/abs/2403.00642](https://arxiv.org/abs/2403.00642)

    通过识别并满足现有均匀性度量未能达标的五个基本性质，本文引入了一个对维度崩溃敏感的新均匀性度量。

    

    均匀性在评估学习表示方面起着至关重要的作用，有助于更深入理解自监督学习。之前的一项开创性工作引入了一个均匀性度量，定量衡量学习表示的崩溃程度。直接优化这一度量与对齐一起，被证明能够有效地防止不断崩溃。然而，我们提出理论和实证证据表明这一度量缺乏对维度崩溃的敏感性，凸显了其局限性。为了解决这一局限性并设计一个更有效的均匀性度量，本文确定了五个基本性质，其中现有的均匀性度量未能满足其中的一些。我们随后引入了一个新的均匀性度量，满足所有这些期望，并且对维度崩溃具有敏感性。

    arXiv:2403.00642v1 Announce Type: cross  Abstract: Uniformity plays a crucial role in the assessment of learned representations, contributing to a deeper comprehension of self-supervised learning. The seminal work by \citet{Wang2020UnderstandingCR} introduced a uniformity metric that quantitatively measures the collapse degree of learned representations. Directly optimizing this metric together with alignment proves to be effective in preventing constant collapse. However, we present both theoretical and empirical evidence revealing that this metric lacks sensitivity to dimensional collapse, highlighting its limitations. To address this limitation and design a more effective uniformity metric, this paper identifies five fundamental properties, some of which the existing uniformity metric fails to meet. We subsequently introduce a novel uniformity metric that satisfies all of these desiderata and exhibits sensitivity to dimensional collapse. When applied as an auxiliary loss in various 
    
[^10]: 通过自动生成的数据集改进文本到图像生成中的显式空间关系

    Improving Explicit Spatial Relationships in Text-to-Image Generation through an Automatically Derived Dataset

    [https://arxiv.org/abs/2403.00587](https://arxiv.org/abs/2403.00587)

    该论文提出了一种自动生成包含明确空间关系的合成标题的方法，介绍了用于训练和评估的SR4G数据集，以及展示了通过微调稳定扩散模型可以获得高达9分的改进。

    

    现有研究发现，当前的文本到图像系统未能准确反映物体之间的明确空间关系，比如“在左侧”或“在下方”。 我们假设这是因为用于训练这些模型的图像标题中很少出现明确的空间关系。我们提出了一种自动方法，通过给定现有图像生成包含14个明确空间关系的合成标题。我们引入了“生成空间关系”(SR4G)数据集，其中包含990万个用于训练的图像标题对和超过6万个用于评估的标题。为了测试泛化性，我们还提供了一个“未见过”的切分，其中训练和测试标题中的对象集是不相交的。 SR4G是可以用来在文本到图像系统中进行空间微调的首个数据集。我们展示了通过微调两个不同的稳定扩散模型（标记为SD$_{SR4G}$）可以获得多达9个分数的改进。

    arXiv:2403.00587v1 Announce Type: cross  Abstract: Existing work has observed that current text-to-image systems do not accurately reflect explicit spatial relations between objects such as 'left of' or 'below'. We hypothesize that this is because explicit spatial relations rarely appear in the image captions used to train these models. We propose an automatic method that, given existing images, generates synthetic captions that contain 14 explicit spatial relations. We introduce the Spatial Relation for Generation (SR4G) dataset, which contains 9.9 millions image-caption pairs for training, and more than 60 thousand captions for evaluation. In order to test generalization we also provide an 'unseen' split, where the set of objects in the train and test captions are disjoint. SR4G is the first dataset that can be used to spatially fine-tune text-to-image systems. We show that fine-tuning two different Stable Diffusion models (denoted as SD$_{SR4G}$) yields up to 9 points improvements i
    
[^11]: 重新思考基于聚类条件的扩散模型

    Rethinking cluster-conditioned diffusion models

    [https://arxiv.org/abs/2403.00570](https://arxiv.org/abs/2403.00570)

    通过结合最新的图片聚类和扩散模型技术，本文提出了一种在考虑最佳聚类粒度的情况下实现最先进FID并具有较强训练样本效率的聚类条件扩散模型，并提出了一种新颖方法来减少视觉组搜索空间。

    

    我们针对使用聚类分配的图片级条件扩散模型进行了全面的实验研究。我们阐明了关于图片聚类的个别组件如何影响三个数据集上的图片合成。通过结合图片聚类和扩散模型的最新进展，我们展示了，在考虑到图片合成（视觉组）的最佳簇粒度的情况下，通过聚类条件可以实现最先进的FID（即在CIFAR10和CIFAR100上分别为1.67和2.17），同时实现了较强的训练样本效率。最后，我们提出了一种新颖的方法，通过仅使用基于特征的聚类来推导减少视觉组搜索空间的上限簇边界。与现有方法不同，我们发现聚类与基于聚类的图片生成之间没有显著联系。代码和聚类分配将会发布。

    arXiv:2403.00570v1 Announce Type: cross  Abstract: We present a comprehensive experimental study on image-level conditioning for diffusion models using cluster assignments. We elucidate how individual components regarding image clustering impact image synthesis across three datasets. By combining recent advancements from image clustering and diffusion models, we show that, given the optimal cluster granularity with respect to image synthesis (visual groups), cluster-conditioning can achieve state-of-the-art FID (i.e. 1.67, 2.17 on CIFAR10 and CIFAR100 respectively), while attaining a strong training sample efficiency. Finally, we propose a novel method to derive an upper cluster bound that reduces the search space of the visual groups using solely feature-based clustering. Unlike existing approaches, we find no significant connection between clustering and cluster-conditional image generation. The code and cluster assignments will be released.
    
[^12]: 摊平长程丢失景观，用于跨领域少样本学习

    Flatten Long-Range Loss Landscapes for Cross-Domain Few-Shot Learning

    [https://arxiv.org/abs/2403.00567](https://arxiv.org/abs/2403.00567)

    将分析损失景观从参数空间扩展到表示空间，观察到尖锐极小值导致难以转移和微调的表示，引入一种简单而有效的方法以增强可转移性和促进微调。

    

    跨领域少样本学习（CDFSL）旨在通过利用源域的丰富训练样本转移先前知识，以从目标域的有限训练数据中获取知识。本文针对CDFSL在跨不同领域传输知识和在有限训练数据下微调模型方面面临的挑战，将分析损失景观从参数空间扩展到表示空间，从而允许我们同时解释CDFSL模型的传输和微调困难。我们观察到表示空间损失景观中的尖锐极小值导致难以转移和微调的表示。此外，现有基于平坦性的方法由于其短程平坦性而具有有限的泛化能力。为增强可转移性并促进微调，我们引入了一种简单而有效的方法

    arXiv:2403.00567v1 Announce Type: cross  Abstract: Cross-domain few-shot learning (CDFSL) aims to acquire knowledge from limited training data in the target domain by leveraging prior knowledge transferred from source domains with abundant training samples. CDFSL faces challenges in transferring knowledge across dissimilar domains and fine-tuning models with limited training data. To address these challenges, we initially extend the analysis of loss landscapes from the parameter space to the representation space, which allows us to simultaneously interpret the transferring and fine-tuning difficulties of CDFSL models. We observe that sharp minima in the loss landscapes of the representation space result in representations that are hard to transfer and fine-tune. Moreover, existing flatness-based methods have limited generalization ability due to their short-range flatness. To enhance the transferability and facilitate fine-tuning, we introduce a simple yet effective approach to achieve
    
[^13]: 预测无人机类型：对时间序列分类进行采样和数据增强的探讨

    Predicting UAV Type: An Exploration of Sampling and Data Augmentation for Time Series Classification

    [https://arxiv.org/abs/2403.00565](https://arxiv.org/abs/2403.00565)

    本文提出了一个用于分类无人机类型的机器学习模型，通过长短期记忆神经网络进行时间序列分类，并优化了时间戳采样和类别不平衡修复方法。

    

    无人机变得越来越普遍并且具有许多生产用途。然而，它们的增加引发了安全担忧--我们如何保护受限制的空域？了解无人机的类型可以很大程度上帮助确定其潜在风险。例如，固定翼飞行器可以在较长距离上携带更多重量，因此可能构成更大的威胁。本文提出了一个用于将无人机分类为四旋翼、六旋翼或固定翼的机器学习模型。我们的方法有效地应用了长短期记忆（LSTM）神经网络来进行时间序列分类。我们进行了实验来测试更改时间戳采样方法和解决类别分布不平衡的影响。通过这些实验，我们确定了表现最好的采样和类别不平衡修复方法。

    arXiv:2403.00565v1 Announce Type: cross  Abstract: Unmanned aerial vehicles are becoming common and have many productive uses. However, their increased prevalence raises safety concerns -- how can we protect restricted airspace? Knowing the type of unmanned aerial vehicle can go a long way in determining any potential risks it carries. For instance, fixed-wing craft can carry more weight over longer distances, thus potentially posing a more significant threat. This paper presents a machine learning model for classifying unmanned aerial vehicles as quadrotor, hexarotor, or fixed-wing. Our approach effectively applies a Long-Short Term Memory (LSTM) neural network for the purpose of time series classification. We performed experiments to test the effects of changing the timestamp sampling method and addressing the imbalance in the class distribution. Through these experiments, we identified the top-performing sampling and class imbalance fixing methods. Averaging the macro f-scores acros
    
[^14]: 高效Zero V2：在有限数据下掌握离散和连续控制

    EfficientZero V2: Mastering Discrete and Continuous Control with Limited Data

    [https://arxiv.org/abs/2403.00564](https://arxiv.org/abs/2403.00564)

    EfficientZero V2在有限数据情况下通过一系列改进，在多个任务中超越了当前最先进水平，并且相比于通用算法DreamerV3有显著提升

    

    强化学习在现实世界任务中的样本效率仍然是一个关键挑战。虽然最近的算法在提高样本效率方面取得了显著进展，但没有一个能在不同领域中一直表现出优越性能。在本文中，我们介绍了EfficientZero V2，这是一个专为高效RL算法设计的通用框架。我们将EfficientZero的性能扩展到多个领域，涵盖连续和离散行动，以及视觉和低维输入。通过一系列我们提出的改进，EfficientZero V2在有限数据设置下在各种任务中大幅超越了当前的最先进水平（SOTA）。EfficientZero V2在多个基准测试中表现出明显的进步，比如Atari 100k，Proprio Control等中，在66个评估任务中有50个取得了优越的结果。

    arXiv:2403.00564v1 Announce Type: cross  Abstract: Sample efficiency remains a crucial challenge in applying Reinforcement Learning (RL) to real-world tasks. While recent algorithms have made significant strides in improving sample efficiency, none have achieved consistently superior performance across diverse domains. In this paper, we introduce EfficientZero V2, a general framework designed for sample-efficient RL algorithms. We have expanded the performance of EfficientZero to multiple domains, encompassing both continuous and discrete actions, as well as visual and low-dimensional inputs. With a series of improvements we propose, EfficientZero V2 outperforms the current state-of-the-art (SOTA) by a significant margin in diverse tasks under the limited data setting. EfficientZero V2 exhibits a notable advancement over the prevailing general algorithm, DreamerV3, achieving superior outcomes in 50 of 66 evaluated tasks across diverse benchmarks, such as Atari 100k, Proprio Control, an
    
[^15]: 使用不确定性加权损失进行异构人脸属性估计的多任务学习

    Multi-Task Learning Using Uncertainty to Weigh Losses for Heterogeneous Face Attribute Estimation

    [https://arxiv.org/abs/2403.00561](https://arxiv.org/abs/2403.00561)

    提出了一种使用不确定性加权损失进行多任务学习的通用框架，通过硬参数共享解决了异构属性之间的相关性问题，取得了对多个人脸属性的最佳估计效果，并降低了训练成本。

    

    人脸图像包含各种属性信息。本文提出了一种基于信息共享的联合估计有序和名义属性的通用框架。我们通过对浅层特征进行硬参数共享来解决异构属性之间的相关性问题，并通过考虑每个属性估计任务的同方差不确定性来权衡多个损失函数。这导致了对人脸的多个属性进行最佳估计，并减少了多任务学习的训练成本。在具有多个人脸属性的基准测试上的实验结果表明，所提出的方法相比最先进技术表现出更优越的性能。最后，我们讨论了提出方法在人脸属性估计中引起的偏见问题，并验证了它在边缘系统上的可行性。

    arXiv:2403.00561v1 Announce Type: cross  Abstract: Face images contain a wide variety of attribute information. In this paper, we propose a generalized framework for joint estimation of ordinal and nominal attributes based on information sharing. We tackle the correlation problem between heterogeneous attributes using hard parameter sharing of shallow features, and trade-off multiple loss functions by considering homoskedastic uncertainty for each attribute estimation task. This leads to optimal estimation of multiple attributes of the face and reduces the training cost of multitask learning. Experimental results on benchmarks with multiple face attributes show that the proposed approach has superior performance compared to state of the art. Finally, we discuss the bias issues arising from the proposed approach in face attribute estimation and validate its feasibility on edge systems.
    
[^16]: 模仿学习数据集：创建数据集、训练智能体和进行基准测试的工具包

    Imitation Learning Datasets: A Toolkit For Creating Datasets, Training Agents and Benchmarking

    [https://arxiv.org/abs/2403.00550](https://arxiv.org/abs/2403.00550)

    本研究提出了模仿学习数据集，通过专家政策的组织、现成数据集和技术的提供以及常见模仿学习技术实现的分享，解决了模仿学习中缺乏可用数据和评估一致性的问题。

    

    模仿学习领域需要专家数据来训练智能体完成任务。然而，这种学习方法常常因缺乏可用数据而备受困扰，导致技术测试都是基于自有数据。创建数据集是一个繁琐的过程，需要研究人员从头开始训练专家智能体、记录它们的交互并用新创建的数据测试每种基准方法。此外，为每种新技术创建新数据集会导致评估过程缺乏一致性，因为每个数据集在状态和动作分布上都可能大不相同。为了应对这些问题，本研究旨在创建模仿学习数据集，提供一个工具包，可以：(i) 提供经过精心策划的专家策略，并支持多线程以加快数据集的创建过程；(ii) 提供现成的数据集和技术以及精确的测量；以及(iii) 分享常用模仿学习技术的实现。

    arXiv:2403.00550v1 Announce Type: cross  Abstract: Imitation learning field requires expert data to train agents in a task. Most often, this learning approach suffers from the absence of available data, which results in techniques being tested on its dataset. Creating datasets is a cumbersome process requiring researchers to train expert agents from scratch, record their interactions and test each benchmark method with newly created data. Moreover, creating new datasets for each new technique results in a lack of consistency in the evaluation process since each dataset can drastically vary in state and action distribution. In response, this work aims to address these issues by creating Imitation Learning Datasets, a toolkit that allows for: (i) curated expert policies with multithreaded support for faster dataset creation; (ii) readily available datasets and techniques with precise measurements; and (iii) sharing implementations of common imitation learning techniques. Demonstration li
    
[^17]: ROME: 大型语言模型中文本、概率和隐藏状态的记忆洞察

    ROME: Memorization Insights from Text, Probability and Hidden State in Large Language Models

    [https://arxiv.org/abs/2403.00510](https://arxiv.org/abs/2403.00510)

    ROME提出了一种新方法，通过比较记忆和非记忆样本之间的差异，探索大型语言模型中的记忆化，这有助于在不访问训练数据的情况下了解模型记忆的洞察和影响因素。

    

    探究大型语言模型的记忆化具有重要意义。先前的研究建立了用于量化记忆的指标，探讨了各种影响因素，如数据复制、模型大小和提示长度，并通过将模型输出与训练语料库进行比较来评估记忆化。然而，训练语料库规模巨大且其预处理耗时。为了在不访问训练数据的情况下探索记忆化，我们提出了一种名为ROME的新方法，在此方法中，通过比较记忆化和非记忆化样本之间的差异来探索记忆化。具体来说，模型首先将选定的样本分为记忆化和非记忆化组，并通过文本、概率和隐藏状态的见解比较这两组中的演示。实验结果显示包括词长、词性、词频、均值和方差在内的因素的差异。

    arXiv:2403.00510v1 Announce Type: cross  Abstract: Probing the memorization of large language models holds significant importance. Previous works have established metrics for quantifying memorization, explored various influencing factors, such as data duplication, model size, and prompt length, and evaluated memorization by comparing model outputs with training corpora. However, the training corpora are of enormous scale and its pre-processing is time-consuming. To explore memorization without accessing training data, we propose a novel approach, named ROME, wherein memorization is explored by comparing disparities across memorized and non-memorized. Specifically, models firstly categorize the selected samples into memorized and non-memorized groups, and then comparing the demonstrations in the two groups from the insights of text, probability, and hidden state. Experimental findings show the disparities in factors including word length, part-of-speech, word frequency, mean and varianc
    
[^18]: 调查死亡思维：基于上下文构建表示（CCR）的历史心理文本分析对于古典中文

    Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese

    [https://arxiv.org/abs/2403.00509](https://arxiv.org/abs/2403.00509)

    基于上下文构建表示（CCR）的历史心理文本分析流程结合了心理测量学和自然语言处理技术，用于从古典中文语料库中提取心理构建，采用间接监督对比学习方法。

    

    在这项工作中，我们为古典中文开发了一个历史心理文本分析流程。数千年来，人类用各种语言创作文本；然而，大多数计算文献都集中在当代语言和语料库上。历史心理学这一新兴领域依赖计算技术，利用自然语言处理（NLP）中开发的新方法，从历史语料库中提取心理学方面的内容。名为上下文化结构表征（CCR）的当前流程，结合了心理测量学（即心理调查）领域的专业知识和通过基于transformer的语言模型生成的文本表示，以测量古典中文语料库中的传统主义、规范力量和集体主义等心理构建。鉴于可用数据的稀缺性，我们提出了间接监督对比学习方法，并建立了第一个中文...

    arXiv:2403.00509v1 Announce Type: cross  Abstract: In this work, we develop a pipeline for historical-psychological text analysis in classical Chinese. Humans have produced texts in various languages for thousands of years; however, most of the computational literature is focused on contemporary languages and corpora. The emerging field of historical psychology relies on computational techniques to extract aspects of psychology from historical corpora using new methods developed in natural language processing (NLP). The present pipeline, called Contextualized Construct Representations (CCR), combines expert knowledge in psychometrics (i.e., psychological surveys) with text representations generated via transformer-based language models to measure psychological constructs such as traditionalism, norm strength, and collectivism in classical Chinese corpora. Considering the scarcity of available data, we propose an indirect supervised contrastive learning approach and build the first Chin
    
[^19]: 学习和利用视觉表示学习中的世界模型

    Learning and Leveraging World Models in Visual Representation Learning

    [https://arxiv.org/abs/2403.00504](https://arxiv.org/abs/2403.00504)

    通过联合嵌入预测架构（JEPA）以及引入图像世界模型（IWM），本研究探讨了如何将JEPA预测任务概括为更广泛的数据损坏形式，并研究了学习性能良好的IWM的关键方面。此外，通过微调可以将IWM学到的预测世界模型用于解决各种任务，最终控制所学习表示的抽象级别。

    

    通过联合嵌入预测架构（JEPA），我们探讨了如何将JEPA预测任务概括为更广泛的数据损坏形式。我们引入了图像世界模型（IWM），这种方法超越了遮罩图像建模，学会在潜在空间中预测全局光度变换的影响。我们研究了学习性能良好的IWM的关键方面：条件、预测困难度和容量。此外，我们表明通过微调可以将IWM学到的预测世界模型用于解决各种任务；经过微调的IWM世界模型的性能与甚至超过以往的自监督方法。最后，我们表明通过IWM学习可以控制所学习表示的抽象级别。

    arXiv:2403.00504v1 Announce Type: cross  Abstract: Joint-Embedding Predictive Architecture (JEPA) has emerged as a promising self-supervised approach that learns by leveraging a world model. While previously limited to predicting missing parts of an input, we explore how to generalize the JEPA prediction task to a broader set of corruptions. We introduce Image World Models, an approach that goes beyond masked image modeling and learns to predict the effect of global photometric transformations in latent space. We study the recipe of learning performant IWMs and show that it relies on three key aspects: conditioning, prediction difficulty, and capacity. Additionally, we show that the predictive world model learned by IWM can be adapted through finetuning to solve diverse tasks; a fine-tuned IWM world model matches or surpasses the performance of previous self-supervised methods. Finally, we show that learning with an IWM allows one to control the abstraction level of the learned represe
    
[^20]: 并行脉冲神经网络的超参数优化

    Parallel Hyperparameter Optimization Of Spiking Neural Network

    [https://arxiv.org/abs/2403.00450](https://arxiv.org/abs/2403.00450)

    该研究通过引入静默网络的概念，并设计特定约束，实现了更大更灵活的脉冲神经网络超参数的优化搜索空间，并应用了并行化的受约束贝叶斯优化技术。

    

    脉冲神经网络（SNN）。SNN基于比通常的人工神经网络更具生物启发的方法。这些模型的特点是神经元和脉冲之间的复杂动态。这些模型对超参数非常敏感，使得它们的优化具有挑战性。为了解决SNN的超参数优化问题，我们首先将SNN的信号损失问题扩展到我们称之为静默网络。这些网络由于超参数或架构设置不当而无法在输出端发出足够的脉冲。一般来说，搜索空间受到严格限制，有时甚至是离散化的，以防止对这样的网络进行采样。通过定义一个早停准则来检测静默网络，并设计特定的约束，我们能够实例化更大、更灵活的搜索空间。我们应用了一种受约束的贝叶斯优化技术，并将其异步并行化，因为一个评估时间

    arXiv:2403.00450v1 Announce Type: cross  Abstract: Spiking Neural Networks (SNN). SNNs are based on a more biologically inspired approach than usual artificial neural networks. Such models are characterized by complex dynamics between neurons and spikes. These are very sensitive to the hyperparameters, making their optimization challenging. To tackle hyperparameter optimization of SNNs, we initially extended the signal loss issue of SNNs to what we call silent networks. These networks fail to emit enough spikes at their outputs due to mistuned hyperparameters or architecture. Generally, search spaces are heavily restrained, sometimes even discretized, to prevent the sampling of such networks. By defining an early stopping criterion detecting silent networks and by designing specific constraints, we were able to instantiate larger and more flexible search spaces. We applied a constrained Bayesian optimization technique, which was asynchronously parallelized, as the evaluation time of a 
    
[^21]: 作者对人工智能桥接的可伸缩个性化创意语言艺术的价值观和态度

    Authors' Values and Attitudes Towards AI-bridged Scalable Personalization of Creative Language Arts

    [https://arxiv.org/abs/2403.00439](https://arxiv.org/abs/2403.00439)

    作者们通过对人工智能桥接的创意语言艺术进行了价值观和态度的研究，发现了AI如何影响作者、作品和观众之间的利益关系，以及作者的担忧。

    

    生成式人工智能有潜力创造一种新形式的交互式媒体：人工智能桥接的创意语言艺术（CLA），通过在规模上将作者的愿景个性化地呈现给观众，从而桥接了作者和观众之间的联系。然而，就作者对人工智能桥接的CLA的价值观和态度而言，目前尚不清楚。为了识别这些价值观和态度，我们通过呈现具有推测性但现实的人工智能桥接的CLA场景，对跨越八种流派（如诗歌、漫画）的18位作者进行了访谈研究。我们确定了作者、作品和观众之间的动态带来的三个收益：作者从该过程中获得的收益，观众从作品中获得的收益，以及作者从观众处获得的收益。我们发现了AI桥接的CLA如何会促进或减少这些利益，以及作者的担忧。我们希望我们的调查能够暗示AI如何为CLA观众提供有趣的体验，同时解决了作者的担忧。

    arXiv:2403.00439v1 Announce Type: cross  Abstract: Generative AI has the potential to create a new form of interactive media: AI-bridged creative language arts (CLA), which bridge the author and audience by personalizing the author's vision to the audience's context and taste at scale. However, it is unclear what the authors' values and attitudes would be regarding AI-bridged CLA. To identify these values and attitudes, we conducted an interview study with 18 authors across eight genres (e.g., poetry, comics) by presenting speculative but realistic AI-bridged CLA scenarios. We identified three benefits derived from the dynamics between author, artifact, and audience: those that 1) authors get from the process, 2) audiences get from the artifact, and 3) authors get from the audience. We found how AI-bridged CLA would either promote or reduce these benefits, along with authors' concerns. We hope our investigation hints at how AI can provide intriguing experiences to CLA audiences while p
    
[^22]: LoMOE: 通过多扩散实现局部多对象编辑

    LoMOE: Localized Multi-Object Editing via Multi-Diffusion

    [https://arxiv.org/abs/2403.00437](https://arxiv.org/abs/2403.00437)

    通过多扩散过程实现零样本局部多对象编辑，赋予用户在图像中一次性添加、替换或编辑多对象的能力。

    

    扩散模型领域的最新发展展示了生成高质量基于提示条件的图像编辑的卓越能力。然而，先前的方法主要依赖于文本提示进行图像编辑，当对场景中包含单个/多个对象的特定对象或细粒度区域进行精确编辑时往往不太有效。我们引入了一种新颖的框架，通过多扩散过程实现零样本局部多对象编辑，以克服这一挑战。该框架赋予用户在图像中对对象执行各种操作的能力，例如在一个复杂场景中一次性添加、替换或编辑$\textbf{多}$对象。我们的方法利用前景 mask 和对应的简单文本提示对目标区域施加局部影响，实现高保真度图像编辑。通过跨注意力和背景

    arXiv:2403.00437v1 Announce Type: cross  Abstract: Recent developments in the field of diffusion models have demonstrated an exceptional capacity to generate high-quality prompt-conditioned image edits. Nevertheless, previous approaches have primarily relied on textual prompts for image editing, which tend to be less effective when making precise edits to specific objects or fine-grained regions within a scene containing single/multiple objects. We introduce a novel framework for zero-shot localized multi-object editing through a multi-diffusion process to overcome this challenge. This framework empowers users to perform various operations on objects within an image, such as adding, replacing, or editing $\textbf{many}$ objects in a complex scene $\textbf{in one pass}$. Our approach leverages foreground masks and corresponding simple text prompts that exert localized influences on the target regions resulting in high-fidelity image editing. A combination of cross-attention and backgrou
    
[^23]: Abductive Ego-View事故视频理解以实现安全驾驶感知

    Abductive Ego-View Accident Video Understanding for Safe Driving Perception

    [https://arxiv.org/abs/2403.00436](https://arxiv.org/abs/2403.00436)

    提出了MM-AU数据集，用于多模态事故视频理解，支持各种事故理解任务，特别是多模态视频扩散以理解安全驾驶的事故因果链。

    

    我们介绍了MM-AU，这是一个用于多模态事故视频理解的新数据集。MM-AU包含11,727个野外自我视角事故视频，每个视频配有时间上对齐的文本描述。我们标注了超过223万个物体框和58,650对基于视频的事故原因，涵盖了58种事故类别。MM-AU支持各种事故理解任务，特别是多模态视频扩散以理解安全驾驶的事故因果链。

    arXiv:2403.00436v1 Announce Type: cross  Abstract: We present MM-AU, a novel dataset for Multi-Modal Accident video Understanding. MM-AU contains 11,727 in-the-wild ego-view accident videos, each with temporally aligned text descriptions. We annotate over 2.23 million object boxes and 58,650 pairs of video-based accident reasons, covering 58 accident categories. MM-AU supports various accident understanding tasks, particularly multimodal video diffusion to understand accident cause-effect chains for safe driving. With MM-AU, we present an Abductive accident Video understanding framework for Safe Driving perception (AdVersa-SD). AdVersa-SD performs video diffusion via an Object-Centric Video Diffusion (OAVD) method which is driven by an abductive CLIP model. This model involves a contrastive interaction loss to learn the pair co-occurrence of normal, near-accident, accident frames with the corresponding text descriptions, such as accident reasons, prevention advice, and accident categor
    
[^24]: 通过自适应焦点对比解码减少对象幻觉：HALC

    HALC: Object Hallucination Reduction via Adaptive Focal-Contrast Decoding

    [https://arxiv.org/abs/2403.00425](https://arxiv.org/abs/2403.00425)

    HALC是一种旨在减少大型视觉-语言模型中对象幻觉的新颖解码算法，通过局部的自动聚焦基准机制和全局的波束搜索算法，成功减少OH而保持文本生成质量，同时可以作为即插即用模块集成到任何LVLMs中。

    

    在解释多模态环境方面，大型视觉-语言模型（LVLMs）展现了令人印象深刻的能力，但它们不可避免地会受到对象幻觉（OH）的困扰。我们介绍了HALC，这是一种新颖的解码算法，旨在减少LVLMs中的OH。HALC利用视觉-语言任务中独特的细粒度最佳视觉信息，并同时在局部和全局上操作。具体来说，HALC集成了一个强大的自动聚焦基准机制（局部），在运行时纠正产生幻觉的标记，以及一种专门的波束搜索算法（全局），以显着减少OH，同时保持文本生成质量。此外，HALC可以作为即插即用模块集成到任何LVLMs中，无需额外训练。大量实验研究证明了HALC在减少OH方面的有效性，优于四个基准测试中的现有技术。

    arXiv:2403.00425v1 Announce Type: cross  Abstract: While large vision-language models (LVLMs) have demonstrated impressive capabilities in interpreting multi-modal contexts, they invariably suffer from object hallucinations (OH). We introduce HALC, a novel decoding algorithm designed to mitigate OH in LVLMs. HALC leverages distinct fine-grained optimal visual information in vision-language tasks and operates on both local and global contexts simultaneously. Specifically, HALC integrates a robust auto-focal grounding mechanism (locally) to correct hallucinated tokens on the fly, and a specialized beam search algorithm (globally) to significantly reduce OH while preserving text generation quality. Additionally, HALC can be integrated into any LVLMs as a plug-and-play module without extra training. Extensive experimental studies demonstrate the effectiveness of HALC in reducing OH, outperforming state-of-the-arts across four benchmarks.
    
[^25]: 经由对抗攻击和训练的稳健深度强化学习：一项调查

    Robust Deep Reinforcement Learning Through Adversarial Attacks and Training : A Survey

    [https://arxiv.org/abs/2403.00420](https://arxiv.org/abs/2403.00420)

    通过对抗性训练来改进DRL对条件变化的鲁棒性，研究者系统分析了当代对抗攻击方法，提供了详细见解。

    

    深度强化学习（DRL）是一种训练自主代理在各种复杂环境中的方法。尽管在众所周知的环境中表现出色，但它仍然容易受到轻微条件变化的影响，引发了人们对其在现实应用中可靠性的担忧。为了提高可用性，DRL必须展示出可信度和鲁棒性。通过对抗性训练提高DRL对条件变化的鲁棒性是一种改进方式，通过训练代理针对环境动态的适当对抗性攻击。我们的工作致力于解决这一关键问题，对当代对抗攻击方法进行了深入分析，系统地对其进行分类，并比较它们的目标和操作机制。这种分类为我们提供了对对抗性攻击如何有效评估DRL代理的恢复力的详细见解，从而为开辟DRL在实际应用中的道路奠定了基础。

    arXiv:2403.00420v1 Announce Type: cross  Abstract: Deep Reinforcement Learning (DRL) is an approach for training autonomous agents across various complex environments. Despite its significant performance in well known environments, it remains susceptible to minor conditions variations, raising concerns about its reliability in real-world applications. To improve usability, DRL must demonstrate trustworthiness and robustness. A way to improve robustness of DRL to unknown changes in the conditions is through Adversarial Training, by training the agent against well suited adversarial attacks on the dynamics of the environment. Addressing this critical issue, our work presents an in-depth analysis of contemporary adversarial attack methodologies, systematically categorizing them and comparing their objectives and operational mechanisms. This classification offers a detailed insight into how adversarial attacks effectively act for evaluating the resilience of DRL agents, thereby paving the 
    
[^26]: GLFNET: 用于高效医学图像分割的全局-局部（频率）滤波器网络

    GLFNET: Global-Local (frequency) Filter Networks for efficient medical image segmentation

    [https://arxiv.org/abs/2403.00396](https://arxiv.org/abs/2403.00396)

    GLFNET提出了全局-局部滤波器网络（GLFNet）用于医学图像分割，采用全局-局部滤波块的组合替换自注意力机制，实现了高效的特征提取，提高了模型的性能。

    

    我们提出了一种名为全局-局部滤波器网络（GLFNet）的新型变压器式架构，用于医学图像分割，并展示了其最先进的性能。我们用全局-局部滤波块的组合替换了自注意力机制以优化模型效率。全局滤波器从整个特征图中提取特征，而局部滤波器被自适应地创建为同一特征图的4x4补丁，并添加了受限的尺度信息。特征提取发生在频域而不是常用的空间（图像）域，以促进更快的计算。从空间和频率空间中融合信息创造出一个复杂性、所需数据和性能方面都高效的模型。我们在三个基准数据集上测试了GLFNet，在所有数据集上都取得了最先进的性能，同时在效率上几乎提高了一倍。

    arXiv:2403.00396v1 Announce Type: cross  Abstract: We propose a novel transformer-style architecture called Global-Local Filter Network (GLFNet) for medical image segmentation and demonstrate its state-of-the-art performance. We replace the self-attention mechanism with a combination of global-local filter blocks to optimize model efficiency. The global filters extract features from the whole feature map whereas the local filters are being adaptively created as 4x4 patches of the same feature map and add restricted scale information. In particular, the feature extraction takes place in the frequency domain rather than the commonly used spatial (image) domain to facilitate faster computations. The fusion of information from both spatial and frequency spaces creates an efficient model with regards to complexity, required data and performance. We test GLFNet on three benchmark datasets achieving state-of-the-art performance on all of them while being almost twice as efficient in terms of 
    
[^27]: 视觉-语言模型泛化的不变测试时适应性

    Invariant Test-Time Adaptation for Vision-Language Model Generalization

    [https://arxiv.org/abs/2403.00376](https://arxiv.org/abs/2403.00376)

    本文提出了一个测试时提示调优范式，通过优化可学习的提示，迫使模型利用真正的因果不变特征，以解决视觉-语言模型在特定任务需求上无法有效利用预训练特征的挑战。

    

    arXiv:2403.00376v1 公告类型: 交叉摘要: 视觉-语言基础模型在大量图像-文本配对数据集上的可扩展性使其在众多下游任务中展现出卓越成功。然而，这些模型在应用于长尾任务（如细粒度图像分类）时显示出明显局限，这是由于“决策捷径”导致了它们的泛化能力受限。本文发现CLIP模型具有丰富的特征集，涵盖了既有的\textit{期望不变因果特征}又有的\textit{不希望的决策捷径}。此外，CLIP在下游任务中的表现不佳源自其无法有效利用预训练特征以符合特定任务要求。为解决这一挑战，本文引入一种测试时提示调优范式，优化一个可学习的提示，从而促使模型利用真正的因果不变特征。

    arXiv:2403.00376v1 Announce Type: cross  Abstract: Vision-language foundation models have exhibited remarkable success across a multitude of downstream tasks due to their scalability on extensive image-text paired datasets. However, these models display significant limitations when applied to long-tail tasks, such as fine-grained image classification, as a result of "decision shortcuts" that hinders their generalization capabilities. In this work, we find that the CLIP model possesses a rich set of features, encompassing both \textit{desired invariant causal features} and \textit{undesired decision shortcuts}. Moreover, the underperformance of CLIP on downstream tasks originates from its inability to effectively utilize pre-trained features in accordance with specific task requirements. To address this challenge, this paper introduces a test-time prompt tuning paradigm that optimizes a learnable prompt, thereby compelling the model to exploit genuine causal invariant features while dis
    
[^28]: MS-Net：多路径稀疏模型用于多场景中的运动预测

    MS-Net: A Multi-Path Sparse Model for Motion Prediction in Multi-Scenes

    [https://arxiv.org/abs/2403.00353](https://arxiv.org/abs/2403.00353)

    MS-Net是一个多路径稀疏模型，通过进化过程进行训练，针对不同场景选择性激活其参数子集进行预测。这种方法解决了多场景下运动预测问题的挑战。

    

    人类行为的多模态性和随机特征使得运动预测成为一项极具挑战性的任务，这对于自动驾驶至关重要。尽管深度学习方法在这一领域展现了巨大潜力，但如何建立多个行驶场景（如合并、环岛、十字路口）与深度学习模型设计之间的联系仍未解决。为解决这一问题，我们提出了Multi-Scenes Network（简称MS-Net），这是一个通过进化过程训练的多路径稀疏模型。MS-Net在推断阶段选择性地激活其参数子集，以产生每个场景的预测结果。在训练阶段，将不同场景下的运动预测任务抽象化。

    arXiv:2403.00353v1 Announce Type: cross  Abstract: The multi-modality and stochastic characteristics of human behavior make motion prediction a highly challenging task, which is critical for autonomous driving. While deep learning approaches have demonstrated their great potential in this area, it still remains unsolved to establish a connection between multiple driving scenes (e.g., merging, roundabout, intersection) and the design of deep learning models. Current learning-based methods typically use one unified model to predict trajectories in different scenarios, which may result in sub-optimal results for one individual scene. To address this issue, we propose Multi-Scenes Network (aka. MS-Net), which is a multi-path sparse model trained by an evolutionary process. MS-Net selectively activates a subset of its parameters during the inference stage to produce prediction results for each scene. In the training stage, the motion prediction task under differentiated scenes is abstracted
    
[^29]: 永不停止的具身机器人学习

    Never-Ending Embodied Robot Learning

    [https://arxiv.org/abs/2403.00336](https://arxiv.org/abs/2403.00336)

    提出了一种具身机器人学习代理NBCagent，通过技能特定的演化规划器和技能共享的语义渲染模块，实现从视觉观测中连续学习新的机器人操作技能知识。

    

    依赖于大型语言模型（LLM），具身机器人可以通过强大的泛化能力，从视觉观测中执行复杂的多模态机器人操作任务。然而，大多数视觉行为克隆代理在适应一系列具有挑战性的未见任务时，会遭受操纵性能下降以及技能知识遗忘的困扰。在本研究中，我们通过NBCagent在具身机器人中探讨了上述挑战，这是一种开创性的、以语言为条件的永不停止行为克隆代理，可以不断从特定技能和共享技能属性中学习新的机器人操作技能的观察知识。具体来说，我们建立了一个特定技能不断演化的规划器来进行知识解耦，这可以从潜在和低秩空间中不断向我们的NBCagent代理嵌入新的技能特定知识。与此同时，我们提出了一个技能共享语义渲染模块和一个技能共享表示区分

    arXiv:2403.00336v1 Announce Type: cross  Abstract: Relying on large language models (LLMs), embodied robots could perform complex multimodal robot manipulation tasks from visual observations with powerful generalization ability. However, most visual behavior-cloning agents suffer from manipulation performance degradation and skill knowledge forgetting when adapting into a series of challenging unseen tasks. We here investigate the above challenge with NBCagent in embodied robots, a pioneering language-conditioned Never-ending Behavior-Cloning agent, which can continually learn observation knowledge of novel robot manipulation skills from skill-specific and skill-shared attributes. Specifically, we establish a skill-specific evolving planner to perform knowledge decoupling, which can continually embed novel skill-specific knowledge in our NBCagent agent from latent and low-rank space. Meanwhile, we propose a skill-shared semantics rendering module and a skill-shared representation disti
    
[^30]: 在不满足捷径的情况下学习逻辑约束

    Learning with Logical Constraints but without Shortcut Satisfaction

    [https://arxiv.org/abs/2403.00329](https://arxiv.org/abs/2403.00329)

    引入了逻辑连接词的双重变量来解决捷径满足问题，提出了一个新的学习逻辑约束的框架，实验证明其在模型的普适性和约束满足方面性能优越。

    

    最近的神经符号学习研究探讨了通过将逻辑知识编码为额外的损失函数将逻辑约束整合到深度学习中。然而，现有方法往往通过捷径虚假地满足了逻辑约束，未能充分利用知识。本文提出了一个新的学习逻辑约束的框架。具体而言，我们通过引入逻辑连接词的双重变量来解决捷径满足问题，对约束的满足方式进行编码。我们进一步提出了一个变分框架，其中编码的逻辑约束被表达为一个分布损失，与模型的原始训练损失兼容。理论分析表明，所提出的方法具有显著的特性，实验评估显示其在模型的普适性和约束满足方面性能优越。

    arXiv:2403.00329v1 Announce Type: new  Abstract: Recent studies in neuro-symbolic learning have explored the integration of logical knowledge into deep learning via encoding logical constraints as an additional loss function. However, existing approaches tend to vacuously satisfy logical constraints through shortcuts, failing to fully exploit the knowledge. In this paper, we present a new framework for learning with logical constraints. Specifically, we address the shortcut satisfaction issue by introducing dual variables for logical connectives, encoding how the constraint is satisfied. We further propose a variational framework where the encoded logical constraint is expressed as a distributional loss that is compatible with the model's original training loss. The theoretical analysis shows that the proposed approach bears salient properties, and the experimental evaluations demonstrate its superior performance in both model generalizability and constraint satisfaction.
    
[^31]: 神经符号系统的软化符号接地

    Softened Symbol Grounding for Neuro-symbolic Systems

    [https://arxiv.org/abs/2403.00323](https://arxiv.org/abs/2403.00323)

    提出了一种软化符号接地过程，有效地桥接了神经网络训练和符号约束求解，形成了一个高效的神经符号学习框架

    

    神经符号学习通常包括两个独立世界，即神经网络训练和符号约束求解，其成功取决于符号接地，这是人工智能中的一个基本问题。本文提出了一种新颖的软化符号接地过程，弥合了两个世界之间的差距，从而形成了一个有效且高效的神经符号学习框架。技术上，该框架具有以下特点：(1)将符号解状态建模为Boltzmann分布，避免了昂贵的状态搜索，并促进了网络训练和符号推理之间的互惠互利交互；(2)利用投影和SMT解算器的新型MCMC技术，高效地从断开的符号解空间中采样；(3)一种退火机制，可以摆脱陷入次优符号接地的困境。对三个代表性的神经符号学习任务进行的实验表明，该框架具有显著提高

    arXiv:2403.00323v1 Announce Type: new  Abstract: Neuro-symbolic learning generally consists of two separated worlds, i.e., neural network training and symbolic constraint solving, whose success hinges on symbol grounding, a fundamental problem in AI. This paper presents a novel, softened symbol grounding process, bridging the gap between the two worlds, and resulting in an effective and efficient neuro-symbolic learning framework. Technically, the framework features (1) modeling of symbol solution states as a Boltzmann distribution, which avoids expensive state searching and facilitates mutually beneficial interactions between network training and symbolic reasoning;(2) a new MCMC technique leveraging projection and SMT solvers, which efficiently samples from disconnected symbol solution spaces; (3) an annealing mechanism that can escape from %being trapped into sub-optimal symbol groundings. Experiments with three representative neuro symbolic learning tasks demonstrate that, owining 
    
[^32]: 深度强化学习用于解决管理问题: 迈向大型管理模式

    Deep Reinforcement Learning for Solving Management Problems: Towards A Large Management Mode

    [https://arxiv.org/abs/2403.00318](https://arxiv.org/abs/2403.00318)

    该论文介绍了一种基于深度强化学习的方法，旨在解决管理问题，如库存管理、动态定价和推荐，提出了一种基于变压器神经网络结构的大型管理模型，能够超越传统启发式方法解决管理任务，实现跨领域决策协调，证明了在复杂动态商业环境中DRL框架的有效性。

    

    我们引入了一种深度强化学习（DRL）方法，用于解决包括库存管理、动态定价和推荐在内的管理问题。该DRL方法有潜力基于特定的变压器神经网络结构，开发出一个大型管理模型，从而形成适用于各种管理任务的人工通用智能范式。我们试图在一个统一框架中解决问题，考虑到不同任务之间的相互关系。我们的方法的核心是通过生成式决策进行基础决策模型的开发，协调跨不同领域的决策。我们的实验结果证实了我们基于DRL的框架在复杂和动态的商业环境中的有效性。

    arXiv:2403.00318v1 Announce Type: new  Abstract: We introduce a deep reinforcement learning (DRL) approach for solving management problems including inventory management, dynamic pricing, and recommendation. This DRL approach has the potential to lead to a large management model based on certain transformer neural network structures, resulting in an artificial general intelligence paradigm for various management tasks. Traditional methods have limitations for solving complex real-world problems, and we demonstrate how DRL can surpass existing heuristic approaches for solving management tasks. We aim to solve the problems in a unified framework, considering the interconnections between different tasks. Central to our methodology is the development of a foundational decision model coordinating decisions across the different domains through generative decision-making. Our experimental results affirm the effectiveness of our DRL-based framework in complex and dynamic business environments.
    
[^33]: 切掉XAI中的X: 为可理解的人工智能辩护

    Axe the X in XAI: A Plea for Understandable AI

    [https://arxiv.org/abs/2403.00315](https://arxiv.org/abs/2403.00315)

    论文辩护了采用“可理解的人工智能”标签作为替代“XAI”，以避免围绕XAI目标和目的的混乱，并主张采用更适合的实用理解概念。

    

    在最近的一篇论文中，Erasmus等人(2021)辩护了在可解释的人工智能(XAI)中术语“解释”存在的歧义可以通过采用哲学科学中四种不同的现存解释模式之一来解决：演绎-规范、归纳-统计、因果机械和新机制主义模式。在本章中，我展示了作者声称这些模式可以像对待任何自然现象一样应用于深度神经网络的说法是错误的。我还提出了更一般的论点，说明了XAI文献中目前使用的可解释性概念与传统科学解释概念几乎没有相似之处。更有成效的做法是使用“可理解的人工智能”标签，以避免围绕XAI目标和目的的困惑。在章节的后半部分，我主张采用更适合扮演核心角色的实用理解概念。

    arXiv:2403.00315v1 Announce Type: new  Abstract: In a recent paper, Erasmus et al. (2021) defend the idea that the ambiguity of the term "explanation" in explainable AI (XAI) can be solved by adopting any of four different extant accounts of explanation in the philosophy of science: the Deductive Nomological, Inductive Statistical, Causal Mechanical, and New Mechanist models. In this chapter, I show that the authors' claim that these accounts can be applied to deep neural networks as they would to any natural phenomenon is mistaken. I also provide a more general argument as to why the notion of explainability as it is currently used in the XAI literature bears little resemblance to the traditional concept of scientific explanation. It would be more fruitful to use the label "understandable AI" to avoid the confusion that surrounds the goal and purposes of XAI. In the second half of the chapter, I argue for a pragmatic conception of understanding that is better suited to play the centra
    
[^34]: 嵌入式多标签特征选择的正交回归方法

    Embedded Multi-label Feature Selection via Orthogonal Regression

    [https://arxiv.org/abs/2403.00307](https://arxiv.org/abs/2403.00307)

    提出了一种新颖的嵌入式多标签特征选择方法，GRROOR，利用正交回归和特征加权以保留足够的统计和结构信息，进一步提高多标签数据的分类性能。

    

    在过去的十年里，嵌入式多标签特征选择方法吸引了相当大的关注，将特征子集的搜索纳入模型优化，以准确评估多标签分类任务中特征的重要性。然而，基于最小二乘回归的最先进的嵌入式多标签特征选择算法通常无法保留足够的多标签数据中的判别信息。为了解决上述挑战，提出了一种新的嵌入式多标签特征选择方法，称为正交回归中的全局冗余和相关性优化（GRROOR），以促进多标签特征选择。该方法利用具有特征加权的正交回归，在特征学习过程中保留与多标签数据的局部标签相关性相关的足够统计和结构信息。此外，既考虑了全局冗余，又考虑了相关性优化，以促进分类性能的进一步提高。

    arXiv:2403.00307v1 Announce Type: cross  Abstract: In the last decade, embedded multi-label feature selection methods, incorporating the search for feature subsets into model optimization, have attracted considerable attention in accurately evaluating the importance of features in multi-label classification tasks. Nevertheless, the state-of-the-art embedded multi-label feature selection algorithms based on least square regression usually cannot preserve sufficient discriminative information in multi-label data. To tackle the aforementioned challenge, a novel embedded multi-label feature selection method, termed global redundancy and relevance optimization in orthogonal regression (GRROOR), is proposed to facilitate the multi-label feature selection. The method employs orthogonal regression with feature weighting to retain sufficient statistical and structural information related to local label correlations of the multi-label data in the feature learning process. Additionally, both glob
    
[^35]: 用于MIMO CSI反馈的通用自编码器框架

    Universal Auto-encoder Framework for MIMO CSI Feedback

    [https://arxiv.org/abs/2403.00299](https://arxiv.org/abs/2403.00299)

    该论文提出了一个通用的自编码器框架，可以支持不同输入大小和多种压缩比，相比于朴素和最先进方法，在降低硬件复杂度的同时提供了可比的性能表现。

    

    现有基于自编码器（AE）的信道状态信息（CSI）框架专注于特定配置的用户设备（UE）和基站（BS），因此AE的输入和输出大小是固定的。然而，在实际情况下，输入和输出大小可能会根据BS和UE的天线数量以及在频率维度上分配的资源块数量而变化。支持不同输入和输出大小的一种简单方法是使用多个AE模型，但由于UE的有限硬件资源，这种方法是不切实际的。在本文中，我们提出了一个通用AE框架，可以支持不同的输入大小和多种压缩比。所提出的AE框架在提供与朴素和最先进方法相比可比的压缩比-失真平衡性能的同时大大降低了硬件复杂度。

    arXiv:2403.00299v1 Announce Type: cross  Abstract: Existing auto-encoder (AE)-based channel state information (CSI) frameworks have focused on a specific configuration of user equipment (UE) and base station (BS), and thus the input and output sizes of the AE are fixed. However, in the real-world scenario, the input and output sizes may vary depending on the number of antennas of the BS and UE and the allocated resource block in the frequency dimension. A naive approach to support the different input and output sizes is to use multiple AE models, which is impractical for the UE due to the limited HW resources. In this paper, we propose a universal AE framework that can support different input sizes and multiple compression ratios. The proposed AE framework significantly reduces the HW complexity while providing comparable performance in terms of compression ratio-distortion trade-off compared to the naive and state-of-the-art approaches.
    
[^36]: 基于小型语言模型的语义文本传输：成本-相似度权衡

    Semantic Text Transmission via Prediction with Small Language Models: Cost-Similarity Trade-off

    [https://arxiv.org/abs/2403.00290](https://arxiv.org/abs/2403.00290)

    该研究通过使用小型语言模型进行预测，实现了在语义文本传输中的成本和相似度之间的权衡。

    

    我们考虑在无噪音和字符擦除通道上从源到目的地传输自然语言文本。我们利用语言的固有相关性和可预测性，通过允许目的地预测或补全与源文本可能不相似的单词来限制传输成本。我们的目标是获得可实现的$(\bar{c}, \bar{s})$对，其中$\bar{c}$是源头的平均传输成本，$\bar{s}$是通过余弦相似度测量的源头词向量和目的地预测/补全词向量之间的平均语义相似度。我们使用神经语言模型和基于一阶马尔可夫链的小型语言模型(SLM)进行预测，为传输使用了阈值策略，即如果单词与目的地预测/补全的单词的余弦相似度低于阈值，则传输该单词。

    arXiv:2403.00290v1 Announce Type: cross  Abstract: We consider the communication of natural language text from a source to a destination over noiseless and character-erasure channels. We exploit language's inherent correlations and predictability to constrain transmission costs by allowing the destination to predict or complete words with potential dissimilarity with the source text. Concretely, our objective is to obtain achievable $(\bar{c}, \bar{s})$ pairs, where $\bar{c}$ is the average transmission cost at the source and $\bar{s}$ is the average semantic similarity measured via cosine similarity between vector embedding of words at the source and those predicted/completed at the destination. We obtain $(\bar{c}, \bar{s})$ pairs for neural language and first-order Markov chain-based small language models (SLM) for prediction, using both a threshold policy that transmits a word if its cosine similarity with that predicted/completed at the destination is below a threshold, and a peri
    
[^37]: 路线推荐综述：方法、应用和机会

    A Survey of Route Recommendations: Methods, Applications, and Opportunities

    [https://arxiv.org/abs/2403.00284](https://arxiv.org/abs/2403.00284)

    基于城市计算的路线推荐综述对路线推荐研究中的传统机器学习和现代深度学习方法进行了分类，展示了与城市计算场景相关的新应用，并揭示了最新进展。

    

    现今，随着先进的信息技术部署在整个城市，大量数据和强大的计算资源正在使现代城市发展智能化。作为智能交通的重要组成部分，路线推荐及其应用被广泛使用，直接影响市民的出行习惯。基于大数据（可能是多模式）开发智能高效的出行路线已成为路线推荐研究的核心挑战。我们的综述对基于城市计算的路线推荐工作进行了全面回顾。它分为以下三个部分：1）方法论。我们对大量传统机器学习和现代深度学习方法进行分类。同时，我们讨论它们的历史关系并揭示最新进展。2）应用方面。我们展示了大量与城市计算场景中路线推荐相关的新应用。3）我们迪

    arXiv:2403.00284v1 Announce Type: new  Abstract: Nowadays, with advanced information technologies deployed citywide, large data volumes and powerful computational resources are intelligentizing modern city development. As an important part of intelligent transportation, route recommendation and its applications are widely used, directly influencing citizens` travel habits. Developing smart and efficient travel routes based on big data (possibly multi-modal) has become a central challenge in route recommendation research. Our survey offers a comprehensive review of route recommendation work based on urban computing. It is organized by the following three parts: 1) Methodology-wise. We categorize a large volume of traditional machine learning and modern deep learning methods. Also, we discuss their historical relations and reveal the edge-cutting progress. 2) Application\-wise. We present numerous novel applications related to route commendation within urban computing scenarios. 3) We di
    
[^38]: 基于云的MRI分割联邦学习框架

    Cloud-based Federated Learning Framework for MRI Segmentation

    [https://arxiv.org/abs/2403.00254](https://arxiv.org/abs/2403.00254)

    提出了一个针对农村医疗环境的脑组织分割的新型框架，结合了深度强化学习环境和本地的精调模型，采用联邦学习进行模型训练，以维护数据隐私并增强模型泛化能力。

    

    在当代农村医疗环境中，诊断脑部图像的主要挑战是数据稀缺，因为大多数现有的深度学习模型需要大量的训练数据来优化其性能，这需要中心化处理方法，可能会损害数据隐私。本文提出了一个针对农村医疗设施的脑组织分割的新颖框架。该框架同时使用了深度强化学习（DRL）环境和在农村医疗网站本地部署的精调模型（RM）。所提出的DRL模型具有较少的参数数量，并且适用于在分布式农村站点上实现。为了维护数据隐私并增强模型的泛化能力，我们采用联邦学习（FL）进行合作模型训练。我们通过训练网络来展示我们方法的有效性

    arXiv:2403.00254v1 Announce Type: cross  Abstract: In contemporary rural healthcare settings, the principal challenge in diagnosing brain images is the scarcity of available data, given that most of the existing deep learning models demand extensive training data to optimize their performance, necessitating centralized processing methods that potentially compromise data privacy. This paper proposes a novel framework tailored for brain tissue segmentation in rural healthcare facilities. The framework employs a deep reinforcement learning (DRL) environment in tandem with a refinement model (RM) deployed locally at rural healthcare sites. The proposed DRL model has a reduced parameter count and practicality for implementation across distributed rural sites. To uphold data privacy and enhance model generalization without transgressing privacy constraints, we employ federated learning (FL) for cooperative model training. We demonstrate the efficacy of our approach by training the network wi
    
[^39]: EUROPA：一个法律多语关键词生成数据集

    EUROPA: A Legal Multilingual Keyphrase Generation Dataset

    [https://arxiv.org/abs/2403.00252](https://arxiv.org/abs/2403.00252)

    提出了一个用于法律领域多语关键词生成的数据集EUROPA，包含所有24种欧盟官方语言，表明在特定领域多语言语料库上仍有改进空间。

    

    关键词生成主要在学术研究文章的背景下进行探索，特别侧重于科学领域和英语。 在这项工作中，我们提出了EUROPA，一个用于法律领域多语关键词生成的数据集。 它源自欧洲法院的法律判决，并包含了所有24种欧盟官方语言中的实例。 我们在我们的语料库上运行多语言模型并分析结果，展示了在像我们提出的特定领域多语言语料库上有改进空间。

    arXiv:2403.00252v1 Announce Type: cross  Abstract: Keyphrase generation has primarily been explored within the context of academic research articles, with a particular focus on scientific domains and the English language. In this work, we present EUROPA, a dataset for multilingual keyphrase generation in the legal domain. It is derived from legal judgments from the Court of Justice of the European Union (EU), and contains instances in all 24 EU official languages. We run multilingual models on our corpus and analyze the results, showing room for improvement on a domain-specific multilingual corpus such as the one we present.
    
[^40]: 重新思考长尾识别中的分类器重训练：一种简单的Logits Retargeting方法

    Rethinking Classifier Re-Training in Long-Tailed Recognition: A Simple Logits Retargeting Approach

    [https://arxiv.org/abs/2403.00250](https://arxiv.org/abs/2403.00250)

    在长尾识别中，重新评估了基于统一特征表示的分类器重训练方法，提出了Logits Magnitude作为更佳的性能度量标准。

    

    在长尾识别领域，解耦训练范式在各种方法中展示了显著的能力。该范式将训练过程分解为独立的表示学习和分类器重训练。先前的工作尝试同时改进两个阶段，这使得难以分离分类器重训练的影响。此外，最近的实证研究显示，简单的正则化可以产生强大的特征表示，强调了有必要重新评估现有的分类器重训练方法。在本研究中，我们重新审视基于统一特征表示的分类器重训练方法，并重新评估它们的性能。我们提出了一种称为Logits Magnitude的新度量作为模型性能的优越衡量标准，取代常用的Weight Norm。然而，由于在训练过程中直接优化新度量很难，我们引入了一种适当的方法。

    arXiv:2403.00250v1 Announce Type: cross  Abstract: In the long-tailed recognition field, the Decoupled Training paradigm has demonstrated remarkable capabilities among various methods. This paradigm decouples the training process into separate representation learning and classifier re-training. Previous works have attempted to improve both stages simultaneously, making it difficult to isolate the effect of classifier re-training. Furthermore, recent empirical studies have demonstrated that simple regularization can yield strong feature representations, emphasizing the need to reassess existing classifier re-training methods. In this study, we revisit classifier re-training methods based on a unified feature representation and re-evaluate their performances. We propose a new metric called Logits Magnitude as a superior measure of model performance, replacing the commonly used Weight Norm. However, since it is hard to directly optimize the new metric during training, we introduce a suita
    
[^41]: 使用FlanT5-XXL进行零-shot立场检测的基准测试：从训练数据、提示和解码策略中探讨其接近SOTA的表现

    Benchmarking zero-shot stance detection with FlanT5-XXL: Insights from training data, prompting, and decoding strategies into its near-SoTA performance

    [https://arxiv.org/abs/2403.00236](https://arxiv.org/abs/2403.00236)

    通过使用FlanT5-XXL和SemEval 2016数据集，研究了零-shot立场检测在推特上的性能表现及其对提示和解码策略的敏感性，揭示了其能够匹敌或超越最先进基准测试的能力，并识别了其中的潜在偏见。

    

    我们研究了基于LLM的零-shot立场检测在推特上的表现。使用FlanT5-XXL，一个经过调整指令的开源LLM，在SemEval 2016任务6A、6B和P-Stance数据集上，我们研究了在不同提示和解码策略下的表现及其变化，以及模型的潜在偏见。我们展示零-shot方法可以匹敌甚至胜过最先进的基准测试，包括微调模型。我们提供了对其表现的各种见解，包括对指令和提示的敏感性，解码策略，提示的困惑度，以及提示中存在的否定和反对。最后，我们确保LLM没有在测试数据集上进行训练，并确定了一种可能部分解释解码策略之间表现差异的积极偏见。

    arXiv:2403.00236v1 Announce Type: cross  Abstract: We investigate the performance of LLM-based zero-shot stance detection on tweets. Using FlanT5-XXL, an instruction-tuned open-source LLM, with the SemEval 2016 Tasks 6A, 6B, and P-Stance datasets, we study the performance and its variations under different prompts and decoding strategies, as well as the potential biases of the model. We show that the zero-shot approach can match or outperform state-of-the-art benchmarks, including fine-tuned models. We provide various insights into its performance including the sensitivity to instructions and prompts, the decoding strategies, the perplexity of the prompts, and to negations and oppositions present in prompts. Finally, we ensure that the LLM has not been trained on test datasets, and identify a positivity bias which may partially explain the performance differences across decoding strategie
    
[^42]: AXOLOTL：通过辅助自我去偏见大型语言模型输出实现公平性

    AXOLOTL: Fairness through Assisted Self-Debiasing of Large Language Model Outputs

    [https://arxiv.org/abs/2403.00198](https://arxiv.org/abs/2403.00198)

    AXOLOTL是一个新颖的后处理框架，通过零样本学习的三步过程，识别和解决偏见，指导模型自我去偏见其输出，从而实现公平性并保持模型性能。

    

    预训练的大型语言模型（LLMs）极大地推动了自然语言处理能力，但容易受其训练数据中存在的偏见影响，导致在各种应用中出现不公平结果。尽管已经提出了许多策略来减轻偏见，但它们通常需要大量计算资源，可能会损害模型性能。在这项工作中，我们介绍了AXOLOTL，这是一个新颖的后处理框架，能够独立于任务和模型运行，在不直接访问内部参数的情况下利用公共API与LLMs交互。通过类似零样本学习的三步过程，AXOLOTL识别偏见，提出解决方案，并指导模型自我去偏见其输出。这种方法最小化了计算成本，并保持了模型性能，使AXOLOTL成为一个具有广泛适用性和易用性的去偏见LLM输出的有前景工具。

    arXiv:2403.00198v1 Announce Type: cross  Abstract: Pre-trained Large Language Models (LLMs) have significantly advanced natural language processing capabilities but are susceptible to biases present in their training data, leading to unfair outcomes in various applications. While numerous strategies have been proposed to mitigate bias, they often require extensive computational resources and may compromise model performance. In this work, we introduce AXOLOTL, a novel post-processing framework, which operates agnostically across tasks and models, leveraging public APIs to interact with LLMs without direct access to internal parameters. Through a three-step process resembling zero-shot learning, AXOLOTL identifies biases, proposes resolutions, and guides the model to self-debias its outputs. This approach minimizes computational costs and preserves model performance, making AXOLOTL a promising tool for debiasing LLM outputs with broad applicability and ease of use.
    
[^43]: 利用合成数据增强学习找到缺失视频帧：一个通用框架及在使用RGB摄像头生成热成像中的应用

    Learning to Find Missing Video Frames with Synthetic Data Augmentation: A General Framework and Application in Generating Thermal Images Using RGB Cameras

    [https://arxiv.org/abs/2403.00196](https://arxiv.org/abs/2403.00196)

    通过引入生成模型的方法解决了由于传感器帧率不匹配而导致数据缺失的问题，利用有条件的生成对抗网络（cGANs）中的pix2pix架构比CycleGAN表现更好，多视角输入风格特别是堆叠视图可以增强热图像生成的准确性

    

    高级驾驶辅助系统（ADAS）在智能车辆中依赖于车辆车厢内的准确驾驶员感知，通常利用各种传感模式的结合。然而，这些模式以不同的速率操作，对于实时、全面的驾驶员状态监测提出了挑战。本文解决了由于传感器帧率不匹配导致数据缺失的问题，引入了一种生成模型方法来创建合成但逼真的热成像。我们提出使用有条件的生成对抗网络（cGANs），具体比较了pix2pix和CycleGAN架构。实验结果表明pix2pix优于CycleGAN，并且利用多视角输入风格，特别是堆叠视图，增强了热图像生成的准确性。此外，该研究评估了模型在不同主体之间的泛化能力，揭示了个性化训练对于最佳性能的重要性。

    arXiv:2403.00196v1 Announce Type: cross  Abstract: Advanced Driver Assistance Systems (ADAS) in intelligent vehicles rely on accurate driver perception within the vehicle cabin, often leveraging a combination of sensing modalities. However, these modalities operate at varying rates, posing challenges for real-time, comprehensive driver state monitoring. This paper addresses the issue of missing data due to sensor frame rate mismatches, introducing a generative model approach to create synthetic yet realistic thermal imagery. We propose using conditional generative adversarial networks (cGANs), specifically comparing the pix2pix and CycleGAN architectures. Experimental results demonstrate that pix2pix outperforms CycleGAN, and utilizing multi-view input styles, especially stacked views, enhances the accuracy of thermal image generation. Moreover, the study evaluates the model's generalizability across different subjects, revealing the importance of individualized training for optimal pe
    
[^44]: 基于人工智能方法的信息传播网络重要节点识别

    Identification of important nodes in the information propagation network based on the artificial intelligence method

    [https://arxiv.org/abs/2403.00190](https://arxiv.org/abs/2403.00190)

    该研究提出了一种综合方法，利用先进的人工智能方法来识别信息传播网络中的关键节点，揭示了对网络行为全面的理解，对战略网络分析和优化有重要贡献。

    

    本研究提出了一种综合方法，利用先进的人工智能方法来识别信息传播网络中的关键节点。我们介绍了一种新颖的技术，将决策试验和评估实验室（DEMATEL）方法与全局结构模型（GSM）相结合，创建了一个有效捕捉网络内部局部和全局影响的协同模型。该方法应用于各种复杂网络，如社交、运输和通信系统，利用全球网络影响数据集（GNID）。我们的分析突出了这些网络的结构动态性和韧性，揭示了节点连接性和社区形成方面的见解。研究结果表明，我们基于人工智能的方法在提供对网络行为全面理解方面具有很高的有效性，对于战略网络分析和优化具有重要贡献。

    arXiv:2403.00190v1 Announce Type: cross  Abstract: This study presents an integrated approach for identifying key nodes in information propagation networks using advanced artificial intelligence methods. We introduce a novel technique that combines the Decision-making Trial and Evaluation Laboratory (DEMATEL) method with the Global Structure Model (GSM), creating a synergistic model that effectively captures both local and global influences within a network. This method is applied across various complex networks, such as social, transportation, and communication systems, utilizing the Global Network Influence Dataset (GNID). Our analysis highlights the structural dynamics and resilience of these networks, revealing insights into node connectivity and community formation. The findings demonstrate the effectiveness of our AI-based approach in offering a comprehensive understanding of network behavior, contributing significantly to strategic network analysis and optimization.
    
[^45]: 因果图ODE：多智能体动态系统中的连续处理效应建模

    Causal Graph ODE: Continuous Treatment Effect Modeling in Multi-agent Dynamical Systems

    [https://arxiv.org/abs/2403.00178](https://arxiv.org/abs/2403.00178)

    提出了Causal Graph Ordinary Differential Equations (CAG-ODE) 模型，能够捕捉多智能体系统中处理的连续动态影响，利用图神经网络作为ODE函数。

    

    实际世界中的多智能体系统通常是动态和连续的，其中智能体共同演化，并随时间改变其轨迹和相互作用。例如，美国的COVID-19传播可以看作是一个多智能体系统，其中各州充当智能体，它们之间的日常人口流动就是相互作用。在这种系统中估计反事实结果可以实现准确的未来预测和有效的决策制定，例如制定COVID-19政策。然而，现有方法未能有效地模拟处理对结果的连续动态影响，尤其是当同时应用多种处理（例如“居家隔离”和“接种疫苗”政策）时。为了解决这一挑战，我们提出了因果图普通微分方程（CAG-ODE），这是一种能够使用图神经网络（GNN）作为ODE函数捕捉智能体之间连续相互作用的新颖模型。

    arXiv:2403.00178v1 Announce Type: cross  Abstract: Real-world multi-agent systems are often dynamic and continuous, where the agents co-evolve and undergo changes in their trajectories and interactions over time. For example, the COVID-19 transmission in the U.S. can be viewed as a multi-agent system, where states act as agents and daily population movements between them are interactions. Estimating the counterfactual outcomes in such systems enables accurate future predictions and effective decision-making, such as formulating COVID-19 policies. However, existing methods fail to model the continuous dynamic effects of treatments on the outcome, especially when multiple treatments (e.g., "stay-at-home" and "get-vaccine" policies) are applied simultaneously. To tackle this challenge, we propose Causal Graph Ordinary Differential Equations (CAG-ODE), a novel model that captures the continuous interaction among agents using a Graph Neural Network (GNN) as the ODE function. The key innovat
    
[^46]: SoD$^2$: 静态优化动态深度神经网络

    SoD$^2$: Statically Optimizing Dynamic Deep Neural Network

    [https://arxiv.org/abs/2403.00176](https://arxiv.org/abs/2403.00176)

    本文提出了SoD$^2$框架，用于静态优化动态深度神经网络，通过秩和维度传播（RDP）方法实现了操作符的形状静态确定，进而进行一系列优化，包括融合代码生成、执行计划和运行时内存分配计划生成。

    

    虽然近年来已开发了许多针对DNN的编译和运行时系统，但主要集中在静态DNN上。动态DNN，其中张量形状和大小甚至使用的操作符集取决于输入和/或执行，正在变得常见。本文提出了SoD$^2$，一个用于优化动态DNN的综合框架。我们方法的基础是对构成DNN的常见操作符进行分类，并利用这一分类方法来实现秩和维度传播（RDP）方法。该框架静态确定操作符的形状为已知常量、符号常量或这些操作的运算。接下来，使用RDP我们实现一系列优化，如融合代码生成、执行（顺序）计划，甚至运行时内存分配计划生成。通过在 10 个新兴动态DNN 上评估该框架，并将其与几个现有系统进行比较，我们展示了

    arXiv:2403.00176v1 Announce Type: cross  Abstract: Though many compilation and runtime systems have been developed for DNNs in recent years, the focus has largely been on static DNNs. Dynamic DNNs, where tensor shapes and sizes and even the set of operators used are dependent upon the input and/or execution, are becoming common. This paper presents SoD$^2$, a comprehensive framework for optimizing Dynamic DNNs. The basis of our approach is a classification of common operators that form DNNs, and the use of this classification towards a Rank and Dimension Propagation (RDP) method. This framework statically determines the shapes of operators as known constants, symbolic constants, or operations on these. Next, using RDP we enable a series of optimizations, like fused code generation, execution (order) planning, and even runtime memory allocation plan generation. By evaluating the framework on 10 emerging Dynamic DNNs and comparing it against several existing systems, we demonstrate both 
    
[^47]: FusionVision：使用YOLO和快速分割任意物体的综合方法进行从RGB-D相机重建和分割的3D对象

    FusionVision: A comprehensive approach of 3D object reconstruction and segmentation from RGB-D cameras using YOLO and fast segment anything

    [https://arxiv.org/abs/2403.00175](https://arxiv.org/abs/2403.00175)

    FusionVision提出了一种综合方法，将YOLO和快速分割任何物体的技术整合到RGB-D相机处理中，实现了对3D物体的鲁棒分割

    

    在计算机视觉领域，将先进技术整合到RGB-D相机输入处理中构成了重大挑战，因为环境条件的多样性和物体外观的变化带来了固有的复杂性。因此，本文介绍了FusionVision，一种为在RGB-D图像中鲁棒地进行3D物体分割而调整的详尽管道。传统计算机视觉系统在同时捕捉精确的物体边界并在深度图上实现高精度物体检测方面存在局限，因为它们主要是为RGB摄像机提出的。为了解决这一挑战，FusionVision采用了综合方法，通过将最先进的物体检测技术与先进的实例分割方法相结合。这些组件的整合使得能够对从彩色RGB和深度D信道获得的信息进行全面统一的解释

    arXiv:2403.00175v1 Announce Type: cross  Abstract: In the realm of computer vision, the integration of advanced techniques into the processing of RGB-D camera inputs poses a significant challenge, given the inherent complexities arising from diverse environmental conditions and varying object appearances. Therefore, this paper introduces FusionVision, an exhaustive pipeline adapted for the robust 3D segmentation of objects in RGB-D imagery. Traditional computer vision systems face limitations in simultaneously capturing precise object boundaries and achieving high-precision object detection on depth map as they are mainly proposed for RGB cameras. To address this challenge, FusionVision adopts an integrated approach by merging state-of-the-art object detection techniques, with advanced instance segmentation methods. The integration of these components enables a holistic (unified analysis of information obtained from both color \textit{RGB} and depth \textit{D} channels) interpretation 
    
[^48]: 超越黑盒策略：重新思考可解释和可验证HVAC控制学习代理的设计

    Go Beyond Black-box Policies: Rethinking the Design of Learning Agent for Interpretable and Verifiable HVAC Control

    [https://arxiv.org/abs/2403.00172](https://arxiv.org/abs/2403.00172)

    通过从现有热动力学模型和历史数据提取的决策树重新设计HVAC控制器，克服了可靠性瓶颈，并实现了更节能的策略。

    

    近期的研究表明，基于模型的强化学习（MBRL）有潜力提高暖通空调（HVAC）系统的能效。然而，现有方法依赖于黑盒热动力学模型和随机优化器，缺乏可靠性保证并对居住者健康构成风险。在本工作中，我们通过重新设计使用现有热动力学模型和历史数据提取的决策树的HVAC控制器，克服了可靠性瓶颈。我们的决策树策略是确定性的、可验证的、可解释的，并且比当前的MBRL方法更节能。首先，我们引入了基于领域知识的RL代理在HVAC控制中的新颖验证标准。其次，我们开发了一个生成可验证决策树策略的策略提取过程。我们发现，热动力学模型输入的高维度阻碍了效率。

    arXiv:2403.00172v1 Announce Type: cross  Abstract: Recent research has shown the potential of Model-based Reinforcement Learning (MBRL) to enhance energy efficiency of Heating, Ventilation, and Air Conditioning (HVAC) systems. However, existing methods rely on black-box thermal dynamics models and stochastic optimizers, lacking reliability guarantees and posing risks to occupant health. In this work, we overcome the reliability bottleneck by redesigning HVAC controllers using decision trees extracted from existing thermal dynamics models and historical data. Our decision tree-based policies are deterministic, verifiable, interpretable, and more energy-efficient than current MBRL methods. First, we introduce a novel verification criterion for RL agents in HVAC control based on domain knowledge. Second, we develop a policy extraction procedure that produces a verifiable decision tree policy. We found that the high dimensionality of the thermal dynamics model input hinders the efficiency 
    
[^49]: 政治科学中的LLMs：开启视觉分析新时代

    LLMs in Political Science: Heralding a New Era of Visual Analysis

    [https://arxiv.org/abs/2403.00154](https://arxiv.org/abs/2403.00154)

    本文旨在提高使用Gemini进行政治科学图像内容分析的可行性意识，并展示Gemini在对象检测方面的高准确性。

    

    政治学家中越来越多的人开始利用图像中丰富的信息。然而，解读这些图像的挑战在于需要计算机视觉领域的专业知识和专门硬件的访问。因此，图像分析一直局限于政治科学界中的一小部分人群。由于大型语言模型（LLMs）的崛起，这种情况有可能发生变化。本文旨在提高使用Gemini进行图像内容分析的可行性意识。对688幅图像语料库进行了回顾性分析。对每幅图像从Gemini中获取内容报告，然后由作者手动评估。我们发现Gemini在执行对象检测方面非常准确，这在政治科学中是可能最常见和基本的图像分析任务。同样重要的是，我们展示了使用Gemini进行图像内容分析是简单的。

    arXiv:2403.00154v1 Announce Type: cross  Abstract: Interest is increasing among political scientists in leveraging the extensive information available in images. However, the challenge of interpreting these images lies in the need for specialized knowledge in computer vision and access to specialized hardware. As a result, image analysis has been limited to a relatively small group within the political science community. This landscape could potentially change thanks to the rise of large language models (LLMs). This paper aims to raise awareness of the feasibility of using Gemini for image content analysis. A retrospective analysis was conducted on a corpus of 688 images. Content reports were elicited from Gemini for each image and then manually evaluated by the authors. We find that Gemini is highly accurate in performing object detection, which is arguably the most common and fundamental task in image analysis for political scientists. Equally important, we show that it is easy to im
    
[^50]: EBBS: 一个具有双层束搜索的集成方法用于零翻译机器翻译

    EBBS: An Ensemble with Bi-Level Beam Search for Zero-Shot Machine Translation

    [https://arxiv.org/abs/2403.00144](https://arxiv.org/abs/2403.00144)

    提出了一种集成方法EBBS，配合新颖的双层束搜索算法，能够优于直接和通过第三语言进行的翻译，并实现知识蒸馏来提高推理效率。

    

    当我们用特定的翻译方向训练多语言模型时，零翻译的能力就会出现；模型可以直接在未见过的方向进行翻译。另外，零翻译也可以通过第三种语言（例如英语）来实现。在我们的工作中，我们发现直接和通过第三种语言进行的翻译都存在噪音，并且表现不尽如人意。我们提出了EBBS，一个具有新颖的双层束搜索算法的集成方法，其中每个集成组件在下层逐步探索自己的预测，但它们通过上层的“软投票”机制进行同步。在两个流行的多语言翻译数据集上的结果表明，EBBS始终优于直接和通过第三种语言进行的翻译，以及现有的集成技术。此外，我们可以将集成的知识传回到多语言模型中，以提高推理效率；值得注意的是，我们的E

    arXiv:2403.00144v1 Announce Type: cross  Abstract: The ability of zero-shot translation emerges when we train a multilingual model with certain translation directions; the model can then directly translate in unseen directions. Alternatively, zero-shot translation can be accomplished by pivoting through a third language (e.g., English). In our work, we observe that both direct and pivot translations are noisy and achieve less satisfactory performance. We propose EBBS, an ensemble method with a novel bi-level beam search algorithm, where each ensemble component explores its own prediction step by step at the lower level but they are synchronized by a "soft voting" mechanism at the upper level. Results on two popular multilingual translation datasets show that EBBS consistently outperforms direct and pivot translations as well as existing ensemble techniques. Further, we can distill the ensemble's knowledge back to the multilingual model to improve inference efficiency; profoundly, our E
    
[^51]: 基于集成的无监督不连续成分句法分析：树平均法

    Ensemble-Based Unsupervised Discontinuous Constituency Parsing by Tree Averaging

    [https://arxiv.org/abs/2403.00143](https://arxiv.org/abs/2403.00143)

    通过树平均法构建集成解析器，稳定并提升无监督不连续成分句法分析性能，实验结果表明该方法在所有指标上均优于基准线

    

    我们解决了无监督不连续成分句法分析的问题，在这个问题中我们观察到先前唯一模型的性能存在高方差。我们提出通过对现有不连续解析器的不同运行构建一个集成，并通过平均预测树来稳定和提升性能。首先，我们针对不同的二元性和连续性设置提供了全面的树平均计算复杂度分析（以P和NP完全为单位）。然后，我们开发了一种高效的精确算法来处理这一任务，在我们的实验中对所有样本运行时间均合理。在三个数据集上的结果显示我们的方法在所有指标上均优于所有基准线，我们还对我们的方法进行了深入分析。

    arXiv:2403.00143v1 Announce Type: cross  Abstract: We address unsupervised discontinuous constituency parsing, where we observe a high variance in the performance of the only previous model. We propose to build an ensemble of different runs of the existing discontinuous parser by averaging the predicted trees, to stabilize and boost performance. To begin with, we provide comprehensive computational complexity analysis (in terms of P and NP-complete) for tree averaging under different setups of binarity and continuity. We then develop an efficient exact algorithm to tackle the task, which runs in a reasonable time for all samples in our experiments. Results on three datasets show our method outperforms all baselines in all metrics; we also provide in-depth analyses of our approach.
    
[^52]: EROS：基于实体的受控政策文件摘要

    EROS: Entity-Driven Controlled Policy Document Summarization

    [https://arxiv.org/abs/2403.00141](https://arxiv.org/abs/2403.00141)

    通过使用受控抽象摘要，提出了一种名为EROS的模型，用于显著改善隐私政策文件的可解释性和可读性，强调了包含关键隐私相关实体和组织理由的重要性。

    

    隐私政策文件在向个人介绍组织对用户个人数据的收集、使用和保护方面发挥着关键作用。然而，它们以长篇、复杂和晦涩的语言而闻名，尤其涉及与隐私相关的实体。因此，对试图理解组织数据使用政策的用户构成了重大挑战。本文提出通过使用受控抽象摘要来增强政策文件的可解释性和可读性 -- 我们强制生成的摘要包括关键的隐私相关实体（如数据和媒体）以及组织的理由（如目标和原因）在收集这些实体时。为实现这一目标，我们开发了PD-Sum，一个带有标记的隐私相关实体标签的政策文件摘要数据集。我们提出的模型EROS通过基于跨度的实体提取模型识别关键实体。

    arXiv:2403.00141v1 Announce Type: cross  Abstract: Privacy policy documents have a crucial role in educating individuals about the collection, usage, and protection of users' personal data by organizations. However, they are notorious for their lengthy, complex, and convoluted language especially involving privacy-related entities. Hence, they pose a significant challenge to users who attempt to comprehend organization's data usage policy. In this paper, we propose to enhance the interpretability and readability of policy documents by using controlled abstractive summarization -- we enforce the generated summaries to include critical privacy-related entities (e.g., data and medium) and organization's rationale (e.g.,target and reason) in collecting those entities. To achieve this, we develop PD-Sum, a policy-document summarization dataset with marked privacy-related entity labels. Our proposed model, EROS, identifies critical entities through a span-based entity extraction model and em
    
[^53]: UniTS: 构建统一的时间序列模型

    UniTS: Building a Unified Time Series Model

    [https://arxiv.org/abs/2403.00131](https://arxiv.org/abs/2403.00131)

    UNITS是一种统一的时间序列模型，通过独特的统一网络骨干实现了通用任务规范，并成功支持多种任务，包括分类、预测、插补和异常检测。

    

    基础模型，特别是LLMs，正在深度学习中产生深远影响。我们可以通过少量提示或微调将单个预训练模型适应于许多任务，而不是训练许多特定任务的模型。然而，当前的基础模型适用于序列数据，但不适用于时间序列，因为时间序列具有独特的挑战，包括固有多样性和多领域时间序列数据集，预测、分类和其他类型任务之间的任务规范分歧，以及对任务专用模型的明显需求。我们开发了UNITS，一种支持通用任务规范的统一时间序列模型，可容纳分类、预测、插补和异常检测任务。这是通过一种新颖的统一网络骨干实现的，该骨干结合了序列和变量注意力以及动态线性算子，并作为统一模型进行训练。在38个多领域数据集上，UNITS展示

    arXiv:2403.00131v1 Announce Type: cross  Abstract: Foundation models, especially LLMs, are profoundly transforming deep learning. Instead of training many task-specific models, we can adapt a single pretrained model to many tasks via fewshot prompting or fine-tuning. However, current foundation models apply to sequence data but not to time series, which present unique challenges due to the inherent diverse and multidomain time series datasets, diverging task specifications across forecasting, classification and other types of tasks, and the apparent need for task-specialized models. We developed UNITS, a unified time series model that supports a universal task specification, accommodating classification, forecasting, imputation, and anomaly detection tasks. This is achieved through a novel unified network backbone, which incorporates sequence and variable attention along with a dynamic linear operator and is trained as a unified model. Across 38 multi-domain datasets, UNITS demonstrate
    
[^54]: 具有异构客户的联邦线性上下文赌臂

    Federated Linear Contextual Bandits with Heterogeneous Clients

    [https://arxiv.org/abs/2403.00116](https://arxiv.org/abs/2403.00116)

    提出了一种适用于异构客户的联邦赌臂学习方法，通过在联邦学习设置下为客户进行聚类，实现了非平凡次线性后悔和通信成本的优化

    

    由于分布式系统产生的数据量不断增加，对跨多个代理进行协同和私密的赌臂学习的需求正在增长。联邦赌臂学习已经成为一种有前途的框架，用于私密、高效和去中心化的在线学习。然而，几乎所有先前的工作都依赖于客户同质性的强假设，即所有参与客户都应共享相同的赌臂模型；否则，它们将遭受线性后悔。这严重限制了联邦赌臂学习在实践中的应用。在这项工作中，我们为异构客户引入了一种新的联邦赌臂方法，该方法在联邦学习环境下对客户进行聚类，用于协同赌臂学习。我们提出的算法实现了对所有客户而言的非平凡次线性后悔和通信成本，符合联邦学习中的通信协议，在任何时候只有一个模型

    arXiv:2403.00116v1 Announce Type: cross  Abstract: The demand for collaborative and private bandit learning across multiple agents is surging due to the growing quantity of data generated from distributed systems. Federated bandit learning has emerged as a promising framework for private, efficient, and decentralized online learning. However, almost all previous works rely on strong assumptions of client homogeneity, i.e., all participating clients shall share the same bandit model; otherwise, they all would suffer linear regret. This greatly restricts the application of federated bandit learning in practice. In this work, we introduce a new approach for federated bandits for heterogeneous clients, which clusters clients for collaborative bandit learning under the federated learning setting. Our proposed algorithm achieves non-trivial sub-linear regret and communication cost for all clients, subject to the communication protocol under federated learning that at anytime only one model c
    
[^55]: 将LoRA作为攻击！在Share-and-Play场景下穿透LLM安全

    LoRA-as-an-Attack! Piercing LLM Safety Under The Share-and-Play Scenario

    [https://arxiv.org/abs/2403.00108](https://arxiv.org/abs/2403.00108)

    LoRA作为攻击者渗透LLM安全，研究探讨了在共享与玩耍场景下可能实现的攻击机会。

    

    对LLMs进行微调对于增强其特定任务的性能并确保模型行为与人类偏好保持一致至关重要。在各种微调方法中，LoRA因其效率和易用性而备受推崇，允许最终用户轻松在开源平台上发布和采用轻量的LoRA模块，以定制其模型以适应不同需求。然而，这种方便的共享与玩耍设置打开了新的攻击面，攻击者可以将LoRA作为攻击者，例如背门注入，并广泛分发对抗性LoRA给社区。这可能导致不利的后果。尽管共享LoRA模块存在巨大的潜在风险，但这一方面尚未得到充分探讨。为了填补这一空白，在本研究中，我们深入探讨了在不断增长的共享与玩耍场景中可能做出的攻击机会。具体而言，我们研究了如何将后门注入LoRA模块并深入探讨。

    arXiv:2403.00108v1 Announce Type: cross  Abstract: Fine-tuning LLMs is crucial to enhancing their task-specific performance and ensuring model behaviors are aligned with human preferences. Among various fine-tuning methods, LoRA is popular for its efficiency and ease to use, allowing end-users to easily post and adopt lightweight LoRA modules on open-source platforms to tailor their model for different customization. However, such a handy share-and-play setting opens up new attack surfaces, that the attacker can render LoRA as an attacker, such as backdoor injection, and widely distribute the adversarial LoRA to the community easily. This can result in detrimental outcomes. Despite the huge potential risks of sharing LoRA modules, this aspect however has not been fully explored. To fill the gap, in this study we thoroughly investigate the attack opportunities enabled in the growing share-and-play scenario. Specifically, we study how to inject backdoor into the LoRA module and dive deep
    
[^56]: 提升大型语言模型的上下文长度泛化能力：共振 RoPE

    Resonance RoPE: Improving Context Length Generalization of Large Language Models

    [https://arxiv.org/abs/2403.00071](https://arxiv.org/abs/2403.00071)

    Resonance RoPE是一种新颖方法，通过调整RoPE特征的插值来缩小训练短-测试长场景下的泛化差距，在不增加额外在线计算成本的情况下显著提高模型性能。

    

    本文针对大型语言模型（LLMs）中的训练短-测试长（TSTL）场景挑战，引入了Rotary Position Embedding（RoPE）技术，解决了在较短序列上预训练的模型在较长序列中遇到位置超出分布（OOD）的困难。我们提出了Resonance RoPE，一种新颖的方法，通过精细调整RoPE特征的插值来缩小TSTL场景中的泛化差距，显著提高了模型性能，而无需额外的在线计算成本。此外，我们提出了PosGen，这是一个新的合成基准，专门针对TSTL场景中的精细行为分析，旨在从长上下文中不断增加的令牌生成困难和识别新令牌位置的挑战中分离出来。我们在合成任务上的实验表明，在应用Resonance RoPE后，Transformer模型可以识别OOD位置。

    arXiv:2403.00071v1 Announce Type: cross  Abstract: This paper addresses the challenge of train-short-test-long (TSTL) scenarios in Large Language Models (LLMs) equipped with Rotary Position Embedding (RoPE), where models pre-trained on shorter sequences face difficulty with out-of-distribution (OOD) token positions in longer sequences. We introduce Resonance RoPE, a novel approach designed to narrow the generalization gap in TSTL scenarios by refining the interpolation of RoPE features for OOD positions, significantly improving the model performance without additional online computational costs. Furthermore, we present PosGen, a new synthetic benchmark specifically designed for fine-grained behavior analysis in TSTL scenarios, aiming to isolate the constantly increasing difficulty of token generation on long contexts from the challenges of recognizing new token positions. Our experiments on synthetic tasks show that after applying Resonance RoPE, Transformers recognize OOD position bet
    
[^57]: 使用样本高效适应对大型语言模型进行自定义以进行代码生成

    SEED: Customize Large Language Models with Sample-Efficient Adaptation for Code Generation

    [https://arxiv.org/abs/2403.00046](https://arxiv.org/abs/2403.00046)

    SEED提出了一种名为Sample-Efficient adaptation with Error-Driven learning的新颖适应方法，利用LLMs产生的错误作为学习机会，从而实现对代码生成任务的高效学习。

    

    虽然大型语言模型（LLMs）在代码生成方面取得了重大进展，但在特定场景下仍然存在困难。这些场景通常需要调整LLMs以满足特定需求，但实际可用的训练数据有限，导致代码生成性能较差。如何有效地调整LLMs以适应新场景并使用更少的训练样本是当前代码生成面临的主要挑战。在本文中，我们提出了一种名为SEED的新颖适应方法，即Sample-Efficient adaptation with Error-Driven learning for code generation。SEED利用LLMs产生的错误作为学习机会，利用错误修订来克服自身缺点，从而实现有效学习。具体而言，SEED涉及识别LLMs生成的错误代码，使用Self-revise进行代码修订，优化模型并迭代地进行适应。

    arXiv:2403.00046v1 Announce Type: cross  Abstract: Although Large Language Models (LLMs) have made significant progress in code generation, they still struggle with code generation tasks in specific scenarios. These scenarios usually necessitate the adaptation of LLMs to fulfill specific needs, but the limited training data available in practice leads to poor code generation performance. How to effectively adapt LLMs to new scenarios with fewer training samples is a major challenge for current code generation. In this paper, we propose a novel adaptation approach named SEED, which stands for Sample-Efficient adaptation with Error-Driven learning for code generation. SEED leverages the errors made by LLMs as learning opportunities, using error revision to overcome its own shortcomings, thus achieving efficient learning. Specifically, SEED involves identifying error code generated by LLMs, employing Self-revise for code revision, optimizing the model with revised code, and iteratively ad
    
[^58]: 通过随机梯度MCMC扩展动态边缘划分模型

    Scaling up Dynamic Edge Partition Models via Stochastic Gradient MCMC

    [https://arxiv.org/abs/2403.00044](https://arxiv.org/abs/2403.00044)

    该论文通过引入Dirichlet先验规范和Dirichlet马尔可夫链构建，扩展了边缘划分模型（EPM）以适应动态环境，并提出了一个简单的Gibbs采样器来处理后验计算。

    

    arXiv:2403.00044v1宣布类型:cross 摘要: 边缘划分模型(EPM)是一种从静态图结构数据中提取重叠社区结构的生成模型。 在EPM中，采用Gamma过程（GaP）先验来推断合适的潜在社区数量，并且每个顶点被赋予一个Gamma分布的正成员向量。 尽管具有许多吸引人的特性，EPM中的推理通常使用马尔可夫链蒙特卡罗（MCMC）方法执行，这阻止了其应用于大规模网络数据。 在本文中，我们通过使用Dirichlet先验规范表示每个顶点的正成员向量来将EPM泛化以考虑动态环境，并通过Dirichlet马尔可夫链构造捕获顶点的时间演变行为。 提出了一种简单实施的Gibbs采样器，使用负二项增强技术执行后验计算。 对于大网络资料

    arXiv:2403.00044v1 Announce Type: cross  Abstract: The edge partition model (EPM) is a generative model for extracting an overlapping community structure from static graph-structured data. In the EPM, the gamma process (GaP) prior is adopted to infer the appropriate number of latent communities, and each vertex is endowed with a gamma distributed positive memberships vector. Despite having many attractive properties, inference in the EPM is typically performed using Markov chain Monte Carlo (MCMC) methods that prevent it from being applied to massive network data. In this paper, we generalize the EPM to account for dynamic enviroment by representing each vertex with a positive memberships vector constructed using Dirichlet prior specification, and capturing the time-evolving behaviour of vertices via a Dirichlet Markov chain construction. A simple-to-implement Gibbs sampler is proposed to perform posterior computation using Negative- Binomial augmentation technique. For large network d
    
[^59]: 通过最优输运实现全局和本地提示的合作，用于联邦学习

    Global and Local Prompts Cooperation via Optimal Transport for Federated Learning

    [https://arxiv.org/abs/2403.00041](https://arxiv.org/abs/2403.00041)

    提出了联邦提示合作 via Optimal Transport（FedOTP）方法，通过最优输运实现全局和本地提示的合作，针对数据异质性设计了高效的协作提示学习策略。

    

    预训练的视觉-语言模型中的提示学习在各种下游任务中表现出了卓越的灵活性。最近的研究尝试将这种强大的预训练模型整合到联邦学习框架中，以同时降低通信成本并促进对数据不足的局部训练。为了应对当前联邦提示学习方法在系统化解决严重的数据异质性方面的不足，即涉及标签和特征转移的数据分布，我们提出了通过最优输运实现联邦提示合作（FedOTP），它引入了高效的协作提示学习策略，以在每个客户端基础上捕捉不同的类别特征。具体而言，对于每个客户端，我们学习一个全局提示来提取客户端之间的共识知识，还学习一个本地提示来捕获特定客户端的特征。

    arXiv:2403.00041v1 Announce Type: cross  Abstract: Prompt learning in pretrained visual-language models has shown remarkable flexibility across various downstream tasks. Leveraging its inherent lightweight nature, recent research attempted to integrate the powerful pretrained models into federated learning frameworks to simultaneously reduce communication costs and promote local training on insufficient data. Despite these efforts, current federated prompt learning methods lack specialized designs to systematically address severe data heterogeneities, e.g., data distribution with both label and feature shifts involved. To address this challenge, we present Federated Prompts Cooperation via Optimal Transport (FedOTP), which introduces efficient collaborative prompt learning strategies to capture diverse category traits on a per-client basis. Specifically, for each client, we learn a global prompt to extract consensus knowledge among clients, and a local prompt to capture client-specific
    
[^60]: FhGenie：一款专为公司和科研使用定制的保密聊天人工智能

    FhGenie: A Custom, Confidentiality-preserving Chat AI for Corporate and Scientific Use

    [https://arxiv.org/abs/2403.00039](https://arxiv.org/abs/2403.00039)

    FhGenie是一款专为确保保密性而定制的聊天人工智能，可以帮助知识工作者提高生产力，成为其他组织效仿的先驱。

    

    自从OpenAI发布了ChatGPT以来，生成式人工智能在各个领域受到了重视。这些基于AI的聊天系统有潜力提升知识工作者在各种任务中的生产力。然而，使用免费公共服务存在数据泄露的风险，因为服务提供商可能会在没有明确界限的情况下利用用户输入进行额外训练和优化。即使是基于订阅的替代方案有时也缺乏处理用户数据的透明度。为了解决这些问题并让Fraunhofer员工在确保保密性的同时利用这项技术，我们设计并开发了一款定制的聊天人工智能称为FhGenie（genie指的是一种有益的精灵）。在发布几天后，成千上万的Fraunhofer员工开始使用这项服务。作为在实施这样的系统方面的先驱，许多其他组织也纷纷效仿。我们的解决方案是基于商业大型语

    arXiv:2403.00039v1 Announce Type: cross  Abstract: Since OpenAI's release of ChatGPT, generative AI has received significant attention across various domains. These AI-based chat systems have the potential to enhance the productivity of knowledge workers in diverse tasks. However, the use of free public services poses a risk of data leakage, as service providers may exploit user input for additional training and optimization without clear boundaries. Even subscription-based alternatives sometimes lack transparency in handling user data. To address these concerns and enable Fraunhofer staff to leverage this technology while ensuring confidentiality, we have designed and developed a customized chat AI called FhGenie (genie being a reference to a helpful spirit). Within few days of its release, thousands of Fraunhofer employees started using this service. As pioneers in implementing such a system, many other organizations have followed suit. Our solution builds upon commercial large langu
    
[^61]: 未来发展：社交媒体上看不见事件的适应性假新闻检测

    Evolving to the Future: Unseen Event Adaptive Fake News Detection on Social Media

    [https://arxiv.org/abs/2403.00037](https://arxiv.org/abs/2403.00037)

    提出了面向未知事件的适应性假新闻检测框架FADE，通过自适应增强和图对比学习训练目标预测器，同时独立训练事件预测器，最终减轻事件偏见。

    

    随着社交媒体的快速发展，假新闻在社交媒体上的广泛传播日益威胁个人和社会。在社交媒体动态环境中，假新闻检测旨在开发一个模型，该模型在新闻报道过去事件的基础上进行训练。目标是预测和识别有关未来事件的假新闻，这些事件通常与过去完全不同。然而，现有的假新闻检测方法存在鲁棒性不足，无法泛化到看不见的事件。为了解决这个问题，我们引入了基于未来自适应事件的假新闻检测（FADE）框架。具体来说，我们通过自适应增强策略和图对比学习训练目标预测器，以进行更稳健的整体预测。同时，我们独立训练一个仅事件的预测器以获得有偏见的预测。然后，我们通过获得最终预测来进一步减轻事件偏见。

    arXiv:2403.00037v1 Announce Type: cross  Abstract: With the rapid development of social media, the wide dissemination of fake news on social media is increasingly threatening both individuals and society. In the dynamic landscape of social media, fake news detection aims to develop a model trained on news reporting past events. The objective is to predict and identify fake news about future events, which often relate to subjects entirely different from those in the past. However, existing fake detection methods exhibit a lack of robustness and cannot generalize to unseen events. To address this, we introduce Future ADaptive Event-based Fake news Detection (FADE) framework. Specifically, we train a target predictor through an adaptive augmentation strategy and graph contrastive learning to make more robust overall predictions. Simultaneously, we independently train an event-only predictor to obtain biased predictions. Then we further mitigate event bias by obtaining the final prediction
    
[^62]: 影响Bandits：用于形塑偏好的手臂选择

    Influencing Bandits: Arm Selection for Preference Shaping

    [https://arxiv.org/abs/2403.00036](https://arxiv.org/abs/2403.00036)

    该论文考虑了在非静态多臂赌博机中，通过观察奖励来积极和消极地强化人群偏好，并提出了用于最大化支持预定手臂的人口比例的算法。对于不同意见动态，提出了不同的策略并分析了后悔，最后讨论了多个推荐系统共存的情况。

    

    我们考虑一个非静态多臂赌博机，在这其中人群的偏好受到观察到的奖励的积极和消极强化。算法的目标是塑造人群的偏好，以最大化支持预定手臂的人口比例。对于二元意见的情况，考虑了两种意见动态 -- 递减弹性（建模为具有增加球数的Polya采样）和常量弹性（使用投票者模型）。对于第一种情况，我们描述了一种探索-然后-承诺策略和一种Thompson采样策略，并分析了每种策略的后悔。然后，我们展示了这些算法及其分析可推广到常弹性情况。我们还描述了一种基于Thompson采样的算法，用于当存在两种以上类型的意见情况。最后，我们讨论了存在多个推荐系统的情况引发的情况。

    arXiv:2403.00036v1 Announce Type: cross  Abstract: We consider a non stationary multi-armed bandit in which the population preferences are positively and negatively reinforced by the observed rewards. The objective of the algorithm is to shape the population preferences to maximize the fraction of the population favouring a predetermined arm. For the case of binary opinions, two types of opinion dynamics are considered -- decreasing elasticity (modeled as a Polya urn with increasing number of balls) and constant elasticity (using the voter model). For the first case, we describe an Explore-then-commit policy and a Thompson sampling policy and analyse the regret for each of these policies. We then show that these algorithms and their analyses carry over to the constant elasticity case. We also describe a Thompson sampling based algorithm for the case when more than two types of opinions are present. Finally, we discuss the case where presence of multiple recommendation systems gives ris
    
[^63]: 时间标记：利用动态影响单事件嵌入模型对引用网络进行建模

    Time to Cite: Modeling Citation Networks using the Dynamic Impact Single-Event Embedding Model

    [https://arxiv.org/abs/2403.00032](https://arxiv.org/abs/2403.00032)

    提出了一个新颖的方法，利用动态影响单事件嵌入模型对引用网络进行建模

    

    理解科学研究的结构和动态，即科学的科学（SciSci），已成为一个重要的研究领域，以解决一些迫在眉睫的问题，包括学者们如何相互作用推进科学发展，学科如何相互关联和演变，以及如何量化和预测研究影响力。研究SciSci的核心是对引用网络的分析。目前已采用了两种著名的建模方法：一种是使用参数分布评估论文的引用影响动态，另一种是将引用网络嵌入到潜在空间中，以最佳方式表征论文之间的静态关系，从而衡量其引用。有趣的是，引用网络是动态单事件网络的一个明显示例，即每个配对仅有一个事件（即引用的时间点）。我们目前提出了一种新颖的似然函数

    arXiv:2403.00032v1 Announce Type: cross  Abstract: Understanding the structure and dynamics of scientific research, i.e., the science of science (SciSci), has become an important area of research in order to address imminent questions including how scholars interact to advance science, how disciplines are related and evolve, and how research impact can be quantified and predicted. Central to the study of SciSci has been the analysis of citation networks. Here, two prominent modeling methodologies have been employed: one is to assess the citation impact dynamics of papers using parametric distributions, and the other is to embed the citation networks in a latent space optimal for characterizing the static relations between papers in terms of their citations. Interestingly, citation networks are a prominent example of single-event dynamic networks, i.e., networks for which each dyad only has a single event (i.e., the point in time of citation). We presently propose a novel likelihood fun
    
[^64]: GraphPub: 具有高可用性的差分隐私图生成

    GraphPub: Generation of Differential Privacy Graph with High Availability

    [https://arxiv.org/abs/2403.00030](https://arxiv.org/abs/2403.00030)

    提出了一种名为GraphPub的新型图边保护框架，通过反向学习和编码器-解码器机制，在保护图拓扑结构的同时保证数据的可用性基本不变。

    

    近年来，随着图神经网络（GNN）的快速发展，越来越多的图数据集被用于GNN任务。然而，当上游数据所有者发布图数据时，往往会存在许多隐私问题，因为许多现实世界的图数据包含像个人的朋友列表等敏感信息。差分隐私（DP）是一种常用的保护隐私的方法，但由于图数据的复杂拓扑结构，将DP应用在图上往往会影响GNN模型的消息传递和聚合，导致模型准确性下降。本文提出了一种新颖的图边保护框架GraphPub，可以保护图拓扑结构同时确保数据的可用性基本不变。通过反向学习和编码器-解码器机制，我们搜索一些对节点特征聚合没有太大负面影响的虚假边。

    arXiv:2403.00030v1 Announce Type: cross  Abstract: In recent years, with the rapid development of graph neural networks (GNN), more and more graph datasets have been published for GNN tasks. However, when an upstream data owner publishes graph data, there are often many privacy concerns, because many real-world graph data contain sensitive information like person's friend list. Differential privacy (DP) is a common method to protect privacy, but due to the complex topological structure of graph data, applying DP on graphs often affects the message passing and aggregation of GNN models, leading to a decrease in model accuracy. In this paper, we propose a novel graph edge protection framework, graph publisher (GraphPub), which can protect graph topology while ensuring that the availability of data is basically unchanged. Through reverse learning and the encoder-decoder mechanism, we search for some false edges that do not have a large negative impact on the aggregation of node features, 
    
[^65]: 学习交付：蒙特利尔容量车辆路径问题的基础模型

    Learning to Deliver: a Foundation Model for the Montreal Capacitated Vehicle Routing Problem

    [https://arxiv.org/abs/2403.00026](https://arxiv.org/abs/2403.00026)

    提出了蒙特利尔容量车辆路径问题的基础模型（FM-MCVRP），将MCVRP视为类似自然语言处理任务，并利用Transformer架构嵌入大型语言模型框架进行训练。

    

    在本文中，我们提出了蒙特利尔容量车辆路径问题（MCVRP）的基础模型（FM-MCVRP），这是一个新颖的深度学习（DL）模型，用于近似解决一个变体的容量车辆路径问题（CVRP），该问题描述了许多现实世界的应用场景。MCVRP首次由Bengio等人（2021）正式描述，定义在一个固定有限的图上，类似于一个城市。每个MCVRP实例本质上是连接固定图中随机抽样节点的子图，这些节点代表给定日期实际交付问题中潜在地址集合。我们利用这个问题结构，将MCVRP构建成类似的自然语言处理（NLP）任务。具体来说，我们利用Transformer架构嵌入到大型语言模型（LLM）框架中，来训练我们的模型。

    arXiv:2403.00026v1 Announce Type: cross  Abstract: In this paper, we present the Foundation Model for the Montreal Capacitated Vehicle Routing Problem (FM-MCVRP), a novel Deep Learning (DL) model that approximates high-quality solutions to a variant of the Capacitated Vehicle Routing Problem (CVRP) that characterizes many real-world applications. The so-called Montreal Capacitated Vehicle Routing Problem (MCVRP), first formally described by Bengio et al. (2021), is defined on a fixed and finite graph, which is analogous to a city. Each MCVRP instance is essentially the sub-graph connecting a randomly sampled subset of the nodes in the fixed graph, which represent a set of potential addresses in a real-world delivery problem on a given day. Our work exploits this problem structure to frame the MCVRP as an analogous Natural Language Processing (NLP) task. Specifically, we leverage a Transformer architecture embedded in a Large Language Model (LLM) framework to train our model in a superv
    
[^66]: 关于生成人工智能中的挑战与机遇

    On the Challenges and Opportunities in Generative AI

    [https://arxiv.org/abs/2403.00025](https://arxiv.org/abs/2403.00025)

    现代生成人工智能范例中存在关键的未解决挑战，如何解决这些挑战将进一步增强它们的能力、多功能性和可靠性，并为研究方向提供有价值的见解。

    

    深度生成建模领域近年来增长迅速而稳定。随着海量训练数据的可用性以及可扩展的无监督学习范式的进步，最近的大规模生成模型展现出合成高分辨率图像和文本以及结构化数据（如视频和分子）的巨大潜力。然而，我们认为当前大规模生成人工智能模型没有充分解决若干基本问题，限制了它们在各个领域的广泛应用。在本工作中，我们旨在确定现代生成人工智能范例中的关键未解决挑战，以进一步增强它们的能力、多功能性和可靠性。通过识别这些挑战，我们旨在为研究人员提供有价值的见解，探索有益的研究方向，从而促进更加强大和可访问的生成人工智能的发展。

    arXiv:2403.00025v1 Announce Type: cross  Abstract: The field of deep generative modeling has grown rapidly and consistently over the years. With the availability of massive amounts of training data coupled with advances in scalable unsupervised learning paradigms, recent large-scale generative models show tremendous promise in synthesizing high-resolution images and text, as well as structured data such as videos and molecules. However, we argue that current large-scale generative AI models do not sufficiently address several fundamental issues that hinder their widespread adoption across domains. In this work, we aim to identify key unresolved challenges in modern generative AI paradigms that should be tackled to further enhance their capabilities, versatility, and reliability. By identifying these challenges, we aim to provide researchers with valuable insights for exploring fruitful research directions, thereby fostering the development of more robust and accessible generative AI so
    
[^67]: 具有基于属性的差分隐私的可审计同态协作人工智能

    Auditable Homomorphic-based Decentralized Collaborative AI with Attribute-based Differential Privacy

    [https://arxiv.org/abs/2403.00023](https://arxiv.org/abs/2403.00023)

    提出了一种名为AerisAI的可审计同态协作人工智能框架，利用同态加密和细粒度差分隐私提高安全性，通过基于区块链的智能合约直接聚合加密参数，消除了对于模型性能的负面影响

    

    在最近几年，联邦学习（FL）的概念引领了具有隐私保护的分布式人工智能（AI）新范式。然而，大多数当前的FL系统因为需要受信任的第三方而存在数据隐私问题。尽管一些先前的工作引入差分隐私来保护数据，但这可能会显著恶化模型性能。为了解决这些问题，我们提出了一种新颖的去中心化协作AI框架，名为具有基于同态加密和细粒度差分隐私的可审计的分布式协作AI（AerisAI）。我们提出的AerisAI直接使用基于区块链的智能合约来聚合加密参数，摆脱了需要受信任的第三方的需求。我们还提出了一个全新的概念，用于消除差分隐私对于模型性能的负面影响。

    arXiv:2403.00023v1 Announce Type: cross  Abstract: In recent years, the notion of federated learning (FL) has led to the new paradigm of distributed artificial intelligence (AI) with privacy preservation. However, most current FL systems suffer from data privacy issues due to the requirement of a trusted third party. Although some previous works introduce differential privacy to protect the data, however, it may also significantly deteriorate the model performance. To address these issues, we propose a novel decentralized collaborative AI framework, named Auditable Homomorphic-based Decentralised Collaborative AI (AerisAI), to improve security with homomorphic encryption and fine-grained differential privacy. Our proposed AerisAI directly aggregates the encrypted parameters with a blockchain-based smart contract to get rid of the need of a trusted third party. We also propose a brand-new concept for eliminating the negative impacts of differential privacy for model performance. Moreove
    
[^68]: 朝着解释多目标特征关联的方向

    Towards Interpreting Multi-Objective Feature Associations

    [https://arxiv.org/abs/2403.00017](https://arxiv.org/abs/2403.00017)

    提出一种使用多标签的客观特征交互设计，结合全局敏感性分析，以在农业环境中找到最佳组合的新方法。

    

    理解多个特征如何相关并对特定目标的贡献是与理解每个特征如何对特定结果贡献同等重要的。在预测中解释单个特征可以通过多种方式处理；然而，在多目标预测中，难以获得特征值组合的可解释性。为了解决这个问题，我们提出了一种使用多标签的客观特征交互设计，以找到农业环境中特征的最佳组合。该设计的一项新颖之处是确定了一种方法，该方法将特征解释与全局敏感性分析相结合，以确保在多目标环境中进行组合优化。我们在初步实验中证明，可以找到近似的特征值组合以实现期望的结果，该结果使用了两个农业数据集。

    arXiv:2403.00017v1 Announce Type: cross  Abstract: Understanding how multiple features are associated and contribute to a specific objective is as important as understanding how each feature contributes to a particular outcome. Interpretability of a single feature in a prediction may be handled in multiple ways; however, in a multi-objective prediction, it is difficult to obtain interpretability of a combination of feature values. To address this issue, we propose an objective specific feature interaction design using multi-labels to find the optimal combination of features in agricultural settings. One of the novel aspects of this design is the identification of a method that integrates feature explanations with global sensitivity analysis in order to ensure combinatorial optimization in multi-objective settings. We have demonstrated in our preliminary experiments that an approximate combination of feature values can be found to achieve the desired outcome using two agricultural datas
    
[^69]: 面向目标的组合优化的深度敏感性分析

    Deep Sensitivity Analysis for Objective-Oriented Combinatorial Optimization

    [https://arxiv.org/abs/2403.00016](https://arxiv.org/abs/2403.00016)

    本研究提出了一种深度敏感性分析方法，结合神经网络反馈和全局敏感性分析，以在家禽管理中最优化降低多种病原体水平。

    

    饲养环境企业代码：2403.00016v1 公告类型：交叉 摘要：病原体控制是现代家禽养殖的关键方面，对公共健康和生产力都具有重要意义。有效的家禽管理措施可以降低家禽群体中的病原体水平，从而通过降低食源性疾病的风险来促进食品安全。同时，它们通过预防能够迅速传播并影响群体生长、蛋产量和整体健康的传染病来支持动物健康和福利。本研究将寻找最佳管理实践以最小化多种病原体存在视为一个组合优化问题。具体来说，我们将各种管理设置的可能组合建模为一个解决空间，可通过高效探索以识别最优降低病原体水平的配置。该设计融入了一种基于神经网络反馈的方法，结合特征解释和全局敏感性分析，以确保组合优化

    arXiv:2403.00016v1 Announce Type: cross  Abstract: Pathogen control is a critical aspect of modern poultry farming, providing important benefits for both public health and productivity. Effective poultry management measures to reduce pathogen levels in poultry flocks promote food safety by lowering risks of food-borne illnesses. They also support animal health and welfare by preventing infectious diseases that can rapidly spread and impact flock growth, egg production, and overall health. This study frames the search for optimal management practices that minimize the presence of multiple pathogens as a combinatorial optimization problem. Specifically, we model the various possible combinations of management settings as a solution space that can be efficiently explored to identify configurations that optimally reduce pathogen levels. This design incorporates a neural network feedback-based method that combines feature explanations with global sensitivity analysis to ensure combinatorial
    
[^70]: GIN-SD: 通过位置编码和关注融合在图中检测有不完整节点的来源

    GIN-SD: Source Detection in Graphs with Incomplete Nodes via Positional Encoding and Attentive Fusion

    [https://arxiv.org/abs/2403.00014](https://arxiv.org/abs/2403.00014)

    本文提出了GIN-SD框架，通过位置编码和关注融合解决了在图中检测具有不完整节点的来源的挑战。

    

    在图中检测源已经在谣言源识别领域展现出强大的效力。尽管最近的解决方案通过利用深度神经网络提高了性能，但通常要求完整的用户数据。在本文中，我们解决了一个更具挑战性的任务，即通过不完整的用户数据进行谣言源检测，并提出了一个新颖的框架GIN-SD，通过位置编码和关注融合来解决这一挑战。具体来说，我们的方法利用位置嵌入模块来区分不完整的节点，并采用自注意机制来关注具有更大信息传输能力的节点。为了缓解由于源节点和非源节点数量之间显著差异导致的预测偏差，我们还引入了一个类平衡机制。大量实验证实了GIN-SD及其优越性。

    arXiv:2403.00014v1 Announce Type: cross  Abstract: Source detection in graphs has demonstrated robust efficacy in the domain of rumor source identification. Although recent solutions have enhanced performance by leveraging deep neural networks, they often require complete user data. In this paper, we address a more challenging task, rumor source detection with incomplete user data, and propose a novel framework, i.e., Source Detection in Graphs with Incomplete Nodes via Positional Encoding and Attentive Fusion (GIN-SD), to tackle this challenge. Specifically, our approach utilizes a positional embedding module to distinguish nodes that are incomplete and employs a self-attention mechanism to focus on nodes with greater information transmission capacity. To mitigate the prediction bias caused by the significant disparity between the numbers of source and non-source nodes, we also introduce a class-balancing mechanism. Extensive experiments validate the effectiveness of GIN-SD and its su
    
[^71]: 引入基于用户反馈的反事实解释（UFCE）

    Introducing User Feedback-based Counterfactual Explanations (UFCE)

    [https://arxiv.org/abs/2403.00011](https://arxiv.org/abs/2403.00011)

    本研究引入了一种名为基于用户反馈的反事实解释（UFCE）的新方法，旨在解决当前反事实解释算法的局限性，并增强提供的解释的可信度。

    

    机器学习模型在实际应用中被广泛使用。然而，它们的复杂性常常使得解释其决策背后的原因成为具有挑战性的任务。反事实解释（CEs）已经成为可行的解决方案，用于在可解释的人工智能（XAI）中生成可理解的解释。CE提供给用户关于如何通过最小的输入修改实现所期望的结果的可操作信息。然而，当前的CE算法通常在优化变化以避免不期望的结果时在整个特征空间内运行，忽视了对结果的主要贡献者的识别，并忽视了建议变化的实际可行性。在这项研究中，我们介绍了一种新的方法，被命名为基于用户反馈的反事实解释（UFCE），该方法解决了这些限制，并旨在增强对所提供解释的信心。UFCE允许t

    arXiv:2403.00011v1 Announce Type: cross  Abstract: Machine learning models are widely used in real-world applications. However, their complexity makes it often challenging to interpret the rationale behind their decisions. Counterfactual explanations (CEs) have emerged as a viable solution for generating comprehensible explanations in eXplainable Artificial Intelligence (XAI). CE provides actionable information to users on how to achieve the desired outcome with minimal modifications to the input. However, current CE algorithms usually operate within the entire feature space when optimizing changes to turn over an undesired outcome, overlooking the identification of key contributors to the outcome and disregarding the practicality of the suggested changes. In this study, we introduce a novel methodology, that is named as user feedback-based counterfactual explanation (UFCE), which addresses these limitations and aims to bolster confidence in the provided explanations. UFCE allows for t
    
[^72]: TV-TREES：用于神经符号视频推理的多模态蕴涵树

    TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning

    [https://arxiv.org/abs/2402.19467](https://arxiv.org/abs/2402.19467)

    TV-TREES是第一个多模态蕴涵树生成器，通过生成视频直接蕴涵的简单前提与高级结论之间的蕴涵关系树，实现了可解释联合模态推理，并在挑战性的TVQA数据集上展示了最先进的零-shot性能。

    

    在处理电视剪辑等复杂的多模态内容进行问答是一项具有挑战性的任务。这部分是因为当前的视频-语言模型依赖于单模态推理，在处理长输入时性能下降，并且缺乏可解释性。我们提出了TV-TREES，这是第一个多模态蕴涵树生成器。TV-TREES作为一种促进可解释联合模态推理的视频理解方法，通过生成视频直接蕴涵的简单前提与高级结论之间的蕴涵关系树。随后，我们引入了多模态蕴涵树生成任务来评估此类方法的推理质量。我们的方法在具有挑战性的TVQA数据集上的实验结果展示了可解释的、具有最先进零-shot性能的完整视频剪辑，展示了与黑盒方法相比的最佳实践。

    arXiv:2402.19467v1 Announce Type: cross  Abstract: It is challenging to perform question-answering over complex, multimodal content such as television clips. This is in part because current video-language models rely on single-modality reasoning, have lowered performance on long inputs, and lack interpetability. We propose TV-TREES, the first multimodal entailment tree generator. TV-TREES serves as an approach to video understanding that promotes interpretable joint-modality reasoning by producing trees of entailment relationships between simple premises directly entailed by the videos and higher-level conclusions. We then introduce the task of multimodal entailment tree generation to evaluate the reasoning quality of such methods. Our method's experimental results on the challenging TVQA dataset demonstrate intepretable, state-of-the-art zero-shot performance on full video clips, illustrating a best of both worlds contrast to black-box methods.
    
[^73]: $\texttt{COSMIC}$: 相互信息用于任务无关摘要评估

    $\texttt{COSMIC}$: Mutual Information for Task-Agnostic Summarization Evaluation

    [https://arxiv.org/abs/2402.19457](https://arxiv.org/abs/2402.19457)

    $\texttt{COSMIC}$是一种以相互信息为基础的新的摘要评估方法，有效预测下游任务表现，并与人类判断相关性强。竞争性能优于$\texttt{BERTScore}$和$\texttt{ROUGE}$。

    

    评估总结质量存在显著挑战。为此，我们提出了一种新颖的面向任务的评估方法，根据总结器生成对下游任务有用且保留任务结果的摘要能力。我们在理论上建立了这些任务的结果错误概率与源文本和生成摘要之间的相互信息之间的直接关系。我们引入了$\texttt{COSMIC}$作为这一度量的实际实现，展示了它与基于人类判断的度量之间的强相关性，以及它在预测下游任务性能方面的有效性。对已建立的度量如$\texttt{BERTScore}$和$\texttt{ROUGE}$的比较分析凸显了$\texttt{COSMIC}$的竞争性能。

    arXiv:2402.19457v1 Announce Type: cross  Abstract: Assessing the quality of summarizers poses significant challenges. In response, we propose a novel task-oriented evaluation approach that assesses summarizers based on their capacity to produce summaries that are useful for downstream tasks, while preserving task outcomes. We theoretically establish a direct relationship between the resulting error probability of these tasks and the mutual information between source texts and generated summaries. We introduce $\texttt{COSMIC}$ as a practical implementation of this metric, demonstrating its strong correlation with human judgment-based metrics and its effectiveness in predicting downstream task performance. Comparative analyses against established metrics like $\texttt{BERTScore}$ and $\texttt{ROUGE}$ highlight the competitive performance of $\texttt{COSMIC}$.
    
[^74]: PEM：基于原型的高效MaskFormer用于图像分割

    PEM: Prototype-based Efficient MaskFormer for Image Segmentation

    [https://arxiv.org/abs/2402.19422](https://arxiv.org/abs/2402.19422)

    PEM提出了基于原型的高效MaskFormer，通过引入原型交叉注意力和多尺度特征金字塔网络，实现了在多个分割任务中的高效运行。

    

    近期基于transformer的架构在图像分割领域展现出令人印象深刻的结果。由于其灵活性，它们在多个分割任务中获得出色的性能，如语义分割和全景分割，在一个统一的框架下。为了填补这一差距，我们提出了基于原型的高效MaskFormer（PEM），这是一个可以在多个分割任务中运行的高效transformer架构。PEM提出了一种新颖的基于原型的交叉注意力，利用视觉特征的冗余性来限制计算并提高效率而不损害性能。此外，PEM引入了一个高效的多尺度特征金字塔网络，能够提取具有高语义的特征。

    arXiv:2402.19422v1 Announce Type: cross  Abstract: Recent transformer-based architectures have shown impressive results in the field of image segmentation. Thanks to their flexibility, they obtain outstanding performance in multiple segmentation tasks, such as semantic and panoptic, under a single unified framework. To achieve such impressive performance, these architectures employ intensive operations and require substantial computational resources, which are often not available, especially on edge devices. To fill this gap, we propose Prototype-based Efficient MaskFormer (PEM), an efficient transformer-based architecture that can operate in multiple segmentation tasks. PEM proposes a novel prototype-based cross-attention which leverages the redundancy of visual features to restrict the computation and improve the efficiency without harming the performance. In addition, PEM introduces an efficient multi-scale feature pyramid network, capable of extracting features that have high seman
    
[^75]: 超越Dropout：通向可推广图像超分辨率的引人注目解决方案

    Navigating Beyond Dropout: An Intriguing Solution Towards Generalizable Image Super Resolution

    [https://arxiv.org/abs/2402.18929](https://arxiv.org/abs/2402.18929)

    本文探讨了超越Dropout的图像超分辨率新解决方案，提出了一种能够改善模型泛化能力的训练策略，同时避免了Dropout引入的不良副作用。

    

    深度学习近年来在单图像超分辨率（SISR）性能方面取得了巨大进展。尽管大多数现有工作假设了简单且固定的降级模型（比如双三次下采样），但盲SR的研究旨在通过未知降级改进模型的泛化能力。最近，Kong等人首次探讨了使用Dropout进行盲SR更合适的训练策略。尽管这种方法通过减少过拟合确实带来了实质性的泛化改进，但我们认为Dropout同时引入了不良副作用，损害了模型忠实重构细节的能力。我们在论文中展示了理论和实验分析，此外，我们还提出了另一种简单有效的训练策略，通过简单调节模型的一阶和二阶来增强模型的泛化能力。

    arXiv:2402.18929v1 Announce Type: cross  Abstract: Deep learning has led to a dramatic leap on Single Image Super-Resolution (SISR) performances in recent years. %Despite the substantial advancement% While most existing work assumes a simple and fixed degradation model (e.g., bicubic downsampling), the research of Blind SR seeks to improve model generalization ability with unknown degradation. Recently, Kong et al pioneer the investigation of a more suitable training strategy for Blind SR using Dropout. Although such method indeed brings substantial generalization improvements via mitigating overfitting, we argue that Dropout simultaneously introduces undesirable side-effect that compromises model's capacity to faithfully reconstruct fine details. We show both the theoretical and experimental analyses in our paper, and furthermore, we present another easy yet effective training strategy that enhances the generalization ability of the model by simply modulating its first and second-orde
    
[^76]: 机器无法取代人类的心灵

    The Machine Can't Replace the Human Heart

    [https://arxiv.org/abs/2402.18826](https://arxiv.org/abs/2402.18826)

    人工智能和虚拟治疗技术的发展带来了更广泛的接触机会，但在实施中需要平衡效率和同理心，以确保技术始终是由医护人员的智慧指导的辅助工具。

    

    这里是翻译过的论文摘要

    arXiv:2402.18826v1 Announce Type: cross  Abstract: What is the true heart of mental healthcare -- innovation or humanity? Can virtual therapy ever replicate the profound human bonds where healing arises? As artificial intelligence and immersive technologies promise expanded access, safeguards must ensure technologies remain supplementary tools guided by providers' wisdom. Implementation requires nuance balancing efficiency and empathy. If conscious of ethical risks, perhaps AI could restore humanity by automating tasks, giving providers more time to listen. Yet no algorithm can replicate the seat of dignity within. We must ask ourselves: What future has people at its core? One where AI thoughtfully plays a collaborative role? Or where pursuit of progress leaves vulnerability behind? This commentary argues for a balanced approach thoughtfully integrating technology while retaining care's irreplaceable human essence, at the heart of this profoundly human profession. Ultimately, by nurtur
    
[^77]: ICE-SEARCH: 一种基于语言模型驱动的特征选择方法

    ICE-SEARCH: A Language Model-Driven Feature Selection Approach

    [https://arxiv.org/abs/2402.18609](https://arxiv.org/abs/2402.18609)

    ICE-SEARCH是首个将语言模型与进化算法相结合用于特征选择任务的方法，在医学预测分析应用中取得了State-of-the-Art(SOTA)表现。

    

    本研究揭示了In-Context Evolutionary Search (ICE-SEARCH)方法，这是首个将语言模型(LMs)与进化算法相结合用于特征选择(FS)任务的工作，并展示了其在医学预测分析(MPA)应用中的有效性。ICE-SEARCH利用语言模型中固有的交叉和突变能力，在一个进化框架内显着改进特征选择，通过模型的全面世界知识和其适应各种角色的能力。我们对该方法的评估涵盖了三个关键的MPA任务：中风、心血管疾病和糖尿病，在这些任务中ICE-SEARCH在确定医学应用的关键特征方面优于传统的FS方法。ICE-SEARCH在中风预测和糖尿病预测中实现了领先水平；决策随机化ICE-SEARCH在心血管疾病预测中排名为领先水平。我们的结果不仅证明了

    arXiv:2402.18609v1 Announce Type: cross  Abstract: This study unveils the In-Context Evolutionary Search (ICE-SEARCH) method, the first work that melds language models (LMs) with evolutionary algorithms for feature selection (FS) tasks and demonstrates its effectiveness in Medical Predictive Analytics (MPA) applications. ICE-SEARCH harnesses the crossover and mutation capabilities inherent in LMs within an evolutionary framework, significantly improving FS through the model's comprehensive world knowledge and its adaptability to a variety of roles. Our evaluation of this methodology spans three crucial MPA tasks: stroke, cardiovascular disease, and diabetes, where ICE-SEARCH outperforms traditional FS methods in pinpointing essential features for medical applications. ICE-SEARCH achieves State-of-the-Art (SOTA) performance in stroke prediction and diabetes prediction; the Decision-Randomized ICE-SEARCH ranks as SOTA in cardiovascular disease prediction. Our results not only demonstrate
    
[^78]: 想象、初始化和探索：多智能体强化学习中的有效探索方法

    Imagine, Initialize, and Explore: An Effective Exploration Method in Multi-Agent Reinforcement Learning

    [https://arxiv.org/abs/2402.17978](https://arxiv.org/abs/2402.17978)

    提出了一种名为Imagine, Initialize, and Explore (IIE)的新方法，利用变压器模型在复杂场景中实现多智能体的有效探索。

    

    有效的探索对于在复杂协调任务中发现多智能体强化学习（MARL）的最佳策略至关重要。现有方法主要利用内在奖励来实现承诺的探索，或者使用基于角色的学习来分解联合动作空间，而不是直接在整个动作-观察空间中进行集体搜索。然而，在长时间跨度任务中，他们往往面临获取特定联合动作序列以达到成功状态的挑战。为解决这一局限性，我们提出了一种称为Imagine, Initialize, and Explore (IIE)的新方法，为复杂场景中的高效多智能体探索提供了一个有前途的解决方案。IIE利用一个变压器模型来想象智能体如何达到可以影响彼此转移函数的关键状态。然后，在探索阶段之前，我们通过模拟器在这个状态下初始化环境。我们制定了实现这种想象的方法。

    arXiv:2402.17978v1 Announce Type: cross  Abstract: Effective exploration is crucial to discovering optimal strategies for multi-agent reinforcement learning (MARL) in complex coordination tasks. Existing methods mainly utilize intrinsic rewards to enable committed exploration or use role-based learning for decomposing joint action spaces instead of directly conducting a collective search in the entire action-observation space. However, they often face challenges obtaining specific joint action sequences to reach successful states in long-horizon tasks. To address this limitation, we propose Imagine, Initialize, and Explore (IIE), a novel method that offers a promising solution for efficient multi-agent exploration in complex scenarios. IIE employs a transformer model to imagine how the agents reach a critical state that can influence each other's transition functions. Then, we initialize the environment at this state using a simulator before the exploration phase. We formulate the imag
    
[^79]: DrAttack: 提示分解和重构使强大的LLM越狱者

    DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLM Jailbreakers

    [https://arxiv.org/abs/2402.16914](https://arxiv.org/abs/2402.16914)

    将恶意提示分解为独立的子提示使得LLM越狱攻击更难被检测

    

    本文发现将恶意提示分解为独立的子提示能够有效模糊其潜在的恶意意图，使之以片段化、不易检测的形式呈现，从而解决了这些局限性。我们引入了一个用于越狱攻击的自动提示分解和重构框架（DrAttack）。DrAttack包括三个关键组件：(a) 将原始提示进行“分解”为子提示，(b) 通过上下文学习中的语义上相似但隐含的“重构”这些子提示

    arXiv:2402.16914v1 Announce Type: cross  Abstract: The safety alignment of Large Language Models (LLMs) is vulnerable to both manual and automated jailbreak attacks, which adversarially trigger LLMs to output harmful content. However, current methods for jailbreaking LLMs, which nest entire harmful prompts, are not effective at concealing malicious intent and can be easily identified and rejected by well-aligned LLMs. This paper discovers that decomposing a malicious prompt into separated sub-prompts can effectively obscure its underlying malicious intent by presenting it in a fragmented, less detectable form, thereby addressing these limitations. We introduce an automatic prompt \textbf{D}ecomposition and \textbf{R}econstruction framework for jailbreak \textbf{Attack} (DrAttack). DrAttack includes three key components: (a) `Decomposition' of the original prompt into sub-prompts, (b) `Reconstruction' of these sub-prompts implicitly by in-context learning with semantically similar but h
    
[^80]: 基于似然的大型语言模型评估偏差的缓解

    Likelihood-based Mitigation of Evaluation Bias in Large Language Models

    [https://arxiv.org/abs/2402.15987](https://arxiv.org/abs/2402.15987)

    该论文研究了基于大型语言模型（LLM）的评估器中的似然偏差，并提出了一种缓解这种偏差的方法。

    

    大型语言模型(LLMs)被广泛用于评估自然语言生成任务的自动化指标。然而，似然作为衡量LLM对句子可信度的指标，可能会因句子表面差异（如词序和句子结构）而变化。因此，如果将LLMs用于评估，可能存在似然偏差：它们可能会高估具有较高似然性的句子，而低估具有较低似然性的句子。本文对LLM评估器中似然偏差的存在和影响进行了研究。我们还提出了一种缓解似然偏差的方法。我们的方法利用高度偏置的实例作为少样本示例进行上下文学习。我们在评估数据到文本和语法错误纠正任务时的实验结果显示，我们测试的几种LLMs显示出似然偏差。此外，我们提出的方法成功地减轻了这种偏差

    arXiv:2402.15987v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are widely used to evaluate natural language generation tasks as automated metrics. However, the likelihood, a measure of LLM's plausibility for a sentence, can vary due to superficial differences in sentences, such as word order and sentence structure. It is therefore possible that there might be a likelihood bias if LLMs are used for evaluation: they might overrate sentences with higher likelihoods while underrating those with lower likelihoods. In this paper, we investigate the presence and impact of likelihood bias in LLM-based evaluators. We also propose a method to mitigate the likelihood bias. Our method utilizes highly biased instances as few-shot examples for in-context learning. Our experiments in evaluating the data-to-text and grammatical error correction tasks reveal that several LLMs we test display a likelihood bias. Furthermore, our proposed method successfully mitigates this bias, also impr
    
[^81]: 面向空间感知的变压器记忆体用于体验代理

    Spatially-Aware Transformer Memory for Embodied Agents

    [https://arxiv.org/abs/2402.15160](https://arxiv.org/abs/2402.15160)

    本文探讨了利用包含空间信息的面向空间感知变压器模型，以改善记忆利用效率。

    

    情节记忆在各种认知过程中起着至关重要的作用，比如能够在头脑中回忆过去事件的能力。虽然认知科学强调空间上下文在情节记忆的形成和检索中的重要性，但当前实现人工智能系统中情节记忆的主要方法是通过存储时间顺序体验的变压器，这忽略了空间维度。因此，目前尚不清楚如何将基础结构扩展到除了仅有时间顺序之外的空间轴，并由此能够获得哪些好处。为了解决这个问题，本文探讨了利用包含空间信息的面向空间感知变压器模型。这些模型使得可以创建考虑时间和空间维度的场所中心情节记忆。采用这种方法，我们证明记忆利用效率可以得到提高，导致增强

    arXiv:2402.15160v1 Announce Type: cross  Abstract: Episodic memory plays a crucial role in various cognitive processes, such as the ability to mentally recall past events. While cognitive science emphasizes the significance of spatial context in the formation and retrieval of episodic memory, the current primary approach to implementing episodic memory in AI systems is through transformers that store temporally ordered experiences, which overlooks the spatial dimension. As a result, it is unclear how the underlying structure could be extended to incorporate the spatial axis beyond temporal order alone and thereby what benefits can be obtained. To address this, this paper explores the use of Spatially-Aware Transformer models that incorporate spatial information. These models enable the creation of place-centric episodic memory that considers both temporal and spatial dimensions. Adopting this approach, we demonstrate that memory utilization efficiency can be improved, leading to enhanc
    
[^82]: AI增强的头脑写作：探讨LLMs在团体构思中的应用

    AI-Augmented Brainwriting: Investigating the use of LLMs in group ideation

    [https://arxiv.org/abs/2402.14978](https://arxiv.org/abs/2402.14978)

    本文探讨了在团体构思中将LLMs整合到创意过程中的两个方面，并发现将LLMs整合到Brainwriting中可以增强构思过程及其结果，并提供了支持想法评估的证据。

    

    随着生成式人工智能技术（如大型语言模型LLMs）日益普及，对创意工作有着重要的影响。本文探讨了将LLMs整合到创意过程中的两个方面 - 创意生成的分歧阶段以及评估和选择想法的收敛阶段。我们设计了一个协作的团体-AI头脑写作构思框架，将LLM作为一个增强因素融入到团体构思过程中，并评估了创意生成过程和结果解空间。为评估在想法评估过程中使用LLMs的潜力，我们设计了一个评估引擎，并将其与三名专家和六名新手评估者分配的想法评级进行了比较。我们的发现表明，将LLMs整合到头脑写作中可以增强构思过程及其结果。我们还提供了LLMs可以支持想法评估的证据。最后，我们讨论了相关的启示。

    arXiv:2402.14978v1 Announce Type: cross  Abstract: The growing availability of generative AI technologies such as large language models (LLMs) has significant implications for creative work. This paper explores twofold aspects of integrating LLMs into the creative process - the divergence stage of idea generation, and the convergence stage of evaluation and selection of ideas. We devised a collaborative group-AI Brainwriting ideation framework, which incorporated an LLM as an enhancement into the group ideation process, and evaluated the idea generation process and the resulted solution space. To assess the potential of using LLMs in the idea evaluation process, we design an evaluation engine and compared it to idea ratings assigned by three expert and six novice evaluators. Our findings suggest that integrating LLM in Brainwriting could enhance both the ideation process and its outcome. We also provide evidence that LLMs can support idea evaluation. We conclude by discussing implicati
    
[^83]: 名字的含义是什么？审计大型语言模型中的种族和性别偏见

    What's in a Name? Auditing Large Language Models for Race and Gender Bias

    [https://arxiv.org/abs/2402.14875](https://arxiv.org/abs/2402.14875)

    调查发现，大型语言模型存在种族和性别偏见，尤其对与黑人女性相关的名字表现最不利。审计在模型部署和实施时的重要性得到强调。

    

    我们采用审计设计来调查最先进的大型语言模型中的偏见，包括GPT-4。在我们的研究中，我们引发模型在各种情景下为个人提供建议，比如在购车谈判或选举结果预测过程中。我们发现该建议系统性地对与种族少数群体和女性常见相关的名字产生不利影响。与黑人女性相关的名字得到的结果最不利。这些偏见在42个提示模板和多个模型中都是一致的，表明这是一个系统性问题，而不是孤立事件。在提示中提供数值、与决策相关的锚点可以成功抵消偏见，而定性细节的影响并不一致，甚至可能会加剧差异。我们的研究结果强调了在语言模型部署和实施时进行审计的重要性，以减轻其潜在影响。

    arXiv:2402.14875v1 Announce Type: cross  Abstract: We employ an audit design to investigate biases in state-of-the-art large language models, including GPT-4. In our study, we elicit prompt the models for advice regarding an individual across a variety of scenarios, such as during car purchase negotiations or election outcome predictions. We find that the advice systematically disadvantages names that are commonly associated with racial minorities and women. Names associated with Black women receive the least advantageous outcomes. The biases are consistent across 42 prompt templates and several models, indicating a systemic issue rather than isolated incidents. While providing numerical, decision-relevant anchors in the prompt can successfully counteract the biases, qualitative details have inconsistent effects and may even increase disparities. Our findings underscore the importance of conducting audits at the point of LLM deployment and implementation to mitigate their potential for
    
[^84]: 使用GANs生成合成数据延伸与保护——基于时间序列医疗记录

    Protect and Extend -- Using GANs for Synthetic Data Generation of Time-Series Medical Records

    [https://arxiv.org/abs/2402.14042](https://arxiv.org/abs/2402.14042)

    本研究使用GANs生成了时间序列合成痴呆患者医疗记录的数据集，并比较了不同GAN模型在生成合成数据方面的质量，实现了在不涉及隐私问题的情况下保护用户数据并延伸数据应用。

    

    arXiv:2402.14042v1 公告类型:交叉摘要: 保护私人用户数据对于高质量体验(QoE)和可接受性至关重要，尤其是对于处理敏感数据的服务，如基于IT的健康服务。尽管已经显示匿名化技术容易被数据重新识别，但合成数据生成逐渐取代了匿名化，因为它相对耗时和资源耗费较少，并且更能抵抗数据泄漏。生成对抗网络(GANs)已被用于生成合成数据集，特别是遵循差分隐私现象的GAN框架。本研究比较了用于生成时间序列合成痴呆患者医疗记录的最新GAN基模型，这些数据可以在不涉及隐私问题的情况下分发。 预测建模、自相关性和分布分析被用来评估生成数据的生成质量(QoG)。

    arXiv:2402.14042v1 Announce Type: cross  Abstract: Preservation of private user data is of paramount importance for high Quality of Experience (QoE) and acceptability, particularly with services treating sensitive data, such as IT-based health services. Whereas anonymization techniques were shown to be prone to data re-identification, synthetic data generation has gradually replaced anonymization since it is relatively less time and resource-consuming and more robust to data leakage. Generative Adversarial Networks (GANs) have been used for generating synthetic datasets, especially GAN frameworks adhering to the differential privacy phenomena. This research compares state-of-the-art GAN-based models for synthetic data generation to generate time-series synthetic medical records of dementia patients which can be distributed without privacy concerns. Predictive modeling, autocorrelation, and distribution analysis are used to assess the Quality of Generating (QoG) of the generated data. T
    
[^85]: E2USD：用于多元时间序列的高效而有效的无监督状态检测

    E2USD: Efficient-yet-effective Unsupervised State Detection for Multivariate Time Series

    [https://arxiv.org/abs/2402.14041](https://arxiv.org/abs/2402.14041)

    E2USD提出了一种有效的无监督多元时间序列状态检测方法，利用了快速傅里叶变换和双视图嵌入模块进行编码，以及通过对抗学习方法消除假阴性，从而实现了SOTA准确性并显著降低了计算开销。

    

    我们提出了E2USD方法，能够实现高效而准确的无监督多元时间序列状态检测。E2USD利用基于快速傅立叶变换的时间序列压缩器(FFTCompress)和分解的双视图嵌入模块(DDEM)，一起以低计算开销对输入的多元时间序列进行编码。此外，我们提出了一种假阴性取消对比学习方法(FNCCLearning)，以抵消假阴性的影响，并实现更友好的簇嵌入空间。为了在流式设置中进一步减少计算开销，我们引入了自适应阈值检测(ADATD)。通过使用六个基线模型和六个数据集进行全面实验，我们证明E2USD能够在显著降低计算开销的情况下达到SOTA的准确性。我们的代码可在https://github.com/AI4CTS/E2Usd 找到。

    arXiv:2402.14041v1 Announce Type: cross  Abstract: We propose E2USD that enables efficient-yet-accurate unsupervised MTS state detection. E2USD exploits a Fast Fourier Transform-based Time Series Compressor (FFTCompress) and a Decomposed Dual-view Embedding Module (DDEM) that together encode input MTSs at low computational overhead. Additionally, we propose a False Negative Cancellation Contrastive Learning method (FNCCLearning) to counteract the effects of false negatives and to achieve more cluster-friendly embedding spaces. To reduce computational overhead further in streaming settings, we introduce Adaptive Threshold Detection (ADATD). Comprehensive experiments with six baselines and six datasets offer evidence that E2USD is capable of SOTA accuracy at significantly reduced computational overhead. Our code is available at https://github.com/AI4CTS/E2Usd.
    
[^86]: AI对齐在社会技术系统中的激励兼容性：立场与前景

    Incentive Compatibility for AI Alignment in Sociotechnical Systems: Positions and Prospects

    [https://arxiv.org/abs/2402.12907](https://arxiv.org/abs/2402.12907)

    该论文提出了激励兼容性社会技术对齐问题（ICSAP），旨在探讨如何利用博弈论中的激励兼容性原则来维持AI与人类社会的共识。

    

    人工智能（AI）日益融入人类社会，对社会治理和安全带来重要影响。尽管在解决AI对齐挑战方面取得了重大进展，但现有方法主要集中在技术方面，往往忽视了AI系统复杂的社会技术性质，这可能导致开发和部署背景之间的不一致。因此，我们提出一个值得探索的新问题：激励兼容性社会技术对齐问题（ICSAP）。我们希望这能呼吁更多研究人员探讨如何利用博弈论中的激励兼容性原则来弥合技术和社会组成部分之间的鸿沟，以在不同背景下维持AI与人类社会的共识。我们进一步讨论了实现IC的三个经典博弈问题：机制设计、契约理论和贝叶斯说服。

    arXiv:2402.12907v1 Announce Type: new  Abstract: The burgeoning integration of artificial intelligence (AI) into human society brings forth significant implications for societal governance and safety. While considerable strides have been made in addressing AI alignment challenges, existing methodologies primarily focus on technical facets, often neglecting the intricate sociotechnical nature of AI systems, which can lead to a misalignment between the development and deployment contexts. To this end, we posit a new problem worth exploring: Incentive Compatibility Sociotechnical Alignment Problem (ICSAP). We hope this can call for more researchers to explore how to leverage the principles of Incentive Compatibility (IC) from game theory to bridge the gap between technical and societal components to maintain AI consensus with human societies in different contexts. We further discuss three classical game problems for achieving IC: mechanism design, contract theory, and Bayesian persuasion,
    
[^87]: PIP-Net：城市中行人意图预测

    PIP-Net: Pedestrian Intention Prediction in the Wild

    [https://arxiv.org/abs/2402.12810](https://arxiv.org/abs/2402.12810)

    PIP-Net是一个新型框架，通过综合利用动态学数据和场景空间特征，采用循环和时间注意力机制解决方案，成功预测行人通过马路的意图，性能优于现有技术。

    

    精准的自动驾驶车辆（AVs）对行人意图的预测是当前该领域的一项研究挑战。在本文中，我们介绍了PIP-Net，这是一个新颖的框架，旨在预测AVs在现实世界城市场景中的行人过马路意图。我们提供了两种针对不同摄像头安装和设置设计的PIP-Net变种。利用来自行驶场景的动力学数据和空间特征，所提出的模型采用循环和时间注意力机制的解决方案，性能优于现有技术。为了增强道路用户的视觉表示及其与自车的相关性，我们引入了一个分类深度特征图，结合局部运动流特征，为场景动态提供丰富的洞察。此外，我们探讨了将摄像头的视野从一个扩展到围绕自车的三个摄像头的影响，以提升

    arXiv:2402.12810v1 Announce Type: cross  Abstract: Accurate pedestrian intention prediction (PIP) by Autonomous Vehicles (AVs) is one of the current research challenges in this field. In this article, we introduce PIP-Net, a novel framework designed to predict pedestrian crossing intentions by AVs in real-world urban scenarios. We offer two variants of PIP-Net designed for different camera mounts and setups. Leveraging both kinematic data and spatial features from the driving scene, the proposed model employs a recurrent and temporal attention-based solution, outperforming state-of-the-art performance. To enhance the visual representation of road users and their proximity to the ego vehicle, we introduce a categorical depth feature map, combined with a local motion flow feature, providing rich insights into the scene dynamics. Additionally, we explore the impact of expanding the camera's field of view, from one to three cameras surrounding the ego vehicle, leading to enhancement in the
    
[^88]: UFO: 一个专注于Windows操作系统交互的用户界面智能体

    UFO: A UI-Focused Agent for Windows OS Interaction

    [https://arxiv.org/abs/2402.07939](https://arxiv.org/abs/2402.07939)

    UFO是一个专注于Windows操作系统上应用程序的用户界面智能体，利用GPT-Vision的能力来满足用户需求。它通过观察和分析Windows应用程序的图形用户界面和控制信息，实现无缝导航和操作以满足用户的请求。UFO的控制交互模块使得无需人工干预即可实现动作连接和完全自动化执行，使繁琐和耗时的过程变为简单任务。经过测试，UFO在各种场景中取得了良好效果。

    

    我们介绍了UFO，一个创新的专注于Windows操作系统上应用程序的用户界面智能体，利用了GPT-Vision的能力来满足用户需求。UFO采用双智能体框架，精确观察和分析Windows应用程序的图形用户界面（GUI）和控制信息。这使得智能体可以无缝地在单个应用程序内以及跨应用程序进行导航和操作，以满足用户的需求，即使涉及多个应用程序。该框架包括一个控制交互模块，实现无需人工干预的动作连接，并实现完全自动化执行。因此，UFO将艰巨而耗时的过程转变为仅通过自然语言命令就可以完成的简单任务。我们在9个流行的Windows应用程序上对UFO进行了测试，涵盖了反映用户日常使用情景的各种情况。通过定量指标和真实案例研究得出的结果强调了UFO的效果。

    We introduce UFO, an innovative UI-Focused agent to fulfill user requests tailored to applications on Windows OS, harnessing the capabilities of GPT-Vision. UFO employs a dual-agent framework to meticulously observe and analyze the graphical user interface (GUI) and control information of Windows applications. This enables the agent to seamlessly navigate and operate within individual applications and across them to fulfill user requests, even when spanning multiple applications. The framework incorporates a control interaction module, facilitating action grounding without human intervention and enabling fully automated execution. Consequently, UFO transforms arduous and time-consuming processes into simple tasks achievable solely through natural language commands. We conducted testing of UFO across 9 popular Windows applications, encompassing a variety of scenarios reflective of users' daily usage. The results, derived from both quantitative metrics and real-case studies, underscore t
    
[^89]: 探索针对设备上模型的白盒攻击

    Investigating White-Box Attacks for On-Device Models

    [https://arxiv.org/abs/2402.05493](https://arxiv.org/abs/2402.05493)

    本研究探究了针对设备上模型的白盒攻击，提出了一种逆向工程框架(REOM)以将编译后的设备上TFLite模型转换为可调试模型。

    

    许多移动应用程序利用了深度学习的能力。然而，设备上的模型容易受到攻击，因为它们可以从相应的移动应用程序中轻易提取出来。现有的设备上攻击方法只能生成黑盒攻击，这种方法远不如白盒策略有效和高效。这是因为移动深度学习框架如TFLite不支持梯度计算，而梯度计算对于白盒攻击算法是必要的。因此，我们认为现有的发现可能低估了设备上攻击的危害性。为了回答这个研究问题，我们进行了一项研究：设备上的模型是否可以通过白盒策略直接受到攻击？我们首先系统地分析了将设备上模型转换为可调试版本的困难，并提出了一种针对设备上模型的逆向工程框架(REOM)，该框架可以自动将编译后的设备上TFLite模型逆向为可调试模型。具体来说，REOM

    Numerous mobile apps have leveraged deep learning capabilities. However, on-device models are vulnerable to attacks as they can be easily extracted from their corresponding mobile apps. Existing on-device attacking approaches only generate black-box attacks, which are far less effective and efficient than white-box strategies. This is because mobile deep learning frameworks like TFLite do not support gradient computing, which is necessary for white-box attacking algorithms. Thus, we argue that existing findings may underestimate the harmfulness of on-device attacks. To this end, we conduct a study to answer this research question: Can on-device models be directly attacked via white-box strategies? We first systematically analyze the difficulties of transforming the on-device model to its debuggable version, and propose a Reverse Engineering framework for On-device Models (REOM), which automatically reverses the compiled on-device TFLite model to the debuggable model. Specifically, REOM
    
[^90]: 来自在线人工智能反馈的直接语言模型对齐

    Direct Language Model Alignment from Online AI Feedback

    [https://arxiv.org/abs/2402.04792](https://arxiv.org/abs/2402.04792)

    本论文提出了一种名为OAIF的方法，通过在线反馈来改善DAP方法，该方法使用LLM作为标注器，从而在多个任务中展示出优于离线DAP和RLHF的性能

    

    最近，直接对齐偏好（DAP）方法如DPO已成为对于从人类反馈中进行增强学习的高效替代方法，不要求单独的奖励模型。然而，DAP方法中使用的偏好数据集通常在训练之前收集，并且从不更新，因此反馈纯粹是离线的。此外，这些数据集中的回应通常是从一个与被对齐的语言模型不同的语言模型中采样的，由于模型在训练过程中会变化，对齐阶段必然是非策略的。在本研究中，我们认为在线反馈是关键，可以改善DAP方法。我们的方法，在线人工智能反馈（OAIF），使用LLM作为标注器：在每个训练迭代中，我们从当前模型中采样两个回应，并提示LLM标注器选择哪个更受欢迎，从而提供在线反馈。尽管简单，但通过多个任务中的人工评估，我们证明OAIF优于离线DAP和RLHF

    Direct alignment from preferences (DAP) methods, such as DPO, have recently emerged as efficient alternatives to reinforcement learning from human feedback (RLHF), that do not require a separate reward model. However, the preference datasets used in DAP methods are usually collected ahead of training and never updated, thus the feedback is purely offline. Moreover, responses in these datasets are often sampled from a language model distinct from the one being aligned, and since the model evolves over training, the alignment phase is inevitably off-policy. In this study, we posit that online feedback is key and improves DAP methods. Our method, online AI feedback (OAIF), uses an LLM as annotator: on each training iteration, we sample two responses from the current model and prompt the LLM annotator to choose which one is preferred, thus providing online feedback. Despite its simplicity, we demonstrate via human evaluation in several tasks that OAIF outperforms both offline DAP and RLHF 
    
[^91]: 大型语言模型作为MOOCs评分者

    Large Language Models As MOOCs Graders

    [https://arxiv.org/abs/2402.03776](https://arxiv.org/abs/2402.03776)

    该研究探索了利用大型语言模型（LLMs）代替MOOCs中同伴评分的可行性，旨在解决大规模在线开放课程中评估学生写作任务的问题。

    

    大规模在线开放课程（MOOCs）为拥有电脑和互联网访问权限的全球任何人提供免费教育的机会。尽管如此，这些课程的大规模注册意味着一位教师几乎不可能评估每个学生的写作任务。因此，同伴评分通常是首选方法，通常由简单明了的评分标准指导。然而，同伴评分在可靠度和有效性方面常常存在问题。在这项研究中，我们利用18个不同的场景，探索利用大型语言模型（LLMs）替代MOOCs中的同伴评分的可行性。具体而言，我们关注两种最先进的LLMs：GPT-4和GPT-3.5，并涵盖三门不同的课程：入门天文学，天体生物学以及天文学的历史与哲学。为了训练LLMs，我们使用了基于零-shot连续思考（Zero-shot-CoT）提示技术的变种的三个不同提示：结合Zero-shot-CoT的提示。

    Massive open online courses (MOOCs) unlock the doors to free education for anyone around the globe with access to a computer and the internet. Despite this democratization of learning, the massive enrollment in these courses means it is almost impossible for one instructor to assess every student's writing assignment. As a result, peer grading, often guided by a straightforward rubric, is the method of choice. While convenient, peer grading often falls short in terms of reliability and validity. In this study, using 18 distinct settings, we explore the feasibility of leveraging large language models (LLMs) to replace peer grading in MOOCs. Specifically, we focus on two state-of-the-art LLMs: GPT-4 and GPT-3.5, across three distinct courses: Introductory Astronomy, Astrobiology, and the History and Philosophy of Astronomy. To instruct LLMs, we use three different prompts based on a variant of the zero-shot chain-of-thought (Zero-shot-CoT) prompting technique: Zero-shot-CoT combined with
    
[^92]: 从推理路径聚合的角度理解语言模型的推理能力

    Understanding the Reasoning Ability of Language Models From the Perspective of Reasoning Paths Aggregation

    [https://arxiv.org/abs/2402.03268](https://arxiv.org/abs/2402.03268)

    本文研究了预训练语言模型的推理能力，并提出了从聚合间接推理路径的角度理解语言模型如何产生推理能力。通过对知识图谱和数学问题数据集进行实验和分析，发现增加无标签的随机游走推理路径可以提高实际应用中的多步推理能力。

    

    预训练的语言模型能够在没有明确微调的情况下执行复杂的推理。为了理解预训练与下一个标记预测目标的关系如何促使推理能力的出现，我们提出可以将语言模型视为在预训练时通过聚合间接的推理路径来得出新结论。我们发现，这个视角在逻辑推理和数学推理等关键情况下非常有效。具体而言，我们将推理路径形式化为在知识/推理图上的随机游走路径。对学习的语言模型分布的分析表明，相关随机游走路径概率的加权和是解释语言模型推理的合理方式。对多个知识图谱和数学问题数据集进行的实验和分析揭示了训练对随机游走路径的影响，并表明增加无标签的随机游走推理路径可以提高现实世界的多步推理能力。

    Pre-trained language models (LMs) are able to perform complex reasoning without explicit fine-tuning. To understand how pre-training with a next-token prediction objective contributes to the emergence of such reasoning capability, we propose that we can view an LM as deriving new conclusions by aggregating indirect reasoning paths seen at pre-training time. We found this perspective effective in two important cases of reasoning: logic reasoning with knowledge graphs (KGs) and math reasoning with math word problems (MWPs). More specifically, we formalize the reasoning paths as random walk paths on the knowledge/reasoning graphs. Analyses of learned LM distributions suggest that a weighted sum of relevant random walk path probabilities is a reasonable way to explain how LMs reason. Experiments and analysis on multiple KG and MWP datasets reveal the effect of training on random walk paths and suggest that augmenting unlabeled random walk reasoning paths can improve real-world multi-step r
    
[^93]: 链式反馈：缓解回答不一致性的影响

    Chain-of-Feedback: Mitigating the Effects of Inconsistency in Responses

    [https://arxiv.org/abs/2402.02648](https://arxiv.org/abs/2402.02648)

    本文提出了链式反馈（CoF）方法，以缓解大型语言模型在回答问题中出现不一致性的问题。同时，作者还提出了递归链式反馈（R-CoF）方法，并提到了进一步的研究。这些方法可以提高回答的可靠性和有效性。

    

    大型语言模型（LLMs）在回答知识密集型问题时经常出现不一致的情况，即使输入相同，也会提供不同的输出。当用户表达坚决相反的立场时，LLMs调整其回答的质量会变差，尽管初始回答是正确的。这些行为降低了这些模型提供的回答的可靠性和有效性。在本文中，我们试图：1）通过展示链式反馈（CoF）如何导致LLMs更加偏离实际答案，引起过度依赖ChatGPT等AI代理带来的固有风险；2）提出一种新的提示方法，递归链式反馈（R-CoF），我们正在进行进一步研究。CoF系统接收一个开放式多步问题，然后我们重复提供无意义的反馈，要求再次尝试。我们的初步实验表明，这种反馈只会降低回答的质量。另一方面，

    Large Language Models (LLMs) frequently suffer from knowledge-intensive questions, often being inconsistent by providing different outputs despite given the same input. The response quality worsens when the user expresses a firm opposing stance which causes the LLMs to adjust its response despite the correct initial one. These behaviors decrease the reliability and validity of the responses provided by these models. In this paper, we attempt to 1) raise awareness of the inherent risks that follow from overly relying on AI agents like ChatGPT by showing how Chain-of-Feedback (CoF) triggers LLMs to deviate more from the actual answer and 2) suggest a novel prompting method, Recursive Chain of Feedback (R-CoF), that we are conducting further study. The CoF system takes in an open-ended multi-step question. Then, we repetitively provide meaningless feedback requesting another attempt. Our preliminary experiments show that such feedback only decreases the quality of the response. On the oth
    
[^94]: 通过期望分区函数和连续优化设计信使RNA

    Messenger RNA Design via Expected Partition Function and Continuous Optimization

    [https://arxiv.org/abs/2401.00037](https://arxiv.org/abs/2401.00037)

    将RNA设计问题转化为连续优化，并提出了基于期望分区函数的通用优化框架，将候选序列的分布逐步优化为单一序列。

    

    RNA设计的任务是离散优化问题，有几个版本的这些问题是NP难题。为了替代常用的局部搜索方法，我们将这些问题表述为连续优化，并基于一种称为"期望分区函数"的经典分区函数的泛化开发了一个通用框架。基本思想是从所有可能的候选序列中开始一个分布，并将目标函数从一个序列扩展到一个分布。然后我们使用基于梯度下降的优化方法改善扩展的目标函数，分布将逐渐收缩到一个独热序列（即一个序列）。作为案例研究，我们考虑了在疫苗和治疗领域有着广泛应用的mRNA设计的重要问题。

    arXiv:2401.00037v2 Announce Type: replace-cross  Abstract: The tasks of designing RNAs are discrete optimization problems, and several versions of these problems are NP-hard. As an alternative to commonly used local search methods, we formulate these problems as continuous optimization and develop a general framework for this optimization based on a generalization of classical partition function which we call "expected partition function". The basic idea is to start with a distribution over all possible candidate sequences, and extend the objective function from a sequence to a distribution. We then use gradient descent-based optimization methods to improve the extended objective function, and the distribution will gradually shrink towards a one-hot sequence (i.e., a single sequence). As a case study, we consider the important problem of mRNA design with wide applications in vaccines and therapeutics. While the recent work of LinearDesign can efficiently optimize mRNAs for minimum free
    
[^95]: 实现端到端人工智能驱动的全球天气预报系统

    Towards an end-to-end artificial intelligence driven global weather forecasting system

    [https://arxiv.org/abs/2312.12462](https://arxiv.org/abs/2312.12462)

    提出了一种端到端基于人工智能的全球天气预报系统，通过将AI技术应用于数据同化和天气预报模型，实现了从数据处理到预测全过程的自动化。

    

    天气预报系统对科学和社会至关重要，在将人工智能（AI）应用于中期天气预报方面取得了重大成就。然而，现有的基于AI的天气预报模型依赖于传统数值天气预报（NWP）系统的分析或再分析产品作为预测的初始条件。初始状态通常由传统数据同化组件生成，这是计算昂贵且耗时。本文提出了一种基于AI的数据同化模型，即Adas，用于全球天气变量。我们将Adas与先进的基于AI的天气预报模型（即FengWu）结合起来，构建了第一个端到端基于AI的全球天气预报系统：FengWu-Adas。我们证明了Adas能够同化稀疏的全球观测数据，产生高质量的分析结果，使系统能够稳定运行。

    arXiv:2312.12462v2 Announce Type: replace-cross  Abstract: The weather forecasting system is important for science and society, and significant achievements have been made in applying artificial intelligence (AI) to medium-range weather forecasting. However, existing AI-based weather forecasting models rely on analysis or reanalysis products from the traditional numerical weather prediction (NWP) systems as initial conditions for making predictions. Initial states are typically generated by traditional data assimilation component, which is computational expensive and time-consuming. Here we present an AI-based data assimilation model, i.e., Adas, for global weather variables. And we combine Adas with the advanced AI-based weather forecasting model (i.e., FengWu) to construct the first end-to-end AI-based global weather forecasting system: FengWu-Adas. We demonstrate that Adas can assimilate sparse global observations to produce high-quality analysis, enabling the system operate stably 
    
[^96]: LatestEval: 通过动态和时间敏感的测试构建解决语言模型评估中的数据污染问题

    LatestEval: Addressing Data Contamination in Language Model Evaluation through Dynamic and Time-Sensitive Test Construction

    [https://arxiv.org/abs/2312.12343](https://arxiv.org/abs/2312.12343)

    LatestEval提出了一种自动方法，通过动态和时间敏感的测试构建不受数据污染的阅读理解评估，避免了使用预先训练语言模型的训练语料库，从而鼓励模型更好地推断答案。

    

    随着预先在超大规模自动抓取语料库上进行训练的语言模型的出现，评估中的数据污染越来越普遍。这个问题导致在准确评估模型能力和泛化能力方面存在重大挑战。在本文中，我们提出了LatestEval，这是一种自动方法，利用最近的文本创建不受污染的阅读理解评估。LatestEval通过仅使用在最近时间窗口内发布的文本来避免数据污染，确保不会与预先训练语言模型的训练语料库重叠。我们开发了LatestEval自动化流水线，用于1）收集最新文本；2）识别关键信息，以及3）构建针对该信息的问题，同时从上下文中删除现有答案。这鼓励模型根据剩余上下文推断答案，而不仅是复制粘贴。

    arXiv:2312.12343v3 Announce Type: replace-cross  Abstract: Data contamination in evaluation is getting increasingly prevalent with the emergence of language models pre-trained on super large, automatically crawled corpora. This problem leads to significant challenges in the accurate assessment of model capabilities and generalisations. In this paper, we propose LatestEval, an automatic method that leverages the most recent texts to create uncontaminated reading comprehension evaluations. LatestEval avoids data contamination by only using texts published within a recent time window, ensuring no overlap with the training corpora of pre-trained language models. We develop the LatestEval automated pipeline to 1) gather the latest texts; 2) identify key information, and 3) construct questions targeting the information while removing the existing answers from the context. This encourages models to infer the answers themselves based on the remaining context, rather than just copy-paste. Our e
    
[^97]: 强化关注力中最短的支柱：增强大型语言模型的上下文意识，以实现有效的工具使用

    Fortify the Shortest Stave in Attention: Enhancing Context Awareness of Large Language Models for Effective Tool Use

    [https://arxiv.org/abs/2312.04455](https://arxiv.org/abs/2312.04455)

    本文证明了大型语言模型中关注分配的波形模式对其在需要高度上下文意识的任务中的性能有显著影响。我们提出了一种名为“Attention Buckets”的推理方法，通过多个并行过程和不同的旋转位置嵌入角度，增强了模型对不同上下文位置的意识，从而减轻了忽视关键信息的风险。

    

    在本文中，我们证明了大型语言模型(LLMs)中关注分配中的内在波形模式显著影响它们在需要高度上下文意识的任务中的性能，例如利用LLMs进行工具使用。具体而言，当关键信息在上下文中位于关注波形的低谷区域时，模型可能会忽视该信息，导致性能下降。为了解决这个问题，我们提出了一种名为“Attention Buckets”的新型推理方法。它允许LLMs通过多个并行过程处理输入。每个过程使用不同的基准角度进行旋转位置嵌入，从而创建出一个独特的关注波形。通过用一个过程的关注低谷补偿另一个过程的关注高峰，我们的方法增强了LLM对不同上下文位置的意识，从而减轻了忽视关键信息的风险。

    In this paper, we demonstrate that an inherent waveform pattern in the attention allocation of large language models (LLMs) significantly affects their performance in tasks demanding a high degree of context awareness, such as utilizing LLMs for tool-use. Specifically, the crucial information in the context will be potentially overlooked by model when it is positioned in the trough zone of the attention waveform, leading to decreased performance. To address this issue, we propose a novel inference method named Attention Buckets. It allows LLMs to process their input through multiple parallel processes. Each process utilizes a distinct base angle for the rotary position embedding, thereby creating a unique attention waveform. By compensating an attention trough of a particular process with an attention peak of another process, our approach enhances LLM's awareness to various contextual positions, thus mitigating the risk of overlooking crucial information. In the largest tool-use benchm
    
[^98]: ARIA：关于联邦视觉分类中架构、初始化和聚合方法之间的相互作用

    ARIA: On the Interaction Between Architectures, Initialization and Aggregation Methods for Federated Visual Classification

    [https://arxiv.org/abs/2311.14625](https://arxiv.org/abs/2311.14625)

    ARIA元素必须共同选择才能实现最佳性能，揭示了不同任务下每个元素的良好选择和标准化效果的影响。

    

    联邦学习（FL）是一种协作训练范式，它允许通过消除敏感数据交换并依赖客户端和服务器之间模型参数的交换，实现跨机构模型的隐私保护学习。尽管关于客户端模型如何聚合以及最近对ImageNet预训练的好处进行了独立研究，但对于联邦选择的架构及其如何相互连接的影响缺乏理解。为此，我们开展了首次联合架构-初始化-聚合研究，并在一系列医学图像分类任务中对ARIA进行基准测试。我们发现，与当前做法相反，必须共同选择ARIA元素才能实现最佳性能。我们的结果还揭示了根据任务选择每个元素的良好选择，标准化效果的影响。

    arXiv:2311.14625v2 Announce Type: replace-cross  Abstract: Federated Learning (FL) is a collaborative training paradigm that allows for privacy-preserving learning of cross-institutional models by eliminating the exchange of sensitive data and instead relying on the exchange of model parameters between the clients and a server. Despite individual studies on how client models are aggregated, and, more recently, on the benefits of ImageNet pre-training, there is a lack of understanding of the effect the architecture chosen for the federation has, and of how the aforementioned elements interconnect. To this end, we conduct the first joint ARchitecture-Initialization-Aggregation study and benchmark ARIAs across a range of medical image classification tasks. We find that, contrary to current practices, ARIA elements have to be chosen together to achieve the best possible performance. Our results also shed light on good choices for each element depending on the task, the effect of normalisat
    
[^99]: 模仿引导式强化学习

    Imitation Bootstrapped Reinforcement Learning

    [https://arxiv.org/abs/2311.02198](https://arxiv.org/abs/2311.02198)

    提出了一种模仿引导式强化学习（IBRL）的框架，用于高效的样本-efficient RL，通过先在提供的示范上训练IL策略，然后使用它提出替代动作进行在线探索和引导目标值。

    

    尽管强化学习（RL）具有相当大的潜力，但机器人控制任务主要依赖模仿学习（IL）是因为其更好的样本效率。然而，收集能使IL推广到所有可能场景的全面专家演示是昂贵的，任何分布的转变都需要重新收集数据进行微调。因此，如果RL可以建立在IL的基础上作为一种高效的自我改进程序，那么它将具有吸引力。我们提出了一种模仿引导式强化学习（IBRL）的新框架，用于具有示范的高效抽样RL，首先在提供的示范上训练IL策略，然后使用它提出替代动作进行在线探索和引导目标值。与先前过度采样示范或用额外的模仿损失对RL进行正则化的工作相比，IBRL能够利用来自IL的高质量动作。

    arXiv:2311.02198v4 Announce Type: replace-cross  Abstract: Despite the considerable potential of reinforcement learning (RL), robotic control tasks predominantly rely on imitation learning (IL) due to its better sample efficiency. However, it is costly to collect comprehensive expert demonstrations that enable IL to generalize to all possible scenarios, and any distribution shift would require recollecting data for finetuning. Therefore, RL is appealing if it can build upon IL as an efficient autonomous self-improvement procedure. We propose imitation bootstrapped reinforcement learning (IBRL), a novel framework for sample-efficient RL with demonstrations that first trains an IL policy on the provided demonstrations and then uses it to propose alternative actions for both online exploration and bootstrapping target values. Compared to prior works that oversample the demonstrations or regularize RL with an additional imitation loss, IBRL is able to utilize high quality actions from IL p
    
[^100]: 为图级任务调优预训练图神经网络的搜索

    Search to Fine-tune Pre-trained Graph Neural Networks for Graph-level Tasks

    [https://arxiv.org/abs/2308.06960](https://arxiv.org/abs/2308.06960)

    设计更好的微调策略以在下游任务中更好地利用转移的知识并提高性能。

    

    最近，图神经网络（GNNs）在许多与图相关的任务中展现了前所未有的成功。然而，与其他神经网络一样，GNN面临着标签稀缺的问题。因此，最近的工作尝试在大规模未标记的图上预训练GNN，并将从未标记的图中获得的知识适应到目标下游任务中。该适应通常通过使用有限数量的标记数据对预训练的GNN进行微调来实现。尽管微调的重要性，当前的GNN预训练工作往往忽视了设计一个良好的微调策略以更好地利用转移的知识并提高下游任务的性能。只有少数工作开始研究预训练GNN的更好微调策略。但他们的设计要么有很强的假设，要么忽视了各种下游数据集的数据感知问题。因此，我们的目标是为预训练的GNN设计更好的微调策略。

    arXiv:2308.06960v2 Announce Type: replace-cross  Abstract: Recently, graph neural networks (GNNs) have shown its unprecedented success in many graph-related tasks. However, GNNs face the label scarcity issue as other neural networks do. Thus, recent efforts try to pre-train GNNs on a large-scale unlabeled graph and adapt the knowledge from the unlabeled graph to the target downstream task. The adaptation is generally achieved by fine-tuning the pre-trained GNNs with a limited number of labeled data. Despite the importance of fine-tuning, current GNNs pre-training works often ignore designing a good fine-tuning strategy to better leverage transferred knowledge and improve the performance on downstream tasks. Only few works start to investigate a better fine-tuning strategy for pre-trained GNNs. But their designs either have strong assumptions or overlook the data-aware issue for various downstream datasets. Therefore, we aim to design a better fine-tuning strategy for pre-trained GNNs t
    
[^101]: 多模态表示学习：演进、预训练及其应用的调查

    Multimodality Representation Learning: A Survey on Evolution, Pretraining and Its Applications

    [https://arxiv.org/abs/2302.00389](https://arxiv.org/abs/2302.00389)

    多模态表示学习涉及学习将不同模态信息嵌入并处理跨模态任务，在不同应用上取得显著成功，研究人员提出多种方法来实现这一目标。

    

    多模态表示学习作为一种学习将来自不同模态及其相关性的信息嵌入的技术，在诸如视觉问答（VQA）、视觉推理的自然语言（NLVR）和视觉语言检索（VLR）等各种应用上取得了显著成功。在这些应用中，来自不同模态的跨模态交互和补充信息对于先进模型执行任何多模态任务（如理解、识别、检索或生成）至关重要。研究人员提出了各种方法来解决这些任务。基于变压器的不同变体架构在多个模态上表现出色。本调查对深度学习多模态架构的演变和增强进行了全面综述，以处理文本、视觉和音频特征，以应对多样的跨模态和现代多模态挑战。

    arXiv:2302.00389v2 Announce Type: replace  Abstract: Multimodality Representation Learning, as a technique of learning to embed information from different modalities and their correlations, has achieved remarkable success on a variety of applications, such as Visual Question Answering (VQA), Natural Language for Visual Reasoning (NLVR), and Vision Language Retrieval (VLR). Among these applications, cross-modal interaction and complementary information from different modalities are crucial for advanced models to perform any multimodal task, e.g., understand, recognize, retrieve, or generate optimally. Researchers have proposed diverse methods to address these tasks. The different variants of transformer-based architectures performed extraordinarily on multiple modalities. This survey presents the comprehensive literature on the evolution and enhancement of deep learning multimodal architectures to deal with textual, visual and audio features for diverse cross-modal and modern multimodal
    
[^102]: 高维状态空间中马尔可夫决策过程的结构估计与有限时间保证

    Structural Estimation of Markov Decision Processes in High-Dimensional State Space with Finite-Time Guarantees

    [https://arxiv.org/abs/2210.01282](https://arxiv.org/abs/2210.01282)

    本论文提出了一种单循环估计算法，具有有限时间保证，能够处理高维状态空间的马尔可夫决策过程的结构估计问题，而不会损害奖励估计精度。

    

    我们考虑基于可观测的行为历史和访问状态来估计人类代理动态决策的结构模型的任务。问题具有固有的嵌套结构：在内部问题中，确定给定奖励函数的最优策略，而在外部问题中，最大化适合度度量。已经提出了几种方法来减轻这种嵌套循环结构的计算负担，但当状态空间要么是具有大基数的离散空间，要么是高维连续空间时，这些方法仍然面临高复杂度的问题。逆强化学习(IRL)文献中的其他方法强调策略估计，但却以降低奖励估计精度为代价。在本文中，我们提出了一种具有有限时间保证的单循环估计算法，适用于处理高维状态空间而不会损害奖励。

    arXiv:2210.01282v3 Announce Type: replace-cross  Abstract: We consider the task of estimating a structural model of dynamic decisions by a human agent based upon the observable history of implemented actions and visited states. This problem has an inherent nested structure: in the inner problem, an optimal policy for a given reward function is identified while in the outer problem, a measure of fit is maximized. Several approaches have been proposed to alleviate the computational burden of this nested-loop structure, but these methods still suffer from high complexity when the state space is either discrete with large cardinality or continuous in high dimensions. Other approaches in the inverse reinforcement learning (IRL) literature emphasize policy estimation at the expense of reduced reward estimation accuracy. In this paper we propose a single-loop estimation algorithm with finite time guarantees that is equipped to deal with high-dimensional state spaces without compromising rewar
    
[^103]: META-GUI：面向移动GUI的多模态对话系统

    META-GUI: Towards Multi-modal Conversational Agents on Mobile GUI

    [https://arxiv.org/abs/2205.11029](https://arxiv.org/abs/2205.11029)

    提出了一种基于GUI的任务导向对话系统（GUI-TOD）架构，并发布了用于在移动GUI上训练多模态对话代理的数据集META-GUI。

    

    任务导向的对话（TOD）系统已被广泛应用于移动电话智能助手，用于完成诸如日历安排或酒店预订等任务。目前的TOD系统通常专注于多轮文本/语音交互，然后调用为TOD设计的后端API来执行任务。然而，这种基于API的架构极大地限制了智能助手的信息搜索能力，甚至可能导致任务失败，如果TOD特定的API不可用或任务过于复杂而无法通过提供的API执行。在本文中，我们提出了一种新的TOD架构：基于GUI的任务导向对话系统（GUI-TOD）。GUI-TOD系统可以直接在真实应用程序上执行GUI操作并执行任务，而无需调用特定于TOD的后端API。此外，我们发布了META-GUI，这是一个用于在移动GUI上训练多模态对话代理的数据集。

    arXiv:2205.11029v2 Announce Type: cross  Abstract: Task-oriented dialogue (TOD) systems have been widely used by mobile phone intelligent assistants to accomplish tasks such as calendar scheduling or hotel reservation. Current TOD systems usually focus on multi-turn text/speech interaction, then they would call back-end APIs designed for TODs to perform the task. However, this API-based architecture greatly limits the information-searching capability of intelligent assistants and may even lead to task failure if TOD-specific APIs are not available or the task is too complicated to be executed by the provided APIs. In this paper, we propose a new TOD architecture: GUI-based task-oriented dialogue system (GUI-TOD). A GUI-TOD system can directly perform GUI operations on real APPs and execute tasks without invoking TOD-specific backend APIs. Furthermore, we release META-GUI, a dataset for training a Multi-modal convErsaTional Agent on mobile GUI. We also propose a multi-model action predi
    
[^104]: 通过逆强化学习实现可解释的深度强化学习模型

    Towards Interpretable Deep Reinforcement Learning Models via Inverse Reinforcement Learning

    [https://arxiv.org/abs/2203.16464](https://arxiv.org/abs/2203.16464)

    本研究提出了一个新颖的框架，利用对抗逆强化学习，可以为强化学习模型所作出的决策提供全局解释，并捕捉直观的倾向。

    

    人工智能，尤其是近年来深度学习的最新进展，在自然语言处理和计算机视觉等领域的许多任务中取得了出色的表现。除了令人满意的评估指标外，这些模型通常需要高度可解释性才能被可靠地利用。因此，提供能够深入了解模型如何将其输入映射到输出的解释成为人们迫切需要的。不幸的是，目前机器学习模型的黑盒特性仍然是一个尚未解决的问题，这种特性阻碍了研究人员学习和提供对模型行为和最终预测的解释描述。

    arXiv:2203.16464v3 Announce Type: replace-cross  Abstract: Artificial intelligence, particularly through recent advancements in deep learning, has achieved exceptional performances in many tasks in fields such as natural language processing and computer vision. In addition to desirable evaluation metrics, a high level of interpretability is often required for these models to be reliably utilized. Therefore, explanations that offer insight into the process by which a model maps its inputs onto its outputs are much sought-after. Unfortunately, the current black box nature of machine learning models is still an unresolved issue and this very nature prevents researchers from learning and providing explicative descriptions for a model's behavior and final predictions. In this work, we propose a novel framework utilizing Adversarial Inverse Reinforcement Learning that can provide global explanations for decisions made by a Reinforcement Learning model and capture intuitive tendencies that th
    
[^105]: 基于混合Tries的内存高效序列模式挖掘

    Memory-Efficient Sequential Pattern Mining with Hybrid Tries

    [https://arxiv.org/abs/2202.06834](https://arxiv.org/abs/2202.06834)

    提出了一种基于混合trie的内存高效序列模式挖掘方法，在内存消耗和计算时间方面相比现有技术有显著改善，且是唯一一个能够处理256GB系统内存下大数据集的方法。

    

    随着现代数据集的指数级增长，对于能够处理如此庞大数据集的高效挖掘算法的需求变得日益迫切。本文提出了一种内存高效的方法用于序列模式挖掘（SPM），这是知识发现中的一个基本主题，面临着针对大数据集的已知内存瓶颈。我们的方法涉及一种新颖的混合trie数据结构，利用重复模式紧凑地存储内存中的数据集; 以及一个相应的挖掘算法，旨在有效地从此紧凑表示中提取模式。对真实测试实例的数值结果显示，与最先进技术相比，对于小到中等大小的数据集，内存消耗平均提高了88％，计算时间提高了41％。此外，我们的算法是唯一一个在系统内存为256GB的情况下能够处理大数据集的SPM方法。

    arXiv:2202.06834v2 Announce Type: replace-cross  Abstract: As modern data sets continue to grow exponentially in size, the demand for efficient mining algorithms capable of handling such large data sets becomes increasingly imperative. This paper develops a memory-efficient approach for Sequential Pattern Mining (SPM), a fundamental topic in knowledge discovery that faces a well-known memory bottleneck for large data sets. Our methodology involves a novel hybrid trie data structure that exploits recurring patterns to compactly store the data set in memory; and a corresponding mining algorithm designed to effectively extract patterns from this compact representation. Numerical results on real-life test instances show an average improvement of 88% in memory consumption and 41% in computation time for small to medium-sized data sets compared to the state of the art. Furthermore, our algorithm stands out as the only capable SPM approach for large data sets within 256GB of system memory.
    
[^106]: InceptionXML：一种带有同步负采样的轻量级框架，用于短文本极端分类

    InceptionXML: A Lightweight Framework with Synchronized Negative Sampling for Short Text Extreme Classification

    [https://arxiv.org/abs/2109.07319](https://arxiv.org/abs/2109.07319)

    提出了一种轻量级框架InceptionXML，通过在embedding维度上重新分配卷积操作，应对短文本查询中的单词顺序缺失，同时提出了InceptionXML+框架，通过同步标签筛选器和极端分类器，改进了动态硬负采样技术。

    

    短文本数据对大量目标标签进行自动注释，被称为短文本极端分类，已经在许多应用中得到应用，包括相关搜索预测和产品推荐任务。本文提出了一种卷积架构InceptionXML，其轻量但功能强大，并且能够应对搜索和推荐任务中短文本查询中固有的缺乏单词顺序的特点。我们通过将卷积的操作沿着嵌入维度重新构建，而不是像传统CNNs一样沿着单词维度进行文本分类，证明了应用卷积的有效性。为了将我们的模型扩展到具有数百万标签的数据集，我们还提出了InceptionXML+框架，通过同步标签筛选器和极端分类器，改进了最近提出的动态硬负采样技术在标签筛选中的缺陷。

    arXiv:2109.07319v3 Announce Type: replace-cross  Abstract: Automatic annotation of short-text data to a large number of target labels, referred to as Short Text Extreme Classification, has found numerous applications including prediction of related searches and product recommendation tasks. In this paper, we propose a convolutional architecture InceptionXML which is light-weight, yet powerful, and robust to the inherent lack of word-order in short-text queries encountered in search and recommendation tasks. We demonstrate the efficacy of applying convolutions by recasting the operation along the embedding dimension instead of the word dimension as applied in conventional CNNs for text classification. Towards scaling our model to datasets with millions of labels, we also propose InceptionXML+ framework which improves upon the shortcomings of the recently proposed dynamic hard-negative mining technique for label shortlisting by synchronizing the label-shortlister and extreme classifier. 
    
[^107]: 深度学习对宇宙结构形成的洞见

    Deep learning insights into cosmological structure formation

    [https://arxiv.org/abs/2011.10577](https://arxiv.org/abs/2011.10577)

    通过构建深度学习框架，研究了各向异性信息在初始条件中如何影响暗物质暗团的最终质量，并发现各向异性添加了一些额外信息量。

    

    通过宇宙模拟可以计算早期宇宙中的线性初始条件如何演变成为后来的暗物质扩展暗团。然而，对于这一复杂过程的理论理解仍然难以捉摸；特别是，初始条件中各向异性信息如何确定最终暗物质暗团质量的角色仍然是一个长期存在的难题。在本文中，我们构建了一个深度学习框架来探讨这个问题。我们训练了一个三维卷积神经网络（CNN）来从初始条件预测暗物质暗团的质量，并全面量化了初始密度场的各向同性和各向异性方面关于最终暗团质量的信息量。我们发现，各向异性确实比密度场的球面平均值所包含的信息量略微增加了一些，尽管在统计上是显著的。

    arXiv:2011.10577v3 Announce Type: replace-cross  Abstract: The evolution of linear initial conditions present in the early universe into extended halos of dark matter at late times can be computed using cosmological simulations. However, a theoretical understanding of this complex process remains elusive; in particular, the role of anisotropic information in the initial conditions in establishing the final mass of dark matter halos remains a long-standing puzzle. Here, we build a deep learning framework to investigate this question. We train a three-dimensional convolutional neural network (CNN) to predict the mass of dark matter halos from the initial conditions, and quantify in full generality the amounts of information in the isotropic and anisotropic aspects of the initial density field about final halo masses. We find that anisotropies add a small, albeit statistically significant amount of information over that contained within spherical averages of the density field about final 
    
[^108]: 优化大规模语言模型用于漏洞检测

    Finetuning Large Language Models for Vulnerability Detection. (arXiv:2401.17010v1 [cs.CR])

    [http://arxiv.org/abs/2401.17010](http://arxiv.org/abs/2401.17010)

    本文优化了大规模语言模型用于源代码中的漏洞检测任务，通过微调最先进的代码语言模型WizardCoder并改进其训练过程和策略，实现了对漏洞数据集的分类性能的提升。

    

    本文介绍了对大规模语言模型进行微调，并将其用于源代码中的漏洞检测的结果。我们利用最先进的语言模型StarCoder的改进版本WizardCoder，并通过进一步微调将其适应于漏洞检测任务。为了加速训练，我们修改了WizardCoder的训练过程，并探究了最佳的训练策略。针对负样本远多于正样本的不平衡数据集，我们还尝试了不同的技术来提高分类性能。微调后的WizardCoder模型在平衡和不平衡的漏洞数据集上在ROC AUC和F1度量上实现了改进，证明了将预训练的语言模型用于源代码中的漏洞检测的有效性。主要贡献包括对最先进的代码语言模型WizardCoder进行微调，提高其训练速度而不影响性能，并对训练过程和策略进行了优化。

    This paper presents the results of finetuning large language models (LLMs) for the task of detecting vulnerabilities in source code. We leverage WizardCoder, a recent improvement of the state-of-the-art LLM StarCoder, and adapt it for vulnerability detection through further finetuning. To accelerate training, we modify WizardCoder's training procedure, also we investigate optimal training regimes. For the imbalanced dataset with many more negative examples than positive, we also explore different techniques to improve classification performance. The finetuned WizardCoder model achieves improvement in ROC AUC and F1 measures on balanced and imbalanced vulnerability datasets over CodeBERT-like model, demonstrating the effectiveness of adapting pretrained LLMs for vulnerability detection in source code. The key contributions are finetuning the state-of-the-art code LLM, WizardCoder, increasing its training speed without the performance harm, optimizing the training procedure and regimes, 
    
[^109]: 深度强化学习中策略梯度的终极指南：理论、算法和实现

    The Definitive Guide to Policy Gradients in Deep Reinforcement Learning: Theory, Algorithms and Implementations. (arXiv:2401.13662v1 [cs.LG])

    [http://arxiv.org/abs/2401.13662](http://arxiv.org/abs/2401.13662)

    本文提供了一个深度强化学习中策略梯度算法的综合指南，包括理论基础、实际实现和比较结果，并对正则化的益处进行了讨论。

    

    最近几年，在深度强化学习中提出了各种强大的策略梯度算法。虽然所有这些算法都建立在策略梯度定理的基础上，但具体的设计选择在算法之间有很大的差异。我们提供了一个整体的视角来概述在线策略梯度算法，以便理解它们的理论基础和实际实现。在这个概述中，我们包括了连续版本的策略梯度定理的详细证明、收敛结果和对实际算法的全面讨论。我们比较了连续控制环境中最重要的算法，并对正则化的益处提供了深入的见解。所有的代码都可以在https://github.com/Matt00n/PolicyGradientsJax获得。

    In recent years, various powerful policy gradient algorithms have been proposed in deep reinforcement learning. While all these algorithms build on the Policy Gradient Theorem, the specific design choices differ significantly across algorithms. We provide a holistic overview of on-policy policy gradient algorithms to facilitate the understanding of both their theoretical foundations and their practical implementations. In this overview, we include a detailed proof of the continuous version of the Policy Gradient Theorem, convergence results and a comprehensive discussion of practical algorithms. We compare the most prominent algorithms on continuous control environments and provide insights on the benefits of regularization. All code is available at https://github.com/Matt00n/PolicyGradientsJax.
    
[^110]: 元认知是你所需要的吗？在生成式智能体中使用内省以提高目标导向行为

    Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior. (arXiv:2401.10910v1 [q-bio.NC])

    [http://arxiv.org/abs/2401.10910](http://arxiv.org/abs/2401.10910)

    本文介绍了一个使用内省的元认知模块，可以让生成式智能体观察自己的思考过程和行动，并通过修改策略来显著提高性能。通过在多种场景下测试，我们观察到该系统在与其他系统的比较中取得了优势，智能体能够适应和改进策略以完成任务。

    

    最近大型语言模型（LLMs）的进展在各种应用中展示了令人印象深刻的能力，然而LLMs面临着有限的上下文窗口和泛化困难等挑战。在本文中，我们引入了一个元认知模块用于生成式智能体，使其能够观察自己的思考过程和行动。这种元认知方法旨在模拟系统1和系统2的认知过程，使智能体能够通过修改策略显著提高性能。我们在各种场景下测试了元认知模块，包括生成式智能体必须在僵尸启示录中存活的情况，并观察到我们的系统在表现上超过其他系统，同时智能体能够随着时间适应和改进策略以完成任务。

    Recent advances in Large Language Models (LLMs) have shown impressive capabilities in various applications, yet LLMs face challenges such as limited context windows and difficulties in generalization. In this paper, we introduce a metacognition module for generative agents, enabling them to observe their own thought processes and actions. This metacognitive approach, designed to emulate System 1 and System 2 cognitive processes, allows agents to significantly enhance their performance by modifying their strategy. We tested the metacognition module on a variety of scenarios, including a situation where generative agents must survive a zombie apocalypse, and observe that our system outperform others, while agents adapt and improve their strategies to complete tasks over time.
    
[^111]: GOAT-Bench: 通过基于迷因的社交虐待研究对大型多模态模型的安全洞察

    GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse. (arXiv:2401.01523v1 [cs.CL])

    [http://arxiv.org/abs/2401.01523](http://arxiv.org/abs/2401.01523)

    通过基于迷因的社交虐待研究对大型多模态模型的安全洞察，我们引入了综合的迷因基准测试集GOAT-Bench，评估各种LMMs在识别和回应迷因中体现的微妙社交虐待方面的能力。

    

    社交媒体的指数级增长深刻改变了信息的创造、传播和吸收方式，在数字时代产生了前所未有的影响。遗憾的是，这个爆炸也导致了网络迷因的滥用数量显著增加。评估迷因的负面影响是相当具有挑战性的，因为它们通常具有微妙和隐晦的含义，这些含义不能直接通过显性的文本和图像传达出来。鉴于此，大型多模态模型(LMMs)作为处理多样化多模态任务的卓越能力的焦点引起了人们的兴趣。针对这一发展，我们的论文旨在深入研究各种LMMs(如GPT-4V)识别和回应迷因中体现的微妙社交虐待方面的能力。我们引入了综合的迷因基准测试集GOAT-Bench，其中包含超过6K个多样的迷因，涵盖的主题包括隐性仇恨言论、性别歧视和网络欺凌等。利用GOAT-Be

    The exponential growth of social media has profoundly transformed how information is created, disseminated, and absorbed, exceeding any precedent in the digital age. Regrettably, this explosion has also spawned a significant increase in the online abuse of memes. Evaluating the negative impact of memes is notably challenging, owing to their often subtle and implicit meanings, which are not directly conveyed through the overt text and imagery. In light of this, large multimodal models (LMMs) have emerged as a focal point of interest due to their remarkable capabilities in handling diverse multimodal tasks. In response to this development, our paper aims to thoroughly examine the capacity of various LMMs (e.g. GPT-4V) to discern and respond to the nuanced aspects of social abuse manifested in memes. We introduce the comprehensive meme benchmark, GOAT-Bench, comprising over 6K varied memes encapsulating themes such as implicit hate speech, sexism, and cyberbullying, etc. Utilizing GOAT-Be
    
[^112]: SalUn：通过基于梯度的权重显著性增强机器遗忘在图像分类和生成中的效果

    SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation. (arXiv:2310.12508v1 [cs.LG])

    [http://arxiv.org/abs/2310.12508](http://arxiv.org/abs/2310.12508)

    这篇论文提出了一种名为SalUn的机器遗忘方法，通过引入"权重显著性"的概念，将关注点从整个模型引导到具体的模型权重上，提高了遗忘的效果和效率。这是第一个能够有效消除遗忘数据、类别或概念影响的有原则的机器遗忘方法。

    

    随着数据法规的不断发展，机器遗忘（MU）已成为增强当前AI模型的信任和安全性的重要工具。然而，现有的MU方法通常在遗忘精度、稳定性和跨领域适用性方面存在局限。为了解决这些挑战，我们引入了MU中的“权重显著性”概念，借鉴了模型解释中的输入显著性。这一创新将MU的关注点从整个模型引导到了具体的模型权重上，提高了其效果和效率。我们称之为显著性遗忘（SalUn）的方法将其与“精确”遗忘（在删除遗忘数据集后从头开始重新训练模型）的性能差距缩小。据我们所知，SalUn是第一个能够在图像分类和生成中有效消除遗忘数据、类别或概念影响的有原则的MU方法。例如，SalUn可在图片分类和生成任务中擦除遗忘数据、类别或概念。

    With evolving data regulations, machine unlearning (MU) has become an important tool for fostering trust and safety in today's AI models. However, existing MU methods focusing on data and/or weight perspectives often grapple with limitations in unlearning accuracy, stability, and cross-domain applicability. To address these challenges, we introduce the concept of 'weight saliency' in MU, drawing parallels with input saliency in model explanation. This innovation directs MU's attention toward specific model weights rather than the entire model, improving effectiveness and efficiency. The resultant method that we call saliency unlearning (SalUn) narrows the performance gap with 'exact' unlearning (model retraining from scratch after removing the forgetting dataset). To the best of our knowledge, SalUn is the first principled MU approach adaptable enough to effectively erase the influence of forgetting data, classes, or concepts in both image classification and generation. For example, Sa
    
[^113]: 基于结构的神经切线内核的快速图结构压缩

    Fast Graph Condensation with Structure-based Neural Tangent Kernel. (arXiv:2310.11046v1 [cs.LG])

    [http://arxiv.org/abs/2310.11046](http://arxiv.org/abs/2310.11046)

    本文提出了一种以数据为中心的解决方案，将大型图数据集压缩为较小的集合而不会损失GNN的预测性能。通过将图结构压缩问题转化为核岭回归任务，利用基于结构的神经切线内核来捕捉图的拓扑结构。

    

    互联网技术的快速发展造成了大量的图结构数据。图神经网络（GNN）作为一种有效的图挖掘方法，在处理大规模图数据时会导致大量的计算资源开销。本文提出了一种以数据为中心的解决方案，将大型图数据集压缩为较小的集合，而不会损失GNN的预测性能。然而，现有的方法通过计算密集型的双层优化架构来压缩图结构数据，同样也会带来巨大的计算开销。本文将图结构压缩问题改为核岭回归任务，而不是在双层优化的内循环中迭代训练GNN。具体来说，本文提出了一种新的图数据集压缩框架（GC-SNTK），其中开发了一种基于结构的神经切线内核（SNTK）来捕捉图的拓扑结构。

    The rapid development of Internet technology has given rise to a vast amount of graph-structured data. Graph Neural Networks (GNNs), as an effective method for various graph mining tasks, incurs substantial computational resource costs when dealing with large-scale graph data. A data-centric manner solution is proposed to condense the large graph dataset into a smaller one without sacrificing the predictive performance of GNNs. However, existing efforts condense graph-structured data through a computational intensive bi-level optimization architecture also suffer from massive computation costs. In this paper, we propose reforming the graph condensation problem as a Kernel Ridge Regression (KRR) task instead of iteratively training GNNs in the inner loop of bi-level optimization. More specifically, We propose a novel dataset condensation framework (GC-SNTK) for graph-structured data, where a Structure-based Neural Tangent Kernel (SNTK) is developed to capture the topology of graph and s
    
[^114]: 简明有序的感知有助于大型语言模型进行演绎推理

    Concise and Organized Perception Facilitates Large Language Models for Deductive Reasoning. (arXiv:2310.03309v1 [cs.CL])

    [http://arxiv.org/abs/2310.03309](http://arxiv.org/abs/2310.03309)

    利用大型语言模型进行演绎推理是一个具有挑战性的问题。这篇论文提出了一个简明有序的方法，将任务分解为子任务并且人类化地组织思维，以提高演绎推理的效果。

    

    利用大型语言模型（LLMs）解决演绎推理问题已经引起了越来越多的关注。在复杂的演绎问题中仍然很难取得令人满意的结果，这类问题具有大量前提（即事实或规则），其中涉及实体之间错综复杂的关系，需要进行多跳推理。一种直观的解决方案是将原始任务分解为较小的子任务，然后以前向（例如选择-推理）或反向（例如LAMBADA）方式将多个因果推理步骤连接在一起。然而，这些技术不可避免地需要大量的总体阶段，导致计算开销大，并且有更高的可能性产生误导性的步骤。除了逐阶段分解之外，我们还从人类问题解决的另一个方面获得了启发。人类倾向于提炼出最相关的信息并有序地组织思维（例如创建思维导图），这有助于他们对问题进行有效的推理。

    Exploiting large language models (LLMs) to tackle deductive reasoning has garnered growing attention. It still remains highly challenging to achieve satisfactory results in complex deductive problems, characterized by plenty of premises (i.e., facts or rules) entailing intricate relationships among entities and requiring multi-hop reasoning. One intuitive solution is to decompose the original task into smaller sub-tasks, and then chain the multiple casual reasoning steps together in a forward (e.g., Selection-Inference) or backward (e.g., LAMBADA) direction. However, these techniques inevitably necessitate a large number of overall stages, leading to computationally expensive operations and a higher possibility of making misleading steps. In addition to stage-by-stage decomposition, we draw inspiration from another aspect of human problem-solving. Humans tend to distill the most relevant information and organize their thoughts systematically (e.g., creating mind maps), which assists th
    
[^115]: 自学优化器（STOP）：递归自我改进的代码生成

    Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation. (arXiv:2310.02304v1 [cs.CL])

    [http://arxiv.org/abs/2310.02304](http://arxiv.org/abs/2310.02304)

    本文提出了一种自学优化器（STOP），通过递归自我改进的代码生成，使用融合了语言模型的脚手架程序来改进自身，从而生成性能更好的程序。

    

    最近几年的人工智能系统（例如思维树和程序辅助语言模型）取得了一些重要进展，通过提供一个“脚手架”程序来解决问题，该程序构建了多次调用语言模型以生成更好的输出。脚手架程序通常使用Python等编程语言编写。在这项工作中，我们使用了一个融合了语言模型的脚手架程序来改进自身。我们从一个种子“改进器”开始，通过多次查询语言模型并返回最佳解决方案，根据给定的效用函数来改进输入程序。然后，我们运行这个种子改进器来改进自身。在一系列细分任务中，得到的改进改进器生成的程序在性能上明显优于种子改进器。随后，我们对语言模型提出的各种自我改进策略进行了分析，包括波束搜索、遗传算法和模拟退火。由于语言模型本身没有改变，这并不是一种增长领域。

    Several recent advances in AI systems (e.g., Tree-of-Thoughts and Program-Aided Language Models) solve problems by providing a "scaffolding" program that structures multiple calls to language models to generate better outputs. A scaffolding program is written in a programming language such as Python. In this work, we use a language-model-infused scaffolding program to improve itself. We start with a seed "improver" that improves an input program according to a given utility function by querying a language model several times and returning the best solution. We then run this seed improver to improve itself. Across a small set of downstream tasks, the resulting improved improver generates programs with significantly better performance than its seed improver. Afterward, we analyze the variety of self-improvement strategies proposed by the language model, including beam search, genetic algorithms, and simulated annealing. Since the language models themselves are not altered, this is not fu
    
[^116]: 将大型语言模型推至6G边缘：视野、挑战和机遇

    Pushing Large Language Models to the 6G Edge: Vision, Challenges, and Opportunities. (arXiv:2309.16739v1 [cs.LG])

    [http://arxiv.org/abs/2309.16739](http://arxiv.org/abs/2309.16739)

    本文探讨了将大型语言模型(LLMs)部署在6G边缘的潜力和挑战。我们介绍了由LLMs支持的关键应用，并从响应时间、带宽成本和数据隐私等方面分析了云端部署面临的问题。我们提出了6G移动边缘计算(MEC)系统可能解决这些问题的方案，并讨论了边缘训练和边缘推理的创新技术。

    

    大型语言模型(LLMs)展示了显著的能力，正在改变人工智能的发展并有可能塑造我们的未来。然而，由于LLMs的多模态特性，当前的基于云的部署面临着一些关键挑战：1) 响应时间长；2) 高带宽成本；以及3) 违反数据隐私。6G移动边缘计算(MEC)系统可能解决这些迫切问题。本文探讨了在6G边缘部署LLMs的潜力。我们首先介绍了由多模态LLMs提供支持的关键应用，包括机器人技术和医疗保健，以突出在终端用户附近部署LLMs的需求。然后，我们确定了在边缘部署LLMs时面临的关键挑战，并设想了适用于LLMs的6G MEC架构。此外，我们深入探讨了两个设计方面，即LLMs的边缘训练和边缘推理。在这两个方面，考虑到边缘的固有资源限制，我们讨论了各种前沿技术。

    Large language models (LLMs), which have shown remarkable capabilities, are revolutionizing AI development and potentially shaping our future. However, given their multimodality, the status quo cloud-based deployment faces some critical challenges: 1) long response time; 2) high bandwidth costs; and 3) the violation of data privacy. 6G mobile edge computing (MEC) systems may resolve these pressing issues. In this article, we explore the potential of deploying LLMs at the 6G edge. We start by introducing killer applications powered by multimodal LLMs, including robotics and healthcare, to highlight the need for deploying LLMs in the vicinity of end users. Then, we identify the critical challenges for LLM deployment at the edge and envision the 6G MEC architecture for LLMs. Furthermore, we delve into two design aspects, i.e., edge training and edge inference for LLMs. In both aspects, considering the inherent resource limitations at the edge, we discuss various cutting-edge techniques, i
    
[^117]: 匿名化语音：评估和设计说话人匿名化技术

    Anonymizing Speech: Evaluating and Designing Speaker Anonymization Techniques. (arXiv:2308.04455v1 [cs.CR])

    [http://arxiv.org/abs/2308.04455](http://arxiv.org/abs/2308.04455)

    本研究提出了匿名化语音的解决方案，并评估了匿名化的程度，以应对语音数据收集中的隐私问题和恶意使用的风险。

    

    随着语音用户界面的广泛使用，语音数据的收集和存储也大大增加。虽然数据收集可以为大多数语音服务提供高效的工具，但它也给用户的隐私造成严重的问题，因为集中存储使个人的语音数据容易受到网络威胁的侵害。随着亚马逊的Alexa，谷歌的Home和苹果的Siri等基于语音的数字助手的使用增加，以及个人语音数据收集变得越来越容易，声音克隆和说话人/性别/病理等识别的恶意使用的风险也增加了。本文提出了匿名化语音的解决方案，并评估匿名化的程度。在这项工作中，匿名化是指使个人语音数据与身份无法关联，同时保持语音信号的实用性（例如，访问语言内容）。我们首先确定了几个评估协议的挑战。

    The growing use of voice user interfaces has led to a surge in the collection and storage of speech data. While data collection allows for the development of efficient tools powering most speech services, it also poses serious privacy issues for users as centralized storage makes private personal speech data vulnerable to cyber threats. With the increasing use of voice-based digital assistants like Amazon's Alexa, Google's Home, and Apple's Siri, and with the increasing ease with which personal speech data can be collected, the risk of malicious use of voice-cloning and speaker/gender/pathological/etc. recognition has increased.  This thesis proposes solutions for anonymizing speech and evaluating the degree of the anonymization. In this work, anonymization refers to making personal speech data unlinkable to an identity while maintaining the usefulness (utility) of the speech signal (e.g., access to linguistic content). We start by identifying several challenges that evaluation protoco
    
[^118]: $\lambda$-AC：学习连续状态空间强化学习中的潜在决策感知模型

    $\lambda$-AC: Learning latent decision-aware models for reinforcement learning in continuous state-spaces. (arXiv:2306.17366v1 [cs.LG])

    [http://arxiv.org/abs/2306.17366](http://arxiv.org/abs/2306.17366)

    这项研究提出了一种$\lambda$-AC算法，通过学习连续状态空间中的潜在决策感知模型，实现了决策驱动的强化学习。通过理论和实证研究，确定了决策感知强化学习模型的必要组成部分，并展示了设计选择对算法性能的重要影响。

    

    决策感知模型学习的思想，在模型驱动的强化学习中变得越来越重要，即模型在决策制定时应该是准确的。尽管已经建立了一些有希望的理论结果，但是在连续控制问题中，利用决策感知损失的算法的实际性能仍然不足。本文研究了决策感知强化学习模型所需的必要组成部分，并展示了能够实现良好算法性能的设计选择。为此，我们对该领域的重要算法思想进行了理论和实证研究。我们强调，在MuZero系列工作中所建立的经验性设计决策对于相关算法的良好性能至关重要，并展示了在随机环境中，不同的价值感知算法实例之间行为差异。在这些见解的基础上，我们提出了潜在模型驱动决策的算法，称为$\lambda$-AC。

    The idea of decision-aware model learning, that models should be accurate where it matters for decision-making, has gained prominence in model-based reinforcement learning. While promising theoretical results have been established, the empirical performance of algorithms leveraging a decision-aware loss has been lacking, especially in continuous control problems. In this paper, we present a study on the necessary components for decision-aware reinforcement learning models and we showcase design choices that enable well-performing algorithms. To this end, we provide a theoretical and empirical investigation into prominent algorithmic ideas in the field. We highlight that empirical design decisions established in the MuZero line of works are vital to achieving good performance for related algorithms, and we showcase differences in behavior between different instantiations of value-aware algorithms in stochastic environments. Using these insights, we propose the Latent Model-Based Decisio
    
[^119]: 自监督学习在时间序列分析中的应用：分类、进展和前景

    Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects. (arXiv:2306.10125v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.10125](http://arxiv.org/abs/2306.10125)

    自监督学习（SSL）在时间序列分析中的应用取得了显著性能，通过减少对标注数据的依赖，即使只有少量标注数据，也能实现高性能。

    

    自监督学习（SSL）最近在各种时间序列任务上取得了令人瞩目的性能。SSL最突出的优势是减少对标注数据的依赖。基于预训练和微调策略，即使只有少量标注数据，也可以实现高性能。与许多关于计算机视觉和自然语言处理的自监督学习综述相比，目前还缺乏针对时间序列SSL的综述。为了填补这一空白，本文回顾了当前时间序列数据中的自监督学习（SSL）方法的最新研究进展。为此，我们首先全面回顾了与自监督学习（SSL）和时间序列相关的现有综述，然后通过总结从生成型、对比型和对抗型三个角度对现有时间序列自监督学习方法进行了新的分类。这些方法进一步细分为十个子类，详细回顾和讨论了它们的关键直觉、主要框架、优势和限制。

    Self-supervised learning (SSL) has recently achieved impressive performance on various time series tasks. The most prominent advantage of SSL is that it reduces the dependence on labeled data. Based on the pre-training and fine-tuning strategy, even a small amount of labeled data can achieve high performance. Compared with many published self-supervised surveys on computer vision and natural language processing, a comprehensive survey for time series SSL is still missing. To fill this gap, we review current state-of-the-art SSL methods for time series data in this article. To this end, we first comprehensively review existing surveys related to SSL and time series, and then provide a new taxonomy of existing time series SSL methods by summarizing them from three perspectives: generative-based, contrastive-based, and adversarial-based. These methods are further divided into ten subcategories with detailed reviews and discussions about their key intuitions, main frameworks, advantages an
    
[^120]: 自然语言处理中社会人口统计偏见的调查

    Survey on Sociodemographic Bias in Natural Language Processing. (arXiv:2306.08158v1 [cs.CL])

    [http://arxiv.org/abs/2306.08158](http://arxiv.org/abs/2306.08158)

    本文调查了209篇关于NLP模型偏见的论文，其中大部分涉及社会人口统计偏见。研究者提出了社会人口统计偏见的定义，并确定了NLP偏见研究的三个主要类别。当前去偏见技术只是隐藏了偏见而不是真正去除它，需要进一步改进。

    

    深度神经网络在训练过程中往往会学习到非预期的偏见，这在实际应用中可能会产生有害的影响。本文对209篇关于NLP模型中偏见的论文进行了调查，其中大部分论文涉及社会人口统计偏见。为了更好地理解偏见与真实世界的危害之间的区别，我们借鉴心理学和行为经济学的思想，提出了社会人口统计偏见的定义。我们确定了NLP偏见研究的三个主要类别：偏见类型、量化偏见和去偏见。我们认为当前对于量化偏见的方法存在可靠性问题，许多偏见度量并不涉及真实世界中的偏见，当前的去偏见技术是表面的，只是隐藏了偏见，而不是真正去除它。最后，我们提供了未来工作的建议。

    Deep neural networks often learn unintended biases during training, which might have harmful effects when deployed in real-world settings. This paper surveys 209 papers on bias in NLP models, most of which address sociodemographic bias. To better understand the distinction between bias and real-world harm, we turn to ideas from psychology and behavioral economics to propose a definition for sociodemographic bias. We identify three main categories of NLP bias research: types of bias, quantifying bias, and debiasing. We conclude that current approaches on quantifying bias face reliability issues, that many of the bias metrics do not relate to real-world biases, and that current debiasing techniques are superficial and hide bias rather than removing it. Finally, we provide recommendations for future work.
    
[^121]: 联邦领域泛化：一项调查研究

    Federated Domain Generalization: A Survey. (arXiv:2306.01334v1 [cs.LG])

    [http://arxiv.org/abs/2306.01334](http://arxiv.org/abs/2306.01334)

    该论文调查了联邦领域泛化的研究领域，提到了联邦学习和领域泛化技术的优势，以及在泛化联邦模型时面临的挑战。

    

    机器学习通常依赖于一个假设，即训练和测试的分布是相同的，数据是集中存储供训练和测试之用。然而，在现实场景中，分布可能存在显著差异，并且数据通常分布在不同的设备、组织或边缘节点上。因此，必须开发能够有效泛化到未见过的分布，并且数据分布在不同领域的模型。为了应对这一挑战，近年来出现了对联邦领域泛化 (FDG) 的极大兴趣。FDG 结合了联邦学习 (FL) 和领域泛化 (DG) 技术的优点，使多个源领域能够协作学习一个能够直接泛化到未见过的领域而又保持数据隐私的模型。然而，在领域转移下泛化联邦模型是一个技术上具有挑战性的问题，目前还没有得到充分的关注。

    Machine learning typically relies on the assumption that training and testing distributions are identical and that data is centrally stored for training and testing. However, in real-world scenarios, distributions may differ significantly and data is often distributed across different devices, organizations, or edge nodes. Consequently, it is imperative to develop models that can effectively generalize to unseen distributions where data is distributed across different domains. In response to this challenge, there has been a surge of interest in federated domain generalization (FDG) in recent years. FDG combines the strengths of federated learning (FL) and domain generalization (DG) techniques to enable multiple source domains to collaboratively learn a model capable of directly generalizing to unseen domains while preserving data privacy. However, generalizing the federated model under domain shifts is a technically challenging problem that has received scant attention in the research 
    
[^122]: 人工智能中介交流的关键评估

    Critical Appraisal of Artificial Intelligence-Mediated Communication. (arXiv:2305.11897v1 [cs.HC])

    [http://arxiv.org/abs/2305.11897](http://arxiv.org/abs/2305.11897)

    本文探讨了人工智能在语言教育中介交流的优缺点，并强调语言教师积极参与CALL教师教育和专业发展的重要性。

    

    在过去的20年中，语言学习和教学中的技术应用得到了显著发展，现在被称为计算机辅助语言学习（CALL）。最近，将人工智能（AI）整合到CALL中，显著改变了语言教育在课堂内外的传统方法。在本文中，我探讨了AI中介交流在语言教育中的优缺点。我首先简要回顾了教育中的AI技术。然后，我介绍了ICALL，并对AI驱动的自动语音识别（ASR）、机器翻译（MT）、智能辅导系统（ITSs）、AI驱动的聊天机器人和扩展现实（XR）的潜力进行了关键评估。最后，我认为，语言教师积极参与CALL教师教育和专业发展至关重要，以跟上不断发展的技术景观并提高自己的教学效果。

    Over the last two decades, technology use in language learning and teaching has significantly advanced and is now referred to as Computer-Assisted Language Learning (CALL). Recently, the integration of Artificial Intelligence (AI) into CALL has brought about a significant shift in the traditional approach to language education both inside and outside the classroom. In line with this book's scope, I explore the advantages and disadvantages of AI-mediated communication in language education. I begin with a brief review of AI in education. I then introduce the ICALL and give a critical appraisal of the potential of AI-powered automatic speech recognition (ASR), Machine Translation (MT), Intelligent Tutoring Systems (ITSs), AI-powered chatbots, and Extended Reality (XR). In conclusion, I argue that it is crucial for language teachers to engage in CALL teacher education and professional development to keep up with the ever-evolving technology landscape and improve their teaching effectivene
    
[^123]: 整数线性规划的局部搜索方法

    Local Search for Integer Linear Programming. (arXiv:2305.00188v1 [math.OC])

    [http://arxiv.org/abs/2305.00188](http://arxiv.org/abs/2305.00188)

    本论文开发了一个独立的局部搜索求解器，可用于解决一般整数线性规划，并在大型异构问题数据集上进行了验证。在搜索、改进和还原模式下，分别提出了可自适应修改变量值的算子和高效的举升算子，从而提高当前解的质量。实验表明，该方法在MIPLIB2017的异构问题集上表现优异。

    

    整数线性规划模型适用于各种实际的组合优化问题，对于产业和管理部门具有重要影响。本论文开发了第一个独立的局部搜索求解器，可用于解决一般整数线性规划，并在大型异构问题数据集上进行了验证。我们提出一个局部搜索框架，切换三种模式，分别为搜索，改进和还原模式，并设计适应不同模式的定制算子，从而根据不同情况提高当前解的质量。对于搜索和还原模式，我们提出了一种名为“紧身动作”的算子，它可以自适应地修改变量的值，试图使某些约束变得更紧。对于改进模式，提出了一种高效的算子“举升动作”，可以在保持可行性的同时提高目标函数的质量。结合这些内容，我们开发了一个局部搜索整数线性规划求解器，称为Local-ILP。对MIPLIB2017的异构问题集进行的实验表明，Local-ILP表现优异，可以与最先进的整数线性规划求解器相竞争。

    Integer linear programming models a wide range of practical combinatorial optimization problems and has significant impacts in industry and management sectors. This work develops the first standalone local search solver for general integer linear programming validated on a large heterogeneous problem dataset. We propose a local search framework that switches in three modes, namely Search, Improve, and Restore modes, and design tailored operators adapted to different modes, thus improve the quality of the current solution according to different situations. For the Search and Restore modes, we propose an operator named tight move, which adaptively modifies variables' values trying to make some constraint tight. For the Improve mode, an efficient operator lift move is proposed to improve the quality of the objective function while maintaining feasibility. Putting these together, we develop a local search solver for integer linear programming called Local-ILP. Experiments conducted on the 
    
[^124]: GPT-4技术报告

    GPT-4 Technical Report. (arXiv:2303.08774v1 [cs.CL])

    [http://arxiv.org/abs/2303.08774](http://arxiv.org/abs/2303.08774)

    GPT-4是一个大规模多模态模型，可以接收图像和文本输入并产生文本输出，能够在各种专业和学术基准测试中表现出人类水平的表现，包括通过模拟的律师考试。该项目的核心组件是开发基础设施和优化方法，可在广泛的规模范围内表现预测性。

    

    我们报告了GPT-4的开发，它是一个可以接受图像和文本输入并产生文本输出的大规模多模态模型。虽然在许多现实场景中不如人类，但GPT-4在各种专业和学术基准测试中表现出人类水平的表现，包括通过模拟的律师考试，成绩排名在前10％左右。GPT-4是一个基于Transformer的模型，预训练用于预测文档中的下一个标记。后训练对齐过程提高了事实性和符合期望行为的性能指标。项目的核心组件是开发基础设施和优化方法，可在广泛的规模范围内表现预测性。这使我们能够准确预测GPT-4的某些性能方面，而这些性能是基于使用不超过GPT-4计算能力的1/1,000的模型训练的。

    We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.
    
[^125]: 正则化神经网络模拟人类洞察力

    Regularised neural networks mimic human insight. (arXiv:2302.11351v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.11351](http://arxiv.org/abs/2302.11351)

    本文研究了正则化神经网络是否具有类似于人类洞察力的行为。研究发现，正则化神经网络在学习动态和行为特征上密切模仿了人类的洞察力，表现出洞察力的延迟、突然性和选择性发生。

    

    人类有时会展现出突然提高任务表现的情况，这与洞察力时刻相关。这种洞察力相关的性能提升似乎很特殊，因为它们前面有一个较长时间的僵局，变化异常突然，并且只发生在一部分学习者身上。本文探讨了使用梯度下降算法训练的人工神经网络中是否也存在类似洞察力行为。我们通过一项感知决策任务比较了人类和正则化神经网络的学习动态，该任务提供了一个隐藏的机会，可以更有效地解决任务。我们发现人类倾向于通过洞察力发现这种规律，而不是逐渐发现。值得注意的是，带有正则化门控调节的神经网络紧密模仿了人类洞察力的行为特征，表现出洞察力的延迟、突然性和选择性发生。网络学习动态的分析揭示了洞察力行为关键地取决于噪声添加。

    Humans sometimes show sudden improvements in task performance that have been linked to moments of insight. Such insight-related performance improvements appear special because they are preceded by an extended period of impasse, are unusually abrupt, and occur only in some, but not all, learners. Here, we ask whether insight-like behaviour also occurs in artificial neural networks trained with gradient descent algorithms. We compared learning dynamics in humans and regularised neural networks in a perceptual decision task that provided a hidden opportunity which allowed to solve the task more efficiently. We show that humans tend to discover this regularity through insight, rather than gradually. Notably, neural networks with regularised gate modulation closely mimicked behavioural characteristics of human insights, exhibiting delay of insight, suddenness and selective occurrence. Analyses of network learning dynamics revealed that insight-like behaviour crucially depended on noise adde
    

