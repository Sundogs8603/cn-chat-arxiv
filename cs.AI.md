# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Annotated Hands for Generative Models.](http://arxiv.org/abs/2401.15075) | 本文提出了一种对生成模型进行手部标注的新方法，通过增加三个额外的通道来改进生成手部图像的质量。在两个不同的生成模型上验证了该方法的有效性，并通过使用手部检测器来衡量生成手部图像质量的提高。 |
| [^2] | [Health Text Simplification: An Annotated Corpus for Digestive Cancer Education and Novel Strategies for Reinforcement Learning.](http://arxiv.org/abs/2401.15043) | 该论文介绍了一个用于健康文本简化研究的消化癌症教育材料的注释语料库，并探索了基于大型语言模型的简化方法，包括微调、增强学习、增强学习与人类反馈、领域自适应和基于提示的应用。 |
| [^3] | [PROXYQA: An Alternative Framework for Evaluating Long-Form Text Generation with Large Language Models.](http://arxiv.org/abs/2401.15042) | PROXYQA是一个用于评估大型语言模型长篇文本生成的替代框架，通过生成详尽的内容，并利用评估器和生成内容作为背景环境，根据评估器回答代理问题的表现来评估生成内容的质量。 |
| [^4] | [Airavata: Introducing Hindi Instruction-tuned LLM.](http://arxiv.org/abs/2401.15006) | "Airavata"是一个针对印地语进行指令调整的LLM，通过微调OpenHathi和IndicInstruct数据集，提供更好的协助任务性能，并计划扩展到所有22种计划Indic语言。 |
| [^5] | [Atmosphere: Context and situational-aware collaborative IoT architecture for edge-fog-cloud computing.](http://arxiv.org/abs/2401.14968) | 本文提出了一种解决边缘-雾-云计算中软件架构不足的方法，该架构可以有效利用上下文感知和情境数据分析，并实现相邻层次之间的双向通信。 |
| [^6] | [Learning Universal Predictors.](http://arxiv.org/abs/2401.14953) | 本论文探索了将Solomonoff Induction（SI）引入神经网络中的潜力，并使用万能图灵机（UTMs）生成的数据来进行元学习，研究结果表明UTM数据是元学习的有价值资源，可以用来训练能够学习通用预测的神经网络。 |
| [^7] | [Conserve-Update-Revise to Cure Generalization and Robustness Trade-off in Adversarial Training.](http://arxiv.org/abs/2401.14948) | 对抗训练在提高神经网络鲁棒性方面取得了进展，但是牺牲了标准和鲁棒泛化之间的权衡。研究发现，选择性地更新特定层可以显著提高网络学习能力。因此，提出了CURE框架，通过选择性保留、更新和修订权重来解决这一问题。这一方法可以有效解决记忆化和过度拟合问题，并提高鲁棒性和泛化性之间的权衡。 |
| [^8] | [SSDOnt: an Ontology for representing Single-Subject Design Studies.](http://arxiv.org/abs/2401.14933) | SSDOnt是一种用于描述和注释单体设计研究的本体论，为这类研究提供了适当的术语和参考模型。 |
| [^9] | [Do LLMs Dream of Ontologies?.](http://arxiv.org/abs/2401.14931) | 本文研究了通用预训练大型语言模型（LLMs）是否记忆了已知本体论的信息以及记忆的程度，结果显示LLMs部分地了解本体论的概念，记忆程度与其在Web上的流行程度成正比。 |
| [^10] | [Reinforcement Learning Interventions on Boundedly Rational Human Agents in Frictionful Tasks.](http://arxiv.org/abs/2401.14923) | 本论文介绍了行为模型强化学习（BMRL）框架，在摩擦性任务中，AI代理对有限理性人类代理的参数进行干预，通过对人类策略进行解释，帮助理解行为干预。 |
| [^11] | [Charting the Future of AI in Project-Based Learning: A Co-Design Exploration with Students.](http://arxiv.org/abs/2401.14915) | 本文介绍了一项与学生共同设计的研究，探索学生在项目化学习中使用人工智能的潜力，并基于学生的视觉对教育目标转变进行分析。研究发现，不同态度的学生对人工智能的使用有不同的偏好。这为未来研究学生与人工智能交互和理解增强学习提供了机会。 |
| [^12] | [Cross-Space Adaptive Filter: Integrating Graph Topology and Node Attributes for Alleviating the Over-smoothing Problem.](http://arxiv.org/abs/2401.14876) | 本论文提出了一种跨空间自适应滤波器（CSF），可以从图拓扑和节点属性空间中提取自适应频率信息，以减轻图卷积网络（GCN）的过度平滑问题。 |
| [^13] | [Memory-Inspired Temporal Prompt Interaction for Text-Image Classification.](http://arxiv.org/abs/2401.14856) | 本文提出了一种基于记忆的暂时提示交互策略，用于文本-图像分类。该策略受到人类记忆策略的启发，通过两个阶段的操作来进行模态对齐和模拟记忆过程，从而提高了大规模预训练多模态模型的效率。 |
| [^14] | [The Machine Vision Iceberg Explained: Advancing Dynamic Testing by Considering Holistic Environmental Circumstances.](http://arxiv.org/abs/2401.14831) | 本研究提出了一个名为粒度等级的层次级别模型，用于更好地理解机器视觉在不同环境条件下的操作。这一模型旨在提供对影响机器视觉功能的各个实体的全面概述。 |
| [^15] | [On the Limitations of Markovian Rewards to Express Multi-Objective, Risk-Sensitive, and Modal Tasks.](http://arxiv.org/abs/2401.14811) | 本文研究了强化学习中标量、马尔可夫奖励函数的表达能力，并确定了它们的一些局限性。我们发现这些奖励函数无法表达多目标、风险敏感和模态任务中的大部分实例。 |
| [^16] | [Large Language Model Adaptation for Financial Sentiment Analysis.](http://arxiv.org/abs/2401.14777) | 本文研究了针对金融领域的大规模语言模型适应方法，并重点关注金融情感分析。通过在金融文件和说明书上进行精细调优，展示了基础模型在目标领域的适应能力。 |
| [^17] | [Topology-Aware Exploration of Energy-Based Models Equilibrium: Toric QC-LDPC Codes and Hyperbolic MET QC-LDPC Codes.](http://arxiv.org/abs/2401.14749) | 本文介绍了一种在不均匀分布的电荷和不规则网格上实现能量模型均衡的方法，通过使用QC-LDPC码和玻尔兹曼机，将系统的维度扩展，将电荷替换为循环物质，并通过循环移位表示距离。通过这种方法，可以将不规则网格转化为均匀配置，适用于不同的拓扑结构。该方法还解决了代码在图形概率模型中的评估问题，并提供了在不同拓扑下玻尔兹曼机达到均衡状态的严格证明。 |
| [^18] | [Synthetic Multimodal Dataset for Empowering Safety and Well-being in Home Environments.](http://arxiv.org/abs/2401.14743) | 本文介绍了一个合成的多模态数据集，结合了3D虚拟空间模拟器的视频数据和描述活动时空背景的知识图，旨在解决家庭环境中的危险情况，并提供给研究人员和从业者作为资源来开发创新解决方案，以提升安全和福祉。 |
| [^19] | [Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion.](http://arxiv.org/abs/2401.14717) | 这个论文提出了一种利用声学和语言模型进行交替和回应预测的方法，通过融合这两种模型，可以在口语对话中实现更加自然和对话式的互动。 |
| [^20] | [Mitigating Feature Gap for Adversarial Robustness by Feature Disentanglement.](http://arxiv.org/abs/2401.14707) | 这项研究提出了一种通过特征解缠来缓解对抗鲁棒性中特征差距的方法，该方法明确建模和消除导致特征差距的潜在特征，有效提升了鲁棒性。 |
| [^21] | [FairSample: Training Fair and Accurate Graph Convolutional Neural Networks Efficiently.](http://arxiv.org/abs/2401.14702) | 本文提出了一种名为FairSample的框架，旨在高效训练公平准确的图卷积神经网络。该框架通过对图结构进行纠正，并使用可学习的邻居采样策略来同时减轻图卷积神经网络中的图结构偏见、节点属性偏见和模型参数偏见。 |
| [^22] | [Under the Surface: Tracking the Artifactuality of LLM-Generated Data.](http://arxiv.org/abs/2401.14698) | 本研究是针对大型语言模型（LLM）生成的人工数据的追踪研究，将各种类型的LLM生成文本数据进行了汇总和测试，并揭示了隐藏的质量和多样性问题。这是第一次对LLM生成数据进行综合分析和比较，并引发了对人工数据质量的关注。 |
| [^23] | [Asymptotic Midpoint Mixup for Margin Balancing and Moderate Broadening.](http://arxiv.org/abs/2401.14696) | 提出了渐进中点混合方法来解决粗细转移学习中的类内崩塌问题。该方法通过逐渐将增强特征移动至类间特征对的中点，实现了边距平衡以及适度扩展边距的效果。 |
| [^24] | [TA-RNN: an Attention-based Time-aware Recurrent Neural Network Architecture for Electronic Health Records.](http://arxiv.org/abs/2401.14694) | TA-RNN和TA-RNN-AE是两种基于RNN的可解释深度学习架构，用于分析电子健康记录并预测患者的临床结果。这些架构考虑了EHR数据的不规则性和时间间隔，并采用时间嵌入的方法解决了这些问题。 |
| [^25] | [PepGB: Facilitating peptide drug discovery via graph neural networks.](http://arxiv.org/abs/2401.14665) | 本研究提出了一个名为PepGB的深度学习框架，通过图神经网络结合细粒度的扰动模块和基于对比学习的肽段预训练表示，以促进肽段早期药物发现中的肽-蛋白相互作用预测。 |
| [^26] | [Efficient Constraint Generation for Stochastic Shortest Path Problems.](http://arxiv.org/abs/2401.14636) | 本文提出了一个高效的约束生成技术，通过忽略次优操作和避免不必要的成本计算，解决了随机最短路径问题中的计算效率问题。实验证明，应用这一技术的CG-iLAO*算法在解决问题的速度上比LRTDP和iLAO*有显著提升。 |
| [^27] | [An Empirical Investigation of Domain Adaptation Ability for Chinese Spelling Check Models.](http://arxiv.org/abs/2401.14630) | 该论文通过构建领域特定术语的新数据集，对各种典型的中文拼写检查（CSC）模型的领域适应能力进行了全面评估，结果表明这些模型在新领域中的性能显著下降。 |
| [^28] | [A Systematic Literature Review on Explainability for Machine/Deep Learning-based Software Engineering Research.](http://arxiv.org/abs/2401.14617) | 本文通过对机器/深度学习的软件工程领域中可解释性的系统文献综述，总结了XAI技术在软件工程中的应用情况，旨在提高AI模型的可解释性以解决实际部署中的不确定性和风险问题。 |
| [^29] | [Alternative Speech: Complementary Method to Counter-Narrative for Better Discourse.](http://arxiv.org/abs/2401.14616) | 该论文引入了“替代性言论”作为直接对抗仇恨言论的新方法，并提供了构建所需数据集的指导。替代性言论通过提供实际可行的替代方案，考虑环境因素并促使演讲者改变，为解决社会问题提供有用工具。将替代性言论与对抗叙事结合使用可以更有效地对抗仇恨言论，补充了对抗叙事的能力。 |
| [^30] | [Enhancing Diagnostic Accuracy through Multi-Agent Conversations: Using Large Language Models to Mitigate Cognitive Bias.](http://arxiv.org/abs/2401.14589) | 本研究旨在通过利用大型语言模型和多智能体对话的方式来减轻临床决策中的认知偏差，并评估其对提高诊断准确性的有效性。 |
| [^31] | [Driving Towards Inclusion: Revisiting In-Vehicle Interaction in Autonomous Vehicles.](http://arxiv.org/abs/2401.14571) | 本文综述了自动驾驶车辆中车内人机交互的现状和新兴技术，并提出了以用户为中心的包容性HCI设计原则，旨在增强乘客体验。 |
| [^32] | [Language Modelling Approaches to Adaptive Machine Translation.](http://arxiv.org/abs/2401.14559) | 自适应机器翻译中的语言建模方法，通过利用大型语言模型(LLMs)来在特定上下文中学习、改进翻译质量，解决了在域适应中因缺乏域内数据而导致翻译不一致的问题。 |
| [^33] | [Exploring Musical Roots: Applying Audio Embeddings to Empower Influence Attribution for a Generative Music Model.](http://arxiv.org/abs/2401.14542) | 本文提出了一种方法来识别音乐音频中相似的作品，以便了解生成音乐模型的训练数据归因。通过应用CLMR和CLAP嵌入到相似度测量中，我们验证了该方法的有效性，并观察了对音频示例进行修改对相似度的影响。 |
| [^34] | [Relative Value Biases in Large Language Models.](http://arxiv.org/abs/2401.14530) | 该研究发现大型语言模型在做选择时表现出了与人类和动物相似的相对价值偏差，这对于理解人类选择中的背景依赖性机制具有重要意义。 |
| [^35] | [Evaluating GPT-3.5's Awareness and Summarization Abilities for European Constitutional Texts with Shared Topics.](http://arxiv.org/abs/2401.14524) | 本研究通过利用GPT-3.5模型，在多国宪法文本中进行宝贵的摘要总结，特别关注于与公民权利和义务相关的欧洲国家宪法段落，结果显示其能够准确、连贯且忠实地捕捉到RD主题。 |
| [^36] | [Empathy and the Right to Be an Exception: What LLMs Can and Cannot Do.](http://arxiv.org/abs/2401.14523) | LLMs既有能力归因于信念、欲望、意图和情感，也能在准确性方面不断提高，但他们无法通过共情方法来尊重个体成为例外的权利。他们仅通过识别语言模式判断案件相似性，而无法考虑个体的内部心理状态。我们提出了共情的方法。 |
| [^37] | [Towards Interpretable Physical-Conceptual Catchment-Scale Hydrological Modeling using the Mass-Conserving-Perceptron.](http://arxiv.org/abs/2401.14521) | 本研究通过利用质量守恒感知器构建基于有向图结构的水文模型，实现了对集水区尺度水文过程的解释能力，在保持简洁性的同时能够准确地模拟各种流量动力学行为，并通过引入输入旁路机制进一步优化了模型的表现。 |
| [^38] | [Automated legal reasoning with discretion to act using s(LAW).](http://arxiv.org/abs/2401.14511) | s(LAW)是一种使用s(CASP)模型的框架，用于自动化法律推理和行为裁量，以解决自顶向下和自底向上执行模型无法表达的模糊概念和完整性问题。 |
| [^39] | [Learning When to See for Long-term Traffic Data Collection on Power-constrained Devices.](http://arxiv.org/abs/2401.14504) | 本研究介绍了一种学习基于框架，通过策略性地决定观测时间并从稀疏采样的观测中重建数据流，以实现在电力受限的设备上进行长期交通数据收集的最小性能损失和显著延长系统寿命。 |
| [^40] | [The Case for Co-Designing Model Architectures with Hardware.](http://arxiv.org/abs/2401.14489) | 本文提供了一组指南，通过考虑模型超参数对GPU上执行的计算内核的效率的影响，来最大化变换器模型的运行时性能。相比于具有相似参数数量但形状未经优化的模型，使用高效模型形状的模型可以提高39%的吞吐量且保持准确性。 |
| [^41] | [Scilab-RL: A software framework for efficient reinforcement learning and cognitive modeling research.](http://arxiv.org/abs/2401.14488) | Scilab-RL是一种用于机器人代理的认知建模和增强学习研究的软件框架，通过提供稳定的基线3和OpenAI gym接口，以及实验可视化和超参数优化的功能，最大程度地提高了研究产出。 |
| [^42] | [Design Principles for Generative AI Applications.](http://arxiv.org/abs/2401.14484) | 该论文提出了六项生成式人工智能应用的设计原则，以应对生成式人工智能用户体验的独特特征，并通过设计策略实现这些原则。这些原则将有助于促进生成式人工智能应用的设计。 |
| [^43] | [Unveiling the Unseen: Identifiable Clusters in Trained Depthwise Convolutional Kernels.](http://arxiv.org/abs/2401.14469) | 本研究揭示了深度可分离卷积神经网络中训练的卷积核中出现的可辨别和可解释的模式，这些模式类似于高斯差分函数和它们的一阶和二阶导数。研究通过对数百万个训练滤波器进行无监督聚类，成功将最先进的模型中的大部分滤波器进行分类。 |
| [^44] | [Marabou 2.0: A Versatile Formal Analyzer of Neural Networks.](http://arxiv.org/abs/2401.14461) | Marabou 2.0是一个多功能的神经网络形式分析器，具有创新的架构设计和引入的主要功能和组件。 |
| [^45] | [Wordflow: Social Prompt Engineering for Large Language Models.](http://arxiv.org/abs/2401.14447) | 本文提出了一种名为Wordflow的工具，通过社交提示工程的方式让非专家用户更好地使用大型语言模型（LLMs），并可以轻松创建、运行、共享和发现LLM提示。通过利用现代网络技术，Wordflow允许用户在浏览器中本地和私下运行LLM。 |
| [^46] | [Black-Box Access is Insufficient for Rigorous AI Audits.](http://arxiv.org/abs/2401.14446) | 本文探讨了黑盒审计的局限性以及白盒和超越框架审计的优势，黑盒访问对于严格的人工智能审计是不充分的。 |
| [^47] | [ICASSP 2024 Speech Signal Improvement Challenge.](http://arxiv.org/abs/2401.14444) | ICASSP 2024语音信号改进大挑战旨在促进通信系统中提高语音信号质量的研究。通过引入数据集合成器、客观指标、测试集转录和新的指标，我们评估了13个实时系统和11个非实时系统。 |
| [^48] | [Semantic Sensitivities and Inconsistent Predictions: Measuring the Fragility of NLI Models.](http://arxiv.org/abs/2401.14440) | 这份论文研究发现，最先进的NLI模型对微小的语义保持表面形式变化非常敏感，导致推断结果不一致。其行为与对组合语义的有效理解不同，这对当前NLI模型的可靠性提出了挑战。 |
| [^49] | [Trust model of privacy-concerned, emotionally-aware agents in a cooperative logistics problem.](http://arxiv.org/abs/2401.14436) | 本文提出了一种面向合作物流问题的关注隐私、具备情绪意识的代理人的信任模型。最具创新性的贡献是在合作决策中引入隐私问题，并展示情绪和信任如何促进代理人的性能改善。 |
| [^50] | [Transforming gradient-based techniques into interpretable methods.](http://arxiv.org/abs/2401.14434) | 本文提出了一种基于梯度的技术支持框架，通过建立区别来强调重要区域, 并减少图像噪音。实证调查表明这些区域在促进类别区分方面起关键作用。 |
| [^51] | [M$^3$TN: Multi-gate Mixture-of-Experts based Multi-valued Treatment Network for Uplift Modeling.](http://arxiv.org/abs/2401.14426) | M$^3$TN是一种用于提升建模的新颖网络，通过多门专家混合和明确建模提升的方法，解决了现有方法中存在的一致性和效率问题。 |
| [^52] | [No Longer Trending on Artstation: Prompt Analysis of Generative AI Art.](http://arxiv.org/abs/2401.14425) | 本文研究使用生成型AI进行图像生成，通过分析提示和生成的图像，发现提示主要关注表面美感和流行话题，而非艺术性。 |
| [^53] | [Discovering Mathematical Formulas from Data via GPT-guided Monte Carlo Tree Search.](http://arxiv.org/abs/2401.14424) | 通过结合MCTS和生成式预训练模型，我们提出了一种新的符号回归算法SR-GPT，在发现数据中的数学公式方面取得了显著的改进。 |
| [^54] | [Fuzzy Logic Function as a Post-hoc Explanator of the Nonlinear Classifier.](http://arxiv.org/abs/2401.14417) | 本文研究了使用模糊逻辑函数作为分类器的事后解释器，通过与黑盒分类器进行并行设计，实现了与黑盒分类器相同的决策结果。 |
| [^55] | [Aprendizado de m\'aquina aplicado na eletroqu\'imica.](http://arxiv.org/abs/2401.14413) | 本文系统综述了机器学习技术在电化学应用中的使用情况，并介绍了其在医学诊断、化学品分类和环境监测等方面的重要作用。 |
| [^56] | [Harnessing Neuron Stability to Improve DNN Verification.](http://arxiv.org/abs/2401.14412) | 本论文提出了VeriStable方法，在DNN验证中利用稳定的神经元减少组合复杂性，同时保持抽象的准确性。这种方法与工业化SAT基准共享重要特征，并在有效性和可扩展性方面取得了显著的进展。 |
| [^57] | [CMMU: A Benchmark for Chinese Multi-modal Multi-type Question Understanding and Reasoning.](http://arxiv.org/abs/2401.14011) | CMMU是一个用于中文多模态多类型问题理解和推理的基准测试，涵盖了从小学到高中的知识，提供了多项选择题、多项回答题和填空题三种类型的问题，对于评估多模态大型语言模型的智能水平具有重要意义。 |
| [^58] | [Assumptions and Bounds in the Instrumental Variable Model.](http://arxiv.org/abs/2401.13758) | 本文证明了在工具变量（IV）模型中，具有二进制响应$Y$和二进制处理$X$的情况下，使用接受$K$个状态的仪器$Z$时，关于ACE界限的结果。 |
| [^59] | [Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions.](http://arxiv.org/abs/2401.13324) | 本研究探讨了受算法决策影响的人的信息需求，发现解释往往不能满足他们的关注点，导致对监管框架的理解和遵守产生障碍。为了解决这个问题，研究团队提出了XAI初学者问题库，涵盖了就业预测和健康监测两个领域中受影响利益相关者的信息需求。 |
| [^60] | [Pixel-Wise Recognition for Holistic Surgical Scene Understanding.](http://arxiv.org/abs/2401.11174) | 本文提出了一个整体和多粒度外科场景理解数据集，以及一个基于变形器的模型，该模型有效地结合了全局视频特征提取和局部器械分割，可用于多层次理解外科活动。 |
| [^61] | [Gaussian Adaptive Attention is All You Need: Robust Contextual Representations Across Multiple Modalities.](http://arxiv.org/abs/2401.11143) | 该论文提出了一个名为GAAM的多头高斯自适应注意力机制，用于增强跨多个模态的信息聚合。通过将可学习的均值和方差纳入注意力机制中，GAAM能够动态地重新调整特征的重要性，从而在处理非平稳数据时取得了显著的性能提升，超过了目前现有的注意力技术。该方法的适应性强且参数数量较少，具有改进现有注意力框架的潜力。 |
| [^62] | [Chem-FINESE: Validating Fine-Grained Few-shot Entity Extraction through Text Reconstruction.](http://arxiv.org/abs/2401.10189) | 这篇论文提出了一种名为Chem-FINESE的方法来处理化学领域中细粒度少样本实体提取的问题。该方法通过使用序列到序列的实体提取器和自我验证模块来从输入句子中提取命名实体并重构原始输入句子。实验证明了该方法的有效性和可行性。 |
| [^63] | [DiConStruct: Causal Concept-based Explanations through Black-Box Distillation.](http://arxiv.org/abs/2401.08534) | DiConStruct是一种基于黑盒模型的因果概念解释方法，通过创建结构性因果模型和概念归因方式提供更具可解释性的局部解释。 |
| [^64] | [No-Clean-Reference Image Super-Resolution: Application to Electron Microscopy.](http://arxiv.org/abs/2401.08115) | 这项研究提出了一种无需清洗参考图像的超分辨率方法，通过深度学习实现从噪声低分辨率的电子显微镜图像重建清洁的高分辨率图像。以及使用无需清洗参考的训练和引入新的网络架构。实验结果表明使用真实训练数据可以产生高质量的重建图像。 |
| [^65] | [Multi-task robot data for dual-arm fine manipulation.](http://arxiv.org/abs/2401.07603) | 这篇论文介绍了一个多任务机器人数据集，其中包括双臂精细操作和需要精细操作的任务，并且公开可用。 |
| [^66] | [DevEval: Evaluating Code Generation in Practical Software Projects.](http://arxiv.org/abs/2401.06401) | 本文提出了一个名为DevEval的新基准测试，用于评估实际软件项目中的代码生成。与之前的基准测试相比，DevEval在真实的项目分布、充足的依赖和足够规模的项目背景等方面更贴合实际。通过对五个流行的大型语言模型进行评估，我们揭示了它们在代码生成中的实际能力。 |
| [^67] | [Agent AI: Surveying the Horizons of Multimodal Interaction.](http://arxiv.org/abs/2401.03568) | Agent AI是一种多模态交互系统，可以感知视觉刺激、语言输入和其他环境相关数据，通过将代理体嵌入物理或虚拟环境中来实现更复杂和上下文感知的人工智能系统。 |
| [^68] | [Efficiently Quantifying Individual Agent Importance in Cooperative MARL.](http://arxiv.org/abs/2312.08466) | 本文提出了一种高效量化合作多智能体强化学习中个体智能体重要性的方法，相对于智能体数量具有线性计算复杂度，并与真实的Shapley值以及真实环境中的个体智能体奖励密切相关。 |
| [^69] | [How much can change in a year? Revisiting Evaluation in Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2312.08463) | 本文重访了多智体强化学习（MARL）领域的评估问题，并扩展了之前的数据库，发现许多令人担忧的性能报告趋势仍然存在。 |
| [^70] | [A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly.](http://arxiv.org/abs/2312.02003) | 该论文调查了大型语言模型（LLM）与安全和隐私的相关性。研究发现LLMs在安全和隐私保护方面具有积极影响，但同时也存在潜在的风险、威胁和漏洞。 |
| [^71] | [ArabIcros: AI-Powered Arabic Crossword Puzzle Generation for Educational Applications.](http://arxiv.org/abs/2312.01339) | 本文介绍了基于人工智能技术的阿拉伯语填字游戏生成器ArabIcros，利用先进的语言模型生成独特且具有挑战性的线索，并通过教育性填字游戏提升学习体验，改变传统学习方法的格局。 |
| [^72] | [GPT-4V Takes the Wheel: Promises and Challenges for Pedestrian Behavior Prediction.](http://arxiv.org/abs/2311.14786) | 本论文研究了GPT-4V在自动驾驶的行人行为预测中的应用，通过视觉语言模型的定量和定性评估，解决了传统深度学习方法难以捕捉行人和交通之间动态互动以及缺乏常识推理能力的问题。 |
| [^73] | [Next-Generation Earth System Models: Towards Reliable Hybrid Models for Weather and Climate Applications.](http://arxiv.org/abs/2311.13691) | 这篇论文回顾了机器学习如何改变我们模拟地球系统的能力，并提出了开发混合的人工智能-物理模型、强调AI降尺度方法的稳健性以及推动包容性模型开发的建议。 |
| [^74] | [Piecewise polynomial regression of tame functions via integer programming.](http://arxiv.org/abs/2311.13544) | 本论文提出了使用整数规划对温顺函数进行分段多项式回归的方法，这可以用于估计包含在许多应用中的温顺函数，并且展示了令人期待的计算结果。 |
| [^75] | [Leveraging Generative AI for Clinical Evidence Summarization Needs to Ensure Trustworthiness.](http://arxiv.org/abs/2311.11211) | 这项研究讨论了利用生成型人工智能进行临床证据摘要的可靠性问题，尤其关注开发问责制、公平和包容性的模型的挑战。 |
| [^76] | [ViR: Towards Efficient Vision Retention Backbones.](http://arxiv.org/abs/2310.19731) | ViR提出了一种新的计算机视觉模型，采用双重并行和递归公式，从而在快速推理和并行训练之间取得了最佳平衡，具有竞争力的性能。 |
| [^77] | [A General Framework for Robust G-Invariance in G-Equivariant Networks.](http://arxiv.org/abs/2310.18564) | 这项研究介绍了一种通用方法，通过引入G-三重相关层，在G-等变卷积神经网络中实现强鲁棒性。该方法利用完备的三重相关理论，这使得G-TC层能够在面对不变性攻击时具有强大的鲁棒性，并且能够在分类准确率上相比标准的Max G-Pooling有明显的改善。 |
| [^78] | [Representation Learning with Large Language Models for Recommendation.](http://arxiv.org/abs/2310.15950) | 这篇论文介绍了一个模型-不可知的框架RLMRec，通过使用大语言模型（LLMs）来增强传统的基于ID的推荐系统，并解决了可扩展性问题、仅依赖文本的限制以及提示输入限制等挑战。 |
| [^79] | [Safe Deep Policy Adaptation.](http://arxiv.org/abs/2310.08602) | 该论文提出了SafeDPA，一种新颖的强化学习和控制框架，用于同时解决策略适应和安全强化学习的问题。SafeDPA在仿真环境中联合学习自适应策略和动力学模型，并使用少量真实数据进行微调。在真实世界部署过程中，通过引入基于控制屏障函数的安全过滤器，确保了SafeDPA的安全性。 |
| [^80] | [Security Considerations in AI-Robotics: A Survey of Current Methods, Challenges, and Opportunities.](http://arxiv.org/abs/2310.08565) | 本文调查和分类了AI-机器人系统中的安全问题，包括攻击面、道德和法律问题以及人机交互安全。旨在为用户、开发者和其他利益相关者提供指导。 |
| [^81] | [ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models.](http://arxiv.org/abs/2310.02998) | ECoFLaP提出了一种高效的粗到细的逐层剪枝方法，解决了大型视觉语言模型在压缩和部署时的计算和能耗问题。 |
| [^82] | [MagicDrive: Street View Generation with Diverse 3D Geometry Control.](http://arxiv.org/abs/2310.02601) | MagicDrive是一个新颖的街景生成框架，通过提供多样化的三维几何控制，包括相机姿态、道路地图和三维边界框，以及文本描述，实现了高保真度的街景合成，并捕捉了细致的三维几何信息。 |
| [^83] | [ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events.](http://arxiv.org/abs/2309.12244) | ChaCha是一个利用大型语言模型（LLMs）的聊天机器人，鼓励儿童分享个人事件和相关情绪。通过一个探索性研究，发现儿童将ChaCha视为亲密的朋友，并愿意与其分享各种主题的故事。 |
| [^84] | [Latent Representation and Simulation of Markov Processes via Time-Lagged Information Bottleneck.](http://arxiv.org/abs/2309.07200) | 本文介绍了一种通过时间滞后信息瓶颈的方法，将复杂系统映射到简化表示空间并模拟时间上的大跳跃。实验证明该方法能够准确模拟原始过程的统计特性和动力学，优于现有的时间滞后降维方法。 |
| [^85] | [HC3 Plus: A Semantic-Invariant Human ChatGPT Comparison Corpus.](http://arxiv.org/abs/2309.02731) | 本文介绍了HC3 Plus，一个语义不变的人类ChatGPT对比语料库。与以往的工作相比，该语料库考虑了更多类型的任务，包括语义不变任务。研究发现，在语义不变任务中检测模型生成的文本更加困难。通过大量任务指令微调和Tk-instruct，建立了一个更强大的模型。 |
| [^86] | [WeatherBench 2: A benchmark for the next generation of data-driven global weather models.](http://arxiv.org/abs/2308.15560) | WeatherBench 2更新了全球中期天气预测基准测试，旨在加速数据驱动天气建模的进展，提供了开源评估框架和最新的模型性能指标。此外，还讨论了当前评估设置中的注意事项和未来的挑战。 |
| [^87] | [FlexKBQA: A Flexible LLM-Powered Framework for Few-Shot Knowledge Base Question Answering.](http://arxiv.org/abs/2308.12060) | FlexKBQA使用大型语言模型(LLMs)作为程序翻译器，通过自动化算法从知识库中抽样多样的程序，将其转换为自然语言问题，从而解决少样本知识库问答任务的挑战。 |
| [^88] | [A multiobjective continuation method to compute the regularization path of deep neural networks.](http://arxiv.org/abs/2308.12044) | 本文提出了一种多目标延续方法，用于计算深度神经网络的正则化路径，以解决DNNs中稀疏性和数值效率之间的冲突。 |
| [^89] | [Exploring Link Prediction over Hyper-Relational Temporal Knowledge Graphs Enhanced with Time-Invariant Relational Knowledge.](http://arxiv.org/abs/2307.10219) | 这项研究填补了时间KG和超关系KG推理之间的差距，并开发了两个新的基准超关系TKG数据集。 |
| [^90] | [Progressive Fourier Neural Representation for Sequential Video Compilation.](http://arxiv.org/abs/2306.11305) | 本研究提出了一种渐进傅里叶神经表示方法，通过在每个训练会话中找到自适应且紧凑的傅里叶空间子模块来编码顺序视频数据，克服了现有神经隐式表示方法在多个复杂数据上的泛化能力差的问题。 |
| [^91] | [Is Normalization Indispensable for Multi-domain Federated Learning?.](http://arxiv.org/abs/2306.05879) | 本研究旨在解决联邦学习中的多领域问题。我们提出一种新的方法，FedWon，通过消除规范化步骤来有效地处理来自不同领域的数据。 |
| [^92] | [Offline Prioritized Experience Replay.](http://arxiv.org/abs/2306.05412) | 本文提出了离线优先经验重放（OPER）方法来解决离线强化学习中的分布偏移问题。通过设计一类优先级函数来对高回报的转换进行优先处理，从而改善行为策略，并在此改进的策略约束下优化离线强化学习算法的解决方案。对于离线强化学习，OPER方法是一种有效的解决方案。 |
| [^93] | [Networked Communication for Decentralised Agents in Mean-Field Games.](http://arxiv.org/abs/2306.02766) | 本研究在均场博弈中引入网络通信，提出了一种提高分布式智能体学习效率的方案，并进行了实际实验验证。 |
| [^94] | [MicroSegNet: A Deep Learning Approach for Prostate Segmentation on Micro-Ultrasound Images.](http://arxiv.org/abs/2305.19956) | 本文提出了一种基于深度学习的微型超声图像前列腺分割方法，利用多尺度注释引导的Transformer UNet模型和注释引导的二分类交叉熵损失解决低分辨率和界限不清的挑战，该方法更加关注难以分割的区域。 |
| [^95] | [Sasha: creative goal-oriented reasoning in smart homes with large language models.](http://arxiv.org/abs/2305.09802) | 本论文研究了在智能家居中使用大型语言模型实现用户命令的创意目标导向推理。实验结果显示，这种方法可以创造性地推理，以实现挑战性的目标。 |
| [^96] | [Expectation Maximization Pseudo Labelling for Segmentation with Limited Annotations.](http://arxiv.org/abs/2305.01747) | 本文提出了一种伪标签的泛化方法，称为贝叶斯伪标签，在半监督医学图像分割任务中应用效果良好。 |
| [^97] | [Fusing Structure from Motion and Simulation-Augmented Pose Regression from Optical Flow for Challenging Indoor Environments.](http://arxiv.org/abs/2304.07250) | 本文探讨了如何在室内环境下进行运动目标的定位，使用了结构运动与模拟数据和深度学习技术。研究者整合光流和相对姿态回归方法帮助解决了因运动模糊、光照变化、重复图案和缺乏特征结构等问题而带来的瓶颈，为室内目标定位提供了更好的方案。 |
| [^98] | [Generative Modeling with Flow-Guided Density Ratio Learning.](http://arxiv.org/abs/2303.03714) | FDRL是一种基于流引导的密度比学习的简单且可扩展的生成建模方法，通过训练密度比估计器从逐渐改进的样本中学习，缓解了密度鸿沟问题，并在生成高尺寸图像上表现优于现有基线方法。 |
| [^99] | [Dual RL: Unification and New Methods for Reinforcement and Imitation Learning.](http://arxiv.org/abs/2302.08560) | 这篇论文介绍了双重强化学习的概念，并在一个统一的框架下解释了几种最新深度强化学习算法及模仿学习方法。作者提出了双重模仿学习方法（DIL）直接最小化策略之间的距离，并提出了一种新的离线演员-评论家方法。 |
| [^100] | [Towards Holistic Surgical Scene Understanding.](http://arxiv.org/abs/2212.04582) | 本研究提出了一个新实验框架，PSI-AVA数据集，以实现对机器人辅助下的前列腺癌根治术视频的整体理解。同时，我们的实验结果证明了基于TAPIR的手术场景理解框架的有效性。 |
| [^101] | [Linear-Time Algorithms for Front-Door Adjustment in Causal Graphs.](http://arxiv.org/abs/2211.16468) | 在因果图中，提出了解决前门调整的线性时间算法，通过观察到的中介变量，即使存在未观测到的混淆，也可以识别因果效应。 |
| [^102] | [A Robot Web for Distributed Many-Device Localisation.](http://arxiv.org/abs/2202.03314) | 我们提出了一个基于点对点通信的分布式机器人网络，通过高斯信念传播实现全局定位。该方法具有高效的计算和通信效率，并且对高故障率有一定的容忍度。 |
| [^103] | [On minimizers and convolutional filters: theoretical connections and applications to genome analysis.](http://arxiv.org/abs/2111.08452) | 该论文通过对哈希函数属性进行数学分析，发现在分类字母表上的序列分析中，使用随机高斯初始化的卷积滤波器和最大池化等价于选择一种最小化器排序，能够有效提取与其他最小化器距离较近但与序列中的k-mer相距较远的重要特征。 |

# 详细

[^1]: 生成模型中的手部标注方法

    Annotated Hands for Generative Models. (arXiv:2401.15075v1 [cs.CV])

    [http://arxiv.org/abs/2401.15075](http://arxiv.org/abs/2401.15075)

    本文提出了一种对生成模型进行手部标注的新方法，通过增加三个额外的通道来改进生成手部图像的质量。在两个不同的生成模型上验证了该方法的有效性，并通过使用手部检测器来衡量生成手部图像质量的提高。

    

    生成模型如GAN和扩散模型在图像生成方面表现出色。然而，这些系统在生成手部图像方面却表现出意外的不足。我们提出了一种新颖的训练框架，可以大大提高这些系统生成手部图像的能力。我们的方法是通过在训练图像中增加三个额外的通道来对手部进行标注。这些标注提供额外的结构，促使生成模型生成更高质量的手部图像。我们在两个不同的生成模型上展示了这种方法：生成对抗网络和扩散模型。我们将我们的方法应用于一个新的合成手部图像数据集和包含手部的真实照片上。我们通过使用一个现有的手部检测器来测量生成手部图像质量的提高，从而得到更高的指关节识别置信度。

    Generative models such as GANs and diffusion models have demonstrated impressive image generation capabilities. Despite these successes, these systems are surprisingly poor at creating images with hands. We propose a novel training framework for generative models that substantially improves the ability of such systems to create hand images. Our approach is to augment the training images with three additional channels that provide annotations to hands in the image. These annotations provide additional structure that coax the generative model to produce higher quality hand images. We demonstrate this approach on two different generative models: a generative adversarial network and a diffusion model. We demonstrate our method both on a new synthetic dataset of hand images and also on real photographs that contain hands. We measure the improved quality of the generated hands through higher confidence in finger joint identification using an off-the-shelf hand detector.
    
[^2]: 健康文本简化：消化癌症教育的注释语料库和增强学习的新策略

    Health Text Simplification: An Annotated Corpus for Digestive Cancer Education and Novel Strategies for Reinforcement Learning. (arXiv:2401.15043v1 [cs.CL])

    [http://arxiv.org/abs/2401.15043](http://arxiv.org/abs/2401.15043)

    该论文介绍了一个用于健康文本简化研究的消化癌症教育材料的注释语料库，并探索了基于大型语言模型的简化方法，包括微调、增强学习、增强学习与人类反馈、领域自适应和基于提示的应用。

    

    目标：健康教育材料的阅读水平显著影响信息的可理解性和可接触性，特别是对于少数族裔人群。许多患者教育资源超过了广泛接受的标准的阅读水平和复杂性。在健康信息中，急需高性能的文本简化模型以增强传播和识字能力。这种需要在癌症教育中尤为迫切，有效的预防和筛查教育可以大大减少发病率和死亡率。方法：我们引入了简化的消化癌症（SimpleDC）并行语料库，用于健康文本简化研究。利用SimpleDC和现有的Med-EASi语料库，我们探索了基于大型语言模型（LLM）的简化方法，包括微调、增强学习（RL）、增强学习与人类反馈（RLHF）、领域自适应和基于提示的应用。

    Objective: The reading level of health educational materials significantly influences information understandability and accessibility, particularly for minoritized populations. Many patient educational resources surpass the reading level and complexity of widely accepted standards. There is a critical need for high-performing text simplification models in health information to enhance dissemination and literacy. This need is particularly acute in cancer education, where effective prevention and screening education can substantially reduce morbidity and mortality.  Methods: We introduce Simplified Digestive Cancer (SimpleDC), a parallel corpus of cancer education materials tailored for health text simplification research. Utilizing SimpleDC alongside the existing Med-EASi corpus, we explore Large Language Model (LLM)-based simplification methods, including fine-tuning, reinforcement learning (RL), reinforcement learning with human feedback (RLHF), domain adaptation, and prompt-based app
    
[^3]: PROXYQA：一种用于评估大型语言模型长篇文本生成的替代框架

    PROXYQA: An Alternative Framework for Evaluating Long-Form Text Generation with Large Language Models. (arXiv:2401.15042v1 [cs.CL])

    [http://arxiv.org/abs/2401.15042](http://arxiv.org/abs/2401.15042)

    PROXYQA是一个用于评估大型语言模型长篇文本生成的替代框架，通过生成详尽的内容，并利用评估器和生成内容作为背景环境，根据评估器回答代理问题的表现来评估生成内容的质量。

    

    大型语言模型（LLM）在长篇文本理解任务中取得了显著的成功。然而，它们生成长篇内容（如报告和文章）的能力尚未得到充分探索。当前的基准不足以充分评估LLMs生成信息丰富且全面的内容，因此需要一种更严格的评估方法。在本研究中，我们介绍了一种名为\textsc{ProxyQA}的框架，用于评估长篇文本生成，包括深入人工策划的涵盖多个领域的“元问题”。每个元问题都包含相应的带注释答案的“代理问题”。LLMs被要求根据这些元问题生成详尽的内容。利用评估器并将生成的内容作为背景环境，\textsc{ProxyQA}根据评估器回答“代理问题”的表现评估生成内容的质量。我们检验了多个LLMs，重点关注了...

    Large Language Models (LLMs) have exhibited remarkable success in long-form context comprehension tasks. However, their capacity to generate long contents, such as reports and articles, remains insufficiently explored. Current benchmarks do not adequately assess LLMs' ability to produce informative and comprehensive content, necessitating a more rigorous evaluation approach. In this study, we introduce \textsc{ProxyQA}, a framework for evaluating long-form text generation, comprising in-depth human-curated \textit{meta-questions} spanning various domains. Each meta-question contains corresponding \textit{proxy-questions} with annotated answers. LLMs are prompted to generate extensive content in response to these meta-questions. Utilizing an evaluator and incorporating generated content as background context, \textsc{ProxyQA} evaluates the quality of generated content based on the evaluator's performance in answering the \textit{proxy-questions}. We examine multiple LLMs, emphasizing \t
    
[^4]: Airavata: 引入针对印地语指令调整的LLM

    Airavata: Introducing Hindi Instruction-tuned LLM. (arXiv:2401.15006v1 [cs.CL])

    [http://arxiv.org/abs/2401.15006](http://arxiv.org/abs/2401.15006)

    "Airavata"是一个针对印地语进行指令调整的LLM，通过微调OpenHathi和IndicInstruct数据集，提供更好的协助任务性能，并计划扩展到所有22种计划Indic语言。

    

    我们宣布首次发布了"Airavata"，这是一个针对印地语进行指令调整的LLM。通过将OpenHathi与各种指令调整的印地语数据集进行微调，Airavata更适合辅助任务。除了模型外，我们还分享了IndicInstruct数据集，这是一组用于进一步研究Indic LLM的多样化指令调整数据集。此外，我们还提供了评估基准和评估框架，以评估LLM在印地语任务中的性能。目前，Airavata支持印地语，但我们计划将其扩展到所有22种计划Indic语言。您可以在https://ai4bharat.github.io/airavata上访问所有工件。

    We announce the initial release of "Airavata," an instruction-tuned LLM for Hindi. Airavata was created by fine-tuning OpenHathi with diverse, instruction-tuning Hindi datasets to make it better suited for assistive tasks. Along with the model, we also share the IndicInstruct dataset, which is a collection of diverse instruction-tuning datasets to enable further research for Indic LLMs. Additionally, we present evaluation benchmarks and a framework for assessing LLM performance across tasks in Hindi. Currently, Airavata supports Hindi, but we plan to expand this to all 22 scheduled Indic languages. You can access all artifacts at https://ai4bharat.github.io/airavata.
    
[^5]: 大气：用于边缘-雾-云计算的上下文感知协同物联网架构

    Atmosphere: Context and situational-aware collaborative IoT architecture for edge-fog-cloud computing. (arXiv:2401.14968v1 [cs.DC])

    [http://arxiv.org/abs/2401.14968](http://arxiv.org/abs/2401.14968)

    本文提出了一种解决边缘-雾-云计算中软件架构不足的方法，该架构可以有效利用上下文感知和情境数据分析，并实现相邻层次之间的双向通信。

    

    物联网的普及使得通信容量增加，成本降低，技术也得到了极大的发展。同时，大数据和实时数据分析变得越来越重要，并引起了市民、公共管理和其他组织之间分享数据的前所未有的兴趣，形成了协同物联网。但是，这种数据和基础设施的增长必须伴随着允许利用的软件架构。尽管有各种关注边缘、雾和/或云层上物联网利用的提议，但很难找到一种将这三个层次一起利用起来的软件解决方案，最大限度地利用每个层次的上下文和情境数据分析，并利用相邻层次之间的双向通信。

    The Internet of Things (IoT) has grown significantly in popularity, accompanied by increased capacity and lower cost of communications, and overwhelming development of technologies. At the same time, big data and real-time data analysis have taken on great importance and have been accompanied by unprecedented interest in sharing data among citizens, public administrations and other organisms, giving rise to what is known as the Collaborative Internet of Things. This growth in data and infrastructure must be accompanied by a software architecture that allows its exploitation. Although there are various proposals focused on the exploitation of the IoT at edge, fog and/or cloud levels, it is not easy to find a software solution that exploits the three tiers together, taking maximum advantage not only of the analysis of contextual and situational data at each tier, but also of two-way communications between adjacent ones. In this paper, we propose an architecture that solves these deficien
    
[^6]: 学习通用预测器

    Learning Universal Predictors. (arXiv:2401.14953v1 [cs.LG])

    [http://arxiv.org/abs/2401.14953](http://arxiv.org/abs/2401.14953)

    本论文探索了将Solomonoff Induction（SI）引入神经网络中的潜力，并使用万能图灵机（UTMs）生成的数据来进行元学习，研究结果表明UTM数据是元学习的有价值资源，可以用来训练能够学习通用预测的神经网络。

    

    元学习已经成为一个强大的方法，训练神经网络快速从有限的数据中学习新任务。对不同任务的广泛暴露导致了多功能表示，从而实现了通用问题解决能力。但是，元学习的限制是什么？在这项工作中，我们通过将最强大的通用预测器Solomonoff Induction（SI）通过元学习的极限进行分担，探索其潜力。我们使用万能图灵机（UTMs）生成训练数据，用于将网络暴露于广泛的模式。我们提供了关于UTM数据生成过程和元训练协议的理论分析。我们使用不同复杂性和普适性的算法数据生成器对神经网络架构（如LSTMs、Transformers）进行了全面的实验。我们的结果表明，UTM数据是元学习的宝贵资源，可以用来训练能够学习通用预测的神经网络。

    Meta-learning has emerged as a powerful approach to train neural networks to learn new tasks quickly from limited data. Broad exposure to different tasks leads to versatile representations enabling general problem solving. But, what are the limits of meta-learning? In this work, we explore the potential of amortizing the most powerful universal predictor, namely Solomonoff Induction (SI), into neural networks via leveraging meta-learning to its limits. We use Universal Turing Machines (UTMs) to generate training data used to expose networks to a broad range of patterns. We provide theoretical analysis of the UTM data generation processes and meta-training protocols. We conduct comprehensive experiments with neural architectures (e.g. LSTMs, Transformers) and algorithmic data generators of varying complexity and universality. Our results suggest that UTM data is a valuable resource for meta-learning, and that it can be used to train neural networks capable of learning universal predicti
    
[^7]: 保留-更新-修订以解决对抗训练中的泛化性和鲁棒性的权衡

    Conserve-Update-Revise to Cure Generalization and Robustness Trade-off in Adversarial Training. (arXiv:2401.14948v1 [cs.LG])

    [http://arxiv.org/abs/2401.14948](http://arxiv.org/abs/2401.14948)

    对抗训练在提高神经网络鲁棒性方面取得了进展，但是牺牲了标准和鲁棒泛化之间的权衡。研究发现，选择性地更新特定层可以显著提高网络学习能力。因此，提出了CURE框架，通过选择性保留、更新和修订权重来解决这一问题。这一方法可以有效解决记忆化和过度拟合问题，并提高鲁棒性和泛化性之间的权衡。

    

    对抗训练可以提高神经网络对抗攻击的鲁棒性，但会导致标准泛化和鲁棒泛化之间的权衡。为了揭示驱动这一现象的潜在因素，我们研究了神经网络在从标准设置到对抗设置过渡时的逐层学习能力。经验结果表明，选择性地更新特定层而保留其他层可以大幅增强网络的学习能力。因此，我们提出了一种新的训练框架CURE，利用梯度显著性准则对权重进行选择性保留、更新和修订。重要的是，CURE的设计是数据集和架构不可知的，确保其适用于各种情况。它有效解决了记忆化和过度拟合问题，从而增强了鲁棒性和泛化性之间的权衡，并且这种训练方法还可以

    Adversarial training improves the robustness of neural networks against adversarial attacks, albeit at the expense of the trade-off between standard and robust generalization. To unveil the underlying factors driving this phenomenon, we examine the layer-wise learning capabilities of neural networks during the transition from a standard to an adversarial setting. Our empirical findings demonstrate that selectively updating specific layers while preserving others can substantially enhance the network's learning capacity. We therefore propose CURE, a novel training framework that leverages a gradient prominence criterion to perform selective conservation, updating, and revision of weights. Importantly, CURE is designed to be dataset- and architecture-agnostic, ensuring its applicability across various scenarios. It effectively tackles both memorization and overfitting issues, thus enhancing the trade-off between robustness and generalization and additionally, this training approach also 
    
[^8]: SSDOnt：表示单体设计研究的本体论

    SSDOnt: an Ontology for representing Single-Subject Design Studies. (arXiv:2401.14933v1 [cs.AI])

    [http://arxiv.org/abs/2401.14933](http://arxiv.org/abs/2401.14933)

    SSDOnt是一种用于描述和注释单体设计研究的本体论，为这类研究提供了适当的术语和参考模型。

    

    背景：单体设计在教育和生物医学等多个领域中被使用。然而，目前还没有适合的正式词汇来注释此类研究的详细配置和结果，以获得有关它们的信息。因此，对这些研究设计的搜索很大程度上依赖于对摘要、关键词或全文进行语法搜索，这存在一些限制。目标：介绍SSDOnt，一个用于描述和注释单体设计研究的特定目的本体论，以便随后可以对其进行复杂问题的提问。方法：本体论是按照NeOn方法论开发的。在定义了本体论的要求后，使用描述逻辑描述了一个形式化模型，并在本体论语言OWL 2 DL中实现了该模型。结果：我们展示了本体论如何提供一个具有适当术语的参考模型，用于表示单体设计研究的详细配置和结果。

    Background: Single-Subject Design is used in several areas such as education and biomedicine. However, no suited formal vocabulary exists for annotating the detailed configuration and the results of this type of research studies with the appropriate granularity for looking for information about them. Therefore, the search for those study designs relies heavily on a syntactical search on the abstract, keywords or full text of the publications about the study, which entails some limitations. Objective: To present SSDOnt, a specific purpose ontology for describing and annotating single-subject design studies, so that complex questions can be asked about them afterwards. Methods: The ontology was developed following the NeOn methodology. Once the requirements of the ontology were defined, a formal model was described in a Description Logic and later implemented in the ontology language OWL 2 DL. Results: We show how the ontology provides a reference model with a suitable terminology for th
    
[^9]: LLM是否能记忆本体论？

    Do LLMs Dream of Ontologies?. (arXiv:2401.14931v1 [cs.CL])

    [http://arxiv.org/abs/2401.14931](http://arxiv.org/abs/2401.14931)

    本文研究了通用预训练大型语言模型（LLMs）是否记忆了已知本体论的信息以及记忆的程度，结果显示LLMs部分地了解本体论的概念，记忆程度与其在Web上的流行程度成正比。

    

    大型语言模型（LLMs）最近在自动文本理解和生成方面取得了革命性的进展。这些模型的性能依赖于底层神经网络体系结构的参数数量，这使得LLMs能够记忆训练过程中接触到的大量数据的一部分。本文研究了通用预训练LLMs是否记忆了已知本体论的信息以及记忆的程度。我们的结果表明，LLMs部分地了解本体论：它们可以记忆文本中提到的本体论概念，但其对概念的记忆程度似乎与其在Web上的流行程度成比例变化，因为Web是它们训练材料的主要来源。此外，我们提出了新的度量标准，通过测量不同提示重复、查询语言和确定度的输出一致性来估计LLMs对本体论信息的记忆程度。

    Large language models (LLMs) have recently revolutionized automated text understanding and generation. The performance of these models relies on the high number of parameters of the underlying neural architectures, which allows LLMs to memorize part of the vast quantity of data seen during the training. This paper investigates whether and to what extent general-purpose pre-trained LLMs have memorized information from known ontologies. Our results show that LLMs partially know ontologies: they can, and do indeed, memorize concepts from ontologies mentioned in the text, but the level of memorization of their concepts seems to vary proportionally to their popularity on the Web, the primary source of their training material. We additionally propose new metrics to estimate the degree of memorization of ontological information in LLMs by measuring the consistency of the output produced across different prompt repetitions, query languages, and degrees of determinism.
    
[^10]: 在有限理性人类代理在摩擦任务中进行强化学习干预

    Reinforcement Learning Interventions on Boundedly Rational Human Agents in Frictionful Tasks. (arXiv:2401.14923v1 [cs.AI])

    [http://arxiv.org/abs/2401.14923](http://arxiv.org/abs/2401.14923)

    本论文介绍了行为模型强化学习（BMRL）框架，在摩擦性任务中，AI代理对有限理性人类代理的参数进行干预，通过对人类策略进行解释，帮助理解行为干预。

    

    许多重要的行为变化是具有摩擦的；它们要求个体长期付出努力，但没有即时的满足。在这种情况下，人工智能（AI）代理可以提供个性化的干预，帮助个体坚持自己的目标。在这些设置中，AI代理必须快速个性化（在个体失去兴趣之前）并具有解释性，以帮助我们理解行为干预。在本文中，我们引入了行为模型强化学习（BMRL）框架，其中AI代理对属于有限理性人类代理的马尔可夫决策过程（MDP）的参数进行干预。我们将人类决策者的形式化为一个规划代理，这样我们就能够将不理想的人类策略（不会达到目标的策略）归因于其不适应的MDP参数，比如极低的折扣因子。此外，我们提出了一类可解释的人类模型，捕捉了摩擦任务中的基本行为。

    Many important behavior changes are frictionful; they require individuals to expend effort over a long period with little immediate gratification. Here, an artificial intelligence (AI) agent can provide personalized interventions to help individuals stick to their goals. In these settings, the AI agent must personalize rapidly (before the individual disengages) and interpretably, to help us understand the behavioral interventions. In this paper, we introduce Behavior Model Reinforcement Learning (BMRL), a framework in which an AI agent intervenes on the parameters of a Markov Decision Process (MDP) belonging to a boundedly rational human agent. Our formulation of the human decision-maker as a planning agent allows us to attribute undesirable human policies (ones that do not lead to the goal) to their maladapted MDP parameters, such as an extremely low discount factor. Furthermore, we propose a class of tractable human models that captures fundamental behaviors in frictionful tasks. Int
    
[^11]: AI在基于项目的学习中的未来规划：与学生一起进行共同设计探索

    Charting the Future of AI in Project-Based Learning: A Co-Design Exploration with Students. (arXiv:2401.14915v1 [cs.HC])

    [http://arxiv.org/abs/2401.14915](http://arxiv.org/abs/2401.14915)

    本文介绍了一项与学生共同设计的研究，探索学生在项目化学习中使用人工智能的潜力，并基于学生的视觉对教育目标转变进行分析。研究发现，不同态度的学生对人工智能的使用有不同的偏好。这为未来研究学生与人工智能交互和理解增强学习提供了机会。

    

    学生在学习中越来越多地使用人工智能（AI），这给基于项目的学习（PBL）的评估带来了新的挑战。本文介绍了一项共同设计研究，探索学生的AI使用数据作为PBL评估的新材料的潜力。我们与18名大学生进行了研讨会，鼓励他们设想一个可以自由使用AI进行PBL的另一个世界，同时需要报告这个过程以评估他们的技能和贡献。我们的研讨会产生了各种学生在PBL中使用AI的情景，以及基于学生对教育目标转变的视觉进行分析这些使用的方式。我们还发现对AI持有不同态度的学生在分析和理解AI使用方面有不同的偏好。基于这些发现，我们讨论了关于学生与AI交互和理解AI增强学习的未来研究机会。

    The increasing use of Artificial Intelligence (AI) by students in learning presents new challenges for assessing their learning outcomes in project-based learning (PBL). This paper introduces a co-design study to explore the potential of students' AI usage data as a novel material for PBL assessment. We conducted workshops with 18 college students, encouraging them to speculate an alternative world where they could freely employ AI in PBL while needing to report this process to assess their skills and contributions. Our workshops yielded various scenarios of students' use of AI in PBL and ways of analyzing these uses grounded by students' vision of education goal transformation. We also found students with different attitudes toward AI exhibited distinct preferences in how to analyze and understand the use of AI. Based on these findings, we discuss future research opportunities on student-AI interactions and understanding AI-enhanced learning.
    
[^12]: 跨空间自适应滤波器：集成图拓扑和节点属性以减轻过度平滑问题

    Cross-Space Adaptive Filter: Integrating Graph Topology and Node Attributes for Alleviating the Over-smoothing Problem. (arXiv:2401.14876v1 [cs.LG])

    [http://arxiv.org/abs/2401.14876](http://arxiv.org/abs/2401.14876)

    本论文提出了一种跨空间自适应滤波器（CSF），可以从图拓扑和节点属性空间中提取自适应频率信息，以减轻图卷积网络（GCN）的过度平滑问题。

    

    传统的图卷积网络（GCN）使用低通滤波器从图拓扑中提取低频信号，但当GCN深度增加时可能导致过度平滑问题。为解决这个问题，已经提出了各种方法通过引入从图拓扑中提取的额外滤波器（如高通滤波器）来创建自适应滤波器。然而，这些方法严重依赖拓扑信息，并忽视了节点属性空间，这严重牺牲了深层GCN的表达能力，特别是在处理非同配图时。本文提出了一种跨空间自适应滤波器，称为CSF，能够从拓扑和属性空间中提取自适应频率信息。具体而言，我们首先推导出了一个定制的基于属性的高通滤波器，可以从理论上解释为半监督核岭回归的最小化器。然后，我们将基于拓扑的低通滤波器视为Mercer's核函数。

    The vanilla Graph Convolutional Network (GCN) uses a low-pass filter to extract low-frequency signals from graph topology, which may lead to the over-smoothing problem when GCN goes deep. To this end, various methods have been proposed to create an adaptive filter by incorporating an extra filter (e.g., a high-pass filter) extracted from the graph topology. However, these methods heavily rely on topological information and ignore the node attribute space, which severely sacrifices the expressive power of the deep GCNs, especially when dealing with disassortative graphs. In this paper, we propose a cross-space adaptive filter, called CSF, to produce the adaptive-frequency information extracted from both the topology and attribute spaces. Specifically, we first derive a tailored attribute-based high-pass filter that can be interpreted theoretically as a minimizer for semi-supervised kernel ridge regression. Then, we cast the topology-based low-pass filter as a Mercer's kernel within the 
    
[^13]: 基于记忆的暂时提示交互用于文本-图像分类

    Memory-Inspired Temporal Prompt Interaction for Text-Image Classification. (arXiv:2401.14856v1 [cs.CV])

    [http://arxiv.org/abs/2401.14856](http://arxiv.org/abs/2401.14856)

    本文提出了一种基于记忆的暂时提示交互策略，用于文本-图像分类。该策略受到人类记忆策略的启发，通过两个阶段的操作来进行模态对齐和模拟记忆过程，从而提高了大规模预训练多模态模型的效率。

    

    近年来，大规模预训练多模态模型（LMM）普遍出现，将视觉和语言模态整合起来，在各种自然语言处理和计算机视觉任务中取得了相当大的成功。然而，LMM的增加规模导致了将这些模型用于下游任务的显着计算成本。因此，研究了基于提示的交互策略以更有效地对齐模态。在这种情况下，我们提出了一种受人类记忆策略启发的新型基于提示的多模态交互策略，即Memory-Inspired Temporal Prompt Interaction（MITP）。我们的方法涉及两个阶段，就像人类记忆策略一样：获取阶段和巩固激活阶段。我们利用中间层上的临时提示来模拟获取阶段，利用基于相似性的提示交互来模拟记忆巩固，使用提示生成策略来模拟记忆激活。

    In recent years, large-scale pre-trained multimodal models (LMM) generally emerge to integrate the vision and language modalities, achieving considerable success in various natural language processing and computer vision tasks. The growing size of LMMs, however, results in a significant computational cost for fine-tuning these models for downstream tasks. Hence, prompt-based interaction strategy is studied to align modalities more efficiently. In this contex, we propose a novel prompt-based multimodal interaction strategy inspired by human memory strategy, namely Memory-Inspired Temporal Prompt Interaction (MITP). Our proposed method involves in two stages as in human memory strategy: the acquiring stage, and the consolidation and activation stage. We utilize temporal prompts on intermediate layers to imitate the acquiring stage, leverage similarity-based prompt interaction to imitate memory consolidation, and employ prompt generation strategy to imitate memory activation. The main str
    
[^14]: 机器视觉冰山的解释：通过考虑全面环境条件推进动态测试

    The Machine Vision Iceberg Explained: Advancing Dynamic Testing by Considering Holistic Environmental Circumstances. (arXiv:2401.14831v1 [cs.RO])

    [http://arxiv.org/abs/2401.14831](http://arxiv.org/abs/2401.14831)

    本研究提出了一个名为粒度等级的层次级别模型，用于更好地理解机器视觉在不同环境条件下的操作。这一模型旨在提供对影响机器视觉功能的各个实体的全面概述。

    

    当前的机器视觉测试是否会带来冰山的危险？本研究深入探讨了机器视觉（MV）测试的领域，这在高度自动驾驶（HAD）系统中是非常必要的。借助向冰山航行的隐喻，我们讨论了当前测试策略中潜在的缺陷。我们强调了对如何处理MV在开发过程中的不透明功能的更深入了解的紧迫需要，因为忽视了这些考虑可能会造成生命的丧失。我们的主要贡献是层次级别模型，我们将其称为粒度等级。该模型鼓励对MV操作环境条件的各个层次进行精细探索，从个体实体之间的关系到整个环境场景。该模型旨在提供对可能影响MV功能的所有实体的全面概述。

    Are we heading for an iceberg with the current testing of machine vision? This work delves into the landscape of Machine Vision (MV) testing, which is heavily required in Highly Automated Driving (HAD) systems. Utilizing the metaphorical notion of navigating towards an iceberg, we discuss the potential shortcomings concealed within current testing strategies. We emphasize the urgent need for a deeper understanding of how to deal with the opaque functions of MV in development processes. As overlooked considerations can cost lives. Our main contribution is the hierarchical level model, which we call Granularity Grades. The model encourages a refined exploration of the multi-scaled depths of understanding about the circumstances of environments in which MV is intended to operate. This model aims to provide a holistic overview of all entities that may impact MV functions, ranging from relations of individual entities like object attributes to entire environmental scenes. The application of
    
[^15]: 关于马尔可夫奖励在多目标、风险敏感和模态任务中表达的局限性

    On the Limitations of Markovian Rewards to Express Multi-Objective, Risk-Sensitive, and Modal Tasks. (arXiv:2401.14811v1 [cs.AI])

    [http://arxiv.org/abs/2401.14811](http://arxiv.org/abs/2401.14811)

    本文研究了强化学习中标量、马尔可夫奖励函数的表达能力，并确定了它们的一些局限性。我们发现这些奖励函数无法表达多目标、风险敏感和模态任务中的大部分实例。

    

    本文研究了强化学习中标量、马尔可夫奖励函数的表达能力，并确定了它们的一些局限性。具体来说，我们研究了三类强化学习任务：多目标强化学习、风险敏感强化学习和模态强化学习。对于每一类任务，我们导出了描述什么样的问题可以使用标量、马尔可夫奖励函数来表达的必要和充分条件。此外，我们发现在这三个类别中，标量、马尔可夫奖励函数无法表达大部分实例。通过这项研究，我们为了解标准奖励函数可以和不能表达的内容做出了更完整的贡献。除此之外，我们还将模态问题作为一个新的问题类别引入，因为在强化学习文献中，目前尚未对其进行系统性研究。我们还简要概述了通过定制的强化学习算法解决所讨论问题的一些方法。

    In this paper, we study the expressivity of scalar, Markovian reward functions in Reinforcement Learning (RL), and identify several limitations to what they can express. Specifically, we look at three classes of RL tasks; multi-objective RL, risk-sensitive RL, and modal RL. For each class, we derive necessary and sufficient conditions that describe when a problem in this class can be expressed using a scalar, Markovian reward. Moreover, we find that scalar, Markovian rewards are unable to express most of the instances in each of these three classes. We thereby contribute to a more complete understanding of what standard reward functions can and cannot express. In addition to this, we also call attention to modal problems as a new class of problems, since they have so far not been given any systematic treatment in the RL literature. We also briefly outline some approaches for solving some of the problems we discuss, by means of bespoke RL algorithms.
    
[^16]: 用于金融情感分析的大规模语言模型适应

    Large Language Model Adaptation for Financial Sentiment Analysis. (arXiv:2401.14777v1 [cs.CL])

    [http://arxiv.org/abs/2401.14777](http://arxiv.org/abs/2401.14777)

    本文研究了针对金融领域的大规模语言模型适应方法，并重点关注金融情感分析。通过在金融文件和说明书上进行精细调优，展示了基础模型在目标领域的适应能力。

    

    最近，自然语言处理（NLP）在金融机构中变得越来越重要，因为它可以提供有关公司和市场的金融文件的高度有价值的见解。然而，金融领域的景观对NLP提出了额外的挑战，因为文本的复杂性和特定术语的使用。即使使用具有出色的自然语言理解和生成能力的大规模语言模型（LLM），通用语言模型在专门针对金融的任务上也往往表现不佳。本文提出了一项关于以金融领域为目标的LLM适应方法研究，并高度关注金融情感分析。为此，我们使用了各种广泛的策略来适应两个参数低于15亿的基础模型。我们展示了通过在金融文档和说明书上进行精细调优，这些基础模型可以适应目标领域。此外，我们观察到小型LLM具有相似的适应能力。

    Natural language processing (NLP) has recently gained relevance within financial institutions by providing highly valuable insights into companies and markets' financial documents. However, the landscape of the financial domain presents extra challenges for NLP, due to the complexity of the texts and the use of specific terminology. Generalist language models tend to fall short in tasks specifically tailored for finance, even when using large language models (LLMs) with great natural language understanding and generative capabilities. This paper presents a study on LLM adaptation methods targeted at the financial domain and with high emphasis on financial sentiment analysis. To this purpose, two foundation models with less than 1.5B parameters have been adapted using a wide range of strategies. We show that through careful fine-tuning on both financial documents and instructions, these foundation models can be adapted to the target domain. Moreover, we observe that small LLMs have comp
    
[^17]: 基于拓扑感知的能量模型均衡探索：Toric QC-LDPC码和Hyperbolic MET QC-LDPC码

    Topology-Aware Exploration of Energy-Based Models Equilibrium: Toric QC-LDPC Codes and Hyperbolic MET QC-LDPC Codes. (arXiv:2401.14749v1 [cs.IT])

    [http://arxiv.org/abs/2401.14749](http://arxiv.org/abs/2401.14749)

    本文介绍了一种在不均匀分布的电荷和不规则网格上实现能量模型均衡的方法，通过使用QC-LDPC码和玻尔兹曼机，将系统的维度扩展，将电荷替换为循环物质，并通过循环移位表示距离。通过这种方法，可以将不规则网格转化为均匀配置，适用于不同的拓扑结构。该方法还解决了代码在图形概率模型中的评估问题，并提供了在不同拓扑下玻尔兹曼机达到均衡状态的严格证明。

    

    本文提出了一种在不均匀分布的电荷和不规则网格上实现ISING哈密顿量均衡的方法。采用（多边缘）QC-LDPC码和玻尔兹曼机，我们的方法涉及对系统的维度扩展，用循环物质替代电荷，并通过循环移位表示距离。这导致电荷系统在空间上的系统映射，将不规则网格转化为均匀配置，适用于Torical和Circular Hyperboloid拓扑。本文涵盖了与QC-LDPC码、多边缘QC-LDPC码和玻尔兹曼机相关的基本定义和符号。它探讨了用于评估分区函数的代码在图形概率模型中的边际化问题，包括精确和近似估计技术。本文提供了严格的证明，证明了在Torical和Circular Hyper拓扑下，玻尔兹曼机可以达到均衡状态。

    This paper presents a method for achieving equilibrium in the ISING Hamiltonian when confronted with unevenly distributed charges on an irregular grid. Employing (Multi-Edge) QC-LDPC codes and the Boltzmann machine, our approach involves dimensionally expanding the system, substituting charges with circulants, and representing distances through circulant shifts. This results in a systematic mapping of the charge system onto a space, transforming the irregular grid into a uniform configuration, applicable to Torical and Circular Hyperboloid Topologies. The paper covers fundamental definitions and notations related to QC-LDPC Codes, Multi-Edge QC-LDPC codes, and the Boltzmann machine. It explores the marginalization problem in code on the graph probabilistic models for evaluating the partition function, encompassing exact and approximate estimation techniques. Rigorous proof is provided for the attainability of equilibrium states for the Boltzmann machine under Torical and Circular Hyper
    
[^18]: 用于增强家庭环境安全和福祉的合成多模态数据集

    Synthetic Multimodal Dataset for Empowering Safety and Well-being in Home Environments. (arXiv:2401.14743v1 [cs.AI])

    [http://arxiv.org/abs/2401.14743](http://arxiv.org/abs/2401.14743)

    本文介绍了一个合成的多模态数据集，结合了3D虚拟空间模拟器的视频数据和描述活动时空背景的知识图，旨在解决家庭环境中的危险情况，并提供给研究人员和从业者作为资源来开发创新解决方案，以提升安全和福祉。

    

    本文介绍了一个合成的多模态数据集，该数据集将来自3D虚拟空间模拟器的视频数据与描述活动的时空背景的知识图融合在一起。该数据集是为社会问题知识图推理挑战（KGRC4SI）开发的，重点是识别和解决家庭环境中的危险情况。该数据集可供公众使用，作为研究人员和从业者开发创新解决方案的有价值的资源，以识别人类行为并提升安全和福祉。

    This paper presents a synthetic multimodal dataset of daily activities that fuses video data from a 3D virtual space simulator with knowledge graphs depicting the spatiotemporal context of the activities. The dataset is developed for the Knowledge Graph Reasoning Challenge for Social Issues (KGRC4SI), which focuses on identifying and addressing hazardous situations in the home environment. The dataset is available to the public as a valuable resource for researchers and practitioners developing innovative solutions recognizing human behaviors to enhance safety and well-being in
    
[^19]: 用声学和大型语言模型融合进行交替和回应预测

    Turn-taking and Backchannel Prediction with Acoustic and Large Language Model Fusion. (arXiv:2401.14717v1 [cs.CL])

    [http://arxiv.org/abs/2401.14717](http://arxiv.org/abs/2401.14717)

    这个论文提出了一种利用声学和语言模型进行交替和回应预测的方法，通过融合这两种模型，可以在口语对话中实现更加自然和对话式的互动。

    

    我们提出了一种连续预测口语对话中交替和回应位置的方法，通过融合神经声学模型和大型语言模型（LLM）。在Switchboard人际对话数据集上的实验表明，我们的方法始终优于单模态的基线模型。我们还开发了一种新颖的多任务指令微调策略，以进一步从LLM编码的知识中受益，从而提高了性能。我们的方法展示了使用组合的LLM和声学模型在人类和语音AI代理之间实现更自然和对话式互动的潜力。

    We propose an approach for continuous prediction of turn-taking and backchanneling locations in spoken dialogue by fusing a neural acoustic model with a large language model (LLM). Experiments on the Switchboard human-human conversation dataset demonstrate that our approach consistently outperforms the baseline models with single modality. We also develop a novel multi-task instruction fine-tuning strategy to further benefit from LLM-encoded knowledge for understanding the tasks and conversational contexts, leading to additional improvements. Our approach demonstrates the potential of combined LLMs and acoustic models for a more natural and conversational interaction between humans and speech-enabled AI agents.
    
[^20]: 通过特征解缠来缓解对抗鲁棒性中的特征差距

    Mitigating Feature Gap for Adversarial Robustness by Feature Disentanglement. (arXiv:2401.14707v1 [cs.CV])

    [http://arxiv.org/abs/2401.14707](http://arxiv.org/abs/2401.14707)

    这项研究提出了一种通过特征解缠来缓解对抗鲁棒性中特征差距的方法，该方法明确建模和消除导致特征差距的潜在特征，有效提升了鲁棒性。

    

    深度神经网络对对抗样本很容易受到攻击。对抗微调方法旨在通过对已经在自然情况下进行预训练的模型进行对抗式微调来提升对抗鲁棒性。然而，我们发现对抗样本中的一些潜在特征被对抗扰动所混淆，并导致自然样本和对抗样本在最后一层隐藏层的特征之间出现意外增加的差距。为了解决这个问题，我们提出了一种基于解缠的方法来明确建模和进一步消除导致特征差距的潜在特征。具体而言，我们引入了特征解缠器，将对抗样本的潜在特征与对抗样本的特征分离开来，从而通过消除潜在特征来提升鲁棒性。此外，我们通过将预训练模型中的特征与对抗样本在微调模型中的特征对齐，进一步从自然样本的特征中获益，避免混淆。

    Deep neural networks are vulnerable to adversarial samples. Adversarial fine-tuning methods aim to enhance adversarial robustness through fine-tuning the naturally pre-trained model in an adversarial training manner. However, we identify that some latent features of adversarial samples are confused by adversarial perturbation and lead to an unexpectedly increasing gap between features in the last hidden layer of natural and adversarial samples. To address this issue, we propose a disentanglement-based approach to explicitly model and further remove the latent features that cause the feature gap. Specifically, we introduce a feature disentangler to separate out the latent features from the features of the adversarial samples, thereby boosting robustness by eliminating the latent features. Besides, we align features in the pre-trained model with features of adversarial samples in the fine-tuned model, to further benefit from the features from natural samples without confusion. Empirical 
    
[^21]: FairSample: 高效训练公平准确的图卷积神经网络

    FairSample: Training Fair and Accurate Graph Convolutional Neural Networks Efficiently. (arXiv:2401.14702v1 [cs.LG])

    [http://arxiv.org/abs/2401.14702](http://arxiv.org/abs/2401.14702)

    本文提出了一种名为FairSample的框架，旨在高效训练公平准确的图卷积神经网络。该框架通过对图结构进行纠正，并使用可学习的邻居采样策略来同时减轻图卷积神经网络中的图结构偏见、节点属性偏见和模型参数偏见。

    

    随着图卷积神经网络在许多关键应用中的应用，图卷积神经网络中的公平性越来越成为一个重要问题。许多真实世界的图中存在对敏感群体的社会偏见。在这篇论文中，我们采用了公平性的经典概念“人口统计平均值”，并解决了高效训练公平准确的图卷积神经网络的挑战。我们对图结构偏见、节点属性偏见和模型参数对图卷积神经网络的人口统计平均性能的影响进行了深入分析。我们的洞察力导致了FairSample，一个可以同时减轻这三种偏见的框架。我们采用了两种直观的策略来纠正图结构。首先，我们在不同敏感群体但具有相似节点特征的节点之间插入边。其次，为了增强模型的公平性并保持模型的质量，我们使用强化学习方法开发了一种可学习的邻居采样策略。

    Fairness in Graph Convolutional Neural Networks (GCNs) becomes a more and more important concern as GCNs are adopted in many crucial applications. Societal biases against sensitive groups may exist in many real world graphs. GCNs trained on those graphs may be vulnerable to being affected by such biases. In this paper, we adopt the well-known fairness notion of demographic parity and tackle the challenge of training fair and accurate GCNs efficiently. We present an in-depth analysis on how graph structure bias, node attribute bias, and model parameters may affect the demographic parity of GCNs. Our insights lead to FairSample, a framework that jointly mitigates the three types of biases. We employ two intuitive strategies to rectify graph structures. First, we inject edges across nodes that are in different sensitive groups but similar in node features. Second, to enhance model fairness and retain model quality, we develop a learnable neighbor sampling policy using reinforcement learni
    
[^22]: 反思LLM生成数据的真实性：对LLM生成数据的追踪研究

    Under the Surface: Tracking the Artifactuality of LLM-Generated Data. (arXiv:2401.14698v1 [cs.CL])

    [http://arxiv.org/abs/2401.14698](http://arxiv.org/abs/2401.14698)

    本研究是针对大型语言模型（LLM）生成的人工数据的追踪研究，将各种类型的LLM生成文本数据进行了汇总和测试，并揭示了隐藏的质量和多样性问题。这是第一次对LLM生成数据进行综合分析和比较，并引发了对人工数据质量的关注。

    

    本研究探讨了大型语言模型（LLM）在生成人工数据方面的不断扩大的作用。LLM越来越多地用于生成多种输出，包括注释、偏好、指令提示、模拟对话和自由文本。由于这些LLM生成数据形式在应用中经常交叉，它们相互影响，并引发了对训练循环中合并的人工数据质量和多样性的重大关注，形成了一个人工数据生态系统。据我们所知，这是第一项研究将各种类型的LLM生成文本数据汇总起来，从更严格受限的数据如“任务标签”到更自由的“自由文本”。然后我们对LLM生成的人工数据的质量和影响进行了压力测试，并与人工数据在各种现有基准上进行比较。尽管人工数据能够匹配人类表现，但本文揭示了隐藏的巨大隐患。

    This work delves into the expanding role of large language models (LLMs) in generating artificial data. LLMs are increasingly employed to create a variety of outputs, including annotations, preferences, instruction prompts, simulated dialogues, and free text. As these forms of LLM-generated data often intersect in their application, they exert mutual influence on each other and raise significant concerns about the quality and diversity of the artificial data incorporated into training cycles, leading to an artificial data ecosystem. To the best of our knowledge, this is the first study to aggregate various types of LLM-generated text data, from more tightly constrained data like "task labels" to more lightly constrained "free-form text". We then stress test the quality and implications of LLM-generated artificial data, comparing it with human data across various existing benchmarks. Despite artificial data's capability to match human performance, this paper reveals significant hidden d
    
[^23]: 渐进中点混合用于边距平衡和适度扩展的方法

    Asymptotic Midpoint Mixup for Margin Balancing and Moderate Broadening. (arXiv:2401.14696v1 [cs.LG])

    [http://arxiv.org/abs/2401.14696](http://arxiv.org/abs/2401.14696)

    提出了渐进中点混合方法来解决粗细转移学习中的类内崩塌问题。该方法通过逐渐将增强特征移动至类间特征对的中点，实现了边距平衡以及适度扩展边距的效果。

    

    在特征空间中，特征之间的崩塌导致了表示学习中的一些关键问题，使得特征无法区分。基于插值的数据增强方法，如mixup，在减轻不同类别之间的崩塌问题上显示出了有效性，这被称为类间崩塌。然而，粗细转移学习中引起的类内崩塌并未在增强方法中讨论。为了解决这些问题，我们提出了一种更好的特征增强方法，即渐进中点混合。该方法通过插值生成增强特征，但将它们逐渐移动到类间特征对的中点。结果是，该方法产生了两个效果：1）平衡所有类别的边距，2）仅适度扩展边距，直到达到最大置信度。我们通过测量可视化表示的对齐性和均匀性来经验分析了崩塌效应。然后，我们验证了增强方法所带来的类内崩塌问题。

    In the feature space, the collapse between features invokes critical problems in representation learning by remaining the features undistinguished. Interpolation-based augmentation methods such as mixup have shown their effectiveness in relieving the collapse problem between different classes, called inter-class collapse. However, intra-class collapse raised in coarse-to-fine transfer learning has not been discussed in the augmentation approach. To address them, we propose a better feature augmentation method, asymptotic midpoint mixup. The method generates augmented features by interpolation but gradually moves them toward the midpoint of inter-class feature pairs. As a result, the method induces two effects: 1) balancing the margin for all classes and 2) only moderately broadening the margin until it holds maximal confidence. We empirically analyze the collapse effects by measuring alignment and uniformity with visualizing representations. Then, we validate the intra-class collapse e
    
[^24]: TA-RNN：一种基于注意力机制的面向电子健康记录的时间感知递归神经网络架构

    TA-RNN: an Attention-based Time-aware Recurrent Neural Network Architecture for Electronic Health Records. (arXiv:2401.14694v1 [cs.LG])

    [http://arxiv.org/abs/2401.14694](http://arxiv.org/abs/2401.14694)

    TA-RNN和TA-RNN-AE是两种基于RNN的可解释深度学习架构，用于分析电子健康记录并预测患者的临床结果。这些架构考虑了EHR数据的不规则性和时间间隔，并采用时间嵌入的方法解决了这些问题。

    

    动机：电子健康记录（EHR）是患者医疗历史的全面资源。EHR对于利用深度学习（DL）等先进技术至关重要，使医疗提供者能够分析大量数据，提取有价值的见解，并做出精确、数据驱动的临床决策。DL方法如递归神经网络（RNN）已被用于分析EHR以建模疾病进展并预测诊断。然而，这些方法并没有解决EHR数据中一些固有的不规则性，如临床访问之间的不规则时间间隔。此外，大多数DL模型都不可解释。在这项研究中，我们提出了两种基于RNN的可解释DL架构，分别是时间感知RNN（TA-RNN）和TA-RNN-Autoencoder（TA-RNN-AE），用于预测下一次访问和多次未来访问中患者的临床结果。为了减轻不规则时间间隔的影响，我们提出了时间嵌入的方法将时间信息纳入模型中。

    Motivation: Electronic Health Records (EHR) represent a comprehensive resource of a patient's medical history. EHR are essential for utilizing advanced technologies such as deep learning (DL), enabling healthcare providers to analyze extensive data, extract valuable insights, and make precise and data-driven clinical decisions. DL methods such as Recurrent Neural Networks (RNN) have been utilized to analyze EHR to model disease progression and predict diagnosis. However, these methods do not address some inherent irregularities in EHR data such as irregular time intervals between clinical visits. Furthermore, most DL models are not interpretable. In this study, we propose two interpretable DL architectures based on RNN, namely Time-Aware RNN (TA-RNN) and TA-RNN-Autoencoder (TA-RNN-AE) to predict patient's clinical outcome in EHR at next visit and multiple visits ahead, respectively. To mitigate the impact of irregular time intervals, we propose incorporating time embedding of the elaps
    
[^25]: PepGB: 通过图神经网络促进肽药物发现

    PepGB: Facilitating peptide drug discovery via graph neural networks. (arXiv:2401.14665v1 [q-bio.BM])

    [http://arxiv.org/abs/2401.14665](http://arxiv.org/abs/2401.14665)

    本研究提出了一个名为PepGB的深度学习框架，通过图神经网络结合细粒度的扰动模块和基于对比学习的肽段预训练表示，以促进肽段早期药物发现中的肽-蛋白相互作用预测。

    

    肽段具有很大的生物医学潜力，是有前景的药物候选物。目前，大部分获批的肽药物直接来自于经过深入研究的自然人类肽段。在广阔而未开发的生物化学空间中，利用先进的深度学习技术识别新型肽药物是非常必要的。尽管已经开发了各种基于计算方法来加速肽段早期药物发现，但现有模型面临过拟合和缺乏普适性的挑战，主要是由于实验数据规模有限，分布不平衡，质量不一致。在本研究中，我们提出了PepGB，一个用于通过预测肽-蛋白相互作用（PepPIs）来促进肽段早期药物发现的深度学习框架。PepGB采用图神经网络，结合了细粒度的扰动模块和基于对比学习的肽段预训练表示的双视图目标来预测PepPIs。通过严格的评估，我们证明了PepGB在预测PepPIs方面的有效性和鲁棒性。

    Peptides offer great biomedical potential and serve as promising drug candidates. Currently, the majority of approved peptide drugs are directly derived from well-explored natural human peptides. It is quite necessary to utilize advanced deep learning techniques to identify novel peptide drugs in the vast, unexplored biochemical space. Despite various in silico methods having been developed to accelerate peptide early drug discovery, existing models face challenges of overfitting and lacking generalizability due to the limited size, imbalanced distribution and inconsistent quality of experimental data. In this study, we propose PepGB, a deep learning framework to facilitate peptide early drug discovery by predicting peptide-protein interactions (PepPIs). Employing graph neural networks, PepGB incorporates a fine-grained perturbation module and a dual-view objective with contrastive learning-based peptide pre-trained representation to predict PepPIs. Through rigorous evaluations, we dem
    
[^26]: 高效约束生成在随机最短路径问题中的应用

    Efficient Constraint Generation for Stochastic Shortest Path Problems. (arXiv:2401.14636v1 [cs.AI])

    [http://arxiv.org/abs/2401.14636](http://arxiv.org/abs/2401.14636)

    本文提出了一个高效的约束生成技术，通过忽略次优操作和避免不必要的成本计算，解决了随机最短路径问题中的计算效率问题。实验证明，应用这一技术的CG-iLAO*算法在解决问题的速度上比LRTDP和iLAO*有显著提升。

    

    目前解决随机最短路径问题的方法是通过应用Bellman备份来找到状态的成本，而最先进的方法使用启发式策略选择需要备份和修剪的状态。这些算法的一个基本限制是需要在每个状态备份期间计算每个适用操作的成本，这导致对于被识别为次优的操作进行了不必要的计算。我们提出了规划和运筹学之间的新联系，并利用这个框架解决了这个不必要计算的问题，引入了一种高效的随机最短路径问题约束生成技术。这种技术使算法能够忽略次优操作并避免计算它们的成本。我们还将这种新技术应用于iLAO*算法，得到了一个新的算法CG-iLAO*。我们的实验证明，CG-iLAO*忽略了最多57%的iLAO*操作，并且比LRTDP和iLAO*解决问题的速度提高了8倍和3倍。

    Current methods for solving Stochastic Shortest Path Problems (SSPs) find states' costs-to-go by applying Bellman backups, where state-of-the-art methods employ heuristics to select states to back up and prune. A fundamental limitation of these algorithms is their need to compute the cost-to-go for every applicable action during each state backup, leading to unnecessary computation for actions identified as sub-optimal. We present new connections between planning and operations research and, using this framework, we address this issue of unnecessary computation by introducing an efficient version of constraint generation for SSPs. This technique allows algorithms to ignore sub-optimal actions and avoid computing their costs-to-go. We also apply our novel technique to iLAO* resulting in a new algorithm, CG-iLAO*. Our experiments show that CG-iLAO* ignores up to 57% of iLAO*'s actions and it solves problems up to 8x and 3x faster than LRTDP and iLAO*.
    
[^27]: 《对中文拼写检查模型的领域适应能力进行实证研究》

    An Empirical Investigation of Domain Adaptation Ability for Chinese Spelling Check Models. (arXiv:2401.14630v1 [cs.CL])

    [http://arxiv.org/abs/2401.14630](http://arxiv.org/abs/2401.14630)

    该论文通过构建领域特定术语的新数据集，对各种典型的中文拼写检查（CSC）模型的领域适应能力进行了全面评估，结果表明这些模型在新领域中的性能显著下降。

    

    中文拼写检查（CSC）是自然语言处理（NLP）领域中一项有意义的任务，旨在检测中文文本中的拼写错误，然后对这些错误进行纠正。然而，CSC模型基于预训练的语言模型，这些模型在一般语料库上进行训练。因此，当面临涉及特定领域术语的下游任务时，它们的性能可能会下降。在本文中，我们通过构建三个包含财经、医疗和法律领域丰富领域特定术语的新数据集，对各种典型的CSC模型的领域适应能力进行了全面评估。然后，我们在相应领域特定的测试数据集中进行了实证研究，以确定几种典型CSC模型的跨域适应能力。我们还测试了流行的大型语言模型ChatGPT的性能。实验证明，在新领域中，CSC模型的性能显著下降。

    Chinese Spelling Check (CSC) is a meaningful task in the area of Natural Language Processing (NLP) which aims at detecting spelling errors in Chinese texts and then correcting these errors. However, CSC models are based on pretrained language models, which are trained on a general corpus. Consequently, their performance may drop when confronted with downstream tasks involving domain-specific terms. In this paper, we conduct a thorough evaluation about the domain adaption ability of various typical CSC models by building three new datasets encompassing rich domain-specific terms from the financial, medical, and legal domains. Then we conduct empirical investigations in the corresponding domain-specific test datasets to ascertain the cross-domain adaptation ability of several typical CSC models. We also test the performance of the popular large language model ChatGPT. As shown in our experiments, the performances of the CSC models drop significantly in the new domains.
    
[^28]: 《基于机器/深度学习的软件工程研究中可解释性的系统文献综述》

    A Systematic Literature Review on Explainability for Machine/Deep Learning-based Software Engineering Research. (arXiv:2401.14617v1 [cs.SE])

    [http://arxiv.org/abs/2401.14617](http://arxiv.org/abs/2401.14617)

    本文通过对机器/深度学习的软件工程领域中可解释性的系统文献综述，总结了XAI技术在软件工程中的应用情况，旨在提高AI模型的可解释性以解决实际部署中的不确定性和风险问题。

    

    人工智能算法，特别是机器学习和深度学习，在软件工程领域取得了显著的成就，并得到了广泛的应用，但由于它们的黑盒特性，这些具有潜力的AI驱动的软件工程模型离实际部署还有很大的差距。这种缺乏可解释性对于在关键任务中应用这些模型，如漏洞检测，决策透明性至关重要，却带来了不必要的风险。本文通过对SE领域中旨在提高AI模型可解释性的方法进行系统文献综述来阐明这个跨学科领域。该综述覆盖了SE和AI学术会议和期刊中出现的研究，涵盖了21个独特的SE任务的63篇论文。基于三个关键的研究问题，我们旨在总结XAI技术在SE任务中的应用情况。

    The remarkable achievements of Artificial Intelligence (AI) algorithms, particularly in Machine Learning (ML) and Deep Learning (DL), have fueled their extensive deployment across multiple sectors, including Software Engineering (SE). However, due to their black-box nature, these promising AI-driven SE models are still far from being deployed in practice. This lack of explainability poses unwanted risks for their applications in critical tasks, such as vulnerability detection, where decision-making transparency is of paramount importance. This paper endeavors to elucidate this interdisciplinary domain by presenting a systematic literature review of approaches that aim to improve the explainability of AI models within the context of SE. The review canvasses work appearing in the most prominent SE & AI conferences and journals, and spans 63 papers across 21 unique SE tasks. Based on three key Research Questions (RQs), we aim to (1) summarize the SE tasks where XAI techniques have shown s
    
[^29]: 替代性言论：补充对抗叙事的方法以改善讨论（arXiv:2401.14616v1 [cs.CL]）

    Alternative Speech: Complementary Method to Counter-Narrative for Better Discourse. (arXiv:2401.14616v1 [cs.CL])

    [http://arxiv.org/abs/2401.14616](http://arxiv.org/abs/2401.14616)

    该论文引入了“替代性言论”作为直接对抗仇恨言论的新方法，并提供了构建所需数据集的指导。替代性言论通过提供实际可行的替代方案，考虑环境因素并促使演讲者改变，为解决社会问题提供有用工具。将替代性言论与对抗叙事结合使用可以更有效地对抗仇恨言论，补充了对抗叙事的能力。

    

    我们引入了“替代性言论”的概念，作为直接对抗仇恨言论和补充叙事限制的新方式。替代性言论通过在真实场景中提供言论级别的修正，考虑周围环境并促使演讲者改变，为仇恨言论提供实际可行的替代方案。此外，替代性言论可以与对抗叙事一起对抗仇恨言论，为解决种族歧视和性别不平等等社会问题提供有用工具。我们提出了这个新概念，并提供了构建所需数据集的详细指导。通过讨论，我们证明将替代性言论与对抗叙事相结合可以是对抗仇恨言论更有效的策略，补充了对抗叙事的具体性和引导能力。本文提出了处理仇恨言论的另一种视角，提供了可行的补救措施来补充当前的限制。

    We introduce the concept of "Alternative Speech" as a new way to directly combat hate speech and complement the limitations of counter-narrative. An alternative speech provides practical alternatives to hate speech in real-world scenarios by offering speech-level corrections to speakers while considering the surrounding context and promoting speakers to reform. Further, an alternative speech can combat hate speech alongside counter-narratives, offering a useful tool to address social issues such as racial discrimination and gender inequality. We propose the new concept and provide detailed guidelines for constructing the necessary dataset. Through discussion, we demonstrate that combining alternative speech and counter-narrative can be a more effective strategy for combating hate speech by complementing specificity and guiding capacity of counter-narrative. This paper presents another perspective for dealing with hate speech, offering viable remedies to complement the constraints of cu
    
[^30]: 通过多智能体对话提高诊断准确度：利用大型语言模型减少认知偏差

    Enhancing Diagnostic Accuracy through Multi-Agent Conversations: Using Large Language Models to Mitigate Cognitive Bias. (arXiv:2401.14589v1 [cs.CL])

    [http://arxiv.org/abs/2401.14589](http://arxiv.org/abs/2401.14589)

    本研究旨在通过利用大型语言模型和多智能体对话的方式来减轻临床决策中的认知偏差，并评估其对提高诊断准确性的有效性。

    

    背景：临床决策中的认知偏差显著导致诊断错误和次优患者结果。解决这些偏差问题在医疗领域面临巨大挑战。本研究通过利用大型语言模型（LLMs）在多智能体框架中减轻这些偏差的作用。我们通过多智能体对话模拟临床决策过程，并评估其对改善诊断准确性的有效性。方法：从文献中找到了总共16个已发表和未发表的病例报告，其中认知偏差导致误诊。在多智能体系统中，我们利用 GPT-4 Turbo 促进四个模拟智能体之间的交互，以复制临床团队动态。每个智能体都有独特的角色：1) 在考虑讨论后进行初步和最终诊断。2) 充当魔鬼的代言人，以纠正确认偏差和锚定偏差。3) 充当导师和促进者。

    Background: Cognitive biases in clinical decision-making significantly contribute to errors in diagnosis and suboptimal patient outcomes. Addressing these biases presents a formidable challenge in the medical field. This study explores the role of large language models (LLMs) in mitigating these biases through the utilization of a multi-agent framework. We simulate the clinical decision-making processes through multi-agent conversation and evaluate its efficacy in improving diagnostic accuracy. Methods: A total of 16 published and unpublished case reports where cognitive biases have resulted in misdiagnoses were identified from the literature. In the multi-agent system, we leveraged GPT-4 Turbo to facilitate interactions among four simulated agents to replicate clinical team dynamics. Each agent has a distinct role: 1) To make the initial and final diagnosis after considering the discussions, 2) The devil's advocate and correct confirmation and anchoring bias, 3) The tutor and facilita
    
[^31]: 向包容性驱动：重新审视自动驾驶车辆中的车内交互

    Driving Towards Inclusion: Revisiting In-Vehicle Interaction in Autonomous Vehicles. (arXiv:2401.14571v1 [cs.HC])

    [http://arxiv.org/abs/2401.14571](http://arxiv.org/abs/2401.14571)

    本文综述了自动驾驶车辆中车内人机交互的现状和新兴技术，并提出了以用户为中心的包容性HCI设计原则，旨在增强乘客体验。

    

    本文综述了目前自动驾驶车辆中车内人机交互（HCI）的现状，特别关注包容性和可访问性。本研究旨在考察自动驾驶车辆中包容性HCI的以用户为中心的设计原则，评估现有HCI系统，并确定可能增强乘客体验的新兴技术。本文首先概述了自动驾驶车辆技术的现状，然后对这一背景下HCI的重要性进行了分析。接下来，本文综述了包容性HCI设计原则的现有文献，并评估了当前自动驾驶车辆中HCI系统的有效性。本文还确定了可能增强乘客体验的新兴技术，如语音激活界面、触觉反馈系统和增强现实显示。最后，本文总结了研究的重要发现，并讨论了未来的研究方向。

    This paper presents a comprehensive literature review of the current state of in-vehicle human-computer interaction (HCI) in the context of self-driving vehicles, with a specific focus on inclusion and accessibility. This study's aim is to examine the user-centered design principles for inclusive HCI in self-driving vehicles, evaluate existing HCI systems, and identify emerging technologies that have the potential to enhance the passenger experience. The paper begins by providing an overview of the current state of self-driving vehicle technology, followed by an examination of the importance of HCI in this context. Next, the paper reviews the existing literature on inclusive HCI design principles and evaluates the effectiveness of current HCI systems in self-driving vehicles. The paper also identifies emerging technologies that have the potential to enhance the passenger experience, such as voice-activated interfaces, haptic feedback systems, and augmented reality displays. Finally, th
    
[^32]: 自适应机器翻译的语言建模方法

    Language Modelling Approaches to Adaptive Machine Translation. (arXiv:2401.14559v1 [cs.CL])

    [http://arxiv.org/abs/2401.14559](http://arxiv.org/abs/2401.14559)

    自适应机器翻译中的语言建模方法，通过利用大型语言模型(LLMs)来在特定上下文中学习、改进翻译质量，解决了在域适应中因缺乏域内数据而导致翻译不一致的问题。

    

    一致性是高质量翻译的关键要求。在特定领域项目中，遵循预定义的术语和适应更正后的翻译尤为重要。机器翻译在域适应方面取得了显著进展。然而，在翻译环境中，由于缺乏专门的数据集和术语，或者可用的域内翻译不一致且不准确，导致域内数据稀缺现象普遍存在。在没有足够域内数据用于微调机器翻译模型的情况下，生成与相关上下文一致的翻译是具有挑战性的。虽然实时适应可以利用较少量的域内数据实时改进翻译质量，但由于受到上下文限制和效率约束，仍然具有挑战性。最近，大型语言模型（LLMs）展示了在上下文中学习的有趣能力，通过学习复制特定的输入输出来改进翻译效果。

    Consistency is a key requirement of high-quality translation. It is especially important to adhere to pre-approved terminology and adapt to corrected translations in domain-specific projects. Machine translation (MT) has achieved significant progress in the area of domain adaptation. However, in-domain data scarcity is common in translation settings, due to the lack of specialised datasets and terminology, or inconsistency and inaccuracy of available in-domain translations. In such scenarios where there is insufficient in-domain data to fine-tune MT models, producing translations that are consistent with the relevant context is challenging. While real-time adaptation can make use of smaller amounts of in-domain data to improve the translation on the fly, it remains challenging due to supported context limitations and efficiency constraints. Large language models (LLMs) have recently shown interesting capabilities of in-context learning, where they learn to replicate certain input-outpu
    
[^33]: 探索音乐根源：应用音频嵌入来增强生成音乐模型的影响力归因

    Exploring Musical Roots: Applying Audio Embeddings to Empower Influence Attribution for a Generative Music Model. (arXiv:2401.14542v1 [cs.SD])

    [http://arxiv.org/abs/2401.14542](http://arxiv.org/abs/2401.14542)

    本文提出了一种方法来识别音乐音频中相似的作品，以便了解生成音乐模型的训练数据归因。通过应用CLMR和CLAP嵌入到相似度测量中，我们验证了该方法的有效性，并观察了对音频示例进行修改对相似度的影响。

    

    每个艺术家都有自己的创作过程，从先前的艺术家和作品中汲取灵感。如今，生成音乐模型已经自动化了这种“灵感”。然而，这些模型的黑匣子性质使得其创作输出的影响力来源无法被清楚地辨认。因此，用户可能会不经意地盗用、滥用或复制现有艺术家的作品。我们建立了一个可复制的方法来系统地识别音乐音频中相似的作品，以便了解训练数据的归因。我们方法的关键之一是利用有效的音乐音频相似度度量。我们将应用CLMR和CLAP嵌入到相似度测量中，并比较其效果，这些嵌入用于训练VampNet，一个最近的开源生成音乐模型中的500万个音频片段。我们通过人类听觉研究验证了这种方法。我们还探讨了对音频示例进行修改（如音高变化、时间拉伸、背景噪音）对相似度的影响。

    Every artist has a creative process that draws inspiration from previous artists and their works. Today, "inspiration" has been automated by generative music models. The black box nature of these models obscures the identity of the works that influence their creative output. As a result, users may inadvertently appropriate, misuse, or copy existing artists' works. We establish a replicable methodology to systematically identify similar pieces of music audio in a manner that is useful for understanding training data attribution. A key aspect of our approach is to harness an effective music audio similarity measure. We compare the effect of applying CLMR and CLAP embeddings to similarity measurement in a set of 5 million audio clips used to train VampNet, a recent open source generative music model. We validate this approach with a human listening study. We also explore the effect that modifications of an audio example (e.g., pitch shifting, time stretching, background noise) have on sim
    
[^34]: 大型语言模型中的相对价值偏差

    Relative Value Biases in Large Language Models. (arXiv:2401.14530v1 [cs.CL])

    [http://arxiv.org/abs/2401.14530](http://arxiv.org/abs/2401.14530)

    该研究发现大型语言模型在做选择时表现出了与人类和动物相似的相对价值偏差，这对于理解人类选择中的背景依赖性机制具有重要意义。

    

    人类和动物在强化学习方面的研究表明，即使那些选项与较低的绝对奖励相关，他们更倾向于选择过去相对更好结果的选项。本研究测试了大型语言模型是否会表现出类似的偏差。我们让gpt-4-1106-preview(GPT-4 Turbo)和Llama-2-70B在最大化回报的目标下反复在选项对之间进行选择。每个提示中都包含了先前结果的完整记录。两个模型表现出了与人类和动物观察到的相对价值决策偏差类似的行为。更明确地进行结果之间的相对比较会放大这种偏差，而促使模型估计预期结果会使偏差消失。这些结果对于了解人类选择中贡献到背景依赖性的潜在机制具有重要意义。

    Studies of reinforcement learning in humans and animals have demonstrated a preference for options that yielded relatively better outcomes in the past, even when those options are associated with lower absolute reward. The present study tested whether large language models would exhibit a similar bias. We had gpt-4-1106-preview (GPT-4 Turbo) and Llama-2-70B make repeated choices between pairs of options with the goal of maximizing payoffs. A complete record of previous outcomes was included in each prompt. Both models exhibited relative value decision biases similar to those observed in humans and animals. Making relative comparisons among outcomes more explicit magnified the bias, whereas prompting the models to estimate expected outcomes caused the bias to disappear. These results have implications for the potential mechanisms that contribute to context-dependent choice in human agents.
    
[^35]: 评估GPT-3.5在共享主题的欧洲宪法文本中的意识和摘要能力

    Evaluating GPT-3.5's Awareness and Summarization Abilities for European Constitutional Texts with Shared Topics. (arXiv:2401.14524v1 [cs.CL])

    [http://arxiv.org/abs/2401.14524](http://arxiv.org/abs/2401.14524)

    本研究通过利用GPT-3.5模型，在多国宪法文本中进行宝贵的摘要总结，特别关注于与公民权利和义务相关的欧洲国家宪法段落，结果显示其能够准确、连贯且忠实地捕捉到RD主题。

    

    宪法是支撑政府和社会结构的基础法律文件。因此，它们不仅是国家文化和社会独特性的反映，还有助于确定普遍重要的主题，如公民的权利和义务（RD）。在这项工作中，我们利用著名的GPT-3.5，利用生成式大型语言模型来理解超越国界的宪法段落。我们研究的一个重要贡献是抽象摘要在多源宪法文本集合上的新应用，重点关注与RD主题相关的欧洲国家宪法段落。我们的结果表明，GPT-3.5具有意义，能够产生涵盖欧洲国家RD主题的信息丰富、连贯和忠实的摘要。

    Constitutions are foundational legal documents that underpin the governmental and societal structures. As such, they are a reflection of a nation's cultural and social uniqueness, but also contribute to establish topics of universal importance, like citizens' rights and duties (RD). In this work, using the renowned GPT-3.5, we leverage generative large language models to understand constitutional passages that transcend national boundaries. A key contribution of our study is the introduction of a novel application of abstractive summarization on a multi-source collection of constitutional texts, with a focus on European countries' constitution passages related to RD topics. Our results show the meaningfulness of GPT-3.5 to produce informative, coherent and faithful summaries capturing RD topics across European countries.
    
[^36]: 共情与成为一个例外的权利：LLMs可以做什么，不能做什么

    Empathy and the Right to Be an Exception: What LLMs Can and Cannot Do. (arXiv:2401.14523v1 [cs.CY])

    [http://arxiv.org/abs/2401.14523](http://arxiv.org/abs/2401.14523)

    LLMs既有能力归因于信念、欲望、意图和情感，也能在准确性方面不断提高，但他们无法通过共情方法来尊重个体成为例外的权利。他们仅通过识别语言模式判断案件相似性，而无法考虑个体的内部心理状态。我们提出了共情的方法。

    

    大语言模型（LLMs）性能的进步导致一些研究者提出了人工智能（AI）中理论心智（ToM）的出现。LLMs能够归因于信念、欲望、意图和情感，并且它们在准确性方面会有所提高。与人类特有的共情方法不同，它们通过识别数据集中通常不包括的语言模式来学习归因心理状态。我们问LLMs的无法共情是否会妨碍它们尊重个体成为一个例外的权利，即是否会妨碍它们基于对个体的个性敏感性进行性格评估和行为预测。LLMs能否认真考虑个体的主张，即他们的情况是基于信念、欲望和意图等内部心理状态而不同，还是仅限于基于其与他人的相似之处来判断该案件？我们提出共情的方法

    Advances in the performance of large language models (LLMs) have led some researchers to propose the emergence of theory of mind (ToM) in artificial intelligence (AI). LLMs can attribute beliefs, desires, intentions, and emotions, and they will improve in their accuracy. Rather than employing the characteristically human method of empathy, they learn to attribute mental states by recognizing linguistic patterns in a dataset that typically do not include that individual. We ask whether LLMs' inability to empathize precludes them from honoring an individual's right to be an exception, that is, from making assessments of character and predictions of behavior that reflect appropriate sensitivity to a person's individuality. Can LLMs seriously consider an individual's claim that their case is different based on internal mental states like beliefs, desires, and intentions, or are they limited to judging that case based on its similarities to others? We propose that the method of empathy has 
    
[^37]: 以质量守恒感知器为基础，实现可解释的物理-概念集水区尺度水文建模

    Towards Interpretable Physical-Conceptual Catchment-Scale Hydrological Modeling using the Mass-Conserving-Perceptron. (arXiv:2401.14521v1 [cs.LG])

    [http://arxiv.org/abs/2401.14521](http://arxiv.org/abs/2401.14521)

    本研究通过利用质量守恒感知器构建基于有向图结构的水文模型，实现了对集水区尺度水文过程的解释能力，在保持简洁性的同时能够准确地模拟各种流量动力学行为，并通过引入输入旁路机制进一步优化了模型的表现。

    

    本研究探讨了利用机器学习技术开发简洁可解释的集水区尺度水文模型的可行性，采用基于质量守恒感知器（MCP）的有向图结构作为基本计算单元。我们关注的是单个位置的结构复杂性（深度），而不是对大样本集水区具有普适性的广度。目标是发现一个最小的表示（单元状态数和流量路径数），用于表示能够解释给定集水区输入状态和输出行为的主要过程，特别强调模拟全范围（高、中、低）的流量动力学。我们发现，在我们的研究区域，采用类似HyMod的架构，具有3个单元状态和2个主要流动路径，能够实现这样的表示，但引入输入旁路机制可以显著改善水文图的时间和形状。

    We investigate the applicability of machine learning technologies to the development of parsimonious, interpretable, catchment-scale hydrologic models using directed-graph architectures based on the mass-conserving perceptron (MCP) as the fundamental computational unit. Here, we focus on architectural complexity (depth) at a single location, rather than universal applicability (breadth) across large samples of catchments. The goal is to discover a minimal representation (numbers of cell-states and flow paths) that represents the dominant processes that can explain the input-state-output behaviors of a given catchment, with particular emphasis given to simulating the full range (high, medium, and low) of flow dynamics. We find that a HyMod-like architecture with three cell-states and two major flow pathways achieves such a representation at our study location, but that the additional incorporation of an input-bypass mechanism significantly improves the timing and shape of the hydrograph
    
[^38]: 使用s(LAW)进行自动化法律推理与行为裁量

    Automated legal reasoning with discretion to act using s(LAW). (arXiv:2401.14511v1 [cs.AI])

    [http://arxiv.org/abs/2401.14511](http://arxiv.org/abs/2401.14511)

    s(LAW)是一种使用s(CASP)模型的框架，用于自动化法律推理和行为裁量，以解决自顶向下和自底向上执行模型无法表达的模糊概念和完整性问题。

    

    自动化法律推理及其在智能合约和自动化决策中的应用越来越受到关注。在这个背景下，道德和法律问题使得自动推理器需要以人类可理解的方式来解释给出的建议。逻辑编程，特别是答案集编程，具有丰富的语义，可以非常简洁地表达复杂知识。然而，在基于Prolog的自顶向下执行模型和基于ASP的自底向上执行模型中，无法表达行为裁量和其他模糊概念，如歧义，并且在ASP中的理由是不完整和/或不可扩展的。我们提出使用s(CASP)，一种用于谓词ASP的自顶向下执行模型，根据一组模式来建模模糊概念。我们实现了一个框架，称为s(LAW)，用于建模、推理和解释适用的法律，并通过翻译（和基准测试）一个代表性用例，即入学标准进行验证。

    Automated legal reasoning and its application in smart contracts and automated decisions are increasingly attracting interest. In this context, ethical and legal concerns make it necessary for automated reasoners to justify in human-understandable terms the advice given. Logic Programming, specially Answer Set Programming, has a rich semantics and has been used to very concisely express complex knowledge. However, modelling discretionality to act and other vague concepts such as ambiguity cannot be expressed in top-down execution models based on Prolog, and in bottom-up execution models based on ASP the justifications are incomplete and/or not scalable. We propose to use s(CASP), a top-down execution model for predicate ASP, to model vague concepts following a set of patterns. We have implemented a framework, called s(LAW), to model, reason, and justify the applicable legislation and validate it by translating (and benchmarking) a representative use case, the criteria for the admission
    
[^39]: 学习何时在电力受限设备上进行长期交通数据收集

    Learning When to See for Long-term Traffic Data Collection on Power-constrained Devices. (arXiv:2401.14504v1 [eess.SY])

    [http://arxiv.org/abs/2401.14504](http://arxiv.org/abs/2401.14504)

    本研究介绍了一种学习基于框架，通过策略性地决定观测时间并从稀疏采样的观测中重建数据流，以实现在电力受限的设备上进行长期交通数据收集的最小性能损失和显著延长系统寿命。

    

    收集交通数据对于交通系统和城市规划至关重要，并且通常更希望通过易于部署但电力受限的设备进行，这是由于电力和网络基础设施的不可用性或高成本所致。有限的电力意味着数据收集持续时间和准确性/分辨率之间不可避免的权衡。我们介绍了一种新颖的基于学习的框架，通过策略性地决定电池供电设备的观测时间，并从稀疏采样的观测中重建完整的数据流，从而实现最小的性能损失和显著延长系统寿命。我们的框架由预测器、控制器和估计器组成。预测器利用历史数据来预测固定时间范围内的未来趋势。控制器使用这些预测来确定下一个最优的数据收集时间。最后，估计器从采样观测中重建完整的数据配置文件。我们评估了该系统的性能。

    Collecting traffic data is crucial for transportation systems and urban planning, and is often more desirable through easy-to-deploy but power-constrained devices, due to the unavailability or high cost of power and network infrastructure. The limited power means an inevitable trade-off between data collection duration and accuracy/resolution. We introduce a novel learning-based framework that strategically decides observation timings for battery-powered devices and reconstructs the full data stream from sparsely sampled observations, resulting in minimal performance loss and a significantly prolonged system lifetime. Our framework comprises a predictor, a controller, and an estimator. The predictor utilizes historical data to forecast future trends within a fixed time horizon. The controller uses the forecasts to determine the next optimal timing for data collection. Finally, the estimator reconstructs the complete data profile from the sampled observations. We evaluate the performanc
    
[^40]: 与硬件共同设计模型架构的理由

    The Case for Co-Designing Model Architectures with Hardware. (arXiv:2401.14489v1 [cs.DC])

    [http://arxiv.org/abs/2401.14489](http://arxiv.org/abs/2401.14489)

    本文提供了一组指南，通过考虑模型超参数对GPU上执行的计算内核的效率的影响，来最大化变换器模型的运行时性能。相比于具有相似参数数量但形状未经优化的模型，使用高效模型形状的模型可以提高39%的吞吐量且保持准确性。

    

    虽然GPU负责训练大部分最先进的深度学习模型，但在设计新的深度学习模型时往往忽视了其架构的影响。因此，将深度学习模型修改为更适合目标硬件可以显著提高深度学习训练和推理的运行时性能。本文提供了一组指南，用于使用户最大程度地提高他们的变换器模型的运行时性能。这些指南是通过仔细考虑控制模型形状的各种模型超参数对GPU上执行的底层计算内核的效率的影响而创建的。我们发现具有高效模型形状的模型的吞吐量比具有相似参数数量但形状未经优化的模型高出39％，同时保持准确性。

    While GPUs are responsible for training the vast majority of state-of-the-art deep learning models, the implications of their architecture are often overlooked when designing new deep learning (DL) models. As a consequence, modifying a DL model to be more amenable to the target hardware can significantly improve the runtime performance of DL training and inference. In this paper, we provide a set of guidelines for users to maximize the runtime performance of their transformer models. These guidelines have been created by carefully considering the impact of various model hyperparameters controlling model shape on the efficiency of the underlying computation kernels executed on the GPU. We find the throughput of models with efficient model shapes is up to 39\% higher while preserving accuracy compared to models with a similar number of parameters but with unoptimized shapes.
    
[^41]: Scilab-RL：用于高效增强学习和认知建模研究的软件框架

    Scilab-RL: A software framework for efficient reinforcement learning and cognitive modeling research. (arXiv:2401.14488v1 [cs.LG])

    [http://arxiv.org/abs/2401.14488](http://arxiv.org/abs/2401.14488)

    Scilab-RL是一种用于机器人代理的认知建模和增强学习研究的软件框架，通过提供稳定的基线3和OpenAI gym接口，以及实验可视化和超参数优化的功能，最大程度地提高了研究产出。

    

    研究认知建模和增强学习的一个问题是，研究人员花费太多时间来设置适当的计算框架进行实验。存在许多当前增强学习算法的开源实现，但缺乏一个模块化的工具套件，结合不同的机器人模拟器和平台、数据可视化、超参数优化和基准实验。为解决这个问题，我们提出了Scilab-RL，这是一个用于机器人代理的认知建模和增强学习研究的软件框架。该框架专注于使用稳定的基线3和OpenAI gym接口进行目标条件增强学习。它提供了原生的实验可视化和超参数优化的可能性。我们描述了这些功能如何使研究人员只需最少的时间和精力就能进行实验，从而最大程度地提高研究产出。

    One problem with researching cognitive modeling and reinforcement learning (RL) is that researchers spend too much time on setting up an appropriate computational framework for their experiments. Many open source implementations of current RL algorithms exist, but there is a lack of a modular suite of tools combining different robotic simulators and platforms, data visualization, hyperparameter optimization, and baseline experiments. To address this problem, we present Scilab-RL, a software framework for efficient research in cognitive modeling and reinforcement learning for robotic agents. The framework focuses on goal-conditioned reinforcement learning using Stable Baselines 3 and the OpenAI gym interface. It enables native possibilities for experiment visualizations and hyperparameter optimization. We describe how these features enable researchers to conduct experiments with minimal time effort, thus maximizing research output.
    
[^42]: 生成式人工智能应用的设计原则

    Design Principles for Generative AI Applications. (arXiv:2401.14484v1 [cs.HC])

    [http://arxiv.org/abs/2401.14484](http://arxiv.org/abs/2401.14484)

    该论文提出了六项生成式人工智能应用的设计原则，以应对生成式人工智能用户体验的独特特征，并通过设计策略实现这些原则。这些原则将有助于促进生成式人工智能应用的设计。

    

    生成式人工智能应用面临着独特的设计挑战。随着生成式人工智能技术越来越多地应用于主流应用程序中，迫切需要指导如何设计用户体验以促进有效和安全使用。我们提出了六项生成式人工智能应用的设计原则，针对生成式人工智能用户体验的独特特征，对AI应用设计中已知问题进行了新的解释和扩展。每个原则都配有一套通过用户体验能力或设计过程来实现该原则的设计策略。这些原则和策略是通过文献综述、设计实践反馈、与真实世界生成式人工智能应用的验证以及两个生成式人工智能应用的设计过程中的融入而发展起来的。我们预计这些原则将有助于促进生成式人工智能应用的设计。

    Generative AI applications present unique design challenges. As generative AI technologies are increasingly being incorporated into mainstream applications, there is an urgent need for guidance on how to design user experiences that foster effective and safe use. We present six principles for the design of generative AI applications that address unique characteristics of generative AI UX and offer new interpretations and extensions of known issues in the design of AI applications. Each principle is coupled with a set of design strategies for implementing that principle via UX capabilities or through the design process. The principles and strategies were developed through an iterative process involving literature review, feedback from design practitioners, validation against real-world generative AI applications, and incorporation into the design process of two generative AI applications. We anticipate the principles to usefully inform the design of generative AI applications by driving
    
[^43]: 揭示看不见的：训练的深度可分离卷积核中的可识别聚类

    Unveiling the Unseen: Identifiable Clusters in Trained Depthwise Convolutional Kernels. (arXiv:2401.14469v1 [cs.LG])

    [http://arxiv.org/abs/2401.14469](http://arxiv.org/abs/2401.14469)

    本研究揭示了深度可分离卷积神经网络中训练的卷积核中出现的可辨别和可解释的模式，这些模式类似于高斯差分函数和它们的一阶和二阶导数。研究通过对数百万个训练滤波器进行无监督聚类，成功将最先进的模型中的大部分滤波器进行分类。

    

    最近深度可分离卷积神经网络(DS-CNNs)的进展已经导致了新颖的架构，通过显着的可扩展性和准确性差距超越了经典CNNs的性能。本文揭示了DS-CNN架构的另一个引人注目的特性：在其所有层的训练深度卷积核中出现了可辨别和可解释的模式。通过对数百万个不同大小和来自各种模型的训练滤波器的广泛分析，我们使用自编码器的无监督聚类将这些滤波器分类。令人惊讶的是，这些模式收敛成几个主要的聚类，

    Recent advances in depthwise-separable convolutional neural networks (DS-CNNs) have led to novel architectures, that surpass the performance of classical CNNs, by a considerable scalability and accuracy margin. This paper reveals another striking property of DS-CNN architectures: discernible and explainable patterns emerge in their trained depthwise convolutional kernels in all layers. Through an extensive analysis of millions of trained filters, with different sizes and from various models, we employed unsupervised clustering with autoencoders, to categorize these filters. Astonishingly, the patterns converged into a few main clusters, each resembling the difference of Gaussian (DoG) functions, and their first and second-order derivatives. Notably, we were able to classify over 95\% and 90\% of the filters from state-of-the-art ConvNextV2 and ConvNeXt models, respectively. This finding is not merely a technological curiosity; it echoes the foundational models neuroscientists have long
    
[^44]: Marabou 2.0: 一个多功能的神经网络形式分析器

    Marabou 2.0: A Versatile Formal Analyzer of Neural Networks. (arXiv:2401.14461v1 [cs.AI])

    [http://arxiv.org/abs/2401.14461](http://arxiv.org/abs/2401.14461)

    Marabou 2.0是一个多功能的神经网络形式分析器，具有创新的架构设计和引入的主要功能和组件。

    

    本文是关于Marabou框架2.0版本的综合系统描述，用于神经网络的形式分析。我们讨论了工具的架构设计，并介绍了自初始发布以来引入的主要功能和组件。

    This paper serves as a comprehensive system description of version 2.0 of the Marabou framework for formal analysis of neural networks. We discuss the tool's architectural design and highlight the major features and components introduced since its initial release.
    
[^45]: Wordflow: 大型语言模型的社交提示工程

    Wordflow: Social Prompt Engineering for Large Language Models. (arXiv:2401.14447v1 [cs.HC])

    [http://arxiv.org/abs/2401.14447](http://arxiv.org/abs/2401.14447)

    本文提出了一种名为Wordflow的工具，通过社交提示工程的方式让非专家用户更好地使用大型语言模型（LLMs），并可以轻松创建、运行、共享和发现LLM提示。通过利用现代网络技术，Wordflow允许用户在浏览器中本地和私下运行LLM。

    

    大型语言模型（LLMs）需要精心设计的提示才能有效使用。对于非专家来说，这是一个具有挑战性的过程，因为他们对人工智能技术不那么熟悉。虽然研究人员提出了一些技术和工具来帮助LLM用户设计提示，但这些作品主要针对的是AI应用开发者而不是非专家。为了填补这一研究空白，我们提出了社交提示工程，这是一种利用社交计算技术促进协作提示设计的新范式。为了研究社交提示工程，我们介绍了Wordflow，一个开源的社交文本编辑器，使普通用户可以轻松创建、运行、共享和发现LLM提示。此外，通过利用现代网络技术，Wordflow允许用户在其浏览器中本地和私下运行LLM。两个使用场景突出了社交提示工程和我们的工具如何增强普通人与LLM的交互。

    Large language models (LLMs) require well-crafted prompts for effective use. Prompt engineering, the process of designing prompts, is challenging, particularly for non-experts who are less familiar with AI technologies. While researchers have proposed techniques and tools to assist LLM users in prompt design, these works primarily target AI application developers rather than non-experts. To address this research gap, we propose social prompt engineering, a novel paradigm that leverages social computing techniques to facilitate collaborative prompt design. To investigate social prompt engineering, we introduce Wordflow, an open-source and social text editor that enables everyday users to easily create, run, share, and discover LLM prompts. Additionally, by leveraging modern web technologies, Wordflow allows users to run LLMs locally and privately in their browsers. Two usage scenarios highlight how social prompt engineering and our tool can enhance laypeople's interaction with LLMs. Wor
    
[^46]: 黑盒访问对于严格的人工智能审计是不充分的

    Black-Box Access is Insufficient for Rigorous AI Audits. (arXiv:2401.14446v1 [cs.CY])

    [http://arxiv.org/abs/2401.14446](http://arxiv.org/abs/2401.14446)

    本文探讨了黑盒审计的局限性以及白盒和超越框架审计的优势，黑盒访问对于严格的人工智能审计是不充分的。

    

    外部对人工智能系统的审计被越来越多地认为是人工智能治理的一个关键机制。审计的有效性取决于审计员被授予的系统访问程度。近期对最先进的人工智能系统的审计主要依赖于黑盒访问，审计员只能查询系统并观察其输出。然而，对系统内部工作方式（例如权重、激活、梯度）的透明访问允许审计员进行更强的攻击，更全面地解释模型，并进行精细调整。同时，对其培训和部署信息的超越框架访问（例如方法论、代码、文档、超参数、数据、部署细节、内部评估结果）允许审计员审查开发过程，并设计更具针对性的评估。在本文中，我们研究了黑盒审计的局限性以及白盒和超越框架审计的优势。我们还讨论了技术和生理上的优势。

    External audits of AI systems are increasingly recognized as a key mechanism for AI governance. The effectiveness of an audit, however, depends on the degree of system access granted to auditors. Recent audits of state-of-the-art AI systems have primarily relied on black-box access, in which auditors can only query the system and observe its outputs. However, white-box access to the system's inner workings (e.g., weights, activations, gradients) allows an auditor to perform stronger attacks, more thoroughly interpret models, and conduct fine-tuning. Meanwhile, outside-the-box access to its training and deployment information (e.g., methodology, code, documentation, hyperparameters, data, deployment details, findings from internal evaluations) allows for auditors to scrutinize the development process and design more targeted evaluations. In this paper, we examine the limitations of black-box audits and the advantages of white- and outside-the-box audits. We also discuss technical, physi
    
[^47]: ICASSP 2024语音信号改进挑战

    ICASSP 2024 Speech Signal Improvement Challenge. (arXiv:2401.14444v1 [cs.SD])

    [http://arxiv.org/abs/2401.14444](http://arxiv.org/abs/2401.14444)

    ICASSP 2024语音信号改进大挑战旨在促进通信系统中提高语音信号质量的研究。通过引入数据集合成器、客观指标、测试集转录和新的指标，我们评估了13个实时系统和11个非实时系统。

    

    ICASSP 2024语音信号改进大挑战旨在促进通信系统中提高语音信号质量的研究。这是我们的第二个挑战，建立在前一次ICASSP 2023大挑战的成功基础上。我们通过引入数据集合成器、为我们的扩展P.804测试引入客观指标、2023测试集的转录以及将Word Accuracy (WA)作为一个指标，来增强竞争。我们使用客观的Word Accuracy指标和主观的P.804指标评估了总共13个实时系统和11个非实时系统。

    The ICASSP 2024 Speech Signal Improvement Grand Challenge is intended to stimulate research in the area of improving the speech signal quality in communication systems. This marks our second challenge, building upon the success from the previous ICASSP 2023 Grand Challenge. We enhance the competition by introducing a dataset synthesizer, enabling all participating teams to start at a higher baseline, an objective metric for our extended P.804 tests, transcripts for the 2023 test set, and we add Word Accuracy (WAcc) as a metric. We evaluate a total of 13 systems in the real-time track and 11 systems in the non-real-time track using both subjective P.804 and objective Word Accuracy metrics.
    
[^48]: 语义敏感性和不一致的预测：衡量NLI模型的脆弱性

    Semantic Sensitivities and Inconsistent Predictions: Measuring the Fragility of NLI Models. (arXiv:2401.14440v1 [cs.CL])

    [http://arxiv.org/abs/2401.14440](http://arxiv.org/abs/2401.14440)

    这份论文研究发现，最先进的NLI模型对微小的语义保持表面形式变化非常敏感，导致推断结果不一致。其行为与对组合语义的有效理解不同，这对当前NLI模型的可靠性提出了挑战。

    

    最近对基于transformer的自然语言理解（NLU）模型的新能力进行的研究表明，它们具备对词汇和组合语义的理解。然而，我们提供了证据表明这些说法应该持保留态度：我们发现目前最先进的自然语言推理（NLI）模型对微小的保留语义的表面形式变化敏感，这导致推断过程中出现大量不一致的模型决策。值得注意的是，这种行为与对组合语义的有效和深入理解不同，而在标准基准测试中评估模型准确度或探究句法、单调性和逻辑鲁棒性推理时均不会出现。我们提出了一个新颖的框架来衡量语义敏感性的程度。为此，我们使用含有微小保留语义的表面形式输入噪声的对抗生成样例来评估NLI模型。

    Recent studies of the emergent capabilities of transformer-based Natural Language Understanding (NLU) models have indicated that they have an understanding of lexical and compositional semantics. We provide evidence that suggests these claims should be taken with a grain of salt: we find that state-of-the-art Natural Language Inference (NLI) models are sensitive towards minor semantics preserving surface-form variations, which lead to sizable inconsistent model decisions during inference. Notably, this behaviour differs from valid and in-depth comprehension of compositional semantics, however does neither emerge when evaluating model accuracy on standard benchmarks nor when probing for syntactic, monotonic, and logically robust reasoning. We propose a novel framework to measure the extent of semantic sensitivity. To this end, we evaluate NLI models on adversarially generated examples containing minor semantics-preserving surface-form input noise. This is achieved using conditional text
    
[^49]: 面向合作物流问题的关注隐私、具备情绪意识的代理人的信任模型

    Trust model of privacy-concerned, emotionally-aware agents in a cooperative logistics problem. (arXiv:2401.14436v1 [cs.MA])

    [http://arxiv.org/abs/2401.14436](http://arxiv.org/abs/2401.14436)

    本文提出了一种面向合作物流问题的关注隐私、具备情绪意识的代理人的信任模型。最具创新性的贡献是在合作决策中引入隐私问题，并展示情绪和信任如何促进代理人的性能改善。

    

    本文提出了一种信任模型，用于在人类和无人车相互合作的虚拟混合环境中使用。我们以一种连贯的方式将情绪引入到信任模型中，并与当前的心理学理论的实际方法相结合。最具创新性的贡献是隐私问题如何在情绪信任模型的合作决策中起作用。情绪和信任都通过自主代理人的认知建模和管理以及使用IEEE FIPA标准进行通信的GAMA代理平台的GAML编程语言来实现。这些情绪代理人的信任行为在一个合作性物流问题中进行了测试：代理人必须将物品移动到目的地，其中一些物品和地点存在隐私问题。对这个物流问题的模拟执行显示情绪和信任如何促进代理人的性能改善。

    In this paper we propose a trust model to be used into a hypothetical mixed environment where humans and unmanned vehicles cooperate. We address the inclusion of emotions inside a trust model in a coherent way to the practical approaches to the current psychology theories. The most innovative contribution is how privacy issues play a role in the cooperation decisions of the emotional trust model. Both, emotions and trust have been cognitively modeled and managed with the Beliefs, Desires and Intentions (BDI) paradigm into autonomous agents implemented in GAML (the programming language of GAMA agent platform) that communicates using the IEEE FIPA standard. The trusting behaviour of these emotional agents is tested in a cooperative logistics problem where: agents have to move objects to destinations and some of the objects and places have privacy issues. The execution of simulations of this logistic problem shows how emotions and trust contribute to improve the performance of agents in t
    
[^50]: 将基于梯度的技术转化为可解释的方法

    Transforming gradient-based techniques into interpretable methods. (arXiv:2401.14434v1 [cs.CV])

    [http://arxiv.org/abs/2401.14434](http://arxiv.org/abs/2401.14434)

    本文提出了一种基于梯度的技术支持框架，通过建立区别来强调重要区域, 并减少图像噪音。实证调查表明这些区域在促进类别区分方面起关键作用。

    

    通过xAI技术解释卷积神经网络（CNN）通常在解释上面临挑战。图像提取的像素等输入特征的内在复杂性引发了复杂的相关性。集成梯度（IG）等基于梯度的方法有效地展示了这些特征的重要性。然而，将这些解释转化为图像时常常产生大量噪音。本文引入了梯度人工分离（GAD）作为梯度基于技术的支持框架。其主要目标是通过建立类别之间的区别来强调有影响力的区域。GAD的核心是在可视化过程中限制分析范围，从而减少图像噪音。通过对被遮挡图像的实证调查，我们证明了通过这种方法确定的区域确实在促进类别区分方面发挥了关键作用。

    The explication of Convolutional Neural Networks (CNN) through xAI techniques often poses challenges in interpretation. The inherent complexity of input features, notably pixels extracted from images, engenders complex correlations. Gradient-based methodologies, exemplified by Integrated Gradients (IG), effectively demonstrate the significance of these features. Nevertheless, the conversion of these explanations into images frequently yields considerable noise. Presently, we introduce GAD (Gradient Artificial Distancing) as a supportive framework for gradient-based techniques. Its primary objective is to accentuate influential regions by establishing distinctions between classes. The essence of GAD is to limit the scope of analysis during visualization and, consequently reduce image noise. Empirical investigations involving occluded images have demonstrated that the identified regions through this methodology indeed play a pivotal role in facilitating class differentiation.
    
[^51]: M$^3$TN：基于多门专家混合的多值处理网络的提升建模

    M$^3$TN: Multi-gate Mixture-of-Experts based Multi-valued Treatment Network for Uplift Modeling. (arXiv:2401.14426v1 [cs.LG])

    [http://arxiv.org/abs/2401.14426](http://arxiv.org/abs/2401.14426)

    M$^3$TN是一种用于提升建模的新颖网络，通过多门专家混合和明确建模提升的方法，解决了现有方法中存在的一致性和效率问题。

    

    提升建模是一种用于预测处理（如折扣）对个体反应的技术。虽然已经提出了几种用于多值处理的方法，但它们都是从二值处理方法扩展而来的，存在一些局限性。首先，现有方法基于预测的响应计算提升，这可能不能保证处理组和对照组之间的一致提升分布。此外，这可能会对多值处理产生累积误差。其次，随着许多预测头，模型参数变得非常复杂，导致效率降低。为了解决这些问题，我们提出了一种新颖的基于多门专家混合的多值处理网络（M$^3$TN）。M$^3$TN由两个组件组成：1) 基于多门专家混合的特征表示模块，以提高效率；2) 通过明确建模提升的重新参数化模块。

    Uplift modeling is a technique used to predict the effect of a treatment (e.g., discounts) on an individual's response. Although several methods have been proposed for multi-valued treatment, they are extended from binary treatment methods. There are still some limitations. Firstly, existing methods calculate uplift based on predicted responses, which may not guarantee a consistent uplift distribution between treatment and control groups. Moreover, this may cause cumulative errors for multi-valued treatment. Secondly, the model parameters become numerous with many prediction heads, leading to reduced efficiency. To address these issues, we propose a novel \underline{M}ulti-gate \underline{M}ixture-of-Experts based \underline{M}ulti-valued \underline{T}reatment \underline{N}etwork (M$^3$TN). M$^3$TN consists of two components: 1) a feature representation module with Multi-gate Mixture-of-Experts to improve the efficiency; 2) a reparameterization module by modeling uplift explicitly to i
    
[^52]: 不再在Artstation上趋势：生成型AI艺术作品的提示分析

    No Longer Trending on Artstation: Prompt Analysis of Generative AI Art. (arXiv:2401.14425v1 [cs.HC])

    [http://arxiv.org/abs/2401.14425](http://arxiv.org/abs/2401.14425)

    本文研究使用生成型AI进行图像生成，通过分析提示和生成的图像，发现提示主要关注表面美感和流行话题，而非艺术性。

    

    使用生成型AI进行图像生成正在迅速成为视觉媒体的主要新来源，过去几年已经使用稳定扩散和中途出行等扩散模型生成了数十亿张AI生成的图像。本文收集和分析了超过300万个提示及其生成的图像。通过自然语言处理、主题分析和可视化方法，我们旨在共同了解人们如何使用文本提示，这些系统对艺术家的影响，以及它们广泛推广的视觉文化。研究结果表明，提示主要集中在表面美感上，强化文化规范、流行的传统表征和意象。我们还发现，许多用户关注热门话题（例如制作涂色书、幻想艺术或圣诞卡片），这表明所分析系统的主要用途是娱乐而非艺术性的。

    Image generation using generative AI is rapidly becoming a major new source of visual media, with billions of AI generated images created using diffusion models such as Stable Diffusion and Midjourney over the last few years. In this paper we collect and analyse over 3 million prompts and the images they generate. Using natural language processing, topic analysis and visualisation methods we aim to understand collectively how people are using text prompts, the impact of these systems on artists, and more broadly on the visual cultures they promote. Our study shows that prompting focuses largely on surface aesthetics, reinforcing cultural norms, popular conventional representations and imagery. We also find that many users focus on popular topics (such as making colouring books, fantasy art, or Christmas cards), suggesting that the dominant use for the systems analysed is recreational rather than artistic.
    
[^53]: 通过GPT引导的蒙特卡洛树搜索从数据中发现数学公式

    Discovering Mathematical Formulas from Data via GPT-guided Monte Carlo Tree Search. (arXiv:2401.14424v1 [cs.LG])

    [http://arxiv.org/abs/2401.14424](http://arxiv.org/abs/2401.14424)

    通过结合MCTS和生成式预训练模型，我们提出了一种新的符号回归算法SR-GPT，在发现数据中的数学公式方面取得了显著的改进。

    

    在科学研究和人工智能中，找到一个简洁且可解释的数学公式来准确描述数据中每个变量与预测值之间的关系是一个关键任务，也是一个重大挑战。这个问题被称为符号回归，是一个NP困难问题。去年，提出了一种基于蒙特卡洛树搜索（MCTS）的符号回归方法，并在多个数据集上获得了sota。虽然与以前的方法相比，该算法在恢复目标表达式方面显示出了相当大的改进，但是在MCTS过程中缺乏引导严重阻碍了其搜索效率。最近，一些算法在MCTS的搜索中添加了一个预训练的策略网络，但是这个预训练的策略网络的泛化能力很差。为了平衡效率和通用性，我们提出了SR-GPT，结合了AlphaZero的思想。SR-GPT是一种新的符号回归算法，将MCTS与一个通用性较好的生成式预训练模型相结合。

    Finding a concise and interpretable mathematical formula that accurately describes the relationship between each variable and the predicted value in the data is a crucial task in scientific research, as well as a significant challenge in artificial intelligence. This problem is referred to as symbolic regression, which is an NP-hard problem. Last year, a symbolic regression method based on Monte Carlo Tree Search (MCTS) was proposed and sota was obtained on multiple datasets. While this algorithm has shown considerable improvement in recovering target expressions compared to previous methods, the lack of guidance during the MCTS process severely hampers its search efficiency. Recently, some algorithms have added a pre-trained policy network to guide the search of MCTS, but the pre-trained policy network generalizes poorly. To balance efficiency and generality, we propose SR-GPT combining ideas from AlphaZero. SR-GPT is a new symbolic regression algorithm that combines MCTS with a Gener
    
[^54]: 模糊逻辑函数作为非线性分类器的事后解释器

    Fuzzy Logic Function as a Post-hoc Explanator of the Nonlinear Classifier. (arXiv:2401.14417v1 [cs.LG])

    [http://arxiv.org/abs/2401.14417](http://arxiv.org/abs/2401.14417)

    本文研究了使用模糊逻辑函数作为分类器的事后解释器，通过与黑盒分类器进行并行设计，实现了与黑盒分类器相同的决策结果。

    

    使用深度神经网络实现的模式识别系统比线性模型获得更好的结果。然而，它们的缺点是黑盒属性。这意味着没有经验使用非线性系统的人可能需要帮助理解决策结果。这种解决方案对于负责最终决策的用户来说是不可接受的。他不仅必须相信决策，还必须理解决策。因此，识别器必须具有允许解释者解释结果的架构。事后可解释的分类器的想法是设计一个可解释的分类器，与黑盒分类器并行，给出与黑盒分类器相同的决策。本文表明，如果Zadeh的模糊逻辑函数形成分类器，DeconvNet的重要性给出了真值，可解释的分类器在MNIST和FashionMNIST数据库上与黑盒分类器产生相同的分类决策。

    Pattern recognition systems implemented using deep neural networks achieve better results than linear models. However, their drawback is the black box property. This property means that one with no experience utilising nonlinear systems may need help understanding the outcome of the decision. Such a solution is unacceptable to the user responsible for the final decision. He must not only believe in the decision but also understand it. Therefore, recognisers must have an architecture that allows interpreters to interpret the findings. The idea of post-hoc explainable classifiers is to design an interpretable classifier parallel to the black box classifier, giving the same decisions as the black box classifier. This paper shows that the explainable classifier completes matching classification decisions with the black box classifier on the MNIST and FashionMNIST databases if Zadeh`s fuzzy logic function forms the classifier and DeconvNet importance gives the truth values. Since the other 
    
[^55]: 应用于电化学的机器学习技术的分析

    Aprendizado de m\'aquina aplicado na eletroqu\'imica. (arXiv:2401.14413v1 [cs.LG])

    [http://arxiv.org/abs/2401.14413](http://arxiv.org/abs/2401.14413)

    本文系统综述了机器学习技术在电化学应用中的使用情况，并介绍了其在医学诊断、化学品分类和环境监测等方面的重要作用。

    

    本系统性综述旨在分析机器学习技术在识别和量化各种电化学应用中的应用情况，并介绍了文献中可用的应用。机器学习是一种能够促进分析并增强涉及各种分析物的过程理解的工具。在电化学生物传感器中，它提高了医学诊断的精确性，提高了识别具有高可靠性的生物标志物和病原体的能力。它还可以有效用于复杂化学品的分类；在环境监测中，使用低成本传感器；在便携设备和可穿戴系统中等等。目前，某些分析物的分析仍然需要专家的专业知识并手动执行，从而阻碍了结果的普遍化。在当前人工智能的进展下，本研究拟进行一项系统综述。

    This systematic review focuses on analyzing the use of machine learning techniques for identifying and quantifying analytes in various electrochemical applications, presenting the available applications in the literature. Machine learning is a tool that can facilitate the analysis and enhance the understanding of processes involving various analytes. In electrochemical biosensors, it increases the precision of medical diagnostics, improving the identification of biomarkers and pathogens with high reliability. It can be effectively used for the classification of complex chemical products; in environmental monitoring, using low-cost sensors; in portable devices and wearable systems; among others. Currently, the analysis of some analytes is still performed manually, requiring the expertise of a specialist in the field and thus hindering the generalization of results. In light of the advancements in artificial intelligence today, this work proposes to carry out a systematic review of the l
    
[^56]: 利用神经元的稳定性改进DNN验证

    Harnessing Neuron Stability to Improve DNN Verification. (arXiv:2401.14412v1 [cs.LG])

    [http://arxiv.org/abs/2401.14412](http://arxiv.org/abs/2401.14412)

    本论文提出了VeriStable方法，在DNN验证中利用稳定的神经元减少组合复杂性，同时保持抽象的准确性。这种方法与工业化SAT基准共享重要特征，并在有效性和可扩展性方面取得了显著的进展。

    

    深度神经网络（DNN）已经成为解决现实世界问题的有效方法。然而，像人类编写的软件一样，DNN也容易受到错误和攻击的影响。这引发了对有效和可扩展的DNN验证技术和工具的重大关注。本文介绍了VeriStable，这是一种新颖的基于DPLL约束DNN验证方法的扩展。VeriStable利用了这样一个洞见：尽管神经元在整个DNN输入空间中的行为可能是非线性的，在验证过程中计算得到的中间状态中，许多神经元可能被约束为具有线性行为-这些神经元是稳定的。高效地检测稳定的神经元可以减少组合复杂性，而不会损害抽象的准确性。此外，DNN验证问题中产生的子句结构与工业化SAT基准具有重要特征。我们调整并融合了多线程和重启优化策略。

    Deep Neural Networks (DNN) have emerged as an effective approach to tackling real-world problems. However, like human-written software, DNNs are susceptible to bugs and attacks. This has generated significant interests in developing effective and scalable DNN verification techniques and tools. In this paper, we present VeriStable, a novel extension of recently proposed DPLL-based constraint DNN verification approach. VeriStable leverages the insight that while neuron behavior may be non-linear across the entire DNN input space, at intermediate states computed during verification many neurons may be constrained to have linear behavior - these neurons are stable. Efficiently detecting stable neurons reduces combinatorial complexity without compromising the precision of abstractions. Moreover, the structure of clauses arising in DNN verification problems shares important characteristics with industrial SAT benchmarks. We adapt and incorporate multi-threading and restart optimizations targ
    
[^57]: CMMU: 一个用于中文多模态多类型问题理解与推理的基准测试

    CMMU: A Benchmark for Chinese Multi-modal Multi-type Question Understanding and Reasoning. (arXiv:2401.14011v1 [cs.CL])

    [http://arxiv.org/abs/2401.14011](http://arxiv.org/abs/2401.14011)

    CMMU是一个用于中文多模态多类型问题理解和推理的基准测试，涵盖了从小学到高中的知识，提供了多项选择题、多项回答题和填空题三种类型的问题，对于评估多模态大型语言模型的智能水平具有重要意义。

    

    多模态大型语言模型（MLLMs）已经取得了显著的进展，并展现出强大的知识理解和推理能力。然而，评估MLLM的智能水平所需的领域特定知识掌握仍然是一个挑战。当前用于领域特定知识的多模态基准测试主要集中在英语多项选择题上，并且在评估的全面性方面存在局限性。为此，我们引入了CMMU，一个用于中文多模态多类型问题理解和推理的新型基准测试。CMMU包含7个学科的3603个问题，涵盖了从小学到高中的知识。这些问题可以分为多项选择题、多项回答题和填空题三类，对MLLMs提出更大的挑战。此外，我们提出了一种严格的评估策略，称为ShiftCheck，用于评估多项选择题。

    Multi-modal large language models(MLLMs) have achieved remarkable progress and demonstrated powerful knowledge comprehension and reasoning abilities. However, the mastery of domain-specific knowledge, which is essential for evaluating the intelligence of MLLMs, continues to be a challenge. Current multi-modal benchmarks for domain-specific knowledge concentrate on multiple-choice questions and are predominantly available in English, which imposes limitations on the comprehensiveness of the evaluation. To this end, we introduce CMMU, a novel benchmark for multi-modal and multi-type question understanding and reasoning in Chinese. CMMU consists of 3,603 questions in 7 subjects, covering knowledge from primary to high school. The questions can be categorized into 3 types: multiple-choice, multiple-response, and fill-in-the-blank, bringing greater challenges to MLLMs. In addition, we propose a rigorous evaluation strategy called ShiftCheck for assessing multiple-choice questions. The strat
    
[^58]: 工具变量模型中的假设和界限

    Assumptions and Bounds in the Instrumental Variable Model. (arXiv:2401.13758v1 [math.ST])

    [http://arxiv.org/abs/2401.13758](http://arxiv.org/abs/2401.13758)

    本文证明了在工具变量（IV）模型中，具有二进制响应$Y$和二进制处理$X$的情况下，使用接受$K$个状态的仪器$Z$时，关于ACE界限的结果。

    

    在本文中，我们给出了关于具有二进制响应$Y$和二进制处理$X$的工具变量（IV）模型的结果证明，但是仪器$Z$接受$K$个状态，这些状态最初是在Richardson＆Robins（2014）的论文“ACE Bounds; SEMS with Equilibrium Conditions”中提出的（arXiv:1410.0470）。

    In this note we give proofs for results relating to the Instrumental Variable (IV) model with binary response $Y$ and binary treatment $X$, but with an instrument $Z$ that takes $K$ states that were originally stated in Richardson & Robins (2014), "ACE Bounds; SEMS with Equilibrium Conditions," arXiv:1410.0470.
    
[^59]: 有关算法决策的信息：探索受到算法决策影响的人的信息需求。

    Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions. (arXiv:2401.13324v1 [cs.HC])

    [http://arxiv.org/abs/2401.13324](http://arxiv.org/abs/2401.13324)

    本研究探讨了受算法决策影响的人的信息需求，发现解释往往不能满足他们的关注点，导致对监管框架的理解和遵守产生障碍。为了解决这个问题，研究团队提出了XAI初学者问题库，涵盖了就业预测和健康监测两个领域中受影响利益相关者的信息需求。

    

    AI系统的解释很少涉及到受算法决策影响的人的信息需求。这种传达信息与受影响利益相关者所关心的信息之间的差距可能阻碍对监管框架（如AI法案）的理解和遵守。为了解决这个差距，我们提出了“XAI初学者问题库”：这是一个涵盖两个算法决策应用领域（就业预测和健康监测）中受影响利益相关者信息需求的目录，包括数据、系统背景、系统使用和系统规范等类别。信息需求是通过访谈研究收集的，参与者根据自己的问题获得解释。参与者还报告了他们的理解和决策信心，结果显示，尽管在接受解释后信心倾向于增加，但参与者也面临着理解上的挑战，如无法解释为什么自己的理解感觉不完整。解释还对理解产生了影响。

    Explanations of AI systems rarely address the information needs of people affected by algorithmic decision-making (ADM). This gap between conveyed information and information that matters to affected stakeholders can impede understanding and adherence to regulatory frameworks such as the AI Act. To address this gap, we present the "XAI Novice Question Bank": A catalog of affected stakeholders' information needs in two ADM use cases (employment prediction and health monitoring), covering the categories data, system context, system usage, and system specifications. Information needs were gathered in an interview study where participants received explanations in response to their inquiries. Participants further reported their understanding and decision confidence, showing that while confidence tended to increase after receiving explanations, participants also met understanding challenges, such as being unable to tell why their understanding felt incomplete. Explanations further influenced
    
[^60]: 像素级别识别用于整体外科场景理解

    Pixel-Wise Recognition for Holistic Surgical Scene Understanding. (arXiv:2401.11174v1 [cs.CV])

    [http://arxiv.org/abs/2401.11174](http://arxiv.org/abs/2401.11174)

    本文提出了一个整体和多粒度外科场景理解数据集，以及一个基于变形器的模型，该模型有效地结合了全局视频特征提取和局部器械分割，可用于多层次理解外科活动。

    

    本文提出了Prostatectomies的整体和多粒度外科场景理解（GraSP）数据集，该数据集对外科场景理解进行了层次化建模，包括不同粒度的互补任务。我们的方法实现了对外科活动的多层次理解，包括外科阶段和步骤的识别以及包括外科器械分割和原子可视动作检测在内的短期任务。为了利用我们提出的数据集，我们引入了基于变形器（Transformers）的行动、阶段、步骤和器械分割（TAPIS）模型，该模型将全局视频特征提取器与来自器械分割模型的局部区域建议相结合，以应对我们数据集的多粒度问题。通过广泛的实验，我们展示了在短期识别任务中包括分割注释的影响，并突显了不同的粒度要求。

    This paper presents the Holistic and Multi-Granular Surgical Scene Understanding of Prostatectomies (GraSP) dataset, a curated benchmark that models surgical scene understanding as a hierarchy of complementary tasks with varying levels of granularity. Our approach enables a multi-level comprehension of surgical activities, encompassing long-term tasks such as surgical phases and steps recognition and short-term tasks including surgical instrument segmentation and atomic visual actions detection. To exploit our proposed benchmark, we introduce the Transformers for Actions, Phases, Steps, and Instrument Segmentation (TAPIS) model, a general architecture that combines a global video feature extractor with localized region proposals from an instrument segmentation model to tackle the multi-granularity of our benchmark. Through extensive experimentation, we demonstrate the impact of including segmentation annotations in short-term recognition tasks, highlight the varying granularity require
    
[^61]: 高斯自适应注意力是唯一所需的：跨多个模态的健壮上下文表示

    Gaussian Adaptive Attention is All You Need: Robust Contextual Representations Across Multiple Modalities. (arXiv:2401.11143v1 [cs.LG])

    [http://arxiv.org/abs/2401.11143](http://arxiv.org/abs/2401.11143)

    该论文提出了一个名为GAAM的多头高斯自适应注意力机制，用于增强跨多个模态的信息聚合。通过将可学习的均值和方差纳入注意力机制中，GAAM能够动态地重新调整特征的重要性，从而在处理非平稳数据时取得了显著的性能提升，超过了目前现有的注意力技术。该方法的适应性强且参数数量较少，具有改进现有注意力框架的潜力。

    

    我们提出了多头高斯自适应注意力机制（GAAM），一种新颖的概率注意力框架，并设计了高斯自适应变压器（GAT），旨在增强跨多个模态（包括语音、文本和视觉）的信息聚合。GAAM将可学习的均值和方差融入其注意力机制中，采用多头框架实现，使其能够集体建模任何概率分布，以动态重新调整特征重要性。该方法在处理高度非平稳数据时表现出显著改进，通过识别特征空间中的关键元素，超越了现有的注意力技术在模型性能上的状态（精度增加约20%）。GAAM与基于点积的注意力模型兼容，并具有相对较低的参数数量，展示了其适应性和提升现有注意力框架的潜力。在实证方面，GAAM表现出卓越的适应性和功效。

    We propose the Multi-Head Gaussian Adaptive Attention Mechanism (GAAM), a novel probabilistic attention framework, and the Gaussian Adaptive Transformer (GAT), designed to enhance information aggregation across multiple modalities, including Speech, Text and Vision. GAAM integrates learnable mean and variance into its attention mechanism, implemented in a Multi-Headed framework enabling it to collectively model any Probability Distribution for dynamic recalibration of feature significance. This method demonstrates significant improvements, especially with highly non-stationary data, surpassing the state-of-the-art attention techniques in model performance (up to approximately +20% in accuracy) by identifying key elements within the feature space. GAAM's compatibility with dot-product-based attention models and relatively low number of parameters showcases its adaptability and potential to boost existing attention frameworks. Empirically, GAAM exhibits superior adaptability and efficacy
    
[^62]: Chem-FINESE: 通过文本重构验证细粒度少样本实体提取

    Chem-FINESE: Validating Fine-Grained Few-shot Entity Extraction through Text Reconstruction. (arXiv:2401.10189v1 [cs.CL])

    [http://arxiv.org/abs/2401.10189](http://arxiv.org/abs/2401.10189)

    这篇论文提出了一种名为Chem-FINESE的方法来处理化学领域中细粒度少样本实体提取的问题。该方法通过使用序列到序列的实体提取器和自我验证模块来从输入句子中提取命名实体并重构原始输入句子。实验证明了该方法的有效性和可行性。

    

    在化学领域中，细粒度少样本实体提取面临两个独特的挑战。首先，与一般领域的实体提取任务相比，化学论文中的句子通常包含更多的实体。此外，实体提取模型通常难以提取长尾类型的实体。在本文中，我们提出了一种新颖的基于序列到序列的少样本实体提取方法Chem-FINESE来解决这两个挑战。我们的Chem-FINESE包含两个组件：一个序列到序列的实体提取器用于从输入句子中提取命名实体，以及一个序列到序列的自我验证模块用于从提取的实体中重构原始输入句子。受到一个好的实体提取系统需要忠实提取实体的事实启发，我们的新自我验证模块利用实体提取结果来重构原始输入句子。此外，我们设计了一种新的对比损失来减少在提取过程中的过度复制。

    Fine-grained few-shot entity extraction in the chemical domain faces two unique challenges. First, compared with entity extraction tasks in the general domain, sentences from chemical papers usually contain more entities. Moreover, entity extraction models usually have difficulty extracting entities of long-tailed types. In this paper, we propose Chem-FINESE, a novel sequence-to-sequence (seq2seq) based few-shot entity extraction approach, to address these two challenges. Our Chem-FINESE has two components: a seq2seq entity extractor to extract named entities from the input sentence and a seq2seq self-validation module to reconstruct the original input sentence from extracted entities. Inspired by the fact that a good entity extraction system needs to extract entities faithfully, our new self-validation module leverages entity extraction results to reconstruct the original input sentence. Besides, we design a new contrastive loss to reduce excessive copying during the extraction proces
    
[^63]: DiConStruct: 基于黑盒精华的因果概念解释

    DiConStruct: Causal Concept-based Explanations through Black-Box Distillation. (arXiv:2401.08534v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.08534](http://arxiv.org/abs/2401.08534)

    DiConStruct是一种基于黑盒模型的因果概念解释方法，通过创建结构性因果模型和概念归因方式提供更具可解释性的局部解释。

    

    模型可解释性在人工智能决策系统中起着核心作用。理想情况下，解释应该使用人可解释的语义概念来表达。此外，解释器应该捕捉这些概念之间的因果关系，以便对解释进行推理。最后，解释方法应该高效，并不损害预测任务的性能。尽管近年来AI解释性取得了快速进展，但据我们所知，至今没有一种方法满足这三个条件。事实上，主流的局部概念可解释性方法不产生因果解释，并在解释性和预测性能之间存在权衡。我们提出了DiConStruct，一种既基于概念又具有因果性的解释方法，旨在通过结构性因果模型和概念归因方式创建更具可解释性的局部解释。我们的解释器作为一个精华模型适用于任何黑盒机器学习模型。

    Model interpretability plays a central role in human-AI decision-making systems. Ideally, explanations should be expressed using human-interpretable semantic concepts. Moreover, the causal relations between these concepts should be captured by the explainer to allow for reasoning about the explanations. Lastly, explanation methods should be efficient and not compromise the performance of the predictive task. Despite the rapid advances in AI explainability in recent years, as far as we know to date, no method fulfills these three properties. Indeed, mainstream methods for local concept explainability do not produce causal explanations and incur a trade-off between explainability and prediction performance. We present DiConStruct, an explanation method that is both concept-based and causal, with the goal of creating more interpretable local explanations in the form of structural causal models and concept attributions. Our explainer works as a distillation model to any black-box machine l
    
[^64]: 无需清洗参考图像的超分辨率：应用于电子显微镜

    No-Clean-Reference Image Super-Resolution: Application to Electron Microscopy. (arXiv:2401.08115v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2401.08115](http://arxiv.org/abs/2401.08115)

    这项研究提出了一种无需清洗参考图像的超分辨率方法，通过深度学习实现从噪声低分辨率的电子显微镜图像重建清洁的高分辨率图像。以及使用无需清洗参考的训练和引入新的网络架构。实验结果表明使用真实训练数据可以产生高质量的重建图像。

    

    无法获得清洁的高分辨率电子显微镜（EM）图像限制了许多神经科学研究。为了解决这个挑战，我们提出了一种基于深度学习的图像超分辨率（SR）方法，以从噪声低分辨率（LR）采集中计算重建具有大视场（FoV）的清洁的高分辨率3D-EM。我们的贡献是：I）研究使用无需清洗参考的$\ell_2$和$\ell_1$损失函数进行训练；II）引入一种名为EMSR的新型网络架构，用于增强LR EM图像的分辨率同时减少固有噪声；以及III）比较不同的训练策略，包括使用获取的LR和HR图像对，即具有真实污染的无需清洗参考的真实对，合成LR和获取的HR对以及获取的LR和去噪HR对。在九个脑数据集上的实验表明，使用真实对进行训练可以产生高质量的超分辨率重建图像。

    The inability to acquire clean high-resolution (HR) electron microscopy (EM) images over a large brain tissue volume hampers many neuroscience studies. To address this challenge, we propose a deep-learning-based image super-resolution (SR) approach to computationally reconstruct clean HR 3D-EM with a large field of view (FoV) from noisy low-resolution (LR) acquisition. Our contributions are I) Investigating training with no-clean references for $\ell_2$ and $\ell_1$ loss functions; II) Introducing a novel network architecture, named EMSR, for enhancing the resolution of LR EM images while reducing inherent noise; and, III) Comparing different training strategies including using acquired LR and HR image pairs, i.e., real pairs with no-clean references contaminated with real corruptions, the pairs of synthetic LR and acquired HR, as well as acquired LR and denoised HR pairs. Experiments with nine brain datasets showed that training with real pairs can produce high-quality super-resolved 
    
[^65]: 多任务机器人数据用于双臂精细操作

    Multi-task robot data for dual-arm fine manipulation. (arXiv:2401.07603v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2401.07603](http://arxiv.org/abs/2401.07603)

    这篇论文介绍了一个多任务机器人数据集，其中包括双臂精细操作和需要精细操作的任务，并且公开可用。

    

    在机器人操纵领域，深度模仿学习被认为是获取操作技能的一种有希望的方法。此外，从多样化的机器人数据集中学习被认为是实现多样性和适应性的可行方法。在这样的研究中，通过学习各种任务，机器人在多个物体上实现了普适性。然而，这样的多任务机器人数据集主要集中在相对不精确的单臂任务上，并没有解决机器人在现实世界中需要执行的细粒度物体操作。本文介绍了一个包括双臂任务和/或需要精细操作的多样化物体操纵数据集。为此，我们生成了包含224k个场景的数据集（150小时，1,104个语言指令），其中包括双臂精细任务，如移动碗、打开笔袋或剥香蕉，并且这些数据是公开可用的。此外，该数据集还包括视觉注意信号。

    In the field of robotic manipulation, deep imitation learning is recognized as a promising approach for acquiring manipulation skills. Additionally, learning from diverse robot datasets is considered a viable method to achieve versatility and adaptability. In such research, by learning various tasks, robots achieved generality across multiple objects. However, such multi-task robot datasets have mainly focused on single-arm tasks that are relatively imprecise, not addressing the fine-grained object manipulation that robots are expected to perform in the real world. This paper introduces a dataset of diverse object manipulations that includes dual-arm tasks and/or tasks requiring fine manipulation. To this end, we have generated dataset with 224k episodes (150 hours, 1,104 language instructions) which includes dual-arm fine tasks such as bowl-moving, pencil-case opening or banana-peeling, and this data is publicly available. Additionally, this dataset includes visual attention signals a
    
[^66]: DevEval: 评估实际软件项目中的代码生成

    DevEval: Evaluating Code Generation in Practical Software Projects. (arXiv:2401.06401v1 [cs.SE])

    [http://arxiv.org/abs/2401.06401](http://arxiv.org/abs/2401.06401)

    本文提出了一个名为DevEval的新基准测试，用于评估实际软件项目中的代码生成。与之前的基准测试相比，DevEval在真实的项目分布、充足的依赖和足够规模的项目背景等方面更贴合实际。通过对五个流行的大型语言模型进行评估，我们揭示了它们在代码生成中的实际能力。

    

    如何评估大型语言模型（LLMs）在代码生成中的表现是一个开放的问题。许多基准测试已经提出，但是与实际软件项目不一致，例如虚构的程序分布，依赖不足和小规模项目背景。因此，LLMs在实际项目中的能力还不清楚。在本文中，我们提出了一个名为DevEval的新基准测试，与开发人员在实际项目中的经验相吻合。DevEval通过一个严格的流程收集到了来自119个实际项目的2690个样本，涵盖10个领域。与之前的基准测试相比，DevEval在多个维度上与实际项目相吻合，例如真实的程序分布，充足的依赖和足够规模的项目背景。我们在DevEval上评估了五个流行的LLMs（例如gpt-4，gpt-3.5-turbo，CodeLLaMa和StarCoder），并揭示了它们在代码生成中的实际能力。例如，gpt-3.5-turbo的最高Pass@1只有42。

    How to evaluate Large Language Models (LLMs) in code generation is an open question. Many benchmarks have been proposed but are inconsistent with practical software projects, e.g., unreal program distributions, insufficient dependencies, and small-scale project contexts. Thus, the capabilities of LLMs in practical projects are still unclear. In this paper, we propose a new benchmark named DevEval, aligned with Developers' experiences in practical projects. DevEval is collected through a rigorous pipeline, containing 2,690 samples from 119 practical projects and covering 10 domains. Compared to previous benchmarks, DevEval aligns to practical projects in multiple dimensions, e.g., real program distributions, sufficient dependencies, and enough-scale project contexts. We assess five popular LLMs on DevEval (e.g., gpt-4, gpt-3.5-turbo, CodeLLaMa, and StarCoder) and reveal their actual abilities in code generation. For instance, the highest Pass@1 of gpt-3.5-turbo only is 42 in our experim
    
[^67]: Agent AI: 对多模态交互的横向调查

    Agent AI: Surveying the Horizons of Multimodal Interaction. (arXiv:2401.03568v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2401.03568](http://arxiv.org/abs/2401.03568)

    Agent AI是一种多模态交互系统，可以感知视觉刺激、语言输入和其他环境相关数据，通过将代理体嵌入物理或虚拟环境中来实现更复杂和上下文感知的人工智能系统。

    

    多模态人工智能系统很可能会成为我们日常生活中无处不在的存在。使其更互动的一种有前途的方法是将它们作为代理体现在物理和虚拟环境中。目前，系统利用现有的基础模型作为创建代理体的基本构建模块。将代理体嵌入这样的环境中有助于模型处理和解释视觉和环境数据的能力，这对于创建更复杂和上下文感知的人工智能系统至关重要。例如，一个系统可以感知用户动作、人类行为、环境物体、音频表达和场景的集体情感，从而在给定环境中为代理体提供信息和指导。为了加速代理体多模态智能的研究，我们将“Agent AI”定义为一类可以感知视觉刺激、语言输入和其他环境相关数据的交互系统。

    Multi-modal AI systems will likely become a ubiquitous presence in our everyday lives. A promising approach to making these systems more interactive is to embody them as agents within physical and virtual environments. At present, systems leverage existing foundation models as the basic building blocks for the creation of embodied agents. Embedding agents within such environments facilitates the ability of models to process and interpret visual and contextual data, which is critical for the creation of more sophisticated and context-aware AI systems. For example, a system that can perceive user actions, human behavior, environmental objects, audio expressions, and the collective sentiment of a scene can be used to inform and direct agent responses within the given environment. To accelerate research on agent-based multimodal intelligence, we define "Agent AI" as a class of interactive systems that can perceive visual stimuli, language inputs, and other environmentally-grounded data, an
    
[^68]: 高效量化合作多智能体强化学习中个体智能体重要性的方法

    Efficiently Quantifying Individual Agent Importance in Cooperative MARL. (arXiv:2312.08466v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.08466](http://arxiv.org/abs/2312.08466)

    本文提出了一种高效量化合作多智能体强化学习中个体智能体重要性的方法，相对于智能体数量具有线性计算复杂度，并与真实的Shapley值以及真实环境中的个体智能体奖励密切相关。

    

    在合作多智能体强化学习中测量个体智能体的贡献是具有挑战性的。在合作多智能体强化学习中，团队表现通常是通过单一共享的全局奖励推断出来的。目前最好的有效测量个体智能体贡献的方法之一是使用Shapley值。然而，计算这些值的成本很高，因为计算复杂度与智能体数量呈指数增长。在本文中，我们将差异奖励方法改进为一种量化个体智能体贡献的高效方法，称为Agent Importance，它相对于智能体数量具有线性的计算复杂度。我们通过实验证明，计算得到的值与真实的Shapley值以及用作环境中真实个体智能体奖励的基本事实密切相关。我们展示了Agent Importance如何帮助研究MARL。

    Measuring the contribution of individual agents is challenging in cooperative multi-agent reinforcement learning (MARL). In cooperative MARL, team performance is typically inferred from a single shared global reward. Arguably, among the best current approaches to effectively measure individual agent contributions is to use Shapley values. However, calculating these values is expensive as the computational complexity grows exponentially with respect to the number of agents. In this paper, we adapt difference rewards into an efficient method for quantifying the contribution of individual agents, referred to as Agent Importance, offering a linear computational complexity relative to the number of agents. We show empirically that the computed values are strongly correlated with the true Shapley values, as well as the true underlying individual agent rewards, used as the ground truth in environments where these are available. We demonstrate how Agent Importance can be used to help study MAR
    
[^69]: 一年能发生多大变化？重访多智体强化学习中的评估

    How much can change in a year? Revisiting Evaluation in Multi-Agent Reinforcement Learning. (arXiv:2312.08463v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.08463](http://arxiv.org/abs/2312.08463)

    本文重访了多智体强化学习（MARL）领域的评估问题，并扩展了之前的数据库，发现许多令人担忧的性能报告趋势仍然存在。

    

    在任何一个快速发展的研究领域中，建立 sound experimental standards 和 rigour 都是非常重要的。深度多智体强化学习（MARL）就是这样一个新兴领域。尽管取得了令人激动的进展，但MARL最近因为可复制性问题和缺乏标准化评估方法遭到了质疑，尤其是在合作设置中。虽然已经提出了一些协议来帮助缓解这个问题，但积极监测该领域的健康状况仍然是重要的。在本研究中，我们扩展了之前所发表的关于评估方法的数据库，其中包含了来自顶级会议的MARL出版物的元数据，并将从此更新后的数据库中提取的发现与他们的工作中确定的趋势进行比较。我们的分析表明，许多令人担忧的性能报告趋势仍然存在。这包括省略不确定性量化，不报告所有相关的评估细节以及算法开发类别的收窄。

    Establishing sound experimental standards and rigour is important in any growing field of research. Deep Multi-Agent Reinforcement Learning (MARL) is one such nascent field. Although exciting progress has been made, MARL has recently come under scrutiny for replicability issues and a lack of standardised evaluation methodology, specifically in the cooperative setting. Although protocols have been proposed to help alleviate the issue, it remains important to actively monitor the health of the field. In this work, we extend the database of evaluation methodology previously published by containing meta-data on MARL publications from top-rated conferences and compare the findings extracted from this updated database to the trends identified in their work. Our analysis shows that many of the worrying trends in performance reporting remain. This includes the omission of uncertainty quantification, not reporting all relevant evaluation details and a narrowing of algorithmic development classe
    
[^70]: 关于大型语言模型（LLM）的安全与隐私的调研：美好、恶劣和丑陋(arXiv:2312.02003v2 [cs.CR] UPDATED)

    A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly. (arXiv:2312.02003v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2312.02003](http://arxiv.org/abs/2312.02003)

    该论文调查了大型语言模型（LLM）与安全和隐私的相关性。研究发现LLMs在安全和隐私保护方面具有积极影响，但同时也存在潜在的风险、威胁和漏洞。

    

    大型语言模型（LLMs），如ChatGPT和Bard，已经革新了自然语言理解和生成。它们具有深入的语言理解能力、人类般的文本生成能力、语境感知和强大的问题解决能力，在各个领域（如搜索引擎、客户支持、翻译）中具有不可估量的价值。与此同时，LLMs也在安全领域引起了关注，揭示了安全漏洞，并展示了它们在安全相关任务中的潜力。本文探讨了LLMs与安全和隐私的交叉点。具体而言，我们研究了LLMs如何对安全和隐私产生积极影响，它们使用中可能存在的风险和威胁，以及LLMs内在的漏洞。通过综合文献回顾，本文将文献分为“美好”（有益的LLM应用）、“恶劣”（攻击性应用）和“丑陋”（LLMs的漏洞及其防御）。我们发现，

    Large Language Models (LLMs), such as ChatGPT and Bard, have revolutionized natural language understanding and generation. They possess deep language comprehension, human-like text generation capabilities, contextual awareness, and robust problem-solving skills, making them invaluable in various domains (e.g., search engines, customer support, translation). In the meantime, LLMs have also gained traction in the security community, revealing security vulnerabilities and showcasing their potential in security-related tasks. This paper explores the intersection of LLMs with security and privacy. Specifically, we investigate how LLMs positively impact security and privacy, potential risks and threats associated with their use, and inherent vulnerabilities within LLMs. Through a comprehensive literature review, the paper categorizes the papers into "The Good" (beneficial LLM applications), "The Bad" (offensive applications), and "The Ugly" (vulnerabilities of LLMs and their defenses). We ha
    
[^71]: ArabIcros: 基于人工智能的阿拉伯语填字游戏生成器用于教育应用

    ArabIcros: AI-Powered Arabic Crossword Puzzle Generation for Educational Applications. (arXiv:2312.01339v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.01339](http://arxiv.org/abs/2312.01339)

    本文介绍了基于人工智能技术的阿拉伯语填字游戏生成器ArabIcros，利用先进的语言模型生成独特且具有挑战性的线索，并通过教育性填字游戏提升学习体验，改变传统学习方法的格局。

    

    本文介绍了第一款由先进人工智能技术驱动的阿拉伯语填字游戏生成器。该系统利用GPT4、GPT3-Davinci、GPT3-Curie、GPT3-Babbage、GPT3-Ada和BERT等最新的大型语言模型，生成独特且具有挑战性的线索。基于包含超过50,000个线索-答案对的数据集，生成器采用微调、少量/零样本学习策略和严格的质量检查协议，以生成高质量的线索-答案对。值得注意的是，教育性填字游戏有助于增强记忆力、扩展词汇量和促进问题解决能力，从而通过有趣和吸引人的方式增强学习体验，改变传统学习方法的格局。整个系统可以被用作强大的教育工具，融合人工智能和创新的学习技术，为阿拉伯语填字游戏和技术与教育交叉领域带来变革时代。

    This paper presents the first Arabic crossword puzzle generator driven by advanced AI technology. Leveraging cutting-edge large language models including GPT4, GPT3-Davinci, GPT3-Curie, GPT3-Babbage, GPT3-Ada, and BERT, the system generates distinctive and challenging clues. Based on a dataset comprising over 50,000 clue-answer pairs, the generator employs fine-tuning, few/zero-shot learning strategies, and rigorous quality-checking protocols to enforce the generation of high-quality clue-answer pairs. Importantly, educational crosswords contribute to enhancing memory, expanding vocabulary, and promoting problem-solving skills, thereby augmenting the learning experience through a fun and engaging approach, reshaping the landscape of traditional learning methods. The overall system can be exploited as a powerful educational tool that amalgamates AI and innovative learning techniques, heralding a transformative era for Arabic crossword puzzles and the intersection of technology and educa
    
[^72]: GPT-4V驾驶：行人行为预测的挑战与前景

    GPT-4V Takes the Wheel: Promises and Challenges for Pedestrian Behavior Prediction. (arXiv:2311.14786v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2311.14786](http://arxiv.org/abs/2311.14786)

    本论文研究了GPT-4V在自动驾驶的行人行为预测中的应用，通过视觉语言模型的定量和定性评估，解决了传统深度学习方法难以捕捉行人和交通之间动态互动以及缺乏常识推理能力的问题。

    

    预测行人行为是确保自动驾驶汽车安全可靠的关键。尽管深度学习方法通过学习注释的视频序列表现出了很大潜力，但它们往往无法完全把握行人和交通之间的动态互动，这对准确预测至关重要。这些模型还缺乏细致入微的常识推理能力。此外，为这些模型手动标注数据集既昂贵又难以适应新情况。视觉语言模型（VLMs）的出现为解决这些问题提供了有希望的替代方案，因为它们具备先进的视觉和因果推理能力。据我们所知，这项研究是首次在自动驾驶的行人行为预测背景下对VLMs进行定量和定性评估。我们在公开可用的行人数据集JAAD和WiDEVIEW上评估了GPT-4V(ision)。我们的定量分析重点关注GPT-4V预测行人行为的能力。

    Predicting pedestrian behavior is the key to ensure safety and reliability of autonomous vehicles. While deep learning methods have been promising by learning from annotated video frame sequences, they often fail to fully grasp the dynamic interactions between pedestrians and traffic, crucial for accurate predictions. These models also lack nuanced common sense reasoning. Moreover, the manual annotation of datasets for these models is expensive and challenging to adapt to new situations. The advent of Vision Language Models (VLMs) introduces promising alternatives to these issues, thanks to their advanced visual and causal reasoning skills. To our knowledge, this research is the first to conduct both quantitative and qualitative evaluations of VLMs in the context of pedestrian behavior prediction for autonomous driving. We evaluate GPT-4V(ision) on publicly available pedestrian datasets: JAAD and WiDEVIEW. Our quantitative analysis focuses on GPT-4V's ability to predict pedestrian beha
    
[^73]: 下一代地球系统模型：面向可靠的混合模型的天气和气候应用

    Next-Generation Earth System Models: Towards Reliable Hybrid Models for Weather and Climate Applications. (arXiv:2311.13691v2 [physics.ao-ph] UPDATED)

    [http://arxiv.org/abs/2311.13691](http://arxiv.org/abs/2311.13691)

    这篇论文回顾了机器学习如何改变我们模拟地球系统的能力，并提出了开发混合的人工智能-物理模型、强调AI降尺度方法的稳健性以及推动包容性模型开发的建议。

    

    我们回顾了机器学习如何改变我们模拟地球系统的能力，并期望近期的突破将使瑞士的最终用户受益。根据我们的回顾，我们提出了三个建议。建议1: 开发混合的人工智能-物理模型：强调整合人工智能和物理建模，以提高可靠性，特别是对于较长的预测时段，同时平衡基于知识和数据驱动的组件以获得最佳性能。建议2: 强调AI降尺度方法的稳健性，优先使用尊重物理定律、保留变量间依赖关系和空间结构、准确表示局部极端情况的技术。建议3: 推动包容性模型开发：确保地球系统模型的开发对多元利益相关者是开放和可访问的，使预测员、公众和AI/统计专家能够使用、开发和参与其中。

    We review how machine learning has transformed our ability to model the Earth system, and how we expect recent breakthroughs to benefit end-users in Switzerland in the near future. Drawing from our review, we identify three recommendations.  Recommendation 1: Develop Hybrid AI-Physical Models: Emphasize the integration of AI and physical modeling for improved reliability, especially for longer prediction horizons, acknowledging the delicate balance between knowledge-based and data-driven components required for optimal performance. Recommendation 2: Emphasize Robustness in AI Downscaling Approaches, favoring techniques that respect physical laws, preserve inter-variable dependencies and spatial structures, and accurately represent extremes at the local scale. Recommendation 3: Promote Inclusive Model Development: Ensure Earth System Model development is open and accessible to diverse stakeholders, enabling forecasters, the public, and AI/statistics experts to use, develop, and engage w
    
[^74]: 通过整数规划对温顺函数进行分段多项式回归

    Piecewise polynomial regression of tame functions via integer programming. (arXiv:2311.13544v1 [math.OC] CROSS LISTED)

    [http://arxiv.org/abs/2311.13544](http://arxiv.org/abs/2311.13544)

    本论文提出了使用整数规划对温顺函数进行分段多项式回归的方法，这可以用于估计包含在许多应用中的温顺函数，并且展示了令人期待的计算结果。

    

    我们考虑估计属于一类特定的非光滑函数的函数的任务，即所谓的温顺函数。这些函数出现在各种应用中：深度学习的训练、混合整数规划的价值函数或小分子的波函数。我们展示了温顺函数在任何完全维度的立方体上可用分段多项式来逼近。然后我们提出了第一个分段多项式回归的混合整数规划形式。这些方法可用于估计温顺函数。我们展示了令人期待的计算结果。

    We consider the task of estimating functions belonging to a specific class of nonsmooth functions, namely so-called tame functions. These functions appear in a wide range of applications: training deep learning, value functions of mixed-integer programs, or wave functions of small molecules. We show that tame functions are approximable by piecewise polynomials on any full-dimensional cube. We then present the first ever mixed-integer programming formulation of piecewise polynomial regression. Together, these can be used to estimate tame functions. We demonstrate promising computational results.
    
[^75]: 利用生成型人工智能进行临床证据摘要需要确保可靠性

    Leveraging Generative AI for Clinical Evidence Summarization Needs to Ensure Trustworthiness. (arXiv:2311.11211v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2311.11211](http://arxiv.org/abs/2311.11211)

    这项研究讨论了利用生成型人工智能进行临床证据摘要的可靠性问题，尤其关注开发问责制、公平和包容性的模型的挑战。

    

    证据医学承诺通过利用最佳可用证据来增强医疗决策和实践，从而提高医疗质量。医学证据的快速增长，可以从各种来源获取，给收集、评估和综合证据信息带来了挑战。最近生成型人工智能的进展，例如大型语言模型，有望促进这项艰巨的任务。然而，开发出具有问责制、公平和包容性的模型仍然是一项复杂的任务。在这个视角中，我们讨论了生成型人工智能在自动化医疗证据摘要方面的可靠性问题。

    Evidence-based medicine promises to improve the quality of healthcare by empowering medical decisions and practices with the best available evidence. The rapid growth of medical evidence, which can be obtained from various sources, poses a challenge in collecting, appraising, and synthesizing the evidential information. Recent advancements in generative AI, exemplified by large language models, hold promise in facilitating the arduous task. However, developing accountable, fair, and inclusive models remains a complicated undertaking. In this perspective, we discuss the trustworthiness of generative AI in the context of automated summarization of medical evidence.
    
[^76]: ViR: 迈向高效视觉保留骨干的研究

    ViR: Towards Efficient Vision Retention Backbones. (arXiv:2310.19731v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2310.19731](http://arxiv.org/abs/2310.19731)

    ViR提出了一种新的计算机视觉模型，采用双重并行和递归公式，从而在快速推理和并行训练之间取得了最佳平衡，具有竞争力的性能。

    

    近年来，视觉变换器（ViTs）因其在建模长程空间依赖性和大规模训练可扩展性方面的卓越能力而受到广泛关注。尽管自注意机制的训练并行性在保持出色性能方面起着重要作用，但其二次复杂度阻碍了ViTs在许多需要快速推理的场景中的应用。这种影响在需要自回归建模输入特征的应用中尤为明显。在自然语言处理（NLP）中，一种新的努力方向提出了具有可并行化模型和递归公式的模型，可以在生成应用中实现高效推理。受到这一趋势的启发，我们提出了一种新的计算机视觉模型，名为Vision Retention Networks（ViR），具有双重并行和递归公式，可以在快速推理和并行训练方面取得最佳平衡，并具有竞争力的性能。

    Vision Transformers (ViTs) have attracted a lot of popularity in recent years, due to their exceptional capabilities in modeling long-range spatial dependencies and scalability for large scale training. Although the training parallelism of self-attention mechanism plays an important role in retaining great performance, its quadratic complexity baffles the application of ViTs in many scenarios which demand fast inference. This effect is even more pronounced in applications in which autoregressive modeling of input features is required. In Natural Language Processing (NLP), a new stream of efforts has proposed parallelizable models with recurrent formulation that allows for efficient inference in generative applications. Inspired by this trend, we propose a new class of computer vision models, dubbed Vision Retention Networks (ViR), with dual parallel and recurrent formulations, which strike an optimal balance between fast inference and parallel training with competitive performance. In 
    
[^77]: 一个通用框架实现G-等变网络中的强鲁棒性

    A General Framework for Robust G-Invariance in G-Equivariant Networks. (arXiv:2310.18564v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.18564](http://arxiv.org/abs/2310.18564)

    这项研究介绍了一种通用方法，通过引入G-三重相关层，在G-等变卷积神经网络中实现强鲁棒性。该方法利用完备的三重相关理论，这使得G-TC层能够在面对不变性攻击时具有强大的鲁棒性，并且能够在分类准确率上相比标准的Max G-Pooling有明显的改善。

    

    我们引入了一种通用方法，用于实现G-等变卷积神经网络（G-CNNs）中的强组不变性，我们将其称为G-三重相关（G-TC）层。该方法利用了群上的三重相关理论，该理论是唯一的、最低次数的多项式不变映射，同时也是完备的。许多常用的不变映射，例如max，是不完备的：它们会同时去除群和信号结构。相比之下，完备的不变映射只移除由于群作用引起的变化，同时保留有关信号结构的所有信息。三重相关的完备性赋予了G-TC层强大的鲁棒性，这可以在其对不变性攻击的抵抗中观察到。此外，我们观察到它相比于G-CNN架构中的标准Max G-Pooling在分类准确率上有明显的改善。我们提供了该方法的通用且高效的实现。

    We introduce a general method for achieving robust group-invariance in group-equivariant convolutional neural networks ($G$-CNNs), which we call the $G$-triple-correlation ($G$-TC) layer. The approach leverages the theory of the triple-correlation on groups, which is the unique, lowest-degree polynomial invariant map that is also complete. Many commonly used invariant maps--such as the max--are incomplete: they remove both group and signal structure. A complete invariant, by contrast, removes only the variation due to the actions of the group, while preserving all information about the structure of the signal. The completeness of the triple correlation endows the $G$-TC layer with strong robustness, which can be observed in its resistance to invariance-based adversarial attacks. In addition, we observe that it yields measurable improvements in classification accuracy over standard Max $G$-Pooling in $G$-CNN architectures. We provide a general and efficient implementation of the method 
    
[^78]: 用大语言模型进行推荐中的表示学习

    Representation Learning with Large Language Models for Recommendation. (arXiv:2310.15950v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2310.15950](http://arxiv.org/abs/2310.15950)

    这篇论文介绍了一个模型-不可知的框架RLMRec，通过使用大语言模型（LLMs）来增强传统的基于ID的推荐系统，并解决了可扩展性问题、仅依赖文本的限制以及提示输入限制等挑战。

    

    推荐系统在深度学习和图神经网络的影响下取得了显著进展，特别是在捕捉复杂的用户-物品关系方面。然而，这些基于图的推荐系统严重依赖于基于ID的数据，可能忽略了与用户和物品相关的有价值的文本信息，导致学到的表示不够富有信息。此外，隐式反馈数据的利用引入了潜在的噪声和偏差，给用户偏好学习的有效性带来了挑战。尽管将大语言模型（LLMs）与传统的基于ID的推荐系统相结合已经引起了人们的关注，但在实际推荐系统中有效实施还需要解决可扩展性问题、仅依赖文本的限制以及提示输入限制等挑战。为了解决这些挑战，我们提出了一个模型不可知的框架RLMRec，旨在通过LLM强化表示来增强现有的推荐系统。

    Recommender systems have seen significant advancements with the influence of deep learning and graph neural networks, particularly in capturing complex user-item relationships. However, these graph-based recommenders heavily depend on ID-based data, potentially disregarding valuable textual information associated with users and items, resulting in less informative learned representations. Moreover, the utilization of implicit feedback data introduces potential noise and bias, posing challenges for the effectiveness of user preference learning. While the integration of large language models (LLMs) into traditional ID-based recommenders has gained attention, challenges such as scalability issues, limitations in text-only reliance, and prompt input constraints need to be addressed for effective implementation in practical recommender systems. To address these challenges, we propose a model-agnostic framework RLMRec that aims to enhance existing recommenders with LLM-empowered representati
    
[^79]: 安全深度策略适应

    Safe Deep Policy Adaptation. (arXiv:2310.08602v1 [cs.RO])

    [http://arxiv.org/abs/2310.08602](http://arxiv.org/abs/2310.08602)

    该论文提出了SafeDPA，一种新颖的强化学习和控制框架，用于同时解决策略适应和安全强化学习的问题。SafeDPA在仿真环境中联合学习自适应策略和动力学模型，并使用少量真实数据进行微调。在真实世界部署过程中，通过引入基于控制屏障函数的安全过滤器，确保了SafeDPA的安全性。

    

    自主和人工智能的一个重要目标是使自主机器人能够在动态和不确定的环境中快速适应。经典的自适应控制和安全控制提供了稳定性和安全性保证，但仅限于特定的系统类别。相比之下，基于强化学习（RL）的策略适应提供了通用性和泛化性，但同时也带来了安全性和稳健性的挑战。我们提出了SafeDPA，一种新颖的RL和控制框架，同时解决了策略适应和安全强化学习的问题。SafeDPA在仿真环境中联合学习自适应策略和动力学模型，预测环境配置，并使用少量真实数据对动力学模型进行微调。在RL策略之上引入基于控制屏障函数（CBF）的安全过滤器，以确保在真实世界部署过程中的安全性。我们提供了SafeDPA的理论安全性保证，并展示了SafeDPA对学习误差的稳健性。

    A critical goal of autonomy and artificial intelligence is enabling autonomous robots to rapidly adapt in dynamic and uncertain environments. Classic adaptive control and safe control provide stability and safety guarantees but are limited to specific system classes. In contrast, policy adaptation based on reinforcement learning (RL) offers versatility and generalizability but presents safety and robustness challenges. We propose SafeDPA, a novel RL and control framework that simultaneously tackles the problems of policy adaptation and safe reinforcement learning. SafeDPA jointly learns adaptive policy and dynamics models in simulation, predicts environment configurations, and fine-tunes dynamics models with few-shot real-world data. A safety filter based on the Control Barrier Function (CBF) on top of the RL policy is introduced to ensure safety during real-world deployment. We provide theoretical safety guarantees of SafeDPA and show the robustness of SafeDPA against learning errors 
    
[^80]: AI-机器人中的安全考虑：当前方法、挑战和机会的调查

    Security Considerations in AI-Robotics: A Survey of Current Methods, Challenges, and Opportunities. (arXiv:2310.08565v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2310.08565](http://arxiv.org/abs/2310.08565)

    本文调查和分类了AI-机器人系统中的安全问题，包括攻击面、道德和法律问题以及人机交互安全。旨在为用户、开发者和其他利益相关者提供指导。

    

    自从它们诞生以来，机器人和人工智能（AI）就密不可分地联系在一起。如今，AI-机器人系统已经成为我们日常生活的重要组成部分，从机器人吸尘器到半自动驾驶汽车。这些系统建立在三个基本的架构元素上：感知、导航与规划，以及控制。然而，尽管AI-机器人系统的整合提高了我们生活的质量，但也带来了一个严重的问题 - 这些系统容易受到安全攻击。构成AI-机器人系统的物理组件、算法和数据可能会被恶意行为者利用，可能导致严重后果。基于应对AI-机器人系统中的安全问题的需求，本文在攻击面、道德和法律问题以及人机交互安全三个维度上提供了一份全面的调查和分类。我们的目标是为用户、开发者和其他利益相关者提供指导。

    Robotics and Artificial Intelligence (AI) have been inextricably intertwined since their inception. Today, AI-Robotics systems have become an integral part of our daily lives, from robotic vacuum cleaners to semi-autonomous cars. These systems are built upon three fundamental architectural elements: perception, navigation and planning, and control. However, while the integration of AI-Robotics systems has enhanced the quality our lives, it has also presented a serious problem - these systems are vulnerable to security attacks. The physical components, algorithms, and data that make up AI-Robotics systems can be exploited by malicious actors, potentially leading to dire consequences. Motivated by the need to address the security concerns in AI-Robotics systems, this paper presents a comprehensive survey and taxonomy across three dimensions: attack surfaces, ethical and legal concerns, and Human-Robot Interaction (HRI) security. Our goal is to provide users, developers and other stakehol
    
[^81]: ECoFLaP: 高效的粗到细的逐层剪枝方法用于视觉语言模型

    ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models. (arXiv:2310.02998v1 [cs.CV])

    [http://arxiv.org/abs/2310.02998](http://arxiv.org/abs/2310.02998)

    ECoFLaP提出了一种高效的粗到细的逐层剪枝方法，解决了大型视觉语言模型在压缩和部署时的计算和能耗问题。

    

    大型视觉语言模型（LVLMs）通过整合不同模态的丰富信息，全面理解世界，并在各种多模态下游任务上取得显著的性能提升。然而，由于其巨大的计算/能耗和碳排放，部署LVLMs往往存在问题。这些问题使得采用传统的迭代全局剪枝变得不可行，因为其需要计算整个大型模型的Hessian矩阵以进行稀疏化。相反，最近的研究提出了逐层剪枝方法，避免了全局剪枝的昂贵计算，并根据层内权重的重要性有效压缩模型。然而，这些方法常常由于缺乏全局视角而导致模型压缩不够优化。为了解决大型模型最近高效剪枝方法的这一局限性，我们提出了高效的粗到细的逐层剪枝方法（ECoFLaP）。

    Large Vision-Language Models (LVLMs) can understand the world comprehensively by integrating rich information from different modalities, achieving remarkable performance improvements on various multimodal downstream tasks. However, deploying LVLMs is often problematic due to their massive computational/energy costs and carbon consumption. Such issues make it infeasible to adopt conventional iterative global pruning, which is costly due to computing the Hessian matrix of the entire large model for sparsification. Alternatively, several studies have recently proposed layer-wise pruning approaches to avoid the expensive computation of global pruning and efficiently compress model weights according to their importance within a layer. However, these methods often suffer from suboptimal model compression due to their lack of a global perspective. To address this limitation in recent efficient pruning methods for large models, we propose Efficient Coarse-to-Fine Layer-Wise Pruning (ECoFLaP), 
    
[^82]: MagicDrive: 多样化的三维几何控制下的街景生成

    MagicDrive: Street View Generation with Diverse 3D Geometry Control. (arXiv:2310.02601v1 [cs.CV])

    [http://arxiv.org/abs/2310.02601](http://arxiv.org/abs/2310.02601)

    MagicDrive是一个新颖的街景生成框架，通过提供多样化的三维几何控制，包括相机姿态、道路地图和三维边界框，以及文本描述，实现了高保真度的街景合成，并捕捉了细致的三维几何信息。

    

    最近扩散模型的进展显著提高了具有2D控制的数据合成。然而，在街景生成中精确的三维控制在三维感知任务中至关重要，但仍然难以实现。具体来说，使用鸟瞰图作为主要条件常常导致几何控制（如高度）方面的挑战，影响物体形状、遮挡模式和道路表面高程等对感知数据合成至关重要的因素，特别是对于三维物体检测任务而言。在本文中，我们介绍了MagicDrive，这是一个新颖的街景生成框架，提供了多样化的三维几何控制，包括相机姿态、道路地图和三维边界框，以及通过定制的编码策略实现的文本描述。此外，我们的设计还采用了跨视图注意力模块，确保多个相机视图之间的一致性。通过MagicDrive，我们实现了高保真度的街景合成，捕捉到了精细的三维几何信息。

    Recent advancements in diffusion models have significantly enhanced the data synthesis with 2D control. Yet, precise 3D control in street view generation, crucial for 3D perception tasks, remains elusive. Specifically, utilizing Bird's-Eye View (BEV) as the primary condition often leads to challenges in geometry control (e.g., height), affecting the representation of object shapes, occlusion patterns, and road surface elevations, all of which are essential to perception data synthesis, especially for 3D object detection tasks. In this paper, we introduce MagicDrive, a novel street view generation framework offering diverse 3D geometry controls, including camera poses, road maps, and 3D bounding boxes, together with textual descriptions, achieved through tailored encoding strategies. Besides, our design incorporates a cross-view attention module, ensuring consistency across multiple camera views. With MagicDrive, we achieve high-fidelity street-view synthesis that captures nuanced 3D ge
    
[^83]: ChaCha：利用大型语言模型引导儿童分享与个人事件相关的情绪

    ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events. (arXiv:2309.12244v1 [cs.HC])

    [http://arxiv.org/abs/2309.12244](http://arxiv.org/abs/2309.12244)

    ChaCha是一个利用大型语言模型（LLMs）的聊天机器人，鼓励儿童分享个人事件和相关情绪。通过一个探索性研究，发现儿童将ChaCha视为亲密的朋友，并愿意与其分享各种主题的故事。

    

    儿童通常通过与家人或他人分享故事和感受来学习辨识和表达情绪，然而，由于儿童正在发展他们的交流技能，父母或兄弟姐妹很难与他们进行情感沟通。本文介绍了ChaCha，一个鼓励和引导儿童分享个人事件和相关情绪的聊天机器人。ChaCha结合了状态机和大型语言模型（LLMs），在进行自由对话的同时保持对话的方向性。通过与20名年龄在8-12岁的儿童进行的探索性研究，我们研究了ChaCha如何促使儿童分享个人事件并引导他们描述相关情绪。参与者认为ChaCha就像一个亲密的朋友，并分享了各种主题的故事，如家庭旅行和个人成就。基于定量和定性发现，我们讨论了利用LLMs设计适合儿童的聊天机器人的机遇。

    Children typically learn to identify and express emotions through sharing their stories and feelings with others, particularly their family. However, it is challenging for parents or siblings to have emotional communication with children since children are still developing their communication skills. We present ChaCha, a chatbot that encourages and guides children to share personal events and associated emotions. ChaCha combines a state machine and large language models (LLMs) to keep the dialogue on track while carrying on free-form conversations. Through an exploratory study with 20 children (aged 8-12), we examine how ChaCha prompts children to share personal events and guides them to describe associated emotions. Participants perceived ChaCha as a close friend and shared their stories on various topics, such as family trips and personal achievements. Based on the quantitative and qualitative findings, we discuss opportunities for leveraging LLMs to design child-friendly chatbots to
    
[^84]: 通过时间滞后信息瓶颈的潜在表示和马尔可夫过程模拟

    Latent Representation and Simulation of Markov Processes via Time-Lagged Information Bottleneck. (arXiv:2309.07200v1 [cs.LG])

    [http://arxiv.org/abs/2309.07200](http://arxiv.org/abs/2309.07200)

    本文介绍了一种通过时间滞后信息瓶颈的方法，将复杂系统映射到简化表示空间并模拟时间上的大跳跃。实验证明该方法能够准确模拟原始过程的统计特性和动力学，优于现有的时间滞后降维方法。

    

    马尔可夫过程是描述各个领域中动态系统的广泛使用的数学模型。然而，由于需要准确积分的短时间步长，精确模拟长时间尺度上的大规模系统计算量很大。在本文中，我们引入了一种将复杂系统映射到简化表示空间并模拟时间上的大跳跃的推理过程。为了实现这一点，我们提出了基于信息理论的原则目标-时间滞后信息瓶颈（T-IB），它旨在捕捉相关的时间特征，同时丢弃高频信息以简化模拟任务并最小化推理误差。我们的实验证明，T-IB学习了信息最优的表示，能够准确地模拟原始过程在选择的时间滞后下的统计特性和动力学，并且优于现有的时间滞后降维方法。

    Markov processes are widely used mathematical models for describing dynamic systems in various fields. However, accurately simulating large-scale systems at long time scales is computationally expensive due to the short time steps required for accurate integration. In this paper, we introduce an inference process that maps complex systems into a simplified representational space and models large jumps in time. To achieve this, we propose Time-lagged Information Bottleneck (T-IB), a principled objective rooted in information theory, which aims to capture relevant temporal features while discarding high-frequency information to simplify the simulation task and minimize the inference error. Our experiments demonstrate that T-IB learns information-optimal representations for accurately modeling the statistical properties and dynamics of the original process at a selected time lag, outperforming existing time-lagged dimensionality reduction methods.
    
[^85]: HC3 Plus：一个语义不变的人类ChatGPT对比语料库

    HC3 Plus: A Semantic-Invariant Human ChatGPT Comparison Corpus. (arXiv:2309.02731v1 [cs.CL])

    [http://arxiv.org/abs/2309.02731](http://arxiv.org/abs/2309.02731)

    本文介绍了HC3 Plus，一个语义不变的人类ChatGPT对比语料库。与以往的工作相比，该语料库考虑了更多类型的任务，包括语义不变任务。研究发现，在语义不变任务中检测模型生成的文本更加困难。通过大量任务指令微调和Tk-instruct，建立了一个更强大的模型。

    

    ChatGPT因其出色的性能而引起了人们的广泛关注，但人们对其潜在风险，尤其是对AI生成内容（AIGC）的检测越来越关注，这对未经训练的人类来说往往很难识别。目前用于检测ChatGPT生成文本的数据集主要集中在问答方面，但往往忽视了具有语义不变性的任务，如摘要、翻译和改写。我们的研究表明，在语义不变任务上检测模型生成的文本更加困难。为了填补这一空白，我们引入了一个更广泛、更全面的数据集，考虑了比以前的工作更多类型的任务，包括语义不变任务。此外，经过大量任务指令微调的模型表现出很强的性能。基于以前的成功，我们进一步指导微调了Tk-instruct，并构建了一个更强大的模型。

    ChatGPT has gained significant interest due to its impressive performance, but people are increasingly concerned about its potential risks, particularly around the detection of AI-generated content (AIGC), which is often difficult for untrained humans to identify. Current datasets utilized for detecting ChatGPT-generated text primarily center around question-answering, yet they tend to disregard tasks that possess semantic-invariant properties, such as summarization, translation, and paraphrasing. Our primary studies demonstrate that detecting model-generated text on semantic-invariant tasks is more difficult. To fill this gap, we introduce a more extensive and comprehensive dataset that considers more types of tasks than previous work, including semantic-invariant tasks. In addition, the model after a large number of task instruction fine-tuning shows a strong powerful performance. Owing to its previous success, we further instruct fine-tuning Tk-instruct and built a more powerful det
    
[^86]: WeatherBench 2：下一代数据驱动全球天气模型的基准测试

    WeatherBench 2: A benchmark for the next generation of data-driven global weather models. (arXiv:2308.15560v1 [physics.ao-ph])

    [http://arxiv.org/abs/2308.15560](http://arxiv.org/abs/2308.15560)

    WeatherBench 2更新了全球中期天气预测基准测试，旨在加速数据驱动天气建模的进展，提供了开源评估框架和最新的模型性能指标。此外，还讨论了当前评估设置中的注意事项和未来的挑战。

    

    WeatherBench 2是对Rasp等人（2020）提出的全球中期（1-14天）天气预测基准测试的更新，旨在加速数据驱动天气建模的进展。WeatherBench 2包括一个开源评估框架，公开可用的训练、基准数据和基线数据，以及一个持续更新的网站，其中包含最新的指标和最先进的模型：https://sites.research.google/weatherbench。本文描述了评估框架的设计原则，并提供当前最先进的物理和数据驱动天气模型的结果。这些指标基于领先操作性天气中心评估天气预报的实践。我们定义了一组主要得分，以提供模型性能的概览。此外，我们还讨论了当前评估设置中的注意事项和数据驱动天气预测未来的挑战。

    WeatherBench 2 is an update to the global, medium-range (1-14 day) weather forecasting benchmark proposed by Rasp et al. (2020), designed with the aim to accelerate progress in data-driven weather modeling. WeatherBench 2 consists of an open-source evaluation framework, publicly available training, ground truth and baseline data as well as a continuously updated website with the latest metrics and state-of-the-art models: https://sites.research.google/weatherbench. This paper describes the design principles of the evaluation framework and presents results for current state-of-the-art physical and data-driven weather models. The metrics are based on established practices for evaluating weather forecasts at leading operational weather centers. We define a set of headline scores to provide an overview of model performance. In addition, we also discuss caveats in the current evaluation setup and challenges for the future of data-driven weather forecasting.
    
[^87]: FlexKBQA：一种用于少样本知识库问答的灵活LLM驱动框架

    FlexKBQA: A Flexible LLM-Powered Framework for Few-Shot Knowledge Base Question Answering. (arXiv:2308.12060v1 [cs.CL])

    [http://arxiv.org/abs/2308.12060](http://arxiv.org/abs/2308.12060)

    FlexKBQA使用大型语言模型(LLMs)作为程序翻译器，通过自动化算法从知识库中抽样多样的程序，将其转换为自然语言问题，从而解决少样本知识库问答任务的挑战。

    

    知识库问答（KBQA）是一个关键且具有挑战性的任务，因为知识库中的实体数量庞大，并且用户提出的自然语言问题多样化。不幸的是，大多数KBQA模型在现实场景中性能显著下降，因为高质量的注释数据不足。为了减轻手动注释的负担，我们利用大型语言模型（LLMs）作为程序翻译器，介绍了FlexKBQA来解决少样本KBQA任务中固有的挑战。具体而言，FlexKBQA利用自动化算法从知识库中抽样多样的程序（如SPARQL查询），然后通过LLMs将其转换为自然语言问题。这个合成的数据集有助于训练一个专门的轻量级模型来处理知识库。此外，为了减少合成数据与真实用户问题之间的分布偏移的障碍，FlexKBQA引入了一个执行机制。

    Knowledge base question answering (KBQA) is a critical yet challenging task due to the vast number of entities within knowledge bases and the diversity of natural language questions posed by users. Unfortunately, the performance of most KBQA models tends to decline significantly in real-world scenarios where high-quality annotated data is insufficient. To mitigate the burden associated with manual annotation, we introduce FlexKBQA by utilizing Large Language Models (LLMs) as program translators for addressing the challenges inherent in the few-shot KBQA task. Specifically, FlexKBQA leverages automated algorithms to sample diverse programs, such as SPARQL queries, from the knowledge base, which are subsequently converted into natural language questions via LLMs. This synthetic dataset facilitates training a specialized lightweight model for the KB. Additionally, to reduce the barriers of distribution shift between synthetic data and real user questions, FlexKBQA introduces an executiong
    
[^88]: 用于计算深度神经网络正则化路径的多目标延续方法

    A multiobjective continuation method to compute the regularization path of deep neural networks. (arXiv:2308.12044v1 [cs.LG])

    [http://arxiv.org/abs/2308.12044](http://arxiv.org/abs/2308.12044)

    本文提出了一种多目标延续方法，用于计算深度神经网络的正则化路径，以解决DNNs中稀疏性和数值效率之间的冲突。

    

    稀疏性是深度神经网络(DNNs)中非常理想的特征，因为它确保了数值效率，提高了模型的可解释性(由于相关特征的数量较少)和鲁棒性。在基于线性模型的机器学习方法中，众所周知在$\ell^1$范数(即零权重)的最稀疏解和非正则化解之间存在一条连接路径，这条路径被称为正则化路径。最近，通过将经验损失和稀疏性($\ell^1$范数)作为两个冲突的标准，并解决由此产生的多目标优化问题，首次尝试将正则化路径的概念扩展到DNNs。然而，由于$\ell^1$范数的不光滑性和参数数量的高度，从计算的角度来看，这种方法并不是很有效。为了克服这个限制，我们提出了一种算法，可以近似计算整个帕累托曲线

    Sparsity is a highly desired feature in deep neural networks (DNNs) since it ensures numerical efficiency, improves the interpretability of models (due to the smaller number of relevant features), and robustness. In machine learning approaches based on linear models, it is well known that there exists a connecting path between the sparsest solution in terms of the $\ell^1$ norm (i.e., zero weights) and the non-regularized solution, which is called the regularization path. Very recently, there was a first attempt to extend the concept of regularization paths to DNNs by means of treating the empirical loss and sparsity ($\ell^1$ norm) as two conflicting criteria and solving the resulting multiobjective optimization problem. However, due to the non-smoothness of the $\ell^1$ norm and the high number of parameters, this approach is not very efficient from a computational perspective. To overcome this limitation, we present an algorithm that allows for the approximation of the entire Pareto
    
[^89]: 在增强的不变关系知识上探索超关系时间知识图的链接预测

    Exploring Link Prediction over Hyper-Relational Temporal Knowledge Graphs Enhanced with Time-Invariant Relational Knowledge. (arXiv:2307.10219v1 [cs.AI])

    [http://arxiv.org/abs/2307.10219](http://arxiv.org/abs/2307.10219)

    这项研究填补了时间KG和超关系KG推理之间的差距，并开发了两个新的基准超关系TKG数据集。

    

    超关系知识图(HKGs)是传统知识图(KGs)的延伸，为每个KG事实提供额外的键值对(即限定词)，以更好地限制事实的有效性。近年来，研究在HKGs上进行图推理越来越受关注。与此同时，由于世界知识的不断演变，大量平行工作集中在对时间KGs(TKGs)进行推理，其中每个TKG事实可以被视为带有时间戳(或时间段)的KG事实，指定其时间有效性。现有的HKG推理方法不考虑时间信息，因为在之前的基准数据集中没有显式地指定。此外，所有以前的TKG推理方法只重视时间推理，并没有办法从限定词中学习。因此，我们的目标是填补TKG推理和HKG推理之间的差距。我们开发了两个新的基准超关系TKG(HTKG)数据集，即Wiki-hy和...

    Stemming from traditional knowledge graphs (KGs), hyper-relational KGs (HKGs) provide additional key-value pairs (i.e., qualifiers) for each KG fact that help to better restrict the fact validity. In recent years, there has been an increasing interest in studying graph reasoning over HKGs. In the meantime, due to the ever-evolving nature of world knowledge, extensive parallel works have been focusing on reasoning over temporal KGs (TKGs), where each TKG fact can be viewed as a KG fact coupled with a timestamp (or time period) specifying its time validity. The existing HKG reasoning approaches do not consider temporal information because it is not explicitly specified in previous benchmark datasets. Besides, all the previous TKG reasoning methods only lay emphasis on temporal reasoning and have no way to learn from qualifiers. To this end, we aim to fill the gap between TKG reasoning and HKG reasoning. We develop two new benchmark hyper-relational TKG (HTKG) datasets, i.e., Wiki-hy and 
    
[^90]: 渐进傅里叶神经表示用于顺序视频编译

    Progressive Fourier Neural Representation for Sequential Video Compilation. (arXiv:2306.11305v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.11305](http://arxiv.org/abs/2306.11305)

    本研究提出了一种渐进傅里叶神经表示方法，通过在每个训练会话中找到自适应且紧凑的傅里叶空间子模块来编码顺序视频数据，克服了现有神经隐式表示方法在多个复杂数据上的泛化能力差的问题。

    

    最近神经隐式表示(NIR)因其将复杂和高维数据编码为表示空间并通过可训练的映射函数轻松重构数据的非凡能力而引起了极大关注。然而，NIR方法假定目标数据和表示模型之间存在一对一的映射，而不考虑数据的相关性或相似性。这导致在多组复杂数据上泛化能力较差，并限制了其效率和可伸缩性。受持续学习的启发，本研究探讨了如何在顺序编码会话中累积和传递多个复杂视频数据的神经隐式表示。为了克服NIR的局限性，我们提出了一种新的方法，即渐进傅里叶神经表示(PFNR)，旨在找到一个自适应和紧凑的傅里叶空间子模块，以编码每个训练会话中的视频。这种稀疏的神经编码使神经网络能够持有自由权重，实现了一种可迭代地编码和解码多个顺序视频数据的方式。

    Neural Implicit Representation (NIR) has recently gained significant attention due to its remarkable ability to encode complex and high-dimensional data into representation space and easily reconstruct it through a trainable mapping function. However, NIR methods assume a one-to-one mapping between the target data and representation models regardless of data relevancy or similarity. This results in poor generalization over multiple complex data and limits their efficiency and scalability. Motivated by continual learning, this work investigates how to accumulate and transfer neural implicit representations for multiple complex video data over sequential encoding sessions. To overcome the limitation of NIR, we propose a novel method, Progressive Fourier Neural Representation (PFNR), that aims to find an adaptive and compact sub-module in Fourier space to encode videos in each training session. This sparsified neural encoding allows the neural network to hold free weights, enabling an imp
    
[^91]: 多领域联邦学习是否离不开标准化?

    Is Normalization Indispensable for Multi-domain Federated Learning?. (arXiv:2306.05879v1 [cs.LG])

    [http://arxiv.org/abs/2306.05879](http://arxiv.org/abs/2306.05879)

    本研究旨在解决联邦学习中的多领域问题。我们提出一种新的方法，FedWon，通过消除规范化步骤来有效地处理来自不同领域的数据。

    

    联邦学习通过分散在客户端上的协作式内部训练增强了数据隐私。然而，联邦学习面临诸多挑战，其中包括非独立同分布数据（non-i.i.d）导致的潜在性能下降和收敛受阻问题。我们的研究解决了一个关键但常常被忽视的问题——多领域联邦学习。在这种情况下，客户端数据来源于具有不同特征分布的各种领域，而不是标签分布。为了解决联邦学习中的多领域问题，我们提出了一种新方法称为不使用规范化的联邦学习（FedWon）。FedWon从一个观察出发，即批量归一化（BN）在有效地建模多个领域的统计信息方面面临挑战，而替代规范化技术具有自身的局限性。FedWon通过消除规范化步骤来解决这些问题。

    Federated learning (FL) enhances data privacy with collaborative in-situ training on decentralized clients. Nevertheless, FL encounters challenges due to non-independent and identically distributed (non-i.i.d) data, leading to potential performance degradation and hindered convergence. While prior studies predominantly addressed the issue of skewed label distribution, our research addresses a crucial yet frequently overlooked problem known as multi-domain FL. In this scenario, clients' data originate from diverse domains with distinct feature distributions, as opposed to label distributions. To address the multi-domain problem in FL, we propose a novel method called Federated learning Without normalizations (FedWon). FedWon draws inspiration from the observation that batch normalization (BN) faces challenges in effectively modeling the statistics of multiple domains, while alternative normalization techniques possess their own limitations. In order to address these issues, FedWon elimi
    
[^92]: 离线优先经验重放

    Offline Prioritized Experience Replay. (arXiv:2306.05412v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.05412](http://arxiv.org/abs/2306.05412)

    本文提出了离线优先经验重放（OPER）方法来解决离线强化学习中的分布偏移问题。通过设计一类优先级函数来对高回报的转换进行优先处理，从而改善行为策略，并在此改进的策略约束下优化离线强化学习算法的解决方案。对于离线强化学习，OPER方法是一种有效的解决方案。

    

    离线强化学习面临着分布偏移问题。为了解决这个问题，现有的工作主要集中在设计学习策略和行为策略之间的复杂约束。然而，这些约束通过均匀采样等方式被应用到表现良好和表现差的行动上，这可能会对学习策略产生负面影响。为了缓解这个问题，我们提出了离线优先经验重放（OPER），其中包括一类优先级函数，用于将高回报的转换置于更频繁的访问中。通过理论分析，我们证明了这类优先级函数能够引起行为策略的改善，当策略约束到这个改进的策略上时，离线强化学习算法很可能得到更好的解决方案。我们开发了两种实用策略来获得基于拟合值网络的优先权重（OPER-A）或者u

    Offline reinforcement learning (RL) is challenged by the distributional shift problem. To address this problem, existing works mainly focus on designing sophisticated policy constraints between the learned policy and the behavior policy. However, these constraints are applied equally to well-performing and inferior actions through uniform sampling, which might negatively affect the learned policy. To alleviate this issue, we propose Offline Prioritized Experience Replay (OPER), featuring a class of priority functions designed to prioritize highly-rewarding transitions, making them more frequently visited during training. Through theoretical analysis, we show that this class of priority functions induce an improved behavior policy, and when constrained to this improved policy, a policy-constrained offline RL algorithm is likely to yield a better solution. We develop two practical strategies to obtain priority weights by estimating advantages based on a fitted value network (OPER-A) or u
    
[^93]: 分布式智能体在均场博弈中的网络通信

    Networked Communication for Decentralised Agents in Mean-Field Games. (arXiv:2306.02766v2 [cs.MA] UPDATED)

    [http://arxiv.org/abs/2306.02766](http://arxiv.org/abs/2306.02766)

    本研究在均场博弈中引入网络通信，提出了一种提高分布式智能体学习效率的方案，并进行了实际实验验证。

    

    我们将网络通信引入均场博弈框架，特别是在无oracle的情况下，N个分布式智能体沿着经过的经验系统的单一非周期演化路径学习。我们证明，我们的架构在只有一些关于网络结构的合理假设的情况下，具有样本保证，在集中学习和独立学习情况之间有界。我们讨论了三个理论算法的样本保证实际上并不会导致实际收敛。因此，我们展示了在实际设置中，当理论参数未被观察到（导致Q函数的估计不准确）时，我们的通信方案显著加速了收敛速度，而无需依赖于一个不可取的集中式控制器的假设。我们对三个理论算法进行了几种实际的改进，使我们能够展示它们的第一个实证表现。

    We introduce networked communication to the mean-field game framework, in particular to oracle-free settings where $N$ decentralised agents learn along a single, non-episodic evolution path of the empirical system. We prove that our architecture, with only a few reasonable assumptions about network structure, has sample guarantees bounded between those of the centralised- and independent-learning cases. We discuss how the sample guarantees of the three theoretical algorithms do not actually result in practical convergence. Accordingly, we show that in practical settings where the theoretical parameters are not observed (leading to poor estimation of the Q-function), our communication scheme significantly accelerates convergence over the independent case, without relying on the undesirable assumption of a centralised controller. We contribute several further practical enhancements to all three theoretical algorithms, allowing us to showcase their first empirical demonstrations. Our expe
    
[^94]: MicroSegNet：一种基于深度学习的微型超声图像前列腺分割方法

    MicroSegNet: A Deep Learning Approach for Prostate Segmentation on Micro-Ultrasound Images. (arXiv:2305.19956v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.19956](http://arxiv.org/abs/2305.19956)

    本文提出了一种基于深度学习的微型超声图像前列腺分割方法，利用多尺度注释引导的Transformer UNet模型和注释引导的二分类交叉熵损失解决低分辨率和界限不清的挑战，该方法更加关注难以分割的区域。

    

    微型超声是一种新型的29MHz超声技术，提供比传统超声高3-4倍的分辨率，在诊断前列腺癌的准确性方面与MRI相当，但成本更低。然而，由于低分辨率和前列腺、膀胱和尿道中线之间的界限不清，基于微型超声的前列腺分割具有挑战性。本文提出了MicroSegNet，这是一个特别设计用于解决这些挑战的多尺度注释引导的Transformer UNet模型。在训练过程中，MicroSegNet更加关注难以分割（难区域）的区域，这些区域具有专家和非专家注释之间的差异。为此，我们提出了注释引导的二分类交叉熵（AG-BCE）损失，它在难区域中给预测误差分配更大的权重和较低的权重。

    Micro-ultrasound (micro-US) is a novel 29-MHz ultrasound technique that provides 3-4 times higher resolution than traditional ultrasound, delivering comparable accuracy for diagnosing prostate cancer to MRI but at a lower cost. Accurate prostate segmentation is crucial for prostate volume measurement, cancer diagnosis, prostate biopsy, and treatment planning. However, prostate segmentation on microUS is challenging due to artifacts and indistinct borders between the prostate, bladder, and urethra in the midline. This paper presents MicroSegNet, a multi-scale annotation-guided transformer UNet model designed specifically to tackle these challenges. During the training process, MicroSegNet focuses more on regions that are hard to segment (hard regions), characterized by discrepancies between expert and non-expert annotations. We achieve this by proposing an annotation-guided binary cross entropy (AG-BCE) loss that assigns a larger weight to prediction errors in hard regions and a lower w
    
[^95]: Sasha: 大型语言模型在智能家居中的创意目标导向推理

    Sasha: creative goal-oriented reasoning in smart homes with large language models. (arXiv:2305.09802v1 [cs.HC])

    [http://arxiv.org/abs/2305.09802](http://arxiv.org/abs/2305.09802)

    本论文研究了在智能家居中使用大型语言模型实现用户命令的创意目标导向推理。实验结果显示，这种方法可以创造性地推理，以实现挑战性的目标。

    

    智能家居的使用者与设备的交互都有明确或隐含的目标。现有的家庭助手能够轻松地实现明确的目标，例如"打开灯"。然而，在更自然的交流中，人们往往会描述隐含的目标。例如，我们可以让别人"让房间变得舒适"而不是描述具体的步骤。当前的系统很难解决这种歧义，因为需要将模糊的意图与具体的设备联系起来。我们从通用大型语言模型（LLMs）的角度来解决这个问题，这些模型经过大量语料库的训练，并通过灵活的方式适应下游任务。我们探讨了使用LLMs控制设备并创建自动化程序以满足用户命令的隐含目标。在以用户为中心的研究中，我们发现LLMs可以创造性地推理，以实现挑战性的目标，同时也揭示了降低其有用性的差距。我们使用Sasha解决了这些差距：这是一个在智能家居中使用LLMs进行灵活解释用户命令和设备控制的创意目标导向推理系统。

    Every smart home user interaction has an explicit or implicit goal. Existing home assistants easily achieve explicit goals, e.g., "turn on the light". In more natural communication, however, humans tend to describe implicit goals. We can, for example, ask someone to "make it cozy" rather than describe the specific steps involved. Current systems struggle with this ambiguity since it requires them to relate vague intent to specific devices. We approach this problem of flexibly achieving user goals from the perspective of general-purpose large language models (LLMs) trained on gigantic corpora and adapted to downstream tasks with remarkable flexibility. We explore the use of LLMs for controlling devices and creating automation routines to meet the implicit goals of user commands. In a user-focused study, we find that LLMs can reason creatively to achieve challenging goals, while also revealing gaps that diminish their usefulness. We address these gaps with Sasha: a system for creative, g
    
[^96]: 带有有限注释的分割任务中的期望最大化伪标签方法研究

    Expectation Maximization Pseudo Labelling for Segmentation with Limited Annotations. (arXiv:2305.01747v1 [cs.CV])

    [http://arxiv.org/abs/2305.01747](http://arxiv.org/abs/2305.01747)

    本文提出了一种伪标签的泛化方法，称为贝叶斯伪标签，在半监督医学图像分割任务中应用效果良好。

    

    本文研究了半监督医学图像分割中的伪标签及其推广，伪标签通过利用未标记数据的原始推断作为自训练的伪标签，在半监督学习中取得了巨大的实证成功。我们建立了伪标签和期望最大化算法之间的联系，部分解释了其实证成功。在此基础上，我们展示了贝叶斯原理下伪标签的完全泛化，称为贝叶斯伪标签。然后，我们提供了一种变分方法来学习逼近贝叶斯伪标签，通过学习选择高质量伪标签的阈值。接下来，我们在医学图像分割的半监督学习中展示了伪标签和其推广贝叶斯伪标签的应用。

    We study pseudo labelling and its generalisation for semi-supervised segmentation of medical images. Pseudo labelling has achieved great empirical successes in semi-supervised learning, by utilising raw inferences on unlabelled data as pseudo labels for self-training. In our paper, we build a connection between pseudo labelling and the Expectation Maximization algorithm which partially explains its empirical successes. We thereby realise that the original pseudo labelling is an empirical estimation of its underlying full formulation. Following this insight, we demonstrate the full generalisation of pseudo labels under Bayes' principle, called Bayesian Pseudo Labels. We then provide a variational approach to learn to approximate Bayesian Pseudo Labels, by learning a threshold to select good quality pseudo labels. In the rest of the paper, we demonstrate the applications of Pseudo Labelling and its generalisation Bayesian Psuedo Labelling in semi-supervised segmentation of medical images
    
[^97]: 通过从光流信息中融合运动结构与模拟数据的绝对位置回归，解决室内环境定位的挑战性问题

    Fusing Structure from Motion and Simulation-Augmented Pose Regression from Optical Flow for Challenging Indoor Environments. (arXiv:2304.07250v1 [cs.CV])

    [http://arxiv.org/abs/2304.07250](http://arxiv.org/abs/2304.07250)

    本文探讨了如何在室内环境下进行运动目标的定位，使用了结构运动与模拟数据和深度学习技术。研究者整合光流和相对姿态回归方法帮助解决了因运动模糊、光照变化、重复图案和缺乏特征结构等问题而带来的瓶颈，为室内目标定位提供了更好的方案。

    

    目标的定位是各种应用中的重要任务，比如机器人、虚拟和增强现实、和在仓库中运送货物。深度学习的先进发展已经使得使用单目视觉相机进行定位成为可能。然而，所面临的挑战是由于环境本身引起的问题，例如运动模糊、光照变化、重复图案和缺乏特征的结构。本研究旨在通过融合附加信息和使用相对位置回归（RPR）方法来解决这些问题。使用Lucas-Kanade算法计算连续图像之间的光流，并使用辅助小型循环卷积网络来预测相对姿态。将绝对姿态和相对姿态进行融合。

    The localization of objects is a crucial task in various applications such as robotics, virtual and augmented reality, and the transportation of goods in warehouses. Recent advances in deep learning have enabled the localization using monocular visual cameras. While structure from motion (SfM) predicts the absolute pose from a point cloud, absolute pose regression (APR) methods learn a semantic understanding of the environment through neural networks. However, both fields face challenges caused by the environment such as motion blur, lighting changes, repetitive patterns, and feature-less structures. This study aims to address these challenges by incorporating additional information and regularizing the absolute pose using relative pose regression (RPR) methods. The optical flow between consecutive images is computed using the Lucas-Kanade algorithm, and the relative pose is predicted using an auxiliary small recurrent convolutional network. The fusion of absolute and relative poses is
    
[^98]: 使用流引导的密度比学习进行生成建模

    Generative Modeling with Flow-Guided Density Ratio Learning. (arXiv:2303.03714v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.03714](http://arxiv.org/abs/2303.03714)

    FDRL是一种基于流引导的密度比学习的简单且可扩展的生成建模方法，通过训练密度比估计器从逐渐改进的样本中学习，缓解了密度鸿沟问题，并在生成高尺寸图像上表现优于现有基线方法。

    

    我们提出了一种简单且可扩展的生成建模方法，称为流引导的密度比学习（FDRL）。该方法基于DGflow中引入的基于熵正则化f-散度的梯度流的过时（时间无关）近似，并且通过GAN鉴别器给出的过时估计器近似了不可计算的时间相关密度比。在样本细化的情况下，这种近似足够，因为流的源分布和目标分布是相近的。然而，在生成的情况下，这个假设是无效的，而且过时估计器的朴素应用由于两个分布之间的大鸿沟而失败。FDRL提出了训练密度比估计器的方法，使其在训练过程中从逐渐改进的样本中学习。我们展示了这种简单的方法缓解了密度鸿沟问题，使得FDRL能够生成高达$128\times128$尺寸的图像，并且在质量上超过了现有的梯度流基线方法。

    We present Flow-Guided Density Ratio Learning (FDRL), a simple and scalable approach to generative modeling which builds on the stale (time-independent) approximation of the gradient flow of entropy-regularized f-divergences introduced in DGflow. In DGflow, the intractable time-dependent density ratio is approximated by a stale estimator given by a GAN discriminator. This is sufficient in the case of sample refinement, where the source and target distributions of the flow are close to each other. However, this assumption is invalid for generation and a naive application of the stale estimator fails due to the large chasm between the two distributions. FDRL proposes to train a density ratio estimator such that it learns from progressively improving samples during the training process. We show that this simple method alleviates the density chasm problem, allowing FDRL to generate images of dimensions as high as $128\times128$, as well as outperform existing gradient flow baselines on qua
    
[^99]: 双重强化学习：强化学习和模仿学习的统一和新方法

    Dual RL: Unification and New Methods for Reinforcement and Imitation Learning. (arXiv:2302.08560v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.08560](http://arxiv.org/abs/2302.08560)

    这篇论文介绍了双重强化学习的概念，并在一个统一的框架下解释了几种最新深度强化学习算法及模仿学习方法。作者提出了双重模仿学习方法（DIL）直接最小化策略之间的距离，并提出了一种新的离线演员-评论家方法。

    

    强化学习的目标是最大化期望累积回报。研究表明，这个目标可以通过在线性约束下优化状态-动作访问分布的优化问题来表示。这个表述的对偶问题，我们称之为双重强化学习，是无约束的并且更容易优化。我们展示了几个最先进的离线和在线强化学习算法以及模仿学习可以在一个统一的框架下被视为双重强化学习方法。这种统一提供了一个共同的基础，可以研究和识别这些方法成功的构成部分，并揭示这些方法的共同缺点和改进的新见解。我们的分析表明，以前的离线模仿学习方法基于一个不现实的覆盖率假设，并最小化了学习代理和专家访问分布之间的特定f-分布。我们提出的双重模仿学习方法（DIL）直接最小化策略之间的距离。在同样的双重框架下，我们还提出了一种新的离线演员-评论家方法，对几个基准任务有效。

    The goal of reinforcement learning (RL) is to maximize the expected cumulative return. It has been shown that this objective can be represented by an optimization problem of the state-action visitation distribution under linear constraints. The dual problem of this formulation, which we refer to as dual RL, is unconstrained and easier to optimize. We show that several state-of-the-art off-policy deep reinforcement learning (RL) algorithms, under both online and offline, RL and imitation learning (IL) settings, can be viewed as dual RL approaches in a unified framework. This unification provides a common ground to study and identify the components that contribute to the success of these methods and also reveals the common shortcomings across methods with new insights for improvement. Our analysis shows that prior off-policy imitation learning methods are based on an unrealistic coverage assumption and are minimizing a particular f-divergence between the visitation distributions of the l
    
[^100]: 实现对手术场景的整体理解：针对机器人辅助下的前列腺癌根治术视频

    Towards Holistic Surgical Scene Understanding. (arXiv:2212.04582v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.04582](http://arxiv.org/abs/2212.04582)

    本研究提出了一个新实验框架，PSI-AVA数据集，以实现对机器人辅助下的前列腺癌根治术视频的整体理解。同时，我们的实验结果证明了基于TAPIR的手术场景理解框架的有效性。

    

    大多数用于研究手术干预的基准测试都集中在特定挑战上，而忽略了不同任务间内在的互补性。本文提出了一个新的实验框架，以实现对手术场景的整体理解。首先，我们介绍了Phase、Step、Instrument和Atomic Visual Action（PSI-AVA）数据集。PSI-AVA在机器人辅助下的前列腺癌根治术视频中，对长期（阶段和步骤的识别）和短期推理（器械检测和新型原子动作识别）进行注释。其次，我们提出了TAPIR，即Transformers for Action，Phase，Instrument和Steps Recognition，作为手术场景理解的强基准。TAPIR利用我们数据集的多级注释，通过器械检测任务上学习的表示方式，提高了其分类能力。我们在PSI-AVA和其他公开数据库中的实验结果证明，我们提出的整体手术场景理解框架是充分有效的。

    Most benchmarks for studying surgical interventions focus on a specific challenge instead of leveraging the intrinsic complementarity among different tasks. In this work, we present a new experimental framework towards holistic surgical scene understanding. First, we introduce the Phase, Step, Instrument, and Atomic Visual Action recognition (PSI-AVA) Dataset. PSI-AVA includes annotations for both long-term (Phase and Step recognition) and short-term reasoning (Instrument detection and novel Atomic Action recognition) in robot-assisted radical prostatectomy videos. Second, we present Transformers for Action, Phase, Instrument, and steps Recognition (TAPIR) as a strong baseline for surgical scene understanding. TAPIR leverages our dataset's multi-level annotations as it benefits from the learned representation on the instrument detection task to improve its classification capacity. Our experimental results in both PSI-AVA and other publicly available databases demonstrate the adequacy o
    
[^101]: 因果图中前门调整的线性时间算法

    Linear-Time Algorithms for Front-Door Adjustment in Causal Graphs. (arXiv:2211.16468v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.16468](http://arxiv.org/abs/2211.16468)

    在因果图中，提出了解决前门调整的线性时间算法，通过观察到的中介变量，即使存在未观测到的混淆，也可以识别因果效应。

    

    从观测数据中估计因果效应是实证科学中的基本任务。当系统中涉及未观察到的混淆因素时，这变得尤为具有挑战性。本文侧重于前门调整——一种经典技术，它使用观察到的中介变量，即使存在未观测到的混淆，也可以识别因果效应。虽然前门估计的统计特性已经很好地理解了，但它的算法方面长期以来一直未得到探究。最近，Jeong，Tian和Barenboim [NeurIPS 2022]提出了一种第一个多项式时间算法，用于在给定的有向无环图（DAG）中找到满足前门准则的集合，其运行时间为$O（n^3（n+m））$，其中$n$表示变量的数量，$m$表示因果图的边的数量。在我们的工作中，我们提供了第一个具有线性时间复杂度的算法，即$O（n+m）$，用于这项任务，从而达到了渐近最优的时间复杂性。

    Causal effect estimation from observational data is a fundamental task in empirical sciences. It becomes particularly challenging when unobserved confounders are involved in a system. This paper focuses on front-door adjustment -- a classic technique which, using observed mediators allows to identify causal effects even in the presence of unobserved confounding. While the statistical properties of the front-door estimation are quite well understood, its algorithmic aspects remained unexplored for a long time. Recently, Jeong, Tian, and Barenboim [NeurIPS 2022] have presented the first polynomial-time algorithm for finding sets satisfying the front-door criterion in a given directed acyclic graph (DAG), with an $O(n^3(n+m))$ run time, where $n$ denotes the number of variables and $m$ the number of edges of the causal graph. In our work, we give the first linear-time, i.e., $O(n+m)$, algorithm for this task, which thus reaches the asymptotically optimal time complexity. This result impli
    
[^102]: 一个用于分布式多设备定位的机器人网络

    A Robot Web for Distributed Many-Device Localisation. (arXiv:2202.03314v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2202.03314](http://arxiv.org/abs/2202.03314)

    我们提出了一个基于点对点通信的分布式机器人网络，通过高斯信念传播实现全局定位。该方法具有高效的计算和通信效率，并且对高故障率有一定的容忍度。

    

    我们展示了一种分布式机器人或其他设备的网络，可以通过高效的点对点通信协作实现全局定位。我们的机器人网络解决方案基于高斯信念传播，通过描述机器人内部或彼此观测的概率结构的非线性因子图，适用于任何类型的机器人、运动或传感器。我们定义了一种简单高效的通信协议，可以通过发布和读取网页或其他异步通信技术来实现。通过与最多1000个机器人在任意模式下进行的仿真实验，我们展示了我们的解决方案在全局准确性上能达到与集中式非线性因子图求解器一样准确的水平，同时具有高分布式计算和通信效率。通过在GBP中使用鲁棒因子，我们的方法对高故障率有一定的容忍度。

    We show that a distributed network of robots or other devices which make measurements of each other can collaborate to globally localise via efficient ad-hoc peer to peer communication. Our Robot Web solution is based on Gaussian Belief Propagation on the fundamental non-linear factor graph describing the probabilistic structure of all of the observations robots make internally or of each other, and is flexible for any type of robot, motion or sensor. We define a simple and efficient communication protocol which can be implemented by the publishing and reading of web pages or other asynchronous communication technologies. We show in simulations with up to 1000 robots interacting in arbitrary patterns that our solution convergently achieves global accuracy as accurate as a centralised non-linear factor graph solver while operating with high distributed efficiency of computation and communication. Via the use of robust factors in GBP, our method is tolerant to a high percentage of faults
    
[^103]: 关于最小化器和卷积滤波器的理论连接及其在基因组分析中的应用

    On minimizers and convolutional filters: theoretical connections and applications to genome analysis. (arXiv:2111.08452v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.08452](http://arxiv.org/abs/2111.08452)

    该论文通过对哈希函数属性进行数学分析，发现在分类字母表上的序列分析中，使用随机高斯初始化的卷积滤波器和最大池化等价于选择一种最小化器排序，能够有效提取与其他最小化器距离较近但与序列中的k-mer相距较远的重要特征。

    

    最小化器和卷积神经网络(CNN)是两种完全不同的流行技术，均被用于分析生物序列。从表面上看，这些方法似乎完全不同。最小化器使用滚动窗口的最小哈希方法提取每个窗口中的一个重要k-mer特征。CNN则以随机初始化的卷积滤波器和池化操作为基础，通过多个神经层来学习滤波器本身及其用于分类序列的方法。本文主要结果是对哈希函数属性进行了仔细的数学分析，显示对于分类字母表上的序列，使用随机高斯初始化的卷积滤波器和最大池化等价于选择一个最小化器排序，使得选择的k-mer与序列中的k-mer（按汉明距离）相距较远，但与其他最小化器相距较近。在实证实验中，我们发现这种方法能够有效降低计算复杂度并与传统方法具有相当的性能。

    Minimizers and convolutional neural networks (CNNs) are two quite distinct popular techniques that have both been employed to analyze categorical biological sequences. At face value, the methods seem entirely dissimilar. Minimizers use min-wise hashing on a rolling window to extract a single important k-mer feature per window. CNNs start with a wide array of randomly initialized convolutional filters, paired with a pooling operation, and then multiple additional neural layers to learn both the filters themselves and how they can be used to classify the sequence.  Here, our main result is a careful mathematical analysis of hash function properties showing that for sequences over a categorical alphabet, random Gaussian initialization of convolutional filters with max-pooling is equivalent to choosing a minimizer ordering such that selected k-mers are (in Hamming distance) far from the k-mers within the sequence but close to other minimizers. In empirical experiments, we find that this pr
    

