# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [PromptCodec: High-Fidelity Neural Speech Codec using Disentangled Representation Learning based Adaptive Feature-aware Prompt Encoders](https://arxiv.org/abs/2404.02702) | 本文提出了PromptCodec，一种使用离散表示学习的特征感知提示编码器的高保真神经语音编解码器，通过引入额外特征表示、自适应特征加权融合和效率优化来解决高压缩率下的高保真音频重建问题。 |
| [^2] | [New methods for drug synergy prediction](https://arxiv.org/abs/2404.02484) | 最佳方法准确解决了涉及已知药物或细胞系的药物协同作用预测情景，但仍未达到准确预测新药物或细胞系的水平。 |
| [^3] | [HyperCLOVA X Technical Report](https://arxiv.org/abs/2404.01954) | HyperCLOVA X 是针对韩国语言和文化定制的大型语言模型，同时具有竞争能力的英语、数学和编码能力，其推理能力强大且具有跨语言的通用能力。 |
| [^4] | [CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs](https://arxiv.org/abs/2404.01343) | CHOPS提出了一个名为CHOPS的LLM代理，旨在更高效地利用现有数据库或系统来访问用户信息，提供准确合理的响应或执行所需操作，同时避免有害操作。 |
| [^5] | [GOV-REK: Governed Reward Engineering Kernels for Designing Robust Multi-Agent Reinforcement Learning Systems](https://arxiv.org/abs/2404.01131) | GOV-REK提出了一种动态为多智能体强化学习系统中的代理分配奖励分布的方法，并通过治理内核利用状态或联合行动空间的结构，以解决奖励工程努力无法转化的问题。 |
| [^6] | [DRCT: Saving Image Super-resolution away from Information Bottleneck](https://arxiv.org/abs/2404.00722) | 基于Vision Transformer的DRCT方法采用创新的机制解决了图像超分辨率中空间信息衰减的问题，提升了模型性能。 |
| [^7] | [MATEval: A Multi-Agent Discussion Framework for Advancing Open-Ended Text Evaluation](https://arxiv.org/abs/2403.19305) | 提出了MATEval框架，利用多个类GPT-4的LLMs作为评估Agent，模拟人类合作讨论方法，以评估开放性文本，结合自我反思和思维链策略，并加入反馈机制，提升评估深度和广度。 |
| [^8] | [Language Models for Text Classification: Is In-Context Learning Enough?](https://arxiv.org/abs/2403.17661) | 本研究通过对16个文本分类数据集的大规模评估研究，填补了现有研究缺乏对文本生成模型与提示技术与更传统的文本分类方法之间比较的理解。 |
| [^9] | [Detoxifying Large Language Models via Knowledge Editing](https://arxiv.org/abs/2403.14472) | 本文研究了使用知识编辑技术对大型语言模型进行去毒化，在构建了SafeEdit基准的基础上，提出了一种简单而有效的方法 DINM，可以通过少量调整步骤减少模型的毒性，同时对各种去毒方法的内部机制进行了深入分析。 |
| [^10] | [Multi-role Consensus through LLMs Discussions for Vulnerability Detection](https://arxiv.org/abs/2403.14274) | 本论文提出了一种利用LLMs模拟不同角色进行讨论，以达成对代码中漏洞存在和分类的共识的方法，并在初步评估中实现了精确率、召回率和F1分数的明显提升。 |
| [^11] | [AFLoRA: Adaptive Freezing of Low Rank Adaptation in Parameter Efficient Fine-Tuning of Large Models](https://arxiv.org/abs/2403.13269) | AFLoRA是一种自适应冻结低秩调整方法，通过逐步冻结投影矩阵来提高性能，减少计算量，并提供对GLUE基准测试的最先进表现。 |
| [^12] | [Adversarial Nibbler: An Open Red-Teaming Method for Identifying Diverse Harms in Text-to-Image Generation](https://arxiv.org/abs/2403.12075) | 批评了文本到图像生成中模型对非明显攻击的鲁棒性，提出了Adversarial Nibbler Challenge以众包多样化的提示来纠正模型的安全问题 |
| [^13] | [Evaluating Text to Image Synthesis: Survey and Taxonomy of Image Quality Metrics](https://arxiv.org/abs/2403.11821) | 评估文本到图像合成中，提出了针对图像质量的新评估指标，以确保文本和图像内容的对齐，并提出了新的分类法来归纳这些指标 |
| [^14] | [DTOR: Decision Tree Outlier Regressor to explain anomalies](https://arxiv.org/abs/2403.10903) | DTOR是一种决策树异常值回归器，通过估计异常检测模型生成的异常分数来产生基于规则的解释，具有鲁棒性，适用于具有大量特征数据集。 |
| [^15] | [LIGHTCODE: Light Analytical and Neural Codes for Channels with Feedback](https://arxiv.org/abs/2403.10751) | 本文提出了一种LIGHTCODE轻量级神经编码方案，在具备解释性的基础上，在低信噪比区域实现了最先进的可靠性。 |
| [^16] | [A Conceptual Framework For White Box Neural Networks](https://arxiv.org/abs/2403.09863) | 引入语义特征作为通用概念框架，实现了完全可解释的神经网络层，为白盒神经网络的范式转变开辟了新的可能性。 |
| [^17] | [Rectifying Demonstration Shortcut in In-Context Learning](https://arxiv.org/abs/2403.09488) | 本研究旨在纠正大型语言模型在上下文学习中的演示快捷方式，并引入了一种新的明示意识校准方法。 |
| [^18] | [Rethinking ASTE: A Minimalist Tagging Scheme Alongside Contrastive Learning](https://arxiv.org/abs/2403.07342) | 提出一种新颖的标记方案，并采用对比学习方法来重新思考ASTE，该方法在性能上优于最先进技术，同时具有更紧凑的设计和降低的计算开销，尤其在少样本学习情景下展现出优越效果。 |
| [^19] | [Towards Optimizing Human-Centric Objectives in AI-Assisted Decision-Making With Offline Reinforcement Learning](https://arxiv.org/abs/2403.05911) | 该研究提出了使用离线强化学习来优化人类中心目标的方法，通过提供适当类型的决策支持，针对特定人员、在适当时间，来优化决策准确性和人类学习能力这两个目标。 |
| [^20] | [PEEB: Part-based Image Classifiers with an Explainable and Editable Language Bottleneck](https://arxiv.org/abs/2403.05297) | PEEB是一种基于部分的图像分类器，通过将类别名称转换为描述视觉部分的文本描述符，并将检测到的部分的嵌入与文本描述符匹配，从而在零样本设置中表现出色，并且不仅在监督学习中表现出色，而且还首次实现用户编辑类定义形成新分类器无需重新训练。 |
| [^21] | [Do Large Language Model Understand Multi-Intent Spoken Language ?](https://arxiv.org/abs/2403.04481) | 该研究利用大型语言模型进行口语语言多目标理解，提出了改进实体槽和子目标指令的创新技术，并展示了LLMs在多目标SLU模型方面的潜力。 |
| [^22] | [IRCoder: Intermediate Representations Make Language Models Robust Multilingual Code Generators](https://arxiv.org/abs/2403.03894) | 通过利用编译器中间表示来改进代码-LMs的多语言能力和促进跨语言转移。 |
| [^23] | [Not all Layers of LLMs are Necessary during Inference](https://arxiv.org/abs/2403.02181) | 推理过程中，根据输入实例的不同难易程度，本文提出了一种名为AdaInfer的算法，可以自适应地使用浅层和深层，从而节省了计算资源。 |
| [^24] | [Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering](https://arxiv.org/abs/2402.14320) | Triad框架利用了基于多角色LLM代理来解决知识库问答问题，通过代理的不同角色分别处理KBQA子任务，合作完成KBQA任务，并在多个基准数据集上表现出色。 |
| [^25] | [Universal Machine Learning Kohn-Sham Hamiltonian for Materials](https://arxiv.org/abs/2402.09251) | 本研究提出了一种通用的电子哈密顿量模型，通过使用来自Materials Project的第一性原理DFT计算的哈密顿矩阵进行训练，可以预测整个周期表中包括复杂多元素系统在内的电子结构。 |
| [^26] | [Comment-aided Video-Language Alignment via Contrastive Pre-training for Short-form Video Humor Detection](https://arxiv.org/abs/2402.09055) | 本文提出了一种新颖的通过对比预训练的方法，命名为CVLA，用于短视频幽默检测。CVLA不仅适用于各种模态信号，还能通过在一致的语义空间中对齐视频和语言组件产生适合的多模式表示。实验证明，CVLA显著优于现有最先进方法和几个竞争基准方法。 |
| [^27] | [The Last JITAI? The Unreasonable Effectiveness of Large Language Models in Issuing Just-in-Time Adaptive Interventions: Fostering Physical Activity in a Prospective Cardiac Rehabilitation Setting](https://arxiv.org/abs/2402.08658) | 本研究探索了使用大型语言模型（LLMs）实现即时自适应干预（JITAIs）的可行性。通过测试GPT-4模型以促进门诊心脏康复中心的心脏健康体育活动的使用案例，我们提出了450个JITAI决策和信息。 |
| [^28] | [Doing Experiments and Revising Rules with Natural Language and Probabilistic Reasoning](https://arxiv.org/abs/2402.06025) | 本论文建立了一个计算模型来模拟人们通过实验主动推断隐藏规则的过程，并发现显式假设、概率规则和在线更新的组合可以解释人们在类似Zendo任务上的表现。 |
| [^29] | [The last Dance : Robust backdoor attack via diffusion models and bayesian approach](https://arxiv.org/abs/2402.05967) | 本文介绍了一种通过扩散模型和贝叶斯方法进行鲁棒后门攻击的方法，具体应用于音频Transformer模型，并证明了攻击的可行性。 |
| [^30] | [MixedNUTS: Training-Free Accuracy-Robustness Balance via Nonlinearly Mixed Classifiers](https://arxiv.org/abs/2402.02263) | MixedNUTS是一种无需训练的方法，通过非线性混合分类器的转换和概率混合来实现准确性和鲁棒性的平衡。 |
| [^31] | [L-TUNING: Synchronized Label Tuning for Prompt and Prefix in LLMs](https://arxiv.org/abs/2402.01643) | 本文介绍了L-Tuning，一种在自然语言推理（NLI）框架内的高效微调方法，通过对预训练的LLM中的标签标记进行微调，提高了训练准确性和效率，并增强了模型的训练细微差别。 |
| [^32] | [Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing](https://arxiv.org/abs/2402.00658) | 本文提出了一种通过直接偏好优化在收集到的轨迹上学习基于规划的推理的框架，以解决大型语言模型在复杂推理任务中的虚幻和缺陷问题。 |
| [^33] | [On the $O(\frac{\sqrt{d}}{T^{1/4}})$ Convergence Rate of RMSProp and Its Momentum Extension Measured by $\ell_1$ Norm: Better Dependence on the Dimension](https://arxiv.org/abs/2402.00389) | 这项研究探讨了RMSProp及其动量扩展方法的收敛速度，并发现使用$\ell_1$范数测度时，收敛速度为$O(\frac{\sqrt{d}}{T^{1/4}})$，在维度极大的问题中具有改进依赖性。 |
| [^34] | [Maintaining User Trust Through Multistage Uncertainty Aware Inference](https://arxiv.org/abs/2402.00015) | 本文介绍了一种多阶段的人工智能部署方法，其中每个阶段都使用更准确的推理方法，以维护用户的信任。作者提出了一种量化模型不确定性的方法，以促进对推理结果的有信心的决策。该方法已经在印度的数千名棉农中进行了实际部署，并且可以适用于其他低资源环境中的人工智能部署。 |
| [^35] | [Rethinking Channel Dependence for Multivariate Time Series Forecasting: Learning from Leading Indicators](https://arxiv.org/abs/2401.17548) | 本文提出了一种新方法，LIFT，通过利用通道相关性和领先指标，为多元时间序列预测提供准确的预测。LIFT方法可以无缝与任意时间序列预测方法协作，大量实验证明了其有效性。 |
| [^36] | [Data-Effective Learning: A Comprehensive Medical Benchmark](https://arxiv.org/abs/2401.17542) | 这项研究引入了一个综合基准，用于评估医学领域的数据有效学习。该基准包括大量的医疗数据样本、基准方法和新的评估指标，能够准确评估数据有效学习的性能。 |
| [^37] | [Psychometric Predictive Power of Large Language Models](https://arxiv.org/abs/2311.07484) | 指令调整和提示在大型语言模型中无法提供比基础模型更好的认知建模估计。 |
| [^38] | [Flames: Benchmarking Value Alignment of Chinese Large Language Models](https://arxiv.org/abs/2311.06899) | 中国的大型语言模型的价值观契合性需要更加全面的评估，该研究提出了一个名为"火焰"（Flames）的基准测试，涵盖了常见的无害原则和特定中国价值观，以及复杂场景和隐含恶意的提示方法。 |
| [^39] | [Sequence-Level Certainty Reduces Hallucination In Knowledge-Grounded Dialogue Generation](https://arxiv.org/abs/2310.18794) | 序列级确定性是减少基于知识的对话生成中幻觉的关键，这项工作提出了基于概率确定性和语义确定性的序列级确定性，结果表明更高水平的确定性对应更低水平的幻觉，进一步提出了基于确定性的响应排序方法 |
| [^40] | [Evaluating Spatial Understanding of Large Language Models](https://arxiv.org/abs/2310.14540) | 本研究评估了大型语言模型对空间结构的理解能力，发现LLMs在表示和推理空间结构时的表现存在显著差异，具有捕捉空间结构隐含特征的潜力。 |
| [^41] | [Can LLM-Generated Misinformation Be Detected?](https://arxiv.org/abs/2309.13788) | LLM生成的虚假信息可能比人类撰写的虚假信息更难以检测，具有更具欺骗性的风格，可能造成更多危害。 |
| [^42] | [Zeroth-Order Optimization Meets Human Feedback: Provable Learning via Ranking Oracles](https://arxiv.org/abs/2303.03751) | 零阶优化算法ZO-RankSGD解决了一个新兴的优化挑战，即只能通过排名预测来评估黑盒目标函数。该算法利用一种新颖的随机估计器来确定下降方向，并保证收敛到一个稳定点。此外，该算法还可用于增强学习中的策略优化问题，特别是当只有对于回报排名的排名预测时。 |
| [^43] | [Variance Reduction Based Experience Replay for Policy Optimization](https://arxiv.org/abs/2110.08902) | 引入了基于方差减少的经验回放框架，实现了选择性重复利用相关样本来改善策略梯度估计，并构建了高效的离策略算法PG-VRER。 |
| [^44] | [Towards Generative Abstract Reasoning: Completing Raven's Progressive Matrix via Rule Abstraction and Selection.](http://arxiv.org/abs/2401.09966) | 本文提出了一个条件生成模型（RAISE），通过在潜在空间中进行规则抽象和选择，以解决Raven的渐进矩阵问题，该模型能够在现实的场景中展示出抽象推理的能力。 |
| [^45] | [Domain Adaptive Graph Neural Networks for Constraining Cosmological Parameters Across Multiple Data Sets.](http://arxiv.org/abs/2311.01588) | 该论文研究了通过领域适应图神经网络对宇宙学参数进行约束的方法。通过利用GNNs捕捉宇宙学信息和使用最大均值差异进行领域适应，该方法在不同数据集上具有较好的泛化能力。 |
| [^46] | [BioImage.IO Chatbot: A Personalized Assistant for BioImage Analysis Augmented by Community Knowledge Base.](http://arxiv.org/abs/2310.18351) | BioImage.IO Chatbot 是一个根据用户个性化需求提供答案的AI聊天助手，通过汇集和解释多个数据库、工具文档和数据源的信息，以及社区贡献的知识库和优化的检索方法，为生物图像分析工具的使用者提供了个性化、上下文感知的体验，为可访问的科学研究设立了新的标准。 |
| [^47] | [Content-based Controls For Music Large Language Modeling.](http://arxiv.org/abs/2310.17162) | 该论文提出了一种基于内容的控制方法，用于音乐大语言建模。通过对音高、和弦和鼓乐等固有音乐语言的直接控制，实现了高质量的音乐生成，并且使用了参数高效微调的方法，比原始模型的参数数量少于4%。 |
| [^48] | [Challenges of Radio Frequency Fingerprinting: From Data Collection to Deployment.](http://arxiv.org/abs/2310.16406) | 射频指纹识别技术通过利用硬件缺陷在物理层验证无线设备的身份，然而与深度学习技术的整合和实际场景应用带来了许多挑战。本文分析了这些挑战并指出当前阻碍射频指纹识别实际部署的问题，并探讨了未来发展方向。 |
| [^49] | [Retro-fallback: retrosynthetic planning in an uncertain world.](http://arxiv.org/abs/2310.09270) | 本文针对逆合成任务在实验室执行可行性的不确定性问题，通过引入随机过程的表述，提出了一种名为 Retro-fallback 的贪婪算法，该算法能够最大化实验室可执行的合成计划的概率。 |
| [^50] | [Benchmarking Large Language Models As AI Research Agents.](http://arxiv.org/abs/2310.03302) | 本研究提出了MLAgentBench，一个用于对AI研究代理进行基准测试的ML任务套件，代理可以执行各种操作，从而运行实验、分析结果并修改整个机器学习流程的代码。这可以帮助我们构建和评估能够执行长期目标任务的AI研究代理。 |
| [^51] | [Bridging the Domain Gap by Clustering-based Image-Text Graph Matching.](http://arxiv.org/abs/2310.02692) | 通过基于聚类的图像-文本图匹配来弥合领域差距，学习领域不变特征以实现在未见过领域上的良好泛化能力，实验结果显示在公共数据集上达到最先进性能。 |
| [^52] | [On the Stability of Expressive Positional Encodings for Graph Neural Networks.](http://arxiv.org/abs/2310.02579) | 本研究针对图神经网络中使用拉普拉斯特征向量作为位置编码面临的非唯一性和不稳定性问题，提出了稳定且表达丰富的位置编码方法（SPE），该方法通过利用特征值对特征空间进行"软分割"，在未见过的图结构上表现出良好的泛化能力。 |
| [^53] | [Adapting LLM Agents Through Communication.](http://arxiv.org/abs/2310.01444) | 这项研究提出了一种名为学习通信（LTC）的训练方法，使用该方法可使LLM代理通过与环境和其他代理的交互不断改进，以适应新任务，而无需过多人类监督。 |
| [^54] | [BooookScore: A systematic exploration of book-length summarization in the era of LLMs.](http://arxiv.org/abs/2310.00785) | 本文对LLM模型进行了系统探索，以解决对超过上下文窗口大小的书籍进行摘要的问题，并通过两种提示工作流实施了基于LLM的书籍长度摘要器的连贯性研究。通过对100本书的GPT-4生成摘要的人工注释，发现了八种常见的连贯性错误。 |
| [^55] | [SyncDreamer: Generating Multiview-consistent Images from a Single-view Image.](http://arxiv.org/abs/2309.03453) | 本文提出了一种名为SyncDreamer的新型扩散模型，可以从单视图图像生成多视角一致性图像。通过同步所有生成图像的中间状态，并利用3D感知特征注意机制，SyncDreamer能够实现在不同视角上生成高度一致的图像，为各种3D生成任务提供了有力的支持。 |
| [^56] | [Large Language Models as Optimizers.](http://arxiv.org/abs/2309.03409) | 本论文提出了一种简单有效的方法，利用大型语言模型(LLMs)作为优化器，通过自然语言描述优化任务。经过实验证明，该方法在线性回归和旅行推销员问题上表现出色，并且优化的最佳提示超过了人为设计的提示。 |
| [^57] | [High-quality Image Dehazing with Diffusion Model.](http://arxiv.org/abs/2308.11949) | 本研究提出了一种基于DDPM和物理感知的图像去雾框架DehazeDDPM，能够在复杂的雾霾场景中实现高质量的图像去雾。 |
| [^58] | [Large Transformers are Better EEG Learners.](http://arxiv.org/abs/2308.11654) | 本研究表明从图像和文本预训练的大型变压器模型可以直接应用于脑电图预测任务的微调，通过设计AdaCE模块在多个EEG基于预测任务上取得了最新的性能。 |
| [^59] | [DiagGPT: An LLM-based Chatbot with Automatic Topic Management for Task-Oriented Dialogue.](http://arxiv.org/abs/2308.08043) | DiagGPT将大型语言模型(LLMs)扩展到任务导向的对话场景，提供了在复杂诊断场景中主动提问和引导用户完成任务的能力。 |
| [^60] | [Audio is all in one: speech-driven gesture synthetics using WavLM pre-trained model.](http://arxiv.org/abs/2308.05995) | 本文介绍了一种利用WavLM预训练模型的基于语音驱动的手势合成方法，实现只使用原始语音音频生成个性化全身手势，消除了复杂的多模态处理和手动注释的需求。 |
| [^61] | [FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets.](http://arxiv.org/abs/2307.10928) | FLASK是一种基于对齐技能集的细粒度语言模型评估协议，通过将粗级评分分解为每个指令的技能集级评分，实现了对模型性能的全面视角和提高评估的可靠性。 |
| [^62] | [Exploring Non-Regular Extensions of Propositional Dynamic Logic with Description-Logics Features.](http://arxiv.org/abs/2307.09913) | 研究了非正则路径表达式对于扩展ALC描述逻辑中可满足性检查和查询的可决定性的影响，并提供了一系列不可决定性结果。 |
| [^63] | [Towards Understanding In-Context Learning with Contrastive Demonstrations and Saliency Maps.](http://arxiv.org/abs/2307.05052) | 本研究探索了对比演示和显著性图在上下文学习中的作用，并发现改变标签对显著性有显著影响，尤其对于更大的语言模型更为明显。在情感分析任务中，将表达情感的术语改为中性词并不像改变标签那样具有显著影响。另外，补充解释在提高上下文学习方面是有效的。 |
| [^64] | [Recommender Systems in the Era of Large Language Models (LLMs).](http://arxiv.org/abs/2307.02046) | 大型语言模型在推荐系统中的应用已经带来了显著的改进，克服了传统DNN方法的限制，并提供了强大的语言理解、生成、推理和泛化能力。 |
| [^65] | [An Interpretable Constructive Algorithm for Incremental Random Weight Neural Networks and Its Application.](http://arxiv.org/abs/2307.00185) | 本文提出了一种可解释的增量随机权重神经网络的构造算法，通过几何信息约束和节点池策略解决了难以解释隐藏参数与残差误差之间关系的问题。这种算法在大规模数据建模任务中表现出了良好的性能。 |
| [^66] | [Transferring Annotator- and Instance-dependent Transition Matrix for Learning from Crowds.](http://arxiv.org/abs/2306.03116) | 本文提出了一个高效的方法来估算特定注释者和特定实例的转移矩阵以及真实标签比例，解决了从众包中学习的标签噪声问题，并在实验中证明了方法的优越性。 |
| [^67] | [Augmented Modular Reinforcement Learning based on Heterogeneous Knowledge.](http://arxiv.org/abs/2306.01158) | 该论文提出了增强模块化强化学习（AMRL），使用仲裁器来选择异构模块，并无缝地整合不同类型的知识。该方法能够减缓强化学习中的一些低效问题，有望在深度强化学习领域得到应用。 |
| [^68] | [The Curse of Recursion: Training on Generated Data Makes Models Forget.](http://arxiv.org/abs/2305.17493) | 使用生成数据进行训练会导致模型不可逆的缺陷并且使得原始内容分布的尾部消失，这种效应称为模型折叠。我们证明了这种现象在所有学习生成模型中都存在，必须认真对待。 |
| [^69] | [Negative Feedback Training: A Novel Concept to Improve Robustness of NVCiM DNN Accelerators.](http://arxiv.org/abs/2305.14561) | 本文介绍了一种新的训练方法，使用负反馈机制来增强DNN模型的鲁棒性，特别是在存在设备变异的情况下。 |
| [^70] | [Annealing Self-Distillation Rectification Improves Adversarial Training.](http://arxiv.org/abs/2305.12118) | 本研究提出了退火自蒸馏校正(ADR)方法，其能生成软标签用作更好的指导机制，准确反映在对抗训练中攻击下的分布变化，提高模型的鲁棒性，并实现了平滑的插入性整合到其他对抗性训练技术中。 |
| [^71] | [Visual Tuning.](http://arxiv.org/abs/2305.06061) | 本文综述了视觉调整的发展与现状，将近期的视觉调整技术分为五类，包括提示调整、适配器调整、参数翻译、紧凑调整和模块调整，并提出了未来研究方向。 |
| [^72] | [Out-of-distribution Evidence-aware Fake News Detection via Dual Adversarial Debiasing.](http://arxiv.org/abs/2304.12888) | 该论文提出了一种新颖的双重对抗学习方法，通过在模型中加入去偏置鉴别器，旨在训练模型更好地进行越界证据感知假新闻检测，有效减轻新闻和证据内容偏差的影响。 |
| [^73] | [Modeling Dense Multimodal Interactions Between Biological Pathways and Histology for Survival Prediction.](http://arxiv.org/abs/2304.06819) | 本论文提出了一种解决整合全切片图像和批量转录组学预测患者生存率的多模态任务的方案，旨在解决标记化转录组学和捕获这两种模态之间的交互的问题。 |
| [^74] | [CT Multi-Task Learning with a Large Image-Text (LIT) Model.](http://arxiv.org/abs/2304.02649) | 本研究通过将大型图像模型和大语言模型结合起来，建立了一个用于肺癌诊断的多任务CT大型图像文本（LIT）模型，能很好地执行肺部CT分割等多个医学任务。 |
| [^75] | [Curvature-Balanced Feature Manifold Learning for Long-Tailed Classification.](http://arxiv.org/abs/2303.12307) | 本文提出了一种曲率平衡特征流形学习的方法，探究了感知流形的几何特性对分类难度的影响，发现曲率不平衡会导致模型不公平。 |
| [^76] | [Adaptive Negative Evidential Deep Learning for Open-set Semi-supervised Learning.](http://arxiv.org/abs/2303.12091) | 本文提出了ANEDL框架，应用证据深度学习量化不同类型的不确定性，并设计了新颖的适应性负优化策略，有效应对在未标记数据集中包含内部值和异常值的开放式半监督学习。 |
| [^77] | [Towards an AI-enabled Connected Industry: AGV Communication and Sensor Measurement Datasets.](http://arxiv.org/abs/2301.03364) | 本文介绍了两个无线测量活动所提供的数据集，并将其与机器学习结合起来用于指纹识别、视线检测、服务质量预测或链路选择等任务。 |
| [^78] | [CALIME: Causality-Aware Local Interpretable Model-Agnostic Explanations.](http://arxiv.org/abs/2212.05256) | 本文提出CALIME方法，将因果知识融入可解释性人工智能方法中，以解决特征独立性的缺陷，并取得了优于初始方法的黑盒模型模拟保真度和解释稳定性的表现。 |
| [^79] | [ComCLIP: Training-Free Compositional Image and Text Matching.](http://arxiv.org/abs/2211.13854) | 本文提出了一个无需训练的组合图像与文本匹配模型 ComCLIP，通过将输入图像分解为主体、对象和动作子图像，并结合视觉编码器和文本编码器进行逐步匹配，以解决组合图像与文本匹配中的伪匹配问题。 |

# 详细

[^1]: PromptCodec: 使用基于自适应特征感知的离散表示学习的高保真神经语音编解码器

    PromptCodec: High-Fidelity Neural Speech Codec using Disentangled Representation Learning based Adaptive Feature-aware Prompt Encoders

    [https://arxiv.org/abs/2404.02702](https://arxiv.org/abs/2404.02702)

    本文提出了PromptCodec，一种使用离散表示学习的特征感知提示编码器的高保真神经语音编解码器，通过引入额外特征表示、自适应特征加权融合和效率优化来解决高压缩率下的高保真音频重建问题。

    

    神经语音编解码器近来在生成语音建模领域引起广泛关注，例如语音转换、文本转语音合成等。然而，在高压缩率下确保语音编解码器的高保真音频重建仍然是一个未解决且具有挑战性的问题。本文提出了PromptCodec，一种使用基于离散表示学习的特征感知提示编码器的新型端到端神经语音编解码器模型。通过引入来自提示编码器的额外特征表示，PromptCodec可以分配需要处理的语音信息并增强其能力。此外，引入了一种简单而有效的自适应特征加权融合方法，以整合不同编码器的特征。同时，我们提出了一种基于余弦距离的新颖离散表示学习策略，以优化PromptCodec的编码器以确保其效率，进一步改进。

    arXiv:2404.02702v1 Announce Type: cross  Abstract: Neural speech codec has recently gained widespread attention in generative speech modeling domains, like voice conversion, text-to-speech synthesis, etc. However, ensuring high-fidelity audio reconstruction of speech codecs under high compression rates remains an open and challenging issue. In this paper, we propose PromptCodec, a novel end-to-end neural speech codec model using disentangled representation learning based feature-aware prompt encoders. By incorporating additional feature representations from prompt encoders, PromptCodec can distribute the speech information requiring processing and enhance its capabilities. Moreover, a simple yet effective adaptive feature weighted fusion approach is introduced to integrate features of different encoders. Meanwhile, we propose a novel disentangled representation learning strategy based on cosine distance to optimize PromptCodec's encoders to ensure their efficiency, thereby further impr
    
[^2]: 药物协同作用预测的新方法

    New methods for drug synergy prediction

    [https://arxiv.org/abs/2404.02484](https://arxiv.org/abs/2404.02484)

    最佳方法准确解决了涉及已知药物或细胞系的药物协同作用预测情景，但仍未达到准确预测新药物或细胞系的水平。

    

    在这篇小型综述中，我们探讨了依赖于高通量组合筛选的药物组合协同作用的新预测方法。自2021年以来，该领域取得了迅速进展，已发表了超过30种原创机器学习方法，其中绝大多数是基于深度学习技术的。我们旨在通过突显方法中使用的核心技术、数据来源、输入数据类型和协同得分，以及论文所涉及的预测情景和评估协议，将这些论文放在一个统一的视角下。我们的发现是，最佳方法准确地解决了涉及已知药物或细胞系的协同作用预测情景，而涉及新药物或细胞系的情景仍未达到准确预测水平。

    arXiv:2404.02484v1 Announce Type: cross  Abstract: In this mini-review, we explore the new prediction methods for drug combination synergy relying on high-throughput combinatorial screens. The fast progress of the field is witnessed in the more than thirty original machine learning methods published since 2021, a clear majority of them based on deep learning techniques. We aim to put these papers under a unifying lens by highlighting the core technologies, the data sources, the input data types and synergy scores used in the methods, as well as the prediction scenarios and evaluation protocols that the papers deal with. Our finding is that the best methods accurately solve the synergy prediction scenarios involving known drugs or cell lines while the scenarios involving new drugs or cell lines still fall short of an accurate prediction level.
    
[^3]: HyperCLOVA X 技术报告

    HyperCLOVA X Technical Report

    [https://arxiv.org/abs/2404.01954](https://arxiv.org/abs/2404.01954)

    HyperCLOVA X 是针对韩国语言和文化定制的大型语言模型，同时具有竞争能力的英语、数学和编码能力，其推理能力强大且具有跨语言的通用能力。

    

    我们介绍了 HyperCLOVA X，这是一系列针对韩国语言和文化定制的大型语言模型（LLMs），同时具有在英语、数学和编码方面的竞争能力。HyperCLOVA X 在平衡混合的韩语、英语和代码数据上进行训练，然后通过高质量的人工注释数据进行指导微调，同时遵守严格的安全准则，体现了我们对负责任人工智能的承诺。该模型在包括综合推理、知识、常识、真实性、编码、数学、聊天、遵循指令和无害性在内的各种基准测试中进行了评估，涵盖韩语和英语。HyperCLOVA X 在韩语方面表现出很强的推理能力，得益于对语言和文化细微差异的深刻理解。对固有的双语特性的进一步分析及其扩展到多语言的研究突显出该模型的跨语言熟练性和强大的泛化能力，以适应未定向的目标。

    arXiv:2404.01954v1 Announce Type: cross  Abstract: We introduce HyperCLOVA X, a family of large language models (LLMs) tailored to the Korean language and culture, along with competitive capabilities in English, math, and coding. HyperCLOVA X was trained on a balanced mix of Korean, English, and code data, followed by instruction-tuning with high-quality human-annotated datasets while abiding by strict safety guidelines reflecting our commitment to responsible AI. The model is evaluated across various benchmarks, including comprehensive reasoning, knowledge, commonsense, factuality, coding, math, chatting, instruction-following, and harmlessness, in both Korean and English. HyperCLOVA X exhibits strong reasoning capabilities in Korean backed by a deep understanding of the language and cultural nuances. Further analysis of the inherent bilingual nature and its extension to multilingualism highlights the model's cross-lingual proficiency and strong generalization ability to untargeted la
    
[^4]: CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs

    CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs

    [https://arxiv.org/abs/2404.01343](https://arxiv.org/abs/2404.01343)

    CHOPS提出了一个名为CHOPS的LLM代理，旨在更高效地利用现有数据库或系统来访问用户信息，提供准确合理的响应或执行所需操作，同时避免有害操作。

    

    商业和软件平台越来越倾向于使用像GPT-3.5、GPT-4、GLM-3和LLaMa-2这样的大型语言模型（LLMs）作为客户服务的聊天辅助或推理代理。然而，当前基于LLM的客户服务模型在与客户配置文件的集成方面存在局限，并且缺乏有效服务所需的操作能力。为了解决这些问题，我们提出了一个名为CHOPS（CHat with custOmer Profile in existing System）的LLM代理，旨在：（1）高效利用现有数据库或系统以访问用户信息或按照现有指南与这些系统交互；（2）提供准确合理的响应或在系统中执行所需操作，同时避免有害操作；（3）利用

    arXiv:2404.01343v1 Announce Type: cross  Abstract: Businesses and software platforms are increasingly turning to Large Language Models (LLMs) such as GPT-3.5, GPT-4, GLM-3, and LLaMa-2 for chat assistance with file access or as reasoning agents for customer service. However, current LLM-based customer service models have limited integration with customer profiles and lack the operational capabilities necessary for effective service. Moreover, existing API integrations emphasize diversity over the precision and error avoidance essential in real-world customer service scenarios. To address these issues, we propose an LLM agent named CHOPS (CHat with custOmer Profile in existing System), designed to: (1) efficiently utilize existing databases or systems for accessing user information or interacting with these systems following existing guidelines; (2) provide accurate and reasonable responses or carry out required operations in the system while avoiding harmful operations; and (3) leverag
    
[^5]: GOV-REK：用于设计鲁棒多智能体强化学习系统的受管奖励工程核

    GOV-REK: Governed Reward Engineering Kernels for Designing Robust Multi-Agent Reinforcement Learning Systems

    [https://arxiv.org/abs/2404.01131](https://arxiv.org/abs/2404.01131)

    GOV-REK提出了一种动态为多智能体强化学习系统中的代理分配奖励分布的方法，并通过治理内核利用状态或联合行动空间的结构，以解决奖励工程努力无法转化的问题。

    

    对于多智能体强化学习系统（MARLS），问题的制定通常需要投入大量奖励工程工作，针对特定问题。然而，这种努力通常无法转化为其他问题；更糟糕的是，当系统动态发生 drastica 改变时，这种努力就会被浪费。在稀疏奖励场景中，有意义的启发式可以帮助策略收敛任务。我们提出了 GOVerned Reward Engineering Kernels (GOV-REK)，在 MARLS 的学习阶段动态地为代理分配奖励分布。我们还引入了治理内核，利用状态或联合行动空间中的基础结构来分配有意义的代理奖励分布。在代理学习阶段，它使用类似 Hyperband 的算法迭代地探索不同的奖励分布配置，以在问题-不可知 ma 中学习理想的代理奖励模型。

    arXiv:2404.01131v1 Announce Type: cross  Abstract: For multi-agent reinforcement learning systems (MARLS), the problem formulation generally involves investing massive reward engineering effort specific to a given problem. However, this effort often cannot be translated to other problems; worse, it gets wasted when system dynamics change drastically. This problem is further exacerbated in sparse reward scenarios, where a meaningful heuristic can assist in the policy convergence task. We propose GOVerned Reward Engineering Kernels (GOV-REK), which dynamically assign reward distributions to agents in MARLS during its learning stage. We also introduce governance kernels, which exploit the underlying structure in either state or joint action space for assigning meaningful agent reward distributions. During the agent learning stage, it iteratively explores different reward distribution configurations with a Hyperband-like algorithm to learn ideal agent reward models in a problem-agnostic ma
    
[^6]: DRCT：将图像超分辨率保存在信息瓶颈之外

    DRCT: Saving Image Super-resolution away from Information Bottleneck

    [https://arxiv.org/abs/2404.00722](https://arxiv.org/abs/2404.00722)

    基于Vision Transformer的DRCT方法采用创新的机制解决了图像超分辨率中空间信息衰减的问题，提升了模型性能。

    

    近年来，基于Vision Transformer的低层视觉任务应用取得了广泛的成功。与基于CNN的模型不同，Transformer更擅长捕捉长距离依赖关系，可以利用非局部区域的信息重建图像。在超分辨率领域，基于Swin Transformer的方法已经成为主流，因为它们能够捕捉全局空间信息，并且具有旋转窗口注意机制，有助于在不同窗口之间交换信息。许多研究人员通过扩大感知野或设计复杂网络来提高图像质量和网络效率，取得了令人称赞的结果。然而，我们观察到在前向传播过程中，由于深度增加，空间信息往往会减少，从而导致空间信息的丢失，并最终限制了模型的潜力。

    arXiv:2404.00722v1 Announce Type: cross  Abstract: In recent years, Vision Transformer-based applications to low-level vision tasks have achieved widespread success. Unlike CNN-based models, Transformers are more adept at capturing long-range dependencies, enabling the reconstruction of images utilizing information from non-local areas. In the domain of super-resolution, Swin-transformer-based approaches have become mainstream due to their capacity to capture global spatial information and their shifting-window attention mechanism that facilitates the interchange of information between different windows. Many researchers have enhanced image quality and network efficiency by expanding the receptive field or designing complex networks, yielding commendable results. However, we observed that spatial information tends to diminish during the forward propagation process due to increased depth, leading to a loss of spatial information and, consequently, limiting the model's potential. To addr
    
[^7]: MATEval：用于推进开放性文本评估的多Agent讨论框架

    MATEval: A Multi-Agent Discussion Framework for Advancing Open-Ended Text Evaluation

    [https://arxiv.org/abs/2403.19305](https://arxiv.org/abs/2403.19305)

    提出了MATEval框架，利用多个类GPT-4的LLMs作为评估Agent，模拟人类合作讨论方法，以评估开放性文本，结合自我反思和思维链策略，并加入反馈机制，提升评估深度和广度。

    

    最近生成式大型语言模型（LLMs）的进展令人瞩目，然而，这些模型生成的文本质量经常暴露出持续存在的问题。评估这些模型生成的文本质量，特别是在开放性文本中，一直是一个重大挑战。为解决这一问题，最近的研究探讨了使用LLMs作为评估者的可能性。虽然使用单个LLM作为评估Agent表现出潜力，但却存在显著的不确定性和不稳定性。为了解决这些问题，我们提出了 MATEval：一种“多Agent文本评估框架”，其中所有Agent都由像GPT-4的LLMs扮演。MATEval框架模拟人类协作讨论方法，整合多个Agent的互动来评估开放性文本。我们的框架结合了自我反思和“思维链”策略，以及反馈机制，增强了评估的深度和广度。

    arXiv:2403.19305v1 Announce Type: cross  Abstract: Recent advancements in generative Large Language Models(LLMs) have been remarkable, however, the quality of the text generated by these models often reveals persistent issues. Evaluating the quality of text generated by these models, especially in open-ended text, has consistently presented a significant challenge. Addressing this, recent work has explored the possibility of using LLMs as evaluators. While using a single LLM as an evaluation agent shows potential, it is filled with significant uncertainty and instability. To address these issues, we propose the MATEval: A "Multi-Agent Text Evaluation framework" where all agents are played by LLMs like GPT-4. The MATEval framework emulates human collaborative discussion methods, integrating multiple agents' interactions to evaluate open-ended text. Our framework incorporates self-reflection and Chain-of-Thought (CoT) strategies, along with feedback mechanisms, enhancing the depth and br
    
[^8]: 文本分类的语言模型：仅仅上下文学习就足够了吗？

    Language Models for Text Classification: Is In-Context Learning Enough?

    [https://arxiv.org/abs/2403.17661](https://arxiv.org/abs/2403.17661)

    本研究通过对16个文本分类数据集的大规模评估研究，填补了现有研究缺乏对文本生成模型与提示技术与更传统的文本分类方法之间比较的理解。

    

    最近的基础语言模型在零次和少次标记设置中展示了在许多自然语言处理任务中的最先进性能。这些模型相对于基于微调的更标准的方法的优势在于能够理解用自然语言编写的指令（提示），这有助于它们更好地推广到不同的任务和领域，而无需特定的训练数据。这使它们适合解决具有有限标注实例数量的领域的文本分类问题。但是，现有研究在规模上有限，并缺乏对文本生成模型与提示技术相结合与更传统的文本分类方法（如微调掩码语言模型）的比较的理解。在本文中，我们通过对涵盖二元、多类和多标签问题的16个文本分类数据集进行大规模评估研究来填补这一研究空白。

    arXiv:2403.17661v1 Announce Type: cross  Abstract: Recent foundational language models have shown state-of-the-art performance in many NLP tasks in zero- and few-shot settings. An advantage of these models over more standard approaches based on fine-tuning is the ability to understand instructions written in natural language (prompts), which helps them generalise better to different tasks and domains without the need for specific training data. This makes them suitable for addressing text classification problems for domains with limited amounts of annotated instances. However, existing research is limited in scale and lacks understanding of how text generation models combined with prompting techniques compare to more established methods for text classification such as fine-tuning masked language models. In this paper, we address this research gap by performing a large-scale evaluation study for 16 text classification datasets covering binary, multiclass, and multilabel problems. In par
    
[^9]: 通过知识编辑实现对大型语言模型的去毒化

    Detoxifying Large Language Models via Knowledge Editing

    [https://arxiv.org/abs/2403.14472](https://arxiv.org/abs/2403.14472)

    本文研究了使用知识编辑技术对大型语言模型进行去毒化，在构建了SafeEdit基准的基础上，提出了一种简单而有效的方法 DINM，可以通过少量调整步骤减少模型的毒性，同时对各种去毒方法的内部机制进行了深入分析。

    

    本文研究了使用知识编辑技术来对大型语言模型（LLMs）进行去毒化。我们构建了一个名为SafeEdit的基准，涵盖了九种不安全类别，具有各种强大的攻击提示，并配备了全面的度量标准进行系统评估。我们进行了实验，比较了知识编辑方法与之前的基准线，结果表明知识编辑有潜力在对LLMs进行去毒化时，在对一般性能的影响相对有限。然后，我们提出了一个简单但有效的基准线，称为通过术中神经监测去毒化（DINM），通过仅一次实例的少量调整步骤减少LLMs的毒性。我们进一步对各种去毒方法的内部机制进行了深入分析，表明先前的方法如SFT和DPO可能仅抑制有毒参数的激活，而DINM则减轻有毒参数的毒性。

    arXiv:2403.14472v1 Announce Type: cross  Abstract: This paper investigates using knowledge editing techniques to detoxify Large Language Models (LLMs). We construct a benchmark, SafeEdit, which covers nine unsafe categories with various powerful attack prompts and equips comprehensive metrics for systematic evaluation. We conduct experiments to compare knowledge editing approaches with previous baselines, indicating that knowledge editing has the potential to efficiently detoxify LLMs with limited impact on general performance. Then, we propose a simple yet effective baseline, dubbed Detoxifying with Intraoperative Neural Monitoring (DINM), to diminish the toxicity of LLMs within a few tuning steps via only one instance. We further provide an in-depth analysis of the internal mechanism for various detoxify approaches, demonstrating that previous methods like SFT and DPO may merely suppress the activations of toxic parameters, while DINM mitigates the toxicity of the toxic parameters to
    
[^10]: 通过LLMs讨论实现漏洞检测的多角共识

    Multi-role Consensus through LLMs Discussions for Vulnerability Detection

    [https://arxiv.org/abs/2403.14274](https://arxiv.org/abs/2403.14274)

    本论文提出了一种利用LLMs模拟不同角色进行讨论，以达成对代码中漏洞存在和分类的共识的方法，并在初步评估中实现了精确率、召回率和F1分数的明显提升。

    

    最近大型语言模型（LLMs）的发展突显了漏洞检测的潜力，这是软件质量保证的关键组成部分。然而，大多数研究仅限于单一角色的视角，通常是测试人员，缺乏典型软件开发生命周期中不同角色的多元观点，包括开发人员和测试人员。为此，本文介绍了一种利用LLMs扮演不同角色的方法，模拟现实代码审查过程，进行讨论以达成关于代码中漏洞存在和分类的共识。所提出方法的初步评估显示，精确率增加了4.73％，召回率增加了58.9％，F1分数增加了28.1％。

    arXiv:2403.14274v1 Announce Type: cross  Abstract: Recent advancements in large language models (LLMs) have highlighted the potential for vulnerability detection, a crucial component of software quality assurance. Despite this progress, most studies have been limited to the perspective of a single role, usually testers, lacking diverse viewpoints from different roles in a typical software development life-cycle, including both developers and testers. To this end, this paper introduces an approach to employ LLMs to act as different roles to simulate real-life code review process, engaging in discussions towards a consensus on the existence and classification of vulnerabilities in the code. Preliminary evaluation of the proposed approach indicates a 4.73% increase in the precision rate, 58.9% increase in the recall rate, and a 28.1% increase in the F1 score.
    
[^11]: AFLoRA: 自适应冻结低秩调整在大型模型参数高效微调中的应用

    AFLoRA: Adaptive Freezing of Low Rank Adaptation in Parameter Efficient Fine-Tuning of Large Models

    [https://arxiv.org/abs/2403.13269](https://arxiv.org/abs/2403.13269)

    AFLoRA是一种自适应冻结低秩调整方法，通过逐步冻结投影矩阵来提高性能，减少计算量，并提供对GLUE基准测试的最先进表现。

    

    我们提出了一种新颖的参数高效微调（PEFT）方法，称为自适应冻结低秩调整（AFLoRA）。具体地，对于每个预训练的冻结权重张量，我们添加一个可训练的低秩矩阵并行路径，即下投影和上投影矩阵，每个矩阵后面跟着一个特征变换向量。基于一种新颖的冻结分数，我们在微调过程中逐步冻结这些投影矩阵，以减少计算量并减轻过拟合。我们的实验结果表明，我们可以在GLUE基准测试中获得最先进的性能，平均改善高达0.85％，同时可减少高达9.5倍的平均可训练参数。在运行时间方面，与类似的PEFT备选方案相比，AFLoRA可以提供高达1.86倍的改进。除了我们方法的实际效用之外，我们还提供了关于训练

    arXiv:2403.13269v1 Announce Type: new  Abstract: We present a novel Parameter-Efficient Fine-Tuning (PEFT) method, dubbed as Adaptive Freezing of Low Rank Adaptation (AFLoRA). Specifically, for each pre-trained frozen weight tensor, we add a parallel path of trainable low-rank matrices, namely a down-projection and an up-projection matrix, each of which is followed by a feature transformation vector. Based on a novel freezing score, we the incrementally freeze these projection matrices during fine-tuning to reduce the computation and alleviate over-fitting. Our experimental results demonstrate that we can achieve state-of-the-art performance with an average improvement of up to $0.85\%$ as evaluated on GLUE benchmark while yeilding up to $9.5\times$ fewer average trainable parameters. While compared in terms of runtime, AFLoRA can yield up to $1.86\times$ improvement as opposed to similar PEFT alternatives. Besides the practical utility of our approach, we provide insights on the train
    
[^12]: Adversarial Nibbler: 一种用于识别文本到图像生成中多样化危害的开放式红队方法

    Adversarial Nibbler: An Open Red-Teaming Method for Identifying Diverse Harms in Text-to-Image Generation

    [https://arxiv.org/abs/2403.12075](https://arxiv.org/abs/2403.12075)

    批评了文本到图像生成中模型对非明显攻击的鲁棒性，提出了Adversarial Nibbler Challenge以众包多样化的提示来纠正模型的安全问题

    

    随着文本到图像（T2I）生成AI模型的崛起，评估模型对于不明显攻击的稳健性以减少生成冒犯性图像变得至关重要。通过专注于"隐性对抗"提示（触发T2I模型生成不安全图像的非明显原因），我们独立辨别出一组难以发现的安全问题，人类创造力很适合揭示这些问题。为此，我们构建了Adversarial Nibbler Challenge，这是一个红队方法，用于众包一组多样化的隐性对抗性提示。我们已汇总一套最先进的T2I模型，采用简单用户界面来识别和注释危害，并吸引广泛人群来捕捉在标准测试中可能被忽视的长尾安全问题。挑战在连续回合中进行，以实现对T2I模型中安全隐患的持续发现和分析。

    arXiv:2403.12075v1 Announce Type: cross  Abstract: With the rise of text-to-image (T2I) generative AI models reaching wide audiences, it is critical to evaluate model robustness against non-obvious attacks to mitigate the generation of offensive images. By focusing on ``implicitly adversarial'' prompts (those that trigger T2I models to generate unsafe images for non-obvious reasons), we isolate a set of difficult safety issues that human creativity is well-suited to uncover. To this end, we built the Adversarial Nibbler Challenge, a red-teaming methodology for crowdsourcing a diverse set of implicitly adversarial prompts. We have assembled a suite of state-of-the-art T2I models, employed a simple user interface to identify and annotate harms, and engaged diverse populations to capture long-tail safety issues that may be overlooked in standard testing. The challenge is run in consecutive rounds to enable a sustained discovery and analysis of safety pitfalls in T2I models.   In this pape
    
[^13]: 评估文本到图像合成：图像质量度量的调查与分类

    Evaluating Text to Image Synthesis: Survey and Taxonomy of Image Quality Metrics

    [https://arxiv.org/abs/2403.11821](https://arxiv.org/abs/2403.11821)

    评估文本到图像合成中，提出了针对图像质量的新评估指标，以确保文本和图像内容的对齐，并提出了新的分类法来归纳这些指标

    

    最近，通过利用语言和视觉结合的基础模型，推动了文本到图像合成方面的进展。这些模型在互联网或其他大规模数据库中的海量文本-图像对上进行了预训练。随着对高质量图像生成的需求转向确保文本与图像之间的内容对齐，已开发了新颖的评估度量标准，旨在模拟人类判断。因此，研究人员开始收集具有越来越复杂注释的数据集，以研究视觉语言模型的组成性及其作为文本与图像内容组成对齐质量度量的其纳入。在这项工作中，我们全面介绍了现有的文本到图像评估指标，并提出了一个新的分类法来对这些指标进行分类。我们还审查了经常采用的文本-图像基准数据集

    arXiv:2403.11821v1 Announce Type: cross  Abstract: Recent advances in text-to-image synthesis have been enabled by exploiting a combination of language and vision through foundation models. These models are pre-trained on tremendous amounts of text-image pairs sourced from the World Wide Web or other large-scale databases. As the demand for high-quality image generation shifts towards ensuring content alignment between text and image, novel evaluation metrics have been developed with the aim of mimicking human judgments. Thus, researchers have started to collect datasets with increasingly complex annotations to study the compositionality of vision-language models and their incorporation as a quality measure of compositional alignment between text and image contents. In this work, we provide a comprehensive overview of existing text-to-image evaluation metrics and propose a new taxonomy for categorizing these metrics. We also review frequently adopted text-image benchmark datasets befor
    
[^14]: DTOR：决策树异常值回归器用于解释异常

    DTOR: Decision Tree Outlier Regressor to explain anomalies

    [https://arxiv.org/abs/2403.10903](https://arxiv.org/abs/2403.10903)

    DTOR是一种决策树异常值回归器，通过估计异常检测模型生成的异常分数来产生基于规则的解释，具有鲁棒性，适用于具有大量特征数据集。

    

    解释异常值的出现以及其产生机制在各种领域中可能非常重要。故障、欺诈、威胁等问题，除了被正确识别之外，通常需要有效的解释以有效执行可操作的对抗措施。越来越广泛地使用复杂的机器学习方法来识别异常值，使得这样的解释更具挑战性。我们提出了决策树异常值回归器（DTOR），这是一种通过估计异常检测模型生成的异常分数来为单个数据点生成基于规则的解释的技术。这是通过首先应用决策树回归器来计算估计分数，然后提取与数据点分数相关联的相对路径来实现的。我们的结果表明，即使在具有大量特征的数据集中，DTOR的鲁棒性也得到了证实。此外，与其他基于规则的方法相比

    arXiv:2403.10903v1 Announce Type: cross  Abstract: Explaining outliers occurrence and mechanism of their occurrence can be extremely important in a variety of domains. Malfunctions, frauds, threats, in addition to being correctly identified, oftentimes need a valid explanation in order to effectively perform actionable counteracts. The ever more widespread use of sophisticated Machine Learning approach to identify anomalies make such explanations more challenging. We present the Decision Tree Outlier Regressor (DTOR), a technique for producing rule-based explanations for individual data points by estimating anomaly scores generated by an anomaly detection model. This is accomplished by first applying a Decision Tree Regressor, which computes the estimation score, and then extracting the relative path associated with the data point score. Our results demonstrate the robustness of DTOR even in datasets with a large number of features. Additionally, in contrast to other rule-based approac
    
[^15]: LIGHTCODE：具有反馈通道的光解析和神经编码

    LIGHTCODE: Light Analytical and Neural Codes for Channels with Feedback

    [https://arxiv.org/abs/2403.10751](https://arxiv.org/abs/2403.10751)

    本文提出了一种LIGHTCODE轻量级神经编码方案，在具备解释性的基础上，在低信噪比区域实现了最先进的可靠性。

    

    通道反馈中可靠且高效的编码方案设计一直是通信理论中一项长期挑战。虽然深度学习技术取得了显著进展，神经编码往往面临计算成本高、缺乏可解释性以及在资源受限环境中的实用性有限等问题。本文旨在设计解释性强且更适用于通信系统的低复杂度编码方案。我们先进了解析编码和神经编码。首先，我们展示了POWERBLAST，一种受Schalkwijk-Kailath（SK）和Gallager-Nakiboglu（GN）方案启发的解析编码方案，在高信噪比（SNR）区域实现了明显的可靠性改进，胜过神经编码。接下来，为了增强低SNR区域的可靠性，我们提出了LIGHTCODE，一种轻量级神经编码，实现了最先进的可靠性。

    arXiv:2403.10751v1 Announce Type: cross  Abstract: The design of reliable and efficient codes for channels with feedback remains a longstanding challenge in communication theory. While significant improvements have been achieved by leveraging deep learning techniques, neural codes often suffer from high computational costs, a lack of interpretability, and limited practicality in resource-constrained settings. We focus on designing low-complexity coding schemes that are interpretable and more suitable for communication systems. We advance both analytical and neural codes. First, we demonstrate that POWERBLAST, an analytical coding scheme inspired by Schalkwijk-Kailath (SK) and Gallager-Nakiboglu (GN) schemes, achieves notable reliability improvements over both SK and GN schemes, outperforming neural codes in high signal-to-noise ratio (SNR) regions. Next, to enhance reliability in low-SNR regions, we propose LIGHTCODE, a lightweight neural code that achieves state-of-the-art reliability
    
[^16]: 一个白盒神经网络的概念框架

    A Conceptual Framework For White Box Neural Networks

    [https://arxiv.org/abs/2403.09863](https://arxiv.org/abs/2403.09863)

    引入语义特征作为通用概念框架，实现了完全可解释的神经网络层，为白盒神经网络的范式转变开辟了新的可能性。

    

    本文引入语义特征作为完全可解释神经网络层的通用概念框架。一个充分动机的MNIST相关子问题的概念验证模型包括4个这样的层，总共4800个可学习参数。该模型易于解释，无需任何形式的对抗训练即可实现人类水平的对抗测试准确率，需要较少的超参数调节，并且可以在单个CPU上快速训练。该技术的通用性承诺为彻底民主化和真正通用的白盒神经网络带来了希望。代码可在https://github.com/314-Foundation/white-box-nn找到。

    arXiv:2403.09863v1 Announce Type: cross  Abstract: This paper introduces semantic features as a general conceptual framework for fully explainable neural network layers. A well-motivated proof of concept model for relevant subproblem of MNIST consists of 4 such layers with the total of 4.8K learnable parameters. The model is easily interpretable, achieves human-level adversarial test accuracy with no form of adversarial training, requires little hyperparameter tuning and can be quickly trained on a single CPU. The general nature of the technique bears promise for a paradigm shift towards radically democratised and truly generalizable white box neural networks. The code is available at https://github.com/314-Foundation/white-box-nn
    
[^17]: 在上下文学习中纠正演示快捷方式

    Rectifying Demonstration Shortcut in In-Context Learning

    [https://arxiv.org/abs/2403.09488](https://arxiv.org/abs/2403.09488)

    本研究旨在纠正大型语言模型在上下文学习中的演示快捷方式，并引入了一种新的明示意识校准方法。

    

    大型语言模型（LLMs）能够利用它们的上下文学习（ICL）能力，仅凭少量演示便能解决各种任务。然而，LLMs常常依赖于它们对演示的预先训练的语义先验，而不是根据输入-标签关系继续进行ICL预测。本文将这一现象称为“演示快捷方式”。尽管先前的研究主要集中于改进预定义任务的ICL预测结果，我们的目标是纠正演示快捷方式，从而使LLM能够有效地从演示中学习新的输入-标签关系。为实现此目标，我们引入了一种明示意识的校准方法：In-Context Calibration。我们在两个设置中评估了所提出方法的有效性：（1）使用标准标签空间的原始ICL任务以及（2）任务学习设置，其中标签空间被语义无关的标记替换。

    arXiv:2403.09488v1 Announce Type: cross  Abstract: Large language models (LLMs) are able to solve various tasks with only a few demonstrations utilizing their in-context learning (ICL) abilities. However, LLMs often rely on their pre-trained semantic priors of demonstrations rather than on the input-label relationships to proceed with ICL prediction. In this work, we term this phenomenon as the `Demonstration Shortcut'. While previous works have primarily focused on improving ICL prediction results for predefined tasks, we aim to rectify the Demonstration Shortcut, thereby enabling the LLM to effectively learn new input-label relationships from demonstrations. To achieve this, we introduce In-Context Calibration, a demonstration-aware calibration method. We evaluate the effectiveness of the proposed method in two settings: (1) the Original ICL Task using the standard label space and (2) the Task Learning setting, where the label space is replaced with semantically unrelated tokens. In 
    
[^18]: 重新思考ASTE:一种极简的标记方案与对比学习

    Rethinking ASTE: A Minimalist Tagging Scheme Alongside Contrastive Learning

    [https://arxiv.org/abs/2403.07342](https://arxiv.org/abs/2403.07342)

    提出一种新颖的标记方案，并采用对比学习方法来重新思考ASTE，该方法在性能上优于最先进技术，同时具有更紧凑的设计和降低的计算开销，尤其在少样本学习情景下展现出优越效果。

    

    Aspect Sentiment Triplet Extraction (ASTE) 是细粒度情感分析的一个新兴子任务，旨在从非结构化文本数据中提取结构化的情感三元组。现有的ASTE方法通常通过额外的结构或外部数据来复杂化任务。在这项研究中，我们提出了一种新颖的标记方案，并采用对比学习方法来缓解这些挑战。所提出的方法在与最先进技术的比较中展示出可比甚至更优越的性能，同时具有更紧凑的设计和降低的计算开销。值得注意的是，在大语言模型(LLMs)时代，我们的方法在少样本学习情景下展现出优于GPT 3.5和GPT 4的效果。本研究还为在大语言模型范式下推进ASTE技术提供了宝贵的见解。

    arXiv:2403.07342v1 Announce Type: cross  Abstract: Aspect Sentiment Triplet Extraction (ASTE) is a burgeoning subtask of fine-grained sentiment analysis, aiming to extract structured sentiment triplets from unstructured textual data. Existing approaches to ASTE often complicate the task with additional structures or external data. In this research, we propose a novel tagging scheme and employ a contrastive learning approach to mitigate these challenges. The proposed approach demonstrates comparable or superior performance in comparison to state-of-the-art techniques, while featuring a more compact design and reduced computational overhead. Notably, even in the era of Large Language Models (LLMs), our method exhibits superior efficacy compared to GPT 3.5 and GPT 4 in a few-shot learning scenarios. This study also provides valuable insights for the advancement of ASTE techniques within the paradigm of large language models.
    
[^19]: 优化人类中心目标：AI辅助决策中的离线强化学习研究

    Towards Optimizing Human-Centric Objectives in AI-Assisted Decision-Making With Offline Reinforcement Learning

    [https://arxiv.org/abs/2403.05911](https://arxiv.org/abs/2403.05911)

    该研究提出了使用离线强化学习来优化人类中心目标的方法，通过提供适当类型的决策支持，针对特定人员、在适当时间，来优化决策准确性和人类学习能力这两个目标。

    

    随着人工智能辅助渗透到决策过程中，我们可能希望优化人类中心目标，超越决策准确性，如那些与这些系统互动的个体的技能提升或任务享受。考虑到这一愿景，我们提出了离线强化学习（RL）作为建模人机决策以优化这些人类中心目标的一般方法。我们的方法通过灵活地为人类提供决策支持来优化不同的目标--在正确的时间、向正确的人提供正确类型的帮助。我们用两个目标实例化我们的方法：人工智能在决策任务中的准确性和人类对该任务的学习，并从先前的人机交互数据中学习优化这两个目标的策略。我们将优化的策略与在AI辅助决策中的各种基线进行比较。在两个实验中（N = 316 和 N

    arXiv:2403.05911v1 Announce Type: cross  Abstract: As AI assistance is increasingly infused into decision-making processes, we may seek to optimize human-centric objectives beyond decision accuracy, such as skill improvement or task enjoyment of individuals interacting with these systems. With this aspiration in mind, we propose offline reinforcement learning (RL) as a general approach for modeling human-AI decision-making to optimize such human-centric objectives. Our approach seeks to optimize different objectives by adaptively providing decision support to humans -- the right type of assistance, to the right person, at the right time. We instantiate our approach with two objectives: human-AI accuracy on the decision-making task and human learning about the task, and learn policies that optimize these two objectives from previous human-AI interaction data. We compare the optimized policies against various baselines in AI-assisted decision-making. Across two experiments (N = 316 and N
    
[^20]: PEEB：具有可解释和可编辑语言瓶颈的基于部分的图像分类器

    PEEB: Part-based Image Classifiers with an Explainable and Editable Language Bottleneck

    [https://arxiv.org/abs/2403.05297](https://arxiv.org/abs/2403.05297)

    PEEB是一种基于部分的图像分类器，通过将类别名称转换为描述视觉部分的文本描述符，并将检测到的部分的嵌入与文本描述符匹配，从而在零样本设置中表现出色，并且不仅在监督学习中表现出色，而且还首次实现用户编辑类定义形成新分类器无需重新训练。

    

    基于CLIP的分类器依赖于包含{text encoder已知的类名称}的提示。也就是说，CLIP在新类别或其名称很少在互联网上出现的类别（例如鸟类的学名）上表现不佳。针对细粒度分类，我们提出了PEEB - 一种可解释和可编辑的分类器，用于（1）将类别名称表达为一组预定义的描述视觉部分的文本描述符；和（2）将检测到的部分的嵌入与每个类别中的文本描述符进行匹配，以计算用于分类的逻辑分数。在一个零样本设置中，其中类别名称是未知的，PEEB在准确性上大幅优于CLIP（约为10倍）。与基于部分的分类器相比，PEEB不仅在监督学习设置上是最先进的（88.80%准确率），而且还是第一个能够让用户编辑类定义以形成新的分类器而无需重新训练的分类器。

    arXiv:2403.05297v1 Announce Type: cross  Abstract: CLIP-based classifiers rely on the prompt containing a {class name} that is known to the text encoder. That is, CLIP performs poorly on new classes or the classes whose names rarely appear on the Internet (e.g., scientific names of birds). For fine-grained classification, we propose PEEB - an explainable and editable classifier to (1) express the class name into a set of pre-defined text descriptors that describe the visual parts of that class; and (2) match the embeddings of the detected parts to their textual descriptors in each class to compute a logit score for classification. In a zero-shot setting where the class names are unknown, PEEB outperforms CLIP by a large margin (~10x in accuracy). Compared to part-based classifiers, PEEB is not only the state-of-the-art on the supervised-learning setting (88.80% accuracy) but also the first to enable users to edit the class definitions to form a new classifier without retraining. Compar
    
[^21]: 大型语言模型能理解多目标口语语言吗？

    Do Large Language Model Understand Multi-Intent Spoken Language ?

    [https://arxiv.org/abs/2403.04481](https://arxiv.org/abs/2403.04481)

    该研究利用大型语言模型进行口语语言多目标理解，提出了改进实体槽和子目标指令的创新技术，并展示了LLMs在多目标SLU模型方面的潜力。

    

    这项研究通过利用大型语言模型（LLMs）进行多目标口语语言理解（SLU）取得了重大进展，提出了一种在SLU环境中利用LLMs生成能力的独特方法。我们的创新技术重新配置了实体槽，专门用于LLMs在多目标SLU环境中的应用，并引入了子目标指令（SII）的概念，增强了对不同领域内复杂多目标交流的解剖和解释。由此产生的数据集，被称为LM-MixATIS和LM-MixSNIPS，是从现有基准中精心制作的。我们的研究表明，LLMs可以匹配并潜在地超越当前最先进的多目标SLU模型的能力。它进一步探讨了LLMs在各种意图配置和数据集比例下的有效性。此外，我们介绍了两个开创性的度量标准，即实体槽准确性（ESA）和Com

    arXiv:2403.04481v1 Announce Type: cross  Abstract: This study marks a significant advancement by harnessing Large Language Models (LLMs) for multi-intent spoken language understanding (SLU), proposing a unique methodology that capitalizes on the generative power of LLMs within an SLU context. Our innovative technique reconfigures entity slots specifically for LLM application in multi-intent SLU environments and introduces the concept of Sub-Intent Instruction (SII), enhancing the dissection and interpretation of intricate, multi-intent communication within varied domains. The resultant datasets, dubbed LM-MixATIS and LM-MixSNIPS, are crafted from pre-existing benchmarks. Our research illustrates that LLMs can match and potentially excel beyond the capabilities of current state-of-the-art multi-intent SLU models. It further explores LLM efficacy across various intent configurations and dataset proportions. Moreover, we introduce two pioneering metrics, Entity Slot Accuracy (ESA) and Com
    
[^22]: IRCoder: 中间表示使语言模型成为稳健的多语言代码生成器

    IRCoder: Intermediate Representations Make Language Models Robust Multilingual Code Generators

    [https://arxiv.org/abs/2403.03894](https://arxiv.org/abs/2403.03894)

    通过利用编译器中间表示来改进代码-LMs的多语言能力和促进跨语言转移。

    

    arXiv:2403.03894v1 公告类型: 新的 摘要: 代码理解和生成已迅速成为语言模型（LMs）最受欢迎的应用之一。然而，与自然语言LM的研究相比，对代码-LMs（即用于代码生成的LMs）的多语言方面的研究，如不同编程语言之间的跨语言转移，特定于语言的数据增强以及事后LM调整，以及利用原始文本内容之外的数据源，要稀少得多。特别是，大多数主流代码-LMs仅在源代码文件上进行了预训练。在这项工作中，我们研究了利用现成的编译器中间表示（跨编程语言共享）来改进代码-LMs的多语言能力并促进跨语言转移的前景。为此，我们首先编制了SLTrans，一个由近400万个自包含源代码文件组成的并行数据集。

    arXiv:2403.03894v1 Announce Type: new  Abstract: Code understanding and generation have fast become some of the most popular applications of language models (LMs). Nonetheless, research on multilingual aspects of Code-LMs (i.e., LMs for code generation) such as cross-lingual transfer between different programming languages, language-specific data augmentation, and post-hoc LM adaptation, alongside exploitation of data sources other than the original textual content, has been much sparser than for their natural language counterparts. In particular, most mainstream Code-LMs have been pre-trained on source code files alone. In this work, we investigate the prospect of leveraging readily available compiler intermediate representations - shared across programming languages - to improve the multilingual capabilities of Code-LMs and facilitate cross-lingual transfer.   To this end, we first compile SLTrans, a parallel dataset consisting of nearly 4M self-contained source code files coupled wi
    
[^23]: 推理过程中不是所有LLMs的层都是必要的

    Not all Layers of LLMs are Necessary during Inference

    [https://arxiv.org/abs/2403.02181](https://arxiv.org/abs/2403.02181)

    推理过程中，根据输入实例的不同难易程度，本文提出了一种名为AdaInfer的算法，可以自适应地使用浅层和深层，从而节省了计算资源。

    

    大型语言模型（LLMs）的推理阶段非常昂贵。理想的LLMs推理阶段可以利用更少的计算资源，同时仍保持其能力（例如泛化和上下文学习能力）。本文尝试回答一个问题：“在LLMs推理过程中，我们可以为简单实例使用浅层，并为难以处理的实例使用深层吗？”为了回答这个问题，我们首先通过统计分析跨任务激活的层来指出并非所有层在推理过程中都是必要的。然后，我们提出了一种简单的算法，名为AdaInfer，根据输入实例自适应地确定推理终止时刻。更重要的是，AdaInfer不改变LLMs参数，并在任务之间保持泛化能力。对知名LLMs（即Llama2系列和OPT）的实验证明，AdaInfer节省了平均14.8%的计算资源，甚至在情感方面高达50%。

    arXiv:2403.02181v1 Announce Type: cross  Abstract: The inference phase of Large Language Models (LLMs) is very expensive. An ideal inference stage of LLMs could utilize fewer computational resources while still maintaining its capabilities (e.g., generalization and in-context learning ability). In this paper, we try to answer the question, "During LLM inference, can we use shallow layers for easy instances; and deep layers for hard ones?" To answer this question, we first indicate that Not all Layers are Necessary during Inference by statistically analyzing the activated layers across tasks. Then, we propose a simple algorithm named AdaInfer to determine the inference termination moment based on the input instance adaptively. More importantly, AdaInfer does not alter LLM parameters and maintains generalizability across tasks. Experiments on well-known LLMs (i.e., Llama2 series and OPT) show that AdaInfer saves an average of 14.8% of computational resources, even up to 50% on sentiment 
    
[^24]: Triad: 一个利用基于多角色LLM代理的框架来解决知识库问答问题

    Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering

    [https://arxiv.org/abs/2402.14320](https://arxiv.org/abs/2402.14320)

    Triad框架利用了基于多角色LLM代理来解决知识库问答问题，通过代理的不同角色分别处理KBQA子任务，合作完成KBQA任务，并在多个基准数据集上表现出色。

    

    最近基于LLM代理的进展在各种任务中展现出了令人期待的结果。然而，它们在回答知识库中问题的运用仍然鲜为人知。使用传统方法来实现KBQA系统具有挑战性，因为缺乏特定任务训练数据以及创建以任务为中心的模型结构的复杂性。在本文中，我们提出了Triad，一个利用具有三个角色的LLM代理的统一框架来进行KBQA任务。代理被分配三个角色来处理不同的KBQA子任务：作为掌握各种子任务的通才，作为选择候选者的决策者，以及作为回答带有知识的问题的顾问。我们的KBQA框架在四个阶段中执行，涉及代理的多重角色的协作。我们使用三个基准数据集评估了我们框架的性能，结果显示我们的框架胜过了

    arXiv:2402.14320v1 Announce Type: cross  Abstract: Recent progress with LLM-based agents has shown promising results across various tasks. However, their use in answering questions from knowledge bases remains largely unexplored. Implementing a KBQA system using traditional methods is challenging due to the shortage of task-specific training data and the complexity of creating task-focused model structures. In this paper, we present Triad, a unified framework that utilizes an LLM-based agent with three roles for KBQA tasks. The agent is assigned three roles to tackle different KBQA subtasks: agent as a generalist for mastering various subtasks, as a decision maker for the selection of candidates, and as an advisor for answering questions with knowledge. Our KBQA framework is executed in four phases, involving the collaboration of the agent's multiple roles. We evaluated the performance of our framework using three benchmark datasets, and the results show that our framework outperforms 
    
[^25]: 材料的通用机器学习Kohn-Sham哈密顿量

    Universal Machine Learning Kohn-Sham Hamiltonian for Materials

    [https://arxiv.org/abs/2402.09251](https://arxiv.org/abs/2402.09251)

    本研究提出了一种通用的电子哈密顿量模型，通过使用来自Materials Project的第一性原理DFT计算的哈密顿矩阵进行训练，可以预测整个周期表中包括复杂多元素系统在内的电子结构。

    

    尽管密度泛函理论(DFT)在电子结构计算中是一种普遍的计算方法，但其计算需求和可扩展性限制仍然存在。最近，利用神经网络来参数化Kohn-Sham DFT哈密顿量已经成为加速电子结构计算的有希望的途径。尽管取得了进展，但仍然存在一些挑战，如为了探索新系统而需要计算大量的DFT训练数据和建立准确的多元素材料的ML模型的复杂性。针对这些障碍，本研究介绍了一种通过对来自Materials Project的第一性原理DFT计算的哈密顿矩阵进行训练的通用电子哈密顿量模型。我们证明了它在整个周期表中预测电子结构的普适性，包括复杂的多元素系统。

    arXiv:2402.09251v1 Announce Type: cross Abstract: While density functional theory (DFT) serves as a prevalent computational approach in electronic structure calculations, its computational demands and scalability limitations persist. Recently, leveraging neural networks to parameterize the Kohn-Sham DFT Hamiltonian has emerged as a promising avenue for accelerating electronic structure computations. Despite advancements, challenges such as the necessity for computing extensive DFT training data to explore new systems and the complexity of establishing accurate ML models for multi-elemental materials still exist. Addressing these hurdles, this study introduces a universal electronic Hamiltonian model trained on Hamiltonian matrices obtained from first-principles DFT calculations of nearly all crystal structures on the Materials Project. We demonstrate its generality in predicting electronic structures across the whole periodic table, including complex multi-elemental systems. By offerin
    
[^26]: 通过对比预训练的方法利用评论辅助视频语言对齐用于短视频幽默检测

    Comment-aided Video-Language Alignment via Contrastive Pre-training for Short-form Video Humor Detection

    [https://arxiv.org/abs/2402.09055](https://arxiv.org/abs/2402.09055)

    本文提出了一种新颖的通过对比预训练的方法，命名为CVLA，用于短视频幽默检测。CVLA不仅适用于各种模态信号，还能通过在一致的语义空间中对齐视频和语言组件产生适合的多模式表示。实验证明，CVLA显著优于现有最先进方法和几个竞争基准方法。

    

    随着短视频在社交媒体平台上的影响力日益扩大，多模式幽默检测在情感计算中的重要性也日益增加。本文提出了一种新颖的用于短视频幽默检测的两层分层模型，命名为通过数据增强的多模式对比预训练的评论辅助视频语言对齐（CVLA）。值得注意的是，我们的CVLA不仅适用于各种模态信号，并且通过在一致的语义空间中对齐视频和语言组件，产生一个适合的多模式表示。在两个幽默检测数据集DY11k和UR-FUNNY上的实验结果表明，CVLA显著优于现有最先进方法和几个竞争基准方法。我们的数据集、代码和模型发布在https://github.com/yliu-cs/CVLA上。

    arXiv:2402.09055v1 Announce Type: cross Abstract: The growing importance of multi-modal humor detection within affective computing correlates with the expanding influence of short-form video sharing on social media platforms. In this paper, we propose a novel two-branch hierarchical model for short-form video humor detection (SVHD), named Comment-aided Video-Language Alignment (CVLA) via data-augmented multi-modal contrastive pre-training. Notably, our CVLA not only operates on raw signals across various modal channels but also yields an appropriate multi-modal representation by aligning the video and language components within a consistent semantic space. The experimental results on two humor detection datasets, including DY11k and UR-FUNNY, demonstrate that CVLA dramatically outperforms state-of-the-art and several competitive baseline approaches. Our dataset, code and model release at https://github.com/yliu-cs/CVLA.
    
[^27]: 最后的JITAI？大型语言模型在发放及时自适应干预中的不合理有效性：在前瞻性心脏康复环境中促进体育活动

    The Last JITAI? The Unreasonable Effectiveness of Large Language Models in Issuing Just-in-Time Adaptive Interventions: Fostering Physical Activity in a Prospective Cardiac Rehabilitation Setting

    [https://arxiv.org/abs/2402.08658](https://arxiv.org/abs/2402.08658)

    本研究探索了使用大型语言模型（LLMs）实现即时自适应干预（JITAIs）的可行性。通过测试GPT-4模型以促进门诊心脏康复中心的心脏健康体育活动的使用案例，我们提出了450个JITAI决策和信息。

    

    我们探索了大型语言模型（LLMs）在数字健康中触发和个性化即时自适应干预（JITAIs）内容的可行性。JITAIs被视为可持续行为改变的关键机制，将干预措施根据个体的当前情境和需求进行调整。然而，传统的基于规则和机器学习模型在JITAI实施中面临可扩展性和可靠性的限制，例如缺乏个性化、管理多参数系统困难以及数据稀疏性等问题。为了研究通过LLMs实现JITAI，我们使用基于在门诊心脏康复中促进心脏健康体育活动的使用案例的现代最高性能模型“GPT-4”的实例作为触发和个性化JITAIs的基础。随后，我们生成了总共450个建议的JITAI决策和信息。

    We explored the viability of Large Language Models (LLMs) for triggering and personalizing content for Just-in-Time Adaptive Interventions (JITAIs) in digital health. JITAIs are being explored as a key mechanism for sustainable behavior change, adapting interventions to an individual's current context and needs. However, traditional rule-based and machine learning models for JITAI implementation face scalability and reliability limitations, such as lack of personalization, difficulty in managing multi-parametric systems, and issues with data sparsity. To investigate JITAI implementation via LLMs, we tested the contemporary overall performance-leading model 'GPT-4' with examples grounded in the use case of fostering heart-healthy physical activity in outpatient cardiac rehabilitation. Three personas and five sets of context information per persona were used as a basis of triggering and personalizing JITAIs. Subsequently, we generated a total of 450 proposed JITAI decisions and message c
    
[^28]: 用自然语言和概率推理进行实验与修订规则

    Doing Experiments and Revising Rules with Natural Language and Probabilistic Reasoning

    [https://arxiv.org/abs/2402.06025](https://arxiv.org/abs/2402.06025)

    本论文建立了一个计算模型来模拟人们通过实验主动推断隐藏规则的过程，并发现显式假设、概率规则和在线更新的组合可以解释人们在类似Zendo任务上的表现。

    

    我们建立了一个计算模型，模拟人们通过实验主动推断隐藏规则的过程。该模型的基本原理是，即使规则是确定性的，学习者也会考虑更广泛的模糊概率规则，并用自然语言表示，根据近似贝叶斯原则在每次实验后在线更新自己的假设。在同一框架下，我们还根据信息论准则建立了实验设计模型。我们发现，这三个原则的组合——显式假设、概率规则和在线更新——可以解释人们在类似Zendo任务上的表现，而去掉其中任何一个组件都使得模型无法解释数据。

    We build a computational model of how humans actively infer hidden rules by doing experiments. The basic principles behind the model is that, even if the rule is deterministic, the learner considers a broader space of fuzzy probabilistic rules, which it represents in natural language, and updates its hypotheses online after each experiment according to approximately Bayesian principles. In the same framework we also model experiment design according to information-theoretic criteria. We find that the combination of these three principles -- explicit hypotheses, probabilistic rules, and online updates -- can explain human performance on a Zendo-style task, and that removing any of these components leaves the model unable to account for the data.
    
[^29]: 最后之舞：通过扩散模型和贝叶斯方法进行鲁棒后门攻击

    The last Dance : Robust backdoor attack via diffusion models and bayesian approach

    [https://arxiv.org/abs/2402.05967](https://arxiv.org/abs/2402.05967)

    本文介绍了一种通过扩散模型和贝叶斯方法进行鲁棒后门攻击的方法，具体应用于音频Transformer模型，并证明了攻击的可行性。

    

    扩散模型是最先进的深度学习生成模型，其通过逐步添加噪音和去噪的方式学习正向和反向扩散过程的原理进行训练。本文旨在欺骗基于音频的DNN模型，例如Hugging Face框架中的音频模型，特别是基于Transformer的人工智能模型，这些模型是强大的机器学习模型，节省时间，提供更高效的结果。我们证明了在Hugging Face推导出的音频Transformer上实现后门攻击（称为`BacKBayDiffMod`）的可行性。本文中开发的后门攻击基于毒化模型的训练数据，涉及后门扩散采样和贝叶斯方法分布的引入。

    Diffusion models are state-of-the-art deep learning generative models that are trained on the principle of learning forward and backward diffusion processes via the progressive addition of noise and denoising. In this paper, we seek to trick audio-based DNN models, such as those in the Hugging Face framework, for example, those that focus on audio, in particular transformer-based artificial intelligence models, which are powerful machine learning models that save time and deliver faster, more efficient results. We demonstrate the feasibility of backdoor attacks (called `BacKBayDiffMod`) on audio transformers derived from Hugging Face, a popular framework in the world of artificial intelligence (AI) research. The backdoor attack developed in this paper is based on poisoning the model's training data by incorporating backdoor diffusion sampling and a Bayesian approach to the distribution of poisoned data.
    
[^30]: MixedNUTS: 通过非线性混合分类器实现无需训练的准确性和鲁棒性平衡

    MixedNUTS: Training-Free Accuracy-Robustness Balance via Nonlinearly Mixed Classifiers

    [https://arxiv.org/abs/2402.02263](https://arxiv.org/abs/2402.02263)

    MixedNUTS是一种无需训练的方法，通过非线性混合分类器的转换和概率混合来实现准确性和鲁棒性的平衡。

    

    鲁棒性往往牺牲了准确性，阻碍了鲁棒分类模型在实际应用中的使用。基于训练的解决方案在与已训练的大型高性能模型兼容性方面存在限制，因此需要探索无需训练的集成方法。我们观察到鲁棒模型在干净数据和对抗数据上的正确预测比错误预测更自信，我们推测通过增强这种“良性置信度特性”可以在集成环境中实现准确性和鲁棒性的平衡。为了实现这一点，我们提出了“MixedNUTS”，一种无需训练的方法，利用仅有三个参数的非线性转换来处理鲁棒分类器和标准非鲁棒分类器的输出Logits，并通过高效算法进行优化。然后，MixedNUTS将转换后的Logits转换为概率，并将它们混合作为最终的输出。在CIFAR-10、CIFAR-100和ImageNet数据集上进行了实验。

    Adversarial robustness often comes at the cost of degraded accuracy, impeding the real-life application of robust classification models. Training-based solutions for better trade-offs are limited by incompatibilities with already-trained high-performance large models, necessitating the exploration of training-free ensemble approaches. Observing that robust models are more confident in correct predictions than in incorrect ones on clean and adversarial data alike, we speculate amplifying this "benign confidence property" can reconcile accuracy and robustness in an ensemble setting. To achieve so, we propose "MixedNUTS", a training-free method where the output logits of a robust classifier and a standard non-robust classifier are processed by nonlinear transformations with only three parameters, which are optimized through an efficient algorithm. MixedNUTS then converts the transformed logits into probabilities and mixes them as the overall output. On CIFAR-10, CIFAR-100, and ImageNet da
    
[^31]: L-TUNING：用于LLMs中的提示和前缀的同步标签调整

    L-TUNING: Synchronized Label Tuning for Prompt and Prefix in LLMs

    [https://arxiv.org/abs/2402.01643](https://arxiv.org/abs/2402.01643)

    本文介绍了L-Tuning，一种在自然语言推理（NLI）框架内的高效微调方法，通过对预训练的LLM中的标签标记进行微调，提高了训练准确性和效率，并增强了模型的训练细微差别。

    

    高效地针对特定任务对大型语言模型（LLMs）进行微调在自然语言处理中面临着重大挑战。传统方法，如提示或前缀调整，通常依赖于任意标记进行训练，从而导致训练时间延长并且通用标记在各种类别标签中使用。为了解决这些问题，本文引入了L-Tuning，这是一种在自然语言推理（NLI）框架内设计的用于分类任务的高效微调方法。与传统方法不同，L-Tuning专注于通过预训练的LLM处理的标签标记的微调，从而利用其预先存在的语义知识。这种技术不仅提高了微调的准确性和效率，还促进了为每个类别生成不同的标签嵌入，增强了模型的训练细微差别。我们的实验结果表明，使用L-Tuning可以显著提高训练效率和分类准确性。

    Efficiently fine-tuning Large Language Models (LLMs) for specific tasks presents a considerable challenge in natural language processing. Traditional methods, like prompt or prefix tuning, typically rely on arbitrary tokens for training, leading to prolonged training times and generalized token use across various class labels. To address these issues, this paper introduces L-Tuning, an efficient fine-tuning approach designed for classification tasks within the Natural Language Inference (NLI) framework. Diverging from conventional methods, L-Tuning focuses on the fine-tuning of label tokens processed through a pre-trained LLM, thereby harnessing its pre-existing semantic knowledge. This technique not only improves the fine-tuning accuracy and efficiency but also facilitates the generation of distinct label embeddings for each class, enhancing the model's training nuance. Our experimental results indicate a significant improvement in training efficiency and classification accuracy with 
    
[^32]: 通过收集轨迹和合成奖励来学习基于规划的推理

    Learning Planning-based Reasoning by Trajectories Collection and Process Reward Synthesizing

    [https://arxiv.org/abs/2402.00658](https://arxiv.org/abs/2402.00658)

    本文提出了一种通过直接偏好优化在收集到的轨迹上学习基于规划的推理的框架，以解决大型语言模型在复杂推理任务中的虚幻和缺陷问题。

    

    大型语言模型（LLM）通过逐步合理化生成，展示了处理复杂推理任务的重要潜力。然而，最近的研究对它们的推理过程中的虚幻和缺陷提出了担忧。为了提高生成合理化的可靠性和忠实性，正在进行大量工作。有些方法将推理建模为规划，而其他方法则专注于注释的过程监督。然而，基于规划的搜索过程往往由于频繁评估中间推理状态和广泛的探索空间而导致高延迟。此外，使用人工注释监督推理过程对于LLM训练来说是昂贵且具有挑战性的。为了解决这些问题，我们在本文中提出了一种通过直接偏好优化（DPO）来学习基于规划的推理的框架，其中轨迹直接根据合成的过程奖励进行排名。

    Large Language Models (LLMs) have demonstrated significant potential in handling complex reasoning tasks through step-by-step rationale generation. However, recent studies have raised concerns regarding the hallucination and flaws in their reasoning process. Substantial efforts are being made to improve the reliability and faithfulness of the generated rationales. Some approaches model reasoning as planning, while others focus on annotating for process supervision. Nevertheless, the planning-based search process often results in high latency due to the frequent assessment of intermediate reasoning states and the extensive exploration space. Additionally, supervising the reasoning process with human annotation is costly and challenging to scale for LLM training. To address these issues, in this paper, we propose a framework to learn planning-based reasoning through direct preference optimization (DPO) on collected trajectories, which are ranked according to synthesized process rewards. 
    
[^33]: 关于RMSProp及其动量扩展方法的$O(\frac{\sqrt{d}}{T^{1/4}})$收敛速度和对维度的改进依赖性

    On the $O(\frac{\sqrt{d}}{T^{1/4}})$ Convergence Rate of RMSProp and Its Momentum Extension Measured by $\ell_1$ Norm: Better Dependence on the Dimension

    [https://arxiv.org/abs/2402.00389](https://arxiv.org/abs/2402.00389)

    这项研究探讨了RMSProp及其动量扩展方法的收敛速度，并发现使用$\ell_1$范数测度时，收敛速度为$O(\frac{\sqrt{d}}{T^{1/4}})$，在维度极大的问题中具有改进依赖性。

    

    尽管自适应梯度方法在深度学习中被广泛使用，但其收敛速度尚未得到彻底研究，特别是对于其对维度的依赖性。本文考虑了经典的RMSProp及其动量扩展方法，并通过$\ell_1$范数建立了收敛率$\frac{1}{T}\sum_{k=1}^TE\left[\|\nabla f(x^k)\|_1\right]\leq O(\frac{\sqrt{d}}{T^{1/4}})$，无需假设梯度有界，其中$d$是优化变量的维度，$T$是迭代次数。由于对于维度极大的问题，$\|x\|_2\ll\|x\|_1\leq\sqrt{d}\|x\|_2$，因此我们的收敛速度可以类比为SGD的$\frac{1}{T}\sum_{k=1}^TE\left[\|\nabla f(x^k)\|_2\right]\leq O(\frac{1}{T^{1/4}})$，测度为$\ell_1$范数。

    Although adaptive gradient methods have been extensively used in deep learning, their convergence rates have not been thoroughly studied, particularly with respect to their dependence on the dimension. This paper considers the classical RMSProp and its momentum extension and establishes the convergence rate of $\frac{1}{T}\sum_{k=1}^TE\left[\|\nabla f(x^k)\|_1\right]\leq O(\frac{\sqrt{d}}{T^{1/4}})$ measured by $\ell_1$ norm without the bounded gradient assumption, where $d$ is the dimension of the optimization variable and $T$ is the iteration number. Since $\|x\|_2\ll\|x\|_1\leq\sqrt{d}\|x\|_2$ for problems with extremely large $d$, our convergence rate can be considered to be analogous to the $\frac{1}{T}\sum_{k=1}^TE\left[\|\nabla f(x^k)\|_2\right]\leq O(\frac{1}{T^{1/4}})$ one of SGD measured by $\ell_1$ norm.
    
[^34]: 通过多阶段不确定性感知推断来维护用户信任

    Maintaining User Trust Through Multistage Uncertainty Aware Inference

    [https://arxiv.org/abs/2402.00015](https://arxiv.org/abs/2402.00015)

    本文介绍了一种多阶段的人工智能部署方法，其中每个阶段都使用更准确的推理方法，以维护用户的信任。作者提出了一种量化模型不确定性的方法，以促进对推理结果的有信心的决策。该方法已经在印度的数千名棉农中进行了实际部署，并且可以适用于其他低资源环境中的人工智能部署。

    

    本文描述并评估了一种多阶段的人工智能部署方法。每个阶段都涉及一种更准确的推理方法，但每个阶段的开销也逐渐增加。在概述架构时，我们提出了一种量化模型不确定性的方法，以促进有信心的延期决策。该架构目前正在印度的数千名棉农中进行积极部署。然而，这个更广泛的想法也适用于在具有挑战性的低资源环境中进行人工智能部署的不断增长的领域。

    This paper describes and evaluates a multistage approach to AI deployment. Each stage involves a more accurate method of inference, yet engaging each comes with an increasing cost. In outlining the architecture, we present a method for quantifying model uncertainty that facilitates confident deferral decisions. The architecture is currently under active deployment to thousands of cotton farmers across India. The broader idea however is applicable to a growing sector of AI deployments in challenging low resources settings.
    
[^35]: 重新思考多元时间序列预测的通道相关性：从领先指标中学习

    Rethinking Channel Dependence for Multivariate Time Series Forecasting: Learning from Leading Indicators

    [https://arxiv.org/abs/2401.17548](https://arxiv.org/abs/2401.17548)

    本文提出了一种新方法，LIFT，通过利用通道相关性和领先指标，为多元时间序列预测提供准确的预测。LIFT方法可以无缝与任意时间序列预测方法协作，大量实验证明了其有效性。

    

    最近，独立于通道的方法在多元时间序列（MTS）预测中取得了最先进的性能。尽管这些方法减少了过拟合的风险，但它们错过了利用通道相关性进行准确预测的潜在机会。我们认为，在变量之间存在局部平稳的领先-滞后关系，即一些滞后变量在短时间内可能遵循领先指标。利用这种通道相关性是有益的，因为领先指标提供了先进信息，可以用来减少滞后变量的预测难度。在本文中，我们提出了一种名为LIFT的新方法，该方法首先在每个时间步骤高效地估计领先指标及其领先步骤，然后巧妙地允许滞后变量利用来自领先指标的先进信息。LIFT作为一个插件，可以与任意时间序列预测方法无缝协作。进行了大量实验证明了LIFT方法的有效性。

    Recently, channel-independent methods have achieved state-of-the-art performance in multivariate time series (MTS) forecasting. Despite reducing overfitting risks, these methods miss potential opportunities in utilizing channel dependence for accurate predictions. We argue that there exist locally stationary lead-lag relationships between variates, i.e., some lagged variates may follow the leading indicators within a short time period. Exploiting such channel dependence is beneficial since leading indicators offer advance information that can be used to reduce the forecasting difficulty of the lagged variates. In this paper, we propose a new method named LIFT that first efficiently estimates leading indicators and their leading steps at each time step and then judiciously allows the lagged variates to utilize the advance information from leading indicators. LIFT plays as a plugin that can be seamlessly collaborated with arbitrary time series forecasting methods. Extensive experiments o
    
[^36]: 数据有效学习：一项综合医学基准研究

    Data-Effective Learning: A Comprehensive Medical Benchmark

    [https://arxiv.org/abs/2401.17542](https://arxiv.org/abs/2401.17542)

    这项研究引入了一个综合基准，用于评估医学领域的数据有效学习。该基准包括大量的医疗数据样本、基准方法和新的评估指标，能够准确评估数据有效学习的性能。

    

    数据有效学习旨在以最有效的方式利用数据来训练AI模型，其涉及关注数据质量而非数量的策略，确保用于训练的数据具有高信息价值。数据有效学习在加快AI训练、减少计算成本和节省数据存储方面发挥着重要作用，这在近年来医学数据的数量超出了许多人的预期时尤为重要。然而，由于缺乏标准和综合的基准研究，医学领域的数据有效学习研究还不够深入。为了填补这一空白，本文引入了一个专门用于评估医学领域数据有效学习的综合基准。该基准包括来自31个医疗中心数百万个数据样本的数据集(DataDEL)，用于比较的基准方法(MedDEL)，以及一个用于客观衡量数据有效学习性能的新评估指标(NormDEL)。我们进行了广泛的实证实验和比较，证明了我们的基准在评估数据有效学习方面的有效性和适用性。

    Data-effective learning aims to use data in the most impactful way to train AI models, which involves strategies that focus on data quality rather than quantity, ensuring the data used for training has high informational value. Data-effective learning plays a profound role in accelerating AI training, reducing computational costs, and saving data storage, which is very important as the volume of medical data in recent years has grown beyond many people's expectations. However, due to the lack of standards and comprehensive benchmark, research on medical data-effective learning is poorly studied. To address this gap, our paper introduces a comprehensive benchmark specifically for evaluating data-effective learning in the medical field. This benchmark includes a dataset with millions of data samples from 31 medical centers (DataDEL), a baseline method for comparison (MedDEL), and a new evaluation metric (NormDEL) to objectively measure data-effective learning performance. Our extensive e
    
[^37]: 大型语言模型的心理测量预测能力

    Psychometric Predictive Power of Large Language Models

    [https://arxiv.org/abs/2311.07484](https://arxiv.org/abs/2311.07484)

    指令调整和提示在大型语言模型中无法提供比基础模型更好的认知建模估计。

    

    arXiv:2311.07484v2 公告类型: 替换-交叉 摘要:指令调整使大型语言模型（LLMs）的响应与人类偏好一致。尽管在人-LLM对齐方面进行了努力，我们报告了一个有趣的发现，即指令调整并不总是使LLMs从认知建模的角度看起来更像人类。更具体地说，由指令调整的LLM估计的下一个词概率往往比基础LLM估计的概率更糟糕，无法模拟人类阅读行为。此外，我们探讨了使用LLMs模拟人类阅读行为的提示方法。我们的结果表明，反映特定语言假设的提示可以提高PPP，但仍不及小型基础模型的PPP。这些发现突显出LLMs最近的进展，即指令调整和提示，并不能提供比基础LLMs直接概率测量更好的认知建模估计。换句话说，我们的实验表明，纯粹的下一个词概率

    arXiv:2311.07484v2 Announce Type: replace-cross  Abstract: Instruction tuning aligns the response of large language models (LLMs) with human preferences. Despite such efforts in human--LLM alignment, we report that, interestingly, instruction tuning does not always make LLMs human-like from a cognitive modeling perspective. More specifically, next-word probabilities estimated by instruction-tuned LLMs are often worse at simulating human reading behavior than those estimated by base LLMs. In addition, we explore prompting methodologies in simulating human reading behavior with LLMs. Our results show that prompts reflecting a particular linguistic hypothesis improve PPP but are still inferior to PPP from small base models. These findings highlight that recent advancements in LLMs, i.e., instruction tuning and prompting, do not offer better estimates than direct probability measurements from base LLMs in cognitive modeling. In other words, our experiments highlight that pure next-word pro
    
[^38]: 火焰: 评估中国大型语言模型与人类价值观的契合性的基准测试

    Flames: Benchmarking Value Alignment of Chinese Large Language Models

    [https://arxiv.org/abs/2311.06899](https://arxiv.org/abs/2311.06899)

    中国的大型语言模型的价值观契合性需要更加全面的评估，该研究提出了一个名为"火焰"（Flames）的基准测试，涵盖了常见的无害原则和特定中国价值观，以及复杂场景和隐含恶意的提示方法。

    

    大型语言模型（LLMs）在各个地区的广泛应用强调了评估它们与人类价值观契合性的迫切性。然而，当前的基准测试未能有效地揭示LLMs中的安全漏洞。尽管许多模型在这些评估中得分很高，且“名列前茅”，但在LLMs与人类价值观的深层契合性和实现真正无害方面仍存在重大差距。为此，本文提出了一个名为"火焰"（Flames）的价值观契合性基准测试，该测试涵盖了常见的无害原则，以及一个整合了特定中国价值观如和谐的独特道德维度。因此，我们精心设计了包含复杂情境和大多带有隐含恶意的破解方法的对抗性提示。通过对17个主流LLMs进行提示，我们获得了模型的回应，并对其进行了详细评估。

    arXiv:2311.06899v2 Announce Type: replace-cross  Abstract: The widespread adoption of large language models (LLMs) across various regions underscores the urgent need to evaluate their alignment with human values. Current benchmarks, however, fall short of effectively uncovering safety vulnerabilities in LLMs. Despite numerous models achieving high scores and 'topping the chart' in these evaluations, there is still a significant gap in LLMs' deeper alignment with human values and achieving genuine harmlessness. To this end, this paper proposes a value alignment benchmark named Flames, which encompasses both common harmlessness principles and a unique morality dimension that integrates specific Chinese values such as harmony. Accordingly, we carefully design adversarial prompts that incorporate complex scenarios and jailbreaking methods, mostly with implicit malice. By prompting 17 mainstream LLMs, we obtain model responses and rigorously annotate them for detailed evaluation. Our findin
    
[^39]: 序列级确定性降低基于知识的对话生成中的虚构情况

    Sequence-Level Certainty Reduces Hallucination In Knowledge-Grounded Dialogue Generation

    [https://arxiv.org/abs/2310.18794](https://arxiv.org/abs/2310.18794)

    序列级确定性是减少基于知识的对话生成中幻觉的关键，这项工作提出了基于概率确定性和语义确定性的序列级确定性，结果表明更高水平的确定性对应更低水平的幻觉，进一步提出了基于确定性的响应排序方法

    

    在这项工作中，我们提出了序列级确定性作为基于知识的对话生成中虚构情况的共同主题。我们探讨了幻觉水平与两种序列级确定性之间的相关性：概率确定性和语义确定性。实证结果表明，模型响应中两种序列级确定性水平的提高与虚构水平的降低相关。我们进一步提出了基于确定性的响应排序（CRR），这是一种解码时的幻觉缓解方法，根据它们的序列级确定性对响应候选进行排序，并输出具有最高确定性水平的答案。与我们关于序列级确定性的定义相一致，我们设计了两种CRR方法：概率CRR（P-CRR）和语义CRR（S-CRR）。P-CRR使用整个序列的算术平均对各个单独抽样的模型响应进行排名

    arXiv:2310.18794v2 Announce Type: replace-cross  Abstract: In this work, we propose sequence-level certainty as a common theme over hallucination in Knowledge Grounded Dialogue Generation (KGDG). We explore the correlation between the level of hallucination and two types of sequence-level certainty: probabilistic certainty and semantic certainty. Empirical results reveal that a higher level of both types of sequence-level certainty in model responses is correlated with a lower level of hallucination. We further propose Certainty-based Response Ranking (CRR), a decoding-time hallucination mitigation method that ranks response candidates based on their sequence-level certainty and outputs the answer with the highest certainty level. Aligning with our definitions of sequence-level certainty, we design 2 types of CRR approaches: Probabilistic CRR (P-CRR) and Semantic CRR (S-CRR). P-CRR ranks individually sampled model responses using the arithmetic mean log-probability of the entire sequen
    
[^40]: 评估大型语言模型的空间理解能力

    Evaluating Spatial Understanding of Large Language Models

    [https://arxiv.org/abs/2310.14540](https://arxiv.org/abs/2310.14540)

    本研究评估了大型语言模型对空间结构的理解能力，发现LLMs在表示和推理空间结构时的表现存在显著差异，具有捕捉空间结构隐含特征的潜力。

    

    大型语言模型 (LLMs) 在各种任务中展现出卓越的能力。尽管这些模型在训练中只看到文本，但一些最近的研究表明，LLM表示隐含地捕捉了地面概念的几个方面。在这里，我们探讨了LLM表示对一种特别显著的基础知识 -- 空间关系的表现。我们设计了自然语言导航任务，评估了LLMs，特别是GPT-3.5-turbo、GPT-4 和 Llama2 系列模型，表示和推理空间结构的能力。这些任务揭示了LLM在不同空间结构 (包括正方形、六边形和三角形格、环和树) 上的性能差异。在广泛的错误分析中，我们发现LLMs的错误反映了空间和非空间因素。这些发现表明，LLMs似乎隐含地捕捉了空间结构的某些方面，但仍有提升的空间。

    arXiv:2310.14540v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) show remarkable capabilities across a variety of tasks. Despite the models only seeing text in training, several recent studies suggest that LLM representations implicitly capture aspects of the underlying grounded concepts. Here, we explore LLM representations of a particularly salient kind of grounded knowledge -- spatial relationships. We design natural-language navigation tasks and evaluate the ability of LLMs, in particular GPT-3.5-turbo, GPT-4, and Llama2 series models, to represent and reason about spatial structures. These tasks reveal substantial variability in LLM performance across different spatial structures, including square, hexagonal, and triangular grids, rings, and trees. In extensive error analysis, we find that LLMs' mistakes reflect both spatial and non-spatial factors. These findings suggest that LLMs appear to capture certain aspects of spatial structure implicitly, but room f
    
[^41]: 能够检测到LLM生成的虚假信息吗?

    Can LLM-Generated Misinformation Be Detected?

    [https://arxiv.org/abs/2309.13788](https://arxiv.org/abs/2309.13788)

    LLM生成的虚假信息可能比人类撰写的虚假信息更难以检测，具有更具欺骗性的风格，可能造成更多危害。

    

    大型语言模型（LLMs）的出现产生了深远影响。然而，LLMs（如ChatGPT）可能被利用来生成虚假信息，这给在线安全和公众信任带来了严重关切。一个基本的研究问题是：LLM生成的虚假信息是否会比人类撰写的虚假信息造成更大危害?我们提出从检测难度的角度来探讨这个问题。我们首先建立了一个LLM生成的虚假信息分类法。然后，我们对利用LLMs生成虚假信息的潜在真实世界方法进行分类和验证。通过广泛的实证调查，我们发现与具有相同语义的人类撰写的虚假信息相比，LLM生成的虚假信息对人类和检测器来说更难检测，这表明它可能具有更具欺骗性的风格，潜在地造成更多危害。我们还讨论了我们发现的影响。

    arXiv:2309.13788v3 Announce Type: replace-cross  Abstract: The advent of Large Language Models (LLMs) has made a transformative impact. However, the potential that LLMs such as ChatGPT can be exploited to generate misinformation has posed a serious concern to online safety and public trust. A fundamental research question is: will LLM-generated misinformation cause more harm than human-written misinformation? We propose to tackle this question from the perspective of detection difficulty. We first build a taxonomy of LLM-generated misinformation. Then we categorize and validate the potential real-world methods for generating misinformation with LLMs. Then, through extensive empirical investigation, we discover that LLM-generated misinformation can be harder to detect for humans and detectors compared to human-written misinformation with the same semantics, which suggests it can have more deceptive styles and potentially cause more harm. We also discuss the implications of our discovery
    
[^42]: 零阶优化遇到人工反馈：通过排名预测实现可证明学习

    Zeroth-Order Optimization Meets Human Feedback: Provable Learning via Ranking Oracles

    [https://arxiv.org/abs/2303.03751](https://arxiv.org/abs/2303.03751)

    零阶优化算法ZO-RankSGD解决了一个新兴的优化挑战，即只能通过排名预测来评估黑盒目标函数。该算法利用一种新颖的随机估计器来确定下降方向，并保证收敛到一个稳定点。此外，该算法还可用于增强学习中的策略优化问题，特别是当只有对于回报排名的排名预测时。

    

    在这项研究中，我们探讨了一种新兴的优化挑战，其中涉及到一个只能通过排名预测来评估的黑盒目标函数-这种情况在实际场景中经常遇到，特别是当函数由人类评判员评估时。这种挑战受到了强化学习与人工反馈（RLHF）的启发，这是一种最近用来提高大型语言模型（LLMs）性能的方法。我们引入了一种创新的零阶优化算法ZO-RankSGD来解决这个优化问题，并提供了理论保证。我们的算法利用一种新颖的基于排名的随机估计器来确定下降方向，并保证收敛到一个稳定点。此外，ZO-RankSGD可以直接应用于增强学习中的策略优化问题，特别是当只有对于回报排名的排名预测时。

    arXiv:2303.03751v2 Announce Type: replace-cross  Abstract: In this study, we delve into an emerging optimization challenge involving a black-box objective function that can only be gauged via a ranking oracle-a situation frequently encountered in real-world scenarios, especially when the function is evaluated by human judges. Such challenge is inspired from Reinforcement Learning with Human Feedback (RLHF), an approach recently employed to enhance the performance of Large Language Models (LLMs) using human guidance. We introduce ZO-RankSGD, an innovative zeroth-order optimization algorithm designed to tackle this optimization problem, accompanied by theoretical assurances. Our algorithm utilizes a novel rank-based random estimator to determine the descent direction and guarantees convergence to a stationary point. Moreover, ZO-RankSGD is readily applicable to policy optimization problems in Reinforcement Learning (RL), particularly when only ranking oracles for the episode reward are a
    
[^43]: 基于方差减少的经验回放用于策略优化

    Variance Reduction Based Experience Replay for Policy Optimization

    [https://arxiv.org/abs/2110.08902](https://arxiv.org/abs/2110.08902)

    引入了基于方差减少的经验回放框架，实现了选择性重复利用相关样本来改善策略梯度估计，并构建了高效的离策略算法PG-VRER。

    

    在复杂随机系统上进行强化学习时，有效利用历史样本中的信息以加速策略优化是很有必要的。传统的经验回放虽然有效，但是将所有观测都视为相同，忽略了它们的相对重要性。为了解决这一限制，我们引入了一种新颖的方差减少经验回放（VRER）框架，实现对相关样本的选择性重复利用，从而改善策略梯度估计。VRER作为一种适应性方法，可以无缝集成到不同的策略优化算法中，构建了我们高效的离策略算法Policy Optimization with VRER (PG-VRER)。此外，文献中对经验回放方法缺乏严格的理论理解，这促使我们引入一个新颖的理论框架，考虑样本依赖性。

    arXiv:2110.08902v3 Announce Type: replace-cross  Abstract: For reinforcement learning on complex stochastic systems, it is desirable to effectively leverage the information from historical samples collected in previous iterations to accelerate policy optimization. Classical experience replay, while effective, treats all observations uniformly, neglecting their relative importance. To address this limitation, we introduce a novel Variance Reduction Experience Replay (VRER) framework, enabling the selective reuse of relevant samples to improve policy gradient estimation. VRER, as an adaptable method that can seamlessly integrate with different policy optimization algorithms, forms the foundation of our sample-efficient off-policy algorithm known as Policy Optimization with VRER (PG-VRER). Furthermore, the lack of a rigorous theoretical understanding of the experience replay method in the literature motivates us to introduce a novel theoretical framework that accounts for sample dependenc
    
[^44]: 朝向生成式抽象推理：通过规则抽象和选择来完成Raven的渐进矩阵

    Towards Generative Abstract Reasoning: Completing Raven's Progressive Matrix via Rule Abstraction and Selection. (arXiv:2401.09966v1 [cs.AI])

    [http://arxiv.org/abs/2401.09966](http://arxiv.org/abs/2401.09966)

    本文提出了一个条件生成模型（RAISE），通过在潜在空间中进行规则抽象和选择，以解决Raven的渐进矩阵问题，该模型能够在现实的场景中展示出抽象推理的能力。

    

    在人工智能领域，赋予机器抽象推理能力是一个长期的研究课题。Raven的渐进矩阵（RPM）被广泛用于探索机器智能中的抽象视觉推理，模型需要理解潜在的规则并从候选集中选择缺失的右下图像来完成图像矩阵。参与者可以通过推断潜在的属性变化规则和想象任意位置的缺失图像展示强大的推理能力。然而，现有的解决方案很难在现实的RPM问题中展示出这种能力。在本文中，我们提出了一个条件生成模型，通过规则抽象和选择（RAISE）在潜在空间中解决答案生成问题。RAISE将图像属性编码为潜在概念，并通过概念将潜在规则分解成原子规则，这些原子规则被抽象为全局可学习的参数。在生成答案时，RAISE选择...

    Endowing machines with abstract reasoning ability has been a long-term research topic in artificial intelligence. Raven's Progressive Matrix (RPM) is widely used to probe abstract visual reasoning in machine intelligence, where models need to understand the underlying rules and select the missing bottom-right images out of candidate sets to complete image matrices. The participators can display powerful reasoning ability by inferring the underlying attribute-changing rules and imagining the missing images at arbitrary positions. However, existing solvers can hardly manifest such an ability in realistic RPM problems. In this paper, we propose a conditional generative model to solve answer generation problems through Rule AbstractIon and SElection (RAISE) in the latent space. RAISE encodes image attributes as latent concepts and decomposes underlying rules into atomic rules by means of concepts, which are abstracted as global learnable parameters. When generating the answer, RAISE select
    
[^45]: 针对多个数据集约束宇宙学参数的领域适应图神经网络

    Domain Adaptive Graph Neural Networks for Constraining Cosmological Parameters Across Multiple Data Sets. (arXiv:2311.01588v1 [astro-ph.CO])

    [http://arxiv.org/abs/2311.01588](http://arxiv.org/abs/2311.01588)

    该论文研究了通过领域适应图神经网络对宇宙学参数进行约束的方法。通过利用GNNs捕捉宇宙学信息和使用最大均值差异进行领域适应，该方法在不同数据集上具有较好的泛化能力。

    

    研究表明，与依赖于摘要统计量（如功率谱）的方法相比，深度学习模型在从复杂宇宙学数据集中提取信息方面表现更好。然而，由于不同模拟套件中的子网格物理实现和数值逼近的差异，模型在一个宇宙学模拟的数据上训练后，在另一个模拟数据上的表现会下降。同样，对于任何模拟数据训练的模型，在应用于观测数据时也可能出现性能下降。通过在两个不同套件的CAMELS水动力宇宙学模拟数据上进行训练，我们研究了领域适应图神经网络（DA-GNNs）的泛化能力。通过利用GNNs，我们可以利用它们捕捉来自星系分布的结构无标度宇宙学信息的能力。此外，通过包括无监督的领域适配最大均值差异（MMD），我们使模型能够自适应地学习两个模拟数据之间的差异。

    Deep learning models have been shown to outperform methods that rely on summary statistics, like the power spectrum, in extracting information from complex cosmological data sets. However, due to differences in the subgrid physics implementation and numerical approximations across different simulation suites, models trained on data from one cosmological simulation show a drop in performance when tested on another. Similarly, models trained on any of the simulations would also likely experience a drop in performance when applied to observational data. Training on data from two different suites of the CAMELS hydrodynamic cosmological simulations, we examine the generalization capabilities of Domain Adaptive Graph Neural Networks (DA-GNNs). By utilizing GNNs, we capitalize on their capacity to capture structured scale-free cosmological information from galaxy distributions. Moreover, by including unsupervised domain adaptation via Maximum Mean Discrepancy (MMD), we enable our models to ex
    
[^46]: BioImage.IO Chatbot: 一个以社区知识库增强的生物图像分析个人助手

    BioImage.IO Chatbot: A Personalized Assistant for BioImage Analysis Augmented by Community Knowledge Base. (arXiv:2310.18351v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.18351](http://arxiv.org/abs/2310.18351)

    BioImage.IO Chatbot 是一个根据用户个性化需求提供答案的AI聊天助手，通过汇集和解释多个数据库、工具文档和数据源的信息，以及社区贡献的知识库和优化的检索方法，为生物图像分析工具的使用者提供了个性化、上下文感知的体验，为可访问的科学研究设立了新的标准。

    

    快速扩展的生物图像分析工具景观给专家和新来者都带来了导航挑战。传统的搜索方法在这个复杂环境中常常无法提供帮助。为了解决这个问题，我们引入了BioImage.IO Chatbot，一个为生物图像社区量身定制的基于人工智能的对话助手。这个聊天机器人建立在大型语言模型的基础上，通过聚合和解释来自多个数据库、特定工具文档和结构化数据源的信息，提供个性化的、上下文感知的答案。通过社区贡献的知识库和经过优化的检索方法，BioImage.IO Chatbot 不仅提供个性化的互动，还提供丰富的知识、上下文感知的体验。它从根本上改变了生物学家、生物图像分析师和开发者导航和利用先进的生物图像分析工具的方式，为社区驱动的可访问科学研究树立了新的标准。

    The rapidly expanding landscape of bioimage analysis tools presents a navigational challenge for both experts and newcomers. Traditional search methods often fall short in assisting users in this complex environment. To address this, we introduce the BioImage$.$IO Chatbot, an AI-driven conversational assistant tailored for the bioimage community. Built upon large language models, this chatbot provides personalized, context-aware answers by aggregating and interpreting information from diverse databases, tool-specific documentation, and structured data sources. Enhanced by a community-contributed knowledge base and fine-tuned retrieval methods, the BioImage$.$IO Chatbot offers not just a personalized interaction but also a knowledge-enriched, context-aware experience. It fundamentally transforms the way biologists, bioimage analysts, and developers navigate and utilize advanced bioimage analysis tools, setting a new standard for community-driven, accessible scientific research.
    
[^47]: 基于内容的音乐大语言建模的控制

    Content-based Controls For Music Large Language Modeling. (arXiv:2310.17162v1 [cs.AI])

    [http://arxiv.org/abs/2310.17162](http://arxiv.org/abs/2310.17162)

    该论文提出了一种基于内容的控制方法，用于音乐大语言建模。通过对音高、和弦和鼓乐等固有音乐语言的直接控制，实现了高质量的音乐生成，并且使用了参数高效微调的方法，比原始模型的参数数量少于4%。

    

    近年来，在音乐音频领域出现了大规模语言模型的迅速增长。这些模型使得能够进行高质量音乐的端到端生成，并且一些模型可以使用文本描述进行条件生成。然而，文本在音乐上的控制能力本质上是有限的，因为它们只能通过元数据（如歌手和乐器）或高级表示（如流派和情感）间接地描述音乐。我们的目标是进一步提供对音高、和弦和鼓乐等固有音乐语言的直接和基于内容的控制能力。为此，我们提出了Coco-Mulla，这是一种用于音乐大语言建模的基于内容的控制方法。它使用了针对基于Transformer的音频模型量身定制的参数高效微调（PEFT）方法。实验表明，我们的方法在低资源半监督学习中实现了高质量的音乐生成，相比原始模型，参数调优的比例不到4%。

    Recent years have witnessed a rapid growth of large-scale language models in the domain of music audio. Such models enable end-to-end generation of higher-quality music, and some allow conditioned generation using text descriptions. However, the control power of text controls on music is intrinsically limited, as they can only describe music indirectly through meta-data (such as singers and instruments) or high-level representations (such as genre and emotion). We aim to further equip the models with direct and content-based controls on innate music languages such as pitch, chords and drum track. To this end, we contribute Coco-Mulla, a content-based control method for music large language modeling. It uses a parameter-efficient fine-tuning (PEFT) method tailored for Transformer-based audio models. Experiments show that our approach achieved high-quality music generation with low-resource semi-supervised learning, tuning with less than 4% parameters compared to the original model and t
    
[^48]: 射频指纹识别的挑战：从数据收集到部署

    Challenges of Radio Frequency Fingerprinting: From Data Collection to Deployment. (arXiv:2310.16406v1 [cs.CR])

    [http://arxiv.org/abs/2310.16406](http://arxiv.org/abs/2310.16406)

    射频指纹识别技术通过利用硬件缺陷在物理层验证无线设备的身份，然而与深度学习技术的整合和实际场景应用带来了许多挑战。本文分析了这些挑战并指出当前阻碍射频指纹识别实际部署的问题，并探讨了未来发展方向。

    

    射频指纹识别（RFF）技术承诺基于制造过程中引入的固有硬件缺陷来在物理层对无线设备进行身份验证。这些射频发射器的缺陷反映在空中信号中，使接收器能够准确识别射频发射源。近年来，机器学习，特别是深度学习（DL）的进步，提高了RFF系统提取和学习构成设备特定指纹的复杂特征的能力。然而，将DL技术与RFF集成并在实际场景中运行系统面临许多挑战。本文在考虑DL-based RFF系统的三个参考阶段（数据收集和预处理，训练，最后部署）的基础上，识别和分析了这些挑战。我们的调查指出了目前阻碍RFF实际部署的现有问题，并讨论了有前途的未来发展方向。

    Radio Frequency Fingerprinting (RFF) techniques promise to authenticate wireless devices at the physical layer based on inherent hardware imperfections introduced during manufacturing. Such RF transmitter imperfections are reflected into over-the-air signals, allowing receivers to accurately identify the RF transmitting source. Recent advances in Machine Learning, particularly in Deep Learning (DL), have improved the ability of RFF systems to extract and learn complex features that make up the device-specific fingerprint. However, integrating DL techniques with RFF and operating the system in real-world scenarios presents numerous challenges. This article identifies and analyzes these challenges while considering the three reference phases of any DL-based RFF system: (i) data collection and preprocessing, (ii) training, and finally, (iii) deployment. Our investigation points out the current open problems that prevent real deployment of RFF while discussing promising future directions, 
    
[^49]: Retro-fallback: 面向不确定世界的逆合成规划

    Retro-fallback: retrosynthetic planning in an uncertain world. (arXiv:2310.09270v1 [cs.AI])

    [http://arxiv.org/abs/2310.09270](http://arxiv.org/abs/2310.09270)

    本文针对逆合成任务在实验室执行可行性的不确定性问题，通过引入随机过程的表述，提出了一种名为 Retro-fallback 的贪婪算法，该算法能够最大化实验室可执行的合成计划的概率。

    

    逆合成是通过提出一系列化学反应从更简单、可购买的分子创建所需分子的任务。虽然先前的研究提出了一些算法来寻找一系列度量指标（例如最短路径、最低成本）的最优解，但这些研究通常忽视了我们对可能反应空间的不完全了解，这意味着算法生成的计划可能在实验室中无法实施。在本文中，我们提出了一种基于随机过程的逆合成新颖表述，以考虑这种不确定性。然后，我们提出了一种新颖的贪婪算法称为 Retro-fallback，最大化至少有一种合成计划能在实验室中执行的概率。使用仿真基准测试，我们证明 Retro-fallback 通常生成比流行的 MCTS 和 retro* 算法更好的一组合成计划。

    Retrosynthesis is the task of proposing a series of chemical reactions to create a desired molecule from simpler, buyable molecules. While previous works have proposed algorithms to find optimal solutions for a range of metrics (e.g. shortest, lowest-cost), these works generally overlook the fact that we have imperfect knowledge of the space of possible reactions, meaning plans created by the algorithm may not work in a laboratory. In this paper we propose a novel formulation of retrosynthesis in terms of stochastic processes to account for this uncertainty. We then propose a novel greedy algorithm called retro-fallback which maximizes the probability that at least one synthesis plan can be executed in the lab. Using in-silico benchmarks we demonstrate that retro-fallback generally produces better sets of synthesis plans than the popular MCTS and retro* algorithms.
    
[^50]: 将大型语言模型作为AI研究代理进行基准测试

    Benchmarking Large Language Models As AI Research Agents. (arXiv:2310.03302v1 [cs.LG])

    [http://arxiv.org/abs/2310.03302](http://arxiv.org/abs/2310.03302)

    本研究提出了MLAgentBench，一个用于对AI研究代理进行基准测试的ML任务套件，代理可以执行各种操作，从而运行实验、分析结果并修改整个机器学习流程的代码。这可以帮助我们构建和评估能够执行长期目标任务的AI研究代理。

    

    科学实验涉及创建假设、设计实验、运行实验和分析结果的迭代过程。我们能否构建AI研究代理来执行这些长期目标的任务呢？为了朝着在此类开放性决策任务上构建和评估研究代理的目标迈出一步，我们着眼于机器学习工程问题：给定一个任务描述和数据集，构建一个高性能模型。在本文中，我们提出了MLAgentBench，一个用于对AI研究代理进行基准测试的ML任务套件。代理可以执行读写文件、执行代码和检查输出等动作。通过这些动作，代理可以运行实验、分析结果，并修改整个机器学习流程的代码，如数据处理、架构、训练过程等。然后，基准测试自动客观地评估代理在与性能和效率相关的各种指标上的表现。我们还设计了一个LLM-

    Scientific experimentation involves an iterative process of creating hypotheses, designing experiments, running experiments, and analyzing the results. Can we build AI research agents to perform these long-horizon tasks? To take a step towards building and evaluating research agents on such open-ended decision-making tasks, we focus on the problem of machine learning engineering: given a task description and a dataset, build a high-performing model. In this paper, we propose MLAgentBench, a suite of ML tasks for benchmarking AI research agents. Agents can perform actions like reading/writing files, executing code, and inspecting outputs. With these actions, agents could run experiments, analyze the results, and modify the code of entire machine learning pipelines, such as data processing, architecture, training processes, etc. The benchmark then automatically evaluates the agent's performance objectively over various metrics related to performance and efficiency. We also design an LLM-
    
[^51]: 基于聚类的图像-文本图匹配来弥合领域差距

    Bridging the Domain Gap by Clustering-based Image-Text Graph Matching. (arXiv:2310.02692v1 [cs.CV])

    [http://arxiv.org/abs/2310.02692](http://arxiv.org/abs/2310.02692)

    通过基于聚类的图像-文本图匹配来弥合领域差距，学习领域不变特征以实现在未见过领域上的良好泛化能力，实验结果显示在公共数据集上达到最先进性能。

    

    学习领域不变表示对于训练可以很好地推广到未见过目标任务领域的模型非常重要。文本描述本身包含概念的语义结构，这样的辅助语义线索可以用作领域概括问题的有效枢纽嵌入。我们使用多模态图像和文本融合的图表示来获得在局部图像和文本描述符之间考虑内在语义结构的领域不变枢纽嵌入。具体来说，我们通过(i)用图表示图像和文本描述，以及(ii)将基于图像节点特征的聚类和匹配应用到文本图中，来学习领域不变特征。我们使用大规模公共数据集（如CUB-DG和DomainBed）进行实验，并在这些数据集上达到与或优于现有最先进模型的性能。我们的代码将在出版后公开提供。

    Learning domain-invariant representations is important to train a model that can generalize well to unseen target task domains. Text descriptions inherently contain semantic structures of concepts and such auxiliary semantic cues can be used as effective pivot embedding for domain generalization problems. Here, we use multimodal graph representations, fusing images and text, to get domain-invariant pivot embeddings by considering the inherent semantic structure between local images and text descriptors. Specifically, we aim to learn domain-invariant features by (i) representing the image and text descriptions with graphs, and by (ii) clustering and matching the graph-based image node features into textual graphs simultaneously. We experiment with large-scale public datasets, such as CUB-DG and DomainBed, and our model achieves matched or better state-of-the-art performance on these datasets. Our code will be publicly available upon publication.
    
[^52]: 关于图神经网络中表达位置编码的稳定性

    On the Stability of Expressive Positional Encodings for Graph Neural Networks. (arXiv:2310.02579v1 [cs.LG])

    [http://arxiv.org/abs/2310.02579](http://arxiv.org/abs/2310.02579)

    本研究针对图神经网络中使用拉普拉斯特征向量作为位置编码面临的非唯一性和不稳定性问题，提出了稳定且表达丰富的位置编码方法（SPE），该方法通过利用特征值对特征空间进行"软分割"，在未见过的图结构上表现出良好的泛化能力。

    

    设计有效的图位置编码对构建强大的图转换器和增强消息传递图神经网络非常关键。尽管广泛使用，使用拉普拉斯特征向量作为位置编码面临两个根本性挑战：（1）\emph{非唯一性}：同一拉普拉斯矩阵存在许多不同的特征分解，以及（2）\emph{不稳定性}：对拉普拉斯矩阵的微小扰动可能导致完全不同的特征空间，从而导致位置编码的不可预测性变化。尽管有很多尝试解决非唯一性的方法，但大多数方法忽视了稳定性，导致在未见过的图结构上表现不佳。我们发现，不稳定性的原因是特征空间的"硬分割"。因此，我们引入了稳定且表达丰富的位置编码（SPE），这是一种用于处理特征向量的架构，利用特征值将特征空间进行"软分割"。SPE是首个（1）可证明稳定的架构，以及（2）普适地提升图结构泛化性能的架构。

    Designing effective positional encodings for graphs is key to building powerful graph transformers and enhancing message-passing graph neural networks. Although widespread, using Laplacian eigenvectors as positional encodings faces two fundamental challenges: (1) \emph{Non-uniqueness}: there are many different eigendecompositions of the same Laplacian, and (2) \emph{Instability}: small perturbations to the Laplacian could result in completely different eigenspaces, leading to unpredictable changes in positional encoding.  Despite many attempts to address non-uniqueness, most methods overlook stability, leading to poor generalization on unseen graph structures. We identify the cause of instability to be a "hard partition" of eigenspaces. Hence, we introduce Stable and Expressive Positional Encodings (SPE), an architecture for processing eigenvectors that uses eigenvalues to "softly partition" eigenspaces. SPE is the first architecture that is (1) provably stable, and (2) universally exp
    
[^53]: 通过交流使LLM代理适应环境的方法

    Adapting LLM Agents Through Communication. (arXiv:2310.01444v1 [cs.CL])

    [http://arxiv.org/abs/2310.01444](http://arxiv.org/abs/2310.01444)

    这项研究提出了一种名为学习通信（LTC）的训练方法，使用该方法可使LLM代理通过与环境和其他代理的交互不断改进，以适应新任务，而无需过多人类监督。

    

    最近大语言模型(LLM)的进展显示出了人类化代理的潜力。为了帮助这些代理在没有广泛人类监督的情况下适应新任务，我们提出了学习通信（LTC）范式，这是一种新颖的训练方法，使LLM代理能够通过与环境和其他代理的交互不断改进。通过迭代探索和PPO训练，LTC使代理能够将短期经验融入长期记忆。为了优化特定任务的代理交互，我们引入了三种结构化的通信模式：独白，对话，

    Recent advancements in large language models (LLMs) have shown potential for human-like agents. To help these agents adapt to new tasks without extensive human supervision, we propose the Learning through Communication (LTC) paradigm, a novel training approach enabling LLM agents to improve continuously through interactions with their environments and other agents. Recent advancements in large language models (LLMs) have shown potential for human-like agents. To help these agents adapt to new tasks without extensive human supervision, we propose the Learning through Communication (LTC) paradigm, a novel training approach enabling LLM agents to improve continuously through interactions with their environments and other agents. Through iterative exploration and PPO training, LTC empowers the agent to assimilate short-term experiences into long-term memory. To optimize agent interactions for task-specific learning, we introduce three structured communication patterns: Monologue, Dialogue,
    
[^54]: BooookScore: LLM时代中对书籍长度摘要的系统探索

    BooookScore: A systematic exploration of book-length summarization in the era of LLMs. (arXiv:2310.00785v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.00785](http://arxiv.org/abs/2310.00785)

    本文对LLM模型进行了系统探索，以解决对超过上下文窗口大小的书籍进行摘要的问题，并通过两种提示工作流实施了基于LLM的书籍长度摘要器的连贯性研究。通过对100本书的GPT-4生成摘要的人工注释，发现了八种常见的连贯性错误。

    

    对于超过大型语言模型（LLMs）上下文窗口大小的书籍长度文档（>100K标记）进行摘要需要首先将输入文档分成较小的块，然后提示LLM合并、更新和压缩块级摘要。尽管这个任务的复杂性和重要性，但由于评估的困难，它尚未得到有意义的研究：现有的书籍长度摘要数据集（例如BookSum）在大多数公共LLM的预训练数据中，而现有的评估方法难以捕捉现代LLM摘要器的错误。在本文中，我们首次研究通过两种提示工作流实施的基于LLM的书籍长度摘要器的连贯性：（1）分层合并块级摘要，（2）逐步更新一个运行摘要。我们对100本最近出版的书籍的GPT-4生成摘要获得了1193个细粒度的人工注释，并确定了LLMs产生的八种常见的连贯性错误。

    Summarizing book-length documents (>100K tokens) that exceed the context window size of large language models (LLMs) requires first breaking the input document into smaller chunks and then prompting an LLM to merge, update, and compress chunk-level summaries. Despite the complexity and importance of this task, it has yet to be meaningfully studied due to the challenges of evaluation: existing book-length summarization datasets (e.g., BookSum) are in the pretraining data of most public LLMs, and existing evaluation methods struggle to capture errors made by modern LLM summarizers. In this paper, we present the first study of the coherence of LLM-based book-length summarizers implemented via two prompting workflows: (1) hierarchically merging chunk-level summaries, and (2) incrementally updating a running summary. We obtain 1193 fine-grained human annotations on GPT-4 generated summaries of 100 recently-published books and identify eight common types of coherence errors made by LLMs. Bec
    
[^55]: SyncDreamer: 从单视图图像生成多视角一致性图像

    SyncDreamer: Generating Multiview-consistent Images from a Single-view Image. (arXiv:2309.03453v1 [cs.CV])

    [http://arxiv.org/abs/2309.03453](http://arxiv.org/abs/2309.03453)

    本文提出了一种名为SyncDreamer的新型扩散模型，可以从单视图图像生成多视角一致性图像。通过同步所有生成图像的中间状态，并利用3D感知特征注意机制，SyncDreamer能够实现在不同视角上生成高度一致的图像，为各种3D生成任务提供了有力的支持。

    

    本文提出了一种名为SyncDreamer的新型扩散模型，可以从单视图图像生成多视角一致性图像。通过使用预训练的大规模2D扩散模型，最近的Zero123工作展示了从单视图物体图像生成合理的新视角的能力。然而，生成的图像在几何和颜色上的一致性仍然是一个挑战。为了解决这个问题，我们提出了一种同步的多视角扩散模型，它模拟了多视角图像的联合概率分布，可以通过单个反向过程生成多视角一致性图像。SyncDreamer通过3D感知特征注意机制，在反向过程的每个步骤中同步所有生成图像的中间状态，从而相关联不同视角上的相应特征。实验表明，SyncDreamer能够在不同视角之间生成高度一致的图像，因此非常适用于各种3D生成任务。

    In this paper, we present a novel diffusion model called that generates multiview-consistent images from a single-view image. Using pretrained large-scale 2D diffusion models, recent work Zero123 demonstrates the ability to generate plausible novel views from a single-view image of an object. However, maintaining consistency in geometry and colors for the generated images remains a challenge. To address this issue, we propose a synchronized multiview diffusion model that models the joint probability distribution of multiview images, enabling the generation of multiview-consistent images in a single reverse process. SyncDreamer synchronizes the intermediate states of all the generated images at every step of the reverse process through a 3D-aware feature attention mechanism that correlates the corresponding features across different views. Experiments show that SyncDreamer generates images with high consistency across different views, thus making it well-suited for various 3D generation
    
[^56]: 大型语言模型作为优化器

    Large Language Models as Optimizers. (arXiv:2309.03409v1 [cs.LG])

    [http://arxiv.org/abs/2309.03409](http://arxiv.org/abs/2309.03409)

    本论文提出了一种简单有效的方法，利用大型语言模型(LLMs)作为优化器，通过自然语言描述优化任务。经过实验证明，该方法在线性回归和旅行推销员问题上表现出色，并且优化的最佳提示超过了人为设计的提示。

    

    优化是无处不在的。虽然基于导数的算法在各种问题上是强大的工具，但是没有梯度对许多实际应用提出了挑战。在这项工作中，我们提出了一种简单有效的方法，利用大型语言模型(LLMs)作为优化器，其中优化任务以自然语言形式描述。在每一次优化步骤中，LLM从包含先前生成的解与其值的提示中生成新的解，然后对新的解进行评估并添加到提示中，用于下一次优化步骤。我们首先展示了OPRO在线性回归和旅行推销员问题上的应用，然后转向提示优化，目标是找到能最大化任务准确性的指令。通过使用各种LLM，我们证明了OPRO优化的最佳提示在GSM8K上击败了人为设计的提示高达8%，在Big-Bench Hard任务上击败了人为设计的提示高达50%。

    Optimization is ubiquitous. While derivative-based algorithms have been powerful tools for various problems, the absence of gradient imposes challenges on many real-world applications. In this work, we propose Optimization by PROmpting (OPRO), a simple and effective approach to leverage large language models (LLMs) as optimizers, where the optimization task is described in natural language. In each optimization step, the LLM generates new solutions from the prompt that contains previously generated solutions with their values, then the new solutions are evaluated and added to the prompt for the next optimization step. We first showcase OPRO on linear regression and traveling salesman problems, then move on to prompt optimization where the goal is to find instructions that maximize the task accuracy. With a variety of LLMs, we demonstrate that the best prompts optimized by OPRO outperform human-designed prompts by up to 8% on GSM8K, and by up to 50% on Big-Bench Hard tasks.
    
[^57]: 高质量图像去雾模型的扩散方法

    High-quality Image Dehazing with Diffusion Model. (arXiv:2308.11949v1 [cs.CV])

    [http://arxiv.org/abs/2308.11949](http://arxiv.org/abs/2308.11949)

    本研究提出了一种基于DDPM和物理感知的图像去雾框架DehazeDDPM，能够在复杂的雾霾场景中实现高质量的图像去雾。

    

    在密集雾霾场景下，图像去雾面临着很大挑战，因为在雾霾图像中很少保留原始信息。尽管之前的方法取得了显著的进展，但在密集雾霾场景中仍然存在内容和颜色的信息损失。最近出现的去噪扩散概率模型（DDPM）展示了强大的生成能力，显示出解决这个问题的潜力。然而，DDPM没有考虑到去雾任务的物理特性，限制了其信息补全能力。在这项工作中，我们提出了一种基于DDPM和物理感知的图像去雾框架DehazeDDPM，适用于复杂的雾霾场景。具体而言，DehazeDDPM分为两个阶段。前一阶段用大气散射模型（ASM）对去雾任务进行物理建模，将分布拉近清晰数据，并赋予DehazeDDPM具有雾霾感知能力。后一阶段利用DDPM的强大生成能力来补偿雾霾引起的信息损失。

    Image dehazing is quite challenging in dense-haze scenarios, where quite less original information remains in the hazy image. Though previous methods have made marvelous progress, they still suffer from information loss in content and color in dense-haze scenarios. The recently emerged Denoising Diffusion Probabilistic Model (DDPM) exhibits strong generation ability, showing potential for solving this problem. However, DDPM fails to consider the physics property of dehazing task, limiting its information completion capacity. In this work, we propose DehazeDDPM: A DDPM-based and physics-aware image dehazing framework that applies to complex hazy scenarios. Specifically, DehazeDDPM works in two stages. The former stage physically models the dehazing task with the Atmospheric Scattering Model (ASM), pulling the distribution closer to the clear data and endowing DehazeDDPM with fog-aware ability. The latter stage exploits the strong generation ability of DDPM to compensate for the haze-ind
    
[^58]: 大型变压器是更好的脑电图学习器

    Large Transformers are Better EEG Learners. (arXiv:2308.11654v1 [eess.SP])

    [http://arxiv.org/abs/2308.11654](http://arxiv.org/abs/2308.11654)

    本研究表明从图像和文本预训练的大型变压器模型可以直接应用于脑电图预测任务的微调，通过设计AdaCE模块在多个EEG基于预测任务上取得了最新的性能。

    

    预训练的大型变压器模型在自然语言处理和计算机视觉领域取得了显著的性能。由于可用的标记脑电图（EEG）数据的规模远远低于文本和图像数据，因此很难将从EEG预训练的变压器模型开发到像GPT-4 100T这样的规模，从而完全发挥该架构的潜力。在本文中，我们展示了从图像和文本预训练的变压器模型可以直接用于EEG基于预测任务的微调。我们设计了AdaCE，即将EEG数据转换为图像和文本形式的插拔式适配器，用于微调预训练的视觉和语言变压器。提出的AdaCE模块在微调预训练的变压器模型时非常有效，同时在多种基于EEG的预测任务上实现了最新的性能。例如，预训练的Swin-Transformer上的AdaCE达到了99.6％的精度，绝对改善了9.2％。

    Pre-trained large transformer models have achieved remarkable performance in the fields of natural language processing and computer vision. Since the magnitude of available labeled electroencephalogram (EEG) data is much lower than that of text and image data, it is difficult for transformer models pre-trained from EEG to be developed as large as GPT-4 100T to fully unleash the potential of this architecture. In this paper, we show that transformers pre-trained from images as well as text can be directly fine-tuned for EEG-based prediction tasks. We design AdaCE, plug-and-play Adapters for Converting EEG data into image as well as text forms, to fine-tune pre-trained vision and language transformers. The proposed AdaCE module is highly effective for fine-tuning pre-trained transformers while achieving state-of-the-art performance on diverse EEG-based prediction tasks. For example, AdaCE on the pre-trained Swin-Transformer achieves 99.6%, an absolute improvement of 9.2%, on the EEG-deco
    
[^59]: DiagGPT:一种基于LLM的任务导向对话的聊天机器人

    DiagGPT: An LLM-based Chatbot with Automatic Topic Management for Task-Oriented Dialogue. (arXiv:2308.08043v1 [cs.CL])

    [http://arxiv.org/abs/2308.08043](http://arxiv.org/abs/2308.08043)

    DiagGPT将大型语言模型(LLMs)扩展到任务导向的对话场景，提供了在复杂诊断场景中主动提问和引导用户完成任务的能力。

    

    大型语言模型(LLMs)如ChatGPT正变得越来越复杂，展示出与人类相似的能力。这些AI模型在日常生活中辅助人类完成各种任务方面发挥着重要作用。AI作为聊天代理人的重要应用是回答人类在各个领域的问题。目前的LLMs在回答一般问题方面已经显示出熟练的能力。然而，在复杂的诊断场景(如法律或医疗咨询)中，基本的问答对话往往表现不佳。这些场景通常需要任务导向对话(TOD)，其中AI聊天代理需要主动提问并引导用户完成特定任务。以前的微调模型在TOD方面表现不佳，而当前的LLMs并未固有这种能力。在本文中，我们介绍了一种名为DiagGPT (Diagnosis GPT)的创新方法，它将LLMs推广到TOD场景中。

    Large Language Models (LLMs), such as ChatGPT, are becoming increasingly sophisticated, demonstrating capabilities that closely resemble those of humans. These AI models are playing an essential role in assisting humans with a wide array of tasks in daily life. A significant application of AI is its use as a chat agent, responding to human inquiries across various domains. Current LLMs have shown proficiency in answering general questions. However, basic question-answering dialogue often falls short in complex diagnostic scenarios, such as legal or medical consultations. These scenarios typically necessitate Task-Oriented Dialogue (TOD), wherein an AI chat agent needs to proactively pose questions and guide users towards specific task completion. Previous fine-tuning models have underperformed in TOD, and current LLMs do not inherently possess this capability. In this paper, we introduce DiagGPT (Dialogue in Diagnosis GPT), an innovative method that extends LLMs to TOD scenarios. Our e
    
[^60]: 一体化音频：利用WavLM预训练模型进行基于语音驱动的手势合成

    Audio is all in one: speech-driven gesture synthetics using WavLM pre-trained model. (arXiv:2308.05995v1 [cs.SD])

    [http://arxiv.org/abs/2308.05995](http://arxiv.org/abs/2308.05995)

    本文介绍了一种利用WavLM预训练模型的基于语音驱动的手势合成方法，实现只使用原始语音音频生成个性化全身手势，消除了复杂的多模态处理和手动注释的需求。

    

    在虚拟人创作领域，生成与语音配套的手势是一个正在兴起的研究方向。先前的研究通过以声学和语义信息作为输入，采用分类方法来识别人物的ID和情感，以驱动与语音配套的手势生成。然而，这项工作仍然面临着重大挑战。这些挑战不仅涉及手势、语音声学和语义之间错综复杂的相互作用，还包括与个性、情感和其他不明确但重要的因素相关的复杂性。本文介绍了“diffmotion-v2”，这是一种基于语音条件扩散和基于非自回归Transformer的生成模型，采用WavLM预训练模型。它可以仅使用原始语音音频生成个性化的全身手势，消除了复杂的多模态处理和手动注释的需求。

    The generation of co-speech gestures for digital humans is an emerging area in the field of virtual human creation. Prior research has made progress by using acoustic and semantic information as input and adopting classify method to identify the person's ID and emotion for driving co-speech gesture generation. However, this endeavour still faces significant challenges. These challenges go beyond the intricate interplay between co-speech gestures, speech acoustic, and semantics; they also encompass the complexities associated with personality, emotion, and other obscure but important factors. This paper introduces "diffmotion-v2," a speech-conditional diffusion-based and non-autoregressive transformer-based generative model with WavLM pre-trained model. It can produce individual and stylized full-body co-speech gestures only using raw speech audio, eliminating the need for complex multimodal processing and manually annotated. Firstly, considering that speech audio not only contains acou
    
[^61]: FLASK: 基于对齐技能集的细粒度语言模型评估

    FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets. (arXiv:2307.10928v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.10928](http://arxiv.org/abs/2307.10928)

    FLASK是一种基于对齐技能集的细粒度语言模型评估协议，通过将粗级评分分解为每个指令的技能集级评分，实现了对模型性能的全面视角和提高评估的可靠性。

    

    由于指令需要与人类的价值观进行对齐，并且所需的技能集根据指令而异，因此对大型语言模型（LLMs）进行评估具有挑战性。然而，先前的研究主要集中在粗粒度评估（即基于整体偏好的评估），这限制了可解释性，因为它未考虑需要实例级技能组合的用户指令的特性。在本文中，我们介绍了FLASK（基于对齐技能集的细粒度语言模型评估），这是一种细粒度评估协议，用于人类和模型的评估，它将粗级评分分解为每个指令的技能集级评分。通过实验证明，评估的细粒度对于获得对模型性能的全面视角和提高评估的可靠性至关重要。利用FLASK，我们比较了多个开源和专有LLMs，并观察到高度相关性。

    Evaluation of Large Language Models (LLMs) is challenging because instruction-following necessitates alignment with human values and the required set of skills varies depending on the instruction. However, previous studies have mainly focused on coarse-grained evaluation (i.e. overall preference-based evaluation), which limits interpretability since it does not consider the nature of user instructions that require instance-wise skill composition. In this paper, we introduce FLASK (Fine-grained Language Model Evaluation based on Alignment Skill Sets), a fine-grained evaluation protocol for both human-based and model-based evaluation which decomposes coarse-level scoring to a skill set-level scoring for each instruction. We experimentally observe that the fine-graininess of evaluation is crucial for attaining a holistic view of model performance and increasing the reliability of the evaluation. Using FLASK, we compare multiple open-source and proprietary LLMs and observe a high correlati
    
[^62]: 探索具有描述逻辑特征的命题动态逻辑的非正则扩展

    Exploring Non-Regular Extensions of Propositional Dynamic Logic with Description-Logics Features. (arXiv:2307.09913v1 [cs.LO])

    [http://arxiv.org/abs/2307.09913](http://arxiv.org/abs/2307.09913)

    研究了非正则路径表达式对于扩展ALC描述逻辑中可满足性检查和查询的可决定性的影响，并提供了一系列不可决定性结果。

    

    我们研究了非正则路径表达式对于扩展ALC描述逻辑中可满足性检查和查询的可决定性的影响。我们主要关注的对象是ALCreg和ALCvpl，分别是使用正则和可见推下语言的路径表达式的扩展。第一个ALCreg是Fischer和Ladner所熟知的命题动态逻辑的一种变种。第二个ALCvpl是由Loding和Serre在2007年引入和研究的。ALCvpl逻辑广义上推广了许多已知的可决定性非正则扩展的ALCreg。我们提供了一系列不可决定性结果。首先，我们展示了在添加看似无害的Self操作符后，对于ALCvpl中的概念可满足性问题的可决定性丧失。其次，我们建立了对于在ALCvpl中添加个体词的概念可满足性问题的不可决定性。有趣的是，我们的不可决定性证明只依赖于一个单一的非正则（可见推下）语言。

    We investigate the impact of non-regular path expressions on the decidability of satisfiability checking and querying in description logics extending ALC. Our primary objects of interest are ALCreg and ALCvpl, the extensions of with path expressions employing, respectively, regular and visibly-pushdown languages. The first one, ALCreg, is a notational variant of the well-known Propositional Dynamic Logic of Fischer and Ladner. The second one, ALCvpl, was introduced and investigated by Loding and Serre in 2007. The logic ALCvpl generalises many known decidable non-regular extensions of ALCreg.  We provide a series of undecidability results. First, we show that decidability of the concept satisfiability problem for ALCvpl is lost upon adding the seemingly innocent Self operator. Second, we establish undecidability for the concept satisfiability problem for ALCvpl extended with nominals. Interestingly, our undecidability proof relies only on one single non-regular (visibly-pushdown) langu
    
[^63]: 探索对比演示和显著性图在上下文学习中的作用

    Towards Understanding In-Context Learning with Contrastive Demonstrations and Saliency Maps. (arXiv:2307.05052v1 [cs.CL])

    [http://arxiv.org/abs/2307.05052](http://arxiv.org/abs/2307.05052)

    本研究探索了对比演示和显著性图在上下文学习中的作用，并发现改变标签对显著性有显著影响，尤其对于更大的语言模型更为明显。在情感分析任务中，将表达情感的术语改为中性词并不像改变标签那样具有显著影响。另外，补充解释在提高上下文学习方面是有效的。

    

    本文研究了在大型语言模型的上下文学习(ICL)性能中，各种演示组件的作用。具体而言，我们探讨了标签、输入分布和补充解释等因素的影响，特别是在这些因素被修改或扰动时的影响。我们基于之前的工作，这些工作对于这些元素如何影响ICL给出了不一致的结果。为了探究这些问题，我们采用了可解释的自然语言处理(XNLP)方法，并利用对比演示的显著性图进行定性和定量分析。我们的研究结果表明，改变标签对显著性有显著影响，尤其对于更大的语言模型更为明显。我们对输入分布进行了粒度级别的分析，发现在情感分析任务中，将表达情感的术语改为中性词并不像改变标签那样具有显著影响。最后，我们发现补充解释在提高ICL方面的效果是存在的。

    We investigate the role of various demonstration components in the in-context learning (ICL) performance of large language models (LLMs). Specifically, we explore the impacts of ground-truth labels, input distribution, and complementary explanations, particularly when these are altered or perturbed. We build on previous work, which offers mixed findings on how these elements influence ICL. To probe these questions, we employ explainable NLP (XNLP) methods and utilize saliency maps of contrastive demonstrations for both qualitative and quantitative analysis. Our findings reveal that flipping ground-truth labels significantly affects the saliency, though it's more noticeable in larger LLMs. Our analysis of the input distribution at a granular level reveals that changing sentiment-indicative terms in a sentiment analysis task to neutral ones does not have as substantial an impact as altering ground-truth labels. Finally, we find that the effectiveness of complementary explanations in boos
    
[^64]: 大语言模型时代的推荐系统 (LLMs)

    Recommender Systems in the Era of Large Language Models (LLMs). (arXiv:2307.02046v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2307.02046](http://arxiv.org/abs/2307.02046)

    大型语言模型在推荐系统中的应用已经带来了显著的改进，克服了传统DNN方法的限制，并提供了强大的语言理解、生成、推理和泛化能力。

    

    随着电子商务和网络应用的繁荣，推荐系统（RecSys）已经成为我们日常生活中重要的组成部分，为用户提供个性化建议以满足其喜好。尽管深度神经网络（DNN）通过模拟用户-物品交互和整合文本侧信息在提升推荐系统方面取得了重要进展，但是DNN方法仍然存在一些限制，例如理解用户兴趣、捕捉文本侧信息的困难，以及在不同推荐场景中泛化和推理能力的不足等。与此同时，大型语言模型（LLMs）的出现（例如ChatGPT和GPT4）在自然语言处理（NLP）和人工智能（AI）领域引起了革命，因为它们在语言理解和生成的基本职责上有着卓越的能力，同时具有令人印象深刻的泛化和推理能力。

    With the prosperity of e-commerce and web applications, Recommender Systems (RecSys) have become an important component of our daily life, providing personalized suggestions that cater to user preferences. While Deep Neural Networks (DNNs) have made significant advancements in enhancing recommender systems by modeling user-item interactions and incorporating textual side information, DNN-based methods still face limitations, such as difficulties in understanding users' interests and capturing textual side information, inabilities in generalizing to various recommendation scenarios and reasoning on their predictions, etc. Meanwhile, the emergence of Large Language Models (LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural Language Processing (NLP) and Artificial Intelligence (AI), due to their remarkable abilities in fundamental responsibilities of language understanding and generation, as well as impressive generalization and reasoning capabilities. As a result, 
    
[^65]: 一种可解释的增量随机权重神经网络及其应用的构造算法

    An Interpretable Constructive Algorithm for Incremental Random Weight Neural Networks and Its Application. (arXiv:2307.00185v1 [cs.LG])

    [http://arxiv.org/abs/2307.00185](http://arxiv.org/abs/2307.00185)

    本文提出了一种可解释的增量随机权重神经网络的构造算法，通过几何信息约束和节点池策略解决了难以解释隐藏参数与残差误差之间关系的问题。这种算法在大规模数据建模任务中表现出了良好的性能。

    

    增量随机权重神经网络(IRWNNs)由于易于实现和快速学习而受到关注。然而，IRWNNs的一个显著缺点是难以解释隐藏参数（节点）与残差误差（模型性能）之间的关系。为了解决这个问题，本文提出了一个具有几何信息约束的可解释的构造算法(ICA)。首先，基于隐藏参数与残差误差之间的几何关系，提出了一个可解释的几何信息约束来随机分配隐藏参数。同时，采用节点池策略获取更有利于收敛的隐藏参数。此外，证明了ICA的通用逼近性质。最后，提出了ICA的轻量级版本用于大规模数据建模任务。在六个基准数据集上的实验结果表明了该算法的有效性。

    Incremental random weight neural networks (IRWNNs) have gained attention in view of its easy implementation and fast learning. However, a significant drawback of IRWNNs is that the elationship between the hidden parameters (node)and the residual error (model performance) is difficult to be interpreted. To address the above issue, this article proposes an interpretable constructive algorithm (ICA) with geometric information constraint. First, based on the geometric relationship between the hidden parameters and the residual error, an interpretable geometric information constraint is proposed to randomly assign the hidden parameters. Meanwhile, a node pool strategy is employed to obtain hidden parameters that is more conducive to convergence from hidden parameters satisfying the proposed constraint. Furthermore, the universal approximation property of the ICA is proved. Finally, a lightweight version of ICA is presented for large-scale data modeling tasks. Experimental results on six ben
    
[^66]: 通过转化特定注释者和特定实例的转移矩阵从众包中学习

    Transferring Annotator- and Instance-dependent Transition Matrix for Learning from Crowds. (arXiv:2306.03116v1 [cs.HC])

    [http://arxiv.org/abs/2306.03116](http://arxiv.org/abs/2306.03116)

    本文提出了一个高效的方法来估算特定注释者和特定实例的转移矩阵以及真实标签比例，解决了从众包中学习的标签噪声问题，并在实验中证明了方法的优越性。

    

    本文描述了从众包服务中获取训练数据的注释方法。每个注释者都完成自己的小部分注释，不同注释者的标注错误往往不同。通过标签噪声的转移矩阵来建模噪声产生过程是解决标签噪声的一种有效工具。在实际众包模型中，转移矩阵既由注释者依赖，也由实例依赖。然而，由于注释者和实例依赖的转移矩阵(AIDTM)具有高复杂度，而实际注释往往涉及注释稀疏性，这使得建立AIDTM非常具有挑战性。既要保持建模的广泛性，又能更真实地解决问题，本文提出了一种高效的算法，可以同时估算AIDTM和真实标签比例。我们还提供了理论分析，证明了我们的算法的收敛性。在合成数据集和真实数据集上的实验结果表明，我们的算法优于基准方法。

    Learning from crowds describes that the annotations of training data are obtained with crowd-sourcing services. Multiple annotators each complete their own small part of the annotations, where labeling mistakes that depend on annotators occur frequently. Modeling the label-noise generation process by the noise transition matrix is a power tool to tackle the label noise. In real-world crowd-sourcing scenarios, noise transition matrices are both annotator- and instance-dependent. However, due to the high complexity of annotator- and instance-dependent transition matrices (AIDTM), \textit{annotation sparsity}, which means each annotator only labels a little part of instances, makes modeling AIDTM very challenging. Prior works simplify the problem by assuming the transition matrix is instance-independent or using simple parametric way, while lose modeling generality. Motivated by this, we target a more realistic problem, estimating general AIDTM in practice. Without losing modeling general
    
[^67]: 基于异构知识的增强模块化强化学习

    Augmented Modular Reinforcement Learning based on Heterogeneous Knowledge. (arXiv:2306.01158v1 [cs.LG])

    [http://arxiv.org/abs/2306.01158](http://arxiv.org/abs/2306.01158)

    该论文提出了增强模块化强化学习（AMRL），使用仲裁器来选择异构模块，并无缝地整合不同类型的知识。该方法能够减缓强化学习中的一些低效问题，有望在深度强化学习领域得到应用。

    

    为了减缓强化学习中的一些低效问题，学者们提出了模块化方法，将不同的决策制定策略组合起来以衍生出可以执行多种任务的代理。这些体系结构的基础模块通常是可重复使用的，也允许“即插即用”的集成。然而，这些解决方案仍然缺乏处理和整合多种类型信息（知识）的能力，例如规则，子目标和技能。我们提出了增强模块化强化学习（AMRL）来解决这些限制。这种新的框架使用仲裁器来选择异构模块，并无缝地整合不同类型的知识。此外，我们引入了一种选择机制的变体，即增强记忆的仲裁器，它增加了利用时间信息的能力。我们在已有的环境中评估了所提出的机制，同时也在新环境中进行了基准测试，结果表明其在深度强化学习领域具有良好的应用前景。

    In order to mitigate some of the inefficiencies of Reinforcement Learning (RL), modular approaches composing different decision-making policies to derive agents capable of performing a variety of tasks have been proposed. The modules at the basis of these architectures are generally reusable, also allowing for "plug-and-play" integration. However, such solutions still lack the ability to process and integrate multiple types of information (knowledge), such as rules, sub-goals, and skills. We propose Augmented Modular Reinforcement Learning (AMRL) to address these limitations. This new framework uses an arbitrator to select heterogeneous modules and seamlessly incorporate different types of knowledge. Additionally, we introduce a variation of the selection mechanism, namely the Memory-Augmented Arbitrator, which adds the capability of exploiting temporal information. We evaluate the proposed mechanisms on established as well as new environments and benchmark them against prominent deep 
    
[^68]: 递归的诅咒：使用生成数据进行训练会让模型忘记

    The Curse of Recursion: Training on Generated Data Makes Models Forget. (arXiv:2305.17493v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.17493](http://arxiv.org/abs/2305.17493)

    使用生成数据进行训练会导致模型不可逆的缺陷并且使得原始内容分布的尾部消失，这种效应称为模型折叠。我们证明了这种现象在所有学习生成模型中都存在，必须认真对待。

    

    稳定扩散技术革命性地改变了从描述性文本中生成图像的方法。GPT-2、GPT-3(.5)和GPT-4在各种语言任务中表现惊人。ChatGPT将这些语言模型引入了大众视野。大语言模型(LLMs)已经不可避免并将彻底改变在线文本和图像的整个生态系统。本文考虑了未来可能发生的事情。当LLMs占据了在线语言的大部分时，GPT-{n}会发生什么？我们发现，在训练中使用模型生成的内容会导致所得模型中不可逆缺陷，原始内容分布的尾部消失。我们将这种效应称为模型折叠，并显示它可以发生在变分自编码器、高斯混合模型和LLMs中。我们建立了现象背后的理论直觉，并展示了这种现象在所有学习生成模型中的普遍性。我们证明，如果我们要在实践中使用生成数据进行训练，就必须认真对待这一问题。

    Stable Diffusion revolutionised image creation from descriptive text. GPT-2, GPT-3(.5) and GPT-4 demonstrated astonishing performance across a variety of language tasks. ChatGPT introduced such language models to the general public. It is now clear that large language models (LLMs) are here to stay, and will bring about drastic change in the whole ecosystem of online text and images. In this paper we consider what the future might hold. What will happen to GPT-{n} once LLMs contribute much of the language found online? We find that use of model-generated content in training causes irreversible defects in the resulting models, where tails of the original content distribution disappear. We refer to this effect as Model Collapse and show that it can occur in Variational Autoencoders, Gaussian Mixture Models and LLMs. We build theoretical intuition behind the phenomenon and portray its ubiquity amongst all learned generative models. We demonstrate that it has to be taken seriously if we ar
    
[^69]: 负反馈训练：提高NVCiM DNN加速器鲁棒性的新概念

    Negative Feedback Training: A Novel Concept to Improve Robustness of NVCiM DNN Accelerators. (arXiv:2305.14561v1 [cs.LG])

    [http://arxiv.org/abs/2305.14561](http://arxiv.org/abs/2305.14561)

    本文介绍了一种新的训练方法，使用负反馈机制来增强DNN模型的鲁棒性，特别是在存在设备变异的情况下。

    

    利用非挥发性存储器(NVM)实现的内存计算(CiM)为加速深度神经网络(DNNs)提供了一种高效的方法。 CiM加速器通过在同一电路板结构中存储网络权重和执行矩阵操作，以最小的面积需求和异常的能效，提供DNN推理加速。然而，NVM设备的随机性和内在变化往往导致性能降低，如与预期结果相比减少分类精度。尽管提出了几种方法来减轻设备变异并增强鲁棒性，但大多数方法都依赖于整体调节并缺乏对训练过程的限制。受到负反馈机制的启发，我们引入了一种新的训练方法，使用多出口机制作为负反馈，在设备变异的情况下增强DNN模型的性能。

    Compute-in-Memory (CiM) utilizing non-volatile memory (NVM) devices presents a highly promising and efficient approach for accelerating deep neural networks (DNNs). By concurrently storing network weights and performing matrix operations within the same crossbar structure, CiM accelerators offer DNN inference acceleration with minimal area requirements and exceptional energy efficiency. However, the stochasticity and intrinsic variations of NVM devices often lead to performance degradation, such as reduced classification accuracy, compared to expected outcomes. Although several methods have been proposed to mitigate device variation and enhance robustness, most of them rely on overall modulation and lack constraints on the training process. Drawing inspiration from the negative feedback mechanism, we introduce a novel training approach that uses a multi-exit mechanism as negative feedback to enhance the performance of DNN models in the presence of device variation. Our negative feedbac
    
[^70]: 退火自蒸馏校正改进了对抗训练

    Annealing Self-Distillation Rectification Improves Adversarial Training. (arXiv:2305.12118v1 [cs.LG])

    [http://arxiv.org/abs/2305.12118](http://arxiv.org/abs/2305.12118)

    本研究提出了退火自蒸馏校正(ADR)方法，其能生成软标签用作更好的指导机制，准确反映在对抗训练中攻击下的分布变化，提高模型的鲁棒性，并实现了平滑的插入性整合到其他对抗性训练技术中。

    

    标准的对抗训练中，模型被优化以适应可接受的对抗扰动预算内的一热标签。然而，忽略由扰动带来的基础分布变化，导致了强健的过拟合问题。为了解决这个问题，增强对抗性鲁棒性，我们分析了强健模型的特征，并确定强健模型倾向于生成更平滑和更良好校准的输出。基于这一观测结果，我们提出了一种简单而有效的方法——退火自蒸馏校正(ADR)，该方法生成软标签作为更好的指导机制，能准确反映在对抗训练中攻击下的分布变化。通过使用ADR，我们可以获得修正的分布，显著改善模型的鲁棒性，而不需要预训练模型或额外的计算。此外，我们的方法通过替换卷积层以实现平滑的插入性整合到其他对抗性训练技术中。

    In standard adversarial training, models are optimized to fit one-hot labels within allowable adversarial perturbation budgets. However, the ignorance of underlying distribution shifts brought by perturbations causes the problem of robust overfitting. To address this issue and enhance adversarial robustness, we analyze the characteristics of robust models and identify that robust models tend to produce smoother and well-calibrated outputs. Based on the observation, we propose a simple yet effective method, Annealing Self-Distillation Rectification (ADR), which generates soft labels as a better guidance mechanism that accurately reflects the distribution shift under attack during adversarial training. By utilizing ADR, we can obtain rectified distributions that significantly improve model robustness without the need for pre-trained models or extensive extra computation. Moreover, our method facilitates seamless plug-and-play integration with other adversarial training techniques by repl
    
[^71]: 视觉调整

    Visual Tuning. (arXiv:2305.06061v1 [cs.CV])

    [http://arxiv.org/abs/2305.06061](http://arxiv.org/abs/2305.06061)

    本文综述了视觉调整的发展与现状，将近期的视觉调整技术分为五类，包括提示调整、适配器调整、参数翻译、紧凑调整和模块调整，并提出了未来研究方向。

    

    对视觉模型进行微调已被广泛证明在许多下游视觉任务中具有有前途的表现。随着预训练视觉基础模型的惊人发展，视觉调整跳出了标准的模式操作，即微调整个预训练模型或仅微调完全连接层。相反，近期的进展可以通过更新更少的参数实现比全面微调整个预训练参数更优异的表现，使边缘设备和下游应用程序可以重复使用部署在云端的日益庞大的基础模型。为了帮助研究人员全面了解视觉调整的全貌和未来方向，本综述描绘了大量的近期研究作品，提供了现有工作和模型系统和全面的概述。具体而言，它提供了视觉调整的详细背景，并将最近的视觉调整技术分为五组：提示调整、适配器调整、参数翻译、紧凑调整和模块调整。本文还强调了当前视觉调整技术的限制和挑战，并提出了几个未来研究方向。

    Fine-tuning visual models has been widely shown promising performance on many downstream visual tasks. With the surprising development of pre-trained visual foundation models, visual tuning jumped out of the standard modus operandi that fine-tunes the whole pre-trained model or just the fully connected layer. Instead, recent advances can achieve superior performance than full-tuning the whole pre-trained parameters by updating far fewer parameters, enabling edge devices and downstream applications to reuse the increasingly large foundation models deployed on the cloud. With the aim of helping researchers get the full picture and future directions of visual tuning, this survey characterizes a large and thoughtful selection of recent works, providing a systematic and comprehensive overview of existing work and models. Specifically, it provides a detailed background of visual tuning and categorizes recent visual tuning techniques into five groups: prompt tuning, adapter tuning, parameter 
    
[^72]: 通过双重对抗去偏置实现的越界证据感知假新闻检测

    Out-of-distribution Evidence-aware Fake News Detection via Dual Adversarial Debiasing. (arXiv:2304.12888v1 [cs.CL])

    [http://arxiv.org/abs/2304.12888](http://arxiv.org/abs/2304.12888)

    该论文提出了一种新颖的双重对抗学习方法，通过在模型中加入去偏置鉴别器，旨在训练模型更好地进行越界证据感知假新闻检测，有效减轻新闻和证据内容偏差的影响。

    

    越界证据感知假新闻检测旨在对新闻和基于新闻内容检索的证据进行推理，以查找统一性或不一致性。然而，我们发现，证据感知检测模型会受到偏差的影响，即新闻/证据内容和真实/假新闻标签之间的虚假相关性，并且很难推广到越界情况。为了应对这个问题，我们提出了一种新颖的双重对抗学习方法。我们在DAL中加入了新闻方面和证据方面去偏置鉴别器，它们的目标都是真假新闻标签。然后，DAL会逆向优化新闻方面和证据方面去偏置鉴别器，以减轻新闻和证据内容偏差的影响。同时，DAL还优化主要的假新闻预测器，让新闻-证据交互模块能够被学习。这个过程能够帮助我们教新闻检测模型更好地进行新闻证据推理，并将检测假新闻的负面影响降至最低。

    Evidence-aware fake news detection aims to conduct reasoning between news and evidence, which is retrieved based on news content, to find uniformity or inconsistency. However, we find evidence-aware detection models suffer from biases, i.e., spurious correlations between news/evidence contents and true/fake news labels, and are hard to be generalized to Out-Of-Distribution (OOD) situations. To deal with this, we propose a novel Dual Adversarial Learning (DAL) approach. We incorporate news-aspect and evidence-aspect debiasing discriminators, whose targets are both true/fake news labels, in DAL. Then, DAL reversely optimizes news-aspect and evidence-aspect debiasing discriminators to mitigate the impact of news and evidence content biases. At the same time, DAL also optimizes the main fake news predictor, so that the news-evidence interaction module can be learned. This process allows us to teach evidence-aware fake news detection models to better conduct news-evidence reasoning, and min
    
[^73]: 建模生物通路和组织学之间的稠密多模态交互以预测存活率

    Modeling Dense Multimodal Interactions Between Biological Pathways and Histology for Survival Prediction. (arXiv:2304.06819v1 [cs.CV])

    [http://arxiv.org/abs/2304.06819](http://arxiv.org/abs/2304.06819)

    本论文提出了一种解决整合全切片图像和批量转录组学预测患者生存率的多模态任务的方案，旨在解决标记化转录组学和捕获这两种模态之间的交互的问题。

    

    整合全切片图像（WSIs）和批量转录组学（bulk transcriptomics）以预测患者生存率可以提高我们对患者预后的理解。然而，由于这些数据的不同性质，这个多模态任务特别具有挑战性：WSIs代表肿瘤的高维空间描述，而批量转录组学则代表该肿瘤内的基因表达水平的全局描述。在这种情况下，我们的工作旨在解决两个关键问题：（1）如何以语义上有意义和可解释的方式对转录组学进行标记化？（2）如何捕捉这两种模态之间的密集多模态交互？具体来说，我们提出从转录组学中学习生物通路标记，以编码特定的细胞功能。结合编码WSI中不同形态模式的组织学块标记，我们认为它们构成了下游可解释性分析的适当推理单元。我们提出融合...

    Integrating whole-slide images (WSIs) and bulk transcriptomics for predicting patient survival can improve our understanding of patient prognosis. However, this multimodal task is particularly challenging due to the different nature of these data: WSIs represent a very high-dimensional spatial description of a tumor, while bulk transcriptomics represent a global description of gene expression levels within that tumor. In this context, our work aims to address two key challenges: (1) how can we tokenize transcriptomics in a semantically meaningful and interpretable way?, and (2) how can we capture dense multimodal interactions between these two modalities? Specifically, we propose to learn biological pathway tokens from transcriptomics that can encode specific cellular functions. Together with histology patch tokens that encode the different morphological patterns in the WSI, we argue that they form appropriate reasoning units for downstream interpretability analyses. We propose fusing 
    
[^74]: 带有大型图像文本（LIT）模型的CT多任务学习

    CT Multi-Task Learning with a Large Image-Text (LIT) Model. (arXiv:2304.02649v1 [eess.IV])

    [http://arxiv.org/abs/2304.02649](http://arxiv.org/abs/2304.02649)

    本研究通过将大型图像模型和大语言模型结合起来，建立了一个用于肺癌诊断的多任务CT大型图像文本（LIT）模型，能很好地执行肺部CT分割等多个医学任务。

    

    大语言模型（LLM）不仅能够支持多种语言任务，而且还可以作为不同领域的通用接口。迄今为止，还没有证明如何将LLM在计算机视觉领域的成功有效地转化为涉及高维和多模态医学图像的医学成像领域。在本文中，我们报告了一项可行性研究，通过组合LLM和大型图像模型（LIM），建立多任务CT大型图像文本（LIT）模型，用于肺癌诊断。具体而言，LLM和LIM用作编码器，根据特定任务的文本提示来感知多模态信息，从而协同作用于多源信息和任务特定和患者特定的先验，以优化诊断性能。我们的LIT模型和相关技术的关键组成部分将重点评估3D肺部CT分析。我们的初步结果表明，LIT模型能够很好地执行多项医学任务，包括肺分割。

    Large language models (LLM) not only empower multiple language tasks but also serve as a general interface across different spaces. Up to now, it has not been demonstrated yet how to effectively translate the successes of LLMs in the computer vision field to the medical imaging field which involves high-dimensional and multi-modal medical images. In this paper, we report a feasibility study of building a multi-task CT large image-text (LIT) model for lung cancer diagnosis by combining an LLM and a large image model (LIM). Specifically, the LLM and LIM are used as encoders to perceive multi-modal information under task-specific text prompts, which synergizes multi-source information and task-specific and patient-specific priors for optimized diagnostic performance. The key components of our LIT model and associated techniques are evaluated with an emphasis on 3D lung CT analysis. Our initial results show that the LIT model performs multiple medical tasks well, including lung segmentatio
    
[^75]: 长尾分类的曲率平衡特征流形学习

    Curvature-Balanced Feature Manifold Learning for Long-Tailed Classification. (arXiv:2303.12307v1 [cs.CV])

    [http://arxiv.org/abs/2303.12307](http://arxiv.org/abs/2303.12307)

    本文提出了一种曲率平衡特征流形学习的方法，探究了感知流形的几何特性对分类难度的影响，发现曲率不平衡会导致模型不公平。

    

    为了应对长尾分类的挑战，研究人员已经提出了几种方法来减少模型偏差，其中大多数假设样本较少的类是弱类。然而，最近的研究表明，尾部类别并不总是难以学习的，而在样本平衡的数据集上观察到了模型偏差，这表明存在其他影响模型偏差的因素。在本文中，我们系统地提出了一系列用于深度神经网络中感知流形的几何度量，并探讨了感知流形的几何特性对分类难度和学习如何塑造感知流形的几何特性的影响。一个意外的发现是：类别准确度和感知流形的分离程度之间的相关性在训练过程中逐渐减小，而与曲率的负相关性逐渐增加，这表明曲率不平衡导致模型不公平。

    To address the challenges of long-tailed classification, researchers have proposed several approaches to reduce model bias, most of which assume that classes with few samples are weak classes. However, recent studies have shown that tail classes are not always hard to learn, and model bias has been observed on sample-balanced datasets, suggesting the existence of other factors that affect model bias. In this work, we systematically propose a series of geometric measurements for perceptual manifolds in deep neural networks, and then explore the effect of the geometric characteristics of perceptual manifolds on classification difficulty and how learning shapes the geometric characteristics of perceptual manifolds. An unanticipated finding is that the correlation between the class accuracy and the separation degree of perceptual manifolds gradually decreases during training, while the negative correlation with the curvature gradually increases, implying that curvature imbalance leads to m
    
[^76]: 适应性负证据深度学习用于开放式半监督学习

    Adaptive Negative Evidential Deep Learning for Open-set Semi-supervised Learning. (arXiv:2303.12091v1 [cs.LG])

    [http://arxiv.org/abs/2303.12091](http://arxiv.org/abs/2303.12091)

    本文提出了ANEDL框架，应用证据深度学习量化不同类型的不确定性，并设计了新颖的适应性负优化策略，有效应对在未标记数据集中包含内部值和异常值的开放式半监督学习。

    

    半监督学习方法假设标记数据、未标记数据和测试数据来自同一分布。开放式半监督学习考虑到一个更实际的情况，即未标记数据和测试数据包含标记数据中未观察到的新类别（异常值）。本文提出了一种新颖的框架——适应性负证据深度学习（ANEDL），以应对二元分类器的不足之处，如缺乏可扩展性和无法区分不同类型的不确定性。具体而言，我们首先介绍证据深度学习（EDL）作为一种异常检测器来量化不同类型的不确定性，并设计不同的不确定性度量方法进行自我训练和推理。此外，我们提出了一种新颖的适应性负优化策略，使EDL更加适合包含内部值和异常值的未标记数据集。通过在基准数据集上的实验验证，我们的ANEDL显著优于现有的开放式半监督学习方法。

    Semi-supervised learning (SSL) methods assume that labeled data, unlabeled data and test data are from the same distribution. Open-set semi-supervised learning (Open-set SSL) considers a more practical scenario, where unlabeled data and test data contain new categories (outliers) not observed in labeled data (inliers). Most previous works focused on outlier detection via binary classifiers, which suffer from insufficient scalability and inability to distinguish different types of uncertainty. In this paper, we propose a novel framework, Adaptive Negative Evidential Deep Learning (ANEDL) to tackle these limitations. Concretely, we first introduce evidential deep learning (EDL) as an outlier detector to quantify different types of uncertainty, and design different uncertainty metrics for self-training and inference. Furthermore, we propose a novel adaptive negative optimization strategy, making EDL more tailored to the unlabeled dataset containing both inliers and outliers. As demonstrat
    
[^77]: 走向AI-enabled连接产业: AGV通信和传感器测量数据集

    Towards an AI-enabled Connected Industry: AGV Communication and Sensor Measurement Datasets. (arXiv:2301.03364v3 [cs.NI] UPDATED)

    [http://arxiv.org/abs/2301.03364](http://arxiv.org/abs/2301.03364)

    本文介绍了两个无线测量活动所提供的数据集，并将其与机器学习结合起来用于指纹识别、视线检测、服务质量预测或链路选择等任务。

    

    本文介绍了两个工业测试平台上的无线测量活动: 工业车辆间通信(iV2V)和工业车辆到基础设施加传感器(iV2I+)。提供了关于这两个捕获数据集的详细信息。iV2V涵盖了自动引导车(AGVs)之间的侧向链路通信场景，而iV2I+则是在工业设置中进行的，其中自主清洁机器人连接到私有蜂窝网络。不同通信技术的组合，连同共同的测量方法，提供了机器学习(ML)可以利用的洞察力，用于指纹识别、视线检测、服务质量预测或链路选择等任务。此外，数据集已标记和预过滤，以便快速启动和应用。对于两个数据集，还详细介绍了相应的测试平台和测量情况。

    This paper presents two wireless measurement campaigns in industrial testbeds: industrial Vehicle-to-vehicle (iV2V) and industrial Vehicle-to-infrastructure plus Sensor (iV2I+). Detailed information about the two captured datasets is provided as well. iV2V covers sidelink communication scenarios between Automated Guided Vehicles (AGVs), while iV2I+ is conducted at an industrial setting where an autonomous cleaning robot is connected to a private cellular network. The combination of different communication technologies, together with a common measurement methodology, provides insights that can be exploited by Machine Learning (ML) for tasks such as fingerprinting, line-of-sight detection, prediction of quality of service or link selection. Moreover, the datasets are labelled and pre-filtered for fast on-boarding and applicability. The corresponding testbeds and measurements are also presented in detail for both datasets.
    
[^78]: CALIME: 因果感知的局部可解释性模型-无关解释

    CALIME: Causality-Aware Local Interpretable Model-Agnostic Explanations. (arXiv:2212.05256v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.05256](http://arxiv.org/abs/2212.05256)

    本文提出CALIME方法，将因果知识融入可解释性人工智能方法中，以解决特征独立性的缺陷，并取得了优于初始方法的黑盒模型模拟保真度和解释稳定性的表现。

    

    可解释性人工智能方法的一个重要缺点是假设特征独立性。本文着眼于将因果知识融入可解释性人工智能方法中，以增加信任并帮助用户评估解释的质量。我们提出一种新颖的扩展方法，明确地在围绕输入实例生成的数据中编码因果关系，以解释模型。大量实验证明，我们的方法在模仿黑盒子的保真度和解释的稳定性方面均比初始方法表现优异。

    A significant drawback of eXplainable Artificial Intelligence (XAI) approaches is the assumption of feature independence. This paper focuses on integrating causal knowledge in XAI methods to increase trust and help users assess explanations' quality. We propose a novel extension to a widely used local and model-agnostic explainer that explicitly encodes causal relationships in the data generated around the input instance to explain. Extensive experiments show that our method achieves superior performance comparing the initial one for both the fidelity in mimicking the black-box and the stability of the explanations.
    
[^79]: ComCLIP: 无需训练的组合图像与文本匹配

    ComCLIP: Training-Free Compositional Image and Text Matching. (arXiv:2211.13854v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.13854](http://arxiv.org/abs/2211.13854)

    本文提出了一个无需训练的组合图像与文本匹配模型 ComCLIP，通过将输入图像分解为主体、对象和动作子图像，并结合视觉编码器和文本编码器进行逐步匹配，以解决组合图像与文本匹配中的伪匹配问题。

    

    对比语言-图像预训练（CLIP）已经展示了在图像与文本匹配方面的很好的零样本性能。然而，将 CLIP 这样的视觉-语言预训练模型适应于更具挑战性的组合图像与文本匹配仍然具有挑战性，这需要模型理解组合词概念和视觉组件。为了实现更好的零样本图像与文本匹配中的组合泛化能力，本文从因果关系的角度研究了该问题：单个实体的错误语义本质上是导致匹配失败的混淆因素。因此，我们提出了一种新颖的“无需训练”的组合 CLIP 模型（ComCLIP）。ComCLIP将输入图像分解为主体、对象和动作子图像，并组合 CLIP 的视觉编码器和文本编码器，以在组合文本嵌入和子图像嵌入之上进行逐步匹配。通过这种方式，ComCLIP 可以减轻伪匹配问题。

    Contrastive Language-Image Pretraining (CLIP) has demonstrated great zero-shot performance for matching images and text. However, it is still challenging to adapt vision-lanaguage pretrained models like CLIP to compositional image and text matching -- a more challenging image and text matching task requiring the model understanding of compositional word concepts and visual components. Towards better compositional generalization in zero-shot image and text matching, in this paper, we study the problem from a causal perspective: the erroneous semantics of individual entities are essentially confounders that cause the matching failure. Therefore, we propose a novel \textbf{\textit{training-free}} compositional CLIP model (ComCLIP). ComCLIP disentangles input images into subjects, objects, and action sub-images and composes CLIP's vision encoder and text encoder to perform evolving matching over compositional text embedding and sub-image embeddings. In this way, ComCLIP can mitigate spurio
    

