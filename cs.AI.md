# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Doduo: Learning Dense Visual Correspondence from Unsupervised Semantic-Aware Flow.](http://arxiv.org/abs/2309.15110) | Doduo是一个从野外图像和视频中学习通用密集视觉对应关系的无监督方法。它使用流场扭曲来获得训练监督信号，并结合语义先验进行自监督流训练，可产生鲁棒准确的密集对应关系。在测试中，Doduo在点级对应估计上表现优于现有的自监督对应关系学习基线。 |
| [^2] | [Attention Satisfies: A Constraint-Satisfaction Lens on Factual Errors of Language Models.](http://arxiv.org/abs/2309.15098) | 本研究使用约束满足问题框架研究了语言模型的内部行为，发现模型对约束标记的关注程度与事实准确性强正相关。提出了一种方法可以预测约束满足和事实错误，并允许早期错误识别，进一步提高了大型语言模型的可靠性。 |
| [^3] | [VideoDirectorGPT: Consistent Multi-scene Video Generation via LLM-Guided Planning.](http://arxiv.org/abs/2309.15091) | 本文提出了VideoDirectorGPT，一种利用LLMs的知识实现一致多场景视频生成的框架，通过视频内容规划和基于内容的视频生成来生成时间上一致的长视频。 |
| [^4] | [Natural Language based Context Modeling and Reasoning with LLMs: A Tutorial.](http://arxiv.org/abs/2309.15074) | 本教程介绍了基于大型语言模型的自然语言上下文建模和推理，通过与LLMs交互，使用自然语言进行上下文建模和推理。 |
| [^5] | [When Prolog meets generative models: a new approach for managing knowledge and planning in robotic applications.](http://arxiv.org/abs/2309.15049) | 本文提出了一种基于Prolog语言的机器人知识管理系统，通过利用大型语言模型自动填充知识库，实现了多机器人系统的连续并行计划生成以及计划到可执行形式的自动转化。 |
| [^6] | [Class Incremental Learning via Likelihood Ratio Based Task Prediction.](http://arxiv.org/abs/2309.15048) | 该论文提出了一种基于似然比的任务预测的类增量学习方法，利用离群检测器进行任务标识预测，解决了无任务标识符的测试样本的任务预测问题。 |
| [^7] | [Combining Survival Analysis and Machine Learning for Mass Cancer Risk Prediction using EHR data.](http://arxiv.org/abs/2309.15039) | 该论文介绍了一种利用 EHR 数据进行大规模肿瘤风险预测的新方法，其创新之处在于只需利用历史的医疗服务代码和诊断信息来实现最小化的数据需求，通过将存活分析和机器学习相结合，可以在大规模应用中实现对患者癌症风险的个性化评估。 |
| [^8] | [Making PPO even better: Value-Guided Monte-Carlo Tree Search decoding.](http://arxiv.org/abs/2309.15028) | 本文提出了一种基于值导向的Monte-Carlo Tree Search解码算法PPO-MCTS，通过在PPO之上集成MCTS，解决了训练和测试之间部分输出评分机制的不匹配问题，实验证明该算法可以显著提升性能。 |
| [^9] | [Large Language Model Alignment: A Survey.](http://arxiv.org/abs/2309.15025) | 这项调查对大规模语言模型对齐的方法进行了广泛探讨，并提出了内部对齐和外部对齐的分类。同时讨论了模型的可解释性和潜在的对抗攻击漏洞。考虑到模型可能产生的不准确和误导性文本，对齐技术显得至关重要。 |
| [^10] | [Unidirectional brain-computer interface: Artificial neural network encoding natural images to fMRI response in the visual cortex.](http://arxiv.org/abs/2309.15018) | 这项研究提出了一个名为"VISION"的人工神经网络模型，通过模仿人脑的工作方式，成功预测了人类脑对自然图像的fMRI响应。与现有技术相比，该模型的准确性提高了45%。通过进一步探索训练过的网络，发现了不同视觉区域的表征偏见，并提出了与皮层功能相关的可实验检验的假设和解释性度量标准。 |
| [^11] | [Automating question generation from educational text.](http://arxiv.org/abs/2309.15004) | 本文设计并评估了一个用于学校形成性和总结性评估的自动化问题生成工具，通过对教师的调查，证明了自动化生成问题的需求，并提出了一个基于Transformer的语言模型的模块化框架，用于从文本内容中自动生成多项选择题。 |
| [^12] | [Measurement Models For Sailboats Price vs. Features And Regional Areas.](http://arxiv.org/abs/2309.14994) | 这项研究调查了帆船技术规格和价格之间的关系以及区域定价的影响。通过应用多个机器学习模型，我们发现单体船通常比双体船更实惠，并且长度、宽度、排水量和帆面积等特定规格与较高的价格直接相关。此外，我们还发现美国是平均帆船价格最高的国家，而国内生产总值与帆船价格没有直接相关关系。 |
| [^13] | [Detecting Sexual Content at the Sentence Level in First Millennium Latin Texts.](http://arxiv.org/abs/2309.14974) | 该研究提出使用深度学习方法在句子级别进行语义分类，以加速人文学科和语言学领域中语料库建设的过程。经过评估，该方法在检测性内容方面表现出高精度和真阳性率，并探索了不同的输入嵌入层对模型性能的影响。 |
| [^14] | [Improving Unsupervised Visual Program Inference with Code Rewriting Families.](http://arxiv.org/abs/2309.14972) | 本论文介绍了一种改进无监督视觉程序推理的方法，通过代码重写来提高从视觉数据中推断程序的性能。使用稀疏间歇性代码重写注入(SIRI)和重写家族，能够实现更好的重构和更快的收敛速率。同时，在测试时使用重写家族还可以改进SIRI预测的输出结果。 |
| [^15] | [Recurrent Hypernetworks are Surprisingly Strong in Meta-RL.](http://arxiv.org/abs/2309.14970) | 递归超网络和循环神经网络在元强化学习中的端到端学习表现出惊人的强大性能，相比于现有专门方法更为简单但效果更好。 |
| [^16] | [Interactively Learning Social Media Representations Improves News Source Factuality Detection.](http://arxiv.org/abs/2309.14966) | 本文提出了一种交互式的方法来改善社交媒体表示质量，通过人类互动帮助自动化系统检测新闻来源的真实性，并在实验证明即使进行了少量的人类互动，也能提高性能。 |
| [^17] | [Addressing preferred orientation in single-particle cryo-EM through AI-generated auxiliary particles.](http://arxiv.org/abs/2309.14954) | 介绍了一种基于人工智能的方法cryoPROS，通过生成辅助粒子来解决单颗粒冷冻电镜中的优选取向问题，可有效地恢复非倾斜数据的高分辨率结构，并改进了膜蛋白的分辨率。 |
| [^18] | [Multi-Source Domain Adaptation for Object Detection with Prototype-based Mean-teacher.](http://arxiv.org/abs/2309.14950) | 该论文提出了一种名为Prototype-based Mean-Teacher (PMT)的新型多源域自适应目标检测方法，通过使用类原型而不是域特定子网络来保留域特定信息，提高了准确性和鲁棒性。 |
| [^19] | [A Democratic Platform for Engaging with Disabled Community in Generative AI Development.](http://arxiv.org/abs/2309.14921) | 这个论文提出了一个平台，允许残障社群参与生成式人工智能的建设过程，以了解残障社群使用生成式人工智能时输出中存在的偏见因素。 |
| [^20] | [Label Deconvolution for Node Representation Learning on Large-scale Attributed Graphs against Learning Bias.](http://arxiv.org/abs/2309.14907) | 本文提出了一种标签解卷积技术(LD)，通过对图神经网络(GNNs)的逆映射进行高效的近似，来解决在大规模属性图上进行节点表示学习时的学习偏差挑战。 |
| [^21] | [Explainable Sustainability for AI in the Arts.](http://arxiv.org/abs/2309.14877) | 这篇论文介绍了为AI艺术开发环境可持续性反思系统的两个实证研究，并引入了可解释的AI艺术中的可持续性。 |
| [^22] | [Navigating Text-To-Image Customization:From LyCORIS Fine-Tuning to Model Evaluation.](http://arxiv.org/abs/2309.14859) | 本文介绍了LyCORIS，一个开源库，提供了多种稳定扩散模型的微调方法，并提出了一个系统评估的全面框架。 |
| [^23] | [Supersonic: Learning to Generate Source Code Optimisations in C/C++.](http://arxiv.org/abs/2309.14846) | Supersonic 是一个神经方法，用于在C/C++中进行源代码优化。与GPT-3.5-Turbo和GPT-4相比，它在代码优化任务上表现更好，并且改变的程度更小。 |
| [^24] | [Revisiting Softmax Masking for Stability in Continual Learning.](http://arxiv.org/abs/2309.14808) | 本文重新审视了用于连续学习中的Softmax掩码的影响，并提出了一种利用其置信度保持效果的方法，通过增加稳定性同时保持准确性。 |
| [^25] | [Evaluating Soccer Match Prediction Models: A Deep Learning Approach and Feature Optimization for Gradient-Boosted Trees.](http://arxiv.org/abs/2309.14807) | 本研究评估了足球比赛预测模型，并采用深度学习方法和梯度增强树特征优化。研究发现，在这个特定的任务中，深度学习模型经常被忽视。 |
| [^26] | [Fine-tuning and aligning question answering models for complex information extraction tasks.](http://arxiv.org/abs/2309.14805) | 本文提出了一种使用抽取型QA模型进行信息提取的方法，以解决大型语言模型在文档分析中的应用限制。实验结果表明，细调德语QA模型可以提高针对定制化信息提取任务的性能。 |
| [^27] | [Forgetting-aware Linear Bias for Attentive Knowledge Tracing.](http://arxiv.org/abs/2309.14796) | 本文提出了FoLiBi方法，通过考虑学习者的遗忘行为作为线性偏差的形式，结合现有的注重型知识追踪（KT）模型，解决了现有模型忽略学习者遗忘行为的问题，实验结果显示与多个KT模型结合使用可以显著提高效果 |
| [^28] | [Semantic Map Learning of Traffic Light to Lane Assignment based on Motion Data.](http://arxiv.org/abs/2309.14793) | 本论文介绍了一种基于运动数据的交通灯-车道分配语义地图学习的方法，通过统计方法自动推导交通灯到车道的分配，并且提出了安全考虑和数据集转换方法来提高效果和扩展性。 |
| [^29] | [Exploring Small Language Models with Prompt-Learning Paradigm for Efficient Domain-Specific Text Classification.](http://arxiv.org/abs/2309.14779) | 本研究探索了将小型语言模型（SLMs）与提示学习范式结合应用于领域特定文本分类的潜力，并在零售业的客户和代理人交互中进行了评估。结果显示，在有限的标记数据下，SLM T5-base能够实现约75%的准确率，展现了SLMs与提示学习的潜力。 |
| [^30] | [Boosting In-Context Learning with Factual Knowledge.](http://arxiv.org/abs/2309.14771) | 本文研究了使用事实知识提升上下文学习的效果，并提出了一个新的知识上下文调优框架来改善学习性能。 |
| [^31] | [Program Repair with Minimal Edits Using CodeT5.](http://arxiv.org/abs/2309.14760) | 本文提出了一种使用CodeT5进行最小编辑的程序修复的方法，该方法通过在错误和正确程序的代码对上对预训练的CodeT5进行微调，实验结果表明其效果良好。 |
| [^32] | [Age Minimization in Massive IoT via UAV Swarm: A Multi-agent Reinforcement Learning Approach.](http://arxiv.org/abs/2309.14757) | 本论文通过应用多智能体深度强化学习方法，利用无人机群从物联网设备收集实时信息，以实现大规模物联网中信息的年龄最小化。研究结果表明，合作和部分合作的多智能体深度强化学习方法能够优于传统的集中式深度强化学习方法，在大规模网络中具有更好的性能表现。 |
| [^33] | [Comparative Analysis of Artificial Intelligence for Indian Legal Question Answering (AILQA) Using Different Retrieval and QA Models.](http://arxiv.org/abs/2309.14735) | 本文对印度法律问答系统的人工智能模型进行比较分析，发现现有的AILQA系统能够自动解析用户的自然语言查询并生成高度准确的响应。 |
| [^34] | [Effective Multi-Agent Deep Reinforcement Learning Control with Relative Entropy Regularization.](http://arxiv.org/abs/2309.14727) | 本文提出了一种新的多智能体强化学习方法，通过相对熵正则化解决了多个智能体策略更新的不一致性问题，并证明在多智能体合作和竞争任务以及传统控制任务中表现出显著的学习能力和样本效率。 |
| [^35] | [PLMM: Personal Large Models on Mobile Devices.](http://arxiv.org/abs/2309.14726) | 本文提出了一种从传统大型语言模型中提取的个人大型模型，该模型更适应于本地用户的个人信息，并且能够保护用户的隐私。该模型分为个人级别、专家级别和传统级别，同时还需要小型化以适应个人计算机或移动设备，并实现实时响应以提供更好的用户体验。 |
| [^36] | [Optimizing delegation between human and AI collaborative agents.](http://arxiv.org/abs/2309.14718) | 该研究提出了一种优化人工智能和人类协作代理之间委派的方法，通过训练一个代理管理器根据任务绩效缺陷进行委派决策，并且可以处理不同环境表示下的团队操作。方法在实验中表现显著优于其他管理团队的方法。 |
| [^37] | [Are Human-generated Demonstrations Necessary for In-context Learning?.](http://arxiv.org/abs/2309.14681) | 本文研究了上下文学习中人工生成的演示是否有必要，并提出了一种新的自反思提示策略（SEC），通过这种策略，大型语言模型（LLMs）可以自行生成演示和最终输出，避免了手动生成过程的复杂性。 |
| [^38] | [XGV-BERT: Leveraging Contextualized Language Model and Graph Neural Network for Efficient Software Vulnerability Detection.](http://arxiv.org/abs/2309.14677) | XGV-BERT提出了一种结合了预训练的CodeBERT模型和图神经网络（GCN）的框架，用于高效的软件漏洞检测。研究结果表明，XGV-BERT相比其他方法显著提高了漏洞检测的准确性。 |
| [^39] | [Leveraging Herpangina Data to Enhance Hospital-level Prediction of Hand-Foot-and-Mouth Disease Admissions Using UPTST.](http://arxiv.org/abs/2309.14674) | 提出了一种新颖的基于Transformer的UPTST模型，利用腭咽口炎数据提升手足口病住院预测的准确性，且在医院级别的预测准确性上优于现有方法。 |
| [^40] | [Learning Emergent Behavior in Robot Swarms with NEAT.](http://arxiv.org/abs/2309.14663) | 本研究提出了一种用NEAT方法训练分布式机器人群体算法产生新颖行为的方法，并通过实验验证了其在不同任务上的有效性。 |
| [^41] | [Divide and Conquer in Video Anomaly Detection: A Comprehensive Review and New Approach.](http://arxiv.org/abs/2309.14622) | 本文综述了近期在视频异常检测领域中应用分而治之策略的方法，并提出了一种结合人体骨骼框架和视频数据分析技术的新方法，在ShanghaiTech数据集上取得了最先进的性能。 |
| [^42] | [Towards A Unified Utilitarian Ethics Framework for Healthcare Artificial Intelligence.](http://arxiv.org/abs/2309.14617) | 本研究通过主题分析识别了对医疗人工智能的效用表现最重要的伦理原则，并提出了一个新的基于功利主义的伦理框架，以解决伦理问题。 |
| [^43] | [Unsupervised Graph Deep Learning Reveals Emergent Flood Risk Profile of Urban Areas.](http://arxiv.org/abs/2309.14610) | 本研究基于无监督图深度学习模型提出了集成城市洪水风险评级模型，能够捕捉区域之间的空间依赖关系和洪水危险与城市要素之间的复杂相互作用，揭示了城市地区的突发洪水风险概况 |
| [^44] | [Efficient Post-training Quantization with FP8 Formats.](http://arxiv.org/abs/2309.14592) | 本研究研究了FP8格式在后训练量化中的优势，并开发了一个通用的量化工作流程。实验结果表明，FP8相对于INT8具有更好的工作负载覆盖率和模型准确性。 |
| [^45] | [Joint Communication and Computation Framework for Goal-Oriented Semantic Communication with Distortion Rate Resilience.](http://arxiv.org/abs/2309.14587) | 本论文提出了一个创新的联合通信和计算框架，利用率畸变理论来分析通信和语义压缩引起的畸变，从而评估其对目标导向语义通信中人工智能模型性能的影响，使目标导向语义通信问题成为可能。 |
| [^46] | [Speech Audio Synthesis from Tagged MRI and Non-Negative Matrix Factorization via Plastic Transformer.](http://arxiv.org/abs/2309.14586) | 这项研究利用标记的MRI测量舌头的功能单元，并开发了一个深度学习框架，将权重图转化为对应的音频波形，为研究语音产生过程提供了重要洞察。 |
| [^47] | [CWCL: Cross-Modal Transfer with Continuously Weighted Contrastive Loss.](http://arxiv.org/abs/2309.14580) | 本文提出了一种称为CWCL的损失函数，用于跨模态迁移中的对比训练。相比于传统的二进制对比训练，CWCL使用连续的相似性度量，可以更好地对齐实例的表示并提高跨模态的迁移性能。 |
| [^48] | [Integrating Higher-Order Dynamics and Roadway-Compliance into Constrained ILQR-based Trajectory Planning for Autonomous Vehicles.](http://arxiv.org/abs/2309.14566) | 本文将高阶动态和道路合规性整合到基于约束的ILQR轨迹规划中的自动驾驶车辆中，提供了更安全和舒适的路径规划。 |
| [^49] | [Generative Escher Meshes.](http://arxiv.org/abs/2309.14564) | 本文提出了一种全自动的生成方法，用于生成周期性的非正方形镶嵌图案，该方法通过优化几何和颜色来生成与所需对象形状和外观相似的瓷砖。 |
| [^50] | [Art or Artifice? Large Language Models and the False Promise of Creativity.](http://arxiv.org/abs/2309.14556) | 本研究通过提出创造性写作的托兰斯测验(TTCW)来评估大型语言模型(LLMs)的写作创造力。结果表明，LLM生成的故事在创意测试中通过的数量比专业作家写的故事少。此外，我们发现LLMs无法代替专家进行TTCW评估。 |
| [^51] | [Tactile Estimation of Extrinsic Contact Patch for Stable Placement.](http://arxiv.org/abs/2309.14552) | 本文介绍了一种利用触觉读数推测物体放置稳定性的方法，通过对接触区域的估计可以有效设计机器人的反馈技能，提高机器人的精细操控能力。 |
| [^52] | [Algorithmic Collusion or Competition: the Role of Platforms' Recommender Systems.](http://arxiv.org/abs/2309.14548) | 这项研究填补了关于电子商务平台推荐算法在算法勾结研究中被忽视的空白，并发现推荐算法可以决定基于AI的定价算法的竞争或勾结动态。 |
| [^53] | [Effect of roundabout design on the behavior of road users: A case study of roundabouts with application of Unsupervised Machine Learning.](http://arxiv.org/abs/2309.14540) | 本研究通过无监督机器学习应用的圆环案例研究，评估了圆环的性能，并研究了人类驾驶员与圆环的互动行为。研究发现，圆环可以显著降低转弯路口的速度，而其对速度的影响取决于道路使用者的行为评级。对于巴士、汽车和卡车驾驶员的行为进行了分类，并开发出一种预测圆环交叉口道路使用者行为的方法。安全主要归功于圆环的两个固有特征。 |
| [^54] | [Watch Your Language: Large Language Models and Content Moderation.](http://arxiv.org/abs/2309.14517) | 本研究评估了大型语言模型在内容审查任务上的表现，发现它们在基于规则的社区审查和有害内容检测方面具有很好的效果，在有害内容检测方面超过了现有的分类器。然而，最近模型规模的增加对有害内容检测的改进效果很小。 |
| [^55] | [Era Splitting.](http://arxiv.org/abs/2309.14496) | 本研究提出了两种新的分裂准则，使得决策树模型能够利用时代信息进行优化，从而将超分布泛化研究中的思想应用于决策树模型。 |
| [^56] | [When Automated Assessment Meets Automated Content Generation: Examining Text Quality in the Era of GPTs.](http://arxiv.org/abs/2309.14488) | 本研究通过对人类和GPT生成的文本进行实证评估，探讨了基于机器学习模型对文本质量评估的差异。结果表明，在评估GPT生成的文本时，预训练转换器模型的性能较差。 |
| [^57] | [Incorporating Ensemble and Transfer Learning For An End-To-End Auto-Colorized Image Detection Model.](http://arxiv.org/abs/2309.14478) | 本论文介绍了一种融合了迁移学习和集成学习的端到端自动上色图像检测模型，该模型通过减少训练时间和资源需求来区分自然彩色和计算机上色图像。 |
| [^58] | [Adapting Double Q-Learning for Continuous Reinforcement Learning.](http://arxiv.org/abs/2309.14471) | 本文介绍了一种新颖的校正偏差方法，通过使用两个组件的混合策略并由分开的网络进行评估，消除了离线策略强化学习算法中的过高估计偏差。在一小组MuJoCo环境中，该方法显示出了有希望接近SOTA的结果。 (校正偏差方法，混合策略，分开的网络评估) |
| [^59] | [DefGoalNet: Contextual Goal Learning from Demonstrations For Deformable Object Manipulation.](http://arxiv.org/abs/2309.14463) | 本文提出了一种名为DefGoalNet的神经网络，通过少量人类示范直接学习可变形物体的目标形状。实验证明，在各种机器人任务中取得了显著的进展。 |
| [^60] | [Online Active Learning For Sound Event Detection.](http://arxiv.org/abs/2309.14460) | 通过提出新的损失函数，该论文解决了在线主动学习在声音事件检测中面临的类别分布波动和数据漂移问题，并在实验中证明该方法能够将训练分类器所需的时间和工作量减少5倍。 |
| [^61] | [Self-Recovery Prompting: Promptable General Purpose Service Robot System with Foundation Models and Self-Recovery.](http://arxiv.org/abs/2309.14425) | 本文研究开发了一个通用服务机器人系统，该系统可以根据不同任务和环境的变化进行自适应，并通过自恢复机制解决信息不足、计划生成错误和执行失败等问题，实现了任务的成功完成。 |
| [^62] | [Joint Audio and Speech Understanding.](http://arxiv.org/abs/2309.14405) | LTU-AS是一个具有普适音频感知和高级推理能力的机器学习模型，可以同时识别和联合理解口语文本、语音声音学和非语音音频事件。 |
| [^63] | [Date-Driven Approach for Identifying State of Hemodialysis Fistulas: Entropy-Complexity and Formal Concept Analysis.](http://arxiv.org/abs/2309.14399) | 该论文提出了一种日期驱动的方法，通过熵-复杂度和形式概念分析，区分正常和混乱时间序列，用于识别血液透析物瘘的状态。 |
| [^64] | [Seeing and hearing what has not been said; A multimodal client behavior classifier in Motivational Interviewing with interpretable fusion.](http://arxiv.org/abs/2309.14398) | 本文提出了一个多模态分类器，在动机性访谈中准确区分了变化话语、持续话语和跟随/中立话语三种类别。该分类器利用文本、声调、面部表情和身体表现等多模态特征，并对AnnoMI数据集进行了注释和训练。研究还找到了决策过程中最重要的模态，提供了宝贵的洞察。 |
| [^65] | [Implicit Sensing in Traffic Optimization: Advanced Deep Reinforcement Learning Techniques.](http://arxiv.org/abs/2309.14395) | 本论文提出了一个基于深度强化学习的集成车辆跟随和变道决策控制系统，旨在解决高速公路上突发路障情况下智能车辆的行车问题。 |
| [^66] | [Multiple Noises in Diffusion Model for Semi-Supervised Multi-Domain Translation.](http://arxiv.org/abs/2309.14394) | 本文提出了一种多噪声扩散模型（MDD）用于半监督多域翻译，通过引入噪声级别来对缺失的域进行建模，实现了任意域之间的翻译而不需要训练单独的模型。 |
| [^67] | [LLMCarbon: Modeling the end-to-end Carbon Footprint of Large Language Models.](http://arxiv.org/abs/2309.14393) | 本研究提出了LLMCarbon，一个针对密集型和MoE LLMs设计的端到端碳足迹预测模型，解决了现有工具的限制，并显著提升了估计的准确性。 |
| [^68] | [An AI Chatbot for Explaining Deep Reinforcement Learning Decisions of Service-oriented Systems.](http://arxiv.org/abs/2309.14391) | 一个AI聊天机器人被介绍来解释深度强化学习在面向服务系统中的决策过程，通过提供自然语言解释来帮助用户理解和建立信任。 |
| [^69] | [Early Churn Prediction from Large Scale User-Product Interaction Time Series.](http://arxiv.org/abs/2309.14390) | 本文通过对历史数据进行全面研究，提出了一种预测用户早期流失的模型，以促进业务决策和行动。 |
| [^70] | [Analyzing the Efficacy of an LLM-Only Approach for Image-based Document Question Answering.](http://arxiv.org/abs/2309.14389) | 本论文分析了仅使用LLM方法在基于图像的文档问答中的有效性，探讨了在文档图像中序列化文本信息并直接使用指令调整的LLM的策略，以及对这种方法的可行性进行了全面的定量分析。 |
| [^71] | [Exploring Robot Morphology Spaces through Breadth-First Search and Random Query.](http://arxiv.org/abs/2309.14387) | 通过比较分析广度优先搜索（BFS）和随机查询在模块化机器人脑体共同进化中的影响，本研究发现这两种查询机制对机器人形态的进化和性能具有重要影响。 |
| [^72] | [Sampling - Variational Auto Encoder - Ensemble: In the Quest of Explainable Artificial Intelligence.](http://arxiv.org/abs/2309.14385) | 本研究通过采样-变分自编码器（VAE）-集成异常检测（SVEAD）框架的实证评估，在可解释人工智能（XAI）领域做出了贡献。研究发现，集成堆叠、VAE和SHAP的结合不仅可以提高模型性能，还提供了一个易于解释的框架。 |
| [^73] | [Towards using Cough for Respiratory Disease Diagnosis by leveraging Artificial Intelligence: A Survey.](http://arxiv.org/abs/2309.14383) | 使用人工智能利用咳嗽诊断呼吸道疾病已经成为一个有希望的趋势，通过研究咳嗽特征进行深度学习算法的发展可以可靠准确地检测特定呼吸系统疾病的发作。 |
| [^74] | [Agree To Disagree.](http://arxiv.org/abs/2309.14382) | "同意不同意"论文提出了一种基于机器学习的方法，旨在自动解析和总结使用户便于理解的关键信息，以帮助用户在承诺协议之前考虑重要细节。 |
| [^75] | [Survey of Social Bias in Vision-Language Models.](http://arxiv.org/abs/2309.14381) | 社交偏见在视觉-语言模型中的调查，旨在为研究人员提供对潜在社会偏见的理解，以解决资源分配不均和不公平代表等问题。 |
| [^76] | [Machine-assisted mixed methods: augmenting humanities and social sciences with artificial intelligence.](http://arxiv.org/abs/2309.14379) | 本研究提出了一种机器辅助的混合方法框架，利用大规模语言模型在人文社科领域的数据分析中的应用潜力，展示了16个案例研究，并涵盖了多种任务，包括语言分析、文本挖掘、社交网络推断等。 |
| [^77] | [A Text Classification-Based Approach for Evaluating and Enhancing the Machine Interpretability of Building Codes.](http://arxiv.org/abs/2309.14374) | 该研究提出了一种基于文本分类的方法，自动评估和增强建筑法规的机器可解释性。研究考虑了条款和文档层面的机器可解释性，通过引入几个类别进行分类并开发了一个数据集进行模型训练，并开发了一个高效的文本分类模型。 |
| [^78] | [Human Transcription Quality Improvement.](http://arxiv.org/abs/2309.14372) | 本文提出了一种可靠的方法来收集高质量的语音转录数据，通过在标注阶段进行置信度估计的重新处理和在标注后阶段进行自动词错误修正，成功降低了转录词误率（WER），并发现了转录错误对ASR模型性能的强相关性。 |
| [^79] | [A Unitary Weights Based One-Iteration Quantum Perceptron Algorithm for Non-Ideal Training Sets.](http://arxiv.org/abs/2309.14366) | 提出了一种基于单位权重的高效量子感知器算法，能够解决非理想训练集问题并实现一次迭代学习。算法通过计算训练集中总权重矩阵的奇异值分解来使权重矩阵成为单位阵，并能够精确实现任意量子门。与其他量子感知器算法相比，该算法具有更好的适用性、准确性和可用性。同时，该算法的适用性得到了进一步验证，演示了由多个基本量子门构成的量子复合门。 |
| [^80] | [An In-depth Survey of Large Language Model-based Artificial Intelligence Agents.](http://arxiv.org/abs/2309.14365) | 本文研究了基于大型语言模型的AI代理与传统AI代理之间的核心差异和特点，并引入了一种创新的记忆分类方案，提供了全新的设计视角。 |
| [^81] | [Diversifying Question Generation over Knowledge Base via External Natural Questions.](http://arxiv.org/abs/2309.14362) | 通过引入新的多样性评估指标，我们提出了一种通过外部自然问题在知识库上进行多样化问题生成的方法。同时，我们设计了一个双模型框架来解决如何增强多样化问题生成的挑战。 |
| [^82] | [Optimizing Chance-Constrained Submodular Problems with Variable Uncertainties.](http://arxiv.org/abs/2309.14359) | 本论文首次对具有可变不确定性的机会约束子模问题进行了详细分析，并提出了贪婪算法，可以获得高质量的解决方案。 |
| [^83] | [Corporate Credit Rating: A Survey.](http://arxiv.org/abs/2309.14349) | 本论文对企业信用评级进行了系统的调查，总结了CCR的发展背景，比较了不同模型的优缺点，并展望了CCR的未来。 |
| [^84] | [Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM.](http://arxiv.org/abs/2309.14348) | 本文提出了一种稳健对齐的LLM（RA-LLM），用于防御可能发生的对齐破坏攻击。RA-LLM可以直接在现有的对齐LLM上构建，并通过稳健的对齐检查函数来确保其有效性。 |
| [^85] | [Bias Assessment and Mitigation in LLM-based Code Generation.](http://arxiv.org/abs/2309.14345) | 这项研究提出了一个新颖的偏差评估框架，针对代码生成任务进行设计。通过对九个最先进的基于LLM的代码生成模型进行广泛评估，发现其中31.45\%到79.93\%的代码函数具有偏见，并提出了如何缓解这种偏见的方法。 |
| [^86] | [Innovative Digital Storytelling with AIGC: Exploration and Discussion of Recent Advances.](http://arxiv.org/abs/2309.14329) | 本研究探索了AIGC与数字叙事的整合状态，发现虽然AIGC在某些领域表现出色，但由于人类的创造力和审美感等因素，仍无法替代人类在复杂人物动画、面部表情和音效方面的贡献。 |
| [^87] | [MoDem-V2: Visuo-Motor World Models for Real-World Robot Manipulation.](http://arxiv.org/abs/2309.14236) | MoDem-V2是一个能够在非仪器化的真实世界中直接学习接触丰富操作的系统。 |
| [^88] | [Species196: A One-Million Semi-supervised Dataset for Fine-grained Species Recognition.](http://arxiv.org/abs/2309.14183) | Species196是一个包含196个类别的大规模半监督数据集，用于细粒度物种识别。它提供了四种实验设置，可以用于基准测试现有模型和算法的性能。 |
| [^89] | [Explainable Machine Learning for ICU Readmission Prediction.](http://arxiv.org/abs/2309.13781) | 本研究提出了一个标准化且可解释的机器学习流程，用于在多中心数据库中预测加护病房患者的再入院情况。 |
| [^90] | [Probabilistic Weight Fixing: Large-scale training of neural network weight uncertainties for quantization.](http://arxiv.org/abs/2309.13575) | 本文提出了一种基于贝叶斯神经网络和变分松弛的概率框架，用于通过将权重值限制在一组有限值上来减少推理过程中的能量消耗。通过利用权重值的概率分布，提高了噪声鲁棒性和可压缩性。迭代聚类过程展示了超越现有方法的优势。 |
| [^91] | [Global-correlated 3D-decoupling Transformer for Clothed Avatar Reconstruction.](http://arxiv.org/abs/2309.13524) | 这项研究提出了全球相关的三维解耦Transformer架构，用于从单目图像中重建具有衣服的人物化身。通过使用Transformer模型捕捉全局相关的图像特征，并采用创新的3D解耦解码器进行特征融合，实现了更好的重建效果。 |
| [^92] | [MiChao-HuaFen 1.0: A Specialized Pre-trained Corpus Dataset for Domain-specific Large Models.](http://arxiv.org/abs/2309.13079) | MiChao-HuaFen 1.0是一个专为新闻和政府部门定制的面向领域特定大模型的预训练语料数据集，它不仅能够满足特定领域的高质量需求，还有助于推动相关领域的深度学习研究和应用。 |
| [^93] | [InvestLM: A Large Language Model for Investment using Financial Domain Instruction Tuning.](http://arxiv.org/abs/2309.13064) | InvestLM是一个通过对金融领域指导数据集进行调优的大型语言模型，具有强大的理解金融文本的能力，并在投资相关问题上提供有帮助的回答。金融专家评价其与最先进的商业模型可媲美，并在金融NLP基准问题上展现了强大的泛化能力。 |
| [^94] | [A Quantum Computing-based System for Portfolio Optimization using Future Asset Values and Automatic Reduction of the Investment Universe.](http://arxiv.org/abs/2309.12627) | 本研究提出了一种基于量子计算的投资组合优化系统Q4FuturePOP，它创新地利用未来资产价值进行建模，并引入了一个自动减少投资范围的模块。通过实验讨论了Q4FuturePOP的原型版本中不同模块的初步性能。 |
| [^95] | [Multimodal Deep Learning for Scientific Imaging Interpretation.](http://arxiv.org/abs/2309.12460) | 本研究提出了一种多模态深度学习框架，通过模拟人类与扫描电子显微镜图像的交互，利用文本和视觉数据进行精细数据合成和评估。该模型（GlassLLaVA）能够准确解释、识别关键特征和检测以前未见的SEM图像中的缺陷，同时引入了适用于多种科学成像应用的灵活评估指标。 |
| [^96] | [Investigating the Catastrophic Forgetting in Multimodal Large Language Models.](http://arxiv.org/abs/2309.10313) | 本论文针对多模态大规模语言模型中的灾难性遗忘问题进行研究，引入了EMT方法来评估灾难性遗忘，并发现在标准图像分类任务上，几乎所有评估的模型都无法保持与视觉编码器相同的性能水平。研究结果表明，早期微调阶段对性能至关重要。 |
| [^97] | [Ultrafast-and-Ultralight ConvNet-Based Intelligent Monitoring System for Diagnosing Early-Stage Mpox Anytime and Anywhere.](http://arxiv.org/abs/2308.13492) | 提出了一种超快超轻的卷积神经网络Fast-MpoxNet，用于早期猴痘诊断。它具有较小的参数量和较快的处理速度，并通过特征融合和辅助损失增强策略提高了诊断性能。 |
| [^98] | [Uncovering local aggregated air quality index with smartphone captured images leveraging efficient deep convolutional neural network.](http://arxiv.org/abs/2308.03200) | 本文利用智能手机拍摄的图像，通过发展一个深度卷积神经网络，成功预测了特定位置的PM2.5浓度，揭示了本地聚合的空气质量指数的潜力。 |
| [^99] | [RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization.](http://arxiv.org/abs/2307.10224) | RL-ViGen是一种用于视觉泛化的强化学习基准，包含多样的任务和广泛的泛化类型，旨在推动对代理人视觉泛化能力的全面评估。 |
| [^100] | [TinyMetaFed: Efficient Federated Meta-Learning for TinyML.](http://arxiv.org/abs/2307.06822) | TinyMetaFed是一个适用于TinyML的高效联邦元学习框架，通过协同训练神经网络初始化，在小型设备上能够快速微调，同时实现通信节省和隐私保护。 |
| [^101] | [LLQL: Logistic Likelihood Q-Learning for Reinforcement Learning.](http://arxiv.org/abs/2307.02345) | 本研究通过研究在线和离线增强学习中 Bellman 近似误差的分布发现，Bellman 误差符合逻辑分布。基于这一发现，本研究提出了一种使用 Logistic 最大似然函数作为替代方法的方案，并通过实验证明了其有效性。 |
| [^102] | [RH20T: A Comprehensive Robotic Dataset for Learning Diverse Skills in One-Shot.](http://arxiv.org/abs/2307.00595) | 本文提出了一个用于单次学习多样技能的综合机器人数据集RH20T。该数据集包含超过11万个接触丰富的机器人操纵序列，涵盖了多种技能、环境、机器人和相机视角。这个数据集的目标是使机器人能够具备广泛的一般化能力，包括视觉和触觉感知。 |
| [^103] | [CompanyKG: A Large-Scale Heterogeneous Graph for Company Similarity Quantification.](http://arxiv.org/abs/2306.10649) | 本研究提出了CompanyKG，一种用于公司相似性量化的大规模异构图数据集。通过丰富的公司特征和关系表示，以及多个评估任务的基准测试，为公司相似性量化方法的综合评估提供了支持。 |
| [^104] | [MO-VLN: A Multi-Task Benchmark for Open-set Zero-Shot Vision-and-Language Navigation.](http://arxiv.org/abs/2306.10322) | MO-VLN是一个用于评估通用机器人在多任务环境中的视觉和语言导航的基准，通过使用虚幻引擎5开发逼真的场景和包含多种不常见物体来测试其效果和泛化能力。 |
| [^105] | [Can ChatGPT Enable ITS? The Case of Mixed Traffic Control via Reinforcement Learning.](http://arxiv.org/abs/2306.08094) | 本文研究探讨使用 ChatGPT 解决混合交通流控制问题，通过大规模用户研究发现 ChatGPT 在某些环境下能够提高成功策略数量 |
| [^106] | [Pre-trained transformer for adversarial purification.](http://arxiv.org/abs/2306.01762) | 本文提出了一个快速防御对抗性攻击的方案RaPiD（Rapid Plug-in Defender），通过预训练的Transformer微调来提纯对抗样本，使其逼近清洁数据分布，实验结果表明，在有限数据情况下，该方法优于最先进的方法。 |
| [^107] | [Med-UniC: Unifying Cross-Lingual Medical Vision-Language Pre-Training by Diminishing Bias.](http://arxiv.org/abs/2305.19894) | Med-UniC是一个新的框架，旨在通过整合英语和西班牙语的跨语言医学数据，实现跨语言医学图像-语言预训练的统一。他们提出了跨语言文本对齐规则(CTR)，以明确统一来自不同语言社区的医学报告的跨语言语义表示。 |
| [^108] | [Weakly-Supervised Visual-Textual Grounding with Semantic Prior Refinement.](http://arxiv.org/abs/2305.10913) | 本文提出了一种利用语义先验细化的弱监督视觉-文本对齐方法，仅使用图像-句子对进行学习，其目标是实现实体表示中的区域-短语对应关系，通过联合两个主要模块的输出进行预测。 |
| [^109] | [Distilling Knowledge for Short-to-Long Term Trajectory Prediction.](http://arxiv.org/abs/2305.08553) | 本文提出了一种新的方法Di-Long，用于解决长期轨迹预测中越来越不确定和不可预测的问题。该方法利用蒸馏短期轨迹模型预测器来指导训练过程中的长期轨迹预测学生网络。学生网络观察短序列并预测长轨迹，教师网络观察更长序列并预测剩余短目标轨迹。 |
| [^110] | [How to Index Item IDs for Recommendation Foundation Models.](http://arxiv.org/abs/2305.06569) | 本研究对推荐基础模型的项目索引问题进行了系统检查，提出了一种新的上下文感知索引方法，该方法在项目推荐准确性和文本生成质量方面具有优势。 |
| [^111] | [Fast exploration and learning of latent graphs with aliased observations.](http://arxiv.org/abs/2303.07397) | 本文介绍了一种在具有别名观测的潜在图上，能够显著提高最大化探索效率的政策算法 eFeX，相比于随机策略，该算法能够更快地恢复各种拓扑结构下的图表。 |
| [^112] | [Quantifying Causes of Arctic Amplification via Deep Learning based Time-series Causal Inference.](http://arxiv.org/abs/2303.07122) | 该研究提出了一种基于循环神经网络的时间序列因果推断模型TCINet，用于推断大气过程对海冰融化的因果效应。通过实验证明，该模型能够显著提高量化北极海冰融化的主要原因的能力。 |
| [^113] | [Understanding the Diffusion Objective as a Weighted Integral of ELBOs.](http://arxiv.org/abs/2303.00848) | 本文深入理解了扩散目标，并揭示了加权损失和ELBO目标之间的直接关系。 |
| [^114] | [Transformed Low-Rank Parameterization Can Help Robust Generalization for Tensor Neural Networks.](http://arxiv.org/abs/2303.00196) | 这项研究首次通过推导泛化误差上界回答了转换的低秩参数化如何影响张量神经网络的学习行为，结果显示通过精确的转换低秩参数化压缩的t-NNs可以实现更尖锐的对抗泛化上界。 |
| [^115] | [Permutation Equivariant Neural Functionals.](http://arxiv.org/abs/2302.14040) | 本文介绍了置换等变神经功能网络的设计，通过对权重进行置换对称性编码，实现对其他网络权重或梯度进行处理，为学习优化、处理隐式神经表示等应用提供了架构原则。 |
| [^116] | [Solving Continuous Control via Q-learning.](http://arxiv.org/abs/2210.12566) | 本研究通过对Q-learning进行简单修改，通过将bang-bang动作离散化与值分解相结合，将单智能体控制视为合作多智能体强化学习来解决连续控制问题，并取得了与最先进的连续actor-critic方法相匹配的性能。 |
| [^117] | [Over-the-Air Computation Based on Balanced Number Systems for Federated Edge Learning.](http://arxiv.org/abs/2210.07012) | 本研究提出了一种基于平衡数系统的数字计算方案，用于联邦边缘学习中的梯度聚合。通过数字的平均值计算实数参数的平均值，避免了对精确样本级时间同步、信道估计开销和信道反转的需求，同时提高了聚合性能。 |
| [^118] | [Mitigating Off-Policy Bias in Actor-Critic Methods with One-Step Q-learning: A Novel Correction Approach.](http://arxiv.org/abs/2208.00755) | 本文提出一种新的策略相似度量来缓解离策略学习中的偏差问题，提供了一种自适应的、可扩展的解决方案。 |
| [^119] | [OpenPodcar: an Open Source Vehicle for Self-Driving Car Research.](http://arxiv.org/abs/2205.04454) | OpenPodcar是一种开源自动驾驶车辆研究平台，基于带硬罩代步车辆进行改装，提供了低成本的硬件和软件构建说明。它具有标准的ROS接口和仿真功能，以及机器人自主规划和控制功能，可以用于最后一英里出租车服务或运输等应用。 |
| [^120] | [Interpretable and Interactive Deep Multiple Instance Learning for Dental Caries Classification in Bitewing X-rays.](http://arxiv.org/abs/2112.09694) | 本研究提出了一种可解释且交互式的深度多实例学习方法，用于在牙齿放射图中的龋齿分类。该方法首先输出局部补丁分类概率的热图，并可根据分割标签进行训练，与现有方法相比表现出了竞争性的性能，并且用户可以解释预测并与模型交互。 |
| [^121] | [Path Regularization: A Convexity and Sparsity Inducing Regularization for Parallel ReLU Networks.](http://arxiv.org/abs/2110.09548) | 路径正则化为并行ReLU网络提供了一种简化的凸优化问题，通过群稀疏性引导实现了凸模型，并提出了一个近似算法，在所有数据维度上具备完全多项式时间复杂度。 |
| [^122] | [Continuous Treatment Recommendation with Deep Survival Dose Response Function.](http://arxiv.org/abs/2108.10453) | 本论文提出了一个通用公式，称为深度生存剂量反应函数（DeepSDRF），用于解决临床生存数据中的连续治疗推荐问题。通过校正选择偏差，DeepSDRF估计的治疗效果可以用于开发推荐算法。在模拟研究和实际医学数据库上的测试中，DeepSDRF表现出良好的性能。 |
| [^123] | [Human-like Energy Management Based on Deep Reinforcement Learning and Historical Driving Experiences.](http://arxiv.org/abs/2007.10126) | 本文提出了一种基于深度强化学习和历史驾驶经验的人类化能量管理框架，通过采用深度确定性策略梯度算法和驾驶数据训练模型，提高了混合动力电动车能量管理的性能。 |

# 详细

[^1]: Doduo: 从无监督语义感知流中学习密集视觉对应关系

    Doduo: Learning Dense Visual Correspondence from Unsupervised Semantic-Aware Flow. (arXiv:2309.15110v1 [cs.CV])

    [http://arxiv.org/abs/2309.15110](http://arxiv.org/abs/2309.15110)

    Doduo是一个从野外图像和视频中学习通用密集视觉对应关系的无监督方法。它使用流场扭曲来获得训练监督信号，并结合语义先验进行自监督流训练，可产生鲁棒准确的密集对应关系。在测试中，Doduo在点级对应估计上表现优于现有的自监督对应关系学习基线。

    

    密集视觉对应关系在机器人感知中起着至关重要的作用。本工作致力于建立捕捉动态场景经历重大变化的一对图像之间的密集对应关系。我们介绍了Doduo，它可以从野外图像和视频中学习通用的密集视觉对应关系，无需地面真实监督。给定一对图像，Doduo估计了密集的流场，编码了一个图像中每个像素到另一个图像中相应像素的位移。Doduo使用基于流场的扭曲来获得训练的监督信号。结合自监督流训练的语义先验，Doduo产生了对场景动态变化具有鲁棒性的准确密集对应关系。在野外视频数据集上训练后，Doduo在点级对应估计上显示出优于现有的自监督对应关系学习基线的性能。我们还将Doduo应用于关节估计和零样本目标.

    Dense visual correspondence plays a vital role in robotic perception. This work focuses on establishing the dense correspondence between a pair of images that captures dynamic scenes undergoing substantial transformations. We introduce Doduo to learn general dense visual correspondence from in-the-wild images and videos without ground truth supervision. Given a pair of images, it estimates the dense flow field encoding the displacement of each pixel in one image to its corresponding pixel in the other image. Doduo uses flow-based warping to acquire supervisory signals for the training. Incorporating semantic priors with self-supervised flow training, Doduo produces accurate dense correspondence robust to the dynamic changes of the scenes. Trained on an in-the-wild video dataset, Doduo illustrates superior performance on point-level correspondence estimation over existing self-supervised correspondence learning baselines. We also apply Doduo to articulation estimation and zero-shot goal
    
[^2]: 满足关注：对语言模型事实错误的约束满足视角的研究

    Attention Satisfies: A Constraint-Satisfaction Lens on Factual Errors of Language Models. (arXiv:2309.15098v1 [cs.CL])

    [http://arxiv.org/abs/2309.15098](http://arxiv.org/abs/2309.15098)

    本研究使用约束满足问题框架研究了语言模型的内部行为，发现模型对约束标记的关注程度与事实准确性强正相关。提出了一种方法可以预测约束满足和事实错误，并允许早期错误识别，进一步提高了大型语言模型的可靠性。

    

    本研究调查了基于Transformer的大型语言模型（LLM）在生成事实上错误的文本时的内部行为。我们将事实查询建模为约束满足问题，并利用这一框架研究模型如何与事实约束进行内部交互。具体而言，我们发现模型对约束标记的关注程度与其响应的事实准确性存在强正相关关系。在我们的11个数据集中，总计超过40,000个提示的精心策划套装中，我们研究了使用Llama-2系列在所有规模（7B，13B，70B）上预测事实错误的任务。我们提出了SAT Probe，一种探查自注意模式的方法，可以预测约束满足和事实错误，并允许早期错误识别。这一方法和发现表明，利用对LLM中事实性的机械理解可以增强可靠性。

    We investigate the internal behavior of Transformer-based Large Language Models (LLMs) when they generate factually incorrect text. We propose modeling factual queries as Constraint Satisfaction Problems and use this framework to investigate how the model interacts internally with factual constraints. Specifically, we discover a strong positive relation between the model's attention to constraint tokens and the factual accuracy of its responses. In our curated suite of 11 datasets with over 40,000 prompts, we study the task of predicting factual errors with the Llama-2 family across all scales (7B, 13B, 70B). We propose SAT Probe, a method probing self-attention patterns, that can predict constraint satisfaction and factual errors, and allows early error identification. The approach and findings demonstrate how using the mechanistic understanding of factuality in LLMs can enhance reliability.
    
[^3]: VideoDirectorGPT: 通过LLM引导的规划实现一致的多场景视频生成

    VideoDirectorGPT: Consistent Multi-scene Video Generation via LLM-Guided Planning. (arXiv:2309.15091v1 [cs.CV])

    [http://arxiv.org/abs/2309.15091](http://arxiv.org/abs/2309.15091)

    本文提出了VideoDirectorGPT，一种利用LLMs的知识实现一致多场景视频生成的框架，通过视频内容规划和基于内容的视频生成来生成时间上一致的长视频。

    

    尽管最近的文本到视频生成方法取得了显著的进展，但大多数工作集中在生成单个事件和单一背景的短视频片段（即单场景视频）。与此同时，最近的大型语言模型（LLMs）已经证明了它们在生成布局和控制下游视觉模块（如图像生成模型）的程序方面的能力。这引发了一个重要问题：我们能否利用这些LLMs中嵌入的知识用于生成时间上一致的长视频？在本文中，我们提出了VideoDirectorGPT，这是一个用于一致的多场景视频生成的新型框架，它利用LLMs的知识进行视频内容规划和基于内容的视频生成。具体而言，我们首先将单个文本提示输入我们的视频规划器LLM（GPT-4）中，将其扩展为“视频计划”，其中包括生成场景描述、实体及其布局、每个场景的背景以及保持一致性等内容。

    Although recent text-to-video (T2V) generation methods have seen significant advancements, most of these works focus on producing short video clips of a single event with a single background (i.e., single-scene videos). Meanwhile, recent large language models (LLMs) have demonstrated their capability in generating layouts and programs to control downstream visual modules such as image generation models. This raises an important question: can we leverage the knowledge embedded in these LLMs for temporally consistent long video generation? In this paper, we propose VideoDirectorGPT, a novel framework for consistent multi-scene video generation that uses the knowledge of LLMs for video content planning and grounded video generation. Specifically, given a single text prompt, we first ask our video planner LLM (GPT-4) to expand it into a 'video plan', which involves generating the scene descriptions, the entities with their respective layouts, the background for each scene, and consistency 
    
[^4]: 基于大型语言模型（LLMs）的自然语言上下文建模与推理：教程

    Natural Language based Context Modeling and Reasoning with LLMs: A Tutorial. (arXiv:2309.15074v1 [cs.CL])

    [http://arxiv.org/abs/2309.15074](http://arxiv.org/abs/2309.15074)

    本教程介绍了基于大型语言模型的自然语言上下文建模和推理，通过与LLMs交互，使用自然语言进行上下文建模和推理。

    

    大型语言模型（LLMs）自2018年以来急剧增长，自引入上下文感知计算系统20年后。上下文感知计算通过考虑普适设备、用户和社会的情况，实现了广泛的创新应用，如辅助生活、基于位置的社交网络服务等。为了识别上下文并相应地做出决策，采用了各种人工智能技术（如本体论和OWL）作为上下文建模和推理的表示方法。最近，随着LLMs的崛起和它们改进的自然语言理解和推理能力，使用自然语言建模上下文并通过与ChatGPT和GPT-4等LLMs交互进行上下文推理变得可行。在本教程中，我们演示了使用文本、提示和自主代理（AutoAgents）使LLMs能够执行上下文建模的方法。

    Large language models (LLMs) have become phenomenally surging, since 2018--two decades after introducing context-awareness into computing systems. Through taking into account the situations of ubiquitous devices, users and the societies, context-aware computing has enabled a wide spectrum of innovative applications, such as assisted living, location-based social network services and so on. To recognize contexts and make decisions for actions accordingly, various artificial intelligence technologies, such as Ontology and OWL, have been adopted as representations for context modeling and reasoning. Recently, with the rise of LLMs and their improved natural language understanding and reasoning capabilities, it has become feasible to model contexts using natural language and perform context reasoning by interacting with LLMs such as ChatGPT and GPT-4. In this tutorial, we demonstrate the use of texts, prompts, and autonomous agents (AutoAgents) that enable LLMs to perform context modeling 
    
[^5]: 当Prolog遇见生成模型：机器人应用中管理知识和规划的新方法

    When Prolog meets generative models: a new approach for managing knowledge and planning in robotic applications. (arXiv:2309.15049v1 [cs.RO])

    [http://arxiv.org/abs/2309.15049](http://arxiv.org/abs/2309.15049)

    本文提出了一种基于Prolog语言的机器人知识管理系统，通过利用大型语言模型自动填充知识库，实现了多机器人系统的连续并行计划生成以及计划到可执行形式的自动转化。

    

    本文提出了一种基于Prolog语言的面向机器人的知识管理系统。我们的框架依赖于一种特殊的知识库组织形式，实现了以下功能：1.利用大型语言模型进行自动化的自然语言文本知识库填充；2.通过一系列转换生成多机器人系统的连续并行计划；3.将计划自动转化为可执行形式（行为树）。该框架支持一系列开源工具，并在一个现实应用中进行了验证。

    In this paper, we propose a robot oriented knowledge management system based on the use of the Prolog language. Our framework hinges on a special organisation of knowledge base that enables: 1. its efficient population from natural language texts using semi-automated procedures based on Large Language Models, 2. the bumpless generation of temporal parallel plans for multi-robot systems through a sequence of transformations, 3. the automated translation of the plan into an executable formalism (the behaviour trees). The framework is supported by a set of open source tools and is shown on a realistic application.
    
[^6]: 基于似然比的任务预测的类增量学习

    Class Incremental Learning via Likelihood Ratio Based Task Prediction. (arXiv:2309.15048v1 [cs.LG])

    [http://arxiv.org/abs/2309.15048](http://arxiv.org/abs/2309.15048)

    该论文提出了一种基于似然比的任务预测的类增量学习方法，利用离群检测器进行任务标识预测，解决了无任务标识符的测试样本的任务预测问题。

    

    类增量学习是一种具有挑战性的不断学习的设置，通过顺序学习一系列任务。每个任务由一组唯一的类组成。类增量学习的关键特点是，在测试时不提供每个测试样本的任务标识符（或任务ID）。为每个测试样本预测任务ID是一个具有挑战性的问题。一种新兴的理论上合理且有效的方法是根据任务增量学习的方法，在共享网络中为所有任务训练每个任务的任务特定模型，以处理遗忘。该方法中每个任务的模型是一个非常规分类器而不是传统分类器的离群检测器。离群检测器可以对任务内（分布内（IND））的类进行预测和识别离群数据。在推断期间，离群检测能力是每个测试样本的任务ID预测的关键。然而，本文认为使用传统的离群检测器进行任务ID预测是次优的。

    Class incremental learning (CIL) is a challenging setting of continual learning, which learns a series of tasks sequentially. Each task consists of a set of unique classes. The key feature of CIL is that no task identifier (or task-id) is provided at test time for each test sample. Predicting the task-id for each test sample is a challenging problem. An emerging theoretically justified and effective approach is to train a task-specific model for each task in a shared network for all tasks based on a task-incremental learning (TIL) method to deal with forgetting. The model for each task in this approach is an out-of-distribution (OOD) detector rather than a conventional classifier. The OOD detector can perform both within-task (in-distribution (IND)) class prediction and OOD detection. The OOD detection capability is the key for task-id prediction during inference for each test sample. However, this paper argues that using a traditional OOD detector for task-id prediction is sub-optimal
    
[^7]: 结合存活分析和机器学习利用电子健康记录数据进行肿瘤风险预测

    Combining Survival Analysis and Machine Learning for Mass Cancer Risk Prediction using EHR data. (arXiv:2309.15039v1 [cs.LG])

    [http://arxiv.org/abs/2309.15039](http://arxiv.org/abs/2309.15039)

    该论文介绍了一种利用 EHR 数据进行大规模肿瘤风险预测的新方法，其创新之处在于只需利用历史的医疗服务代码和诊断信息来实现最小化的数据需求，通过将存活分析和机器学习相结合，可以在大规模应用中实现对患者癌症风险的个性化评估。

    

    纯粹的医学肿瘤筛查方法通常费用高昂、耗时长，并且仅适用于大规模应用。先进的人工智能（AI）方法在癌症检测方面发挥了巨大作用，但需要特定或深入的医学数据。这些方面影响了癌症筛查方法的大规模实施。因此，基于已有的电子健康记录（EHR）数据对患者进行大规模个性化癌症风险评估应用AI方法是一种颠覆性的改变。本文提出了一种利用EHR数据进行大规模肿瘤风险预测的新方法。与其他方法相比，我们的方法通过最小的数据贪婪策略脱颖而出，仅需要来自EHR的医疗服务代码和诊断历史。我们将问题形式化为二分类问题。该数据集包含了175441名不记名的患者（其中2861名被诊断为癌症）。作为基准，我们实现了一个基于循环神经网络（RNN）的解决方案。我们提出了一种方法，将存活分析和机器学习相结合，

    Purely medical cancer screening methods are often costly, time-consuming, and weakly applicable on a large scale. Advanced Artificial Intelligence (AI) methods greatly help cancer detection but require specific or deep medical data. These aspects affect the mass implementation of cancer screening methods. For these reasons, it is a disruptive change for healthcare to apply AI methods for mass personalized assessment of the cancer risk among patients based on the existing Electronic Health Records (EHR) volume.  This paper presents a novel method for mass cancer risk prediction using EHR data. Among other methods, our one stands out by the minimum data greedy policy, requiring only a history of medical service codes and diagnoses from EHR. We formulate the problem as a binary classification. This dataset contains 175 441 de-identified patients (2 861 diagnosed with cancer). As a baseline, we implement a solution based on a recurrent neural network (RNN). We propose a method that combine
    
[^8]: 让PPO变得更好：基于值导向的Monte-Carlo Tree Search解码

    Making PPO even better: Value-Guided Monte-Carlo Tree Search decoding. (arXiv:2309.15028v1 [cs.CL])

    [http://arxiv.org/abs/2309.15028](http://arxiv.org/abs/2309.15028)

    本文提出了一种基于值导向的Monte-Carlo Tree Search解码算法PPO-MCTS，通过在PPO之上集成MCTS，解决了训练和测试之间部分输出评分机制的不匹配问题，实验证明该算法可以显著提升性能。

    

    在生成自然语言文本时，使用最新的强化学习算法，如Proximal Policy Optimization (PPO)，因此可以认为推理时间的搜索算法，如Monte-Carlo Tree Search (MCTS) 是不必要的。本文证明了通过在PPO之上集成MCTS，可以进一步提升PPO的性能。关键思想是在解码文本时，不要丢弃值网络，即PPO训练时用于评估部分输出序列的副产品，而是将其与策略网络紧密结合。具体而言，本文提出了一种称为PPO-MCTS的新颖的值导向解码算法，可以将来自PPO的值网络与推理时间产生的策略网络紧密结合。与基于MCTS的控制文本生成的先前方法相比，我们的方法的关键优势在于减少了训练和测试之间部分输出的评分机制的基本不匹配。在四个文本生成任务上的评估结果表明，PPO-MCTS可以显著提升性能。

    Inference-time search algorithms such as Monte-Carlo Tree Search (MCTS) may seem unnecessary when generating natural language text based on state-of-the-art reinforcement learning such as Proximal Policy Optimization (PPO). In this paper, we demonstrate that it is possible to get extra mileage out of PPO by integrating MCTS on top. The key idea is not to throw out the value network, a byproduct of PPO training for evaluating partial output sequences, when decoding text out of the policy network. More concretely, we present a novel value-guided decoding algorithm called PPO-MCTS, which can integrate the value network from PPO to work closely with the policy network during inference-time generation. Compared to prior approaches based on MCTS for controlled text generation, the key strength of our approach is to reduce the fundamental mismatch of the scoring mechanisms of the partial outputs between training and test. Evaluation on four text generation tasks demonstrate that PPO-MCTS grea
    
[^9]: 大规模语言模型对齐：一项调查

    Large Language Model Alignment: A Survey. (arXiv:2309.15025v1 [cs.CL])

    [http://arxiv.org/abs/2309.15025](http://arxiv.org/abs/2309.15025)

    这项调查对大规模语言模型对齐的方法进行了广泛探讨，并提出了内部对齐和外部对齐的分类。同时讨论了模型的可解释性和潜在的对抗攻击漏洞。考虑到模型可能产生的不准确和误导性文本，对齐技术显得至关重要。

    

    近年来，大规模语言模型（LLMs）取得了显著进展。这些进展引起了广泛关注，但同时也引发了各种担忧。这些模型的潜力无疑是巨大的；然而，它们可能产生不准确、误导性甚至有害的文本。因此，采用对齐技术以确保这些模型表现出与人类价值一致的行为变得至关重要。本调查旨在对针对LLMs设计的对齐方法进行广泛探讨，并结合该领域中的现有能力研究。采用AI对齐的视角，我们将用于对齐LLMs的主流方法和新兴提议分为外部对齐和内部对齐。我们还探讨了模型可解释性和潜在的对抗攻击漏洞等重要问题。为了评估LLM的对齐，我们提出了多样化的基准和评估方法。

    Recent years have witnessed remarkable progress made in large language models (LLMs). Such advancements, while garnering significant attention, have concurrently elicited various concerns. The potential of these models is undeniably vast; however, they may yield texts that are imprecise, misleading, or even detrimental. Consequently, it becomes paramount to employ alignment techniques to ensure these models to exhibit behaviors consistent with human values.  This survey endeavors to furnish an extensive exploration of alignment methodologies designed for LLMs, in conjunction with the extant capability research in this domain. Adopting the lens of AI alignment, we categorize the prevailing methods and emergent proposals for the alignment of LLMs into outer and inner alignment. We also probe into salient issues including the models' interpretability, and potential vulnerabilities to adversarial attacks. To assess LLM alignment, we present a wide variety of benchmarks and evaluation metho
    
[^10]: 单向脑机接口：通过人工神经网络将自然图像编码为视觉皮层的fMRI响应

    Unidirectional brain-computer interface: Artificial neural network encoding natural images to fMRI response in the visual cortex. (arXiv:2309.15018v1 [cs.CV])

    [http://arxiv.org/abs/2309.15018](http://arxiv.org/abs/2309.15018)

    这项研究提出了一个名为"VISION"的人工神经网络模型，通过模仿人脑的工作方式，成功预测了人类脑对自然图像的fMRI响应。与现有技术相比，该模型的准确性提高了45%。通过进一步探索训练过的网络，发现了不同视觉区域的表征偏见，并提出了与皮层功能相关的可实验检验的假设和解释性度量标准。

    

    尽管人工智能在各个领域取得了显著进展，但其在理解视觉知觉方面的完全潜力仍未得到充分探索。我们提出了一个名为"VISION"的人工神经网络，为"神经活动成像输出的视觉接口系统"的首字母缩写，模仿人脑并展示如何促进神经科学研究。利用视觉和情境输入，这个多模态模型预测人脑对自然图像的功能性磁共振成像（fMRI）扫描响应。VISION成功预测了人类血氧水平依赖性信号作为fMRI体素值对视觉输入的响应，其准确度比现有技术的性能提高了45%。我们进一步探索训练过的网络以揭示不同视觉区域的表征偏见，产生可实验检验的假设，并制定一个可解释的度量标准将这些假设与皮层功能相关联。

    While significant advancements in artificial intelligence (AI) have catalyzed progress across various domains, its full potential in understanding visual perception remains underexplored. We propose an artificial neural network dubbed VISION, an acronym for "Visual Interface System for Imaging Output of Neural activity," to mimic the human brain and show how it can foster neuroscientific inquiries. Using visual and contextual inputs, this multimodal model predicts the brain's functional magnetic resonance imaging (fMRI) scan response to natural images. VISION successfully predicts human hemodynamic responses as fMRI voxel values to visual inputs with an accuracy exceeding state-of-the-art performance by 45%. We further probe the trained networks to reveal representational biases in different visual areas, generate experimentally testable hypotheses, and formulate an interpretable metric to associate these hypotheses with cortical functions. With both a model and evaluation metric, the 
    
[^11]: 从教育文本中自动生成问题

    Automating question generation from educational text. (arXiv:2309.15004v1 [cs.CL])

    [http://arxiv.org/abs/2309.15004](http://arxiv.org/abs/2309.15004)

    本文设计并评估了一个用于学校形成性和总结性评估的自动化问题生成工具，通过对教师的调查，证明了自动化生成问题的需求，并提出了一个基于Transformer的语言模型的模块化框架，用于从文本内容中自动生成多项选择题。

    

    问题式活动（QBA）在教育中得到广泛应用，传统上是学习和评估过程的一个重要组成部分。本文设计并评估了一个用于学校形成性和总结性评估的自动化问题生成工具。通过对104名教师的专家调查，我们展示了自动化生成QBA的需求，作为一个能够显著减轻教师工作量并促进个性化学习体验的工具。利用生成型AI的最新进展，我们提出了一个基于Transformer的语言模型的模块化框架，用于从文本内容中自动生成多项选择题（MCQ）。所提出的解决方案具有问题生成、正确答案预测和干扰项制定的不同模块，使我们能够评估不同的语言模型和生成技术。最后，我们进行了广泛的定量和定性评估。

    The use of question-based activities (QBAs) is wide-spread in education, traditionally forming an integral part of the learning and assessment process. In this paper, we design and evaluate an automated question generation tool for formative and summative assessment in schools. We present an expert survey of one hundred and four teachers, demonstrating the need for automated generation of QBAs, as a tool that can significantly reduce the workload of teachers and facilitate personalized learning experiences. Leveraging the recent advancements in generative AI, we then present a modular framework employing transformer based language models for automatic generation of multiple-choice questions (MCQs) from textual content. The presented solution, with distinct modules for question generation, correct answer prediction, and distractor formulation, enables us to evaluate different language models and generation techniques. Finally, we perform an extensive quantitative and qualitative evaluat
    
[^12]: 针对帆船价格和特征以及区域地区的测量模型

    Measurement Models For Sailboats Price vs. Features And Regional Areas. (arXiv:2309.14994v1 [cs.LG])

    [http://arxiv.org/abs/2309.14994](http://arxiv.org/abs/2309.14994)

    这项研究调查了帆船技术规格和价格之间的关系以及区域定价的影响。通过应用多个机器学习模型，我们发现单体船通常比双体船更实惠，并且长度、宽度、排水量和帆面积等特定规格与较高的价格直接相关。此外，我们还发现美国是平均帆船价格最高的国家，而国内生产总值与帆船价格没有直接相关关系。

    

    在这项研究中，我们调查了帆船技术规格与其价格之间的关系，以及区域定价的影响。利用包括长度、宽度、吃水、排水量、帆面积和水线等特征的数据集，我们应用多个机器学习模型来预测帆船价格。梯度下降模型表现出优秀的性能，产生了最低的MSE和MAE。我们的分析发现，单体船通常比双体船更实惠，而长度、宽度、排水量和帆面积等特定规格与较高的价格直接相关。有趣的是，较低的吃水与较高的挂牌价格有关联。我们还探讨了区域定价因素，并发现美国在平均帆船价格上居首，其次是欧洲、香港和加勒比地区。与我们最初的假设相反，一个国家的GDP与帆船价格没有直接相关关系。

    In this study, we investigated the relationship between sailboat technical specifications and their prices, as well as regional pricing influences. Utilizing a dataset encompassing characteristics like length, beam, draft, displacement, sail area, and waterline, we applied multiple machine learning models to predict sailboat prices. The gradient descent model demonstrated superior performance, producing the lowest MSE and MAE. Our analysis revealed that monohulled boats are generally more affordable than catamarans, and that certain specifications such as length, beam, displacement, and sail area directly correlate with higher prices. Interestingly, lower draft was associated with higher listing prices. We also explored regional price determinants and found that the United States tops the list in average sailboat prices, followed by Europe, Hong Kong, and the Caribbean. Contrary to our initial hypothesis, a country's GDP showed no direct correlation with sailboat prices. Utilizing a 50
    
[^13]: 在一千年前的拉丁文本中检测句子级别的性内容

    Detecting Sexual Content at the Sentence Level in First Millennium Latin Texts. (arXiv:2309.14974v1 [cs.CL])

    [http://arxiv.org/abs/2309.14974](http://arxiv.org/abs/2309.14974)

    该研究提出使用深度学习方法在句子级别进行语义分类，以加速人文学科和语言学领域中语料库建设的过程。经过评估，该方法在检测性内容方面表现出高精度和真阳性率，并探索了不同的输入嵌入层对模型性能的影响。

    

    在这项研究中，我们提出使用深度学习方法在句子级别进行语义分类，以加快人文学科和语言学领域中语料库建设的过程，这是一项传统且耗时的任务。我们引入了一个新颖的语料库，包括约2500个句子，涵盖了从公元前300年到公元900年的性语义学（医学，情色等）。我们评估了各种句子分类方法和不同的输入嵌入层，并表明它们都比简单的基于标记的搜索方法更好。我们探索了个人言语和社会言语元数据嵌入（世纪，作者，写作类型）的整合，但发现这导致了过拟合。我们的结果表明了这种方法的有效性，使用HAN分别达到了70.60%的高精度和86.33%的真阳性率（TPR）。我们评估了数据集大小对模型性能的影响（420而不是2013），并显示出，尽管我们的模型性能可能稍有下降，但性能仍然稳定。

    In this study, we propose to evaluate the use of deep learning methods for semantic classification at the sentence level to accelerate the process of corpus building in the field of humanities and linguistics, a traditional and time-consuming task. We introduce a novel corpus comprising around 2500 sentences spanning from 300 BCE to 900 CE including sexual semantics (medical, erotica, etc.). We evaluate various sentence classification approaches and different input embedding layers, and show that all consistently outperform simple token-based searches. We explore the integration of idiolectal and sociolectal metadata embeddings (centuries, author, type of writing), but find that it leads to overfitting. Our results demonstrate the effectiveness of this approach, achieving high precision and true positive rates (TPR) of respectively 70.60% and 86.33% using HAN. We evaluate the impact of the dataset size on the model performances (420 instead of 2013), and show that, while our models per
    
[^14]: 通过代码重写家族改善无监督的视觉程序推理

    Improving Unsupervised Visual Program Inference with Code Rewriting Families. (arXiv:2309.14972v1 [cs.CV])

    [http://arxiv.org/abs/2309.14972](http://arxiv.org/abs/2309.14972)

    本论文介绍了一种改进无监督视觉程序推理的方法，通过代码重写来提高从视觉数据中推断程序的性能。使用稀疏间歇性代码重写注入(SIRI)和重写家族，能够实现更好的重构和更快的收敛速率。同时，在测试时使用重写家族还可以改进SIRI预测的输出结果。

    

    程序提供了一种紧凑且有结构的表示方法，对于可视化数据来说非常有吸引力。我们探索了如何利用代码重写来改善从视觉数据中推断程序的系统。我们首先提出了稀疏间歇性代码重写注入（SIRI），这是一个用于无监督引导式学习的框架。SIRI在训练程序的数据集上稀疏地应用代码重写操作，并将改进的程序注入到训练集中。我们设计了一个适用于视觉编程领域的重写家族：参数优化、代码修剪和代码移植。对于二维和三维的三种形状编程语言，我们展示了使用SIRI和我们的重写家族能够提高性能：更好的重构和更快的收敛速率，与不使用重写器或者只是简单地使用重写器的引导式学习方法相比。最后，我们证明了我们的重写家族可以在测试时有效地改进SIRI预测的输出。

    Programs offer compactness and structure that makes them an attractive representation for visual data. We explore how code rewriting can be used to improve systems for inferring programs from visual data. We first propose Sparse Intermittent Rewrite Injection (SIRI), a framework for unsupervised bootstrapped learning. SIRI sparsely applies code rewrite operations over a dataset of training programs, injecting the improved programs back into the training set. We design a family of rewriters for visual programming domains: parameter optimization, code pruning, and code grafting. For three shape programming languages in 2D and 3D, we show that using SIRI with our family of rewriters improves performance: better reconstructions and faster convergence rates, compared with bootstrapped learning methods that do not use rewriters or use them naively. Finally, we demonstrate that our family of rewriters can be effectively used at test time to improve the output of SIRI predictions. For 2D and 3
    
[^15]: 递归超网络在元强化学习中表现出惊人的强大性能

    Recurrent Hypernetworks are Surprisingly Strong in Meta-RL. (arXiv:2309.14970v1 [cs.LG])

    [http://arxiv.org/abs/2309.14970](http://arxiv.org/abs/2309.14970)

    递归超网络和循环神经网络在元强化学习中的端到端学习表现出惊人的强大性能，相比于现有专门方法更为简单但效果更好。

    

    深度强化学习在实际应用时因样本效率低而不易部署。元强化学习通过学习在元训练时利用相关任务的分布来实现少样本学习，直接解决了这个样本效率问题。最近的研究表明，与专门的元强化学习方法相比，与一个通用的序列模型（如循环神经网络）结合的端到端学习是一个令人惊讶的强基准。然而，这样的观点由于有限的支持证据而引起了争议，特别是在之前的研究中确立了完全相反的观点。在本文中，我们进行了实证研究。虽然我们同样发现循环网络可以达到强大的性能，但我们证明了超网络的使用对于发挥循环基线的潜力至关重要。令人惊讶的是，与超网络相结合时，这种远比现有专门方法简单的循环基准实际上能取得更好的表现。

    Deep reinforcement learning (RL) is notoriously impractical to deploy due to sample inefficiency. Meta-RL directly addresses this sample inefficiency by learning to perform few-shot learning when a distribution of related tasks is available for meta-training. While many specialized meta-RL methods have been proposed, recent work suggests that end-to-end learning in conjunction with an off-the-shelf sequential model, such as a recurrent network, is a surprisingly strong baseline. However, such claims have been controversial due to limited supporting evidence, particularly in the face of prior work establishing precisely the opposite. In this paper, we conduct an empirical investigation. While we likewise find that a recurrent network can achieve strong performance, we demonstrate that the use of hypernetworks is crucial to maximizing their potential. Surprisingly, when combined with hypernetworks, the recurrent baselines that are far simpler than existing specialized methods actually ac
    
[^16]: 通过交互学习社交媒体表示改善新闻来源真实性检测

    Interactively Learning Social Media Representations Improves News Source Factuality Detection. (arXiv:2309.14966v1 [cs.CL])

    [http://arxiv.org/abs/2309.14966](http://arxiv.org/abs/2309.14966)

    本文提出了一种交互式的方法来改善社交媒体表示质量，通过人类互动帮助自动化系统检测新闻来源的真实性，并在实验证明即使进行了少量的人类互动，也能提高性能。

    

    社交媒体的兴起使得虚假新闻的广泛传播成为可能，虚假新闻是指以传播错误信息和影响信仰为目的的文本。及时检测虚假新闻，特别是在新事件出现时，对于防止误导信息非常重要。尽管以前的研究利用监督学习系统解决了这个问题，但是自动建模社交媒体传播虚假新闻的复杂性仍然具有挑战性。相反，通过人工实时检查所有新闻是不可扩展的。因此，在本文中，我们提出了一种交互式的方法来解决这个问题，人们可以与自动化系统互动，帮助其学习更好的社交媒体表示质量。在真实事件中的实验证明，即使进行了少量的人类互动，也能提高检测新闻来源真实性的性能。

    The rise of social media has enabled the widespread propagation of fake news, text that is published with an intent to spread misinformation and sway beliefs. Rapidly detecting fake news, especially as new events arise, is important to prevent misinformation.  While prior works have tackled this problem using supervised learning systems, automatedly modeling the complexities of the social media landscape that enables the spread of fake news is challenging. On the contrary, having humans fact check all news is not scalable. Thus, in this paper, we propose to approach this problem interactively, where humans can interact to help an automated system learn a better social media representation quality. On real world events, our experiments show performance improvements in detecting factuality of news sources, even after few human interactions.
    
[^17]: 通过AI生成的辅助粒子解决单颗粒冷冻电镜中的优选取向问题

    Addressing preferred orientation in single-particle cryo-EM through AI-generated auxiliary particles. (arXiv:2309.14954v1 [q-bio.BM])

    [http://arxiv.org/abs/2309.14954](http://arxiv.org/abs/2309.14954)

    介绍了一种基于人工智能的方法cryoPROS，通过生成辅助粒子来解决单颗粒冷冻电镜中的优选取向问题，可有效地恢复非倾斜数据的高分辨率结构，并改进了膜蛋白的分辨率。

    

    单颗粒冷冻电镜领域一直面临着优选取向的挑战，缺乏通用的计算解决方案。我们引入了基于人工智能的cryoPROS方法，旨在解决上述问题。通过使用条件深度生成模型生成辅助粒子，cryoPROS解决了对观察粒子的取向估计的固有偏差。在血凝素三聚体的单颗粒冷冻电镜分析中，我们成功地使用cryoPROS恢复了非倾角数据的近原子分辨率结构。此外，经过改进的版本cryoPROS-MP在不倾斜的包含胶束效应的数据上显著提高了膜蛋白NaX的分辨率。与传统方法相比，cryoPROS不需要特殊的实验或图像获取技术，为优选取向问题提供了纯计算但有效的解决方案。

    The single-particle cryo-EM field faces the persistent challenge of preferred orientation, lacking general computational solutions. We introduce cryoPROS, an AI-based approach designed to address the above issue. By generating the auxiliary particles with a conditional deep generative model, cryoPROS addresses the intrinsic bias in orientation estimation for the observed particles. We effectively employed cryoPROS in the cryo-EM single particle analysis of the hemagglutinin trimer, showing the ability to restore the near-atomic resolution structure on non-tilt data. Moreover, the enhanced version named cryoPROS-MP significantly improves the resolution of the membrane protein NaX using the no-tilted data that contains the effects of micelles. Compared to the classical approaches, cryoPROS does not need special experimental or image acquisition techniques, providing a purely computational yet effective solution for the preferred orientation problem. Finally, we conduct extensive experime
    
[^18]: 使用基于原型的均值教师的多源域自适应目标检测

    Multi-Source Domain Adaptation for Object Detection with Prototype-based Mean-teacher. (arXiv:2309.14950v1 [cs.CV])

    [http://arxiv.org/abs/2309.14950](http://arxiv.org/abs/2309.14950)

    该论文提出了一种名为Prototype-based Mean-Teacher (PMT)的新型多源域自适应目标检测方法，通过使用类原型而不是域特定子网络来保留域特定信息，提高了准确性和鲁棒性。

    

    将视觉目标检测器适应于操作目标领域是一项具有挑战性的任务，通常使用无监督域自适应（UDA）方法来实现。当标记的数据集来自多个源域时，将它们视为单独的域并进行多源域自适应（MSDA），相比将这些源域混合并进行UDA，可以提高准确性和鲁棒性，近期的研究也证明了这一点。现有的MSDA方法学习域不变和域特定参数（对于每个源域）来进行自适应。然而，与单源UDA方法不同，学习域特定参数使它们与使用的源域数量成正比增长。本文提出了一种名为基于原型的均值教师（PMT）的新型MSDA方法，该方法使用类原型而不是域特定子网络来保留域特定信息。这些原型是使用对比损失学习的，对齐相同的类别。

    Adapting visual object detectors to operational target domains is a challenging task, commonly achieved using unsupervised domain adaptation (UDA) methods. When the labeled dataset is coming from multiple source domains, treating them as separate domains and performing a multi-source domain adaptation (MSDA) improves the accuracy and robustness over mixing these source domains and performing a UDA, as observed by recent studies in MSDA. Existing MSDA methods learn domain invariant and domain-specific parameters (for each source domain) for the adaptation. However, unlike single-source UDA methods, learning domain-specific parameters makes them grow significantly proportional to the number of source domains used. This paper proposes a novel MSDA method called Prototype-based Mean-Teacher (PMT), which uses class prototypes instead of domain-specific subnets to preserve domain-specific information. These prototypes are learned using a contrastive loss, aligning the same categories across 
    
[^19]: 与残障社群共同参与生成式人工智能开发的民主平台

    A Democratic Platform for Engaging with Disabled Community in Generative AI Development. (arXiv:2309.14921v1 [cs.HC])

    [http://arxiv.org/abs/2309.14921](http://arxiv.org/abs/2309.14921)

    这个论文提出了一个平台，允许残障社群参与生成式人工智能的建设过程，以了解残障社群使用生成式人工智能时输出中存在的偏见因素。

    

    人工智能（AI）系统，特别是生成式人工智能技术在我们的社会中变得越来越重要。像ChatGPT这样的工具被残障社群的成员使用，例如，自闭症患者可以使用它来帮助撰写电子邮件。生成式人工智能工具的不断增长的影响和受欢迎程度促使我们研究它们在残障社群中的相关性。设计和开发阶段通常忽视了这个边缘化群体，导致了针对他们的预测不准确和不公平的歧视。这可能是由于在创建和实施的各个阶段中的数据集、算法和系统中的偏见所导致。本研讨会论文提出了一个平台，以在构建生成式人工智能系统时让残障社群参与其中。通过这个平台，我们的目标是深入了解当残障社群使用生成式人工智能时，对其输出产生偏见的因素。此外，我们希望理解哪些算法因素是最具影响力的。

    Artificial Intelligence (AI) systems, especially generative AI technologies are becoming more relevant in our society. Tools like ChatGPT are being used by members of the disabled community e.g., Autistic people may use it to help compose emails. The growing impact and popularity of generative AI tools have prompted us to examine their relevance within the disabled community. The design and development phases often neglect this marginalized group, leading to inaccurate predictions and unfair discrimination directed towards them. This could result from bias in data sets, algorithms, and systems at various phases of creation and implementation. This workshop paper proposes a platform to involve the disabled community while building generative AI systems. With this platform, our aim is to gain insight into the factors that contribute to bias in the outputs generated by generative AI when used by the disabled community. Furthermore, we expect to comprehend which algorithmic factors are the
    
[^20]: 对大规模属性图上的节点表示学习进行标签解卷积以抵抗学习偏差的研究

    Label Deconvolution for Node Representation Learning on Large-scale Attributed Graphs against Learning Bias. (arXiv:2309.14907v1 [cs.LG])

    [http://arxiv.org/abs/2309.14907](http://arxiv.org/abs/2309.14907)

    本文提出了一种标签解卷积技术(LD)，通过对图神经网络(GNNs)的逆映射进行高效的近似，来解决在大规模属性图上进行节点表示学习时的学习偏差挑战。

    

    在带属性的图中，节点表示学习对许多重要的下游任务起着关键作用。为了同时编码属性和图结构，最近的研究将预训练模型与图神经网络(GNNs)进行整合，其中预训练模型作为节点编码器(NEs)来编码属性。由于在大规模图上同时训练大型NEs和GNNs存在严重的可伸缩性问题，许多方法提出了分别训练NEs和GNNs的方法。因此，在NEs的训练阶段中，他们没有考虑到GNNs中的特征卷积，导致了与联合训练相比的显著学习偏差。为了解决这个挑战，我们提出了一种高效的标签正则化技术，即标签解卷积(LD)，通过对GNNs的逆映射进行新颖且高度可伸缩的近似，以减轻学习偏差。

    Node representation learning on attributed graphs -- whose nodes are associated with rich attributes (e.g., texts and protein sequences) -- plays a crucial role in many important downstream tasks. To encode the attributes and graph structures simultaneously, recent studies integrate pre-trained models with graph neural networks (GNNs), where pre-trained models serve as node encoders (NEs) to encode the attributes. As jointly training large NEs and GNNs on large-scale graphs suffers from severe scalability issues, many methods propose to train NEs and GNNs separately. Consequently, they do not take feature convolutions in GNNs into consideration in the training phase of NEs, leading to a significant learning bias from that by the joint training. To address this challenge, we propose an efficient label regularization technique, namely Label Deconvolution (LD), to alleviate the learning bias by a novel and highly scalable approximation to the inverse mapping of GNNs. The inverse mapping l
    
[^21]: 可解释的AI艺术中的可持续性

    Explainable Sustainability for AI in the Arts. (arXiv:2309.14877v1 [cs.HC])

    [http://arxiv.org/abs/2309.14877](http://arxiv.org/abs/2309.14877)

    这篇论文介绍了为AI艺术开发环境可持续性反思系统的两个实证研究，并引入了可解释的AI艺术中的可持续性。

    

    AI在艺术实践中越来越受欢迎，但是用于通知从业者有关AI的环境影响（以及其他可持续性问题）的工具适用于其他背景环境，而非创意实践背景，这使得艺术家和创意从业者无法获取AI工具和可持续性问题的相关信息。在这篇立场论文中，我描述了两个旨在为AI艺术开发环境可持续性反思系统的经验研究，并讨论和介绍了可解释的AI艺术中的可持续性。

    AI is becoming increasingly popular in artistic practices, but the tools for informing practitioners about the environmental impact (and other sustainability implications) of AI are adapted for other contexts than creative practices -- making the tools and sustainability implications of AI not accessible for artists and creative practitioners. In this position paper, I describe two empirical studies that aim to develop environmental sustainability reflection systems for AI Arts, and discuss and introduce Explainable Sustainability in for AI Arts.
    
[^22]: 导航文本到图像定制：从LyCORIS微调到模型评估

    Navigating Text-To-Image Customization:From LyCORIS Fine-Tuning to Model Evaluation. (arXiv:2309.14859v1 [cs.CV])

    [http://arxiv.org/abs/2309.14859](http://arxiv.org/abs/2309.14859)

    本文介绍了LyCORIS，一个开源库，提供了多种稳定扩散模型的微调方法，并提出了一个系统评估的全面框架。

    

    文本到图像生成模型因其能够从文本提示生成高保真度图像而受到广泛关注。其中，稳定扩散模型作为领先的开源模型在这个快速发展的领域中表现出色。然而，微调这些模型的复杂性给新方法的整合和系统评估带来了多重挑战。本文介绍了LyCORIS（Lora beYond Conventional methods，Other Rank adaptation Implementations for Stable diffusion）[https://github.com/KohakuBlueleaf/LyCORIS]，这是一个开源库，提供了多种稳定扩散模型的微调方法。此外，我们还提出了一个系统评估的全面框架，该框架采用了多样化的指标，并深入研究了微调的多个方面，包括超参数调整和在不同概念类别下使用不同提示类型的评估。

    Text-to-image generative models have garnered immense attention for their ability to produce high-fidelity images from text prompts. Among these, Stable Diffusion distinguishes itself as a leading open-source model in this fast-growing field. However, the intricacies of fine-tuning these models pose multiple challenges from new methodology integration to systematic evaluation. Addressing these issues, this paper introduces LyCORIS (Lora beYond Conventional methods, Other Rank adaptation Implementations for Stable diffusion) [https://github.com/KohakuBlueleaf/LyCORIS], an open-source library that offers a wide selection of fine-tuning methodologies for Stable Diffusion. Furthermore, we present a thorough framework for the systematic assessment of varied fine-tuning techniques. This framework employs a diverse suite of metrics and delves into multiple facets of fine-tuning, including hyperparameter adjustments and the evaluation with different prompt types across various concept categori
    
[^23]: Supersonic: 学习在C/C++中生成源代码优化

    Supersonic: Learning to Generate Source Code Optimisations in C/C++. (arXiv:2309.14846v1 [cs.SE])

    [http://arxiv.org/abs/2309.14846](http://arxiv.org/abs/2309.14846)

    Supersonic 是一个神经方法，用于在C/C++中进行源代码优化。与GPT-3.5-Turbo和GPT-4相比，它在代码优化任务上表现更好，并且改变的程度更小。

    

    软件优化在保持功能的同时改善资源效率。传统上，这是由开发人员和编译器完成的过程。本文介绍了第三种选择，即在源代码级别进行自动优化。我们提出了Supersonic，一个针对优化的轻微源代码修改的神经方法。使用seq2seq模型，Supersonic在C / C ++程序对（$x_{t}$，$x_{t+1}$）上进行训练，其中$x_{t+1}$是$x_{t}$的优化版本，并输出一个差异。Supersonic的性能在竞技编程任务上与OpenAI的GPT-3.5-Turbo和GPT-4进行了基准测试。实验表明，Supersonic不仅在代码优化任务上胜过了这两个模型，而且改变的程度比GPT-3.5-Turbo小了600多倍，比GPT-4小了3700多倍。

    Software optimization refines programs for resource efficiency while preserving functionality. Traditionally, it is a process done by developers and compilers. This paper introduces a third option, automated optimization at the source code level. We present Supersonic, a neural approach targeting minor source code modifications for optimization. Using a seq2seq model, Supersonic is trained on C/C++ program pairs ($x_{t}$, $x_{t+1}$), where $x_{t+1}$ is an optimized version of $x_{t}$, and outputs a diff. Supersonic's performance is benchmarked against OpenAI's GPT-3.5-Turbo and GPT-4 on competitive programming tasks. The experiments show that Supersonic not only outperforms both models on the code optimization task, but also minimizes the extent of change with a more than 600x smaller than GPT-3.5-Turbo and 3700x smaller than GPT-4.
    
[^24]: 重新审视用于连续学习中的Softmax掩码以提高稳定性

    Revisiting Softmax Masking for Stability in Continual Learning. (arXiv:2309.14808v1 [cs.LG])

    [http://arxiv.org/abs/2309.14808](http://arxiv.org/abs/2309.14808)

    本文重新审视了用于连续学习中的Softmax掩码的影响，并提出了一种利用其置信度保持效果的方法，通过增加稳定性同时保持准确性。

    

    在连续学习中，许多分类器使用Softmax函数来学习置信度。然而，许多研究指出其无法准确确定离群值的置信度分布，通常称为认识不确定性。这种固有限制还限制了在连续学习过程中选择何时忘记和保留先前训练的置信度分布的准确决策。为了解决这个问题，我们重新审视了掩码Softmax函数的影响。尽管这种方法在文献中既简单又普遍，但对于在连续学习过程中保持置信度分布（也称为稳定性）的影响尚未得到充分调查。在本文中，我们重新审视了Softmax掩码的影响，并引入了一种利用其置信度保持效果的方法。在具有和不具有记忆重放的类-和任务增量学习基准测试中，我们的方法显著增加了稳定性同时保持了足够大的准确性。

    In continual learning, many classifiers use softmax function to learn confidence. However, numerous studies have pointed out its inability to accurately determine confidence distributions for outliers, often referred to as epistemic uncertainty. This inherent limitation also curtails the accurate decisions for selecting what to forget and keep in previously trained confidence distributions over continual learning process. To address the issue, we revisit the effects of masking softmax function. While this method is both simple and prevalent in literature, its implication for retaining confidence distribution during continual learning, also known as stability, has been under-investigated. In this paper, we revisit the impact of softmax masking, and introduce a methodology to utilize its confidence preservation effects. In class- and task-incremental learning benchmarks with and without memory replay, our approach significantly increases stability while maintaining sufficiently large pla
    
[^25]: 评估足球比赛预测模型：深度学习方法和梯度增强树特征优化的研究

    Evaluating Soccer Match Prediction Models: A Deep Learning Approach and Feature Optimization for Gradient-Boosted Trees. (arXiv:2309.14807v1 [cs.LG])

    [http://arxiv.org/abs/2309.14807](http://arxiv.org/abs/2309.14807)

    本研究评估了足球比赛预测模型，并采用深度学习方法和梯度增强树特征优化。研究发现，在这个特定的任务中，深度学习模型经常被忽视。

    

    机器学习模型越来越受欢迎地用于预测足球比赛结果，然而，缺乏公开的基准数据集使得模型评估变得具有挑战性。2023年足球预测挑战要求首先预测每支球队的准确进球数，其次预测胜负平的概率。竞赛提供了原始的训练集和特征，但还增加了在2023年4月4日至4月13日期间进行的额外比赛，这代表了训练集截止日期到首次预测比赛之间的时期（用于评估性能）。使用pi-ratings作为特征的CatBoost模型被应用，最初被确定为计算胜负平概率的最佳选择。值得注意的是，深度学习模型在这个特定任务中经常被忽视。

    Machine learning models have become increasingly popular for predicting the results of soccer matches, however, the lack of publicly-available benchmark datasets has made model evaluation challenging. The 2023 Soccer Prediction Challenge required the prediction of match results first in terms of the exact goals scored by each team, and second, in terms of the probabilities for a win, draw, and loss. The original training set of matches and features, which was provided for the competition, was augmented with additional matches that were played between 4 April and 13 April 2023, representing the period after which the training set ended, but prior to the first matches that were to be predicted (upon which the performance was evaluated). A CatBoost model was employed using pi-ratings as the features, which were initially identified as the optimal choice for calculating the win/draw/loss probabilities. Notably, deep learning models have frequently been disregarded in this particular task. 
    
[^26]: 细调和对齐问题回答模型以进行复杂信息提取任务

    Fine-tuning and aligning question answering models for complex information extraction tasks. (arXiv:2309.14805v1 [cs.CL])

    [http://arxiv.org/abs/2309.14805](http://arxiv.org/abs/2309.14805)

    本文提出了一种使用抽取型QA模型进行信息提取的方法，以解决大型语言模型在文档分析中的应用限制。实验结果表明，细调德语QA模型可以提高针对定制化信息提取任务的性能。

    

    大型语言模型(LLMs)的出现提升了各种自然语言处理任务的性能和可能性。尽管像ChatGPT这样的生成型AI模型为一些商业用例开启了新的机会，但其当前倾向于产生虚假内容的特点严重限制了其在文档分析(如从文档中检索信息)方面的适用性。相反，像问题回答(QA)或段落检索模型这样的抽取型语言模型保证查询结果在相应上下文文档的边界内，使其成为公司生产环境中更可靠的信息提取候选模型。在这项工作中，我们提出了一种方法，使用和整合抽取型QA模型来改进对德语商业文档(如保险报告或药品说明书)的特征提取，形成一个文档分析解决方案。我们还展示了细调现有德语QA模型可以提升针对定制化信息提取的性能。

    The emergence of Large Language Models (LLMs) has boosted performance and possibilities in various NLP tasks. While the usage of generative AI models like ChatGPT opens up new opportunities for several business use cases, their current tendency to hallucinate fake content strongly limits their applicability to document analysis, such as information retrieval from documents. In contrast, extractive language models like question answering (QA) or passage retrieval models guarantee query results to be found within the boundaries of an according context document, which makes them candidates for more reliable information extraction in productive environments of companies. In this work we propose an approach that uses and integrates extractive QA models for improved feature extraction of German business documents such as insurance reports or medical leaflets into a document analysis solution. We further show that fine-tuning existing German QA models boosts performance for tailored extractio
    
[^27]: 考虑遗忘的线性偏差对注重型知识追踪的影响

    Forgetting-aware Linear Bias for Attentive Knowledge Tracing. (arXiv:2309.14796v1 [cs.AI])

    [http://arxiv.org/abs/2309.14796](http://arxiv.org/abs/2309.14796)

    本文提出了FoLiBi方法，通过考虑学习者的遗忘行为作为线性偏差的形式，结合现有的注重型知识追踪（KT）模型，解决了现有模型忽略学习者遗忘行为的问题，实验结果显示与多个KT模型结合使用可以显著提高效果

    

    知识追踪（KT）旨在基于问题解决历史追踪学习熟练度，以便为我们提供一套流畅的课程。最近的研究积极利用基于注意力的机制来捕捉问题的相关性，并结合学习者的特征来进行响应。然而，我们的实证研究表明，现有的基于注意力的KT模型忽略了学习者的遗忘行为，尤其是当互动历史变得更长时。这个问题源于过度优先考虑问题的相关性，无意中忽视了遗忘行为的影响。本文提出了一个简单但有效的解决方案，即考虑遗忘的线性偏差（FoLiBi），以反映遗忘行为作为线性偏差。尽管简单，但FoLiBi通过有效地分解问题的相关性和遗忘行为，可以方便地与现有的注重型KT模型配合使用。将FoLiBi与几个KT模型结合使用可以获得一致的改进

    Knowledge Tracing (KT) aims to track proficiency based on a question-solving history, allowing us to offer a streamlined curriculum. Recent studies actively utilize attention-based mechanisms to capture the correlation between questions and combine it with the learner's characteristics for responses. However, our empirical study shows that existing attention-based KT models neglect the learner's forgetting behavior, especially as the interaction history becomes longer. This problem arises from the bias that overprioritizes the correlation of questions while inadvertently ignoring the impact of forgetting behavior. This paper proposes a simple-yet-effective solution, namely Forgetting-aware Linear Bias (FoLiBi), to reflect forgetting behavior as a linear bias. Despite its simplicity, FoLiBi is readily equipped with existing attentive KT models by effectively decomposing question correlations with forgetting behavior. FoLiBi plugged with several KT models yields a consistent improvement 
    
[^28]: 基于运动数据的交通灯-车道分配语义地图学习

    Semantic Map Learning of Traffic Light to Lane Assignment based on Motion Data. (arXiv:2309.14793v1 [cs.CV])

    [http://arxiv.org/abs/2309.14793](http://arxiv.org/abs/2309.14793)

    本论文介绍了一种基于运动数据的交通灯-车道分配语义地图学习的方法，通过统计方法自动推导交通灯到车道的分配，并且提出了安全考虑和数据集转换方法来提高效果和扩展性。

    

    理解哪个交通灯控制哪个车道对于安全通过路口至关重要。自动驾驶车辆通常依赖包含交通灯-车道分配信息的高清地图。手动提供这些信息既费时又昂贵，而且不可扩展。为了解决这些问题，我们提出了一种新颖的方法，利用交通灯状态和车辆运动模式推导出分配方式。该方法自动化并且不依赖几何排列。我们通过实现和评估基于模式的贡献方法展示了基本统计方法在这个任务上的有效性。此外，我们的新颖的拒绝方法通过利用统计假设检验考虑了安全因素。最后，我们提出了一种数据集转换方法，以重新利用现有的运动预测数据集进行语义地图学习。我们还提供了适用于Lyft Level 5数据集的公开API。

    Understanding which traffic light controls which lane is crucial to navigate intersections safely. Autonomous vehicles commonly rely on High Definition (HD) maps that contain information about the assignment of traffic lights to lanes. The manual provisioning of this information is tedious, expensive, and not scalable. To remedy these issues, our novel approach derives the assignments from traffic light states and the corresponding motion patterns of vehicle traffic. This works in an automated way and independently of the geometric arrangement. We show the effectiveness of basic statistical approaches for this task by implementing and evaluating a pattern-based contribution method. In addition, our novel rejection method includes accompanying safety considerations by leveraging statistical hypothesis testing. Finally, we propose a dataset transformation to re-purpose available motion prediction datasets for semantic map learning. Our publicly available API for the Lyft Level 5 dataset 
    
[^29]: 使用提示学习范式探索小型语言模型在高效领域特定文本分类中的应用

    Exploring Small Language Models with Prompt-Learning Paradigm for Efficient Domain-Specific Text Classification. (arXiv:2309.14779v1 [cs.CL])

    [http://arxiv.org/abs/2309.14779](http://arxiv.org/abs/2309.14779)

    本研究探索了将小型语言模型（SLMs）与提示学习范式结合应用于领域特定文本分类的潜力，并在零售业的客户和代理人交互中进行了评估。结果显示，在有限的标记数据下，SLM T5-base能够实现约75%的准确率，展现了SLMs与提示学习的潜力。

    

    面对手动标记的高成本，领域特定文本分类面临稀缺的标记数据的挑战。提示学习作为传统微调方法的替代方案，在少样本场景中表现出高效性。此外，虽然大型语言模型（LLMs）已经引起了关注，但小型语言模型（SLMs，小于10亿个参数）在领域特定任务中具有显著的定制性、适应性和成本效益，符合工业约束。本研究探讨了将SLMs与提示学习范式结合应用于领域特定文本分类的潜力，尤其是在零售业的客户和代理人交互中。我们的评估结果显示，在少样本的情况下，当可以进行基于提示的模型微调时，具有220M参数的典型SLM T5-base能够在有限的标记数据上实现约75%的准确率（达到完整数据的15%），显示出SLMs与提示学习的巨大潜力。

    Domain-specific text classification faces the challenge of scarce labeled data due to the high cost of manual labeling. Prompt-learning, known for its efficiency in few-shot scenarios, is proposed as an alternative to traditional fine-tuning methods. And besides, although large language models (LLMs) have gained prominence, small language models (SLMs, with under 1B parameters) offer significant customizability, adaptability, and cost-effectiveness for domain-specific tasks, given industry constraints. In this study, we investigate the potential of SLMs combined with prompt-learning paradigm for domain-specific text classification, specifically within customer-agent interactions in retail. Our evaluations show that, in few-shot settings when prompt-based model fine-tuning is possible, T5-base, a typical SLM with 220M parameters, achieve approximately 75% accuracy with limited labeled data (up to 15% of full data), which shows great potentials of SLMs with prompt-learning. Based on this
    
[^30]: 使用事实知识提升上下文学习的效果

    Boosting In-Context Learning with Factual Knowledge. (arXiv:2309.14771v1 [cs.CL])

    [http://arxiv.org/abs/2309.14771](http://arxiv.org/abs/2309.14771)

    本文研究了使用事实知识提升上下文学习的效果，并提出了一个新的知识上下文调优框架来改善学习性能。

    

    在大型语言模型上下文学习（ICL）旨在通过依赖于少量的训练示例解决以前未见过的任务，从而消除参数更新的需求，并实现有竞争力的性能。本文展示了事实知识在ICL的性能中的重要性，包括在LLM中学到的固有知识，从所选的上下文示例中得出的事实知识，以及LLM在输出生成中的知识偏差。为了发挥LLM在少样本学习场景中的能力，我们引入了一种新的知识上下文调优（KICT）框架来进一步提高ICL的性能：1）在持续自监督预训练期间向LLM注入事实知识，2）谨慎选择具有高知识相关性的示例，3）根据先前的知识对预测结果进行校准。我们在自回归LLM（如GPT风格模型）上评估了所提出的方法。

    In-Context Learning (ICL) over Large language models (LLMs) aims at solving previously unseen tasks by conditioning on a few training examples, eliminating the need for parameter updates and achieving competitive performance. In this paper, we demonstrate that factual knowledge is imperative for the performance of ICL in three core facets, i.e., the inherent knowledge learned in LLMs, the factual knowledge derived from the selected in-context examples, and the knowledge biases in LLMs for output generation. To unleash the power of LLMs in few-shot learning scenarios, we introduce a novel Knowledgeable In-Context Tuning (KICT) framework to further improve the performance of ICL: 1) injecting factual knowledge to LLMs during continual self-supervised pre-training, 2) judiciously selecting the examples with high knowledge relevance, and 3) calibrating the prediction results based on prior knowledge. We evaluate the proposed approaches on auto-regressive LLMs (e.g., GPT-style models) over 
    
[^31]: 使用CodeT5进行最小编辑的程序修复

    Program Repair with Minimal Edits Using CodeT5. (arXiv:2309.14760v1 [cs.CL])

    [http://arxiv.org/abs/2309.14760](http://arxiv.org/abs/2309.14760)

    本文提出了一种使用CodeT5进行最小编辑的程序修复的方法，该方法通过在错误和正确程序的代码对上对预训练的CodeT5进行微调，实验结果表明其效果良好。

    

    程序员往往难以识别和修复程序中的错误。近年来，许多语言模型（LM）已经被提出用来修复错误的程序并支持错误恢复。然而，LMs往往会生成与原始输入程序不同的解决方案。这可能导致用户的理解困难。在本文中，我们提出了一种使用CodeT5建议进行最小修复编辑的正确程序的方法。我们在错误和正确程序的代码对上对预先训练的CodeT5进行微调，并使用几个基准模型评估其性能。实验结果表明，经过微调的CodeT5的通过率为91.95%，最相似的正确程序的平均编辑距离为6.84，这表明至少可以通过生成100个候选程序来建议一个正确的程序。我们展示了语言模型在解决初级编程问题时建议使用最小编辑的程序修复的有效性。

    Programmers often struggle to identify and fix bugs in their programs. In recent years, many language models (LMs) have been proposed to fix erroneous programs and support error recovery. However, the LMs tend to generate solutions that differ from the original input programs. This leads to potential comprehension difficulties for users. In this paper, we propose an approach to suggest a correct program with minimal repair edits using CodeT5. We fine-tune a pre-trained CodeT5 on code pairs of wrong and correct programs and evaluate its performance with several baseline models. The experimental results show that the fine-tuned CodeT5 achieves a pass@100 of 91.95% and an average edit distance of the most similar correct program of 6.84, which indicates that at least one correct program can be suggested by generating 100 candidate programs. We demonstrate the effectiveness of LMs in suggesting program repair with minimal edits for solving introductory programming problems.
    
[^32]: 通过无人机群实现大规模物联网的年龄最小化：一种多智能体强化学习方法

    Age Minimization in Massive IoT via UAV Swarm: A Multi-agent Reinforcement Learning Approach. (arXiv:2309.14757v1 [cs.LG])

    [http://arxiv.org/abs/2309.14757](http://arxiv.org/abs/2309.14757)

    本论文通过应用多智能体深度强化学习方法，利用无人机群从物联网设备收集实时信息，以实现大规模物联网中信息的年龄最小化。研究结果表明，合作和部分合作的多智能体深度强化学习方法能够优于传统的集中式深度强化学习方法，在大规模网络中具有更好的性能表现。

    

    在许多大规模物联网通信场景中，物联网设备需要由能够靠近物联网设备并减少上行能量消耗的动态单元进行覆盖。一种强大的解决方案是部署大量无人机（无人机群）提供覆盖并为物联网网络提供更好的视线连通性。然而，研究这些具有大量服务单元的大规模物联网场景会引导出具有高复杂性的高维问题。在本文中，我们应用多智能体深度强化学习来解决由部署无人机群从物联网设备收集实时信息引起的高维问题。目标是将物联网网络中的信息年龄最小化。结果表明，合作和部分合作的多智能体深度强化学习方法能够胜过高复杂性的集中式深度强化学习方法，在大规模网络中表现出无能为力。

    In many massive IoT communication scenarios, the IoT devices require coverage from dynamic units that can move close to the IoT devices and reduce the uplink energy consumption. A robust solution is to deploy a large number of UAVs (UAV swarm) to provide coverage and a better line of sight (LoS) for the IoT network. However, the study of these massive IoT scenarios with a massive number of serving units leads to high dimensional problems with high complexity. In this paper, we apply multi-agent deep reinforcement learning to address the high-dimensional problem that results from deploying a swarm of UAVs to collect fresh information from IoT devices. The target is to minimize the overall age of information in the IoT network. The results reveal that both cooperative and partially cooperative multi-agent deep reinforcement learning approaches are able to outperform the high-complexity centralized deep reinforcement learning approach, which stands helpless in large-scale networks.
    
[^33]: 基于不同检索和问答模型的印度法律问答系统的人工智能比较分析

    Comparative Analysis of Artificial Intelligence for Indian Legal Question Answering (AILQA) Using Different Retrieval and QA Models. (arXiv:2309.14735v1 [cs.CL])

    [http://arxiv.org/abs/2309.14735](http://arxiv.org/abs/2309.14735)

    本文对印度法律问答系统的人工智能模型进行比较分析，发现现有的AILQA系统能够自动解析用户的自然语言查询并生成高度准确的响应。

    

    法律问答（QA）系统有潜力改变法律专业人士与案例文件的互动方式。本文对现有的人工智能模型进行了比较分析，以评估其在印度法律体系下回答法律问题的效用，特别关注印度法律问答（AILQA）并研究了当前可用的不同检索和QA算法的有效性。利用OpenAI GPT模型作为基准，结合查询提示，我们的研究表明现有的AILQA系统能够自动解析用户的自然语言查询并生成高度准确的响应。本研究特别关注印度刑事司法领域的应用，该领域由于复杂性和资源限制而面临一系列挑战。为了严格评估这些模型的性能，经验证评估与从实践中获得的反馈相结合。

    Legal question-answering (QA) systems have the potential to revolutionize the way legal professionals interact with case law documents. This paper conducts a comparative analysis of existing artificial intelligence models for their utility in answering legal questions within the Indian legal system, specifically focusing on Indian Legal Question Answering (AILQA) and our study investigates the efficacy of different retrieval and QA algorithms currently available. Utilizing the OpenAI GPT model as a benchmark, along with query prompts, our investigation shows that existing AILQA systems can automatically interpret natural language queries from users and generate highly accurate responses. This research is particularly focused on applications within the Indian criminal justice domain, which has its own set of challenges due to its complexity and resource constraints. In order to rigorously assess the performance of these models, empirical evaluations are complemented by feedback from pra
    
[^34]: 高效的多智能体深度强化学习控制与相对熵正则化

    Effective Multi-Agent Deep Reinforcement Learning Control with Relative Entropy Regularization. (arXiv:2309.14727v1 [eess.SY])

    [http://arxiv.org/abs/2309.14727](http://arxiv.org/abs/2309.14727)

    本文提出了一种新的多智能体强化学习方法，通过相对熵正则化解决了多个智能体策略更新的不一致性问题，并证明在多智能体合作和竞争任务以及传统控制任务中表现出显著的学习能力和样本效率。

    

    本文提出了一种新颖的多智能体强化学习（MARL）方法，即多智能体连续动态策略梯度（MACDPP），用于解决多个智能体控制的各种场景中存在的能力有限和样本效率问题。通过引入相对熵正则化到中心化训练与分散执行（CTDE）框架中的Actor-Critic（AC）结构，它缓解了多个智能体策略更新的不一致性。通过对多智能体合作和竞争任务以及包括OpenAI基准和机械臂操作在内的传统控制任务的评估，MACDPP在学习能力和样本效率方面相较于相关的多智能体和广泛使用的单智能体基线表现出显著优势，因此扩展了MARL在有效学习具有挑战性的控制场景中的潜力。

    In this paper, a novel Multi-agent Reinforcement Learning (MARL) approach, Multi-Agent Continuous Dynamic Policy Gradient (MACDPP) was proposed to tackle the issues of limited capability and sample efficiency in various scenarios controlled by multiple agents. It alleviates the inconsistency of multiple agents' policy updates by introducing the relative entropy regularization to the Centralized Training with Decentralized Execution (CTDE) framework with the Actor-Critic (AC) structure. Evaluated by multi-agent cooperation and competition tasks and traditional control tasks including OpenAI benchmarks and robot arm manipulation, MACDPP demonstrates significant superiority in learning capability and sample efficiency compared with both related multi-agent and widely implemented signal-agent baselines and therefore expands the potential of MARL in effectively learning challenging control scenarios.
    
[^35]: PLMM：移动设备上的个人大型模型

    PLMM: Personal Large Models on Mobile Devices. (arXiv:2309.14726v1 [cs.CV])

    [http://arxiv.org/abs/2309.14726](http://arxiv.org/abs/2309.14726)

    本文提出了一种从传统大型语言模型中提取的个人大型模型，该模型更适应于本地用户的个人信息，并且能够保护用户的隐私。该模型分为个人级别、专家级别和传统级别，同时还需要小型化以适应个人计算机或移动设备，并实现实时响应以提供更好的用户体验。

    

    在本文中，受到联邦学习的启发，我们提出了从传统大型语言模型中提取的个人大型模型，这些模型更适应本地用户的个人信息，如教育背景和爱好。我们将大型语言模型分为三个级别：个人级别，专家级别和传统级别。个人级别模型适应用户的个人信息，对用户的输入进行加密并保护其隐私。专家级别模型专注于合并特定领域的知识，如金融、IT和艺术。传统模型专注于普遍知识的发现和提升专家模型。在这样的分类中，个人模型直接与用户交互。对于整个系统来说，个人模型具有用户的（加密的）个人信息。此外，这些模型必须足够小以在个人计算机或移动设备上运行。最后，它们还必须实时响应，以提供更好的用户体验。

    Inspired by Federated Learning, in this paper, we propose personal large models that are distilled from traditional large language models but more adaptive to local users' personal information such as education background and hobbies. We classify the large language models into three levels: the personal level, expert level and traditional level. The personal level models are adaptive to users' personal information. They encrypt the users' input and protect their privacy. The expert level models focus on merging specific knowledge such as finance, IT and art. The traditional models focus on the universal knowledge discovery and upgrading the expert models. In such classifications, the personal models directly interact with the user. For the whole system, the personal models have users' (encrypted) personal information. Moreover, such models must be small enough to be performed on personal computers or mobile devices. Finally, they also have to response in real-time for better user exper
    
[^36]: 优化人工智能和人类协作代理之间的委派

    Optimizing delegation between human and AI collaborative agents. (arXiv:2309.14718v1 [cs.AI])

    [http://arxiv.org/abs/2309.14718](http://arxiv.org/abs/2309.14718)

    该研究提出了一种优化人工智能和人类协作代理之间委派的方法，通过训练一个代理管理器根据任务绩效缺陷进行委派决策，并且可以处理不同环境表示下的团队操作。方法在实验中表现显著优于其他管理团队的方法。

    

    在人类与人工智能或自主代理形成混合团队的情景中，精确地确定何时授权团队成员执行行动是至关重要的。鉴于过去的例子中，人类和自主系统在任务上可能成功也可能失败，我们试图训练一个代理管理器来根据这些潜在的绩效缺陷做出委派决策。此外，我们不能总是期望各种代理在相同的环境模型中运行。可能会遇到代理之间的行动和转换有所不同的情况。因此，我们的框架提供了一个经过观察团队绩效学习的管理模型，而不限制代理与匹配的动态。我们的结果表明，我们的管理器能够在操作环境的不同表示下进行委派决策，远远超过了其他管理团队方法。

    In the context of humans operating with artificial or autonomous agents in a hybrid team, it is essential to accurately identify when to authorize those team members to perform actions. Given past examples where humans and autonomous systems can either succeed or fail at tasks, we seek to train a delegating manager agent to make delegation decisions with respect to these potential performance deficiencies. Additionally, we cannot always expect the various agents to operate within the same underlying model of the environment. It is possible to encounter cases where the actions and transitions would vary between agents. Therefore, our framework provides a manager model which learns through observations of team performance without restricting agents to matching dynamics. Our results show our manager learns to perform delegation decisions with teams of agents operating under differing representations of the environment, significantly outperforming alternative methods to manage the team.
    
[^37]: 人工生成的演示是否对于上下文学习有必要？

    Are Human-generated Demonstrations Necessary for In-context Learning?. (arXiv:2309.14681v1 [cs.LG])

    [http://arxiv.org/abs/2309.14681](http://arxiv.org/abs/2309.14681)

    本文研究了上下文学习中人工生成的演示是否有必要，并提出了一种新的自反思提示策略（SEC），通过这种策略，大型语言模型（LLMs）可以自行生成演示和最终输出，避免了手动生成过程的复杂性。

    

    尽管大型语言模型（LLMs）具备良好的少样本能力，但在上下文学习（ICL）的标准范式中存在以下弊端：易受选定演示的影响，生成这些演示的复杂性。本文提出了对于ICL，人工生成的演示是否有必要的基本问题，并提出了自反思提示策略（SEC），这是一种不依赖人工演示的范例。SEC的关键点在于，不使用手工制作的示例作为ICL中的演示，而是要求LLMs首先自行创建演示，然后生成最终输出。SEC是一种灵活的框架，可适应原始ICL和“思维链”（CoT），并且更加便捷：因为可以节省示例和理由的手动生成过程。在算术推理、常识推理和多任务语言理解方面进行了大量实验。

    Despite the promising few-shot ability of large language models (LLMs), the standard paradigm of In-context Learning (ICL) suffers the disadvantages of susceptibility to selected demonstrations and the intricacy to generate these demonstrations. In this paper, we raise the fundamental question that whether human-generated demonstrations are necessary for ICL. To answer this question, we propose self-contemplation prompting strategy (SEC), a paradigm free from human-crafted demonstrations. The key point of SEC is that, instead of using hand-crafted examples as demonstrations in ICL, SEC asks LLMs to first create demonstrations on their own, based on which the final output is generated. SEC is a flexible framework and can be adapted to both the vanilla ICL and the chain-of-thought (CoT), but with greater ease: as the manual-generation process of both examples and rationale can be saved. Extensive experiments in arithmetic reasoning, commonsense reasoning, multi-task language understandin
    
[^38]: XGV-BERT:利用上下文化语言模型和图神经网络进行高效的软件漏洞检测

    XGV-BERT: Leveraging Contextualized Language Model and Graph Neural Network for Efficient Software Vulnerability Detection. (arXiv:2309.14677v1 [cs.CR])

    [http://arxiv.org/abs/2309.14677](http://arxiv.org/abs/2309.14677)

    XGV-BERT提出了一种结合了预训练的CodeBERT模型和图神经网络（GCN）的框架，用于高效的软件漏洞检测。研究结果表明，XGV-BERT相比其他方法显著提高了漏洞检测的准确性。

    

    随着深度学习在各个领域的发展，通过数据驱动方法揭示软件漏洞的尝试越来越多。然而，现有的工作缺乏能够保留源代码属性的非顺序语义特征和上下文关系的有效表示。因此，在这项工作中，我们提出了XGV-BERT，这是一种结合了预训练的CodeBERT模型和图神经网络（GCN）用于检测软件漏洞的框架。通过在XGV-BERT中联合训练CodeBERT和GCN模块，所提出的模型利用了大规模预训练、利用庞大原始数据和通过图卷积学习训练数据的迁移学习的优势。研究结果表明，与VulDeePecker和SySeVR等两种现有方法相比，XGV-BERT方法显著提高了漏洞检测的准确性。对于VulDeePecker数据集，XGV-BERT取得了令人印象深刻的F1-s

    With the advancement of deep learning (DL) in various fields, there are many attempts to reveal software vulnerabilities by data-driven approach. Nonetheless, such existing works lack the effective representation that can retain the non-sequential semantic characteristics and contextual relationship of source code attributes. Hence, in this work, we propose XGV-BERT, a framework that combines the pre-trained CodeBERT model and Graph Neural Network (GCN) to detect software vulnerabilities. By jointly training the CodeBERT and GCN modules within XGV-BERT, the proposed model leverages the advantages of large-scale pre-training, harnessing vast raw data, and transfer learning by learning representations for training data through graph convolution. The research results demonstrate that the XGV-BERT method significantly improves vulnerability detection accuracy compared to two existing methods such as VulDeePecker and SySeVR. For the VulDeePecker dataset, XGV-BERT achieves an impressive F1-s
    
[^39]: 利用腭咽口炎数据提升基于UPTST的手足口病住院预测的准确性

    Leveraging Herpangina Data to Enhance Hospital-level Prediction of Hand-Foot-and-Mouth Disease Admissions Using UPTST. (arXiv:2309.14674v1 [cs.LG])

    [http://arxiv.org/abs/2309.14674](http://arxiv.org/abs/2309.14674)

    提出了一种新颖的基于Transformer的UPTST模型，利用腭咽口炎数据提升手足口病住院预测的准确性，且在医院级别的预测准确性上优于现有方法。

    

    手足口病（HFMD）爆发与严重的发病率和死亡率相关。因此，准确预测儿科HFMD患者的每日住院人数对于协助医院应对潜在的爆发和减少医院内传播至关重要。为了解决这一迫切需求，我们提出了一种新颖的基于Transformer的模型，它具有U-net形状，并利用了与HFMD密切相关的腭咽口炎的见解。该模型还通过引入重构损失作为辅助损失来整合表示学习。结果显示，我们的UPTST模型在医院级别的HFMD长短臂预测准确性方面优于现有方法。此外，探索性的扩展实验表明该模型的能力超出了传染病的预测，提示...

    Outbreaks of hand-foot-and-mouth disease(HFMD) have been associated with significant morbidity and, in severe cases, mortality. Accurate forecasting of daily admissions of pediatric HFMD patients is therefore crucial for aiding the hospital in preparing for potential outbreaks and mitigating nosocomial transmissions. To address this pressing need, we propose a novel transformer-based model with a U-net shape, utilizing the patching strategy and the joint prediction strategy that capitalizes on insights from herpangina, a disease closely correlated with HFMD. This model also integrates representation learning by introducing reconstruction loss as an auxiliary loss. The results show that our U-net Patching Time Series Transformer (UPTST) model outperforms existing approaches in both long- and short-arm prediction accuracy of HFMD at hospital-level. Furthermore, the exploratory extension experiments show that the model's capabilities extend beyond prediction of infectious disease, suggest
    
[^40]: 用NEAT学习机器人群体的新颖行为

    Learning Emergent Behavior in Robot Swarms with NEAT. (arXiv:2309.14663v1 [cs.AI])

    [http://arxiv.org/abs/2309.14663](http://arxiv.org/abs/2309.14663)

    本研究提出了一种用NEAT方法训练分布式机器人群体算法产生新颖行为的方法，并通过实验验证了其在不同任务上的有效性。

    

    在研究机器人群体时，许多研究观察到复杂的群体行为是由个体智能体的简单局部动作产生的。然而，学习个体策略以产生所期望的新颖行为的任务仍然是一个具有挑战性且基本上未解决的问题。我们提出了一种训练分布式机器人群体算法以产生新颖行为的方法。受到动物中新颖行为的生物进化启发，我们使用进化算法训练一个“种群”中的个体行为来近似期望的群体行为。我们在使用CoppeliaSim模拟器进行的Georgia Tech Miniature Autonomous Blimps（GT-MABs）空中机器人平台模拟实验中进行了实验。此外，我们还在Anki Vector机器人的模拟中进行测试，以展示我们的算法在各种激励模式下的有效性。我们对需要一定复杂群体行为才能成功的各种任务进行了算法评估，其中包括一个区域C任务。

    When researching robot swarms, many studies observe complex group behavior emerging from the individual agents' simple local actions. However, the task of learning an individual policy to produce a desired emergent behavior remains a challenging and largely unsolved problem. We present a method of training distributed robotic swarm algorithms to produce emergent behavior. Inspired by the biological evolution of emergent behavior in animals, we use an evolutionary algorithm to train a 'population' of individual behaviors to approximate a desired group behavior. We perform experiments using simulations of the Georgia Tech Miniature Autonomous Blimps (GT-MABs) aerial robotics platforms conducted in the CoppeliaSim simulator. Additionally, we test on simulations of Anki Vector robots to display our algorithm's effectiveness on various modes of actuation. We evaluate our algorithm on various tasks where a somewhat complex group behavior is required for success. These tasks include an Area C
    
[^41]: 视频异常检测中的分而治之：综述与新方法

    Divide and Conquer in Video Anomaly Detection: A Comprehensive Review and New Approach. (arXiv:2309.14622v1 [cs.CV])

    [http://arxiv.org/abs/2309.14622](http://arxiv.org/abs/2309.14622)

    本文综述了近期在视频异常检测领域中应用分而治之策略的方法，并提出了一种结合人体骨骼框架和视频数据分析技术的新方法，在ShanghaiTech数据集上取得了最先进的性能。

    

    视频异常检测是一项复杂任务，而“分而治之”的原则通常被认为是解决复杂问题的有效方法。最近的视频异常检测方法揭示了分而治之理念的应用（尽管与传统用法有所不同），取得了令人印象深刻的成果。本文从六个维度系统地回顾了这些文献，旨在提升在视频异常检测中使用分而治之策略的效果。此外，基于从这个综述中获得的见解，提出了一种新颖的方法，将人体骨骼框架与视频数据分析技术相结合。该方法在ShanghaiTech数据集上取得了最先进的性能，超过了所有现有的高级方法。

    Video anomaly detection is a complex task, and the principle of "divide and conquer" is often regarded as an effective approach to tackling intricate issues. It's noteworthy that recent methods in video anomaly detection have revealed the application of the divide and conquer philosophy (albeit with distinct perspectives from traditional usage), yielding impressive outcomes. This paper systematically reviews these literatures from six dimensions, aiming to enhance the use of the divide and conquer strategy in video anomaly detection. Furthermore, based on the insights gained from this review, a novel approach is presented, which integrates human skeletal frameworks with video data analysis techniques. This method achieves state-of-the-art performance on the ShanghaiTech dataset, surpassing all existing advanced methods.
    
[^42]: 为医疗人工智能建立统一的功利伦理框架的探索

    Towards A Unified Utilitarian Ethics Framework for Healthcare Artificial Intelligence. (arXiv:2309.14617v1 [cs.CY])

    [http://arxiv.org/abs/2309.14617](http://arxiv.org/abs/2309.14617)

    本研究通过主题分析识别了对医疗人工智能的效用表现最重要的伦理原则，并提出了一个新的基于功利主义的伦理框架，以解决伦理问题。

    

    人工智能旨在通过辅助临床决策支持将医疗提升到一个巅峰。解决与设计伦理人工智能相关的挑战将使临床医生、医生、医疗专业人员和其他利益相关者能够在医疗环境中使用和信赖人工智能。本研究试图通过主题分析，识别影响人工智能在不同技术层面（如数据获取、算法和系统）的效用表现的主要伦理原则。我们观察到，正义、隐私、偏见、缺乏规定、风险和可解释性是考虑伦理人工智能的最重要原则。该数据驱动的研究通过对36位人工智能专家的皮尤研究中心（2020年）的二次调查数据进行分析，将人工智能设计的顶级伦理原则进行分类。为了解决元分析和领域专家所发现的伦理问题，我们提出了一个基于功利主义伦理的人工智能理论框架，用于设计伦理人工智能。

    Artificial Intelligence (AI) aims to elevate healthcare to a pinnacle by aiding clinical decision support. Overcoming the challenges related to the design of ethical AI will enable clinicians, physicians, healthcare professionals, and other stakeholders to use and trust AI in healthcare settings. This study attempts to identify the major ethical principles influencing the utility performance of AI at different technological levels such as data access, algorithms, and systems through a thematic analysis. We observed that justice, privacy, bias, lack of regulations, risks, and interpretability are the most important principles to consider for ethical AI. This data-driven study has analyzed secondary survey data from the Pew Research Center (2020) of 36 AI experts to categorize the top ethical principles of AI design. To resolve the ethical issues identified by the meta-analysis and domain experts, we propose a new utilitarian ethics-based theoretical framework for designing ethical AI fo
    
[^43]: 无监督的图深度学习揭示了城市地区突发洪水风险概况

    Unsupervised Graph Deep Learning Reveals Emergent Flood Risk Profile of Urban Areas. (arXiv:2309.14610v1 [cs.LG])

    [http://arxiv.org/abs/2309.14610](http://arxiv.org/abs/2309.14610)

    本研究基于无监督图深度学习模型提出了集成城市洪水风险评级模型，能够捕捉区域之间的空间依赖关系和洪水危险与城市要素之间的复杂相互作用，揭示了城市地区的突发洪水风险概况

    

    城市洪水风险源于与洪水危险、洪水暴露以及社会和物理脆弱性相关的多个要素之间的复杂和非线性相互作用，以及复杂的空间洪水依赖关系。然而，现有的用于表征城市洪水风险的方法主要是基于洪水平原地图，侧重于有限数量的要素，主要是危险和暴露要素，没有考虑要素之间的相互作用或空间区域之间的依赖关系。为了填补这一空白，本研究提出了一种基于新颖的无监督图深度学习模型（称为FloodRisk-Net）的集成城市洪水风险评级模型。FloodRisk-Net能够捕捉区域之间的空间依赖关系以及洪水危险和城市要素之间的复杂和非线性相互作用，从而确定突发洪水风险。利用美国多个都市统计区（MSAs）的数据，该模型将它们的洪水风险特征化为

    Urban flood risk emerges from complex and nonlinear interactions among multiple features related to flood hazard, flood exposure, and social and physical vulnerabilities, along with the complex spatial flood dependence relationships. Existing approaches for characterizing urban flood risk, however, are primarily based on flood plain maps, focusing on a limited number of features, primarily hazard and exposure features, without consideration of feature interactions or the dependence relationships among spatial areas. To address this gap, this study presents an integrated urban flood-risk rating model based on a novel unsupervised graph deep learning model (called FloodRisk-Net). FloodRisk-Net is capable of capturing spatial dependence among areas and complex and nonlinear interactions among flood hazards and urban features for specifying emergent flood risk. Using data from multiple metropolitan statistical areas (MSAs) in the United States, the model characterizes their flood risk into
    
[^44]: 使用FP8格式的高效后训练量化方法

    Efficient Post-training Quantization with FP8 Formats. (arXiv:2309.14592v1 [cs.LG])

    [http://arxiv.org/abs/2309.14592](http://arxiv.org/abs/2309.14592)

    本研究研究了FP8格式在后训练量化中的优势，并开发了一个通用的量化工作流程。实验结果表明，FP8相对于INT8具有更好的工作负载覆盖率和模型准确性。

    

    最近深度学习方法的进展，如LLMs和扩散模型，提出了对改进的量化方法的需求，以满足这些现代架构的计算需求，同时保持准确性。为了实现这一目标，我们研究了FP8数据格式在75个不同网络架构上进行后训练量化的优势，这些网络架构涵盖了多种任务，包括机器翻译、语言建模、文本生成、图像分类、生成和分割。我们研究了三种不同的FP8表示（E5M2、E4M3和E3M4），以研究在动态范围和精度之间不同权衡程度对模型准确性的影响。基于我们的广泛研究，我们开发了一个量化工作流程，可以概括适用于不同的网络架构。我们的实证结果表明，FP8格式在多个方面优于INT8，包括工作负载覆盖率（92.64％对65.87％）、模型准确性和适用于更广泛的操作范围。

    Recent advances in deep learning methods such as LLMs and Diffusion models have created a need for improved quantization methods that can meet the computational demands of these modern architectures while maintaining accuracy. Towards this goal, we study the advantages of FP8 data formats for post-training quantization across 75 unique network architectures covering a wide range of tasks, including machine translation, language modeling, text generation, image classification, generation, and segmentation. We examine three different FP8 representations (E5M2, E4M3, and E3M4) to study the effects of varying degrees of trade-off between dynamic range and precision on model accuracy. Based on our extensive study, we developed a quantization workflow that generalizes across different network architectures. Our empirical results show that FP8 formats outperform INT8 in multiple aspects, including workload coverage (92.64% vs. 65.87%), model accuracy and suitability for a broader range of ope
    
[^45]: 目标导向语义通信的联合通信和计算框架，具有畸变率鲁棒性

    Joint Communication and Computation Framework for Goal-Oriented Semantic Communication with Distortion Rate Resilience. (arXiv:2309.14587v1 [cs.LG])

    [http://arxiv.org/abs/2309.14587](http://arxiv.org/abs/2309.14587)

    本论文提出了一个创新的联合通信和计算框架，利用率畸变理论来分析通信和语义压缩引起的畸变，从而评估其对目标导向语义通信中人工智能模型性能的影响，使目标导向语义通信问题成为可能。

    

    最近关于语义通信的研究主要考虑准确性作为优化目标导向通信系统的主要问题。然而，这些方法引入了一个悖论：人工智能任务的准确性应该通过训练自然地出现，而不是由网络约束所决定。鉴于这个困境，本文引入了一种创新的方法，利用率畸变理论来分析由通信和语义压缩引起的畸变，并分析学习过程。具体来说，我们研究了原始数据和畸变数据之间的分布偏移，从而评估其对人工智能模型性能的影响。基于这个分析，我们可以预先估计人工智能任务的实际准确性，使目标导向语义通信问题变得可行。为了实现这个目标，我们提出了我们方法的理论基础，并进行了模拟和实验。

    Recent research efforts on semantic communication have mostly considered accuracy as a main problem for optimizing goal-oriented communication systems. However, these approaches introduce a paradox: the accuracy of artificial intelligence (AI) tasks should naturally emerge through training rather than being dictated by network constraints. Acknowledging this dilemma, this work introduces an innovative approach that leverages the rate-distortion theory to analyze distortions induced by communication and semantic compression, thereby analyzing the learning process. Specifically, we examine the distribution shift between the original data and the distorted data, thus assessing its impact on the AI model's performance. Founding upon this analysis, we can preemptively estimate the empirical accuracy of AI tasks, making the goal-oriented semantic communication problem feasible. To achieve this objective, we present the theoretical foundation of our approach, accompanied by simulations and ex
    
[^46]: 从标记的MRI和非负矩阵分解通过可塑性变换器合成语音音频

    Speech Audio Synthesis from Tagged MRI and Non-Negative Matrix Factorization via Plastic Transformer. (arXiv:2309.14586v1 [cs.SD])

    [http://arxiv.org/abs/2309.14586](http://arxiv.org/abs/2309.14586)

    这项研究利用标记的MRI测量舌头的功能单元，并开发了一个深度学习框架，将权重图转化为对应的音频波形，为研究语音产生过程提供了重要洞察。

    

    舌头的复杂3D结构是语音产生过程中起关键作用的局部功能单元的组成部分。使用标记的MRI测量时，这些功能单元表现出具有内聚位移的和派生数量，从而促进了复杂的语音产生过程。基于非负矩阵分解的方法已经被证明可以通过运动特征估计功能单元，从而产生一组构建块和相应的加权图。研究加权图与语音声学之间的联系可以对复杂的语音产生过程提供重要洞察。为此，我们在这项工作中利用二维频谱图作为代理表示，开发了一个端到端的深度学习框架，将加权图转化为相应的音频波形。我们提出的可塑性轻型变换器（PLT）框架基于方向性产品相对位置偏差和单层空间金字塔池化。

    The tongue's intricate 3D structure, comprising localized functional units, plays a crucial role in the production of speech. When measured using tagged MRI, these functional units exhibit cohesive displacements and derived quantities that facilitate the complex process of speech production. Non-negative matrix factorization-based approaches have been shown to estimate the functional units through motion features, yielding a set of building blocks and a corresponding weighting map. Investigating the link between weighting maps and speech acoustics can offer significant insights into the intricate process of speech production. To this end, in this work, we utilize two-dimensional spectrograms as a proxy representation, and develop an end-to-end deep learning framework for translating weighting maps to their corresponding audio waveforms. Our proposed plastic light transformer (PLT) framework is based on directional product relative position bias and single-level spatial pyramid pooling,
    
[^47]: CWCL：连续加权对比损失下的跨模态迁移

    CWCL: Cross-Modal Transfer with Continuously Weighted Contrastive Loss. (arXiv:2309.14580v1 [cs.LG])

    [http://arxiv.org/abs/2309.14580](http://arxiv.org/abs/2309.14580)

    本文提出了一种称为CWCL的损失函数，用于跨模态迁移中的对比训练。相比于传统的二进制对比训练，CWCL使用连续的相似性度量，可以更好地对齐实例的表示并提高跨模态的迁移性能。

    

    本文考虑使用对比训练进行跨模态零样本迁移，其中一个模态中的预训练模型用于在另一个领域中进行表示学习，使用成对数据。然后，后一个领域中学到的模型可以以一种零样本的方式用于各种任务，类似于最近引起相当关注的“对比语言-图像预训练（CLIP）”和“锁定图像调整（LiT）”。大多数现有的跨模态表示对齐方法（包括CLIP和LiT）使用标准的对比训练目标，它使用一组正样本和负样本来对齐相似和驱散不相似的训练数据样本。然而，训练样本之间的相似性具有更连续的性质，因此需要更“非二进制”的处理。为了解决这个问题，我们提出了一种称为连续加权对比损失（CWCL）的新型损失函数，它使用连续的相似度测量。使用CWCL，我们旨在对齐实例的表示并提高跨模态的迁移性能。

    This paper considers contrastive training for cross-modal 0-shot transfer wherein a pre-trained model in one modality is used for representation learning in another domain using pairwise data. The learnt models in the latter domain can then be used for a diverse set of tasks in a zero-shot way, similar to ``Contrastive Language-Image Pre-training (CLIP)'' and ``Locked-image Tuning (LiT)'' that have recently gained considerable attention. Most existing works for cross-modal representation alignment (including CLIP and LiT) use the standard contrastive training objective, which employs sets of positive and negative examples to align similar and repel dissimilar training data samples. However, similarity amongst training examples has a more continuous nature, thus calling for a more `non-binary' treatment. To address this, we propose a novel loss function called Continuously Weighted Contrastive Loss (CWCL) that employs a continuous measure of similarity. With CWCL, we seek to align the e
    
[^48]: 将高阶动态和道路合规性整合到基于约束的ILQR轨迹规划中的自动驾驶车辆中

    Integrating Higher-Order Dynamics and Roadway-Compliance into Constrained ILQR-based Trajectory Planning for Autonomous Vehicles. (arXiv:2309.14566v1 [cs.RO])

    [http://arxiv.org/abs/2309.14566](http://arxiv.org/abs/2309.14566)

    本文将高阶动态和道路合规性整合到基于约束的ILQR轨迹规划中的自动驾驶车辆中，提供了更安全和舒适的路径规划。

    

    本文解决了自动乘客车辆（APV）的道路轨迹规划领域的进展。轨迹规划旨在为APV生成全局最优的路径，考虑到诸如车辆动力学、约束和检测到的障碍物等各种因素。传统技术涉及采样方法与优化算法的组合，前者确保全局感知，后者优化局部最优解。值得注意的是，约束迭代线性二次调节器（CILQR）优化算法最近出现，针对APV系统进行了改进，强调提高安全性和舒适度。然而，使用车辆自行车运动模型的现有实现可能无法保证可控的轨迹。我们通过加入高阶项，包括曲率和纵向加速度的一阶和二阶导数，来增强这个模型。这种包含有助于在成本和约束设计中获得更丰富的表达。

    This paper addresses the advancements in on-road trajectory planning for Autonomous Passenger Vehicles (APV). Trajectory planning aims to produce a globally optimal route for APVs, considering various factors such as vehicle dynamics, constraints, and detected obstacles. Traditional techniques involve a combination of sampling methods followed by optimization algorithms, where the former ensures global awareness and the latter refines for local optima. Notably, the Constrained Iterative Linear Quadratic Regulator (CILQR) optimization algorithm has recently emerged, adapted for APV systems, emphasizing improved safety and comfort. However, existing implementations utilizing the vehicle bicycle kinematic model may not guarantee controllable trajectories. We augment this model by incorporating higher-order terms, including the first and second-order derivatives of curvature and longitudinal jerk. This inclusion facilitates a richer representation in our cost and constraint design. We also
    
[^49]: 生成艾舍尔网格

    Generative Escher Meshes. (arXiv:2309.14564v1 [cs.CV])

    [http://arxiv.org/abs/2309.14564](http://arxiv.org/abs/2309.14564)

    本文提出了一种全自动的生成方法，用于生成周期性的非正方形镶嵌图案，该方法通过优化几何和颜色来生成与所需对象形状和外观相似的瓷砖。

    

    本文提出了一种全自动、以文本为导向的生成方法，用于生成周期性的、可重复的二维艺术作品，如地板、马赛克、陶瓷和艾舍尔的作品。与传统的无缝纹理概念不同，即平铺无缝的正方形图像，我们的方法生成的是由重复的相同对象组成的非正方形镶嵌图案。它通过优化二维网格的几何和颜色来生成与所需对象形状和外观相似的非正方形瓷砖，几乎没有额外的背景细节。我们通过一个关键的技术贡献实现了镶嵌图案的几何优化：一个无约束的、可微分的参数化方法，用于给定对称群的所有可能的可铺砖形状空间。换句话说，我们证明了修改二维网格映射技术Orbifold Tutte Embedding中使用的Laplacian算子可以实现所选平面对称群的所有可能的铺砖配置。

    This paper proposes a fully-automatic, text-guided generative method for producing periodic, repeating, tile-able 2D art, such as the one seen on floors, mosaics, ceramics, and the work of M.C. Escher. In contrast to the standard concept of a seamless texture, i.e., square images that are seamless when tiled, our method generates non-square tilings which comprise solely of repeating copies of the same object. It achieves this by optimizing both geometry and color of a 2D mesh, in order to generate a non-square tile in the shape and appearance of the desired object, with close to no additional background details. We enable geometric optimization of tilings by our key technical contribution: an unconstrained, differentiable parameterization of the space of all possible tileable shapes for a given symmetry group. Namely, we prove that modifying the laplacian used in a 2D mesh-mapping technique Orbifold Tutte Embedding - can achieve all possible tiling configurations for a chosen planar 
    
[^50]: 艺术还是技巧？大型语言模型与创造力的虚假承诺

    Art or Artifice? Large Language Models and the False Promise of Creativity. (arXiv:2309.14556v1 [cs.CL])

    [http://arxiv.org/abs/2309.14556](http://arxiv.org/abs/2309.14556)

    本研究通过提出创造性写作的托兰斯测验(TTCW)来评估大型语言模型(LLMs)的写作创造力。结果表明，LLM生成的故事在创意测试中通过的数量比专业作家写的故事少。此外，我们发现LLMs无法代替专家进行TTCW评估。

    

    研究人员认为，大型语言模型(LLMs)具有从博客到故事的高质量写作能力。然而，客观评估一段文字的创造力是具有挑战性的。受创造性思维的托兰斯测验(TTC)的启发，我们使用共识评估技术[3]，提出了创造性写作的托兰斯测验(TTCW)来评估创造力作为一个产品。TTCW由包含在流畅度、灵活性、独创性和细致度原始维度中的14个二元测试组成。我们招募了10位创意作家，并使用TTCW对48个由专业作家或LLMs撰写的故事进行人工评估。我们的分析表明，LLM生成的故事通过的TTCW测试比专业作家写的故事少了3-10倍。此外，我们探索了使用LLMs作为评价者，以自动化TTCW评估，结果显示没有一个LLM与专家评估呈正相关。

    Researchers have argued that large language models (LLMs) exhibit high-quality writing capabilities from blogs to stories. However, evaluating objectively the creativity of a piece of writing is challenging. Inspired by the Torrance Test of Creative Thinking (TTCT), which measures creativity as a process, we use the Consensual Assessment Technique [3] and propose the Torrance Test of Creative Writing (TTCW) to evaluate creativity as a product. TTCW consists of 14 binary tests organized into the original dimensions of Fluency, Flexibility, Originality, and Elaboration. We recruit 10 creative writers and implement a human assessment of 48 stories written either by professional authors or LLMs using TTCW. Our analysis shows that LLM-generated stories pass 3-10X less TTCW tests than stories written by professionals. In addition, we explore the use of LLMs as assessors to automate the TTCW evaluation, revealing that none of the LLMs positively correlate with the expert assessments.
    
[^51]: 稳定放置的外部接触块的触觉估计

    Tactile Estimation of Extrinsic Contact Patch for Stable Placement. (arXiv:2309.14552v1 [cs.RO])

    [http://arxiv.org/abs/2309.14552](http://arxiv.org/abs/2309.14552)

    本文介绍了一种利用触觉读数推测物体放置稳定性的方法，通过对接触区域的估计可以有效设计机器人的反馈技能，提高机器人的精细操控能力。

    

    对于机器人的精细操作技能来说，准确感知接触交互至关重要。本文提出了一种为机器人设计反馈技能的方法，该机器人必须学习将复杂形状的物体堆叠在一起。为了设计这样一个系统，机器人应该能够根据非常轻微的接触交互来推理放置的稳定性。我们的实验结果表明，可以根据接触形成过程中的触觉读数来推测物体放置的稳定性。具体而言，我们使用力和触觉观测来估计抓取物体和其环境之间的接触区域，从而估计接触形成过程中物体的稳定性。这种接触区域可以用来估计释放抓取后物体的稳定性。所提出的方法在一款非常流行的棋盘游戏中使用了多种物体对进行了验证。

    Precise perception of contact interactions is essential for the fine-grained manipulation skills for robots. In this paper, we present the design of feedback skills for robots that must learn to stack complex-shaped objects on top of each other. To design such a system, a robot should be able to reason about the stability of placement from very gentle contact interactions. Our results demonstrate that it is possible to infer the stability of object placement based on tactile readings during contact formation between the object and its environment. In particular, we estimate the contact patch between a grasped object and its environment using force and tactile observations to estimate the stability of the object during a contact formation. The contact patch could be used to estimate the stability of the object upon the release of the grasp. The proposed method is demonstrated on various pairs of objects that are used in a very popular board game.
    
[^52]: 算法勾结还是竞争：平台推荐系统的角色

    Algorithmic Collusion or Competition: the Role of Platforms' Recommender Systems. (arXiv:2309.14548v1 [cs.AI])

    [http://arxiv.org/abs/2309.14548](http://arxiv.org/abs/2309.14548)

    这项研究填补了关于电子商务平台推荐算法在算法勾结研究中被忽视的空白，并发现推荐算法可以决定基于AI的定价算法的竞争或勾结动态。

    

    最近的学术研究广泛探讨了基于人工智能(AI)的动态定价算法导致的算法勾结。然而，电子商务平台使用推荐算法来分配不同产品的曝光，而这一重要方面在先前的算法勾结研究中被大部分忽视。我们的研究填补了文献中这一重要的空白，并检验了推荐算法如何决定基于AI的定价算法的竞争或勾结动态。具体而言，我们研究了两种常用的推荐算法：(i)以最大化卖家总利润为目标的推荐系统和(ii)以最大化平台上产品需求为目标的推荐系统。我们构建了一个重复博弈框架，将卖家的定价算法和平台的推荐算法进行了整合。

    Recent academic research has extensively examined algorithmic collusion resulting from the utilization of artificial intelligence (AI)-based dynamic pricing algorithms. Nevertheless, e-commerce platforms employ recommendation algorithms to allocate exposure to various products, and this important aspect has been largely overlooked in previous studies on algorithmic collusion. Our study bridges this important gap in the literature and examines how recommendation algorithms can determine the competitive or collusive dynamics of AI-based pricing algorithms. Specifically, two commonly deployed recommendation algorithms are examined: (i) a recommender system that aims to maximize the sellers' total profit (profit-based recommender system) and (ii) a recommender system that aims to maximize the demand for products sold on the platform (demand-based recommender system). We construct a repeated game framework that incorporates both pricing algorithms adopted by sellers and the platform's recom
    
[^53]: 圆环设计对道路使用者行为的影响：基于无监督机器学习应用的圆环案例研究

    Effect of roundabout design on the behavior of road users: A case study of roundabouts with application of Unsupervised Machine Learning. (arXiv:2309.14540v1 [cs.LG])

    [http://arxiv.org/abs/2309.14540](http://arxiv.org/abs/2309.14540)

    本研究通过无监督机器学习应用的圆环案例研究，评估了圆环的性能，并研究了人类驾驶员与圆环的互动行为。研究发现，圆环可以显著降低转弯路口的速度，而其对速度的影响取决于道路使用者的行为评级。对于巴士、汽车和卡车驾驶员的行为进行了分类，并开发出一种预测圆环交叉口道路使用者行为的方法。安全主要归功于圆环的两个固有特征。

    

    本研究旨在评估圆环的性能并研究人类驾驶员与圆环的互动行为。近年来，由于其安全性、容量和环境优势以及为过境和整合提供安全和流畅车辆流动，圆环在国家间的应用越来越多。结果表明，圆环可以显著降低转弯路口的速度、入口速度以及其对速度的影响取决于道路使用者的行为评级。在我们的研究中，（巴士、汽车、卡车）驾驶员受到特别关注，并将其行为分为保守型、正常型和侵略型。预测和识别驾驶员行为是一个重要的挑战。因此，本研究旨在研究圆环对这些分类器的影响，并开发一种预测圆环交叉口道路使用者行为的方法。安全主要归功于圆环的两个固有特征。

    This research aims to evaluate the performance of the rotors and study the behavior of the human driver in interacting with the rotors. In recent years, rotors have been increasingly used between countries due to their safety, capacity, and environmental advantages, and because they provide safe and fluid flows of vehicles for transit and integration. It turns out that roundabouts can significantly reduce speed at twisting intersections, entry speed and the resulting effect on speed depends on the rating of road users. In our research, (bus, car, truck) drivers were given special attention and their behavior was categorized into (conservative, normal, aggressive). Anticipating and recognizing driver behavior is an important challenge. Therefore, the aim of this research is to study the effect of roundabouts on these classifiers and to develop a method for predicting the behavior of road users at roundabout intersections. Safety is primarily due to two inherent features of the rotor. Fi
    
[^54]: 注意言辞：大型语言模型和内容审查

    Watch Your Language: Large Language Models and Content Moderation. (arXiv:2309.14517v1 [cs.HC])

    [http://arxiv.org/abs/2309.14517](http://arxiv.org/abs/2309.14517)

    本研究评估了大型语言模型在内容审查任务上的表现，发现它们在基于规则的社区审查和有害内容检测方面具有很好的效果，在有害内容检测方面超过了现有的分类器。然而，最近模型规模的增加对有害内容检测的改进效果很小。

    

    由于其在各种自然语言任务上的能力，大型语言模型（LLMs）变得非常受欢迎。基于文本的内容审查是其中一个受到近期热情关注的LLM应用案例，然而，鲜有研究调查LLMs在内容审查设置中的表现。在这项工作中，我们评估了一套现代、商业化的LLMs（GPT-3、GPT-3.5、GPT-4）在两个常见的内容审查任务上的表现：基于规则的社区审查和有害内容检测。对于基于规则的社区审查，我们构建了95个LLM审查引擎，并使用95个Reddit子社区的规则进行指导，发现LLMs在许多社区的基于规则的审查中表现出色，实现了中位数准确率为64%和中位数精确度为83%。在有害内容检测方面，我们发现LLMs明显优于现有商业可用的有害性分类器。然而，我们还发现最近模型规模的增加对有害内容检测几乎没有带来明显的好处。

    Large language models (LLMs) have exploded in popularity due to their ability to perform a wide array of natural language tasks. Text-based content moderation is one LLM use case that has received recent enthusiasm, however, there is little research investigating how LLMs perform in content moderation settings. In this work, we evaluate a suite of modern, commercial LLMs (GPT-3, GPT-3.5, GPT-4) on two common content moderation tasks: rule-based community moderation and toxic content detection. For rule-based community moderation, we construct 95 LLM moderation-engines prompted with rules from 95 Reddit subcommunities and find that LLMs can be effective at rule-based moderation for many communities, achieving a median accuracy of 64% and a median precision of 83%. For toxicity detection, we find that LLMs significantly outperform existing commercially available toxicity classifiers. However, we also find that recent increases in model size add only marginal benefit to toxicity detection
    
[^55]: Era Splitting.（arXiv:2309.14496v1 [cs.LG]）

    Era Splitting. (arXiv:2309.14496v1 [cs.LG])

    [http://arxiv.org/abs/2309.14496](http://arxiv.org/abs/2309.14496)

    本研究提出了两种新的分裂准则，使得决策树模型能够利用时代信息进行优化，从而将超分布泛化研究中的思想应用于决策树模型。

    

    现实生活中的机器学习问题在时间和空间上会呈现出数据的分布变化。这种行为超出了传统的经验风险最小化范式的范围，该范式假设数据在时间和地点上是独立同分布的。新兴的超分布泛化领域通过将环境或时代信息融入算法中，来应对这个现实。迄今为止，大部分研究都集中在线性模型和/或神经网络上。在本研究中，我们针对决策树模型，包括随机森林和梯度提升决策树，开发了两种新的分裂准则，使得树模型能够利用与每个数据点相关的时代信息，来找到在数据的所有不相交时代中都是最优的切分点，从而将超分布泛化研究中的思想应用于决策树模型。

    Real life machine learning problems exhibit distributional shifts in the data from one time to another or from on place to another. This behavior is beyond the scope of the traditional empirical risk minimization paradigm, which assumes i.i.d. distribution of data over time and across locations. The emerging field of out-of-distribution (OOD) generalization addresses this reality with new theory and algorithms which incorporate environmental, or era-wise information into the algorithms. So far, most research has been focused on linear models and/or neural networks. In this research we develop two new splitting criteria for decision trees, which allow us to apply ideas from OOD generalization research to decision tree models, including random forest and gradient-boosting decision trees. The new splitting criteria use era-wise information associated with each data point to allow tree-based models to find split points that are optimal across all disjoint eras in the data, instead of optim
    
[^56]: 当自动化评估遇上自动化内容生成：在GPT时代审查文本质量

    When Automated Assessment Meets Automated Content Generation: Examining Text Quality in the Era of GPTs. (arXiv:2309.14488v1 [cs.CL])

    [http://arxiv.org/abs/2309.14488](http://arxiv.org/abs/2309.14488)

    本研究通过对人类和GPT生成的文本进行实证评估，探讨了基于机器学习模型对文本质量评估的差异。结果表明，在评估GPT生成的文本时，预训练转换器模型的性能较差。

    

    机器学习模型在评估和打分文本数据方面的应用已经在包括自然语言处理、信息检索、搜索和推荐以及在线内容可信度评估等各种情境中变得越来越普遍。在机器学习和文本交叉领域的一次重要变革是生成式预训练转换器（GPT）等生成大型语言模型的使用。我们通过经验性评估人类和GPT生成的文本对于基于人类内容训练的机器学习打分模型如何评估内容质量的差异。为此，我们提出了一个分析框架，该框架包括论文评分机器学习模型、人类和机器学习生成的论文，以及一种可以简洁考虑到被调查者类型、提示类型和评估模型的统计模型。我们利用一个丰富的测试样本，涵盖了18,460篇人工生成和GPT生成的论文。我们的基准分析结果显示，预训练转换器线性分类器在评估GPT生成的论文时性能较差。

    The use of machine learning (ML) models to assess and score textual data has become increasingly pervasive in an array of contexts including natural language processing, information retrieval, search and recommendation, and credibility assessment of online content. A significant disruption at the intersection of ML and text are text-generating large-language models such as generative pre-trained transformers (GPTs). We empirically assess the differences in how ML-based scoring models trained on human content assess the quality of content generated by humans versus GPTs. To do so, we propose an analysis framework that encompasses essay scoring ML-models, human and ML-generated essays, and a statistical model that parsimoniously considers the impact of type of respondent, prompt genre, and the ML model used for assessment model. A rich testbed is utilized that encompasses 18,460 human-generated and GPT-based essays. Results of our benchmark analysis reveal that transformer pretrained lan
    
[^57]: 融合集成学习和迁移学习的端到端自动上色图像检测模型

    Incorporating Ensemble and Transfer Learning For An End-To-End Auto-Colorized Image Detection Model. (arXiv:2309.14478v1 [cs.CV])

    [http://arxiv.org/abs/2309.14478](http://arxiv.org/abs/2309.14478)

    本论文介绍了一种融合了迁移学习和集成学习的端到端自动上色图像检测模型，该模型通过减少训练时间和资源需求来区分自然彩色和计算机上色图像。

    

    图像上色是将灰度图像上色或重新上色已彩色图像的过程。它可以用于使卫星、医学和历史图像更具表现力。随着深度学习技术的不断发展，上色算法的结果变得更加逼真，以至于人眼无法区分自然图像和上色图像。然而，这也带来了潜在的安全问题，因为伪造或非法修改的图像可以被用于非法目的。因此，需要有效的检测方法来区分自然彩色图像和计算机上色图像。本文提出了一种新颖的方法，结合了迁移学习和集成学习的优点，用于减少训练时间和资源需求，并提出了一个模型来对自然彩色和计算机上色图像进行分类。本文提出的模型使用了预训练的分支VGG16和Resn

    Image colorization is the process of colorizing grayscale images or recoloring an already-color image. This image manipulation can be used for grayscale satellite, medical and historical images making them more expressive. With the help of the increasing computation power of deep learning techniques, the colorization algorithms results are becoming more realistic in such a way that human eyes cannot differentiate between natural and colorized images. However, this poses a potential security concern, as forged or illegally manipulated images can be used illegally. There is a growing need for effective detection methods to distinguish between natural color and computer-colorized images. This paper presents a novel approach that combines the advantages of transfer and ensemble learning approaches to help reduce training time and resource requirements while proposing a model to classify natural color and computer-colorized images. The proposed model uses pre-trained branches VGG16 and Resn
    
[^58]: 为连续强化学习适应双Q-Learning

    Adapting Double Q-Learning for Continuous Reinforcement Learning. (arXiv:2309.14471v1 [cs.LG])

    [http://arxiv.org/abs/2309.14471](http://arxiv.org/abs/2309.14471)

    本文介绍了一种新颖的校正偏差方法，通过使用两个组件的混合策略并由分开的网络进行评估，消除了离线策略强化学习算法中的过高估计偏差。在一小组MuJoCo环境中，该方法显示出了有希望接近SOTA的结果。 (校正偏差方法，混合策略，分开的网络评估)

    

    大部分离线策略强化学习算法使用过高估计偏差控制技术。大多数这些技术基于启发式方法，主要解决的是过高估计的结果，而非其根本原因。本文提出了一种新颖的校正偏差的方法，类似于双Q-Learning。我们提出使用一种由两个组成成分构成的混合策略。每个策略成分由分别最大化和评估的网络处理，从而消除了过高估计偏差的基础。我们的方法在一小组MuJoCo环境上展示了令人期待的接近SOTA的结果。

    Majority of off-policy reinforcement learning algorithms use overestimation bias control techniques. Most of these techniques rooted in heuristics, primarily addressing the consequences of overestimation rather than its fundamental origins. In this work we present a novel approach to the bias correction, similar in spirit to Double Q-Learning. We propose using a policy in form of a mixture with two components. Each policy component is maximized and assessed by separate networks, which removes any basis for the overestimation bias. Our approach shows promising near-SOTA results on a small set of MuJoCo environments.
    
[^59]: DefGoalNet：可变形物体操作时的上下文目标学习

    DefGoalNet: Contextual Goal Learning from Demonstrations For Deformable Object Manipulation. (arXiv:2309.14463v1 [cs.RO])

    [http://arxiv.org/abs/2309.14463](http://arxiv.org/abs/2309.14463)

    本文提出了一种名为DefGoalNet的神经网络，通过少量人类示范直接学习可变形物体的目标形状。实验证明，在各种机器人任务中取得了显著的进展。

    

    形状伺服是一种控制物体到达预期目标形状的机器人任务，对于可变形物体的操作具有潜在的应用前景。然而，目标形状的规定成为一个问题。目标形状通常通过繁琐的领域知识工程过程获取，或者通过手动操作物体到达所需形状并捕获该特定时刻的目标形状，这两种方法在各种机器人应用中都不切实际。本文通过开发一种新颖的神经网络DefGoalNet来解决这个问题，该网络可以直接从少量人类示范中学习可变形物体的目标形状。我们在模拟和实际机器人上展示了我们方法的有效性。值得注意的是，在手术撤退任务中，即使仅使用10个示范进行训练，我们的方法的成功率中值也接近90%。这些结果标志着在可变形物体操作中的重要进展。

    Shape servoing, a robotic task dedicated to controlling objects to desired goal shapes, is a promising approach to deformable object manipulation. An issue arises, however, with the reliance on the specification of a goal shape. This goal has been obtained either by a laborious domain knowledge engineering process or by manually manipulating the object into the desired shape and capturing the goal shape at that specific moment, both of which are impractical in various robotic applications. In this paper, we solve this problem by developing a novel neural network DefGoalNet, which learns deformable object goal shapes directly from a small number of human demonstrations. We demonstrate our method's effectiveness on various robotic tasks, both in simulation and on a physical robot. Notably, in the surgical retraction task, even when trained with as few as 10 demonstrations, our method achieves a median success percentage of nearly 90%. These results mark a substantial advancement in enabl
    
[^60]: 在线主动学习声音事件检测

    Online Active Learning For Sound Event Detection. (arXiv:2309.14460v1 [eess.AS])

    [http://arxiv.org/abs/2309.14460](http://arxiv.org/abs/2309.14460)

    通过提出新的损失函数，该论文解决了在线主动学习在声音事件检测中面临的类别分布波动和数据漂移问题，并在实验中证明该方法能够将训练分类器所需的时间和工作量减少5倍。

    

    数据收集和标注是监督机器学习任务的繁琐、耗时的前提条件。在线主动学习（OAL）是一种同时减少训练分类器所需的标注量并适应数据变化的范例。先前的研究表明，波动的类别分布和数据漂移仍然是OAL的常见问题。本文提出了新的损失函数，用于解决当OAL应用于声音事件检测时面临的挑战。SONYC数据集和两个语音类型识别（VTD）语料库的实验结果表明，OAL可以将训练声音事件检测分类器所需的时间和工作量减少5倍，并且本文介绍的新方法成功解决了现有OAL方法中存在的问题。

    Data collection and annotation is a laborious, time-consuming prerequisite for supervised machine learning tasks. Online Active Learning (OAL) is a paradigm that addresses this issue by simultaneously minimizing the amount of annotation required to train a classifier and adapting to changes in the data over the duration of the data collection process. Prior work has indicated that fluctuating class distributions and data drift are still common problems for OAL. This work presents new loss functions that address these challenges when OAL is applied to Sound Event Detection (SED). Experimental results from the SONYC dataset and two Voice-Type Discrimination (VTD) corpora indicate that OAL can reduce the time and effort required to train SED classifiers by a factor of 5 for SONYC, and that the new methods presented here successfully resolve issues present in existing OAL methods.
    
[^61]: 自恢复提示：基于基础模型和自恢复的通用服务机器人系统

    Self-Recovery Prompting: Promptable General Purpose Service Robot System with Foundation Models and Self-Recovery. (arXiv:2309.14425v1 [cs.RO])

    [http://arxiv.org/abs/2309.14425](http://arxiv.org/abs/2309.14425)

    本文研究开发了一个通用服务机器人系统，该系统可以根据不同任务和环境的变化进行自适应，并通过自恢复机制解决信息不足、计划生成错误和执行失败等问题，实现了任务的成功完成。

    

    通用服务机器人（GPSR）能够在各种环境中执行多种任务，需要一个具有高通用性和适应性的系统来应对不同的任务和环境。本文首先基于多个基础模型开发了一个顶层GPSR系统，用于全球竞赛（RoboCup@Home 2023）。该系统既可以适应多种变化，又可以通过提示每个模型来实现自适应。然后，通过分析所开发系统的性能，我们发现在更加现实的GPSR应用设置中存在三种失败类型：信息不足、错误的计划生成和计划执行失败。我们提出了自恢复提示管道，该管道探索必要的信息，并修改其提示来从失败中恢复。我们通过实验证实，具有自恢复机制的系统可以通过解决各种失败案例来完成任务。供补充的视频可在https://sites.google.com/view/srgpsr上找到。

    A general-purpose service robot (GPSR), which can execute diverse tasks in various environments, requires a system with high generalizability and adaptability to tasks and environments. In this paper, we first developed a top-level GPSR system for worldwide competition (RoboCup@Home 2023) based on multiple foundation models. This system is both generalizable to variations and adaptive by prompting each model. Then, by analyzing the performance of the developed system, we found three types of failure in more realistic GPSR application settings: insufficient information, incorrect plan generation, and plan execution failure. We then propose the self-recovery prompting pipeline, which explores the necessary information and modifies its prompts to recover from failure. We experimentally confirm that the system with the self-recovery mechanism can accomplish tasks by resolving various failure cases. Supplementary videos are available at https://sites.google.com/view/srgpsr .
    
[^62]: 联合音频和语音理解

    Joint Audio and Speech Understanding. (arXiv:2309.14405v1 [cs.SD])

    [http://arxiv.org/abs/2309.14405](http://arxiv.org/abs/2309.14405)

    LTU-AS是一个具有普适音频感知和高级推理能力的机器学习模型，可以同时识别和联合理解口语文本、语音声音学和非语音音频事件。

    

    人类周围充斥着包括语音和非语音声音在内的音频信号。对语音和非语音音频事件的识别和理解，以及对它们之间关系的深刻理解，构成了基本的认知能力。我们首次构建了一个名为LTU-AS的机器学习模型，它具有类似于人类的普遍音频感知和高级推理能力。具体而言，通过将Whisper作为感知模块和LLaMA作为推理模块进行集成，LTU-AS可以同时识别和联合理解口语文本、语音声音学以及非语音音频事件 - 几乎可以从音频信号中感知到的一切。

    Humans are surrounded by audio signals that include both speech and non-speech sounds. The recognition and understanding of speech and non-speech audio events, along with a profound comprehension of the relationship between them, constitute fundamental cognitive capabilities. For the first time, we build a machine learning model, called LTU-AS, that has a conceptually similar universal audio perception and advanced reasoning ability. Specifically, by integrating Whisper as a perception module and LLaMA as a reasoning module, LTU-AS can simultaneously recognize and jointly understand spoken text, speech paralinguistics, and non-speech audio events - almost everything perceivable from audio signals.
    
[^63]: 日期驱动的方法用于识别血液透析物瘘的状态：熵-复杂度和形式概念分析

    Date-Driven Approach for Identifying State of Hemodialysis Fistulas: Entropy-Complexity and Formal Concept Analysis. (arXiv:2309.14399v1 [physics.med-ph])

    [http://arxiv.org/abs/2309.14399](http://arxiv.org/abs/2309.14399)

    该论文提出了一种日期驱动的方法，通过熵-复杂度和形式概念分析，区分正常和混乱时间序列，用于识别血液透析物瘘的状态。

    

    该论文探讨了区分正常和混乱时间序列的数学方法，特别是用于识别病理性物瘘。它提出了一种抗噪声方法，用于分类正常和病理性功能的物瘘的响应行。该方法基于以下假设：层流血液流动表示正常功能，而湍流流动表示病理性。该研究探讨了两种区分混乱和正常时间序列的不同方法。第一种方法涉及将时间序列映射到熵-复杂度平面上，然后与已建立的聚类进行比较。第二种方法是由作者引入的，它使用形式概念分析构建了一个概念-对象图。这两种方法在确定物瘘状态方面都表现出高效性。

    The paper explores mathematical methods that differentiate regular and chaotic time series, specifically for identifying pathological fistulas. It proposes a noise-resistant method for classifying responding rows of normally and pathologically functioning fistulas. This approach is grounded in the hypothesis that laminar blood flow signifies normal function, while turbulent flow indicates pathology. The study explores two distinct methods for distinguishing chaotic from regular time series. The first method involves mapping the time series onto the entropy-complexity plane and subsequently comparing it to established clusters. The second method, introduced by the authors, constructs a concepts-objects graph using formal concept analysis. Both of these methods exhibit high efficiency in determining the state of the fistula.
    
[^64]: 看见和听到没被说的话：可解释融合的多模态动机性访谈客户行为分类器

    Seeing and hearing what has not been said; A multimodal client behavior classifier in Motivational Interviewing with interpretable fusion. (arXiv:2309.14398v1 [cs.LG])

    [http://arxiv.org/abs/2309.14398](http://arxiv.org/abs/2309.14398)

    本文提出了一个多模态分类器，在动机性访谈中准确区分了变化话语、持续话语和跟随/中立话语三种类别。该分类器利用文本、声调、面部表情和身体表现等多模态特征，并对AnnoMI数据集进行了注释和训练。研究还找到了决策过程中最重要的模态，提供了宝贵的洞察。

    

    动机性访谈（MI）是一种强调合作并鼓励行为改变的治疗方法。为了评估MI对话的质量，可以利用MISC代码将客户话语分类为变化话语、持续话语或跟随/中立话语。MI对话中变化话语的比例与治疗结果呈正相关，因此准确分类客户话语至关重要。本文提出了一个分类器，利用文本、声调、面部表情和身体表现等多模态特征准确区分三个MISC类别（变化话语、持续话语和跟随/中立话语）。为了训练我们的模型，我们对公开可用的AnnoMI数据集进行注释，收集了文本、音频、面部表情和身体表现等多模态信息。此外，我们还确定了决策过程中最重要的模态，提供了宝贵的洞察。

    Motivational Interviewing (MI) is an approach to therapy that emphasizes collaboration and encourages behavioral change. To evaluate the quality of an MI conversation, client utterances can be classified using the MISC code as either change talk, sustain talk, or follow/neutral talk. The proportion of change talk in a MI conversation is positively correlated with therapy outcomes, making accurate classification of client utterances essential. In this paper, we present a classifier that accurately distinguishes between the three MISC classes (change talk, sustain talk, and follow/neutral talk) leveraging multimodal features such as text, prosody, facial expressivity, and body expressivity. To train our model, we perform annotations on the publicly available AnnoMI dataset to collect multimodal information, including text, audio, facial expressivity, and body expressivity. Furthermore, we identify the most important modalities in the decision-making process, providing valuable insights i
    
[^65]: 隐性感知在交通优化中的应用：先进的深度强化学习技术

    Implicit Sensing in Traffic Optimization: Advanced Deep Reinforcement Learning Techniques. (arXiv:2309.14395v1 [cs.LG])

    [http://arxiv.org/abs/2309.14395](http://arxiv.org/abs/2309.14395)

    本论文提出了一个基于深度强化学习的集成车辆跟随和变道决策控制系统，旨在解决高速公路上突发路障情况下智能车辆的行车问题。

    

    高速公路上的突然路障由于道路维护、事故和汽车维修等原因是我们几乎每天都会遇到的情况。配备可以获取车辆动态信息（如速度、加速度和位置）的自主驾驶车辆（AV）可以在到达路障之前做出智能决策来变换车道。许多文献研究已经考察了车辆跟随模型和变道模型。然而，只有很少的研究提出了集成的车辆跟随和变道模型，这个模型有潜力模拟实际的驾驶操纵。因此，在本文中，我们提出了一个基于深度强化学习（DRL）的集成车辆跟随和变道决策控制系统来解决这个问题。具体而言，我们考虑了在高速公路上将进行突发施工的情景。我们将情景建模为马尔可夫决策过程（MDP），并采用着名的DQN算法来训练RL代理以制定决策。

    A sudden roadblock on highways due to many reasons such as road maintenance, accidents, and car repair is a common situation we encounter almost daily. Autonomous Vehicles (AVs) equipped with sensors that can acquire vehicle dynamics such as speed, acceleration, and location can make intelligent decisions to change lanes before reaching a roadblock. A number of literature studies have examined car-following models and lane-changing models. However, only a few studies proposed an integrated car-following and lane-changing model, which has the potential to model practical driving maneuvers. Hence, in this paper, we present an integrated car-following and lane-changing decision-control system based on Deep Reinforcement Learning (DRL) to address this issue. Specifically, we consider a scenario where sudden construction work will be carried out along a highway. We model the scenario as a Markov Decision Process (MDP) and employ the well-known DQN algorithm to train the RL agent to make the
    
[^66]: 多噪声扩散模型用于半监督多域翻译

    Multiple Noises in Diffusion Model for Semi-Supervised Multi-Domain Translation. (arXiv:2309.14394v1 [cs.CL])

    [http://arxiv.org/abs/2309.14394](http://arxiv.org/abs/2309.14394)

    本文提出了一种多噪声扩散模型（MDD）用于半监督多域翻译，通过引入噪声级别来对缺失的域进行建模，实现了任意域之间的翻译而不需要训练单独的模型。

    

    域间翻译涉及在给定源域条件下生成目标域样本。大多数现有方法都集中在固定的输入和输出域上，即它们仅适用于特定的配置（例如对于两个域，要么$D_1\rightarrow{}D_2$，要么$D_2\rightarrow{}D_1$）。本文提出了Multi-Domain Diffusion（MDD）方法，这是一种用于半监督多域翻译的条件扩散框架。与以往的方法不同，MDD不需要定义输入和输出域，允许在一组域的任何分区之间进行翻译（例如$(D_1, D_2)\rightarrow{}D_3$，$D_2\rightarrow{}(D_1, D_3)$，$D_3\rightarrow{}D_1$等），而无需为每个域配置训练单独的模型。MDD的关键思想是利用扩散模型的噪声形式，通过为每个域引入一个噪声级别，以自然的方式对缺失的域进行建模。这将传统的翻译问题转化为一个通过噪声建模来解决的问题。

    Domain-to-domain translation involves generating a target domain sample given a condition in the source domain. Most existing methods focus on fixed input and output domains, i.e. they only work for specific configurations (i.e. for two domains, either $D_1\rightarrow{}D_2$ or $D_2\rightarrow{}D_1$). This paper proposes Multi-Domain Diffusion (MDD), a conditional diffusion framework for multi-domain translation in a semi-supervised context. Unlike previous methods, MDD does not require defining input and output domains, allowing translation between any partition of domains within a set (such as $(D_1, D_2)\rightarrow{}D_3$, $D_2\rightarrow{}(D_1, D_3)$, $D_3\rightarrow{}D_1$, etc. for 3 domains), without the need to train separate models for each domain configuration. The key idea behind MDD is to leverage the noise formulation of diffusion models by incorporating one noise level per domain, which allows missing domains to be modeled with noise in a natural way. This transforms the tra
    
[^67]: LLMCarbon: 对大型语言模型的端到端碳足迹建模

    LLMCarbon: Modeling the end-to-end Carbon Footprint of Large Language Models. (arXiv:2309.14393v1 [cs.CL])

    [http://arxiv.org/abs/2309.14393](http://arxiv.org/abs/2309.14393)

    本研究提出了LLMCarbon，一个针对密集型和MoE LLMs设计的端到端碳足迹预测模型，解决了现有工具的限制，并显著提升了估计的准确性。

    

    大型语言模型（LLMs）的碳足迹是一个重要关注点，包括它们的训练、推理、实验和存储过程中的排放，包括运营和固定碳排放。一个重要方面是在LLMs训练之前准确估计其碳影响，这在很大程度上依赖于GPU的使用。现有研究已报告了LLMs训练的碳足迹，但只有一个工具mlco2能够在实际训练之前预测新的神经网络的碳足迹。然而，mlco2存在一些严重的限制。它不能扩展其对密集或专家混合（MoE）LLMs的估计，忽视了关键的架构参数，仅关注GPU，并不能建模固化的碳足迹。为了解决这些问题，我们引入了LLMCarbon，一个为密集型和MoE LLMs设计的端到端碳足迹预测模型。与mlco2相比，LLMCarbon显著增强了准确性。

    The carbon footprint associated with large language models (LLMs) is a significant concern, encompassing emissions from their training, inference, experimentation, and storage processes, including operational and embodied carbon emissions. An essential aspect is accurately estimating the carbon impact of emerging LLMs even before their training, which heavily relies on GPU usage. Existing studies have reported the carbon footprint of LLM training, but only one tool, mlco2, can predict the carbon footprint of new neural networks prior to physical training. However, mlco2 has several serious limitations. It cannot extend its estimation to dense or mixture-of-experts (MoE) LLMs, disregards critical architectural parameters, focuses solely on GPUs, and cannot model embodied carbon footprints. Addressing these gaps, we introduce \textit{LLMCarbon}, an end-to-end carbon footprint projection model designed for both dense and MoE LLMs. Compared to mlco2, LLMCarbon significantly enhances the ac
    
[^68]: 一个用于解释面向服务系统的深度强化学习决策的AI聊天机器人

    An AI Chatbot for Explaining Deep Reinforcement Learning Decisions of Service-oriented Systems. (arXiv:2309.14391v1 [cs.LG])

    [http://arxiv.org/abs/2309.14391](http://arxiv.org/abs/2309.14391)

    一个AI聊天机器人被介绍来解释深度强化学习在面向服务系统中的决策过程，通过提供自然语言解释来帮助用户理解和建立信任。

    

    深度强化学习 (Deep RL) 在面向服务系统中应用越来越多，以应对开放世界的假设。深度强化学习已成功应用于动态服务组合、作业调度、卸载以及服务适应等问题。然而，理解深度强化学习的决策过程具有挑战性，因为其学到的决策策略本质上是一个黑盒子。然而，理解深度强化学习的决策过程对于帮助服务开发人员进行调试、支持服务提供商遵守相关法律框架以及帮助服务使用者建立信任是至关重要的。我们引入了Chat4XAI，通过提供自然语言解释来促进对深度强化学习决策过程的理解。与视觉解释相比，自然语言解释的报告优点包括非技术用户更好的可理解性、用户的接受度和信任度提高，以及更高的效率。

    Deep Reinforcement Learning (Deep RL) is increasingly used to cope with the open-world assumption in service-oriented systems. Deep RL was successfully applied to problems such as dynamic service composition, job scheduling, and offloading, as well as service adaptation. While Deep RL offers many benefits, understanding the decision-making of Deep RL is challenging because its learned decision-making policy essentially appears as a black box. Yet, understanding the decision-making of Deep RL is key to help service developers perform debugging, support service providers to comply with relevant legal frameworks, and facilitate service users to build trust. We introduce Chat4XAI to facilitate the understanding of the decision-making of Deep RL by providing natural-language explanations. Compared with visual explanations, the reported benefits of natural-language explanations include better understandability for non-technical users, increased user acceptance and trust, as well as more effi
    
[^69]: 从大规模用户-产品互动时间序列中预测早期流失

    Early Churn Prediction from Large Scale User-Product Interaction Time Series. (arXiv:2309.14390v1 [cs.LG])

    [http://arxiv.org/abs/2309.14390](http://arxiv.org/abs/2309.14390)

    本文通过对历史数据进行全面研究，提出了一种预测用户早期流失的模型，以促进业务决策和行动。

    

    用户流失，在各种面向客户的业务场景中，以结束与企业关系为特征，对经济产生深远的影响。在许多系统对用户的行动中，如促销折扣和留存活动，预测潜在的流失客户是一个主要目标。在变动剧烈的领域，如幻想体育，不可预测的因素，如国际体育赛事，甚至可以影响到常规的消费习惯。因此，虽然交易历史和用户-产品互动对于预测流失是有价值的，但它们需要深入的领域知识和复杂的特征工程。此外，流失预测系统的特征开发可能会消耗大量资源，特别是在为2亿多用户提供服务的生产环境中，推理流水线主要集中在特征工程上。本文通过对历史数据进行全面的研究，旨在创建一个模型来预测客户流失的可能性，促进决策和行动。

    User churn, characterized by customers ending their relationship with a business, has profound economic consequences across various Business-to-Customer scenarios. For numerous system-to-user actions, such as promotional discounts and retention campaigns, predicting potential churners stands as a primary objective. In volatile sectors like fantasy sports, unpredictable factors such as international sports events can influence even regular spending habits. Consequently, while transaction history and user-product interaction are valuable in predicting churn, they demand deep domain knowledge and intricate feature engineering. Additionally, feature development for churn prediction systems can be resource-intensive, particularly in production settings serving 200m+ users, where inference pipelines largely focus on feature engineering. This paper conducts an exhaustive study on predicting user churn using historical data. We aim to create a model forecasting customer churn likelihood, facil
    
[^70]: 分析仅使用LLM方法在基于图像的文档问答中的有效性

    Analyzing the Efficacy of an LLM-Only Approach for Image-based Document Question Answering. (arXiv:2309.14389v1 [cs.CV])

    [http://arxiv.org/abs/2309.14389](http://arxiv.org/abs/2309.14389)

    本论文分析了仅使用LLM方法在基于图像的文档问答中的有效性，探讨了在文档图像中序列化文本信息并直接使用指令调整的LLM的策略，以及对这种方法的可行性进行了全面的定量分析。

    

    最近的文档问答模型由两个关键组件组成：视觉编码器，用于捕获图像中的布局和视觉元素，以及一个大型语言模型（LLM），帮助将问题与图像进行语境化，并通过外部世界知识补充以生成准确的答案。然而，这些任务中视觉编码器和语言模型的相对贡献仍不清楚。考虑到针对指令调整的LLM的有效性，这尤其有趣，因为它们表现出对新任务的卓越适应性。为此，我们在这项工作中探索以下方面：（1）仅使用LLM方法在文档问答任务中的有效性、（2）在文档图像中序列化文本信息并直接将其馈送给指令调整的LLM，从而绕过显式视觉编码器的需要、（3）对这种方法的可行性进行彻底的定量分析。我们的综合分析涵盖了六个不同的场景。

    Recent document question answering models consist of two key components: the vision encoder, which captures layout and visual elements in images, and a Large Language Model (LLM) that helps contextualize questions to the image and supplements them with external world knowledge to generate accurate answers. However, the relative contributions of the vision encoder and the language model in these tasks remain unclear. This is especially interesting given the effectiveness of instruction-tuned LLMs, which exhibit remarkable adaptability to new tasks. To this end, we explore the following aspects in this work: (1) The efficacy of an LLM-only approach on document question answering tasks (2) strategies for serializing textual information within document images and feeding it directly to an instruction-tuned LLM, thus bypassing the need for an explicit vision encoder (3) thorough quantitative analysis on the feasibility of such an approach. Our comprehensive analysis encompasses six diverse 
    
[^71]: 通过广度优先搜索和随机查询探索机器人形态空间

    Exploring Robot Morphology Spaces through Breadth-First Search and Random Query. (arXiv:2309.14387v1 [cs.RO])

    [http://arxiv.org/abs/2309.14387](http://arxiv.org/abs/2309.14387)

    通过比较分析广度优先搜索（BFS）和随机查询在模块化机器人脑体共同进化中的影响，本研究发现这两种查询机制对机器人形态的进化和性能具有重要影响。

    

    进化机器人学为设计和进化机器人形态提供了一个强大的框架，尤其在模块化机器人的上下文中。然而，在基因型到表型映射过程中，查询机制的作用往往被忽视。本研究通过对模块化机器人的脑体共同进化中查询机制的比较分析，填补了这一空白。通过使用两种不同的查询机制——广度优先搜索（BFS）和随机查询，在使用CPPN进化机器人形态和使用张量进化机器人控制器的上下文中，并在两种进化框架（拉马克和达尔文系统）中进行测试，本研究调查了它们对进化结果和性能的影响。研究结果表明，这两种查询机制对模块化机器人身体的进化和性能，包括形态智能、多样性和形态特征的影响。本研究认为BFS更加有效和...

    Evolutionary robotics offers a powerful framework for designing and evolving robot morphologies, particularly in the context of modular robots. However, the role of query mechanisms during the genotype-to-phenotype mapping process has been largely overlooked. This research addresses this gap by conducting a comparative analysis of query mechanisms in the brain-body co-evolution of modular robots. Using two different query mechanisms, Breadth-First Search (BFS) and Random Query, within the context of evolving robot morphologies using CPPNs and robot controllers using tensors, and testing them in two evolutionary frameworks, Lamarckian and Darwinian systems, this study investigates their influence on evolutionary outcomes and performance. The findings demonstrate the impact of the two query mechanisms on the evolution and performance of modular robot bodies, including morphological intelligence, diversity, and morphological traits. This study suggests that BFS is both more effective and 
    
[^72]: 采样 - 变分自编码器 - 集成：在可解释人工智能的探索中

    Sampling - Variational Auto Encoder - Ensemble: In the Quest of Explainable Artificial Intelligence. (arXiv:2309.14385v1 [cs.LG])

    [http://arxiv.org/abs/2309.14385](http://arxiv.org/abs/2309.14385)

    本研究通过采样-变分自编码器（VAE）-集成异常检测（SVEAD）框架的实证评估，在可解释人工智能（XAI）领域做出了贡献。研究发现，集成堆叠、VAE和SHAP的结合不仅可以提高模型性能，还提供了一个易于解释的框架。

    

    可解释人工智能（XAI）模型近年来引起了各个应用领域的广泛兴趣。尽管在这个领域取得了显著进展，但目前仍缺乏标准化的方法或途径来理解人工智能模型的输出。为了弥合这一差距，一个系统和有凝聚力的框架已经越来越必要，以整合新的技术，如判别模型和生成模型。本文通过提出一个基于新颖框架的经验评估，即采样 - 变分自编码器（VAE） - 集成异常检测（SVEAD），为XAI的讨论做出了贡献。该框架是一个混合架构，其中VAE与集成堆叠和SHapley可加性解释（SHAP）用于不平衡分类。研究结果表明，集成堆叠、VAE和SHAP的结合不仅可以提高模型性能，而且提供了一个易于解释的框架。本研究还结合排列重要性和内部与外部重要性的SHAP进行了研究。

    Explainable Artificial Intelligence (XAI) models have recently attracted a great deal of interest from a variety of application sectors. Despite significant developments in this area, there are still no standardized methods or approaches for understanding AI model outputs. A systematic and cohesive framework is also increasingly necessary to incorporate new techniques like discriminative and generative models to close the gap. This paper contributes to the discourse on XAI by presenting an empirical evaluation based on a novel framework: Sampling - Variational Auto Encoder (VAE) - Ensemble Anomaly Detection (SVEAD). It is a hybrid architecture where VAE combined with ensemble stacking and SHapley Additive exPlanations are used for imbalanced classification. The finding reveals that combining ensemble stacking, VAE, and SHAP can. not only lead to better model performance but also provide an easily explainable framework. This work has used SHAP combined with Permutation Importance and In
    
[^73]: 通过利用人工智能进行咳嗽诊断: 一项调查

    Towards using Cough for Respiratory Disease Diagnosis by leveraging Artificial Intelligence: A Survey. (arXiv:2309.14383v1 [cs.SD])

    [http://arxiv.org/abs/2309.14383](http://arxiv.org/abs/2309.14383)

    使用人工智能利用咳嗽诊断呼吸道疾病已经成为一个有希望的趋势，通过研究咳嗽特征进行深度学习算法的发展可以可靠准确地检测特定呼吸系统疾病的发作。

    

    咳嗽声音包含着呼吸系统病理形态学改变的众多重要信息。通过研究潜在的咳嗽特征以及疾病诊断，可可靠准确地检测咳嗽事件在恢复医疗实践中发挥不可或缺的作用。人工智能（AI）的近期应用和泛在计算的进步为呼吸道疾病预测开创了有利的趋势和无数未来可能性。特别是，基于机器学习（ML）和深度学习（DL）的咳嗽诊断算法的迅速出现已经开始利用咳嗽特征。大量关于基于咳嗽的AI算法的文献表明，这些模型可以在检测特定呼吸系统疾病的发作方面发挥重要作用。然而，对医疗专家来说，以详尽的方式收集所有相关研究的信息是非常关键的。

    Cough acoustics contain multitudes of vital information about pathomorphological alterations in the respiratory system. Reliable and accurate detection of cough events by investigating the underlying cough latent features and disease diagnosis can play an indispensable role in revitalizing the healthcare practices. The recent application of Artificial Intelligence (AI) and advances of ubiquitous computing for respiratory disease prediction has created an auspicious trend and myriad of future possibilities in the medical domain. In particular, there is an expeditiously emerging trend of Machine learning (ML) and Deep Learning (DL)-based diagnostic algorithms exploiting cough signatures. The enormous body of literature on cough-based AI algorithms demonstrate that these models can play a significant role for detecting the onset of a specific respiratory disease. However, it is pertinent to collect the information from all relevant studies in an exhaustive manner for the medical experts a
    
[^74]: 同意不同意

    Agree To Disagree. (arXiv:2309.14382v1 [cs.CL])

    [http://arxiv.org/abs/2309.14382](http://arxiv.org/abs/2309.14382)

    "同意不同意"论文提出了一种基于机器学习的方法，旨在自动解析和总结使用户便于理解的关键信息，以帮助用户在承诺协议之前考虑重要细节。

    

    在注册服务、安装软件或访问网站之前，个人有多频繁地仔细审查条款和条件？大多数互联网用户并不参与这种做法。鉴于条款和条件通常包含大量复杂的法律术语和晦涩难懂的句子，这种趋势并不令人意外。本文介绍了一种基于机器学习的方法，旨在以用户友好的方式自动解析和总结关键信息。这项技术专注于提取用户在承诺协议之前应考虑的相关细节。

    How frequently do individuals thoroughly review terms and conditions before proceeding to register for a service, install software, or access a website? The majority of internet users do not engage in this practice. This trend is not surprising, given that terms and conditions typically consist of lengthy documents replete with intricate legal terminology and convoluted sentences. In this paper, we introduce a Machine Learning-powered approach designed to automatically parse and summarize critical information in a user-friendly manner. This technology focuses on distilling the pertinent details that users should contemplate before committing to an agreement.
    
[^75]: 社交偏见在视觉-语言模型中的调查

    Survey of Social Bias in Vision-Language Models. (arXiv:2309.14381v1 [cs.CL])

    [http://arxiv.org/abs/2309.14381](http://arxiv.org/abs/2309.14381)

    社交偏见在视觉-语言模型中的调查，旨在为研究人员提供对潜在社会偏见的理解，以解决资源分配不均和不公平代表等问题。

    

    近年来，机器学习模型，尤其是基于Transformer的预训练模型，在自然语言处理和计算机视觉领域取得了快速的发展。然而，研究人员发现这些模型可能会无意中捕捉和强化其训练数据集中存在的社会偏见，导致资源分配不均和对特定社会群体的不公平代表。在人工智能系统中解决这些偏见并确保公平性已经成为机器学习社区的关键关切。最近引入的预训练的视觉-语言模型在新兴的多模态领域中需要关注这些模型中存在的潜在社会偏见。虽然视觉-语言模型容易受到社会偏见的影响，但对于与自然语言处理和计算机视觉中的偏见相比，人们对其了解有限。本调查旨在为研究人员提供高水平的综述和资源，以增进对视觉-语言模型中社会偏见的理解。

    In recent years, the rapid advancement of machine learning (ML) models, particularly transformer-based pre-trained models, has revolutionized Natural Language Processing (NLP) and Computer Vision (CV) fields. However, researchers have discovered that these models can inadvertently capture and reinforce social biases present in their training datasets, leading to potential social harms, such as uneven resource allocation and unfair representation of specific social groups. Addressing these biases and ensuring fairness in artificial intelligence (AI) systems has become a critical concern in the ML community.  The recent introduction of pre-trained vision-and-language (VL) models in the emerging multimodal field demands attention to the potential social biases present in these models as well. Although VL models are susceptible to social bias, there is a limited understanding compared to the extensive discussions on bias in NLP and CV. This survey aims to provide researchers with a high-le
    
[^76]: 机器辅助的混合方法：用人工智能增强人文社科研究

    Machine-assisted mixed methods: augmenting humanities and social sciences with artificial intelligence. (arXiv:2309.14379v1 [cs.CL])

    [http://arxiv.org/abs/2309.14379](http://arxiv.org/abs/2309.14379)

    本研究提出了一种机器辅助的混合方法框架，利用大规模语言模型在人文社科领域的数据分析中的应用潜力，展示了16个案例研究，并涵盖了多种任务，包括语言分析、文本挖掘、社交网络推断等。

    

    大规模语言模型（LLM）的不断进化为人文社科领域的数据分析提供了前所未有的机会，能够在以前通常由人力完成的定性分析任务中实现规模化、自动化。本研究提出了一种系统的混合方法框架，以利用定性分析专业知识、机器的可扩展性和严谨的量化方法，同时注重透明度和可复制性。研究展示了16个机器辅助的案例研究作为概念验证。任务包括语言和话语分析、词汇语义变化检测、采访分析、历史事件因果推断和文本挖掘、政治立场检测、文本和思想重复使用、文学和电影中的文类构成、社交网络推断、自动词典编纂、元数据补充和多模态视觉文化分析。与现有LLM应用文献中对英文的关注不同，本研究涵盖多种语言。

    The increasing capacities of large language models (LLMs) present an unprecedented opportunity to scale up data analytics in the humanities and social sciences, augmenting and automating qualitative analytic tasks previously typically allocated to human labor. This contribution proposes a systematic mixed methods framework to harness qualitative analytic expertise, machine scalability, and rigorous quantification, with attention to transparency and replicability. 16 machine-assisted case studies are showcased as proof of concept. Tasks include linguistic and discourse analysis, lexical semantic change detection, interview analysis, historical event cause inference and text mining, detection of political stance, text and idea reuse, genre composition in literature and film; social network inference, automated lexicography, missing metadata augmentation, and multimodal visual cultural analytics. In contrast to the focus on English in the emerging LLM applicability literature, many exampl
    
[^77]: 基于文本分类的方法用于评估和增强建筑法规的机器可解释性

    A Text Classification-Based Approach for Evaluating and Enhancing the Machine Interpretability of Building Codes. (arXiv:2309.14374v1 [cs.CL])

    [http://arxiv.org/abs/2309.14374](http://arxiv.org/abs/2309.14374)

    该研究提出了一种基于文本分类的方法，自动评估和增强建筑法规的机器可解释性。研究考虑了条款和文档层面的机器可解释性，通过引入几个类别进行分类并开发了一个数据集进行模型训练，并开发了一个高效的文本分类模型。

    

    将监管文件或建筑法规解释为可计算机处理的格式对于智能设计和建造建筑和基础设施至关重要。虽然自动化规则解释（ARI）方法已经研究多年，但其中大部分方法都严重依赖于从建筑法规中早期和手动筛选可解释条款。 虽然其中少数方法考虑了从条款和文档层面上的机器可解释性，但这代表了将其转化为可计算机处理格式的潜力。因此，本研究旨在提出一种新的方法，自动评估和增强单个条款和建筑法规的机器可解释性。首先，引入了几个类别，以考虑对规则解释的要求对每个建筑法规条款进行分类，并开发了一个数据集来进行模型训练。然后，基于预训练的领域特定语言的高效文本分类模型被开发出来。

    Interpreting regulatory documents or building codes into computer-processable formats is essential for the intelligent design and construction of buildings and infrastructures. Although automated rule interpretation (ARI) methods have been investigated for years, most of them highly depend on the early and manual filtering of interpretable clauses from a building code. While few of them considered machine interpretability, which represents the potential to be transformed into a computer-processable format, from both clause- and document-level. Therefore, this research aims to propose a novel approach to automatically evaluate and enhance the machine interpretability of single clause and building codes. First, a few categories are introduced to classify each clause in a building code considering the requirements for rule interpretation, and a dataset is developed for model training. Then, an efficient text classification model is developed based on a pretrained domain-specific language 
    
[^78]: 人类转录质量改进

    Human Transcription Quality Improvement. (arXiv:2309.14372v1 [cs.CL])

    [http://arxiv.org/abs/2309.14372](http://arxiv.org/abs/2309.14372)

    本文提出了一种可靠的方法来收集高质量的语音转录数据，通过在标注阶段进行置信度估计的重新处理和在标注后阶段进行自动词错误修正，成功降低了转录词误率（WER），并发现了转录错误对ASR模型性能的强相关性。

    

    高质量的转录数据对于训练自动语音识别（ASR）系统至关重要。然而，现有的行业级数据收集管道对研究人员来说成本高昂，而众包转录的质量较低。在本文中，我们提出了一种可靠的方法来收集语音转录。我们引入了两种机制来改善转录质量：在标注阶段基于置信度估计的重新处理和在标注后阶段的自动词错误修正。我们收集并发布了LibriCrowd - 一个包含100小时英语语音转录的大规模众包数据集。实验表明，转录词误率（WER）降低了50%以上。我们进一步研究了转录错误对ASR模型性能的影响，并发现了强相关性。转录质量的提升使ASR模型的WER相对减少了10%以上。我们发布了数据集和代码，以造福研究界。

    High quality transcription data is crucial for training automatic speech recognition (ASR) systems. However, the existing industry-level data collection pipelines are expensive to researchers, while the quality of crowdsourced transcription is low. In this paper, we propose a reliable method to collect speech transcriptions. We introduce two mechanisms to improve transcription quality: confidence estimation based reprocessing at labeling stage, and automatic word error correction at post-labeling stage. We collect and release LibriCrowd - a large-scale crowdsourced dataset of audio transcriptions on 100 hours of English speech. Experiment shows the Transcription WER is reduced by over 50%. We further investigate the impact of transcription error on ASR model performance and found a strong correlation. The transcription quality improvement provides over 10% relative WER reduction for ASR models. We release the dataset and code to benefit the research community.
    
[^79]: 基于单位权重的单次迭代量子感知器算法用于非理想训练集

    A Unitary Weights Based One-Iteration Quantum Perceptron Algorithm for Non-Ideal Training Sets. (arXiv:2309.14366v1 [quant-ph])

    [http://arxiv.org/abs/2309.14366](http://arxiv.org/abs/2309.14366)

    提出了一种基于单位权重的高效量子感知器算法，能够解决非理想训练集问题并实现一次迭代学习。算法通过计算训练集中总权重矩阵的奇异值分解来使权重矩阵成为单位阵，并能够精确实现任意量子门。与其他量子感知器算法相比，该算法具有更好的适用性、准确性和可用性。同时，该算法的适用性得到了进一步验证，演示了由多个基本量子门构成的量子复合门。

    

    为了解决非理想训练集（即不完整或过完备集）问题并实现一次迭代学习，提出了一种基于单位权重的高效量子感知器算法，通过计算训练集中总权重矩阵的奇异值分解来使权重矩阵成为单位阵。对量子门{H，S，T，CNOT，Toffoli，Fredkin}的示例验证表明，我们的算法能够在一次迭代中准确实现任意量子门。通过对我们的算法和其他量子感知器算法的性能比较，证明了我们算法在适用性、准确性和可用性方面的优势。为了进一步验证我们算法的适用性，还演示了由几个基本量子门构成的量子复合门。

    In order to solve the problem of non-ideal training sets (i.e., the less-complete or over-complete sets) and implement one-iteration learning, a novel efficient quantum perceptron algorithm based on unitary weights is proposed, where the singular value decomposition of the total weight matrix from the training set is calculated to make the weight matrix to be unitary. The example validation of quantum gates {H, S, T, CNOT, Toffoli, Fredkin} shows that our algorithm can accurately implement arbitrary quantum gates within one iteration. The performance comparison between our algorithm and other quantum perceptron algorithms demonstrates the advantages of our algorithm in terms of applicability, accuracy, and availability. For further validating the applicability of our algorithm, a quantum composite gate which consists of several basic quantum gates is also illustrated.
    
[^80]: 基于大型语言模型的人工智能代理的深度调查

    An In-depth Survey of Large Language Model-based Artificial Intelligence Agents. (arXiv:2309.14365v1 [cs.CL])

    [http://arxiv.org/abs/2309.14365](http://arxiv.org/abs/2309.14365)

    本文研究了基于大型语言模型的AI代理与传统AI代理之间的核心差异和特点，并引入了一种创新的记忆分类方案，提供了全新的设计视角。

    

    由于大型语言模型（LLM）展示了强大的能力，最近人们一直在努力将它们与人工智能代理结合起来，以提高其性能。本文探讨了LLM-based AI代理与传统AI代理之间的核心差异和特点。具体而言，我们首先比较了这两种类型代理的基本特征，阐明了LLM-based代理在处理自然语言、知识存储和推理能力方面的显著优势。随后，我们对AI代理的关键组成部分，包括规划、记忆和工具使用进行了深入分析。尤其是对于关键的记忆组件，本文引入了一种创新的分类方案，不仅远离了传统的分类方法，而且为AI代理的记忆系统设计提供了全新的视角。我们坚信对这些核心组件进行深入的研究和理解

    Due to the powerful capabilities demonstrated by large language model (LLM), there has been a recent surge in efforts to integrate them with AI agents to enhance their performance. In this paper, we have explored the core differences and characteristics between LLM-based AI agents and traditional AI agents. Specifically, we first compare the fundamental characteristics of these two types of agents, clarifying the significant advantages of LLM-based agents in handling natural language, knowledge storage, and reasoning capabilities. Subsequently, we conducted an in-depth analysis of the key components of AI agents, including planning, memory, and tool use. Particularly, for the crucial component of memory, this paper introduced an innovative classification scheme, not only departing from traditional classification methods but also providing a fresh perspective on the design of an AI agent's memory system. We firmly believe that in-depth research and understanding of these core components
    
[^81]: 通过外部自然问题在知识库上进行多样化问题生成

    Diversifying Question Generation over Knowledge Base via External Natural Questions. (arXiv:2309.14362v1 [cs.CL])

    [http://arxiv.org/abs/2309.14362](http://arxiv.org/abs/2309.14362)

    通过引入新的多样性评估指标，我们提出了一种通过外部自然问题在知识库上进行多样化问题生成的方法。同时，我们设计了一个双模型框架来解决如何增强多样化问题生成的挑战。

    

    先前的知识库问题生成方法主要集中在提高单个生成问题的质量。我们认为，人类出色的改写能力表明相同的语义可以通过不同的表达来传达。以上观点使得多样化问题生成成为一个有趣的任务，其中第一个挑战是多样性评估指标。当前的指标不足以评估多样性，因为它们仅计算生成问题中唯一n-gram的比例，更倾向于衡量重复而非真正的多样性。因此，我们设计了一个新的多样性评估指标，它衡量每个实例的前k个生成问题之间的多样性，同时确保它们与基准问题相关。显然，第二个挑战是如何增强多样化问题生成。为了解决这个问题，我们引入了一个由两个选择模型交织而成的双模型框架。

    Previous methods on knowledge base question generation (KBQG) primarily focus on enhancing the quality of a single generated question. Recognizing the remarkable paraphrasing ability of humans, we contend that diverse texts should convey the same semantics through varied expressions. The above insights make diversifying question generation an intriguing task, where the first challenge is evaluation metrics for diversity. Current metrics inadequately assess the above diversity since they calculate the ratio of unique n-grams in the generated question itself, which leans more towards measuring duplication rather than true diversity. Accordingly, we devise a new diversity evaluation metric, which measures the diversity among top-k generated questions for each instance while ensuring their relevance to the ground truth. Clearly, the second challenge is how to enhance diversifying question generation. To address this challenge, we introduce a dual model framework interwoven by two selection
    
[^82]: 优化具有可变不确定性的机会约束子模问题

    Optimizing Chance-Constrained Submodular Problems with Variable Uncertainties. (arXiv:2309.14359v1 [math.OC])

    [http://arxiv.org/abs/2309.14359](http://arxiv.org/abs/2309.14359)

    本论文首次对具有可变不确定性的机会约束子模问题进行了详细分析，并提出了贪婪算法，可以获得高质量的解决方案。

    

    机会约束经常用于限制约束在涉及随机组件的现实优化问题中的违反概率。我们研究了具有随机约束的子模优化问题，这种问题涵盖了一系列具有随机约束的优化问题。之前的研究考虑了具有随机背包约束的子模问题，其中每个可选择的项目的不确定性是相同的。然而，在现实场景中，不确定性水平通常与不同的随机组件有关，对于这种设置缺乏严格的分析在子模优化的上下文中提供了首个这样的分析：项目的权重具有相同的期望但不同的离散度。我们提出了贪婪算法，可以获得高质量的解决方案，即对给定最优解的恒定逼近比。

    Chance constraints are frequently used to limit the probability of constraint violations in real-world optimization problems where the constraints involve stochastic components. We study chance-constrained submodular optimization problems, which capture a wide range of optimization problems with stochastic constraints. Previous studies considered submodular problems with stochastic knapsack constraints in the case where uncertainties are the same for each item that can be selected. However, uncertainty levels are usually variable with respect to the different stochastic components in real-world scenarios, and rigorous analysis for this setting is missing in the context of submodular optimization. This paper provides the first such analysis for this case, where the weights of items have the same expectation but different dispersion. We present greedy algorithms that can obtain a high-quality solution, i.e., a constant approximation ratio to the given optimal solution from the determinis
    
[^83]: 企业信用评级：一项调查

    Corporate Credit Rating: A Survey. (arXiv:2309.14349v1 [cs.LG])

    [http://arxiv.org/abs/2309.14349](http://arxiv.org/abs/2309.14349)

    本论文对企业信用评级进行了系统的调查，总结了CCR的发展背景，比较了不同模型的优缺点，并展望了CCR的未来。

    

    企业信用评级（CCR）在当代经济和社会发展过程中扮演着非常重要的角色。如何使用信用评级方法对企业进行评估一直是一个值得讨论的问题。通过国内外相关文献的阅读和研究，本论文对CCR进行了系统的调查。本论文从统计模型、机器学习模型和神经网络模型的三个层面整理了CCR方法发展的背景，总结了CCR的常见数据集，并深入比较了这些模型的优缺点。最后，本论文总结了当前研究存在的问题，并展望了CCR的未来。与现有的CCR综述相比，本论文详细阐述和分析了神经网络模型在这一领域近年来的进展。

    Corporate credit rating (CCR) plays a very important role in the process of contemporary economic and social development. How to use credit rating methods for enterprises has always been a problem worthy of discussion. Through reading and studying the relevant literature at home and abroad, this paper makes a systematic survey of CCR. This paper combs the context of the development of CCR methods from the three levels: statistical models, machine learning models and neural network models, summarizes the common databases of CCR, and deeply compares the advantages and disadvantages of the models. Finally, this paper summarizes the problems existing in the current research and prospects the future of CCR. Compared with the existing review of CCR, this paper expounds and analyzes the progress of neural network model in this field in recent years.
    
[^84]: 通过稳健对齐的LLM抵御对齐破坏攻击

    Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM. (arXiv:2309.14348v1 [cs.CL])

    [http://arxiv.org/abs/2309.14348](http://arxiv.org/abs/2309.14348)

    本文提出了一种稳健对齐的LLM（RA-LLM），用于防御可能发生的对齐破坏攻击。RA-LLM可以直接在现有的对齐LLM上构建，并通过稳健的对齐检查函数来确保其有效性。

    

    最近，大型语言模型（LLMs）取得了显著的进展，并在各个领域得到广泛应用。不幸的是，人们越来越担心LLMs可能被滥用来生成有害或恶意内容。尽管有一系列的研究专注于对齐LLMs与人类价值观，并防止它们生成不适当的内容，但这些对齐通常是脆弱的，并且可以通过对抗优化或手工构建的越狱提示来绕过。在这项工作中，我们介绍了一种稳健对齐的LLM（RA-LLM），以防范潜在的对齐破坏攻击。RA-LLM可以直接构建在现有的对齐LLM上，通过具有稳健对齐检查功能的方法，而无需对原始LLM进行任何昂贵的重新训练或微调。此外，我们还通过理论分析验证了RA-LLM在防御对齐破坏攻击方面的有效性。通过现实世界的实验，

    Recently, Large Language Models (LLMs) have made significant advancements and are now widely used across various domains. Unfortunately, there has been a rising concern that LLMs can be misused to generate harmful or malicious content. Though a line of research has focused on aligning LLMs with human values and preventing them from producing inappropriate content, such alignments are usually vulnerable and can be bypassed by alignment-breaking attacks via adversarially optimized or handcrafted jailbreaking prompts. In this work, we introduce a Robustly Aligned LLM (RA-LLM) to defend against potential alignment-breaking attacks. RA-LLM can be directly constructed upon an existing aligned LLM with a robust alignment checking function, without requiring any expensive retraining or fine-tuning process of the original LLM. Furthermore, we also provide a theoretical analysis for RA-LLM to verify its effectiveness in defending against alignment-breaking attacks. Through real-world experiments
    
[^85]: 基于LLM的代码生成中的偏差评估与缓解

    Bias Assessment and Mitigation in LLM-based Code Generation. (arXiv:2309.14345v1 [cs.SE])

    [http://arxiv.org/abs/2309.14345](http://arxiv.org/abs/2309.14345)

    这项研究提出了一个新颖的偏差评估框架，针对代码生成任务进行设计。通过对九个最先进的基于LLM的代码生成模型进行广泛评估，发现其中31.45\%到79.93\%的代码函数具有偏见，并提出了如何缓解这种偏见的方法。

    

    利用最新的大型语言模型（LLM），自动代码生成模型在提高软件开发编码过程的生产力和效率方面起着至关重要的作用。随着LLM在软件编码生态系统中的普及，一个紧迫的问题已经出现：生成的代码是否包含与年龄、性别和种族相关的社会偏见？这个问题关系到依赖于这些模型生成的代码的软件应用的完整性、公平性和道德基础，然而在文献中还没有得到充分探讨。本文提出了一个专为代码生成任务设计的新颖偏差评估框架。基于该框架，我们对九个最先进的基于LLM的代码生成模型的偏差进行了广泛评估。我们的发现揭示了，首先，我们评估的代码生成模型生成的31.45\%到79.93\%的代码函数具有偏见，9.68\%到37.37\%的代码函数的功能使

    Utilizing state-of-the-art Large Language Models (LLMs), automatic code generation models play a pivotal role in enhancing the productivity and efficiency of software development coding procedures. As the adoption of LLMs becomes more widespread in software coding ecosystems, a pressing issue has emerged: does the generated code contain social biases, such as those related to age, gender, and race? This issue concerns the integrity, fairness, and ethical foundation of software applications that depend on the code generated by these models, yet is under-explored in the literature. This paper presents a novel bias assessment framework that is specifically designed for code generation tasks. Based on this framework, we conduct an extensive evaluation on the bias of nine state-of-the-art LLM-based code generation models. Our findings reveal that first, 31.45\% to 79.93\% code functions generated by our evaluated code generation models are biased, and 9.68\% to 37.37\% code functions' funct
    
[^86]: AIGC的创新数字叙事探索与讨论：对最新进展的探索与讨论

    Innovative Digital Storytelling with AIGC: Exploration and Discussion of Recent Advances. (arXiv:2309.14329v1 [cs.HC] CROSS LISTED)

    [http://arxiv.org/abs/2309.14329](http://arxiv.org/abs/2309.14329)

    本研究探索了AIGC与数字叙事的整合状态，发现虽然AIGC在某些领域表现出色，但由于人类的创造力和审美感等因素，仍无法替代人类在复杂人物动画、面部表情和音效方面的贡献。

    

    数字叙事作为一种艺术形式，一直在费用与质量之间挣扎。AI生成内容（AIGC）的出现被视为高效数字叙事制作的潜在解决方案。然而，这种融合的具体形式、效果和影响仍不清楚，使得AIGC与叙事的边界模糊不清。本研究探讨了AIGC与数字叙事的当前整合状态，在样本项目中研究了两者融合的艺术价值，并通过访谈解决常见问题。通过我们的研究，我们发现AIGC在图像创作、配音制作和音乐创作方面表现出色，但由于人类创造力和审美感的不可替代元素，尤其是在复杂人物动画、面部表情和音效方面，AIGC还无法取代人类。本研究的目标是增强公众对当前状态、限制和挑战的认识。

    Digital storytelling, as an art form, has struggled with cost-quality balance. The emergence of AI-generated Content (AIGC) is considered as a potential solution for efficient digital storytelling production. However, the specific form, effects, and impacts of this fusion remain unclear, leaving the boundaries of AIGC combined with storytelling undefined. This work explores the current integration state of AIGC and digital storytelling, investigates the artistic value of their fusion in a sample project, and addresses common issues through interviews. Through our study, we conclude that AIGC, while proficient in image creation, voiceover production, and music composition, falls short of replacing humans due to the irreplaceable elements of human creativity and aesthetic sensibilities at present, especially in complex character animations, facial expressions, and sound effects. The research objective is to increase public awareness of the current state, limitations, and challenges arisi
    
[^87]: MoDem-V2: 面向真实世界机器人操作的视觉-运动世界模型

    MoDem-V2: Visuo-Motor World Models for Real-World Robot Manipulation. (arXiv:2309.14236v1 [cs.RO] CROSS LISTED)

    [http://arxiv.org/abs/2309.14236](http://arxiv.org/abs/2309.14236)

    MoDem-V2是一个能够在非仪器化的真实世界中直接学习接触丰富操作的系统。

    

    希望在非仪器化的真实世界环境中运行的机器人系统必须通过机载传感器直接感知世界。基于视觉的学习系统旨在通过基于原始像素的隐式对世界的理解，消除环境装置的需求，但仅仅依靠稀疏的视觉奖励信号在接触丰富的高维搜索空间中导航，显著加剧了探索的难度。因此，这种系统的适用性通常局限于模拟或严格工程化的环境，因为在没有明确的状态估计和稠密奖励的指导下，在真实世界中进行代理的探索可能导致不安全行为和重大安全故障。在本研究中，我们分离了这些限制的根本原因，开发了一个名为MoDem-V2的系统，能够直接在非仪器化的真实世界中学习接触丰富的操作。在最新的算法进展的基础上构建，

    Robotic systems that aspire to operate in uninstrumented real-world environments must perceive the world directly via onboard sensing. Vision-based learning systems aim to eliminate the need for environment instrumentation by building an implicit understanding of the world based on raw pixels, but navigating the contact-rich high-dimensional search space from solely sparse visual reward signals significantly exacerbates the challenge of exploration. The applicability of such systems is thus typically restricted to simulated or heavily engineered environments since agent exploration in the real-world without the guidance of explicit state estimation and dense rewards can lead to unsafe behavior and safety faults that are catastrophic. In this study, we isolate the root causes behind these limitations to develop a system, called MoDem-V2, capable of learning contact-rich manipulation directly in the uninstrumented real world. Building on the latest algorithmic advancements in model-based
    
[^88]: Species196：一百万半监督数据集用于细粒度物种识别

    Species196: A One-Million Semi-supervised Dataset for Fine-grained Species Recognition. (arXiv:2309.14183v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.14183](http://arxiv.org/abs/2309.14183)

    Species196是一个包含196个类别的大规模半监督数据集，用于细粒度物种识别。它提供了四种实验设置，可以用于基准测试现有模型和算法的性能。

    

    基于基础视觉模型的发展，普通视觉识别已经达到了一个很高的水平，但是不能很好地处理专门领域中的细粒度识别，比如入侵物种分类。识别和管理入侵物种具有很强的社会和生态价值。目前，大多数入侵物种数据集的规模有限，覆盖的物种范围狭窄，这限制了基于深度学习的入侵生物计量系统的发展。为了填补这个领域的空白，我们引入了Species196，一个包含196个类别的大规模半监督数据集。它收集了超过19K带有专家级准确注释的图像Species196-L，以及120万张未标记的入侵物种图像Species196-U。该数据集提供了四种实验设置，用于基准测试现有的模型和算法，分别是监督学习、半监督学习、自监督预训练和大型多模态模型的零样本推理能力。

    The development of foundation vision models has pushed the general visual recognition to a high level, but cannot well address the fine-grained recognition in specialized domain such as invasive species classification. Identifying and managing invasive species has strong social and ecological value. Currently, most invasive species datasets are limited in scale and cover a narrow range of species, which restricts the development of deep-learning based invasion biometrics systems. To fill the gap of this area, we introduced Species196, a large-scale semi-supervised dataset of 196-category invasive species. It collects over 19K images with expert-level accurate annotations Species196-L, and 1.2M unlabeled images of invasive species Species196-U. The dataset provides four experimental settings for benchmarking the existing models and algorithms, namely, supervised learning, semi-supervised learning, self-supervised pretraining and zero-shot inference ability of large multi-modal models. T
    
[^89]: ICU 重新入院预测的可解释机器学习

    Explainable Machine Learning for ICU Readmission Prediction. (arXiv:2309.13781v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.13781](http://arxiv.org/abs/2309.13781)

    本研究提出了一个标准化且可解释的机器学习流程，用于在多中心数据库中预测加护病房患者的再入院情况。

    

    加护病房（ICU）是一个复杂的医院环境，医生的决策对患者的生命构成高风险。必须遵循一条全面的护理路径来减少并发症。在这种环境中，不确定性、竞争性和非计划性的因素增加了统一实施护理路径的困难。再入院是该路径的困难之一，即患者在短时间内再次入住ICU，导致高死亡率和高资源利用率。一些研究尝试通过患者的医疗信息来预测再入院情况。尽管它们在预测再入院时有一定的成功，但这些研究并未对再入院预测进行适当的评估、描述和理解。本研究提出了一个标准化且可解释的机器学习流程，用于在多中心数据库（即包含166,355名患者的eICU队列，200,859名...）

    The intensive care unit (ICU) comprises a complex hospital environment, where decisions made by clinicians have a high level of risk for the patients' lives. A comprehensive care pathway must then be followed to reduce p complications. Uncertain, competing and unplanned aspects within this environment increase the difficulty in uniformly implementing the care pathway. Readmission contributes to this pathway's difficulty, occurring when patients are admitted again to the ICU in a short timeframe, resulting in high mortality rates and high resource utilisation. Several works have tried to predict readmission through patients' medical information. Although they have some level of success while predicting readmission, those works do not properly assess, characterise and understand readmission prediction. This work proposes a standardised and explainable machine learning pipeline to model patient readmission on a multicentric database (i.e., the eICU cohort with 166,355 patients, 200,859 ad
    
[^90]: 概率权重固定：用于量化的神经网络权重不确定性的大规模训练

    Probabilistic Weight Fixing: Large-scale training of neural network weight uncertainties for quantization. (arXiv:2309.13575v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.13575](http://arxiv.org/abs/2309.13575)

    本文提出了一种基于贝叶斯神经网络和变分松弛的概率框架，用于通过将权重值限制在一组有限值上来减少推理过程中的能量消耗。通过利用权重值的概率分布，提高了噪声鲁棒性和可压缩性。迭代聚类过程展示了超越现有方法的优势。

    

    权重共享量化是一种通过将神经网络的权重限制在一组有限的值上来减少推理过程中能量消耗的技术。然而，现有的权重共享量化方法常常基于权重值本身进行假设，并忽视了权重位置在其中扮演的独特角色。本文提出了一个基于贝叶斯神经网络（BNNs）和变分松弛的概率框架，根据单个权重的位置特定学习不确定性分布来确定可以将哪些权重移动到哪个聚类中心以及移动到什么程度。我们引入了一种新的初始化设置和正则化项，可以在复杂的数据集-模型组合下训练BNNs。通过利用通过概率分布捕捉到的权重值的灵活性，我们提高了噪声的鲁棒性和下游的可压缩性。我们的迭代聚类过程展示了超越现有方法的优越性能。

    Weight-sharing quantization has emerged as a technique to reduce energy expenditure during inference in large neural networks by constraining their weights to a limited set of values. However, existing methods for weight-sharing quantization often make assumptions about the treatment of weights based on value alone that neglect the unique role weight position plays. This paper proposes a probabilistic framework based on Bayesian neural networks (BNNs) and a variational relaxation to identify which weights can be moved to which cluster centre and to what degree based on their individual position-specific learned uncertainty distributions. We introduce a new initialisation setting and a regularisation term which allow for the training of BNNs under complex dataset-model combinations. By leveraging the flexibility of weight values captured through a probability distribution, we enhance noise resilience and downstream compressibility. Our iterative clustering procedure demonstrates superio
    
[^91]: 全球相关的三维解耦Transformer用于服装化身重建

    Global-correlated 3D-decoupling Transformer for Clothed Avatar Reconstruction. (arXiv:2309.13524v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.13524](http://arxiv.org/abs/2309.13524)

    这项研究提出了全球相关的三维解耦Transformer架构，用于从单目图像中重建具有衣服的人物化身。通过使用Transformer模型捕捉全局相关的图像特征，并采用创新的3D解耦解码器进行特征融合，实现了更好的重建效果。

    

    从单一图像中重建三维服装化身是一项具有挑战性的任务，特别是在遇到复杂姿势和宽松衣物时。现有方法在性能上存在局限性，这主要归因于它们对不足的二维图像特征和不一致的查询方法的依赖。基于此，我们提出了用于服装化身重建的全球相关的三维解耦Transformer（GTA），这是一种基于Transformer的创新体系结构，可以从单目图像中重建出具有衣服的人物化身。我们的方法利用Transformer体系结构，通过使用Vision Transformer模型作为编码器来捕捉全球相关的图像特征。随后，我们创新性地采用交叉注意力来解耦三位平面特征，并使用可学习的嵌入作为跨平面生成的查询。为了有效增强与三维特征和人体先验的特征融合，我们提出了一种融合空间和p的混合先验融合策略

    Reconstructing 3D clothed human avatars from single images is a challenging task, especially when encountering complex poses and loose clothing. Current methods exhibit limitations in performance, largely attributable to their dependence on insufficient 2D image features and inconsistent query methods. Owing to this, we present the Global-correlated 3D-decoupling Transformer for clothed Avatar reconstruction (GTA), a novel transformer-based architecture that reconstructs clothed human avatars from monocular images. Our approach leverages transformer architectures by utilizing a Vision Transformer model as an encoder for capturing global-correlated image features. Subsequently, our innovative 3D-decoupling decoder employs cross-attention to decouple tri-plane features, using learnable embeddings as queries for cross-plane generation. To effectively enhance feature fusion with the tri-plane 3D feature and human body prior, we propose a hybrid prior fusion strategy combining spatial and p
    
[^92]: MiChao-HuaFen 1.0：面向领域特定大模型的专用预训练语料数据集

    MiChao-HuaFen 1.0: A Specialized Pre-trained Corpus Dataset for Domain-specific Large Models. (arXiv:2309.13079v1 [cs.CL])

    [http://arxiv.org/abs/2309.13079](http://arxiv.org/abs/2309.13079)

    MiChao-HuaFen 1.0是一个专为新闻和政府部门定制的面向领域特定大模型的预训练语料数据集，它不仅能够满足特定领域的高质量需求，还有助于推动相关领域的深度学习研究和应用。

    

    随着深度学习技术的进步，如GPT-4等通用大模型已经在各个领域展现出卓越的能力。然而，在诸如医疗、法律和金融等领域仍然存在对高质量的领域特定输出的需求。本文首先评估了现有的面向特定领域的大模型，并讨论了它们的局限性。为了满足特定领域的特殊需求，我们引入了“MiChao-HuaFen 1.0”预训练语料数据集，该数据集特别针对新闻和政府部门。该数据集来源于2022年公开可用的互联网数据，经过多轮清洁和处理以确保高质量和可靠性，并具备持续和稳定的更新机制。该数据集不仅支持针对中文垂直领域的大模型的预训练，还助力于推动相关领域的深度学习研究和应用。

    With the advancement of deep learning technologies, general-purpose large models such as GPT-4 have demonstrated exceptional capabilities across various domains. Nevertheless, there remains a demand for high-quality, domain-specific outputs in areas like healthcare, law, and finance. This paper first evaluates the existing large models for specialized domains and discusses their limitations. To cater to the specific needs of certain domains, we introduce the ``MiChao-HuaFen 1.0'' pre-trained corpus dataset, tailored for the news and governmental sectors. The dataset, sourced from publicly available internet data from 2022, underwent multiple rounds of cleansing and processing to ensure high quality and reliable origins, with provisions for consistent and stable updates. This dataset not only supports the pre-training of large models for Chinese vertical domains but also aids in propelling deep learning research and applications in related fields.
    
[^93]: InvestLM：使用金融领域指导调优的大型语言模型

    InvestLM: A Large Language Model for Investment using Financial Domain Instruction Tuning. (arXiv:2309.13064v1 [q-fin.GN])

    [http://arxiv.org/abs/2309.13064](http://arxiv.org/abs/2309.13064)

    InvestLM是一个通过对金融领域指导数据集进行调优的大型语言模型，具有强大的理解金融文本的能力，并在投资相关问题上提供有帮助的回答。金融专家评价其与最先进的商业模型可媲美，并在金融NLP基准问题上展现了强大的泛化能力。

    

    我们介绍了一种新的金融领域大型语言模型InvestLM，该模型通过精心策划的与金融投资相关的指导数据集对LLaMA-65B进行调优。受到“少即是多”的启发，我们手动策划了一个既小又多样的指导数据集，涵盖了从特许金融分析师（CFA）考试问题到SEC文件和Stackexchange量化金融讨论的广泛金融相关主题。InvestLM表现出良好的理解金融文本的能力，并对投资相关问题提供有帮助的回答。包括对冲基金经理和研究分析师在内的金融专家将InvestLM的回答评价为与最先进的商业模型（GPT-3.5、GPT-4和Claude-2）可媲美。对一组金融NLP基准问题进行零样本评估表明了其强大的泛化能力。从研究角度来看，本研究表明可以使用高质量的领域特定LLM进行调优。

    We present a new financial domain large language model, InvestLM, tuned on LLaMA-65B (Touvron et al., 2023), using a carefully curated instruction dataset related to financial investment. Inspired by less-is-more-for-alignment (Zhou et al., 2023), we manually curate a small yet diverse instruction dataset, covering a wide range of financial related topics, from Chartered Financial Analyst (CFA) exam questions to SEC filings to Stackexchange quantitative finance discussions. InvestLM shows strong capabilities in understanding financial text and provides helpful responses to investment related questions. Financial experts, including hedge fund managers and research analysts, rate InvestLM's response as comparable to those of state-of-the-art commercial models (GPT-3.5, GPT-4 and Claude-2). Zero-shot evaluation on a set of financial NLP benchmarks demonstrates strong generalizability. From a research perspective, this work suggests that a high-quality domain specific LLM can be tuned usin
    
[^94]: 基于量子计算的投资组合优化系统：利用未来资产价值和自动减少投资范围

    A Quantum Computing-based System for Portfolio Optimization using Future Asset Values and Automatic Reduction of the Investment Universe. (arXiv:2309.12627v1 [cs.AI])

    [http://arxiv.org/abs/2309.12627](http://arxiv.org/abs/2309.12627)

    本研究提出了一种基于量子计算的投资组合优化系统Q4FuturePOP，它创新地利用未来资产价值进行建模，并引入了一个自动减少投资范围的模块。通过实验讨论了Q4FuturePOP的原型版本中不同模块的初步性能。

    

    量化金融中备受关注的问题之一是投资组合优化问题。针对该问题，近年来利用量子计算的技术得到了广泛应用。本研究介绍了一种名为Q4FuturePOP的基于量子计算的投资组合优化系统，该系统通过以下创新解决了投资组合优化问题：i）该工具针对未来资产预测进行建模，而不是使用历史数据；ii）Q4FuturePOP包括一个智能减少问题复杂性的自动减少投资范围模块。此外，我们还对Q4FuturePOP的原型版本的不同模块的初步性能进行了简要讨论。

    One of the problems in quantitative finance that has received the most attention is the portfolio optimization problem. Regarding its solving, this problem has been approached using different techniques, with those related to quantum computing being especially prolific in recent years. In this study, we present a system called Quantum Computing-based System for Portfolio Optimization with Future Asset Values and Automatic Universe Reduction (Q4FuturePOP), which deals with the Portfolio Optimization Problem considering the following innovations: i) the developed tool is modeled for working with future prediction of assets, instead of historical values; and ii) Q4FuturePOP includes an automatic universe reduction module, which is conceived to intelligently reduce the complexity of the problem. We also introduce a brief discussion about the preliminary performance of the different modules that compose the prototypical version of Q4FuturePOP.
    
[^95]: 多模态深度学习用于科学成像解释

    Multimodal Deep Learning for Scientific Imaging Interpretation. (arXiv:2309.12460v1 [cs.LG])

    [http://arxiv.org/abs/2309.12460](http://arxiv.org/abs/2309.12460)

    本研究提出了一种多模态深度学习框架，通过模拟人类与扫描电子显微镜图像的交互，利用文本和视觉数据进行精细数据合成和评估。该模型（GlassLLaVA）能够准确解释、识别关键特征和检测以前未见的SEM图像中的缺陷，同时引入了适用于多种科学成像应用的灵活评估指标。

    

    在科学成像领域，解释视觉数据常常需要人类专业知识和对主题材料的深入理解的复杂组合。本研究提出了一种新的方法，通过多模态深度学习框架来模拟并评估与扫描电子显微镜（SEM）图像的人类交互，特别是玻璃材料图像。我们的方法利用从同行评议的文章中收集的文本和视觉数据，进一步借助 GPT-4 的能力进行精细数据合成和评估。尽管存在诸多挑战，如细微的解释和专业数据集的有限可用性，但我们的模型（GlassLLaVA）在制定准确的解释、识别关键特征和检测以前未见的SEM图像中的缺陷方面表现出色。此外，我们引入了适用于多种科学成像应用的灵活评估指标，使得进行综合评估成为可能。

    In the domain of scientific imaging, interpreting visual data often demands an intricate combination of human expertise and deep comprehension of the subject materials. This study presents a novel methodology to linguistically emulate and subsequently evaluate human-like interactions with Scanning Electron Microscopy (SEM) images, specifically of glass materials. Leveraging a multimodal deep learning framework, our approach distills insights from both textual and visual data harvested from peer-reviewed articles, further augmented by the capabilities of GPT-4 for refined data synthesis and evaluation. Despite inherent challenges--such as nuanced interpretations and the limited availability of specialized datasets--our model (GlassLLaVA) excels in crafting accurate interpretations, identifying key features, and detecting defects in previously unseen SEM images. Moreover, we introduce versatile evaluation metrics, suitable for an array of scientific imaging applications, which allows for
    
[^96]: 对多模态大规模语言模型中的灾难性遗忘进行的研究

    Investigating the Catastrophic Forgetting in Multimodal Large Language Models. (arXiv:2309.10313v1 [cs.CL])

    [http://arxiv.org/abs/2309.10313](http://arxiv.org/abs/2309.10313)

    本论文针对多模态大规模语言模型中的灾难性遗忘问题进行研究，引入了EMT方法来评估灾难性遗忘，并发现在标准图像分类任务上，几乎所有评估的模型都无法保持与视觉编码器相同的性能水平。研究结果表明，早期微调阶段对性能至关重要。

    

    在GPT4的成功之后，多模态大规模语言模型（MLLM）研究引起了广泛关注。这一研究方向侧重于通过微调预训练的LLM和视觉模型来开发通用的LLM。然而，灾难性遗忘，即微调模型无法保持与预训练模型相似的性能水平，仍然是多模态LLM（MLLM）中的一个固有问题。本文介绍了EMT：用于评估MLLM中灾难性遗忘的评估方法，将每个MLLM作为一个图像分类器进行评估。我们首先应用EMT来评估几个开源的微调MLLM，并发现几乎所有评估的MLLM在标准图像分类任务上无法保持与他们的视觉编码器相同的性能水平。此外，我们继续微调LLaVA，一种MLLM，并利用EMT来评估整个微调过程中的性能。有趣的是，我们的结果表明，早期的微调阶段是关键的，过早停止微调可能导致低性能的模型。

    Following the success of GPT4, there has been a surge in interest in multimodal large language model (MLLM) research. This line of research focuses on developing general-purpose LLMs through fine-tuning pre-trained LLMs and vision models. However, catastrophic forgetting, a notorious phenomenon where the fine-tuned model fails to retain similar performance compared to the pre-trained model, still remains an inherent problem in multimodal LLMs (MLLM). In this paper, we introduce EMT: Evaluating MulTimodality for evaluating the catastrophic forgetting in MLLMs, by treating each MLLM as an image classifier. We first apply EMT to evaluate several open-source fine-tuned MLLMs and we discover that almost all evaluated MLLMs fail to retain the same performance levels as their vision encoders on standard image classification tasks. Moreover, we continue fine-tuning LLaVA, an MLLM and utilize EMT to assess performance throughout the fine-tuning. Interestingly, our results suggest that early-sta
    
[^97]: 超快超轻卷积神经网络智能监测系统用于在任何时间和地点诊断早期猴痘

    Ultrafast-and-Ultralight ConvNet-Based Intelligent Monitoring System for Diagnosing Early-Stage Mpox Anytime and Anywhere. (arXiv:2308.13492v1 [cs.CV])

    [http://arxiv.org/abs/2308.13492](http://arxiv.org/abs/2308.13492)

    提出了一种超快超轻的卷积神经网络Fast-MpoxNet，用于早期猴痘诊断。它具有较小的参数量和较快的处理速度，并通过特征融合和辅助损失增强策略提高了诊断性能。

    

    由于缺乏更高效的猴痘诊断工具，其传播仍然未受控制，给全球健康带来了巨大的挑战。虽然相关研究已经证明了深度学习模型在猴痘诊断方面的高效性，但是对于早期猴痘的推理速度、参数大小和诊断性能的忽视使得这些模型无法在现实世界中应用。为了解决这些问题，我们提出了一种超快超轻的网络，名为Fast-MpoxNet。Fast-MpoxNet只有0.27M个参数，并且可以在CPU上以每秒68帧的速度处理输入图像。为了克服小模型容量带来的诊断性能限制，它集成了基于注意力的特征融合模块和多个辅助损失增强策略，以更好地检测微小的图像变化和优化权重。通过转移学习和五折交叉验证，Fast-MpoxNet实现了94.26%的准确率。

    Due to the lack of more efficient diagnostic tools for monkeypox, its spread remains unchecked, presenting a formidable challenge to global health. While the high efficacy of deep learning models for monkeypox diagnosis has been demonstrated in related studies, the overlook of inference speed, the parameter size and diagnosis performance for early-stage monkeypox renders the models inapplicable in real-world settings. To address these challenges, we proposed an ultrafast and ultralight network named Fast-MpoxNet. Fast-MpoxNet possesses only 0.27M parameters and can process input images at 68 frames per second (FPS) on the CPU. To counteract the diagnostic performance limitation brought about by the small model capacity, it integrates the attention-based feature fusion module and the multiple auxiliary losses enhancement strategy for better detecting subtle image changes and optimizing weights. Using transfer learning and five-fold cross-validation, Fast-MpoxNet achieves 94.26% Accuracy
    
[^98]: 利用高效的深度卷积神经网络从智能手机拍摄图像中揭示本地聚合的空气质量指数

    Uncovering local aggregated air quality index with smartphone captured images leveraging efficient deep convolutional neural network. (arXiv:2308.03200v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2308.03200](http://arxiv.org/abs/2308.03200)

    本文利用智能手机拍摄的图像，通过发展一个深度卷积神经网络，成功预测了特定位置的PM2.5浓度，揭示了本地聚合的空气质量指数的潜力。

    

    智能手机的普及和可移动性使其成为环境健康研究中广泛使用的工具。然而，现有文献中对基于特定位置PM2.5浓度确定聚合空气质量指数（AQI）的潜力的研究仍然较少。在本文中，我们深入研究了使用智能手机相机拍摄的图像来预测特定位置PM2.5浓度的挑战。我们的研究重点是孟加拉国首都达卡，因其严重的空气污染水平和大量暴露于其中的人口。我们的研究涉及开发一个深度卷积神经网络（DCNN），我们使用超过一千张在达卡不同地点拍摄和标注的室外图像进行训练。这些照片的标签基于从当地美国领事馆获取的PM2.5浓度数据，使用NowCast算法计算得到。通过监督学习，我们的模型建立了一个c

    The prevalence and mobility of smartphones make these a widely used tool for environmental health research. However, their potential for determining aggregated air quality index (AQI) based on PM2.5 concentration in specific locations remains largely unexplored in the existing literature. In this paper, we thoroughly examine the challenges associated with predicting location-specific PM2.5 concentration using images taken with smartphone cameras. The focus of our study is on Dhaka, the capital of Bangladesh, due to its significant air pollution levels and the large population exposed to it. Our research involves the development of a Deep Convolutional Neural Network (DCNN), which we train using over a thousand outdoor images taken and annotated. These photos are captured at various locations in Dhaka, and their labels are based on PM2.5 concentration data obtained from the local US consulate, calculated using the NowCast algorithm. Through supervised learning, our model establishes a c
    
[^99]: RL-ViGen: 一种用于视觉泛化的强化学习基准

    RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization. (arXiv:2307.10224v1 [cs.AI])

    [http://arxiv.org/abs/2307.10224](http://arxiv.org/abs/2307.10224)

    RL-ViGen是一种用于视觉泛化的强化学习基准，包含多样的任务和广泛的泛化类型，旨在推动对代理人视觉泛化能力的全面评估。

    

    视觉强化学习（Visual RL）与高维观察相结合，一直面临着长期存在的泛化挑战。尽管有重点研究用于解决视觉泛化问题的算法，但我们认为现有的基准存在问题，因为它们局限于孤立的任务和泛化类别，从而削弱了对代理人视觉泛化能力的全面评估。为了弥合这一差距，我们引入了RL-ViGen：一种新型的用于视觉泛化的强化学习基准，其中包含多样的任务和广泛的泛化类型，从而促进得出更可靠的结论。此外，RL-ViGen将最新的泛化视觉强化学习算法融入到一个统一的框架中，实验结果表明，没有单一的现有算法在所有任务上普遍占优势。我们的愿景是RL-ViGen将在这个领域起到催化剂的作用。

    Visual Reinforcement Learning (Visual RL), coupled with high-dimensional observations, has consistently confronted the long-standing challenge of generalization. Despite the focus on algorithms aimed at resolving visual generalization problems, we argue that the devil is in the existing benchmarks as they are restricted to isolated tasks and generalization categories, undermining a comprehensive evaluation of agents' visual generalization capabilities. To bridge this gap, we introduce RL-ViGen: a novel Reinforcement Learning Benchmark for Visual Generalization, which contains diverse tasks and a wide spectrum of generalization types, thereby facilitating the derivation of more reliable conclusions. Furthermore, RL-ViGen incorporates the latest generalization visual RL algorithms into a unified framework, under which the experiment results indicate that no single existing algorithm has prevailed universally across tasks. Our aspiration is that RL-ViGen will serve as a catalyst in this a
    
[^100]: TinyMetaFed: 高效的用于TinyML的联邦元学习

    TinyMetaFed: Efficient Federated Meta-Learning for TinyML. (arXiv:2307.06822v1 [cs.LG])

    [http://arxiv.org/abs/2307.06822](http://arxiv.org/abs/2307.06822)

    TinyMetaFed是一个适用于TinyML的高效联邦元学习框架，通过协同训练神经网络初始化，在小型设备上能够快速微调，同时实现通信节省和隐私保护。

    

    Tiny Machine Learning (TinyML)领域在使得机器学习在低功耗设备（如微控制器）上实现方面取得了重大进展。这些微型设备的普及引发了一个问题，即聚合它们的知识是否能够使TinyML应用受益。联邦元学习是这个问题的一个有前景的答案，因为它解决了现实世界中标记数据的稀缺性和设备之间的异构数据分布。然而，部署TinyML硬件面临着独特的资源限制，现有方法由于能源、隐私和通信限制而不实用。我们引入了TinyMetaFed，一个适用于TinyML的模型无关的元学习框架。TinyMetaFed促进了神经网络初始化的协同训练，可以在新设备上快速微调。它通过部分本地重构和Top-P%选择性通信提供通信节省和隐私保护，具有计算效果好。

    The field of Tiny Machine Learning (TinyML) has made substantial advancements in democratizing machine learning on low-footprint devices, such as microcontrollers. The prevalence of these miniature devices raises the question of whether aggregating their knowledge can benefit TinyML applications. Federated meta-learning is a promising answer to this question, as it addresses the scarcity of labeled data and heterogeneous data distribution across devices in the real world. However, deploying TinyML hardware faces unique resource constraints, making existing methods impractical due to energy, privacy, and communication limitations. We introduce TinyMetaFed, a model-agnostic meta-learning framework suitable for TinyML. TinyMetaFed facilitates collaborative training of a neural network initialization that can be quickly fine-tuned on new devices. It offers communication savings and privacy protection through partial local reconstruction and Top-P% selective communication, computational eff
    
[^101]: LLQL: 逻辑似然 Q-Learning 用于增强学习

    LLQL: Logistic Likelihood Q-Learning for Reinforcement Learning. (arXiv:2307.02345v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.02345](http://arxiv.org/abs/2307.02345)

    本研究通过研究在线和离线增强学习中 Bellman 近似误差的分布发现，Bellman 误差符合逻辑分布。基于这一发现，本研究提出了一种使用 Logistic 最大似然函数作为替代方法的方案，并通过实验证明了其有效性。

    

    现代增强学习（RL）可以分为在线和离线两种变体。作为在线和离线 RL 的关键方面，当前对 Bellman 方程的研究主要集中在优化技术和性能增强上，而不是探索 Bellman 误差的固有结构特性，如其分布特征。本研究通过对 Bellman 方程进行迭代探索，研究了在线 RL 和离线 RL 中 Bellman 近似误差的分布情况。我们观察到无论是在线 RL 还是离线 RL，Bellman 误差都符合逻辑分布。基于这一发现，本研究采用 Logistic 最大似然函数（LLoss）作为常用的 MSE Loss 的替代方法，假设 Bellman 误差服从正态分布。通过广泛的数值实验验证了我们的假设，在不同的在线和离线环境中得到了验证。

    Modern reinforcement learning (RL) can be categorized into online and offline variants. As a pivotal aspect of both online and offline RL, current research on the Bellman equation revolves primarily around optimization techniques and performance enhancement rather than exploring the inherent structural properties of the Bellman error, such as its distribution characteristics. This study investigates the distribution of the Bellman approximation error in both online and offline settings through iterative exploration of the Bellman equation. We observed that both in online RL and offline RL, the Bellman error conforms to a Logistic distribution. Building upon this discovery, this study employed the Logistics maximum likelihood function (LLoss) as an alternative to the commonly used MSE Loss, assuming that Bellman errors adhere to a normal distribution. We validated our hypotheses through extensive numerical experiments across diverse online and offline environments. In particular, we app
    
[^102]: RH20T: 一种用于单次学习多样技能的综合机器人数据集

    RH20T: A Comprehensive Robotic Dataset for Learning Diverse Skills in One-Shot. (arXiv:2307.00595v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2307.00595](http://arxiv.org/abs/2307.00595)

    本文提出了一个用于单次学习多样技能的综合机器人数据集RH20T。该数据集包含超过11万个接触丰富的机器人操纵序列，涵盖了多种技能、环境、机器人和相机视角。这个数据集的目标是使机器人能够具备广泛的一般化能力，包括视觉和触觉感知。

    

    在开放领域的机器人操作中，如何获取多样化且具有一般化能力的机器人技能是一个关键挑战。最近的单次模仿学习研究表明，基于示范，将训练好的策略转移到新任务上具有潜力。这种特性有助于使机器人获得新的技能并改进任务和动作规划。然而，由于训练数据集的限制，目前社区的关注点主要集中在简单的情况，如推动或拾取放置任务，仅依靠视觉指导。实际上，存在许多复杂的技能，其中一些甚至可能需要视觉和触觉感知来解决。本文旨在解锁代理商运用多模态感知推广到数百种现实世界技能的潜力。为实现这一目标，我们收集了一个数据集，其中包括超过11万个跨多种技能、环境、机器人和相机视角的接触丰富的机器人操纵序列。

    A key challenge in robotic manipulation in open domains is how to acquire diverse and generalizable skills for robots. Recent research in one-shot imitation learning has shown promise in transferring trained policies to new tasks based on demonstrations. This feature is attractive for enabling robots to acquire new skills and improving task and motion planning. However, due to limitations in the training dataset, the current focus of the community has mainly been on simple cases, such as push or pick-place tasks, relying solely on visual guidance. In reality, there are many complex skills, some of which may even require both visual and tactile perception to solve. This paper aims to unlock the potential for an agent to generalize to hundreds of real-world skills with multi-modal perception. To achieve this, we have collected a dataset comprising over 110,000 contact-rich robot manipulation sequences across diverse skills, contexts, robots, and camera viewpoints, all collected in the re
    
[^103]: CompanyKG:一种用于公司相似性量化的大规模异构图

    CompanyKG: A Large-Scale Heterogeneous Graph for Company Similarity Quantification. (arXiv:2306.10649v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.10649](http://arxiv.org/abs/2306.10649)

    本研究提出了CompanyKG，一种用于公司相似性量化的大规模异构图数据集。通过丰富的公司特征和关系表示，以及多个评估任务的基准测试，为公司相似性量化方法的综合评估提供了支持。

    

    在投资行业中，对于许多目的包括市场映射、竞争对手分析和并购，进行细粒度公司相似性量化通常是至关重要的。我们提出并发布了一个名为CompanyKG的知识图，用于表示和学习多样化的公司特征和关系。具体而言，1.17百万家公司被表示为节点，丰富了公司描述嵌入; 15种不同的公司间关系导致了5106百万个带权重的边。为了实现对公司相似性量化方法的全面评估，我们设计并编译了三个带有注释测试集的评估任务: 相似性预测、竞争对手检索和相似性排序。我们对11种可重现预测方法进行了广泛的基准测试，分为节点、边和节点+边三组。据我们所知，CompanyKG是第一个大规模的异构图数据集

    In the investment industry, it is often essential to carry out fine-grained company similarity quantification for a range of purposes, including market mapping, competitor analysis, and mergers and acquisitions. We propose and publish a knowledge graph, named CompanyKG, to represent and learn diverse company features and relations. Specifically, 1.17 million companies are represented as nodes enriched with company description embeddings; and 15 different inter-company relations result in 51.06 million weighted edges. To enable a comprehensive assessment of methods for company similarity quantification, we have devised and compiled three evaluation tasks with annotated test sets: similarity prediction, competitor retrieval and similarity ranking. We present extensive benchmarking results for 11 reproducible predictive methods categorized into three groups: node-only, edge-only, and node+edge. To the best of our knowledge, CompanyKG is the first large-scale heterogeneous graph dataset or
    
[^104]: MO-VLN:一个用于开放集合零样本视觉和语言导航的多任务基准 (arXiv:2306.10322v2 [cs.CV] 更新)

    MO-VLN: A Multi-Task Benchmark for Open-set Zero-Shot Vision-and-Language Navigation. (arXiv:2306.10322v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.10322](http://arxiv.org/abs/2306.10322)

    MO-VLN是一个用于评估通用机器人在多任务环境中的视觉和语言导航的基准，通过使用虚幻引擎5开发逼真的场景和包含多种不常见物体来测试其效果和泛化能力。

    

    给定一个自然语言，一个通用的机器人必须理解指令并根据视觉观察找到目标对象或位置，即使在未探索的环境中也能做到。大多数代理依赖于大量多样的训练数据以实现更好的泛化，这需要昂贵的劳动力。这些代理通常只关注常见的对象和较少的任务，因此不足以处理不同类型的指令。为了促进开放集合视觉和语言导航的研究，我们提出了一个名为MO-VLN的基准，旨在测试代理在多任务设置中的有效性和泛化能力。首先，我们使用虚幻引擎5开发了一个3D模拟器，渲染了逼真的场景，包含更真实的光照和细节。模拟器包含三个场景，即咖啡馆、餐厅和养老院，这些场景在工业中具有很高的价值。此外，我们的模拟器涉及多种不常见的物体，如外卖杯和医用胶带，这些物体更加复杂。

    Given a natural language, a general robot has to comprehend the instruction and find the target object or location based on visual observations even in unexplored environments. Most agents rely on massive diverse training data to achieve better generalization, which requires expensive labor. These agents often focus on common objects and fewer tasks, thus are not intelligent enough to handle different types of instructions. To facilitate research in open-set vision-and-language navigation, we propose a benchmark named MO-VLN, aiming at testing the effectiveness and generalization of the agent in the multi-task setting. First, we develop a 3D simulator rendered by realistic scenarios using Unreal Engine 5, containing more realistic lights and details. The simulator contains three scenes, i.e., cafe, restaurant, and nursing house, of high value in the industry. Besides, our simulator involves multiple uncommon objects, such as takeaway cup and medical adhesive tape, which are more compli
    
[^105]: 能否通过 ChatGPT 实现智能交通系统？使用强化学习实现混合交通流控制的案例研究

    Can ChatGPT Enable ITS? The Case of Mixed Traffic Control via Reinforcement Learning. (arXiv:2306.08094v1 [cs.AI])

    [http://arxiv.org/abs/2306.08094](http://arxiv.org/abs/2306.08094)

    本文研究探讨使用 ChatGPT 解决混合交通流控制问题，通过大规模用户研究发现 ChatGPT 在某些环境下能够提高成功策略数量

    

    强化学习在智能交通系统中的应用不断增多，同时也凸显了一些关键问题。本文研究使用大型语言模型 ChatGPT 研究是否可以帮助解决复杂的混合交通流控制问题，通过一个大规模的用户研究，发现 ChatGPT 在某些环境下能够增加成功策略数量

    The surge in Reinforcement Learning (RL) applications in Intelligent Transportation Systems (ITS) has contributed to its growth as well as highlighted key challenges. However, defining objectives of RL agents in traffic control and management tasks, as well as aligning policies with these goals through an effective formulation of Markov Decision Process (MDP), can be challenging and often require domain experts in both RL and ITS. Recent advancements in Large Language Models (LLMs) such as GPT-4 highlight their broad general knowledge, reasoning capabilities, and commonsense priors across various domains. In this work, we conduct a large-scale user study involving 70 participants to investigate whether novices can leverage ChatGPT to solve complex mixed traffic control problems. Three environments are tested, including ring road, bottleneck, and intersection. We find ChatGPT has mixed results. For intersection and bottleneck, ChatGPT increases number of successful policies by 150% and 
    
[^106]: 预训练Transformer用于对抗性样本提纯

    Pre-trained transformer for adversarial purification. (arXiv:2306.01762v1 [cs.CR])

    [http://arxiv.org/abs/2306.01762](http://arxiv.org/abs/2306.01762)

    本文提出了一个快速防御对抗性攻击的方案RaPiD（Rapid Plug-in Defender），通过预训练的Transformer微调来提纯对抗样本，使其逼近清洁数据分布，实验结果表明，在有限数据情况下，该方法优于最先进的方法。

    

    随着越来越多的深度神经网络被部署为各种日常服务，它们的可靠性至关重要。深度神经网络容易受到对抗性攻击的影响，其中逃避攻击是最普遍的一种。最近的研究通常通过对抗训练或利用大量清洁数据的知识来增强其健壮性。然而，在实际应用中，重新训练和部署模型需要大量的计算资源，对在线服务造成重大损失。此外，当检测到某种攻击的对抗性例子时，服务提供者只能获得有限的对抗性样本，而大量的清洁数据可能无法获取。针对这些问题，我们提出了一种新的方案，名为RaPiD（Rapid Plug-in Defender），旨在快速防御具有少量干净和对抗性示例限制的原始服务模型的某种攻击。受到预训练模型提供转移学习良好初始化的通用趋势的启发，我们建议通过微调预先训练的Transformer来提纯对抗性样本。预训练的Transformer作为正则化器，鼓励提纯后的对抗性样本接近清晰数据的分布。实验结果表明，RaPiD在防御各种具有限数据的攻击方面优于最先进的方法。

    With more and more deep neural networks being deployed as various daily services, their reliability is essential. It's frightening that deep neural networks are vulnerable and sensitive to adversarial attacks, the most common one of which for the services is evasion-based. Recent works usually strengthen the robustness by adversarial training or leveraging the knowledge of an amount of clean data. However, in practical terms, retraining and redeploying the model need a large computational budget, leading to heavy losses to the online service. In addition, when adversarial examples of a certain attack are detected, only limited adversarial examples are available for the service provider, while much clean data may not be accessible. Given the mentioned problems, we propose a new scenario, RaPiD (Rapid Plug-in Defender), which is to rapidly defend against a certain attack for the frozen original service model with limitations of few clean and adversarial examples. Motivated by the general
    
[^107]: Med-UniC：通过减少偏见实现跨语言医学图像-语言预训练的统一

    Med-UniC: Unifying Cross-Lingual Medical Vision-Language Pre-Training by Diminishing Bias. (arXiv:2305.19894v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.19894](http://arxiv.org/abs/2305.19894)

    Med-UniC是一个新的框架，旨在通过整合英语和西班牙语的跨语言医学数据，实现跨语言医学图像-语言预训练的统一。他们提出了跨语言文本对齐规则(CTR)，以明确统一来自不同语言社区的医学报告的跨语言语义表示。

    

    数据稀缺性对医学图像-语言预训练(VLP)的效果造成了严重障碍。解决方案可能在于结合来自各种语言社区的数据集。然而，主要挑战来自于整合不同的语法和语义、特定于语言的医学术语以及特定于文化的隐式知识的复杂性。因此，一个关键的考虑因素是由不同语言引起的社区偏见的存在。本文介绍了一种名为统一跨语言医学图像-语言预训练(Med-UniC)的新框架，旨在整合来自两种最常见语言的多模态医学数据，即英语和西班牙语。具体而言，我们提出了跨语言文本对齐规则(CTR)，明确统一来自不同语言社区的医学报告的跨语言语义表示。通过潜在语言解缠，优化CTR，使我们的优化成果。

    The scarcity of data presents a critical obstacle to the efficacy of medical visionlanguage pre-training (VLP). A potential solution lies in the combination of datasets from various language communities. Nevertheless, the main challenge stems from the complexity of integrating diverse syntax and semantics, language-specific medical terminology, and culture-specific implicit knowledge. Therefore, one crucial aspect to consider is the presence of community bias caused by different languages. This paper presents a novel framework named Unifying Cross-Lingual Medical Vision-Language Pre-Training (Med-UniC), designed to integrate multimodal medical data from the two most prevalent languages, English and Spanish. Specifically, we propose Cross-lingual Text Alignment Regularization (CTR) to explicitly unify cross-lingual semantic representations of medical reports originating from diverse language communities. CTR is optimized through latent language disentanglement, rendering our optimizatio
    
[^108]: 利用语义先验细化的弱监督视觉-文本对齐

    Weakly-Supervised Visual-Textual Grounding with Semantic Prior Refinement. (arXiv:2305.10913v1 [cs.CV])

    [http://arxiv.org/abs/2305.10913](http://arxiv.org/abs/2305.10913)

    本文提出了一种利用语义先验细化的弱监督视觉-文本对齐方法，仅使用图像-句子对进行学习，其目标是实现实体表示中的区域-短语对应关系，通过联合两个主要模块的输出进行预测。

    

    弱监督视觉-文本对齐的目标是仅利用图像-句子对学习实体表示中的区域-短语对应关系。与监督方法相比，其难度更大，因为无法获得边界框和文本短语的对应关系。因此，我们提出了语义先验细化模型（SPRM），其预测结果是通过组合两个主要模块的输出得到的。第一个未经训练的模块旨在返回文本短语和边界框之间的粗略对齐。第二个训练过的模块由两个子组件组成，用于细化粗略的对齐以提高最终短语-边界框对齐的准确性。该模型的训练目标是最大化图像和句子之间的多模态相似度，同时使同一句子和一个新的不相关的图像的多模态相似度最小化，以在训练过程中最大限度地提高训练效果。我们的方法在两个流行的数据集上展现了最先进的结果。

    Using only image-sentence pairs, weakly-supervised visual-textual grounding aims to learn region-phrase correspondences of the respective entity mentions. Compared to the supervised approach, learning is more difficult since bounding boxes and textual phrases correspondences are unavailable. In light of this, we propose the Semantic Prior Refinement Model (SPRM), whose predictions are obtained by combining the output of two main modules. The first untrained module aims to return a rough alignment between textual phrases and bounding boxes. The second trained module is composed of two sub-components that refine the rough alignment to improve the accuracy of the final phrase-bounding box alignments. The model is trained to maximize the multimodal similarity between an image and a sentence, while minimizing the multimodal similarity of the same sentence and a new unrelated image, carefully selected to help the most during training. Our approach shows state-of-the-art results on two popula
    
[^109]: 将知识蒸馏用于短期到长期轨迹预测

    Distilling Knowledge for Short-to-Long Term Trajectory Prediction. (arXiv:2305.08553v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.08553](http://arxiv.org/abs/2305.08553)

    本文提出了一种新的方法Di-Long，用于解决长期轨迹预测中越来越不确定和不可预测的问题。该方法利用蒸馏短期轨迹模型预测器来指导训练过程中的长期轨迹预测学生网络。学生网络观察短序列并预测长轨迹，教师网络观察更长序列并预测剩余短目标轨迹。

    

    长期轨迹预测是计算机视觉、机器学习和机器人领域中一个重要且具有挑战性的问题。其中一个基本困难在于随着时间范围的增长，轨迹的演变变得越来越不确定和不可预测，从而增加了问题的复杂性。为了克服这个问题，在本文中，我们提出了Di-Long，一种新的方法，它利用蒸馏短期轨迹模型预测器来指导训练过程中的长期轨迹预测学生网络。给定一个包含学生网络允许的观测序列和补充目标序列的总序列长度，我们让学生和教师对同一个完整轨迹定义两个不同但相关的任务：学生观察一个短序列并预测一个长轨迹，而教师观察一个更长的序列并预测剩下的短目标轨迹。

    Long-term trajectory forecasting is an important and challenging problem in the fields of computer vision, machine learning, and robotics. One fundamental difficulty stands in the evolution of the trajectory that becomes more and more uncertain and unpredictable as the time horizon grows, subsequently increasing the complexity of the problem. To overcome this issue, in this paper, we propose Di-Long, a new method that employs the distillation of a short-term trajectory model forecaster that guides a student network for long-term trajectory prediction during the training process. Given a total sequence length that comprehends the allowed observation for the student network and the complementary target sequence, we let the student and the teacher solve two different related tasks defined over the same full trajectory: the student observes a short sequence and predicts a long trajectory, whereas the teacher observes a longer sequence and predicts the remaining short target trajectory. The
    
[^110]: 如何为推荐基础模型索引项目ID

    How to Index Item IDs for Recommendation Foundation Models. (arXiv:2305.06569v1 [cs.IR])

    [http://arxiv.org/abs/2305.06569](http://arxiv.org/abs/2305.06569)

    本研究对推荐基础模型的项目索引问题进行了系统检查，提出了一种新的上下文感知索引方法，该方法在项目推荐准确性和文本生成质量方面具有优势。

    

    推荐基础模型将推荐任务转换为自然语言任务，利用大型语言模型（LLM）进行推荐。它通过直接生成建议的项目而不是计算传统推荐模型中每个候选项目的排名得分，简化了推荐管道，避免了多段过滤的问题。为了避免在决定要推荐哪些项目时生成过长的文本，为推荐基础模型创建LLM兼容的项目ID是必要的。本研究系统地研究了推荐基础模型的项目索引问题，以P5为代表的主干模型，并使用各种索引方法复制其结果。我们首先讨论了几种微不足道的项目索引方法（如独立索引、标题索引和随机索引）的问题，并表明它们不适用于推荐基础模型，然后提出了一种新的索引方法，称为上下文感知索引。我们表明，这种索引方法在项目推荐准确性和文本生成质量方面优于其他索引方法。

    Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text when deciding which item(s) to recommend, creating LLM-compatible item IDs is essential for recommendation foundation models. In this study, we systematically examine the item indexing problem for recommendation foundation models, using P5 as the representative backbone model and replicating its results with various indexing methods. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as independent indexing, title indexing, and random inde
    
[^111]: 具有别名观测的潜在图的快速探索与学习

    Fast exploration and learning of latent graphs with aliased observations. (arXiv:2303.07397v1 [cs.LG])

    [http://arxiv.org/abs/2303.07397](http://arxiv.org/abs/2303.07397)

    本文介绍了一种在具有别名观测的潜在图上，能够显著提高最大化探索效率的政策算法 eFeX，相比于随机策略，该算法能够更快地恢复各种拓扑结构下的图表。

    

    考虑这种场景：一个智能体通过执行操作从一个节点到另一个节点来导航潜在图。所选操作确定了下一个访问节点上的概率分布。在每个节点处，智能体收到一个观测，但该观测不是唯一的，因此它不能唯一地标识节点，这使得问题别名化。本文旨在提供一个政策，该政策约等于最大化探索效率（即在给定的探索预算下如何恢复图表）。在非别名化的情况下，我们展示了相对于现有最先进强化学习基线的改进性能。对于别名化的情况，我们不知道适用的基线，而是展示了在各种拓扑结构下相对于随机策略更快的恢复速度，并且对于具有挑战性的拓扑结构，恢复速度比随机策略快指数倍。我们将该算法称为 eFeX（来自于 efficient exploration 的缩写）。

    Consider this scenario: an agent navigates a latent graph by performing actions that take it from one node to another. The chosen action determines the probability distribution over the next visited node. At each node, the agent receives an observation, but this observation is not unique, so it does not identify the node, making the problem aliased. The purpose of this work is to provide a policy that approximately maximizes exploration efficiency (i.e., how well the graph is recovered for a given exploration budget). In the unaliased case, we show improved performance w.r.t. state-of-the-art reinforcement learning baselines. For the aliased case we are not aware of suitable baselines and instead show faster recovery w.r.t. a random policy for a wide variety of topologies, and exponentially faster recovery than a random policy for challenging topologies. We dub the algorithm eFeX (from eFficient eXploration).
    
[^112]: 基于深度学习的时间序列因果推断量化北极放大的原因

    Quantifying Causes of Arctic Amplification via Deep Learning based Time-series Causal Inference. (arXiv:2303.07122v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.07122](http://arxiv.org/abs/2303.07122)

    该研究提出了一种基于循环神经网络的时间序列因果推断模型TCINet，用于推断大气过程对海冰融化的因果效应。通过实验证明，该模型能够显著提高量化北极海冰融化的主要原因的能力。

    

    北极变暖，也称北极放大，由多种大气和海洋因素导致，但其基础热力因素的详细情况仍不清楚。使用固定治疗效应策略推断大气过程对海冰融化的因果效应会导致不现实的反事实估计。这样的模型也容易受到时间变化的混淆的影响而引起偏差。为了解决这些挑战，我们提出了TCINet - 一种基于循环神经网络的时间序列因果推断模型，以连续治疗方式推断因果关系。通过对合成和观测数据的实验，我们展示了我们的研究如何大大提高量化北极海冰融化的主要原因的能力。

    The warming of the Arctic, also known as Arctic amplification, is led by several atmospheric and oceanic drivers, however, the details of its underlying thermodynamic causes are still unknown. Inferring the causal effects of atmospheric processes on sea ice melt using fixed treatment effect strategies leads to unrealistic counterfactual estimations. Such models are also prone to bias due to time-varying confoundedness. In order to tackle these challenges, we propose TCINet - time-series causal inference model to infer causation under continuous treatment using recurrent neural networks. Through experiments on synthetic and observational data, we show how our research can substantially improve the ability to quantify the leading causes of Arctic sea ice melt.
    
[^113]: 以ELBOs的加权积分理解扩散目标

    Understanding the Diffusion Objective as a Weighted Integral of ELBOs. (arXiv:2303.00848v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00848](http://arxiv.org/abs/2303.00848)

    本文深入理解了扩散目标，并揭示了加权损失和ELBO目标之间的直接关系。

    

    文献中的扩散模型采用不同的目标进行优化，并且这些目标都是加权损失的特例，其中加权函数指定每个噪声级别的权重。均匀加权对应于最大似然的原则性近似ELBO的最大化。但是实际上，由于更好的样本质量，目前的扩散模型使用非均匀加权。本文揭示了加权损失（带有任何加权）和ELBO目标之间的直接关系。我们展示了加权损失可以被写成一种ELBOs的加权积分形式，其中每个噪声级别都有一个ELBO。如果权重函数是单调的，那么加权损失是一种基于似然的目标：它在简单的数据增强下（即高斯噪声扰动）下最大化ELBO。我们的主要贡献是更深入地理解了扩散目标，但我们还进行了一些比较单调和非单调权重的实验。

    Diffusion models in the literature are optimized with various objectives that are special cases of a weighted loss, where the weighting function specifies the weight per noise level. Uniform weighting corresponds to maximizing the ELBO, a principled approximation of maximum likelihood. In current practice diffusion models are optimized with non-uniform weighting due to better results in terms of sample quality. In this work we expose a direct relationship between the weighted loss (with any weighting) and the ELBO objective.  We show that the weighted loss can be written as a weighted integral of ELBOs, with one ELBO per noise level. If the weighting function is monotonic, then the weighted loss is a likelihood-based objective: it maximizes the ELBO under simple data augmentation, namely Gaussian noise perturbation. Our main contribution is a deeper theoretical understanding of the diffusion objective, but we also performed some experiments comparing monotonic with non-monotonic weight
    
[^114]: 转换的低秩参数化可以帮助张量神经网络实现稳健的泛化

    Transformed Low-Rank Parameterization Can Help Robust Generalization for Tensor Neural Networks. (arXiv:2303.00196v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00196](http://arxiv.org/abs/2303.00196)

    这项研究首次通过推导泛化误差上界回答了转换的低秩参数化如何影响张量神经网络的学习行为，结果显示通过精确的转换低秩参数化压缩的t-NNs可以实现更尖锐的对抗泛化上界。

    

    在数据科学中，实现高效且稳健的多通道数据学习是一项具有挑战性的任务。通过利用转换域中的低秩性，即转换的低秩性，张量奇异值分解（t-SVD）在多通道数据表示方面取得了广泛的成功，并最近扩展到了函数表示，如具有t-乘积层（t-NNs）的神经网络。然而，t-SVD理论上如何影响t-NNs的学习行为仍不清楚。本文第一次通过推导标准和对抗训练的t-NNs的泛化误差上界来回答这个问题。研究结果显示，通过精确的转换低秩参数化压缩的t-NNs可以实现更尖锐的对抗泛化上界。在实践中，尽管t-NNs很少具有完全转换的低秩权重，我们的分析进一步表明，通过使用梯度流（GF）进行对抗性训练，过参数化的t-NNs具有ReLU

    Achieving efficient and robust multi-channel data learning is a challenging task in data science. By exploiting low-rankness in the transformed domain, i.e., transformed low-rankness, tensor Singular Value Decomposition (t-SVD) has achieved extensive success in multi-channel data representation and has recently been extended to function representation such as Neural Networks with t-product layers (t-NNs). However, it still remains unclear how t-SVD theoretically affects the learning behavior of t-NNs. This paper is the first to answer this question by deriving the upper bounds of the generalization error of both standard and adversarially trained t-NNs. It reveals that the t-NNs compressed by exact transformed low-rank parameterization can achieve a sharper adversarial generalization bound. In practice, although t-NNs rarely have exactly transformed low-rank weights, our analysis further shows that by adversarial training with gradient flow (GF), the over-parameterized t-NNs with ReLU 
    
[^115]: 置换等变神经功能网络

    Permutation Equivariant Neural Functionals. (arXiv:2302.14040v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.14040](http://arxiv.org/abs/2302.14040)

    本文介绍了置换等变神经功能网络的设计，通过对权重进行置换对称性编码，实现对其他网络权重或梯度进行处理，为学习优化、处理隐式神经表示等应用提供了架构原则。

    

    本文研究了能够处理其他神经网络的权重或梯度的神经网络的设计，我们将其称为神经功能网络（NFN）。尽管具有广泛的潜在应用，包括学习优化、处理隐式神经表示、网络编辑和策略评估，但设计处理其他网络权重的有效架构的统一原则很少。我们通过对称性的视角来设计神经功能，特别是通过关注深度前馈网络权重中出现的置换对称性，因为隐藏层神经元没有固有顺序。我们介绍了一种构建置换等变神经功能的框架，该框架将这些对称性编码为归纳偏差。该框架的关键组成部分是我们通过适当的参数来约束为置换等变的NF-Layers（神经功能层）。

    This work studies the design of neural networks that can process the weights or gradients of other neural networks, which we refer to as neural functional networks (NFNs). Despite a wide range of potential applications, including learned optimization, processing implicit neural representations, network editing, and policy evaluation, there are few unifying principles for designing effective architectures that process the weights of other networks. We approach the design of neural functionals through the lens of symmetry, in particular by focusing on the permutation symmetries that arise in the weights of deep feedforward networks because hidden layer neurons have no inherent order. We introduce a framework for building permutation equivariant neural functionals, whose architectures encode these symmetries as an inductive bias. The key building blocks of this framework are NF-Layers (neural functional layers) that we constrain to be permutation equivariant through an appropriate paramet
    
[^116]: 通过Q-learning解决连续控制问题

    Solving Continuous Control via Q-learning. (arXiv:2210.12566v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.12566](http://arxiv.org/abs/2210.12566)

    本研究通过对Q-learning进行简单修改，通过将bang-bang动作离散化与值分解相结合，将单智能体控制视为合作多智能体强化学习来解决连续控制问题，并取得了与最先进的连续actor-critic方法相匹配的性能。

    

    尽管在解决连续控制问题上，使用actor-critic方法取得了巨大的成功，但是简单的critic-only方法如Q-learning在涉及高维动作空间时应用有限。然而，大多数actor-critic方法的成本是增加了复杂性：稳定性启发式、计算要求和更广泛的超参数搜索空间。我们展示了一种对深度Q-learning进行简单修改的方法，大大减轻了这些问题。通过将bang-bang动作离散化与值分解相结合，将单智能体控制视为合作多智能体强化学习（MARL），这种简单的critic-only方法在从特征或像素学习时与最先进的连续actor-critic方法的性能相匹配。我们将合作MARL的经典赌徒问题扩展到了提供直观感觉的，展示了解耦的critics如何利用状态信息协调联合优化，并表现出了出乎意料的强大性能。

    While there has been substantial success for solving continuous control with actor-critic methods, simpler critic-only methods such as Q-learning find limited application in the associated high-dimensional action spaces. However, most actor-critic methods come at the cost of added complexity: heuristics for stabilisation, compute requirements and wider hyperparameter search spaces. We show that a simple modification of deep Q-learning largely alleviates these issues. By combining bang-bang action discretization with value decomposition, framing single-agent control as cooperative multi-agent reinforcement learning (MARL), this simple critic-only approach matches performance of state-of-the-art continuous actor-critic methods when learning from features or pixels. We extend classical bandit examples from cooperative MARL to provide intuition for how decoupled critics leverage state information to coordinate joint optimization, and demonstrate surprisingly strong performance across a var
    
[^117]: 基于平衡数系统的联邦边缘学习无线计算设计方案

    Over-the-Air Computation Based on Balanced Number Systems for Federated Edge Learning. (arXiv:2210.07012v2 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2210.07012](http://arxiv.org/abs/2210.07012)

    本研究提出了一种基于平衡数系统的数字计算方案，用于联邦边缘学习中的梯度聚合。通过数字的平均值计算实数参数的平均值，避免了对精确样本级时间同步、信道估计开销和信道反转的需求，同时提高了聚合性能。

    

    本研究提出了一种数字无线计算（OAC）方案，用于联邦边缘学习（FEEL）的连续值（模拟）聚合。我们展示了利用基于平衡数系统的数字可以近似计算一组实数参数的平均值。通过利用该关键属性，该方案将本地随机梯度编码为一组数字。接下来，它利用数字的值确定激活的正交频分复用（OFDM）子载波的位置。该方案在边缘服务器（ES）使用非相干接收器，不需要精确的样本级时间同步、信道估计开销和信道反转，并且不利用边缘设备（EDs）上的预均衡。我们理论分析了该方案的MSE性能和收敛速度。

    In this study, we propose a digital over-the-air computation (OAC) scheme for achieving continuous-valued (analog) aggregation for federated edge learning (FEEL). We show that the average of a set of real-valued parameters can be calculated approximately by using the average of the corresponding numerals, where the numerals are obtained based on a balanced number system. By exploiting this key property, the proposed scheme encodes the local stochastic gradients into a set of numerals. Next, it determines the positions of the activated orthogonal frequency division multiplexing (OFDM) subcarriers by using the values of the numerals. To eliminate the need for precise sample-level time synchronization, channel estimation overhead, and channel inversion, the proposed scheme also uses a non-coherent receiver at the edge server (ES) and does not utilize a pre-equalization at the edge devices (EDs). We theoretically analyze the MSE performance of the proposed scheme and the convergence rate f
    
[^118]: 使用单步 Q-learning 缓解 Actor-Critic 方法中的离策略偏差：一种新的纠正方法。

    Mitigating Off-Policy Bias in Actor-Critic Methods with One-Step Q-learning: A Novel Correction Approach. (arXiv:2208.00755v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.00755](http://arxiv.org/abs/2208.00755)

    本文提出一种新的策略相似度量来缓解离策略学习中的偏差问题，提供了一种自适应的、可扩展的解决方案。

    

    相较于基于策略的对比方法，离策略无模型深度强化学习可以通过重复使用以前收集的数据来提高数据使用效率。然而，当代理的策略和收集到的数据的基本分布之间的偏差增加时，离策略学习变得具有挑战性。尽管已经研究了重要性采样和离策略策略梯度技术来补偿这种偏差，但它们通常需要一系列长轨迹，并导致额外的问题，如消失/爆炸梯度或抛弃许多有用的经验，最终增加了计算复杂性。此外，它们对连续动作域或由确定性深度神经网络逼近的策略的泛化受到严格限制。为了克服这些限制，我们引入了一种新的策略相似度量来缓解连续控制中这种偏差的影响。我们的方法提供了一种自适应的、可扩展的解决方案，用于减轻 Actor-Critic 方法中离政策偏差的影响。

    Compared to on-policy counterparts, off-policy model-free deep reinforcement learning can improve data efficiency by repeatedly using the previously gathered data. However, off-policy learning becomes challenging when the discrepancy between the underlying distributions of the agent's policy and collected data increases. Although the well-studied importance sampling and off-policy policy gradient techniques were proposed to compensate for this discrepancy, they usually require a collection of long trajectories and induce additional problems such as vanishing/exploding gradients or discarding many useful experiences, which eventually increases the computational complexity. Moreover, their generalization to either continuous action domains or policies approximated by deterministic deep neural networks is strictly limited. To overcome these limitations, we introduce a novel policy similarity measure to mitigate the effects of such discrepancy in continuous control. Our method offers an ad
    
[^119]: OpenPodcar:一种用于自动驾驶汽车研究的开源车辆

    OpenPodcar: an Open Source Vehicle for Self-Driving Car Research. (arXiv:2205.04454v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2205.04454](http://arxiv.org/abs/2205.04454)

    OpenPodcar是一种开源自动驾驶车辆研究平台，基于带硬罩代步车辆进行改装，提供了低成本的硬件和软件构建说明。它具有标准的ROS接口和仿真功能，以及机器人自主规划和控制功能，可以用于最后一英里出租车服务或运输等应用。

    

    OpenPodcar是一种低成本、开源硬件和软件的自主车辆研究平台，它基于一个现成的、带有硬罩的代步车辆进行改装。提供了硬件和软件构建说明，可以将代步车辆转换为低成本且完全自主的平台。开放式平台包括（a）硬件组件：CAD设计、物料清单和构建说明；（b）Arduino、ROS和Gazebo控制和仿真软件文件，提供标准的ROS接口和车辆仿真功能；（c）更高级的ROS软件实现和标准机器人自主规划和控制配置，包括使用Timed-Elastic-Band planner的move_base接口，通过绕过障碍物来驱动车辆从当前位置到目标位置。该车辆足够大，可以以最高时速15公里运送乘客或类似负载，例如用作最后一英里自主出租车服务或用于运输。

    OpenPodcar is a low-cost, open source hardware and software, autonomous vehicle research platform based on an off-the-shelf, hard-canopy, mobility scooter donor vehicle. Hardware and software build instructions are provided to convert the donor vehicle into a low-cost and fully autonomous platform. The open platform consists of (a) hardware components: CAD designs, bill of materials, and build instructions; (b) Arduino, ROS and Gazebo control and simulation software files which provide standard ROS interfaces and simulation of the vehicle; and (c) higher-level ROS software implementations and configurations of standard robot autonomous planning and control, including the move_base interface with Timed-Elastic-Band planner which enacts commands to drive the vehicle from a current to a desired pose around obstacles. The vehicle is large enough to transport a human passenger or similar load at speeds up to 15km/h, for example for use as a last-mile autonomous taxi service or to transport 
    
[^120]: 可解释且交互式的深度多实例学习用于牙齿龋齿在多位X光片中的分类

    Interpretable and Interactive Deep Multiple Instance Learning for Dental Caries Classification in Bitewing X-rays. (arXiv:2112.09694v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2112.09694](http://arxiv.org/abs/2112.09694)

    本研究提出了一种可解释且交互式的深度多实例学习方法，用于在牙齿放射图中的龋齿分类。该方法首先输出局部补丁分类概率的热图，并可根据分割标签进行训练，与现有方法相比表现出了竞争性的性能，并且用户可以解释预测并与模型交互。

    

    我们提出了一种基于深度多实例学习的简单高效的图像分类架构，并将其应用于在牙科放射图中具有挑战性的龋齿检测任务。从技术上讲，我们的方法有两个贡献：首先，即使使用弱的图像级标签进行训练，它也能输出局部补丁分类概率的热图。其次，它适用于从分割标签中学习以指导训练。与现有方法相比，人类用户可以忠实地解释预测，并与模型交互以决定要关注的区域。在一个包含约38k个多位X光片（约316k个牙齿）的大型临床数据集上进行了实验，在与各种基线方法相比表现出了竞争性的性能。当由外部龋齿分割模型指导时，观察到分类和定位性能的显著改善。

    We propose a simple and efficient image classification architecture based on deep multiple instance learning, and apply it to the challenging task of caries detection in dental radiographs. Technically, our approach contributes in two ways: First, it outputs a heatmap of local patch classification probabilities despite being trained with weak image-level labels. Second, it is amenable to learning from segmentation labels to guide training. In contrast to existing methods, the human user can faithfully interpret predictions and interact with the model to decide which regions to attend to. Experiments are conducted on a large clinical dataset of $\sim$38k bitewings ($\sim$316k teeth), where we achieve competitive performance compared to various baselines. When guided by an external caries segmentation model, a significant improvement in classification and localization performance is observed.
    
[^121]: 路径正则化：一种对并行ReLU网络进行凸性和稀疏性引导的正则化方法

    Path Regularization: A Convexity and Sparsity Inducing Regularization for Parallel ReLU Networks. (arXiv:2110.09548v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.09548](http://arxiv.org/abs/2110.09548)

    路径正则化为并行ReLU网络提供了一种简化的凸优化问题，通过群稀疏性引导实现了凸模型，并提出了一个近似算法，在所有数据维度上具备完全多项式时间复杂度。

    

    理解深度神经网络成功背后的基本原理是当前文献中最重要的开放问题之一。为此，我们研究了深度神经网络的训练问题，并引入了一种分析方法来揭示优化景观中隐藏的凸性。我们考虑了深度并行ReLU网络架构，其也包括标准的深度网络和ResNet作为其特例。然后我们表明，基于路径正则化的训练问题可以表示为一个精确的凸优化问题。我们进一步证明等价的凸问题是通过一种群稀疏性引导的规范进行正则化的。因此，路径正则化的并行ReLU网络可以被视为高维中一种简化的凸模型。更重要的是，由于原始的训练问题可能无法在多项式时间内训练，我们提出了一个在所有数据维度上具有完全多项式时间复杂度的近似算法。然后，我们证明了强全局收敛性。

    Understanding the fundamental principles behind the success of deep neural networks is one of the most important open questions in the current literature. To this end, we study the training problem of deep neural networks and introduce an analytic approach to unveil hidden convexity in the optimization landscape. We consider a deep parallel ReLU network architecture, which also includes standard deep networks and ResNets as its special cases. We then show that pathwise regularized training problems can be represented as an exact convex optimization problem. We further prove that the equivalent convex problem is regularized via a group sparsity inducing norm. Thus, a path regularized parallel ReLU network can be viewed as a parsimonious convex model in high dimensions. More importantly, since the original training problem may not be trainable in polynomial-time, we propose an approximate algorithm with a fully polynomial-time complexity in all data dimensions. Then, we prove strong glob
    
[^122]: 深度生存剂量反应函数的连续治疗推荐

    Continuous Treatment Recommendation with Deep Survival Dose Response Function. (arXiv:2108.10453v5 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2108.10453](http://arxiv.org/abs/2108.10453)

    本论文提出了一个通用公式，称为深度生存剂量反应函数（DeepSDRF），用于解决临床生存数据中的连续治疗推荐问题。通过校正选择偏差，DeepSDRF估计的治疗效果可以用于开发推荐算法。在模拟研究和实际医学数据库上的测试中，DeepSDRF表现出良好的性能。

    

    我们提出了一个在临床生存数据设置中的连续治疗推荐问题的通用公式，称为深度生存剂量反应函数（DeepSDRF）。也就是说，我们考虑从历史数据中仅仅通过观察到的因素（混杂因子）对观察到的治疗和事件发生时间结果都有影响的条件平均剂量反应（CADR）函数的学习问题。从DeepSDRF中估计的治疗效果使我们能够开发具有选择偏差校正的推荐算法。我们比较了基于随机搜索和强化学习的两种推荐方法，并发现在患者结果方面表现相似。我们在大量的模拟研究和eICU研究机构（eRI）数据库上测试了DeepSDRF和相应的推荐器。据我们所知，这是首次在医学背景下使用因果模型来解决观察数据中的连续治疗效应问题。

    We propose a general formulation for continuous treatment recommendation problems in settings with clinical survival data, which we call the Deep Survival Dose Response Function (DeepSDRF). That is, we consider the problem of learning the conditional average dose response (CADR) function solely from historical data in which observed factors (confounders) affect both observed treatment and time-to-event outcomes. The estimated treatment effect from DeepSDRF enables us to develop recommender algorithms with the correction for selection bias. We compared two recommender approaches based on random search and reinforcement learning and found similar performance in terms of patient outcome. We tested the DeepSDRF and the corresponding recommender on extensive simulation studies and the eICU Research Institute (eRI) database. To the best of our knowledge, this is the first time that causal models are used to address the continuous treatment effect with observational data in a medical context.
    
[^123]: 基于深度强化学习和历史驾驶经验的人类化能量管理

    Human-like Energy Management Based on Deep Reinforcement Learning and Historical Driving Experiences. (arXiv:2007.10126v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2007.10126](http://arxiv.org/abs/2007.10126)

    本文提出了一种基于深度强化学习和历史驾驶经验的人类化能量管理框架，通过采用深度确定性策略梯度算法和驾驶数据训练模型，提高了混合动力电动车能量管理的性能。

    

    混合动力电动车的发展依赖于先进高效的能量管理策略（EMS）。本文提出了一种基于深度强化学习方法和采集的历史驾驶数据的人类化能量管理框架。该研究中的混合动力传动系统采用串联-并联拓扑结构，并首先建立了面向控制的模型。然后引入了独特的深度强化学习算法——深度确定性策略梯度（DDPG）。为了提高深度强化学习框架中的功率分配控制，利用动态规划（DP）获得的全局最优控制轨迹作为专家知识来训练DDPG模型。这个操作确保了所提出的控制架构的最优性。此外，利用基于有经验驾驶员的采集的历史驾驶数据来替代基于DP的控制，从而进一步提升能量管理的性能。

    Development of hybrid electric vehicles depends on an advanced and efficient energy management strategy (EMS). With online and real-time requirements in mind, this article presents a human-like energy management framework for hybrid electric vehicles according to deep reinforcement learning methods and collected historical driving data. The hybrid powertrain studied has a series-parallel topology, and its control-oriented modeling is founded first. Then, the distinctive deep reinforcement learning (DRL) algorithm, named deep deterministic policy gradient (DDPG), is introduced. To enhance the derived power split controls in the DRL framework, the global optimal control trajectories obtained from dynamic programming (DP) are regarded as expert knowledge to train the DDPG model. This operation guarantees the optimality of the proposed control architecture. Moreover, the collected historical driving data based on experienced drivers are employed to replace the DP-based controls, and thus c
    

