# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Optimizing Drug Design by Merging Generative AI With Active Learning Frameworks.](http://arxiv.org/abs/2305.06334) | 该论文提出了一种基于主动学习的生成AI工作流程，可以克服当前生成AI方法的局限性，去设计出具有高预测亲和力的可行化学分子。 |
| [^2] | [Alternating Gradient Descent and Mixture-of-Experts for Integrated Multimodal Perception.](http://arxiv.org/abs/2305.06324) | 本文提出了集成多模态感知（IMP）方法，将多模态输入集成到单个编码器中，采用交替梯度下降法（AGD）和混合专家（MoE）相结合的方法实现高效的模型和任务扩展，取得了在多个基准测试中具有竞争力的性能表现。 |
| [^3] | [Scan2LoD3: Reconstructing semantic 3D building models at LoD3 using ray casting and Bayesian networks.](http://arxiv.org/abs/2305.06314) | 本文提出一种称为Scan2LoD3的新方法，通过改进外墙层次的语义三维分割来精确重建具有语义信息的LoD3建筑模型。 |
| [^4] | [Self-Supervised Instance Segmentation by Grasping.](http://arxiv.org/abs/2305.06305) | 本文提出了一种自监督实例分割方法，使用抓取交互来收集分割监督。利用分割出的抓取对象，采用“剪切和粘贴”生成方法，训练的模型可以达到与完全监督实例分割数据集训练的模型相当或更优的性能。 |
| [^5] | [Why Don't You Do Something About It? Outlining Connections between AI Explanations and User Actions.](http://arxiv.org/abs/2305.06297) | 可解释人工智能（XAI）系统的核心假设是解释可以改变用户的知识并促进他们在复杂的技术环境中采取行动。本文提出了一个框架来映射解释中呈现的信息和用户采取的行动之间的联系，并探讨了现有工作中的信息缺口。 |
| [^6] | [Radious: Unveiling the Enigma of Dental Radiology with BEIT Adaptor and Mask2Former in Semantic Segmentation.](http://arxiv.org/abs/2305.06236) | 文章利用BEIT适配器和Mask2Former开发了一种语义分割算法，最终成功提高了9％和33％的mIoU得分来检测和识别多种不同的牙科疾病和异常。 |
| [^7] | [DaGAN++: Depth-Aware Generative Adversarial Network for Talking Head Video Generation.](http://arxiv.org/abs/2305.06225) | DaGAN++是一种深度感知生成对抗网络，能够从面部视频中自学习密集的3D面部几何，将它们融入到生成器中，从而实现面向语音头视频生成，并在多个基准数据集上取得了最先进的结果。 |
| [^8] | [ComputeGPT: A computational chat model for numerical problems.](http://arxiv.org/abs/2305.06223) | ComputeGPT是一种计算型聊天模型，可以通过运行代码解决数值问题，结合本地浏览器的Python解释器和优化的提示，实现最先进的数值问题效率并为代码提供合适的前端和安全环境。 |
| [^9] | [Multi-Prompt with Depth Partitioned Cross-Modal Learning.](http://arxiv.org/abs/2305.06221) | 本研究提出了划分的多模态提示（PMPO）方法，将软提示从一个扩展到多个，通过连接多个提示到视觉编码器的不同深度上，能够更好地捕捉视觉表示的上下文深度，与传统单提示方法相比，在下游视觉语言任务中具有更好的表现。 |
| [^10] | [Multi-Task End-to-End Training Improves Conversational Recommendation.](http://arxiv.org/abs/2305.06218) | 本文表明，采用多任务端到端Transformer模型可以提高对话式推荐的性能，可竞争于先前采用复杂多组件方法的模型，通过微调我们的模型和额外的多任务学习设置，实现了知识在领域间的转移。 |
| [^11] | [Patchwork Learning: A Paradigm Towards Integrative Analysis across Diverse Biomedical Data Sources.](http://arxiv.org/abs/2305.06217) | 补丁学习是一种新的范式，通过整合来自不同数据源的信息，解决了数据隐私、异构数据来源和无法充分利用多个数据模态的挑战。它可以同时利用互补的数据来源，同时保护数据隐私，从而实现开发更全面和具有普适性的ML模型。 |
| [^12] | [Sequence-Agnostic Multi-Object Navigation.](http://arxiv.org/abs/2305.06178) | 该论文提出了一种无序多物体导航算法，该算法利用深度强化学习框架，通过适当的奖励规范，奖励单个和多个目标对象类别的进展，实现了对多个对象类别的准确定位，适用于动态变化的实际应用。 |
| [^13] | [Fine-tuning Language Models with Generative Adversarial Feedback.](http://arxiv.org/abs/2305.06176) | 本研究探讨了一种新的方法，使用生成对抗反馈的强化学习(RLGAF)对大型语言模型进行微调，以取代仅受人类反馈的强化学习(RLHF)，从而消除评估者的专业限制并提高性能。 |
| [^14] | [Analysis of Climate Campaigns on Social Media using Bayesian Model Averaging.](http://arxiv.org/abs/2305.06174) | 本文分析了工业、倡导组织和气候倡导组织在社交媒体上如何影响气候变化的叙事，并提出了一个最小化监督模型组合方法，用于识别Facebook上气候广告的立场。 |
| [^15] | [QICHWABASE: A Quechua Language and Knowledge Base for Quechua Communities.](http://arxiv.org/abs/2305.06173) | QICHWABASE为少数民族语言和知识构建Wikibase实例，支持凯楚亚社区和谐进程，能增强少数民族在网络上的存在感。 |
| [^16] | [Conversational Semantic Parsing using Dynamic Context Graphs.](http://arxiv.org/abs/2305.06164) | 本论文提出了一种新的方法，使用动态创建的子图表示话语及上下文的信息来进行会话语义解析，并利用图形神经网络编码，可表示大量看不见的节点，比静态方法更为优越。 |
| [^17] | [Algebra Error Classification with Large Language Models.](http://arxiv.org/abs/2305.06163) | 本研究提出了一种基于大语言模型的代数错误分类方法，相较于现有方法，具有更好的泛化能力和处理学生回答的能力。 |
| [^18] | [StarCoder: may the source be with you!.](http://arxiv.org/abs/2305.06161) | 本研究介绍了一个具有15.5B参数和8K上下文长度的大型语言模型——StarCoder，其可以进行快速大批量推理。经评估证明，在Python上表现优异，能够通过人工评估获得40\%的pass@1的得分，且在其他程序中也表现出令人满意的性能。 |
| [^19] | [A Review of Vision-Language Models and their Performance on the Hateful Memes Challenge.](http://arxiv.org/abs/2305.06159) | 本文综述了视觉-语言模型及其在社交媒体内容审核上的应用，研究发现早期融合模型比晚期融合模型更有效，其中表现最佳的早期融合模型是ClipBERT。 |
| [^20] | [EdgeNet : Encoder-decoder generative Network for Auction Design in E-commerce Online Advertising.](http://arxiv.org/abs/2305.06158) | EdgeNet是一种编码器-解码器生成网络，可用于在线电商广告拍卖中的数据驱动竞价设计。与传统模型相比，EdgeNet 可以更好地捕捉广告间的相互影响，并利用丰富的上下文信息，提高广告竞拍的效率。 |
| [^21] | [Implications of Multi-Word Expressions on English to Bharti Braille Machine Translation.](http://arxiv.org/abs/2305.06157) | 本文通过给基线神经机器翻译模型添加语言知识及多词语翻译子模块，在英语到巴提盲文机器翻译中取得了显著的改进。 |
| [^22] | [The Vault: A Comprehensive Multilingual Dataset for Advancing Code Understanding and Generation.](http://arxiv.org/abs/2305.06156) | The Vault是一个提供了10种流行编程语言的40百万行代码-文本对的开源数据集，旨在增强面向代码的大型语言模型（LLM）的训练，有望在代码理解和生成任务上取得显著进展。 |
| [^23] | [Leveraging Synthetic Targets for Machine Translation.](http://arxiv.org/abs/2305.06155) | 本文提供了一种利用预训练模型生成合成目标从而提高机器翻译性能的方法，并发现其在不同测试基准下的表现优于使用真实数据训练，这一方法在有限资源的情况下尤其有用。 |
| [^24] | [Structure-CLIP: Enhance Multi-modal Language Representations with Structure Knowledge.](http://arxiv.org/abs/2305.06152) | Structure-CLIP使用文本中的结构化知识，使用场景图强化多模态语言表示，从而在图像-文本匹配任务中展现了更好的性能。 |
| [^25] | [A proof of convergence of inverse reinforcement learning for multi-objective optimization.](http://arxiv.org/abs/2305.06137) | 本论文证明了多目标优化的逆强化学习方法在理论层面上的收敛性，包括Wasserstein逆强化学习和常规逆强化学习方法。 |
| [^26] | [Few-shot Action Recognition via Intra- and Inter-Video Information Maximization.](http://arxiv.org/abs/2305.06114) | 本论文提出了一种称为VIM的框架，采用自适应空间-时间视频采样器和时空动作增强器，用于小样本动作识别，充分利用视频内部和视频间信息以提高识别精度。 |
| [^27] | [The Compositional Structure of Bayesian Inference.](http://arxiv.org/abs/2305.06112) | 该论文研究了贝叶斯反演在复杂组合结构中的计算方法，并探讨了将其用作统计推断的类型驱动方法。 |
| [^28] | [Few-shot Link Prediction on N-ary Facts.](http://arxiv.org/abs/2305.06104) | 本文提出了一个新任务——少样本N-元事实链接预测，并提出了一个名为FLEN的模型来实现。FLEN由三个模块组成，可以从有限的标记实例中预测N-元事实中的缺失实体。 |
| [^29] | [Towards Better Graph Representation Learning with Parameterized Decomposition & Filtering.](http://arxiv.org/abs/2305.06102) | 本研究提出一个新的通用框架，采用参数化分解和滤波，统一了现有的GNN模型，提高了GNN的灵活性，缓解了现有模型的平滑和放大问题，并开发了简单但有效的模型，在各种图形学习任务中实现了显著的改进和计算效率。 |
| [^30] | [PAI at SemEval-2023 Task 2: A Universal System for Named Entity Recognition with External Entity Information.](http://arxiv.org/abs/2305.06099) | PAI团队提出了一种利用维基百科等外部实体信息的通用命名实体识别系统，在SemEval-2023任务2中表现出色，共赢得了7个奖项。 |
| [^31] | [Building Interoperable Electronic Health Records as Purpose-Driven Knowledge Graphs.](http://arxiv.org/abs/2305.06088) | 提出了一种名为iTelos的集成方法，该方法使用目的驱动的知识图谱来构建可互操作的电子健康记录。其中关键思想是数据级别和模式级别应独立开发，允许最大限度地重用先前的知识，并通过能力查询来规范需要的功能。该方法已在eHealth领域实施并通过真实案例评估，显示了开发时间和成本的显著降低。 |
| [^32] | [A Glimpse in ChatGPT Capabilities and its impact for AI research.](http://arxiv.org/abs/2305.06087) | ChatGPT展示了LLMs的强大能力，但这些模型的训练和运行需要巨大的计算资源和高昂的成本，预计会给AI研究带来重大影响。 |
| [^33] | [Best Arm Identification in Bandits with Limited Precision Sampling.](http://arxiv.org/abs/2305.06082) | 本文研究了在有限精度下采样的多臂赌博机问题，提出了一种修改的跟踪算法来处理最优分配的非唯一性，并证明了其渐进最优性。 |
| [^34] | [Visual Tuning.](http://arxiv.org/abs/2305.06061) | 本文综述了视觉调整的发展与现状，将近期的视觉调整技术分为五类，包括提示调整、适配器调整、参数翻译、紧凑调整和模块调整，并提出了未来研究方向。 |
| [^35] | [Compressing neural network by tensor network with exponentially fewer variational parameters.](http://arxiv.org/abs/2305.06058) | 本文提出了一种通用的压缩方案，将神经网络的可变参数编码为多层张量网络，明显减少了可变参数的数量，并在多个神经网络和数据集上表现出了卓越的压缩性能，以VGG-16的测试精度提高为例。 |
| [^36] | [Search for the UGLE Truth: An Investigation into Unsupervised GNN Learning Environments.](http://arxiv.org/abs/2305.06026) | 本文提出了一种GNN学习环境下的社区检测算法比较框架，包括数据集和评估指标，以解决目前文献中对于基于GNN的社区检测缺乏公平且严谨评估的问题。 |
| [^37] | [Safe motion planning with environment uncertainty.](http://arxiv.org/abs/2305.06004) | 提出了一种在机器人状态和环境不确定性下进行安全运动规划的方法，其中通过贝叶斯滤波估计框架考虑了地标不确定性，通过对图搜索算法进行改进，引入了机器人动态感知的新视角。 |
| [^38] | [ANALOGYKB: Unlocking Analogical Reasoning of Language Models with A Million-scale Knowledge Base.](http://arxiv.org/abs/2305.05994) | 本文提出了ANALOGYKB，一种使用百万规模知识库的类比推理方法，能够使语言模型在类比推理任务上取得比之前的最先进方法更好的结果。 |
| [^39] | [Structural Hawkes Processes for Learning Causal Structure from Discrete-Time Event Sequences.](http://arxiv.org/abs/2305.05986) | 本文提出了一种叫做结构Hawkes过程的方法，通过利用瞬时效应学习离散时间事件序列中事件类型之间的因果结构。 |
| [^40] | [Interpretable Multimodal Misinformation Detection with Logic Reasoning.](http://arxiv.org/abs/2305.05964) | 本文提出了一种新的基于逻辑的多模态虚假信息检测神经模型，通过集成可解释性逻辑子句表达目标任务的推理过程，并使用神经表征参数化符号逻辑元素，从而便于自动生成和评估有意义的逻辑子句。此外，引入了五个元预测器来捕获虚假信息的基本模式。实验结果表明，该模型不仅性能显著优于当前方法，而且提供了透明且可解释的逻辑推理过程。 |
| [^41] | [Multi-Path Transformer is Better: A Case Study on Neural Machine Translation.](http://arxiv.org/abs/2305.05948) | 本文研究了多路径结构对Transformer模型的影响，通过在每个子层中添加归一化、产生更多特征的廉价操作和可学习的加权机制来融合从不同路径提取的特征，实验发现相同参数下浅层多路径模型可以实现与深层模型相似甚至更好的性能。 |
| [^42] | [V2X-Seq: A Large-Scale Sequential Dataset for Vehicle-Infrastructure Cooperative Perception and Forecasting.](http://arxiv.org/abs/2305.05938) | V2X-Seq是第一个大规模的时序V2X数据集，包括时序感知数据集和轨迹预测数据集。基于这个数据集，我们提出了三个新的车路协同自动驾驶任务。 |
| [^43] | [Text-guided High-definition Consistency Texture Model.](http://arxiv.org/abs/2305.05901) | 该论文介绍了一种名为 HCTM 的方法，它可以根据文本提示为 3D 网格生成高清晰度和一致的纹理。该方法结合预训练深度到图像扩散模型和参数高效微调方法，利用多扩散策略生成高分辨率和一致的结果，并提出了一种防止噪声出现的策略。 |
| [^44] | [Mixture of personality improved Spiking actor network for efficient multi-agent cooperation.](http://arxiv.org/abs/2305.05898) | 本文提出了一种基于人格混合的尖峰演员网络，通过行列式点过程和动态尖峰神经元的融合实现了多方协作中的高效强化学习。 |
| [^45] | [Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text Analytics? An Examination on Several Typical Tasks.](http://arxiv.org/abs/2305.05862) | 本研究探讨了ChatGPT和GPT-4在金融文本分析任务中的潜力，结果显示它们在数值推理上表现出色但在需要领域特定知识的任务上表现不佳。 |
| [^46] | [Dual Intent Enhanced Graph Neural Network for Session-based New Item Recommendation.](http://arxiv.org/abs/2305.05848) | 本文提出了一种基于双意图增强的图神经网络，用于解决基于历史会话的推荐系统中无法推荐新产品的问题，并在实验中证明其有效性。 |
| [^47] | [Sketching the Future (STF): Applying Conditional Control Techniques to Text-to-Video Models.](http://arxiv.org/abs/2305.05845) | 本文提出一种将零样本文本到视频生成与ControlNet相结合的新颖方法，利用插值帧视频作为控制技术生成高质量且一致的视频内容，更准确地符合用户对视频中主体运动的意图。 |
| [^48] | [Achieving Diversity in Counterfactual Explanations: a Review and Discussion.](http://arxiv.org/abs/2305.05840) | 本篇论文综述了因果关系解释中多样性的概念及其定义，提出了生成多种因果关系例子以解释一个预测结果的方法，探讨了这种方法的优点和局限性。 |
| [^49] | [Causal Information Splitting: Engineering Proxy Features for Robustness to Distribution Shifts.](http://arxiv.org/abs/2305.05832) | 本文提出了利用因果机制在不同环境下保持不变的直觉来主动准备的代理特征选择和工程技术，用以应对统计预测模型在分布转移情况下的稳定性问题。 |
| [^50] | [Context-dependent communication under environmental constraints.](http://arxiv.org/abs/2305.05821) | 本文研究了在压缩词汇量的情况下，如何利用环境压力促进情境依赖性沟通的出现，并研究了在接收者无法处理歧义的情况下，发送者如何利用环境的制约因素实现沟通。 |
| [^51] | [Towards an Automatic Optimisation Model Generator Assisted with Generative Pre-trained Transformer.](http://arxiv.org/abs/2305.05811) | 本文提出了一个利用生成式预训练变换器辅助自动生成优化模型的框架，并进行了实验验证，结果表明，使用语言模型生成优化模型是可行的。 |
| [^52] | [Even Small Correlation and Diversity Shifts Pose Dataset-Bias Issues.](http://arxiv.org/abs/2305.05807) | 本文研究了数据集中的分布变化对深度学习模型的影响，并提出了一个综合协议来分析多样性变化和相关性变化。使用皮肤癌分析分类问题的实例，发现模型不仅会学习和传播相关性变化，而且可能会使用错误的特征。 |
| [^53] | [Segment Anything Model (SAM) Enhanced Pseudo Labels for Weakly Supervised Semantic Segmentation.](http://arxiv.org/abs/2305.05803) | 本论文提出了一种通过利用Segment Anything Model (SAM)增强Class Activation Maps (CAM)生成高质量伪标签的方法来解决弱监督语义分割中CAM的局部激活和虚假激活的限制问题。 |
| [^54] | [Reducing the Cost of Cycle-Time Tuning for Real-World Policy Optimization.](http://arxiv.org/abs/2305.05760) | 本研究提出了一种新方法，可基于周期时间设置超参数，使得PPO和SAC在广泛的循环时间范围内进行学习，同时实现了接近耗时的在线超参数调整获得的性能。 |
| [^55] | [Ranking & Reweighting Improves Group Distributional Robustness.](http://arxiv.org/abs/2305.05759) | 本文提出了一种利用折扣累积增益（DCG）排序并加权处理训练数据以提高模型对低代表性组的鲁棒性的方法，实验证明其优于先前方法。 |
| [^56] | [When and What to Ask Through World States and Text Instructions: IGLU NLP Challenge Solution.](http://arxiv.org/abs/2305.05754) | 论文解决了在协作建筑任务中如何解决模棱两可的情况，从而提出了何时寻求澄清以及应该询问什么澄清问题这两个关键问题的解答方法。 |
| [^57] | [A Systematic Literature Review on Hardware Reliability Assessment Methods for Deep Neural Networks.](http://arxiv.org/abs/2305.05750) | 本文为深度神经网络硬件可靠性进行了系统文献综述，总结了现有的可靠性评估方法以及数据集和基准的评估，揭示了这一领域的研究空缺。 |
| [^58] | [Graph-Based Reductions for Parametric and Weighted MDPs.](http://arxiv.org/abs/2305.05739) | 研究了参数化马尔科夫决策过程中加权可达性的降低复杂度问题，提出了一个多项式时间算法来计算我们所研究的马尔可夫链排序的等价类，并实现了两个规则来欠估计“永不更糟”的关系。 |
| [^59] | [Vision-Language Models in Remote Sensing: Current Progress and Future Trends.](http://arxiv.org/abs/2305.05726) | 本文介绍了遥感图像中应用视觉语言模型的现状及未来趋势，视觉语言模型可以推理图像中的底层语义，可以识别对象之间的关系及生成自然语言描述。 |
| [^60] | [CodeIE: Large Code Generation Models are Better Few-Shot Information Extractors.](http://arxiv.org/abs/2305.05711) | CodeIE提出了使用代码生成模型（Code-LLMs）代替自然语言生成模型（NL-LLMs）对命名实体识别和关系抽取这类信息提取任务进行少样本学习，取得优于几个强基准高达4.5%的绝对精度改进。 |
| [^61] | [Enhancing Road Safety through Accurate Detection of Hazardous Driving Behaviors with Graph Convolutional Recurrent Networks.](http://arxiv.org/abs/2305.05670) | 本文提出了一种基于图卷积循环网络的可靠DBD系统，利用公共传感器提高了驾驶行为检测模型的准确性和实用性。 |
| [^62] | [Neurosymbolic Artificial Intelligence (NSAI) based Algorithm for predicting the Impact Strength of Additive Manufactured Polylactic Acid (PLA) Specimens.](http://arxiv.org/abs/2305.05668) | 本研究介绍了一种基于神经符号人工智能的算法，能够高精度预测增材制造聚乳酸（PLA）样品的冲击强度。 |
| [^63] | [Representation Learning for Person or Entity-centric Knowledge Graphs: an application in Healthcare.](http://arxiv.org/abs/2305.05640) | 本研究提出了一种在医疗保健领域构建面向实体的知识图谱的端到端表示学习方法 HEER，通过将领域特定的约束和特征纳入到图嵌入算法中，有效地改善了下游预测任务。 |
| [^64] | [Safe Deep RL for Intraoperative Planning of Pedicle Screw Placement.](http://arxiv.org/abs/2305.05354) | 本论文提出了一种基于安全深度强化学习的椎管机器人手术术中规划方法，解决了相对传统的术前规划和术中注册开环控制的局限，能够提高放置准确度和保证手术安全。 |
| [^65] | [Learning to Personalize Recommendation based on Customers' Shopping Intents.](http://arxiv.org/abs/2305.05279) | 本文介绍了亚马逊的新系统，利用深度学习模型将顾客的在线行为映射成为高级别购物意图，以便个性化推荐，提供更相关、可解释和多样化的购物体验。 |
| [^66] | [Distilling Script Knowledge from Large Language Models for Constrained Language Planning.](http://arxiv.org/abs/2305.05252) | 本文首次定义了受限语言规划任务，提出了一种方法来提高大型语言模型在这个任务中的表现，并提取了一个新颖的受限语言规划数据集。实验证明该方法显著提高了其在约束忠实度方面的能力，并对赋予较小的语言模型受限语言规划能力非常有效。 |
| [^67] | [FedZKP: Federated Model Ownership Verification with Zero-knowledge Proof.](http://arxiv.org/abs/2305.04507) | 提出了一种名为FedZKP的联邦模型所有权验证方案，使用零知识证明，可在不公开凭据的情况下抵御各种攻击，并在理论分析和实证研究中证明了其安全性和准确性。 |
| [^68] | [Heterogeneous Directed Hypergraph Neural Network over abstract syntax tree (AST) for Code Classification.](http://arxiv.org/abs/2305.04228) | 本研究提出了使用异构有向超图表示AST，并使用异构有向超图神经网络处理图形进行代码分类，超过了现有方法。 |
| [^69] | [X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages.](http://arxiv.org/abs/2305.04160) | 本论文提出了一种名为X-LLM的方法，将多模态信息转换为外语并输入到大型语言模型中，从而赋予LLM多模态能力，对于LLM加入多模态信息的能力进行了探究和拓展。 |
| [^70] | [Causality-aware Concept Extraction based on Knowledge-guided Prompting.](http://arxiv.org/abs/2305.01876) | 该论文提出了一种基于因果感知的知识引导提示方法，将其作为干预器装备到基于预训练语言模型的句子提取器中，以缓解概念偏差。在代表性的多语言KG数据集上进行广泛实验，获得了最先进的结果。 |
| [^71] | [Diffusion-based Generative AI for Exploring Transition States from 2D Molecular Graphs.](http://arxiv.org/abs/2304.12233) | 本文提出了一种基于扩散的生成式方法(TSDiff)，用于从二维分子图中预测过渡态几何结构。与现有具有 3D 几何结构机器学习模型相比，TSdiff 的准确性和效率都更高。TSDiff 能够找到比参考数据库更优化的反应途径，在反应势垒更低的情况下找到更为优化的反应路径。 |
| [^72] | [Multi-scale Evolutionary Neural Architecture Search for Deep Spiking Neural Networks.](http://arxiv.org/abs/2304.10749) | 本文提出了一种新方法--多尺度进化神经架构搜索，用于自动设计脉冲神经网络，同时考虑微观、中观和宏观尺度的脑拓扑结构。MSE-NAS可以帮助SNN实现多电路模式的自组织集成，并通过全局性的跨模式连接来优化网络性能。 |
| [^73] | [Better Language Models of Code through Self-Improvement.](http://arxiv.org/abs/2304.01228) | 本文提出了一个简单的数据增强框架来改善预训练语言模型为代码生成和代码摘要等任务微调的瓶颈问题，提高了模型性能。 |
| [^74] | [Path Planning for Autonomous Driving: The State of the Art and Perspectives.](http://arxiv.org/abs/2303.09824) | 本文综述了现有的自动驾驶路径规划方法，包括管道规划和端到端规划方法。在挑战和潜在解决方案方面提供了讨论，有助于为智能汽车的发展提供更好的规划方法。 |
| [^75] | [Parameter is Not All You Need: Starting from Non-Parametric Networks for 3D Point Cloud Analysis.](http://arxiv.org/abs/2303.08134) | 本文提出了一种基于非参数化模型的三维点云分析网络Point-NN。它在各种三维任务中表现良好，不需要参数或训练，可以作为基础架构框架构建参数化网络和已经训练好的三维模型的即插即用模块。 |
| [^76] | [Causal Explanations for Stochastic Sequential Multi-Agent Decision-Making.](http://arxiv.org/abs/2302.10809) | CEMA是一个用于多智能体决策因果解释的系统，使用采样反事实世界的方法可以识别和排名决策背后的显著原因。该系统还可以生成基于所选原因的对比解释，并与用户进行交互循环以确保解释的相关性和可读性。 |
| [^77] | [Get Your Act Together: A Comparative View on Transparency in the AI Act and Technology.](http://arxiv.org/abs/2302.10766) | 该论文比较了欧盟提出的《人工智能法案》和可解释AI（XAI）对于透明度和解释性的基本定义，强调了将这些定义对齐的重要性，以确保技术实践符合法规。 |
| [^78] | [Approximately Bayes-Optimal Pseudo Label Selection.](http://arxiv.org/abs/2302.08883) | 本文介绍了BPLS，一种用于PLS的贝叶斯框架，通过解析逼近选择标签实例的标准，以避免由过度自信但错误预测的实例选择而导致的确认偏差问题。 |
| [^79] | [SNeRL: Semantic-aware Neural Radiance Fields for Reinforcement Learning.](http://arxiv.org/abs/2301.11520) | 本文提出了一种称为SNeRL的语义感知神经辐射场，它通过学习3D-aware的隐式表示来进行强化学习，并在基于像素的以及最新的3D感知表示方法中表现出更好的性能。 |
| [^80] | [Deep learning enhanced noise spectroscopy of a spin qubit environment.](http://arxiv.org/abs/2301.05079) | 本文研究使用深度学习模型提高噪声谱学准确性，实验表明此方法可以比标准技术更加准确，并且需要更少的序列。 |
| [^81] | [TarViS: A Unified Approach for Target-based Video Segmentation.](http://arxiv.org/abs/2301.02657) | 提出了一种名为TarViS的新颖、统一的网络架构，可用于任何需要在视频中分段任意定义的“目标”集的任务。可以联合训练不同任务的数据集集合，并且可以在推断期间在任务之间进行热切换。在四个不同的任务中进行了应用，均优于现有最先进方法。 |
| [^82] | [VISEM-Tracking, a human spermatozoa tracking dataset.](http://arxiv.org/abs/2212.02842) | 本文提供了人类精子跟踪数据集VISEM-Tracking，包含手动注释的包围框坐标和由专家分析的精子特征，并提供未标记的视频以供易于访问和分析，有助于训练监督式机器学习方法，提高在评估精子运动和运动学方面的精度和可靠性。 |
| [^83] | [Query-Driven Knowledge Base Completion using Multimodal Path Fusion over Multimodal Knowledge Graph.](http://arxiv.org/abs/2212.01923) | 基于查询的多模态路径融合算法可以有效地对知识库进行补全，提高了性能，并且使用了基于查询的技术来提高系统的效率。 |
| [^84] | [Trust-Awareness to Secure Swarm Intelligence from Data Injection Attack.](http://arxiv.org/abs/2211.08407) | 本文提出一种基于信任感知的方法，以应对群体智能的数据注入攻击。 |
| [^85] | [Modelling black-box audio effects with time-varying feature modulation.](http://arxiv.org/abs/2211.00497) | 提出了利用时变特征调制来模拟黑盒音频效应，可以更好地捕获长时间尺度上的依赖关系，适用于fuzz和压缩等音频效应。 |
| [^86] | [Extracting Cultural Commonsense Knowledge at Scale.](http://arxiv.org/abs/2210.07763) | 本篇论文提出了一种名为CANDLE的方法，用于从网络语料库中提取文化常识知识，其优于之前的工作。这些知识对于情境化人工智能和GPT-3语言模型都有好处。 |
| [^87] | [Learnware: Small Models Do Big.](http://arxiv.org/abs/2210.03647) | Learnware范式旨在帮助用户充分利用小型模型，实现超越原始目的的事情，以解决当前机器学习技术面临的数据量大、训练难度高、数据安全等问题。 |
| [^88] | [An Empirical Study on How the Developers Discussed about Pandas Topics.](http://arxiv.org/abs/2210.03519) | 本研究通过收集Stack Overflow中与Pandas主题讨论相关的帖子，进行主题建模，发现了Pandas数据操作、数据分析和数据可视化等主题非常受欢迎，而数据清洗和数据挖掘等主题相对较难。 |
| [^89] | [Self-supervised Learning for Clustering of Wireless Spectrum Activity.](http://arxiv.org/abs/2210.02899) | 本研究使用无人监督学习技术探索无线电频谱活动，比较了两种不同的无人监督学习模型和一种混合模型，实现了精准的频谱活动聚类。 |
| [^90] | [FreeREA: Training-Free Evolution-based Architecture Search.](http://arxiv.org/abs/2207.05135) | 本研究提出了一种无需训练步骤的进化式架构搜索算法FreeREA，可直接在目标硬件上优化搜索，且能够在性能最大化的同时，极大地减小内存占用。实验结果证明其比手动设计更高效。 |
| [^91] | [On the Generalization of Spiking Neural Networks via Minimum Description Length and Structural Stability.](http://arxiv.org/abs/2207.04876) | 本研究通过利用最小描述长度原则和结构稳定性为脉冲神经网络提供了一个明确的泛化界限，并指定了最大稳定分歧解数的下限和上限。 |
| [^92] | [Faster Exact MPE and Constrained Optimization with Deterministic Finite State Automata.](http://arxiv.org/abs/2108.03899) | 本文提出了一种基于确定性有限状态自动机的简洁函数表示方法FABE，可以更快地处理图模型中的精确最可能解和约束优化任务。在基准测试中，FABE通常优于现有技术，导致显着的运行时间改进（高达5个数量级）。 |
| [^93] | [Modern Non-Linear Function-on-Function Regression.](http://arxiv.org/abs/2107.14151) | 本研究提出一种利用神经网络分析功能数据的新型非线性函数回归模型，通过连续隐藏层实现对功能响应建模，并提供了两种模型拟合策略（FDNN和FBNN），并通过正则化技术得到更加简明的结果。 |
| [^94] | [Non-linear Functional Modeling using Neural Networks.](http://arxiv.org/abs/2104.09371) | 本文提出了一种基于神经网络的、适用于函数数据的新型非线性模型。我们提出了两种变体，旨在显式利用函数数据中固有的结构，并通过全面的模拟研究和实际数据示例证明了该方法的有效性。 |

# 详细

[^1]: 将生成AI与主动学习框架相结合来优化药物设计

    Optimizing Drug Design by Merging Generative AI With Active Learning Frameworks. (arXiv:2305.06334v1 [q-bio.BM])

    [http://arxiv.org/abs/2305.06334](http://arxiv.org/abs/2305.06334)

    该论文提出了一种基于主动学习的生成AI工作流程，可以克服当前生成AI方法的局限性，去设计出具有高预测亲和力的可行化学分子。

    

    传统的药物研发项目正在通过机器学习方法进行转型。其中，生成AI方法因其设计新分子和增强现有分子特性的能力而受到关注。然而，当前的生成AI方法存在局限性，例如对目标的亲和力低，ADME/PK特性未知或缺乏合成可追溯性等。为了提高生成AI方法的适用范围，我们开发了基于变分自编码器和主动学习步骤的工作流程。设计的生成AI工作流程从分子指标，包括药物相似性、可合成性、相似性和对接得分中迭代学习。此外，我们还在最后的选择步骤中包括了一组基于先进的分子建模模拟的层次化标准。我们在两个模型系统CDK2和KRAS上测试了我们的生成AI工作流程。在两种情况下，我们的模型生成了具有高预测亲和力的可行化学分子。

    Traditional drug discovery programs are being transformed by the advent of machine learning methods. Among these, Generative AI methods (GM) have gained attention due to their ability to design new molecules and enhance specific properties of existing ones. However, current GM methods have limitations, such as low affinity towards the target, unknown ADME/PK properties, or the lack of synthetic tractability. To improve the applicability domain of GM methods, we have developed a workflow based on a variational autoencoder coupled with active learning steps. The designed GM workflow iteratively learns from molecular metrics, including drug likeliness, synthesizability, similarity, and docking scores. In addition, we also included a hierarchical set of criteria based on advanced molecular modeling simulations during a final selection step. We tested our GM workflow on two model systems, CDK2 and KRAS. In both cases, our model generated chemically viable molecules with a high predicted aff
    
[^2]: AGD和MoE用于集成多模态感知

    Alternating Gradient Descent and Mixture-of-Experts for Integrated Multimodal Perception. (arXiv:2305.06324v1 [cs.CV])

    [http://arxiv.org/abs/2305.06324](http://arxiv.org/abs/2305.06324)

    本文提出了集成多模态感知（IMP）方法，将多模态输入集成到单个编码器中，采用交替梯度下降法（AGD）和混合专家（MoE）相结合的方法实现高效的模型和任务扩展，取得了在多个基准测试中具有竞争力的性能表现。

    

    本文提出了一种简单可扩展的多模态多任务训练和建模方法——集成多模态感知（IMP）。IMP将图像、视频、文本和音频等多模态输入集成到单个Transformer编码器中，并具有最小的模态特定组件。IMP使用了一种新颖的设计，将交替梯度下降法（AGD）和混合专家（MoE）相结合，以实现高效的模型和任务扩展。通过广泛的实证研究，我们揭示了以下关键见解：1）在多样化的异构模态、损失函数和任务上交替执行梯度下降更新，并同时改变输入分辨率，可以有效提高多模态理解。2）在单一的模态不可知编码器上使用MoE进行模型稀疏化可以显著提高性能，胜过使用模态特定编码器或额外融合层的稠密模型，并大大缓解模态之间的冲突。IMP在三个多模态基准测试中取得了具有竞争力的性能，胜过了大部分已发表的方法。

    We present Integrated Multimodal Perception (IMP), a simple and scalable multimodal multi-task training and modeling approach. IMP integrates multimodal inputs including image, video, text, and audio into a single Transformer encoder with minimal modality-specific components. IMP makes use of a novel design that combines Alternating Gradient Descent (AGD) and Mixture-of-Experts (MoE) for efficient model \& task scaling. We conduct extensive empirical studies about IMP and reveal the following key insights: 1) performing gradient descent updates by alternating on diverse heterogeneous modalities, loss functions, and tasks, while also varying input resolutions, efficiently improves multimodal understanding. 2) model sparsification with MoE on a single modality-agnostic encoder substantially improves the performance, outperforming dense models that use modality-specific encoders or additional fusion layers and greatly mitigating the conflicts between modalities. IMP achieves competitive p
    
[^3]: Scan2LoD3: 使用射线投射和贝叶斯网络重建具有语义信息的LoD3三维建筑模型

    Scan2LoD3: Reconstructing semantic 3D building models at LoD3 using ray casting and Bayesian networks. (arXiv:2305.06314v1 [cs.CV])

    [http://arxiv.org/abs/2305.06314](http://arxiv.org/abs/2305.06314)

    本文提出一种称为Scan2LoD3的新方法，通过改进外墙层次的语义三维分割来精确重建具有语义信息的LoD3建筑模型。

    

    在精细程度为LoD3的级别上重建带有语义信息的三维建筑模型一直是一个长期存在的挑战。与基于网格的模型不同，这些模型需要具有完全的几何形状和外墙层次的物体语义信息。这种要求严格的语义三维重建的主要挑战在于可靠地在三维输入数据的外墙层次进行语义分割。我们提出了一种称为Scan2LoD3的新方法，通过改进外墙层次的语义三维分割来精确重建具有语义信息的LoD3建筑模型。为此，我们利用激光物理学和三维建筑模型的先验知识来概率地识别模型冲突。这些概率物理冲突提出了模型开口的位置：它们的最终语义和形状是通过融合冲突、三维点云和二维图像的多模态概率图的贝叶斯网络推断出来的。为了满足严格的LoD3要求，我们利用估计的形状在三维建筑先验中切割出开口，并从库中适配语义三维对象。

    Reconstructing semantic 3D building models at the level of detail (LoD) 3 is a long-standing challenge. Unlike mesh-based models, they require watertight geometry and object-wise semantics at the fa\c{c}ade level. The principal challenge of such demanding semantic 3D reconstruction is reliable fa\c{c}ade-level semantic segmentation of 3D input data. We present a novel method, called Scan2LoD3, that accurately reconstructs semantic LoD3 building models by improving fa\c{c}ade-level semantic 3D segmentation. To this end, we leverage laser physics and 3D building model priors to probabilistically identify model conflicts. These probabilistic physical conflicts propose locations of model openings: Their final semantics and shapes are inferred in a Bayesian network fusing multimodal probabilistic maps of conflicts, 3D point clouds, and 2D images. To fulfill demanding LoD3 requirements, we use the estimated shapes to cut openings in 3D building priors and fit semantic 3D objects from a libra
    
[^4]: 通过抓取的方式进行自监督实例分割

    Self-Supervised Instance Segmentation by Grasping. (arXiv:2305.06305v1 [cs.CV])

    [http://arxiv.org/abs/2305.06305](http://arxiv.org/abs/2305.06305)

    本文提出了一种自监督实例分割方法，使用抓取交互来收集分割监督。利用分割出的抓取对象，采用“剪切和粘贴”生成方法，训练的模型可以达到与完全监督实例分割数据集训练的模型相当或更优的性能。

    

    实例分割在许多机器人应用中都是一项基本的技能。本文提出了一种自监督方法，使用抓取交互来收集一个实例分割模型的分割监督。当机器人抓取物品时，可以从抓取前和抓取后的图像中推断出抓取物品的掩码。利用这个观点，我们学习了一个抓取分割模型，用于从抓取前和抓取后的图像中分割出抓取的物体。这样的模型可以从数千个抓取交互中分割出抓取的对象，而不需要昂贵的人工注释。利用分割出的抓取对象，我们可以“剪切”物体从原始场景中，并将它们“粘贴”到新的场景中来生成实例监督。我们证明，与传统的图像减法方法相比，我们的抓取分割模型在分割抓取对象时提供了5倍的误差降低。结合我们的“剪切和粘贴”生成方法，训练使用我们方法的实例分割模型可以达到与完全监督实例分割数据集训练的模型相当或更优的性能。

    Instance segmentation is a fundamental skill for many robotic applications. We propose a self-supervised method that uses grasp interactions to collect segmentation supervision for an instance segmentation model. When a robot grasps an item, the mask of that grasped item can be inferred from the images of the scene before and after the grasp. Leveraging this insight, we learn a grasp segmentation model to segment the grasped object from before and after grasp images. Such a model can segment grasped objects from thousands of grasp interactions without costly human annotation. Using the segmented grasped objects, we can "cut" objects from their original scenes and "paste" them into new scenes to generate instance supervision. We show that our grasp segmentation model provides a 5x error reduction when segmenting grasped objects compared with traditional image subtraction approaches. Combined with our "cut-and-paste" generation method, instance segmentation models trained with our method
    
[^5]: 为什么不行动起来？揭示可解释人工智能和用户行动之间的联系。

    Why Don't You Do Something About It? Outlining Connections between AI Explanations and User Actions. (arXiv:2305.06297v1 [cs.HC])

    [http://arxiv.org/abs/2305.06297](http://arxiv.org/abs/2305.06297)

    可解释人工智能（XAI）系统的核心假设是解释可以改变用户的知识并促进他们在复杂的技术环境中采取行动。本文提出了一个框架来映射解释中呈现的信息和用户采取的行动之间的联系，并探讨了现有工作中的信息缺口。

    

    可解释人工智能系统的核心假设是解释可以改变用户的知识，从而使他们能够在复杂的社会技术环境中行动。尽管行动至关重要，但解释通常是基于技术方面组织和评估的。先前的工作在提供的信息和用户行为之间的联系方面差异很大。在评估中将行动置于中心位置的一个重要的第一步是理解可解释人工智能社区集体认可的解释可以提供的信息范围以及与之相关联的行动。在本文中，我们提出了一个框架，将关于可解释人工智能解释中呈现的信息和用户行动的先前工作进行了映射，并讨论了我们发现的呈现给用户的信息方面的差距。

    A core assumption of explainable AI systems is that explanations change what users know, thereby enabling them to act within their complex socio-technical environments. Despite the centrality of action, explanations are often organized and evaluated based on technical aspects. Prior work varies widely in the connections it traces between information provided in explanations and resulting user actions. An important first step in centering action in evaluations is understanding what the XAI community collectively recognizes as the range of information that explanations can present and what actions are associated with them. In this paper, we present our framework, which maps prior work on information presented in explanations and user action, and we discuss the gaps we uncovered about the information presented to users.
    
[^6]: BEIT适配器和Mask2Former在语义分割中解密牙科放射线学的偏见

    Radious: Unveiling the Enigma of Dental Radiology with BEIT Adaptor and Mask2Former in Semantic Segmentation. (arXiv:2305.06236v1 [cs.CV])

    [http://arxiv.org/abs/2305.06236](http://arxiv.org/abs/2305.06236)

    文章利用BEIT适配器和Mask2Former开发了一种语义分割算法，最终成功提高了9％和33％的mIoU得分来检测和识别多种不同的牙科疾病和异常。

    

    X光图像是诊断和治疗牙齿问题的第一步。因此，早期诊断可以防止口腔和牙齿疾病的发展和加重。本文基于BEIT适配器和Mask2Former开发了一种语义分割算法，用于检测和识别全景、根尖、翼状突、修复、根管治疗、冠、龋齿、钉、复合材料、桥梁、牙髓炎、根尖囊肿、牙槽囊肿、囊肿、种植物和骨移植材料等多种牙科疾病和异常。我们将算法结果与两种图像分割的现有算法Deeplabv3和Segformer在自己的数据集上进行了比较。我们发现Radious算法的mIoU得分在Deeplabv3+和Segformer中分别比现有算法提高了9％和33％。

    X-ray images are the first steps for diagnosing and further treating dental problems. So, early diagnosis prevents the development and increase of oral and dental diseases. In this paper, we developed a semantic segmentation algorithm based on BEIT adaptor and Mask2Former to detect and identify teeth, roots, and multiple dental diseases and abnormalities such as pulp chamber, restoration, endodontics, crown, decay, pin, composite, bridge, pulpitis, orthodontics, radicular cyst, periapical cyst, cyst, implant, and bone graft material in panoramic, periapical, and bitewing X-ray images. We compared the result of our algorithm to two state-of-the-art algorithms in image segmentation named: Deeplabv3 and Segformer on our own data set. We discovered that Radious outperformed those algorithms by increasing the mIoU scores by 9% and 33% in Deeplabv3+ and Segformer, respectively.
    
[^7]: DaGAN++：面向语音头视频生成的深度感知生成对抗网络

    DaGAN++: Depth-Aware Generative Adversarial Network for Talking Head Video Generation. (arXiv:2305.06225v1 [cs.CV])

    [http://arxiv.org/abs/2305.06225](http://arxiv.org/abs/2305.06225)

    DaGAN++是一种深度感知生成对抗网络，能够从面部视频中自学习密集的3D面部几何，将它们融入到生成器中，从而实现面向语音头视频生成，并在多个基准数据集上取得了最先进的结果。

    

    以往的语音头视频生成技术主要依赖于2D信息，包括面部外貌和动作。然而，像素级的深度等密集的3D面部几何数据在构建准确的3D面部结构和抑制背景噪声方面发挥了至关重要的作用。本文提出了一种自监督的模块，能够从面部视频中学习密集的3D面部几何数据（即深度），而不需要训练时的摄像机参数和几何注释。论文还提出了一个策略，学习像素级的不确定性，以便更可靠地感知刚性运动像素。此外，还设计了一个有效的面部关键点估计模块，为生成运动场提供准确的关键点。最后，我们提出了一种3D感知的跨模态（即外貌和深度）注意机制，并将其融入生成对抗网络框架中，实现面向语音头视频生成。所提出的DaGAN ++模型在多个基准数据集上取得了最先进的结果，表现出卓越的视觉质量，稳定性和多样性。

    Predominant techniques on talking head generation largely depend on 2D information, including facial appearances and motions from input face images. Nevertheless, dense 3D facial geometry, such as pixel-wise depth, plays a critical role in constructing accurate 3D facial structures and suppressing complex background noises for generation. However, dense 3D annotations for facial videos is prohibitively costly to obtain. In this work, firstly, we present a novel self-supervised method for learning dense 3D facial geometry (ie, depth) from face videos, without requiring camera parameters and 3D geometry annotations in training. We further propose a strategy to learn pixel-level uncertainties to perceive more reliable rigid-motion pixels for geometry learning. Secondly, we design an effective geometry-guided facial keypoint estimation module, providing accurate keypoints for generating motion fields. Lastly, we develop a 3D-aware cross-modal (ie, appearance and depth) attention mechanism,
    
[^8]: ComputeGPT：适用于数值问题的计算型聊天模型

    ComputeGPT: A computational chat model for numerical problems. (arXiv:2305.06223v1 [cs.PL])

    [http://arxiv.org/abs/2305.06223](http://arxiv.org/abs/2305.06223)

    ComputeGPT是一种计算型聊天模型，可以通过运行代码解决数值问题，结合本地浏览器的Python解释器和优化的提示，实现最先进的数值问题效率并为代码提供合适的前端和安全环境。

    

    语言模型在解决数值问题上不够精确，其结构要求的是概率性的下一个单词。本文提出了ComputeGPT：一种通过按需运行代码来解决计算问题的聊天模型。ComputeGPT将每个问题转换为相关的代码，运行代码并将计算结果作为聊天的一部分返回。我们将这种方法与基于本地浏览器的Python解释器和优化的提示相结合，以实现最先进的数值问题效率，并为代码提供合适的前端和安全环境。

    Language models are not accurate in numerical problems. Their architecture does not allow for anything less than a probabilistic next word. This paper introduces ComputeGPT: an approach of creating a chat model able to answer computational problems through running on-demand code. ComputeGPT converts each question to relevant code, runs the code, and returns the computed answer as part of the chat. We combine this approach with a local browser-based Python interpretation and fine-tuned prompts in order to achieve state-of-the-art efficiency on numerical problems and provide a suitable front-end and safe environment for the code to be executed in.
    
[^9]: 带深度划分的多提示模态交叉学习

    Multi-Prompt with Depth Partitioned Cross-Modal Learning. (arXiv:2305.06221v1 [cs.CV])

    [http://arxiv.org/abs/2305.06221](http://arxiv.org/abs/2305.06221)

    本研究提出了划分的多模态提示（PMPO）方法，将软提示从一个扩展到多个，通过连接多个提示到视觉编码器的不同深度上，能够更好地捕捉视觉表示的上下文深度，与传统单提示方法相比，在下游视觉语言任务中具有更好的表现。

    

    近年来，软提示学习方法被提出来微调大型视觉-语言预训练模型以完成各种下游任务。这些方法通常将可学习的文本标记与类别标记组合作为模型的输入，其中模型的参数被冻结。然而，它们经常使用单一提示来描述类别上下文，而不能充分捕捉类别的多样属性。本研究介绍了划分的多模态提示（PMPO），这是一种多模态提示技术，将软提示从一个可学习提示扩展到多个提示。我们的方法将视觉编码器深度进行分割，并将可学习提示连接到分离的视觉深度上，使不同提示能够捕捉视觉表示的层次上下文深度。此外，为了最大限度地利用多提示学习的优势，我们将来自手动设计的模板和可学习的多提示的先验信息结合在一起，从而提高了模型的泛化能力。

    In recent years, soft prompt learning methods have been proposed to fine-tune large-scale vision-language pre-trained models for various downstream tasks. These methods typically combine learnable textual tokens with class tokens as input for models with frozen parameters. However, they often employ a single prompt to describe class contexts, failing to capture categories' diverse attributes adequately. This study introduces the Partitioned Multi-modal Prompt (PMPO), a multi-modal prompting technique that extends the soft prompt from a single learnable prompt to multiple prompts. Our method divides the visual encoder depths and connects learnable prompts to the separated visual depths, enabling different prompts to capture the hierarchical contextual depths of visual representations. Furthermore, to maximize the advantages of multi-prompt learning, we incorporate prior information from manually designed templates and learnable multi-prompts, thus improving the generalization capabiliti
    
[^10]: 多任务端到端训练改进了对话式推荐

    Multi-Task End-to-End Training Improves Conversational Recommendation. (arXiv:2305.06218v1 [cs.CL])

    [http://arxiv.org/abs/2305.06218](http://arxiv.org/abs/2305.06218)

    本文表明，采用多任务端到端Transformer模型可以提高对话式推荐的性能，可竞争于先前采用复杂多组件方法的模型，通过微调我们的模型和额外的多任务学习设置，实现了知识在领域间的转移。

    

    本文分析了一个多任务端到端Transformer模型在对话式推荐任务上的性能，该任务旨在基于用户在对话中明确表示的偏好提供推荐。虽然先前的研究在此领域采用了复杂的多组件方法，其中对话管理和实体推荐任务由单独的组件处理，但我们表明，基于T5文本-文本Transformer模型的统一Transformer模型在推荐相关项目和生成对话方面都可以竞争。我们在ReDIAL对话式电影推荐数据集上微调我们的模型，并在多任务学习设置中创建了衍生自MovieLens的额外训练任务（例如基于输入电影预测电影属性和相关电影）。使用一系列探针研究，我们证明了在额外任务中学习到的知识被转移到了对话式推荐领域中。

    In this paper, we analyze the performance of a multitask end-to-end transformer model on the task of conversational recommendations, which aim to provide recommendations based on a user's explicit preferences expressed in dialogue. While previous works in this area adopt complex multi-component approaches where the dialogue management and entity recommendation tasks are handled by separate components, we show that a unified transformer model, based on the T5 text-to-text transformer model, can perform competitively in both recommending relevant items and generating conversation dialogue. We fine-tune our model on the ReDIAL conversational movie recommendation dataset, and create additional training tasks derived from MovieLens (such as the prediction of movie attributes and related movies based on an input movie), in a multitask learning setting. Using a series of probe studies, we demonstrate that the learned knowledge in the additional tasks is transferred to the conversational setti
    
[^11]: 补丁学习：实现跨不同生物医学数据源的综合分析的范式。

    Patchwork Learning: A Paradigm Towards Integrative Analysis across Diverse Biomedical Data Sources. (arXiv:2305.06217v1 [cs.LG])

    [http://arxiv.org/abs/2305.06217](http://arxiv.org/abs/2305.06217)

    补丁学习是一种新的范式，通过整合来自不同数据源的信息，解决了数据隐私、异构数据来源和无法充分利用多个数据模态的挑战。它可以同时利用互补的数据来源，同时保护数据隐私，从而实现开发更全面和具有普适性的ML模型。

    

    在医疗保健领域中，机器学习（ML）提供了许多增强患者护理、人口健康和医疗保健提供者工作流程的机会。然而，由于数据隐私、异构数据来源和无法充分利用多个数据模态的挑战，现实中的临床和成本效益仍然有限。在这篇观点论文中，我们介绍了“补丁学习”（PL），这是一种新的范式，通过集成来自不同数据来源（例如，临床免费文本、医学图像、组学）和分布在不同安全站点上的不同数据模态的不同数据集的信息来解决这些限制。PL允许同时利用互补的数据来源，同时保护数据隐私，从而实现开发更全面和具有普适性的ML模型。我们介绍了补丁学习的概念以及其在医疗保健领域的当前实现，探讨了解决各种问题的潜在机会和适用数据来源。

    Machine learning (ML) in healthcare presents numerous opportunities for enhancing patient care, population health, and healthcare providers' workflows. However, the real-world clinical and cost benefits remain limited due to challenges in data privacy, heterogeneous data sources, and the inability to fully leverage multiple data modalities. In this perspective paper, we introduce "patchwork learning" (PL), a novel paradigm that addresses these limitations by integrating information from disparate datasets composed of different data modalities (e.g., clinical free-text, medical images, omics) and distributed across separate and secure sites. PL allows the simultaneous utilization of complementary data sources while preserving data privacy, enabling the development of more holistic and generalizable ML models. We present the concept of patchwork learning and its current implementations in healthcare, exploring the potential opportunities and applicable data sources for addressing various
    
[^12]: 无序多物体导航

    Sequence-Agnostic Multi-Object Navigation. (arXiv:2305.06178v1 [cs.RO])

    [http://arxiv.org/abs/2305.06178](http://arxiv.org/abs/2305.06178)

    该论文提出了一种无序多物体导航算法，该算法利用深度强化学习框架，通过适当的奖励规范，奖励单个和多个目标对象类别的进展，实现了对多个对象类别的准确定位，适用于动态变化的实际应用。

    

    多物体导航 (MultiON) 任务要求机器人定位多种物体类别的实例。这是家庭或工厂辅助机器人的基本任务。已有的 MultiON 方法将此视为对象导航 (ON) 的直接扩展，即本文所述的 ON 任务需要提前指定探索对象类别的顺序。这在动态变化的实际应用中具有很大的局限性。本文描述了一种基于演员-评论家体系结构和适当的奖励规范的深度强化学习框架，用于无序 MultiON。我们的框架利用过去的经验，并试图奖励单个和多个目标对象类别的进展。我们在 AI Habitat 3D 模拟环境中使用 Gibson 基准数据集中的照片逼真场景进行实验，结果表明我们的方法性能更好。

    The Multi-Object Navigation (MultiON) task requires a robot to localize an instance (each) of multiple object classes. It is a fundamental task for an assistive robot in a home or a factory. Existing methods for MultiON have viewed this as a direct extension of Object Navigation (ON), the task of localising an instance of one object class, and are pre-sequenced, i.e., the sequence in which the object classes are to be explored is provided in advance. This is a strong limitation in practical applications characterized by dynamic changes. This paper describes a deep reinforcement learning framework for sequence-agnostic MultiON based on an actor-critic architecture and a suitable reward specification. Our framework leverages past experiences and seeks to reward progress toward individual as well as multiple target object classes. We use photo-realistic scenes from the Gibson benchmark dataset in the AI Habitat 3D simulation environment to experimentally show that our method performs bett
    
[^13]: 通过生成对抗反馈对语言模型进行微调

    Fine-tuning Language Models with Generative Adversarial Feedback. (arXiv:2305.06176v1 [cs.CL])

    [http://arxiv.org/abs/2305.06176](http://arxiv.org/abs/2305.06176)

    本研究探讨了一种新的方法，使用生成对抗反馈的强化学习(RLGAF)对大型语言模型进行微调，以取代仅受人类反馈的强化学习(RLHF)，从而消除评估者的专业限制并提高性能。

    

    通过人类反馈的强化学习已经显著提高了大型语言模型(LLMs)的性能，使其输出与人类期望的价值观保持一致。然而，RLHF受到人类评估者的专业知识和生产力限制。在本研究中，我们研究了一种替代方法: 使用生成对抗反馈的强化学习(RLGAF)代替RLHF。我们的初步发现表明，RLGAF可以帮助对齐LLM的输出，同时不会受到RLHF固有的限制，为进一步自动化AI对齐的研究提供了有希望的途径。

    Reinforcement Learning with Human Feedback (RLHF) has been demonstrated to significantly enhance the performance of large language models (LLMs) by aligning their outputs with desired human values. However, RLHF is constrained by the expertise and productivity limitations of human evaluators. In this study, we investigate an alternative approach: Reinforcement Learning with Generative Adversarial Feedback (RLGAF) to RLHF. Our preliminary findings indicate that RLGAF can help align LLMs outputs while not suffering from the inherent restrictions of RLHF, suggesting promising avenues for further research on automating AI alignment.
    
[^14]: 使用贝叶斯模型平均分析社交媒体上的气候宣传活动

    Analysis of Climate Campaigns on Social Media using Bayesian Model Averaging. (arXiv:2305.06174v1 [cs.CL])

    [http://arxiv.org/abs/2305.06174](http://arxiv.org/abs/2305.06174)

    本文分析了工业、倡导组织和气候倡导组织在社交媒体上如何影响气候变化的叙事，并提出了一个最小化监督模型组合方法，用于识别Facebook上气候广告的立场。

    

    气候变化是我们时代的核心问题，我们正处于一个关键时刻。各种利益集团、社会运动组织和个人在社交媒体上开展针对这个问题的集体行动。此外，社交媒体上的问题倡导活动往往是针对当前社会关注的问题，特别是能源行业面临的问题。本文的目标是分析工业、倡导组织和气候倡导组织如何利用社交媒体影响气候变化的叙事。在这项工作中，我们提出了一个最小化监督模型组合方法，并结合消息主题来识别Facebook上气候广告的立场。最后，我们发布了我们的立场数据集、模型和与气候宣传活动相关的主题，供未来的舆情挖掘和自动检测气候变化立场的研究使用。

    Climate change is the defining issue of our time, and we are at a defining moment. Various interest groups, social movement organizations, and individuals engage in collective action on this issue on social media. In addition, issue advocacy campaigns on social media often arise in response to ongoing societal concerns, especially those faced by energy industries. Our goal in this paper is to analyze how those industries, their advocacy group, and climate advocacy group use social media to influence the narrative on climate change. In this work, we propose a minimally supervised model soup [56] approach combined with messaging themes to identify the stances of climate ads on Facebook. Finally, we release our stance dataset, model, and set of themes related to climate campaigns for future work on opinion mining and the automatic detection of climate change stances.
    
[^15]: QICHWABASE: 一个面向凯楚亚社区的凯楚亚语言和知识库

    QICHWABASE: A Quechua Language and Knowledge Base for Quechua Communities. (arXiv:2305.06173v1 [cs.CL])

    [http://arxiv.org/abs/2305.06173](http://arxiv.org/abs/2305.06173)

    QICHWABASE为少数民族语言和知识构建Wikibase实例，支持凯楚亚社区和谐进程，能增强少数民族在网络上的存在感。

    

    近十年来，网络越来越成为语言和知识表示的空间。然而，这只针对广泛流行的语言和社区，在少数民族社区和其资源方面却受到较少关注。本文提出了QICHWABASE以支持凯楚亚语言和知识及其社区的和谐进程。为此，我们采用了一些方法和工具，能够成为全球凯楚亚社区的助推器。我们得出的结论是，在构建QICHWABASE，即一个Wikibase实例时采用的方法和工具能够增强少数民族在网络上的存在感。

    Over the last decade, the Web has increasingly become a space of language and knowledge representation. However, it is only true for well-spread languages and well-established communities, while minority communities and their resources received less attention. In this paper, we propose QICHWABASE to support the harmonization process of the Quechua language and knowledge, and its community. For doing it, we adopt methods and tools that could become a game changer in favour of Quechua communities around the world. We conclude that the methodology and tools adopted on building QICHWABASE, which is a Wikibase instance, could enhance the presence of minorities on the Web.
    
[^16]: 动态上下文图形实现对万物知识图谱的会话语义解析

    Conversational Semantic Parsing using Dynamic Context Graphs. (arXiv:2305.06164v1 [cs.CL])

    [http://arxiv.org/abs/2305.06164](http://arxiv.org/abs/2305.06164)

    本论文提出了一种新的方法，使用动态创建的子图表示话语及上下文的信息来进行会话语义解析，并利用图形神经网络编码，可表示大量看不见的节点，比静态方法更为优越。

    

    本文考虑了在拥有数百万个实体和数千种关系类型的通用知识图谱上进行会话语义解析的任务。我们致力于开发能够交互地将用户语言映射为可执行逻辑形式（例如SPARQL）的模型，同时考虑到对话历史的上下文。我们的关键想法是通过一个动态创建的子图来表示有关话语及其上下文的信息，即每个话语的节点数会发生变化。而且，我们利用子图的基本结构，而不是将其视为序列，使用图形神经网络进行编码，从而进一步允许我们表示大量（看不见的）节点。实验结果表明，动态建模上下文优于静态方法，可在各个方面（即简单和复杂问题）提高性能。我们的结果进一步证实，模型化上下文结构比仅考虑单个话语更好。

    In this paper we consider the task of conversational semantic parsing over general purpose knowledge graphs (KGs) with millions of entities, and thousands of relation-types. We are interested in developing models capable of interactively mapping user utterances into executable logical forms (e.g., SPARQL) in the context of the conversational history. Our key idea is to represent information about an utterance and its context via a subgraph which is created dynamically, i.e., the number of nodes varies per utterance. Moreover, rather than treating the subgraph as a sequence we exploit its underlying structure, and thus encode it using a graph neural network which further allows us to represent a large number of (unseen) nodes. Experimental results show that modeling context dynamically is superior to static approaches, delivering performance improvements across the board (i.e., for simple and complex questions). Our results further confirm that modeling the structure of context is bette
    
[^17]: 基于大语言模型的代数错误分类方法

    Algebra Error Classification with Large Language Models. (arXiv:2305.06163v1 [cs.CL])

    [http://arxiv.org/abs/2305.06163](http://arxiv.org/abs/2305.06163)

    本研究提出了一种基于大语言模型的代数错误分类方法，相较于现有方法，具有更好的泛化能力和处理学生回答的能力。

    

    在回答开放式数学问题时自动反馈具有显著的潜力来提高大规模学习成果。自动反馈系统的关键部分是错误分类组件，该组件识别学生的错误，并启用适当的预定义反馈。大多数现有的错误分类方法使用基于规则的方法，其泛化能力有限。现有的数据驱动方法避免了这些限制，但具体要求将学生答复中的数学表达式解析为语法树。这一要求本身就是一个限制，因为学生的答复并不总是符合语法的，无法转换为树形结构。在这项工作中，我们介绍一种使用预训练的大型语言模型进行错误分类的灵活方法。我们证明我们的方法可以在代数错误分类方面优于现有方法，并能够对更大的学生回答进行分类。此外，我们还展示了我们的方法可以推广到其他领域和语言，而无需额外的训练数据。

    Automated feedback as students answer open-ended math questions has significant potential in improving learning outcomes at large scale. A key part of automated feedback systems is an error classification component, which identifies student errors and enables appropriate, predefined feedback to be deployed. Most existing approaches to error classification use a rule-based method, which has limited capacity to generalize. Existing data-driven methods avoid these limitations but specifically require mathematical expressions in student responses to be parsed into syntax trees. This requirement is itself a limitation, since student responses are not always syntactically valid and cannot be converted into trees. In this work, we introduce a flexible method for error classification using pre-trained large language models. We demonstrate that our method can outperform existing methods in algebra error classification, and is able to classify a larger set of student responses. Additionally, we 
    
[^18]: StarCoder: 源代码与你同在！

    StarCoder: may the source be with you!. (arXiv:2305.06161v1 [cs.CL])

    [http://arxiv.org/abs/2305.06161](http://arxiv.org/abs/2305.06161)

    本研究介绍了一个具有15.5B参数和8K上下文长度的大型语言模型——StarCoder，其可以进行快速大批量推理。经评估证明，在Python上表现优异，能够通过人工评估获得40\%的pass@1的得分，且在其他程序中也表现出令人满意的性能。

    

    BigCode社区是一个开放的科学合作组织，致力于开发代表代码的大型语言模型（Code LLMs）的负责任发展。该文介绍了StarCoder和StarCoderBase，这是具有15.5B参数模型和8K上下文长度、填充能力以及多种查询注意力实现的快速大批量推理的模型。我们对StarCoderBase的1万亿个标记进行 fine-tuning，创建了StarCoder。我们进行了迄今为止最全面的Code LLMs评估，并表明StarCoderBase优于支持多种编程语言的每个开放Code LLM，并与OpenAI code-cushman-001模型相匹配或优于该模型。此外，StarCoder在Python上也表现出优异性能，能够通过人工评估获得40\%的pass@1的得分，并仍然保持其在其他程序中的性能。

    The BigCode community, an open-scientific collaboration working on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder and StarCoderBase: 15.5B parameter models with 8K context length, infilling capabilities and fast large-batch inference enabled by multi-query attention. StarCoderBase is trained on 1 trillion tokens sourced from The Stack, a large collection of permissively licensed GitHub repositories with inspection tools and an opt-out process. We fine-tuned StarCoderBase on 35B Python tokens, resulting in the creation of StarCoder. We perform the most comprehensive evaluation of Code LLMs to date and show that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model. Furthermore, StarCoder outperforms every model that is fine-tuned on Python, can be prompted to achieve 40\% pass@1 on HumanEval, and still retains its performance on other program
    
[^19]: 视觉-语言模型综述及在“恶意表情”挑战中的表现

    A Review of Vision-Language Models and their Performance on the Hateful Memes Challenge. (arXiv:2305.06159v1 [cs.CL])

    [http://arxiv.org/abs/2305.06159](http://arxiv.org/abs/2305.06159)

    本文综述了视觉-语言模型及其在社交媒体内容审核上的应用，研究发现早期融合模型比晚期融合模型更有效，其中表现最佳的早期融合模型是ClipBERT。

    

    社交媒体内容的审核目前仍然是一项高度手动的任务，然而每天发布的内容量太多，难以有效执行。随着许多多模态模型的出现，有潜力降低该任务的手动劳动量。本文旨在探讨不同的模型并确定在“恶意表情”挑战中最有效的模型。具体来说，我们探讨了早期融合和晚期融合模型在分类包含文本和图像的多模态表情中的差异。我们首先使用BERT和ResNet-152分别实现了文本和图像的单模态基线模型。然后将这些单模态模型的输出连接在一起创建了一个晚期融合模型。在早期融合模型方面，我们实现了ConcatBERT、VisualBERT、ViLT、CLIP和BridgeTower。结果发现，晚期融合模型的表现明显不如早期融合模型，而表现最佳的早期融合模型是ClipBERT。我们的研究结果表明，视觉-语言模型有潜力改善社交媒体上的恶意内容审核，但还需要更多的研究来进一步提高其性能。

    Moderation of social media content is currently a highly manual task, yet there is too much content posted daily to do so effectively. With the advent of a number of multimodal models, there is the potential to reduce the amount of manual labor for this task. In this work, we aim to explore different models and determine what is most effective for the Hateful Memes Challenge, a challenge by Meta designed to further machine learning research in content moderation. Specifically, we explore the differences between early fusion and late fusion models in classifying multimodal memes containing text and images. We first implement a baseline using unimodal models for text and images separately using BERT and ResNet-152, respectively. The outputs from these unimodal models were then concatenated together to create a late fusion model. In terms of early fusion models, we implement ConcatBERT, VisualBERT, ViLT, CLIP, and BridgeTower. It was found that late fusion performed significantly worse th
    
[^20]: EdgeNet：电子商务在线广告竞价设计的编码器-解码器生成网络

    EdgeNet : Encoder-decoder generative Network for Auction Design in E-commerce Online Advertising. (arXiv:2305.06158v1 [cs.IR])

    [http://arxiv.org/abs/2305.06158](http://arxiv.org/abs/2305.06158)

    EdgeNet是一种编码器-解码器生成网络，可用于在线电商广告拍卖中的数据驱动竞价设计。与传统模型相比，EdgeNet 可以更好地捕捉广告间的相互影响，并利用丰富的上下文信息，提高广告竞拍的效率。

    

    我们提出了一种新的编码器-解码器生成网络EdgeNet，引入了一种新颖的编码器-解码器框架，用于在线电子商务广告中数据驱动的拍卖设计。我们打破了广义次高价（GSP）的神经拍卖范式，提高了数据利用效率，同时确保了拍卖机制的经济特征。具体而言，EdgeNet引入了基于transformer的编码器来更好地捕捉不同广告间的相互作用。与基于GSP的神经拍卖模型相比，我们设计了一个自回归解码器，以更好地利用在线广告竞拍中的丰富上下文信息。EdgeNet在概念上简单易懂，并易于扩展到现有的端到端神经拍卖框架中。我们在广泛的电子商务广告竞拍中验证了EdgeNet的有效性，展示了其在提高用户体验和平台收入方面的潜力。

    We present a new encoder-decoder generative network dubbed EdgeNet, which introduces a novel encoder-decoder framework for data-driven auction design in online e-commerce advertising. We break the neural auction paradigm of Generalized-Second-Price(GSP), and improve the utilization efficiency of data while ensuring the economic characteristics of the auction mechanism. Specifically, EdgeNet introduces a transformer-based encoder to better capture the mutual influence among different candidate advertisements. In contrast to GSP based neural auction model, we design an autoregressive decoder to better utilize the rich context information in online advertising auctions. EdgeNet is conceptually simple and easy to extend to the existing end-to-end neural auction framework. We validate the efficiency of EdgeNet on a wide range of e-commercial advertising auction, demonstrating its potential in improving user experience and platform revenue.
    
[^21]: 多词语对于英语到巴提盲文机器翻译的影响

    Implications of Multi-Word Expressions on English to Bharti Braille Machine Translation. (arXiv:2305.06157v1 [cs.CL])

    [http://arxiv.org/abs/2305.06157](http://arxiv.org/abs/2305.06157)

    本文通过给基线神经机器翻译模型添加语言知识及多词语翻译子模块，在英语到巴提盲文机器翻译中取得了显著的改进。

    

    本文研究了如何提高英语到巴提盲文机器翻译系统，通过在基线神经机器翻译模型中加入语言知识，对五种语言对进行实验，即将英语句子翻译成五种印度语言，并随后翻译成相应的巴提盲文。通过添加子模块翻译多词语，本研究显示了可行的方法，跨语言对 NMT 输出质量有所提高。最小的改进出现在英语-尼泊尔语对中，为 22.08%，最大的改进出现在英语-印地语对中，为 23.30%。

    In this paper, we have shown the improvement of English to Bharti Braille machine translation system. We have shown how we can improve a baseline NMT model by adding some linguistic knowledge to it. This was done for five language pairs where English sentences were translated into five Indian languages and then subsequently to corresponding Bharti Braille. This has been demonstrated by adding a sub-module for translating multi-word expressions. The approach shows promising results as across language pairs, we could see improvement in the quality of NMT outputs. The least improvement was observed in English-Nepali language pair with 22.08% and the most improvement was observed in the English-Hindi language pair with 23.30%.
    
[^22]: The Vault：一个全面的多语言数据集，为促进代码理解和生成而设计

    The Vault: A Comprehensive Multilingual Dataset for Advancing Code Understanding and Generation. (arXiv:2305.06156v1 [cs.CL])

    [http://arxiv.org/abs/2305.06156](http://arxiv.org/abs/2305.06156)

    The Vault是一个提供了10种流行编程语言的40百万行代码-文本对的开源数据集，旨在增强面向代码的大型语言模型（LLM）的训练，有望在代码理解和生成任务上取得显著进展。

    

    我们介绍了 The Vault，这是一个开源的大规模代码文本数据集，旨在增强面向代码的大型语言模型（LLM）的训练。现有的用于训练基于代码的LLM的开源数据集在大小、质量(由于噪声信号)和格式（仅包含代码函数和文本说明配对）方面经常面临挑战。The Vault通过提供10种流行编程语言的40百万行代码-文本对，彻底清除10种多样的问题，以及各种级别的代码-文本对，包括类、函数和代码行等级别，来克服这些限制。研究人员和从业人员可以利用The Vault来训练不同的面向代码的LLM，或者将提供的数据清洗方法和脚本合并到自己的数据集中来改进数据集。通过将The Vault作为面向代码的LLMs的训练数据集，我们预计在代码理解和生成任务上取得显著进展，促进人工智能研究和实践的发展。

    We present The Vault, an open-source, large-scale code-text dataset designed to enhance the training of code-focused large language models (LLMs). Existing open-source datasets for training code-based LLMs often face challenges in terms of size, quality (due to noisy signals), and format (only containing code function and text explanation pairings). The Vault overcomes these limitations by providing 40 million code-text pairs across 10 popular programming languages, thorough cleaning for 10+ prevalent issues, and various levels of code-text pairings, including class, function, and line levels. Researchers and practitioners can utilize The Vault for training diverse code-focused LLMs or incorporate the provided data cleaning methods and scripts to improve their datasets. By employing The Vault as the training dataset for code-centric LLMs, we anticipate significant advancements in code understanding and generation tasks, fostering progress in both artificial intelligence research and so
    
[^23]: 利用合成目标进行机器翻译

    Leveraging Synthetic Targets for Machine Translation. (arXiv:2305.06155v1 [cs.CL])

    [http://arxiv.org/abs/2305.06155](http://arxiv.org/abs/2305.06155)

    本文提供了一种利用预训练模型生成合成目标从而提高机器翻译性能的方法，并发现其在不同测试基准下的表现优于使用真实数据训练，这一方法在有限资源的情况下尤其有用。

    

    在本文中，我们提供了一种在有限资源情况下训练机器翻译模型的方法，该方法通过利用通过大型预训练模型生成的合成目标数据。我们表明，在双语、多语言和语音翻译设置的不同基准测试中，使用合成目标训练模型的性能优于使用实际的正确数据训练模型。这种性能差距随着可用资源的限制（数据集大小和模型参数数量）的增加而变得更大。我们还对性能提升是否与优化的便利性或预测的更确定性相关进行了初步分析，以及这种范例是否能够提高在不同测试领域的超出分布性能。

    In this work, we provide a recipe for training machine translation models in a limited resource setting by leveraging synthetic target data generated using a large pre-trained model. We show that consistently across different benchmarks in bilingual, multilingual, and speech translation setups, training models on synthetic targets outperforms training on the actual ground-truth data. This performance gap grows bigger with increasing limits on the amount of available resources in the form of the size of the dataset and the number of parameters in the model. We also provide preliminary analysis into whether this boost in performance is linked to ease of optimization or more deterministic nature of the predictions, and whether this paradigm leads to better out-of-distribution performance across different testing domains.
    
[^24]: Structure-CLIP: 结合结构知识优化多模态语言表示

    Structure-CLIP: Enhance Multi-modal Language Representations with Structure Knowledge. (arXiv:2305.06152v1 [cs.CL])

    [http://arxiv.org/abs/2305.06152](http://arxiv.org/abs/2305.06152)

    Structure-CLIP使用文本中的结构化知识，使用场景图强化多模态语言表示，从而在图像-文本匹配任务中展现了更好的性能。

    

    大规模的视觉-语言预训练在各种下游任务中展现出了很好的性能，并在多模态理解和生成任务中取得了显著的进展。然而，现有方法在需要对文本进行详细语义理解的图像-文本匹配任务上通常表现较差。尽管已经有一些研究在解决这个问题，但它们没有充分利用句子中存在的结构化知识来增强多模态语言表示，导致性能较差。本文提出了一个端到端的框架Structure-CLIP，该框架结合了从文本中提取的隐式详细语义，以增强精细的语义表示。具体而言，(1)我们使用场景图来更加关注文本中的详细语义学习，并充分探索细粒度语义之间的结构化知识，(2)我们结合场景图的知识强化框架来充分利用这些信息。

    Large-scale vision-language pre-training has shown promising advances on various downstream tasks and achieved significant performance in multi-modal understanding and generation tasks. However, existing methods often perform poorly on image-text matching tasks that require a detailed semantics understanding of the text. Although there have been some works on this problem, they do not sufficiently exploit the structural knowledge present in sentences to enhance multi-modal language representations, which leads to poor performance. In this paper, we present an end-to-end framework Structure-CLIP, which integrates latent detailed semantics from the text to enhance fine-grained semantic representations. Specifically, (1) we use scene graphs in order to pay more attention to the detailed semantic learning in the text and fully explore structured knowledge between fine-grained semantics, and (2) we utilize the knowledge-enhanced framework with the help of the scene graph to make full use of
    
[^25]: 多目标优化的逆强化学习的收敛性证明研究

    A proof of convergence of inverse reinforcement learning for multi-objective optimization. (arXiv:2305.06137v1 [cs.LG])

    [http://arxiv.org/abs/2305.06137](http://arxiv.org/abs/2305.06137)

    本论文证明了多目标优化的逆强化学习方法在理论层面上的收敛性，包括Wasserstein逆强化学习和常规逆强化学习方法。

    

    本文通过将等效于多目标优化的WIRL问题的逆问题与投影次梯度法相结合，证明了Wasserstein逆强化学习（WIRL）在多目标优化中的收敛性。此外，我们还证明了逆强化学习（最大熵逆强化学习，导引成本学习）在多目标优化中的收敛性。

    We show the convergence of Wasserstein inverse reinforcement learning (WIRL) for multi-objective optimizations with the projective subgradient method by formulating an inverse problem of the optimization problem that is equivalent to WIRL for multi-objective optimizations.  In addition, we prove convergence of inverse reinforcement learning (maximum entropy inverse reinforcement learning, guid cost learning) for multi-objective optimization with the projective subgradient method.
    
[^26]: 基于视频内部和视频间信息最大化的小样本动作识别

    Few-shot Action Recognition via Intra- and Inter-Video Information Maximization. (arXiv:2305.06114v1 [cs.CV])

    [http://arxiv.org/abs/2305.06114](http://arxiv.org/abs/2305.06114)

    本论文提出了一种称为VIM的框架，采用自适应空间-时间视频采样器和时空动作增强器，用于小样本动作识别，充分利用视频内部和视频间信息以提高识别精度。

    

    当前的小样本动作识别涉及两个主要的信息源用于分类: (1) 来自视频片段内部的视频内部信息，由单个视频剪辑中的帧内容确定，以及 (2) 通过视频之间的关系(例如，特征相似性)测量的视频间信息。然而，现有方法未充分利用这两个信息源。关于视频内部信息，当前的输入视频采样操作可能会遗漏关键的动作信息，降低视频数据的利用效率。对于视频间信息，视频之间的动作不对齐使得计算精确关系变得困难。此外，如何共同考虑视频内外信息在小样本动作识别中仍未被充分探索。为此，我们提出了一个新的框架，称为视频信息最大化 (VIM)，用于小样本视频动作识别。VIM配备了一个自适应的时空视频采样器和一个时空动作增强器。

    Current few-shot action recognition involves two primary sources of information for classification:(1) intra-video information, determined by frame content within a single video clip, and (2) inter-video information, measured by relationships (e.g., feature similarity) among videos. However, existing methods inadequately exploit these two information sources. In terms of intra-video information, current sampling operations for input videos may omit critical action information, reducing the utilization efficiency of video data. For the inter-video information, the action misalignment among videos makes it challenging to calculate precise relationships. Moreover, how to jointly consider both inter- and intra-video information remains under-explored for few-shot action recognition. To this end, we propose a novel framework, Video Information Maximization (VIM), for few-shot video action recognition. VIM is equipped with an adaptive spatial-temporal video sampler and a spatiotemporal actio
    
[^27]: 贝叶斯推断的组合结构

    The Compositional Structure of Bayesian Inference. (arXiv:2305.06112v1 [math.CT])

    [http://arxiv.org/abs/2305.06112](http://arxiv.org/abs/2305.06112)

    该论文研究了贝叶斯反演在复杂组合结构中的计算方法，并探讨了将其用作统计推断的类型驱动方法。

    

    贝叶斯规则告诉我们如何反转因果过程以根据新证据更新我们的信念。如果认为该过程具有复杂的组合结构，我们可以观察到整个过程的反转可以按部件过程计算。我们研究了这种组成规则的结构，注意到它与函数式编程中的凸透镜模式相关。在适当的Markov核范畴的公理化表述中工作，我们看到了如何将贝叶斯反演看作是纤维范畴中状态依赖态射的特定实例。我们讨论了其组合性质，以底层类别上的函子表述，并探讨了如何将其用于更加类型驱动的统计推断方法。

    Bayes' rule tells us how to invert a causal process in order to update our beliefs in light of new evidence. If the process is believed to have a complex compositional structure, we may observe that the inversion of the whole can be computed piecewise in terms of the component processes. We study the structure of this compositional rule, noting that it relates to the lens pattern in functional programming. Working in a suitably general axiomatic presentation of a category of Markov kernels, we see how we can think of Bayesian inversion as a particular instance of a state-dependent morphism in a fibred category. We discuss the compositional nature of this, formulated as a functor on the underlying category and explore how this can used for a more type-driven approach to statistical inference.
    
[^28]: N-元事实的少样本链接预测

    Few-shot Link Prediction on N-ary Facts. (arXiv:2305.06104v1 [cs.AI])

    [http://arxiv.org/abs/2305.06104](http://arxiv.org/abs/2305.06104)

    本文提出了一个新任务——少样本N-元事实链接预测，并提出了一个名为FLEN的模型来实现。FLEN由三个模块组成，可以从有限的标记实例中预测N-元事实中的缺失实体。

    

    N-元事实由主要三元组（头实体、关系、尾实体）和任意数量的辅助属性值对组成，这在现实世界的知识图谱中很常见。对于N-元事实的链接预测是预测其中一个元素的缺失，填补缺失元素有助于丰富知识图谱并促进许多下游应用程序。以往的研究通常需要大量高质量的数据来理解N-元事实中的元素，但这些研究忽视了少样本关系，在现实世界的场景中却很常见。因此，本文引入一个新任务——少样本N-元事实链接预测，旨在使用有限的标记实例来预测N-元事实中的缺失实体。我们也提出了一个针对N-元事实的少样本链接预测模型FLEN，它由三个模块组成：关系学习模块、支持特定调整模块和查询推理模块。

    N-ary facts composed of a primary triple (head entity, relation, tail entity) and an arbitrary number of auxiliary attribute-value pairs, are prevalent in real-world knowledge graphs (KGs). Link prediction on n-ary facts is to predict a missing element in an n-ary fact. This helps populate and enrich KGs and further promotes numerous downstream applications. Previous studies usually require a substantial amount of high-quality data to understand the elements in n-ary facts. However, these studies overlook few-shot relations, which have limited labeled instances, yet are common in real-world scenarios. Thus, this paper introduces a new task, few-shot link prediction on n-ary facts. It aims to predict a missing entity in an n-ary fact with limited labeled instances. We further propose a model for Few-shot Link prEdict on N-ary facts, thus called FLEN, which consists of three modules: the relation learning, support-specific adjusting, and query inference modules. FLEN captures relation me
    
[^29]: 采用参数分解和滤波技术实现更好的图表征学习

    Towards Better Graph Representation Learning with Parameterized Decomposition & Filtering. (arXiv:2305.06102v1 [cs.LG])

    [http://arxiv.org/abs/2305.06102](http://arxiv.org/abs/2305.06102)

    本研究提出一个新的通用框架，采用参数化分解和滤波，统一了现有的GNN模型，提高了GNN的灵活性，缓解了现有模型的平滑和放大问题，并开发了简单但有效的模型，在各种图形学习任务中实现了显著的改进和计算效率。

    

    提出一种有效而灵活的矩阵来表示图形是一个基本的挑战，其已从多个角度进行了探索，例如，使用图傅里叶变换中的滤波。在本文中，我们从参数化分解和滤波的角度开发了一个新的通用框架，统一了许多现有的GNN模型，并展示了如何提高GNN的灵活性，同时减轻现有模型的平滑和放大问题。本质上，我们表明，具有可学习多项式滤波器的谱图卷积是这种表述的约束变体，放弃这些约束使我们的模型能够同时表达所需的分解和滤波。基于这个广义框架，我们开发的模型在实现上简单，但在各种图形学习任务中实现了显著的改进和计算效率。 代码可在 https://github.com/qslim/PDF 获得。

    Proposing an effective and flexible matrix to represent a graph is a fundamental challenge that has been explored from multiple perspectives, e.g., filtering in Graph Fourier Transforms. In this work, we develop a novel and general framework which unifies many existing GNN models from the view of parameterized decomposition and filtering, and show how it helps to enhance the flexibility of GNNs while alleviating the smoothness and amplification issues of existing models. Essentially, we show that the extensively studied spectral graph convolutions with learnable polynomial filters are constrained variants of this formulation, and releasing these constraints enables our model to express the desired decomposition and filtering simultaneously. Based on this generalized framework, we develop models that are simple in implementation but achieve significant improvements and computational efficiency on a variety of graph learning tasks. Code is available at https://github.com/qslim/PDF.
    
[^30]: PAI在SemEval-2023任务2中：利用外部实体信息进行命名实体识别的通用系统

    PAI at SemEval-2023 Task 2: A Universal System for Named Entity Recognition with External Entity Information. (arXiv:2305.06099v1 [cs.CL])

    [http://arxiv.org/abs/2305.06099](http://arxiv.org/abs/2305.06099)

    PAI团队提出了一种利用维基百科等外部实体信息的通用命名实体识别系统，在SemEval-2023任务2中表现出色，共赢得了7个奖项。

    

    MultiCoNER II任务旨在在低文本情境和存在拼写错误和错别字等噪音场景下，检测多种语言的复杂、模糊和细粒度命名实体。该任务由于上下文信息的缺乏、实体的高粒度（高达33种类）以及噪音数据的干扰而具有重要的挑战性。为了应对这些问题，我们的团队PAI提出了一种通用的命名实体识别系统，该系统集成了外部实体信息以提高性能。具体而言，我们的系统从知识库（即维基百科）中检索给定文本的实体属性，然后将实体信息与输入句子连接起来，将其馈入基于Transformer的模型。最终，我们的系统在13个轨道中赢得了2个一等奖，4个二等奖和1个三等奖。该系统的代码公开可供使用，网址为\url{https://github.com/diqiuzhuanzhuan/semeval-2023}。

    The MultiCoNER II task aims to detect complex, ambiguous, and fine-grained named entities in low-context situations and noisy scenarios like the presence of spelling mistakes and typos for multiple languages. The task poses significant challenges due to the scarcity of contextual information, the high granularity of the entities(up to 33 classes), and the interference of noisy data. To address these issues, our team {\bf PAI} proposes a universal Named Entity Recognition (NER) system that integrates external entity information to improve performance. Specifically, our system retrieves entities with properties from the knowledge base (i.e. Wikipedia) for a given text, then concatenates entity information with the input sentence and feeds it into Transformer-based models. Finally, our system wins 2 first places, 4 second places, and 1 third place out of 13 tracks. The code is publicly available at \url{https://github.com/diqiuzhuanzhuan/semeval-2023}.
    
[^31]: 基于目的驱动知识图谱建立可互操作的电子健康档案

    Building Interoperable Electronic Health Records as Purpose-Driven Knowledge Graphs. (arXiv:2305.06088v1 [cs.AI])

    [http://arxiv.org/abs/2305.06088](http://arxiv.org/abs/2305.06088)

    提出了一种名为iTelos的集成方法，该方法使用目的驱动的知识图谱来构建可互操作的电子健康记录。其中关键思想是数据级别和模式级别应独立开发，允许最大限度地重用先前的知识，并通过能力查询来规范需要的功能。该方法已在eHealth领域实施并通过真实案例评估，显示了开发时间和成本的显著降低。

    

    在构建新应用程序时，我们越来越需要重用和整合已有知识。然而，实际情况是，这些先前的知识几乎不可能直接重用。这在eHealth等领域尤其如此，这些领域已经付出了大量的努力来开发高质量的标准和参考本体，例如FHIR。本文提出了一种集成方法，称为iTelos，该方法支持数据和知识的重用，以构建可互操作的电子健康记录（iEHR）。关键思想是应用程序的数据级别和模式级别应该独立开发，从而在满足需要的前提下最大限度地灵活重用先前的知识，这些需求被规范化为能力查询。本文利用预先定义的目的来实现这种直觉，这个目的被用于驱动特定领域中基于目的的知识图谱（PD-KG）的开发。iTelos方法包括七个步骤，涉及目标的定义、要求的收集、现有标准和知识源的识别、异构数据到PD-KG的集成、PD-KG能力查询的注释、基于能力需求的推理机制的实现以及对iEHR模型与参考用例的验证。该方法已在eHealth领域实施，重用了几种标准和参考本体，包括FHIR和SNOMED-CT，并通过一个真实的案例研究进行了评估，显示出了在确保符合相关法规和质量标准的情况下，开发时间和成本的显著降低。

    When building a new application we are increasingly confronted with the need of reusing and integrating pre-existing knowledge. Nevertheless, it is a fact that this prior knowledge is virtually impossible to reuse as-is. This is true also in domains, e.g., eHealth, where a lot of effort has been put into developing high-quality standards and reference ontologies, e.g. FHIR1. In this paper, we propose an integrated methodology, called iTelos, which enables data and knowledge reuse towards the construction of Interoperable Electronic Health Records (iEHR). The key intuition is that the data level and the schema level of an application should be developed independently, thus allowing for maximum flexibility in the reuse of the prior knowledge, but under the overall guidance of the needs to be satisfied, formalized as competence queries. This intuition is implemented by codifying all the requirements, including those concerning reuse, as part of a purpose defined a priori, which is then us
    
[^32]: ChatGPT能力展示及其对AI研究的影响

    A Glimpse in ChatGPT Capabilities and its impact for AI research. (arXiv:2305.06087v1 [cs.AI])

    [http://arxiv.org/abs/2305.06087](http://arxiv.org/abs/2305.06087)

    ChatGPT展示了LLMs的强大能力，但这些模型的训练和运行需要巨大的计算资源和高昂的成本，预计会给AI研究带来重大影响。

    

    大型语言模型（LLMs）最近在人工智能（AI）研究领域成为热门话题。像Google、亚马逊、Facebook、特斯拉和苹果（GAFA）这样的公司正在大力发展这些模型。这些模型会使用海量的数据进行训练，可用于各种任务，包括语言翻译、文章生成和问答系统。然而，训练和运行这些模型所需的计算资源非常巨大，而硬件和电力的成本可能限制了那些没有GAFA资金和资源的研究实验室。本文将研究LLMs对AI研究的影响，重点关注GPT3.5/ChatGPT3.4，并给出使用这些模型进行研究的一些示例。

    Large language models (LLMs) have recently become a popular topic in the field of Artificial Intelligence (AI) research, with companies such as Google, Amazon, Facebook, Amazon, Tesla, and Apple (GAFA) investing heavily in their development. These models are trained on massive amounts of data and can be used for a wide range of tasks, including language translation, text generation, and question answering. However, the computational resources required to train and run these models are substantial, and the cost of hardware and electricity can be prohibitive for research labs that do not have the funding and resources of the GAFA. In this paper, we will examine the impact of LLMs on AI research. The pace at which such models are generated as well as the range of domains covered is an indication of the trend which not only the public but also the scientific community is currently experiencing. We give some examples on how to use such models in research by focusing on GPT3.5/ChatGPT3.4 and
    
[^33]: 有限精度采样下的赌博机最优臂识别问题研究

    Best Arm Identification in Bandits with Limited Precision Sampling. (arXiv:2305.06082v1 [cs.LG])

    [http://arxiv.org/abs/2305.06082](http://arxiv.org/abs/2305.06082)

    本文研究了在有限精度下采样的多臂赌博机问题，提出了一种修改的跟踪算法来处理最优分配的非唯一性，并证明了其渐进最优性。

    

    本文研究了一种多臂赌博机问题的变体，在该问题中，学习者在选择臂时有限的精度。学习者只能通过特定的探索组合（即所谓的箱子）采样臂。具体而言，在每个采样时刻，学习者选择一个箱子，然后根据箱子特定的概率分布拉动臂，揭示被拉动的臂及其瞬时收益，其目标是通过最小化期望停止时间来找到最佳臂，而误差概率受到上限约束。

    We study best arm identification in a variant of the multi-armed bandit problem where the learner has limited precision in arm selection. The learner can only sample arms via certain exploration bundles, which we refer to as boxes. In particular, at each sampling epoch, the learner selects a box, which in turn causes an arm to get pulled as per a box-specific probability distribution. The pulled arm and its instantaneous reward are revealed to the learner, whose goal is to find the best arm by minimising the expected stopping time, subject to an upper bound on the error probability. We present an asymptotic lower bound on the expected stopping time, which holds as the error probability vanishes. We show that the optimal allocation suggested by the lower bound is, in general, non-unique and therefore challenging to track. We propose a modified tracking-based algorithm to handle non-unique optimal allocations, and demonstrate that it is asymptotically optimal. We also present non-asympto
    
[^34]: 视觉调整

    Visual Tuning. (arXiv:2305.06061v1 [cs.CV])

    [http://arxiv.org/abs/2305.06061](http://arxiv.org/abs/2305.06061)

    本文综述了视觉调整的发展与现状，将近期的视觉调整技术分为五类，包括提示调整、适配器调整、参数翻译、紧凑调整和模块调整，并提出了未来研究方向。

    

    对视觉模型进行微调已被广泛证明在许多下游视觉任务中具有有前途的表现。随着预训练视觉基础模型的惊人发展，视觉调整跳出了标准的模式操作，即微调整个预训练模型或仅微调完全连接层。相反，近期的进展可以通过更新更少的参数实现比全面微调整个预训练参数更优异的表现，使边缘设备和下游应用程序可以重复使用部署在云端的日益庞大的基础模型。为了帮助研究人员全面了解视觉调整的全貌和未来方向，本综述描绘了大量的近期研究作品，提供了现有工作和模型系统和全面的概述。具体而言，它提供了视觉调整的详细背景，并将最近的视觉调整技术分为五组：提示调整、适配器调整、参数翻译、紧凑调整和模块调整。本文还强调了当前视觉调整技术的限制和挑战，并提出了几个未来研究方向。

    Fine-tuning visual models has been widely shown promising performance on many downstream visual tasks. With the surprising development of pre-trained visual foundation models, visual tuning jumped out of the standard modus operandi that fine-tunes the whole pre-trained model or just the fully connected layer. Instead, recent advances can achieve superior performance than full-tuning the whole pre-trained parameters by updating far fewer parameters, enabling edge devices and downstream applications to reuse the increasingly large foundation models deployed on the cloud. With the aim of helping researchers get the full picture and future directions of visual tuning, this survey characterizes a large and thoughtful selection of recent works, providing a systematic and comprehensive overview of existing work and models. Specifically, it provides a detailed background of visual tuning and categorizes recent visual tuning techniques into five groups: prompt tuning, adapter tuning, parameter 
    
[^35]: 使用指数级别的少量变分参数的张量网络压缩神经网络

    Compressing neural network by tensor network with exponentially fewer variational parameters. (arXiv:2305.06058v1 [cs.LG])

    [http://arxiv.org/abs/2305.06058](http://arxiv.org/abs/2305.06058)

    本文提出了一种通用的压缩方案，将神经网络的可变参数编码为多层张量网络，明显减少了可变参数的数量，并在多个神经网络和数据集上表现出了卓越的压缩性能，以VGG-16的测试精度提高为例。

    

    为了解决神经网络（NN）所包含的巨大可变的参数问题，本文提出了一种将这些参数 encoding 为多层张量网络（TN）的压缩方案。这种方案演示了出色的压缩性能，超过了以浅层张量网络为基础的现有最先进方法。例如，VGG-16中的3个卷积层的大约1000万参数被压缩到具有仅632个参数的TN中，而在CIFAR-10上的测试准确性令人惊喜地提高了81.14％。

    Neural network (NN) designed for challenging machine learning tasks is in general a highly nonlinear mapping that contains massive variational parameters. High complexity of NN, if unbounded or unconstrained, might unpredictably cause severe issues including over-fitting, loss of generalization power, and unbearable cost of hardware. In this work, we propose a general compression scheme that significantly reduces the variational parameters of NN by encoding them to multi-layer tensor networks (TN's) that contain exponentially-fewer free parameters. Superior compression performance of our scheme is demonstrated on several widely-recognized NN's (FC-2, LeNet-5, and VGG-16) and datasets (MNIST and CIFAR-10), surpassing the state-of-the-art method based on shallow tensor networks. For instance, about 10 million parameters in the three convolutional layers of VGG-16 are compressed in TN's with just $632$ parameters, while the testing accuracy on CIFAR-10 is surprisingly improved from $81.14
    
[^36]: 搜索UGLE真相：无监督GNN学习环境的调查

    Search for the UGLE Truth: An Investigation into Unsupervised GNN Learning Environments. (arXiv:2305.06026v1 [cs.LG])

    [http://arxiv.org/abs/2305.06026](http://arxiv.org/abs/2305.06026)

    本文提出了一种GNN学习环境下的社区检测算法比较框架，包括数据集和评估指标，以解决目前文献中对于基于GNN的社区检测缺乏公平且严谨评估的问题。

    

    图神经网络 (GNN) 是任何机器学习任务中的一个重要工具，因为它们能够学习图结构上的函数，这是一种强大和表达性强的数据表示。社区检测是一种无监督任务，越来越多地使用GNN进行。利用节点特征的多维度与图的连接性对图中的节点进行聚类，对从社交网络到基因组学的真实世界任务有许多应用。不幸的是，目前文献中缺乏公平且严谨评估基于GNN的社区检测的充分基准环境，从而可能阻碍这一新兴领域的进展。我们观察到这种情况下的特定困难是模糊的超参数调整环境与性能和评估数据集的冲突指标。在这项工作中，我们提出和评估了框架，用于在GNN学习环境中进行一致的社区检测算法比较。我们提供了一个基准数据集，并提出了评估指标，反映了检测到的社区的内在质量以及聚类的准确性。

    Graph Neural Networks (GNNs) are a pertinent tool for any machine learning task due to their ability to learn functions over graph structures, a powerful and expressive data representation. The detection of communities, an unsupervised task has increasingly been performed with GNNs. Clustering nodes in a graph using the multi-dimensionality of node features with the connectivity of the graph has many applications to real world tasks from social networks to genomics. Unfortunately, there is currently a gap in the literature with no established sufficient benchmarking environment for fairly and rigorously evaluating GNN based community detection, thereby potentially impeding progress in this nascent field. We observe the particular difficulties in this setting is the ambiguous hyperparameter tuning environments combined with conflicting metrics of performance and evaluation datasets. In this work, we propose and evaluate frameworks for the consistent comparisons of community detection al
    
[^37]: 带有环境不确定性的安全运动规划

    Safe motion planning with environment uncertainty. (arXiv:2305.06004v1 [cs.RO])

    [http://arxiv.org/abs/2305.06004](http://arxiv.org/abs/2305.06004)

    提出了一种在机器人状态和环境不确定性下进行安全运动规划的方法，其中通过贝叶斯滤波估计框架考虑了地标不确定性，通过对图搜索算法进行改进，引入了机器人动态感知的新视角。

    

    我们提出了一种在机器人状态和环境（障碍和地标位置）不确定性下进行安全运动规划的方法。为此，我们首先开发了一种方法，考虑机器人定位中的地标不确定性。现有的规划方法假定地标位置已经很好地知道，或者只有很小的不确定性。然而，这在实践中可能不成立。噪声传感器和不完美的运动使得来自环境特征估计的误差加剧。此外，环境中可能出现遮挡和动态物体，从而导致地标估计不准确。因此，不考虑这种不确定性可能会错误地定位机器人，导致低效的规划。我们的方法在贝叶斯滤波器估计框架中纳入了地标不确定性。我们还分析了考虑这种不确定性的影响，并勾勒了可以忽略它的情况。其次，我们通过对图搜索算法进行改进，引入了机器人动态感知的新视角来扩展最新技术的应用范围。

    We present an approach for safe motion planning under robot state and environment (obstacle and landmark location) uncertainties. To this end, we first develop an approach that accounts for the landmark uncertainties during robot localization. Existing planning approaches assume that the landmark locations are well known or are known with little uncertainty. However, this might not be true in practice. Noisy sensors and imperfect motions compound to the errors originating from the estimate of environment features. Moreover, possible occlusions and dynamic objects in the environment render imperfect landmark estimation. Consequently, not considering this uncertainty can wrongly localize the robot, leading to inefficient plans. Our approach thus incorporates the landmark uncertainty within the Bayes filter estimation framework. We also analyze the effect of considering this uncertainty and delineate the conditions under which it can be ignored. Second, we extend the state-of-the-art by c
    
[^38]: ANALOGYKB：使用百万规模知识库开启语言模型的类比推理能力。

    ANALOGYKB: Unlocking Analogical Reasoning of Language Models with A Million-scale Knowledge Base. (arXiv:2305.05994v1 [cs.CL])

    [http://arxiv.org/abs/2305.05994](http://arxiv.org/abs/2305.05994)

    本文提出了ANALOGYKB，一种使用百万规模知识库的类比推理方法，能够使语言模型在类比推理任务上取得比之前的最先进方法更好的结果。

    

    类比推理是人类的一项基本认知能力，然而，由于缺乏模型训练资源，目前的语言模型仍然难以在类比推理任务中达到人类的表现水平。本文提出了ANALOGYKB，这是一个百万规模的类比知识库，它由现有的知识图谱导出。ANALOGYKB从知识图谱中识别了两种类型的类比：1）相同关系的类比，可以直接从知识图谱中提取；2）类似关系的类比，则由大型语言模型（InstructGPT）启用的选择和过滤管道进行识别，再经过少量人工质量控制。在两个类比推理任务（类比识别和生成）的一系列数据集上的评估表明，ANALOGYKB成功地使语言模型取得了比之前的最先进方法更好的结果。

    Analogical reasoning is a fundamental cognitive ability of humans. However, current language models (LMs) still struggle to achieve human-like performance in analogical reasoning tasks due to a lack of resources for model training. In this work, we address this gap by proposing ANALOGYKB, a million-scale analogy knowledge base (KB) derived from existing knowledge graphs (KGs). ANALOGYKB identifies two types of analogies from the KGs: 1) analogies of the same relations, which can be directly extracted from the KGs, and 2) analogies of analogous relations, which are identified with a selection and filtering pipeline enabled by large LMs (InstructGPT), followed by minor human efforts for data quality control. Evaluations on a series of datasets of two analogical reasoning tasks (analogy recognition and generation) demonstrate that ANALOGYKB successfully enables LMs to achieve much better results than previous state-of-the-art methods.
    
[^39]: 从离散化时间事件序列中学习因果结构的结构Hawkes过程

    Structural Hawkes Processes for Learning Causal Structure from Discrete-Time Event Sequences. (arXiv:2305.05986v1 [cs.LG])

    [http://arxiv.org/abs/2305.05986](http://arxiv.org/abs/2305.05986)

    本文提出了一种叫做结构Hawkes过程的方法，通过利用瞬时效应学习离散时间事件序列中事件类型之间的因果结构。

    

    从离散时间事件序列中学习事件类型之间的因果结构是一个重要但具有挑战性的任务。现有的方法，如基于多元Hawkes过程的方法，大多都归结为学习所谓的Granger因果关系，它假定因果事件在效应事件之前严格发生。这种假设在低分辨率离散时间事件序列中往往是不可行的；而典型的离散Hawkes过程主要受到瞬时效应引起的可识别性问题的困扰，即由于低分辨率数据而同时发生的因果关系不会被Granger因果性所捕捉。在本文中，我们提出了一种结构Hawkes过程（SHPs），利用瞬时效应来学习离散事件序列中事件类型之间的因果结构。所提出的方法具有最小化-最大化似然函数的特点。

    Learning causal structure among event types from discrete-time event sequences is a particularly important but challenging task. Existing methods, such as the multivariate Hawkes processes based methods, mostly boil down to learning the so-called Granger causality which assumes that the cause event happens strictly prior to its effect event. Such an assumption is often untenable beyond applications, especially when dealing with discrete-time event sequences in low-resolution; and typical discrete Hawkes processes mainly suffer from identifiability issues raised by the instantaneous effect, i.e., the causal relationship that occurred simultaneously due to the low-resolution data will not be captured by Granger causality. In this work, we propose Structure Hawkes Processes (SHPs) that leverage the instantaneous effect for learning the causal structure among events type in discrete-time event sequence. The proposed method is featured with the minorization-maximization of the likelihood fu
    
[^40]: 多模态虚假信息解释性检测与逻辑推理

    Interpretable Multimodal Misinformation Detection with Logic Reasoning. (arXiv:2305.05964v1 [cs.MM])

    [http://arxiv.org/abs/2305.05964](http://arxiv.org/abs/2305.05964)

    本文提出了一种新的基于逻辑的多模态虚假信息检测神经模型，通过集成可解释性逻辑子句表达目标任务的推理过程，并使用神经表征参数化符号逻辑元素，从而便于自动生成和评估有意义的逻辑子句。此外，引入了五个元预测器来捕获虚假信息的基本模式。实验结果表明，该模型不仅性能显著优于当前方法，而且提供了透明且可解释的逻辑推理过程。

    

    在线社交平台上的多模态虚假信息由于多媒体内容的可信度和传播更容易而变得越来越重要。虽然现有的多模态检测方法已经达到了较高的性能，但缺乏解释性阻碍了这些系统的可靠性和实际部署。受到 NeuralSymbolic AI 的启发，该方法结合了神经网络的学习能力和符号学习的可解释性，我们提出了一种新的基于逻辑的多模态虚假信息检测神经模型，它集成了可解释性逻辑子句以表达目标任务的推理过程。为了使学习有效，我们使用神经表征来参数化符号逻辑元素，从而便于自动生成和评估有意义的逻辑子句。另外，为了使我们的框架可适用于各种虚假信息来源，我们在多模态融合网络中引入了五个元预测器来捕获虚假信息的基本模式。我们在实际的多模态虚假信息数据集上进行了大量实验，结果表明，我们的模型不仅显着优于现有方法，还为每个预测提供了透明且可解释的逻辑推理过程。

    Multimodal misinformation on online social platforms is becoming a critical concern due to increasing credibility and easier dissemination brought by multimedia content, compared to traditional text-only information. While existing multimodal detection approaches have achieved high performance, the lack of interpretability hinders these systems' reliability and practical deployment. Inspired by NeuralSymbolic AI which combines the learning ability of neural networks with the explainability of symbolic learning, we propose a novel logic-based neural model for multimodal misinformation detection which integrates interpretable logic clauses to express the reasoning process of the target task. To make learning effective, we parameterize symbolic logical elements using neural representations, which facilitate the automatic generation and evaluation of meaningful logic clauses. Additionally, to make our framework generalizable across diverse misinformation sources, we introduce five meta-pre
    
[^41]: 多路径Transformer更好：神经机器翻译的案例研究

    Multi-Path Transformer is Better: A Case Study on Neural Machine Translation. (arXiv:2305.05948v1 [cs.CL])

    [http://arxiv.org/abs/2305.05948](http://arxiv.org/abs/2305.05948)

    本文研究了多路径结构对Transformer模型的影响，通过在每个子层中添加归一化、产生更多特征的廉价操作和可学习的加权机制来融合从不同路径提取的特征，实验发现相同参数下浅层多路径模型可以实现与深层模型相似甚至更好的性能。

    

    多年来，机器学习模型的性能遵循参数尺寸为幂律分布的规律。为了考虑参数效率，最近的研究集中于增加模型深度而非宽度，以实现更好的性能。本文通过一个参数高效的多路径结构来研究模型宽度如何影响Transformer模型。为了更好地融合从不同路径提取的特征，我们在每个子层中添加了三个附加操作：每个路径末尾的归一化、产生更多特征的廉价操作以及可学习的加权机制，以灵活地融合所有特征。在12个WMT机器翻译任务上的大量实验表明，拥有相同数量参数的浅层多路径模型可以实现与深层模型相似甚至更好的性能，揭示了应更加关注多路径结构，并应在模型深度和宽度之间达成平衡，以训练更好的大规模机器学习模型。

    For years the model performance in machine learning obeyed a power-law relationship with the model size. For the consideration of parameter efficiency, recent studies focus on increasing model depth rather than width to achieve better performance. In this paper, we study how model width affects the Transformer model through a parameter-efficient multi-path structure. To better fuse features extracted from different paths, we add three additional operations to each sublayer: a normalization at the end of each path, a cheap operation to produce more features, and a learnable weighted mechanism to fuse all features flexibly. Extensive experiments on 12 WMT machine translation tasks show that, with the same number of parameters, the shallower multi-path model can achieve similar or even better performance than the deeper model. It reveals that we should pay more attention to the multi-path structure, and there should be a balance between the model depth and width to train a better large-sc
    
[^42]: V2X-Seq：一种用于车路协同感知和预测的大规模时序数据集

    V2X-Seq: A Large-Scale Sequential Dataset for Vehicle-Infrastructure Cooperative Perception and Forecasting. (arXiv:2305.05938v1 [cs.CV])

    [http://arxiv.org/abs/2305.05938](http://arxiv.org/abs/2305.05938)

    V2X-Seq是第一个大规模的时序V2X数据集，包括时序感知数据集和轨迹预测数据集。基于这个数据集，我们提出了三个新的车路协同自动驾驶任务。

    

    利用基础设施和车辆端信息跟踪和预测周围交通参与者的行为可以显著提高自动驾驶决策和安全性。然而，缺乏真实世界的时序数据集限制了这一领域的研究。为解决这个问题，我们介绍了V2X-Seq，第一个大规模时序V2X数据集，包括从自然景观中捕获的数据帧、轨迹、向量地图和交通灯。V2X-Seq包括两个部分：时序感知数据集，包括来自95个场景的超过15,000个帧，以及轨迹预测数据集，包含从28个交叉口区域捕获的约80,000个基础设施视图场景，80,000个车辆视图场景和50,000个协同视图场景，涵盖了672小时的数据。基于V2X-Seq，我们引入了三个新的车路协同自动驾驶任务：VIC 3D跟踪，在线VIC预测和多模VIC预测。

    Utilizing infrastructure and vehicle-side information to track and forecast the behaviors of surrounding traffic participants can significantly improve decision-making and safety in autonomous driving. However, the lack of real-world sequential datasets limits research in this area. To address this issue, we introduce V2X-Seq, the first large-scale sequential V2X dataset, which includes data frames, trajectories, vector maps, and traffic lights captured from natural scenery. V2X-Seq comprises two parts: the sequential perception dataset, which includes more than 15,000 frames captured from 95 scenarios, and the trajectory forecasting dataset, which contains about 80,000 infrastructure-view scenarios, 80,000 vehicle-view scenarios, and 50,000 cooperative-view scenarios captured from 28 intersections' areas, covering 672 hours of data. Based on V2X-Seq, we introduce three new tasks for vehicle-infrastructure cooperative (VIC) autonomous driving: VIC3D Tracking, Online-VIC Forecasting, an
    
[^43]: 文本引导下的高清一致纹理模型

    Text-guided High-definition Consistency Texture Model. (arXiv:2305.05901v1 [cs.CV])

    [http://arxiv.org/abs/2305.05901](http://arxiv.org/abs/2305.05901)

    该论文介绍了一种名为 HCTM 的方法，它可以根据文本提示为 3D 网格生成高清晰度和一致的纹理。该方法结合预训练深度到图像扩散模型和参数高效微调方法，利用多扩散策略生成高分辨率和一致的结果，并提出了一种防止噪声出现的策略。

    

    随着深度到图像扩散模型的出现，逼真纹理的文本引导生成、编辑和转移不再困难。然而，由于预训练扩散模型的限制，它们只能创建低分辨率、不一致的纹理。为了解决这个问题，我们提出了一种新的方法：高清一致纹理模型（HCTM），它可以根据文本提示为 3D 网格生成高清晰度和一致的纹理。我们利用预训练的深度到图像扩散模型根据文本提示和深度图生成单视点结果，利用参数高效微调方法对扩散模型进行微调，以快速学习所生成结果的风格，并采用多扩散策略从不同视点产生高分辨率和一致的结果。此外，我们提出了一种策略，防止由反向传播引起的纹理上出现噪声。

    With the advent of depth-to-image diffusion models, text-guided generation, editing, and transfer of realistic textures are no longer difficult. However, due to the limitations of pre-trained diffusion models, they can only create low-resolution, inconsistent textures. To address this issue, we present the High-definition Consistency Texture Model (HCTM), a novel method that can generate high-definition and consistent textures for 3D meshes according to the text prompts. We achieve this by leveraging a pre-trained depth-to-image diffusion model to generate single viewpoint results based on the text prompt and a depth map. We fine-tune the diffusion model with Parameter-Efficient Fine-Tuning to quickly learn the style of the generated result, and apply the multi-diffusion strategy to produce high-resolution and consistent results from different viewpoints. Furthermore, we propose a strategy that prevents the appearance of noise on the textures caused by backpropagation. Our proposed app
    
[^44]: 基于人格混合的尖峰演员网络在高效多方协作中的应用

    Mixture of personality improved Spiking actor network for efficient multi-agent cooperation. (arXiv:2305.05898v1 [cs.AI])

    [http://arxiv.org/abs/2305.05898](http://arxiv.org/abs/2305.05898)

    本文提出了一种基于人格混合的尖峰演员网络，通过行列式点过程和动态尖峰神经元的融合实现了多方协作中的高效强化学习。

    

    在多智能体强化学习领域，自适应的人与智能体以及智能体之间的协作变得越来越重要。本文提出了一种名为MoP的混合人格改进尖峰演员网络。该网络使用行列式点过程来模拟不同类型人格的复杂组合和整合，并将动态和尖峰神经元融入到SAN中以实现高效的强化学习。在评估中，该方法在Overcooked基准测试中表现出色。

    Adaptive human-agent and agent-agent cooperation are becoming more and more critical in the research area of multi-agent reinforcement learning (MARL), where remarked progress has been made with the help of deep neural networks. However, many established algorithms can only perform well during the learning paradigm but exhibit poor generalization during cooperation with other unseen partners. The personality theory in cognitive psychology describes that humans can well handle the above cooperation challenge by predicting others' personalities first and then their complex actions. Inspired by this two-step psychology theory, we propose a biologically plausible mixture of personality (MoP) improved spiking actor network (SAN), whereby a determinantal point process is used to simulate the complex formation and integration of different types of personality in MoP, and dynamic and spiking neurons are incorporated into the SAN for the efficient reinforcement learning. The benchmark Overcooke
    
[^45]: ChatGPT和GPT-4是否是金融文本分析的通用求解器？对几种典型任务进行检验。

    Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text Analytics? An Examination on Several Typical Tasks. (arXiv:2305.05862v1 [cs.CL])

    [http://arxiv.org/abs/2305.05862](http://arxiv.org/abs/2305.05862)

    本研究探讨了ChatGPT和GPT-4在金融文本分析任务中的潜力，结果显示它们在数值推理上表现出色但在需要领域特定知识的任务上表现不佳。

    

    最近的大型语言模型如ChatGPT和GPT-4引起了人们的广泛关注，因为它们能够生成高质量的对话回应。尽管ChatGPT和GPT-4在通用文本语料库上经过了广泛的测试，展示了它们令人印象深刻的能力，但还没有对金融语料库进行研究。本研究旨在通过在零样本或少样本情况下考察ChatGPT和GPT-4作为典型金融文本分析问题求解器的潜力来弥补这一差距。具体而言，我们评估了它们在五个不同的金融文本数据集上进行的四项代表性任务的能力。初步研究表明，ChatGPT和GPT-4在需要领域特定知识的金融命名实体识别（NER）和情感分析等任务上表现不佳，而在数值推理任务上表现出色。我们报告了当前版本ChatGPT和GPT-4的优点和局限性，并将它们与现有技术进行了比较。

    The most recent large language models such as ChatGPT and GPT-4 have garnered significant attention, as they are capable of generating high-quality responses to human input. Despite the extensive testing of ChatGPT and GPT-4 on generic text corpora, showcasing their impressive capabilities, a study focusing on financial corpora has not been conducted. In this study, we aim to bridge this gap by examining the potential of ChatGPT and GPT-4 as a solver for typical financial text analytic problems in the zero-shot or few-shot setting. Specifically, we assess their capabilities on four representative tasks over five distinct financial textual datasets. The preliminary study shows that ChatGPT and GPT-4 struggle on tasks such as financial named entity recognition (NER) and sentiment analysis, where domain-specific knowledge is required, while they excel in numerical reasoning tasks. We report both the strengths and limitations of the current versions of ChatGPT and GPT-4, comparing them to 
    
[^46]: 基于双意图增强图神经网络的会话新品推荐

    Dual Intent Enhanced Graph Neural Network for Session-based New Item Recommendation. (arXiv:2305.05848v1 [cs.IR])

    [http://arxiv.org/abs/2305.05848](http://arxiv.org/abs/2305.05848)

    本文提出了一种基于双意图增强的图神经网络，用于解决基于历史会话的推荐系统中无法推荐新产品的问题，并在实验中证明其有效性。

    

    推荐系统是各个领域，例如电子商务、电子学习和流媒体等中不可或缺的部分。目前，用于会话推荐的图神经网络通常只能推荐用户历史会话中已存在的项目。因此这些图神经网络在推荐用户从未与之交互的项目（新产品）时面临信息封闭的问题。因此，有必要向用户推荐新的产品。由于新产品与用户之间没有交互，因此在构建基于图神经网络的会话推荐系统时，我们不能将新产品包括在会话图中。因此，使用基于GNN（图神经网络）的方法向用户推荐新产品具有挑战性。为了解决这个问题，我们提出了一种双意图增强图神经网络。由于新的产品与历史会话没有绑定关系，模型学习如何捕捉用户和项目的意图。具体而言，我们的模型引入了双意图图神经网络，一张图来捕获项目意图的表示，另一张图来捕获用户意图的表示。该模型将历史会话与用户和项目双重意图表示相结合，用于推荐。两个真实数据集上的实验结果证明了我们提出的方法的有效性。

    Recommender systems are essential to various fields, e.g., e-commerce, e-learning, and streaming media. At present, graph neural networks (GNNs) for session-based recommendations normally can only recommend items existing in users' historical sessions. As a result, these GNNs have difficulty recommending items that users have never interacted with (new items), which leads to a phenomenon of information cocoon. Therefore, it is necessary to recommend new items to users. As there is no interaction between new items and users, we cannot include new items when building session graphs for GNN session-based recommender systems. Thus, it is challenging to recommend new items for users when using GNN-based methods. We regard this challenge as '\textbf{G}NN \textbf{S}ession-based \textbf{N}ew \textbf{I}tem \textbf{R}ecommendation (GSNIR)'. To solve this problem, we propose a dual-intent enhanced graph neural network for it. Due to the fact that new items are not tied to historical sessions, the
    
[^47]: 画出未来：将条件控制技术应用于文本到视频模型中

    Sketching the Future (STF): Applying Conditional Control Techniques to Text-to-Video Models. (arXiv:2305.05845v1 [cs.CV])

    [http://arxiv.org/abs/2305.05845](http://arxiv.org/abs/2305.05845)

    本文提出一种将零样本文本到视频生成与ControlNet相结合的新颖方法，利用插值帧视频作为控制技术生成高质量且一致的视频内容，更准确地符合用户对视频中主体运动的意图。

    

    视频内容的爆炸式增长对于生成新的视频内容需要高效灵活的神经网络方法。本文提出了一种新颖的方法，将零样本文本到视频生成与ControlNet相结合，从而改善模型的输出。我们的方法将多个草图帧作为输入，并生成符合这些帧流程的视频输出，基于文本到视频零架构，结合ControlNet以启用额外的输入条件。通过首先插值输入草图之间的帧，然后使用新的插值帧视频作为控制技术来运行文本到视频零，我们利用了零样本文本到视频生成和ControlNet提供的强大控制的优势。实验证明，我们的方法擅长生成高质量，非常一致的视频内容，更准确地与用户对视频中主体运动的意图相吻合。

    The proliferation of video content demands efficient and flexible neural network based approaches for generating new video content. In this paper, we propose a novel approach that combines zero-shot text-to-video generation with ControlNet to improve the output of these models. Our method takes multiple sketched frames as input and generates video output that matches the flow of these frames, building upon the Text-to-Video Zero architecture and incorporating ControlNet to enable additional input conditions. By first interpolating frames between the inputted sketches and then running Text-to-Video Zero using the new interpolated frames video as the control technique, we leverage the benefits of both zero-shot text-to-video generation and the robust control provided by ControlNet. Experiments demonstrate that our method excels at producing high-quality and remarkably consistent video content that more accurately aligns with the user's intended motion for the subject within the video. We
    
[^48]: 实现因果关系解释的多样性：一项综述和讨论

    Achieving Diversity in Counterfactual Explanations: a Review and Discussion. (arXiv:2305.05840v1 [cs.AI])

    [http://arxiv.org/abs/2305.05840](http://arxiv.org/abs/2305.05840)

    本篇论文综述了因果关系解释中多样性的概念及其定义，提出了生成多种因果关系例子以解释一个预测结果的方法，探讨了这种方法的优点和局限性。

    

    在可解释的人工智能领域中，因果关系例子通过指出更改实例以更改其预测的修改来解释受过训练的决策模型的预测结果。这些因果关系例子通常定义为解决一个优化问题的解决方案，其中代价函数结合了几个衡量满足用户需求的良好解释的标准。可以考虑多种这样适当的性质，因为用户需求通常是未知的，而且不同用户之间也有所不同；它们的选择和规范化是困难的。为了解决这个问题，一些方法提出生成一组不同的因果关系例子来解释一个预测结果，而不是单个的。本文提出了对这个多样性概念的许多、有时相互矛盾的定义的综述。它讨论了它们的基本原则、假设、优势和局限性。此外，它介绍了一些关于这个特定研究主题的最新工作和未来发展方向。

    In the field of Explainable Artificial Intelligence (XAI), counterfactual examples explain to a user the predictions of a trained decision model by indicating the modifications to be made to the instance so as to change its associated prediction. These counterfactual examples are generally defined as solutions to an optimization problem whose cost function combines several criteria that quantify desiderata for a good explanation meeting user needs. A large variety of such appropriate properties can be considered, as the user needs are generally unknown and differ from one user to another; their selection and formalization is difficult. To circumvent this issue, several approaches propose to generate, rather than a single one, a set of diverse counterfactual examples to explain a prediction. This paper proposes a review of the numerous, sometimes conflicting, definitions that have been proposed for this notion of diversity. It discusses their underlying principles as well as the hypothe
    
[^49]: 因果信息分离：为抗分布转移设计代理特征

    Causal Information Splitting: Engineering Proxy Features for Robustness to Distribution Shifts. (arXiv:2305.05832v1 [cs.LG])

    [http://arxiv.org/abs/2305.05832](http://arxiv.org/abs/2305.05832)

    本文提出了利用因果机制在不同环境下保持不变的直觉来主动准备的代理特征选择和工程技术，用以应对统计预测模型在分布转移情况下的稳定性问题。

    

    统计预测模型通常是在与最终使用情况不同的概率分布中进行训练的。为了预测分布转移，有一种方法是利用因果机制在不同环境下保持不变的直觉来主动准备。本文针对一个具有挑战性的场景，其中目标的因果和反因果变量都是未被观察到的。利用信息论，我们为下游观测变量开发了特征选择和工程技术，这些变量充当代理。我们选择有助于建立稳定模型的代理，并使用辅助训练任务从代理中提取增强稳定性的信息。我们在合成数据和真实数据上展示了我们技术的有效性。

    Statistical prediction models are often trained on data that is drawn from different probability distributions than their eventual use cases. One approach to proactively prepare for these shifts harnesses the intuition that causal mechanisms should remain invariant between environments. Here we focus on a challenging setting in which the causal and anticausal variables of the target are unobserved. Leaning on information theory, we develop feature selection and engineering techniques for the observed downstream variables that act as proxies. We identify proxies that help to build stable models and moreover utilize auxiliary training tasks to extract stability-enhancing information from proxies. We demonstrate the effectiveness of our techniques on synthetic and real data.
    
[^50]: 环境约束下的情境依赖性沟通

    Context-dependent communication under environmental constraints. (arXiv:2305.05821v1 [cs.AI])

    [http://arxiv.org/abs/2305.05821](http://arxiv.org/abs/2305.05821)

    本文研究了在压缩词汇量的情况下，如何利用环境压力促进情境依赖性沟通的出现，并研究了在接收者无法处理歧义的情况下，发送者如何利用环境的制约因素实现沟通。

    

    存在大量的证据表明，现实世界中的沟通不能简单地通过发送具有独立于情境意义的信号来实现。本文以经典的Lewis(1969)信号模型的变体为基础，探讨在情境化场景下产生情境依赖性沟通的条件。具体而言，我们证明了在最小化词汇量的压力下，这种沟通的出现是足够的。同时，我们研究了可能使符号含义得到情境区分的环境条件和认知能力。我们展示了在接受者的指代选择受到环境限制的情况下，发送者可以单方面地利用这些限制，而无需接收者具有澄清歧义的能力。与常见的假设一致，发送者对情境的意识似乎是需要的。我们认为，情境依赖性沟通是一种多层次的情境化现象，其受环境特性的影响至关重要。

    There is significant evidence that real-world communication cannot be reduced to sending signals with context-independent meaning. In this work, based on a variant of the classical Lewis (1969) signaling model, we explore the conditions for the emergence of context-dependent communication in a situated scenario. In particular, we demonstrate that pressure to minimise the vocabulary size is sufficient for such emergence. At the same time, we study the environmental conditions and cognitive capabilities that enable contextual disambiguation of symbol meanings. We show that environmental constraints on the receiver's referent choice can be unilaterally exploited by the sender, without disambiguation capabilities on the receiver's end. Consistent with common assumptions, the sender's awareness of the context appears to be required for contextual communication. We suggest that context-dependent communication is a situated multilayered phenomenon, crucially influenced by environment properti
    
[^51]: 利用生成式预训练变换器辅助自动生成优化模型的模型生成器

    Towards an Automatic Optimisation Model Generator Assisted with Generative Pre-trained Transformer. (arXiv:2305.05811v1 [cs.NE])

    [http://arxiv.org/abs/2305.05811](http://arxiv.org/abs/2305.05811)

    本文提出了一个利用生成式预训练变换器辅助自动生成优化模型的框架，并进行了实验验证，结果表明，使用语言模型生成优化模型是可行的。

    

    本文提出了一个使用预训练生成式变换器来生成优化模型的框架。该框架涉及指定优化模型应具有的特征，并使用语言模型生成模型的初始版本。然后，模型进行测试和验证，如果包含构建错误，则触发自动编辑过程。使用MiniZinc作为目标语言和两个GPT-3.5语言模型进行了实验来进行生成和调试。结果表明，使用语言模型生成优化模型是可行的，有些模型满足所需的规格，而其他模型需要进一步细化。该研究为利用语言模型来建模优化问题提供了有希望的证据，并提出了未来研究的方向。

    This article presents a framework for generating optimisation models using a pre-trained generative transformer. The framework involves specifying the features that the optimisation model should have and using a language model to generate an initial version of the model. The model is then tested and validated, and if it contains build errors, an automatic edition process is triggered. An experiment was performed using MiniZinc as the target language and two GPT-3.5 language models for generation and debugging. The results show that the use of language models for the generation of optimisation models is feasible, with some models satisfying the requested specifications, while others require further refinement. The study provides promising evidence for the use of language models in the modelling of optimisation problems and suggests avenues for future research.
    
[^52]: 即使很小的相关性和多样性变化也会导致数据集偏差问题

    Even Small Correlation and Diversity Shifts Pose Dataset-Bias Issues. (arXiv:2305.05807v1 [cs.CV])

    [http://arxiv.org/abs/2305.05807](http://arxiv.org/abs/2305.05807)

    本文研究了数据集中的分布变化对深度学习模型的影响，并提出了一个综合协议来分析多样性变化和相关性变化。使用皮肤癌分析分类问题的实例，发现模型不仅会学习和传播相关性变化，而且可能会使用错误的特征。

    

    分布变化在实际数据集中很常见，会影响深度学习模型的性能和可靠性。本文研究了两种类型的分布变化：多样性变化和相关性变化。我们提出了一个综合协议，使用同时存在这两种变化的数据集来分析它们。最后，我们将我们的方法应用于一个真实的皮肤癌分析分类问题中，使用了超出数据集和专门的偏差注释。我们的协议揭示了三个发现：1）模型即使进行了低偏差训练也会学习并传播相关性变化，这可能会累积和结合难以解释的弱偏差的风险；2）模型在高、低偏差情况下可以学习到稳健的特征，但是如果测试样本有错误的特征它们可能会使用这些特征。

    Distribution shifts are common in real-world datasets and can affect the performance and reliability of deep learning models. In this paper, we study two types of distribution shifts: diversity shifts, which occur when test samples exhibit patterns unseen during training, and correlation shifts, which occur when test data present a different correlation between seen invariant and spurious features. We propose an integrated protocol to analyze both types of shifts using datasets where they co-exist in a controllable manner. Finally, we apply our approach to a real-world classification problem of skin cancer analysis, using out-of-distribution datasets and specialized bias annotations. Our protocol reveals three findings: 1) Models learn and propagate correlation shifts even with low-bias training; this poses a risk of accumulating and combining unaccountable weak biases; 2) Models learn robust features in highand low-bias scenarios but use spurious ones if test samples have them; this
    
[^53]: 基于Segment Anything Model (SAM)增强伪标签的弱监督语义分割

    Segment Anything Model (SAM) Enhanced Pseudo Labels for Weakly Supervised Semantic Segmentation. (arXiv:2305.05803v1 [cs.CV])

    [http://arxiv.org/abs/2305.05803](http://arxiv.org/abs/2305.05803)

    本论文提出了一种通过利用Segment Anything Model (SAM)增强Class Activation Maps (CAM)生成高质量伪标签的方法来解决弱监督语义分割中CAM的局部激活和虚假激活的限制问题。

    

    仅使用图像级别的监督的弱监督语义分割(WSSS)由于其与像素级注释相比的低成本而越来越受到关注。大多数现有方法依赖于类激活图(CAM)生成像素级的伪标签进行监督训练。然而，众所周知，CAM经常遭受局部激活的限制-只激活最具区分性的部分，而不是整个对象区域和虚假的激活-不必要地激活物体周围的背景。本研究引入了一种简单而有效的方法来解决这些限制，即利用最近发布的Segment Anything Model (SAM)增强CAM生成高质量的伪标签。SAM是一个分割基础模型，展示了将图像分割成段落的强零-shot能力，但缺乏这些区域的语义标签。为了解决这个问题，我们采用特定类别的伪标签作为信号来选择m。

    Weakly Supervised Semantic Segmentation (WSSS) with only image-level supervision has garnered increasing attention due to its low annotation cost compared to pixel-level annotation. Most existing methods rely on Class Activation Maps (CAM) to generate pixel-level pseudo labels for supervised training. However, it is well known that CAM often suffers from partial activation -- activating the most discriminative part instead of the entire object area, and false activation -- unnecessarily activating the background around the object. In this study, we introduce a simple yet effective approach to address these limitations by harnessing the recently released Segment Anything Model (SAM) to generate higher-quality pseudo labels with CAM. SAM is a segmentation foundation model that demonstrates strong zero-shot ability in partitioning images into segments but lacks semantic labels for these regions. To circumvent this, we employ pseudo labels for a specific class as the signal to select the m
    
[^54]: 降低现实策略优化中循环时间调整的代价

    Reducing the Cost of Cycle-Time Tuning for Real-World Policy Optimization. (arXiv:2305.05760v1 [cs.LG])

    [http://arxiv.org/abs/2305.05760](http://arxiv.org/abs/2305.05760)

    本研究提出了一种新方法，可基于周期时间设置超参数，使得PPO和SAC在广泛的循环时间范围内进行学习，同时实现了接近耗时的在线超参数调整获得的性能。

    

    连续时间强化学习任务通常使用固定周期时间的离散步骤进行操作。实践中需要为给定任务选择操作周期时间，一个重要问题是学习算法的超参数是否需要为每个周期时间重新调整，这对于现实世界的机器人来说是不可行的。在本文中，我们研究了两种策略梯度算法--PPO和SAC--在不同的周期时间下使用基线超参数值的情况。通过使用基线超参数在一个基准任务中展示这两种算法表现良好的情况，我们发现当选择不同于任务默认值的周期时间时，使用基线超参数的PPO无法学习。此外，当超参数用于每个周期时间时，基于基线的PPO和SAC表现均明显劣于它们的调整值。我们提出了一种基于周期时间设置这些超参数的新方法。在我们的仿真机器人运动任务实验中，我们的方法使得PPO和SAC在极其广泛的周期时间范围内进行学习，同时实现了接近于耗时的在线超参数调整获得的性能。

    Continuous-time reinforcement learning tasks commonly use discrete steps of fixed cycle times for actions. As practitioners need to choose the action-cycle time for a given task, a significant concern is whether the hyper-parameters of the learning algorithm need to be re-tuned for each choice of the cycle time, which is prohibitive for real-world robotics. In this work, we investigate the widely-used baseline hyper-parameter values of two policy gradient algorithms -- PPO and SAC -- across different cycle times. Using a benchmark task where the baseline hyper-parameters of both algorithms were shown to work well, we reveal that when a cycle time different than the task default is chosen, PPO with baseline hyper-parameters fails to learn. Moreover, both PPO and SAC with their baseline hyper-parameters perform substantially worse than their tuned values for each cycle time. We propose novel approaches for setting these hyper-parameters based on the cycle time. In our experiments on simu
    
[^55]: 排名和重新加权提高了组的分布鲁棒性

    Ranking & Reweighting Improves Group Distributional Robustness. (arXiv:2305.05759v1 [cs.LG])

    [http://arxiv.org/abs/2305.05759](http://arxiv.org/abs/2305.05759)

    本文提出了一种利用折扣累积增益（DCG）排序并加权处理训练数据以提高模型对低代表性组的鲁棒性的方法，实验证明其优于先前方法。

    

    最近的研究表明，通过经验风险最小化（ERM）进行标准训练可能会产生在平均精度上表现出色但在低代表性组上准确性较低的模型，这是由于表征中虚假特征的普遍存在所致。解决这个组鲁棒性问题的主要方法是在训练数据上最小化最坏的组误差（类似于极小值策略），希望它会在测试数据上有良好的泛化性能。然而，这种方法往往是次优的，尤其是当测试数据集中包含以前未见过的组时。本文受信息检索和Learning-to-Rank文献的启发，首先提出使用折扣累积增益（DCG）作为模型质量度量标准，以促进更好的超参数调整和模型选择。作为一种基于排序的度量标准，DCG加权多个性能较差的组（而不仅仅是考虑性能最差的组）。作为自然的下一步，我们基于这些结果提出了一种新的组重新加权方法，在训练期间鼓励模型集中于低代表性的组。在几个基准数据集上的实验证明，我们提出的方法优于先前的最先进方法，并显著提高了对组不平衡的鲁棒性。

    Recent work has shown that standard training via empirical risk minimization (ERM) can produce models that achieve high accuracy on average but low accuracy on underrepresented groups due to the prevalence of spurious features. A predominant approach to tackle this group robustness problem minimizes the worst group error (akin to a minimax strategy) on the training data, hoping it will generalize well on the testing data. However, this is often suboptimal, especially when the out-of-distribution (OOD) test data contains previously unseen groups. Inspired by ideas from the information retrieval and learning-to-rank literature, this paper first proposes to use Discounted Cumulative Gain (DCG) as a metric of model quality for facilitating better hyperparameter tuning and model selection. Being a ranking-based metric, DCG weights multiple poorly-performing groups (instead of considering just the group with the worst performance). As a natural next step, we build on our results to propose a
    
[^56]: 通过世界状态和文本指令提问的时间和问题：IGLU NLP挑战解决方案

    When and What to Ask Through World States and Text Instructions: IGLU NLP Challenge Solution. (arXiv:2305.05754v1 [cs.CL])

    [http://arxiv.org/abs/2305.05754](http://arxiv.org/abs/2305.05754)

    论文解决了在协作建筑任务中如何解决模棱两可的情况，从而提出了何时寻求澄清以及应该询问什么澄清问题这两个关键问题的解答方法。

    

    在协作任务中，有效的交流对于实现共同目标至关重要。其中一个任务是协作建筑，在这个任务中，建筑者必须相互通信，在诸如Minecraft之类的模拟环境中构建所需的结构。我们旨在开发一个智能建筑代理，根据用户对话建造结构。然而，在协作建筑中，建筑者可能会遇到难以解读的情况，因为信息和指令有限，导致模棱两可。在NeurIPS 2022竞赛的NLP任务中，我们回答了两个关键的研究问题，旨在填补这一空白：代理何时应该寻求澄清，应该询问什么澄清问题？我们通过两个子任务朝着这个目标迈进，一个是分类任务，一个是排序任务。对于分类任务，目标是根据当前的世界状态和对话历史确定代理是否应该寻求澄清。对于排序任务，目标是提供一份可能的澄清问题的排名列表。我们的方法结合了基于规则的启发式方法和机器学习模型，并在IGLU NLP挑战数据集上取得了竞争性的性能。

    In collaborative tasks, effective communication is crucial for achieving joint goals. One such task is collaborative building where builders must communicate with each other to construct desired structures in a simulated environment such as Minecraft. We aim to develop an intelligent builder agent to build structures based on user input through dialogue. However, in collaborative building, builders may encounter situations that are difficult to interpret based on the available information and instructions, leading to ambiguity. In the NeurIPS 2022 Competition NLP Task, we address two key research questions, with the goal of filling this gap: when should the agent ask for clarification, and what clarification questions should it ask? We move towards this target with two sub-tasks, a classification task and a ranking task. For the classification task, the goal is to determine whether the agent should ask for clarification based on the current world state and dialogue history. For the ran
    
[^57]: 深度神经网络硬件可靠性评估方法的系统文献综述

    A Systematic Literature Review on Hardware Reliability Assessment Methods for Deep Neural Networks. (arXiv:2305.05750v1 [cs.LG])

    [http://arxiv.org/abs/2305.05750](http://arxiv.org/abs/2305.05750)

    本文为深度神经网络硬件可靠性进行了系统文献综述，总结了现有的可靠性评估方法以及数据集和基准的评估，揭示了这一领域的研究空缺。

    

    人工智能（AI）和机器学习（ML）特别是由于其学习解决复杂问题的能力而被应用于各种应用程序中。过去十年中，机器学习的快速进展提出了由大量神经元和层组成的深度神经网络（DNN）。深度神经网络硬件加速器（DHA）用于将DNNs部署到目标应用程序中，同时在硬件故障/错误会导致灾难性后果的安全关键应用程序中也受益于DHA。因此，DNN的可靠性是研究的重要主题。近年来，已经发表了多项研究，以评估DNNs的可靠性。在这方面，已经提出了各种各样的可靠性评估方法，适用于各种平台和应用程序。因此，有必要总结现有技术以确定研究DNN的可靠性的研究中存在的差距。在这项工作中，我们进行了系统文献综述（SLR），以确定现有的DNN硬件可靠性评估方法。我们还回顾了现有的可用于DNN可靠性评估的数据集和基准。本研究的结果将帮助研究人员了解当前深度神经网络硬件可靠性评估方法的最新技术，同时也揭示了这一领域的遗漏空缺。

    Artificial Intelligence (AI) and, in particular, Machine Learning (ML) have emerged to be utilized in various applications due to their capability to learn how to solve complex problems. Over the last decade, rapid advances in ML have presented Deep Neural Networks (DNNs) consisting of a large number of neurons and layers. DNN Hardware Accelerators (DHAs) are leveraged to deploy DNNs in the target applications. Safety-critical applications, where hardware faults/errors would result in catastrophic consequences, also benefit from DHAs. Therefore, the reliability of DNNs is an essential subject of research. In recent years, several studies have been published accordingly to assess the reliability of DNNs. In this regard, various reliability assessment methods have been proposed on a variety of platforms and applications. Hence, there is a need to summarize the state of the art to identify the gaps in the study of the reliability of DNNs. In this work, we conduct a Systematic Literature R
    
[^58]: 基于图的方式降低参数化和加权MDP的复杂度

    Graph-Based Reductions for Parametric and Weighted MDPs. (arXiv:2305.05739v1 [cs.LO])

    [http://arxiv.org/abs/2305.05739](http://arxiv.org/abs/2305.05739)

    研究了参数化马尔科夫决策过程中加权可达性的降低复杂度问题，提出了一个多项式时间算法来计算我们所研究的马尔可夫链排序的等价类，并实现了两个规则来欠估计“永不更糟”的关系。

    

    我们研究了参数化马尔科夫决策过程中加权可达性的降低复杂度问题。即，我们说一个状态p永远不会比q更糟，如果对于多项式未知数的所有估值，从p到达的最大预期权重都比从q到达的最大预期权重大。在计算复杂度方面，我们确定了判断p是否永远不会比q更糟的coETR完全性。在积极方面，我们提供了一个多项式时间算法来计算我们所研究的马尔可夫链排序的等价类。此外，我们描述并实现了两个推理规则来欠估计“永不更糟”的关系，并且在实验中展示它可以用作大型马尔科夫决策过程分析的高效预处理步骤。

    We study the complexity of reductions for weighted reachability in parametric Markov decision processes. That is, we say a state p is never worse than q if for all valuations of the polynomial indeterminates it is the case that the maximal expected weight that can be reached from p is greater than the same value from q. In terms of computational complexity, we establish that determining whether p is never worse than q is coETR-complete. On the positive side, we give a polynomial-time algorithm to compute the equivalence classes of the order we study for Markov chains. Additionally, we describe and implement two inference rules to under-approximate the never-worse relation and empirically show that it can be used as an efficient preprocessing step for the analysis of large Markov decision processes.
    
[^59]: 遥感中的视觉语言模型：现状与未来趋势

    Vision-Language Models in Remote Sensing: Current Progress and Future Trends. (arXiv:2305.05726v1 [cs.CV])

    [http://arxiv.org/abs/2305.05726](http://arxiv.org/abs/2305.05726)

    本文介绍了遥感图像中应用视觉语言模型的现状及未来趋势，视觉语言模型可以推理图像中的底层语义，可以识别对象之间的关系及生成自然语言描述。

    

    论文介绍了视觉语言模型在遥感领域的应用现状和未来趋势。遥感领域中现有的人工智能研究主要集中在图像的视觉理解上，忽略了对象和它们之间关系的语义理解，而视觉语言模型的出现则填补了这一空缺。视觉语言模型可以通过图像及其相关的文字描述进行推理，深入理解其底层语义，比仅仅识别图像中的对象，能够推断出它们之间的关系，甚至生成自然语言描述。

    The remarkable achievements of ChatGPT and GPT-4 have sparked a wave of interest and research in the field of large language models for Artificial General Intelligence (AGI). These models provide us with intelligent solutions that are more similar to human thinking, enabling us to use general artificial intelligence to solve problems in various applications. However, in the field of remote sensing, the scientific literature on the implementation of AGI remains relatively scant. Existing AI-related research primarily focuses on visual understanding tasks while neglecting the semantic understanding of the objects and their relationships. This is where vision-language models excel, as they enable reasoning about images and their associated textual descriptions, allowing for a deeper understanding of the underlying semantics. Vision-language models can go beyond recognizing the objects in an image and can infer the relationships between them, as well as generate natural language descriptio
    
[^60]: CodeIE: 大型代码生成模型优于少样本信息提取器

    CodeIE: Large Code Generation Models are Better Few-Shot Information Extractors. (arXiv:2305.05711v1 [cs.CL])

    [http://arxiv.org/abs/2305.05711](http://arxiv.org/abs/2305.05711)

    CodeIE提出了使用代码生成模型（Code-LLMs）代替自然语言生成模型（NL-LLMs）对命名实体识别和关系抽取这类信息提取任务进行少样本学习，取得优于几个强基准高达4.5%的绝对精度改进。

    

    在大规模语言模型（LLMs）的预训练方面，已经表现出在许多自然语言处理任务上具有惊人的少样本学习能力。通常的做法是将任务重构为文本到文本的格式，以便自然语言的生成式LLMs（如GPT-3）可以被提示解决它。然而，使用NL-LLMs进行信息提取（IE）任务是不易的，因为IE任务的输出通常是结构化的，因此很难转换成纯文本。我们提出使用代码形式而非自然语言来表达结构化的输出，并利用代码生成LLMs（如Codex）来执行IE任务，特别是命名实体识别和关系抽取。与NL-LLMs相比，我们表明通过设计代码风格的提示和将这些IE任务更改为代码生成任务，Code-LLMs可以与这些IE任务很好地对齐。在七个基准测试上的实验结果表明，我们的方法在少样本学习环境下一直优于几个强基准，并取得了高达4.5%的绝对精度改进。

    Large language models (LLMs) pre-trained on massive corpora have demonstrated impressive few-shot learning ability on many NLP tasks. A common practice is to recast the task into a text-to-text format such that generative LLMs of natural language (NL-LLMs) like GPT-3 can be prompted to solve it. However, it is nontrivial to perform information extraction (IE) tasks with NL-LLMs since the output of the IE task is usually structured and therefore is hard to be converted into plain text. In this paper, we propose to recast the structured output in the form of code instead of natural language and utilize generative LLMs of code (Code-LLMs) such as Codex to perform IE tasks, in particular, named entity recognition and relation extraction. In contrast to NL-LLMs, we show that Code-LLMs can be well-aligned with these IE tasks by designing code-style prompts and formulating these IE tasks as code generation tasks. Experiment results on seven benchmarks show that our method consistently outperf
    
[^61]: 基于图卷积循环网络的危险驾驶行为精准检测提高道路安全性

    Enhancing Road Safety through Accurate Detection of Hazardous Driving Behaviors with Graph Convolutional Recurrent Networks. (arXiv:2305.05670v1 [cs.LG])

    [http://arxiv.org/abs/2305.05670](http://arxiv.org/abs/2305.05670)

    本文提出了一种基于图卷积循环网络的可靠DBD系统，利用公共传感器提高了驾驶行为检测模型的准确性和实用性。

    

    车祸仍然是全球重大的公共安全问题，其中的大多数归因于驾驶员错误，包括不足的驾驶知识、不合规定以及不良驾驶习惯。为了提高道路安全性，多项驾驶行为检测（DBD）系统已经被提出，以识别安全和不安全的驾驶行为。这些研究中的许多利用了从控制器区域网络（CAN）总线获取的传感器数据来构建模型。然而，使用公共可用传感器已知会降低检测模型的准确性，而将供应商特定的传感器纳入数据集中则可以增加准确性。为了解决现有方法的局限性，我们提出了一个基于图卷积长短期记忆网络（GConvLSTM）的可靠DBD系统，利用公共传感器提高了DBD模型的精度和实用性。此外，我们还加入了非公共传感器来评估模型的有效性。

    Car accidents remain a significant public safety issue worldwide, with the majority of them attributed to driver errors stemming from inadequate driving knowledge, non-compliance with regulations, and poor driving habits. To improve road safety, Driving Behavior Detection (DBD) systems have been proposed in several studies to identify safe and unsafe driving behavior. Many of these studies have utilized sensor data obtained from the Controller Area Network (CAN) bus to construct their models. However, the use of publicly available sensors is known to reduce the accuracy of detection models, while incorporating vendor-specific sensors into the dataset increases accuracy. To address the limitations of existing approaches, we present a reliable DBD system based on Graph Convolutional Long Short-Term Memory Networks (GConvLSTM) that enhances the precision and practicality of DBD models using public sensors. Additionally, we incorporate non-public sensors to evaluate the model's effectivene
    
[^62]: 基于神经符号人工智能算法的预测增材制造聚乳酸（PLA）样品冲击强度

    Neurosymbolic Artificial Intelligence (NSAI) based Algorithm for predicting the Impact Strength of Additive Manufactured Polylactic Acid (PLA) Specimens. (arXiv:2305.05668v1 [cs.LG])

    [http://arxiv.org/abs/2305.05668](http://arxiv.org/abs/2305.05668)

    本研究介绍了一种基于神经符号人工智能的算法，能够高精度预测增材制造聚乳酸（PLA）样品的冲击强度。

    

    本研究介绍了神经符号人工智能（NSAI）在预测增材制造聚乳酸（PLA）组件冲击强度方面的应用，是NSAI在增材制造领域首次应用。NSAI模型融合了神经网络和符号人工智能的优势，相比传统的机器学习技术能够提供更精准和准确的预测。采集了实验数据并进行了合成增强，使模型更加精确。神经符号模型使用包括输入、两个隐藏层、和一个输出层的神经网络架构来开发，接着是一个代表符号组件的决策树回归器。通过对比评估训练集和验证集的均方误差（MSE）和R2值，模型的表现被与简单人工神经网络（ANN）模型进行了基准测试。结果显示，神经符号模型优于简单的ANN模型，在两个数据集上的MSE更低，R2值更高。总的来说，所提出的基于NSAI算法的方法在预测增材制造PLA组件的冲击强度方面表现出极高的准确性。

    In this study, we introduce application of Neurosymbolic Artificial Intelligence (NSAI) for predicting the impact strength of additive manufactured polylactic acid (PLA) components, representing the first-ever use of NSAI in the domain of additive manufacturing. The NSAI model amalgamates the advantages of neural networks and symbolic AI, offering a more robust and accurate prediction than traditional machine learning techniques. Experimental data was collected and synthetically augmented to 1000 data points, enhancing the model's precision. The Neurosymbolic model was developed using a neural network architecture comprising input, two hidden layers, and an output layer, followed by a decision tree regressor representing the symbolic component. The model's performance was benchmarked against a Simple Artificial Neural Network (ANN) model by assessing mean squared error (MSE) and R-squared (R2) values for both training and validation datasets. The results reveal that the Neurosymbolic m
    
[^63]: 面向个人或实体的知识图谱表示学习：在医疗保健领域应用的研究

    Representation Learning for Person or Entity-centric Knowledge Graphs: an application in Healthcare. (arXiv:2305.05640v1 [cs.AI])

    [http://arxiv.org/abs/2305.05640](http://arxiv.org/abs/2305.05640)

    本研究提出了一种在医疗保健领域构建面向实体的知识图谱的端到端表示学习方法 HEER，通过将领域特定的约束和特征纳入到图嵌入算法中，有效地改善了下游预测任务。

    

    知识图谱是一种按本体或模式组织信息的流行方式，已经在从搜索到推荐的各种场景中得到了应用。尽管在知识图谱方面有了一些进展，但知识表示仍然是跨行业的一个非常棘手的任务，特别是在生物医学和医疗保健领域，由于实体之间的复杂相互关系、异质性、缺乏标准化和数据稀疏性等因素，这一任务尤其具有挑战性。本文提出了一种面向医疗保健领域构建面向实体的知识图谱的端到端表示学习方法，重点是捕捉生物医学领域的独特特征。所提出的框架名为HEER（Healthcare Entity-Entity Representation learning），将领域特定的约束和特征纳入到图嵌入算法中。对多个基准数据集的结果表明，与最先进的方法相比，HEER在改善下游预测任务方面具有有效性。

    Knowledge graphs (KGs) are a popular way to organise information based on ontologies or schemas and have been used across a variety of scenarios from search to recommendation. Despite advances in KGs, representing knowledge remains a non-trivial task across industries and it is especially challenging in the biomedical and healthcare domains due to complex interdependent relations between entities, heterogeneity, lack of standardization, and sparseness of data. KGs are used to discover diagnoses or prioritize genes relevant to disease, but they often rely on schemas that are not centred around a node or entity of interest, such as a person. Entity-centric KGs are relatively unexplored but hold promise in representing important facets connected to a central node and unlocking downstream tasks beyond graph traversal and reasoning, such as generating graph embeddings and training graph neural networks for a wide range of predictive tasks. This paper presents an end-to-end representation le
    
[^64]: 脊柱融合手术中经皮椎弓根螺钉放置的安全深度强化学习规划

    Safe Deep RL for Intraoperative Planning of Pedicle Screw Placement. (arXiv:2305.05354v1 [cs.RO])

    [http://arxiv.org/abs/2305.05354](http://arxiv.org/abs/2305.05354)

    本论文提出了一种基于安全深度强化学习的椎管机器人手术术中规划方法，解决了相对传统的术前规划和术中注册开环控制的局限，能够提高放置准确度和保证手术安全。

    

    脊柱融合手术需要高精度实施椎弓根螺钉植入，其必须在极度接近重要结构并且解剖视野有限的情况下进行。虽然提出了机器人手术系统以改善放置准确度，但是现有系统仍然存在传统的术前规划和术中注册开环控制的局限。本文提出了一种采用安全深度强化学习进行实时观察的椎管机器人手术术中规划方法。我们主要的贡献有：（1）通过引入基于距离的不确定性感知安全过滤器保证安全操作能力；（2）通过使用先验解剖结构信息对不完整的术中解剖信息进行补偿。

    Spinal fusion surgery requires highly accurate implantation of pedicle screw implants, which must be conducted in critical proximity to vital structures with a limited view of anatomy. Robotic surgery systems have been proposed to improve placement accuracy, however, state-of-the-art systems suffer from the limitations of open-loop approaches, as they follow traditional concepts of preoperative planning and intraoperative registration, without real-time recalculation of the surgical plan. In this paper, we propose an intraoperative planning approach for robotic spine surgery that leverages real-time observation for drill path planning based on Safe Deep Reinforcement Learning (DRL). The main contributions of our method are (1) the capability to guarantee safe actions by introducing an uncertainty-aware distance-based safety filter; and (2) the ability to compensate for incomplete intraoperative anatomical information, by encoding a-priori knowledge about anatomical structures with a ne
    
[^65]: 学习个性化推荐以基于客户购物意图

    Learning to Personalize Recommendation based on Customers' Shopping Intents. (arXiv:2305.05279v1 [cs.IR])

    [http://arxiv.org/abs/2305.05279](http://arxiv.org/abs/2305.05279)

    本文介绍了亚马逊的新系统，利用深度学习模型将顾客的在线行为映射成为高级别购物意图，以便个性化推荐，提供更相关、可解释和多样化的购物体验。

    

    理解顾客的高级别购物意图，如他们去露营或举办生日派对的愿望，对于电商平台非常重要；它可以通过提供更相关、可解释和多样化的推荐来提高购物体验的质量。然而，由于实际挑战，这种高级别的购物意图在行业中被忽视。在这项工作中，我们介绍了亚马逊的新系统，明确地识别和利用每个客户的高级别购物意图来个性化推荐。我们开发了一种新技术，自动识别亚马逊客户正在追求的各种高级别目标，如“去露营”和“准备海滩派对”。我们的解决方案进行了扩展（跨越21个国家的14种语言）。然后，一个深度学习模型将每个客户的在线行为，如产品搜索和个体项目参与，映射成一组高级别的购物意图。

    Understanding the customers' high level shopping intent, such as their desire to go camping or hold a birthday party, is critically important for an E-commerce platform; it can help boost the quality of shopping experience by enabling provision of more relevant, explainable, and diversified recommendations. However, such high level shopping intent has been overlooked in the industry due to practical challenges. In this work, we introduce Amazon's new system that explicitly identifies and utilizes each customer's high level shopping intents for personalizing recommendations. We develop a novel technique that automatically identifies various high level goals being pursued by the Amazon customers, such as "go camping", and "preparing for a beach party". Our solution is in a scalable fashion (in 14 languages across 21 countries). Then a deep learning model maps each customer's online behavior, e.g. product search and individual item engagements, into a subset of high level shopping intents
    
[^66]: 从大型语言模型中提取脚本知识以进行受限语言规划

    Distilling Script Knowledge from Large Language Models for Constrained Language Planning. (arXiv:2305.05252v1 [cs.CL])

    [http://arxiv.org/abs/2305.05252](http://arxiv.org/abs/2305.05252)

    本文首次定义了受限语言规划任务，提出了一种方法来提高大型语言模型在这个任务中的表现，并提取了一个新颖的受限语言规划数据集。实验证明该方法显著提高了其在约束忠实度方面的能力，并对赋予较小的语言模型受限语言规划能力非常有效。

    

    在日常生活中，人们经常通过遵循目标导向的脚本形式的逐步说明来规划自己的行动。以往的工作利用语言模型（LM）来为立体活动的抽象目标（例如，“制作蛋糕”）进行规划，但对于具有多方面约束的更具体目标（例如，“为糖尿病患者制作蛋糕”）鲜有研究。本文首次定义了受限语言规划任务。我们提出了一种过度生成并过滤的方法来改善大型语言模型（LLM）在这个任务中的表现，并利用它来提取一种新颖的受限语言规划数据集CoScript，其中包括55,000个脚本。实验证明，我们的方法显著提高了LLM在受限语言规划方面的能力，特别是在约束忠实度方面。此外，CoScript被证明对赋予较小的LM受限语言规划能力是非常有效的。

    In everyday life, humans often plan their actions by following step-by-step instructions in the form of goal-oriented scripts. Previous work has exploited language models (LMs) to plan for abstract goals of stereotypical activities (e.g., "make a cake"), but leaves more specific goals with multi-facet constraints understudied (e.g., "make a cake for diabetics"). In this paper, we define the task of constrained language planning for the first time. We propose an overgenerate-then-filter approach to improve large language models (LLMs) on this task, and use it to distill a novel constrained language planning dataset, CoScript, which consists of 55,000 scripts. Empirical results demonstrate that our method significantly improves the constrained language planning ability of LLMs, especially on constraint faithfulness. Furthermore, CoScript is demonstrated to be quite effective in endowing smaller LMs with constrained language planning ability.
    
[^67]: FedZKP：使用零知识证明的联邦模型所有权验证

    FedZKP: Federated Model Ownership Verification with Zero-knowledge Proof. (arXiv:2305.04507v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2305.04507](http://arxiv.org/abs/2305.04507)

    提出了一种名为FedZKP的联邦模型所有权验证方案，使用零知识证明，可在不公开凭据的情况下抵御各种攻击，并在理论分析和实证研究中证明了其安全性和准确性。

    

    联邦学习允许多个参与方在不共享私有数据的情况下合作学习联邦模型。为了保护这种联邦模型免受抄袭或滥用的侵害，我们提出了一种可证明安全的模型所有权验证方案，称为FedZKP。研究表明，FedZKP方案在不公开凭据的情况下，能够抵御各种现有和潜在的攻击。理论分析和实证研究均证明了FedZKP的安全性，攻击者破解该方案的概率可以忽略不计。此外，广泛的实验结果证实了我们方案的准确性和鲁棒性。

    Federated learning (FL) allows multiple parties to cooperatively learn a federated model without sharing private data with each other. The need of protecting such federated models from being plagiarized or misused, therefore, motivates us to propose a provable secure model ownership verification scheme using zero-knowledge proof, named FedZKP. It is shown that the FedZKP scheme without disclosing credentials is guaranteed to defeat a variety of existing and potential attacks. Both theoretical analysis and empirical studies demonstrate the security of FedZKP in the sense that the probability for attackers to breach the proposed FedZKP is negligible. Moreover, extensive experimental results confirm the fidelity and robustness of our scheme.
    
[^68]: 基于抽象语法树的异构有向超图神经网络用于代码分类

    Heterogeneous Directed Hypergraph Neural Network over abstract syntax tree (AST) for Code Classification. (arXiv:2305.04228v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2305.04228](http://arxiv.org/abs/2305.04228)

    本研究提出了使用异构有向超图表示AST，并使用异构有向超图神经网络处理图形进行代码分类，超过了现有方法。

    

    代码分类是程序理解和自动编码中的一个难题。由于程序的模糊语法和复杂语义，大多数现有研究使用基于抽象语法树（AST）和图神经网络（GNN）的技术创建代码表示用于代码分类。这些技术利用代码的结构和语义信息，但只考虑节点之间的成对关系，忽略了AST中节点之间已经存在的高阶相关性，可能导致代码结构信息的丢失。本研究提出使用异构有向超图（HDHG）表示AST，并使用异构有向超图神经网络（HDHGN）处理图形。HDHG保留了节点之间的高阶相关性，并更全面地编码了AST的语义和结构信息。HDHGN通过聚合不同节点的特征并使用不同的函数对其进行处理来对AST进行建模。在四个数据集上的实验表明，HDHG和HDHGN在代码分类任务中超越了现有方法。

    Code classification is a difficult issue in program understanding and automatic coding. Due to the elusive syntax and complicated semantics in programs, most existing studies use techniques based on abstract syntax tree (AST) and graph neural network (GNN) to create code representations for code classification. These techniques utilize the structure and semantic information of the code, but they only take into account pairwise associations and neglect the high-order correlations that already exist between nodes in the AST, which may result in the loss of code structural information. On the other hand, while a general hypergraph can encode high-order data correlations, it is homogeneous and undirected which will result in a lack of semantic and structural information such as node types, edge types, and directions between child nodes and parent nodes when modeling AST. In this study, we propose to represent AST as a heterogeneous directed hypergraph (HDHG) and process the graph by hetero
    
[^69]: X-LLM: 通过将多模态视为外语引入大型语言模型来启动高级大型语言模型

    X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages. (arXiv:2305.04160v1 [cs.CL])

    [http://arxiv.org/abs/2305.04160](http://arxiv.org/abs/2305.04160)

    本论文提出了一种名为X-LLM的方法，将多模态信息转换为外语并输入到大型语言模型中，从而赋予LLM多模态能力，对于LLM加入多模态信息的能力进行了探究和拓展。

    

    大型语言模型（LLM）展示了卓越的语言能力。基于高级LLM的GPT-4表现出超常的多模态能力，超越了以往的视觉语言模型。我们将这归功于与以前的多模态模型相比使用了更先进的LLM。但不幸的是，GPT-4的模型架构和训练策略是未知的。为了赋予LLM多模态能力，我们提出了X-LLM，通过使用X2L接口将多模态（图像、语音、视频）转换为外语并将其输入到大型语言模型（ChatGLM）中。具体而言，X-LLM使用X2L接口将多个冻结的单模态编码器和冻结的LLM对齐，其中“X”表示多模态，例如图像、语音和视频，“L”表示语言。X-LLM的训练由三个阶段组成：（1）转换多模态信息：第一阶段分别训练每个X2L接口与其各自的单模态编码器对齐，将多模态信息转换为外语输入到ChatGLM中。...

    Large language models (LLMs) have demonstrated remarkable language abilities. GPT-4, based on advanced LLMs, exhibits extraordinary multimodal capabilities beyond previous visual language models. We attribute this to the use of more advanced LLMs compared with previous multimodal models. Unfortunately, the model architecture and training strategies of GPT-4 are unknown. To endow LLMs with multimodal capabilities, we propose X-LLM, which converts Multi-modalities (images, speech, videos) into foreign languages using X2L interfaces and inputs them into a large Language model (ChatGLM). Specifically, X-LLM aligns multiple frozen single-modal encoders and a frozen LLM using X2L interfaces, where ``X'' denotes multi-modalities such as image, speech, and videos, and ``L'' denotes languages. X-LLM's training consists of three stages: (1) Converting Multimodal Information: The first stage trains each X2L interface to align with its respective single-modal encoder separately to convert multimod
    
[^70]: 基于因果感知的知识引导句子提取

    Causality-aware Concept Extraction based on Knowledge-guided Prompting. (arXiv:2305.01876v1 [cs.CL])

    [http://arxiv.org/abs/2305.01876](http://arxiv.org/abs/2305.01876)

    该论文提出了一种基于因果感知的知识引导提示方法，将其作为干预器装备到基于预训练语言模型的句子提取器中，以缓解概念偏差。在代表性的多语言KG数据集上进行广泛实验，获得了最先进的结果。

    

    概念有助于自然语言理解，但现有的知识图谱（KG）中远未完善。最近，预训练语言模型（PLM）已被广泛用于基于文本的概念提取（CE）。然而，PLM往往从大量语料库的共现关联中进行预训练知识挖掘，而非Token之间的真实因果关系。因此，预训练知识混淆了PLM，导致提取基于虚假共现相关性的有偏概念，不可避免地导致低精度。本文通过结构因果模型（SCM）提出了一种知识引导提示方法，将其作为干预器装备到基于PLM的提取器中，以减轻概念偏差。提示采用现有KG中的给定实体主题来缓解实体和有偏概念之间的虚假共现相关性。我们在代表性的多语言KG数据集上进行了广泛的实验，证明了我们提出的提示显著改进了提取性能，并达到了最先进的结果。

    Concepts benefit natural language understanding but are far from complete in existing knowledge graphs (KGs). Recently, pre-trained language models (PLMs) have been widely used in text-based concept extraction (CE). However, PLMs tend to mine the co-occurrence associations from massive corpus as pre-trained knowledge rather than the real causal effect between tokens.As a result, the pre-trained knowledge confounds PLMs to extract biased concepts based on spurious co-occurrence correlations, inevitably resulting in low precision. In this paper, through the lens of a Structural Causal Model (SCM), we propose equipping the PLM-based extractor with a knowledge-guided prompt as an intervention to alleviate concept bias. The prompt adopts the topic of the given entity from the existing knowledge in KGs to mitigate the spurious co-occurrence correlations between entities and biased concepts. Our extensive experiments on representative multilingual KG datasets justify that our proposed prompt 
    
[^71]: 基于扩散的生成式人工智能在探索二维分子图的过渡态上的应用

    Diffusion-based Generative AI for Exploring Transition States from 2D Molecular Graphs. (arXiv:2304.12233v2 [physics.chem-ph] UPDATED)

    [http://arxiv.org/abs/2304.12233](http://arxiv.org/abs/2304.12233)

    本文提出了一种基于扩散的生成式方法(TSDiff)，用于从二维分子图中预测过渡态几何结构。与现有具有 3D 几何结构机器学习模型相比，TSdiff 的准确性和效率都更高。TSDiff 能够找到比参考数据库更优化的反应途径，在反应势垒更低的情况下找到更为优化的反应路径。

    

    探究过渡态几何结构对于阐明化学反应机理和模拟反应动力学至关重要。最近，机器学习模型在预测过渡态几何结构方面表现出了出色的性能。然而，它们需要反应物和产物的 3D 形态和方向作为输入，这需要大量的努力和计算成本。在这里，我们提出了一种基于随机扩散方法的生成式方法(TSDiff)，用于从二维分子图中预测过渡态几何结构。TSDiff在准确性和效率方面优于现有的具有 3D 几何结构的机器学习模型。此外，它可以从训练中了解到各种反应的过渡态几何分布，从而能够采样各种过渡态构象。因此，TSDiff 能够找到比参考数据库中更为有利的反应途径，在反应势垒更低的情况下找到更为优化的反应路径。这些结果表明，TSDiff 在加速化学反应和反应途径的发现方面具有潜在的价值。

    The exploration of transition state (TS) geometries is crucial for elucidating chemical reaction mechanisms and modeling their kinetics. Recently, machine learning (ML) models have shown remarkable performance for prediction of TS geometries. However, they require 3D conformations of reactants and products often with their appropriate orientations as input, which demands substantial efforts and computational cost. Here, we propose a generative approach based on the stochastic diffusion method, namely TSDiff, for prediction of TS geometries just from 2D molecular graphs. TSDiff outperformed the existing ML models with 3D geometries in terms of both accuracy and efficiency. Moreover, it enables to sample various TS conformations, because it learned the distribution of TS geometries for diverse reactions in training. Thus, TSDiff was able to find more favorable reaction pathways with lower barrier heights than those in the reference database. These results demonstrate that TSDiff shows pr
    
[^72]: 多尺度进化神经架构搜索用于深度脉冲神经网络

    Multi-scale Evolutionary Neural Architecture Search for Deep Spiking Neural Networks. (arXiv:2304.10749v1 [cs.NE])

    [http://arxiv.org/abs/2304.10749](http://arxiv.org/abs/2304.10749)

    本文提出了一种新方法--多尺度进化神经架构搜索，用于自动设计脉冲神经网络，同时考虑微观、中观和宏观尺度的脑拓扑结构。MSE-NAS可以帮助SNN实现多电路模式的自组织集成，并通过全局性的跨模式连接来优化网络性能。

    

    脉冲神经网络（SNN）不仅因其离散信号处理的能源效率卓越，而且因其天然适合于集成多尺度生物可塑性而受到广泛关注。然而，大多数SNN直接采用成熟的DNN结构，很少自动设计神经架构搜索（NAS）用于SNN。人类大脑神经模式的拓扑结构，模块化的区域结构和全局性的跨脑区连接是自然进化的产物，可以作为设计基于脑的SNN架构的完美参考。本文提出了一种多尺度进化神经架构搜索（MSE-NAS），同时考虑微观、中观和宏观尺度的脑拓扑作为进化搜索空间。 MSE-NAS通过基于大脑启发的间接方式，进化单个神经元操作，多个电路模式的自组织集成以及跨模式的全局连通性。

    Spiking Neural Networks (SNNs) have received considerable attention not only for their superiority in energy efficient with discrete signal processing, but also for their natural suitability to integrate multi-scale biological plasticity. However, most SNNs directly adopt the structure of the well-established DNN, rarely automatically design Neural Architecture Search (NAS) for SNNs. The neural motifs topology, modular regional structure and global cross-brain region connection of the human brain are the product of natural evolution and can serve as a perfect reference for designing brain-inspired SNN architecture. In this paper, we propose a Multi-Scale Evolutionary Neural Architecture Search (MSE-NAS) for SNN, simultaneously considering micro-, meso- and macro-scale brain topologies as the evolutionary search space. MSE-NAS evolves individual neuron operation, self-organized integration of multiple circuit motifs, and global connectivity across motifs through a brain-inspired indirec
    
[^73]: 通过自我改进的方式实现更好的代码语言模型

    Better Language Models of Code through Self-Improvement. (arXiv:2304.01228v1 [cs.CL])

    [http://arxiv.org/abs/2304.01228](http://arxiv.org/abs/2304.01228)

    本文提出了一个简单的数据增强框架来改善预训练语言模型为代码生成和代码摘要等任务微调的瓶颈问题，提高了模型性能。

    

    近期，各种预训练的代码语言模型引起了人们的广泛关注。这些模型通过多模式目标在大规模数据集上进行预训练。但是，对其进行微调需要大量监督，并且受到提供的数据集规模的限制。我们提出了一个简单的数据增强框架以改善这个问题。这个框架利用了在预训练和微调阶段获得的知识来生成伪数据，并将其用作下一步的训练数据。我们将这个框架应用到最先进的语言模型中，如CodeT5、CodeBERT和UnixCoder。结果表明，我们的框架显著提高了PLMC在与代码相关的序列生成任务中的性能，如CodeXGLUE基准测试中的代码摘要和代码生成。

    Pre-trained language models for code (PLMCs) have gained attention in recent research. These models are pre-trained on large-scale datasets using multi-modal objectives. However, fine-tuning them requires extensive supervision and is limited by the size of the dataset provided. We aim to improve this issue by proposing a simple data augmentation framework. Our framework utilizes knowledge gained during the pre-training and fine-tuning stage to generate pseudo data, which is then used as training data for the next step. We incorporate this framework into the state-of-the-art language models, such as CodeT5, CodeBERT, and UnixCoder. The results show that our framework significantly improves PLMCs' performance in code-related sequence generation tasks, such as code summarization and code generation in the CodeXGLUE benchmark.
    
[^74]: 自动驾驶路径规划：现状与展望

    Path Planning for Autonomous Driving: The State of the Art and Perspectives. (arXiv:2303.09824v1 [cs.RO])

    [http://arxiv.org/abs/2303.09824](http://arxiv.org/abs/2303.09824)

    本文综述了现有的自动驾驶路径规划方法，包括管道规划和端到端规划方法。在挑战和潜在解决方案方面提供了讨论，有助于为智能汽车的发展提供更好的规划方法。

    

    智能汽车由于提高的便利性、安全性和潜在的商业价值而受到广泛关注。但由于各种问题，如安全性、可靠性和规划方法的泛化等限制，它们的部署仍局限于小规模验证阶段。本文旨在综述最先进的路径规划方法，包括管道规划和端到端规划方法。针对管道方法，本文提供了选取算法的概述，并讨论了扩展和优化机制；针对端到端方法，本文强调培训和验证方法。此外，本文还讨论了挑战和潜在解决方案，这有助于为智能汽车的发展提供更好的规划方法。

    Intelligent vehicles (IVs) have attracted wide attention thanks to the augmented convenience, safety advantages, and potential commercial value. Although a few of autonomous driving unicorns assert that IVs will be commercially deployable by 2025, their deployment is still restricted to small-scale validation due to various issues, among which safety, reliability, and generalization of planning methods are prominent concerns. Precise computation of control commands or trajectories by planning methods remains a prerequisite for IVs, owing to perceptual imperfections under complex environments, which pose an obstacle to the successful commercialization of IVs. This paper aims to review state-of-the-art planning methods, including pipeline planning and end-to-end planning methods. In terms of pipeline methods, a survey of selecting algorithms is provided along with a discussion of the expansion and optimization mechanisms, whereas in end-to-end methods, the training approaches and verific
    
[^75]: 非参数化网络在三维点云分析中的应用：参数不是唯一需要的。

    Parameter is Not All You Need: Starting from Non-Parametric Networks for 3D Point Cloud Analysis. (arXiv:2303.08134v1 [cs.CV])

    [http://arxiv.org/abs/2303.08134](http://arxiv.org/abs/2303.08134)

    本文提出了一种基于非参数化模型的三维点云分析网络Point-NN。它在各种三维任务中表现良好，不需要参数或训练，可以作为基础架构框架构建参数化网络和已经训练好的三维模型的即插即用模块。

    

    本文提出了一种基于非参数化模型的三维点云分析网络——Point-NN。该网络仅由不可学习组件组成，包括最远点采样（FPS）、K近邻（k-NN）和加权平均池化等操作及三角函数。令人惊讶的是，它在各种三维任务中表现良好，不需要参数或训练，甚至超过了现有的完全训练模型。基于这种非参数模型，我们提出了两种扩展。首先，Point-NN可以作为基础架构框架，通过在其上简单插入线性层来构建参数化网络。在非参数基础上，得到的Point-PN具有较高的性能效率权衡，只需要很少的可学习参数。其次，Point-NN可以被视为已经训练好的三维模型的即插即用模块。Point-NN捕获互补的几何知识，增强现有方法对不同三维基准的性能。我们希望我们的工作能够激发更多对非线性操作和几何知识的研究。

    We present a Non-parametric Network for 3D point cloud analysis, Point-NN, which consists of purely non-learnable components: farthest point sampling (FPS), k-nearest neighbors (k-NN), and pooling operations, with trigonometric functions. Surprisingly, it performs well on various 3D tasks, requiring no parameters or training, and even surpasses existing fully trained models. Starting from this basic non-parametric model, we propose two extensions. First, Point-NN can serve as a base architectural framework to construct Parametric Networks by simply inserting linear layers on top. Given the superior non-parametric foundation, the derived Point-PN exhibits a high performance-efficiency trade-off with only a few learnable parameters. Second, Point-NN can be regarded as a plug-and-play module for the already trained 3D models during inference. Point-NN captures the complementary geometric knowledge and enhances existing methods for different 3D benchmarks without re-training. We hope our w
    
[^76]: 随机序列多智能体决策的因果解释

    Causal Explanations for Stochastic Sequential Multi-Agent Decision-Making. (arXiv:2302.10809v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.10809](http://arxiv.org/abs/2302.10809)

    CEMA是一个用于多智能体决策因果解释的系统，使用采样反事实世界的方法可以识别和排名决策背后的显著原因。该系统还可以生成基于所选原因的对比解释，并与用户进行交互循环以确保解释的相关性和可读性。

    

    我们提出CEMA：用于多智能体决策的因果解释系统；用于在随机序列多智能体环境中生成关于智能体决策的因果解释。CEMA的核心是一种新颖的因果选择方法，不同于之前假设特定因果结构的方法，只需要一个可以预测环境未来状态的概率模型即可应用。我们使用该模型采样反事实世界，以识别和排名决策背后的显著原因。我们还设计了CEMA以满足社会可解释AI的要求。它可以基于所选原因生成对比解释，通过与用户的交互循环来确保对用户的相关性和可读性。我们将CEMA实现在自动驾驶的运动规划中，并在四个不同的模拟场景中进行测试。我们展示CEMA能够正确而且鲁棒地识别决策背后的相关原因，并提供相关解释。

    We present CEMA: Causal Explanations for Multi-Agent decision-making; a system to generate causal explanations for agents' decisions in stochastic sequential multi-agent environments. The core of CEMA is a novel causal selection method which, unlike prior work that assumes a specific causal structure, is applicable whenever a probabilistic model for predicting future states of the environment is available. We sample counterfactual worlds with this model which are used to identify and rank the salient causes behind decisions. We also designed CEMA to meet the requirements of social explainable AI. It can generate contrastive explanations based on selected causes and it works as an interaction loop with users to assure relevance and intelligibility for them. We implement CEMA for motion planning for autonomous driving and test it in four diverse simulated scenarios. We show that CEMA correctly and robustly identifies the relevant causes behind decisions and delivers relevant explanations
    
[^77]: 让你的行为井然有序：AI法案和技术透明度的比较视角

    Get Your Act Together: A Comparative View on Transparency in the AI Act and Technology. (arXiv:2302.10766v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.10766](http://arxiv.org/abs/2302.10766)

    该论文比较了欧盟提出的《人工智能法案》和可解释AI（XAI）对于透明度和解释性的基本定义，强调了将这些定义对齐的重要性，以确保技术实践符合法规。

    

    欧盟提出了《人工智能法案》，引入了基于风险的比例方法来规范人工智能，其中详细要求透明度和可解释性。虽然可解释AI（XAI）领域可以解决这些要求中的许多问题，但在透明度和可解释性的具体定义上，XAI与该法案存在基本差异。为了实现这种对齐，我们首先概述了XAI和欧洲法规是如何看待透明度的基本定义的，特别是AI法案和相关的通用数据保护条例（GDPR）。然后我们进行了比较，旨在确定改善领域之间对齐的主要要点：澄清透明度的范围，XAI的法律地位，监管问题。

    The European Union has proposed the Artificial Intelligence Act which introduces a proportional risk-based approach to AI regulation including detailed requirements for transparency and explainability. Many of these requirements may be addressed in practice by the field of explainable AI (XAI), however, there are fundamental differences between XAI and the Act regarding what transparency and explainability are. These basic definitions should be aligned to assure that regulation continually translates into appropriate technical practices. To facilitate this alignment, we first give an overview of how XAI and European regulation view basic definitions of transparency with a particular focus on the AI Act and the related General Data Protection Regulation (GDPR). We then present a comparison of XAI and regulatory approaches to identify the main points that would improve alignment between the fields: clarification of the scope of transparency, the legal status of XAI, oversight issues in c
    
[^78]: 近乎贝叶斯最优的伪标签选择

    Approximately Bayes-Optimal Pseudo Label Selection. (arXiv:2302.08883v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.08883](http://arxiv.org/abs/2302.08883)

    本文介绍了BPLS，一种用于PLS的贝叶斯框架，通过解析逼近选择标签实例的标准，以避免由过度自信但错误预测的实例选择而导致的确认偏差问题。

    

    自训练的半监督学习严重依赖于伪标签选择（PLS）。选择通常取决于初始模型拟合标记数据的程度。过早的过拟合可能通过选择具有过度自信但错误的预测的实例（通常称为确认偏差）而传播到最终模型。本文介绍了BPLS，这是一种用于PLS的贝叶斯框架，旨在减轻这个问题。其核心是选择标签实例的标准：伪样本的后验预测的分析近似。我们通过证明伪样本的后验预测的贝叶斯最优性获得了这种选择标准。我们进一步通过解析逼近克服计算难题。它与边际似然的关系使我们能够提出基于拉普拉斯方法和高斯积分的逼近。我们针对参数广义线性和非参数广义加性模型对BPLS进行了实证评估。

    Semi-supervised learning by self-training heavily relies on pseudo-label selection (PLS). The selection often depends on the initial model fit on labeled data. Early overfitting might thus be propagated to the final model by selecting instances with overconfident but erroneous predictions, often referred to as confirmation bias. This paper introduces BPLS, a Bayesian framework for PLS that aims to mitigate this issue. At its core lies a criterion for selecting instances to label: an analytical approximation of the posterior predictive of pseudo-samples. We derive this selection criterion by proving Bayes optimality of the posterior predictive of pseudo-samples. We further overcome computational hurdles by approximating the criterion analytically. Its relation to the marginal likelihood allows us to come up with an approximation based on Laplace's method and the Gaussian integral. We empirically assess BPLS for parametric generalized linear and non-parametric generalized additive models
    
[^79]: SNeRL: 语义感知的神经辐射场用于强化学习

    SNeRL: Semantic-aware Neural Radiance Fields for Reinforcement Learning. (arXiv:2301.11520v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11520](http://arxiv.org/abs/2301.11520)

    本文提出了一种称为SNeRL的语义感知神经辐射场，它通过学习3D-aware的隐式表示来进行强化学习，并在基于像素的以及最新的3D感知表示方法中表现出更好的性能。

    

    传统的强化学习表示方法很难有效地融合人类直观的3D环境理解，因此经常表现出次优性能。本文提出了一种称为SNeRL的语义感知神经辐射场，它通过联合优化卷积编码器和语义感知神经辐射场（NeRF）来从多视角图像中学习3D感知神经隐式表示。我们在NeRF中引入了3D语义和蒸馏特征场，并与RGB辐射场并行用于强化学习中的语义和对象中心表示学习。SNeRL在无模型和有模型强化学习中不仅优于以往的基于像素的表示方法，还优于最近的3D感知表示方法。

    As previous representations for reinforcement learning cannot effectively incorporate a human-intuitive understanding of the 3D environment, they usually suffer from sub-optimal performances. In this paper, we present Semantic-aware Neural Radiance Fields for Reinforcement Learning (SNeRL), which jointly optimizes semantic-aware neural radiance fields (NeRF) with a convolutional encoder to learn 3D-aware neural implicit representation from multi-view images. We introduce 3D semantic and distilled feature fields in parallel to the RGB radiance fields in NeRF to learn semantic and object-centric representation for reinforcement learning. SNeRL outperforms not only previous pixel-based representations but also recent 3D-aware representations both in model-free and model-based reinforcement learning.
    
[^80]: 深度学习增强自旋量子比特环境的噪声谱学

    Deep learning enhanced noise spectroscopy of a spin qubit environment. (arXiv:2301.05079v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2301.05079](http://arxiv.org/abs/2301.05079)

    本文研究使用深度学习模型提高噪声谱学准确性，实验表明此方法可以比标准技术更加准确，并且需要更少的序列。

    

    量子系统与环境之间的不良相互作用通常导致超态在时间上的相干衰减。精确了解环境引起的噪声的频谱内容对于保护量子比特相干性并优化其在量子器件应用中的使用至关重要。我们实验证明，使用神经网络可以极大地增加噪声谱学的准确性，通过重构碳杂质组合围绕钻石氮-空位（NV）中心所特征化的功率谱密度。神经网络训练于NV中心的自旋相干函数之上，NV中心受不同的Carr-Purcell序列控制，通常用于动力学解偶（DD）。结果表明，深度学习模型可以比标准DD噪声谱学技术更加准确，并且同时需要更少的DD序列。

    The undesired interaction of a quantum system with its environment generally leads to a coherence decay of superposition states in time. A precise knowledge of the spectral content of the noise induced by the environment is crucial to protect qubit coherence and optimize its employment in quantum device applications. We experimentally show that the use of neural networks can highly increase the accuracy of noise spectroscopy, by reconstructing the power spectral density that characterizes an ensemble of carbon impurities around a nitrogen-vacancy (NV) center in diamond. Neural networks are trained over spin coherence functions of the NV center subjected to different Carr-Purcell sequences, typically used for dynamical decoupling (DD). As a result, we determine that deep learning models can be more accurate than standard DD noise-spectroscopy techniques, by requiring at the same time a much smaller number of DD sequences.
    
[^81]: TarViS：一种面向目标的视频分割的统一方法

    TarViS: A Unified Approach for Target-based Video Segmentation. (arXiv:2301.02657v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.02657](http://arxiv.org/abs/2301.02657)

    提出了一种名为TarViS的新颖、统一的网络架构，可用于任何需要在视频中分段任意定义的“目标”集的任务。可以联合训练不同任务的数据集集合，并且可以在推断期间在任务之间进行热切换。在四个不同的任务中进行了应用，均优于现有最先进方法。

    

    视频分割领域目前被划分为不同的任务，涵盖了多个基准。尽管最先进技术正在快速发展，但是当前方法主要是针对特定任务的，这些方法不能概念上推广到其他任务。受到具有多任务能力的最近方法的启发，我们提出了TarViS：一种新颖的统一网络架构，可应用于需要在视频中分段任意定义的“目标”集的任何任务。我们的方法在任务定义这些目标的方式方面具有灵活性，因为它将后者建模为抽象的“查询”，然后用于预测像素精确的目标掩码。单个TarViS模型可以联合训练跨越不同任务的数据集集合，并且可以在推断期间在任务之间进行热切换，无需任何特定于任务的重新训练。为了证明其有效性，我们将TarViS应用于四个不同的任务，即视频实例分割(VIS)、视频全景分割(VPS)、视频语义分割和视频目标分割(VOS)。实验结果表明，TarViS在所有任务中均优于现有最先进方法。

    The general domain of video segmentation is currently fragmented into different tasks spanning multiple benchmarks. Despite rapid progress in the state-of-the-art, current methods are overwhelmingly task-specific and cannot conceptually generalize to other tasks. Inspired by recent approaches with multi-task capability, we propose TarViS: a novel, unified network architecture that can be applied to any task that requires segmenting a set of arbitrarily defined 'targets' in video. Our approach is flexible with respect to how tasks define these targets, since it models the latter as abstract 'queries' which are then used to predict pixel-precise target masks. A single TarViS model can be trained jointly on a collection of datasets spanning different tasks, and can hot-swap between tasks during inference without any task-specific retraining. To demonstrate its effectiveness, we apply TarViS to four different tasks, namely Video Instance Segmentation (VIS), Video Panoptic Segmentation (VPS
    
[^82]: VISEM-Tracking，一份人类精子跟踪数据集

    VISEM-Tracking, a human spermatozoa tracking dataset. (arXiv:2212.02842v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.02842](http://arxiv.org/abs/2212.02842)

    本文提供了人类精子跟踪数据集VISEM-Tracking，包含手动注释的包围框坐标和由专家分析的精子特征，并提供未标记的视频以供易于访问和分析，有助于训练监督式机器学习方法，提高在评估精子运动和运动学方面的精度和可靠性。

    

    精子运动的手动评估需要显微镜观察，由于所观察的精子在视野中的快速移动，这是具有挑战性的。为了获得正确的结果，手动评估需要进行广泛的培训。因此，在诊所中，计算机辅助精子分析（CASA）变得越来越常用。尽管如此，需要更多数据来训练监督式机器学习方法，以提高在评估精子运动和运动学方面的精度和可靠性。在这方面，我们提供了一个名为VISEM-Tracking的数据集，其中包含20个30秒的视频记录（包括29,196帧）的湿性精子制备物，具备手动注释的包围框坐标和由该领域的专家分析的一组精子特征。除了已注释的数据，我们还提供了未标记的视频剪辑，以便通过自监督或无监督学习等方法轻松访问和分析数据。作为本文的一部分，我们提出了基线精子检测性能。

    A manual assessment of sperm motility requires microscopy observation, which is challenging due to the fast-moving spermatozoa in the field of view. To obtain correct results, manual evaluation requires extensive training. Therefore, computer-assisted sperm analysis (CASA) has become increasingly used in clinics. Despite this, more data is needed to train supervised machine learning approaches in order to improve accuracy and reliability in the assessment of sperm motility and kinematics. In this regard, we provide a dataset called VISEM-Tracking with 20 video recordings of 30 seconds (comprising 29,196 frames) of wet sperm preparations with manually annotated bounding-box coordinates and a set of sperm characteristics analyzed by experts in the domain. In addition to the annotated data, we provide unlabeled video clips for easy-to-use access and analysis of the data via methods such as selfor unsupervised learning. As part of this paper, we present baseline sperm detection performan
    
[^83]: 基于查询的多模态路径融合知识库补全

    Query-Driven Knowledge Base Completion using Multimodal Path Fusion over Multimodal Knowledge Graph. (arXiv:2212.01923v2 [cs.DB] UPDATED)

    [http://arxiv.org/abs/2212.01923](http://arxiv.org/abs/2212.01923)

    基于查询的多模态路径融合算法可以有效地对知识库进行补全，提高了性能，并且使用了基于查询的技术来提高系统的效率。

    

    在过去的几年中，大型知识库已经被构建来存储大量的知识。然而，这些知识库高度不完整，例如Freebase中有70%的人没有出生地点。为了解决这个问题，我们提出了一个使用结构化和非结构化信息的多模态融合的、基于查询驱动的知识库补全系统。为了有效地融合来自Web的非结构化信息和知识库中的结构化信息以实现良好的性能，我们的系统基于问答和规则推理构建了多模态知识图。我们提出了一个多模态路径融合算法，在多模态知识图中基于不同的路径对候选答案进行排名，取得了比问答、规则推理和基线融合算法更好的性能。为了提高系统效率，我们使用了基于查询的技术来减少系统的运行时间，为用户查询提供快速响应。

    Over the past few years, large knowledge bases have been constructed to store massive amounts of knowledge. However, these knowledge bases are highly incomplete, for example, over 70% of people in Freebase have no known place of birth. To solve this problem, we propose a query-driven knowledge base completion system with multimodal fusion of unstructured and structured information. To effectively fuse unstructured information from the Web and structured information in knowledge bases to achieve good performance, our system builds multimodal knowledge graphs based on question answering and rule inference. We propose a multimodal path fusion algorithm to rank candidate answers based on different paths in the multimodal knowledge graphs, achieving much better performance than question answering, rule inference and a baseline fusion algorithm. To improve system efficiency, query-driven techniques are utilized to reduce the runtime of our system, providing fast responses to user queries. Ex
    
[^84]: 基于信任感知的群体智能数据注入攻击防御

    Trust-Awareness to Secure Swarm Intelligence from Data Injection Attack. (arXiv:2211.08407v3 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2211.08407](http://arxiv.org/abs/2211.08407)

    本文提出一种基于信任感知的方法，以应对群体智能的数据注入攻击。

    

    群体智能（SI）借助新兴的工业智能体（IA）技术得以实现，被预计在由第六代移动通信和数字孪生（DT）构成的未来工业物联网（IIoT）中扮演重要角色。然而，SI 对于数据注入攻击的脆弱性可能会使其无法实际部署。本文提出了一种有效的信任方法，以应对 SI 的这一安全问题。

    Enabled by the emerging industrial agent (IA) technology, swarm intelligence (SI) is envisaged to play an important role in future industrial Internet of Things (IIoT) that is shaped by Sixth Generation (6G) mobile communications and digital twin (DT). However, its fragility against data injection attack may halt it from practical deployment. In this paper we propose an efficient trust approach to address this security concern for SI.
    
[^85]: 利用时变特征调制模拟黑盒音频效应

    Modelling black-box audio effects with time-varying feature modulation. (arXiv:2211.00497v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2211.00497](http://arxiv.org/abs/2211.00497)

    提出了利用时变特征调制来模拟黑盒音频效应，可以更好地捕获长时间尺度上的依赖关系，适用于fuzz和压缩等音频效应。

    

    深度学习方法用于黑盒建模音效已显示出很大的潜力。但是，现有大部分工作集中在具有相对较短时间尺度行为的非线性效应，例如吉他放大器和失真。虽然递归和卷积结构在理论上可以扩展到长时间尺度来捕获行为，但我们发现简单地扩展现有结构的宽度、深度或膨胀因子不能令其在模拟fuzz和动态范围压缩等音频效应时表现得十分令人满意。为了解决这个问题，我们提出在现有的时间卷积骨干中整合时变特征的线性调制的方法，使中间激活可以进行可学习的自适应。我们展示了我们的方法更准确捕获了一系列fuzz和压缩实现的长距离依赖关系，包括时间和频率领域的指标。我们提供了声音示例。

    Deep learning approaches for black-box modelling of audio effects have shown promise, however, the majority of existing work focuses on nonlinear effects with behaviour on relatively short time-scales, such as guitar amplifiers and distortion. While recurrent and convolutional architectures can theoretically be extended to capture behaviour at longer time scales, we show that simply scaling the width, depth, or dilation factor of existing architectures does not result in satisfactory performance when modelling audio effects such as fuzz and dynamic range compression. To address this, we propose the integration of time-varying feature-wise linear modulation into existing temporal convolutional backbones, an approach that enables learnable adaptation of the intermediate activations. We demonstrate that our approach more accurately captures long-range dependencies for a range of fuzz and compressor implementations across both time and frequency domain metrics. We provide sound examples, s
    
[^86]: 大规模提取文化常识知识

    Extracting Cultural Commonsense Knowledge at Scale. (arXiv:2210.07763v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.07763](http://arxiv.org/abs/2210.07763)

    本篇论文提出了一种名为CANDLE的方法，用于从网络语料库中提取文化常识知识，其优于之前的工作。这些知识对于情境化人工智能和GPT-3语言模型都有好处。

    

    结构化知识对于许多人工智能应用非常重要。常识知识对于强大的以人为中心的人工智能至关重要，但是当前列出的少数结构化常识项目缺乏有关社会文化背景下人类特征和行为的知识，这对于情境化人工智能至关重要。本文提出了CANDLE，一种用于大规模提取高质量文化常识知识（CCSK）的端到端方法。CANDLE从庞大的网络语料库中提取CCSK断言，并将其组织成一致的聚类，针对三个主题领域（地理，宗教，职业）和几个文化方面进行分类（食物，饮料，服装，传统，仪式，行为）。CANDLE包括分类过滤和趣味性评分的审慎技术。实验评估显示，CANDLE CCSK集合优于之前的工作，并且外部用例展示了CCSK对于GPT-3语言模型的好处。CANDLE的代码和数据是公开可用的。

    Structured knowledge is important for many AI applications. Commonsense knowledge, which is crucial for robust human-centric AI, is covered by a small number of structured knowledge projects. However, they lack knowledge about human traits and behaviors conditioned on socio-cultural contexts, which is crucial for situative AI. This paper presents CANDLE, an end-to-end methodology for extracting high-quality cultural commonsense knowledge (CCSK) at scale. CANDLE extracts CCSK assertions from a huge web corpus and organizes them into coherent clusters, for 3 domains of subjects (geography, religion, occupation) and several cultural facets (food, drinks, clothing, traditions, rituals, behaviors). CANDLE includes judicious techniques for classification-based filtering and scoring of interestingness. Experimental evaluations show the superiority of the CANDLE CCSK collection over prior works, and an extrinsic use case demonstrates the benefits of CCSK for the GPT-3 language model. Code and 
    
[^87]: Learnware: 小模型实现大作为

    Learnware: Small Models Do Big. (arXiv:2210.03647v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.03647](http://arxiv.org/abs/2210.03647)

    Learnware范式旨在帮助用户充分利用小型模型，实现超越原始目的的事情，以解决当前机器学习技术面临的数据量大、训练难度高、数据安全等问题。

    

    当前机器学习技术存在训练数据量大、训练技能高、连续学习难、遗忘风险大、数据隐私和专有信息泄露等问题，而过去的大模型范式虽然在自然语言处理和计算机视觉应用中取得了惊人的结果，但并未解决这些问题，反而成为严重的碳排放源。该文概述了Learnware范式，让用户不需要从头构建机器学习模型，希望利用小型模型可以实现超越原始目的的事情，其中关键是规范，可以使训练的模型得到充分鉴别。

    There are complaints about current machine learning techniques such as the requirement of a huge amount of training data and proficient training skills, the difficulty of continual learning, the risk of catastrophic forgetting, the leaking of data privacy/proprietary, etc. Most research efforts have been focusing on one of those concerned issues separately, paying less attention to the fact that most issues are entangled in practice. The prevailing big model paradigm, which has achieved impressive results in natural language processing and computer vision applications, has not yet addressed those issues, whereas becoming a serious source of carbon emissions. This article offers an overview of the learnware paradigm, which attempts to enable users not need to build machine learning models from scratch, with the hope of reusing small models to do things even beyond their original purposes, where the key ingredient is the specification which enables a trained model to be adequately identi
    
[^88]: 开发者如何讨论Pandas主题的实证研究

    An Empirical Study on How the Developers Discussed about Pandas Topics. (arXiv:2210.03519v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2210.03519](http://arxiv.org/abs/2210.03519)

    本研究通过收集Stack Overflow中与Pandas主题讨论相关的帖子，进行主题建模，发现了Pandas数据操作、数据分析和数据可视化等主题非常受欢迎，而数据清洗和数据挖掘等主题相对较难。

    

    Pandas是Python编程语言中用于数据分析的软件库。由于Pandas是一种快速、易于使用且开源的数据分析工具，因此它在软件工程项目（如软件开发、机器学习、计算机视觉、自然语言处理、机器人技术等）中被广泛使用。因此，软件开发者对Pandas表现出了巨大的兴趣，并且现在在线开发者论坛（如Stack Overflow）中的讨论数量也越来越多。这些讨论可以帮助了解Pandas库的受欢迎程度，也可以帮助了解Pandas主题的重要性、普及率和困难程度。本研究的主要目的是找到Pandas主题的受欢迎程度和困难程度。为此，我们收集了与Pandas主题讨论相关的Stack Overflow帖子，对帖子的文本内容进行了主题建模。我们发现了26个主题，进一步将其分类为5个广泛的类别。结果显示，最受欢迎的主题是与数据操作、数据分析和数据可视化相关的主题，而最困难的主题与数据清洗和数据挖掘相关。

    Pandas is defined as a software library which is used for data analysis in Python programming language. As pandas is a fast, easy and open source data analysis tool, it is rapidly used in different software engineering projects like software development, machine learning, computer vision, natural language processing, robotics, and others. So a huge interests are shown in software developers regarding pandas and a huge number of discussions are now becoming dominant in online developer forums, like Stack Overflow (SO). Such discussions can help to understand the popularity of pandas library and also can help to understand the importance, prevalence, difficulties of pandas topics. The main aim of this research paper is to find the popularity and difficulty of pandas topics. For this regard, SO posts are collected which are related to pandas topic discussions. Topic modeling are done on the textual contents of the posts. We found 26 topics which we further categorized into 5 board categor
    
[^89]: 无人监督学习用于无线电频谱活动聚类

    Self-supervised Learning for Clustering of Wireless Spectrum Activity. (arXiv:2210.02899v2 [cs.NI] UPDATED)

    [http://arxiv.org/abs/2210.02899](http://arxiv.org/abs/2210.02899)

    本研究使用无人监督学习技术探索无线电频谱活动，比较了两种不同的无人监督学习模型和一种混合模型，实现了精准的频谱活动聚类。

    

    近年来，通过机器学习技术处理无线电频谱数据以解决认知无线电网络相关问题，如异常检测、调制分类、技术分类和设备指纹等领域，取得了很大进展。大多数解决方案都是基于受控制的、带标签的数据，并使用监督式学习方法进行处理。然而，在现实世界环境下测量的频谱数据高度不确定，其标记是一项费时且昂贵的过程，需要领域专业知识，因此成为在该领域使用监督式学习方法的主要缺点之一。本文研究了在现实世界未标记数据中利用无人监督学习（SSL）来探索频谱活动的使用。具体来说，我们比较了两种 SSL 模型的性能，一种基于 DeepCluster 参考体系结构，另一种适用于频谱活动识别和聚类，以及一种新型的混合 SSL 方法，结合了两种模型。我们的实验评估表明，这三种方法都可以有效地对频谱活动数据进行聚类，混合方法的性能最佳。

    In recent years, much work has been done on processing of wireless spectrum data involving machine learning techniques in domain-related problems for cognitive radio networks, such as anomaly detection, modulation classification, technology classification and device fingerprinting. Most of the solutions are based on labeled data, created in a controlled manner and processed with supervised learning approaches. However, spectrum data measured in real-world environment is highly nondeterministic, making its labeling a laborious and expensive process, requiring domain expertise, thus being one of the main drawbacks of using supervised learning approaches in this domain. In this paper, we investigate the use of self-supervised learning (SSL) for exploring spectrum activities in a real-world unlabeled data. In particular, we compare the performance of two SSL models, one based on a reference DeepCluster architecture and one adapted for spectrum activity identification and clustering, and a 
    
[^90]: FreeREA: 无需训练的进化式架构搜索算法

    FreeREA: Training-Free Evolution-based Architecture Search. (arXiv:2207.05135v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2207.05135](http://arxiv.org/abs/2207.05135)

    本研究提出了一种无需训练步骤的进化式架构搜索算法FreeREA，可直接在目标硬件上优化搜索，且能够在性能最大化的同时，极大地减小内存占用。实验结果证明其比手动设计更高效。

    

    在过去的十年中，机器学习领域的大部分研究都是为了改进现有模型，以增加神经网络在各种不同任务的解决方案中的性能。然而，这样的进步往往以增加模型内存和计算需求的代价为代价。这对于研究成果在实际环境中的部署具有相当大的限制性，其中成本、能源消耗和框架的复杂性发挥着至关重要的作用。本文提出了一种新颖的进化式架构搜索算法FreeREA，通过该算法可以快速识别性能最大化且内存占用最小化的神经网络，而无需训练步骤，并在目标硬件上直接优化架构搜索，无需代理指标。实验结果表明了FreeREA的有效性，它能够在需要少达487倍计算资源的情况下，胜过最先进的手动设计架构。

    In the last decade, most research in Machine Learning contributed to the improvement of existing models, with the aim of increasing the performance of neural networks for the solution of a variety of different tasks. However, such advancements often come at the cost of an increase of model memory and computational requirements. This represents a significant limitation for the deployability of research output in realistic settings, where the cost, the energy consumption, and the complexity of the framework play a crucial role. To solve this issue, the designer should search for models that maximise the performance while limiting its footprint. Typical approaches to reach this goal rely either on manual procedures, which cannot guarantee the optimality of the final design, or upon Neural Architecture Search algorithms to automatise the process, at the expenses of extremely high computational time. This paper provides a solution for the fast identification of a neural network that maximis
    
[^91]: 基于最小描述长度和结构稳定性的脉冲神经网络的泛化研究

    On the Generalization of Spiking Neural Networks via Minimum Description Length and Structural Stability. (arXiv:2207.04876v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2207.04876](http://arxiv.org/abs/2207.04876)

    本研究通过利用最小描述长度原则和结构稳定性为脉冲神经网络提供了一个明确的泛化界限，并指定了最大稳定分歧解数的下限和上限。

    

    过去几十年中，由于其对于建模时间相关数据的潜力，脉冲神经网络引起了越来越多的关注。许多经验算法和技术已经被开发出来。然而，从理论上讲，训练后的脉冲神经网络在未见数据上的表现仍然是未知的。本研究通过利用最小描述长度原则，为脉冲神经网络提供一个明确的泛化界限。此外，我们通过结构稳定性实施了SNN的描述长度，并指定了最大稳定分歧解数的下限和上限，将在SNN中确定结构稳定性的挑战转化为一个具有定量特性的数学问题。

    The past decades have witnessed an increasing interest in spiking neural networks due to their great potential of modeling time-dependent data. Many empirical algorithms and techniques have been developed. However, theoretically, it remains unknown whether and to what extent a trained spiking neural network performs well on unseen data. This work takes one step in this direction by exploiting the minimum description length principle and thus, presents an explicit generalization bound for spiking neural networks. Further, we implement the description length of SNNs through structural stability and specify the lower and upper bounds of the maximum number of stable bifurcation solutions, which convert the challenge of qualifying structural stability in SNNs into a mathematical problem with quantitative properties.
    
[^92]: 基于确定性有限状态自动机的精确最可能解和约束优化的更快方法

    Faster Exact MPE and Constrained Optimization with Deterministic Finite State Automata. (arXiv:2108.03899v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2108.03899](http://arxiv.org/abs/2108.03899)

    本文提出了一种基于确定性有限状态自动机的简洁函数表示方法FABE，可以更快地处理图模型中的精确最可能解和约束优化任务。在基准测试中，FABE通常优于现有技术，导致显着的运行时间改进（高达5个数量级）。

    

    我们提出了一种基于确定性有限状态自动机的简洁函数表示，用于解决图模型中的精确最可能解和约束优化任务。然后我们在Bucket消除（BE）中利用我们简洁的表示方法，我们将我们的BE版本称为FABE。通过最小化冗余，FABE显著改善了BE在运行时间和内存需求方面的性能。在最可能解和加权约束满足基准测试中的结果表明，FABE通常优于现有技术，导致显着的运行时间改进（在我们的测试中高达5个数量级）。

    We propose a concise function representation based on deterministic finite state automata for exact most probable explanation and constrained optimization tasks in graphical models. We then exploit our concise representation within Bucket Elimination (BE). We denote our version of BE as FABE. FABE significantly improves the performance of BE in terms of runtime and memory requirements by minimizing redundancy. Results on most probable explanation and weighted constraint satisfaction benchmarks show that FABE often outperforms the state of the art, leading to significant runtime improvements (up to 5 orders of magnitude in our tests).
    
[^93]: 现代非线性函数回归模型：使用神经网络分析功能数据

    Modern Non-Linear Function-on-Function Regression. (arXiv:2107.14151v1 [stat.ME] CROSS LISTED)

    [http://arxiv.org/abs/2107.14151](http://arxiv.org/abs/2107.14151)

    本研究提出一种利用神经网络分析功能数据的新型非线性函数回归模型，通过连续隐藏层实现对功能响应建模，并提供了两种模型拟合策略（FDNN和FBNN），并通过正则化技术得到更加简明的结果。

    

    本论文引入了一种新的非线性函数回归模型类，使用神经网络分析功能数据。我们提出了一个框架，使用由连续神经元组成的隐藏层，称为连续隐藏层，用于功能响应建模，并提供了两种模型拟合策略：功能直接神经网络（FDNN）和功能基础神经网络（FBNN）。这两种方法都是专门设计来利用功能数据固有的结构，并捕捉功能预测变量和功能响应变量之间存在的复杂关系。我们通过求解函数梯度并实施正则化技术进行模型拟合，得到更简明的结果。我们通过广泛的模拟研究和实际数据示例展示了我们提出的方法在处理复杂功能模型方面的强大灵活性。

    We introduce a new class of non-linear function-on-function regression models for functional data using neural networks. We propose a framework using a hidden layer consisting of continuous neurons, called a continuous hidden layer, for functional response modeling and give two model fitting strategies, Functional Direct Neural Network (FDNN) and Functional Basis Neural Network (FBNN). Both are designed explicitly to exploit the structure inherent in functional data and capture the complex relations existing between the functional predictors and the functional response. We fit these models by deriving functional gradients and implement regularization techniques for more parsimonious results. We demonstrate the power and flexibility of our proposed method in handling complex functional models through extensive simulation studies as well as real data examples.
    
[^94]: 基于神经网络的非线性函数建模

    Non-linear Functional Modeling using Neural Networks. (arXiv:2104.09371v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2104.09371](http://arxiv.org/abs/2104.09371)

    本文提出了一种基于神经网络的、适用于函数数据的新型非线性模型。我们提出了两种变体，旨在显式利用函数数据中固有的结构，并通过全面的模拟研究和实际数据示例证明了该方法的有效性。

    

    本文介绍了一种基于神经网络的新型非线性函数数据模型。深度学习在非线性建模方面非常成功，但在函数数据设置方面却很少有研究。我们提出了两种变体：一种是具有连续隐藏层的函数神经网络，称为函数直接神经网络（FDNN），另一种则利用基扩展和连续隐藏层，称为基函数神经网络（FBNN）。两种变体都是设计用来显式利用函数数据中固有的结构。为了拟合这些模型，我们导出了一种基于函数梯度的优化算法。我们通过全面的模拟研究和实际数据示例展示了所提出方法在处理复杂函数模型方面的有效性。

    We introduce a new class of non-linear models for functional data based on neural networks. Deep learning has been very successful in non-linear modeling, but there has been little work done in the functional data setting. We propose two variations of our framework: a functional neural network with continuous hidden layers, called the Functional Direct Neural Network (FDNN), and a second version that utilizes basis expansions and continuous hidden layers, called the Functional Basis Neural Network (FBNN). Both are designed explicitly to exploit the structure inherent in functional data. To fit these models we derive a functional gradient based optimization algorithm. The effectiveness of the proposed methods in handling complex functional models is demonstrated by comprehensive simulation studies and real data examples.
    

