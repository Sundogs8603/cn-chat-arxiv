# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [RAVEN: In-Context Learning with Retrieval Augmented Encoder-Decoder Language Models.](http://arxiv.org/abs/2308.07922) | RAVEN是一种结合了检索增强的蒙特卡洛语言建模和前缀语言建模的模型，通过引入上下文融合学习，它能够在上下文学习方面取得比ATLAS更好的性能。 |
| [^2] | [Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification.](http://arxiv.org/abs/2308.07921) | 本文研究了使用GPT-4代码解释器解决数学问题的方法，并提出了显式的基于代码的自我验证（CSV）方法，用于进一步提升GPT-4 Code Interpreter的数学推理能力。 |
| [^3] | [Relightable and Animatable Neural Avatar from Sparse-View Video.](http://arxiv.org/abs/2308.07903) | 本文提出了一种从稀疏视角视频中创建可重光和可动化的神经化身的方法，通过使用Hierarchical Distance Query（HDQ）算法来近似任意人体姿态下的世界空间距离，并使用这些距离来进行材料恢复和重光。 |
| [^4] | [Through the Lens of Core Competency: Survey on Evaluation of Large Language Models.](http://arxiv.org/abs/2308.07902) | 本论文通过核心竞争力的视角，调查了大型语言模型(LLM)评估的多篇论文，总结出LLM的4个核心竞争力：推理能力、知识能力、可靠性和安全性，并介绍了对应的基准和评估指标。 |
| [^5] | [Probabilistic Phase Labeling and Lattice Refinement for Autonomous Material Research.](http://arxiv.org/abs/2308.07897) | CrystalShift是一种高效的算法，用于自主材料研究中的概率XRD相位标记和晶格细化。它通过采用对称约束的伪细化优化、最佳优先树搜索和贝叶斯模型比较来估计相位组合的概率，无需相位空间信息或训练。与现有方法相比，CrystalShift在合成和实验数据集上提供了稳健的概率估计，并可以轻松集成到高通量实验工作流程中。 |
| [^6] | [EduSAT: A Pedagogical Tool for Theory and Applications of Boolean Satisfiability.](http://arxiv.org/abs/2308.07890) | EduSAT是一个教学工具，用于支持SAT和SMT求解的学习和理解。它提供了关键算法的实现，且可以应用于SAT和SMT的解决以及其他NP完全问题的求解。 |
| [^7] | [A Comprehensive Study on Knowledge Graph Embedding over Relational Patterns Based on Rule Learning.](http://arxiv.org/abs/2308.07889) | 本研究主要通过对7个知识图嵌入模型在4种常见关系模式上的性能评估，以及理论、实体频率和整体分析，探讨了知识图嵌入模型在不同关系模式下的能力，并得出了一些具有讽刺意味的结论。 |
| [^8] | [Towards Temporal Edge Regression: A Case Study on Agriculture Trade Between Nations.](http://arxiv.org/abs/2308.07883) | 本文研究了国家间农业贸易的时态边缘回归任务，探索了使用图神经网络（GNNs）进行边缘回归的应用。实验结果显示现有GNNs的不足，提出了TGN作为边缘回归任务的更合适选择。 |
| [^9] | [The $10 Million ANA Avatar XPRIZE Competition Advanced Immersive Telepresence Systems.](http://arxiv.org/abs/2308.07878) | 1000万美元的ANA Avatar XPRIZE竞赛旨在开发能够实时传送人类存在感到远程位置的化身系统。竞赛决赛中，参与者展示了对远程与人类进行互动的支持、探索新环境以及使用专业技能的能力。 |
| [^10] | [Synthesizing Political Zero-Shot Relation Classification via Codebook Knowledge, NLI, and ChatGPT.](http://arxiv.org/abs/2308.07876) | 该论文通过利用已建立的注释编码本的知识，探索零样本方法用于政治事件本体关系分类，并介绍一种基于自然语言推理的方法，名为ZSP。ZSP采用了一种树查询框架，提高了解释性、效率和对模式更改的适应性。在细粒度根代码分类上，ZSP的性能明显优于ChatGPT，F1得分提高了40%。 |
| [^11] | [Emotion Embeddings $\unicode{x2014}$ Learning Stable and Homogeneous Abstractions from Heterogeneous Affective Datasets.](http://arxiv.org/abs/2308.07871) | 这篇论文提出了一种统一的计算模型，通过学习情感嵌入，独立于不同的语言、交流方式、媒体或标签形式，从而将以往对不同类型异质情感数据的研究整合起来。 |
| [^12] | [Brain-Inspired Computational Intelligence via Predictive Coding.](http://arxiv.org/abs/2308.07870) | 这项研究介绍了一种通过预测编码的脑启发式计算智能方法，它可以解决现有人工智能方法的一些重要限制，并具有在机器学习领域有希望的应用潜力。 |
| [^13] | [Impression-Aware Recommender Systems.](http://arxiv.org/abs/2308.07857) | 基于印象的推荐系统利用印象数据源提升推荐质量，通过综述分类推荐系统、数据集和评估方法，揭示开放性问题和未来研究方向。 |
| [^14] | [REFORMS: Reporting Standards for Machine Learning Based Science.](http://arxiv.org/abs/2308.07832) | REFORMS是一个基于机器学习的科学报告标准，旨在解决使用机器学习方法在科学研究中出现的有效性、可重复性和可推广性失败问题。这个标准由32个问题和一套指导方针组成，可作为研究人员设计和实施科研时的参考资源。 |
| [^15] | [Learning to Identify Critical States for Reinforcement Learning from Videos.](http://arxiv.org/abs/2308.07795) | 该论文提出了一种名为深度状态识别器的方法，能够从视频中学习识别关键状态，并预测强化学习的回报。该方法在理解和改善智能体行为方面具有潜力。 |
| [^16] | [Informed Named Entity Recognition Decoding for Generative Language Models.](http://arxiv.org/abs/2308.07791) | 该论文提出了一种利用生成式语言模型进行命名实体识别解码的方法，通过在信息提取过程中应用生成模型的语言理解能力，提高了性能并消除了幻觉的风险。 |
| [^17] | [Do We Fully Understand Students' Knowledge States? Identifying and Mitigating Answer Bias in Knowledge Tracing.](http://arxiv.org/abs/2308.07779) | 本文针对知识追踪中常见的答案偏见现象提出了一种新的COunterfactual REasoning (CORE)框架，从因果关系的角度解决了问题，并减轻了答案偏见对于学生知识状态理解的影响。 |
| [^18] | [Hierarchical generative modelling for autonomous robots.](http://arxiv.org/abs/2308.07775) | 该论文研究了自主机器人操作中运动控制的分层生成建模方法，通过模仿人类的深层时间结构来实现多级规划和协调肢体运动，以实现复杂的整体身体动作。 |
| [^19] | [A Graph Encoder-Decoder Network for Unsupervised Anomaly Detection.](http://arxiv.org/abs/2308.07774) | 本文提出了一种无监督图编码解码模型，用于检测图中的异常节点。在编码阶段，通过设计一种新的池化机制，该模型能够根据节点的异常程度对节点进行排序。模型的池化过程具有较低的计算复杂度和更高的可解释性。 |
| [^20] | [MOLE: MOdular Learning FramEwork via Mutual Information Maximization.](http://arxiv.org/abs/2308.07772) | MOLE是一种异步和本地化的神经网络学习框架，它通过层次化的模块化方式和最大化互信息的方法来进行训练，具有局部优化和梯度隔离的特性，并且在不同类型的数据上都有良好的应用效果。 |
| [^21] | [Evaluating the anticipated outcomes of MRI seizure image from open-source tool- Prototype approach.](http://arxiv.org/abs/2308.07762) | 本论文评估了开源工具在MRI癫痫图像处理中的应用，展示了MATLAB等工具的范围和使用率，并介绍了其他开源软件工具在磁共振癫痫图像研究中的应用。 |
| [^22] | [NeFL: Nested Federated Learning for Heterogeneous Clients.](http://arxiv.org/abs/2308.07761) | NeFL是一个嵌套联邦学习框架，通过深度和宽度缩放将模型有效地划分为子模型，解决了在联邦学习中由于慢或能力有限的客户端导致的训练时间延长和性能下降的问题。 |
| [^23] | [Dynamic Embedding Size Search with Minimum Regret for Streaming Recommender System.](http://arxiv.org/abs/2308.07760) | 本文针对流式推荐系统中嵌入尺寸设置问题，将动态嵌入尺寸搜索建模为一个强盗问题，并从统计学角度分析和量化影响最佳嵌入尺寸的因素。 |
| [^24] | [Backward Reasoning in Large Language Models for Verification.](http://arxiv.org/abs/2308.07758) | 本文研究了在大型语言模型中使用反向推理进行验证的方法。作者提出了一种新颖的技术，通过屏蔽问题中的一个标记，并要求语言模型预测被屏蔽的标记来验证候选答案。同时，作者还提出了一种结合正向和反向推理的方法来估计候选答案的概率。 |
| [^25] | [Dancing Avatar: Pose and Text-Guided Human Motion Videos Synthesis with Image Diffusion Model.](http://arxiv.org/abs/2308.07749) | 该论文提出了一种名为舞蹈化身的方法，通过姿势和文本引导生成高质量的人体动作视频。创新之处在于巧妙地利用T2I扩散模型连续生成视频帧，并解决了保持人物特征和服装一致性以及背景连续性的困难。通过设计帧内对齐模块，确保整个视频中人物外观一致。 |
| [^26] | [Exploiting Sparsity in Automotive Radar Object Detection Networks.](http://arxiv.org/abs/2308.07748) | 本文研究了在汽车雷达目标检测网络中利用稀疏性的方法，提出了稀疏核心点柱体和双体素点卷积来解决网格渲染和稀疏骨干结构问题。实验结果显示，这种方法在Car AP4.0上优于基准模型5.89%和先前的最优模型4.19%，并将平均尺度误差相对于基准模型减少了21.41%。 |
| [^27] | [Formally-Sharp DAgger for MCTS: Lower-Latency Monte Carlo Tree Search using Data Aggregation with Formal Methods.](http://arxiv.org/abs/2308.07738) | 本研究提出了一种使用形式方法指导蒙特卡罗树搜索以生成高质量决策的算法。通过训练神经网络来模仿生成的策略，并在低延迟搜索或最小延迟情况下作为完整策略使用。模拟实验结果表明该方法的有效性和性能提升。 |
| [^28] | [Flashpoints Signal Hidden Inherent Instabilities in Land-Use Planning.](http://arxiv.org/abs/2308.07714) | 这项研究发现了土地利用规划中的内在不稳定性，即微小的规划优先级变化会导致大规模的土地利用变化。这一发现对于改善土地利用决策具有重要意义。 |
| [^29] | [Exploring Transfer Learning in Medical Image Segmentation using Vision-Language Models.](http://arxiv.org/abs/2308.07706) | 本论文提出使用视觉-语言模型进行医学图像分割的迁移学习，并评估了其在医学领域的可迁移性。通过捕捉语义信息和引入新的图像描述变化，实现了对多样化医学图像的分割。 |
| [^30] | [DiffGuard: Semantic Mismatch-Guided Out-of-Distribution Detection using Pre-trained Diffusion Models.](http://arxiv.org/abs/2308.07687) | 本论文提出了一种名为DiffGuard的方法，使用预训练的扩散模型进行语义不匹配引导的带外分布检测。实验证明，DiffGuard在小规模数据集上表现出色，但在ImageNet规模的数据集上无法应用。 |
| [^31] | [Boosting Multi-modal Model Performance with Adaptive Gradient Modulation.](http://arxiv.org/abs/2308.07686) | 本论文提出了一种自适应梯度调节方法，能够提升多模态模型的性能，并引入了一种新的度量竞争强度的指标。 |
| [^32] | [EQ-Net: Elastic Quantization Neural Networks.](http://arxiv.org/abs/2308.07650) | 本文提出了EQ-Net，一种弹性量化神经网络，旨在训练一个灵活的权重共享量化超网络。通过探索弹性量化空间和引入权重分布正则化损失和分组渐进引导损失，本文解决了现有模型量化方法中对不同场景重复优化的局限性。 |
| [^33] | [Ternary Singular Value Decomposition as a Better Parameterized Form in Linear Mapping.](http://arxiv.org/abs/2308.07641) | 本文提出了一种名为三元奇异值分解 (TSVD) 的新颖线性映射参数化形式，通过限制奇异值分解中的矩阵为三元矩阵形式，它在网络压缩性能方面表现出色。实验证明，TSVD在各种类型的网络和任务中都能实现最先进的网络压缩性能。 |
| [^34] | [LLM-Mini-CEX: Automatic Evaluation of Large Language Model for Diagnostic Conversation.](http://arxiv.org/abs/2308.07635) | 本研究提出了一种用于诊断对话的自动评估方法，通过建立LLM-specific Mini-CEX评估标准和使用患者模拟器与ChatGPT自动评估诊断对话，解决了医学LLMs评估中的统一和全面性问题。 |
| [^35] | [A Survey on Model Compression for Large Language Models.](http://arxiv.org/abs/2308.07633) | 本论文提供了关于大型语言模型的模型压缩综述，探讨了量化、修剪、知识蒸馏等不同方法，并突出介绍了最新进展和创新方法，为实现高效的部署提供了重要思路。 |
| [^36] | [Vision-based Semantic Communications for Metaverse Services: A Contest Theoretic Approach.](http://arxiv.org/abs/2308.07618) | 本文提出了一个基于竞赛理论的语义通信框架，用于实现元宇宙服务中用户和服务提供商之间的优化资源分配。通过减少传输数据量和使用深度Q网络优化奖励，实现了实时同步和减少网络资源消耗。 |
| [^37] | [SGDiff: A Style Guided Diffusion Model for Fashion Synthesis.](http://arxiv.org/abs/2308.07605) | 这个论文介绍了一种名为SGDiff的风格引导扩散模型，通过结合图像模态和预训练的文本到图像扩散模型，成功地实现了创造性时尚图像合成。它通过引入辅助风格引导、减少训练成本以及克服文本输入限制等方式，克服了现有模型的局限性。此外，还提出了一个专门为时尚图像合成设计的数据集SG-Fashion，通过全面的实验证明了所提出模型的有效性。 |
| [^38] | [Generating Personas for Games with Multimodal Adversarial Imitation Learning.](http://arxiv.org/abs/2308.07598) | 本论文介绍了一种使用多模态对抗模仿学习的方法，可以生成多个游戏角色策略，以用于游戏测试。这种方法通过使用多个判别器作为奖励模型，并根据辅助输入对每个判别器的奖励进行加权，有效地建模各种人类游戏风格。 |
| [^39] | [AutoLTS: Automating Cycling Stress Assessment via Contrastive Learning and Spatial Post-processing.](http://arxiv.org/abs/2308.07580) | 本文提出了一个基于深度学习的框架，通过对比学习和空间后处理实现自动化骑行压力评估。在缺乏高质量的道路几何和汽车交通数据的情况下，利用街景图像数据能够准确、快速地评估城市道路网络的骑行压力。 |
| [^40] | [Story Visualization by Online Text Augmentation with Context Memory.](http://arxiv.org/abs/2308.07575) | 本论文提出了一种通过在线文本增强和上下文记忆来进行故事可视化的方法。通过使用新颖的记忆架构和多个伪描述作为训练过程的补充监督，该方法在两个故事可视化基准测试中取得了显著优于现有方法的结果。 |
| [^41] | [Action Class Relation Detection and Classification Across Multiple Video Datasets.](http://arxiv.org/abs/2308.07558) | 本论文提出了一种在多个视频数据集上检测和分类行动类别关系的方法，并通过语言和视觉信息来预测行动类别之间的关系。实验结果表明，预训练的神经网络模型对提高预测性能有贡献，基于行动标签文本的关系预测更准确，通过综合两种模态的预测结果可以进一步改进预测性能。 |
| [^42] | [Reinforcement Learning (RL) Augmented Cold Start Frequency Reduction in Serverless Computing.](http://arxiv.org/abs/2308.07541) | 本文提出了一种基于强化学习的方法来降低无服务器计算中的冷启动频率。通过使用Q学习和考虑多种指标，我们可以在预期需求的基础上提前初始化函数，从而减少冷启动次数。 |
| [^43] | [Domain Adaptation via Minimax Entropy for Real/Bogus Classification of Astronomical Alerts.](http://arxiv.org/abs/2308.07538) | 本文研究了用于天文警报真伪分类的领域适应方法，通过使用微调方法和半监督深度领域适应（MME）来提高分类模型的性能。实验证明，微调模型和MME模型都能在只有少数标记数据的情况下显著改进基本模型。 |
| [^44] | [Nonlinearity, Feedback and Uniform Consistency in Causal Structural Learning.](http://arxiv.org/abs/2308.07520) | 这篇论文研究了非线性、反馈和因果结构学习中的一致性问题，并提出了一个弱于强可靠性的k-Triangle Faithfulness的替代定义。 |
| [^45] | [Boosting Semi-Supervised Learning by bridging high and low-confidence predictions.](http://arxiv.org/abs/2308.07509) | 该论文提出了一种名为ReFixMatch的方法，通过连接高和低置信度的预测来解决半监督学习中的伪标签问题，并充分利用所有无标签数据进行训练。 |
| [^46] | [Detecting The Corruption Of Online Questionnaires By Artificial Intelligence.](http://arxiv.org/abs/2308.07499) | 这项研究发现，基于人工智能的大型语言模型使得不良行为者能够自动填写在线问卷，威胁到数据质量。目前，无法有效检测人工智能生成的文本，需要依赖不良行为者的不积极性来保证数据质量。 |
| [^47] | [DREAMWALKER: Mental Planning for Continuous Vision-Language Navigation.](http://arxiv.org/abs/2308.07498) | DREAMWALKER是一种基于世界模型的连续视觉-语言导航代理，通过在内部抽象世界中模拟和评估可能的计划，实现了智能的和可解释的规划行为。 |
| [^48] | [ST-MLP: A Cascaded Spatio-Temporal Linear Framework with Channel-Independence Strategy for Traffic Forecasting.](http://arxiv.org/abs/2308.07496) | ST-MLP是一种基于级联多层感知器（MLP）模块和线性层的时空模型，通过成功实现分组独立策略的时间序列预测技术，将时间信息、空间信息和预定义的图结构结合起来。实验结果表明ST-MLP在精度和计算效率方面优于其他模型。 |
| [^49] | [Omega-Regular Reward Machines.](http://arxiv.org/abs/2308.07469) | 本文引入了ω-正规奖励机器，将奖励机器与ω-正规语言集成在一起，为RL提供了一种表达能力强且有效的奖励机制。 |
| [^50] | [Playing with Words: Comparing the Vocabulary and Lexical Richness of ChatGPT and Humans.](http://arxiv.org/abs/2308.07462) | 这篇论文比较了ChatGPT和人类在词汇和词汇丰富度方面的差异，研究发现使用ChatGPT等工具会对词汇使用和词汇丰富度产生影响，这可能会对语言演变产生影响。 |
| [^51] | [Artificial Intelligence for Smart Transportation.](http://arxiv.org/abs/2308.07457) | 本论文调查了人工智能如何从交通机构的角度提高效率和增加利用率，以改善智能交通系统的设计，重点关注数据来源与数据、人工智能辅助决策和计算问题。 |
| [^52] | [GRU-D-Weibull: A Novel Real-Time Individualized Endpoint Prediction.](http://arxiv.org/abs/2308.07452) | GRU-D-Weibull是一种新型的实时个体化终点预测方法，结合了门控循环单元和衰减技术，用于建模威布尔分布。通过在慢性肾脏疾病患者队列中的评估，发现该方法在终点预测方面的性能优于其他竞争方法。 |
| [^53] | [The Performance of Transferability Metrics does not Translate to Medical Tasks.](http://arxiv.org/abs/2308.07444) | 该论文研究了转移能力指标在医学任务中的表现，并发现现有的转移能力指标无法可靠地估计目标在医学环境中的性能。 |
| [^54] | [Physics-Informed Deep Learning to Reduce the Bias in Joint Prediction of Nitrogen Oxides.](http://arxiv.org/abs/2308.07441) | 该论文提出了一个物理先验的深度学习框架，通过编码平流-扩散机制和流体动力学约束来联合预测NO2和NOx，并成功降低了机器学习模型的偏差。 |
| [^55] | [Interaction-Aware Personalized Vehicle Trajectory Prediction Using Temporal Graph Neural Networks.](http://arxiv.org/abs/2308.07439) | 本研究提出了一种交互感知的个性化车辆轨迹预测方法，利用时间图神经网络来建模目标车辆与周围交通之间的时空交互，并通过迁移学习来个性化预测。实验结果表明，该方法能够更准确地预测车辆的轨迹。 |
| [^56] | [Semantic Similarity Loss for Neural Source Code Summarization.](http://arxiv.org/abs/2308.07429) | 本文提出了一种适用于神经源代码摘要的改进损失函数，通过使用语义相似性度量来评估整个输出句子预测的损失，解决了当前方法中基于分类交叉熵损失函数的两个问题。 |
| [^57] | [UniBrain: Unify Image Reconstruction and Captioning All in One Diffusion Model from Human Brain Activity.](http://arxiv.org/abs/2308.07428) | UniBrain 是一个统一的图像重建和标题生成模型，通过使用名为Versatile Diffusion的潜变量扩散模型，结合fMRI的图像和文本条件，实现了从人脑活动中生成逼真的图像和标题。 |
| [^58] | [Exploring the Intersection of Large Language Models and Agent-Based Modeling via Prompt Engineering.](http://arxiv.org/abs/2308.07411) | 通过提示工程，我们使用大型语言模型进行人类互动模拟，包括两个Agent的谈判和六个Agent的谋杀之谜游戏。 |
| [^59] | [PARIS: Part-level Reconstruction and Motion Analysis for Articulated Objects.](http://arxiv.org/abs/2308.07391) | PARIS是一种面向关节物体的部分级别重建与运动分析方法，它使用自我监督的、端到端的架构来学习隐式形状和外观模型，并在没有3D监督的情况下优化运动参数。与其他基线方法相比，PARIS方法在重建和运动估计方面表现出色，对于对象的重建距离减少了45.2%，对于部分的重建距离减少了84.5%。 |
| [^60] | [Conformal Predictions Enhanced Expert-guided Meshing with Graph Neural Networks.](http://arxiv.org/abs/2308.07358) | 本研究提出了一种机器学习的方案，结合图神经网络和专家指导自动化生成计算流体力学网格，并引入了一种新的三维分割算法，用于表面分类。 |
| [^61] | [Demonstration of CORNET: A System For Learning Spreadsheet Formatting Rules By Example.](http://arxiv.org/abs/2308.07357) | CORNET是一个可以通过示例自动学习电子表格条件格式化规则的系统，它结合了归纳程序合成和符号规则枚举方法，并使用神经网络评估器生成准确的规则。 |
| [^62] | [Bayesian Physics-Informed Neural Network for the Forward and Inverse Simulation of Engineered Nano-particles Mobility in a Contaminated Aquifer.](http://arxiv.org/abs/2308.07352) | 本研究使用基于贝叶斯物理信息神经网络（B-PINN）的框架来模拟含水层中纳米颗粒的运动性，并为理解和开发高效的修复策略提供了预测性工具。 |
| [^63] | [IOB: Integrating Optimization Transfer and Behavior Transfer for Multi-Policy Reuse.](http://arxiv.org/abs/2308.07351) | 该论文提出了一种新颖的传递强化学习方法，通过在actor-critic框架中使用Q函数来选择源策略，解决了在有限样本下选择适当的源策略的挑战。 |
| [^64] | [Efficient Neural PDE-Solvers using Quantization Aware Training.](http://arxiv.org/abs/2308.07350) | 使用量化感知训练的高效神经PDE求解器研究了在减少计算成本方面的潜力，并证明了量化网络权重和激活可以成功降低计算成本而不损害性能。 |
| [^65] | [A Parallel Ensemble of Metaheuristic Solvers for the Traveling Salesman Problem.](http://arxiv.org/abs/2308.07347) | 这篇论文研究了并行集合中旅行商问题的元启发式求解器。通过将不同求解器结合使用，能够超越单个求解器的性能表现。 |
| [^66] | [Py-Tetrad and RPy-Tetrad: A New Python Interface with R Support for Tetrad Causal Search.](http://arxiv.org/abs/2308.07346) | Py-Tetrad和RPy-Tetrad是提供了新的Python和R接口的项目，用于将Python和R与Tetrad因果搜索工具进行接口化，解决了现有方法不足的问题。 |
| [^67] | [Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic.](http://arxiv.org/abs/2308.07336) | 本研究研究了一种从合成语料库中学习演绎推理能力的方法，通过采用基于形式逻辑理论的演绎规则，训练的语言模型具有更泛化的推理能力。 |
| [^68] | [An Encoder-Decoder Approach for Packing Circles.](http://arxiv.org/abs/2308.07335) | 本文提出了一个编码-解码的方法，用于将相同的圆形放置在一个较大的圆形中。该方法通过编码和解码过程，以及添加受控扰动来有效解决装填问题。 |
| [^69] | [Notation3 as an Existential Rule Language.](http://arxiv.org/abs/2308.07332) | 本文研究了Notation3与存在规则之间的关系，并提出了一个将部分Notation3直接映射到存在规则的方法，从而提高了Notation3推理的效率。 |
| [^70] | [Variations on the Reinforcement Learning performance of Blackjack.](http://arxiv.org/abs/2308.07329) | 本研究探讨了在不同的牌堆大小下，强化学习代理在Blackjack游戏中的表现变化。研究发现算法的学习收敛速度与牌堆大小有关，并展示了使用基本策略和HI-LO系统的牌数计数器如何使庄家破产。这项工作的创新之处在于认识到牌堆大小是影响Blackjack表现的关键因素。 |
| [^71] | [PokerKit: A Comprehensive Python Library for Fine-Grained Multi-Variant Poker Game Simulations.](http://arxiv.org/abs/2308.07327) | PokerKit是一个全面的Python库，用于细粒度多变体扑克游戏模拟，提供广泛的扑克变体支持和灵活的游戏状态控制，对扑克AI开发、工具创建和在线扑克赌场实现等领域具有重要贡献。 |
| [^72] | [AI Text-to-Behavior: A Study In Steerability.](http://arxiv.org/abs/2308.07326) | 本研究探讨了大型语言模型的可操控性，通过使用行为心理学框架，模型在生成文本时能够根据提示展现特定的行为特征。研究发现，模型在不同特征上的表现具有灵活性和区分度，并能够准确复制历史人物的个性和对话风格。 |
| [^73] | [MSLE: An ontology for Materials Science Laboratory Equipment. Large-Scale Devices for Materials Characterization.](http://arxiv.org/abs/2308.07325) | 本论文提出了一种用于材料科学实验室设备的新本体论MSLE，通过整合现有的本体论，建立一个一致的设备描述，为科学家们提供指导，解决了多种设备类型和规格的统一描述问题。 |
| [^74] | [Analytical Techniques to Support Hospital Case Mix Planning.](http://arxiv.org/abs/2308.07323) | 本文介绍了一种支持医院病例组合规划的分析技术和决策支持工具，包括优化模型和多目标决策技术，可以对医院容量进行信息量化评估。 |
| [^75] | [Multicriteria Optimization Techniques for Understanding the Case Mix Landscape of a Hospital.](http://arxiv.org/abs/2308.07322) | 本文提出了一种多准则优化方法来理解医院的病例组成，通过改进的并行化方法生成非支配病例组成存档，以提高容量利用率。 |
| [^76] | [The Efficacy of Utility Functions for Multicriteria Hospital Case-Mix Planning.](http://arxiv.org/abs/2308.07321) | 本文介绍了一种利用效用函数的多准则医院病例组合规划的新方法，通过提供一种方法来评估不同利益相关者和医院目标之间的权衡，解决了当前CMP中的各种技术限制和缺陷。 |
| [^77] | [LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked.](http://arxiv.org/abs/2308.07308) | 本文提出了一种通过自检来防御大型语言模型(LLMs)对抗性攻击的简单方法，即让模型自行过滤回应。实验结果表明，即使模型未对齐人类价值观，通过使用语言模型验证内容，仍然可以防止模型向用户呈现有害内容。 |
| [^78] | [Why Not? Explaining Missing Entailments with Evee (Technical Report).](http://arxiv.org/abs/2308.07294) | 本文介绍了新版本的Evee插件，它通过基于绑定和反例的技术来解释本体中缺失的蕴涵关系。 |
| [^79] | [#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models.](http://arxiv.org/abs/2308.07074) | 本研究提出了InsTag，一种用于标记基于语义和意图的监督微调（SFT）数据集样本的开放式细粒度标注器。通过分析开源SFT数据集，发现模型能力会随着更多多样化和复杂化的数据而增长。基于这一观察结果，使用InsTag选择的数据进行模型微调，得到的TagLM模型在大规模SFT数据上优于开源模型，验证了查询多样性和复杂性的重要性。 |
| [^80] | [SAILOR: Structural Augmentation Based Tail Node Representation Learning.](http://arxiv.org/abs/2308.06801) | SAILOR是一种基于结构增强的尾节点表示学习框架，针对真实场景中长尾分布的图节点度数，通过学习增强图结构和提取更有信息的尾节点表示，解决了GNN在尾节点表示上的性能退化问题。 |
| [^81] | [MC-DRE: Multi-Aspect Cross Integration for Drug Event/Entity Extraction.](http://arxiv.org/abs/2308.06546) | 本文提出了一个新的多方面交叉整合框架，用于从药物相关文档中提取药物事件/实体。该框架能够捕捉并对齐不同的上下文/语言/知识属性，并实现药物事件信息的全面检测和理解。 |
| [^82] | [Testing GPT-4 with Wolfram Alpha and Code Interpreter plug-ins on math and science problems.](http://arxiv.org/abs/2308.05713) | 本研究测试了GPT-4在科学和数学问题上使用Wolfram Alpha和Code Interpreter插件的效果，结果表明插件显著提升了GPT的问题解决能力，但接口故障仍然是其可靠性的主要挑战。 |
| [^83] | [Diffusion Model in Causal Inference with Unmeasured Confounders.](http://arxiv.org/abs/2308.03669) | 本研究扩展了扩散模型的使用，提出了一种新的模型BDCM，可以在存在无法测量的混淆因素的情况下更准确地回答因果问题。 |
| [^84] | [SynJax: Structured Probability Distributions for JAX.](http://arxiv.org/abs/2308.03291) | SynJax是一个针对JAX的结构化概率分布库，通过提供高效的向量化实现解决了对于结构化对象的难以实现的问题。 |
| [^85] | [Source-free Domain Adaptive Human Pose Estimation.](http://arxiv.org/abs/2308.03202) | 提出了无源域自适应的人体姿势估计任务，旨在解决在适应过程中无法访问源数据的跨域学习挑战。通过提出的新框架，源保护模块更有效地保留源信息并抵抗噪声。 |
| [^86] | [MiAMix: Enhancing Image Classification through a Multi-stage Augmented Mixied Sample Data Augmentation Method.](http://arxiv.org/abs/2308.02804) | MiAMix是一种新型的混合样本数据增强方法，通过将图像增强集成到混合框架中并利用多种多样的混合方法来提升图像分类模型的性能和泛化能力。 |
| [^87] | [LaFiCMIL: Rethinking Large File Classification from the Perspective of Correlated Multiple Instance Learning.](http://arxiv.org/abs/2308.01413) | LaFiCMIL是一个新的方法，从相关多实例学习的角度解决了Transformer模型输入长度限制的问题，可以用于改进大文件分类任务。 |
| [^88] | [PromptStyler: Prompt-driven Style Generation for Source-free Domain Generalization.](http://arxiv.org/abs/2307.15199) | 提出了PromptStyler，通过使用提示合成样式特征，解决了无源域泛化的问题。该方法通过学习样式词向量生成多样的样式，并通过强制样式内容特征与内容特征靠近来保证样式不会扭曲内容信息。在多个数据集上取得了最先进的结果。 |
| [^89] | [Deep Bradley-Terry Rating: Estimate Properties Without Metric of Unseen Items.](http://arxiv.org/abs/2307.13709) | 本论文提出了深度布拉德利-特里评分（DBTR）方法，用于评估不一定存在于数据集中的未知物品的属性。该方法通过将传统的布拉德利-特里模型与神经网络结构无缝结合，成功地学习了这些属性的预期量化。 |
| [^90] | [PromptMagician: Interactive Prompt Engineering for Text-to-Image Creation.](http://arxiv.org/abs/2307.09036) | PromptMagician是一个交互式的提示工程系统，可以帮助用户针对文本到图像生成任务发展出高效的提示，并通过多级可视化和个性化探索支持用户在输入提示过程中的交互和迭代。 |
| [^91] | [Anomaly Detection in Automated Fibre Placement: Learning with Data Limitations.](http://arxiv.org/abs/2307.07893) | 本文提出了一种在数据有限的情况下，通过自动编码器进行异常检测的方法，利用纤维层片的深度图进行二分类，并使用重构误差作为量化指标。 |
| [^92] | [Principles and Guidelines for Evaluating Social Robot Navigation Algorithms.](http://arxiv.org/abs/2306.16740) | 本文提出了评估社交机器人导航算法的原则与指南，为解决在人类居住环境中导航的挑战提供了可重复和可比较的基准标准。 |
| [^93] | [DiffSketcher: Text Guided Vector Sketch Synthesis through Latent Diffusion Models.](http://arxiv.org/abs/2306.14685) | 本文介绍了DiffSketcher，一种通过隐式扩散模型实现文本引导的矢量素描合成的创新算法。DiffSketcher通过直接优化贝塞尔曲线和扩散模型损失来生成矢量化的手绘素描，并通过注意力图加快生成过程。实验结果表明DiffSketcher的素描质量高于之前方法。 |
| [^94] | [Deep Reinforcement Learning with Multitask Episodic Memory Based on Task-Conditioned Hypernetwork.](http://arxiv.org/abs/2306.10698) | 人工智能领域，一个新算法利用基于任务条件化超网络的检索网络，根据任务调整网络参数，以解决深度强化学习中选择最相关的过去经验并将其融合到既有决策网络中的问题。 |
| [^95] | [Virtual Human Generative Model: Masked Modeling Approach for Learning Human Characteristics.](http://arxiv.org/abs/2306.10656) | 本论文提出了一种名为VHGM的深度生成模型，基于掩码建模的方法来学习健康属性、生活方式和人格之间的关系。通过使用异构表格数据集，VHGM有效地学习了超过1,800个属性。该模型具有潜在的应用前景，例如用于医疗属性的虚拟测量和生活方式的假设验证。 |
| [^96] | [Time-aware Graph Structure Learning via Sequence Prediction on Temporal Graphs.](http://arxiv.org/abs/2306.07699) | 该论文提出了一种基于时间图序列预测的时态图结构学习方法，通过添加潜在的时间边来学习更好的图像结构，提高下游任务的性能。 |
| [^97] | [Policy Regularization with Dataset Constraint for Offline Reinforcement Learning.](http://arxiv.org/abs/2306.06569) | 本文提出了一种离线强化学习方法，称为PRDC，它使用数据集约束来正则化学习策略。相比于现有方法，PRDC可以更有效地指导策略的更新，并提高其性能。 |
| [^98] | [A Bio-Inspired Chaos Sensor Model Based on the Perceptron Neural Network: Machine Learning Concept and Application for Computational Neuro-Science.](http://arxiv.org/abs/2306.01991) | 该论文介绍了一种基于感知器神经网络的生物灵感混沌传感器模型，用于估计神经动力学系统中脉冲序列的熵。经过训练，该模型能够以高精度近似一个短时间序列的模糊熵，即使隐藏层只有一个神经元，也能够达到良好的结果。 |
| [^99] | [GripRank: Bridging the Gap between Retrieval and Generation via the Generative Knowledge Improved Passage Ranking.](http://arxiv.org/abs/2305.18144) | GripRank是一种通过将生成式知识应用于段落排序，填补检索和文本生成之间差距的方法。 |
| [^100] | [Formal Modelling for Multi-Robot Systems Under Uncertainty.](http://arxiv.org/abs/2305.17018) | 通过考虑不确定性和机器人交互对动作执行的影响，研究者提出了更准确捕捉多机器人系统执行的建模形式。其他工作还提出了降低模型规模以提高解决效率的方法。 |
| [^101] | [Lightweight Online Learning for Sets of Related Problems in Automated Reasoning.](http://arxiv.org/abs/2305.11087) | 本文提出了一种自动推理中解决一组相关问题的轻量级在线学习方法，它能够自动收集信息并拟合机器学习模型来调整解决策略。在实验中证明该方法能证明更大的边界和发现更多反例。 |
| [^102] | [ANTONIO: Towards a Systematic Method of Generating NLP Benchmarks for Verification.](http://arxiv.org/abs/2305.04003) | 本文介绍了一种名为ANTONIO的Python库，它基于抽象解释方法提供了一种实用的方法和启发式规则，以便为自然语言处理（NLP）数据集和模型生成已知验证方法的基准。因为其普遍适用性，这项工作将为将NLP验证问题纳入神经网络验证比赛开辟新的可能性，并在NLP问题中普及这一方向。 |
| [^103] | [Optimizing the AI Development Process by Providing the Best Support Environment.](http://arxiv.org/abs/2305.00136) | 本研究旨在提供人工智能（AI）和机器学习（ML）应用的最佳支持环境，具体重点研究了ML开发中数据管理阶段的障碍以及如何构建和开发一个框架，利用多种数据增强技术来解决数据管理阶段缺乏足够数据的问题。 |
| [^104] | [Implicit Temporal Modeling with Learnable Alignment for Video Recognition.](http://arxiv.org/abs/2304.10465) | 本文提出了一种隐式学习对齐方法，通过预测交互点并增强周围特征，实现两帧视频的隐式对齐，同时最小化时间建模的工作量。 |
| [^105] | [Decidability of Querying First-Order Theories via Countermodels of Finite Width.](http://arxiv.org/abs/2304.06348) | 通过有限宽度的反模型查询一阶理论的可决定性并提出分割宽度，使其能够捕获实际相关的查询语言 |
| [^106] | [Probe: Learning Users' Personalized Projection Bias in Intertemporal Bundle Choices.](http://arxiv.org/abs/2303.06016) | 本文提出了一种新的偏差嵌入式偏好模型——Probe，旨在解决用户在时间跨度的购物选择中的投影偏差和参照点效应，提高决策的有效性和个性化。 |
| [^107] | [Semantic-aware Node Synthesis for Imbalanced Heterogeneous Information Networks.](http://arxiv.org/abs/2302.14061) | 这项研究提出了一种解决不平衡异构信息网络中语义不平衡的方法，通过合成节点来应对少数类别的样本不足和偏倚的问题。 |
| [^108] | [SGL-PT: A Strong Graph Learner with Graph Prompt Tuning.](http://arxiv.org/abs/2302.12449) | SGL-PT是一个具有图形提示调优的强大图形学习器，以缩小预训练和下游图形任务之间的差距，并提供一致的训练目标来增强预训练模型的能力。 |
| [^109] | [InfiniCity: Infinite-Scale City Synthesis.](http://arxiv.org/abs/2301.09637) | InfiniCity是一个无限规模的城市合成框架，可以从随机噪音构建和渲染一个无限制大小的3D环境，具有可扩展的功能和交互式编辑。 |
| [^110] | [Quality at the Tail.](http://arxiv.org/abs/2212.13925) | 本研究发现深度学习推理质量存在波动，引入了“尾部质量”的概念来描述这一现象。 |
| [^111] | [End-to-end AI framework for interpretable prediction of molecular and crystal properties.](http://arxiv.org/abs/2212.11317) | 我们引入了一个端到端的AI框架，利用最先进的模型和计算环境，可以预测分子和晶体的属性，提供了可解释的推断功能，并在领先的计算设施中进行了部署和测试。 |
| [^112] | [FedALA: Adaptive Local Aggregation for Personalized Federated Learning.](http://arxiv.org/abs/2212.01197) | FedALA是一种用于个性化联邦学习的方法，通过自适应局部聚合（ALA）模块来解决统计异质性问题，并在广泛的实验证明中超过了11种最先进的基准模型。 |
| [^113] | [Catastrophic overfitting can be induced with discriminative non-robust features.](http://arxiv.org/abs/2206.08242) | 本研究通过控制性修改典型的自然图像数据集，研究了对抗训练中灾难性过度拟合的出现。通过注入看似无害的特征，可以在较小的epsilon值下引发灾难性过度拟合。 |
| [^114] | [Positive Unlabeled Contrastive Learning.](http://arxiv.org/abs/2206.01206) | 我们提出了一种正样本未标记对比学习的新方法，通过扩展对比损失和使用PU特定聚类方案，该方法在PU任务中学习到了优秀的表示，并在多个标准数据集上明显优于现有方法。 |

# 详细

[^1]: RAVEN：上下文学习与检索增强的编码器-解码器语言模型

    RAVEN: In-Context Learning with Retrieval Augmented Encoder-Decoder Language Models. (arXiv:2308.07922v1 [cs.CL])

    [http://arxiv.org/abs/2308.07922](http://arxiv.org/abs/2308.07922)

    RAVEN是一种结合了检索增强的蒙特卡洛语言建模和前缀语言建模的模型，通过引入上下文融合学习，它能够在上下文学习方面取得比ATLAS更好的性能。

    

    本文研究了检索增强的编码器-解码器语言模型在上下文学习方面的能力。我们首先对现有的ATLAS模型进行全面分析，发现其在上下文学习方面存在限制，主要原因是预训练和测试之间存在不匹配，以及上下文长度受限。为了解决这些问题，我们提出了RAVEN模型，该模型结合了检索增强的蒙特卡洛语言建模和前缀语言建模。我们还引入了上下文融合学习，通过使模型能够利用更多上下文示例而无需额外训练或模型修改来提高少样本性能。通过大量实验，我们证明了RAVEN在某些场景下明显优于ATLAS，并达到了与最先进的语言模型相当的结果，尽管参数数量显著较少。我们的工作强调了检索增强的编码器-解码器语言模型的潜力。

    In this paper, we investigate the in-context learning ability of retrieval-augmented encoder-decoder language models. We first conduct a comprehensive analysis of the state-of-the-art ATLAS model and identify its limitations in in-context learning, primarily due to a mismatch between pretraining and testing, as well as a restricted context length. To address these issues, we propose RAVEN, a model that combines retrieval-augmented masked language modeling and prefix language modeling. We further introduce Fusion-in-Context Learning to enhance the few-shot performance by enabling the model to leverage more in-context examples without requiring additional training or model modifications. Through extensive experiments, we demonstrate that RAVEN significantly outperforms ATLAS and achieves results comparable to the most advanced language models in certain scenarios, despite having substantially fewer parameters. Our work underscores the potential of retrieval-augmented encoder-decoder lang
    
[^2]: 使用GPT-4代码解释器和基于代码的自我验证解决具有挑战性的数学问题

    Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with Code-based Self-Verification. (arXiv:2308.07921v1 [cs.CL])

    [http://arxiv.org/abs/2308.07921](http://arxiv.org/abs/2308.07921)

    本文研究了使用GPT-4代码解释器解决数学问题的方法，并提出了显式的基于代码的自我验证（CSV）方法，用于进一步提升GPT-4 Code Interpreter的数学推理能力。

    

    最近大型语言模型（LLMs）如GPT-4和PaLM-2在解决数学推理问题方面取得了显著进展。尤其是OpenAI的最新版本GPT-4 Code Interpreter在挑战性的数学数据集上表现出色。本文通过引入不同的约束条件，探讨了代码对提升LLMs推理能力的影响。我们发现其成功很大程度上归功于其在生成和执行代码、评估代码执行结果以及修正解决方案时的强大技巧。基于这一洞察，我们提出了一种新颖有效的提示方法，即显式的基于代码的自我验证（CSV），以进一步提升GPT-4 Code Interpreter的数学推理潜力。该方法在GPT-4 Code Interpreter上采用零-shot提示，鼓励其使用代码进行推理。

    Recent progress in large language models (LLMs) like GPT-4 and PaLM-2 has brought significant advancements in addressing math reasoning problems. In particular, OpenAI's latest version of GPT-4, known as GPT-4 Code Interpreter, shows remarkable performance on challenging math datasets. In this paper, we explore the effect of code on enhancing LLMs' reasoning capability by introducing different constraints on the \textit{Code Usage Frequency} of GPT-4 Code Interpreter. We found that its success can be largely attributed to its powerful skills in generating and executing code, evaluating the output of code execution, and rectifying its solution when receiving unreasonable outputs. Based on this insight, we propose a novel and effective prompting method, explicit \uline{c}ode-based \uline{s}elf-\uline{v}erification~(CSV), to further boost the mathematical reasoning potential of GPT-4 Code Interpreter. This method employs a zero-shot prompt on GPT-4 Code Interpreter to encourage it to use 
    
[^3]: 从稀疏视角视频中生成可重光和可动化的神经化身

    Relightable and Animatable Neural Avatar from Sparse-View Video. (arXiv:2308.07903v1 [cs.CV])

    [http://arxiv.org/abs/2308.07903](http://arxiv.org/abs/2308.07903)

    本文提出了一种从稀疏视角视频中创建可重光和可动化的神经化身的方法，通过使用Hierarchical Distance Query（HDQ）算法来近似任意人体姿态下的世界空间距离，并使用这些距离来进行材料恢复和重光。

    

    本文解决了从未知照明条件下的稀疏视角（甚至单目）视频中创建可重光和可动化的神经化身的挑战。与工作室环境相比，这个设置更实际和可行，但是面临一个极具挑战性的逆问题。之前的神经人类重建方法能够使用变形有符号距离场（SDF）从稀疏视角重建可动化的化身，但无法恢复用于重光的材料参数。虽然可微逆渲染方法已成功地恢复了静态对象的材料，但对于动态人类，将其扩展为动态人体是不直观的，因为在变形SDF上计算像素-表面相交和光能见度对于逆渲染来说是计算密集型的。为了解决这个挑战，我们提出了一种分层距离查询（HDQ）算法来近似任意人体姿态下的世界空间距离。具体来说，我们估算了粗略的距离值，然后使用迭代过程来提高距离估算的精度，并使用这些估算出的距离值进行材料恢复和重光。

    This paper tackles the challenge of creating relightable and animatable neural avatars from sparse-view (or even monocular) videos of dynamic humans under unknown illumination. Compared to studio environments, this setting is more practical and accessible but poses an extremely challenging ill-posed problem. Previous neural human reconstruction methods are able to reconstruct animatable avatars from sparse views using deformed Signed Distance Fields (SDF) but cannot recover material parameters for relighting. While differentiable inverse rendering-based methods have succeeded in material recovery of static objects, it is not straightforward to extend them to dynamic humans as it is computationally intensive to compute pixel-surface intersection and light visibility on deformed SDFs for inverse rendering. To solve this challenge, we propose a Hierarchical Distance Query (HDQ) algorithm to approximate the world space distances under arbitrary human poses. Specifically, we estimate coarse
    
[^4]: 通过核心竞争力的视角：大型语言模型评估调查

    Through the Lens of Core Competency: Survey on Evaluation of Large Language Models. (arXiv:2308.07902v1 [cs.CL])

    [http://arxiv.org/abs/2308.07902](http://arxiv.org/abs/2308.07902)

    本论文通过核心竞争力的视角，调查了大型语言模型(LLM)评估的多篇论文，总结出LLM的4个核心竞争力：推理能力、知识能力、可靠性和安全性，并介绍了对应的基准和评估指标。

    

    从预训练语言模型（PLM）到大型语言模型（LLM），自然语言处理（NLP）领域已经见证了快速的性能提升和广泛的实际应用。然而，由于LLM的卓越性能，对其进行全面评估极其困难，主要有两个原因：首先，传统的NLP任务在LLM表现出色之后变得不够适用；其次，现有的评估任务难以跟上实际场景中广泛应用的速度。为了解决这些问题，已有研究提出了各种基准来更好地评估LLM。为了澄清学术界和工业界中与LLM评估相关的众多论文，我们调查了多篇关于LLM评估的论文。我们总结了LLM的4个核心竞争力，包括推理能力、知识能力、可靠性和安全性。对于每个核心竞争力，我们介绍了其定义、对应的基准和评估指标。基于这个核心竞争力体系，类似的任务可进行比较。

    From pre-trained language model (PLM) to large language model (LLM), the field of natural language processing (NLP) has witnessed steep performance gains and wide practical uses. The evaluation of a research field guides its direction of improvement. However, LLMs are extremely hard to thoroughly evaluate for two reasons. First of all, traditional NLP tasks become inadequate due to the excellent performance of LLM. Secondly, existing evaluation tasks are difficult to keep up with the wide range of applications in real-world scenarios. To tackle these problems, existing works proposed various benchmarks to better evaluate LLMs. To clarify the numerous evaluation tasks in both academia and industry, we investigate multiple papers concerning LLM evaluations. We summarize 4 core competencies of LLM, including reasoning, knowledge, reliability, and safety. For every competency, we introduce its definition, corresponding benchmarks, and metrics. Under this competency architecture, similar ta
    
[^5]: 用于自主材料研究的概率相位标记和晶格细化

    Probabilistic Phase Labeling and Lattice Refinement for Autonomous Material Research. (arXiv:2308.07897v1 [cond-mat.mtrl-sci])

    [http://arxiv.org/abs/2308.07897](http://arxiv.org/abs/2308.07897)

    CrystalShift是一种高效的算法，用于自主材料研究中的概率XRD相位标记和晶格细化。它通过采用对称约束的伪细化优化、最佳优先树搜索和贝叶斯模型比较来估计相位组合的概率，无需相位空间信息或训练。与现有方法相比，CrystalShift在合成和实验数据集上提供了稳健的概率估计，并可以轻松集成到高通量实验工作流程中。

    

    X射线衍射（XRD）是一种确定材料晶体结构的基本技术，在自主科学发现过程中最近被应用于人工智能代理中。然而，快速、自动化和可靠的XRD数据分析方法与输入数据速率相匹配仍然是一个重大挑战。为了解决这些问题，我们提出了CrystalShift，一种用于概率XRD相位标记的高效算法，它采用了对称约束的伪细化优化、最佳优先树搜索和贝叶斯模型比较，可以估计相位组合的概率，而无需相位空间信息或训练。我们证明了CrystalShift提供了稳健的概率估计，在合成和实验数据集上表现优于现有方法，并可以轻松集成到高通量实验工作流程中。除了高效的相位映射，CrystalShift还提供了定量的内在贡献。

    X-ray diffraction (XRD) is an essential technique to determine a material's crystal structure in high-throughput experimentation, and has recently been incorporated in artificially intelligent agents in autonomous scientific discovery processes. However, rapid, automated and reliable analysis method of XRD data matching the incoming data rate remains a major challenge. To address these issues, we present CrystalShift, an efficient algorithm for probabilistic XRD phase labeling that employs symmetry-constrained pseudo-refinement optimization, best-first tree search, and Bayesian model comparison to estimate probabilities for phase combinations without requiring phase space information or training. We demonstrate that CrystalShift provides robust probability estimates, outperforming existing methods on synthetic and experimental datasets, and can be readily integrated into high-throughput experimental workflows. In addition to efficient phase-mapping, CrystalShift offers quantitative ins
    
[^6]: EduSAT: 用于布尔可满足性理论和应用的教学工具

    EduSAT: A Pedagogical Tool for Theory and Applications of Boolean Satisfiability. (arXiv:2308.07890v1 [cs.AI])

    [http://arxiv.org/abs/2308.07890](http://arxiv.org/abs/2308.07890)

    EduSAT是一个教学工具，用于支持SAT和SMT求解的学习和理解。它提供了关键算法的实现，且可以应用于SAT和SMT的解决以及其他NP完全问题的求解。

    

    布尔可满足性（SAT）和可满足性模型理论（SMT）在自动验证中被广泛应用，但在这个领域缺乏专门用于教育目的的交互式工具。为了填补这个空白，我们提出了EduSAT，这是一个专门为支持SAT和SMT求解的学习和理解而开发的教学工具。EduSAT提供了关键算法的实现，如Davis-Putnam-Logemann-Loveland（DPLL）算法和简化的二进制决策图（ROBDD）用于SAT求解。此外，EduSAT还为SAT和SMT之外的五个NP完全问题提供求解器抽象。用户可以通过使用EduSAT进行实验、分析和验证对SAT和SMT求解技术的理解。我们的工具配有全面的文档和教程，广泛的测试，以及实用的功能，如自然语言界面和SAT和SMT公式生成器，这也为学习者提供了宝贵的机会。

    Boolean Satisfiability (SAT) and Satisfiability Modulo Theories (SMT) are widely used in automated verification, but there is a lack of interactive tools designed for educational purposes in this field. To address this gap, we present EduSAT, a pedagogical tool specifically developed to support learning and understanding of SAT and SMT solving. EduSAT offers implementations of key algorithms such as the Davis-Putnam-Logemann-Loveland (DPLL) algorithm and the Reduced Order Binary Decision Diagram (ROBDD) for SAT solving. Additionally, EduSAT provides solver abstractions for five NP-complete problems beyond SAT and SMT. Users can benefit from EduSAT by experimenting, analyzing, and validating their understanding of SAT and SMT solving techniques. Our tool is accompanied by comprehensive documentation and tutorials, extensive testing, and practical features such as a natural language interface and SAT and SMT formula generators, which also serve as a valuable opportunity for learners to d
    
[^7]: 基于规则学习的关系模式的知识图嵌入的综合研究

    A Comprehensive Study on Knowledge Graph Embedding over Relational Patterns Based on Rule Learning. (arXiv:2308.07889v1 [cs.AI])

    [http://arxiv.org/abs/2308.07889](http://arxiv.org/abs/2308.07889)

    本研究主要通过对7个知识图嵌入模型在4种常见关系模式上的性能评估，以及理论、实体频率和整体分析，探讨了知识图嵌入模型在不同关系模式下的能力，并得出了一些具有讽刺意味的结论。

    

    知识图嵌入（KGE）已被证明是解决知识图补全（KGC）任务的有效方法。关系模式是指具有特定语义的关系，展示图形模式，是影响KGE模型性能的重要因素。尽管理论上分析了KGE模型在不同关系模式上的能力，并建立了更好的关系模式建模与KGC更好性能之间的粗略关联，但对于KGE模型在关系模式上的综合定量分析尚未完成，因此不确定KGE对于关系模式的理论支持如何影响与此关系模式相关的三元组的性能。为解决这个挑战，我们评估了7个KGE模型在4个常见关系模式上的性能，并在2个基准数据集上进行了理论、实体频率和整体分析，得出了一些直观的结论。

    Knowledge Graph Embedding (KGE) has proven to be an effective approach to solving the Knowledge Graph Completion (KGC) task. Relational patterns which refer to relations with specific semantics exhibiting graph patterns are an important factor in the performance of KGE models. Though KGE models' capabilities are analyzed over different relational patterns in theory and a rough connection between better relational patterns modeling and better performance of KGC has been built, a comprehensive quantitative analysis on KGE models over relational patterns remains absent so it is uncertain how the theoretical support of KGE to a relational pattern contributes to the performance of triples associated to such a relational pattern. To address this challenge, we evaluate the performance of 7 KGE models over 4 common relational patterns on 2 benchmarks, then conduct an analysis in theory, entity frequency, and part-to-whole three aspects and get some counterintuitive conclusions. Finally, we int
    
[^8]: 迈向时态边缘回归：关于国家间农业贸易的案例研究

    Towards Temporal Edge Regression: A Case Study on Agriculture Trade Between Nations. (arXiv:2308.07883v1 [cs.LG])

    [http://arxiv.org/abs/2308.07883](http://arxiv.org/abs/2308.07883)

    本文研究了国家间农业贸易的时态边缘回归任务，探索了使用图神经网络（GNNs）进行边缘回归的应用。实验结果显示现有GNNs的不足，提出了TGN作为边缘回归任务的更合适选择。

    

    最近，图神经网络（GNNs）在动态图任务如节点分类、链接预测和图回归等方面表现出了很有前景的性能。然而，很少有工作研究了具有重要现实应用的时态边缘回归任务。在本文中，我们探索了GNNs在静态和动态设置下边缘回归任务中的应用，重点是预测国家之间的食品和农业贸易价值。我们引入了三个简单但强大的基准线，并使用联合国贸易数据集全面评估了一个静态和三个动态GNN模型。我们的实验结果表明，这些基线在各种设置下表现出异常强大的性能，突显了现有GNNs的不足之处。我们还发现，TGN优于其他GNN模型，这表明TGN是边缘回归任务的更合适选择。此外，我们注意到训练样本中负边的比例显著影响了测试的结果。

    Recently, Graph Neural Networks (GNNs) have shown promising performance in tasks on dynamic graphs such as node classification, link prediction and graph regression. However, few work has studied the temporal edge regression task which has important real-world applications. In this paper, we explore the application of GNNs to edge regression tasks in both static and dynamic settings, focusing on predicting food and agriculture trade values between nations. We introduce three simple yet strong baselines and comprehensively evaluate one static and three dynamic GNN models using the UN Trade dataset. Our experimental results reveal that the baselines exhibit remarkably strong performance across various settings, highlighting the inadequacy of existing GNNs. We also find that TGN outperforms other GNN models, suggesting TGN is a more appropriate choice for edge regression tasks. Moreover, we note that the proportion of negative edges in the training samples significantly affects the test p
    
[^9]: 1000万美元的ANA Avatar XPRIZE竞赛先进的沉浸式远程交互系统

    The $10 Million ANA Avatar XPRIZE Competition Advanced Immersive Telepresence Systems. (arXiv:2308.07878v1 [cs.RO])

    [http://arxiv.org/abs/2308.07878](http://arxiv.org/abs/2308.07878)

    1000万美元的ANA Avatar XPRIZE竞赛旨在开发能够实时传送人类存在感到远程位置的化身系统。竞赛决赛中，参与者展示了对远程与人类进行互动的支持、探索新环境以及使用专业技能的能力。

    

    1000万美元的ANA Avatar XPRIZE旨在创建能够实时传送人类存在感到远程位置的化身系统。这个多年的竞赛中，参与者开发了机器人系统，使运营者能够以真实存在的方式在远程环境中看到、听到和交互。另一方面，远程环境中的人们会觉得操作者就在化身机器人内。在2022年11月于美国加利福尼亚州长滩举行的竞赛决赛中，化身系统根据其对远程与人类进行互动的支持、探索新环境以及使用专业技能进行评估。本文描述了竞赛阶段的任务和评估程序，报告了结果，介绍了获胜团队的方法，并讨论了所得到的经验教训。

    The $10M ANA Avatar XPRIZE aimed to create avatar systems that can transport human presence to remote locations in real time. The participants of this multi-year competition developed robotic systems that allow operators to see, hear, and interact with a remote environment in a way that feels as if they are truly there. On the other hand, people in the remote environment were given the impression that the operator was present inside the avatar robot. At the competition finals, held in November 2022 in Long Beach, CA, USA, the avatar systems were evaluated on their support for remotely interacting with humans, exploring new environments, and employing specialized skills. This article describes the competition stages with tasks and evaluation procedures, reports the results, presents the winning teams' approaches, and discusses lessons learned.
    
[^10]: 通过编码本知识、自然语言推理和ChatGPT来合成政治零样本关系分类

    Synthesizing Political Zero-Shot Relation Classification via Codebook Knowledge, NLI, and ChatGPT. (arXiv:2308.07876v1 [cs.CL])

    [http://arxiv.org/abs/2308.07876](http://arxiv.org/abs/2308.07876)

    该论文通过利用已建立的注释编码本的知识，探索零样本方法用于政治事件本体关系分类，并介绍一种基于自然语言推理的方法，名为ZSP。ZSP采用了一种树查询框架，提高了解释性、效率和对模式更改的适应性。在细粒度根代码分类上，ZSP的性能明显优于ChatGPT，F1得分提高了40%。

    

    最近的事件编码的监督模型在性能方面远远超过模式匹配方法。然而，它们仅仅依赖于新的注释，忽视了专家数据库中的大量知识，限制了它们在细粒度分类中的适用性。为了解决这些限制，我们通过利用已建立的注释编码本的知识，探索零样本方法用于政治事件本体关系分类。我们的研究涵盖了ChatGPT和一种新颖的基于自然语言推理的方法，名为ZSP。ZSP采用了一种树查询框架，将任务分解为上下文、语态和类别消歧的不同层次。该框架提高了解释性、效率和对模式更改的适应性。通过在我们新策划的数据集上进行大量实验，我们指出了ChatGPT中的不稳定性问题，并突出了ZSP的卓越性能。ZSP在细粒度根代码分类的F1得分上取得了令人印象深刻的提高40%。

    Recent supervised models for event coding vastly outperform pattern-matching methods. However, their reliance solely on new annotations disregards the vast knowledge within expert databases, hindering their applicability to fine-grained classification. To address these limitations, we explore zero-shot approaches for political event ontology relation classification, by leveraging knowledge from established annotation codebooks. Our study encompasses both ChatGPT and a novel natural language inference (NLI) based approach named ZSP. ZSP adopts a tree-query framework that deconstructs the task into context, modality, and class disambiguation levels. This framework improves interpretability, efficiency, and adaptability to schema changes. By conducting extensive experiments on our newly curated datasets, we pinpoint the instability issues within ChatGPT and highlight the superior performance of ZSP. ZSP achieves an impressive 40% improvement in F1 score for fine-grained Rootcode classific
    
[^11]: 情感嵌入——从异质情感数据中学习稳定且均匀的抽象表示

    Emotion Embeddings $\unicode{x2014}$ Learning Stable and Homogeneous Abstractions from Heterogeneous Affective Datasets. (arXiv:2308.07871v1 [cs.LG])

    [http://arxiv.org/abs/2308.07871](http://arxiv.org/abs/2308.07871)

    这篇论文提出了一种统一的计算模型，通过学习情感嵌入，独立于不同的语言、交流方式、媒体或标签形式，从而将以往对不同类型异质情感数据的研究整合起来。

    

    人类情感通过多种交流方式和媒体格式表达，因此它们的计算研究同样多样化，涉及到自然语言处理、音频信号分析、计算机视觉等等。在先前的研究中，情感被以不同的形式进行描述（极性尺度、基本情感类别、维度方法、评价理论等），导致数据集、预测模型和情感分析软件工具的多样化增长。由于这两种不同类型的异质性，在表达和表示层面上，迫切需要统一以往对越来越分散的数据和标签类型的研究成果。本文提出了一个统一的计算模型。我们提出了一种训练过程，可以学习一种共享的情感潜在表示，即所谓情感嵌入，不依赖于不同的自然语言、交流方式、媒体或表示标签形式。

    Human emotion is expressed in many communication modalities and media formats and so their computational study is equally diversified into natural language processing, audio signal analysis, computer vision, etc. Similarly, the large variety of representation formats used in previous research to describe emotions (polarity scales, basic emotion categories, dimensional approaches, appraisal theory, etc.) have led to an ever proliferating diversity of datasets, predictive models, and software tools for emotion analysis. Because of these two distinct types of heterogeneity, at the expressional and representational level, there is a dire need to unify previous work on increasingly diverging data and label types. This article presents such a unifying computational model. We propose a training procedure that learns a shared latent representation for emotions, so-called emotion embeddings, independent of different natural languages, communication modalities, media or representation label form
    
[^12]: 通过预测编码实现脑启发式计算智能

    Brain-Inspired Computational Intelligence via Predictive Coding. (arXiv:2308.07870v1 [cs.AI])

    [http://arxiv.org/abs/2308.07870](http://arxiv.org/abs/2308.07870)

    这项研究介绍了一种通过预测编码的脑启发式计算智能方法，它可以解决现有人工智能方法的一些重要限制，并具有在机器学习领域有希望的应用潜力。

    

    人工智能（AI）正在迅速成为本世纪的关键技术之一。到目前为止，在AI领域取得的大部分成果都是使用误差反向传播学习算法训练的深度神经网络所实现的。然而，这种方法的普及应用已经凸显出了一些重要的局限性，例如计算成本高、难以量化不确定性、缺乏鲁棒性、不可靠性和生物学上的不合理性。解决这些限制可能需要受到神经科学理论的启发和指导的方案。其中一种理论称为预测编码（PC），在机器智能任务中表现出有希望的性能，具有令人兴奋的特性，使其在机器学习社区中具有潜在的价值：PC可以模拟不同脑区的信息处理，可以用于认知控制和机器人技术，并在变分推理方面具有坚实的数学基础，提供了一个强大的工具。

    Artificial intelligence (AI) is rapidly becoming one of the key technologies of this century. The majority of results in AI thus far have been achieved using deep neural networks trained with the error backpropagation learning algorithm. However, the ubiquitous adoption of this approach has highlighted some important limitations such as substantial computational cost, difficulty in quantifying uncertainty, lack of robustness, unreliability, and biological implausibility. It is possible that addressing these limitations may require schemes that are inspired and guided by neuroscience theories. One such theory, called predictive coding (PC), has shown promising performance in machine intelligence tasks, exhibiting exciting properties that make it potentially valuable for the machine learning community: PC can model information processing in different brain areas, can be used in cognitive control and robotics, and has a solid mathematical grounding in variational inference, offering a pow
    
[^13]: 基于印象的推荐系统

    Impression-Aware Recommender Systems. (arXiv:2308.07857v1 [cs.IR])

    [http://arxiv.org/abs/2308.07857](http://arxiv.org/abs/2308.07857)

    基于印象的推荐系统利用印象数据源提升推荐质量，通过综述分类推荐系统、数据集和评估方法，揭示开放性问题和未来研究方向。

    

    新型数据源为改进推荐系统的质量带来了新的机遇。印象是一种包含过去推荐（展示的项目）和传统互动的新型数据源。研究人员可以利用印象来优化用户偏好并克服当前推荐系统研究中的限制。印象的相关性和兴趣度逐年增加，因此需要对这类推荐系统中相关工作进行综述。我们提出了一篇关于使用印象的推荐系统的系统文献综述，侧重于研究中的三个基本方面：推荐系统、数据集和评估方法。我们对使用印象的推荐系统的论文进行了三个分类，详细介绍了每篇综述论文，描述了具有印象的数据集，并分析了现有的评估方法。最后，我们提出了值得关注的开放性问题和未来的研究方向，强调了文献中缺失的方面。

    Novel data sources bring new opportunities to improve the quality of recommender systems. Impressions are a novel data source containing past recommendations (shown items) and traditional interactions. Researchers may use impressions to refine user preferences and overcome the current limitations in recommender systems research. The relevance and interest of impressions have increased over the years; hence, the need for a review of relevant work on this type of recommenders. We present a systematic literature review on recommender systems using impressions, focusing on three fundamental angles in research: recommenders, datasets, and evaluation methodologies. We provide three categorizations of papers describing recommenders using impressions, present each reviewed paper in detail, describe datasets with impressions, and analyze the existing evaluation methodologies. Lastly, we present open questions and future directions of interest, highlighting aspects missing in the literature that
    
[^14]: REFORMS: 基于机器学习的科学报告标准

    REFORMS: Reporting Standards for Machine Learning Based Science. (arXiv:2308.07832v1 [cs.LG])

    [http://arxiv.org/abs/2308.07832](http://arxiv.org/abs/2308.07832)

    REFORMS是一个基于机器学习的科学报告标准，旨在解决使用机器学习方法在科学研究中出现的有效性、可重复性和可推广性失败问题。这个标准由32个问题和一套指导方针组成，可作为研究人员设计和实施科研时的参考资源。

    

    机器学习方法在科学研究中得到了广泛应用。然而，这些方法的采用也伴随着有效性、可重复性和可推广性的失败。这些失败可能会阻碍科学进展，导致对无效结论的错误共识，并削弱基于机器学习的科学的可信度。机器学习方法在不同学科中常常以相似的方式应用且失败。出于这个观察，我们的目标是为基于机器学习的科学提供清晰的报告标准。基于对过去文献的广泛评论，我们提出了REFORMS检查表（$\textbf{Re}$porting Standards $\textbf{For}$ $\textbf{M}$achine Learning Based $\textbf{S}$cience）。它由32个问题和一套配套的指导方针组成。REFORMS是基于19位研究人员的共识开发的，这些人来自计算机科学、数据科学、数学、社会科学和生物医学科学领域。REFORMS可以为研究人员在设计和实施科研时提供参考。

    Machine learning (ML) methods are proliferating in scientific research. However, the adoption of these methods has been accompanied by failures of validity, reproducibility, and generalizability. These failures can hinder scientific progress, lead to false consensus around invalid claims, and undermine the credibility of ML-based science. ML methods are often applied and fail in similar ways across disciplines. Motivated by this observation, our goal is to provide clear reporting standards for ML-based science. Drawing from an extensive review of past literature, we present the REFORMS checklist ($\textbf{Re}$porting Standards $\textbf{For}$ $\textbf{M}$achine Learning Based $\textbf{S}$cience). It consists of 32 questions and a paired set of guidelines. REFORMS was developed based on a consensus of 19 researchers across computer science, data science, mathematics, social sciences, and biomedical sciences. REFORMS can serve as a resource for researchers when designing and implementing 
    
[^15]: 从视频中学习识别强化学习的关键状态

    Learning to Identify Critical States for Reinforcement Learning from Videos. (arXiv:2308.07795v1 [cs.CV])

    [http://arxiv.org/abs/2308.07795](http://arxiv.org/abs/2308.07795)

    该论文提出了一种名为深度状态识别器的方法，能够从视频中学习识别关键状态，并预测强化学习的回报。该方法在理解和改善智能体行为方面具有潜力。

    

    最近关于深度强化学习(DRL)的研究指出，有关好策略的算法信息可以从缺乏执行动作明确信息的离线数据中提取出来。例如，人类或机器人的视频可能传达了很多有关奖励动作序列的隐含信息，但是想要从这些视频中观察并获益的DRL机器必须首先通过自身学习来识别和认可相关的状态/动作/奖励。在不依赖于地面真值标注的情况下，我们提出了一种被称为深度状态识别器的新方法，它学习预测被编码为视频的返回值。然后，它使用一种基于掩码的敏感性分析方法来提取/识别重要的关键状态。广泛的实验展示了我们的方法在理解和改善智能体行为方面的潜力。源代码和生成的数据集可以在https://github.com/AI-Initiative-KAUST/VideoRLCS 上找到。

    Recent work on deep reinforcement learning (DRL) has pointed out that algorithmic information about good policies can be extracted from offline data which lack explicit information about executed actions. For example, videos of humans or robots may convey a lot of implicit information about rewarding action sequences, but a DRL machine that wants to profit from watching such videos must first learn by itself to identify and recognize relevant states/actions/rewards. Without relying on ground-truth annotations, our new method called Deep State Identifier learns to predict returns from episodes encoded as videos. Then it uses a kind of mask-based sensitivity analysis to extract/identify important critical states. Extensive experiments showcase our method's potential for understanding and improving agent behavior. The source code and the generated datasets are available at https://github.com/AI-Initiative-KAUST/VideoRLCS.
    
[^16]: 为生成式语言模型提供信息的命名实体识别解码

    Informed Named Entity Recognition Decoding for Generative Language Models. (arXiv:2308.07791v1 [cs.CL])

    [http://arxiv.org/abs/2308.07791](http://arxiv.org/abs/2308.07791)

    该论文提出了一种利用生成式语言模型进行命名实体识别解码的方法，通过在信息提取过程中应用生成模型的语言理解能力，提高了性能并消除了幻觉的风险。

    

    越来越大的语言模型具有越来越强的能力，已成为被广泛应用的文本处理工具。然而，信息提取任务，如命名实体识别，仍然受到之前一代仅编码器的转换器模型的影响。在这里，我们提出了一种简单但有效的方法，称为Informed Named Entity Recognition Decoding（iNERD），它将命名实体识别视为一种生成过程。它以面向未来的方式利用最近生成模型的语言理解能力，并采用了一种基于信息提取的有限文本生成方法，提高了性能并消除了任何幻觉的风险。我们在合并的命名实体语料库上粗调优化了模型，评估了五个生成式语言模型在八个命名实体识别数据集上的表现，并取得了显著的结果。

    Ever-larger language models with ever-increasing capabilities are by now well-established text processing tools. Alas, information extraction tasks such as named entity recognition are still largely unaffected by this progress as they are primarily based on the previous generation of encoder-only transformer models. Here, we propose a simple yet effective approach, Informed Named Entity Recognition Decoding (iNERD), which treats named entity recognition as a generative process. It leverages the language understanding capabilities of recent generative models in a future-proof manner and employs an informed decoding scheme incorporating the restricted nature of information extraction into open-ended text generation, improving performance and eliminating any risk of hallucinations. We coarse-tune our model on a merged named entity corpus to strengthen its performance, evaluate five generative language models on eight named entity recognition datasets, and achieve remarkable results, espec
    
[^17]: 我们充分理解学生的知识状态吗？识别和减轻知识追踪中的答案偏见

    Do We Fully Understand Students' Knowledge States? Identifying and Mitigating Answer Bias in Knowledge Tracing. (arXiv:2308.07779v1 [cs.AI])

    [http://arxiv.org/abs/2308.07779](http://arxiv.org/abs/2308.07779)

    本文针对知识追踪中常见的答案偏见现象提出了一种新的COunterfactual REasoning (CORE)框架，从因果关系的角度解决了问题，并减轻了答案偏见对于学生知识状态理解的影响。

    

    知识追踪（KT）旨在通过学生与与概念相关的问题的学习互动来监测学生不断变化的知识状态，并可以通过预测学生在未来问题上的表现来进行间接评估。本文观察到一个常见的现象，即答案偏见，即每个问题的正确答案和错误答案高度不平衡的分布。现有模型倾向于将答案偏见作为一个捷径来实现在KT中的高预测性能，从而未能充分理解学生的知识状态。为了解决这个问题，我们从因果关系的角度来处理KT任务。首先建立了KT的因果图，从中我们确定了答案偏见对学生反应的直接因果效应。进一步提出了一种新颖的对策反事实推理（CORE）框架进行KT，该框架在训练过程中分别捕捉了总因果效应和直接因果效应，并减轻了答案偏见的影响。

    Knowledge tracing (KT) aims to monitor students' evolving knowledge states through their learning interactions with concept-related questions, and can be indirectly evaluated by predicting how students will perform on future questions. In this paper, we observe that there is a common phenomenon of answer bias, i.e., a highly unbalanced distribution of correct and incorrect answers for each question. Existing models tend to memorize the answer bias as a shortcut for achieving high prediction performance in KT, thereby failing to fully understand students' knowledge states. To address this issue, we approach the KT task from a causality perspective. A causal graph of KT is first established, from which we identify that the impact of answer bias lies in the direct causal effect of questions on students' responses. A novel COunterfactual REasoning (CORE) framework for KT is further proposed, which separately captures the total causal effect and direct causal effect during training, and mit
    
[^18]: 自主机器人的分层生成建模

    Hierarchical generative modelling for autonomous robots. (arXiv:2308.07775v1 [cs.RO])

    [http://arxiv.org/abs/2308.07775](http://arxiv.org/abs/2308.07775)

    该论文研究了自主机器人操作中运动控制的分层生成建模方法，通过模仿人类的深层时间结构来实现多级规划和协调肢体运动，以实现复杂的整体身体动作。

    

    人类在与周围环境互动时可以产生复杂的整体身体动作，通过计划、执行和组合各个肢体的运动。我们在自主机器人操作环境中探索了运动控制的这一基本方面。我们采用分层生成建模的方法来处理这个问题，该方法配备了多级规划，以模仿人类运动控制的深层时间结构。在这里，时间深度是指前向或生成模型的连续层次的嵌套时间尺度，例如，交付一个物体需要一个全局计划来上下文化多个肢体的快速协调。这种时间尺度的分离也推动了机器人和控制领域的发展。具体来说，为了实现多功能的感知动作控制，以分层结构化规划和低层肢体运动控制是有优势的。我们使用数值和物理模拟进行实验。

    Humans can produce complex whole-body motions when interacting with their surroundings, by planning, executing and combining individual limb movements. We investigated this fundamental aspect of motor control in the setting of autonomous robotic operations. We approach this problem by hierarchical generative modelling equipped with multi-level planning-for autonomous task completion-that mimics the deep temporal architecture of human motor control. Here, temporal depth refers to the nested time scales at which successive levels of a forward or generative model unfold, for example, delivering an object requires a global plan to contextualise the fast coordination of multiple local movements of limbs. This separation of temporal scales also motivates robotics and control. Specifically, to achieve versatile sensorimotor control, it is advantageous to hierarchically structure the planning and low-level motor control of individual limbs. We use numerical and physical simulation to conduct e
    
[^19]: 无监督异常检测的图编码解码网络

    A Graph Encoder-Decoder Network for Unsupervised Anomaly Detection. (arXiv:2308.07774v1 [cs.LG])

    [http://arxiv.org/abs/2308.07774](http://arxiv.org/abs/2308.07774)

    本文提出了一种无监督图编码解码模型，用于检测图中的异常节点。在编码阶段，通过设计一种新的池化机制，该模型能够根据节点的异常程度对节点进行排序。模型的池化过程具有较低的计算复杂度和更高的可解释性。

    

    许多图神经网络中的关键组件是池化操作，它旨在减小图的大小同时保留重要的结构信息。然而，大多数现有的图池化策略依赖于通过使用图神经网络层获得的分配矩阵，该矩阵具有可训练的参数，往往导致显著的计算复杂性和池化过程的缺乏可解释性。本文提出了一种无监督图编码解码模型，通过学习一种异常评分函数对节点进行排序，从而检测出图中的异常节点。在编码阶段，我们设计了一种新的池化机制，命名为LCPool，它利用局部约束线性编码进行特征编码，通过求解带有局部正则化项的最小二乘优化问题来找到聚类分配矩阵。通过在编码过程中强制执行局部约束，LCPool被设计成免费

    A key component of many graph neural networks (GNNs) is the pooling operation, which seeks to reduce the size of a graph while preserving important structural information. However, most existing graph pooling strategies rely on an assignment matrix obtained by employing a GNN layer, which is characterized by trainable parameters, often leading to significant computational complexity and a lack of interpretability in the pooling process. In this paper, we propose an unsupervised graph encoder-decoder model to detect abnormal nodes from graphs by learning an anomaly scoring function to rank nodes based on their degree of abnormality. In the encoding stage, we design a novel pooling mechanism, named LCPool, which leverages locality-constrained linear coding for feature encoding to find a cluster assignment matrix by solving a least-squares optimization problem with a locality regularization term. By enforcing locality constraints during the coding process, LCPool is designed to be free fr
    
[^20]: MOLE: MOdular Learning FramEwork通过最大化互信息引入了一种异步和本地化的神经网络学习框架

    MOLE: MOdular Learning FramEwork via Mutual Information Maximization. (arXiv:2308.07772v1 [cs.LG])

    [http://arxiv.org/abs/2308.07772](http://arxiv.org/abs/2308.07772)

    MOLE是一种异步和本地化的神经网络学习框架，它通过层次化的模块化方式和最大化互信息的方法来进行训练，具有局部优化和梯度隔离的特性，并且在不同类型的数据上都有良好的应用效果。

    

    本文介绍了一种名为MOLE（MOdular Learning Framework）的异步和本地化学习框架，该框架通过层次化的方式对神经网络进行模块化，并通过最大化互信息的方式定义了每个模块的训练目标，并按顺序通过最大化互信息的方法对每个模块进行训练。MOLE使得训练变得具有局部优化和模块之间梯度隔离的特性，这种方案在生物学上更具可行性，比反向传播更加合理。我们在向量、网格和图形类型的数据上进行了实验。特别地，这个框架能够解决图形类型数据的图形级和节点级任务。因此，通过实验证明MOLE可以广泛适用于不同类型的数据。

    This paper is to introduce an asynchronous and local learning framework for neural networks, named Modular Learning Framework (MOLE). This framework modularizes neural networks by layers, defines the training objective via mutual information for each module, and sequentially trains each module by mutual information maximization. MOLE makes the training become local optimization with gradient-isolated across modules, and this scheme is more biologically plausible than BP. We run experiments on vector-, grid- and graph-type data. In particular, this framework is capable of solving both graph- and node-level tasks for graph-type data. Therefore, MOLE has been experimentally proven to be universally applicable to different types of data.
    
[^21]: 评估开源工具MRI癫痫图像预期结果的原型方法

    Evaluating the anticipated outcomes of MRI seizure image from open-source tool- Prototype approach. (arXiv:2308.07762v1 [physics.med-ph])

    [http://arxiv.org/abs/2308.07762](http://arxiv.org/abs/2308.07762)

    本论文评估了开源工具在MRI癫痫图像处理中的应用，展示了MATLAB等工具的范围和使用率，并介绍了其他开源软件工具在磁共振癫痫图像研究中的应用。

    

    癫痫是大脑中异常的神经活动，影响全球近7000万人口（Ngugi et al., 2010）。许多开源神经影像工具用于代谢检查和分析。本文介绍了诸如MATLAB，Slicer 3D，Brain Suite21a，SPM和MedCalc等开源工具的范围。60%的研究人员使用MATLAB进行图像处理，10%的人使用自有软件。超过30%的研究人员在处理技术中使用其他开源软件工具来研究磁共振癫痫图像。

    Epileptic Seizure is an abnormal neuronal exertion in the brain, affecting nearly 70 million of the world's population (Ngugi et al., 2010). So many open-source neuroimaging tools are used for metabolism checkups and analysis purposes. The scope of open-source tools like MATLAB, Slicer 3D, Brain Suite21a, SPM, and MedCalc are explained in this paper. MATLAB was used by 60% of the researchers for their image processing and 10% of them use their proprietary software. More than 30% of the researchers use other open-source software tools with their processing techniques for the study of magnetic resonance seizure images
    
[^22]: NeFL: 针对异构客户端的嵌套联邦学习

    NeFL: Nested Federated Learning for Heterogeneous Clients. (arXiv:2308.07761v1 [cs.LG])

    [http://arxiv.org/abs/2308.07761](http://arxiv.org/abs/2308.07761)

    NeFL是一个嵌套联邦学习框架，通过深度和宽度缩放将模型有效地划分为子模型，解决了在联邦学习中由于慢或能力有限的客户端导致的训练时间延长和性能下降的问题。

    

    联邦学习是一种有希望的分布式学习方法，可以保持隐私。然而，在联邦学习的训练过程中，慢或能力有限的客户端（即阻塞者）会减慢总体训练时间并降低性能。系统的异构性，包括异构计算和网络带宽，已经被用来减轻阻塞者的影响。以往的研究将模型分割来解决这个问题，但在模型架构方面的自由度较小。我们提出了嵌套联邦学习（NeFL），这是一个通用的框架，可以使用深度和宽度缩放将模型有效地分成子模型。NeFL通过将模型解释为解决常微分方程（ODE）并使用自适应步长来实现。为了解决训练具有不同架构的多个子模型时出现的不一致性问题，我们解耦了一些参数。NeFL使资源受限的客户端能够有效地加入联邦学习流程，并使模型能够被训练。

    Federated learning (FL) is a promising approach in distributed learning keeping privacy. However, during the training pipeline of FL, slow or incapable clients (i.e., stragglers) slow down the total training time and degrade performance. System heterogeneity, including heterogeneous computing and network bandwidth, has been addressed to mitigate the impact of stragglers. Previous studies split models to tackle the issue, but with less degree-of-freedom in terms of model architecture. We propose nested federated learning (NeFL), a generalized framework that efficiently divides a model into submodels using both depthwise and widthwise scaling. NeFL is implemented by interpreting models as solving ordinary differential equations (ODEs) with adaptive step sizes. To address the inconsistency that arises when training multiple submodels with different architecture, we decouple a few parameters. NeFL enables resource-constrained clients to effectively join the FL pipeline and the model to be 
    
[^23]: 流式推荐系统的最小后悔动态嵌入尺寸搜索

    Dynamic Embedding Size Search with Minimum Regret for Streaming Recommender System. (arXiv:2308.07760v1 [cs.IR])

    [http://arxiv.org/abs/2308.07760](http://arxiv.org/abs/2308.07760)

    本文针对流式推荐系统中嵌入尺寸设置问题，将动态嵌入尺寸搜索建模为一个强盗问题，并从统计学角度分析和量化影响最佳嵌入尺寸的因素。

    

    随着用户和物品数量的不断增加，传统的静态数据集上训练的推荐系统很难适应不断变化的环境。高吞吐量的数据要求模型及时更新以捕捉用户兴趣动态，这导致了流式推荐系统的出现。由于基于深度学习的推荐系统的普及，嵌入层广泛采用以低维向量表示用户、物品和其他特征的特性。然而，已经证明设置相同和静态的嵌入尺寸在推荐性能和内存成本方面是次优的，特别是对于流式推荐。为解决这个问题，我们首先重新思考了流式模型更新过程，并将动态嵌入尺寸搜索建模为一个强盗问题。然后，我们从统计学角度分析和量化影响最佳嵌入尺寸的因素。

    With the continuous increase of users and items, conventional recommender systems trained on static datasets can hardly adapt to changing environments. The high-throughput data requires the model to be updated in a timely manner for capturing the user interest dynamics, which leads to the emergence of streaming recommender systems. Due to the prevalence of deep learning-based recommender systems, the embedding layer is widely adopted to represent the characteristics of users, items, and other features in low-dimensional vectors. However, it has been proved that setting an identical and static embedding size is sub-optimal in terms of recommendation performance and memory cost, especially for streaming recommendations. To tackle this problem, we first rethink the streaming model update process and model the dynamic embedding size search as a bandit problem. Then, we analyze and quantify the factors that influence the optimal embedding sizes from the statistics perspective. Based on this
    
[^24]: 在大型语言模型中使用反向推理进行验证

    Backward Reasoning in Large Language Models for Verification. (arXiv:2308.07758v1 [cs.CL])

    [http://arxiv.org/abs/2308.07758](http://arxiv.org/abs/2308.07758)

    本文研究了在大型语言模型中使用反向推理进行验证的方法。作者提出了一种新颖的技术，通过屏蔽问题中的一个标记，并要求语言模型预测被屏蔽的标记来验证候选答案。同时，作者还提出了一种结合正向和反向推理的方法来估计候选答案的概率。

    

    链式思考（Chain-of-Though, CoT）提示在各种推理任务中表现出了很好的性能。最近，Self-Consistency提出了一种方法，即通过采样一组不同的推理链，这些链可能导致不同的答案，然后选择得票最多的答案。本文提出了一种新颖的方法，即在验证候选答案时使用反向推理。我们使用一个简单的模板，即``如果我们知道上述问题的答案是候选答案，那么未知变量x的值是多少？''，将问题中的一个标记屏蔽，并要求语言模型预测被屏蔽的标记。直观上讲，如果提供的候选答案是正确的，语言模型应该能够成功预测被屏蔽的标记。我们进一步提出了FOBAR方法，将正向和反向推理结合起来估计候选答案的概率。我们在六个数据集和三个实验中进行了广泛的实验。

    Chain-of-Though (CoT) prompting has shown promising performance in various reasoning tasks. Recently, Self-Consistency \citep{wang2023selfconsistency} proposes to sample a diverse set of reasoning chains which may lead to different answers while the answer that receives the most votes is selected. In this paper, we propose a novel method to use backward reasoning in verifying candidate answers. We mask a token in the question by ${\bf x}$ and ask the LLM to predict the masked token when a candidate answer is provided by \textit{a simple template}, i.e., ``\textit{\textbf{If we know the answer of the above question is \{a candidate answer\}, what is the value of unknown variable ${\bf x}$?}}'' Intuitively, the LLM is expected to predict the masked token successfully if the provided candidate answer is correct. We further propose FOBAR to combine forward and backward reasoning for estimating the probability of candidate answers. We conduct extensive experiments on six data sets and three
    
[^25]: 舞蹈化身：通过图像扩散模型合成受姿势和文本引导的人体动作视频

    Dancing Avatar: Pose and Text-Guided Human Motion Videos Synthesis with Image Diffusion Model. (arXiv:2308.07749v1 [cs.CV])

    [http://arxiv.org/abs/2308.07749](http://arxiv.org/abs/2308.07749)

    该论文提出了一种名为舞蹈化身的方法，通过姿势和文本引导生成高质量的人体动作视频。创新之处在于巧妙地利用T2I扩散模型连续生成视频帧，并解决了保持人物特征和服装一致性以及背景连续性的困难。通过设计帧内对齐模块，确保整个视频中人物外观一致。

    

    在数字领域中创建逼真化身的需求日益增长，需要通过文本描述和姿势来生成高质量的人体视频。我们提出了舞蹈化身，旨在通过姿势和文本提示生成人体运动视频。我们的方法使用经过预训练的T2I扩散模型来自回归地生成每个视频帧。创新的关键在于我们巧妙地利用T2I扩散模型来连续生成视频帧，同时保持上下文相关性。我们克服了在不同姿势下保持人物特征和服装一致性以及在各种人体运动中保持背景连续性的困难。为了确保整个视频中人物外观一致，我们设计了一个帧内对齐模块。这个模块将文本引导的合成人物知识融合到预训练的T2I扩散模型中，结合了ChatGPT的见解。

    The rising demand for creating lifelike avatars in the digital realm has led to an increased need for generating high-quality human videos guided by textual descriptions and poses. We propose Dancing Avatar, designed to fabricate human motion videos driven by poses and textual cues. Our approach employs a pretrained T2I diffusion model to generate each video frame in an autoregressive fashion. The crux of innovation lies in our adept utilization of the T2I diffusion model for producing video frames successively while preserving contextual relevance. We surmount the hurdles posed by maintaining human character and clothing consistency across varying poses, along with upholding the background's continuity amidst diverse human movements. To ensure consistent human appearances across the entire video, we devise an intra-frame alignment module. This module assimilates text-guided synthesized human character knowledge into the pretrained T2I diffusion model, synergizing insights from ChatGPT
    
[^26]: 在汽车雷达目标检测网络中利用稀疏性

    Exploiting Sparsity in Automotive Radar Object Detection Networks. (arXiv:2308.07748v1 [cs.CV])

    [http://arxiv.org/abs/2308.07748](http://arxiv.org/abs/2308.07748)

    本文研究了在汽车雷达目标检测网络中利用稀疏性的方法，提出了稀疏核心点柱体和双体素点卷积来解决网格渲染和稀疏骨干结构问题。实验结果显示，这种方法在Car AP4.0上优于基准模型5.89%和先前的最优模型4.19%，并将平均尺度误差相对于基准模型减少了21.41%。

    

    精确感知环境对于确保自动驾驶系统的安全可靠性至关重要。雷达目标检测网络是这类系统的一个基本组成部分。基于CNN的目标检测器在这一背景下表现良好，但需要大量计算资源。本文研究了稀疏卷积目标检测网络，它将强大的基于网格的检测与低计算资源相结合。我们研究了雷达特定的挑战，并提出了稀疏核心点柱体（SKPP）和双体素点卷积（DVPC）来解决网格渲染和稀疏骨干结构问题。我们在nuScenes数据集上评估了SKPP-DPVCN架构，在Car AP4.0上优于基准模型5.89%，优于先前的最优模型4.19%。此外，SKPP-DPVCN还将平均尺度误差（ASE）相对于基准模型减少了21.41%。

    Having precise perception of the environment is crucial for ensuring the secure and reliable functioning of autonomous driving systems. Radar object detection networks are one fundamental part of such systems. CNN-based object detectors showed good performance in this context, but they require large compute resources. This paper investigates sparse convolutional object detection networks, which combine powerful grid-based detection with low compute resources. We investigate radar specific challenges and propose sparse kernel point pillars (SKPP) and dual voxel point convolutions (DVPC) as remedies for the grid rendering and sparse backbone architectures. We evaluate our SKPP-DPVCN architecture on nuScenes, which outperforms the baseline by 5.89% and the previous state of the art by 4.19% in Car AP4.0. Moreover, SKPP-DPVCN reduces the average scale error (ASE) by 21.41% over the baseline.
    
[^27]: 使用形式方法的DAgger算法实现低延迟的蒙特卡罗树搜索

    Formally-Sharp DAgger for MCTS: Lower-Latency Monte Carlo Tree Search using Data Aggregation with Formal Methods. (arXiv:2308.07738v1 [cs.AI])

    [http://arxiv.org/abs/2308.07738](http://arxiv.org/abs/2308.07738)

    本研究提出了一种使用形式方法指导蒙特卡罗树搜索以生成高质量决策的算法。通过训练神经网络来模仿生成的策略，并在低延迟搜索或最小延迟情况下作为完整策略使用。模拟实验结果表明该方法的有效性和性能提升。

    

    本文研究如何高效地结合形式方法、蒙特卡罗树搜索（MCTS）和深度学习，以在大规模马尔可夫决策过程（MDP）中生成高质量的突前视界策略。我们使用模型检测技术指导MCTS算法，在MDP的一组代表性状态上生成高质量决策的离线样本。这些样本可以用来训练一个神经网络，该网络模仿用于生成它们的策略。这个神经网络可以作为低延迟的MCTS在线搜索的指导，也可以在需要最小延迟时作为一个完整的策略使用。我们使用统计模型检测来检测需要额外样本的情况，并将这些额外样本集中在学到的神经网络策略与（计算昂贵的）离线策略不一致的配置上。我们在模拟冰湖和吃豆人环境的MDP上展示了我们方法的应用。

    We study how to efficiently combine formal methods, Monte Carlo Tree Search (MCTS), and deep learning in order to produce high-quality receding horizon policies in large Markov Decision processes (MDPs). In particular, we use model-checking techniques to guide the MCTS algorithm in order to generate offline samples of high-quality decisions on a representative set of states of the MDP. Those samples can then be used to train a neural network that imitates the policy used to generate them. This neural network can either be used as a guide on a lower-latency MCTS online search, or alternatively be used as a full-fledged policy when minimal latency is required. We use statistical model checking to detect when additional samples are needed and to focus those additional samples on configurations where the learnt neural network policy differs from the (computationally-expensive) offline policy. We illustrate the use of our method on MDPs that model the Frozen Lake and Pac-Man environments --
    
[^28]: 《土地利用规划中隐藏的内在不稳定性的标志》

    Flashpoints Signal Hidden Inherent Instabilities in Land-Use Planning. (arXiv:2308.07714v1 [cs.AI])

    [http://arxiv.org/abs/2308.07714](http://arxiv.org/abs/2308.07714)

    这项研究发现了土地利用规划中的内在不稳定性，即微小的规划优先级变化会导致大规模的土地利用变化。这一发现对于改善土地利用决策具有重要意义。

    

    土地利用决策进程长期以来产生了全球普遍的系统性公平性和可持续性问题。定量的、基于优化的规划方法，如多目标土地分配（MOLA），似乎可以通过明确评估土地利用类型、数量和位置来提高客观性和透明度。在这里，我们展示了基于优化的规划方法使用通用规划标准会产生一系列不稳定的“闪点”，微小的规划优先级变化会导致大规模的土地利用变化。我们提出定量的论证，证明我们在MOLA模型中发现的闪点是一种更普遍的不稳定性的例子，无论这些规划因素是明确还是隐含，只要规划考虑到协调地点之间和地点内的使用因素，都会出现这种不稳定性。我们展示了不稳定性会导致存在不确定性的地区。

    Land-use decision-making processes have a long history of producing globally pervasive systemic equity and sustainability concerns. Quantitative, optimization-based planning approaches, e.g. Multi-Objective Land Allocation (MOLA), seemingly open the possibility to improve objectivity and transparency by explicitly evaluating planning priorities by the type, amount, and location of land uses. Here, we show that optimization-based planning approaches with generic planning criteria generate a series of unstable "flashpoints" whereby tiny changes in planning priorities produce large-scale changes in the amount of land use by type. We give quantitative arguments that the flashpoints we uncover in MOLA models are examples of a more general family of instabilities that occur whenever planning accounts for factors that coordinate use on- and between-sites, regardless of whether these planning factors are formulated explicitly or implicitly. We show that instabilities lead to regions of ambigui
    
[^29]: 利用视觉-语言模型在医学图像分割中探索迁移学习

    Exploring Transfer Learning in Medical Image Segmentation using Vision-Language Models. (arXiv:2308.07706v1 [cs.CV])

    [http://arxiv.org/abs/2308.07706](http://arxiv.org/abs/2308.07706)

    本论文提出使用视觉-语言模型进行医学图像分割的迁移学习，并评估了其在医学领域的可迁移性。通过捕捉语义信息和引入新的图像描述变化，实现了对多样化医学图像的分割。

    

    医学图像分割在医学领域的各种临床应用中至关重要。尽管最先进的分割模型已被证明有效，但在这个任务中整合文本指导以增强视觉特征仍然是一个进展有限的领域。现有利用文本指导的分割模型主要在开放领域图像上训练，这引发了在医学领域直接应用的难题，需要手动介入或进行微调。为了解决这些挑战，我们提出使用多模态的视觉-语言模型从图像描述和图像中捕捉语义信息，使得能够对多样化的医学图像进行分割。该研究全面评估了现有的视觉-语言模型在多个数据集上的可迁移性，以评估其从开放领域向医学领域的迁移能力。此外，我们对数据集中以前未见图像的图像描述引入了变化，揭示了显著的变异。

    Medical Image Segmentation is crucial in various clinical applications within the medical domain. While state-of-the-art segmentation models have proven effective, integrating textual guidance to enhance visual features for this task remains an area with limited progress. Existing segmentation models that utilize textual guidance are primarily trained on open-domain images, raising concerns about their direct applicability in the medical domain without manual intervention or fine-tuning.  To address these challenges, we propose using multimodal vision-language models for capturing semantic information from image descriptions and images, enabling the segmentation of diverse medical images. This study comprehensively evaluates existing vision language models across multiple datasets to assess their transferability from the open domain to the medical field. Furthermore, we introduce variations of image descriptions for previously unseen images in the dataset, revealing notable variations 
    
[^30]: DiffGuard：使用预训练扩散模型进行语义不匹配引导的带外分布检测

    DiffGuard: Semantic Mismatch-Guided Out-of-Distribution Detection using Pre-trained Diffusion Models. (arXiv:2308.07687v1 [cs.CV])

    [http://arxiv.org/abs/2308.07687](http://arxiv.org/abs/2308.07687)

    本论文提出了一种名为DiffGuard的方法，使用预训练的扩散模型进行语义不匹配引导的带外分布检测。实验证明，DiffGuard在小规模数据集上表现出色，但在ImageNet规模的数据集上无法应用。

    

    本论文针对语义带外（OOD）样本与合法类别内容在语义上的不匹配特征，提出了一种语义不匹配引导的带外分布检测方法DiffGuard。与其他方法相比，DiffGuard直接使用预训练的扩散模型进行语义不匹配引导，相较于条件生成对抗网络，扩散模型更易于训练且适用于各种条件。实验结果表明，在小规模数据集上，DiffGuard取得了显著的带外分布检测性能。然而，由于使用图像和标签作为条件训练条件生成对抗网络的困难性，DiffGuard在ImageNet规模的数据集上无法应用。

    Given a classifier, the inherent property of semantic Out-of-Distribution (OOD) samples is that their contents differ from all legal classes in terms of semantics, namely semantic mismatch. There is a recent work that directly applies it to OOD detection, which employs a conditional Generative Adversarial Network (cGAN) to enlarge semantic mismatch in the image space. While achieving remarkable OOD detection performance on small datasets, it is not applicable to ImageNet-scale datasets due to the difficulty in training cGANs with both input images and labels as conditions. As diffusion models are much easier to train and amenable to various conditions compared to cGANs, in this work, we propose to directly use pre-trained diffusion models for semantic mismatch-guided OOD detection, named DiffGuard. Specifically, given an OOD input image and the predicted label from the classifier, we try to enlarge the semantic difference between the reconstructed OOD image under these conditions and t
    
[^31]: Boosting Multi-modal Model Performance with Adaptive Gradient Modulation. (arXiv:2308.07686v1 [cs.CV])

    Boosting Multi-modal Model Performance with Adaptive Gradient Modulation. (arXiv:2308.07686v1 [cs.CV])

    [http://arxiv.org/abs/2308.07686](http://arxiv.org/abs/2308.07686)

    本论文提出了一种自适应梯度调节方法，能够提升多模态模型的性能，并引入了一种新的度量竞争强度的指标。

    

    尽管多模态学习领域发展迅速，但近期研究表明标准的联合训练模式的缺陷已经变得明显。研究指出联合训练模型性能亚优的原因是模态竞争现象。现有方法试图通过调控训练过程来改善联合训练模型。尽管这些方法有效，但只能应用于后期融合模型。更重要的是，模态竞争的机制仍未被探究。本文首先提出了一种自适应梯度调节方法，可以提升具有不同融合策略的多模态模型的性能。大量实验证明了我们的方法超越了所有现有的调控方法。此外，为了对模态竞争以及我们调节方法效果背后的机制有量化的理解，我们引入了一种新的度量竞争强度的指标。该指标被构建

    While the field of multi-modal learning keeps growing fast, the deficiency of the standard joint training paradigm has become clear through recent studies. They attribute the sub-optimal performance of the jointly trained model to the modality competition phenomenon. Existing works attempt to improve the jointly trained model by modulating the training process. Despite their effectiveness, those methods can only apply to late fusion models. More importantly, the mechanism of the modality competition remains unexplored. In this paper, we first propose an adaptive gradient modulation method that can boost the performance of multi-modal models with various fusion strategies. Extensive experiments show that our method surpasses all existing modulation methods. Furthermore, to have a quantitative understanding of the modality competition and the mechanism behind the effectiveness of our modulation method, we introduce a novel metric to measure the competition strength. This metric is built 
    
[^32]: EQ-Net：弹性量化神经网络

    EQ-Net: Elastic Quantization Neural Networks. (arXiv:2308.07650v1 [cs.CV])

    [http://arxiv.org/abs/2308.07650](http://arxiv.org/abs/2308.07650)

    本文提出了EQ-Net，一种弹性量化神经网络，旨在训练一个灵活的权重共享量化超网络。通过探索弹性量化空间和引入权重分布正则化损失和分组渐进引导损失，本文解决了现有模型量化方法中对不同场景重复优化的局限性。

    

    当前的模型量化方法在减少存储空间和计算复杂度方面显示出了巨大的潜力。然而，由于不同硬件所支持的量化形式的多样性，现有解决方案的一个局限性通常是需要针对不同场景进行重复优化。如何构建一个具有灵活量化形式的模型还未被充分研究。在本文中，我们探索了一种一次性网络量化方案，称为弹性量化神经网络（EQ-Net），旨在训练一个强大的权重共享量化超网络。首先，我们提出了一个弹性量化空间（包括弹性位宽、粒度和对称性）以适应各种主流量化形式。其次，我们提出了权重分布正则化损失（WDR-Loss）和分组渐进引导损失（GPG-Loss）来弥合弹性量化空间差异中权重和输出标准差的不一致性。最后，我们通过一阶搜索算法和二分查找算法确定最优量化策略，并在多个数据集上进行了广泛的实验验证。

    Current model quantization methods have shown their promising capability in reducing storage space and computation complexity. However, due to the diversity of quantization forms supported by different hardware, one limitation of existing solutions is that usually require repeated optimization for different scenarios. How to construct a model with flexible quantization forms has been less studied. In this paper, we explore a one-shot network quantization regime, named Elastic Quantization Neural Networks (EQ-Net), which aims to train a robust weight-sharing quantization supernet. First of all, we propose an elastic quantization space (including elastic bit-width, granularity, and symmetry) to adapt to various mainstream quantitative forms. Secondly, we propose the Weight Distribution Regularization Loss (WDR-Loss) and Group Progressive Guidance Loss (GPG-Loss) to bridge the inconsistency of the distribution for weights and output logits in the elastic quantization space gap. Lastly, we
    
[^33]: 三元奇异值分解作为线性映射中更好的参数化形式

    Ternary Singular Value Decomposition as a Better Parameterized Form in Linear Mapping. (arXiv:2308.07641v1 [cs.LG])

    [http://arxiv.org/abs/2308.07641](http://arxiv.org/abs/2308.07641)

    本文提出了一种名为三元奇异值分解 (TSVD) 的新颖线性映射参数化形式，通过限制奇异值分解中的矩阵为三元矩阵形式，它在网络压缩性能方面表现出色。实验证明，TSVD在各种类型的网络和任务中都能实现最先进的网络压缩性能。

    

    我们提出了一种简单但新颖的线性映射参数化形式，称为三元奇异值分解 (TSVD)，以实现卓越的网络压缩性能。与传统的奇异值分解不同，TSVD将奇异值分解中的$U$和$V$矩阵限制为三元矩阵形式，即$\{ \pm 1, 0 \}$。这意味着在计算$U(\cdot)$和$V(\cdot)$时，TSVD只需要加法指令，而不需要昂贵的乘法指令。我们提供了直接转换算法和训练过渡算法，如后训练量化和量化感知训练。此外，我们在理论上分析了直接转换算法的收敛性。在实验中，我们证明了TSVD在各种类型的网络和任务中都能实现最先进的网络压缩性能，包括当前的基准模型，如ConvNext、Swim、BERT以及类似OPT的大型语言模型。

    We present a simple yet novel parameterized form of linear mapping to achieves remarkable network compression performance: a pseudo SVD called Ternary SVD (TSVD).  Unlike vanilla SVD, TSVD limits the $U$ and $V$ matrices in SVD to ternary matrices form in $\{\pm 1, 0\}$. This means that instead of using the expensive multiplication instructions, TSVD only requires addition instructions when computing $U(\cdot)$ and $V(\cdot)$.  We provide direct and training transition algorithms for TSVD like Post Training Quantization and Quantization Aware Training respectively. Additionally, we analyze the convergence of the direct transition algorithms in theory.  In experiments, we demonstrate that TSVD can achieve state-of-the-art network compression performance in various types of networks and tasks, including current baseline models such as ConvNext, Swim, BERT, and large language model like OPT.
    
[^34]: LLM-Mini-CEX: 用于诊断对话的大型语言模型的自动评估

    LLM-Mini-CEX: Automatic Evaluation of Large Language Model for Diagnostic Conversation. (arXiv:2308.07635v1 [cs.CL])

    [http://arxiv.org/abs/2308.07635](http://arxiv.org/abs/2308.07635)

    本研究提出了一种用于诊断对话的自动评估方法，通过建立LLM-specific Mini-CEX评估标准和使用患者模拟器与ChatGPT自动评估诊断对话，解决了医学LLMs评估中的统一和全面性问题。

    

    在开发用于医学诊断的LLM（大型语言模型）以提高诊断效率方面引起了越来越多的兴趣。尽管它们具有吸引人的技术潜力，但缺乏统一和全面的评估标准导致无法评估医学LLMs的质量和潜在风险，进一步阻碍了LLMs在医疗治疗场景中的应用。此外，当前的评估严重依赖于与LLMs进行劳动密集型的交互以获取诊断对话和人工评估诊断对话的质量。为了解决缺乏统一和全面评估标准的问题，我们首先根据原始的Mini-CEX建立了一个评估标准，称为LLM-specific Mini-CEX，以有效评估LLMs的诊断能力。为了解决劳动密集型交互问题，我们开发了一个患者模拟器与LLMs自动进行对话，并利用ChatGPT自动评估诊断对话。

    There is an increasing interest in developing LLMs for medical diagnosis to improve diagnosis efficiency. Despite their alluring technological potential, there is no unified and comprehensive evaluation criterion, leading to the inability to evaluate the quality and potential risks of medical LLMs, further hindering the application of LLMs in medical treatment scenarios. Besides, current evaluations heavily rely on labor-intensive interactions with LLMs to obtain diagnostic dialogues and human evaluation on the quality of diagnosis dialogue. To tackle the lack of unified and comprehensive evaluation criterion, we first initially establish an evaluation criterion, termed LLM-specific Mini-CEX to assess the diagnostic capabilities of LLMs effectively, based on original Mini-CEX. To address the labor-intensive interaction problem, we develop a patient simulator to engage in automatic conversations with LLMs, and utilize ChatGPT for evaluating diagnosis dialogues automatically. Experimenta
    
[^35]: 关于大型语言模型的模型压缩综述

    A Survey on Model Compression for Large Language Models. (arXiv:2308.07633v1 [cs.CL])

    [http://arxiv.org/abs/2308.07633](http://arxiv.org/abs/2308.07633)

    本论文提供了关于大型语言模型的模型压缩综述，探讨了量化、修剪、知识蒸馏等不同方法，并突出介绍了最新进展和创新方法，为实现高效的部署提供了重要思路。

    

    大型语言模型（LLMs）以惊人的成功彻底改变了自然语言处理任务。然而，它们庞大的体量和计算需求在资源受限环境下的实际部署中带来了重大挑战。随着这些挑战日益紧迫，模型压缩领域已成为一个关键的研究领域，旨在缓解这些限制。本文提供了一份全面的综述，探讨专门针对LLMs的模型压缩技术。我们深入研究了各种方法，包括量化、修剪、知识蒸馏等，以应对高效部署的迫切需求。在每种技术中，我们重点介绍了最新进展和创新方法，为LLM研究的发展提供了贡献。此外，我们还探讨了用于评估效果的基准策略和评估指标的重要性。

    Large Language Models (LLMs) have revolutionized natural language processing tasks with remarkable success. However, their formidable size and computational demands present significant challenges for practical deployment, especially in resource-constrained environments. As these challenges become increasingly pertinent, the field of model compression has emerged as a pivotal research area to alleviate these limitations. This paper presents a comprehensive survey that navigates the landscape of model compression techniques tailored specifically for LLMs. Addressing the imperative need for efficient deployment, we delve into various methodologies, encompassing quantization, pruning, knowledge distillation, and more. Within each of these techniques, we highlight recent advancements and innovative approaches that contribute to the evolving landscape of LLM research. Furthermore, we explore benchmarking strategies and evaluation metrics that are essential for assessing the effectiveness of 
    
[^36]: 基于视觉的元宇宙服务的语义通信：竞赛理论方法

    Vision-based Semantic Communications for Metaverse Services: A Contest Theoretic Approach. (arXiv:2308.07618v1 [cs.GT])

    [http://arxiv.org/abs/2308.07618](http://arxiv.org/abs/2308.07618)

    本文提出了一个基于竞赛理论的语义通信框架，用于实现元宇宙服务中用户和服务提供商之间的优化资源分配。通过减少传输数据量和使用深度Q网络优化奖励，实现了实时同步和减少网络资源消耗。

    

    元宇宙作为一个娱乐、社交和工作平台的流行，导致了对虚拟世界中无缝化身集成的巨大需求。在元宇宙中，必须更新和渲染化身以反映用户的行为。实现虚拟位置和用户之间的实时同步是复杂的，对元宇宙服务提供商（MSP）的渲染资源分配方案提出了很高的要求。为了解决这个问题，我们提出了一个语义通信框架，利用竞赛理论来模拟用户和MSP之间的交互，并确定每个用户的最优资源分配。为了减少无线传输中网络资源的消耗，我们使用语义通信技术来减少需要传输的数据量。在我们的模拟设置中，编码的语义数据只包含了51个字节的骨骼坐标，而不是8.243兆字节的图像大小。此外，我们实现了深度Q网络来优化奖励。

    The popularity of Metaverse as an entertainment, social, and work platform has led to a great need for seamless avatar integration in the virtual world. In Metaverse, avatars must be updated and rendered to reflect users' behaviour. Achieving real-time synchronization between the virtual bilocation and the user is complex, placing high demands on the Metaverse Service Provider (MSP)'s rendering resource allocation scheme. To tackle this issue, we propose a semantic communication framework that leverages contest theory to model the interactions between users and MSPs and determine optimal resource allocation for each user. To reduce the consumption of network resources in wireless transmission, we use the semantic communication technique to reduce the amount of data to be transmitted. Under our simulation settings, the encoded semantic data only contains 51 bytes of skeleton coordinates instead of the image size of 8.243 megabytes. Moreover, we implement Deep Q-Network to optimize rewar
    
[^37]: SGDiff: 一种用于时尚合成的风格引导扩散模型

    SGDiff: A Style Guided Diffusion Model for Fashion Synthesis. (arXiv:2308.07605v1 [cs.CV])

    [http://arxiv.org/abs/2308.07605](http://arxiv.org/abs/2308.07605)

    这个论文介绍了一种名为SGDiff的风格引导扩散模型，通过结合图像模态和预训练的文本到图像扩散模型，成功地实现了创造性时尚图像合成。它通过引入辅助风格引导、减少训练成本以及克服文本输入限制等方式，克服了现有模型的局限性。此外，还提出了一个专门为时尚图像合成设计的数据集SG-Fashion，通过全面的实验证明了所提出模型的有效性。

    

    本文介绍了一种新颖的风格引导扩散模型（SGDiff），它克服了现有图像合成模型固有的一些弱点。所提出的SGDiff将图像模态与预训练的文本到图像扩散模型相结合，以促进创造性的时尚图像合成。它通过引入辅助的风格引导来解决文本到图像扩散模型的局限性，大大降低了训练成本，并克服了只有文本输入时控制合成样式的困难。本文还介绍了一个新的数据集-SG-Fashion，专门设计用于时尚图像合成应用，提供高分辨率的图像和广泛的服装类别。通过全面的消融实验，我们研究了在各种条件下应用无分类器引导的效果，并验证了所提出模型生成所需类别的时尚图像的有效性。

    This paper reports on the development of \textbf{a novel style guided diffusion model (SGDiff)} which overcomes certain weaknesses inherent in existing models for image synthesis. The proposed SGDiff combines image modality with a pretrained text-to-image diffusion model to facilitate creative fashion image synthesis. It addresses the limitations of text-to-image diffusion models by incorporating supplementary style guidance, substantially reducing training costs, and overcoming the difficulties of controlling synthesized styles with text-only inputs. This paper also introduces a new dataset -- SG-Fashion, specifically designed for fashion image synthesis applications, offering high-resolution images and an extensive range of garment categories. By means of comprehensive ablation study, we examine the application of classifier-free guidance to a variety of conditions and validate the effectiveness of the proposed model for generating fashion images of the desired categories, product at
    
[^38]: 使用多模态对抗模仿学习生成游戏角色

    Generating Personas for Games with Multimodal Adversarial Imitation Learning. (arXiv:2308.07598v1 [cs.LG])

    [http://arxiv.org/abs/2308.07598](http://arxiv.org/abs/2308.07598)

    本论文介绍了一种使用多模态对抗模仿学习的方法，可以生成多个游戏角色策略，以用于游戏测试。这种方法通过使用多个判别器作为奖励模型，并根据辅助输入对每个判别器的奖励进行加权，有效地建模各种人类游戏风格。

    

    强化学习在游戏中取得了广泛的成功，能够生成具有人类水平的玩家智能体。然而，这需要复杂的奖励工程，并且智能体的策略往往是不可预测的。为了建模各种人类游戏风格，超越强化学习是必要的，而这往往很难用奖励函数表示。本文提出了一种新颖的模仿学习方法，用于生成多个角色策略用于游戏测试。多模态生成对抗模仿学习（MultiGAIL）使用辅助输入参数，使用单智能体模型学习不同的角色。MultiGAIL基于生成对抗模仿学习，并使用多个判别器作为奖励模型，通过比较智能体和不同的专家策略来推断环境奖励。每个判别器的奖励根据辅助输入进行加权。我们的实验分析证明了我们的技术的有效性。

    Reinforcement learning has been widely successful in producing agents capable of playing games at a human level. However, this requires complex reward engineering, and the agent's resulting policy is often unpredictable. Going beyond reinforcement learning is necessary to model a wide range of human playstyles, which can be difficult to represent with a reward function. This paper presents a novel imitation learning approach to generate multiple persona policies for playtesting. Multimodal Generative Adversarial Imitation Learning (MultiGAIL) uses an auxiliary input parameter to learn distinct personas using a single-agent model. MultiGAIL is based on generative adversarial imitation learning and uses multiple discriminators as reward models, inferring the environment reward by comparing the agent and distinct expert policies. The reward from each discriminator is weighted according to the auxiliary input. Our experimental analysis demonstrates the effectiveness of our technique in two
    
[^39]: AutoLTS：通过对比学习和空间后处理实现自动化骑行压力评估

    AutoLTS: Automating Cycling Stress Assessment via Contrastive Learning and Spatial Post-processing. (arXiv:2308.07580v1 [cs.CV])

    [http://arxiv.org/abs/2308.07580](http://arxiv.org/abs/2308.07580)

    本文提出了一个基于深度学习的框架，通过对比学习和空间后处理实现自动化骑行压力评估。在缺乏高质量的道路几何和汽车交通数据的情况下，利用街景图像数据能够准确、快速地评估城市道路网络的骑行压力。

    

    骑行压力评估是一种衡量骑行者受到建筑环境和汽车交通影响的主观压力的方法，它越来越多地用于骑行基础设施规划和骑行路线推荐。然而，目前计算骑行压力的方法速度慢且需要大量数据，这限制了其更广泛的应用。本文提出了一个基于街景图像的深度学习框架，支持准确、快速和大规模的城市道路网络骑行压力评估。我们的框架具有以下特点：i）利用骑行压力标签的序关系进行对比学习；ii）使用后处理技术将空间平滑性纳入我们的预测中。在加拿大多伦多收集的39,153个道路段数据集上，我们的结果证明了我们的深度学习框架的有效性，以及在缺乏高质量的道路几何和汽车交通数据时使用图像数据进行骑行压力评估的价值。

    Cycling stress assessment, which quantifies cyclists' perceived stress imposed by the built environment and motor traffics, increasingly informs cycling infrastructure planning and cycling route recommendation. However, currently calculating cycling stress is slow and data-intensive, which hinders its broader application. In this paper, We propose a deep learning framework to support accurate, fast, and large-scale cycling stress assessments for urban road networks based on street-view images. Our framework features i) a contrastive learning approach that leverages the ordinal relationship among cycling stress labels, and ii) a post-processing technique that enforces spatial smoothness into our predictions. On a dataset of 39,153 road segments collected in Toronto, Canada, our results demonstrate the effectiveness of our deep learning framework and the value of using image data for cycling stress assessment in the absence of high-quality road geometry and motor traffic data.
    
[^40]: 通过在线文本增强和上下文记忆的方式进行故事可视化

    Story Visualization by Online Text Augmentation with Context Memory. (arXiv:2308.07575v1 [cs.CV])

    [http://arxiv.org/abs/2308.07575](http://arxiv.org/abs/2308.07575)

    本论文提出了一种通过在线文本增强和上下文记忆来进行故事可视化的方法。通过使用新颖的记忆架构和多个伪描述作为训练过程的补充监督，该方法在两个故事可视化基准测试中取得了显著优于现有方法的结果。

    

    故事可视化是一个具有挑战性的文本到图像生成任务，难点在于不仅需要从文本描述中呈现视觉细节，还需要对跨多个句子的长期上下文进行编码。以往的工作主要关注为每个句子生成语义相关的图像，但在给定段落中编码上下文以生成具有上下文说服力的图像（例如，正确的角色或适当的场景背景）仍然是一个挑战。为此，我们提出了一种新颖的记忆架构，用于双向Transformer，并通过在线文本增强生成多个伪描述作为训练过程中的补充监督，以更好地适应推理中的语言变化。在两个流行的故事可视化基准测试中进行了大量实验证明，即Pororo-SV和Flintstones-SV，所提出的方法在包括FID、字符...

    Story visualization (SV) is a challenging text-to-image generation task for the difficulty of not only rendering visual details from the text descriptions but also encoding a long-term context across multiple sentences. While prior efforts mostly focus on generating a semantically relevant image for each sentence, encoding a context spread across the given paragraph to generate contextually convincing images (e.g., with a correct character or with a proper background of the scene) remains a challenge. To this end, we propose a novel memory architecture for the Bi-directional Transformers with an online text augmentation that generates multiple pseudo-descriptions as supplementary supervision during training, for better generalization to the language variation at inference. In extensive experiments on the two popular SV benchmarks, i.e., the Pororo-SV and Flintstones-SV, the proposed method significantly outperforms the state of the arts in various evaluation metrics including FID, char
    
[^41]: 跨多个视频数据集检测和分类行动类别关系

    Action Class Relation Detection and Classification Across Multiple Video Datasets. (arXiv:2308.07558v1 [cs.CV])

    [http://arxiv.org/abs/2308.07558](http://arxiv.org/abs/2308.07558)

    本论文提出了一种在多个视频数据集上检测和分类行动类别关系的方法，并通过语言和视觉信息来预测行动类别之间的关系。实验结果表明，预训练的神经网络模型对提高预测性能有贡献，基于行动标签文本的关系预测更准确，通过综合两种模态的预测结果可以进一步改进预测性能。

    

    Meta Video Dataset (MetaVD)提供了主要视频人体动作识别数据集中行动类别之间的关系注释。虽然这些关系注释可以实现数据集扩充，但只适用于MetaVD覆盖的数据集。对于外部数据集要享受相同的好处，需要确定其行动类别与MetaVD中行动类别之间的关系。为了解决这个问题，我们考虑了两个新的机器学习任务：行动类别关系检测和分类。我们提出了一个统一的模型来预测行动类别之间的关系，利用与类别相关的语言和视觉信息。实验结果表明：(i) 针对文本和视频的预训练的最新神经网络模型对高预测性能有贡献，(ii) 基于行动标签文本的关系预测比基于视频更准确，(iii) 通过将两种模态的预测结果进行综合可以进一步提高预测性能

    The Meta Video Dataset (MetaVD) provides annotated relations between action classes in major datasets for human action recognition in videos. Although these annotated relations enable dataset augmentation, it is only applicable to those covered by MetaVD. For an external dataset to enjoy the same benefit, the relations between its action classes and those in MetaVD need to be determined. To address this issue, we consider two new machine learning tasks: action class relation detection and classification. We propose a unified model to predict relations between action classes, using language and visual information associated with classes. Experimental results show that (i) pre-trained recent neural network models for texts and videos contribute to high predictive performance, (ii) the relation prediction based on action label texts is more accurate than based on videos, and (iii) a blending approach that combines predictions by both modalities can further improve the predictive performan
    
[^42]: 基于强化学习的无服务器计算中冷启动频率降低方法

    Reinforcement Learning (RL) Augmented Cold Start Frequency Reduction in Serverless Computing. (arXiv:2308.07541v1 [cs.DC])

    [http://arxiv.org/abs/2308.07541](http://arxiv.org/abs/2308.07541)

    本文提出了一种基于强化学习的方法来降低无服务器计算中的冷启动频率。通过使用Q学习和考虑多种指标，我们可以在预期需求的基础上提前初始化函数，从而减少冷启动次数。

    

    函数即服务是一种云计算范例，为应用程序提供了事件驱动执行模型。它通过从开发者那里消除资源管理责任，提供透明和按需可扩展性来实现无服务器特性。典型的无服务器应用程序对响应时间和可扩展性有严格要求，因此依赖于部署的服务为客户提供快速和容错的反馈。然而，函数即服务范例在需要按需初始化函数时存在非常可观的延迟，即冷启动问题。本研究旨在通过使用强化学习来减少平台上的冷启动频率。我们的方法使用Q学习，并考虑函数的CPU利用率、已有函数实例和响应失败率等指标，根据预期需求提前主动初始化函数。我们提出的解决方案在Kubeless上实现并进行评估。

    Function-as-a-Service is a cloud computing paradigm offering an event-driven execution model to applications. It features serverless attributes by eliminating resource management responsibilities from developers and offers transparent and on-demand scalability of applications. Typical serverless applications have stringent response time and scalability requirements and therefore rely on deployed services to provide quick and fault-tolerant feedback to clients. However, the FaaS paradigm suffers from cold starts as there is a non-negligible delay associated with on-demand function initialization. This work focuses on reducing the frequency of cold starts on the platform by using Reinforcement Learning. Our approach uses Q-learning and considers metrics such as function CPU utilization, existing function instances, and response failure rate to proactively initialize functions in advance based on the expected demand. The proposed solution was implemented on Kubeless and was evaluated usin
    
[^43]: 通过极小极大熵进行领域适应，用于天文警报的真伪分类

    Domain Adaptation via Minimax Entropy for Real/Bogus Classification of Astronomical Alerts. (arXiv:2308.07538v1 [astro-ph.IM])

    [http://arxiv.org/abs/2308.07538](http://arxiv.org/abs/2308.07538)

    本文研究了用于天文警报真伪分类的领域适应方法，通过使用微调方法和半监督深度领域适应（MME）来提高分类模型的性能。实验证明，微调模型和MME模型都能在只有少数标记数据的情况下显著改进基本模型。

    

    时间域天文学正朝着实时分析多个大规模数据集的方向发展，促使多流机器学习模型的发展。本文使用四个不同的数据集（HiTS、DES、ATLAS和ZTF）研究了天文警报的真伪分类的领域适应（DA）。我们研究了这些数据集之间的领域变化，并通过使用微调方法和半监督深度领域适应（MME）改进了一个简单的深度学习分类模型。我们比较了这些模型在不同源目标情景下的平衡准确性。我们发现，微调模型和MME模型都能显著改进基本模型，即使从目标数据集中只有一个标记的项，而且MME模型不会损害源数据集上的性能。

    Time domain astronomy is advancing towards the analysis of multiple massive datasets in real time, prompting the development of multi-stream machine learning models. In this work, we study Domain Adaptation (DA) for real/bogus classification of astronomical alerts using four different datasets: HiTS, DES, ATLAS, and ZTF. We study the domain shift between these datasets, and improve a naive deep learning classification model by using a fine tuning approach and semi-supervised deep DA via Minimax Entropy (MME). We compare the balanced accuracy of these models for different source-target scenarios. We find that both the fine tuning and MME models improve significantly the base model with as few as one labeled item per class coming from the target dataset, but that the MME does not compromise its performance on the source dataset.
    
[^44]: 非线性、反馈和因果结构学习中的一致性问题研究

    Nonlinearity, Feedback and Uniform Consistency in Causal Structural Learning. (arXiv:2308.07520v1 [stat.ML])

    [http://arxiv.org/abs/2308.07520](http://arxiv.org/abs/2308.07520)

    这篇论文研究了非线性、反馈和因果结构学习中的一致性问题，并提出了一个弱于强可靠性的k-Triangle Faithfulness的替代定义。

    

    因果发现的目标是从观测数据中找到学习因果结构的自动化搜索方法。有些情况下，感兴趣的因果机制的所有变量都已经被测量，任务是预测一个变量对另一个变量的影响。相反，有时主要关注的变量并非直接可观察，而是通过它们在数据中的表现来推理出来的。这些被称为潜在变量。一个广泛被知道的例子是心理构造的智商，因为无法直接测量，所以研究人员尝试通过各种指标如智商测试来评估。在这种情况下，因果发现算法可以揭示潜在变量之间和潜在变量与观察变量之间的因果连接，从而发现潜在的模式和结构。这篇论文主要研究因果发现中的两个问题：提供了一个弱于强可靠性的k-Triangle Faithfulness的替代定义，并提出了对统计一致性的新要求。

    The goal of Causal Discovery is to find automated search methods for learning causal structures from observational data. In some cases all variables of the interested causal mechanism are measured, and the task is to predict the effects one measured variable has on another. In contrast, sometimes the variables of primary interest are not directly observable but instead inferred from their manifestations in the data. These are referred to as latent variables. One commonly known example is the psychological construct of intelligence, which cannot directly measured so researchers try to assess through various indicators such as IQ tests. In this case, casual discovery algorithms can uncover underlying patterns and structures to reveal the causal connections between the latent variables and between the latent and observed variables. This thesis focuses on two questions in causal discovery: providing an alternative definition of k-Triangle Faithfulness that (i) is weaker than strong faithfu
    
[^45]: 通过连接高和低置信度的预测来提升半监督学习

    Boosting Semi-Supervised Learning by bridging high and low-confidence predictions. (arXiv:2308.07509v1 [cs.CV])

    [http://arxiv.org/abs/2308.07509](http://arxiv.org/abs/2308.07509)

    该论文提出了一种名为ReFixMatch的方法，通过连接高和低置信度的预测来解决半监督学习中的伪标签问题，并充分利用所有无标签数据进行训练。

    

    伪标签是半监督学习中的关键技术，通过训练模型为无标签数据生成人工标签，从而在监督设置下同时训练有标签和无标签数据。然而，一些研究发现伪标签方法存在三个主要问题。首先，这些方法严重依赖训练模型的预测，可能不总是准确，导致确认偏差问题。其次，训练模型可能对易学例子过拟合，忽视难学例子，从而导致“马太效应”，即强者更强，弱者更弱。第三，由于使用了高阈值，大部分无标签数据的低置信度预测被丢弃，导致训练时无标签数据的利用不足。为了解决这些问题，我们提出了一种新方法ReFixMatch，旨在充分利用所有无标签数据进行训练。

    Pseudo-labeling is a crucial technique in semi-supervised learning (SSL), where artificial labels are generated for unlabeled data by a trained model, allowing for the simultaneous training of labeled and unlabeled data in a supervised setting. However, several studies have identified three main issues with pseudo-labeling-based approaches. Firstly, these methods heavily rely on predictions from the trained model, which may not always be accurate, leading to a confirmation bias problem. Secondly, the trained model may be overfitted to easy-to-learn examples, ignoring hard-to-learn ones, resulting in the \textit{"Matthew effect"} where the already strong become stronger and the weak weaker. Thirdly, most of the low-confidence predictions of unlabeled data are discarded due to the use of a high threshold, leading to an underutilization of unlabeled data during training. To address these issues, we propose a new method called ReFixMatch, which aims to utilize all of the unlabeled data dur
    
[^46]: 人工智能检测在线问卷的篡改

    Detecting The Corruption Of Online Questionnaires By Artificial Intelligence. (arXiv:2308.07499v1 [cs.HC])

    [http://arxiv.org/abs/2308.07499](http://arxiv.org/abs/2308.07499)

    这项研究发现，基于人工智能的大型语言模型使得不良行为者能够自动填写在线问卷，威胁到数据质量。目前，无法有效检测人工智能生成的文本，需要依赖不良行为者的不积极性来保证数据质量。

    

    在线问卷使用众包平台招募参与者已经变得普遍，因为它们易于使用且成本低廉。基于人工智能的大型语言模型使得不良行为者能够自动填写在线表单，包括为开放性任务生成有意义的文本。这些技术进步威胁到使用在线问卷的研究的数据质量。本研究测试了人工智能生成的用于在线研究目的的文本是否可以被人类和自动人工智能检测系统检测出来。虽然人类能够正确辨别文本的作者身份（76%的准确率），但他们的表现仍然低于确保令人满意的数据质量所需的水平。目前，研究人员只能依赖不良行为者的不积极性来成功使用开放性回答作为确保数据质量的有用工具。自动人工智能检测系统目前无法使用。

    Online questionnaires that use crowd-sourcing platforms to recruit participants have become commonplace, due to their ease of use and low costs. Artificial Intelligence (AI) based Large Language Models (LLM) have made it easy for bad actors to automatically fill in online forms, including generating meaningful text for open-ended tasks. These technological advances threaten the data quality for studies that use online questionnaires. This study tested if text generated by an AI for the purpose of an online study can be detected by both humans and automatic AI detection systems. While humans were able to correctly identify authorship of text above chance level (76 percent accuracy), their performance was still below what would be required to ensure satisfactory data quality. Researchers currently have to rely on the disinterest of bad actors to successfully use open-ended responses as a useful tool for ensuring data quality. Automatic AI detection systems are currently completely unusab
    
[^47]: DREAMWALKER:连续视觉-语言导航的心理规划

    DREAMWALKER: Mental Planning for Continuous Vision-Language Navigation. (arXiv:2308.07498v1 [cs.CV])

    [http://arxiv.org/abs/2308.07498](http://arxiv.org/abs/2308.07498)

    DREAMWALKER是一种基于世界模型的连续视觉-语言导航代理，通过在内部抽象世界中模拟和评估可能的计划，实现了智能的和可解释的规划行为。

    

    VLN-CE是一项最近发布的任务，AI代理需要根据语言指令在自由可穿越的环境中导航到达一个远处的目标位置。由于可能策略的巨大空间，这个任务带来了巨大的挑战。基于我们相信能够预期未来行动的后果对于智能和可解释的规划行为的出现至关重要的信念，我们提出了基于世界模型的VLN-CE代理DREAMWALKER。这个世界模型将复杂连续环境的视觉、拓扑和动态特性总结为离散、结构化和紧凑的表示。DREAMWALKER可以在这种内部抽象世界中模拟和评估可能的计划，然后再执行昂贵的行动。与现有的基于模型的VLN-CE代理只在真实世界中作贪婪决策相反，这很容易导致短视行为，DREAMWALKER能够通过大量的规划进行战略性的规划。

    VLN-CE is a recently released embodied task, where AI agents need to navigate a freely traversable environment to reach a distant target location, given language instructions. It poses great challenges due to the huge space of possible strategies. Driven by the belief that the ability to anticipate the consequences of future actions is crucial for the emergence of intelligent and interpretable planning behavior, we propose DREAMWALKER -- a world model based VLN-CE agent. The world model is built to summarize the visual, topological, and dynamic properties of the complicated continuous environment into a discrete, structured, and compact representation. DREAMWALKER can simulate and evaluate possible plans entirely in such internal abstract world, before executing costly actions. As opposed to existing model-free VLN-CE agents simply making greedy decisions in the real world, which easily results in shortsighted behaviors, DREAMWALKER is able to make strategic planning through large amou
    
[^48]: ST-MLP：一种基于分组独立策略的级联时空线性框架用于交通预测

    ST-MLP: A Cascaded Spatio-Temporal Linear Framework with Channel-Independence Strategy for Traffic Forecasting. (arXiv:2308.07496v1 [cs.LG])

    [http://arxiv.org/abs/2308.07496](http://arxiv.org/abs/2308.07496)

    ST-MLP是一种基于级联多层感知器（MLP）模块和线性层的时空模型，通过成功实现分组独立策略的时间序列预测技术，将时间信息、空间信息和预定义的图结构结合起来。实验结果表明ST-MLP在精度和计算效率方面优于其他模型。

    

    在智能交通系统中，准确预测交通流量对于优化交通流管理至关重要。时空图神经网络（STGNNs）因其适应道路图结构的能力而备受赞誉。然而，当前关于STGNNs架构的研究常常优先考虑复杂的设计，导致计算负担加重，仅在精度上有少许提升。为解决这个问题，我们提出了ST-MLP，这是一个简洁的基于级联多层感知器（MLP）模块和线性层的时空模型。具体而言，我们通过成功实现分组独立策略的时间序列预测技术，将时间信息、空间信息和预定义的图结构结合起来。实证结果表明，ST-MLP在精度和计算效率方面优于最先进的STGNNs和其他模型。我们的发现鼓励了有关交通预测的进一步研究和应用。

    The criticality of prompt and precise traffic forecasting in optimizing traffic flow management in Intelligent Transportation Systems (ITS) has drawn substantial scholarly focus. Spatio-Temporal Graph Neural Networks (STGNNs) have been lauded for their adaptability to road graph structures. Yet, current research on STGNNs architectures often prioritizes complex designs, leading to elevated computational burdens with only minor enhancements in accuracy. To address this issue, we propose ST-MLP, a concise spatio-temporal model solely based on cascaded Multi-Layer Perceptron (MLP) modules and linear layers. Specifically, we incorporate temporal information, spatial information and predefined graph structure with a successful implementation of the channel-independence strategy - an effective technique in time series forecasting. Empirical results demonstrate that ST-MLP outperforms state-of-the-art STGNNs and other models in terms of accuracy and computational efficiency. Our finding encou
    
[^49]: Omega-Regular Reward Machines. (arXiv:2308.07469v1 [cs.LG])

    Omega-Regular Reward Machines. (arXiv:2308.07469v1 [cs.LG])

    [http://arxiv.org/abs/2308.07469](http://arxiv.org/abs/2308.07469)

    本文引入了ω-正规奖励机器，将奖励机器与ω-正规语言集成在一起，为RL提供了一种表达能力强且有效的奖励机制。

    

    强化学习（RL）是一种强大的训练代理执行任务的方法，但设计适当的奖励机制对其成功至关重要。然而，在许多情况下，学习目标的复杂性超出了马尔可夫假设的能力范围，需要更复杂的奖励机制。奖励机器和ω-正规语言是用于表示定量和定性目标的非马尔可夫奖励的两种形式化方法。本文引入了ω-正规奖励机器，将奖励机器与ω-正规语言集成在一起，为RL提供了一种表达能力强且有效的奖励机制。我们提出了一种无模型RL算法来计算针对ω-正规奖励机器的ε-最优策略，并通过实验证明了所提算法的有效性。

    Reinforcement learning (RL) is a powerful approach for training agents to perform tasks, but designing an appropriate reward mechanism is critical to its success. However, in many cases, the complexity of the learning objectives goes beyond the capabilities of the Markovian assumption, necessitating a more sophisticated reward mechanism. Reward machines and omega-regular languages are two formalisms used to express non-Markovian rewards for quantitative and qualitative objectives, respectively. This paper introduces omega-regular reward machines, which integrate reward machines with omega-regular languages to enable an expressive and effective reward mechanism for RL. We present a model-free RL algorithm to compute epsilon-optimal strategies against omega-egular reward machines and evaluate the effectiveness of the proposed algorithm through experiments.
    
[^50]: 玩弄文字：比较ChatGPT和人类的词汇和词汇丰富度

    Playing with Words: Comparing the Vocabulary and Lexical Richness of ChatGPT and Humans. (arXiv:2308.07462v1 [cs.CL])

    [http://arxiv.org/abs/2308.07462](http://arxiv.org/abs/2308.07462)

    这篇论文比较了ChatGPT和人类在词汇和词汇丰富度方面的差异，研究发现使用ChatGPT等工具会对词汇使用和词汇丰富度产生影响，这可能会对语言演变产生影响。

    

    人工智能生成语言模型（如GPT）和ChatGPT等工具的引入引发了一场革命，可以改变文本生成的方式。这对读者的语言能力以及新型人工智能工具的培训是否会产生影响具有许多含义？它是否会影响语言的演变？我们关注语言的一个特定方面：词语；在编写给定文本时，使用ChatGPT等工具会增加或减少使用的词汇量或词汇丰富度（理解为书面或口头表达中使用的不同词汇数量）？这对词语有影响，因为未包含在人工智能生成的内容中的词语往往会变得越来越不受欢迎，并最终可能消失。在这项工作中，我们对ChatGPT和人类的词汇和词汇丰富度进行了初步比较。

    The introduction of Artificial Intelligence (AI) generative language models such as GPT (Generative Pre-trained Transformer) and tools such as ChatGPT has triggered a revolution that can transform how text is generated. This has many implications, for example, as AI-generated text becomes a significant fraction of the text in many disciplines, would this have an effect on the language capabilities of readers and also on the training of newer AI tools? Would it affect the evolution of languages? Focusing on one specific aspect of the language: words; will the use of tools such as ChatGPT increase or reduce the vocabulary used or the lexical richness (understood as the number of different words used in a written or oral production) when writing a given text? This has implications for words, as those not included in AI-generated content will tend to be less and less popular and may eventually be lost. In this work, we perform an initial comparison of the vocabulary and lexical richness of
    
[^51]: 智能交通的人工智能研究

    Artificial Intelligence for Smart Transportation. (arXiv:2308.07457v1 [cs.AI])

    [http://arxiv.org/abs/2308.07457](http://arxiv.org/abs/2308.07457)

    本论文调查了人工智能如何从交通机构的角度提高效率和增加利用率，以改善智能交通系统的设计，重点关注数据来源与数据、人工智能辅助决策和计算问题。

    

    在美国有超过7,000家公共交通机构（还有更多的私营机构），它们一年为600亿乘客提供服务。一个运行良好的交通系统可以促进企业的增长和扩张，分发社会和经济福利，并连接社区成员的能力，从而提高他们作为一个社会的成就。由于经济实惠的公共交通服务是许多社区的支柱，本研究探讨了人工智能如何从交通机构的角度提高效率和增加利用率。这篇书章讨论了与设计基于人工智能的智能交通系统相关的主要需求、目标和挑战。我们重点关注三个主要主题。首先，我们讨论数据来源和数据。其次，我们总结了人工智能如何帮助交通决策。最后，我们讨论了计算问题。

    There are more than 7,000 public transit agencies in the U.S. (and many more private agencies), and together, they are responsible for serving 60 billion passenger miles each year. A well-functioning transit system fosters the growth and expansion of businesses, distributes social and economic benefits, and links the capabilities of community members, thereby enhancing what they can accomplish as a society. Since affordable public transit services are the backbones of many communities, this work investigates ways in which Artificial Intelligence (AI) can improve efficiency and increase utilization from the perspective of transit agencies. This book chapter discusses the primary requirements, objectives, and challenges related to the design of AI-driven smart transportation systems. We focus on three major topics. First, we discuss data sources and data. Second, we provide an overview of how AI can aid decision-making with a focus on transportation. Lastly, we discuss computational prob
    
[^52]: GRU-D-Weibull:一种新型的实时个体化终点预测方法

    GRU-D-Weibull: A Novel Real-Time Individualized Endpoint Prediction. (arXiv:2308.07452v1 [cs.LG])

    [http://arxiv.org/abs/2308.07452](http://arxiv.org/abs/2308.07452)

    GRU-D-Weibull是一种新型的实时个体化终点预测方法，结合了门控循环单元和衰减技术，用于建模威布尔分布。通过在慢性肾脏疾病患者队列中的评估，发现该方法在终点预测方面的性能优于其他竞争方法。

    

    在临床实践中，准确的个体级终点和终点时间预测模型至关重要。本研究提出了一种新的方法，GRU-D-Weibull，它将门控循环单元与衰减技术（GRU-D）结合，来建模威布尔分布。我们的方法实现了实时个体化终点预测和群体级风险管理。我们使用一个包含6,879名慢性肾脏疾病（CKD4）患者的队列，评估了GRU-D-Weibull在终点预测中的性能。在指标日期，GRU-D-Weibull的C-指数约为0.7，随着4.3年的随访，C-指数提高到约0.77，类似于随机生存森林。我们的方法在CKD4指标日期的绝对L1损失约为1.1年（标准差0.95），随访4年后的最小L1损失约为0.45年（标准差0.3），明显优于其他竞争方法。相比之下，GRU-D-Weibull在事件发生时的预测生存概率范围更小且更固定。

    Accurate prediction models for individual-level endpoints and time-to-endpoints are crucial in clinical practice. In this study, we propose a novel approach, GRU-D-Weibull, which combines gated recurrent units with decay (GRU-D) to model the Weibull distribution. Our method enables real-time individualized endpoint prediction and population-level risk management. Using a cohort of 6,879 patients with stage 4 chronic kidney disease (CKD4), we evaluated the performance of GRU-D-Weibull in endpoint prediction. The C-index of GRU-D-Weibull was ~0.7 at the index date and increased to ~0.77 after 4.3 years of follow-up, similar to random survival forest. Our approach achieved an absolute L1-loss of ~1.1 years (SD 0.95) at the CKD4 index date and a minimum of ~0.45 years (SD0.3) at 4 years of follow-up, outperforming competing methods significantly. GRU-D-Weibull consistently constrained the predicted survival probability at the time of an event within a smaller and more fixed range compared 
    
[^53]: 转移能力指标的性能并不能转化为医学任务

    The Performance of Transferability Metrics does not Translate to Medical Tasks. (arXiv:2308.07444v1 [cs.CV])

    [http://arxiv.org/abs/2308.07444](http://arxiv.org/abs/2308.07444)

    该论文研究了转移能力指标在医学任务中的表现，并发现现有的转移能力指标无法可靠地估计目标在医学环境中的性能。

    

    通过从大型数据集中获取的知识，转移学习提高了医学图像分析的性能，使得在小型数据集上进行深度学习成为可能。随着深度学习架构的数量急剧增加，耗尽所有候选者的尝试变得不可行，这促使人们寻找更便宜的选择方法。转移性评分方法成为一种有吸引力的解决方案，它可以有效地计算出与任何目标数据集上架构准确性相关的分数。然而，由于转移性评分在医学数据集上尚未得到评估，它们在这种情况下的使用仍然存在不确定性，无法使从业人员受益。我们在这项工作中填补了这一空白，对三个医学应用程序中的七个转移能力评分进行了全面评估，包括跨分布的情景。尽管在通用数据集中取得了有希望的结果，但我们的结果表明，没有一个转移能力评分能够可靠且一致地估计目标在医学环境中的性能。

    Transfer learning boosts the performance of medical image analysis by enabling deep learning (DL) on small datasets through the knowledge acquired from large ones. As the number of DL architectures explodes, exhaustively attempting all candidates becomes unfeasible, motivating cheaper alternatives for choosing them. Transferability scoring methods emerge as an enticing solution, allowing to efficiently calculate a score that correlates with the architecture accuracy on any target dataset. However, since transferability scores have not been evaluated on medical datasets, their use in this context remains uncertain, preventing them from benefiting practitioners. We fill that gap in this work, thoroughly evaluating seven transferability scores in three medical applications, including out-of-distribution scenarios. Despite promising results in general-purpose datasets, our results show that no transferability score can reliably and consistently estimate target performance in medical contex
    
[^54]: 使用物理先验的深度学习降低联合预测氮氧化物的偏差

    Physics-Informed Deep Learning to Reduce the Bias in Joint Prediction of Nitrogen Oxides. (arXiv:2308.07441v1 [cs.LG])

    [http://arxiv.org/abs/2308.07441](http://arxiv.org/abs/2308.07441)

    该论文提出了一个物理先验的深度学习框架，通过编码平流-扩散机制和流体动力学约束来联合预测NO2和NOx，并成功降低了机器学习模型的偏差。

    

    大气中的氮氧化物（NOx）主要来自燃料燃烧，对健康和环境有明显的急性和慢性影响。机器学习（ML）方法显著增强了我们在高时空分辨率下预测地面上NOx浓度的能力，但由于缺乏有关大气污染动力学的物理和化学知识，可能存在高估偏差。化学传输模型（CTMs）利用这些知识；然而，准确预测地面浓度通常需要进行广泛的后校准。在这里，我们提出了一个物理先验的深度学习框架，通过编码平流-扩散机制和流体动力学约束来联合预测NO2和NOx，并将ML模型的偏差降低了21-42％。我们的方法捕捉到了NO2和NOx的细粒度传输，生成了强大的空间外推，并提供了明确的不确定性估计。该框架将CTM的知识驱动的物理化学原理与深度学习相融合。

    Atmospheric nitrogen oxides (NOx) primarily from fuel combustion have recognized acute and chronic health and environmental effects. Machine learning (ML) methods have significantly enhanced our capacity to predict NOx concentrations at ground-level with high spatiotemporal resolution but may suffer from high estimation bias since they lack physical and chemical knowledge about air pollution dynamics. Chemical transport models (CTMs) leverage this knowledge; however, accurate predictions of ground-level concentrations typically necessitate extensive post-calibration. Here, we present a physics-informed deep learning framework that encodes advection-diffusion mechanisms and fluid dynamics constraints to jointly predict NO2 and NOx and reduce ML model bias by 21-42%. Our approach captures fine-scale transport of NO2 and NOx, generates robust spatial extrapolation, and provides explicit uncertainty estimation. The framework fuses knowledge-driven physicochemical principles of CTMs with th
    
[^55]: 使用时间图神经网络的交互感知个性化车辆轨迹预测

    Interaction-Aware Personalized Vehicle Trajectory Prediction Using Temporal Graph Neural Networks. (arXiv:2308.07439v1 [cs.LG])

    [http://arxiv.org/abs/2308.07439](http://arxiv.org/abs/2308.07439)

    本研究提出了一种交互感知的个性化车辆轨迹预测方法，利用时间图神经网络来建模目标车辆与周围交通之间的时空交互，并通过迁移学习来个性化预测。实验结果表明，该方法能够更准确地预测车辆的轨迹。

    

    准确预测车辆轨迹对于先进驾驶辅助系统和自动驾驶汽车至关重要。现有方法主要依赖于从大型数据集中推导出的通用轨迹预测，忽视了个别驾驶员的个性化驾驶模式。为了弥补这一差距，我们提出了一种交互感知的个性化车辆轨迹预测方法，该方法采用了时间图神经网络。我们的方法利用图卷积神经网络（GCN）和长短期记忆（LSTM）来建模目标车辆与周围交通之间的时空交互。为了个性化预测，我们建立了一个利用迁移学习的流程：模型首先在大规模轨迹数据集上进行预训练，然后使用特定驾驶数据针对每个驾驶员进行微调。我们采用人机协同仿真来收集个性化的自然驾驶轨迹及其相应的周围车辆轨迹。

    Accurate prediction of vehicle trajectories is vital for advanced driver assistance systems and autonomous vehicles. Existing methods mainly rely on generic trajectory predictions derived from large datasets, overlooking the personalized driving patterns of individual drivers. To address this gap, we propose an approach for interaction-aware personalized vehicle trajectory prediction that incorporates temporal graph neural networks. Our method utilizes Graph Convolution Networks (GCN) and Long Short-Term Memory (LSTM) to model the spatio-temporal interactions between target vehicles and their surrounding traffic. To personalize the predictions, we establish a pipeline that leverages transfer learning: the model is initially pre-trained on a large-scale trajectory dataset and then fine-tuned for each driver using their specific driving data. We employ human-in-the-loop simulation to collect personalized naturalistic driving trajectories and corresponding surrounding vehicle trajectories
    
[^56]: 适用于神经源代码摘要的语义相似性损失

    Semantic Similarity Loss for Neural Source Code Summarization. (arXiv:2308.07429v1 [cs.SE])

    [http://arxiv.org/abs/2308.07429](http://arxiv.org/abs/2308.07429)

    本文提出了一种适用于神经源代码摘要的改进损失函数，通过使用语义相似性度量来评估整个输出句子预测的损失，解决了当前方法中基于分类交叉熵损失函数的两个问题。

    

    本文提出了一种改进的损失函数用于神经源代码摘要。代码摘要是编写源代码的自然语言描述的任务。神经代码摘要是使用神经网络生成这些描述的自动化技术。几乎所有目前的方法都涉及神经网络作为独立模型或作为预训练的大型语言模型的一部分，例如GPT、Codex、LLaMA。然而，几乎所有方法都使用分类交叉熵（CCE）损失函数进行网络优化。CCE存在两个问题：1）它一次计算每个单词预测的损失，而不是评估整个句子；2）它要求完美预测，不允许对同义词给予部分信用。我们提出并评估了一种损失函数来缓解这个问题。实质上，我们建议使用语义相似性度量来计算整个输出句子预测的损失，而不仅仅是每个训练批次的损失。

    This paper presents an improved loss function for neural source code summarization. Code summarization is the task of writing natural language descriptions of source code. Neural code summarization refers to automated techniques for generating these descriptions using neural networks. Almost all current approaches involve neural networks as either standalone models or as part of a pretrained large language models e.g., GPT, Codex, LLaMA. Yet almost all also use a categorical cross-entropy (CCE) loss function for network optimization. Two problems with CCE are that 1) it computes loss over each word prediction one-at-a-time, rather than evaluating a whole sentence, and 2) it requires a perfect prediction, leaving no room for partial credit for synonyms. We propose and evaluate a loss function to alleviate this problem. In essence, we propose to use a semantic similarity metric to calculate loss over the whole output sentence prediction per training batch, rather than just loss for each 
    
[^57]: UniBrain: 统一图像重建和标题生成于一体的人脑活动扩散模型

    UniBrain: Unify Image Reconstruction and Captioning All in One Diffusion Model from Human Brain Activity. (arXiv:2308.07428v1 [cs.CV])

    [http://arxiv.org/abs/2308.07428](http://arxiv.org/abs/2308.07428)

    UniBrain 是一个统一的图像重建和标题生成模型，通过使用名为Versatile Diffusion的潜变量扩散模型，结合fMRI的图像和文本条件，实现了从人脑活动中生成逼真的图像和标题。

    

    通过对视觉刺激引起的脑活动进行图像重建和标题生成，研究人员可以进一步理解人脑与视觉感知系统之间的联系。尽管最近在该领域中使用了深度生成模型，但是在保持低层细节和高语义保真度的情况下重建逼真的标题和图像仍然是一个具有挑战性的问题。在这项工作中，我们提出了UniBrain：通过人脑活动的统一图像重建和标题生成在一个扩散模型中。这是第一次通过名为Versatile Diffusion的潜在扩散模型将图像重建和标题生成从视觉诱导功能磁共振成像（fMRI）统一起来。具体而言，我们将fMRI体素转换为文本和图像潜变量，用于低层信息，并通过基于fMRI的图像和文本条件从CLIP导引反向扩散过程，生成逼真的标题和图像。UniBrain在性能上超越了当前的方法

    Image reconstruction and captioning from brain activity evoked by visual stimuli allow researchers to further understand the connection between the human brain and the visual perception system. While deep generative models have recently been employed in this field, reconstructing realistic captions and images with both low-level details and high semantic fidelity is still a challenging problem. In this work, we propose UniBrain: Unify Image Reconstruction and Captioning All in One Diffusion Model from Human Brain Activity. For the first time, we unify image reconstruction and captioning from visual-evoked functional magnetic resonance imaging (fMRI) through a latent diffusion model termed Versatile Diffusion. Specifically, we transform fMRI voxels into text and image latent for low-level information and guide the backward diffusion process through fMRI-based image and text conditions derived from CLIP to generate realistic captions and images. UniBrain outperforms current methods both 
    
[^58]: 通过提示工程探索大型语言模型和基于Agent的建模的交叉点

    Exploring the Intersection of Large Language Models and Agent-Based Modeling via Prompt Engineering. (arXiv:2308.07411v1 [cs.AI])

    [http://arxiv.org/abs/2308.07411](http://arxiv.org/abs/2308.07411)

    通过提示工程，我们使用大型语言模型进行人类互动模拟，包括两个Agent的谈判和六个Agent的谋杀之谜游戏。

    

    模拟复杂真实世界社会系统的准确表示是一个最终的挑战。尽管基于Agent的建模（ABM）旨在研究一个更大系统中的Agent的行为和相互作用，但无法忠实地捕捉到人类驱动行为的全部复杂性。大型语言模型（LLMs），如ChatGPT，已经成为潜在的解决这一瓶颈的方法，使研究人员能够以前所未有的方式探索人类驱动的互动。我们的研究通过受Park等人（2023年）启发的提示工程，调查了使用LLMs进行人类互动模拟的场景。我们提出了两个关于人类行为的可信代理的仿真：一个是两个Agent的谈判，另一个是六个Agent的谋杀之谜游戏。

    The final frontier for simulation is the accurate representation of complex, real-world social systems. While agent-based modeling (ABM) seeks to study the behavior and interactions of agents within a larger system, it is unable to faithfully capture the full complexity of human-driven behavior. Large language models (LLMs), like ChatGPT, have emerged as a potential solution to this bottleneck by enabling researchers to explore human-driven interactions in previously unimaginable ways. Our research investigates simulations of human interactions using LLMs. Through prompt engineering, inspired by Park et al. (2023), we present two simulations of believable proxies of human behavior: a two-agent negotiation and a six-agent murder mystery game.
    
[^59]: PARIS: 面向关节物体的部分级别重建与运动分析

    PARIS: Part-level Reconstruction and Motion Analysis for Articulated Objects. (arXiv:2308.07391v1 [cs.CV])

    [http://arxiv.org/abs/2308.07391](http://arxiv.org/abs/2308.07391)

    PARIS是一种面向关节物体的部分级别重建与运动分析方法，它使用自我监督的、端到端的架构来学习隐式形状和外观模型，并在没有3D监督的情况下优化运动参数。与其他基线方法相比，PARIS方法在重建和运动估计方面表现出色，对于对象的重建距离减少了45.2%，对于部分的重建距离减少了84.5%。

    

    我们解决了关节物体的部分级别重建和运动参数估计的任务。给定一个物体在两个静态关节状态下的两组多视角图像，我们将可移动部分与静态部分分离出来，在预测运动参数的同时重建形状和外观。为了解决这个问题，我们提出了一种自我监督的、端到端的架构PARIS，该架构学习了部分级别的隐式形状和外观模型，并在没有任何3D监督、运动或语义注释的情况下共同优化运动参数。我们的实验结果表明，我们的方法在物体类别之间具有更好的泛化性，并且在给定3D点云作为输入的基准线和之前的工作中胜过了其他方法。我们的方法相对于最先进的基线方法改进了重建效果，对于对象的Chamfer-L1距离减少了3.94（45.2%），对于部分的距离减少了26.79（84.5%），并在10个对象类别中实现了5%的运动估计误差率。

    We address the task of simultaneous part-level reconstruction and motion parameter estimation for articulated objects. Given two sets of multi-view images of an object in two static articulation states, we decouple the movable part from the static part and reconstruct shape and appearance while predicting the motion parameters. To tackle this problem, we present PARIS: a self-supervised, end-to-end architecture that learns part-level implicit shape and appearance models and optimizes motion parameters jointly without any 3D supervision, motion, or semantic annotation. Our experiments show that our method generalizes better across object categories, and outperforms baselines and prior work that are given 3D point clouds as input. Our approach improves reconstruction relative to state-of-the-art baselines with a Chamfer-L1 distance reduction of 3.94 (45.2%) for objects and 26.79 (84.5%) for parts, and achieves 5% error rate for motion estimation across 10 object categories.  Video summar
    
[^60]: 使用图神经网络增强专家引导的网格划分的确认性预测

    Conformal Predictions Enhanced Expert-guided Meshing with Graph Neural Networks. (arXiv:2308.07358v1 [cs.GR])

    [http://arxiv.org/abs/2308.07358](http://arxiv.org/abs/2308.07358)

    本研究提出了一种机器学习的方案，结合图神经网络和专家指导自动化生成计算流体力学网格，并引入了一种新的三维分割算法，用于表面分类。

    

    计算流体力学在不同的工程领域广泛应用，但准确的模拟依赖于仿真域的适当网格划分。虽然高度精细的网格可以确保精度，但也带来了高计算成本。类似地，自适应重网格技术需要多次仿真，计算成本高。这意味着网格划分过程依赖于专业知识和多年的经验。自动化网格生成可以节省大量的时间和精力，并带来更快速和高效的设计过程。本文提出了一种基于机器学习的方案，利用图神经网络（GNN）和专家指导来自动生成飞机模型的计算流体力学网格。在这项工作中，我们引入了一种优于两个先进模型（PointNet++和PointMLP）的新的三维分割算法，用于表面分类。我们还提出了一种新颖的方法，用于从三维网格分割模型中投射预测结果。

    Computational Fluid Dynamics (CFD) is widely used in different engineering fields, but accurate simulations are dependent upon proper meshing of the simulation domain. While highly refined meshes may ensure precision, they come with high computational costs. Similarly, adaptive remeshing techniques require multiple simulations and come at a great computational cost. This means that the meshing process is reliant upon expert knowledge and years of experience. Automating mesh generation can save significant time and effort and lead to a faster and more efficient design process. This paper presents a machine learning-based scheme that utilizes Graph Neural Networks (GNN) and expert guidance to automatically generate CFD meshes for aircraft models. In this work, we introduce a new 3D segmentation algorithm that outperforms two state-of-the-art models, PointNet++ and PointMLP, for surface classification. We also present a novel approach to project predictions from 3D mesh segmentation model
    
[^61]: CORNET演示: 一种通过示例学习电子表格格式规则的系统

    Demonstration of CORNET: A System For Learning Spreadsheet Formatting Rules By Example. (arXiv:2308.07357v1 [cs.SE])

    [http://arxiv.org/abs/2308.07357](http://arxiv.org/abs/2308.07357)

    CORNET是一个可以通过示例自动学习电子表格条件格式化规则的系统，它结合了归纳程序合成和符号规则枚举方法，并使用神经网络评估器生成准确的规则。

    

    数据管理和分析任务通常使用电子表格软件来完成。大多数电子表格平台中一个受欢迎的功能是定义数据相关的格式规则。这些规则可以表达如“将某列中所有负数标记为红色”或“加粗所有不包含错误或故障的行”的操作。不幸的是，想要使用这个功能的用户需要手动编写这些条件格式化规则。我们介绍了CORNET，这是一个能够从用户示例中自动学习这些条件格式化规则的系统。CORNET借鉴了归纳程序合成的思想，结合了基于半监督聚类和迭代决策树学习的符号规则枚举方法，并使用神经网络评估器生成准确的条件格式化规则。在这个演示中，我们展示了CORNET作为Microsoft Excel的一个简单插件的使用情况。用户提供一个或两个格式化的单元格示例后，CORNET会生成格式化规则。

    Data management and analysis tasks are often carried out using spreadsheet software. A popular feature in most spreadsheet platforms is the ability to define data-dependent formatting rules. These rules can express actions such as "color red all entries in a column that are negative" or "bold all rows not containing error or failure." Unfortunately, users who want to exercise this functionality need to manually write these conditional formatting (CF) rules. We introduce CORNET, a system that automatically learns such conditional formatting rules from user examples. CORNET takes inspiration from inductive program synthesis and combines symbolic rule enumeration, based on semi-supervised clustering and iterative decision tree learning, with a neural ranker to produce accurate conditional formatting rules. In this demonstration, we show CORNET in action as a simple add-in to Microsoft Excel. After the user provides one or two formatted cells as examples, CORNET generates formatting rule s
    
[^62]: 基于贝叶斯物理信息神经网络的工程纳米颗粒在受污染含水层中的正向和反向模拟

    Bayesian Physics-Informed Neural Network for the Forward and Inverse Simulation of Engineered Nano-particles Mobility in a Contaminated Aquifer. (arXiv:2308.07352v1 [cs.LG])

    [http://arxiv.org/abs/2308.07352](http://arxiv.org/abs/2308.07352)

    本研究使用基于贝叶斯物理信息神经网络（B-PINN）的框架来模拟含水层中纳米颗粒的运动性，并为理解和开发高效的修复策略提供了预测性工具。

    

    在全球范围内，有许多受污染的地下水场地需要积极的修复计划来恢复当地生态系统和环境。工程纳米颗粒（ENPs）已被证明是地下水中污染物原位降解的有效反应剂。虽然这些ENPs在实验室阶段表现出色，但在实际场地条件下的应用仍然有限。ENPs的复杂输运和滞留机制阻碍了高效的修复策略的开发。因此，需要一种预测性工具来理解ENPs的输运和滞留行为。现有文献中的工具主要是以数值模拟器为主，对稀疏数据集和含水层异质性的存在具有有限的灵活性和准确性。本研究使用基于贝叶斯物理信息神经网络（B-PINN）的框架来模拟含水层中纳米颗粒的运动性。

    Globally, there are many polluted groundwater sites that need an active remediation plan for the restoration of local ecosystem and environment. Engineered nanoparticles (ENPs) have proven to be an effective reactive agent for the in-situ degradation of pollutants in groundwater. While the performance of these ENPs has been highly promising on the laboratory scale, their application in real field case conditions is still limited. The complex transport and retention mechanisms of ENPs hinder the development of an efficient remediation strategy. Therefore, a predictive tool to comprehend the transport and retention behavior of ENPs is highly required. The existing tools in the literature are dominated with numerical simulators, which have limited flexibility and accuracy in the presence of sparse datasets and the aquifer heterogeneity. This work uses a Bayesian Physics-Informed Neural Network (B-PINN) framework to model the nano-particles mobility within an aquifer. The result from the f
    
[^63]: IOB：集成优化传递和行为传递用于多策略复用

    IOB: Integrating Optimization Transfer and Behavior Transfer for Multi-Policy Reuse. (arXiv:2308.07351v1 [cs.LG])

    [http://arxiv.org/abs/2308.07351](http://arxiv.org/abs/2308.07351)

    该论文提出了一种新颖的传递强化学习方法，通过在actor-critic框架中使用Q函数来选择源策略，解决了在有限样本下选择适当的源策略的挑战。

    

    人类有能力重复利用之前学习的策略来快速解决新任务，而强化学习（RL）代理也可以通过从源策略向相关目标任务传递知识来做到同样的事情。传递RL方法可以通过改变策略优化目标（优化传递）或者影响行为策略（行为传递）来利用源策略。然而，在有限的样本下选择适当的源策略来引导目标策略学习一直是一个挑战。之前的方法引入了额外的组件，比如层次策略或者源策略的值函数估计，这可能导致非平稳的策略优化或者大量的采样成本，从而降低了传递的有效性。为了解决这个挑战，我们提出了一种新颖的传递RL方法，选择源策略而无需训练额外的组件。我们的方法利用了actor-critic框架中的Q函数来指导策略选择，选择源策略。

    Humans have the ability to reuse previously learned policies to solve new tasks quickly, and reinforcement learning (RL) agents can do the same by transferring knowledge from source policies to a related target task. Transfer RL methods can reshape the policy optimization objective (optimization transfer) or influence the behavior policy (behavior transfer) using source policies. However, selecting the appropriate source policy with limited samples to guide target policy learning has been a challenge. Previous methods introduce additional components, such as hierarchical policies or estimations of source policies' value functions, which can lead to non-stationary policy optimization or heavy sampling costs, diminishing transfer effectiveness. To address this challenge, we propose a novel transfer RL method that selects the source policy without training extra components. Our method utilizes the Q function in the actor-critic framework to guide policy selection, choosing the source poli
    
[^64]: 使用量化感知训练的高效神经PDE求解器

    Efficient Neural PDE-Solvers using Quantization Aware Training. (arXiv:2308.07350v1 [cs.LG])

    [http://arxiv.org/abs/2308.07350](http://arxiv.org/abs/2308.07350)

    使用量化感知训练的高效神经PDE求解器研究了在减少计算成本方面的潜力，并证明了量化网络权重和激活可以成功降低计算成本而不损害性能。

    

    过去几年中，将神经网络应用作为解决偏微分方程的经典数值方法的替代方案已经成为这个有着百年历史的数学领域潜在范式转变。然而，在实际可行性方面，计算成本仍然是一个重大瓶颈。传统的方法通过限制PDE定义的空间分辨率来减轻这个挑战。对于神经PDE求解器，我们可以做得更好：在这里，我们研究了最先进的量化方法在降低计算成本方面的潜力。我们展示了对网络权重和激活进行量化可以成功降低推断的计算成本，同时保持性能。我们在四个标准PDE数据集和三个网络架构上的结果表明，量化感知训练适用于各种设置和三个数量级的FLOPs。最后，我们以实证的方式证明了计算成本与模型性能之间的帕累托最优关系。

    In the past years, the application of neural networks as an alternative to classical numerical methods to solve Partial Differential Equations has emerged as a potential paradigm shift in this century-old mathematical field. However, in terms of practical applicability, computational cost remains a substantial bottleneck. Classical approaches try to mitigate this challenge by limiting the spatial resolution on which the PDEs are defined. For neural PDE solvers, we can do better: Here, we investigate the potential of state-of-the-art quantization methods on reducing computational costs. We show that quantizing the network weights and activations can successfully lower the computational cost of inference while maintaining performance. Our results on four standard PDE datasets and three network architectures show that quantization-aware training works across settings and three orders of FLOPs magnitudes. Finally, we empirically demonstrate that Pareto-optimality of computational cost vs p
    
[^65]: 针对旅行商问题的并行元启发式求解器的集合

    A Parallel Ensemble of Metaheuristic Solvers for the Traveling Salesman Problem. (arXiv:2308.07347v1 [cs.AI])

    [http://arxiv.org/abs/2308.07347](http://arxiv.org/abs/2308.07347)

    这篇论文研究了并行集合中旅行商问题的元启发式求解器。通过将不同求解器结合使用，能够超越单个求解器的性能表现。

    

    旅行商问题（TSP）是文献中研究较多的NP-hard问题之一。最先进的近似TSP求解器是Lin-Kernighan-Helsgaun（LKH）启发式算法和Edge Assembly交叉算法（EAX）。最近的研究表明，带有重启机制的EAX在广泛的TSP实例中表现优秀。然而，这项研究仅限于涉及2000个城市的问题。我们研究了从2000到85900个城市的问题。我们发现求解器的性能因问题类型而异。然而，将这些求解器结合在一起，以集合的方式使用，我们能够超越单独求解器的性能。我们认为集合式设置是利用丰富的计算资源的有效方式。除了EAX和LKH，我们还使用了EAX和混合遗传算法（MGA）的多个版本的混合算法。MGA和EAX的混合已经被证明可以解决一些困难的问题。我们发现混合版本的集合胜过了最先进的求解器。

    The travelling salesman problem (TSP) is one of the well-studied NP-hard problems in the literature. The state-of-the art inexact TSP solvers are the Lin-Kernighan-Helsgaun (LKH) heuristic and Edge Assembly crossover (EAX). A recent study suggests that EAX with restart mechanisms perform well on a wide range of TSP instances. However, this study is limited to 2,000 city problems. We study for problems ranging from 2,000 to 85,900. We see that the performance of the solver varies with the type of the problem. However, combining these solvers in an ensemble setup, we are able to outperform the individual solver's performance. We see the ensemble setup as an efficient way to make use of the abundance of compute resources. In addition to EAX and LKH, we use several versions of the hybrid of EAX and Mixing Genetic Algorithm (MGA). A hybrid of MGA and EAX is known to solve some hard problems. We see that the ensemble of the hybrid version outperforms the state-of-the-art solvers on problems 
    
[^66]: Py-Tetrad和RPy-Tetrad：支持Tetrad因果搜索的新Python界面与R支持

    Py-Tetrad and RPy-Tetrad: A New Python Interface with R Support for Tetrad Causal Search. (arXiv:2308.07346v1 [cs.MS])

    [http://arxiv.org/abs/2308.07346](http://arxiv.org/abs/2308.07346)

    Py-Tetrad和RPy-Tetrad是提供了新的Python和R接口的项目，用于将Python和R与Tetrad因果搜索工具进行接口化，解决了现有方法不足的问题。

    

    我们为Tetrad项目提供了新颖的Python和R接口，用于因果建模、搜索和估计（使用Java编写）。Tetrad项目已经在文献中扎根30多年，它的一些算法已经成为经典，如PC和FCI，而其他算法则是最近的发展。然而，越来越多的研究人员需要从Python或R中访问底层的Java代码，现有的方法不够满足需求。我们提供了新的、最新的方法，使用JPype Python-Java接口和Reticulate Python-R接口，直接解决了这些问题。通过添加一些简单的工具和提供Python和R的工作示例，使用JPype和Reticulate将Python和R与Tetrad进行接口化变得简单直观。

    We give novel Python and R interfaces for the (Java) Tetrad project for causal modeling, search, and estimation. The Tetrad project is a mainstay in the literature, having been under consistent development for over 30 years. Some of its algorithms are now classics, like PC and FCI; others are recent developments. It is increasingly the case, however, that researchers need to access the underlying Java code from Python or R. Existing methods for doing this are inadequate. We provide new, up-to-date methods using the JPype Python-Java interface and the Reticulate Python-R interface, directly solving these issues. With the addition of some simple tools and the provision of working examples for both Python and R, using JPype and Reticulate to interface Python and R with Tetrad is straightforward and intuitive.
    
[^67]: 从合成语料库和形式逻辑学习演绎推理

    Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic. (arXiv:2308.07336v1 [cs.AI])

    [http://arxiv.org/abs/2308.07336](http://arxiv.org/abs/2308.07336)

    本研究研究了一种从合成语料库中学习演绎推理能力的方法，通过采用基于形式逻辑理论的演绎规则，训练的语言模型具有更泛化的推理能力。

    

    我们研究了一种从合成语料库中学习演绎推理能力的语言模型（LMs）方法。之前的研究使用了具体的演绎规则来生成演绎示例，但这些规则受限或者是任意的。这可能限制了所获得演绎推理能力的泛化能力。我们重新思考并采用基于形式逻辑理论的一组良好基础的演绎规则，当这些规则以多步方式组合时，可以推导出任何其他演绎规则。我们通过实验证明，在提出的语料库上训练的LMs，即$\textbf{FLD}$（$\textbf{F}$ormal $\textbf{L}$ogic $\textbf{D}$eduction），获得了更具泛化性的演绎推理能力。此外，我们确定了演绎推理语料库可以增强LMs的推理能力的方面，以及不同方面无法增强的方面。最后，基于这些结果，我们讨论了将演绎语料库或其他方法应用于每个方面的未来方向。

    We study a synthetic corpus-based approach for language models (LMs) to acquire logical deductive reasoning ability. The previous studies generated deduction examples using specific sets of deduction rules. However, these rules were limited or otherwise arbitrary. This can limit the generalizability of acquired deductive reasoning ability. We rethink this and adopt a well-grounded set of deduction rules based on formal logic theory, which can derive any other deduction rules when combined in a multistep way. We empirically verify that LMs trained on the proposed corpora, which we name $\textbf{FLD}$ ($\textbf{F}$ormal $\textbf{L}$ogic $\textbf{D}$eduction), acquire more generalizable deductive reasoning ability. Furthermore, we identify the aspects of deductive reasoning ability on which deduction corpora can enhance LMs and those on which they cannot. Finally, on the basis of these results, we discuss the future directions for applying deduction corpora or other approaches for each as
    
[^68]: 一个编码-解码的方法用于装填圆形

    An Encoder-Decoder Approach for Packing Circles. (arXiv:2308.07335v1 [cs.AI])

    [http://arxiv.org/abs/2308.07335](http://arxiv.org/abs/2308.07335)

    本文提出了一个编码-解码的方法，用于将相同的圆形放置在一个较大的圆形中。该方法通过编码和解码过程，以及添加受控扰动来有效解决装填问题。

    

    自从几十年以来，将较小的物体完全放置在较大的物体内一直是一个有趣的问题。在这些问题中，除了要求较小的物体必须完全位于较大的物体内，还要求它们不重叠或尽量最小化重叠面积。因此，装填问题成为一个非凸问题，其最优解的获取具有挑战性。因此，在一般情况下，我们使用了一些启发式方法来获取亚最优解，并针对某些特殊情况获得了可证明最优解。在本文中，我们提出了一种新颖的编码-解码架构，包括编码器块、扰动块和解码器块，用于将相同的圆形放置在一个较大的圆形中。在我们的方法中，编码器以要放置的圆的索引作为输入，并通过标准化层输出其中心，扰动层对中心添加受控扰动，以确保它不会超出边界。解码器通过反转编码器过程来恢复圆的位置。通过训练集进行训练和优化，我们的方法可以有效地解决圆形装填问题，并取得了很好的效果。

    The problem of packing smaller objects within a larger object has been of interest since decades. In these problems, in addition to the requirement that the smaller objects must lie completely inside the larger objects, they are expected to not overlap or have minimum overlap with each other. Due to this, the problem of packing turns out to be a non-convex problem, obtaining whose optimal solution is challenging. As such, several heuristic approaches have been used for obtaining sub-optimal solutions in general, and provably optimal solutions for some special instances. In this paper, we propose a novel encoder-decoder architecture consisting of an encoder block, a perturbation block and a decoder block, for packing identical circles within a larger circle. In our approach, the encoder takes the index of a circle to be packed as an input and outputs its center through a normalization layer, the perturbation layer adds controlled perturbations to the center, ensuring that it does not de
    
[^69]: Notation3作为一种存在规则语言

    Notation3 as an Existential Rule Language. (arXiv:2308.07332v1 [cs.AI])

    [http://arxiv.org/abs/2308.07332](http://arxiv.org/abs/2308.07332)

    本文研究了Notation3与存在规则之间的关系，并提出了一个将部分Notation3直接映射到存在规则的方法，从而提高了Notation3推理的效率。

    

    Notation3逻辑（\nthree）是RDF的扩展，允许用户编写引入新的空白节点到RDF图中的规则。许多应用程序（例如本体映射）依赖于此功能，因为空白节点在Web上广泛存在，直接使用或作为辅助结构。然而，涵盖该逻辑非常重要功能的快速\nthree推理器的数量相对有限。另一方面，像VLog或Nemo之类的引擎不直接支持语义Web规则格式，但是它们是为非常相似的构造（存在规则）开发和优化的。在本文中，我们研究了具有空白节点的\nthree规则与存在规则之间的关系。我们确定了一个可以直接映射到存在规则的\nthree子集，并定义了这样一个映射，保持了\nthree公式的等价性。为了进一步说明在某些情况下\nthree推理可以受益于我们的转换，我们使用该映射进行分析。

    Notation3 Logic (\nthree) is an extension of RDF that allows the user to write rules introducing new blank nodes to RDF graphs. Many applications (e.g., ontology mapping) rely on this feature as blank nodes -- used directly or in auxiliary constructs -- are omnipresent on the Web. However, the number of fast \nthree reasoners covering this very important feature of the logic is rather limited. On the other hand, there are engines like VLog or Nemo which do not directly support Semantic Web rule formats but which are developed and optimized for very similar constructs: existential rules. In this paper, we investigate the relation between \nthree rules with blank nodes in their heads and existential rules. We identify a subset of \nthree which can be mapped directly to existential rules and define such a mapping preserving the equivalence of \nthree formulae. In order to also illustrate that in some cases \nthree reasoning could benefit from our translation, we then employ this mapping i
    
[^70]: Blackjack的强化学习性能变化

    Variations on the Reinforcement Learning performance of Blackjack. (arXiv:2308.07329v1 [cs.AI])

    [http://arxiv.org/abs/2308.07329](http://arxiv.org/abs/2308.07329)

    本研究探讨了在不同的牌堆大小下，强化学习代理在Blackjack游戏中的表现变化。研究发现算法的学习收敛速度与牌堆大小有关，并展示了使用基本策略和HI-LO系统的牌数计数器如何使庄家破产。这项工作的创新之处在于认识到牌堆大小是影响Blackjack表现的关键因素。

    

    Blackjack或称为“21点”是一种流行的基于扑克牌的运气和技巧游戏。游戏的目标是在不超过21点的情况下，获得比庄家更高的手牌总数。理想的黑杰克策略将在长期内最大化财务回报，同时避免赌徒的破产。由于黑杰克的随机环境和固有的奖励结构，这为我们更好地理解强化学习代理在环境变化下的表现提供了一个吸引人的问题。在这里，我们考虑了一种用于最佳玩法的Q-learning解决方案，并研究了算法学习收敛速度与牌堆大小的关系。我们还实现了一个允许使用通用黑杰克规则的模拟器，以展示一个使用基本策略和HI-LO系统的牌数完美计数器如何使庄家破产，以及环境变化对这个结果的影响。我们的工作的创新之处在于将牌堆大小的影响概念性地理解为黑杰克中的因素。

    Blackjack or "21" is a popular card-based game of chance and skill. The objective of the game is to win by obtaining a hand total higher than the dealer's without exceeding 21. The ideal blackjack strategy will maximize financial return in the long run while avoiding gambler's ruin. The stochastic environment and inherent reward structure of blackjack presents an appealing problem to better understand reinforcement learning agents in the presence of environment variations. Here we consider a q-learning solution for optimal play and investigate the rate of learning convergence of the algorithm as a function of deck size. A blackjack simulator allowing for universal blackjack rules is also implemented to demonstrate the extent to which a card counter perfectly using the basic strategy and hi-lo system can bring the house to bankruptcy and how environment variations impact this outcome. The novelty of our work is to place this conceptual understanding of the impact of deck size in the con
    
[^71]: PokerKit: 一种用于细粒度多变体扑克游戏模拟的全面的Python库

    PokerKit: A Comprehensive Python Library for Fine-Grained Multi-Variant Poker Game Simulations. (arXiv:2308.07327v1 [cs.AI])

    [http://arxiv.org/abs/2308.07327](http://arxiv.org/abs/2308.07327)

    PokerKit是一个全面的Python库，用于细粒度多变体扑克游戏模拟，提供广泛的扑克变体支持和灵活的游戏状态控制，对扑克AI开发、工具创建和在线扑克赌场实现等领域具有重要贡献。

    

    PokerKit是一个开源的Python库，旨在克服现有扑克游戏模拟和手牌评估工具的限制，这些工具通常只支持少量扑克变体，并且在游戏状态控制方面缺乏灵活性。相比之下，PokerKit通过支持广泛的扑克变体，并提供灵活的架构供用户定义自定义游戏，显著扩大了这一范围。本文详细介绍了PokerKit的设计和实现，包括其直观的编程API，多变体游戏支持以及统一的手牌评估套件在不同手牌类型间的应用。PokerKit的灵活性使其能够在扑克AI开发、工具创建和在线扑克赌场实现等多个领域中使用。PokerKit的可靠性通过静态类型检查、广泛的doctest和单元测试来确保，达到了97%的代码覆盖率。引入PokerKit代表了对该领域的重要贡献。

    PokerKit is an open-source Python library designed to overcome the restrictions of existing poker game simulation and hand evaluation tools, which typically support only a handful of poker variants and lack flexibility in game state control. In contrast, PokerKit significantly expands this scope by supporting an extensive array of poker variants and it provides a flexible architecture for users to define their custom games. This paper details the design and implementation of PokerKit, including its intuitive programmatic API, multi-variant game support, and a unified hand evaluation suite across different hand types. The flexibility of PokerKit allows for applications in diverse areas, such as poker AI development, tool creation, and online poker casino implementation. PokerKit's reliability has been established through static type checking, extensive doctests, and unit tests, achieving 97\% code coverage. The introduction of PokerKit represents a significant contribution to the field 
    
[^72]: AI文本-行为：可操控性研究

    AI Text-to-Behavior: A Study In Steerability. (arXiv:2308.07326v1 [cs.AI])

    [http://arxiv.org/abs/2308.07326](http://arxiv.org/abs/2308.07326)

    本研究探讨了大型语言模型的可操控性，通过使用行为心理学框架，模型在生成文本时能够根据提示展现特定的行为特征。研究发现，模型在不同特征上的表现具有灵活性和区分度，并能够准确复制历史人物的个性和对话风格。

    

    该研究探讨了大型语言模型（LLM），特别是OpenAI的ChatGPT迭代版本的可操控性。通过采用一种名为OCEAN（开放性，责任心，外向性，宜人性，神经质）的行为心理学框架，我们量化评估了模型对定制提示的响应能力。当要求生成类似于外向人格的文本时，OCEAN得分对齐到了该行为特质。在我们的分析中，“开放性”呈现了语言的模糊性，而“责任心”和“神经质”在OCEAN框架中明确地被唤起，而“外向性”和“宜人性”则展示了与其他特征明显重叠但又有明显分离的特点。我们的发现强调了GPT的多功能性和识别以及适应微妙指导的能力。此外，历史人物模拟突出了LLM内化和投射可指导个性的能力，精确复制了他们的哲学和对话风格。

    The research explores the steerability of Large Language Models (LLMs), particularly OpenAI's ChatGPT iterations. By employing a behavioral psychology framework called OCEAN (Openness, Conscientiousness, Extroversion, Agreeableness, Neuroticism), we quantitatively gauged the model's responsiveness to tailored prompts. When asked to generate text mimicking an extroverted personality, OCEAN scored the language alignment to that behavioral trait. In our analysis, while "openness" presented linguistic ambiguity, "conscientiousness" and "neuroticism" were distinctly evoked in the OCEAN framework, with "extroversion" and "agreeableness" showcasing a notable overlap yet distinct separation from other traits. Our findings underscore GPT's versatility and ability to discern and adapt to nuanced instructions. Furthermore, historical figure simulations highlighted the LLM's capacity to internalize and project instructible personas, precisely replicating their philosophies and dialogic styles. How
    
[^73]: MSLE：一种用于材料科学实验室设备的本体论。用于材料表征的大规模设备。

    MSLE: An ontology for Materials Science Laboratory Equipment. Large-Scale Devices for Materials Characterization. (arXiv:2308.07325v1 [cs.AI])

    [http://arxiv.org/abs/2308.07325](http://arxiv.org/abs/2308.07325)

    本论文提出了一种用于材料科学实验室设备的新本体论MSLE，通过整合现有的本体论，建立一个一致的设备描述，为科学家们提供指导，解决了多种设备类型和规格的统一描述问题。

    

    本论文介绍了一种用于材料科学实验室设备的新本体论，称为MSLE。现实世界中材料科学实验室设备的一个基本问题是科学家们使用各种类型和多个规格的设备。例如，在化学和物理实验室中有许多具有不同参数的电子显微镜。统一描述的一个关键发展是建立一个设备领域本体论作为基本的语义知识，并指导用户适当地使用设备。在这里，我们提议开发一种一致的设备本体论，即MSLE本体论。在MSLE中，将两个主要的现有本体论，语义传感器网络（SSN）和材料词汇（MatVoc），集成到MSLE核心中以建立一个一致的本体论。由于设备使用了各种缩写词和术语，本论文提出了使用简单知识组织系统（SKOS）来表示将这些表示处理成本体论术语的方法。

    This paper introduces a new ontology for Materials Science Laboratory Equipment, termed MSLE. A fundamental issue with materials science laboratory (hereafter lab) equipment in the real world is that scientists work with various types of equipment with multiple specifications. For example, there are many electron microscopes with different parameters in chemical and physical labs. A critical development to unify the description is to build an equipment domain ontology as basic semantic knowledge and to guide the user to work with the equipment appropriately. Here, we propose to develop a consistent ontology for equipment, the MSLE ontology. In the MSLE, two main existing ontologies, the Semantic Sensor Network (SSN) and the Material Vocabulary (MatVoc), have been integrated into the MSLE core to build a coherent ontology. Since various acronyms and terms have been used for equipment, this paper proposes an approach to use a Simple Knowledge Organization System (SKOS) to represent the h
    
[^74]: 支持医院病例组合规划的分析技术

    Analytical Techniques to Support Hospital Case Mix Planning. (arXiv:2308.07323v1 [cs.AI])

    [http://arxiv.org/abs/2308.07323](http://arxiv.org/abs/2308.07323)

    本文介绍了一种支持医院病例组合规划的分析技术和决策支持工具，包括优化模型和多目标决策技术，可以对医院容量进行信息量化评估。

    

    本文介绍了一种支持容量评估和医院病例组合规划的分析技术和决策支持工具。首先，提出了一个优化模型，用于分析对已有病例组合进行修改的影响。该模型确定了在医院资源可用性发生变化时，其他患者类型应按比例进行修改的方式。然后，我们提出了多目标决策技术，用于比较和评价获得的竞争性病例组合解决方案。所提出的技术无缝嵌入在Excel的Visual Basic for Applications（VBA）个人决策支持工具（PDST）中，用于对医院容量进行信息量化评估。PDST报告了不同指标的差异信息，并报告了病例组合修改对其他患者类型的影响。本文开发的技术为当前理论和实践之间建立了桥梁。

    This article introduces analytical techniques and a decision support tool to support capacity assessment and case mix planning (CMP) approaches previously created for hospitals. First, an optimization model is proposed to analyse the impact of making a change to an existing case mix. This model identifies how other patient types should be altered proportionately to the changing levels of hospital resource availability. Then we propose multi-objective decision-making techniques to compare and critique competing case mix solutions obtained. The proposed techniques are embedded seamlessly within an Excel Visual Basic for Applications (VBA) personal decision support tool (PDST), for performing informative quantitative assessments of hospital capacity. The PDST reports informative metrics of difference and reports the impact of case mix modifications on the other types of patient present. The techniques developed in this article provide a bridge between theory and practice that is currently
    
[^75]: 医院病例组成的多准则优化技术

    Multicriteria Optimization Techniques for Understanding the Case Mix Landscape of a Hospital. (arXiv:2308.07322v1 [cs.AI])

    [http://arxiv.org/abs/2308.07322](http://arxiv.org/abs/2308.07322)

    本文提出了一种多准则优化方法来理解医院的病例组成，通过改进的并行化方法生成非支配病例组成存档，以提高容量利用率。

    

    一个典型医院内有各种医疗和手术单位，为了治疗患者，这些单位竞争手术室和病房资源。如何管控这种竞争对医院的能力和产出有着重要影响。本文考虑了在医院中治疗不同病例组成的影响。由于每种病例组成都有经济后果和独特的医院资源使用特征，因此这一考虑非常重要。为了更好地理解病例组成的情况，并从容量利用角度确定最优的病例组成，提出了一种改进的多准则优化方法。在典型医院中有很多病患类型，生成一组非支配（即帕累托最优）病例组成的存档是一项具有计算挑战性的任务。为了生成更好的存档，引入了一种改进的并行化ε约束方法 (ECM)。我们的并行随机修正方法速度显著加快。

    Various medical and surgical units operate in a typical hospital and to treat their patients these units compete for infrastructure like operating rooms (OR) and ward beds. How that competition is regulated affects the capacity and output of a hospital. This article considers the impact of treating different patient case mix (PCM) in a hospital. As each case mix has an economic consequence and a unique profile of hospital resource usage, this consideration is important. To better understand the case mix landscape and to identify those which are optimal from a capacity utilisation perspective, an improved multicriteria optimization (MCO) approach is proposed. As there are many patient types in a typical hospital, the task of generating an archive of non-dominated (i.e., Pareto optimal) case mix is computationally challenging. To generate a better archive, an improved parallelised epsilon constraint method (ECM) is introduced. Our parallel random corrective approach is significantly fast
    
[^76]: 多准则医院病例组合规划的效能性别作用 (arXiv：2308.07321v1[cs.AI])

    The Efficacy of Utility Functions for Multicriteria Hospital Case-Mix Planning. (arXiv:2308.07321v1 [cs.AI])

    [http://arxiv.org/abs/2308.07321](http://arxiv.org/abs/2308.07321)

    本文介绍了一种利用效用函数的多准则医院病例组合规划的新方法，通过提供一种方法来评估不同利益相关者和医院目标之间的权衡，解决了当前CMP中的各种技术限制和缺陷。

    

    本文介绍了一种新的医院病例组合规划（CMP）方法。我们的多准则方法利用效用函数（UF）来表达独立决策者关于输出的偏好和立场。本文的主要目的是测试基于上述UF标量化的效用函数方法（UFM）是否是一个合适的定量技术，以实现以下目标：i）将医院资源分配到不同的运营单位；ii）提供更好的容量分配和病例组合。我们的方法源于对评估不同利益相关者和医院目标之间权衡的需求。据我们所知，以前的文献中没有考虑过这种方法。正如我们将在后面展示的，这个想法解决了当前CMP中的各种技术限制、弱点和缺陷。我们对一家大型三级医院的案例研究进行了上述方法的有效性测试。

    A new approach to perform hospital case-mix planning (CMP) is introduced in this article. Our multi-criteria approach utilises utility functions (UF) to articulate the preferences and standpoint of independent decision makers regarding outputs. The primary aim of this article is to test whether a utility functions method (UFM) based upon the scalarization of aforesaid UF is an appropriate quantitative technique to, i) distribute hospital resources to different operating units, and ii) provide a better capacity allocation and case mix. Our approach is motivated by the need to provide a method able to evaluate the trade-off between different stakeholders and objectives of hospitals. To the best of our knowledge, no such approach has been considered before in the literature. As we will later show, this idea addresses various technical limitations, weaknesses, and flaws in current CMP. The efficacy of the aforesaid approach is tested on a case study of a large tertiary hospital. Currently 
    
[^77]: LLM自卫：通过自检，LLMs意识到它们被愚弄了。

    LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked. (arXiv:2308.07308v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.07308](http://arxiv.org/abs/2308.07308)

    本文提出了一种通过自检来防御大型语言模型(LLMs)对抗性攻击的简单方法，即让模型自行过滤回应。实验结果表明，即使模型未对齐人类价值观，通过使用语言模型验证内容，仍然可以防止模型向用户呈现有害内容。

    

    近年来，大型语言模型（LLMs）由于其能够对人类提示做出高质量文本回应而变得非常受欢迎。然而，研究表明，这些模型在回应用户提示时可能生成有害内容（例如，给用户提供犯罪指导）。文献中已经着重研究如何通过方法（例如通过强化学习将模型与人类价值观对齐）来减轻这些风险。然而，研究发现，即使对齐的语言模型也容易受到绕过生成有害文本限制的对抗性攻击。我们提出了一种简单的方法来防御这些攻击，即大型语言模型对自己的回应进行过滤。我们目前的研究结果表明，即使模型没有被微调以与人类价值观对齐，也可以通过使用语言模型验证内容来防止其向用户呈现有害内容。

    Large language models (LLMs) have skyrocketed in popularity in recent years due to their ability to generate high-quality text in response to human prompting. However, these models have been shown to have the potential to generate harmful content in response to user prompting (e.g., giving users instructions on how to commit crimes). There has been a focus in the literature on mitigating these risks, through methods like aligning models with human values through reinforcement learning. However, it has been shown that even aligned language models are susceptible to adversarial attacks that bypass their restrictions on generating harmful text. We propose a simple approach to defending against these attacks by having a large language model filter its own responses. Our current results show that even if a model is not fine-tuned to be aligned with human values, it is possible to stop it from presenting harmful content to users by validating the content using a language model.
    
[^78]: 为什么不呢？用Evee解释缺失的蕴涵关系（技术报告）

    Why Not? Explaining Missing Entailments with Evee (Technical Report). (arXiv:2308.07294v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.07294](http://arxiv.org/abs/2308.07294)

    本文介绍了新版本的Evee插件，它通过基于绑定和反例的技术来解释本体中缺失的蕴涵关系。

    

    对于本体用户来说，理解描述逻辑推理器派生出的逻辑蕴涵关系并不总是直接的。因此，已经开发和实现了各种用于解释蕴涵关系的方法，这些方法通过证明和证据作为Protégé本体编辑器的插件来提供。然而，当用户预期某种缺失的蕴涵关系应该成立时，同样重要的是解释为什么它不会从本体中得出。在本文中，我们描述了EVEE的新版本，它是一个Protégé插件，现在还通过基于绑定和反例的现有和新技术来提供解释缺失蕴涵关系的功能。

    Understanding logical entailments derived by a description logic reasoner is not always straight-forward for ontology users. For this reason, various methods for explaining entailments using justifications and proofs have been developed and implemented as plug-ins for the ontology editor Prot\'eg\'e. However, when the user expects a missing consequence to hold, it is equally important to explain why it does not follow from the ontology. In this paper, we describe a new version of $\rm E{\scriptsize VEE}$, a Prot\'eg\'e plugin that now also provides explanations for missing consequences, via existing and new techniques based on abduction and counterexamples.
    
[^79]: #InsTag:针对大型语言模型监督微调的指令标注分析

    #InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of Large Language Models. (arXiv:2308.07074v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.07074](http://arxiv.org/abs/2308.07074)

    本研究提出了InsTag，一种用于标记基于语义和意图的监督微调（SFT）数据集样本的开放式细粒度标注器。通过分析开源SFT数据集，发现模型能力会随着更多多样化和复杂化的数据而增长。基于这一观察结果，使用InsTag选择的数据进行模型微调，得到的TagLM模型在大规模SFT数据上优于开源模型，验证了查询多样性和复杂性的重要性。

    

    基于监督微调（SFT），基础语言模型获得了遵循指令的能力。多样性和复杂性被认为是成功的SFT数据集的重要因素，但其定义仍然模糊不清，缺乏定量分析。在这项工作中，我们提出了InsTag，一种开放的细粒度标注器，根据语义和意图对SFT数据集中的样本进行标记，并且通过标签来定义指令的多样性和复杂性。我们获得了6.6K个标签来描述综合用户查询。然后，我们分析了一些流行的开源SFT数据集，并发现模型的能力随着更多多样化和复杂化的数据而增长。基于这一观察结果，我们提出了一个基于InsTag的数据选择器，从开源数据集中选择6K个多样性和复杂性样本，并在InsTag选择的数据上进行模型微调。结果表明，TagLM模型在MT-Bench评估的大规模SFT数据上优于开源模型，验证了查询多样性和复杂性的重要性。

    Foundation language models obtain the instruction-following ability through supervised fine-tuning (SFT). Diversity and complexity are considered critical factors of a successful SFT dataset, while their definitions remain obscure and lack quantitative analyses. In this work, we propose InsTag, an open-set fine-grained tagger, to tag samples within SFT datasets based on semantics and intentions and define instruction diversity and complexity regarding tags. We obtain 6.6K tags to describe comprehensive user queries. Then we analyze popular open-sourced SFT datasets and find that the model ability grows with more diverse and complex data. Based on this observation, we propose a data selector based on InsTag to select 6K diverse and complex samples from open-source datasets and fine-tune models on InsTag-selected data. The resulting models, TagLM, outperform open-source models based on considerably larger SFT data evaluated by MT-Bench, echoing the importance of query diversity and compl
    
[^80]: SAILOR: 基于结构增强的尾节点表示学习

    SAILOR: Structural Augmentation Based Tail Node Representation Learning. (arXiv:2308.06801v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2308.06801](http://arxiv.org/abs/2308.06801)

    SAILOR是一种基于结构增强的尾节点表示学习框架，针对真实场景中长尾分布的图节点度数，通过学习增强图结构和提取更有信息的尾节点表示，解决了GNN在尾节点表示上的性能退化问题。

    

    近期，图神经网络（GNN）在图表示学习方面取得了最先进的性能。然而，GNN的有效性主要依赖于拓扑结构的质量，而大多数真实场景中的图节点度数呈现长尾分布，即图中大部分节点都是只有少数连接边的尾节点。由于缺乏结构信息，GNN对尾节点产生较差的节点表示。为了提升GNN对尾节点的表达能力，我们研究了结构信息不足如何恶化尾节点的性能，并提出了一种名为SAILOR的通用结构增强的尾节点表示学习框架，该框架可以同时学习增强图结构和提取更多有信息的尾节点表示。

    Graph Neural Networks (GNNs) have achieved state-of-the-art performance in representation learning for graphs recently. However, the effectiveness of GNNs, which capitalize on the key operation of message propagation, highly depends on the quality of the topology structure. Most of the graphs in real-world scenarios follow a long-tailed distribution on their node degrees, that is, a vast majority of the nodes in the graph are tail nodes with only a few connected edges. GNNs produce inferior node representations for tail nodes since they lack structural information. In the pursuit of promoting the expressiveness of GNNs for tail nodes, we explore how the deficiency of structural information deteriorates the performance of tail nodes and propose a general Structural Augmentation based taIL nOde Representation learning framework, dubbed as SAILOR, which can jointly learn to augment the graph structure and extract more informative representations for tail nodes. Extensive experiments on pu
    
[^81]: MC-DRE: 多方面交叉整合用于药物事件/实体提取

    MC-DRE: Multi-Aspect Cross Integration for Drug Event/Entity Extraction. (arXiv:2308.06546v1 [cs.CL])

    [http://arxiv.org/abs/2308.06546](http://arxiv.org/abs/2308.06546)

    本文提出了一个新的多方面交叉整合框架，用于从药物相关文档中提取药物事件/实体。该框架能够捕捉并对齐不同的上下文/语言/知识属性，并实现药物事件信息的全面检测和理解。

    

    提取有意义的药物相关信息块，如不良药物事件（ADE），对于预防疾病和拯救许多生命至关重要。大多数ADE是通过医疗背景下的非结构化对话报告的。因此，应用通用实体识别方法是不足够的。关键在于如何整合和对齐多个关键方面来检测药物事件信息，包括药物事件语义、句法结构和医学领域术语。在本文中，我们提出了一个新的多方面交叉整合框架，通过从药物相关文档中捕捉和对齐不同的上下文/语言/知识属性，用于药物实体/事件检测。我们首先构建多方面编码器来描述语义、句法和医学文档上下文信息，方法包括槽标注任务、主要药物实体/事件检测、词性标注和通用医学命名实体识别。然后，每个编码器进行交叉整合。

    Extracting meaningful drug-related information chunks, such as adverse drug events (ADE), is crucial for preventing morbidity and saving many lives. Most ADE are reported via an unstructured conversation with the medical context. Hence, applying a general entity recognition approach is not sufficient enough. The key is how to integrate and align multiple crucial aspects to detect drug event information, including drug event semantics, syntactic structures, and medical domain terminology. In this paper, we propose a new multi-aspect cross-integration framework for drug entity/event detection by capturing and aligning different context/language/knowledge properties from drug-related documents. We first construct multi-aspect encoders to describe semantic, syntactic, and medical document contextual information by conducting those slot tagging tasks, main drug entity/event detection, part-of-speech tagging, and general medical named entity recognition. Then, each encoder conducts cross int
    
[^82]: 通过在数学和科学问题上使用Wolfram Alpha和Code Interpreter插件测试GPT-4

    Testing GPT-4 with Wolfram Alpha and Code Interpreter plug-ins on math and science problems. (arXiv:2308.05713v1 [cs.AI])

    [http://arxiv.org/abs/2308.05713](http://arxiv.org/abs/2308.05713)

    本研究测试了GPT-4在科学和数学问题上使用Wolfram Alpha和Code Interpreter插件的效果，结果表明插件显著提升了GPT的问题解决能力，但接口故障仍然是其可靠性的主要挑战。

    

    本报告描述了在2023年6月至8月期间对大型语言模型GPT-4在科学和数学领域进行的105个原创问题的测试，其中使用了Wolfram Alpha和Code Interpreter插件。我们的测试表明，这些插件显著增强了GPT解决这些问题的能力。然而，仍然经常出现“接口”故障；也就是说，GPT经常在问题的表述上遇到困难，无法从插件中得到有用的答案。解决这些接口故障似乎是使GPT成为可靠的大学级计算问题工具的关键挑战。

    This report describes a test of the large language model GPT-4 with the Wolfram Alpha and the Code Interpreter plug-ins on 105 original problems in science and math, at the high school and college levels, carried out in June-August 2023. Our tests suggest that the plug-ins significantly enhance GPT's ability to solve these problems. Having said that, there are still often "interface" failures; that is, GPT often has trouble formulating problems in a way that elicits useful answers from the plug-ins. Fixing these interface failures seems like a central challenge in making GPT a reliable tool for college-level calculation problems.
    
[^83]: 无法测量混淆因素下因果推断中的扩散模型

    Diffusion Model in Causal Inference with Unmeasured Confounders. (arXiv:2308.03669v1 [cs.LG])

    [http://arxiv.org/abs/2308.03669](http://arxiv.org/abs/2308.03669)

    本研究扩展了扩散模型的使用，提出了一种新的模型BDCM，可以在存在无法测量的混淆因素的情况下更准确地回答因果问题。

    

    我们研究了如何在无法测量的混淆因素存在的情况下，扩展扩散模型的使用，以从观测数据中回答因果问题。在Pearl的使用有向无环图（DAG）捕捉因果干预的框架中，提出了一种基于扩散模型的因果模型（DCM），可以更准确地回答因果问题，假设所有混淆因素都是可以观察到的。然而，实际中存在无法测量的混淆因素，这使得DCM无法应用。为了缓解DCM的这一局限性，我们提出了一个扩展模型，称为基于反门准则的DCM（BDCM），其思想根植于在DAG中找到要包括在扩散模型解码过程中的变量的反门准则，这样我们可以将DCM扩展到存在无法测量的混淆因素的情况。合成数据实验表明，我们提出的模型在无法测量混淆因素的情况下更精确地捕捉到了反事实分布。

    We study how to extend the use of the diffusion model to answer the causal question from the observational data under the existence of unmeasured confounders. In Pearl's framework of using a Directed Acyclic Graph (DAG) to capture the causal intervention, a Diffusion-based Causal Model (DCM) was proposed incorporating the diffusion model to answer the causal questions more accurately, assuming that all of the confounders are observed. However, unmeasured confounders in practice exist, which hinders DCM from being applicable. To alleviate this limitation of DCM, we propose an extended model called Backdoor Criterion based DCM (BDCM), whose idea is rooted in the Backdoor criterion to find the variables in DAG to be included in the decoding process of the diffusion model so that we can extend DCM to the case with unmeasured confounders. Synthetic data experiment demonstrates that our proposed model captures the counterfactual distribution more precisely than DCM under the unmeasured confo
    
[^84]: SynJax: JAX的结构化概率分布

    SynJax: Structured Probability Distributions for JAX. (arXiv:2308.03291v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2308.03291](http://arxiv.org/abs/2308.03291)

    SynJax是一个针对JAX的结构化概率分布库，通过提供高效的向量化实现解决了对于结构化对象的难以实现的问题。

    

    深度学习软件库的发展使得该领域取得了显著的进展，它使用户能够专注于建模，同时让库来处理针对现代硬件加速器进行优化执行的繁琐和耗时的任务。然而，这仅对特定类型的深度学习模型有益，例如Transformer，其基本操作易于映射到向量化计算。而对于显式考虑结构化对象（如树和分割）的模型，并没有同样的受益，因为它们需要定制的难以以向量化形式实现的算法。SynJax通过提供用于结构化分布的推理算法的高效向量化实现来直接解决这个问题，包括对齐、标记、分割、组成树和生成树的处理。使用SynJax，我们可以构建大规模的可微分模型，显式地对数据的结构进行建模。代码可在https://g中获得。

    The development of deep learning software libraries enabled significant progress in the field by allowing users to focus on modeling, while letting the library to take care of the tedious and time-consuming task of optimizing execution for modern hardware accelerators. However, this has benefited only particular types of deep learning models, such as Transformers, whose primitives map easily to the vectorized computation. The models that explicitly account for structured objects, such as trees and segmentations, did not benefit equally because they require custom algorithms that are difficult to implement in a vectorized form.  SynJax directly addresses this problem by providing an efficient vectorized implementation of inference algorithms for structured distributions covering alignment, tagging, segmentation, constituency trees and spanning trees. With SynJax we can build large-scale differentiable models that explicitly model structure in the data. The code is available at https://g
    
[^85]: 无源域自适应的人体姿势估计

    Source-free Domain Adaptive Human Pose Estimation. (arXiv:2308.03202v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2308.03202](http://arxiv.org/abs/2308.03202)

    提出了无源域自适应的人体姿势估计任务，旨在解决在适应过程中无法访问源数据的跨域学习挑战。通过提出的新框架，源保护模块更有效地保留源信息并抵抗噪声。

    

    人体姿势估计广泛应用于运动分析、医疗保健和虚拟现实等领域。然而，标注实际场景的数据集的巨大开销对姿势估计构成了重要挑战。为了解决这个问题，一种方法是在合成数据集上训练姿势估计模型，然后在真实世界数据上进行域自适应(DA)。然而，现有的HPE的DA方法在适应过程中忽略了数据隐私和安全问题，因为使用了源数据和目标数据。为此，我们提出了一种新的任务，名为无源域自适应的HPE，旨在解决在适应过程中无法访问源数据的HPE的跨域学习挑战。我们进一步提出了一个由三个模型组成的新框架：源模型、中间模型和目标模型，从源数据和目标数据的角度探索该任务。源保护模块更有效地保留源信息并抵抗噪声。

    Human Pose Estimation (HPE) is widely used in various fields, including motion analysis, healthcare, and virtual reality. However, the great expenses of labeled real-world datasets present a significant challenge for HPE. To overcome this, one approach is to train HPE models on synthetic datasets and then perform domain adaptation (DA) on real-world data. Unfortunately, existing DA methods for HPE neglect data privacy and security by using both source and target data in the adaptation process. To this end, we propose a new task, named source-free domain adaptive HPE, which aims to address the challenges of cross-domain learning of HPE without access to source data during the adaptation process. We further propose a novel framework that consists of three models: source model, intermediate model, and target model, which explores the task from both source-protect and target-relevant perspectives. The source-protect module preserves source information more effectively while resisting noise
    
[^86]: MiAMix: 通过多阶段增强混合样本数据增强方法提升图像分类

    MiAMix: Enhancing Image Classification through a Multi-stage Augmented Mixied Sample Data Augmentation Method. (arXiv:2308.02804v1 [cs.CV])

    [http://arxiv.org/abs/2308.02804](http://arxiv.org/abs/2308.02804)

    MiAMix是一种新型的混合样本数据增强方法，通过将图像增强集成到混合框架中并利用多种多样的混合方法来提升图像分类模型的性能和泛化能力。

    

    尽管深度学习领域取得了相当大的进展，但过拟合依然是一个关键的挑战。数据增强作为一种十分有前景的方法，因其能够增强模型在各种计算机视觉任务中的泛化能力而备受关注。虽然已经提出了各种各样的策略，但混合样本数据增强（MSDA）在增强模型性能和泛化能力方面显示出了巨大潜力。我们引入了一种称为MiAMix的新型混合方法，即多阶段增强混合。MiAMix将图像增强集成到混合框架中，同时利用多种多样的混合方法，并通过随机选择混合掩模增强方法来改进混合方法。最近的方法利用了显著性信息，而MiAMix的设计也考虑到了计算效率，减少了额外的开销，并且可以轻松集成到现有的训练流程中。我们对MiAMix进行了全面的评估，使用了四个图像基准和进行了比较。

    Despite substantial progress in the field of deep learning, overfitting persists as a critical challenge, and data augmentation has emerged as a particularly promising approach due to its capacity to enhance model generalization in various computer vision tasks. While various strategies have been proposed, Mixed Sample Data Augmentation (MSDA) has shown great potential for enhancing model performance and generalization. We introduce a novel mixup method called MiAMix, which stands for Multi-stage Augmented Mixup. MiAMix integrates image augmentation into the mixup framework, utilizes multiple diversified mixing methods concurrently, and improves the mixing method by randomly selecting mixing mask augmentation methods. Recent methods utilize saliency information and the MiAMix is designed for computational efficiency as well, reducing additional overhead and offering easy integration into existing training pipelines. We comprehensively evaluate MiaMix using four image benchmarks and pit
    
[^87]: LaFiCMIL：从相关多实例学习的角度重新思考大文件分类

    LaFiCMIL: Rethinking Large File Classification from the Perspective of Correlated Multiple Instance Learning. (arXiv:2308.01413v1 [cs.CL])

    [http://arxiv.org/abs/2308.01413](http://arxiv.org/abs/2308.01413)

    LaFiCMIL是一个新的方法，从相关多实例学习的角度解决了Transformer模型输入长度限制的问题，可以用于改进大文件分类任务。

    

    基于Transformer的模型在各种语言任务的性能上取得了革命性的突破。直观上，人们可能会期望文本分类，作为不需要像生成任务那样许多高级表示的任务，能够充分利用Transformer强大的表示能力来进行综合性的处理。然而，实际上，在多类别和多标签分类长文本文档和其他大文件的领域仍然存在较大的改进潜力。Transformer模型的性能主要受到一个重要限制的阻碍：有限的输入长度，比如BERT的512个标记。虽然增加GPU内存可以稍微扩展这个限制，但实际应用中往往受限于有限的GPU资源。在这项工作中，我们从相关多实例学习的角度解决了输入限制问题。所提出的方法LaFiCMIL，作为一个多功能的框架，适用于

    Transformer-based models have revolutionized the performance of a wide range of language tasks. Intuitively, one might expect text classification, which does not necessitate as many high-level representations as generative tasks, to be comprehensively addressed with the powerful representation capabilities of Transformers. However, in reality, there remains significant potential for enhancement, particularly in the areas of multi-class and multi-label classification of lengthy textual documents and other large files. The performance of Transformer-based models is mainly hindered by a major limitation: a restricted input length, e.g., 512 tokens for BERT. While an increase in GPU memory can marginally extend this limit, practical real-world applications often operate under constrained GPU resources. In this work, we tackle the input limit problem from the perspective of correlated multiple instance learning. The proposed approach, LaFiCMIL, serves as a versatile framework applicable to 
    
[^88]: PromptStyler：基于提示的无源域泛化风格生成

    PromptStyler: Prompt-driven Style Generation for Source-free Domain Generalization. (arXiv:2307.15199v1 [cs.CV])

    [http://arxiv.org/abs/2307.15199](http://arxiv.org/abs/2307.15199)

    提出了PromptStyler，通过使用提示合成样式特征，解决了无源域泛化的问题。该方法通过学习样式词向量生成多样的样式，并通过强制样式内容特征与内容特征靠近来保证样式不会扭曲内容信息。在多个数据集上取得了最先进的结果。

    

    在联合视觉语言空间中，文本特征（如“一张狗的照片”）可以有效地表示其相关的图像特征（如狗的照片）。受此启发，我们提出了PromptStyler，通过使用提示来合成各种样式，而不使用任何图像来处理无源域泛化中的分布偏移。我们的方法通过可学习的样式词向量为伪词S*生成多样的样式特征（如“a S* style of a”）。为了确保学习到的样式不会扭曲内容信息，我们强制要求样式内容特征（如“a S* style of a [class]”）在联合视觉语言空间中靠近其对应的内容特征（如“[class]”）。在学习样式词向量之后，我们使用合成的样式内容特征训练一个线性分类器。尽管PromptStyler不需要使用任何图像，并且需要额外的训练，但在PACS、VLCS、OfficeHome和DomainNet上取得了最先进的结果。

    In a joint vision-language space, a text feature (e.g., from "a photo of a dog") could effectively represent its relevant image features (e.g., from dog photos). Inspired by this, we propose PromptStyler which simulates various distribution shifts in the joint space by synthesizing diverse styles via prompts without using any images to deal with source-free domain generalization. Our method learns to generate a variety of style features (from "a S* style of a") via learnable style word vectors for pseudo-words S*. To ensure that learned styles do not distort content information, we force style-content features (from "a S* style of a [class]") to be located nearby their corresponding content features (from "[class]") in the joint vision-language space. After learning style word vectors, we train a linear classifier using synthesized style-content features. PromptStyler achieves the state of the art on PACS, VLCS, OfficeHome and DomainNet, although it does not require any images and take
    
[^89]: 深度布拉德利-特里评分：在没有具体评价标准的情况下估计物品的属性

    Deep Bradley-Terry Rating: Estimate Properties Without Metric of Unseen Items. (arXiv:2307.13709v1 [cs.LG])

    [http://arxiv.org/abs/2307.13709](http://arxiv.org/abs/2307.13709)

    本论文提出了深度布拉德利-特里评分（DBTR）方法，用于评估不一定存在于数据集中的未知物品的属性。该方法通过将传统的布拉德利-特里模型与神经网络结构无缝结合，成功地学习了这些属性的预期量化。

    

    在现实世界中，许多属性，如竞争环境中的可取性或强度，无法直接观测，这使得它们难以评估。为了解决这个具有挑战性的问题，先前的研究主要集中在估计已知物品的这些属性，特别是出现在配对比较数据集中的运动员的实力。在本文中，我们介绍了深度布拉德利-特里评分（DBTR），这是一个新颖的机器学习框架，用于评估不一定存在于数据集中的未知物品的任何属性。我们的方法无缝地将传统的布拉德利-特里模型与神经网络结构相结合。我们还进一步推广了这个架构，用于具有不公平性的非对称环境，这在现实世界中更为常见。在我们的实验分析中，DBTR成功地学习了这些属性的预期量化。

    Many properties in real world, such as desirability or strength in competitive environment, can't be directly observed, which makes them difficult to evaluate. To deal with this challenging problem, prior work has primarily focused on estimating those properties of known items, especially the strength of sports players, only of those who appears in paired comparison dataset. In this paper, we introduce Deep Bradley-Terry Rating (DBTR), a novel ML framework to evaluate any properties of unknown items, not necessarily present in dataset. Our method seamlessly integrates traditional Bradley-Terry model with a neural network structure. We also generalizes this architecture further for asymmetric environment with unfairness, which is much more common in real world settings. In our experimental analysis, DBTR successfully learned desired quantification of those properties.
    
[^90]: PromptMagician：用于文本到图像生成的交互式提示工程

    PromptMagician: Interactive Prompt Engineering for Text-to-Image Creation. (arXiv:2307.09036v1 [cs.AI])

    [http://arxiv.org/abs/2307.09036](http://arxiv.org/abs/2307.09036)

    PromptMagician是一个交互式的提示工程系统，可以帮助用户针对文本到图像生成任务发展出高效的提示，并通过多级可视化和个性化探索支持用户在输入提示过程中的交互和迭代。

    

    生成式文本到图像模型因其基于自然语言提示生成高质量图像的强大能力而受到大众的广泛关注。然而，由于自然语言的复杂性和歧义性，为期望的图像开发有效的提示可能具有挑战性。本研究提出了PromptMagician，一个视觉分析系统，可帮助用户探索图像结果并细化输入的提示。我们系统的主干是一个提示推荐模型，它以用户提示作为输入，从DiffusionDB中检索类似的提示-图像对，并识别出特殊的（重要的和相关的）提示关键词。为了促进交互式提示细化，PromptMagician引入了一个多级可视化，用于检索的图像和推荐的关键词的跨模态嵌入，并支持用户指定多个个性化探索的标准。通过两个使用场景、用户研究和专家访谈，证明了PromptMagician的有效性。

    Generative text-to-image models have gained great popularity among the public for their powerful capability to generate high-quality images based on natural language prompts. However, developing effective prompts for desired images can be challenging due to the complexity and ambiguity of natural language. This research proposes PromptMagician, a visual analysis system that helps users explore the image results and refine the input prompts. The backbone of our system is a prompt recommendation model that takes user prompts as input, retrieves similar prompt-image pairs from DiffusionDB, and identifies special (important and relevant) prompt keywords. To facilitate interactive prompt refinement, PromptMagician introduces a multi-level visualization for the cross-modal embedding of the retrieved images and recommended keywords, and supports users in specifying multiple criteria for personalized exploration. Two usage scenarios, a user study, and expert interviews demonstrate the effectiv
    
[^91]: 自动化纤维成型中的异常检测：数据有限的学习

    Anomaly Detection in Automated Fibre Placement: Learning with Data Limitations. (arXiv:2307.07893v1 [cs.CV])

    [http://arxiv.org/abs/2307.07893](http://arxiv.org/abs/2307.07893)

    本文提出了一种在数据有限的情况下，通过自动编码器进行异常检测的方法，利用纤维层片的深度图进行二分类，并使用重构误差作为量化指标。

    

    当前自动化纤维成型(AFP)的缺陷检测系统主要基于端到端的监督学习方法，需要大量标记的有缺陷样本，而这些样本很难生成足够数量。为了解决这个数据稀缺的问题，我们引入了一种基于自动编码器的方法，适用于小型数据集。幸运的是，从基础的角度来看，这个问题可以简化为正常样本和异常样本之间的二分类。所提出的方法使用纤维层片（tow）对纤维铺设表面的深度图进行分割成小窗口。其中不包含异常的窗口子集传递给自动编码器来重构输入。因为自动编码器是用正常样本进行训练的，对于这些样本，它产生的重构比对于异常样本更精确。因此，重构误差的值被用作一个量化指标，用于判断是否存在潜在的异常。

    Current defect detection systems for Automated Fibre Placement (AFP) are mostly based on end-to-end supervised learning methods requiring abundant labelled defective samples, which are not easily generated in sufficient numbers. To address this data scarcity problem, we introduce an autoencoder-based approach compatible with small datasets. Fortunately, the problem from a foundational point of view can be simplified as a binary classification between normal and abnormal samples. The proposed approach uses a depth map of the fibre layup surface, split into small windows aligned to each composite strip (tow). A subset of these windows that do not contain anomalies is passed to an autoencoder to reconstruct the input. Because the autoencoder is trained with normal samples, it produces more accurate reconstructions for these samples than for abnormal ones. Therefore, the value of reconstruction error is used as a quantitative metric for whether there are potential anomalies. These values a
    
[^92]: 评估社交机器人导航算法的原则与指南

    Principles and Guidelines for Evaluating Social Robot Navigation Algorithms. (arXiv:2306.16740v1 [cs.RO])

    [http://arxiv.org/abs/2306.16740](http://arxiv.org/abs/2306.16740)

    本文提出了评估社交机器人导航算法的原则与指南，为解决在人类居住环境中导航的挑战提供了可重复和可比较的基准标准。

    

    在人类居住环境中导航是部署机器人广泛应用的主要挑战，通常被称为社交机器人导航。虽然社交导航领域近年来取得了很大进展，但评估解决社交导航的算法仍然困难，因为它不仅涉及机器人在静态环境中移动，还涉及到动态的人类参与者及其对机器人行为的感知适应性。相比之下，清晰、可重复、易于获得的基准在计算机视觉、自然语言处理和传统机器人导航等领域加速了进展，使研究人员能够公平比较算法，揭示现有解决方案的局限性，并呈现有前途的新方向。我们相信相同的方法可以有助于社交导航。在本文中，我们为评估社交机器人导航建立了共同、广泛可用且可重复的基准标准，并提出了自己的创新点。

    A major challenge to deploying robots widely is navigation in human-populated environments, commonly referred to as social robot navigation. While the field of social navigation has advanced tremendously in recent years, the fair evaluation of algorithms that tackle social navigation remains hard because it involves not just robotic agents moving in static environments but also dynamic human agents and their perceptions of the appropriateness of robot behavior. In contrast, clear, repeatable, and accessible benchmarks have accelerated progress in fields like computer vision, natural language processing and traditional robot navigation by enabling researchers to fairly compare algorithms, revealing limitations of existing solutions and illuminating promising new directions. We believe the same approach can benefit social navigation. In this paper, we pave the road towards common, widely accessible, and repeatable benchmarking criteria to evaluate social robot navigation. Our contributio
    
[^93]: DiffSketcher: 通过隐式扩散模型实现文本引导的矢量素描合成

    DiffSketcher: Text Guided Vector Sketch Synthesis through Latent Diffusion Models. (arXiv:2306.14685v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.14685](http://arxiv.org/abs/2306.14685)

    本文介绍了DiffSketcher，一种通过隐式扩散模型实现文本引导的矢量素描合成的创新算法。DiffSketcher通过直接优化贝塞尔曲线和扩散模型损失来生成矢量化的手绘素描，并通过注意力图加快生成过程。实验结果表明DiffSketcher的素描质量高于之前方法。

    

    尽管主要训练于图像，但我们发现预训练的扩散模型在引导素描合成方面表现出惊人的能力。本文提出了DiffSketcher，一种创新的算法，利用自然语言输入创建矢量化的手绘素描。DiffSketcher基于预训练的文本到图像扩散模型开发，通过使用扩展版本的得分蒸馏采样（SDS）损失直接优化一组贝塞尔曲线，使得我们可以将栅格级扩散模型作为先验来优化参数化的矢量素描生成器。此外，我们还探索了扩散模型中嵌入的注意力图，在生成过程中实现有效的笔画初始化以加快速度。生成的素描展示了多层次的抽象，同时保持了被绘制主题的可识别性、基本结构和重要的视觉细节。我们的实验证明，DiffSketcher的质量优于之前方法。

    Even though trained mainly on images, we discover that pretrained diffusion models show impressive power in guiding sketch synthesis. In this paper, we present DiffSketcher, an innovative algorithm that creates vectorized free-hand sketches using natural language input. DiffSketcher is developed based on a pre-trained text-to-image diffusion model. It performs the task by directly optimizing a set of Bezier curves with an extended version of the score distillation sampling (SDS) loss, which allows us to use a raster-level diffusion model as a prior for optimizing a parametric vectorized sketch generator. Furthermore, we explore attention maps embedded in the diffusion model for effective stroke initialization to speed up the generation process. The generated sketches demonstrate multiple levels of abstraction while maintaining recognizability, underlying structure, and essential visual details of the subject drawn. Our experiments show that DiffSketcher achieves greater quality than pr
    
[^94]: 基于任务条件化超网络的多任务记忆深度强化学习

    Deep Reinforcement Learning with Multitask Episodic Memory Based on Task-Conditioned Hypernetwork. (arXiv:2306.10698v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.10698](http://arxiv.org/abs/2306.10698)

    人工智能领域，一个新算法利用基于任务条件化超网络的检索网络，根据任务调整网络参数，以解决深度强化学习中选择最相关的过去经验并将其融合到既有决策网络中的问题。

    

    深度强化学习算法通常受到采样效率低下的限制，严重依赖与环境的多次交互才能获得准确的决策能力。相比之下，人类似乎依赖海马体从过去有关任务的经历中检索相关信息，在学习新任务时指导其决策，而不是仅仅依赖于环境交互。然而，为代理设计类似海马体的模块以将过去的经历融入既有的强化学习算法面临两个挑战。第一个挑战涉及选择当前任务最相关的过去经验，第二个是将这些经验与决策网络相结合。为了解决这些问题，我们提出了一种新算法，利用基于任务条件化超网络的检索网络，根据任务调整检索网络的参数。

    Deep reinforcement learning algorithms are usually impeded by sampling inefficiency, heavily depending on multiple interactions with the environment to acquire accurate decision-making capabilities. In contrast, humans seem to rely on their hippocampus to retrieve relevant information from past experiences of relevant tasks, which guides their decision-making when learning a new task, rather than exclusively depending on environmental interactions. Nevertheless, designing a hippocampus-like module for an agent to incorporate past experiences into established reinforcement learning algorithms presents two challenges. The first challenge involves selecting the most relevant past experiences for the current task, and the second is integrating such experiences into the decision network. To address these challenges, we propose a novel algorithm that utilizes a retrieval network based on a task-conditioned hypernetwork, which adapts the retrieval network's parameters depending on the task. A
    
[^95]: 虚拟人类生成模型：基于掩码建模的方法来学习人类特征

    Virtual Human Generative Model: Masked Modeling Approach for Learning Human Characteristics. (arXiv:2306.10656v1 [cs.LG])

    [http://arxiv.org/abs/2306.10656](http://arxiv.org/abs/2306.10656)

    本论文提出了一种名为VHGM的深度生成模型，基于掩码建模的方法来学习健康属性、生活方式和人格之间的关系。通过使用异构表格数据集，VHGM有效地学习了超过1,800个属性。该模型具有潜在的应用前景，例如用于医疗属性的虚拟测量和生活方式的假设验证。

    

    识别医疗属性、生活方式和人格之间的关系对于理解和改善身体和精神状况至关重要。本文提出了一种名为虚拟人类生成模型（VHGM）的机器学习模型，用于估计有关医疗保健、生活方式和个性的属性。VHGM是一个深度生成模型，使用掩码建模训练，在已知属性的条件下学习属性的联合分布。利用异构表格数据集，VHGM高效地学习了超过1,800个属性。我们数值评估了VHGM及其训练技术的性能。作为VHGM的概念验证，我们提出了几个应用程序，演示了用户情境，例如医疗属性的虚拟测量和生活方式的假设验证。

    Identifying the relationship between healthcare attributes, lifestyles, and personality is vital for understanding and improving physical and mental conditions. Machine learning approaches are promising for modeling their relationships and offering actionable suggestions. In this paper, we propose Virtual Human Generative Model (VHGM), a machine learning model for estimating attributes about healthcare, lifestyles, and personalities. VHGM is a deep generative model trained with masked modeling to learn the joint distribution of attributes conditioned on known ones. Using heterogeneous tabular datasets, VHGM learns more than 1,800 attributes efficiently. We numerically evaluate the performance of VHGM and its training techniques. As a proof-of-concept of VHGM, we present several applications demonstrating user scenarios, such as virtual measurements of healthcare attributes and hypothesis verifications of lifestyles.
    
[^96]: 基于时间图序列预测的时态图结构学习

    Time-aware Graph Structure Learning via Sequence Prediction on Temporal Graphs. (arXiv:2306.07699v1 [cs.LG])

    [http://arxiv.org/abs/2306.07699](http://arxiv.org/abs/2306.07699)

    该论文提出了一种基于时间图序列预测的时态图结构学习方法，通过添加潜在的时间边来学习更好的图像结构，提高下游任务的性能。

    

    近年来，旨在模拟图像的传递性质的时间图学习变得越来越受关注并取得了显著的性能。然而，实际上，图像结构往往是不完整和嘈杂的，这阻碍了时间图网络（TGN）学习信息丰富的表示。为了解决这些问题，我们提出了一种基于时间图序列预测的时态图结构学习（TGSL）方法，通过添加潜在的时间边学习更好的图像结构，提高了下游任务的性能。

    Temporal Graph Learning, which aims to model the time-evolving nature of graphs, has gained increasing attention and achieved remarkable performance recently. However, in reality, graph structures are often incomplete and noisy, which hinders temporal graph networks (TGNs) from learning informative representations. Graph contrastive learning uses data augmentation to generate plausible variations of existing data and learn robust representations. However, rule-based augmentation approaches may be suboptimal as they lack learnability and fail to leverage rich information from downstream tasks. To address these issues, we propose a Time-aware Graph Structure Learning (TGSL) approach via sequence prediction on temporal graphs, which learns better graph structures for downstream tasks through adding potential temporal edges. In particular, it predicts time-aware context embedding based on previously observed interactions and uses the Gumble-Top-K to select the closest candidate edges to th
    
[^97]: 离线强化学习中具有数据集约束的策略正则化

    Policy Regularization with Dataset Constraint for Offline Reinforcement Learning. (arXiv:2306.06569v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.06569](http://arxiv.org/abs/2306.06569)

    本文提出了一种离线强化学习方法，称为PRDC，它使用数据集约束来正则化学习策略。相比于现有方法，PRDC可以更有效地指导策略的更新，并提高其性能。

    

    本文考虑从固定数据集中学习最佳策略的问题，即离线强化学习。现有的离线强化学习方法通常采用策略正则化来约束学习策略的分布或行为策略的支持。然而，分布和支持约束过于保守，因为它们都要求学习策略在特定状态下选择与行为策略相似的动作。这将限制学习策略的性能，特别是当行为策略是次优的情况下。本文发现，将策略正则化指向最近的状态-动作对可能更加有效，因此提出了具有数据集约束的策略正则化（PRDC）。在给定状态下更新策略时，PRDC会在整个数据集中搜索最接近的状态-动作样本，然后用该样本的动作来约束策略。与现有方法不同，PRDC可以指导策略根据最相关的状态-动作来进行更新，从而提高策略的性能。

    We consider the problem of learning the best possible policy from a fixed dataset, known as offline Reinforcement Learning (RL). A common taxonomy of existing offline RL works is policy regularization, which typically constrains the learned policy by distribution or support of the behavior policy. However, distribution and support constraints are overly conservative since they both force the policy to choose similar actions as the behavior policy when considering particular states. It will limit the learned policy's performance, especially when the behavior policy is sub-optimal. In this paper, we find that regularizing the policy towards the nearest state-action pair can be more effective and thus propose Policy Regularization with Dataset Constraint (PRDC). When updating the policy in a given state, PRDC searches the entire dataset for the nearest state-action sample and then restricts the policy with the action of this sample. Unlike previous works, PRDC can guide the policy with pr
    
[^98]: 基于感知器神经网络的生物灵感混沌传感器模型：机器学习概念与计算神经科学应用

    A Bio-Inspired Chaos Sensor Model Based on the Perceptron Neural Network: Machine Learning Concept and Application for Computational Neuro-Science. (arXiv:2306.01991v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.01991](http://arxiv.org/abs/2306.01991)

    该论文介绍了一种基于感知器神经网络的生物灵感混沌传感器模型，用于估计神经动力学系统中脉冲序列的熵。经过训练，该模型能够以高精度近似一个短时间序列的模糊熵，即使隐藏层只有一个神经元，也能够达到良好的结果。

    

    本研究提出了一种基于感知器神经网络的生物灵感混沌传感器模型，用于估计神经动力学系统中脉冲序列的熵。经过训练，感知器模型，隐藏层有50个神经元，输出层有1个神经元，能够以高精度近似一个短时间序列的模糊熵，决定系数R2约为0.9。使用Hindmarsh-Rose脉冲模型生成脉冲间隔的时间序列，并使用这些数据集来训练和测试感知器。使用K-block交叉验证方法选择感知器模型的超参数和估计传感器的准确性。即使隐藏层只有一个神经元，该模型也能够以良好的结果近似模糊熵，并且决定系数R2约为0.5-0.8。在一个简化的模型中，隐藏层只有一个神经元，并且第一层的权重相等，近似的原理基于时间序列的平均值的线性变换。

    The study presents a bio-inspired chaos sensor model based on the perceptron neural network for the estimation of entropy of spike train in neurodynamic systems. After training, the sensor on perceptron, having 50 neurons in the hidden layer and 1 neuron at the output, approximates the fuzzy entropy of a short time series with high accuracy, with a determination coefficient of R2 ~ 0.9. The Hindmarsh-Rose spike model was used to generate time series of spike intervals, and datasets for training and testing the perceptron. The selection of the hyperparameters of the perceptron model and the estimation of the sensor accuracy were performed using the K-block cross-validation method. Even for a hidden layer with one neuron, the model approximates the fuzzy entropy with good results and the metric R2 ~ 0.5-0.8. In a simplified model with one neuron and equal weights in the first layer, the principle of approximation is based on the linear transformation of the average value of the time seri
    
[^99]: GripRank: 通过生成式知识改进的段落排序填补检索和生成之间的差距

    GripRank: Bridging the Gap between Retrieval and Generation via the Generative Knowledge Improved Passage Ranking. (arXiv:2305.18144v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18144](http://arxiv.org/abs/2305.18144)

    GripRank是一种通过将生成式知识应用于段落排序，填补检索和文本生成之间差距的方法。

    

    通过利用从大型段落语料库检索到的段落来提供合适的答案，检索增强的文本生成在知识密集型语言任务上取得了显著进展，如开放域问答和知识增强对话生成。然而，由于检索和生成之间存在差异，即在检索过程中候选段落都被等同对待而不考虑它们生成合适答案的潜力，因此检索到的段落并不理想用于指导答案生成。为了解决这个挑战，本文提出了GeneRative Knowledge Improved Passage Ranking (GripRank) 方法，通过将生成式段落估计器(GPE)的知识提炼到一个段落排序器中，其中GPE是用于衡量生成合适答案的可能性的生成式语言模型。

    Retrieval-enhanced text generation has shown remarkable progress on knowledge-intensive language tasks, such as open-domain question answering and knowledge-enhanced dialogue generation, by leveraging passages retrieved from a large passage corpus for delivering a proper answer given the input query. However, the retrieved passages are not ideal for guiding answer generation because of the discrepancy between retrieval and generation, i.e., the candidate passages are all treated equally during the retrieval procedure without considering their potential to generate a proper answer. This discrepancy makes a passage retriever deliver a sub-optimal collection of candidate passages to generate the answer. In this paper, we propose the GeneRative Knowledge Improved Passage Ranking (GripRank) approach, addressing the above challenge by distilling knowledge from a generative passage estimator (GPE) to a passage ranker, where the GPE is a generative language model used to measure how likely the
    
[^100]: 多机器人系统不确定性下的形式建模

    Formal Modelling for Multi-Robot Systems Under Uncertainty. (arXiv:2305.17018v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2305.17018](http://arxiv.org/abs/2305.17018)

    通过考虑不确定性和机器人交互对动作执行的影响，研究者提出了更准确捕捉多机器人系统执行的建模形式。其他工作还提出了降低模型规模以提高解决效率的方法。

    

    为了有效地综合和分析多机器人行为，我们需要准确捕捉多机器人执行的形式化任务级模型。本文回顾了多机器人系统不确定性下的建模形式，并讨论了如何将其用于规划、强化学习、模型检验和仿真。最近的研究表明，考虑到不同形式的不确定性（如时间不确定性和部分可观测性），以及建模机器人交互对动作执行的影响，可以更准确地捕捉多机器人执行。其他工作方向提出了降低多机器人模型规模以实现更高效解决方法的方法。这可以通过在独立假设下解耦机器人，或者对更高层次的宏动作进行推理来实现。

    Purpose of Review: To effectively synthesise and analyse multi-robot behaviour, we require formal task-level models which accurately capture multi-robot execution. In this paper, we review modelling formalisms for multi-robot systems under uncertainty, and discuss how they can be used for planning, reinforcement learning, model checking, and simulation.  Recent Findings: Recent work has investigated models which more accurately capture multi-robot execution by considering different forms of uncertainty, such as temporal uncertainty and partial observability, and modelling the effects of robot interactions on action execution. Other strands of work have presented approaches for reducing the size of multi-robot models to admit more efficient solution methods. This can be achieved by decoupling the robots under independence assumptions, or reasoning over higher level macro actions.  Summary: Existing multi-robot models demonstrate a trade off between accurately capturing robot dependencie
    
[^101]: 自动推理领域相关问题的轻量级在线学习方法

    Lightweight Online Learning for Sets of Related Problems in Automated Reasoning. (arXiv:2305.11087v1 [cs.AI])

    [http://arxiv.org/abs/2305.11087](http://arxiv.org/abs/2305.11087)

    本文提出了一种自动推理中解决一组相关问题的轻量级在线学习方法，它能够自动收集信息并拟合机器学习模型来调整解决策略。在实验中证明该方法能证明更大的边界和发现更多反例。

    

    本文提出一种名为Self-Driven Strategy Learning (sdsl)的轻量级在线学习方法。该方法适用于自动推理中需要解决一组相关问题的任务。sdsl会在解决早期问题时自动收集信息来生成数据集。它利用这些学习到的数据来调整后续问题的解决策略，通过在线拟合机器学习模型。我们将这种方法形式化为一组抽象的转换规则。本文还描述了一个具体的sdsl计算实例，其中使用条件采样来生成数据，采用随机森林作为底层机器学习模型。我们在Kissat求解器上实现了该方法，并展示了Kissat+sdsl在最新的硬件模型检查竞赛中比其他最先进的有限模型检查方法证明了更大的边界和发现了更多的反例。

    We present Self-Driven Strategy Learning (sdsl), a lightweight online learning methodology for automated reasoning tasks that involve solving a set of related problems. sdsl automatically gathers information, in form of a dataset, while solving earlier problems. It utilizes the learned data to adjust the solving strategy for later problems by fitting a machine learning model to the obtained data on the fly. We formally define the approach as a set of abstract transition rules. We describe a concrete instance of the sdsl calculus which uses conditional sampling for generating data and random forests as the underlying machine learning model. We implement the approach on top of the Kissat solver and show that the combination of Kissat+sdsl certifies larger bounds and finds more counter-examples than other state-of-the-art bounded model checking approaches on benchmarks obtained from the latest Hardware Model Checking Competition.
    
[^102]: ANTONIO:面向NLP验证的系统化基准生成方法

    ANTONIO: Towards a Systematic Method of Generating NLP Benchmarks for Verification. (arXiv:2305.04003v1 [cs.CL])

    [http://arxiv.org/abs/2305.04003](http://arxiv.org/abs/2305.04003)

    本文介绍了一种名为ANTONIO的Python库，它基于抽象解释方法提供了一种实用的方法和启发式规则，以便为自然语言处理（NLP）数据集和模型生成已知验证方法的基准。因为其普遍适用性，这项工作将为将NLP验证问题纳入神经网络验证比赛开辟新的可能性，并在NLP问题中普及这一方向。

    

    自然语言处理（NLP）中使用的机器学习模型的验证被认为是一个难题。现有的神经网络验证方法常用于计算机视觉和其他数字数据集，但并不适用于NLP。本研究探讨了造成这一问题的技术原因，并在此基础上提出了实用的方法和启发式规则，以便将NLP数据集和模型准备为适合基于抽象解释的已知验证方法。我们将这些方法实现为一个名为ANTONIO的Python库，该库连接到神经网络验证器ERAN和Marabou。我们使用一个名为R-U-A-Robot的NLP数据集对工具进行了评估，该数据集被提议作为验证具有法律重要性的NLP应用的基准。我们希望，由于其普遍适用性，这项工作将为将NLP验证问题纳入神经网络验证比赛开辟新的可能性，并在NLP问题中普及这一方向。

    Verification of machine learning models used in Natural Language Processing (NLP) is known to be a hard problem. In particular, many known neural network verification methods that work for computer vision and other numeric datasets do not work for NLP. Here, we study technical reasons that underlie this problem. Based on this analysis, we propose practical methods and heuristics for preparing NLP datasets and models in a way that renders them amenable to known verification methods based on abstract interpretation. We implement these methods as a Python library called ANTONIO that links to the neural network verifiers ERAN and Marabou. We perform evaluation of the tool using an NLP dataset R-U-A-Robot suggested as a benchmark for verifying legally critical NLP applications. We hope that, thanks to its general applicability, this work will open novel possibilities for including NLP verification problems into neural network verification competitions, and will popularise NLP problems withi
    
[^103]: 提供最佳支持环境优化人工智能开发过程

    Optimizing the AI Development Process by Providing the Best Support Environment. (arXiv:2305.00136v1 [cs.SE])

    [http://arxiv.org/abs/2305.00136](http://arxiv.org/abs/2305.00136)

    本研究旨在提供人工智能（AI）和机器学习（ML）应用的最佳支持环境，具体重点研究了ML开发中数据管理阶段的障碍以及如何构建和开发一个框架，利用多种数据增强技术来解决数据管理阶段缺乏足够数据的问题。

    

    本研究旨在调查人工智能（AI）和机器学习（ML）应用的开发过程，以提供最佳支持环境。ML的主要阶段包括问题理解，数据管理，模型构建，模型部署和维护。本项目重点研究了ML开发的数据管理阶段及其障碍，因为最终模型的准确性取决于输入到模型中的数据类型。发现这一阶段最大的障碍是缺乏足够的模型学习数据，尤其是在数据保密领域。本项目旨在构建和开发一个框架，帮助解决数据管理阶段缺乏足够数据的问题。该框架利用多种数据增强技术，可以从原始数据集中生成新数据。

    The purpose of this study is to investigate the development process for Artificial inelegance (AI) and machine learning (ML) applications in order to provide the best support environment. The main stages of ML are problem understanding, data management, model building, model deployment and maintenance. This project focuses on investigating the data management stage of ML development and its obstacles as it is the most important stage of machine learning development because the accuracy of the end model is relying on the kind of data fed into the model. The biggest obstacle found on this stage was the lack of sufficient data for model learning, especially in the fields where data is confidential. This project aimed to build and develop a framework for researchers and developers that can help solve the lack of sufficient data during data management stage. The framework utilizes several data augmentation techniques that can be used to generate new data from the original dataset which can 
    
[^104]: 可学习对齐的隐式时间建模用于视频识别

    Implicit Temporal Modeling with Learnable Alignment for Video Recognition. (arXiv:2304.10465v1 [cs.CV])

    [http://arxiv.org/abs/2304.10465](http://arxiv.org/abs/2304.10465)

    本文提出了一种隐式学习对齐方法，通过预测交互点并增强周围特征，实现两帧视频的隐式对齐，同时最小化时间建模的工作量。

    

    对比语言-图像预训练(CLIP)在各种图像任务中都取得了显著的成功。然而，如何有效地扩展CLIP以进行时间建模仍然是一个开放且关键的问题。本文提出了一种新颖的隐式学习对齐(ILA)方法，通过最小化时间建模的工作量，同时实现了极高的性能。具体而言，对于一帧对，每帧都预测一个交互点，作为彼此信息丰富的区域。通过增强交互点周围的特征，两帧被隐式对齐。对齐的特征然后被汇集成一个令牌，用于后续的空间建模。

    Contrastive language-image pretraining (CLIP) has demonstrated remarkable success in various image tasks. However, how to extend CLIP with effective temporal modeling is still an open and crucial problem. Existing factorized or joint spatial-temporal modeling trades off between the efficiency and performance. While modeling temporal information within straight through tube is widely adopted in literature, we find that simple frame alignment already provides enough essence without temporal attention. To this end, in this paper, we proposed a novel Implicit Learnable Alignment (ILA) method, which minimizes the temporal modeling effort while achieving incredibly high performance. Specifically, for a frame pair, an interactive point is predicted in each frame, serving as a mutual information rich region. By enhancing the features around the interactive point, two frames are implicitly aligned. The aligned features are then pooled into a single token, which is leveraged in the subsequent sp
    
[^105]: 通过有限宽度的反模型查询一阶理论的可决定性

    Decidability of Querying First-Order Theories via Countermodels of Finite Width. (arXiv:2304.06348v1 [cs.LO])

    [http://arxiv.org/abs/2304.06348](http://arxiv.org/abs/2304.06348)

    通过有限宽度的反模型查询一阶理论的可决定性并提出分割宽度，使其能够捕获实际相关的查询语言

    

    我们提出了一个通用框架，基于具有结构简单的反模型的存在性（通过某些类型的宽度量来衡量，包括树宽和团宽等），为广泛的逻辑蕴含问题（简称查询）的可决定性提供了支持。作为我们框架的一个重要特例，我们确定了展现出宽度有限有限通用模型集的逻辑，保证了各种同态封闭查询的可决定性，包括了各种实际相关的查询语言。作为一个特别强大的宽度量，我们提出了Blumensath的分割宽度，该量包含了各种通常考虑的宽度量，具有非常有利的计算和结构特性。针对普遍展现存在性规则为一个展示案例，我们解释了有限分割宽度规则集包含其他已知的抽象可决定类，但借助现有的分层和受控规则集概念，也使我们能够捕获实际相关的查询语言，例如正则，连接和布尔连接查询。我们以存在规则的形式为重点，补充我们的理论结果，并进行了彻底的实验评估，展示了我们的框架在各种高级知识处理场景中的实际适用性和可伸缩性。

    We propose a generic framework for establishing the decidability of a wide range of logical entailment problems (briefly called querying), based on the existence of countermodels that are structurally simple, gauged by certain types of width measures (with treewidth and cliquewidth as popular examples). As an important special case of our framework, we identify logics exhibiting width-finite finitely universal model sets, warranting decidable entailment for a wide range of homomorphism-closed queries, subsuming a diverse set of practically relevant query languages. As a particularly powerful width measure, we propose Blumensath's partitionwidth, which subsumes various other commonly considered width measures and exhibits highly favorable computational and structural properties. Focusing on the formalism of existential rules as a popular showcase, we explain how finite partitionwidth sets of rules subsume other known abstract decidable classes but -- leveraging existing notions of strat
    
[^106]: Probe：学习用户在时间跨度的捆绑选择中的个性化投影偏差

    Probe: Learning Users' Personalized Projection Bias in Intertemporal Bundle Choices. (arXiv:2303.06016v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2303.06016](http://arxiv.org/abs/2303.06016)

    本文提出了一种新的偏差嵌入式偏好模型——Probe，旨在解决用户在时间跨度的购物选择中的投影偏差和参照点效应，提高决策的有效性和个性化。

    

    时间跨度的选择需要权衡现在的成本和未来的收益。其中一种具体的选择是决定购买单个物品还是选择包含该物品的捆绑销售方式。以往的研究假设个人对这些选择中涉及的因素有准确的期望。然而，在现实中，用户对这些因素的感知往往存在偏差，导致了非理性和次优的决策。本文重点关注两种常见的偏差：投影偏差和参照点效应，并为此提出了一种新颖的偏差嵌入式偏好模型——Probe。该模型利用加权函数来捕捉用户的投影偏差，利用价值函数来考虑参照点效应，并引入行为经济学中的前景理论来组合加权和价值函数。这使得我们能够确定用户购买捆绑销售的概率，从而提高决策的有效性和个性化。

    Intertemporal choices involve making decisions that require weighing the costs in the present against the benefits in the future. One specific type of intertemporal choice is the decision between purchasing an individual item or opting for a bundle that includes that item. Previous research assumes that individuals have accurate expectations of the factors involved in these choices. However, in reality, users' perceptions of these factors are often biased, leading to irrational and suboptimal decision-making. In this work, we specifically focus on two commonly observed biases: projection bias and the reference-point effect. To address these biases, we propose a novel bias-embedded preference model called Probe. The Probe incorporates a weight function to capture users' projection bias and a value function to account for the reference-point effect, and introduce prospect theory from behavioral economics to combine the weight and value functions. This allows us to determine the probabili
    
[^107]: 用于不平衡异构信息网络的语义感知节点合成

    Semantic-aware Node Synthesis for Imbalanced Heterogeneous Information Networks. (arXiv:2302.14061v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.14061](http://arxiv.org/abs/2302.14061)

    这项研究提出了一种解决不平衡异构信息网络中语义不平衡的方法，通过合成节点来应对少数类别的样本不足和偏倚的问题。

    

    异构图神经网络（HGNNs）在建模异构信息网络（HINs）中的复杂异质性方面显示出了非凡的效能。HGNNs的关键优势在于通过提取和利用丰富的语义信息进行有效的表示学习，以处理HINs中不同的节点和边类型。然而，作为许多现实场景中普遍存在的现象，HINs中的类别不平衡分布为现有的HGNNs创建了性能瓶颈。除了节点数量的不平衡外，HINs中更关键和独特的挑战是语义不平衡。HINs中的少数类别往往缺乏多样化和足够的邻居节点，导致偏倚和不完整的语义信息。这种语义不平衡进一步加剧了准确分类少数节点的困难，导致HGNNs的性能下降。为了解决少数类别的不平衡和补充其不足的情况。

    Heterogeneous graph neural networks (HGNNs) have exhibited exceptional efficacy in modeling the complex heterogeneity in heterogeneous information networks (HINs). The critical advantage of HGNNs is their ability to handle diverse node and edge types in HINs by extracting and utilizing the abundant semantic information for effective representation learning. However, as a widespread phenomenon in many real-world scenarios, the class-imbalance distribution in HINs creates a performance bottleneck for existing HGNNs. Apart from the quantity imbalance of nodes, another more crucial and distinctive challenge in HINs is semantic imbalance. Minority classes in HINs often lack diverse and sufficient neighbor nodes, resulting in biased and incomplete semantic information. This semantic imbalance further compounds the difficulty of accurately classifying minority nodes, leading to the performance degradation of HGNNs. To tackle the imbalance of minority classes and supplement their inadequate se
    
[^108]: SGL-PT: 一种具有图形提示调优的强大图形学习器

    SGL-PT: A Strong Graph Learner with Graph Prompt Tuning. (arXiv:2302.12449v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.12449](http://arxiv.org/abs/2302.12449)

    SGL-PT是一个具有图形提示调优的强大图形学习器，以缩小预训练和下游图形任务之间的差距，并提供一致的训练目标来增强预训练模型的能力。

    

    最近，人们付出了很多努力来设计图形自监督方法，以获得通用的预训练模型，并通过微调将预训练模型应用于下游任务。然而，前文任务和下游图形任务之间存在固有差距，这不充分发挥了预训练模型的能力，甚至导致负传递。同时，通过将预训练和微调与一致的训练目标对齐，提示调优在自然语言处理中取得了成功。在本文中，我们确定了图形提示调优的挑战：首先，图领域中各种预训练方法之间缺乏强大且通用的预训练任务。第二个挑战在于设计一致的训练目标，既适用于预训练任务，也适用于下游任务。为了克服上述障碍，我们提出了一种名为SGL-PT的新框架，该框架遵循学习策略“预训练、提示和预测”。

    Recently, much exertion has been paid to design graph self-supervised methods to obtain generalized pre-trained models, and adapt pre-trained models onto downstream tasks through fine-tuning. However, there exists an inherent gap between pretext and downstream graph tasks, which insufficiently exerts the ability of pre-trained models and even leads to negative transfer. Meanwhile, prompt tuning has seen emerging success in natural language processing by aligning pre-training and fine-tuning with consistent training objectives. In this paper, we identify the challenges for graph prompt tuning: The first is the lack of a strong and universal pre-training task across sundry pre-training methods in graph domain. The second challenge lies in the difficulty of designing a consistent training objective for both pre-training and downstream tasks. To overcome above obstacles, we propose a novel framework named SGL-PT which follows the learning strategy ``Pre-train, Prompt, and Predict''. Specif
    
[^109]: InfiniCity: 无限规模城市合成

    InfiniCity: Infinite-Scale City Synthesis. (arXiv:2301.09637v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.09637](http://arxiv.org/abs/2301.09637)

    InfiniCity是一个无限规模的城市合成框架，可以从随机噪音构建和渲染一个无限制大小的3D环境，具有可扩展的功能和交互式编辑。

    

    为了实现无限规模的3D城市合成，我们提出了一个新颖的框架InfiniCity，它可以从随机噪音构建和渲染一个无限制大小的3D环境。InfiniCity将看似不可行的任务分解为三个可行模块，充分利用了2D和3D数据。首先，一个无限像素图像合成模块从鸟瞰图生成任意尺度的2D地图。接下来，一个基于八叉树的体素完成模块将生成的2D地图转换为3D八叉树。最后，一个基于体素的神经渲染模块给体素贴上纹理并渲染2D图像。InfiniCity能够合成任意尺度和可遍历的3D城市环境，并允许用户进行灵活和交互式编辑。我们定量和定性地证明了该框架的有效性。

    Toward infinite-scale 3D city synthesis, we propose a novel framework, InfiniCity, which constructs and renders an unconstrainedly large and 3D-grounded environment from random noises. InfiniCity decomposes the seemingly impractical task into three feasible modules, taking advantage of both 2D and 3D data. First, an infinite-pixel image synthesis module generates arbitrary-scale 2D maps from the bird's-eye view. Next, an octree-based voxel completion module lifts the generated 2D map to 3D octrees. Finally, a voxel-based neural rendering module texturizes the voxels and renders 2D images. InfiniCity can thus synthesize arbitrary-scale and traversable 3D city environments, and allow flexible and interactive editing from users. We quantitatively and qualitatively demonstrate the efficacy of the proposed framework. Project page: https://hubert0527.github.io/infinicity/
    
[^110]: 质量的尾部

    Quality at the Tail. (arXiv:2212.13925v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.13925](http://arxiv.org/abs/2212.13925)

    本研究发现深度学习推理质量存在波动，引入了“尾部质量”的概念来描述这一现象。

    

    对深度学习模型和系统进行基准测试和评估需要一种细致入微的方法，以确保全面评估。在实际应用中，考虑到推理质量和推理时间是至关重要的，特别是在严苛的环境下，要求同时满足两个指标的要求。忽视其中任何一个方面都可能导致严重和不可逆的后果，包括人员伤亡和财产损失。不幸的是，许多研究缺乏对这些指标的全面考虑，通常在理想或宽松条件下进行，从而导致评估方法不完整或不直观。本研究揭示了深度学习推理质量的波动，进一步给基准测试和评估带来了复杂性和挑战。为了更好地描述这一现象，引入了“尾部质量”的概念，表示分布尾部的质量。

    Benchmarking and evaluating deep learning models and systems necessitate a meticulous approach to ensure comprehensive assessment. In practical applications, it is paramount to consider both the inference quality and the inference time, particularly within critical contexts, where stringent requirements demand the simultaneous satisfaction of both metrics. Neglecting either aspect can result in severe and irreversible consequences, including loss of human life and property damage. Unfortunately, many studies lack a comprehensive consideration of these metrics, often conducted under ideal or permissive conditions, thereby leading to incomplete or non-intuitive evaluation methodologies.  This study reveals that deep learning inference quality exhibits fluctuations, which further introduces complications and challenges to the benchmarking and evaluation. To better characterize the phenomenon, the concept of "tail quality" is introduced, which indicates the quality at the tail of distribut
    
[^111]: 可解释预测分子和晶体属性的端到端AI框架

    End-to-end AI framework for interpretable prediction of molecular and crystal properties. (arXiv:2212.11317v2 [cond-mat.mtrl-sci] UPDATED)

    [http://arxiv.org/abs/2212.11317](http://arxiv.org/abs/2212.11317)

    我们引入了一个端到端的AI框架，利用最先进的模型和计算环境，可以预测分子和晶体的属性，提供了可解释的推断功能，并在领先的计算设施中进行了部署和测试。

    

    我们引入了一个端到端的计算框架，利用DeepHyper库进行超参数优化，加速模型训练，并进行可解释的AI推断。该框架基于最先进的AI模型，包括CGCNN、PhysNet、SchNet、MPNN、MPNN-transformer和TorchMD-NET。我们利用QM9、hMOF和MD17等基准数据集展示了这些模型如何在现代计算环境中预测用户指定的材料属性。我们演示了该统一、独立框架在小分子、无机晶体和纳米多孔金属有机框架建模中的可迁移应用。我们在Argonne领导计算设施的ThetaGPU超级计算机和国家超级计算应用中心的Delta超级计算机上部署和测试了这个框架，为研究人员提供了进行加速的AI驱动发现的现代工具。

    We introduce an end-to-end computational framework that allows for hyperparameter optimization using the DeepHyper library, accelerated model training, and interpretable AI inference. The framework is based on state-of-the-art AI models including CGCNN, PhysNet, SchNet, MPNN, MPNN-transformer, and TorchMD-NET. We employ these AI models along with the benchmark QM9, hMOF, and MD17 datasets to showcase how the models can predict user-specified material properties within modern computing environments. We demonstrate transferable applications in the modeling of small molecules, inorganic crystals and nanoporous metal organic frameworks with a unified, standalone framework. We have deployed and tested this framework in the ThetaGPU supercomputer at the Argonne Leadership Computing Facility, and in the Delta supercomputer at the National Center for Supercomputing Applications to provide researchers with modern tools to conduct accelerated AI-driven discovery in leadership-class computing env
    
[^112]: FedALA: 自适应局部聚合用于个性化联邦学习

    FedALA: Adaptive Local Aggregation for Personalized Federated Learning. (arXiv:2212.01197v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.01197](http://arxiv.org/abs/2212.01197)

    FedALA是一种用于个性化联邦学习的方法，通过自适应局部聚合（ALA）模块来解决统计异质性问题，并在广泛的实验证明中超过了11种最先进的基准模型。

    

    联邦学习中的一个关键挑战是统计异质性，这会影响全局模型在每个客户端上的泛化能力。为了解决这个问题，我们提出了一种名为Federated learning with Adaptive Local Aggregation（FedALA）的方法，通过在个性化联邦学习中捕捉全局模型对客户端模型中所需的信息。FedALA的关键组成部分是自适应局部聚合（ALA）模块，它可以根据每个客户端上的局部目标自适应聚合下载的全局模型和本地模型以在每次迭代中初始化本地模型。为了评估FedALA的有效性，我们在计算机视觉和自然语言处理领域使用了五个基准数据集进行了大量的实验证明。FedALA在测试准确性方面比十一种最先进的基准模型取得了最多3.27%的改进。此外，我们还将ALA模块应用于其他联邦学习方法，并在测试准确性方面取得了最多24.19%的改进。

    A key challenge in federated learning (FL) is the statistical heterogeneity that impairs the generalization of the global model on each client. To address this, we propose a method Federated learning with Adaptive Local Aggregation (FedALA) by capturing the desired information in the global model for client models in personalized FL. The key component of FedALA is an Adaptive Local Aggregation (ALA) module, which can adaptively aggregate the downloaded global model and local model towards the local objective on each client to initialize the local model before training in each iteration. To evaluate the effectiveness of FedALA, we conduct extensive experiments with five benchmark datasets in computer vision and natural language processing domains. FedALA outperforms eleven state-of-the-art baselines by up to 3.27% in test accuracy. Furthermore, we also apply ALA module to other federated learning methods and achieve up to 24.19% improvement in test accuracy.
    
[^113]: 非鲁棒性特征会导致灾难性的过度拟合

    Catastrophic overfitting can be induced with discriminative non-robust features. (arXiv:2206.08242v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.08242](http://arxiv.org/abs/2206.08242)

    本研究通过控制性修改典型的自然图像数据集，研究了对抗训练中灾难性过度拟合的出现。通过注入看似无害的特征，可以在较小的epsilon值下引发灾难性过度拟合。

    

    对抗训练是构建鲁棒神经网络的事实方法，但计算成本较高。为了减轻这一问题，可以使用快速单步攻击，但这可能导致灾难性的过度拟合。本文通过对典型的自然图像数据集进行控制性修改，研究了单步对抗训练方法中灾难性过度拟合的出现。特别地，我们表明，通过注入看似无害的特征，可以在比之前观察到的较小的epsilon值下引发灾难性过度拟合。这些特征有助于非鲁棒性分类，但不能单独实现鲁棒性。通过大量实验，我们分析了这一新现象，并发现了这种失败模式的机制还不够清楚。

    Adversarial training (AT) is the de facto method for building robust neural networks, but it can be computationally expensive. To mitigate this, fast single-step attacks can be used, but this may lead to catastrophic overfitting (CO). This phenomenon appears when networks gain non-trivial robustness during the first stages of AT, but then reach a breaking point where they become vulnerable in just a few iterations. The mechanisms that lead to this failure mode are still poorly understood. In this work, we study the onset of CO in single-step AT methods through controlled modifications of typical datasets of natural images. In particular, we show that CO can be induced at much smaller $\epsilon$ values than it was observed before just by injecting images with seemingly innocuous features. These features aid non-robust classification but are not enough to achieve robustness on their own. Through extensive experiments we analyze this novel phenomenon and discover that the presence of thes
    
[^114]: 正样本未标记对比学习

    Positive Unlabeled Contrastive Learning. (arXiv:2206.01206v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.01206](http://arxiv.org/abs/2206.01206)

    我们提出了一种正样本未标记对比学习的新方法，通过扩展对比损失和使用PU特定聚类方案，该方法在PU任务中学习到了优秀的表示，并在多个标准数据集上明显优于现有方法。

    

    自我监督预训练无标签数据，然后在标记数据上进行监督微调是一种常见的从有限标记样本中学习的方法。我们将这个方法扩展到经典的正样本未标记（PU）设置，其中的任务是仅通过一些标记为正样本和（通常）大量的未标记样本（可以是正样本或负样本）来学习二分类器。我们首先对标准infoNCE对比损失的家族提出了一个简单的扩展，适用于PU设置；并且证明相比于现有的无监督和有监督方法，这种方法学习到了更好的表示。然后，我们开发了一种简单的方法，使用新的PU特定聚类方案为未标记样本构建伪标签；这些伪标签可以用来训练最终的（正样本 vs. 负样本）分类器。我们的方法在几个标准PU基准数据集上明显优于现有的PU方法，并且不需要任何类别的先验知识。

    Self-supervised pretraining on unlabeled data followed by supervised fine-tuning on labeled data is a popular paradigm for learning from limited labeled examples. We extend this paradigm to the classical positive unlabeled (PU) setting, where the task is to learn a binary classifier given only a few labeled positive samples, and (often) a large amount of unlabeled samples (which could be positive or negative).  We first propose a simple extension of standard infoNCE family of contrastive losses, to the PU setting; and show that this learns superior representations, as compared to existing unsupervised and supervised approaches. We then develop a simple methodology to pseudo-label the unlabeled samples using a new PU-specific clustering scheme; these pseudo-labels can then be used to train the final (positive vs. negative) classifier. Our method handily outperforms state-of-the-art PU methods over several standard PU benchmark datasets, while not requiring a-priori knowledge of any clas
    

