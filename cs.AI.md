# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Pok\'eLLMon: A Human-Parity Agent for Pok\'emon Battles with Large Language Models](https://rss.arxiv.org/abs/2402.01118) | Pok\'eLLMon是第一个在战术对战游戏中实现人类能力的语言模型化身代理机器人。它通过上下文强化学习、知识增强生成和一致的行动生成的策略，展现了与人类类似的战斗策略和及时决策，并在Ladder比赛中达到了49%的胜率，在邀请对战中达到了56%的胜率。 |
| [^2] | [Segment Any 3D Object with Language](https://arxiv.org/abs/2404.02157) | 提出了SOLE框架，使用自由形式语言指令进行开放词汇的3D实例分割，通过直接从3D点云生成语义相关的掩模，实现了强大的泛化能力。 |
| [^3] | [Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks](https://arxiv.org/abs/2404.02151) | 展示了对齐的LLM对简单自适应越狱攻击不具有鲁棒性，并成功实现了在多个模型上几乎100%的攻击成功率，同时还介绍了对于不公开logprobs的模型如何进行越狱以及如何在受污染的模型中查找木马字符串的方法。 |
| [^4] | [FLawN-T5: An Empirical Examination of Effective Instruction-Tuning Data Mixtures for Legal Reasoning](https://arxiv.org/abs/2404.02127) | 本研究提出了一个名为LawInstruct的大型法律指导数据集，证明了领域特定的预训练和指导调整可以改善在LegalBench上的性能，为在法律领域开发具有更强信息处理和决策能力的模型提供了一个资源。 |
| [^5] | [Already Moderate Population Sizes Provably Yield Strong Robustness to Noise](https://arxiv.org/abs/2404.02090) | 适中的种群规模可以在先验位噪声存在时保持强鲁棒性，而不会增加在OneMax基准上的渐近运行时间 |
| [^6] | [Advancing LLM Reasoning Generalists with Preference Trees](https://arxiv.org/abs/2404.02078) | 新推出的Eurus模型通过基于首选树的推理优化，在多项基准测试中取得了业界领先的成果，尤其在击败了GPT-3.5 Turbo的基准测试中表现突出。 |
| [^7] | [Red-Teaming Segment Anything Model](https://arxiv.org/abs/2404.02067) | 本文对端分任意模型进行了多方面的红队分析，发现模型在应对风格迁移、隐私攻击和敌对攻击方面存在一些挑战 |
| [^8] | [SPMamba: State-space model is all you need in speech separation](https://arxiv.org/abs/2404.02063) | SPMamba提出了一种利用状态空间模型进行语音分离的新网络架构，通过替换Transformer组件为Mamba模块，旨在提高性能并减少计算需求。 |
| [^9] | [Digital Forgetting in Large Language Models: A Survey of Unlearning Methods](https://arxiv.org/abs/2404.02062) | 本综述聚焦于大型语言模型中的数字遗忘，旨在获得一种遗忘方法，能有效地消除模型中的不良知识或行为，同时保留原始模型在理想任务上的性能，并具有可伸缩性。 |
| [^10] | [Long-context LLMs Struggle with Long In-context Learning](https://arxiv.org/abs/2404.02060) | 该研究引入了一个专门的基准 LIConBench，聚焦于长上下文学习，发现长文本语言模型在极端标签分类领域中性能良好，尤其在标记长度不超过20K时表现相对较好。 |
| [^11] | [Universal representations for financial transactional data: embracing local, global, and external contexts](https://arxiv.org/abs/2404.02047) | 提出了一个金融交易数据通用表示的学习框架，结合了本地、全局和外部语境，提出了新颖的生成模型和整合外部信息的方法，并在本地任务中表现出超越性能。 |
| [^12] | [Ukrainian Texts Classification: Exploration of Cross-lingual Knowledge Transfer Approaches](https://arxiv.org/abs/2404.02043) | 乌克兰文本分类领域探索跨语言知识传递方法，利用最新的NLP技术，测试了在毒性分类、文体分类和自然语言推理任务上的最佳设置。 |
| [^13] | [A Survey on Large Language Model-Based Game Agents](https://arxiv.org/abs/2404.02039) | LLM和MLLM的进步为游戏智能体提供了强大的人类决策能力，本文全面综述了基于LLM的游戏智能体的概念架构、方法论和未来研究方向 |
| [^14] | [MultiParaDetox: Extending Text Detoxification with Parallel Data to New Languages](https://arxiv.org/abs/2404.02037) | 本研究提出了MultiParaDetox，将ParaDetox管道扩展到多种语言，以自动化收集潜在任何语言的并行净化语料库。 |
| [^15] | [Large Language Models for Orchestrating Bimanual Robots](https://arxiv.org/abs/2404.02018) | 通过提出基于语言模型的双手编排（LABOR），本研究首次应对了在连续空间中进行双手任务协调的挑战。 |
| [^16] | [Predicting the Intention to Interact with a Service Robot:the Role of Gaze Cues](https://arxiv.org/abs/2404.01986) | 凝视线索的有效利用显著提高了服务机器人感知用户互动意图的性能，分类准确性和适应新环境能力。 |
| [^17] | [Joint-Task Regularization for Partially Labeled Multi-Task Learning](https://arxiv.org/abs/2404.01976) | 提出了一种联合任务正则化（JTR）技术，通过在单个联合任务潜在空间中同时对所有任务进行正则化，改善了当数据未完全标记所有任务时的学习。 |
| [^18] | [Towards Leveraging AutoML for Sustainable Deep Learning: A Multi-Objective HPO Approach on Deep Shift Neural Networks](https://arxiv.org/abs/2404.01965) | 该研究旨在利用AutoML技术最大化Deep Shift神经网络性能并最小化资源消耗，提出了结合多保真度HPO和多目标优化的方法，实验证明该方法在提高准确率的同时降低了计算复杂性。 |
| [^19] | [HyperCLOVA X Technical Report](https://arxiv.org/abs/2404.01954) | HyperCLOVA X 是针对韩国语言和文化定制的大型语言模型，同时具有竞争能力的英语、数学和编码能力，其推理能力强大且具有跨语言的通用能力。 |
| [^20] | [Improving Bird's Eye View Semantic Segmentation by Task Decomposition](https://arxiv.org/abs/2404.01925) | 该方法通过将鸟瞰视图语义分割任务分解为BEV地图重建和RGB-BEV特征对齐两个阶段，来优化自动驾驶中的语义分割任务。 |
| [^21] | [SGSH: Stimulate Large Language Models with Skeleton Heuristics for Knowledge Base Question Generation](https://arxiv.org/abs/2404.01923) | 本研究提出了SGSH框架，通过骨架启发来激发GPT-3.5生成知识库问题，有效地组织和利用丰富的语义知识。 |
| [^22] | [SCANNER: Knowledge-Enhanced Approach for Robust Multi-modal Named Entity Recognition of Unseen Entities](https://arxiv.org/abs/2404.01914) | 提出了SCANNER模型，通过提取实体候选并利用知识从多种来源获取知识，增强了对未见实体的识别能力，并引入了一种新颖的方法来处理NER数据集中带有噪声注释的挑战。 |
| [^23] | [Continuous Spiking Graph Neural Networks](https://arxiv.org/abs/2404.01897) | COS-GNN将脉冲神经网络（SNNs）与连续图神经网络（CGNNs）结合在一起，以在每个时间步骤对图节点进行表示，并将其与时间一起集成到ODE过程中，以增强信息保存和解决在离散图神经网络中的问题。 |
| [^24] | [RAVE: Residual Vector Embedding for CLIP-Guided Backlit Image Enhancement](https://arxiv.org/abs/2404.01889) | 该论文提出了一种用于背光图像增强的CLIP引导方法RAVE，通过残差向量嵌入和提示调整的新颖方法，加快了训练并提高了质量。 |
| [^25] | [Real, fake and synthetic faces - does the coin have three sides?](https://arxiv.org/abs/2404.01878) | 通过分析真实、Deepfake和合成面部图像，研究了它们在图像性质上的相似和不同之处，以及使用了八个深度学习模型进行区分分析。 |
| [^26] | [Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language Models -- A Survey](https://arxiv.org/abs/2404.01869) | 本文通过综述超越任务准确性的研究，提供对大型语言模型推理过程更深入了解，并强调了LLMs倾向于依赖于训练数据中的表面模式和相关性。 |
| [^27] | [Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models](https://arxiv.org/abs/2404.01863) | 使用奖励函数训练的细化文本到图像模型可能会因为奖励过度优化而损害性能，为了解决这一问题，提出了一种基于奖励模型置信度的对齐性增强方法。 |
| [^28] | [Where to Move Next: Zero-shot Generalization of LLMs for Next POI Recommendation](https://arxiv.org/abs/2404.01855) | 设计了新颖的提示策略和进行了实证研究以探索LLMs用于下一个POI推荐的零样本泛化能力 |
| [^29] | [EV2Gym: A Flexible V2G Simulator for EV Smart Charging Research and Benchmarking](https://arxiv.org/abs/2404.01849) | 该论文介绍了EV2Gym，这是一个灵活的V2G模拟器平台，用于开发和评估各种规模的智能充电算法，并提供了丰富的模型和界面选择。 |
| [^30] | [Great, Now Write an Article About That: The Crescendo Multi-Turn LLM Jailbreak Attack](https://arxiv.org/abs/2404.01833) | 提出了一种名为Crescendo的新型多回合越狱攻击方法，通过看似良性的对话方式逐渐升级与模型的交互，成功突破了大型语言模型的限制。 |
| [^31] | [Defense without Forgetting: Continual Adversarial Defense with Anisotropic & Isotropic Pseudo Replay](https://arxiv.org/abs/2404.01828) | 持续对抗性防御概念下提出了各向异性和各向同性伪重演（AIR），通过各向同性重演保持模型一致性，在各向异性重演中学习折衷数据流形。 |
| [^32] | [Uncertainty-aware Active Learning of NeRF-based Object Models for Robot Manipulators using Visual and Re-orientation Actions](https://arxiv.org/abs/2404.01812) | 本文提出了一种基于NeRF的物体模型的不确定性感知主动学习方法，通过优化信息量和可行性来快速学习完整的3D物体模型，能够在陌生方向进行操作，并在操作过程中改进视觉重建质量。 |
| [^33] | [Imitation Game: A Model-based and Imitation Learning Deep Reinforcement Learning Hybrid](https://arxiv.org/abs/2404.01794) | 深度强化学习的研究结合了基于模型的方法和模仿学习，以解决训练样本需求高和概念漂移等问题。 |
| [^34] | [A noisy elephant in the room: Is your out-of-distribution detector robust to label noise?](https://arxiv.org/abs/2404.01775) | 本研究探讨了当下训练分类器的标签不可靠时，20种最新OOD检测方法在离群检测中的表现，为了解类别标签噪音对OOD检测的影响提供了深入见解。 |
| [^35] | [Auditing Large Language Models for Enhanced Text-Based Stereotype Detection and Probing-Based Bias Evaluation](https://arxiv.org/abs/2404.01768) | 该研究引入了Multi-Grain Stereotype（MGS）数据集，探索了不同的机器学习方法用于建立陈规检测的基线，并提出了一系列基于MGS数据训练的英文文本的陈规分类器模型。 |
| [^36] | [Peer-aided Repairer: Empowering Large Language Models to Repair Advanced Student Assignments](https://arxiv.org/abs/2404.01754) | 该研究提出了一个名为PaR的新框架，通过大型语言模型的支持，能够修复高级编程作业中的程序错误。 |
| [^37] | [Safe Interval RRT* for Scalable Multi-Robot Path Planning in Continuous Space](https://arxiv.org/abs/2404.01752) | 提出了安全间隔RRT*（SI-RRT*）两级方法，低级采用采样规划器找到单个机器人的无碰撞轨迹，高级通过优先规划或基于冲突的搜索解决机器人间冲突，实验结果表明SI-RRT*能够快速找到高质量解决方案 |
| [^38] | [Towards Scalable & Efficient Interaction-Aware Planning in Autonomous Vehicles using Knowledge Distillation](https://arxiv.org/abs/2404.01746) | 引入了一种结合深度学习和约束优化的高效方法，利用知识蒸馏训练更小更高效的网络，从而减轻复杂性 |
| [^39] | [Unleash the Potential of CLIP for Video Highlight Detection](https://arxiv.org/abs/2404.01745) | 使用Highlight-CLIP方法，在视频精彩片段检测任务中通过利用多模态模型的预训练知识和创新的显著性池化技术，取得了最先进的性能。 |
| [^40] | [Intrusion Tolerance for Networked Systems through Two-Level Feedback Control](https://arxiv.org/abs/2404.01741) | 该论文提出了一种名为TOLERANCE的新型控制架构，通过两级最优控制解决网络系统的入侵容忍问题，并设计了高效算法来改善服务可用性和降低操作成本。 |
| [^41] | [Weakly-supervised Audio Separation via Bi-modal Semantic Similarity](https://arxiv.org/abs/2404.01740) | 本文提出了通过双模态语义相似性进行弱监督音频分离的框架，可在没有单独源音频数据的情况下通过语言模态中的信息实现音频信号的分离。 |
| [^42] | [Effective internal language model training and fusion for factorized transducer model](https://arxiv.org/abs/2404.01716) | 提出了一种对于分解转录模型的有效ILM训练和解码策略，能够显著改善与标准解码方法的性能，并在LibriSpeech数据集上取得了17%的相对改善。 |
| [^43] | [Conjugate-Gradient-like Based Adaptive Moment Estimation Optimization Algorithm for Deep Learning](https://arxiv.org/abs/2404.01714) | 提出一种基于共轭梯度样式的新优化算法CG-like-Adam，用于深度学习，并在收敛分析和数值实验中展示了其优越性 |
| [^44] | [Generative AI for Immersive Communication: The Next Frontier in Internet-of-Senses Through 6G](https://arxiv.org/abs/2404.01713) | 本文探讨了生成式人工智能用于沉浸式通信中减少带宽消耗的实用价值。 |
| [^45] | [Efficient Online Unlearning via Hessian-Free Recollection of Individual Data Statistics](https://arxiv.org/abs/2404.01712) | 通过提出的Hessian-free在线遗忘方法，实现了近乎瞬时的在线遗忘，仅需要进行矢量加法操作。 |
| [^46] | [Upsample Guidance: Scale Up Diffusion Models without Training](https://arxiv.org/abs/2404.01709) | 提出了一种称为上采样指导的技术，能够适应预训练的扩散模型，实现更高分辨率图像的生成，无需额外训练或依赖外部模型。 |
| [^47] | [A Methodology for Improving Accuracy of Embedded Spiking Neural Networks through Kernel Size Scaling](https://arxiv.org/abs/2404.01685) | 通过核大小缩放提高嵌入式脉冲神经网络准确性的方法学在实验中表现出更高的准确性。 |
| [^48] | [Towards Generalizable and Faithful Logic Reasoning over Natural Language via Resolution Refutation](https://arxiv.org/abs/2404.01677) | 通过引入归结反驳范式，提出了一个名为GFaiR的框架，旨在解决大型语言模型在进行自然语言形式逻辑理论一阶逻辑推理时的困难，并通过证明插入解决方案改进了系统的完整性 |
| [^49] | [Release of Pre-Trained Models for the Japanese Language](https://arxiv.org/abs/2404.01657) | 发布日语预训练模型以缩小非英语社区中的AI访问差距，促进AI民主化。 |
| [^50] | [AI WALKUP: A Computer-Vision Approach to Quantifying MDS-UPDRS in Parkinson's Disease](https://arxiv.org/abs/2404.01654) | 提出了一种使用计算机视觉方法来量化帕金森氏病患者MDS-UPDRS的新方法，通过捕捉人体姿势图像并进行特征提取，实现快速与简便的病情评估。 |
| [^51] | [Towards Better Generalization in Open-Domain Question Answering by Mitigating Context Memorization](https://arxiv.org/abs/2404.01652) | 本文研究了在开放域问答中泛化性能的问题，发现挑战在于阅读器过度依赖记忆外部语料库的知识，限制了模型的泛化能力。 |
| [^52] | [A Closer Look at Spatial-Slice Features Learning for COVID-19 Detection](https://arxiv.org/abs/2404.01643) | 为解决CT扫描中存在的变异性和OOD切片挑战，提出了一种增强型的空间分割特征学习框架，通过滤除OOD数据和减少冗余来选择关键的空间切片进行分析，并引入了基于核密度的切片采样方法来提高稳定性和加快收敛速度 |
| [^53] | [Learning to Control Camera Exposure via Reinforcement Learning](https://arxiv.org/abs/2404.01636) | 提出了一种通过深度强化学习快速控制摄像机曝光的新框架，具有简化训练场地、奖励设计和曝光调整能力逐步改善等四大创新贡献 |
| [^54] | [Learning Equi-angular Representations for Online Continual Learning](https://arxiv.org/abs/2404.01628) | 使用神经坍缩现象引入神经坍缩来形成表示空间中的等角紧框架结构，通过提出预备数据训练和残差修正，使得单周期学习的连续学习模型能更好地适应流数据，这种方法在在线连续学习中取得了明显的优势。 |
| [^55] | [Gen4DS: Workshop on Data Storytelling in an Era of Generative AI](https://arxiv.org/abs/2404.01622) | 论文讨论了数据叙事在生成AI时代的重要性和挑战，并邀请学术界和工业界一起探讨生成AI对数据叙事的影响。 |
| [^56] | [Voice EHR: Introducing Multimodal Audio Data for Health](https://arxiv.org/abs/2404.01620) | 本报告引入了一种通过引导问题使用移动应用程序捕获健康数据的新的音频电子健康记录（voice EHR），可能包含复杂的健康生物标志物，从而弥补了单一模态临床数据的典型限制。 |
| [^57] | [Helmsman of the Masses? Evaluate the Opinion Leadership of Large Language Models in the Werewolf Game](https://arxiv.org/abs/2404.01602) | 本研究通过狼人游戏模拟平台评估了大语言模型的观点领导作用，并开发了两个新的评估指标。 |
| [^58] | [Extremum-Seeking Action Selection for Accelerating Policy Optimization](https://arxiv.org/abs/2404.01598) | 提出了在无模型强化学习中改进动作选择的方法，通过引入极值寻找控制（ESC）进行自适应控制步骤，以加速策略优化。 |
| [^59] | [PhysORD: A Neuro-Symbolic Approach for Physics-infused Motion Prediction in Off-road Driving](https://arxiv.org/abs/2404.01596) | PhysORD是一种神经符号方法，将物理定律融入神经模型中，显著提高了在越野驾驶中的运动预测泛化能力。 |
| [^60] | [Classifying Cancer Stage with Open-Source Clinical Large Language Models](https://arxiv.org/abs/2404.01589) | 本研究展示了在没有任何标记的训练数据的情况下，开源的临床大型语言模型能够从真实病理报告中提取病理性肿瘤-淋巴结-转移（pTNM）分期信息 |
| [^61] | [Hallucination Diversity-Aware Active Learning for Text Summarization](https://arxiv.org/abs/2404.01588) | 本文首次提出了一种基于幻觉多样性的主动学习框架，用于减轻大型语言模型（LLMs）在文本摘要中产生的幻觉，减少了昂贵的人类注释需求。 |
| [^62] | [BERT-Enhanced Retrieval Tool for Homework Plagiarism Detection System](https://arxiv.org/abs/2404.01582) | 本文提出了一种基于GPT-3.5的抄袭文本数据生成方法和一种基于Faiss和BERT的高效高准确性的抄袭识别方法，填补了高水平抄袭检测研究数据集缺失的空白，实验证明该模型在多个指标上表现优异 |
| [^63] | [Evaluating Large Language Models Using Contrast Sets: An Experimental Approach](https://arxiv.org/abs/2404.01569) | 介绍了一种为斯坦福自然语言推断（SNLI）数据集生成对比集的创新技术，通过自动替换动词、副词和形容词为同义词来评估模型的性能是否基于真实的语言理解还是仅仅基于模式识别。 |
| [^64] | [Automated User Story Generation with Test Case Specification Using Large Language Model](https://arxiv.org/abs/2404.01558) | 利用 GPT-4.0 开发了工具 "GeneUS"，实现了从需求文档自动生成用户故事的自动化，为后续集成到项目管理工具提供可能性。 |
| [^65] | [Distributed Autonomous Swarm Formation for Dynamic Network Bridging](https://arxiv.org/abs/2404.01557) | 提出了一种用于动态网络桥接的新颖分布式部分可观察马尔可夫决策过程（Dec-POMDP）方法，以及基于图卷积强化学习（DGN）的多智能体强化学习（MARL）方法。 |
| [^66] | [Multi-Agent Reinforcement Learning with Control-Theoretic Safety Guarantees for Dynamic Network Bridging](https://arxiv.org/abs/2404.01551) | 将多智能体强化学习与控制理论相结合，提出了一种新的设定点更新算法，以确保安全条件并实现良好的任务目标性能。 |
| [^67] | [mChartQA: A universal benchmark for multimodal Chart Question Answer based on Vision-Language Alignment and Reasoning](https://arxiv.org/abs/2404.01548) | 本文提出了一种新颖的多模态图表问答模型，采用双阶段训练方法，通过整合视觉和语言处理解决多模态问答中复杂的颜色、结构和无文本图表挑战。 |
| [^68] | [Laying Anchors: Semantically Priming Numerals in Language Modeling](https://arxiv.org/abs/2404.01536) | 通过生成受数字分布规律控制的锚点，我们引入了一种在语义上引导数字的策略，在广泛范围的数字任务上实现了数学基础表示的显著改进。 |
| [^69] | [Categorical semiotics: Foundations for Knowledge Integration](https://arxiv.org/abs/2404.01526) | 本文扩展了代数规范方法，提出了一个全面的框架，用于定义和分析深度学习架构，采用类似Ehresmann素描的图形结构，在模糊集的宇宙中进行解释。 |
| [^70] | [On Train-Test Class Overlap and Detection for Image Retrieval](https://arxiv.org/abs/2404.01524) | 重新审视了谷歌地标v2的训练集，通过识别和移除类别重叠，引入了一种新的端到端单阶段流程Single-stage Detect-to-Retrieve（CiDeR），旨在检测对象并提取全局图像表示，在现有最先进方法上表现优异。 |
| [^71] | [Can Biases in ImageNet Models Explain Generalization?](https://arxiv.org/abs/2404.01509) | 图像网模型的偏见是否能够解释模型的泛化问题，对此进行了大规模研究。 |
| [^72] | [Some Orders Are Important: Partially Preserving Orders in Top-Quality Planning](https://arxiv.org/abs/2404.01503) | 提出在规划中部分保留顺序的新方法，通过指定重要顺序的子集来在高质量和无序规划问题之间进行插值，并展示了利用部分顺序减少搜索修剪技术的好处 |
| [^73] | [Modality Translation for Object Detection Adaptation Without Forgetting Prior Knowledge](https://arxiv.org/abs/2404.01492) | 本文提出了一种ModTr方法，通过小型转换网络调整输入以最小化检测损失，实现了目标检测模型从一个或多个模态到另一个的有效适应，而无需微调参数。 |
| [^74] | [QuAD: Query-based Interpretable Neural Motion Planning for Autonomous Driving](https://arxiv.org/abs/2404.01486) | 提出了一个新的自动驾驶神经运动规划框架，通过查询感兴趣的时空点的占据信息，避免了传统对象检测和密集占据栅格地图方法中的信息丢失和计算浪费。 |
| [^75] | [TraveLER: A Multi-LMM Agent Framework for Video Question-Answering](https://arxiv.org/abs/2404.01476) | TraveLER是一种多重LMM代理框架，通过沿着视频移动，并通过交互式提问收集关键帧的信息，以解决视频问答中关键时间戳选择和错误时间戳调整的问题 |
| [^76] | [Are large language models superhuman chemists?](https://arxiv.org/abs/2404.01475) | 介绍了一个自动化框架“ChemBench”，旨在评估最先进的大型语言模型（LLMs）在化学知识和推理能力方面与人类化学家专业知识的对比。 |
| [^77] | [Data-Efficient Unsupervised Interpolation Without Any Intermediate Frame for 4D Medical Images](https://arxiv.org/abs/2404.01464) | 该论文提出了一种简单而有效的无监督三维插值框架UVI-Net，能够在4D医学图像中实现无需中间帧的时间插值，取得了显着的性能改善。 |
| [^78] | [Game-Theoretic Deep Reinforcement Learning to Minimize Carbon Emissions and Energy Costs for AI Inference Workloads in Geo-Distributed Data Centers](https://arxiv.org/abs/2404.01459) | 结合博弈论和深度强化学习优化地理分布式数据中心中AI推断工作负载的分布，以降低碳排放和运营成本。 |
| [^79] | [Unveiling Divergent Inductive Biases of LLMs on Temporal Data](https://arxiv.org/abs/2404.01453) | 本研究探索了LLMs在时间数据分析中的固有挑战，重点评估了GPT-3.5和GPT-4模型的性能，发现了它们在特定时间关系上存在偏向性。 |
| [^80] | [Finding Regions of Interest in Whole Slide Images Using Multiple Instance Learning](https://arxiv.org/abs/2404.01446) | 本研究使用多实例学习方法来解决整张切片图像中准确预测癌症表型和在图块级别找到与之相关的细胞形态学的挑战。 |
| [^81] | [Neural Implicit Representation for Building Digital Twins of Unknown Articulated Objects](https://arxiv.org/abs/2404.01440) | 该方法通过显式建模点级对应关系、利用图像、3D重建和运动学的线索，成功构建了未知关节对象的数字孪生体，结果更准确和稳定，且不依赖于任何对象形状或结构先验。 |
| [^82] | [Creating emoji lexica from unsupervised sentiment analysis of their descriptions](https://arxiv.org/abs/2404.01439) | 该论文提出了一种从在线文本消息中预测表情符号所表达情感的新方法，无需人工标注数据，节省了宝贵时间。 |
| [^83] | [Generation and Detection of Sign Language Deepfakes - A Linguistic and Visual Analysis](https://arxiv.org/abs/2404.01438) | 通过在上半身生成手语深度伪造视频，并由手语专家审核，本研究探讨了在深度伪造技术中的积极应用，为聋哑和听障社区带来潜在的健康和教育益处。 |
| [^84] | [Position-Aware Parameter Efficient Fine-Tuning Approach for Reducing Positional Bias in LLMs](https://arxiv.org/abs/2404.01430) | 本研究发现LLMs的位置偏差主要源于不同模型的固有位置偏好，并提出了一种面向位置的参数高效微调方法来解决这一问题。 |
| [^85] | [Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data](https://arxiv.org/abs/2404.01413) | 本文通过比较数据取代和数据积累两种情况，发现累积数据可以防止模型崩溃。 |
| [^86] | [OVFoodSeg: Elevating Open-Vocabulary Food Image Segmentation via Image-Informed Textual Representation](https://arxiv.org/abs/2404.01409) | OVFoodSeg通过开放词汇设定和视觉-语言模型，结合图像信息，提升食品图像分割任务的效果。 |
| [^87] | [ContactHandover: Contact-Guided Robot-to-Human Object Handover](https://arxiv.org/abs/2404.01402) | ContactHandover是一个机器人向人类递送物体的系统，通过接触引导的抓取和物体递送阶段来实现成功的物体递送。 |
| [^88] | [Object-conditioned Bag of Instances for Few-Shot Personalized Instance Recognition](https://arxiv.org/abs/2404.01397) | 该论文提出了一种基于对象条件的实例袋（OBoI）方法，通过多阶统计实现了个性化实例识别，能够在少样本数据集中达到较高的准确度。 |
| [^89] | [Prompt-prompted Mixture of Experts for Efficient LLM Generation](https://arxiv.org/abs/2404.01365) | 提出了一种名为GRIFFIN的训练-free MoE，能够在各种LLM模型中选择唯一的FF专家以实现高效生成。 |
| [^90] | [Information Plane Analysis Visualization in Deep Learning via Transfer Entropy](https://arxiv.org/abs/2404.01364) | 通过转移熵进行信息平面分析可视化揭示了信息瓶颈方法中压缩和信息保留的权衡，以及信息论压缩与泛化之间存在的关系。 |
| [^91] | [AIOps Solutions for Incident Management: Technical Guidelines and A Comprehensive Literature Review](https://arxiv.org/abs/2404.01363) | AIOps利用机器学习和大数据等技术提升故障管理效率，但领域仍未统一标准化。 |
| [^92] | [LLM Attributor: Interactive Visual Attribution for LLM Generation](https://arxiv.org/abs/2404.01361) | LLM Attributor是一个Python库，提供了交互式可视化方式用于将LLM的文本生成结果归因到训练数据点，帮助用户检查模型行为、增强可信度，并与用户提供的文本进行比较。 |
| [^93] | [Parallel Proportional Fusion of Spiking Quantum Neural Network for Optimizing Image Classification](https://arxiv.org/abs/2404.01359) | 提出了一种新型架构PPF-QSNN，通过并行方式将数据集信息输入到脉冲神经网络和变分量子电路中，并根据它们各自的贡献比例合并输出。 |
| [^94] | [Utilizing AI and Social Media Analytics to Discover Adverse Side Effects of GLP-1 Receptor Agonists](https://arxiv.org/abs/2404.01358) | 通过利用人工智能驱动的社交媒体分析，我们开发了一种数字健康方法，成功检测出与GLP-1受体激动剂相关的21种潜在不良副作用，包括易怒和麻木感，从而革新了对新部署药物未报告ASEs的检测。 |
| [^95] | [The Double-Edged Sword of Input Perturbations to Robust Accurate Fairness](https://arxiv.org/abs/2404.01356) | 该论文研究了深度神经网络对敌对输入扰动的敏感性，提出了新的鲁棒准确公平性定义，并介绍了一种敌对攻击方法和相应的解决方案。 |
| [^96] | [Efficiently Distilling LLMs for Edge Applications](https://arxiv.org/abs/2404.01353) | 提出了一种名为MLFS的新方法，用于高效参数的超网络训练，可以获得适用于商业边缘应用的高质量编码器模型，并有效地减少训练时间。 |
| [^97] | [VortexViz: Finding Vortex Boundaries by Learning from Particle Trajectories](https://arxiv.org/abs/2404.01352) | 通过将粒子轨迹纳入学习过程，该方法旨在通过利用流线或路径线捕获的流场的区域/局部特征来提高涡旋边界提取的准确性。 |
| [^98] | [AETTA: Label-Free Accuracy Estimation for Test-Time Adaptation](https://arxiv.org/abs/2404.01351) | 提出了AETTA，一种用于测试时适应的无标签准确性估计算法，通过预测不一致性来改进准确性估计并在适应失败情况下展现更高的准确性估计。 |
| [^99] | [Fairness in Large Language Models: A Taxonomic Survey](https://arxiv.org/abs/2404.01349) | 该调查总结了大型语言模型中公平性的最新进展，包括对偏见因素的分析、公平度量和现有算法分类。 |
| [^100] | [CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs](https://arxiv.org/abs/2404.01343) | CHOPS提出了一个名为CHOPS的LLM代理，旨在更高效地利用现有数据库或系统来访问用户信息，提供准确合理的响应或执行所需操作，同时避免有害操作。 |
| [^101] | [DiffAgent: Fast and Accurate Text-to-Image API Selection with Large Language Model](https://arxiv.org/abs/2404.01342) | DiffAgent利用大语言模型设计了一个新的代理工具，能够快速准确地选择最适合的文本到图像API，并提出了一个综合数据集DABench来评估其性能。 |
| [^102] | [Block-Diagonal Guided DBSCAN Clustering](https://arxiv.org/abs/2404.01341) | 该研究提出了一种改进版本的DBSCAN，利用相似性图的块对角属性引导聚类过程，通过构建块对角图并进行聚类排序，易于确定聚类结构。 |
| [^103] | [From Similarity to Superiority: Channel Clustering for Time Series Forecasting](https://arxiv.org/abs/2404.01340) | 通过对通道进行聚类，实现了一种新颖的通道策略，有效平衡了个体通道处理和通道之间必要交互作用，从而提高了时间序列预测性能。 |
| [^104] | [Humane Speech Synthesis through Zero-Shot Emotion and Disfluency Generation](https://arxiv.org/abs/2404.01339) | 该论文实现了一种新颖的语音合成技术，通过零-shot设置中引入人类情感和不流畅特征，使得系统能更好地模仿人类语音，促进更自然的用户互动。 |
| [^105] | [FineFake: A Knowledge-Enriched Dataset for Fine-Grained Multi-Domain Fake News Detecction](https://arxiv.org/abs/2404.01336) | FineFake 数据集为细粒度多领域假新闻检测提供了知识增强，包含16,909个数据样本覆盖六个语义主题和八个平台。 |
| [^106] | [Generative AI for Architectural Design: A Literature Review](https://arxiv.org/abs/2404.01335) | 生成式人工智能在建筑设计中开创了新的方法论范式，显著扩展了设计过程的创新潜力和效率，通过广泛应用生成式AI技术和深度生成模型生成2D图像、视频和3D模型，并审视其在不同阶段的影响趋势。 |
| [^107] | [Wait, It's All Token Noise? Always Has Been: Interpreting LLM Behavior Using Shapley Value](https://arxiv.org/abs/2404.01332) | 使用Shapley值方法解释LLM行为，揭示了所谓的“令牌噪音”效应，揭示了LLMs的决策在很大程度上受到提示组件的影响 |
| [^108] | [LLaVA-Gemma: Accelerating Multimodal Foundation Models with a Compact Language Model](https://arxiv.org/abs/2404.01331) | 使用最新发布的Gemma大型语言模型在LLaVA框架中训练了多模态基础模型，研究了预训练连接器、更强大的图像主干和增加语言主干大小对模型性能的影响。 |
| [^109] | [Entertainment chatbot for the digital inclusion of elderly people without abstraction capabilities](https://arxiv.org/abs/2404.01327) | EBER chatbot是一个旨在减少老年人数字鸿沟的娱乐聊天机器人，其创新之处在于其"智能电台"概念，根据用户的心情和需求提供相关信息。 |
| [^110] | [A Review of Multi-Modal Large Language and Vision Models](https://arxiv.org/abs/2404.01322) | 该论文对具有多模态能力的大型语言模型进行了综述，涵盖了LLMs的发展历程、transformer-based 架构的进展以及注意机制的作用 |
| [^111] | [Graph-Based Optimisation of Network Expansion in a Dockless Bike Sharing System](https://arxiv.org/abs/2404.01320) | 本研究利用Moby Bikes的行程数据构建了一个优化的地理时间图，揭示了在扩展共享单车系统时建立新站点的最佳位置，并利用Louvain算法揭示了展现相似使用模式的自包含子网络。 |
| [^112] | [Information Cascade Prediction under Public Emergencies: A Survey](https://arxiv.org/abs/2404.01319) | 大数据时代带来了公共紧急事件下信息级联预测的机遇，但应用领域限制了跨学科预测方法的统一框架，该调查论文系统分类和总结了这一领域，为研究人员提供了前沿研究和未来方向。 |
| [^113] | [Intelligent Learning Rate Distribution to reduce Catastrophic Forgetting in Transformers](https://arxiv.org/abs/2404.01317) | 本文研究了在Transformer神经网络中的灾难性遗忘问题，通过智能学习率分布取得了比平坦学习率更好的性能，并在GLUE数据集中得到验证。 |
| [^114] | [Learning to Solve Job Shop Scheduling under Uncertainty](https://arxiv.org/abs/2404.01308) | 该论文利用深度强化学习技术解决了具有不确定性的作业车间调度问题，重点在于提出了一种新颖方法来处理具有不确定持续时间的JSSP。 |
| [^115] | [IsoBench: Benchmarking Multimodal Foundation Models on Isomorphic Representations](https://arxiv.org/abs/2404.01266) | IsoBench提出了一个基准数据集，用于评估基于不同同构表示的多模态基础模型的性能差异，发现大多数模型更偏好文本表示。 |
| [^116] | [Direct Preference Optimization of Video Large Multimodal Models from Language Model Reward](https://arxiv.org/abs/2404.01258) | 本研究提出了一种新的框架，利用详细的视频标题作为视频内容的代理，使得语言模型在评分视频问答（QA）预测时能够融入这些信息作为支持证据。 |
| [^117] | [Can LLMs get help from other LLMs without revealing private information?](https://arxiv.org/abs/2404.01041) | 本研究展示了在级联系统中运用隐私保护技术的可行性，以减少在查询远程模型时泄漏私人信息的风险，并引入了两个隐私度量。 |
| [^118] | [Survey of Bias In Text-to-Image Generation: Definition, Evaluation, and Mitigation](https://arxiv.org/abs/2404.01030) | 该调查综述了文本到图像生成中的偏见问题，重点讨论了性别、肤色和地域文化这些方面，旨在帮助理解当前进展和研究空白。 |
| [^119] | [DRCT: Saving Image Super-resolution away from Information Bottleneck](https://arxiv.org/abs/2404.00722) | 基于Vision Transformer的DRCT方法采用创新的机制解决了图像超分辨率中空间信息衰减的问题，提升了模型性能。 |
| [^120] | [LLM meets Vision-Language Models for Zero-Shot One-Class Classification](https://arxiv.org/abs/2404.00675) | 提出了一种两步解决方案，结合大型语言模型和视觉-语言预训练模型，用于零样本单类分类问题，并在实际基准测试中表现出优越性能。 |
| [^121] | [Learning to Generate Conditional Tri-plane for 3D-aware Expression Controllable Portrait Animation](https://arxiv.org/abs/2404.00636) | 本文提出了一种一次性的3D感知肖像动画方法Export3D，通过引入三平面生成器和对比预训练框架，实现了控制给定肖像图像的面部表情和摄像机视角，提供了一种新的表达方式。 |
| [^122] | [AI Act and Large Language Models (LLMs): When critical issues and privacy impact require human and ethical oversight](https://arxiv.org/abs/2404.00600) | 论文讨论了人类监督、道德监督和隐私影响评估在面对人工智能系统和大型语言模型发展中的重要性。 |
| [^123] | [Planning and Editing What You Retrieve for Enhanced Tool Learning](https://arxiv.org/abs/2404.00450) | 该论文提出了一种新颖的模型，结合了“规划与检索”和“编辑与确认”范式，通过神经检索模块和LLM-based查询规划器提高了工具利用的效果。 |
| [^124] | [InfLoRA: Interference-Free Low-Rank Adaptation for Continual Learning](https://arxiv.org/abs/2404.00228) | InfLoRA提出了一种新的PEFT方法，名为无干扰低秩自适应（InfLoRA），用于持续学习，旨在消除新任务对旧任务的干扰，帮助模型在稳定性和可塑性之间取得良好平衡。 |
| [^125] | [LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership and Reasoning](https://arxiv.org/abs/2404.00027) | 探讨使用大型语言模型作为写作助手引发的写作所有权感和作者身份认知之间的心理困境。 |
| [^126] | [Ink and Individuality: Crafting a Personalised Narrative in the Age of LLMs](https://arxiv.org/abs/2404.00026) | 研究探讨了人们日益依赖的基于LLM的写作助手对创造力和个性可能造成的负面影响，旨在改进人机交互系统和提升写作助手的个性化和个性化功能。 |
| [^127] | [Artificial Neural Networks-based Real-time Classification of ENG Signals for Implanted Nerve Interfaces](https://arxiv.org/abs/2403.20234) | 本文探讨了基于人工神经网络的实时分类ENG信号的方法，通过比较ANNs在不同大小数据集上的表现来分析其在处理运动/感觉刺激分类任务中的可行性。 |
| [^128] | [Concept-based Analysis of Neural Networks via Vision-Language Models](https://arxiv.org/abs/2403.19837) | 本文提出利用视觉语言模型作为透镜，通过其隐含的高层次概念来进行对视觉模型的分析。 |
| [^129] | [Knowledge Boundary and Persona Dynamic Shape A Better Social Media Agent](https://arxiv.org/abs/2403.19275) | 通过个性化知识和动态角色信息构建社交媒体代理以解决代理拥有不属于其角色的知识和无法消除多样化角色信息干扰的问题。 |
| [^130] | [ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation](https://arxiv.org/abs/2403.18807) | 通过使用预训练的ViT模型生成的全局图像先验，为单图深度估计模型提供更详细的上下文信息，并提出了一种新的使用扩散骨干且受ViT嵌入条件约束的深度估计模型。 |
| [^131] | [Long-form factuality in large language models](https://arxiv.org/abs/2403.18802) | 该论文提出了一种通过使用大型语言模型将长篇回应分解为单个事实，并通过发送搜索查询到Google搜索，评估事实准确性的方法，并扩展了F1分数作为长篇事实性的聚合度量。 |
| [^132] | [Large Language Models for Education: A Survey and Outlook](https://arxiv.org/abs/2403.18105) | 大型语言模型在教育领域的应用调研总结了LLMs在教育中的各种技术应用，包括学生和教师辅助、自适应学习和商业工具，提出了未来研究机会和潜在方向。 |
| [^133] | [PeersimGym: An Environment for Solving the Task Offloading Problem with Reinforcement Learning](https://arxiv.org/abs/2403.17637) | 引入了 PeersimGym 环境，通过强化学习解决任务卸载问题，支持定制化仿真环境，有助于开发和优化计算网络中的任务卸载策略。 |
| [^134] | [MapGuide: A Simple yet Effective Method to Reconstruct Continuous Language from Brain Activities](https://arxiv.org/abs/2403.17516) | 本研究提出了一种直接比较预测文本嵌入的脑活动映射来指导文本重建的简单而有效方法，相比之前的间接方法显著提高了模型性能。 |
| [^135] | [Transcribing Bengali Text with Regional Dialects to IPA using District Guided Tokens](https://arxiv.org/abs/2403.17407) | 通过引入区域指导标记技术，本文提出了一种将孟加拉文本与地方方言转录为国际音标的方法，为模型提供了关于输入文本的地区方言信息，以理解与每个地区相关的独特音韵模式。 |
| [^136] | [Evolution and Efficiency in Neural Architecture Search: Bridging the Gap Between Expert Design and Automated Optimization](https://arxiv.org/abs/2403.17012) | 本文综述了神经架构搜索（NAS）领域的进化历程，介绍了从手动设计到自动化优化的演变过程，探讨了NAS在各个领域的应用，以及针对计算效率挑战提出的高效NAS方法。 |
| [^137] | [Deciphering the Interplay between Local Differential Privacy, Average Bayesian Privacy, and Maximum Bayesian Privacy](https://arxiv.org/abs/2403.16591) | 论文探讨了本地差分隐私、贝叶斯隐私及其之间的相互关系，揭示了关于效用-隐私权衡的新见解，并提出了一个框架来突出攻击和防御策略的相互作用和效果。 |
| [^138] | [SegICL: A Universal In-context Learning Framework for Enhanced Segmentation in Medical Imaging](https://arxiv.org/abs/2403.16578) | SegICL引入了一种利用上下文学习的图像分割新方法，能够在新任务中适应医学图像分割，无需从头训练模型或进行复杂微调。 |
| [^139] | [Image Captioning in news report scenario](https://arxiv.org/abs/2403.16209) | 本论文探索了专门针对名人照片的图像描述，旨在增强新闻行业实践，并提出了对自动新闻内容生成的改进方法。 |
| [^140] | [Rumor Detection with a novel graph neural network approach](https://arxiv.org/abs/2403.16206) | 本论文提出了一种新颖的检测模型，同时学习用户相关性和信息传播的表示，以检测社交媒体上的谣言 |
| [^141] | [Diverse Representation Embedding for Lifelong Person Re-Identification](https://arxiv.org/abs/2403.16003) | 提出了一种多元表示嵌入(DRE)框架，用于终身人员再识别(LReID)，可以在学习新信息的同时有效保留旧知识，通过自适应约束模块(ACM)实现多个表示之间的整合和推开操作，为每个实例获取密集嵌入子空间，提高有限旧任务数据集上的匹配能力。 |
| [^142] | [FusionINN: Invertible Image Fusion for Brain Tumor Monitoring](https://arxiv.org/abs/2403.15769) | FusionINN引入了一种新颖的可逆图像融合框架，可以高效生成融合图像，并解开融合过程的逆向分解，保证无损的像素映射。 |
| [^143] | [AutoTRIZ: Artificial Ideation with TRIZ and Large Language Models](https://arxiv.org/abs/2403.13002) | 本文提出了AutoTRIZ，一种利用大型语言模型自动化和增强TRIZ方法的人工创意工具，为设计自动化和可解释创意提供了一种新颖方法。 |
| [^144] | [Enhancing Formal Theorem Proving: A Comprehensive Dataset for Training AI Models on Coq Code](https://arxiv.org/abs/2403.12627) | 提出了一个全面的数据集，用于增强大型语言模型在解释和生成Coq代码方面的熟练程度，推动自动定理证明的发展。 |
| [^145] | [Can LLMs Generate Human-Like Wayfinding Instructions? Towards Platform-Agnostic Embodied Instruction Synthesis](https://arxiv.org/abs/2403.11487) | 提出了一种新方法，利用LLM以及上下文学习，实现了自动生成具身机器人的“行路指示”，并且在多个模拟平台上展示出跨平台特性。 |
| [^146] | [Twin Transformer using Gated Dynamic Learnable Attention mechanism for Fault Detection and Diagnosis in the Tennessee Eastman Process](https://arxiv.org/abs/2403.10842) | 本研究提出一种新颖的双Transformer模型，结合门控动态可学习注意机制，用于田纳西伊斯曼过程的故障检测与诊断，提高性能通过独立处理输入数据和提取多样化信息，以及动态学习适应性调整注意策略。 |
| [^147] | [FeatUp: A Model-Agnostic Framework for Features at Any Resolution](https://arxiv.org/abs/2403.10516) | FeatUp是一个任务和模型无关的框架，用于在深度特征中恢复丢失的空间信息，从而使特征可以以任何分辨率重建，在现有应用中取得分辨率和性能的提升。 |
| [^148] | [A Continued Pretrained LLM Approach for Automatic Medical Note Generation](https://arxiv.org/abs/2403.09057) | 这项研究提出了一种用于医疗记录生成的持续预训练LLM方法，在PubMedQA方面性能优于GPT-4，能够更好地捕捉正确的医疗概念，并且在正确性和完整性方面超过人类抄写员。 |
| [^149] | [Cross-modality debiasing: using language to mitigate sub-population shifts in imaging](https://arxiv.org/abs/2403.07888) | 使用自然语言输入去偏置图像特征表示，以改善在子群体上的最坏情况表现。 |
| [^150] | [SSM Meets Video Diffusion Models: Efficient Video Generation with Structured State Spaces](https://arxiv.org/abs/2403.07711) | 提出了一种基于状态空间模型（SSMs）的方法，用于解决使用扩散模型生成长视频序列时注意力层内存消耗增长快、限制较大的问题 |
| [^151] | [Defending Against Unforeseen Failure Modes with Latent Adversarial Training](https://arxiv.org/abs/2403.05030) | 本研究利用潜在对抗训练（LAT）来防御AI系统中未预见的故障模式，通过利用网络实际用于预测的压缩、抽象和结构化概念的潜在表示，有效清除了恶意软件和对抗性攻击。 |
| [^152] | [GraphInstruct: Empowering Large Language Models with Graph Understanding and Reasoning Capability](https://arxiv.org/abs/2403.04483) | 该论文提出了一个名为GraphInstruct的基准，用于评估和增强大规模语言模型的图理解能力，并通过构建GraphLM和提出GraphLM+模型实现了显著的图推理能力增强。 |
| [^153] | [Learning to Compress Prompt in Natural Language Formats](https://arxiv.org/abs/2402.18700) | 该研究旨在通过提出自然语言提示封装（Nano-Capsulator）框架，解决了在自然语言格式中压缩提示的挑战，以提高大型语言模型的可转移性和性能。 |
| [^154] | [All in a Single Image: Large Multimodal Models are In-Image Learners](https://arxiv.org/abs/2402.17971) | 这项研究引入了一种名为图片内学习（I$^2$L）的新型上下文学习机制，将演示示例、视觉线索和指令合并到一个图片中，以提升GPT-4V的能力，并通过整合图像处理、理解和推理的能力来取得多个优点 |
| [^155] | [Understanding the Dataset Practitioners Behind Large Language Model Development](https://arxiv.org/abs/2402.16611) | 数据质量是大型语言模型开发中数据集管理者的首要任务，但管理者间对于数据质量定义和评估方法缺乏共识。 |
| [^156] | [Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering](https://arxiv.org/abs/2402.14320) | Triad框架利用了基于多角色LLM代理来解决知识库问答问题，通过代理的不同角色分别处理KBQA子任务，合作完成KBQA任务，并在多个基准数据集上表现出色。 |
| [^157] | [On Automating Video Game Testing by Planning and Learning](https://arxiv.org/abs/2402.12393) | 提出了一种通过自动规划和学习技术自动化测试视频游戏的方法和工作流程，使得自动规划变得更容易接触到更广泛的受众。 |
| [^158] | [Measuring and Controlling Persona Drift in Language Model Dialogs](https://arxiv.org/abs/2402.10962) | 提出了一种量化基准来测量语言模型对话中的“人设”漂移，并提出了一种称为split-softmax的轻量级方法来对抗注意力衰减和“人设”漂移 |
| [^159] | [MuChin: A Chinese Colloquial Description Benchmark for Evaluating Language Models in the Field of Music](https://arxiv.org/abs/2402.09871) | MuChin是一个用于评估多模态语言模型在音乐理解和描述方面性能的中文口语描述基准。 |
| [^160] | [AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts](https://arxiv.org/abs/2402.07625) | 本论文介绍了一种自主数据选择策略，利用语言模型进行数学文本的自动评估和选择，并通过连续预训练显著提高了数学推理能力。主要创新包括利用元提示语言模型作为验证器，发布了高质量的AutoMathText数据集，并实现了预训练令牌效率的提升。 |
| [^161] | [SCAPE: Searching Conceptual Architecture Prompts using Evolution](https://arxiv.org/abs/2402.00089) | SCAPE是一个将进化搜索与生成式人工智能相结合的工具，能够帮助用户通过简单的操作探索由初始输入启发的创造性和高质量设计，同时提高了图像的新颖性、质量和使用效果。 |
| [^162] | [Deployable Reinforcement Learning with Variable Control Rate](https://arxiv.org/abs/2401.09286) | 应用可变控制频率的强化学习系统，以简化硬件使用、降低能源消耗，并挑战固定频率控制的假设 |
| [^163] | [TeleChat Technical Report](https://arxiv.org/abs/2401.03804) | TeleChat是一个包含30亿、70亿和120亿参数的大型语言模型合集，旨在提供预训练语言模型和与人类喜好相一致的微调聊天模型。研究表明，TeleChat在各种任务上表现出与其他类似规模的开源模型相当的性能。 |
| [^164] | [UINav: A Practical Approach to Train On-Device Automation Agents](https://arxiv.org/abs/2312.10170) | UINav提出了一种基于演示的方法，用于训练适合移动设备的自动化代理，成功率高，训练数据少。 |
| [^165] | [Social, Legal, Ethical, Empathetic, and Cultural Rules: Compilation and Reasoning (Extended Version)](https://arxiv.org/abs/2312.09699) | 该研究介绍了SLEEC（社会、法律、伦理、移情、文化）规则的概念，旨在推动AI系统遵守人类背景相关规则的制定、验证和执行。 |
| [^166] | [Large Human Language Models: A Need and the Challenges](https://arxiv.org/abs/2312.07751) | 大型人类语言模型的建立需要更好地整合人类背景，并面临着如何捕捉人类因素、如何表示以及如何建模的一系列挑战。 |
| [^167] | [HALO: An Ontology for Representing and Categorizing Hallucinations in Large Language Models](https://arxiv.org/abs/2312.05209) | 本文介绍了一种名为HALO的形式化、可扩展的本体论，用OWL编写，用于描述和表示大型语言模型中的六种不同类型的幻觉。 |
| [^168] | [Large Language Models for Mathematicians](https://arxiv.org/abs/2312.04556) | 大型语言模型（LLMs）如ChatGPT因其通用语言理解的能力以及生成高质量文本或计算机代码的能力而备受关注，对数学家的潜在帮助和改变工作方式的影响进行了讨论。 |
| [^169] | [FRDiff : Feature Reuse for Universal Training-free Acceleration of Diffusion Models](https://arxiv.org/abs/2312.03517) | 引入了一种新的加速技术FRDiff，通过利用扩散模型的时间冗余性，重新使用具有高时间相似性的特征图，节省计算资源而不影响输出质量。 |
| [^170] | [Classification for everyone : Building geography agnostic models for fairer recognition](https://arxiv.org/abs/2312.02957) | 本文分析了消除现有图像分类模型中地理偏见的方法，并探讨了如何使这些模型更加鲁棒到图像的地理位置。 |
| [^171] | [DiffiT: Diffusion Vision Transformers for Image Generation](https://arxiv.org/abs/2312.02139) | DiffiT是一种新的模型，结合了Vision Transformer和扩散模型的优势，在图像生成中表现出色，特别是通过引入细粒度去噪控制和时间依赖的多头自注意力机制，实现了高保真图像的生成。 |
| [^172] | [Modular Control Architecture for Safe Marine Navigation: Reinforcement Learning and Predictive Safety Filters](https://arxiv.org/abs/2312.01855) | 这项研究提出了一种模块化的控制架构，结合强化学习和预测安全过滤器，在海产导航中实现了安全稳定的闭环控制。 |
| [^173] | [VA3: Virtually Assured Amplification Attack on Probabilistic Copyright Protection for Text-to-Image Generative Models](https://arxiv.org/abs/2312.00057) | 提出了一种名为VA3的虚拟确认攻击框架，通过对文本到图像生成模型持续交互，显著增加生成侵权内容的概率，并在各种情况下验证了攻击的有效性。 |
| [^174] | [Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce Grokking](https://arxiv.org/abs/2311.18817) | 通过早期和晚期隐性偏见的二分法，本文证明在训练同质神经网络时会出现从核预测器到最小范数/最大间隔预测器的急剧转变，从而引发测试准确性的显著变化。 |
| [^175] | [Corrupting Convolution-based Unlearnable Datasets with Pixel-based Image Transformations](https://arxiv.org/abs/2311.18403) | 研究者提出了一种基于卷积的不可学习数据集，该数据集使得现有的防御方法都失效，提出通过增加特定度量来减轻不可学习效果。 |
| [^176] | [Discovering Effective Policies for Land-Use Planning](https://arxiv.org/abs/2311.12304) | 通过学习代理模型并使用进化搜索过程，发现了可定制到不同位置的有效土地利用政策，为土地利用规划提供了一个潜在有用的工具。 |
| [^177] | [You don't need a personality test to know these models are unreliable: Assessing the Reliability of Large Language Models on Psychometric Instruments](https://arxiv.org/abs/2311.09718) | 评估大型语言模型在人格测量工具上的可靠性，研究探讨当前提示方式是否导致一致且稳健的响应 |
| [^178] | [How Trustworthy are Open-Source LLMs? An Assessment under Malicious Demonstrations Shows their Vulnerabilities](https://arxiv.org/abs/2311.09447) | 本研究通过恶意演示在八个方面对开源LLMs的可信度进行了敌对评估，提出了一种新的攻击策略advCoU，以揭示它们的脆弱性。 |
| [^179] | [Flames: Benchmarking Value Alignment of Chinese Large Language Models](https://arxiv.org/abs/2311.06899) | 中国的大型语言模型的价值观契合性需要更加全面的评估，该研究提出了一个名为"火焰"（Flames）的基准测试，涵盖了常见的无害原则和特定中国价值观，以及复杂场景和隐含恶意的提示方法。 |
| [^180] | [Low-Rank MDPs with Continuous Action Spaces](https://arxiv.org/abs/2311.03564) | 该研究通过探索多种方法，将针对低秩MDPs的现有方法扩展到连续动作空间，同时保持近似正确的学习保证。 |
| [^181] | [Separating and Learning Latent Confounders to Enhancing User Preferences Modeling](https://arxiv.org/abs/2311.03381) | 通过分离和学习潜在混淆因素，提高了用户偏好建模的准确性 |
| [^182] | [MCAD: Multi-teacher Cross-modal Alignment Distillation for efficient image-text retrieval](https://arxiv.org/abs/2310.19654) | 提出了一种Multi-teacher Cross-modality Alignment Distillation（MCAD）技术，通过将融合的单流特征合并到双流模型的图像和文本特征中，以整合单流和双流模型的优点。 |
| [^183] | [Affective and Dynamic Beam Search for Story Generation](https://arxiv.org/abs/2310.15079) | 本文提出了一种情感故事生成器AffGen，通过引入动态束调整和情感重新排名两种新技术，在叙事中注入“有趣的转折”，并在生成充满情感和有趣的叙事方面表现出优异性能。 |
| [^184] | [Configuration Validation with Large Language Models](https://arxiv.org/abs/2310.09690) | 大型语言模型在配置验证中的应用具有可行性和有效性，通过开发一个名为Ciri的通用基于LLM的配置验证框架进行了实证评估。 |
| [^185] | [Rephrase, Augment, Reason: Visual Grounding of Questions for Vision-Language Models](https://arxiv.org/abs/2310.05861) | 通过在输入中添加具有视觉基础的信息作为预防性澄清，可以提高模型性能，减少不充分性，并简化模型回答问题的方式。 |
| [^186] | [Put Your Money Where Your Mouth Is: Evaluating Strategic Planning and Execution of LLM Agents in an Auction Arena](https://arxiv.org/abs/2310.05746) | LLM代理在拍卖竞技场展示出了关键的规划和执行技能，这为建模复杂社会互动在竞争背景下的LLMs潜力提供了新途径。 |
| [^187] | [Bridging the Projection Gap: Overcoming Projection Bias Through Parameterized Distance Learning](https://arxiv.org/abs/2309.01390) | 通过学习参数化的马氏距离度量，解决广义零样本学习中的投影偏差问题，提出了扩展VAEGAN架构和引入新损失函数以实现更稳健的距离学习 |
| [^188] | [Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties](https://arxiv.org/abs/2309.00779) | 介绍了ValuePrism，一个包含218k个价值观、权利和义务，并与31k人类书写情境相联系的大规模数据集。 |
| [^189] | [Generative AI in the Wild: Prospects, Challenges, and Strategies](https://arxiv.org/abs/2302.10827) | GenAI技术在创意产业中推动人类专业知识和AI能力的共同创作过程，但用户同时面临着资源、工具和监管等方面带来的挑战。 |
| [^190] | [Benchmarking Model Predictive Control Algorithms in Building Optimization Testing Framework (BOPTEST)](https://arxiv.org/abs/2301.13447) | 提出了一个基于数据驱动的建模和控制框架，加速模型评估、提供成本效益的梯度，并在模型预测控制中保持良好的预测精度，同时通过建筑优化测试框架（BOPTEST）对建模和控制性能进行广泛评估 |
| [^191] | [BRAIxDet: Learning to Detect Malignant Breast Lesion with Incomplete Annotations](https://arxiv.org/abs/2301.13418) | 本文提出了一种中间解决方案，即将训练构建为弱监督和半监督学习问题，以解决通过不完整注释数据检测恶性乳腺病变的困境 |
| [^192] | [Morphable Diffusion: 3D-Consistent Diffusion for Single-image Avatar Creation.](http://arxiv.org/abs/2401.04728) | 本文通过在多视点一致扩散方法中整合三维可塑模型，提高了从单个图像生成三维一致、可动画和逼真的人物化身的质量和功能。 |
| [^193] | [i-Rebalance: Personalized Vehicle Repositioning for Supply Demand Balance.](http://arxiv.org/abs/2401.04429) | 本文提出了一种名为i-Rebalance的个性化车辆重新定位技术，通过深度强化学习（DRL）估计驾驶员对重新定位推荐的决策。该技术采用顺序重新定位策略，并使用双DRL代理实现供需平衡和驾驶员偏好满意度的优化。 |
| [^194] | [The Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Model Performance.](http://arxiv.org/abs/2401.03729) | 本研究通过一系列提示变化探究改变提示的构建方式对大规模语言模型决策的影响，发现即使微小的改变，比如在提示末尾加一个空格，也可能导致模型的答案变化。同时，请求以XML格式返回和常用的越狱方式也可能对模型标记的数据产生灾难性影响。 |
| [^195] | [SVGDreamer: Text Guided SVG Generation with Diffusion Model.](http://arxiv.org/abs/2312.16476) | 该论文提出了一种名为SVGDreamer的方法，用于基于文本引导的SVG生成。它通过引入语义驱动的图像矢量化过程和基于注意力的元素控制，增强了生成结果的可编辑性和质量。同时，采用基于矢量化粒子分数蒸馏的方法解决了现有方法中的颜色、平滑度和结果多样性方面的挑战。 |
| [^196] | [YAYI-UIE: A Chat-Enhanced Instruction Tuning Framework for Universal Information Extraction.](http://arxiv.org/abs/2312.15548) | 本文提出了一个端到端的增强对话指导的通用信息抽取调优框架（YAYI-UIE），利用对话数据和信息抽取数据共同增强信息抽取性能，在中文数据集上达到了业界领先的性能，在英文数据集上也达到了可比较的性能。 |
| [^197] | [Meta Prompting for AGI Systems.](http://arxiv.org/abs/2311.11482) | 本文全面研究了元提示技术，这是一种创新方法，重塑了大型语言模型、多模态模型和人工智能系统在问题解决和数据解释方面的应用。通过强调信息的结构和句法，元提示将复杂问题拆解为简单的子问题，提高了效率，并且能够与少样本方法进行公平的比较。同时，本文还提出了元提示用于自动生成提示的方法。 |
| [^198] | [FedSN: A General Federated Learning Framework over LEO Satellite Networks.](http://arxiv.org/abs/2311.01483) | FedSN是一个通用的联邦学习框架，用于解决在LEO卫星网络中的异构计算和存储能力、有限的上行速率以及模型陈旧等关键挑战。 |
| [^199] | [Learning and Discovering Quantum Properties with Multi-Task Neural Networks.](http://arxiv.org/abs/2310.11807) | 这篇论文介绍了一种用多任务神经网络学习和发现量子性质的方法，该方法能够同时预测和发现多个量子性质，并且能够推断多体量子系统的全局性质和发现不同相之间的未知边界。 |
| [^200] | [Quantify Health-Related Atomic Knowledge in Chinese Medical Large Language Models: A Computational Analysis.](http://arxiv.org/abs/2310.11722) | 本研究通过构建一个基准，量化了中文医学大型语言模型中与健康相关的原子知识的存储程度，并发现通用LLMs在原子知识和指令遵循能力方面表现更好。两种类型的LLMs都倾向于迎合用户要求。 |
| [^201] | [Hexa: Self-Improving for Knowledge-Grounded Dialogue System.](http://arxiv.org/abs/2310.06404) | 本论文提出了一种自我提升的方法，用于改进知识驱动对话生成的中间步骤的生成性能。通过引入引导提示和修改损失函数的自举策略，提高了生成自动生成回答的多样性，并在各种基准数据集上实验证明了该方法的有效性。 |
| [^202] | [Making PPO even better: Value-Guided Monte-Carlo Tree Search decoding.](http://arxiv.org/abs/2309.15028) | 本文提出了一种基于值导向的Monte-Carlo Tree Search解码算法PPO-MCTS，通过在PPO之上集成MCTS，解决了训练和测试之间部分输出评分机制的不匹配问题，实验证明该算法可以显著提升性能。 |
| [^203] | ["It's a Fair Game'', or Is It? Examining How Users Navigate Disclosure Risks and Benefits When Using LLM-Based Conversational Agents.](http://arxiv.org/abs/2309.11653) | 本研究通过分析用户在实际对话中的敏感披露和采访LLM型对话型智能助手用户的方式，发现用户在使用LLM型对话型智能助手时面临隐私、效用和便利之间的权衡，但用户对隐私风险的认知存在问题，而人类化的互动鼓励了更多敏感的披露，加重了用户的权衡困难。 |
| [^204] | [SLIDE: Reference-free Evaluation for Machine Translation using a Sliding Document Window.](http://arxiv.org/abs/2309.08832) | 本论文提出了一种名为SLIDE的度量方法，通过使用滑动文档窗口来评估机器翻译质量，该方法在某些情况下甚至能消除与参考度量之间的差距，表明源语言上下文可能提供了与人类参考相同的信息。 |
| [^205] | [MusiLingo: Bridging Music and Text with Pre-trained Language Models for Music Captioning and Query Response.](http://arxiv.org/abs/2309.08730) | MusiLingo是一个利用预训练的语言模型将音乐和文本相结合的系统，可以生成音乐字幕和回答音乐相关的查询。通过使用投影层对齐音乐表示，该系统成功地将音乐音频和文本环境联系起来，同时使用了一个新的数据集来推动领域的进展。 |
| [^206] | [ExpertQA: Expert-Curated Questions and Attributed Answers.](http://arxiv.org/abs/2309.07852) | 本论文介绍了ExpertQA，它是一个专家策划的问题和带有属性的答案系统。该系统通过分析语言模型在领域特定情景中提供的事实准确性和归因等方面来确保提供准确的信息。研究还收集了领域专家的问题并要求他们评估生成的答案。这项工作的目的是确保语言模型在高风险领域中不会传播错误信息，从而避免不良的社会后果。 |
| [^207] | [LLM-Rec: Personalized Recommendation via Prompting Large Language Models.](http://arxiv.org/abs/2307.15780) | 本文通过引导大型语言模型进行个性化推荐的研究，提出了四种不同的引导策略，并通过实验证明了这些策略的有效性。这一发现强调了在个性化内容推荐中，采用多样的引导和输入增强技术可以提高大型语言模型的推荐性能。 |
| [^208] | [Gradient strikes back: How filtering out high frequencies improves explanations.](http://arxiv.org/abs/2307.09591) | 本研究发现，基于预测的属性方法与基于梯度的方法产生的属性图具有不同的高频内容，滤除高频率可以提高解释性。 |
| [^209] | [Learned Kernels for Interpretable and Efficient PPG Signal Quality Assessment and Artifact Segmentation.](http://arxiv.org/abs/2307.05385) | 本文提出了一种通过学习核技术，具有解释性且参数较少的方法来评估和分割PPG信号的质量和伪影，与现有的深度神经网络方法相比有着类似甚至更好的性能。 |
| [^210] | [FasterViT: Fast Vision Transformers with Hierarchical Attention.](http://arxiv.org/abs/2306.06189) | 本研究设计了一种新型混合CNN-ViT神经网络FasterViT，引入了具有分层注意力的方法HAT，将全局自我注意力分解为多级注意力，实现了高效的跨窗口通信。 FasterViT在精度和图像吞吐量方面达到了SOTA前沿水平，并已在分类，物体检测和分割等CV任务中得到广泛验证。 |
| [^211] | [Visually-Grounded Descriptions Improve Zero-Shot Image Classification.](http://arxiv.org/abs/2306.06077) | 本文提出了一种称为V-GLOSS的新方法，它利用现代语言模型和语义知识库生成具有视觉基础的类别描述，提高了零样本图像分类的准确性，并引入了一个带有类别描述的银标准数据集。 |
| [^212] | [How Effective Are Neural Networks for Fixing Security Vulnerabilities.](http://arxiv.org/abs/2305.18607) | 这篇论文比较了使用大型代码语言模型和自动化程序修复技术修复Java漏洞的能力，并提供了新的Java漏洞修复基准。在两个真实的Java漏洞基准上进行评估。 |
| [^213] | [Few-shot Link Prediction on N-ary Facts.](http://arxiv.org/abs/2305.06104) | 本文提出了一个新任务——少样本N-元事实链接预测，并提出了一个名为FLEN的模型来实现。FLEN由三个模块组成，可以从有限的标记实例中预测N-元事实中的缺失实体。 |
| [^214] | [Vision-Language Models in Remote Sensing: Current Progress and Future Trends.](http://arxiv.org/abs/2305.05726) | 本文介绍了遥感图像中应用视觉语言模型的现状及未来趋势，视觉语言模型可以推理图像中的底层语义，可以识别对象之间的关系及生成自然语言描述。 |
| [^215] | [PersonaLLM: Investigating the Ability of GPT-3.5 to Express Personality Traits and Gender Differences.](http://arxiv.org/abs/2305.02547) | 本文探究了基于LLMs模拟代理的行为，称之为LLM Personas，在分配大五人格类型和性别角色时是否可以生成具有一致性的个性化特质的内容。 |
| [^216] | [Deep Transfer Learning Applications in Intrusion Detection Systems: A Comprehensive Review.](http://arxiv.org/abs/2304.10550) | 本文全面回顾了深度迁移学习在入侵检测系统中的应用，特别是基于IDS的深度迁移学习，该技术利用多个领域的知识融合和/或适应以提高目标任务的性能，尤其是在目标领域中的标记数据非常少的情况下。 |
| [^217] | [Bayesian neural networks via MCMC: a Python-based tutorial.](http://arxiv.org/abs/2304.02595) | 本文提供了一个基于Python的教程，介绍了贝叶斯神经网络的MCMC方法应用，通过教程使得深度学习开发者能够更好地应用贝叶斯推断进行参数估计和不确定性量化。 |
| [^218] | [Lifelong Learning for Anomaly Detection: New Challenges, Perspectives, and Insights.](http://arxiv.org/abs/2303.07557) | 本文探讨了终身异常检测的重要性，提出设计终身学习复杂性的异常检测方法的挑战和机会，并提供了一种场景生成过程使得研究人员能够进行实验。 |
| [^219] | [Hierarchical Generative Adversarial Imitation Learning with Mid-level Input Generation for Autonomous Driving on Urban Environments.](http://arxiv.org/abs/2302.04823) | 本研究提出了一种名为hGAIL的架构，用于解决车辆的自主导航问题，通过将感知信息直接映射到低级动作的同时，学习车辆环境的中级输入表示。 |
| [^220] | [Estimating truncation effects of quantum bosonic systems using sampling algorithms.](http://arxiv.org/abs/2212.08546) | 本文提出了一种使用传统采样方法估计量子玻色系统截断误差的方法，该方法可用于估计实际量子模拟玻色理论所需的资源，并检查对应量子模拟的结果的有效性。 |
| [^221] | [CP-PINNs: Changepoints Detection in PDEs using Physics Informed Neural Networks with Total-Variation Penalty.](http://arxiv.org/abs/2208.08626) | 本文提出了一种新的CP-PINNs模型，通过将PINNs与总变差惩罚相结合，实现了准确的变点检测和PDE的发现。我们还开发了一种元学习算法，能够在数据的连续批次上动态改进优化目标。实证结果表明，在存在变点的情况下，该方法能够准确估计参数和模型对齐，在没有变点的情况下能够数值上收敛到原始PINNs模型的解。 |

# 详细

[^1]: Pok\'eLLMon：一个用于使用大型语言模型的Pok\'emon对战的与人类能力相当的代理机器人

    Pok\'eLLMon: A Human-Parity Agent for Pok\'emon Battles with Large Language Models

    [https://rss.arxiv.org/abs/2402.01118](https://rss.arxiv.org/abs/2402.01118)

    Pok\'eLLMon是第一个在战术对战游戏中实现人类能力的语言模型化身代理机器人。它通过上下文强化学习、知识增强生成和一致的行动生成的策略，展现了与人类类似的战斗策略和及时决策，并在Ladder比赛中达到了49%的胜率，在邀请对战中达到了56%的胜率。

    

    我们介绍了\textsc{Pok\'eLLMon}，这是第一个在战术对战游戏中实现人类能力的语言模型化身代理机器人，同时以Pok\'emon对战为例进行了证明。 \textsc{Pok\'eLLMon}的设计采用了三个关键策略：（i）上下文强化学习，即即时使用从对战中获得的基于文本的反馈来逐步完善策略；（ii）知识增强生成，即检索外部知识以对抗产生幻觉现象，并使代理机器人能够及时正确地行动；（iii）一致的行动生成，以减轻代理机器人面对强敌时的“惊慌换手”现象，使其可以逃避战斗。我们展示了与人类进行的在线对战中，\textsc{Pok\'eLLMon}采用与人类类似的战斗策略和及时决策，其在Ladder比赛中达到了49%的胜率，在邀请对战中达到了56%的胜率。我们的实现和可玩的战斗日志可以在以下链接中找到：\url{https://gith

    We introduce \textsc{Pok\'eLLMon}, the first LLM-embodied agent that achieves human-parity performance in tactical battle games, as demonstrated in Pok\'emon battles. The design of \textsc{Pok\'eLLMon} incorporates three key strategies: (i) In-context reinforcement learning that instantly consumes text-based feedback derived from battles to iteratively refine the policy; (ii) Knowledge-augmented generation that retrieves external knowledge to counteract hallucination and enables the agent to act timely and properly; (iii) Consistent action generation to mitigate the \textit{panic switching} phenomenon when the agent faces a powerful opponent and wants to elude the battle. We show that online battles against human demonstrates \textsc{Pok\'eLLMon}'s human-like battle strategies and just-in-time decision making, achieving 49\% of win rate in the Ladder competitions and 56\% of win rate in the invited battles. Our implementation and playable battle logs are available at: \url{https://gith
    
[^2]: 用语言对任意3D物体进行分割

    Segment Any 3D Object with Language

    [https://arxiv.org/abs/2404.02157](https://arxiv.org/abs/2404.02157)

    提出了SOLE框架，使用自由形式语言指令进行开放词汇的3D实例分割，通过直接从3D点云生成语义相关的掩模，实现了强大的泛化能力。

    

    在本文中，我们研究了利用自由形式语言指令进行开放词汇的3D实例分割（OV-3DIS）。我们引入了一个名为SOLE的语义和几何意识的视觉-语言学习框架，通过直接从3D点云生成与语义相关的掩模来实现强大的泛化能力。

    arXiv:2404.02157v1 Announce Type: cross  Abstract: In this paper, we investigate Open-Vocabulary 3D Instance Segmentation (OV-3DIS) with free-form language instructions. Earlier works that rely on only annotated base categories for training suffer from limited generalization to unseen novel categories. Recent works mitigate poor generalizability to novel categories by generating class-agnostic masks or projecting generalized masks from 2D to 3D, but disregard semantic or geometry information, leading to sub-optimal performance. Instead, generating generalizable but semantic-related masks directly from 3D point clouds would result in superior outcomes. In this paper, we introduce Segment any 3D Object with LanguagE (SOLE), which is a semantic and geometric-aware visual-language learning framework with strong generalizability by generating semantic-related masks directly from 3D point clouds. Specifically, we propose a multimodal fusion network to incorporate multimodal semantics in both
    
[^3]: 用简单自适应攻击越狱功能对齐的LLM

    Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks

    [https://arxiv.org/abs/2404.02151](https://arxiv.org/abs/2404.02151)

    展示了对齐的LLM对简单自适应越狱攻击不具有鲁棒性，并成功实现了在多个模型上几乎100%的攻击成功率，同时还介绍了对于不公开logprobs的模型如何进行越狱以及如何在受污染的模型中查找木马字符串的方法。

    

    我们展示了即使是最新的安全对齐的LLM也不具有抵抗简单自适应越狱攻击的稳健性。首先，我们展示了如何成功利用对logprobs的访问进行越狱：我们最初设计了一个对抗性提示模板（有时会适应目标LLM），然后我们在后缀上应用随机搜索以最大化目标logprob（例如token“Sure”），可能会进行多次重启。通过这种方式，我们实现了对GPT-3.5/4、Llama-2-Chat-7B/13B/70B、Gemma-7B和针对GCG攻击进行对抗训练的HarmBench上的R2D2等几乎100%的攻击成功率--根据GPT-4的评判。我们还展示了如何通过转移或预填充攻击以100%的成功率对所有不暴露logprobs的Claude模型进行越狱。此外，我们展示了如何在受污染的模型中使用对一组受限制的token执行随机搜索以查找木马字符串的方法--这项任务与许多其他任务共享相同的属性。

    arXiv:2404.02151v1 Announce Type: cross  Abstract: We show that even the most recent safety-aligned LLMs are not robust to simple adaptive jailbreaking attacks. First, we demonstrate how to successfully leverage access to logprobs for jailbreaking: we initially design an adversarial prompt template (sometimes adapted to the target LLM), and then we apply random search on a suffix to maximize the target logprob (e.g., of the token "Sure"), potentially with multiple restarts. In this way, we achieve nearly 100\% attack success rate -- according to GPT-4 as a judge -- on GPT-3.5/4, Llama-2-Chat-7B/13B/70B, Gemma-7B, and R2D2 from HarmBench that was adversarially trained against the GCG attack. We also show how to jailbreak all Claude models -- that do not expose logprobs -- via either a transfer or prefilling attack with 100\% success rate. In addition, we show how to use random search on a restricted set of tokens for finding trojan strings in poisoned models -- a task that shares many s
    
[^4]: FLawN-T5: 有效指导调整数据混合在法律推理中的实证研究

    FLawN-T5: An Empirical Examination of Effective Instruction-Tuning Data Mixtures for Legal Reasoning

    [https://arxiv.org/abs/2404.02127](https://arxiv.org/abs/2404.02127)

    本研究提出了一个名为LawInstruct的大型法律指导数据集，证明了领域特定的预训练和指导调整可以改善在LegalBench上的性能，为在法律领域开发具有更强信息处理和决策能力的模型提供了一个资源。

    

    arXiv:2404.02127v1  公告类型: 跨领域  摘要: 指导调整是使语言模型对直接用户交互有效的重要步骤。然而，许多法律任务仍然超出了大多数开放式LLMs的范围，而且目前该领域还没有任何大规模的数据集。这严重限制了该应用领域的研究。在这项工作中，我们策划了一个名为LawInstruct的大型法律指导数据集，涵盖了17个司法管辖区、24种语言，总计1200万个示例。我们呈现证据表明，领域特定的预训练和指导调整能够改善在LegalBench上的性能，包括将Flan-T5 XL在基准线上提高8个点或16%。然而，该效应并不适用于所有任务、训练模式、模型大小和其他因素。LawInstruct是一个资源，可以加速在法律领域开发具有更强信息处理和决策能力的模型。

    arXiv:2404.02127v1 Announce Type: cross  Abstract: Instruction tuning is an important step in making language models useful for direct user interaction. However, many legal tasks remain out of reach for most open LLMs and there do not yet exist any large scale instruction datasets for the domain. This critically limits research in this application area. In this work, we curate LawInstruct, a large legal instruction dataset, covering 17 jurisdictions, 24 languages and a total of 12M examples. We present evidence that domain-specific pretraining and instruction tuning improve performance on LegalBench, including improving Flan-T5 XL by 8 points or 16\% over the baseline. However, the effect does not generalize across all tasks, training regimes, model sizes, and other factors. LawInstruct is a resource for accelerating the development of models with stronger information processing and decision making capabilities in the legal domain.
    
[^5]: 已经适中的种群规模可证明对噪声具有强大的鲁棒性

    Already Moderate Population Sizes Provably Yield Strong Robustness to Noise

    [https://arxiv.org/abs/2404.02090](https://arxiv.org/abs/2404.02090)

    适中的种群规模可以在先验位噪声存在时保持强鲁棒性，而不会增加在OneMax基准上的渐近运行时间

    

    经验表明，典型的进化算法可以很好地应对诸如嘈杂的函数评估等随机干扰。在第一次针对$(1+\lambda)$和$(1,\lambda)$进化算法在先验位噪声存在时的数学运行时间分析中，我们表明两种算法都能容忍恒定的噪声概率，而不会增加在OneMax基准上的渐近运行时间。为此，种群规模$\lambda$应至少为问题规模$n$的对数。在这方向上的唯一先前结果涉及不太现实的一位噪声模型，需要超线性的问题规模种群大小，并且对于OneMax基准证明了大致是无噪声运行时间的三次方的运行时间保证。我们的显着更强结果基于一种新颖的证明方法，即无噪声后代可以看作是父代和有噪声的后代之间的有偏统一交叉。

    arXiv:2404.02090v1 Announce Type: cross  Abstract: Experience shows that typical evolutionary algorithms can cope well with stochastic disturbances such as noisy function evaluations.   In this first mathematical runtime analysis of the $(1+\lambda)$ and $(1,\lambda)$ evolutionary algorithms in the presence of prior bit-wise noise, we show that both algorithms can tolerate constant noise probabilities without increasing the asymptotic runtime on the OneMax benchmark. For this, a population size $\lambda$ suffices that is at least logarithmic in the problem size $n$. The only previous result in this direction regarded the less realistic one-bit noise model, required a population size super-linear in the problem size, and proved a runtime guarantee roughly cubic in the noiseless runtime for the OneMax benchmark. Our significantly stronger results are based on the novel proof argument that the noiseless offspring can be seen as a biased uniform crossover between the parent and the noisy o
    
[^6]: 通过首选树推进LLM推理通用性

    Advancing LLM Reasoning Generalists with Preference Trees

    [https://arxiv.org/abs/2404.02078](https://arxiv.org/abs/2404.02078)

    新推出的Eurus模型通过基于首选树的推理优化，在多项基准测试中取得了业界领先的成果，尤其在击败了GPT-3.5 Turbo的基准测试中表现突出。

    

    我们介绍了Eurus，一套专为推理优化的大语言模型（LLMs）。经过Mistral-7B和CodeLlama-70B的微调，Eurus模型在涵盖数学、代码生成和逻辑推理问题的多样化基准测试中取得了业界领先的成果。值得注意的是，Eurus-70B在通过涵盖五项任务的12个测试的全面基准测试中击败了GPT-3.5 Turbo，并在LeetCode和TheoremQA两个具有挑战性的基准测试中分别实现了33.3%和32.6%的pass@1准确率，明显优于现有开源模型超过13.3%的边际。Eurus的强大性能主要归功于我们新设计的大规模、高质量对齐数据集UltraInteract，该数据集专门为复杂推理任务而设计。UltraInteract可用于监督微调和首选学习。对于每个指令，它包括一个首选树。

    arXiv:2404.02078v1 Announce Type: new  Abstract: We introduce Eurus, a suite of large language models (LLMs) optimized for reasoning. Finetuned from Mistral-7B and CodeLlama-70B, Eurus models achieve state-of-the-art results among open-source models on a diverse set of benchmarks covering mathematics, code generation, and logical reasoning problems. Notably, Eurus-70B beats GPT-3.5 Turbo in reasoning through a comprehensive benchmarking across 12 tests covering five tasks, and achieves a 33.3% pass@1 accuracy on LeetCode and 32.6% on TheoremQA, two challenging benchmarks, substantially outperforming existing open-source models by margins more than 13.3%. The strong performance of Eurus can be primarily attributed to UltraInteract, our newly-curated large-scale, high-quality alignment dataset specifically designed for complex reasoning tasks. UltraInteract can be used in both supervised fine-tuning and preference learning. For each instruction, it includes a preference tree consisting o
    
[^7]: 红队测试端分任意模型

    Red-Teaming Segment Anything Model

    [https://arxiv.org/abs/2404.02067](https://arxiv.org/abs/2404.02067)

    本文对端分任意模型进行了多方面的红队分析，发现模型在应对风格迁移、隐私攻击和敌对攻击方面存在一些挑战

    

    基础模型已经成为重要的工具，通过在大量数据集上进行预训练，然后对特定应用进行微调，来解决许多复杂任务。端分任意模型是计算机视觉分割任务中第一个也是最知名的基础模型之一。本文提出了一个多方面的红队分析，测试了端分任意模型在挑战性任务上的表现：（1）我们分析了风格迁移对分割掩模的影响，证明将逆境天气条件和雨滴应用于城市道路仪表盘图像显著扭曲生成的掩模。（2）我们专注于评估模型是否可以用于攻击隐私，如识别名人的面孔，并显示出模型在这一任务上具有一些不良知识。（3）最后，我们检查模型在文本提示下对分割掩模的敌对攻击有多强大。我们不仅展示了

    arXiv:2404.02067v1 Announce Type: cross  Abstract: Foundation models have emerged as pivotal tools, tackling many complex tasks through pre-training on vast datasets and subsequent fine-tuning for specific applications. The Segment Anything Model is one of the first and most well-known foundation models for computer vision segmentation tasks. This work presents a multi-faceted red-teaming analysis that tests the Segment Anything Model against challenging tasks: (1) We analyze the impact of style transfer on segmentation masks, demonstrating that applying adverse weather conditions and raindrops to dashboard images of city roads significantly distorts generated masks. (2) We focus on assessing whether the model can be used for attacks on privacy, such as recognizing celebrities' faces, and show that the model possesses some undesired knowledge in this task. (3) Finally, we check how robust the model is to adversarial attacks on segmentation masks under text prompts. We not only show the
    
[^8]: SPMamba：状态空间模型是语音分离中所需的一切

    SPMamba: State-space model is all you need in speech separation

    [https://arxiv.org/abs/2404.02063](https://arxiv.org/abs/2404.02063)

    SPMamba提出了一种利用状态空间模型进行语音分离的新网络架构，通过替换Transformer组件为Mamba模块，旨在提高性能并减少计算需求。

    

    在语音分离领域，CNN和Transformer模型都展示了稳健的分离能力，引起了研究社区的广泛关注。然而，基于CNN的方法对于长序列音频的建模能力有限，导致分离性能不佳。相反，基于Transformer的方法在实际应用中受到计算复杂性的限制。本文提出了一种利用状态空间模型进行语音分离的网络架构，即SPMamba。我们采用TF-GridNet模型作为基础框架，并将其Transformer组件替换为一个双向Mamba模块，旨在捕获更广泛的上下文信息。我们的实验结果揭示了Mamba基于方法在提高性能和减少计算需求方面的重要作用。

    arXiv:2404.02063v1 Announce Type: cross  Abstract: In speech separation, both CNN- and Transformer-based models have demonstrated robust separation capabilities, garnering significant attention within the research community. However, CNN-based methods have limited modelling capability for long-sequence audio, leading to suboptimal separation performance. Conversely, Transformer-based methods are limited in practical applications due to their high computational complexity. Notably, within computer vision, Mamba-based methods have been celebrated for their formidable performance and reduced computational requirements. In this paper, we propose a network architecture for speech separation using a state-space model, namely SPMamba. We adopt the TF-GridNet model as the foundational framework and substitute its Transformer component with a bidirectional Mamba module, aiming to capture a broader range of contextual information. Our experimental results reveal an important role in the performa
    
[^9]: 大规模语言模型中的数字遗忘：遗忘方法综述

    Digital Forgetting in Large Language Models: A Survey of Unlearning Methods

    [https://arxiv.org/abs/2404.02062](https://arxiv.org/abs/2404.02062)

    本综述聚焦于大型语言模型中的数字遗忘，旨在获得一种遗忘方法，能有效地消除模型中的不良知识或行为，同时保留原始模型在理想任务上的性能，并具有可伸缩性。

    

    数字遗忘的目标是，在给定一个存在不良知识或行为的模型的情况下，得到一个新模型，其中不再存在检测到的问题。遗忘的动机包括隐私保护、版权保护、消除偏见和歧视以及预防有害内容生成。有效的数字遗忘必须是有效的（即新模型多么好地遗忘了不良知识/行为），保留原始模型在理想任务上的性能，并且具有可伸缩性（特别是遗忘必须比仅重新训练要有效，仅重新训练需要保留的任务/数据）。本综述聚焦于大型语言模型（LLMs）中的遗忘。首先，我们介绍LLMs的背景，包括它们的组成部分、LLMs的类型以及它们通常的训练流程。其次，我们描述数字遗忘的动机、类型和期望的属性。

    arXiv:2404.02062v1 Announce Type: cross  Abstract: The objective of digital forgetting is, given a model with undesirable knowledge or behavior, obtain a new model where the detected issues are no longer present. The motivations for forgetting include privacy protection, copyright protection, elimination of biases and discrimination, and prevention of harmful content generation. Effective digital forgetting has to be effective (meaning how well the new model has forgotten the undesired knowledge/behavior), retain the performance of the original model on the desirable tasks, and be scalable (in particular forgetting has to be more efficient than retraining from scratch on just the tasks/data to be retained). This survey focuses on forgetting in large language models (LLMs). We first provide background on LLMs, including their components, the types of LLMs, and their usual training pipeline. Second, we describe the motivations, types, and desired properties of digital forgetting. Third, 
    
[^10]: 长文本语言模型在长上下文学习中遇到困难

    Long-context LLMs Struggle with Long In-context Learning

    [https://arxiv.org/abs/2404.02060](https://arxiv.org/abs/2404.02060)

    该研究引入了一个专门的基准 LIConBench，聚焦于长上下文学习，发现长文本语言模型在极端标签分类领域中性能良好，尤其在标记长度不超过20K时表现相对较好。

    

    大型语言模型（LLMs）在处理超过32K标记的长序列方面取得了重大进展。然而，它们的性能评估主要局限在困惑度和合成任务等指标上，这可能无法充分捕捉它们在更微妙的现实场景中的能力。本研究引入了一个专门的基准（LIConBench），着重于长上下文学习，在极端标签分类领域。我们精心选择了六个数据集，其标签范围跨度为28至174类，涵盖了从2K到50K的不同输入（少量演示）长度。我们的基准要求LLMs理解整个输入，以识别庞大的标签空间以进行正确预测。我们在我们的基准上评估了13个长上下文LLMs。我们发现长上下文LLMs在标记长度为20K以下时表现相对较好，并且利用长上下文窗口会带来性能上的好处。

    arXiv:2404.02060v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have made significant strides in handling long sequences exceeding 32K tokens. However, their performance evaluation has largely been confined to metrics like perplexity and synthetic tasks, which may not fully capture their abilities in more nuanced, real-world scenarios. This study introduces a specialized benchmark (LIConBench) focusing on long in-context learning within the realm of extreme-label classification. We meticulously selected six datasets with a label range spanning 28 to 174 classes covering different input (few-shot demonstration) length from 2K to 50K. Our benchmark requires LLMs to comprehend the entire input to recognize the massive label spaces to make correct prediction. We evaluate 13 long-context LLMs on our benchmarks. We find that the long-context LLMs perform relatively well under the token length of 20K and the performance benefits from utilizing the long context window. However,
    
[^11]: 金融交易数据的通用表示：融合本地、全局和外部语境

    Universal representations for financial transactional data: embracing local, global, and external contexts

    [https://arxiv.org/abs/2404.02047](https://arxiv.org/abs/2404.02047)

    提出了一个金融交易数据通用表示的学习框架，结合了本地、全局和外部语境，提出了新颖的生成模型和整合外部信息的方法，并在本地任务中表现出超越性能。

    

    金融交易的有效处理对银行数据分析至关重要。然而，在这一领域中，大多数方法专注于为独立问题提供专门化解决方案，而不是构建适用于许多问题的通用表示。我们提出了一个表示学习框架，旨在解决各种企业挑战。我们还提出了考虑数据特定性的新颖生成模型，并提出了一种整合外部信息到客户表示的方式，借鉴其他客户行动的见解。最后，我们提供了一个基准，描述了全球范围内的表示质量，涉及整个交易历史；本地范围内，反映客户当前状态；动态范围内，捕捉表示随时间演变的情况。我们的生成方法在本地任务中表现出色，对于下一个MCC预测任务的ROC-AUC提升高达14％，对于dow...

    arXiv:2404.02047v1 Announce Type: cross  Abstract: Effective processing of financial transactions is essential for banking data analysis. However, in this domain, most methods focus on specialized solutions to stand-alone problems instead of constructing universal representations suitable for many problems. We present a representation learning framework that addresses diverse business challenges. We also suggest novel generative models that account for data specifics, and a way to integrate external information into a client's representation, leveraging insights from other customers' actions. Finally, we offer a benchmark, describing representation quality globally, concerning the entire transaction history; locally, reflecting the client's current state; and dynamically, capturing representation evolution over time. Our generative approach demonstrates superior performance in local tasks, with an increase in ROC-AUC of up to 14\% for the next MCC prediction task and up to 46\% for dow
    
[^12]: 乌克兰文本分类：跨语言知识传递方法的探索

    Ukrainian Texts Classification: Exploration of Cross-lingual Knowledge Transfer Approaches

    [https://arxiv.org/abs/2404.02043](https://arxiv.org/abs/2404.02043)

    乌克兰文本分类领域探索跨语言知识传递方法，利用最新的NLP技术，测试了在毒性分类、文体分类和自然语言推理任务上的最佳设置。

    

    虽然在自然语言处理文本分类领域存在大量标记数据集，但各种语言可用数据的不平衡问题依然显而易见。乌克兰语作为一种仍可从跨语言方法的持续完善中受益的语言。鉴于我们所了解，针对典型文本分类任务，乌克兰语语料库极度匮乏。在这项工作中，我们利用自然语言处理领域的最新进展，探索跨语言知识传递方法，避免手动数据整理：大型多语言编码器和翻译系统、LLMs，以及语言适配器。我们在三个文本分类任务上测试这些方法--毒性分类、文体分类和自然语言推理--提供了最佳设置的"配方"。

    arXiv:2404.02043v1 Announce Type: cross  Abstract: Despite the extensive amount of labeled datasets in the NLP text classification field, the persistent imbalance in data availability across various languages remains evident. Ukrainian, in particular, stands as a language that still can benefit from the continued refinement of cross-lingual methodologies. Due to our knowledge, there is a tremendous lack of Ukrainian corpora for typical text classification tasks. In this work, we leverage the state-of-the-art advances in NLP, exploring cross-lingual knowledge transfer methods avoiding manual data curation: large multilingual encoders and translation systems, LLMs, and language adapters. We test the approaches on three text classification tasks -- toxicity classification, formality classification, and natural language inference -- providing the "recipe" for the optimal setups.
    
[^13]: 基于大型语言模型的游戏智能体综述

    A Survey on Large Language Model-Based Game Agents

    [https://arxiv.org/abs/2404.02039](https://arxiv.org/abs/2404.02039)

    LLM和MLLM的进步为游戏智能体提供了强大的人类决策能力，本文全面综述了基于LLM的游戏智能体的概念架构、方法论和未来研究方向

    

    游戏智能体的发展在推动人工通用智能（AGI）方面扮演着关键角色。LLM及其多模态对应物（MLLM）的进展为游戏智能体在复杂的电脑游戏环境中具备类似人类决策能力提供了前所未有的机会。本文从整体视角全面概述了基于LLM的游戏智能体。首先，我们介绍了以感知、记忆、思维、角色扮演、行动和学习为中心的LLM游戏智能体的概念架构。其次，我们调查了文献中已有的代表性LLM游戏智能体，涉及到六类游戏中的方法论和适应能力，包括冒险、沟通、竞争、合作、模拟以及创造与探索游戏。最后，我们展望了未来研究的方向。

    arXiv:2404.02039v1 Announce Type: new  Abstract: The development of game agents holds a critical role in advancing towards Artificial General Intelligence (AGI). The progress of LLMs and their multimodal counterparts (MLLMs) offers an unprecedented opportunity to evolve and empower game agents with human-like decision-making capabilities in complex computer game environments. This paper provides a comprehensive overview of LLM-based game agents from a holistic viewpoint. First, we introduce the conceptual architecture of LLM-based game agents, centered around six essential functional components: perception, memory, thinking, role-playing, action, and learning. Second, we survey existing representative LLM-based game agents documented in the literature with respect to methodologies and adaptation agility across six genres of games, including adventure, communication, competition, cooperation, simulation, and crafting & exploration games. Finally, we present an outlook of future research
    
[^14]: MultiParaDetox：将文本净化与并行数据扩展到新语言

    MultiParaDetox: Extending Text Detoxification with Parallel Data to New Languages

    [https://arxiv.org/abs/2404.02037](https://arxiv.org/abs/2404.02037)

    本研究提出了MultiParaDetox，将ParaDetox管道扩展到多种语言，以自动化收集潜在任何语言的并行净化语料库。

    

    文本净化是一项文本风格转换（TST）任务，其中文本被从有毒的表面形式，例如包含粗鲁词汇，转述为中性语体。最近，文本净化方法在各种任务中找到了应用，比如净化大型语言模型（LLMs）（Leong等，2023；He等，2024；Tang等，2023）以及在社交网络中对抗有毒言论（Deng等，2023；Mun等，2023；Agarwal等，2023）。所有这些应用对于确保现代数字世界中的安全沟通至关重要。然而，以前用于并行文本净化语料库收集的方法-- ParaDetox（Logacheva等，2022）和APPADIA（Atwell等，2022）-- 仅在单语言设置中进行了探讨。在本研究中，我们旨在将ParaDetox流程扩展到多种语言，提出MultiParaDetox以自动化潜在任何语言的并行净化语料库收集。

    arXiv:2404.02037v1 Announce Type: cross  Abstract: Text detoxification is a textual style transfer (TST) task where a text is paraphrased from a toxic surface form, e.g. featuring rude words, to the neutral register. Recently, text detoxification methods found their applications in various task such as detoxification of Large Language Models (LLMs) (Leong et al., 2023; He et al., 2024; Tang et al., 2023) and toxic speech combating in social networks (Deng et al., 2023; Mun et al., 2023; Agarwal et al., 2023). All these applications are extremely important to ensure safe communication in modern digital worlds. However, the previous approaches for parallel text detoxification corpora collection -- ParaDetox (Logacheva et al., 2022) and APPADIA (Atwell et al., 2022) -- were explored only in monolingual setup. In this work, we aim to extend ParaDetox pipeline to multiple languages presenting MultiParaDetox to automate parallel detoxification corpus collection for potentially any language. 
    
[^15]: 用于编排双手机器人的大型语言模型

    Large Language Models for Orchestrating Bimanual Robots

    [https://arxiv.org/abs/2404.02018](https://arxiv.org/abs/2404.02018)

    通过提出基于语言模型的双手编排（LABOR），本研究首次应对了在连续空间中进行双手任务协调的挑战。

    

    尽管使机器人具有解决复杂操纵任务的能力已经取得了迅速进展，但为双手机器人生成控制策略以解决涉及两只手的任务仍然具有挑战性，原因是在有效的时间和空间协调方面存在困难。具有逐步推理和背景学习能力，大型语言模型（LLM）已经控制了各种机器人任务。然而，通过单个离散符号序列进行语言交流的本质使得LLM在连续空间中进行双手任务协调成为一项特殊挑战。为了首次通过LLM应对这一挑战，我们提出了基于语言模型的双手编排（LABOR），这是一个利用LLM分析任务配置并设计协调控制策略以解决长期双手任务的代理。在模拟环境中，LABOR代理进行了评估。

    arXiv:2404.02018v1 Announce Type: cross  Abstract: Although there has been rapid progress in endowing robots with the ability to solve complex manipulation tasks, generating control policies for bimanual robots to solve tasks involving two hands is still challenging because of the difficulties in effective temporal and spatial coordination. With emergent abilities in terms of step-by-step reasoning and in-context learning, Large Language Models (LLMs) have taken control of a variety of robotic tasks. However, the nature of language communication via a single sequence of discrete symbols makes LLM-based coordination in continuous space a particular challenge for bimanual tasks. To tackle this challenge for the first time by an LLM, we present LAnguage-model-based Bimanual ORchestration (LABOR), an agent utilizing an LLM to analyze task configurations and devise coordination control policies for addressing long-horizon bimanual tasks. In the simulated environment, the LABOR agent is eval
    
[^16]: 预测与服务机器人互动意图：凝视线索的作用

    Predicting the Intention to Interact with a Service Robot:the Role of Gaze Cues

    [https://arxiv.org/abs/2404.01986](https://arxiv.org/abs/2404.01986)

    凝视线索的有效利用显著提高了服务机器人感知用户互动意图的性能，分类准确性和适应新环境能力。

    

    对于服务机器人来说，尽快感知一个接近的人是否有意互动至关重要：在这种情况下，它可以主动采取友好行为，从而提高用户体验。我们通过一个潜在用户互动意图的序列到序列分类器来解决这个感知任务，可以以自监督方式进行训练。我们的主要贡献在于研究在这一背景下代表个人凝视的特征的益处。对新颖数据集进行的大量实验证明了凝视线索的包含显著改善了分类器性能（AUROC从84.5%提高到91.2%）；可以实现准确分类的距离从2.4米提高到3.2米。我们还量化了系统在没有外部监督的情况下适应新环境的能力。定性实验展示了服务员机器人的实际应用。

    arXiv:2404.01986v1 Announce Type: cross  Abstract: For a service robot, it is crucial to perceive as early as possible that an approaching person intends to interact: in this case, it can proactively enact friendly behaviors that lead to an improved user experience. We solve this perception task with a sequence-to-sequence classifier of a potential user intention to interact, which can be trained in a self-supervised way. Our main contribution is a study of the benefit of features representing the person's gaze in this context. Extensive experiments on a novel dataset show that the inclusion of gaze cues significantly improves the classifier performance (AUROC increases from 84.5% to 91.2%); the distance at which an accurate classification can be achieved improves from 2.4 m to 3.2 m. We also quantify the system's ability to adapt to new environments without external supervision. Qualitative experiments show practical applications with a waiter robot.
    
[^17]: 联合任务正则化用于部分标记的多任务学习

    Joint-Task Regularization for Partially Labeled Multi-Task Learning

    [https://arxiv.org/abs/2404.01976](https://arxiv.org/abs/2404.01976)

    提出了一种联合任务正则化（JTR）技术，通过在单个联合任务潜在空间中同时对所有任务进行正则化，改善了当数据未完全标记所有任务时的学习。

    

    多任务学习在机器学习领域变得越来越流行，但其实用性受到需要大量标记数据集的限制。大多数多任务学习方法依赖完全标记的数据集，其中每个输入示例都附带所有目标任务的地面真相标签。不幸的是，筛选这样的数据集可能会因为昂贵且不切实际，尤其是对于需要每个图像的每个像素标签的密集预测任务。基于此，我们提出了联合任务正则化（JTR），这是一种直观的技术，利用跨任务关系在单个联合任务潜在空间中同时对所有任务进行正则化，以改善在数据未完全标记所有任务时的学习。JTR与现有方法有所不同之处在于它同时对所有任务进行正则化而不是分别对每对任务进行，因此实现了相对于任务数量的线性复杂度，而以前的方法没有做到这一点。

    arXiv:2404.01976v1 Announce Type: cross  Abstract: Multi-task learning has become increasingly popular in the machine learning field, but its practicality is hindered by the need for large, labeled datasets. Most multi-task learning methods depend on fully labeled datasets wherein each input example is accompanied by ground-truth labels for all target tasks. Unfortunately, curating such datasets can be prohibitively expensive and impractical, especially for dense prediction tasks which require per-pixel labels for each image. With this in mind, we propose Joint-Task Regularization (JTR), an intuitive technique which leverages cross-task relations to simultaneously regularize all tasks in a single joint-task latent space to improve learning when data is not fully labeled for all tasks. JTR stands out from existing approaches in that it regularizes all tasks jointly rather than separately in pairs -- therefore, it achieves linear complexity relative to the number of tasks while previous 
    
[^18]: 旨在利用AutoML实现可持续深度学习：基于Deep Shift神经网络的多目标HPO方法

    Towards Leveraging AutoML for Sustainable Deep Learning: A Multi-Objective HPO Approach on Deep Shift Neural Networks

    [https://arxiv.org/abs/2404.01965](https://arxiv.org/abs/2404.01965)

    该研究旨在利用AutoML技术最大化Deep Shift神经网络性能并最小化资源消耗，提出了结合多保真度HPO和多目标优化的方法，实验证明该方法在提高准确率的同时降低了计算复杂性。

    

    深度学习（DL）通过从大型数据集中提取复杂模式推动了各个领域的发展。然而，DL模型的计算需求带来了环境和资源挑战。Deep Shift神经网络（DSNN）利用shift操作减少推理时的计算复杂性，为此提供了解决方案。通过借鉴标准DNN的见解，我们有兴趣通过AutoML技术充分发挥DSNN的潜力。我们研究了超参数优化（HPO）对于最大化DSNN性能同时最小化资源消耗的影响。由于将准确性和能耗作为可能互补目标结合的多目标（MO）优化，我们建议将最先进的多保真度（MF）HPO与多目标优化相结合。实验结果证明了我们方法的有效性，得到了准确率超过80％且计算低耗的模型。

    arXiv:2404.01965v1 Announce Type: cross  Abstract: Deep Learning (DL) has advanced various fields by extracting complex patterns from large datasets. However, the computational demands of DL models pose environmental and resource challenges. Deep shift neural networks (DSNNs) offer a solution by leveraging shift operations to reduce computational complexity at inference. Following the insights from standard DNNs, we are interested in leveraging the full potential of DSNNs by means of AutoML techniques. We study the impact of hyperparameter optimization (HPO) to maximize DSNN performance while minimizing resource consumption. Since this combines multi-objective (MO) optimization with accuracy and energy consumption as potentially complementary objectives, we propose to combine state-of-the-art multi-fidelity (MF) HPO with multi-objective optimization. Experimental results demonstrate the effectiveness of our approach, resulting in models with over 80\% in accuracy and low computational 
    
[^19]: HyperCLOVA X 技术报告

    HyperCLOVA X Technical Report

    [https://arxiv.org/abs/2404.01954](https://arxiv.org/abs/2404.01954)

    HyperCLOVA X 是针对韩国语言和文化定制的大型语言模型，同时具有竞争能力的英语、数学和编码能力，其推理能力强大且具有跨语言的通用能力。

    

    我们介绍了 HyperCLOVA X，这是一系列针对韩国语言和文化定制的大型语言模型（LLMs），同时具有在英语、数学和编码方面的竞争能力。HyperCLOVA X 在平衡混合的韩语、英语和代码数据上进行训练，然后通过高质量的人工注释数据进行指导微调，同时遵守严格的安全准则，体现了我们对负责任人工智能的承诺。该模型在包括综合推理、知识、常识、真实性、编码、数学、聊天、遵循指令和无害性在内的各种基准测试中进行了评估，涵盖韩语和英语。HyperCLOVA X 在韩语方面表现出很强的推理能力，得益于对语言和文化细微差异的深刻理解。对固有的双语特性的进一步分析及其扩展到多语言的研究突显出该模型的跨语言熟练性和强大的泛化能力，以适应未定向的目标。

    arXiv:2404.01954v1 Announce Type: cross  Abstract: We introduce HyperCLOVA X, a family of large language models (LLMs) tailored to the Korean language and culture, along with competitive capabilities in English, math, and coding. HyperCLOVA X was trained on a balanced mix of Korean, English, and code data, followed by instruction-tuning with high-quality human-annotated datasets while abiding by strict safety guidelines reflecting our commitment to responsible AI. The model is evaluated across various benchmarks, including comprehensive reasoning, knowledge, commonsense, factuality, coding, math, chatting, instruction-following, and harmlessness, in both Korean and English. HyperCLOVA X exhibits strong reasoning capabilities in Korean backed by a deep understanding of the language and cultural nuances. Further analysis of the inherent bilingual nature and its extension to multilingualism highlights the model's cross-lingual proficiency and strong generalization ability to untargeted la
    
[^20]: 通过任务分解来改进鸟瞰视图语义分割

    Improving Bird's Eye View Semantic Segmentation by Task Decomposition

    [https://arxiv.org/abs/2404.01925](https://arxiv.org/abs/2404.01925)

    该方法通过将鸟瞰视图语义分割任务分解为BEV地图重建和RGB-BEV特征对齐两个阶段，来优化自动驾驶中的语义分割任务。

    

    鸟瞰视图（BEV）中的语义分割在自动驾驶中扮演着关键角色。先前的方法通常遵循端到端的流程，直接从单眼RGB输入预测BEV分割地图。然而，当RGB输入和BEV目标来自不同视角时，直接点对点预测变得难以优化。本文将原始的BEV分割任务分解为两个阶段，即BEV地图重建和RGB-BEV特征对齐。在第一阶段，我们训练一个BEV自动编码器，以给定受损噪声潜在表示的方式重建BEV分割地图，从而促使解码器学习典型BEV模式的基本知识。第二阶段涉及将RGB输入图像映射到第一阶段的BEV潜在空间中，直接优化两个视图在特征级别上的相关性。我们的方法简化了端到端方法的复杂性。

    arXiv:2404.01925v1 Announce Type: cross  Abstract: Semantic segmentation in bird's eye view (BEV) plays a crucial role in autonomous driving. Previous methods usually follow an end-to-end pipeline, directly predicting the BEV segmentation map from monocular RGB inputs. However, the challenge arises when the RGB inputs and BEV targets from distinct perspectives, making the direct point-to-point predicting hard to optimize. In this paper, we decompose the original BEV segmentation task into two stages, namely BEV map reconstruction and RGB-BEV feature alignment. In the first stage, we train a BEV autoencoder to reconstruct the BEV segmentation maps given corrupted noisy latent representation, which urges the decoder to learn fundamental knowledge of typical BEV patterns. The second stage involves mapping RGB input images into the BEV latent space of the first stage, directly optimizing the correlations between the two views at the feature level. Our approach simplifies the complexity of 
    
[^21]: SGSH：用骨架启发来激发大型语言模型进行知识库问题生成

    SGSH: Stimulate Large Language Models with Skeleton Heuristics for Knowledge Base Question Generation

    [https://arxiv.org/abs/2404.01923](https://arxiv.org/abs/2404.01923)

    本研究提出了SGSH框架，通过骨架启发来激发GPT-3.5生成知识库问题，有效地组织和利用丰富的语义知识。

    

    知识库问题生成（KBQG）旨在从从知识库中提取的三元组事实集生成自然语言问题。现有方法通过预训练语言模型（PLMs）显著提升了KBQG的性能，得益于丰富的语义知识。本文提出了SGSH--一个简单有效的框架，通过骨架启发来增强KBQG的性能。该框架包含“骨架启发”，提供了与每个输入相关的更精细的指导，以激发LLMs生成最佳问题，包括问题短语和助动词等关键要素。

    arXiv:2404.01923v1 Announce Type: cross  Abstract: Knowledge base question generation (KBQG) aims to generate natural language questions from a set of triplet facts extracted from KB. Existing methods have significantly boosted the performance of KBQG via pre-trained language models (PLMs) thanks to the richly endowed semantic knowledge. With the advance of pre-training techniques, large language models (LLMs) (e.g., GPT-3.5) undoubtedly possess much more semantic knowledge. Therefore, how to effectively organize and exploit the abundant knowledge for KBQG becomes the focus of our study. In this work, we propose SGSH--a simple and effective framework to Stimulate GPT-3.5 with Skeleton Heuristics to enhance KBQG. The framework incorporates "skeleton heuristics", which provides more fine-grained guidance associated with each input to stimulate LLMs to generate optimal questions, encompassing essential elements like the question phrase and the auxiliary verb.More specifically, we devise a
    
[^22]: SCANNER：用于强大的多模式具名实体识别的知识增强方法

    SCANNER: Knowledge-Enhanced Approach for Robust Multi-modal Named Entity Recognition of Unseen Entities

    [https://arxiv.org/abs/2404.01914](https://arxiv.org/abs/2404.01914)

    提出了SCANNER模型，通过提取实体候选并利用知识从多种来源获取知识，增强了对未见实体的识别能力，并引入了一种新颖的方法来处理NER数据集中带有噪声注释的挑战。

    

    最近具名实体识别(NER)的进展推动了该任务的边界，将视觉信号纳入其中，导致许多变体，包括多模式NER（MNER）或基于实体的MNER（GMNER）。 这些任务的一个关键挑战是模型应能够推广到训练过程中未见的实体，并能够处理训练样本中带有噪声注释的情况。 为了解决这一障碍，我们提出了SCANNER（用于NER的SpAN CANdidate检测和识别），这是一种能够有效处理所有三种NER变体的模型。 SCANNER是一个两阶段结构；我们在第一阶段提取实体候选，并将其用作查询以获取知识，有效地从各种来源中提取知识。 我们可以通过利用这种以实体为中心的提取知识来提高性能，以解决未见实体。 此外，为了应对NER数据集中由嘈杂注释引起的挑战，我们还介绍了一种新颖的方法。

    arXiv:2404.01914v1 Announce Type: cross  Abstract: Recent advances in named entity recognition (NER) have pushed the boundary of the task to incorporate visual signals, leading to many variants, including multi-modal NER (MNER) or grounded MNER (GMNER). A key challenge to these tasks is that the model should be able to generalize to the entities unseen during the training, and should be able to handle the training samples with noisy annotations. To address this obstacle, we propose SCANNER (Span CANdidate detection and recognition for NER), a model capable of effectively handling all three NER variants. SCANNER is a two-stage structure; we extract entity candidates in the first stage and use it as a query to get knowledge, effectively pulling knowledge from various sources. We can boost our performance by utilizing this entity-centric extracted knowledge to address unseen entities. Furthermore, to tackle the challenges arising from noisy annotations in NER datasets, we introduce a nove
    
[^23]: 连续脉冲图神经网络

    Continuous Spiking Graph Neural Networks

    [https://arxiv.org/abs/2404.01897](https://arxiv.org/abs/2404.01897)

    COS-GNN将脉冲神经网络（SNNs）与连续图神经网络（CGNNs）结合在一起，以在每个时间步骤对图节点进行表示，并将其与时间一起集成到ODE过程中，以增强信息保存和解决在离散图神经网络中的问题。

    

    连续图神经网络（CGNNs）因引入连续动力学而引起了极大关注，能够推广现有的离散图神经网络（GNNs）。它们通常受扩散类方法启发，引入了一种新颖的传播方案，并使用常微分方程（ODE）进行分析。然而，CGNNs的实现需要大量计算能力，这使得它们难以部署在电池供电设备上。受最近脉冲神经网络（SNNs）的启发，SNNs模拟生物推理过程并提供一种节能的神经架构，我们将SNNs与CGNNs结合到一个统一框架中，命名为连续脉冲图神经网络（COS-GNN）。我们在每个时间步骤使用SNNs进行图节点表示，这些表示进一步与时间一起集成到ODE过程中，以增强信息保存和缓解...

    arXiv:2404.01897v1 Announce Type: cross  Abstract: Continuous graph neural networks (CGNNs) have garnered significant attention due to their ability to generalize existing discrete graph neural networks (GNNs) by introducing continuous dynamics. They typically draw inspiration from diffusion-based methods to introduce a novel propagation scheme, which is analyzed using ordinary differential equations (ODE). However, the implementation of CGNNs requires significant computational power, making them challenging to deploy on battery-powered devices. Inspired by recent spiking neural networks (SNNs), which emulate a biological inference process and provide an energy-efficient neural architecture, we incorporate the SNNs with CGNNs in a unified framework, named Continuous Spiking Graph Neural Networks (COS-GNN). We employ SNNs for graph node representation at each time step, which are further integrated into the ODE process along with time. To enhance information preservation and mitigate in
    
[^24]: RAVE: CLIP引导的残差向量嵌入用于背光图像增强

    RAVE: Residual Vector Embedding for CLIP-Guided Backlit Image Enhancement

    [https://arxiv.org/abs/2404.01889](https://arxiv.org/abs/2404.01889)

    该论文提出了一种用于背光图像增强的CLIP引导方法RAVE，通过残差向量嵌入和提示调整的新颖方法，加快了训练并提高了质量。

    

    在本文中，我们提出了一种对反差异式语言-图像预训练（CLIP）指导进行了新颖修改的方法，用于无监督背光图像增强任务。我们的工作建立在最先进的CLIP-LIT方法基础之上，该方法通过约束在CLIP嵌入空间中一个提示对之间的文本-图像相似性来学习一个提示对（负/正样本）和相应图像（背光图像/光照良好的图像）。学习的提示然后指导图像增强网络。基于CLIP-LIT框架，我们提出了两种CLIP引导的新方法。首先，我们展示了在文本嵌入空间调整提示而不损失质量的可能性，从而可以直接在潜在空间中调整它们的嵌入，加快训练并潜在地实现使用没有文本编码器的其他编码器。其次，我们提出了一种不需要任何提示调整的新方法。

    arXiv:2404.01889v1 Announce Type: cross  Abstract: In this paper we propose a novel modification of Contrastive Language-Image Pre-Training (CLIP) guidance for the task of unsupervised backlit image enhancement. Our work builds on the state-of-the-art CLIP-LIT approach, which learns a prompt pair by constraining the text-image similarity between a prompt (negative/positive sample) and a corresponding image (backlit image/well-lit image) in the CLIP embedding space. Learned prompts then guide an image enhancement network. Based on the CLIP-LIT framework, we propose two novel methods for CLIP guidance. First, we show that instead of tuning prompts in the space of text embeddings, it is possible to directly tune their embeddings in the latent space without any loss in quality. This accelerates training and potentially enables the use of additional encoders that do not have a text encoder. Second, we propose a novel approach that does not require any prompt tuning. Instead, based on CLIP e
    
[^25]: 真实、虚假和合成面孔 - 币有三面吗？

    Real, fake and synthetic faces - does the coin have three sides?

    [https://arxiv.org/abs/2404.01878](https://arxiv.org/abs/2404.01878)

    通过分析真实、Deepfake和合成面部图像，研究了它们在图像性质上的相似和不同之处，以及使用了八个深度学习模型进行区分分析。

    

    随着生成人工智能的不断增强，Deepfake和人工生成的（合成）媒体继续在网络上传播，引发了关于它们使用的各种伦理和道德关切。为了解决这个问题，我们对真实、Deepfake和合成面部图像中观察到的趋势和模式进行了新颖的探索。提出的分析分为两部分：首先，我们引入了八个深度学习模型，并分析它们在区分这三类图像方面的性能。接下来，我们进一步研究了这三类图像之间的相似之处和差异，通过分析它们的图像特性，既涵盖整个图像的背景，也包括图像内的特定区域。ANOVA测试也被执行，并为这三类图像之间关联的模式提供了进一步的诠释。通过我们的研究结果，我们发现

    arXiv:2404.01878v1 Announce Type: cross  Abstract: With the ever-growing power of generative artificial intelligence, deepfake and artificially generated (synthetic) media have continued to spread online, which creates various ethical and moral concerns regarding their usage. To tackle this, we thus present a novel exploration of the trends and patterns observed in real, deepfake and synthetic facial images. The proposed analysis is done in two parts: firstly, we incorporate eight deep learning models and analyze their performances in distinguishing between the three classes of images. Next, we look to further delve into the similarities and differences between these three sets of images by investigating their image properties both in the context of the entire image as well as in the context of specific regions within the image. ANOVA test was also performed and provided further clarity amongst the patterns associated between the images of the three classes. From our findings, we obser
    
[^26]: 超越准确性：评估大型语言模型的推理行为--一项调查

    Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language Models -- A Survey

    [https://arxiv.org/abs/2404.01869](https://arxiv.org/abs/2404.01869)

    本文通过综述超越任务准确性的研究，提供对大型语言模型推理过程更深入了解，并强调了LLMs倾向于依赖于训练数据中的表面模式和相关性。

    

    大型语言模型（LLMs）最近在涉及推理的任务中表现出色，引发了关于这些模型是否具有类似于人类的推理能力的激烈讨论。然而，尽管取得了成功，但LLMs的推理能力的深度仍然存在不确定性。这种不确定性部分源自对模型推理行为的深入调查而非仅仅通过表面准确性指标来衡量任务表现。本文旨在通过综述超越任务准确性的研究，提供对模型推理过程更深入的了解来弥补这一差距。此外，我们调查了评估LLMs推理行为的主要方法论，强调了当前对更细致推理分析的趋势和努力。我们的综述表明，LLMs倾向于依赖于训练数据中的表面模式和相关性。

    arXiv:2404.01869v1 Announce Type: cross  Abstract: Large language models (LLMs) have recently shown impressive performance on tasks involving reasoning, leading to a lively debate on whether these models possess reasoning capabilities similar to humans. However, despite these successes, the depth of LLMs' reasoning abilities remains uncertain. This uncertainty partly stems from the predominant focus on task performance, measured through shallow accuracy metrics, rather than a thorough investigation of the models' reasoning behavior. This paper seeks to address this gap by providing a comprehensive review of studies that go beyond task accuracy, offering deeper insights into the models' reasoning processes. Furthermore, we survey prevalent methodologies to evaluate the reasoning behavior of LLMs, emphasizing current trends and efforts towards more nuanced reasoning analyses. Our review suggests that LLMs tend to rely on surface-level patterns and correlations in their training data, rat
    
[^27]: 面向细化文本到图像模型的置信度感知奖励优化

    Confidence-aware Reward Optimization for Fine-tuning Text-to-Image Models

    [https://arxiv.org/abs/2404.01863](https://arxiv.org/abs/2404.01863)

    使用奖励函数训练的细化文本到图像模型可能会因为奖励过度优化而损害性能，为了解决这一问题，提出了一种基于奖励模型置信度的对齐性增强方法。

    

    在人类反馈数据训练的奖励函数上对细化文本到图像模型进行微调已被证明可以有效地使模型行为与人类意图一致。然而，过度优化使用这些奖励模型，作为简单的替代目标，可能会损害细化模型的性能，这一现象被称为奖励过度优化。为深入研究这个问题，我们引入了Text-Image Alignment Assessment (TIA2)基准测试，它包括一系列文本提示、图像和人类注释。我们在该基准测试上评估了几种最先进的奖励模型，发现它们经常与人类评估不一致。我们从实证角度证明，当使用一个与人类评估不一致的奖励模型作为微调目标时，奖励过度优化尤为明显。为应对这个问题，我们提出了TextNorm，一种简单的方法，它基于估计的奖励模型置信度来增强对齐性。

    arXiv:2404.01863v1 Announce Type: cross  Abstract: Fine-tuning text-to-image models with reward functions trained on human feedback data has proven effective for aligning model behavior with human intent. However, excessive optimization with such reward models, which serve as mere proxy objectives, can compromise the performance of fine-tuned models, a phenomenon known as reward overoptimization. To investigate this issue in depth, we introduce the Text-Image Alignment Assessment (TIA2) benchmark, which comprises a diverse collection of text prompts, images, and human annotations. Our evaluation of several state-of-the-art reward models on this benchmark reveals their frequent misalignment with human assessment. We empirically demonstrate that overoptimization occurs notably when a poorly aligned reward model is used as the fine-tuning objective. To address this, we propose TextNorm, a simple method that enhances alignment based on a measure of reward model confidence estimated across 
    
[^28]: 下一个去哪里：基于零样本泛化的LLMs用于下一个POI推荐

    Where to Move Next: Zero-shot Generalization of LLMs for Next POI Recommendation

    [https://arxiv.org/abs/2404.01855](https://arxiv.org/abs/2404.01855)

    设计了新颖的提示策略和进行了实证研究以探索LLMs用于下一个POI推荐的零样本泛化能力

    

    下一个兴趣点（POI）推荐为用户提供了探索周边环境的宝贵建议。现有研究依赖于从大规模用户签到数据构建推荐模型，这是任务特定的，并需要大量的计算资源。最近，预训练的大型语言模型（LLMs）在各种NLP任务中取得了显著进展，并且已经被研究用于推荐场景。然而，LLMs的泛化能力在解决下一个POI推荐问题时仍未被探索，其中应提取用户的地理移动模式。虽然有研究利用LLMs进行下一个项目推荐，但它们未能考虑地理影响和顺序转换。因此，它们无法有效解决下一个POI推荐任务。为此，我们设计了新颖的提示策略，并进行了实证研究以验证

    arXiv:2404.01855v1 Announce Type: cross  Abstract: Next Point-of-interest (POI) recommendation provides valuable suggestions for users to explore their surrounding environment. Existing studies rely on building recommendation models from large-scale users' check-in data, which is task-specific and needs extensive computational resources. Recently, the pretrained large language models (LLMs) have achieved significant advancements in various NLP tasks and have also been investigated for recommendation scenarios. However, the generalization abilities of LLMs still are unexplored to address the next POI recommendations, where users' geographical movement patterns should be extracted. Although there are studies that leverage LLMs for next-item recommendations, they fail to consider the geographical influence and sequential transitions. Hence, they cannot effectively solve the next POI recommendation task. To this end, we design novel prompting strategies and conduct empirical studies to ass
    
[^29]: EV2Gym：一种用于电动汽车智能充电研究和基准测试的灵活V2G模拟器

    EV2Gym: A Flexible V2G Simulator for EV Smart Charging Research and Benchmarking

    [https://arxiv.org/abs/2404.01849](https://arxiv.org/abs/2404.01849)

    该论文介绍了EV2Gym，这是一个灵活的V2G模拟器平台，用于开发和评估各种规模的智能充电算法，并提供了丰富的模型和界面选择。

    

    随着电动汽车（EV）数量的增加，人们对当前充电和电网基础设施容量的担忧日益加剧，必须开发智能充电解决方案。尽管近年来已开发了许多智能充电模拟器，但只有少数支持以Gym环境形式开发强化学习（RL）算法，而这些模拟器通常缺乏对V2G场景的深入建模。为解决上述问题，本文介绍了EV2Gym，这是一个用于开发和评估规模化智能充电算法的实际模拟器平台，并提供了标准化平台。所提出的模拟器采用了经过验证的真实数据进行验证的全面EV、充电站、电力变压器和EV行为模型。EV2Gym具有高度可定制的界面，用户可以从预设计的案例研究中进行选择，也可以制定自己的定制场景。

    arXiv:2404.01849v1 Announce Type: cross  Abstract: As electric vehicle (EV) numbers rise, concerns about the capacity of current charging and power grid infrastructure grow, necessitating the development of smart charging solutions. While many smart charging simulators have been developed in recent years, only a few support the development of Reinforcement Learning (RL) algorithms in the form of a Gym environment, and those that do usually lack depth in modeling Vehicle-to-Grid (V2G) scenarios. To address the aforementioned issues, this paper introduces the EV2Gym, a realistic simulator platform for the development and assessment of small and large-scale smart charging algorithms within a standardized platform. The proposed simulator is populated with comprehensive EV, charging station, power transformer, and EV behavior models validated using real data. EV2Gym has a highly customizable interface empowering users to choose from pre-designed case studies or craft their own customized sc
    
[^30]: 伟大，现在写一篇关于此的文章：Crescendo多回合LLM越狱攻击

    Great, Now Write an Article About That: The Crescendo Multi-Turn LLM Jailbreak Attack

    [https://arxiv.org/abs/2404.01833](https://arxiv.org/abs/2404.01833)

    提出了一种名为Crescendo的新型多回合越狱攻击方法，通过看似良性的对话方式逐渐升级与模型的交互，成功突破了大型语言模型的限制。

    

    大型语言模型（LLMs）的流行程度大幅上升，并且越来越多地被应用于多个领域。这些LLMs在设计上避免涉及非法或不道德的话题，以避免对负责任的AI造成伤害。然而，最近出现了一系列攻击，被称为“越狱”，旨在突破这种对齐。直观地说，越狱攻击旨在缩小模型能做的与愿意做的之间的差距。本文介绍了一种名为Crescendo的新型越狱攻击。与现有的越狱方法不同，Crescendo是一种多回合越狱，以一种看似良性的方式与模型进行交互。它从有关手头任务的一般提示或问题开始，然后逐渐升级对话，引用模型的回复，逐渐导致成功越狱。我们在包括ChatGPT、Gemini Pr在内的各种公共系统上评估了Crescendo。

    arXiv:2404.01833v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have risen significantly in popularity and are increasingly being adopted across multiple applications. These LLMs are heavily aligned to resist engaging in illegal or unethical topics as a means to avoid contributing to responsible AI harms. However, a recent line of attacks, known as "jailbreaks", seek to overcome this alignment. Intuitively, jailbreak attacks aim to narrow the gap between what the model can do and what it is willing to do. In this paper, we introduce a novel jailbreak attack called Crescendo. Unlike existing jailbreak methods, Crescendo is a multi-turn jailbreak that interacts with the model in a seemingly benign manner. It begins with a general prompt or question about the task at hand and then gradually escalates the dialogue by referencing the model's replies, progressively leading to a successful jailbreak. We evaluate Crescendo on various public systems, including ChatGPT, Gemini Pr
    
[^31]: 不忘防御：各向异性与各向同性伪重演的持续对抗性防御

    Defense without Forgetting: Continual Adversarial Defense with Anisotropic & Isotropic Pseudo Replay

    [https://arxiv.org/abs/2404.01828](https://arxiv.org/abs/2404.01828)

    持续对抗性防御概念下提出了各向异性和各向同性伪重演（AIR），通过各向同性重演保持模型一致性，在各向异性重演中学习折衷数据流形。

    

    深度神经网络已经表现出对抗性攻击的易受性。对抗性防御技术通常专注于一次性设置，以保持对抗攻击的稳健性。然而，在实际部署场景中，新的攻击可能会连续出现。因此，防御模型不断适应新的攻击是至关重要的，但适应过程可能会导致对先前进行防御的攻击的灾难性遗忘。在本文中，我们首次讨论了在一系列攻击下的持续对抗性防御的概念，并提出了一种名为各向异性与各向同性重演（AIR）的终身防御基线，具有三个优势：（1）各向同性重演确保模型在新数据的邻域分布中保持一致性，间接地对齐了旧任务和新任务之间的输出偏好。 (2) 各向异性重演使模型能够学习一个带有新混合语义的折衷数据流形

    arXiv:2404.01828v1 Announce Type: cross  Abstract: Deep neural networks have demonstrated susceptibility to adversarial attacks. Adversarial defense techniques often focus on one-shot setting to maintain robustness against attack. However, new attacks can emerge in sequences in real-world deployment scenarios. As a result, it is crucial for a defense model to constantly adapt to new attacks, but the adaptation process can lead to catastrophic forgetting of previously defended against attacks. In this paper, we discuss for the first time the concept of continual adversarial defense under a sequence of attacks, and propose a lifelong defense baseline called Anisotropic \& Isotropic Replay (AIR), which offers three advantages: (1) Isotropic replay ensures model consistency in the neighborhood distribution of new data, indirectly aligning the output preference between old and new tasks. (2) Anisotropic replay enables the model to learn a compromise data manifold with fresh mixed semantics 
    
[^32]: 基于NeRF的物体模型的不确定性感知主动学习对机器人操作者进行视觉和重新定位操作

    Uncertainty-aware Active Learning of NeRF-based Object Models for Robot Manipulators using Visual and Re-orientation Actions

    [https://arxiv.org/abs/2404.01812](https://arxiv.org/abs/2404.01812)

    本文提出了一种基于NeRF的物体模型的不确定性感知主动学习方法，通过优化信息量和可行性来快速学习完整的3D物体模型，能够在陌生方向进行操作，并在操作过程中改进视觉重建质量。

    

    在没有三维表示的情况下操作看不见的物体是具有挑战性的，因为物体通常有遮挡表面。这需要通过与物体的物理交互来构建它们的内部表示。本文提出了一种方法，使机器人能够快速学习给定物体的完整三维模型，以便在陌生方向进行操作。我们使用部分构造的NeRF模型的集成来量化模型的不确定性，以确定下一步行动（视觉或重新定位行动），通过优化信息量和可行性。此外，我们的方法确定何时以及如何抓取和重新定位物体，鉴于其部分NeRF模型，并重新估计物体姿态以纠正交互过程中引入的错位。在模拟环境中对使用基准物体操作的Franka Emika机械手操作者进行实验，表明视觉重建质量提高了14%。

    arXiv:2404.01812v1 Announce Type: cross  Abstract: Manipulating unseen objects is challenging without a 3D representation, as objects generally have occluded surfaces. This requires physical interaction with objects to build their internal representations. This paper presents an approach that enables a robot to rapidly learn the complete 3D model of a given object for manipulation in unfamiliar orientations. We use an ensemble of partially constructed NeRF models to quantify model uncertainty to determine the next action (a visual or re-orientation action) by optimizing informativeness and feasibility. Further, our approach determines when and how to grasp and re-orient an object given its partial NeRF model and re-estimates the object pose to rectify misalignments introduced during the interaction. Experiments with a simulated Franka Emika Robot Manipulator operating in a tabletop environment with benchmark objects demonstrate an improvement of (i) 14% in visual reconstruction quality
    
[^33]: 模仿游戏：基于模型和模仿学习的深度强化学习混合方法

    Imitation Game: A Model-based and Imitation Learning Deep Reinforcement Learning Hybrid

    [https://arxiv.org/abs/2404.01794](https://arxiv.org/abs/2404.01794)

    深度强化学习的研究结合了基于模型的方法和模仿学习，以解决训练样本需求高和概念漂移等问题。

    

    基于深度强化学习的自主学习系统已经被牢固地确立为创建具有韧性和高效能的网络能源系统方法的基础。然而，大多数当前方法存在两个明显问题：像Soft Actor Critic这样的现代无模型算法需要大量样本来学习有意义的策略，以及需要应对概念漂移（例如，灾难性遗忘）的备用措施。在本文中，我们提出了一个混合代理架构的进行中工作，将基于模型的深度强化学习与模仿学习相结合，以克服这两个问题。

    arXiv:2404.01794v1 Announce Type: new  Abstract: Autonomous and learning systems based on Deep Reinforcement Learning have firmly established themselves as a foundation for approaches to creating resilient and efficient Cyber-Physical Energy Systems. However, most current approaches suffer from two distinct problems: Modern model-free algorithms such as Soft Actor Critic need a high number of samples to learn a meaningful policy, as well as a fallback to ward against concept drifts (e. g., catastrophic forgetting). In this paper, we present the work in progress towards a hybrid agent architecture that combines model-based Deep Reinforcement Learning with imitation learning to overcome both problems.
    
[^34]: 房间里的一只吵闹的大象：您的离群检测器对标签噪音鲁棒吗？

    A noisy elephant in the room: Is your out-of-distribution detector robust to label noise?

    [https://arxiv.org/abs/2404.01775](https://arxiv.org/abs/2404.01775)

    本研究探讨了当下训练分类器的标签不可靠时，20种最新OOD检测方法在离群检测中的表现，为了解类别标签噪音对OOD检测的影响提供了深入见解。

    

    多数情况下，检测计算机视觉系统中的陌生或意外图像是确保安全部署的关键。在分类领域，检测模型训练领域外图像的任务被称为离群检测（OOD检测）。尽管人们越来越关注发展事后OOD检测方法，但对于在基础分类器未经过干净、精心筛选数据集训练时这些方法表现如何的讨论相对较少。本研究在20种最新的OOD检测方法中更为现实的情况下进行了深入探讨，在此情况下，用于训练基础分类器的标签不可靠（例如，众包或网络抓取标签）。通过在不同数据集、噪音类型和级别、架构和检查点策略上进行广泛实验，我们研究了类别标签噪音对OOD检测的影响，并表明...

    arXiv:2404.01775v1 Announce Type: cross  Abstract: The ability to detect unfamiliar or unexpected images is essential for safe deployment of computer vision systems. In the context of classification, the task of detecting images outside of a model's training domain is known as out-of-distribution (OOD) detection. While there has been a growing research interest in developing post-hoc OOD detection methods, there has been comparably little discussion around how these methods perform when the underlying classifier is not trained on a clean, carefully curated dataset. In this work, we take a closer look at 20 state-of-the-art OOD detection methods in the (more realistic) scenario where the labels used to train the underlying classifier are unreliable (e.g. crowd-sourced or web-scraped labels). Extensive experiments across different datasets, noise types & levels, architectures and checkpointing strategies provide insights into the effect of class label noise on OOD detection, and show tha
    
[^35]: 用于增强基于文本的陈规检测和基于探测的偏见评估的大规模语言模型审计

    Auditing Large Language Models for Enhanced Text-Based Stereotype Detection and Probing-Based Bias Evaluation

    [https://arxiv.org/abs/2404.01768](https://arxiv.org/abs/2404.01768)

    该研究引入了Multi-Grain Stereotype（MGS）数据集，探索了不同的机器学习方法用于建立陈规检测的基线，并提出了一系列基于MGS数据训练的英文文本的陈规分类器模型。

    

    大型语言模型（LLMs）的最新进展显著提高了它们在面向人类的人工智能（AI）应用中的影响力。然而，LLMs可能会复制甚至加剧自训练数据中的陈规输出。本研究介绍了Multi-Grain Stereotype（MGS）数据集，包括51,867个实例，涵盖性别、种族、职业、宗教和陈规文本，通过融合多个先前公开的陈规检测数据集收集而来。我们探索了旨在为陈规检测建立基线的不同机器学习方法，并微调了多种架构和模型大小的几个语言模型，本文展示了一系列基于MGS训练的英文文本的陈规分类器模型。为了了解我们的陈规检测器是否捕捉到与人类常识一致的相关特征，我们利用了各种可解释的AI工具，

    arXiv:2404.01768v1 Announce Type: cross  Abstract: Recent advancements in Large Language Models (LLMs) have significantly increased their presence in human-facing Artificial Intelligence (AI) applications. However, LLMs could reproduce and even exacerbate stereotypical outputs from training data. This work introduces the Multi-Grain Stereotype (MGS) dataset, encompassing 51,867 instances across gender, race, profession, religion, and stereotypical text, collected by fusing multiple previously publicly available stereotype detection datasets. We explore different machine learning approaches aimed at establishing baselines for stereotype detection, and fine-tune several language models of various architectures and model sizes, presenting in this work a series of stereotypes classifier models for English text trained on MGS. To understand whether our stereotype detectors capture relevant features (aligning with human common sense) we utilise a variety of explanainable AI tools, including 
    
[^36]: Peer-aided Repairer: 增强大型语言模型修复高级学生作业

    Peer-aided Repairer: Empowering Large Language Models to Repair Advanced Student Assignments

    [https://arxiv.org/abs/2404.01754](https://arxiv.org/abs/2404.01754)

    该研究提出了一个名为PaR的新框架，通过大型语言模型的支持，能够修复高级编程作业中的程序错误。

    

    arXiv:2404.01754v1 通告类型:跨领域 摘要:自动化生成针对编程作业的反馈对编程教育具有重要意义，尤其是在涉及高级作业时。自动程序修复技术，尤其是基于大型语言模型的方法，因其具有修复入门作业潜力而备受认可。然而，用于评估的程序相对简单。现有方法在修复来自高级编程课程的程序方面的表现仍不清楚。为了解决这些限制，我们从高级编程课程中创建了一个名为Defects4DS的新高级学生作业数据集。随后，我们确定了在修复高级作业中的错误方面所面临的挑战。基于分析，我们开发了一个名为PaR的由LLM驱动的框架。PaR分为三个阶段运行：同行解决方案选择、多源提示生成和程序修复。

    arXiv:2404.01754v1 Announce Type: cross  Abstract: Automated generation of feedback on programming assignments holds significant benefits for programming education, especially when it comes to advanced assignments. Automated Program Repair techniques, especially Large Language Model based approaches, have gained notable recognition for their potential to fix introductory assignments. However, the programs used for evaluation are relatively simple. It remains unclear how existing approaches perform in repairing programs from higher-level programming courses. To address these limitations, we curate a new advanced student assignment dataset named Defects4DS from a higher-level programming course. Subsequently, we identify the challenges related to fixing bugs in advanced assignments. Based on the analysis, we develop a framework called PaR that is powered by the LLM. PaR works in three phases: Peer Solution Selection, Multi-Source Prompt Generation, and Program Repair. Peer Solution Selec
    
[^37]: 安全间隔RRT*用于连续空间中可扩展的多机器人路径规划

    Safe Interval RRT* for Scalable Multi-Robot Path Planning in Continuous Space

    [https://arxiv.org/abs/2404.01752](https://arxiv.org/abs/2404.01752)

    提出了安全间隔RRT*（SI-RRT*）两级方法，低级采用采样规划器找到单个机器人的无碰撞轨迹，高级通过优先规划或基于冲突的搜索解决机器人间冲突，实验结果表明SI-RRT*能够快速找到高质量解决方案

    

    在本文中，我们考虑了在连续空间中解决多机器人路径规划（MRPP）问题以找到无冲突路径的问题。问题的困难主要来自两个因素。首先，涉及多个机器人会导致组合决策，使搜索空间呈指数级增长。其次，连续空间呈现出潜在无限的状态和动作。针对这个问题，我们提出了一个两级方法，低级是基于采样的规划器安全间隔RRT*（SI-RRT*），用于找到单个机器人的无碰撞轨迹。高级可以使用能够解决机器人间冲突的任何方法，我们采用了两种代表性方法，即优先规划（SI-CPP）和基于冲突的搜索（SI-CCBS）。实验结果表明，SI-RRT*能够快速找到高质量解决方案，并且所需的样本数量较少。SI-CPP表现出更好的可扩展性，而SI-CCBS产生

    arXiv:2404.01752v1 Announce Type: cross  Abstract: In this paper, we consider the problem of Multi-Robot Path Planning (MRPP) in continuous space to find conflict-free paths. The difficulty of the problem arises from two primary factors. First, the involvement of multiple robots leads to combinatorial decision-making, which escalates the search space exponentially. Second, the continuous space presents potentially infinite states and actions. For this problem, we propose a two-level approach where the low level is a sampling-based planner Safe Interval RRT* (SI-RRT*) that finds a collision-free trajectory for individual robots. The high level can use any method that can resolve inter-robot conflicts where we employ two representative methods that are Prioritized Planning (SI-CPP) and Conflict Based Search (SI-CCBS). Experimental results show that SI-RRT* can find a high-quality solution quickly with a small number of samples. SI-CPP exhibits improved scalability while SI-CCBS produces 
    
[^38]: 面向自动驾驶车辆的可扩展高效交互感知规划使用知识蒸馏

    Towards Scalable & Efficient Interaction-Aware Planning in Autonomous Vehicles using Knowledge Distillation

    [https://arxiv.org/abs/2404.01746](https://arxiv.org/abs/2404.01746)

    引入了一种结合深度学习和约束优化的高效方法，利用知识蒸馏训练更小更高效的网络，从而减轻复杂性

    

    真实世界的驾驶涉及车辆在拥挤交通场景中相互复杂的互动。最近的研究关注于增强自动驾驶车辆的交互意识，以利用这些互动来进行决策制定。这些交互感知规划器依赖于基于神经网络的预测模型来捕获车辆间的相互作用，旨在将这些预测与传统控制技术如模型预测控制相整合。然而，深度学习模型与传统控制范式的整合往往导致计算密集型的优化问题，依赖于启发式方法。本研究引入了一种原则性和高效的方法，将深度学习与约束优化相结合，采用知识蒸馏来训练更小、更高效的网络，从而减轻复杂性。我们证明了这些优化后的网络能够维持问题的...

    arXiv:2404.01746v1 Announce Type: cross  Abstract: Real-world driving involves intricate interactions among vehicles navigating through dense traffic scenarios. Recent research focuses on enhancing the interaction awareness of autonomous vehicles to leverage these interactions in decision-making. These interaction-aware planners rely on neural-network-based prediction models to capture inter-vehicle interactions, aiming to integrate these predictions with traditional control techniques such as Model Predictive Control. However, this integration of deep learning-based models with traditional control paradigms often results in computationally demanding optimization problems, relying on heuristic methods. This study introduces a principled and efficient method for combining deep learning with constrained optimization, employing knowledge distillation to train smaller and more efficient networks, thereby mitigating complexity. We demonstrate that these refined networks maintain the problem
    
[^39]: 发挥CLIP在视频精彩片段检测中的潜力

    Unleash the Potential of CLIP for Video Highlight Detection

    [https://arxiv.org/abs/2404.01745](https://arxiv.org/abs/2404.01745)

    使用Highlight-CLIP方法，在视频精彩片段检测任务中通过利用多模态模型的预训练知识和创新的显著性池化技术，取得了最先进的性能。

    

    多模态和大型语言模型（LLMs）已经彻底改变了开放世界知识的利用方式，在各种任务和应用中释放出了新的潜力。在这些领域中，视频领域显著受益于它们的能力。在本文中，我们提出了Highlight-CLIP（HL-CLIP），一种旨在通过利用多模态模型中预训练知识在视频精彩片段检测任务中表现卓越的方法。通过简单地微调多模态编码器，结合我们创新的显著性池化技术，我们在精彩片段检测任务中达到了最先进的性能，根据我们所知道的最佳成绩，此任务是QVHighlight Benchmark。

    arXiv:2404.01745v1 Announce Type: cross  Abstract: Multimodal and large language models (LLMs) have revolutionized the utilization of open-world knowledge, unlocking novel potentials across various tasks and applications. Among these domains, the video domain has notably benefited from their capabilities. In this paper, we present Highlight-CLIP (HL-CLIP), a method designed to excel in the video highlight detection task by leveraging the pre-trained knowledge embedded in multimodal models. By simply fine-tuning the multimodal encoder in combination with our innovative saliency pooling technique, we have achieved the state-of-the-art performance in the highlight detection task, the QVHighlight Benchmark, to the best of our knowledge.
    
[^40]: 通过两级反馈控制实现网络系统的入侵容忍

    Intrusion Tolerance for Networked Systems through Two-Level Feedback Control

    [https://arxiv.org/abs/2404.01741](https://arxiv.org/abs/2404.01741)

    该论文提出了一种名为TOLERANCE的新型控制架构，通过两级最优控制解决网络系统的入侵容忍问题，并设计了高效算法来改善服务可用性和降低操作成本。

    

    我们将服务复制品系统的入侵容忍问题制定为一个两级最优控制问题。在本地级别，节点控制器执行入侵恢复，在全局级别，系统控制器管理复制因子。本地和全局控制问题可以被制定为运筹学中的经典问题，即机器更换问题和库存补给问题。基于这一模式，我们设计了一种新颖的名为TOLERANCE的入侵容忍系统控制架构。我们证明了两个层面上的最优控制策略具有阈值结构，并设计了用于计算它们的高效算法。我们在一个仿真环境中实施和评估了TOLERANCE，其中运行了10种网络入侵。结果显示，与最先进的入侵容忍系统相比，TOLERANCE能够提高服务可用性并减少操作成本。

    arXiv:2404.01741v1 Announce Type: cross  Abstract: We formulate intrusion tolerance for a system with service replicas as a two-level optimal control problem. On the local level node controllers perform intrusion recovery, and on the global level a system controller manages the replication factor. The local and global control problems can be formulated as classical problems in operations research, namely, the machine replacement problem and the inventory replenishment problem. Based on this formulation, we design TOLERANCE, a novel control architecture for intrusion-tolerant systems. We prove that the optimal control strategies on both levels have threshold structure and design efficient algorithms for computing them. We implement and evaluate TOLERANCE in an emulation environment where we run 10 types of network intrusions. The results show that TOLERANCE can improve service availability and reduce operational cost compared with state-of-the-art intrusion-tolerant systems.
    
[^41]: 通过双模态语义相似性进行弱监督音频分离

    Weakly-supervised Audio Separation via Bi-modal Semantic Similarity

    [https://arxiv.org/abs/2404.01740](https://arxiv.org/abs/2404.01740)

    本文提出了通过双模态语义相似性进行弱监督音频分离的框架，可在没有单独源音频数据的情况下通过语言模态中的信息实现音频信号的分离。

    

    多源音频混合物中的条件声音分离，在训练过程中没有单源音频数据的情况下是一个长期存在的挑战。现有的基于混合与分离的方法在训练过程中由于缺乏对单源分离情况的监督信号而在多源训练混合物中表现出显著的性能下降。然而，在语言条件音频分离的情况下，我们可以访问训练数据中每个音频混合物的相应文本描述，这可以被视为语言模态中音频样本的（粗略）表示。因此，在本文中，我们提出了一个通用的双模态分离框架，该框架可以增强现有的无监督框架，以使用在条件模态（即语言）中易于分离的对应信号来分离目标模态（即音频）中的单源信号，而无需访问单源信号。进行训练。

    arXiv:2404.01740v1 Announce Type: cross  Abstract: Conditional sound separation in multi-source audio mixtures without having access to single source sound data during training is a long standing challenge. Existing mix-and-separate based methods suffer from significant performance drop with multi-source training mixtures due to the lack of supervision signal for single source separation cases during training. However, in the case of language-conditional audio separation, we do have access to corresponding text descriptions for each audio mixture in our training data, which can be seen as (rough) representations of the audio samples in the language modality. To this end, in this paper, we propose a generic bi-modal separation framework which can enhance the existing unsupervised frameworks to separate single-source signals in a target modality (i.e., audio) using the easily separable corresponding signals in the conditioning modality (i.e., language), without having access to single-so
    
[^42]: 有效的内部语言模型训练和融合对于分解转录模型

    Effective internal language model training and fusion for factorized transducer model

    [https://arxiv.org/abs/2404.01716](https://arxiv.org/abs/2404.01716)

    提出了一种对于分解转录模型的有效ILM训练和解码策略，能够显著改善与标准解码方法的性能，并在LibriSpeech数据集上取得了17%的相对改善。

    

    神经转录器的内部语言模型（ILM）已被广泛研究。在大多数先前的工作中，它主要用于估计ILM分数，并在推理过程中随后被减去，以促进与外部语言模型更好的集成。最近，已提出了各种分解转录模型，明确采用独立的内部语言模型用于非空白令牌预测。然而，即使采用了分解转录模型，与浅层融合相比，改进仍然有限。在本文中，我们提出了一种新颖的ILM训练和解码策略，用于分解转录模型，有效地结合了空白、声学和ILM分数。我们的实验表明，在LibriSpeech数据集上利用经过良好训练的ILM和所提出的解码策略时，相对于标准解码方法，有17%的相对改善。此外，与强RNN-T ba相比

    arXiv:2404.01716v1 Announce Type: cross  Abstract: The internal language model (ILM) of the neural transducer has been widely studied. In most prior work, it is mainly used for estimating the ILM score and is subsequently subtracted during inference to facilitate improved integration with external language models. Recently, various of factorized transducer models have been proposed, which explicitly embrace a standalone internal language model for non-blank token prediction. However, even with the adoption of factorized transducer models, limited improvement has been observed compared to shallow fusion. In this paper, we propose a novel ILM training and decoding strategy for factorized transducer models, which effectively combines the blank, acoustic and ILM scores. Our experiments show a 17% relative improvement over the standard decoding method when utilizing a well-trained ILM and the proposed decoding strategy on LibriSpeech datasets. Furthermore, when compared to a strong RNN-T ba
    
[^43]: 基于共轭梯度的自适应矩估计优化算法用于深度学习

    Conjugate-Gradient-like Based Adaptive Moment Estimation Optimization Algorithm for Deep Learning

    [https://arxiv.org/abs/2404.01714](https://arxiv.org/abs/2404.01714)

    提出一种基于共轭梯度样式的新优化算法CG-like-Adam，用于深度学习，并在收敛分析和数值实验中展示了其优越性

    

    训练深度神经网络是一项具有挑战性的任务。为加快培训速度并增强深度神经网络的性能，我们将传统的共轭梯度修正为共轭梯度样式，并将其并入通用Adam中，因此提出了一种名为CG-like-Adam的新优化算法用于深度学习。具体而言，通用Adam的一阶和二阶矩估计均由共轭梯度样式替换。收敛分析处理了一阶矩估计的指数移动平均系数为常数且一阶矩估计无偏的情况。数值实验显示了基于CIFAR10/100数据集的所提算法的优越性。

    arXiv:2404.01714v1 Announce Type: cross  Abstract: Training deep neural networks is a challenging task. In order to speed up training and enhance the performance of deep neural networks, we rectify the vanilla conjugate gradient as conjugate-gradient-like and incorporate it into the generic Adam, and thus propose a new optimization algorithm named CG-like-Adam for deep learning. Specifically, both the first-order and the second-order moment estimation of generic Adam are replaced by the conjugate-gradient-like. Convergence analysis handles the cases where the exponential moving average coefficient of the first-order moment estimation is constant and the first-order moment estimation is unbiased. Numerical experiments show the superiority of the proposed algorithm based on the CIFAR10/100 dataset.
    
[^44]: 生成式人工智能用于沉浸式通信：通过6G探索感知互联网的下一个领域

    Generative AI for Immersive Communication: The Next Frontier in Internet-of-Senses Through 6G

    [https://arxiv.org/abs/2404.01713](https://arxiv.org/abs/2404.01713)

    本文探讨了生成式人工智能用于沉浸式通信中减少带宽消耗的实用价值。

    

    在过去的二十年中，物联网(IoT)已经是一个具有变革性的概念，当我们逼近2030年时，一个新的范式被称为感知互联网(IoS)正在兴起。与传统的虚拟现实（VR）不同，IoS旨在提供多感官体验，认识到在我们的现实世界中，我们的感知远不止于视觉和听觉；它涵盖了一系列感觉。本文探讨了推动沉浸式多感官媒体的现有技术，深入探讨它们的功能和潜在应用。这项探索包括传统沉浸式媒体流与一个提出的利用生成式人工智能增强语义交流的用例之间的比较分析。这项分析的重点是所提方案中带宽消耗减少了99.93%。通过这种比较，我们旨在强调该实用应用的价值。

    arXiv:2404.01713v1 Announce Type: cross  Abstract: Over the past two decades, the Internet-of-Things (IoT) has been a transformative concept, and as we approach 2030, a new paradigm known as the Internet of Senses (IoS) is emerging. Unlike conventional Virtual Reality (VR), IoS seeks to provide multi-sensory experiences, acknowledging that in our physical reality, our perception extends far beyond just sight and sound; it encompasses a range of senses. This article explores existing technologies driving immersive multi-sensory media, delving into their capabilities and potential applications. This exploration includes a comparative analysis between conventional immersive media streaming and a proposed use case that lever- ages semantic communication empowered by generative Artificial Intelligence (AI). The focal point of this analysis is the substantial reduction in bandwidth consumption by 99.93% in the proposed scheme. Through this comparison, we aim to underscore the practical appli
    
[^45]: 通过免Hessian重新整合个体数据统计实现高效在线遗忘

    Efficient Online Unlearning via Hessian-Free Recollection of Individual Data Statistics

    [https://arxiv.org/abs/2404.01712](https://arxiv.org/abs/2404.01712)

    通过提出的Hessian-free在线遗忘方法，实现了近乎瞬时的在线遗忘，仅需要进行矢量加法操作。

    

    机器遗忘旨在通过使模型能够选择性地忘记特定数据来维护数据所有者的被遗忘权利。最近的方法表明，一种数据遗忘的方法是通过预先计算和存储携带二阶信息的统计数据，以改进计算和内存效率。然而，它们依赖于苛刻的假设，而且计算/存储受到模型参数维度的诅咒，这使得难以应用到大多数深度神经网络中。在本工作中，我们提出了一种免Hessian在线遗忘方法。我们建议为每个数据点维护一个统计向量，通过重新训练和学习模型之间的差异的仿射随机递归逼近来计算。我们提出的算法实现了近乎瞬时的在线遗忘，因为它只需要进行矢量加法操作。基于重新收集遗忘数据统计的策略，

    arXiv:2404.01712v1 Announce Type: cross  Abstract: Machine unlearning strives to uphold the data owners' right to be forgotten by enabling models to selectively forget specific data. Recent methods suggest that one approach of data forgetting is by precomputing and storing statistics carrying second-order information to improve computational and memory efficiency. However, they rely on restrictive assumptions and the computation/storage suffer from the curse of model parameter dimensionality, making it challenging to apply to most deep neural networks. In this work, we propose a Hessian-free online unlearning method. We propose to maintain a statistical vector for each data point, computed through affine stochastic recursion approximation of the difference between retrained and learned models. Our proposed algorithm achieves near-instantaneous online unlearning as it only requires a vector addition operation. Based on the strategy that recollecting statistics for forgetting data, the p
    
[^46]: Upsample Guidance: 不经过训练即可扩展扩散模型

    Upsample Guidance: Scale Up Diffusion Models without Training

    [https://arxiv.org/abs/2404.01709](https://arxiv.org/abs/2404.01709)

    提出了一种称为上采样指导的技术，能够适应预训练的扩散模型，实现更高分辨率图像的生成，无需额外训练或依赖外部模型。

    

    扩散模型在包括图像、视频和音频等各种生成任务中已经表现出卓越性能。然而，它们在直接生成高分辨率样本方面遇到困难。先前提出的解决方案包括修改架构、进一步训练或将采样过程划分为多个阶段。这些方法的局限性在于无法直接使用预训练模型，需要额外工作。在本文中，我们引入了上采样指导，这是一种技术，通过在采样过程中仅添加一个项，使预训练扩散模型（例如$512^2$）能够生成更高分辨率的图像（例如$1536^2$）。值得注意的是，这种技术不需要任何额外训练或依赖外部模型。我们展示了上采样指导可应用于各种模型，如像素空间、潜在空间和视频扩散模型。

    arXiv:2404.01709v1 Announce Type: cross  Abstract: Diffusion models have demonstrated superior performance across various generative tasks including images, videos, and audio. However, they encounter difficulties in directly generating high-resolution samples. Previously proposed solutions to this issue involve modifying the architecture, further training, or partitioning the sampling process into multiple stages. These methods have the limitation of not being able to directly utilize pre-trained models as-is, requiring additional work. In this paper, we introduce upsample guidance, a technique that adapts pretrained diffusion model (e.g., $512^2$) to generate higher-resolution images (e.g., $1536^2$) by adding only a single term in the sampling process. Remarkably, this technique does not necessitate any additional training or relying on external models. We demonstrate that upsample guidance can be applied to various models, such as pixel-space, latent space, and video diffusion model
    
[^47]: 通过核大小缩放提高嵌入式脉冲神经网络准确性的方法学

    A Methodology for Improving Accuracy of Embedded Spiking Neural Networks through Kernel Size Scaling

    [https://arxiv.org/abs/2404.01685](https://arxiv.org/abs/2404.01685)

    通过核大小缩放提高嵌入式脉冲神经网络准确性的方法学在实验中表现出更高的准确性。

    

    脉冲神经网络（SNNs）由于其稀疏的基于脉冲的操作而能为基于机器学习的应用提供超低功耗/能耗。目前，大多数SNN架构需要更大的模型大小才能实现更高的准确性，这对资源受限的嵌入式应用不太适合。因此，迫切需要开发能够以可接受的内存占用实现高准确性的SNNs。为此，我们提出了一种通过核大小缩放提高SNNs准确性的新方法学。其关键步骤包括调查不同核大小对准确性的影响，设计新的核大小集合，基于选定的核大小生成SNN架构，并分析SNN模型选择的准确性-内存折衷。实验结果表明，我们的方法学在准确性方面优于最先进的方法（对于CIFAR10有93.24%的准确度）

    arXiv:2404.01685v1 Announce Type: cross  Abstract: Spiking Neural Networks (SNNs) can offer ultra low power/ energy consumption for machine learning-based applications due to their sparse spike-based operations. Currently, most of the SNN architectures need a significantly larger model size to achieve higher accuracy, which is not suitable for resource-constrained embedded applications. Therefore, developing SNNs that can achieve high accuracy with acceptable memory footprint is highly needed. Toward this, we propose a novel methodology that improves the accuracy of SNNs through kernel size scaling. Its key steps include investigating the impact of different kernel sizes on the accuracy, devising new sets of kernel sizes, generating SNN architectures based on the selected kernel sizes, and analyzing the accuracy-memory trade-offs for SNN model selection. The experimental results show that our methodology achieves higher accuracy than state-of-the-art (93.24% accuracy for CIFAR10 and 70
    
[^48]: 通过归结反驳实现自然语言通用且可靠的逻辑推理

    Towards Generalizable and Faithful Logic Reasoning over Natural Language via Resolution Refutation

    [https://arxiv.org/abs/2404.01677](https://arxiv.org/abs/2404.01677)

    通过引入归结反驳范式，提出了一个名为GFaiR的框架，旨在解决大型语言模型在进行自然语言形式逻辑理论一阶逻辑推理时的困难，并通过证明插入解决方案改进了系统的完整性

    

    大型语言模型在各种自然语言推理任务中取得了显著的性能，但它们在对自然语言表达的形式逻辑理论进行一阶逻辑推理方面仍然有困难。为了解决这一问题，我们提出了一个名为“可泛化且可靠推理器（GFaiR）”的新框架，引入了归结反驳范式。实验结果表明，我们的系统...

    arXiv:2404.01677v1 Announce Type: new  Abstract: Large language models (LLMs) have achieved significant performance in various natural language reasoning tasks. However, they still struggle with performing first-order logic reasoning over formal logical theories expressed in natural language. This is because the previous LLMs-based reasoning systems have the theoretical incompleteness issue. As a result, it can only address a limited set of simple reasoning problems, which significantly decreases their generalization ability. To address this issue, we propose a novel framework, named Generalizable and Faithful Reasoner (GFaiR), which introduces the paradigm of resolution refutation. Resolution refutation has the capability to solve all first-order logic reasoning problems by extending reasoning rules and employing the principle of proof by contradiction, so our system's completeness can be improved by introducing resolution refutation. Experimental results demonstrate that our system o
    
[^49]: 发布针对日语的预训练模型

    Release of Pre-Trained Models for the Japanese Language

    [https://arxiv.org/abs/2404.01657](https://arxiv.org/abs/2404.01657)

    发布日语预训练模型以缩小非英语社区中的AI访问差距，促进AI民主化。

    

    arXiv:2404.01657v1 公告类型:交叉摘要: AI民主化旨在创造一个普通人可以利用AI技术的世界。为了实现这一目标，许多研究机构已经试图让他们的结果对公众可及。特别是，基于大规模数据训练的大型预训练模型展现了前所未有的潜力，它们的发布产生了重大影响。然而，大多数发布的模型专门针对英语，因此，在非英语社区中，AI民主化存在明显滞后。为了缩小AI访问的差距，我们发布了用日语预先训练的生成式预训练转换器（GPT）、对比语言和图像预训练（CLIP）、稳定扩散和隐藏单元双向编码器表示来自变压器（HuBERT）。通过提供这些模型，用户可以自由地与符合日本文化价值观的AI进行交互，并确保日本文化的身份，从而增强

    arXiv:2404.01657v1 Announce Type: cross  Abstract: AI democratization aims to create a world in which the average person can utilize AI techniques. To achieve this goal, numerous research institutes have attempted to make their results accessible to the public. In particular, large pre-trained models trained on large-scale data have shown unprecedented potential, and their release has had a significant impact. However, most of the released models specialize in the English language, and thus, AI democratization in non-English-speaking communities is lagging significantly. To reduce this gap in AI access, we released Generative Pre-trained Transformer (GPT), Contrastive Language and Image Pre-training (CLIP), Stable Diffusion, and Hidden-unit Bidirectional Encoder Representations from Transformers (HuBERT) pre-trained in Japanese. By providing these models, users can freely interface with AI that aligns with Japanese cultural values and ensures the identity of Japanese culture, thus enha
    
[^50]: AI WALKUP：一种用于量化帕金森氏病患者MDS-UPDRS的计算机视觉方法

    AI WALKUP: A Computer-Vision Approach to Quantifying MDS-UPDRS in Parkinson's Disease

    [https://arxiv.org/abs/2404.01654](https://arxiv.org/abs/2404.01654)

    提出了一种使用计算机视觉方法来量化帕金森氏病患者MDS-UPDRS的新方法，通过捕捉人体姿势图像并进行特征提取，实现快速与简便的病情评估。

    

    帕金森氏病（PD）是第二常见的神经退行性疾病。现有的PD评估方法通常采用运动障碍协会-统一帕金森病评分量表（MDS-UPDRS）来评估各种类型的运动症状严重程度和疾病进展。然而，手动评估存在主观性高、缺乏一致性、手动沟通成本高和效率低等问题。我们希望使用基于计算机视觉的解决方案，通过摄像头捕捉人体姿势图像，利用算法重建并进行运动分析，并通过特征工程提取运动量特征。提出的方法可以部署在不同的智能手机上，通过我们的应用程序，可以快速轻松地进行视频录制和人工智能分析。

    arXiv:2404.01654v1 Announce Type: cross  Abstract: Parkinson's Disease (PD) is the second most common neurodegenerative disorder. The existing assessment method for PD is usually the Movement Disorder Society - Unified Parkinson's Disease Rating Scale (MDS-UPDRS) to assess the severity of various types of motor symptoms and disease progression. However, manual assessment suffers from high subjectivity, lack of consistency, and high cost and low efficiency of manual communication. We want to use a computer vision based solution to capture human pose images based on a camera, reconstruct and perform motion analysis using algorithms, and extract the features of the amount of motion through feature engineering. The proposed approach can be deployed on different smartphones, and the video recording and artificial intelligence analysis can be done quickly and easily through our APP.
    
[^51]: 通过缓解上下文记忆实现开放域问答中更好的泛化

    Towards Better Generalization in Open-Domain Question Answering by Mitigating Context Memorization

    [https://arxiv.org/abs/2404.01652](https://arxiv.org/abs/2404.01652)

    本文研究了在开放域问答中泛化性能的问题，发现挑战在于阅读器过度依赖记忆外部语料库的知识，限制了模型的泛化能力。

    

    开放域问答（OpenQA）旨在利用外部大规模知识语料库回答事实问题。然而，现实世界中的知识并非静态的；它不断更新和演变。这种知识的动态特性为这些模型带来了重要挑战，因为训练的模型需要不断适应最新信息，以确保答案保持准确。此外，目前尚不清楚开放域问答模型能够多好地转移到完全新的知识领域。本文研究了一个基于检索增强的QA模型在两种具体情景下的泛化性能：1）适应相同知识语料库的更新版本；2）转换到完全不同的知识领域。我们发现，开放域问答模型的泛化挑战源自阅读器过度依赖从外部语料库中记忆知识，从而阻碍了模型的泛化能力。

    arXiv:2404.01652v1 Announce Type: cross  Abstract: Open-domain Question Answering (OpenQA) aims at answering factual questions with an external large-scale knowledge corpus. However, real-world knowledge is not static; it updates and evolves continually. Such a dynamic characteristic of knowledge poses a vital challenge for these models, as the trained models need to constantly adapt to the latest information to make sure that the answers remain accurate. In addition, it is still unclear how well an OpenQA model can transfer to completely new knowledge domains. In this paper, we investigate the generalization performance of a retrieval-augmented QA model in two specific scenarios: 1) adapting to updated versions of the same knowledge corpus; 2) switching to completely different knowledge domains. We observe that the generalization challenges of OpenQA models stem from the reader's over-reliance on memorizing the knowledge from the external corpus, which hinders the model from generaliz
    
[^52]: 对COVID-19检测的空间分割特征学习进行更细致的研究

    A Closer Look at Spatial-Slice Features Learning for COVID-19 Detection

    [https://arxiv.org/abs/2404.01643](https://arxiv.org/abs/2404.01643)

    为解决CT扫描中存在的变异性和OOD切片挑战，提出了一种增强型的空间分割特征学习框架，通过滤除OOD数据和减少冗余来选择关键的空间切片进行分析，并引入了基于核密度的切片采样方法来提高稳定性和加快收敛速度

    

    传统的计算机断层扫描（CT）成像识别面临两个重要挑战：（1）每个CT扫描的分辨率和大小经常存在相当大的变异性，需要对输入尺寸和模型的适应性有严格的要求。 （2）CT扫描包含大量的超出分布范围（OOD）切片。关键特性可能仅存在于整个CT扫描的特定空间区域和切片中。我们如何有效地找出这些区域的位置？为了解决这个问题，我们引入了一种针对CT扫描的增强型空间分割特征学习（SSFL ++）框架。它旨在从整个CT扫描中滤除OOD数据，通过完全减少70％的冗余来选择关键的空间切片进行分析。同时，我们提出了一种基于核密度的切片采样（KDS）方法，以提高训练和推断阶段的稳定性，从而加快收敛速度。

    arXiv:2404.01643v1 Announce Type: cross  Abstract: Conventional Computed Tomography (CT) imaging recognition faces two significant challenges: (1) There is often considerable variability in the resolution and size of each CT scan, necessitating strict requirements for the input size and adaptability of models. (2) CT-scan contains large number of out-of-distribution (OOD) slices. The crucial features may only be present in specific spatial regions and slices of the entire CT scan. How can we effectively figure out where these are located? To deal with this, we introduce an enhanced Spatial-Slice Feature Learning (SSFL++) framework specifically designed for CT scan. It aim to filter out a OOD data within whole CT scan, enabling our to select crucial spatial-slice for analysis by reducing 70% redundancy totally. Meanwhile, we proposed Kernel-Density-based slice Sampling (KDS) method to improve the stability when training and inference stage, therefore speeding up the rate of convergence 
    
[^53]: 通过强化学习学习控制摄像机曝光

    Learning to Control Camera Exposure via Reinforcement Learning

    [https://arxiv.org/abs/2404.01636](https://arxiv.org/abs/2404.01636)

    提出了一种通过深度强化学习快速控制摄像机曝光的新框架，具有简化训练场地、奖励设计和曝光调整能力逐步改善等四大创新贡献

    

    调整摄像机曝光是确保计算机视觉应用功能的第一步。传统的摄像机曝光控制方法需要多次收敛和耗时的流程，使其不适用于动态照明条件。本文提出了一种利用深度强化学习快速控制摄像机曝光的新框架。该框架包括四个贡献：1）简化训练场地来模拟现实世界的多样化和动态照明变化，2）闪烁和图像属性感知奖励设计，以及轻量级状态设计以进行实时处理，3）静态到动态照明课程，逐步改善代理的曝光调整能力

    arXiv:2404.01636v1 Announce Type: cross  Abstract: Adjusting camera exposure in arbitrary lighting conditions is the first step to ensure the functionality of computer vision applications. Poorly adjusted camera exposure often leads to critical failure and performance degradation. Traditional camera exposure control methods require multiple convergence steps and time-consuming processes, making them unsuitable for dynamic lighting conditions. In this paper, we propose a new camera exposure control framework that rapidly controls camera exposure while performing real-time processing by exploiting deep reinforcement learning. The proposed framework consists of four contributions: 1) a simplified training ground to simulate real-world's diverse and dynamic lighting changes, 2) flickering and image attribute-aware reward design, along with lightweight state design for real-time processing, 3) a static-to-dynamic lighting curriculum to gradually improve the agent's exposure-adjusting capabi
    
[^54]: 学习等角表示进行在线连续学习

    Learning Equi-angular Representations for Online Continual Learning

    [https://arxiv.org/abs/2404.01628](https://arxiv.org/abs/2404.01628)

    使用神经坍缩现象引入神经坍缩来形成表示空间中的等角紧框架结构，通过提出预备数据训练和残差修正，使得单周期学习的连续学习模型能更好地适应流数据，这种方法在在线连续学习中取得了明显的优势。

    

    在线连续学习存在欠拟合解决方案的问题，因为由于不及时的模型更新培训不足（例如，单周期训练）。为了解决这一挑战，我们提出了一种有效的在线连续学习方法，利用神经坍缩现象。具体地，我们诱导神经坍缩形成表示空间中的单纯等角紧框架（ETF）结构，以便通过在表示空间中提出预备数据训练和残差修正来更好地使经过单周期学习的持续学习模型适应流媒体数据。通过使用CIFAR-10/100、TinyImageNet、ImageNet-200和ImageNet-1K进行大量实证验证，我们展示了我们提出的方法在各种在线连续学习场景（如不相交和高斯调度连续（即无边界）数据设置）中均较领先方法表现出显著优势。

    arXiv:2404.01628v1 Announce Type: cross  Abstract: Online continual learning suffers from an underfitted solution due to insufficient training for prompt model update (e.g., single-epoch training). To address the challenge, we propose an efficient online continual learning method using the neural collapse phenomenon. In particular, we induce neural collapse to form a simplex equiangular tight frame (ETF) structure in the representation space so that the continuously learned model with a single epoch can better fit to the streamed data by proposing preparatory data training and residual correction in the representation space. With an extensive set of empirical validations using CIFAR-10/100, TinyImageNet, ImageNet-200, and ImageNet-1K, we show that our proposed method outperforms state-of-the-art methods by a noticeable margin in various online continual learning scenarios such as disjoint and Gaussian scheduled continuous (i.e., boundary-free) data setups.
    
[^55]: Gen4DS：生成AI时代的数据叙事研讨会

    Gen4DS: Workshop on Data Storytelling in an Era of Generative AI

    [https://arxiv.org/abs/2404.01622](https://arxiv.org/abs/2404.01622)

    论文讨论了数据叙事在生成AI时代的重要性和挑战，并邀请学术界和工业界一起探讨生成AI对数据叙事的影响。

    

    叙事是一种古老而珍贵的人类能力，在数字时代得到了新生。在过去的十年里，学术界和工业界对数据叙事的认可和应用有了显著增长。最近，生成AI的快速发展为这一领域带来了新的机遇和挑战，引发了许多新问题。我们邀请大家参加我们的研讨会（Gen4DS），讨论生成AI如何促进数据叙事的创作？生成AI如何改变数据叙事者的工作流程？在叙事中加入AI的风险和隐患是什么？

    arXiv:2404.01622v1 Announce Type: cross  Abstract: Storytelling is an ancient and precious human ability that has been rejuvenated in the digital age. Over the last decade, there has been a notable surge in the recognition and application of data storytelling, both in academia and industry. Recently, the rapid development of generative AI has brought new opportunities and challenges to this field, sparking numerous new questions. These questions may not necessarily be quickly transformed into papers, but we believe it is necessary to promptly discuss them to help the community better clarify important issues and research agendas for the future. We thus invite you to join our workshop (Gen4DS) to discuss questions such as: How can generative AI facilitate the creation of data stories? How might generative AI alter the workflow of data storytellers? What are the pitfalls and risks of incorporating AI in storytelling? We have designed both paper presentations and interactive activities (i
    
[^56]: Voice EHR:引入多模式音频数据用于健康

    Voice EHR: Introducing Multimodal Audio Data for Health

    [https://arxiv.org/abs/2404.01620](https://arxiv.org/abs/2404.01620)

    本报告引入了一种通过引导问题使用移动应用程序捕获健康数据的新的音频电子健康记录（voice EHR），可能包含复杂的健康生物标志物，从而弥补了单一模态临床数据的典型限制。

    

    在音频数据上训练的大型AI模型可能具有快速分类患者的潜力，通过早期检测增强医疗决策，并可能通过早期检测改善结果。现有技术依赖于在高收入、英语国家使用昂贵记录设备的有限数据集，这种技术面临资源受限、高收入场所的部署挑战，音频数据可能具有深远影响。本报告介绍了一种新的数据类型和相应的收集系统，通过引导问题仅使用移动应用/网络应用程序捕获健康数据。该应用程序最终产生一个音频电子健康记录（voice EHR），它可能包含来自传统语音/呼吸特征、语音模式和具有语义意义的语言的复杂生物标志物，补偿单一模态临床数据的典型限制。本报告介绍了一个合作伙伴财团

    arXiv:2404.01620v1 Announce Type: cross  Abstract: Large AI models trained on audio data may have the potential to rapidly classify patients, enhancing medical decision-making and potentially improving outcomes through early detection. Existing technologies depend on limited datasets using expensive recording equipment in high-income, English-speaking countries. This challenges deployment in resource-constrained, high-volume settings where audio data may have a profound impact. This report introduces a novel data type and a corresponding collection system that captures health data through guided questions using only a mobile/web application. This application ultimately results in an audio electronic health record (voice EHR) which may contain complex biomarkers of health from conventional voice/respiratory features, speech patterns, and language with semantic meaning - compensating for the typical limitations of unimodal clinical datasets. This report introduces a consortium of partner
    
[^57]: 大语言模型在狼人游戏中的舵手？评估其观点引领作用

    Helmsman of the Masses? Evaluate the Opinion Leadership of Large Language Models in the Werewolf Game

    [https://arxiv.org/abs/2404.01602](https://arxiv.org/abs/2404.01602)

    本研究通过狼人游戏模拟平台评估了大语言模型的观点领导作用，并开发了两个新的评估指标。

    

    大语言模型（LLMs）在社交推理游戏中展现出令人难忘的战略行为。然而，LLM代理所展示的观点领导力的重要性被忽视了，而这对于多智能体和人工智能交互设置中的实际应用至关重要。在此研究中，我们利用狼人游戏作为模拟平台，评估LLMs的观点引领作用。该游戏中有警长角色，负责总结论据并推荐决策选项，因此可作为观点领袖的可信代理。我们开发了一个整合了警长角色的框架，并设计了两个基于观点领袖关键特征的新指标进行评估。第一个度量标准衡量观点领袖的可靠性，第二个评估...

    arXiv:2404.01602v1 Announce Type: cross  Abstract: Large language models (LLMs) have exhibited memorable strategic behaviors in social deductive games. However, the significance of opinion leadership exhibited by LLM-based agents has been overlooked, which is crucial for practical applications in multi-agent and human-AI interaction settings. Opinion leaders are individuals who have a noticeable impact on the beliefs and behaviors of others within a social group. In this work, we employ the Werewolf game as a simulation platform to assess the opinion leadership of LLMs. The game features the role of the Sheriff, tasked with summarizing arguments and recommending decision options, and therefore serves as a credible proxy for an opinion leader. We develop a framework integrating the Sheriff role and devise two novel metrics for evaluation based on the critical characteristics of opinion leaders. The first metric measures the reliability of the opinion leader, and the second assesses the 
    
[^58]: 用于加速策略优化的极值寻找动作选择

    Extremum-Seeking Action Selection for Accelerating Policy Optimization

    [https://arxiv.org/abs/2404.01598](https://arxiv.org/abs/2404.01598)

    提出了在无模型强化学习中改进动作选择的方法，通过引入极值寻找控制（ESC）进行自适应控制步骤，以加速策略优化。

    

    在连续空间上进行控制的强化学习通常使用高熵的随机策略，如高斯分布，用于局部探索和估计策略梯度以优化性能。许多机器人控制问题涉及复杂不稳定的动力学，其中施加在可行控制流形之外的动作很快会导致不良发散。在这种情况下，大多数从环境动作空间中采样的样本生成的轨迹价值较低，几乎没有贡献于策略改进，导致学习缓慢或失败。我们提出在这种无模型RL设置中通过引入基于极值寻找控制（ESC）的附加自适应控制步骤来改善动作选择。对于从随机策略采样的每个动作，我们应用正弦扰动并查询估计的Q值作为响应信号。根据ESC，我们动态改进采样的动作以使之更接近理想动作。

    arXiv:2404.01598v1 Announce Type: cross  Abstract: Reinforcement learning for control over continuous spaces typically uses high-entropy stochastic policies, such as Gaussian distributions, for local exploration and estimating policy gradient to optimize performance. Many robotic control problems deal with complex unstable dynamics, where applying actions that are off the feasible control manifolds can quickly lead to undesirable divergence. In such cases, most samples taken from the ambient action space generate low-value trajectories that hardly contribute to policy improvement, resulting in slow or failed learning. We propose to improve action selection in this model-free RL setting by introducing additional adaptive control steps based on Extremum-Seeking Control (ESC). On each action sampled from stochastic policies, we apply sinusoidal perturbations and query for estimated Q-values as the response signal. Based on ESC, we then dynamically improve the sampled actions to be closer 
    
[^59]: PhysORD：一种神经符号方法用于越野驾驶中注入物理学的运动预测

    PhysORD: A Neuro-Symbolic Approach for Physics-infused Motion Prediction in Off-road Driving

    [https://arxiv.org/abs/2404.01596](https://arxiv.org/abs/2404.01596)

    PhysORD是一种神经符号方法，将物理定律融入神经模型中，显著提高了在越野驾驶中的运动预测泛化能力。

    

    运动预测对于自主越野驾驶至关重要，但与在道路上驾驶相比，它面临着更多挑战，主要是由于车辆与地形之间复杂的相互作用。传统的基于物理的方法在准确建模动态系统和外部干扰方面遇到困难。相反，基于数据驱动的神经网络需要大量数据集，并且难以明确捕捉基本的物理定律，这很容易导致泛化能力差。通过融合这两种方法的优势，神经符号方法提出了一个有前途的方向。这些方法将物理定律嵌入神经模型中，可能显著提高泛化能力。然而，以往的研究都没有在现实世界的越野驾驶环境中进行评估。为了弥合这一差距，我们提出 PhysORD，这是一种神经符号方法，集成了守恒定律，即欧拉-拉格朗日方程。

    arXiv:2404.01596v1 Announce Type: cross  Abstract: Motion prediction is critical for autonomous off-road driving, however, it presents significantly more challenges than on-road driving because of the complex interaction between the vehicle and the terrain. Traditional physics-based approaches encounter difficulties in accurately modeling dynamic systems and external disturbance. In contrast, data-driven neural networks require extensive datasets and struggle with explicitly capturing the fundamental physical laws, which can easily lead to poor generalization. By merging the advantages of both methods, neuro-symbolic approaches present a promising direction. These methods embed physical laws into neural models, potentially significantly improving generalization capabilities. However, no prior works were evaluated in real-world settings for off-road driving. To bridge this gap, we present PhysORD, a neural-symbolic approach integrating the conservation law, i.e., the Euler-Lagrange equa
    
[^60]: 使用开源临床大型语言模型对癌症分期进行分类

    Classifying Cancer Stage with Open-Source Clinical Large Language Models

    [https://arxiv.org/abs/2404.01589](https://arxiv.org/abs/2404.01589)

    本研究展示了在没有任何标记的训练数据的情况下，开源的临床大型语言模型能够从真实病理报告中提取病理性肿瘤-淋巴结-转移（pTNM）分期信息

    

    癌症分期分类对于为肿瘤学患者制定治疗和护理管理计划至关重要。分期信息通常以非结构化形式包含在临床、病理学、放射学和其他自由文本报告中，需要大量工作来解析和获取。为了促进这些信息的提取，先前的自然语言处理方法依赖于标记的训练数据集，这些数据集准备起来需要大量的人力。本研究展示了在没有任何标记的训练数据的情况下，开源的临床大型语言模型（LLMs）可以从真实病理报告中提取病理性肿瘤-淋巴结-转移（pTNM）分期信息。我们的实验比较了LLMs和使用标记数据进行微调的基于BERT的模型。我们的发现表明，虽然LLMs在肿瘤（T）分类方面仍然表现不佳，但通过适当采用提示策略，它们可以实现

    arXiv:2404.01589v1 Announce Type: cross  Abstract: Cancer stage classification is important for making treatment and care management plans for oncology patients. Information on staging is often included in unstructured form in clinical, pathology, radiology and other free-text reports in the electronic health record system, requiring extensive work to parse and obtain. To facilitate the extraction of this information, previous NLP approaches rely on labeled training datasets, which are labor-intensive to prepare. In this study, we demonstrate that without any labeled training data, open-source clinical large language models (LLMs) can extract pathologic tumor-node-metastasis (pTNM) staging information from real-world pathology reports. Our experiments compare LLMs and a BERT-based model fine-tuned using the labeled data. Our findings suggest that while LLMs still exhibit subpar performance in Tumor (T) classification, with the appropriate adoption of prompting strategies, they can achi
    
[^61]: 基于幻觉多样性的文本摘要主动学习

    Hallucination Diversity-Aware Active Learning for Text Summarization

    [https://arxiv.org/abs/2404.01588](https://arxiv.org/abs/2404.01588)

    本文首次提出了一种基于幻觉多样性的主动学习框架，用于减轻大型语言模型（LLMs）在文本摘要中产生的幻觉，减少了昂贵的人类注释需求。

    

    大型语言模型（LLMs）已经表现出生成幻觉输出的倾向，即在事实上不正确或不支持的文本。现有的减轻幻觉的方法通常需要昂贵的人类注释来识别和纠正LLMs输出中的幻觉。此外，大多数这些方法专注于特定类型的幻觉，例如实体或标记错误，这限制了它们在解决LLMs输出中展示的各种类型的幻觉方面的有效性。据我们所知，本文提出了第一个旨在减轻LLMs幻觉的主动学习框架，降低了对幻觉所需的昂贵人类注释。通过在文本摘要中衡量语义框架、议论和内容可验证性错误中的细粒度幻觉，我们提出了 HAllucination Diversity-Aware Sampling（HADAS）来选择多样化的幻觉，以供LLM微调的主动学习注释。

    arXiv:2404.01588v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have shown propensity to generate hallucinated outputs, i.e., texts that are factually incorrect or unsupported. Existing methods for alleviating hallucinations typically require costly human annotations to identify and correct hallucinations in LLM outputs. Moreover, most of these methods focus on a specific type of hallucination, e.g., entity or token errors, which limits their effectiveness in addressing various types of hallucinations exhibited in LLM outputs. To our best knowledge, in this paper we propose the first active learning framework to alleviate LLM hallucinations, reducing costly human annotations of hallucination needed. By measuring fine-grained hallucinations from errors in semantic frame, discourse and content verifiability in text summarization, we propose HAllucination Diversity-Aware Sampling (HADAS) to select diverse hallucinations for annotations in active learning for LLM finetuning
    
[^62]: 基于BERT增强的作业抄袭检测系统

    BERT-Enhanced Retrieval Tool for Homework Plagiarism Detection System

    [https://arxiv.org/abs/2404.01582](https://arxiv.org/abs/2404.01582)

    本文提出了一种基于GPT-3.5的抄袭文本数据生成方法和一种基于Faiss和BERT的高效高准确性的抄袭识别方法，填补了高水平抄袭检测研究数据集缺失的空白，实验证明该模型在多个指标上表现优异

    

    文本抄袭检测任务是一项常见的自然语言处理任务，旨在检测给定文本是否包含从其他文本中抄袭或复制的内容。在现有研究中，由于缺乏高质量的数据集，检测高水平的抄袭仍然是一个挑战。本文提出了一种基于GPT-3.5的抄袭文本数据生成方法，产生了32,927对文本抄袭检测数据集，涵盖了各种抄袭方法，填补了这一研究领域的空白。同时，我们提出了一种基于Faiss和BERT的高效高准确性的抄袭识别方法。我们的实验证明，这种模型在准确率、精确率、召回率和F1分数等多个指标上的表现优于其他模型，分别达到了98.86％、98.90％、98.86％和0.9888。最后，我们还提供了一个用户友好的演示平台，允许用户上传文本。

    arXiv:2404.01582v1 Announce Type: cross  Abstract: Text plagiarism detection task is a common natural language processing task that aims to detect whether a given text contains plagiarism or copying from other texts. In existing research, detection of high level plagiarism is still a challenge due to the lack of high quality datasets. In this paper, we propose a plagiarized text data generation method based on GPT-3.5, which produces 32,927 pairs of text plagiarism detection datasets covering a wide range of plagiarism methods, bridging the gap in this part of research. Meanwhile, we propose a plagiarism identification method based on Faiss with BERT with high efficiency and high accuracy. Our experiments show that the performance of this model outperforms other models in several metrics, including 98.86\%, 98.90%, 98.86%, and 0.9888 for Accuracy, Precision, Recall, and F1 Score, respectively. At the end, we also provide a user-friendly demo platform that allows users to upload a text 
    
[^63]: 使用对比集评估大型语言模型：一种实验方法

    Evaluating Large Language Models Using Contrast Sets: An Experimental Approach

    [https://arxiv.org/abs/2404.01569](https://arxiv.org/abs/2404.01569)

    介绍了一种为斯坦福自然语言推断（SNLI）数据集生成对比集的创新技术，通过自动替换动词、副词和形容词为同义词来评估模型的性能是否基于真实的语言理解还是仅仅基于模式识别。

    

    在自然语言推断（NLI）领域，尤其是涉及多个输入文本分类的任务中，交叉熵损失度量被广泛应用作为错误度量的标准。然而，该度量在有效评估模型理解语句蕴涵能力方面存在不足。本研究引入了一种创新的技术，用于为斯坦福自然语言推断（SNLI）数据集生成对比集。我们的策略涉及自动将动词、副词和形容词替换为它们的同义词，以保留句子的原始含义。该方法旨在评估模型的性能是否基于真实的语言理解还是仅仅基于模式识别。我们使用ELECTRA-small模型进行了分析。该模型在传统的SNLI数据集上实现了89.9%的准确度，但在我们的对比集上显示出了72.5%的准确度，表明

    arXiv:2404.01569v1 Announce Type: cross  Abstract: In the domain of Natural Language Inference (NLI), especially in tasks involving the classification of multiple input texts, the Cross-Entropy Loss metric is widely employed as a standard for error measurement. However, this metric falls short in effectively evaluating a model's capacity to understand language entailments. In this study, we introduce an innovative technique for generating a contrast set for the Stanford Natural Language Inference (SNLI) dataset. Our strategy involves the automated substitution of verbs, adverbs, and adjectives with their synonyms to preserve the original meaning of sentences. This method aims to assess whether a model's performance is based on genuine language comprehension or simply on pattern recognition. We conducted our analysis using the ELECTRA-small model. The model achieved an accuracy of 89.9% on the conventional SNLI dataset but showed a reduced accuracy of 72.5% on our contrast set, indicati
    
[^64]: 利用大型语言模型实现自动用户故事生成与测试用例规范

    Automated User Story Generation with Test Case Specification Using Large Language Model

    [https://arxiv.org/abs/2404.01558](https://arxiv.org/abs/2404.01558)

    利用 GPT-4.0 开发了工具 "GeneUS"，实现了从需求文档自动生成用户故事的自动化，为后续集成到项目管理工具提供可能性。

    

    现代软件工程领域正在利用人工智能（AI），特别是大型语言模型（LLM），快速发展。研究人员已经开始自动化软件开发工作流的许多部分。需求工程（RE）是一个关键阶段，通过对提出的工作范围进行多次讨论并以不同形式记录来开始软件开发周期。RE 阶段以每个单元任务的用户故事清单结束，这些用户故事是通过讨论确定的，通常在项目管理工具（如 Jira、AzurDev 等）上创建和跟踪。在这项研究中，我们利用 GPT-4.0 开发了一个名为“GeneUS”的工具，用于根据需求文档自动创建用户故事，这是 RE 阶段的产物。输出以 JSON 格式提供，为后续集成到流行项目管理工具留下可能性。分析需求文档占据着重要位置

    arXiv:2404.01558v1 Announce Type: cross  Abstract: Modern Software Engineering era is moving fast with the assistance of artificial intelligence (AI), especially Large Language Models (LLM). Researchers have already started automating many parts of the software development workflow. Requirements Engineering (RE) is a crucial phase that begins the software development cycle through multiple discussions on a proposed scope of work documented in different forms. RE phase ends with a list of user-stories for each unit task identified through discussions and usually these are created and tracked on a project management tool such as Jira, AzurDev etc. In this research we developed a tool "GeneUS" using GPT-4.0 to automatically create user stories from requirements document which is the outcome of the RE phase. The output is provided in JSON format leaving the possibilities open for downstream integration to the popular project management tools. Analyzing requirements documents takes signific
    
[^65]: 分布式自主群体形成动态网络桥接

    Distributed Autonomous Swarm Formation for Dynamic Network Bridging

    [https://arxiv.org/abs/2404.01557](https://arxiv.org/abs/2404.01557)

    提出了一种用于动态网络桥接的新颖分布式部分可观察马尔可夫决策过程（Dec-POMDP）方法，以及基于图卷积强化学习（DGN）的多智能体强化学习（MARL）方法。

    

    有效的机器人系统操作和无缝协作是下一代技术和应用的基本组成部分。在诸如灾难响应之类的情景中，群体操作需要协调的行为和移动控制以分布式方式处理，代理之间的通信以及底层网络质量对其行动的质量产生重大影响。本文针对动态网络桥接问题提出了一种新颖的分布式部分可观察马尔可夫决策过程（Dec-POMDP）方法，其中一群代理协作形成两个远距移动目标之间的连接。此外，我们提出了一种基于图卷积强化学习（DGN）的多智能体强化学习（MARL）方法，该方法自然适用于任务的网络化、分布式性质。所提出的方法在模拟环境中进行了评估，并与一个基于强化学习的中心化方法进行了比较。

    arXiv:2404.01557v1 Announce Type: cross  Abstract: Effective operation and seamless cooperation of robotic systems are a fundamental component of next-generation technologies and applications. In contexts such as disaster response, swarm operations require coordinated behavior and mobility control to be handled in a distributed manner, with the quality of the agents' actions heavily relying on the communication between them and the underlying network. In this paper, we formulate the problem of dynamic network bridging in a novel Decentralized Partially Observable Markov Decision Process (Dec-POMDP), where a swarm of agents cooperates to form a link between two distant moving targets. Furthermore, we propose a Multi-Agent Reinforcement Learning (MARL) approach for the problem based on Graph Convolutional Reinforcement Learning (DGN) which naturally applies to the networked, distributed nature of the task. The proposed method is evaluated in a simulated environment and compared to a cent
    
[^66]: 具有控制理论安全保证的动态网络桥接的多智能体强化学习

    Multi-Agent Reinforcement Learning with Control-Theoretic Safety Guarantees for Dynamic Network Bridging

    [https://arxiv.org/abs/2404.01551](https://arxiv.org/abs/2404.01551)

    将多智能体强化学习与控制理论相结合，提出了一种新的设定点更新算法，以确保安全条件并实现良好的任务目标性能。

    

    在安全关键环境下解决复杂的合作任务对多智能体系统提出了重大挑战，尤其在部分可观测条件下。本文引入了一种混合方法，将多智能体强化学习与控制理论方法相结合，以确保安全和高效的分布式策略。我们的贡献包括一种新颖的设定点更新算法，动态调整智能体位置，以保持安全条件而不影响任务目标。通过实验验证，我们证明相比传统的多智能体强化学习策略，我们取得了显著优势，实现了与零安全违规相比可比的任务性能。研究结果表明，将安全控制与学习方法相结合不仅增强了安全合规性，还实现了良好的任务目标性能。

    arXiv:2404.01551v1 Announce Type: cross  Abstract: Addressing complex cooperative tasks in safety-critical environments poses significant challenges for Multi-Agent Systems, especially under conditions of partial observability. This work introduces a hybrid approach that integrates Multi-Agent Reinforcement Learning with control-theoretic methods to ensure safe and efficient distributed strategies. Our contributions include a novel setpoint update algorithm that dynamically adjusts agents' positions to preserve safety conditions without compromising the mission's objectives. Through experimental validation, we demonstrate significant advantages over conventional MARL strategies, achieving comparable task performance with zero safety violations. Our findings indicate that integrating safe control with learning approaches not only enhances safety compliance but also achieves good performance in mission objectives.
    
[^67]: mChartQA：基于视觉-语言对齐和推理的多模态图表问答通用基准

    mChartQA: A universal benchmark for multimodal Chart Question Answer based on Vision-Language Alignment and Reasoning

    [https://arxiv.org/abs/2404.01548](https://arxiv.org/abs/2404.01548)

    本文提出了一种新颖的多模态图表问答模型，采用双阶段训练方法，通过整合视觉和语言处理解决多模态问答中复杂的颜色、结构和无文本图表挑战。

    

    在计算机视觉和自然语言处理领域，多模态图表问答，特别是涉及颜色、结构和无文本图表，带来了重大挑战。传统方法通常涉及直接多模态处理或表格到文本转换，然后进行语言模型分析，但在有效处理这些复杂场景方面存在局限性。本文介绍了一种新颖的多模态图表问答模型，专门设计来解决这些复杂任务。我们的模型整合了视觉和语言处理，克服了现有方法的限制。我们采用了双阶段训练方法：初始阶段专注于调整图像和文本表示，随后的阶段集中于优化模型在图表相关查询中的解释和分析能力。这种方法在多个公开基准上展现出优越的性能。

    arXiv:2404.01548v1 Announce Type: cross  Abstract: In the fields of computer vision and natural language processing, multimodal chart question-answering, especially involving color, structure, and textless charts, poses significant challenges. Traditional methods, which typically involve either direct multimodal processing or a table-to-text conversion followed by language model analysis, have limitations in effectively handling these complex scenarios. This paper introduces a novel multimodal chart question-answering model, specifically designed to address these intricate tasks. Our model integrates visual and linguistic processing, overcoming the constraints of existing methods. We adopt a dual-phase training approach: the initial phase focuses on aligning image and text representations, while the subsequent phase concentrates on optimizing the model's interpretative and analytical abilities in chart-related queries. This approach has demonstrated superior performance on multiple pub
    
[^68]: 放置锚点：在语言建模中给数字语义上的引导

    Laying Anchors: Semantically Priming Numerals in Language Modeling

    [https://arxiv.org/abs/2404.01536](https://arxiv.org/abs/2404.01536)

    通过生成受数字分布规律控制的锚点，我们引入了一种在语义上引导数字的策略，在广泛范围的数字任务上实现了数学基础表示的显著改进。

    

    现有大量预训练语言模型已成为自然语言处理管线中的事实标准，然而这些模型未能正确编码数字，限制了它们在需要数字理解的任务上的性能。我们引入了一种策略，通过在任何语料库中生成受数字分布规律控制的锚点来在语义上引导数字，从而实现这些数字标记的数学基础表示。我们通过对一系列数值任务进行评估，证明了我们提出的技术的优越性，对领域内（已见）和领域外（未见）的数字都适用。此外，我们将实证评估扩展到从1到10亿的数字范围，比以往相同类型研究的范围广得多，展示了我们学得的嵌入向数学上的显著改进。

    arXiv:2404.01536v1 Announce Type: cross  Abstract: Off-the-shelf pre-trained language models have become the de facto standard in NLP pipelines for a multitude of downstream tasks. However, the inability of these models to properly encode numerals limits their performance on tasks requiring numeric comprehension. We introduce strategies to semantically prime numerals in any corpus by generating anchors governed by the distribution of numerals in said corpus, thereby enabling mathematically grounded representations of these numeral tokens. We establish the superiority of our proposed techniques through evaluation on a range of numeracy tasks for both in-domain (seen) and out-domain (unseen) numerals. Further, we expand our empirical evaluations to numerals ranging from 1 to 10 billion, a significantly broader range compared to previous studies of the same nature, and we demonstrate significant improvements in the mathematical grounding of our learned embeddings.
    
[^69]: 分类符号学：知识整合的基础

    Categorical semiotics: Foundations for Knowledge Integration

    [https://arxiv.org/abs/2404.01526](https://arxiv.org/abs/2404.01526)

    本文扩展了代数规范方法，提出了一个全面的框架，用于定义和分析深度学习架构，采用类似Ehresmann素描的图形结构，在模糊集的宇宙中进行解释。

    

    从不同模型中提取的知识整合，无论是由领域专家描述还是由机器学习算法生成，历来面临着缺乏一个适当框架来指定和整合结构、学习过程、数据转换以及数据模型或规则的挑战。 在这项工作中，我们将代数规范方法扩展以解决这些挑战。在我们的工作中，我们致力于开发一个全面的框架，用于定义和分析深度学习架构。我们认为以往的努力并未能建立模型必须遵守的约束与其实际实现之间的明确联系。 我们的方法论采用了类似Ehresmann素描的图形结构，在模糊集的宇宙中进行解释。这种方法提供了一个统一的理论，优雅地包含了确定性和不确定性方面。

    arXiv:2404.01526v1 Announce Type: new  Abstract: The integration of knowledge extracted from diverse models, whether described by domain experts or generated by machine learning algorithms, has historically been challenged by the absence of a suitable framework for specifying and integrating structures, learning processes, data transformations, and data models or rules. In this work, we extend algebraic specification methods to address these challenges within such a framework.   In our work, we tackle the challenging task of developing a comprehensive framework for defining and analyzing deep learning architectures. We believe that previous efforts have fallen short by failing to establish a clear connection between the constraints a model must adhere to and its actual implementation.   Our methodology employs graphical structures that resemble Ehresmann's sketches, interpreted within a universe of fuzzy sets. This approach offers a unified theory that elegantly encompasses both determ
    
[^70]: 关于图像检索中的训练-测试类别重叠和检测

    On Train-Test Class Overlap and Detection for Image Retrieval

    [https://arxiv.org/abs/2404.01524](https://arxiv.org/abs/2404.01524)

    重新审视了谷歌地标v2的训练集，通过识别和移除类别重叠，引入了一种新的端到端单阶段流程Single-stage Detect-to-Retrieve（CiDeR），旨在检测对象并提取全局图像表示，在现有最先进方法上表现优异。

    

    有多重要，训练和评估集中不要有图像检索中的类别重叠？我们通过识别并移除谷歌地标v2清洁集中的类别重叠，来重新审视Revisited Oxford和Paris，最流行的评估集。通过比较原始和新的RGLDv2-clean在一系列最先进方法的基准上，我们的发现令人瞩目。不仅性能急剧下降，而且在方法之间不一致，改变了排名。当索引时集中关注对象或兴趣并忽略背景杂乱需要什么？我们需要分别训练对象检测器和表示吗？我们需要位置监督吗？我们介绍了一种称为Single-stage Detect-to-Retrieve（CiDeR）的端到端、单阶段流程，用于检测感兴趣的对象并提取全局图像表示。我们在现有测试基准上均表现优异。

    arXiv:2404.01524v1 Announce Type: cross  Abstract: How important is it for training and evaluation sets to not have class overlap in image retrieval? We revisit Google Landmarks v2 clean, the most popular training set, by identifying and removing class overlap with Revisited Oxford and Paris [34], the most popular evaluation set. By comparing the original and the new RGLDv2-clean on a benchmark of reproduced state-of-the-art methods, our findings are striking. Not only is there a dramatic drop in performance, but it is inconsistent across methods, changing the ranking.What does it take to focus on objects or interest and ignore background clutter when indexing? Do we need to train an object detector and the representation separately? Do we need location supervision? We introduce Single-stage Detect-to-Retrieve (CiDeR), an end-to-end, single-stage pipeline to detect objects of interest and extract a global image representation. We outperform previous state-of-the-art on both existing tr
    
[^71]: 图像网模型中的偏见能解释泛化吗？

    Can Biases in ImageNet Models Explain Generalization?

    [https://arxiv.org/abs/2404.01509](https://arxiv.org/abs/2404.01509)

    图像网模型的偏见是否能够解释模型的泛化问题，对此进行了大规模研究。

    

    深度学习方法面临的主要挑战之一是模型对来自训练分布长尾的稀有内部分布（ID）样本和训练分布之外（OOD）样本的强大泛化能力。对于图像分类，这体现在对扭曲图像的攻击、性能下降以及对概念（如草图）的泛化不足。目前对神经网络泛化的理解非常有限，但发现了一些区别模型与人类视觉的偏见，这些偏见可能导致这些限制。因此，已经尝试了多种不同成功程度的方法来减少这些训练中的偏见以改善泛化性能。我们在已建立的ResNet-50架构上进行大规模研究，在48个通过不同获取途径获得的ImageNet模型上进行了实验。

    arXiv:2404.01509v1 Announce Type: cross  Abstract: The robust generalization of models to rare, in-distribution (ID) samples drawn from the long tail of the training distribution and to out-of-training-distribution (OOD) samples is one of the major challenges of current deep learning methods. For image classification, this manifests in the existence of adversarial attacks, the performance drops on distorted images, and a lack of generalization to concepts such as sketches. The current understanding of generalization in neural networks is very limited, but some biases that differentiate models from human vision have been identified and might be causing these limitations. Consequently, several attempts with varying success have been made to reduce these biases during training to improve generalization. We take a step back and sanity-check these attempts. Fixing the architecture to the well-established ResNet-50, we perform a large-scale study on 48 ImageNet models obtained via different 
    
[^72]: 一些顺序很重要：在高质量规划中部分保留顺序

    Some Orders Are Important: Partially Preserving Orders in Top-Quality Planning

    [https://arxiv.org/abs/2404.01503](https://arxiv.org/abs/2404.01503)

    提出在规划中部分保留顺序的新方法，通过指定重要顺序的子集来在高质量和无序规划问题之间进行插值，并展示了利用部分顺序减少搜索修剪技术的好处

    

    生成多个计划的能力对于在现实应用中使用规划是至关重要的。高质量规划器生成一组顶级成本计划，允许灵活确定等效计划。论文提出了在计划中行动顺序方面，文献只考虑两个极端 -- 要么所有顺序重要，使得每个计划都是唯一的，要么所有顺序都不重要，将只在行动顺序上不同的两个计划视为等效。为了允许在选择重要顺序时灵活性，我们提出指定一子集行动，其中顺序重要，插值于高质量和无序高质量规划问题之间。我们探讨了如何调整部分顺序减少搜索修剪技术以解决这一新的计算问题，并提出了实验评估，展示了在这种情况下利用这些技术的好处。

    arXiv:2404.01503v1 Announce Type: new  Abstract: The ability to generate multiple plans is central to using planning in real-life applications. Top-quality planners generate sets of such top-cost plans, allowing flexibility in determining equivalent ones. In terms of the order between actions in a plan, the literature only considers two extremes -- either all orders are important, making each plan unique, or all orders are unimportant, treating two plans differing only in the order of actions as equivalent. To allow flexibility in selecting important orders, we propose specifying a subset of actions the orders between which are important, interpolating between the top-quality and unordered top-quality planning problems. We explore the ways of adapting partial order reduction search pruning techniques to address this new computational problem and present experimental evaluations demonstrating the benefits of exploiting such techniques in this setting.
    
[^73]: 不遗忘先验知识的目标检测适应模态转换

    Modality Translation for Object Detection Adaptation Without Forgetting Prior Knowledge

    [https://arxiv.org/abs/2404.01492](https://arxiv.org/abs/2404.01492)

    本文提出了一种ModTr方法，通过小型转换网络调整输入以最小化检测损失，实现了目标检测模型从一个或多个模态到另一个的有效适应，而无需微调参数。

    

    深度学习中常见的做法是在大规模数据集上训练大型神经网络，以在不同领域和任务中准确执行。然而，这种方法在许多应用领域只适用于跨模态，因为使用不同传感器捕获的数据存在更大的分布偏移。本文专注于将大型目标检测模型调整到一个或多个模态的问题，同时保持高效。为此，我们提出了ModTr作为普遍做法微调大型模型的替代方案。ModTr包括使用一个小型转换网络调整输入，该网络经过训练，直接使检测损失最小化。因此，原始模型可以在转换后的输入上工作，无需进行任何进一步的更改或参数微调。对两个知名数据集上从红外到RGB图像的转换的实验结果表明，这种简单的ModTr方法提供了检测器。

    arXiv:2404.01492v1 Announce Type: cross  Abstract: A common practice in deep learning consists of training large neural networks on massive datasets to perform accurately for different domains and tasks. While this methodology may work well in numerous application areas, it only applies across modalities due to a larger distribution shift in data captured using different sensors. This paper focuses on the problem of adapting a large object detection model to one or multiple modalities while being efficient. To do so, we propose ModTr as an alternative to the common approach of fine-tuning large models. ModTr consists of adapting the input with a small transformation network trained to minimize the detection loss directly. The original model can therefore work on the translated inputs without any further change or fine-tuning to its parameters. Experimental results on translating from IR to RGB images on two well-known datasets show that this simple ModTr approach provides detectors tha
    
[^74]: QuAD: 基于查询的可解释的神经运动规划方法用于自动驾驶

    QuAD: Query-based Interpretable Neural Motion Planning for Autonomous Driving

    [https://arxiv.org/abs/2404.01486](https://arxiv.org/abs/2404.01486)

    提出了一个新的自动驾驶神经运动规划框架，通过查询感兴趣的时空点的占据信息，避免了传统对象检测和密集占据栅格地图方法中的信息丢失和计算浪费。

    

    自动驾驶车辆必须了解其环境以确定适当的动作。传统自主系统依赖于对象检测来找到场景中的代理。然而，对象检测假设一组离散的对象，并丢失有关不确定性的信息，因此在预测这些代理未来行为时任何错误都会累积。与此相反，密集的占据栅格地图已被用于理解自由空间。然而，为整个场景预测网格是浪费的，因为只有某些时空区域是可到达的并且对自动驾驶车辆相关。我们提出了一个统一的、可解释的、高效的自主框架，摆脱了先感知、再预测，最后规划的级联模块的范式。相反，我们将规划者的重点转移到查询相关时空点的占据，限制计算在这些感兴趣的区域上。利用这种表示

    arXiv:2404.01486v1 Announce Type: cross  Abstract: A self-driving vehicle must understand its environment to determine the appropriate action. Traditional autonomy systems rely on object detection to find the agents in the scene. However, object detection assumes a discrete set of objects and loses information about uncertainty, so any errors compound when predicting the future behavior of those agents. Alternatively, dense occupancy grid maps have been utilized to understand free-space. However, predicting a grid for the entire scene is wasteful since only certain spatio-temporal regions are reachable and relevant to the self-driving vehicle. We present a unified, interpretable, and efficient autonomy framework that moves away from cascading modules that first perceive, then predict, and finally plan. Instead, we shift the paradigm to have the planner query occupancy at relevant spatio-temporal points, restricting the computation to those regions of interest. Exploiting this represent
    
[^75]: TraveLER：用于视频问答的多重LMM代理框架

    TraveLER: A Multi-LMM Agent Framework for Video Question-Answering

    [https://arxiv.org/abs/2404.01476](https://arxiv.org/abs/2404.01476)

    TraveLER是一种多重LMM代理框架，通过沿着视频移动，并通过交互式提问收集关键帧的信息，以解决视频问答中关键时间戳选择和错误时间戳调整的问题

    

    最近，大型多模态模型（LMMs）在视频问答方面取得了重要进展，通过利用大规模、基于图像的预训练以零样本方式以帧为单位进行处理。虽然基于图像的视频方法展现了令人印象深刻的性能，但目前的局限是它们经常忽视了如何选择关键时间戳，并且无法在确定错误时间戳时进行调整。此外，它们无法提取与问题相关的细节，而是提供帧的一般描述。为了克服这一点，我们设计了一个多重LMM代理框架，它沿着视频进行移动，通过交互式提问的方式迭代地从关键帧收集相关信息，直到获得足够的信息来回答问题。具体来说，我们提出了TraveLER，这是一个可以制定“遍历”视频计划的模型，询问关于单个帧的问题以“定位”并存储关键信息

    arXiv:2404.01476v1 Announce Type: cross  Abstract: Recently, Large Multimodal Models (LMMs) have made significant progress in video question-answering using a frame-wise approach by leveraging large-scale, image-based pretraining in a zero-shot manner. While image-based methods for videos have shown impressive performance, a current limitation is that they often overlook how key timestamps are selected and cannot adjust when incorrect timestamps are identified. Moreover, they are unable to extract details relevant to the question, instead providing general descriptions of the frame. To overcome this, we design a multi-LMM agent framework that travels along the video, iteratively collecting relevant information from keyframes through interactive question-asking until there is sufficient information to answer the question. Specifically, we propose TraveLER, a model that can create a plan to "Traverse" through the video, ask questions about individual frames to "Locate" and store key info
    
[^76]: 大型语言模型是否是超人类化学家？

    Are large language models superhuman chemists?

    [https://arxiv.org/abs/2404.01475](https://arxiv.org/abs/2404.01475)

    介绍了一个自动化框架“ChemBench”，旨在评估最先进的大型语言模型（LLMs）在化学知识和推理能力方面与人类化学家专业知识的对比。

    

    大型语言模型（LLMs）因其处理人类语言并执行未经明确训练的任务的能力而引起了广泛关注。这对化学科学是相关的，因为化学面临着数据集小且多样的问题，这些数据集通常以文本形式呈现。 LLMs在解决这些问题方面表现出潜力，并且越来越多地被利用来预测化学性质，优化反应，甚至自主设计和进行实验。然而，我们对LLMs的化学推理能力仅有非常有限的系统性理解，这是改进模型和减轻潜在危害所必需的。在这里，我们介绍了“ChemBench”，这是一个自动化框架，旨在严格评估最先进的LLMs的化学知识和推理能力，以与人类化学家的专业知识相比较。

    arXiv:2404.01475v1 Announce Type: cross  Abstract: Large language models (LLMs) have gained widespread interest due to their ability to process human language and perform tasks on which they have not been explicitly trained. This is relevant for the chemical sciences, which face the problem of small and diverse datasets that are frequently in the form of text. LLMs have shown promise in addressing these issues and are increasingly being harnessed to predict chemical properties, optimize reactions, and even design and conduct experiments autonomously. However, we still have only a very limited systematic understanding of the chemical reasoning capabilities of LLMs, which would be required to improve models and mitigate potential harms. Here, we introduce "ChemBench," an automated framework designed to rigorously evaluate the chemical knowledge and reasoning abilities of state-of-the-art LLMs against the expertise of human chemists. We curated more than 7,000 question-answer pairs for a 
    
[^77]: 4D医学图像的无监督插值方法：无需任何中间帧

    Data-Efficient Unsupervised Interpolation Without Any Intermediate Frame for 4D Medical Images

    [https://arxiv.org/abs/2404.01464](https://arxiv.org/abs/2404.01464)

    该论文提出了一种简单而有效的无监督三维插值框架UVI-Net，能够在4D医学图像中实现无需中间帧的时间插值，取得了显着的性能改善。

    

    4D医学图像在临床实践中至关重要，能够捕捉动态变化并监测长期疾病进展。然而，获取4D医学图像会面临挑战，如辐射暴露和成像时间，需要在实现高时间分辨率和减少不良影响之间取得平衡。在这种情况下，数据获取不仅具有挑战性，增加每个数据集的帧率也很困难。为解决这一挑战，本文提出了一种简单而有效的无监督三维插值框架，UVI-Net。该框架促进了时间插值而无需任何中间帧，与大多数现有无监督方法不同。对基准数据集的实验表明，在各种评估指标上都取得了显着进展。

    arXiv:2404.01464v1 Announce Type: cross  Abstract: 4D medical images, which represent 3D images with temporal information, are crucial in clinical practice for capturing dynamic changes and monitoring long-term disease progression. However, acquiring 4D medical images poses challenges due to factors such as radiation exposure and imaging duration, necessitating a balance between achieving high temporal resolution and minimizing adverse effects. Given these circumstances, not only is data acquisition challenging, but increasing the frame rate for each dataset also proves difficult. To address this challenge, this paper proposes a simple yet effective Unsupervised Volumetric Interpolation framework, UVI-Net. This framework facilitates temporal interpolation without the need for any intermediate frames, distinguishing it from the majority of other existing unsupervised methods. Experiments on benchmark datasets demonstrate significant improvements across diverse evaluation metrics compare
    
[^78]: 游戏理论深度强化学习在地理分布式数据中心中最小化碳排放和能源成本的AI推断负载

    Game-Theoretic Deep Reinforcement Learning to Minimize Carbon Emissions and Energy Costs for AI Inference Workloads in Geo-Distributed Data Centers

    [https://arxiv.org/abs/2404.01459](https://arxiv.org/abs/2404.01459)

    结合博弈论和深度强化学习优化地理分布式数据中心中AI推断工作负载的分布，以降低碳排放和运营成本。

    

    数据中心由于人工智能（AI）工作负载的增加而消耗更多能源，这对环境造成负面影响并提高运营成本。本文提出了一种独特的方法，将博弈论（GT）和深度强化学习（DRL）相结合，优化地理分布式数据中心中AI推断工作负载的分布，以减少碳排放和云运营（能源+数据传输）成本。

    arXiv:2404.01459v1 Announce Type: cross  Abstract: Data centers are increasingly using more energy due to the rise in Artificial Intelligence (AI) workloads, which negatively impacts the environment and raises operational costs. Reducing operating expenses and carbon emissions while maintaining performance in data centers is a challenging problem. This work introduces a unique approach combining Game Theory (GT) and Deep Reinforcement Learning (DRL) for optimizing the distribution of AI inference workloads in geo-distributed data centers to reduce carbon emissions and cloud operating (energy + data transfer) costs. The proposed technique integrates the principles of non-cooperative Game Theory into a DRL framework, enabling data centers to make intelligent decisions regarding workload allocation while considering the heterogeneity of hardware resources, the dynamic nature of electricity prices, inter-data center data transfer costs, and carbon footprints. We conducted extensive experim
    
[^79]: 揭示LLMs在时间数据上的分歧归纳偏见

    Unveiling Divergent Inductive Biases of LLMs on Temporal Data

    [https://arxiv.org/abs/2404.01453](https://arxiv.org/abs/2404.01453)

    本研究探索了LLMs在时间数据分析中的固有挑战，重点评估了GPT-3.5和GPT-4模型的性能，发现了它们在特定时间关系上存在偏向性。

    

    揭示自然语言事件的微妙细节需要对时间动态进行微妙理解。尽管大型语言模型（LLMs）在从数据中辨别模式和关系方面表现得很熟练，但它们对时间动态的内在理解仍然是一个巨大挑战。本研究在LLMs中细致探索这些固有挑战，特别强调评估GPT-3.5和GPT-4模型在时间数据分析中的性能。通过采用问答（QA）格式和文本蕴涵（TE）格式两种不同的提示类型，我们的分析深入探究了隐式和显式事件。研究结果凸显了一些显著趋势，揭示了GPT-3.5和GPT-4性能上的差异。值得注意的是，倾向于特定时间关系的偏见浮出水面，其中在QA格式中，GPT-3.5在隐式和显式方面均表现出对"AFTER"的偏好。

    arXiv:2404.01453v1 Announce Type: cross  Abstract: Unraveling the intricate details of events in natural language necessitates a subtle understanding of temporal dynamics. Despite the adeptness of Large Language Models (LLMs) in discerning patterns and relationships from data, their inherent comprehension of temporal dynamics remains a formidable challenge. This research meticulously explores these intrinsic challenges within LLMs, with a specific emphasis on evaluating the performance of GPT-3.5 and GPT-4 models in the analysis of temporal data. Employing two distinct prompt types, namely Question Answering (QA) format and Textual Entailment (TE) format, our analysis probes into both implicit and explicit events. The findings underscore noteworthy trends, revealing disparities in the performance of GPT-3.5 and GPT-4. Notably, biases toward specific temporal relationships come to light, with GPT-3.5 demonstrating a preference for "AFTER'' in the QA format for both implicit and explicit
    
[^80]: 使用多实例学习在整张切片图像中找到感兴趣区域

    Finding Regions of Interest in Whole Slide Images Using Multiple Instance Learning

    [https://arxiv.org/abs/2404.01446](https://arxiv.org/abs/2404.01446)

    本研究使用多实例学习方法来解决整张切片图像中准确预测癌症表型和在图块级别找到与之相关的细胞形态学的挑战。

    

    Whole Slide Images (WSI)是通过高分辨率数字扫描显微镜切片在多个尺度下获得的，是现代数字病理学的基石。然而，它们对基于人工智能的/人工智能中介分析提出特殊挑战，因为病理标注通常是在切片级别而不是图块级别进行的。本文探讨了一种弱监督的多实例学习（MIL）方法，用于两种常见癌症类型，侵袭性乳腺癌（TCGA-BRCA）和肺鳞状细胞癌（TCGA-LUSC）。

    arXiv:2404.01446v1 Announce Type: cross  Abstract: Whole Slide Images (WSI), obtained by high-resolution digital scanning of microscope slides at multiple scales, are the cornerstone of modern Digital Pathology. However, they represent a particular challenge to AI-based/AI-mediated analysis because pathology labeling is typically done at slide-level, instead of tile-level. It is not just that medical diagnostics is recorded at the specimen level, the detection of oncogene mutation is also experimentally obtained, and recorded by initiatives like The Cancer Genome Atlas (TCGA), at the slide level. This configures a dual challenge: a) accurately predicting the overall cancer phenotype and b) finding out what cellular morphologies are associated with it at the tile level. To address these challenges, a weakly supervised Multiple Instance Learning (MIL) approach was explored for two prevalent cancer types, Invasive Breast Carcinoma (TCGA-BRCA) and Lung Squamous Cell Carcinoma (TCGA-LUSC). 
    
[^81]: 用于构建未知关节对象数字孪生体的神经隐式表示

    Neural Implicit Representation for Building Digital Twins of Unknown Articulated Objects

    [https://arxiv.org/abs/2404.01440](https://arxiv.org/abs/2404.01440)

    该方法通过显式建模点级对应关系、利用图像、3D重建和运动学的线索，成功构建了未知关节对象的数字孪生体，结果更准确和稳定，且不依赖于任何对象形状或结构先验。

    

    我们解决了从两个不同关节状态的物体的RGBD扫描构建未知关节对象的数字孪生体的问题。我们将问题分解为两个阶段，每个阶段都处理不同的方面。我们的方法首先在每个状态重建物体级形状，然后恢复包括部件分割和关节关联在内的基础关节模型。通过显式建模点级对应关系并利用来自图像、3D重建和运动学的线索，我们的方法与先前工作相比产生了更准确和稳定的结果。它还处理了多个可移动部件，不依赖于任何对象形状或结构先验。

    arXiv:2404.01440v1 Announce Type: cross  Abstract: We address the problem of building digital twins of unknown articulated objects from two RGBD scans of the object at different articulation states. We decompose the problem into two stages, each addressing distinct aspects. Our method first reconstructs object-level shape at each state, then recovers the underlying articulation model including part segmentation and joint articulations that associate the two states. By explicitly modeling point-level correspondences and exploiting cues from images, 3D reconstructions, and kinematics, our method yields more accurate and stable results compared to prior work. It also handles more than one movable part and does not rely on any object shape or structure priors. Project page: https://github.com/NVlabs/DigitalTwinArt
    
[^82]: 从描述中无监督地进行情感分析，创建表情符号词库

    Creating emoji lexica from unsupervised sentiment analysis of their descriptions

    [https://arxiv.org/abs/2404.01439](https://arxiv.org/abs/2404.01439)

    该论文提出了一种从在线文本消息中预测表情符号所表达情感的新方法，无需人工标注数据，节省了宝贵时间。

    

    线上媒体，如博客和社交网络网站，生成了大量非结构化数据供分析个人和组织的观点和情感之用。传统的自然语言处理方法已经不能很好地量化这些观点的极性度量，因此需要新颖的方法。迄今为止，表情符号所表达的情感得到的关注较少。然而，过去四年间，符号的使用量激增。如今，Twitter中每天会被输入大约两百亿个符号，并且每个新的Unicode版本都会增加新的表情符号，使得它们对情感分析任务越来越重要。这促使我们提出了一种新颖的方法来预测在线文本消息（如推文）中表情符号表达的情感，该方法不需要人工手动注释数据，以此节省宝贵的时间用于其他分析任务。为此，我们自动构建了一种新颖的表情符号情感词库。

    arXiv:2404.01439v1 Announce Type: cross  Abstract: Online media, such as blogs and social networking sites, generate massive volumes of unstructured data of great interest to analyze the opinions and sentiments of individuals and organizations. Novel approaches beyond Natural Language Processing are necessary to quantify these opinions with polarity metrics. So far, the sentiment expressed by emojis has received little attention. The use of symbols, however, has boomed in the past four years. About twenty billion are typed in Twitter nowadays, and new emojis keep appearing in each new Unicode version, making them increasingly relevant to sentiment analysis tasks. This has motivated us to propose a novel approach to predict the sentiments expressed by emojis in online textual messages, such as tweets, that does not require human effort to manually annotate data and saves valuable time for other analysis tasks. For this purpose, we automatically constructed a novel emoji sentiment lexico
    
[^83]: 深度伪造手语的生成与检测-语言和视觉分析

    Generation and Detection of Sign Language Deepfakes - A Linguistic and Visual Analysis

    [https://arxiv.org/abs/2404.01438](https://arxiv.org/abs/2404.01438)

    通过在上半身生成手语深度伪造视频，并由手语专家审核，本研究探讨了在深度伪造技术中的积极应用，为聋哑和听障社区带来潜在的健康和教育益处。

    

    深度伪造领域中一个逐渐出现的问题是我们是否可以超越面部深度伪造，以及这对社会是否有益。因此，这项研究提出了在上半身生成中深度伪造技术的积极应用，同时为聋哑和听障（DHoH）社区执行手语。随后，通过一位手语专家对生成的视频进行审核。鉴于手语的复杂性、手语专家的匮乏以及对健康和教育的潜在益处，这种做法尤为有益。本研究的目标包括构建可靠的深度伪造数据集，通过计算机视觉和自然语言处理模型评估其技术和视觉可信度，以及评估生成内容的可信度。使用1200多个视频，模型包含以前见过和未见过的个体，借助一位手语专家的帮助进行生成。

    arXiv:2404.01438v1 Announce Type: cross  Abstract: A question in the realm of deepfakes is slowly emerging pertaining to whether we can go beyond facial deepfakes and whether it would be beneficial to society. Therefore, this research presents a positive application of deepfake technology in upper body generation, while performing sign-language for the Deaf and Hard of Hearing (DHoH) community. The resulting videos are later vetted with a sign language expert. This is particularly helpful, given the intricate nature of sign language, a scarcity of sign language experts, and potential benefits for health and education. The objectives of this work encompass constructing a reliable deepfake dataset, evaluating its technical and visual credibility through computer vision and natural language processing models, and assessing the plausibility of the generated content. With over 1200 videos, featuring both previously seen and unseen individuals for the generation model, using the help of a si
    
[^84]: 降低LLMs中位置偏差的面向位置的参数高效微调方法

    Position-Aware Parameter Efficient Fine-Tuning Approach for Reducing Positional Bias in LLMs

    [https://arxiv.org/abs/2404.01430](https://arxiv.org/abs/2404.01430)

    本研究发现LLMs的位置偏差主要源于不同模型的固有位置偏好，并提出了一种面向位置的参数高效微调方法来解决这一问题。

    

    大型语言模型（LLMs）的最新进展增强了它们处理长输入上下文的能力。对于涉及从外部数据存储库检索知识的任务，这一进展尤为关键，因为可能涉及长输入。然而，最近的研究显示LLMs存在位置偏差，表明其性能会根据输入序列中有用信息的位置而变化。本研究进行了大量实验，以调查位置偏差的根本原因。我们的发现表明，LLMs的位置偏差的主要贡献者源于不同模型的固有位置偏好。我们证明，仅仅采用基于提示的解决方案无法克服位置偏好。为了解决预训练LLMs的位置偏差问题，我们开发了一种面向位置的参数高效微调（PAPEFT）方法，该方法包含一个数据增广。

    arXiv:2404.01430v1 Announce Type: cross  Abstract: Recent advances in large language models (LLMs) have enhanced their ability to process long input contexts. This development is particularly crucial for tasks that involve retrieving knowledge from an external datastore, which can result in long inputs. However, recent studies show a positional bias in LLMs, demonstrating varying performance depending on the location of useful information within the input sequence. In this study, we conduct extensive experiments to investigate the root causes of positional bias. Our findings indicate that the primary contributor to LLM positional bias stems from the inherent positional preferences of different models. We demonstrate that merely employing prompt-based solutions is inadequate for overcoming the positional preferences. To address this positional bias issue of a pre-trained LLM, we developed a Position-Aware Parameter Efficient Fine-Tuning (PAPEFT) approach which is composed of a data augm
    
[^85]: 模型崩溃是否不可避免？通过累积真实和合成数据打破递归的诅咒

    Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data

    [https://arxiv.org/abs/2404.01413](https://arxiv.org/abs/2404.01413)

    本文通过比较数据取代和数据积累两种情况，发现累积数据可以防止模型崩溃。

    

    随着生成模型的激增，以及在网络规模数据上的预训练，一个及时的问题浮出水面：当这些模型被训练在它们自己生成的输出上时会发生什么？最近对模型数据反馈循环的研究发现，这样的循环可能导致模型崩溃，即性能随着每次模型拟合迭代逐渐下降，直到最新的模型变得无用。然而，最近几篇研究模型崩溃的论文都假设随着时间推移，新数据会取代旧数据，而不是假设数据会随时间累积。在本文中，我们比较了这两种情况，并表明积累数据可以防止模型崩溃。我们首先研究了一个解析可处理的设置，其中一系列线性模型拟合到先前模型的预测。先前的工作表明，如果数据被替换，测试误差会随着模型拟合迭代次数线性增加；我们扩展了这个研究探讨了数据逐渐累积的情况下会发生什么。

    arXiv:2404.01413v1 Announce Type: cross  Abstract: The proliferation of generative models, combined with pretraining on web-scale data, raises a timely question: what happens when these models are trained on their own generated outputs? Recent investigations into model-data feedback loops discovered that such loops can lead to model collapse, a phenomenon where performance progressively degrades with each model-fitting iteration until the latest model becomes useless. However, several recent papers studying model collapse assumed that new data replace old data over time rather than assuming data accumulate over time. In this paper, we compare these two settings and show that accumulating data prevents model collapse. We begin by studying an analytically tractable setup in which a sequence of linear models are fit to the previous models' predictions. Previous work showed if data are replaced, the test error increases linearly with the number of model-fitting iterations; we extend this r
    
[^86]: OVFoodSeg：通过基于图像信息的文本表示提升开放词汇食品图像分割

    OVFoodSeg: Elevating Open-Vocabulary Food Image Segmentation via Image-Informed Textual Representation

    [https://arxiv.org/abs/2404.01409](https://arxiv.org/abs/2404.01409)

    OVFoodSeg通过开放词汇设定和视觉-语言模型，结合图像信息，提升食品图像分割任务的效果。

    

    在食品计算领域，从图像中分割出食材面临着巨大挑战，这主要是由于相同食材之间存在大量的内部类别差异、新食材的出现，以及与大型食品分割数据集相关的高昂注释成本。现有方法主要采用闭合词汇和静态文本嵌入设置。这些方法通常在有效处理食材方面存在不足，特别是新的和多样化的食材。为了应对这些局限性，我们引入了OVFoodSeg，这是一个采用开放词汇设置并通过视觉背景增强文本嵌入的框架。通过集成视觉-语言模型（VLMs），我们的方法通过两个创新模块（例如，图像到文本学习器FoodLearner和基于图像信息的文本编码器）将文本嵌入与图像特定信息相结合。OVFoodSeg的训练过程分为两个阶段：FoodLea的预训练

    arXiv:2404.01409v1 Announce Type: cross  Abstract: In the realm of food computing, segmenting ingredients from images poses substantial challenges due to the large intra-class variance among the same ingredients, the emergence of new ingredients, and the high annotation costs associated with large food segmentation datasets. Existing approaches primarily utilize a closed-vocabulary and static text embeddings setting. These methods often fall short in effectively handling the ingredients, particularly new and diverse ones. In response to these limitations, we introduce OVFoodSeg, a framework that adopts an open-vocabulary setting and enhances text embeddings with visual context. By integrating vision-language models (VLMs), our approach enriches text embedding with image-specific information through two innovative modules, eg, an image-to-text learner FoodLearner and an Image-Informed Text Encoder. The training process of OVFoodSeg is divided into two stages: the pre-training of FoodLea
    
[^87]: ContactHandover: 接触引导的机器人向人类递送物体

    ContactHandover: Contact-Guided Robot-to-Human Object Handover

    [https://arxiv.org/abs/2404.01402](https://arxiv.org/abs/2404.01402)

    ContactHandover是一个机器人向人类递送物体的系统，通过接触引导的抓取和物体递送阶段来实现成功的物体递送。

    

    机器人向人类递送物体是许多人机协作任务中的重要一步。成功的递送需要机器人保持对物体的稳定抓取，同时确保人类以一种自然且易于使用的方式接收物体。我们提出了ContactHandover，这是一个机器人向人类递送物体的系统，包括两个阶段：接触引导的抓取阶段和物体递送阶段。在抓取阶段，ContactHandover预测机器人的6自由度抓取姿势和人类接触点在物体上的3D可供性图。机器人的抓取姿势通过惩罚那些阻碍人类接触点的姿势进行重新排序，并执行排名最高的抓取。在递送阶段，通过最大化靠近人类的接触点并最小化人类手臂关节扭矩和位移来计算机器人末端执行器姿势。我们在27种不同家用物品上评估了我们的系统，并展示了o

    arXiv:2404.01402v1 Announce Type: cross  Abstract: Robot-to-human object handover is an important step in many human robot collaboration tasks. A successful handover requires the robot to maintain a stable grasp on the object while making sure the human receives the object in a natural and easy-to-use manner. We propose ContactHandover, a robot to human handover system that consists of two phases: a contact-guided grasping phase and an object delivery phase. During the grasping phase, ContactHandover predicts both 6-DoF robot grasp poses and a 3D affordance map of human contact points on the object. The robot grasp poses are reranked by penalizing those that block human contact points, and the robot executes the highest ranking grasp. During the delivery phase, the robot end effector pose is computed by maximizing human contact points close to the human while minimizing the human arm joint torques and displacements. We evaluate our system on 27 diverse household objects and show that o
    
[^88]: 基于对象条件的实例袋用于少样本个性化实例识别

    Object-conditioned Bag of Instances for Few-Shot Personalized Instance Recognition

    [https://arxiv.org/abs/2404.01397](https://arxiv.org/abs/2404.01397)

    该论文提出了一种基于对象条件的实例袋（OBoI）方法，通过多阶统计实现了个性化实例识别，能够在少样本数据集中达到较高的准确度。

    

    现今，用户需求增加了对视觉系统个性化的要求，从少样本数据集中仅仅识别和定位个人实例（例如，我的狗而不是狗）。尽管深度网络在传统标注丰富的基准上取得了出色的结果（例如，最新YOLOv8模型的标准目标检测），但它们很难保持类内变异性以表示不同实例而不仅仅是对象类别。我们构建了一种基于抽取特征的多阶统计的对象条件实例袋（OBoI），在这里，将通用对象检测模型扩展到搜索并从 OBoI 的度量空间识别个人实例，无需反向传播。通过依赖多阶统计，OBoI 在区分不同实例方面实现了一致的超凡准确性。在结果中，我们在18个个人实例的情况下实现了77.1% 的个人对象识别准确度。

    arXiv:2404.01397v1 Announce Type: cross  Abstract: Nowadays, users demand for increased personalization of vision systems to localize and identify personal instances of objects (e.g., my dog rather than dog) from a few-shot dataset only. Despite outstanding results of deep networks on classical label-abundant benchmarks (e.g., those of the latest YOLOv8 model for standard object detection), they struggle to maintain within-class variability to represent different instances rather than object categories only. We construct an Object-conditioned Bag of Instances (OBoI) based on multi-order statistics of extracted features, where generic object detection models are extended to search and identify personal instances from the OBoI's metric space, without need for backpropagation. By relying on multi-order statistics, OBoI achieves consistent superior accuracy in distinguishing different instances. In the results, we achieve 77.1% personal object recognition accuracy in case of 18 personal in
    
[^89]: 基于提示的混合专家模型用于高效生成LLM

    Prompt-prompted Mixture of Experts for Efficient LLM Generation

    [https://arxiv.org/abs/2404.01365](https://arxiv.org/abs/2404.01365)

    提出了一种名为GRIFFIN的训练-free MoE，能够在各种LLM模型中选择唯一的FF专家以实现高效生成。

    

    随着基于transformer的大规模语言模型（LLMs）的发展，由于其出色的实用性，它们已被应用于许多领域，但在部署时存在相当大的计算成本。幸运的是，一些方法，如修剪或构建混合专家（MoE），旨在利用transformer前馈（FF）块中的稀疏性，以提高速度并降低内存需求。但是，这些技术在实践中可能非常昂贵和不灵活，因为它们通常需要训练或仅限于特定类型的架构。为了解决这个问题，我们引入了GRIFFIN，一种新颖的无需训练的MoE，它在序列级别为不同非ReLU激活函数的大量LLMs选择独特的FF专家以实现高效生成。这是可能的，因为我们关键观察到，许多经过训练的LLMs在序列中自然产生高度结构化的FF激活模式，这

    arXiv:2404.01365v1 Announce Type: cross  Abstract: With the development of transformer-based large language models (LLMs), they have been applied to many fields due to their remarkable utility, but this comes at a considerable computational cost at deployment. Fortunately, some methods such as pruning or constructing a mixture of experts (MoE) aim at exploiting sparsity in transformer feedforward (FF) blocks to gain boosts in speed and reduction in memory requirements. However, these techniques can be very costly and inflexible in practice, as they often require training or are restricted to specific types of architectures. To address this, we introduce GRIFFIN, a novel training-free MoE that selects unique FF experts at the sequence level for efficient generation across a plethora of LLMs with different non-ReLU activation functions. This is possible due to a critical observation that many trained LLMs naturally produce highly structured FF activation patterns within a sequence, which
    
[^90]: 通过转移熵在深度学习中的信息平面分析可视化

    Information Plane Analysis Visualization in Deep Learning via Transfer Entropy

    [https://arxiv.org/abs/2404.01364](https://arxiv.org/abs/2404.01364)

    通过转移熵进行信息平面分析可视化揭示了信息瓶颈方法中压缩和信息保留的权衡，以及信息论压缩与泛化之间存在的关系。

    

    在前馈网络中，可以利用转移熵（TE）来衡量一层对另一层的影响，通过量化它们之间在训练期间的信息传递。根据信息瓶颈原理，神经模型的内部表示应尽可能压缩输入数据，同时仍保留足够的关于输出的信息。信息平面分析是一种可视化技术，用于通过绘制输入数据中的信息量与压缩表示之间的关系，来理解信息瓶颈方法中压缩和信息保留之间的权衡。声称信息论压缩和泛化之间存在因果联系，通过互信息来衡量是可信的，但不同研究的结果存在冲突。TE可以捕捉时间关系，与互信息相比，存在差异。

    arXiv:2404.01364v1 Announce Type: cross  Abstract: In a feedforward network, Transfer Entropy (TE) can be used to measure the influence that one layer has on another by quantifying the information transfer between them during training. According to the Information Bottleneck principle, a neural model's internal representation should compress the input data as much as possible while still retaining sufficient information about the output. Information Plane analysis is a visualization technique used to understand the trade-off between compression and information preservation in the context of the Information Bottleneck method by plotting the amount of information in the input data against the compressed representation. The claim that there is a causal link between information-theoretic compression and generalization, measured by mutual information, is plausible, but results from different studies are conflicting. In contrast to mutual information, TE can capture temporal relationships be
    
[^91]: AIOps解决方案的故障管理：技术指南和综合文献综述

    AIOps Solutions for Incident Management: Technical Guidelines and A Comprehensive Literature Review

    [https://arxiv.org/abs/2404.01363](https://arxiv.org/abs/2404.01363)

    AIOps利用机器学习和大数据等技术提升故障管理效率，但领域仍未统一标准化。

    

    现代IT系统管理面临独特挑战，需要处理大量数据流时具有可伸缩性、可靠性和高效性。依靠手动任务和基于规则的传统方法对IT系统产生的大量数据量和警报效率低下。操作系统人工智能（AIOps）作为一种解决方案出现，利用机器学习和大数据等先进分析技术来增强故障管理。AIOps可以检测和预测故障，识别根本原因，自动化治愈操作，提高质量并降低运营成本。然而，尽管它具有潜力，AIOps领域仍处于早期阶段，在多个领域分散，缺乏标准化惯例。研究和工业贡献分布广泛，缺乏一致的数据管理框架、目标问题、实施细节、需求，

    arXiv:2404.01363v1 Announce Type: cross  Abstract: The management of modern IT systems poses unique challenges, necessitating scalability, reliability, and efficiency in handling extensive data streams. Traditional methods, reliant on manual tasks and rule-based approaches, prove inefficient for the substantial data volumes and alerts generated by IT systems. Artificial Intelligence for Operating Systems (AIOps) has emerged as a solution, leveraging advanced analytics like machine learning and big data to enhance incident management. AIOps detects and predicts incidents, identifies root causes, and automates healing actions, improving quality and reducing operational costs. However, despite its potential, the AIOps domain is still in its early stages, decentralized across multiple sectors, and lacking standardized conventions. Research and industrial contributions are distributed without consistent frameworks for data management, target problems, implementation details, requirements, a
    
[^92]: LLM Attributor: 交互式可视化归因用于LLM生成

    LLM Attributor: Interactive Visual Attribution for LLM Generation

    [https://arxiv.org/abs/2404.01361](https://arxiv.org/abs/2404.01361)

    LLM Attributor是一个Python库，提供了交互式可视化方式用于将LLM的文本生成结果归因到训练数据点，帮助用户检查模型行为、增强可信度，并与用户提供的文本进行比较。

    

    虽然大型语言模型（LLMs）显示出在各个领域生成令人信服的文本的能力，但对其潜在风险的担忧凸显了了解文本生成背后原因的重要性。我们提出了LLM Attributor，一个提供LLM文本生成训练数据归因交互可视化的Python库。我们的库为快速将LLM的文本生成归因到训练数据点提供了一种新方式，以检查模型行为、增强其可信度，并将模型生成的文本与用户提供的文本进行比较。我们描述了工具的视觉和交互设计，并强调LLaMA2模型的使用场景，该模型通过两个不同数据集进行微调：关于最近灾难和金融相关问答对的在线文章。由于LLM Attributor对计算笔记本的广泛支持，用户可以轻松将其整合到他们的工作流程中。

    arXiv:2404.01361v1 Announce Type: cross  Abstract: While large language models (LLMs) have shown remarkable capability to generate convincing text across diverse domains, concerns around its potential risks have highlighted the importance of understanding the rationale behind text generation. We present LLM Attributor, a Python library that provides interactive visualizations for training data attribution of an LLM's text generation. Our library offers a new way to quickly attribute an LLM's text generation to training data points to inspect model behaviors, enhance its trustworthiness, and compare model-generated text with user-provided text. We describe the visual and interactive design of our tool and highlight usage scenarios for LLaMA2 models fine-tuned with two different datasets: online articles about recent disasters and finance-related question-answer pairs. Thanks to LLM Attributor's broad support for computational notebooks, users can easily integrate it into their workflow 
    
[^93]: 并行比例融合脉冲量子神经网络用于优化图像分类

    Parallel Proportional Fusion of Spiking Quantum Neural Network for Optimizing Image Classification

    [https://arxiv.org/abs/2404.01359](https://arxiv.org/abs/2404.01359)

    提出了一种新型架构PPF-QSNN，通过并行方式将数据集信息输入到脉冲神经网络和变分量子电路中，并根据它们各自的贡献比例合并输出。

    

    最近混合量子-经典神经网络（HQCNN）架构的出现引起了人们的广泛关注，因为将量子原理集成到增强各种机器学习算法和计算方面可能带来的优势。然而，HQCNN当前研究的串行结构，信息依次从一个网络传递到另一个网络，经常会对网络的可训练性和表现力造成限制。在本研究中，我们引入了一种名为并行比例融合量子和脉冲神经网络（PPF-QSNN）的新型架构。数据集信息同时输入到脉冲神经网络和变分量子电路中，输出按照它们各自的贡献比例合并。我们系统地评估了不同PPF-QSNN参数对图像分类网络性能的影响，旨在提高

    arXiv:2404.01359v1 Announce Type: cross  Abstract: The recent emergence of the hybrid quantum-classical neural network (HQCNN) architecture has garnered considerable attention due to the potential advantages associated with integrating quantum principles to enhance various facets of machine learning algorithms and computations. However, the current investigated serial structure of HQCNN, wherein information sequentially passes from one network to another, often imposes limitations on the trainability and expressivity of the network. In this study, we introduce a novel architecture termed Parallel Proportional Fusion of Quantum and Spiking Neural Networks (PPF-QSNN). The dataset information is simultaneously fed into both the spiking neural network and the variational quantum circuits, with the outputs amalgamated in proportion to their individual contributions. We systematically assess the impact of diverse PPF-QSNN parameters on network performance for image classification, aiming to 
    
[^94]: 利用人工智能和社交媒体分析发现GLP-1受体激动剂的不良副作用

    Utilizing AI and Social Media Analytics to Discover Adverse Side Effects of GLP-1 Receptor Agonists

    [https://arxiv.org/abs/2404.01358](https://arxiv.org/abs/2404.01358)

    通过利用人工智能驱动的社交媒体分析，我们开发了一种数字健康方法，成功检测出与GLP-1受体激动剂相关的21种潜在不良副作用，包括易怒和麻木感，从而革新了对新部署药物未报告ASEs的检测。

    

    药物的不良副作用（ASEs）在FDA批准后被发现，对患者安全构成威胁。为了及时发现被忽视的ASEs，我们开发了一种数字健康方法，能够分析来自社交媒体、已发表的临床研究、制造商报告和ChatGPT等大量公开数据。我们发现了与肝素样肽1受体激动剂（GLP-1 RA）相关的ASEs，这一市场预计到2030年将呈指数增长至1335亿美元。利用命名实体识别（NER）模型，我们的方法成功检测出FDA批准时被忽视的21种潜在ASEs，包括易怒和麻木感。我们的数据分析方法彻底改变了对新部署药物相关未报告的ASEs的检测，利用前沿的人工智能驱动社交媒体分析。它可以通过释放社交媒体的力量来支持监管机构和制造商在市场上增加新药的安全性。

    arXiv:2404.01358v1 Announce Type: cross  Abstract: Adverse side effects (ASEs) of drugs, revealed after FDA approval, pose a threat to patient safety. To promptly detect overlooked ASEs, we developed a digital health methodology capable of analyzing massive public data from social media, published clinical research, manufacturers' reports, and ChatGPT. We uncovered ASEs associated with the glucagon-like peptide 1 receptor agonists (GLP-1 RA), a market expected to grow exponentially to $133.5 billion USD by 2030. Using a Named Entity Recognition (NER) model, our method successfully detected 21 potential ASEs overlooked upon FDA approval, including irritability and numbness. Our data-analytic approach revolutionizes the detection of unreported ASEs associated with newly deployed drugs, leveraging cutting-edge AI-driven social media analytics. It can increase the safety of new drugs in the marketplace by unlocking the power of social media to support regulators and manufacturers in the ra
    
[^95]: 输入扰动对鲁棒准确公平性的双刃剑

    The Double-Edged Sword of Input Perturbations to Robust Accurate Fairness

    [https://arxiv.org/abs/2404.01356](https://arxiv.org/abs/2404.01356)

    该论文研究了深度神经网络对敌对输入扰动的敏感性，提出了新的鲁棒准确公平性定义，并介绍了一种敌对攻击方法和相应的解决方案。

    

    深度神经网络(DNNs)被认为对敌对输入扰动敏感，导致预测的准确性或个体公平性降低。为了共同表征预测准确性和个体公平性对敌对扰动的敏感性，我们引入了一个名为鲁棒准确公平性的新定义。鲁棒准确公平性要求当实例及其相似对应物受到输入扰动时，预测与地面事实一致。我们提出一种敌对攻击方法RAFair，以暴露DNN中的虚假或偏见敌对缺陷，这些缺陷会欺骗准确性或损害个体公平性。然后，我们展示这样的敌对实例可以通过精心设计的良性扰动有效地解决，从而使它们的预测准确而公平。我们的工作探讨了输入对准确公平性的双刃剑。

    arXiv:2404.01356v1 Announce Type: cross  Abstract: Deep neural networks (DNNs) are known to be sensitive to adversarial input perturbations, leading to a reduction in either prediction accuracy or individual fairness. To jointly characterize the susceptibility of prediction accuracy and individual fairness to adversarial perturbations, we introduce a novel robustness definition termed robust accurate fairness. Informally, robust accurate fairness requires that predictions for an instance and its similar counterparts consistently align with the ground truth when subjected to input perturbations. We propose an adversarial attack approach dubbed RAFair to expose false or biased adversarial defects in DNN, which either deceive accuracy or compromise individual fairness. Then, we show that such adversarial instances can be effectively addressed by carefully designed benign perturbations, correcting their predictions to be accurate and fair. Our work explores the double-edged sword of input 
    
[^96]: 用于边缘应用的LLM高效提取方法

    Efficiently Distilling LLMs for Edge Applications

    [https://arxiv.org/abs/2404.01353](https://arxiv.org/abs/2404.01353)

    提出了一种名为MLFS的新方法，用于高效参数的超网络训练，可以获得适用于商业边缘应用的高质量编码器模型，并有效地减少训练时间。

    

    在工业应用中，LLMs的超网络训练具有很大的重要性，因为它赋予了以固定成本产生不同大小/延迟模型的能力。我们提出了一种名为MLFS的新方法，用于高效参数的超网络训练。我们展示了可以获得适用于商业边缘应用的高质量编码器模型，并且虽然仅解码器模型对压缩具有相当的抵抗力，但可以有效地对解码器进行切片以大幅减少训练时间。

    arXiv:2404.01353v1 Announce Type: cross  Abstract: Supernet training of LLMs is of great interest in industrial applications as it confers the ability to produce a palette of smaller models at constant cost, regardless of the number of models (of different size / latency) produced. We propose a new method called Multistage Low-rank Fine-tuning of Super-transformers (MLFS) for parameter-efficient supernet training. We show that it is possible to obtain high-quality encoder models that are suitable for commercial edge applications, and that while decoder-only models are resistant to a comparable degree of compression, decoders can be effectively sliced for a significant reduction in training time.
    
[^97]: VortexViz: 通过学习粒子轨迹来发现涡旋边界

    VortexViz: Finding Vortex Boundaries by Learning from Particle Trajectories

    [https://arxiv.org/abs/2404.01352](https://arxiv.org/abs/2404.01352)

    通过将粒子轨迹纳入学习过程，该方法旨在通过利用流线或路径线捕获的流场的区域/局部特征来提高涡旋边界提取的准确性。

    

    涡旋在各种科学学科中都得到了研究，在提供流体流动行为洞察的同时，可视化涡旋的边界对于理解流动现象和检测流动不规则性至关重要。本文解决了使用深度学习技术准确提取涡旋边界的挑战。虽然现有方法主要是基于速度分量进行训练，我们提出了一种新颖的方法，将粒子轨迹（流线或路径线）纳入学习过程。通过利用流线或路径线捕获的流场的区域/局部特征，我们的方法旨在增强涡旋边界提取的准确性。

    arXiv:2404.01352v1 Announce Type: cross  Abstract: Vortices are studied in various scientific disciplines, offering insights into fluid flow behavior. Visualizing the boundary of vortices is crucial for understanding flow phenomena and detecting flow irregularities. This paper addresses the challenge of accurately extracting vortex boundaries using deep learning techniques. While existing methods primarily train on velocity components, we propose a novel approach incorporating particle trajectories (streamlines or pathlines) into the learning process. By leveraging the regional/local characteristics of the flow field captured by streamlines or pathlines, our methodology aims to enhance the accuracy of vortex boundary extraction.
    
[^98]: AETTA: 无标签准确性估计用于测试时适应

    AETTA: Label-Free Accuracy Estimation for Test-Time Adaptation

    [https://arxiv.org/abs/2404.01351](https://arxiv.org/abs/2404.01351)

    提出了AETTA，一种用于测试时适应的无标签准确性估计算法，通过预测不一致性来改进准确性估计并在适应失败情况下展现更高的准确性估计。

    

    测试时适应（TTA）已经成为一种可行的解决方案，利用无标签测试数据来使预训练模型适应领域偏移。然而，TTA面临着适应失败的挑战，因为在动态场景中它依赖于对未知测试样本的盲目适应。传统的用于评估检测性能的方法在TTA背景下受到限制，因为它们对于无标签数据或重新训练模型有着不切实际的假设。为了解决这个问题，我们提出了AETTA，一个用于TTA的无标签准确性估计算法。我们提出了预测不一致性作为准确性估计，通过比较目标模型预测和dropout推断来计算。然后，我们改进了预测不一致性以扩展AETTA在适应失败下的适用性。我们对四个基线和六种TTA方法进行了广泛评估，结果显示AETTA相比于其他方法平均提高了19.8%的准确性估计。

    arXiv:2404.01351v1 Announce Type: cross  Abstract: Test-time adaptation (TTA) has emerged as a viable solution to adapt pre-trained models to domain shifts using unlabeled test data. However, TTA faces challenges of adaptation failures due to its reliance on blind adaptation to unknown test samples in dynamic scenarios. Traditional methods for out-of-distribution performance estimation are limited by unrealistic assumptions in the TTA context, such as requiring labeled data or re-training models. To address this issue, we propose AETTA, a label-free accuracy estimation algorithm for TTA. We propose the prediction disagreement as the accuracy estimate, calculated by comparing the target model prediction with dropout inferences. We then improve the prediction disagreement to extend the applicability of AETTA under adaptation failures. Our extensive evaluation with four baselines and six TTA methods demonstrates that AETTA shows an average of 19.8%p more accurate estimation compared with 
    
[^99]: 大型语言模型中的公平性：一个分类调查

    Fairness in Large Language Models: A Taxonomic Survey

    [https://arxiv.org/abs/2404.01349](https://arxiv.org/abs/2404.01349)

    该调查总结了大型语言模型中公平性的最新进展，包括对偏见因素的分析、公平度量和现有算法分类。

    

    大型语言模型（LLMs）在各个领域展现了显著的成功。然而，尽管它们在许多实际应用中表现出色，大多数这些算法缺乏公平性考虑。因此，它们可能导致针对某些社区，特别是边缘化人群的歧视性结果，促使对公平的LLMs进行广泛研究。与传统机器学习中的公平相反，在LLMs中的公平性涉及独特的背景、分类法和实现技术。为此，该调查提供了关于公平LLMs的现有文献研究进展的全面概述。具体来说，提供了有关LLMs的简要介绍，接着分析了导致LLMs偏见的因素。此外，分类讨论了LLMs中的公平概念，总结了评估LLMs偏见的指标和现有算法。

    arXiv:2404.01349v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated remarkable success across various domains. However, despite their promising performance in numerous real-world applications, most of these algorithms lack fairness considerations. Consequently, they may lead to discriminatory outcomes against certain communities, particularly marginalized populations, prompting extensive study in fair LLMs. On the other hand, fairness in LLMs, in contrast to fairness in traditional machine learning, entails exclusive backgrounds, taxonomies, and fulfillment techniques. To this end, this survey presents a comprehensive overview of recent advances in the existing literature concerning fair LLMs. Specifically, a brief introduction to LLMs is provided, followed by an analysis of factors contributing to bias in LLMs. Additionally, the concept of fairness in LLMs is discussed categorically, summarizing metrics for evaluating bias in LLMs and existing algorithms 
    
[^100]: CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs

    CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs

    [https://arxiv.org/abs/2404.01343](https://arxiv.org/abs/2404.01343)

    CHOPS提出了一个名为CHOPS的LLM代理，旨在更高效地利用现有数据库或系统来访问用户信息，提供准确合理的响应或执行所需操作，同时避免有害操作。

    

    商业和软件平台越来越倾向于使用像GPT-3.5、GPT-4、GLM-3和LLaMa-2这样的大型语言模型（LLMs）作为客户服务的聊天辅助或推理代理。然而，当前基于LLM的客户服务模型在与客户配置文件的集成方面存在局限，并且缺乏有效服务所需的操作能力。为了解决这些问题，我们提出了一个名为CHOPS（CHat with custOmer Profile in existing System）的LLM代理，旨在：（1）高效利用现有数据库或系统以访问用户信息或按照现有指南与这些系统交互；（2）提供准确合理的响应或在系统中执行所需操作，同时避免有害操作；（3）利用

    arXiv:2404.01343v1 Announce Type: cross  Abstract: Businesses and software platforms are increasingly turning to Large Language Models (LLMs) such as GPT-3.5, GPT-4, GLM-3, and LLaMa-2 for chat assistance with file access or as reasoning agents for customer service. However, current LLM-based customer service models have limited integration with customer profiles and lack the operational capabilities necessary for effective service. Moreover, existing API integrations emphasize diversity over the precision and error avoidance essential in real-world customer service scenarios. To address these issues, we propose an LLM agent named CHOPS (CHat with custOmer Profile in existing System), designed to: (1) efficiently utilize existing databases or systems for accessing user information or interacting with these systems following existing guidelines; (2) provide accurate and reasonable responses or carry out required operations in the system while avoiding harmful operations; and (3) leverag
    
[^101]: DiffAgent：使用大语言模型实现快速准确的文本到图像API选择

    DiffAgent: Fast and Accurate Text-to-Image API Selection with Large Language Model

    [https://arxiv.org/abs/2404.01342](https://arxiv.org/abs/2404.01342)

    DiffAgent利用大语言模型设计了一个新的代理工具，能够快速准确地选择最适合的文本到图像API，并提出了一个综合数据集DABench来评估其性能。

    

    文本到图像（T2I）生成模型引起了广泛关注，并在学术研究以及其他领域找到了广泛应用。本文中，我们从大语言模型（LLMs）的工具使用研究中汲取灵感，引入了DiffAgent，这是一个经过设计用于通过API调用在几秒钟内进行准确选择的LLM代理。DiffAgent利用了一种全新的两阶段训练框架SFTA，使其能够根据用户偏好精确地将T2I API响应与用户输入对齐。为了训练和评估DiffAgent的能力，我们提出了DABench，这是一个包含大量T2I API的综合数据集，来自社区。

    arXiv:2404.01342v1 Announce Type: cross  Abstract: Text-to-image (T2I) generative models have attracted significant attention and found extensive applications within and beyond academic research. For example, the Civitai community, a platform for T2I innovation, currently hosts an impressive array of 74,492 distinct models. However, this diversity presents a formidable challenge in selecting the most appropriate model and parameters, a process that typically requires numerous trials. Drawing inspiration from the tool usage research of large language models (LLMs), we introduce DiffAgent, an LLM agent designed to screen the accurate selection in seconds via API calls. DiffAgent leverages a novel two-stage training framework, SFTA, enabling it to accurately align T2I API responses with user input in accordance with human preferences. To train and evaluate DiffAgent's capabilities, we present DABench, a comprehensive dataset encompassing an extensive range of T2I APIs from the community. 
    
[^102]: 块对角引导的DBSCAN聚类

    Block-Diagonal Guided DBSCAN Clustering

    [https://arxiv.org/abs/2404.01341](https://arxiv.org/abs/2404.01341)

    该研究提出了一种改进版本的DBSCAN，利用相似性图的块对角属性引导聚类过程，通过构建块对角图并进行聚类排序，易于确定聚类结构。

    

    集群分析在数据库挖掘中起着至关重要的作用，而在这一领域中最广泛使用的算法之一是DBSCAN。然而，DBSCAN存在一些局限性，例如难以处理高维大规模数据、对输入参数敏感以及在产生聚类结果时缺乏稳健性。本文引入了一种改进版本的DBSCAN，利用了相似性图的块对角属性来引导DBSCAN的聚类过程。其关键思想是构建一个图，衡量高维大规模数据点之间的相似性，并有可能通过未知置换转换为块对角形式，随后通过一个聚类排序过程来生成期望的置换。聚类结构可以通过识别置换后图中的对角块来轻松确定。我们提出了一种基于梯度下降的方法来解决这个问题。

    arXiv:2404.01341v1 Announce Type: cross  Abstract: Cluster analysis plays a crucial role in database mining, and one of the most widely used algorithms in this field is DBSCAN. However, DBSCAN has several limitations, such as difficulty in handling high-dimensional large-scale data, sensitivity to input parameters, and lack of robustness in producing clustering results. This paper introduces an improved version of DBSCAN that leverages the block-diagonal property of the similarity graph to guide the clustering procedure of DBSCAN. The key idea is to construct a graph that measures the similarity between high-dimensional large-scale data points and has the potential to be transformed into a block-diagonal form through an unknown permutation, followed by a cluster-ordering procedure to generate the desired permutation. The clustering structure can be easily determined by identifying the diagonal blocks in the permuted graph. We propose a gradient descent-based method to solve the propose
    
[^103]: 从相似到优越：时间序列预测的通道聚类

    From Similarity to Superiority: Channel Clustering for Time Series Forecasting

    [https://arxiv.org/abs/2404.01340](https://arxiv.org/abs/2404.01340)

    通过对通道进行聚类，实现了一种新颖的通道策略，有效平衡了个体通道处理和通道之间必要交互作用，从而提高了时间序列预测性能。

    

    时间序列预测在最近几十年吸引了很多关注。先前的研究表明，独立通道策略通过单独处理不同通道来提高预测性能，但在未知实例上导致了差劲的泛化，并忽略了通道之间潜在的必要交互作用。相反，依赖通道策略将所有通道混合在一起，甚至包含无关紧要和随意的信息，然而这会导致过度平滑的问题并限制了预测的准确性。目前缺乏一种能够有效平衡个体通道处理以提高预测性能而又不忽视通道之间必要交互作用的通道策略。受到我们观察到的时间序列模型练习提高对混合通道的结果与一对通道之间本质相似性之间的关联的启发，我们开发了一种新颖且适应性的方法

    arXiv:2404.01340v1 Announce Type: cross  Abstract: Time series forecasting has attracted significant attention in recent decades. Previous studies have demonstrated that the Channel-Independent (CI) strategy improves forecasting performance by treating different channels individually, while it leads to poor generalization on unseen instances and ignores potentially necessary interactions between channels. Conversely, the Channel-Dependent (CD) strategy mixes all channels with even irrelevant and indiscriminate information, which, however, results in oversmoothing issues and limits forecasting accuracy. There is a lack of channel strategy that effectively balances individual channel treatment for improved forecasting performance without overlooking essential interactions between channels. Motivated by our observation of a correlation between the time series model's performance boost against channel mixing and the intrinsic similarity on a pair of channels, we developed a novel and adapt
    
[^104]: 通过零-shot情绪和不流畅生成实现人性化语音合成

    Humane Speech Synthesis through Zero-Shot Emotion and Disfluency Generation

    [https://arxiv.org/abs/2404.01339](https://arxiv.org/abs/2404.01339)

    该论文实现了一种新颖的语音合成技术，通过零-shot设置中引入人类情感和不流畅特征，使得系统能更好地模仿人类语音，促进更自然的用户互动。

    

    当代对话系统往往存在一个重要局限性：它们的回应缺乏人类交互的情感深度和不流畅特征。这种缺失在用户寻求更个性化和有共情的互动时尤为明显。因此，这使它们显得机械化，难以引起人类用户的共鸣。认识到这一差距，我们着手于人性化机器通信的旅程，以确保AI系统不仅理解而且共鸣。为了解决这一缺点，我们设计了一种创新的语音合成流程。在这一框架内，一种先进的语言模型在零-shot设置中引入了类似人类的情感和语言紊乱。这些复杂性通过语言模型在文本生成期间无缝集成到生成文本中，使系统更好地模仿人类语音模式，促进更直观和自然的用户互动。

    arXiv:2404.01339v1 Announce Type: cross  Abstract: Contemporary conversational systems often present a significant limitation: their responses lack the emotional depth and disfluent characteristic of human interactions. This absence becomes particularly noticeable when users seek more personalized and empathetic interactions. Consequently, this makes them seem mechanical and less relatable to human users. Recognizing this gap, we embarked on a journey to humanize machine communication, to ensure AI systems not only comprehend but also resonate. To address this shortcoming, we have designed an innovative speech synthesis pipeline. Within this framework, a cutting-edge language model introduces both human-like emotion and disfluencies in a zero-shot setting. These intricacies are seamlessly integrated into the generated text by the language model during text generation, allowing the system to mirror human speech patterns better, promoting more intuitive and natural user interactions. The
    
[^105]: FineFake：一个用于细粒度多领域假新闻检测的知识增强数据集

    FineFake: A Knowledge-Enriched Dataset for Fine-Grained Multi-Domain Fake News Detecction

    [https://arxiv.org/abs/2404.01336](https://arxiv.org/abs/2404.01336)

    FineFake 数据集为细粒度多领域假新闻检测提供了知识增强，包含16,909个数据样本覆盖六个语义主题和八个平台。

    

    现有的假新闻检测基准数据集在评估新闻内容的真实性方面取得了显著进展。然而，这些基准数据集通常仅关注单一语义主题的新闻或来自单一平台的新闻，因此无法捕捉真实场景中多领域新闻的多样性。为了了解不同领域的假新闻，外部知识和细粒度注释至关重要，以提供精确证据并揭示制造假新闻的多样潜在策略，而这也是现有基准数据集所忽略的。为了填补这一空白，我们引入了一个名为FineFake的新型多领域知识增强基准数据集，具有细粒度注释。FineFake涵盖了来自六个语义主题和八个平台的16,909个数据样本。每个新闻项目都包含多模态内容、潜在社交背景、半自动

    arXiv:2404.01336v1 Announce Type: cross  Abstract: Existing benchmarks for fake news detection have significantly contributed to the advancement of models in assessing the authenticity of news content. However, these benchmarks typically focus solely on news pertaining to a single semantic topic or originating from a single platform, thereby failing to capture the diversity of multi-domain news in real scenarios. In order to understand fake news across various domains, the external knowledge and fine-grained annotations are indispensable to provide precise evidence and uncover the diverse underlying strategies for fabrication, which are also ignored by existing benchmarks. To address this gap, we introduce a novel multi-domain knowledge-enhanced benchmark with fine-grained annotations, named \textbf{FineFake}. FineFake encompasses 16,909 data samples spanning six semantic topics and eight platforms. Each news item is enriched with multi-modal content, potential social context, semi-man
    
[^106]: 建筑设计的生成式人工智能：文献综述

    Generative AI for Architectural Design: A Literature Review

    [https://arxiv.org/abs/2404.01335](https://arxiv.org/abs/2404.01335)

    生成式人工智能在建筑设计中开创了新的方法论范式，显著扩展了设计过程的创新潜力和效率，通过广泛应用生成式AI技术和深度生成模型生成2D图像、视频和3D模型，并审视其在不同阶段的影响趋势。

    

    arXiv:2404.01335v1 公告类型：跨越 摘要：生成式人工智能（AI）在建筑设计中开创了新的方法论范式，显著扩展了设计过程的创新潜力和效率。本文探讨了生成式人工智能技术在建筑设计中的广泛应用，这一趋势受益于深度生成模型的快速发展。文章全面回顾了生成式人工智能和大规模模型的基本原理，并突出了在生成2D图像、视频和3D模型方面的应用。此外，通过审查来自2020年的最新文献，本文审视了生成式人工智能技术在建筑设计的不同阶段的影响，从生成初始建筑3D形式到生成最终建筑图像。研究增长的明显趋势表明建筑设计领域对生成式人工智能技术的倾向不断增长。

    arXiv:2404.01335v1 Announce Type: cross  Abstract: Generative Artificial Intelligence (AI) has pioneered new methodological paradigms in architectural design, significantly expanding the innovative potential and efficiency of the design process. This paper explores the extensive applications of generative AI technologies in architectural design, a trend that has benefited from the rapid development of deep generative models. This article provides a comprehensive review of the basic principles of generative AI and large-scale models and highlights the applications in the generation of 2D images, videos, and 3D models. In addition, by reviewing the latest literature from 2020, this paper scrutinizes the impact of generative AI technologies at different stages of architectural design, from generating initial architectural 3D forms to producing final architectural imagery. The marked trend of research growth indicates an increasing inclination within the architectural design community towa
    
[^107]: 等等，这都是令牌噪音？一直就是吗：利用 Shapley 值解释 LLM 行为

    Wait, It's All Token Noise? Always Has Been: Interpreting LLM Behavior Using Shapley Value

    [https://arxiv.org/abs/2404.01332](https://arxiv.org/abs/2404.01332)

    使用Shapley值方法解释LLM行为，揭示了所谓的“令牌噪音”效应，揭示了LLMs的决策在很大程度上受到提示组件的影响

    

    大型语言模型（LLMs）的出现为模拟人类行为和认知过程开辟了新的可能性，潜在应用包括市场研究和消费者行为分析等各个领域。然而，由于LLMs的显著差异暗示了不同的基础过程在起作用，以及LLMs对提示变化的敏感性，利用LLMs作为人类主体的替代仍然存在不确定性。本文提出了一种基于合作博弈理论中Shapley值的新方法来解释LLM行为，并量化每个提示组件对模型输出的相对贡献。通过两个应用--一个离散选择实验和一个认知偏见调查，我们展示了Shapley值方法如何揭示我们所谓的“令牌噪音”效应，即LLM决策受到的影响严重偏向于

    arXiv:2404.01332v1 Announce Type: cross  Abstract: The emergence of large language models (LLMs) has opened up exciting possibilities for simulating human behavior and cognitive processes, with potential applications in various domains, including marketing research and consumer behavior analysis. However, the validity of utilizing LLMs as stand-ins for human subjects remains uncertain due to glaring divergences that suggest fundamentally different underlying processes at play and the sensitivity of LLM responses to prompt variations. This paper presents a novel approach based on Shapley values from cooperative game theory to interpret LLM behavior and quantify the relative contribution of each prompt component to the model's output. Through two applications-a discrete choice experiment and an investigation of cognitive biases-we demonstrate how the Shapley value method can uncover what we term "token noise" effects, a phenomenon where LLM decisions are disproportionately influenced by 
    
[^108]: LLaVA-Gemma：利用紧凑的语言模型加速多模态基础模型

    LLaVA-Gemma: Accelerating Multimodal Foundation Models with a Compact Language Model

    [https://arxiv.org/abs/2404.01331](https://arxiv.org/abs/2404.01331)

    使用最新发布的Gemma大型语言模型在LLaVA框架中训练了多模态基础模型，研究了预训练连接器、更强大的图像主干和增加语言主干大小对模型性能的影响。

    

    我们使用最新发布的Gemma大型语言模型（LLM）在流行的LLaVA框架中训练一系列多模态基础模型（MMFM）。特别值得关注的是2B参数的Gemma模型，它提供了构建功能强大的小规模MMFM的机会。与该领域其他论文的发现一致，我们测试了去除三种设计特性的影响：预训练连接器，利用更强大的图像主干，增加语言主干的大小。我们称之为LLaVA-Gemma的结果模型在一系列评估中表现出中等性能，但未能超越当前相对大小的SOTA模型。性能的更详细分析显示出不同的效果：跳过预训练往往会降低性能，更大的视觉模型有时会提高性能，增加语言模型的大小效果不一致。我们公开发布了训练配方，代码等。

    arXiv:2404.01331v1 Announce Type: cross  Abstract: We train a suite of multimodal foundation models (MMFM) using the popular LLaVA framework with the recently released Gemma family of large language models (LLMs). Of particular interest is the 2B parameter Gemma model, which provides opportunities to construct capable small-scale MMFMs. In line with findings from other papers in this space, we test the effect of ablating three design features: pretraining the connector, utilizing a more powerful image backbone, and increasing the size of the language backbone. The resulting models, which we call LLaVA-Gemma, exhibit moderate performance on an array of evaluations, but fail to improve past the current comparably sized SOTA models. Closer analysis of performance shows mixed effects; skipping pretraining tends to reduce performance, larger vision models sometimes improve performance, and increasing language model size has inconsistent effects. We publicly release training recipes, code an
    
[^109]: 无抽象能力的老年人数字包容娱乐聊天机器人

    Entertainment chatbot for the digital inclusion of elderly people without abstraction capabilities

    [https://arxiv.org/abs/2404.01327](https://arxiv.org/abs/2404.01327)

    EBER chatbot是一个旨在减少老年人数字鸿沟的娱乐聊天机器人，其创新之处在于其"智能电台"概念，根据用户的心情和需求提供相关信息。

    

    当前的语言处理技术允许创建对话式聊天机器人平台。尽管人工智能在许多大众市场领域仍然过于不成熟，无法支持令人满意的用户体验，但对话式界面已经在临时应用中找到了自己的位置，比如电话中心和在线购物助手。然而，目前还没有将其应用于老年人的社会包容，老年人特别容易受到数字鸿沟的影响。许多老年人通过传统媒体如电视和广播来减轻孤独感，这些媒体被认为是创造陪伴感的方式。在本文中，我们介绍了旨在减少老年人数字鸿沟的EBER聊天机器人。EBER会在后台阅读新闻，并根据用户的心情调整回复。其创新之处在于“智能电台”概念，根据该概念，不是简化数字信息系统以使其易于访问，而是根据用户的心情和需求提供相关信息。

    arXiv:2404.01327v1 Announce Type: cross  Abstract: Current language processing technologies allow the creation of conversational chatbot platforms. Even though artificial intelligence is still too immature to support satisfactory user experience in many mass market domains, conversational interfaces have found their way into ad hoc applications such as call centres and online shopping assistants. However, they have not been applied so far to social inclusion of elderly people, who are particularly vulnerable to the digital divide. Many of them relieve their loneliness with traditional media such as TV and radio, which are known to create a feeling of companionship. In this paper we present the EBER chatbot, designed to reduce the digital gap for the elderly. EBER reads news in the background and adapts its responses to the user's mood. Its novelty lies in the concept of "intelligent radio", according to which, instead of simplifying a digital information system to make it accessible to
    
[^110]: 对多模态大型语言与视觉模型的综述

    A Review of Multi-Modal Large Language and Vision Models

    [https://arxiv.org/abs/2404.01322](https://arxiv.org/abs/2404.01322)

    该论文对具有多模态能力的大型语言模型进行了综述，涵盖了LLMs的发展历程、transformer-based 架构的进展以及注意机制的作用

    

    大型语言模型（LLMs）最近成为研究和应用的焦点，其能够理解和生成具有类似于人类质量的文本，受到了推动。更近期，LLMs被扩展为多模态大型语言模型（MM-LLMs），将其能力扩展到处理图像、视频和音频信息，除了文本。这打开了诸如文本到视频生成、图像字幕、文本到语音等应用，并通过将LLM与多模态能力进行后期调整，或者从头开始构建MM-LLM来实现。本文全面回顾了具有多模态能力的当前LLMs以及最新的MM-LLMs的现状。它涵盖了LLMs的历史发展，特别是由transformer-based 架构如OpenAI的GPT系列和Google的BERT提供的进展，以及注意机制在增强中的作用

    arXiv:2404.01322v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have recently emerged as a focal point of research and application, driven by their unprecedented ability to understand and generate text with human-like quality. Even more recently, LLMs have been extended into multi-modal large language models (MM-LLMs) which extends their capabilities to deal with image, video and audio information, in addition to text. This opens up applications like text-to-video generation, image captioning, text-to-speech, and more and is achieved either by retro-fitting an LLM with multi-modal capabilities, or building a MM-LLM from scratch. This paper provides an extensive review of the current state of those LLMs with multi-modal capabilities as well as the very recent MM-LLMs. It covers the historical development of LLMs especially the advances enabled by transformer-based architectures like OpenAI's GPT series and Google's BERT, as well as the role of attention mechanisms in enh
    
[^111]: 基于图的无桩共享单车系统网络扩张优化

    Graph-Based Optimisation of Network Expansion in a Dockless Bike Sharing System

    [https://arxiv.org/abs/2404.01320](https://arxiv.org/abs/2404.01320)

    本研究利用Moby Bikes的行程数据构建了一个优化的地理时间图，揭示了在扩展共享单车系统时建立新站点的最佳位置，并利用Louvain算法揭示了展现相似使用模式的自包含子网络。

    

    自行车共享系统（BSSs）部署在全球一千多个城市，并在许多城市交通系统中发挥重要作用。BSSs缓解了拥堵，减少了污染并促进了体育锻炼。探索共享单车需求的时空模式以及影响这些模式的因素对于优化系统运营效率至关重要。本研究利用Moby Bikes的行程数据构建了一个优化的地理时间图。优化图的过程揭示了在将来扩展BSS时建立新站点的最佳位置。使用Louvain算法，一种社区检测技术，揭示了在不同时间粒度水平上的使用模式。社区检测结果揭示了在各自的时间粒度级别上表现出类似使用模式的主要自包含子网络。

    arXiv:2404.01320v1 Announce Type: cross  Abstract: Bike-sharing systems (BSSs) are deployed in over a thousand cities worldwide and play an important role in many urban transportation systems. BSSs alleviate congestion, reduce pollution and promote physical exercise. It is essential to explore the spatiotemporal patterns of bike-sharing demand, as well as the factors that influence these patterns, in order to optimise system operational efficiency. In this study, an optimised geo-temporal graph is constructed using trip data from Moby Bikes, a dockless BSS operator. The process of optimising the graph unveiled prime locations for erecting new stations during future expansions of the BSS. The Louvain algorithm, a community detection technique, is employed to uncover usage patterns at different levels of temporal granularity. The community detection results reveal largely self-contained sub-networks that exhibit similar usage patterns at their respective levels of temporal granularity. O
    
[^112]: 公共紧急事件下信息级联预测：一项调查

    Information Cascade Prediction under Public Emergencies: A Survey

    [https://arxiv.org/abs/2404.01319](https://arxiv.org/abs/2404.01319)

    大数据时代带来了公共紧急事件下信息级联预测的机遇，但应用领域限制了跨学科预测方法的统一框架，该调查论文系统分类和总结了这一领域，为研究人员提供了前沿研究和未来方向。

    

    随着大数据时代的到来，海量信息、专家经验和高准确度模型为公共紧急事件下信息级联预测带来了巨大机遇。然而，来自各个学科的专业知识的参与导致了信息级联预测主要集中在特定应用领域（如地震、洪灾、传染病）上。缺乏一个统一的预测框架对跨不同应用领域中的交叉预测方法的分类构成了挑战。本调查论文提供了信息级联建模、预测和应用的系统分类和总结。我们旨在帮助研究人员识别前沿研究，并理解公共紧急事件下信息级联预测的模型和方法。通过总结待解决问题并概述该领域的未来方向，本文对该领域的信息级联预测具有重要的参考价值。

    arXiv:2404.01319v1 Announce Type: cross  Abstract: With the advent of the era of big data, massive information, expert experience, and high-accuracy models bring great opportunities to the information cascade prediction of public emergencies. However, the involvement of specialist knowledge from various disciplines has resulted in a primarily application-specific focus (e.g., earthquakes, floods, infectious diseases) for information cascade prediction of public emergencies. The lack of a unified prediction framework poses a challenge for classifying intersectional prediction methods across different application fields. This survey paper offers a systematic classification and summary of information cascade modeling, prediction, and application. We aim to help researchers identify cutting-edge research and comprehend models and methods of information cascade prediction under public emergencies. By summarizing open issues and outlining future directions in this field, this paper has the p
    
[^113]: 在Transformer中智能学习率分布以减少灾难性遗忘

    Intelligent Learning Rate Distribution to reduce Catastrophic Forgetting in Transformers

    [https://arxiv.org/abs/2404.01317](https://arxiv.org/abs/2404.01317)

    本文研究了在Transformer神经网络中的灾难性遗忘问题，通过智能学习率分布取得了比平坦学习率更好的性能，并在GLUE数据集中得到验证。

    

    在自然语言处理中，对大型文本语料库进行语言模型的预训练是一种常见做法。然后对这些模型进行微调以在各种任务上取得最佳结果。本文研究了Transformer神经网络中灾难性遗忘的问题，并质疑在这种情况下对整个网络采用相同学习率的微调常见做法。我们进行了超参数优化过程，找到了比平坦学习率更好的学习率分布。我们结合这些学习率分布，并展示它们对灾难性遗忘问题的性能表现更好。我们使用GLUE数据集中的各种自然语言处理基准验证了这些学习率分布。

    arXiv:2404.01317v1 Announce Type: cross  Abstract: Pretraining language models on large text corpora is a common practice in natural language processing. Fine-tuning of these models is then performed to achieve the best results on a variety of tasks. In this paper, we investigate the problem of catastrophic forgetting in transformer neural networks and question the common practice of fine-tuning with a flat learning rate for the entire network in this context. We perform a hyperparameter optimization process to find learning rate distributions that are better than a flat learning rate. We combine the learning rate distributions thus found and show that they generalize to better performance with respect to the problem of catastrophic forgetting. We validate these learning rate distributions with a variety of NLP benchmarks from the GLUE dataset.
    
[^114]: 学习在不确定性下解决作业车间调度问题

    Learning to Solve Job Shop Scheduling under Uncertainty

    [https://arxiv.org/abs/2404.01308](https://arxiv.org/abs/2404.01308)

    该论文利用深度强化学习技术解决了具有不确定性的作业车间调度问题，重点在于提出了一种新颖方法来处理具有不确定持续时间的JSSP。

    

    作业车间调度问题（JSSP）是一个组合优化问题，其中任务需要在机器上进行调度，以最小化诸如最大完工时间或延迟等标准。为了解决更加现实的场景，我们为每个任务的持续时间关联了一个概率分布。我们的目标是生成一个稳健的调度，即最小化平均完工时间。本文引入了一种新方法，利用深度强化学习（DRL）技术来寻找稳健的解决方案，重点关注具有不确定持续时间的JSSP。本研究的关键贡献包括：（1）DRL在JSSP应用中的进展，增强泛化性和可伸缩性，（2）一种新颖的方法来解决具有不确定持续时间的JSSP。 Wheatley方法，集成了图神经网络（GNNs）和DRL，已公开可用于进一步的研究和应用。

    arXiv:2404.01308v1 Announce Type: new  Abstract: Job-Shop Scheduling Problem (JSSP) is a combinatorial optimization problem where tasks need to be scheduled on machines in order to minimize criteria such as makespan or delay. To address more realistic scenarios, we associate a probability distribution with the duration of each task. Our objective is to generate a robust schedule, i.e. that minimizes the average makespan. This paper introduces a new approach that leverages Deep Reinforcement Learning (DRL) techniques to search for robust solutions, emphasizing JSSPs with uncertain durations. Key contributions of this research include: (1) advancements in DRL applications to JSSPs, enhancing generalization and scalability, (2) a novel method for addressing JSSPs with uncertain durations. The Wheatley approach, which integrates Graph Neural Networks (GNNs) and DRL, is made publicly available for further research and applications.
    
[^115]: IsoBench：基于同构表示对多模态基础模型进行基准测试

    IsoBench: Benchmarking Multimodal Foundation Models on Isomorphic Representations

    [https://arxiv.org/abs/2404.01266](https://arxiv.org/abs/2404.01266)

    IsoBench提出了一个基准数据集，用于评估基于不同同构表示的多模态基础模型的性能差异，发现大多数模型更偏好文本表示。

    

    当前的基础模型在仅文本或图像和文本输入同时提示时表现出令人印象深刻的能力。但它们的能力是否会根据输入方式而改变呢？在这项工作中，我们提出了一个名为$\textbf{IsoBench}$的基准数据集，其中包含来自四个主要领域的问题: 数学、科学、算法和游戏。每个示例呈现了多个输入的同构表示，如视觉、文本和数学展示。IsoBench提供了细粒度的反馈，以诊断由表示形式造成的性能差距。在各种基础模型中，我们观察到在相同问题上，模型一贯偏好文本表示。最突出的是，在所有IsoBench问题上进行评估时，Claude-3 Opus在提供图像而不是文本时性能下降28.7分；同样，GPT-4 Turbo性能下降18.7分，Gemini Pro下降14.9分。

    arXiv:2404.01266v1 Announce Type: new  Abstract: Current foundation models exhibit impressive capabilities when prompted either with text only or with both image and text inputs. But do their capabilities change depending on the input modality? In this work, we propose $\textbf{IsoBench}$, a benchmark dataset containing problems from four major areas: math, science, algorithms, and games. Each example is presented with multiple $\textbf{isomorphic representations}$ of inputs, such as visual, textual, and mathematical presentations. IsoBench provides fine-grained feedback to diagnose performance gaps caused by the form of the representation. Across various foundation models, we observe that on the same problem, models have a consistent preference towards textual representations. Most prominently, when evaluated on all IsoBench problems, Claude-3 Opus performs 28.7 points worse when provided with images instead of text; similarly, GPT-4 Turbo is 18.7 points worse and Gemini Pro is 14.9 p
    
[^116]: 语言模型奖励下的视频大型多模态模型直接偏好优化

    Direct Preference Optimization of Video Large Multimodal Models from Language Model Reward

    [https://arxiv.org/abs/2404.01258](https://arxiv.org/abs/2404.01258)

    本研究提出了一种新的框架，利用详细的视频标题作为视频内容的代理，使得语言模型在评分视频问答（QA）预测时能够融入这些信息作为支持证据。

    

    偏好建模技术，如直接偏好优化（DPO），已证明在增强大型语言模型（LLM）的泛化能力方面是有效的。然而，在涉及视频指令跟随的任务中，提供信息丰富的反馈，特别是用于检测生成的响应中的幻觉，仍然是一个重要挑战。先前的研究已经探讨了使用大型多模态模型（LMM）作为奖励模型来指导偏好建模，但它们准确评估生成响应的事实性与对应视频相比的能力尚未得出结论。本文介绍了一个新颖的框架，利用详细的视频标题作为视频内容的代理，使语言模型能够将这些信息作为支持证据来为视频问答（QA）预测打分。我们的方法表现出与OpenAI GPT-4V模型的奖励机制的稳健对齐

    arXiv:2404.01258v1 Announce Type: cross  Abstract: Preference modeling techniques, such as direct preference optimization (DPO), has shown effective in enhancing the generalization abilities of large language model (LLM). However, in tasks involving video instruction-following, providing informative feedback, especially for detecting hallucinations in generated responses, remains a significant challenge. Previous studies have explored using large large multimodal models (LMMs) as reward models to guide preference modeling, but their ability to accurately assess the factuality of generated responses compared to corresponding videos has not been conclusively established. This paper introduces a novel framework that utilizes detailed video captions as a proxy of video content, enabling language models to incorporate this information as supporting evidence for scoring video Question Answering (QA) predictions. Our approach demonstrates robust alignment with OpenAI GPT-4V model's reward mec
    
[^117]: LLM可以在不透露私人信息的情况下获得其他LLM的帮助吗？

    Can LLMs get help from other LLMs without revealing private information?

    [https://arxiv.org/abs/2404.01041](https://arxiv.org/abs/2404.01041)

    本研究展示了在级联系统中运用隐私保护技术的可行性，以减少在查询远程模型时泄漏私人信息的风险，并引入了两个隐私度量。

    

    级联是一种常见类型的机器学习系统，其中如果本地模型无法单独准确标记用户数据，则可以查询一个大型的远程模型。对于大型语言模型（LLMs），由于其在显著降低推断成本的同时保持任务性能的能力，服务堆栈越来越多地使用级联。然而，在本地模型可以访问敏感数据的情况下应用级联系统构成用户的重大隐私风险，因为这些数据可能被转发到远程模型。在这项工作中，我们展示了在此类设置中应用级联系统的可行性，方法是为本地模型配备隐私保护技术，从而减少访问远程模型时泄漏私人信息的风险。为了量化此类设置中的信息泄漏，我们引入了两个隐私度量。然后，我们提出了一个利用最近引入的社交学习范式的系统

    arXiv:2404.01041v1 Announce Type: cross  Abstract: Cascades are a common type of machine learning systems in which a large, remote model can be queried if a local model is not able to accurately label a user's data by itself. Serving stacks for large language models (LLMs) increasingly use cascades due to their ability to preserve task performance while dramatically reducing inference costs. However, applying cascade systems in situations where the local model has access to sensitive data constitutes a significant privacy risk for users since such data could be forwarded to the remote model. In this work, we show the feasibility of applying cascade systems in such setups by equipping the local model with privacy-preserving techniques that reduce the risk of leaking private information when querying the remote model. To quantify information leakage in such setups, we introduce two privacy measures. We then propose a system that leverages the recently introduced social learning paradigm 
    
[^118]: 文本到图像生成中的偏见调查：定义、评估和缓解

    Survey of Bias In Text-to-Image Generation: Definition, Evaluation, and Mitigation

    [https://arxiv.org/abs/2404.01030](https://arxiv.org/abs/2404.01030)

    该调查综述了文本到图像生成中的偏见问题，重点讨论了性别、肤色和地域文化这些方面，旨在帮助理解当前进展和研究空白。

    

    最近强大的大型模型，如OpenAI的DALLE-3和Google的Gemini，使得用户能够从文本提示生成高质量图像。然而，即使是简单的提示也可能导致文本到图像模型在生成的图像中展现明显的社会偏见。这种偏见可能会导致社会中的分配和代表性伤害，进一步边缘化少数群体。鉴于这一问题，最近有大量研究致力于调查文本到图像系统中偏见的不同维度。然而，对这些研究的全面回顾仍然缺乏，阻碍了对当前进展和研究空白的系统性理解。我们提出了关于文本到图像生成模型中偏见的第一次广泛调查。在这项调查中，我们回顾了先前关于偏见维度的研究：性别、肤色和地域文化。

    arXiv:2404.01030v1 Announce Type: cross  Abstract: The recent advancement of large and powerful models with Text-to-Image (T2I) generation abilities -- such as OpenAI's DALLE-3 and Google's Gemini -- enables users to generate high-quality images from textual prompts. However, it has become increasingly evident that even simple prompts could cause T2I models to exhibit conspicuous social bias in generated images. Such bias might lead to both allocational and representational harms in society, further marginalizing minority groups. Noting this problem, a large body of recent works has been dedicated to investigating different dimensions of bias in T2I systems. However, an extensive review of these studies is lacking, hindering a systematic understanding of current progress and research gaps. We present the first extensive survey on bias in T2I generative models. In this survey, we review prior studies on dimensions of bias: Gender, Skintone, and Geo-Culture. Specifically, we discuss how 
    
[^119]: DRCT：将图像超分辨率保存在信息瓶颈之外

    DRCT: Saving Image Super-resolution away from Information Bottleneck

    [https://arxiv.org/abs/2404.00722](https://arxiv.org/abs/2404.00722)

    基于Vision Transformer的DRCT方法采用创新的机制解决了图像超分辨率中空间信息衰减的问题，提升了模型性能。

    

    近年来，基于Vision Transformer的低层视觉任务应用取得了广泛的成功。与基于CNN的模型不同，Transformer更擅长捕捉长距离依赖关系，可以利用非局部区域的信息重建图像。在超分辨率领域，基于Swin Transformer的方法已经成为主流，因为它们能够捕捉全局空间信息，并且具有旋转窗口注意机制，有助于在不同窗口之间交换信息。许多研究人员通过扩大感知野或设计复杂网络来提高图像质量和网络效率，取得了令人称赞的结果。然而，我们观察到在前向传播过程中，由于深度增加，空间信息往往会减少，从而导致空间信息的丢失，并最终限制了模型的潜力。

    arXiv:2404.00722v1 Announce Type: cross  Abstract: In recent years, Vision Transformer-based applications to low-level vision tasks have achieved widespread success. Unlike CNN-based models, Transformers are more adept at capturing long-range dependencies, enabling the reconstruction of images utilizing information from non-local areas. In the domain of super-resolution, Swin-transformer-based approaches have become mainstream due to their capacity to capture global spatial information and their shifting-window attention mechanism that facilitates the interchange of information between different windows. Many researchers have enhanced image quality and network efficiency by expanding the receptive field or designing complex networks, yielding commendable results. However, we observed that spatial information tends to diminish during the forward propagation process due to increased depth, leading to a loss of spatial information and, consequently, limiting the model's potential. To addr
    
[^120]: LLM meets Vision-Language Models用于零样本单类分类

    LLM meets Vision-Language Models for Zero-Shot One-Class Classification

    [https://arxiv.org/abs/2404.00675](https://arxiv.org/abs/2404.00675)

    提出了一种两步解决方案，结合大型语言模型和视觉-语言预训练模型，用于零样本单类分类问题，并在实际基准测试中表现出优越性能。

    

    我们考虑零样本单类视觉分类问题。在这种情况下，仅目标类别的标签可用，并且目标是在不需要来自目标任务的任何验证示例的情况下区分正负查询样本。我们提出了一个两步解决方案，首先查询大型语言模型以查找在视觉上令人困惑的对象，然后依赖于视觉语言预训练模型（例如CLIP）进行分类。通过调整大规模视觉基准，我们展示了所提出的方法在此设置中优于自适应的现成替代方法的能力。具体而言，我们提出了一个实际的基准，其中负查询样本从与正查询样本相同的原始数据集中获取，包括iNaturalist的细粒度控制版本，其中负样本在分类树中与正样本相距固定距离。我们的工作表明，可以通过查询大型语言模型并依赖视觉-语言预训练模型来解决零样本单类分类问题。

    arXiv:2404.00675v1 Announce Type: cross  Abstract: We consider the problem of zero-shot one-class visual classification. In this setting, only the label of the target class is available, and the goal is to discriminate between positive and negative query samples without requiring any validation example from the target task. We propose a two-step solution that first queries large language models for visually confusing objects and then relies on vision-language pre-trained models (e.g., CLIP) to perform classification. By adapting large-scale vision benchmarks, we demonstrate the ability of the proposed method to outperform adapted off-the-shelf alternatives in this setting. Namely, we propose a realistic benchmark where negative query samples are drawn from the same original dataset as positive ones, including a granularity-controlled version of iNaturalist, where negative samples are at a fixed distance in the taxonomy tree from the positive ones. Our work shows that it is possible to 
    
[^121]: 学习生成条件化三平面用于3D感知表情可控肖像动画

    Learning to Generate Conditional Tri-plane for 3D-aware Expression Controllable Portrait Animation

    [https://arxiv.org/abs/2404.00636](https://arxiv.org/abs/2404.00636)

    本文提出了一种一次性的3D感知肖像动画方法Export3D，通过引入三平面生成器和对比预训练框架，实现了控制给定肖像图像的面部表情和摄像机视角，提供了一种新的表达方式。

    

    在本文中，我们提出了一种一次性的3D感知肖像动画方法Export3D，能够控制给定肖像图像的面部表情和摄像机视角。为了实现这一目标，我们引入了一个三平面生成器，通过将3DMM的表情参数转移到源图像中直接生成3D先验的三平面。然后，通过可微分体积渲染将三平面解码为不同视角的图像。现有的肖像动画方法严重依赖于图像变形来在运动空间中传输表情，挑战在外观和表情的分离上。相比之下，我们提出了一个用于无外观表情参数的对比预训练框架，消除了在传输跨身份表达时不良外观交换。大量实验证明，我们的预训练框架能够学习隐藏在3DMM中的无外观表达表示。

    arXiv:2404.00636v1 Announce Type: cross  Abstract: In this paper, we present Export3D, a one-shot 3D-aware portrait animation method that is able to control the facial expression and camera view of a given portrait image. To achieve this, we introduce a tri-plane generator that directly generates a tri-plane of 3D prior by transferring the expression parameter of 3DMM into the source image. The tri-plane is then decoded into the image of different view through a differentiable volume rendering. Existing portrait animation methods heavily rely on image warping to transfer the expression in the motion space, challenging on disentanglement of appearance and expression. In contrast, we propose a contrastive pre-training framework for appearance-free expression parameter, eliminating undesirable appearance swap when transferring a cross-identity expression. Extensive experiments show that our pre-training framework can learn the appearance-free expression representation hidden in 3DMM, and 
    
[^122]: AI法律和大型语言模型（LLMs）：当关键问题和隐私影响需要人类和道德监督时

    AI Act and Large Language Models (LLMs): When critical issues and privacy impact require human and ethical oversight

    [https://arxiv.org/abs/2404.00600](https://arxiv.org/abs/2404.00600)

    论文讨论了人类监督、道德监督和隐私影响评估在面对人工智能系统和大型语言模型发展中的重要性。

    

    人工智能系统的日益发展，特别是大型语言模型（LLM）的发展，使得有必要对它们在隐私、个人数据保护以及道德层面，尤其是对最脆弱和最弱势群体可能产生的风险和影响进行评估。本文对人类监督、道德监督和隐私影响评估进行了讨论。

    arXiv:2404.00600v1 Announce Type: cross  Abstract: The imposing evolution of artificial intelligence systems and, specifically, of Large Language Models (LLM) makes it necessary to carry out assessments of their level of risk and the impact they may have in the area of privacy, personal data protection and at an ethical level, especially on the weakest and most vulnerable. This contribution addresses human oversight, ethical oversight, and privacy impact assessment.
    
[^123]: 规划和编辑检索以增强工具学习

    Planning and Editing What You Retrieve for Enhanced Tool Learning

    [https://arxiv.org/abs/2404.00450](https://arxiv.org/abs/2404.00450)

    该论文提出了一种新颖的模型，结合了“规划与检索”和“编辑与确认”范式，通过神经检索模块和LLM-based查询规划器提高了工具利用的效果。

    

    最近在将外部工具与大型语言模型（LLMs）集成方面取得的进展打开了新的领域，应用范围涵盖数学推理、代码生成器和智能助手。然而，现有方法依赖简单的一次性检索策略，无法有效准确地筛选相关工具。本文介绍了一种新颖的“规划与检索（P&R）”和“编辑与确认（E&G）”范式的模型，包括了神经检索模块和基于LLM的查询规划器，以增强工具利用的效果。

    arXiv:2404.00450v1 Announce Type: new  Abstract: Recent advancements in integrating external tools with Large Language Models (LLMs) have opened new frontiers, with applications in mathematical reasoning, code generators, and smart assistants. However, existing methods, relying on simple one-time retrieval strategies, fall short on effectively and accurately shortlisting relevant tools. This paper introduces a novel \modelname (\modelmeaning) approach, encompassing ``Plan-and-Retrieve (P\&R)'' and ``Edit-and-Ground (E\&G)'' paradigms. The P\&R paradigm consists of a neural retrieval module for shortlisting relevant tools and an LLM-based query planner that decomposes complex queries into actionable tasks, enhancing the effectiveness of tool utilization. The E\&G paradigm utilizes LLMs to enrich tool descriptions based on user scenarios, bridging the gap between user queries and tool functionalities. Experiment results demonstrate that these paradigms significantly improve the recall an
    
[^124]: InfLoRA：无干扰的低秩自适应持续学习方法

    InfLoRA: Interference-Free Low-Rank Adaptation for Continual Learning

    [https://arxiv.org/abs/2404.00228](https://arxiv.org/abs/2404.00228)

    InfLoRA提出了一种新的PEFT方法，名为无干扰低秩自适应（InfLoRA），用于持续学习，旨在消除新任务对旧任务的干扰，帮助模型在稳定性和可塑性之间取得良好平衡。

    

    持续学习要求模型依次学习多个任务。在持续学习中，模型应具备在旧任务上维持性能（稳定性）和不断适应新任务的能力（可塑性）。最近，基于参数高效微调（PEFT）的持续学习方法变得越来越受欢迎。尽管现有基于PEFT的持续学习方法表现出比非PEFT方法更优秀的性能，但大多数方法并未考虑如何消除新任务对旧任务的干扰，从而阻碍模型在稳定性和可塑性之间取得良好平衡。本文提出了一种新的PEFT方法，称为无干扰低秩自适应（InfLoRA）方法，用于持续学习。

    arXiv:2404.00228v1 Announce Type: cross  Abstract: Continual learning requires the model to learn multiple tasks sequentially. In continual learning, the model should possess the ability to maintain its performance on old tasks (stability) and the ability to adapt to new tasks continuously (plasticity). Recently, parameter-efficient fine-tuning (PEFT), which involves freezing a pre-trained model and injecting a small number of learnable parameters to adapt to downstream tasks, has gained increasing popularity in continual learning. Although existing continual learning methods based on PEFT have demonstrated superior performance compared to those not based on PEFT, most of them do not consider how to eliminate the interference of the new task on the old tasks, which inhibits the model from making a good trade-off between stability and plasticity. In this work, we propose a new PEFT method, called interference-free low-rank adaptation (InfLoRA), for continual learning. InfLoRA injects a 
    
[^125]: LLM作为写作助手：探讨所有权感和推理的视角

    LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership and Reasoning

    [https://arxiv.org/abs/2404.00027](https://arxiv.org/abs/2404.00027)

    探讨使用大型语言模型作为写作助手引发的写作所有权感和作者身份认知之间的心理困境。

    

    写作中的所有权感限制了我们对思想、时间和贡献的投入，导致对产出物的依恋。然而，使用写作助手引入了一种心理困境，因为一些内容并非直接我们的创作。我们往往更倾向于在创造性任务中更多地归功于大型语言模型（LLMs），尽管它们对所有任务都是平等的。此外，虽然我们可能不会完全声称对由LLM生成的内容拥有所有权，但却自由地声称作者身份。我们进行了一项简短调查来研究这些问题，并了解潜在的认知过程，以更好地了解人机交互在写作中的应用并改进写作辅助系统。

    arXiv:2404.00027v1 Announce Type: cross  Abstract: Sense of ownership in writing confines our investment of thoughts, time, and contribution, leading to attachment to the output. However, using writing assistants introduces a mental dilemma, as some content isn't directly our creation. For instance, we tend to credit Large Language Models (LLMs) more in creative tasks, even though all tasks are equal for them. Additionally, while we may not claim complete ownership of LLM-generated content, we freely claim authorship. We conduct a short survey to examine these issues and understand underlying cognitive processes in order to gain a better knowledge of human-computer interaction in writing and improve writing aid systems.
    
[^126]: 墨水与个性：在LLMs时代塑造个性化叙事

    Ink and Individuality: Crafting a Personalised Narrative in the Age of LLMs

    [https://arxiv.org/abs/2404.00026](https://arxiv.org/abs/2404.00026)

    研究探讨了人们日益依赖的基于LLM的写作助手对创造力和个性可能造成的负面影响，旨在改进人机交互系统和提升写作助手的个性化和个性化功能。

    

    个性和个性化构成了使每个作家独特并影响其文字以有效吸引读者同时传达真实性的独特特征。然而，我们日益依赖基于LLM的写作助手可能会危及我们的创造力和个性。我们经常忽视这一趋势对我们的创造力和独特性的负面影响，尽管可能会造成后果。本研究通过进行简要调查探索不同的观点和概念，以及尝试理解人们的观点，结合以往在该领域的研究，来研究这些问题。解决这些问题对于改进人机交互系统和增强个性化和个性化写作助手至关重要。

    arXiv:2404.00026v1 Announce Type: cross  Abstract: Individuality and personalization comprise the distinctive characteristics that make each writer unique and influence their words in order to effectively engage readers while conveying authenticity. However, our growing reliance on LLM-based writing assistants risks compromising our creativity and individuality over time. We often overlook the negative impacts of this trend on our creativity and uniqueness, despite the possible consequences. This study investigates these concerns by performing a brief survey to explore different perspectives and concepts, as well as trying to understand people's viewpoints, in conjunction with past studies in the area. Addressing these issues is essential for improving human-computer interaction systems and enhancing writing assistants for personalization and individuality.
    
[^127]: 基于人工神经网络的植入神经接口实时分类ENG信号

    Artificial Neural Networks-based Real-time Classification of ENG Signals for Implanted Nerve Interfaces

    [https://arxiv.org/abs/2403.20234](https://arxiv.org/abs/2403.20234)

    本文探讨了基于人工神经网络的实时分类ENG信号的方法，通过比较ANNs在不同大小数据集上的表现来分析其在处理运动/感觉刺激分类任务中的可行性。

    

    神经病在临床环境中变得更加重要，因为它们有可能永久危及一个人的生命。为了支持患者的康复，使用完全植入式设备正成为最有前途的解决方案之一。然而，即使成为完全复杂神经纳米网络系统的一个组成部分，这些设备仍面临着诸多挑战。在本文中，我们解决其中之一，即运动/感觉刺激的分类问题。通过探索四种不同类型的人工神经网络（ANNs），从大鼠坐骨神经测量的电神经图（ENG）信号中提取各种感觉刺激来执行该任务。考虑不同大小的数据集以分析被调查的ANNs在实时分类中的可行性，通过比较它们在准确性、F1分数和预测时间方面的性能。

    arXiv:2403.20234v1 Announce Type: new  Abstract: Neuropathies are gaining higher relevance in clinical settings, as they risk permanently jeopardizing a person's life. To support the recovery of patients, the use of fully implanted devices is emerging as one of the most promising solutions. However, these devices, even if becoming an integral part of a fully complex neural nanonetwork system, pose numerous challenges. In this article, we address one of them, which consists of the classification of motor/sensory stimuli. The task is performed by exploring four different types of artificial neural networks (ANNs) to extract various sensory stimuli from the electroneurographic (ENG) signal measured in the sciatic nerve of rats. Different sizes of the data sets are considered to analyze the feasibility of the investigated ANNs for real-time classification through a comparison of their performance in terms of accuracy, F1-score, and prediction time. The design of the ANNs takes advantage of
    
[^128]: 通过视觉语言模型对神经网络进行基于概念的分析

    Concept-based Analysis of Neural Networks via Vision-Language Models

    [https://arxiv.org/abs/2403.19837](https://arxiv.org/abs/2403.19837)

    本文提出利用视觉语言模型作为透镜，通过其隐含的高层次概念来进行对视觉模型的分析。

    

    视觉深度神经网络（DNNs）的形式化分析非常可取，但由于难以表达视觉任务的形式化规范以及缺乏高效的验证程序，这是非常具有挑战性的。在本文中，我们提出利用新兴的多模态、视觉语言、基础模型（VLMs）作为一种通过其可以推理视觉模型的透镜。VLMs已经在大量图像及其文本描述上进行了训练，因此隐式地了解描述这些图像的高层次、人类可理解的概念。我们描述了一种名为$\texttt{Con}_{\texttt{spec}}$的逻辑规范语言，旨在便于按照这些概念编写规范。为了定义和形式化检查$\texttt{Con}_{\texttt{spec}}$规范，我们利用了一个VLM，它提供了一种编码和高效检查视觉模型的自然语言属性的方法。我们展示了我们的te

    arXiv:2403.19837v1 Announce Type: cross  Abstract: Formal analysis of vision-based deep neural networks (DNNs) is highly desirable but it is very challenging due to the difficulty of expressing formal specifications for vision tasks and the lack of efficient verification procedures. In this paper, we propose to leverage emerging multimodal, vision-language, foundation models (VLMs) as a lens through which we can reason about vision models. VLMs have been trained on a large body of images accompanied by their textual description, and are thus implicitly aware of high-level, human-understandable concepts describing the images. We describe a logical specification language $\texttt{Con}_{\texttt{spec}}$ designed to facilitate writing specifications in terms of these concepts. To define and formally check $\texttt{Con}_{\texttt{spec}}$ specifications, we leverage a VLM, which provides a means to encode and efficiently check natural-language properties of vision models. We demonstrate our te
    
[^129]: 知识边界与角色动态塑造更好的社交媒体代理

    Knowledge Boundary and Persona Dynamic Shape A Better Social Media Agent

    [https://arxiv.org/abs/2403.19275](https://arxiv.org/abs/2403.19275)

    通过个性化知识和动态角色信息构建社交媒体代理以解决代理拥有不属于其角色的知识和无法消除多样化角色信息干扰的问题。

    

    构建个性化和拟人化代理在社交网络模拟中具有重要意义。然而，现有作品中仍存在两个关键问题：代理拥有不属于其角色的世界知识，不能消除多样化角色信息对当前行为的干扰，从而降低了代理的个性化和拟人化。为了解决以上问题，我们基于个性化知识和动态角色信息构建社交媒体代理。对于个性化知识，我们添加外部知识源并将其与代理的角色信息匹配，从而赋予代理个性化的世界知识。对于动态角色信息，我们使用当前行为信息内部检索代理的角色信息，从而减少多样化角色信息对当前行为的干扰。

    arXiv:2403.19275v1 Announce Type: cross  Abstract: Constructing personalized and anthropomorphic agents holds significant importance in the simulation of social networks. However, there are still two key problems in existing works: the agent possesses world knowledge that does not belong to its personas, and it cannot eliminate the interference of diverse persona information on current actions, which reduces the personalization and anthropomorphism of the agent. To solve the above problems, we construct the social media agent based on personalized knowledge and dynamic persona information. For personalized knowledge, we add external knowledge sources and match them with the persona information of agents, thereby giving the agent personalized world knowledge. For dynamic persona information, we use current action information to internally retrieve the persona information of the agent, thereby reducing the interference of diverse persona information on the current action. To make the age
    
[^130]: ECoDepth: 有效调整扩散模型以用于单目深度估计

    ECoDepth: Effective Conditioning of Diffusion Models for Monocular Depth Estimation

    [https://arxiv.org/abs/2403.18807](https://arxiv.org/abs/2403.18807)

    通过使用预训练的ViT模型生成的全局图像先验，为单图深度估计模型提供更详细的上下文信息，并提出了一种新的使用扩散骨干且受ViT嵌入条件约束的深度估计模型。

    

    在缺乏视差线索的情况下，基于学习的单图深度估计（SIDE）模型严重依赖图像中的阴影和上下文线索。我们从已有研究的启发中探讨使用从预训练的ViT模型生成的全局图像先验，以提供更详细的上下文信息。基于这一想法，我们提出了一种新的使用扩散骨干的SIDE模型，其受到ViT嵌入的条件约束。

    arXiv:2403.18807v1 Announce Type: cross  Abstract: In the absence of parallax cues, a learning-based single image depth estimation (SIDE) model relies heavily on shading and contextual cues in the image. While this simplicity is attractive, it is necessary to train such models on large and varied datasets, which are difficult to capture. It has been shown that using embeddings from pre-trained foundational models, such as CLIP, improves zero shot transfer in several applications. Taking inspiration from this, in our paper we explore the use of global image priors generated from a pre-trained ViT model to provide more detailed contextual information. We argue that the embedding vector from a ViT model, pre-trained on a large dataset, captures greater relevant information for SIDE than the usual route of generating pseudo image captions, followed by CLIP based text embeddings. Based on this idea, we propose a new SIDE model using a diffusion backbone which is conditioned on ViT embedding
    
[^131]: 大型语言模型中的长篇事实性

    Long-form factuality in large language models

    [https://arxiv.org/abs/2403.18802](https://arxiv.org/abs/2403.18802)

    该论文提出了一种通过使用大型语言模型将长篇回应分解为单个事实，并通过发送搜索查询到Google搜索，评估事实准确性的方法，并扩展了F1分数作为长篇事实性的聚合度量。

    

    大型语言模型（LLMs）在回答开放性主题的事实性提示时，经常生成包含事实错误的内容。为了在开放领域中对模型的长篇事实性进行基准测试，我们首先使用GPT-4生成了一个名为LongFact的提示集，其中包含数千个囊括38个主题的问题。然后，我们提出LLM代理可以通过一种名为Search-Augmented Factuality Evaluator（SAFE）的方法作为长篇事实性的自动评估器。SAFE利用LLM将长篇回应分解为一组单独的事实，并通过发送搜索查询到Google搜索以及确定一个事实是否得到搜索结果支持的多步推理过程来评估每个事实的准确性。此外，我们还提议将F1分数扩展为长篇事实性的聚合度量。为此，我们平衡了回应中支持事实的百分比（精度）与

    arXiv:2403.18802v1 Announce Type: cross  Abstract: Large language models (LLMs) often generate content that contains factual errors when responding to fact-seeking prompts on open-ended topics. To benchmark a model's long-form factuality in open domains, we first use GPT-4 to generate LongFact, a prompt set comprising thousands of questions spanning 38 topics. We then propose that LLM agents can be used as automated evaluators for long-form factuality through a method which we call Search-Augmented Factuality Evaluator (SAFE). SAFE utilizes an LLM to break down a long-form response into a set of individual facts and to evaluate the accuracy of each fact using a multi-step reasoning process comprising sending search queries to Google Search and determining whether a fact is supported by the search results. Furthermore, we propose extending F1 score as an aggregated metric for long-form factuality. To do so, we balance the percentage of supported facts in a response (precision) with the 
    
[^132]: 大型语言模型在教育领域的应用：调研与展望

    Large Language Models for Education: A Survey and Outlook

    [https://arxiv.org/abs/2403.18105](https://arxiv.org/abs/2403.18105)

    大型语言模型在教育领域的应用调研总结了LLMs在教育中的各种技术应用，包括学生和教师辅助、自适应学习和商业工具，提出了未来研究机会和潜在方向。

    

    大型语言模型（LLMs）的出现为教育领域带来了新的可能性。这篇调研论文总结了LLMs在教育环境中的各种技术，涵盖了学生和教师的辅助，自适应学习和商业工具。我们系统地审查了每个视角中的技术进步，整理了相关数据集和基准测试，并确定了在教育中部署LLMs所涉及的风险和挑战。此外，我们概述了未来的研究机会，突出了潜在的有前途的方向。我们的调研旨在为教育工作者、研究人员和决策者提供全面的技术图景，以利用LLMs的力量，彻底改革教育实践，并促进更有效的个性化学习环境。

    arXiv:2403.18105v1 Announce Type: cross  Abstract: The advent of Large Language Models (LLMs) has brought in a new era of possibilities in the realm of education. This survey paper summarizes the various technologies of LLMs in educational settings from multifaceted perspectives, encompassing student and teacher assistance, adaptive learning, and commercial tools. We systematically review the technological advancements in each perspective, organize related datasets and benchmarks, and identify the risks and challenges associated with deploying LLMs in education. Furthermore, we outline future research opportunities, highlighting the potential promising directions. Our survey aims to provide a comprehensive technological picture for educators, researchers, and policymakers to harness the power of LLMs to revolutionize educational practices and foster a more effective personalized learning environment.
    
[^133]: PeersimGym：用于通过强化学习解决任务卸载问题的环境

    PeersimGym: An Environment for Solving the Task Offloading Problem with Reinforcement Learning

    [https://arxiv.org/abs/2403.17637](https://arxiv.org/abs/2403.17637)

    引入了 PeersimGym 环境，通过强化学习解决任务卸载问题，支持定制化仿真环境，有助于开发和优化计算网络中的任务卸载策略。

    

    任务卸载对于在诸如物联网之类的网络中平衡设备的计算负载至关重要，但面临着诸如在严格的通信和存储约束下最小化延迟和能源使用等重要优化挑战。传统优化在可扩展性方面存在不足；启发式方法缺乏实现最佳结果，而强化学习（RL）通过允许通过迭代交互学习最佳卸载策略的方式提供了一种有前景的途径。然而，RL 的功效取决于对丰富数据集和定制的现实训练环境的访问。为解决这一问题，我们引入了 PeersimGym，这是一个开源的、可定制的仿真环境，旨在开发和优化计算网络中的任务卸载策略。PeersimGym 支持各种网络拓扑和计算约束，并整合了一种"PettingZo"方法，使用户能够轻松配置仿真参数和监控仿真过程。

    arXiv:2403.17637v1 Announce Type: cross  Abstract: Task offloading, crucial for balancing computational loads across devices in networks such as the Internet of Things, poses significant optimization challenges, including minimizing latency and energy usage under strict communication and storage constraints. While traditional optimization falls short in scalability; and heuristic approaches lack in achieving optimal outcomes, Reinforcement Learning (RL) offers a promising avenue by enabling the learning of optimal offloading strategies through iterative interactions. However, the efficacy of RL hinges on access to rich datasets and custom-tailored, realistic training environments. To address this, we introduce PeersimGym, an open-source, customizable simulation environment tailored for developing and optimizing task offloading strategies within computational networks. PeersimGym supports a wide range of network topologies and computational constraints and integrates a \textit{PettingZo
    
[^134]: MapGuide: 从脑活动中重建连续语言的简单而有效方法

    MapGuide: A Simple yet Effective Method to Reconstruct Continuous Language from Brain Activities

    [https://arxiv.org/abs/2403.17516](https://arxiv.org/abs/2403.17516)

    本研究提出了一种直接比较预测文本嵌入的脑活动映射来指导文本重建的简单而有效方法，相比之前的间接方法显著提高了模型性能。

    

    从脑活动中解码连续语言是一项艰巨但有前景的研究领域。这对于帮助语言残障人士通过脑信号进行沟通尤为重要。本文提出了一种简单而有效的方法，通过直接将从脑活动映射的预测文本嵌入向导文本重建。全面的实验证明，我们的方法明显优于当前最先进的模型，在BLEU和METEOR分数上平均提高了77%和54%。

    arXiv:2403.17516v1 Announce Type: cross  Abstract: Decoding continuous language from brain activity is a formidable yet promising field of research. It is particularly significant for aiding people with speech disabilities to communicate through brain signals. This field addresses the complex task of mapping brain signals to text. The previous best attempt reverse-engineered this process in an indirect way: it began by learning to encode brain activity from text and then guided text generation by aligning with predicted brain responses. In contrast, we propose a simple yet effective method that guides text reconstruction by directly comparing them with the predicted text embeddings mapped from brain activities. Comprehensive experiments reveal that our method significantly outperforms the current state-of-the-art model, showing average improvements of 77% and 54% on BLEU and METEOR scores. We further validate the proposed modules through detailed ablation studies and case analyses and 
    
[^135]: 使用区域指导标记将孟加拉文本与地方方言转录为国际音标

    Transcribing Bengali Text with Regional Dialects to IPA using District Guided Tokens

    [https://arxiv.org/abs/2403.17407](https://arxiv.org/abs/2403.17407)

    通过引入区域指导标记技术，本文提出了一种将孟加拉文本与地方方言转录为国际音标的方法，为模型提供了关于输入文本的地区方言信息，以理解与每个地区相关的独特音韵模式。

    

    孟加拉文本到国际音标（IPA）的准确转录是一项具有挑战性的任务，主要是由于语言的复杂音韵学和语境相关的音变。对于区域孟加拉方言来说，由于缺乏针对这些方言的标准拼写约定、当地和外语在这些地区中流行的词汇以及不同地区之间的音韵多样性，这一挑战甚至更为严峻。本文提出了一种方法来解决这个序列到序列的问题，即在覆盖孟加拉国六个地区的新数据集上引入“区域指导标记”（DGT）技术。其关键思想是在生成IPA转录之前向模型提供有关输入文本的区域方言或“地区”的明确信息。这通过在输入序列前添加一个地区标记来实现，有效地引导模型理解与每个地区相关的独特音韵模式。

    arXiv:2403.17407v1 Announce Type: cross  Abstract: Accurate transcription of Bengali text to the International Phonetic Alphabet (IPA) is a challenging task due to the complex phonology of the language and context-dependent sound changes. This challenge is even more for regional Bengali dialects due to unavailability of standardized spelling conventions for these dialects, presence of local and foreign words popular in those regions and phonological diversity across different regions. This paper presents an approach to this sequence-to-sequence problem by introducing the District Guided Tokens (DGT) technique on a new dataset spanning six districts of Bangladesh. The key idea is to provide the model with explicit information about the regional dialect or "district" of the input text before generating the IPA transcription. This is achieved by prepending a district token to the input sequence, effectively guiding the model to understand the unique phonetic patterns associated with each 
    
[^136]: 神经架构搜索中的进化与效率：弥合专家设计与自动优化之间的鸿沟

    Evolution and Efficiency in Neural Architecture Search: Bridging the Gap Between Expert Design and Automated Optimization

    [https://arxiv.org/abs/2403.17012](https://arxiv.org/abs/2403.17012)

    本文综述了神经架构搜索（NAS）领域的进化历程，介绍了从手动设计到自动化优化的演变过程，探讨了NAS在各个领域的应用，以及针对计算效率挑战提出的高效NAS方法。

    

    本文全面介绍了神经架构搜索（NAS），强调了它从手动设计到自动化、计算驱动方法的演变。它涵盖了NAS的起源和发展，突出了其在各个领域的应用，包括医学影像和自然语言处理。文章详细阐述了从专家驱动设计到算法驱动过程的转变，探讨了强化学习和进化算法等初始方法。还讨论了计算需求的挑战以及高效NAS方法的出现，如可微架构搜索和硬件感知NAS。该论文进一步阐述了NAS在计算机视觉、NLP等领域的应用，展示了其在不同任务中优化神经网络架构的多功能性和潜力。探讨了未来的方向和挑战，包括计算效率。

    arXiv:2403.17012v1 Announce Type: cross  Abstract: The paper provides a comprehensive overview of Neural Architecture Search (NAS), emphasizing its evolution from manual design to automated, computationally-driven approaches. It covers the inception and growth of NAS, highlighting its application across various domains, including medical imaging and natural language processing. The document details the shift from expert-driven design to algorithm-driven processes, exploring initial methodologies like reinforcement learning and evolutionary algorithms. It also discusses the challenges of computational demands and the emergence of efficient NAS methodologies, such as Differentiable Architecture Search and hardware-aware NAS. The paper further elaborates on NAS's application in computer vision, NLP, and beyond, demonstrating its versatility and potential for optimizing neural network architectures across different tasks. Future directions and challenges, including computational efficiency
    
[^137]: 揭示本地差分隐私、平均贝叶斯隐私和最大贝叶斯隐私之间的相互作用

    Deciphering the Interplay between Local Differential Privacy, Average Bayesian Privacy, and Maximum Bayesian Privacy

    [https://arxiv.org/abs/2403.16591](https://arxiv.org/abs/2403.16591)

    论文探讨了本地差分隐私、贝叶斯隐私及其之间的相互关系，揭示了关于效用-隐私权衡的新见解，并提出了一个框架来突出攻击和防御策略的相互作用和效果。

    

    机器学习的迅速发展导致了隐私定义的多样化，由于对隐私构成的威胁，包括本地差分隐私（LDP）的概念。虽然被广泛接受并在许多领域中被利用，但这种传统的隐私测量方法仍然存在一定限制，从无法防止推断披露到缺乏对对手背景知识的考虑。在这项全面研究中，我们引入贝叶斯隐私并深入探讨本地差分隐私和其贝叶斯对应物之间错综复杂的关系，揭示了关于效用-隐私权衡的新见解。我们引入了一个框架，概括了攻击和防御策略，突出它们之间的相互作用和效果。我们的理论贡献基于平均贝叶斯隐私（ABP）和最大贝叶斯隐私之间的严格定义和关系。

    arXiv:2403.16591v1 Announce Type: cross  Abstract: The swift evolution of machine learning has led to emergence of various definitions of privacy due to the threats it poses to privacy, including the concept of local differential privacy (LDP). Although widely embraced and utilized across numerous domains, this conventional approach to measure privacy still exhibits certain limitations, spanning from failure to prevent inferential disclosure to lack of consideration for the adversary's background knowledge. In this comprehensive study, we introduce Bayesian privacy and delve into the intricate relationship between local differential privacy and its Bayesian counterparts, unveiling novel insights into utility-privacy trade-offs. We introduce a framework that encapsulates both attack and defense strategies, highlighting their interplay and effectiveness. Our theoretical contributions are anchored in the rigorous definitions and relationships between Average Bayesian Privacy (ABP) and Max
    
[^138]: SegICL：一种用于增强医学成像分割的通用上下文学习框架

    SegICL: A Universal In-context Learning Framework for Enhanced Segmentation in Medical Imaging

    [https://arxiv.org/abs/2403.16578](https://arxiv.org/abs/2403.16578)

    SegICL引入了一种利用上下文学习的图像分割新方法，能够在新任务中适应医学图像分割，无需从头训练模型或进行复杂微调。

    

    通过上下文学习以新任务中适应的医学图像分割模型是一个令人兴奋的进展。通用分割模型旨在横跨医学图像的不同模态进行概括，然而，它们的效果在应用于分布之外的（OOD）数据模态和任务时通常会减弱，需要对模型进行复杂微调以获得最佳性能。为解决这一挑战，我们引入了SegICL，一种利用上下文学习（ICL）进行图像分割的新方法。与现有方法不同，SegICL能够利用文本引导分割并使用一小组图像-掩码对进行上下文学习，消除了从头开始训练模型或为OOD任务（包括OOD模态和数据集）进行微调的需要。SegICL的大量实验验证表明，提示示例数量与分割之间存在正相关关系。

    arXiv:2403.16578v1 Announce Type: cross  Abstract: Medical image segmentation models adapting to new tasks in a training-free manner through in-context learning is an exciting advancement. Universal segmentation models aim to generalize across the diverse modality of medical images, yet their effectiveness often diminishes when applied to out-of-distribution (OOD) data modalities and tasks, requiring intricate fine-tuning of model for optimal performance. For addressing this challenge, we introduce SegICL, a novel approach leveraging In-Context Learning (ICL) for image segmentation. Unlike existing methods, SegICL has the capability to employ text-guided segmentation and conduct in-context learning with a small set of image-mask pairs, eliminating the need for training the model from scratch or fine-tuning for OOD tasks (including OOD modality and dataset). Extensive experimental validation of SegICL demonstrates a positive correlation between the number of prompt samples and segmentat
    
[^139]: 新闻报道场景中的图像描述

    Image Captioning in news report scenario

    [https://arxiv.org/abs/2403.16209](https://arxiv.org/abs/2403.16209)

    本论文探索了专门针对名人照片的图像描述，旨在增强新闻行业实践，并提出了对自动新闻内容生成的改进方法。

    

    arXiv:2403.16209v1 公告类型: 跨领域 摘要: 图像描述旨在为指定的图像生成相关的描述，使其处于计算机视觉（CV）和自然语言处理（NLP）的交叉点。这项努力在推荐系统、新闻媒体、社交媒体等领域具有重要意义。特别是在新闻报道领域，标题应涵盖详细信息，如图像中捕捉到的名人的身份。然而，现有大部分工作主要集中于理解场景和动作。本文探讨了专门针对名人照片的图像描述领域，展示了其在增强新闻行业实践方面的广泛潜力。这一探索旨在增强自动化新闻内容生成，从而促进更加细致地传播信息。我们的努力展示了一个更广阔的视野，丰富了n

    arXiv:2403.16209v1 Announce Type: cross  Abstract: Image captioning strives to generate pertinent captions for specified images, situating itself at the crossroads of Computer Vision (CV) and Natural Language Processing (NLP). This endeavor is of paramount importance with far-reaching applications in recommendation systems, news outlets, social media, and beyond. Particularly within the realm of news reporting, captions are expected to encompass detailed information, such as the identities of celebrities captured in the images. However, much of the existing body of work primarily centers around understanding scenes and actions. In this paper, we explore the realm of image captioning specifically tailored for celebrity photographs, illustrating its broad potential for enhancing news industry practices. This exploration aims to augment automated news content generation, thereby facilitating a more nuanced dissemination of information. Our endeavor shows a broader horizon, enriching the n
    
[^140]: 一种新颖的图神经网络方法用于谣言检测

    Rumor Detection with a novel graph neural network approach

    [https://arxiv.org/abs/2403.16206](https://arxiv.org/abs/2403.16206)

    本论文提出了一种新颖的检测模型，同时学习用户相关性和信息传播的表示，以检测社交媒体上的谣言

    

    社交媒体上谣言的广泛传播对人们的日常生活造成了负面影响，导致公众产生潜在的恐慌、恐惧和心理健康问题。如何尽早揭穿谣言仍然是一个具有挑战性的问题。现有研究主要利用信息传播结构来检测谣言，而很少有研究关注用户之间的相关性，即他们可能协调传播谣言以获得较大的流行度。在本文中，我们提出了一种新的检测模型，同时学习用户相关性和信息传播的表示，以便检测社交媒体上的谣言。具体而言，我们利用图神经网络从描述用户和来源推文之间相关性的二部图中学习用户相关性的表示，以及使用树结构学习信息传播的表示。然后，我们结合得到的表示

    arXiv:2403.16206v1 Announce Type: new  Abstract: The wide spread of rumors on social media has caused a negative impact on people's daily life, leading to potential panic, fear, and mental health problems for the public. How to debunk rumors as early as possible remains a challenging problem. Existing studies mainly leverage information propagation structure to detect rumors, while very few works focus on correlation among users that they may coordinate to spread rumors in order to gain large popularity. In this paper, we propose a new detection model, that jointly learns both the representations of user correlation and information propagation to detect rumors on social media. Specifically, we leverage graph neural networks to learn the representations of user correlation from a bipartite graph that describes the correlations between users and source tweets, and the representations of information propagation with a tree structure. Then we combine the learned representations from these 
    
[^141]: 多元表示嵌入用于终身人员再识别

    Diverse Representation Embedding for Lifelong Person Re-Identification

    [https://arxiv.org/abs/2403.16003](https://arxiv.org/abs/2403.16003)

    提出了一种多元表示嵌入(DRE)框架，用于终身人员再识别(LReID)，可以在学习新信息的同时有效保留旧知识，通过自适应约束模块(ACM)实现多个表示之间的整合和推开操作，为每个实例获取密集嵌入子空间，提高有限旧任务数据集上的匹配能力。

    

    终身人员再识别(LReID)旨在不断学习连续的数据流，跨多个摄像头匹配个人。LReID的关键挑战是在增量学习新信息的同时有效保留旧知识。任务级域差距和有限的旧任务数据集是导致ReID中灾难性遗忘的关键因素，这些因素在现有方法中被忽视。为了缓解这一问题，我们提出了一种新颖的多元表示嵌入(DRE)框架用于LReID。所提出的DRE基于实例级和任务级布局，保留旧知识同时适应新信息。具体来说，提出了一种自适应约束模块(ACM)来实现多个表示之间的整合和推开操作，为每个实例获取密集嵌入子空间，以提高有限旧任务数据集上的匹配能力。

    arXiv:2403.16003v1 Announce Type: cross  Abstract: Lifelong Person Re-Identification (LReID) aims to continuously learn from successive data streams, matching individuals across multiple cameras. The key challenge for LReID is how to effectively preserve old knowledge while learning new information incrementally. Task-level domain gaps and limited old task datasets are key factors leading to catastrophic forgetting in ReLD, which are overlooked in existing methods. To alleviate this problem, we propose a novel Diverse Representation Embedding (DRE) framework for LReID. The proposed DRE preserves old knowledge while adapting to new information based on instance-level and task-level layout. Concretely, an Adaptive Constraint Module (ACM) is proposed to implement integration and push away operations between multiple representations, obtaining dense embedding subspace for each instance to improve matching ability on limited old task datasets. Based on the processed diverse representation, 
    
[^142]: FusionINN：可逆图像融合用于脑肿瘤监测

    FusionINN: Invertible Image Fusion for Brain Tumor Monitoring

    [https://arxiv.org/abs/2403.15769](https://arxiv.org/abs/2403.15769)

    FusionINN引入了一种新颖的可逆图像融合框架，可以高效生成融合图像，并解开融合过程的逆向分解，保证无损的像素映射。

    

    图像融合通常使用不可逆神经网络将多个源图像合并为单个融合图像。然而，对于临床专家，仅依赖融合图像可能不足以做出诊断决策，因为融合机制混合了来自源图像的特征，从而难以解释潜在的肿瘤病理。我们引入了FusionINN，一种新颖的可逆图像融合框架，能够高效生成融合图像，并通过求解融合过程的逆过程将其分解回源图像。FusionINN通过整合一个正态分布的潜在图像与融合图像一起，以促进分解过程的生成建模，从而保证无损的一对一像素映射。据我们所知，我们是首次研究融合图像的可分解性，这对于生命敏感应用程序尤为关键。

    arXiv:2403.15769v1 Announce Type: cross  Abstract: Image fusion typically employs non-invertible neural networks to merge multiple source images into a single fused image. However, for clinical experts, solely relying on fused images may be insufficient for making diagnostic decisions, as the fusion mechanism blends features from source images, thereby making it difficult to interpret the underlying tumor pathology. We introduce FusionINN, a novel invertible image fusion framework, capable of efficiently generating fused images and also decomposing them back to the source images by solving the inverse of the fusion process. FusionINN guarantees lossless one-to-one pixel mapping by integrating a normally distributed latent image alongside the fused image to facilitate the generative modeling of the decomposition process. To the best of our knowledge, we are the first to investigate the decomposability of fused images, which is particularly crucial for life-sensitive applications such as
    
[^143]: AutoTRIZ：利用TRIZ和大型语言模型的人工创意

    AutoTRIZ: Artificial Ideation with TRIZ and Large Language Models

    [https://arxiv.org/abs/2403.13002](https://arxiv.org/abs/2403.13002)

    本文提出了AutoTRIZ，一种利用大型语言模型自动化和增强TRIZ方法的人工创意工具，为设计自动化和可解释创意提供了一种新颖方法。

    

    研究人员和创新者在开发思维方法方面做出了巨大努力，比如形态分析和类比设计，以辅助工程设计创意，解决问题和推动创新。在这些方法中，TRIZ作为最著名的方法脱颖而出，被广泛应用于系统化创新。然而，TRIZ资源和概念的复杂性，以及其对用户知识、经验和推理能力的依赖，限制了其实用性。本文提出了AutoTRIZ，一种利用大型语言模型（LLMs）自动化和增强TRIZ方法的人工创意工具。通过利用LLMs的广泛知识和先进推理能力，AutoTRIZ提供了一种新颖的利用人工智能进行设计自动化和可解释创意的方法。我们通过对矛盾检测和比较方面的一致性实验来证明并评估AutoTRIZ的有效性。

    arXiv:2403.13002v1 Announce Type: cross  Abstract: Researchers and innovators have made enormous efforts in developing ideation methods, such as morphological analysis and design-by-analogy, to aid engineering design ideation for problem solving and innovation. Among these, TRIZ stands out as the most well-known approach, widely applied for systematic innovation. However, the complexity of TRIZ resources and concepts, coupled with its reliance on users' knowledge, experience, and reasoning capabilities, limits its practicability. This paper proposes AutoTRIZ, an artificial ideation tool that leverages large language models (LLMs) to automate and enhance the TRIZ methodology. By leveraging the broad knowledge and advanced reasoning capabilities of LLMs, AutoTRIZ offers a novel approach to design automation and interpretable ideation with artificial intelligence. We demonstrate and evaluate the effectiveness of AutoTRIZ through consistency experiments in contradiction detection and compa
    
[^144]: 加强形式定理证明：用于在Coq代码上训练AI模型的全面数据集

    Enhancing Formal Theorem Proving: A Comprehensive Dataset for Training AI Models on Coq Code

    [https://arxiv.org/abs/2403.12627](https://arxiv.org/abs/2403.12627)

    提出了一个全面的数据集，用于增强大型语言模型在解释和生成Coq代码方面的熟练程度，推动自动定理证明的发展。

    

    在形式定理证明领域，Coq证明辅助工具以其对验证数学断言和软件正确性的严格方法脱颀而出。尽管人工智能和机器学习取得了进展，但Coq语法和语义的特殊性为大型语言模型（LLMs）带来了独特的挑战。为填补这一空白，我们提出了一个专门设计的全面数据集，旨在增强LLMs在解释和生成Coq代码方面的熟练程度。该数据集源自一组超过10,000个Coq源文件，涵盖了各种命题、证明和定义，丰富的元数据包括源引用和许可信息。我们的主要目标是促进能够生成语法正确且语义丰富的Coq构造的LLMs的发展，从而推进自动定理证明的前沿。这个数据集的初步实验

    arXiv:2403.12627v1 Announce Type: new  Abstract: In the realm of formal theorem proving, the Coq proof assistant stands out for its rigorous approach to verifying mathematical assertions and software correctness. Despite the advances in artificial intelligence and machine learning, the specialized nature of Coq syntax and semantics poses unique challenges for Large Language Models (LLMs). Addressing this gap, we present a comprehensive dataset specifically designed to enhance LLMs' proficiency in interpreting and generating Coq code. This dataset, derived from a collection of over 10,000 Coq source files, encompasses a wide array of propositions, proofs, and definitions, enriched with metadata including source references and licensing information. Our primary aim is to facilitate the development of LLMs capable of generating syntactically correct and semantically meaningful Coq constructs, thereby advancing the frontier of automated theorem proving. Initial experiments with this datase
    
[^145]: LLM能生成类人行路指示吗？走向跨平台的具身指令综合

    Can LLMs Generate Human-Like Wayfinding Instructions? Towards Platform-Agnostic Embodied Instruction Synthesis

    [https://arxiv.org/abs/2403.11487](https://arxiv.org/abs/2403.11487)

    提出了一种新方法，利用LLM以及上下文学习，实现了自动生成具身机器人的“行路指示”，并且在多个模拟平台上展示出跨平台特性。

    

    我们提出了一种新颖的方法，用于自动合成“行路指示”以指导具身机器人。与先前的方法相比，这种方法不再依赖于仅设计用于特定模拟平台的人工注释数据集，而是使用上下文学习来调节LLM，以使用少量参考生成指示。我们使用基于LLM的视觉问答策略收集环境的详细信息，LLM用于指令合成。我们将我们的方法实现在多个模拟平台上，包括Matterport3D、AI Habitat和ThreeDWorld，从而展示了其跨平台特性。我们通过用户研究主观评估了我们的方法，观察到83.3%的用户认为合成的指示准确捕捉了环境的细节，并表现出与人类生成的指示类似的特征。

    arXiv:2403.11487v1 Announce Type: cross  Abstract: We present a novel approach to automatically synthesize "wayfinding instructions" for an embodied robot agent. In contrast to prior approaches that are heavily reliant on human-annotated datasets designed exclusively for specific simulation platforms, our algorithm uses in-context learning to condition an LLM to generate instructions using just a few references. Using an LLM-based Visual Question Answering strategy, we gather detailed information about the environment which is used by the LLM for instruction synthesis. We implement our approach on multiple simulation platforms including Matterport3D, AI Habitat and ThreeDWorld, thereby demonstrating its platform-agnostic nature. We subjectively evaluate our approach via a user study and observe that 83.3% of users find the synthesized instructions accurately capture the details of the environment and show characteristics similar to those of human-generated instructions. Further, we con
    
[^146]: 使用门控动态可学习注意机制的双Transformer在田纳西伊斯曼过程中进行故障检测与诊断

    Twin Transformer using Gated Dynamic Learnable Attention mechanism for Fault Detection and Diagnosis in the Tennessee Eastman Process

    [https://arxiv.org/abs/2403.10842](https://arxiv.org/abs/2403.10842)

    本研究提出一种新颖的双Transformer模型，结合门控动态可学习注意机制，用于田纳西伊斯曼过程的故障检测与诊断，提高性能通过独立处理输入数据和提取多样化信息，以及动态学习适应性调整注意策略。

    

    故障检测和诊断（FDD）对于确保工业过程的安全性和效率至关重要。我们提出了一种新颖的FDD方法，适用于田纳西伊斯曼过程（TEP），这是化工过程控制中广泛使用的基准。该模型采用两个独立的Transformer分支，能够独立处理输入数据并提取多样化的信息。引入了一种新颖的注意机制，即门控动态可学习注意（GDLAttention），它集成了门控机制和动态学习能力。门控机制调节注意权重，使模型能够关注输入的最相关部分。动态学习方法在训练过程中调整注意策略，有可能提高性能。注意机制使用双线性相似性函数，提供更大的灵活性来捕捉查询和输入之间的复杂关系。

    arXiv:2403.10842v1 Announce Type: cross  Abstract: Fault detection and diagnosis (FDD) is a crucial task for ensuring the safety and efficiency of industrial processes. We propose a novel FDD methodology for the Tennessee Eastman Process (TEP), a widely used benchmark for chemical process control. The model employs two separate Transformer branches, enabling independent processing of input data and potential extraction of diverse information. A novel attention mechanism, Gated Dynamic Learnable Attention (GDLAttention), is introduced which integrates a gating mechanism and dynamic learning capabilities. The gating mechanism modulates the attention weights, allowing the model to focus on the most relevant parts of the input. The dynamic learning approach adapts the attention strategy during training, potentially leading to improved performance. The attention mechanism uses a bilinear similarity function, providing greater flexibility in capturing complex relationships between query and 
    
[^147]: FeatUp: 一个与模型无关的特征任意分辨率框架

    FeatUp: A Model-Agnostic Framework for Features at Any Resolution

    [https://arxiv.org/abs/2403.10516](https://arxiv.org/abs/2403.10516)

    FeatUp是一个任务和模型无关的框架，用于在深度特征中恢复丢失的空间信息，从而使特征可以以任何分辨率重建，在现有应用中取得分辨率和性能的提升。

    

    深度特征是计算机视觉研究的基石，捕捉图像语义并使社区能够解决下游任务，即使在零或少样本情况下也能做到。然而，这些特征通常缺乏空间分辨率，无法直接执行像分割和深度预测这样的稠密预测任务，因为模型会过于聚合大范围的信息。在这项工作中，我们介绍了FeatUp，一个任务和模型无关的框架，用于恢复深度特征中丢失的空间信息。我们介绍了FeatUp的两个变体：一个在单次前向传递中引导具有高分辨率信号的特征，另一个适应单个图像并以任何分辨率重构特征的隐式模型。这两种方法都使用了一个具有与 NeRF 类似的深度类比的多视图一致性损失。我们的特征保留其原始语义，并可以替换现有应用程序，即使不重新

    arXiv:2403.10516v1 Announce Type: cross  Abstract: Deep features are a cornerstone of computer vision research, capturing image semantics and enabling the community to solve downstream tasks even in the zero- or few-shot regime. However, these features often lack the spatial resolution to directly perform dense prediction tasks like segmentation and depth prediction because models aggressively pool information over large areas. In this work, we introduce FeatUp, a task- and model-agnostic framework to restore lost spatial information in deep features. We introduce two variants of FeatUp: one that guides features with high-resolution signal in a single forward pass, and one that fits an implicit model to a single image to reconstruct features at any resolution. Both approaches use a multi-view consistency loss with deep analogies to NeRFs. Our features retain their original semantics and can be swapped into existing applications to yield resolution and performance gains even without re-
    
[^148]: 一种用于自动生成医疗记录的持续预训练LLM方法

    A Continued Pretrained LLM Approach for Automatic Medical Note Generation

    [https://arxiv.org/abs/2403.09057](https://arxiv.org/abs/2403.09057)

    这项研究提出了一种用于医疗记录生成的持续预训练LLM方法，在PubMedQA方面性能优于GPT-4，能够更好地捕捉正确的医疗概念，并且在正确性和完整性方面超过人类抄写员。

    

    LLM（大型语言模型）正在革新自然语言处理任务。然而，像GPT-4这样的最强大的LLM对于大多数领域特定场景来说成本太高。我们提出了第一个连续训练的130亿参数 Llama2-basd LLM，专为医疗对话而设计，并在自动记录上进行了测试。我们的结果显示，我们的模型在PubMedQA中的准确率高达76.6％，在总结医疗对话为SOAP笔记方面与GPT-4的性能相当。值得注意的是，我们的模型在捕捉正确的医疗概念方面超过了GPT-4，并且在正确性和完整性方面超越了人类抄写员。

    arXiv:2403.09057v1 Announce Type: cross  Abstract: LLMs are revolutionizing NLP tasks. However, the most powerful LLM, like GPT-4, is too costly for most domain-specific scenarios. We present the first continuously trained 13B Llama2-based LLM that is purpose-built for medical conversations and measured on automated scribing. Our results show that our model outperforms GPT-4 in PubMedQA with 76.6\% accuracy and matches its performance in summarizing medical conversations into SOAP notes. Notably, our model exceeds GPT-4 in capturing a higher number of correct medical concepts and outperforms human scribes with higher correctness and completeness.
    
[^149]: 跨模态去偏见: 使用语言减轻影像中的子群体转变

    Cross-modality debiasing: using language to mitigate sub-population shifts in imaging

    [https://arxiv.org/abs/2403.07888](https://arxiv.org/abs/2403.07888)

    使用自然语言输入去偏置图像特征表示，以改善在子群体上的最坏情况表现。

    

    子群体转变是一种特定类型的领域转变，突显了在训练和测试之间特定子群体或人口的数据分布的变化。子群体转变占据了算法偏见的一个重要来源，并需要分布鲁棒性。最近的研究发现，多模态基础模型，如视觉-语言模型CLIP，具有固有的分布鲁棒性，但这种鲁棒性对参数微调是脆弱的。在本文中，我们提出利用不同模态之间的鲁棒性连接，重新塑造一个模态的分布鲁棒性。具体地，在CLIP的分布鲁棒性上下文中，我们提出利用自然语言输入来去偏置图像特征表示，以改善在子群体上的最坏情况表现。我们的广泛实证研究表明，通过自然语言输入进行去偏见处理的图像表示能够在子群体上改善最坏情况的性能。

    arXiv:2403.07888v1 Announce Type: cross  Abstract: Sub-population shift is a specific type of domain shift that highlights changes in data distribution within specific sub-groups or populations between training and testing. Sub-population shift accounts for a significant source of algorithmic bias and calls for distributional robustness. Recent studies found inherent distributional robustness in multi-modality foundation models, such as the vision-language model CLIP, yet this robustness is vulnerable through parameter fine-tuning. In this paper, we propose leveraging the connection of robustness among different modalities and reshaping the distributional robustness of one modality with another. Specifically, in the context of the distributional robustness of CLIP, we propose to leverage natural language inputs to debias the image feature representations, to improve worst-case performance on sub-populations. Our extensive empirical studies show that image representations debiased by na
    
[^150]: SSM遇上视频扩散模型: 结构化状态空间下的高效视频生成

    SSM Meets Video Diffusion Models: Efficient Video Generation with Structured State Spaces

    [https://arxiv.org/abs/2403.07711](https://arxiv.org/abs/2403.07711)

    提出了一种基于状态空间模型（SSMs）的方法，用于解决使用扩散模型生成长视频序列时注意力层内存消耗增长快、限制较大的问题

    

    鉴于图像生成通过扩散模型取得的显著成就，研究界对将这些模型扩展到视频生成表现出越来越大的兴趣。最近用于视频生成的扩散模型主要利用注意力层来提取时间特征。然而，由于注意力层的内存消耗随着序列长度的增加呈二次增长，这种限制在尝试使用扩散模型生成更长视频序列时会带来重大挑战。为了克服这一挑战，我们提出利用状态空间模型（SSMs）。由于相对于序列长度，SSMs具有线性内存消耗，最近已经引起了越来越多的关注。在实验中，我们首先通过使用UCF101这一视频生成的标准基准来评估我们基于SSM的模型。此外，为探讨SSMs在更长视频生成中的潜力，

    arXiv:2403.07711v1 Announce Type: cross  Abstract: Given the remarkable achievements in image generation through diffusion models, the research community has shown increasing interest in extending these models to video generation. Recent diffusion models for video generation have predominantly utilized attention layers to extract temporal features. However, attention layers are limited by their memory consumption, which increases quadratically with the length of the sequence. This limitation presents significant challenges when attempting to generate longer video sequences using diffusion models. To overcome this challenge, we propose leveraging state-space models (SSMs). SSMs have recently gained attention as viable alternatives due to their linear memory consumption relative to sequence length. In the experiments, we first evaluate our SSM-based model with UCF101, a standard benchmark of video generation. In addition, to investigate the potential of SSMs for longer video generation, 
    
[^151]: 利用潜在对抗训练防御未预见的故障模式

    Defending Against Unforeseen Failure Modes with Latent Adversarial Training

    [https://arxiv.org/abs/2403.05030](https://arxiv.org/abs/2403.05030)

    本研究利用潜在对抗训练（LAT）来防御AI系统中未预见的故障模式，通过利用网络实际用于预测的压缩、抽象和结构化概念的潜在表示，有效清除了恶意软件和对抗性攻击。

    

    人工智能系统有时在部署后会展示出有害的意外行为。尽管开发人员进行了大量诊断和调试，这种情况经常发生。由于攻击面非常广泛，从模型中减少风险具有挑战性。耗尽地搜索可能导致模型失败的输入是不可行的。红队和对抗训练（AT）通常用于使人工智能系统更加健壮。然而，它们并不足以避免许多与对抗训练不同的真实世界故障模式。在这项工作中，我们利用潜在对抗训练（LAT）来防御漏洞，而无需生成引发这些漏洞的输入。LAT利用网络实际用于预测的压缩、抽象和结构化概念的潜在表示。我们使用LAT来清除恶意软件并防御针对保留类别的对抗性攻击。我们展示在图像分类、文本分类

    arXiv:2403.05030v1 Announce Type: cross  Abstract: AI systems sometimes exhibit harmful unintended behaviors post-deployment. This is often despite extensive diagnostics and debugging by developers. Minimizing risks from models is challenging because the attack surface is so large. It is not tractable to exhaustively search for inputs that may cause a model to fail. Red-teaming and adversarial training (AT) are commonly used to make AI systems more robust. However, they have not been sufficient to avoid many real-world failure modes that differ from the ones adversarially trained on. In this work, we utilize latent adversarial training (LAT) to defend against vulnerabilities without generating inputs that elicit them. LAT leverages the compressed, abstract, and structured latent representations of concepts that the network actually uses for prediction. We use LAT to remove trojans and defend against held-out classes of adversarial attacks. We show in image classification, text classifi
    
[^152]: 使用图理解和推理功能增强大规模语言模型的GraphInstruct

    GraphInstruct: Empowering Large Language Models with Graph Understanding and Reasoning Capability

    [https://arxiv.org/abs/2403.04483](https://arxiv.org/abs/2403.04483)

    该论文提出了一个名为GraphInstruct的基准，用于评估和增强大规模语言模型的图理解能力，并通过构建GraphLM和提出GraphLM+模型实现了显著的图推理能力增强。

    

    评估和增强大规模语言模型（LLMs）的通用能力一直是一个重要的研究课题。图是现实世界中常见的数据结构，理解图数据对于推进通用智能至关重要。为了评估和增强LLMs的图理解能力，在本文中，我们提出了一个名为GraphInstruct的基准，全面包括21个经典图推理任务，提供多样的图生成流水线和详细的推理步骤。基于GraphInstruct，我们进一步通过高效的指导调整构建了GraphLM，展示出显著的图理解能力。为了增强LLM的图推理能力，我们提出了一种步骤掩码训练策略，并构建了一个名为GraphLM+的模型。作为增强LLMs图理解和推理能力的先驱性努力之一，我们进行了大量实验。

    arXiv:2403.04483v1 Announce Type: new  Abstract: Evaluating and enhancing the general capabilities of large language models (LLMs) has been an important research topic. Graph is a common data structure in the real world, and understanding graph data is a crucial part for advancing general intelligence. To evaluate and enhance the graph understanding abilities of LLMs, in this paper, we propose a benchmark named GraphInstruct, which comprehensively includes 21 classical graph reasoning tasks, providing diverse graph generation pipelines and detailed reasoning steps. Based on GraphInstruct, we further construct GraphLM through efficient instruction-tuning, which shows prominent graph understanding capability. In order to enhance the LLM with graph reasoning capability as well, we propose a step mask training strategy, and construct a model named GraphLM+. As one of the pioneering efforts to enhance the graph understanding and reasoning abilities of LLMs, extensive experiments have demons
    
[^153]: 学习在自然语言格式中压缩提示

    Learning to Compress Prompt in Natural Language Formats

    [https://arxiv.org/abs/2402.18700](https://arxiv.org/abs/2402.18700)

    该研究旨在通过提出自然语言提示封装（Nano-Capsulator）框架，解决了在自然语言格式中压缩提示的挑战，以提高大型语言模型的可转移性和性能。

    

    大型语言模型（LLMs）擅长处理多个自然语言处理任务，但它们的能力受到长上下文、推理速度慢以及计算结果成本高的限制。部署具有精确和信息丰富上下文的LLMs有助于用户更有效和更具成本效益地处理大规模数据集。现有作品依赖将长提示上下文压缩为软提示。然而，软提示压缩在不同LLM之间的可转移性受到限制，尤其是基于API的LLMs。因此，本研究旨在以LLM可转移性的形式压缩长提示的自然语言形式。这带来两个挑战：(i) 自然语言（NL）提示不兼容反向传播，(ii) NL提示在施加长度约束方面缺乏灵活性。在本研究中，我们提出了一种自然语言提示封装（Nano-Capsulator）框架

    arXiv:2402.18700v1 Announce Type: cross  Abstract: Large language models (LLMs) are great at processing multiple natural language processing tasks, but their abilities are constrained by inferior performance with long context, slow inference speed, and the high cost of computing the results. Deploying LLMs with precise and informative context helps users process large-scale datasets more effectively and cost-efficiently. Existing works rely on compressing long prompt contexts into soft prompts. However, soft prompt compression encounters limitations in transferability across different LLMs, especially API-based LLMs. To this end, this work aims to compress lengthy prompts in the form of natural language with LLM transferability. This poses two challenges: (i) Natural Language (NL) prompts are incompatible with back-propagation, and (ii) NL prompts lack flexibility in imposing length constraints. In this work, we propose a Natural Language Prompt Encapsulation (Nano-Capsulator) framewor
    
[^154]: 一张图片搞定：大型多模态模型是图片内学习者

    All in a Single Image: Large Multimodal Models are In-Image Learners

    [https://arxiv.org/abs/2402.17971](https://arxiv.org/abs/2402.17971)

    这项研究引入了一种名为图片内学习（I$^2$L）的新型上下文学习机制，将演示示例、视觉线索和指令合并到一个图片中，以提升GPT-4V的能力，并通过整合图像处理、理解和推理的能力来取得多个优点

    

    本文介绍了一种名为图片内学习（I$^2$L）的新型上下文学习（ICL）机制，将演示示例、视觉线索和指令合并到一张图片中，以增强GPT-4V的能力。与以往依赖将图像转换为文本或将视觉输入融入语言模型的方法不同，I$^2$L将所有信息整合到一张图片中，主要利用图像处理、理解和推理能力。这有几个优点：避免了对复杂图像的不准确文本描述，提供了在定位演示示例时的灵活性，减少了输入负担，并通过消除对多个图片和冗长文本的需求来避免超过输入限制。为了进一步结合不同ICL方法的优势，我们引入了一种自动策略，用于选择给定任务中数据示例的适当ICL方法。我们在MathVi上进行了实验

    arXiv:2402.17971v1 Announce Type: cross  Abstract: This paper introduces a new in-context learning (ICL) mechanism called In-Image Learning (I$^2$L) that combines demonstration examples, visual cues, and instructions into a single image to enhance the capabilities of GPT-4V. Unlike previous approaches that rely on converting images to text or incorporating visual input into language models, I$^2$L consolidates all information into one image and primarily leverages image processing, understanding, and reasoning abilities. This has several advantages: it avoids inaccurate textual descriptions of complex images, provides flexibility in positioning demonstration examples, reduces the input burden, and avoids exceeding input limits by eliminating the need for multiple images and lengthy text. To further combine the strengths of different ICL methods, we introduce an automatic strategy to select the appropriate ICL method for a data example in a given task. We conducted experiments on MathVi
    
[^155]: 理解大型语言模型开发背后的数据集管理者

    Understanding the Dataset Practitioners Behind Large Language Model Development

    [https://arxiv.org/abs/2402.16611](https://arxiv.org/abs/2402.16611)

    数据质量是大型语言模型开发中数据集管理者的首要任务，但管理者间对于数据质量定义和评估方法缺乏共识。

    

    随着大型语言模型(LLMs)变得越来越先进和有影响力，审视它们依赖和产生的数据变得越来越重要。本文探讨了数据集管理者的工作内容：首先，我们通过对谷歌贡献LLM开发团队责任的回顾性分析，定义了“数据集管理者”的角色。然后，我们对这些管理者进行了半结构化访谈（N=10）。我们发现数据质量是首要任务。为了评估数据质量，管理者要么凭直觉，要么编写自定义评估逻辑。管理者之间对数据质量的定义和评估方法缺乏共识。我们讨论了这种现象的潜在原因和实现一致性的机会。

    arXiv:2402.16611v1 Announce Type: new  Abstract: As large language models (LLMs) become more advanced and impactful, it is increasingly important to scrutinize the data that they rely upon and produce. What is it to be a dataset practitioner doing this work? We approach this in two parts: first, we define the role of "dataset practitioner" by performing a retrospective analysis on the responsibilities of teams contributing to LLM development at Google. Then, we conduct semi-structured interviews with a cross-section of these practitioners (N=10). We find that data quality is the top priority. To evaluate data quality, practitioners either rely on their own intuition or write custom evaluation logic. There is a lack of consensus across practitioners on what quality is and how to evaluate it. We discuss potential reasons for this phenomenon and opportunities for alignment.
    
[^156]: Triad: 一个利用基于多角色LLM代理的框架来解决知识库问答问题

    Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering

    [https://arxiv.org/abs/2402.14320](https://arxiv.org/abs/2402.14320)

    Triad框架利用了基于多角色LLM代理来解决知识库问答问题，通过代理的不同角色分别处理KBQA子任务，合作完成KBQA任务，并在多个基准数据集上表现出色。

    

    最近基于LLM代理的进展在各种任务中展现出了令人期待的结果。然而，它们在回答知识库中问题的运用仍然鲜为人知。使用传统方法来实现KBQA系统具有挑战性，因为缺乏特定任务训练数据以及创建以任务为中心的模型结构的复杂性。在本文中，我们提出了Triad，一个利用具有三个角色的LLM代理的统一框架来进行KBQA任务。代理被分配三个角色来处理不同的KBQA子任务：作为掌握各种子任务的通才，作为选择候选者的决策者，以及作为回答带有知识的问题的顾问。我们的KBQA框架在四个阶段中执行，涉及代理的多重角色的协作。我们使用三个基准数据集评估了我们框架的性能，结果显示我们的框架胜过了

    arXiv:2402.14320v1 Announce Type: cross  Abstract: Recent progress with LLM-based agents has shown promising results across various tasks. However, their use in answering questions from knowledge bases remains largely unexplored. Implementing a KBQA system using traditional methods is challenging due to the shortage of task-specific training data and the complexity of creating task-focused model structures. In this paper, we present Triad, a unified framework that utilizes an LLM-based agent with three roles for KBQA tasks. The agent is assigned three roles to tackle different KBQA subtasks: agent as a generalist for mastering various subtasks, as a decision maker for the selection of candidates, and as an advisor for answering questions with knowledge. Our KBQA framework is executed in four phases, involving the collaboration of the agent's multiple roles. We evaluated the performance of our framework using three benchmark datasets, and the results show that our framework outperforms 
    
[^157]: 关于通过规划和学习自动化视频游戏测试

    On Automating Video Game Testing by Planning and Learning

    [https://arxiv.org/abs/2402.12393](https://arxiv.org/abs/2402.12393)

    提出了一种通过自动规划和学习技术自动化测试视频游戏的方法和工作流程，使得自动规划变得更容易接触到更广泛的受众。

    

    在本文中，我们提出了一种使用自动规划和规划行为模型学习技术自动化测试特定视频游戏方面的方法和工作流程。基本想法是生成详细的游戏日志，并应用行动模型学习来获得规划领域描述语言（PDDL）中的形式模型。该工作流程实现了游戏开发人员与具有PDDL建模经验但无游戏开发技能的人员之间的高效合作，并且无需任何PDDL或其他正式系统经验。我们总体描述了该方法和工作流程，然后在一个具体的概念证明示例上进行演示 -- 这是一个简单的角色扮演游戏，作为流行游戏开发引擎Unity中的教程项目之一。本文是朝着减少甚至消除工作流程中对建模专家需求的第一步，从而使自动规划可供更广泛的人群使用。

    arXiv:2402.12393v1 Announce Type: cross  Abstract: In this paper, we propose a method and workflow for automating the testing of certain video game aspects using automated planning and planning action model learning techniques. The basic idea is to generate detailed gameplay logs and apply action model learning to obtain a formal model in the planning domain description language (PDDL). The workflow enables efficient cooperation of game developers without any experience with PDDL or other formal systems and a person experienced with PDDL modeling but no game development skills. We describe the method and workflow in general and then demonstrate it on a concrete proof-of-concept example -- a simple role-playing game provided as one of the tutorial projects in the popular game development engine Unity. This paper presents the first step towards minimizing or even eliminating the need for a modeling expert in the workflow, thus making automated planning accessible to a broader audience.
    
[^158]: 在语言模型对话中测量和控制“人设”漂移

    Measuring and Controlling Persona Drift in Language Model Dialogs

    [https://arxiv.org/abs/2402.10962](https://arxiv.org/abs/2402.10962)

    提出了一种量化基准来测量语言模型对话中的“人设”漂移，并提出了一种称为split-softmax的轻量级方法来对抗注意力衰减和“人设”漂移

    

    提示是定制语言模型聊天机器人的标准工具，使其能够承担特定的“人设”。在使用提示时的一个隐含假设是，它们将是稳定的，因此聊天机器人将在整个对话过程中继续根据规定的“人设”生成文本。我们提出了一个量化基准来测试这一假设，通过两个个性化聊天机器人之间的自我对话来评估“人设”的稳定性。我们对流行模型如LLaMA2-chat-70B进行测试，发现在八轮对话中存在显著的“人设”漂移。对这一现象的实证和理论分析表明，由于长对话中的注意力衰减，变压器注意力机制起到了一定作用。为了对抗注意力衰减和“人设”漂移，我们提出了一种称为split-softmax的轻量级方法，与两个强基线方法相比表现优异。

    arXiv:2402.10962v1 Announce Type: cross  Abstract: Prompting is a standard tool for customizing language-model chatbots, enabling them to take on a specific "persona". An implicit assumption in the use of prompts is that they will be stable, so the chatbot will continue to generate text according to the stipulated persona for the duration of a conversation. We propose a quantitative benchmark to test this assumption, evaluating persona stability via self-chats between two personalized chatbots. Testing popular models like LLaMA2-chat-70B, we reveal a significant persona drift within eight rounds of conversations. An empirical and theoretical analysis of this phenomenon suggests the transformer attention mechanism plays a role, due to attention decay over long exchanges. To combat attention decay and persona drift, we propose a lightweight method called split-softmax, which compares favorably against two strong baselines.
    
[^159]: MuChin：用于评估音乐领域中语言模型的中文口语描述基准

    MuChin: A Chinese Colloquial Description Benchmark for Evaluating Language Models in the Field of Music

    [https://arxiv.org/abs/2402.09871](https://arxiv.org/abs/2402.09871)

    MuChin是一个用于评估多模态语言模型在音乐理解和描述方面性能的中文口语描述基准。

    

    快速发展的多模态大型语言模型（LLMs）迫切需要新的基准来统一评估它们在理解和以文字描述音乐方面的性能。然而，由于音乐信息检索（MIR）算法与人类理解之间的语义差距，专业人士和公众之间的差异，以及注释的低精度，现有的音乐描述数据集无法作为基准。为此，我们提出了MuChin，这是第一个用中文口语描述的开源音乐描述基准，旨在评估多模态LLMs在理解和描述音乐方面的性能。我们建立了采虫音乐注释平台（CaiMAP），采用创新的多人、多阶段保证方法，并招募了业余爱好者和专业人士，以确保注释的精度和与流行语义的对齐。利用这种方法，我们构建了一个数据集。

    arXiv:2402.09871v1 Announce Type: cross  Abstract: The rapidly evolving multimodal Large Language Models (LLMs) urgently require new benchmarks to uniformly evaluate their performance on understanding and textually describing music. However, due to semantic gaps between Music Information Retrieval (MIR) algorithms and human understanding, discrepancies between professionals and the public, and low precision of annotations, existing music description datasets cannot serve as benchmarks. To this end, we present MuChin, the first open-source music description benchmark in Chinese colloquial language, designed to evaluate the performance of multimodal LLMs in understanding and describing music. We established the Caichong Music Annotation Platform (CaiMAP) that employs an innovative multi-person, multi-stage assurance method, and recruited both amateurs and professionals to ensure the precision of annotations and alignment with popular semantics. Utilizing this method, we built a dataset w
    
[^160]: AutoMathText：使用语言模型进行数学文本的自主数据选择

    AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts

    [https://arxiv.org/abs/2402.07625](https://arxiv.org/abs/2402.07625)

    本论文介绍了一种自主数据选择策略，利用语言模型进行数学文本的自动评估和选择，并通过连续预训练显著提高了数学推理能力。主要创新包括利用元提示语言模型作为验证器，发布了高质量的AutoMathText数据集，并实现了预训练令牌效率的提升。

    

    为了通过持续的预训练改善语言模型在数学推理方面的能力，我们引入了一种新颖的策略，利用基础语言模型进行自主数据选择。与传统的有人工标注数据的监督微调或训练过的分类器不同，我们的方法利用元提示语言模型作为零样本验证器，自主评估和选择高质量的数学内容，并发布了经过策划的开源AutoMathText数据集，其中包含超过200GB的数据。为了证明我们方法的有效性，我们对AutoMathText数据集进行了连续预训练，使得7B参数的Mistral语言模型在MATH数据集上的下游性能大幅提升，而令牌数量比之前的连续预训练工作减少了几个数量级。我们的方法展示了基准的预训练令牌效率提高了2倍，突显了我们方法在增强中的潜力。

    To improve language models' proficiency in mathematical reasoning via continual pretraining, we introduce a novel strategy that leverages base language models for autonomous data selection. Departing from conventional supervised fine-tuning or trained classifiers with human-annotated data, our approach utilizes meta-prompted language models as zero-shot verifiers to autonomously evaluate and select high-quality mathematical content, and we release the curated open-source AutoMathText dataset encompassing over 200GB of data. To demonstrate the efficacy of our method, we continuously pretrained a 7B-parameter Mistral language model on the AutoMathText dataset, achieving substantial improvements in downstream performance on the MATH dataset with a token amount reduced by orders of magnitude compared to previous continuous pretraining works. Our method showcases a 2 times increase in pretraining token efficiency compared to baselines, underscoring the potential of our approach in enhancing
    
[^161]: SCAPE: 使用进化搜索概念架构提示

    SCAPE: Searching Conceptual Architecture Prompts using Evolution

    [https://arxiv.org/abs/2402.00089](https://arxiv.org/abs/2402.00089)

    SCAPE是一个将进化搜索与生成式人工智能相结合的工具，能够帮助用户通过简单的操作探索由初始输入启发的创造性和高质量设计，同时提高了图像的新颖性、质量和使用效果。

    

    概念架构涉及对来自其他学科的新颖理念进行高度创造性的探索，建筑师考虑将建筑的形式、材料、质地和颜色进行激进的创新。虽然如今的生成式人工智能系统能够产生出色的结果，但它们缺乏几十年来进化算法所展示的创造性。我们提出的工具SCAPE将进化搜索与生成式人工智能结合起来，使用户能够通过简单的点按界面探索由初始输入启发的创造性和高质量设计。SCAPE将随机性注入到生成式人工智能中，并利用GPT-4的内置语言能力通过基于文本的突变和交叉操作来变化提示。我们证明，与DALL-E 3相比，SCAPE在图像的新颖性方面提高了67%，同时在质量和使用效果方面也有所改进；我们展示，仅经过3次迭代，SCAPE的图像新颖性增加了24%，使有效的探索和优化成为可能。

    Conceptual architecture involves a highly creative exploration of novel ideas, often taken from other disciplines as architects consider radical new forms, materials, textures and colors for buildings. While today's generative AI systems can produce remarkable results, they lack the creativity demonstrated for decades by evolutionary algorithms. SCAPE, our proposed tool, combines evolutionary search with generative AI, enabling users to explore creative and good quality designs inspired by their initial input through a simple point and click interface. SCAPE injects randomness into generative AI, and enables memory, making use of the built-in language skills of GPT-4 to vary prompts via text-based mutation and crossover. We demonstrate that compared to DALL-E 3, SCAPE enables a 67% improvement in image novelty, plus improvements in quality and effectiveness of use; we show that in just 3 iterations SCAPE has a 24% image novelty increase enabling effective exploration, plus optimization
    
[^162]: 具有可变控制频率的可部署强化学习系统

    Deployable Reinforcement Learning with Variable Control Rate

    [https://arxiv.org/abs/2401.09286](https://arxiv.org/abs/2401.09286)

    应用可变控制频率的强化学习系统，以简化硬件使用、降低能源消耗，并挑战固定频率控制的假设

    

    部署经过强化学习（RL）训练的控制器到真实机器人上可能具有挑战性：RL依赖于被建模为马尔可夫决策过程（MDPs）的代理策略，这些策略假设时间离散。使用MDPs导致几乎所有基于RL的控制系统都采用固定速率控制策略，周期（或时间步长）通常基于开发者经验或应用环境的特定特征选择。不幸的是，为了确保稳定性，系统应以最高、最坏情况频率进行控制，这可能需要大量的计算和能源资源，并且阻碍控制器在板载硬件上的可部署性。遵循反应式编程原则，我们认为仅在必要时应用控制动作可以使用更简单的硬件，并有助于减少能源消耗。我们挑战了固定频率的假设。

    arXiv:2401.09286v2 Announce Type: replace-cross  Abstract: Deploying controllers trained with Reinforcement Learning (RL) on real robots can be challenging: RL relies on agents' policies being modeled as Markov Decision Processes (MDPs), which assume an inherently discrete passage of time. The use of MDPs results in that nearly all RL-based control systems employ a fixed-rate control strategy with a period (or time step) typically chosen based on the developer's experience or specific characteristics of the application environment. Unfortunately, the system should be controlled at the highest, worst-case frequency to ensure stability, which can demand significant computational and energy resources and hinder the deployability of the controller on onboard hardware. Adhering to the principles of reactive programming, we surmise that applying control actions only when necessary enables the use of simpler hardware and helps reduce energy consumption. We challenge the fixed frequency assump
    
[^163]: TeleChat技术报告

    TeleChat Technical Report

    [https://arxiv.org/abs/2401.03804](https://arxiv.org/abs/2401.03804)

    TeleChat是一个包含30亿、70亿和120亿参数的大型语言模型合集，旨在提供预训练语言模型和与人类喜好相一致的微调聊天模型。研究表明，TeleChat在各种任务上表现出与其他类似规模的开源模型相当的性能。

    

    在这份技术报告中，我们介绍了TeleChat，这是由30亿、70亿和120亿参数的大型语言模型（LLMs）组成的合集。它包括预训练的语言模型以及与人类喜好相一致的微调聊天模型。TeleChat最初在包含英语和中文语言的多样文本集合中预训练，包括数万亿的标记。随后，该模型经过微调以与人类喜好相一致，遵循我们描述的详细方法论。我们评估了TeleChat在各种任务上的表现，包括语言理解、数学、推理、代码生成和基于知识的问答。我们的发现表明，TeleChat在各种公开基准测试中表现出与其他开源模型相似规模的可比性能。为支持未来利用该模型进行研究和应用，

    arXiv:2401.03804v2 Announce Type: replace-cross  Abstract: In this technical report, we present TeleChat, a collection of large language models (LLMs) with parameters of 3 billion, 7 billion and 12 billion. It includes pretrained language models as well as fine-tuned chat models that is aligned with human preferences. TeleChat is initially pretrained on an extensive corpus containing a diverse collection of texts from both English and Chinese languages, including trillions of tokens. Subsequently, the model undergoes fine-tuning to align with human preferences, following a detailed methodology that we describe. We evaluate the performance of TeleChat on various tasks, including language understanding, mathematics, reasoning, code generation, and knowledge-based question answering. Our findings indicate that TeleChat achieves comparable performance to other open-source models of similar size across a wide range of public benchmarks. To support future research and applications utilizing 
    
[^164]: UINav：一种训练设备端自动化代理的实用方法

    UINav: A Practical Approach to Train On-Device Automation Agents

    [https://arxiv.org/abs/2312.10170](https://arxiv.org/abs/2312.10170)

    UINav提出了一种基于演示的方法，用于训练适合移动设备的自动化代理，成功率高，训练数据少。

    

    具有自主驱动应用程序用户界面以完成用户任务的自动化系统，尤其是当用户处于情境性或永久性受损时，具有巨大的益处。之前的自动化系统不能产生具有普遍适用性的模型，而基于人工智能的自动化代理仅在简单的手工制作应用程序中可靠工作，或者会产生高计算成本。我们提出了UINav，这是一种基于演示的方法，用于训练适合移动设备的自动化代理，同时可以在演示数量不多的情况下实现高成功率。为了减少演示的工作量，UINav使用了一个裁判模型，在代理失败的任务上为用户提供即时反馈，并自动增加人类演示以增加训练数据的多样性。我们的评估表明，仅需10次演示，UINav就可以实现70%的准确率，而有足够多次演示时，它可以超过90%的准确率。

    arXiv:2312.10170v2 Announce Type: replace-cross  Abstract: Automation systems that can autonomously drive application user interfaces to complete user tasks are of great benefit, especially when users are situationally or permanently impaired. Prior automation systems do not produce generalizable models while AI-based automation agents work reliably only in simple, hand-crafted applications or incur high computation costs. We propose UINav, a demonstration-based approach to train automation agents that fit mobile devices, yet achieving high success rates with modest numbers of demonstrations. To reduce the demonstration overhead, UINav uses a referee model that provides users with immediate feedback on tasks where the agent fails, and automatically augments human demonstrations to increase diversity in training data. Our evaluation shows that with only 10 demonstrations UINav can achieve 70% accuracy, and that with enough demonstrations it can surpass 90% accuracy.
    
[^165]: 社会、法律、伦理、移情和文化规则：编制与推理（扩展版）

    Social, Legal, Ethical, Empathetic, and Cultural Rules: Compilation and Reasoning (Extended Version)

    [https://arxiv.org/abs/2312.09699](https://arxiv.org/abs/2312.09699)

    该研究介绍了SLEEC（社会、法律、伦理、移情、文化）规则的概念，旨在推动AI系统遵守人类背景相关规则的制定、验证和执行。

    

    AI基础和自主系统的崛起引发了人们对潜在负面影响的担忧，这些影响来自于它们的行为或决策。这些系统必须被设计为遵守它们将运作的人类背景。Townsend等人（2022）引入了SLEEC（社会、法律、伦理、移情或文化）规则的概念，旨在促进AI基础和自主系统应遵守规则的制定、验证和执行。他们提出了一种方法论来揭示这些规则，让哲学家、律师、领域专家和其他人用自然语言来制定这些规则。为了使这些规则在AI系统中有效使用，需要将这些规则系统地翻译成支持自动推理的形式语言。在这项研究中，我们首先对SLEEC规则模式进行了语言分析，这使得将SLEEC规则转换成c…

    arXiv:2312.09699v2 Announce Type: replace  Abstract: The rise of AI-based and autonomous systems is raising concerns and apprehension due to potential negative repercussions stemming from their behavior or decisions. These systems must be designed to comply with the human contexts in which they will operate. To this extent, Townsend et al. (2022) introduce the concept of SLEEC (social, legal, ethical, empathetic, or cultural) rules that aim to facilitate the formulation, verification, and enforcement of the rules AI-based and autonomous systems should obey. They lay out a methodology to elicit them and to let philosophers, lawyers, domain experts, and others to formulate them in natural language. To enable their effective use in AI systems, it is necessary to translate these rules systematically into a formal language that supports automated reasoning. In this study, we first conduct a linguistic analysis of the SLEEC rules pattern, which justifies the translation of SLEEC rules into c
    
[^166]: 大型人类语言模型：需求和挑战

    Large Human Language Models: A Need and the Challenges

    [https://arxiv.org/abs/2312.07751](https://arxiv.org/abs/2312.07751)

    大型人类语言模型的建立需要更好地整合人类背景，并面临着如何捕捉人类因素、如何表示以及如何建模的一系列挑战。

    

    随着人类中心的自然语言处理研究的进展，人们越来越意识到将人类和社会因素纳入到自然语言处理模型的重要性。同时，我们的自然语言处理系统已经严重依赖于LLM，其中大多数并没有对作者进行建模。为了构建能够真正理解人类语言的自然语言处理系统，我们必须更好地将人类背景整合到LLM中。这提出了一系列设计考虑和挑战，涉及到要捕捉哪些人类因素、如何表示它们以及要采用何种建模策略等问题。为了应对这些挑战，我们提倡从心理学和行为科学的概念出发，支持三个立场来创建大型人类语言模型（LHLMs）：首先，语言模型训练应包括人类背景。其次，LHLMs应该意识到人不仅仅是他们所属的群体。第三，LHLMs应该能够考虑到人类背景的动态和时间依赖性特点。

    arXiv:2312.07751v2 Announce Type: replace-cross  Abstract: As research in human-centered NLP advances, there is a growing recognition of the importance of incorporating human and social factors into NLP models. At the same time, our NLP systems have become heavily reliant on LLMs, most of which do not model authors. To build NLP systems that can truly understand human language, we must better integrate human contexts into LLMs. This brings to the fore a range of design considerations and challenges in terms of what human aspects to capture, how to represent them, and what modeling strategies to pursue. To address these, we advocate for three positions toward creating large human language models (LHLMs) using concepts from psychological and behavioral sciences: First, LM training should include the human context. Second, LHLMs should recognize that people are more than their group(s). Third, LHLMs should be able to account for the dynamic and temporally-dependent nature of the human con
    
[^167]: HALO：用于在大型语言模型中表示和分类幻觉的本体论

    HALO: An Ontology for Representing and Categorizing Hallucinations in Large Language Models

    [https://arxiv.org/abs/2312.05209](https://arxiv.org/abs/2312.05209)

    本文介绍了一种名为HALO的形式化、可扩展的本体论，用OWL编写，用于描述和表示大型语言模型中的六种不同类型的幻觉。

    

    arXiv:2312.05209v2 公告类型：替换 摘要：生成式人工智能的最新进展，包括ChatGPT等大型语言模型（LLMs），为从自然语言处理到知识发现和数据挖掘等领域带来了重大机遇。然而，人们越来越意识到这些模型可能存在问题，例如虚构信息或“幻觉”，以及在看似简单问题上犯错误的推理能力。由于像ChatGPT这样的模型备受欢迎，学术界和公民科学家都记录了多种类型和严重程度的幻觉。尽管已有相关工作，但仍然缺乏一种形式模型来细致描述和表示这些幻觉（带有相关元数据）。本文通过提出Hallucination Ontology或HALO来填补这一空白，HALO是一种正式的、可扩展的本体论，用OWL编写，目前支持六种已知的幻觉类型。

    arXiv:2312.05209v2 Announce Type: replace  Abstract: Recent progress in generative AI, including large language models (LLMs) like ChatGPT, has opened up significant opportunities in fields ranging from natural language processing to knowledge discovery and data mining. However, there is also a growing awareness that the models can be prone to problems such as making information up or `hallucinations', and faulty reasoning on seemingly simple problems. Because of the popularity of models like ChatGPT, both academic scholars and citizen scientists have documented hallucinations of several different types and severity. Despite this body of work, a formal model for describing and representing these hallucinations (with relevant meta-data) at a fine-grained level, is still lacking. In this paper, we address this gap by presenting the Hallucination Ontology or HALO, a formal, extensible ontology written in OWL that currently offers support for six different types of hallucinations known to 
    
[^168]: 数学家的大型语言模型

    Large Language Models for Mathematicians

    [https://arxiv.org/abs/2312.04556](https://arxiv.org/abs/2312.04556)

    大型语言模型（LLMs）如ChatGPT因其通用语言理解的能力以及生成高质量文本或计算机代码的能力而备受关注，对数学家的潜在帮助和改变工作方式的影响进行了讨论。

    

    大型语言模型（LLMs）如ChatGPT因其通用语言理解的能力以及生成高质量文本或计算机代码的能力而备受关注。对许多职业来说，LLMs代表一种无价的工具，可以加快工作速度并提高工作质量。本文讨论它们在帮助专业数学家方面的作用程度。我们首先提供了所有现代语言模型中使用的Transformer模型的数学描述。基于最近的研究，我们概述了最佳实践和潜在问题，并报告了语言模型的数学能力。最后，我们探讨了LLMs改变数学家工作方式的潜力。

    arXiv:2312.04556v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) such as ChatGPT have received immense interest for their general-purpose language understanding and, in particular, their ability to generate high-quality text or computer code. For many professions, LLMs represent an invaluable tool that can speed up and improve the quality of work. In this note, we discuss to what extent they can aid professional mathematicians. We first provide a mathematical description of the transformer model used in all modern language models. Based on recent studies, we then outline best practices and potential issues and report on the mathematical abilities of language models. Finally, we shed light on the potential of LLMs to change how mathematicians work.
    
[^169]: FRDiff：特征重用用于无训练加速扩散模型

    FRDiff : Feature Reuse for Universal Training-free Acceleration of Diffusion Models

    [https://arxiv.org/abs/2312.03517](https://arxiv.org/abs/2312.03517)

    引入了一种新的加速技术FRDiff，通过利用扩散模型的时间冗余性，重新使用具有高时间相似性的特征图，节省计算资源而不影响输出质量。

    

    扩散模型的较大计算成本，特别是由于高质量图像生成所必需的重复去噪步骤而产生的，这是阻碍它们得到广泛采用的主要障碍。我们引入一种高级加速技术，利用扩散模型固有的时间冗余性来重新使用具有高时间相似性的特征图，从而节省计算资源而不影响输出质量。

    arXiv:2312.03517v2 Announce Type: replace-cross  Abstract: The substantial computational costs of diffusion models, especially due to the repeated denoising steps necessary for high-quality image generation, present a major obstacle to their widespread adoption. While several studies have attempted to address this issue by reducing the number of score function evaluations (NFE) using advanced ODE solvers without fine-tuning, the decreased number of denoising iterations misses the opportunity to update fine details, resulting in noticeable quality degradation. In our work, we introduce an advanced acceleration technique that leverages the temporal redundancy inherent in diffusion models. Reusing feature maps with high temporal similarity opens up a new opportunity to save computation resources without compromising output quality. To realize the practical benefits of this intuition, we conduct an extensive analysis and propose a novel method, FRDiff. FRDiff is designed to harness the adv
    
[^170]: 为所有人构建地理不可知模型的分类：消除地域偏见

    Classification for everyone : Building geography agnostic models for fairer recognition

    [https://arxiv.org/abs/2312.02957](https://arxiv.org/abs/2312.02957)

    本文分析了消除现有图像分类模型中地理偏见的方法，并探讨了如何使这些模型更加鲁棒到图像的地理位置。

    

    在本文中，我们分析了减轻现有最先进图像分类模型中固有地理偏见的不同方法。我们首先定量地展示了这种偏见在两个数据集上 - Dollar Street数据集和ImageNet上的存在，使用带有位置信息的图片。然后，我们提出了可以用来减少这种偏见的不同方法。最后，我们分析了不同技术对于使这些模型更加鲁棒到图像地理位置的有效性。

    arXiv:2312.02957v3 Announce Type: replace-cross  Abstract: In this paper, we analyze different methods to mitigate inherent geographical biases present in state of the art image classification models. We first quantitatively present this bias in two datasets - The Dollar Street Dataset and ImageNet, using images with location information. We then present different methods which can be employed to reduce this bias. Finally, we analyze the effectiveness of the different techniques on making these models more robust to geographical locations of the images.
    
[^171]: DiffiT: 用于图像生成的扩散视觉Transformer模型

    DiffiT: Diffusion Vision Transformers for Image Generation

    [https://arxiv.org/abs/2312.02139](https://arxiv.org/abs/2312.02139)

    DiffiT是一种新的模型，结合了Vision Transformer和扩散模型的优势，在图像生成中表现出色，特别是通过引入细粒度去噪控制和时间依赖的多头自注意力机制，实现了高保真图像的生成。

    

    具有强大表现力和高样本质量的扩散模型在生成领域取得了最先进的性能。开创性的视觉Transformer（ViT）展现了强大的建模能力和可扩展性，特别适用于识别任务。本文研究了ViTs在基于扩散的生成学习中的有效性，并提出了一个新模型，称为Diffusion Vision Transformers（DiffiT）。具体地，我们提出了一种用于对去噪过程进行细粒度控制的方法，并引入了时间依赖的多头自注意力（TMSA）机制。DiffiT在生成高保真图像方面非常有效，参数效率也显著提高。我们还提出了基于潜空间和图像空间的DiffiT模型，并在不同分辨率的各种类别条件和非条件综合任务上展现了最先进的性能。潜空间DiffiT模型达到

    arXiv:2312.02139v2 Announce Type: replace-cross  Abstract: Diffusion models with their powerful expressivity and high sample quality have achieved State-Of-The-Art (SOTA) performance in the generative domain. The pioneering Vision Transformer (ViT) has also demonstrated strong modeling capabilities and scalability, especially for recognition tasks. In this paper, we study the effectiveness of ViTs in diffusion-based generative learning and propose a new model denoted as Diffusion Vision Transformers (DiffiT). Specifically, we propose a methodology for finegrained control of the denoising process and introduce the Time-dependant Multihead Self Attention (TMSA) mechanism. DiffiT is surprisingly effective in generating high-fidelity images with significantly better parameter efficiency. We also propose latent and image space DiffiT models and show SOTA performance on a variety of class-conditional and unconditional synthesis tasks at different resolutions. The Latent DiffiT model achieves
    
[^172]: 安全海上导航的模块化控制架构：强化学习和预测安全过滤器

    Modular Control Architecture for Safe Marine Navigation: Reinforcement Learning and Predictive Safety Filters

    [https://arxiv.org/abs/2312.01855](https://arxiv.org/abs/2312.01855)

    这项研究提出了一种模块化的控制架构，结合强化学习和预测安全过滤器，在海产导航中实现了安全稳定的闭环控制。

    

    许多自主系统面临安全挑战，需要强大的闭环控制来处理物理限制和安全约束。现实世界中的系统，如自主船只，遇到非线性动力学和环境扰动。强化学习越来越多地用于适应复杂场景，但缺乏确保安全和稳定性的标准框架。预测安全过滤器（PSF）提供了一种有希望的解决方案，确保在基于学习的控制中满足约束条件而无需显式约束处理。这种模块化方法允许使用任意的控制策略，安全过滤器优化所提议的动作以满足物理和安全约束。我们将这种方法应用于海上导航，将RL与PSF结合在一个模拟的Cybership II模型上。RL代理经过路径跟踪和避碰训练，而PSF监视并修改控制动作以确保安全。结果表明，PSF能够在不牺牲性能的情况下有效确保安全性。

    arXiv:2312.01855v2 Announce Type: replace-cross  Abstract: Many autonomous systems face safety challenges, requiring robust closed-loop control to handle physical limitations and safety constraints. Real-world systems, like autonomous ships, encounter nonlinear dynamics and environmental disturbances. Reinforcement learning is increasingly used to adapt to complex scenarios, but standard frameworks ensuring safety and stability are lacking. Predictive Safety Filters (PSF) offer a promising solution, ensuring constraint satisfaction in learning-based control without explicit constraint handling. This modular approach allows using arbitrary control policies, with the safety filter optimizing proposed actions to meet physical and safety constraints. We apply this approach to marine navigation, combining RL with PSF on a simulated Cybership II model. The RL agent is trained on path following and collision avpodance, while the PSF monitors and modifies control actions for safety. Results de
    
[^173]: VA3：基于概率版权保护的文本到图像生成模型的虚拟确认攻击

    VA3: Virtually Assured Amplification Attack on Probabilistic Copyright Protection for Text-to-Image Generative Models

    [https://arxiv.org/abs/2312.00057](https://arxiv.org/abs/2312.00057)

    提出了一种名为VA3的虚拟确认攻击框架，通过对文本到图像生成模型持续交互，显著增加生成侵权内容的概率，并在各种情况下验证了攻击的有效性。

    

    随着文本到图像生成模型的广泛使用，人们开始担心它们产生侵犯版权内容的高风险。尽管概率版权保护方法提供了一种对抗侵权行为的概率性保证，但在本文中，我们介绍了一种名为Virtually Assured Amplification Attack (VA3)的新型在线攻击框架，揭示了这些保护机制的漏洞。提出的框架显著增加了在与生成模型持续交互的过程中产生侵权内容的概率，并对每次交互的成功概率提供了一个非平凡的下界。我们的理论和实验结果展示了我们方法在各种情况下的有效性。这些发现凸显了在文本到图像生成模型的实际应用中实施概率版权保护的潜在风险。

    arXiv:2312.00057v2 Announce Type: replace-cross  Abstract: The booming use of text-to-image generative models has raised concerns about their high risk of producing copyright-infringing content. While probabilistic copyright protection methods provide a probabilistic guarantee against such infringement, in this paper, we introduce Virtually Assured Amplification Attack (VA3), a novel online attack framework that exposes the vulnerabilities of these protection mechanisms. The proposed framework significantly amplifies the probability of generating infringing content on the sustained interactions with generative models and a non-trivial lower-bound on the success probability of each engagement. Our theoretical and experimental results demonstrate the effectiveness of our approach under various scenarios. These findings highlight the potential risk of implementing probabilistic copyright protection in practical applications of text-to-image generative models. Code is available at https://
    
[^174]: 早期和晚期隐性偏见的二分法可以明显诱导领悟

    Dichotomy of Early and Late Phase Implicit Biases Can Provably Induce Grokking

    [https://arxiv.org/abs/2311.18817](https://arxiv.org/abs/2311.18817)

    通过早期和晚期隐性偏见的二分法，本文证明在训练同质神经网络时会出现从核预测器到最小范数/最大间隔预测器的急剧转变，从而引发测试准确性的显著变化。

    

    Power等人（2022）最近的研究突出了学习算术任务中出现的令人惊讶的“领悟”现象：神经网络首先“记忆”训练集，导致训练准确性完美，但测试准确性接近随机，然后在训练足够长时间后，突然过渡至完美测试准确性。本文研究了领悟现象在理论设置中的情况，并展示了它可以通过早期和晚期隐性偏见的二分法来诱导。具体来说，当使用大的初始化和小的权重衰减训练同质神经网络进行分类和回归任务时，我们证明训练过程在长时间内被困在对应于核预测器的解上，然后突然出现对于最小范数/最大间隔预测器的非常明显的过渡，导致测试准确性出现显著变化。

    arXiv:2311.18817v2 Announce Type: replace-cross  Abstract: Recent work by Power et al. (2022) highlighted a surprising "grokking" phenomenon in learning arithmetic tasks: a neural net first "memorizes" the training set, resulting in perfect training accuracy but near-random test accuracy, and after training for sufficiently longer, it suddenly transitions to perfect test accuracy. This paper studies the grokking phenomenon in theoretical setups and shows that it can be induced by a dichotomy of early and late phase implicit biases. Specifically, when training homogeneous neural nets with large initialization and small weight decay on both classification and regression tasks, we prove that the training process gets trapped at a solution corresponding to a kernel predictor for a long time, and then a very sharp transition to min-norm/max-margin predictors occurs, leading to a dramatic change in test accuracy.
    
[^175]: 使用基于像素的图像转换破坏基于卷积的不可学习数据集

    Corrupting Convolution-based Unlearnable Datasets with Pixel-based Image Transformations

    [https://arxiv.org/abs/2311.18403](https://arxiv.org/abs/2311.18403)

    研究者提出了一种基于卷积的不可学习数据集，该数据集使得现有的防御方法都失效，提出通过增加特定度量来减轻不可学习效果。

    

    不可学习的数据集会通过向干净训练集引入精心设计且难以察觉的扰动，导致模型的泛化性能急剧下降。许多现有防御方法，如JPEG压缩和对抗训练，能够有效对抗基于范数约束的附加噪声的不可学习数据集。然而，最新提出的一种基于卷积的不可学习数据集让现有的防御方法无效，给防御者带来更大挑战。为了解决这个问题，我们在简化的情景中将基于卷积的不可学习样本表达为将矩阵乘以干净样本的结果，并将类内矩阵不一致性形式化为$\Theta_{imi}$，将类间矩阵一致性形式化为$\Theta_{imc}$以研究基于卷积的不可学习数据集的工作机制。我们推测增加这两个度量将有助于减轻不可学习效果。

    arXiv:2311.18403v2 Announce Type: replace-cross  Abstract: Unlearnable datasets lead to a drastic drop in the generalization performance of models trained on them by introducing elaborate and imperceptible perturbations into clean training sets. Many existing defenses, e.g., JPEG compression and adversarial training, effectively counter UDs based on norm-constrained additive noise. However, a fire-new type of convolution-based UDs have been proposed and render existing defenses all ineffective, presenting a greater challenge to defenders. To address this, we express the convolution-based unlearnable sample as the result of multiplying a matrix by a clean sample in a simplified scenario, and formalize the intra-class matrix inconsistency as $\Theta_{imi}$, inter-class matrix consistency as $\Theta_{imc}$ to investigate the working mechanism of the convolution-based UDs. We conjecture that increasing both of these metrics will mitigate the unlearnability effect. Through validation experi
    
[^176]: 发现有效的土地利用规划政策

    Discovering Effective Policies for Land-Use Planning

    [https://arxiv.org/abs/2311.12304](https://arxiv.org/abs/2311.12304)

    通过学习代理模型并使用进化搜索过程，发现了可定制到不同位置的有效土地利用政策，为土地利用规划提供了一个潜在有用的工具。

    

    土地被分配给不同的用途，如森林、城市区域和农业，对陆地碳平衡和气候变化有重大影响。基于可用的土地利用变化的历史数据和相关的碳排放和吸收的模拟，可以学习到一个代理模型，从而能够高效评估决策者可选择的不同选项。然后可以使用进化搜索过程来发现特定位置的有效土地利用政策。该系统构建在Project Resilience平台上，并使用Land-Use Harmonization数据集LUH2和簿记模型BLUE进行评估。它生成可定制到不同位置的碳影响和土地利用变化量的帕累托前沿，从而为土地利用规划提供了一个潜在有用的工具。

    How areas of land are allocated for different uses, such as forests, urban areas, and agriculture, has a large effect on the terrestrial carbon balance, and therefore climate change. Based on available historical data on land-use changes and a simulation of the associated carbon emissions and removals, a surrogate model can be learned that makes it possible to evaluate the different options available to decision-makers efficiently. An evolutionary search process can then be used to discover effective land-use policies for specific locations. Such a system was built on the Project Resilience platform and evaluated with the Land-Use Harmonization dataset LUH2 and the bookkeeping model BLUE. It generates Pareto fronts that trade off carbon impact and amount of land-use change customized to different locations, thus providing a potentially useful tool for land-use planning.
    
[^177]: 你不需要进行人格测试来知道这些模型是不可靠的：评估大型语言模型在心理测量工具上的可靠性

    You don't need a personality test to know these models are unreliable: Assessing the Reliability of Large Language Models on Psychometric Instruments

    [https://arxiv.org/abs/2311.09718](https://arxiv.org/abs/2311.09718)

    评估大型语言模型在人格测量工具上的可靠性，研究探讨当前提示方式是否导致一致且稳健的响应

    

    大型语言模型（LLMs）在自然语言理解任务中的多功能性使其在社会科学研究中备受青睐。为了正确理解LLMs的属性和固有人格，研究人员进行了涉及使用提示的研究，这些提示采用问题形式询问LLMs关于特定观点。在本研究中，我们谨慎退一步，检查当前提示LLMs的格式是否以一致且稳健的方式引出响应。我们首先构建了一个包含693个问题的数据集，涵盖115个人格轴上的39种不同人格测量工具。此外，我们设计了一组包含微小变化的提示，并检查LLMs生成答案的能力，以及提示变化以检查它们在内容级别变化方面的一致性，例如更改响应选项的顺序或否定该语句。

    arXiv:2311.09718v2 Announce Type: replace-cross  Abstract: The versatility of Large Language Models (LLMs) on natural language understanding tasks has made them popular for research in social sciences. To properly understand the properties and innate personas of LLMs, researchers have performed studies that involve using prompts in the form of questions that ask LLMs about particular opinions. In this study, we take a cautionary step back and examine whether the current format of prompting LLMs elicits responses in a consistent and robust manner. We first construct a dataset that contains 693 questions encompassing 39 different instruments of persona measurement on 115 persona axes. Additionally, we design a set of prompts containing minor variations and examine LLMs' capabilities to generate answers, as well as prompt variations to examine their consistency with respect to content-level variations such as switching the order of response options or negating the statement. Our experimen
    
[^178]: 开源LLMs的可信度有多高？对恶意演示下的评估显示它们的脆弱性

    How Trustworthy are Open-Source LLMs? An Assessment under Malicious Demonstrations Shows their Vulnerabilities

    [https://arxiv.org/abs/2311.09447](https://arxiv.org/abs/2311.09447)

    本研究通过恶意演示在八个方面对开源LLMs的可信度进行了敌对评估，提出了一种新的攻击策略advCoU，以揭示它们的脆弱性。

    

    arXiv:2311.09447v2 公告类型：替换-交叉摘要：开源大型语言模型（LLMs）的快速发展显著推动着人工智能的发展。然而，对它们的可信度仍然了解有限。在规模部署这些模型，而没有足够的可信度可能会带来重大风险，突出了及时发现这些问题的重要性。本文对开源LLMs在可信度上进行了敌对评估，跨足毒性、陈规俗套、伦理、幻觉、公平性、谄媚、隐私以及对抗性演示的八个不同方面。我们提出了advCoU，一种基于扩展的Chain of Utterances（CoU）提示策略，通过加入精心设计的恶意演示来攻击可信度。我们的广泛实验涵盖了最近和代表性系列的开源LLMs，包括Vicuna、MPT、Falcon、Mistral和Llama 2。

    arXiv:2311.09447v2 Announce Type: replace-cross  Abstract: The rapid progress in open-source Large Language Models (LLMs) is significantly driving AI development forward. However, there is still a limited understanding of their trustworthiness. Deploying these models at scale without sufficient trustworthiness can pose significant risks, highlighting the need to uncover these issues promptly. In this work, we conduct an adversarial assessment of open-source LLMs on trustworthiness, scrutinizing them across eight different aspects including toxicity, stereotypes, ethics, hallucination, fairness, sycophancy, privacy, and robustness against adversarial demonstrations. We propose advCoU, an extended Chain of Utterances-based (CoU) prompting strategy by incorporating carefully crafted malicious demonstrations for trustworthiness attack. Our extensive experiments encompass recent and representative series of open-source LLMs, including Vicuna, MPT, Falcon, Mistral, and Llama 2. The empirical
    
[^179]: 火焰: 评估中国大型语言模型与人类价值观的契合性的基准测试

    Flames: Benchmarking Value Alignment of Chinese Large Language Models

    [https://arxiv.org/abs/2311.06899](https://arxiv.org/abs/2311.06899)

    中国的大型语言模型的价值观契合性需要更加全面的评估，该研究提出了一个名为"火焰"（Flames）的基准测试，涵盖了常见的无害原则和特定中国价值观，以及复杂场景和隐含恶意的提示方法。

    

    大型语言模型（LLMs）在各个地区的广泛应用强调了评估它们与人类价值观契合性的迫切性。然而，当前的基准测试未能有效地揭示LLMs中的安全漏洞。尽管许多模型在这些评估中得分很高，且“名列前茅”，但在LLMs与人类价值观的深层契合性和实现真正无害方面仍存在重大差距。为此，本文提出了一个名为"火焰"（Flames）的价值观契合性基准测试，该测试涵盖了常见的无害原则，以及一个整合了特定中国价值观如和谐的独特道德维度。因此，我们精心设计了包含复杂情境和大多带有隐含恶意的破解方法的对抗性提示。通过对17个主流LLMs进行提示，我们获得了模型的回应，并对其进行了详细评估。

    arXiv:2311.06899v2 Announce Type: replace-cross  Abstract: The widespread adoption of large language models (LLMs) across various regions underscores the urgent need to evaluate their alignment with human values. Current benchmarks, however, fall short of effectively uncovering safety vulnerabilities in LLMs. Despite numerous models achieving high scores and 'topping the chart' in these evaluations, there is still a significant gap in LLMs' deeper alignment with human values and achieving genuine harmlessness. To this end, this paper proposes a value alignment benchmark named Flames, which encompasses both common harmlessness principles and a unique morality dimension that integrates specific Chinese values such as harmony. Accordingly, we carefully design adversarial prompts that incorporate complex scenarios and jailbreaking methods, mostly with implicit malice. By prompting 17 mainstream LLMs, we obtain model responses and rigorously annotate them for detailed evaluation. Our findin
    
[^180]: 具有连续动作空间的低秩马尔可夫决策过程

    Low-Rank MDPs with Continuous Action Spaces

    [https://arxiv.org/abs/2311.03564](https://arxiv.org/abs/2311.03564)

    该研究通过探索多种方法，将针对低秩MDPs的现有方法扩展到连续动作空间，同时保持近似正确的学习保证。

    

    低秩马尔可夫决策过程（MDPs）最近在强化学习（RL）领域中崭露头角，因为它们可以提供约等于正确（PAC）的学习保证，同时还可以融合ML算法进行表示学习。然而，当前对低秩MDPs的方法存在局限性，它们只考虑有限的动作空间，并且在动作数量$|\mathcal{A}| \to \infty$时给出了空洞的界限，这极大地限制了它们的适用性。在这项工作中，我们研究了将这些方法扩展到具有连续动作的设置的问题，并探讨了多种具体的方法来进行这种扩展。作为案例研究，我们考虑了FLAMBE算法（Agarwal等，2020），这是一种用于低秩MDPs的PAC RL的奖励无关方法。我们展示了，在不对算法进行任何修改的情况下，当允许动作为连续时，我们获得了类似的PAC界限。

    arXiv:2311.03564v2 Announce Type: replace-cross  Abstract: Low-Rank Markov Decision Processes (MDPs) have recently emerged as a promising framework within the domain of reinforcement learning (RL), as they allow for provably approximately correct (PAC) learning guarantees while also incorporating ML algorithms for representation learning. However, current methods for low-rank MDPs are limited in that they only consider finite action spaces, and give vacuous bounds as $|\mathcal{A}| \to \infty$, which greatly limits their applicability. In this work, we study the problem of extending such methods to settings with continuous actions, and explore multiple concrete approaches for performing this extension. As a case study, we consider the seminal FLAMBE algorithm (Agarwal et al., 2020), which is a reward-agnostic method for PAC RL with low-rank MDPs. We show that, without any modifications to the algorithm, we obtain a similar PAC bound when actions are allowed to be continuous. Specifical
    
[^181]: 分离和学习潜在混淆因素以增强用户偏好建模

    Separating and Learning Latent Confounders to Enhancing User Preferences Modeling

    [https://arxiv.org/abs/2311.03381](https://arxiv.org/abs/2311.03381)

    通过分离和学习潜在混淆因素，提高了用户偏好建模的准确性

    

    推荐模型旨在从历史反馈中捕获用户偏好，然后预测用户对候选项目的特定反馈。然而，各种未测量的混淆因素导致历史反馈中的用户偏好与真实偏好之间存在偏差，进而导致模型未达到预期的性能。现有的去偏模型要么特定于解决特定偏差，要么直接从用户历史反馈中获取辅助信息，这无法确定所学偏好是真实用户偏好还是混入未测量的混淆因素。此外，我们发现以前的推荐系统不仅是未测量的混淆因素的后继者，还会作为影响用户偏好建模的未测量混淆因素，这在先前的研究中一直被忽视。为此，我们将前述推荐系统的影响纳入考虑，并将其视为

    arXiv:2311.03381v2 Announce Type: replace-cross  Abstract: Recommender models aim to capture user preferences from historical feedback and then predict user-specific feedback on candidate items. However, the presence of various unmeasured confounders causes deviations between the user preferences in the historical feedback and the true preferences, resulting in models not meeting their expected performance. Existing debias models either (1) specific to solving one particular bias or (2) directly obtain auxiliary information from user historical feedback, which cannot identify whether the learned preferences are true user preferences or mixed with unmeasured confounders. Moreover, we find that the former recommender system is not only a successor to unmeasured confounders but also acts as an unmeasured confounder affecting user preference modeling, which has always been neglected in previous studies. To this end, we incorporate the effect of the former recommender system and treat it as
    
[^182]: MCAD: 多教师跨模态对齐蒸馏用于高效图像-文本检索

    MCAD: Multi-teacher Cross-modal Alignment Distillation for efficient image-text retrieval

    [https://arxiv.org/abs/2310.19654](https://arxiv.org/abs/2310.19654)

    提出了一种Multi-teacher Cross-modality Alignment Distillation（MCAD）技术，通过将融合的单流特征合并到双流模型的图像和文本特征中，以整合单流和双流模型的优点。

    

    由于大规模视觉-语言预训练（VLP）模型的成功以及图像-文本检索在工业领域的广泛应用，现在迫切需要减小模型大小并简化它们在移动设备上的部署。 图像-文本检索中通常使用单流和双流模型结构，目的是缩小文本和视觉模态之间的语义差距。 虽然单流模型使用深度特征融合实现更准确的跨模态对齐，但双流模型更适用于离线索引和快速推理。我们提出了一种多教师跨模态对齐蒸馏（MCAD）技术，以整合单流和双流模型的优点。 通过将融合的单流特征合并到双流模型的图像和文本特征中，我们构建了新的修改后的教师相似性分布和特征。 然后，我们进行了分布

    arXiv:2310.19654v2 Announce Type: replace-cross  Abstract: Due to the success of large-scale visual-language pretraining (VLP) models and the widespread use of image-text retrieval in industry areas, it is now critically necessary to reduce the model size and streamline their mobile-device deployment. Single- and dual-stream model structures are commonly used in image-text retrieval with the goal of closing the semantic gap between textual and visual modalities. While single-stream models use deep feature fusion to achieve more accurate cross-model alignment, dual-stream models are better at offline indexing and fast inference.We propose a Multi-teacher Cross-modality Alignment Distillation (MCAD) technique to integrate the advantages of single- and dual-stream models. By incorporating the fused single-stream features into the image and text features of the dual-stream model, we formulate new modified teacher similarity distributions and features. Then, we conduct both distribution and
    
[^183]: 情感和动态束搜索用于故事生成

    Affective and Dynamic Beam Search for Story Generation

    [https://arxiv.org/abs/2310.15079](https://arxiv.org/abs/2310.15079)

    本文提出了一种情感故事生成器AffGen，通过引入动态束调整和情感重新排名两种新技术，在叙事中注入“有趣的转折”，并在生成充满情感和有趣的叙事方面表现出优异性能。

    

    故事具有迷人的潜力，使其成为一个引人入胜的研究领域，对娱乐、教育、治疗和认知研究具有重要意义。本文提出了一种情感故事生成器（AffGen），用于生成有趣的叙事。AffGen通过采用两种新技术——动态束调整和情感重新排名，在叙事中引入“有趣的转折”。动态束调整使用上下文多臂赌博模型鼓励不太可预测、更具吸引力的词语选择。情感重新排名基于情感强度对句子候选项进行优先排序。我们的实证评估，包括自动评估和人类评估，证明了AffGen在生成充满情感并且有趣的叙事方面优于现有的基线模型。我们的消融研究和分析提供了关于AffGen优势和劣势的见解。

    arXiv:2310.15079v1 Announce Type: cross  Abstract: Storytelling's captivating potential makes it a fascinating research area, with implications for entertainment, education, therapy, and cognitive studies. In this paper, we propose Affective Story Generator (AffGen) for generating interesting narratives. AffGen introduces "intriguing twists" in narratives by employing two novel techniques-Dynamic Beam Sizing and Affective Reranking. Dynamic Beam Sizing encourages less predictable, more captivating word choices using a contextual multi-arm bandit model. Affective Reranking prioritizes sentence candidates based on affect intensity. Our empirical evaluations, both automatic and human, demonstrate AffGen's superior performance over existing baselines in generating affectively charged and interesting narratives. Our ablation study and analysis provide insights into the strengths and weaknesses of AffGen.
    
[^184]: 使用大型语言模型进行配置验证

    Configuration Validation with Large Language Models

    [https://arxiv.org/abs/2310.09690](https://arxiv.org/abs/2310.09690)

    大型语言模型在配置验证中的应用具有可行性和有效性，通过开发一个名为Ciri的通用基于LLM的配置验证框架进行了实证评估。

    

    配置不当是软件故障的主要原因之一。现有实践依赖于开发人员编写的规则或测试用例来验证配置，这是昂贵的。配置验证的机器学习(ML)被认为是一个有前途的方向，但面临诸如需要大规模的现场数据和特定于系统的模型等挑战。大型语言模型(LLMs)的最新进展显示了在解决基于ML的配置验证长期限制方面的一些希望。我们首次分析了使用LLMs进行配置验证的可行性和有效性。我们通过开发一个名为Ciri的通用基于LLM的配置验证框架，以经验性评估LLMs作为配置验证器。Ciri利用有效的提示工程，基于有效配置和误配置数据进行少次学习。当生成结果时，Ciri检查LLM的输出。

    arXiv:2310.09690v2 Announce Type: replace-cross  Abstract: Misconfigurations are major causes of software failures. Existing practices rely on developer-written rules or test cases to validate configurations, which are expensive. Machine learning (ML) for configuration validation is considered a promising direction, but has been facing challenges such as the need of large-scale field data and system-specific models. Recent advances in Large Language Models (LLMs) show promise in addressing some of the long-lasting limitations of ML-based configuration validation. We present a first analysis on the feasibility and effectiveness of using LLMs for configuration validation. We empirically evaluate LLMs as configuration validators by developing a generic LLM-based configuration validation framework, named Ciri. Ciri employs effective prompt engineering with few-shot learning based on both valid configuration and misconfiguration data. Ciri checks outputs from LLMs when producing results, ad
    
[^185]: 重新表述、增强、推理：视觉问题的视觉基础与语言模型

    Rephrase, Augment, Reason: Visual Grounding of Questions for Vision-Language Models

    [https://arxiv.org/abs/2310.05861](https://arxiv.org/abs/2310.05861)

    通过在输入中添加具有视觉基础的信息作为预防性澄清，可以提高模型性能，减少不充分性，并简化模型回答问题的方式。

    

    越来越多的视觉-语言任务可以在零至少训练的情况下处理，即通过将大型语言模型（LLMs）与视觉编码器相结合，形成大型视觉-语言模型（LVLMs）。尽管这具有巨大的优势，比如不需要训练数据或自定义架构，但如何将输入呈现给LVLM会对零参考模型的性能产生重大影响。特别是，以不充分方式表达的输入可能会导致错误答案，原因包括缺失视觉信息、复杂的隐含推理或语言歧义。因此，通过在输入中添加具有视觉基础的信息作为预防性澄清，应该能够通过减少不充分性提高模型性能，例如通过定位对象和消除引用歧义。类似地，在VQA设置中，改变问题的构思方式可以使模型更容易回答。

    arXiv:2310.05861v2 Announce Type: replace-cross  Abstract: An increasing number of vision-language tasks can be handled with little to no training, i.e., in a zero and few-shot manner, by marrying large language models (LLMs) to vision encoders, resulting in large vision-language models (LVLMs). While this has huge upsides, such as not requiring training data or custom architectures, how an input is presented to an LVLM can have a major impact on zero-shot model performance. In particular, inputs phrased in an underspecified way can result in incorrect answers due to factors like missing visual information, complex implicit reasoning, or linguistic ambiguity. Therefore, adding visually-grounded information to the input as a preemptive clarification should improve model performance by reducing underspecification, e.g., by localizing objects and disambiguating references. Similarly, in the VQA setting, changing the way questions are framed can make them easier for models to answer. To th
    
[^186]: 让行动胜于雄辩：评估LLM代理在拍卖竞技场中的战略规划与执行

    Put Your Money Where Your Mouth Is: Evaluating Strategic Planning and Execution of LLM Agents in an Auction Arena

    [https://arxiv.org/abs/2310.05746](https://arxiv.org/abs/2310.05746)

    LLM代理在拍卖竞技场展示出了关键的规划和执行技能，这为建模复杂社会互动在竞争背景下的LLMs潜力提供了新途径。

    

    最近大型语言模型（LLM）的发展展示了先进的推理能力，然而自然语言处理的评估通常依赖于静态基准。评估这一点需要测试战略推理能力的环境，这种环境需要在动态的竞争场景中进行长期规划。我们引入了AucArena，这是一个模拟拍卖的新颖评估套件，选择这个设置是因为它非常不可预测，涉及与资源和风险管理相关的许多技能，同时也易于评估。我们进行了使用最先进的LLM驱动竞标代理的受控实验，以评估他们的规划和执行技能。我们的研究表明，诸如GPT-4之类的LLM具有拍卖参与的关键技能，如预算管理和目标遵从，这些技能会随着自适应策略的改进而提高。这突出了LLM在建模竞技背景下的复杂社会互动潜力。

    arXiv:2310.05746v2 Announce Type: replace-cross  Abstract: Recent advancements in Large Language Models (LLMs) showcase advanced reasoning, yet NLP evaluations often depend on static benchmarks. Evaluating this necessitates environments that test strategic reasoning in dynamic, competitive scenarios requiring long-term planning. We introduce AucArena, a novel evaluation suite that simulates auctions, a setting chosen for being highly unpredictable and involving many skills related to resource and risk management, while also being easy to evaluate. We conduct controlled experiments using state-of-the-art LLMs to power bidding agents to benchmark their planning and execution skills. Our research demonstrates that LLMs, such as GPT-4, possess key skills for auction participation, such as budget management and goal adherence, which improve with adaptive strategies. This highlights LLMs' potential in modeling complex social interactions in competitive contexts. However, variability in LLM p
    
[^187]: 弥合投影差距：通过参数化距离学习克服投影偏差

    Bridging the Projection Gap: Overcoming Projection Bias Through Parameterized Distance Learning

    [https://arxiv.org/abs/2309.01390](https://arxiv.org/abs/2309.01390)

    通过学习参数化的马氏距离度量，解决广义零样本学习中的投影偏差问题，提出了扩展VAEGAN架构和引入新损失函数以实现更稳健的距离学习

    

    广义零样本学习（GZSL）旨在仅利用已知类别样本训练来识别来自已知和未知类别的样本。然而，在推断过程中，由于投影函数是从已知类别中学习的，GZSL方法很容易偏向已知类别。大多数方法致力于学习准确的投影，但投影中的偏差是不可避免的。我们通过提出学习参数化的马氏距离度量来解决该投影偏差，关键洞察是尽管投影存在偏差，但在推断过程中距离计算至关重要。我们作出两个主要贡献 - (1)我们通过增加两个分支扩展了VAEGAN（变分自动编码器和生成对抗网络）架构，分别输出来自已知和未知类别的样本的投影，从而实现更稳健的距离学习。 (2)我们引入了一种新颖的损失函数来优化马氏距离

    arXiv:2309.01390v2 Announce Type: replace-cross  Abstract: Generalized zero-shot learning (GZSL) aims to recognize samples from both seen and unseen classes using only seen class samples for training. However, GZSL methods are prone to bias towards seen classes during inference due to the projection function being learned from seen classes. Most methods focus on learning an accurate projection, but bias in the projection is inevitable. We address this projection bias by proposing to learn a parameterized Mahalanobis distance metric for robust inference. Our key insight is that the distance computation during inference is critical, even with a biased projection. We make two main contributions - (1) We extend the VAEGAN (Variational Autoencoder \& Generative Adversarial Networks) architecture with two branches to separately output the projection of samples from seen and unseen classes, enabling more robust distance learning. (2) We introduce a novel loss function to optimize the Mahalano
    
[^188]: 价值万花筒：将人工智能与多元化人类价值观、权利和义务联系起来

    Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties

    [https://arxiv.org/abs/2309.00779](https://arxiv.org/abs/2309.00779)

    介绍了ValuePrism，一个包含218k个价值观、权利和义务，并与31k人类书写情境相联系的大规模数据集。

    

    人类价值观对于人类的决策至关重要。价值观多元主义认为，可以同时存在多种正确的价值观（例如，在考虑是否对朋友撒谎以保护他们的感受时，如何平衡诚实和友谊？）。作为统计学习者，人工智能系统默认适应平均值，忽略了这些潜在的不可简化的价值冲突。为了改进人工智能系统以更好地反映价值多元主义，首要挑战是探索人工智能系统可以模拟多元化人类价值观、权利和义务以及它们之间互动的程度。

    arXiv:2309.00779v2 Announce Type: replace-cross  Abstract: Human values are crucial to human decision-making. Value pluralism is the view that multiple correct values may be held in tension with one another (e.g., when considering lying to a friend to protect their feelings, how does one balance honesty with friendship?). As statistical learners, AI systems fit to averages by default, washing out these potentially irreducible value conflicts. To improve AI systems to better reflect value pluralism, the first-order challenge is to explore the extent to which AI systems can model pluralistic human values, rights, and duties as well as their interaction.   We introduce ValuePrism, a large-scale dataset of 218k values, rights, and duties connected to 31k human-written situations. ValuePrism's contextualized values are generated by GPT-4 and deemed high-quality by human annotators 91% of the time. We conduct a large-scale study with annotators across diverse social and demographic backgroun
    
[^189]: 野外的生成人工智能：前景、挑战和策略

    Generative AI in the Wild: Prospects, Challenges, and Strategies

    [https://arxiv.org/abs/2302.10827](https://arxiv.org/abs/2302.10827)

    GenAI技术在创意产业中推动人类专业知识和AI能力的共同创作过程，但用户同时面临着资源、工具和监管等方面带来的挑战。

    

    驱动着生成人工智能（GenAI）技术以其出色的生成新颖和引人入胜的内容的能力，正在颠覆许多行业中的传统工作流。尽管先前的研究从技术中心的角度研究了GenAI，但人们对用户如何在现实场景中感知和利用GenAI仍然缺乏了解。为了弥合这一差距，我们对创意产业中的（N=18）GenAI用户进行了半结构化访谈，研究了在整体的LUA（学习、使用和评估）框架内人类和GenAI共同创作过程。我们的研究揭示了一个复杂而有趣的景观：前景-GenAI极大地促进了人类专业知识和GenAI能力之间的共同创作，深刻改变了创意工作流程；挑战-与此同时，用户面临着由资源可用性、工具可用性和监管复杂性引起的重大不确定性和复杂性。

    arXiv:2302.10827v2 Announce Type: replace-cross  Abstract: Propelled by their remarkable capabilities to generate novel and engaging content, Generative Artificial Intelligence (GenAI) technologies are disrupting traditional workflows in many industries. While prior research has examined GenAI from a techno-centric perspective, there is still a lack of understanding about how users perceive and utilize GenAI in real-world scenarios. To bridge this gap, we conducted semi-structured interviews with (N=18) GenAI users increative industries, investigating the human-GenAI co-creation process within a holistic LUA (Learning, Using and Assessing)framework. Our study uncovered an intriguingly complex landscape: Prospects-GenAI greatly fosters the co-creation between human expertise and GenAI capabilities, profoundly transforming creative workflows; Challenges-Meanwhile, users face substantial uncertainties and complexities arising from resource availability, tool usability, and regulatory comp
    
[^190]: 在建筑优化测试框架（BOPTEST）中对模型预测控制算法进行基准测试

    Benchmarking Model Predictive Control Algorithms in Building Optimization Testing Framework (BOPTEST)

    [https://arxiv.org/abs/2301.13447](https://arxiv.org/abs/2301.13447)

    提出了一个基于数据驱动的建模和控制框架，加速模型评估、提供成本效益的梯度，并在模型预测控制中保持良好的预测精度，同时通过建筑优化测试框架（BOPTEST）对建模和控制性能进行广泛评估

    

    我们提出了一个基于数据驱动的建模和控制框架，用于基于物理的建筑仿真器。我们的方法包括：（a）训练加速模型评估、提供具有成本效益的梯度、并保持在模型预测控制（MPC）中回溯视野的良好预测精度的可微替代模型；以及（b）制定和解决非线性建筑空调暖通空调MPC问题。我们通过使用建筑优化测试框架（BOPTEST）中提供的各种测试案例，广泛评估建模和控制性能。我们的框架与其他建模技术兼容，并可以通过不同的控制公式进行定制，使其适应并为当前正在为BOPTEST开发的测试案例提供了前瞻设计保证。这种模块化性为在大型建筑物中设计预测控制器提供了一条道路，确保

    arXiv:2301.13447v2 Announce Type: replace-cross  Abstract: We present a data-driven modeling and control framework for physics-based building emulators. Our approach consists of: (a) Offline training of differentiable surrogate models that accelerate model evaluations, provide cost-effective gradients, and maintain good predictive accuracy for the receding horizon in Model Predictive Control (MPC), and (b) Formulating and solving nonlinear building HVAC MPC problems. We extensively evaluate the modeling and control performance using multiple surrogate models and optimization frameworks across various test cases available in the Building Optimization Testing Framework (BOPTEST). Our framework is compatible with other modeling techniques and can be customized with different control formulations, making it adaptable and future-proof for test cases currently under development for BOPTEST. This modularity provides a path towards prototyping predictive controllers in large buildings, ensurin
    
[^191]: BRAIxDet：学习使用不完整注释检测恶性乳腺病变

    BRAIxDet: Learning to Detect Malignant Breast Lesion with Incomplete Annotations

    [https://arxiv.org/abs/2301.13418](https://arxiv.org/abs/2301.13418)

    本文提出了一种中间解决方案，即将训练构建为弱监督和半监督学习问题，以解决通过不完整注释数据检测恶性乳腺病变的困境

    

    从筛查乳房X线照片中检测恶性病变的方法通常是使用具有完全注释的数据集进行训练，其中图像被标记为癌症病变的定位和分类。然而，真实世界的筛查乳房X线照片数据集通常有一个部分是完全注释的，另一个部分只有全局分类的弱注释（即没有病变定位）。鉴于这类数据集的庞大规模，研究人员通常在弱注释子集面临两难选择：要么不使用它，要么完全注释它。第一种选择会降低检测准确性，因为它没有使用整个数据集，而第二种选择则过于昂贵，因为注释需要专业放射科医师完成。在本文中，我们提出了这一困境的一个中间解决方案，即将训练构建为一个我们称之为恶性

    arXiv:2301.13418v3 Announce Type: replace-cross  Abstract: Methods to detect malignant lesions from screening mammograms are usually trained with fully annotated datasets, where images are labelled with the localisation and classification of cancerous lesions. However, real-world screening mammogram datasets commonly have a subset that is fully annotated and another subset that is weakly annotated with just the global classification (i.e., without lesion localisation). Given the large size of such datasets, researchers usually face a dilemma with the weakly annotated subset: to not use it or to fully annotate it. The first option will reduce detection accuracy because it does not use the whole dataset, and the second option is too expensive given that the annotation needs to be done by expert radiologists. In this paper, we propose a middle-ground solution for the dilemma, which is to formulate the training as a weakly- and semi-supervised learning problem that we refer to as malignant
    
[^192]: 可塑性扩散：单图像化身创建的三维一致扩散

    Morphable Diffusion: 3D-Consistent Diffusion for Single-image Avatar Creation. (arXiv:2401.04728v1 [cs.CV])

    [http://arxiv.org/abs/2401.04728](http://arxiv.org/abs/2401.04728)

    本文通过在多视点一致扩散方法中整合三维可塑模型，提高了从单个图像生成三维一致、可动画和逼真的人物化身的质量和功能。

    

    最近的生成扩散模型的进展使得从单个输入图像或文本提示生成三维资产成为可能。在这项工作中，我们旨在增强这些模型在创建可控、逼真的人物化身任务中的质量和功能。我们通过将三维可塑模型整合到最先进的多视点一致扩散方法中来实现这一目标。我们证明了精确地将生成流程与关节三维模型的条件相结合，提高了基准模型在单个图像的新视图合成任务上的性能。更重要的是，这种整合使面部表情和身体姿势控制在生成过程中无缝准确地融入其中。据我们所知，我们提出的框架是第一个能够从未见过的主题的单个图像创建完全三维一致、可动画和逼真的人物化身的扩散模型；扩展了当前研究的能力。

    Recent advances in generative diffusion models have enabled the previously unfeasible capability of generating 3D assets from a single input image or a text prompt. In this work, we aim to enhance the quality and functionality of these models for the task of creating controllable, photorealistic human avatars. We achieve this by integrating a 3D morphable model into the state-of-the-art multiview-consistent diffusion approach. We demonstrate that accurate conditioning of a generative pipeline on the articulated 3D model enhances the baseline model performance on the task of novel view synthesis from a single image. More importantly, this integration facilitates a seamless and accurate incorporation of facial expression and body pose control into the generation process. To the best of our knowledge, our proposed framework is the first diffusion model to enable the creation of fully 3D-consistent, animatable, and photorealistic human avatars from a single image of an unseen subject; exte
    
[^193]: i-Rebalance: 个性化车辆重新定位以实现供需平衡

    i-Rebalance: Personalized Vehicle Repositioning for Supply Demand Balance. (arXiv:2401.04429v1 [cs.AI])

    [http://arxiv.org/abs/2401.04429](http://arxiv.org/abs/2401.04429)

    本文提出了一种名为i-Rebalance的个性化车辆重新定位技术，通过深度强化学习（DRL）估计驾驶员对重新定位推荐的决策。该技术采用顺序重新定位策略，并使用双DRL代理实现供需平衡和驾驶员偏好满意度的优化。

    

    租车平台面临着供需平衡的挑战。现有的车辆重新定位技术通常将司机视为同质化的代理人，并且以确定性的方式重新定位他们，假设他们会遵守重新定位。在本文中，我们考虑了一个更真实和以驾驶员为中心的场景，其中驾驶员具有独特的巡航偏好，并且可以自行决定是否接受推荐。我们提出了一种使用深度强化学习（DRL）的个性化车辆重新定位技术：i-Rebalance。i-Rebalance通过涉及99名真实驾驶员的现场用户研究来估计驾驶员对重新定位推荐的决策。为了同时优化供需平衡和增强偏好满意度，i-Rebalance采用了顺序重新定位策略，并使用双DRL代理：网格代理确定空闲车辆的重新定位顺序，车辆代理为预定义的顺序中的每辆车提供个性化推荐。

    Ride-hailing platforms have been facing the challenge of balancing demand and supply. Existing vehicle reposition techniques often treat drivers as homogeneous agents and relocate them deterministically, assuming compliance with the reposition. In this paper, we consider a more realistic and driver-centric scenario where drivers have unique cruising preferences and can decide whether to take the recommendation or not on their own. We propose i-Rebalance, a personalized vehicle reposition technique with deep reinforcement learning (DRL). i-Rebalance estimates drivers' decisions on accepting reposition recommendations through an on-field user study involving 99 real drivers. To optimize supply-demand balance and enhance preference satisfaction simultaneously, i-Rebalance has a sequential reposition strategy with dual DRL agents: Grid Agent to determine the reposition order of idle vehicles, and Vehicle Agent to provide personalized recommendations to each vehicle in the pre-defined order
    
[^194]: 改变提示的蝴蝶效应：微小的变化和越狱对大规模语言模型性能的影响

    The Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Model Performance. (arXiv:2401.03729v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.03729](http://arxiv.org/abs/2401.03729)

    本研究通过一系列提示变化探究改变提示的构建方式对大规模语言模型决策的影响，发现即使微小的改变，比如在提示末尾加一个空格，也可能导致模型的答案变化。同时，请求以XML格式返回和常用的越狱方式也可能对模型标记的数据产生灾难性影响。

    

    大规模语言模型（LLMs）被广泛用于对多个领域和多个任务的数据进行标注。通过简单地向LLM提问或“提示”，实践者能够快速获得任意任务的响应。提示的构建方式是否变化会影响LLM的最终决策？我们通过对多种文本分类任务进行一系列提示变化来回答这个问题。我们发现，即使是最微小的扰动，比如在提示的末尾加一个空格，也可能导致LLM改变其答案。此外，我们发现在XML中请求响应和常用的越狱方式可能对由LLMs标记的数据产生灾难性影响。

    Large Language Models (LLMs) are regularly being used to label data across many domains and for myriad tasks. By simply asking the LLM for an answer, or ``prompting,'' practitioners are able to use LLMs to quickly get a response for an arbitrary task. This prompting is done through a series of decisions by the practitioner, from simple wording of the prompt, to requesting the output in a certain data format, to jailbreaking in the case of prompts that address more sensitive topics. In this work, we ask: do variations in the way a prompt is constructed change the ultimate decision of the LLM? We answer this using a series of prompt variations across a variety of text classification tasks. We find that even the smallest of perturbations, such as adding a space at the end of a prompt, can cause the LLM to change its answer. Further, we find that requesting responses in XML and commonly used jailbreaks can have cataclysmic effects on the data labeled by LLMs.
    
[^195]: SVGDreamer：基于文本引导的SVG生成与扩散模型

    SVGDreamer: Text Guided SVG Generation with Diffusion Model. (arXiv:2312.16476v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.16476](http://arxiv.org/abs/2312.16476)

    该论文提出了一种名为SVGDreamer的方法，用于基于文本引导的SVG生成。它通过引入语义驱动的图像矢量化过程和基于注意力的元素控制，增强了生成结果的可编辑性和质量。同时，采用基于矢量化粒子分数蒸馏的方法解决了现有方法中的颜色、平滑度和结果多样性方面的挑战。

    

    最近，基于文本引导的可缩放矢量图形（SVG）合成在图标设计和草图等领域展示出了潜力。然而，现有的文本到SVG生成方法存在缺乏可编辑性、视觉质量和结果多样性不足的问题。为了解决这些限制，我们提出了一种新颖的基于文本引导的矢量图形合成方法，称为SVGDreamer。SVGDreamer整合了一种语义驱动的图像矢量化（SIVE）过程，可以将合成过程分解为前景对象和背景，从而增强了可编辑性。具体而言，SIVE过程引入了基于注意力的基本元素控制和注意力掩蔽损失函数，以有效控制和操作各个元素。此外，我们提出了一种基于矢量化粒子分数蒸馏（VPSD）的方法，以解决现有文本到SVG生成方法中颜色过饱和、矢量基元过平滑和结果多样性有限的挑战。

    Recently, text-guided scalable vector graphics (SVGs) synthesis has shown promise in domains such as iconography and sketch. However, existing text-to-SVG generation methods lack editability and struggle with visual quality and result diversity. To address these limitations, we propose a novel text-guided vector graphics synthesis method called SVGDreamer. SVGDreamer incorporates a semantic-driven image vectorization (SIVE) process that enables the decomposition of synthesis into foreground objects and background, thereby enhancing editability. Specifically, the SIVE process introduce attention-based primitive control and an attention-mask loss function for effective control and manipulation of individual elements. Additionally, we propose a Vectorized Particle-based Score Distillation (VPSD) approach to tackle the challenges of color over-saturation, vector primitives over-smoothing, and limited result diversity in existing text-to-SVG generation methods. Furthermore, on the basis of 
    
[^196]: YAYI-UIE: 一个增强对话指导的通用信息抽取调优框架

    YAYI-UIE: A Chat-Enhanced Instruction Tuning Framework for Universal Information Extraction. (arXiv:2312.15548v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.15548](http://arxiv.org/abs/2312.15548)

    本文提出了一个端到端的增强对话指导的通用信息抽取调优框架（YAYI-UIE），利用对话数据和信息抽取数据共同增强信息抽取性能，在中文数据集上达到了业界领先的性能，在英文数据集上也达到了可比较的性能。

    

    信息抽取任务的难点在于处理特定任务的标签模式和异构数据结构。最近的工作提出了基于大型语言模型的方法来统一建模不同的信息抽取任务。然而，这些现有方法在除了英语以外的中文语言的信息提取能力上存在不足。在本文中，我们提出了一个端到端的增强对话指导的通用信息抽取调优框架（YAYI-UIE），支持中文和英文。具体而言，我们利用对话数据和信息抽取数据共同增强信息抽取性能。实验结果表明，我们提出的框架在中文数据集上达到了业界领先的性能，同时在有监督和零样本设置下在英文数据集上也达到了可比较的性能。

    The difficulty of the information extraction task lies in dealing with the task-specific label schemas and heterogeneous data structures. Recent work has proposed methods based on large language models to uniformly model different information extraction tasks. However, these existing methods are deficient in their information extraction capabilities for Chinese languages other than English. In this paper, we propose an end-to-end chat-enhanced instruction tuning framework for universal information extraction (YAYI-UIE), which supports both Chinese and English. Specifically, we utilize dialogue data and information extraction data to enhance the information extraction performance jointly. Experimental results show that our proposed framework achieves state-of-the-art performance on Chinese datasets while also achieving comparable performance on English datasets under both supervised settings and zero-shot settings.
    
[^197]: AGI系统的元提示

    Meta Prompting for AGI Systems. (arXiv:2311.11482v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2311.11482](http://arxiv.org/abs/2311.11482)

    本文全面研究了元提示技术，这是一种创新方法，重塑了大型语言模型、多模态模型和人工智能系统在问题解决和数据解释方面的应用。通过强调信息的结构和句法，元提示将复杂问题拆解为简单的子问题，提高了效率，并且能够与少样本方法进行公平的比较。同时，本文还提出了元提示用于自动生成提示的方法。

    

    本文介绍了元提示(meta prompting)的全面研究，这是一种创新技术，重新塑造了大型语言模型(LLMs)、多模态基础模型和人工智能系统在问题解决和数据解释方面的利用。基于类型理论和范畴论，元提示注重信息的结构和句法，而不是传统以内容为中心的方法。本文探讨了元提示的形式定义，并将其与少样本提示(few-shot prompting)区分开来，并强调其在各种人工智能应用中的有效性。重点关注将元提示扩展到复杂推理任务上，展示如何将复杂问题拆分成较为简单的子问题，提高令牌效率，并使问题求解的比较更加公平，尤其是与少样本示例方法相比。此外，本文还引入了元提示用于提示任务，允许LLMs以迭代的元编程形式自动生成新的提示。

    This paper presents a comprehensive study of Meta Prompting, an innovative technique reshaping the utilization of large language models (LLMs), multi-modal foundation models, and AI systems in problem-solving and data interpretation. Grounded in type theory and category theory, Meta Prompting emphasizes the structure and syntax of information over traditional content-centric methods. The paper explores the formal definitions of Meta Prompting (MP), sets it apart from Few-Shot Prompting, and underlines its effectiveness in various AI applications. A key focus is on extending Meta Prompting to complex reasoning tasks, showing how it effectively deconstructs intricate problems into simpler sub-problems, enhancing token efficiency and enabling more equitable problem-solving comparisons, especially against few-shot example methods. Additionally, the paper introduces Meta Prompting for Prompting Tasks, allowing LLMs to self-generate new prompts in an iterative, metaprogramming-like manner. T
    
[^198]: FedSN：一个适用于LEO卫星网络的通用联邦学习框架

    FedSN: A General Federated Learning Framework over LEO Satellite Networks. (arXiv:2311.01483v1 [cs.LG])

    [http://arxiv.org/abs/2311.01483](http://arxiv.org/abs/2311.01483)

    FedSN是一个通用的联邦学习框架，用于解决在LEO卫星网络中的异构计算和存储能力、有限的上行速率以及模型陈旧等关键挑战。

    

    最近，许多低地球轨道（LEO）卫星已经由商业公司成功地发射和部署到太空中，如SpaceX。由于LEO卫星配备了多模传感器，它们不仅用于通信，还用于各种机器学习应用，如空间调制识别、遥感图像分类等。然而，由于与LEO卫星的有限接触时间（例如5分钟），地面站（GS）可能无法下载如此大量的原始感测数据进行集中模型训练。因此，联邦学习（FL）已经成为解决这个问题的有希望的解决方案，通过在设备上进行训练。不幸的是，要在LEO卫星上使用FL，我们仍然面临三个关键挑战，即i）异构计算和存储能力，ii）有限的上行速率，以及iii）模型陈旧问题。为此，我们提出了一种名为FedSN的通用FL框架来解决上述挑战，一

    Recently, a large number of Low Earth Orbit (LEO) satellites have been launched and deployed successfully in space by commercial companies, such as SpaceX. Due to multimodal sensors equipped by the LEO satellites, they serve not only for communication but also for various machine learning applications, such as space modulation recognition, remote sensing image classification, etc. However, the ground station (GS) may be incapable of downloading such a large volume of raw sensing data for centralized model training due to the limited contact time with LEO satellites (e.g. 5 minutes). Therefore, federated learning (FL) has emerged as the promising solution to address this problem via on-device training. Unfortunately, to enable FL on LEO satellites, we still face three critical challenges that are i) heterogeneous computing and memory capabilities, ii) limited uplink rate, and iii) model staleness. To this end, we propose FedSN as a general FL framework to tackle the above challenges, an
    
[^199]: 用多任务神经网络学习和发现量子性质

    Learning and Discovering Quantum Properties with Multi-Task Neural Networks. (arXiv:2310.11807v1 [quant-ph])

    [http://arxiv.org/abs/2310.11807](http://arxiv.org/abs/2310.11807)

    这篇论文介绍了一种用多任务神经网络学习和发现量子性质的方法，该方法能够同时预测和发现多个量子性质，并且能够推断多体量子系统的全局性质和发现不同相之间的未知边界。

    

    深度神经网络是一种从有限测量数据中预测量子态性质的强大工具。在这里，我们开发了一个网络模型，可以同时预测多个量子性质，包括量子可观测量的期望值以及量子状态的一般非线性函数，如纠缠熵和多体拓扑不变量。值得注意的是，我们发现一个在给定性质集上训练的模型也可以发现超出该集合的新性质。多功能训练还使模型能够从局部测量中推断出多体量子系统的全局性质，分类保护对称的拓扑物质相，并发现不同相之间的未知边界。

    Deep neural networks are a powerful tool for predicting properties of quantum states from limited measurement data. Here we develop a network model that can simultaneously predict multiple quantum properties, including not only expectation values of quantum observables, but also general nonlinear functions of the quantum state, like entanglement entropies and many-body topological invariants. Remarkably, we find that a model trained on a given set of properties can also discover new properties outside that set. Multi-purpose training also enables the model to infer global properties of many-body quantum systems from local measurements, to classify symmetry protected topological phases of matter, and to discover unknown boundaries between different phases.
    
[^200]: 量化中文医学大型语言模型中与健康相关的原子知识：一项计算分析

    Quantify Health-Related Atomic Knowledge in Chinese Medical Large Language Models: A Computational Analysis. (arXiv:2310.11722v1 [cs.CL])

    [http://arxiv.org/abs/2310.11722](http://arxiv.org/abs/2310.11722)

    本研究通过构建一个基准，量化了中文医学大型语言模型中与健康相关的原子知识的存储程度，并发现通用LLMs在原子知识和指令遵循能力方面表现更好。两种类型的LLMs都倾向于迎合用户要求。

    

    大型语言模型（LLMs）有潜力通过搜索引擎直接和高效地提供用户的自诊断建议，从而革新用户自诊断的方式。最近的研究主要关注基于GPT-4评估LLMs的质量或其通过医学考试的能力，但没有研究量化存储在LLMs记忆中的健康相关原子知识的程度，而这是LLMs提供更准确建议的基础。在本文中，我们首先构建了一个基准，包括用户自诊断查询中最常见的原子知识类型，共17种原子类型和14048条原子知识。然后，我们对通用和专业LLMs在基准上进行了评估。实验结果表明，在原子知识和指令遵循能力方面，通用LLMs的表现优于专业LLMs。错误分析显示，通用和专业LLMs都是马屁精，即在涉及用户要求时总是迎合用户。

    Large Language Models (LLMs) have the potential to revolutionize the way users self-diagnose through search engines by offering direct and efficient suggestions. Recent studies primarily focused on the quality of LLMs evaluated by GPT-4 or their ability to pass medical exams, no studies have quantified the extent of health-related atomic knowledge stored in LLMs' memory, which is the basis of LLMs to provide more factual suggestions. In this paper, we first constructed a benchmark, including the most common types of atomic knowledge in user self-diagnosis queries, with 17 atomic types and a total of 14, 048 pieces of atomic knowledge. Then, we evaluated both generic and specialized LLMs on the benchmark. The experimental results showcased that generic LLMs perform better than specialized LLMs in terms of atomic knowledge and instruction-following ability. Error analysis revealed that both generic and specialized LLMs are sycophantic, e.g., always catering to users' claims when it comes
    
[^201]: Hexa: 知识驱动的对话系统的自我提升

    Hexa: Self-Improving for Knowledge-Grounded Dialogue System. (arXiv:2310.06404v1 [cs.CL])

    [http://arxiv.org/abs/2310.06404](http://arxiv.org/abs/2310.06404)

    本论文提出了一种自我提升的方法，用于改进知识驱动对话生成的中间步骤的生成性能。通过引入引导提示和修改损失函数的自举策略，提高了生成自动生成回答的多样性，并在各种基准数据集上实验证明了该方法的有效性。

    

    知识驱动的对话生成中一种常见的做法是使用模块化的方法明确地利用中间步骤（如网络搜索、记忆检索）。然而，与对话响应相比，这些步骤的数据往往难以获取，因为在普通对话中无法观察到它们。为了填补这些数据的缺失，我们开发了一种自我提升方法，以改进中间步骤的生成性能，而不需要地面真实数据。具体而言，我们提出了一种新颖的引导提示和修改的损失函数的引导自动生成回答多样性的自举方法。通过在各种基准数据集上进行实验，我们经验证明我们的方法成功地利用了自我提升机制，在生成中间和最终回答方面改善了知识驱动对话生成任务的性能。

    A common practice in knowledge-grounded dialogue generation is to explicitly utilize intermediate steps (e.g., web-search, memory retrieval) with modular approaches. However, data for such steps are often inaccessible compared to those of dialogue responses as they are unobservable in an ordinary dialogue. To fill in the absence of these data, we develop a self-improving method to improve the generative performances of intermediate steps without the ground truth data. In particular, we propose a novel bootstrapping scheme with a guided prompt and a modified loss function to enhance the diversity of appropriate self-generated responses. Through experiments on various benchmark datasets, we empirically demonstrate that our method successfully leverages a self-improving mechanism in generating intermediate and final responses and improves the performances on the task of knowledge-grounded dialogue generation.
    
[^202]: 让PPO变得更好：基于值导向的Monte-Carlo Tree Search解码

    Making PPO even better: Value-Guided Monte-Carlo Tree Search decoding. (arXiv:2309.15028v1 [cs.CL])

    [http://arxiv.org/abs/2309.15028](http://arxiv.org/abs/2309.15028)

    本文提出了一种基于值导向的Monte-Carlo Tree Search解码算法PPO-MCTS，通过在PPO之上集成MCTS，解决了训练和测试之间部分输出评分机制的不匹配问题，实验证明该算法可以显著提升性能。

    

    在生成自然语言文本时，使用最新的强化学习算法，如Proximal Policy Optimization (PPO)，因此可以认为推理时间的搜索算法，如Monte-Carlo Tree Search (MCTS) 是不必要的。本文证明了通过在PPO之上集成MCTS，可以进一步提升PPO的性能。关键思想是在解码文本时，不要丢弃值网络，即PPO训练时用于评估部分输出序列的副产品，而是将其与策略网络紧密结合。具体而言，本文提出了一种称为PPO-MCTS的新颖的值导向解码算法，可以将来自PPO的值网络与推理时间产生的策略网络紧密结合。与基于MCTS的控制文本生成的先前方法相比，我们的方法的关键优势在于减少了训练和测试之间部分输出的评分机制的基本不匹配。在四个文本生成任务上的评估结果表明，PPO-MCTS可以显著提升性能。

    Inference-time search algorithms such as Monte-Carlo Tree Search (MCTS) may seem unnecessary when generating natural language text based on state-of-the-art reinforcement learning such as Proximal Policy Optimization (PPO). In this paper, we demonstrate that it is possible to get extra mileage out of PPO by integrating MCTS on top. The key idea is not to throw out the value network, a byproduct of PPO training for evaluating partial output sequences, when decoding text out of the policy network. More concretely, we present a novel value-guided decoding algorithm called PPO-MCTS, which can integrate the value network from PPO to work closely with the policy network during inference-time generation. Compared to prior approaches based on MCTS for controlled text generation, the key strength of our approach is to reduce the fundamental mismatch of the scoring mechanisms of the partial outputs between training and test. Evaluation on four text generation tasks demonstrate that PPO-MCTS grea
    
[^203]: "公平游戏"，还是吗？研究用户在使用基于LLM的对话型智能助手时如何处理披露风险和效益

    "It's a Fair Game'', or Is It? Examining How Users Navigate Disclosure Risks and Benefits When Using LLM-Based Conversational Agents. (arXiv:2309.11653v1 [cs.HC])

    [http://arxiv.org/abs/2309.11653](http://arxiv.org/abs/2309.11653)

    本研究通过分析用户在实际对话中的敏感披露和采访LLM型对话型智能助手用户的方式，发现用户在使用LLM型对话型智能助手时面临隐私、效用和便利之间的权衡，但用户对隐私风险的认知存在问题，而人类化的互动鼓励了更多敏感的披露，加重了用户的权衡困难。

    

    基于大型语言模型（LLM）的对话型智能助手在高风险领域的广泛使用引发了许多隐私问题。构建尊重用户隐私的道德LLM型对话型智能助手需要深入了解最关注用户的隐私风险。然而，现有的研究主要以模型为中心，无法提供用户的观点。为了弥补这一差距，我们分析了实际的ChatGPT对话中的敏感披露，并对19名LLM型对话型智能助手用户进行了半结构化采访。我们发现，在使用LLM型对话型智能助手时，用户不断面临隐私、效用和便利之间的权衡。然而，用户错误的心智模式和系统设计中的黑暗模式限制了他们对隐私风险的认识和理解。此外，人类化的互动鼓励了更多敏感的披露，这使得用户在权衡中更加困难。我们讨论了实际的设计指南。

    The widespread use of Large Language Model (LLM)-based conversational agents (CAs), especially in high-stakes domains, raises many privacy concerns. Building ethical LLM-based CAs that respect user privacy requires an in-depth understanding of the privacy risks that concern users the most. However, existing research, primarily model-centered, does not provide insight into users' perspectives. To bridge this gap, we analyzed sensitive disclosures in real-world ChatGPT conversations and conducted semi-structured interviews with 19 LLM-based CA users. We found that users are constantly faced with trade-offs between privacy, utility, and convenience when using LLM-based CAs. However, users' erroneous mental models and the dark patterns in system design limited their awareness and comprehension of the privacy risks. Additionally, the human-like interactions encouraged more sensitive disclosures, which complicated users' ability to navigate the trade-offs. We discuss practical design guideli
    
[^204]: SLIDE: 使用滑动文档窗口进行无参考机器翻译评估

    SLIDE: Reference-free Evaluation for Machine Translation using a Sliding Document Window. (arXiv:2309.08832v1 [cs.CL])

    [http://arxiv.org/abs/2309.08832](http://arxiv.org/abs/2309.08832)

    本论文提出了一种名为SLIDE的度量方法，通过使用滑动文档窗口来评估机器翻译质量，该方法在某些情况下甚至能消除与参考度量之间的差距，表明源语言上下文可能提供了与人类参考相同的信息。

    

    基于参考的度量通常在句子级别上优于仅能访问源语言和系统输出的质量估计度量。这并不奇怪，因为参考能够消除源语言中可能存在的歧义。我们研究了是否可以用额外的源语言上下文有效地替代参考。我们提出了一种度量方法，SLIDE（SLiding Document Evaluator），它通过一个滑动窗口在每个测试集中的文档上操作，将每个块输入到未修改的现成质量估计模型中。我们发现，SLIDE在系统准确性的成对比较上较句子级别基线显著提高，有些情况下甚至消除了与参考度量之间的差距。这表明源语言上下文可能提供了与人类参考相同的信息。

    Reference-based metrics that operate at the sentence level typically outperform quality estimation metrics, which have access only to the source and system output. This is unsurprising, since references resolve ambiguities that may be present in the source. We investigate whether additional source context can effectively substitute for a reference. We present a metric, SLIDE (SLiding Document Evaluator), which operates on blocks of sentences using a window that slides over each document in the test set, feeding each chunk into an unmodified, off-the-shelf quality estimation model. We find that SLIDE obtains significantly higher pairwise system accuracy than its sentence-level baseline, in some cases even eliminating the gap with reference-base metrics. This suggests that source context may provide the same information as a human reference.
    
[^205]: MusiLingo：利用预训练的语言模型将音乐和文本相结合，实现音乐字幕和查询响应

    MusiLingo: Bridging Music and Text with Pre-trained Language Models for Music Captioning and Query Response. (arXiv:2309.08730v1 [eess.AS])

    [http://arxiv.org/abs/2309.08730](http://arxiv.org/abs/2309.08730)

    MusiLingo是一个利用预训练的语言模型将音乐和文本相结合的系统，可以生成音乐字幕和回答音乐相关的查询。通过使用投影层对齐音乐表示，该系统成功地将音乐音频和文本环境联系起来，同时使用了一个新的数据集来推动领域的进展。

    

    大型语言模型（LLM）已经在多模态应用中展现出巨大潜力，然而文本和音乐领域的融合仍相对未被探索。为了解决这一问题，我们提出了MusiLingo，这是一个用于音乐字幕生成和音乐相关查询响应的新系统。MusiLingo使用一个投影层来对齐预训练的冻结音乐音频模型MERT和冻结的LLaMA语言模型的音乐表示，实现音乐音频和文本环境之间的桥梁。我们在一个大规模的音乐字幕数据集上进行训练，并使用指导性数据进行微调。由于高质量的音乐问答数据集稀缺，我们从MusicCaps创建了MusicInstruct（MI）数据集，专为开放式音乐查询而设计。实证评估证明了它在生成音乐字幕和组织音乐相关问答对方面的竞争性表现。我们引入的数据集在之前的数据集的基础上取得了显著进展。

    Large Language Models (LLMs) have shown immense potential in multimodal applications, yet the convergence of textual and musical domains remains relatively unexplored. To address this gap, we present MusiLingo, a novel system for music caption generation and music-related query responses. MusiLingo employs a single projection layer to align music representations from the pre-trained frozen music audio model MERT with the frozen LLaMA language model, bridging the gap between music audio and textual contexts. We train it on an extensive music caption dataset and fine-tune it with instructional data. Due to the scarcity of high-quality music Q&A datasets, we created the MusicInstruct (MI) dataset from MusicCaps, tailored for open-ended music inquiries. Empirical evaluations demonstrate its competitive performance in generating music captions and composing music-related Q&A pairs. Our introduced dataset enables notable advancements beyond previous ones.
    
[^206]: ExpertQA: 专家策划的问题和带有属性的答案

    ExpertQA: Expert-Curated Questions and Attributed Answers. (arXiv:2309.07852v1 [cs.CL])

    [http://arxiv.org/abs/2309.07852](http://arxiv.org/abs/2309.07852)

    本论文介绍了ExpertQA，它是一个专家策划的问题和带有属性的答案系统。该系统通过分析语言模型在领域特定情景中提供的事实准确性和归因等方面来确保提供准确的信息。研究还收集了领域专家的问题并要求他们评估生成的答案。这项工作的目的是确保语言模型在高风险领域中不会传播错误信息，从而避免不良的社会后果。

    

    随着语言模型被越来越复杂和多样化的用户所采用，确保它们提供基于可验证来源的事实准确信息的重要性在各个领域的研究和职业中都是至关重要的。这特别适用于医学和法律等高风险领域，因为传播错误信息的风险较高，可能导致不良的社会后果。先前的研究关注于事实性和归因方面，并未专注于分析语言模型在特定领域情景中的这些特征。在这项工作中，我们通过将领域专家纳入其中，提出了一个评估研究，分析来自几个系统的响应中提供的事实准确性和归因的各个方面。具体而言，我们先从32个学科领域的484名参与者中收集由专家策划的问题，然后要求这些专家评估对他们自己问题的产生的响应。我们还要求专家修改产生的答案。

    As language models are adapted by a more sophisticated and diverse set of users, the importance of guaranteeing that they provide factually correct information supported by verifiable sources is critical across fields of study & professions. This is especially the case for high-stakes fields, such as medicine and law, where the risk of propagating false information is high and can lead to undesirable societal consequences. Previous work studying factuality and attribution has not focused on analyzing these characteristics of language model outputs in domain-specific scenarios. In this work, we present an evaluation study analyzing various axes of factuality and attribution provided in responses from a few systems, by bringing domain experts in the loop. Specifically, we first collect expert-curated questions from 484 participants across 32 fields of study, and then ask the same experts to evaluate generated responses to their own questions. We also ask experts to revise answers produce
    
[^207]: LLM-Rec: 通过引导大型语言模型进行个性化推荐

    LLM-Rec: Personalized Recommendation via Prompting Large Language Models. (arXiv:2307.15780v1 [cs.CL])

    [http://arxiv.org/abs/2307.15780](http://arxiv.org/abs/2307.15780)

    本文通过引导大型语言模型进行个性化推荐的研究，提出了四种不同的引导策略，并通过实验证明了这些策略的有效性。这一发现强调了在个性化内容推荐中，采用多样的引导和输入增强技术可以提高大型语言模型的推荐性能。

    

    本文通过输入增强技术，研究了多种不同的引导策略，以提高大型语言模型（LLM）在个性化内容推荐方面的性能。我们提出的方法名为LLM-Rec，包括四种不同的引导策略：（1）基础引导，（2）推荐驱动引导，（3）参与引导引导，和（4）推荐驱动+参与引导引导。实验证明，将原始内容描述与LLM生成的增强输入文本结合起来，采用这些引导策略可以提高推荐性能。这一发现强调了在个性化内容推荐中，通过引入多样的引导和输入增强技术来提升大型语言模型的推荐能力的重要性。

    We investigate various prompting strategies for enhancing personalized content recommendation performance with large language models (LLMs) through input augmentation. Our proposed approach, termed LLM-Rec, encompasses four distinct prompting strategies: (1) basic prompting, (2) recommendation-driven prompting, (3) engagement-guided prompting, and (4) recommendation-driven + engagement-guided prompting. Our empirical experiments show that combining the original content description with the augmented input text generated by LLM using these prompting strategies leads to improved recommendation performance. This finding highlights the importance of incorporating diverse prompts and input augmentation techniques to enhance the recommendation capabilities with large language models for personalized content recommendation.
    
[^208]: 梯度反击：如何滤除高频率提高解释性

    Gradient strikes back: How filtering out high frequencies improves explanations. (arXiv:2307.09591v1 [cs.AI])

    [http://arxiv.org/abs/2307.09591](http://arxiv.org/abs/2307.09591)

    本研究发现，基于预测的属性方法与基于梯度的方法产生的属性图具有不同的高频内容，滤除高频率可以提高解释性。

    

    近年来，新型基于预测的属性方法的发展迅猛，逐渐取代了旧的基于梯度的方法来解释深度神经网络的决策。然而，预测型方法为何优于梯度型方法仍不清楚。本文从经验观察开始：这两种方法产生的属性图具有非常不同的功率谱，梯度型方法揭示了比预测型方法更多的高频内容。这一观察引发了多个问题：这种高频信息的来源是什么，它是否真正反映了系统所作出的决策？最后，为什么在多个评价指标下，预测型方法中缺乏高频信息将产生更好的可解释性分数？我们分析了三个代表性的视觉分类模型的梯度，并观察到它包含来自高频的噪声信息。

    Recent years have witnessed an explosion in the development of novel prediction-based attribution methods, which have slowly been supplanting older gradient-based methods to explain the decisions of deep neural networks. However, it is still not clear why prediction-based methods outperform gradient-based ones. Here, we start with an empirical observation: these two approaches yield attribution maps with very different power spectra, with gradient-based methods revealing more high-frequency content than prediction-based methods. This observation raises multiple questions: What is the source of this high-frequency information, and does it truly reflect decisions made by the system? Lastly, why would the absence of high-frequency information in prediction-based methods yield better explainability scores along multiple metrics? We analyze the gradient of three representative visual classification models and observe that it contains noisy information emanating from high-frequencies. Furthe
    
[^209]: 学习核技术用于可解释和高效的PPG信号质量评估和伪影分割

    Learned Kernels for Interpretable and Efficient PPG Signal Quality Assessment and Artifact Segmentation. (arXiv:2307.05385v1 [eess.SP])

    [http://arxiv.org/abs/2307.05385](http://arxiv.org/abs/2307.05385)

    本文提出了一种通过学习核技术，具有解释性且参数较少的方法来评估和分割PPG信号的质量和伪影，与现有的深度神经网络方法相比有着类似甚至更好的性能。

    

    光电容抗(PPG)提供了一种低成本、非侵入性的方法来持续监测各种心血管参数。PPG信号由可穿戴设备产生，常常包含由外部因素(如人体运动)引起的大型伪影。为了确保对生理参数进行稳健和准确的提取，信号的损坏区域需要被正确地识别和处理。之前的方法依靠手工特征检测器或信号度量，结果性能不佳，或依靠深度神经网络(DNN)等机器学习技术，缺乏可解释性，计算和内存密集。在这项工作中，我们提出了一种新的方法，学习一小组可解释的卷积核，其性能与现有技术DNN方法相似，甚至更好，而参数数量比DNN方法少几个数量级。这项工作实现了高效、稳健和可解释的PPG信号质量评估和伪影分割。

    Photoplethysmography (PPG) provides a low-cost, non-invasive method to continuously monitor various cardiovascular parameters. PPG signals are generated by wearable devices and frequently contain large artifacts caused by external factors, such as motion of the human subject. In order to ensure robust and accurate extraction of physiological parameters, corrupted areas of the signal need to be identified and handled appropriately. Previous methodology relied either on handcrafted feature detectors or signal metrics which yield sub-optimal performance, or relied on machine learning techniques such as deep neural networks (DNN) which lack interpretability and are computationally and memory intensive. In this work, we present a novel method to learn a small set of interpretable convolutional kernels that has performance similar to -- and often better than -- the state-of-the-art DNN approach with several orders of magnitude fewer parameters. This work allows for efficient, robust, and int
    
[^210]: FasterViT：具有分层注意力的快速视觉变换器

    FasterViT: Fast Vision Transformers with Hierarchical Attention. (arXiv:2306.06189v1 [cs.CV])

    [http://arxiv.org/abs/2306.06189](http://arxiv.org/abs/2306.06189)

    本研究设计了一种新型混合CNN-ViT神经网络FasterViT，引入了具有分层注意力的方法HAT，将全局自我注意力分解为多级注意力，实现了高效的跨窗口通信。 FasterViT在精度和图像吞吐量方面达到了SOTA前沿水平，并已在分类，物体检测和分割等CV任务中得到广泛验证。

    

    本研究设计了一种新型混合CNN-ViT神经网络，命名为FasterViT，专注于计算机视觉应用中的高图像吞吐量。FasterViT将CNN中快速本地表示学习的优点与ViT中的全局建模特性相结合。我们引入了分层注意力（HAT）方法，将具有二次复杂度的全局自我注意力分解为具有较小计算成本的多级注意力。我们受益于高效的基于窗口的自我注意力，每个窗口都可以访问专门用于本地和全局表示学习的专用载体令牌。在高层次上，全局自我注意力实现了较低成本的跨窗口通信，FasterViT在精度与图像吞吐量方面实现了SOTA前沿水平，并已在各种CV任务中进行了广泛验证，包括分类，物体检测和分割。我们还展示了HAT可以用作现有CNN架构的即插即用模块，以改善性能。

    We design a new family of hybrid CNN-ViT neural networks, named FasterViT, with a focus on high image throughput for computer vision (CV) applications. FasterViT combines the benefits of fast local representation learning in CNNs and global modeling properties in ViT. Our newly introduced Hierarchical Attention (HAT) approach decomposes global self-attention with quadratic complexity into a multi-level attention with reduced computational costs. We benefit from efficient window-based self-attention. Each window has access to dedicated carrier tokens that participate in local and global representation learning. At a high level, global self-attentions enable the efficient cross-window communication at lower costs. FasterViT achieves a SOTA Pareto-front in terms of accuracy \vs image throughput. We have extensively validated its effectiveness on various CV tasks including classification, object detection and segmentation. We also show that HAT can be used as a plug-and-play module for exi
    
[^211]: 视觉词汇描述提升零样本图像分类

    Visually-Grounded Descriptions Improve Zero-Shot Image Classification. (arXiv:2306.06077v1 [cs.CV])

    [http://arxiv.org/abs/2306.06077](http://arxiv.org/abs/2306.06077)

    本文提出了一种称为V-GLOSS的新方法，它利用现代语言模型和语义知识库生成具有视觉基础的类别描述，提高了零样本图像分类的准确性，并引入了一个带有类别描述的银标准数据集。

    

    语言视觉模型如CLIP在零样本视觉任务（例如零样本图像分类ZSIC）方面取得了显著进展。然而，生成具体和富有表现力的类别描述仍然是一个主要挑战。现有方法存在粒度和标签歧义等问题。为了解决这些挑战，我们提出了一种新方法V-GLOSS：Visual Glosses，它利用现代语言模型和语义知识库来生成具有视觉基础的类别描述。我们通过在基准ZSIC数据集（包括ImageNet和STL-10）上实现最先进的结果来展示V-GLOSS的有效性。此外，我们引入了一个由V-GLOSS生成的带有类别描述的银标准数据集，并展示其用于视觉任务的有用性。我们提供了源代码和数据集。

    Language-vision models like CLIP have made significant progress in zero-shot vision tasks, such as zero-shot image classification (ZSIC). However, generating specific and expressive class descriptions remains a major challenge. Existing approaches suffer from granularity and label ambiguity issues. To tackle these challenges, we propose V-GLOSS: Visual Glosses, a novel method leveraging modern language models and semantic knowledge bases to produce visually-grounded class descriptions. We demonstrate V-GLOSS's effectiveness by achieving state-of-the-art results on benchmark ZSIC datasets including ImageNet and STL-10. In addition, we introduce a silver dataset with class descriptions generated by V-GLOSS, and show its usefulness for vision tasks. We make available our code and dataset.
    
[^212]: 神经网络修复安全漏洞的有效性有多高？

    How Effective Are Neural Networks for Fixing Security Vulnerabilities. (arXiv:2305.18607v1 [cs.SE])

    [http://arxiv.org/abs/2305.18607](http://arxiv.org/abs/2305.18607)

    这篇论文比较了使用大型代码语言模型和自动化程序修复技术修复Java漏洞的能力，并提供了新的Java漏洞修复基准。在两个真实的Java漏洞基准上进行评估。

    

    安全漏洞修复是一项需要自动化的困难任务。两组技术表现出了希望：（1）大型代码语言模型（LLMs），它们已经针对代码完成等任务进行了预训练，以及（2）使用深度学习（DL）模型自动修复软件错误的自动化程序修复（APR）技术。本文是首次研究和比较LLMs和DL-based APR模型在Java漏洞修复能力方面的论文。这项工作的贡献包括：（1）将并评估五个LLMs（Codex、CodeGen、CodeT5、PLBART和InCoder）、四个精细调整的LLMs和四种基于DL的APR技术在两个真实世界的Java漏洞基准（Vul4J和VJBench）上，（2）设计代码转换来解决对Codex的训练和测试数据重叠威胁，（3）创建一个新的Java漏洞修复基准VJBench，以及它的转化版本VJBench-trans，（4）评估LLMs和APR技术对转化的漏洞。

    Security vulnerability repair is a difficult task that is in dire need of automation. Two groups of techniques have shown promise: (1) large code language models (LLMs) that have been pre-trained on source code for tasks such as code completion, and (2) automated program repair (APR) techniques that use deep learning (DL) models to automatically fix software bugs.  This paper is the first to study and compare Java vulnerability repair capabilities of LLMs and DL-based APR models. The contributions include that we (1) apply and evaluate five LLMs (Codex, CodeGen, CodeT5, PLBART and InCoder), four fine-tuned LLMs, and four DL-based APR techniques on two real-world Java vulnerability benchmarks (Vul4J and VJBench), (2) design code transformations to address the training and test data overlapping threat to Codex, (3) create a new Java vulnerability repair benchmark VJBench, and its transformed version VJBench-trans and (4) evaluate LLMs and APR techniques on the transformed vulnerabilities
    
[^213]: N-元事实的少样本链接预测

    Few-shot Link Prediction on N-ary Facts. (arXiv:2305.06104v1 [cs.AI])

    [http://arxiv.org/abs/2305.06104](http://arxiv.org/abs/2305.06104)

    本文提出了一个新任务——少样本N-元事实链接预测，并提出了一个名为FLEN的模型来实现。FLEN由三个模块组成，可以从有限的标记实例中预测N-元事实中的缺失实体。

    

    N-元事实由主要三元组（头实体、关系、尾实体）和任意数量的辅助属性值对组成，这在现实世界的知识图谱中很常见。对于N-元事实的链接预测是预测其中一个元素的缺失，填补缺失元素有助于丰富知识图谱并促进许多下游应用程序。以往的研究通常需要大量高质量的数据来理解N-元事实中的元素，但这些研究忽视了少样本关系，在现实世界的场景中却很常见。因此，本文引入一个新任务——少样本N-元事实链接预测，旨在使用有限的标记实例来预测N-元事实中的缺失实体。我们也提出了一个针对N-元事实的少样本链接预测模型FLEN，它由三个模块组成：关系学习模块、支持特定调整模块和查询推理模块。

    N-ary facts composed of a primary triple (head entity, relation, tail entity) and an arbitrary number of auxiliary attribute-value pairs, are prevalent in real-world knowledge graphs (KGs). Link prediction on n-ary facts is to predict a missing element in an n-ary fact. This helps populate and enrich KGs and further promotes numerous downstream applications. Previous studies usually require a substantial amount of high-quality data to understand the elements in n-ary facts. However, these studies overlook few-shot relations, which have limited labeled instances, yet are common in real-world scenarios. Thus, this paper introduces a new task, few-shot link prediction on n-ary facts. It aims to predict a missing entity in an n-ary fact with limited labeled instances. We further propose a model for Few-shot Link prEdict on N-ary facts, thus called FLEN, which consists of three modules: the relation learning, support-specific adjusting, and query inference modules. FLEN captures relation me
    
[^214]: 遥感中的视觉语言模型：现状与未来趋势

    Vision-Language Models in Remote Sensing: Current Progress and Future Trends. (arXiv:2305.05726v1 [cs.CV])

    [http://arxiv.org/abs/2305.05726](http://arxiv.org/abs/2305.05726)

    本文介绍了遥感图像中应用视觉语言模型的现状及未来趋势，视觉语言模型可以推理图像中的底层语义，可以识别对象之间的关系及生成自然语言描述。

    

    论文介绍了视觉语言模型在遥感领域的应用现状和未来趋势。遥感领域中现有的人工智能研究主要集中在图像的视觉理解上，忽略了对象和它们之间关系的语义理解，而视觉语言模型的出现则填补了这一空缺。视觉语言模型可以通过图像及其相关的文字描述进行推理，深入理解其底层语义，比仅仅识别图像中的对象，能够推断出它们之间的关系，甚至生成自然语言描述。

    The remarkable achievements of ChatGPT and GPT-4 have sparked a wave of interest and research in the field of large language models for Artificial General Intelligence (AGI). These models provide us with intelligent solutions that are more similar to human thinking, enabling us to use general artificial intelligence to solve problems in various applications. However, in the field of remote sensing, the scientific literature on the implementation of AGI remains relatively scant. Existing AI-related research primarily focuses on visual understanding tasks while neglecting the semantic understanding of the objects and their relationships. This is where vision-language models excel, as they enable reasoning about images and their associated textual descriptions, allowing for a deeper understanding of the underlying semantics. Vision-language models can go beyond recognizing the objects in an image and can infer the relationships between them, as well as generate natural language descriptio
    
[^215]: PersonaLLM: 探究GPT-3.5表达个性特征和性别差异的能力

    PersonaLLM: Investigating the Ability of GPT-3.5 to Express Personality Traits and Gender Differences. (arXiv:2305.02547v1 [cs.CL])

    [http://arxiv.org/abs/2305.02547](http://arxiv.org/abs/2305.02547)

    本文探究了基于LLMs模拟代理的行为，称之为LLM Personas，在分配大五人格类型和性别角色时是否可以生成具有一致性的个性化特质的内容。

    

    尽管大型语言模型在各个行业的聊天机器人设计中有许多用途，并且研究表明个性化聊天机器人在满足不同人格特征方面的重要性，但很少有研究评估个性化LLM的行为是否能够准确、一致地反映某些人格特征。我们考虑研究基于LLM的模拟代理的行为，称之为LLM personas，并使用GPT-3.5（text-davinci-003）进行案例研究，以研究LLM在分配大五人格类型和性别角色时是否可以生成具有一致性的个性化特质的内容。我们创建了320个LLM personas（每种大五人格类型有5个女性和5个男性），并提示他们完成经典的44项大五人格问卷（BFI），然后撰写一个关于他们童年的800字故事。结果表明，LLM personas的自我报告的BFI分数与他们分配的人格类型一致。

    Despite the many use cases for large language models (LLMs) in the design of chatbots in various industries and the research showing the importance of personalizing chatbots to cater to different personality traits, little work has been done to evaluate whether the behaviors of personalized LLMs can reflect certain personality traits accurately and consistently. We consider studying the behavior of LLM-based simulated agents which refer to as LLM personas and present a case study with GPT-3.5 (text-davinci-003) to investigate whether LLMs can generate content with consistent, personalized traits when assigned Big Five personality types and gender roles. We created 320 LLM personas (5 females and 5 males for each of the 32 Big Five personality types) and prompted them to complete the classic 44-item Big Five Inventory (BFI) and then write an 800-word story about their childhood. Results showed that LLM personas' self-reported BFI scores are consistent with their assigned personality typ
    
[^216]: 深度迁移学习在入侵检测系统中的应用：综述

    Deep Transfer Learning Applications in Intrusion Detection Systems: A Comprehensive Review. (arXiv:2304.10550v1 [cs.CR])

    [http://arxiv.org/abs/2304.10550](http://arxiv.org/abs/2304.10550)

    本文全面回顾了深度迁移学习在入侵检测系统中的应用，特别是基于IDS的深度迁移学习，该技术利用多个领域的知识融合和/或适应以提高目标任务的性能，尤其是在目标领域中的标记数据非常少的情况下。

    

    全球范围内，外部互联网越来越多地与当代工业控制系统相连接。因此，有一个迫切的需求保护网络免受各种威胁。可以使用入侵检测系统（IDS）来保护工业活动的关键基础设施，这是一种预防性措施机制，用于识别新的危险威胁和敌对活动。本文研究了用于在许多种工业控制网络中创建IDS的最新人工智能（AI）技术，特别侧重于基于IDS的深度迁移学习（DTL）。DTL可以看作是将来自多个领域的知识融合和/或适应以增强目标任务的性能的一种信息融合。重点是当目标域中的标记数据很少时，DTL可以帮助提高IDS的性能。考虑了2015年之后的出版物。这些选定的出版物被分为三类：仅DTL和仅IDS，具有迁移学习（TL）的IDS，以及基于深度迁移学习的IDS。该研究全面回顾了入侵检测系统中深度迁移学习应用的最新技术和方法。

    Globally, the external Internet is increasingly being connected to the contemporary industrial control system. As a result, there is an immediate need to protect the network from several threats. The key infrastructure of industrial activity may be protected from harm by using an intrusion detection system (IDS), a preventive measure mechanism, to recognize new kinds of dangerous threats and hostile activities. The most recent artificial intelligence (AI) techniques used to create IDS in many kinds of industrial control networks are examined in this study, with a particular emphasis on IDS-based deep transfer learning (DTL). This latter can be seen as a type of information fusion that merge, and/or adapt knowledge from multiple domains to enhance the performance of the target task, particularly when the labeled data in the target domain is scarce. Publications issued after 2015 were taken into account. These selected publications were divided into three categories: DTL-only and IDS-onl
    
[^217]: 基于MCMC的贝叶斯神经网络：基于Python的教程

    Bayesian neural networks via MCMC: a Python-based tutorial. (arXiv:2304.02595v1 [stat.ML])

    [http://arxiv.org/abs/2304.02595](http://arxiv.org/abs/2304.02595)

    本文提供了一个基于Python的教程，介绍了贝叶斯神经网络的MCMC方法应用，通过教程使得深度学习开发者能够更好地应用贝叶斯推断进行参数估计和不确定性量化。

    

    贝叶斯推断为机器学习和深度学习提供了参数估计和不确定性量化的方法。变分推断和马尔科夫链蒙特卡罗（MCMC）采样技术用于实现贝叶斯推断。在过去三十年中，MCMC方法在适应更大的模型（如深度学习）和大数据问题方面面临了许多挑战。包括梯度的高级提议（例如Langevin提议分布）提供了一种解决MCMC采样中的一些限制的方法，此外，MCMC方法通常被限制在统计学家的使用范围内，并且仍不是深度学习研究人员的主流方法。我们提供了一个MCMC方法的教程，涵盖了简单的贝叶斯线性和逻辑模型，以及贝叶斯神经网络。这个教程的目的是通过编码来弥合理论和实现之间的差距，鉴于当前MCMC方法的普及程度仍然较低。

    Bayesian inference provides a methodology for parameter estimation and uncertainty quantification in machine learning and deep learning methods. Variational inference and Markov Chain Monte-Carlo (MCMC) sampling techniques are used to implement Bayesian inference. In the past three decades, MCMC methods have faced a number of challenges in being adapted to larger models (such as in deep learning) and big data problems. Advanced proposals that incorporate gradients, such as a Langevin proposal distribution, provide a means to address some of the limitations of MCMC sampling for Bayesian neural networks. Furthermore, MCMC methods have typically been constrained to use by statisticians and are still not prominent among deep learning researchers. We present a tutorial for MCMC methods that covers simple Bayesian linear and logistic models, and Bayesian neural networks. The aim of this tutorial is to bridge the gap between theory and implementation via coding, given a general sparsity of li
    
[^218]: 终身学习在异常检测中的应用: 新的挑战、视角和见解

    Lifelong Learning for Anomaly Detection: New Challenges, Perspectives, and Insights. (arXiv:2303.07557v1 [cs.LG])

    [http://arxiv.org/abs/2303.07557](http://arxiv.org/abs/2303.07557)

    本文探讨了终身异常检测的重要性，提出设计终身学习复杂性的异常检测方法的挑战和机会，并提供了一种场景生成过程使得研究人员能够进行实验。

    

    在许多实际领域中，异常检测具有极其重要的意义，特别是在行为不断变化的情况下。终身学习是一种新兴趋势，它能够满足需要机器学习模型在动态环境中不断适应新挑战并保留过去知识的需求。然而，目前很少有人致力于建立终身异常检测的基础，这与更广泛探索的分类设置存在本质不同的挑战。本文通过探讨、阐述和讨论终身异常检测，试图为其更广泛的采用建立基础。首先，我们解释了为什么终身异常检测很重要，定义了应对终身学习复杂性的异常检测方法设计的挑战和机会。其次，我们对学习设置和场景生成过程进行了表征，使研究人员能够使用这些工具进行终身异常检测的实验。

    Anomaly detection is of paramount importance in many real-world domains, characterized by evolving behavior. Lifelong learning represents an emerging trend, answering the need for machine learning models that continuously adapt to new challenges in dynamic environments while retaining past knowledge. However, limited efforts are dedicated to building foundations for lifelong anomaly detection, which provides intrinsically different challenges compared to the more widely explored classification setting. In this paper, we face this issue by exploring, motivating, and discussing lifelong anomaly detection, trying to build foundations for its wider adoption. First, we explain why lifelong anomaly detection is relevant, defining challenges and opportunities to design anomaly detection methods that deal with lifelong learning complexities. Second, we characterize learning settings and a scenario generation procedure that enables researchers to experiment with lifelong anomaly detection using
    
[^219]: 基于分层生成对抗模拟学习的自动驾驶在城市环境中的应用

    Hierarchical Generative Adversarial Imitation Learning with Mid-level Input Generation for Autonomous Driving on Urban Environments. (arXiv:2302.04823v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.04823](http://arxiv.org/abs/2302.04823)

    本研究提出了一种名为hGAIL的架构，用于解决车辆的自主导航问题，通过将感知信息直接映射到低级动作的同时，学习车辆环境的中级输入表示。

    

    对于现实中的城市导航场景，设计健壮的控制策略并不是一项简单的任务。在端到端的方法中，这些策略必须将车辆摄像头获得的高维图像映射到低级动作，如转向和油门。本研究提出了一种名为hGAIL的架构，用于解决车辆的自主导航问题，通过将感知信息直接映射到低级动作的同时，学习车辆环境的中级输入表示。

    Deriving robust control policies for realistic urban navigation scenarios is not a trivial task. In an end-to-end approach, these policies must map high-dimensional images from the vehicle's cameras to low-level actions such as steering and throttle. While pure Reinforcement Learning (RL) approaches are based exclusively on rewards,Generative Adversarial Imitation Learning (GAIL) agents learn from expert demonstrations while interacting with the environment, which favors GAIL on tasks for which a reward signal is difficult to derive. In this work, the hGAIL architecture was proposed to solve the autonomous navigation of a vehicle in an end-to-end approach, mapping sensory perceptions directly to low-level actions, while simultaneously learning mid-level input representations of the agent's environment. The proposed hGAIL consists of an hierarchical Adversarial Imitation Learning architecture composed of two main modules: the GAN (Generative Adversarial Nets) which generates the Bird's-
    
[^220]: 使用采样算法估计量子玻色系统的截断效应

    Estimating truncation effects of quantum bosonic systems using sampling algorithms. (arXiv:2212.08546v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2212.08546](http://arxiv.org/abs/2212.08546)

    本文提出了一种使用传统采样方法估计量子玻色系统截断误差的方法，该方法可用于估计实际量子模拟玻色理论所需的资源，并检查对应量子模拟的结果的有效性。

    

    要在基于量子比特或量子位的量子计算机上模拟玻色子，必须通过将无限维局部希尔伯特空间截断为有限维来规范理论。在寻求实际量子应用的过程中，了解截断误差有多大非常重要。通常情况下，除非我们拥有好的量子计算机，否则很难估计误差。本文表明，传统的经典设备采样方法，具体而言是马尔科夫链蒙特卡罗方法可以用现有合理的计算资源解决这个问题。我们以二维格点上的标量场理论为例演示了这个想法，其大小超过了使用确切对角化方法所能达到的范围。这种方法可用于估计实际量子模拟玻色理论所需的资源，并检查对应量子模拟的结果的有效性。

    To simulate bosons on a qubit- or qudit-based quantum computer, one has to regularize the theory by truncating infinite-dimensional local Hilbert spaces to finite dimensions. In the search for practical quantum applications, it is important to know how big the truncation errors can be. In general, it is not easy to estimate errors unless we have a good quantum computer. In this paper we show that traditional sampling methods on classical devices, specifically Markov Chain Monte Carlo, can address this issue with a reasonable amount of computational resources available today. As a demonstration, we apply this idea to the scalar field theory on a two-dimensional lattice, with a size that goes beyond what is achievable using exact diagonalization methods. This method can be used to estimate the resources needed for realistic quantum simulations of bosonic theories, and also, to check the validity of the results of the corresponding quantum simulations.
    
[^221]: CP-PINNs: 使用物理知识神经网络和总变差惩罚进行PDE中的变点检测

    CP-PINNs: Changepoints Detection in PDEs using Physics Informed Neural Networks with Total-Variation Penalty. (arXiv:2208.08626v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2208.08626](http://arxiv.org/abs/2208.08626)

    本文提出了一种新的CP-PINNs模型，通过将PINNs与总变差惩罚相结合，实现了准确的变点检测和PDE的发现。我们还开发了一种元学习算法，能够在数据的连续批次上动态改进优化目标。实证结果表明，在存在变点的情况下，该方法能够准确估计参数和模型对齐，在没有变点的情况下能够数值上收敛到原始PINNs模型的解。

    

    本文展示了在参数中存在未知变点的情况下，物理知识神经网络（PINNs）可能无法正确估计偏微分方程（PDE）的动态过程。为了解决这个问题，我们提出了一个新的CP-PINNs模型，将PINNs与总变差惩罚相结合，用于准确的变点检测和PDE的发现。为了在模型拟合、PDE发现和变点检测任务之间进行最优组合，我们开发了一种新的元学习算法，利用批量学习在数据的连续批次上动态改进优化目标。在实证方面，在动态过程中存在变点的情况下，我们的方法能够准确估计参数和模型对齐，在数据中没有变点的情况下，数值上收敛到原始PINNs模型的解。

    The paper shows that Physics-Informed Neural Networks (PINNs) can fail to estimate the correct Partial Differential Equations (PDEs) dynamics in cases of unknown changepoints in the parameters. To address this, we propose a new CP-PINNs model which integrates PINNs with Total-Variation penalty for accurate changepoints detection and PDEs discovery. In order to optimally combine the tasks of model fitting, PDEs discovery, and changepoints detection, we develop a new meta-learning algorithm that exploits batch learning to dynamically refines the optimization objective when moving over the consecutive batches of the data. Empirically, in case of changepoints in the dynamics, our approach demonstrates accurate parameter estimation and model alignment, and in case of no changepoints in the data, it converges numerically to the solution from the original PINNs model.
    

