# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [An Efficient General-Purpose Modular Vision Model via Multi-Task Heterogeneous Training.](http://arxiv.org/abs/2306.17165) | 本文提出了一种通过多任务异构训练实现高效通用模块化视觉模型的方法，以应对在视觉任务之间的大量内在差异，并解决多任务模型扩展的挑战。 |
| [^2] | [Synthetic Demographic Data Generation for Card Fraud Detection Using GANs.](http://arxiv.org/abs/2306.17109) | 该论文提出了一种名为DGGAN的深度学习生成对抗网络，用于生成合成人口数据，以用于信用卡欺诈检测。通过使用相对复杂的合成人口数据，可以提高交易数据特征的复杂性，并提升欺诈检测性能。 |
| [^3] | [RL4CO: an Extensive Reinforcement Learning for Combinatorial Optimization Benchmark.](http://arxiv.org/abs/2306.17100) | RL4CO是一个用于组合优化的广泛强化学习基准测试，着重于可扩展性和泛化能力的评估，并展示了一些最新方法在样本效率和适应不同数据分布方面的表现相对较差，强调了对神经CO求解器性能的平衡评估的重要性。 |
| [^4] | [RAPGen: An Approach for Fixing Code Inefficiencies in Zero-Shot.](http://arxiv.org/abs/2306.17077) | RAPGen是一种新方法，通过在零样本情况下使用Retrieval-Augmented Prompt Generation（RAPGen）方法，即从预先构建的性能Bug修复知识库中检索提示指令并生成提示，然后在大型语言模型上生成修复方案，可以有效地解决代码低效问题。实验结果显示，在专家验证的数据集中，RAPGen在60%的情况下可以生成与开发者等效或更好的性能改进建议，其中约39%的建议完全相同。 |
| [^5] | [Learning Structure-Guided Diffusion Model for 2D Human Pose Estimation.](http://arxiv.org/abs/2306.17074) | 本文提出了一种学习结构引导的扩散模型(DiffusionPose)用于二维人体姿态估计，通过从噪声热图生成关键点热图的方式，通过添加噪声将关键点扩散到随机分布，并利用图像特征构建的条件恢复出真实的热图。扩散模型以逐步去噪的方式生成热图，同时利用人体结构信息进一步提高性能，在大量实验中取得了优越的结果。 |
| [^6] | [Interdisciplinary Methods in Computational Creativity: How Human Variables Shape Human-Inspired AI Research.](http://arxiv.org/abs/2306.17070) | 本文研究了计算创造力中人类变量对人工智能研究的影响和转化过程，通过22个访谈发现了与计算创造力最相关的信息。 |
| [^7] | [Presenting an approach based on weighted CapsuleNet networks for Arabic and Persian multi-domain sentiment analysis.](http://arxiv.org/abs/2306.17068) | 本文提出了一种基于加权胶囊网络的阿拉伯语和波斯语多领域情感分析方法，通过训练单独的胶囊网络并使用加权度量来实现情感分类，具有较好的准确性和适应性。 |
| [^8] | [The mapKurator System: A Complete Pipeline for Extracting and Linking Text from Historical Maps.](http://arxiv.org/abs/2306.17059) | 该论文介绍了一种名为mapKurator的系统，能完整地从历史地图中提取和链接文本信息。该系统解决了传统方法中对位置相关词语的忽略问题，并利用主题建模方法考虑更广的主题范围，能够识别文档的空间焦点。 |
| [^9] | [Safe Model-Based Multi-Agent Mean-Field Reinforcement Learning.](http://arxiv.org/abs/2306.17052) | 本文提出了Safe-$\text{M}^3$-UCRL算法，通过使用模型中的认知不确定性和对数障碍方法，实现了在未知转移动态情况下达到安全策略的优化，成功解决了大规模多智能体协调问题。 |
| [^10] | [Exploring & Exploiting High-Order Graph Structure for Sparse Knowledge Graph Completion.](http://arxiv.org/abs/2306.17034) | 本论文提出了一种新的框架 LR-GCN，用于在稀疏知识图谱中进行补全。该框架能够探索高阶图结构，自动捕捉实体之间的远程依赖关系，并通过逻辑推理提炼知识，从而有效解决稀疏性带来的挑战。 |
| [^11] | [Safety-Aware Task Composition for Discrete and Continuous Reinforcement Learning.](http://arxiv.org/abs/2306.17033) | 本文研究了布尔组合在强化学习中的应用，通过引入两种安全性概念和拓展到连续行动空间，实现了任务的安全感知组合。 |
| [^12] | [Classifying Crime Types using Judgment Documents from Social Media.](http://arxiv.org/abs/2306.17020) | 本文提出了一种通过NLP处理方法的新的训练模型，通过生成新样本来平衡不均匀的数据集分布的缺陷，并使用预训练和微调来赋予模型对小数据集的良好泛化能力。 |
| [^13] | [milliFlow: Scene Flow Estimation on mmWave Radar Point Cloud for Human Motion Sensing.](http://arxiv.org/abs/2306.17010) | milliFlow是一种用于人体运动感知的新型深度学习方法，通过对毫米波雷达点云进行场景流估计，能够提供中间层的特征并直接用于下游的人体运动感知任务中。实验证明该方法具有优越性能。 |
| [^14] | [Diffusion-Jump GNNs: Homophiliation via Learnable Metric Filters.](http://arxiv.org/abs/2306.16976) | 提出了一种名为Diffusion-Jump GNNs的新方法，通过学习可调节的度量过滤器，来提高高阶图神经网络在异质化场景下的效果。这种方法通过跳跃式的渐进扩散距离生成过滤器的支持和系数，以寻找散点之间的联系。 |
| [^15] | [Identifiability of direct effects from summary causal graphs.](http://arxiv.org/abs/2306.16958) | 该论文研究了在缺乏完整时间因果图的情况下，直接因果效应如何从总结因果图中进行可辨识，并提出了一个完整的可辨识性结果。 |
| [^16] | [MEMD-ABSA: A Multi-Element Multi-Domain Dataset for Aspect-Based Sentiment Analysis.](http://arxiv.org/abs/2306.16956) | 这个论文提出了一个大规模的多要素多领域数据集（MEMD-ABSA），用于面向方面情感分析的研究。数据集涵盖了五个领域的四个要素，包括近2万个评论句子和3万个带有显式和隐式方面和观点的四元组。研究结果表明，开放领域ABSA以及挖掘隐含的方面和观点仍然是待解决的挑战。 |
| [^17] | [Alternative Telescopic Displacement: An Efficient Multimodal Alignment Method.](http://arxiv.org/abs/2306.16950) | 备选的变焦位移是一种高效的多模态对齐方法，通过交替移动和扩展特征信息来融合多模态数据，可以稳健地捕捉不同模态特征之间的高级交互作用，从而显著提高多模态学习的性能，并在多个任务上优于其他流行的多模态方案。 |
| [^18] | [UMASS_BioNLP at MEDIQA-Chat 2023: Can LLMs generate high-quality synthetic note-oriented doctor-patient conversations?.](http://arxiv.org/abs/2306.16931) | 本文介绍了UMASS_BioNLP团队在MEDIQA-Chat 2023共享任务中的参与，提出了一种新型LLMs协作系统用于生成高质量对话数据集，并与ChatGPT和GPT-4进行了比较分析。 |
| [^19] | [One-2-3-45: Any Single Image to 3D Mesh in 45 Seconds without Per-Shape Optimization.](http://arxiv.org/abs/2306.16928) | 本论文提出了一种无需进行形状优化的新方法，可以在45秒内将任意单张图像转换为360度的3D纹理网格。该方法采用了视图条件的2D扩散模型和基于SDF的神经表面重建方法，通过关键的训练策略实现了准确且一致的多视图预测。 |
| [^20] | [End-to-end Autonomous Driving: Challenges and Frontiers.](http://arxiv.org/abs/2306.16927) | 这项研究调查了端到端自动驾驶领域中的关键挑战和未来趋势，包括多模态、可解释性、因果混淆、鲁棒性和世界模型等。通过联合特征优化感知和规划，端到端系统在感知和规划上获得了更好的效果。 |
| [^21] | [The ELM Neuron: an Efficient and Expressive Cortical Neuron Model Can Solve Long-Horizon Tasks.](http://arxiv.org/abs/2306.16922) | ELM神经元是一种高效且表达力强的皮层神经元模型，它只需要8K个参数就能准确模拟复杂的计算任务。 |
| [^22] | [Computationally Assisted Quality Control for Public Health Data Streams.](http://arxiv.org/abs/2306.16914) | 开发了一个实用的异常点检测框架FlaSH，用于公共卫生数据流。该框架考虑了数据量和统计特性，并在实验中展现了良好的性能。 |
| [^23] | [AutoML in Heavily Constrained Applications.](http://arxiv.org/abs/2306.16913) | 本文提出了Caml，一种在严格约束的应用中使用元学习的AutoML方法。Caml能够自动适应特定任务的AutoML参数，并考虑用户定义的约束，生成满足约束且具有高预测性能的流程。 |
| [^24] | [From Query Tools to Causal Architects: Harnessing Large Language Models for Advanced Causal Discovery from Data.](http://arxiv.org/abs/2306.16902) | 本文提出了一个新的框架，将基于知识的大型语言模型（LLM）因果分析与基于数据的因果结构学习相结合，以实现更高级的因果发现和数据分析。通过利用LLM的专业知识，并结合统计分析客观数据，构建了一个新颖且实用的因果结构学习的基准。 |
| [^25] | [PFB-Diff: Progressive Feature Blending Diffusion for Text-driven Image Editing.](http://arxiv.org/abs/2306.16894) | PFB-Diff 是一个通过渐进特征混合的方法，用于文本驱动的图像编辑。该方法解决了扩散模型在像素级混合中产生的伪影问题，并通过多级特征混合和注意力屏蔽机制确保了编辑图像的语义连贯性和高质量。 |
| [^26] | [Harnessing the Power of Hugging Face Transformers for Predicting Mental Health Disorders in Social Networks.](http://arxiv.org/abs/2306.16891) | 该研究通过使用社交媒体和预训练的语言模型，探索了使用用户生成的数据预测精神障碍症状的方法，并发现新模型的准确度高达97%。这表明社交媒体数据是进行精神健康筛查的一个重要资源，预训练模型能够有效地自动化这一任务。 |
| [^27] | [Towards a Self-Replicating Turing Machine.](http://arxiv.org/abs/2306.16872) | 该论文介绍了一种自复制图灵机的构造方法，通过从简单的构建块开始，并使用最小的假设和相同的原理，提供了von Neumann的通用构造器和通用复制器的部分实现。该构造允许进行变异，并提供了一个简单的描述语言。 |
| [^28] | [Sustainable Palm Tree Farming: Leveraging IoT and Multi-Modal Data for Early Detection and Mapping of Red Palm Weevil.](http://arxiv.org/abs/2306.16862) | 本文提出了一种可持续的棕榈树种植方法，利用物联网和多模态数据对红棕象进行早期检测和映射。通过计算机视觉、深度学习、物联网和地理空间数据的综合应用，我们可以有效检测和分类寄生红棕象的棕榈树，并利用地理空间数据创建综合红棕象分布图，为高效监测和有针对性的管理策略提供支持。 |
| [^29] | [Intelligence of Astronomical Optical Telescope: Present Status and Future Perspectives.](http://arxiv.org/abs/2306.16834) | 本文综合介绍了人工智能技术在天文学中的应用以及望远镜智能化的发展和研究热点，对各种研究方向进行了统计分析，并指出了各个望远镜智能化的研究趋势。 |
| [^30] | [Graph Denoising Diffusion for Inverse Protein Folding.](http://arxiv.org/abs/2306.16819) | 我们提出了一种逆向蛋白质折叠的图去噪扩散模型，通过扩散过程生成了一组多样的候选序列，该模型能够很好地概括多样的可行解决方案。 |
| [^31] | [Improving Online Continual Learning Performance and Stability with Temporal Ensembles.](http://arxiv.org/abs/2306.16817) | 该研究通过模型集成方法改进了在线连续学习的性能和稳定性，通过综合利用来自不同训练任务的模型，显著提高了在线连续学习的表现。 |
| [^32] | [LeanAI: A method for AEC practitioners to effectively plan AI implementations.](http://arxiv.org/abs/2306.16799) | LeanAI是一种让AEC从业者有效规划AI实施的方法，解决了由于缺乏对AI能力和限制的理解而导致的规划与实施之间的脱节问题。 |
| [^33] | [Evaluation of Environmental Conditions on Object Detection using Oriented Bounding Boxes for AR Applications.](http://arxiv.org/abs/2306.16798) | 本研究提出了一种使用定向边界框和深度网络进行物体检测的新方法，通过在不同环境条件下对两个数据集的评估发现，该方法在处理小物体时能够提高性能和准确性。 |
| [^34] | [Sparse Model Soups: A Recipe for Improved Pruning via Model Averaging.](http://arxiv.org/abs/2306.16788) | 本研究通过将多个经过迭代幅度剪枝的模型进行平均，解决了同时利用稀疏性和参数平均的问题，并显著提升了泛化性能。 |
| [^35] | [A Survey on Datasets for Decision-making of Autonomous Vehicle.](http://arxiv.org/abs/2306.16784) | 本综述调查了自动驾驶决策的数据集，比较了车辆、环境和驾驶员相关的数据集，并总结了它们的特点。这有助于研究人员找到适合的数据集来开发数据驱动的自动驾驶决策方法。 |
| [^36] | [Learning from Synthetic Human Group Activities.](http://arxiv.org/abs/2306.16772) | 提出了M3Act，一个多视图多团队多人的人类原子动作和团队活动数据生成器，通过Unity引擎驱动实现。该生成器具有大规模数据生成、多模态和高质量注释等特点，能够用于研究复杂的人类互动和团队活动。 |
| [^37] | [DialoGPS: Dialogue Path Sampling in Continuous Semantic Space for Data Augmentation in Multi-Turn Conversations.](http://arxiv.org/abs/2306.16770) | DialoGPS是第一个在连续语义空间中进行对话路径采样的多对多增强方法，用于多轮对话的数据增强任务。 |
| [^38] | [Eigensubspace of Temporal-Difference Dynamics and How It Improves Value Approximation in Reinforcement Learning.](http://arxiv.org/abs/2306.16750) | ERC是一种新的值估计方法，通过在深度强化学习中利用时间差分动力学的特征子空间，实现了更高效和稳定的值估计路径。实验证明ERC有效地减少了值函数的方差，并在多项任务中优于其他最先进方法。 |
| [^39] | [Principles and Guidelines for Evaluating Social Robot Navigation Algorithms.](http://arxiv.org/abs/2306.16740) | 本文提出了评估社交机器人导航算法的原则与指南，为解决在人类居住环境中导航的挑战提供了可重复和可比较的基准标准。 |
| [^40] | [GraMMaR: Ground-aware Motion Model for 3D Human Motion Reconstruction.](http://arxiv.org/abs/2306.16736) | 提出了一种用于3D人体运动重建的地面感知运动模型（GraMMaR），通过学习姿势和关节与地面之间的互动的过渡分布，明确促进运动和与地面距离变化之间的一致性。 |
| [^41] | [Multi-Scenario Ranking with Adaptive Feature Learning.](http://arxiv.org/abs/2306.16732) | 多情景学习在推荐和检索系统中被广泛应用于行业中。本文提出了一种自适应特征学习方法，通过优化特征表示来提高排序性能，减少了对网络结构的搜索和维护成本。 |
| [^42] | [Evaluating Paraphrastic Robustness in Textual Entailment Models.](http://arxiv.org/abs/2306.16722) | 本文介绍了PaRTE，一个包含1,126对文本蕴涵示例的集合，用于评估模型对改写句的鲁棒性。实验结果表明，现代模型在8-16％的改写示例上改变了他们的预测，说明仍有改进的空间。 |
| [^43] | [Answer Mining from a Pool of Images: Towards Retrieval-Based Visual Question Answering.](http://arxiv.org/abs/2306.16713) | 本研究探究了在给定上下文中从相关和无关图像池中挖掘答案的视觉问答问题。我们提出了一个统一的模型，Multi Image BART (MI-BART)，通过检索相关图像并使用相关性编码器进行自由流畅的答案生成。同时，我们还引入了最大的RETVQA数据集，该数据集具有多图像和检索要求，并且可以对一组异构图像进行元数据无关的问题提问。 |
| [^44] | [NNQS-Transformer: an Efficient and Scalable Neural Network Quantum States Approach for Ab initio Quantum Chemistry.](http://arxiv.org/abs/2306.16705) | NNQS-Transformer是一种高效可扩展的神经网络量子态方法，用于从头计算量子化学。其主要创新包括基于Transformer的量子波函数安萨茨、数据中心并行化方案、并行批量采样策略和并行局域能量评估方案。研究结果显示了与最先进方法相比的优越精度和对于大分子系统的强可扩展性和弱可扩展性。 |
| [^45] | [Elastically-Constrained Meta-Learner for Federated Learning.](http://arxiv.org/abs/2306.16703) | 这项研究提出了一种弹性约束的元学习方法，用于解决联邦学习中由于非独立同分布数据导致元学习的不稳定目标的收敛问题。 |
| [^46] | [Rapid-INR: Storage Efficient CPU-free DNN Training Using Implicit Neural Representation.](http://arxiv.org/abs/2306.16699) | 本文提出了一种使用隐式神经表示进行高效的无CPU深度神经网络训练的新方法，通过在GPU上直接存储整个数据集以INR格式，减少了数据传输开销，从而加速训练过程。同时，采用高度并行化和实时执行的解码过程，进一步提升了压缩效果。 |
| [^47] | [Neural Polarizer: A Lightweight and Effective Backdoor Defense via Purifying Poisoned Features.](http://arxiv.org/abs/2306.16697) | 神经极化器是一种轻量且有效的后门攻击防御方法，通过插入一个可学习的神经极化器来净化被污染的样本，过滤恶意信息并保留良性信息。 |
| [^48] | [SRL: Scaling Distributed Reinforcement Learning to Over Ten Thousand Cores.](http://arxiv.org/abs/2306.16688) | SRL是一个可扩展，高效，可扩展的分布式强化学习系统，通过一种新的抽象框架统一了各种实际强化学习训练，并实现了精细优化。 |
| [^49] | [Game Level Blending using a Learned Level Representation.](http://arxiv.org/abs/2306.16666) | 本文介绍了一种使用聚类-based 平铺嵌入的方法，通过学习的关卡表示来实现游戏关卡混合，为未注释的游戏提供关卡表示，并在游戏之间提供统一的关卡表示，而无需人工注释。 |
| [^50] | [NaturalInversion: Data-Free Image Synthesis Improving Real-World Consistency.](http://arxiv.org/abs/2306.16661) | NaturalInversion 是一种无需真实数据的图像合成方法，通过特征传递金字塔、一对一生成模型和可学习的自适应通道缩放参数，合成的图像与原始数据分布更加一致，并在性能上超过以前的方法。 |
| [^51] | [Multi-source Semantic Graph-based Multimodal Sarcasm Explanation Generation.](http://arxiv.org/abs/2306.16650) | 本研究提出了一种基于多源语义图的多模态讽刺解释生成方案（TEAM），该方案通过提取对象级语义元数据和引入外部相关知识概念，有效地解决了现有方法中存在的视觉特征与解码器语义空间之间的差距以及潜在的外部知识限制。 |
| [^52] | [The Future of AI-Assisted Writing.](http://arxiv.org/abs/2306.16641) | 本研究比较了拉取和推送两种AI辅助写作模式对用户需求、质量、所有权、效率和享受度的影响，并发现用户欢迎AI在写作中的无缝辅助，AI能够帮助用户更快地使写作中的想法多样化，同时保持清晰和简洁，并且用户喜欢与AI辅助写作工具的协作，没有感到缺乏所有权。尽管在实验中没有体验到偏见影响。 |
| [^53] | [Evaluating ChatGPT's Decimal Skills and Feedback Generation in a Digital Learning Game.](http://arxiv.org/abs/2306.16639) | 本研究评估了ChatGPT在数字学习游戏中解决十进制问题、判断学生答案正确性和提供有意义反馈的能力。结果显示，ChatGPT能够在概念问题上表现良好，但在十进制位和数线问题上存在困难。 |
| [^54] | [CMATH: Can Your Language Model Pass Chinese Elementary School Math Test?.](http://arxiv.org/abs/2306.16636) | 该论文介绍了中国小学数学应用题（CMATH）数据集，评估了多个流行的大型语言模型（LLMs）在小学数学不同年级的表现。研究发现只有GPT-4在所有年级中取得成功，并且能够保持鲁棒性，而其他模型则在不同年级上表现较差。 |
| [^55] | [Towards Blockchain-Assisted Privacy-Aware Data Sharing For Edge Intelligence: A Smart Healthcare Perspective.](http://arxiv.org/abs/2306.16630) | 这篇论文提出了一个基于区块链的隐私感知数据共享模型，用于保护智慧医疗网络中的个人健康数据。通过评估用户之间的信任水平，使用者可以选择不同的隐私保护级别，并使用差分隐私技术和可控随机噪声保护数据的隐私性，以应对链结攻击和污染攻击的威胁。 |
| [^56] | [Laxity-Aware Scalable Reinforcement Learning for HVAC Control.](http://arxiv.org/abs/2306.16619) | 本文介绍了一种利用松弛度概念来量化HVAC操作请求紧急程度的方法，并提出了一个两级方法来优化大量HVAC系统的能源消耗。 |
| [^57] | [GuidedMixup: An Efficient Mixup Strategy Guided by Saliency Maps.](http://arxiv.org/abs/2306.16612) | 提出了一种新颖的显著性感知混合方法GuidedMixup，通过优化配对图像中显著区域的冲突，以低计算开销在混合图像中保留显著区域。多个数据集上的实验证明，GuidedMixup在增强效果和计算效率之间取得了良好的平衡。 |
| [^58] | [An Efficient Sparse Inference Software Accelerator for Transformer-based Language Models on CPUs.](http://arxiv.org/abs/2306.16601) | 本文提出了一个用于基于Transformer的语言模型的高效稀疏推断软件加速器，在CPU上利用Intel Deep Learning Boost实现了稀疏矩阵-稠密矩阵乘法的优化，相较于现有的稀疏库，在各种形状和稀疏度下都获得了一个数量级的性能提升。 |
| [^59] | [Does Saliency-Based Training bring Robustness for Deep Neural Networks in Image Classification?.](http://arxiv.org/abs/2306.16581) | 通过对深度神经网络进行显著性训练无法提高其在对抗性示例攻击下的鲁棒性。 |
| [^60] | [Feature Selection: A perspective on inter-attribute cooperation.](http://arxiv.org/abs/2306.16559) | 本文综述了辅助特征间协作的过滤特征选择方法的最新研究进展，并总结了不同方法在文献中的贡献。同时提出了当前存在的问题和挑战，以确定未来有前景的研究和发展方向。 |
| [^61] | [Learning Fair Classifiers via Min-Max F-divergence Regularization.](http://arxiv.org/abs/2306.16552) | 本文提出了一种通过最小-最大F-散度正则化学习公平分类器的框架，该框架通过使用F-散度衡量公平性，并保持高准确性。该框架可以适用于多个敏感属性和高维数据集。 |
| [^62] | [A systematic study of the foreground-background imbalance problem in deep learning for object detection.](http://arxiv.org/abs/2306.16539) | 本文系统研究了深度学习目标检测中前景-背景不平衡问题，发现该问题会导致检测性能下降，尤其当训练数据较少时影响更大。同时，减小目标大小也会增加不平衡问题的影响。 |
| [^63] | [CLANet: A Comprehensive Framework for Cross-Batch Cell Line Identification Using Brightfield Images.](http://arxiv.org/abs/2306.16538) | CLANet是一个全面的基于亮场图像的跨批细胞系鉴定框架，通过引入细胞聚类级别的选择方法和自监督学习策略，解决了批次效应导致的数据分布偏移问题，从而提高了细胞系鉴定的准确性和可靠性。 |
| [^64] | [ICSVR: Investigating Compositional and Semantic Understanding in Video Retrieval Models.](http://arxiv.org/abs/2306.16533) | 这篇论文研究了视频检索模型中的组合和语义理解，并通过在标准基准测试上进行实验，评估了这些组成部分对视频检索性能的影响。 |
| [^65] | [Multimodal Search on Iconclass using Vision-Language Pre-Trained Models.](http://arxiv.org/abs/2306.16529) | 本文介绍了一种使用预训练的视觉-语言模型CLIP的搜索引擎实现方案，用于Iconclass图像分类系统，可以通过图像或文本查询来检索和探索Iconclass概念。 |
| [^66] | [HNO: Hyena Neural Operator for solving PDEs.](http://arxiv.org/abs/2306.16524) | 本研究使用了一种名为鬣狗的新型神经算子，它利用多层感知器参数化的长卷积滤波器来解决PDE问题。这种方法通过增强模型对输入上下文的理解，并为不同的PDE实例提供数据依赖权重，提供了一种有效的求解PDE的方式。 |
| [^67] | [SARC: Soft Actor Retrospective Critic.](http://arxiv.org/abs/2306.16503) | SARC是一个基于SAC算法的新方法，通过改进评论者实现更好的收敛性和梯度估计，为演员提供了更好的策略梯度估计。 |
| [^68] | [Event Detection from Social Media Stream: Methods, Datasets and Opportunities.](http://arxiv.org/abs/2306.16495) | 本论文调查了Twitter数据流的事件检测方法，提供了公开可用的数据集，并探讨了未来的研究机会。 |
| [^69] | [Increasing Performance And Sample Efficiency With Model-agnostic Interactive Feature Attributions.](http://arxiv.org/abs/2306.16431) | 本文提出了一种增强模型普适的交互式特征归因方法，通过纠正特征归因并重新训练模型，显著提高了模型的性能和样本效率。 |
| [^70] | [Realistic Synthetic Financial Transactions for Anti-Money Laundering Models.](http://arxiv.org/abs/2306.16424) | 本文提供了一个逼真的合成金融交易数据集生成器和一组合成的反洗钱数据集，以满足训练模型和推进领域发展的需求。 |
| [^71] | [A Framework for Identifying Depression on Social Media: MentalRiskES@IberLEF 2023.](http://arxiv.org/abs/2306.16125) | 该论文介绍了在社交媒体上识别抑郁症的框架，使用机器学习和深度学习技术来解决四个预测子任务，并发现使用句子嵌入作为线性回归器的输入产生了更好的结果。 |
| [^72] | [Secure and Fast Asynchronous Vertical Federated Learning via Cascaded Hybrid Optimization.](http://arxiv.org/abs/2306.16077) | 本论文提出了一种在垂直联邦学习中使用级联混合优化的方法，通过在下游使用零阶优化保护隐私并在上游使用一阶优化提高收敛速度，从而解决了ZOO-based VFL收敛速度较慢的问题。 |
| [^73] | [An Empirical Evaluation of the Rashomon Effect in Explainable Machine Learning.](http://arxiv.org/abs/2306.15786) | 通过对不同数据集、模型和指标进行定量评估，我们发现罗生门效应对可解释机器学习具有影响，这为之前的轶事证据提供了实证支持，并展示了科学家和实践者面临的挑战。 |
| [^74] | [ShuttleSet22: Benchmarking Stroke Forecasting with Stroke-Level Badminton Dataset.](http://arxiv.org/abs/2306.15664) | 本研究提供了一个收集自2022年高排名比赛的羽毛球单打数据集ShuttleSet22，并使用最先进的拍球预测方法ShuttleNet进行了基准测试。 |
| [^75] | [Enhancing Adversarial Training via Reweighting Optimization Trajectory.](http://arxiv.org/abs/2306.14275) | 本文提出了一种名为“加权优化轨迹（WOT）”的新方法，通过优化历史轨迹，解决了对抗训练中的鲁棒泛化问题。 |
| [^76] | [On Computational Mechanisms for Shared Intentionality, and Speculation on Rationality and Consciousness.](http://arxiv.org/abs/2306.13657) | 本文提出了一种共享意图优先的理论，探讨了支持计算机代理人之间共享意图的基本机制所必须具备的特征，并探索了这些机制如何适用于人类以提供对人类理性和意识的解释。 |
| [^77] | [SDR-GAIN: A High Real-Time Occluded Pedestrian Pose Completion Method for Autonomous Driving.](http://arxiv.org/abs/2306.03538) | SDR-GAIN是一种用于解决行人姿态中部分遮挡问题的关键点补全方法，它通过对不完整的关键点进行降维，统一特征分布，并使用GAN框架的两种生成模型来完成姿态的补全。该方法的实验表明性能优于基本的GAIN框架。 |
| [^78] | [Rethinking Model Evaluation as Narrowing the Socio-Technical Gap.](http://arxiv.org/abs/2306.03100) | 针对同质化的模型，模型评估需要提供有效的评估，以判断特定模型是否在下游使用场景中可以满足多少人类需求，并且应该根据真实的社会需求来开发评估模型，并拥抱多样化的评估方法。 |
| [^79] | [Data Augmentation Approaches for Source Code Models: A Survey.](http://arxiv.org/abs/2305.19915) | 本文对源代码的数据增强技术进行了全面的调查和综述，介绍了它们的分类法、优化策略和性能结果，并讨论了未来方向和研究挑战。 |
| [^80] | [Multi-source adversarial transfer learning based on similar source domains with local features.](http://arxiv.org/abs/2305.19067) | 本论文提出一种基于局部特征相似性的多源对抗迁移学习方法，用于处理源域和目标域仅具有局部相似性的迁移场景。通过子网络提取可迁移局部特征，并使用注意力模块对特征进行加权处理以抑制非相关特征。 |
| [^81] | [Python Wrapper for Simulating Multi-Fidelity Optimization on HPO Benchmarks without Any Wait.](http://arxiv.org/abs/2305.17595) | 本研究开发了一个Python封装器，用于在HPO基准测试上模拟多保真度优化，通过强制每个工作进程等待，可以减少多小时的等待时间，使得模拟结果与实际实验的评估顺序完全一致。 |
| [^82] | [Learngene: Inheriting Condensed Knowledge from the Ancestry Model to Descendant Models.](http://arxiv.org/abs/2305.02279) | 本文提出了一种机器学习范式 Learngene，将积累的知识压缩成更为紧凑的信息片段并继承给后代模型，以便于适应新的环境 |
| [^83] | [Benchmark dataset and instance generator for Real-World Three-Dimensional Bin Packing Problems.](http://arxiv.org/abs/2304.14712) | 本文提出了一个真实世界装箱问题的基准数据集和实例生成器，可以用来比较不同装箱算法的性能。 |
| [^84] | [ChatGPT vs State-of-the-Art Models: A Benchmarking Study in Keyphrase Generation Task.](http://arxiv.org/abs/2304.14177) | 本研究比较了ChatGPT和现有模型在关键短语生成任务上的性能，并发现ChatGPT在所有测试数据集和环境中的表现均优于现有模型，适用于不同领域和文档长度的关键短语生成。 |
| [^85] | [Impact-Oriented Contextual Scholar Profiling using Self-Citation Graphs.](http://arxiv.org/abs/2304.12217) | 本研究提出了一个名为GeneticFlow的基于自引图的学者剖析工具，能够满足学者特征剖析中的三个基本要求，即结构化背景、学者为中心和丰富的进化，在科学奖项推理真实任务中表现出色。 |
| [^86] | [Non-Proportional Parametrizations for Stable Hypernetwork Learning.](http://arxiv.org/abs/2304.07645) | 本文提出一种针对当前超网络训练策略不稳定、收敛速度慢的问题的解决方案，通过使用非比例加性参数化的方式来修订超网络形式，实现更加稳定和快速的训练。 |
| [^87] | [Improving Patient Pre-screening for Clinical Trials: Assisting Physicians with Large Language Models.](http://arxiv.org/abs/2304.07396) | 本文研究了使用大型语言模型InstructGPT辅助医生预筛选患者是否符合临床试验资格。通过10个合成患者简况的性能评估，展示了LLMs在识别筛选资格标准、单独分类、整体分类、以及需要筛选资格标准的百分比上的表现。 |
| [^88] | [Improving Identity-Robustness for Face Models.](http://arxiv.org/abs/2304.03838) | 该论文探讨了在没有身份注释信息的情况下，使用人脸识别嵌入向量作为身份标识的替代方法，以提高人脸模型的身份鲁棒性和公平性。 |
| [^89] | [A Survey of Large Language Models.](http://arxiv.org/abs/2303.18223) | 本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。 |
| [^90] | [Can AI-Generated Text be Reliably Detected?.](http://arxiv.org/abs/2303.11156) | 本研究通过实证和理论分析表明，在实际场景中，几种AI文本检测器不可靠。改写攻击可以破解多种检测器，包括水印方案、神经网络检测器和零样本分类器。即使是最好的检测器，随着语言模型的进一步提升，性能也会下降。因此，AI生成的文本的可靠检测仍然是一个挑战。 |
| [^91] | [A Generalized Multi-Modal Fusion Detection Framework.](http://arxiv.org/abs/2303.07064) | 本文提出了一个通用的多模态融合检测框架，旨在在复杂场景中通过准确融合激光雷达和图像来提高3D检测的精度。 |
| [^92] | [Expert-Free Online Transfer Learning in Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2303.01170) | 本文提出了Expert-Free Online Transfer Learning (EF-OnTL)算法，在多智能体系统中实现无专家的实时迁移学习。通过动态选择迁移源智能体和要转移的知识，解决了传统迁移学习需要对专家智能体任务有良好理解的问题。 |
| [^93] | [Temporal Robustness against Data Poisoning.](http://arxiv.org/abs/2302.03684) | 该论文提出了一种针对数据污染的时序威胁模型，通过利用数据的时间戳，引入了提前时间和持续时间这两个指标，从而定义了数据污染的时序鲁棒性，并提供了一种有效的保护方法。 |
| [^94] | [A geometrically aware auto-encoder for multi-texture synthesis.](http://arxiv.org/abs/2302.01616) | 一个几何感知的自编码器用于多纹理合成，通过紧凑的编码器和自适应周期内容的生成器，在几何一致的潜在空间中进行纹理表示和空间组织的分离，从而提高了纹理合成和插值任务的性能。 |
| [^95] | [DeciLS-PBO: an Effective Local Search Method for Pseudo-Boolean Optimization.](http://arxiv.org/abs/2301.12251) | 本文提出了一种名为DeciLS-PBO的有效的局部搜索方法，可以用于解决伪布尔优化问题。通过扩展基于单元传播的减少算法，并引入基于特征学习的子句权重计算方法，该方法在PBO问题的求解中取得了显著的进展。 |
| [^96] | [Mathematical Foundations for a Compositional Account of the Bayesian Brain.](http://arxiv.org/abs/2212.12538) | 本文通过应用范畴论的方法为近似推断提供了函子语义，同时还提出了贝叶斯透镜的概念和统计博弈的纤维，对统计推断问题进行了分类。 |
| [^97] | [Motion Informed Object Detection of Small Insects in Time-lapse Camera Recordings.](http://arxiv.org/abs/2212.00423) | 本文提出了一种基于运动信息的方法，用于在时间演进相机录像中检测小昆虫。通过提供一个包含大量标注昆虫的数据集，采用预处理和基于运动信息的增强技术，该方法能够有效地在复杂动态场景中提取昆虫。 |
| [^98] | [iSmallNet: Densely Nested Network with Label Decoupling for Infrared Small Target Detection.](http://arxiv.org/abs/2210.16561) | iSmallNet是一种采用标签解耦的密集嵌套网络，用于红外小目标检测。它通过解耦标签信息和引入关键模块来提升检测性能，包括多尺度嵌套交互模块和内部边界融合模块。 |
| [^99] | [Transformers over Directed Acyclic Graphs.](http://arxiv.org/abs/2210.13148) | 本文研究了在有向无环图上的Transformer。通过改进注意机制和位置编码，本方法在多种任务上表现出了很好的效果。 |
| [^100] | [SAFER: Safe Collision Avoidance using Focused and Efficient Trajectory Search with Reinforcement Learning.](http://arxiv.org/abs/2209.11789) | SAFER是一种高效有效的碰撞避障系统，通过纠正控制指令来提高安全性。它结合了强化学习、在线轨迹规划和自动紧急干预。强化学习的目标是学习有效的纠正控制动作，减少紧急制动的频率。实验结果显示，与基准方法相比，SAFER具有更高的速度、更低的碰撞率和较小的计算开销。 |
| [^101] | [MAGIC: Mask-Guided Image Synthesis by Inverting a Quasi-Robust Classifier.](http://arxiv.org/abs/2209.11549) | 本论文提出了一种名为MAGIC的方法，通过反转准鲁棒分类器进行一次性掩码引导的图像合成。它通过聚合梯度并利用强空间先验的指导二进制掩码，实现了形状和位置控制、非刚性形状变形以及复制/移动操作，并可简单指定二进制引导掩码来提供强大的合成控制。 |
| [^102] | [Language Models as Knowledge Embeddings.](http://arxiv.org/abs/2206.12617) | 该论文提出了一种使用语言模型来推导知识嵌入的方法LMKE，它旨在提高对丰富的长尾实体的表示能力并解决基于描述的先前方法的问题，实验结果表明该方法在多个基准数据集上实现了最先进的性能。 |
| [^103] | [N$^2$M$^2$: Learning Navigation for Arbitrary Mobile Manipulation Motions in Unseen and Dynamic Environments.](http://arxiv.org/abs/2206.08737) | N$^2$M$^2$是一个新的移动操纵导航系统，能够在未知和动态环境中执行各种任务，包括复杂的障碍物环境，同时具备末端执行器轨迹生成和导航技能的无缝集成能力。 |
| [^104] | ["That Is a Suspicious Reaction!": Interpreting Logits Variation to Detect NLP Adversarial Attacks.](http://arxiv.org/abs/2204.04636) | 这项工作提出了一个模型无关的对抗文本检测器，通过识别目标分类器的概率中的模式来改进对抗输入的识别性能，并具有较强的泛化能力。 |
| [^105] | [Toward a Perspectivist Turn in Ground Truthing for Predictive Computing.](http://arxiv.org/abs/2109.04270) | 本文提出了一种新的范式，数据透视主义，用于机器学习中的知识表示步骤。这种方法整合了人类参与者的观点和角度，相较于传统黄金标准数据集，具有更多潜力和优势。 |
| [^106] | [Simulation of Human and Artificial Emotion (SHArE).](http://arxiv.org/abs/2011.02151) | 这项研究介绍了模拟人类和人工情感的框架，为人类的心理健康问题提供了新的治疗方案，并且为人工智能提供了一种观察机器情感和动机的方法。 |
| [^107] | [Using Machine Teaching to Investigate Human Assumptions when Teaching Reinforcement Learners.](http://arxiv.org/abs/2009.02476) | 本文研究了在线奖励和惩罚方法下，人们对于学习者的期望假设，发现人们假设学习者具有高的折扣率和高度重视探索，并根据学习者进展调整教学策略。 |

# 详细

[^1]: 一种通过多任务异构训练实现高效通用模块化视觉模型的研究

    An Efficient General-Purpose Modular Vision Model via Multi-Task Heterogeneous Training. (arXiv:2306.17165v1 [cs.CV])

    [http://arxiv.org/abs/2306.17165](http://arxiv.org/abs/2306.17165)

    本文提出了一种通过多任务异构训练实现高效通用模块化视觉模型的方法，以应对在视觉任务之间的大量内在差异，并解决多任务模型扩展的挑战。

    

    我们提出了一种模型，可以执行多个视觉任务，并且可以高效地适应其他后续任务。尽管在多任务学习方面取得了相当大的进展，但大多数工作都集中在从多标签数据中学习：即单个图像集合具有多个任务标签。这种多标签数据集很少、规模小且昂贵。我们将异构指的是具有不同任务标签的图像集，或者是单一任务数据集的组合。很少有人研究在这种异构数据集上进行训练。通用视觉模型仍然以单一任务预训练为主导，如何通过利用设计用于不同目的的主流视觉数据集来扩展多任务模型仍然不清楚。挑战在于管理视觉任务之间的大量内在差异，包括数据分布、架构、任务特定模块、数据集规模和采样策略。为了解决这些挑战，我们提出了修改和扩展专家混合(MoE)视觉转换的方法。

    We present a model that can perform multiple vision tasks and can be adapted to other downstream tasks efficiently. Despite considerable progress in multi-task learning, most efforts focus on learning from multi-label data: a single image set with multiple task labels. Such multi-label data sets are rare, small, and expensive. We say heterogeneous to refer to image sets with different task labels, or to combinations of single-task datasets. Few have explored training on such heterogeneous datasets. General-purpose vision models are still dominated by single-task pretraining, and it remains unclear how to scale up multi-task models by leveraging mainstream vision datasets designed for different purposes. The challenges lie in managing large intrinsic differences among vision tasks, including data distribution, architectures, task-specific modules, dataset scales, and sampling strategies. To address these challenges, we propose to modify and scale up mixture-of-experts (MoE) vision trans
    
[^2]: 通过生成对抗网络(GANs)生成用于信用卡欺诈检测的合成人口数据

    Synthetic Demographic Data Generation for Card Fraud Detection Using GANs. (arXiv:2306.17109v1 [cs.LG])

    [http://arxiv.org/abs/2306.17109](http://arxiv.org/abs/2306.17109)

    该论文提出了一种名为DGGAN的深度学习生成对抗网络，用于生成合成人口数据，以用于信用卡欺诈检测。通过使用相对复杂的合成人口数据，可以提高交易数据特征的复杂性，并提升欺诈检测性能。

    

    在许多领域中，使用机器学习模型生成合成数据已经变得普遍。生成可以用于检测欺诈的合成交易数据的技术也在快速发展。一般来说，这些合成数据只包含交易的信息，例如时间、地点和金额。通常不包含个体用户的特征（年龄和性别偶尔会包含）。使用相对复杂的合成人口数据可能提高交易数据特征的复杂性，从而提高欺诈检测性能。受益于机器学习的发展，一些深度学习模型具有超过其他成熟的合成数据生成方法（如微模拟）的潜力。在本研究中，我们构建了一个名为DGGAN的深度学习生成对抗网络，用于生成人口数据。我们的模型在模型训练期间生成样本，我们发现这是重要的。

    Using machine learning models to generate synthetic data has become common in many fields. Technology to generate synthetic transactions that can be used to detect fraud is also growing fast. Generally, this synthetic data contains only information about the transaction, such as the time, place, and amount of money. It does not usually contain the individual user's characteristics (age and gender are occasionally included). Using relatively complex synthetic demographic data may improve the complexity of transaction data features, thus improving the fraud detection performance. Benefiting from developments of machine learning, some deep learning models have potential to perform better than other well-established synthetic data generation methods, such as microsimulation. In this study, we built a deep-learning Generative Adversarial Network (GAN), called DGGAN, which will be used for demographic data generation. Our model generates samples during model training, which we found importan
    
[^3]: RL4CO: 用于组合优化的广泛强化学习基准测试

    RL4CO: an Extensive Reinforcement Learning for Combinatorial Optimization Benchmark. (arXiv:2306.17100v1 [cs.LG])

    [http://arxiv.org/abs/2306.17100](http://arxiv.org/abs/2306.17100)

    RL4CO是一个用于组合优化的广泛强化学习基准测试，着重于可扩展性和泛化能力的评估，并展示了一些最新方法在样本效率和适应不同数据分布方面的表现相对较差，强调了对神经CO求解器性能的平衡评估的重要性。

    

    我们引入了RL4CO，这是一个广泛的强化学习（RL）用于组合优化（CO）的基准测试。RL4CO采用最先进的软件库和最佳实践，如模块化和配置管理，以便研究人员可以轻松修改神经网络架构、环境和算法。与现有的专注于特定任务（如旅行推销员问题）进行性能评估的方法不同，我们强调可扩展性和泛化能力对于各种优化任务的重要性。我们还系统地评估了各种模型在样本效率、零-shot泛化和适应不同数据分布方面的表现。我们的实验结果表明，一些最新的最先进方法在使用这些新指标进行评估时落后于之前的方法，这表明有必要更加平衡地评估神经CO求解器的性能。我们希望RL4CO能够为研究人员提供一个综合性的基准测试工具，以进一步推动强化学习在组合优化领域的研究。

    We introduce RL4CO, an extensive reinforcement learning (RL) for combinatorial optimization (CO) benchmark. RL4CO employs state-of-the-art software libraries as well as best practices in implementation, such as modularity and configuration management, to be efficient and easily modifiable by researchers for adaptations of neural network architecture, environments, and algorithms. Contrary to the existing focus on specific tasks like the traveling salesman problem (TSP) for performance assessment, we underline the importance of scalability and generalization capabilities for diverse optimization tasks. We also systematically benchmark sample efficiency, zero-shot generalization, and adaptability to changes in data distributions of various models. Our experiments show that some recent state-of-the-art methods fall behind their predecessors when evaluated using these new metrics, suggesting the necessity for a more balanced view of the performance of neural CO solvers. We hope RL4CO will 
    
[^4]: RAPGen: 一种解决零样本代码低效问题的方法

    RAPGen: An Approach for Fixing Code Inefficiencies in Zero-Shot. (arXiv:2306.17077v1 [cs.SE])

    [http://arxiv.org/abs/2306.17077](http://arxiv.org/abs/2306.17077)

    RAPGen是一种新方法，通过在零样本情况下使用Retrieval-Augmented Prompt Generation（RAPGen）方法，即从预先构建的性能Bug修复知识库中检索提示指令并生成提示，然后在大型语言模型上生成修复方案，可以有效地解决代码低效问题。实验结果显示，在专家验证的数据集中，RAPGen在60%的情况下可以生成与开发者等效或更好的性能改进建议，其中约39%的建议完全相同。

    

    性能Bug是一种即使在经过充分测试的商业产品中也可能出现的非功能性问题。修复这些性能Bug是一个重要但具有挑战性的问题。在这项工作中，我们解决了这个挑战，并提出了一种名为Retrieval-Augmented Prompt Generation（RAPGen）的新方法。给定一个存在性能问题的代码片段，RAPGen首先从预先构建的之前性能Bug修复知识库中检索一个提示指令，然后使用检索到的指令生成一个提示。然后，它在零样本情况下使用这个提示在大型语言模型（如Codex）上生成一个修复方案。我们将我们的方法与各种提示变体和现有方法在性能Bug修复任务中进行了比较。我们的评估结果显示，RAPGen在60%的情况下可以生成与开发者等效或更好的性能改进建议，在经过专家验证的过去C#开发者所做的性能更改数据集中有约39%的建议完全相同。

    Performance bugs are non-functional bugs that can even manifest in well-tested commercial products. Fixing these performance bugs is an important yet challenging problem. In this work, we address this challenge and present a new approach called Retrieval-Augmented Prompt Generation (RAPGen). Given a code snippet with a performance issue, RAPGen first retrieves a prompt instruction from a pre-constructed knowledge-base of previous performance bug fixes and then generates a prompt using the retrieved instruction. It then uses this prompt on a Large Language Model (such as Codex) in zero-shot to generate a fix. We compare our approach with the various prompt variations and state of the art methods in the task of performance bug fixing. Our evaluation shows that RAPGen can generate performance improvement suggestions equivalent or better than a developer in ~60% of the cases, getting ~39% of them verbatim, in an expert-verified dataset of past performance changes made by C# developers.
    
[^5]: 学习结构引导的扩散模型用于二维人体姿态估计

    Learning Structure-Guided Diffusion Model for 2D Human Pose Estimation. (arXiv:2306.17074v1 [cs.CV])

    [http://arxiv.org/abs/2306.17074](http://arxiv.org/abs/2306.17074)

    本文提出了一种学习结构引导的扩散模型(DiffusionPose)用于二维人体姿态估计，通过从噪声热图生成关键点热图的方式，通过添加噪声将关键点扩散到随机分布，并利用图像特征构建的条件恢复出真实的热图。扩散模型以逐步去噪的方式生成热图，同时利用人体结构信息进一步提高性能，在大量实验中取得了优越的结果。

    

    二维人体姿态估计的主流方案之一是通过神经网络学习关键点热图。现有方法通常通过定制化的架构（如高分辨率表示和视觉Transformer）改进热图的质量。本文提出了DiffusionPose，一种新的方案，将二维人体姿态估计表述为从噪声热图生成关键点热图的问题。在训练过程中，通过添加噪声将关键点扩散到随机分布，扩散模型学习根据图像特征构建的条件从噪声热图中恢复出真实的热图。在推断过程中，扩散模型以逐步去噪的方式从初始化热图生成热图。此外，我们进一步探索通过人体结构信息改善DiffusionPose的性能。大量实验显示了我们的DiffusionPose的优越性，分别提高了1.6、1.2和1.2 mAP。

    One of the mainstream schemes for 2D human pose estimation (HPE) is learning keypoints heatmaps by a neural network. Existing methods typically improve the quality of heatmaps by customized architectures, such as high-resolution representation and vision Transformers. In this paper, we propose \textbf{DiffusionPose}, a new scheme that formulates 2D HPE as a keypoints heatmaps generation problem from noised heatmaps. During training, the keypoints are diffused to random distribution by adding noises and the diffusion model learns to recover ground-truth heatmaps from noised heatmaps with respect to conditions constructed by image feature. During inference, the diffusion model generates heatmaps from initialized heatmaps in a progressive denoising way. Moreover, we further explore improving the performance of DiffusionPose with conditions from human structural information. Extensive experiments show the prowess of our DiffusionPose, with improvements of 1.6, 1.2, and 1.2 mAP on widely-us
    
[^6]: 计算创造力中的跨学科方法：人类变量如何塑造人工智能研究

    Interdisciplinary Methods in Computational Creativity: How Human Variables Shape Human-Inspired AI Research. (arXiv:2306.17070v1 [cs.AI])

    [http://arxiv.org/abs/2306.17070](http://arxiv.org/abs/2306.17070)

    本文研究了计算创造力中人类变量对人工智能研究的影响和转化过程，通过22个访谈发现了与计算创造力最相关的信息。

    

    创造力最初是来自人类心理学的一个概念，但在计算创造力的领域中，它变得更深入。当创造力作为计算系统的一部分时，创造力的含义可以被认为是计算创造力的核心问题。然而，当研究人员将人类心理学的概念转化为计算时，这个问题变得更加突出。本文通过对22个深入的半结构化访谈进行研究，主要针对以创造力为主要研究领域的人工智能研究人员。本文重点关注与计算创造力最相关的发现。

    The word creativity originally described a concept from human psychology, but in the realm of computational creativity (CC), it has become much more. The question of what creativity means when it is part of a computational system might be considered core to CC. Pinning down the meaning of creativity, and concepts like it, becomes salient when researchers port concepts from human psychology to computation, a widespread practice extending beyond CC into artificial intelligence (AI). Yet, the human processes shaping human-inspired computational systems have been little investigated. In this paper, we question which human literatures (social sciences, psychology, neuroscience) enter AI scholarship and how they are translated at the port of entry. This study is based on 22 in-depth, semi-structured interviews, primarily with human-inspired AI researchers, half of whom focus on creativity as a major research area. This paper focuses on findings most relevant to CC. We suggest that which huma
    
[^7]: 基于加权CapsuleNet网络的阿拉伯语和波斯语多领域情感分析方法

    Presenting an approach based on weighted CapsuleNet networks for Arabic and Persian multi-domain sentiment analysis. (arXiv:2306.17068v1 [cs.CL])

    [http://arxiv.org/abs/2306.17068](http://arxiv.org/abs/2306.17068)

    本文提出了一种基于加权胶囊网络的阿拉伯语和波斯语多领域情感分析方法，通过训练单独的胶囊网络并使用加权度量来实现情感分类，具有较好的准确性和适应性。

    

    情感分类是自然语言处理中的基本任务，对自由文本进行正面、负面或中性的分类。然而，情感分类模型高度依赖于领域，分类器在一个领域中可能具有合理的准确性，但在另一个领域中由于词语的语义多重性而准确率较低。本文提出了一种新的波斯语/阿拉伯语多领域情感分析方法，使用累积加权胶囊网络的方法。加权胶囊集合由为每个领域训练的单独的胶囊网络和称为领域所属度（DBD）的加权度量组成。这个度量由TF和IDF组成，计算每个文档对于每个领域的依赖关系，然后乘以每个胶囊创建的可能输出。最终，这些乘积的总和是最终输出的标签，并用于确定极性。

    Sentiment classification is a fundamental task in natural language processing, assigning one of the three classes, positive, negative, or neutral, to free texts. However, sentiment classification models are highly domain dependent; the classifier may perform classification with reasonable accuracy in one domain but not in another due to the Semantic multiplicity of words getting poor accuracy. This article presents a new Persian/Arabic multi-domain sentiment analysis method using the cumulative weighted capsule networks approach. Weighted capsule ensemble consists of training separate capsule networks for each domain and a weighting measure called domain belonging degree (DBD). This criterion consists of TF and IDF, which calculates the dependency of each document for each domain separately; this value is multiplied by the possible output that each capsule creates. In the end, the sum of these multiplications is the title of the final output, and is used to determine the polarity. And 
    
[^8]: The mapKurator系统：从历史地图中提取和链接文本的完整管道

    The mapKurator System: A Complete Pipeline for Extracting and Linking Text from Historical Maps. (arXiv:2306.17059v1 [cs.AI])

    [http://arxiv.org/abs/2306.17059](http://arxiv.org/abs/2306.17059)

    该论文介绍了一种名为mapKurator的系统，能完整地从历史地图中提取和链接文本信息。该系统解决了传统方法中对位置相关词语的忽略问题，并利用主题建模方法考虑更广的主题范围，能够识别文档的空间焦点。

    

    文档具有空间焦点和有价值的地方特征。例如，房地产或旅行博客中的列表描述包含有关特定地区社区的信息。这些信息对于描述人类如何感知他们的环境是有价值的。然而，利用这些信息的第一步是识别文档的空间焦点（例如，城市）。传统方法用于识别文档的空间焦点依赖于从文档中检测和消歧化地名。这种方法需要一个包含位置短语和临时规则的词汇集，这些规则忽略了与位置相关的重要词语。最近，使用大型语言模型的主题建模方法通常考虑几个广度的主题。相比之下，文档的空间焦点可以是一个国家、一个城市，甚至是一个社区，这些范围比这些方法考虑的主题数要大得多。

    Documents hold spatial focus and valuable locality characteristics. For example, descriptions of listings in real estate or travel blogs contain information about specific local neighborhoods. This information is valuable to characterize how humans perceive their environment. However, the first step to making use of this information is to identify the spatial focus (e.g., a city) of a document. Traditional approaches for identifying the spatial focus of a document rely on detecting and disambiguating toponyms from the document. This approach requires a vocabulary set of location phrases and ad-hoc rules, which ignore important words related to location. Recent topic modeling approaches using large language models often consider a few topics, each with broad coverage. In contrast, the spatial focus of a document can be a country, a city, or even a neighborhood, which together, is much larger than the number of topics considered in these approaches. Additionally, topic modeling methods a
    
[^9]: 安全的基于模型的多智能体均场强化学习

    Safe Model-Based Multi-Agent Mean-Field Reinforcement Learning. (arXiv:2306.17052v1 [cs.LG])

    [http://arxiv.org/abs/2306.17052](http://arxiv.org/abs/2306.17052)

    本文提出了Safe-$\text{M}^3$-UCRL算法，通过使用模型中的认知不确定性和对数障碍方法，实现了在未知转移动态情况下达到安全策略的优化，成功解决了大规模多智能体协调问题。

    

    许多应用，比如共享交通，需要协调大量的智能体。均场强化学习通过优化代表性智能体的策略来应对由此带来的可扩展性挑战。在本文中，我们解决了一个重要的泛化问题，即智能体分布存在全局约束的情况（例如需要满足容量约束或最小覆盖要求）。我们提出了Safe-$\text{M}^3$-UCRL，这是第一个能够在未知转移动态的情况下实现安全策略的基于模型的算法。作为一个关键因素，它在保证悲观约束满足的同时，利用转移模型中的认知不确定性来使用对数障碍方法确保高概率。我们在许多共享交通运营商面临的车辆重定位问题上展示了Safe-$\text{M}^3$-UCRL，并通过基于深圳出租车轨迹数据的仿真评估其性能。我们的算法能够有效满足关键需求。

    Many applications, e.g., in shared mobility, require coordinating a large number of agents. Mean-field reinforcement learning addresses the resulting scalability challenge by optimizing the policy of a representative agent. In this paper, we address an important generalization where there exist global constraints on the distribution of agents (e.g., requiring capacity constraints or minimum coverage requirements to be met). We propose Safe-$\text{M}^3$-UCRL, the first model-based algorithm that attains safe policies even in the case of unknown transition dynamics. As a key ingredient, it uses epistemic uncertainty in the transition model within a log-barrier approach to ensure pessimistic constraints satisfaction with high probability. We showcase Safe-$\text{M}^3$-UCRL on the vehicle repositioning problem faced by many shared mobility operators and evaluate its performance through simulations built on Shenzhen taxi trajectory data. Our algorithm effectively meets the demand in critica
    
[^10]: 探索和利用高阶图结构进行稀疏知识图谱补全

    Exploring & Exploiting High-Order Graph Structure for Sparse Knowledge Graph Completion. (arXiv:2306.17034v1 [cs.AI])

    [http://arxiv.org/abs/2306.17034](http://arxiv.org/abs/2306.17034)

    本论文提出了一种新的框架 LR-GCN，用于在稀疏知识图谱中进行补全。该框架能够探索高阶图结构，自动捕捉实体之间的远程依赖关系，并通过逻辑推理提炼知识，从而有效解决稀疏性带来的挑战。

    

    稀疏知识图谱场景对之前的知识图谱补全方法提出了挑战，即随着图的稀疏性增加，补全性能迅速下降。由于稀疏知识图谱在实际应用中广泛存在，这个问题也被加剧。为了缓解这个挑战，我们提出了一种新颖的框架，LR-GCN，能够自动捕捉实体之间有价值的远程依赖关系，以补充不足的结构特征并提炼逻辑推理知识用于稀疏图谱补全。所提出的方法包括两个主要组件：基于GNN的预测器和推理路径提取器。推理路径提取器探索高阶图结构，如推理路径，并将其编码为富语义边，明确地将远程依赖关系组合到预测器中。此步骤还在稀疏问题中起着重要作用，有效缓解了稀疏问题。此外，路径提取器还可以帮助密化知识图谱。

    Sparse knowledge graph (KG) scenarios pose a challenge for previous Knowledge Graph Completion (KGC) methods, that is, the completion performance decreases rapidly with the increase of graph sparsity. This problem is also exacerbated because of the widespread existence of sparse KGs in practical applications. To alleviate this challenge, we present a novel framework, LR-GCN, that is able to automatically capture valuable long-range dependency among entities to supplement insufficient structure features and distill logical reasoning knowledge for sparse KGC. The proposed approach comprises two main components: a GNN-based predictor and a reasoning path distiller. The reasoning path distiller explores high-order graph structures such as reasoning paths and encodes them as rich-semantic edges, explicitly compositing long-range dependencies into the predictor. This step also plays an essential role in densifying KGs, effectively alleviating the sparse issue. Furthermore, the path distiller
    
[^11]: 面向离散和连续强化学习的安全感知任务组合

    Safety-Aware Task Composition for Discrete and Continuous Reinforcement Learning. (arXiv:2306.17033v1 [cs.LG])

    [http://arxiv.org/abs/2306.17033](http://arxiv.org/abs/2306.17033)

    本文研究了布尔组合在强化学习中的应用，通过引入两种安全性概念和拓展到连续行动空间，实现了任务的安全感知组合。

    

    组合性是可扩展系统设计的关键方面。强化学习（RL）最近在任务学习方面取得了重大成功，但是在真正利用组合方面才刚刚开始。在本文中，我们关注学习任务的布尔组合，而不是功能性或顺序性组合。现有的RL布尔组合侧重于在具有离散行动空间的环境中达到一个令人满意的吸收状态，但不支持可组合的安全性（即避免）约束。我们通过三个贡献推进了学习任务布尔组合的最新技术：i）在此框架中引入了两种不同的安全性概念；ii）展示如何强制执行安全语义，证明正确性（在一些假设下），并分析两种安全性概念之间的权衡；iii）将布尔组合从离散行动空间扩展到连续行动空间。我们使用修改版的价值迭代算法来演示这些技术。

    Compositionality is a critical aspect of scalable system design. Reinforcement learning (RL) has recently shown substantial success in task learning, but has only recently begun to truly leverage composition. In this paper, we focus on Boolean composition of learned tasks as opposed to functional or sequential composition. Existing Boolean composition for RL focuses on reaching a satisfying absorbing state in environments with discrete action spaces, but does not support composable safety (i.e., avoidance) constraints. We advance the state of the art in Boolean composition of learned tasks with three contributions: i) introduce two distinct notions of safety in this framework; ii) show how to enforce either safety semantics, prove correctness (under some assumptions), and analyze the trade-offs between the two safety notions; and iii) extend Boolean composition from discrete action spaces to continuous action spaces. We demonstrate these techniques using modified versions of value iter
    
[^12]: 使用社交媒体上的判决文件对犯罪类型进行分类

    Classifying Crime Types using Judgment Documents from Social Media. (arXiv:2306.17020v1 [cs.CL])

    [http://arxiv.org/abs/2306.17020](http://arxiv.org/abs/2306.17020)

    本文提出了一种通过NLP处理方法的新的训练模型，通过生成新样本来平衡不均匀的数据集分布的缺陷，并使用预训练和微调来赋予模型对小数据集的良好泛化能力。

    

    基于犯罪行为事实来确定犯罪类型的任务在社会科学中变得非常重要和有意义。但该领域面临的问题是，由于犯罪本身的性质，数据样本本身分布不均匀。同时，司法领域的数据集少有公开可用，无法产生用于直接训练的大型数据集。本文提出了一种通过NLP处理方法解决该问题的新的训练模型。我们首先提出了一个犯罪事实数据预处理模块(CFDPM)，通过生成新样本来平衡不均匀的数据集分布的缺陷。然后，我们使用一个大型开源数据集(CAIL-big)作为我们的预训练数据集，使用我们自己收集的一个小数据集进行微调，赋予模型对不熟悉的小数据集具有良好的泛化能力。同时，我们使用改进的Bert模型和动态遮蔽来改进模型。实验证明

    The task of determining crime types based on criminal behavior facts has become a very important and meaningful task in social science. But the problem facing the field now is that the data samples themselves are unevenly distributed, due to the nature of the crime itself. At the same time, data sets in the judicial field are less publicly available, and it is not practical to produce large data sets for direct training. This article proposes a new training model to solve this problem through NLP processing methods. We first propose a Crime Fact Data Preprocessing Module (CFDPM), which can balance the defects of uneven data set distribution by generating new samples. Then we use a large open source dataset (CAIL-big) as our pretraining dataset and a small dataset collected by ourselves for Fine-tuning, giving it good generalization ability to unfamiliar small datasets. At the same time, we use the improved Bert model with dynamic masking to improve the model. Experiments show that the 
    
[^13]: milliFlow：用于人体运动感知的毫米波雷达点云场景流估计

    milliFlow: Scene Flow Estimation on mmWave Radar Point Cloud for Human Motion Sensing. (arXiv:2306.17010v1 [cs.CV])

    [http://arxiv.org/abs/2306.17010](http://arxiv.org/abs/2306.17010)

    milliFlow是一种用于人体运动感知的新型深度学习方法，通过对毫米波雷达点云进行场景流估计，能够提供中间层的特征并直接用于下游的人体运动感知任务中。实验证明该方法具有优越性能。

    

    随着普适计算时代的到来，人体运动感知在智能系统中起着关键作用，用于决策、用户交互和个性化服务。在传统方法中，人体跟踪、姿势估计、手势识别和活动识别等方面进行了大量研究，这些方法主要基于摄像机。然而，摄像机的侵入性特点限制了它们在智能家居应用中的使用。为了解决这个问题，毫米波雷达由于其保护隐私的特点而受到欢迎。在这项工作中，我们提出了一种新颖的深度学习方法milliFlow，用于对毫米波雷达点云进行场景流估计，作为中间层的特征，直接受益于下游的人体运动感知任务。实验结果表明，我们的方法具有优越的性能，平均3D端点误差为4.6cm，明显超过竞争方法。此外，通过结合...

    Approaching the era of ubiquitous computing, human motion sensing plays a crucial role in smart systems for decision making, user interaction, and personalized services. Extensive research has been conducted on human tracking, pose estimation, gesture recognition, and activity recognition, which are predominantly based on cameras in traditional methods. However, the intrusive nature of cameras limits their use in smart home applications. To address this, mmWave radars have gained popularity due to their privacy-friendly features. In this work, we propose \textit{milliFlow}, a novel deep learning method for scene flow estimation as a complementary motion information for mmWave point cloud, serving as an intermediate level of features and directly benefiting downstream human motion sensing tasks. Experimental results demonstrate the superior performance of our method with an average 3D endpoint error of 4.6cm, significantly surpassing the competing approaches. Furthermore, by incorporati
    
[^14]: Diffusion-Jump GNNs: 可学习度量过滤器的同质化

    Diffusion-Jump GNNs: Homophiliation via Learnable Metric Filters. (arXiv:2306.16976v1 [cs.LG])

    [http://arxiv.org/abs/2306.16976](http://arxiv.org/abs/2306.16976)

    提出了一种名为Diffusion-Jump GNNs的新方法，通过学习可调节的度量过滤器，来提高高阶图神经网络在异质化场景下的效果。这种方法通过跳跃式的渐进扩散距离生成过滤器的支持和系数，以寻找散点之间的联系。

    

    高阶图神经网络（HO-GNNs）被开发用于在异质性范围中推断一致的潜在空间，其中标签分布与图结构无关。然而，大多数现有的HO-GNNs是基于跳数的，即它们依赖于转移矩阵的幂次。因此，这些结构对分类损失的反应不完全，并且所达到的结构化过滤器具有静态支持。换句话说，这些网络不能学习过滤器的支持或系数，而只能学习过滤器的组合。为了解决上述问题，我们提出了基于渐进扩散距离的跳跃扩散GNNs方法。扩散跳跃生成一对一的距离，其投影确定每个结构化过滤器的支持和系数。这些过滤器称为跳跃，因为它们在广泛的尺度范围内探索以找到散点之间的联系。

    High-order Graph Neural Networks (HO-GNNs) have been developed to infer consistent latent spaces in the heterophilic regime, where the label distribution is not correlated with the graph structure. However, most of the existing HO-GNNs are hop-based, i.e., they rely on the powers of the transition matrix. As a result, these architectures are not fully reactive to the classification loss and the achieved structural filters have static supports. In other words, neither the filters' supports nor their coefficients can be learned with these networks. They are confined, instead, to learn combinations of filters. To address the above concerns, we propose Diffusion-jump GNNs a method relying on asymptotic diffusion distances that operates on jumps. A diffusion-pump generates pairwise distances whose projections determine both the support and coefficients of each structural filter. These filters are called jumps because they explore a wide range of scales in order to find bonds between scatter
    
[^15]: 直接效应在总结因果图中的可辨识性

    Identifiability of direct effects from summary causal graphs. (arXiv:2306.16958v1 [cs.AI])

    [http://arxiv.org/abs/2306.16958](http://arxiv.org/abs/2306.16958)

    该论文研究了在缺乏完整时间因果图的情况下，直接因果效应如何从总结因果图中进行可辨识，并提出了一个完整的可辨识性结果。

    

    动态结构因果模型（SCMs）是一个强大的框架，用于推理动态系统中的直接效应，即衡量一个变量的变化如何影响另一个变量，同时保持其他变量不变。动态结构因果模型中的因果关系可以用完全时间因果图来进行定性表示。假设线性和因果充分性，并给定完全时间因果图，直接因果效应总是可辨识的，并可以通过调整由所谓的单门准则给出的任何变量集合来从数据中估计。然而，在许多应用中，由于各种原因没有此类图形可用，但专家仍然可以访问完全时间因果图的一个抽象，该抽象表示了时间序列之间的因果关系，同时省略了时间信息。本文提出了一个完整的可辨识性结果，其中详细描述了所有直接效应在总结因果图中可辨识的情况。

    Dynamic structural causal models (SCMs) are a powerful framework for reasoning in dynamic systems about direct effects which measure how a change in one variable affects another variable while holding all other variables constant. The causal relations in a dynamic structural causal model can be qualitatively represented with a full-time causal graph. Assuming linearity and causal sufficiency and given the full-time causal graph, the direct causal effect is always identifiable and can be estimated from data by adjusting on any set of variables given by the so-called single-door criterion. However, in many application such a graph is not available for various reasons but nevertheless experts have access to an abstraction of the full-time causal graph which represents causal relations between time series while omitting temporal information. This paper presents a complete identifiability result which characterizes all cases for which the direct effect is graphically identifiable from summa
    
[^16]: MEMD-ABSA：面向方面情感分析的多要素多领域数据集

    MEMD-ABSA: A Multi-Element Multi-Domain Dataset for Aspect-Based Sentiment Analysis. (arXiv:2306.16956v1 [cs.CL])

    [http://arxiv.org/abs/2306.16956](http://arxiv.org/abs/2306.16956)

    这个论文提出了一个大规模的多要素多领域数据集（MEMD-ABSA），用于面向方面情感分析的研究。数据集涵盖了五个领域的四个要素，包括近2万个评论句子和3万个带有显式和隐式方面和观点的四元组。研究结果表明，开放领域ABSA以及挖掘隐含的方面和观点仍然是待解决的挑战。

    

    面向方面情感分析是情感挖掘领域长期以来的研究兴趣，近年来，研究人员逐渐将焦点从简单的ABSA子任务转向端到端的多要素ABSA任务。然而，目前研究中使用的数据集局限于特定任务的个别要素，通常关注于领域内设置，忽略了隐含的方面和观点，并且数据规模较小。为了解决这些问题，我们提出了一个大规模的多要素多领域数据集(MEMD)，涵盖了五个领域的四个要素，包括近2万个评论句子和3万个带有显式和隐式方面和观点的四元组，可用于ABSA研究。同时，我们在开放领域设置下评估了生成式和非生成式基线模型在多个ABSA子任务上的表现，结果表明，开放领域ABSA以及挖掘隐含的方面和观点仍然是待解决的挑战。

    Aspect-based sentiment analysis is a long-standing research interest in the field of opinion mining, and in recent years, researchers have gradually shifted their focus from simple ABSA subtasks to end-to-end multi-element ABSA tasks. However, the datasets currently used in the research are limited to individual elements of specific tasks, usually focusing on in-domain settings, ignoring implicit aspects and opinions, and with a small data scale. To address these issues, we propose a large-scale Multi-Element Multi-Domain dataset (MEMD) that covers the four elements across five domains, including nearly 20,000 review sentences and 30,000 quadruples annotated with explicit and implicit aspects and opinions for ABSA research. Meanwhile, we evaluate generative and non-generative baselines on multiple ABSA subtasks under the open domain setting, and the results show that open domain ABSA as well as mining implicit aspects and opinions remain ongoing challenges to be addressed. The datasets
    
[^17]: 备选的变焦位移：一种高效的多模态对齐方法

    Alternative Telescopic Displacement: An Efficient Multimodal Alignment Method. (arXiv:2306.16950v1 [cs.CV])

    [http://arxiv.org/abs/2306.16950](http://arxiv.org/abs/2306.16950)

    备选的变焦位移是一种高效的多模态对齐方法，通过交替移动和扩展特征信息来融合多模态数据，可以稳健地捕捉不同模态特征之间的高级交互作用，从而显著提高多模态学习的性能，并在多个任务上优于其他流行的多模态方案。

    

    特征对齐是融合多模态数据的主要方式。我们提出了一种特征对齐方法，可以完全融合多模态信息，通过在特征空间中交替移动和扩展来实现不同模态之间的一致表示。所提出的方法能够稳健地捕捉不同模态特征之间的高级交互作用，从而显著提高多模态学习的性能。我们还表明，所提出的方法在多个任务上优于其他流行的多模态方案。对ETT和MIT-BIH-Arrhythmia数据集的实验评估表明，所提出的方法达到了最先进的性能。

    Feature alignment is the primary means of fusing multimodal data. We propose a feature alignment method that fully fuses multimodal information, which alternately shifts and expands feature information from different modalities to have a consistent representation in a feature space. The proposed method can robustly capture high-level interactions between features of different modalities, thus significantly improving the performance of multimodal learning. We also show that the proposed method outperforms other popular multimodal schemes on multiple tasks. Experimental evaluation of ETT and MIT-BIH-Arrhythmia, datasets shows that the proposed method achieves state of the art performance.
    
[^18]: UMASS_BioNLP参加MEDIQA-Chat 2023：LLMs能否生成高质量的医生-患者基于笔记的对话？

    UMASS_BioNLP at MEDIQA-Chat 2023: Can LLMs generate high-quality synthetic note-oriented doctor-patient conversations?. (arXiv:2306.16931v1 [cs.CL])

    [http://arxiv.org/abs/2306.16931](http://arxiv.org/abs/2306.16931)

    本文介绍了UMASS_BioNLP团队在MEDIQA-Chat 2023共享任务中的参与，提出了一种新型LLMs协作系统用于生成高质量对话数据集，并与ChatGPT和GPT-4进行了比较分析。

    

    本文介绍了UMASS_BioNLP团队参与MEDIQA-Chat 2023共享任务的Task-A和Task-C。我们特别关注Task-C，并提出了一种名为医生-患者循环的新型LLMs协作系统，用于生成高质量的对话数据集。实验证明，我们的方法在ROUGE、医疗概念召回率、BLEU和Self-BLEU等自动评估指标下表现合理。此外，我们还对我们提出的方法与ChatGPT和GPT-4进行了比较分析，探讨了利用协作LLMs生成高质量数据集的潜力。

    This paper presents UMASS_BioNLP team participation in the MEDIQA-Chat 2023 shared task for Task-A and Task-C. We focus especially on Task-C and propose a novel LLMs cooperation system named a doctor-patient loop to generate high-quality conversation data sets. The experiment results demonstrate that our approaches yield reasonable performance as evaluated by automatic metrics such as ROUGE, medical concept recall, BLEU, and Self-BLEU. Furthermore, we conducted a comparative analysis between our proposed method and ChatGPT and GPT-4. This analysis also investigates the potential of utilizing cooperation LLMs to generate high-quality datasets.
    
[^19]: One-2-3-45: 在45秒内将任意单张图像转换为3D网格，无需进行形状优化

    One-2-3-45: Any Single Image to 3D Mesh in 45 Seconds without Per-Shape Optimization. (arXiv:2306.16928v1 [cs.CV])

    [http://arxiv.org/abs/2306.16928](http://arxiv.org/abs/2306.16928)

    本论文提出了一种无需进行形状优化的新方法，可以在45秒内将任意单张图像转换为360度的3D纹理网格。该方法采用了视图条件的2D扩散模型和基于SDF的神经表面重建方法，通过关键的训练策略实现了准确且一致的多视图预测。

    

    单图像3D重建是一项重要但具有挑战性的任务，需要对自然世界有广泛的知识。许多现有方法通过在2D扩散模型的指导下优化神经辐射场来解决这个问题，但存在优化时间长、3D结果不一致和几何质量差的问题。本文提出了一种新的方法，它以任意物体的单张图像作为输入，并在单次前馈传递中生成一个完整的360度3D纹理网格。给定一张图像，我们首先使用一个视图条件的2D扩散模型Zero123为输入视图生成多视图图像，然后将它们提升到3D空间。由于传统重建方法难以处理不一致的多视图预测，我们基于基于SDF的通用神经表面重建方法构建了我们的3D重建模块，并提出了几种关键的训练策略，以实现360度网格的重建。无需耗时的优化过程。

    Single image 3D reconstruction is an important but challenging task that requires extensive knowledge of our natural world. Many existing methods solve this problem by optimizing a neural radiance field under the guidance of 2D diffusion models but suffer from lengthy optimization time, 3D inconsistency results, and poor geometry. In this work, we propose a novel method that takes a single image of any object as input and generates a full 360-degree 3D textured mesh in a single feed-forward pass. Given a single image, we first use a view-conditioned 2D diffusion model, Zero123, to generate multi-view images for the input view, and then aim to lift them up to 3D space. Since traditional reconstruction methods struggle with inconsistent multi-view predictions, we build our 3D reconstruction module upon an SDF-based generalizable neural surface reconstruction method and propose several critical training strategies to enable the reconstruction of 360-degree meshes. Without costly optimizat
    
[^20]: 线束自动驾驶：挑战与前景

    End-to-end Autonomous Driving: Challenges and Frontiers. (arXiv:2306.16927v1 [cs.RO])

    [http://arxiv.org/abs/2306.16927](http://arxiv.org/abs/2306.16927)

    这项研究调查了端到端自动驾驶领域中的关键挑战和未来趋势，包括多模态、可解释性、因果混淆、鲁棒性和世界模型等。通过联合特征优化感知和规划，端到端系统在感知和规划上获得了更好的效果。

    

    自动驾驶领域正在迅速发展，越来越多的方法采用端到端算法框架，利用原始传感器输入生成车辆运动计划，而不是专注于诸如检测和运动预测等单个任务。与模块化流水线相比，端到端系统通过联合特征优化感知和规划来获益。这一领域因大规模数据集的可用性、闭环评估以及自动驾驶算法在挑战性场景中的有效执行所需的需求而蓬勃发展。在本调查中，我们全面分析了250多篇论文，涵盖了端到端自动驾驶的动机、路线图、方法论、挑战和未来趋势。我们深入探讨了多模态、可解释性、因果混淆、鲁棒性和世界模型等几个关键挑战。此外，我们还讨论了基础技术的最新进展。

    The autonomous driving community has witnessed a rapid growth in approaches that embrace an end-to-end algorithm framework, utilizing raw sensor input to generate vehicle motion plans, instead of concentrating on individual tasks such as detection and motion prediction. End-to-end systems, in comparison to modular pipelines, benefit from joint feature optimization for perception and planning. This field has flourished due to the availability of large-scale datasets, closed-loop evaluation, and the increasing need for autonomous driving algorithms to perform effectively in challenging scenarios. In this survey, we provide a comprehensive analysis of more than 250 papers, covering the motivation, roadmap, methodology, challenges, and future trends in end-to-end autonomous driving. We delve into several critical challenges, including multi-modality, interpretability, causal confusion, robustness, and world models, amongst others. Additionally, we discuss current advancements in foundation
    
[^21]: ELM神经元：一种高效且表达力强的皮层神经元模型可以解决长时间跨度任务

    The ELM Neuron: an Efficient and Expressive Cortical Neuron Model Can Solve Long-Horizon Tasks. (arXiv:2306.16922v1 [cs.NE])

    [http://arxiv.org/abs/2306.16922](http://arxiv.org/abs/2306.16922)

    ELM神经元是一种高效且表达力强的皮层神经元模型，它只需要8K个参数就能准确模拟复杂的计算任务。

    

    传统的大规模神经科学模型和机器学习利用简化的个体神经元模型，依靠集体活动和适当调整的连接来执行复杂的计算。然而，每个生物皮层神经元本质上都是一个复杂的计算设备，最近的一项研究证实了这一点，该研究中，需要一个具有数百万个参数的深度人工神经网络来复制详细生物物理模型的输入输出关系。我们对这些多个参数的必要性提出了质疑，并引入了表达力强的泄漏存储器（ELM）神经元，这是一种受生物启发的计算模型，具有高计算表达力，同时也非常高效。值得注意的是，我们的ELM神经元仅需要8,000个可训练参数就能准确匹配前述的输入输出关系。我们发现，准确的模型需要多个类似于存储器的隐藏状态和复杂的非线性突触整合。

    Traditional large-scale neuroscience models and machine learning utilize simplified models of individual neurons, relying on collective activity and properly adjusted connections to perform complex computations. However, each biological cortical neuron is inherently a sophisticated computational device, as corroborated in a recent study where it took a deep artificial neural network with millions of parameters to replicate the input-output relationship of a detailed biophysical model of a cortical pyramidal neuron. We question the necessity for these many parameters and introduce the Expressive Leaky Memory (ELM) neuron, a biologically inspired, computationally expressive, yet efficient model of a cortical neuron. Remarkably, our ELM neuron requires only 8K trainable parameters to match the aforementioned input-output relationship accurately. We find that an accurate model necessitates multiple memory-like hidden states and intricate nonlinear synaptic integration. To assess the comput
    
[^22]: 计算辅助公共卫生数据流的质量控制

    Computationally Assisted Quality Control for Public Health Data Streams. (arXiv:2306.16914v1 [cs.AI])

    [http://arxiv.org/abs/2306.16914](http://arxiv.org/abs/2306.16914)

    开发了一个实用的异常点检测框架FlaSH，用于公共卫生数据流。该框架考虑了数据量和统计特性，并在实验中展现了良好的性能。

    

    公共卫生数据流中的异常情况（如COVID-19病例）阻碍了公共卫生利益相关者基于数据的决策。实时生成的计算机列表可以帮助专家评审员识别成千上万个每日更新的公共卫生数据流中最重要的异常数据点。然而，现有的异常点检测框架在该任务上表现不佳，因为它们没有考虑数据量或公共卫生数据流的统计特性。因此，我们开发了FlaSH（旗标公共卫生数据流），它是一个实用的公共卫生数据用户用的异常点检测框架，使用简单可扩展的模型来明确捕捉这些统计特性。在一个实验中，人类专家评估了FlaSH和现有方法（包括深度学习方法），FlaSH适应了该任务的数据量，与其他方法在平均准确度上达到或超过，并且可以识别出异常数据点。

    Irregularities in public health data streams (like COVID-19 Cases) hamper data-driven decision-making for public health stakeholders. A real-time, computer-generated list of the most important, outlying data points from thousands of daily-updated public health data streams could assist an expert reviewer in identifying these irregularities. However, existing outlier detection frameworks perform poorly on this task because they do not account for the data volume or for the statistical properties of public health streams. Accordingly, we developed FlaSH (Flagging Streams in public Health), a practical outlier detection framework for public health data users that uses simple, scalable models to capture these statistical properties explicitly. In an experiment where human experts evaluate FlaSH and existing methods (including deep learning approaches), FlaSH scales to the data volume of this task, matches or exceeds these other methods in mean accuracy, and identifies the outlier points th
    
[^23]: 严格约束应用中的AutoML

    AutoML in Heavily Constrained Applications. (arXiv:2306.16913v1 [cs.LG])

    [http://arxiv.org/abs/2306.16913](http://arxiv.org/abs/2306.16913)

    本文提出了Caml，一种在严格约束的应用中使用元学习的AutoML方法。Caml能够自动适应特定任务的AutoML参数，并考虑用户定义的约束，生成满足约束且具有高预测性能的流程。

    

    为了优化特定任务的机器学习流程，需要对各种超参数进行仔细配置，通常由AutoML系统支持，该系统优化给定训练数据集的超参数。然而，根据AutoML系统的二阶元配置，AutoML过程的性能可能会有很大差异。目前的AutoML系统无法自动适应特定用例的配置。此外，它们也无法编译用户定义的应用约束，以确保流程及其生成的有效性和效率。在本文中，我们提出了Caml，它使用元学习自动适应其自身的AutoML参数，比如搜索策略、验证策略和搜索空间，以适应特定的任务。Caml的动态AutoML策略考虑用户定义的约束，并获得具有高预测性能的满足约束的流程。

    Optimizing a machine learning pipeline for a task at hand requires careful configuration of various hyperparameters, typically supported by an AutoML system that optimizes the hyperparameters for the given training dataset. Yet, depending on the AutoML system's own second-order meta-configuration, the performance of the AutoML process can vary significantly. Current AutoML systems cannot automatically adapt their own configuration to a specific use case. Further, they cannot compile user-defined application constraints on the effectiveness and efficiency of the pipeline and its generation. In this paper, we propose Caml, which uses meta-learning to automatically adapt its own AutoML parameters, such as the search strategy, the validation strategy, and the search space, for a task at hand. The dynamic AutoML strategy of Caml takes user-defined constraints into account and obtains constraint-satisfying pipelines with high predictive performance.
    
[^24]: 从查询工具到因果架构：利用大型语言模型进行高级因果发现和数据分析

    From Query Tools to Causal Architects: Harnessing Large Language Models for Advanced Causal Discovery from Data. (arXiv:2306.16902v1 [cs.AI])

    [http://arxiv.org/abs/2306.16902](http://arxiv.org/abs/2306.16902)

    本文提出了一个新的框架，将基于知识的大型语言模型（LLM）因果分析与基于数据的因果结构学习相结合，以实现更高级的因果发现和数据分析。通过利用LLM的专业知识，并结合统计分析客观数据，构建了一个新颖且实用的因果结构学习的基准。

    

    大型语言模型（LLMs）在医学、科学和法律等多个重要领域展现出了在概念间进行因果分析的卓越能力。最近对LLM在各种因果发现和推理任务中的表现的研究已经为经典的三阶段因果框架带来了一个新的阶梯。本文通过提出一个将基于知识的LLM因果分析与基于数据的因果结构学习相结合的新框架，推进了目前基于LLM的因果发现的研究。为了使LLM不只是一个查询工具，充分利用其在发现自然和新的因果定律方面的能力，我们将LLM对现有因果机制的宝贵专业知识融入客观数据的统计分析中，构建了一个新颖且实用的因果结构学习的基准。我们引入了一组通用的提示，旨在从给定变量中提取因果图，并评估LLM之前因果性对恢复因果关系的影响。

    Large Language Models (LLMs) exhibit exceptional abilities for causal analysis between concepts in numerous societally impactful domains, including medicine, science, and law. Recent research on LLM performance in various causal discovery and inference tasks has given rise to a new ladder in the classical three-stage framework of causality. In this paper, we advance the current research of LLM-driven causal discovery by proposing a novel framework that combines knowledge-based LLM causal analysis with data-driven causal structure learning. To make LLM more than a query tool and to leverage its power in discovering natural and new laws of causality, we integrate the valuable LLM expertise on existing causal mechanisms into statistical analysis of objective data to build a novel and practical baseline for causal structure learning.  We introduce a universal set of prompts designed to extract causal graphs from given variables and assess the influence of LLM prior causality on recovering 
    
[^25]: PFB-Diff: 渐进特征混合扩散用于文本驱动的图像编辑

    PFB-Diff: Progressive Feature Blending Diffusion for Text-driven Image Editing. (arXiv:2306.16894v1 [cs.CV])

    [http://arxiv.org/abs/2306.16894](http://arxiv.org/abs/2306.16894)

    PFB-Diff 是一个通过渐进特征混合的方法，用于文本驱动的图像编辑。该方法解决了扩散模型在像素级混合中产生的伪影问题，并通过多级特征混合和注意力屏蔽机制确保了编辑图像的语义连贯性和高质量。

    

    扩散模型展示了其合成多样性和高质量图像的卓越能力，引起了人们对将其应用于实际图像编辑的兴趣。然而，现有的基于扩散的局部图像编辑方法常常因为目标图像和扩散潜在变量的像素级混合而产生不期望的伪影，缺乏维持图像一致性所必需的语义。为了解决这些问题，我们提出了PFB-Diff，一种逐步特征混合的方法，用于基于扩散的图像编辑。与以往方法不同，PFB-Diff通过多级特征混合将文本引导生成的内容与目标图像无缝集成在一起。深层特征中编码的丰富语义和从高到低级别的渐进混合方案确保了编辑图像的语义连贯性和高质量。此外，我们在交叉注意力层中引入了一个注意力屏蔽机制，以限制特定词语对编辑图像的影响。

    Diffusion models have showcased their remarkable capability to synthesize diverse and high-quality images, sparking interest in their application for real image editing. However, existing diffusion-based approaches for local image editing often suffer from undesired artifacts due to the pixel-level blending of the noised target images and diffusion latent variables, which lack the necessary semantics for maintaining image consistency. To address these issues, we propose PFB-Diff, a Progressive Feature Blending method for Diffusion-based image editing. Unlike previous methods, PFB-Diff seamlessly integrates text-guided generated content into the target image through multi-level feature blending. The rich semantics encoded in deep features and the progressive blending scheme from high to low levels ensure semantic coherence and high quality in edited images. Additionally, we introduce an attention masking mechanism in the cross-attention layers to confine the impact of specific words to 
    
[^26]: 利用Hugging Face Transformers预测社交网络中的精神健康障碍的力量

    Harnessing the Power of Hugging Face Transformers for Predicting Mental Health Disorders in Social Networks. (arXiv:2306.16891v1 [cs.IR])

    [http://arxiv.org/abs/2306.16891](http://arxiv.org/abs/2306.16891)

    该研究通过使用社交媒体和预训练的语言模型，探索了使用用户生成的数据预测精神障碍症状的方法，并发现新模型的准确度高达97%。这表明社交媒体数据是进行精神健康筛查的一个重要资源，预训练模型能够有效地自动化这一任务。

    

    早期诊断精神障碍并进行干预可以促进预防严重伤害和改善治疗效果。本研究利用社交媒体和预训练的语言模型，探讨用户生成的数据如何用于预测精神障碍症状。我们的研究比较了Hugging Face的四种不同BERT模型和近期文献中用于自动抑郁症诊断的标准机器学习技术。结果显示，新模型的准确率高达97%，超过了以前的方法。通过补充先前的发现，对结果进行分析，我们发现即使是微小的数据量（如用户的个人简介描述）也有预测精神障碍的潜力。我们得出结论，社交媒体数据是进行精神健康筛查的一个极好的来源，并且预训练模型可以有效自动化这一关键任务。

    Early diagnosis of mental disorders and intervention can facilitate the prevention of severe injuries and the improvement of treatment results. Using social media and pre-trained language models, this study explores how user-generated data can be used to predict mental disorder symptoms. Our study compares four different BERT models of Hugging Face with standard machine learning techniques used in automatic depression diagnosis in recent literature. The results show that new models outperform the previous approach with an accuracy rate of up to 97%. Analyzing the results while complementing past findings, we find that even tiny amounts of data (like users' bio descriptions) have the potential to predict mental disorders. We conclude that social media data is an excellent source of mental health screening, and pre-trained models can effectively automate this critical task.
    
[^27]: 迈向自复制图灵机

    Towards a Self-Replicating Turing Machine. (arXiv:2306.16872v1 [cs.FL])

    [http://arxiv.org/abs/2306.16872](http://arxiv.org/abs/2306.16872)

    该论文介绍了一种自复制图灵机的构造方法，通过从简单的构建块开始，并使用最小的假设和相同的原理，提供了von Neumann的通用构造器和通用复制器的部分实现。该构造允许进行变异，并提供了一个简单的描述语言。

    

    我们提供了von Neumann的通用构造器和通用复制器的部分实现，从三种简单的构建块开始，使用最小的假设。使用相同的原理，我们还构建了图灵机。将两者结合起来，我们提出了一个自复制的图灵机的方案。我们的构造允许进行变异，并给出一个简单的描述语言。

    We provide partial implementations of von Neumann's universal constructor and universal copier, starting out with three types of simple building blocks using minimal assumptions. Using the same principles, we also construct Turing machines. Combining both, we arrive at a proposal for a self-replicating Turing machine. Our construction allows for mutations if desired, and we give a simple description language.
    
[^28]: 可持续棕榈树种植：利用物联网和多模态数据进行红棕象早期检测和映射

    Sustainable Palm Tree Farming: Leveraging IoT and Multi-Modal Data for Early Detection and Mapping of Red Palm Weevil. (arXiv:2306.16862v1 [cs.CV])

    [http://arxiv.org/abs/2306.16862](http://arxiv.org/abs/2306.16862)

    本文提出了一种可持续的棕榈树种植方法，利用物联网和多模态数据对红棕象进行早期检测和映射。通过计算机视觉、深度学习、物联网和地理空间数据的综合应用，我们可以有效检测和分类寄生红棕象的棕榈树，并利用地理空间数据创建综合红棕象分布图，为高效监测和有针对性的管理策略提供支持。

    

    红棕象是一种具有破坏性的昆虫，对全球棕榈树种植业造成经济损失。本文提出了一种创新方法，利用先进技术对红棕象的早期检测和管理，实现可持续棕榈树种植。我们的方法结合了计算机视觉、深度学习、物联网和地理空间数据，有效地检测和分类寄生红棕象的棕榈树。主要阶段包括：（1）使用物联网设备的声音数据进行深度学习分类，（2）使用无人机图像中的YOLOv8进行棕榈树检测，（3）使用地理空间数据进行红棕象映射。我们的自定义深度学习模型在检测和定位寄生棕榈树方面达到100%的精确度和召回率。整合地理空间数据可以创建综合红棕象分布图，实现高效监测和有针对性的管理策略。这种技术驱动的方法有益于农业部门、农民和研究人员管理红棕象侵袭。

    The Red Palm Weevil (RPW) is a highly destructive insect causing economic losses and impacting palm tree farming worldwide. This paper proposes an innovative approach for sustainable palm tree farming by utilizing advanced technologies for the early detection and management of RPW. Our approach combines computer vision, deep learning (DL), the Internet of Things (IoT), and geospatial data to detect and classify RPW-infested palm trees effectively. The main phases include; (1) DL classification using sound data from IoT devices, (2) palm tree detection using YOLOv8 on UAV images, and (3) RPW mapping using geospatial data. Our custom DL model achieves 100% precision and recall in detecting and localizing infested palm trees. Integrating geospatial data enables the creation of a comprehensive RPW distribution map for efficient monitoring and targeted management strategies. This technology-driven approach benefits agricultural authorities, farmers, and researchers in managing RPW infestati
    
[^29]: 天文光学望远镜的智能化：现状与未来展望

    Intelligence of Astronomical Optical Telescope: Present Status and Future Perspectives. (arXiv:2306.16834v1 [astro-ph.IM])

    [http://arxiv.org/abs/2306.16834](http://arxiv.org/abs/2306.16834)

    本文综合介绍了人工智能技术在天文学中的应用以及望远镜智能化的发展和研究热点，对各种研究方向进行了统计分析，并指出了各个望远镜智能化的研究趋势。

    

    人工智能技术在天文学中得到了广泛应用，不断涌现出新的人工智能技术和应用场景。目前，有大量的论文回顾了人工智能技术在天文学中的应用，然而很少有相关文章单独提及望远镜的智能化，并且很难从这些论文中了解到望远镜智能化的当前发展状况和研究热点。本文结合人工智能技术的发展历史和望远镜关键技术的困难，全面介绍了望远镜智能化的发展和研究热点，然后对望远镜智能化的各种研究方向进行了统计分析，并定义了各个研究方向的优点。评估了各种研究方向，并指出了每个望远镜智能化的研究趋势。

    Artificial intelligence technology has been widely used in astronomy, and new artificial intelligence technologies and application scenarios are constantly emerging. There have been a large number of papers reviewing the application of artificial intelligence technology in astronomy. However, relevant articles seldom mention telescope intelligence separately, and it is difficult to understand the current development status and research hotspots of telescope intelligence from these papers. This paper combines the development history of artificial intelligence technology and the difficulties of critical technologies of telescopes, comprehensively introduces the development and research hotspots of telescope intelligence, then conducts statistical analysis on various research directions of telescope intelligence and defines the research directions' merits. All kinds of research directions are evaluated, and the research trend of each telescope's intelligence is pointed out. Finally, accor
    
[^30]: 逆向蛋白质折叠的图去噪扩散

    Graph Denoising Diffusion for Inverse Protein Folding. (arXiv:2306.16819v1 [q-bio.QM])

    [http://arxiv.org/abs/2306.16819](http://arxiv.org/abs/2306.16819)

    我们提出了一种逆向蛋白质折叠的图去噪扩散模型，通过扩散过程生成了一组多样的候选序列，该模型能够很好地概括多样的可行解决方案。

    

    逆向蛋白质折叠具有一对多的映射特性，这使得它具有挑战性，因为许多可能的氨基酸序列可以折叠成一个相同的蛋白质骨架。这个任务不仅涉及到识别可行的序列，还要表示潜在解决方案的多样性。然而，现有的鉴别模型，如基于Transformer的自回归模型，很难概括各种可行解的多样性。相反，作为一种新兴的生成方法，扩散概率模型提供了生成一组多样序列候选的潜力，用于确定蛋白质骨架。我们提出了一种新颖的逆向蛋白质折叠的图去噪扩散模型，其中给定的蛋白质骨架指导对应氨基酸残基类型的扩散过程。该模型推断了以节点的物理化学属性和局部环境为条件的氨基酸的联合分布。

    Inverse protein folding is challenging due to its inherent one-to-many mapping characteristic, where numerous possible amino acid sequences can fold into a single, identical protein backbone. This task involves not only identifying viable sequences but also representing the sheer diversity of potential solutions. However, existing discriminative models, such as transformer-based auto-regressive models, struggle to encapsulate the diverse range of plausible solutions. In contrast, diffusion probabilistic models, as an emerging genre of generative approaches, offer the potential to generate a diverse set of sequence candidates for determined protein backbones. We propose a novel graph denoising diffusion model for inverse protein folding, where a given protein backbone guides the diffusion process on the corresponding amino acid residue types. The model infers the joint distribution of amino acids conditioned on the nodes' physiochemical properties and local environment. Moreover, we uti
    
[^31]: 使用时间集成改进在线连续学习性能和稳定性

    Improving Online Continual Learning Performance and Stability with Temporal Ensembles. (arXiv:2306.16817v1 [cs.LG])

    [http://arxiv.org/abs/2306.16817](http://arxiv.org/abs/2306.16817)

    该研究通过模型集成方法改进了在线连续学习的性能和稳定性，通过综合利用来自不同训练任务的模型，显著提高了在线连续学习的表现。

    

    当神经网络在大型数据集上进行大量迭代训练时，它们非常有效。然而，当它们在非平稳的数据流和在线方式下进行训练时，其性能会下降：(1)在线设置限制了数据的可用性，(2)由于数据的非平稳性导致灾难性遗忘。此外，几篇最近的文章表明连续学习中使用的重放方法在模型持续评估时存在稳定性差距。在本文中，我们研究了模型集成作为改进在线连续学习性能和稳定性的一种方法。我们观察到，简单地集成来自各种训练任务的模型显著提高了在线连续学习的性能。基于这一观察，并从半监督学习中获取灵感，我们提出了一种改进的连续学习框架，该框架综合利用了显式和隐式知识。

    Neural networks are very effective when trained on large datasets for a large number of iterations. However, when they are trained on non-stationary streams of data and in an online fashion, their performance is reduced (1) by the online setup, which limits the availability of data, (2) due to catastrophic forgetting because of the non-stationary nature of the data. Furthermore, several recent works (Caccia et al., 2022; Lange et al., 2023) arXiv:2205.1345(2) showed that replay methods used in continual learning suffer from the stability gap, encountered when evaluating the model continually (rather than only on task boundaries). In this article, we study the effect of model ensembling as a way to improve performance and stability in online continual learning. We notice that naively ensembling models coming from a variety of training tasks increases the performance in online continual learning considerably. Starting from this observation, and drawing inspirations from semi-supervised l
    
[^32]: LeanAI: 一种有效规划AI实施的AEC从业者方法

    LeanAI: A method for AEC practitioners to effectively plan AI implementations. (arXiv:2306.16799v1 [cs.HC])

    [http://arxiv.org/abs/2306.16799](http://arxiv.org/abs/2306.16799)

    LeanAI是一种让AEC从业者有效规划AI实施的方法，解决了由于缺乏对AI能力和限制的理解而导致的规划与实施之间的脱节问题。

    

    最近人工智能(AI)的发展为建筑、工程和施工(AEC)行业提供了前所未有的自动化机会。然而，尽管人们对使用AI充满热情，但目前85%的大数据项目失败。AEC行业AI项目失败的主要原因之一是规划或决定使用AI的人与实施者之间的脱节。AEC从业者经常缺乏对AI的能力和限制的清晰理解，导致无法区分AI应该解决什么问题、能解决什么问题以及将解决什么问题，将这些类别视为互相可替代的。这种理解上的缺乏导致AI规划与实施之间的脱节，因为规划基于AI应该解决的愿景，而不考虑它是否能够或将会解决。为了解决这一挑战，本研究介绍了LeanAI方法。该方法使用AEC行业的数据进行了开发。

    Recent developments in Artificial Intelligence (AI) provide unprecedented automation opportunities in the Architecture, Engineering, and Construction (AEC) industry. However, despite the enthusiasm regarding the use of AI, 85% of current big data projects fail. One of the main reasons for AI project failures in the AEC industry is the disconnect between those who plan or decide to use AI and those who implement it. AEC practitioners often lack a clear understanding of the capabilities and limitations of AI, leading to a failure to distinguish between what AI should solve, what it can solve, and what it will solve, treating these categories as if they are interchangeable. This lack of understanding results in the disconnect between AI planning and implementation because the planning is based on a vision of what AI should solve without considering if it can or will solve it. To address this challenge, this work introduces the LeanAI method. The method has been developed using data from s
    
[^33]: 评估环境条件对使用定向边界框进行AR应用的物体检测的影响

    Evaluation of Environmental Conditions on Object Detection using Oriented Bounding Boxes for AR Applications. (arXiv:2306.16798v1 [cs.CV])

    [http://arxiv.org/abs/2306.16798](http://arxiv.org/abs/2306.16798)

    本研究提出了一种使用定向边界框和深度网络进行物体检测的新方法，通过在不同环境条件下对两个数据集的评估发现，该方法在处理小物体时能够提高性能和准确性。

    

    增强现实（AR）的目标是将数字内容添加到自然图像和视频中，以创建用户与环境之间的交互体验。场景分析和物体识别在AR中起着至关重要的作用，因为它们必须快速且准确地执行。本研究提出了一种新的方法，利用定向边界框与检测和识别深度网络相结合，以提高性能和处理时间。该方法使用两个数据集进行评估：一个常用于计算机视觉任务的真实图像数据集（DOTA数据集）和一个模拟不同环境、照明和采集条件的合成数据集。评估的重点是小物体，这些物体往往难以检测和识别。结果表明，所提出的方法在大多数测试条件下，对于小物体往往能产生更好的平均精度和更高的准确性。

    The objective of augmented reality (AR) is to add digital content to natural images and videos to create an interactive experience between the user and the environment. Scene analysis and object recognition play a crucial role in AR, as they must be performed quickly and accurately. In this study, a new approach is proposed that involves using oriented bounding boxes with a detection and recognition deep network to improve performance and processing time. The approach is evaluated using two datasets: a real image dataset (DOTA dataset) commonly used for computer vision tasks, and a synthetic dataset that simulates different environmental, lighting, and acquisition conditions. The focus of the evaluation is on small objects, which are difficult to detect and recognise. The results indicate that the proposed approach tends to produce better Average Precision and greater accuracy for small objects in most of the tested conditions.
    
[^34]: 稀疏模型汤：通过模型平均改进修剪的方法

    Sparse Model Soups: A Recipe for Improved Pruning via Model Averaging. (arXiv:2306.16788v1 [cs.LG])

    [http://arxiv.org/abs/2306.16788](http://arxiv.org/abs/2306.16788)

    本研究通过将多个经过迭代幅度剪枝的模型进行平均，解决了同时利用稀疏性和参数平均的问题，并显著提升了泛化性能。

    

    神经网络可以通过剪枝显著压缩，从而得到稀疏模型，这些模型需要更少的存储和浮点运算，同时保持预测性能。模型汤（Wortsman等人，2022年）通过将多个模型的参数平均成一个单一模型来改善泛化和超出分布性能，而不增加推理时间。然而，识别处于相同损失区域的模型以同时利用稀疏性和参数平均是具有挑战性的，因为对任意稀疏模型进行平均会降低整体稀疏度，原因是不同的稀疏连接性。在这项工作中，我们通过展示在迭代幅度剪枝（IMP）的单次重新训练阶段中探索不同的超参数配置（例如批次排序或权重衰减）产生的模型适合进行平均，并且通过设计共享相同的稀疏连接性来解决这些挑战。平均这些模型显著提升了泛化性能。

    Neural networks can be significantly compressed by pruning, leading to sparse models requiring considerably less storage and floating-point operations while maintaining predictive performance. Model soups (Wortsman et al., 2022) improve generalization and out-of-distribution performance by averaging the parameters of multiple models into a single one without increased inference time. However, identifying models in the same loss basin to leverage both sparsity and parameter averaging is challenging, as averaging arbitrary sparse models reduces the overall sparsity due to differing sparse connectivities. In this work, we address these challenges by demonstrating that exploring a single retraining phase of Iterative Magnitude Pruning (IMP) with varying hyperparameter configurations, such as batch ordering or weight decay, produces models that are suitable for averaging and share the same sparse connectivity by design. Averaging these models significantly enhances generalization performanc
    
[^35]: 自动驾驶决策数据集综述

    A Survey on Datasets for Decision-making of Autonomous Vehicle. (arXiv:2306.16784v1 [cs.RO])

    [http://arxiv.org/abs/2306.16784](http://arxiv.org/abs/2306.16784)

    本综述调查了自动驾驶决策的数据集，比较了车辆、环境和驾驶员相关的数据集，并总结了它们的特点。这有助于研究人员找到适合的数据集来开发数据驱动的自动驾驶决策方法。

    

    自动驾驶车辆（AV）有望重塑未来的交通系统，而决策是实现高级自动驾驶的关键模块之一。为了克服那些基于规则的方法无法很好处理的复杂场景，数据驱动的决策方法引起了越来越多的关注。用于开发数据驱动方法的数据集极大地影响决策性能，因此有必要全面了解现有数据集。从采集来源的角度来看，驾驶数据可以分为车辆、环境和驾驶员相关的数据。本研究比较了这三类最先进的数据集，并总结了它们的特点，包括使用的传感器、注释和驾驶场景。基于数据集的特点，本综述还总结了数据集在AV决策各个方面的潜在应用，帮助研究者找到最适合的数据集。

    Autonomous vehicles (AV) are expected to reshape future transportation systems, and decision-making is one of the critical modules toward high-level automated driving. To overcome those complicated scenarios that rule-based methods could not cope with well, data-driven decision-making approaches have aroused more and more focus. The datasets to be used in developing data-driven methods dramatically influences the performance of decision-making, hence it is necessary to have a comprehensive insight into the existing datasets. From the aspects of collection sources, driving data can be divided into vehicle, environment, and driver related data. This study compares the state-of-the-art datasets of these three categories and summarizes their features including sensors used, annotation, and driving scenarios. Based on the characteristics of the datasets, this survey also concludes the potential applications of datasets on various aspects of AV decision-making, assisting researchers to find 
    
[^36]: 从合成的人类团队活动中学习

    Learning from Synthetic Human Group Activities. (arXiv:2306.16772v1 [cs.CV])

    [http://arxiv.org/abs/2306.16772](http://arxiv.org/abs/2306.16772)

    提出了M3Act，一个多视图多团队多人的人类原子动作和团队活动数据生成器，通过Unity引擎驱动实现。该生成器具有大规模数据生成、多模态和高质量注释等特点，能够用于研究复杂的人类互动和团队活动。

    

    在以人为中心的计算机视觉中，对复杂的人类互动和团队活动的理解引起了人们的关注。然而，相关任务的进展受到了获取大规模标记的真实世界数据集的困难的限制。为了缓解这个问题，我们提出了M3Act，一个多视图多团队多人的人类原子动作和团队活动数据生成器。M3Act采用Unity引擎驱动，包含可供仿真使用的三维场景和人物资源，可配置的照明和摄像系统，高度参数化的模块化团队活动，以及在数据生成过程中具有大量领域随机化的特点。我们的数据生成器能够生成具有多个视图、模态（RGB图像、2D姿势、3D动作）和高质量注释的大规模人类活动数据集（2D边界框、实例分割掩模、个体动作和团队活动类别）。利用M3Act，我们可以生成大规模的人类活动数据集，用于研究人类互动和团队活动。

    The understanding of complex human interactions and group activities has garnered attention in human-centric computer vision. However, the advancement of the related tasks is hindered due to the difficulty of obtaining large-scale labeled real-world datasets. To mitigate the issue, we propose M3Act, a multi-view multi-group multi-person human atomic action and group activity data generator. Powered by the Unity engine, M3Act contains simulation-ready 3D scenes and human assets, configurable lighting and camera systems, highly parameterized modular group activities, and a large degree of domain randomization during the data generation process. Our data generator is capable of generating large-scale datasets of human activities with multiple viewpoints, modalities (RGB images, 2D poses, 3D motions), and high-quality annotations for individual persons and multi-person groups (2D bounding boxes, instance segmentation masks, individual actions and group activity categories). Using M3Act, we
    
[^37]: DialoGPS: 在连续语义空间中对话路径采样用于多轮对话的数据增强

    DialoGPS: Dialogue Path Sampling in Continuous Semantic Space for Data Augmentation in Multi-Turn Conversations. (arXiv:2306.16770v1 [cs.CL])

    [http://arxiv.org/abs/2306.16770](http://arxiv.org/abs/2306.16770)

    DialoGPS是第一个在连续语义空间中进行对话路径采样的多对多增强方法，用于多轮对话的数据增强任务。

    

    在开放领域对话生成任务中，大多数数据集中的上下文和回复是一对一的映射，违反了重要的多对多特性：上下文有多种回复，回复回答多个上下文。缺乏这样的模式，模型很难泛化并倾向于安全回复。已经有许多尝试以一对多的角度处理多轮对话或以多对多的角度处理单轮对话，但对于多对多的多轮对话的增强仍然存在挑战。在本文中，我们提出了DialoGPS方法，它是第一个用于多轮对话的多对多增强方法。具体而言，我们将对话映射到我们的扩展布朗桥（Brownian Bridge），一个特殊的高斯过程。我们采样潜变量以形成连续空间中的连贯对话路径。

    In open-domain dialogue generation tasks, contexts and responses in most datasets are one-to-one mapped, violating an important many-to-many characteristic: a context leads to various responses, and a response answers multiple contexts. Without such patterns, models poorly generalize and prefer responding safely. Many attempts have been made in either multi-turn settings from a one-to-many perspective or in a many-to-many perspective but limited to single-turn settings. The major challenge to many-to-many augment multi-turn dialogues is that discretely replacing each turn with semantic similarity breaks fragile context coherence. In this paper, we propose DialoGue Path Sampling (DialoGPS) method in continuous semantic space, the first many-to-many augmentation method for multi-turn dialogues. Specifically, we map a dialogue to our extended Brownian Bridge, a special Gaussian process. We sample latent variables to form coherent dialogue paths in the continuous space. A dialogue path cor
    
[^38]: 时间差分动力学的特征子空间及其如何在强化学习中改进值估计

    Eigensubspace of Temporal-Difference Dynamics and How It Improves Value Approximation in Reinforcement Learning. (arXiv:2306.16750v1 [cs.LG])

    [http://arxiv.org/abs/2306.16750](http://arxiv.org/abs/2306.16750)

    ERC是一种新的值估计方法，通过在深度强化学习中利用时间差分动力学的特征子空间，实现了更高效和稳定的值估计路径。实验证明ERC有效地减少了值函数的方差，并在多项任务中优于其他最先进方法。

    

    我们提出了一种新的值估计方法，即特征子空间规范化批评家（ERC），用于深度强化学习（RL）。 ERC受到了对时序差分（TD）方法中Q值估计误差动力学的分析的启发，该方法遵循由与马尔可夫决策过程（MDP）相关的转移核关联的1-特征子空间定义的路径。它揭示了TD学习的一个基本性质，在先前的深度RL方法中未被使用。在ERC中，我们提出了一个正则化器，指导近似误差趋向于1-特征子空间，从而得到更高效稳定的值估计路径。此外，我们在理论上证明了ERC方法的收敛性。此外，理论分析和实验证明ERC有效地减少了值函数的方差。在DMControl基准测试的26个任务中，ERC优于20个最先进方法。此外，在Q值估计方面也显示出明显的优势。

    We propose a novel value approximation method, namely Eigensubspace Regularized Critic (ERC) for deep reinforcement learning (RL). ERC is motivated by an analysis of the dynamics of Q-value approximation error in the Temporal-Difference (TD) method, which follows a path defined by the 1-eigensubspace of the transition kernel associated with the Markov Decision Process (MDP). It reveals a fundamental property of TD learning that has remained unused in previous deep RL approaches. In ERC, we propose a regularizer that guides the approximation error tending towards the 1-eigensubspace, resulting in a more efficient and stable path of value approximation. Moreover, we theoretically prove the convergence of the ERC method. Besides, theoretical analysis and experiments demonstrate that ERC effectively reduces the variance of value functions. Among 26 tasks in the DMControl benchmark, ERC outperforms state-of-the-art methods for 20. Besides, it shows significant advantages in Q-value approxim
    
[^39]: 评估社交机器人导航算法的原则与指南

    Principles and Guidelines for Evaluating Social Robot Navigation Algorithms. (arXiv:2306.16740v1 [cs.RO])

    [http://arxiv.org/abs/2306.16740](http://arxiv.org/abs/2306.16740)

    本文提出了评估社交机器人导航算法的原则与指南，为解决在人类居住环境中导航的挑战提供了可重复和可比较的基准标准。

    

    在人类居住环境中导航是部署机器人广泛应用的主要挑战，通常被称为社交机器人导航。虽然社交导航领域近年来取得了很大进展，但评估解决社交导航的算法仍然困难，因为它不仅涉及机器人在静态环境中移动，还涉及到动态的人类参与者及其对机器人行为的感知适应性。相比之下，清晰、可重复、易于获得的基准在计算机视觉、自然语言处理和传统机器人导航等领域加速了进展，使研究人员能够公平比较算法，揭示现有解决方案的局限性，并呈现有前途的新方向。我们相信相同的方法可以有助于社交导航。在本文中，我们为评估社交机器人导航建立了共同、广泛可用且可重复的基准标准，并提出了自己的创新点。

    A major challenge to deploying robots widely is navigation in human-populated environments, commonly referred to as social robot navigation. While the field of social navigation has advanced tremendously in recent years, the fair evaluation of algorithms that tackle social navigation remains hard because it involves not just robotic agents moving in static environments but also dynamic human agents and their perceptions of the appropriateness of robot behavior. In contrast, clear, repeatable, and accessible benchmarks have accelerated progress in fields like computer vision, natural language processing and traditional robot navigation by enabling researchers to fairly compare algorithms, revealing limitations of existing solutions and illuminating promising new directions. We believe the same approach can benefit social navigation. In this paper, we pave the road towards common, widely accessible, and repeatable benchmarking criteria to evaluate social robot navigation. Our contributio
    
[^40]: GraMMaR: 用于3D人体运动重建的地面感知运动模型

    GraMMaR: Ground-aware Motion Model for 3D Human Motion Reconstruction. (arXiv:2306.16736v1 [cs.CV])

    [http://arxiv.org/abs/2306.16736](http://arxiv.org/abs/2306.16736)

    提出了一种用于3D人体运动重建的地面感知运动模型（GraMMaR），通过学习姿势和关节与地面之间的互动的过渡分布，明确促进运动和与地面距离变化之间的一致性。

    

    对于准确和真实的从RGB视频中重建3D人体运动，解密复杂的人地互动对于保证人类和地面之间的一致性至关重要。以往的方法要么隐式地模拟人地互动，要么以稀疏的方式模拟，往往在面对噪声和不确定性时导致不真实和不正确的运动。相反，我们的方法以一种密集和连续的方式明确表示这些互动。为此，我们提出了一种新颖的用于3D人体运动重建的地面感知运动模型，称为GraMMaR，它在运动序列中每个时间步骤中同时学习姿势和每个关节与地面之间的互动的过渡分布。它被训练用于明确促进运动和与地面距离变化之间的一致性。训练后，我们建立了一种联合优化策略，利用GraMMaR作为双重先验，规范优化过程朝着

    Demystifying complex human-ground interactions is essential for accurate and realistic 3D human motion reconstruction from RGB videos, as it ensures consistency between the humans and the ground plane. Prior methods have modeled human-ground interactions either implicitly or in a sparse manner, often resulting in unrealistic and incorrect motions when faced with noise and uncertainty. In contrast, our approach explicitly represents these interactions in a dense and continuous manner. To this end, we propose a novel Ground-aware Motion Model for 3D Human Motion Reconstruction, named GraMMaR, which jointly learns the distribution of transitions in both pose and interaction between every joint and ground plane at each time step of a motion sequence. It is trained to explicitly promote consistency between the motion and distance change towards the ground. After training, we establish a joint optimization strategy that utilizes GraMMaR as a dual-prior, regularizing the optimization towards 
    
[^41]: 多情景排序与自适应特征学习

    Multi-Scenario Ranking with Adaptive Feature Learning. (arXiv:2306.16732v1 [cs.IR])

    [http://arxiv.org/abs/2306.16732](http://arxiv.org/abs/2306.16732)

    多情景学习在推荐和检索系统中被广泛应用于行业中。本文提出了一种自适应特征学习方法，通过优化特征表示来提高排序性能，减少了对网络结构的搜索和维护成本。

    

    最近，多情景学习（MSL）在推荐和检索系统中被广泛应用于行业中，因为它有助于从不同情景中进行迁移学习，减轻了数据稀疏性并降低了维护成本。这些努力通过搜索更优网络结构（如辅助网络、专家网络和多塔网络）产生不同的MSL范式。不同的情景可以持有特定的特征，因此激活用户的意图会有所不同。换句话说，在不同的情景下，不同类型的辅助特征的重要性也会有所不同。通过以情景感知的方式优化更具有区分性的特征表示，可以轻松地获得更好的排序性能，而无需昂贵地搜索最优网络结构。不幸的是，这个简单的想法在实际系统中主要被忽视，但却是非常需要的。进一步的分析也验证了自适应特征学习的合理性。

    Recently, Multi-Scenario Learning (MSL) is widely used in recommendation and retrieval systems in the industry because it facilitates transfer learning from different scenarios, mitigating data sparsity and reducing maintenance cost. These efforts produce different MSL paradigms by searching more optimal network structure, such as Auxiliary Network, Expert Network, and Multi-Tower Network. It is intuitive that different scenarios could hold their specific characteristics, activating the user's intents quite differently. In other words, different kinds of auxiliary features would bear varying importance under different scenarios. With more discriminative feature representations refined in a scenario-aware manner, better ranking performance could be easily obtained without expensive search for the optimal network structure. Unfortunately, this simple idea is mainly overlooked but much desired in real-world systems.Further analysis also validates the rationality of adaptive feature learni
    
[^42]: 评估文本蕴涵模型对改写句的鲁棒性

    Evaluating Paraphrastic Robustness in Textual Entailment Models. (arXiv:2306.16722v1 [cs.CL])

    [http://arxiv.org/abs/2306.16722](http://arxiv.org/abs/2306.16722)

    本文介绍了PaRTE，一个包含1,126对文本蕴涵示例的集合，用于评估模型对改写句的鲁棒性。实验结果表明，现代模型在8-16％的改写示例上改变了他们的预测，说明仍有改进的空间。

    

    我们提出了PaRTE，一个包含1,126对文本蕴涵（RTE）示例的集合，用于评估模型对改写句的鲁棒性。我们认为，如果RTE模型能够理解语言，它们的预测应该在具有相同含义的输入上保持一致。我们使用评估集来确定当示例被改写时，RTE模型的预测是否发生变化。在我们的实验中，现代模型在8-16％的改写示例上改变了他们的预测，这说明仍有改进的空间。

    We present PaRTE, a collection of 1,126 pairs of Recognizing Textual Entailment (RTE) examples to evaluate whether models are robust to paraphrasing. We posit that if RTE models understand language, their predictions should be consistent across inputs that share the same meaning. We use the evaluation set to determine if RTE models' predictions change when examples are paraphrased. In our experiments, contemporary models change their predictions on 8-16\% of paraphrased examples, indicating that there is still room for improvement.
    
[^43]: 来自图像池的答案挖掘：面向基于检索的视觉问答

    Answer Mining from a Pool of Images: Towards Retrieval-Based Visual Question Answering. (arXiv:2306.16713v1 [cs.CV])

    [http://arxiv.org/abs/2306.16713](http://arxiv.org/abs/2306.16713)

    本研究探究了在给定上下文中从相关和无关图像池中挖掘答案的视觉问答问题。我们提出了一个统一的模型，Multi Image BART (MI-BART)，通过检索相关图像并使用相关性编码器进行自由流畅的答案生成。同时，我们还引入了最大的RETVQA数据集，该数据集具有多图像和检索要求，并且可以对一组异构图像进行元数据无关的问题提问。

    

    我们研究在一个给定上下文的相关和无关图像池中挖掘答案的视觉问答问题。在这样的设置中，模型必须首先从图像池中检索相关图像，并从这些检索到的图像中回答问题。我们将这个问题称为基于检索的视觉问答（或简称为RETVQA）。RETVQA与传统研究的视觉问答（VQA）有着明显不同和更大的挑战，传统的VQA要求根据上下文中的单个相关图像回答给定的问题。为了解决RETVQA任务，我们提出了一个统一的Multi Image BART（MI-BART）模型，该模型使用我们的相关性编码器来生成自由流畅的答案。此外，我们还引入了这个领域最大的数据集，即RETVQA，具有以下显著特点：VQA的多图像和检索要求，对一组异构图像进行元数据无关的问题提问。

    We study visual question answering in a setting where the answer has to be mined from a pool of relevant and irrelevant images given as a context. For such a setting, a model must first retrieve relevant images from the pool and answer the question from these retrieved images. We refer to this problem as retrieval-based visual question answering (or RETVQA in short). The RETVQA is distinctively different and more challenging than the traditionally-studied Visual Question Answering (VQA), where a given question has to be answered with a single relevant image in context. Towards solving the RETVQA task, we propose a unified Multi Image BART (MI-BART) that takes a question and retrieved images using our relevance encoder for free-form fluent answer generation. Further, we introduce the largest dataset in this space, namely RETVQA, which has the following salient features: multi-image and retrieval requirement for VQA, metadata-independent questions over a pool of heterogeneous images, exp
    
[^44]: NNQS-Transformer: 一种高效可扩展的神经网络量子态方法用于从头计算量子化学

    NNQS-Transformer: an Efficient and Scalable Neural Network Quantum States Approach for Ab initio Quantum Chemistry. (arXiv:2306.16705v1 [quant-ph])

    [http://arxiv.org/abs/2306.16705](http://arxiv.org/abs/2306.16705)

    NNQS-Transformer是一种高效可扩展的神经网络量子态方法，用于从头计算量子化学。其主要创新包括基于Transformer的量子波函数安萨茨、数据中心并行化方案、并行批量采样策略和并行局域能量评估方案。研究结果显示了与最先进方法相比的优越精度和对于大分子系统的强可扩展性和弱可扩展性。

    

    神经网络量子态（NNQS）已成为量子多体问题的有希望的候选方法，但其实际应用常受到采样和局域能量计算的高成本的限制。我们开发了一种高性能的NNQS方法，用于从头电子结构计算。主要创新包括：（1）将Transformer作为量子波函数的安萨茨；（2）一种以数据为中心的并行化方案，用于变分蒙特卡洛（VMC）算法，可以保持数据的局部性并适应不同的计算架构；（3）一种并行批量采样策略，降低采样成本并实现良好的负载平衡；（4）一种既具有内存又具有计算效率的并行局域能量评估方案；（5）对真实化学系统的研究表明，我们的方法相比最先进方法具有更高的精度，并且对于具有高达120个自旋的大分子系统具有很强的可扩展性和弱可扩展性。

    Neural network quantum state (NNQS) has emerged as a promising candidate for quantum many-body problems, but its practical applications are often hindered by the high cost of sampling and local energy calculation. We develop a high-performance NNQS method for \textit{ab initio} electronic structure calculations. The major innovations include: (1) A transformer based architecture as the quantum wave function ansatz; (2) A data-centric parallelization scheme for the variational Monte Carlo (VMC) algorithm which preserves data locality and well adapts for different computing architectures; (3) A parallel batch sampling strategy which reduces the sampling cost and achieves good load balance; (4) A parallel local energy evaluation scheme which is both memory and computationally efficient; (5) Study of real chemical systems demonstrates both the superior accuracy of our method compared to state-of-the-art and the strong and weak scalability for large molecular systems with up to $120$ spin o
    
[^45]: 弹性约束下的元学习器用于联邦学习

    Elastically-Constrained Meta-Learner for Federated Learning. (arXiv:2306.16703v1 [cs.LG])

    [http://arxiv.org/abs/2306.16703](http://arxiv.org/abs/2306.16703)

    这项研究提出了一种弹性约束的元学习方法，用于解决联邦学习中由于非独立同分布数据导致元学习的不稳定目标的收敛问题。

    

    联邦学习是一种协作训练机器学习模型的方法，用于多个参与方之间禁止数据共享。在联邦学习中的一个挑战是客户端之间的非独立同分布数据，因为单个模型无法适应所有客户端的数据分布。为了解决这个问题，介绍了元学习（如Per-FedAvg）。元学习学习适用于所有客户端的共享初始参数。每个客户端使用梯度下降法将初始化快速调整到本地数据分布，实现模型个性化。然而，由于非凸损失函数和采样更新的随机性，元学习方法在本地适应同一客户端时具有不稳定的目标。这种不同适应方向的波动阻碍了元学习的收敛。为了克服这个挑战，我们使用了历史本地调整的模型来限制内循环的方向，并提出了一种弹性约束方法。

    Federated learning is an approach to collaboratively training machine learning models for multiple parties that prohibit data sharing. One of the challenges in federated learning is non-IID data between clients, as a single model can not fit the data distribution for all clients. Meta-learning, such as Per-FedAvg, is introduced to cope with the challenge. Meta-learning learns shared initial parameters for all clients. Each client employs gradient descent to adapt the initialization to local data distributions quickly to realize model personalization. However, due to non-convex loss function and randomness of sampling update, meta-learning approaches have unstable goals in local adaptation for the same client. This fluctuation in different adaptation directions hinders the convergence in meta-learning. To overcome this challenge, we use the historical local adapted model to restrict the direction of the inner loop and propose an elastic-constrained method. As a result, the current round
    
[^46]: 快速-INR: 使用隐式神经表示进行效率高的无CPU深度神经网络训练

    Rapid-INR: Storage Efficient CPU-free DNN Training Using Implicit Neural Representation. (arXiv:2306.16699v1 [cs.CV])

    [http://arxiv.org/abs/2306.16699](http://arxiv.org/abs/2306.16699)

    本文提出了一种使用隐式神经表示进行高效的无CPU深度神经网络训练的新方法，通过在GPU上直接存储整个数据集以INR格式，减少了数据传输开销，从而加速训练过程。同时，采用高度并行化和实时执行的解码过程，进一步提升了压缩效果。

    

    隐式神经表示(INR)是一种创新方法，用于表示复杂的形状或对象，而无需明确定义它们的几何形状或表面结构。相反，INR将对象表示为连续函数。先前的研究已经证明了将神经网络用作INR进行图像压缩的有效性，展示了与传统方法（如JPEG）相当的性能。然而，INR在图像压缩之外还具有各种应用潜力。本文介绍了Rapid-INR，一种利用INR对图像进行编码和压缩的新方法，从而加速计算机视觉任务中的神经网络训练。我们的方法在GPU上直接以INR格式存储整个数据集，减少了训练过程中CPU和GPU之间的数据传输开销。此外，从INR到RGB格式的解码过程高度并行化并实时执行。为了进一步提高压缩效果，我们提出了一种迭代的图像压缩算法。

    Implicit Neural Representation (INR) is an innovative approach for representing complex shapes or objects without explicitly defining their geometry or surface structure. Instead, INR represents objects as continuous functions. Previous research has demonstrated the effectiveness of using neural networks as INR for image compression, showcasing comparable performance to traditional methods such as JPEG. However, INR holds potential for various applications beyond image compression. This paper introduces Rapid-INR, a novel approach that utilizes INR for encoding and compressing images, thereby accelerating neural network training in computer vision tasks. Our methodology involves storing the whole dataset directly in INR format on a GPU, mitigating the significant data communication overhead between the CPU and GPU during training. Additionally, the decoding process from INR to RGB format is highly parallelized and executed on-the-fly. To further enhance compression, we propose iterativ
    
[^47]: 神经极化器：一种轻量且有效的通过净化恶意特征防御后门攻击的方法

    Neural Polarizer: A Lightweight and Effective Backdoor Defense via Purifying Poisoned Features. (arXiv:2306.16697v1 [cs.AI])

    [http://arxiv.org/abs/2306.16697](http://arxiv.org/abs/2306.16697)

    神经极化器是一种轻量且有效的后门攻击防御方法，通过插入一个可学习的神经极化器来净化被污染的样本，过滤恶意信息并保留良性信息。

    

    最近的研究表明，深度神经网络容易受到后门攻击。给定一个后门模型，在具有触发器的恶意样本的预测中，触发器信息会主导，尽管触发器信息和良性信息并存。受到光学偏振器的工作机制的启发，光学偏振器可以通过滤波特定偏振的光波，来提出了一种新颖的后门防御方法，在后门模型中插入一个可学习的神经极化器作为中间层，以便通过过滤触发器信息来净化被污染的样本，同时保留良性信息。神经极化器被实例化为一个轻量级线性变换层，通过解决一个精心设计的双层优化问题，并基于有限的清洁数据集进行学习。与其他基于微调的防御方法相比，这种方法仅仅调整后门模型的部分参数。

    Recent studies have demonstrated the susceptibility of deep neural networks to backdoor attacks. Given a backdoored model, its prediction of a poisoned sample with trigger will be dominated by the trigger information, though trigger information and benign information coexist. Inspired by the mechanism of the optical polarizer that a polarizer could pass light waves with particular polarizations while filtering light waves with other polarizations, we propose a novel backdoor defense method by inserting a learnable neural polarizer into the backdoored model as an intermediate layer, in order to purify the poisoned sample via filtering trigger information while maintaining benign information. The neural polarizer is instantiated as one lightweight linear transformation layer, which is learned through solving a well designed bi-level optimization problem, based on a limited clean dataset. Compared to other fine-tuning-based defense methods which often adjust all parameters of the backdoor
    
[^48]: SRL: 将分布式强化学习扩展到一万多个核心

    SRL: Scaling Distributed Reinforcement Learning to Over Ten Thousand Cores. (arXiv:2306.16688v1 [cs.DC])

    [http://arxiv.org/abs/2306.16688](http://arxiv.org/abs/2306.16688)

    SRL是一个可扩展，高效，可扩展的分布式强化学习系统，通过一种新的抽象框架统一了各种实际强化学习训练，并实现了精细优化。

    

    强化学习（RL）任务的不断复杂化要求分布式RL系统可以高效地生成和处理大量数据以训练智能Agent。然而，现有的开源库存在各种限制，阻碍了它们在需要大规模训练的挑战性场景中的实际应用。虽然OpenAI和DeepMind的工业系统已经成功实现了大规模RL训练，但是它们的系统架构和实现细节对社区来说仍然不公开。在本文中，我们提出了RL训练数据流的新抽象，将各种应用中的实际RL训练统一成一个通用框架，并实现了精细优化。根据这个抽象，我们开发了一个可扩展、高效、可扩展的分布式RL系统，名为"ReaLly Scalable RL（SRL）"。

    The ever-growing complexity of reinforcement learning (RL) tasks demands a distributed RL system to efficiently generate and process a massive amount of data to train intelligent agents. However, existing open-source libraries suffer from various limitations, which impede their practical use in challenging scenarios where large-scale training is necessary. While industrial systems from OpenAI and DeepMind have achieved successful large-scale RL training, their system architecture and implementation details remain undisclosed to the community. In this paper, we present a novel abstraction on the dataflows of RL training, which unifies practical RL training across diverse applications into a general framework and enables fine-grained optimizations. Following this abstraction, we develop a scalable, efficient, and extensible distributed RL system called ReaLly Scalable RL (SRL). The system architecture of SRL separates major RL computation components and allows massively parallelized trai
    
[^49]: 使用学习的关卡表示进行游戏关卡混合

    Game Level Blending using a Learned Level Representation. (arXiv:2306.16666v1 [cs.LG])

    [http://arxiv.org/abs/2306.16666](http://arxiv.org/abs/2306.16666)

    本文介绍了一种使用聚类-based 平铺嵌入的方法，通过学习的关卡表示来实现游戏关卡混合，为未注释的游戏提供关卡表示，并在游戏之间提供统一的关卡表示，而无需人工注释。

    

    近年来，通过机器学习进行游戏关卡混合的方法在游戏产生技术领域逐渐流行起来。然而，许多现有的技术依赖于人工注释的关卡表示，从而限制了游戏关卡混合的数量。即使有人工注释的游戏，研究人员还需要创建一个额外的共享表示才能进行混合。本文提出了一种新颖的游戏关卡混合方法，使用了基于聚类的平铺嵌入（CTE），这是一种学习的关卡表示技术，可以为非注释游戏提供关卡表示，并在游戏之间提供统一的关卡表示，而无需人工注释。

    Game level blending via machine learning, the process of combining features of game levels to create unique and novel game levels using Procedural Content Generation via Machine Learning (PCGML) techniques, has gained increasing popularity in recent years. However, many existing techniques rely on human-annotated level representations, which limits game level blending to a limited number of annotated games. Even with annotated games, researchers often need to author an additional shared representation to make blending possible. In this paper, we present a novel approach to game level blending that employs Clustering-based Tile Embeddings (CTE), a learned level representation technique that can serve as a level representation for unannotated games and a unified level representation across games without the need for human annotation. CTE represents game level tiles as a continuous vector representation, unifying their visual, contextual, and behavioral information. We apply this approach
    
[^50]: NaturalInversion: 无需真实数据的图像合成方法，提升现实世界的一致性

    NaturalInversion: Data-Free Image Synthesis Improving Real-World Consistency. (arXiv:2306.16661v1 [cs.CV])

    [http://arxiv.org/abs/2306.16661](http://arxiv.org/abs/2306.16661)

    NaturalInversion 是一种无需真实数据的图像合成方法，通过特征传递金字塔、一对一生成模型和可学习的自适应通道缩放参数，合成的图像与原始数据分布更加一致，并在性能上超过以前的方法。

    

    我们介绍了一种名为 NaturalInversion 的新颖的基于模型反演的方法，可以合成与原始数据分布相符的图像，而无需使用真实数据。在 NaturalInversion 中，我们提出了以下几点创新：（1）特征传递金字塔，在预训练分类器提取的多尺度特征图的基础上，使用增强的原始数据图像先验信息；（2）一对一生成模型，每个生成器只合成一个批次的图像，以引入非线性度量并简化整个优化过程；（3）可学习的自适应通道缩放参数，以调整输出图像通道并更好地利用原始图像先验信息。通过使用我们的 NaturalInversion，我们从在 CIFAR-10/100 上训练的分类器合成图像，并通过可视化和附加分析显示，我们的合成图像与原始数据分布的一致性比以前的方法更好。此外，我们的合成图像在性能上超过以前的方法。

    We introduce NaturalInversion, a novel model inversion-based method to synthesize images that agrees well with the original data distribution without using real data. In NaturalInversion, we propose: (1) a Feature Transfer Pyramid which uses enhanced image prior of the original data by combining the multi-scale feature maps extracted from the pre-trained classifier, (2) a one-to-one approach generative model where only one batch of images are synthesized by one generator to bring the non-linearity to optimization and to ease the overall optimizing process, (3) learnable Adaptive Channel Scaling parameters which are end-to-end trained to scale the output image channel to utilize the original image prior further. With our NaturalInversion, we synthesize images from classifiers trained on CIFAR-10/100 and show that our images are more consistent with original data distribution than prior works by visualization and additional analysis. Furthermore, our synthesized images outperform prior w
    
[^51]: 基于多源语义图的多模态讽刺解释生成

    Multi-source Semantic Graph-based Multimodal Sarcasm Explanation Generation. (arXiv:2306.16650v1 [cs.CL])

    [http://arxiv.org/abs/2306.16650](http://arxiv.org/abs/2306.16650)

    本研究提出了一种基于多源语义图的多模态讽刺解释生成方案（TEAM），该方案通过提取对象级语义元数据和引入外部相关知识概念，有效地解决了现有方法中存在的视觉特征与解码器语义空间之间的差距以及潜在的外部知识限制。

    

    多模态讽刺解释（MuSE）是一个新而具有挑战性的任务，旨在为多模态社交帖子（包括图像和其标题）生成自然语言句子，解释为什么它包含讽刺。尽管现有的先驱研究在使用BART框架方面取得了巨大成功，但它忽视了图像的对象级元数据与解码器语义空间之间的差距，以及潜在的外部知识。为了解决这些限制，本研究提出了一种新颖的基于多源语义图的多模态讽刺解释方案，称为TEAM。具体而言，TEAM提取了输入图像的对象级语义元数据而不是传统全局视觉特征。同时，TEAM利用ConceptNet获取输入文本和提取的对象元数据的相关外部知识概念。然后，TEAM引入了一个多源语义图，全面地刻画了多模态讽刺解释的特征。

    Multimodal Sarcasm Explanation (MuSE) is a new yet challenging task, which aims to generate a natural language sentence for a multimodal social post (an image as well as its caption) to explain why it contains sarcasm. Although the existing pioneer study has achieved great success with the BART backbone, it overlooks the gap between the visual feature space and the decoder semantic space, the object-level metadata of the image, as well as the potential external knowledge. To solve these limitations, in this work, we propose a novel mulTi-source sEmantic grAph-based Multimodal sarcasm explanation scheme, named TEAM. In particular, TEAM extracts the object-level semantic meta-data instead of the traditional global visual features from the input image. Meanwhile, TEAM resorts to ConceptNet to obtain the external related knowledge concepts for the input text and the extracted object meta-data. Thereafter, TEAM introduces a multi-source semantic graph that comprehensively characterize the m
    
[^52]: AI辅助写作的未来

    The Future of AI-Assisted Writing. (arXiv:2306.16641v1 [cs.HC])

    [http://arxiv.org/abs/2306.16641](http://arxiv.org/abs/2306.16641)

    本研究比较了拉取和推送两种AI辅助写作模式对用户需求、质量、所有权、效率和享受度的影响，并发现用户欢迎AI在写作中的无缝辅助，AI能够帮助用户更快地使写作中的想法多样化，同时保持清晰和简洁，并且用户喜欢与AI辅助写作工具的协作，没有感到缺乏所有权。尽管在实验中没有体验到偏见影响。

    

    自然语言生成模型的发展导致了强大的人工智能辅助写作工具的出现。这些工具能够预测用户的需求，并在用户写作时主动提供建议。本研究从信息检索的角度进行了一项比较性用户研究，研究了两种范式（拉取和推送）对AI辅助写作的用户需求、质量、写作产品的所有权以及写作过程的效率和享受度的影响。我们还试图了解AI辅助写作的偏见影响。我们的研究结果表明，用户对人工智能在写作中的无缝辅助表示欢迎。此外，AI帮助用户更快地使写作中的想法多样化，同时保持清晰和简洁。用户还喜欢与AI辅助写作工具的协作，并没有感到缺乏所有权。最后，尽管参与者在我们的实验中没有体验到偏见。

    The development of Natural Language Generation models has led to the creation of powerful Artificial Intelligence-assisted writing tools. These tools are capable of predicting users' needs and actively providing suggestions as they write. In this work, we conduct a comparative user-study between such tools from an information retrieval lens: pull and push. Specifically, we investigate the user demand of AI-assisted writing, the impact of the two paradigms on quality, ownership of the writing product, and efficiency and enjoyment of the writing process. We also seek to understand the impact of bias of AI-assisted writing. Our findings show that users welcome seamless assistance of AI in their writing. Furthermore, AI helped users to diversify the ideas in their writing while keeping it clear and concise more quickly. Users also enjoyed the collaboration with AI-assisted writing tools and did not feel a lack of ownership. Finally, although participants did not experience bias in our expe
    
[^53]: 评估ChatGPT在数字学习游戏中的十进制技能和反馈生成能力

    Evaluating ChatGPT's Decimal Skills and Feedback Generation in a Digital Learning Game. (arXiv:2306.16639v1 [cs.HC])

    [http://arxiv.org/abs/2306.16639](http://arxiv.org/abs/2306.16639)

    本研究评估了ChatGPT在数字学习游戏中解决十进制问题、判断学生答案正确性和提供有意义反馈的能力。结果显示，ChatGPT能够在概念问题上表现良好，但在十进制位和数线问题上存在困难。

    

    尽管多项研究表明自由解释能够促进健全学习，但由于学生输入的无限制性质，这在技术增强学习的自动评分和反馈中产生了重大挑战。我们的工作研究了最新的大型语言模型（特别是ChatGPT）能否解决这个问题。我们使用了从前一项十进制游戏学习研究中获得的数字练习和学生数据，包括5000多个自由解释回答，研究了ChatGPT在以下方面的能力：(1)解决游戏中的练习，(2)确定学生答案的正确性，以及(3)为错误答案提供有意义的反馈。我们的结果显示，ChatGPT能够很好地回答概念问题，但在十进制位和数线问题上存在困难。此外，它能够正确评估75%的学生答案的正确性，并生成通常具有较高质量的反馈。

    While open-ended self-explanations have been shown to promote robust learning in multiple studies, they pose significant challenges to automated grading and feedback in technology-enhanced learning, due to the unconstrained nature of the students' input. Our work investigates whether recent advances in Large Language Models, and in particular ChatGPT, can address this issue. Using decimal exercises and student data from a prior study of the learning game Decimal Point, with more than 5,000 open-ended self-explanation responses, we investigate ChatGPT's capability in (1) solving the in-game exercises, (2) determining the correctness of students' answers, and (3) providing meaningful feedback to incorrect answers. Our results showed that ChatGPT can respond well to conceptual questions, but struggled with decimal place values and number line problems. In addition, it was able to accurately assess the correctness of 75% of the students' answers and generated generally high-quality feedbac
    
[^54]: CMATH：你的语言模型能通过中国小学数学测试吗？

    CMATH: Can Your Language Model Pass Chinese Elementary School Math Test?. (arXiv:2306.16636v1 [cs.CL])

    [http://arxiv.org/abs/2306.16636](http://arxiv.org/abs/2306.16636)

    该论文介绍了中国小学数学应用题（CMATH）数据集，评估了多个流行的大型语言模型（LLMs）在小学数学不同年级的表现。研究发现只有GPT-4在所有年级中取得成功，并且能够保持鲁棒性，而其他模型则在不同年级上表现较差。

    

    我们提出了中国小学数学应用题（CMATH）数据集，包含了1.7k个具有详细注释的小学水平数学应用题，来源于中国实际的练习和考试。该数据集旨在提供一个评估流行的大型语言模型（LLMs）能够达到小学数学哪个年级水平的基准工具。我们评估了各种流行的LLMs，包括商业和开源选项，并发现只有GPT-4在所有六个小学年级中都取得了成功（准确率≥60%），而其他模型在不同年级上的表现欠佳。此外，我们通过添加干扰信息来评估几个表现最佳的LLMs的鲁棒性。我们的发现显示GPT-4能够保持鲁棒性，而其他模型则失败。我们预计我们的研究将揭示LLMs在算术和推理能力方面的局限性。

    We present the Chinese Elementary School Math Word Problems (CMATH) dataset, comprising 1.7k elementary school-level math word problems with detailed annotations, source from actual Chinese workbooks and exams. This dataset aims to provide a benchmark tool for assessing the following question: to what grade level of elementary school math do the abilities of popular large language models (LLMs) correspond? We evaluate a variety of popular LLMs, including both commercial and open-source options, and discover that only GPT-4 achieves success (accuracy $\geq$ 60\%) across all six elementary school grades, while other models falter at different grade levels. Furthermore, we assess the robustness of several top-performing LLMs by augmenting the original problems in the CMATH dataset with distracting information. Our findings reveal that GPT-4 is able to maintains robustness, while other model fail. We anticipate that our study will expose limitations in LLMs' arithmetic and reasoning capabi
    
[^55]: 面向边缘智能的区块链辅助隐私感知数据共享：智慧医疗视角

    Towards Blockchain-Assisted Privacy-Aware Data Sharing For Edge Intelligence: A Smart Healthcare Perspective. (arXiv:2306.16630v1 [cs.CR])

    [http://arxiv.org/abs/2306.16630](http://arxiv.org/abs/2306.16630)

    这篇论文提出了一个基于区块链的隐私感知数据共享模型，用于保护智慧医疗网络中的个人健康数据。通过评估用户之间的信任水平，使用者可以选择不同的隐私保护级别，并使用差分隐私技术和可控随机噪声保护数据的隐私性，以应对链结攻击和污染攻击的威胁。

    

    智能医疗设备和大数据分析的普及显著推动了智慧医疗网络（SHNs）的发展。为了提高诊断的准确性，SHNs中的不同参与者共享包含敏感信息的健康数据。因此，数据交换过程引发了隐私问题，特别是当来自多个来源的健康数据（链结攻击）的整合导致进一步泄露时。链结攻击是隐私领域中一种主要攻击类型，可以利用各种数据源进行隐私数据挖掘。此外，对手发动污染攻击以篡改健康数据，导致误诊甚至身体损害。为了保护私人健康数据，我们提出了基于用户之间信任水平的个性化差分隐私模型。信任是通过定义的社区密度来评估的，而相应的隐私保护级别则映射到可控随机噪声，并受到约束。

    The popularization of intelligent healthcare devices and big data analytics significantly boosts the development of smart healthcare networks (SHNs). To enhance the precision of diagnosis, different participants in SHNs share health data that contains sensitive information. Therefore, the data exchange process raises privacy concerns, especially when the integration of health data from multiple sources (linkage attack) results in further leakage. Linkage attack is a type of dominant attack in the privacy domain, which can leverage various data sources for private data mining. Furthermore, adversaries launch poisoning attacks to falsify the health data, which leads to misdiagnosing or even physical damage. To protect private health data, we propose a personalized differential privacy model based on the trust levels among users. The trust is evaluated by a defined community density, while the corresponding privacy protection level is mapped to controllable randomized noise constrained by
    
[^56]: Laxity-Aware可扩展强化学习用于HVAC控制

    Laxity-Aware Scalable Reinforcement Learning for HVAC Control. (arXiv:2306.16619v1 [eess.SY])

    [http://arxiv.org/abs/2306.16619](http://arxiv.org/abs/2306.16619)

    本文介绍了一种利用松弛度概念来量化HVAC操作请求紧急程度的方法，并提出了一个两级方法来优化大量HVAC系统的能源消耗。

    

    需求灵活性在维持电网平衡、降低峰值需求和节约客户能源费用方面起着重要作用。由于其可调整负荷和对建筑能源消耗的显著影响，采暖、通风和空调（HVAC）系统可以通过根据电价和电力系统需求调整能源消耗来提供有价值的需求灵活性给电力系统。为了利用这种在操作时间和功率上的灵活性，准确建模和合并大量HVAC系统的负荷灵活性以及设计有效的控制算法至关重要。在本文中，我们利用松弛度的概念来量化每个HVAC操作请求的紧急程度，以解决建模和控制中的维度灾难问题。我们进一步提出了一种两级方法来解决大量HVAC系统的能源优化问题。下层涉及一个聚合器以合并和控制大量HVAC系统的能源灵活性，上层涉及一个强化学习智能体来优化聚合器的决策。

    Demand flexibility plays a vital role in maintaining grid balance, reducing peak demand, and saving customers' energy bills. Given their highly shiftable load and significant contribution to a building's energy consumption, Heating, Ventilation, and Air Conditioning (HVAC) systems can provide valuable demand flexibility to the power systems by adjusting their energy consumption in response to electricity price and power system needs. To exploit this flexibility in both operation time and power, it is imperative to accurately model and aggregate the load flexibility of a large population of HVAC systems as well as designing effective control algorithms. In this paper, we tackle the curse of dimensionality issue in modeling and control by utilizing the concept of laxity to quantify the emergency level of each HVAC operation request. We further propose a two-level approach to address energy optimization for a large population of HVAC systems. The lower level involves an aggregator to aggr
    
[^57]: GuidedMixup：由显著性图引导的高效Mixup策略

    GuidedMixup: An Efficient Mixup Strategy Guided by Saliency Maps. (arXiv:2306.16612v1 [cs.CV])

    [http://arxiv.org/abs/2306.16612](http://arxiv.org/abs/2306.16612)

    提出了一种新颖的显著性感知混合方法GuidedMixup，通过优化配对图像中显著区域的冲突，以低计算开销在混合图像中保留显著区域。多个数据集上的实验证明，GuidedMixup在增强效果和计算效率之间取得了良好的平衡。

    

    数据增强现在是图像训练过程中必不可少的一部分，它有效地防止了过拟合，并使模型对噪声数据集更加鲁棒。最近的混合增强策略发展出了能够丰富显著性信息的混合掩模，这是一种监督信号。然而，这些方法需要很大的计算负担来优化混合掩模。出于这个动机，我们提出了一种新颖的显著性感知混合方法GuidedMixup，它旨在在混合图像中保留显著区域，并具有较低的计算开销。我们开发了一种高效的配对算法，旨在最小化配对图像中显著区域的冲突，并在混合图像中实现丰富的显著性。此外，GuidedMixup通过平滑地插值两个配对图像来控制每个像素的混合比例，以更好地保留显著区域。在多个数据集上的实验证明，GuidedMixup在增强效果和计算效率之间提供了一个良好的平衡。

    Data augmentation is now an essential part of the image training process, as it effectively prevents overfitting and makes the model more robust against noisy datasets. Recent mixing augmentation strategies have advanced to generate the mixup mask that can enrich the saliency information, which is a supervisory signal. However, these methods incur a significant computational burden to optimize the mixup mask. From this motivation, we propose a novel saliency-aware mixup method, GuidedMixup, which aims to retain the salient regions in mixup images with low computational overhead. We develop an efficient pairing algorithm that pursues to minimize the conflict of salient regions of paired images and achieve rich saliency in mixup images. Moreover, GuidedMixup controls the mixup ratio for each pixel to better preserve the salient region by interpolating two paired images smoothly. The experiments on several datasets demonstrate that GuidedMixup provides a good trade-off between augmentatio
    
[^58]: 用于CPU上基于Transformer的语言模型的高效稀疏推断软件加速器

    An Efficient Sparse Inference Software Accelerator for Transformer-based Language Models on CPUs. (arXiv:2306.16601v1 [cs.LG])

    [http://arxiv.org/abs/2306.16601](http://arxiv.org/abs/2306.16601)

    本文提出了一个用于基于Transformer的语言模型的高效稀疏推断软件加速器，在CPU上利用Intel Deep Learning Boost实现了稀疏矩阵-稠密矩阵乘法的优化，相较于现有的稀疏库，在各种形状和稀疏度下都获得了一个数量级的性能提升。

    

    近年来，基于Transformer的语言模型已成为自然语言处理任务的标准方法。然而，在工业应用中，严格的吞吐量和延迟要求限制了它们的采用。为了缓解这一差距，我们采用了结构化剪枝等模型压缩技术来提高推断效率。然而，大多数现有的神经网络推断运行时对结构化稀疏性缺乏充分的支持。本文提出了一种高效的稀疏深度学习推断软件堆栈，用于基于Transformer的语言模型，其中权重使用恒定的块大小进行剪枝。我们的稀疏软件加速器利用Intel Deep Learning Boost在CPU上最大化稀疏矩阵-稠密矩阵乘法（通常被缩写为SpMM）的性能。在广泛的GEMM形状和5个代表性稀疏度水平下，我们的SpMM内核的性能优于现有的稀疏库（oneMKL、TVM和LIBXSMM）一个数量级。

    In recent years, Transformer-based language models have become the standard approach for natural language processing tasks. However, stringent throughput and latency requirements in industrial applications are limiting their adoption. To mitigate the gap, model compression techniques such as structured pruning are being used to improve inference efficiency. However, most existing neural network inference runtimes lack adequate support for structured sparsity. In this paper, we propose an efficient sparse deep learning inference software stack for Transformer-based language models where the weights are pruned with constant block size. Our sparse software accelerator leverages Intel Deep Learning Boost to maximize the performance of sparse matrix - dense matrix multiplication (commonly abbreviated as SpMM) on CPUs. Our SpMM kernel outperforms the existing sparse libraries (oneMKL, TVM, and LIBXSMM) by an order of magnitude on a wide range of GEMM shapes under 5 representative sparsity ra
    
[^59]: 通过显著性训练为图像分类中的深度神经网络带来鲁棒性吗？

    Does Saliency-Based Training bring Robustness for Deep Neural Networks in Image Classification?. (arXiv:2306.16581v1 [cs.CV])

    [http://arxiv.org/abs/2306.16581](http://arxiv.org/abs/2306.16581)

    通过对深度神经网络进行显著性训练无法提高其在对抗性示例攻击下的鲁棒性。

    

    深度神经网络是理解复杂模式和做出决策的强大工具。然而，它们的黑箱特性阻碍了对其内部工作的完全理解。虽然在线显著性引导训练方法试图通过突出显示模型输出中的明显特征来缓解这个问题，但显然非常规的特征与模型对抗性示例的鲁棒性是否对齐仍不清楚。本文研究了经过显著性训练的模型对抗性示例方法的脆弱性。采用在线显著性引导训练方法训练模型，并针对常见的对抗性示例算法进行评估。我们量化了鲁棒性，并得出结论：尽管模型输出中有良好解释的可视化效果，但显著性训练的模型在对抗性示例攻击中的性能较低。

    Deep Neural Networks are powerful tools to understand complex patterns and making decisions. However, their black-box nature impedes a complete understanding of their inner workings. While online saliency-guided training methods try to highlight the prominent features in the model's output to alleviate this problem, it is still ambiguous if the visually explainable features align with robustness of the model against adversarial examples. In this paper, we investigate the saliency trained model's vulnerability to adversarial examples methods. Models are trained using an online saliency-guided training method and evaluated against popular algorithms of adversarial examples. We quantify the robustness and conclude that despite the well-explained visualizations in the model's output, the salient models suffer from the lower performance against adversarial examples attacks.
    
[^60]: 特征选择：对属性间协作的视角

    Feature Selection: A perspective on inter-attribute cooperation. (arXiv:2306.16559v1 [cs.LG])

    [http://arxiv.org/abs/2306.16559](http://arxiv.org/abs/2306.16559)

    本文综述了辅助特征间协作的过滤特征选择方法的最新研究进展，并总结了不同方法在文献中的贡献。同时提出了当前存在的问题和挑战，以确定未来有前景的研究和发展方向。

    

    高维数据对数据挖掘和机器学习中的学习任务构成了挑战。特征选择是处理维度缩减的一种有效技术，通常是在应用学习算法之前的重要数据处理步骤。在过去几十年中，过滤特征选择方法从简单的单变量相关性排序算法发展到更复杂的相关性-冗余权衡和基于多元依赖性的方法。这种捕捉多变量依赖的趋势旨在通过特征间的互相合作获取关于类别的独特信息。本文对辅助特征间协作的过滤特征选择方法的最新研究工作进行了全面的调查，并总结了文献中不同方法的贡献。此外，还介绍了当前存在的问题和挑战，以确定未来有前景的研究和发展方向。

    High-dimensional datasets depict a challenge for learning tasks in data mining and machine learning. Feature selection is an effective technique in dealing with dimensionality reduction. It is often an essential data processing step prior to applying a learning algorithm. Over the decades, filter feature selection methods have evolved from simple univariate relevance ranking algorithms to more sophisticated relevance-redundancy trade-offs and to multivariate dependencies-based approaches in recent years. This tendency to capture multivariate dependence aims at obtaining unique information about the class from the intercooperation among features. This paper presents a comprehensive survey of the state-of-the-art work on filter feature selection methods assisted by feature intercooperation, and summarizes the contributions of different approaches found in the literature. Furthermore, current issues and challenges are introduced to identify promising future research and development.
    
[^61]: 通过最小-最大F-散度正则化学习公平分类器

    Learning Fair Classifiers via Min-Max F-divergence Regularization. (arXiv:2306.16552v1 [cs.LG])

    [http://arxiv.org/abs/2306.16552](http://arxiv.org/abs/2306.16552)

    本文提出了一种通过最小-最大F-散度正则化学习公平分类器的框架，该框架通过使用F-散度衡量公平性，并保持高准确性。该框架可以适用于多个敏感属性和高维数据集。

    

    随着机器学习（ML）系统在执法、刑事司法、金融、招聘和录取等领域得到应用，确保ML辅助决策的公平性变得越来越重要。本文关注公平分类问题，提出一种新颖的最小-最大F-散度正则化框架，用于学习公平分类模型并保持高准确性。我们的框架由两个可训练的网络组成，即分类器网络和偏差/公平性估计器网络，其中公平性使用统计概念的F-散度进行衡量。我们展示了F-散度度量具有凸性和可微性的特性，并且它们的变分表示使它们在实际的基于梯度的训练方法中具有广泛的适用性。所提出的框架可以方便地适应多个敏感属性和高维数据集。我们研究了基于F-散度的训练范式在两种类型的问题上的性能。

    As machine learning (ML) based systems are adopted in domains such as law enforcement, criminal justice, finance, hiring and admissions, ensuring the fairness of ML aided decision-making is becoming increasingly important. In this paper, we focus on the problem of fair classification, and introduce a novel min-max F-divergence regularization framework for learning fair classification models while preserving high accuracy. Our framework consists of two trainable networks, namely, a classifier network and a bias/fairness estimator network, where the fairness is measured using the statistical notion of F-divergence. We show that F-divergence measures possess convexity and differentiability properties, and their variational representation make them widely applicable in practical gradient based training methods. The proposed framework can be readily adapted to multiple sensitive attributes and for high dimensional datasets. We study the F-divergence based training paradigm for two types of 
    
[^62]: 深度学习目标检测中前景-背景不平衡问题的系统研究

    A systematic study of the foreground-background imbalance problem in deep learning for object detection. (arXiv:2306.16539v1 [cs.CV])

    [http://arxiv.org/abs/2306.16539](http://arxiv.org/abs/2306.16539)

    本文系统研究了深度学习目标检测中前景-背景不平衡问题，发现该问题会导致检测性能下降，尤其当训练数据较少时影响更大。同时，减小目标大小也会增加不平衡问题的影响。

    

    在深度学习中，类别不平衡问题已经在多个研究中被探讨过，但目前还没有对目标检测中的这个现象进行系统的分析。本文针对目标检测中广泛存在的前景-背景（F-B）不平衡问题进行了全面的分析和实验，该问题往往是由于小的、不频繁出现的感兴趣对象引起的。我们实验性地研究了F-B不平衡的不同方面（目标大小、目标数量、数据集大小、目标类型）对检测性能的影响。另外，我们还比较了9种主流方法来解决这个问题，包括Faster-RCNN、SSD、OHEM、Libra-RCNN、Focal-Loss、GHM、PISA、YOLO-v3和GFL，并使用来自不同成像领域的数据集进行了实验。我们得出以下结论：（1）F-B不平衡确实会导致检测性能显著下降，（2）当训练数据较少时，检测性能更受到F-B不平衡的影响，（3）大多数情况下，减小目标大小会增加F-B不平衡的影响。

    The class imbalance problem in deep learning has been explored in several studies, but there has yet to be a systematic analysis of this phenomenon in object detection. Here, we present comprehensive analyses and experiments of the foreground-background (F-B) imbalance problem in object detection, which is very common and caused by small, infrequent objects of interest. We experimentally study the effects of different aspects of F-B imbalance (object size, number of objects, dataset size, object type) on detection performance. In addition, we also compare 9 leading methods for addressing this problem, including Faster-RCNN, SSD, OHEM, Libra-RCNN, Focal-Loss, GHM, PISA, YOLO-v3, and GFL with a range of datasets from different imaging domains. We conclude that (1) the F-B imbalance can indeed cause a significant drop in detection performance, (2) The detection performance is more affected by F-B imbalance when fewer training data are available, (3) in most cases, decreasing object size l
    
[^63]: CLANet: 一种全面的基于亮场图像的批间细胞系鉴定框架

    CLANet: A Comprehensive Framework for Cross-Batch Cell Line Identification Using Brightfield Images. (arXiv:2306.16538v1 [cs.CV])

    [http://arxiv.org/abs/2306.16538](http://arxiv.org/abs/2306.16538)

    CLANet是一个全面的基于亮场图像的跨批细胞系鉴定框架，通过引入细胞聚类级别的选择方法和自监督学习策略，解决了批次效应导致的数据分布偏移问题，从而提高了细胞系鉴定的准确性和可靠性。

    

    细胞系鉴定在生物医学领域中起着关键作用，确保研究人员使用准确鉴定的细胞。通过研究细胞形态特征，监督深度学习在细胞系鉴定方面取得了显著进展。然而，批次效应是一个重要的问题，由于数据生成的不同时间导致了潜在数据分布的巨大偏移，从而使从不同批次培养的细胞系之间的可靠区分变得复杂。为了解决这个挑战，我们引入了CLANet，一种用于基于亮场图像的跨批细胞系鉴定的创新框架，专门设计来解决三种不同的批次效应。我们提出了一种细胞聚类级别的选择方法，以有效捕捉细胞密度变化，并采取自监督学习策略来处理图像质量变化，从而产生可靠的补丁表示。此外，我们采用多实例学习方法来建立模型，通过学习不同批次的实例之间的相关性，从而进一步提高鉴定的准确性。

    Cell line authentication plays a crucial role in the biomedical field, ensuring researchers work with accurately identified cells. Supervised deep learning has made remarkable strides in cell line identification by studying cell morphological features through cell imaging. However, batch effects, a significant issue stemming from the different times at which data is generated, lead to substantial shifts in the underlying data distribution, thus complicating reliable differentiation between cell lines from distinct batch cultures. To address this challenge, we introduce CLANet, a pioneering framework for cross-batch cell line identification using brightfield images, specifically designed to tackle three distinct batch effects. We propose a cell cluster-level selection method to efficiently capture cell density variations, and a self-supervised learning strategy to manage image quality variations, thus producing reliable patch representations. Additionally, we adopt multiple instance lea
    
[^64]: ICSVR: 在视频检索模型中研究组合和语义理解

    ICSVR: Investigating Compositional and Semantic Understanding in Video Retrieval Models. (arXiv:2306.16533v1 [cs.CV])

    [http://arxiv.org/abs/2306.16533](http://arxiv.org/abs/2306.16533)

    这篇论文研究了视频检索模型中的组合和语义理解，并通过在标准基准测试上进行实验，评估了这些组成部分对视频检索性能的影响。

    

    视频检索（VR）涉及根据文本标题检索视频数据库中的真实视频，或反之亦然。合成性的两个重要组成部分：对象和属性以及动作，使用正确的语义联结以形成正确的文本查询。这些组成部分（对象和属性、动作和语义）各自在帮助区分视频和检索正确的真实视频方面起着重要作用。然而，这些组成部分对视频检索性能的影响尚不清楚。因此，我们进行了一项系统研究，评估了视频检索模型在标准基准测试上对组合和语义理解的能力，如MSRVTT、MSVD和DIDEMO。该研究针对两类视频检索模型进行了，一类是在视频文本对上预训练并在下游视频检索数据集上进行微调的（例如，Frozen-in-Time、Violet、MCQ等），另一类是适应预训练的图像文本表示（如CLIP）的。

    Video retrieval (VR) involves retrieving the ground truth video from the video database given a text caption or vice-versa. The two important components of compositionality: objects \& attributes and actions are joined using correct semantics to form a proper text query. These components (objects \& attributes, actions and semantics) each play an important role to help distinguish among videos and retrieve the correct ground truth video. However, it is unclear what is the effect of these components on the video retrieval performance. We therefore, conduct a systematic study to evaluate the compositional and semantic understanding of video retrieval models on standard benchmarks such as MSRVTT, MSVD and DIDEMO. The study is performed on two categories of video retrieval models: (i) which are pre-trained on video-text pairs and fine-tuned on downstream video retrieval datasets (Eg. Frozen-in-Time, Violet, MCQ etc.) (ii) which adapt pre-trained image-text representations like CLIP for vid
    
[^65]: 使用视觉-语言预训练模型在Iconclass上进行多模态搜索

    Multimodal Search on Iconclass using Vision-Language Pre-Trained Models. (arXiv:2306.16529v1 [cs.IR])

    [http://arxiv.org/abs/2306.16529](http://arxiv.org/abs/2306.16529)

    本文介绍了一种使用预训练的视觉-语言模型CLIP的搜索引擎实现方案，用于Iconclass图像分类系统，可以通过图像或文本查询来检索和探索Iconclass概念。

    

    术语来源，如受控词汇、词表和分类系统，在数字化文化遗产中起着关键作用。然而，允许查询和探索这些词汇资源的信息检索（IR）系统往往缺乏对用户搜索背后语义的适当表示，这可以通过多种表达方式传达（例如，图像、关键词或文本描述）。本文介绍了一种新的搜索引擎实现方案，用于其中一种最常用的图像分类系统Iconclass。该系统的创新之处在于使用预训练的视觉 - 语言模型CLIP来检索和探索Iconclass概念，无论是通过视觉查询还是文本查询。

    Terminology sources, such as controlled vocabularies, thesauri and classification systems, play a key role in digitizing cultural heritage. However, Information Retrieval (IR) systems that allow to query and explore these lexical resources often lack an adequate representation of the semantics behind the user's search, which can be conveyed through multiple expression modalities (e.g., images, keywords or textual descriptions). This paper presents the implementation of a new search engine for one of the most widely used iconography classification system, Iconclass. The novelty of this system is the use of a pre-trained vision-language model, namely CLIP, to retrieve and explore Iconclass concepts using visual or textual queries.
    
[^66]: HNO：用于解决PDE的鬣狗神经算子

    HNO: Hyena Neural Operator for solving PDEs. (arXiv:2306.16524v1 [cs.LG])

    [http://arxiv.org/abs/2306.16524](http://arxiv.org/abs/2306.16524)

    本研究使用了一种名为鬣狗的新型神经算子，它利用多层感知器参数化的长卷积滤波器来解决PDE问题。这种方法通过增强模型对输入上下文的理解，并为不同的PDE实例提供数据依赖权重，提供了一种有效的求解PDE的方式。

    

    数值求解偏微分方程（PDE）通常需要精细离散化以解析必要的时空尺度，这可能会耗费大量计算资源。深度学习的最新进展提供了一种新方法来解决PDE，该方法涉及使用神经算子。神经算子是一种神经网络架构，可以学习函数空间之间的映射，并能够基于数据解决偏微分方程。本研究利用了一种称为鬣狗（Hyena）的新型神经算子，该算子采用由多层感知器参数化的长卷积滤波器。鬣狗算子是一种具有次线性复杂性的操作，它使用状态空间模型来参数化具有全局感受野的长卷积。这种机制增强了模型对输入上下文的理解，并能够为不同的PDE实例提供数据依赖权重。为了衡量各个层在解决PDE中的有效性，我们进行实验评估。

    Numerically solving partial differential equations (PDEs) typically requires fine discretization to resolve necessary spatiotemporal scales, which can be computationally expensive. Recent advances in deep learning have provided a new approach to solving PDEs that involves the use of neural operators. Neural operators are neural network architectures that learn mappings between function spaces and have the capability to solve partial differential equations based on data. This study utilizes a novel neural operator called Hyena, which employs a long convolutional filter that is parameterized by a multilayer perceptron. The Hyena operator is an operation that enjoys sub-quadratic complexity and state space model to parameterize long convolution that enjoys global receptive field. This mechanism enhances the model's comprehension of the input's context and enables data-dependent weight for different PDE instances. To measure how effective the layers are in solving PDEs, we conduct experime
    
[^67]: SARC: 软参演者回顾评论者

    SARC: Soft Actor Retrospective Critic. (arXiv:2306.16503v1 [cs.LG])

    [http://arxiv.org/abs/2306.16503](http://arxiv.org/abs/2306.16503)

    SARC是一个基于SAC算法的新方法，通过改进评论者实现更好的收敛性和梯度估计，为演员提供了更好的策略梯度估计。

    

    SAC是一个演员评论者算法，其两个时间尺度的特性在于评论者估计在任何给定时间都没有收敛于演员，但由于评论者学习速度比演员快，它确保了两者之间的最终一致性。文献中引入了各种策略来学习更好的梯度估计，以帮助实现更好的收敛性。由于梯度估计依赖于评论者，我们认为改进评论者可以为每个时间点的演员提供更好的梯度估计。基于此，我们提出了软参演者回顾评论者(SARC)，其中我们将SAC评论者损失与另一个损失项回顾损失相结合 - 实现了更快的评论者收敛和更好的演员策略梯度估计。现有的SAC实现可以很容易地适应SARC，只需进行微小的修改。通过大量的实验和分析，我们展示了SARC相比S的一致改进。

    The two-time scale nature of SAC, which is an actor-critic algorithm, is characterised by the fact that the critic estimate has not converged for the actor at any given time, but since the critic learns faster than the actor, it ensures eventual consistency between the two. Various strategies have been introduced in literature to learn better gradient estimates to help achieve better convergence. Since gradient estimates depend upon the critic, we posit that improving the critic can provide a better gradient estimate for the actor at each time. Utilizing this, we propose Soft Actor Retrospective Critic (SARC), where we augment the SAC critic loss with another loss term retrospective loss - leading to faster critic convergence and consequently, better policy gradient estimates for the actor. An existing implementation of SAC can be easily adapted to SARC with minimal modifications. Through extensive experimentation and analysis, we show that SARC provides consistent improvement over S
    
[^68]: 社交媒体流中的事件检测：方法、数据集和机会

    Event Detection from Social Media Stream: Methods, Datasets and Opportunities. (arXiv:2306.16495v1 [cs.SI])

    [http://arxiv.org/abs/2306.16495](http://arxiv.org/abs/2306.16495)

    本论文调查了Twitter数据流的事件检测方法，提供了公开可用的数据集，并探讨了未来的研究机会。

    

    社交媒体流包含大量多样化的信息，从日常生活故事到最新的全球和当地事件和新闻。特别是Twitter，允许快速传播实时发生的事件，并使个人和组织能够及时了解当前事件。从社交媒体数据中检测事件与传统文本面临不同的挑战，是近年来受到关注的研究领域。在本文中，我们调查了Twitter数据流的广泛事件检测方法，帮助读者了解该领域的最新发展。我们还介绍了公开可用的数据集。此外，还有一些研究机会。

    Social media streams contain large and diverse amount of information, ranging from daily-life stories to the latest global and local events and news. Twitter, especially, allows a fast spread of events happening real time, and enables individuals and organizations to stay informed of the events happening now. Event detection from social media data poses different challenges from traditional text and is a research area that has attracted much attention in recent years. In this paper, we survey a wide range of event detection methods for Twitter data stream, helping readers understand the recent development in this area. We present the datasets available to the public. Furthermore, a few research opportunities
    
[^69]: 增强模型普适的交互式特征归因提高性能和样本效率

    Increasing Performance And Sample Efficiency With Model-agnostic Interactive Feature Attributions. (arXiv:2306.16431v1 [cs.LG])

    [http://arxiv.org/abs/2306.16431](http://arxiv.org/abs/2306.16431)

    本文提出了一种增强模型普适的交互式特征归因方法，通过纠正特征归因并重新训练模型，显著提高了模型的性能和样本效率。

    

    模型普适的特征归因可以为复杂的机器学习模型提供局部洞察力。如果解释是正确的，领域专家可以验证和信任模型的决策。然而，如果它与专家的知识相矛盾，相关工作只纠正了无关的特征以改进模型。为了允许无限的交互，本文针对两种流行的解释方法（遮蔽法和沙普利值）提供了模型普适的实现，以在复杂模型中强制执行完全不同的归因。对于特定的样本集，我们使用纠正的特征归因来生成额外的局部数据，用于重新训练模型以对样本进行正确解释。通过在各种模型上进行模拟和真实数据实验，我们展示了我们提出的方法如何通过基于纠正的解释来扩充训练数据集，从而显著提高模型的性能。将我们的交互式解释添加到主动学习设置中可以增加样本效率。

    Model-agnostic feature attributions can provide local insights in complex ML models. If the explanation is correct, a domain expert can validate and trust the model's decision. However, if it contradicts the expert's knowledge, related work only corrects irrelevant features to improve the model. To allow for unlimited interaction, in this paper we provide model-agnostic implementations for two popular explanation methods (Occlusion and Shapley values) to enforce entirely different attributions in the complex model. For a particular set of samples, we use the corrected feature attributions to generate extra local data, which is used to retrain the model to have the right explanation for the samples. Through simulated and real data experiments on a variety of models we show how our proposed approach can significantly improve the model's performance only by augmenting its training dataset based on corrected explanations. Adding our interactive explanations to active learning settings incr
    
[^70]: 逼真的合成金融交易用于反洗钱模型

    Realistic Synthetic Financial Transactions for Anti-Money Laundering Models. (arXiv:2306.16424v1 [cs.AI])

    [http://arxiv.org/abs/2306.16424](http://arxiv.org/abs/2306.16424)

    本文提供了一个逼真的合成金融交易数据集生成器和一组合成的反洗钱数据集，以满足训练模型和推进领域发展的需求。

    

    随着金融的广泛数字化和加密货币的日益流行，网络犯罪分子设计的欺诈方案越来越复杂。洗钱——将非法资金移动以掩盖其来源——可以跨越银行和国界，产生复杂的交易模式。联合国估计每年全球洗钱金额占全球GDP的2-5%，约为0.8-2.0万亿美元。不幸的是，通常无法获得用于训练机器学习模型来检测洗钱的真实数据，且之前的合成数据生成器存在显著缺陷。为了比较模型并推进该领域的发展，需要一个逼真、标准化、公开可用的基准数据集。为此，本文提出了一种合成金融交易数据集生成器和一组合成的反洗钱数据集。我们根据实际交易尽可能地校准了这个基于代理的生成器。

    With the widespread digitization of finance and the increasing popularity of cryptocurrencies, the sophistication of fraud schemes devised by cybercriminals is growing. Money laundering -- the movement of illicit funds to conceal their origins -- can cross bank and national boundaries, producing complex transaction patterns. The UN estimates 2-5\% of global GDP or \$0.8 - \$2.0 trillion dollars are laundered globally each year. Unfortunately, real data to train machine learning models to detect laundering is generally not available, and previous synthetic data generators have had significant shortcomings. A realistic, standardized, publicly-available benchmark is needed for comparing models and for the advancement of the area.  To this end, this paper contributes a synthetic financial transaction dataset generator and a set of synthetically generated AML (Anti-Money Laundering) datasets. We have calibrated this agent-based generator to match real transactions as closely as possible and
    
[^71]: 在社交媒体上识别抑郁症的框架：MentalRiskES@IberLEF 2023

    A Framework for Identifying Depression on Social Media: MentalRiskES@IberLEF 2023. (arXiv:2306.16125v1 [cs.CL])

    [http://arxiv.org/abs/2306.16125](http://arxiv.org/abs/2306.16125)

    该论文介绍了在社交媒体上识别抑郁症的框架，使用机器学习和深度学习技术来解决四个预测子任务，并发现使用句子嵌入作为线性回归器的输入产生了更好的结果。

    

    本文描述了我们参与IberLEF 2023的MentalRiskES任务。该任务涉及根据个人在社交媒体上的活动来预测他们可能患抑郁症的可能性。数据集由175个Telegram用户的对话组成，每个用户根据他们患病证据进行标记。我们使用传统机器学习和深度学习技术的组合来解决四个预测子任务：二分类、简单回归、多类别分类和多类别回归。我们通过训练一个模型来解决多类别回归问题，然后将预测结果转换为适用于其他三个子任务的结果。我们比较了两种不同建模方法的性能：对基于BERT的模型进行微调和使用句子嵌入作为线性回归器的输入，后者产生了更好的结果。可以在以下链接找到复现我们结果的代码：https://github.com/simonsanvil/EarlyDep

    This paper describes our participation in the MentalRiskES task at IberLEF 2023. The task involved predicting the likelihood of an individual experiencing depression based on their social media activity. The dataset consisted of conversations from 175 Telegram users, each labeled according to their evidence of suffering from the disorder. We used a combination of traditional machine learning and deep learning techniques to solve four predictive subtasks: binary classification, simple regression, multiclass classification, and multiclass regression. We approached this by training a model to solve the multiclass regression case and then transforming the predictions to work for the other three subtasks. We compare the performance of two different modeling approaches: fine-tuning a BERT-based model and using sentence embeddings as inputs to a linear regressor, with the latter yielding better results. The code to reproduce our results can be found at: https://github.com/simonsanvil/EarlyDep
    
[^72]: 安全高效的异步垂直联邦学习:基于级联混合优化方法

    Secure and Fast Asynchronous Vertical Federated Learning via Cascaded Hybrid Optimization. (arXiv:2306.16077v1 [cs.LG])

    [http://arxiv.org/abs/2306.16077](http://arxiv.org/abs/2306.16077)

    本论文提出了一种在垂直联邦学习中使用级联混合优化的方法，通过在下游使用零阶优化保护隐私并在上游使用一阶优化提高收敛速度，从而解决了ZOO-based VFL收敛速度较慢的问题。

    

    垂直联邦学习(VFL)因能够在垂直分割的数据上联合训练隐私保护模型而引起越来越多的关注。最近的研究表明，应用零阶优化(ZOO)在构建实用的VFL算法方面具有许多优势。然而，基于ZOO的VFL存在一个关键问题，即其收敛速度较慢，限制了其在处理现代大型模型时的应用。为了解决这个问题，我们提出了一种在VFL中使用级联混合优化方法。该方法中，下游模型（客户端）使用ZOO进行训练以保护隐私并确保不共享内部信息。同时，上游模型（服务器）在本地使用一阶优化(FOO)进行更新，这显著提高了收敛速度，使得能够在不损害隐私和安全性的前提下训练大型模型。我们在理论上证明了我们的VFL框架比基于ZOO的VFL更快地收敛。

    Vertical Federated Learning (VFL) attracts increasing attention because it empowers multiple parties to jointly train a privacy-preserving model over vertically partitioned data. Recent research has shown that applying zeroth-order optimization (ZOO) has many advantages in building a practical VFL algorithm. However, a vital problem with the ZOO-based VFL is its slow convergence rate, which limits its application in handling modern large models. To address this problem, we propose a cascaded hybrid optimization method in VFL. In this method, the downstream models (clients) are trained with ZOO to protect privacy and ensure that no internal information is shared. Meanwhile, the upstream model (server) is updated with first-order optimization (FOO) locally, which significantly improves the convergence rate, making it feasible to train the large models without compromising privacy and security. We theoretically prove that our VFL framework converges faster than the ZOO-based VFL, as the c
    
[^73]: 可解释机器学习中罗生门效应的实证评估

    An Empirical Evaluation of the Rashomon Effect in Explainable Machine Learning. (arXiv:2306.15786v1 [cs.LG])

    [http://arxiv.org/abs/2306.15786](http://arxiv.org/abs/2306.15786)

    通过对不同数据集、模型和指标进行定量评估，我们发现罗生门效应对可解释机器学习具有影响，这为之前的轶事证据提供了实证支持，并展示了科学家和实践者面临的挑战。

    

    罗生门效应描述了以下现象：对于给定的数据集，可能存在许多具有相同良好性能但采用不同解决策略的模型。罗生门效应对可解释机器学习具有影响，特别是对解释的可比性。我们对三种不同比较场景提供了统一视角，并在不同数据集、模型、归因方法和指标上进行了定量评估。我们发现超参数调整起到了一定作用，指标选择也很重要。我们的结果为先前的轶事证据提供了实证支持，并展示了科学家和实践者面临的挑战。

    The Rashomon Effect describes the following phenomenon: for a given dataset there may exist many models with equally good performance but with different solution strategies. The Rashomon Effect has implications for Explainable Machine Learning, especially for the comparability of explanations. We provide a unified view on three different comparison scenarios and conduct a quantitative evaluation across different datasets, models, attribution methods, and metrics. We find that hyperparameter-tuning plays a role and that metric selection matters. Our results provide empirical support for previously anecdotal evidence and exhibit challenges for both scientists and practitioners.
    
[^74]: ShuttleSet22: 用羽毛球单打数据集对中风预测进行基准测试

    ShuttleSet22: Benchmarking Stroke Forecasting with Stroke-Level Badminton Dataset. (arXiv:2306.15664v1 [cs.AI])

    [http://arxiv.org/abs/2306.15664](http://arxiv.org/abs/2306.15664)

    本研究提供了一个收集自2022年高排名比赛的羽毛球单打数据集ShuttleSet22，并使用最先进的拍球预测方法ShuttleNet进行了基准测试。

    

    近年来，由于人工智能的进步和数据采集的效率，羽毛球分析引起了人们的关注。虽然已经有一系列有效的应用来改善和研究选手表现，但只有很少几个可以供羽毛球领域外的研究人员使用的公开羽毛球数据集。现有的羽毛球单打数据集集中于特定的比赛对决，然而它们无法对不同选手和各种比赛对决进行综合研究。在本文中，我们提供了一个羽毛球单打数据集ShuttleSet22，这个数据集是从2022年高排名比赛中收集的。ShuttleSet22训练集包括30,172个回合中的2,888个拍球，验证集包括450个回合中的1,400个拍球，测试集包括654个回合中的2,040个拍球，并且具有每个回合中详细的拍球级元数据。为了与ShuttleSet22进行基准测试，我们使用ShuttleNet，这是目前最先进的拍球预测方法。

    In recent years, badminton analytics has drawn attention due to the advancement of artificial intelligence and the efficiency of data collection. While there is a line of effective applications to improve and investigate player performance, there are only a few public badminton datasets that can be used for researchers outside the badminton domain. Existing badminton singles datasets focus on specific matchups; however, they cannot provide comprehensive studies on different players and various matchups. In this paper, we provide a badminton singles dataset, ShuttleSet22, which is collected from high-ranking matches in 2022. ShuttleSet22 consists of 30,172 strokes in 2,888 rallies in the training set, 1,400 strokes in 450 rallies in the validation set, and 2,040 strokes in 654 rallies in the testing set with detailed stroke-level metadata within a rally. To benchmark existing work with ShuttleSet22, we test the state-of-the-art stroke forecasting approach, ShuttleNet, with the correspon
    
[^75]: 通过重新加权优化轨迹增强对抗训练

    Enhancing Adversarial Training via Reweighting Optimization Trajectory. (arXiv:2306.14275v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.14275](http://arxiv.org/abs/2306.14275)

    本文提出了一种名为“加权优化轨迹（WOT）”的新方法，通过优化历史轨迹，解决了对抗训练中的鲁棒泛化问题。

    

    尽管对抗训练已成为提高深度神经网络鲁棒性的事实上的方法，但众所周知，简单的对抗训练遭受了令人畏缩的鲁棒过拟合问题，导致鲁棒泛化效果不佳。近年来已经提出了一些方法来解决这些缺点，如额外的规范化、对抗权重扰动和更多数据训练。然而，鲁棒泛化的改进仍然远不理想。在本文中，我们从全新的角度解决这一挑战--优化历史轨迹的精细化。我们提出了一种名为“加权优化轨迹（WOT）”的新方法，利用对抗训练的优化轨迹在时间上的特点。我们进行了大量实验证明了WOT在各种最新对抗攻击下的有效性。结果显示，WOT与现有方法完美融合。

    Despite the fact that adversarial training has become the de facto method for improving the robustness of deep neural networks, it is well-known that vanilla adversarial training suffers from daunting robust overfitting, resulting in unsatisfactory robust generalization. A number of approaches have been proposed to address these drawbacks such as extra regularization, adversarial weights perturbation, and training with more data over the last few years. However, the robust generalization improvement is yet far from satisfactory. In this paper, we approach this challenge with a brand new perspective -- refining historical optimization trajectories. We propose a new method named \textbf{Weighted Optimization Trajectories (WOT)} that leverages the optimization trajectories of adversarial training in time. We have conducted extensive experiments to demonstrate the effectiveness of WOT under various state-of-the-art adversarial attacks. Our results show that WOT integrates seamlessly with t
    
[^76]: 论共享意图的计算机制以及有关理性和意识的推测

    On Computational Mechanisms for Shared Intentionality, and Speculation on Rationality and Consciousness. (arXiv:2306.13657v1 [cs.AI])

    [http://arxiv.org/abs/2306.13657](http://arxiv.org/abs/2306.13657)

    本文提出了一种共享意图优先的理论，探讨了支持计算机代理人之间共享意图的基本机制所必须具备的特征，并探索了这些机制如何适用于人类以提供对人类理性和意识的解释。

    

    人类独特的特征之一是我们能够进行新颖的、合作的行为或团队合作。这需要我们能够在个体之间传达目标、计划和思想，以创建共享意图。本文利用David Marr的信息处理模型，推导出支持计算机代理人之间共享意图的基本机制所必须具备的特征，并指出这些特征如何在现有的基于人工智能的机器人中实现。此外，本文提出这个思维实验所得到的机制也适用于人类，并进一步提供了与观察相符的关于人类理性、意向和感知意识的解释。这样就形成了作者所称的共享意图优先理论（SIFT）。

    A singular attribute of humankind is our ability to undertake novel, cooperative behavior, or teamwork. This requires that we can communicate goals, plans, and ideas between the brains of individuals to create shared intentionality. Using the information processing model of David Marr, I derive necessary characteristics of basic mechanisms to enable shared intentionality between computational agents and indicate how these could be implemented in present-day AI-based robots.  More speculatively, I suggest the mechanisms derived by this thought experiment apply to humans and extend to provide explanations for human rationality and aspects of intentional and phenomenal consciousness that accord with observation. This yields what I call the Shared Intentionality First Theory (SIFT) for rationality and consciousness.
    
[^77]: SDR-GAIN：一种用于自动驾驶的高实时遮挡行人姿态完成方法

    SDR-GAIN: A High Real-Time Occluded Pedestrian Pose Completion Method for Autonomous Driving. (arXiv:2306.03538v1 [cs.CV])

    [http://arxiv.org/abs/2306.03538](http://arxiv.org/abs/2306.03538)

    SDR-GAIN是一种用于解决行人姿态中部分遮挡问题的关键点补全方法，它通过对不完整的关键点进行降维，统一特征分布，并使用GAN框架的两种生成模型来完成姿态的补全。该方法的实验表明性能优于基本的GAIN框架。

    

    为了缓解基于人体姿态关键点的行人检测算法中部分遮挡带来的挑战，我们提出了一种称为分离和降维基于生成对抗性补全网络(SDR-GAIN)的新型行人姿势关键点补全方法。首先，我们利用OpenPose在图像中估计行人的姿态。然后，我们对由于遮挡或其他因素而不完整的行人头部和躯干关键点进行维度缩减，以增强特征并进一步统一特征分布。最后，我们引入了基于生成对抗网络(GAN)框架的两种生成模型，这些模型融合了Huber损失、残差结构和L1正则化来生成部分遮挡行人不完整头部和躯干姿态关键点的缺失部分，从而实现了姿态补全。我们在MS COCO和JAAD数据集上的实验表明，SDR-GAIN的性能优于基本的GAIN框架。

    To mitigate the challenges arising from partial occlusion in human pose keypoint based pedestrian detection methods , we present a novel pedestrian pose keypoint completion method called the separation and dimensionality reduction-based generative adversarial imputation networks (SDR-GAIN) . Firstly, we utilize OpenPose to estimate pedestrian poses in images. Then, we isolate the head and torso keypoints of pedestrians with incomplete keypoints due to occlusion or other factors and perform dimensionality reduction to enhance features and further unify feature distribution. Finally, we introduce two generative models based on the generative adversarial networks (GAN) framework, which incorporate Huber loss, residual structure, and L1 regularization to generate missing parts of the incomplete head and torso pose keypoints of partially occluded pedestrians, resulting in pose completion. Our experiments on MS COCO and JAAD datasets demonstrate that SDR-GAIN outperforms basic GAIN framework
    
[^78]: 将模型评估重新考虑为缩小社会技术差距

    Rethinking Model Evaluation as Narrowing the Socio-Technical Gap. (arXiv:2306.03100v1 [cs.HC])

    [http://arxiv.org/abs/2306.03100](http://arxiv.org/abs/2306.03100)

    针对同质化的模型，模型评估需要提供有效的评估，以判断特定模型是否在下游使用场景中可以满足多少人类需求，并且应该根据真实的社会需求来开发评估模型，并拥抱多样化的评估方法。

    

    生成和大型语言模型的最近发展给模型评估带来了新的挑战，研究界和工业界正在努力应对。虽然这些模型的多才多艺引起了人们的兴奋，但它们也不可避免地向同质化迈进：用单个常称之为“通用”的模型为一系列应用提供动力。在这篇立场论文中，我们认为模型评估实践必须承担一个关键任务，以应对这种同质化带来的挑战和责任：为特定模型提供有效的评估，判断是否以及在下游使用场景中可以通过给定模型满足多少人类需求（“社会技术差距”）。我们汲取社会科学、人机交互（HCI）和可解释AI（XAI）跨学科领域的经验，敦促社区开发基于真实社会需求的评估方法，并拥抱多样化的评估方法。

    The recent development of generative and large language models (LLMs) poses new challenges for model evaluation that the research community and industry are grappling with. While the versatile capabilities of these models ignite excitement, they also inevitably make a leap toward homogenization: powering a wide range of applications with a single, often referred to as ``general-purpose'', model. In this position paper, we argue that model evaluation practices must take on a critical task to cope with the challenges and responsibilities brought by this homogenization: providing valid assessments for whether and how much human needs in downstream use cases can be satisfied by the given model (\textit{socio-technical gap}). By drawing on lessons from the social sciences, human-computer interaction (HCI), and the interdisciplinary field of explainable AI (XAI), we urge the community to develop evaluation methods based on real-world socio-requirements and embrace diverse evaluation methods 
    
[^79]: 源代码模型的数据增强方法：一份综述

    Data Augmentation Approaches for Source Code Models: A Survey. (arXiv:2305.19915v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.19915](http://arxiv.org/abs/2305.19915)

    本文对源代码的数据增强技术进行了全面的调查和综述，介绍了它们的分类法、优化策略和性能结果，并讨论了未来方向和研究挑战。

    

    源代码在许多关键任务中的广泛应用促进了数据增强（DA）技术的发展，以增强训练数据并提高这些模型的各种能力（例如健壮性和可泛化性）。虽然已经提出并针对源代码模型进行了一系列DA方法的调整，但缺乏综合性的调查和审查以理解它们的有效性和含义。本文通过对源代码的数据增强进行全面而综合的调查，填补这一空白，我们系统地整理和概述现有文献，以提供该领域的全面概述。我们首先构建了适用于源代码模型的数据增强的分类法，然后讨论了著名的、方法上具有说明性的方法。接下来，我们强调了优化DA质量的一般策略和技术。随后，我们强调了在被广泛接受的基准测试中发挥作用的技术，并呈现了它们的性能结果。最后，我们讨论了DA用于源代码模型的潜在未来方向和开放研究挑战。

    The increasingly popular adoption of source code in many critical tasks motivates the development of data augmentation (DA) techniques to enhance training data and improve various capabilities (e.g., robustness and generalizability) of these models. Although a series of DA methods have been proposed and tailored for source code models, there lacks a comprehensive survey and examination to understand their effectiveness and implications. This paper fills this gap by conducting a comprehensive and integrative survey of data augmentation for source code, wherein we systematically compile and encapsulate existing literature to provide a comprehensive overview of the field. We start by constructing a taxonomy of DA for source code models model approaches, followed by a discussion on prominent, methodologically illustrative approaches. Next, we highlight the general strategies and techniques to optimize the DA quality. Subsequently, we underscore techniques that find utility in widely-accept
    
[^80]: 基于相似局部特征的多源对抗迁移学习

    Multi-source adversarial transfer learning based on similar source domains with local features. (arXiv:2305.19067v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.19067](http://arxiv.org/abs/2305.19067)

    本论文提出一种基于局部特征相似性的多源对抗迁移学习方法，用于处理源域和目标域仅具有局部相似性的迁移场景。通过子网络提取可迁移局部特征，并使用注意力模块对特征进行加权处理以抑制非相关特征。

    

    迁移学习利用其他领域的知识，在许多应用中取得了成功。迁移学习方法依赖于源域和目标域的整体相似性。然而，在某些情况下，很难提供一个整体相似的源域，只能提供一些具有相似局部特征的源域。那么，能否实现迁移学习？在这方面，我们提出了一种基于局部特征相似性的多源对抗迁移学习方法，用于处理源域和目标域仅具有局部相似性的迁移场景。该方法通过子网络提取单个源域和目标域之间的可迁移局部特征。具体而言，子网络的特征提取器由域判别器引导，学习源域和目标域之间的可迁移知识。然后，使用注意力模块对提取的特征进行加权，以抑制非相关特征。

    Transfer learning leverages knowledge from other domains and has been successful in many applications. Transfer learning methods rely on the overall similarity of the source and target domains. However, in some cases, it is impossible to provide an overall similar source domain, and only some source domains with similar local features can be provided. Can transfer learning be achieved? In this regard, we propose a multi-source adversarial transfer learning method based on local feature similarity to the source domain to handle transfer scenarios where the source and target domains have only local similarities. This method extracts transferable local features between a single source domain and the target domain through a sub-network. Specifically, the feature extractor of the sub-network is induced by the domain discriminator to learn transferable knowledge between the source domain and the target domain. The extracted features are then weighted by an attention module to suppress non-tr
    
[^81]: Python封装器用于在HPO基准测试上模拟多保真度优化，无需等待

    Python Wrapper for Simulating Multi-Fidelity Optimization on HPO Benchmarks without Any Wait. (arXiv:2305.17595v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.17595](http://arxiv.org/abs/2305.17595)

    本研究开发了一个Python封装器，用于在HPO基准测试上模拟多保真度优化，通过强制每个工作进程等待，可以减少多小时的等待时间，使得模拟结果与实际实验的评估顺序完全一致。

    

    深度学习的超参数（HP）优化对于高性能至关重要。由于深度学习往往需要几小时到几天的训练时间，因此深度学习的HP优化通常是难以承受的昂贵的。这促使出现了表格或替代基准测试，可以在一小部分时间内查询特定HP配置的DL的（预测）性能。然而，由于DL训练的实际运行时间与查询响应时间明显不同，异步HPO（例如多保真度优化）的模拟器必须在每次迭代中等待实际运行时间，否则模拟中的评估顺序不符合实际实验。为了解决这个问题，我们开发了一个Python封装器并描述了它的用法。这个封装器强制每个工作进程等待，以便我们只需等待$10^{-2}$秒，就可以获得与实际实验完全相同的评估顺序，而不是等待几个小时。

    Hyperparameter (HP) optimization of deep learning (DL) is essential for high performance. As DL often requires several hours to days for its training, HP optimization (HPO) of DL is often prohibitively expensive. This boosted the emergence of tabular or surrogate benchmarks, which enable querying the (predictive) performance of DL with a specific HP configuration in a fraction. However, since the actual runtime of a DL training is significantly different from its query response time, simulators of an asynchronous HPO, e.g. multi-fidelity optimization, must wait for the actual runtime at each iteration in a na\"ive implementation; otherwise, the evaluation order during simulation does not match with the real experiment. To ease this issue, we developed a Python wrapper and describe its usage. This wrapper forces each worker to wait so that we yield exactly the same evaluation order as in the real experiment with only $10^{-2}$ seconds of waiting instead of waiting several hours. Our imp
    
[^82]: Learngene: 从祖先模型中继承压缩知识到后代模型

    Learngene: Inheriting Condensed Knowledge from the Ancestry Model to Descendant Models. (arXiv:2305.02279v1 [cs.LG])

    [http://arxiv.org/abs/2305.02279](http://arxiv.org/abs/2305.02279)

    本文提出了一种机器学习范式 Learngene，将积累的知识压缩成更为紧凑的信息片段并继承给后代模型，以便于适应新的环境

    

    在一个生物的连续进化过程中，它的基因积累了广泛的经验和知识，使新生后代能够快速适应其特定环境。受到这一观察的启发，我们提出了一种新的机器学习范 paradigm，即 Learngene，使学习模型能够融合基因的三个关键特征。 (i) 积累：知识在祖先模型的连续学习过程中积累。 (ii) 压缩：将积累的详尽知识压缩成更为紧凑的信息片段，即 Learngene。 (iii) 继承：将压缩的 Learngene 继承给后代模型，以便于适应新的环境。由于积累已在一些成熟的范式中得到研究，如大规模预训练和终身学习，因此我们专注于压缩和继承，这引发了三个关键问题，并为这些问题提供了初步的解决方案。

    During the continuous evolution of one organism's ancestry, its genes accumulate extensive experiences and knowledge, enabling newborn descendants to rapidly adapt to their specific environments. Motivated by this observation, we propose a novel machine learning paradigm \textit{Learngene} to enable learning models to incorporate three key characteristics of genes. (i) Accumulating: the knowledge is accumulated during the continuous learning of an \textbf{ancestry model}. (ii) Condensing: the exhaustive accumulated knowledge is condensed into a much more compact information piece, \ie \textbf{learngene}. (iii): Inheriting: the condensed \textbf{learngene} is inherited to make it easier for \textbf{descendant models} to adapt to new environments. Since accumulating has been studied in some well-developed paradigms like large-scale pre-training and lifelong learning, we focus on condensing and inheriting, which induces three key issues and we provide the preliminary solutions to these is
    
[^83]: 真实世界三维装箱问题的基准数据集和实例生成器

    Benchmark dataset and instance generator for Real-World Three-Dimensional Bin Packing Problems. (arXiv:2304.14712v1 [cs.AI])

    [http://arxiv.org/abs/2304.14712](http://arxiv.org/abs/2304.14712)

    本文提出了一个真实世界装箱问题的基准数据集和实例生成器，可以用来比较不同装箱算法的性能。

    

    本文提出了一个真实世界装箱问题的基准数据集。该数据集由12个实例组成，涵盖了不同大小和用户需求的问题复杂度水平（包含从38到53个包裹的数量）。实际上，我们考虑了几个面向真实世界的限制条件来构建这些实例：i)物品和箱子尺寸，ii)重量限制，iii)包类别之间的亲和性，iv)包装顺序的偏好和v)负载平衡。除了数据外，我们还提供了一个自主开发的Python脚本用于数据集生成，称为Q4RealBPP-DataGen。该基准首先被设计用于评估量子求解器，因此这组实例的特征是按照量子设备的当前限制设计的。此外，数据集生成器包含在内，允许构建通用基准。本文介绍的数据提供了一个基准，可以用来比较不同方法的性能和对比算法的效果。

    In this paper, a benchmark for real-world bin packing problems is proposed. This dataset is composed of 12 instances comprehending different levels of problem complexity regarding size (with the number of packages ranging from 38 to 53) and user-defined requirements. In fact, several real-world oriented restrictions have been considered for building these instances: i) items and bins dimensions, ii) weight restrictions, iii) affinities among packages categories iv) preferences for package ordering and v) load balancing. Besides the data, we also provide an own-developed Python script for the dataset generation, coined as Q4RealBPP-DataGen. The benchmark was firstly proposed to evaluate quantum solvers, therefore the characteristic of this set of instances were designed according to the current limitations of quantum devices. Additionally, the dataset generator is included to allow the construction of general-purpose benchmarks. The data introduced on this paper provides a baseline that
    
[^84]: ChatGPT与现有模型之间的关键短语生成任务基准研究

    ChatGPT vs State-of-the-Art Models: A Benchmarking Study in Keyphrase Generation Task. (arXiv:2304.14177v1 [cs.CL])

    [http://arxiv.org/abs/2304.14177](http://arxiv.org/abs/2304.14177)

    本研究比较了ChatGPT和现有模型在关键短语生成任务上的性能，并发现ChatGPT在所有测试数据集和环境中的表现均优于现有模型，适用于不同领域和文档长度的关键短语生成。

    

    基于Transformer的语言模型，包括ChatGPT，已经在各种自然语言生成任务中展现了出色的性能。但是，在评估ChatGPT的关键短语生成能力方面，还没有多少研究，这涉及到准确反映文档内容的信息性短语的识别。本文试图通过将ChatGPT的关键短语生成表现与现有模型进行比较来解决这个问题，同时还测试了它作为解决领域适应和长文档关键短语生成两个重大挑战的潜力。我们在来自科学文章和新闻领域的六个公开数据集上进行了实验，分析了在短文档和长文档上的表现。结果表明，在所有测试的数据集和环境中，ChatGPT的性能优于当前现有模型，产生适应不同领域和文档长度的高质量关键短语。

    Transformer-based language models, including ChatGPT, have demonstrated exceptional performance in various natural language generation tasks. However, there has been limited research evaluating ChatGPT's keyphrase generation ability, which involves identifying informative phrases that accurately reflect a document's content. This study seeks to address this gap by comparing ChatGPT's keyphrase generation performance with state-of-the-art models, while also testing its potential as a solution for two significant challenges in the field: domain adaptation and keyphrase generation from long documents. We conducted experiments on six publicly available datasets from scientific articles and news domains, analyzing performance on both short and long documents. Our results show that ChatGPT outperforms current state-of-the-art models in all tested datasets and environments, generating high-quality keyphrases that adapt well to diverse domains and document lengths.
    
[^85]: 基于自引图的面向影响力的学者环境剖析

    Impact-Oriented Contextual Scholar Profiling using Self-Citation Graphs. (arXiv:2304.12217v2 [cs.DL] UPDATED)

    [http://arxiv.org/abs/2304.12217](http://arxiv.org/abs/2304.12217)

    本研究提出了一个名为GeneticFlow的基于自引图的学者剖析工具，能够满足学者特征剖析中的三个基本要求，即结构化背景、学者为中心和丰富的进化，在科学奖项推理真实任务中表现出色。

    

    定量地剖析学者的科研影响力对于现代研究社会至关重要。目前使用的文献计量指标（如h指数）、列表和网络在学者排名方面表现良好，但不提供学者相关、分析性任务的结构化背景，例如剖析和理解学者特征。本文提出了一个基于图的学者剖析工具——GeneticFlow (GF)，满足三个基本要求：结构化背景、学者为中心和丰富的进化。我们提出了一个框架，用于在包括数百万学者的大规模学术数据源上计算GF；该框架包含了一种新的无监督导师-学生检测算法、一个使用可解释特征的精心设计的引用类型分类器，以及一个经过微调的图神经网络(GNN)模型。通过对科学奖项推理的真实任务进行评估，实验结果表明，最佳GF剖析的F1得分明显优于替代方案。

    Quantitatively profiling a scholar's scientific impact is important to modern research society. Current practices with bibliometric indicators (e.g., h-index), lists, and networks perform well at scholar ranking, but do not provide structured context for scholar-centric, analytical tasks such as profile reasoning and understanding. This work presents GeneticFlow (GF), a suite of novel graph-based scholar profiles that fulfill three essential requirements: structured-context, scholar-centric, and evolution-rich. We propose a framework to compute GF over large-scale academic data sources with millions of scholars. The framework encompasses a new unsupervised advisor-advisee detection algorithm, a well-engineered citation type classifier using interpretable features, and a fine-tuned graph neural network (GNN) model. Evaluations are conducted on the real-world task of scientific award inference. Experiment outcomes show that the F1 score of best GF profile significantly outperforms altern
    
[^86]: 针对稳定的超网络学习的非比例参数化

    Non-Proportional Parametrizations for Stable Hypernetwork Learning. (arXiv:2304.07645v1 [cs.LG])

    [http://arxiv.org/abs/2304.07645](http://arxiv.org/abs/2304.07645)

    本文提出一种针对当前超网络训练策略不稳定、收敛速度慢的问题的解决方案，通过使用非比例加性参数化的方式来修订超网络形式，实现更加稳定和快速的训练。

    

    超网络是生成另一个神经网络参数的神经网络。在许多情况下，当前的超网络训练策略是不稳定的，收敛速度通常比非超网络模型慢得多。我们展示了这个问题与使用常见的超网络架构和初始化时出现的问题有关。我们在理论上和实验上证明了这种数值问题在训练过程中会导致不稳定性，从而降低甚至阻止收敛。我们还证明了流行的深度学习归一化策略无法解决这些问题。然后，我们提出了一种基于修订的超网络形式的解决方案，该超网络使用非比例加性参数化。我们在几个任务上测试了所提出的重新参数化，并证明它始终可以导致更稳定的训练，实现更快的收敛。

    Hypernetworks are neural networks that generate the parameters of another neural network. In many scenarios, current hypernetwork training strategies are unstable, and convergence is often far slower than for non-hypernetwork models. We show that this problem is linked to an issue that arises when using common choices of hypernetwork architecture and initialization. We demonstrate analytically and experimentally how this numerical issue can lead to an instability during training that slows, and sometimes even prevents, convergence. We also demonstrate that popular deep learning normalization strategies fail to address these issues. We then propose a solution to the problem based on a revised hypernetwork formulation that uses non-proportional additive parametrizations. We test the proposed reparametrization on several tasks, and demonstrate that it consistently leads to more stable training, achieving faster convergence.
    
[^87]: 改善临床试验的患者预筛选：利用大型语言模型辅助医生

    Improving Patient Pre-screening for Clinical Trials: Assisting Physicians with Large Language Models. (arXiv:2304.07396v1 [cs.LG])

    [http://arxiv.org/abs/2304.07396](http://arxiv.org/abs/2304.07396)

    本文研究了使用大型语言模型InstructGPT辅助医生预筛选患者是否符合临床试验资格。通过10个合成患者简况的性能评估，展示了LLMs在识别筛选资格标准、单独分类、整体分类、以及需要筛选资格标准的百分比上的表现。

    

    考虑到患者的临床试验，医生需要进行繁琐的检查，以确定患者是否符合文本基准。大型语言模型（LLMs）已被证明在临床信息提取和临床推理方面表现良好，但尚未在现实场景中得到应用。本文研究了使用InstructGPT辅助医生根据患者的医疗简况确定其是否符合临床试验的资格。使用一次性、选择-推理和思维链策略相结合的提示策略，我们研究了LLMs在10个合成患者简况上的表现。在四个级别上评估了性能：能否从临床试验中给出的医疗简况中识别筛选资格标准；能否为每个单独的标准分类是否符合患者；整体分类是否符合临床试验资格以及需要筛选资格标准的百分比。

    Physicians considering clinical trials for their patients are met with the laborious process of checking many text based eligibility criteria. Large Language Models (LLMs) have shown to perform well for clinical information extraction and clinical reasoning, including medical tests, but not yet in real-world scenarios. This paper investigates the use of InstructGPT to assist physicians in determining eligibility for clinical trials based on a patient's summarised medical profile. Using a prompting strategy combining one-shot, selection-inference and chain-of-thought techniques, we investigate the performance of LLMs on 10 synthetically created patient profiles. Performance is evaluated at four levels: ability to identify screenable eligibility criteria from a trial given a medical profile; ability to classify for each individual criterion whether the patient qualifies; the overall classification whether a patient is eligible for a clinical trial and the percentage of criteria to be scr
    
[^88]: 提高人脸模型的身份鲁棒性

    Improving Identity-Robustness for Face Models. (arXiv:2304.03838v1 [cs.CV])

    [http://arxiv.org/abs/2304.03838](http://arxiv.org/abs/2304.03838)

    该论文探讨了在没有身份注释信息的情况下，使用人脸识别嵌入向量作为身份标识的替代方法，以提高人脸模型的身份鲁棒性和公平性。

    

    虽然深度学习模型在许多任务中取得了成功，但人们仍然担心这些模型可能学习到快捷方式，并且缺乏对无关混淆因素的鲁棒性。在直接训练于人脸上的模型中，一个敏感的混淆因素是人的身份。许多与人脸相关的任务理想情况下应该是与身份无关的，并在不同个体之间表现一致（即公平）。通过在训练期间强制执行这种鲁棒性和性能均匀性是度量和实施的一种方法，假设可以在规模上获取与身份相关的信息。但是，由于隐私问题以及收集此类信息的成本，这通常不是情况，大多数人脸数据集只包含输入图像及其相应的任务标签。因此，无需此类注释即可提高身份相关鲁棒性非常重要。在这里，我们探讨使用人脸识别嵌入向量作为身份标识的替代方法，以执行这种鲁棒性和公平性。

    Despite the success of deep-learning models in many tasks, there have been concerns about such models learning shortcuts, and their lack of robustness to irrelevant confounders. When it comes to models directly trained on human faces, a sensitive confounder is that of human identities. Many face-related tasks should ideally be identity-independent, and perform uniformly across different individuals (i.e. be fair). One way to measure and enforce such robustness and performance uniformity is through enforcing it during training, assuming identity-related information is available at scale. However, due to privacy concerns and also the cost of collecting such information, this is often not the case, and most face datasets simply contain input images and their corresponding task-related labels. Thus, improving identity-related robustness without the need for such annotations is of great importance. Here, we explore using face-recognition embedding vectors, as proxies for identities, to enfo
    
[^89]: 大型语言模型综述

    A Survey of Large Language Models. (arXiv:2303.18223v1 [cs.CL])

    [http://arxiv.org/abs/2303.18223](http://arxiv.org/abs/2303.18223)

    本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。

    

    语言本质上是一个由语法规则控制的复杂精细的人类表达系统，对于开发理解和掌握语言的能力的AI算法来说是一项重大挑战。作为主要方法之一，语言建模在过去二十年里广泛研究用于语言理解和生成，从统计语言模型演化为神经语言模型。最近，通过在大规模语料库上预训练Transformer模型，提出了预训练语言模型（PLMs），在解决各种NLP任务方面显示出强大的能力。由于研究人员发现模型缩放可以导致性能改进，他们进一步通过增加模型规模来研究缩放效应，有趣的是，当参数规模超过一定水平时，这些扩大的语言模型不仅可以实现显着的性能提升，而且还显示出一些小规模语言模型所没有的特殊能力。

    Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale langu
    
[^90]: AI生成的文本是否可靠地检测出来？

    Can AI-Generated Text be Reliably Detected?. (arXiv:2303.11156v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.11156](http://arxiv.org/abs/2303.11156)

    本研究通过实证和理论分析表明，在实际场景中，几种AI文本检测器不可靠。改写攻击可以破解多种检测器，包括水印方案、神经网络检测器和零样本分类器。即使是最好的检测器，随着语言模型的进一步提升，性能也会下降。因此，AI生成的文本的可靠检测仍然是一个挑战。

    

    本文从实证和理论两个方面表明，在实际场景中，几种AI文本检测器并不可靠。从实践上来说，我们证明了轻量级的改写器应用在大型语言模型（LLM）上可以破解一系列的检测器，包括使用水印方案、神经网络检测器和零样本分类器。我们的实验表明，旨在躲避改写攻击的基于检索的检测器仍然容易受到递归改写的攻击。然后，我们提出了一个理论上的不可能结果，指出随着语言模型变得越来越复杂和更擅长模仿人类文本，在最好的检测器性能会下降。对于一个足够先进的语言模型来模仿人类文本，即使最佳的检测器的表现只比随机分类器好上一点点。我们的结果足够概括特定的场景，如改写攻击。

    In this paper, both empirically and theoretically, we show that several AI-text detectors are not reliable in practical scenarios. Empirically, we show that paraphrasing attacks, where a light paraphraser is applied on top of a large language model (LLM), can break a whole range of detectors, including ones using watermarking schemes as well as neural network-based detectors and zero-shot classifiers. Our experiments demonstrate that retrieval-based detectors, designed to evade paraphrasing attacks, are still vulnerable to recursive paraphrasing. We then provide a theoretical impossibility result indicating that as language models become more sophisticated and better at emulating human text, the performance of even the best-possible detector decreases. For a sufficiently advanced language model seeking to imitate human text, even the best-possible detector may only perform marginally better than a random classifier. Our result is general enough to capture specific scenarios such as par
    
[^91]: 一个通用的多模态融合检测框架

    A Generalized Multi-Modal Fusion Detection Framework. (arXiv:2303.07064v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.07064](http://arxiv.org/abs/2303.07064)

    本文提出了一个通用的多模态融合检测框架，旨在在复杂场景中通过准确融合激光雷达和图像来提高3D检测的精度。

    

    激光雷达点云已成为自动驾驶中最常见的数据来源，但由于点云的稀疏性，在特定场景下无法实现准确可靠的检测。图像因其与点云的互补性而越来越受到关注。虽然已有一些成功案例，但现有的融合方法要么进行硬融合，要么不直接进行融合。本文提出了一种称为MMFusion的通用的3D检测框架，使用多模态特征。该框架旨在实现在复杂场景中激光雷达和图像的准确融合，从而提高3D检测的精度。我们的框架由两个独立的流组成：激光雷达流和相机流，可以与任何单模态特征提取网络兼容。激光雷达流中的体素局部感知模块增强了局部特征表示，然后多模态特征融合模块有选择地将来自不同流的特征输出进行融合，实现。

    LiDAR point clouds have become the most common data source in autonomous driving. However, due to the sparsity of point clouds, accurate and reliable detection cannot be achieved in specific scenarios. Because of their complementarity with point clouds, images are getting increasing attention. Although with some success, existing fusion methods either perform hard fusion or do not fuse in a direct manner. In this paper, we propose a generic 3D detection framework called MMFusion, using multi-modal features. The framework aims to achieve accurate fusion between LiDAR and images to improve 3D detection in complex scenes. Our framework consists of two separate streams: the LiDAR stream and the camera stream, which can be compatible with any single-modal feature extraction network. The Voxel Local Perception Module in the LiDAR stream enhances local feature representation, and then the Multi-modal Feature Fusion Module selectively combines feature output from different streams to achieve b
    
[^92]: 无专家在线多智能体强化学习中的迁移学习

    Expert-Free Online Transfer Learning in Multi-Agent Reinforcement Learning. (arXiv:2303.01170v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.01170](http://arxiv.org/abs/2303.01170)

    本文提出了Expert-Free Online Transfer Learning (EF-OnTL)算法，在多智能体系统中实现无专家的实时迁移学习。通过动态选择迁移源智能体和要转移的知识，解决了传统迁移学习需要对专家智能体任务有良好理解的问题。

    

    传统上，强化学习中的迁移学习通过将知识从专家智能体转移到新手智能体来解决训练问题，如探索成本、数据可用性和收敛时间。然而，这种迁移需要新手智能体对专家智能体的任务有良好的理解才能有效。作为替代方案，本文提出了一种无专家在线动态迁移学习算法（EF-OnTL），该算法能够在多智能体系统中实现无专家的实时迁移学习。在每一次迁移步骤中，根据智能体的性能和不确定性来动态选择迁移源智能体和要转移的知识。为了提高不确定性估计，我们还提出了一种称为SARS-RND的方法，它是对RND的扩展，可以从智能体的状态、行动、奖励和下一状态中估计不确定性。

    Transfer learning in Reinforcement Learning (RL) has been widely studied to overcome training issues of Deep-RL, i.e., exploration cost, data availability and convergence time, by introducing a way to enhance training phase with external knowledge. Generally, knowledge is transferred from expert-agents to novices. While this fixes the issue for a novice agent, a good understanding of the task on expert agent is required for such transfer to be effective. As an alternative, in this paper we propose Expert-Free Online Transfer Learning (EF-OnTL), an algorithm that enables expert-free real-time dynamic transfer learning in multi-agent system. No dedicated expert exists, and transfer source agent and knowledge to be transferred are dynamically selected at each transfer step based on agents' performance and uncertainty. To improve uncertainty estimation, we also propose State Action Reward Next-State Random Network Distillation (sars-RND), an extension of RND that estimates uncertainty from
    
[^93]: 数据污染中的时序鲁棒性

    Temporal Robustness against Data Poisoning. (arXiv:2302.03684v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.03684](http://arxiv.org/abs/2302.03684)

    该论文提出了一种针对数据污染的时序威胁模型，通过利用数据的时间戳，引入了提前时间和持续时间这两个指标，从而定义了数据污染的时序鲁棒性，并提供了一种有效的保护方法。

    

    数据污染考虑了通过恶意训练数据操纵机器学习算法行为的情况。现有的数据污染威胁模型都围绕着一个单一指标，即被污染样本的数量。因此，如果攻击者能够以可承受的代价污染比预期更多的样本，就像许多实际场景中一样，他们可能能够在很短的时间内使现有的防御措施失效。为了解决这个问题，我们利用数据的出生日期时间戳，这些时间戳通常是可用的但过去被忽略。利用这些时间戳，我们提出了一个带有两个新型指标（提前时间和持续时间）的数据污染的时序威胁模型，分别衡量攻击提前开始的时间和攻击持续的时间。利用这些指标，我们定义了数据污染的时序鲁棒性的概念，即使有大量被污染的样本，也能提供有意义的保护。我们提出一种方法

    Data poisoning considers cases when an adversary manipulates the behavior of machine learning algorithms through malicious training data. Existing threat models of data poisoning center around a single metric, the number of poisoned samples. In consequence, if attackers can poison more samples than expected with affordable overhead, as in many practical scenarios, they may be able to render existing defenses ineffective in a short time. To address this issue, we leverage timestamps denoting the birth dates of data, which are often available but neglected in the past. Benefiting from these timestamps, we propose a temporal threat model of data poisoning with two novel metrics, earliness and duration, which respectively measure how long an attack started in advance and how long an attack lasted. Using these metrics, we define the notions of temporal robustness against data poisoning, providing a meaningful sense of protection even with unbounded amounts of poisoned samples. We present a 
    
[^94]: 一个几何感知的自编码器用于多纹理合成

    A geometrically aware auto-encoder for multi-texture synthesis. (arXiv:2302.01616v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.01616](http://arxiv.org/abs/2302.01616)

    一个几何感知的自编码器用于多纹理合成，通过紧凑的编码器和自适应周期内容的生成器，在几何一致的潜在空间中进行纹理表示和空间组织的分离，从而提高了纹理合成和插值任务的性能。

    

    我们提出了一个用于多纹理合成的自编码器架构。该方法依赖于一个紧凑的编码器，考虑了二阶神经统计信息，以及一个包含自适应周期内容的生成器。图像被嵌入到一个紧凑且几何一致的潜在空间中，在这个空间中纹理表示和其空间组织被分离。纹理合成和插值任务可以直接从这些潜在代码中完成。我们的实验证明，我们的模型在视觉质量和各种纹理相关度量方面优于最先进的前向方法。

    We propose an auto-encoder architecture for multi-texture synthesis. The approach relies on both a compact encoder accounting for second order neural statistics and a generator incorporating adaptive periodic content. Images are embedded in a compact and geometrically consistent latent space, where the texture representation and its spatial organisation are disentangled. Texture synthesis and interpolation tasks can be performed directly from these latent codes. Our experiments demonstrate that our model outperforms state-of-the-art feed-forward methods in terms of visual quality and various texture related metrics.
    
[^95]: DeciLS-PBO:一种有效的用于伪布尔优化的局部搜索方法

    DeciLS-PBO: an Effective Local Search Method for Pseudo-Boolean Optimization. (arXiv:2301.12251v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.12251](http://arxiv.org/abs/2301.12251)

    本文提出了一种名为DeciLS-PBO的有效的局部搜索方法，可以用于解决伪布尔优化问题。通过扩展基于单元传播的减少算法，并引入基于特征学习的子句权重计算方法，该方法在PBO问题的求解中取得了显著的进展。

    

    局部搜索方法是解决大规模组合优化问题的一种有效方法，并且通过几种微妙的机制在最近几年取得了显著的进展。本文在解决伪布尔优化（PBO）的局部搜索算法中发现了两种改进方法：首先，一些机制如单元传播仅仅用于解决MaxSAT问题，但同样可以推广到解决PBO问题；其次，现有的局部搜索算法利用变量的启发式评分来引导搜索。我们试图对从变量到给定公式之间建立桥梁的子句进行更深入的研究，因为子句在其中起到了中间人的作用。因此，我们首先将基于单元传播的减少算法扩展到PBO问题中，为PBO问题给出了更进一步的广义定义，并将其应用于现有的求解器LS-PBO以构建初始分配；然后，我们介绍了一种基于特征学习的子句权重计算方法。

    Local search is an effective method for solving large-scale combinatorial optimization problems, and it has made remarkable progress in recent years through several subtle mechanisms. In this paper, we found two ways to improve the local search algorithms in solving Pseudo-Boolean Optimization (PBO): Firstly, some of those mechanisms such as unit propagation are merely used in solving MaxSAT before, which can be generalized to solve PBO as well; Secondly, the existing local search algorithms utilize the heuristic on variables, so-called score, to mainly guide the search. We attempt to gain more insights into the clause, as it plays the role of a middleman who builds a bridge between variables and the given formula. Hence, we first extended the combination of unit propagation-based decimation algorithm to PBO problem, giving a further generalized definition of unit clause for PBO problem, and apply it to the existing solver LS-PBO for constructing an initial assignment; then, we introdu
    
[^96]: 一种贝叶斯大脑的组合性解释的数学基础

    Mathematical Foundations for a Compositional Account of the Bayesian Brain. (arXiv:2212.12538v2 [q-bio.NC] UPDATED)

    [http://arxiv.org/abs/2212.12538](http://arxiv.org/abs/2212.12538)

    本文通过应用范畴论的方法为近似推断提供了函子语义，同时还提出了贝叶斯透镜的概念和统计博弈的纤维，对统计推断问题进行了分类。

    

    本篇论文报告了关于主动推断和贝叶斯大脑组合性解释的一些初步研究。具体而言，我们使用当代应用范畴论的工具为近似推断提供了函子语义。为此，我们在“语法”方面定义了新的贝叶斯透镜的概念，并展示了贝叶斯更新遵循组合透镜模式。利用贝叶斯透镜，并受组合博弈论的启发，我们定义了统计博弈的纤维和将各种统计推断问题分类为对应的部分：相对熵的链式规则被形式化为严格部分，而最大似然估计和自由能则给出了松弛部分。在这个过程中，我们引入了一种新的“复制-组合”的概念。在“语义”方面，我们将一般的开放动力系统（尤其是确定性、随机性和随机性，以及离散和连续时间）作为证明。

    This dissertation reports some first steps towards a compositional account of active inference and the Bayesian brain. Specifically, we use the tools of contemporary applied category theory to supply functorial semantics for approximate inference. To do so, we define on the `syntactic' side the new notion of Bayesian lens and show that Bayesian updating composes according to the compositional lens pattern. Using Bayesian lenses, and inspired by compositional game theory, we define fibrations of statistical games and classify various problems of statistical inference as corresponding sections: the chain rule of the relative entropy is formalized as a strict section, while maximum likelihood estimation and the free energy give lax sections. In the process, we introduce a new notion of `copy-composition'.  On the `semantic' side, we present a new formalization of general open dynamical systems (particularly: deterministic, stochastic, and random; and discrete- and continuous-time) as cert
    
[^97]: 基于运动信息的时间演进相机录像中小昆虫的对象检测

    Motion Informed Object Detection of Small Insects in Time-lapse Camera Recordings. (arXiv:2212.00423v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.00423](http://arxiv.org/abs/2212.00423)

    本文提出了一种基于运动信息的方法，用于在时间演进相机录像中检测小昆虫。通过提供一个包含大量标注昆虫的数据集，采用预处理和基于运动信息的增强技术，该方法能够有效地在复杂动态场景中提取昆虫。

    

    作为传粉媒介，昆虫在生态系统管理和全球粮食生产中起着至关重要的作用。然而，昆虫数量正在下降，需要高效的昆虫监测方法。现有的方法通过分析昆虫在自然环境中的视频或时间演进图像来进行，但由于昆虫是复杂动态场景中的小物体，分析变得具有挑战性。本研究提供了一个数据集，包括夏季两个月期间三种不同植物物种上的107,387个经过标注的时间演进图像，其中包含9,423个标注昆虫。我们提出了一种用于检测时间演进RGB图像中昆虫的方法流程。该流程由两个步骤组成。首先，对时间演进RGB图像进行预处理，以增强图像中的昆虫。该基于运动信息的增强技术使用运动和颜色来增强图像中的昆虫。然后，将增强后的图像输入到卷积神经网络进行检测。

    Insects as pollinators play a crucial role in ecosystem management and world food production. However, insect populations are declining, calling for efficient methods of insect monitoring. Existing methods analyze video or time-lapse images of insects in nature, but the analysis is challenging since insects are small objects in complex and dynamic scenes of natural vegetation. In this work, we provide a dataset of primary honeybees visiting three different plant species during two months of the summer period. The dataset consists of 107,387 annotated time-lapse images from multiple cameras, including 9,423 annotated insects. We present a method pipeline for detecting insects in time-lapse RGB images. The pipeline consists of a two-step process. Firstly, the time-lapse RGB images are preprocessed to enhance insects in the images. This Motion-Informed-Enhancement technique uses motion and colors to enhance insects in images. Secondly, the enhanced images are subsequently fed into a Convo
    
[^98]: iSmallNet: 基于标签解耦的密集嵌套网络用于红外小目标检测

    iSmallNet: Densely Nested Network with Label Decoupling for Infrared Small Target Detection. (arXiv:2210.16561v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.16561](http://arxiv.org/abs/2210.16561)

    iSmallNet是一种采用标签解耦的密集嵌套网络，用于红外小目标检测。它通过解耦标签信息和引入关键模块来提升检测性能，包括多尺度嵌套交互模块和内部边界融合模块。

    

    红外图像中的小目标常常被杂乱的背景所掩盖。传统的检测器往往会产生误报，而基于CNN的检测器则会在深层中丢失小目标。为此，我们提出了一种名为iSmallNet的多流密集嵌套网络，采用标签解耦来用于红外小目标检测。一方面，为了充分利用小目标的形状信息，我们将原始的标记地面真值(GT)图解耦为内部图和边界图。GT图与另外两张图协同工作，以解决小目标边界的不均衡分布问题。另一方面，我们精心设计并融入了两个关键模块到提议的网络中，以提高整体性能。首先，为了在深层中保留小目标，我们开发了一个多尺度嵌套交互模块来探索广泛的上下文信息。其次，我们开发了一个内部边界融合模块来集成多粒度信息。

    Small targets are often submerged in cluttered backgrounds of infrared images. Conventional detectors tend to generate false alarms, while CNN-based detectors lose small targets in deep layers. To this end, we propose iSmallNet, a multi-stream densely nested network with label decoupling for infrared small object detection. On the one hand, to fully exploit the shape information of small targets, we decouple the original labeled ground-truth (GT) map into an interior map and a boundary one. The GT map, in collaboration with the two additional maps, tackles the unbalanced distribution of small object boundaries. On the other hand, two key modules are delicately designed and incorporated into the proposed network to boost the overall performance. First, to maintain small targets in deep layers, we develop a multi-scale nested interaction module to explore a wide range of context information. Second, we develop an interior-boundary fusion module to integrate multi-granularity information.
    
[^99]: 在有向无环图上的Transformer

    Transformers over Directed Acyclic Graphs. (arXiv:2210.13148v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.13148](http://arxiv.org/abs/2210.13148)

    本文研究了在有向无环图上的Transformer。通过改进注意机制和位置编码，本方法在多种任务上表现出了很好的效果。

    

    最近，Transformer模型在图表示学习中变得流行起来，因为它们有能力学习超出常规图神经网络捕捉到的复杂关系。主要的研究问题是如何将图的结构偏差注入到Transformer的架构中，并针对有向无环图（DAGs）提出了一些适应性的架构改进：（1）一个比常规Transformer的二次复杂度更高效的注意机制，同时忠实地捕捉了DAGs的结构，（2）一个对DAG的偏序进行位置编码，补充了前者。我们对我们的方法在各种类型的任务上进行了严格的评估，从对源代码图的分类到对引用网络中的节点，结果显示它在两个重要的任务上是有效的。

    Transformer models have recently gained popularity in graph representation learning as they have the potential to learn complex relationships beyond the ones captured by regular graph neural networks. The main research question is how to inject the structural bias of graphs into the transformer architecture, and several proposals have been made for undirected molecular graphs and, recently, also for larger network graphs. In this paper, we study transformers over directed acyclic graphs (DAGs) and propose architecture adaptations tailored to DAGs: (1) An attention mechanism that is considerably more efficient than the regular quadratic complexity of transformers and at the same time faithfully captures the DAG structure, and (2) a positional encoding of the DAG's partial order, complementing the former. We rigorously evaluate our approach over various types of tasks, ranging from classifying source code graphs to nodes in citation networks, and show that it is effective in two importan
    
[^100]: SAFER:使用强化学习的聚焦高效轨迹搜索的安全避障机制

    SAFER: Safe Collision Avoidance using Focused and Efficient Trajectory Search with Reinforcement Learning. (arXiv:2209.11789v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2209.11789](http://arxiv.org/abs/2209.11789)

    SAFER是一种高效有效的碰撞避障系统，通过纠正控制指令来提高安全性。它结合了强化学习、在线轨迹规划和自动紧急干预。强化学习的目标是学习有效的纠正控制动作，减少紧急制动的频率。实验结果显示，与基准方法相比，SAFER具有更高的速度、更低的碰撞率和较小的计算开销。

    

    避免碰撞是移动机器人和智能体安全运作于现实世界的关键。本文介绍了一种名为SAFER的高效有效的碰撞避障系统，能够通过纠正操作者发送的控制指令来提高安全性。它结合了现实世界的强化学习（RL），基于搜索的在线轨迹规划和自动紧急干预，例如自动紧急制动（AEB）。强化学习的目标是学习一种有效的纠正控制动作，用于聚焦搜索无碰撞轨迹，并减少触发紧急制动的频率。这种新颖的设置使得强化学习策略能够在真实室内环境中在移动机器人上安全学习，即使在训练过程中，也能最大限度地减少实际碰撞。我们的实际实验显示，与几种基准方法相比，我们的方法具有更高的平均速度，更低的碰撞率，更少的紧急干预和较小的计算开销。

    Collision avoidance is key for mobile robots and agents to operate safely in the real world. In this work we present SAFER, an efficient and effective collision avoidance system that is able to improve safety by correcting the control commands sent by an operator. It combines real-world reinforcement learning (RL), search-based online trajectory planning, and automatic emergency intervention, e.g. automatic emergency braking (AEB). The goal of the RL is to learn an effective corrective control action that is used in a focused search for collision-free trajectories, and to reduce the frequency of triggering automatic emergency braking. This novel setup enables the RL policy to learn safely and directly on mobile robots in a real-world indoor environment, minimizing actual crashes even during training. Our real-world experiments show that, when compared with several baselines, our approach enjoys a higher average speed, lower crash rate, less emergency intervention, smaller computation o
    
[^101]: MAGIC: 通过反转准鲁棒分类器实现基于掩码的图像合成

    MAGIC: Mask-Guided Image Synthesis by Inverting a Quasi-Robust Classifier. (arXiv:2209.11549v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.11549](http://arxiv.org/abs/2209.11549)

    本论文提出了一种名为MAGIC的方法，通过反转准鲁棒分类器进行一次性掩码引导的图像合成。它通过聚合梯度并利用强空间先验的指导二进制掩码，实现了形状和位置控制、非刚性形状变形以及复制/移动操作，并可简单指定二进制引导掩码来提供强大的合成控制。

    

    我们提供了一种一次性掩码引导图像合成的方法，通过反转带有强正则化器的准鲁棒分类器来控制对单个图像的操作。我们提出的方法名为MAGIC，利用来自预训练的准鲁棒分类器的结构化梯度，可以更好地保留输入的语义，并保持其分类准确性，从而保证合成的可信度。与目前使用复杂原语来监督过程或使用注意力图作为弱监督信号的方法不同，MAGIC通过在输入上聚合梯度，由强空间先验的指导二进制掩码推动。MAGIC以单个框架实现了一系列操作，实现了形状和位置控制、强烈的非刚性形状变形以及在重复物体存在的情况下的复制/移动操作，并通过简单指定二进制引导掩码来给用户提供强大的合成控制。

    We offer a method for one-shot mask-guided image synthesis that allows controlling manipulations of a single image by inverting a quasi-robust classifier equipped with strong regularizers. Our proposed method, entitled MAGIC, leverages structured gradients from a pre-trained quasi-robust classifier to better preserve the input semantics while preserving its classification accuracy, thereby guaranteeing credibility in the synthesis. Unlike current methods that use complex primitives to supervise the process or use attention maps as a weak supervisory signal, MAGIC aggregates gradients over the input, driven by a guide binary mask that enforces a strong, spatial prior. MAGIC implements a series of manipulations with a single framework achieving shape and location control, intense non-rigid shape deformations, and copy/move operations in the presence of repeating objects and gives users firm control over the synthesis by requiring to simply specify binary guide masks. Our study and findin
    
[^102]: 语言模型作为知识嵌入

    Language Models as Knowledge Embeddings. (arXiv:2206.12617v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.12617](http://arxiv.org/abs/2206.12617)

    该论文提出了一种使用语言模型来推导知识嵌入的方法LMKE，它旨在提高对丰富的长尾实体的表示能力并解决基于描述的先前方法的问题，实验结果表明该方法在多个基准数据集上实现了最先进的性能。

    

    知识嵌入是通过将实体和关系嵌入到连续向量空间中来表示知识图谱的一种方法。现有的方法主要是基于结构或基于描述。基于结构的方法学习表示，以保留知识图谱的内在结构。它们不能很好地表示现实世界知识图谱中有限结构信息下丰富的长尾实体。基于描述的方法利用文本信息和语言模型。在这个方向上的先前方法几乎无法超越基于结构的方法，并且存在昂贵的负采样和限制性描述需求等问题。在本文中，我们提出了LMKE，采用语言模型来推导知识嵌入，旨在丰富长尾实体的表示并解决基于描述的先前方法的问题。我们用对比学习框架来表述基于描述的知识嵌入学习，以提高训练和评价的效率。实验结果表明，LMKE在多个基准数据集上实现了最先进的性能，超越了基于结构和基于先前描述的方法。

    Knowledge embeddings (KE) represent a knowledge graph (KG) by embedding entities and relations into continuous vector spaces. Existing methods are mainly structure-based or description-based. Structure-based methods learn representations that preserve the inherent structure of KGs. They cannot well represent abundant long-tail entities in real-world KGs with limited structural information. Description-based methods leverage textual information and language models. Prior approaches in this direction barely outperform structure-based ones, and suffer from problems like expensive negative sampling and restrictive description demand. In this paper, we propose LMKE, which adopts Language Models to derive Knowledge Embeddings, aiming at both enriching representations of long-tail entities and solving problems of prior description-based methods. We formulate description-based KE learning with a contrastive learning framework to improve efficiency in training and evaluation. Experimental resul
    
[^103]: N$^2$M$^2$: 在未知和动态环境中学习任意移动操纵动作的导航

    N$^2$M$^2$: Learning Navigation for Arbitrary Mobile Manipulation Motions in Unseen and Dynamic Environments. (arXiv:2206.08737v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2206.08737](http://arxiv.org/abs/2206.08737)

    N$^2$M$^2$是一个新的移动操纵导航系统，能够在未知和动态环境中执行各种任务，包括复杂的障碍物环境，同时具备末端执行器轨迹生成和导航技能的无缝集成能力。

    

    尽管在工业和服务机器人中具有重要性，移动操纵仍然是一个巨大的挑战，因为它要求将末端执行器轨迹生成与导航技能以及在长时间范围内进行推理的无缝集成。现有方法难以控制大型配置空间，无法在动态和未知环境中进行导航。在先前的工作中，我们提出将移动操纵任务分解为任务空间中末端执行器的简化运动生成器和针对运动的运动基准学习强化学习代理。在这项工作中，我们引入了神经网络导航移动操纵（N$^2$M$^2$），它将这种分解推广到复杂的障碍环境，并使其能够处理真实世界情况下的广泛任务。由此产生的方法可以在未知环境中执行未见过的、长时间范围内的任务，并即时应对动态障碍物和环境变化。

    Despite its importance in both industrial and service robotics, mobile manipulation remains a significant challenge as it requires a seamless integration of end-effector trajectory generation with navigation skills as well as reasoning over long-horizons. Existing methods struggle to control the large configuration space, and to navigate dynamic and unknown environments. In previous work, we proposed to decompose mobile manipulation tasks into a simplified motion generator for the end-effector in task space and a trained reinforcement learning agent for the mobile base to account for kinematic feasibility of the motion. In this work, we introduce Neural Navigation for Mobile Manipulation (N$^2$M$^2$) which extends this decomposition to complex obstacle environments and enables it to tackle a broad range of tasks in real world settings. The resulting approach can perform unseen, long-horizon tasks in unexplored environments while instantly reacting to dynamic obstacles and environmental
    
[^104]: “这是一个可疑的反应！”：解读概率变化以检测NLP对抗攻击。

    "That Is a Suspicious Reaction!": Interpreting Logits Variation to Detect NLP Adversarial Attacks. (arXiv:2204.04636v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2204.04636](http://arxiv.org/abs/2204.04636)

    这项工作提出了一个模型无关的对抗文本检测器，通过识别目标分类器的概率中的模式来改进对抗输入的识别性能，并具有较强的泛化能力。

    

    对抗攻击是当前机器学习研究面临的主要挑战。这些有意制作的输入甚至可以欺骗最先进的模型，使其无法在安全关键的应用中部署。计算机视觉领域已经进行了大量研究以开发可靠的防御策略。然而，在自然语言处理中，同样的问题仍然没有得到深入探究。我们的工作提出了一个对抗文本示例的模型无关检测器。该方法通过扰动输入文本时在目标分类器的概率中识别模式。所提出的检测器在识别对抗输入方面提高了当前技术水平，并展示了在不同的NLP模型、数据集和词级攻击中具有较强的泛化能力。

    Adversarial attacks are a major challenge faced by current machine learning research. These purposely crafted inputs fool even the most advanced models, precluding their deployment in safety-critical applications. Extensive research in computer vision has been carried to develop reliable defense strategies. However, the same issue remains less explored in natural language processing. Our work presents a model-agnostic detector of adversarial text examples. The approach identifies patterns in the logits of the target classifier when perturbing the input text. The proposed detector improves the current state-of-the-art performance in recognizing adversarial inputs and exhibits strong generalization capabilities across different NLP models, datasets, and word-level attacks.
    
[^105]: 走向预测计算的透视主义真实性验证转变

    Toward a Perspectivist Turn in Ground Truthing for Predictive Computing. (arXiv:2109.04270v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2109.04270](http://arxiv.org/abs/2109.04270)

    本文提出了一种新的范式，数据透视主义，用于机器学习中的知识表示步骤。这种方法整合了人类参与者的观点和角度，相较于传统黄金标准数据集，具有更多潜力和优势。

    

    大多数人工智能应用基于监督式机器学习，而监督式机器学习最终依赖手动注释的数据。注释过程通常以多数票为基础，但最近的研究表明这种方法常常存在问题。本文描述并倡导一种不同的范式，我们称之为数据透视主义，它摆脱了传统的黄金标准数据集，转向采用整合人类参与的角度和观点的方法来进行机器学习过程中的知识表示步骤。借鉴启发我们提议的前人作品，我们描述了我们的提议对于不仅是更主观的任务（例如与人类语言有关的任务），而且对于通常被视为客观的任务（例如医疗决策）的潜力，并介绍了采用透视主义立场在机器学习中的主要优势，以及可能的...

    Most Artificial Intelligence applications are based on supervised machine learning (ML), which ultimately grounds on manually annotated data. The annotation process is often performed in terms of a majority vote and this has been proved to be often problematic, as highlighted by recent studies on the evaluation of ML models. In this article we describe and advocate for a different paradigm, which we call data perspectivism, which moves away from traditional gold standard datasets, towards the adoption of methods that integrate the opinions and perspectives of the human subjects involved in the knowledge representation step of ML processes. Drawing on previous works which inspired our proposal we describe the potential of our proposal for not only the more subjective tasks (e.g. those related to human language) but also to tasks commonly understood as objective (e.g. medical decision making), and present the main advantages of adopting a perspectivist stance in ML, as well as possible d
    
[^106]: 模拟人类和人工情感 (SHArE)的研究

    Simulation of Human and Artificial Emotion (SHArE). (arXiv:2011.02151v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2011.02151](http://arxiv.org/abs/2011.02151)

    这项研究介绍了模拟人类和人工情感的框架，为人类的心理健康问题提供了新的治疗方案，并且为人工智能提供了一种观察机器情感和动机的方法。

    

    模拟人类和人工情感 (SHArE) 的框架描述了情感的架构，可以在心理学、神经科学和人工智能之间进行参数转移。这些参数可以被定义为抽象概念，也可以细化到个体神经元的电压水平。该模型使得可以设计人类的情感轨迹，从而可能为各种心理健康问题提供新的治疗方案。对于人工智能而言，这项工作提供了一种紧凑的表示方法，可以应用于神经网络，以观察机器的情感和动机。

    The framework for Simulation of Human and Artificial Emotion (SHArE) describes the architecture of emotion in terms of parameters transferable between psychology, neuroscience, and artificial intelligence. These parameters can be defined as abstract concepts or granularized down to the voltage levels of individual neurons. This model enables emotional trajectory design for humans which may lead to novel therapeutic solutions for various mental health concerns. For artificial intelligence, this work provides a compact notation which can be applied to neural networks as a means to observe the emotions and motivations of machines.
    
[^107]: 使用机器教学研究教授强化学习者时人类的假设

    Using Machine Teaching to Investigate Human Assumptions when Teaching Reinforcement Learners. (arXiv:2009.02476v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2009.02476](http://arxiv.org/abs/2009.02476)

    本文研究了在线奖励和惩罚方法下，人们对于学习者的期望假设，发现人们假设学习者具有高的折扣率和高度重视探索，并根据学习者进展调整教学策略。

    

    为成功教学，需要对学习者学习方式进行假设，即学习者如何使用来自世界的经验来更新其内部状态。本文研究了在线奖励和惩罚方法下，人们对于学习者的期望假设。研究重点是一种常见的强化学习方法 Q-learning，通过行为实验考察人们的假设。为了达到此目的，我们首先建立了一个规范标准，将问题形式化为机器教学优化问题。为了解决机器教学优化问题，我们使用深度学习逼近方法来模拟学习者在环境中的表现，并学习预测反馈如何影响学习者的内部状态。在教授理想化的探索利用任务时，人们对学习者的学习和折扣率有哪些假设？在行为实验中，我们发现人们可以相对高效和准确地教导 Q-学习者这项任务。人们倾向于假设学习者具有高的折扣率，并高度重视探索。此外，人们会根据学习者的进展调整自己的教学策略。

    Successful teaching requires an assumption of how the learner learns - how the learner uses experiences from the world to update their internal states. We investigate what expectations people have about a learner when they teach them in an online manner using rewards and punishment. We focus on a common reinforcement learning method, Q-learning, and examine what assumptions people have using a behavioral experiment. To do so, we first establish a normative standard, by formulating the problem as a machine teaching optimization problem. To solve the machine teaching optimization problem, we use a deep learning approximation method which simulates learners in the environment and learns to predict how feedback affects the learner's internal states. What do people assume about a learner's learning and discount rates when they teach them an idealized exploration-exploitation task? In a behavioral experiment, we find that people can teach the task to Q-learners in a relatively efficient and 
    

