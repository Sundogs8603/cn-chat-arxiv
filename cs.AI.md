# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Offline Imitation from Observation via Primal Wasserstein State Occupancy Matching.](http://arxiv.org/abs/2311.01331) | 本论文提出了一种通过最小化原始Wasserstein距离来匹配专家和学习者状态占用的方法，以解决离线学习从观察中模仿任务的问题。 |
| [^2] | [SERA:Sample Efficient Reward Augmentation in offline-to-online Reinforcement Learning.](http://arxiv.org/abs/2310.19805) | 这篇论文提出了一种称为SERA的奖励增强框架，用于改善离线到在线强化学习中的探索能力。它通过设计内在奖励来鼓励agent进行探索，并实现更好的在线微调效果。 |
| [^3] | [Personas as a Way to Model Truthfulness in Language Models.](http://arxiv.org/abs/2310.18168) | 本研究探讨了在大型语言模型中使用人设来建模真实性的可能性。通过建模真实人设，语言模型可以将真实性推广到不同上下文中，并通过相关特征判断个体产生文本的真实性。 |
| [^4] | [Unified Segment-to-Segment Framework for Simultaneous Sequence Generation.](http://arxiv.org/abs/2310.17940) | 这篇论文提出了一种统一的片段到片段框架 (Seg2Seg) 用于同时序列生成，通过自适应和统一的方式学习源序列和目标序列之间的映射，实现高质量生成和低延迟。 |
| [^5] | [Absolute Policy Optimization.](http://arxiv.org/abs/2310.13230) | 这篇论文提出了绝对策略优化（APO）的方法，通过优化一个新颖的目标函数，在保证性能下界的同时，实现了连续控制任务和Atari游戏中的令人瞩目的结果。 |
| [^6] | [Tailoring Adversarial Attacks on Deep Neural Networks for Targeted Class Manipulation Using DeepFool Algorithm.](http://arxiv.org/abs/2310.13019) | 本文提出了一种增强版DeepFool算法，名为Targeted DeepFool，可以针对特定类别进行错误分类，并引入了最小置信度分数要求超参数来提高灵活性。 |
| [^7] | [Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation.](http://arxiv.org/abs/2309.06255) | 本文提出了一种精细的模态评估指标，用于评估每个模态在样本级别的贡献，并发现多模态模型倾向于依赖一个特定的模态，导致其他模态的贡献较低。 |
| [^8] | [An Efficient Temporary Deepfake Location Approach Based Embeddings for Partially Spoofed Audio Detection.](http://arxiv.org/abs/2309.03036) | 该论文提出了一种基于嵌入的临时Deepfake位置方法（TDL）用于部分伪造音频检测，通过嵌入相似性模块和时间卷积操作，能有效捕捉音频的特征和位置信息。实验结果表明，在ASVspoof2019 Partial Spoof数据集中，该方法优于基准模型。 |
| [^9] | [Unsupervised discovery of Interpretable Visual Concepts.](http://arxiv.org/abs/2309.00018) | 本文提出了两种方法（MAGE和Ms-IV），用于解释深度学习模型的决策，提高全局可解释性。MAGE可以发现形成语义含义的特征组合，将其称为概念，并通过聚类分组为“概念”，然后通过Ms-IV进行可视化。这一方法受到阻断和敏感性分析的启发，并使用一种新的指标（CaOC）全局评估模型最重要的图像区域。 |
| [^10] | [survex: an R package for explaining machine learning survival models.](http://arxiv.org/abs/2308.16113) | survex是一个R软件包，通过应用可解释的人工智能技术，提供了一个连贯的框架来解释任何生存模型，可以改进模型，提高透明度和责任感。 |
| [^11] | [Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting.](http://arxiv.org/abs/2307.11494) | 本研究提出了一种面向概率时间序列预测的自引导扩散模型，称为TSDiff。该模型不需要辅助网络或训练过程的改变，在预测、改进和合成数据生成等时间序列任务上展现出了竞争力。 |
| [^12] | [Multi-Stage Cable Routing through Hierarchical Imitation Learning.](http://arxiv.org/abs/2307.08927) | 本研究探讨了多阶段电缆布线任务中的层次化模仿学习方法，解决了处理可变形物体、视觉感知闭环和扩展行为的挑战。成功控制器需要能够从失败中恢复，并通过选择纠正低级控制器的缺陷。 |
| [^13] | [Causal Reinforcement Learning: A Survey.](http://arxiv.org/abs/2307.01452) | 这项综述总结了因果强化学习的研究文献，强调因果关系的重要作用，它能够形式化知识并实现有效的知识传递。 |
| [^14] | [Learning from Synthetic Human Group Activities.](http://arxiv.org/abs/2306.16772) | 提出了M3Act，一个多视图多团队多人的人类原子动作和团队活动数据生成器，通过Unity引擎驱动实现。该生成器具有大规模数据生成、多模态和高质量注释等特点，能够用于研究复杂的人类互动和团队活动。 |
| [^15] | [Exploring Inductive Biases in Contrastive Learning: A Clustering Perspective.](http://arxiv.org/abs/2305.10229) | 本文比较了对比学习和监督学习方法形成的簇，揭示了对比学习可以生成具有局部密度但无全局密度的簇，而监督学习创建具有局部和全局密度的簇。同时，作者提出了使用图卷积网络分类器作为处理局部密集簇的线性分类器的替代方法，并利用t-SNE可视化证明了对比和监督学习方法产生的特征之间的差异。 |
| [^16] | [DroidBot-GPT: GPT-powered UI Automation for Android.](http://arxiv.org/abs/2304.07061) | DroidBot-GPT是一款利用GPT模型自动化Android应用程序的工具，可以根据任务的自然语言描述自动生成并执行操作，有望提高移动应用程序的测试和开发效率。 |
| [^17] | [The Short Text Matching Model Enhanced with Knowledge via Contrastive Learning.](http://arxiv.org/abs/2304.03898) | 提出了一种短文本匹配模型，使用生成模型生成补充句子，结合对比学习和外部知识进行语义匹配，并使用关键词避免噪声问题。 |
| [^18] | [Finding Alignments Between Interpretable Causal Variables and Distributed Neural Representations.](http://arxiv.org/abs/2303.02536) | 本文提出了分布式对齐搜索（DAS）算法，可以在不使用暴力搜索的情况下找到高层因果模型和低层深度学习系统之间的对齐方法，并且DAS可以发现先前方法忽略的内部结构。DAS算法有潜力实现对复杂深度学习系统的更好解释和理解。 |
| [^19] | [Long-term Causal Effects Estimation via Latent Surrogates Representation Learning.](http://arxiv.org/abs/2208.04589) | Laser 是一种基于潜在代理表示学习的估计长期因果效应的灵活方法，能够在代理和其代理混合在一起的真实世界情景中应用。 |
| [^20] | [Relphormer: Relational Graph Transformer for Knowledge Graph Representations.](http://arxiv.org/abs/2205.10852) | Relphormer是一种新的Transformer变体，用于知识图谱表示。它引入了Triple2Seq和增强式自我注意机制，以解决基本Transformer架构在捕捉知识图谱结构和语义信息方面的不足。 |

# 详细

[^1]: 通过原始Wasserstein状态占用匹配实现的离线观察模仿

    Offline Imitation from Observation via Primal Wasserstein State Occupancy Matching. (arXiv:2311.01331v1 [cs.LG])

    [http://arxiv.org/abs/2311.01331](http://arxiv.org/abs/2311.01331)

    本论文提出了一种通过最小化原始Wasserstein距离来匹配专家和学习者状态占用的方法，以解决离线学习从观察中模仿任务的问题。

    

    在现实世界的情境中，与环境的任意交互往往是昂贵的，并且专家示范的行为并不总是可用的。为了减少这两者的需求，离线学习从观察（LfO）得到了广泛研究，其中代理通过只有专家状态和与任务无关的非专家状态-动作对来学习解决任务。最先进的分布校正估计（DICE）方法最小化了学习者和专家策略之间的状态占用差异。然而，它们仅限于$f$-divergences（KL和$\chi^2$）或带有Rubinstein对偶的Wasserstein距离，后者限制了对性能关键的基础距离度量的使用。为了解决这个问题，我们提出了原始Wasserstein DICE（PW-DICE），它通过悲观正则化器最小化专家和学习者状态占用之间的原始Wasserstein距离，并利用了对比学习的dis

    In real-world scenarios, arbitrary interactions with the environment can often be costly, and actions of expert demonstrations are not always available. To reduce the need for both, Offline Learning from Observations (LfO) is extensively studied, where the agent learns to solve a task with only expert states and \textit{task-agnostic} non-expert state-action pairs. The state-of-the-art DIstribution Correction Estimation (DICE) methods minimize the state occupancy divergence between the learner and expert policies. However, they are limited to either $f$-divergences (KL and $\chi^2$) or Wasserstein distance with Rubinstein duality, the latter of which constrains the underlying distance metric crucial to the performance of Wasserstein-based solutions. To address this problem, we propose Primal Wasserstein DICE (PW-DICE), which minimizes the primal Wasserstein distance between the expert and learner state occupancies with a pessimistic regularizer and leverages a contrastively learned dis
    
[^2]: SERA：离线到在线强化学习中的样本高效奖励增强

    SERA:Sample Efficient Reward Augmentation in offline-to-online Reinforcement Learning. (arXiv:2310.19805v1 [cs.LG])

    [http://arxiv.org/abs/2310.19805](http://arxiv.org/abs/2310.19805)

    这篇论文提出了一种称为SERA的奖励增强框架，用于改善离线到在线强化学习中的探索能力。它通过设计内在奖励来鼓励agent进行探索，并实现更好的在线微调效果。

    

    离线强化学习的一个潜在应用是使用现有的静态数据集来初始化预训练策略，然后进行后续在线微调。然而，直接对离线预训练策略进行微调往往会导致次优性能。主要原因是离线保守方法降低了agent的探索能力，从而影响了在线微调的性能。为了增强在线微调过程中的探索能力，从而提高整体的在线微调性能，我们引入了一种称为样本高效奖励增强（SERA）的通用奖励增强框架。SERA旨在通过设计鼓励agent进行探索的内在奖励来改善在线微调的性能。具体来说，它隐式地实现了状态边缘匹配（SMM）并惩罚超出分布范围的状态行动，从而鼓励agent覆盖目标状态密度，并实现更好的在线微调结果。

    A prospective application of offline reinforcement learning (RL) involves initializing a pre-trained policy using existing static datasets for subsequent online fine-tuning. However, direct fine-tuning of the offline pre-trained policy often results in sub-optimal performance. A primary reason is that offline conservative methods diminish the agent's capability of exploration, thereby impacting online fine-tuning performance. To enhance exploration during online fine-tuning and thus enhance the overall online fine-tuning performance, we introduce a generalized reward augmentation framework called Sample Efficient Reward Augmentation (SERA). SERA aims to improve the performance of online fine-tuning by designing intrinsic rewards that encourage the agent to explore. Specifically, it implicitly implements State Marginal Matching (SMM) and penalizes out-of-distribution (OOD) state actions, thus encouraging agents to cover the target state density, and achieving better online fine-tuning r
    
[^3]: 使用人设来建模语言模型中的真实性

    Personas as a Way to Model Truthfulness in Language Models. (arXiv:2310.18168v1 [cs.CL])

    [http://arxiv.org/abs/2310.18168](http://arxiv.org/abs/2310.18168)

    本研究探讨了在大型语言模型中使用人设来建模真实性的可能性。通过建模真实人设，语言模型可以将真实性推广到不同上下文中，并通过相关特征判断个体产生文本的真实性。

    

    大型语言模型使用互联网上的大量文本进行训练，这些文本中既包含了事实，也包含了误导性的信息。语言模型能够从这些相互矛盾的数据中辨别真实与虚假吗？基于语言模型能够建模不同产生文本的个体这一观点，我们假设它们可以通过建模真实人设来聚类真实文本：一群很可能产生真实文本并具有相似特征的个体。例如，可信源如维基百科和科学期刊通常使用正式的写作风格并提出一致的主张。通过建模这一人设，语言模型可以将真实性推广到每个个体生成训练文本的特定上下文之外。例如，模型可以推断出“维基百科”这个个体在“科学”生成的主题上会表现出真实性，因为它们共享一个人设。我们首先通过两个观察结果为人设假设提供了证据：（1）我们可以探测模型在不同领域中判断真实性的能力；（2）模型可以从相关特征中推测个体产生文本的真实性。

    Large Language Models are trained on vast amounts of text from the internet, which contains both factual and misleading information about the world. Can language models discern truth from falsehood in this contradicting data? Expanding on the view that LLMs can model different agents producing the corpora, we hypothesize that they can cluster truthful text by modeling a truthful persona: a group of agents that are likely to produce truthful text and share similar features. For example, trustworthy sources like Wikipedia and Science usually use formal writing styles and make consistent claims. By modeling this persona, LLMs can generalize truthfulness beyond the specific contexts in which each agent generated the training text. For example, the model can infer that the agent "Wikipedia" will behave truthfully on topics that were only generated by "Science" because they share a persona. We first show evidence for the persona hypothesis via two observations: (1) we can probe whether a mod
    
[^4]: 统一的片段到片段框架用于同时序列生成

    Unified Segment-to-Segment Framework for Simultaneous Sequence Generation. (arXiv:2310.17940v1 [cs.CL])

    [http://arxiv.org/abs/2310.17940](http://arxiv.org/abs/2310.17940)

    这篇论文提出了一种统一的片段到片段框架 (Seg2Seg) 用于同时序列生成，通过自适应和统一的方式学习源序列和目标序列之间的映射，实现高质量生成和低延迟。

    

    同时序列生成是实时场景的关键任务，比如流式语音识别、同时机器翻译和同时语音翻译，其中目标序列在接收源序列的同时生成。实现高质量生成和低延迟的关键在于确定生成的最佳时机，通过学习源序列和目标序列之间的映射实现。然而，现有方法往往依赖于特定任务的启发式方法，限制了模型对源-目标映射的自适应学习能力，阻碍了多任务学习在各种同时任务中的探索。本文提出了一种统一的片段到片段框架 (Seg2Seg) 用于同时序列生成，以自适应和统一的方式学习映射。在同时生成的过程中，模型在等待源片段和生成目标片段之间交替进行。

    Simultaneous sequence generation is a pivotal task for real-time scenarios, such as streaming speech recognition, simultaneous machine translation and simultaneous speech translation, where the target sequence is generated while receiving the source sequence. The crux of achieving high-quality generation with low latency lies in identifying the optimal moments for generating, accomplished by learning a mapping between the source and target sequences. However, existing methods often rely on task-specific heuristics for different sequence types, limiting the model's capacity to adaptively learn the source-target mapping and hindering the exploration of multi-task learning for various simultaneous tasks. In this paper, we propose a unified segment-to-segment framework (Seg2Seg) for simultaneous sequence generation, which learns the mapping in an adaptive and unified manner. During the process of simultaneous generation, the model alternates between waiting for a source segment and generat
    
[^5]: 绝对策略优化

    Absolute Policy Optimization. (arXiv:2310.13230v1 [cs.LG])

    [http://arxiv.org/abs/2310.13230](http://arxiv.org/abs/2310.13230)

    这篇论文提出了绝对策略优化（APO）的方法，通过优化一个新颖的目标函数，在保证性能下界的同时，实现了连续控制任务和Atari游戏中的令人瞩目的结果。

    

    近年来，基于信任域的在线策略强化学习在解决复杂控制任务和游戏场景方面取得了令人瞩目的结果。然而，这一类别中现有的最先进算法主要强调对预期性能的改进，缺乏对最坏情况下性能结果的控制能力。为了解决这个限制，我们引入了一个新颖的目标函数；通过优化该函数，可以确保近乎总体性能样本的下界（绝对性能）呈现单调改进。考虑到这一具有突破性的理论进展，我们通过一系列的近似对这个理论基础算法进行了改进，得到了一种实用的解决方案称为绝对策略优化（APO）。我们的实验证明了我们的方法在具有挑战性的连续控制基准任务上的有效性，并将其适用性扩展到掌握Atari游戏。我们的发现表明，APO在提高性能的同时也显著改善了最坏情况下的性能结果。

    In recent years, trust region on-policy reinforcement learning has achieved impressive results in addressing complex control tasks and gaming scenarios. However, contemporary state-of-the-art algorithms within this category primarily emphasize improvement in expected performance, lacking the ability to control over the worst-case performance outcomes. To address this limitation, we introduce a novel objective function; by optimizing which, it will lead to guaranteed monotonic improvement in the lower bound of near-total performance samples (absolute performance). Considering this groundbreaking theoretical advancement, we then refine this theoretically grounded algorithm through a series of approximations, resulting in a practical solution called Absolute Policy Optimization (APO). Our experiments demonstrate the effectiveness of our approach across challenging continuous control benchmark tasks and extend its applicability to mastering Atari games. Our findings reveal that APO signifi
    
[^6]: 通过DeepFool算法对深度神经网络进行有针对性的类别操纵的对抗攻击定制

    Tailoring Adversarial Attacks on Deep Neural Networks for Targeted Class Manipulation Using DeepFool Algorithm. (arXiv:2310.13019v1 [cs.CV])

    [http://arxiv.org/abs/2310.13019](http://arxiv.org/abs/2310.13019)

    本文提出了一种增强版DeepFool算法，名为Targeted DeepFool，可以针对特定类别进行错误分类，并引入了最小置信度分数要求超参数来提高灵活性。

    

    深度神经网络（DNNs）在各个领域都取得了显著的进展，但对抗攻击的易受攻击性引起了严重关注。了解这些易受攻击性并开发有效的防御机制至关重要。DeepFool是Moosavi-Dezfooli等人（2016年）提出的一种算法，用于找到将输入图像错误分类的最小扰动。然而，DeepFool缺乏有针对性的方法，使其在特定攻击场景中的有效性较低。此外，在先前的相关工作中，研究人员主要关注的是成功率，而没有考虑图像被扭曲的程度、图像质量的完整性以及错误分类的置信度水平。因此，在本文中，我们提出了Targeted DeepFool，这是DeepFool的增强版，可以针对特定类别进行错误分类。我们还引入了一个最小置信度分数要求超参数来增强灵活性。我们的实验证明了所提方法在不同情况下的有效性和效率。

    Deep neural networks (DNNs) have significantly advanced various domains, but their vulnerability to adversarial attacks poses serious concerns. Understanding these vulnerabilities and developing effective defense mechanisms is crucial. DeepFool, an algorithm proposed by Moosavi-Dezfooli et al. (2016), finds minimal perturbations to misclassify input images. However, DeepFool lacks a targeted approach, making it less effective in specific attack scenarios. Also, in previous related works, researchers primarily focus on success, not considering how much an image is getting distorted; the integrity of the image quality, and the confidence level to misclassifying. So, in this paper, we propose Targeted DeepFool, an augmented version of DeepFool that allows targeting specific classes for misclassification. We also introduce a minimum confidence score requirement hyperparameter to enhance flexibility. Our experiments demonstrate the effectiveness and efficiency of the proposed method across 
    
[^7]: 通过精细的模态评估增强多模态协作

    Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation. (arXiv:2309.06255v1 [cs.CV])

    [http://arxiv.org/abs/2309.06255](http://arxiv.org/abs/2309.06255)

    本文提出了一种精细的模态评估指标，用于评估每个模态在样本级别的贡献，并发现多模态模型倾向于依赖一个特定的模态，导致其他模态的贡献较低。

    

    多模态学习的一个主要问题是如何将来自不同模态的异质信息共同结合起来。然而，大多数模型在多模态协作方面常常存在不尽人意的问题，不能很好地共同利用所有模态。一些方法被提出来识别和增强学习效果较差的模态，但往往难以在理论上提供对样本级别多模态协作的细粒度观察和支持。因此，合理观察和改进模态之间细粒度的协作尤为重要，尤其是在面对模态差异在不同样本之间可能变化的实际场景时。为了实现这一目标，我们引入了一种精细的模态评估指标，以评估每个模态在样本级别的贡献。通过模态评估，我们遗憾地发现多模态模型倾向于依赖一个特定的模态，导致其他模态的贡献较低。我们进一步分析了这个问题。

    One primary topic of multi-modal learning is to jointly incorporate heterogeneous information from different modalities. However, most models often suffer from unsatisfactory multi-modal cooperation, which could not jointly utilize all modalities well. Some methods are proposed to identify and enhance the worse learnt modality, but are often hard to provide the fine-grained observation of multi-modal cooperation at sample-level with theoretical support. Hence, it is essential to reasonably observe and improve the fine-grained cooperation between modalities, especially when facing realistic scenarios where the modality discrepancy could vary across different samples. To this end, we introduce a fine-grained modality valuation metric to evaluate the contribution of each modality at sample-level. Via modality valuation, we regretfully observe that the multi-modal model tends to rely on one specific modality, resulting in other modalities being low-contributing. We further analyze this iss
    
[^8]: 基于嵌入的高效临时Deepfake位置方法用于部分伪造音频检测

    An Efficient Temporary Deepfake Location Approach Based Embeddings for Partially Spoofed Audio Detection. (arXiv:2309.03036v1 [cs.SD])

    [http://arxiv.org/abs/2309.03036](http://arxiv.org/abs/2309.03036)

    该论文提出了一种基于嵌入的临时Deepfake位置方法（TDL）用于部分伪造音频检测，通过嵌入相似性模块和时间卷积操作，能有效捕捉音频的特征和位置信息。实验结果表明，在ASVspoof2019 Partial Spoof数据集中，该方法优于基准模型。

    

    部分伪造音频检测是一项具有挑战性的任务，需要在帧级别准确地定位音频的真实性。为了解决这个问题，我们提出了一种精细化的部分伪造音频检测方法，即临时Deepfake位置（TDL），可以有效地捕捉特征和位置信息。具体而言，我们的方法包括两个新颖的部分：嵌入相似性模块和时间卷积操作。为了增强真实特征和伪造特征之间的区分度，嵌入相似性模块被设计用于生成一个嵌入空间，可以将真实帧与伪造帧分离开来。为了有效地关注位置信息，我们提出了时间卷积操作，用于计算相邻帧之间的特定帧相似性，并动态选择信息丰富的邻居进行卷积。广泛的实验表明，我们的方法在ASVspoof2019 Partial Spoof数据集中优于基准模型。

    Partially spoofed audio detection is a challenging task, lying in the need to accurately locate the authenticity of audio at the frame level. To address this issue, we propose a fine-grained partially spoofed audio detection method, namely Temporal Deepfake Location (TDL), which can effectively capture information of both features and locations. Specifically, our approach involves two novel parts: embedding similarity module and temporal convolution operation. To enhance the identification between the real and fake features, the embedding similarity module is designed to generate an embedding space that can separate the real frames from fake frames. To effectively concentrate on the position information, temporal convolution operation is proposed to calculate the frame-specific similarities among neighboring frames, and dynamically select informative neighbors to convolution. Extensive experiments show that our method outperform baseline models in ASVspoof2019 Partial Spoof dataset and
    
[^9]: 无监督发现可解释的视觉概念

    Unsupervised discovery of Interpretable Visual Concepts. (arXiv:2309.00018v1 [cs.CV])

    [http://arxiv.org/abs/2309.00018](http://arxiv.org/abs/2309.00018)

    本文提出了两种方法（MAGE和Ms-IV），用于解释深度学习模型的决策，提高全局可解释性。MAGE可以发现形成语义含义的特征组合，将其称为概念，并通过聚类分组为“概念”，然后通过Ms-IV进行可视化。这一方法受到阻断和敏感性分析的启发，并使用一种新的指标（CaOC）全局评估模型最重要的图像区域。

    

    深度学习模型的可解释性对于非专家用户非常重要，但是在实际应用中，提供给用户的模型解释性是一项具有挑战性的任务。诸如集成梯度等可解释性方法产生了包含大量信息但难以解释的归因映射。本文提出了两种方法，最大激活组提取（MAGE）和多尺度可解释性可视化（Ms-IV），用于解释模型的决策，提高全局可解释性。MAGE可以找到给定CNN中形成语义含义的特征组合，我们将其称为概念，并通过聚类将这些相似特征模式分组为“概念”，然后通过Ms-IV进行可视化。这一方法受到阻断和敏感性分析的启发（包括因果关系），并使用一种新的指标，称为类别感知顺序相关性（CaOC），全局评估根据模型预测结果最重要的图像区域。

    Providing interpretability of deep-learning models to non-experts, while fundamental for a responsible real-world usage, is challenging. Attribution maps from xAI techniques, such as Integrated Gradients, are a typical example of a visualization technique containing a high level of information, but with difficult interpretation. In this paper, we propose two methods, Maximum Activation Groups Extraction (MAGE) and Multiscale Interpretable Visualization (Ms-IV), to explain the model's decision, enhancing global interpretability. MAGE finds, for a given CNN, combinations of features which, globally, form a semantic meaning, that we call concepts. We group these similar feature patterns by clustering in ``concepts'', that we visualize through Ms-IV. This last method is inspired by Occlusion and Sensitivity analysis (incorporating causality), and uses a novel metric, called Class-aware Order Correlation (CaOC), to globally evaluate the most important image regions according to the model's 
    
[^10]: survex：用于解释机器学习生存模型的R软件包

    survex: an R package for explaining machine learning survival models. (arXiv:2308.16113v1 [cs.LG])

    [http://arxiv.org/abs/2308.16113](http://arxiv.org/abs/2308.16113)

    survex是一个R软件包，通过应用可解释的人工智能技术，提供了一个连贯的框架来解释任何生存模型，可以改进模型，提高透明度和责任感。

    

    由于其灵活性和出色性能，机器学习模型经常用于补充和超越传统的统计生存模型。然而，它们的广泛应用受到缺乏用户友好的工具来解释其内部操作和预测原理的限制。为了解决这个问题，我们引入了survex R软件包，通过应用可解释的人工智能技术，提供了一个连贯的框架来解释任何生存模型。所提软件的功能包括理解和诊断生存模型，从而可以改进它们。通过揭示变量效应和重要性等决策过程的见解，survex能够评估模型的可靠性并检测偏差。因此，在生物医学研究和医疗应用等敏感领域可以促进透明度和责任。

    Due to their flexibility and superior performance, machine learning models frequently complement and outperform traditional statistical survival models. However, their widespread adoption is hindered by a lack of user-friendly tools to explain their internal operations and prediction rationales. To tackle this issue, we introduce the survex R package, which provides a cohesive framework for explaining any survival model by applying explainable artificial intelligence techniques. The capabilities of the proposed software encompass understanding and diagnosing survival models, which can lead to their improvement. By revealing insights into the decision-making process, such as variable effects and importances, survex enables the assessment of model reliability and the detection of biases. Thus, transparency and responsibility may be promoted in sensitive areas, such as biomedical research and healthcare applications.
    
[^11]: 预测、改进、合成：面向概率时间序列预测的自引导扩散模型

    Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting. (arXiv:2307.11494v1 [cs.LG])

    [http://arxiv.org/abs/2307.11494](http://arxiv.org/abs/2307.11494)

    本研究提出了一种面向概率时间序列预测的自引导扩散模型，称为TSDiff。该模型不需要辅助网络或训练过程的改变，在预测、改进和合成数据生成等时间序列任务上展现出了竞争力。

    

    扩散模型在各个领域的生成建模任务中取得了最先进的性能。之前关于时间序列扩散模型的研究主要集中在开发针对特定预测或填补任务的条件模型。在这项工作中，我们探索了面向多种时间序列应用的任务不可知条件下的扩散模型的潜力。我们提出了TSDiff，一种面向时间序列的无条件训练的扩散模型。我们的自引导机制在推理过程中使得TSDiff能够为下游任务进行条件设置，而无需辅助网络或改变训练过程。我们在三个不同的时间序列任务上展示了我们方法的有效性：预测、改进和合成数据生成。首先，我们表明TSDiff与几种任务特定的条件预测方法相竞争（预测）。其次，我们利用TSDiff学到的隐性概率密度来迭代地改进p

    Diffusion models have achieved state-of-the-art performance in generative modeling tasks across various domains. Prior works on time series diffusion models have primarily focused on developing conditional models tailored to specific forecasting or imputation tasks. In this work, we explore the potential of task-agnostic, unconditional diffusion models for several time series applications. We propose TSDiff, an unconditionally trained diffusion model for time series. Our proposed self-guidance mechanism enables conditioning TSDiff for downstream tasks during inference, without requiring auxiliary networks or altering the training procedure. We demonstrate the effectiveness of our method on three different time series tasks: forecasting, refinement, and synthetic data generation. First, we show that TSDiff is competitive with several task-specific conditional forecasting methods (predict). Second, we leverage the learned implicit probability density of TSDiff to iteratively refine the p
    
[^12]: 多阶段电缆布线的层次化模仿学习

    Multi-Stage Cable Routing through Hierarchical Imitation Learning. (arXiv:2307.08927v3 [cs.RO] CROSS LISTED)

    [http://arxiv.org/abs/2307.08927](http://arxiv.org/abs/2307.08927)

    本研究探讨了多阶段电缆布线任务中的层次化模仿学习方法，解决了处理可变形物体、视觉感知闭环和扩展行为的挑战。成功控制器需要能够从失败中恢复，并通过选择纠正低级控制器的缺陷。

    

    我们研究了学习如何执行多阶段机器人操作任务的问题，应用于电缆布线，其中机器人必须通过一系列夹子来布线。这个设置代表了复杂多阶段机器人操作场景的挑战：处理可变形物体，对视觉感知闭环，处理由多个步骤组成的扩展行为，必须成功执行才能完成整个任务。在这种设置中，为每个阶段学习成功率足够高的单个基元是不切实际的：如果每个阶段必须成功完成并且有较大的失败概率，整个任务成功完成的概率变得微不足道。因此，这样的多阶段任务的成功控制器必须能够从失败中恢复，并通过聪明地选择从而纠正低级控制器的缺陷。

    We study the problem of learning to perform multi-stage robotic manipulation tasks, with applications to cable routing, where the robot must route a cable through a series of clips. This setting presents challenges representative of complex multi-stage robotic manipulation scenarios: handling deformable objects, closing the loop on visual perception, and handling extended behaviors consisting of multiple steps that must be executed successfully to complete the entire task. In such settings, learning individual primitives for each stage that succeed with a high enough rate to perform a complete temporally extended task is impractical: if each stage must be completed successfully and has a non-negligible probability of failure, the likelihood of successful completion of the entire task becomes negligible. Therefore, successful controllers for such multi-stage tasks must be able to recover from failure and compensate for imperfections in low-level controllers by smartly choosing which con
    
[^13]: 因果强化学习：一项综述

    Causal Reinforcement Learning: A Survey. (arXiv:2307.01452v1 [cs.LG])

    [http://arxiv.org/abs/2307.01452](http://arxiv.org/abs/2307.01452)

    这项综述总结了因果强化学习的研究文献，强调因果关系的重要作用，它能够形式化知识并实现有效的知识传递。

    

    强化学习是在不确定性条件下解决序列决策问题的一种重要范式。尽管近几十年来取得了许多显著的成就，但将强化学习方法应用于现实世界仍然具有挑战性。其中一个主要障碍是强化学习代理缺乏对世界的基本理解，因此必须通过大量的试错交互学习。他们可能在解释自己的决策以及推广所获得的知识方面面临挑战。然而，因果关系具有明显的优势，它可以以系统化的方式形式化知识，并利用不变性进行有效的知识传递。这导致了因果强化学习的出现，它是强化学习的一个子领域，旨在通过将因果关系纳入学习过程来增强现有算法。在这篇综述中，我们全面回顾了有关因果强化学习的文献。

    Reinforcement learning is an essential paradigm for solving sequential decision problems under uncertainty. Despite many remarkable achievements in recent decades, applying reinforcement learning methods in the real world remains challenging. One of the main obstacles is that reinforcement learning agents lack a fundamental understanding of the world and must therefore learn from scratch through numerous trial-and-error interactions. They may also face challenges in providing explanations for their decisions and generalizing the acquired knowledge. Causality, however, offers a notable advantage as it can formalize knowledge in a systematic manner and leverage invariance for effective knowledge transfer. This has led to the emergence of causal reinforcement learning, a subfield of reinforcement learning that seeks to enhance existing algorithms by incorporating causal relationships into the learning process. In this survey, we comprehensively review the literature on causal reinforcemen
    
[^14]: 从合成的人类团队活动中学习

    Learning from Synthetic Human Group Activities. (arXiv:2306.16772v1 [cs.CV])

    [http://arxiv.org/abs/2306.16772](http://arxiv.org/abs/2306.16772)

    提出了M3Act，一个多视图多团队多人的人类原子动作和团队活动数据生成器，通过Unity引擎驱动实现。该生成器具有大规模数据生成、多模态和高质量注释等特点，能够用于研究复杂的人类互动和团队活动。

    

    在以人为中心的计算机视觉中，对复杂的人类互动和团队活动的理解引起了人们的关注。然而，相关任务的进展受到了获取大规模标记的真实世界数据集的困难的限制。为了缓解这个问题，我们提出了M3Act，一个多视图多团队多人的人类原子动作和团队活动数据生成器。M3Act采用Unity引擎驱动，包含可供仿真使用的三维场景和人物资源，可配置的照明和摄像系统，高度参数化的模块化团队活动，以及在数据生成过程中具有大量领域随机化的特点。我们的数据生成器能够生成具有多个视图、模态（RGB图像、2D姿势、3D动作）和高质量注释的大规模人类活动数据集（2D边界框、实例分割掩模、个体动作和团队活动类别）。利用M3Act，我们可以生成大规模的人类活动数据集，用于研究人类互动和团队活动。

    The understanding of complex human interactions and group activities has garnered attention in human-centric computer vision. However, the advancement of the related tasks is hindered due to the difficulty of obtaining large-scale labeled real-world datasets. To mitigate the issue, we propose M3Act, a multi-view multi-group multi-person human atomic action and group activity data generator. Powered by the Unity engine, M3Act contains simulation-ready 3D scenes and human assets, configurable lighting and camera systems, highly parameterized modular group activities, and a large degree of domain randomization during the data generation process. Our data generator is capable of generating large-scale datasets of human activities with multiple viewpoints, modalities (RGB images, 2D poses, 3D motions), and high-quality annotations for individual persons and multi-person groups (2D bounding boxes, instance segmentation masks, individual actions and group activity categories). Using M3Act, we
    
[^15]: 探索对比学习中的归纳偏差：从聚类角度出发

    Exploring Inductive Biases in Contrastive Learning: A Clustering Perspective. (arXiv:2305.10229v1 [cs.LG])

    [http://arxiv.org/abs/2305.10229](http://arxiv.org/abs/2305.10229)

    本文比较了对比学习和监督学习方法形成的簇，揭示了对比学习可以生成具有局部密度但无全局密度的簇，而监督学习创建具有局部和全局密度的簇。同时，作者提出了使用图卷积网络分类器作为处理局部密集簇的线性分类器的替代方法，并利用t-SNE可视化证明了对比和监督学习方法产生的特征之间的差异。

    

    本文研究对比学习方法和监督学习方法之间数据组织的差异，重点关注局部密集簇的概念。我们引入一个新的度量指标，相对局部密度（RLD），用于定量测量簇内的局部密度。我们提供了视觉示例，以突出局部密集簇和全局密集簇之间的区别。通过对比对比学习和监督学习形成的簇，我们发现对比学习生成具有局部密度而无全局密度的簇，而监督学习创建具有局部和全局密度的簇。我们进一步探讨了使用图卷积网络（GCN）分类器作为处理局部密集簇的线性分类器的替代方法。最后，我们利用t-SNE可视化来证明对比和监督学习方法产生的特征之间的差异。我们提出了未来的研究方向来结束本文。

    This paper investigates the differences in data organization between contrastive and supervised learning methods, focusing on the concept of locally dense clusters. We introduce a novel metric, Relative Local Density (RLD), to quantitatively measure local density within clusters. Visual examples are provided to highlight the distinctions between locally dense clusters and globally dense ones. By comparing the clusters formed by contrastive and supervised learning, we reveal that contrastive learning generates locally dense clusters without global density, while supervised learning creates clusters with both local and global density. We further explore the use of a Graph Convolutional Network (GCN) classifier as an alternative to linear classifiers for handling locally dense clusters. Finally, we utilize t-SNE visualizations to substantiate the differences between the features generated by contrastive and supervised learning methods. We conclude by proposing future research directions, 
    
[^16]: DroidBot-GPT：基于GPT的Android UI自动化

    DroidBot-GPT: GPT-powered UI Automation for Android. (arXiv:2304.07061v1 [cs.SE])

    [http://arxiv.org/abs/2304.07061](http://arxiv.org/abs/2304.07061)

    DroidBot-GPT是一款利用GPT模型自动化Android应用程序的工具，可以根据任务的自然语言描述自动生成并执行操作，有望提高移动应用程序的测试和开发效率。

    

    本文介绍了DroidBot-GPT，这是一种利用类似GPT的大型语言模型（LLM）自动化与Android移动应用程序交互的工具。给定所需任务的自然语言描述，DroidBot-GPT可以自动生成并执行操作，导航应用程序以完成任务。它通过将应用程序GUI状态信息和智能手机屏幕上可用的操作转换为自然语言提示，并要求LLM选择动作来实现。由于LLM通常受过大量数据的训练，包括各种软件应用程序的操作指南，因此它具有根据提供的信息作出合理动作选择的能力。我们使用了一个自创建的数据集对DroidBot-GPT进行评估，该数据集包含来自10个类别的17个Android应用程序的33个任务。它可以成功完成39.39%的任务，并且平均部分完成进度约为66.76%。鉴于我们的方法是完全自动的，并且用于训练LLM的数据是广泛可用的，我们认为DroidBot-GPT在改善移动应用程序的测试和开发效率方面具有巨大潜力。

    This paper introduces DroidBot-GPT, a tool that utilizes GPT-like large language models (LLMs) to automate the interactions with Android mobile applications. Given a natural language description of a desired task, DroidBot-GPT can automatically generate and execute actions that navigate the app to complete the task. It works by translating the app GUI state information and the available actions on the smartphone screen to natural language prompts and asking the LLM to make a choice of actions. Since the LLM is typically trained on a large amount of data including the how-to manuals of diverse software applications, it has the ability to make reasonable choices of actions based on the provided information. We evaluate DroidBot-GPT with a self-created dataset that contains 33 tasks collected from 17 Android applications spanning 10 categories. It can successfully complete 39.39% of the tasks, and the average partial completion progress is about 66.76%. Given the fact that our method is f
    
[^17]: 通过对比学习加强知识的短文本匹配模型

    The Short Text Matching Model Enhanced with Knowledge via Contrastive Learning. (arXiv:2304.03898v1 [cs.CL])

    [http://arxiv.org/abs/2304.03898](http://arxiv.org/abs/2304.03898)

    提出了一种短文本匹配模型，使用生成模型生成补充句子，结合对比学习和外部知识进行语义匹配，并使用关键词避免噪声问题。

    

    近年来，短文本匹配任务在广告搜索和推荐领域得到了广泛应用。由于文本长度短，语义信息匮乏和单词歧义问题成为此类任务的难点。先前的研究已经引入文本补充句子或知识库来提供附加的特征信息。然而，这些方法没有充分地交互原始句子和补充句子，也没有考虑到外部知识库引入的噪声问题。因此，本文提出了一种结合对比学习和外部知识的短文本匹配模型。该模型利用生成模型生成对应的补充句子，并使用对比学习方法指导模型获得更具语义匹配性的原始句子编码。此外，为了避免噪声，我们使用关键词作为原始句子的主要语义进行检索。

    In recent years, short Text Matching tasks have been widely applied in the fields ofadvertising search and recommendation. The difficulty lies in the lack of semantic information and word ambiguity caused by the short length of the text. Previous works have introduced complement sentences or knowledge bases to provide additional feature information. However, these methods have not fully interacted between the original sentence and the complement sentence, and have not considered the noise issue that may arise from the introduction of external knowledge bases. Therefore, this paper proposes a short Text Matching model that combines contrastive learning and external knowledge. The model uses a generative model to generate corresponding complement sentences and uses the contrastive learning method to guide the model to obtain more semantically meaningful encoding of the original sentence. In addition, to avoid noise, we use keywords as the main semantics of the original sentence to retrie
    
[^18]: 在可解释的因果变量和分布式神经表示之间寻找对齐方法

    Finding Alignments Between Interpretable Causal Variables and Distributed Neural Representations. (arXiv:2303.02536v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.02536](http://arxiv.org/abs/2303.02536)

    本文提出了分布式对齐搜索（DAS）算法，可以在不使用暴力搜索的情况下找到高层因果模型和低层深度学习系统之间的对齐方法，并且DAS可以发现先前方法忽略的内部结构。DAS算法有潜力实现对复杂深度学习系统的更好解释和理解。

    

    因果抽象是可解释的人工智能的一个有前途的理论框架，它定义了可解释的高层因果模型何时是低层深度学习系统的可信简化。然而，现有的因果抽象方法存在两个主要限制：它们需要在高层模型和低层模型之间进行暴力搜索对齐，并且它们预设高层模型中的变量将与低层模型中的不相交的神经元集对齐。在本文中，我们提出了分布式对齐搜索（DAS），它克服了这些限制。在DAS中，我们使用梯度下降找到高层模型和低层模型之间的对齐方法，允许个体神经元在非传统基底分布表示中发挥多个不同的角色。我们的实验表明，DAS可以发现先前方法忽略的内部结构。总体而言，DAS有潜力实现对复杂深度学习系统的更好解释和理解。

    Causal abstraction is a promising theoretical framework for explainable artificial intelligence that defines when an interpretable high-level causal model is a faithful simplification of a low-level deep learning system. However, existing causal abstraction methods have two major limitations: they require a brute-force search over alignments between the high-level model and the low-level one, and they presuppose that variables in the high-level model will align with disjoint sets of neurons in the low-level one. In this paper, we present distributed alignment search (DAS), which overcomes these limitations. In DAS, we find the alignment between high-level and low-level models using gradient descent rather than conducting a brute-force search, and we allow individual neurons to play multiple distinct roles by analyzing representations in non-standard bases-distributed representations. Our experiments show that DAS can discover internal structure that prior approaches miss. Overall, DAS 
    
[^19]: 基于潜在代理表示学习的长期因果效应估计

    Long-term Causal Effects Estimation via Latent Surrogates Representation Learning. (arXiv:2208.04589v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.04589](http://arxiv.org/abs/2208.04589)

    Laser 是一种基于潜在代理表示学习的估计长期因果效应的灵活方法，能够在代理和其代理混合在一起的真实世界情景中应用。

    

    在许多实际应用，如营销和医学中，基于短期代理来估计长期因果效应是一个重要而具有挑战性的问题。尽管某些领域中已有所成功，但大多数现有方法以一种理想化和简化的方式估计因果效应，忽略了短期结果之间的因果结构，并将它们全部视为代理。然而，这种方法无法很好地应用于真实世界的情景，其中局部观察到的代理与它们在短期结果中的代理混合在一起。因此，我们开发了一种灵活的方法，称为Laser，以在更现实的情况下估计长期因果效应，其中观察到代理或具有观察代理。鉴于代理和代理之间的不可区分性，我们利用可识别变分自编码器（iVAE）在不需要区分观察到的代理或先验条件的情况下恢复所有有效代理候选者上的整个有效代理。

    Estimating long-term causal effects based on short-term surrogates is a significant but challenging problem in many real-world applications, e.g., marketing and medicine. Despite its success in certain domains, most existing methods estimate causal effects in an idealistic and simplistic way - ignoring the causal structure among short-term outcomes and treating all of them as surrogates. However, such methods cannot be well applied to real-world scenarios, in which the partially observed surrogates are mixed with their proxies among short-term outcomes. To this end, we develop our flexible method, Laser, to estimate long-term causal effects in the more realistic situation that the surrogates are observed or have observed proxies.Given the indistinguishability between the surrogates and proxies, we utilize identifiable variational auto-encoder (iVAE) to recover the whole valid surrogates on all the surrogates candidates without the need of distinguishing the observed surrogates or the p
    
[^20]: Relphormer：关系图转换器用于知识图谱表示

    Relphormer: Relational Graph Transformer for Knowledge Graph Representations. (arXiv:2205.10852v5 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.10852](http://arxiv.org/abs/2205.10852)

    Relphormer是一种新的Transformer变体，用于知识图谱表示。它引入了Triple2Seq和增强式自我注意机制，以解决基本Transformer架构在捕捉知识图谱结构和语义信息方面的不足。

    

    Transformer已经在自然语言处理、计算机视觉和图形挖掘等广泛领域中取得了remarkable的性能。然而，基本的Transformer架构在知识图谱（KG）表示中并没有取得很好的改进，其中平移距离模型支配了这个领域。需注意的是，基本的Transformer架构难以捕捉到知识图谱的内在异构结构和语义信息。为此，我们提出了一种新的用于知识图谱表示的Transformer变体，名为Relphormer。具体来说，我们引入了Triple2Seq，可以动态地采样上下文化的子图序列作为输入，以缓解异构性问题。我们提出了一种新的增强式自我注意机制，用于对关系信息进行编码，并保持实体和关系内的语义信息。此外，我们利用掩蔽式知识建模来实现通用的知识图形表示。

    Transformers have achieved remarkable performance in widespread fields, including natural language processing, computer vision and graph mining. However, vanilla Transformer architectures have not yielded promising improvements in the Knowledge Graph (KG) representations, where the translational distance paradigm dominates this area. Note that vanilla Transformer architectures struggle to capture the intrinsically heterogeneous structural and semantic information of knowledge graphs. To this end, we propose a new variant of Transformer for knowledge graph representations dubbed Relphormer. Specifically, we introduce Triple2Seq which can dynamically sample contextualized sub-graph sequences as the input to alleviate the heterogeneity issue. We propose a novel structure-enhanced self-attention mechanism to encode the relational information and keep the semantic information within entities and relations. Moreover, we utilize masked knowledge modeling for general knowledge graph representa
    

