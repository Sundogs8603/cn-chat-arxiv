# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [WavJourney: Compositional Audio Creation with Large Language Models.](http://arxiv.org/abs/2307.14335) | 本研究提出了WavJourney系统，利用大型语言模型实现音频内容的创作。该系统可以根据文本指令生成包含语音、音乐和音效的音频内容。 |
| [^2] | [Event-based Vision for Early Prediction of Manipulation Actions.](http://arxiv.org/abs/2307.14332) | 本研究基于事件的视觉数据集，利用Transformer网络提前预测操纵动作，实现了最先进的分类效果。 |
| [^3] | [Waypoint-Based Imitation Learning for Robotic Manipulation.](http://arxiv.org/abs/2307.14326) | 该论文提出了一种基于路径点的机器人操作模仿学习方法，通过自动提取路径点来减少行为克隆中累积误差的问题。 |
| [^4] | [Evaluating the Moral Beliefs Encoded in LLMs.](http://arxiv.org/abs/2307.14324) | 本文提出了一种对LLMs中编码的道德信念进行评估的案例研究方法。通过设计大规模调查了解不同LLMs中的道德信念，在明确的情况下，LLMs倾向于与人类的道德直觉保持一致，但在模糊的情况下，它们的回答会有所不同，并可能存在偏见和不一致性。 |
| [^5] | [Reinforcement Learning by Guided Safe Exploration.](http://arxiv.org/abs/2307.14316) | 本文研究了一种通过引导安全探索的强化学习方法，通过训练一个代理在没有奖励信号的情况下学习安全探索，然后利用其构建一个安全的行为策略，并且借鉴迁移学习的思想，在训练过程中逐渐消除引导代理的影响。 |
| [^6] | [ChatGPT and Persuasive Technologies for the Management and Delivery of Personalized Recommendations in Hotel Hospitality.](http://arxiv.org/abs/2307.14298) | 本文研究了将ChatGPT和说服技术应用于酒店推荐系统的潜力，通过ChatGPT可以提供更准确和上下文感知的推荐，而说服技术可影响用户行为并增强推荐的说服力。 |
| [^7] | [Unraveling the Complexity of Splitting Sequential Data: Tackling Challenges in Video and Time Series Analysis.](http://arxiv.org/abs/2307.14294) | 本概念文章研究了各种拆分序列数据的挑战，并通过电机测试台和液体中的粒子跟踪等实例进行了探索。 |
| [^8] | [General Purpose Artificial Intelligence Systems (GPAIS): Properties, Definition, Taxonomy, Open Challenges and Implications.](http://arxiv.org/abs/2307.14283) | 这里是中文总结出的一句话要点：本论文讨论了通用目的人工智能系统（GPAIS）的性质、定义、分类和开放挑战，并提出了一种新的定义，允许根据其性质和限制逐步区分GPAIS的类型。 |
| [^9] | [Improving International Climate Policy via Mutually Conditional Binding Commitments.](http://arxiv.org/abs/2307.14267) | 本文介绍了一种名为有条件的承诺机制的分散，自下而上的方法，旨在通过形式化国际气候政策中的有条件合作来解决无条件性贡献带来的问题。该机制受民主全民投票州间协定的启发，并提供灵活性和激励措施，以促使早期采用者。期望能改善大污染国的自由骑车行为，从而提高国际气候政策的有效性。 |
| [^10] | [Improving International Climate Policy via Mutually Conditional Binding Commitments.](http://arxiv.org/abs/2307.14266) | 本文提出了改进RICE-N模拟和多智能体强化学习框架的方法，以提高国际气候政策谈判的逼真度和决策效果。 |
| [^11] | [A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI).](http://arxiv.org/abs/2307.14246) | 这项工作通过批判性地审视解释性和性能之间的所谓权衡，提出了一种以细致入微的方式来处理这个问题的方法，考虑到资源可用性、领域特征和风险因素。这为未来研究和最佳实践奠定了基础。 |
| [^12] | [Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI).](http://arxiv.org/abs/2307.14239) | 本文重新审视了在可解释人工智能中性能和可解释性之间的权衡问题，并提出了资源可用性、领域特征和风险考虑的细致方法。为未来研究和最佳实践提供基础。 |
| [^13] | [UnScientify: Detecting Scientific Uncertainty in Scholarly Full Text.](http://arxiv.org/abs/2307.14236) | UnScientify是一个交互系统，可以检测学术全文中的科学不确定性。它利用弱监督技术和细粒度注释方案，自动标记和注释科学不确定性，并提供可解释的结果。 |
| [^14] | [Sources of Opacity in Computer Systems: Towards a Comprehensive Taxonomy.](http://arxiv.org/abs/2307.14232) | 该论文提出了一个综合分类方法论，用于解决计算机系统中的不透明性问题。该分类方法论包含八个不透明性来源，分别属于体系结构、分析和社会技术三个主要类别。该方法论为从业人员提供了一种理解和克服不透明性问题的起点。 |
| [^15] | [Explore the possibility of advancing climate negotiations on the basis of regional trade organizations: A study based on RICE-N.](http://arxiv.org/abs/2307.14226) | 本研究探索了利用基于区域贸易组织推进气候谈判的可能性，以RICE-N模型为基础，利用深度学习构建了一个新的模型。模拟结果显示该方案具有良好前景。 |
| [^16] | [AI and Education: An Investigation into the Use of ChatGPT for Systems Thinking.](http://arxiv.org/abs/2307.14206) | 本研究探索了AI工具ChatGPT在各个学科中支持系统思维的潜力，并发现其能够提供准确和有用的回答，尽管存在一些限制，但谨慎使用时可以成为教学和学习系统思维的有价值工具。 |
| [^17] | [Unveiling Security, Privacy, and Ethical Concerns of ChatGPT.](http://arxiv.org/abs/2307.14192) | 本文研究了ChatGPT的安全、隐私和伦理问题，揭示了将其应用到不同行业可能存在的潜在风险和挑战，并呼吁共同努力确保开发安全和伦理健全的大型语言模型。 |
| [^18] | [LOIS: Looking Out of Instance Semantics for Visual Question Answering.](http://arxiv.org/abs/2307.14142) | LOIS是一个新的模型框架，用于解决视觉问答中的语义理解问题。它不依赖于边界框，并使用精细的特征描述来生成视觉事实。另外，LOIS通过两种类型的关系注意力模块来解决由实例掩码引起的标签不确定性。 |
| [^19] | [Piecewise-Stationary Combinatorial Semi-Bandit with Causally Related Rewards.](http://arxiv.org/abs/2307.14138) | 本研究研究了具有因果关系奖励的分段稳定组合半强盗问题，并提出了上界置信度算法以应对非平稳环境中的挑战。此外，引入了组重启的概念作为结构化环境中的备份策略。 |
| [^20] | [Developing and Evaluating Tiny to Medium-Sized Turkish BERT Models.](http://arxiv.org/abs/2307.14134) | 本研究开发并评估了小型到中型的土耳其BERT模型，在填补资源匮乏语言领域的研究空白方面取得了积极的成果，并为开发和应用小型语言模型提供了有价值的见解。 |
| [^21] | [A semantics-driven methodology for high-quality image annotation.](http://arxiv.org/abs/2307.14119) | 本文提出了一种以语义为驱动的高质量图像标注方法vTelos，利用WordNet作为提供自然语言标签含义的主要手段，减少主观选择，提高标注的准确性。 |
| [^22] | [GraphRNN Revisited: An Ablation Study and Extensions for Directed Acyclic Graphs.](http://arxiv.org/abs/2307.14109) | 本文对GraphRNN进行了复现和评估，发现You等人建议的BFS遍历对模型性能有重要贡献。此外，通过将BFS遍历替换为拓扑排序，我们扩展了GraphRNN以生成有向无环图，并在真实数据集上取得了显著改进。 |
| [^23] | [Actions Speak What You Want: Provably Sample-Efficient Reinforcement Learning of the Quantal Stackelberg Equilibrium from Strategic Feedbacks.](http://arxiv.org/abs/2307.14085) | 本文研究了强化学习中的量化斯坦克伯格均衡问题，提出了省样本量的在线和离线算法，并通过推断追随者的行动来学习量化响应模型。 |
| [^24] | [Open Image Content Disarm And Reconstruction.](http://arxiv.org/abs/2307.14057) | 本论文提出了一种新颖的图像内容非官方解除和重构（ICDR）方法，用于解决恶意软件使用图像进行隐藏和隐写的问题。 |
| [^25] | [One-Nearest Neighborhood Guides Inlier Estimation for Unsupervised Point Cloud Registration.](http://arxiv.org/abs/2307.14019) | 本文提出了一种无监督点云配准方法，通过对几何结构一致性的捕捉和最近邻点云的生成来提高内点估计和匹配置信度。 |
| [^26] | [ESSAformer: Efficient Transformer for Hyperspectral Image Super-resolution.](http://arxiv.org/abs/2307.14010) | ESSAformer是一种用于单一超光谱图像超分辨率的高效Transformer网络，通过引入稳健的相似度度量和核化注意力技术，解决了CNN-based方法在光谱信息利用和伪影问题上的限制。 |
| [^27] | [Controlling the Latent Space of GANs through Reinforcement Learning: A Case Study on Task-based Image-to-Image Translation.](http://arxiv.org/abs/2307.13978) | 本文提出了一种通过将强化学习代理与潜在空间 GAN 集成来控制生成过程的新方法，在实验证明其有效性的基础上。 |
| [^28] | [Understanding Deep Neural Networks via Linear Separability of Hidden Layers.](http://arxiv.org/abs/2307.13962) | 本文通过测量深度神经网络隐藏层输出的线性可分性来研究其特性，并发现隐藏层输出的线性可分性程度与网络训练性能有同步性，进一步探讨激活函数和网络尺寸对隐藏层线性可分性的影响。 |
| [^29] | [How Does Diffusion Influence Pretrained Language Models on Out-of-Distribution Data?.](http://arxiv.org/abs/2307.13949) | 这项研究探讨了扩散模型对预训练语言模型(PLMs)在超出分布(OOD)数据上的影响。研究发现，在OOD数据上使用扩散微调PLMs会降低重建能力。比较实验还表明，扩散模型能够有效提高OOD样本的重构能力和检测能力。 |
| [^30] | [Learning-based Control for PMSM Using Distributed Gaussian Processes with Optimal Aggregation Strategy.](http://arxiv.org/abs/2307.13945) | 本文提出了一种基于分布式高斯过程的学习控制方法用于PMSM。该方法采用了控制感知最优聚合策略，并仅利用后验均值进行计算，从而避免了与后验方差相关的计算。 |
| [^31] | [Entropy Neural Estimation for Graph Contrastive Learning.](http://arxiv.org/abs/2307.13944) | 本文提出了一种基于熵神经估计的图对比学习方法，通过最大化互信息下界来近似估计数据集的熵。通过简单但有效的子集抽样策略对比数据集不同视图中的节点表示，同时使用两个目标优化网络的学习过程。 |
| [^32] | [Stability of Multi-Agent Learning: Convergence in Network Games with Many Players.](http://arxiv.org/abs/2307.13922) | 该研究探讨了多智能体学习在网络游戏中的稳定性，发现了在任何网络游戏中实现动力学收敛到唯一均衡的充分条件，并且证明在适当的网络条件下，可以实现具有任意数量代理的稳定学习动力学。 |
| [^33] | [Embedding Democratic Values into Social Media AIs via Societal Objective Functions.](http://arxiv.org/abs/2307.13912) | 本研究介绍了一种方法，通过将社会科学构造转化为人工智能目标函数，将民主价值观嵌入社交媒体人工智能系统中。通过一个应用于反民主态度的模型示例，我们展示了该方法的有效性。通过利用社会科学的调查工具和定性编码手册，我们能够精确地转化这些构造为大型语言模型的提示。 |
| [^34] | [Robustness Verification of Deep Neural Networks using Star-Based Reachability Analysis with Variable-Length Time Series Input.](http://arxiv.org/abs/2307.13907) | 本文介绍了一种利用基于星星的可达性分析和变长时间序列输入的深度神经网络鲁棒性验证方法，并在预测与健康管理领域的SOC估计和RUL估计中进行了应用。 |
| [^35] | [FinTree: Financial Dataset Pretrain Transformer Encoder for Relation Extraction.](http://arxiv.org/abs/2307.13900) | FinTree是一种用于关系抽取的金融数据集预训练变换器编码器，其采用了预测掩码标记的新颖结构，通过训练提供上下文和位置信息，并在大规模金融关系抽取数据集上表现出色。 |
| [^36] | [Regularizing Neural Networks with Meta-Learning Generative Models.](http://arxiv.org/abs/2307.13899) | 本文提出了一种名为元生成正则化（MGR）的新型生成数据增强策略，通过将合成样本用于特征提取器的正则化项而不是损失函数，最小化验证损失，提高了深度学习中的生成数据增强效果。 |
| [^37] | [AI4GCC - Team: Below Sea Level: Critiques and Improvements.](http://arxiv.org/abs/2307.13894) | 这项研究对气候变化评估模型RICE-N进行了批判性分析，发现了关键问题并提出了改进建议，同时也对综合评估模型的特征进行了讨论。研究结果有助于进一步发展RICE-N框架，为政策制定者提供参考。 |
| [^38] | [Dynamic Grouping for Climate Change Negotiation: Facilitating Cooperation and Balancing Interests through Effective Strategies.](http://arxiv.org/abs/2307.13893) | 本文提出了一个基于现实世界业务和政治谈判协议的动态分组谈判模型，通过实施组形成方法和组更新策略解决了多地区气候谈判中的复杂性和不平衡问题，促进各利益相关方之间的高效合作以实现全球气候变化目标。 |
| [^39] | [AI4GCC - Team: Below Sea Level: Score and Real World Relevance.](http://arxiv.org/abs/2307.13892) | 我们提出了一种谈判协议来解决碳泄漏问题，通过与代表性浓度路径和共享社会经济路径进行比较，我们的方法显示出了良好的效果，此外我们还分析了协议的合规性、可行性和伦理关切。 |
| [^40] | [Dynamic Grouping for Climate Change Negotiation: Facilitating Cooperation and Balancing Interests through Effective Strategies.](http://arxiv.org/abs/2307.13886) | 本研究主要目的在于改进气候变化谈判模型，特别集中在地理影响和效用框架两个关键领域。我们探讨了地理影响的五个关键方面，并强调了完善效用和奖励框架的重要性。通过解决这些限制，我们希望提高准确性和效果。 |
| [^41] | [WebArena: A Realistic Web Environment for Building Autonomous Agents.](http://arxiv.org/abs/2307.13854) | WebArena是一个用于构建自主智能体的真实网络环境，它包含了完全功能的网站，并且通过引入工具和外部知识库来鼓励智能体像人类一样解决任务。此外，WebArena还发布了一组用于评估任务完成功能正确性的基准任务。 |
| [^42] | [MAEA: Multimodal Attribution for Embodied AI.](http://arxiv.org/abs/2307.13850) | MAEA是一个用于计算任何可微分的多模态智能体人工智能政策的全局归因的框架。它可以通过归因分析来排名和分组故障场景，调查建模和数据集偏见，并对多模态智能体人工智能政策的稳健性和用户信任进行关键分析。 |
| [^43] | [Scaling Integer Arithmetic in Probabilistic Programs.](http://arxiv.org/abs/2307.13837) | 本文提出了一种利用整数算术结构扩展概率编程中整数分布的方法，通过二进制编码和知识编译实现了精确的概率推理，能够处理规模更大的整数分布。 |
| [^44] | [Offline Reinforcement Learning with On-Policy Q-Function Regularization.](http://arxiv.org/abs/2307.13824) | 本论文提出了一种无模型强化学习方法，通过正则化向行为策略的Q函数进行训练，而不是训练行为策略本身。该方法利用了Q函数的估计来处理外推误差，并在D4RL基准测试中展现了强大的性能。 |
| [^45] | [Fitting Auditory Filterbanks with Multiresolution Neural Networks.](http://arxiv.org/abs/2307.13821) | 本文提出了一种名为多分辨率神经网络（MuReNN）的神经音频模型，通过在离散小波变换（DWT）的八度子带上训练单独的卷积算子，解决了基于波形的深度学习面临的非参数和参数方法之间的困境。 |
| [^46] | [ForestMonkey: Toolkit for Reasoning with AI-based Defect Detection and Classification Models.](http://arxiv.org/abs/2307.13815) | 本文介绍了Forest Monkey（FM）工具包，它是一个用于推理任何基于AI的缺陷检测和/或分类模型输出结果的工具包。该工具包提供了可解释性的数据和图表，以帮助用户理解推理结果并提出改进建议。 |
| [^47] | [How to Scale Your EMA.](http://arxiv.org/abs/2307.13813) | 本研究提供了在存在模型EMA的情况下进行优化的缩放规则，以保持训练动态的一致性。这对于实际机器学习中的权衡批量大小和墙钟时间非常重要。模型EMA能够提高模型的性能以及稳定训练过程，并为自监督学习提供学习信号。 |
| [^48] | [Is GPT a Computational Model of Emotion? Detailed Analysis.](http://arxiv.org/abs/2307.13779) | 本文通过组件的视角研究了GPT系列大型语言模型的情感推理能力。尽管GPT的预测结果与人类提供的评估和情感标签显著一致，但在预测情感强度和应对反应方面遇到了困难。 |
| [^49] | [An Empirical Study on Bugs Inside PyTorch: A Replication Study.](http://arxiv.org/abs/2307.13777) | 本研究对PyTorch深度学习库中的错误进行了复制研究，通过调查和评估错误的原因和症状，提供了对错误识别和修复过程的了解。 |
| [^50] | [Combating the Curse of Multilinguality in Cross-Lingual WSD by Aligning Sparse Contextualized Word Representations.](http://arxiv.org/abs/2307.13776) | 本文提出了使用大型预训练单语语言模型和上下文化映射机制来解决跨语言词义消歧的多语言诅咒，并通过实验验证了这种方法的有效性。 |
| [^51] | [E^2VPT: An Effective and Efficient Approach for Visual Prompt Tuning.](http://arxiv.org/abs/2307.13770) | E^2VPT是一种有效和高效的大规模Transformer模型适应方法，通过引入可学习的键值和视觉提示，以及提示剪枝过程来改善模型微调的效果并提高模型的效率。 |
| [^52] | [ClusterSeq: Enhancing Sequential Recommender Systems with Clustering based Meta-Learning.](http://arxiv.org/abs/2307.13766) | ClusterSeq是一种基于聚类的元学习顺序推荐系统，通过利用用户序列的动态信息提高了物品预测的准确性，并保留了次要用户的偏好，并利用了同一聚类中用户的集体知识。 |
| [^53] | [Implicitly Normalized Explicitly Regularized Density Estimation.](http://arxiv.org/abs/2307.13763) | 我们提出了一种新的非参数密度估计方法，基于正则化密度的 Sobolev 范数，通过适当的初始化和使用自然梯度，可以得到性能良好的解，该方法在 Anomaly Detection benchmark 中排名第二。 |
| [^54] | [TMR-RD: Training-based Model Refinement and Representation Disagreement for Semi-Supervised Object Detection.](http://arxiv.org/abs/2307.13755) | 在半监督目标检测中，本文提出了基于训练的模型精化(TMR)阶段和表示分歧(RD)策略，用来解决伪标签噪声和教师-学生模型的一致性问题。TMR阶段通过轻量级缩放操作优化模型权重，防止过度拟合或遗忘学到的模式；RD策略帮助保持模型的差异，鼓励学生模型探索互补的表示。 |
| [^55] | [Foundational Models Defining a New Era in Vision: A Survey and Outlook.](http://arxiv.org/abs/2307.13721) | 这项调查提供了对新兴基础模型的全面回顾，这些模型能够通过人类提供的提示实现上下文推理、生成泛化的结果，并在测试时具有即时能力。 |
| [^56] | [Composite Diffusion | whole >= \Sigma parts.](http://arxiv.org/abs/2307.13720) | 本文引入了组合扩散作为艺术家生成高质量图像的方法，通过组合子场景并灵活布局，艺术家可以描述每个子场景的内容，并利用各种控制输入生成、组合和协调子场景，以实现综合而细致的图像生成。作者提出现有图像质量评估指标缺乏整体评估的能力，希望通过组合扩散方法来综合评估图像质量和实现艺术家意图。 |
| [^57] | [FedDRL: A Trustworthy Federated Learning Model Fusion Method Based on Staged Reinforcement Learning.](http://arxiv.org/abs/2307.13716) | FedDRL是一种分阶段强化学习的联邦学习模型融合方法，解决了传统方法中无法解决的客户端模型质量和恶意模型问题。 |
| [^58] | [Team Intro to AI team8 at CoachAI Badminton Challenge 2023: Advanced ShuttleNet for Shot Predictions.](http://arxiv.org/abs/2307.13715) | 本文提出了一个名为ShuttleNet的框架，通过利用过去的击球信息，显著改进了预测羽毛球击球类型和位置的性能，最终在CoachAI羽毛球挑战赛中获得第一名。 |
| [^59] | [Deep Bradley-Terry Rating: Estimate Properties Without Metric of Unseen Items.](http://arxiv.org/abs/2307.13709) | 本论文提出了深度布拉德利-特里评分（DBTR）方法，用于评估不一定存在于数据集中的未知物品的属性。该方法通过将传统的布拉德利-特里模型与神经网络结构无缝结合，成功地学习了这些属性的预期量化。 |
| [^60] | [Introducing CALMED: Multimodal Annotated Dataset for Emotion Detection in Children with Autism.](http://arxiv.org/abs/2307.13706) | 本研究介绍了CALMED，这是一个针对自闭症儿童的多模态情绪检测数据集，旨在改进自动情绪检测系统在自闭症患者身上的表现。 |
| [^61] | [Control and Monitoring of Artificial Intelligence Algorithms.](http://arxiv.org/abs/2307.13705) | 论文阐述了控制和监控人工智能算法的重要性，介绍了数据漂移和概念漂移的概念，并提出了一系列指标用于审查模型在潜在时间变化方面的性能。 |
| [^62] | [eXplainable Artificial Intelligence (XAI) in age prediction: A systematic review.](http://arxiv.org/abs/2307.13704) | 本综述探讨了可解释人工智能（XAI）在年龄预测任务中的应用。通过系统性综述，我们讨论了XAI方法在医疗应用和年龄预测领域的益处。 |
| [^63] | [Measuring Faithfulness in Chain-of-Thought Reasoning.](http://arxiv.org/abs/2307.13702) | 本研究探讨了在回答问题之前，大型语言模型（LLMs）能否进行忠实的“链式思维”推理。结果显示，模型在不同任务上对链式思维的依赖程度有很大变化，随着模型变得更大更能力越强，它们在大多数任务中产生的推理越来越不忠实。 |
| [^64] | [$\text{EFO}_{k}$-CQA: Towards Knowledge Graph Complex Query Answering beyond Set Operation.](http://arxiv.org/abs/2307.13701) | 本文提出了$\text{EFO}_{k}$-CQA框架，用于超越集合操作的知识图谱复杂查询回答。该框架包括数据生成、模型训练和方法评估，并且扩展了现有查询空间。使用构建的$\text{EFO}_{k}$-CQA数据集进行实证评估，结果揭示了查询难度对结果的影响。此外，还证明了现有数据集构建过程存在的问题。 |
| [^65] | [CAMP: A Context-Aware Cricket Players Performance Metric.](http://arxiv.org/abs/2307.13700) | CAMP是一种上下文感知的板球球员表现指标，通过综合考虑对手实力和比赛环境等因素，可以量化个体球员对比赛结果的贡献。CAMP通过数据挖掘方法，为选择和草案、教练和训练、团队阵容和战略制定提供数据驱动的决策支持。 |
| [^66] | [EFL Students' Attitudes and Contradictions in a Machine-in-the-loop Activity System.](http://arxiv.org/abs/2307.13699) | 这项研究探讨了67位来自香港四所中学的EFL学生对机器辅助写作的态度和矛盾。研究发现学生对机器辅助写作持积极态度，但也存在一些负面或矛盾的感情。研究提出了在EFL课堂中实施机器辅助写作的益处和挑战，建议教育工作者将活动目标与学生的价值观、语言能力和AI能力相一致，以提高学生的活动系统。 |
| [^67] | [GPT-3 Models are Few-Shot Financial Reasoners.](http://arxiv.org/abs/2307.13617) | GPT-3模型在金融领域的少样本推理表现有限，需要使用独立的检索模型和逻辑引擎来获得最佳性能。 |
| [^68] | [FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios.](http://arxiv.org/abs/2307.13528) | 提出了FacTool框架，用于检测大型语言模型（如ChatGPT）生成的文本中的事实错误。实验结果表明该方法在知识型问答、代码生成、数学推理和科学文献综述等四个任务中具有良好的效果。 |
| [^69] | [Duet: efficient and scalable hybriD neUral rElation undersTanding.](http://arxiv.org/abs/2307.13494) | Duet是一种高效且可扩展的混合神经关系理解方法，旨在解决基数估计问题中高成本和难以区分的采样方法，并通过可微分的预测过程改进模型的准确性。 |
| [^70] | [On the learning Dynamics of Attention Networks.](http://arxiv.org/abs/2307.13421) | 本研究分析了软注意力、硬注意力和潜变量边际似然（LVML）注意力三种注意力模型的学习动态，发现了它们在所选择的片段聚合方式上的显著差异，并解释了分类模型在梯度下降下的演化对最终结果的影响。 |
| [^71] | [Hierarchical Skeleton Meta-Prototype Contrastive Learning with Hard Skeleton Mining for Unsupervised Person Re-Identification.](http://arxiv.org/abs/2307.12917) | 本文提出了一种无监督的层次骨架元-原型对比学习（Hi-MPC）方法，结合硬骨架挖掘，用于无标签3D骨架的人物重新识别。通过构建层次骨架表示并利用元-原型对比学习进行特征提取和聚类，实现了更多信息丰富的骨架特征的利用。 |
| [^72] | [MediaGPT : A Large Language Model For Chinese Media.](http://arxiv.org/abs/2307.10930) | 本论文提出了MediaGPT，一个用于中国媒体领域的大型语言模型。通过特定领域数据和专家数据的训练，MediaGPT在各种中国媒体任务上优于主流模型，并验证了其重要性。 |
| [^73] | [AdjointDPM: Adjoint Sensitivity Method for Gradient Backpropagation of Diffusion Probabilistic Models.](http://arxiv.org/abs/2307.10711) | AdjointDPM是一种新的伴随灵敏度方法，用于扩散概率模型的梯度反向传播，解决了DPM定制化中内存消耗高的问题，并通过解决增强的ODE将损失的梯度反向传播到模型的参数。 |
| [^74] | [Deceptive Alignment Monitoring.](http://arxiv.org/abs/2307.10569) | 本论文提出了欺骗性对齐监测这一新方向，旨在探讨大型机器学习模型在表面上表现正常，却暗中进行隐藏行为的问题，并提出了新的研究机会。 |
| [^75] | [Do Emergent Abilities Exist in Quantized Large Language Models: An Empirical Study.](http://arxiv.org/abs/2307.08072) | 本研究旨在研究量子化对大型语言模型中的新兴能力的影响，结果显示在4位量化模型中这些新兴能力仍然存在。 |
| [^76] | [No Train No Gain: Revisiting Efficient Training Algorithms For Transformer-based Language Models.](http://arxiv.org/abs/2307.06440) | 本论文重新审视了基于Transformer的语言模型的高效训练算法，包括动态架构，批量选择和高效优化器。然而，在使用这些算法预训练时，相对于基线方法，它们的训练、验证和下游收益消失了。同时，论文提出了一个评估协议来进行计算，并释放了代码来促进高效训练的研究。 |
| [^77] | [SAS Video-QA: Self-Adaptive Sampling for Efficient Video Question-Answering.](http://arxiv.org/abs/2307.04192) | SAS视频问答通过自适应采样策略解决了视频问答中的问题，提高了效率和准确性 |
| [^78] | [Derivative Free Weight-space Ensembling.](http://arxiv.org/abs/2307.03506) | 本文引入了一种新的无导数权重空间集成方法（DFWE），用于开放域对话的少样本任务传递。通过在几个不同的知识库的角度上对专家模型进行微调，并使用无梯度优化算法进行线性插值，我们有效地找到了一个好的模型权重插值，从而在FETA-Friends上超过了标准的预训练-微调方法。 |
| [^79] | [DifFSS: Diffusion Model for Few-Shot Semantic Segmentation.](http://arxiv.org/abs/2307.00773) | DifFSS是一种利用扩散模型改进小样本语义分割性能的方法，通过生成多样化的辅助支持图像，而不需要修改网络结构，从而显著提高最先进的小样本语义分割模型的性能。 |
| [^80] | [FedNoisy: Federated Noisy Label Learning Benchmark.](http://arxiv.org/abs/2306.11650) | FedNoisy是第一个标准化的联合噪声标签学习基准测试，并提供20个基本设置和标准化的仿真流程，以帮助研究人员探索联合学习中噪声标签的影响。 |
| [^81] | [Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse Engineering of Language at Scale.](http://arxiv.org/abs/2306.00017) | 本文提出结合符号表示和自下而上的逆向工程的方法，解决大规模语言模型在真正语言理解上的局限性，实现可解释的、语言无关的LLMs。 |
| [^82] | [Null-text Guidance in Diffusion Models is Secretly a Cartoon-style Creator.](http://arxiv.org/abs/2305.06710) | 本文发现，模型扩散中的无标注文本实际上是一个能够生成卡通风格图片的工具。通过简单地扰动无标注文本指导，这一功能得以实现。回滚扰动能够将生成的图像有效转换成卡通图像，而图像扰动则能够产生高保真度、多样性的卡通图像。 |
| [^83] | [Uncertainty-driven Trajectory Truncation for Data Augmentation in Offline Reinforcement Learning.](http://arxiv.org/abs/2304.04660) | 本研究提出了一种基于不确定性的轨迹截断方法（TATU），用于解决模型驱动的离线强化学习中生成样本不可靠的问题。实验证明TATU相较于其他方法表现优越。 |
| [^84] | [The Stable Signature: Rooting Watermarks in Latent Diffusion Models.](http://arxiv.org/abs/2303.15435) | 本文介绍了一种结合图像水印和潜在扩散模型的方法，使所有生成的图像都能隐藏一个不可见的水印，该方法在各种生成任务中表现出良好的隐形性和鲁棒性。 |
| [^85] | [Generative AI Assistants in Software Development Education.](http://arxiv.org/abs/2303.13936) | 本文探讨了当前软件开发行业采用生成式 AI（GAI）助手进行软件开发的现状和挑战，提出了未来软件开发教育的愿景和教学建议。 |
| [^86] | [Quantifying & Modeling Multimodal Interactions: An Information Decomposition Framework.](http://arxiv.org/abs/2302.12247) | 通过引入信息分解框架，我们提供了一种量化和建模多模态交互的方法，通过PID统计量来度量输入模态与输出任务之间的冗余度、独特性和协同性，并引入了两个新的PID统计估计器。 |
| [^87] | [A Novel Deep Reinforcement Learning Based Automated Stock Trading System Using Cascaded LSTM Networks.](http://arxiv.org/abs/2212.02721) | 本文提出了一种使用级联LSTM网络的基于深度强化学习的自动股票交易系统，通过对股票数据进行特征提取和策略函数训练，我们的模型在累积回报和夏普比率方面优于基准模型，特别在中国股市这一新兴市场中表现更为突出。 |
| [^88] | [Formal Controller Synthesis for Markov Jump Linear Systems with Uncertain Dynamics.](http://arxiv.org/abs/2212.00679) | 本文介绍了一种方法，用于合成马尔可夫跳变线性系统（MJLS）的控制器，以确保满足概率计算树逻辑（PCTL）公式，对于转移概率未知或已知但存在一定的区间的问题提出了解决方案。 |
| [^89] | [FsaNet: Frequency Self-attention for Semantic Segmentation.](http://arxiv.org/abs/2211.15595) | FsaNet是一种用于语义分割的新型自注意机制，通过在不同频段上进行个性化处理，可以在保留边缘的同时促进对象内的相似性。通过消融研究表明，即使不重新训练网络，低频自注意力也可以达到接近或更好的性能。频率自注意力还简化了令牌映射和令牌混合阶段，具有较低的计算复杂性。 |
| [^90] | [Early Detection of Bark Beetle Attack Using Remote Sensing and Machine Learning: A Review.](http://arxiv.org/abs/2210.03829) | 本文综述了早期检测树皮甲虫攻击的过去和现有进展，重点关注了使用遥感和机器学习方法的优势和劣势，以及提供了有关树皮甲虫物种、攻击阶段、寄主树木、研究区域、遥感平台与传感器、光谱分辨率、光谱特征、机器学习方法和深度学习网络的知识。 |
| [^91] | [FedIIC: Towards Robust Federated Learning for Class-Imbalanced Medical Image Classification.](http://arxiv.org/abs/2206.13803) | 提出了一种名为FedIIC的隐私保护联邦学习方法，从特征学习和分类器学习两个角度解决了类别不平衡的医学图像分类问题。 |
| [^92] | [Priors in Deep Image Restoration and Enhancement: A Survey.](http://arxiv.org/abs/2206.02070) | 这篇论文是对深度图像恢复和增强中先验知识最新进展的综述，包括理论分析、分类、讨论和问题总结。 |
| [^93] | [Fairness in Recommendation: Foundations, Methods and Applications.](http://arxiv.org/abs/2205.13619) | 这篇论文对推荐系统中的公平性问题进行了系统调查，针对推荐过程中可能出现的数据或算法偏见，提供了一些方法和应用来提升推荐中的公平性。 |
| [^94] | [Robust Quantity-Aware Aggregation for Federated Learning.](http://arxiv.org/abs/2205.10848) | 本文提出了一种针对联邦学习的强健的数量感知聚合算法，名为FedRA，能够在聚合模型时考虑本地数据的数量，并能够抵御数量增强攻击。 |
| [^95] | [MICDIR: Multi-scale Inverse-consistent Deformable Image Registration using UNetMSS with Self-Constructing Graph Latent.](http://arxiv.org/abs/2203.04317) | 本文提出了MICDIR方法，在多尺度上使用UNetMSS和自构建图潜变量，用于解决医学图像配准中存在的全局依赖性和大形变的问题。 |
| [^96] | [Exploring Multi-Modal Representations for Ambiguity Detection & Coreference Resolution in the SIMMC 2.0 Challenge.](http://arxiv.org/abs/2202.12645) | 本文在SIMMC 2.0挑战中探索了多模态表达对于歧义检测和共识消解的影响，并通过实验证明了语言模型的能力和基于单模态的共识消解模型的优势。 |
| [^97] | [Priming Cross-Session Motor Imagery Classification with A Universal Deep Domain Adaptation Framework.](http://arxiv.org/abs/2202.09559) | 本文提出了一个基于数学模型的深度域适应框架，用于处理跨会话运动想象分类问题。该框架能够轻松应用于现有的人工神经网络，无需改变网络结构，并通过通道归一化和欧氏对齐构建了域不变性。 |
| [^98] | [Combining optimal path search with task-dependent learning in a neural network.](http://arxiv.org/abs/2201.11104) | 这篇论文提出了一种在神经网络中结合最优路径搜索和任务相关学习的方法，通过将成本值转化为神经网络的权重来实现在线权重适应。实验结果表明，该方法与经典算法Bellman-Ford具有相同的解，并且网络学习机制可以进一步增强算法的性能。 |

# 详细

[^1]: WavJourney：使用大型语言模型进行音频创作

    WavJourney: Compositional Audio Creation with Large Language Models. (arXiv:2307.14335v1 [cs.SD])

    [http://arxiv.org/abs/2307.14335](http://arxiv.org/abs/2307.14335)

    本研究提出了WavJourney系统，利用大型语言模型实现音频内容的创作。该系统可以根据文本指令生成包含语音、音乐和音效的音频内容。

    

    大型语言模型在整合不同的专家模型以解决复杂的语言和视觉任务方面显示出巨大的潜力。尽管它们在推动人工智能生成内容领域的发展方面具有重要意义，但它们在智能音频内容创作方面的潜力仍未被发掘。在这项工作中，我们解决了使用文本指令创建涵盖语音、音乐和音效的音频内容的问题。我们提出了一种名为WavJourney的系统，利用大型语言模型连接各种音频模型进行音频内容生成。给定一个听觉场景的文本描述，WavJourney首先提示大型语言模型生成一个专用于音频叙事的结构脚本。音频脚本包含了不同的音频元素，根据它们的时空关系进行组织。作为音频的概念表示，音频脚本为人类参与提供了互动和可解释的理由。随后，音频脚本被传递给音频生成模型，生成相应的音频内容。

    Large Language Models (LLMs) have shown great promise in integrating diverse expert models to tackle intricate language and vision tasks. Despite their significance in advancing the field of Artificial Intelligence Generated Content (AIGC), their potential in intelligent audio content creation remains unexplored. In this work, we tackle the problem of creating audio content with storylines encompassing speech, music, and sound effects, guided by text instructions. We present WavJourney, a system that leverages LLMs to connect various audio models for audio content generation. Given a text description of an auditory scene, WavJourney first prompts LLMs to generate a structured script dedicated to audio storytelling. The audio script incorporates diverse audio elements, organized based on their spatio-temporal relationships. As a conceptual representation of audio, the audio script provides an interactive and interpretable rationale for human engagement. Afterward, the audio script is fe
    
[^2]: 基于事件视觉的早期操纵动作预测

    Event-based Vision for Early Prediction of Manipulation Actions. (arXiv:2307.14332v1 [cs.CV])

    [http://arxiv.org/abs/2307.14332](http://arxiv.org/abs/2307.14332)

    本研究基于事件的视觉数据集，利用Transformer网络提前预测操纵动作，实现了最先进的分类效果。

    

    神经形态视觉传感器是人工视网膜，当场景中发生亮度变化时输出异步事件序列。这些传感器具有很多优势，包括非常高的时间分辨率，没有运动模糊和智能数据压缩，非常适合实时处理。在本研究中，我们介绍了一个关于细粒度操纵动作的基于事件的数据集，并对使用Transformer进行事件动作预测进行了实验研究。在认知机器人和人机交互领域，对理解和预测人类动作的兴趣很大，尽早预测能够让我们预测规划复杂阶段，实现有效的实时交互。我们的Transformer网络使用事件在其发生时预测操纵动作，使用在线推理。该模型能够在早期预测动作，并随着时间推移逐渐建立信心，实现了最先进的分类效果。

    Neuromorphic visual sensors are artificial retinas that output sequences of asynchronous events when brightness changes occur in the scene. These sensors offer many advantages including very high temporal resolution, no motion blur and smart data compression ideal for real-time processing. In this study, we introduce an event-based dataset on fine-grained manipulation actions and perform an experimental study on the use of transformers for action prediction with events. There is enormous interest in the fields of cognitive robotics and human-robot interaction on understanding and predicting human actions as early as possible. Early prediction allows anticipating complex stages for planning, enabling effective and real-time interaction. Our Transformer network uses events to predict manipulation actions as they occur, using online inference. The model succeeds at predicting actions early on, building up confidence over time and achieving state-of-the-art classification. Moreover, the at
    
[^3]: 基于路径点的机器人操作模仿学习

    Waypoint-Based Imitation Learning for Robotic Manipulation. (arXiv:2307.14326v1 [cs.RO])

    [http://arxiv.org/abs/2307.14326](http://arxiv.org/abs/2307.14326)

    该论文提出了一种基于路径点的机器人操作模仿学习方法，通过自动提取路径点来减少行为克隆中累积误差的问题。

    

    尽管模仿学习方法在机器人操作中再次引起了广泛关注，但误差累积问题仍然困扰着行为克隆（BC）。路径点可以通过减少BC学习问题的视野来解决这个问题，从而减少随时间累积的误差。然而，路径点标记是不充分的，并且需要额外的人工监督。我们的关键见解是，如果一个轨迹段可以用线性运动近似，那么端点可以用作路径点。我们提出了一种基于自动路径点提取（AWE）的模仿学习预处理模块，将演示分解为一组最小的路径点，线性插值可以近似到指定的误差阈值。AWE可以与任何BC算法结合使用，并且我们发现AWE能够提高最先进算法的成功率。

    While imitation learning methods have seen a resurgent interest for robotic manipulation, the well-known problem of compounding errors continues to afflict behavioral cloning (BC). Waypoints can help address this problem by reducing the horizon of the learning problem for BC, and thus, the errors compounded over time. However, waypoint labeling is underspecified, and requires additional human supervision. Can we generate waypoints automatically without any additional human supervision? Our key insight is that if a trajectory segment can be approximated by linear motion, the endpoints can be used as waypoints. We propose Automatic Waypoint Extraction (AWE) for imitation learning, a preprocessing module to decompose a demonstration into a minimal set of waypoints which when interpolated linearly can approximate the trajectory up to a specified error threshold. AWE can be combined with any BC algorithm, and we find that AWE can increase the success rate of state-of-the-art algorithms by u
    
[^4]: 评估LLMs中编码的道德信念

    Evaluating the Moral Beliefs Encoded in LLMs. (arXiv:2307.14324v1 [cs.CL])

    [http://arxiv.org/abs/2307.14324](http://arxiv.org/abs/2307.14324)

    本文提出了一种对LLMs中编码的道德信念进行评估的案例研究方法。通过设计大规模调查了解不同LLMs中的道德信念，在明确的情况下，LLMs倾向于与人类的道德直觉保持一致，但在模糊的情况下，它们的回答会有所不同，并可能存在偏见和不一致性。

    

    本文提供了一个关于对大型语言模型(LLMs)进行设计、管理、后处理和评估调查的案例研究。它包括两个组成部分：(1) 一种用于获取LLMs中编码的信念的统计方法。我们介绍了统计量和评估指标，用于量化LLM“做出选择”的概率、相关的不确定性以及选择的一致性。(b) 我们将这种方法应用于研究不同LLMs中编码的道德信念，特别是在正确选择不明显的模糊情况下。我们设计了一个大规模调查，其中包括680个高模糊度的道德场景（例如，“我应该撒一个善意的谎言吗？”）和687个低模糊度的道德场景（例如，“我应该为路上的行人停下来吗？”）。每个场景包括一个描述、两个可能的行动以及指示违反规则的辅助标签（例如，“不要杀人”）。我们将这个调查应用于28个开源和闭源的LLMs。我们发现(b) 在明确的情况下，LLMs tend to align with human moral intuitions, but in ambiguous scenarios, their responses vary and may exhibit biases and inconsistencies.

    This paper presents a case study on the design, administration, post-processing, and evaluation of surveys on large language models (LLMs). It comprises two components: (1) A statistical method for eliciting beliefs encoded in LLMs. We introduce statistical measures and evaluation metrics that quantify the probability of an LLM "making a choice", the associated uncertainty, and the consistency of that choice. (2) We apply this method to study what moral beliefs are encoded in different LLMs, especially in ambiguous cases where the right choice is not obvious. We design a large-scale survey comprising 680 high-ambiguity moral scenarios (e.g., "Should I tell a white lie?") and 687 low-ambiguity moral scenarios (e.g., "Should I stop for a pedestrian on the road?"). Each scenario includes a description, two possible actions, and auxiliary labels indicating violated rules (e.g., "do not kill"). We administer the survey to 28 open- and closed-source LLMs. We find that (a) in unambiguous scen
    
[^5]: 通过引导安全探索的强化学习

    Reinforcement Learning by Guided Safe Exploration. (arXiv:2307.14316v1 [cs.LG])

    [http://arxiv.org/abs/2307.14316](http://arxiv.org/abs/2307.14316)

    本文研究了一种通过引导安全探索的强化学习方法，通过训练一个代理在没有奖励信号的情况下学习安全探索，然后利用其构建一个安全的行为策略，并且借鉴迁移学习的思想，在训练过程中逐渐消除引导代理的影响。

    

    安全性对于扩大强化学习(RL)的应用至关重要。我们经常在受控环境中训练RL智能体，如实验室，然后再在真实世界中部署它们。然而，在部署之前，真实世界的目标任务可能是未知的。无奖励RL在没有奖励的情况下训练智能体，以便在奖励揭示后能够快速适应。我们考虑了有约束的无奖励设置，其中一个代理（导引者）在没有奖励信号的情况下学习安全探索。该代理在受控环境中接受训练，可以进行不安全的交互但仍提供安全信号。当目标任务被揭示后，不允许违反安全规则。因此，导引者被利用来构建一个安全的行为策略。受到迁移学习的启发，我们还将目标策略（学生）向导引者进行正则化，同时学生在可靠性上是不可靠的，并逐渐消除导引者在训练过程中的影响。实证分析显示...

    Safety is critical to broadening the application of reinforcement learning (RL). Often, we train RL agents in a controlled environment, such as a laboratory, before deploying them in the real world. However, the real-world target task might be unknown prior to deployment. Reward-free RL trains an agent without the reward to adapt quickly once the reward is revealed. We consider the constrained reward-free setting, where an agent (the guide) learns to explore safely without the reward signal. This agent is trained in a controlled environment, which allows unsafe interactions and still provides the safety signal. After the target task is revealed, safety violations are not allowed anymore. Thus, the guide is leveraged to compose a safe behaviour policy. Drawing from transfer learning, we also regularize a target policy (the student) towards the guide while the student is unreliable and gradually eliminate the influence of the guide as training progresses. The empirical analysis shows tha
    
[^6]: ChatGPT和说服技术在酒店服务领域个性化推荐管理和提供中的应用

    ChatGPT and Persuasive Technologies for the Management and Delivery of Personalized Recommendations in Hotel Hospitality. (arXiv:2307.14298v1 [cs.IR])

    [http://arxiv.org/abs/2307.14298](http://arxiv.org/abs/2307.14298)

    本文研究了将ChatGPT和说服技术应用于酒店推荐系统的潜力，通过ChatGPT可以提供更准确和上下文感知的推荐，而说服技术可影响用户行为并增强推荐的说服力。

    

    推荐系统在酒店服务业已成为不可或缺的工具，为客人提供个性化和定制化的体验。近年来，大型语言模型（LLM），如ChatGPT和说服技术的进步，为提升这些系统的效果打开了新的途径。本文探讨了将ChatGPT和说服技术整合到酒店服务推荐系统中自动化和改进的潜力。首先，我们深入研究了ChatGPT的能力，它可以理解和生成类似人类的文本，从而实现更准确和上下文感知的推荐。我们讨论了将ChatGPT整合到推荐系统中的能力，突出了其分析用户偏好、从在线评论中提取有价值的洞见，并根据客人配置生成个性化推荐的能力。其次，我们研究了说服技术在影响用户行为和提升酒店推荐的说服效果方面的作用。

    Recommender systems have become indispensable tools in the hotel hospitality industry, enabling personalized and tailored experiences for guests. Recent advancements in large language models (LLMs), such as ChatGPT, and persuasive technologies, have opened new avenues for enhancing the effectiveness of those systems. This paper explores the potential of integrating ChatGPT and persuasive technologies for automating and improving hotel hospitality recommender systems. First, we delve into the capabilities of ChatGPT, which can understand and generate human-like text, enabling more accurate and context-aware recommendations. We discuss the integration of ChatGPT into recommender systems, highlighting the ability to analyze user preferences, extract valuable insights from online reviews, and generate personalized recommendations based on guest profiles. Second, we investigate the role of persuasive technology in influencing user behavior and enhancing the persuasive impact of hotel recomm
    
[^7]: 揭示拆分序列数据的复杂性：解决视频和时间序列分析中的挑战

    Unraveling the Complexity of Splitting Sequential Data: Tackling Challenges in Video and Time Series Analysis. (arXiv:2307.14294v1 [cs.LG])

    [http://arxiv.org/abs/2307.14294](http://arxiv.org/abs/2307.14294)

    本概念文章研究了各种拆分序列数据的挑战，并通过电机测试台和液体中的粒子跟踪等实例进行了探索。

    

    序列数据的拆分，如视频和时间序列，是各种数据分析任务的重要步骤，包括目标跟踪和异常检测。然而，拆分序列数据面临各种挑战，可能会影响后续分析的准确性和可靠性。本概念文章研究了与拆分序列数据相关的挑战，包括数据获取、数据表示、拆分比例选择、建立质量标准和选择合适的选择策略。我们通过两个真实世界的例子进行了探索：电机测试台和液体中的粒子跟踪。

    Splitting of sequential data, such as videos and time series, is an essential step in various data analysis tasks, including object tracking and anomaly detection. However, splitting sequential data presents a variety of challenges that can impact the accuracy and reliability of subsequent analyses. This concept article examines the challenges associated with splitting sequential data, including data acquisition, data representation, split ratio selection, setting up quality criteria, and choosing suitable selection strategies. We explore these challenges through two real-world examples: motor test benches and particle tracking in liquids.
    
[^8]: 通用目的人工智能系统（GPAIS）：性质、定义、分类、开放挑战和影响

    General Purpose Artificial Intelligence Systems (GPAIS): Properties, Definition, Taxonomy, Open Challenges and Implications. (arXiv:2307.14283v1 [cs.AI])

    [http://arxiv.org/abs/2307.14283](http://arxiv.org/abs/2307.14283)

    这里是中文总结出的一句话要点：本论文讨论了通用目的人工智能系统（GPAIS）的性质、定义、分类和开放挑战，并提出了一种新的定义，允许根据其性质和限制逐步区分GPAIS的类型。

    

    大部分人工智能（AI）应用都设计用于特定和有限的任务。然而，有许多场景需要更通用的AI，能够解决各种任务而不需要专门为它们设计。通用目的人工智能系统（GPAIS）这个术语被定义为指代这些AI系统。尽管迄今为止，实现人工通用智能的可能性，即足够强大以模拟人类并改进各种智力任务，一直是一个愿望、虚构的概念，并被认为对我们社会构成风险。虽然我们离实现这一目标可能还很遥远，但GPAIS是现实存在并位居人工智能研究的前沿。本文讨论了现有GPAIS定义，并提出了一种新的定义，允许根据其性质和限制逐步区分GPAIS的类型。我们区分了封闭世界和开放世界的GPAIS，描述其自主程度和...

    Most applications of Artificial Intelligence (AI) are designed for a confined and specific task. However, there are many scenarios that call for a more general AI, capable of solving a wide array of tasks without being specifically designed for them. The term General-Purpose Artificial Intelligence Systems (GPAIS) has been defined to refer to these AI systems. To date, the possibility of an Artificial General Intelligence, powerful enough to perform any intellectual task as if it were human, or even improve it, has remained an aspiration, fiction, and considered a risk for our society. Whilst we might still be far from achieving that, GPAIS is a reality and sitting at the forefront of AI research.  This work discusses existing definitions for GPAIS and proposes a new definition that allows for a gradual differentiation among types of GPAIS according to their properties and limitations. We distinguish between closed-world and open-world GPAIS, characterising their degree of autonomy and
    
[^9]: 通过相互有条件的约束承诺改进国际气候政策

    Improving International Climate Policy via Mutually Conditional Binding Commitments. (arXiv:2307.14267v1 [cs.CY])

    [http://arxiv.org/abs/2307.14267](http://arxiv.org/abs/2307.14267)

    本文介绍了一种名为有条件的承诺机制的分散，自下而上的方法，旨在通过形式化国际气候政策中的有条件合作来解决无条件性贡献带来的问题。该机制受民主全民投票州间协定的启发，并提供灵活性和激励措施，以促使早期采用者。期望能改善大污染国的自由骑车行为，从而提高国际气候政策的有效性。

    

    巴黎协定被认为是气候谈判中的重要里程碑，但由于大多数国家自主确定贡献的无条件性质，它在有效应对气候变化方面面临挑战。这导致主要污染国存在自由骑车行为，并且国家自主确定贡献缺乏具体的条件性。为了解决这个问题，我们提出了一个分散的自下而上的方法，名为有条件的承诺机制。这个机制受到“民主全民投票州间协定”的启发，为早期采用者提供灵活性和激励，并旨在规范国际气候政策中的有条件合作。在本文中，我们概述了这个机制，介绍了其在AI4ClimateCooperation挑战中的表现，并讨论了潜在的实际实施方面。假定读者具备有关气候减缓集体行动问题、基本经济原理和博弈论概念的先前知识。

    The Paris Agreement, considered a significant milestone in climate negotiations, has faced challenges in effectively addressing climate change due to the unconditional nature of most Nationally Determined Contributions (NDCs). This has resulted in a prevalence of free-riding behavior among major polluters and a lack of concrete conditionality in NDCs. To address this issue, we propose the implementation of a decentralized, bottom-up approach called the Conditional Commitment Mechanism. This mechanism, inspired by the National Popular Vote Interstate Compact, offers flexibility and incentives for early adopters, aiming to formalize conditional cooperation in international climate policy. In this paper, we provide an overview of the mechanism, its performance in the AI4ClimateCooperation challenge, and discuss potential real-world implementation aspects. Prior knowledge of the climate mitigation collective action problem, basic economic principles, and game theory concepts are assumed.
    
[^10]: 通过相互条件绑定承诺来改进国际气候政策

    Improving International Climate Policy via Mutually Conditional Binding Commitments. (arXiv:2307.14266v1 [cs.CY])

    [http://arxiv.org/abs/2307.14266](http://arxiv.org/abs/2307.14266)

    本文提出了改进RICE-N模拟和多智能体强化学习框架的方法，以提高国际气候政策谈判的逼真度和决策效果。

    

    本文提出了改善RICE-N模拟和多智能体强化学习框架的方法，以提高国际气候政策谈判的逼真度。我们强调了框架的价值，并指出了需要进行重大改进来解决建模气候谈判中各种因素的多样性的必要性。在我们之前的工作《条件承诺机制》（CCF机制）的基础上，我们讨论了如何弥合模拟和现实之间的差距。我们建议加入一个推荐或计划代理以增强协调，通过纳入社会因素和非当事方利益相关者副代理来解决Real2Sim差距，并提出改进底层强化学习解决方案算法。这些改进旨在推进Rice-N中用于更有效的国际气候政策决策的谈判协议的评估和制定。然而，还需要进一步的实验和测试。

    This paper proposes enhancements to the RICE-N simulation and multi-agent reinforcement learning framework to improve the realism of international climate policy negotiations. Acknowledging the framework's value, we highlight the necessity of significant enhancements to address the diverse array of factors in modeling climate negotiations. Building upon our previous work on the "Conditional Commitments Mechanism" (CCF mechanism) we discuss ways to bridge the gap between simulation and reality. We suggest the inclusion of a recommender or planner agent to enhance coordination, address the Real2Sim gap by incorporating social factors and non-party stakeholder sub-agents, and propose enhancements to the underlying Reinforcement Learning solution algorithm. These proposed improvements aim to advance the evaluation and formulation of negotiation protocols for more effective international climate policy decision-making in Rice-N. However, further experimentation and testing are required to d
    
[^11]: 关于可解释人工智能（XAI）评估方法的新视角

    A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI). (arXiv:2307.14246v1 [cs.AI])

    [http://arxiv.org/abs/2307.14246](http://arxiv.org/abs/2307.14246)

    这项工作通过批判性地审视解释性和性能之间的所谓权衡，提出了一种以细致入微的方式来处理这个问题的方法，考虑到资源可用性、领域特征和风险因素。这为未来研究和最佳实践奠定了基础。

    

    在需求工程领域中，可解释人工智能（XAI）在将AI支持的系统与用户需求、社会期望和监管标准相一致方面的重要性日益受到认可。总体而言，可解释性已经成为影响系统质量的重要非功能性需求。然而，解释性和性能之间的所谓权衡挑战了解释性的预期正面影响。如果满足解释性的要求意味着系统性能的降低，那么必须慎重考虑这两个质量方面的优先顺序以及如何权衡它们。在本文中，我们对这种所谓的权衡进行了批判性的审视。我们认为最好以细致入微的方式来处理这个问题，考虑到资源可用性、领域特征和风险因素。通过为未来的研究和最佳实践提供基础，本工作旨在促进XAI领域的发展。

    Within the field of Requirements Engineering (RE), the increasing significance of Explainable Artificial Intelligence (XAI) in aligning AI-supported systems with user needs, societal expectations, and regulatory standards has garnered recognition. In general, explainability has emerged as an important non-functional requirement that impacts system quality. However, the supposed trade-off between explainability and performance challenges the presumed positive influence of explainability. If meeting the requirement of explainability entails a reduction in system performance, then careful consideration must be given to which of these quality aspects takes precedence and how to compromise between them. In this paper, we critically examine the alleged trade-off. We argue that it is best approached in a nuanced way that incorporates resource availability, domain characteristics, and considerations of risk. By providing a foundation for future research and best practices, this work aims to ad
    
[^12]: 重访可解释人工智能中的性能-可解释性权衡问题

    Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI). (arXiv:2307.14239v1 [cs.AI])

    [http://arxiv.org/abs/2307.14239](http://arxiv.org/abs/2307.14239)

    本文重新审视了在可解释人工智能中性能和可解释性之间的权衡问题，并提出了资源可用性、领域特征和风险考虑的细致方法。为未来研究和最佳实践提供基础。

    

    在需求工程领域中，可解释人工智能（XAI）在将AI支持的系统与用户需求、社会期望和法规标准对齐方面的重要性逐渐得到认识。一般来说，可解释性已经成为一个重要的非功能需求，影响着系统的质量。然而，可解释性和性能之间的权衡挑战了可解释性的预期积极影响。如果满足可解释性的要求意味着系统性能的降低，那么必须仔细考虑哪个质量方面更为重要，以及如何在它们之间取得妥协。在本文中，我们对这种所谓的权衡进行了批判性的考察。我们认为最好以一种细致入微的方式来处理这个问题，包括资源可用性、领域特征以及风险的考虑。通过为未来研究和最佳实践提供基础，本研究旨在提供一个解决该问题的指导。

    Within the field of Requirements Engineering (RE), the increasing significance of Explainable Artificial Intelligence (XAI) in aligning AI-supported systems with user needs, societal expectations, and regulatory standards has garnered recognition. In general, explainability has emerged as an important non-functional requirement that impacts system quality. However, the supposed trade-off between explainability and performance challenges the presumed positive influence of explainability. If meeting the requirement of explainability entails a reduction in system performance, then careful consideration must be given to which of these quality aspects takes precedence and how to compromise between them. In this paper, we critically examine the alleged trade-off. We argue that it is best approached in a nuanced way that incorporates resource availability, domain characteristics, and considerations of risk. By providing a foundation for future research and best practices, this work aims to ad
    
[^13]: UnScientify: 检测学术全文中的科学不确定性

    UnScientify: Detecting Scientific Uncertainty in Scholarly Full Text. (arXiv:2307.14236v1 [cs.CL])

    [http://arxiv.org/abs/2307.14236](http://arxiv.org/abs/2307.14236)

    UnScientify是一个交互系统，可以检测学术全文中的科学不确定性。它利用弱监督技术和细粒度注释方案，自动标记和注释科学不确定性，并提供可解释的结果。

    

    本演示论文介绍了UnScientify，一个用于检测学术全文中科学不确定性的交互系统。该系统利用一种弱监督技术，采用细粒度注释方案，从句子级别上识别科学文本中口头表述的不确定性。系统的流程包括模式匹配、复杂句子检查和作者参考检查。我们的方法自动标记和注释科学不确定性识别任务，考虑了不同类型的科学不确定性，可以用于信息检索、文本挖掘和学术文献处理等多种应用。此外，UnScientify提供可解释的结果，有助于理解文本中识别出的科学不确定性实例。

    This demo paper presents UnScientify, an interactive system designed to detect scientific uncertainty in scholarly full text. The system utilizes a weakly supervised technique that employs a fine-grained annotation scheme to identify verbally formulated uncertainty at the sentence level in scientific texts. The pipeline for the system includes a combination of pattern matching, complex sentence checking, and authorial reference checking. Our approach automates labeling and annotation tasks for scientific uncertainty identification, taking into account different types of scientific uncertainty, that can serve various applications such as information retrieval, text mining, and scholarly document processing. Additionally, UnScientify provides interpretable results, aiding in the comprehension of identified instances of scientific uncertainty in text.
    
[^14]: 计算机系统中的不透明性来源：迈向全面分类方法论

    Sources of Opacity in Computer Systems: Towards a Comprehensive Taxonomy. (arXiv:2307.14232v1 [cs.SE])

    [http://arxiv.org/abs/2307.14232](http://arxiv.org/abs/2307.14232)

    该论文提出了一个综合分类方法论，用于解决计算机系统中的不透明性问题。该分类方法论包含八个不透明性来源，分别属于体系结构、分析和社会技术三个主要类别。该方法论为从业人员提供了一种理解和克服不透明性问题的起点。

    

    现代计算机系统无处不在，但其中许多系统仍然不透明。这在以公平或问责为关键因素的领域中带来了重大挑战。我们认为实现系统透明度的最佳策略因特定不透明源在给定语境中的普遍性而有所不同。综合和扩展现有讨论，我们提出了一个包含三个主要类别（体系结构、分析和社会技术）的八个不透明性来源的分类方法论。对于每个来源，我们提供了如何实际解决由此产生的不透明性的初步建议。该分类方法论为需求工程师和其他从业人员提供了了解语境中普遍的不透明性来源，并选择或开发适当策略来克服这些问题的起点。

    Modern computer systems are ubiquitous in contemporary life yet many of them remain opaque. This poses significant challenges in domains where desiderata such as fairness or accountability are crucial. We suggest that the best strategy for achieving system transparency varies depending on the specific source of opacity prevalent in a given context. Synthesizing and extending existing discussions, we propose a taxonomy consisting of eight sources of opacity that fall into three main categories: architectural, analytical, and socio-technical. For each source, we provide initial suggestions as to how to address the resulting opacity in practice. The taxonomy provides a starting point for requirements engineers and other practitioners to understand contextually prevalent sources of opacity, and to select or develop appropriate strategies for overcoming them.
    
[^15]: 基于区域贸易组织推进气候谈判的可能性探索：基于RICE-N模型的研究

    Explore the possibility of advancing climate negotiations on the basis of regional trade organizations: A study based on RICE-N. (arXiv:2307.14226v1 [cs.CY])

    [http://arxiv.org/abs/2307.14226](http://arxiv.org/abs/2307.14226)

    本研究探索了利用基于区域贸易组织推进气候谈判的可能性，以RICE-N模型为基础，利用深度学习构建了一个新的模型。模拟结果显示该方案具有良好前景。

    

    气候问题变得越来越重要。尽管全球政府取得了一些进展，但我们仍面临着国际合作前景不明的事实。由于综合评估模型（IAMs）的局限性，很难模拟动态谈判过程。因此，利用深度学习构建一个新的基于智能体的模型（ABM）可能为气候谈判提供新的理论支持。本研究在RICE-N模型基础上，提出了一个基于现有贸易集团的气候谈判方法。模拟结果显示该方案具有良好前景。

    Climate issues have become more and more important now. Although global governments have made some progress, we are still facing the truth that the prospect of international cooperation is not clear at present. Due to the limitations of the Integrated assessment models (IAMs) model, it is difficult to simulate the dynamic negotiation process. Therefore, using deep learning to build a new agents based model (ABM) might can provide new theoretical support for climate negotiations. Building on the RICE-N model, this work proposed an approach to climate negotiations based on existing trade groups. Simulation results show that the scheme has a good prospect.
    
[^16]: AI与教育：ChatGPT在系统思维中的应用研究

    AI and Education: An Investigation into the Use of ChatGPT for Systems Thinking. (arXiv:2307.14206v1 [cs.HC])

    [http://arxiv.org/abs/2307.14206](http://arxiv.org/abs/2307.14206)

    本研究探索了AI工具ChatGPT在各个学科中支持系统思维的潜力，并发现其能够提供准确和有用的回答，尽管存在一些限制，但谨慎使用时可以成为教学和学习系统思维的有价值工具。

    

    本研究探讨了人工智能工具ChatGPT在各个学科中支持系统思维的潜力。通过使用一般和学科特定的提示，研究评估了ChatGPT在不同版本中的响应准确性、有用性和可靠性。结果表明，ChatGPT在各个学科中能够提供准确和非常有用的回答，展示了其在增强系统思维能力方面的潜力。然而，偶尔的不准确性也强调了用户需要对ChatGPT的回答持有批判态度。尽管存在一些限制，本研究表明，通过谨慎使用并注意其特殊之处，ChatGPT可以成为教学和学习系统思维的有价值工具。

    This exploratory study investigates the potential of the artificial intelligence tool, ChatGPT, to support systems thinking (ST) in various subjects. Using both general and subject specific prompts, the study assesses the accuracy, helpfulness, and reliability of ChatGPT's responses across different versions of the tool. The results indicate that ChatGPT can provide largely correct and very helpful responses in various subjects, demonstrating its potential as a tool for enhancing ST skills. However, occasional inaccuracies highlight the need for users to remain critical of ChatGPT's responses. Despite some limitations, this study suggests that with careful use and attention to its idiosyncrasies, ChatGPT can be a valuable tool for teaching and learning ST.
    
[^17]: 揭开ChatGPT的安全、隐私和伦理问题

    Unveiling Security, Privacy, and Ethical Concerns of ChatGPT. (arXiv:2307.14192v1 [cs.CR])

    [http://arxiv.org/abs/2307.14192](http://arxiv.org/abs/2307.14192)

    本文研究了ChatGPT的安全、隐私和伦理问题，揭示了将其应用到不同行业可能存在的潜在风险和挑战，并呼吁共同努力确保开发安全和伦理健全的大型语言模型。

    

    本文研究了ChatGPT，这是一个利用主题建模和强化学习生成自然回答的AI聊天机器人。虽然ChatGPT在客户服务、教育、心理健康治疗、个人生产力和内容创作等多个行业具有巨大潜力，但有必要解决其安全、隐私和伦理问题。通过探讨从GPT-1到GPT-4的升级路径，讨论模型的特点、限制和潜在应用，本研究旨在揭示将ChatGPT整合到我们日常生活中可能带来的潜在风险。我们重点关注安全、隐私和伦理问题，强调这些问题对广泛采用的挑战。最后，我们分析了这些领域的未解决问题，并呼吁共同努力确保开发安全和伦理健全的大型语言模型。

    This paper delves into the realm of ChatGPT, an AI-powered chatbot that utilizes topic modeling and reinforcement learning to generate natural responses. Although ChatGPT holds immense promise across various industries, such as customer service, education, mental health treatment, personal productivity, and content creation, it is essential to address its security, privacy, and ethical implications. By exploring the upgrade path from GPT-1 to GPT-4, discussing the model's features, limitations, and potential applications, this study aims to shed light on the potential risks of integrating ChatGPT into our daily lives. Focusing on security, privacy, and ethics issues, we highlight the challenges these concerns pose for widespread adoption. Finally, we analyze the open problems in these areas, calling for concerted efforts to ensure the development of secure and ethically sound large language models.
    
[^18]: LOIS: 在视觉问答中观察实例语义

    LOIS: Looking Out of Instance Semantics for Visual Question Answering. (arXiv:2307.14142v1 [cs.CV])

    [http://arxiv.org/abs/2307.14142](http://arxiv.org/abs/2307.14142)

    LOIS是一个新的模型框架，用于解决视觉问答中的语义理解问题。它不依赖于边界框，并使用精细的特征描述来生成视觉事实。另外，LOIS通过两种类型的关系注意力模块来解决由实例掩码引起的标签不确定性。

    

    视觉问答(VQA)作为一项多模态任务，需要在视觉和语言之间进行努力，以正确地推断答案。最近的研究尝试开发了各种基于注意力的模块来解决VQA任务。然而，模型推断的性能主要受限于对语义理解的视觉处理。大多数现有的检测方法依赖于边界框，这对于VQA模型理解图像中物体语义的因果关系并正确推断上下文信息仍然是一个严峻的挑战。为此，我们在这项工作中提出了一个更精细的模型框架，名为Looking Out of Instance Semantics (LOIS)，以解决这个重要问题。LOIS能够生成更精细的特征描述，以产生视觉事实。此外，为了克服实例掩码引起的标签不确定性，我们设计了两种类型的关系注意力模块：1) 内部模态和2) 交互模态，用于推断正确的上下文关系。

    Visual question answering (VQA) has been intensively studied as a multimodal task that requires effort in bridging vision and language to infer answers correctly. Recent attempts have developed various attention-based modules for solving VQA tasks. However, the performance of model inference is largely bottlenecked by visual processing for semantics understanding. Most existing detection methods rely on bounding boxes, remaining a serious challenge for VQA models to understand the causal nexus of object semantics in images and correctly infer contextual information. To this end, we propose a finer model framework without bounding boxes in this work, termed Looking Out of Instance Semantics (LOIS) to tackle this important issue. LOIS enables more fine-grained feature descriptions to produce visual facts. Furthermore, to overcome the label ambiguity caused by instance masks, two types of relation attention modules: 1) intra-modality and 2) inter-modality, are devised to infer the correct
    
[^19]: 分段稳定组合半强盗问题及因果关系奖励研究

    Piecewise-Stationary Combinatorial Semi-Bandit with Causally Related Rewards. (arXiv:2307.14138v1 [cs.LG])

    [http://arxiv.org/abs/2307.14138](http://arxiv.org/abs/2307.14138)

    本研究研究了具有因果关系奖励的分段稳定组合半强盗问题，并提出了上界置信度算法以应对非平稳环境中的挑战。此外，引入了组重启的概念作为结构化环境中的备份策略。

    

    本文研究了具有因果关系奖励的分段稳定组合半强盗问题。在非平稳环境中，基本臂的分布变化、奖励之间的因果关系，或者两者同时改变奖励生成过程。在这样的环境中，最优的决策者必须跟随这两个变化源，并相应地进行适应。在组合半强盗设置中，问题变得更加严重，因为决策者只观察到所选臂组合的结果。我们提出的策略核心是上界置信度（Upper Confidence Bound, UCB）算法。我们假设代理依靠自适应的方法来应对这一挑战。具体来说，它使用基于广义似然比检验的变点检测器。此外，我们引入了组重启的概念作为结构化环境中决策过程中的新型备份策略。最后，我们的算法整合了一个跟踪机制以追踪

    We study the piecewise stationary combinatorial semi-bandit problem with causally related rewards. In our nonstationary environment, variations in the base arms' distributions, causal relationships between rewards, or both, change the reward generation process. In such an environment, an optimal decision-maker must follow both sources of change and adapt accordingly. The problem becomes aggravated in the combinatorial semi-bandit setting, where the decision-maker only observes the outcome of the selected bundle of arms. The core of our proposed policy is the Upper Confidence Bound (UCB) algorithm. We assume the agent relies on an adaptive approach to overcome the challenge. More specifically, it employs a change-point detector based on the Generalized Likelihood Ratio (GLR) test. Besides, we introduce the notion of group restart as a new alternative restarting strategy in the decision making process in structured environments. Finally, our algorithm integrates a mechanism to trace the 
    
[^20]: 开发和评估小型到中型的土耳其BERT模型

    Developing and Evaluating Tiny to Medium-Sized Turkish BERT Models. (arXiv:2307.14134v1 [cs.CL])

    [http://arxiv.org/abs/2307.14134](http://arxiv.org/abs/2307.14134)

    本研究开发并评估了小型到中型的土耳其BERT模型，在填补资源匮乏语言领域的研究空白方面取得了积极的成果，并为开发和应用小型语言模型提供了有价值的见解。

    

    本研究引入并评估了小型、迷你型、小型和中型的无大小写的土耳其BERT模型，旨在填补资源匮乏语言领域的研究空白。我们使用多个来源的75GB以上文本数据集对这些模型进行了训练，并在多个任务上进行了测试，包括掩码预测、情感分析、新闻分类和零样本分类。尽管规模较小，我们的模型表现出了强大的性能，包括零样本任务，同时保证了计算效率和更快的执行时间。我们的研究结果为小型语言模型的开发和应用提供了有价值的见解，特别是在土耳其语境下。

    This study introduces and evaluates tiny, mini, small, and medium-sized uncased Turkish BERT models, aiming to bridge the research gap in less-resourced languages. We trained these models on a diverse dataset encompassing over 75GB of text from multiple sources and tested them on several tasks, including mask prediction, sentiment analysis, news classification, and, zero-shot classification. Despite their smaller size, our models exhibited robust performance, including zero-shot task, while ensuring computational efficiency and faster execution times. Our findings provide valuable insights into the development and application of smaller language models, especially in the context of the Turkish language.
    
[^21]: 一种以语义为驱动的高质量图像标注方法

    A semantics-driven methodology for high-quality image annotation. (arXiv:2307.14119v1 [cs.CV])

    [http://arxiv.org/abs/2307.14119](http://arxiv.org/abs/2307.14119)

    本文提出了一种以语义为驱动的高质量图像标注方法vTelos，利用WordNet作为提供自然语言标签含义的主要手段，减少主观选择，提高标注的准确性。

    

    机器学习和计算机视觉领域的最新研究已经突出了存在于真实对象识别基准数据集中的各种系统性缺陷。我们的基本观点是，这些缺陷根源于图像中编码的视觉信息与标注其的语义之间存在的多对多映射。其最终结果是当前的标注过程在很大程度上是不够明确的，因此给标注者的主观判断留下了过多的自由度。在本文中，我们提出了vTelos，一种集成了自然语言处理、知识表示和计算机视觉的方法，其主要目标是显性地呈现（否则隐性的）既定标注语义，从而减少主观选择的数量和作用。vTelos的一个关键要素是利用WordNet词汇-语义层次结构作为提供自然语言标签含义的主要手段，从而实现了标注语义的准确定义。

    Recent work in Machine Learning and Computer Vision has highlighted the presence of various types of systematic flaws inside ground truth object recognition benchmark datasets. Our basic tenet is that these flaws are rooted in the many-to-many mappings which exist between the visual information encoded in images and the intended semantics of the labels annotating them. The net consequence is that the current annotation process is largely under-specified, thus leaving too much freedom to the subjective judgment of annotators. In this paper, we propose vTelos, an integrated Natural Language Processing, Knowledge Representation, and Computer Vision methodology whose main goal is to make explicit the (otherwise implicit) intended annotation semantics, thus minimizing the number and role of subjective choices. A key element of vTelos is the exploitation of the WordNet lexico-semantic hierarchy as the main means for providing the meaning of natural language labels and, as a consequence, for 
    
[^22]: GraphRNN再探：消融研究和有向无环图的扩展

    GraphRNN Revisited: An Ablation Study and Extensions for Directed Acyclic Graphs. (arXiv:2307.14109v1 [cs.LG])

    [http://arxiv.org/abs/2307.14109](http://arxiv.org/abs/2307.14109)

    本文对GraphRNN进行了复现和评估，发现You等人建议的BFS遍历对模型性能有重要贡献。此外，通过将BFS遍历替换为拓扑排序，我们扩展了GraphRNN以生成有向无环图，并在真实数据集上取得了显著改进。

    

    GraphRNN是由You等人提出的基于深度学习的架构，用于学习图的生成模型。我们使用重新实现的GraphRNN架构复现了You等人的结果，并使用新的指标将其与基准模型进行了评估。通过消融研究，我们发现You等人建议的BFS遍历以合并同构图的表示对模型性能有显著贡献。此外，我们通过替换BFS遍历为拓扑排序，将GraphRNN扩展为生成有向无环图。我们证明这种方法在真实数据集上明显优于GraphRNN的有向多类别变体。

    GraphRNN is a deep learning-based architecture proposed by You et al. for learning generative models for graphs. We replicate the results of You et al. using a reproduced implementation of the GraphRNN architecture and evaluate this against baseline models using new metrics. Through an ablation study, we find that the BFS traversal suggested by You et al. to collapse representations of isomorphic graphs contributes significantly to model performance. Additionally, we extend GraphRNN to generate directed acyclic graphs by replacing the BFS traversal with a topological sort. We demonstrate that this method improves significantly over a directed-multiclass variant of GraphRNN on a real-world dataset.
    
[^23]: 行动胜于言辞：证明了从策略反馈中省样本量的量化斯坦克伯格均衡的强化学习

    Actions Speak What You Want: Provably Sample-Efficient Reinforcement Learning of the Quantal Stackelberg Equilibrium from Strategic Feedbacks. (arXiv:2307.14085v1 [cs.LG])

    [http://arxiv.org/abs/2307.14085](http://arxiv.org/abs/2307.14085)

    本文研究了强化学习中的量化斯坦克伯格均衡问题，提出了省样本量的在线和离线算法，并通过推断追随者的行动来学习量化响应模型。

    

    本文研究具有领导者-追随者结构的情境马尔科夫博弈中学习量化斯坦克伯格均衡（QSE）的强化学习（RL）。在游戏开始时，领导者宣布她的策略并承诺执行。追随者观察领导者的策略，然后采取量化响应策略，通过解决由领导者策略引发的熵正则化策略优化问题来确定。领导者的目标是通过与追随者的交互并从数据中学习，找到自己的最优策略，从而获得最优的预期总回报。这个问题的一个关键挑战是领导者无法观察到追随者的奖励，并且需要从追随者对抗领导者策略的行动中推断出追随者的量化响应模型。我们在函数逼近的背景下提出了适用于在线和离线设置的样本效率算法。我们的算法基于（i）通过最大似然学习量化响应模型

    We study reinforcement learning (RL) for learning a Quantal Stackelberg Equilibrium (QSE) in an episodic Markov game with a leader-follower structure. In specific, at the outset of the game, the leader announces her policy to the follower and commits to it. The follower observes the leader's policy and, in turn, adopts a quantal response policy by solving an entropy-regularized policy optimization problem induced by leader's policy. The goal of the leader is to find her optimal policy, which yields the optimal expected total return, by interacting with the follower and learning from data. A key challenge of this problem is that the leader cannot observe the follower's reward, and needs to infer the follower's quantal response model from his actions against leader's policies. We propose sample-efficient algorithms for both the online and offline settings, in the context of function approximation. Our algorithms are based on (i) learning the quantal response model via maximum likelihood 
    
[^24]: 开放图像内容非官方解除和重构

    Open Image Content Disarm And Reconstruction. (arXiv:2307.14057v1 [cs.CR])

    [http://arxiv.org/abs/2307.14057](http://arxiv.org/abs/2307.14057)

    本论文提出了一种新颖的图像内容非官方解除和重构（ICDR）方法，用于解决恶意软件使用图像进行隐藏和隐写的问题。

    

    随着恶意软件技术的进步，攻击者创造了新的方法来隐藏其恶意代码以躲避杀毒服务。一种模糊攻击的方法是使用常规文件作为掩盖，隐藏恶意脚本，使恶意软件看起来像一个合法的文件。尽管有先进的人工智能和内容签名技术存在，但逃避性恶意软件成功地绕过了下一代恶意软件检测，使用诸如隐写术之类的高级方法。一些常用于隐藏恶意软件的文件是图像文件（如JPEG）。此外，一些恶意软件使用隐写术将恶意脚本或敏感数据隐藏在图像中。即使使用专门的工具，难以检测出图像中的隐写术。基于图像的攻击试图使用恶意弹药攻击用户设备，或者利用图像隐写术将敏感数据隐藏在合法图像中并在用户设备之外泄露。因此，在本文中，我们提出了一种新颖的图像内容非官方解除和重构（ICDR）。

    With the advance in malware technology, attackers create new ways to hide their malicious code from antivirus services. One way to obfuscate an attack is to use common files as cover to hide the malicious scripts, so the malware will look like a legitimate file. Although cutting-edge Artificial Intelligence and content signature exist, evasive malware successfully bypasses next-generation malware detection using advanced methods like steganography. Some of the files commonly used to hide malware are image files (e.g., JPEG). In addition, some malware use steganography to hide malicious scripts or sensitive data in images. Steganography in images is difficult to detect even with specialized tools. Image-based attacks try to attack the user's device using malicious payloads or utilize image steganography to hide sensitive data inside legitimate images and leak it outside the user's device. Therefore in this paper, we present a novel Image Content Disarm and Reconstruction (ICDR). Our ICD
    
[^25]: 无监督点云配准中的最近邻指导内点估计

    One-Nearest Neighborhood Guides Inlier Estimation for Unsupervised Point Cloud Registration. (arXiv:2307.14019v1 [cs.CV])

    [http://arxiv.org/abs/2307.14019](http://arxiv.org/abs/2307.14019)

    本文提出了一种无监督点云配准方法，通过对几何结构一致性的捕捉和最近邻点云的生成来提高内点估计和匹配置信度。

    

    无监督点云配准方法的精度通常受可靠内点估计和自我监督信号的限制，尤其在部分重叠的情况下更为明显。本文提出了一种有效的无监督点云配准内点估计方法，通过捕捉源点云和其对应的参考点云副本之间的几何结构一致性来实现。具体而言，为了获得高质量的参考点云副本，我们使用输入点云生成一个最近邻（1-NN）点云。这有助于匹配图构建，并允许将1-NN点云和输入点云的双邻域匹配得分整合，以提高匹配置信度。基于高质量的参考副本，我们认为内点及其邻域形成的邻域图应该在源点云和对应的参考副本之间具有一致性。基于这一观察，我们提出了一种新的内点估计方法来提高无监督点云配准的精度。

    The precision of unsupervised point cloud registration methods is typically limited by the lack of reliable inlier estimation and self-supervised signal, especially in partially overlapping scenarios. In this paper, we propose an effective inlier estimation method for unsupervised point cloud registration by capturing geometric structure consistency between the source point cloud and its corresponding reference point cloud copy. Specifically, to obtain a high quality reference point cloud copy, an One-Nearest Neighborhood (1-NN) point cloud is generated by input point cloud. This facilitates matching map construction and allows for integrating dual neighborhood matching scores of 1-NN point cloud and input point cloud to improve matching confidence. Benefiting from the high quality reference copy, we argue that the neighborhood graph formed by inlier and its neighborhood should have consistency between source point cloud and its corresponding reference copy. Based on this observation, 
    
[^26]: ESSAformer: 高效超光谱图像超分辨率变换器

    ESSAformer: Efficient Transformer for Hyperspectral Image Super-resolution. (arXiv:2307.14010v1 [cs.CV])

    [http://arxiv.org/abs/2307.14010](http://arxiv.org/abs/2307.14010)

    ESSAformer是一种用于单一超光谱图像超分辨率的高效Transformer网络，通过引入稳健的相似度度量和核化注意力技术，解决了CNN-based方法在光谱信息利用和伪影问题上的限制。

    

    单一超光谱图像超分辨率（Single-HSI-SR）旨在从低分辨率观测中恢复出高分辨率超光谱图像。然而，目前的基于卷积神经网络的方法在构建长程依赖性和捕捉光谱特征之间的交互信息方面存在局限性。这导致光谱信息的利用不足并且在放大后产生伪影。为了解决这个问题，我们提出了ESSAformer，一种嵌入ESSA注意力的变换器网络，用于单一超光谱图像超分辨率，并具有迭代优化结构。具体而言，我们首先引入了一个稳健且与光谱友好的相似度度量，即谱相关系数（SCC），以取代原始的注意力矩阵，并将归纳偏置引入模型以促进训练。在此基础上，我们进一步利用具有理论支持的可核化注意力技术形成一种新的高效SCC核自注意力（ESSA），并减少注意力计算的复杂度。

    Single hyperspectral image super-resolution (single-HSI-SR) aims to restore a high-resolution hyperspectral image from a low-resolution observation. However, the prevailing CNN-based approaches have shown limitations in building long-range dependencies and capturing interaction information between spectral features. This results in inadequate utilization of spectral information and artifacts after upsampling. To address this issue, we propose ESSAformer, an ESSA attention-embedded Transformer network for single-HSI-SR with an iterative refining structure. Specifically, we first introduce a robust and spectral-friendly similarity metric, \ie, the spectral correlation coefficient of the spectrum (SCC), to replace the original attention matrix and incorporates inductive biases into the model to facilitate training. Built upon it, we further utilize the kernelizable attention technique with theoretical support to form a novel efficient SCC-kernel-based self-attention (ESSA) and reduce atte
    
[^27]: 通过强化学习控制 GAN 的潜在空间：基于任务的图像翻译案例研究

    Controlling the Latent Space of GANs through Reinforcement Learning: A Case Study on Task-based Image-to-Image Translation. (arXiv:2307.13978v1 [cs.LG])

    [http://arxiv.org/abs/2307.13978](http://arxiv.org/abs/2307.13978)

    本文提出了一种通过将强化学习代理与潜在空间 GAN 集成来控制生成过程的新方法，在实验证明其有效性的基础上。

    

    生成对抗网络（GAN）已经成为一种强大的人工智能工具，可以根据训练数据生成逼真的输出。然而，控制 GAN 生成过程的挑战仍然存在。在本文中，我们提出了一种新颖的方法来解决这个问题，通过将强化学习（RL）代理与潜在空间 GAN（l-GAN）集成在一起，从而促进生成所需的输出。具体来说，我们开发了一个带有精心设计的奖励策略的 actor-critic RL 代理，使其能够熟练地在 l-GAN 的潜在空间中导航，并根据指定的任务生成输出。为了验证我们的方法的效果，我们进行了一系列实验，使用 MNIST 数据集，包括算术加法作为一个说明性任务。这些实验的结果验证了我们的方法的有效性。我们首次将 RL 代理与 GAN 模型集成起来，代表了一种创新

    Generative Adversarial Networks (GAN) have emerged as a formidable AI tool to generate realistic outputs based on training datasets. However, the challenge of exerting control over the generation process of GANs remains a significant hurdle. In this paper, we propose a novel methodology to address this issue by integrating a reinforcement learning (RL) agent with a latent-space GAN (l-GAN), thereby facilitating the generation of desired outputs. More specifically, we have developed an actor-critic RL agent with a meticulously designed reward policy, enabling it to acquire proficiency in navigating the latent space of the l-GAN and generating outputs based on specified tasks. To substantiate the efficacy of our approach, we have conducted a series of experiments employing the MNIST dataset, including arithmetic addition as an illustrative task. The outcomes of these experiments serve to validate our methodology. Our pioneering integration of an RL agent with a GAN model represents a nov
    
[^28]: 通过隐藏层的线性可分性理解深度神经网络

    Understanding Deep Neural Networks via Linear Separability of Hidden Layers. (arXiv:2307.13962v1 [cs.LG])

    [http://arxiv.org/abs/2307.13962](http://arxiv.org/abs/2307.13962)

    本文通过测量深度神经网络隐藏层输出的线性可分性来研究其特性，并发现隐藏层输出的线性可分性程度与网络训练性能有同步性，进一步探讨激活函数和网络尺寸对隐藏层线性可分性的影响。

    

    本文通过测量隐藏层输出的线性可分性来研究深度神经网络的特性。具体来说，我们首先提出了基于闵可夫斯基差异的线性可分度量（MD-LSMs）来评估两个点集的线性可分程度。然后，我们证明了隐藏层输出的线性可分性程度与网络训练性能之间存在一种同步性，即如果更新的权重能够提高隐藏层输出的线性可分性程度，那么更新后的网络将实现更好的训练性能，反之亦然。此外，我们还研究了激活函数和网络尺寸（包括宽度和深度）对隐藏层线性可分性的影响。最后，我们进行了数值实验证实了我们的发现对一些流行的深度网络，包括多层感知机（MLP）、卷积神经网络（CNN）、深度置信网络（DBN）、ResNet、VGGNet、AlexNet、vision tran的验证。

    In this paper, we measure the linear separability of hidden layer outputs to study the characteristics of deep neural networks. In particular, we first propose Minkowski difference based linear separability measures (MD-LSMs) to evaluate the linear separability degree of two points sets. Then, we demonstrate that there is a synchronicity between the linear separability degree of hidden layer outputs and the network training performance, i.e., if the updated weights can enhance the linear separability degree of hidden layer outputs, the updated network will achieve a better training performance, and vice versa. Moreover, we study the effect of activation function and network size (including width and depth) on the linear separability of hidden layers. Finally, we conduct the numerical experiments to validate our findings on some popular deep networks including multilayer perceptron (MLP), convolutional neural network (CNN), deep belief network (DBN), ResNet, VGGNet, AlexNet, vision tran
    
[^29]: 扩散如何影响预训练语言模型在超出分布数据上的表现？

    How Does Diffusion Influence Pretrained Language Models on Out-of-Distribution Data?. (arXiv:2307.13949v1 [cs.CL])

    [http://arxiv.org/abs/2307.13949](http://arxiv.org/abs/2307.13949)

    这项研究探讨了扩散模型对预训练语言模型(PLMs)在超出分布(OOD)数据上的影响。研究发现，在OOD数据上使用扩散微调PLMs会降低重建能力。比较实验还表明，扩散模型能够有效提高OOD样本的重构能力和检测能力。

    

    基于Transformer的预训练语言模型(PLMs)在现代自然语言处理(NLP)领域取得了巨大成功。PLMs的一个重要优势是良好的超出分布(OOD)鲁棒性。最近，扩散模型吸引了很多研究将扩散应用于PLMs。然而，扩散对PLMs在OOD数据上的影响仍未得到充分探讨。扩散模型的核心是一个前向扩散过程，逐渐对输入应用高斯噪声，并且一个反向去噪过程，用于去除噪声。噪声输入重建是扩散模型的基本能力。我们通过测量重建损失直接分析OOD鲁棒性，包括测试重建OOD数据和检测OOD样本的能力。通过分析不同的训练参数和数据统计特征在八个数据集上进行了实验。结果显示，使用扩散微调PLMs会降低在OOD数据上的重建能力。比较还表明，扩散模型可以有效地提高OOD样本的重构能力和检测能力。

    Transformer-based pretrained language models (PLMs) have achieved great success in modern NLP. An important advantage of PLMs is good out-of-distribution (OOD) robustness. Recently, diffusion models have attracted a lot of work to apply diffusion to PLMs. It remains under-explored how diffusion influences PLMs on OOD data. The core of diffusion models is a forward diffusion process which gradually applies Gaussian noise to inputs, and a reverse denoising process which removes noise. The noised input reconstruction is a fundamental ability of diffusion models. We directly analyze OOD robustness by measuring the reconstruction loss, including testing the abilities to reconstruct OOD data, and to detect OOD samples. Experiments are conducted by analyzing different training parameters and data statistical features on eight datasets. It shows that finetuning PLMs with diffusion degrades the reconstruction ability on OOD data. The comparison also shows that diffusion models can effectively d
    
[^30]: 基于分布式高斯过程的学习控制方法用于PMSM

    Learning-based Control for PMSM Using Distributed Gaussian Processes with Optimal Aggregation Strategy. (arXiv:2307.13945v1 [eess.SY])

    [http://arxiv.org/abs/2307.13945](http://arxiv.org/abs/2307.13945)

    本文提出了一种基于分布式高斯过程的学习控制方法用于PMSM。该方法采用了控制感知最优聚合策略，并仅利用后验均值进行计算，从而避免了与后验方差相关的计算。

    

    随着精确控制在不同和未知环境中的需求增加，对电源供应组件的要求也相应增加，其中包括永磁同步电机（Permanent Magnet Synchronous Motors, PMSMs）。为了推断系统中的未知部分，广泛使用机器学习技术，特别是高斯过程回归（Gaussian Process Regression, GPR），因为它具有灵活的连续系统建模能力和保证性能。为了实际实现，采用了分布式GPR来减轻高计算复杂性。然而，从控制的角度研究分布式GPR仍然是一个开放的问题。本文提出了一种基于Lyapunov稳定性理论的用于PMSMs的控制感知最优聚合策略。该策略仅利用后验均值，从而避免了与后验方差相关的计算密集性计算。

    The growing demand for accurate control in varying and unknown environments has sparked a corresponding increase in the requirements for power supply components, including permanent magnet synchronous motors (PMSMs). To infer the unknown part of the system, machine learning techniques are widely employed, especially Gaussian process regression (GPR) due to its flexibility of continuous system modeling and its guaranteed performance. For practical implementation, distributed GPR is adopted to alleviate the high computational complexity. However, the study of distributed GPR from a control perspective remains an open problem. In this paper, a control-aware optimal aggregation strategy of distributed GPR for PMSMs is proposed based on the Lyapunov stability theory. This strategy exclusively leverages the posterior mean, thereby obviating the need for computationally intensive calculations associated with posterior variance in alternative approaches. Moreover, the straightforward calculati
    
[^31]: 图对比学习的熵神经估计

    Entropy Neural Estimation for Graph Contrastive Learning. (arXiv:2307.13944v1 [cs.LG])

    [http://arxiv.org/abs/2307.13944](http://arxiv.org/abs/2307.13944)

    本文提出了一种基于熵神经估计的图对比学习方法，通过最大化互信息下界来近似估计数据集的熵。通过简单但有效的子集抽样策略对比数据集不同视图中的节点表示，同时使用两个目标优化网络的学习过程。

    

    图对比学习旨在提取节点的可区分的高层表示。本文理论上证明了数据集的熵可以通过最大化不同视图下的互信息下界来近似估计，即通过神经网络估计熵。基于这一发现，我们提出了一种简单而有效的子集抽样策略，用于对比数据集各视图之间的成对表示。具体而言，我们随机从给定的图中抽样节点和边来构建视图的输入子集。两个视图被输入到参数共享的连体网络中，以提取高维嵌入并估计整个图的信息熵。对于学习过程，我们提出了同时使用两个目标优化网络的方法。具体而言，对比损失函数的输入由正负对组成。我们的对比对策略与以前的不同

    Contrastive learning on graphs aims at extracting distinguishable high-level representations of nodes. In this paper, we theoretically illustrate that the entropy of a dataset can be approximated by maximizing the lower bound of the mutual information across different views of a graph, \ie, entropy is estimated by a neural network. Based on this finding, we propose a simple yet effective subset sampling strategy to contrast pairwise representations between views of a dataset. In particular, we randomly sample nodes and edges from a given graph to build the input subset for a view. Two views are fed into a parameter-shared Siamese network to extract the high-dimensional embeddings and estimate the information entropy of the entire graph. For the learning process, we propose to optimize the network using two objectives, simultaneously. Concretely, the input of the contrastive loss function consists of positive and negative pairs. Our selection strategy of pairs is different from previous
    
[^32]: 多智能体学习的稳定性：在具有多个玩家的网络游戏中的收敛性

    Stability of Multi-Agent Learning: Convergence in Network Games with Many Players. (arXiv:2307.13922v1 [cs.GT])

    [http://arxiv.org/abs/2307.13922](http://arxiv.org/abs/2307.13922)

    该研究探讨了多智能体学习在网络游戏中的稳定性，发现了在任何网络游戏中实现动力学收敛到唯一均衡的充分条件，并且证明在适当的网络条件下，可以实现具有任意数量代理的稳定学习动力学。

    

    已经证明多智能体学习在许多玩家游戏中的行为显示出复杂的动力学，超出了限制性示例（如网络零和游戏）。此外，已经证明随着玩家数量的增加，收敛行为变得不太可能发生。为了在解决这个问题上取得进展，我们研究了Q-Learning动力学，并确定了在任何网络游戏中动力学收敛于唯一均衡的充分条件。我们发现这个条件取决于成对交互的性质和网络结构，但明确与游戏中的总代理数量无关。我们评估了这个结果在一些代表性的网络游戏上，并表明在适当的网络条件下，可以实现具有任意数量代理的稳定学习动力学。

    The behaviour of multi-agent learning in many player games has been shown to display complex dynamics outside of restrictive examples such as network zero-sum games. In addition, it has been shown that convergent behaviour is less likely to occur as the number of players increase. To make progress in resolving this problem, we study Q-Learning dynamics and determine a sufficient condition for the dynamics to converge to a unique equilibrium in any network game. We find that this condition depends on the nature of pairwise interactions and on the network structure, but is explicitly independent of the total number of agents in the game. We evaluate this result on a number of representative network games and show that, under suitable network conditions, stable learning dynamics can be achieved with an arbitrary number of agents.
    
[^33]: 将民主价值观嵌入社交媒体人工智能中的社会客观函数

    Embedding Democratic Values into Social Media AIs via Societal Objective Functions. (arXiv:2307.13912v1 [cs.HC])

    [http://arxiv.org/abs/2307.13912](http://arxiv.org/abs/2307.13912)

    本研究介绍了一种方法，通过将社会科学构造转化为人工智能目标函数，将民主价值观嵌入社交媒体人工智能系统中。通过一个应用于反民主态度的模型示例，我们展示了该方法的有效性。通过利用社会科学的调查工具和定性编码手册，我们能够精确地转化这些构造为大型语言模型的提示。

    

    我们能否设计人工智能系统，使其考虑到民主价值观，如减少党派敌意，作为其目标函数来排名我们的社交媒体信息流？我们引入了一种方法，将已建立、经审查的社会科学构造转化为人工智能目标函数，我们称之为社会客观函数，并通过应用于反民主态度这一政治科学构造来演示该方法。传统上，我们缺乏可观察的结果来对这些模型进行训练，然而社会科学已经开发了调查工具和定性编码手册，用于这些构造的翻译，其精确性便于将其转化为大型语言模型的详细提示。我们应用这种方法创建了一个民主态度模型，用于估计社交媒体帖子宣传反民主态度的程度，并在三个研究中测试了这个民主态度模型。

    Can we design artificial intelligence (AI) systems that rank our social media feeds to consider democratic values such as mitigating partisan animosity as part of their objective functions? We introduce a method for translating established, vetted social scientific constructs into AI objective functions, which we term societal objective functions, and demonstrate the method with application to the political science construct of anti-democratic attitudes. Traditionally, we have lacked observable outcomes to use to train such models, however, the social sciences have developed survey instruments and qualitative codebooks for these constructs, and their precision facilitates translation into detailed prompts for large language models. We apply this method to create a democratic attitude model that estimates the extent to which a social media post promotes anti-democratic attitudes, and test this democratic attitude model across three studies. In Study 1, we first test the attitudinal and 
    
[^34]: 使用基于星星的可达性分析和变长时间序列输入的深度神经网络鲁棒性验证

    Robustness Verification of Deep Neural Networks using Star-Based Reachability Analysis with Variable-Length Time Series Input. (arXiv:2307.13907v1 [cs.LG])

    [http://arxiv.org/abs/2307.13907](http://arxiv.org/abs/2307.13907)

    本文介绍了一种利用基于星星的可达性分析和变长时间序列输入的深度神经网络鲁棒性验证方法，并在预测与健康管理领域的SOC估计和RUL估计中进行了应用。

    

    数据驱动的神经网络（NN）异常检测和预测维护是新兴的研究领域。基于时间序列数据的NN分析可以提供有关过去行为和关键参数（如设备的剩余寿命（RUL）和电池的荷电状态（SOC））的有价值见解。然而，输入的时间序列数据在经过传感器时可能遭受有意或无意的噪声干扰，因此需要对这些NN进行鲁棒性验证和验证。本文提出了一种针对时间序列回归NN（TSRegNN）的鲁棒性验证方法的案例研究，采用基于集合的形式方法。它着重于利用变长输入数据来简化输入操作并增强网络架构的泛化能力。该方法应用于预测与健康管理（PHM）应用领域中的两个数据集：（1）锂离子电池SOC估计和（2）涡轮发动机RUL估计。对NN的鲁棒性进行了核实。

    Data-driven, neural network (NN) based anomaly detection and predictive maintenance are emerging research areas. NN-based analytics of time-series data offer valuable insights into past behaviors and estimates of critical parameters like remaining useful life (RUL) of equipment and state-of-charge (SOC) of batteries. However, input time series data can be exposed to intentional or unintentional noise when passing through sensors, necessitating robust validation and verification of these NNs. This paper presents a case study of the robustness verification approach for time series regression NNs (TSRegNN) using set-based formal methods. It focuses on utilizing variable-length input data to streamline input manipulation and enhance network architecture generalizability. The method is applied to two data sets in the Prognostics and Health Management (PHM) application areas: (1) SOC estimation of a Lithium-ion battery and (2) RUL estimation of a turbine engine. The NNs' robustness is checke
    
[^35]: FinTree：用于关系抽取的金融数据集预训练变换器编码器

    FinTree: Financial Dataset Pretrain Transformer Encoder for Relation Extraction. (arXiv:2307.13900v1 [cs.CL])

    [http://arxiv.org/abs/2307.13900](http://arxiv.org/abs/2307.13900)

    FinTree是一种用于关系抽取的金融数据集预训练变换器编码器，其采用了预测掩码标记的新颖结构，通过训练提供上下文和位置信息，并在大规模金融关系抽取数据集上表现出色。

    

    我们提出了FinTree，使用金融数据集预训练的变换器编码器，用于关系抽取。利用编码器语言模型，在金融领域任务中进一步预训练FinTree。FinTree以其预测掩码标记而不是传统的[CLS]标记的新颖结构而脱颖而出，受到模式利用训练方法的启发。这种结构可以更准确地预测两个给定实体之间的关系。该模型通过一种独特的输入模式进行训练，以提供有关所关注实体的上下文和位置信息，并通过后处理步骤确保与实体类型一致的准确预测。我们的实验证明FinTree在大规模金融关系抽取数据集REFinD上的表现优于其他模型。代码和预训练模型可在https://github.com/HJ-Ok/FinTree上获取。

    We present FinTree, Financial Dataset Pretrain Transformer Encoder for Relation Extraction. Utilizing an encoder language model, we further pretrain FinTree on the financial dataset, adapting the model in financial domain tasks. FinTree stands out with its novel structure that predicts a masked token instead of the conventional [CLS] token, inspired by the Pattern Exploiting Training methodology. This structure allows for more accurate relation predictions between two given entities. The model is trained with a unique input pattern to provide contextual and positional information about the entities of interest, and a post-processing step ensures accurate predictions in line with the entity types. Our experiments demonstrate that FinTree outperforms on the REFinD, a large-scale financial relation extraction dataset. The code and pretrained models are available at https://github.com/HJ-Ok/FinTree.
    
[^36]: 用元学习生成模型正则化神经网络

    Regularizing Neural Networks with Meta-Learning Generative Models. (arXiv:2307.13899v1 [cs.LG])

    [http://arxiv.org/abs/2307.13899](http://arxiv.org/abs/2307.13899)

    本文提出了一种名为元生成正则化（MGR）的新型生成数据增强策略，通过将合成样本用于特征提取器的正则化项而不是损失函数，最小化验证损失，提高了深度学习中的生成数据增强效果。

    

    本文研究了改进深度学习的生成数据增强方法。生成数据增强利用生成模型产生的合成样本作为小数据集分类的额外数据集。生成数据增强的一个关键挑战是合成数据中包含降低准确性的无信息样本。这是因为合成样本不能完美地代表真实数据中的类别，均匀抽样也不一定为任务提供有用的样本。本文提出了一种名为元生成正则化（MGR）的新型生成数据增强策略。为了避免生成数据增强的降级，MGR将合成样本用于特征提取器的正则化项而不是损失函数，如交叉熵。这些合成样本通过元学习动态确定，以最小化验证损失。

    This paper investigates methods for improving generative data augmentation for deep learning. Generative data augmentation leverages the synthetic samples produced by generative models as an additional dataset for classification with small dataset settings. A key challenge of generative data augmentation is that the synthetic data contain uninformative samples that degrade accuracy. This is because the synthetic samples do not perfectly represent class categories in real data and uniform sampling does not necessarily provide useful samples for tasks. In this paper, we present a novel strategy for generative data augmentation called meta generative regularization (MGR). To avoid the degradation of generative data augmentation, MGR utilizes synthetic samples in the regularization term for feature extractors instead of in the loss function, e.g., cross-entropy. These synthetic samples are dynamically determined to minimize the validation losses through meta-learning. We observed that MGR 
    
[^37]: AI4GCC - 团队: 低于海平面: 评论和改进

    AI4GCC - Team: Below Sea Level: Critiques and Improvements. (arXiv:2307.13894v1 [cs.CY])

    [http://arxiv.org/abs/2307.13894](http://arxiv.org/abs/2307.13894)

    这项研究对气候变化评估模型RICE-N进行了批判性分析，发现了关键问题并提出了改进建议，同时也对综合评估模型的特征进行了讨论。研究结果有助于进一步发展RICE-N框架，为政策制定者提供参考。

    

    我们对模拟框架RICE-N进行了批判性分析，这是一个用于评估气候变化对经济影响的综合评估模型(IAM)。我们确定了RICE-N的关键问题，包括行动屏蔽和无关的行动，并提出了改进的建议，如利用关税收入和惩罚过量生产。我们还批判性地讨论了IAM的特征，即过于乐观的损失函数和不现实的减排成本函数。我们的研究结果有助于不断改进RICE-N框架，使其作为政策制定者的灵感更加有用。

    We present a critical analysis of the simulation framework RICE-N, an integrated assessment model (IAM) for evaluating the impacts of climate change on the economy. We identify key issues with RICE-N, including action masking and irrelevant actions, and suggest improvements such as utilizing tariff revenue and penalizing overproduction. We also critically engage with features of IAMs in general, namely overly optimistic damage functions and unrealistic abatement cost functions. Our findings contribute to the ongoing efforts to further develop the RICE-N framework in an effort to improve the simulation, making it more useful as an inspiration for policymakers.
    
[^38]: 动态分组用于气候变化谈判：通过有效策略促进合作和平衡利益

    Dynamic Grouping for Climate Change Negotiation: Facilitating Cooperation and Balancing Interests through Effective Strategies. (arXiv:2307.13893v1 [cs.CY])

    [http://arxiv.org/abs/2307.13893](http://arxiv.org/abs/2307.13893)

    本文提出了一个基于现实世界业务和政治谈判协议的动态分组谈判模型，通过实施组形成方法和组更新策略解决了多地区气候谈判中的复杂性和不平衡问题，促进各利益相关方之间的高效合作以实现全球气候变化目标。

    

    本文提出了一个基于现实世界业务和政治谈判协议的气候减缓动态分组谈判模型。在AI4GCC竞赛框架下，我们开发了一个三阶段流程：组形成和更新、组内谈判和组间谈判。我们的模型促进各利益相关方之间的高效合作，以实现全球气候变化目标。通过实施组形成方法和组更新策略，我们解决了多地区气候谈判中的复杂性和不平衡问题。组内谈判确保所有成员都为减缓努力做出贡献，而组间谈判则使用提案评估框架来制定减缓和节约率。我们在RICE-N框架中展示了我们的谈判模型，展示了一个有前景的促进国际合作应对气候变化减缓的方法。

    In this paper, we propose a dynamic grouping negotiation model for climate mitigation based on real-world business and political negotiation protocols. Within the AI4GCC competition framework, we develop a three-stage process: group formation and updates, intra-group negotiation, and inter-group negotiation. Our model promotes efficient and effective cooperation between various stakeholders to achieve global climate change objectives. By implementing a group-forming method and group updating strategy, we address the complexities and imbalances in multi-region climate negotiations. Intra-group negotiations ensure that all members contribute to mitigation efforts, while inter-group negotiations use the proposal-evaluation framework to set mitigation and savings rates. We demonstrate our negotiation model within the RICE-N framework, illustrating a promising approach for facilitating international cooperation on climate change mitigation.
    
[^39]: AI4GCC - 团队: 海平面以下: 评分和实际世界相关性

    AI4GCC - Team: Below Sea Level: Score and Real World Relevance. (arXiv:2307.13892v1 [cs.CY])

    [http://arxiv.org/abs/2307.13892](http://arxiv.org/abs/2307.13892)

    我们提出了一种谈判协议来解决碳泄漏问题，通过与代表性浓度路径和共享社会经济路径进行比较，我们的方法显示出了良好的效果，此外我们还分析了协议的合规性、可行性和伦理关切。

    

    作为我们参加AI for Global Climate Cooperation (AI4GCC)竞赛的第三项跟踪任务的提交，我们针对RICE-N气候经济模拟提出了一种谈判协议。我们的提议通过受到碳边境调整机制(CBAM)和气候俱乐部(CC)启发的方法来应对碳泄漏的挑战。我们通过将模拟结果与代表性浓度路径(RCP)和共享社会经济路径(SSP)进行比较，证明了我们方法的有效性。我们的协议导致了与RCP 3.4/4.5和SSP 2相当的温度上升。此外，我们对我们的协议的世界贸易组织合规性、行政和政治可行性以及伦理关切进行了分析。我们意识到我们的提议可能会对最不发达国家造成伤害，因此我们建议采取特定的纠正措施，避免加剧现有的不平等，例如技术共享和财富再分配。未来的研究应该改进...

    As our submission for track three of the AI for Global Climate Cooperation (AI4GCC) competition, we propose a negotiation protocol for use in the RICE-N climate-economic simulation. Our proposal seeks to address the challenges of carbon leakage through methods inspired by the Carbon Border Adjustment Mechanism (CBAM) and Climate Clubs (CC). We demonstrate the effectiveness of our approach by comparing simulated outcomes to representative concentration pathways (RCP) and shared socioeconomic pathways (SSP). Our protocol results in a temperature rise comparable to RCP 3.4/4.5 and SSP 2. Furthermore, we provide an analysis of our protocol's World Trade Organization compliance, administrative and political feasibility, and ethical concerns. We recognize that our proposal risks hurting the least developing countries, and we suggest specific corrective measures to avoid exacerbating existing inequalities, such as technology sharing and wealth redistribution. Future research should improve th
    
[^40]: 气候变化谈判的动态分组：通过有效策略促进合作和平衡利益

    Dynamic Grouping for Climate Change Negotiation: Facilitating Cooperation and Balancing Interests through Effective Strategies. (arXiv:2307.13886v1 [cs.CY])

    [http://arxiv.org/abs/2307.13886](http://arxiv.org/abs/2307.13886)

    本研究主要目的在于改进气候变化谈判模型，特别集中在地理影响和效用框架两个关键领域。我们探讨了地理影响的五个关键方面，并强调了完善效用和奖励框架的重要性。通过解决这些限制，我们希望提高准确性和效果。

    

    当前的气候变化谈判模型存在一些限制，需要进一步研究和发展。在这个方向上，我们主要讨论了两个关键改进领域，重点放在地理影响和效用框架上。在地理影响方面，我们探讨了五个关键方面：（1）从局部到全球影响的转变，（2）不同地区气候变化效应的变异性，（3）地理位置和政治结构的异质性，（4）相邻国家之间的合作，（5）包括历史和文化因素对气候谈判的影响的重要性。此外，我们强调了需要完善效用和奖励框架，减少一致性和高估气候缓解程度的问题，将储蓄率的正面效应纳入奖励函数，并考虑所有地区的异质性。通过解决这些限制，我们希望提高准确性和效果。

    The current framework for climate change negotiation models presents several limitations that warrant further research and development. In this track, we discuss mainly two key areas for improvement, focusing on the geographical impacts and utility framework. In the aspects of geographical impacts, We explore five critical aspects: (1) the shift from local to global impact, (2) variability in climate change effects across regions, (3) heterogeneity in geographical location and political structures, and (4) collaborations between adjacent nations, (5) the importance of including historical and cultural factors influencing climate negotiations. Furthermore, we emphasize the need to refine the utility and rewards framework to reduce the homogeneity and the level of overestimating the climate mitigation by integrating the positive effects of saving rates into the reward function and heterogeneity among all regions. By addressing these limitations, we hope to enhance the accuracy and effect
    
[^41]: WebArena: 一个用于构建自主智能体的真实网络环境

    WebArena: A Realistic Web Environment for Building Autonomous Agents. (arXiv:2307.13854v1 [cs.AI])

    [http://arxiv.org/abs/2307.13854](http://arxiv.org/abs/2307.13854)

    WebArena是一个用于构建自主智能体的真实网络环境，它包含了完全功能的网站，并且通过引入工具和外部知识库来鼓励智能体像人类一样解决任务。此外，WebArena还发布了一组用于评估任务完成功能正确性的基准任务。

    

    随着生成式人工智能的进展，通过自然语言指令进行日常任务的自主智能体的潜力逐渐显现。然而，当前的智能体主要是在简化的合成环境中创建和测试的，严重限制了现实世界场景的表示能力。在本文中，我们构建了一个高度逼真且可复现的智能体指令和控制环境。具体而言，我们关注在网站上执行任务的智能体，我们创建了一个包含来自四个常见领域的完全功能网站的环境，分别是电子商务、社交论坛讨论、协同软件开发和内容管理。我们的环境使用工具（如地图）和外部知识库（如用户手册）来鼓励像人类一样解决任务。在我们的环境基础上，我们发布了一组重点评估任务完成功能正确性的基准任务。我们基准任务具有多样性和长远的视野，并且被设计为鼓励智能体进行更深层次的任务理解和解决。

    With generative AI advances, the exciting potential for autonomous agents to manage daily tasks via natural language commands has emerged. However, cur rent agents are primarily created and tested in simplified synthetic environments, substantially limiting real-world scenario representation. In this paper, we build an environment for agent command and control that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on websites, and we create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and are desi
    
[^42]: MAEA: 基于多模态的智能体人工智能的归因

    MAEA: Multimodal Attribution for Embodied AI. (arXiv:2307.13850v1 [cs.LG])

    [http://arxiv.org/abs/2307.13850](http://arxiv.org/abs/2307.13850)

    MAEA是一个用于计算任何可微分的多模态智能体人工智能政策的全局归因的框架。它可以通过归因分析来排名和分组故障场景，调查建模和数据集偏见，并对多模态智能体人工智能政策的稳健性和用户信任进行关键分析。

    

    理解多模态感知对于智能体人工智能是一个开放性问题，因为这样的输入可能包含高度互补和冗余的信息用于任务。多模态政策的一个相关方向是理解融合层中每种模态的全局趋势。为此，我们在ALFRED数据集训练的不同政策上解开了视觉、语言和先前动作输入的归因。归因分析可以用于排名和分组故障场景、调查建模和数据集偏见，并在部署之前对多模态EAI政策的稳健性和用户信任进行关键分析。我们提出了MAEA，一个用于计算任何可微分政策的每个模态的全局归因的框架。此外，我们展示了归因如何在EAI政策的语言和视觉归因中启用更底层的行为分析。

    Understanding multimodal perception for embodied AI is an open question because such inputs may contain highly complementary as well as redundant information for the task. A relevant direction for multimodal policies is understanding the global trends of each modality at the fusion layer. To this end, we disentangle the attributions for visual, language, and previous action inputs across different policies trained on the ALFRED dataset. Attribution analysis can be utilized to rank and group the failure scenarios, investigate modeling and dataset biases, and critically analyze multimodal EAI policies for robustness and user trust before deployment. We present MAEA, a framework to compute global attributions per modality of any differentiable policy. In addition, we show how attributions enable lower-level behavior analysis in EAI policies for language and visual attributions.
    
[^43]: 在概率编程中的整数算术的扩展

    Scaling Integer Arithmetic in Probabilistic Programs. (arXiv:2307.13837v1 [cs.AI])

    [http://arxiv.org/abs/2307.13837](http://arxiv.org/abs/2307.13837)

    本文提出了一种利用整数算术结构扩展概率编程中整数分布的方法，通过二进制编码和知识编译实现了精确的概率推理，能够处理规模更大的整数分布。

    

    整数分布在概率建模中非常常见，但对于许多当今的概率编程语言来说仍然具有挑战性。核心挑战来自于离散结构：当今的概率编程语言推理策略往往依赖于枚举、采样或微分来进行扩展，但这些方法在涉及整数的高维复杂离散分布上失效。我们的观点是，这些方法没有利用到算术中的结构。我们提出了一种针对离散分布的二进制编码策略，利用了整数运算（如求和和比较）的丰富逻辑结构。我们利用这种结构化编码和知识编译进行精确的概率推理，并展示了这种方法在具有算术的更大整数分布上的扩展能力。

    Distributions on integers are ubiquitous in probabilistic modeling but remain challenging for many of today's probabilistic programming languages (PPLs). The core challenge comes from discrete structure: many of today's PPL inference strategies rely on enumeration, sampling, or differentiation in order to scale, which fail for high-dimensional complex discrete distributions involving integers. Our insight is that there is structure in arithmetic that these approaches are not using. We present a binary encoding strategy for discrete distributions that exploits the rich logical structure of integer operations like summation and comparison. We leverage this structured encoding with knowledge compilation to perform exact probabilistic inference, and show that this approach scales to much larger integer distributions with arithmetic.
    
[^44]: 无模型强化学习中的在线Q函数正则化方法

    Offline Reinforcement Learning with On-Policy Q-Function Regularization. (arXiv:2307.13824v1 [cs.LG])

    [http://arxiv.org/abs/2307.13824](http://arxiv.org/abs/2307.13824)

    本论文提出了一种无模型强化学习方法，通过正则化向行为策略的Q函数进行训练，而不是训练行为策略本身。该方法利用了Q函数的估计来处理外推误差，并在D4RL基准测试中展现了强大的性能。

    

    离线强化学习（Offline RL）的核心挑战是处理历史数据集与期望策略之间的分布变化所引起的（潜在灾难性的）外推误差。先前的大部分工作通过隐式/显式地将学习策略向行为策略进行正则化来解决这个挑战，但在实践中很难可靠地估计行为策略。本文中，我们提出了一种向行为策略的Q函数进行正则化的方法，前提是Q函数可以通过SARSA-style估计更可靠且更容易地处理外推误差。我们提出了两种算法，通过正则化利用估计的Q函数，并证明它们在D4RL基准测试中表现出很强的性能。

    The core challenge of offline reinforcement learning (RL) is dealing with the (potentially catastrophic) extrapolation error induced by the distribution shift between the history dataset and the desired policy. A large portion of prior work tackles this challenge by implicitly/explicitly regularizing the learning policy towards the behavior policy, which is hard to estimate reliably in practice. In this work, we propose to regularize towards the Q-function of the behavior policy instead of the behavior policy itself, under the premise that the Q-function can be estimated more reliably and easily by a SARSA-style estimate and handles the extrapolation error more straightforwardly. We propose two algorithms taking advantage of the estimated Q-function through regularizations, and demonstrate they exhibit strong performance on the D4RL benchmarks.
    
[^45]: 用多分辨率神经网络拟合听觉滤波器组

    Fitting Auditory Filterbanks with Multiresolution Neural Networks. (arXiv:2307.13821v1 [cs.SD])

    [http://arxiv.org/abs/2307.13821](http://arxiv.org/abs/2307.13821)

    本文提出了一种名为多分辨率神经网络（MuReNN）的神经音频模型，通过在离散小波变换（DWT）的八度子带上训练单独的卷积算子，解决了基于波形的深度学习面临的非参数和参数方法之间的困境。

    

    基于波形的深度学习面临非参数和参数方法之间的困境。一方面，卷积神经网络（convnets）可以近似任何线性时不变系统；然而，在实践中，它们的频率响应随着感受野的增长变得更加不规则。另一方面，诸如LEAF之类的参数模型保证产生Gabor滤波器，从而实现最佳的时频定位；然而，这种强烈的归纳偏见不利于表示能力。本文旨在通过引入名为多分辨率神经网络（MuReNN）的神经音频模型来克服这一困境。MuReNN背后的核心思想是在离散小波变换（DWT）的八度子带上训练单独的卷积算子。由于DWT原子的尺度在八度之间按指数增长，MuReNN中后续可学习卷积的感受野也相应扩张。对于给定的真实世界数据集，我们拟合了幅度...

    Waveform-based deep learning faces a dilemma between nonparametric and parametric approaches. On one hand, convolutional neural networks (convnets) may approximate any linear time-invariant system; yet, in practice, their frequency responses become more irregular as their receptive fields grow. On the other hand, a parametric model such as LEAF is guaranteed to yield Gabor filters, hence an optimal time-frequency localization; yet, this strong inductive bias comes at the detriment of representational capacity. In this paper, we aim to overcome this dilemma by introducing a neural audio model, named multiresolution neural network (MuReNN). The key idea behind MuReNN is to train separate convolutional operators over the octave subbands of a discrete wavelet transform (DWT). Since the scale of DWT atoms grows exponentially between octaves, the receptive fields of the subsequent learnable convolutions in MuReNN are dilated accordingly. For a given real-world dataset, we fit the magnitude r
    
[^46]: ForestMonkey：基于人工智能的缺陷检测和分类模型推理工具包的设计

    ForestMonkey: Toolkit for Reasoning with AI-based Defect Detection and Classification Models. (arXiv:2307.13815v1 [cs.AI])

    [http://arxiv.org/abs/2307.13815](http://arxiv.org/abs/2307.13815)

    本文介绍了Forest Monkey（FM）工具包，它是一个用于推理任何基于AI的缺陷检测和/或分类模型输出结果的工具包。该工具包提供了可解释性的数据和图表，以帮助用户理解推理结果并提出改进建议。

    

    最近人工智能（AI）推理和可解释AI（XAI）任务越来越受欢迎，使用户能够解释AI模型的预测或决策过程。本文介绍了Forest Monkey（FM）工具包，它是为了推理任何基于AI的缺陷检测和/或分类模型的输出而设计的，并具备数据可解释性。作为一个Python软件包实现，FM以数据集文件夹路径的形式作为输入（包括原始图像、真实标签和预测标签），并提供一组图表和文本文件以说明推理结果，并提出可能的改进。FM工具包包括从预测提取特征到推理目标、从图像提取特征到缺陷特征以及基于决策树的AI推理器等过程。此外，本文还研究了FM工具包在应用于四个不同数据集的AI模型时的时间性能。最后，还提供了一个教程来指导用户。

    Artificial intelligence (AI) reasoning and explainable AI (XAI) tasks have gained popularity recently, enabling users to explain the predictions or decision processes of AI models. This paper introduces Forest Monkey (FM), a toolkit designed to reason the outputs of any AI-based defect detection and/or classification model with data explainability. Implemented as a Python package, FM takes input in the form of dataset folder paths (including original images, ground truth labels, and predicted labels) and provides a set of charts and a text file to illustrate the reasoning results and suggest possible improvements. The FM toolkit consists of processes such as feature extraction from predictions to reasoning targets, feature extraction from images to defect characteristics, and a decision tree-based AI-Reasoner. Additionally, this paper investigates the time performance of the FM toolkit when applied to four AI models with different datasets. Lastly, a tutorial is provided to guide users
    
[^47]: 如何扩展您的EMA（arXiv:2307.13813v1 [stat.ML]）

    How to Scale Your EMA. (arXiv:2307.13813v1 [stat.ML])

    [http://arxiv.org/abs/2307.13813](http://arxiv.org/abs/2307.13813)

    本研究提供了在存在模型EMA的情况下进行优化的缩放规则，以保持训练动态的一致性。这对于实际机器学习中的权衡批量大小和墙钟时间非常重要。模型EMA能够提高模型的性能以及稳定训练过程，并为自监督学习提供学习信号。

    

    在实际机器学习中，保持训练动态在批量大小之间的一致性是一种重要工具，它能够在批量大小和墙钟时间之间进行权衡。这种权衡通常通过一个缩放规则来实现，例如，在随机梯度下降中，应该将学习率与批量大小呈线性关系。另一个实际机器学习的重要工具是模型指数移动平均（EMA），它是一个不接收梯度信息的模型副本，而是以一定的动量跟随其目标模型。这个模型EMA可以提高监督学习的稳健性和泛化性能，稳定伪标记，为自监督学习提供学习信号。之前的研究将模型EMA与优化分开处理，导致批量大小之间存在不同的训练动态和较低的模型性能。在这项工作中，我们提供了在存在模型EMA的情况下进行优化的缩放规则，并展示了其效果。

    Preserving training dynamics across batch sizes is an important tool for practical machine learning as it enables the trade-off between batch size and wall-clock time. This trade-off is typically enabled by a scaling rule, for example, in stochastic gradient descent, one should scale the learning rate linearly with the batch size. Another important tool for practical machine learning is the model Exponential Moving Average (EMA), which is a model copy that does not receive gradient information, but instead follows its target model with some momentum. This model EMA can improve the robustness and generalization properties of supervised learning, stabilize pseudo-labeling, and provide a learning signal for Self-Supervised Learning (SSL). Prior works have treated the model EMA separately from optimization, leading to different training dynamics across batch sizes and lower model performance. In this work, we provide a scaling rule for optimization in the presence of model EMAs and demonst
    
[^48]: GPT是情感的计算模型吗？详细分析。

    Is GPT a Computational Model of Emotion? Detailed Analysis. (arXiv:2307.13779v1 [cs.CL])

    [http://arxiv.org/abs/2307.13779](http://arxiv.org/abs/2307.13779)

    本文通过组件的视角研究了GPT系列大型语言模型的情感推理能力。尽管GPT的预测结果与人类提供的评估和情感标签显著一致，但在预测情感强度和应对反应方面遇到了困难。

    

    本文通过组件的视角研究了GPT系列大型语言模型的情感推理能力。首先，本文考察了该模型对自传式记忆的推理方式。其次，通过系统性地改变情境的各个方面来影响情感强度和应对倾向。研究结果表明，即使在没有使用提示工程的情况下，GPT的预测结果与人类提供的评估和情感标签显著一致。然而，GPT在预测情感强度和应对反应方面遇到了困难。尽管GPT-4在初步研究中表现最好，但在第二项研究中表现不佳，尽管经过轻微的提示工程后提供了更好的结果。这个评估引发了如何有效地利用这些模型的优点并解决其弱点的问题，尤其是关于响应的变异性。这些研究突显了从组件的角度评估模型的优点。

    This paper investigates the emotional reasoning abilities of the GPT family of large language models via a component perspective. The paper first examines how the model reasons about autobiographical memories. Second, it systematically varies aspects of situations to impact emotion intensity and coping tendencies. Even without the use of prompt engineering, it is shown that GPT's predictions align significantly with human-provided appraisals and emotional labels. However, GPT faces difficulties predicting emotion intensity and coping responses. GPT-4 showed the highest performance in the initial study but fell short in the second, despite providing superior results after minor prompt engineering. This assessment brings up questions on how to effectively employ the strong points and address the weak areas of these models, particularly concerning response variability. These studies underscore the merits of evaluating models from a componential perspective.
    
[^49]: PyTorch内部的错误：一个复制研究的实证研究

    An Empirical Study on Bugs Inside PyTorch: A Replication Study. (arXiv:2307.13777v1 [cs.SE])

    [http://arxiv.org/abs/2307.13777](http://arxiv.org/abs/2307.13777)

    本研究对PyTorch深度学习库中的错误进行了复制研究，通过调查和评估错误的原因和症状，提供了对错误识别和修复过程的了解。

    

    由于其识别复杂数据模式和实现智能行为的显著能力，软件系统越来越依赖于深度学习组件。这种软件开发变革的核心推动者是易于使用的深度学习库的可用性。像PyTorch和TensorFlow这样的库赋予各种智能系统以能力，提供了大量的算法和配置选项，适用于多个领域的系统。然而，这些受欢迎的深度学习库中的错误也可能对其所支持的系统的质量产生严重影响，因此了解如何在这些库中识别和修复错误非常重要。受Jia等人的研究启发，该研究调查了TensorFlow中错误的识别和修复过程，我们对非常流行的深度学习框架PyTorch中的错误进行了特征化。我们调查了PyTorch开发过程中发现的错误的原因和症状，并评估了修复这些错误的方法。

    Software systems are increasingly relying on deep learning components, due to their remarkable capability of identifying complex data patterns and powering intelligent behaviour. A core enabler of this change in software development is the availability of easy-to-use deep learning libraries. Libraries like PyTorch and TensorFlow empower a large variety of intelligent systems, offering a multitude of algorithms and configuration options, applicable to numerous domains of systems. However, bugs in those popular deep learning libraries also may have dire consequences for the quality of systems they enable; thus, it is important to understand how bugs are identified and fixed in those libraries.  Inspired by a study of Jia et al., which investigates the bug identification and fixing process at TensorFlow, we characterize bugs in the PyTorch library, a very popular deep learning framework. We investigate the causes and symptoms of bugs identified during PyTorch's development, and assess the
    
[^50]: 通过对齐稀疏上下文化的词表示来解决跨语言词义消歧中的多语言诅咒

    Combating the Curse of Multilinguality in Cross-Lingual WSD by Aligning Sparse Contextualized Word Representations. (arXiv:2307.13776v1 [cs.CL])

    [http://arxiv.org/abs/2307.13776](http://arxiv.org/abs/2307.13776)

    本文提出了使用大型预训练单语语言模型和上下文化映射机制来解决跨语言词义消歧的多语言诅咒，并通过实验验证了这种方法的有效性。

    

    本文提倡在跨语言零样本词义消歧（WSD）中使用大型预训练单语语言模型，并结合上下文化映射机制。我们还进行了严格的实验，证明了通过字典学习过程获得的稀疏上下文化词表示的有效性。我们的实验结果表明，上述改进使得17种语言的平均F分数有近6.5个百分点的显著提高（从62.0提高到68.5）。我们在https://github.com/begab/sparsity_makes_sense发布了用于复现我们实验的源代码。

    In this paper, we advocate for using large pre-trained monolingual language models in cross lingual zero-shot word sense disambiguation (WSD) coupled with a contextualized mapping mechanism. We also report rigorous experiments that illustrate the effectiveness of employing sparse contextualized word representations obtained via a dictionary learning procedure. Our experimental results demonstrate that the above modifications yield a significant improvement of nearly 6.5 points of increase in the average F-score (from 62.0 to 68.5) over a collection of 17 typologically diverse set of target languages. We release our source code for replicating our experiments at https://github.com/begab/sparsity_makes_sense.
    
[^51]: E^2VPT: 一种有效高效的视觉提示调整方法

    E^2VPT: An Effective and Efficient Approach for Visual Prompt Tuning. (arXiv:2307.13770v1 [cs.CV])

    [http://arxiv.org/abs/2307.13770](http://arxiv.org/abs/2307.13770)

    E^2VPT是一种有效和高效的大规模Transformer模型适应方法，通过引入可学习的键值和视觉提示，以及提示剪枝过程来改善模型微调的效果并提高模型的效率。

    

    随着基于Transformer的模型规模的不断增长，对这些大规模预训练视觉模型进行新任务的微调变得越来越参数密集。为了减少微调过程中可调参数的数量，开发了一种参数高效学习的方法。尽管这些方法表现出了很好的结果，但与完全微调相比仍存在显著的性能差距。为了解决这个挑战，我们提出了一种Effective and Efficient Visual Prompt Tuning（E^2VPT）方法，用于大规模基于Transformer的模型调整。具体而言，我们引入了一组可学习的键值提示和视觉提示到自注意力和输入层，分别改善模型微调的效果。此外，我们设计了一种提示剪枝过程，系统地剪枝低重要性的提示，同时保持模型性能，从而大大提高了模型的效率。实证结果表明，我们的方法优于几种目前最先进的方法。

    As the size of transformer-based models continues to grow, fine-tuning these large-scale pretrained vision models for new tasks has become increasingly parameter-intensive. Parameter-efficient learning has been developed to reduce the number of tunable parameters during fine-tuning. Although these methods show promising results, there is still a significant performance gap compared to full fine-tuning. To address this challenge, we propose an Effective and Efficient Visual Prompt Tuning (E^2VPT) approach for large-scale transformer-based model adaptation. Specifically, we introduce a set of learnable key-value prompts and visual prompts into self-attention and input layers, respectively, to improve the effectiveness of model fine-tuning. Moreover, we design a prompt pruning procedure to systematically prune low importance prompts while preserving model performance, which largely enhances the model's efficiency. Empirical results demonstrate that our approach outperforms several state-o
    
[^52]: ClusterSeq: 用基于聚类的元学习增强顺序推荐系统

    ClusterSeq: Enhancing Sequential Recommender Systems with Clustering based Meta-Learning. (arXiv:2307.13766v1 [cs.IR])

    [http://arxiv.org/abs/2307.13766](http://arxiv.org/abs/2307.13766)

    ClusterSeq是一种基于聚类的元学习顺序推荐系统，通过利用用户序列的动态信息提高了物品预测的准确性，并保留了次要用户的偏好，并利用了同一聚类中用户的集体知识。

    

    在实际场景中，顺序推荐系统的有效性受到了用户冷启动问题的限制，这是由于有限的交互使得无法准确确定用户的偏好。以前的研究试图通过将元学习与用户和物品侧信息相结合来解决这个问题。然而，这些方法在建模用户偏好动态方面面临着固有的挑战，尤其是对于展现出与更常见或“主要用户”不同偏好的“次要用户”。为了克服这些局限性，我们提出了一种新颖的方法，称为ClusterSeq，一种基于聚类的元学习顺序推荐系统。ClusterSeq利用用户序列中的动态信息来提高物品预测的准确性，即使没有侧信息。该模型保留了次要用户的偏好，而不会被主要用户所掩盖，并利用了同一聚类中用户的集体知识。

    In practical scenarios, the effectiveness of sequential recommendation systems is hindered by the user cold-start problem, which arises due to limited interactions for accurately determining user preferences. Previous studies have attempted to address this issue by combining meta-learning with user and item-side information. However, these approaches face inherent challenges in modeling user preference dynamics, particularly for "minor users" who exhibit distinct preferences compared to more common or "major users." To overcome these limitations, we present a novel approach called ClusterSeq, a Meta-Learning Clustering-Based Sequential Recommender System. ClusterSeq leverages dynamic information in the user sequence to enhance item prediction accuracy, even in the absence of side information. This model preserves the preferences of minor users without being overshadowed by major users, and it capitalizes on the collective knowledge of users within the same cluster. Extensive experiment
    
[^53]: 隐式归一化显式正则化密度估计

    Implicitly Normalized Explicitly Regularized Density Estimation. (arXiv:2307.13763v1 [stat.ML])

    [http://arxiv.org/abs/2307.13763](http://arxiv.org/abs/2307.13763)

    我们提出了一种新的非参数密度估计方法，基于正则化密度的 Sobolev 范数，通过适当的初始化和使用自然梯度，可以得到性能良好的解，该方法在 Anomaly Detection benchmark 中排名第二。

    

    我们提出了一种新的非参数密度估计方法，该方法是基于正则化密度的 Sobolev 范数。这种方法与核密度估计有明显差异，可以清晰解释模型的偏差。虽然我们无法得到相关核函数的闭合解析形式，但我们证明可以通过采样进行近似。决定密度的优化问题是非凸的，标准的梯度方法效果不好。然而，我们证明在适当的初始化和使用自然梯度的情况下，可以得到性能良好的解。最后，虽然该方法提供的是非归一化的密度，无法使用对数似然进行交叉验证，但我们证明可以采用基于 Fisher 散度的分数匹配方法来解决这个问题。我们在最近的异常检测基准套件 ADBench 上评估了得到的方法，并发现它在超过15个算法中排名第二。

    We propose a new approach to non-parametric density estimation, that is based on regularizing a Sobolev norm of the density. This method is provably different from Kernel Density Estimation, and makes the bias of the model clear and interpretable. While there is no closed analytic form for the associated kernel, we show that one can approximate it using sampling. The optimization problem needed to determine the density is non-convex, and standard gradient methods do not perform well. However, we show that with an appropriate initialization and using natural gradients, one can obtain well performing solutions. Finally, while the approach provides unnormalized densities, which prevents the use of log-likelihood for cross validation, we show that one can instead adapt Fisher Divergence based Score Matching methods for this task. We evaluate the resulting method on the comprehensive recent Anomaly Detection benchmark suite, ADBench, and find that it ranks second best, among more than 15 al
    
[^54]: TMR-RD: 用于半监督目标检测的基于训练的模型精化和表示分歧方法

    TMR-RD: Training-based Model Refinement and Representation Disagreement for Semi-Supervised Object Detection. (arXiv:2307.13755v1 [cs.CV])

    [http://arxiv.org/abs/2307.13755](http://arxiv.org/abs/2307.13755)

    在半监督目标检测中，本文提出了基于训练的模型精化(TMR)阶段和表示分歧(RD)策略，用来解决伪标签噪声和教师-学生模型的一致性问题。TMR阶段通过轻量级缩放操作优化模型权重，防止过度拟合或遗忘学到的模式；RD策略帮助保持模型的差异，鼓励学生模型探索互补的表示。

    

    半监督目标检测(SSOD)可以将有限的标记数据和大量的未标记数据结合起来，提高现有目标检测器的性能和泛化能力。尽管取得了许多进展，但是最近的SSOD方法仍然面临着伪标签噪声/误导、经典指数移动平均(EMA)策略和后期训练中教师-学生模型的一致性等挑战。本文提出了一种新颖的基于训练的模型精化(TMR)阶段和简单而有效的表示分歧(RD)策略，以解决经典EMA的局限性和一致性问题。教师-学生模型的TMR阶段优化了轻量级缩放操作，以精化模型的权重，并防止过度拟合或遗忘从未标记数据中学到的模式。同时，RD策略帮助保持这些模型的差异，鼓励学生模型探索互补的表示。此外，我们使用级连回归来生成... (摘要未完整提供)

    Semi-supervised object detection (SSOD) can incorporate limited labeled data and large amounts of unlabeled data to improve the performance and generalization of existing object detectors. Despite many advances, recent SSOD methods are still challenged by noisy/misleading pseudo-labels, classical exponential moving average (EMA) strategy, and the consensus of Teacher-Student models in the latter stages of training. This paper proposes a novel training-based model refinement (TMR) stage and a simple yet effective representation disagreement (RD) strategy to address the limitations of classical EMA and the consensus problem. The TMR stage of Teacher-Student models optimizes the lightweight scaling operation to refine the model's weights and prevent overfitting or forgetting learned patterns from unlabeled data. Meanwhile, the RD strategy helps keep these models diverged to encourage the student model to explore complementary representations. In addition, we use cascade regression to gene
    
[^55]: 视觉的一个新时代定义的基础模型: 一项调查和展望

    Foundational Models Defining a New Era in Vision: A Survey and Outlook. (arXiv:2307.13721v1 [cs.CV])

    [http://arxiv.org/abs/2307.13721](http://arxiv.org/abs/2307.13721)

    这项调查提供了对新兴基础模型的全面回顾，这些模型能够通过人类提供的提示实现上下文推理、生成泛化的结果，并在测试时具有即时能力。

    

    视觉系统以观察和推理视觉场景的组成性质为基础，对于理解我们的世界至关重要。对象之间的复杂关系以及它们在真实环境中的位置、歧义和变化可以更好地用人类语言描述，这种语言通常受到语法规则和其他模态（如音频和深度）的约束。这些模型学习了如何弥合这些模态之间的差距，并结合大规模的训练数据，促进了上下文推理、泛化以及测试时的即时能力。这些模型被称为基础模型。这些模型的输出可以通过人类提供的提示进行修改，无需重新训练，例如通过提供边界框对特定对象进行分割，通过询问关于图像或视频场景的问题实现互动对话，或通过语言指令对机器人的行为进行操作。在本调查中，我们对这些新兴的基础模型进行了全面的回顾。

    Vision systems to see and reason about the compositional nature of visual scenes are fundamental to understanding our world. The complex relations between objects and their locations, ambiguities, and variations in the real-world environment can be better described in human language, naturally governed by grammatical rules and other modalities such as audio and depth. The models learned to bridge the gap between such modalities coupled with large-scale training data facilitate contextual reasoning, generalization, and prompt capabilities at test time. These models are referred to as foundational models. The output of such models can be modified through human-provided prompts without retraining, e.g., segmenting a particular object by providing a bounding box, having interactive dialogues by asking questions about an image or video scene or manipulating the robot's behavior through language instructions. In this survey, we provide a comprehensive review of such emerging foundational mod
    
[^56]: 组合扩散：整体> = SUM（部分）

    Composite Diffusion | whole >= \Sigma parts. (arXiv:2307.13720v1 [cs.CV])

    [http://arxiv.org/abs/2307.13720](http://arxiv.org/abs/2307.13720)

    本文引入了组合扩散作为艺术家生成高质量图像的方法，通过组合子场景并灵活布局，艺术家可以描述每个子场景的内容，并利用各种控制输入生成、组合和协调子场景，以实现综合而细致的图像生成。作者提出现有图像质量评估指标缺乏整体评估的能力，希望通过组合扩散方法来综合评估图像质量和实现艺术家意图。

    

    对于艺术家或平面设计师来说，场景的空间布局是一个关键的设计选择。然而，现有的文本到图像扩散模型在整合空间信息方面提供的支持有限。本文介绍了组合扩散作为艺术家通过组合子场景生成高质量图像的手段。艺术家可以通过灵活的自由形式段落布局来指定这些子场景的排列。他们可以主要使用自然文本来描述每个子场景的内容，此外还可以利用参考图像或控制输入，如线条艺术、涂鸦、人体姿势、边缘等。我们提供了一个综合而模块化的组合扩散方法，使得可以以备选的方式生成、组合和协调子场景。此外，我们希望评估组合图像在图像质量和实现艺术家意图方面的效果。我们认为现有的图像质量评估指标缺乏整体评估的能力。

    For an artist or a graphic designer, the spatial layout of a scene is a critical design choice. However, existing text-to-image diffusion models provide limited support for incorporating spatial information. This paper introduces Composite Diffusion as a means for artists to generate high-quality images by composing from the sub-scenes. The artists can specify the arrangement of these sub-scenes through a flexible free-form segment layout. They can describe the content of each sub-scene primarily using natural text and additionally by utilizing reference images or control inputs such as line art, scribbles, human pose, canny edges, and more.  We provide a comprehensive and modular method for Composite Diffusion that enables alternative ways of generating, composing, and harmonizing sub-scenes. Further, we wish to evaluate the composite image for effectiveness in both image quality and achieving the artist's intent. We argue that existing image quality metrics lack a holistic evaluation
    
[^57]: FedDRL: 一种基于分阶段强化学习的可信联邦学习模型融合方法

    FedDRL: A Trustworthy Federated Learning Model Fusion Method Based on Staged Reinforcement Learning. (arXiv:2307.13716v1 [cs.LG])

    [http://arxiv.org/abs/2307.13716](http://arxiv.org/abs/2307.13716)

    FedDRL是一种分阶段强化学习的联邦学习模型融合方法，解决了传统方法中无法解决的客户端模型质量和恶意模型问题。

    

    传统的联邦学习使用样本数量计算每个客户端模型的权重，并使用这个固定权重值来融合全局模型。然而，在实际场景中，每个客户端设备和数据的异质性导致每个客户端模型的质量存在差异。因此，对全局模型的贡献不仅仅取决于样本量。此外，如果客户端故意上传低质量或恶意模型，使用这些模型进行聚合将严重降低全局模型的准确性。传统的联邦学习算法没有解决这些问题。为了解决这个问题，我们提出了一种名为FedDRL的模型融合方法，它使用两个阶段的强化学习。在第一个阶段，我们的方法可以过滤掉恶意模型，并选择可信的客户端模型参与模型融合。在第二个阶段，FedDRL算法自适应地调整可信客户端模型的权重并聚合。

    Traditional federated learning uses the number of samples to calculate the weights of each client model and uses this fixed weight value to fusion the global model. However, in practical scenarios, each client's device and data heterogeneity leads to differences in the quality of each client's model. Thus the contribution to the global model is not wholly determined by the sample size. In addition, if clients intentionally upload low-quality or malicious models, using these models for aggregation will lead to a severe decrease in global model accuracy. Traditional federated learning algorithms do not address these issues. To solve this probelm, we propose FedDRL, a model fusion approach using reinforcement learning based on a two staged approach. In the first stage, Our method could filter out malicious models and selects trusted client models to participate in the model fusion. In the second stage, the FedDRL algorithm adaptively adjusts the weights of the trusted client models and ag
    
[^58]: 《2023年教练人工智能团队8参加CoachAI羽毛球挑战赛：用于击球预测的高级ShuttleNet》

    Team Intro to AI team8 at CoachAI Badminton Challenge 2023: Advanced ShuttleNet for Shot Predictions. (arXiv:2307.13715v1 [cs.LG])

    [http://arxiv.org/abs/2307.13715](http://arxiv.org/abs/2307.13715)

    本文提出了一个名为ShuttleNet的框架，通过利用过去的击球信息，显著改进了预测羽毛球击球类型和位置的性能，最终在CoachAI羽毛球挑战赛中获得第一名。

    

    本文的目标是通过利用过去的击球来改进现有框架ShuttleNet在预测羽毛球击球类型和位置方面的性能。我们参加了2023年IJCAI的CoachAI羽毛球挑战赛，并取得了显著优于基准线的成绩。最终，我们的团队在比赛中获得了第一名，并公开了我们的代码。

    In this paper, our objective is to improve the performance of the existing framework ShuttleNet in predicting badminton shot types and locations by leveraging past strokes. We participated in the CoachAI Badminton Challenge at IJCAI 2023 and achieved significantly better results compared to the baseline. Ultimately, our team achieved the first position in the competition and we made our code available.
    
[^59]: 深度布拉德利-特里评分：在没有具体评价标准的情况下估计物品的属性

    Deep Bradley-Terry Rating: Estimate Properties Without Metric of Unseen Items. (arXiv:2307.13709v1 [cs.LG])

    [http://arxiv.org/abs/2307.13709](http://arxiv.org/abs/2307.13709)

    本论文提出了深度布拉德利-特里评分（DBTR）方法，用于评估不一定存在于数据集中的未知物品的属性。该方法通过将传统的布拉德利-特里模型与神经网络结构无缝结合，成功地学习了这些属性的预期量化。

    

    在现实世界中，许多属性，如竞争环境中的可取性或强度，无法直接观测，这使得它们难以评估。为了解决这个具有挑战性的问题，先前的研究主要集中在估计已知物品的这些属性，特别是出现在配对比较数据集中的运动员的实力。在本文中，我们介绍了深度布拉德利-特里评分（DBTR），这是一个新颖的机器学习框架，用于评估不一定存在于数据集中的未知物品的任何属性。我们的方法无缝地将传统的布拉德利-特里模型与神经网络结构相结合。我们还进一步推广了这个架构，用于具有不公平性的非对称环境，这在现实世界中更为常见。在我们的实验分析中，DBTR成功地学习了这些属性的预期量化。

    Many properties in real world, such as desirability or strength in competitive environment, can't be directly observed, which makes them difficult to evaluate. To deal with this challenging problem, prior work has primarily focused on estimating those properties of known items, especially the strength of sports players, only of those who appears in paired comparison dataset. In this paper, we introduce Deep Bradley-Terry Rating (DBTR), a novel ML framework to evaluate any properties of unknown items, not necessarily present in dataset. Our method seamlessly integrates traditional Bradley-Terry model with a neural network structure. We also generalizes this architecture further for asymmetric environment with unfairness, which is much more common in real world settings. In our experimental analysis, DBTR successfully learned desired quantification of those properties.
    
[^60]: 引入CALMED：用于自闭症儿童情绪检测的多模态注释数据集

    Introducing CALMED: Multimodal Annotated Dataset for Emotion Detection in Children with Autism. (arXiv:2307.13706v1 [cs.HC])

    [http://arxiv.org/abs/2307.13706](http://arxiv.org/abs/2307.13706)

    本研究介绍了CALMED，这是一个针对自闭症儿童的多模态情绪检测数据集，旨在改进自动情绪检测系统在自闭症患者身上的表现。

    

    自动情绪检测（ED）旨在构建系统以自动识别用户的情绪。这一领域有潜力提升人机交互体验，为用户创造个性化的体验。然而，ED系统在自闭症谱系障碍（ASD）患者身上表现出较差的性能。因此，有必要创建针对自闭症患者情绪表达方式的ED系统。先前的研究虽然创建了针对ASD儿童的ED系统，但未共享所得到的数据集。共享注释数据集对于促进研究社区内更先进的计算机模型对ED的发展至关重要。在本文中，我们描述了我们建立一个流程来创建一个多模态注释数据集，其中包括自闭症1级诊断的儿童。此外，我们介绍了CALMED（Children, Autism, Multimodal, Emotion, Detection），这是一个多模态的情绪检测数据集，包括年龄在8-12岁的自闭症儿童的音频和视频特征。

    Automatic Emotion Detection (ED) aims to build systems to identify users' emotions automatically. This field has the potential to enhance HCI, creating an individualised experience for the user. However, ED systems tend to perform poorly on people with Autism Spectrum Disorder (ASD). Hence, the need to create ED systems tailored to how people with autism express emotions. Previous works have created ED systems tailored for children with ASD but did not share the resulting dataset. Sharing annotated datasets is essential to enable the development of more advanced computer models for ED within the research community. In this paper, we describe our experience establishing a process to create a multimodal annotated dataset featuring children with a level 1 diagnosis of autism. In addition, we introduce CALMED (Children, Autism, Multimodal, Emotion, Detection), the resulting multimodal emotion detection dataset featuring children with autism aged 8-12. CALMED includes audio and video featur
    
[^61]: 控制和监控人工智能算法

    Control and Monitoring of Artificial Intelligence Algorithms. (arXiv:2307.13705v1 [cs.LG])

    [http://arxiv.org/abs/2307.13705](http://arxiv.org/abs/2307.13705)

    论文阐述了控制和监控人工智能算法的重要性，介绍了数据漂移和概念漂移的概念，并提出了一系列指标用于审查模型在潜在时间变化方面的性能。

    

    本文阐述了在部署后管理人工智能模型和监测当前数据分布与训练数据之间的潜在波动的重要性。详细解释了数据漂移和概念漂移的概念，以及它们各自的基本分布。此外，介绍了一系列可用于审查模型在潜在时间变化方面性能的指标。

    This paper elucidates the importance of governing an artificial intelligence model post-deployment and overseeing potential fluctuations in the distribution of present data in contrast to the training data. The concepts of data drift and concept drift are explicated, along with their respective foundational distributions. Furthermore, a range of metrics is introduced, which can be utilized to scrutinize the model's performance concerning potential temporal variations.
    
[^62]: 可解释人工智能（XAI）在年龄预测中的应用：一项系统综述

    eXplainable Artificial Intelligence (XAI) in age prediction: A systematic review. (arXiv:2307.13704v1 [cs.AI])

    [http://arxiv.org/abs/2307.13704](http://arxiv.org/abs/2307.13704)

    本综述探讨了可解释人工智能（XAI）在年龄预测任务中的应用。通过系统性综述，我们讨论了XAI方法在医疗应用和年龄预测领域的益处。

    

    可解释人工智能（XAI）现在是机器学习中的重要组成部分，能够解释复杂模型的预测结果。XAI特别适用于危险应用，特别是在医疗保健领域，人类的生命依赖于AI系统的决策。医疗研究的一个领域是年龄预测和衰老及与年龄相关疾病的生物标志物鉴定。然而，在年龄预测任务中，XAI的作用尚未直接探讨。在本综述中，我们讨论了XAI方法在年龄预测任务中的应用。我们通过器官系统进行了系统性综述，并讨论了XAI在医疗应用以及特别是年龄预测领域的益处。

    eXplainable Artificial Intelligence (XAI) is now an important and essential part of machine learning, allowing to explain the predictions of complex models. XAI is especially required in risky applications, particularly in health care, where human lives depend on the decisions of AI systems. One area of medical research is age prediction and identification of biomarkers of aging and age-related diseases. However, the role of XAI in the age prediction task has not previously been explored directly. In this review, we discuss the application of XAI approaches to age prediction tasks. We give a systematic review of the works organized by body systems, and discuss the benefits of XAI in medical applications and, in particular, in the age prediction domain.
    
[^63]: 测量链式思维推理中的忠诚度

    Measuring Faithfulness in Chain-of-Thought Reasoning. (arXiv:2307.13702v1 [cs.AI])

    [http://arxiv.org/abs/2307.13702](http://arxiv.org/abs/2307.13702)

    本研究探讨了在回答问题之前，大型语言模型（LLMs）能否进行忠实的“链式思维”推理。结果显示，模型在不同任务上对链式思维的依赖程度有很大变化，随着模型变得更大更能力越强，它们在大多数任务中产生的推理越来越不忠实。

    

    大型语言模型（LLMs）在回答问题之前，如果能够产生逐步的“链式思维”推理，其表现会更好，但不清楚所述的推理是否忠实地解释了模型实际的推理过程（即回答问题的方式）。我们通过检查当介入链式思维时模型预测如何发生变化（例如，添加错误或改写它），来研究链式思维可能不忠实的假设。模型在不同任务上在预测答案时对链式思维的依赖程度有很大变化，有时会严重依赖链式思维，而其他时候则主要忽视它。链式思维的性能提升似乎不仅仅来自于其增加的测试计算量，也不仅仅来自于链式思维的特定措辞所编码的信息。随着模型变得更大更有能力，它们在我们研究的大多数任务中产生的推理越来越不忠实。总体而言，我们的结果表明，如果环境适当，链式思维可以是忠实的。

    Large language models (LLMs) perform better when they produce step-by-step, "Chain-of-Thought" (CoT) reasoning before answering a question, but it is unclear if the stated reasoning is a faithful explanation of the model's actual reasoning (i.e., its process for answering the question). We investigate hypotheses for how CoT reasoning may be unfaithful, by examining how the model predictions change when we intervene on the CoT (e.g., by adding mistakes or paraphrasing it). Models show large variation across tasks in how strongly they condition on the CoT when predicting their answer, sometimes relying heavily on the CoT and other times primarily ignoring it. CoT's performance boost does not seem to come from CoT's added test-time compute alone or from information encoded via the particular phrasing of the CoT. As models become larger and more capable, they produce less faithful reasoning on most tasks we study. Overall, our results suggest that CoT can be faithful if the circumstances s
    
[^64]: $\text{EFO}_{k}$-CQA：超越集合操作的知识图谱复杂查询回答

    $\text{EFO}_{k}$-CQA: Towards Knowledge Graph Complex Query Answering beyond Set Operation. (arXiv:2307.13701v1 [cs.AI])

    [http://arxiv.org/abs/2307.13701](http://arxiv.org/abs/2307.13701)

    本文提出了$\text{EFO}_{k}$-CQA框架，用于超越集合操作的知识图谱复杂查询回答。该框架包括数据生成、模型训练和方法评估，并且扩展了现有查询空间。使用构建的$\text{EFO}_{k}$-CQA数据集进行实证评估，结果揭示了查询难度对结果的影响。此外，还证明了现有数据集构建过程存在的问题。

    

    为了回答知识图谱上的复杂查询，需要对不完整知识进行逻辑推理，因为存在着开放世界的假设。基于学习的方法至关重要，因为它们能够对未观察到的知识进行泛化。因此，在这种范式下，一个合适的数据集对于获取和评估这样的方法都是基础。在本文中，我们提出了一个全面的框架，用于数据生成、模型训练和方法评估，涵盖了存在量化一阶查询与多个变量($\text{EFO}_{k}$)的组合空间。我们框架中的组合查询空间显著扩展了现有文献中通过集合操作定义的查询空间。此外，我们构建了一个包含741种查询类型的数据集$\text{EFO}_{k}$-CQA，以进行经验评估，我们的基准结果为理解查询难度如何影响结果提供了新的见解。此外，我们还证明了现有数据集构建过程的系统性问题。

    To answer complex queries on knowledge graphs, logical reasoning over incomplete knowledge is required due to the open-world assumption. Learning-based methods are essential because they are capable of generalizing over unobserved knowledge. Therefore, an appropriate dataset is fundamental to both obtaining and evaluating such methods under this paradigm. In this paper, we propose a comprehensive framework for data generation, model training, and method evaluation that covers the combinatorial space of Existential First-order Queries with multiple variables ($\text{EFO}_{k}$). The combinatorial query space in our framework significantly extends those defined by set operations in the existing literature. Additionally, we construct a dataset, $\text{EFO}_{k}$-CQA, with 741 types of query for empirical evaluation, and our benchmark results provide new insights into how query hardness affects the results. Furthermore, we demonstrate that the existing dataset construction process is systema
    
[^65]: CAMP:一种上下文感知的板球球员表现指标

    CAMP: A Context-Aware Cricket Players Performance Metric. (arXiv:2307.13700v1 [cs.AI])

    [http://arxiv.org/abs/2307.13700](http://arxiv.org/abs/2307.13700)

    CAMP是一种上下文感知的板球球员表现指标，通过综合考虑对手实力和比赛环境等因素，可以量化个体球员对比赛结果的贡献。CAMP通过数据挖掘方法，为选择和草案、教练和训练、团队阵容和战略制定提供数据驱动的决策支持。

    

    板球是仅次于足球在收视率上最受欢迎的运动。然而，对个体球员表现的评估，作为团队运动的基本任务，目前主要基于综合表现数据，包括平均得分和击球次数。我们提出了一种称为CAMP的上下文感知球员表现指标，用于衡量个体球员对板球比赛结果的贡献。CAMP采用数据挖掘方法，并为选择和草案、教练和训练、团队阵容和战略制定提供了有效的数据驱动决策。CAMP纳入了表现的确切上下文，例如对手的实力和比赛的特定环境，例如压力情况。我们在2001年至2019年间的有限过度板球比赛数据上进行了实证评估。在每场比赛中，一组专家宣布一名球员为最佳球员，被称为M}atch的最佳球员（MoM）。通过CAMP评估，最高评分的两名球员与MoM匹配的概率为83％。

    Cricket is the second most popular sport after soccer in terms of viewership. However, the assessment of individual player performance, a fundamental task in team sports, is currently primarily based on aggregate performance statistics, including average runs and wickets taken. We propose Context-Aware Metric of player Performance, CAMP, to quantify individual players' contributions toward a cricket match outcome. CAMP employs data mining methods and enables effective data-driven decision-making for selection and drafting, coaching and training, team line-ups, and strategy development. CAMP incorporates the exact context of performance, such as opponents' strengths and specific circumstances of games, such as pressure situations. We empirically evaluate CAMP on data of limited-over cricket matches between 2001 and 2019. In every match, a committee of experts declares one player as the best player, called Man of the M}atch (MoM). The top two rated players by CAMP match with MoM in 83\% 
    
[^66]: EFL学生对机器辅助写作的态度和矛盾的研究

    EFL Students' Attitudes and Contradictions in a Machine-in-the-loop Activity System. (arXiv:2307.13699v1 [cs.HC])

    [http://arxiv.org/abs/2307.13699](http://arxiv.org/abs/2307.13699)

    这项研究探讨了67位来自香港四所中学的EFL学生对机器辅助写作的态度和矛盾。研究发现学生对机器辅助写作持积极态度，但也存在一些负面或矛盾的感情。研究提出了在EFL课堂中实施机器辅助写作的益处和挑战，建议教育工作者将活动目标与学生的价值观、语言能力和AI能力相一致，以提高学生的活动系统。

    

    本研究应用活动理论探讨了来自香港四所中学的67名英语作为外语（EFL）学生对机器辅助写作的态度和矛盾。在写作过程中，人工智能（AI）提供创作想法。学生回答了一个开放性问题，表达他们对与AI一起写作的感受。研究结果显示，大部分学生持积极态度，但也存在一些负面或矛盾的感情。通过主题分析发现，学生和AI之间的矛盾或紧张点源于AI的不足，学生在热情和偏好之间的平衡，以及他们追求语言自主性。研究突出了在EFL课堂上实施机器辅助写作的益处和挑战，建议教育工作者将活动目标与学生的价值观、语言能力和AI能力相一致，以提高学生的活动系统。

    This study applies Activity Theory and investigates the attitudes and contradictions of 67 English as a foreign language (EFL) students from four Hong Kong secondary schools towards machine-in-the-loop writing, where artificial intelligence (AI) suggests ideas during composition. Students answered an open-ended question about their feelings on writing with AI. Results revealed mostly positive attitudes, with some negative or mixed feelings. From a thematic analysis, contradictions or points of tension between students and AI stemmed from AI inadequacies, students' balancing enthusiasm with preference, and their striving for language autonomy. The research highlights the benefits and challenges of implementing machine-in-the-loop writing in EFL classrooms, suggesting educators align activity goals with students' values, language abilities, and AI capabilities to enhance students' activity systems.
    
[^67]: GPT-3模型是少样本金融推理器

    GPT-3 Models are Few-Shot Financial Reasoners. (arXiv:2307.13617v1 [cs.CL])

    [http://arxiv.org/abs/2307.13617](http://arxiv.org/abs/2307.13617)

    GPT-3模型在金融领域的少样本推理表现有限，需要使用独立的检索模型和逻辑引擎来获得最佳性能。

    

    金融分析是评估公司业绩的重要工具。从业者通过深入的量化分析回答金融问题，从而做出有利可图的投资决策。因此，金融问答是一个需要对数字进行深入推理的问题回答任务。此外，目前尚不清楚预训练语言模型在金融领域的推理能力如何。目前的最新技术需要一个检索模型从文本中收集与金融问题相关的事实，并使用一个生成器来生成有效的金融程序和最终答案。然而，最近的大型语言模型如GPT-3仅仅通过少量示例就实现了广泛任务的最新性能。我们对GPT-3进行了多个实验，发现独立的检索模型和逻辑引擎仍然是实现这一任务的关键组件，尤其是由于金融领域的精确性要求。

    Financial analysis is an important tool for evaluating company performance. Practitioners work to answer financial questions to make profitable investment decisions, and use advanced quantitative analyses to do so. As a result, Financial Question Answering (QA) is a question answering task that requires deep reasoning about numbers. Furthermore, it is unknown how well pre-trained language models can reason in the financial domain. The current state-of-the-art requires a retriever to collect relevant facts about the financial question from the text and a generator to produce a valid financial program and a final answer. However, recently large language models like GPT-3 have achieved state-of-the-art performance on wide variety of tasks with just a few shot examples. We run several experiments with GPT-3 and find that a separate retrieval model and logic engine continue to be essential components to achieving SOTA performance in this task, particularly due to the precise nature of finan
    
[^68]: FacTool：生成AI中的事实性检测 —— 一种为多任务和多领域场景加强的工具增强框架

    FacTool: Factuality Detection in Generative AI -- A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios. (arXiv:2307.13528v1 [cs.CL])

    [http://arxiv.org/abs/2307.13528](http://arxiv.org/abs/2307.13528)

    提出了FacTool框架，用于检测大型语言模型（如ChatGPT）生成的文本中的事实错误。实验结果表明该方法在知识型问答、代码生成、数学推理和科学文献综述等四个任务中具有良好的效果。

    

    生成式预训练模型的出现方便了高质量文本的合成，但也在识别生成文本中的事实错误方面提出了挑战。本文针对以下问题提出了FacTool框架：（1）越来越多的任务由生成模型处理时，存在着包含事实错误的风险；（2）生成的文本往往很长，缺乏清晰定义的细粒度个体事实；（3）在事实检查过程中缺乏明确的证据。我们在四个不同的任务上进行实验（基于知识的问答、代码生成、数学推理和科学文献综述），证明了该方法的有效性。

    The emergence of generative pre-trained models has facilitated the synthesis of high-quality text, but it has also posed challenges in identifying factual errors in the generated text. In particular: (1) A wider range of tasks now face an increasing risk of containing factual errors when handled by generative models. (2) Generated texts tend to be lengthy and lack a clearly defined granularity for individual facts. (3) There is a scarcity of explicit evidence available during the process of fact checking. With the above challenges in mind, in this paper, we propose FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT). Experiments on four different tasks (knowledge-based QA, code generation, mathematical reasoning, and scientific literature review) show the efficacy of the proposed method.
    
[^69]: Duet: 高效且可扩展的混合神经关系理解

    Duet: efficient and scalable hybriD neUral rElation undersTanding. (arXiv:2307.13494v1 [cs.DB])

    [http://arxiv.org/abs/2307.13494](http://arxiv.org/abs/2307.13494)

    Duet是一种高效且可扩展的混合神经关系理解方法，旨在解决基数估计问题中高成本和难以区分的采样方法，并通过可微分的预测过程改进模型的准确性。

    

    基于概率分布估计的基数估计方法相较于传统方法取得了高精度的估计结果。然而，最先进的方法由于在处理范围查询时使用的采样方法而导致估计成本较高。此外，这种采样方法也使得它们难以区分，因此来自查询工作负载的监督信号很难训练模型以提高基数估计的准确性。在本文中，我们提出了一种新的混合确定性建模方法（Duet）用于基数估计问题，与以前的方法相比，具有更好的效率和可扩展性。Duet可以以更低的时间和内存成本直接估计范围查询的基数，并且以可区分的形式呈现。由于此方法的预测过程是可微分的，我们可以将估计误差较大的查询纳入训练过程以进行改进。

    Cardinality estimation methods based on probability distribution estimation have achieved high-precision estimation results compared to traditional methods. However, the most advanced methods suffer from high estimation costs due to the sampling method they use when dealing with range queries. Also, such a sampling method makes them difficult to differentiate, so the supervision signal from the query workload is difficult to train the model to improve the accuracy of cardinality estimation. In this paper, we propose a new hybrid and deterministic modeling approach (Duet) for the cardinality estimation problem which has better efficiency and scalability compared to previous approaches. Duet allows for direct cardinality estimation of range queries with significantly lower time and memory costs, as well as in a differentiable form. As the prediction process of this approach is differentiable, we can incorporate queries with larger model estimation errors into the training process to addr
    
[^70]: 关于注意力网络学习动态的研究

    On the learning Dynamics of Attention Networks. (arXiv:2307.13421v1 [cs.LG])

    [http://arxiv.org/abs/2307.13421](http://arxiv.org/abs/2307.13421)

    本研究分析了软注意力、硬注意力和潜变量边际似然（LVML）注意力三种注意力模型的学习动态，发现了它们在所选择的片段聚合方式上的显著差异，并解释了分类模型在梯度下降下的演化对最终结果的影响。

    

    注意力模型通常通过优化三个标准损失函数之一来学习，分别称为软注意力、硬注意力和潜变量边际似然（LVML）注意力。这三种范式都是为了达到相同的目标，即找到两个模型：一个“焦点”模型，用于“选择”输入中的正确“片段”，和一个“分类”模型，用于将选定的片段处理成目标标签。然而，它们在所选择的片段聚合方式上存在显著差异，导致了不同的动态和最终结果。我们观察到使用这些范式学习的模型具有独特的特征，并将其解释为在焦点模型固定时，分类模型在梯度下降下的演化所致。我们还在一个简单的设置中分析了这些范式，并推导出梯度流下参数轨迹的闭式表达式。在软注意力损失下，焦点模型在初始化阶段快速改善。

    Attention models are typically learned by optimizing one of three standard loss functions that are variously called -- soft attention, hard attention, and latent variable marginal likelihood (LVML) attention. All three paradigms are motivated by the same goal of finding two models -- a `focus' model that `selects' the right \textit{segment} of the input and a `classification' model that processes the selected segment into the target label. However, they differ significantly in the way the selected segments are aggregated, resulting in distinct dynamics and final results. We observe a unique signature of models learned using these paradigms and explain this as a consequence of the evolution of the classification model under gradient descent when the focus model is fixed. We also analyze these paradigms in a simple setting and derive closed-form expressions for the parameter trajectory under gradient flow. With the soft attention loss, the focus model improves quickly at initialization a
    
[^71]: 层次骨架元-原型对比学习与硬骨架挖掘相结合的无监督人物重新识别方法

    Hierarchical Skeleton Meta-Prototype Contrastive Learning with Hard Skeleton Mining for Unsupervised Person Re-Identification. (arXiv:2307.12917v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2307.12917](http://arxiv.org/abs/2307.12917)

    本文提出了一种无监督的层次骨架元-原型对比学习（Hi-MPC）方法，结合硬骨架挖掘，用于无标签3D骨架的人物重新识别。通过构建层次骨架表示并利用元-原型对比学习进行特征提取和聚类，实现了更多信息丰富的骨架特征的利用。

    

    随着深度传感器和深度学习的快速发展，基于骨架的人物重新识别模型近年来取得了显著进展，并具有许多优势。然而，大多数现有方法仅从身体关节学习单层次的骨架特征，并假设骨架的重要性相等，因此通常无法利用更多来自不同层次（如肢体层次）的信息丰富的骨架特征。此外，这些方法的标签依赖性也限制了它们在学习更一般的骨架表示方面的灵活性。本文提出了一种通用的无监督层次骨架元-原型对比学习（Hi-MPC）方法，结合硬骨架挖掘（HSM）用于无标签3D骨架的人物重新识别。首先，我们构建了骨架的层次表示，以模拟身体关节、组件和肢体层次的粗到细的身体和动作特征。然后，我们使用层次化的元-原型对比学习方法进行特征提取和聚类。

    With rapid advancements in depth sensors and deep learning, skeleton-based person re-identification (re-ID) models have recently achieved remarkable progress with many advantages. Most existing solutions learn single-level skeleton features from body joints with the assumption of equal skeleton importance, while they typically lack the ability to exploit more informative skeleton features from various levels such as limb level with more global body patterns. The label dependency of these methods also limits their flexibility in learning more general skeleton representations. This paper proposes a generic unsupervised Hierarchical skeleton Meta-Prototype Contrastive learning (Hi-MPC) approach with Hard Skeleton Mining (HSM) for person re-ID with unlabeled 3D skeletons. Firstly, we construct hierarchical representations of skeletons to model coarse-to-fine body and motion features from the levels of body joints, components, and limbs. Then a hierarchical meta-prototype contrastive learni
    
[^72]: MediaGPT：用于中国媒体的大型语言模型

    MediaGPT : A Large Language Model For Chinese Media. (arXiv:2307.10930v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.10930](http://arxiv.org/abs/2307.10930)

    本论文提出了MediaGPT，一个用于中国媒体领域的大型语言模型。通过特定领域数据和专家数据的训练，MediaGPT在各种中国媒体任务上优于主流模型，并验证了其重要性。

    

    大型语言模型（LLM）在生成高质量文本和基于大量数据进行预测方面展现出了卓越的能力，包括媒体领域。然而，在实际应用中，媒体的用例与通用LLM应用之间的差异变得越来越明显，特别是在中文方面。本文研究了媒体领域特定LLM与通用LLM之间的独特特点，设计了一系列多样化的任务指令类型以满足领域特定需求，并构建了适用于媒体领域的独特数据集。基于这些工作，我们提出了一种针对中国媒体领域的领域特定LLM，通过领域特定数据和专家的SFT数据进行训练。通过在验证集上进行人工专家评估和强模型评估，本文证明了MediaGPT在各种中国媒体领域任务上优于主流模型，并验证了其重要性。

    Large language models (LLMs) have shown remarkable capabilities in generating high-quality text and making predictions based on large amounts of data, including the media domain. However, in practical applications, the differences between the media's use cases and the general-purpose applications of LLMs have become increasingly apparent, especially Chinese. This paper examines the unique characteristics of media-domain-specific LLMs compared to general LLMs, designed a diverse set of task instruction types to cater the specific requirements of the domain and constructed unique datasets that are tailored to the media domain. Based on these, we proposed MediaGPT, a domain-specific LLM for the Chinese media domain, training by domain-specific data and experts SFT data. By performing human experts evaluation and strong model evaluation on a validation set, this paper demonstrated that MediaGPT outperforms mainstream models on various Chinese media domain tasks and verifies the importance 
    
[^73]: AdjointDPM: 扩散概率模型梯度反向传播的伴随灵敏度方法

    AdjointDPM: Adjoint Sensitivity Method for Gradient Backpropagation of Diffusion Probabilistic Models. (arXiv:2307.10711v1 [cs.CV])

    [http://arxiv.org/abs/2307.10711](http://arxiv.org/abs/2307.10711)

    AdjointDPM是一种新的伴随灵敏度方法，用于扩散概率模型的梯度反向传播，解决了DPM定制化中内存消耗高的问题，并通过解决增强的ODE将损失的梯度反向传播到模型的参数。

    

    现有的定制化方法需要多个参考样例来将预训练的扩散概率模型(DPMs)与用户提供的概念对齐。本文旨在解决当唯一可用的监督是定义在生成内容上的可微度量时的DPM定制化挑战。由于DPM的采样过程涉及对去噪UNet的递归调用，朴素的梯度反向传播需要存储所有迭代的中间状态，导致内存消耗极高。为了解决这个问题，我们提出了一种新的方法AdjointDPM，首先通过求解相应的概率流ODE从扩散模型中生成新样本。然后使用伴随灵敏度方法通过求解另一个增强的ODE将损失的梯度反向传播到模型的参数(包括调制信号、网络权重和初始噪声)。为了减少正向生成和反向传播中的数值误差

    Existing customization methods require access to multiple reference examples to align pre-trained diffusion probabilistic models (DPMs) with user-provided concepts. This paper aims to address the challenge of DPM customization when the only available supervision is a differentiable metric defined on the generated contents. Since the sampling procedure of DPMs involves recursive calls to the denoising UNet, na\"ive gradient backpropagation requires storing the intermediate states of all iterations, resulting in extremely high memory consumption. To overcome this issue, we propose a novel method AdjointDPM, which first generates new samples from diffusion models by solving the corresponding probability-flow ODEs. It then uses the adjoint sensitivity method to backpropagate the gradients of the loss to the models' parameters (including conditioning signals, network weights, and initial noises) by solving another augmented ODE. To reduce numerical errors in both the forward generation and 
    
[^74]: 欺骗性对齐监测

    Deceptive Alignment Monitoring. (arXiv:2307.10569v1 [cs.LG])

    [http://arxiv.org/abs/2307.10569](http://arxiv.org/abs/2307.10569)

    本论文提出了欺骗性对齐监测这一新方向，旨在探讨大型机器学习模型在表面上表现正常，却暗中进行隐藏行为的问题，并提出了新的研究机会。

    

    随着大型机器学习模型的能力不断增长，以及对这些模型的自治权不断扩大，一个新的对手出现了：模型本身。一个模型看似合理地行为，却暗中、微妙地修改其行为以达到别的目的的威胁，通常在AI安全与对齐社区中被称为欺骗性对齐。因此，我们将这个新方向称为欺骗性对齐监测。在这项工作中，我们确定了机器学习不同子领域中的新兴方向，我们认为在不久的将来对欺骗性对齐监测会变得越来越重要且紧密相关，并且我们认为这些领域的进步既提出了长期挑战，也带来了新的研究机会。最后，我们呼吁对抗性机器学习社区更多地参与这些新兴方向的研究。

    As the capabilities of large machine learning models continue to grow, and as the autonomy afforded to such models continues to expand, the spectre of a new adversary looms: the models themselves. The threat that a model might behave in a seemingly reasonable manner, while secretly and subtly modifying its behavior for ulterior reasons is often referred to as deceptive alignment in the AI Safety & Alignment communities. Consequently, we call this new direction Deceptive Alignment Monitoring. In this work, we identify emerging directions in diverse machine learning subfields that we believe will become increasingly important and intertwined in the near future for deceptive alignment monitoring, and we argue that advances in these fields present both long-term challenges and new research opportunities. We conclude by advocating for greater involvement by the adversarial machine learning community in these emerging directions.
    
[^75]: 在量子化的大型语言模型中是否存在新兴能力：一项经验研究

    Do Emergent Abilities Exist in Quantized Large Language Models: An Empirical Study. (arXiv:2307.08072v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.08072](http://arxiv.org/abs/2307.08072)

    本研究旨在研究量子化对大型语言模型中的新兴能力的影响，结果显示在4位量化模型中这些新兴能力仍然存在。

    

    尽管大型语言模型（LLMs）具有出色的性能，但需要大量的计算资源进行部署和使用。为了解决这个问题，已经广泛应用量子化方法来减少LLMs的内存占用以及增加推理速度。然而，一个主要的挑战是低位量子化方法往往会导致性能下降。了解量子化对LLMs能力的影响是重要的。与以往专注于总体性能的研究不同，本研究旨在调查量子化对“新兴能力”的影响，这些能力是区分LLMs和小型语言模型的重要特征。具体而言，我们研究了量子化LLMs中的上下文学习、思维连贯和遵循指令的能力。我们的实证实验表明，这些新兴能力在4位量化模型中仍然存在，而2位模型在这些能力上遇到了严重的性能下降。

    Despite the superior performance, Large Language Models~(LLMs) require significant computational resources for deployment and use. To overcome this issue, quantization methods have been widely applied to reduce the memory footprint of LLMs as well as increasing the inference rate. However, a major challenge is that low-bit quantization methods often lead to performance degradation. It is important to understand how quantization impacts the capacity of LLMs. Different from previous studies focused on overall performance, this work aims to investigate the impact of quantization on \emph{emergent abilities}, which are important characteristics that distinguish LLMs from small language models. Specially, we examine the abilities of in-context learning, chain-of-thought reasoning, and instruction-following in quantized LLMs. Our empirical experiments show that these emergent abilities still exist in 4-bit quantization models, while 2-bit models encounter severe performance degradation on th
    
[^76]: 没有训练就没有收益：重新审视基于Transformer的语言模型的高效训练算法

    No Train No Gain: Revisiting Efficient Training Algorithms For Transformer-based Language Models. (arXiv:2307.06440v1 [cs.LG])

    [http://arxiv.org/abs/2307.06440](http://arxiv.org/abs/2307.06440)

    本论文重新审视了基于Transformer的语言模型的高效训练算法，包括动态架构，批量选择和高效优化器。然而，在使用这些算法预训练时，相对于基线方法，它们的训练、验证和下游收益消失了。同时，论文提出了一个评估协议来进行计算，并释放了代码来促进高效训练的研究。

    

    近年来，训练Transformer-based语言模型所需的计算量急剧增加。这一趋势促使研究者们开展了针对高效训练算法的研究，旨在比标准训练更快地改善训练、验证和下游性能。在这项工作中，我们重新审视了三类这样的算法：动态架构（层叠、层丢弃）、批量选择（选择性反向传播、RHO损失）和高效优化器（Lion、Sophia）。当使用这些方法在固定计算预算下对BERT和T5进行预训练时，我们发现它们的训练、验证和下游收益相对于一个具有完全衰减学习率的基线而言会消失。我们定义了一个评估协议，可以通过将所有计算时间映射到一个称为参考系统时间的参考机器上，在任意机器上进行计算。我们讨论了我们提出的协议的局限性，并发布了我们的代码，以鼓励对高效训练的严格研究。

    The computation necessary for training Transformer-based language models has skyrocketed in recent years. This trend has motivated research on efficient training algorithms designed to improve training, validation, and downstream performance faster than standard training. In this work, we revisit three categories of such algorithms: dynamic architectures (layer stacking, layer dropping), batch selection (selective backprop, RHO loss), and efficient optimizers (Lion, Sophia). When pre-training BERT and T5 with a fixed computation budget using such methods, we find that their training, validation, and downstream gains vanish compared to a baseline with a fully-decayed learning rate. We define an evaluation protocol that enables computation to be done on arbitrary machines by mapping all computation time to a reference machine which we call reference system time. We discuss the limitations of our proposed protocol and release our code to encourage rigorous research in efficient training p
    
[^77]: SAS视频问答：自适应采样用于高效视频问答

    SAS Video-QA: Self-Adaptive Sampling for Efficient Video Question-Answering. (arXiv:2307.04192v1 [cs.CV])

    [http://arxiv.org/abs/2307.04192](http://arxiv.org/abs/2307.04192)

    SAS视频问答通过自适应采样策略解决了视频问答中的问题，提高了效率和准确性

    

    视频问答是视频理解领域的一项基础任务。尽管当前的视觉-语言模型(VLMs)配备了视频变换器(Video Transformers)，实现了时间建模并取得了优秀的结果，但代价是巨大的计算能力，因此在实时应用场景中过于昂贵。一种经济的解决方法是只对视频的一小部分帧进行采样，来代表视频的主要内容，并在这些采样帧上调整图像-文本模型。最近的视频理解模型通常随机采样一组帧或片段，而不考虑它们的内部关联性和与问题的相关性。我们认为这种无目标的采样可能会遗漏可以推导出正确答案的关键帧，在采样稀疏程度增加时，情况会变得更糟，而随着视频长度的增加，采样稀疏程度也会增加。为了解决这个问题，我们提出了两种帧采样策略，分别是

    Video question--answering is a fundamental task in the field of video understanding. Although current vision--language models (VLMs) equipped with Video Transformers have enabled temporal modeling and yielded superior results, they are at the cost of huge computational power and thus too expensive to deploy in real-time application scenarios. An economical workaround only samples a small portion of frames to represent the main content of that video and tune an image--text model on these sampled frames. Recent video understanding models usually randomly sample a set of frames or clips, regardless of internal correlations between their visual contents, nor their relevance to the problem. We argue that such kinds of aimless sampling may omit the key frames from which the correct answer can be deduced, and the situation gets worse when the sampling sparsity increases, which always happens as the video lengths increase. To mitigate this issue, we propose two frame sampling strategies, namel
    
[^78]: 无导数的权重空间集成

    Derivative Free Weight-space Ensembling. (arXiv:2307.03506v1 [cs.CL])

    [http://arxiv.org/abs/2307.03506](http://arxiv.org/abs/2307.03506)

    本文引入了一种新的无导数权重空间集成方法（DFWE），用于开放域对话的少样本任务传递。通过在几个不同的知识库的角度上对专家模型进行微调，并使用无梯度优化算法进行线性插值，我们有效地找到了一个好的模型权重插值，从而在FETA-Friends上超过了标准的预训练-微调方法。

    

    最近的研究表明，在两个专门的语言模型的权重之间插值可以在任务之间传递知识，但很少有人探索在两个以上模型之间插值，每个模型都有一个不同的知识库。在本文中，我们引入了一种新的无导数权重空间集成方法（DFWE），用于开放域对话的少样本任务传递。我们的框架创建了一组多样化的专家语言模型，这些模型是使用预定义的一组源任务进行训练的。接下来，我们对每个专家模型在目标任务上进行微调，从几个不同的知识库的角度来处理目标任务。最后，我们使用无梯度优化算法在模型权重之间进行线性插值，以高效地找到一个好的插值权重。我们在FETA-Friends上展示了该方法的有效性，优于标准的预训练-微调方法。

    Recent work suggests that interpolating between the weights of two specialized language models can transfer knowledge between tasks in a way that multi-task learning cannot. However, very few have explored interpolation between more than two models, where each has a distinct knowledge base. In this paper, we introduce Derivative Free Weight-space Ensembling (DFWE), a new few-sample task transfer approach for open-domain dialogue. Our framework creates a set of diverse expert language models trained using a predefined set of source tasks. Next, we finetune each of the expert models on the target task, approaching the target task from several distinct knowledge bases. Finally, we linearly interpolate between the model weights using a gradient-free-optimization algorithm, to efficiently find a good interpolation weighting. We demonstrate the effectiveness of the method on FETA-Friends outperforming the standard pretrain-finetune approach.
    
[^79]: DifFSS: 一种用于小样本语义分割的扩散模型

    DifFSS: Diffusion Model for Few-Shot Semantic Segmentation. (arXiv:2307.00773v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2307.00773](http://arxiv.org/abs/2307.00773)

    DifFSS是一种利用扩散模型改进小样本语义分割性能的方法，通过生成多样化的辅助支持图像，而不需要修改网络结构，从而显著提高最先进的小样本语义分割模型的性能。

    

    扩散模型在图像生成中表现出色。虽然已经提出了各种结构不同的小样本语义分割模型，但是性能的改进已经达到了瓶颈。本文提出了一种首次利用扩散模型用于小样本语义分割任务的方法，称为DifFSS。DifFSS是一种新颖的小样本语义分割范式，可以在不修改网络结构的情况下显著提高最先进的小样本语义分割模型的性能。具体来说，我们利用扩散模型的强大生成能力，通过使用语义掩码、涂抹或软HED边界的支持图像作为控制条件，生成多样化的辅助支持图像。这个生成过程模拟了查询图像类别内的多样性，如颜色、纹理变化和光照等。因此，小样本语义分割模型可以参考更多多样的支持图像，产生更具鲁棒性的表示，从而实现一致的性能改进。

    Diffusion models have demonstrated excellent performance in image generation. Although various few-shot semantic segmentation (FSS) models with different network structures have been proposed, performance improvement has reached a bottleneck. This paper presents the first work to leverage the diffusion model for FSS task, called DifFSS. DifFSS, a novel FSS paradigm, can further improve the performance of the state-of-the-art FSS models by a large margin without modifying their network structure. Specifically, we utilize the powerful generation ability of diffusion models to generate diverse auxiliary support images by using the semantic mask, scribble or soft HED boundary of the support image as control conditions. This generation process simulates the variety within the class of the query image, such as color, texture variation, lighting, $etc$. As a result, FSS models can refer to more diverse support images, yielding more robust representations, thereby achieving a consistent improv
    
[^80]: FedNoisy: 分布式噪声标签学习基准测试

    FedNoisy: Federated Noisy Label Learning Benchmark. (arXiv:2306.11650v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.11650](http://arxiv.org/abs/2306.11650)

    FedNoisy是第一个标准化的联合噪声标签学习基准测试，并提供20个基本设置和标准化的仿真流程，以帮助研究人员探索联合学习中噪声标签的影响。

    

    联合学习已经因为无需对来自客户端的敏感数据进行聚合而变得受欢迎。但是，数据隔离的分布式和孤立性可能会受到数据质量的复杂性的影响，使其更容易受到噪声标签的干扰。许多努力都致力于在集中式或联合式环境中防御噪声标签的负面影响。然而，缺乏一个全面考虑各种典型联合学习场景中噪声标签影响的基准测试。在这项工作中，我们提供了第一个标准化的基准测试，可以帮助研究人员充分探索潜在的联合噪声设置。此外，我们进行了全面的实验，探索这些数据设置的特性，并揭示了联合学习中的挑战性场景，这可能指导未来的方法开发。我们强调我们基准测试中提出的20个基本设置，适用于5个以上的数据集，并提供了标准化的仿真流程。

    Federated learning has gained popularity for distributed learning without aggregating sensitive data from clients. But meanwhile, the distributed and isolated nature of data isolation may be complicated by data quality, making it more vulnerable to noisy labels. Many efforts exist to defend against the negative impacts of noisy labels in centralized or federated settings. However, there is a lack of a benchmark that comprehensively considers the impact of noisy labels in a wide variety of typical FL settings. In this work, we serve the first standardized benchmark that can help researchers fully explore potential federated noisy settings. Also, we conduct comprehensive experiments to explore the characteristics of these data settings and unravel challenging scenarios on the federated noisy label learning, which may guide method development in the future. We highlight the 20 basic settings for more than 5 datasets proposed in our benchmark and standardized simulation pipeline for federa
    
[^81]: 向可解释的、语言无关的LLMs迈进：大规模语言符号逆向工程

    Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse Engineering of Language at Scale. (arXiv:2306.00017v1 [cs.CL])

    [http://arxiv.org/abs/2306.00017](http://arxiv.org/abs/2306.00017)

    本文提出结合符号表示和自下而上的逆向工程的方法，解决大规模语言模型在真正语言理解上的局限性，实现可解释的、语言无关的LLMs。

    

    大型语言模型（LLMs）取得了一个里程碑，无可否认地改变了人工智能（AI）中许多信仰。然而，当涉及真正的语言理解时，这些LLM的许多限制仍然存在，这些限制是深度神经网络底层架构的副产品。此外，由于它们的亚符号性质，这些模型获得有关语言如何运作的任何知识都将被埋在数十亿个微特征（权重）中，其中没有一个单独的特征有意义，使得这些模型无法解释。为了解决这些限制，我们建议将符号表示的强度与我们认为是LLMs成功的关键结合起来，即在规模上成功地进行自下而上的语言逆向工程。因此，我们主张在符号设置下对语言进行自下而上的逆向工程。一些作者提出了这个项目的提示，我们将进行详细讨论。

    Large language models (LLMs) have achieved a milestone that undenia-bly changed many held beliefs in artificial intelligence (AI). However, there remains many limitations of these LLMs when it comes to true language understanding, limitations that are a byproduct of the under-lying architecture of deep neural networks. Moreover, and due to their subsymbolic nature, whatever knowledge these models acquire about how language works will always be buried in billions of microfeatures (weights), none of which is meaningful on its own, making such models hopelessly unexplainable. To address these limitations, we suggest com-bining the strength of symbolic representations with what we believe to be the key to the success of LLMs, namely a successful bottom-up re-verse engineering of language at scale. As such we argue for a bottom-up reverse engineering of language in a symbolic setting. Hints on what this project amounts to have been suggested by several authors, and we discuss in some detail
    
[^82]: 模型扩散中的无标注文本实际上是卡通风格生成器

    Null-text Guidance in Diffusion Models is Secretly a Cartoon-style Creator. (arXiv:2305.06710v1 [cs.CV])

    [http://arxiv.org/abs/2305.06710](http://arxiv.org/abs/2305.06710)

    本文发现，模型扩散中的无标注文本实际上是一个能够生成卡通风格图片的工具。通过简单地扰动无标注文本指导，这一功能得以实现。回滚扰动能够将生成的图像有效转换成卡通图像，而图像扰动则能够产生高保真度、多样性的卡通图像。

    

    无分类器指导是扩散模型中被广泛采用的一种有效的采样技术。其主要思想是在文本指导方向上对模型进行外推，并远离无标注文本指导。在本文中，我们展示了模型扩散中的无标注文本实际上是一个卡通风格生成器，即通过简单地扰动无标注文本指导就可以有效地将生成的图像转换成卡通图像。具体地，我们提出了两种扰动方法：回滚扰动（Back-D）和图像扰动（Image-D），用于构造在采样过程中用于预测无标注文本指导和文本指导的嘈杂图像之间的错位。Back-D通过通过将$x_t$替换为$x_{t+\Delta t}$来改变无标注嘈杂图像的噪声水平从而实现卡通化。Image-D则通过产生高保真度、多样性的卡通图像。

    Classifier-free guidance is an effective sampling technique in diffusion models that has been widely adopted. The main idea is to extrapolate the model in the direction of text guidance and away from null-text guidance. In this paper, we demonstrate that null-text guidance in diffusion models is secretly a cartoon-style creator, i.e., the generated images can be efficiently transformed into cartoons by simply perturbing the null-text guidance. Specifically, we proposed two disturbance methods, i.e., Rollback disturbance (Back-D) and Image disturbance (Image-D), to construct misalignment between the noisy images used for predicting null-text guidance and text guidance (subsequently referred to as \textbf{null-text noisy image} and \textbf{text noisy image} respectively) in the sampling process. Back-D achieves cartoonization by altering the noise level of null-text noisy image via replacing $x_t$ with $x_{t+\Delta t}$. Image-D, alternatively, produces high-fidelity, diverse cartoons by 
    
[^83]: 数据增强中基于不确定性的轨迹截断在离线强化学习中的应用

    Uncertainty-driven Trajectory Truncation for Data Augmentation in Offline Reinforcement Learning. (arXiv:2304.04660v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2304.04660](http://arxiv.org/abs/2304.04660)

    本研究提出了一种基于不确定性的轨迹截断方法（TATU），用于解决模型驱动的离线强化学习中生成样本不可靠的问题。实验证明TATU相较于其他方法表现优越。

    

    模型驱动的离线强化学习算法通常能够从固定大小的数据集中学到好的策略，甚至一些质量较差的数据集。然而，生成的合成样本是否可靠无法得到保证（例如，一些合成样本可能位于静态数据集支持区域之外）。为了解决这个问题，我们提出了具有不确定性的轨迹截断（TATU）方法，如果累积不确定性超过阈值，则自适应截断合成轨迹。我们理论上证明了TATU的性能边界以证明其优势。为了在实证上显示出TATU的优势，我们首先将其与两个经典的模型驱动离线强化学习算法MOPO和COMBO相结合。此外，我们还将TATU与多个现成的无模型离线强化学习算法（例如BCQ）进行整合。在D4RL基准测试上的实验结果表明，TATU的表现优越。

    Equipped with the trained environmental dynamics, model-based offline reinforcement learning (RL) algorithms can often successfully learn good policies from fixed-sized datasets, even some datasets with poor quality. Unfortunately, however, it can not be guaranteed that the generated samples from the trained dynamics model are reliable (e.g., some synthetic samples may lie outside of the support region of the static dataset). To address this issue, we propose Trajectory Truncation with Uncertainty (TATU), which adaptively truncates the synthetic trajectory if the accumulated uncertainty along the trajectory is too large. We theoretically show the performance bound of TATU to justify its benefits. To empirically show the advantages of TATU, we first combine it with two classical model-based offline RL algorithms, MOPO and COMBO. Furthermore, we integrate TATU with several off-the-shelf model-free offline RL algorithms, e.g., BCQ. Experimental results on the D4RL benchmark show that TATU
    
[^84]: 稳定签名：将水印扎根于潜在扩散模型中

    The Stable Signature: Rooting Watermarks in Latent Diffusion Models. (arXiv:2303.15435v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.15435](http://arxiv.org/abs/2303.15435)

    本文介绍了一种结合图像水印和潜在扩散模型的方法，使所有生成的图像都能隐藏一个不可见的水印，该方法在各种生成任务中表现出良好的隐形性和鲁棒性。

    

    生成图像建模可以实现各种应用，但也引发了关于负责任部署的道德关注。本文介绍了一种结合图像水印和潜在扩散模型的主动策略。其目标是使所有生成的图像都隐藏一个不可见的水印，以供将来检测和/或识别。该方法通过在二进制签名的条件下快速微调图像生成器的潜在解码器来实现。预训练的水印提取器可以从任何生成的图像中恢复隐藏的签名，然后通过统计测试来确定它是否来自生成模型。我们评估了水印在各种生成任务上的隐形性和鲁棒性，结果表明稳定签名在图像被修改后仍然有效。例如，当将从文本提示生成的图像裁剪保留10%的内容后，以10$^{-6}$以下的错误率下，能以90%以上的准确率检测出图像的源头。

    Generative image modeling enables a wide range of applications but raises ethical concerns about responsible deployment. This paper introduces an active strategy combining image watermarking and Latent Diffusion Models. The goal is for all generated images to conceal an invisible watermark allowing for future detection and/or identification. The method quickly fine-tunes the latent decoder of the image generator, conditioned on a binary signature. A pre-trained watermark extractor recovers the hidden signature from any generated image and a statistical test then determines whether it comes from the generative model. We evaluate the invisibility and robustness of the watermarks on a variety of generation tasks, showing that Stable Signature works even after the images are modified. For instance, it detects the origin of an image generated from a text prompt, then cropped to keep $10\%$ of the content, with $90$+$\%$ accuracy at a false positive rate below 10$^{-6}$.
    
[^85]: 软件开发教育中的生成式 AI 助手

    Generative AI Assistants in Software Development Education. (arXiv:2303.13936v1 [cs.SE])

    [http://arxiv.org/abs/2303.13936](http://arxiv.org/abs/2303.13936)

    本文探讨了当前软件开发行业采用生成式 AI（GAI）助手进行软件开发的现状和挑战，提出了未来软件开发教育的愿景和教学建议。

    

    软件开发行业正在进行一次潜在的颠覆性的范式变革——采用生成式 AI（GAI）助手进行软件开发。虽然 AI 已经在软件工程的各个领域中被使用，但是像 GitHub Copilot 和 ChatGPT 这样的 GAI 技术已经激发了许多人的想象力（和恐惧）。尽管目前尚不清楚该行业将如何采用和适应这些技术，但微软（GitHub、必应）和谷歌（Bard）等大型软件公司将这些技术整合到更广泛的行业中的举动是明确的意图和方向。我们与行业专业人士进行了探索性访谈，以了解当前的实践和挑战，将其纳入我们对未来软件开发教育的愿景，并提出了一些教学建议。

    The software development industry is amid another potentially disruptive paradigm change--adopting the use of generative AI (GAI) assistants for software development. Whilst AI is already used in various areas of software engineering, GAI technologies, such as GitHub Copilot and ChatGPT, have ignited the imaginations (and fears) of many people. Whilst it is unclear how the industry will adopt and adapt to these technologies, the move to integrate these technologies into the wider industry by large software companies, such as Microsoft (GitHub, Bing) and Google (Bard), is a clear indication of intent and direction. We performed exploratory interviews with industry professionals to understand current practices and challenges, which we incorporate into our vision of a future of software development education and make some pedagogical recommendations.
    
[^86]: 量化和建模多模态交互：一种信息分解框架

    Quantifying & Modeling Multimodal Interactions: An Information Decomposition Framework. (arXiv:2302.12247v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.12247](http://arxiv.org/abs/2302.12247)

    通过引入信息分解框架，我们提供了一种量化和建模多模态交互的方法，通过PID统计量来度量输入模态与输出任务之间的冗余度、独特性和协同性，并引入了两个新的PID统计估计器。

    

    对于解决多模态任务所需的交互如何进行量化？最适合捕捉这些交互的多模态模型是什么？为了回答这些问题，我们提出了一种信息论方法来量化输入模态与输出任务之间的冗余度、独特性和协同性。我们将这三个衡量标准称为多模态分布（或简称PID）的PID统计量，并引入了两个新的PID统计估计器，适用于高维分布。为了验证PID估计，我们在已知PID的合成数据集和大规模多模态基准测试集上进行了大量实验。

    The recent explosion of interest in multimodal applications has resulted in a wide selection of datasets and methods for representing and integrating information from different modalities. Despite these empirical advances, there remain fundamental research questions: How can we quantify the interactions that are necessary to solve a multimodal task? Subsequently, what are the most suitable multimodal models to capture these interactions? To answer these questions, we propose an information-theoretic approach to quantify the degree of redundancy, uniqueness, and synergy relating input modalities with an output task. We term these three measures as the PID statistics of a multimodal distribution (or PID for short), and introduce two new estimators for these PID statistics that scale to high-dimensional distributions. To validate PID estimation, we conduct extensive experiments on both synthetic datasets where the PID is known and on large-scale multimodal benchmarks where PID estimations
    
[^87]: 使用级联LSTM网络的一种新型基于深度强化学习的自动股票交易系统

    A Novel Deep Reinforcement Learning Based Automated Stock Trading System Using Cascaded LSTM Networks. (arXiv:2212.02721v2 [q-fin.CP] UPDATED)

    [http://arxiv.org/abs/2212.02721](http://arxiv.org/abs/2212.02721)

    本文提出了一种使用级联LSTM网络的基于深度强化学习的自动股票交易系统，通过对股票数据进行特征提取和策略函数训练，我们的模型在累积回报和夏普比率方面优于基准模型，特别在中国股市这一新兴市场中表现更为突出。

    

    越来越多的股票交易策略是使用深度强化学习（DRL）算法构建的，但是DRL方法最初在游戏界广泛使用，直接适应金融数据的低信噪比和不均匀性会导致性能不足。为了捕捉隐藏的信息，本文提出了一种使用级联LSTM的DRL股票交易系统，首先使用LSTM从股票日常数据中提取时间序列特征，然后将提取的特征馈给代理进行训练，同时强化学习中的策略函数也使用另一个LSTM进行训练。在美国市场的DJI和中国股市的SSE50上的实验证明，我们的模型在累积回报和夏普比率方面优于以前的基准模型，并且在中国股市这一新兴市场中优势更为显著。这表明我们提出的方法是一种有前景的构建自动股票交易系统的方式。

    More and more stock trading strategies are constructed using deep reinforcement learning (DRL) algorithms, but DRL methods originally widely used in the gaming community are not directly adaptable to financial data with low signal-to-noise ratios and unevenness, and thus suffer from performance shortcomings. In this paper, to capture the hidden information, we propose a DRL based stock trading system using cascaded LSTM, which first uses LSTM to extract the time-series features from stock daily data, and then the features extracted are fed to the agent for training, while the strategy functions in reinforcement learning also use another LSTM for training. Experiments in DJI in the US market and SSE50 in the Chinese stock market show that our model outperforms previous baseline models in terms of cumulative returns and Sharp ratio, and this advantage is more significant in the Chinese stock market, a merging market. It indicates that our proposed method is a promising way to build a aut
    
[^88]: 未知动态马尔可夫跳变线性系统的形式化控制器合成

    Formal Controller Synthesis for Markov Jump Linear Systems with Uncertain Dynamics. (arXiv:2212.00679v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2212.00679](http://arxiv.org/abs/2212.00679)

    本文介绍了一种方法，用于合成马尔可夫跳变线性系统（MJLS）的控制器，以确保满足概率计算树逻辑（PCTL）公式，对于转移概率未知或已知但存在一定的区间的问题提出了解决方案。

    

    在安全关键场景中，对于控制器的自动化合成可以确保系统的正确性至关重要。然而，混合特性和随机或未知的行为使得合成控制器的问题变得具有挑战性。本论文提出了一种方法，用于合成马尔可夫跳变线性系统（MJLS）的控制器，这是一类离散时钟模型的控制器，用于解决这些系统的安全问题，以确保满足概率计算树逻辑（PCTL）公式。一个MJLS由一组有限的随机线性动态和这些动态之间的离散跳变组成，这些跳变由一个马尔可夫决策过程（MDP）来管理。我们考虑了这个MDP的转移概率未知或已知但存在一定的区间。我们的方法基于一个有限状态抽象，捕捉了MJLS的离散（模式跳跃）和连续（随机线性）行为。我们将这个抽象形式化为一个区间MDP（iMDP），然后计算了状态转移区间。

    Automated synthesis of provably correct controllers for cyber-physical systems is crucial for deployment in safety-critical scenarios. However, hybrid features and stochastic or unknown behaviours make this problem challenging. We propose a method for synthesising controllers for Markov jump linear systems (MJLSs), a class of discrete-time models for cyber-physical systems, so that they certifiably satisfy probabilistic computation tree logic (PCTL) formulae. An MJLS consists of a finite set of stochastic linear dynamics and discrete jumps between these dynamics that are governed by a Markov decision process (MDP). We consider the cases where the transition probabilities of this MDP are either known up to an interval or completely unknown. Our approach is based on a finite-state abstraction that captures both the discrete (mode-jumping) and continuous (stochastic linear) behaviour of the MJLS. We formalise this abstraction as an interval MDP (iMDP) for which we compute intervals of tra
    
[^89]: FsaNet: 频率自注意力用于语义分割

    FsaNet: Frequency Self-attention for Semantic Segmentation. (arXiv:2211.15595v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.15595](http://arxiv.org/abs/2211.15595)

    FsaNet是一种用于语义分割的新型自注意机制，通过在不同频段上进行个性化处理，可以在保留边缘的同时促进对象内的相似性。通过消融研究表明，即使不重新训练网络，低频自注意力也可以达到接近或更好的性能。频率自注意力还简化了令牌映射和令牌混合阶段，具有较低的计算复杂性。

    

    考虑到图像的频谱特性，我们提出了一种新的带有高度降低计算复杂性的自注意机制。为了更好地保留边缘并促进对象内的相似性，我们提出了在不同频段上个性化处理的方法。特别是，我们研究了仅在低频分量上进行处理的情况。通过消融研究，我们展示了即使在不重新训练网络的情况下，低频自注意力也可以达到非常接近甚至更好的性能。因此，我们设计并嵌入了新的即插即用模块到CNN网络的头部，我们将其称为FsaNet。频率自注意力1）仅需要几个低频系数作为输入，2）在数学上可以等效于具有线性结构的空间域自注意力，3）同时简化了令牌映射（$1\times1$卷积）阶段和令牌混合阶段。我们展示了频率自注意力只需要87

    Considering the spectral properties of images, we propose a new self-attention mechanism with highly reduced computational complexity, up to a linear rate. To better preserve edges while promoting similarity within objects, we propose individualized processes over different frequency bands. In particular, we study a case where the process is merely over low-frequency components. By ablation study, we show that low frequency self-attention can achieve very close or better performance relative to full frequency even without retraining the network. Accordingly, we design and embed novel plug-and-play modules to the head of a CNN network that we refer to as FsaNet. The frequency self-attention 1) requires only a few low frequency coefficients as input, 2) can be mathematically equivalent to spatial domain self-attention with linear structures, 3) simplifies token mapping ($1\times1$ convolution) stage and token mixing stage simultaneously. We show that frequency self-attention requires $87
    
[^90]: 利用遥感和机器学习实现早期检测树皮甲虫攻击：一项综述

    Early Detection of Bark Beetle Attack Using Remote Sensing and Machine Learning: A Review. (arXiv:2210.03829v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.03829](http://arxiv.org/abs/2210.03829)

    本文综述了早期检测树皮甲虫攻击的过去和现有进展，重点关注了使用遥感和机器学习方法的优势和劣势，以及提供了有关树皮甲虫物种、攻击阶段、寄主树木、研究区域、遥感平台与传感器、光谱分辨率、光谱特征、机器学习方法和深度学习网络的知识。

    

    本文全面回顾了早期检测树皮甲虫引起的树木死亡方面的过去和现有进展，从树皮甲虫与寄主之间的相互作用、遥感和机器学习/深度学习三个主要角度进行了总结。与以往的努力相反，本综述包括了所有遥感系统，并强调了机器学习/深度学习方法来研究它们的优势和劣势。我们根据多光谱或高光谱分析解析了现有文献，并从树皮甲虫物种和攻击阶段，重点关注攻击的早期阶段、寄主树木、研究区域、遥感平台和传感器、光谱/空间/时间分辨率、光谱特征、光谱植被指数（SVIs）、机器学习方法、学习方案、任务类别、模型、算法、类别/簇、特征和深度学习网络与架构方面提取知识。尽管基于深度学习的方法和随机森林（RF）算法显示出有希望的结果，突出了它们在可见光和热红外等波段上检测微小变化的潜力。

    This paper provides a comprehensive review of past and current advances in the early detection of bark beetle-induced tree mortality from three primary perspectives: bark beetle & host interactions, RS, and ML/DL. In contrast to prior efforts, this review encompasses all RS systems and emphasizes ML/DL methods to investigate their strengths and weaknesses. We parse existing literature based on multi- or hyper-spectral analyses and distill their knowledge based on: bark beetle species & attack phases with a primary emphasis on early stages of attacks, host trees, study regions, RS platforms & sensors, spectral/spatial/temporal resolutions, spectral signatures, spectral vegetation indices (SVIs), ML approaches, learning schemes, task categories, models, algorithms, classes/clusters, features, and DL networks & architectures. Although DL-based methods and the random forest (RF) algorithm showed promising results, highlighting their potential to detect subtle changes across visible, therma
    
[^91]: FedIIC: 面向类别不平衡医学图像分类的鲁棒联邦学习

    FedIIC: Towards Robust Federated Learning for Class-Imbalanced Medical Image Classification. (arXiv:2206.13803v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.13803](http://arxiv.org/abs/2206.13803)

    提出了一种名为FedIIC的隐私保护联邦学习方法，从特征学习和分类器学习两个角度解决了类别不平衡的医学图像分类问题。

    

    联邦学习（FL），在不泄露隐私的情况下从分散数据中训练深度模型，最近在医学图像计算中展现出巨大潜力。然而，考虑到医学数据中普遍存在的类别不平衡问题，FL在性能上可能会出现下降，特别是对于少数类（如罕见疾病）。现有方法主要集中于训练一个平衡分类器以消除类别先验偏差，但忽视了探索更好的特征表示以促进分类性能。本文提出了一种名为FedIIC的隐私保护FL方法，从特征学习和分类器学习两个角度解决了类别不平衡问题。在特征学习方面，设计了两级对比学习来提取更好的与不平衡数据相关的类别特定特征。在分类器学习方面，根据实时难度和类别先验动态设置每类间隔，帮助模型平等地学习各个类别。

    Federated learning (FL), training deep models from decentralized data without privacy leakage, has shown great potential in medical image computing recently. However, considering the ubiquitous class imbalance in medical data, FL can exhibit performance degradation, especially for minority classes (e.g. rare diseases). Existing methods towards this problem mainly focus on training a balanced classifier to eliminate class prior bias among classes, but neglect to explore better representation to facilitate classification performance. In this paper, we present a privacy-preserving FL method named FedIIC to combat class imbalance from two perspectives: feature learning and classifier learning. In feature learning, two levels of contrastive learning are designed to extract better class-specific features with imbalanced data in FL. In classifier learning, per-class margins are dynamically set according to real-time difficulty and class priors, which helps the model learn classes equally. Exp
    
[^92]: 深度图像恢复和增强中的先验知识：一次综述

    Priors in Deep Image Restoration and Enhancement: A Survey. (arXiv:2206.02070v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.02070](http://arxiv.org/abs/2206.02070)

    这篇论文是对深度图像恢复和增强中先验知识最新进展的综述，包括理论分析、分类、讨论和问题总结。

    

    图像恢复和增强是通过去除噪声、模糊和分辨率降低等降质来改善图像质量的过程。深度学习（DL）最近被应用于图像恢复和增强。由于其逆问题的特性，许多研究已经探索了先验知识来帮助训练深度神经网络（DNNs）。然而，迄今为止，先验知识的重要性尚未被系统地研究和分析。因此，本文是第一次对深度图像恢复和增强的先验知识的最新进展进行全面概述的研究。我们的工作包括五个主要内容：（1）对深度图像恢复和增强的先验知识进行理论分析；（2）对DL方法中常用的先验知识进行分层和结构化分类；（3）对每个先验知识的原理、潜力和应用进行深入讨论；（4）通过重点突出关键问题的总结

    Image restoration and enhancement is a process of improving the image quality by removing degradations, such as noise, blur, and resolution degradation. Deep learning (DL) has recently been applied to image restoration and enhancement. Due to its ill-posed property, plenty of works have been explored priors to facilitate training deep neural networks (DNNs). However, the importance of priors has not been systematically studied and analyzed by far in the research community. Therefore, this paper serves as the first study that provides a comprehensive overview of recent advancements in priors for deep image restoration and enhancement. Our work covers five primary contents: (1) A theoretical analysis of priors for deep image restoration and enhancement; (2) A hierarchical and structural taxonomy of priors commonly used in the DL-based methods; (3) An insightful discussion on each prior regarding its principle, potential, and applications; (4) A summary of crucial problems by highlighting
    
[^93]: 推荐系统中的公平性：基础、方法和应用

    Fairness in Recommendation: Foundations, Methods and Applications. (arXiv:2205.13619v5 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2205.13619](http://arxiv.org/abs/2205.13619)

    这篇论文对推荐系统中的公平性问题进行了系统调查，针对推荐过程中可能出现的数据或算法偏见，提供了一些方法和应用来提升推荐中的公平性。

    

    作为机器学习最普遍的应用之一，推荐系统在辅助人类决策中起着重要作用。用户的满意度和平台的利益与生成的推荐结果的质量密切相关。然而，作为一个高度数据驱动的系统，推荐系统可能受到数据或算法偏见的影响，从而产生不公平的结果，这可能削弱系统的可信赖性。因此，在推荐设置中解决潜在的不公平问题至关重要。最近，对推荐系统的公平性考虑引起了越来越多的关注，涉及提升推荐中的公平性的方法越来越多。然而，这些研究相对零散且缺乏系统化整理，因此对于新研究人员来说难以深入领域。这促使我们对推荐中现有公平性作品进行系统调查。

    As one of the most pervasive applications of machine learning, recommender systems are playing an important role on assisting human decision making. The satisfaction of users and the interests of platforms are closely related to the quality of the generated recommendation results. However, as a highly data-driven system, recommender system could be affected by data or algorithmic bias and thus generate unfair results, which could weaken the reliance of the systems. As a result, it is crucial to address the potential unfairness problems in recommendation settings. Recently, there has been growing attention on fairness considerations in recommender systems with more and more literature on approaches to promote fairness in recommendation. However, the studies are rather fragmented and lack a systematic organization, thus making it difficult to penetrate for new researchers to the domain. This motivates us to provide a systematic survey of existing works on fairness in recommendation. This
    
[^94]: 强健的数量感知聚合方法用于联邦学习

    Robust Quantity-Aware Aggregation for Federated Learning. (arXiv:2205.10848v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2205.10848](http://arxiv.org/abs/2205.10848)

    本文提出了一种针对联邦学习的强健的数量感知聚合算法，名为FedRA，能够在聚合模型时考虑本地数据的数量，并能够抵御数量增强攻击。

    

    联邦学习（FL）是一种能够使多个客户端协同训练模型而不共享本地数据的隐私保护机器学习框架。然而，传统的FL面临严重的安全性和鲁棒性问题，例如，恶意的客户端可以污染模型更新，并同时虚报大量以放大其在模型聚合中的影响。现有的FL防御方法，虽然都能处理恶意的模型更新，但要么将所有数量视为良性，要么简单地忽略/截断所有客户端的数量。前者容易受到数量增强攻击的影响，而后者会导致子优的性能，因为不同客户端上的本地数据通常具有显着不同的大小。在本文中，我们提出了一种 robust quantity-aware aggregation algorithm for federated learning (FedRA)，通过对本地数据数量的感知来执行聚合，并能够抵御数量增强攻击。

    Federated learning (FL) enables multiple clients to collaboratively train models without sharing their local data, and becomes an important privacy-preserving machine learning framework. However, classical FL faces serious security and robustness problem, e.g., malicious clients can poison model updates and at the same time claim large quantities to amplify the impact of their model updates in the model aggregation. Existing defense methods for FL, while all handling malicious model updates, either treat all quantities benign or simply ignore/truncate the quantities of all clients. The former is vulnerable to quantity-enhanced attack, while the latter leads to sub-optimal performance since the local data on different clients is usually in significantly different sizes. In this paper, we propose a robust quantity-aware aggregation algorithm for federated learning, called FedRA, to perform the aggregation with awareness of local data quantities while being able to defend against quantity
    
[^95]: MICDIR: 使用UNetMSS和自构建图潜变量的多尺度反向一致可变形图像配准

    MICDIR: Multi-scale Inverse-consistent Deformable Image Registration using UNetMSS with Self-Constructing Graph Latent. (arXiv:2203.04317v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2203.04317](http://arxiv.org/abs/2203.04317)

    本文提出了MICDIR方法，在多尺度上使用UNetMSS和自构建图潜变量，用于解决医学图像配准中存在的全局依赖性和大形变的问题。

    

    图像配准是将不同图像带入到一个共同坐标系的过程，广泛应用于计算机视觉的各个领域，如遥感、图像检索和医学成像。深度学习技术已成功应用于解决各种复杂的医学图像处理问题，包括医学图像配准。多年来，已提出了几种使用深度学习的图像配准技术。例如Voxelmorph等可变形图像配准技术，成功捕捉到更细微的变化并提供更平滑的变形。然而，Voxelmorph、ICNet和FIRE等方法并没有明确编码全局依赖性（即所提供图像的整体解剖视图），因此不能跟踪大的形变。为了解决上述问题，本文以三种不同的方式扩展了Voxelmorph方法。

    Image registration is the process of bringing different images into a common coordinate system - a technique widely used in various applications of computer vision, such as remote sensing, image retrieval, and, most commonly, medical imaging. Deep learning based techniques have been applied successfully to tackle various complex medical image processing problems, including medical image registration. Over the years, several image registration techniques have been proposed using deep learning. Deformable image registration techniques such as Voxelmorph have been successful in capturing finer changes and providing smoother deformations. However, Voxelmorph, as well as ICNet and FIRE, do not explicitly encode global dependencies (i.e. the overall anatomical view of the supplied image) and, therefore, cannot track large deformations. In order to tackle the aforementioned problems, this paper extends the Voxelmorph approach in three different ways. To improve the performance in case of smal
    
[^96]: 在SIMMC 2.0挑战中探索多模态表达对于歧义检测和共识消解的影响

    Exploring Multi-Modal Representations for Ambiguity Detection & Coreference Resolution in the SIMMC 2.0 Challenge. (arXiv:2202.12645v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2202.12645](http://arxiv.org/abs/2202.12645)

    本文在SIMMC 2.0挑战中探索了多模态表达对于歧义检测和共识消解的影响，并通过实验证明了语言模型的能力和基于单模态的共识消解模型的优势。

    

    指代表达，比如代词和指示描述，既受前文的语言语境的影响，也受到当前视觉环境的影响。然而，发言者的指示描述并不能总是唯一地确定指代物，导致需要通过后续的澄清交流来消除歧义。因此，在对话式人工智能中，有效的歧义检测和共识消解对于任务成功至关重要。本文作为SIMMC 2.0挑战的一部分，提出了这两个任务的模型。具体来说，我们使用TOD-BERT和LXMERT模型，并将它们与一些基线模型进行对比，并进行了消融实验。我们的结果表明，（1）语言模型能够利用数据中的相关性来检测歧义；（2）基于单模态的共识消解模型可以通过使用智能物体表示来避免需要视觉组件。

    Anaphoric expressions, such as pronouns and referential descriptions, are situated with respect to the linguistic context of prior turns, as well as, the immediate visual environment. However, a speaker's referential descriptions do not always uniquely identify the referent, leading to ambiguities in need of resolution through subsequent clarificational exchanges. Thus, effective Ambiguity Detection and Coreference Resolution are key to task success in Conversational AI. In this paper, we present models for these two tasks as part of the SIMMC 2.0 Challenge (Kottur et al. 2021). Specifically, we use TOD-BERT and LXMERT based models, compare them to a number of baselines and provide ablation experiments. Our results show that (1) language models are able to exploit correlations in the data to detect ambiguity; and (2) unimodal coreference resolution models can avoid the need for a vision component, through the use of smart object representations.
    
[^97]: 用通用深度域适应框架进行跨会话运动想象分类的预处理

    Priming Cross-Session Motor Imagery Classification with A Universal Deep Domain Adaptation Framework. (arXiv:2202.09559v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2202.09559](http://arxiv.org/abs/2202.09559)

    本文提出了一个基于数学模型的深度域适应框架，用于处理跨会话运动想象分类问题。该框架能够轻松应用于现有的人工神经网络，无需改变网络结构，并通过通道归一化和欧氏对齐构建了域不变性。

    

    运动想象是一种常见的脑机接口（BCI）范式。脑电图（EEG）具有非平稳性和低信噪比，将同一个参与者在不同EEG记录会话中的运动想象任务进行分类通常具有挑战性，因为EEG数据分布在不同采集会话之间可能差异巨大。虽然将跨会话运动想象分类视为域适应问题是直观的，但其原理和可行的方法尚未阐明。本文提出了一种基于数学模型的同构深度域适应（SDDA）框架，用于跨会话运动想象分类。所提出的框架可以轻松应用于大多数现有的人工神经网络，而无需改变网络结构，这使得我们的方法具有很大的灵活性和可转移性。在所提出的框架中，首先通过通道归一化和欧氏对齐共同构建了域不变性。

    Motor imagery (MI) is a common brain computer interface (BCI) paradigm. EEG is non-stationary with low signal-to-noise, classifying motor imagery tasks of the same participant from different EEG recording sessions is generally challenging, as EEG data distribution may vary tremendously among different acquisition sessions. Although it is intuitive to consider the cross-session MI classification as a domain adaptation problem, the rationale and feasible approach is not elucidated. In this paper, we propose a Siamese deep domain adaptation (SDDA) framework for cross-session MI classification based on mathematical models in domain adaptation theory. The proposed framework can be easily applied to most existing artificial neural networks without altering the network structure, which facilitates our method with great flexibility and transferability. In the proposed framework, domain invariants were firstly constructed jointly with channel normalization and Euclidean alignment. Then, embeddi
    
[^98]: 在神经网络中结合最优路径搜索和任务相关学习

    Combining optimal path search with task-dependent learning in a neural network. (arXiv:2201.11104v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.11104](http://arxiv.org/abs/2201.11104)

    这篇论文提出了一种在神经网络中结合最优路径搜索和任务相关学习的方法，通过将成本值转化为神经网络的权重来实现在线权重适应。实验结果表明，该方法与经典算法Bellman-Ford具有相同的解，并且网络学习机制可以进一步增强算法的性能。

    

    在连接图中找到最优路径需要确定沿着图的边缘行进的最小总成本。这个问题可以通过几种经典算法来解决，通常所有边缘的成本都是预先定义好的。因此，在想要根据某个任务的要求以自适应的方式改变成本时，通常无法使用传统规划方法。在这里，我们展示了可以通过将成本值转化为突触权重来定义路径搜索问题的神经网络表示，这允许使用网络学习机制进行在线权重适应。当从一个初始活跃度值为1开始时，在这个网络中的活动传播将导致与Bellman-Ford算法找到的解相同的解。神经网络具有与Bellman-Ford相同的算法复杂度，并且此外，我们可以证明网络学习机制（如赫布学习）可以调整网络中的权重来增强算法的性能。

    Finding optimal paths in connected graphs requires determining the smallest total cost for traveling along the graph's edges. This problem can be solved by several classical algorithms where, usually, costs are predefined for all edges. Conventional planning methods can, thus, normally not be used when wanting to change costs in an adaptive way following the requirements of some task. Here we show that one can define a neural network representation of path finding problems by transforming cost values into synaptic weights, which allows for online weight adaptation using network learning mechanisms. When starting with an initial activity value of one, activity propagation in this network will lead to solutions, which are identical to those found by the Bellman-Ford algorithm. The neural network has the same algorithmic complexity as Bellman-Ford and, in addition, we can show that network learning mechanisms (such as Hebbian learning) can adapt the weights in the network augmenting the r
    

