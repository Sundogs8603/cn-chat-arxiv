# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Studying the Impact of Semi-Cooperative Drivers on Overall Highway Flow.](http://arxiv.org/abs/2304.11693) | 本论文研究了半合作驾驶汇入自动驾驶将会对公路整体流量产生什么影响，并通过实验表明了半合作的好处不成比例地影响利己和高速驾驶员。 |
| [^2] | [CoReFace: Sample-Guided Contrastive Regularization for Deep Face Recognition.](http://arxiv.org/abs/2304.11668) | CoReFace 是一种样本导向的对比正则化方法，能够直接约束图像间关系，提高深度人脸识别性能并能处理大的姿态和表情变化。 |
| [^3] | [IslamicPCQA: A Dataset for Persian Multi-hop Complex Question Answering in Islamic Text Resources.](http://arxiv.org/abs/2304.11664) | IslamicPCQA是第一个基于非结构化信息源回答复杂问题的波斯语数据集，包含从9部伊斯兰百科全书中提取的12,282个问题-答案对，旨在方便回答涉及伊斯兰文本资源的复杂波斯语问题。 |
| [^4] | [Efficient Training of Deep Equilibrium Models.](http://arxiv.org/abs/2304.11663) | 本文介绍一种简单而有效的策略来避免深度平衡模型层中反向传播的计算负担。该方法可以显著加速训练，同时不会影响性能。 |
| [^5] | [Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models.](http://arxiv.org/abs/2304.11657) | 本文提出 Iter-CoT 方法，在大型语言模型中进行迭代增强的思维链提示，通过选择具有适度难度的具有挑战性但可回答的问题，并伴随推理链作为示例，提高了模型的泛化能力，同时使模型能够更准确地生成推理链。 |
| [^6] | [Probabilistic Planning with Prioritized Preferences over Temporal Logic Objectives.](http://arxiv.org/abs/2304.11641) | 本文提出了一种新的规范语言，名为优先定性选择线性时态逻辑，用于描述具有优先级偏好的概率环境下的时间规划。该语言允许简洁地指定与完成每个时间任务相对应的具有相应优先级的时间目标，并通过有限轨迹上的优先级合取和有序析取来扩展有限轨迹上的线性时态逻辑。 |
| [^7] | [Towards Effective and Interpretable Human-Agent Collaboration in MOBA Games: A Communication Perspective.](http://arxiv.org/abs/2304.11632) | 本论文提出一种基于元命令通信的框架，即 MCC 框架，以有效探索 MOBA 游戏的人机协作，并提供解释性通信机制来帮助理解人机协作的工作原理。 |
| [^8] | [TSGCNeXt: Dynamic-Static Multi-Graph Convolution for Efficient Skeleton-Based Action Recognition with Long-term Learning Potential.](http://arxiv.org/abs/2304.11631) | TSGCNeXt是一个用于基于骨架的动作识别的模型，具有长期学习潜力，它采用动静态多图卷积来汇集多个独立拓扑图的特征，以及构建了一个图形卷积训练加速机制。 |
| [^9] | [Meaningful Causal Aggregation and Paradoxical Confounding.](http://arxiv.org/abs/2304.11625) | 聚合变量上的因果性不确定性可能会使得原本不混淆的因果关系变得混淆，在实际应用中，我们需要接受宏观因果关系通常只与微观状态相关的事实。 |
| [^10] | [SATIN: A Multi-Task Metadataset for Classifying Satellite Imagery using Vision-Language Models.](http://arxiv.org/abs/2304.11619) | 本研究介绍了一个遥感图像元数据集SATIN，它由27个现有的遥感数据集组成，并使用一系列视觉-语言（VL）模型全面评估了它的零-shot转移分类能力。该研究发现SATIN是一个具有挑战性的基准测试，强大方法的分类精度为52.0％，并提供了一个公共排行榜以跟踪模型的进展。 |
| [^11] | [Modality-Aware Negative Sampling for Multi-modal Knowledge Graph Embedding.](http://arxiv.org/abs/2304.11618) | 本文提出了一种适用于多模态知识图谱嵌入的模态感知负采样方法(MANS)，通过对知识图谱中实体的结构性和视觉嵌入进行对齐，MANS能够学习更有意义的嵌入以在多模态KGE中达到更好的效果，同时保持轻量级和高效率。 |
| [^12] | [Transductive Few-shot Learning with Prototype-based Label Propagation by Iterative Graph Refinement.](http://arxiv.org/abs/2304.11598) | 本文提出一种基于原型的标签传播方法，通过迭代图形细化解决了传统方法中原型估计不准确和核函数下亚优图形构建的问题，在少样迁移学习和半监督FSL方面表现优异。 |
| [^13] | [Learning Partial Correlation based Deep Visual Representation for Image Classification.](http://arxiv.org/abs/2304.11597) | 本文提出了一种基于偏相关的深度视觉表示学习方法，解决了使用协方差矩阵表征相关性在存在混淆效应时的误导问题。 |
| [^14] | [Segment Anything in Non-Euclidean Domains: Challenges and Opportunities.](http://arxiv.org/abs/2304.11595) | 本文探讨了一种新的Segment Non-Euclidean Anything（SNA）方法，旨在扩大语义分割的范围，导致更多的基础模型用于非欧几里得域中的分割任务。 |
| [^15] | [Meta-multigraph Search: Rethinking Meta-structure on Heterogeneous Information Networks.](http://arxiv.org/abs/2304.11574) | 本文提出了一种称为元多重图的新概念来代替元图和元路径用于处理异构信息网络中的信息聚合，同时提出了稳定的可微分搜索方法来优化元多重图以适应不同的任务和HIN，此外，还引入了复杂到简洁的C2C元多重图来降低冗余信息传播的影响。 |
| [^16] | [Differentiate ChatGPT-generated and Human-written Medical Texts.](http://arxiv.org/abs/2304.11567) | 本研究旨在区分由ChatGPT生成和人类撰写的医学文本，并通过设计机器学习工作流来有效检测医学领域的人工智能生成内容，以避免可能导致的假消息和对公众造成的损害。 |
| [^17] | [Lightweight Machine Learning for Digital Cross-Link Interference Cancellation with RF Chain Characteristics in Flexible Duplex MIMO Systems.](http://arxiv.org/abs/2304.11559) | 本文提出了适用于柔性双工MIMO系统的轻量级机器学习CLI抵消器，实验结果表明与传统方法相比，机器学习方法具有显着的性能提高和计算复杂度和内存消耗的显著降低，特别适用于实际实现。 |
| [^18] | [Divide and Prompt: Chain of Thought Prompting for Text-to-SQL.](http://arxiv.org/abs/2304.11556) | 本文通过思维链逐个解决子任务的方式，提出了一种新的Text-to-SQL提示方法的范例，运用于LLM模型可以有效地提高其执行准确性。 |
| [^19] | [Ensuring Trustworthy Medical Artificial Intelligencethrough Ethical and Philosophical Principles.](http://arxiv.org/abs/2304.11530) | 本文讨论了人工智能在医疗保健中的应用和考虑伦理和哲学原则以确保可靠的人工智能工具的重要性。人工智能在医疗中带来了更多挑战，必须解决偏见、透明度、自主权、责任和问责制等问题，作者提出了可能的解决办法。 |
| [^20] | [How to Control Hydrodynamic Force on Fluidic Pinball via Deep Reinforcement Learning.](http://arxiv.org/abs/2304.11526) | 本文利用深度强化学习提出了一种实时反馈策略，以控制流体弹球上的水动力力，可在非参数控制参数空间内作出合理有效的控制决策，从而更好地了解流控过程的基础。 |
| [^21] | [Personalized Federated Learning via Gradient Modulation for Heterogeneous Text Summarization.](http://arxiv.org/abs/2304.11524) | 本研究提出了一种基于梯度调制的个性化联合学习方案，名为FedSUMM，用于异构文本摘要。它能够在隐私保护下实现模型的准确性和良好的性能。 |
| [^22] | [LayerNAS: Neural Architecture Search in Polynomial Complexity.](http://arxiv.org/abs/2304.11517) | LayerNAS提出了一种多项式复杂度的神经架构搜索方法，将搜索分为多个目标，并将搜索成本和奖励元素分开，能够快速有效地发现优越模型。 |
| [^23] | [Detecting Socially Abnormal Highway Driving Behaviors via Recurrent Graph Attention Networks.](http://arxiv.org/abs/2304.11513) | 该研究利用循环图注意力网络检测高速公路上的社交异常驾驶行为，多样性的车辆交互和时空变化增加了检测的复杂度。 |
| [^24] | [Machine learning framework for end-to-end implementation of Incident duration prediction.](http://arxiv.org/abs/2304.11507) | 该研究提出了一个端到端机器学习框架，通过分析交通事故报告中可以获取的信息，预测并优化应急响应团队的资源部署，从而减少事故持续时间，同时提高公众安全。 |
| [^25] | [Boosting Theory-of-Mind Performance in Large Language Models via Prompting.](http://arxiv.org/abs/2304.11490) | 本研究通过提示提高大型语言模型（LLMs）在心智理论（ToM）任务上的表现，证明了上下文学习可以提升LLMs在复杂推理特别是ToM任务中的表现。 |
| [^26] | [Understanding Lexical Biases when Identifying Gang-related Social Media Communications.](http://arxiv.org/abs/2304.11485) | 本研究使用自然语言处理工具有效识别了帮派相关社交媒体上可能需要社区资源帮助的人群，拓展了社区成员照顾的范畴。 |
| [^27] | [A Comparative Study of Pre-trained Speech and Audio Embeddings for Speech Emotion Recognition.](http://arxiv.org/abs/2304.11472) | 本文对来自八个语音和音频PTMs提取的嵌入进行了比较分析，旨在提高情感识别模型的发展速度和效率，并使其能够在实际环境中得到应用。 |
| [^28] | [Fast Diffusion Probabilistic Model Sampling through the lens of Backward Error Analysis.](http://arxiv.org/abs/2304.11446) | 本文旨在开发一种用于去噪扩散概率模型（DDPM）的快速采样方法，只需要较少的步骤即可保持高质量的样本。我们提出了基于动态调节长时间反向误差的限制反向误差调度（RBE调度）的快速采样方法。 |
| [^29] | [Breaching FedMD: Image Recovery via Paired-Logits Inversion Attack.](http://arxiv.org/abs/2304.11436) | 本文揭示了即便使用FedMD的安全机制，仍存在被精心设计的恶意攻击利用的风险，如Paired-Logits反演攻击，会导致隐私数据曝光。 |
| [^30] | [Conditional Denoising Diffusion for Sequential Recommendation.](http://arxiv.org/abs/2304.11433) | 提出了一种条件去噪扩散模型，通过条件自回归的方式将优化和生成过程分解为更容易和可处理的步骤，并引入了一种新的优化模式，结合交叉熵损失和对抗性损失稳定训练过程。在多个数据集上的实验表明，该模型在顺序推荐方面具有较优的性能。 |
| [^31] | [Detecting Spoilers in Movie Reviews with External Movie Knowledge and User Networks.](http://arxiv.org/abs/2304.11411) | 该研究提出了一种新型多视角剧透检测框架，MVSD，该框架将电影知识和用户活动纳入考虑，并且在LCS数据集上展示了其优于强基线的相关实验结果。 |
| [^32] | [ML-based Approaches for Wireless NLOS Localization: Input Representations and Uncertainty Estimation.](http://arxiv.org/abs/2304.11396) | 本文探讨了三种不同的输入表示方法，分别是单个无线电路径特征、无线电链路特征和基于图像的表示，设计了卷积神经网络进行NLOS定位，支持更丰富的预测输出和不可靠预测的识别。 |
| [^33] | [Knowledge Distillation from 3D to Bird's-Eye-View for LiDAR Semantic Segmentation.](http://arxiv.org/abs/2304.11393) | 该论文提出了一种3D到BEV的知识蒸馏方法，使BEV分割模型具有更丰富的结构和几何信息，以提高分割的准确性和推理速度。 |
| [^34] | [Sequential Recommendation with Probabilistic Logical Reasoning.](http://arxiv.org/abs/2304.11383) | 本文提出了一种结合了概率逻辑推理的序列推荐框架，以解决神经-符号SR存在的问题。通过将特征嵌入和逻辑嵌入分离，SR-PLR结合相似性匹配和逻辑推理，能够更好地捕捉用户口味的不确定性和演变。 |
| [^35] | [SimplyMime: A Control at Our Fingertips.](http://arxiv.org/abs/2304.11377) | SimplyMime是一种旨在消除消费电子产品需求多个遥控器的系统，采用了动态手势识别体系结构，为用户提供直观的控制方式，同时还具有安全性方面的功能。 |
| [^36] | [Stimulating student engagement with an AI board game tournament.](http://arxiv.org/abs/2304.11376) | 该论文介绍了一种基于项目和竞赛的本科课程，旨在为大学生提供搜索方法在棋盘游戏中的应用。学生通过构建AI代理来参加黑白棋锦标赛，最终评估他们的项目质量和比赛表现。该课程以竞争式学习的形式实现游戏化，激发学生参与学习，有助于打下AI和算法学科的基础。 |
| [^37] | [Detecting Political Opinions in Tweets through Bipartite Graph Analysis: A Skip Aggregation Graph Convolution Approach.](http://arxiv.org/abs/2304.11367) | 本文聚焦于2020年美国总统选举，通过构建用户-推文双分图并利用图神经网络以检测 Twitter 中的政治观点。通过引入 Skip Aggregation 机制，有效利用用户行为信息，提高了模型效果。 |
| [^38] | [Detecting Adversarial Faces Using Only Real Face Self-Perturbations.](http://arxiv.org/abs/2304.11359) | 本文提出了一种使用真实人脸自扰动生成伪对抗性人脸的方法，利用这种方法训练的对抗性人脸检测器不需攻击数据即可检测新型未知攻击。 |
| [^39] | [Learning Symbolic Representations Through Joint GEnerative and DIscriminative Training.](http://arxiv.org/abs/2304.11357) | GEDI是一种将自监督学习和基于似然生成模型结合的贝叶斯框架。它与现有的神经符号框架联合训练，无需额外监督或预训练步骤，能够产生更好的符号表示。通过实验，证明GEDI可以在聚类性能上显著超越现有的自监督学习策略，在小数据范围内的性能也得到提高。 |
| [^40] | [A Semi-Supervised Framework for Misinformation Detection.](http://arxiv.org/abs/2304.11318) | 这篇论文提出了一种半监督学习框架来解决虚假信息检测中的极端类别不平衡问题。这种方法使用实际而不是模拟数据来增加少数派类别数量，在 Covid 相关的 Twitter 数据上实验表明其可以显著提高 F1 值。 |
| [^41] | [Unmatched uncertainty mitigation through neural network supported model predictive control.](http://arxiv.org/abs/2304.11315) | 本文利用基于深度学习的模型预测控制算法，采用双时间尺度适应机制，结合深度神经网络作为预言机，实时估计不匹配的不确定性，成功地实现了对具有未知结构的不匹配和有界状态-动作相关不确定性的系统的控制。 |
| [^42] | [Lookahead Diffusion Probabilistic Models for Refining Mean Estimation.](http://arxiv.org/abs/2304.11312) | 本文提出基于前瞻扩散概率模型的技术来优化条件高斯分布的均值估计，通过对两个估计进行外推来计算更准确的估计值。该方法不需要对DNN模型进行微调，并在基准数据集上获得了比最新方法更好的实验结果。 |
| [^43] | [Nonverbal Cues in Human-Robot Interaction: A Communication Studies Perspective.](http://arxiv.org/abs/2304.11293) | 本文从传播学视角出发，提出人机交互中的五种非语言代码，并将其转化为设计模式。该研究认为，将这些非语言代码整合到机器人中可以使机器人更加“生动”和“社会化”，同时提出了未来的研究方向。 |
| [^44] | [On the Identification of the Energy related Issues from the App Reviews.](http://arxiv.org/abs/2304.11292) | 本文研究了自动提取与能源相关的应用程序评论的不同技术。结果表明，神经网络优于其他机器学习模型。 |
| [^45] | [Identifying Appropriate Intellectual Property Protection Mechanisms for Machine Learning Models: A Systematization of Watermarking, Fingerprinting, Model Access, and Attacks.](http://arxiv.org/abs/2304.11285) | 本文系统化分析了机器学习模型在知识产权保护方面的挑战，提出了针对水印、指纹、模型访问和攻击的保护技术，并构建了综合的威胁模型。 |
| [^46] | [Trust and Reliance in Consensus-Based Explanations from an Anti-Misinformation Agent.](http://arxiv.org/abs/2304.11279) | 本文探讨了基于人工智能的智能代理在反误信息方面对共识幻觉的影响，并发现依赖（行为）会影响基于共识的解释，这对使用XAI的反误信息系统的设计指导有意义。 |
| [^47] | [PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel.](http://arxiv.org/abs/2304.11277) | 本论文介绍了基于PyTorch的Fully Sharded Data Parallel（FSDP）解决方案，该方案可扩展大型模型训练，并优化各种硬件配置的资源利用率。 |
| [^48] | [Benchmarking Low-Shot Robustness to Natural Distribution Shifts.](http://arxiv.org/abs/2304.11263) | 本文通过对不同少样本数据集、架构、预训练初始化和稳健性干预的自然分布漂移的稳健性进行了首次深入研究，发现没有单一的选择模型比其他模型更稳健，现有的干预措施也可能无法提高某些数据集的稳健性。 |
| [^49] | [eWaSR -- an embedded-compute-ready maritime obstacle detection network.](http://arxiv.org/abs/2304.11249) | 本论文提出了一种嵌入式计算准备好的海事障碍物检测网络——eWaSR，能够在保证检测质量的前提下运行速度更快，且在F1得分方面也优于其他目前最先进的嵌入式就绪架构。 |
| [^50] | [Explainability in AI Policies: A Critical Review of Communications, Reports, Regulations, and Standards in the EU, US, and UK.](http://arxiv.org/abs/2304.11218) | 本文对欧盟、美国和英国关于AI可解释性的政策和标准文献进行了主题和差距分析，旨在解决由于缺乏共同的监管基线和解释的情境性而难以采用的可解释性产出的问题。 |
| [^51] | [ACROCPoLis: A Descriptive Framework for Making Sense of Fairness.](http://arxiv.org/abs/2304.11217) | ACROCPoLis框架提供了一个共享词汇，明确了不同情况和程序的公平评估相关因素及其相互关系，让我们能够比较类似的情况，确定影响不同边缘化群体的因素。 |
| [^52] | [ChatGPT: More than a Weapon of Mass Deception, Ethical challenges and responses from the Human-Centered Artificial Intelligence (HCAI) perspective.](http://arxiv.org/abs/2304.11215) | 本文探讨了将ChatGPT作为一种生成式人工智能所带来的伦理问题，提出了采取技术（数字水印、样式化、检测器和事实核查器）和非技术措施（使用条款、透明度和用户教育）来减轻其可能成为大规模欺骗武器和促进欺诈犯罪的危险。 |
| [^53] | [Exploring the Use of ChatGPT as a Tool for Learning and Assessment in Undergraduate Computer Science Curriculum: Opportunities and Challenges.](http://arxiv.org/abs/2304.11214) | 本文讨论了将ChatGPT用作本科计算机科学课程学习和评估工具的前景和障碍，通过对数据结构和算法课程的学生进行短期编程任务的调查，证明了ChatGPT能够提升学生的参与度、合作性、可访问性和可用性。 |
| [^54] | [SSS3D: Fast Neural Architecture Search For Efficient Three-Dimensional Semantic Segmentation.](http://arxiv.org/abs/2304.11207) | SSS3D是为了高效三维语义场景分割而设计的快速多目标神经体系结构搜索框架，它使用超级网络RandLA-Net实现权重共享并显著减少搜索时间，通过两个阶段搜索在更短的时间内找到最佳子网络。 |
| [^55] | [Fast GraspNeXt: A Fast Self-Attention Neural Network Architecture for Multi-task Learning in Computer Vision Tasks for Robotic Grasping on the Edge.](http://arxiv.org/abs/2304.11196) | 本文提出了一种针对边缘计算机器人抓取的计算机视觉任务定制的多任务深度自注意神经网络架构，名为快速GraspNeXt。实验表明，快速GraspNeXt在精度和速度方面表现优异。 |
| [^56] | [Combining Vision and Tactile Sensation for Video Prediction.](http://arxiv.org/abs/2304.11193) | 本文研究将触觉反馈集成到物理机器人交互的视频预测模型中的影响，并介绍了两个新的机器人推动数据集，使用基于磁性的触觉传感器进行无监督学习。 |
| [^57] | [Task-Adaptive Pseudo Labeling for Transductive Meta-Learning.](http://arxiv.org/abs/2304.11173) | 本文提出了一种名为“任务自适应伪标签”的跨感知元学习方法，利用伪标签生成未标记的查询集，使用监督设置并利用未标记的查询集，可以处理更多实例，从而带来更好的分类性能。 |
| [^58] | [Granular ball computing: an efficient, robust, and interpretable adaptive multi-granularity representation and computation method.](http://arxiv.org/abs/2304.11171) | 本文提出了一种基于颗粒球计算的自适应多粒度表示和计算方法，能够提高机器学习的效率、鲁棒性和可解释性。 |
| [^59] | [Dialectical language model evaluation: An initial appraisal of the commonsense spatial reasoning abilities of LLMs.](http://arxiv.org/abs/2304.11164) | 本文介绍了一种辩证评估方式，旨在描绘语言模型系统失败的边界并检查其一致性，以及对LLMs通识空间推理能力进行了初步定性研究。 |
| [^60] | [Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT.](http://arxiv.org/abs/2304.11116) | 本文旨在通过Graph-ToolFormer框架赋予LLMs图形推理能力，并解决现有LLMs在执行图形学习任务中存在的固有弱点。 |
| [^61] | [Exogenous Data in Forecasting: FARM -- An Approach for Relevance Evaluation.](http://arxiv.org/abs/2304.11028) | 该论文介绍了一种名为FARM的方法，用于有效处理实时数据流并提供平衡的相关性度量，进而确定外部数据在预测中的重要性。 |
| [^62] | [Joint Client Assignment and UAV Route Planning for Indirect-Communication Federated Learning.](http://arxiv.org/abs/2304.10744) | 提出了一种新的FedEx框架，利用无人机等移动传输器建立间接通信通道，在解决客户端和服务器之间无法直接通信的问题时，本文提出了一种联合客户端分配和无人机路径规划的方法，最小化整体训练时间和通信成本。 |
| [^63] | [Using Z3 for Formal Modeling and Verification of FNN Global Robustness.](http://arxiv.org/abs/2304.10558) | 本文介绍了使用Z3求解器对全局鲁棒性可验证框架DeepGlobal进行更明确的定义和优化的工作，来建立FNN的形式化模型，以实现更有效的验证。 |
| [^64] | [An Introduction to Transformers.](http://arxiv.org/abs/2304.10557) | Transformer是一种神经网络组件，可以学习序列或数据集表示，在自然语言处理、计算机视觉和时空建模方面取得了重大进展。本论文提供了一个数学精确、直观、简洁的Transformer架构描述。 |
| [^65] | [Nerfbusters: Removing Ghostly Artifacts from Casually Captured NeRFs.](http://arxiv.org/abs/2304.10532) | 通过使用新的数据集和评估程序，提出了一种使用3D扩散优先级别加上新颖的基于密度的得分蒸馏采样损失的方法来防止NeRF优化过程中出现图形伪影的解决方案。 |
| [^66] | [Can ChatGPT Reproduce Human-Generated Labels? A Study of Social Computing Tasks.](http://arxiv.org/abs/2304.10145) | 本文研究了ChatGPT在社交计算任务中是否可以复制人类生成的标签注释，结果表明ChatGPT有潜力处理这些数据注释任务，尽管仍存在许多挑战。 |
| [^67] | [Two-Memory Reinforcement Learning.](http://arxiv.org/abs/2304.10098) | 本文提出了双记忆强化学习代理 (2M)，它结合了情节记忆和强化学习的优点来提高学习速度和准确性。 |
| [^68] | [A Latent Space Theory for Emergent Abilities in Large Language Models.](http://arxiv.org/abs/2304.09960) | 本文探讨了大规模语言模型中的贝叶斯推断和稀疏联合分布，证明了LLMs能够完成语言理解、上下文学习、思路启发以及有效指令微调的新兴能力。 |
| [^69] | [GeneGPT: Teaching Large Language Models to Use NCBI Web APIs.](http://arxiv.org/abs/2304.09667) | GeneGPT通过少量NCBI API调用URL请求作为演示，教授大型语言模型使用NCBI Web API回答基因组问题，并在GeneTuring测试中达到了优异的结果。 |
| [^70] | [SemEval 2023 Task 6: LegalEval -- Understanding Legal Texts.](http://arxiv.org/abs/2304.09548) | SemEval 2023举办了LegalEval共享任务，即理解法律文本，包括 自动结构化和语义连贯化的法律文件（Task-A），法律命名实体识别（Task-B）以及自动预测法律案件结果和提供预测解释（Task-C）。26个团队提交了系统论文并在所有子任务中优于基准线，但仍有改进空间。 |
| [^71] | [PaTeCon: A Pattern-Based Temporal Constraint Mining Method for Conflict Detection on Knowledge Graphs.](http://arxiv.org/abs/2304.09015) | PaTeCon是一种基于模式的知识图谱时间约束挖掘方法，能够自动生成时间约束来维护KG的时间一致性，并在不需要人工专家的情况下准确地检测潜在的时间冲突。 |
| [^72] | [CornerFormer: Boosting Corner Representation for Fine-Grained Structured Reconstruction.](http://arxiv.org/abs/2304.07072) | CornerFormer是一种新的方法，它利用不同建模策略于单个模型中融合角点检测和边缘预测来提升精细结构重建的表现，并在挑战性的基准测试中取得了最好的结果。 |
| [^73] | [Evaluation of Differentially Constrained Motion Models for Graph-Based Trajectory Prediction.](http://arxiv.org/abs/2304.05116) | 使用深度学习模型进行运动预测在自动驾驶中表现出色，但缺乏解释性和可能违反物理约束。因此，结合差分约束运动模型能提供物理上可行的轨迹，研究表明低阶积分器模型表现更好，并且数值求解器对模型性能产生影响。 |
| [^74] | [SSS at SemEval-2023 Task 10: Explainable Detection of Online Sexism using Majority Voted Fine-Tuned Transformers.](http://arxiv.org/abs/2304.03518) | 本文描述了使用细调BERT模型和多数投票集成模型来检测和解释在线性别歧视的方法。翻转显着降低了女性在社交媒体平台上经历不成比例的性别歧视的风险。 |
| [^75] | [A Survey of Large Language Models.](http://arxiv.org/abs/2303.18223) | 本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。 |
| [^76] | [The Semantic Reader Project: Augmenting Scholarly Documents through AI-Powered Interactive Reading Interfaces.](http://arxiv.org/abs/2303.14334) | 本文探讨了利用人工智能和人机交互技术为研究论文提供智能、交互式和无障碍的阅读界面的可行性，并介绍了跨机构合作的语义阅读器项目。 |
| [^77] | [Multi-View Zero-Shot Open Intent Induction from Dialogues: Multi Domain Batch and Proxy Gradient Transfer.](http://arxiv.org/abs/2303.13099) | 本研究提出了一种多领域批处理和代理梯度转移的语义多视角模型，可以解决任务导向对话系统中的意图检测和诱导新意图的问题，在Open Intent Induction中有显著的性能提升。 |
| [^78] | [TOT: Topology-Aware Optimal Transport For Multimodal Hate Detection.](http://arxiv.org/abs/2303.09314) | 本文针对隐式危害检测的挑战，提出一种面向表情包情境的拓扑感知最优传输框架TOT，利用最优传输核方法从多个模态中捕捉互补信息。 |
| [^79] | [Guarded Policy Optimization with Imperfect Online Demonstrations.](http://arxiv.org/abs/2303.01728) | 本文放弃了教师表现良好的假设，提出了一种新的算法，能够融合任意教师策略，并通过基于轨迹的价值估计实现高效的探索和安全保障。 |
| [^80] | [UZH_CLyp at SemEval-2023 Task 9: Head-First Fine-Tuning and ChatGPT Data Generation for Cross-Lingual Learning in Tweet Intimacy Prediction.](http://arxiv.org/abs/2303.01194) | 本文介绍了UZH_CLyp在SemEval 2023任务9中的表现。我们的跨语言迁移学习方法包含了先使用Head-First Fine-Tuning（HeFiT）方法更新回归头参数，再降低学习率更新预训练transformer的参数。同时，我们研究了在没有人工标记数据的情况下，使用ChatGPT生成的自动小型样例来解决低资源问题。研究发现，HeFiT稳定训练并显著提高预训练模型的性能，使用合成数据时也能提高跨语言学习的性能。 |
| [^81] | [BrainCLIP: Bridging Brain and Visual-Linguistic Representation via CLIP for Generic Natural Visual Stimulus Decoding from fMRI.](http://arxiv.org/abs/2302.12971) | BrainCLIP是一种从fMRI中获取自然图像信息的解码方法，它利用了CLIP跨模态泛化能力并在语义空间中统一视觉刺激分类和重构任务，同时文本监督也能提高解码模型的性能。 |
| [^82] | [An Iterative Classification and Semantic Segmentation Network for Old Landslide Detection Using High-Resolution Remote Sensing Images.](http://arxiv.org/abs/2302.12420) | 本文提出了一种迭代分类和语义分割网络(ICSSN)，它可以通过迭代升级两个共享特征提取器来大大增强目标级和像素级分类性能。 |
| [^83] | [SAT Requires Exhaustive Search.](http://arxiv.org/abs/2302.09512) | 本文证明了对于一些具有大域和长子句的极难例子，要求进行彻底搜索才能解决，这意味着P $\neq$ NP。 |
| [^84] | [CC-FedAvg: Computationally Customized Federated Averaging.](http://arxiv.org/abs/2212.13679) | 本论文提出了一个称为CC-FedAvg的计算定制的联邦平均算法，可让参与者根据其计算预算决定在每轮中是否执行传统的本地训练或模型估算。实验结果表明，CC-FedAvg能够显著提高模型性能并降低通信成本。 |
| [^85] | [MN-DS: A Multilabeled News Dataset for News Articles Hierarchical Classification.](http://arxiv.org/abs/2212.12061) | 本文介绍了一个包含10,917篇新闻文章的多标签数据集，可用于训练机器学习模型自动按主题对新闻文章进行分类，对新闻结构、分类和预测未来事件的研究人员非常有帮助。 |
| [^86] | [Guaranteed Conformance of Neurosymbolic Models to Natural Constraints.](http://arxiv.org/abs/2212.01346) | 该论文提出了一种能够担保数据驱动模型符合自然科学已有知识并最优逼近系统模型的方法。 |
| [^87] | [Dynamic Sparse Training via Balancing the Exploration-Exploitation Trade-off.](http://arxiv.org/abs/2211.16667) | 本文提出了一种动态稀疏训练方法，采用开发和探索收购函数来平衡探索和开发之间的权衡，从而摆脱了局部最优和鞍点问题，实验结果表明，该方法在精度和收敛速度方面超过了现有的稀疏训练方法。 |
| [^88] | [Continuous Episodic Control.](http://arxiv.org/abs/2211.15183) | CEC是一种新颖的非参数情景记忆算法，用于连续性行动空间问题中的序列决策制定，其在几个稀疏奖励连续控制环境中比最先进的RL和记忆增强RL算法学习更快，是学习连续控制任务的快速方法。 |
| [^89] | [Melting Pot 2.0.](http://arxiv.org/abs/2211.13746) | 研究工具Melting Pot 2.0为多智能体人工智能提供了评估协议，在一组典型测试场景中测量它们对新颖社交伙伴的泛化能力。 |
| [^90] | [GammaE: Gamma Embeddings for Logical Queries on Knowledge Graphs.](http://arxiv.org/abs/2210.15578) | GammaE是一种新颖的概率嵌入模型，利用了Gamma分布的线性特性和强边界支持来捕捉实体和查询的更多特征，解决了知识图谱中否定和联合算符的建模问题，并在知识图谱上回答不同类型的FOL查询。 |
| [^91] | [Broken Neural Scaling Laws.](http://arxiv.org/abs/2210.14891) | 本文提出了一个平滑破碎的幂律函数形式，可以准确地模拟和外推深度神经网络的缩放行为，适用于各种架构和大量不同任务，包括视觉、语言、音频、视频、生成建模、对比学习、机器人、不确定性估计/校准、对抗鲁棒性、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。 |
| [^92] | [Alternating Differentiation for Optimization Layers.](http://arxiv.org/abs/2210.01802) | Alt-Diff是一种新的框架，可以在不需要对整个雅可比矩阵进行昂贵计算的情况下，以快速和递归的方式微分优化问题，从而大大提高隐式微分的计算速度。 |
| [^93] | [On the benefits of self-taught learning for brain decoding.](http://arxiv.org/abs/2209.10099) | 本文探索了利用大量公共神经成像数据库进行自学习的方法，以改善大脑解码的性能。研究表明这种方法可以提高分类器的性能，但其益处的大小受到多个因素的影响。 |
| [^94] | [Deep Symbolic Learning: Discovering Symbols and Rules from Perceptions.](http://arxiv.org/abs/2208.11561) | DSL是一种能够在学习中自动发现有意义符号规则的NeSy系统，并在各种任务中取得最先进的结果。 |
| [^95] | [Conformal Risk Control.](http://arxiv.org/abs/2208.02814) | 该论文提出了一种符合保序的风险控制方法，可以控制任何单调损失函数的期望值，示例证明其在计算机视觉和自然语言处理领域具有控制误报率、图形距离和令牌级F1得分的能力。 |
| [^96] | [Cross-Modal Causal Relational Reasoning for Event-Level Visual Question Answering.](http://arxiv.org/abs/2207.12647) | 本篇论文提出了一个新型的事件级视觉问答框架——跨模态因果关系推理（CMCIR），通过引入因果干预方法，发现视觉和语言模态的真正因果结构，实现强健的因果感知视觉语言问答。 |
| [^97] | [An Experimental Evaluation of Machine Learning Training on a Real Processing-in-Memory System.](http://arxiv.org/abs/2207.07886) | 该研究评估了在处理内存系统上训练机器学习算法的潜能，并证明基于PIM的ML训练实现了显着的加速和能量效率。 |
| [^98] | [q-Learning in Continuous Time.](http://arxiv.org/abs/2207.00713) | 本文研究了连续时间下的q-Learning，通过引入小q函数作为一阶近似，研究了q-learning理论，应用于设计不同的演员-评论家算法。 |
| [^99] | [Using a Cognitive Architecture to consider antiblackness in design and development of AI systems.](http://arxiv.org/abs/2207.00644) | 本文利用ACT-R/{\Phi}认知体系结构和现有的知识图系统ConceptNet，从认知、社会文化和生理学三个角度考虑反黑和种族主义对AI系统的影响，并认为在认知建模中典型的回避社会文化过程和知识结构，隐含地推动了认知建模的色盲方法，并隐藏了总是存在于AI系统中的社会文化背景。 |
| [^100] | [Beyond neural scaling laws: beating power law scaling via data pruning.](http://arxiv.org/abs/2206.14486) | 本研究通过数据修剪算法突破神经网络训练集大小与模型误差幂律的尺度界限，并在多个数据集实验中验证了有效性，同时进行了首次大规模数据修剪算法基准测试研究。 |
| [^101] | [ACMP: Allen-Cahn Message Passing for Graph Neural Networks with Particle Phase Transition.](http://arxiv.org/abs/2206.05437) | 本文提出了一种基于ACMP的图神经网络模型，它可以通过具有吸引力和排斥力的相互作用粒子系统进行消息传递传播，克服了GNN过度平滑问题，将网络深度推到100层，并在基准数据集上实现了最先进的节点分类和图匹配性能。 |
| [^102] | [Formal Interpretability with Merlin-Arthur Classifiers.](http://arxiv.org/abs/2206.00759) | 该论文提出了一种新型的多智能体交互分类器，利用“Merlin-Arthur”协议的启发，在不假设最优智能体或特征独立分布的情况下，通过相对强度和“非对称特征相关性”概念捕捉特征之间精确的相关性，提供可证明的可解释性保证。 |
| [^103] | [Frustratingly Easy Regularization on Representation Can Boost Deep Reinforcement Learning.](http://arxiv.org/abs/2205.14557) | 本文证明了DRL的学习表示应该满足一个有利的可区分表示属性，提出了一种正则化器PEER，旨在通过对内部表示进行显式正则化来维持可区分表示属性。 |
| [^104] | [Efficient Feedback and Partial Credit Grading for Proof Blocks Problems.](http://arxiv.org/abs/2204.04196) | 本文提出了一个算法，可以高效地计算学生提交作业与预定义解决方案之间的编辑距离，可应用于证明、编程与自然语言处理等领域。 |
| [^105] | [Question-Answer Sentence Graph for Joint Modeling Answer Selection.](http://arxiv.org/abs/2203.03549) | 本文研究了基于图的方法用于答案选择，通过构建相关训练图并集成最先进模型，成功解决了检索型问答系统中的AS2任务，并在实验中表现优异。 |
| [^106] | [Tutorial on amortized optimization.](http://arxiv.org/abs/2202.00665) | 该教程介绍了分摊优化的基础，并总结了其在变分推断、稀疏编码、元学习、控制、强化学习、凸优化、最优传输和深度平衡网络中的应用。 |
| [^107] | [FedMed-GAN: Federated Domain Translation on Unsupervised Cross-Modality Brain Image Synthesis.](http://arxiv.org/abs/2201.08953) | 本文提出了一种新的基准方法FedMed-GAN: 用于联邦学习和医疗GAN之间的无监督脑图像合成和翻译,具有模式崩溃现象小、数据性能高等优点，广泛适用于不配对和配对数据集的联邦训练。 |
| [^108] | [Deep Reinforcement Learning, a textbook.](http://arxiv.org/abs/2201.02135) | 深度强化学习是一种引人注目的技术，计算机程序通过尝试、得到反馈和再次尝试来自我解决困难问题，甚至在某些领域比最好的人类表现更好。 |
| [^109] | [Demonstration Informed Specification Search.](http://arxiv.org/abs/2112.10807) | 本文提出了演示指导的规范搜索（DISS）算法，可以从专家演示中学习时间任务规范。 |
| [^110] | [Probabilistic Approach for Road-Users Detection.](http://arxiv.org/abs/2112.01360) | 本文介绍了一种用于缓解深度目标检测模型中过于自信预测问题的方法，通过引入一种新颖的概率层来避免传统的预测层，实验证明该方法能够减少假阳性中的过度自信。 |
| [^111] | [PatchCensor: Patch Robustness Certification for Transformers via Exhaustive Testing.](http://arxiv.org/abs/2111.10481) | PatchCensor是一种用于视觉Transformer的补丁鲁棒性认证方法，基于全面测试并考虑最坏的补丁攻击情境，能够提供受保证的准确性。 |
| [^112] | [PAIR: Leveraging Passage-Centric Similarity Relation for Improving Dense Passage Retrieval.](http://arxiv.org/abs/2108.06027) | PAIR算法是一种新方法，在密集型段落检索中同时考虑查询中心和段落中心相似关系，通过正式公式、知识蒸馏和两阶段训练实现。实验证明，该方法优于先前方法。 |
| [^113] | [A Modulation Layer to Increase Neural Network Robustness Against Data Quality Issues.](http://arxiv.org/abs/2107.08574) | 提出了一种新颖的神经网络修正方法，用于缓解低质量和缺失数据的影响，具备神经调制特征，通过一个额外的输入的函数替换了全连接层的固定权重，使得在测试中具有调制层的模型对于数据质量的降解更加鲁棒，同时也能够节省训练时间并且不会受到插补错误的影响。 |
| [^114] | [Human Attention during Goal-directed Reading Comprehension Relies on Task Optimization.](http://arxiv.org/abs/2107.05799) | 本文研究了阅读理解中人类关注力分配的计算模型。研究表明，在执行相同的阅读任务时，深度神经网络可以预测每个单词的阅读时间，读者在第一遍阅读和重新阅读过程中分别关注基本文本特征和与问题相关的信息，并且文本特征和问题相关性会分别调节注意力权重。 |
| [^115] | [Doctor Imitator: Hand-Radiography-based Bone Age Assessment by Imitating Scoring Methods.](http://arxiv.org/abs/2102.05424) | 本文提出了一种新的基于手部放射线检查图像的骨龄评估模型Doctor Imitator，通过模仿医生使用评分方法进行诊断逻辑，能够更好地与医生配合。 |
| [^116] | [The ERA of FOLE: Foundation.](http://arxiv.org/abs/1512.07430) | 本文讨论本体在FOLE一阶逻辑环境中的表示，特别是提供了ERA数据模型的严格数学表示，作为本体论的基础探讨。 |

# 详细

[^1]: 研究半合作驾驶对公路整体流量的影响。

    Studying the Impact of Semi-Cooperative Drivers on Overall Highway Flow. (arXiv:2304.11693v1 [cs.CL])

    [http://arxiv.org/abs/2304.11693](http://arxiv.org/abs/2304.11693)

    本论文研究了半合作驾驶汇入自动驾驶将会对公路整体流量产生什么影响，并通过实验表明了半合作的好处不成比例地影响利己和高速驾驶员。

    

    半合作行为是人类驾驶员固有的特性，应该考虑到自动驾驶。此外，新的自主规划器可以考虑人类驾驶员的社会价值取向（SVO）以生成符合社会准则的轨迹。然而，这种新型规划器对交通流量的整体影响仍需了解。在这项工作中，我们研究了隐式半合作驾驶，其中代理人部署了一个博弈论版本的迭代最佳响应，假定知道其他代理人的SVO。我们模拟名义交通流量，并研究了道路上的利他代理人比例是否影响个体或系统级驾驶表现。实验表明，利他代理人的比例对整体交通流量影响较小，而半合作的好处不成比例地影响利己和高速驾驶员。

    Semi-cooperative behaviors are intrinsic properties of human drivers and should be considered for autonomous driving. In addition, new autonomous planners can consider the social value orientation (SVO) of human drivers to generate socially-compliant trajectories. Yet the overall impact on traffic flow for this new class of planners remain to be understood. In this work, we present study of implicit semi-cooperative driving where agents deploy a game-theoretic version of iterative best response assuming knowledge of the SVOs of other agents. We simulate nominal traffic flow and investigate whether the proportion of prosocial agents on the road impact individual or system-wide driving performance. Experiments show that the proportion of prosocial agents has a minor impact on overall traffic flow and that benefits of semi-cooperation disproportionally affect egoistic and high-speed drivers.
    
[^2]: CoReFace: 面向深度人脸识别的样本导向对比正则化方法

    CoReFace: Sample-Guided Contrastive Regularization for Deep Face Recognition. (arXiv:2304.11668v1 [cs.CV])

    [http://arxiv.org/abs/2304.11668](http://arxiv.org/abs/2304.11668)

    CoReFace 是一种样本导向的对比正则化方法，能够直接约束图像间关系，提高深度人脸识别性能并能处理大的姿态和表情变化。

    

    特征表达的可分性对于开放式人脸识别至关重要。之前的方法依赖于代表身份的可学习分类层权重。然而，评估过程不学习身份表示，并在训练中删除分类器。这种不一致可能会困惑特征编码器，阻碍基于身份的方法的有效性。为了缓解以上问题，我们提出了一种新方法，即面向人脸识别的对比正则化（CoReFace），通过对特征表示学习应用基于图像的正则化。具体来说，我们采用样本导向的对比学习来直接约束图像间关系，这与评估过程一致。为了将对比学习融入人脸识别中，我们增强了嵌入而不是图像，避免了图像质量退化。然后，我们提出了一种新的针对变换不变人脸识别的对比损失，能够处理大的姿态和表情变化。在几个基准数据集上的实验证明了我们的方法在提高深度人脸识别性能方面的有效性。

    The discriminability of feature representation is the key to open-set face recognition. Previous methods rely on the learnable weights of the classification layer that represent the identities. However, the evaluation process learns no identity representation and drops the classifier from training. This inconsistency could confuse the feature encoder in understanding the evaluation goal and hinder the effect of identity-based methods. To alleviate the above problem, we propose a novel approach namely Contrastive Regularization for Face recognition (CoReFace) to apply image-level regularization in feature representation learning. Specifically, we employ sample-guided contrastive learning to regularize the training with the image-image relationship directly, which is consistent with the evaluation process. To integrate contrastive learning into face recognition, we augment embeddings instead of images to avoid the image quality degradation. Then, we propose a novel contrastive loss for t
    
[^3]: IslamicPCQA：基于伊斯兰文本资源的波斯语多跳复杂问答数据集

    IslamicPCQA: A Dataset for Persian Multi-hop Complex Question Answering in Islamic Text Resources. (arXiv:2304.11664v1 [cs.CL])

    [http://arxiv.org/abs/2304.11664](http://arxiv.org/abs/2304.11664)

    IslamicPCQA是第一个基于非结构化信息源回答复杂问题的波斯语数据集，包含从9部伊斯兰百科全书中提取的12,282个问题-答案对，旨在方便回答涉及伊斯兰文本资源的复杂波斯语问题。

    

    现在，问答系统面临的主要挑战之一是使用各种信息源回答复杂问题。多跳问题是一种需要多步推理才能回答的复杂问题。本文介绍了IslamicPCQA数据集，这是第一份基于非结构化信息源回答复杂问题的波斯语数据集，包含从9部伊斯兰百科全书中提取的12,282个问题-答案对。该数据集受HotpotQA英语数据集方法的启发，经过定制以适应波斯语的复杂性。回答该数据集的问题需要多个段落和推理过程。问题不限于任何先前的知识库或本体论，并且为了提供强大的推理能力，该数据集还包括支持事实和关键句子。准备好的数据集涵盖了广泛的伊斯兰主题，旨在方便回答涉及伊斯兰文本资源的复杂波斯语问题。

    Nowadays, one of the main challenges for Question Answering Systems is to answer complex questions using various sources of information. Multi-hop questions are a type of complex questions that require multi-step reasoning to answer. In this article, the IslamicPCQA dataset is introduced. This is the first Persian dataset for answering complex questions based on non-structured information sources and consists of 12,282 question-answer pairs extracted from 9 Islamic encyclopedias. This dataset has been created inspired by the HotpotQA English dataset approach, which was customized to suit the complexities of the Persian language. Answering questions in this dataset requires more than one paragraph and reasoning. The questions are not limited to any prior knowledge base or ontology, and to provide robust reasoning ability, the dataset also includes supporting facts and key sentences. The prepared dataset covers a wide range of Islamic topics and aims to facilitate answering complex Persi
    
[^4]: 深度平衡模型的高效训练

    Efficient Training of Deep Equilibrium Models. (arXiv:2304.11663v1 [cs.LG])

    [http://arxiv.org/abs/2304.11663](http://arxiv.org/abs/2304.11663)

    本文介绍一种简单而有效的策略来避免深度平衡模型层中反向传播的计算负担。该方法可以显著加速训练，同时不会影响性能。

    

    深度平衡模型（DEQ）在学习数据表示方面已经被证明非常强大。其思想是用隐式的固定点方程替换传统（显式的）前馈神经网络，从而允许解耦前向和后向传递。特别地，通过隐式函数定理，DEQ层的训练变得非常高效。但是，通过DEQ层的反向传播仍需要解决一个昂贵的基于Jacobian的方程。在本文中，我们介绍了一种简单而有效的策略来避免这种计算负担。我们的方法依赖于Broyden方法的Jacobian近似，在前向传递之后计算反向传递中的梯度。实验证明，简单地重复使用这个近似可以显著加速训练，同时不会造成性能降低。

    Deep equilibrium models (DEQs) have proven to be very powerful for learning data representations. The idea is to replace traditional (explicit) feedforward neural networks with an implicit fixed-point equation, which allows to decouple the forward and backward passes. In particular, training DEQ layers becomes very memory-efficient via the implicit function theorem. However, backpropagation through DEQ layers still requires solving an expensive Jacobian-based equation. In this paper, we introduce a simple but effective strategy to avoid this computational burden. Our method relies on the Jacobian approximation of Broyden's method after the forward pass to compute the gradients during the backward pass. Experiments show that simply re-using this approximation can significantly speed up the training while not causing any performance degradation.
    
[^5]: 在大型语言模型中加强迭代增强的思维链提示

    Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models. (arXiv:2304.11657v1 [cs.CL])

    [http://arxiv.org/abs/2304.11657](http://arxiv.org/abs/2304.11657)

    本文提出 Iter-CoT 方法，在大型语言模型中进行迭代增强的思维链提示，通过选择具有适度难度的具有挑战性但可回答的问题，并伴随推理链作为示例，提高了模型的泛化能力，同时使模型能够更准确地生成推理链。

    

    通过逐步引导思维链 (CoT) 作为示范，大型语言模型 (LLMs) 可以在各种推理任务上实现高度有效的性能。然而，LLMs 生成的演示推理链容易出现错误，这可能会导致推理过程中的错误。此外，不恰当的示例 (过于简单或复杂) 可以影响在不同难度级别下的整体性能。我们引入了Iter-CoT (迭代引导思维链提示) 的迭代引导方法，用于选择实例并生成推理链。通过利用迭代增强，我们的方法使LLMs 自主更正错误，从而产生更精确、全面的推理链。同时，我们的方法选择具有适度难度的具有挑战性但可回答的问题，并伴随推理链作为示例，从而增强LLMs 的泛化能力。

    Large language models (LLMs) can achieve highly effective performance on various reasoning tasks by incorporating step-by-step chain-of-thought (CoT) prompting as demonstrations. However, the reasoning chains of demonstrations generated by LLMs are prone to errors, which can subsequently lead to incorrect reasoning during inference. Furthermore, inappropriate exemplars (overly simplistic or complex), can affect overall performance among varying levels of difficulty. We introduce Iter-CoT (Iterative bootstrapping in Chain-of-Thoughts Prompting), an iterative bootstrapping approach for selecting exemplars and generating reasoning chains. By utilizing iterative bootstrapping, our approach enables LLMs to autonomously rectify errors, resulting in more precise and comprehensive reasoning chains. Simultaneously, our approach selects challenging yet answerable questions accompanied by reasoning chains as exemplars with a moderate level of difficulty, which enhances the LLMs' generalizability 
    
[^6]: 具有优先级偏好的概率规划和时间逻辑目标

    Probabilistic Planning with Prioritized Preferences over Temporal Logic Objectives. (arXiv:2304.11641v1 [cs.FL])

    [http://arxiv.org/abs/2304.11641](http://arxiv.org/abs/2304.11641)

    本文提出了一种新的规范语言，名为优先定性选择线性时态逻辑，用于描述具有优先级偏好的概率环境下的时间规划。该语言允许简洁地指定与完成每个时间任务相对应的具有相应优先级的时间目标，并通过有限轨迹上的优先级合取和有序析取来扩展有限轨迹上的线性时态逻辑。

    

    本文研究了在标记马尔科夫决策过程中具有多个时间目标的用户优先级偏好下的概率环境下的时间规划。现有的工作将这些偏好反映为目标的优先级列表。本文引入了一种新的规范语言，称为有限轨迹上的优先定性选择线性时态逻辑，其通过定性选择逻辑上的优先级合取和有序析取来扩展了有限轨迹上的线性时态逻辑。该语言允许简洁地指定与完成每个时间任务相对应的具有相应优先级的时间目标。描述系统行为的有限轨迹基于其对公式的不满意度得分进行排名。我们提出了从新语言到加权确定性有限自动机的系统化转换。利用这个计算模型，我们制定并解决了一个计算最优策略的问题。

    This paper studies temporal planning in probabilistic environments, modeled as labeled Markov decision processes (MDPs), with user preferences over multiple temporal goals. Existing works reflect such preferences as a prioritized list of goals. This paper introduces a new specification language, termed prioritized qualitative choice linear temporal logic on finite traces, which augments linear temporal logic on finite traces with prioritized conjunction and ordered disjunction from prioritized qualitative choice logic. This language allows for succinctly specifying temporal objectives with corresponding preferences accomplishing each temporal task. The finite traces that describe the system's behaviors are ranked based on their dissatisfaction scores with respect to the formula. We propose a systematic translation from the new language to a weighted deterministic finite automaton. Utilizing this computational model, we formulate and solve a problem of computing an optimal policy that m
    
[^7]: 在 MOBA 游戏中实现有效和可解释的人机协作：一种通信​​视角

    Towards Effective and Interpretable Human-Agent Collaboration in MOBA Games: A Communication Perspective. (arXiv:2304.11632v1 [cs.AI])

    [http://arxiv.org/abs/2304.11632](http://arxiv.org/abs/2304.11632)

    本论文提出一种基于元命令通信的框架，即 MCC 框架，以有效探索 MOBA 游戏的人机协作，并提供解释性通信机制来帮助理解人机协作的工作原理。

    

    MOBA 游戏，如 Dota2 和王者荣耀，已经成为最近关于游戏人工智能研究的测试基地，迄今已经开发出了许多在人类水平上的人工智能系统。然而，这些人工智能系统主要集中在如何与人类竞争，而不是探索如何与人类合作。为此，本文首次尝试研究 MOBA 游戏中的人机协作。本文提出通过设计一种高效且可解释的基于元命令通信的框架（MCC），使人类和代理可以通过明确的通信协作，以实现在 MOBA 游戏中有效的人机协作。MCC 框架由两个关键模块组成：1）解释性通信协议，即元命令，以弥合人类和代理之间的通信差距；2）元命令值估计器，即元命令选择器，选择每个代理完成有效人机协作的有价值元命令。实验结果表明，我们提出的 MCC 框架可以有效地加快人机协作，并且 MCC 框架提供的可解释性通信机制有助于深入了解在 MOBA 游戏中人机协作的工作原理。

    MOBA games, e.g., Dota2 and Honor of Kings, have been actively used as the testbed for the recent AI research on games, and various AI systems have been developed at the human level so far. However, these AI systems mainly focus on how to compete with humans, less on exploring how to collaborate with humans. To this end, this paper makes the first attempt to investigate human-agent collaboration in MOBA games. In this paper, we propose to enable humans and agents to collaborate through explicit communication by designing an efficient and interpretable Meta-Command Communication-based framework, dubbed MCC, for accomplishing effective human-agent collaboration in MOBA games. The MCC framework consists of two pivotal modules: 1) an interpretable communication protocol, i.e., the Meta-Command, to bridge the communication gap between humans and agents; 2) a meta-command value estimator, i.e., the Meta-Command Selector, to select a valuable meta-command for each agent to achieve effective h
    
[^8]: TSGCNeXt：具备长期学习潜力的高效基于骨架的动作识别的动静态多图卷积

    TSGCNeXt: Dynamic-Static Multi-Graph Convolution for Efficient Skeleton-Based Action Recognition with Long-term Learning Potential. (arXiv:2304.11631v1 [cs.CV])

    [http://arxiv.org/abs/2304.11631](http://arxiv.org/abs/2304.11631)

    TSGCNeXt是一个用于基于骨架的动作识别的模型，具有长期学习潜力，它采用动静态多图卷积来汇集多个独立拓扑图的特征，以及构建了一个图形卷积训练加速机制。

    

    随着图卷积网络（GCN）的发展，基于骨架的动作识别在人类动作识别方面取得了显著的成果。然而，最近的研究趋向于构建具有冗余训练的复杂学习机制，并存在长时间序列的瓶颈。为了解决这些问题，我们提出了Temporal-Spatio Graph ConvNeXt（TSGCNeXt）来探索长时间骨骼序列的高效学习机制。首先，我们提出了一个新的图形学习机制，动静分离多图卷积（DS-SMG），以汇集多个独立拓扑图的特征并避免节点信息在动态卷积期间被忽略。接下来，我们构建了一个图形卷积训练加速机制，以55.08％的速度提高动态图形学习的反向传播计算速度。最后，TSGCNeXt通过三个时空学习模块重新构建了GCN的整体结构，实现了更加高效的基于骨架的动作识别。

    Skeleton-based action recognition has achieved remarkable results in human action recognition with the development of graph convolutional networks (GCNs). However, the recent works tend to construct complex learning mechanisms with redundant training and exist a bottleneck for long time-series. To solve these problems, we propose the Temporal-Spatio Graph ConvNeXt (TSGCNeXt) to explore efficient learning mechanism of long temporal skeleton sequences. Firstly, a new graph learning mechanism with simple structure, Dynamic-Static Separate Multi-graph Convolution (DS-SMG) is proposed to aggregate features of multiple independent topological graphs and avoid the node information being ignored during dynamic convolution. Next, we construct a graph convolution training acceleration mechanism to optimize the back-propagation computing of dynamic graph learning with 55.08\% speed-up. Finally, the TSGCNeXt restructure the overall structure of GCN with three Spatio-temporal learning modules,effic
    
[^9]: 有意义的因果聚合和悖论性混淆

    Meaningful Causal Aggregation and Paradoxical Confounding. (arXiv:2304.11625v1 [cs.AI])

    [http://arxiv.org/abs/2304.11625](http://arxiv.org/abs/2304.11625)

    聚合变量上的因果性不确定性可能会使得原本不混淆的因果关系变得混淆，在实际应用中，我们需要接受宏观因果关系通常只与微观状态相关的事实。

    

    在聚合变量中，干预的影响通常是不确定的，因为相同的宏观干预的不同微观实现可能会导致下游宏观变量的不同变化。我们表明，对于聚合变量，因果性的不确定性可以使得原本不混淆的因果关系变得混淆，并且反之亦然，这一点取决于相应的微观实现。我们认为，只有在聚合因果系统没有这种不确定性的情况下，我们才可以实际应用这种方法。否则，我们需要接受一点，就是宏观因果关系通常只与微观状态相关。在积极方面，我们表明当宏观干预的分布与观测分布中微观状态的分布相同时，因果关系可以进行聚合，并讨论了此观察的概括。

    In aggregated variables the impact of interventions is typically ill-defined because different micro-realizations of the same macro-intervention can result in different changes of downstream macro-variables. We show that this ill-definedness of causality on aggregated variables can turn unconfounded causal relations into confounded ones and vice versa, depending on the respective micro-realization. We argue that it is practically infeasible to only use aggregated causal systems when we are free from this ill-definedness. Instead, we need to accept that macro causal relations are typically defined only with reference to the micro states. On the positive side, we show that cause-effect relations can be aggregated when the macro interventions are such that the distribution of micro states is the same as in the observational distribution and also discuss generalizations of this observation.
    
[^10]: SATIN：一个使用视觉-语言模型对卫星图像进行分类的多任务元数据集。

    SATIN: A Multi-Task Metadataset for Classifying Satellite Imagery using Vision-Language Models. (arXiv:2304.11619v1 [cs.CV])

    [http://arxiv.org/abs/2304.11619](http://arxiv.org/abs/2304.11619)

    本研究介绍了一个遥感图像元数据集SATIN，它由27个现有的遥感数据集组成，并使用一系列视觉-语言（VL）模型全面评估了它的零-shot转移分类能力。该研究发现SATIN是一个具有挑战性的基准测试，强大方法的分类精度为52.0％，并提供了一个公共排行榜以跟踪模型的进展。

    

    解释遥感图像可以实现许多下游应用，从土地利用规划到森林砍伐监测都有可能。由于地球地理多样性的存在，对这些数据进行稳健分类是具有挑战性的。虽然存在许多不同的卫星和航空图像分类数据集，但尚未有一个适合涵盖这种多样性的基准。在这项工作中，我们介绍了来自27个现有遥感数据集的元数据集SATellite ImageNet（SATIN），并全面评估了一系列视觉-语言（VL）模型在SATIN上的零-shot转移分类能力。我们发现SATIN是一个具有挑战性的基准测试-我们评估的最强方法的分类精度为52.0％。我们提供了一个公共排行榜，以指导和跟踪VL模型在这一重要领域的进展。

    Interpreting remote sensing imagery enables numerous downstream applications ranging from land-use planning to deforestation monitoring. Robustly classifying this data is challenging due to the Earth's geographic diversity. While many distinct satellite and aerial image classification datasets exist, there is yet to be a benchmark curated that suitably covers this diversity. In this work, we introduce SATellite ImageNet (SATIN), a metadataset curated from 27 existing remotely sensed datasets, and comprehensively evaluate the zero-shot transfer classification capabilities of a broad range of vision-language (VL) models on SATIN. We find SATIN to be a challenging benchmark-the strongest method we evaluate achieves a classification accuracy of 52.0%. We provide a $\href{https://satinbenchmark.github.io}{\text{public leaderboard}}$ to guide and track the progress of VL models in this important domain.
    
[^11]: 多模态知识图谱嵌入中的模态感知负采样

    Modality-Aware Negative Sampling for Multi-modal Knowledge Graph Embedding. (arXiv:2304.11618v1 [cs.CL])

    [http://arxiv.org/abs/2304.11618](http://arxiv.org/abs/2304.11618)

    本文提出了一种适用于多模态知识图谱嵌入的模态感知负采样方法(MANS)，通过对知识图谱中实体的结构性和视觉嵌入进行对齐，MANS能够学习更有意义的嵌入以在多模态KGE中达到更好的效果，同时保持轻量级和高效率。

    

    在知识图谱嵌入中，负采样被广泛应用以在训练过程中产生负三元组以进行正负区分。然而，现有的负采样方法在多模态信息考虑时不适用于KGE模型，而且由于它们的复杂设计而效率低下。本文提出了适用于多模态知识图谱嵌入（MMKGE）的模态感知负采样（MANS），以解决上述问题。MANS能够对知识图谱中的实体进行结构性和视觉嵌入的对齐，学习有意义的嵌入以在多模态KGE中表现更好，同时保持轻量级和高效率。在两个基准测试上的实证结果表明，MANS优于现有的NS方法。同时，我们对MANS进行了进一步探索以证实其有效性。

    Negative sampling (NS) is widely used in knowledge graph embedding (KGE), which aims to generate negative triples to make a positive-negative contrast during training. However, existing NS methods are unsuitable when multi-modal information is considered in KGE models. They are also inefficient due to their complex design. In this paper, we propose Modality-Aware Negative Sampling (MANS) for multi-modal knowledge graph embedding (MMKGE) to address the mentioned problems. MANS could align structural and visual embeddings for entities in KGs and learn meaningful embeddings to perform better in multi-modal KGE while keeping lightweight and efficient. Empirical results on two benchmarks demonstrate that MANS outperforms existing NS methods. Meanwhile, we make further explorations about MANS to confirm its effectiveness.
    
[^12]: 迭代图形细化的基于原型的标签传播的迁移少样学习。

    Transductive Few-shot Learning with Prototype-based Label Propagation by Iterative Graph Refinement. (arXiv:2304.11598v1 [cs.CV])

    [http://arxiv.org/abs/2304.11598](http://arxiv.org/abs/2304.11598)

    本文提出一种基于原型的标签传播方法，通过迭代图形细化解决了传统方法中原型估计不准确和核函数下亚优图形构建的问题，在少样迁移学习和半监督FSL方面表现优异。

    

    少样学习(FSL)因其适应新领域的能力而受欢迎。与归纳式少样学习相比，传导式模型通常表现更好，因为它们利用查询集的所有样本。现有方法的两个类别，基于原型和基于图形的方法，分别具有原型估计不准确和核函数下亚优图形构建的缺点。本文提出了一种新的基于原型的标签传播方法来解决这些问题。具体而言，我们的图形构建基于原型和样本之间的关系，而不是样本之间。随着原型的更新，图形也会随之变化。我们还估计每个原型的标签，而不是将原型视为类中心。在mini-ImageNet，tiered-ImageNet，CIFAR-FS和CUB数据集上，我们展示了所提出的方法在少样迁移学习和半监督FSL方面优于其他现有最先进的方法。

    Few-shot learning (FSL) is popular due to its ability to adapt to novel classes. Compared with inductive few-shot learning, transductive models typically perform better as they leverage all samples of the query set. The two existing classes of methods, prototype-based and graph-based, have the disadvantages of inaccurate prototype estimation and sub-optimal graph construction with kernel functions, respectively. In this paper, we propose a novel prototype-based label propagation to solve these issues. Specifically, our graph construction is based on the relation between prototypes and samples rather than between samples. As prototypes are being updated, the graph changes. We also estimate the label of each prototype instead of considering a prototype be the class centre. On mini-ImageNet, tiered-ImageNet, CIFAR-FS and CUB datasets, we show the proposed method outperforms other state-of-the-art methods in transductive FSL and semi-supervised FSL when some unlabeled data accompanies the 
    
[^13]: 基于偏相关的深度视觉表示学习用于图像分类

    Learning Partial Correlation based Deep Visual Representation for Image Classification. (arXiv:2304.11597v1 [cs.CV])

    [http://arxiv.org/abs/2304.11597](http://arxiv.org/abs/2304.11597)

    本文提出了一种基于偏相关的深度视觉表示学习方法，解决了使用协方差矩阵表征相关性在存在混淆效应时的误导问题。

    

    基于协方差矩阵的视觉表示已经证明了其在图像分类中的有效性，通过对卷积特征映射中不同通道之间的成对相关性进行建模。然而，如果存在另一个通道与感兴趣的两个通道相关，则成对相关性将变得误导人，导致“混淆”效应。针对这种情况，应该估计“偏相关”，以消除混淆效应。然而，可靠地估计偏相关需要解决一个对称正定矩阵优化问题，即稀疏逆协方差矩阵估计（SICE）。如何将此过程融入CNN中仍然是一个开放问题。在这项工作中，我们将SICE制定为CNN的一个新结构层。为确保端到端的可训练性，我们开发了一种迭代方法，在前向和后向传播步骤中解决上述矩阵优化问题。我们的工作获得了基于偏相关的深度视觉表示。

    Visual representation based on covariance matrix has demonstrates its efficacy for image classification by characterising the pairwise correlation of different channels in convolutional feature maps. However, pairwise correlation will become misleading once there is another channel correlating with both channels of interest, resulting in the ``confounding'' effect. For this case, ``partial correlation'' which removes the confounding effect shall be estimated instead. Nevertheless, reliably estimating partial correlation requires to solve a symmetric positive definite matrix optimisation, known as sparse inverse covariance estimation (SICE). How to incorporate this process into CNN remains an open issue. In this work, we formulate SICE as a novel structured layer of CNN. To ensure end-to-end trainability, we develop an iterative method to solve the above matrix optimisation during forward and backward propagation steps. Our work obtains a partial correlation based deep visual representa
    
[^14]: 非欧几里得域中的分割问题：挑战与机遇

    Segment Anything in Non-Euclidean Domains: Challenges and Opportunities. (arXiv:2304.11595v1 [cs.CV])

    [http://arxiv.org/abs/2304.11595](http://arxiv.org/abs/2304.11595)

    本文探讨了一种新的Segment Non-Euclidean Anything（SNA）方法，旨在扩大语义分割的范围，导致更多的基础模型用于非欧几里得域中的分割任务。

    

    最近的一项工作称为Segment Anything（SA）在将语义分割的边界推向基础模型时取得了重大进展。SA的影响引发了极为活跃的讨论，并引领了一波新的发展浪潮，用于欧几里得域中的各种任务，如物体检测和图像修复。尽管SA所带来的进展很有前途，但该概念尚未扩展到非欧几里得图形领域。在本文中，我们探索了一种称为Segment Non-Euclidean Anything（SNA）的新范式，该范式旨在开发能够处理非欧几里得域中各种图形数据的基础模型，试图扩大SA的范围并为未来的研究奠定基础。为了实现这一目标，我们首先讨论了与SA相关的基础模型的最新成就。然后，我们着眼于将SA概念应用于图形数据时出现的独特挑战。

    The recent work known as Segment Anything (SA) has made significant strides in pushing the boundaries of semantic segmentation into the era of foundation models. The impact of SA has sparked extremely active discussions and ushered in an encouraging new wave of developing foundation models for the diverse tasks in the Euclidean domain, such as object detection and image inpainting. Despite the promising advances led by SA, the concept has yet to be extended to the non-Euclidean graph domain. In this paper, we explore a novel Segment Non-Euclidean Anything (SNA) paradigm that strives to develop foundation models that can handle the diverse range of graph data within the non-Euclidean domain, seeking to expand the scope of SA and lay the groundwork for future research in this direction. To achieve this goal, we begin by discussing the recent achievements in foundation models associated with SA. We then shed light on the unique challenges that arise when applying the SA concept to graph a
    
[^15]: 元多重图搜索：重新思考异构信息网络上的元结构

    Meta-multigraph Search: Rethinking Meta-structure on Heterogeneous Information Networks. (arXiv:2304.11574v1 [cs.AI])

    [http://arxiv.org/abs/2304.11574](http://arxiv.org/abs/2304.11574)

    本文提出了一种称为元多重图的新概念来代替元图和元路径用于处理异构信息网络中的信息聚合，同时提出了稳定的可微分搜索方法来优化元多重图以适应不同的任务和HIN，此外，还引入了复杂到简洁的C2C元多重图来降低冗余信息传播的影响。

    

    元结构被广泛应用于定义在异构信息网络（HIN）中哪些邻居的子集来聚合信息。在本文中，我们调查了现有的元结构，包括元路径和元图，并观察到它们最初是手动设计的固定模式，因此不足以编码不同HIN上的各种丰富语义信息。通过反思它们的限制，我们定义了一个称为元多重图的新概念，作为元图的更具表现力和灵活的泛化，并提出了一种稳定可微分的搜索方法，以自动优化特定HIN和任务的元多重图。由于元多重图的灵活性可能会传播冗余的消息，因此我们进一步介绍了一种从复杂到简洁的C2C元多重图，它沿着元多重图的深度从复杂到简洁地传播消息。此外，我们观察到可微分搜索通常会遭受不稳定的搜索和显着的g

    Meta-structures are widely used to define which subset of neighbors to aggregate information in heterogeneous information networks (HINs). In this work, we investigate existing meta-structures, including meta-path and meta-graph, and observe that they are initially designed manually with fixed patterns and hence are insufficient to encode various rich semantic information on diverse HINs. Through reflection on their limitation, we define a new concept called meta-multigraph as a more expressive and flexible generalization of meta-graph, and propose a stable differentiable search method to automatically optimize the meta-multigraph for specific HINs and tasks. As the flexibility of meta-multigraphs may propagate redundant messages, we further introduce a complex-to-concise (C2C) meta-multigraph that propagates messages from complex to concise along the depth of meta-multigraph. Moreover, we observe that the differentiable search typically suffers from unstable search and a significant g
    
[^16]: 区分ChatGPT生成和人写的医学文本

    Differentiate ChatGPT-generated and Human-written Medical Texts. (arXiv:2304.11567v1 [cs.CL])

    [http://arxiv.org/abs/2304.11567](http://arxiv.org/abs/2304.11567)

    本研究旨在区分由ChatGPT生成和人类撰写的医学文本，并通过设计机器学习工作流来有效检测医学领域的人工智能生成内容，以避免可能导致的假消息和对公众造成的损害。

    

    背景：像ChatGPT这样的大型语言模型可以生成语法完美、类似人类文本内容的大量文本。然而，临床病历和诊断等医学文本需要严格的验证，由ChatGPT生成的错误医学内容可能导致假消息，从而对医疗保健和公众造成重大危害。目的：本研究是关于医疗领域负责和道德的人工智能生成内容的第一项研究。我们专注于分析由人类专家撰写的医学文本和由ChatGPT生成的文本之间的差异，并设计机器学习工作流来有效地检测和区分由ChatGPT生成的医学文本。方法：我们首先构建了一套包含人类专家撰写和由ChatGPT生成的医学文本的数据集合。接着，我们分析了这些文本的语言特征。

    Background: Large language models such as ChatGPT are capable of generating grammatically perfect and human-like text content, and a large number of ChatGPT-generated texts have appeared on the Internet. However, medical texts such as clinical notes and diagnoses require rigorous validation, and erroneous medical content generated by ChatGPT could potentially lead to disinformation that poses significant harm to healthcare and the general public.  Objective: This research is among the first studies on responsible and ethical AIGC (Artificial Intelligence Generated Content) in medicine. We focus on analyzing the differences between medical texts written by human experts and generated by ChatGPT, and designing machine learning workflows to effectively detect and differentiate medical texts generated by ChatGPT.  Methods: We first construct a suite of datasets containing medical texts written by human experts and generated by ChatGPT. In the next step, we analyze the linguistic features o
    
[^17]: 基于RF链路特征的柔性双工MIMO系统中数字交叉链接干扰抵消的轻量级机器学习

    Lightweight Machine Learning for Digital Cross-Link Interference Cancellation with RF Chain Characteristics in Flexible Duplex MIMO Systems. (arXiv:2304.11559v1 [cs.AI])

    [http://arxiv.org/abs/2304.11559](http://arxiv.org/abs/2304.11559)

    本文提出了适用于柔性双工MIMO系统的轻量级机器学习CLI抵消器，实验结果表明与传统方法相比，机器学习方法具有显着的性能提高和计算复杂度和内存消耗的显著降低，特别适用于实际实现。

    

    柔性双工（FD）技术（包括动态时分双工（D-TDD）和动态频分双工（D-FDD））被认为是实现5G-Advanced或6G移动通信系统更灵活的上行/下行传输的一种有前途的解决方案。然而，它可能引入严重的交叉链接干扰（CLI）。为了更好地减轻CLI的影响，我们首先提出了一个更现实的基站（BS）到BS通道模型，其中包含射频（RF）链路特性，这些特性表现出一种硬件依赖性非线性属性，因此传统通道建模的精度不足以用于CLI的取消。然后，我们提出了一个基于通道参数估计的多项式CLI抵消器和两个使用轻量级前馈神经网络（FNN）的机器学习（ML）CLI抵消器。我们的模拟结果和分析表明，与多项式抵消器相比，基于ML的CLI抵消器实现了显着的性能提高和计算复杂度和内存消耗的显著降低，特别适用于在FD MIMO系统中进行实际实现。

    The flexible duplex (FD) technique, including dynamic time-division duplex (D-TDD) and dynamic frequency-division duplex (D-FDD), is regarded as a promising solution to achieving a more flexible uplink/downlink transmission in 5G-Advanced or 6G mobile communication systems. However, it may introduce serious cross-link interference (CLI). For better mitigating the impact of CLI, we first present a more realistic base station (BS)-to-BS channel model incorporating the radio frequency (RF) chain characteristics, which exhibit a hardware-dependent nonlinear property, and hence the accuracy of conventional channel modelling is inadequate for CLI cancellation. Then, we propose a channel parameter estimation based polynomial CLI canceller and two machine learning (ML) based CLI cancellers that use the lightweight feedforward neural network (FNN). Our simulation results and analysis show that the ML based CLI cancellers achieve notable performance improvement and dramatic reduction of computat
    
[^18]: 分而治之，思维链指导下的Text-to-SQL

    Divide and Prompt: Chain of Thought Prompting for Text-to-SQL. (arXiv:2304.11556v1 [cs.CL])

    [http://arxiv.org/abs/2304.11556](http://arxiv.org/abs/2304.11556)

    本文通过思维链逐个解决子任务的方式，提出了一种新的Text-to-SQL提示方法的范例，运用于LLM模型可以有效地提高其执行准确性。

    

    链式思维与大型语言模型结合已在复杂推理任务上取得了令人鼓舞的结果。Text-to-SQL是一个将自然语言问题转换为SQL语句的关键语义分析任务，涉及复杂的推理过程。然而，很少有研究使用思维链指导来激活LLM在Text-to-SQL任务中的推理能力。本文提出了一个新的Text-to-SQL提示方法的范式，称为分而治之，通过先将任务分解为子任务，然后通过思维链逐个解决子任务。我们提出了3种基于提示的方法来增强LLM的Text-to-SQL能力。实验证明，这些提示引导LLM生成具有更高执行准确性的Text-to-SQL。

    Chain-of-thought (CoT) prompting combined with large language models (LLMs) have achieved encouraging results on complex reasoning tasks. Text-to-SQL is a critical semantic parsing task that converts natural language questions into SQL statements, involving a complex reasoning process. However, there is little work about using CoT prompting to activate LLM's reasoning capabilities on Text-to-SQL tasks. In this work, we propose a new paradigm for prompting Text-to-SQL tasks, called Divide-and-Prompt, which first divides the task into subtasks, and then approach each subtask through CoT. We present 3 prompting-based methods to enhance the Text-to-SQL ability of LLMs. Experiments show that these prompts guide LLMs to generate Text-to-SQL with higher execution accuracy.
    
[^19]: 通过伦理和哲学原则确保可信赖的医疗人工智能

    Ensuring Trustworthy Medical Artificial Intelligencethrough Ethical and Philosophical Principles. (arXiv:2304.11530v1 [cs.AI])

    [http://arxiv.org/abs/2304.11530](http://arxiv.org/abs/2304.11530)

    本文讨论了人工智能在医疗保健中的应用和考虑伦理和哲学原则以确保可靠的人工智能工具的重要性。人工智能在医疗中带来了更多挑战，必须解决偏见、透明度、自主权、责任和问责制等问题，作者提出了可能的解决办法。

    

    人工智能方法在医疗护理方面具有极大的潜力，可以通过提高医疗专家和患者的体验来彻底改变众多医疗护理。基于人工智能的计算机辅助诊断工具如果能够表现出色甚至与临床专家的水平相当，就可以产生巨大的效益。因此，发展中国家可以提供先进的医疗护理服务，并解决缺乏专业医疗从业者的问题。基于人工智能的工具可以节省时间、资源和整体治疗成本。此外，与人类相比，人工智能可以揭示大量输入数据中的复杂关系，甚至可以为医学提供新的基于证据的知识。然而，在医疗护理中整合人工智能也带来了几个伦理和哲学上的问题，如偏见、透明度、自主权、责任和问责制，这些问题必须在将这些工具整合到临床环境之前得到解决。在本文中，我们强调了人工智能在医疗护理中的最新应用以及考虑伦理和哲学原则以确保可信赖的人工智能工具的重要性。我们讨论了与医疗护理中的人工智能相关的各种挑战，包括数据偏见、透明度的需要、自主决策的问题以及问责制。我们还提出了解决这些挑战的潜在方案，包括确保透明度和问责制的框架以及指导人工智能开发者考虑伦理原则的指南。通过解决这些挑战并实施伦理和哲学原则，我们可以确保开发出符合诊所设置的受信任的医疗人工智能。

    Artificial intelligence (AI) methods have great potential to revolutionize numerous medical care by enhancing the experience of medical experts and patients. AI based computer-assisted diagnosis tools can have a tremendous benefit if they can outperform or perform similarly to the level of a clinical expert. As a result, advanced healthcare services can be affordable in developing nations, and the problem of a lack of expert medical practitioners can be addressed. AI based tools can save time, resources, and overall cost for patient treatment. Furthermore, in contrast to humans, AI can uncover complex relations in the data from a large set of inputs and even lead to new evidence-based knowledge in medicine. However, integrating AI in healthcare raises several ethical and philosophical concerns, such as bias, transparency, autonomy, responsibility and accountability, which must be addressed before integrating such tools into clinical settings. In this article, we emphasize recent advanc
    
[^20]: 利用深度强化学习控制流体弹球的水动力力​​​​​​​

    How to Control Hydrodynamic Force on Fluidic Pinball via Deep Reinforcement Learning. (arXiv:2304.11526v1 [eess.SY])

    [http://arxiv.org/abs/2304.11526](http://arxiv.org/abs/2304.11526)

    本文利用深度强化学习提出了一种实时反馈策略，以控制流体弹球上的水动力力，可在非参数控制参数空间内作出合理有效的控制决策，从而更好地了解流控过程的基础。

    

    本文提出了一种基于深度强化学习的实时反馈策略，以控制流体弹球上的水动力力。通过充分设计奖励函数和编码历史观察结果，自动学习并迭代上千次，该策略可以在非参数控制参数空间内作出合理有效的控制决策，比冗长的暴力搜索找到的最优策略还要好。随后，通过机器学习模型对其中一项结果进行分析，使我们能够以此了解流控过程的基础。

    Deep reinforcement learning (DRL) for fluidic pinball, three individually rotating cylinders in the uniform flow arranged in an equilaterally triangular configuration, can learn the efficient flow control strategies due to the validity of self-learning and data-driven state estimation for complex fluid dynamic problems. In this work, we present a DRL-based real-time feedback strategy to control the hydrodynamic force on fluidic pinball, i.e., force extremum and tracking, from cylinders' rotation. By adequately designing reward functions and encoding historical observations, and after automatic learning of thousands of iterations, the DRL-based control was shown to make reasonable and valid control decisions in nonparametric control parameter space, which is comparable to and even better than the optimal policy found through lengthy brute-force searching. Subsequently, one of these results was analyzed by a machine learning model that enabled us to shed light on the basis of decision-ma
    
[^21]: 基于梯度调制的个性化联合学习在异构文本摘要中的应用

    Personalized Federated Learning via Gradient Modulation for Heterogeneous Text Summarization. (arXiv:2304.11524v1 [cs.AI])

    [http://arxiv.org/abs/2304.11524](http://arxiv.org/abs/2304.11524)

    本研究提出了一种基于梯度调制的个性化联合学习方案，名为FedSUMM，用于异构文本摘要。它能够在隐私保护下实现模型的准确性和良好的性能。

    

    文本摘要对于信息聚合至关重要，并且需要大量的训练数据。但是，对数据隐私和安全的担忧限制了数据的收集和模型的训练。为了解决这个问题，我们提出了一种联合学习文本摘要方案，它允许用户在不共享原始数据的情况下以合作学习的方式分享全局模型。个性化联合学习（PFL）在全局模型优化过程中平衡个性化和泛化，以指导本地模型的训练。然而，多个本地数据具有不同的语义和上下文分布，这可能导致本地模型学习到偏离的语义和上下文信息。在本文中，我们提出了FedSUMM，一种动态梯度适配器，为本地模型提供更适当的本地参数。同时，FedSUMM使用差分隐私来防止分布式训练期间的参数泄露。实验证据验证了FedSUMM可以在模型准确性和隐私保护方面实现竞争性的性能。

    Text summarization is essential for information aggregation and demands large amounts of training data. However, concerns about data privacy and security limit data collection and model training. To eliminate this concern, we propose a federated learning text summarization scheme, which allows users to share the global model in a cooperative learning manner without sharing raw data. Personalized federated learning (PFL) balances personalization and generalization in the process of optimizing the global model, to guide the training of local models. However, multiple local data have different distributions of semantics and context, which may cause the local model to learn deviated semantic and context information. In this paper, we propose FedSUMM, a dynamic gradient adapter to provide more appropriate local parameters for local model. Simultaneously, FedSUMM uses differential privacy to prevent parameter leakage during distributed training. Experimental evidence verifies FedSUMM can ach
    
[^22]: LayerNAS：多目标神经架构搜索的多项式复杂度方法

    LayerNAS: Neural Architecture Search in Polynomial Complexity. (arXiv:2304.11517v1 [cs.LG])

    [http://arxiv.org/abs/2304.11517](http://arxiv.org/abs/2304.11517)

    LayerNAS提出了一种多项式复杂度的神经架构搜索方法，将搜索分为多个目标，并将搜索成本和奖励元素分开，能够快速有效地发现优越模型。

    

    神经架构搜索（NAS）已成为发现有效模型架构的流行方法，尤其是对于目标硬件而言。因此，在约束条件下找到最佳架构的NAS方法至关重要。在本文中，我们提出了LayerNAS，将多目标NAS的挑战转化为组合优化问题，有效地将搜索复杂度限制为多项式。对于具有$L$层的模型架构，我们为每一层执行逐层搜索，从一个搜索选项集$\mathbb{S}$中进行选择。LayerNAS根据一个目标，例如模型大小或延迟，对模型候选进行分组，并基于另一个目标搜索最佳模型，从而分割了搜索的成本和奖励元素。这种方法将搜索复杂度限制在$O(H \cdot |\mathbb{S}| \cdot L)$，其中$H$是在LayerNAS中设定的常数。我们的实验表明，LayerNAS能够持续发现优越的模型。

    Neural Architecture Search (NAS) has become a popular method for discovering effective model architectures, especially for target hardware. As such, NAS methods that find optimal architectures under constraints are essential. In our paper, we propose LayerNAS to address the challenge of multi-objective NAS by transforming it into a combinatorial optimization problem, which effectively constrains the search complexity to be polynomial.  For a model architecture with $L$ layers, we perform layerwise-search for each layer, selecting from a set of search options $\mathbb{S}$. LayerNAS groups model candidates based on one objective, such as model size or latency, and searches for the optimal model based on another objective, thereby splitting the cost and reward elements of the search. This approach limits the search complexity to $ O(H \cdot |\mathbb{S}| \cdot L) $, where $H$ is a constant set in LayerNAS.  Our experiments show that LayerNAS is able to consistently discover superior models
    
[^23]: 通过循环图注意力网络检测高速公路上的社交异常驾驶行为

    Detecting Socially Abnormal Highway Driving Behaviors via Recurrent Graph Attention Networks. (arXiv:2304.11513v1 [cs.AI])

    [http://arxiv.org/abs/2304.11513](http://arxiv.org/abs/2304.11513)

    该研究利用循环图注意力网络检测高速公路上的社交异常驾驶行为，多样性的车辆交互和时空变化增加了检测的复杂度。

    

    随着物联网技术的快速发展，下一代交通监控基础设施通过网络连接，以帮助交通数据收集和智能交通管理。交通中最重要的任务之一是异常检测，因为异常司机会降低交通效率并引起安全问题。本研究集中于从高速公路视频监控系统生成的轨迹中检测异常驾驶行为。大多数当前的异常驾驶行为检测方法侧重于处理单个车辆而不考虑车辆之间的交互。本研究考虑检测多种不符合附近其他驾驶员行为的社交异常驾驶行为。这个任务由于车辆交互的多样性和高速公路交通的时空变化而变得复杂。为了解决这个问题，我们使用RGANs对不同车辆之间的交互以及高速公路交通的时空变化进行建模。

    With the rapid development of Internet of Things technologies, the next generation traffic monitoring infrastructures are connected via the web, to aid traffic data collection and intelligent traffic management. One of the most important tasks in traffic is anomaly detection, since abnormal drivers can reduce traffic efficiency and cause safety issues. This work focuses on detecting abnormal driving behaviors from trajectories produced by highway video surveillance systems. Most of the current abnormal driving behavior detection methods focus on a limited category of abnormal behaviors that deal with a single vehicle without considering vehicular interactions. In this work, we consider the problem of detecting a variety of socially abnormal driving behaviors, i.e., behaviors that do not conform to the behavior of other nearby drivers. This task is complicated by the variety of vehicular interactions and the spatial-temporal varying nature of highway traffic. To solve this problem, we p
    
[^24]: 用于一体化事件持续时间预测的机器学习框架

    Machine learning framework for end-to-end implementation of Incident duration prediction. (arXiv:2304.11507v1 [cs.LG])

    [http://arxiv.org/abs/2304.11507](http://arxiv.org/abs/2304.11507)

    该研究提出了一个端到端机器学习框架，通过分析交通事故报告中可以获取的信息，预测并优化应急响应团队的资源部署，从而减少事故持续时间，同时提高公众安全。

    

    非经常性事件，如车辆碰撞和障碍物所引起的交通拥堵是交通管理中心(TMCs)的一个关键问题。及时清除事件对于改善安全、减少延误和排放对公众出行的影响至关重要。然而，TMCs和其他应急响应团队往往难以准确地预测事件的持续时间(等到路面得到清理)，使得决策如何部署资源存在挑战。为了解决这个问题，该研究开发了一种分析框架和端到端的机器学习解决方案，根据事件报告后立即可用的信息预测事件持续时间。对事件持续时间的质量预测可以帮助TMCs和其他应急响应团队采取主动措施，部署救援服务，如拖车、维护团队或激活备选路线。预测使用分类和回归机器学习模块的组合。该模型在来自佛罗里达交通部的实际数据中进行了评估，结果很有希望。

    Traffic congestion caused by non-recurring incidents such as vehicle crashes and debris is a key issue for Traffic Management Centers (TMCs). Clearing incidents in a timely manner is essential for improving safety and reducing delays and emissions for the traveling public. However, TMCs and other responders face a challenge in predicting the duration of incidents (until the roadway is clear), making decisions of what resources to deploy difficult. To address this problem, this research developed an analytical framework and end-to-end machine-learning solution for predicting incident duration based on information available as soon as an incident report is received. Quality predictions of incident duration can help TMCs and other responders take a proactive approach in deploying responder services such as tow trucks, maintenance crews or activating alternative routes. The predictions use a combination of classification and regression machine learning modules. The performance of the devel
    
[^25]: 通过提示提高大型语言模型的心智理论表现

    Boosting Theory-of-Mind Performance in Large Language Models via Prompting. (arXiv:2304.11490v1 [cs.AI])

    [http://arxiv.org/abs/2304.11490](http://arxiv.org/abs/2304.11490)

    本研究通过提示提高大型语言模型（LLMs）在心智理论（ToM）任务上的表现，证明了上下文学习可以提升LLMs在复杂推理特别是ToM任务中的表现。

    

    2023年，大型语言模型（LLMs）在许多任务中表现出色，但在复杂推理方面仍面临挑战。心智理论（ToM）任务需要理解代理人的信念、目标和心理状态，对于涉及人类的常识推理至关重要，因此提高LLM在这方面的表现至关重要。本研究测量了GPT-4和三个GPT-3.5变体（Davinci-2、Davinci-3、GPT-3.5-Turbo）的ToM表现，并研究了上下文学习提高它们的ToM理解力的有效性。我们评估了包含两步思维推理和逐步思考说明的提示。我们发现，通过人类反馈的强化学习（RLHF）训练的LLMs（除Davinci-2外的所有模型）通过上下文学习提高了它们的ToM准确性。GPT-4在零轮情况下表现最佳，达到了近80%的ToM准确性，但仍不足测试集上87%的人类准确性。然而，当提供上下文学习的提示时，GPT-4和三个GPT-3.5变体的ToM准确性显著高于无提示时，其中表现最好的模型（GPT-3.5-Turbo）达到了92%的准确性。我们的研究展示了上下文学习提升LLM在复杂推理尤其是ToM任务中表现的潜力。

    Large language models (LLMs) excel in many tasks in 2023, but they still face challenges in complex reasoning. Theory-of-mind (ToM) tasks, which require understanding agents' beliefs, goals, and mental states, are essential for common-sense reasoning involving humans, making it crucial to enhance LLM performance in this area. This study measures the ToM performance of GPT-4 and three GPT-3.5 variants (Davinci-2, Davinci-3, GPT-3.5-Turbo), and investigates the effectiveness of in-context learning in improving their ToM comprehension. We evaluated prompts featuring two-shot chain of thought reasoning and step-by-step thinking instructions. We found that LLMs trained with Reinforcement Learning from Human Feedback (RLHF) (all models excluding Davinci-2) improved their ToM accuracy via in-context learning. GPT-4 performed best in zero-shot settings, reaching nearly 80% ToM accuracy, but still fell short of the 87% human accuracy on the test set. However, when supplied with prompts for in-c
    
[^26]: 识别与帮助社区成员的帮派相关社交媒体交流中的词汇偏差研究

    Understanding Lexical Biases when Identifying Gang-related Social Media Communications. (arXiv:2304.11485v1 [cs.CL])

    [http://arxiv.org/abs/2304.11485](http://arxiv.org/abs/2304.11485)

    本研究使用自然语言处理工具有效识别了帮派相关社交媒体上可能需要社区资源帮助的人群，拓展了社区成员照顾的范畴。

    

    参与帮派活动的人使用包括Facebook和Twitter在内的主流社交媒体来表达嘲讽和威胁以及哀悼和纪念。然而，识别帮派相关活动的影响以通过社交媒体为社区成员提供帮助是具有独特挑战的，这包括道德上识别受帮派活动影响的个体的训练数据的困难和需要考虑这些个体在推文中常用的非标准语言风格。我们的研究提供了证据表明，自然语言处理工具可以有效地识别可能需要社区照顾资源，如顾问、冲突调解者或学术/专业培训计划的个体。我们证明了我们的二元逻辑分类器在识别受帮派相关暴力影响的个体时，在使用与2015年巴尔的摩暴动相关的帮派相关推文样本时，优于基线标准。

    Individuals involved in gang-related activity use mainstream social media including Facebook and Twitter to express taunts and threats as well as grief and memorializing. However, identifying the impact of gang-related activity in order to serve community member needs through social media sources has a unique set of challenges. This includes the difficulty of ethically identifying training data of individuals impacted by gang activity and the need to account for a non-standard language style commonly used in the tweets from these individuals. Our study provides evidence of methods where natural language processing tools can be helpful in efficiently identifying individuals who may be in need of community care resources such as counselors, conflict mediators, or academic/professional training programs. We demonstrate that our binary logistic classifier outperforms baseline standards in identifying individuals impacted by gang-related violence using a sample of gang-related tweets associ
    
[^27]: 预训练语音和音频嵌入与情感识别的比较研究

    A Comparative Study of Pre-trained Speech and Audio Embeddings for Speech Emotion Recognition. (arXiv:2304.11472v1 [eess.AS])

    [http://arxiv.org/abs/2304.11472](http://arxiv.org/abs/2304.11472)

    本文对来自八个语音和音频PTMs提取的嵌入进行了比较分析，旨在提高情感识别模型的发展速度和效率，并使其能够在实际环境中得到应用。

    

    预训练模型（PTMs）在语音和音频领域中表现出巨大的应用潜力。从这些模型中提取出的嵌入可以作为输入，用于学习算法，可以应用于各种下游任务。其中一个关键任务是情感识别，它具有广泛的应用，包括对顾客呼叫的动态分析、心理健康评估和个性化语言学习等。PTM嵌入有助于推动情感识别的发展，但缺乏一个考虑多个方面的综合比较，例如嵌入模型架构、用于预训练的数据以及预训练过程等。PTM嵌入的彻底比较将有助于更快，更高效地开发模型，并使它们能够在实际场景中得到应用。本文利用这一研究空白，对来自八个语音和音频PTMs提取的嵌入进行了比较分析（包括wav2vec 2.0，data2vec，wavLM，UniSpeec）

    Pre-trained models (PTMs) have shown great promise in the speech and audio domain. Embeddings leveraged from these models serve as inputs for learning algorithms with applications in various downstream tasks. One such crucial task is Speech Emotion Recognition (SER) which has a wide range of applications, including dynamic analysis of customer calls, mental health assessment, and personalized language learning. PTM embeddings have helped advance SER, however, a comprehensive comparison of these PTM embeddings that consider multiple facets such as embedding model architecture, data used for pre-training, and the pre-training procedure being followed is missing. A thorough comparison of PTM embeddings will aid in the faster and more efficient development of models and enable their deployment in real-world scenarios. In this work, we exploit this research gap and perform a comparative analysis of embeddings extracted from eight speech and audio PTMs (wav2vec 2.0, data2vec, wavLM, UniSpeec
    
[^28]: 通过反向误差分析加速扩散概率模型采样

    Fast Diffusion Probabilistic Model Sampling through the lens of Backward Error Analysis. (arXiv:2304.11446v1 [cs.CV])

    [http://arxiv.org/abs/2304.11446](http://arxiv.org/abs/2304.11446)

    本文旨在开发一种用于去噪扩散概率模型（DDPM）的快速采样方法，只需要较少的步骤即可保持高质量的样本。我们提出了基于动态调节长时间反向误差的限制反向误差调度（RBE调度）的快速采样方法。

    

    去噪扩散概率模型（DDPM）是一类强大的生成模型。近年来，DDPM在生成高保真度样本方面取得了巨大成功。然而，DDPM的一个重大限制是采样速度慢。要生成一个样本，通常需要进行数百或数千次顺序神经网络的函数评估步骤。本文旨在为DDPM开发一种快速采样方法，只需要较少的步骤即可保持高质量的样本。DDPM的推断过程近似于连续极限中求解相应的扩散常微分方程（扩散ODE）。本文分析了反向误差如何影响扩散ODE和DDPM中的样本质量。我们提出了基于动态调节长时间反向误差的\textbf{限制反向误差调度（RBE调度）}的快速采样方法。我们的方法不需要进一步的培训即可加速DDPM。

    Denoising diffusion probabilistic models (DDPMs) are a class of powerful generative models. The past few years have witnessed the great success of DDPMs in generating high-fidelity samples. A significant limitation of the DDPMs is the slow sampling procedure. DDPMs generally need hundreds or thousands of sequential function evaluations (steps) of neural networks to generate a sample. This paper aims to develop a fast sampling method for DDPMs requiring much fewer steps while retaining high sample quality. The inference process of DDPMs approximates solving the corresponding diffusion ordinary differential equations (diffusion ODEs) in the continuous limit. This work analyzes how the backward error affects the diffusion ODEs and the sample quality in DDPMs. We propose fast sampling through the \textbf{Restricting Backward Error schedule (RBE schedule)} based on dynamically moderating the long-time backward error. Our method accelerates DDPMs without any further training. Our experiments
    
[^29]: 通过Paired-Logits反演攻击恢复图像的FedMD

    Breaching FedMD: Image Recovery via Paired-Logits Inversion Attack. (arXiv:2304.11436v1 [cs.CR])

    [http://arxiv.org/abs/2304.11436](http://arxiv.org/abs/2304.11436)

    本文揭示了即便使用FedMD的安全机制，仍存在被精心设计的恶意攻击利用的风险，如Paired-Logits反演攻击，会导致隐私数据曝光。

    

    联邦学习与模型蒸馏（FedMD）是一种新兴的协作学习范式，其中仅传输公共数据集的输出logits作为蒸馏知识，而不是传递易受梯度反演攻击的私有模型参数，这是联邦学习中已知的隐私风险。本文发现，即使共享公共数据集的输出 logit比直接共享梯度更安全，仍存在因精心设计的恶意攻击导致的数据曝光风险。我们的研究表明，恶意服务器可以训练一个反演神经网络来利用服务器和客户端模型之间的置信度差，针对FedMD及其变种进行PLI（配对logits反演）攻击。在多个人脸识别数据集上进行的实验证明，在类似于FedMD的方案中，仅使用公共数据集的配对服务器-客户端logits，恶意服务器能够重构私有图像。

    Federated Learning with Model Distillation (FedMD) is a nascent collaborative learning paradigm, where only output logits of public datasets are transmitted as distilled knowledge, instead of passing on private model parameters that are susceptible to gradient inversion attacks, a known privacy risk in federated learning. In this paper, we found that even though sharing output logits of public datasets is safer than directly sharing gradients, there still exists a substantial risk of data exposure caused by carefully designed malicious attacks. Our study shows that a malicious server can inject a PLI (Paired-Logits Inversion) attack against FedMD and its variants by training an inversion neural network that exploits the confidence gap between the server and client models. Experiments on multiple facial recognition datasets validate that under FedMD-like schemes, by using paired server-client logits of public datasets only, the malicious server is able to reconstruct private images on a
    
[^30]: 条件去噪扩散用于顺序推荐

    Conditional Denoising Diffusion for Sequential Recommendation. (arXiv:2304.11433v1 [cs.LG])

    [http://arxiv.org/abs/2304.11433](http://arxiv.org/abs/2304.11433)

    提出了一种条件去噪扩散模型，通过条件自回归的方式将优化和生成过程分解为更容易和可处理的步骤，并引入了一种新的优化模式，结合交叉熵损失和对抗性损失稳定训练过程。在多个数据集上的实验表明，该模型在顺序推荐方面具有较优的性能。

    

    由于能够学习内在的数据分布并处理不确定性，生成模型受到了广泛的关注。然而，两种主要的生成模型——生成对抗网络（GANs）和变分自编码器（VAEs）在顺序推荐任务中的表现存在挑战，GANs存在不稳定的优化，而VAEs则容易发生后验崩塌和过度平滑的生成。顺序推荐的稀疏和嘈杂的特性进一步加剧了这些问题。为了解决这些限制，我们提出了一个条件去噪扩散模型，包括序列编码器，交叉注意去噪解码器和逐步扩散器。这种方法以条件自回归的方式将优化和生成过程分解为更容易和可处理的步骤。此外，我们引入了一种新的优化模式，结合交叉熵损失和对抗性损失稳定训练过程。在多个数据集上的大量实验表明，我们的模型在顺序推荐方面优于几种最先进的方法，无论是在定量指标上还是在定性指标上。

    Generative models have attracted significant interest due to their ability to handle uncertainty by learning the inherent data distributions. However, two prominent generative models, namely Generative Adversarial Networks (GANs) and Variational AutoEncoders (VAEs), exhibit challenges that impede achieving optimal performance in sequential recommendation tasks. Specifically, GANs suffer from unstable optimization, while VAEs are prone to posterior collapse and over-smoothed generations. The sparse and noisy nature of sequential recommendation further exacerbates these issues. In response to these limitations, we present a conditional denoising diffusion model, which includes a sequence encoder, a cross-attentive denoising decoder, and a step-wise diffuser. This approach streamlines the optimization and generation process by dividing it into easier and tractable steps in a conditional autoregressive manner. Furthermore, we introduce a novel optimization schema that incorporates both cro
    
[^31]: 用电影知识和用户网络检测影评中的剧透

    Detecting Spoilers in Movie Reviews with External Movie Knowledge and User Networks. (arXiv:2304.11411v1 [cs.AI])

    [http://arxiv.org/abs/2304.11411](http://arxiv.org/abs/2304.11411)

    该研究提出了一种新型多视角剧透检测框架，MVSD，该框架将电影知识和用户活动纳入考虑，并且在LCS数据集上展示了其优于强基线的相关实验结果。

    

    在线电影评论平台为电影产业和公众提供众包反馈，但剧透评论严重损害了用户体验。尽管已经进行了初步的研究以自动识别剧透，但其仅关注于评论内容本身，而强大的剧透检测需要将评论放入关于电影的事实和知识、用户在电影评论平台上的行为等上下文中。因此，在我们首先整理了一个基于网络的剧透检测数据集LCS和一个全面的最新电影知识库UKM之后，我们提出了MVSD，一种考虑到有关电影和用户活动的外部知识的新型多视角剧透检测框架。具体而言，MVSD构建三个互联的异构信息网络来模拟多样化的数据来源及其多视图属性，而我们设计并采用了一种新型的异构图卷积神经网络（HGCN）来融合多视图嵌入并预测剧透。我们在LCS数据集上进行了广泛的实验，并展示了MVSD在准确性和F1得分方面显著优于强基线。此外，我们还在一个流行的电影评论网站上展示了MVSD在真实剧透识别任务上的功效。

    Online movie review platforms are providing crowdsourced feedback for the film industry and the general public, while spoiler reviews greatly compromise user experience. Although preliminary research efforts were made to automatically identify spoilers, they merely focus on the review content itself, while robust spoiler detection requires putting the review into the context of facts and knowledge regarding movies, user behavior on film review platforms, and more. In light of these challenges, we first curate a large-scale network-based spoiler detection dataset LCS and a comprehensive and up-to-date movie knowledge base UKM. We then propose MVSD, a novel Multi-View Spoiler Detection framework that takes into account the external knowledge about movies and user activities on movie review platforms. Specifically, MVSD constructs three interconnecting heterogeneous information networks to model diverse data sources and their multi-view attributes, while we design and employ a novel heter
    
[^32]: 无线NLOS定位的基于机器学习的方法：输入表示与不确定性估计

    ML-based Approaches for Wireless NLOS Localization: Input Representations and Uncertainty Estimation. (arXiv:2304.11396v1 [cs.NI])

    [http://arxiv.org/abs/2304.11396](http://arxiv.org/abs/2304.11396)

    本文探讨了三种不同的输入表示方法，分别是单个无线电路径特征、无线电链路特征和基于图像的表示，设计了卷积神经网络进行NLOS定位，支持更丰富的预测输出和不可靠预测的识别。

    

    非直视路径（NLOS）定位是许多无线网络应用的关键问题。缺乏可用数据集使得利用机器学习方法解决NLOS定位问题变得困难，但是近期合成数据集生成的新发展为研究提供了新机遇。本文探讨了三种不同的输入表示方法：（i）单个无线电路径特征，（ii）无线电链路特征（多径），和（iii）基于图像的表示。在后两种新的表示方法的启发下，我们设计了两个卷积神经网络（CNNs），并且尽管没有显著提高NLOS定位性能，他们能够支持更丰富的预测输出，从而使预测结果深入分析。特别是，更丰富的输出能够可靠地识别出不可靠的预测，并支持给定实例的前K个候选位置的预测。我们还测量了不同表示的不确定性，展示了基于图像的表示方式能够获得更好的不确定性估计。

    The challenging problem of non-line-of-sight (NLOS) localization is critical for many wireless networking applications. The lack of available datasets has made NLOS localization difficult to tackle with ML-driven methods, but recent developments in synthetic dataset generation have provided new opportunities for research. This paper explores three different input representations: (i) single wireless radio path features, (ii) wireless radio link features (multi-path), and (iii) image-based representations. Inspired by the two latter new representations, we design two convolutional neural networks (CNNs) and we demonstrate that, although not significantly improving the NLOS localization performance, they are able to support richer prediction outputs, thus allowing deeper analysis of the predictions. In particular, the richer outputs enable reliable identification of non-trustworthy predictions and support the prediction of the top-K candidate locations for a given instance. We also measu
    
[^33]: 从3D到鸟瞰图的知识蒸馏用于LiDAR语义分割

    Knowledge Distillation from 3D to Bird's-Eye-View for LiDAR Semantic Segmentation. (arXiv:2304.11393v1 [cs.CV])

    [http://arxiv.org/abs/2304.11393](http://arxiv.org/abs/2304.11393)

    该论文提出了一种3D到BEV的知识蒸馏方法，使BEV分割模型具有更丰富的结构和几何信息，以提高分割的准确性和推理速度。

    

    LiDAR点云分割是自动驾驶场景理解最基本的任务之一。然而，现有模型很难同时实现高推理速度和准确性。我们开发了一种有效的3D到BEV知识蒸馏方法，将来自3D体素模型的丰富知识转移到BEV模型中。我们的框架主要包括两个模块：体素到柱状体蒸馏模块和标签权重蒸馏模块。

    LiDAR point cloud segmentation is one of the most fundamental tasks for autonomous driving scene understanding. However, it is difficult for existing models to achieve both high inference speed and accuracy simultaneously. For example, voxel-based methods perform well in accuracy, while Bird's-Eye-View (BEV)-based methods can achieve real-time inference. To overcome this issue, we develop an effective 3D-to-BEV knowledge distillation method that transfers rich knowledge from 3D voxel-based models to BEV-based models. Our framework mainly consists of two modules: the voxel-to-pillar distillation module and the label-weight distillation module. Voxel-to-pillar distillation distills sparse 3D features to BEV features for middle layers to make the BEV-based model aware of more structural and geometric information. Label-weight distillation helps the model pay more attention to regions with more height information. Finally, we conduct experiments on the SemanticKITTI dataset and Paris-Lille
    
[^34]: 带有概率逻辑推理的序列推荐

    Sequential Recommendation with Probabilistic Logical Reasoning. (arXiv:2304.11383v1 [cs.AI])

    [http://arxiv.org/abs/2304.11383](http://arxiv.org/abs/2304.11383)

    本文提出了一种结合了概率逻辑推理的序列推荐框架，以解决神经-符号SR存在的问题。通过将特征嵌入和逻辑嵌入分离，SR-PLR结合相似性匹配和逻辑推理，能够更好地捕捉用户口味的不确定性和演变。

    

    深度学习和符号学习是序列推荐（SR）中经常使用的两种方法。最近的神经-符号SR模型展示了它们使SR具备并发感知和认知能力的潜力。然而，神经-符号SR仍然存在问题，如在逻辑推理中表示用户和物品。在本文中，我们将Deep Neural Network（DNN）SR模型与逻辑推理相结合，提出了一个通用框架，称为带有概率逻辑推理的序列推荐（简称SR-PLR）。该框架通过在DNN和概率逻辑网络中解开特征嵌入和逻辑嵌入，允许SR-PLR从相似性匹配和逻辑推理中受益。为了更好地捕捉用户口味的不确定性和演变，SR-PLR使用概率方法嵌入用户和物品，并对用户的交互模式进行概率逻辑推理。

    Deep learning and symbolic learning are two frequently employed methods in Sequential Recommendation (SR). Recent neural-symbolic SR models demonstrate their potential to enable SR to be equipped with concurrent perception and cognition capacities. However, neural-symbolic SR remains a challenging problem due to open issues like representing users and items in logical reasoning. In this paper, we combine the Deep Neural Network (DNN) SR models with logical reasoning and propose a general framework named Sequential Recommendation with Probabilistic Logical Reasoning (short for SR-PLR). This framework allows SR-PLR to benefit from both similarity matching and logical reasoning by disentangling feature embedding and logic embedding in the DNN and probabilistic logic network. To better capture the uncertainty and evolution of user tastes, SR-PLR embeds users and items with a probabilistic method and conducts probabilistic logical reasoning on users' interaction patterns. Then the feature a
    
[^35]: SimplyMime：触手可及的控制方式

    SimplyMime: A Control at Our Fingertips. (arXiv:2304.11377v1 [cs.HC])

    [http://arxiv.org/abs/2304.11377](http://arxiv.org/abs/2304.11377)

    SimplyMime是一种旨在消除消费电子产品需求多个遥控器的系统，采用了动态手势识别体系结构，为用户提供直观的控制方式，同时还具有安全性方面的功能。

    

    随着技术的不断演进，消费电子产品（如电视、机顶盒、家庭影院和空调）的使用在现代社会变得越来越普遍。随着每年新设备的进入，操作它们需要多个红外线遥控器的累积不仅浪费能源和资源，而且为用户创造了繁琐和混乱的环境。本文提出了一种名为SimplyMime的新型系统，旨在消除消费电子产品需要多个遥控器的需求，为用户提供直观的控制方式，而不需要额外的设备。SimplyMime利用了一种动态手势识别体系结构，融合了人工智能和人机交互，创建出一种先进的系统，使用户能够轻松地与绝大多数消费电子产品进行交互。此外，SimplyMime还具有安全性方面的功能，可以验证和认证设备。

    The utilization of consumer electronics, such as televisions, set-top boxes, home theaters, and air conditioners, has become increasingly prevalent in modern society as technology continues to evolve. As new devices enter our homes each year, the accumulation of multiple infrared remote controls to operate them not only results in a waste of energy and resources, but also creates a cumbersome and cluttered environment for the user. This paper presents a novel system, named SimplyMime, which aims to eliminate the need for multiple remote controls for consumer electronics and provide the user with intuitive control without the need for additional devices. SimplyMime leverages a dynamic hand gesture recognition architecture, incorporating Artificial Intelligence and Human-Computer Interaction, to create a sophisticated system that enables users to interact with a vast majority of consumer electronics with ease. Additionally, SimplyMime has a security aspect where it can verify and authent
    
[^36]: 通过AI棋盘游戏锦标赛激发学生参与度

    Stimulating student engagement with an AI board game tournament. (arXiv:2304.11376v1 [cs.AI])

    [http://arxiv.org/abs/2304.11376](http://arxiv.org/abs/2304.11376)

    该论文介绍了一种基于项目和竞赛的本科课程，旨在为大学生提供搜索方法在棋盘游戏中的应用。学生通过构建AI代理来参加黑白棋锦标赛，最终评估他们的项目质量和比赛表现。该课程以竞争式学习的形式实现游戏化，激发学生参与学习，有助于打下AI和算法学科的基础。

    

    基本的AI技术是理解更高级概念的关键。我们认为在高等教育早期引入搜索方法等AI技术有助于创造更深刻的理解，为更高级别的AI和算法课程打下基础。我们提出一个基于项目和竞赛的本科课程，为大二学生提供搜索方法应用于棋盘游戏的简介。在两人一组的情况下，学生必须使用网络编程和AI方法来构建AI代理以参加棋盘游戏锦标赛，今年的游戏是黑白棋。学生将根据项目的质量和在最终锦标赛中的表现进行评估。我们认为，引入竞争式学习的游戏化形式可以为学生提供更好的学习体验。

    Strong foundations in basic AI techniques are key to understanding more advanced concepts. We believe that introducing AI techniques, such as search methods, early in higher education helps create a deeper understanding of the concepts seen later in more advanced AI and algorithms courses. We present a project-based and competition-based bachelor course that gives second-year students an introduction to search methods applied to board games. In groups of two, students have to use network programming and AI methods to build an AI agent to compete in a board game tournament-othello was this year's game. Students are evaluated based on the quality of their projects and on their performance during the final tournament. We believe that the introduction of gamification, in the form of competition-based learning, allows for a better learning experience for the students.
    
[^37]: 通过双分图分析检测 Twitter 中的政治观点：一种基于 Skip Aggregation 图卷积的方法。

    Detecting Political Opinions in Tweets through Bipartite Graph Analysis: A Skip Aggregation Graph Convolution Approach. (arXiv:2304.11367v1 [cs.SI])

    [http://arxiv.org/abs/2304.11367](http://arxiv.org/abs/2304.11367)

    本文聚焦于2020年美国总统选举，通过构建用户-推文双分图并利用图神经网络以检测 Twitter 中的政治观点。通过引入 Skip Aggregation 机制，有效利用用户行为信息，提高了模型效果。

    

    公众舆论是影响政治决策的关键因素。如今，社交媒体成为个人参与政治讨论和表达政治观点的重要平台，为研究公众舆论提供了宝贵的资源。本文聚焦于2020年美国总统选举，并从 Twitter 中创建了大规模的数据集。我们建立了一个基于用户的发布和转推行为的用户-推文双分图，并将任务转换为一个基于图神经网络（GNN）的节点分类问题，以检测推文中的政治观点。然后，我们引入了一种新颖的 Skip Aggregation 机制，使推文节点从二阶邻居（也是推文节点）聚合信息，有效利用用户行为信息。实验结果表明，我们提出的模型显著优于几种竞争性的基准模型。进一步的分析表明

    Public opinion is a crucial factor in shaping political decision-making. Nowadays, social media has become an essential platform for individuals to engage in political discussions and express their political views, presenting researchers with an invaluable resource for analyzing public opinion. In this paper, we focus on the 2020 US presidential election and create a large-scale dataset from Twitter. To detect political opinions in tweets, we build a user-tweet bipartite graph based on users' posting and retweeting behaviors and convert the task into a Graph Neural Network (GNN)-based node classification problem. Then, we introduce a novel skip aggregation mechanism that makes tweet nodes aggregate information from second-order neighbors, which are also tweet nodes due to the graph's bipartite nature, effectively leveraging user behavioral information. The experimental results show that our proposed model significantly outperforms several competitive baselines. Further analyses demonst
    
[^38]: 仅使用真实人脸自扰动检测对抗性人脸

    Detecting Adversarial Faces Using Only Real Face Self-Perturbations. (arXiv:2304.11359v1 [cs.CV])

    [http://arxiv.org/abs/2304.11359](http://arxiv.org/abs/2304.11359)

    本文提出了一种使用真实人脸自扰动生成伪对抗性人脸的方法，利用这种方法训练的对抗性人脸检测器不需攻击数据即可检测新型未知攻击。

    

    对抗性攻击旨在通过向输入样本添加特定噪声来扰乱目标系统的功能，当应用于人脸识别系统时，对安全性和稳健性带来潜在威胁。虽然现有的防御技术在检测某些特定的对抗性人脸（adv-faces）方面取得了高准确性，但具有完全不同噪声模式的新攻击方法尤其是基于 GAN 的攻击则绕过它们并达到更高的攻击成功率。更糟糕的是，现有技术需要攻击数据才能实现防御，使得防御者无法防御未被发现的新兴攻击。在本文中，我们研究了adv-faces的内在普遍性，通过使用三种启发式设计的噪声模式扰动真实人脸来生成伪对抗性人脸。我们是第一个仅使用真实人脸及其自扰动训练对抗性人脸检测器的研究，不受受害者人脸识别系统影响，也不受未知攻击影响。

    Adversarial attacks aim to disturb the functionality of a target system by adding specific noise to the input samples, bringing potential threats to security and robustness when applied to facial recognition systems. Although existing defense techniques achieve high accuracy in detecting some specific adversarial faces (adv-faces), new attack methods especially GAN-based attacks with completely different noise patterns circumvent them and reach a higher attack success rate. Even worse, existing techniques require attack data before implementing the defense, making it impractical to defend newly emerging attacks that are unseen to defenders. In this paper, we investigate the intrinsic generality of adv-faces and propose to generate pseudo adv-faces by perturbing real faces with three heuristically designed noise patterns. We are the first to train an adv-face detector using only real faces and their self-perturbations, agnostic to victim facial recognition systems, and agnostic to unsee
    
[^39]: 通过联合生成式和判别式训练学习符号表示

    Learning Symbolic Representations Through Joint GEnerative and DIscriminative Training. (arXiv:2304.11357v1 [cs.LG])

    [http://arxiv.org/abs/2304.11357](http://arxiv.org/abs/2304.11357)

    GEDI是一种将自监督学习和基于似然生成模型结合的贝叶斯框架。它与现有的神经符号框架联合训练，无需额外监督或预训练步骤，能够产生更好的符号表示。通过实验，证明GEDI可以在聚类性能上显著超越现有的自监督学习策略，在小数据范围内的性能也得到提高。

    

    我们介绍了GEDI，它是一种贝叶斯框架，将现有的自监督学习目标与基于似然的生成模型相结合。该框架利用生成式和判别式方法的优势，比独立解决方案产生了更好的符号表示。此外，GEDI可以轻松集成并与现有的神经符号框架联合训练，无需额外的监督或昂贵的预训练步骤。我们通过对包括SVHN、CIFAR10和CIFAR100在内的实际数据进行实验，证明了GEDI在聚类性能方面大大优于现有的自监督学习策略。符号组件进一步允许它利用逻辑约束形式的知识，提高小数据范围内的性能。

    We introduce GEDI, a Bayesian framework that combines existing self-supervised learning objectives with likelihood-based generative models. This framework leverages the benefits of both GEnerative and DIscriminative approaches, resulting in improved symbolic representations over standalone solutions. Additionally, GEDI can be easily integrated and trained jointly with existing neuro-symbolic frameworks without the need for additional supervision or costly pre-training steps. We demonstrate through experiments on real-world data, including SVHN, CIFAR10, and CIFAR100, that GEDI outperforms existing self-supervised learning strategies in terms of clustering performance by a significant margin. The symbolic component further allows it to leverage knowledge in the form of logical constraints to improve performance in the small data regime.
    
[^40]: 一种半监督的虚假信息检测框架

    A Semi-Supervised Framework for Misinformation Detection. (arXiv:2304.11318v1 [cs.AI])

    [http://arxiv.org/abs/2304.11318](http://arxiv.org/abs/2304.11318)

    这篇论文提出了一种半监督学习框架来解决虚假信息检测中的极端类别不平衡问题。这种方法使用实际而不是模拟数据来增加少数派类别数量，在 Covid 相关的 Twitter 数据上实验表明其可以显著提高 F1 值。

    

    社交媒体上虚假信息的传播已成为一种普遍的社会问题，是许多社会不安的原因。机器学习已经显示出显著的应用前景，但是在应用机器学习解决这个问题时存在两个主要挑战。首先，虚假信息在某种程度上的普及性使得它们在社交媒体上只占少数。其次，标记大量数据来训练一个有用的分类器变得不切实际。鉴于这些挑战，我们提出了一种简单的半监督学习框架，以处理极端的类别不平衡，其优点在于使用实际数据而不是模拟数据来增加少数派类别数量，相对于其他方法更优。我们在两组与 Covid 相关的 Twitter 数据上测试了我们的框架，在极度不平衡的情况下获得了显着的 F1 值提升。

    The spread of misinformation in social media outlets has become a prevalent societal problem and is the cause of many kinds of social unrest. Curtailing its prevalence is of great importance and machine learning has shown significant promise. However, there are two main challenges when applying machine learning to this problem. First, while much too prevalent in one respect, misinformation, actually, represents only a minor proportion of all the postings seen on social media. Second, labeling the massive amount of data necessary to train a useful classifier becomes impractical. Considering these challenges, we propose a simple semi-supervised learning framework in order to deal with extreme class imbalances that has the advantage, over other approaches, of using actual rather than simulated data to inflate the minority class. We tested our framework on two sets of Covid-related Twitter data and obtained significant improvement in F1-measure on extremely imbalanced scenarios, as compare
    
[^41]: 神经网络支持的模型预测控制在不匹配不确定性缓解方面的应用

    Unmatched uncertainty mitigation through neural network supported model predictive control. (arXiv:2304.11315v1 [cs.LG])

    [http://arxiv.org/abs/2304.11315](http://arxiv.org/abs/2304.11315)

    本文利用基于深度学习的模型预测控制算法，采用双时间尺度适应机制，结合深度神经网络作为预言机，实时估计不匹配的不确定性，成功地实现了对具有未知结构的不匹配和有界状态-动作相关不确定性的系统的控制。

    

    本文提出了一种基于深度学习的模型预测控制（MPC）算法，用于具有未知结构的不匹配和有界状态-动作相关不确定性的系统。我们利用深度神经网络（DNN）作为学习基础MPC（LBMPC）中的预言机，以估计不匹配的不确定性。由于实时估计其系数的技术困难，通常认为LBMPC难以使用非参数预言机，例如DNN。我们采用双时间尺度适应机制，在内部层以缓慢的时间尺度使用在线收集并有选择地存储在缓冲区中的训练数据进行训练，同时实时更新神经网络的最后一层的权重。我们通过对喷气发动机压缩系统模型的数值实验进行验证。这些结果表明，所提出的方法是可以实时实现的，并具有理论意义。

    This paper presents a deep learning based model predictive control (MPC) algorithm for systems with unmatched and bounded state-action dependent uncertainties of unknown structure. We utilize a deep neural network (DNN) as an oracle in the underlying optimization problem of learning based MPC (LBMPC) to estimate unmatched uncertainties. Generally, non-parametric oracles such as DNN are considered difficult to employ with LBMPC due to the technical difficulties associated with estimation of their coefficients in real time. We employ a dual-timescale adaptation mechanism, where the weights of the last layer of the neural network are updated in real time while the inner layers are trained on a slower timescale using the training data collected online and selectively stored in a buffer. Our results are validated through a numerical experiment on the compression system model of jet engine. These results indicate that the proposed approach is implementable in real time and carries the theore
    
[^42]: 基于前瞻扩散概率模型的均值估计方法优化

    Lookahead Diffusion Probabilistic Models for Refining Mean Estimation. (arXiv:2304.11312v1 [cs.AI])

    [http://arxiv.org/abs/2304.11312](http://arxiv.org/abs/2304.11312)

    本文提出基于前瞻扩散概率模型的技术来优化条件高斯分布的均值估计，通过对两个估计进行外推来计算更准确的估计值。该方法不需要对DNN模型进行微调，并在基准数据集上获得了比最新方法更好的实验结果。

    

    本论文提出了基于前瞻扩散概率模型（LA-DPMs）的技术，该技术利用了深度神经网络（DNNs）在扩散概率模型（DPMs）中，在连续时间步骤之后输出之间的相关性，以优化条件高斯分布的均值估计。我们提出了通过对两个$\boldsymbol{x}$估计进行外推来计算更准确的$\boldsymbol{x}$估计的方法。这可以通过在现有DPMs的后向过程中引入额外的连接来轻松将其集成到后向过程中，并且不需要对DNN模型进行微调。在几个基准数据集上的实验结果表明，与现有的最新方法相比，所提出的LA-DPMs方法是有效的。

    We propose lookahead diffusion probabilistic models (LA-DPMs) to exploit the correlation in the outputs of the deep neural networks (DNNs) over subsequent timesteps in diffusion probabilistic models (DPMs) to refine the mean estimation of the conditional Gaussian distributions in the backward process. A typical DPM first obtains an estimate of the original data sample $\boldsymbol{x}$ by feeding the most recent state $\boldsymbol{z}_i$ and index $i$ into the DNN model and then computes the mean vector of the conditional Gaussian distribution for $\boldsymbol{z}_{i-1}$. We propose to calculate a more accurate estimate for $\boldsymbol{x}$ by performing extrapolation on the two estimates of $\boldsymbol{x}$ that are obtained by feeding $(\boldsymbol{z}_{i+1},i+1)$ and $(\boldsymbol{z}_{i},i)$ into the DNN model. The extrapolation can be easily integrated into the backward process of existing DPMs by introducing an additional connection over two consecutive timesteps, and fine-tuning is n
    
[^43]: 人机交互中的非语言暗示：传播学视角

    Nonverbal Cues in Human-Robot Interaction: A Communication Studies Perspective. (arXiv:2304.11293v1 [cs.RO])

    [http://arxiv.org/abs/2304.11293](http://arxiv.org/abs/2304.11293)

    本文从传播学视角出发，提出人机交互中的五种非语言代码，并将其转化为设计模式。该研究认为，将这些非语言代码整合到机器人中可以使机器人更加“生动”和“社会化”，同时提出了未来的研究方向。

    

    人与人之间的交流除了语言之外，还包括广泛的非语言暗示。将这些暗示应用于设计与人交互的机器人和其他人工智能代理，可能会带来更自然、易理解和易接近的交互体验。本文提出了一系列定义性的非语言代码，以地址通信研究领域的五个人类感官系统（视、听、触、嗅、味），可以将这些代码翻译为人机交互的设计模式，使用精选的通信研究和人机交互文献。由于非语言代码是人类交流的重要方式之一，我们认为将机器人的非语言代码整合到人机交互中，将为机器人带来“生动感”或“社会代理”，否则机器人将缺乏这种体验。最后，我们提出了研究方向的建议，以促进非语言交流领域在人机交互中的发展和改进之间的沟通。

    Communication between people is characterized by a broad range of nonverbal cues. Transferring these cues into the design of robots and other artificial agents that interact with people may foster more natural, inviting, and accessible experiences. In this position paper, we offer a series of definitive nonverbal codes for human-robot interaction (HRI) that address the five human sensory systems (visual, auditory, haptic, olfactory, gustatory) drawn from the field of communication studies. We discuss how these codes can be translated into design patterns for HRI using a curated sample of the communication studies and HRI literatures. As nonverbal codes are an essential mode in human communication, we argue that integrating robotic nonverbal codes in HRI will afford robots a feeling of "aliveness" or "social agency" that would otherwise be missing. We end with suggestions for research directions to stimulate work on nonverbal communication within the field of HRI and improve communicati
    
[^44]: 关于应用评论中能源相关问题的识别

    On the Identification of the Energy related Issues from the App Reviews. (arXiv:2304.11292v1 [cs.AI])

    [http://arxiv.org/abs/2304.11292](http://arxiv.org/abs/2304.11292)

    本文研究了自动提取与能源相关的应用程序评论的不同技术。结果表明，神经网络优于其他机器学习模型。

    

    应用程序的能源效率问题可能会对应用程序用户造成重大问题，并在应用商店广泛讨论。之前的研究表明，研究与能源相关的应用程序评论以确定能源相关用户反馈的主要原因或类别的重要性。然而，还没有研究有效地自动提取与能源相关的应用程序评论。在本文中，我们经验性地研究了不同的技术，以自动提取与能源相关的用户反馈。我们比较了许多机器学习模型的准确性、F1分数和运行时间，并与相关特征组合和相对较新的基于神经网络的模型进行比较。总共比较了60个机器学习模型，以及使用六种神经网络架构和三种单词嵌入模型构建的30个模型。我们开发了一个可视化工具，通过该工具，开发人员可以遍历这个大规模的结果集。结果表明，神经网络优于其他机器学习模型。

    The energy inefficiency of the apps can be a major issue for the app users which is discussed on App Stores extensively. Previous research has shown the importance of investigating the energy related app reviews to identify the major causes or categories of energy related user feedback. However, there is no study that efficiently extracts the energy related app reviews automatically. In this paper, we empirically study different techniques for automatic extraction of the energy related user feedback. We compare the accuracy, F1-score and run time of numerous machine-learning models with relevant feature combinations and relatively modern Neural Network-based models. In total, 60 machine learning models are compared to 30 models that we build using six neural network architectures and three word embedding models. We develop a visualization tool for this study through which a developer can traverse through this large-scale result set. The results show that neural networks outperform the 
    
[^45]: 机器学习模型适当的知识产权保护机制的辨别：针对水印、指纹、模型访问和攻击的系统化分析

    Identifying Appropriate Intellectual Property Protection Mechanisms for Machine Learning Models: A Systematization of Watermarking, Fingerprinting, Model Access, and Attacks. (arXiv:2304.11285v1 [cs.LG])

    [http://arxiv.org/abs/2304.11285](http://arxiv.org/abs/2304.11285)

    本文系统化分析了机器学习模型在知识产权保护方面的挑战，提出了针对水印、指纹、模型访问和攻击的保护技术，并构建了综合的威胁模型。

    

    机器学习（ML）的商业应用越来越普及；同时，ML模型变得越来越复杂，而且训练成本越来越高，这使得训练模型的知识产权保护（IPP）成为一个紧迫的问题。与其他领域可以建立在对其IP进行保护的威胁、攻击和防御措施有着深刻理解的基础上不同，机器学习领域的相关研究仍然非常零散。这也是由于缺少统一的视角以及这些方面的共同分类学。在本文中，我们系统化了我们在ML中关于IPP的发现，同时专注于编写时已确认的威胁、攻击和防御措施。我们为ML中的IP建立了综合的威胁模型，将攻击和防御措施分类到统一和整合的分类法中，从而搭起了来自ML和安全社区的研究之间的桥梁。

    The commercial use of Machine Learning (ML) is spreading; at the same time, ML models are becoming more complex and more expensive to train, which makes Intellectual Property Protection (IPP) of trained models a pressing issue. Unlike other domains that can build on a solid understanding of the threats, attacks and defenses available to protect their IP, the ML-related research in this regard is still very fragmented. This is also due to a missing unified view as well as a common taxonomy of these aspects.  In this paper, we systematize our findings on IPP in ML, while focusing on threats and attacks identified and defenses proposed at the time of writing. We develop a comprehensive threat model for IP in ML, categorizing attacks and defenses within a unified and consolidated taxonomy, thus bridging research from both the ML and security communities.
    
[^46]: 基于反误信息智能体的共识解释中的信任与依赖

    Trust and Reliance in Consensus-Based Explanations from an Anti-Misinformation Agent. (arXiv:2304.11279v1 [cs.HC])

    [http://arxiv.org/abs/2304.11279](http://arxiv.org/abs/2304.11279)

    本文探讨了基于人工智能的智能代理在反误信息方面对共识幻觉的影响，并发现依赖（行为）会影响基于共识的解释，这对使用XAI的反误信息系统的设计指导有意义。

    

    “共识幻觉”指的是人们认为多个来源都达成了一致，但实际上这些来源是相同的，因此不存在“真正”的一致。本文研究了帮助提高社交媒体元认知的基于人工智能的智能代理的情况下，这种现象的存在。在Twitter等平台上，虚假信息是一个全球性的问题，目前还没有一个好的解决方案。作为一个可解释的人工智能（XAI）系统，智能代理在对社交媒体内容的错误判断上提供解释。在这项研究中，我们探讨了信任（态度）和依赖（行为）作为XAI用户体验（UX）的关键因素，以及这些因素是否会影响共识幻觉。研究结果显示，信任没有影响，但依赖对基于共识的解释有影响。该研究可指导使用XAI的反误信息系统的设计，特别是解释的用户中心设计。

    The illusion of consensus occurs when people believe there is consensus across multiple sources, but the sources are the same and thus there is no "true" consensus. We explore this phenomenon in the context of an AI-based intelligent agent designed to augment metacognition on social media. Misinformation, especially on platforms like Twitter, is a global problem for which there is currently no good solution. As an explainable AI (XAI) system, the agent provides explanations for its decisions on the misinformed nature of social media content. In this late-breaking study, we explored the roles of trust (attitude) and reliance (behaviour) as key elements of XAI user experience (UX) and whether these influenced the illusion of consensus. Findings show no effect of trust, but an effect of reliance on consensus-based explanations. This work may guide the design of anti-misinformation systems that use XAI, especially the user-centred design of explanations.
    
[^47]: PyTorch FSDP：全面分片数据并行规模化的经验

    PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel. (arXiv:2304.11277v1 [cs.DC])

    [http://arxiv.org/abs/2304.11277](http://arxiv.org/abs/2304.11277)

    本论文介绍了基于PyTorch的Fully Sharded Data Parallel（FSDP）解决方案，该方案可扩展大型模型训练，并优化各种硬件配置的资源利用率。

    

    众所周知，大型模型在广泛领域内具有优异的性能潜力。尽管机器学习系统研究领域取得了显著进展，使得开发和探索大型模型成为可能，但这些能力仍受限于少数高级用户和行业领袖，导致技术上的隐含壁垒阻碍广泛社区访问和利用这些技术。本文介绍了PyTorch Fully Sharded Data Parallel（FSDP）作为大型模型训练的产业级解决方案。FSDP已与几个关键PyTorch核心组件（包括张量实现、分发器系统和CUDA内存缓存分配器）密切协作，以提供非侵入式用户体验和高训练效率。此外，FSDP本地集成了一系列技术和设置，优化了各种硬件配置的资源利用率。

    It is widely acknowledged that large models have the potential to deliver superior performance across a broad range of domains. Despite the remarkable progress made in the field of machine learning systems research, which has enabled the development and exploration of large models, such abilities remain confined to a small group of advanced users and industry leaders, resulting in an implicit technical barrier for the wider community to access and leverage these technologies. In this paper, we introduce PyTorch Fully Sharded Data Parallel (FSDP) as an industry-grade solution for large model training. FSDP has been closely co-designed with several key PyTorch core components including Tensor implementation, dispatcher system, and CUDA memory caching allocator, to provide non-intrusive user experiences and high training efficiency. Additionally, FSDP natively incorporates a range of techniques and settings to optimize resource utilization across a variety of hardware configurations. The 
    
[^48]: 自然分布漂移下低样本稳健性的基准测试

    Benchmarking Low-Shot Robustness to Natural Distribution Shifts. (arXiv:2304.11263v1 [cs.CV])

    [http://arxiv.org/abs/2304.11263](http://arxiv.org/abs/2304.11263)

    本文通过对不同少样本数据集、架构、预训练初始化和稳健性干预的自然分布漂移的稳健性进行了首次深入研究，发现没有单一的选择模型比其他模型更稳健，现有的干预措施也可能无法提高某些数据集的稳健性。

    

    近年来，结合更好的微调方法的预训练策略已经取得了针对自然分布漂移的鲁棒性的显著进展。然而，这样的微调假设可以访问大量标记数据，而当训练数据量不高时观察到的情况尚不清楚。我们通过对不同少样本数据集、架构、预训练初始化和最先进的稳健性干预的自然分布漂移的稳健性进行了首次深入研究，填补了这一空白。最重要的是，我们发现没有单一的选择模型比其他模型更稳健，即使在完整样本下，现有的干预措施也可能无法提高某些数据集的稳健性。我们希望我们的工作能够激励社区关注这个实际重要性的问题。

    Robustness to natural distribution shifts has seen remarkable progress thanks to recent pre-training strategies combined with better fine-tuning methods. However, such fine-tuning assumes access to large amounts of labelled data, and the extent to which the observations hold when the amount of training data is not as high remains unknown. We address this gap by performing the first in-depth study of robustness to various natural distribution shifts in different low-shot regimes: spanning datasets, architectures, pre-trained initializations, and state-of-the-art robustness interventions. Most importantly, we find that there is no single model of choice that is often more robust than others, and existing interventions can fail to improve robustness on some datasets even if they do so in the full-shot regime. We hope that our work will motivate the community to focus on this problem of practical importance.
    
[^49]: eWaSR——一种嵌入式计算准备好的海事障碍物检测网络

    eWaSR -- an embedded-compute-ready maritime obstacle detection network. (arXiv:2304.11249v1 [cs.CV])

    [http://arxiv.org/abs/2304.11249](http://arxiv.org/abs/2304.11249)

    本论文提出了一种嵌入式计算准备好的海事障碍物检测网络——eWaSR，能够在保证检测质量的前提下运行速度更快，且在F1得分方面也优于其他目前最先进的嵌入式就绪架构。

    

    海事障碍物检测对于自主水面船舶（ASV）的安全导航至关重要。虽然基于图像的检测方法的准确性已经大大提高，但它们的计算和内存要求阻止了在嵌入式设备上的部署。在本文中，我们对当前表现最佳的海事障碍物检测网络WaSR进行了分析。在分析基础上，我们提出替换最耗计算资源的阶段并提出其嵌入式计算准备好的变体eWaSR。特别地，新设计遵循了基于transformer的轻量级网络的最新进展。eWaSR在仅有0.52％的F1得分性能下降的情况下实现了与最先进的WaSR相当的检测结果，并在F1得分方面优于其他最先进的嵌入式就绪架构高达9.74％。在标准GPU上，eWaSR的运行速度比原始WaSR快10倍（115 FPS vs 11 FPS）。在OAK-D实际嵌入式设备上的测试表明，尽管WaSR由于内存限制而无法运行，但eWaSR仍然能够表现出色。

    Maritime obstacle detection is critical for safe navigation of autonomous surface vehicles (ASVs). While the accuracy of image-based detection methods has advanced substantially, their computational and memory requirements prohibit deployment on embedded devices. In this paper we analyze the currently best-performing maritime obstacle detection network WaSR. Based on the analysis we then propose replacements for the most computationally intensive stages and propose its embedded-compute-ready variant eWaSR. In particular, the new design follows the most recent advancements of transformer-based lightweight networks. eWaSR achieves comparable detection results to state-of-the-art WaSR with only 0.52% F1 score performance drop and outperforms other state-of-the-art embedded-ready architectures by over 9.74% in F1 score. On a standard GPU, eWaSR runs 10x faster than the original WaSR (115 FPS vs 11 FPS). Tests on a real embedded device OAK-D show that, while WaSR cannot run due to memory re
    
[^50]: AI政策的可解释性：欧盟、美国和英国通信、报告、规则和标准的批判性审查

    Explainability in AI Policies: A Critical Review of Communications, Reports, Regulations, and Standards in the EU, US, and UK. (arXiv:2304.11218v1 [cs.CY])

    [http://arxiv.org/abs/2304.11218](http://arxiv.org/abs/2304.11218)

    本文对欧盟、美国和英国关于AI可解释性的政策和标准文献进行了主题和差距分析，旨在解决由于缺乏共同的监管基线和解释的情境性而难以采用的可解释性产出的问题。

    

    近年来，公众对人工智能（AI）系统的可解释性引起了越来越多的关注，以提供人类监督的方法。这已经转化为大量的研究成果，例如来自可解释AI的成果，以增强系统的透明度和控制，进行系统调试和监控，并提高用户服务的系统流程和输出的可理解性。然而，由于缺乏共同的监管基线和解释的情境性，这些产出在实践层面上很难采用。政府政策现在正在尝试解决这一迫切需求，然而，发表的通信、规章和标准在多大程度上采用了有根据的观点，支持研究、产业和公民利益，这仍然不清楚。在本研究中，我们对欧盟、美国和英国的可解释性政策和标准文献进行了首次主题和差距分析。通过对政策文件进行严格的调查，我们首先对这个大量的政策和标准做出了一个贡献。

    Public attention towards explainability of artificial intelligence (AI) systems has been rising in recent years to offer methodologies for human oversight. This has translated into the proliferation of research outputs, such as from Explainable AI, to enhance transparency and control for system debugging and monitoring, and intelligibility of system process and output for user services. Yet, such outputs are difficult to adopt on a practical level due to a lack of a common regulatory baseline, and the contextual nature of explanations. Governmental policies are now attempting to tackle such exigence, however it remains unclear to what extent published communications, regulations, and standards adopt an informed perspective to support research, industry, and civil interests. In this study, we perform the first thematic and gap analysis of this plethora of policies and standards on explainability in the EU, US, and UK. Through a rigorous survey of policy documents, we first contribute an
    
[^51]: ACROCPoLis: 一个用于公平性分析的描述性框架

    ACROCPoLis: A Descriptive Framework for Making Sense of Fairness. (arXiv:2304.11217v1 [cs.CY])

    [http://arxiv.org/abs/2304.11217](http://arxiv.org/abs/2304.11217)

    ACROCPoLis框架提供了一个共享词汇，明确了不同情况和程序的公平评估相关因素及其相互关系，让我们能够比较类似的情况，确定影响不同边缘化群体的因素。

    

    公平对于人工智能系统的道德和负责任的开发和使用至关重要，有许多算法公平的框架和形式概念可用。然而，许多提出的公平性解决方案都围绕技术考虑，而不是对最受影响社区的需求和后果。因此，我们想把重点转移到定义之外，并允许包括社会和关系方面，以表示AI系统的影响如何影响个人和社会群体。我们通过提出ACROCPoLis框架来通过建模强调公平性方面，从而实现这一点。该框架提供了一个共享词汇，明确了不同情况和程序的公平评估相关因素及其相互关系。这使我们能够比较类似的情况，突出差异，以及确定影响不同边缘化群体的因素。

    Fairness is central to the ethical and responsible development and use of AI systems, with a large number of frameworks and formal notions of algorithmic fairness being available. However, many of the fairness solutions proposed revolve around technical considerations and not the needs of and consequences for the most impacted communities. We therefore want to take the focus away from definitions and allow for the inclusion of societal and relational aspects to represent how the effects of AI systems impact and are experienced by individuals and social groups. In this paper, we do this by means of proposing the ACROCPoLis framework to represent allocation processes with a modeling emphasis on fairness aspects. The framework provides a shared vocabulary in which the factors relevant to fairness assessments for different situations and procedures are made explicit, as well as their interrelationships. This enables us to compare analogous situations, to highlight the differences in dissim
    
[^52]: ChatGPT：不只是一种大规模欺骗武器，基于人本主义人工智能（HCAI）视角的伦理挑战与应对

    ChatGPT: More than a Weapon of Mass Deception, Ethical challenges and responses from the Human-Centered Artificial Intelligence (HCAI) perspective. (arXiv:2304.11215v1 [cs.CY])

    [http://arxiv.org/abs/2304.11215](http://arxiv.org/abs/2304.11215)

    本文探讨了将ChatGPT作为一种生成式人工智能所带来的伦理问题，提出了采取技术（数字水印、样式化、检测器和事实核查器）和非技术措施（使用条款、透明度和用户教育）来减轻其可能成为大规模欺骗武器和促进欺诈犯罪的危险。

    

    本文探讨了将ChatGPT作为一种生成式人工智能所产生的伦理问题，并提出了基于人本主义人工智能框架的应对。该框架理解技术首先是一种赋能、增强和提升人类机能的工具，同时将人类福祉作为一个重大挑战，完全与伦理学，即人类繁荣的科学相一致。此外，HCAI为可靠、安全和值得信赖的人工智能提供了目标、原则、程序和结构，我们将其应用于我们的ChatGPT评估中。ChatGPT所带来的主要危险是成为一种大规模欺骗（WMD）武器和涉及欺诈的犯罪活动的促进因素。我们回顾了技术规格以更好地理解它的潜力和局限性。然后我们建议实施技术措施（数字水印、样式化、检测器和事实核查器）和非技术措施（使用条款、透明度和用户教育）来减轻ChatGPT所带来的伦理挑战。

    This article explores the ethical problems arising from the use of ChatGPT as a kind of generative AI and suggests responses based on the Human-Centered Artificial Intelligence (HCAI) framework. The HCAI framework is appropriate because it understands technology above all as a tool to empower, augment, and enhance human agency while referring to human wellbeing as a grand challenge, thus perfectly aligning itself with ethics, the science of human flourishing. Further, HCAI provides objectives, principles, procedures, and structures for reliable, safe, and trustworthy AI which we apply to our ChatGPT assessments. The main danger ChatGPT presents is the propensity to be used as a weapon of mass deception (WMD) and an enabler of criminal activities involving deceit. We review technical specifications to better comprehend its potentials and limitations. We then suggest both technical (watermarking, styleme, detectors, and fact-checkers) and non-technical measures (terms of use, transparenc
    
[^53]: 探索在本科计算机科学课程中将ChatGPT用作学习和评估工具的机会和挑战

    Exploring the Use of ChatGPT as a Tool for Learning and Assessment in Undergraduate Computer Science Curriculum: Opportunities and Challenges. (arXiv:2304.11214v1 [cs.CY])

    [http://arxiv.org/abs/2304.11214](http://arxiv.org/abs/2304.11214)

    本文讨论了将ChatGPT用作本科计算机科学课程学习和评估工具的前景和障碍，通过对数据结构和算法课程的学生进行短期编程任务的调查，证明了ChatGPT能够提升学生的参与度、合作性、可访问性和可用性。

    

    在计算机教育领域，应用人工智能进行教学和学习是一个备受关注的趋势。作为一种基于人工智能的工具，ChatGPT提供了许多优势，如增强了学生的参与度、合作性、可访问性和可用性。本文就在本科计算机科学课程中将ChatGPT用作学习和评估工具的前景和障碍进行了讨论，特别是在教授基础编程课程方面。本研究针对已完成数据结构和算法（一门二年级课程）课程作业的学生进行了研究。两组学生被要求在短时间内解决编程挑战问题。对照组（A组）只有编程课程的课本和笔记，并没有提供互联网访问权限。而B组的学生可以使用ChatGPT，并鼓励他们使用它来帮助解决问题。

    The application of Artificial intelligence for teaching and learning in the academic sphere is a trending subject of interest in the computing education. ChatGPT, as an AI-based tool, provides various advantages, such as heightened student involvement, cooperation, accessibility and availability. This paper addresses the prospects and obstacles associated with utilizing ChatGPT as a tool for learning and assessment in undergraduate Computer Science curriculum in particular to teaching and learning fundamental programming courses. Students having completed the course work for a Data Structures and Algorithms (a sophomore level course) participated in this study. Two groups of students were given programming challenges to solve within a short period of time. The control group (group A) had access to text books and notes of programming courses, however no Internet access was provided. Group B students were given access to ChatGPT and were encouraged to use it to help solve the programming
    
[^54]: SSS3D：快速的神经体系结构搜索，用于高效三维语义分割。

    SSS3D: Fast Neural Architecture Search For Efficient Three-Dimensional Semantic Segmentation. (arXiv:2304.11207v1 [cs.CV])

    [http://arxiv.org/abs/2304.11207](http://arxiv.org/abs/2304.11207)

    SSS3D是为了高效三维语义场景分割而设计的快速多目标神经体系结构搜索框架，它使用超级网络RandLA-Net实现权重共享并显著减少搜索时间，通过两个阶段搜索在更短的时间内找到最佳子网络。

    

    我们提出了SSS3D，这是一个快速的多目标NAS框架，专为查找计算效率高的三维语义场景分割网络而设计。它使用RandLA-Net作为超级网络，以实现权重共享，并通过单阶段搜索将搜索时间减少99.67％。SSS3D具有复杂的搜索空间，由采样和架构参数组成，可以形成2.88*10^17种可能的网络。为了进一步减少搜索时间，SSS3D将完整的搜索空间分成两个阶段，以单阶段搜索所需时间的54％找到最佳子网络。

    We present SSS3D, a fast multi-objective NAS framework designed to find computationally efficient 3D semantic scene segmentation networks. It uses RandLA-Net, an off-the-shelf point-based network, as a super-network to enable weight sharing and reduce search time by 99.67% for single-stage searches. SSS3D has a complex search space composed of sampling and architectural parameters that can form 2.88 * 10^17 possible networks. To further reduce search time, SSS3D splits the complete search space and introduces a two-stage search that finds optimal subnetworks in 54% of the time required by single-stage searches.
    
[^55]: 快速GraspNeXt：用于边缘计算机器人抓取的多任务视觉学习的快速自注意神经网络架构

    Fast GraspNeXt: A Fast Self-Attention Neural Network Architecture for Multi-task Learning in Computer Vision Tasks for Robotic Grasping on the Edge. (arXiv:2304.11196v1 [cs.CV])

    [http://arxiv.org/abs/2304.11196](http://arxiv.org/abs/2304.11196)

    本文提出了一种针对边缘计算机器人抓取的计算机视觉任务定制的多任务深度自注意神经网络架构，名为快速GraspNeXt。实验表明，快速GraspNeXt在精度和速度方面表现优异。

    

    多任务学习已经被证明可以显著提高深度学习驱动的视觉系统在机器人抓取方面的性能。然而，高架构和计算复杂度可能导致在实际制造和仓库环境中通常用于机器人手臂的嵌入式设备上部署效果较差。因此，设计高效的、针对边缘计算机器人抓取的计算机视觉任务定制的多任务深度神经网络架构对于在制造环境中的广泛应用非常必要。为此，我们提出了快速GraspNeXt，一种针对嵌入式多任务学习的快速自注意神经网络架构，用于计算机视觉任务的机器人抓取。通过采用一个基于生成网络架构搜索策略和一组用于实现多任务学习性能和计算效率高度平衡的架构约束，我们构建了快速GraspNeXt。我们的实验结果表明，当在边缘设备上进行评估时，快速GraspNeXt在精度和速度方面均优于目前的最先进方法。

    Multi-task learning has shown considerable promise for improving the performance of deep learning-driven vision systems for the purpose of robotic grasping. However, high architectural and computational complexity can result in poor suitability for deployment on embedded devices that are typically leveraged in robotic arms for real-world manufacturing and warehouse environments. As such, the design of highly efficient multi-task deep neural network architectures tailored for computer vision tasks for robotic grasping on the edge is highly desired for widespread adoption in manufacturing environments. Motivated by this, we propose Fast GraspNeXt, a fast self-attention neural network architecture tailored for embedded multi-task learning in computer vision tasks for robotic grasping. To build Fast GraspNeXt, we leverage a generative network architecture search strategy with a set of architectural constraints customized to achieve a strong balance between multi-task learning performance a
    
[^56]: 视觉和触觉感觉相结合的视频预测

    Combining Vision and Tactile Sensation for Video Prediction. (arXiv:2304.11193v1 [cs.RO])

    [http://arxiv.org/abs/2304.11193](http://arxiv.org/abs/2304.11193)

    本文研究将触觉反馈集成到物理机器人交互的视频预测模型中的影响，并介绍了两个新的机器人推动数据集，使用基于磁性的触觉传感器进行无监督学习。

    

    本文探讨将触觉感觉添加到物理机器人交互的视频预测模型中的影响。预测机器人行为对环境的影响是机器人技术中的关键挑战。目前的方法利用视觉和机器人动作数据来生成一定时间段内的视频预测，然后可以用于调整机器人动作。然而，人类依赖于视觉和触觉反馈来发展和维护他们对物理环境的心理模型。本文研究了将触觉反馈集成到物理机器人交互的视频预测模型中的影响。我们提出了三种多模态集成方法，并比较了这些触觉增强的视频预测模型的表现。此外，我们还介绍了两个新的机器人推动数据集，使用基于磁性的触觉传感器进行无监督学习。第一个数据集包含具有不同物理特性的视觉上相同的对象，第二个数据集用于测试模型的泛化性能。

    In this paper, we explore the impact of adding tactile sensation to video prediction models for physical robot interactions. Predicting the impact of robotic actions on the environment is a fundamental challenge in robotics. Current methods leverage visual and robot action data to generate video predictions over a given time period, which can then be used to adjust robot actions. However, humans rely on both visual and tactile feedback to develop and maintain a mental model of their physical surroundings. In this paper, we investigate the impact of integrating tactile feedback into video prediction models for physical robot interactions. We propose three multi-modal integration approaches and compare the performance of these tactile-enhanced video prediction models. Additionally, we introduce two new datasets of robot pushing that use a magnetic-based tactile sensor for unsupervised learning. The first dataset contains visually identical objects with different physical properties, whil
    
[^57]: 基于任务自适应伪标签的跨感知元学习

    Task-Adaptive Pseudo Labeling for Transductive Meta-Learning. (arXiv:2304.11173v1 [cs.LG])

    [http://arxiv.org/abs/2304.11173](http://arxiv.org/abs/2304.11173)

    本文提出了一种名为“任务自适应伪标签”的跨感知元学习方法，利用伪标签生成未标记的查询集，使用监督设置并利用未标记的查询集，可以处理更多实例，从而带来更好的分类性能。

    

    元学习通过有限数量的支持集来进行适应性学习，这可能会导致样本偏差问题。为了解决这个问题，跨感知元学习越来越受到关注，超越了传统的感知性学习视角。本文提出了一种称为“任务自适应伪标签”的跨感知元学习方法。具体而言，利用标记的支持集生成未标记的查询集的伪标签，借此使得在适应过程中可以采用监督设置并利用未标记的查询集。结果，该方法比感知性方法能够处理更多的示例，从而可以产生更好的分类性能。需要注意的是，该提出的方法是首个将任务自适应应用于伪标签的方法。实验证明，该方法在5路1-shot few-shot中胜过了现有技术。

    Meta-learning performs adaptation through a limited amount of support set, which may cause a sample bias problem. To solve this problem, transductive meta-learning is getting more and more attention, going beyond the conventional inductive learning perspective. This paper proposes so-called task-adaptive pseudo labeling for transductive meta-learning. Specifically, pseudo labels for unlabeled query sets are generated from labeled support sets through label propagation. Pseudo labels enable to adopt the supervised setting as it is and also use the unlabeled query set in the adaptation process. As a result, the proposed method is able to deal with more examples in the adaptation process than inductive ones, which can result in better classification performance of the model. Note that the proposed method is the first approach of applying task adaptation to pseudo labeling. Experiments show that the proposed method outperforms the state-of-the-art (SOTA) technique in 5-way 1-shot few-shot 
    
[^58]: 颗粒球计算：一种高效、鲁棒和可解释的自适应多粒度表示和计算方法

    Granular ball computing: an efficient, robust, and interpretable adaptive multi-granularity representation and computation method. (arXiv:2304.11171v1 [cs.LG])

    [http://arxiv.org/abs/2304.11171](http://arxiv.org/abs/2304.11171)

    本文提出了一种基于颗粒球计算的自适应多粒度表示和计算方法，能够提高机器学习的效率、鲁棒性和可解释性。

    

    人类认知具有“先大后小”的认知机制，因此具有自适应的多粒度描述能力。这导致了有效性、鲁棒性和可解释性等计算特性。本文提出了一种新的基于颗粒球计算的自适应多粒度表示和计算方法。他们将这种方法应用于几个机器学习任务，并证明其相对于其他最先进的方法的有效性。

    Human cognition has a ``large-scale first'' cognitive mechanism, therefore possesses adaptive multi-granularity description capabilities. This results in computational characteristics such as efficiency, robustness, and interpretability. Although most existing artificial intelligence learning methods have certain multi-granularity features, they do not fully align with the ``large-scale first'' cognitive mechanism. Multi-granularity granular-ball computing is an important model method developed in recent years. This method can use granular-balls of different sizes to adaptively represent and cover the sample space, and perform learning based on granular-balls. Since the number of coarse-grained "granular-ball" is smaller than the number of sample points, granular-ball computing is more efficient; the coarse-grained characteristics of granular-balls are less likely to be affected by fine-grained sample points, making them more robust; the multi-granularity structure of granular-balls ca
    
[^59]: 辩证语言模型评估：对LLMs通识空间推理能力的初步评估

    Dialectical language model evaluation: An initial appraisal of the commonsense spatial reasoning abilities of LLMs. (arXiv:2304.11164v1 [cs.CL])

    [http://arxiv.org/abs/2304.11164](http://arxiv.org/abs/2304.11164)

    本文介绍了一种辩证评估方式，旨在描绘语言模型系统失败的边界并检查其一致性，以及对LLMs通识空间推理能力进行了初步定性研究。

    

    最近语言模型非常受欢迎，并且其能力得到了许多赞誉，包括通识推理。鉴于当前语言模型在以往通识推理静态基准上取得越来越好的结果，我们探索了一种另类的辩证评估方式。这种评估的目标不是获得一个总体性能值，而是找到失败的地方并描绘系统的边界。与系统对话可以检查其一致性，并获得越过单一证据的边界保证。在本文中，我们就空间推理（通识推理的基本方面）的特定情况进行了一些定性研究。结论包括对未来工作的一些建议，旨在提高语言模型的能力并将这种辩证评估系统化。

    Language models have become very popular recently and many claims have been made about their abilities, including for commonsense reasoning. Given the increasingly better results of current language models on previous static benchmarks for commonsense reasoning, we explore an alternative dialectical evaluation. The goal of this kind of evaluation is not to obtain an aggregate performance value but to find failures and map the boundaries of the system. Dialoguing with the system gives the opportunity to check for consistency and get more reassurance of these boundaries beyond anecdotal evidence. In this paper we conduct some qualitative investigations of this kind of evaluation for the particular case of spatial reasoning (which is a fundamental aspect of commonsense reasoning). We conclude with some suggestions for future work both to improve the capabilities of language models and to systematise this kind of dialectical evaluation.
    
[^60]: Graph-ToolFormer: 通过ChatGPT增强的提示，赋予LLMs图形推理能力

    Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT. (arXiv:2304.11116v1 [cs.AI])

    [http://arxiv.org/abs/2304.11116](http://arxiv.org/abs/2304.11116)

    本文旨在通过Graph-ToolFormer框架赋予LLMs图形推理能力，并解决现有LLMs在执行图形学习任务中存在的固有弱点。

    

    本文旨在开发一个能够对复杂图形数据进行推理的大语言模型（LLM）。当前，LLMs在各种自然语言学习任务上取得了非常出色的表现，这些扩展也已被应用于研究具有多模态数据的视觉任务。然而，在图形学习任务中，现有的LLMs由于在执行多步逻辑推理、精确的数学计算以及对空间和时间因素的感知方面存在一些固有弱点，因此呈现出非常严重的缺陷。为了解决这些挑战，本文将调查探索赋予现有LLMs图形推理能力的原理、方法和算法，这将对LLMs和图形学习的当前研究产生巨大影响。受最新的ChatGPT和Toolformer模型的启发，我们提出了Graph-ToolFormer（面向图形推理的Toolformer）框架，通过ChatGPT增强的提示来教导LLMs自身，旨在培养他们的图形推理能力。

    In this paper, we aim to develop a large language model (LLM) with the reasoning ability on complex graph data. Currently, LLMs have achieved very impressive performance on various natural language learning tasks, extensions of which have also been applied to study the vision tasks with multi-modal data. However, when it comes to the graph learning tasks, existing LLMs present very serious flaws due to their several inherited weaknesses in performing {multi-step logic reasoning}, {precise mathematical calculation} and {perception about the spatial and temporal factors}.  To address such challenges, in this paper, we will investigate the principles, methodologies and algorithms to empower existing LLMs with graph reasoning ability, which will have tremendous impacts on the current research of both LLMs and graph learning. Inspired by the latest ChatGPT and Toolformer models, we propose the Graph-ToolFormer (Graph Reasoning oriented Toolformer) framework to teach LLMs themselves with pro
    
[^61]: 预测中的外在数据：一种用于关联评估的FARM方法

    Exogenous Data in Forecasting: FARM -- An Approach for Relevance Evaluation. (arXiv:2304.11028v1 [eess.SP])

    [http://arxiv.org/abs/2304.11028](http://arxiv.org/abs/2304.11028)

    该论文介绍了一种名为FARM的方法，用于有效处理实时数据流并提供平衡的相关性度量，进而确定外部数据在预测中的重要性。

    

    外在数据被认为在提高预测准确性方面起着关键作用。针对恰当的选择，全面的相关性分析是一个基本的第一步，从外在数据与参考时间序列的相似性开始。受现有时间序列相似性指标的启发，我们介绍了一种名为FARM（前向角相关度量）的新方法，能够有效地处理实时数据流。我们的前向方法依赖于一种角度特征，该特征利用后续数据点的变化比较来对齐经过时间变形的序列。所提出的算法结合了本地和全局指标，提供了一个平衡的相关性度量。这导致将部分、中间匹配也视为外在数据序列重要指标的考虑因素。作为第一步验证，我们介绍了我们的FARM方法对合成但具有代表性的信号和真实世界时间序列记录的应用。同时展示了FARM方法提高了预测准确度的结果。

    Exogenous data is believed to play a key role for increasing forecasting accuracy. For an appropriate selection, a throughout relevance analysis is a fundamental first step, starting from the exogenous data similarity with the reference time series. Inspired by existing metrics for time series similarity, we introduce a new approach named FARM - Forward Angular Relevance Measure, able to effectively deal with real-time data streams. Our forward method relies on an angular feature that compares changes in subsequent data points to align time-warped series in an efficient way. The proposed algorithm combines local and global measures to provide a balanced relevance measure. This results in considering also partial, intermediate matches as relevant indicators for exogenous data series significance. As a first validation step, we present the application of our FARM approach to both synthetic but representative signals and real-world time series recordings. While demonstrating the improved 
    
[^62]: 基于间接通信的联邦学习中的客户端分配和无人机路径规划

    Joint Client Assignment and UAV Route Planning for Indirect-Communication Federated Learning. (arXiv:2304.10744v1 [cs.DC])

    [http://arxiv.org/abs/2304.10744](http://arxiv.org/abs/2304.10744)

    提出了一种新的FedEx框架，利用无人机等移动传输器建立间接通信通道，在解决客户端和服务器之间无法直接通信的问题时，本文提出了一种联合客户端分配和无人机路径规划的方法，最小化整体训练时间和通信成本。

    

    联邦学习是一种机器学习方法，可以创建用于强大应用程序的共享模型，同时允许数据保留在设备上，提供了改进的数据隐私性、安全性和降低的延迟等优点。然而，在某些系统中，客户端和服务器之间的直接通信可能不可能，例如没有适当通信基础设施的远程地区。为了解决这一问题，提出了一种新的框架 FedEx（通过模型传递实现联邦学习），这个框架利用移动传输器，如无人机，建立了服务器和客户端之间的间接通信通道。这些传输器作为中介，允许模型信息的交换。间接通信的使用为收敛分析和优化带来了新的挑战，因为传输器运动引入的延迟对全局模型分发和本地模型收集都会产生问题。为了解决这些问题，本文提出了一种联合客户端分配和无人机路径规划方法，优化了移动传输器的使用，同时最小化总体训练时间和通信成本。

    Federated Learning (FL) is a machine learning approach that enables the creation of shared models for powerful applications while allowing data to remain on devices. This approach provides benefits such as improved data privacy, security, and reduced latency. However, in some systems, direct communication between clients and servers may not be possible, such as remote areas without proper communication infrastructure. To overcome this challenge, a new framework called FedEx (Federated Learning via Model Express Delivery) is proposed. This framework employs mobile transporters, such as UAVs, to establish indirect communication channels between the server and clients. These transporters act as intermediaries and allow for model information exchange. The use of indirect communication presents new challenges for convergence analysis and optimization, as the delay introduced by the transporters' movement creates issues for both global model dissemination and local model collection. To addre
    
[^63]: 使用Z3进行FNN全局鲁棒性的形式化建模和验证

    Using Z3 for Formal Modeling and Verification of FNN Global Robustness. (arXiv:2304.10558v1 [cs.LG])

    [http://arxiv.org/abs/2304.10558](http://arxiv.org/abs/2304.10558)

    本文介绍了使用Z3求解器对全局鲁棒性可验证框架DeepGlobal进行更明确的定义和优化的工作，来建立FNN的形式化模型，以实现更有效的验证。

    

    虽然前馈神经网络（FNN）在各种任务中取得了显著的成功，但它们对对抗样本很容易受到攻击。已经开发了几种技术来验证FNN的对抗鲁棒性，但大多数技术都集中在针对单个数据点的局部扰动邻域的鲁棒性验证上。全局鲁棒性分析仍存在较大的研究空白。DeepGlobal是一种全局鲁棒性可验证框架，旨在确定FNN的所有可能的对抗危险区域（ADR），不限于测试集中的数据样本。本文提出了DeepGlobal的完整规范和实现，利用SMT求解器Z3进行更明确的定义，并提出了几项改进以进行更高效的验证。为了评估我们的实现和改进的有效性，我们对一组基准数据集进行了广泛的实验。我们的实验结果进行了可视化。

    While Feedforward Neural Networks (FNNs) have achieved remarkable success in various tasks, they are vulnerable to adversarial examples. Several techniques have been developed to verify the adversarial robustness of FNNs, but most of them focus on robustness verification against the local perturbation neighborhood of a single data point. There is still a large research gap in global robustness analysis. The global-robustness verifiable framework DeepGlobal has been proposed to identify \textit{all} possible Adversarial Dangerous Regions (ADRs) of FNNs, not limited to data samples in a test set. In this paper, we propose a complete specification and implementation of DeepGlobal utilizing the SMT solver Z3 for more explicit definition, and propose several improvements to DeepGlobal for more efficient verification. To evaluate the effectiveness of our implementation and improvements, we conduct extensive experiments on a set of benchmark datasets. Visualization of our experiment results s
    
[^64]: Transformer介绍

    An Introduction to Transformers. (arXiv:2304.10557v1 [cs.LG])

    [http://arxiv.org/abs/2304.10557](http://arxiv.org/abs/2304.10557)

    Transformer是一种神经网络组件，可以学习序列或数据集表示，在自然语言处理、计算机视觉和时空建模方面取得了重大进展。本论文提供了一个数学精确、直观、简洁的Transformer架构描述。

    

    Transformer是一种可以学习序列或数据集表示的神经网络组件。Transformer在自然语言处理、计算机视觉和时空建模方面取得了重大进展。虽然有很多Transformer的介绍，但大多数都缺少对其架构的精确数学描述，其设计选择的直觉也常常缺失。此外，随着研究路径的曲折，Transformer部件的解释可能是异质的。在这篇论文中，我们旨在提供一个数学精确、直观、简洁的Transformer架构描述。

    The transformer is a neural network component that can be used to learn useful representations of sequences or sets of datapoints. The transformer has driven recent advances in natural language processing, computer vision, and spatio-temporal modelling. There are many introductions to transformers, but most do not contain precise mathematical descriptions of the architecture and the intuitions behind the design choices are often also missing. Moreover, as research takes a winding path, the explanations for the components of the transformer can be idiosyncratic. In this note we aim for a mathematically precise, intuitive, and clean description of the transformer architecture.
    
[^65]: Nerfbusters：从随意捕获的NeRF中去除幽灵似的图像伪影

    Nerfbusters: Removing Ghostly Artifacts from Casually Captured NeRFs. (arXiv:2304.10532v1 [cs.CV])

    [http://arxiv.org/abs/2304.10532](http://arxiv.org/abs/2304.10532)

    通过使用新的数据集和评估程序，提出了一种使用3D扩散优先级别加上新颖的基于密度的得分蒸馏采样损失的方法来防止NeRF优化过程中出现图形伪影的解决方案。

    

    随意捕获的神经辐射场（NeRF）在渲染摄像机轨迹之外时会出现浮点错误或有缺陷的几何图形等伪影。现有的评估协议通常无法捕捉这些效应，因为通常仅在训练抓取的每个第八帧评估图像质量。为了推动新视角合成的进展，我们提出了一个新的数据集和评估程序，其中记录了场景的两个摄像机轨迹：一个用于训练，另一个用于评估。在这种更具挑战性的实际环境中，我们发现现有的手工制作的规则不仅不能去除浮点错误，而且也不能改善场景几何形状。因此，我们提出了一种基于3D扩散的方法，该方法利用本地3D先验和新颖的基于密度的得分蒸馏采样损失，在NeRF优化过程中防止出现伪像现象。我们展示了这种基于数据的优先级别能够去除浮点错误并改善随意捕获的场景几何形状。

    Casually captured Neural Radiance Fields (NeRFs) suffer from artifacts such as floaters or flawed geometry when rendered outside the camera trajectory. Existing evaluation protocols often do not capture these effects, since they usually only assess image quality at every 8th frame of the training capture. To push forward progress in novel-view synthesis, we propose a new dataset and evaluation procedure, where two camera trajectories are recorded of the scene: one used for training, and the other for evaluation. In this more challenging in-the-wild setting, we find that existing hand-crafted regularizers do not remove floaters nor improve scene geometry. Thus, we propose a 3D diffusion-based method that leverages local 3D priors and a novel density-based score distillation sampling loss to discourage artifacts during NeRF optimization. We show that this data-driven prior removes floaters and improves scene geometry for casual captures.
    
[^66]: ChatGPT能否复制人类生成的标签？对社交计算任务的研究

    Can ChatGPT Reproduce Human-Generated Labels? A Study of Social Computing Tasks. (arXiv:2304.10145v1 [cs.AI])

    [http://arxiv.org/abs/2304.10145](http://arxiv.org/abs/2304.10145)

    本文研究了ChatGPT在社交计算任务中是否可以复制人类生成的标签注释，结果表明ChatGPT有潜力处理这些数据注释任务，尽管仍存在许多挑战。

    

    ChatGPT的发布揭示了语言模型可以取代人类智慧的各种可能性。本文旨在了解ChatGPT是否有潜力在社交计算任务中复制人类生成的标签注释。这样的成就可以显著降低社交计算研究的成本和复杂性。因此，我们使用ChatGPT重新标记了五个具有里程碑意义的数据集，涉及立场检测（2个）、情感分析、仇恨言论和机器人检测。我们的结果表明，ChatGPT有潜力处理这些数据注释任务，尽管仍存在许多挑战。ChatGPT获得了平均精度0.609。 ChatGPT对情感分析数据集的表现最佳，正确注释了64.9％的推文。然而，我们显示性能在不同标签之间有很大差异。我们认为这项工作可以开辟新的分析线路，并作为未来利用ChatGPT进行数据注释的基础。

    The release of ChatGPT has uncovered a range of possibilities whereby large language models (LLMs) can substitute human intelligence. In this paper, we seek to understand whether ChatGPT has the potential to reproduce human-generated label annotations in social computing tasks. Such an achievement could significantly reduce the cost and complexity of social computing research. As such, we use ChatGPT to re-label five seminal datasets covering stance detection (2x), sentiment analysis, hate speech, and bot detection. Our results highlight that ChatGPT does have the potential to handle these data annotation tasks, although a number of challenges remain. ChatGPT obtains an average precision 0.609. Performance is highest for the sentiment analysis dataset, with ChatGPT correctly annotating 64.9% of tweets. Yet, we show that performance varies substantially across individual labels. We believe this work can open up new lines of analysis and act as a basis for future research into the exploi
    
[^67]: 双记忆强化学习

    Two-Memory Reinforcement Learning. (arXiv:2304.10098v1 [cs.LG])

    [http://arxiv.org/abs/2304.10098](http://arxiv.org/abs/2304.10098)

    本文提出了双记忆强化学习代理 (2M)，它结合了情节记忆和强化学习的优点来提高学习速度和准确性。

    

    虽然深度强化学习取得了重要的经验性成功，但由于奖励信息传播和参数神经网络更新的速度较慢，它倾向于学习得比较慢。另一方面，非参数化的情节记忆提供了相对较快的学习替代方案，它不需要表示学习，并使用最大情节回报作为状态-动作值进行行动选择。情节记忆和强化学习都有各自的优点和缺点。值得注意的是，人类可以同时利用多个记忆系统进行学习，并从中获益。在这项工作中，我们提出了一种称为双记忆强化学习代理（2M）的方法，它结合了情节记忆和强化学习的优点。 2M 代理利用情节记忆部分的速度和强化学习部分的最优性和广泛适用性相互补充。我们的实验表明，

    While deep reinforcement learning has shown important empirical success, it tends to learn relatively slow due to slow propagation of rewards information and slow update of parametric neural networks. Non-parametric episodic memory, on the other hand, provides a faster learning alternative that does not require representation learning and uses maximum episodic return as state-action values for action selection. Episodic memory and reinforcement learning both have their own strengths and weaknesses. Notably, humans can leverage multiple memory systems concurrently during learning and benefit from all of them. In this work, we propose a method called Two-Memory reinforcement learning agent (2M) that combines episodic memory and reinforcement learning to distill both of their strengths. The 2M agent exploits the speed of the episodic memory part and the optimality and the generalization capacity of the reinforcement learning part to complement each other. Our experiments demonstrate that 
    
[^68]: 大规模语言模型中潜在空间理论对应新兴能力

    A Latent Space Theory for Emergent Abilities in Large Language Models. (arXiv:2304.09960v1 [cs.CL])

    [http://arxiv.org/abs/2304.09960](http://arxiv.org/abs/2304.09960)

    本文探讨了大规模语言模型中的贝叶斯推断和稀疏联合分布，证明了LLMs能够完成语言理解、上下文学习、思路启发以及有效指令微调的新兴能力。

    

    语言并不是随机生成，而是为了传递信息。语言与其底层含义之间存在强烈的关联，在其相关性方面有着严重偏差的稀疏联合分布。此外，由于稀疏性，这些高峰值恰好与语言的边缘分布匹配。随着大数据和大模型上训练的LLMs的出现，我们现在可以精确评估语言的边缘分布，这提供了一种方便的探索联合分布稀疏结构实现有效推理的方式。在本文中，我们将语言分类为明确与{\epsilon}-模糊，并提出定量结果，以表明LLMs的新兴能力（例如语言理解、上下文学习、思路启发以及有效指令微调）都可以归因于对稀疏联合分布进行贝叶斯推断。

    Languages are not created randomly but rather to communicate information. There is a strong association between languages and their underlying meanings, resulting in a sparse joint distribution that is heavily peaked according to their correlations. Moreover, these peak values happen to match with the marginal distribution of languages due to the sparsity. With the advent of LLMs trained on big data and large models, we can now precisely assess the marginal distribution of languages, providing a convenient means of exploring the sparse structures in the joint distribution for effective inferences. In this paper, we categorize languages as either unambiguous or {\epsilon}-ambiguous and present quantitative results to demonstrate that the emergent abilities of LLMs, such as language understanding, in-context learning, chain-of-thought prompting, and effective instruction fine-tuning, can all be attributed to Bayesian inference on the sparse joint distribution of languages.
    
[^69]: GeneGPT: 教授大型语言模型使用NCBI Web API

    GeneGPT: Teaching Large Language Models to Use NCBI Web APIs. (arXiv:2304.09667v1 [cs.CL])

    [http://arxiv.org/abs/2304.09667](http://arxiv.org/abs/2304.09667)

    GeneGPT通过少量NCBI API调用URL请求作为演示，教授大型语言模型使用NCBI Web API回答基因组问题，并在GeneTuring测试中达到了优异的结果。

    

    本文介绍了GeneGPT，一种新颖的方法，用于教授大型语言模型（LLM）使用国家生物技术信息中心（NCBI）的Web应用程序编程接口（API），并回答基因组问题。具体而言，我们通过少量的NCBI API调用URL请求作为上下文学习的演示，启发Codex（code-davinci-002）解决GeneTuring测试。在推理过程中，一旦检测到调用请求，我们就停止解码并使用生成的URL进行API调用。我们然后将NCBI API返回的原始执行结果附加到生成的文本中，并继续生成直到找到答案或检测到另一个API调用。初步结果表明，GeneGPT在GeneTuring数据集的四个One-shot任务中取得了三个最先进的结果，在五个Zero-shot任务中取得了四个最先进的结果。总体而言，GeneGPT的宏平均分数为0.76，远高于检索增强LLM，如New Bin。

    In this paper, we present GeneGPT, a novel method for teaching large language models (LLMs) to use the Web Application Programming Interfaces (APIs) of the National Center for Biotechnology Information (NCBI) and answer genomics questions. Specifically, we prompt Codex (code-davinci-002) to solve the GeneTuring tests with few-shot URL requests of NCBI API calls as demonstrations for in-context learning. During inference, we stop the decoding once a call request is detected and make the API call with the generated URL. We then append the raw execution results returned by NCBI APIs to the generated texts and continue the generation until the answer is found or another API call is detected. Our preliminary results show that GeneGPT achieves state-of-the-art results on three out of four one-shot tasks and four out of five zero-shot tasks in the GeneTuring dataset. Overall, GeneGPT achieves a macro-average score of 0.76, which is much higher than retrieval-augmented LLMs such as the New Bin
    
[^70]: SemEval 2023 任务6: LegalEval -- 理解法律文本

    SemEval 2023 Task 6: LegalEval -- Understanding Legal Texts. (arXiv:2304.09548v1 [cs.CL])

    [http://arxiv.org/abs/2304.09548](http://arxiv.org/abs/2304.09548)

    SemEval 2023举办了LegalEval共享任务，即理解法律文本，包括 自动结构化和语义连贯化的法律文件（Task-A），法律命名实体识别（Task-B）以及自动预测法律案件结果和提供预测解释（Task-C）。26个团队提交了系统论文并在所有子任务中优于基准线，但仍有改进空间。

    

    在人口众多的国家，待处理的法律案件呈指数增长。有必要开发基于自然语言处理的技术，对法律文件进行处理和自动理解。为了促进在法律自然语言处理领域的研究，我们在 SemEval 2023 上组织了共享任务 LegalEval - 理解法律文本。LegalEval 任务有三个子任务：Task-A（修辞角色标记）是自动将法律文件结构化为语义连贯的单元，Task-B（法律命名实体识别）处理在法律文件中识别相关实体，而 Task-C（法院判决预测与解释）探索了自动预测法律案件结果以及提供预测解释的可能性。共有26个团队（分布在全球的约100名参与者）提交了系统论文。在每个子任务中，所提出的系统都优于基准线；但是，仍然有很大的改进空间。本文介绍了 LegalEval 任务的组织和细节，并概述了参与系统及其性能。

    In populous countries, pending legal cases have been growing exponentially. There is a need for developing NLP-based techniques for processing and automatically understanding legal documents. To promote research in the area of Legal NLP we organized the shared task LegalEval - Understanding Legal Texts at SemEval 2023. LegalEval task has three sub-tasks: Task-A (Rhetorical Roles Labeling) is about automatically structuring legal documents into semantically coherent units, Task-B (Legal Named Entity Recognition) deals with identifying relevant entities in a legal document and Task-C (Court Judgement Prediction with Explanation) explores the possibility of automatically predicting the outcome of a legal case along with providing an explanation for the prediction. In total 26 teams (approx. 100 participants spread across the world) submitted systems paper. In each of the sub-tasks, the proposed systems outperformed the baselines; however, there is a lot of scope for improvement. This pape
    
[^71]: PaTeCon：基于模式的知识图谱时间约束挖掘方法用于冲突检测

    PaTeCon: A Pattern-Based Temporal Constraint Mining Method for Conflict Detection on Knowledge Graphs. (arXiv:2304.09015v1 [cs.AI])

    [http://arxiv.org/abs/2304.09015](http://arxiv.org/abs/2304.09015)

    PaTeCon是一种基于模式的知识图谱时间约束挖掘方法，能够自动生成时间约束来维护KG的时间一致性，并在不需要人工专家的情况下准确地检测潜在的时间冲突。

    

    在知识图谱（KG）研究社区中，时间事实指特定时间段内发生的事件的数据。引入时间限制给KG的时间一致性维护带来了新的挑战，先前的研究依赖于手动列举时间约束来检测冲突，这很费力且可能存在粒度问题。本文提出了一种基于模式的时间约束挖掘方法PaTeCon，它使用自动确定的图形模式及其相关统计信息代替人工专家来生成时间约束。具体地，PaTeCon根据其测量得分动态地将类限制附加到候选约束上。我们基于维基数据集评估了PaTeCon的效果。

    Temporal facts, the facts for characterizing events that hold in specific time periods, are attracting rising attention in the knowledge graph (KG) research communities. In terms of quality management, the introduction of time restrictions brings new challenges to maintaining the temporal consistency of KGs and detecting potential temporal conflicts. Previous studies rely on manually enumerated temporal constraints to detect conflicts, which are labor-intensive and may have granularity issues. We start from the common pattern of temporal facts and constraints and propose a pattern-based temporal constraint mining method, PaTeCon. PaTeCon uses automatically determined graph patterns and their relevant statistical information over the given KG instead of human experts to generate time constraints. Specifically, PaTeCon dynamically attaches class restriction to candidate constraints according to their measuring scores.We evaluate PaTeCon on two large-scale datasets based on Wikidata and F
    
[^72]: CornerFormer: 提升角点表征以进行精细结构重建

    CornerFormer: Boosting Corner Representation for Fine-Grained Structured Reconstruction. (arXiv:2304.07072v1 [cs.CV])

    [http://arxiv.org/abs/2304.07072](http://arxiv.org/abs/2304.07072)

    CornerFormer是一种新的方法，它利用不同建模策略于单个模型中融合角点检测和边缘预测来提升精细结构重建的表现，并在挑战性的基准测试中取得了最好的结果。

    

    结构化重建是一种非平凡的密集预测问题，它从栅格图像中提取结构信息（例如，建筑角点和边缘），然后相应地重建为二维平面图。与常见的分割或检测问题相比，它显著依赖于利用整体几何信息进行结构推理的能力。目前，基于transformer的方法采用两阶段方式解决这个具有挑战性的问题，在第一个模型中检测角点，并在第二个模型中分类拟议边缘（角对）。然而，它们将两个阶段分开成不同的模型，并且只共享主干编码器。与现有的建模策略不同，我们提出了增强的角点表示方法：1）通过在不同的粒度中共享特征，它在角点检测和边缘预测之间融合知识；2）角点候选者根据其方向作为四个热图通道提出。定性和定量评估均表明，我们的CornerFormer明显优于以前的transformer-based模型，在具有挑战性的基准测试中取得了最先进的结果。

    Structured reconstruction is a non-trivial dense prediction problem, which extracts structural information (\eg, building corners and edges) from a raster image, then reconstructs it to a 2D planar graph accordingly. Compared with common segmentation or detection problems, it significantly relays on the capability that leveraging holistic geometric information for structural reasoning. Current transformer-based approaches tackle this challenging problem in a two-stage manner, which detect corners in the first model and classify the proposed edges (corner-pairs) in the second model. However, they separate two-stage into different models and only share the backbone encoder. Unlike the existing modeling strategies, we present an enhanced corner representation method: 1) It fuses knowledge between the corner detection and edge prediction by sharing feature in different granularity; 2) Corner candidates are proposed in four heatmap channels w.r.t its direction. Both qualitative and quantita
    
[^73]: 不同约束运动模型在基于图的轨迹预测中的评估

    Evaluation of Differentially Constrained Motion Models for Graph-Based Trajectory Prediction. (arXiv:2304.05116v1 [cs.RO])

    [http://arxiv.org/abs/2304.05116](http://arxiv.org/abs/2304.05116)

    使用深度学习模型进行运动预测在自动驾驶中表现出色，但缺乏解释性和可能违反物理约束。因此，结合差分约束运动模型能提供物理上可行的轨迹，研究表明低阶积分器模型表现更好，并且数值求解器对模型性能产生影响。

    

    随着深度学习模型在自动驾驶中表现出色且可调性高，成为运动预测的标准。然而，高度灵活性伴随的是解释性缺失和可能违反的物理约束。使用差分约束运动模型来提供物理上可行的轨迹，可以作为与这些数据驱动方法相配合的一个有前途的方向。本研究基于先前提出的基于图神经网络的模型 MTP-GO，研究了各种运动模型结合数值求解器进行预测任务的表现。研究表明，为了获得精确的预测结果，简单的模型，如低阶积分器模型，优于更复杂的运动学模型。此外，数值求解器可以对运动预测模型的性能产生重大影响。

    Given their adaptability and encouraging performance, deep-learning models are becoming standard for motion prediction in autonomous driving. However, with great flexibility comes a lack of interpretability and possible violations of physical constraints. Accompanying these data-driven methods with differentially-constrained motion models to provide physically feasible trajectories is a promising future direction. The foundation for this work is a previously introduced graph-neural-network-based model, MTP-GO. The neural network learns to compute the inputs to an underlying motion model to provide physically feasible trajectories. This research investigates the performance of various motion models in combination with numerical solvers for the prediction task. The study shows that simpler models, such as low-order integrator models, are preferred over more complex ones, e.g., kinematic models, to achieve accurate predictions. Further, the numerical solver can have a substantial impact o
    
[^74]: SSS在SemEval-2023任务10中的论文：使用投票细调变压器可解释的检测在线性别歧视。 (arXiv：2304.03518v1 [cs.CL])

    SSS at SemEval-2023 Task 10: Explainable Detection of Online Sexism using Majority Voted Fine-Tuned Transformers. (arXiv:2304.03518v1 [cs.CL])

    [http://arxiv.org/abs/2304.03518](http://arxiv.org/abs/2304.03518)

    本文描述了使用细调BERT模型和多数投票集成模型来检测和解释在线性别歧视的方法。翻转显着降低了女性在社交媒体平台上经历不成比例的性别歧视的风险。

    

    本文描述了我们在SemEval 2023任务10中提交的作品-可解释的在线性别歧视检测（EDOS），分为三个子任务。社交媒体平台的不断增长导致女性在社交媒体平台上面临不成比例的性别歧视。这使得检测和解释在线性别歧视内容变得比以往更加重要，以使社交媒体对女性更加安全和可访问。我们的方法包括实验和微调基于BERT的模型，并使用多数投票集合模型，该模型优于单个基线模型得分。我们的系统在任务A中实现了宏F1分数0.8392，在任务B中为0.6092，在任务C中为0.4319。

    This paper describes our submission to Task 10 at SemEval 2023-Explainable Detection of Online Sexism (EDOS), divided into three subtasks. The recent rise in social media platforms has seen an increase in disproportionate levels of sexism experienced by women on social media platforms. This has made detecting and explaining online sexist content more important than ever to make social media safer and more accessible for women. Our approach consists of experimenting and finetuning BERT-based models and using a Majority Voting ensemble model that outperforms individual baseline model scores. Our system achieves a macro F1 score of 0.8392 for Task A, 0.6092 for Task B, and 0.4319 for Task C.
    
[^75]: 大型语言模型综述

    A Survey of Large Language Models. (arXiv:2303.18223v1 [cs.CL])

    [http://arxiv.org/abs/2303.18223](http://arxiv.org/abs/2303.18223)

    本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。

    

    语言本质上是一个由语法规则控制的复杂精细的人类表达系统，对于开发理解和掌握语言的能力的AI算法来说是一项重大挑战。作为主要方法之一，语言建模在过去二十年里广泛研究用于语言理解和生成，从统计语言模型演化为神经语言模型。最近，通过在大规模语料库上预训练Transformer模型，提出了预训练语言模型（PLMs），在解决各种NLP任务方面显示出强大的能力。由于研究人员发现模型缩放可以导致性能改进，他们进一步通过增加模型规模来研究缩放效应，有趣的是，当参数规模超过一定水平时，这些扩大的语言模型不仅可以实现显着的性能提升，而且还显示出一些小规模语言模型所没有的特殊能力。

    Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale langu
    
[^76]: 语义阅读器项目：利用人工智能驱动的交互式阅读界面增强学术文档

    The Semantic Reader Project: Augmenting Scholarly Documents through AI-Powered Interactive Reading Interfaces. (arXiv:2303.14334v1 [cs.DL])

    [http://arxiv.org/abs/2303.14334](http://arxiv.org/abs/2303.14334)

    本文探讨了利用人工智能和人机交互技术为研究论文提供智能、交互式和无障碍的阅读界面的可行性，并介绍了跨机构合作的语义阅读器项目。

    

    学术出版物是学者向他人传递知识的关键。然而，研究论文信息密集，随着科学文献量的增长，需要新技术支持阅读过程。与通过互联网技术转变的查找论文过程不同，阅读研究论文的体验几十年来几乎没有改变。虽然PDF格式因其便携性而广泛使用，但它有重大缺点，包括：静态内容，低视觉读者的可访问性差，以及在移动设备上阅读困难。本文探讨“最近的AI和HCI进展能否为遗留的PDF提供智能，交互式和无障碍的阅读界面？”，我们描述了语义阅读器项目，这是多个机构的协作努力，旨在探索为研究论文自动创建动态阅读界面的方法。

    Scholarly publications are key to the transfer of knowledge from scholars to others. However, research papers are information-dense, and as the volume of the scientific literature grows, the need for new technology to support the reading process grows. In contrast to the process of finding papers, which has been transformed by Internet technology, the experience of reading research papers has changed little in decades. The PDF format for sharing research papers is widely used due to its portability, but it has significant downsides including: static content, poor accessibility for low-vision readers, and difficulty reading on mobile devices. This paper explores the question "Can recent advances in AI and HCI power intelligent, interactive, and accessible reading interfaces -- even for legacy PDFs?" We describe the Semantic Reader Project, a collaborative effort across multiple institutions to explore automatic creation of dynamic reading interfaces for research papers. Through this pro
    
[^77]: 多视角的零样本开放意图归纳：多领域批处理和代理梯度转移

    Multi-View Zero-Shot Open Intent Induction from Dialogues: Multi Domain Batch and Proxy Gradient Transfer. (arXiv:2303.13099v1 [cs.CL])

    [http://arxiv.org/abs/2303.13099](http://arxiv.org/abs/2303.13099)

    本研究提出了一种多领域批处理和代理梯度转移的语义多视角模型，可以解决任务导向对话系统中的意图检测和诱导新意图的问题，在Open Intent Induction中有显著的性能提升。

    

    在任务导向的对话系统中，检测和诱导新的意图是将该系统应用于实际应用的两个主要挑战。本文提出了语义多视角模型来解决这两个难题：（1）用于一般嵌入的SBERT（2）多领域批处理（MDB）用于对话领域知识，以及（3）用于集群专业语义的代理梯度转移（PGT）。 MDB一次向模型提供多种对话数据集，通过学习多领域知识来解决多领域问题。我们引入了一种新的方法PGT，它采用Siamese网络直接使用聚类方法微调模型。我们的模型可以学习如何使用PGT聚类对话语句。实验结果表明，与基线系统相比，我们的多视角模型与MDB和PGT显着提高了Open Intent Induction的性能。

    In Task Oriented Dialogue (TOD) system, detecting and inducing new intents are two main challenges to apply the system in the real world. In this paper, we suggest the semantic multi-view model to resolve these two challenges: (1) SBERT for General Embedding (GE), (2) Multi Domain Batch (MDB) for dialogue domain knowledge, and (3) Proxy Gradient Transfer (PGT) for cluster-specialized semantic. MDB feeds diverse dialogue datasets to the model at once to tackle the multi-domain problem by learning the multiple domain knowledge. We introduce a novel method PGT, which employs the Siamese network to fine-tune the model with a clustering method directly.Our model can learn how to cluster dialogue utterances by using PGT. Experimental results demonstrate that our multi-view model with MDB and PGT significantly improves the Open Intent Induction performance compared to baseline systems.
    
[^78]: TOT：面向多模态仇恨检测的拓扑感知最优传输

    TOT: Topology-Aware Optimal Transport For Multimodal Hate Detection. (arXiv:2303.09314v1 [cs.CL])

    [http://arxiv.org/abs/2303.09314](http://arxiv.org/abs/2303.09314)

    本文针对隐式危害检测的挑战，提出一种面向表情包情境的拓扑感知最优传输框架TOT，利用最优传输核方法从多个模态中捕捉互补信息。

    

    多模态仇恨检测旨在识别在线有害内容（如表情包等），是构建健康的互联网环境至关重要。以往的研究重点关注显式仇恨言论的检测，而忽略了隐式危害的分析，这在存在着扭曲或缺乏明显文本标记和人口统计视觉线索的情况下面临着特别大的挑战。本文提出了TOT：一种面向表情包情境的拓扑感知最优传输框架，将跨模态对齐问题转化为最优传输方案的求解。具体来说，我们利用最优传输核方法从多个模态中捕捉互补信息。核嵌入提供了一种非线性转换能力，以重现输入的分布。

    Multimodal hate detection, which aims to identify harmful content online such as memes, is crucial for building a wholesome internet environment. Previous work has made enlightening exploration in detecting explicit hate remarks. However, most of their approaches neglect the analysis of implicit harm, which is particularly challenging as explicit text markers and demographic visual cues are often twisted or missing. The leveraged cross-modal attention mechanisms also suffer from the distributional modality gap and lack logical interpretability. To address these semantic gaps issues, we propose TOT: a topology-aware optimal transport framework to decipher the implicit harm in memes scenario, which formulates the cross-modal aligning problem as solutions for optimal transportation plans. Specifically, we leverage an optimal transport kernel method to capture complementary information from multiple modalities. The kernel embedding provides a non-linear transformation ability to reproduce 
    
[^79]: 有缺陷在线演示的保护策略优化

    Guarded Policy Optimization with Imperfect Online Demonstrations. (arXiv:2303.01728v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.01728](http://arxiv.org/abs/2303.01728)

    本文放弃了教师表现良好的假设，提出了一种新的算法，能够融合任意教师策略，并通过基于轨迹的价值估计实现高效的探索和安全保障。

    

    “教师-学生框架”（TSF）是一种强化学习设置，其中教师代理通过干预和提供在线演示来监督学生代理的训练。本文放宽了教师表现良好的假设，并开发了一种能够融合任意教师策略的新方法。我们实例化了一个离策略强化学习算法,即教师-学生共享控制（TS2C），它基于基于轨迹的价值估计来融入教师干预。理论分析证明了所提出的TS2C算法实现了高效的探索和可靠的安全保障，而不会过分依赖教师策略的质量。

    The Teacher-Student Framework (TSF) is a reinforcement learning setting where a teacher agent guards the training of a student agent by intervening and providing online demonstrations. Assuming optimal, the teacher policy has the perfect timing and capability to intervene in the learning process of the student agent, providing safety guarantee and exploration guidance. Nevertheless, in many real-world settings it is expensive or even impossible to obtain a well-performing teacher policy. In this work, we relax the assumption of a well-performing teacher and develop a new method that can incorporate arbitrary teacher policies with modest or inferior performance. We instantiate an Off-Policy Reinforcement Learning algorithm, termed Teacher-Student Shared Control (TS2C), which incorporates teacher intervention based on trajectory-based value estimation. Theoretical analysis validates that the proposed TS2C algorithm attains efficient exploration and substantial safety guarantee without be
    
[^80]: UZH_CLyp在SemEval-2023任务9中的表现：基于Head-First Fine-Tuning和ChatGPT数据生成的跨语言学习方法用于推文亲密度预测

    UZH_CLyp at SemEval-2023 Task 9: Head-First Fine-Tuning and ChatGPT Data Generation for Cross-Lingual Learning in Tweet Intimacy Prediction. (arXiv:2303.01194v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.01194](http://arxiv.org/abs/2303.01194)

    本文介绍了UZH_CLyp在SemEval 2023任务9中的表现。我们的跨语言迁移学习方法包含了先使用Head-First Fine-Tuning（HeFiT）方法更新回归头参数，再降低学习率更新预训练transformer的参数。同时，我们研究了在没有人工标记数据的情况下，使用ChatGPT生成的自动小型样例来解决低资源问题。研究发现，HeFiT稳定训练并显著提高预训练模型的性能，使用合成数据时也能提高跨语言学习的性能。

    

    本文介绍了UZH_CLyp在SemEval 2023任务9“多语言推文亲密度分析”中的表现。我们在所有10种语言中均取得了第二好的结果，根据官方的Pearson相关系数回归评估指标。我们的跨语言迁移学习方法探索了使用Head-First Fine-Tuning方法（HeFiT）的益处，该方法首先仅更新回归头参数，然后再以降低的学习率更新预训练的transformer编码器参数。此外，我们研究了在低资源设置中使用一小组自动生成的示例（在我们的情况下，来自ChatGPT）对没有人工标记数据的情况的影响。我们的研究表明，HeFiT稳定了培训并且对于缺乏推文领域适应的预训练模型一致地提高了结果。我们的研究还表明，当使用合成数据时，跨语言学习的性能显着提高，证实了当前文本生成模型用于解决低资源情况的实用性。

    This paper describes the submission of UZH_CLyp for the SemEval 2023 Task 9 "Multilingual Tweet Intimacy Analysis". We achieved second-best results in all 10 languages according to the official Pearson's correlation regression evaluation measure. Our cross-lingual transfer learning approach explores the benefits of using a Head-First Fine-Tuning method (HeFiT) that first updates only the regression head parameters and then also updates the pre-trained transformer encoder parameters at a reduced learning rate. Additionally, we study the impact of using a small set of automatically generated examples (in our case, from ChatGPT) for low-resource settings where no human-labeled data is available. Our study shows that HeFiT stabilizes training and consistently improves results for pre-trained models that lack domain adaptation to tweets. Our study also shows a noticeable performance increase in cross-lingual learning when synthetic data is used, confirming the usefulness of current text gen
    
[^81]: BrainCLIP：通过CLIP框架实现从fMRI中获取自然视觉信息的通用解码方法

    BrainCLIP: Bridging Brain and Visual-Linguistic Representation via CLIP for Generic Natural Visual Stimulus Decoding from fMRI. (arXiv:2302.12971v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.12971](http://arxiv.org/abs/2302.12971)

    BrainCLIP是一种从fMRI中获取自然图像信息的解码方法，它利用了CLIP跨模态泛化能力并在语义空间中统一视觉刺激分类和重构任务，同时文本监督也能提高解码模型的性能。

    

    从fMRI信号重构感知到的自然图像或解码它们的类别是具有科学意义的挑战性任务。由于缺乏成对样本，大多数现有方法无法生成语义可识别的重构，并且难以推广到新颖类别。在这项工作中，我们首次提出了一种任务不可知的大脑解码模型，通过在语义空间中统一视觉刺激分类和重构任务来实现。我们将它命名为BrainCLIP，利用了CLIP跨模态泛化能力，以填补大脑活动，图像和文本之间的模态差距。具体而言，BrainCLIP是一种基于VAE的体系结构，通过结合视觉和文本监督，将fMRI模式转换为CLIP嵌入空间。注意，以前的研究很少使用多模态监督进行视觉刺激解码。我们的实验表明，文本监督可以显着提高解码模型的性能。

    Reconstructing perceived natural images or decoding their categories from fMRI signals are challenging tasks with great scientific significance. Due to the lack of paired samples, most existing methods fail to generate semantically recognizable reconstruction and are difficult to generalize to novel classes. In this work, we propose, for the first time, a task-agnostic brain decoding model by unifying the visual stimulus classification and reconstruction tasks in a semantic space. We denote it as BrainCLIP, which leverages CLIP's cross-modal generalization ability to bridge the modality gap between brain activities, images, and texts. Specifically, BrainCLIP is a VAE-based architecture that transforms fMRI patterns into the CLIP embedding space by combining visual and textual supervision. Note that previous works rarely use multi-modal supervision for visual stimulus decoding. Our experiments demonstrate that textual supervision can significantly boost the performance of decoding model
    
[^82]: 高分辨率遥感图像在老滑坡探测中的迭代分类和语义分割网络

    An Iterative Classification and Semantic Segmentation Network for Old Landslide Detection Using High-Resolution Remote Sensing Images. (arXiv:2302.12420v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.12420](http://arxiv.org/abs/2302.12420)

    本文提出了一种迭代分类和语义分割网络(ICSSN)，它可以通过迭代升级两个共享特征提取器来大大增强目标级和像素级分类性能。

    

    长时间的作用使得老滑坡的形态特征被部分或强烈改变且与周围环境差异不大，因此老滑坡检测面临巨大挑战。此外，小样本问题也制约了深度学习的深入。本文提出了一种迭代分类和语义分割网络(ICSSN)，通过迭代升级两个共享特征提取器来大大增强目标级和像素级分类性能。在对象分类子网络中采用对象级对比学习(OCL)策略，采用连体网络实现全局特征提取；在语义分割子网络中设计了子对象级对比学习(SOCL)范式，以有效地从滑坡边界提取显著特征。此外，详细阐述了一种迭代训练策略，以在语义空间中融合特征，从而既提高目标级别分类性能，又提高像素级别的语义分割性能。

    Huge challenges exist for old landslide detection because their morphology features have been partially or strongly transformed over a long time and have little difference from their surrounding. Besides, small-sample problem also restrict in-depth learning.  In this paper, an iterative classification and semantic segmentation network (ICSSN) is developed, which can greatly enhance both object-level and pixel-level classification performance by iteratively upgrading the feature extractor shared by two network. An object-level contrastive learning (OCL) strategy is employed in the object classification sub-network featuring a siamese network to realize the global features extraction, and a sub-object-level contrastive learning (SOCL) paradigm is designed in the semantic segmentation sub-network to efficiently extract salient features from boundaries of landslides. Moreover, an iterative training strategy is elaborated to fuse features in semantic space such that both object-level and pi
    
[^83]: SAT需要彻底搜索

    SAT Requires Exhaustive Search. (arXiv:2302.09512v4 [cs.CC] CROSS LISTED)

    [http://arxiv.org/abs/2302.09512](http://arxiv.org/abs/2302.09512)

    本文证明了对于一些具有大域和长子句的极难例子，要求进行彻底搜索才能解决，这意味着P $\neq$ NP。

    

    本文通过构造具有大域和长子句的CSP和SAT的极难例子，证明这些例子无法在不进行彻底搜索的情况下解决，这意味着一个较弱的结论P $\neq$ NP。本文采用的是一种证明不可能性结果的建设性方法，与目前计算复杂性理论中使用的方法非常不同，但与Kurt G\"{o}del在证明他著名的逻辑不可能性结果时使用的方法相似。正如G\"{o}del的结果表明，在数学中证明形式上的不可证明性是可行的一样，本文的结果表明，在数学中证明计算上的难度不是很难的。具体来说，对许多问题，如3-SAT，证明下界可能具有挑战性，因为这些问题有各种有效的策略可用于避免进行彻底搜索。然而，在极难的例子中，彻底搜索可能是唯一可行的选择，证明其必要性变得更加重要。

    In this paper, by constructing extremely hard examples of CSP (with large domains) and SAT (with long clauses), we prove that such examples cannot be solved without exhaustive search, which implies a weaker conclusion P $\neq$ NP. This constructive approach for proving impossibility results is very different (and missing) from those currently used in computational complexity theory, but is similar to that used by Kurt G\"{o}del in proving his famous logical impossibility results. Just as shown by G\"{o}del's results that proving formal unprovability is feasible in mathematics, the results of this paper show that proving computational hardness is not hard in mathematics. Specifically, proving lower bounds for many problems, such as 3-SAT, can be challenging because these problems have various effective strategies available for avoiding exhaustive search. However, in cases of extremely hard examples, exhaustive search may be the only viable option, and proving its necessity becomes more 
    
[^84]: CC-FedAvg：计算定制的联邦平均算法

    CC-FedAvg: Computationally Customized Federated Averaging. (arXiv:2212.13679v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.13679](http://arxiv.org/abs/2212.13679)

    本论文提出了一个称为CC-FedAvg的计算定制的联邦平均算法，可让参与者根据其计算预算决定在每轮中是否执行传统的本地训练或模型估算。实验结果表明，CC-FedAvg能够显著提高模型性能并降低通信成本。

    

    联邦学习是一种新兴的模型训练方式，通过分布在众多物联网设备上的数据进行模型训练。它在本质上假设参与者的计算能力相同，但实际上，由于不同的能源预算或并行执行的任务不同，参与者计算资源存在着差异。缺乏计算预算的参与者必须适当规划其受限计算资源的使用，否则他们将无法完成整个训练过程，导致模型性能下降。为了解决这个问题，我们提出了一种估算本地模型而无需计算密集迭代的策略。基于此，我们提出了计算定制的联邦平均算法(CC-FedAvg)，允许参与者根据其当前的计算预算，在每个轮次中决定是执行传统的本地训练还是模型估算。理论分析和实验结果均表明，与传统的联邦平均算法相比，CC-FedAvg能显著提高模型性能并降低通信成本。

    Federated learning (FL) is an emerging paradigm to train model with distributed data from numerous Internet of Things (IoT) devices. It inherently assumes a uniform capacity among participants. However, due to different conditions such as differing energy budgets or executing parallel unrelated tasks, participants have diverse computational resources in practice. Participants with insufficient computation budgets must plan for the use of restricted computational resources appropriately, otherwise they would be unable to complete the entire training procedure, resulting in model performance decline. To address the this issue, we propose a strategy for estimating local models without computationally intensive iterations. Based on it, we propose Computationally Customized Federated Averaging (CC-FedAvg), which allows participants to determine whether to perform traditional local training or model estimation in each round based on their current computational budgets. Both theoretical analy
    
[^85]: MN-DS：新闻文章层次分类的多标签数据集

    MN-DS: A Multilabeled News Dataset for News Articles Hierarchical Classification. (arXiv:2212.12061v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.12061](http://arxiv.org/abs/2212.12061)

    本文介绍了一个包含10,917篇新闻文章的多标签数据集，可用于训练机器学习模型自动按主题对新闻文章进行分类，对新闻结构、分类和预测未来事件的研究人员非常有帮助。

    

    本文介绍了一个数据集，其中包含10,917篇新闻文章，涵盖了从2019年1月1日到2019年12月31日的层次新闻分类。我们根据17个一级类别和109个二级类别的层次分类手动标记了这些文章。该数据集可用于训练机器学习模型，以自动按主题分类新闻文章。该数据集对于从事新闻结构、分类和根据发布的新闻预测未来事件的研究人员非常有帮助。

    This article presents a dataset of 10,917 news articles with hierarchical news categories collected between January 1st 2019, and December 31st 2019. We manually labelled the articles based on a hierarchical taxonomy with 17 first-level and 109 second-level categories. This dataset can be used to train machine learning models for automatically classifying news articles by topic. This dataset can be helpful for researchers working on news structuring, classification, and predicting future events based on released news.
    
[^86]: 神经符号模型的自然约束担保一致性

    Guaranteed Conformance of Neurosymbolic Models to Natural Constraints. (arXiv:2212.01346v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.01346](http://arxiv.org/abs/2212.01346)

    该论文提出了一种能够担保数据驱动模型符合自然科学已有知识并最优逼近系统模型的方法。

    

    深度神经网络已经成为大部分机器人和控制应用的主要模型，特别是作为动态系统模型。这类数据驱动模型又可以用于设计和验证自主系统。在医疗系统建模方面尤其有用，因为数据能够被用于个体化治疗。在安全关键的应用中，数据驱动模型对来自自然科学的已有知识的符合性显得尤为重要。这些知识通常是可用的，或者可以被浓缩成（可能是黑盒的）模型。例如，F1赛车应符合牛顿定律（这被编码在一个单轮模型中）。鉴于这一点，我们考虑以下问题——给定一个模型M和一个状态转移数据集，我们希望在距离M的范围内最好地近似系统模型。我们提出一种方法来担保这种一致性。我们的第一步是将数据集浓缩成几个代表性的样例。

    Deep neural networks have emerged as the workhorse for a large section of robotics and control applications, especially as models for dynamical systems. Such data-driven models are in turn used for designing and verifying autonomous systems. They are particularly useful in modeling medical systems where data can be leveraged to individualize treatment. In safety-critical applications, it is important that the data-driven model is conformant to established knowledge from the natural sciences. Such knowledge is often available or can often be distilled into a (possibly black-box) model. For instance, an F1 racing car should conform to Newton's laws (which are encoded within a unicycle model). In this light, we consider the following problem - given a model $M$ and a state transition dataset, we wish to best approximate the system model while being a bounded distance away from $M$. We propose a method to guarantee this conformance. Our first step is to distill the dataset into a few repre
    
[^87]: 平衡探索和开发权衡的动态稀疏训练

    Dynamic Sparse Training via Balancing the Exploration-Exploitation Trade-off. (arXiv:2211.16667v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.16667](http://arxiv.org/abs/2211.16667)

    本文提出了一种动态稀疏训练方法，采用开发和探索收购函数来平衡探索和开发之间的权衡，从而摆脱了局部最优和鞍点问题，实验结果表明，该方法在精度和收敛速度方面超过了现有的稀疏训练方法。

    

    深度神经网络的超参数化已经在许多应用中表现出高预测准确性。虽然有效，但大量参数阻碍了它在资源受限设备上的普及，并对环境产生不良影响。使用固定数量的非零权重来进行稀疏训练可以显着减轻训练成本，减小模型大小，但现有的稀疏训练方法主要使用基于随机或贪婪的减少和增长策略，导致局部最小值和低精度问题。在本文中，我们将动态稀疏训练视为稀疏连通性搜索问题，并设计一个开发和探索收购函数来摆脱局部最优和鞍点。我们进一步设计了一种收购功能，并提供了所提方法的理论保证并阐明其收敛性质。实验结果表明，我们的程序获得了多种深度神经网络上与密集模型可比的精度（高达98％的稀疏度），并且在精度和收敛速度方面超过了现有的稀疏训练方法。

    Over-parameterization of deep neural networks (DNNs) has shown high prediction accuracy for many applications. Although effective, the large number of parameters hinders its popularity on resource-limited devices and has an outsize environmental impact. Sparse training (using a fixed number of nonzero weights in each iteration) could significantly mitigate the training costs by reducing the model size. However, existing sparse training methods mainly use either random-based or greedy-based drop-and-grow strategies, resulting in local minimal and low accuracy. In this work, we consider the dynamic sparse training as a sparse connectivity search problem and design an exploitation and exploration acquisition function to escape from local optima and saddle points. We further design an acquisition function and provide the theoretical guarantees for the proposed method and clarify its convergence property. Experimental results show that sparse models (up to 98\% sparsity) obtained by our pro
    
[^88]: 连续情景控制

    Continuous Episodic Control. (arXiv:2211.15183v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.15183](http://arxiv.org/abs/2211.15183)

    CEC是一种新颖的非参数情景记忆算法，用于连续性行动空间问题中的序列决策制定，其在几个稀疏奖励连续控制环境中比最先进的RL和记忆增强RL算法学习更快，是学习连续控制任务的快速方法。

    

    非参数情景记忆可以用于快速锁定强化学习任务中高奖励的经验。与参数深度强化学习方法相比，在参数需要缓慢地反向传递奖励信号的方法中，这些方法只需要发现一次解决方案，然后就可以反复解决任务。然而，情景控制解决方案存储在离散表中，这种方法迄今只应用于离散行动空间问题。因此，本文介绍了连续情景控制（CEC），这是一种新颖的非参数情景记忆算法，可用于连续性行动空间问题中的序列决策制定。在几个稀疏奖励连续控制环境中的结果表明，我们提出的方法比最先进的无模型RL和记忆增强RL算法学习更快，同时保持良好的长期性能。简而言之，CEC可以是学习连续控制任务的快速方法。

    Non-parametric episodic memory can be used to quickly latch onto high-rewarded experience in reinforcement learning tasks. In contrast to parametric deep reinforcement learning approaches in which reward signals need to be back-propagated slowly, these methods only need to discover the solution once, and may then repeatedly solve the task. However, episodic control solutions are stored in discrete tables, and this approach has so far only been applied to discrete action space problems. Therefore, this paper introduces Continuous Episodic Control (CEC), a novel non-parametric episodic memory algorithm for sequential decision making in problems with a continuous action space. Results on several sparse-reward continuous control environments show that our proposed method learns faster than state-of-the-art model-free RL and memory-augmented RL algorithms, while maintaining good long-run performance as well. In short, CEC can be a fast approach for learning in continuous control tasks.
    
[^89]: 熔炉2.0

    Melting Pot 2.0. (arXiv:2211.13746v4 [cs.MA] UPDATED)

    [http://arxiv.org/abs/2211.13746](http://arxiv.org/abs/2211.13746)

    研究工具Melting Pot 2.0为多智能体人工智能提供了评估协议，在一组典型测试场景中测量它们对新颖社交伙伴的泛化能力。

    

    多智能体人工智能研究承诺开发比“自我中心”方法更具人类特点和更易于与人类兼容的智能技术。 Melting Pot是为促进多智能体人工智能工作而开发的研究工具，并提供一个评估协议，该协议在一组典型的测试场景中测量对新颖社交伙伴的泛化能力。每种情景将一个物理环境（“基板”）与一组参考合作者（“背景人群”）配对，以创建一个具有个体间相互依存性的社交情境。例如，一些情形受到了基于制度经济学的自然资源管理和公共物品供给困境的考虑的启发，而其他情形则受到了进化生物学、博弈论和人工生命等方面的考虑所启发。Melting Pot旨在涵盖一组最大多样化的情形。

    Multi-agent artificial intelligence research promises a path to develop intelligent technologies that are more human-like and more human-compatible than those produced by "solipsistic" approaches, which do not consider interactions between agents. Melting Pot is a research tool developed to facilitate work on multi-agent artificial intelligence, and provides an evaluation protocol that measures generalization to novel social partners in a set of canonical test scenarios. Each scenario pairs a physical environment (a "substrate") with a reference set of co-players (a "background population"), to create a social situation with substantial interdependence between the individuals involved. For instance, some scenarios were inspired by institutional-economics-based accounts of natural resource management and public-good-provision dilemmas. Others were inspired by considerations from evolutionary biology, game theory, and artificial life. Melting Pot aims to cover a maximally diverse set of 
    
[^90]: GammaE: 基于Gamma分布的知识图谱逻辑查询嵌入

    GammaE: Gamma Embeddings for Logical Queries on Knowledge Graphs. (arXiv:2210.15578v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.15578](http://arxiv.org/abs/2210.15578)

    GammaE是一种新颖的概率嵌入模型，利用了Gamma分布的线性特性和强边界支持来捕捉实体和查询的更多特征，解决了知识图谱中否定和联合算符的建模问题，并在知识图谱上回答不同类型的FOL查询。

    

    将知识图谱（KG）进行嵌入以进行多跳逻辑推理是一个具有挑战性的问题，因为许多KG具有庞大而复杂的结构。最近，许多有前途的工作将实体和查询投影到几何空间中以有效地找到答案。但是，建模否定和联合运算符仍然具有挑战性。否定运算符没有严格的边界，这会生成重叠的嵌入并导致获得模糊的答案。另一个限制是并集运算符是非闭合的，这削弱了模型处理一系列并集运算符的能力。为了解决这些问题，我们提出了一个新颖的概率嵌入模型，即Gamma Embeddings（GammaE），用于编码实体和查询以回答KG上不同类型的FOL查询。我们利用了Gamma分布的线性特性和强边界支持来捕捉实体和查询的更多特征，从而极大地减少了模型的不确定性。此外，GammaE实现了统一的框架来处理否定和联合运算符。

    Embedding knowledge graphs (KGs) for multi-hop logical reasoning is a challenging problem due to massive and complicated structures in many KGs. Recently, many promising works projected entities and queries into a geometric space to efficiently find answers. However, it remains challenging to model the negation and union operator. The negation operator has no strict boundaries, which generates overlapped embeddings and leads to obtaining ambiguous answers. An additional limitation is that the union operator is non-closure, which undermines the model to handle a series of union operators. To address these problems, we propose a novel probabilistic embedding model, namely Gamma Embeddings (GammaE), for encoding entities and queries to answer different types of FOL queries on KGs. We utilize the linear property and strong boundary support of the Gamma distribution to capture more features of entities and queries, which dramatically reduces model uncertainty. Furthermore, GammaE implements
    
[^91]: 破碎的神经缩放定律

    Broken Neural Scaling Laws. (arXiv:2210.14891v7 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.14891](http://arxiv.org/abs/2210.14891)

    本文提出了一个平滑破碎的幂律函数形式，可以准确地模拟和外推深度神经网络的缩放行为，适用于各种架构和大量不同任务，包括视觉、语言、音频、视频、生成建模、对比学习、机器人、不确定性估计/校准、对抗鲁棒性、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。

    This paper proposes a smoothly broken power law functional form (referred to as a Broken Neural Scaling Law (BNSL)) that accurately models and extrapolates the scaling behaviors of deep neural networks for various architectures and a large and diverse set of tasks, including vision, language, audio, video, generative modeling, contrastive learning, robotics, uncertainty estimation/calibration, adversarial robustness, molecules, computer programming/coding, math word problems, arithmetic, unsupervised/self-supervised learning, and reinforcement learning.

    我们提出了一个平滑破碎的幂律函数形式（我们称之为破碎的神经缩放定律（BNSL）），它准确地模拟和外推了深度神经网络的缩放行为（即感兴趣的评估指标随用于训练的计算量、模型参数数量、训练数据集大小或上游性能变化而变化）对于各种架构和大量不同任务中的每个任务，包括大规模视觉、语言、音频、视频、扩散、生成建模、多模态学习、对比学习、AI对齐、机器人、超出分布（OOD）泛化、持续学习、不确定性估计/校准、超出分布检测、对抗鲁棒性、蒸馏、分子、计算机编程/编码、数学单词问题、算术、无监督/自监督学习和强化学习。

    We present a smoothly broken power law functional form (referred to by us as a Broken Neural Scaling Law (BNSL)) that accurately models and extrapolates the scaling behaviors of deep neural networks (i.e. how the evaluation metric of interest varies as the amount of compute used for training, number of model parameters, training dataset size, or upstream performance varies) for various architectures and for each of various tasks within a large and diverse set of upstream and downstream tasks, in zero-shot, prompted, and fine-tuned settings. This set includes large-scale vision, language, audio, video, diffusion, generative modeling, multimodal learning, contrastive learning, AI alignment, robotics, out-of-distribution (OOD) generalization, continual learning, uncertainty estimation / calibration, out-of-distribution detection, adversarial robustness, distillation, molecules, computer programming/coding, math word problems, arithmetic, unsupervised/self-supervised learning, and reinforc
    
[^92]: 优化层的交替微分

    Alternating Differentiation for Optimization Layers. (arXiv:2210.01802v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.01802](http://arxiv.org/abs/2210.01802)

    Alt-Diff是一种新的框架，可以在不需要对整个雅可比矩阵进行昂贵计算的情况下，以快速和递归的方式微分优化问题，从而大大提高隐式微分的计算速度。

    

    将优化问题嵌入深度神经网络作为优化层以编码约束和归纳先验的想法在近年来已经深入人心。现有的大多数方法都集中在以一种需要在雅可比矩阵上进行昂贵计算的方式隐式微分Karush-Kuhn-Tucker（KKT）条件上，这可能是慢和内存密集的。在本文中，我们开发了一种名为交替微分（Alt-Diff）的新框架，以一种快速且递归的方式微分优化问题（这里特别指带有多面体约束的凸优化问题）。Alt-Diff将微分过程分解为主问题更新和对偶问题更新的交替方式。因此，Alt-Diff尤其能够减小雅可比矩阵的维度，特别是针对具有大规模约束的优化问题，从而提高了隐式微分的计算速度。我们展示了通过Alt-Diff获得的梯度

    The idea of embedding optimization problems into deep neural networks as optimization layers to encode constraints and inductive priors has taken hold in recent years. Most existing methods focus on implicitly differentiating Karush-Kuhn-Tucker (KKT) conditions in a way that requires expensive computations on the Jacobian matrix, which can be slow and memory-intensive. In this paper, we developed a new framework, named Alternating Differentiation (Alt-Diff), that differentiates optimization problems (here, specifically in the form of convex optimization problems with polyhedral constraints) in a fast and recursive way. Alt-Diff decouples the differentiation procedure into a primal update and a dual update in an alternating way. Accordingly, Alt-Diff substantially decreases the dimensions of the Jacobian matrix especially for optimization with large-scale constraints and thus increases the computational speed of implicit differentiation. We show that the gradients obtained by Alt-Diff a
    
[^93]: 自学习对大脑解码的益处研究

    On the benefits of self-taught learning for brain decoding. (arXiv:2209.10099v4 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2209.10099](http://arxiv.org/abs/2209.10099)

    本文探索了利用大量公共神经成像数据库进行自学习的方法，以改善大脑解码的性能。研究表明这种方法可以提高分类器的性能，但其益处的大小受到多个因素的影响。

    

    本文研究了在自学习框架下使用大规模公共神经成像数据库中的功能磁共振成像统计图的好处，以改善解码新任务时的表现。首先，我们利用NeuroVault数据库，在一些相关的统计图上训练卷积自动编码器，对这些图进行重建。然后，我们使用这个已训练好的编码器来初始化一个有监督的卷积神经网络，以对从NeuroVault数据库大量收集的未见过的统计图的任务或认知过程进行分类。我们发现自学习过程始终可以提高分类器的性能，但其益处的大小强烈依赖于预训练和微调模型使用的样本数量以及目标下游任务的复杂度。

    Context. We study the benefits of using a large public neuroimaging database composed of fMRI statistic maps, in a self-taught learning framework, for improving brain decoding on new tasks. First, we leverage the NeuroVault database to train, on a selection of relevant statistic maps, a convolutional autoencoder to reconstruct these maps. Then, we use this trained encoder to initialize a supervised convolutional neural network to classify tasks or cognitive processes of unseen statistic maps from large collections of the NeuroVault database. Results. We show that such a self-taught learning process always improves the performance of the classifiers but the magnitude of the benefits strongly depends on the number of samples available both for pre-training and finetuning the models and on the complexity of the targeted downstream task. Conclusion. The pre-trained model improves the classification performance and displays more generalizable features, less sensitive to individual differenc
    
[^94]: 深度符号学习：从感知中发现符号和规则

    Deep Symbolic Learning: Discovering Symbols and Rules from Perceptions. (arXiv:2208.11561v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.11561](http://arxiv.org/abs/2208.11561)

    DSL是一种能够在学习中自动发现有意义符号规则的NeSy系统，并在各种任务中取得最先进的结果。

    

    神经符号（NeSy）集成将符号推理与神经网络（NN）结合起来，用于需要感知和推理的任务。大多数NeSy系统依赖于逻辑知识的连续放松，并且模型管道内不做出离散决策。此外，这些方法假定给定符号规则。本文提出了深度符号学习（DSL），一种NeSy系统，它可以学习NeSy函数，即将连续数据映射到离散符号的（一组）感知函数的组合和符号函数。DSL同时学习感知和符号函数，仅在它们的组合（NeSy函数）上进行培训。DSL的关键创新在于，它可以在可微的NN学习管道内创建内部（可解释的）符号表示，并将它们映射到感知输入。创建的符号是自动选择的，以生成最好解释数据的符号函数。我们提供了一系列关于合成和真实数据集的实验，展示了DSL在各种任务中学习符号规则和发现有意义的符号的能力，并取得了最先进的结果。

    Neuro-Symbolic (NeSy) integration combines symbolic reasoning with Neural Networks (NNs) for tasks requiring perception and reasoning. Most NeSy systems rely on continuous relaxation of logical knowledge, and no discrete decisions are made within the model pipeline. Furthermore, these methods assume that the symbolic rules are given. In this paper, we propose Deep Symbolic Learning (DSL), a NeSy system that learns NeSy-functions, i.e., the composition of a (set of) perception functions which map continuous data to discrete symbols, and a symbolic function over the set of symbols. DSL learns simultaneously the perception and symbolic functions while being trained only on their composition (NeSy-function). The key novelty of DSL is that it can create internal (interpretable) symbolic representations and map them to perception inputs within a differentiable NN learning pipeline. The created symbols are automatically selected to generate symbolic functions that best explain the data. We pr
    
[^95]: 一种符合保序的风险控制方法

    Conformal Risk Control. (arXiv:2208.02814v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2208.02814](http://arxiv.org/abs/2208.02814)

    该论文提出了一种符合保序的风险控制方法，可以控制任何单调损失函数的期望值，示例证明其在计算机视觉和自然语言处理领域具有控制误报率、图形距离和令牌级F1得分的能力。

    

    我们将符合性预测推广至控制任何单调损失函数的期望值。该算法将分裂符合性预测及其覆盖保证进行了泛化。类似于符合性预测，符合保序的风险控制方法在$\mathcal{O}(1/n)$因子内保持紧密性。计算机视觉和自然语言处理领域的示例证明了我们算法在控制误报率、图形距离和令牌级F1得分方面的应用。

    We extend conformal prediction to control the expected value of any monotone loss function. The algorithm generalizes split conformal prediction together with its coverage guarantee. Like conformal prediction, the conformal risk control procedure is tight up to an $\mathcal{O}(1/n)$ factor. Worked examples from computer vision and natural language processing demonstrate the usage of our algorithm to bound the false negative rate, graph distance, and token-level F1-score.
    
[^96]: 跨模态因果关系推理在事件级视觉问答中的应用

    Cross-Modal Causal Relational Reasoning for Event-Level Visual Question Answering. (arXiv:2207.12647v5 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2207.12647](http://arxiv.org/abs/2207.12647)

    本篇论文提出了一个新型的事件级视觉问答框架——跨模态因果关系推理（CMCIR），通过引入因果干预方法，发现视觉和语言模态的真正因果结构，实现强健的因果感知视觉语言问答。

    

    现有的视觉问答方法往往捕捉跨模态的伪相关性，而未能发现真正的因果机制，以真实地基于主导视觉证据和问题意图进行推理。此外，现有方法通常忽略了跨模态事件级理解，需要联合建模事件的时间性、因果性和动态性。在本文中，我们从新的角度，即跨模态因果关系推理，聚焦于事件级视觉问答，引入因果干预方法来发现视觉和语言模态的真正因果结构。具体而言，我们提出了一个名为跨模态因果关系推理（CMCIR）的新型事件级视觉问答框架，以实现强健的因果感知视觉语言问答。为了发现跨模态因果结构，我们提出了因果感知视觉语言推理（CVLR）模块，用于共同对视觉和语言模态建模。

    Existing visual question answering methods tend to capture the cross-modal spurious correlations and fail to discover the true causal mechanism that facilitates reasoning truthfully based on the dominant visual evidence and the question intention. Additionally, the existing methods usually ignore the cross-modal event-level understanding that requires to jointly model event temporality, causality, and dynamics. In this work, we focus on event-level visual question answering from a new perspective, i.e., cross-modal causal relational reasoning, by introducing causal intervention methods to discover the true causal structures for visual and linguistic modalities. Specifically, we propose a novel event-level visual question answering framework named Cross-Modal Causal RelatIonal Reasoning (CMCIR), to achieve robust causality-aware visual-linguistic question answering. To discover cross-modal causal structures, the Causality-aware Visual-Linguistic Reasoning (CVLR) module is proposed to co
    
[^97]: 基于处理内存系统的机器学习训练的实验评估

    An Experimental Evaluation of Machine Learning Training on a Real Processing-in-Memory System. (arXiv:2207.07886v2 [cs.AR] UPDATED)

    [http://arxiv.org/abs/2207.07886](http://arxiv.org/abs/2207.07886)

    该研究评估了在处理内存系统上训练机器学习算法的潜能，并证明基于PIM的ML训练实现了显着的加速和能量效率。

    

    训练机器学习算法是一种计算密集型的过程，由于不断访问大型训练数据集，这种过程通常会受到内存限制。因此，以处理器为中心的系统（例如CPU，GPU）在内存单元和处理单元之间的数据传输方面存在昂贵的瓶颈，这会消耗大量的能量和执行周期。具有处理内存（PIM）功能的内存中心计算系统可以缓解这种数据移动瓶颈。我们的目标是了解现代通用PIM架构加速ML训练的潜力。为此，我们（1）在实际通用PIM架构上实现了几种代表性的传统ML算法（即线性回归，逻辑回归，决策树，K-Means聚类），（2）严格评估和表征这些算法的准确性，性能和扩展性，并且（3）与它们在CPU和GPU上的相应实现进行比较。我们在实际内存中心计算平台上的评估表明，与相应的CPU和GPU方法相比，基于PIM的ML训练实现了显着的加速和能量效率。

    Training machine learning (ML) algorithms is a computationally intensive process, which is frequently memory-bound due to repeatedly accessing large training datasets. As a result, processor-centric systems (e.g., CPU, GPU) suffer from costly data movement between memory units and processing units, which consumes large amounts of energy and execution cycles. Memory-centric computing systems, i.e., with processing-in-memory (PIM) capabilities, can alleviate this data movement bottleneck.  Our goal is to understand the potential of modern general-purpose PIM architectures to accelerate ML training. To do so, we (1) implement several representative classic ML algorithms (namely, linear regression, logistic regression, decision tree, K-Means clustering) on a real-world general-purpose PIM architecture, (2) rigorously evaluate and characterize them in terms of accuracy, performance and scaling, and (3) compare to their counterpart implementations on CPU and GPU. Our evaluation on a real mem
    
[^98]: 连续时间下的q-Learning

    q-Learning in Continuous Time. (arXiv:2207.00713v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.00713](http://arxiv.org/abs/2207.00713)

    本文研究了连续时间下的q-Learning，通过引入小q函数作为一阶近似，研究了q-learning理论，应用于设计不同的演员-评论家算法。

    

    我们研究了基于熵正则化的探索性扩散过程的Q-learning在连续时间下的应用。我们引入了“小q函数”作为大Q函数的一阶近似，研究了q函数的q-learning理论，并应用于设计不同的演员-评论家算法。

    We study the continuous-time counterpart of Q-learning for reinforcement learning (RL) under the entropy-regularized, exploratory diffusion process formulation introduced by Wang et al. (2020). As the conventional (big) Q-function collapses in continuous time, we consider its first-order approximation and coin the term ``(little) q-function". This function is related to the instantaneous advantage rate function as well as the Hamiltonian. We develop a ``q-learning" theory around the q-function that is independent of time discretization. Given a stochastic policy, we jointly characterize the associated q-function and value function by martingale conditions of certain stochastic processes, in both on-policy and off-policy settings. We then apply the theory to devise different actor-critic algorithms for solving underlying RL problems, depending on whether or not the density function of the Gibbs measure generated from the q-function can be computed explicitly. One of our algorithms inter
    
[^99]: 应用认知体系结构考虑反黑和种族主义对AI系统设计和开发的影响

    Using a Cognitive Architecture to consider antiblackness in design and development of AI systems. (arXiv:2207.00644v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2207.00644](http://arxiv.org/abs/2207.00644)

    本文利用ACT-R/{\Phi}认知体系结构和现有的知识图系统ConceptNet，从认知、社会文化和生理学三个角度考虑反黑和种族主义对AI系统的影响，并认为在认知建模中典型的回避社会文化过程和知识结构，隐含地推动了认知建模的色盲方法，并隐藏了总是存在于AI系统中的社会文化背景。

    

    我们如何利用认知建模来考虑反黑和种族主义更广泛地影响AI系统的设计和开发？我们提供了一个讨论和一个示例来回答这个问题。我们使用ACT-R/{\Phi}认知体系结构和现有的知识图系统ConceptNet，不仅从认知和社会文化的角度考虑这个问题，也从生理学的角度考虑。除了利用认知建模来探索反黑如何在AI系统的设计和开发中表现出来（尤其是从软件工程的角度），我们还介绍了反黑、人类和计算认知建模之间的联系。我们认为，在认知体系结构和认知建模中典型的回避社会文化过程和知识结构，隐含地推动了认知建模的色盲方法，并隐藏了总是存在于AI系统中的社会文化背景。

    How might we use cognitive modeling to consider the ways in which antiblackness, and racism more broadly, impact the design and development of AI systems? We provide a discussion and an example towards an answer to this question. We use the ACT-R/{\Phi} cognitive architecture and an existing knowledge graph system, ConceptNet, to consider this question not only from a cognitive and sociocultural perspective, but also from a physiological perspective. In addition to using a cognitive modeling as a means to explore how antiblackness may manifest in the design and development of AI systems (particularly from a software engineering perspective), we also introduce connections between antiblackness, the Human, and computational cognitive modeling. We argue that the typical eschewing of sociocultural processes and knowledge structures in cognitive architectures and cognitive modeling implicitly furthers a colorblind approach to cognitive modeling and hides sociocultural context that is always
    
[^100]: 超越神经尺度定律：通过数据修剪打败幂律尺度

    Beyond neural scaling laws: beating power law scaling via data pruning. (arXiv:2206.14486v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.14486](http://arxiv.org/abs/2206.14486)

    本研究通过数据修剪算法突破神经网络训练集大小与模型误差幂律的尺度界限，并在多个数据集实验中验证了有效性，同时进行了首次大规模数据修剪算法基准测试研究。

    

    普遍存在的神经尺度定律以训练集大小、模型规模或两者的幂为模型误差下降的驱动力，为深度学习带来了显著的性能提升。但是，仅通过尺度来实现这些改进需要巨大的计算和能源成本。本文着重研究数据集大小与误差比例的尺度，并展示理论上我们如何突破幂律尺度，并在pruning算法条件下潜在地甚至能将其降至指数尺度。我们接着在CIFAR-10、SVHN和ImageNet的ResNet上进行了实验验证，并观察到实践中优于幂律尺度的表现。此外，鉴于寻找优质pruning算法的重要性，我们对ImageNet上的十种不同的数据修剪算法进行了首次大规模基准测试研究。

    Widely observed neural scaling laws, in which error falls off as a power of the training set size, model size, or both, have driven substantial performance improvements in deep learning. However, these improvements through scaling alone require considerable costs in compute and energy. Here we focus on the scaling of error with dataset size and show how in theory we can break beyond power law scaling and potentially even reduce it to exponential scaling instead if we have access to a high-quality data pruning metric that ranks the order in which training examples should be discarded to achieve any pruned dataset size. We then test this improved scaling prediction with pruned dataset size empirically, and indeed observe better than power law scaling in practice on ResNets trained on CIFAR-10, SVHN, and ImageNet. Next, given the importance of finding high-quality pruning metrics, we perform the first large-scale benchmarking study of ten different data pruning metrics on ImageNet. We fin
    
[^101]: ACMP: Allen-Cahn信息传递用于带有物质相变的图神经网络

    ACMP: Allen-Cahn Message Passing for Graph Neural Networks with Particle Phase Transition. (arXiv:2206.05437v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.05437](http://arxiv.org/abs/2206.05437)

    本文提出了一种基于ACMP的图神经网络模型，它可以通过具有吸引力和排斥力的相互作用粒子系统进行消息传递传播，克服了GNN过度平滑问题，将网络深度推到100层，并在基准数据集上实现了最先进的节点分类和图匹配性能。

    

    神经消息传递是基于图结构数据的特征提取单元，考虑从一层到下一层的网络传播中的相邻节点特征。我们通过具有吸引力和排斥力的相互作用粒子系统来建模这种过程，并在相变建模中引入Allen-Cahn力。系统的动力学是一种反应扩散过程，可以将粒子分离而不会扩散。这引出了一种Allen-Cahn信息传递(ACMP)用于图神经网络，其中粒子系统解的数值迭代构成了消息传递传播。ACMP具有简单的实现和神经ODE求解器，可以将网络深度推到100层，并具有理论上证明的Dirichlet能量严格正下界。因此，它提供了一种深度模型的GNN，避免了常见的GNN过度平滑问题。使用ACMP的GNN在基准数据集上实现了实际节点分类和图匹配任务的最先进性能。

    Neural message passing is a basic feature extraction unit for graph-structured data considering neighboring node features in network propagation from one layer to the next. We model such process by an interacting particle system with attractive and repulsive forces and the Allen-Cahn force arising in the modeling of phase transition. The dynamics of the system is a reaction-diffusion process which can separate particles without blowing up. This induces an Allen-Cahn message passing (ACMP) for graph neural networks where the numerical iteration for the particle system solution constitutes the message passing propagation. ACMP which has a simple implementation with a neural ODE solver can propel the network depth up to one hundred of layers with theoretically proven strictly positive lower bound of the Dirichlet energy. It thus provides a deep model of GNNs circumventing the common GNN problem of oversmoothing. GNNs with ACMP achieve state of the art performance for real-world node class
    
[^102]: Merlin-Arthur分类器的形式可解释性

    Formal Interpretability with Merlin-Arthur Classifiers. (arXiv:2206.00759v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.00759](http://arxiv.org/abs/2206.00759)

    该论文提出了一种新型的多智能体交互分类器，利用“Merlin-Arthur”协议的启发，在不假设最优智能体或特征独立分布的情况下，通过相对强度和“非对称特征相关性”概念捕捉特征之间精确的相关性，提供可证明的可解释性保证。

    

    我们提出了一种新类型的多智能体交互分类器，即使是像神经网络这样的复杂智能体也能提供可证明的可解释性保证。这些保证包括对此分类器选择的特征之间互信息的上下界约束。我们的结果受交互式证明系统中 Merlin-Arthur 协议的启发，并以可测量的指标（如声音和完整性）表达了这些约束。与现有的交互式设置相比，我们不依赖于最优智能体或特征独立分布的假设。相反，我们利用智能体的相对强度以及新的“非对称特征相关性”概念来捕捉使可解释性保证困难的精确相关性类型。 我们通过两个小规模数据集的数值实验来测试我们的结果，这些实验可验证高互信息性。

    We propose a new type of multi-agent interactive classifier that provides provable interpretability guarantees even for complex agents such as neural networks. These guarantees consist of bounds on the mutual information of the features selected by this classifier. Our results are inspired by the Merlin-Arthur protocol from Interactive Proof Systems and express these bounds in terms of measurable metrics such as soundness and completeness. Compared to existing interactive setups we do not rely on optimal agents or on the assumption that features are distributed independently. Instead, we use the relative strength of the agents as well as the new concept of Asymmetric Feature Correlation which captures the precise kind of correlations that make interpretability guarantees difficult. %relates the information carried by sets of features to one of the individual features. We test our results through numerical experiments on two small-scale datasets where high mutual information can be veri
    
[^103]: 令人沮丧的简单正则化可以提升深度强化学习的效果

    Frustratingly Easy Regularization on Representation Can Boost Deep Reinforcement Learning. (arXiv:2205.14557v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.14557](http://arxiv.org/abs/2205.14557)

    本文证明了DRL的学习表示应该满足一个有利的可区分表示属性，提出了一种正则化器PEER，旨在通过对内部表示进行显式正则化来维持可区分表示属性。

    

    深度强化学习(DRL)承诺代理能够从高维信息中学习到良好的策略，而表示学习则能够消除不相关和冗余的信息并保留相关的信息。本文证明了Q网络及其目标Q网络的学习表示在理论上应该满足一个有利的可区分表示属性。具体来说，在典型的DRL设置中两个相邻时间步长的价值函数的表示相似度存在一个上界。但是，通过说明性实验，我们发现学习到的DRL代理可能违反这个属性，并导致次优策略。因此，我们提出了一种名为"表示简单正则化的策略评估"(PEER)的简单而有效的正则化器，旨在通过对内部表示进行显式正则化来维持可区分表示属性。同时，我们提供了收敛速度分析。

    Deep reinforcement learning (DRL) gives the promise that an agent learns good policy from high-dimensional information, whereas representation learning removes irrelevant and redundant information and retains pertinent information. In this work, we demonstrate that the learned representation of the $Q$-network and its target $Q$-network should, in theory, satisfy a favorable distinguishable representation property. Specifically, there exists an upper bound on the representation similarity of the value functions of two adjacent time steps in a typical DRL setting. However, through illustrative experiments, we show that the learned DRL agent may violate this property and lead to a sub-optimal policy. Therefore, we propose a simple yet effective regularizer called Policy Evaluation with Easy Regularization on Representation (PEER), which aims to maintain the distinguishable representation property via explicit regularization on internal representations. And we provide the convergence rate
    
[^104]: 证明块问题中的高效反馈和部分分评分

    Efficient Feedback and Partial Credit Grading for Proof Blocks Problems. (arXiv:2204.04196v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2204.04196](http://arxiv.org/abs/2204.04196)

    本文提出了一个算法，可以高效地计算学生提交作业与预定义解决方案之间的编辑距离，可应用于证明、编程与自然语言处理等领域。

    

    证明块是一种软件工具，允许学生通过拖放而非从头写证明，练习数学证明的写作。证明块提供了分部分分和提供解决方案质量反馈的能力。这是通过计算学生提交的作业与一些预定义解决方案之间的编辑距离来完成的。本文提出了一种编辑距离问题的算法，显著优于排列整个搜索空间的基线程序。我们的算法依赖于将问题的缩减为最小顶点覆盖问题。我们在多个课程的数千份学生提交中对我们的算法进行了基准测试，表明基线算法难以计算，并且我们提出的算法对于实现课堂部署至关重要。我们新的算法也已经被用于许多其他领域的问题，其中解决方案空间可以建模为DAG，包括但不限于编程作业和自然语言处理任务。

    Proof Blocks is a software tool that allows students to practice writing mathematical proofs by dragging and dropping lines instead of writing proofs from scratch. Proof Blocks offers the capability of assigning partial credit and providing solution quality feedback to students. This is done by computing the edit distance from a student's submission to some predefined set of solutions. In this work, we propose an algorithm for the edit distance problem that significantly outperforms the baseline procedure of exhaustively enumerating over the entire search space. Our algorithm relies on a reduction to the minimum vertex cover problem. We benchmark our algorithm on thousands of student submissions from multiple courses, showing that the baseline algorithm is intractable, and that our proposed algorithm is critical to enable classroom deployment. Our new algorithm has also been used for problems in many other domains where the solution space can be modeled as a DAG, including but not limi
    
[^105]: 问题-回答句子图用于联合建模答案选择

    Question-Answer Sentence Graph for Joint Modeling Answer Selection. (arXiv:2203.03549v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2203.03549](http://arxiv.org/abs/2203.03549)

    本文研究了基于图的方法用于答案选择，通过构建相关训练图并集成最先进模型，成功解决了检索型问答系统中的AS2任务，并在实验中表现优异。

    

    本研究研究了基于图的方法用于答案选择（AS2），这是检索型问答（QA）系统的重要组成部分。在离线学习中，我们的模型以无监督的方式为每个问题构建一个小规模的相关训练图，并与图神经网络集成。图节点是问题句子到答案句子的对。我们训练并集成了用于计算问题-问题、问题-答案和答案-答案对之间得分的最先进模型，并使用相关得分阈值来创建图边缘。然后进行在线推理以解决看不见的查询的AS2任务。在两个知名的学术基准和一个现实世界的数据集上的实验表明，我们的方法始终优于SOTA QA基线模型。

    This research studies graph-based approaches for Answer Sentence Selection (AS2), an essential component for retrieval-based Question Answering (QA) systems. During offline learning, our model constructs a small-scale relevant training graph per question in an unsupervised manner, and integrates with Graph Neural Networks. Graph nodes are question sentence to answer sentence pairs. We train and integrate state-of-the-art (SOTA) models for computing scores between question-question, question-answer, and answer-answer pairs, and use thresholding on relevance scores for creating graph edges. Online inference is then performed to solve the AS2 task on unseen queries. Experiments on two well-known academic benchmarks and a real-world dataset show that our approach consistently outperforms SOTA QA baseline models.
    
[^106]: 关于分摊优化的教程

    Tutorial on amortized optimization. (arXiv:2202.00665v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.00665](http://arxiv.org/abs/2202.00665)

    该教程介绍了分摊优化的基础，并总结了其在变分推断、稀疏编码、元学习、控制、强化学习、凸优化、最优传输和深度平衡网络中的应用。

    

    优化是一种普遍的建模工具，经常在反复解决相同问题的情况下使用。分摊优化方法使用学习来预测这些设置中问题的解决方案，利用相似问题实例之间的共享结构。这些方法在变分推断和强化学习中至关重要，能够比不使用分摊的传统优化方法快几个数量级地解决优化问题。本次教程介绍了这些进步背后的分摊优化基础，并概述了它们在变分推断、稀疏编码、基于梯度的元学习、控制、强化学习、凸优化、最优传输和深度平衡网络中的应用。本教程的源代码可在https://github.com/facebookresearch/amortized-optimization-tutorial上获得。

    Optimization is a ubiquitous modeling tool and is often deployed in settings which repeatedly solve similar instances of the same problem. Amortized optimization methods use learning to predict the solutions to problems in these settings, exploiting the shared structure between similar problem instances. These methods have been crucial in variational inference and reinforcement learning and are capable of solving optimization problems many orders of magnitudes times faster than traditional optimization methods that do not use amortization. This tutorial presents an introduction to the amortized optimization foundations behind these advancements and overviews their applications in variational inference, sparse coding, gradient-based meta-learning, control, reinforcement learning, convex optimization, optimal transport, and deep equilibrium networks. The source code for this tutorial is available at https://github.com/facebookresearch/amortized-optimization-tutorial.
    
[^107]: FedMed-GAN: 基于联邦学习的无监督跨模态脑图像合成与翻译

    FedMed-GAN: Federated Domain Translation on Unsupervised Cross-Modality Brain Image Synthesis. (arXiv:2201.08953v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2201.08953](http://arxiv.org/abs/2201.08953)

    本文提出了一种新的基准方法FedMed-GAN: 用于联邦学习和医疗GAN之间的无监督脑图像合成和翻译,具有模式崩溃现象小、数据性能高等优点，广泛适用于不配对和配对数据集的联邦训练。

    

    利用多模态神经影像数据被证明对于研究人类认知活动和某些疾病很有效。然而，由于高昂的检查成本、长时间的获取时间和图像损坏等多种限制，集中获得完整配对的神经影像数据是不现实的。此外，这些数据分散在不同的医疗机构中，由于隐私问题无法进行中央集中培训。因此，迫切需要开展联邦学习，促进来自不同机构的分散数据的集成。本文提出了一个新的基准方法-FedMed-GAN，用于联邦领域翻译和无监督脑图像合成上，弥补了联邦学习和医疗GAN之间的差距。FedMed-GAN通过减轻模式崩溃现象而不损失生成器的性能，并广泛应用于联邦设置下不配对、配对数据集的不同比例。实验结果表明，我们的方法在公共数据集和真实临床数据上都达到了最先进的性能，证明了其在无监督跨模态脑图像合成方面的有效性。

    Utilizing multi-modal neuroimaging data has been proved to be effective to investigate human cognitive activities and certain pathologies. However, it is not practical to obtain the full set of paired neuroimaging data centrally since the collection faces several constraints, e.g., high examination cost, long acquisition time, and image corruption. In addition, these data are dispersed into different medical institutions and thus cannot be aggregated for centralized training considering the privacy issues. There is a clear need to launch a federated learning and facilitate the integration of the dispersed data from different institutions. In this paper, we propose a new benchmark for federated domain translation on unsupervised brain image synthesis (termed as FedMed-GAN) to bridge the gap between federated learning and medical GAN. FedMed-GAN mitigates the mode collapse without sacrificing the performance of generators, and is widely applied to different proportions of unpaired and pa
    
[^108]: 深度强化学习，一本教材

    Deep Reinforcement Learning, a textbook. (arXiv:2201.02135v5 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2201.02135](http://arxiv.org/abs/2201.02135)

    深度强化学习是一种引人注目的技术，计算机程序通过尝试、得到反馈和再次尝试来自我解决困难问题，甚至在某些领域比最好的人类表现更好。

    

    最近，深度强化学习引起了很多关注。在自动驾驶、游戏玩法、分子重组和机器人等各个领域都取得了惊人的成果。在所有这些领域中，计算机程序已经学会了自我解决困难问题。它们已经学会了飞行模型直升机和进行像环和翻滚这样的特技动作。在某些应用中，它们甚至比最好的人类表现得更好，例如 Atari、围棋、扑克和星际争霸。深度强化学习探索复杂环境的方式让我们想起了孩子们的学习方式，通过尝试、得到反馈和再次尝试来充满乐趣地学习。计算机似乎真正具备了人类学习的方面，这触动了人工智能梦想的核心。研究成功引起了教育工作者的关注，学校开始开设相关课程。本书的目的就是提供深度强化学习的全面概述。

    Deep reinforcement learning has gathered much attention recently. Impressive results were achieved in activities as diverse as autonomous driving, game playing, molecular recombination, and robotics. In all these fields, computer programs have taught themselves to solve difficult problems. They have learned to fly model helicopters and perform aerobatic manoeuvers such as loops and rolls. In some applications they have even become better than the best humans, such as in Atari, Go, poker and StarCraft. The way in which deep reinforcement learning explores complex environments reminds us of how children learn, by playfully trying out things, getting feedback, and trying again. The computer seems to truly possess aspects of human learning; this goes to the heart of the dream of artificial intelligence. The successes in research have not gone unnoticed by educators, and universities have started to offer courses on the subject. The aim of this book is to provide a comprehensive overview of
    
[^109]: 演示指导的规范搜索

    Demonstration Informed Specification Search. (arXiv:2112.10807v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2112.10807](http://arxiv.org/abs/2112.10807)

    本文提出了演示指导的规范搜索（DISS）算法，可以从专家演示中学习时间任务规范。

    

    本文考虑了从专家演示中学习时间任务规范的问题，例如自动机和时间逻辑。任务规范是一类带有明确的时间和布尔组合支持的稀疏记忆增强奖励。学习时间任务规范具有以下三个困难：（1）（可数的）无限数量的任务；（2）不知道编码任务所需的内存；（3）离散解空间通常需要通过（暴力）枚举。为了克服这些困难，我们提出了演示指导的规范搜索（DISS）：一族只需要黑盒访问最大熵规划器和来自标记示例的任务采样器的算法。然后，DISS通过交替猜测标记示例来使提供的演示变得不那么令人惊讶，并采样与猜测的标记示例一致的任务。我们提供了一个具体实现。

    This paper considers the problem of learning temporal task specifications, e.g. automata and temporal logic, from expert demonstrations. Task specifications are a class of sparse memory augmented rewards with explicit support for temporal and Boolean composition. Three features make learning temporal task specifications difficult: (1) the (countably) infinite number of tasks under consideration; (2) an a-priori ignorance of what memory is needed to encode the task; and (3) the discrete solution space - typically addressed by (brute force) enumeration. To overcome these hurdles, we propose Demonstration Informed Specification Search (DISS): a family of algorithms requiring only black box access to a maximum entropy planner and a task sampler from labeled examples. DISS then works by alternating between conjecturing labeled examples to make the provided demonstrations less surprising and sampling tasks consistent with the conjectured labeled examples. We provide a concrete implementation
    
[^110]: 路用户检测的概率方法

    Probabilistic Approach for Road-Users Detection. (arXiv:2112.01360v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2112.01360](http://arxiv.org/abs/2112.01360)

    本文介绍了一种用于缓解深度目标检测模型中过于自信预测问题的方法，通过引入一种新颖的概率层来避免传统的预测层，实验证明该方法能够减少假阳性中的过度自信。

    

    自动驾驶应用中的目标检测意味着对语义对象的检测和跟踪通常是城市驾驶环境的特色，如行人和车辆。目前最先进的基于深度学习的目标检测中存在假阳性问题，这些问题通常带有过于自信的得分。在自动驾驶和其他关键的机器人感知领域，这是非常不希望看到的，因为涉及安全问题。本文提出了一种方法来缓解过于自信的预测问题，通过在测试中引入一种新颖的概率层，向深度目标检测网络中添加这种概率层。建议的方法避免了传统的Sigmoid或Softmax预测层，这些层通常会产生过于自信的预测。实验证明，所提出的技术能够减少假阳性中的过度自信，而不会降低真阳性的性能。该方法在2D-KITTI目标检测中进行了验证，使用了YOLOV4和S。

    Object detection in autonomous driving applications implies that the detection and tracking of semantic objects are commonly native to urban driving environments, as pedestrians and vehicles. One of the major challenges in state-of-the-art deep-learning based object detection are false positives which occur with overconfident scores. This is highly undesirable in autonomous driving and other critical robotic-perception domains because of safety concerns. This paper proposes an approach to alleviate the problem of overconfident predictions by introducing a novel probabilistic layer to deep object detection networks in testing. The suggested approach avoids the traditional Sigmoid or Softmax prediction layer which often produces overconfident predictions. It is demonstrated that the proposed technique reduces overconfidence in the false positives without degrading the performance on the true positives. The approach is validated on the 2D-KITTI objection detection through the YOLOV4 and S
    
[^111]: PatchCensor：通过穷尽测试提高视觉Transformers的补丁鲁棒性认证

    PatchCensor: Patch Robustness Certification for Transformers via Exhaustive Testing. (arXiv:2111.10481v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2111.10481](http://arxiv.org/abs/2111.10481)

    PatchCensor是一种用于视觉Transformer的补丁鲁棒性认证方法，基于全面测试并考虑最坏的补丁攻击情境，能够提供受保证的准确性。

    

    与其他经典神经网络一样，视觉Transformer（ViT）也被认为是高度非线性的，并且容易受到自然和对抗性补丁扰动的干扰。在真实的工业环境中，这种限制可能对ViT的部署产生威胁，尤其是在安全关键场景中。本文提出了PatchCensor，旨在通过全面测试来证明ViT的补丁鲁棒性。我们试图通过考虑最坏的补丁攻击情境来提供可证明的保证。与那些可能被自适应攻击破坏的对抗性补丁的经验性防御措施不同，认证可靠的方法可以在某些条件下提供对于任意攻击的受保证的准确性。但是，现有的鲁棒性认证主要基于鲁棒性训练，这通常需要大量的训练工作，并且会在正常样本上牺牲模型的性能。为了弥合这一差距，PatchCensor旨在通过检测和剔除不合规则的区域来提高整个系统的鲁棒性。

    Vision Transformer (ViT) is known to be highly nonlinear like other classical neural networks and could be easily fooled by both natural and adversarial patch perturbations. This limitation could pose a threat to the deployment of ViT in the real industrial environment, especially in safety-critical scenarios. In this work, we propose PatchCensor, aiming to certify the patch robustness of ViT by applying exhaustive testing. We try to provide a provable guarantee by considering the worst patch attack scenarios. Unlike empirical defenses against adversarial patches that may be adaptively breached, certified robust approaches can provide a certified accuracy against arbitrary attacks under certain conditions. However, existing robustness certifications are mostly based on robust training, which often requires substantial training efforts and the sacrifice of model performance on normal samples. To bridge the gap, PatchCensor seeks to improve the robustness of the whole system by detecting
    
[^112]: PAIR：利用段落中心的相似关系改进密集型段落检索

    PAIR: Leveraging Passage-Centric Similarity Relation for Improving Dense Passage Retrieval. (arXiv:2108.06027v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2108.06027](http://arxiv.org/abs/2108.06027)

    PAIR算法是一种新方法，在密集型段落检索中同时考虑查询中心和段落中心相似关系，通过正式公式、知识蒸馏和两阶段训练实现。实验证明，该方法优于先前方法。

    

    最近，密集型段落检索已成为在各种自然语言处理任务中找到相关信息的一种主流方法。许多研究致力于改进广泛采用的双编码器架构。但是，大多数以前的研究在学习双编码器检索器时仅考虑了查询中心的相似关系。为了捕捉更全面的相似关系，我们提出了一种新方法，利用查询中心和段落中心的相似关系（称为PAIR）进行密集型段落检索。为了实现我们的方法，我们提出了两种相似关系的正式公式，通过知识蒸馏生成高质量的伪标记数据，并设计了一种有效的两阶段训练过程，其中包括段落中心相似关系约束。广泛的实验表明，我们的方法显著优于先前的方法。

    Recently, dense passage retrieval has become a mainstream approach to finding relevant information in various natural language processing tasks. A number of studies have been devoted to improving the widely adopted dual-encoder architecture. However, most of the previous studies only consider query-centric similarity relation when learning the dual-encoder retriever. In order to capture more comprehensive similarity relations, we propose a novel approach that leverages both query-centric and PAssage-centric sImilarity Relations (called PAIR) for dense passage retrieval. To implement our approach, we make three major technical contributions by introducing formal formulations of the two kinds of similarity relations, generating high-quality pseudo labeled data via knowledge distillation, and designing an effective two-stage training procedure that incorporates passage-centric similarity relation constraint. Extensive experiments show that our approach significantly outperforms previous s
    
[^113]: 一种增加神经网络对数据质量问题的鲁棒性的调制层

    A Modulation Layer to Increase Neural Network Robustness Against Data Quality Issues. (arXiv:2107.08574v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2107.08574](http://arxiv.org/abs/2107.08574)

    提出了一种新颖的神经网络修正方法，用于缓解低质量和缺失数据的影响，具备神经调制特征，通过一个额外的输入的函数替换了全连接层的固定权重，使得在测试中具有调制层的模型对于数据质量的降解更加鲁棒，同时也能够节省训练时间并且不会受到插补错误的影响。

    

    数据缺失和质量是机器学习中常见的问题，特别是在高风险应用领域，如医疗保健。开发者通常只使用高质量数据精心筛选出的数据集来训练机器学习模型；然而，这会降低这些模型在生产环境中的效用。本文提出了一种新颖的神经网络修正方法，用于缓解低质量和缺失数据的影响，其中利用一个额外的输入的函数替换了全连接层的固定权重。这受启发于生物神经网络中的神经调制，皮质可以根据输入的可靠性和其他数据的存在程度上下调节输入。在测试中，使用可靠性得分作为调制信号，发现具有调制层的模型对于数据质量的降解（包括额外的缺失数据）更加鲁棒。这些模型优于插补方法，因为它们通过完全跳过插补过程节省了训练时间，并且不会受到插补错误的影响。

    Data missingness and quality are common problems in machine learning, especially for high-stakes applications such as healthcare. Developers often train machine learning models on carefully curated datasets using only high quality data; however, this reduces the utility of such models in production environments. We propose a novel neural network modification to mitigate the impacts of low quality and missing data which involves replacing the fixed weights of a fully-connected layer with a function of an additional input. This is inspired from neuromodulation in biological neural networks where the cortex can up- and down-regulate inputs based on their reliability and the presence of other data. In testing, with reliability scores as a modulating signal, models with modulating layers were found to be more robust against degradation of data quality, including additional missingness. These models are superior to imputation as they save on training time by completely skipping the imputatio
    
[^114]: 人的注意力在目标定向阅读理解时依赖于任务优化

    Human Attention during Goal-directed Reading Comprehension Relies on Task Optimization. (arXiv:2107.05799v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2107.05799](http://arxiv.org/abs/2107.05799)

    本文研究了阅读理解中人类关注力分配的计算模型。研究表明，在执行相同的阅读任务时，深度神经网络可以预测每个单词的阅读时间，读者在第一遍阅读和重新阅读过程中分别关注基本文本特征和与问题相关的信息，并且文本特征和问题相关性会分别调节注意力权重。

    

    复杂任务中关注力分配的计算原则仍然不明确。目标定向阅读，即阅读一篇文章以回答脑海中的问题，是一种强烈引发注意力的常见真实世界任务。在这里，我们研究了什么计算模型可以解释这种复杂任务中的关注力分配。我们展示了在基于Transformer的深度神经网络（DNN）中，优化执行相同阅读任务的关注权重可以预测每个单词上的阅读时间。眼动跟踪进一步揭示了读者在第一遍阅读和重新阅读过程中分别关注基本文本特征和与问题相关的信息。类似地，文本特征和问题相关性在浅层和深层DNN层中分别调节注意力权重。此外，当读者在脑海中没有问题的情况下扫描一篇文章时，他们的阅读时间可以由为单词预测任务优化的DNN预测。因此，在真实世界的阅读中关注力分配依赖于任务优化。

    The computational principles underlying attention allocation in complex goal-directed tasks remain elusive. Goal-directed reading, i.e., reading a passage to answer a question in mind, is a common real-world task that strongly engages attention. Here, we investigate what computational models can explain attention distribution in this complex task. We show that the reading time on each word is predicted by the attention weights in transformer-based deep neural networks (DNNs) optimized to perform the same reading task. Eye-tracking further reveals that readers separately attend to basic text features and question-relevant information during first-pass reading and rereading, respectively. Similarly, text features and question relevance separately modulate attention weights in shallow and deep DNN layers. Furthermore, when readers scan a passage without a question in mind, their reading time is predicted by DNNs optimized for a word prediction task. Therefore, attention during real-world 
    
[^115]: 医生模仿者：手部放射线检查骨龄评估模型通过模仿医生评分方法

    Doctor Imitator: Hand-Radiography-based Bone Age Assessment by Imitating Scoring Methods. (arXiv:2102.05424v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2102.05424](http://arxiv.org/abs/2102.05424)

    本文提出了一种新的基于手部放射线检查图像的骨龄评估模型Doctor Imitator，通过模仿医生使用评分方法进行诊断逻辑，能够更好地与医生配合。

    

    骨龄评估是临床实践中具有挑战性的任务，由于骨龄评估过程繁琐复杂。目前的自动骨龄评估方法很少考虑诊断逻辑，因此可能产生某些无法解释的隐藏状态和输出。因此，医生们可能很难与这些模型和谐合作，因为很难检查模型预测的正确性。本文提出了一种新的基于手部放射线检查图像的骨龄评估图像分析框架，称为Doctor Imitator（DI）模型。DI模型的设计是为了学习医生使用评分方法（例如Tanner-Whitehouse方法）进行骨龄评估的诊断逻辑。具体而言，DI模型的卷积层捕捉手部放射线检查图像感兴趣区域（ROIs）的局部特征，并通过我们提出的基于解剖学的组卷积进行ROI区域的得分预测，最后进行求和得到骨龄预测结果。

    Bone age assessment is challenging in clinical practice due to the complicated bone age assessment process. Current automatic bone age assessment methods were designed with rare consideration of the diagnostic logistics and thus may yield certain uninterpretable hidden states and outputs. Consequently, doctors can find it hard to cooperate with such models harmoniously because it is difficult to check the correctness of the model predictions. In this work, we propose a new graph-based deep learning framework for bone age assessment with hand radiographs, called Doctor Imitator (DI). The architecture of DI is designed to learn the diagnostic logistics of doctors using the scoring methods (e.g., the Tanner-Whitehouse method) for bone age assessment. Specifically, the convolutions of DI capture the local features of the anatomical regions of interest (ROIs) on hand radiographs and predict the ROI scores by our proposed Anatomy-based Group Convolution, summing up for bone age prediction. B
    
[^116]: FOLE ERA：基础探讨

    The ERA of FOLE: Foundation. (arXiv:1512.07430v2 [cs.DB] UPDATED)

    [http://arxiv.org/abs/1512.07430](http://arxiv.org/abs/1512.07430)

    本文讨论本体在FOLE一阶逻辑环境中的表示，特别是提供了ERA数据模型的严格数学表示，作为本体论的基础探讨。

    

    本文讨论本体在FOLE（Kent 2013）一阶逻辑环境中的表示。本体定义了用于为话语社区建模知识资源的原语（Gruber 2009）。这些原语包括类、关系和属性，由实体-关系-属性（ERA）数据模型（Chen 1976）表示。本文是三篇论文中的第一篇，它在FOLE的第一阶逻辑环境中提供了ERA数据模型的严格数学表示，特别是本体论的基础探讨。

    This paper discusses the representation of ontologies in the first-order logical environment FOLE (Kent 2013). An ontology defines the primitives with which to model the knowledge resources for a community of discourse (Gruber 2009). These primitives, consisting of classes, relationships and properties, are represented by the entity-relationship-attribute ERA data model (Chen 1976). An ontology uses formal axioms to constrain the interpretation of these primitives. In short, an ontology specifies a logical theory. This paper is the first in a series of three papers that provide a rigorous mathematical representation for the ERA data model in particular, and ontologies in general, within the first-order logical environment FOLE. The first two papers show how FOLE represents the formalism and semantics of (many-sorted) first-order logic in a classification form corresponding to ideas discussed in the Information Flow Framework (IFF). In particular, this first paper provides a foundation 
    

