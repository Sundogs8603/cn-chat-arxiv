# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [DiT-3D: Exploring Plain Diffusion Transformers for 3D Shape Generation.](http://arxiv.org/abs/2307.01831) | DiT-3D是一种针对3D形状生成的新型扩散Transformer，通过在纯Transformer上进行去噪处理，结合3D位置和补丁嵌入来聚合体素化点云的输入，并引入了3D窗口注意力以降低计算成本。 |
| [^2] | [Human Trajectory Forecasting with Explainable Behavioral Uncertainty.](http://arxiv.org/abs/2307.01817) | 本研究提出了一种新的人类轨迹预测模型BNSP-SFM，将行为SDE模型与贝叶斯神经网络相结合，能够提供较好的预测能力和强大的可解释性。与11种最先进的方法相比，BNSP-SFM在预测精度上取得了多达50％的改进。这种模型在不同环境和人群密度的场景中也能够更好地推广。 |
| [^3] | [DeepFlorist: Rethinking Deep Neural Networks and Ensemble Learning as A Meta-Classifier For Object Classification.](http://arxiv.org/abs/2307.01806) | DeepFlorist提出了一种新型学习范式，通过集成学习作为元分类器实现花卉分类。通过密集卷积神经网络和卷积神经网络提取高级特征，并采用多个模型进行集成，DeepFlorist在准确性和鲁棒性方面表现优于其他方法。 |
| [^4] | [The Inner Sentiments of a Thought.](http://arxiv.org/abs/2307.01784) | 这篇论文探索了基于Transformer的大型语言模型中句子内部情感表示的方法，训练了预测器来分析句子的情感分布，并展示了即使是普通的连接词也可以显著改变话语的情感轨迹。 |
| [^5] | [GHOST: A Graph Neural Network Accelerator using Silicon Photonics.](http://arxiv.org/abs/2307.01782) | GHOST是第一个使用硅光子学的图神经网络加速器，高效地处理和加速GNN，克服了传统加速器的缺点，使得它可以应用于各种GNN模型和架构的推理。 |
| [^6] | [Physically Realizable Natural-Looking Clothing Textures Evade Person Detectors via 3D Modeling.](http://arxiv.org/abs/2307.01778) | 通过3D建模，制作出与日常服装纹理相似的对抗性伪装纹理，可以在多个视角下避开人物检测，实现自然外观的服装纹理。 |
| [^7] | [MOPO-LSI: A User Guide.](http://arxiv.org/abs/2307.01719) | MOPO-LSI是一款开源的多目标投资组合优化库，为可持续投资提供用户指南，并介绍了版本1.0的问题设置、工作流程和超参数。 |
| [^8] | [On the Constrained Time-Series Generation Problem.](http://arxiv.org/abs/2307.01717) | 这篇论文研究了约束时间序列生成问题。在实际应用中，合成时间序列被广泛用于增强历史时间序列数据集，提高机器学习算法的性能，放大稀有事件的发生，以及创建反事实情景。然而，现有的方法在满足约束方面存在问题，需要重新训练且计算代价高，或者在复杂约束条件下不切实际。 |
| [^9] | [Distributional Model Equivalence for Risk-Sensitive Reinforcement Learning.](http://arxiv.org/abs/2307.01708) | 本文研究了风险敏感强化学习中的分布模型等效性问题。我们提出了两种新的模型等价性概念，并展示了如何将这些概念应用于增强任何基于模型的风险敏感算法。 |
| [^10] | [Synthetic is all you need: removing the auxiliary data assumption for membership inference attacks against synthetic data.](http://arxiv.org/abs/2307.01701) | 这项研究提出了一种新方法，移除了成员推断攻击对辅助数据的假设，使用只有合成数据的情况下仍然能够成功进行成员推断攻击。 |
| [^11] | [Online Learning and Solving Infinite Games with an ERM Oracle.](http://arxiv.org/abs/2307.01689) | 这项工作提出了一种仅依赖ERM预言机调用的在线学习算法，该算法在可实现情况下具有有限的遗憾，并在不可知情况下具有亚线性增长的遗憾。同时，还提供了类似的结果用于非参数博弈环境中的学习算法，即仅依赖最佳响应预言机的学习算法，并收敛到近似极小-极大均衡点。 |
| [^12] | [Serving Graph Neural Networks With Distributed Fog Servers For Smart IoT Services.](http://arxiv.org/abs/2307.01684) | 本文提出了一种分布式实时GNN推断框架Fograph，该框架利用了靠近物联网数据源的多个雾节点的资源，通过引入异构感知执行规划和GNN特定的压缩技术，以最大限度地发挥雾计算的架构优势。 |
| [^13] | [Learning Discrete Weights and Activations Using the Local Reparameterization Trick.](http://arxiv.org/abs/2307.01683) | 本论文研究了使用局部重新参数化技巧学习离散权重和激活的方法，通过二值化网络来降低计算复杂度，提高神经网络推理效率。 |
| [^14] | [RaidEnv: Exploring New Challenges in Automated Content Balancing for Boss Raid Games.](http://arxiv.org/abs/2307.01676) | RaidEnv是一个新的游戏模拟器，用于MMORPG游戏中boss raid情景的自动内容平衡研究，并提供两个基准来辅助游戏人工智能的实际应用。 |
| [^15] | [SwinGNN: Rethinking Permutation Invariance in Diffusion Models for Graph Generation.](http://arxiv.org/abs/2307.01646) | 本文提出了一种新的图生成扩散模型SwinGNN，通过使用高效的2-WL消息传递网络和移动窗口自注意力，以及结合关键的训练和采样技术，显著提高了图生成样本的质量，并引入了随机置换的后处理技巧转换生成的图形统计量。 |
| [^16] | [Insert-expansions for Tool-enabled Conversational Agents.](http://arxiv.org/abs/2307.01644) | 本文研究了特定工具支持下的对话式智能助手的插入扩展。通过将用户作为工具，在生成明确推理路径时提供更多细节和更精确的请求，从而解决了工具干扰用户意图的问题。通过两个实证研究，发现在推荐领域中使用这种方法带来了好处。 |
| [^17] | [Heuristic Algorithms for the Approximation of Mutual Coherence.](http://arxiv.org/abs/2307.01639) | 本研究提出了近似互连性的启发式算法，用于加速计算互连性指标。算法通过建模确认值的分布并估计其模型参数，然后利用分布的期望值来近似计算互连性。 |
| [^18] | [Random Walk on Multiple Networks.](http://arxiv.org/abs/2307.01637) | 本论文提出了一种在多个网络上进行随机游走的方法，通过充分利用多个网络中的信息来进行更好的实体推断和分析。该方法支持多重网络和一般多网络，并且在理论上具有收敛性质。 |
| [^19] | [SageFormer: Series-Aware Graph-Enhanced Transformers for Multivariate Time Series Forecasting.](http://arxiv.org/abs/2307.01616) | 本文介绍了SageFormer，一种面向多变量时间序列预测的系列感知图增强Transformer模型，通过图结构有效捕捉和建模序列之间的依赖关系，在表示不同序列中的时间模式和减少序列间冗余信息等方面取得了优越性能。 |
| [^20] | [Overconfidence is a Dangerous Thing: Mitigating Membership Inference Attacks by Enforcing Less Confident Prediction.](http://arxiv.org/abs/2307.01610) | 本文提出了一种防御技术HAMP，可以在不需要额外数据的情况下，通过强制模型进行不太自信的预测，达到强大的成员隐私保护和高准确性的目标。 |
| [^21] | [Bridge the Performance Gap in Peak-hour Series Forecasting: The Seq2Peak Framework.](http://arxiv.org/abs/2307.01597) | 本文提出了Seq2Peak框架，针对高峰小时序列预测任务，该框架通过解决高度非平稳性和性能评估问题，成功缩小了在常规时间序列预测模型中观察到的性能差距。 |
| [^22] | [Prompt Tuning Pushes Farther, Contrastive Learning Pulls Closer: A Two-Stage Approach to Mitigate Social Biases.](http://arxiv.org/abs/2307.01595) | 这个论文提出了一种使用连续提示增强的对比学习的两阶段去偏模型，以减轻预训练语言模型中的社会偏见。在第一阶段，通过提示调整推进不同人口群体之间的表示距离。 |
| [^23] | [Cross-Element Combinatorial Selection for Multi-Element Creative in Display Advertising.](http://arxiv.org/abs/2307.01593) | 这篇论文提出了一个跨元素组合选择框架CECS，用于解决显示广告中多元素创意选择的问题，通过采用跨元素交互的方式进行编码，将创意组合问题转化为多个创意元素级联选择问题。 |
| [^24] | [IAdet: Simplest human-in-the-loop object detection.](http://arxiv.org/abs/2307.01582) | 本文提出了一种最简单的人机交互目标检测方法，其中的关键创新是智能注释（IA）策略和开源的IAdet工具。对于PASCAL VOC数据集，IAdet工具能够减少数据库标注时间，并提供免费训练好的模型，为强大的人机交互目标检测系统提供了改进的可能。 |
| [^25] | [Optimal and Efficient Binary Questioning for Human-in-the-Loop Annotation.](http://arxiv.org/abs/2307.01578) | 本文研究了人机协作注释中的二元问题，提出了从最优通用解决方案到实际高效方法的一系列解决方案。我们将问题构建为在给定预测器的情况下用最少的是/否问题来完全注释一个二元分类数据集。通过编码理论和启发式算法，我们提供了一个计算可行且高效的替代方案。 |
| [^26] | [Conceptual Cognitive Maps Formation with Neural Successor Networks and Word Embeddings.](http://arxiv.org/abs/2307.01577) | 本研究通过使用神经后继网络和词嵌入向量构建了一个概念认知地图，该地图能够根据不同的尺度学习并将新信息与相关的既有表示相连接。 |
| [^27] | [Machine Learning-Based Intrusion Detection: Feature Selection versus Feature Extraction.](http://arxiv.org/abs/2307.01570) | 本文对于入侵检测中的特征选择与特征提取两种方法在不同性能指标下进行了全面比较，并提供了基于机器学习的物联网入侵检测的综述。 |
| [^28] | [Scalable variable selection for two-view learning tasks with projection operators.](http://arxiv.org/abs/2307.01558) | 本文提出了一种可扩展的变量选择方法，适用于两视图学习任务或向量值监督学习问题，能够处理规模极大的选择任务，并利用投影算子以及核函数进行相关性衡量和非线性相关模型的处理。 |
| [^29] | [Separated RoadTopoFormer.](http://arxiv.org/abs/2307.01557) | 这篇论文提出了一种分离的RoadTopoFormer框架，用于检测车道中心线和交通元素，并推理它们之间的关系。 |
| [^30] | [Knowledge Graph for NLG in the context of conversational agents.](http://arxiv.org/abs/2307.01548) | 本文回顾了对话代理中使用的不同的知识图谱到文本生成架构，并讨论了每种架构的优点和局限性。根据具体任务的要求选择合适的架构，并强调了考虑执行时间和模型有效性的重要性，特别是在对话代理背景下。 |
| [^31] | [Learning to Prompt in the Classroom to Understand AI Limits: A pilot study.](http://arxiv.org/abs/2307.01540) | 在本研究中，通过学习提示，试图在课堂环境中理解人工智能的限制。人工智能的进展带来了巨大的潜力，但也引发了负面情绪。当前大型语言模型的能力限制被忽视，导致了错误的自信和不准确的建议。承认人工智能的不可靠性是解决这个问题的关键。 |
| [^32] | [Analyzing Intentional Behavior in Autonomous Agents under Uncertainty.](http://arxiv.org/abs/2307.01532) | 本论文提出了一种在不确定环境下分析自主代理有意行为的方法，通过定量度量证据来区分有意结果、疏忽设计和实际意外。方法使用马尔可夫决策过程建模不确定环境，并通过概率模型检查计算代理的影响能力。采用反事实推理自动生成相关情景增加评估信心。在一个案例研究中成功区分“有意”和“意外”的交通碰撞。 |
| [^33] | [Convolutional Transformer for Autonomous Recognition and Grading of Tomatoes Under Various Lighting, Occlusion, and Ripeness Conditions.](http://arxiv.org/abs/2307.01530) | 本研究引入了一种卷积变换器架构的框架，能够在不同光照、遮挡和成熟度条件下自主识别和分级西红柿。 |
| [^34] | [LEAT: Towards Robust Deepfake Disruption in Real-World Scenarios via Latent Ensemble Attack.](http://arxiv.org/abs/2307.01520) | 这项研究通过一种名为LEAT的方法，在真实场景中实现了对深度伪造的可靠干扰。LEAT通过攻击独立的潜在编码过程来干扰深度伪造，提高了鲁棒性。 |
| [^35] | [Deep Attention Q-Network for Personalized Treatment Recommendation.](http://arxiv.org/abs/2307.01519) | 本研究提出了Deep Attention Q-Network，利用Transformer架构在深度强化学习框架内，个性化推荐治疗方案，通过高效整合过去的病患观察信息，解决了仅依赖当前观察信息的限制，从而提高了治疗效果。 |
| [^36] | [All in One: Multi-task Prompting for Graph Neural Networks.](http://arxiv.org/abs/2307.01504) | 本文提出了一种新颖的图模型的多任务提示方法，通过统一图提示和语言提示的格式，填补了预训练模型与各种图任务之间的差距。 |
| [^37] | [HEDI: First-Time Clinical Application and Results of a Biomechanical Evaluation and Visualisation Tool for Incisional Hernia Repair.](http://arxiv.org/abs/2307.01502) | HEDI是一种用于切口疝修复的生物力学评估和可视化工具，通过考虑腹壁的不稳定性，能够自动检测和评估疝的大小、体积和腹壁不稳定性。在31名患者的预手术评估中，HEDI显示出明显改善的成功率，所有患者在随访三年后仍然没有疼痛和疝再发。 |
| [^38] | [Mitigating Bias: Enhancing Image Classification by Improving Model Explanations.](http://arxiv.org/abs/2307.01473) | 本文提出了一种通过改进模型解释的方法来缓解图像分类中的偏见问题，通过引导模型的注意力向前景集中，从而提升对主要概念的学习效果。 |
| [^39] | [Beyond Conservatism: Diffusion Policies in Offline Multi-agent Reinforcement Learning.](http://arxiv.org/abs/2307.01472) | DOM2是一种离线多智能体强化学习模型，通过扩散策略的改进，提高了算法在性能、泛化能力和数据效率方面的表现。DOM2在多智能体粒子和多智能体MuJoCo环境中优于现有算法，并在移位环境中具有更好的泛化能力。此外，DOM2还展现了卓越的数据效率，只使用较少的数据即可达到最先进的性能水平。 |
| [^40] | [Causal Reinforcement Learning: A Survey.](http://arxiv.org/abs/2307.01452) | 这项综述总结了因果强化学习的研究文献，强调因果关系的重要作用，它能够形式化知识并实现有效的知识传递。 |
| [^41] | [A Double Machine Learning Approach to Combining Experimental and Observational Data.](http://arxiv.org/abs/2307.01449) | 这种双机器学习方法将实验和观测研究结合起来，能够测试假设的违反情况并一致估计处理效应。它提供了半参数高效的处理效应估计器。这种方法在实际环境中是可行的。 |
| [^42] | [Unsupervised Feature Learning with Emergent Data-Driven Prototypicality.](http://arxiv.org/abs/2307.01421) | 本文提出了在无监督的情况下，利用双曲空间进行特征学习的方法，其中图像之间的距离仍然表示其相似度，而位置则表示其典型性。 |
| [^43] | [Learning to Communicate using Contrastive Learning.](http://arxiv.org/abs/2307.01403) | 本研究提出了一种使用对比学习进行通信的方法，在分散的环境中通过最大化反映发送和接收消息关系的互信息来学习通信。在通信关键的环境中，我们的方法在性能和学习速度方面优于先前的工作，并且能够捕获全局状态信息，实现了更对称的通信。 |
| [^44] | [In-depth Analysis On Parallel Processing Patterns for High-Performance Dataframes.](http://arxiv.org/abs/2307.01394) | 本论文通过从高性能计算的角度出发，对面向高性能数据框的并行处理模式进行了深入分析，并指出当前最广泛使用的串行数据框在处理中等规模的数据集时存在性能限制，提出改进的空间。 |
| [^45] | [Depth video data-enabled predictions of longitudinal dairy cow body weight using thresholding and Mask R-CNN algorithms.](http://arxiv.org/abs/2307.01383) | 该研究利用深度视频数据预测了奶牛的长期体重，并比较了阈值和Mask R-CNN深度学习方法的性能，证实了基于视频的体重预测的有效性，并促进了动物科学界的开放科学。 |
| [^46] | [Shifting Attention to Relevance: Towards the Uncertainty Estimation of Large Language Models.](http://arxiv.org/abs/2307.01379) | 本论文研究了大型语言模型（LLMs）自动生成的关键词不平等问题，发现在估计不确定性时，重要的令牌和含有有限语义的句子被同等或更加重视。为了解决这个问题，提出了共同转移关注点来更好地估计不确定性。 |
| [^47] | [A CNN regression model to estimate buildings height maps using Sentinel-1 SAR and Sentinel-2 MSI time series.](http://arxiv.org/abs/2307.01378) | 本研究提出了一种使用Sentinel-1 SAR和Sentinel-2 MSI时间序列的CNN回归模型，能够准确估计建筑物的高度，并在荷兰的10个城市进行了测试。 |
| [^48] | [Efficient Determination of Safety Requirements for Perception Systems.](http://arxiv.org/abs/2307.01371) | 本研究提出了一种高效确定感知系统安全要求的方法，并且在视觉飞行器避碰问题上的实验结果表明了该方法在精度和效率方面的改进。 |
| [^49] | [Minimizing Age of Information for Mobile Edge Computing Systems: A Nested Index Approach.](http://arxiv.org/abs/2307.01366) | 该论文提出了一种嵌套索引框架及策略，用于最小化移动边缘计算系统中多用户的信息时延，并利用信息时延(AoI)指标评估信息新鲜度。 |
| [^50] | [Towards Safe Autonomous Driving Policies using a Neuro-Symbolic Deep Reinforcement Learning Approach.](http://arxiv.org/abs/2307.01316) | 本文介绍了一种名为DRL with Symbolic Logics (DRLSL)的新颖神经符号无模型深度强化学习方法，旨在实现在真实环境中安全学习自主驾驶策略。该方法结合了深度强化学习和符号逻辑驱动的推理，允许通过与物理环境的实时交互来学习自主驾驶策略并确保安全性。 |
| [^51] | [Self-Tuning PID Control via a Hybrid Actor-Critic-Based Neural Structure for Quadcopter Control.](http://arxiv.org/abs/2307.01312) | 本研究提出了一种基于混合Actor-Critic神经结构的自整定PID控制器，用于四旋翼飞行器的姿态和高度控制，通过强化学习的方法调整PID增益，提高了系统的稳健性和可靠性。 |
| [^52] | [Reliable AI: Does the Next Generation Require Quantum Computing?.](http://arxiv.org/abs/2307.01301) | 这项调查研究了下一代人工智能是否需要量子计算，发现数字硬件无法完全解决可靠性问题。 |
| [^53] | [Pareto-Secure Machine Learning (PSML): Fingerprinting and Securing Inference Serving Systems.](http://arxiv.org/abs/2307.01292) | 本论文研究了模型服务系统的安全性，通过引入一个查询高效的指纹算法，使得攻击者能够一致地触发任何想要的模型，从而增强了对模型提取攻击的鲁棒性和准确性。 |
| [^54] | [Fighting the disagreement in Explainable Machine Learning with consensus.](http://arxiv.org/abs/2307.01288) | 这项研究评估了六种共识函数用于解释五个机器学习模型，并发现了在解释模型方面存在着分歧问题，对于解决这个问题尚需进一步研究。 |
| [^55] | [MWPRanker: An Expression Similarity Based Math Word Problem Retriever.](http://arxiv.org/abs/2307.01240) | 提出了一种基于表达相似性的数学问题检索工具MWPRanker，该工具能够检索具有相同问题模型的数学问题，包括算术和逻辑序列。 |
| [^56] | [Learning Difference Equations with Structured Grammatical Evolution for Postprandial Glycaemia Prediction.](http://arxiv.org/abs/2307.01238) | 本研究提出了一种用于餐后血糖预测的新方法，通过结构化语法演化学习差分方程，并结合聚类分析提供可解释性强的预测模型。 |
| [^57] | [Internet of Things Fault Detection and Classification via Multitask Learning.](http://arxiv.org/abs/2307.01234) | 本文通过多任务学习实现了物联网故障检测和分类系统，并在真实数据上展示了优越的性能，相较于现有技术，在特异性、精确度、召回率和F1值等方面均有显著改进。 |
| [^58] | [A Critical Re-evaluation of Benchmark Datasets for (Deep) Learning-Based Matching Algorithms.](http://arxiv.org/abs/2307.01231) | 本研究重新评估了(深度)学习匹配算法的基准数据集，发现其中大多数数据集都属于相对简单的分类任务。 |
| [^59] | [EmoGen: Eliminating Subjective Bias in Emotional Music Generation.](http://arxiv.org/abs/2307.01229) | EmoGen是一种消除情感音乐生成中主观偏差的系统，通过利用与情感相关的音乐属性作为桥梁，将生成分为情感到属性的映射以及属性到音乐的生成两个阶段，并在学习过程中消除主观偏差，实现生成具有普遍情感的音乐。 |
| [^60] | [ESGCN: Edge Squeeze Attention Graph Convolutional Network for Traffic Flow Forecasting.](http://arxiv.org/abs/2307.01227) | ESGCN是一种用于交通流量预测的边缘压缩注意图卷积网络，通过建模时空动态和引入边缘特征和边缘注意机制来提高预测的准确性。 |
| [^61] | [vONTSS: vMF based semi-supervised neural topic modeling with optimal transport.](http://arxiv.org/abs/2307.01226) | vONTSS是一种基于vMF和最优传输的半监督神经主题建模方法，它在分类准确率和多样性方面优于其他方法，并且支持无监督主题建模。实验证明，vONTSS比最近的NTM更快。 |
| [^62] | [Interpretability and Transparency-Driven Detection and Transformation of Textual Adversarial Examples (IT-DT).](http://arxiv.org/abs/2307.01225) | 通过提出的解释性和透明性驱动的检测与转换（IT-DT）框架，我们在检测和转换文本对抗示例方面注重解释性和透明性。这个框架利用了注意力图、集成梯度和模型反馈等技术，在检测阶段有助于识别对对抗性分类有贡献的显著特征和扰动词语，并在转换阶段使用预训练的嵌入和模型反馈来生成扰动词语的最佳替代，以将对抗性示例转换为正常示例。 |
| [^63] | [Filter Bubbles in Recommender Systems: Fact or Fallacy -- A Systematic Review.](http://arxiv.org/abs/2307.01221) | 研究发现了推荐系统中筛选泡沫的存在，揭示了导致筛选泡沫的多种偏见，并提出了一个集成工具，帮助用户避免在推荐系统中受到筛选泡沫的影响。 |
| [^64] | [FedCP: Separating Feature Information for Personalized Federated Learning via Conditional Policy.](http://arxiv.org/abs/2307.01217) | 提出了一种名为FedCP的个性化联邦学习方法，通过生成条件策略分离特征中的全局信息和个性化信息，并分别进行处理。实验证明该方法在计算机视觉和自然语言处理领域的性能超过了十一种最先进的方法，最高可提高6.69%。 |
| [^65] | [Automatic Counterfactual Augmentation for Robust Text Classification Based on Word-Group Search.](http://arxiv.org/abs/2307.01214) | 这篇论文提出了一种基于单词组搜索的自动反事实扩充方法，用于鲁棒文本分类。该方法通过捕捉关键字组合的因果效应，并排序最影响预测的组合，从而解决了由于只关注单个单词而导致的错误因果特征的问题。 |
| [^66] | [An automated method for the ontological representation of security directives.](http://arxiv.org/abs/2307.01211) | 本文提出了一种将大型法律文件自动转化为本体表示的方法，通过自然语言处理技术和本体发展原则的结合，展示了在欧洲网络和信息系统安全指令上的应用。 |
| [^67] | [AI and Non AI Assessments for Dementia.](http://arxiv.org/abs/2307.01210) | 本论文总结了人工智能和非人工智能评估老年痴呆的现有解决方案，并为医生和AI工程师提供了相关的技术和数据集。 |
| [^68] | [Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach.](http://arxiv.org/abs/2307.01204) | 本文提出了一种基于关系匿名漫步引导的神经过程方法，用于知识图谱上的少样本归纳链接预测。该方法利用未见实体周围的子图来获取语义并归纳地预测链接，在捕捉一般的归纳模式的同时，还能快速适应新的实体并估计预测的不确定性。 |
| [^69] | [Predictive Patentomics: Forecasting Innovation Success and Valuation with ChatGPT.](http://arxiv.org/abs/2307.01202) | 本研究采用ChatGPT技术，以OpenAI的最先进的文本嵌入为基础，通过深度学习预测模型实现了对专利创新成功和估值的准确预测，为专利估值提供了革命性的改进。此外，通过预测接受率构建的多空投资组合实现了显著的异常收益率。 |
| [^70] | [Schema-learning and rebinding as mechanisms of in-context learning and emergence.](http://arxiv.org/abs/2307.01201) | 本文研究了上下文学习的机制，发现使用克隆结构因果图可以实现与transformer-based语言模型相似的能力，并且这种方法可以解释上下文学习的工作原理。 |
| [^71] | [SDC-HSDD-NDSA: Structure Detecting Cluster by Hierarchical Secondary Directed Differential with Normalized Density and Self-Adaption.](http://arxiv.org/abs/2307.00677) | 本文提出了一种基于密度的聚类算法，能够检测到高密度区域中的结构，具有先前算法所不具备的能力。 |
| [^72] | [Sparsity-aware generalization theory for deep neural networks.](http://arxiv.org/abs/2307.00426) | 本文研究了深度神经网络的泛化能力，提出了一种基于稀疏感知的分析方法。通过考虑隐藏层激活的稀疏程度，我们展示了稀疏和泛化之间的权衡，而且结果对模型的稀疏程度没有强烈的假设，并在特定情况下的数值实验中得到了非空的界限。 |
| [^73] | [Counterfactual Collaborative Reasoning.](http://arxiv.org/abs/2307.00165) | 本文提出了反事实协同推理（CCR）方法，通过整合反事实推理和逻辑推理来提高机器学习模型的准确性和可解释性。通过利用反事实推理生成困难的反事实训练样本进行数据增强，CCR在推荐系统中展示了如何缓解数据稀缺、提高准确性和增强透明度。 |
| [^74] | [Goal quest for an intelligent surfer moving in a chaotic flow.](http://arxiv.org/abs/2307.00019) | 这篇论文提出了一个智能冲浪者的模型，通过使用Ulman网络在混沌动力学中进行搜索。使用一种新的算法，智能冲浪者能够在网络中找到最短路径，并且比尝试尽量减小与目标距离的愚蠢冲浪者更加高效。这为在混沌流动中的运动控制提供了新的方法。 |
| [^75] | [Discriminatory or Samaritan -- which AI is needed for humanity? An Evolutionary Game Theory Analysis of Hybrid Human-AI populations.](http://arxiv.org/abs/2306.17747) | 这项研究通过进化博弈理论的分析发现，相比于只帮助符合条件的人的歧视性人工智能，撒马利亚式人工智能可以更好地促进人类间的合作。这对于缓慢发展的社会尤为重要，因为在这种社会中，变化被视为谨慎和抵抗。 |
| [^76] | [Towards Personalized Cold-Start Recommendation with Prompts.](http://arxiv.org/abs/2306.17256) | 本研究旨在解决个性化冷启动推荐问题，通过利用预训练语言模型的能力，将推荐过程转化为自然语言情感分析，提供适用于创业企业和用户参与历史不足的平台的个性化推荐。 |
| [^77] | [The mapKurator System: A Complete Pipeline for Extracting and Linking Text from Historical Maps.](http://arxiv.org/abs/2306.17059) | 该论文介绍了一种名为mapKurator的系统，能完整地从历史地图中提取和链接文本信息。该系统解决了传统方法中对位置相关词语的忽略问题，并利用主题建模方法考虑更广的主题范围，能够识别文档的空间焦点。 |
| [^78] | [milliFlow: Scene Flow Estimation on mmWave Radar Point Cloud for Human Motion Sensing.](http://arxiv.org/abs/2306.17010) | milliFlow是一种用于人体运动感知的新型深度学习方法，通过对毫米波雷达点云进行场景流估计，能够提供中间层的特征并直接用于下游的人体运动感知任务中。实验证明该方法具有优越性能。 |
| [^79] | [SRL: Scaling Distributed Reinforcement Learning to Over Ten Thousand Cores.](http://arxiv.org/abs/2306.16688) | SRL是一个可扩展，高效，可扩展的分布式强化学习系统，通过一种新的抽象框架统一了各种实际强化学习训练，并实现了精细优化。 |
| [^80] | [Phase Unwrapping of Color Doppler Echocardiography using Deep Learning.](http://arxiv.org/abs/2306.13695) | 本文提出了一种基于展开型原始-对偶网络的新方法，用于纠正彩色多普勒心脏超声图像中的相位包裹伪影，与其他最新分割技术相比，该方法在性能上表现突出。 |
| [^81] | [Recent Developments in Recommender Systems: A Survey.](http://arxiv.org/abs/2306.12680) | 本篇综述全面总结了推荐系统领域的最新进展和趋势，包括推荐系统分类，知识推荐系统，鲁棒性，数据偏见和公平性问题，以及评估度量。该研究还提供了未来研究的新方向。 |
| [^82] | [Learning Models of Adversarial Agent Behavior under Partial Observability.](http://arxiv.org/abs/2306.11168) | 本论文提出了一种名为GrAMMI的方法，用于在部分可观测性下建模对抗对手代理的行为。通过最大化互信息作为辅助目标来预测对抗对手的当前和未来状态，GrAMMI在两个大规模追逐-逃避领域中表现出了显著优越性能。 |
| [^83] | [Recurrent Memory Decision Transformer.](http://arxiv.org/abs/2306.09459) | 本文提出了循环记忆决策变压器（RMDT）模型，用于处理强化学习中的长序列问题。在Atari游戏和MoJoCo控制问题上的实验表明，采用循环记忆机制的RMDT模型显着优于其没有循环记忆机制的对应模型。 |
| [^84] | [Neural Mixed Effects for Nonlinear Personalized Predictions.](http://arxiv.org/abs/2306.08149) | 本文提出了神经混合效应（NME）模型，用于个性化预测，并通过结合个人通用和个人特定参数来考虑线性和非线性趋势。 |
| [^85] | [$E(2)$-Equivariant Vision Transformer.](http://arxiv.org/abs/2306.06722) | 本文设计了一个群等变视觉Transformer，通过一种新颖有效的位置编码操作解决了视觉Transformer中的等变性学习难题，并通过实验证明了其明显优于非等变的自注意力网络。 |
| [^86] | [Don't trust your eyes: on the (un)reliability of feature visualizations.](http://arxiv.org/abs/2306.04719) | 本文探讨了神经网络如何从像素中提取模式的问题，并研究了特征可视化的可靠性。实验证据表明，由于优化过程中固有的限制，特征可视化能够可靠理解的功能集非常有限，对于解释神经网络如何处理自然图像的解释能力产生怀疑。 |
| [^87] | [$\textit{WHAT}$, $\textit{WHEN}$, and $\textit{HOW}$ to Ground: Designing User Persona-Aware Conversational Agents for Engaging Dialogue.](http://arxiv.org/abs/2306.03361) | 本文提出了一种针对商业环境的、能够平衡对话流畅性和趋向于理解对话系统的个性化开放领域对话系统方法，通过加权数据集混合、负角色信息增强方法，以及设计个性化对话数据集，解决了 $\textit{WHAT}$、$\textit{WHEN}$和$\textit{HOW}$ 等问题，同时提高了对话系统响应的可控性和解释性。 |
| [^88] | [Annotation-free Audio-Visual Segmentation.](http://arxiv.org/abs/2305.11019) | 本文提出了一种可伸缩且无需注释的管道，用于生成音视频分割任务的人工数据，并引入了一个音频感知的基于查询的Transformer解码器，使模型能够在音频信号的指导下搜索声音对象，得到更准确的分割。 |
| [^89] | [Scale-Adaptive Balancing of Exploration and Exploitation in Classical Planning.](http://arxiv.org/abs/2305.09840) | 本文提出了一种MCTS/THTS算法GreedyUCT-Normal，该算法能够通过采用奖励变化的尺度处理不同尺度的分布，以在经典计划中平衡探索和开发。 |
| [^90] | [Language, Time Preferences, and Consumer Behavior: Evidence from Large Language Models.](http://arxiv.org/abs/2305.02531) | 本研究分析了大型语言模型在不同语言提示下的奖励时间偏好，并发现GPT在具有较弱未来时态的语言下表现出更大的耐心，这与使用该语言的人类的偏好相似。 |
| [^91] | [Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes.](http://arxiv.org/abs/2305.02301) | 本研究提出了Distilling Step-by-Step机制，通过提取LLM基础信息为小型模型提供额外的监督训练，从而使它们胜过更大的LLM模型，并需更少的训练数据。 |
| [^92] | [An Introduction to Transformers.](http://arxiv.org/abs/2304.10557) | Transformer是一种神经网络组件，可以学习序列或数据集表示，在自然语言处理、计算机视觉和时空建模方面取得了重大进展。本论文提供了一个数学精确、直观、简洁的Transformer架构描述。 |
| [^93] | [Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Methods.](http://arxiv.org/abs/2303.13988) | 本文提出了一种新领域——机器心理学，利用心理学的方法考察大型语言模型的能力。该文规范了机器心理学研究的方法论标准，并对心理实验中提示设计政策进行了探讨和制定。 |
| [^94] | [Graph Neural Network contextual embedding for Deep Learning on Tabular Data.](http://arxiv.org/abs/2303.06455) | 本文介绍了一种基于图神经网络的深度学习模型，使用交互网络进行上下文嵌入，用于表格数据的处理。该模型在公共数据集上的表现优于最近的深度学习基准调查，并且与提升树解决方案相比也取得了竞争性的结果。 |
| [^95] | [Causal Dependence Plots.](http://arxiv.org/abs/2303.04209) | 本论文提出了因果依赖图（CDPs）来解释人工智能或机器学习模型的因果依赖关系。CDPs与传统方法不同，可以模块化地结合因果学习或敏感度分析方法。这些图表可以成为可解释机器学习工具包中的强大工具，并对相关应用做出贡献。 |
| [^96] | [Can we avoid Double Descent in Deep Neural Networks?.](http://arxiv.org/abs/2302.13259) | 这项研究表明，通过适当调整学习问题的条件，可以避免双下降现象，特别是在复杂情况下使用适当的正则化。这对于寻找深度学习模型的最优大小具有重要意义。 |
| [^97] | [Video-SwinUNet: Spatio-temporal Deep Learning Framework for VFSS Instance Segmentation.](http://arxiv.org/abs/2302.11325) | 本文提出了一个用于医学视频分割的深度学习框架，通过显式地利用时间维度并结合Swin Transformer的全局特征编码能力，改进了医学图像分割任务的性能。 |
| [^98] | [Pseudo Contrastive Learning for Graph-based Semi-supervised Learning.](http://arxiv.org/abs/2302.09532) | 本论文提出了一种基于伪对比学习的半监督图神经网络方法，通过生成可靠的负样本对来改进伪标签的质量。 |
| [^99] | [The Expressive Power of Tuning Only the Normalization Layers.](http://arxiv.org/abs/2302.07937) | 本研究发现，仅调整神经网络的归一化层参数就可以达到高准确性，甚至可以重建比原网络小O(根号宽度)倍的目标网络。 |
| [^100] | [Deep Anomaly Detection under Labeling Budget Constraints.](http://arxiv.org/abs/2302.07832) | 本文针对标签预算约束下的深度异常检测问题提出了一种数据标记策略和半监督学习框架，在多种数据集上取得了最先进的性能。 |
| [^101] | [Beyond In-Domain Scenarios: Robust Density-Aware Calibration.](http://arxiv.org/abs/2302.05118) | 这个论文提出了一种鲁棒的密度感知校准方法，通过利用隐藏层的信息，该方法能够提供在领域转移和领域外情景下可靠的不确定性估计，并在保持出色领域内预测不确定性估计的同时提高校准性能。 |
| [^102] | [RPN: A Word Vector Level Data Augmentation Algorithm in Deep Learning for Language Understanding.](http://arxiv.org/abs/2212.05961) | RPN是一种基于词向量级别的数据增强算法，通过引入噪声修改原始文本的词嵌入，更好地捕捉自然语言变化，并在自然语言理解任务中表现出优异的性能。 |
| [^103] | [Breaking the Spurious Causality of Conditional Generation via Fairness Intervention with Corrective Sampling.](http://arxiv.org/abs/2212.02090) | 本文提出了一种通过公平干预和纠正采样的方法来解决条件生成中的伪因果关系。实验证明，该方法在各种数据集上都能有效地解决这个问题。 |
| [^104] | [TAX-Pose: Task-Specific Cross-Pose Estimation for Robot Manipulation.](http://arxiv.org/abs/2211.09325) | 本论文提出了一种名为TAX-Pose的系统，在机器人操作中实现了任务特定跨姿势的估计。通过学习对象之间的对应关系，这种系统能够在给定操作任务的情况下准确估计两个对象之间的跨姿势，并利用估计结果指导下游的运动规划。 |
| [^105] | [Robot Learning on the Job: Human-in-the-Loop Autonomy and Learning During Deployment.](http://arxiv.org/abs/2211.08416) | 本论文提出了Sirius框架，通过任务分工实现人机协作，部分自主的机器人负责决策工作，人类操作员在需要时进行干预。这种人机团队可以确保复杂任务的安全部署。同时，引入了一种新的学习算法，通过重新加权训练样本来改进策略性能。 |
| [^106] | [On the Informativeness of Supervision Signals.](http://arxiv.org/abs/2211.01407) | 本文使用信息论比较了常用的监督信号对表示学习性能的贡献，并为在大数据时代使用硬标签提供了理论上的证明，但对于少样本学习和分布外泛化，需要使用更丰富的监督信号。 |
| [^107] | [Artificial ASMR: A Cyber-Psychological Approach.](http://arxiv.org/abs/2210.14321) | 本研究提出了一种网络心理学方法，结合信号处理、人工智能和实验心理学，通过分析ASMR音频中的循环特征，合成能触发ASMR效应的ASMR片段，从而揭示了ASMR效应触发的一种可能因素。 |
| [^108] | [Language Detoxification with Attribute-Discriminative Latent Space.](http://arxiv.org/abs/2210.10329) | 本研究提出了一种使用属性辨别潜空间进行语言去毒化的方法，通过将原始Transformer语言模型的潜空间投影到一个能够通过属性将文本进行良好分离的潜空间上，最小化内存和计算开销，实现了对有毒文本的控制。 |
| [^109] | [Exclusive Supermask Subnetwork Training for Continual Learning.](http://arxiv.org/abs/2210.10209) | 本研究提出了一种连续学习方法ExSSNeT，通过独占超掩码子网络训练和KNN-based知识传递，解决了固定权重限制和知识积累问题。 |
| [^110] | [Universal Prompt Tuning for Graph Neural Networks.](http://arxiv.org/abs/2209.15240) | 本文介绍了一种名为Graph Prompt Feature（GPF）的新方法，可通用地调整预先训练过的图神经网络模型，操作于输入的特征空间，能够对应任何形式的Prompt函数。 |
| [^111] | [Learning from Symmetry: Meta-Reinforcement Learning with Symmetrical Behaviors and Language Instructions.](http://arxiv.org/abs/2209.10656) | 这篇论文研究了元强化学习中结合对称行为和语言指令的方法，以提高算法的泛化能力和学习效率。实验证明该方法能够极大地改善元强化学习的泛化能力和学习效率。 |
| [^112] | [A Simple Approach for State-Action Abstraction using a Learned MDP Homomorphism.](http://arxiv.org/abs/2209.06356) | 本论文提出了一种在离散动作空间中构建同态映射的新方法，通过使用环境动力学的部分模型来推断相同状态的状态动作对，从而减小状态-动作空间的大小。 |
| [^113] | [A first-order logic characterization of safety and co-safety languages.](http://arxiv.org/abs/2209.02307) | 本论文提出了一些新的语言类型和算法，可以降低模型检测和反应合成等问题的复杂度。 |
| [^114] | [SFusion: Self-attention based N-to-One Multimodal Fusion Block.](http://arxiv.org/abs/2208.12776) | SFusion是一个基于自注意力的融合模块，用于解决N对一的多模态融合问题，不需要合成或填充缺失的模态。它通过自动学习融合可用的模态，并构建共享表示来实现多模态的融合，以便下游决策模型使用。 |
| [^115] | [Softmax-free Linear Transformers.](http://arxiv.org/abs/2207.03341) | 这项研究提出了无softmax的线性变换器(SOFT)，用高斯核函数来逼近自注意机制，以改善视觉识别领域中现有方法的局限性。 |
| [^116] | [Worldwide AI Ethics: a review of 200 guidelines and recommendations for AI governance.](http://arxiv.org/abs/2206.11922) | 本篇论文回顾了200个AI治理指南和建议，通过对这些文档内容和性质的可视化，旨在了解各机构间AI伦理原则存在的共识和相似点，为未来的法规辩论提供启示。 |
| [^117] | [Are Message Passing Neural Networks Really Helpful for Knowledge Graph Completion?.](http://arxiv.org/abs/2205.10652) | 这项研究发现简单的多层感知器（MLP）模型在知识图谱补全任务上能够与消息传递神经网络（MPNNs）相媲美，暗示消息传递可能不像之前认为的那样关键。评分函数和损失函数设计对于模型性能有更大影响。 |
| [^118] | [Cross-Camera Trajectories Help Person Retrieval in a Camera Network.](http://arxiv.org/abs/2204.12900) | 本文提出了一种基于跨摄像头轨迹生成的行人检索框架，该框架在时间和空间信息中进行了结合。通过提取跨摄像头轨迹并进行条件随机场模型和受限非负矩阵分解的优化，最终提高了检索效果。 |
| [^119] | [Towards Visual Affordance Learning: A Benchmark for Affordance Segmentation and Recognition.](http://arxiv.org/abs/2203.14092) | 该论文介绍了一个大规模的多视角RGBD视觉可管理学习数据集，其中包含了37个对象类别的47210个图像，并且每个图像都带有15个视觉可管理类别的注释。 |
| [^120] | [Meta-Learning for Simple Regret Minimization.](http://arxiv.org/abs/2202.12888) | 本论文提出了用于在赌博机中进行简单遗憾最小化的元学习框架，并提出了首个贝叶斯和频率派元学习算法。贝叶斯算法具有先验分布并且具有较小的元简单遗憾，而频率派算法更通用且可以在更多的设置中进行分析。通过将算法应用于不同的赌博机问题，我们验证了理论的有效性。 |
| [^121] | [Human Detection of Political Speech Deepfakes across Transcripts, Audio, and Video.](http://arxiv.org/abs/2202.12883) | 这项研究通过实验发现，人们在判断政治演讲的真实性时，音频和视觉信息对于准确区分真实和伪造的Deepfakes更为重要，而错误信息的基准影响较小。 |
| [^122] | [Continual Learning Beyond a Single Model.](http://arxiv.org/abs/2202.09826) | 本论文研究了超越单一模型的持续学习。通过使用集成模型，能够改善持续性能，但随着模型数量增加，计算成本也会增加。为了解决这个问题，提出了一种计算成本较低的算法，能够在运行时间上与单一模型相当，并享有集成的性能优势。 |
| [^123] | [Learning Interpretable Models Through Multi-Objective Neural Architecture Search.](http://arxiv.org/abs/2112.08645) | 本研究提出了一种多目标分布式神经架构搜索框架，旨在优化深度神经网络的任务性能和可解释性。利用非支配排序遗传算法（NSGA-II）和可解释人工智能（XAI）技术，奖励那些可以被领域专家更好理解的架构。 |
| [^124] | [Reinforcement Learning for Robot Navigation with Adaptive Forward Simulation Time (AFST) in a Semi-Markov Model.](http://arxiv.org/abs/2108.06161) | 本文提出了一种基于深度强化学习的机器人导航方法，通过自适应前向模拟时间 (AFST) 在半马尔科夫模型中进行建模，克服了导航中的局部最小问题，并通过减少动作空间的维度和改进分布式近端策略优化 (DPPO) 算法来优化模型，在各种未知环境中取得了良好的效果。 |
| [^125] | [The Curse of Passive Data Collection in Batch Reinforcement Learning.](http://arxiv.org/abs/2106.09973) | 本文研究了批量强化学习中被动数据采集的代价问题，并发现与主动数据采集相比，被动采集的样本复杂性呈指数级增加。 |
| [^126] | [A unified logical framework for explanations in classifier systems.](http://arxiv.org/abs/2105.14452) | 本研究提出了一种以ceteris paribus为基础的模态语言，用于解释二进制分类器及其属性的推理。我们证明了两个关于语言基数的证明系统的完备性，并研究了无限变量和有限变量情况下的可满足性检查问题。我们还使用这种语言来形式化多种解释概念，包括对事实、对比和反事实解释以及偏见。 |
| [^127] | [Handling Noisy Labels via One-Step Abductive Multi-Target Learning and Its Application to Helicobacter Pylori Segmentation.](http://arxiv.org/abs/2011.14956) | 本文研究了处理噪声标签的新方法，特别针对医学组织病理学图像分析中的困难情况。通过一步式绳索多目标学习，该方法克服了标签中存在的复杂噪声和评估策略不明确的问题。 |
| [^128] | [Transfer Learning in Deep Reinforcement Learning: A Survey.](http://arxiv.org/abs/2009.07888) | 这篇综述调查了深度强化学习领域中的迁移学习方法的最新进展，并提供了一个对这些方法进行分类的框架。分析了它们的目标、方法学、兼容的强化学习背景以及实际应用，并探讨了迁移学习与其他相关主题之间的联系。 |

# 详细

[^1]: DiT-3D: 探索用于3D形状生成的纯扩散Transformer

    DiT-3D: Exploring Plain Diffusion Transformers for 3D Shape Generation. (arXiv:2307.01831v1 [cs.CV])

    [http://arxiv.org/abs/2307.01831](http://arxiv.org/abs/2307.01831)

    DiT-3D是一种针对3D形状生成的新型扩散Transformer，通过在纯Transformer上进行去噪处理，结合3D位置和补丁嵌入来聚合体素化点云的输入，并引入了3D窗口注意力以降低计算成本。

    

    最近的扩散Transformer（例如DiT）已经在生成高质量的2D图像方面展示了强大的效果。但是，是否Transformer架构在3D形状生成方面同样有效仍然有待确定，因为先前的3D扩散方法大部分采用了U-Net架构。为了弥合这一差距，我们提出了一种新颖的用于3D形状生成的扩散Transformer，称为DiT-3D，它可以直接在用于体素化点云的纯Transformer上进行去噪处理。与现有的U-Net方法相比，我们的DiT-3D在模型尺寸上具有更好的可扩展性，并且产生的生成结果质量更高。具体来说，DiT-3D采用了DiT的设计理念，但通过融合3D位置和补丁嵌入来自适应地聚合来自体素化点云的输入。为了减少3D形状生成中自注意力的计算成本，我们在Transformer块中引入了3D窗口注意力，以增加3D令牌数量。

    Recent Diffusion Transformers (e.g., DiT) have demonstrated their powerful effectiveness in generating high-quality 2D images. However, it is still being determined whether the Transformer architecture performs equally well in 3D shape generation, as previous 3D diffusion methods mostly adopted the U-Net architecture. To bridge this gap, we propose a novel Diffusion Transformer for 3D shape generation, namely DiT-3D, which can directly operate the denoising process on voxelized point clouds using plain Transformers. Compared to existing U-Net approaches, our DiT-3D is more scalable in model size and produces much higher quality generations. Specifically, the DiT-3D adopts the design philosophy of DiT but modifies it by incorporating 3D positional and patch embeddings to adaptively aggregate input from voxelized point clouds. To reduce the computational cost of self-attention in 3D shape generation, we incorporate 3D window attention into Transformer blocks, as the increased 3D token le
    
[^2]: 具有可解释行为不确定性的人类轨迹预测

    Human Trajectory Forecasting with Explainable Behavioral Uncertainty. (arXiv:2307.01817v1 [cs.CV])

    [http://arxiv.org/abs/2307.01817](http://arxiv.org/abs/2307.01817)

    本研究提出了一种新的人类轨迹预测模型BNSP-SFM，将行为SDE模型与贝叶斯神经网络相结合，能够提供较好的预测能力和强大的可解释性。与11种最先进的方法相比，BNSP-SFM在预测精度上取得了多达50％的改进。这种模型在不同环境和人群密度的场景中也能够更好地推广。

    

    人类轨迹预测有助于理解和预测人类行为，可以应用于社交机器人到自动驾驶汽车等各种场景，并且一直受到深入研究。现有方法可以分为基于模型和基于模型的方法。基于模型的方法提供了可解释性，但预测能力有限，而基于模型的方法提供了较好的预测能力，但缺乏可解释性。结合这两种方法，我们提出了一种新的贝叶斯神经随机微分方程模型BNSP-SFM，其中行为SDE模型与贝叶斯神经网络（BNNs）相结合。虽然神经网络提供了较好的预测能力，SDE提供了强大的可解释性和行为和观察的可量化不确定性。我们展示了BNSP-SFM相比于11种最先进的方法，预测精度提高了多达50％。BNSP-SFM还能更好地推广到不同环境和人群密度的截然不同场景中（约20倍）。

    Human trajectory forecasting helps to understand and predict human behaviors, enabling applications from social robots to self-driving cars, and therefore has been heavily investigated. Most existing methods can be divided into model-free and model-based methods. Model-free methods offer superior prediction accuracy but lack explainability, while model-based methods provide explainability but cannot predict well. Combining both methodologies, we propose a new Bayesian Neural Stochastic Differential Equation model BNSP-SFM, where a behavior SDE model is combined with Bayesian neural networks (BNNs). While the NNs provide superior predictive power, the SDE offers strong explainability with quantifiable uncertainty in behavior and observation. We show that BNSP-SFM achieves up to a 50% improvement in prediction accuracy, compared with 11 state-of-the-art methods. BNSP-SFM also generalizes better to drastically different scenes with different environments and crowd densities (~ 20 times hi
    
[^3]: DeepFlorist: 重新思考深度神经网络和集成学习作为目标分类的元分类器

    DeepFlorist: Rethinking Deep Neural Networks and Ensemble Learning as A Meta-Classifier For Object Classification. (arXiv:2307.01806v1 [cs.CV])

    [http://arxiv.org/abs/2307.01806](http://arxiv.org/abs/2307.01806)

    DeepFlorist提出了一种新型学习范式，通过集成学习作为元分类器实现花卉分类。通过密集卷积神经网络和卷积神经网络提取高级特征，并采用多个模型进行集成，DeepFlorist在准确性和鲁棒性方面表现优于其他方法。

    

    在本文中，我们提出了一种名为"DeepFlorist"的新型学习范式，利用集成学习作为元分类器进行花卉分类。DeepFlorist将深度学习的强大性能与集成方法的稳健性结合起来，以实现准确可靠的花卉分类结果。所提出的网络架构利用密集卷积神经网络（DCNNs）和卷积神经网络（CNNs）的组合来提取花卉图像的高级特征，然后通过全连接层进行分类。为了增强DeepFlorist的性能和泛化能力，采用了集成学习方法，结合多个不同的模型以提高分类准确性。在基准花卉数据集上的实验证明了DeepFlorist的有效性，在准确性和鲁棒性方面表现优于最先进的方法。所提出的框架在实际应用中对于自动化花卉识别系统具有重要潜力。

    In this paper, we propose a novel learning paradigm called "DeepFlorist" for flower classification using ensemble learning as a meta-classifier. DeepFlorist combines the power of deep learning with the robustness of ensemble methods to achieve accurate and reliable flower classification results. The proposed network architecture leverages a combination of dense convolutional and convolutional neural networks (DCNNs and CNNs) to extract high-level features from flower images, followed by a fully connected layer for classification. To enhance the performance and generalization of DeepFlorist, an ensemble learning approach is employed, incorporating multiple diverse models to improve the classification accuracy. Experimental results on benchmark flower datasets demonstrate the effectiveness of DeepFlorist, outperforming state-of-the-art methods in terms of accuracy and robustness. The proposed framework holds significant potential for automated flower recognition systems in real-world app
    
[^4]: 一个思想的内在情感

    The Inner Sentiments of a Thought. (arXiv:2307.01784v1 [cs.CL])

    [http://arxiv.org/abs/2307.01784](http://arxiv.org/abs/2307.01784)

    这篇论文探索了基于Transformer的大型语言模型中句子内部情感表示的方法，训练了预测器来分析句子的情感分布，并展示了即使是普通的连接词也可以显著改变话语的情感轨迹。

    

    基于Transformer的大型语言模型能够生成高度逼真的文本。它们能够表达并至少暗示出一系列情感和色彩，从明显的价值和唤起到微妙的决心和赞赏。我们首次探索了这些表示及其如何用于理解单个句子内部的情感运作。我们训练了从增长长度的前缀中应用到LLM的隐藏表示的句子的最终情感的分布的定量预测器。在展示了价值、决心、赞赏、焦虑和烦恼的分布预测器是良好校准的基础上，我们提供了使用这些预测器分析句子的示例，例如，展示了即使是普通的连接词（例如，“但是”）也可以极大地改变话语的情感轨迹。然后，我们展示了如何利用这些预测器来利用分布表示。

    Transformer-based large-scale language models (LLMs) are able to generate highly realistic text. They are duly able to express, and at least implicitly represent, a wide range of sentiments and color, from the obvious, such as valence and arousal to the subtle, such as determination and admiration. We provide a first exploration of these representations and how they can be used for understanding the inner sentimental workings of single sentences. We train predictors of the quantiles of the distributions of final sentiments of sentences from the hidden representations of an LLM applied to prefixes of increasing lengths. After showing that predictors of distributions of valence, determination, admiration, anxiety and annoyance are well calibrated, we provide examples of using these predictors for analyzing sentences, illustrating, for instance, how even ordinary conjunctions (e.g., "but") can dramatically alter the emotional trajectory of an utterance. We then show how to exploit the dis
    
[^5]: GHOST:一种使用硅光子学的图神经网络加速器

    GHOST: A Graph Neural Network Accelerator using Silicon Photonics. (arXiv:2307.01782v1 [cs.AR])

    [http://arxiv.org/abs/2307.01782](http://arxiv.org/abs/2307.01782)

    GHOST是第一个使用硅光子学的图神经网络加速器，高效地处理和加速GNN，克服了传统加速器的缺点，使得它可以应用于各种GNN模型和架构的推理。

    

    图神经网络（GNN）已经成为一种强大的建模和学习图结构数据的方法。GNN的能力已经在推荐系统、社交网络分析、药物发现和机器人领域等多个领域得到了巨大的益处。然而，加速和高效处理GNN需要一种超越传统人工神经网络加速器的独特方法，这是由于GNN具有巨大的计算和存储需求。CMOS平台缩放的减速也推动了对替代实现基体的寻求。在本文中，我们提出了GHOST，这是第一个用于GNN的硅光子硬件加速器。GHOST高效地减轻了与顶点和边操作相关的成本。它在光学领域中分别实现了运行GNN所涉及的三个主要阶段，使其可以用于各种广泛使用的GNN模型和架构的推理。

    Graph neural networks (GNNs) have emerged as a powerful approach for modelling and learning from graph-structured data. Multiple fields have since benefitted enormously from the capabilities of GNNs, such as recommendation systems, social network analysis, drug discovery, and robotics. However, accelerating and efficiently processing GNNs require a unique approach that goes beyond conventional artificial neural network accelerators, due to the substantial computational and memory requirements of GNNs. The slowdown of scaling in CMOS platforms also motivates a search for alternative implementation substrates. In this paper, we present GHOST, the first silicon-photonic hardware accelerator for GNNs. GHOST efficiently alleviates the costs associated with both vertex-centric and edge-centric operations. It implements separately the three main stages involved in running GNNs in the optical domain, allowing it to be used for the inference of various widely used GNN models and architectures, 
    
[^6]: 通过3D建模，实现自然外观的服装纹理以逃避人物检测器

    Physically Realizable Natural-Looking Clothing Textures Evade Person Detectors via 3D Modeling. (arXiv:2307.01778v1 [cs.CV])

    [http://arxiv.org/abs/2307.01778](http://arxiv.org/abs/2307.01778)

    通过3D建模，制作出与日常服装纹理相似的对抗性伪装纹理，可以在多个视角下避开人物检测，实现自然外观的服装纹理。

    

    最近的研究提出了制作对抗性服装来逃避人物检测器，但要么只对限定的视角有效，要么对人类非常明显。我们旨在基于3D建模来制作对抗性的服装纹理，这个想法已经被用于制作刚性的对抗性物体，如3D打印的乌龟。与刚性物体不同，人类和服装是非刚性的，这导致了在实际制作中的困难。为了制作出看起来自然的对抗性服装，可以在多个视角下避开人物检测器，我们提出了类似于日常服装纹理之一的对抗性伪装纹理（AdvCaT），即伪装纹理。我们利用Voronoi图和Gumbel-softmax技巧来参数化伪装纹理，并通过3D建模来优化参数。此外，我们还提出了一个高效的增强管道，将拓扑合理的投影（TopoProj）和Thin Plate Spline（TPS）结合在3D网格上使用。

    Recent works have proposed to craft adversarial clothes for evading person detectors, while they are either only effective at limited viewing angles or very conspicuous to humans. We aim to craft adversarial texture for clothes based on 3D modeling, an idea that has been used to craft rigid adversarial objects such as a 3D-printed turtle. Unlike rigid objects, humans and clothes are non-rigid, leading to difficulties in physical realization. In order to craft natural-looking adversarial clothes that can evade person detectors at multiple viewing angles, we propose adversarial camouflage textures (AdvCaT) that resemble one kind of the typical textures of daily clothes, camouflage textures. We leverage the Voronoi diagram and Gumbel-softmax trick to parameterize the camouflage textures and optimize the parameters via 3D modeling. Moreover, we propose an efficient augmentation pipeline on 3D meshes combining topologically plausible projection (TopoProj) and Thin Plate Spline (TPS) to narr
    
[^7]: MOPO-LSI：用户指南

    MOPO-LSI: A User Guide. (arXiv:2307.01719v1 [q-fin.PM])

    [http://arxiv.org/abs/2307.01719](http://arxiv.org/abs/2307.01719)

    MOPO-LSI是一款开源的多目标投资组合优化库，为可持续投资提供用户指南，并介绍了版本1.0的问题设置、工作流程和超参数。

    

    MOPO-LSI是一种开源的可持续投资多目标投资组合优化库。本文提供了MOPO-LSI版本1.0的用户指南，包括问题设置、工作流程和配置中的超参数。

    MOPO-LSI is an open-source Multi-Objective Portfolio Optimization Library for Sustainable Investments. This document provides a user guide for MOPO-LSI version 1.0, including problem setup, workflow and the hyper-parameters in configurations.
    
[^8]: 关于约束时间序列生成问题的研究

    On the Constrained Time-Series Generation Problem. (arXiv:2307.01717v1 [cs.LG])

    [http://arxiv.org/abs/2307.01717](http://arxiv.org/abs/2307.01717)

    这篇论文研究了约束时间序列生成问题。在实际应用中，合成时间序列被广泛用于增强历史时间序列数据集，提高机器学习算法的性能，放大稀有事件的发生，以及创建反事实情景。然而，现有的方法在满足约束方面存在问题，需要重新训练且计算代价高，或者在复杂约束条件下不切实际。

    

    合成时间序列经常在实际应用中用于增加历史时间序列数据集，以提高机器学习算法的性能，放大稀有事件的发生，并创建由时间序列描述的反事实情景。分布相似性（我们称之为真实性）以及满足一定数值约束是反事实时间序列场景生成请求中常见的要求。例如，美联储发布了给定约束时间序列的合成市场压力情景，供金融机构评估其在假设性衰退中的表现。现有的生成约束时间序列的方法通常通过对损失函数进行惩罚来强制满足约束，并拒绝不符合约束的样本。然而，如果我们改变约束条件，这些方法需要重新训练，而拒绝抽样可能在计算上是昂贵的，或者在复杂约束条件下是不切实际的。

    Synthetic time series are often used in practical applications to augment the historical time series dataset for better performance of machine learning algorithms, amplify the occurrence of rare events, and also create counterfactual scenarios described by the time series. Distributional-similarity (which we refer to as realism) as well as the satisfaction of certain numerical constraints are common requirements in counterfactual time series scenario generation requests. For instance, the US Federal Reserve publishes synthetic market stress scenarios given by the constrained time series for financial institutions to assess their performance in hypothetical recessions. Existing approaches for generating constrained time series usually penalize training loss to enforce constraints, and reject non-conforming samples. However, these approaches would require re-training if we change constraints, and rejection sampling can be computationally expensive, or impractical for complex constraints.
    
[^9]: 风险敏感强化学习的分布模型等效性

    Distributional Model Equivalence for Risk-Sensitive Reinforcement Learning. (arXiv:2307.01708v1 [cs.LG])

    [http://arxiv.org/abs/2307.01708](http://arxiv.org/abs/2307.01708)

    本文研究了风险敏感强化学习中的分布模型等效性问题。我们提出了两种新的模型等价性概念，并展示了如何将这些概念应用于增强任何基于模型的风险敏感算法。

    

    我们考虑学习用于风险敏感强化学习的模型的问题。我们在理论上证明了适当的价值等价性，这是一种学习模型的方法，可以用于在风险中性的情况下进行最优规划，但在风险敏感的情况下无法进行最优规划。我们利用分布式强化学习引入了两种新的模型等价性概念，其中一个是通用的，可以用于针对任何风险度量进行规划，但是计算复杂；另一个是实际的变体，允许选择可以进行最优规划的风险度量。我们展示了如何使用我们的框架来增强任何基于模型的风险敏感算法，并提供了表格和大规模实验来展示其能力。

    We consider the problem of learning models for risk-sensitive reinforcement learning. We theoretically demonstrate that proper value equivalence, a method of learning models which can be used to plan optimally in the risk-neutral setting, is not sufficient to plan optimally in the risk-sensitive setting. We leverage distributional reinforcement learning to introduce two new notions of model equivalence, one which is general and can be used to plan for any risk measure, but is intractable; and a practical variation which allows one to choose which risk measures they may plan optimally for. We demonstrate how our framework can be used to augment any model-free risk-sensitive algorithm, and provide both tabular and large-scale experiments to demonstrate its ability.
    
[^10]: 合成就是你需要的：移除针对合成数据的成员推断攻击的辅助数据假设

    Synthetic is all you need: removing the auxiliary data assumption for membership inference attacks against synthetic data. (arXiv:2307.01701v1 [cs.CR])

    [http://arxiv.org/abs/2307.01701](http://arxiv.org/abs/2307.01701)

    这项研究提出了一种新方法，移除了成员推断攻击对辅助数据的假设，使用只有合成数据的情况下仍然能够成功进行成员推断攻击。

    

    合成数据正在成为在保护隐私的同时共享个体级数据的最有希望的解决方案。基于影子建模的成员推断攻击已经成为评估合成数据隐私的标准。然而，这些攻击目前假设攻击者可以访问与训练数据集的类似分布的辅助数据集。这往往是一个非常强的假设，在实践中很难发生攻击。我们在这里展示了如何移除这个假设，以及如何仅使用合成数据进行成员推断攻击。具体而言，在三种不同的攻击场景中仅使用合成数据，我们的结果表明，成员推断攻击仍然成功，涉及两个真实世界数据集和两个合成数据生成器。这些结果表明，在审计合成数据发布访问辅助数据集的强假设可以放松以进行实际攻击。

    Synthetic data is emerging as the most promising solution to share individual-level data while safeguarding privacy. Membership inference attacks (MIAs), based on shadow modeling, have become the standard to evaluate the privacy of synthetic data. These attacks, however, currently assume the attacker to have access to an auxiliary dataset sampled from a similar distribution as the training dataset. This often is a very strong assumption that would make an attack unlikely to happen in practice. We here show how this assumption can be removed and how MIAs can be performed using only the synthetic data. More specifically, in three different attack scenarios using only synthetic data, our results demonstrate that MIAs are still successful, across two real-world datasets and two synthetic data generators. These results show how the strong hypothesis made when auditing synthetic data releases access to an auxiliary dataset - can be relaxed to perform an actual attack.
    
[^11]: 在线学习和使用ERM预言机解决无穷博弈问题

    Online Learning and Solving Infinite Games with an ERM Oracle. (arXiv:2307.01689v1 [cs.LG])

    [http://arxiv.org/abs/2307.01689](http://arxiv.org/abs/2307.01689)

    这项工作提出了一种仅依赖ERM预言机调用的在线学习算法，该算法在可实现情况下具有有限的遗憾，并在不可知情况下具有亚线性增长的遗憾。同时，还提供了类似的结果用于非参数博弈环境中的学习算法，即仅依赖最佳响应预言机的学习算法，并收敛到近似极小-极大均衡点。

    

    在基于在线学习的情况下，ERM足以达到接近最优泛化误差的目标，但在在线学习环境下并非如此，通常的概念类算法依赖计算效率较低的预言机，如标准最优算法(SOA)。在这项工作中，我们提出了一种仅依赖ERM预言机调用的在线二分类算法，并证明在可实现的情况下具有有限的遗憾(regret)，在不可知的情况下具有亚线性增长的遗憾。我们通过底层概念类的Littlestone和阈值维度来限制遗憾。我们获得了类似的结果用于非参数博弈，其中ERM预言机可以被理解为最佳响应预言机，根据其他玩家的游戏历史找到一个玩家的最佳响应。在这种情况下，我们提供了仅依赖最佳响应预言机的学习算法，并收敛到两人零和博弈的近似极小-极大均衡点。

    While ERM suffices to attain near-optimal generalization error in the stochastic learning setting, this is not known to be the case in the online learning setting, where algorithms for general concept classes rely on computationally inefficient oracles such as the Standard Optimal Algorithm (SOA). In this work, we propose an algorithm for online binary classification setting that relies solely on ERM oracle calls, and show that it has finite regret in the realizable setting and sublinearly growing regret in the agnostic setting. We bound the regret in terms of the Littlestone and threshold dimensions of the underlying concept class.  We obtain similar results for nonparametric games, where the ERM oracle can be interpreted as a best response oracle, finding the best response of a player to a given history of play of the other players. In this setting, we provide learning algorithms that only rely on best response oracles and converge to approximate-minimax equilibria in two-player zero
    
[^12]: 使用分布式雾服务器为智能物联网服务提供图神经网络支持

    Serving Graph Neural Networks With Distributed Fog Servers For Smart IoT Services. (arXiv:2307.01684v1 [cs.DC])

    [http://arxiv.org/abs/2307.01684](http://arxiv.org/abs/2307.01684)

    本文提出了一种分布式实时GNN推断框架Fograph，该框架利用了靠近物联网数据源的多个雾节点的资源，通过引入异构感知执行规划和GNN特定的压缩技术，以最大限度地发挥雾计算的架构优势。

    

    由于其在图结构上提取潜在表示能力的突出优势，图神经网络（GNN）在各种应用中引起了越来越多的关注。为了为物联网驱动的智能应用提供基于GNN的服务，传统的模型服务范例通常通过完全上传地理分布的输入数据到远程数据中心来依赖云。然而，我们的实证测量显示这种基于云的服务存在显著的通信开销，并且强调了应用新兴的雾计算的潜在巨大潜力。为了最大限度地发挥雾计算带来的架构优势，本文提出了一种新颖的分布式实时GNN推断框架Fograph，该框架利用了靠近物联网数据源的多个雾节点的多样性和动态资源。通过引入异构感知执行规划和GNN特定的压缩技术，Fograph的设计与GNN服务的独特特征相契合。

    Graph Neural Networks (GNNs) have gained growing interest in miscellaneous applications owing to their outstanding ability in extracting latent representation on graph structures. To render GNN-based service for IoT-driven smart applications, traditional model serving paradigms usually resort to the cloud by fully uploading geo-distributed input data to remote datacenters. However, our empirical measurements reveal the significant communication overhead of such cloud-based serving and highlight the profound potential in applying the emerging fog computing. To maximize the architectural benefits brought by fog computing, in this paper, we present Fograph, a novel distributed real-time GNN inference framework that leverages diverse and dynamic resources of multiple fog nodes in proximity to IoT data sources. By introducing heterogeneity-aware execution planning and GNN-specific compression techniques, Fograph tailors its design to well accommodate the unique characteristics of GNN servin
    
[^13]: 使用局部重新参数化技巧学习离散权重和激活

    Learning Discrete Weights and Activations Using the Local Reparameterization Trick. (arXiv:2307.01683v1 [cs.LG])

    [http://arxiv.org/abs/2307.01683](http://arxiv.org/abs/2307.01683)

    本论文研究了使用局部重新参数化技巧学习离散权重和激活的方法，通过二值化网络来降低计算复杂度，提高神经网络推理效率。

    

    在计算机视觉和机器学习中，一个关键的挑战是降低神经网络推理的计算和内存需求。一个常见的解决方案是使用二值化。通过对网络权重和激活进行二值化，可以通过用更快的位运算替代计算复杂的浮点操作来显著降低计算复杂度。这导致了一个更高效的神经网络推理，可以部署在资源有限的设备上。在这项工作中，我们扩展了之前使用局部重新参数化技巧训练具有离散权重的网络的方法，以允许离散激活。原始方法优化了离散权重的分布，并使用中心极限定理将预激活近似为连续的高斯分布。在这里，我们展示了概率建模也可以有效地训练具有离散激活的网络。

    In computer vision and machine learning, a crucial challenge is to lower the computation and memory demands for neural network inference. A commonplace solution to address this challenge is through the use of binarization. By binarizing the network weights and activations, one can significantly reduce computational complexity by substituting the computationally expensive floating operations with faster bitwise operations. This leads to a more efficient neural network inference that can be deployed on low-resource devices. In this work, we extend previous approaches that trained networks with discrete weights using the local reparameterization trick to also allow for discrete activations. The original approach optimized a distribution over the discrete weights and uses the central limit theorem to approximate the pre-activation with a continuous Gaussian distribution. Here we show that the probabilistic modeling can also allow effective training of networks with discrete activation as w
    
[^14]: RaidEnv: 探索Boss Raid游戏中自动内容平衡的新挑战

    RaidEnv: Exploring New Challenges in Automated Content Balancing for Boss Raid Games. (arXiv:2307.01676v1 [cs.AI])

    [http://arxiv.org/abs/2307.01676](http://arxiv.org/abs/2307.01676)

    RaidEnv是一个新的游戏模拟器，用于MMORPG游戏中boss raid情景的自动内容平衡研究，并提供两个基准来辅助游戏人工智能的实际应用。

    

    游戏内容的平衡显著影响游戏体验。不平衡的游戏内容会降低参与度或增加重复失败的挫败感。虽然游戏设计师有意调整游戏内容的难度，但这是一个繁琐、劳动密集且具有挑战性的过程，特别是对于内容丰富的商业级游戏。为了解决这个问题，游戏研究界探索了使用人工智能（AI）技术进行自动游戏平衡的方法。然而，以往的研究主要集中在有限的游戏内容上，并没有考虑到游戏测试代理在遇到内容变化时的泛化能力的重要性。在本研究中，我们提出了RaidEnv，这是一个新的游戏模拟器，包括多样化且可定制的内容，适用于MMORPG游戏中的boss raid情景。此外，我们设计了两个boss raid情景的基准，可以辅助游戏人工智能的实际应用。这些基准解决了两个开放性问题。

    The balance of game content significantly impacts the gaming experience. Unbalanced game content diminishes engagement or increases frustration because of repetitive failure. Although game designers intend to adjust the difficulty of game content, this is a repetitive, labor-intensive, and challenging process, especially for commercial-level games with extensive content. To address this issue, the game research community has explored automated game balancing using artificial intelligence (AI) techniques. However, previous studies have focused on limited game content and did not consider the importance of the generalization ability of playtesting agents when encountering content changes. In this study, we propose RaidEnv, a new game simulator that includes diverse and customizable content for the boss raid scenario in MMORPG games. Additionally, we design two benchmarks for the boss raid scenario that can aid in the practical application of game AI. These benchmarks address two open pro
    
[^15]: SwinGNN:重新思考在图生成的扩散模型中的置换不变性

    SwinGNN: Rethinking Permutation Invariance in Diffusion Models for Graph Generation. (arXiv:2307.01646v1 [cs.LG])

    [http://arxiv.org/abs/2307.01646](http://arxiv.org/abs/2307.01646)

    本文提出了一种新的图生成扩散模型SwinGNN，通过使用高效的2-WL消息传递网络和移动窗口自注意力，以及结合关键的训练和采样技术，显著提高了图生成样本的质量，并引入了随机置换的后处理技巧转换生成的图形统计量。

    

    基于置换等变网络的扩散模型可以学习图数据的置换不变分布。然而，相对于非不变模型，我们发现这些不变模型遇到了更大的学习挑战，因为1）它们的目标分布更具模态性；2）它们的最优一步去噪得分是具有更多成分的高斯混合物的得分函数。受到这个分析的启发，我们提出了一种非不变的扩散模型，称为“SwinGNN”，它采用了一种高效的边到边的2-WL消息传递网络，并利用SwinTransformers中的移动窗口自注意力。此外，通过系统性的实验和剖析，我们确定了几种关键的训练和采样技术，显著提高了图生成样本的质量。最后，我们引入了一种简单的后处理技巧，即随机置换生成的图，可以证明将任何图转换成图形统计量。

    Diffusion models based on permutation-equivariant networks can learn permutation-invariant distributions for graph data. However, in comparison to their non-invariant counterparts, we have found that these invariant models encounter greater learning challenges since 1) their effective target distributions exhibit more modes; 2) their optimal one-step denoising scores are the score functions of Gaussian mixtures with more components. Motivated by this analysis, we propose a non-invariant diffusion model, called $\textit{SwinGNN}$, which employs an efficient edge-to-edge 2-WL message passing network and utilizes shifted window based self-attention inspired by SwinTransformers. Further, through systematic ablations, we identify several critical training and sampling techniques that significantly improve the sample quality of graph generation. At last, we introduce a simple post-processing trick, $\textit{i.e.}$, randomly permuting the generated graphs, which provably converts any graph ge
    
[^16]: 特定工具支持下的对话式智能助手的插入扩展

    Insert-expansions for Tool-enabled Conversational Agents. (arXiv:2307.01644v1 [cs.HC])

    [http://arxiv.org/abs/2307.01644](http://arxiv.org/abs/2307.01644)

    本文研究了特定工具支持下的对话式智能助手的插入扩展。通过将用户作为工具，在生成明确推理路径时提供更多细节和更精确的请求，从而解决了工具干扰用户意图的问题。通过两个实证研究，发现在推荐领域中使用这种方法带来了好处。

    

    本文深入研究了在大型语言模型中实现Chain-of-Thought-Prompting的高级方式，重点研究了在这种提示方法生成的明确推理路径中使用工具（或“插件”）。我们发现，使用工具的对话式智能助手往往会走偏，因为来自搜索引擎或计算器等工具的额外上下文会偏离原始用户意图。为了解决这个问题，我们探索了一种概念，即用户成为工具，提供必要的细节并完善他们的请求。通过对话分析，我们将这种交互称为插入扩展-一种旨在促进所需响应的中间对话。我们通过两个实证研究使用直接比较的方法探索了从这种“用户作为工具”的方法中产生的可能性，并在推荐领域中发现了好处。

    This paper delves into an advanced implementation of Chain-of-Thought-Prompting in Large Language Models, focusing on the use of tools (or "plug-ins") within the explicit reasoning paths generated by this prompting method. We find that tool-enabled conversational agents often become sidetracked, as additional context from tools like search engines or calculators diverts from original user intents. To address this, we explore a concept wherein the user becomes the tool, providing necessary details and refining their requests. Through Conversation Analysis, we characterize this interaction as insert-expansion - an intermediary conversation designed to facilitate the preferred response. We explore possibilities arising from this 'user-as-a-tool' approach in two empirical studies using direct comparison, and find benefits in the recommendation domain.
    
[^17]: 近似互连性的启发式算法

    Heuristic Algorithms for the Approximation of Mutual Coherence. (arXiv:2307.01639v1 [cs.AI])

    [http://arxiv.org/abs/2307.01639](http://arxiv.org/abs/2307.01639)

    本研究提出了近似互连性的启发式算法，用于加速计算互连性指标。算法通过建模确认值的分布并估计其模型参数，然后利用分布的期望值来近似计算互连性。

    

    互连性是衡量两种观点相似性的指标。尽管该概念来自哲学，但它在广泛的技术中至关重要，例如Wahl-O-Mat系统。在德国，该系统帮助选民找到最符合他们政治偏好的候选人。由于要迭代遍历观点的所有子集，准确计算互连性非常耗时。而且，对于每个子集，必须解决一个SAT模型计数问题的实例，这在计算机科学中被认为是一个硬问题。本研究是加速这种计算的第一项研究。我们将所谓的确认值的分布建模为三个高斯混合，并提出了有效的启发式算法来估计其模型参数。然后，通过分布的期望值来近似互连性。其中一些算法是全多项式时间的，其他算法只需要解决少量的SA模型实例。

    Mutual coherence is a measure of similarity between two opinions. Although the notion comes from philosophy, it is essential for a wide range of technologies, e.g., the Wahl-O-Mat system. In Germany, this system helps voters to find candidates that are the closest to their political preferences. The exact computation of mutual coherence is highly time-consuming due to the iteration over all subsets of an opinion. Moreover, for every subset, an instance of the SAT model counting problem has to be solved which is known to be a hard problem in computer science. This work is the first study to accelerate this computation. We model the distribution of the so-called confirmation values as a mixture of three Gaussians and present efficient heuristics to estimate its model parameters. The mutual coherence is then approximated with the expected value of the distribution. Some of the presented algorithms are fully polynomial-time, others only require solving a small number of instances of the SA
    
[^18]: 多网络上的随机游走

    Random Walk on Multiple Networks. (arXiv:2307.01637v1 [cs.SI])

    [http://arxiv.org/abs/2307.01637](http://arxiv.org/abs/2307.01637)

    本论文提出了一种在多个网络上进行随机游走的方法，通过充分利用多个网络中的信息来进行更好的实体推断和分析。该方法支持多重网络和一般多网络，并且在理论上具有收敛性质。

    

    随机游走是一种探索网络结构的基本算法，可以用于许多任务，如局部社区检测和网络嵌入。现有的随机游走方法基于包含有限信息的单个网络。相比之下，实际数据通常包含不同类型或来源的实体，这些实体是全面的，并且可以通过多个网络更好地建模。为了充分利用多个网络中的丰富信息，并对实体进行更好的推断，在本研究中，我们提出了多网络上的随机游走（RWM）。RWM是灵活的，支持多重网络和一般的多网络，可以在网络之间形成多对多的节点映射。RWM在每个网络上发送一个随机行者以获得与起始节点相关的局部接近度（即节点访问概率）。具有相似访问概率的行者相互强化。我们从理论上分析了RWM的收敛性质。

    Random Walk is a basic algorithm to explore the structure of networks, which can be used in many tasks, such as local community detection and network embedding. Existing random walk methods are based on single networks that contain limited information. In contrast, real data often contain entities with different types or/and from different sources, which are comprehensive and can be better modeled by multiple networks. To take advantage of rich information in multiple networks and make better inferences on entities, in this study, we propose random walk on multiple networks, RWM. RWM is flexible and supports both multiplex networks and general multiple networks, which may form many-to-many node mappings between networks. RWM sends a random walker on each network to obtain the local proximity (i.e., node visiting probabilities) w.r.t. the starting nodes. Walkers with similar visiting probabilities reinforce each other. We theoretically analyze the convergence properties of RWM. Two appr
    
[^19]: SageFormer：面向多变量时间序列预测的系列感知图增强Transformer

    SageFormer: Series-Aware Graph-Enhanced Transformers for Multivariate Time Series Forecasting. (arXiv:2307.01616v1 [cs.LG])

    [http://arxiv.org/abs/2307.01616](http://arxiv.org/abs/2307.01616)

    本文介绍了SageFormer，一种面向多变量时间序列预测的系列感知图增强Transformer模型，通过图结构有效捕捉和建模序列之间的依赖关系，在表示不同序列中的时间模式和减少序列间冗余信息等方面取得了优越性能。

    

    多变量时间序列预测在各个领域起着至关重要的作用。虽然近期深度学习方法，特别是Transformer，展示了很大的潜力，但在解决跨序列依赖性的重要性问题上仍存在差距。本文介绍了SageFormer，一种系列感知图增强Transformer模型，旨在使用图结构有效捕捉和建模序列之间的依赖关系。SageFormer解决了两个关键挑战：有效地表示不同序列中的时间模式以及减少序列之间的冗余信息。重要的是，所提议的系列感知框架可以无缝集成到现有的基于Transformer的模型中，增强了模型对跨序列依赖性的建模能力。通过对真实世界和合成数据集进行广泛的实验证明，SageFormer相比先前的最先进方法展示出了优越的性能。

    Multivariate time series forecasting plays a critical role in diverse domains. While recent advancements in deep learning methods, especially Transformers, have shown promise, there remains a gap in addressing the significance of inter-series dependencies. This paper introduces SageFormer, a Series-aware Graph-enhanced Transformer model designed to effectively capture and model dependencies between series using graph structures. SageFormer tackles two key challenges: effectively representing diverse temporal patterns across series and mitigating redundant information among series. Importantly, the proposed series-aware framework seamlessly integrates with existing Transformer-based models, augmenting their ability to model inter-series dependencies. Through extensive experiments on real-world and synthetic datasets, we showcase the superior performance of SageFormer compared to previous state-of-the-art approaches.
    
[^20]: 过度自信是一件危险的事情：通过强制不太自信的预测来缓解成员推断攻击

    Overconfidence is a Dangerous Thing: Mitigating Membership Inference Attacks by Enforcing Less Confident Prediction. (arXiv:2307.01610v1 [cs.CR])

    [http://arxiv.org/abs/2307.01610](http://arxiv.org/abs/2307.01610)

    本文提出了一种防御技术HAMP，可以在不需要额外数据的情况下，通过强制模型进行不太自信的预测，达到强大的成员隐私保护和高准确性的目标。

    

    机器学习（ML）模型容易受到成员推断攻击（MIAs）的威胁，这些攻击确定给定的输入是否被用于训练目标模型。尽管有很多努力来缓解MIAs，但它们往往会受到有限的隐私保护、大幅降低准确性和/或需要难以获得的额外数据的困扰。本文提出了一种防御技术HAMP，可以在不需要额外数据的情况下实现强大的成员隐私和高准确性。为了缓解不同形式的MIAs，我们观察到它们可以统一，因为它们都利用了ML模型在通过不同的代理预测训练样本时的过度自信。这促使我们设计了一种通过模型强制进行不太自信预测的方法，从而迫使模型在训练样本和测试样本上表现类似。HAMP包括一个新颖的训练框架，使用高熵软标签和基于熵的正则化器来约束模型的预测，同时实现高准确性和成员隐私保护。

    Machine learning (ML) models are vulnerable to membership inference attacks (MIAs), which determine whether a given input is used for training the target model. While there have been many efforts to mitigate MIAs, they often suffer from limited privacy protection, large accuracy drop, and/or requiring additional data that may be difficult to acquire. This work proposes a defense technique, HAMP that can achieve both strong membership privacy and high accuracy, without requiring extra data. To mitigate MIAs in different forms, we observe that they can be unified as they all exploit the ML model's overconfidence in predicting training samples through different proxies. This motivates our design to enforce less confident prediction by the model, hence forcing the model to behave similarly on the training and testing samples. HAMP consists of a novel training framework with high-entropy soft labels and an entropy-based regularizer to constrain the model's prediction while still achieving h
    
[^21]: 在高峰小时序列预测中缩小性能差距: Seq2Peak框架

    Bridge the Performance Gap in Peak-hour Series Forecasting: The Seq2Peak Framework. (arXiv:2307.01597v1 [cs.LG])

    [http://arxiv.org/abs/2307.01597](http://arxiv.org/abs/2307.01597)

    本文提出了Seq2Peak框架，针对高峰小时序列预测任务，该框架通过解决高度非平稳性和性能评估问题，成功缩小了在常规时间序列预测模型中观察到的性能差距。

    

    高峰小时序列预测（PHSF）是各个领域中一个重要但未被充分探索的任务。虽然最先进的深度学习模型在常规时间序列预测（TSF）中表现出色，但在PHSF中却难以达到可比较的结果。这可能归因于高峰小时序列中高度非平稳性的挑战，使得直接预测比标准的TSF更加困难。此外，手动从常规预测结果中提取最大值会导致性能不佳，因为模型会最小化平均差。为了解决这些问题，本文提出了Seq2Peak，一个专为PHSF任务而设计的新颖框架，以弥合在TSF模型中观察到的性能差距。Seq2Peak具有两个关键组件：CyclicNorm流程来减轻非平稳性问题，以及一个简单而有效的可训练参数自由峰值小时解码器，采用混合损失函数来利用原始序列和高峰小时序列作为监督信号。

    Peak-Hour Series Forecasting (PHSF) is a crucial yet underexplored task in various domains. While state-of-the-art deep learning models excel in regular Time Series Forecasting (TSF), they struggle to achieve comparable results in PHSF. This can be attributed to the challenges posed by the high degree of non-stationarity in peak-hour series, which makes direct forecasting more difficult than standard TSF. Additionally, manually extracting the maximum value from regular forecasting results leads to suboptimal performance due to models minimizing the mean deficit. To address these issues, this paper presents Seq2Peak, a novel framework designed specifically for PHSF tasks, bridging the performance gap observed in TSF models. Seq2Peak offers two key components: the CyclicNorm pipeline to mitigate the non-stationarity issue, and a simple yet effective trainable-parameter-free peak-hour decoder with a hybrid loss function that utilizes both the original series and peak-hour series as superv
    
[^22]: 提示调整进一步推进，对比学习拉近距离：一种两阶段方法来减轻社会偏见

    Prompt Tuning Pushes Farther, Contrastive Learning Pulls Closer: A Two-Stage Approach to Mitigate Social Biases. (arXiv:2307.01595v1 [cs.CL])

    [http://arxiv.org/abs/2307.01595](http://arxiv.org/abs/2307.01595)

    这个论文提出了一种使用连续提示增强的对比学习的两阶段去偏模型，以减轻预训练语言模型中的社会偏见。在第一阶段，通过提示调整推进不同人口群体之间的表示距离。

    

    随着预训练语言模型（PLMs）的表示能力的提高，人们越来越担心它们会继承未经处理的语料库中的社会偏见。大多数先前的去偏技术使用对比数据增强（CDA）来平衡训练语料库。然而，CDA略微修改了原始语料库，限制了不同人口群体之间的表示距离在一个狭窄范围内。结果，去偏模型容易适应对比事实对之间的差异，这影响了它在有限的文本资源下的去偏性能。在本文中，我们提出了一种受对抗训练启发的两阶段去偏模型，使用连续提示增强的对比学习（称为CCPA）来减轻PLMs编码中的社会偏见。在第一阶段，我们提出了一种基于连续提示调整的数据增强方法，可以进一步推进不同人口群体之间的表示距离。在第二阶段，

    As the representation capability of Pre-trained Language Models (PLMs) improve, there is growing concern that they will inherit social biases from unprocessed corpora. Most previous debiasing techniques used Counterfactual Data Augmentation (CDA) to balance the training corpus. However, CDA slightly modifies the original corpus, limiting the representation distance between different demographic groups to a narrow range. As a result, the debiasing model easily fits the differences between counterfactual pairs, which affects its debiasing performance with limited text resources. In this paper, we propose an adversarial training-inspired two-stage debiasing model using Contrastive learning with Continuous Prompt Augmentation (named CCPA) to mitigate social biases in PLMs' encoding. In the first stage, we propose a data augmentation method based on continuous prompt tuning to push farther the representation distance between sample pairs along different demographic groups. In the second sta
    
[^23]: 显示广告中多元素创意的跨元素组合选择

    Cross-Element Combinatorial Selection for Multi-Element Creative in Display Advertising. (arXiv:2307.01593v1 [cs.IR])

    [http://arxiv.org/abs/2307.01593](http://arxiv.org/abs/2307.01593)

    这篇论文提出了一个跨元素组合选择框架CECS，用于解决显示广告中多元素创意选择的问题，通过采用跨元素交互的方式进行编码，将创意组合问题转化为多个创意元素级联选择问题。

    

    广告创意的有效性很大程度上受其视觉外观的影响。广告平台可以通过组合广告创意中的不同元素来生成具有不同外观的广告创意。然而，随着广告创意元素数量的增加，从无数可能性中选择合适的组合变得具有挑战性。行业的主流方法是独立选择各个创意元素，这经常忽视了建模过程中创意元素之间相互作用的重要性。作为回应，本文提出了一个用于多个创意元素的跨元素组合选择框架，称为CECS。在编码器过程中，采用了跨元素交互，根据当前候选创意动态调整单个创意元素的表达。在解码器过程中，将创意组合问题转化为多个创意元素级联选择问题。

    The effectiveness of ad creatives is greatly influenced by their visual appearance. Advertising platforms can generate ad creatives with different appearances by combining creative elements provided by advertisers. However, with the increasing number of ad creative elements, it becomes challenging to select a suitable combination from the countless possibilities. The industry's mainstream approach is to select individual creative elements independently, which often overlooks the importance of interaction between creative elements during the modeling process. In response, this paper proposes a Cross-Element Combinatorial Selection framework for multiple creative elements, termed CECS. In the encoder process, a cross-element interaction is adopted to dynamically adjust the expression of a single creative element based on the current candidate creatives. In the decoder process, the creative combination problem is transformed into a cascade selection problem of multiple creative elements. 
    
[^24]: IAdet：最简单的人机交互目标检测

    IAdet: Simplest human-in-the-loop object detection. (arXiv:2307.01582v1 [cs.CV])

    [http://arxiv.org/abs/2307.01582](http://arxiv.org/abs/2307.01582)

    本文提出了一种最简单的人机交互目标检测方法，其中的关键创新是智能注释（IA）策略和开源的IAdet工具。对于PASCAL VOC数据集，IAdet工具能够减少数据库标注时间，并提供免费训练好的模型，为强大的人机交互目标检测系统提供了改进的可能。

    

    本文提出了一种在标注数据的同时训练模型的策略，称为智能注释（IA）。IA包括三个模块：（1）辅助数据标注，（2）背景模型训练和（3）主动选择下一个数据点。在这个框架下，我们开源了特定于单类目标检测的IAdet工具。此外，我们设计了一种自动评估这种人机交互系统的方法。对于PASCAL VOC数据集，IAdet工具在减少数据库标注时间的同时提供了一个训练好的模型。这些结果是基于一个故意设计非常简单的IAdet系统。因此，IAdet易于改进，为强大的人机交互目标检测系统铺平了道路。

    This work proposes a strategy for training models while annotating data named Intelligent Annotation (IA). IA involves three modules: (1) assisted data annotation, (2) background model training, and (3) active selection of the next datapoints. Under this framework, we open-source the IAdet tool, which is specific for single-class object detection. Additionally, we devise a method for automatically evaluating such a human-in-the-loop system. For the PASCAL VOC dataset, the IAdet tool reduces the database annotation time by $25\%$ while providing a trained model for free. These results are obtained for a deliberately very simple IAdet design. As a consequence, IAdet is susceptible to multiple easy improvements, paving the way for powerful human-in-the-loop object detection systems.
    
[^25]: 人机协作注释的最优高效二元问题研究

    Optimal and Efficient Binary Questioning for Human-in-the-Loop Annotation. (arXiv:2307.01578v1 [cs.LG])

    [http://arxiv.org/abs/2307.01578](http://arxiv.org/abs/2307.01578)

    本文研究了人机协作注释中的二元问题，提出了从最优通用解决方案到实际高效方法的一系列解决方案。我们将问题构建为在给定预测器的情况下用最少的是/否问题来完全注释一个二元分类数据集。通过编码理论和启发式算法，我们提供了一个计算可行且高效的替代方案。

    

    尽管数据注释对解释能力、人工智能解决方案的研究和开发至关重要，但大多数研究如主动学习或少样本学习都集中在样本效率问题上。本文研究了另一个被忽视的问题，即在给定预测器的情况下如何获得带注释的数据。针对简单的二元分类设置，我们提出了从最优通用解决方案到实际高效方法的一系列解决方案。问题被构建为给定预测器情况下拥有最少的是/否问题来完全注释一个二元分类数据集。对于一般二元问题，解决方案可以在编码理论中找到，其中最优的提问策略由可能的标签编码的霍夫曼编码给出。然而，即使对于较小的数据集大小，这种方法的计算复杂度也是难以处理的。我们提出了一种基于多种启发式和前瞻性最小化的替代实际解决方案。

    Even though data annotation is extremely important for interpretability, research and development of artificial intelligence solutions, most research efforts such as active learning or few-shot learning focus on the sample efficiency problem. This paper studies the neglected complementary problem of getting annotated data given a predictor. For the simple binary classification setting, we present the spectrum ranging from optimal general solutions to practical efficient methods. The problem is framed as the full annotation of a binary classification dataset with the minimal number of yes/no questions when a predictor is available. For the case of general binary questions the solution is found in coding theory, where the optimal questioning strategy is given by the Huffman encoding of the possible labelings. However, this approach is computationally intractable even for small dataset sizes. We propose an alternative practical solution based on several heuristics and lookahead minimizati
    
[^26]: 使用神经后继网络和词嵌入形成概念认知地图

    Conceptual Cognitive Maps Formation with Neural Successor Networks and Word Embeddings. (arXiv:2307.01577v1 [cs.AI])

    [http://arxiv.org/abs/2307.01577](http://arxiv.org/abs/2307.01577)

    本研究通过使用神经后继网络和词嵌入向量构建了一个概念认知地图，该地图能够根据不同的尺度学习并将新信息与相关的既有表示相连接。

    

    人脑具有从环境中接收信息并进行上下文处理的非凡能力。侧隔核-海马在这一功能中起着关键作用，它深度参与记忆处理和使用地点和网格细胞构建认知地图。理解和利用这种能力可以极大地增强人工智能领域。多尺度后续表示作为地点和网格细胞功能的良好模型，并已显示出潜力。在这里，我们介绍了一个模型，该模型利用后续表示、神经网络以及词嵌入向量来构建三个独立概念的认知地图。该网络能够灵活学习两种不同的尺度地图，并将新信息放置在相关的既有表示附近。信息在认知地图上的分布根据尺度的不同而变化，可以是高度集中的，导致...

    The human brain possesses the extraordinary capability to contextualize the information it receives from our environment. The entorhinal-hippocampal plays a critical role in this function, as it is deeply engaged in memory processing and constructing cognitive maps using place and grid cells. Comprehending and leveraging this ability could significantly augment the field of artificial intelligence. The multi-scale successor representation serves as a good model for the functionality of place and grid cells and has already shown promise in this role. Here, we introduce a model that employs successor representations and neural networks, along with word embedding vectors, to construct a cognitive map of three separate concepts. The network adeptly learns two different scaled maps and situates new information in proximity to related pre-existing representations. The dispersion of information across the cognitive map varies according to its scale - either being heavily concentrated, resulti
    
[^27]: 基于机器学习的入侵检测：特征选择与特征提取

    Machine Learning-Based Intrusion Detection: Feature Selection versus Feature Extraction. (arXiv:2307.01570v1 [cs.CR])

    [http://arxiv.org/abs/2307.01570](http://arxiv.org/abs/2307.01570)

    本文对于入侵检测中的特征选择与特征提取两种方法在不同性能指标下进行了全面比较，并提供了基于机器学习的物联网入侵检测的综述。

    

    物联网在智慧城市、智慧农业、智慧医疗和智慧制造等许多领域中扮演着重要角色。然而，物联网设备非常容易受到网络攻击，可能导致安全漏洞和数据泄漏。为了有效预防这些攻击，已经开发了各种基于机器学习的物联网网络入侵检测方法，这些方法通常依赖于特征提取或特征选择技术，以减少输入数据的维数，然后再将其输入到机器学习模型中。这旨在降低检测复杂度，以适应实时操作，这在任何入侵检测系统中都非常重要。本文在精确率、召回率、检测准确度以及运行时间复杂度等性能指标方面对这两种特征降维方法进行了全面比较。

    Internet of things (IoT) has been playing an important role in many sectors, such as smart cities, smart agriculture, smart healthcare, and smart manufacturing. However, IoT devices are highly vulnerable to cyber-attacks, which may result in security breaches and data leakages. To effectively prevent these attacks, a variety of machine learning-based network intrusion detection methods for IoT networks have been developed, which often rely on either feature extraction or feature selection techniques for reducing the dimension of input data before being fed into machine learning models. This aims to make the detection complexity low enough for real-time operations, which is particularly vital in any intrusion detection systems. This paper provides a comprehensive comparison between these two feature reduction methods of intrusion detection in terms of various performance metrics, namely, precision rate, recall rate, detection accuracy, as well as runtime complexity, in the presence of t
    
[^28]: 可扩展的投影算子用于两视图学习任务的变量选择方法

    Scalable variable selection for two-view learning tasks with projection operators. (arXiv:2307.01558v1 [cs.LG])

    [http://arxiv.org/abs/2307.01558](http://arxiv.org/abs/2307.01558)

    本文提出了一种可扩展的变量选择方法，适用于两视图学习任务或向量值监督学习问题，能够处理规模极大的选择任务，并利用投影算子以及核函数进行相关性衡量和非线性相关模型的处理。

    

    本文提出了一种针对两视图设置或向量值监督学习问题的新型变量选择方法。我们的框架能够处理规模极大的选择任务，样本数甚至可以达到百万级。简言之，我们的方法通过选择与输出变量高度相关但与先前选择的变量无关的变量来进行变量选择。为了衡量相关性，我们的方法使用了投影算子及其代数的概念。通过投影算子，输入和输出变量集之间的关系、相关性也可以通过核函数来表达，从而可以利用非线性相关模型。通过实验证明了我们方法的可扩展性以及所选择特征的相关性。

    In this paper we propose a novel variable selection method for two-view settings, or for vector-valued supervised learning problems. Our framework is able to handle extremely large scale selection tasks, where number of data samples could be even millions. In a nutshell, our method performs variable selection by iteratively selecting variables that are highly correlated with the output variables, but which are not correlated with the previously chosen variables. To measure the correlation, our method uses the concept of projection operators and their algebra. With the projection operators the relationship, correlation, between sets of input and output variables can also be expressed by kernel functions, thus nonlinear correlation models can be exploited as well. We experimentally validate our approach, showing on both synthetic and real data its scalability and the relevance of the selected features. Keywords: Supervised variable selection, vector-valued learning, projection-valued mea
    
[^29]: 分离的RoadTopoFormer

    Separated RoadTopoFormer. (arXiv:2307.01557v1 [cs.CV])

    [http://arxiv.org/abs/2307.01557](http://arxiv.org/abs/2307.01557)

    这篇论文提出了一种分离的RoadTopoFormer框架，用于检测车道中心线和交通元素，并推理它们之间的关系。

    

    理解驾驶场景对实现自动驾驶至关重要。以往的工作如地图学习和BEV车道检测忽视了车道实例之间的连接关系，交通元素检测任务通常忽视与车道线的关系。为了解决这些问题，提出了一个任务，包括4个子任务，即交通元素检测、车道中心线检测、推理车道之间的连接关系和推理车道与交通元素之间的关联关系。我们提出了分离的RoadTopoFormer来解决这些问题，这是一个端到端的框架，可以检测到车道中心线和交通元素，并推理它们之间的关系。我们分别优化每个模块，以防止它们之间的相互影响，并通过少量的微调将它们聚合在一起。对于两个检测头，我们采用了类似DETR的架构来检测物体，对于关系头，我们将两个实例特征连接在一起。

    Understanding driving scenarios is crucial to realizing autonomous driving. Previous works such as map learning and BEV lane detection neglect the connection relationship between lane instances, and traffic elements detection tasks usually neglect the relationship with lane lines. To address these issues, the task is presented which includes 4 sub-tasks, the detection of traffic elements, the detection of lane centerlines, reasoning connection relationships among lanes, and reasoning assignment relationships between lanes and traffic elements. We present Separated RoadTopoFormer to tackle the issues, which is an end-to-end framework that detects lane centerline and traffic elements with reasoning relationships among them. We optimize each module separately to prevent interaction with each other and aggregate them together with few finetunes. For two detection heads, we adopted a DETR-like architecture to detect objects, and for the relationship head, we concat two instance features fro
    
[^30]: 对话代理中自然语言生成的知识图谱

    Knowledge Graph for NLG in the context of conversational agents. (arXiv:2307.01548v1 [cs.AI])

    [http://arxiv.org/abs/2307.01548](http://arxiv.org/abs/2307.01548)

    本文回顾了对话代理中使用的不同的知识图谱到文本生成架构，并讨论了每种架构的优点和局限性。根据具体任务的要求选择合适的架构，并强调了考虑执行时间和模型有效性的重要性，特别是在对话代理背景下。

    

    知识图谱（KG）的使用提高了对话代理提供的响应的准确性和全面性。在对话中生成答案包括从这些知识图谱生成文本，这仍被视为一个具有重要意义的具有挑战的任务。在本文中，我们对用于知识图谱到文本生成的不同架构进行了回顾，包括图神经网络、图转换器和带有seq2seq模型的线性化。我们讨论了每种架构的优点和局限性，并得出结论，选择架构将取决于具体任务的要求。我们还强调了考虑诸如执行时间和模型有效性等约束的重要性，特别是在对话代理的背景下。基于这些约束以及DAVI领域的标记数据的可用性，我们选择使用基于seq2seq的Transformer模型（PLMs）。

    The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness of the responses provided by a conversational agent. While generating answers during conversations consists in generating text from these KGs, it is still regarded as a challenging task that has gained significant attention in recent years. In this document, we provide a review of different architectures used for knowledge graph-to-text generation including: Graph Neural Networks, the Graph Transformer, and linearization with seq2seq models. We discuss the advantages and limitations of each architecture and conclude that the choice of architecture will depend on the specific requirements of the task at hand. We also highlight the importance of considering constraints such as execution time and model validity, particularly in the context of conversational agents. Based on these constraints and the availability of labeled data for the domains of DAVI, we choose to use seq2seq Transformer-based models (PLMs) for
    
[^31]: 在课堂上学习提示以了解人工智能的限制：一项试点研究

    Learning to Prompt in the Classroom to Understand AI Limits: A pilot study. (arXiv:2307.01540v1 [cs.HC])

    [http://arxiv.org/abs/2307.01540](http://arxiv.org/abs/2307.01540)

    在本研究中，通过学习提示，试图在课堂环境中理解人工智能的限制。人工智能的进展带来了巨大的潜力，但也引发了负面情绪。当前大型语言模型的能力限制被忽视，导致了错误的自信和不准确的建议。承认人工智能的不可靠性是解决这个问题的关键。

    

    人工智能的进展在帮助社会解决紧迫的社会问题方面具有巨大的潜力。特别是大型语言模型（LLM）和派生的聊天机器人，如ChatGPT，大大改进了AI系统的自然语言处理能力，使其能够处理前所未有的大量非结构化数据。由此产生的炒作也产生了负面情绪，即使在新颖的AI方法取得令人惊讶的贡献之后。造成这种情况的原因之一，但也是一个重要的问题本身，是越来越多人错误地认为自己能够轻松访问和处理任何形式的知识，以解决任何领域的问题，无需对AI或问题领域有任何专业知识，而忽视了当前LLMs的限制，例如幻觉和推理限制。承认人工智能的不可靠性对于解决由LLMs生成的可能错误建议可能产生的盲目过度自信的影响至关重要。同时，这可以减少恐惧和其他负面态度。

    Artificial intelligence's progress holds great promise in assisting society in addressing pressing societal issues. In particular Large Language Models (LLM) and the derived chatbots, like ChatGPT, have highly improved the natural language processing capabilities of AI systems allowing them to process an unprecedented amount of unstructured data. The consequent hype has also backfired, raising negative sentiment even after novel AI methods' surprising contributions. One of the causes, but also an important issue per se, is the rising and misleading feeling of being able to access and process any form of knowledge to solve problems in any domain with no effort or previous expertise in AI or problem domain, disregarding current LLMs limits, such as hallucinations and reasoning limits. Acknowledging AI fallibility is crucial to address the impact of dogmatic overconfidence in possibly erroneous suggestions generated by LLMs. At the same time, it can reduce fear and other negative attitude
    
[^32]: 在不确定环境下分析自主代理的有意行为

    Analyzing Intentional Behavior in Autonomous Agents under Uncertainty. (arXiv:2307.01532v1 [cs.AI])

    [http://arxiv.org/abs/2307.01532](http://arxiv.org/abs/2307.01532)

    本论文提出了一种在不确定环境下分析自主代理有意行为的方法，通过定量度量证据来区分有意结果、疏忽设计和实际意外。方法使用马尔可夫决策过程建模不确定环境，并通过概率模型检查计算代理的影响能力。采用反事实推理自动生成相关情景增加评估信心。在一个案例研究中成功区分“有意”和“意外”的交通碰撞。

    

    在不确定环境中，对自主决策行为进行有效的问责需要区分有意结果、疏忽设计和实际意外。我们提出使用有意行为的证据的定量度量来分析自主代理的行为。我们将不确定环境建模为马尔可夫决策过程（MDP）。对于给定的情景，我们依靠概率性模型检查来计算代理影响达成特定事件的能力。我们称之为代理的范围。如果代理的范围较大且其决策接近达到该事件的最佳状态，则存在有意行为的证据。我们的方法应用反事实推理来自动生成相关情景，以增加我们评估的信心。在一个案例研究中，我们展示了我们的方法如何区分“有意”和“意外”的交通碰撞。

    Principled accountability for autonomous decision-making in uncertain environments requires distinguishing intentional outcomes from negligent designs from actual accidents. We propose analyzing the behavior of autonomous agents through a quantitative measure of the evidence of intentional behavior. We model an uncertain environment as a Markov Decision Process (MDP). For a given scenario, we rely on probabilistic model checking to compute the ability of the agent to influence reaching a certain event. We call this the scope of agency. We say that there is evidence of intentional behavior if the scope of agency is high and the decisions of the agent are close to being optimal for reaching the event. Our method applies counterfactual reasoning to automatically generate relevant scenarios that can be analyzed to increase the confidence of our assessment. In a case study, we show how our method can distinguish between 'intentional' and 'accidental' traffic collisions.
    
[^33]: 应对不同光照、遮挡和成熟度条件下的西红柿自主识别和分级的卷积变换器

    Convolutional Transformer for Autonomous Recognition and Grading of Tomatoes Under Various Lighting, Occlusion, and Ripeness Conditions. (arXiv:2307.01530v1 [cs.CV])

    [http://arxiv.org/abs/2307.01530](http://arxiv.org/abs/2307.01530)

    本研究引入了一种卷积变换器架构的框架，能够在不同光照、遮挡和成熟度条件下自主识别和分级西红柿。

    

    在实际环境中，用移动机器人采摘完全成熟的西红柿面临着诸多挑战。这些挑战来自于叶子和树枝造成的遮挡，以及在果实发育阶段，西红柿和周围植被之间的颜色相似性。自然环境的多样性进一步加剧了这些问题，包括不同的光照条件、视角、遮挡因素和不同的成熟度水平。为了克服这些障碍，本研究引入了一种新颖的框架，利用卷积变换器架构自主识别和分级西红柿，无论其遮挡水平、光照条件和成熟度如何。所提出的模型经过特别为此目的精心注释的图像进行训练和测试。数据集在不同的光照条件、视角和使用不同的移动相机传感器下准备，与现有的数据集（如Laboro）有所区别。

    Harvesting fully ripe tomatoes with mobile robots presents significant challenges in real-world scenarios. These challenges arise from factors such as occlusion caused by leaves and branches, as well as the color similarity between tomatoes and the surrounding foliage during the fruit development stage. The natural environment further compounds these issues with varying light conditions, viewing angles, occlusion factors, and different maturity levels. To overcome these obstacles, this research introduces a novel framework that leverages a convolutional transformer architecture to autonomously recognize and grade tomatoes, irrespective of their occlusion level, lighting conditions, and ripeness. The proposed model is trained and tested using carefully annotated images curated specifically for this purpose. The dataset is prepared under various lighting conditions, viewing perspectives, and employs different mobile camera sensors, distinguishing it from existing datasets such as Laboro 
    
[^34]: LEAT: 通过潜在编码集成攻击，实现对真实场景中深度伪造的可靠干扰

    LEAT: Towards Robust Deepfake Disruption in Real-World Scenarios via Latent Ensemble Attack. (arXiv:2307.01520v1 [cs.CV])

    [http://arxiv.org/abs/2307.01520](http://arxiv.org/abs/2307.01520)

    这项研究通过一种名为LEAT的方法，在真实场景中实现了对深度伪造的可靠干扰。LEAT通过攻击独立的潜在编码过程来干扰深度伪造，提高了鲁棒性。

    

    深度伪造是由生成模型创建的恶意视觉内容，对社会造成越来越大的威胁。为了主动减轻深度伪造的损害，最近的研究采用了对抗扰动来干扰深度伪造模型的输出。然而，之前的方法主要集中在基于预定目标属性生成扭曲输出，导致在目标属性未知的真实场景中缺乏鲁棒性。此外，两种主要生成模型——生成对抗网络（GAN）和扩散模型之间的扰动可转移性仍然未被探索。在本文中，我们强调了目标属性可转移性和模型可转移性在实现对深度伪造的可靠干扰方面的重要性。为了解决这一挑战，我们提出了一种简单而有效的干扰方法，即潜在编码集成攻击（LEAT），它攻击了独立的潜在编码过程。通过干扰潜在编码过程，它可以提高在真实场景中的鲁棒性。

    Deepfakes, malicious visual contents created by generative models, pose an increasingly harmful threat to society. To proactively mitigate deepfake damages, recent studies have employed adversarial perturbation to disrupt deepfake model outputs. However, previous approaches primarily focus on generating distorted outputs based on only predetermined target attributes, leading to a lack of robustness in real-world scenarios where target attributes are unknown. Additionally, the transferability of perturbations between two prominent generative models, Generative Adversarial Networks (GANs) and Diffusion Models, remains unexplored. In this paper, we emphasize the importance of target attribute-transferability and model-transferability for achieving robust deepfake disruption. To address this challenge, we propose a simple yet effective disruption method called Latent Ensemble ATtack (LEAT), which attacks the independent latent encoding process. By disrupting the latent encoding process, it
    
[^35]: 个性化治疗推荐的深度注意力Q网络

    Deep Attention Q-Network for Personalized Treatment Recommendation. (arXiv:2307.01519v1 [cs.LG])

    [http://arxiv.org/abs/2307.01519](http://arxiv.org/abs/2307.01519)

    本研究提出了Deep Attention Q-Network，利用Transformer架构在深度强化学习框架内，个性化推荐治疗方案，通过高效整合过去的病患观察信息，解决了仅依赖当前观察信息的限制，从而提高了治疗效果。

    

    个性化治疗对于每个病患至关重要，但是在达到最佳的医疗效果方面也面临挑战。最近强化学习的进展为个性化治疗推荐提供了有希望的方法；但是，这些方法仅依靠当前病患的观察信息（生命体征、人口统计数据）作为病患的状态，可能无法准确地代表病患的真实健康状况。这种限制妨碍了策略学习和评估，最终限制了治疗效果。在本研究中，我们提出了深度注意力Q网络来进行个性化治疗推荐，利用Transformer架构在深度强化学习框架内，高效地整合了所有过去的病患观察信息。我们在实际的败血症和急性低血压病人群中评估了该模型，证明了其优于现有模型的优越性。我们的模型源代码可以在https://github.com/stevenmsm/RL-ICU-DAQN获得。

    Tailoring treatment for individual patients is crucial yet challenging in order to achieve optimal healthcare outcomes. Recent advances in reinforcement learning offer promising personalized treatment recommendations; however, they rely solely on current patient observations (vital signs, demographics) as the patient's state, which may not accurately represent the true health status of the patient. This limitation hampers policy learning and evaluation, ultimately limiting treatment effectiveness. In this study, we propose the Deep Attention Q-Network for personalized treatment recommendations, utilizing the Transformer architecture within a deep reinforcement learning framework to efficiently incorporate all past patient observations. We evaluated the model on real-world sepsis and acute hypotension cohorts, demonstrating its superiority to state-of-the-art models. The source code for our model is available at https://github.com/stevenmsm/RL-ICU-DAQN.
    
[^36]: 一体化：图神经网络的多任务提示

    All in One: Multi-task Prompting for Graph Neural Networks. (arXiv:2307.01504v1 [cs.SI])

    [http://arxiv.org/abs/2307.01504](http://arxiv.org/abs/2307.01504)

    本文提出了一种新颖的图模型的多任务提示方法，通过统一图提示和语言提示的格式，填补了预训练模型与各种图任务之间的差距。

    

    最近，“预训练和微调”已成为许多图任务的标准工作流程，因为它可以利用通用的图知识来缓解每个应用中缺乏图注释的问题。然而，节点级、边级和图级的图任务差异很大，导致预训练预文本通常与这些多任务不兼容。这种差距甚至可能导致对特定应用的“负迁移”，从而导致结果不佳。受自然语言处理（NLP）中提示学习的启发，该方法在各种NLP任务中利用先前知识已经显示出较大的有效性，我们研究了填补预训练模型和各种图任务之间差距的提示主题。在本文中，我们提出了一种新颖的用于图模型的多任务提示方法。具体来说，我们首先通过提示令牌、令牌结构和插入模式统一图提示和语言提示的格式。

    Recently, ''pre-training and fine-tuning'' has been adopted as a standard workflow for many graph tasks since it can take general graph knowledge to relieve the lack of graph annotations from each application. However, graph tasks with node level, edge level, and graph level are far diversified, making the pre-training pretext often incompatible with these multiple tasks. This gap may even cause a ''negative transfer'' to the specific application, leading to poor results. Inspired by the prompt learning in natural language processing (NLP), which has presented significant effectiveness in leveraging prior knowledge for various NLP tasks, we study the prompting topic for graphs with the motivation of filling the gap between pre-trained models and various graph tasks. In this paper, we propose a novel multi-task prompting method for graph models. Specifically, we first unify the format of graph prompts and language prompts with the prompt token, token structure, and inserting pattern. In
    
[^37]: HEDI: 第一次临床应用的切口疝修复生物力学评估和可视化工具的结果

    HEDI: First-Time Clinical Application and Results of a Biomechanical Evaluation and Visualisation Tool for Incisional Hernia Repair. (arXiv:2307.01502v1 [cs.CV])

    [http://arxiv.org/abs/2307.01502](http://arxiv.org/abs/2307.01502)

    HEDI是一种用于切口疝修复的生物力学评估和可视化工具，通过考虑腹壁的不稳定性，能够自动检测和评估疝的大小、体积和腹壁不稳定性。在31名患者的预手术评估中，HEDI显示出明显改善的成功率，所有患者在随访三年后仍然没有疼痛和疝再发。

    

    腹壁缺陷通常导致疼痛、不适以及切口疝再发，全球范围内造成重大发病率和多次手术修复。对于大型疝，网格修复通常基于缺陷区域与固定重叠，而不考虑生物力学方面的因素，如肌肉激活、腹腔内压力、组织弹性和腹壁扩张。为了解决这个问题，我们提出了一种考虑不稳定腹壁的切口疝修复的生物力学方法。此外，我们介绍了HEDI，这是一种利用Valsalva动作的动态计算机断层扫描技术来自动检测和评估疝大小、体积和腹壁不稳定性的工具。我们在31名患者预手术评估中首次临床应用了HEDI，与报道的成功率相比，显示出明显改善，所有患者在随访三年后仍然没有疼痛和疝再发。

    Abdominal wall defects often lead to pain, discomfort, and recurrence of incisional hernias, resulting in significant morbidity and repeated surgical repairs worldwide. Mesh repair for large hernias is usually based on the defect area with a fixed overlap, without considering biomechanical aspects such as muscle activation, intra-abdominal pressure, tissue elasticity, and abdominal wall distention. To address this issue, we present a biomechanical approach to incisional hernia repair that takes into account the unstable abdominal wall. Additionally, we introduce HEDI, a tool that uses dynamic computed tomography with Valsalva maneuver to automatically detect and assess hernia size, volume, and abdominal wall instability. Our first clinical application of HEDI in the preoperative evaluation of 31 patients shows significantly improved success rates compared to reported rates, with all patients remaining pain-free and showing no hernia recurrence after three years of follow-up.
    
[^38]: 缓解偏见：通过改进模型解释来提升图像分类

    Mitigating Bias: Enhancing Image Classification by Improving Model Explanations. (arXiv:2307.01473v1 [cs.CV])

    [http://arxiv.org/abs/2307.01473](http://arxiv.org/abs/2307.01473)

    本文提出了一种通过改进模型解释的方法来缓解图像分类中的偏见问题，通过引导模型的注意力向前景集中，从而提升对主要概念的学习效果。

    

    深度学习模型在从训练数据中学习复杂模式和概念方面展示出了显著的能力。然而，最近的研究发现这些模型倾向于过分依赖于图片背景中的简单和容易识别的特征，而不是它们本应分类的主要概念或对象。这种现象给图像分类器带来了挑战，因为图片中的关键元素可能会被掩盖。在本文中，我们提出了一种新的方法来解决这个问题并改善图像分类器对主要概念的学习。我们的核心思想是在分类任务过程中同时引导模型的注意力向前景集中。通过强调前景，即主要感兴趣的对象，我们旨在将模型的注意力从背景的主导影响上转移开来。为了实现这一点，我们引入了一种机制来鼓励模型足够地分配注意力给前景。

    Deep learning models have demonstrated remarkable capabilities in learning complex patterns and concepts from training data. However, recent findings indicate that these models tend to rely heavily on simple and easily discernible features present in the background of images rather than the main concepts or objects they are intended to classify. This phenomenon poses a challenge to image classifiers as the crucial elements of interest in images may be overshadowed. In this paper, we propose a novel approach to address this issue and improve the learning of main concepts by image classifiers. Our central idea revolves around concurrently guiding the model's attention toward the foreground during the classification task. By emphasizing the foreground, which encapsulates the primary objects of interest, we aim to shift the focus of the model away from the dominant influence of the background. To accomplish this, we introduce a mechanism that encourages the model to allocate sufficient att
    
[^39]: 超越保守主义：离线多智能体强化学习中的扩散策略

    Beyond Conservatism: Diffusion Policies in Offline Multi-agent Reinforcement Learning. (arXiv:2307.01472v1 [cs.AI])

    [http://arxiv.org/abs/2307.01472](http://arxiv.org/abs/2307.01472)

    DOM2是一种离线多智能体强化学习模型，通过扩散策略的改进，提高了算法在性能、泛化能力和数据效率方面的表现。DOM2在多智能体粒子和多智能体MuJoCo环境中优于现有算法，并在移位环境中具有更好的泛化能力。此外，DOM2还展现了卓越的数据效率，只使用较少的数据即可达到最先进的性能水平。

    

    我们提出了一种新颖的离线多智能体模型（DOM2），用于离线多智能体强化学习（MARL）。与现有算法在策略设计中主要依赖保守主义不同，DOM2基于扩散增强了策略的表达能力和多样性。具体而言，我们将扩散模型纳入策略网络，并提出了一种基于轨迹的数据增强方案进行训练。这些关键因素使我们的算法在环境变化方面更加稳健，并在性能、泛化能力和数据效率方面取得了显著的改进。我们广泛的实验结果表明，DOM2在多智能体粒子和多智能体MuJoCo环境中优于现有的最先进方法，并且由于其高表达能力和多样性，在移位环境中具有更好的泛化能力。此外，DOM2表现出卓越的数据效率，在与现有算法相比只使用$20+$倍少的数据下，就能达到最先进的性能水平。

    We present a novel Diffusion Offline Multi-agent Model (DOM2) for offline Multi-Agent Reinforcement Learning (MARL). Different from existing algorithms that rely mainly on conservatism in policy design, DOM2 enhances policy expressiveness and diversity based on diffusion. Specifically, we incorporate a diffusion model into the policy network and propose a trajectory-based data-augmentation scheme in training. These key ingredients make our algorithm more robust to environment changes and achieve significant improvements in performance, generalization and data-efficiency. Our extensive experimental results demonstrate that DOM2 outperforms existing state-of-the-art methods in multi-agent particle and multi-agent MuJoCo environments, and generalizes significantly better in shifted environments thanks to its high expressiveness and diversity. Furthermore, DOM2 shows superior data efficiency and can achieve state-of-the-art performance with $20+$ times less data compared to existing algori
    
[^40]: 因果强化学习：一项综述

    Causal Reinforcement Learning: A Survey. (arXiv:2307.01452v1 [cs.LG])

    [http://arxiv.org/abs/2307.01452](http://arxiv.org/abs/2307.01452)

    这项综述总结了因果强化学习的研究文献，强调因果关系的重要作用，它能够形式化知识并实现有效的知识传递。

    

    强化学习是在不确定性条件下解决序列决策问题的一种重要范式。尽管近几十年来取得了许多显著的成就，但将强化学习方法应用于现实世界仍然具有挑战性。其中一个主要障碍是强化学习代理缺乏对世界的基本理解，因此必须通过大量的试错交互学习。他们可能在解释自己的决策以及推广所获得的知识方面面临挑战。然而，因果关系具有明显的优势，它可以以系统化的方式形式化知识，并利用不变性进行有效的知识传递。这导致了因果强化学习的出现，它是强化学习的一个子领域，旨在通过将因果关系纳入学习过程来增强现有算法。在这篇综述中，我们全面回顾了有关因果强化学习的文献。

    Reinforcement learning is an essential paradigm for solving sequential decision problems under uncertainty. Despite many remarkable achievements in recent decades, applying reinforcement learning methods in the real world remains challenging. One of the main obstacles is that reinforcement learning agents lack a fundamental understanding of the world and must therefore learn from scratch through numerous trial-and-error interactions. They may also face challenges in providing explanations for their decisions and generalizing the acquired knowledge. Causality, however, offers a notable advantage as it can formalize knowledge in a systematic manner and leverage invariance for effective knowledge transfer. This has led to the emergence of causal reinforcement learning, a subfield of reinforcement learning that seeks to enhance existing algorithms by incorporating causal relationships into the learning process. In this survey, we comprehensively review the literature on causal reinforcemen
    
[^41]: 将实验数据与观测数据结合的双机器学习方法

    A Double Machine Learning Approach to Combining Experimental and Observational Data. (arXiv:2307.01449v1 [stat.ME])

    [http://arxiv.org/abs/2307.01449](http://arxiv.org/abs/2307.01449)

    这种双机器学习方法将实验和观测研究结合起来，能够测试假设的违反情况并一致估计处理效应。它提供了半参数高效的处理效应估计器。这种方法在实际环境中是可行的。

    

    实验和观测研究通常由于无法测试的假设而缺乏有效性。我们提出了一种双机器学习方法，将实验和观测研究结合起来，使从业人员能够测试假设违反情况并一致估计处理效应。我们的框架在较轻的假设下测试外部效度和可忽视性的违反情况。当只有一个假设被违反时，我们提供半参数高效的处理效应估计器。然而，我们的无免费午餐定理强调了准确识别违反的假设对一致的处理效应估计的必要性。我们通过三个实际案例研究展示了我们方法的适用性，并突出了其在实际环境中的相关性。

    Experimental and observational studies often lack validity due to untestable assumptions. We propose a double machine learning approach to combine experimental and observational studies, allowing practitioners to test for assumption violations and estimate treatment effects consistently. Our framework tests for violations of external validity and ignorability under milder assumptions. When only one assumption is violated, we provide semi-parametrically efficient treatment effect estimators. However, our no-free-lunch theorem highlights the necessity of accurately identifying the violated assumption for consistent treatment effect estimation. We demonstrate the applicability of our approach in three real-world case studies, highlighting its relevance for practical settings.
    
[^42]: 无监督特征学习与新兴数据驱动的典型性

    Unsupervised Feature Learning with Emergent Data-Driven Prototypicality. (arXiv:2307.01421v1 [cs.CV])

    [http://arxiv.org/abs/2307.01421](http://arxiv.org/abs/2307.01421)

    本文提出了在无监督的情况下，利用双曲空间进行特征学习的方法，其中图像之间的距离仍然表示其相似度，而位置则表示其典型性。

    

    在没有任何标签的图像集中，我们的目标是训练一个模型，将每个图像映射到一个特征空间中的一个点，使得不仅接近性表示视觉相似度，而且位置直接编码了图像在数据集中的典型性。我们的关键见解是在双曲空间而不是欧几里德空间中进行无监督特征学习，其中点之间的距离仍然反映图像的相似度，但我们在位置上增加了表示典型性的能力：它离原点越近，就越典型。后一属性仅仅是从优化通常的度量学习目标中得到的：与许多训练实例相似的图像最好放置在欧几里德空间中相应点的中心位置，但在双曲空间中更靠近原点。我们提出了一种在双曲空间中利用球体密集编码（sphere pACKing）的无监督特征学习算法。

    Given an image set without any labels, our goal is to train a model that maps each image to a point in a feature space such that, not only proximity indicates visual similarity, but where it is located directly encodes how prototypical the image is according to the dataset.  Our key insight is to perform unsupervised feature learning in hyperbolic instead of Euclidean space, where the distance between points still reflect image similarity, and yet we gain additional capacity for representing prototypicality with the location of the point: The closer it is to the origin, the more prototypical it is. The latter property is simply emergent from optimizing the usual metric learning objective: The image similar to many training instances is best placed at the center of corresponding points in Euclidean space, but closer to the origin in hyperbolic space.  We propose an unsupervised feature learning algorithm in Hyperbolic space with sphere pACKing. HACK first generates uniformly packed part
    
[^43]: 学习使用对比学习进行通信

    Learning to Communicate using Contrastive Learning. (arXiv:2307.01403v1 [cs.AI])

    [http://arxiv.org/abs/2307.01403](http://arxiv.org/abs/2307.01403)

    本研究提出了一种使用对比学习进行通信的方法，在分散的环境中通过最大化反映发送和接收消息关系的互信息来学习通信。在通信关键的环境中，我们的方法在性能和学习速度方面优于先前的工作，并且能够捕获全局状态信息，实现了更对称的通信。

    

    通信是多智能体强化学习中协调的有力工具。但在分散的环境中诱导一个有效的共同语言是一个困难的挑战。在这项工作中，我们引入了一个替代视角，即将智能体之间发送的通信消息视为环境状态的不完整视图。通过检查发送和接收的消息之间的关系，我们提出使用对比学习来最大化给定轨迹的消息之间的互信息来学习通信。在通信关键的环境中，我们的方法在性能和学习速度方面优于先前的工作。使用定性指标和表示探测，我们展示了我们的方法诱导了更对称的通信并从环境中捕获了全局状态信息。总体而言，我们展示了对比学习的力量以及利用消息作为编码实现有效通信的重要性。

    Communication is a powerful tool for coordination in multi-agent RL. But inducing an effective, common language is a difficult challenge, particularly in the decentralized setting. In this work, we introduce an alternative perspective where communicative messages sent between agents are considered as different incomplete views of the environment state. By examining the relationship between messages sent and received, we propose to learn to communicate using contrastive learning to maximize the mutual information between messages of a given trajectory. In communication-essential environments, our method outperforms previous work in both performance and learning speed. Using qualitative metrics and representation probing, we show that our method induces more symmetric communication and captures global state information from the environment. Overall, we show the power of contrastive learning and the importance of leveraging messages as encodings for effective communication.
    
[^44]: 面向高性能数据框的并行处理模式的深入分析

    In-depth Analysis On Parallel Processing Patterns for High-Performance Dataframes. (arXiv:2307.01394v1 [cs.DC])

    [http://arxiv.org/abs/2307.01394](http://arxiv.org/abs/2307.01394)

    本论文通过从高性能计算的角度出发，对面向高性能数据框的并行处理模式进行了深入分析，并指出当前最广泛使用的串行数据框在处理中等规模的数据集时存在性能限制，提出改进的空间。

    

    在过去的十年中，由于大数据革命，数据科学领域在研究和工业界都得到了巨大的扩展。人工智能（AI）和机器学习（ML）给数据工程应用带来了更多的复杂性，这些应用现在被集成到数据处理管道中以处理大量的数据。通常，在这些管道中花费大量时间进行数据预处理，因此提高其效率直接影响整体管道的性能。近年来，社区已经接受了数据框作为事实上的数据表示和操作的数据结构的概念。然而，目前最广泛使用的串行数据框（R、pandas）在处理中等规模的数据集时存在性能限制。我们相信从高性能计算的角度出发，还有很大的提升空间来解决这个问题。

    The Data Science domain has expanded monumentally in both research and industry communities during the past decade, predominantly owing to the Big Data revolution. Artificial Intelligence (AI) and Machine Learning (ML) are bringing more complexities to data engineering applications, which are now integrated into data processing pipelines to process terabytes of data. Typically, a significant amount of time is spent on data preprocessing in these pipelines, and hence improving its e fficiency directly impacts the overall pipeline performance. The community has recently embraced the concept of Dataframes as the de-facto data structure for data representation and manipulation. However, the most widely used serial Dataframes today (R, pandas) experience performance limitations while working on even moderately large data sets. We believe that there is plenty of room for improvement by taking a look at this problem from a high-performance computing point of view. In a prior publication, we p
    
[^45]: 利用阈值和Mask R-CNN算法的深度视频数据预测奶牛长期体重

    Depth video data-enabled predictions of longitudinal dairy cow body weight using thresholding and Mask R-CNN algorithms. (arXiv:2307.01383v1 [cs.CV])

    [http://arxiv.org/abs/2307.01383](http://arxiv.org/abs/2307.01383)

    该研究利用深度视频数据预测了奶牛的长期体重，并比较了阈值和Mask R-CNN深度学习方法的性能，证实了基于视频的体重预测的有效性，并促进了动物科学界的开放科学。

    

    监测奶牛体重对于支持农场管理决策至关重要，因为它与奶牛的生长、营养状况和健康直接相关。然而，绝大多数先前的体重预测研究只使用了在单一时间点采集的数据。此外，基于深度学习的视频分割在体重预测方面的效用尚未得到解答。因此，本研究的目标是从反复测量的视频数据中预测奶牛体重，比较阈值和Mask R-CNN深度学习方法的性能，评估体重回归模型的预测能力，并通过公开发布基于视频的体重预测的源代码，在动物科学界推广开放科学。共获得10头泌乳荷斯坦牛和2头非泌乳泽西牛的40,405个深度图像和深度图文件。

    Monitoring cow body weight is crucial to support farm management decisions due to its direct relationship with the growth, nutritional status, and health of dairy cows. Cow body weight is a repeated trait, however, the majority of previous body weight prediction research only used data collected at a single point in time. Furthermore, the utility of deep learning-based segmentation for body weight prediction using videos remains unanswered. Therefore, the objectives of this study were to predict cow body weight from repeatedly measured video data, to compare the performance of the thresholding and Mask R-CNN deep learning approaches, to evaluate the predictive ability of body weight regression models, and to promote open science in the animal science community by releasing the source code for video-based body weight prediction. A total of 40,405 depth images and depth map files were obtained from 10 lactating Holstein cows and 2 non-lactating Jersey cows. Three approaches were investig
    
[^46]: 将关注点转移到相关性上: 探索大型语言模型的不确定性估计

    Shifting Attention to Relevance: Towards the Uncertainty Estimation of Large Language Models. (arXiv:2307.01379v1 [cs.CL])

    [http://arxiv.org/abs/2307.01379](http://arxiv.org/abs/2307.01379)

    本论文研究了大型语言模型（LLMs）自动生成的关键词不平等问题，发现在估计不确定性时，重要的令牌和含有有限语义的句子被同等或更加重视。为了解决这个问题，提出了共同转移关注点来更好地估计不确定性。

    

    虽然大型语言模型（LLMs）在自然语言生成方面表现出了巨大的潜力，但是对于模型生成的不确定性的特征化仍然具有挑战性，即用户何时可以信任模型的输出。我们的研究基于一些启发性的事实，即在自回归的LLMs中，令牌在反映生成的含义方面是不平等的，即一些令牌比其他令牌更相关（或更具代表性），然而在估计不确定性时所有的令牌被等值对待。这是由于语言冗余，其中大部分情况下，只需要几个关键词就足以传达一个长句的含义。我们将这些不平等称为生成的不平等，并研究它们如何影响不确定性的估计。我们的结果揭示，相当数量的令牌和包含有限语义的句子，在估计不确定性时被同等或甚至更加重视。为了解决由生成的不平等引起的这些偏差，我们提出了共同转移关注点来更好地估计不确定性。

    Although Large Language Models (LLMs) have shown great potential in Natural Language Generation, it is still challenging to characterize the uncertainty of model generations, i.e., when users could trust model outputs. Our research is derived from the heuristic facts that tokens are created unequally in reflecting the meaning of generations by auto-regressive LLMs, i.e., some tokens are more relevant (or representative) than others, yet all the tokens are equally valued when estimating uncertainty. It is because of the linguistic redundancy where mostly a few keywords are sufficient to convey the meaning of a long sentence. We name these inequalities as generative inequalities and investigate how they affect uncertainty estimation. Our results reveal that considerable tokens and sentences containing limited semantics are weighted equally or even heavily when estimating uncertainty. To tackle these biases posed by generative inequalities, we propose to jointly Shifting Attention to more
    
[^47]: 使用Sentinel-1 SAR和Sentinel-2 MSI时间序列的CNN回归模型估计建筑物高度图

    A CNN regression model to estimate buildings height maps using Sentinel-1 SAR and Sentinel-2 MSI time series. (arXiv:2307.01378v1 [cs.CV])

    [http://arxiv.org/abs/2307.01378](http://arxiv.org/abs/2307.01378)

    本研究提出了一种使用Sentinel-1 SAR和Sentinel-2 MSI时间序列的CNN回归模型，能够准确估计建筑物的高度，并在荷兰的10个城市进行了测试。

    

    准确估计建筑物高度对于城市规划、基础设施管理和环境分析至关重要。在本研究中，我们提出了一种监督式多模态建筑物高度回归网络（MBHR-Net），用于使用Sentinel-1（S1）和Sentinel-2（S2）卫星时间序列估计10m空间分辨率的建筑物高度。S1提供合成孔径雷达（SAR）数据，对建筑结构提供了有价值的信息，而S2提供了对不同土地覆盖类型、植被季节性和建筑阴影敏感的多光谱数据。我们的MBHR-Net旨在从S1和S2图像中提取有意义的特征，学习图像模式与建筑物高度之间的复杂时空关系。该模型在荷兰的10个城市进行训练和测试。采用均方根误差（RMSE）、交并比（IOU）和R平方（R2）分数指标评估模型的性能。初步结果显示（3.73m RMSE, 0.）

    Accurate estimation of building heights is essential for urban planning, infrastructure management, and environmental analysis. In this study, we propose a supervised Multimodal Building Height Regression Network (MBHR-Net) for estimating building heights at 10m spatial resolution using Sentinel-1 (S1) and Sentinel-2 (S2) satellite time series. S1 provides Synthetic Aperture Radar (SAR) data that offers valuable information on building structures, while S2 provides multispectral data that is sensitive to different land cover types, vegetation phenology, and building shadows. Our MBHR-Net aims to extract meaningful features from the S1 and S2 images to learn complex spatio-temporal relationships between image patterns and building heights. The model is trained and tested in 10 cities in the Netherlands. Root Mean Squared Error (RMSE), Intersection over Union (IOU), and R-squared (R2) score metrics are used to evaluate the performance of the model. The preliminary results (3.73m RMSE, 0.
    
[^48]: 感知系统的安全要求的高效确定

    Efficient Determination of Safety Requirements for Perception Systems. (arXiv:2307.01371v1 [cs.RO])

    [http://arxiv.org/abs/2307.01371](http://arxiv.org/abs/2307.01371)

    本研究提出了一种高效确定感知系统安全要求的方法，并且在视觉飞行器避碰问题上的实验结果表明了该方法在精度和效率方面的改进。

    

    感知系统作为整体自主栈的一个子组件运行，感知系统设计者常常需要在维护整体闭环系统的安全性的同时优化性能特性。因此，将高层安全要求化简为感知系统的组件级要求是非常有用的。在这项工作中，我们专注于在给定完全集成的闭环系统的黑盒模拟器的情况下，高效地确定一组安全的感知系统性能特性。我们结合了常见的黑盒估计技术（如高斯过程和阈值贝叶斯）的优点，开发了一种新的估计方法，称为平滑贝叶斯。我们在基于视觉的飞行器避碰问题上演示了我们的方法，并展示了与高斯过程和阈值贝叶斯基线相比，精度和效率上的改进。

    Perception systems operate as a subcomponent of the general autonomy stack, and perception system designers often need to optimize performance characteristics while maintaining safety with respect to the overall closed-loop system. For this reason, it is useful to distill high-level safety requirements into component-level requirements on the perception system. In this work, we focus on efficiently determining sets of safe perception system performance characteristics given a black-box simulator of the fully-integrated, closed-loop system. We combine the advantages of common black-box estimation techniques such as Gaussian processes and threshold bandits to develop a new estimation method, which we call smoothing bandits. We demonstrate our method on a vision-based aircraft collision avoidance problem and show improvements in terms of both accuracy and efficiency over the Gaussian process and threshold bandit baselines.
    
[^49]: 移动边缘计算系统中最小化信息时延：一种嵌套索引方法

    Minimizing Age of Information for Mobile Edge Computing Systems: A Nested Index Approach. (arXiv:2307.01366v1 [cs.AI])

    [http://arxiv.org/abs/2307.01366](http://arxiv.org/abs/2307.01366)

    该论文提出了一种嵌套索引框架及策略，用于最小化移动边缘计算系统中多用户的信息时延，并利用信息时延(AoI)指标评估信息新鲜度。

    

    利用移动设备和边缘节点的计算异构性，移动边缘计算(MEC)提供了一种有效的方法来实现对信息新鲜度敏感的实时应用，通过将任务从移动设备转移到边缘节点。我们使用信息时延(AoI)指标来评估信息新鲜度。由于随机的计算时间，要找到最小化MEC系统中多个用户的AoI的有效解决方案并不容易。在本文中，我们考虑多个用户将任务从异构的边缘服务器转移到MEC系统中。我们首先将问题重新定义为一个不安全多臂赌博机(RMAB)问题，并建立一个层次化的马尔可夫决策过程(MDP)来描述MEC系统的AoI的更新。基于层次化MDP，我们提出了一个嵌套索引框架，并设计了一个具有可证明渐进优化性能的嵌套索引策略。最后，得到了嵌套索引的闭合形式，从而使得

    Exploiting the computational heterogeneity of mobile devices and edge nodes, mobile edge computation (MEC) provides an efficient approach to achieving real-time applications that are sensitive to information freshness, by offloading tasks from mobile devices to edge nodes. We use the metric Age-of-Information (AoI) to evaluate information freshness. An efficient solution to minimize the AoI for the MEC system with multiple users is non-trivial to obtain due to the random computing time. In this paper, we consider multiple users offloading tasks to heterogeneous edge servers in a MEC system. We first reformulate the problem as a Restless Multi-Arm-Bandit (RMAB) problem and establish a hierarchical Markov Decision Process (MDP) to characterize the updating of AoI for the MEC system. Based on the hierarchical MDP, we propose a nested index framework and design a nested index policy with provably asymptotic optimality. Finally, the closed form of the nested index is obtained, which enables
    
[^50]: 用神经符号深度强化学习方法实现安全自主驾驶策略的研究

    Towards Safe Autonomous Driving Policies using a Neuro-Symbolic Deep Reinforcement Learning Approach. (arXiv:2307.01316v1 [cs.RO])

    [http://arxiv.org/abs/2307.01316](http://arxiv.org/abs/2307.01316)

    本文介绍了一种名为DRL with Symbolic Logics (DRLSL)的新颖神经符号无模型深度强化学习方法，旨在实现在真实环境中安全学习自主驾驶策略。该方法结合了深度强化学习和符号逻辑驱动的推理，允许通过与物理环境的实时交互来学习自主驾驶策略并确保安全性。

    

    自主驾驶中的动态驾驶环境和多样化道路使用者的存在给决策造成了巨大的挑战。深度强化学习(DRL)已成为解决这一问题的一种流行方法。然而，由于安全问题的限制，现有的DRL解决方案的应用主要局限于模拟环境，阻碍了它们在现实世界中的部署。为了克服这一局限，本文引入了一种新颖的神经符号无模型深度强化学习方法，称为带有符号逻辑的DRL(DRLSL)，它将DRL(从经验中学习)和符号一阶逻辑知识驱动的推理相结合，以实现在实际环境下安全学习自主驾驶的实时交互。这种创新的方法提供了一种通过积极与物理环境互动来学习自主驾驶政策并确保安全性的方式。我们使用高维度数据实现了自主驾驶的DRLSL框架。

    The dynamic nature of driving environments and the presence of diverse road users pose significant challenges for decision-making in autonomous driving. Deep reinforcement learning (DRL) has emerged as a popular approach to tackle this problem. However, the application of existing DRL solutions is mainly confined to simulated environments due to safety concerns, impeding their deployment in real-world. To overcome this limitation, this paper introduces a novel neuro-symbolic model-free DRL approach, called DRL with Symbolic Logics (DRLSL) that combines the strengths of DRL (learning from experience) and symbolic first-order logics knowledge-driven reasoning) to enable safe learning in real-time interactions of autonomous driving within real environments. This innovative approach provides a means to learn autonomous driving policies by actively engaging with the physical environment while ensuring safety. We have implemented the DRLSL framework in autonomous driving using the highD data
    
[^51]: 通过基于混合Actor-Critic神经结构的自整定PID控制器，实现四旋翼飞行器控制

    Self-Tuning PID Control via a Hybrid Actor-Critic-Based Neural Structure for Quadcopter Control. (arXiv:2307.01312v1 [eess.SY])

    [http://arxiv.org/abs/2307.01312](http://arxiv.org/abs/2307.01312)

    本研究提出了一种基于混合Actor-Critic神经结构的自整定PID控制器，用于四旋翼飞行器的姿态和高度控制，通过强化学习的方法调整PID增益，提高了系统的稳健性和可靠性。

    

    比例积分微分（PID）控制器被广泛应用于工业和实验过程中，现有的离线方法可以用于调整PID增益。然而，由于模型参数的不确定性和外部干扰的存在，实际系统（如四旋翼飞行器）需要更稳健可靠的PID控制器。本研究探讨了一种使用强化学习的神经网络来实现四旋翼飞行器姿态和高度控制的自整定PID控制器。采用了增量式PID控制器，并仅对可变增益进行了调整。为了调整动态增益，使用了一种基于模型的无模型Actor-Critic混合神经结构，能够适当调整PID增益，同时充当最佳识别器。在调整和识别任务中，使用了一个具有两个隐藏层和Sigmoid激活函数的神经网络，并利用自适应动量（ADAM）优化器和反向传播算法进行学习。

    Proportional-Integrator-Derivative (PID) controller is used in a wide range of industrial and experimental processes. There are a couple of offline methods for tuning PID gains. However, due to the uncertainty of model parameters and external disturbances, real systems such as Quadrotors need more robust and reliable PID controllers. In this research, a self-tuning PID controller using a Reinforcement-Learning-based Neural Network for attitude and altitude control of a Quadrotor has been investigated. An Incremental PID, which contains static and dynamic gains, has been considered and only the variable gains have been tuned. To tune dynamic gains, a model-free actor-critic-based hybrid neural structure was used that was able to properly tune PID gains, and also has done the best as an identifier. In both tunning and identification tasks, a Neural Network with two hidden layers and sigmoid activation functions has been learned using Adaptive Momentum (ADAM) optimizer and Back-Propagatio
    
[^52]: 可靠的人工智能：下一代是否需要量子计算？

    Reliable AI: Does the Next Generation Require Quantum Computing?. (arXiv:2307.01301v1 [cs.AI])

    [http://arxiv.org/abs/2307.01301](http://arxiv.org/abs/2307.01301)

    这项调查研究了下一代人工智能是否需要量子计算，发现数字硬件无法完全解决可靠性问题。

    

    在这项调查中，我们旨在探讨一个基本问题，即下一代人工智能是否需要量子计算。人工智能在我们日常生活的许多方面都起着重要作用，并且是第四次工业革命的核心。因此，人工智能的可靠性和值得信赖性是至关重要的。然而，人工智能的可靠性仍然存在许多问题，例如隐私、责任、安全等，在自动驾驶、医疗保健、机器人等领域都存在着。这些问题可能有各种原因，包括数据不足、偏见、鲁棒性问题，以及基本的计算问题，如数字硬件上的可计算性问题。这些可计算性问题的根源在于数字硬件基于图灵机的计算模型，该模型本质上是离散的。值得注意的是，我们的研究结果表明，数字硬件无法完全解决这些问题。

    In this survey, we aim to explore the fundamental question of whether the next generation of artificial intelligence requires quantum computing. Artificial intelligence is increasingly playing a crucial role in many aspects of our daily lives and is central to the fourth industrial revolution. It is therefore imperative that artificial intelligence is reliable and trustworthy. However, there are still many issues with reliability of artificial intelligence, such as privacy, responsibility, safety, and security, in areas such as autonomous driving, healthcare, robotics, and others. These problems can have various causes, including insufficient data, biases, and robustness problems, as well as fundamental issues such as computability problems on digital hardware. The cause of these computability problems is rooted in the fact that digital hardware is based on the computing model of the Turing machine, which is inherently discrete. Notably, our findings demonstrate that digital hardware i
    
[^53]: Pareto-安全的机器学习（PSML）：指纹和保护推断服务系统。

    Pareto-Secure Machine Learning (PSML): Fingerprinting and Securing Inference Serving Systems. (arXiv:2307.01292v1 [cs.CR])

    [http://arxiv.org/abs/2307.01292](http://arxiv.org/abs/2307.01292)

    本论文研究了模型服务系统的安全性，通过引入一个查询高效的指纹算法，使得攻击者能够一致地触发任何想要的模型，从而增强了对模型提取攻击的鲁棒性和准确性。

    

    随着大型基础模型的出现，模型服务系统越来越受欢迎。在这样的系统中，用户将查询发送到服务器，并指定所需的性能指标（例如准确性、延迟等）。服务器在后端维护一组模型（模型库），并根据指定的指标提供查询服务。本文研究了这些系统的安全性，特别是对模型提取攻击的鲁棒性。现有的黑盒攻击不能直接应用于提取受害模型，因为模型隐藏在推理服务接口背后的模型库中，攻击者无法确定使用的是哪个模型。需要一个中间步骤来确保每个输入查询都能得到受害模型的输出。为此，我们提出了一种查询高效的指纹算法，使攻击者能够一致地触发任何想要的模型。我们证明，通过使用我们的指纹算法，模型提取可以具有保真度和准确性。

    With the emergence of large foundational models, model-serving systems are becoming popular. In such a system, users send the queries to the server and specify the desired performance metrics (e.g., accuracy, latency, etc.). The server maintains a set of models (model zoo) in the back-end and serves the queries based on the specified metrics. This paper examines the security, specifically robustness against model extraction attacks, of such systems. Existing black-box attacks cannot be directly applied to extract a victim model, as models hide among the model zoo behind the inference serving interface, and attackers cannot identify which model is being used. An intermediate step is required to ensure that every input query gets the output from the victim model. To this end, we propose a query-efficient fingerprinting algorithm to enable the attacker to trigger any desired model consistently. We show that by using our fingerprinting algorithm, model extraction can have fidelity and accu
    
[^54]: 用共识方式解决可解释机器学习中的分歧问题

    Fighting the disagreement in Explainable Machine Learning with consensus. (arXiv:2307.01288v1 [cs.LG])

    [http://arxiv.org/abs/2307.01288](http://arxiv.org/abs/2307.01288)

    这项研究评估了六种共识函数用于解释五个机器学习模型，并发现了在解释模型方面存在着分歧问题，对于解决这个问题尚需进一步研究。

    

    机器学习模型的价值通常通过其预测的准确性来评估。然而，在某些科学领域中，模型的内部工作方式与其准确性同等重要。为了理解机器学习模型的内部工作原理，解释性算法是首选。然而，尽管有多种算法可供选择，它们在解释模型方面经常存在分歧，导致相互矛盾的解释结果。为了应对这个问题，在模型被解释之后可以应用共识函数。然而，问题并没有完全解决，因为最终结果将取决于选择的共识函数和其他因素。本文评估了六种共识函数用于解释五个机器学习模型。这些模型先前在四个已知内部规则的合成数据集上进行了训练。然后，使用与模型无关的局部和全局可解释性算法对模型进行了解释。最后，进行共识处理。

    Machine learning (ML) models are often valued by the accuracy of their predictions. However, in some areas of science, the inner workings of models are as relevant as their accuracy. To understand how ML models work internally, the use of interpretability algorithms is the preferred option. Unfortunately, despite the diversity of algorithms available, they often disagree in explaining a model, leading to contradictory explanations. To cope with this issue, consensus functions can be applied once the models have been explained. Nevertheless, the problem is not completely solved because the final result will depend on the selected consensus function and other factors. In this paper, six consensus functions have been evaluated for the explanation of five ML models. The models were previously trained on four synthetic datasets whose internal rules were known in advance. The models were then explained with model-agnostic local and global interpretability algorithms. Finally, consensus was c
    
[^55]: MWPRanker: 一种基于表达相似性的数学问题检索工具

    MWPRanker: An Expression Similarity Based Math Word Problem Retriever. (arXiv:2307.01240v1 [cs.IR])

    [http://arxiv.org/abs/2307.01240](http://arxiv.org/abs/2307.01240)

    提出了一种基于表达相似性的数学问题检索工具MWPRanker，该工具能够检索具有相同问题模型的数学问题，包括算术和逻辑序列。

    

    在在线评估中，数学问题（MWPs）帮助测试学习者通过解释其中的语言信息来进行关键推理能力的测试。为了测试学习者的数学推理能力，有时会重新表述问题或更改原始MWP的主题设置。由于手动识别具有相似问题模型的MWPs很麻烦，因此我们在这项工作中提出了一个为MWP检索提供工具。我们提出了一种混合方法来检索具有相同问题模型的类似MWPs。在我们的工作中，问题模型是指要执行的操作序列以达到解决方案。我们证明了我们的工具对所述任务非常有用，并优于基于语义相似度的方法，后者无法捕捉MWPs的算术和逻辑顺序。可以在https://www.youtube.com/watch?v=gSQWP3chFIs找到该工具的演示。

    Math Word Problems (MWPs) in online assessments help test the ability of the learner to make critical inferences by interpreting the linguistic information in them. To test the mathematical reasoning capabilities of the learners, sometimes the problem is rephrased or the thematic setting of the original MWP is changed. Since manual identification of MWPs with similar problem models is cumbersome, we propose a tool in this work for MWP retrieval. We propose a hybrid approach to retrieve similar MWPs with the same problem model. In our work, the problem model refers to the sequence of operations to be performed to arrive at the solution. We demonstrate that our tool is useful for the mentioned tasks and better than semantic similarity-based approaches, which fail to capture the arithmetic and logical sequence of the MWPs. A demo of the tool can be found at https://www.youtube.com/watch?v=gSQWP3chFIs
    
[^56]: 用结构化语法演化学习差分方程用于餐后血糖预测

    Learning Difference Equations with Structured Grammatical Evolution for Postprandial Glycaemia Prediction. (arXiv:2307.01238v1 [cs.LG])

    [http://arxiv.org/abs/2307.01238](http://arxiv.org/abs/2307.01238)

    本研究提出了一种用于餐后血糖预测的新方法，通过结构化语法演化学习差分方程，并结合聚类分析提供可解释性强的预测模型。

    

    糖尿病患者必须密切监测他们的血糖水平，尤其是进餐后。血糖调节需要正确组合的食物摄入和胰岛素注射。血糖预测对于避免治疗糖尿病患者餐后并发症非常重要。虽然传统的方法，如人工神经网络，显示出很高的准确率，但由于其缺乏可解释性，有时不适用于医生开发个性化治疗。在本研究中，我们提出了一种强调可解释性的新型血糖预测方法：可解释稀疏识别通过语法演化。结合先前的聚类阶段，我们的方法提供了有限差分方程来预测餐后两小时内的血糖水平。我们将数据集分为四小时的段，根据进餐前两小时的血糖值进行聚类。预测模型被训练。

    People with diabetes must carefully monitor their blood glucose levels, especially after eating. Blood glucose regulation requires a proper combination of food intake and insulin boluses. Glucose prediction is vital to avoid dangerous post-meal complications in treating individuals with diabetes. Although traditional methods, such as artificial neural networks, have shown high accuracy rates, sometimes they are not suitable for developing personalised treatments by physicians due to their lack of interpretability. In this study, we propose a novel glucose prediction method emphasising interpretability: Interpretable Sparse Identification by Grammatical Evolution. Combined with a previous clustering stage, our approach provides finite difference equations to predict postprandial glucose levels up to two hours after meals. We divide the dataset into four-hour segments and perform clustering based on blood glucose values for the twohour window before the meal. Prediction models are traine
    
[^57]: 通过多任务学习实现物联网故障检测和分类

    Internet of Things Fault Detection and Classification via Multitask Learning. (arXiv:2307.01234v1 [cs.LG])

    [http://arxiv.org/abs/2307.01234](http://arxiv.org/abs/2307.01234)

    本文通过多任务学习实现了物联网故障检测和分类系统，并在真实数据上展示了优越的性能，相较于现有技术，在特异性、精确度、召回率和F1值等方面均有显著改进。

    

    本文针对实际工业物联网应用开发了一个全面的故障检测和分类系统进行了深入研究。研究解决了数据收集、标注、算法开发和部署方面的挑战。通过使用一个真实的工业物联网系统，我们对11个预定义的故障类别进行了三个阶段的数据收集模拟。我们提出了SMTCNN用于工业物联网中的故障检测和分类，评估其在真实数据上的性能。与现有技术相比，SMTCNN在特异性（3.5%）方面取得了卓越的效果，并且在精确度、召回率和F1值方面显示出显著改进。

    This paper presents a comprehensive investigation into developing a fault detection and classification system for real-world IIoT applications. The study addresses challenges in data collection, annotation, algorithm development, and deployment. Using a real-world IIoT system, three phases of data collection simulate 11 predefined fault categories. We propose SMTCNN for fault detection and category classification in IIoT, evaluating its performance on real-world data. SMTCNN achieves superior specificity (3.5%) and shows significant improvements in precision, recall, and F1 measures compared to existing techniques.
    
[^58]: 对(深度)学习匹配算法的基准数据集的关键重新评估

    A Critical Re-evaluation of Benchmark Datasets for (Deep) Learning-Based Matching Algorithms. (arXiv:2307.01231v1 [cs.DB])

    [http://arxiv.org/abs/2307.01231](http://arxiv.org/abs/2307.01231)

    本研究重新评估了(深度)学习匹配算法的基准数据集，发现其中大多数数据集都属于相对简单的分类任务。

    

    实体解析(ER)是识别在一个或多个数据库中指向相同实体的记录的过程。多年来，已经开发了许多技术来解决ER挑战，近年来，机器学习和深度学习方法在匹配阶段受到了重视。然而，在文献中尚未对实验评估中常用的学习匹配算法的基准数据集的质量进行检查。为了弥补这个空白，我们提出了四种不同的方法来评估13个已建立数据集的难度和适用性：两种理论方法，涉及新的线性度量和现有的复杂度度量，以及两种实际方法：最佳非线性和线性匹配器之间的差异，以及最佳学习匹配器和完美预测器之间的差异。我们的分析表明，大多数流行数据集都提出了相当简单的分类任务。

    Entity resolution (ER) is the process of identifying records that refer to the same entities within one or across multiple databases. Numerous techniques have been developed to tackle ER challenges over the years, with recent emphasis placed on machine and deep learning methods for the matching phase. However, the quality of the benchmark datasets typically used in the experimental evaluations of learning-based matching algorithms has not been examined in the literature. To cover this gap, we propose four different approaches to assessing the difficulty and appropriateness of 13 established datasets: two theoretical approaches, which involve new measures of linearity and existing measures of complexity, and two practical approaches: the difference between the best non-linear and linear matchers, as well as the difference between the best learning-based matcher and the perfect oracle. Our analysis demonstrates that most of the popular datasets pose rather easy classification tasks. As a
    
[^59]: EmoGen: 消除情感音乐生成中的主观偏差

    EmoGen: Eliminating Subjective Bias in Emotional Music Generation. (arXiv:2307.01229v1 [cs.SD])

    [http://arxiv.org/abs/2307.01229](http://arxiv.org/abs/2307.01229)

    EmoGen是一种消除情感音乐生成中主观偏差的系统，通过利用与情感相关的音乐属性作为桥梁，将生成分为情感到属性的映射以及属性到音乐的生成两个阶段，并在学习过程中消除主观偏差，实现生成具有普遍情感的音乐。

    

    音乐用于传达情感，因此在自动生成音乐时生成情感音乐非常重要。之前关于情感音乐生成的工作直接使用标注的情感标签作为控制信号，但存在主观偏差：不同的人可能会在同样的音乐上标注不同的情感，同一个人在不同情境下也可能感受到不同的情感。因此，直接将情感标签映射到音乐序列中会混淆学习过程，并阻碍模型生成具有普遍情感的音乐。本文提出了EmoGen，一种情感音乐生成系统，它利用一组与情感相关的音乐属性作为情感和音乐之间的桥梁，并将生成分为两个阶段：基于监督聚类的情感到属性映射以及基于自监督学习的属性到音乐生成。这两个阶段都是有益的：在第一个阶段，聚类周围的属性值有助于消除主观偏差，第二个阶段则实现了音乐的生成。

    Music is used to convey emotions, and thus generating emotional music is important in automatic music generation. Previous work on emotional music generation directly uses annotated emotion labels as control signals, which suffers from subjective bias: different people may annotate different emotions on the same music, and one person may feel different emotions under different situations. Therefore, directly mapping emotion labels to music sequences in an end-to-end way would confuse the learning process and hinder the model from generating music with general emotions. In this paper, we propose EmoGen, an emotional music generation system that leverages a set of emotion-related music attributes as the bridge between emotion and music, and divides the generation into two stages: emotion-to-attribute mapping with supervised clustering, and attribute-to-music generation with self-supervised learning. Both stages are beneficial: in the first stage, the attribute values around the clusterin
    
[^60]: ESGCN: 边缘压缩注意图卷积网络用于交通流量预测

    ESGCN: Edge Squeeze Attention Graph Convolutional Network for Traffic Flow Forecasting. (arXiv:2307.01227v1 [cs.LG])

    [http://arxiv.org/abs/2307.01227](http://arxiv.org/abs/2307.01227)

    ESGCN是一种用于交通流量预测的边缘压缩注意图卷积网络，通过建模时空动态和引入边缘特征和边缘注意机制来提高预测的准确性。

    

    交通流量预测是一个极具挑战性的任务，由于交通流的动态时空依赖关系。为了应对这个问题，我们着重于建模时空动态并提出了一种名为Edge Squeeze Graph Convolutional Network (ESGCN)的网络来预测多个地区的交通流量。ESGCN由两个模块组成：W模块和ES模块。W模块是一个完全以节点为基础的卷积网络。它分别对每个交通区域的时间序列进行编码，并在不同尺度上分解时间序列以捕捉细粒度和粗粒度的特征。ES模块使用图卷积网络(GCN)建模时空动态，并利用时序特征生成自适应邻接矩阵(AAM)。为了提高AAM的准确性，我们引入了三个关键概念。1）使用边缘特征直接捕捉区域之间的时空流动表示。2）将边缘注意机制应用于GCN，从边缘特征中提取AAM。

    Traffic forecasting is a highly challenging task owing to the dynamical spatio-temporal dependencies of traffic flows. To handle this, we focus on modeling the spatio-temporal dynamics and propose a network termed Edge Squeeze Graph Convolutional Network (ESGCN) to forecast traffic flow in multiple regions. ESGCN consists of two modules: W-module and ES module. W-module is a fully node-wise convolutional network. It encodes the time-series of each traffic region separately and decomposes the time-series at various scales to capture fine and coarse features. The ES module models the spatio-temporal dynamics using Graph Convolutional Network (GCN) and generates an Adaptive Adjacency Matrix (AAM) with temporal features. To improve the accuracy of AAM, we introduce three key concepts. 1) Using edge features to directly capture the spatiotemporal flow representation among regions. 2) Applying an edge attention mechanism to GCN to extract the AAM from the edge features. Here, the attention m
    
[^61]: vONTSS：基于vMF和最优传输的半监督神经主题建模

    vONTSS: vMF based semi-supervised neural topic modeling with optimal transport. (arXiv:2307.01226v1 [cs.LG])

    [http://arxiv.org/abs/2307.01226](http://arxiv.org/abs/2307.01226)

    vONTSS是一种基于vMF和最优传输的半监督神经主题建模方法，它在分类准确率和多样性方面优于其他方法，并且支持无监督主题建模。实验证明，vONTSS比最近的NTM更快。

    

    最近，受变分自编码器启发的神经主题模型（NTM）引起了很多研究兴趣，然而，由于整合人类知识的挑战，这些方法在实际应用中受到了限制。本研究提出了一种半监督神经主题建模方法vONTSS，该方法利用基于von Mises-Fisher（vMF）的变分自编码器和最优传输。在半监督设置中，当提供每个主题的少量关键词时，vONTSS生成潜在主题并优化主题-关键词质量和主题分类。实验证明，vONTSS在分类准确率和多样性方面优于现有的半监督主题建模方法。vONTSS还支持无监督主题建模。定量和定性实验证明，vONTSS在无监督设置下在多个方面优于最近的NTM：vONTSS在基准数据集上发现高度聚类和连贯的主题。它也比现有-手法快得多。

    Recently, Neural Topic Models (NTM), inspired by variational autoencoders, have attracted a lot of research interest; however, these methods have limited applications in the real world due to the challenge of incorporating human knowledge. This work presents a semi-supervised neural topic modeling method, vONTSS, which uses von Mises-Fisher (vMF) based variational autoencoders and optimal transport. When a few keywords per topic are provided, vONTSS in the semi-supervised setting generates potential topics and optimizes topic-keyword quality and topic classification. Experiments show that vONTSS outperforms existing semi-supervised topic modeling methods in classification accuracy and diversity. vONTSS also supports unsupervised topic modeling. Quantitative and qualitative experiments show that vONTSS in the unsupervised setting outperforms recent NTMs on multiple aspects: vONTSS discovers highly clustered and coherent topics on benchmark datasets. It is also much faster than the state
    
[^62]: 解释性和透明性驱动的文本对抗示例的检测与转换（IT-DT）

    Interpretability and Transparency-Driven Detection and Transformation of Textual Adversarial Examples (IT-DT). (arXiv:2307.01225v1 [cs.CL])

    [http://arxiv.org/abs/2307.01225](http://arxiv.org/abs/2307.01225)

    通过提出的解释性和透明性驱动的检测与转换（IT-DT）框架，我们在检测和转换文本对抗示例方面注重解释性和透明性。这个框架利用了注意力图、集成梯度和模型反馈等技术，在检测阶段有助于识别对对抗性分类有贡献的显著特征和扰动词语，并在转换阶段使用预训练的嵌入和模型反馈来生成扰动词语的最佳替代，以将对抗性示例转换为正常示例。

    

    基于Transformer的文本分类器如BERT、Roberta、T5和GPT-3在自然语言处理方面展示了令人印象深刻的性能。然而，它们对于对抗性示例的脆弱性提出了安全风险。现有的防御方法缺乏解释性，很难理解对抗性分类并识别模型的漏洞。为了解决这个问题，我们提出了解释性和透明性驱动的检测与转换（IT-DT）框架。它专注于在检测和转换文本对抗示例时的解释性和透明性。IT-DT利用注意力图、集成梯度和模型反馈等技术进行解释性检测。这有助于识别对对抗性分类有贡献的显著特征和扰动词语。在转换阶段，IT-DT利用预训练的嵌入和模型反馈来生成扰动词语的最佳替代。通过找到合适的替换，我们的目标是将对抗性示例转换为正常示例。

    Transformer-based text classifiers like BERT, Roberta, T5, and GPT-3 have shown impressive performance in NLP. However, their vulnerability to adversarial examples poses a security risk. Existing defense methods lack interpretability, making it hard to understand adversarial classifications and identify model vulnerabilities. To address this, we propose the Interpretability and Transparency-Driven Detection and Transformation (IT-DT) framework. It focuses on interpretability and transparency in detecting and transforming textual adversarial examples. IT-DT utilizes techniques like attention maps, integrated gradients, and model feedback for interpretability during detection. This helps identify salient features and perturbed words contributing to adversarial classifications. In the transformation phase, IT-DT uses pre-trained embeddings and model feedback to generate optimal replacements for perturbed words. By finding suitable substitutions, we aim to convert adversarial examples into
    
[^63]: 推荐系统中的筛选泡沫：事实还是谬论--一项系统性回顾

    Filter Bubbles in Recommender Systems: Fact or Fallacy -- A Systematic Review. (arXiv:2307.01221v1 [cs.IR])

    [http://arxiv.org/abs/2307.01221](http://arxiv.org/abs/2307.01221)

    研究发现了推荐系统中筛选泡沫的存在，揭示了导致筛选泡沫的多种偏见，并提出了一个集成工具，帮助用户避免在推荐系统中受到筛选泡沫的影响。

    

    筛选泡沫是指互联网定制化使个体与多样的观点或材料有效隔离，导致他们只受到一组特定内容的影响。这可能导致现有态度、信念或条件的强化。在这项研究中，我们主要关注筛选泡沫在推荐系统中的影响。这项开创性的研究旨在揭示这个问题背后的原因，探索潜在的解决方案，并提出一个集成工具，帮助用户避免在推荐系统中的筛选泡沫。为了达到这个目标，我们对推荐系统中的筛选泡沫进行了系统的文献综述。对所综述的文章进行了仔细分析和分类，提供了对集成方法发展有价值的见解。值得注意的是，我们的综述揭示了推荐系统中筛选泡沫的证据，强调了几个导致其存在的偏见。

    A filter bubble refers to the phenomenon where Internet customization effectively isolates individuals from diverse opinions or materials, resulting in their exposure to only a select set of content. This can lead to the reinforcement of existing attitudes, beliefs, or conditions. In this study, our primary focus is to investigate the impact of filter bubbles in recommender systems. This pioneering research aims to uncover the reasons behind this problem, explore potential solutions, and propose an integrated tool to help users avoid filter bubbles in recommender systems. To achieve this objective, we conduct a systematic literature review on the topic of filter bubbles in recommender systems. The reviewed articles are carefully analyzed and classified, providing valuable insights that inform the development of an integrated approach. Notably, our review reveals evidence of filter bubbles in recommendation systems, highlighting several biases that contribute to their existence. Moreove
    
[^64]: FedCP:通过条件策略对个性化联邦学习中的特征信息进行分离

    FedCP: Separating Feature Information for Personalized Federated Learning via Conditional Policy. (arXiv:2307.01217v1 [cs.LG])

    [http://arxiv.org/abs/2307.01217](http://arxiv.org/abs/2307.01217)

    提出了一种名为FedCP的个性化联邦学习方法，通过生成条件策略分离特征中的全局信息和个性化信息，并分别进行处理。实验证明该方法在计算机视觉和自然语言处理领域的性能超过了十一种最先进的方法，最高可提高6.69%。

    

    最近，个性化联邦学习（pFL）在隐私保护、协作学习以及解决客户端之间的统计异质性等方面引起了越来越多的关注，例如医院、移动智能手机等。大多数现有的pFL方法侧重于利用客户端级模型参数中的全局信息和个性化信息，但忽略了数据是这两种信息的源头。为了解决这个问题，我们提出了联邦条件策略（FedCP）方法，该方法为每个样本生成一个条件策略，以分离其特征中的全局信息和个性化信息，然后分别通过全局头和个性化头进行处理。与现有的pFL方法相比，FedCP更加细粒度地考虑个性化的样本特定方式。在计算机视觉和自然语言处理领域进行的大量实验表明，FedCP在性能上超过了十一种最先进的方法，最高可提高6.69%。

    Recently, personalized federated learning (pFL) has attracted increasing attention in privacy protection, collaborative learning, and tackling statistical heterogeneity among clients, e.g., hospitals, mobile smartphones, etc. Most existing pFL methods focus on exploiting the global information and personalized information in the client-level model parameters while neglecting that data is the source of these two kinds of information. To address this, we propose the Federated Conditional Policy (FedCP) method, which generates a conditional policy for each sample to separate the global information and personalized information in its features and then processes them by a global head and a personalized head, respectively. FedCP is more fine-grained to consider personalization in a sample-specific manner than existing pFL methods. Extensive experiments in computer vision and natural language processing domains show that FedCP outperforms eleven state-of-the-art methods by up to 6.69%. Furthe
    
[^65]: 基于单词组搜索的鲁棒文本分类的自动反事实扩充

    Automatic Counterfactual Augmentation for Robust Text Classification Based on Word-Group Search. (arXiv:2307.01214v1 [cs.CL])

    [http://arxiv.org/abs/2307.01214](http://arxiv.org/abs/2307.01214)

    这篇论文提出了一种基于单词组搜索的自动反事实扩充方法，用于鲁棒文本分类。该方法通过捕捉关键字组合的因果效应，并排序最影响预测的组合，从而解决了由于只关注单个单词而导致的错误因果特征的问题。

    

    尽管大规模预训练语言模型在文本分类方面取得了显著的成果，但最近的研究对于捷径学习的挑战提出了担忧。通常情况下，如果关键字与标签产生表面关联，从而导致错误预测，那么它被视为一种捷径。相反，如果模型依赖于能够产生准确预测的鲁棒因果特征，就可以缓解捷径学习。为此，许多研究探索了事后可解释的方法来挖掘鲁棒性和泛化性的捷径和因果特征。然而，大多数现有方法只关注句子中的单个单词，忽视了单词组的考虑，导致错误的因果特征。为了解决这个问题，我们提出了一种新的单词组挖掘方法，它能够捕捉任何关键字组合的因果效应，并对最影响预测的组合进行排序。我们的方法基于有效的事后分析和波束搜索，确保了算法的准确性。

    Despite large-scale pre-trained language models have achieved striking results for text classificaion, recent work has raised concerns about the challenge of shortcut learning. In general, a keyword is regarded as a shortcut if it creates a superficial association with the label, resulting in a false prediction. Conversely, shortcut learning can be mitigated if the model relies on robust causal features that help produce sound predictions. To this end, many studies have explored post-hoc interpretable methods to mine shortcuts and causal features for robustness and generalization. However, most existing methods focus only on single word in a sentence and lack consideration of word-group, leading to wrong causal features. To solve this problem, we propose a new Word-Group mining approach, which captures the causal effect of any keyword combination and orders the combinations that most affect the prediction. Our approach bases on effective post-hoc analysis and beam search, which ensures
    
[^66]: 一个用于安全指令本体表示的自动化方法

    An automated method for the ontological representation of security directives. (arXiv:2307.01211v1 [cs.AI])

    [http://arxiv.org/abs/2307.01211](http://arxiv.org/abs/2307.01211)

    本文提出了一种将大型法律文件自动转化为本体表示的方法，通过自然语言处理技术和本体发展原则的结合，展示了在欧洲网络和信息系统安全指令上的应用。

    

    难以解释的大型法律文件，长句导致名词之间错综复杂的关系。本文将这个问题放在最近欧洲安全指令的背景下。通过对自然语言处理（NLP）技术的特定定制，自动化提取关键信息，即每个从句的词类。这些与本体发展原则相结合，设计了我们的安全指令本体表示的自动化方法。该方法在一个实际问题上展示，即推导出表示欧洲层面上网络和信息系统安全指令的本体。尽管采用的NLP技术存在一些限制，并且需要通过手动分析进行补充，但总体结果为指令提供了有效的支持。

    Large documents written in juridical language are difficult to interpret, with long sentences leading to intricate and intertwined relations between the nouns. The present paper frames this problem in the context of recent European security directives. The complexity of their language is here thwarted by automating the extraction of the relevant information, namely of the parts of speech from each clause, through a specific tailoring of Natural Language Processing (NLP) techniques. These contribute, in combination with ontology development principles, to the design of our automated method for the representation of security directives as ontologies. The method is showcased on a practical problem, namely to derive an ontology representing the NIS 2 directive, which is the peak of cybersecurity prescripts at the European level. Although the NLP techniques adopted showed some limitations and had to be complemented by manual analysis, the overall results provide valid support for directive 
    
[^67]: 人工智能和非人工智能评估老年痴呆

    AI and Non AI Assessments for Dementia. (arXiv:2307.01210v1 [q-bio.OT])

    [http://arxiv.org/abs/2307.01210](http://arxiv.org/abs/2307.01210)

    本论文总结了人工智能和非人工智能评估老年痴呆的现有解决方案，并为医生和AI工程师提供了相关的技术和数据集。

    

    当前人工智能领域的进展已经导致了各种类型的AI驱动的老年痴呆评估方法的发展，可以用于识别早期老年痴呆患者。它有可能对老年痴呆的护理模式进行革命性的改变。医疗界必须了解各种AI评估方法，并根据其在早期识别老年痴呆患者方面的准确性、效率、实用性、可靠性和准确性选择适合的方法。另一方面，AI开发人员也应了解各种非AI评估方法以及最近开发的AI评估方法。因此，本文填补了文献中对老年痴呆识别现有解决方案向医生解释的空白，同时也向AI工程师介绍了使用的技术和最普遍的老年痴呆数据集。它对医生和AI工程师都具有可读性。

    Current progress in the artificial intelligence domain has led to the development of various types of AI-powered dementia assessments, which can be employed to identify patients at the early stage of dementia. It can revolutionize the dementia care settings. It is essential that the medical community be aware of various AI assessments and choose them considering their degrees of validity, efficiency, practicality, reliability, and accuracy concerning the early identification of patients with dementia (PwD). On the other hand, AI developers should be informed about various non-AI assessments as well as recently developed AI assessments. Thus, this paper, which can be readable by both clinicians and AI engineers, fills the gap in the literature in explaining the existing solutions for the recognition of dementia to clinicians, as well as the techniques used and the most widespread dementia datasets to AI engineers. It follows a review of papers on AI and non-AI assessments for dementia t
    
[^68]: 面向知识图谱的少样本归纳链接预测：一种基于关系匿名漫步引导的神经过程方法

    Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach. (arXiv:2307.01204v1 [cs.AI])

    [http://arxiv.org/abs/2307.01204](http://arxiv.org/abs/2307.01204)

    本文提出了一种基于关系匿名漫步引导的神经过程方法，用于知识图谱上的少样本归纳链接预测。该方法利用未见实体周围的子图来获取语义并归纳地预测链接，在捕捉一般的归纳模式的同时，还能快速适应新的实体并估计预测的不确定性。

    

    知识图谱上的少样本归纳链接预测旨在用少样本的链接来预测未见实体的缺失链接。以往的方法仅限于传导场景，即在知识图谱中存在实体，因此无法处理未见实体。因此，近期的归纳方法利用未见实体周围的子图来获取语义并归纳地预测链接。然而，在少样本场景下，子图通常是稀疏的，无法提供有意义的归纳模式。本文提出了一种新颖的基于关系匿名漫步引导的神经过程，用于知识图谱上的少样本归纳链接预测，称为RawNP。具体而言，我们开发了一种基于神经过程的方法，对链接预测函数建模为灵活的分布。这使得模型能够快速适应新的实体并在进行预测时估计不确定性。为了捕捉一般的归纳模式，我们提出了一种关系匿名漫步方法。

    Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict missing links for unseen entities with few-shot links observed. Previous methods are limited to transductive scenarios, where entities exist in the knowledge graphs, so they are unable to handle unseen entities. Therefore, recent inductive methods utilize the sub-graphs around unseen entities to obtain the semantics and predict links inductively. However, in the few-shot setting, the sub-graphs are often sparse and cannot provide meaningful inductive patterns. In this paper, we propose a novel relational anonymous walk-guided neural process for few-shot inductive link prediction on knowledge graphs, denoted as RawNP. Specifically, we develop a neural process-based method to model a flexible distribution over link prediction functions. This enables the model to quickly adapt to new entities and estimate the uncertainty when making predictions. To capture general inductive patterns, we present a relational anony
    
[^69]: 预测性专利学：使用ChatGPT技术预测创新成功和估值

    Predictive Patentomics: Forecasting Innovation Success and Valuation with ChatGPT. (arXiv:2307.01202v1 [cs.LG])

    [http://arxiv.org/abs/2307.01202](http://arxiv.org/abs/2307.01202)

    本研究采用ChatGPT技术，以OpenAI的最先进的文本嵌入为基础，通过深度学习预测模型实现了对专利创新成功和估值的准确预测，为专利估值提供了革命性的改进。此外，通过预测接受率构建的多空投资组合实现了显著的异常收益率。

    

    传统方法对于创新的分析在广泛的结构变量方面存在根本性的局限性。本文通过开创性的ChatGPT技术采用LLM方法对专利进行分析，突破了边界。OpenAI的最先进的文本嵌入能够访问关于每个发明的质量和影响的复杂信息，用于驱动深度学习预测模型。细致的嵌入使预测专利价值的R-squared提高了24％，并明确地将最差和最佳应用程序分离开来。这些模型通过预测接受率构建的多空投资组合每年实现显著的异常收益率高达3.3%，同时也证明了市场无法及时整合有关应用程序的信息。这些模型为革命性改变科根、帕帕尼科洛、塞鲁和斯托夫曼（2017）对专利估值的更正提供了机会。

    Analysis of innovation has been fundamentally limited by conventional approaches to broad, structural variables. This paper pushes the boundaries, taking an LLM approach to patent analysis with the groundbreaking ChatGPT technology. OpenAI's state-of-the-art textual embedding accesses complex information about the quality and impact of each invention to power deep learning predictive models. The nuanced embedding drives a 24% incremental improvement in R-squared predicting patent value and clearly isolates the worst and best applications. These models enable a revision of the contemporary Kogan, Papanikolaou, Seru, and Stoffman (2017) valuation of patents by a median deviation of 1.5 times, accounting for potential institutional predictions. Furthermore, the market fails to incorporate timely information about applications; a long-short portfolio based on predicted acceptance rates achieves significant abnormal returns of 3.3% annually. The models provide an opportunity to revolutioniz
    
[^70]: 在上下文学习和出现中的模式学习和重新绑定机制

    Schema-learning and rebinding as mechanisms of in-context learning and emergence. (arXiv:2307.01201v1 [cs.CL])

    [http://arxiv.org/abs/2307.01201](http://arxiv.org/abs/2307.01201)

    本文研究了上下文学习的机制，发现使用克隆结构因果图可以实现与transformer-based语言模型相似的能力，并且这种方法可以解释上下文学习的工作原理。

    

    上下文学习（ICL）是近期基于Transformer的大型语言模型（LLMs）中最强大且最令人意外的能力之一。然而，它的基础机制尚不清楚。在本文中，我们证明可以通过使用克隆结构因果图（CSCGs）这种替代的序列预测学习方法获得可比较的ICL能力。此外，CSCGs的一个关键特性是，与基于Transformer的LLMs不同，它们是可解释的，这大大简化了解释ICL工作原理的任务。具体而言，我们显示它使用了以下组合：（a）学习模板（模式）电路进行模式完成，（b）以上下文敏感方式检索相关模板，以及（c）将新标记重新绑定到模板的适当位置。我们进一步提出了ICL在LLMs中采用类似机制的假设证据。例如，我们发现，与LLMs一样，使用CSCGs时会出现不同的能力。

    In-context learning (ICL) is one of the most powerful and most unexpected capabilities to emerge in recent transformer-based large language models (LLMs). Yet the mechanisms that underlie it are poorly understood. In this paper, we demonstrate that comparable ICL capabilities can be acquired by an alternative sequence prediction learning method using clone-structured causal graphs (CSCGs). Moreover, a key property of CSCGs is that, unlike transformer-based LLMs, they are {\em interpretable}, which considerably simplifies the task of explaining how ICL works. Specifically, we show that it uses a combination of (a) learning template (schema) circuits for pattern completion, (b) retrieving relevant templates in a context-sensitive manner, and (c) rebinding of novel tokens to appropriate slots in the templates. We go on to marshall evidence for the hypothesis that similar mechanisms underlie ICL in LLMs. For example, we find that, with CSCGs as with LLMs, different capabilities emerge at d
    
[^71]: SDC-HSDD-NDSA: 使用层次次级导向差异和归一化密度自适应的结构检测聚类算法

    SDC-HSDD-NDSA: Structure Detecting Cluster by Hierarchical Secondary Directed Differential with Normalized Density and Self-Adaption. (arXiv:2307.00677v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.00677](http://arxiv.org/abs/2307.00677)

    本文提出了一种基于密度的聚类算法，能够检测到高密度区域中的结构，具有先前算法所不具备的能力。

    

    基于密度的聚类算法是最受欢迎的聚类算法之一，因为它能够识别任意形状的聚类，只要不同的高密度聚类之间有低密度区域分隔。然而，通过低密度区域将聚类分隔开的要求并不是微不足道的，因为高密度区域可能具有不同的结构，应该被聚类到不同的组中。这种情况说明了我们已知的所有先前基于密度的聚类算法的主要缺陷--无法检测高密度聚类中的结构。因此，本文旨在提供一种基于密度的聚类方案，既具有先前方法的能力，又能够检测到高密度区域中未被低密度区分开的结构。该算法采用层次次级导向差异、层次化、归一化密度以及自适应系数，因此被称为结构检测聚类算法。

    Density-based clustering could be the most popular clustering algorithm since it can identify clusters of arbitrary shape as long as different (high-density) clusters are separated by low-density regions. However, the requirement of the separateness of clusters by low-density regions is not trivial since a high-density region might have different structures which should be clustered into different groups. Such a situation demonstrates the main flaw of all previous density-based clustering algorithms we have known--structures in a high-density cluster could not be detected. Therefore, this paper aims to provide a density-based clustering scheme that not only has the ability previous ones have but could also detect structures in a high-density region not separated by low-density ones. The algorithm employs secondary directed differential, hierarchy, normalized density, as well as the self-adaption coefficient, and thus is called Structure Detecting Cluster by Hierarchical Secondary Direc
    
[^72]: 基于稀疏感知的深度神经网络泛化理论

    Sparsity-aware generalization theory for deep neural networks. (arXiv:2307.00426v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.00426](http://arxiv.org/abs/2307.00426)

    本文研究了深度神经网络的泛化能力，提出了一种基于稀疏感知的分析方法。通过考虑隐藏层激活的稀疏程度，我们展示了稀疏和泛化之间的权衡，而且结果对模型的稀疏程度没有强烈的假设，并在特定情况下的数值实验中得到了非空的界限。

    

    深度人工神经网络取得了令人惊讶的泛化能力，但其具体机制尚不清楚。本文提出了一种新的方法来分析前向深度ReLU网络的泛化能力，利用隐藏层激活的稀疏程度。通过构建一个考虑每个输入样本减小有效模型大小的框架，我们能够展示出稀疏和泛化之间的根本权衡。重要的是，我们的结果对模型实现的稀疏程度没有强烈的假设，并且改进了最近的基于范数的方法。我们通过数值实例展示了结果，即使在过参数化的模型中，在特定情况下与数据相关的先验结合时也能得到非空界限。

    Deep artificial neural networks achieve surprising generalization abilities that remain poorly understood. In this paper, we present a new approach to analyzing generalization for deep feed-forward ReLU networks that takes advantage of the degree of sparsity that is achieved in the hidden layer activations. By developing a framework that accounts for this reduced effective model size for each input sample, we are able to show fundamental trade-offs between sparsity and generalization. Importantly, our results make no strong assumptions about the degree of sparsity achieved by the model, and it improves over recent norm-based approaches. We illustrate our results numerically, demonstrating non-vacuous bounds when coupled with data-dependent priors in specific settings, even in over-parametrized models.
    
[^73]: 反事实协同推理

    Counterfactual Collaborative Reasoning. (arXiv:2307.00165v1 [cs.IR])

    [http://arxiv.org/abs/2307.00165](http://arxiv.org/abs/2307.00165)

    本文提出了反事实协同推理（CCR）方法，通过整合反事实推理和逻辑推理来提高机器学习模型的准确性和可解释性。通过利用反事实推理生成困难的反事实训练样本进行数据增强，CCR在推荐系统中展示了如何缓解数据稀缺、提高准确性和增强透明度。

    

    因果推理和逻辑推理是人类智能的两种重要推理能力。然而，在机器智能背景下，它们的关系还未得到广泛探索。本文探讨了如何共同建模这两种推理能力，以提高机器学习模型的准确性和可解释性。具体而言，通过整合反事实推理和（神经）逻辑推理两种重要的推理能力，我们提出了反事实协同推理（CCR），它通过进行反事实逻辑推理来改进性能。特别是，我们以推荐系统为例，展示了CCR如何缓解数据稀缺、提高准确性和增强透明度。从技术上讲，我们利用反事实推理来生成“困难”的反事实训练样本进行数据增强，这与原始的训练样本一起可以提升模型性能。

    Causal reasoning and logical reasoning are two important types of reasoning abilities for human intelligence. However, their relationship has not been extensively explored under machine intelligence context. In this paper, we explore how the two reasoning abilities can be jointly modeled to enhance both accuracy and explainability of machine learning models. More specifically, by integrating two important types of reasoning ability -- counterfactual reasoning and (neural) logical reasoning -- we propose Counterfactual Collaborative Reasoning (CCR), which conducts counterfactual logic reasoning to improve the performance. In particular, we use recommender system as an example to show how CCR alleviate data scarcity, improve accuracy and enhance transparency. Technically, we leverage counterfactual reasoning to generate "difficult" counterfactual training examples for data augmentation, which -together with the original training examples -- can enhance the model performance. Since the 
    
[^74]: 智能冲浪者在混沌流动中的目标搜索

    Goal quest for an intelligent surfer moving in a chaotic flow. (arXiv:2307.00019v1 [physics.soc-ph] CROSS LISTED)

    [http://arxiv.org/abs/2307.00019](http://arxiv.org/abs/2307.00019)

    这篇论文提出了一个智能冲浪者的模型，通过使用Ulman网络在混沌动力学中进行搜索。使用一种新的算法，智能冲浪者能够在网络中找到最短路径，并且比尝试尽量减小与目标距离的愚蠢冲浪者更加高效。这为在混沌流动中的运动控制提供了新的方法。

    

    我们考虑了一个模型，其中智能冲浪者在由Chirikov标准映射中的混沌动力学生成的Ulam网络上移动。该有向网络是通过Ulam方法获得的，利用固定大小的相空间单元形成马尔可夫链的节点。该冲浪者的目标是确定从初始节点A到最终节点B的网络路径，其阻力最小，即转移概率的倒数之和最小。我们开发了一种算法，使智能冲浪者能够在少量的转移中完成搜索，其数量仅以网络大小的对数增长。最优路径搜索在具有正向和逆向网络的小Erd\"os数节点形成的分形交集集合上进行。智能冲浪者在尽量减小与目标B的相空间距离的愚蠢冲浪者上呈指数级优势。我们认为，这种算法为在混沌流动中进行运动控制提供了新的线索。

    We consider a model of an intelligent surfer moving on the Ulam network generated by a chaotic dynamics in the Chirikov standard map. This directed network is obtained by the Ulam method with a division of the phase space in cells of fixed size forming the nodes of a Markov chain. The goal quest for this surfer is to determine the network path from an initial node A to a final node B with minimal resistance given by the sum of inverse transition probabilities. We develop an algorithm for the intelligent surfer that allows to perform the quest in a small number of transitions which grows only logarithmically with the network size. The optimal path search is done on a fractal intersection set formed by nodes with small Erd\"os numbers of the forward and inverted networks. The intelligent surfer exponentially outperforms a naive surfer who tries to minimize its phase space distance to the target B. We argue that such an algorithm provides new hints for motion control in chaotic flows.
    
[^75]: 歧视性或撒马利亚式 -- 人类需要哪种人工智能？混合人工智能人口的进化博弈论分析

    Discriminatory or Samaritan -- which AI is needed for humanity? An Evolutionary Game Theory Analysis of Hybrid Human-AI populations. (arXiv:2306.17747v1 [cs.MA])

    [http://arxiv.org/abs/2306.17747](http://arxiv.org/abs/2306.17747)

    这项研究通过进化博弈理论的分析发现，相比于只帮助符合条件的人的歧视性人工智能，撒马利亚式人工智能可以更好地促进人类间的合作。这对于缓慢发展的社会尤为重要，因为在这种社会中，变化被视为谨慎和抵抗。

    

    随着人工智能系统越来越嵌入我们的生活，它们的存在导致了塑造我们的行为、决策和社会互动的相互作用。现有的理论研究主要集中在人与人之间的互动上，忽视了人工智能存在导致的独特动态。在本文中，我们采用进化博弈理论的方法，研究了不同形式的人工智能对在混合人工智能人口中进行一次性囚徒困境游戏的合作演化的影响，包括完全混合人口和结构化人口。我们发现，无论是向每个人都无条件提供帮助，包括叛徒，还是只帮助被认为值得或合作的人的撒马利亚人工智能代理人，对于推动人类合作的水平来说，后者要比前者更有利，特别是在变化被谨慎或抵抗视为的缓慢发展的社会中（选择的强度较小）。直观上，在变化快速的社会中（选择的强度较高），歧视性人工智能可以更好地推动合作。

    As artificial intelligence (AI) systems are increasingly embedded in our lives, their presence leads to interactions that shape our behaviour, decision-making, and social interactions. Existing theoretical research has primarily focused on human-to-human interactions, overlooking the unique dynamics triggered by the presence of AI. In this paper, resorting to methods from evolutionary game theory, we study how different forms of AI influence the evolution of cooperation in a human population playing the one-shot Prisoner's Dilemma game in both well-mixed and structured populations. We found that Samaritan AI agents that help everyone unconditionally, including defectors, can promote higher levels of cooperation in humans than Discriminatory AI that only help those considered worthy/cooperative, especially in slow-moving societies where change is viewed with caution or resistance (small intensities of selection). Intuitively, in fast-moving societies (high intensities of selection), Dis
    
[^76]: 以提示为基础的个性化冷启动推荐的研究

    Towards Personalized Cold-Start Recommendation with Prompts. (arXiv:2306.17256v1 [cs.IR])

    [http://arxiv.org/abs/2306.17256](http://arxiv.org/abs/2306.17256)

    本研究旨在解决个性化冷启动推荐问题，通过利用预训练语言模型的能力，将推荐过程转化为自然语言情感分析，提供适用于创业企业和用户参与历史不足的平台的个性化推荐。

    

    推荐系统在根据用户过去的行为帮助用户发现与其兴趣相符的信息方面发挥着关键作用。然而，当用户和物品之间的历史交互记录不可用时，开发个性化推荐系统变得具有挑战性，这就是所谓的系统冷启动推荐问题。此问题在创业企业或用户参与历史不足的平台中尤为突出。以往的研究集中在用户或物品的冷启动场景，其中系统仍然通过在同一领域中的历史用户和物品交互进行训练来为新用户或物品提供推荐，而无法解决我们的问题。为了弥合这一鸿沟，我们的研究引入了一种创新且有效的方法，利用预训练语言模型的能力。我们将推荐过程转化为自然语言情感分析，其中包含用户资料和物品属性的信息。

    Recommender systems play a crucial role in helping users discover information that aligns with their interests based on their past behaviors. However, developing personalized recommendation systems becomes challenging when historical records of user-item interactions are unavailable, leading to what is known as the system cold-start recommendation problem. This issue is particularly prominent in start-up businesses or platforms with insufficient user engagement history. Previous studies focus on user or item cold-start scenarios, where systems could make recommendations for new users or items but are still trained with historical user-item interactions in the same domain, which cannot solve our problem. To bridge the gap, our research introduces an innovative and effective approach, capitalizing on the capabilities of pre-trained language models. We transform the recommendation process into sentiment analysis of natural languages containing information of user profiles and item attribu
    
[^77]: The mapKurator系统：从历史地图中提取和链接文本的完整管道

    The mapKurator System: A Complete Pipeline for Extracting and Linking Text from Historical Maps. (arXiv:2306.17059v1 [cs.AI])

    [http://arxiv.org/abs/2306.17059](http://arxiv.org/abs/2306.17059)

    该论文介绍了一种名为mapKurator的系统，能完整地从历史地图中提取和链接文本信息。该系统解决了传统方法中对位置相关词语的忽略问题，并利用主题建模方法考虑更广的主题范围，能够识别文档的空间焦点。

    

    文档具有空间焦点和有价值的地方特征。例如，房地产或旅行博客中的列表描述包含有关特定地区社区的信息。这些信息对于描述人类如何感知他们的环境是有价值的。然而，利用这些信息的第一步是识别文档的空间焦点（例如，城市）。传统方法用于识别文档的空间焦点依赖于从文档中检测和消歧化地名。这种方法需要一个包含位置短语和临时规则的词汇集，这些规则忽略了与位置相关的重要词语。最近，使用大型语言模型的主题建模方法通常考虑几个广度的主题。相比之下，文档的空间焦点可以是一个国家、一个城市，甚至是一个社区，这些范围比这些方法考虑的主题数要大得多。

    Documents hold spatial focus and valuable locality characteristics. For example, descriptions of listings in real estate or travel blogs contain information about specific local neighborhoods. This information is valuable to characterize how humans perceive their environment. However, the first step to making use of this information is to identify the spatial focus (e.g., a city) of a document. Traditional approaches for identifying the spatial focus of a document rely on detecting and disambiguating toponyms from the document. This approach requires a vocabulary set of location phrases and ad-hoc rules, which ignore important words related to location. Recent topic modeling approaches using large language models often consider a few topics, each with broad coverage. In contrast, the spatial focus of a document can be a country, a city, or even a neighborhood, which together, is much larger than the number of topics considered in these approaches. Additionally, topic modeling methods a
    
[^78]: milliFlow：用于人体运动感知的毫米波雷达点云场景流估计

    milliFlow: Scene Flow Estimation on mmWave Radar Point Cloud for Human Motion Sensing. (arXiv:2306.17010v1 [cs.CV])

    [http://arxiv.org/abs/2306.17010](http://arxiv.org/abs/2306.17010)

    milliFlow是一种用于人体运动感知的新型深度学习方法，通过对毫米波雷达点云进行场景流估计，能够提供中间层的特征并直接用于下游的人体运动感知任务中。实验证明该方法具有优越性能。

    

    随着普适计算时代的到来，人体运动感知在智能系统中起着关键作用，用于决策、用户交互和个性化服务。在传统方法中，人体跟踪、姿势估计、手势识别和活动识别等方面进行了大量研究，这些方法主要基于摄像机。然而，摄像机的侵入性特点限制了它们在智能家居应用中的使用。为了解决这个问题，毫米波雷达由于其保护隐私的特点而受到欢迎。在这项工作中，我们提出了一种新颖的深度学习方法milliFlow，用于对毫米波雷达点云进行场景流估计，作为中间层的特征，直接受益于下游的人体运动感知任务。实验结果表明，我们的方法具有优越的性能，平均3D端点误差为4.6cm，明显超过竞争方法。此外，通过结合...

    Approaching the era of ubiquitous computing, human motion sensing plays a crucial role in smart systems for decision making, user interaction, and personalized services. Extensive research has been conducted on human tracking, pose estimation, gesture recognition, and activity recognition, which are predominantly based on cameras in traditional methods. However, the intrusive nature of cameras limits their use in smart home applications. To address this, mmWave radars have gained popularity due to their privacy-friendly features. In this work, we propose \textit{milliFlow}, a novel deep learning method for scene flow estimation as a complementary motion information for mmWave point cloud, serving as an intermediate level of features and directly benefiting downstream human motion sensing tasks. Experimental results demonstrate the superior performance of our method with an average 3D endpoint error of 4.6cm, significantly surpassing the competing approaches. Furthermore, by incorporati
    
[^79]: SRL: 将分布式强化学习扩展到一万多个核心

    SRL: Scaling Distributed Reinforcement Learning to Over Ten Thousand Cores. (arXiv:2306.16688v1 [cs.DC])

    [http://arxiv.org/abs/2306.16688](http://arxiv.org/abs/2306.16688)

    SRL是一个可扩展，高效，可扩展的分布式强化学习系统，通过一种新的抽象框架统一了各种实际强化学习训练，并实现了精细优化。

    

    强化学习（RL）任务的不断复杂化要求分布式RL系统可以高效地生成和处理大量数据以训练智能Agent。然而，现有的开源库存在各种限制，阻碍了它们在需要大规模训练的挑战性场景中的实际应用。虽然OpenAI和DeepMind的工业系统已经成功实现了大规模RL训练，但是它们的系统架构和实现细节对社区来说仍然不公开。在本文中，我们提出了RL训练数据流的新抽象，将各种应用中的实际RL训练统一成一个通用框架，并实现了精细优化。根据这个抽象，我们开发了一个可扩展、高效、可扩展的分布式RL系统，名为"ReaLly Scalable RL（SRL）"。

    The ever-growing complexity of reinforcement learning (RL) tasks demands a distributed RL system to efficiently generate and process a massive amount of data to train intelligent agents. However, existing open-source libraries suffer from various limitations, which impede their practical use in challenging scenarios where large-scale training is necessary. While industrial systems from OpenAI and DeepMind have achieved successful large-scale RL training, their system architecture and implementation details remain undisclosed to the community. In this paper, we present a novel abstraction on the dataflows of RL training, which unifies practical RL training across diverse applications into a general framework and enables fine-grained optimizations. Following this abstraction, we develop a scalable, efficient, and extensible distributed RL system called ReaLly Scalable RL (SRL). The system architecture of SRL separates major RL computation components and allows massively parallelized trai
    
[^80]: 基于深度学习的彩色多普勒心脏超声相位展开技术研究

    Phase Unwrapping of Color Doppler Echocardiography using Deep Learning. (arXiv:2306.13695v1 [eess.IV])

    [http://arxiv.org/abs/2306.13695](http://arxiv.org/abs/2306.13695)

    本文提出了一种基于展开型原始-对偶网络的新方法，用于纠正彩色多普勒心脏超声图像中的相位包裹伪影，与其他最新分割技术相比，该方法在性能上表现突出。

    

    彩色多普勒心脏超声是一种广泛使用的非侵入性成像技术，可以提供关于心脏血流的实时信息。在左心室长轴视图中，彩色多普勒容易出现相位包裹现象，特别是在心脏收缩和舒张期。当基于彩色多普勒的定量方法时，必须纠正这种包裹伪影。我们开发了一个基于展开型原始-对偶网络的方法来解包(去伪影)彩色多普勒心脏超声图像，将其有效性与基于nnU-Net和Transformer模型的两种最新分割方法进行了比较。我们在自有数据集上对每种方法进行了训练和评估，并发现nnU-Net方法提供了最佳的去伪影结果，其次是展开型原始-对偶方法和基于Transformer的技术。值得注意的是，展开型原始-对偶网络拥有显著更少的可训练参数，但性能仍能与其他方法相媲美。

    Color Doppler echocardiography is a widely used non-invasive imaging modality that provides real-time information about the intracardiac blood flow. In an apical long-axis view of the left ventricle, color Doppler is subject to phase wrapping, or aliasing, especially during cardiac filling and ejection. When setting up quantitative methods based on color Doppler, it is necessary to correct this wrapping artifact. We developed an unfolded primal-dual network to unwrap (dealias) color Doppler echocardiographic images and compared its effectiveness against two state-of-the-art segmentation approaches based on nnU-Net and transformer models. We trained and evaluated the performance of each method on an in-house dataset and found that the nnU-Net-based method provided the best dealiased results, followed by the primal-dual approach and the transformer-based technique. Noteworthy, the primal-dual network, which had significantly fewer trainable parameters, performed competitively with respec
    
[^81]: 推荐系统的最新发展：综述

    Recent Developments in Recommender Systems: A Survey. (arXiv:2306.12680v1 [cs.IR])

    [http://arxiv.org/abs/2306.12680](http://arxiv.org/abs/2306.12680)

    本篇综述全面总结了推荐系统领域的最新进展和趋势，包括推荐系统分类，知识推荐系统，鲁棒性，数据偏见和公平性问题，以及评估度量。该研究还提供了未来研究的新方向。

    

    这篇技术综述全面总结了推荐系统领域的最新进展。本研究的目的是提供领域内现状的概述，并强调推荐系统发展的最新趋势。该研究首先全面总结了主要推荐系统分类方法，包括个性化和群组推荐系统，然后深入探讨了基于知识的推荐系统类别。此外，该综述分析了推荐系统中的鲁棒性、数据偏见和公平性问题，并总结了评估度量用于评估这些系统的性能。最后，研究提供了有关推荐系统发展的最新趋势的见解，并强调了未来研究的新方向。

    In this technical survey, we comprehensively summarize the latest advancements in the field of recommender systems. The objective of this study is to provide an overview of the current state-of-the-art in the field and highlight the latest trends in the development of recommender systems. The study starts with a comprehensive summary of the main taxonomy of recommender systems, including personalized and group recommender systems, and then delves into the category of knowledge-based recommender systems. In addition, the survey analyzes the robustness, data bias, and fairness issues in recommender systems, summarizing the evaluation metrics used to assess the performance of these systems. Finally, the study provides insights into the latest trends in the development of recommender systems and highlights the new directions for future research in the field.
    
[^82]: 在部分可观测性下学习对抗代理行为模型

    Learning Models of Adversarial Agent Behavior under Partial Observability. (arXiv:2306.11168v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.11168](http://arxiv.org/abs/2306.11168)

    本论文提出了一种名为GrAMMI的方法，用于在部分可观测性下建模对抗对手代理的行为。通过最大化互信息作为辅助目标来预测对抗对手的当前和未来状态，GrAMMI在两个大规模追逐-逃避领域中表现出了显著优越性能。

    

    在许多现实场景中，比如职业体育、视频游戏设计和毒品截获中，对手建模和跟踪的需求越来越多。本文提出了一种基于图的对抗建模方法，名为GrAMMI，用于建模对抗对手代理的行为。GrAMMI是一种新颖的基于图神经网络(GNN)的方法，使用互信息最大化作为辅助目标来预测部分可观测的对抗对手的当前和未来状态。为了评估GrAMMI，我们设计了两个大规模的追逐-逃避领域，灵感来自于真实世界的场景，在这些领域中，一个异构代理团队的任务是追踪和截获一个对抗对手代理，而对抗对手代理必须在同时达到自己目标的情况下逃避被发现。通过互信息的形式化，GrAMMI在两个领域中均优于所有基线，并实现了未来对抗的平均对数似然值提高了31.68%。

    The need for opponent modeling and tracking arises in several real-world scenarios, such as professional sports, video game design, and drug-trafficking interdiction. In this work, we present Graph based Adversarial Modeling with Mutal Information (GrAMMI) for modeling the behavior of an adversarial opponent agent. GrAMMI is a novel graph neural network (GNN) based approach that uses mutual information maximization as an auxiliary objective to predict the current and future states of an adversarial opponent with partial observability. To evaluate GrAMMI, we design two large-scale, pursuit-evasion domains inspired by real-world scenarios, where a team of heterogeneous agents is tasked with tracking and interdicting a single adversarial agent, and the adversarial agent must evade detection while achieving its own objectives. With the mutual information formulation, GrAMMI outperforms all baselines in both domains and achieves 31.68% higher log-likelihood on average for future adversarial
    
[^83]: 循环记忆决策变压器

    Recurrent Memory Decision Transformer. (arXiv:2306.09459v1 [cs.LG])

    [http://arxiv.org/abs/2306.09459](http://arxiv.org/abs/2306.09459)

    本文提出了循环记忆决策变压器（RMDT）模型，用于处理强化学习中的长序列问题。在Atari游戏和MoJoCo控制问题上的实验表明，采用循环记忆机制的RMDT模型显着优于其没有循环记忆机制的对应模型。

    

    变革性模型最初是为自然语言问题而开发的，最近在离线强化学习任务中得到广泛应用。这是因为代理的历史可以表示为序列，并且整个任务可以缩减为序列建模任务。然而，变压器操作的二次复杂性限制了上下文的潜在增加。因此，为了在自然语言中处理长序列，使用了不同版本的记忆机制。在本文中，我们提出了循环记忆决策变压器（RMDT），这是一种在强化学习问题中使用循环记忆机制的模型。我们在Atari游戏和MoJoCo控制问题上进行了彻底的实验，并表明我们提出的模型在Atari游戏上显着优于没有循环记忆机制的对应模型。我们还仔细研究了记忆对所提出的模型绩效的影响。这些发现为开发更高效和更有效的处理长序列的强化学习模型提供了启示。

    Transformative models, originally developed for natural language problems, have recently been widely used in offline reinforcement learning tasks. This is due to the fact that the agent's history can be represented as a sequence, and the whole task can be reduced to the sequence modeling task. However, the quadratic complexity of the transformer operation limits the potential increase in context. Therefore, to work with long sequences in a natural language, different versions of the memory mechanism are used. In this paper, we propose the Recurrent Memory Decision Transformer (RMDT), a model that uses a recurrent memory mechanism for reinforcement learning problems. We conduct thorough experiments on Atari games and MoJoCo control problems, and show that our proposed model is significantly superior to its counterparts without the recurrent memory mechanism on Atari games. We also carefully study the effect of memory on the performance of the proposed model. These findings shed light on
    
[^84]: 非线性个性化预测的神经混合效应

    Neural Mixed Effects for Nonlinear Personalized Predictions. (arXiv:2306.08149v1 [cs.LG])

    [http://arxiv.org/abs/2306.08149](http://arxiv.org/abs/2306.08149)

    本文提出了神经混合效应（NME）模型，用于个性化预测，并通过结合个人通用和个人特定参数来考虑线性和非线性趋势。

    

    个性化预测是一种机器学习方法，根据过去标记观测预测一个人未来的观测值，通常用于连续任务，例如预测日常情绪评分。在进行个性化预测时，模型可以结合两种趋势：（a）跨人共享的趋势，即个人通用趋势，例如周末更开心，和（b）每个人独特的趋势，即个人特定的趋势，例如每周有一次压力大的会议。混合效应模型是一种流行的统计模型，用于通过组合个人通用和个人特定参数来研究这两种趋势。尽管现在线性混合效应模型通过将其与神经网络整合而变得越来越流行，但这种整合目前仅限于线性个人特定参数：排除非线性个人特定趋势。在本文中，我们提出了神经混合效应（NME）模型，以优化非线性个人特定参数。

    Personalized prediction is a machine learning approach that predicts a person's future observations based on their past labeled observations and is typically used for sequential tasks, e.g., to predict daily mood ratings. When making personalized predictions, a model can combine two types of trends: (a) trends shared across people, i.e., person-generic trends, such as being happier on weekends, and (b) unique trends for each person, i.e., person-specific trends, such as a stressful weekly meeting. Mixed effect models are popular statistical models to study both trends by combining person-generic and person-specific parameters. Though linear mixed effect models are gaining popularity in machine learning by integrating them with neural networks, these integrations are currently limited to linear person-specific parameters: ruling out nonlinear person-specific trends. In this paper, we propose Neural Mixed Effect (NME) models to optimize nonlinear person-specific parameters anywhere in a 
    
[^85]: $E(2)$-等变视觉Transformer

    $E(2)$-Equivariant Vision Transformer. (arXiv:2306.06722v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.06722](http://arxiv.org/abs/2306.06722)

    本文设计了一个群等变视觉Transformer，通过一种新颖有效的位置编码操作解决了视觉Transformer中的等变性学习难题，并通过实验证明了其明显优于非等变的自注意力网络。

    

    视觉Transformer（ViT）在计算机视觉领域取得了显著的性能。然而，ViT中的位置编码使得学习数据的内在等变性变得非常困难。本文对设计的等变ViT进行了初步尝试，但证明在某些情况下存在缺陷。为了解决这个问题，我们通过一种新颖有效的位置编码操作设计了一个群等变视觉Transformer（GE-ViT）。我们证明了GE-ViT满足等变神经网络的所有理论要求。在标准基准数据集上进行了全面的实验证明，GE-ViT明显优于非等变的自注意力网络。代码可在https://github.com/ZJUCDSYangKaifan/GEVit中获得。

    Vision Transformer (ViT) has achieved remarkable performance in computer vision. However, positional encoding in ViT makes it substantially difficult to learn the intrinsic equivariance in data. Initial attempts have been made on designing equivariant ViT but are proved defective in some cases in this paper. To address this issue, we design a Group Equivariant Vision Transformer (GE-ViT) via a novel, effective positional encoding operator. We prove that GE-ViT meets all the theoretical requirements of an equivariant neural network. Comprehensive experiments are conducted on standard benchmark datasets, demonstrating that GE-ViT significantly outperforms non-equivariant self-attention networks. The code is available at https://github.com/ZJUCDSYangKaifan/GEVit.
    
[^86]: 不要相信你的眼睛：关于特征可视化的（不）可靠性。

    Don't trust your eyes: on the (un)reliability of feature visualizations. (arXiv:2306.04719v1 [cs.CV])

    [http://arxiv.org/abs/2306.04719](http://arxiv.org/abs/2306.04719)

    本文探讨了神经网络如何从像素中提取模式的问题，并研究了特征可视化的可靠性。实验证据表明，由于优化过程中固有的限制，特征可视化能够可靠理解的功能集非常有限，对于解释神经网络如何处理自然图像的解释能力产生怀疑。

    

    神经网络是如何从像素中提取模式的？特征可视化通过优化来可视化高激活的模式，试图回答这个重要问题。如今，可视化方法构成了我们对神经网络内部工作的了解的基础，作为一种机械式的可解释性。在这里，我们问：特征可视化有多可靠？我们通过开发网络电路来诈骗特征可视化，使其显示完全与自然输入的正常网络行为毫无联系的任意模式。然后，我们提供证据表明在标准，未操纵网络中发生了类似的现象：特征可视化与标准输入处理非常不同，对神经网络如何处理自然图像的解释能力产生怀疑。我们通过理论证明支撑这一经验发现，由于优化过程中固有的限制，可以通过特征可视化可靠理解的功能集极其有限。

    How do neural networks extract patterns from pixels? Feature visualizations attempt to answer this important question by visualizing highly activating patterns through optimization. Today, visualization methods form the foundation of our knowledge about the internal workings of neural networks, as a type of mechanistic interpretability. Here we ask: How reliable are feature visualizations? We start our investigation by developing network circuits that trick feature visualizations into showing arbitrary patterns that are completely disconnected from normal network behavior on natural input. We then provide evidence for a similar phenomenon occurring in standard, unmanipulated networks: feature visualizations are processed very differently from standard input, casting doubt on their ability to "explain" how neural networks process natural images. We underpin this empirical finding by theory proving that the set of functions that can be reliably understood by feature visualization is extr
    
[^87]: 设计用户角色感知的对话代理进行有趣的对话：$\textit{WHAT}$, $\textit{WHEN}$, and $\textit{HOW}$ to Ground

    $\textit{WHAT}$, $\textit{WHEN}$, and $\textit{HOW}$ to Ground: Designing User Persona-Aware Conversational Agents for Engaging Dialogue. (arXiv:2306.03361v1 [cs.CL])

    [http://arxiv.org/abs/2306.03361](http://arxiv.org/abs/2306.03361)

    本文提出了一种针对商业环境的、能够平衡对话流畅性和趋向于理解对话系统的个性化开放领域对话系统方法，通过加权数据集混合、负角色信息增强方法，以及设计个性化对话数据集，解决了 $\textit{WHAT}$、$\textit{WHEN}$和$\textit{HOW}$ 等问题，同时提高了对话系统响应的可控性和解释性。

    

    本文提出了一种建立个性化开放领域对话系统以解决商业设置中涉及个性化对话响应与非正式响应交替的$\textit{WWH}$（$\textit{WHAT}$、$\textit{WHEN}$和$\textit{HOW}$）问题的方法。所提出的方法涉及加权数据集混合、负角色信息增强方法以及设计个性化对话数据集，以应对个性化、开放领域对话系统中$\textit{WWH}$的挑战。本文有效地平衡了对话流畅性和趋向于理解对话系统，同时还引入了响应类型标签来提高可控性和解释性。这些方法的组合导致了更加流畅的对话，证明了基于主观人类评估和客观评估的实验结果。

    This paper presents a method for building a personalized open-domain dialogue system to address the $\textit{WWH}$ ($\textit{WHAT}$, $\textit{WHEN}$, and $\textit{HOW}$) problem for natural response generation in a commercial setting, where personalized dialogue responses are heavily interleaved with casual response turns. The proposed approach involves weighted dataset blending, negative persona information augmentation methods, and the design of personalized conversation datasets to address the challenges of $\textit{WWH}$ in personalized, open-domain dialogue systems. Our work effectively balances dialogue fluency and tendency to ground, while also introducing a response-type label to improve the controllability and explainability of the grounded responses. The combination of these methods leads to more fluent conversations, as evidenced by subjective human evaluations as well as objective evaluations.
    
[^88]: 无标注音视频分割

    Annotation-free Audio-Visual Segmentation. (arXiv:2305.11019v1 [cs.CV])

    [http://arxiv.org/abs/2305.11019](http://arxiv.org/abs/2305.11019)

    本文提出了一种可伸缩且无需注释的管道，用于生成音视频分割任务的人工数据，并引入了一个音频感知的基于查询的Transformer解码器，使模型能够在音频信号的指导下搜索声音对象，得到更准确的分割。

    

    音视频分割的目标是通过准确地预测像素级分割掩码在视觉场景中定位声音对象。本文提出了以下贡献：（i）我们提出了一种可伸缩且无需注释的管道，用于生成音视频分割任务的人工数据。我们利用现有的图像分割和音频数据集，建立类别标签、图像掩模对和音频样本之间的联系，从而可以轻松组合训练AVS模型的（图像、音频、掩模）三元组；（ii）我们引入了一种新的音频感知变压器（AuTR）架构，其中包含一个音频感知的基于查询的Transformer解码器。该架构使模型能够在音频信号的指导下搜索声音对象，从而得到更准确的分割；（iii）我们在合成和真实数据集上进行了广泛的实验，证明了使用我们的管道生成的合成数据训练AVS模型的有效性。

    The objective of Audio-Visual Segmentation (AVS) is to locate sounding objects within visual scenes by accurately predicting pixelwise segmentation masks. In this paper, we present the following contributions: (i), we propose a scalable and annotation-free pipeline for generating artificial data for the AVS task. We leverage existing image segmentation and audio datasets to draw links between category labels, image-mask pairs, and audio samples, which allows us to easily compose (image, audio, mask) triplets for training AVS models; (ii), we introduce a novel Audio-Aware Transformer (AuTR) architecture that features an audio-aware query-based transformer decoder. This architecture enables the model to search for sounding objects with the guidance of audio signals, resulting in more accurate segmentation; (iii), we present extensive experiments conducted on both synthetic and real datasets, which demonstrate the effectiveness of training AVS models with synthetic data generated by our p
    
[^89]: 经典规划中探索和开发的自适应平衡

    Scale-Adaptive Balancing of Exploration and Exploitation in Classical Planning. (arXiv:2305.09840v1 [cs.AI])

    [http://arxiv.org/abs/2305.09840](http://arxiv.org/abs/2305.09840)

    本文提出了一种MCTS/THTS算法GreedyUCT-Normal，该算法能够通过采用奖励变化的尺度处理不同尺度的分布，以在经典计划中平衡探索和开发。

    

    在游戏树搜索和自动化规划中，平衡探索和开发一直是一个重要的问题。然而，虽然这个问题在多臂赌博机（MAB）文献中已经被广泛分析，但规划社区在试图应用这些结果时取得的成功有限。我们展示了MAB文献更详细的理论理解有助于改进基于蒙特卡罗树搜索（MCTS）/基于试验的启发式树搜索（THTS）的现有规划算法。具体而言，THTS在一种临时方法中使用UCB1 MAB算法，因为在启发式搜索中UCB1理论上需要有界支持奖励分布的要求在经典规划中不被满足。核心问题在于UCB1缺乏对不同奖励尺度的自适应。我们提出了GreedyUCT-Normal，这是一种具有UCB1-Normal赌博机的MCTS/THTS算法，用于敏捷经典计划，它通过采用奖励变化的尺度处理不同尺度的分布。

    Balancing exploration and exploitation has been an important problem in both game tree search and automated planning. However, while the problem has been extensively analyzed within the Multi-Armed Bandit (MAB) literature, the planning community has had limited success when attempting to apply those results. We show that a more detailed theoretical understanding of MAB literature helps improve existing planning algorithms that are based on Monte Carlo Tree Search (MCTS) / Trial Based Heuristic Tree Search (THTS). In particular, THTS uses UCB1 MAB algorithms in an ad hoc manner, as UCB1's theoretical requirement of fixed bounded support reward distributions is not satisfied within heuristic search for classical planning. The core issue lies in UCB1's lack of adaptations to the different scales of the rewards. We propose GreedyUCT-Normal, a MCTS/THTS algorithm with UCB1-Normal bandit for agile classical planning, which handles distributions with different scales by taking the reward vari
    
[^90]: 语言、时间偏好和消费行为：大型语言模型的证据

    Language, Time Preferences, and Consumer Behavior: Evidence from Large Language Models. (arXiv:2305.02531v1 [econ.GN])

    [http://arxiv.org/abs/2305.02531](http://arxiv.org/abs/2305.02531)

    本研究分析了大型语言模型在不同语言提示下的奖励时间偏好，并发现GPT在具有较弱未来时态的语言下表现出更大的耐心，这与使用该语言的人类的偏好相似。

    

    语言对我们对时间和奖励的感知有很大的影响。这引发了一个问题，即当以不同的语言询问大型语言模型时，它们是否显示出不同的奖励时间偏好，并且它们的选择是否类似于人类的选择。本研究分析了GPT-3.5（以下简称GPT）在多种语言提示下的响应，探索了较小、较早的奖励和较大、较晚的奖励之间的偏好。我们的结果显示，当以语义含义较弱的未来时态参考（FTR），如德语和汉语，为提示语时，GPT表现出更大的耐心，相比英语和法语等具有强大FTR的语言。这些发现与现有文献一致，并表明了GPT的选择与这些语言的使用者的偏好之间的关联。然而，进一步的分析揭示了较早或较晚奖励的偏好并没有随着奖励差异系统地改变，这表明了一种词典序优先的选择。

    Language has a strong influence on our perceptions of time and rewards. This raises the question of whether large language models, when asked in different languages, show different preferences for rewards over time and if their choices are similar to those of humans. In this study, we analyze the responses of GPT-3.5 (hereafter referred to as GPT) to prompts in multiple languages, exploring preferences between smaller, sooner rewards and larger, later rewards. Our results show that GPT displays greater patience when prompted in languages with weak future tense references (FTR), such as German and Mandarin, compared to languages with strong FTR, like English and French. These findings are consistent with existing literature and suggest a correlation between GPT's choices and the preferences of speakers of these languages. However, further analysis reveals that the preference for earlier or later rewards does not systematically change with reward gaps, indicating a lexicographic preferen
    
[^91]: Distilling Step-by-Step！使用更少的训练数据和更小的模型尺寸胜过更大的语言模型

    Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes. (arXiv:2305.02301v1 [cs.CL])

    [http://arxiv.org/abs/2305.02301](http://arxiv.org/abs/2305.02301)

    本研究提出了Distilling Step-by-Step机制，通过提取LLM基础信息为小型模型提供额外的监督训练，从而使它们胜过更大的LLM模型，并需更少的训练数据。

    

    部署大型语言模型（LLM）面临内存效率低和计算密集度高的问题，研究人员通过微调或精炼使用LLM生成的标签来训练较小的任务特定模型。但是，要想达到LLM相当的性能，这需要大量的训练数据。我们引入了Distilling Step-by-Step，这是一种新的机制， (a)训练较小的模型比LLM表现更好，(b)并通过利用微调或精炼所需的更少的训练数据来实现。我们的方法在多任务训练框架中提取LLM基础，并作为额外的监督来训练小型模型。在四个NLP基准测试中，我们提出了三个发现：第一，与微调和精炼相比，我们的机制使用较少的标记/未标记训练示例取得更好的性能。第二，与LLM相比，即使使用更小的模型，我们也实现了更好的性能。

    Deploying large language models (LLMs) is challenging because they are memory inefficient and compute-intensive for practical applications. In reaction, researchers train smaller task-specific models by either finetuning with human labels or distilling using LLM-generated labels. However, finetuning and distillation require large amounts of training data to achieve comparable performance to LLMs. We introduce Distilling step-by-step, a new mechanism that (a) trains smaller models that outperform LLMs, and (b) achieves so by leveraging less training data needed by finetuning or distillation. Our method extracts LLM rationales as additional supervision for small models within a multi-task training framework. We present three findings across 4 NLP benchmarks: First, compared to both finetuning and distillation, our mechanism achieves better performance with much fewer labeled/unlabeled training examples. Second, compared to LLMs, we achieve better performance using substantially smaller m
    
[^92]: Transformer介绍

    An Introduction to Transformers. (arXiv:2304.10557v1 [cs.LG])

    [http://arxiv.org/abs/2304.10557](http://arxiv.org/abs/2304.10557)

    Transformer是一种神经网络组件，可以学习序列或数据集表示，在自然语言处理、计算机视觉和时空建模方面取得了重大进展。本论文提供了一个数学精确、直观、简洁的Transformer架构描述。

    

    Transformer是一种可以学习序列或数据集表示的神经网络组件。Transformer在自然语言处理、计算机视觉和时空建模方面取得了重大进展。虽然有很多Transformer的介绍，但大多数都缺少对其架构的精确数学描述，其设计选择的直觉也常常缺失。此外，随着研究路径的曲折，Transformer部件的解释可能是异质的。在这篇论文中，我们旨在提供一个数学精确、直观、简洁的Transformer架构描述。

    The transformer is a neural network component that can be used to learn useful representations of sequences or sets of datapoints. The transformer has driven recent advances in natural language processing, computer vision, and spatio-temporal modelling. There are many introductions to transformers, but most do not contain precise mathematical descriptions of the architecture and the intuitions behind the design choices are often also missing. Moreover, as research takes a winding path, the explanations for the components of the transformer can be idiosyncratic. In this note we aim for a mathematically precise, intuitive, and clean description of the transformer architecture.
    
[^93]: 机器心理学：利用心理学方法探究大型语言模型的新兴能力和行为

    Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Methods. (arXiv:2303.13988v1 [cs.CL])

    [http://arxiv.org/abs/2303.13988](http://arxiv.org/abs/2303.13988)

    本文提出了一种新领域——机器心理学，利用心理学的方法考察大型语言模型的能力。该文规范了机器心理学研究的方法论标准，并对心理实验中提示设计政策进行了探讨和制定。

    

    大型语言模型（LLM）是将人工智能系统与人类交流和日常生活紧密结合的先锋。由于快速技术进步和其极高的通用性，现今LLM已经拥有数百万用户，并正处于成为主要信息检索、内容生成、问题解决等技术的前沿。因此，对其进行全面评估和审查显得尤为重要。由于当前LLM中出现愈加复杂和新颖的行为模式，可将其视为参与人类心理实验的对象，以便更为全面地评估其能力。为此，本文引入了一个名为"机器心理学"的新兴研究领域。本文概述了各类心理学分支如何为LLM的行为测试提供有用参考。同时，本文规范了机器心理学研究的方法论标准，特别是专注于提示设计政策的制定。此外，它还描述了行为测试结果如何为未来的LLM发展提供指导。

    Large language models (LLMs) are currently at the forefront of intertwining AI systems with human communication and everyday life. Due to rapid technological advances and their extreme versatility, LLMs nowadays have millions of users and are at the cusp of being the main go-to technology for information retrieval, content generation, problem-solving, etc. Therefore, it is of great importance to thoroughly assess and scrutinize their capabilities. Due to increasingly complex and novel behavioral patterns in current LLMs, this can be done by treating them as participants in psychology experiments that were originally designed to test humans. For this purpose, the paper introduces a new field of research called "machine psychology". The paper outlines how different subfields of psychology can inform behavioral tests for LLMs. It defines methodological standards for machine psychology research, especially by focusing on policies for prompt designs. Additionally, it describes how behaviora
    
[^94]: 基于图神经网络的上下文嵌入在表格数据深度学习中的应用

    Graph Neural Network contextual embedding for Deep Learning on Tabular Data. (arXiv:2303.06455v1 [cs.LG])

    [http://arxiv.org/abs/2303.06455](http://arxiv.org/abs/2303.06455)

    本文介绍了一种基于图神经网络的深度学习模型，使用交互网络进行上下文嵌入，用于表格数据的处理。该模型在公共数据集上的表现优于最近的深度学习基准调查，并且与提升树解决方案相比也取得了竞争性的结果。

    This paper introduces a novel deep learning model based on Graph Neural Network (GNN) with Interaction Network (IN) for contextual embedding, which outperforms the recent DL benchmark on five public datasets and achieves competitive results compared to boosted-tree solutions in tabular data processing.

    所有行业都试图利用现有的大数据进行基于人工智能的应用，这些数据通常以所谓的表格形式存在，其中每个记录由许多异构的连续和分类列组成，也称为特征。深度学习在自然语言处理等与人类技能相关的领域中已经取得了重大突破，但其在表格数据上的应用更具挑战性。更经典的机器学习模型，如基于树的集成模型通常表现更好。本文介绍了一种新颖的深度学习模型，它使用图神经网络（GNN），更具体地说是交互网络（IN），进行上下文嵌入。其结果优于最近发布的基于五个公共数据集的深度学习基准调查，与提升树解决方案相比也取得了竞争性的结果。

    All industries are trying to leverage Artificial Intelligence (AI) based on their existing big data which is available in so called tabular form, where each record is composed of a number of heterogeneous continuous and categorical columns also known as features. Deep Learning (DL) has consituted a major breathrough for AI in fields related to human skills like natural language processing, but its applicability to tabular data has been more challenging. More classical Machine Learning (ML) models like tree-based ensemble ones usually perform better. In this manuscript a novel DL model that uses Graph Neural Network (GNN), more specifically Interaction Network (IN), for contextual embedding is introduced. Its results outperform those of the recently published survey with DL benchmark based on five public datasets, achieving also competitive results when compared to boosted-tree solutions.
    
[^95]: 因果依赖图

    Causal Dependence Plots. (arXiv:2303.04209v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.04209](http://arxiv.org/abs/2303.04209)

    本论文提出了因果依赖图（CDPs）来解释人工智能或机器学习模型的因果依赖关系。CDPs与传统方法不同，可以模块化地结合因果学习或敏感度分析方法。这些图表可以成为可解释机器学习工具包中的强大工具，并对相关应用做出贡献。

    

    解释人工智能或机器学习模型的重要性越来越大。为了明智地使用这些数据驱动的系统，我们必须了解它们如何与世界互动，包括它们在数据输入上的因果依赖关系。在这项工作中，我们开发了因果依赖图 (CDPs)，用于可视化一个变量（结果）如何随另一个变量（预测器）的变化而变化，以及其他预测器变量的因果变化。关键是，CDPs与基于保持其他预测器恒定或假设它们独立的标准方法不同。CDPs利用辅助因果模型，因为因果结论需要因果假设。通过模拟和真实数据实验，我们展示了CDPs可以与因果学习或敏感性分析方法以模块化的方式结合使用。由于人们经常在输入-输出依赖性方面进行因果思考，CDPs可以成为xAI或可解释机器学习工具包中强有力的工具，并对应用有所贡献。

    Explaining artificial intelligence or machine learning models is increasingly important. To use such data-driven systems wisely we must understand how they interact with the world, including how they depend causally on data inputs. In this work we develop Causal Dependence Plots (CDPs) to visualize how one variable--an outcome--depends on changes in another variable--a predictor--$\textit{along with any consequent causal changes in other predictor variables}$. Crucially, CDPs differ from standard methods based on holding other predictors constant or assuming they are independent. CDPs make use of an auxiliary causal model because causal conclusions require causal assumptions. With simulations and real data experiments, we show CDPs can be combined in a modular way with methods for causal learning or sensitivity analysis. Since people often think causally about input-output dependence, CDPs can be powerful tools in the xAI or interpretable machine learning toolkit and contribute to appl
    
[^96]: 是否可以在深度神经网络中避免双下降？

    Can we avoid Double Descent in Deep Neural Networks?. (arXiv:2302.13259v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.13259](http://arxiv.org/abs/2302.13259)

    这项研究表明，通过适当调整学习问题的条件，可以避免双下降现象，特别是在复杂情况下使用适当的正则化。这对于寻找深度学习模型的最优大小具有重要意义。

    

    寻找深度学习模型的最优大小非常重要且具有广泛影响，尤其在节能方案中。最近，一个意外的现象，“双下降”，引起了深度学习界的关注。随着模型大小的增加，性能首先变差，然后恢复提升。这对于维持高泛化的最优模型大小提出了严重的问题：模型需要足够的超参数化，但添加过多的参数会浪费训练资源。是否可能以高效的方式找到最佳折衷方案？我们的工作表明，通过适当调整学习问题的条件，可能可以避免双下降现象，但最终答案仍待确定。我们经验地观察到，在复杂情况下，通过适当的正则化有望避开双下降，简单的$\ell_2$正则化已经对此有积极的贡献。

    Finding the optimal size of deep learning models is very actual and of broad impact, especially in energy-saving schemes. Very recently, an unexpected phenomenon, the ``double descent'', has caught the attention of the deep learning community. As the model's size grows, the performance gets first worse, and then goes back to improving. It raises serious questions about the optimal model's size to maintain high generalization: the model needs to be sufficiently over-parametrized, but adding too many parameters wastes training resources. Is it possible to find, in an efficient way, the best trade-off? Our work shows that the double descent phenomenon is potentially avoidable with proper conditioning of the learning problem, but a final answer is yet to be found. We empirically observe that there is hope to dodge the double descent in complex scenarios with proper regularization, as a simple $\ell_2$ regularization is already positively contributing to such a perspective.
    
[^97]: Video-SwinUNet：VFSS 实例分割的时空深度学习框架

    Video-SwinUNet: Spatio-temporal Deep Learning Framework for VFSS Instance Segmentation. (arXiv:2302.11325v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.11325](http://arxiv.org/abs/2302.11325)

    本文提出了一个用于医学视频分割的深度学习框架，通过显式地利用时间维度并结合Swin Transformer的全局特征编码能力，改进了医学图像分割任务的性能。

    

    本文提出了一种用于医学视频分割的深度学习框架。由于其具有令人难以置信的语义特征编码和全局信息理解能力，卷积神经网络（CNN）和基于Transformer的方法在医学图像分割任务中取得了巨大的里程碑。然而，大多数现有方法忽略了医学视频数据的一个显著方面 - 时间维度。我们提出的框架明确地从时间维度上的相邻帧中提取特征，并将其与一个时间特征混合器结合起来，然后使用Swin Transformer对高水平的时空特征进行标记。最终的分割结果通过一个类似UNet的编码器-解码器架构生成。我们的模型在VFSS2022数据集上表现出色，较其他方法提升显著，对于两个测试数据集的Dice系数分别达到了0.8986和0.8186。

    This paper presents a deep learning framework for medical video segmentation. Convolution neural network (CNN) and transformer-based methods have achieved great milestones in medical image segmentation tasks due to their incredible semantic feature encoding and global information comprehension abilities. However, most existing approaches ignore a salient aspect of medical video data - the temporal dimension. Our proposed framework explicitly extracts features from neighbouring frames across the temporal dimension and incorporates them with a temporal feature blender, which then tokenises the high-level spatio-temporal feature to form a strong global feature encoded via a Swin Transformer. The final segmentation results are produced via a UNet-like encoder-decoder architecture. Our model outperforms other approaches by a significant margin and improves the segmentation benchmarks on the VFSS2022 dataset, achieving a dice coefficient of 0.8986 and 0.8186 for the two datasets tested. Our 
    
[^98]: 基于伪对比学习的基于图的半监督学习

    Pseudo Contrastive Learning for Graph-based Semi-supervised Learning. (arXiv:2302.09532v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.09532](http://arxiv.org/abs/2302.09532)

    本论文提出了一种基于伪对比学习的半监督图神经网络方法，通过生成可靠的负样本对来改进伪标签的质量。

    

    伪标签是一种用于改进半监督图神经网络(GNNs)性能的技术，通过根据自信的预测生成附加的伪标签。然而，由于分类目标对给定标签的敏感性，生成的伪标签质量一直是一个长期存在的问题。为了避免不可靠的分类监督“一个节点属于特定类”，我们更喜欢容错性对比监督“两个节点不属于同一类”。因此，生成高质量伪标签问题转化为一个放松的版本，即识别可靠的负样本对。为了实现这一点，我们提出了一种通用的GNNs框架，称之为伪对比学习(PCL)。它将目标为相同类的正伪标签和负伪标签的两个节点分开。为了将拓扑知识纳入学习中，我们设计了一种拓扑加权对比学习方法

    Pseudo Labeling is a technique used to improve the performance of semi-supervised Graph Neural Networks (GNNs) by generating additional pseudo-labels based on confident predictions. However, the quality of generated pseudo-labels has been a longstanding concern due to the sensitivity of the classification objective with respect to the given labels. To avoid the untrustworthy classification supervision indicating ``a node belongs to a specific class,'' we favor the fault-tolerant contrasting supervision demonstrating ``two nodes do not belong to the same class.'' Thus, the problem of generating high-quality pseudo-labels is then transformed into a relaxed version, i.e., identifying reliable negative pairs. To achieve this, we propose a general framework for GNNs, termed Pseudo Contrastive Learning (PCL). It separates two nodes whose positive and negative pseudo-labels target the same class. To incorporate topological knowledge into learning, we devise a topologically weighted contrastiv
    
[^99]: 仅调整归一化层的表达能力

    The Expressive Power of Tuning Only the Normalization Layers. (arXiv:2302.07937v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07937](http://arxiv.org/abs/2302.07937)

    本研究发现，仅调整神经网络的归一化层参数就可以达到高准确性，甚至可以重建比原网络小O(根号宽度)倍的目标网络。

    

    特征归一化转换，如批量归一化和层归一化，已成为当今先进深度神经网络不可或缺的组成部分。关于微调大型预训练模型的最近研究表明，仅调整这些仿射变换的参数就可以在下游任务中获得高准确性。这些研究结果引发了对调整冻结网络的归一化层的表达能力的问题。本文首次探讨这个问题，并显示对于随机ReLU网络，仅微调其归一化层可以重建任何大小为O(根号宽度)倍小的目标网络。我们证明，即使在随机稀疏网络中，在足够超参数化的情况下，这个结论也成立，与先前的实证工作一致。

    Feature normalization transforms such as Batch and Layer-Normalization have become indispensable ingredients of state-of-the-art deep neural networks. Recent studies on fine-tuning large pretrained models indicate that just tuning the parameters of these affine transforms can achieve high accuracy for downstream tasks. These findings open the questions about the expressive power of tuning the normalization layers of frozen networks. In this work, we take the first step towards this question and show that for random ReLU networks, fine-tuning only its normalization layers can reconstruct any target network that is $O(\sqrt{\text{width}})$ times smaller. We show that this holds even for randomly sparsified networks, under sufficient overparameterization, in agreement with prior empirical work.
    
[^100]: 标签预算约束下的深度异常检测

    Deep Anomaly Detection under Labeling Budget Constraints. (arXiv:2302.07832v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07832](http://arxiv.org/abs/2302.07832)

    本文针对标签预算约束下的深度异常检测问题提出了一种数据标记策略和半监督学习框架，在多种数据集上取得了最先进的性能。

    

    在各种场景下，选择信息丰富的数据点进行专家反馈可以显著提高异常检测的性能，例如医学诊断或欺诈检测。在本文中，我们确定了一组理论条件，使得从标记的查询到未标记的数据中异常分数能够推广。基于这些结果，我们提出了一种在标签预算约束下具有最优数据覆盖的数据标记策略。此外，我们还提出了一种新的半监督异常检测学习框架。在图像、表格和视频数据集上进行了大量实验证明，我们的方法在标签预算约束下具有最先进的半监督异常检测性能。

    Selecting informative data points for expert feedback can significantly improve the performance of anomaly detection (AD) in various contexts, such as medical diagnostics or fraud detection. In this paper, we determine a set of theoretical conditions under which anomaly scores generalize from labeled queries to unlabeled data. Motivated by these results, we propose a data labeling strategy with optimal data coverage under labeling budget constraints. In addition, we propose a new learning framework for semi-supervised AD. Extensive experiments on image, tabular, and video data sets show that our approach results in state-of-the-art semi-supervised AD performance under labeling budget constraints.
    
[^101]: 超越领域情景：鲁棒的密度感知校准

    Beyond In-Domain Scenarios: Robust Density-Aware Calibration. (arXiv:2302.05118v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.05118](http://arxiv.org/abs/2302.05118)

    这个论文提出了一种鲁棒的密度感知校准方法，通过利用隐藏层的信息，该方法能够提供在领域转移和领域外情景下可靠的不确定性估计，并在保持出色领域内预测不确定性估计的同时提高校准性能。

    

    随着深度神经网络在安全关键应用中的部署越来越多，校准深度学习模型以获得具有不确定性意识的预测变得至关重要。尽管现有的事后校准方法在领域内的测试数据集上取得了令人印象深刻的结果，但它们在领域转移和领域外（OOD）情景下无法产生可靠的不确定性估计。我们旨在通过提出基于k近邻的DAC（Density-Aware Calibration）方法来弥补这个差距。与现有的事后方法不同，我们利用分类器的隐藏层作为与不确定性相关信息的来源，并研究它们的重要性。我们表明DAC是一个通用的方法，可以方便地与最先进的事后方法结合使用。DAC提高了在领域转移和OOD情景下校准性能的稳健性，同时保持了出色的领域内预测不确定性估计。我们证明了DAC能够一直引导着一致

    Calibrating deep learning models to yield uncertainty-aware predictions is crucial as deep neural networks get increasingly deployed in safety-critical applications. While existing post-hoc calibration methods achieve impressive results on in-domain test datasets, they are limited by their inability to yield reliable uncertainty estimates in domain-shift and out-of-domain (OOD) scenarios. We aim to bridge this gap by proposing DAC, an accuracy-preserving as well as Density-Aware Calibration method based on k-nearest-neighbors (KNN). In contrast to existing post-hoc methods, we utilize hidden layers of classifiers as a source for uncertainty-related information and study their importance. We show that DAC is a generic method that can readily be combined with state-of-the-art post-hoc methods. DAC boosts the robustness of calibration performance in domain-shift and OOD, while maintaining excellent in-domain predictive uncertainty estimates. We demonstrate that DAC leads to consistently b
    
[^102]: RPN: 一种深度学习中基于词向量的数据增强算法，用于语言理解

    RPN: A Word Vector Level Data Augmentation Algorithm in Deep Learning for Language Understanding. (arXiv:2212.05961v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.05961](http://arxiv.org/abs/2212.05961)

    RPN是一种基于词向量级别的数据增强算法，通过引入噪声修改原始文本的词嵌入，更好地捕捉自然语言变化，并在自然语言理解任务中表现出优异的性能。

    

    数据增强是机器学习中广泛使用以提高模型性能的技术。然而，现有的自然语言理解数据增强技术可能无法完全捕捉到自然语言的复杂变化，并且在大型数据集中应用起来具有挑战性。本文提出了一种新颖的数据增强技术——随机位置噪声（RPN）算法，它在词向量级别上进行操作。RPN通过根据选定词向量的现有值引入噪声修改原始文本的词嵌入，允许更细粒度的修改并更好地捕捉自然语言变化。与传统的数据增强方法不同，RPN不需要计算图中的梯度来进行虚拟样本更新，使其更容易应用于大型数据集。实验结果表明，在各种自然语言理解任务中，包括情感分析等，RPN始终优于现有数据增强技术。

    Data augmentation is a widely used technique in machine learning to improve model performance. However, existing data augmentation techniques in natural language understanding (NLU) may not fully capture the complexity of natural language variations, and they can be challenging to apply to large datasets. This paper proposes the Random Position Noise (RPN) algorithm, a novel data augmentation technique that operates at the word vector level. RPN modifies the word embeddings of the original text by introducing noise based on the existing values of selected word vectors, allowing for more fine-grained modifications and better capturing natural language variations. Unlike traditional data augmentation methods, RPN does not require gradients in the computational graph during virtual sample updates, making it simpler to apply to large datasets. Experimental results demonstrate that RPN consistently outperforms existing data augmentation techniques across various NLU tasks, including sentime
    
[^103]: 通过公平干预和纠正采样来打破条件生成的伪因果关系

    Breaking the Spurious Causality of Conditional Generation via Fairness Intervention with Corrective Sampling. (arXiv:2212.02090v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.02090](http://arxiv.org/abs/2212.02090)

    本文提出了一种通过公平干预和纠正采样的方法来解决条件生成中的伪因果关系。实验证明，该方法在各种数据集上都能有效地解决这个问题。

    

    为了捕捉样本和标签之间的关系，条件生成模型经常从训练数据集中继承了伪相关性。这可能导致标签条件分布在另一个潜在属性上不平衡。为了减轻这个问题，我们提出了一种通用的两步策略。 （a）公平干预（FI）：强调在训练数据集中由于伪相关性难以生成的少数样本。（b）纠正采样（CS）：显式过滤生成的样本，并确保它们遵循所需的潜在属性分布。我们设计的公平干预可以适用于不同程度的对伪属性的监督，包括无监督、弱监督和半监督场景。我们的实验结果证明，FICS可以有效地解决各种数据集上的条件生成的伪因果关系。

    To capture the relationship between samples and labels, conditional generative models often inherit spurious correlations from the training dataset. This can result in label-conditional distributions that are imbalanced with respect to another latent attribute. To mitigate this issue, which we call spurious causality of conditional generation, we propose a general two-step strategy. (a) Fairness Intervention (FI): emphasize the minority samples that are hard to generate due to the spurious correlation in the training dataset. (b) Corrective Sampling (CS): explicitly filter the generated samples and ensure that they follow the desired latent attribute distribution. We have designed the fairness intervention to work for various degrees of supervision on the spurious attribute, including unsupervised, weakly-supervised, and semi-supervised scenarios. Our experimental results demonstrate that FICS can effectively resolve spurious causality of conditional generation across various datasets.
    
[^104]: TAX-Pose：机器人操作的任务特定跨姿势估计

    TAX-Pose: Task-Specific Cross-Pose Estimation for Robot Manipulation. (arXiv:2211.09325v2 [cs.RO] CROSS LISTED)

    [http://arxiv.org/abs/2211.09325](http://arxiv.org/abs/2211.09325)

    本论文提出了一种名为TAX-Pose的系统，在机器人操作中实现了任务特定跨姿势的估计。通过学习对象之间的对应关系，这种系统能够在给定操作任务的情况下准确估计两个对象之间的跨姿势，并利用估计结果指导下游的运动规划。

    

    我们如何赋予机器人有效地操作未知物体的能力，并基于示范转移相关技能？端到端学习方法通常无法泛化到新的物体或未见过的配置。相反，我们关注交互对象相关部分的任务特定姿势关系。我们推测这种关系是一种可以转移到同一类别新物体的操作任务的可泛化概念；例如，平底锅相对于烤箱的姿势关系或者杯子相对于杯架的姿势关系。我们称这种任务特定姿势关系为“跨姿势”，并提供了该概念的数学定义。我们提出了一个基于视觉的系统，使用学习的对象间对应关系来学习估计给定操作任务的两个对象之间的跨姿势。然后，估计的跨姿势用于引导下游的运动规划器将对象操纵到所需的姿势。

    How do we imbue robots with the ability to efficiently manipulate unseen objects and transfer relevant skills based on demonstrations? End-to-end learning methods often fail to generalize to novel objects or unseen configurations. Instead, we focus on the task-specific pose relationship between relevant parts of interacting objects. We conjecture that this relationship is a generalizable notion of a manipulation task that can transfer to new objects in the same category; examples include the relationship between the pose of a pan relative to an oven or the pose of a mug relative to a mug rack. We call this task-specific pose relationship "cross-pose" and provide a mathematical definition of this concept. We propose a vision-based system that learns to estimate the cross-pose between two objects for a given manipulation task using learned cross-object correspondences. The estimated cross-pose is then used to guide a downstream motion planner to manipulate the objects into the desired po
    
[^105]: 在工作中学习的机器人：人为环境下的自主学习和部署期间的学习

    Robot Learning on the Job: Human-in-the-Loop Autonomy and Learning During Deployment. (arXiv:2211.08416v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2211.08416](http://arxiv.org/abs/2211.08416)

    本论文提出了Sirius框架，通过任务分工实现人机协作，部分自主的机器人负责决策工作，人类操作员在需要时进行干预。这种人机团队可以确保复杂任务的安全部署。同时，引入了一种新的学习算法，通过重新加权训练样本来改进策略性能。

    

    随着计算能力的快速增长和深度学习的最新进展，我们在研究环境中见证了新型机器人能力的令人印象深刻的展示。然而，这些学习系统表现出脆弱的泛化能力，并且在实际任务中需要大量训练数据。为了利用最先进的机器人学习模型的能力，同时接受它们的不完美性，我们提出了Sirius，一个为人类和机器人通过分工合作而设计的原则性框架。在这个框架中，部分自主的机器人负责处理大部分决策工作，在这些工作中它们能可靠地工作；与此同时，人类操作员监控这个过程，并在挑战性情况下进行干预。这样的人机团队确保了复杂任务的安全部署。此外，我们引入了一种新的学习算法来改进从任务执行中收集的数据对策略的性能的影响。核心思想是使用近似人类行为的样本对训练样本进行重新加权。

    With the rapid growth of computing powers and recent advances in deep learning, we have witnessed impressive demonstrations of novel robot capabilities in research settings. Nonetheless, these learning systems exhibit brittle generalization and require excessive training data for practical tasks. To harness the capabilities of state-of-the-art robot learning models while embracing their imperfections, we present Sirius, a principled framework for humans and robots to collaborate through a division of work. In this framework, partially autonomous robots are tasked with handling a major portion of decision-making where they work reliably; meanwhile, human operators monitor the process and intervene in challenging situations. Such a human-robot team ensures safe deployments in complex tasks. Further, we introduce a new learning algorithm to improve the policy's performance on the data collected from the task executions. The core idea is re-weighing training samples with approximated human
    
[^106]: 关于监督信号的信息量

    On the Informativeness of Supervision Signals. (arXiv:2211.01407v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.01407](http://arxiv.org/abs/2211.01407)

    本文使用信息论比较了常用的监督信号对表示学习性能的贡献，并为在大数据时代使用硬标签提供了理论上的证明，但对于少样本学习和分布外泛化，需要使用更丰富的监督信号。

    

    监督学习通常侧重于从人类标注的训练示例中学习可转移的表示。虽然丰富的注释（如软标签）比稀疏的注释（如硬标签）提供更多信息，但它们的收集成本也更高。我们使用信息论比较了许多常用的监督信号对于表示学习性能的贡献，以及它们的能力如何受到标签数、类别、维度和噪声等因素的影响。我们的框架为在大数据时代使用硬标签提供了理论上的证明，但对于少样本学习和分布外泛化，需要使用更丰富的监督信号。

    Supervised learning typically focuses on learning transferable representations from training examples annotated by humans. While rich annotations (like soft labels) carry more information than sparse annotations (like hard labels), they are also more expensive to collect. For example, while hard labels only provide information about the closest class an object belongs to (e.g., "this is a dog"), soft labels provide information about the object's relationship with multiple classes (e.g., "this is most likely a dog, but it could also be a wolf or a coyote"). We use information theory to compare how a number of commonly-used supervision signals contribute to representation-learning performance, as well as how their capacity is affected by factors such as the number of labels, classes, dimensions, and noise. Our framework provides theoretical justification for using hard labels in the big-data regime, but richer supervision signals for few-shot learning and out-of-distribution generalizati
    
[^107]: 人工ASMR：一种网络心理学方法

    Artificial ASMR: A Cyber-Psychological Approach. (arXiv:2210.14321v3 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2210.14321](http://arxiv.org/abs/2210.14321)

    本研究提出了一种网络心理学方法，结合信号处理、人工智能和实验心理学，通过分析ASMR音频中的循环特征，合成能触发ASMR效应的ASMR片段，从而揭示了ASMR效应触发的一种可能因素。

    

    自主感官经络反应（ASMR）在过去十年中的受欢迎程度一直在飙升，但关于ASMR效应的准确触发因素的科学研究仍然很少且不成熟，其中一个被广为认可的触发因素是ASMR片段通常提供丰富的语义信息。通过对ASMR音频中常见声学模式的关注，我们研究了音频信号的循环特征与其触发ASMR效应之间的相关性。我们采取了一种结合信号处理、人工智能和实验心理学的网络心理学方法，通过这种方法，我们能够量化与ASMR相关的声学特征，并通过随机循环模式合成ASMR片段，但不向观众提供可识别的情景，这被证明对触发ASMR效应有效。

    The popularity of Autonomous Sensory Meridian Response (ASMR) has skyrockted over the past decade, but scientific studies on what exactly triggered ASMR effect remain few and immature, one most commonly acknowledged trigger is that ASMR clips typically provide rich semantic information. With our attention caught by the common acoustic patterns in ASMR audios, we investigate the correlation between the cyclic features of audio signals and their effectiveness in triggering ASMR effects. A cyber-psychological approach that combines signal processing, artificial intelligence, and experimental psychology is taken, with which we are able to quantize ASMR-related acoustic features, and therewith synthesize ASMR clips with random cyclic patterns but not delivering identifiably scenarios to the audience, which were proven to be effective in triggering ASMR effects.
    
[^108]: 带属性辨别潜空间的语言去毒化

    Language Detoxification with Attribute-Discriminative Latent Space. (arXiv:2210.10329v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.10329](http://arxiv.org/abs/2210.10329)

    本研究提出了一种使用属性辨别潜空间进行语言去毒化的方法，通过将原始Transformer语言模型的潜空间投影到一个能够通过属性将文本进行良好分离的潜空间上，最小化内存和计算开销，实现了对有毒文本的控制。

    

    基于Transformer的语言模型已在自然语言理解任务上取得了令人瞩目的结果，但它们也可能生成包含侮辱、威胁和亵渎等有毒文本，限制了它们在现实世界中的应用。为了克服这个问题，一些文本生成方法旨在使用额外的语言模型或扰动来去毒化有毒文本。然而，先前的方法需要过多的内存、计算和时间，这在实际应用中成为了严重的瓶颈。为了解决这些限制，我们提出了一种有效 yet 高效的语言去毒化方法，使用一个带属性辨别的潜空间。具体而言，我们通过投影块和属性辨别器，将原始Transformer语言模型的潜空间投影到一个能够通过属性将文本进行良好分离的辨别性潜空间上。这允许语言模型在最小的内存和计算开销下控制文本生成为非有毒的。我们验证了我们的模型，

    Transformer-based Language Models (LMs) have achieved impressive results on natural language understanding tasks, but they can also generate toxic text such as insults, threats, and profanity, limiting their real-world applications. To overcome this issue, a few text generation approaches aim to detoxify toxic texts using additional LMs or perturbations. However, previous methods require excessive memory, computations, and time which are serious bottlenecks in their real-world application. To address such limitations, we propose an effective yet efficient method for language detoxification using an attribute-discriminative latent space. Specifically, we project the latent space of an original Transformer LM onto a discriminative latent space that well-separates texts by their attributes using a projection block and an attribute discriminator. This allows the LM to control the text generation to be non-toxic with minimal memory and computation overhead. We validate our model, Attribute-
    
[^109]: 连续学习的独占超掩码子网络训练

    Exclusive Supermask Subnetwork Training for Continual Learning. (arXiv:2210.10209v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.10209](http://arxiv.org/abs/2210.10209)

    本研究提出了一种连续学习方法ExSSNeT，通过独占超掩码子网络训练和KNN-based知识传递，解决了固定权重限制和知识积累问题。

    

    连续学习方法关注在避免灾难性遗忘的同时随着时间累积知识。最近，Wortsman等人提出了一种连续学习方法SupSup，该方法使用一个随机初始化的固定基础网络，并为每个新任务找到一个超掩码，以选择性地保留或移除每个权重以产生一个子网络。他们通过不更新网络权重来避免遗忘。虽然没有遗忘，但SupSup的性能不佳，因为固定权重限制了其表征能力。此外，在学习新任务时，模型内部没有知识的积累或传递。因此，我们提出了ExSSNeT（独占超掩码子网络训练），它进行了独有且不重叠的子网络权重训练，避免了后续任务对共享权重的冲突更新，从而提高性能的同时仍然防止遗忘。此外，我们提出了一种基于KNN的知识传递（KKT）方法。

    Continual Learning (CL) methods focus on accumulating knowledge over time while avoiding catastrophic forgetting. Recently, Wortsman et al. (2020) proposed a CL method, SupSup, which uses a randomly initialized, fixed base network (model) and finds a supermask for each new task that selectively keeps or removes each weight to produce a subnetwork. They prevent forgetting as the network weights are not being updated. Although there is no forgetting, the performance of SupSup is sub-optimal because fixed weights restrict its representational power. Furthermore, there is no accumulation or transfer of knowledge inside the model when new tasks are learned. Hence, we propose ExSSNeT (Exclusive Supermask SubNEtwork Training), that performs exclusive and non-overlapping subnetwork weight training. This avoids conflicting updates to the shared weights by subsequent tasks to improve performance while still preventing forgetting. Furthermore, we propose a novel KNN-based Knowledge Transfer (KKT)
    
[^110]: 图神经网络的通用Prompt调整方法

    Universal Prompt Tuning for Graph Neural Networks. (arXiv:2209.15240v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.15240](http://arxiv.org/abs/2209.15240)

    本文介绍了一种名为Graph Prompt Feature（GPF）的新方法，可通用地调整预先训练过的图神经网络模型，操作于输入的特征空间，能够对应任何形式的Prompt函数。

    

    近年来，Prompt调整在适应预训练模型方面引起了研究热潮。与语言领域采用的统一预训练策略不同，图形领域展示了多样化的预训练策略，设计适当的基于Prompt的图神经网络调整方法面临挑战。本文引入了一种名为Graph Prompt Feature (GPF) 的通用Prompt调整方法，可适用于任何预训练策略下的预训练图神经网络模型。GPF在输入图形的特征空间上操作，理论上可实现与任何形式的Prompt函数等效的效果。因此，我们不再需要明确说明每个预训练策略对应的Prompt函数。相反，我们采用GPF来实现调整。

    In recent years, prompt tuning has sparked a research surge in adapting pre-trained models. Unlike the unified pre-training strategy employed in the language field, the graph field exhibits diverse pre-training strategies, posing challenges in designing appropriate prompt-based tuning methods for graph neural networks. While some pioneering work has devised specialized prompting functions for models that employ edge prediction as their pre-training tasks, these methods are limited to specific pre-trained GNN models and lack broader applicability. In this paper, we introduce a universal prompt-based tuning method called Graph Prompt Feature (GPF) for pre-trained GNN models under any pre-training strategy. GPF operates on the input graph's feature space and can theoretically achieve an equivalent effect to any form of prompting function. Consequently, we no longer need to illustrate the prompting function corresponding to each pre-training strategy explicitly. Instead, we employ GPF to o
    
[^111]: 从对称中学习：具有对称行为和语言指令的元强化学习

    Learning from Symmetry: Meta-Reinforcement Learning with Symmetrical Behaviors and Language Instructions. (arXiv:2209.10656v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.10656](http://arxiv.org/abs/2209.10656)

    这篇论文研究了元强化学习中结合对称行为和语言指令的方法，以提高算法的泛化能力和学习效率。实验证明该方法能够极大地改善元强化学习的泛化能力和学习效率。

    

    元强化学习是一种有望能够使代理快速学习新任务的方法。然而，由于只有奖励提供的任务信息不足，大多数元强化学习算法在多任务场景中表现出很差的泛化能力。以语言为条件的元强化学习通过将语言指令与代理的行为进行匹配，提高了泛化能力。行为和语言指令都具有对称性，这可以加速人类对新知识的学习。因此，将对称性和语言指令结合到元强化学习中可以改善算法的泛化能力和学习效率。我们提出了一种双马尔可夫决策过程元强化学习方法，通过对称行为和语言指令，能够有效地学习新任务。我们在多个具有挑战性的操作任务中评估了我们的方法，实验结果表明我们的方法能够极大地改善元强化学习的泛化能力和学习效率。

    Meta-reinforcement learning (meta-RL) is a promising approach that enables the agent to learn new tasks quickly. However, most meta-RL algorithms show poor generalization in multi-task scenarios due to the insufficient task information provided only by rewards. Language-conditioned meta-RL improves the generalization capability by matching language instructions with the agent's behaviors. While both behaviors and language instructions have symmetry, which can speed up human learning of new knowledge. Thus, combining symmetry and language instructions into meta-RL can help improve the algorithm's generalization and learning efficiency. We propose a dual-MDP meta-reinforcement learning method that enables learning new tasks efficiently with symmetrical behaviors and language instructions. We evaluate our method in multiple challenging manipulation tasks, and experimental results show that our method can greatly improve the generalization and learning efficiency of meta-reinforcement lear
    
[^112]: 使用学习到的MDP同态映射的简单状态-动作抽象方法

    A Simple Approach for State-Action Abstraction using a Learned MDP Homomorphism. (arXiv:2209.06356v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.06356](http://arxiv.org/abs/2209.06356)

    本论文提出了一种在离散动作空间中构建同态映射的新方法，通过使用环境动力学的部分模型来推断相同状态的状态动作对，从而减小状态-动作空间的大小。

    

    动物能够在有限的经验中迅速推断出等价奖励和转移动力学的状态动作对集合。与此相反，现代强化学习系统必须通过反复试错来学习状态动作对集合的值等价性，这通常需要大量样本。已经提出了MDP同态映射的方法，将环境的观察MDP简化为抽象MDP，可以实现更高效的策略学习。因此，当可以事先构建适当的MDP同态映射时，可以取得令人印象深刻的样本效率改进，通常通过利用环境的对称性来实现。我们提出了一种新颖的方法来构建离散动作空间中的同态映射，该方法使用环境动力学的部分模型来推断哪些状态动作对导致相同的状态，从而减小状态-动作空间的大小。

    Animals are able to rapidly infer from limited experience when sets of state action pairs have equivalent reward and transition dynamics. On the other hand, modern reinforcement learning systems must painstakingly learn through trial and error that sets of state action pairs are value equivalent -- requiring an often prohibitively large amount of samples from their environment. MDP homomorphisms have been proposed that reduce the observed MDP of an environment to an abstract MDP, which can enable more sample efficient policy learning. Consequently, impressive improvements in sample efficiency have been achieved when a suitable MDP homomorphism can be constructed a priori -- usually by exploiting a practioner's knowledge of environment symmetries. We propose a novel approach to constructing a homomorphism in discrete action spaces, which uses a partial model of environment dynamics to infer which state action pairs lead to the same state -- reducing the size of the state-action space by
    
[^113]: 安全和协安全语言的一阶逻辑特征

    A first-order logic characterization of safety and co-safety languages. (arXiv:2209.02307v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.02307](http://arxiv.org/abs/2209.02307)

    本论文提出了一些新的语言类型和算法，可以降低模型检测和反应合成等问题的复杂度。

    

    线性时间逻辑（LTL）是最受欢迎的时间逻辑之一，广泛应用于计算机科学的各个领域。LTL的强大基础性质之一是其等价于无计数ω-自动机、星自由ω-正则表达式以及（通过Kamp定理）线性序的一阶理论（FO-TLO）。安全语言和协安全语言分别指只需有限前缀便可确定该单词属于或不属于该语言的语言类型。SafetyLTL（和coSafetyLTL）是LTL的一个片段，其中仅允许使用全局（存在）时间修饰词来识别安全（协安全）语言。本文的主要贡献是引入FO-TLO的片段SafetyFO以及其对偶的coSafetyFO，它们在表达能力上都是完备的（except一些边界情况）。

    Linear Temporal Logic (LTL) is one of the most popular temporal logics, that comes into play in a variety of branches of computer science. Among the various reasons of its widespread use there are its strong foundational properties: LTL is equivalent to counter-free omega-automata, to star-free omega-regular expressions, and (by Kamp's theorem) to the First-Order Theory of Linear Orders (FO-TLO). Safety and co-safety languages, where a finite prefix suffices to establish whether a word does not belong or belongs to the language, respectively, play a crucial role in lowering the complexity of problems like model checking and reactive synthesis for LTL. SafetyLTL (resp., coSafetyLTL) is a fragment of LTL where only universal (resp., existential) temporal modalities are allowed, that recognises safety (resp., co-safety) languages only. The main contribution of this paper is the introduction of a fragment of FO-TLO, called SafetyFO, and of its dual coSafetyFO, which are expressively comple
    
[^114]: SFusion: 基于自注意力的N对一多模态融合模块

    SFusion: Self-attention based N-to-One Multimodal Fusion Block. (arXiv:2208.12776v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2208.12776](http://arxiv.org/abs/2208.12776)

    SFusion是一个基于自注意力的融合模块，用于解决N对一的多模态融合问题，不需要合成或填充缺失的模态。它通过自动学习融合可用的模态，并构建共享表示来实现多模态的融合，以便下游决策模型使用。

    

    人们通过不同的感官（如视觉、听觉、嗅觉和触觉）来感知世界。处理和融合来自多个模态的信息使得人工智能更容易理解我们周围的世界。然而，当存在缺失的模态时，在不同的情况下可用的模态数量是不同的，这就导致了一个N对一的融合问题。为了解决这个问题，我们提出了一个基于自注意力的融合模块，称为SFusion。与预设的公式化或基于卷积的方法不同，所提出的模块自动学习融合可用的模态，而不是合成或填充缺失的模态。具体而言，从上游处理模型提取的特征表示被投影为令牌，并输入自注意力模块以生成潜在的多模态相关性。然后，引入模态注意机制构建一个共享表示，可以被下游决策模型使用。所提出的SFusion模块能够有效地解决N对一的多模态融合问题。

    People perceive the world with different senses, such as sight, hearing, smell, and touch. Processing and fusing information from multiple modalities enables Artificial Intelligence to understand the world around us more easily. However, when there are missing modalities, the number of available modalities is different in diverse situations, which leads to an N-to-One fusion problem. To solve this problem, we propose a self-attention based fusion block called SFusion. Different from preset formulations or convolution based methods, the proposed block automatically learns to fuse available modalities without synthesizing or zero-padding missing ones. Specifically, the feature representations extracted from upstream processing model are projected as tokens and fed into self-attention module to generate latent multimodal correlations. Then, a modal attention mechanism is introduced to build a shared representation, which can be applied by the downstream decision model. The proposed SFusio
    
[^115]: 无Softmax的线性变换器

    Softmax-free Linear Transformers. (arXiv:2207.03341v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2207.03341](http://arxiv.org/abs/2207.03341)

    这项研究提出了无softmax的线性变换器(SOFT)，用高斯核函数来逼近自注意机制，以改善视觉识别领域中现有方法的局限性。

    

    视觉变换器(ViTs)在视觉感知任务的最新成果中起到了推动作用。ViTs的核心自注意机制在计算和内存使用方面具有二次复杂度。这促使我们开发出在线性复杂度下逼近自注意的方法。然而，本研究的深入分析发现，现有方法在视觉识别方面要么在理论上有缺陷，要么在实践中无效。我们发现它们的局限性来源于在逼近过程中继承了基于softmax的自注意机制，即使用softmax函数对令牌特征向量之间的缩放点积进行归一化。由于存在这个softmax操作，挑战了任何后续的线性化工作。基于这一观点，我们提出了一系列无softmax的变换器(SOFT)。具体而言，我们采用高斯核函数来替代点积相似度，从而实现全自注意矩阵的逼近。

    Vision transformers (ViTs) have pushed the state-of-the-art for visual perception tasks. The self-attention mechanism underpinning the strength of ViTs has a quadratic complexity in both computation and memory usage. This motivates the development of approximating the self-attention at linear complexity. However, an in-depth analysis in this work reveals that existing methods are either theoretically flawed or empirically ineffective for visual recognition. We identify that their limitations are rooted in the inheritance of softmax-based self-attention during approximations, that is, normalizing the scaled dot-product between token feature vectors using the softmax function. As preserving the softmax operation challenges any subsequent linearization efforts. By this insight, a family of Softmax-Free Transformers (SOFT) are proposed. Specifically, a Gaussian kernel function is adopted to replace the dot-product similarity, enabling a full self-attention matrix to be approximated under l
    
[^116]: 《全球AI伦理：200个AI治理指南和建议的综述》

    Worldwide AI Ethics: a review of 200 guidelines and recommendations for AI governance. (arXiv:2206.11922v5 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2206.11922](http://arxiv.org/abs/2206.11922)

    本篇论文回顾了200个AI治理指南和建议，通过对这些文档内容和性质的可视化，旨在了解各机构间AI伦理原则存在的共识和相似点，为未来的法规辩论提供启示。

    

    在过去的十年中，一些组织已经制定了文件，旨在规范和推动我们最近和快速发展的AI技术的指南。然而，除了一些领域的元分析和批判性评论外，这些文件中呈现的完整思想光谱尚未得到分析。在这项工作中，我们试图扩展过去研究人员所做的工作，创建一个更好的数据可视化工具，以了解各机构所倡导原则之间是否存在共识或相似之处，这可能会激发未来的法规辩论。我们还通过对200份文档样本的方法论结果进行批判性分析，提出了一些初步的想法和问题，以指导研究的连续性。

    In the last decade, several organizations have produced documents intended to standardize, in the normative sense, and promote guidance to our recent and rapid AI development. However, the full spectrum of ideas presented in these documents has not yet been analyzed, except for a few meta-analyses and critical reviews of the field. In this work, we seek to expand on the work done by past researchers and create a tool for better data visualization of the contents and nature of these documents, to understand whether there is consensus or similarity between the principles espoused by various institutions, which may inspire debates on future regulations. We also provide some preliminary thoughts and questions that could guide the continuity of the research through a critical analysis of the results acquired by our methodology into a sample size of 200 documents.
    
[^117]: 消息传递神经网络对于知识图谱补全真的有帮助吗？

    Are Message Passing Neural Networks Really Helpful for Knowledge Graph Completion?. (arXiv:2205.10652v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2205.10652](http://arxiv.org/abs/2205.10652)

    这项研究发现简单的多层感知器（MLP）模型在知识图谱补全任务上能够与消息传递神经网络（MPNNs）相媲美，暗示消息传递可能不像之前认为的那样关键。评分函数和损失函数设计对于模型性能有更大影响。

    

    知识图谱（KG）在各种应用中发挥了重要作用。尽管在创建和维护方面做出了巨大努力，但即使是最大的KG也远未完备。因此，知识图谱补全（KGC）已成为KG研究中最关键的任务之一。最近，这一领域的大量文献都集中在使用消息传递（图）神经网络（MPNNs）来学习强大的嵌入表示。这些方法的成功自然归因于相比于简单的多层感知器（MLP）模型，使用了额外的消息传递（MP）组件的MPNNs。在这项工作中，我们发现令人惊讶的是，简单的MLP模型能够达到与MPNNs相当的性能，这表明MP可能并不像之前认为的那样关键。通过进一步探索，我们展示了仔细的评分函数和损失函数设计对于KGC模型性能有更强的影响。这表明以前的工作中对评分函数设计、损失函数设计和MP的混淆。

    Knowledge graphs (KGs) facilitate a wide variety of applications. Despite great efforts in creation and maintenance, even the largest KGs are far from complete. Hence, KG completion (KGC) has become one of the most crucial tasks for KG research. Recently, considerable literature in this space has centered around the use of Message Passing (Graph) Neural Networks (MPNNs), to learn powerful embeddings. The success of these methods is naturally attributed to the use of MPNNs over simpler multi-layer perceptron (MLP) models, given their additional message passing (MP) component. In this work, we find that surprisingly, simple MLP models are able to achieve comparable performance to MPNNs, suggesting that MP may not be as crucial as previously believed. With further exploration, we show careful scoring function and loss function design has a much stronger influence on KGC model performance. This suggests a conflation of scoring function design, loss function design, and MP in prior work, wi
    
[^118]: “跨摄像头轨迹辅助相机网络中的人员检索”

    Cross-Camera Trajectories Help Person Retrieval in a Camera Network. (arXiv:2204.12900v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.12900](http://arxiv.org/abs/2204.12900)

    本文提出了一种基于跨摄像头轨迹生成的行人检索框架，该框架在时间和空间信息中进行了结合。通过提取跨摄像头轨迹并进行条件随机场模型和受限非负矩阵分解的优化，最终提高了检索效果。

    

    本文关注如何从一个非覆盖的摄像头网络中的多个视频中检索出一个查询对象的身份。目前已有的方法往往依赖于视觉匹配或者考虑时间约束，但是忽略了摄像头网格的空间信息。为了解决这个问题，我们提出了一种基于跨摄像头轨迹生成的行人检索框架，将时间和空间信息结合起来。为了获取行人轨迹，我们提出了一种新颖的跨摄像头时空模型，它结合了行人的行走习惯和相邻摄像头之间的路径布局，形成了一个联合概率分布。这样的时空模型可以基于稀疏采样的行人数据在摄像头网络中实现。基于这个时空模型，可以通过条件随机场模型提取跨摄像头轨迹，并通过受限非负矩阵分解进行进一步优化。最后，文章提出了一种轨迹重新排序技术来提高检索效果。

    We are concerned with retrieving a query person from multiple videos captured by a non-overlapping camera network. Existing methods often rely on purely visual matching or consider temporal constraints but ignore the spatial information of the camera network. To address this issue, we propose a pedestrian retrieval framework based on cross-camera trajectory generation, which integrates both temporal and spatial information. To obtain pedestrian trajectories, we propose a novel cross-camera spatio-temporal model that integrates pedestrians' walking habits and the path layout between cameras to form a joint probability distribution. Such a spatio-temporal model among a camera network can be specified using sparsely sampled pedestrian data. Based on the spatio-temporal model, cross-camera trajectories can be extracted by the conditional random field model and further optimized by restricted non-negative matrix factorization. Finally, a trajectory re-ranking technique is proposed to improv
    
[^119]: 向视觉可管理学习迈进：一个用于可管理分割和识别的基准。 (arXiv:2203.14092v2 [cs.CV] UPDATED)

    Towards Visual Affordance Learning: A Benchmark for Affordance Segmentation and Recognition. (arXiv:2203.14092v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2203.14092](http://arxiv.org/abs/2203.14092)

    该论文介绍了一个大规模的多视角RGBD视觉可管理学习数据集，其中包含了37个对象类别的47210个图像，并且每个图像都带有15个视觉可管理类别的注释。

    

    对于计算机视觉中的识别、检测和分割任务，对象的物理和纹理属性已得到广泛研究。许多数据集，如大规模的ImageNet，已经被提出用于使用数据饥饿的深度神经网络进行特征学习和手工特征提取。为了智能地与对象进行交互，机器人和智能机器需要除了传统的物理/纹理属性之外的推理能力，以及理解/学习被称为视觉可管理的视觉提示，用于可管理的识别、检测和分割。到目前为止，还没有公开可用的用于视觉可管理理解和学习的大规模数据集。在本文中，我们介绍了一个大规模的多视角RGBD视觉可管理学习数据集，这是一个包含37个对象类别的47210个RGBD图像的基准，每个图像都带有15个视觉可管理类别的注释。据我们所知，这是有史以来第一个也是最大的多视角RGBD视觉可管理学习数据集。

    The physical and textural attributes of objects have been widely studied for recognition, detection and segmentation tasks in computer vision.~A number of datasets, such as large scale ImageNet, have been proposed for feature learning using data hungry deep neural networks and for hand-crafted feature extraction. To intelligently interact with objects, robots and intelligent machines need the ability to infer beyond the traditional physical/textural attributes, and understand/learn visual cues, called visual affordances, for affordance recognition, detection and segmentation. To date there is no publicly available large dataset for visual affordance understanding and learning. In this paper, we introduce a large scale multi-view RGBD visual affordance learning dataset, a benchmark of 47210 RGBD images from 37 object categories, annotated with 15 visual affordance categories. To the best of our knowledge, this is the first ever and the largest multi-view RGBD visual affordance learning 
    
[^120]: 用于简单遗憾最小化的元学习

    Meta-Learning for Simple Regret Minimization. (arXiv:2202.12888v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.12888](http://arxiv.org/abs/2202.12888)

    本论文提出了用于在赌博机中进行简单遗憾最小化的元学习框架，并提出了首个贝叶斯和频率派元学习算法。贝叶斯算法具有先验分布并且具有较小的元简单遗憾，而频率派算法更通用且可以在更多的设置中进行分析。通过将算法应用于不同的赌博机问题，我们验证了理论的有效性。

    

    我们提出了一个用于在赌博机中简单遗憾最小化的元学习框架。在这个框架中，学习代理与一系列赌博机任务进行交互，这些任务是从一个未知的先验分布中独立采样的，并学习其元参数以在未来任务中表现更好。我们提出了这个设置的第一个贝叶斯和频率派元学习算法。贝叶斯算法可以访问元参数的先验分布，并且其在$m$个赌博机任务中，时间界为$n$的元简单遗憾仅为$\tilde{O}(m / \sqrt{n})$。另一方面，频率派算法的元简单遗憾为$\tilde{O}(\sqrt{m} n + m/ \sqrt{n})$。尽管遗憾更大，但频率派算法更通用，因为它不需要元参数的先验分布，并且可以在更多的设置中进行分析。我们通过将算法应用于几类赌博机问题来验证我们的理论。

    We develop a meta-learning framework for simple regret minimization in bandits. In this framework, a learning agent interacts with a sequence of bandit tasks, which are sampled i.i.d.\ from an unknown prior distribution, and learns its meta-parameters to perform better on future tasks. We propose the first Bayesian and frequentist meta-learning algorithms for this setting. The Bayesian algorithm has access to a prior distribution over the meta-parameters and its meta simple regret over $m$ bandit tasks with horizon $n$ is mere $\tilde{O}(m / \sqrt{n})$. On the other hand, the meta simple regret of the frequentist algorithm is $\tilde{O}(\sqrt{m} n + m/ \sqrt{n})$. While its regret is worse, the frequentist algorithm is more general because it does not need a prior distribution over the meta-parameters. It can also be analyzed in more settings. We instantiate our algorithms for several classes of bandit problems. Our algorithms are general and we complement our theory by evaluating them
    
[^121]: 跨转录本、音频和视频的政治演讲Deepfakes的人类检测

    Human Detection of Political Speech Deepfakes across Transcripts, Audio, and Video. (arXiv:2202.12883v3 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2202.12883](http://arxiv.org/abs/2202.12883)

    这项研究通过实验发现，人们在判断政治演讲的真实性时，音频和视觉信息对于准确区分真实和伪造的Deepfakes更为重要，而错误信息的基准影响较小。

    

    最近技术的飞速进步使得超逼真的视觉效果引发了人们对深度伪造的政治演讲视频是否很快就会与真实录像无法区分的担忧。传播理论中的常识预测，当同一个故事以视频形式和文本形式展示时，人们更容易上当受骗。我们进行了4个预先登记的随机实验，涉及2015名参与者，以评估人类在不同的错误信息基准、音频来源和媒体形式下，是否能够准确区分真实的政治演讲和伪造的演讲。我们发现错误信息的基准对辨别判断影响较小，使用最先进的文本转语音算法生成的带有音频的Deepfakes较使用声音演员音频的相同Deepfakes更难辨别。此外，我们发现音频和视觉信息比仅有文本能够更准确地进行辨别：人类的辨别更依赖于事物是如何被表达的，音频-视觉

    Recent advances in technology for hyper-realistic visual effects provoke the concern that deepfake videos of political speeches will soon be visually indistinguishable from authentic video recordings. The conventional wisdom in communication theory predicts people will fall for fake news more often when the same version of a story is presented as a video versus text. We conduct 4 pre-registered randomized experiments with 2,015 participants to evaluate how accurately humans distinguish real political speeches from fabrications across base rates of misinformation, audio sources, and media modalities. We find base rates of misinformation minimally influence discernment and deepfakes with audio produced by the state-of-the-art text-to-speech algorithms are harder to discern than the same deepfakes with voice actor audio. Moreover, we find audio and visual information enables more accurate discernment than text alone: human discernment relies more on how something is said, the audio-visual
    
[^122]: 超越单一模型的持续学习

    Continual Learning Beyond a Single Model. (arXiv:2202.09826v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.09826](http://arxiv.org/abs/2202.09826)

    本论文研究了超越单一模型的持续学习。通过使用集成模型，能够改善持续性能，但随着模型数量增加，计算成本也会增加。为了解决这个问题，提出了一种计算成本较低的算法，能够在运行时间上与单一模型相当，并享有集成的性能优势。

    

    在持续学习中，越来越多的研究集中在灾难性遗忘问题上。虽然有很多方法试图缓解这个问题，但大多数方法都假设在持续学习中只有一个模型。在这项工作中，我们质疑这个假设，并展示了使用集成模型可以是一个简单而有效的方法来提高持续性能。然而，随着模型数量的增加，集成的训练和推断成本可能会显著增加。受到这个限制的启发，我们研究了不同的集成模型，以了解它们在持续学习场景中的优点和缺点。最后，为了克服集成的高计算成本，我们利用神经网络子空间的最新进展，提出了一种计算成本较低的算法，其运行时间与单一模型相当，但享有集成的性能优势。

    A growing body of research in continual learning focuses on the catastrophic forgetting problem. While many attempts have been made to alleviate this problem, the majority of the methods assume a single model in the continual learning setup. In this work, we question this assumption and show that employing ensemble models can be a simple yet effective method to improve continual performance. However, ensembles' training and inference costs can increase significantly as the number of models grows. Motivated by this limitation, we study different ensemble models to understand their benefits and drawbacks in continual learning scenarios. Finally, to overcome the high compute cost of ensembles, we leverage recent advances in neural network subspace to propose a computationally cheap algorithm with similar runtime to a single model yet enjoying the performance benefits of ensembles.
    
[^123]: 通过多目标神经架构搜索学习可解释模型

    Learning Interpretable Models Through Multi-Objective Neural Architecture Search. (arXiv:2112.08645v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.08645](http://arxiv.org/abs/2112.08645)

    本研究提出了一种多目标分布式神经架构搜索框架，旨在优化深度神经网络的任务性能和可解释性。利用非支配排序遗传算法（NSGA-II）和可解释人工智能（XAI）技术，奖励那些可以被领域专家更好理解的架构。

    

    深度学习的巨大进展在各个领域取得了前所未有的成就。尽管深度神经网络的性能无可置疑，但其架构设计和可解释性却并非易事。为了自动化神经网络架构设计，引入了神经架构搜索（NAS）的研究。最近的进展通过利用分布式计算和新颖的优化算法使这些方法更为实用。然而，在优化可解释性方面的研究仍相对较少。为此，我们提出了一个多目标分布式NAS框架，旨在优化任务性能和“可视识别性”，这是解释性的一种代理度量。我们利用非支配排序遗传算法（NSGA-II）和可解释人工智能（XAI）技术，奖励那些可以被领域专家更好理解的架构。该框架在几个图像分类数据集上进行了评估。

    Monumental advances in deep learning have led to unprecedented achievements across various domains. While the performance of deep neural networks is indubitable, the architectural design and interpretability of such models are nontrivial. Research has been introduced to automate the design of neural network architectures through neural architecture search (NAS). Recent progress has made these methods more pragmatic by exploiting distributed computation and novel optimization algorithms. However, there is little work in optimizing architectures for interpretability. To this end, we propose a multi-objective distributed NAS framework that optimizes for both task performance and "introspectability," a surrogate metric for aspects of interpretability. We leverage the non-dominated sorting genetic algorithm (NSGA-II) and explainable AI (XAI) techniques to reward architectures that can be better comprehended by domain experts. The framework is evaluated on several image classification datase
    
[^124]: 自适应前向模拟时间的强化学习在半马尔科夫模型中的机器人导航应用

    Reinforcement Learning for Robot Navigation with Adaptive Forward Simulation Time (AFST) in a Semi-Markov Model. (arXiv:2108.06161v4 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2108.06161](http://arxiv.org/abs/2108.06161)

    本文提出了一种基于深度强化学习的机器人导航方法，通过自适应前向模拟时间 (AFST) 在半马尔科夫模型中进行建模，克服了导航中的局部最小问题，并通过减少动作空间的维度和改进分布式近端策略优化 (DPPO) 算法来优化模型，在各种未知环境中取得了良好的效果。

    

    深度强化学习算法已经被证明对机器人导航非常有效，尤其在未知环境中，通过将感知输入直接映射为机器人控制命令。然而，大多数现有方法忽略了导航中的局部最小问题，因此无法处理复杂的未知环境。本文提出了第一个基于深度强化学习的导航方法，该方法使用连续动作空间的半马尔科夫决策过程模型，并命名为自适应前向模拟时间 (AFST)，以克服这个问题。具体而言，我们通过减少动作空间的维度，并改进分布式近端策略优化 (DPPO) 算法来适应指定的半马尔科夫问题，修改其广义优势估计 (GAE) 以更好地估计 SMDP 中的策略梯度。在各种未知环境中的实验证明了 AFST 的有效性。

    Deep reinforcement learning (DRL) algorithms have proven effective in robot navigation, especially in unknown environments, by directly mapping perception inputs into robot control commands. However, most existing methods ignore the local minimum problem in navigation and thereby cannot handle complex unknown environments. In this paper, we propose the first DRL-based navigation method modeled by a semi-Markov decision process (SMDP) with continuous action space, named Adaptive Forward Simulation Time (AFST), to overcome this problem. Specifically, we reduce the dimensions of the action space and improve the distributed proximal policy optimization (DPPO) algorithm for the specified SMDP problem by modifying its GAE to better estimate the policy gradient in SMDPs. Experiments in various unknown environments demonstrate the effectiveness of AFST.
    
[^125]: 批量强化学习中被动数据采集的诅咒

    The Curse of Passive Data Collection in Batch Reinforcement Learning. (arXiv:2106.09973v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.09973](http://arxiv.org/abs/2106.09973)

    本文研究了批量强化学习中被动数据采集的代价问题，并发现与主动数据采集相比，被动采集的样本复杂性呈指数级增加。

    

    在高风险应用中，主动实验可能被认为风险太大，因此通常会被动采集数据。虽然在简单情况下，如在赌博机中，被动和主动数据采集的效果相似，但在从带有可控状态的系统中收集数据时，被动采样的代价可能会更高。本文的主要重点是对这种代价的特征化。例如，在具有$\mathrm{S}$个状态和$\mathrm{A}$个动作的离散状态-动作马尔可夫决策过程(MDP)中学习时，我们展示了即使使用最佳（但被动选择的）日志记录策略，也需要（且足够）获得$\epsilon$-最优策略的$\Omega(\mathrm{A}^{\min(\mathrm{S}-1, H)}/\varepsilon^2)$个回合，其中$H$是回合长度。请注意，这表明与主动数据采集相比，样本复杂性呈指数级增加，这个结果是可以预料的，但据我们所知，尚未发表。

    In high stake applications, active experimentation may be considered too risky and thus data are often collected passively. While in simple cases, such as in bandits, passive and active data collection are similarly effective, the price of passive sampling can be much higher when collecting data from a system with controlled states. The main focus of the current paper is the characterization of this price. For example, when learning in episodic finite state-action Markov decision processes (MDPs) with $\mathrm{S}$ states and $\mathrm{A}$ actions, we show that even with the best (but passively chosen) logging policy, $\Omega(\mathrm{A}^{\min(\mathrm{S}-1, H)}/\varepsilon^2)$ episodes are necessary (and sufficient) to obtain an $\epsilon$-optimal policy, where $H$ is the length of episodes. Note that this shows that the sample complexity blows up exponentially compared to the case of active data collection, a result which is not unexpected, but, as far as we know, have not been published
    
[^126]: 一种统一的逻辑框架用于分类器系统的解释

    A unified logical framework for explanations in classifier systems. (arXiv:2105.14452v6 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2105.14452](http://arxiv.org/abs/2105.14452)

    本研究提出了一种以ceteris paribus为基础的模态语言，用于解释二进制分类器及其属性的推理。我们证明了两个关于语言基数的证明系统的完备性，并研究了无限变量和有限变量情况下的可满足性检查问题。我们还使用这种语言来形式化多种解释概念，包括对事实、对比和反事实解释以及偏见。

    

    在可解释的人工智能（XAI）领域中，布尔函数对于解释二进制分类器越来越受关注。传统的布尔函数方法采用命题逻辑。我们提出了一种以ceteris paribus为基础的模态语言，支持对二进制输入分类器及其属性进行推理。我们研究了一系列分类器模型，将其公理化为关于语言基数的两个证明系统，并证明了我们公理系统的完备性。此外，我们证明了在无限变量情况下，我们模态语言的可满足性检查问题是NEXPTIME完全的，而在有限变量情况下，该问题变为多项式复杂度。我们还在无限变量情况下确定了一个有趣的NP片段。我们利用这种语言来形式化对事实条件以及包括从属、对比和反事实解释以及偏见在内的各种解释概念。最后，我们提出了两种扩展的方法。

    Recent years have witnessed a renewed interest in Boolean function in explaining binary classifiers in the field of explainable AI (XAI). The standard approach of Boolean function is propositional logic. We present a modal language of a ceteris paribus nature which supports reasoning about binary input classifiers and their properties. We study a family of classifier models, axiomatize it as two proof systems regarding the cardinality of the language and show completeness of our axiomatics. Moreover, we prove that satisfiability checking problem for our modal language is NEXPTIME-complete in the infinite-variable case, while it becomes polynomial in the finite-variable case. We furthermore identify an interesting NP fragment of our language in the infinite-variable case. We leverage the language to formalize counterfactual conditional as well as a variety of notions of explanation including abductive, contrastive and counterfactual explanations, and biases. Finally, we present two exte
    
[^127]: 通过一步式绳索多目标学习处理噪声标签及其在幽门螺杆菌分割中的应用

    Handling Noisy Labels via One-Step Abductive Multi-Target Learning and Its Application to Helicobacter Pylori Segmentation. (arXiv:2011.14956v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2011.14956](http://arxiv.org/abs/2011.14956)

    本文研究了处理噪声标签的新方法，特别针对医学组织病理学图像分析中的困难情况。通过一步式绳索多目标学习，该方法克服了标签中存在的复杂噪声和评估策略不明确的问题。

    

    由于在许多现实场景中缺乏准确的地面实况标签，因此从噪声标签中学习是一个重要问题。在实践中，针对这个问题的不同方法首先对可能有噪声标签的实例进行一些纠正，然后用纠正信息更新预测模型。然而，在医学组织病理学全切片图像分析（MHWSIA）等特定领域中，专家往往难以或甚至无法手动实现无噪声的地面实况标签，导致标签存在复杂噪声。这种情况引发了两个更加困难的问题：1）由于标签中存在复杂噪声，先前方法纠正可能有噪声标签的实例的方法学存在局限性；2）由于收集无噪声地面实况标签非常困难，验证/测试的适当评估策略不明确。本文重点研究了缓解以上问题的方法。

    Learning from noisy labels is an important concern because of the lack of accurate ground-truth labels in plenty of real-world scenarios. In practice, various approaches for this concern first make some corrections corresponding to potentially noisy-labeled instances, and then update predictive model with information of the made corrections. However, in specific areas, such as medical histopathology whole slide image analysis (MHWSIA), it is often difficult or even impossible for experts to manually achieve the noisy-free ground-truth labels which leads to labels with complex noise. This situation raises two more difficult problems: 1) the methodology of approaches making corrections corresponding to potentially noisy-labeled instances has limitations due to the complex noise existing in labels; and 2) the appropriate evaluation strategy for validation/testing is unclear because of the great difficulty in collecting the noisy-free ground-truth labels. In this paper, we focus on allevia
    
[^128]: 深度强化学习中的迁移学习综述

    Transfer Learning in Deep Reinforcement Learning: A Survey. (arXiv:2009.07888v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2009.07888](http://arxiv.org/abs/2009.07888)

    这篇综述调查了深度强化学习领域中的迁移学习方法的最新进展，并提供了一个对这些方法进行分类的框架。分析了它们的目标、方法学、兼容的强化学习背景以及实际应用，并探讨了迁移学习与其他相关主题之间的联系。

    

    强化学习是解决序列决策问题的学习范式。近年来，随着深度神经网络的快速发展，强化学习取得了显著的进展。除了在机器人和游戏等诸多领域中具有良好前景的强化学习，迁移学习作为一种解决强化学习面临的各种挑战的方法已经出现，通过从外部专业知识中转移知识，以提高学习过程的效率和效果。在这项综述中，我们系统地调查了深度强化学习领域中的迁移学习方法的最新进展。具体而言，我们提供了一个对最先进的迁移学习方法进行分类的框架，在此框架下分析了它们的目标、方法学、兼容的强化学习背景以及实际应用。我们还探讨了迁移学习与其他相关主题之间的联系。

    Reinforcement learning is a learning paradigm for solving sequential decision-making problems. Recent years have witnessed remarkable progress in reinforcement learning upon the fast development of deep neural networks. Along with the promising prospects of reinforcement learning in numerous domains such as robotics and game-playing, transfer learning has arisen to tackle various challenges faced by reinforcement learning, by transferring knowledge from external expertise to facilitate the efficiency and effectiveness of the learning process. In this survey, we systematically investigate the recent progress of transfer learning approaches in the context of deep reinforcement learning. Specifically, we provide a framework for categorizing the state-of-the-art transfer learning approaches, under which we analyze their goals, methodologies, compatible reinforcement learning backbones, and practical applications. We also draw connections between transfer learning and other relevant topics 
    

