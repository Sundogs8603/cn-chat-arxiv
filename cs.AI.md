# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Interactive Motion Planning for Autonomous Vehicles with Joint Optimization.](http://arxiv.org/abs/2310.18301) | 本论文介绍了一种交互式联合规划方法，将模型预测控制（MPC）与基于深度学习的轨迹预测模型结合，实现在高度交互的驾驶场景中为自主驾驶车辆规划安全的运动路径。 |
| [^2] | [Is Channel Independent strategy optimal for Time Series Forecasting?.](http://arxiv.org/abs/2310.17658) | 本文重新考虑了当前通道独立策略在时间序列预测中是否是最佳解决方案，并提出了一种称为CSC的通道自聚类策略来增强性能并减小参数大小。 |
| [^3] | [On existence, uniqueness and scalability of adversarial robustness measures for AI classifiers.](http://arxiv.org/abs/2310.14421) | 本文研究了针对AI分类器的对抗鲁棒性度量的存在性、唯一性和可扩展性，提出了可以验证的数学条件，并在合成基准测试和生物医学应用中进行了实际计算和解释。 |
| [^4] | [A Critical Survey on Fairness Benefits of XAI.](http://arxiv.org/abs/2310.13007) | 这个批判性调查分析了可解释的人工智能（XAI）与公平之间的关系，指出XAI在实现公平理想方面存在潜力和限制，呼吁更具体地说明XAI方法如何帮助解决公平理想。 |
| [^5] | [Eliminating Reasoning via Inferring with Planning: A New Framework to Guide LLMs' Non-linear Thinking.](http://arxiv.org/abs/2310.12342) | 本文提出了一种名为推断性排除提示（IEP）的新框架，通过结合排除和推理的原则，引导LLM进行非线性思考。IEP通过规划和自然语言推理，可以模拟复杂的人类思维过程，比其他方法具有更广泛的视角。 |
| [^6] | [ChatGPT for Computational Topology.](http://arxiv.org/abs/2310.07570) | 该论文介绍了如何利用ChatGPT桥接理论拓扑概念和计算拓扑实现之间的差距，展示了在没有编码技能的情况下，通过ChatGPT的帮助，纯粹的理论家如何将数学公式和概念转化为功能性的计算拓扑代码。 |
| [^7] | [AdaptNet: Policy Adaptation for Physics-Based Character Control.](http://arxiv.org/abs/2310.00239) | AdaptNet是一种基于物理的角色控制的策略调整方法，通过修改现有策略的潜在空间，可以从类似任务中快速学习到新的行为，显著提高训练效率。 |
| [^8] | [Are Deep Learning Classification Results Obtained on CT Scans Fair and Interpretable?.](http://arxiv.org/abs/2309.12632) | 深度学习在CT扫描分类中的结果往往只关注准确性，而忽视了公正性和解释性，导致模型不可信和不适用于真实场景。 |
| [^9] | [Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping.](http://arxiv.org/abs/2309.06038) | 本文提出了一个名为“人类助力灵巧抓取”的新型任务，通过使用Grasping Gradient Field和基于历史条件的残差策略，训练控制机器人手指以适应不同用户意图和物体几何形状的灵巧抓取操作。 |
| [^10] | [When Do Program-of-Thoughts Work for Reasoning?.](http://arxiv.org/abs/2308.15452) | 提出了复杂性影响推理分数（CIRS）来衡量编程语言对推理能力的影响，发现并非所有复杂性的代码数据都可以被学习或理解，适当的复杂性水平对于改善推理能力至关重要。 |
| [^11] | [Expressive probabilistic sampling in recurrent neural networks.](http://arxiv.org/abs/2308.11809) | 该论文探索了循环神经电路如何从复杂概率分布中进行抽样，并证明了带有单独输出单元的神经电路的发放率动力学可以从任意概率分布中进行抽样。 |
| [^12] | [Improving Nonalcoholic Fatty Liver Disease Classification Performance With Latent Diffusion Models.](http://arxiv.org/abs/2307.06507) | 本研究通过结合使用扩散模型生成的合成图像和真实图像，提高了非酒精性脂肪性肝病分类的性能。 |
| [^13] | [Resetting the Optimizer in Deep RL: An Empirical Study.](http://arxiv.org/abs/2306.17833) | 在深度强化学习中，当优化问题的风景在不同迭代中差异较大时，重置优化器的内部参数可以避免污染和提高性能。 |
| [^14] | [Energy Optimization for HVAC Systems in Multi-VAV Open Offices: A Deep Reinforcement Learning Approach.](http://arxiv.org/abs/2306.13333) | 本研究提出了一种基于低复杂度深度强化学习模型的多输入多输出体系结构，以最小化可控因素的数量，实现了对多变风量开放式办公室 HVAC 系统的能源优化，与传统系统相比能源消耗减少了 37%，且温度范围违规率极低 (<1%)。 |
| [^15] | [AdCraft: An Advanced Reinforcement Learning Benchmark Environment for Search Engine Marketing Optimization.](http://arxiv.org/abs/2306.11971) | AdCraft是一种高级强化学习基准环境，用于模拟出价和预算变化的搜索引擎营销(SEM)活动，可用于评估和提高SEM出价和预算管理相关的RL算法的鲁棒性。 |
| [^16] | [BackpropTools: A Fast, Portable Deep Reinforcement Learning Library for Continuous Control.](http://arxiv.org/abs/2306.03530) | BackpropTools是一款快速、可移植的连续控制深度强化学习库，它通过模板元编程提供紧密集成的可组合组件，并在异构平台集合上无缝使用，同时在连续控制问题的深度RL代理高效可扩展训练方面具有优势。由于其可移植性和实时保证，它成为了在嵌入式设备上部署学来的策略的有价值的工具。 |
| [^17] | [A Categorical Representation Language and Computational System for Knowledge-Based Planning.](http://arxiv.org/abs/2305.17208) | 本文提出了一种基于范畴论的世界状态表示和转换方法，可以有效处理结构化知识，并且提供了使用知识图和关系数据库来建模规划中世界状态和更新的正式语义。 |
| [^18] | [Selectively Answering Ambiguous Questions.](http://arxiv.org/abs/2305.14613) | 本研究调查了解决模糊问题的方法，通过定量测量模型输出中的重复性，找出了在含糊问题集中回答高精度子集问题的最可靠方法。这种基于采样的方法可以有效解决问题回答中的歧义，并提高语言模型的可靠性。 |
| [^19] | [GPT4Table: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study.](http://arxiv.org/abs/2305.13062) | 本文设计了一个基准测试来评估大型语言模型（LLMs）对结构化表格数据的理解能力，并发现不同的输入选择会对性能产生影响。在基准测试的基础上，提出了“自我增强”技术以改善理解能力。 |
| [^20] | [Explaining black box text modules in natural language with language models.](http://arxiv.org/abs/2305.09863) | 本文介绍了一种名为Summarize and Score（SASC）的方法，该方法可以自动获取黑盒文本模块的自然语言解释以及解释可靠程度的分数。研究者们已经在合成模块和BERT模型中使用SASC，让我们可以解释模块的选择性，这对于增强大型语言模型的可解释性非常重要。 |
| [^21] | [Is My Prediction Arbitrary? Measuring Self-Consistency in Fair Classification.](http://arxiv.org/abs/2301.11562) | 在公平分类中，模型的预测方差是一个重要但鲜为人知的误差来源问题。作者提出了一个自洽性标准来衡量测量和减少随意性。作者还开发了一个算法来处理随意性预测，并通过实证研究揭示了当前模型无法处理某些类型数据的问题。 |
| [^22] | [Editing Language Model-based Knowledge Graph Embeddings.](http://arxiv.org/abs/2301.10405) | 本文提出了一种新的任务——编辑基于语言模型的知识图谱嵌入，旨在实现对KG嵌入的数据高效和快速更新。针对这一任务，提出了一个简单而强大的方案——KGEditor，可以更好地更新特定事实而不影响其余部分的性能。 |
| [^23] | [Deanthropomorphising NLP: Can a Language Model Be Conscious?.](http://arxiv.org/abs/2211.11483) | 本文讨论了关于使用Transformer架构的预训练语言模型LaMDA是否具有意识的说法。作者认为语言模型不可能具有意识，而LaMDA没有比其他类似模型更具先进性。 |
| [^24] | [Reward is not Necessary: How to Create a Compositional Self-Preserving Agent for Life-Long Learning.](http://arxiv.org/abs/2211.10851) | 这项研究表明，我们可以使用内在动机衡量标准而不依赖于奖励来创建一个具有自我保护能力的智能体。 |
| [^25] | [On the Need and Applicability of Causality for Fair Machine Learning.](http://arxiv.org/abs/2207.04053) | 本论文探讨了因果关系在公平机器学习中的必要性和适用性，强调了非因果预测的社会影响和法律反歧视过程依赖于因果主张。同时讨论了在实际场景中应用因果关系所面临的挑战和限制，并提出了可能的解决方案。 |
| [^26] | [The Causal Structure of Semantic Ambiguities.](http://arxiv.org/abs/2206.06807) | 本文使用Gogioso和Pinzani在QPL 2021中提出的束理论模型，为语义歧义的两个特征（不同可能解释的联合可信度和某些词在过程中扮演更重要角色的因果结构）进行建模。通过对心理语言学文献中的歧义短语数据集进行分析，研究人员对人类对于这些歧义的判断进行了实证测量。 |

# 详细

[^1]: 自主驾驶车辆的交互式运动规划与联合优化

    Interactive Motion Planning for Autonomous Vehicles with Joint Optimization. (arXiv:2310.18301v1 [cs.RO])

    [http://arxiv.org/abs/2310.18301](http://arxiv.org/abs/2310.18301)

    本论文介绍了一种交互式联合规划方法，将模型预测控制（MPC）与基于深度学习的轨迹预测模型结合，实现在高度交互的驾驶场景中为自主驾驶车辆规划安全的运动路径。

    

    在高度交互的驾驶场景中，一个车辆的行动会极大地影响到其周围车辆的行为。因此，在这样的交互环境中为自主驾驶车辆规划安全的运动路径需要考虑自身意图行动对周围车辆行为的影响。近年来，基于深度学习的轨迹预测模型在相关研究中取得了巨大的成功，许多模型都支持以自身条件来进行预测。然而，由于神经网络的复杂性，利用自身条件的预测在下游规划中仍然具有挑战性，限制了规划器的结构，例如采样型规划器。尽管采样型规划器能够生成精细的高质量运动路径，但基于梯度的规划算法，如模型预测控制（MPC），由于其迭代性质和对梯度的需求，很难利用自身条件的预测。我们提出了交互式联合规划（IJP），将MPC与

    In highly interactive driving scenarios, the actions of one agent greatly influences those of its neighbors. Planning safe motions for autonomous vehicles in such interactive environments, therefore, requires reasoning about the impact of the ego's intended motion plan on nearby agents' behavior. Deep-learning-based models have recently achieved great success in trajectory prediction and many models in the literature allow for ego-conditioned prediction. However, leveraging ego-conditioned prediction remains challenging in downstream planning due to the complex nature of neural networks, limiting the planner structure to simple ones, e.g., sampling-based planner. Despite their ability to generate fine-grained high-quality motion plans, it is difficult for gradient-based planning algorithms, such as model predictive control (MPC), to leverage ego-conditioned prediction due to their iterative nature and need for gradient. We present Interactive Joint Planning (IJP) that bridges MPC with 
    
[^2]: 通道独立策略是否是时间序列预测的最佳解？

    Is Channel Independent strategy optimal for Time Series Forecasting?. (arXiv:2310.17658v1 [cs.LG])

    [http://arxiv.org/abs/2310.17658](http://arxiv.org/abs/2310.17658)

    本文重新考虑了当前通道独立策略在时间序列预测中是否是最佳解决方案，并提出了一种称为CSC的通道自聚类策略来增强性能并减小参数大小。

    

    近年来出现了许多用于长期时间序列预测的模型。最近的研究表明，使用单一线性层的通道相关(CD)或通道独立(CI)建模，甚至可以超过许多复杂模型的性能。然而，当前的研究主要将CD和CI视为两种互补但互斥的方法，无法同时利用这两个极端。而且，CD和CI都是静态策略，无法在没有大量实验的情况下确定是特定数据集的最佳策略。在本文中，我们重新考虑了当前CI策略是否是时间序列预测的最佳解决方案。首先，我们提出了一种简单而有效的策略，称为CSC（通道自聚类策略），用于线性模型。我们的通道自聚类策略增强了CI策略的性能改进，并减小了参数大小。

    There has been an emergence of various models for long-term time series forecasting. Recent studies have demonstrated that a single linear layer, using Channel Dependent (CD) or Channel Independent (CI) modeling, can even outperform a large number of sophisticated models. However, current research primarily considers CD and CI as two complementary yet mutually exclusive approaches, unable to harness these two extremes simultaneously. And it is also a challenging issue that both CD and CI are static strategies that cannot be determined to be optimal for a specific dataset without extensive experiments. In this paper, we reconsider whether the current CI strategy is the best solution for time series forecasting. First, we propose a simple yet effective strategy called CSC, which stands for $\mathbf{C}$hannel $\mathbf{S}$elf-$\mathbf{C}$lustering strategy, for linear models. Our Channel Self-Clustering (CSC) enhances CI strategy's performance improvements while reducing parameter size, fo
    
[^3]: 对AI分类器的对抗鲁棒性度量的存在性，唯一性和可扩展性研究

    On existence, uniqueness and scalability of adversarial robustness measures for AI classifiers. (arXiv:2310.14421v1 [stat.ML])

    [http://arxiv.org/abs/2310.14421](http://arxiv.org/abs/2310.14421)

    本文研究了针对AI分类器的对抗鲁棒性度量的存在性、唯一性和可扩展性，提出了可以验证的数学条件，并在合成基准测试和生物医学应用中进行了实际计算和解释。

    

    本文提出并证明了针对（局部）唯一可逆分类器、广义线性模型（GLM）和熵AI（EAI）具有最小对抗路径（MAP）和最小对抗距离（MAD）的存在性、唯一性和明确的分析计算的简单可验证的数学条件。在常见的合成基准测试数据集上，针对神经网络、提升随机森林、GLM和EAI等各类AI工具进行MAP和MAD的实际计算、比较和解释，包括双卷状螺旋线及其扩展以及两个生物医学数据问题（用于健康保险理赔预测和心脏病发作致死率分类）。在生物医学应用中，展示了MAP如何在预定义的可访问控制变量子集中提供唯一的最小患者特定风险缓解干预措施。

    Simply-verifiable mathematical conditions for existence, uniqueness and explicit analytical computation of minimal adversarial paths (MAP) and minimal adversarial distances (MAD) for (locally) uniquely-invertible classifiers, for generalized linear models (GLM), and for entropic AI (EAI) are formulated and proven. Practical computation of MAP and MAD, their comparison and interpretations for various classes of AI tools (for neuronal networks, boosted random forests, GLM and EAI) are demonstrated on the common synthetic benchmarks: on a double Swiss roll spiral and its extensions, as well as on the two biomedical data problems (for the health insurance claim predictions, and for the heart attack lethality classification). On biomedical applications it is demonstrated how MAP provides unique minimal patient-specific risk-mitigating interventions in the predefined subsets of accessible control variables.
    
[^4]: XAI的公平效益的批判性调查

    A Critical Survey on Fairness Benefits of XAI. (arXiv:2310.13007v1 [cs.AI])

    [http://arxiv.org/abs/2310.13007](http://arxiv.org/abs/2310.13007)

    这个批判性调查分析了可解释的人工智能（XAI）与公平之间的关系，指出XAI在实现公平理想方面存在潜力和限制，呼吁更具体地说明XAI方法如何帮助解决公平理想。

    

    在这个批判性调查中，我们分析了关于可解释的人工智能（XAI）和公平之间关系的典型论述，以解开这两个概念之间的多维关系。通过系统文献综述和随后的定性内容分析，我们从175篇论文中识别出关于XAI的公平效益的七个典型论断。我们提出关于这些论断的重要警告，并为未来围绕XAI在特定公平理想中的潜力和限制进行讨论提供了一个切入点。虽然文献通常认为XAI是实现多个公平理想的一种手段，但我们注意到这些理想与XAI的能力之间存在不一致。我们鼓励将XAI视为应对算法公平这一多维社会技术挑战的众多工具之一，并更具体地说明哪种XAI方法如何帮助哪些人解决哪些公平理想。

    In this critical survey, we analyze typical claims on the relationship between explainable AI (XAI) and fairness to disentangle the multidimensional relationship between these two concepts. Based on a systematic literature review and a subsequent qualitative content analysis, we identify seven archetypal claims from 175 papers on the alleged fairness benefits of XAI. We present crucial caveats with respect to these claims and provide an entry point for future discussions around the potentials and limitations of XAI for specific fairness desiderata. While the literature often suggests XAI to be an enabler for several fairness desiderata, we notice a misalignment between these desiderata and the capabilities of XAI. We encourage to conceive XAI as one of many tools to approach the multidimensional, sociotechnical challenge of algorithmic fairness and to be more specific about how exactly what kind of XAI method enables whom to address which fairness desideratum.
    
[^5]: 通过推理与规划消除推理：一种引导LLMs非线性思维的新框架

    Eliminating Reasoning via Inferring with Planning: A New Framework to Guide LLMs' Non-linear Thinking. (arXiv:2310.12342v1 [cs.CL])

    [http://arxiv.org/abs/2310.12342](http://arxiv.org/abs/2310.12342)

    本文提出了一种名为推断性排除提示（IEP）的新框架，通过结合排除和推理的原则，引导LLM进行非线性思考。IEP通过规划和自然语言推理，可以模拟复杂的人类思维过程，比其他方法具有更广泛的视角。

    

    Thought Chain（CoT）提示及其变体通过模拟人类线性认知和逻辑，探索为大型语言模型（LLM）装备高级推理能力。然而，人类思维复杂且混合线性和非线性思维。在这项工作中，我们提出了一种新的提示方式，称为推断性排除提示（IEP），它结合了排除和推理的原则，以引导LLM进行非线性思考。IEP指导LLM进行规划，并利用自然语言推理（NLI）推断每个可能解与上下文、常识或事实的推理关系，从而通过回溯推理获得更广泛的视角。相比其他基于CoT的方法，IEP的前向规划和后向排除过程更好地模拟了复杂的人类思维过程，后者仅反映线性认知过程。我们进行了一系列的实证研究，并验证了IEP的优势。

    Chain-of-Thought(CoT) prompting and its variants explore equipping large language models (LLMs) with high-level reasoning abilities by emulating human-like linear cognition and logic. However, the human mind is complicated and mixed with both linear and nonlinear thinking. In this work, we propose \textbf{I}nferential \textbf{E}xclusion \textbf{P}rompting (IEP), a novel prompting that combines the principles of elimination and inference in order to guide LLMs to think non-linearly. IEP guides LLMs to plan and then utilize Natural Language Inference (NLI) to deduce each possible solution's entailment relation with context, commonsense, or facts, therefore yielding a broader perspective by thinking back for inferring. This forward planning and backward eliminating process allows IEP to better simulate the complex human thinking processes compared to other CoT-based methods, which only reflect linear cognitive processes. We conducted a series of empirical studies and have corroborated tha
    
[^6]: ChatGPT用于计算拓扑学

    ChatGPT for Computational Topology. (arXiv:2310.07570v2 [math.AT] UPDATED)

    [http://arxiv.org/abs/2310.07570](http://arxiv.org/abs/2310.07570)

    该论文介绍了如何利用ChatGPT桥接理论拓扑概念和计算拓扑实现之间的差距，展示了在没有编码技能的情况下，通过ChatGPT的帮助，纯粹的理论家如何将数学公式和概念转化为功能性的计算拓扑代码。

    

    ChatGPT是人工智能领域的一个重要里程碑，广泛应用于不同领域。然而，在数学环境中，它往往受到概念错误的限制。同时，拓扑数据分析是一个相对较新的学科，在近年来引起了广泛关注。然而，计算算法和编码技能在理论家中的理解还有限，这阻碍了拓扑学的进展。这项工作旨在通过利用ChatGPT来弥合理论拓扑概念与计算拓扑实现之间的差距。我们展示了如何在没有计算经验和编码技能的情况下，纯粹的理论家如何借助ChatGPT将数学公式和概念有效地转化为功能性的计算拓扑代码。我们的策略概述了一个有效的过程。

    ChatGPT represents a significant milestone in the field of artificial intelligence (AI), finding widespread applications across diverse domains. However, its effectiveness in mathematical contexts has been somewhat constrained by its susceptibility to conceptual errors. Concurrently, topological data analysis (TDA), a relatively new discipline, has garnered substantial interest in recent years. Nonetheless, the advancement of TDA is impeded by the limited understanding of computational algorithms and coding proficiency among theoreticians. This work endeavors to bridge the gap between theoretical topological concepts and their practical implementation in computational topology through the utilization of ChatGPT. We showcase how a pure theoretician, devoid of computational experience and coding skills, can effectively transform mathematical formulations and concepts into functional code for computational topology with the assistance of ChatGPT. Our strategy outlines a productive process
    
[^7]: AdaptNet: 基于物理的角色控制的策略调整

    AdaptNet: Policy Adaptation for Physics-Based Character Control. (arXiv:2310.00239v2 [cs.GR] UPDATED)

    [http://arxiv.org/abs/2310.00239](http://arxiv.org/abs/2310.00239)

    AdaptNet是一种基于物理的角色控制的策略调整方法，通过修改现有策略的潜在空间，可以从类似任务中快速学习到新的行为，显著提高训练效率。

    

    受到人类在学习新技能时能够适应现有技能的能力的启发，本文提出了一种名为AdaptNet的方法，该方法可以修改现有策略的潜在空间，使其能够从类似任务中快速学习到新的行为，相比从头开始学习。AdaptNet在给定的强化学习控制器基础上构建了一个两层次结构，通过增加原始状态嵌入来支持行为的适度变化，并进一步修改策略网络层来实现更深远的变化。该技术被证明可以有效地适应现有的基于物理的控制器以适应广泛的新的运动风格、新的任务目标、角色形态的变化以及环境的广泛变化。此外，与从头开始训练或使用其他修改现有策略的方法相比，它显示出显著提高的学习效率，表现为大大缩短的训练时间。代码可在https://motion-上获得。

    Motivated by humans' ability to adapt skills in the learning of new ones, this paper presents AdaptNet, an approach for modifying the latent space of existing policies to allow new behaviors to be quickly learned from like tasks in comparison to learning from scratch. Building on top of a given reinforcement learning controller, AdaptNet uses a two-tier hierarchy that augments the original state embedding to support modest changes in a behavior and further modifies the policy network layers to make more substantive changes. The technique is shown to be effective for adapting existing physics-based controllers to a wide range of new styles for locomotion, new task targets, changes in character morphology and extensive changes in environment. Furthermore, it exhibits significant increase in learning efficiency, as indicated by greatly reduced training times when compared to training from scratch or using other approaches that modify existing policies. Code is available at https://motion-
    
[^8]: 深度学习在CT扫描分类中的结果是否公正可解释？

    Are Deep Learning Classification Results Obtained on CT Scans Fair and Interpretable?. (arXiv:2309.12632v1 [cs.LG])

    [http://arxiv.org/abs/2309.12632](http://arxiv.org/abs/2309.12632)

    深度学习在CT扫描分类中的结果往往只关注准确性，而忽视了公正性和解释性，导致模型不可信和不适用于真实场景。

    

    鉴于深度学习方法在图像和物体分类中的巨大成功，生物医学图像处理领域也面临着深度学习应用于各种自动诊断案例的压力。不幸的是，文献中大多数基于深度学习的分类尝试仅仅关注极高的准确性，而不考虑可解释性或者患者训练和测试数据的分离。例如，大部分使用深度学习的肺结节分类论文会对数据进行随机洗牌，并将其分为训练、验证和测试集，导致一个人的CT扫描图像中的某些图像位于训练集中，而其他图像则位于验证或测试图像集中。这可能导致误导性的准确率报告和学习到的无关特征，最终降低了这些模型在实际应用中的可用性。

    Following the great success of various deep learning methods in image and object classification, the biomedical image processing society is also overwhelmed with their applications to various automatic diagnosis cases. Unfortunately, most of the deep learning-based classification attempts in the literature solely focus on the aim of extreme accuracy scores, without considering interpretability, or patient-wise separation of training and test data. For example, most lung nodule classification papers using deep learning randomly shuffle data and split it into training, validation, and test sets, causing certain images from the CT scan of a person to be in the training set, while other images of the exact same person to be in the validation or testing image sets. This can result in reporting misleading accuracy rates and the learning of irrelevant features, ultimately reducing the real-life usability of these models. When the deep neural networks trained on the traditional, unfair data sh
    
[^9]: 为人类助力灵巧抓取学习基于得分的抓取原语

    Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping. (arXiv:2309.06038v1 [cs.RO])

    [http://arxiv.org/abs/2309.06038](http://arxiv.org/abs/2309.06038)

    本文提出了一个名为“人类助力灵巧抓取”的新型任务，通过使用Grasping Gradient Field和基于历史条件的残差策略，训练控制机器人手指以适应不同用户意图和物体几何形状的灵巧抓取操作。

    

    在本文中，我们提出了一种名为“人类助力灵巧抓取”的新型任务，旨在训练控制机器人手指以帮助用户抓取物体的策略。与传统的灵巧抓取不同，这个任务面临着更复杂的挑战，因为策略需要适应不同的用户意图和物体的几何形状。我们通过提出一个由两个子模块组成的方法来解决这个挑战：一种手-物体条件抓取原语称为Grasping Gradient Field（GraspGF），以及一种基于历史条件的残差策略。GraspGF通过估计来自成功抓取示例集的梯度来学习“如何”抓取，而残差策略根据轨迹历史确定“何时”和以何种速度执行抓取动作。实验结果证明了我们方法的有效性。

    The use of anthropomorphic robotic hands for assisting individuals in situations where human hands may be unavailable or unsuitable has gained significant importance. In this paper, we propose a novel task called human-assisting dexterous grasping that aims to train a policy for controlling a robotic hand's fingers to assist users in grasping objects. Unlike conventional dexterous grasping, this task presents a more complex challenge as the policy needs to adapt to diverse user intentions, in addition to the object's geometry. We address this challenge by proposing an approach consisting of two sub-modules: a hand-object-conditional grasping primitive called Grasping Gradient Field~(GraspGF), and a history-conditional residual policy. GraspGF learns `how' to grasp by estimating the gradient from a success grasping example set, while the residual policy determines `when' and at what speed the grasping action should be executed based on the trajectory history. Experimental results demons
    
[^10]: 什么时候编程思维对推理起作用?

    When Do Program-of-Thoughts Work for Reasoning?. (arXiv:2308.15452v1 [cs.CL])

    [http://arxiv.org/abs/2308.15452](http://arxiv.org/abs/2308.15452)

    提出了复杂性影响推理分数（CIRS）来衡量编程语言对推理能力的影响，发现并非所有复杂性的代码数据都可以被学习或理解，适当的复杂性水平对于改善推理能力至关重要。

    

    大型语言模型（LLM）的推理能力在体现出人工智能领域中起着关键作用。尽管像编程思维提示这样的方法对于使用编程语言来解决复杂推理任务的LLM非常有效，但代码数据对推理能力的具体影响仍未充分探索。为了填补这一空白，我们提出了复杂性影响推理分数（CIRS），它结合了结构和逻辑属性，以衡量代码和推理能力之间的相关性。具体而言，我们使用抽象语法树来编码结构信息，并通过考虑难度和圈复杂度来计算逻辑复杂性。通过实证分析，我们发现并非所有复杂性的代码数据都可以被LLM学习或理解。最佳复杂性水平对于通过编程辅助提示改善推理能力至关重要。然后我们设计了一个自动合成的方法...

    The reasoning capabilities of Large Language Models (LLMs) play a pivotal role in the realm of embodied artificial intelligence. Although there are effective methods like program-of-thought prompting for LLMs which uses programming language to tackle complex reasoning tasks, the specific impact of code data on the improvement of reasoning capabilities remains under-explored. To address this gap, we propose complexity-impacted reasoning score (CIRS), which combines structural and logical attributes, to measure the correlation between code and reasoning abilities. Specifically, we use the abstract syntax tree to encode the structural information and calculate logical complexity by considering the difficulty and the cyclomatic complexity. Through an empirical analysis, we find not all code data of complexity can be learned or understood by LLMs. Optimal level of complexity is critical to the improvement of reasoning abilities by program-aided prompting. Then we design an auto-synthesizing
    
[^11]: 在循环神经网络中的表达性概率抽样

    Expressive probabilistic sampling in recurrent neural networks. (arXiv:2308.11809v1 [q-bio.NC])

    [http://arxiv.org/abs/2308.11809](http://arxiv.org/abs/2308.11809)

    该论文探索了循环神经电路如何从复杂概率分布中进行抽样，并证明了带有单独输出单元的神经电路的发放率动力学可以从任意概率分布中进行抽样。

    

    在基于采样的大脑功能贝叶斯模型中，假设神经活动是来自大脑用于概率计算的概率分布样本。然而，对于神经动力学机制模型如何从任意分布中进行抽样仍然缺乏全面理解。我们使用函数分析和随机微分方程的工具来探索$\textit{循环}$神经电路从复杂分布中进行抽样的最小架构要求。首先我们考虑传统的采样模型，它由一个神经元网络组成，其输出直接表示样本（仅采样器网络）。我们认为传统模型中的突触电流和发放率动力学能够从复杂概率分布中进行抽样的能力有限。我们证明了一个带有单独的输出单元集的循环神经电路的发放率动力学可以从任意概率分布中进行抽样。

    In sampling-based Bayesian models of brain function, neural activities are assumed to be samples from probability distributions that the brain uses for probabilistic computation. However, a comprehensive understanding of how mechanistic models of neural dynamics can sample from arbitrary distributions is still lacking. We use tools from functional analysis and stochastic differential equations to explore the minimum architectural requirements for $\textit{recurrent}$ neural circuits to sample from complex distributions. We first consider the traditional sampling model consisting of a network of neurons whose outputs directly represent the samples (sampler-only network). We argue that synaptic current and firing-rate dynamics in the traditional model have limited capacity to sample from a complex probability distribution. We show that the firing rate dynamics of a recurrent neural circuit with a separate set of output units can sample from an arbitrary probability distribution. We call 
    
[^12]: 用潜在扩散模型改进非酒精性脂肪性肝病分类性能

    Improving Nonalcoholic Fatty Liver Disease Classification Performance With Latent Diffusion Models. (arXiv:2307.06507v1 [cs.CV])

    [http://arxiv.org/abs/2307.06507](http://arxiv.org/abs/2307.06507)

    本研究通过结合使用扩散模型生成的合成图像和真实图像，提高了非酒精性脂肪性肝病分类的性能。

    

    将深度学习与临床专业知识相结合在解决医疗挑战和提供改进诊断工具方面具有很大潜力。然而，往往需要有注释的医学图像成为充分利用机器学习模型强大能力的障碍。我们的研究表明，通过结合使用扩散模型生成的合成图像和真实图像，我们可以提高非酒精性脂肪性肝病（NAFLD）的分类性能。我们通过比较两个指标来评估合成图像的质量：基于扩散生成的图像和生成对抗网络（GANs）生成的图像计算的Inception Score（IS）和Fr\'{e}chet Inception Distance（FID）。我们的结果显示，扩散生成的图像具有卓越的性能，最大IS得分为1.90，而GANs为1.67，最小FID得分为69.45，而GANs为99.53。利用部分冻结的CNN骨干（EfficientNet v1）。

    Integrating deep learning with clinical expertise holds great potential for addressing healthcare challenges and empowering medical professionals with improved diagnostic tools. However, the need for annotated medical images is often an obstacle to leveraging the full power of machine learning models. Our research demonstrates that by combining synthetic images, generated using diffusion models, with real images, we can enhance nonalcoholic fatty liver disease (NAFLD) classification performance. We evaluate the quality of the synthetic images by comparing two metrics: Inception Score (IS) and Fr\'{e}chet Inception Distance (FID), computed on diffusion-generated images and generative adversarial networks (GANs)-generated images. Our results show superior performance for the diffusion-generated images, with a maximum IS score of $1.90$ compared to $1.67$ for GANs, and a minimum FID score of $69.45$ compared to $99.53$ for GANs. Utilizing a partially frozen CNN backbone (EfficientNet v1),
    
[^13]: 重置深度强化学习中的优化器：一个实证研究

    Resetting the Optimizer in Deep RL: An Empirical Study. (arXiv:2306.17833v1 [cs.LG])

    [http://arxiv.org/abs/2306.17833](http://arxiv.org/abs/2306.17833)

    在深度强化学习中，当优化问题的风景在不同迭代中差异较大时，重置优化器的内部参数可以避免污染和提高性能。

    

    我们关注的是在深度强化学习中近似计算最优值函数的任务。这个迭代过程包括在每个迭代中解决一系列不同迭代中目标函数可能改变的优化问题。解决这个问题的常见方法是使用现代变种的随机梯度下降算法，如Adam。这些优化器保持自己的内部参数，如梯度的一阶和二阶矩估计，并随时间更新这些参数。因此，之前迭代的信息被用来在当前迭代中解决优化问题。我们假设在之前迭代的优化风景与当前迭代相差较大的情况下，这可能会污染所使用优化器的内部参数。为了避免这种影响，一个简单的想法是在开始新的迭代时重置优化器的内部参数。

    We focus on the task of approximating the optimal value function in deep reinforcement learning. This iterative process is comprised of approximately solving a sequence of optimization problems where the objective function can change per iteration. The common approach to solving the problem is to employ modern variants of the stochastic gradient descent algorithm such as Adam. These optimizers maintain their own internal parameters such as estimates of the first and the second moment of the gradient, and update these parameters over time. Therefore, information obtained in previous iterations is being used to solve the optimization problem in the current iteration. We hypothesize that this can contaminate the internal parameters of the employed optimizer in situations where the optimization landscape of the previous iterations is quite different from the current iteration. To hedge against this effect, a simple idea is to reset the internal parameters of the optimizer when starting a n
    
[^14]: 多变风量开放式办公室中 HVAC 系统能源优化：一种深度强化学习方法

    Energy Optimization for HVAC Systems in Multi-VAV Open Offices: A Deep Reinforcement Learning Approach. (arXiv:2306.13333v1 [eess.SY])

    [http://arxiv.org/abs/2306.13333](http://arxiv.org/abs/2306.13333)

    本研究提出了一种基于低复杂度深度强化学习模型的多输入多输出体系结构，以最小化可控因素的数量，实现了对多变风量开放式办公室 HVAC 系统的能源优化，与传统系统相比能源消耗减少了 37%，且温度范围违规率极低 (<1%)。

    

    全球超过 32% 的能源用于商业和住宅建筑，迫切需要重新审视传统的建筑能源管理方法。由于 HVAC 系统占商业部门总能耗的约 40%，我们提出了一种基于低复杂度 DRL 模型的多输入多输出体系结构，以实现开放式办公室 HVAC 能源优化，仅使用少量可控和可访问因素。通过与真实建筑中基于现有 HVAC 计划的基线系统进行比较，评估了我们解决方案的整体能源消耗和热舒适度水平。该比较显示，我们的方法在工作时间内实现了 37% 的能源消耗节约，违规温度范围占比最低 (<1%)。训练一个性能优越的覆盖 d

    With more than 32% of the global energy used by commercial and residential buildings, there is an urgent need to revisit traditional approaches to Building Energy Management (BEM). With HVAC systems accounting for about 40% of the total energy cost in the commercial sector, we propose a low-complexity DRL-based model with multi-input multi-output architecture for the HVAC energy optimization of open-plan offices, which uses only a handful of controllable and accessible factors. The efficacy of our solution is evaluated through extensive analysis of the overall energy consumption and thermal comfort levels compared to a baseline system based on the existing HVAC schedule in a real building. This comparison shows that our method achieves 37% savings in energy consumption with minimum violation (<1%) of the desired temperature range during work hours. It takes only a total of 40 minutes for 5 epochs (about 7.75 minutes per epoch) to train a network with superior performance and covering d
    
[^15]: AdCraft：一种用于搜索引擎营销优化的高级强化学习基准环境

    AdCraft: An Advanced Reinforcement Learning Benchmark Environment for Search Engine Marketing Optimization. (arXiv:2306.11971v1 [cs.LG])

    [http://arxiv.org/abs/2306.11971](http://arxiv.org/abs/2306.11971)

    AdCraft是一种高级强化学习基准环境，用于模拟出价和预算变化的搜索引擎营销(SEM)活动，可用于评估和提高SEM出价和预算管理相关的RL算法的鲁棒性。

    

    本文介绍了一种新的强化学习基准环境—— AdCraft，其具有随机和非静态特性。该环境模拟了搜索引擎营销中出价和预算的动态变化。SEM是一种利用付费广告来增加网站在搜索引擎结果页面上的可见性的数字营销技术。SEM广告活动的表现取决于多个因素，包括关键字选择、广告设计、出价管理、预算调整和表现监控。深度强化学习最近被认为是一种优化SEM广告投放活动的潜在策略，但需要大量数据，在实践中可能成本高昂或不可行。我们的可定制环境使从业者能够评估和提高与SEM出价和预算管理相关的RL算法的鲁棒性，而无需付出这些成本。通过在AdCraft环境下进行一系列实验，

    We introduce \env{}, a novel benchmark environment for the Reinforcement Learning (RL) community distinguished by its stochastic and non-stationary properties. The environment simulates bidding and budgeting dynamics within Search Engine Marketing (SEM), a digital marketing technique utilizing paid advertising to enhance the visibility of websites on search engine results pages (SERPs). The performance of SEM advertisement campaigns depends on several factors, including keyword selection, ad design, bid management, budget adjustments, and performance monitoring. Deep RL recently emerged as a potential strategy to optimize campaign profitability within the complex and dynamic landscape of SEM but it requires substantial data, which may be costly or infeasible to acquire in practice. Our customizable environment enables practitioners to assess and enhance the robustness of RL algorithms pertinent to SEM bid and budget management without such costs. Through a series of experiments within 
    
[^16]: BackpropTools: 一款快速、可移植的连续控制深度强化学习库

    BackpropTools: A Fast, Portable Deep Reinforcement Learning Library for Continuous Control. (arXiv:2306.03530v1 [cs.LG])

    [http://arxiv.org/abs/2306.03530](http://arxiv.org/abs/2306.03530)

    BackpropTools是一款快速、可移植的连续控制深度强化学习库，它通过模板元编程提供紧密集成的可组合组件，并在异构平台集合上无缝使用，同时在连续控制问题的深度RL代理高效可扩展训练方面具有优势。由于其可移植性和实时保证，它成为了在嵌入式设备上部署学来的策略的有价值的工具。

    

    深度强化学习在许多领域中已被证明可以产生出具有能力的代理和控制策略，但常常受到训练时间过长的困扰。此外，在连续控制问题的情况下，现有深度学习库的实时性和可移植性的缺乏限制了学习策略在实际嵌入式设备上的应用。为了解决这些问题，我们提出了BackpropTools，一种依赖性-free、header-only、pure C++的深度监督和强化学习库。利用最近C++标准的模板元编程能力，我们提供了可以由编译器紧密集成的可组合组件。其新颖的架构允许BackpropTools在异构平台集合上无缝使用，从HPC集群、工作站和笔记本电脑到智能手机、智能手表和微控制器。具体来说，由于RL算法与模拟环境的紧密集成，BackpropTools在连续控制问题的深度RL代理的高效可扩展训练方面具有优势。此外，它的可移植性和实时保证使其成为在嵌入式设备上部署学来的策略的有价值的工具。

    Deep Reinforcement Learning (RL) has been demonstrated to yield capable agents and control policies in several domains but is commonly plagued by prohibitively long training times. Additionally, in the case of continuous control problems, the applicability of learned policies on real-world embedded devices is limited due to the lack of real-time guarantees and portability of existing deep learning libraries. To address these challenges, we present BackpropTools, a dependency-free, header-only, pure C++ library for deep supervised and reinforcement learning. Leveraging the template meta-programming capabilities of recent C++ standards, we provide composable components that can be tightly integrated by the compiler. Its novel architecture allows BackpropTools to be used seamlessly on a heterogeneous set of platforms, from HPC clusters over workstations and laptops to smartphones, smartwatches, and microcontrollers. Specifically, due to the tight integration of the RL algorithms with simu
    
[^17]: 知识为基础的规划的范畴表达语言和计算系统

    A Categorical Representation Language and Computational System for Knowledge-Based Planning. (arXiv:2305.17208v1 [cs.AI])

    [http://arxiv.org/abs/2305.17208](http://arxiv.org/abs/2305.17208)

    本文提出了一种基于范畴论的世界状态表示和转换方法，可以有效处理结构化知识，并且提供了使用知识图和关系数据库来建模规划中世界状态和更新的正式语义。

    

    基于一阶逻辑的经典规划表达语言已经被广泛应用于建模和解决规划问题，但是在复杂的规划场景中往往难以捕捉到隐含的前提和影响。为了解决这个问题，我们提出了一种表示和转换规划过程中世界状态的替代方法。基于范畴论的C集和双推成重写（DPO）的概念，我们提出的表示法可以有效地处理结构化知识，这些知识支持各个层次的领域抽象。它根据用户提供的本体学表示谓词的语义，并在状态转换时保持语义的一致性。这种方法为使用知识图和关系数据库来建模规划中的世界状态和更新提供了正式的语义。在本文中，我们将我们的范畴论表示与经典规划表示进行了比较。

    Classical planning representation languages based on first-order logic have been extensively used to model and solve planning problems, but they struggle to capture implicit preconditions and effects that arise in complex planning scenarios. To address this problem, we propose an alternative approach to representing and transforming world states during planning. Based on the category-theoretic concepts of $\mathsf{C}$-sets and double-pushout rewriting (DPO), our proposed representation can effectively handle structured knowledge about world states that support domain abstractions at all levels. It formalizes the semantics of predicates according to a user-provided ontology and preserves the semantics when transitioning between world states. This method provides a formal semantics for using knowledge graphs and relational databases to model world states and updates in planning. In this paper, we compare our category-theoretic representation with the classical planning representation. We
    
[^18]: 对模糊问题的有选择性回答

    Selectively Answering Ambiguous Questions. (arXiv:2305.14613v1 [cs.CL])

    [http://arxiv.org/abs/2305.14613](http://arxiv.org/abs/2305.14613)

    本研究调查了解决模糊问题的方法，通过定量测量模型输出中的重复性，找出了在含糊问题集中回答高精度子集问题的最可靠方法。这种基于采样的方法可以有效解决问题回答中的歧义，并提高语言模型的可靠性。

    

    可靠的语言模型应该在不知道答案的情况下放弃回答问题。然而，由于问问者意图或上下文的不确定性，问题的答案也可能不清楚。本研究从这个角度调查了问题回答，专注于在众多本质上含糊的问题集中回答高精度子集的问题。在此设置中，我们发现定量测量一组采样模型输出中的重复性是最可靠的校准方法，而非先前工作中使用的模型的概率或自我验证。我们发现，这种方法适用于不同类型的不确定性，不同的模型规模，以及带或不带指导调整。我们的结果表明，基于采样的方法可以有效解决问题回答中的歧义，并提高语言模型的可靠性。

    Trustworthy language models should abstain from answering questions when they do not know the answer. However, the answer to a question can be unknown for a variety of reasons. Prior research has focused on the case in which the question is clear and the answer is unambiguous but possibly unknown. However, the answer to a question can also be unclear due to uncertainty of the questioner's intent or context. We investigate question answering from this perspective, focusing on answering a subset of questions with a high degree of accuracy, from a set of questions in which many are inherently ambiguous. In this setting, we find that the most reliable approach to calibration involves quantifying repetition within a set of sampled model outputs, rather than the model's likelihood or self-verification as used in prior work. % We find this to be the case across different types of uncertainty, varying model scales and both with or without instruction tuning. Our results suggest that sampling-b
    
[^19]: GPT4Table：大型语言模型能理解结构化表格数据吗？一项基准测试和实证研究

    GPT4Table: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study. (arXiv:2305.13062v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.13062](http://arxiv.org/abs/2305.13062)

    本文设计了一个基准测试来评估大型语言模型（LLMs）对结构化表格数据的理解能力，并发现不同的输入选择会对性能产生影响。在基准测试的基础上，提出了“自我增强”技术以改善理解能力。

    

    大型语言模型（LLMs）作为少样本推理器来解决与自然语言相关的任务越来越具吸引力。然而，关于LLMs对结构化数据（例如表格）的理解程度还有很多需要学习的地方。尽管可以使用表格序列化作为LLMs的输入，但目前还缺乏对LLMs是否真正能够理解这类数据的全面研究。本文通过设计一个基准测试来评估LLMs的结构理解能力（SUC）来解决这个问题。我们创建的基准测试包括七个任务，每个任务都有其独特的挑战，例如单元格查找、行检索和大小检测。我们对GPT-3.5和GPT-4进行了一系列评估。我们发现性能因多种输入选择而异，包括表格输入格式、内容顺序、角色提示和分区标记等。根据基准测试评估所得的见解，我们提出了“自我增强”技术以改善性能。

    Large language models (LLMs) are becoming attractive as few-shot reasoners to solve Natural Language (NL)-related tasks. However, there is still much to learn about how well LLMs understand structured data, such as tables. While it is true that tables can be used as inputs to LLMs with serialization, there lack of comprehensive studies examining whether LLMs can truly comprehend such data. In this paper, we try to understand this by designing a benchmark to evaluate the structural understanding capabilities (SUC) of LLMs. The benchmark we create includes seven tasks, each with its own unique challenges, \eg, cell lookup, row retrieval, and size detection. We run a series of evaluations on GPT-3.5 and GPT-4. We discover that the performance varied depending on a number of input choices, including table input format, content order, role prompting, and partition marks. Drawing from the insights gained through the benchmark evaluations, we then propose \textit{self-augmentation} for effect
    
[^20]: 利用语言模型用自然语言解释黑盒文本模块

    Explaining black box text modules in natural language with language models. (arXiv:2305.09863v1 [cs.AI])

    [http://arxiv.org/abs/2305.09863](http://arxiv.org/abs/2305.09863)

    本文介绍了一种名为Summarize and Score（SASC）的方法，该方法可以自动获取黑盒文本模块的自然语言解释以及解释可靠程度的分数。研究者们已经在合成模块和BERT模型中使用SASC，让我们可以解释模块的选择性，这对于增强大型语言模型的可解释性非常重要。

    

    大型语言模型已经证明在各种任务中具有出色的预测性能。然而，它们的快速增长和不透明性已经引起了对可解释性的需求。本文询问是否可以自动获取黑盒文本模块的自然语言解释。一个“文本模块”是将文本映射到标量连续值的任何函数，例如LLM内的子模块或大脑区域的拟合模型。“黑盒”表示我们只能访问模块的输入/输出。我们引入了Summarize and Score（SASC）方法，它接受文本模块并返回模块选择性的自然语言解释以及解释可靠程度的分数。我们在三个上下文中研究SASC。首先，我们在合成模块上评估SASC，并发现它经常恢复基本真相说明。其次，我们使用SASC来解释预训练BERT模型中的模块，使得检查BERT的模块成为可能。

    Large language models (LLMs) have demonstrated remarkable prediction performance for a growing array of tasks. However, their rapid proliferation and increasing opaqueness have created a growing need for interpretability. Here, we ask whether we can automatically obtain natural language explanations for black box text modules. A "text module" is any function that maps text to a scalar continuous value, such as a submodule within an LLM or a fitted model of a brain region. "Black box" indicates that we only have access to the module's inputs/outputs.  We introduce Summarize and Score (SASC), a method that takes in a text module and returns a natural language explanation of the module's selectivity along with a score for how reliable the explanation is. We study SASC in 3 contexts. First, we evaluate SASC on synthetic modules and find that it often recovers ground truth explanations. Second, we use SASC to explain modules found within a pre-trained BERT model, enabling inspection of the 
    
[^21]: 预测是否随意？在公平分类中评估自洽性

    Is My Prediction Arbitrary? Measuring Self-Consistency in Fair Classification. (arXiv:2301.11562v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11562](http://arxiv.org/abs/2301.11562)

    在公平分类中，模型的预测方差是一个重要但鲜为人知的误差来源问题。作者提出了一个自洽性标准来衡量测量和减少随意性。作者还开发了一个算法来处理随意性预测，并通过实证研究揭示了当前模型无法处理某些类型数据的问题。

    

    在公平分类中，不同经过训练的模型之间的预测方差是一个重要但鲜为人知的误差来源问题。 实证表明，某些情况下，预测的方差差异非常大，以至于决策实际上是随意的。 为了研究这个问题，我们进行了大规模的实证研究，并做出了四个总体贡献：我们1）定义了一种基于方差的度量标准，称为自洽性，在测量和减少随意性时使用； 2）开发了一种合理的算法，当预测无法做出决策时，可以放弃分类； 3）进行了迄今为止有关公平分类中方差（相对于自洽性和随意性）作用的最大规模实证研究； 4）推出了一个工具包，使美国住房抵押贷款披露法案（HMDA）数据集易于用于未来研究。 总的来说，我们的实证结果揭示了关于可重复性的令人震惊的见解。当考虑到方差和随意预测的可能性时，大多数公平分类基准接近公平。 但是，一小部分实例显示出极大的随意性水平，这表明当前的模型可能无法处理某些类型的数据。

    Variance in predictions across different trained models is a significant, under-explored source of error in fair classification. Empirically, the variance on some instances is so large that decisions can be effectively arbitrary. To study this problem, we perform a large-scale empirical study and make four overarching contributions: We 1) Define a metric called self-consistency, derived from variance, which we use as a proxy for measuring and reducing arbitrariness; 2) Develop an ensembling algorithm that abstains from classification when a prediction would be arbitrary; 3) Conduct the largest to-date empirical study of the role of variance (vis-a-vis self-consistency and arbitrariness) in fair classification; and, 4) Release a toolkit that makes the US Home Mortgage Disclosure Act (HMDA) datasets easily usable for future research. Altogether, our empirical results reveal shocking insights about reproducibility. Most fairness classification benchmarks are close-to-fair when taking into
    
[^22]: 基于语言模型的知识图谱嵌入编辑

    Editing Language Model-based Knowledge Graph Embeddings. (arXiv:2301.10405v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.10405](http://arxiv.org/abs/2301.10405)

    本文提出了一种新的任务——编辑基于语言模型的知识图谱嵌入，旨在实现对KG嵌入的数据高效和快速更新。针对这一任务，提出了一个简单而强大的方案——KGEditor，可以更好地更新特定事实而不影响其余部分的性能。

    

    近几十年来，使用语言模型进行知识图谱（KG）嵌入已经取得了实证成功。但是，基于语言模型的KG嵌入通常作为静态工件部署，修改起来具有挑战性，需要重新训练。为了解决这个问题，本文提出了一种新的任务，即编辑基于语言模型的KG嵌入。该任务旨在实现对KG嵌入的数据高效和快速更新，而不影响其余部分的性能。我们构建了四个新数据集：E-FB15k237、A-FB15k237、E-WN18RR 和 A-WN18RR，并评估了几种知识编辑基线，证明了之前的模型处理该任务的能力有限。我们进一步提出了一个简单但强大的基线——KGEditor，它利用超网络的附加参数层来编辑/添加事实。全面的实验结果表明，当更新特定事实而不影响其余部分的性能时，KGEditor 的表现更好。

    Recently decades have witnessed the empirical success of framing Knowledge Graph (KG) embeddings via language models. However, language model-based KG embeddings are usually deployed as static artifacts, which are challenging to modify without re-training after deployment. To address this issue, we propose a new task of editing language model-based KG embeddings in this paper. The proposed task aims to enable data-efficient and fast updates to KG embeddings without damaging the performance of the rest. We build four new datasets: E-FB15k237, A-FB15k237, E-WN18RR, and A-WN18RR, and evaluate several knowledge editing baselines demonstrating the limited ability of previous models to handle the proposed challenging task. We further propose a simple yet strong baseline dubbed KGEditor, which utilizes additional parametric layers of the hyper network to edit/add facts. Comprehensive experimental results demonstrate that KGEditor can perform better when updating specific facts while not affec
    
[^23]: Deanthropomorphising NLP：语言模型可以意识到吗？

    Deanthropomorphising NLP: Can a Language Model Be Conscious?. (arXiv:2211.11483v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.11483](http://arxiv.org/abs/2211.11483)

    本文讨论了关于使用Transformer架构的预训练语言模型LaMDA是否具有意识的说法。作者认为语言模型不可能具有意识，而LaMDA没有比其他类似模型更具先进性。

    

    本文旨在对最近有关使用Transformer模型架构的预训练语言模型LaMDA具有意识的说法进行讨论。我们认为这样的语言模型不可能具有意识，而LaMDA并没有比其他类似模型更具先进性。我们通过综合信息理论对Transformer架构进行分析来证明这一点。我们认为这些有意识的说法是NLP报道中使用拟人化语言的更广泛倾向的一部分。无论这些说法的真实性如何，我们认为现在是评估语言建模进展并考虑该任务的伦理影响的适当时机。为了使本文有助于NLP社区以外的读者，我们还提供了一些NLP基础知识的介绍。

    This work is intended as a voice in the discussion over the recent claims that LaMDA, a pretrained language model based on the Transformer model architecture, is sentient. This claim, if confirmed, would have serious ramifications in the Natural Language Processing (NLP) community due to wide-spread use of similar models. However, here we take the position that such a language model cannot be sentient, or conscious, and that LaMDA in particular exhibits no advances over other similar models that would qualify it. We justify this by analysing the Transformer architecture through Integrated Information Theory. We see the claims of consciousness as part of a wider tendency to use anthropomorphic language in NLP reporting. Regardless of the veracity of the claims, we consider this an opportune moment to take stock of progress in language modelling and consider the ethical implications of the task. In order to make this work helpful for readers outside the NLP community, we also present the
    
[^24]: 奖励并非必要：如何为终身学习创建一个组合性自我保护智能体

    Reward is not Necessary: How to Create a Compositional Self-Preserving Agent for Life-Long Learning. (arXiv:2211.10851v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.10851](http://arxiv.org/abs/2211.10851)

    这项研究表明，我们可以使用内在动机衡量标准而不依赖于奖励来创建一个具有自我保护能力的智能体。

    

    强化学习认为最大化奖励和避免惩罚是解释目标导向行为的核心。然而，在一生中，生物需要学习关于世界结构的许多不同方面：世界状态和状态转移动力学。随着智能体融入新知识，状态组合的数量以指数级增长，并且对于给定的状态组合，没有明显定义的预设奖励或成本的加权组合，因为这样的加权需要在智能体在世界中的经验之前对好的和坏的组合进行编码。因此，我们必须在大状态空间中开发更自然的行为和动机模型。我们展示了仅使用内在动机衡量标准（即赋予能力）是可能的，该标准衡量智能体在转移操作者下实现许多可能未来的能力。我们建议将赋予能力扩展到分层状态空间中。

    Reinforcement Learning views the maximization of rewards and avoidance of punishments as central to explaining goal-directed behavior. However, over a life, organisms will need to learn about many different aspects of the world's structure: the states of the world and state-vector transition dynamics. The number of combinations of states grows exponentially as an agent incorporates new knowledge, and there is no obvious weighted combination of pre-existing rewards or costs defined for a given combination of states, as such a weighting would need to encode information about good and bad combinations prior to an agent's experience in the world. Therefore, we must develop more naturalistic accounts of behavior and motivation in large state-spaces. We show that it is possible to use only the intrinsic motivation metric of empowerment, which measures the agent's capacity to realize many possible futures under a transition operator. We propose to scale empowerment to hierarchical state-space
    
[^25]: 论公平机器学习中因果关系的必要性和适用性

    On the Need and Applicability of Causality for Fair Machine Learning. (arXiv:2207.04053v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.04053](http://arxiv.org/abs/2207.04053)

    本论文探讨了因果关系在公平机器学习中的必要性和适用性，强调了非因果预测的社会影响和法律反歧视过程依赖于因果主张。同时讨论了在实际场景中应用因果关系所面临的挑战和限制，并提出了可能的解决方案。

    

    除了在流行病学、政治和社会科学中的常见应用案例外，事实证明因果关系在评估自动决策的公正性方面十分重要，无论是在法律上还是日常生活中。我们提供了关于为何因果关系对公平性评估尤为重要的论点和示例。特别是，我们指出了非因果预测的社会影响以及依赖因果主张的法律反歧视过程。我们最后讨论了应用因果关系在实际场景中的挑战和局限性，以及可能的解决方案。

    Besides its common use cases in epidemiology, political, and social sciences, causality turns out to be crucial in evaluating the fairness of automated decisions, both in a legal and everyday sense. We provide arguments and examples, of why causality is particularly important for fairness evaluation. In particular, we point out the social impact of non-causal predictions and the legal anti-discrimination process that relies on causal claims. We conclude with a discussion about the challenges and limitations of applying causality in practical scenarios as well as possible solutions.
    
[^26]: 语义歧义的因果结构

    The Causal Structure of Semantic Ambiguities. (arXiv:2206.06807v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.06807](http://arxiv.org/abs/2206.06807)

    本文使用Gogioso和Pinzani在QPL 2021中提出的束理论模型，为语义歧义的两个特征（不同可能解释的联合可信度和某些词在过程中扮演更重要角色的因果结构）进行建模。通过对心理语言学文献中的歧义短语数据集进行分析，研究人员对人类对于这些歧义的判断进行了实证测量。

    

    歧义是自然语言现象，在不同的语法、语义和语用层面上发生。它得到了广泛的研究；例如，在心理语言学领域，我们有多种竞争性的研究人类消歧过程的方法。这些研究是经验性的，基于眼动跟踪等测量方法。本文首次尝试为语义歧义形式化这些进程，其中我们确定了两个特征：(1)不同可能解释之间的联合可信度，(2)根据某些词在过程中扮演更重要角色的因果结构。Gogioso和Pinzani在QPL 2021中提出的新型束理论确定因果性模型并对这些特征进行推理提供了工具。我们将这个理论应用于从心理语言学文献中提取的歧义短语数据集和我们使用Amazon的机械土耳其引擎收集的人类可信度判断中。我们测量了其中的因果关系、歧义水平等。

    Ambiguity is a natural language phenomenon occurring at different levels of syntax, semantics, and pragmatics. It is widely studied; in Psycholinguistics, for instance, we have a variety of competing studies for the human disambiguation processes. These studies are empirical and based on eyetracking measurements. Here we take first steps towards formalizing these processes for semantic ambiguities where we identified the presence of two features: (1) joint plausibility degrees of different possible interpretations, (2) causal structures according to which certain words play a more substantial role in the processes. The novel sheaf-theoretic model of definite causality developed by Gogioso and Pinzani in QPL 2021 offers tools to model and reason about these features. We applied this theory to a dataset of ambiguous phrases extracted from Psycholinguistics literature and their human plausibility judgements collected by us using the Amazon Mechanical Turk engine. We measured the causal fr
    

