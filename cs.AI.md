# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model.](http://arxiv.org/abs/2304.15010) | 本文提出了LLaMA-Adapter V2，这是一个参数高效的视觉指令模型，通过解锁更多可学习的参数，早期融合策略和联合训练策略，能够更好地处理视觉输入和精确地执行开放式视觉指令。 |
| [^2] | [Are Emergent Abilities of Large Language Models a Mirage?.](http://arxiv.org/abs/2304.15004) | 研究指出大型语言模型所谓的新兴技能是研究者分析的产物，不是模型行为的基本变化。研究还展示了度量标准选择和可能研究人员的偏见，可能导致这种新兴技能的出现。 |
| [^3] | [Empirical Analysis of the Strengths and Weaknesses of PEFT Techniques for LLMs.](http://arxiv.org/abs/2304.14999) | 本文实证分析了参数高效微调技术在大型语言模型中的优势和劣势，提供了选择优化微调技术的框架，同时揭示了在低数据场景下PEFT技术收敛速度较慢的事实。 |
| [^4] | [ChatGPT -- a Blessing or a Curse for Undergraduate Computer Science Students and Instructors?.](http://arxiv.org/abs/2304.14993) | 本文分析了ChatGPT在回答本科计算机科学问题上的不可靠性，并提供了在学术界使用ChatGPT的建议。 |
| [^5] | [Interpreting Vision and Language Generative Models with Semantic Visual Priors.](http://arxiv.org/abs/2304.14986) | 本研究提出了一种利用SHAP框架和视觉先验知识生成全面、有意义解释的方法，相较于传统方法具有更低的计算成本、更高的解释表现力，并可以推广到其他模型上。 |
| [^6] | [Optimal majority rules and quantitative Condorcet properties of setwise Kemeny voting schemes.](http://arxiv.org/abs/2304.14980) | 本文研究了集合Kemeny投票机制，提出了最优多数规则和数量化博德雷得准则，并比较了传统Kemeny规则和3-方式Kemeny投票方案的优劣。 |
| [^7] | [MLCopilot: Unleashing the Power of Large Language Models in Solving Machine Learning Tasks.](http://arxiv.org/abs/2304.14979) | 本文介绍了一种新型框架MLCopilot，通过利用最先进的大语言模型，扩展其能力以理解结构化输入并进行深入推理以解决新型ML任务的能力，展示了MLCopilot在解决图像分类，文本分类和表格分类三项任务方面的巨大潜力。 |
| [^8] | [A New Quantum Dempster Rule of Combination.](http://arxiv.org/abs/2304.14966) | 该论文提出了一种新的量子Dempster组合规则（QDRC），利用Toffoli门实现，能够应对Dempster组合规则计算复杂度指数级增长的问题。 |
| [^9] | [An Empirical Study of Multimodal Model Merging.](http://arxiv.org/abs/2304.14933) | 本研究通过融合在不同模态上训练的transformer进行多模态模型融合，并提出一种参数有效的模态不可知架构，形成有效的训练配方。 |
| [^10] | [Uncertainty Aware Neural Network from Similarity and Sensitivity.](http://arxiv.org/abs/2304.14925) | 本文提出了一种神经网络训练方法，可以考虑相似样本与敏感性感知，有效地计算神经网络中的不确定性。 |
| [^11] | [An EEG Channel Selection Framework for Driver Drowsiness Detection via Interpretability Guidance.](http://arxiv.org/abs/2304.14920) | 本文提出了一种解释性引导的通道选择框架（ICS）用于司机疲劳检测任务，通过逐步选择关键的贡献通道，在提高司机疲劳检测准确性、可解释性和效率方面具有显著的效果。 |
| [^12] | [Representation Matters: The Game of Chess Poses a Challenge to Vision Transformers.](http://arxiv.org/abs/2304.14918) | 这篇论文通过改变输入表示和价值损失，使棋盘游戏性能获得了高达180 Elo点的增强 |
| [^13] | ["Can't Take the Pressure?": Examining the Challenges of Blood Pressure Estimation via Pulse Wave Analysis.](http://arxiv.org/abs/2304.14916) | 本文分析了脉搏波分析预测血压的任务，发现许多论文常常出现数据泄漏和对任务及预处理步骤的不切实际限制。提出了新的工具来确定输入信号（如PPG）是否能预测所需的量度。 |
| [^14] | [Human Activity Recognition Using Self-Supervised Representations of Wearable Data.](http://arxiv.org/abs/2304.14912) | 本文提出了一个基于自监督表示法识别人类活动的模型，该模型在大量未标记数据集的基础上获得了较强性能，并在真实世界数据集上展现出了很好的效果。 |
| [^15] | [Evaluating the Stability of Semantic Concept Representations in CNNs for Robust Explainability.](http://arxiv.org/abs/2304.14864) | 本文提出了一种用于评估语义概念表示在CNN中稳定性的方法，为实现强大的可解释性提供了基础。本文关注计算机视觉CNN中概念表示的稳定性：概念检索稳定性和概念归属稳定性。在此基础上，本文提出了一种新的度量标准以解决概念检索稳定性的问题。 |
| [^16] | [MASK-CNN-Transformer For Real-Time Multi-Label Weather Recognition.](http://arxiv.org/abs/2304.14857) | 本文提出了一种考虑天气条件复杂共现依赖关系的多标签识别模型MASK-CNN-Transformer，该模型结合了CNN和Transformer，并利用MASK机制以提高泛化能力。 |
| [^17] | [Musical Voice Separation as Link Prediction: Modeling a Musical Perception Task as a Multi-Trajectory Tracking Problem.](http://arxiv.org/abs/2304.14848) | 本文提出了一种将音乐人声分离的感知任务建模为多轨迹跟踪问题的方法，通过预测音符之间的链接将不同的人声进行分离，从而鼓励单声部（人声）轨迹的产生。 |
| [^18] | [Sensitive Tuning of Large Scale CNNs for E2E Secure Prediction using Homomorphic Encryption.](http://arxiv.org/abs/2304.14836) | 本论文提出一种新的HE友好模型训练方法，成功演示了在ResNet和ConvNeXt等经典和现代CNN上运行加密样本，并以前所未有的方式演示了如何使用CLIP GPT-2模型进行零知识安全预测，是一种可行的隐私保护机器学习解决方案。 |
| [^19] | [Visual Diagrammatic Queries in ViziQuer: Overview and Implementation.](http://arxiv.org/abs/2304.14825) | ViziQuer是一种可视化查询符号和工具，提供了可视化图形手段来描述丰富的数据查询。它的创新点在于提供一种可视化的方式来进行数据查询，使得非技术专家也能参与到数据查询的过程中。 |
| [^20] | [Deep Learning assisted microwave-plasma interaction based technique for plasma density estimation.](http://arxiv.org/abs/2304.14807) | 本文提出了一种基于深度学习辅助微波等离子体相互作用技术的等离子体密度估计方法，通过测量微波散射引起的电场模式来估计密度剖面。 |
| [^21] | [ResiDual: Transformer with Dual Residual Connections.](http://arxiv.org/abs/2304.14802) | 本文提出了具有Pre-Post-LN双重残差连接的新型Transformer架构ResiDual，解决了Post-LN和Pre-LN存在的问题，并具有优越的性能表现。 |
| [^22] | [Multi-to-Single Knowledge Distillation for Point Cloud Semantic Segmentation.](http://arxiv.org/abs/2304.14800) | 本文提出了一个基于多对单知识蒸馏的模型来提高点云语义分割中的分类表现，该模型针对难分类类别只融合它们的实例，并使用多级蒸馏框架和实例感知构形蒸馏算法从多个扫描中蒸馏有价值的知识。 |
| [^23] | [Learning Graph Neural Networks using Exact Compression.](http://arxiv.org/abs/2304.14793) | 本文研究了利用精确压缩来减少在大型图上学习图神经网络的内存需求，并提出了一种证明等效的压缩图神经网络学习问题的方法。 |
| [^24] | [Training and Evaluation of a Multilingual Tokenizer for GPT-SW3.](http://arxiv.org/abs/2304.14780) | 本文介绍了GPT-SW3的多语言分词器，通过使用SentencePiece库和BPE算法在Nordic Pile上训练，评估了其对于不同语言的表现和性能。 |
| [^25] | [Metric Temporal Equilibrium Logic over Timed Traces.](http://arxiv.org/abs/2304.14778) | 提出了基于度量的线性时间平衡逻辑来处理涉及时间约束的动态系统问题，并给出了通过将度量公式转化为单一一阶公式实现模型检查的方法。 |
| [^26] | [Synergy of Machine and Deep Learning Models for Multi-Painter Recognition.](http://arxiv.org/abs/2304.14773) | 本文使用机器学习和深度学习模型，结合迁移学习和经典机器学习方法，解决数字化绘画中的画家识别问题，并提出了一个包含约 10,000 张图片和 146 位画家的新型数据集 MultiPaint-10K。 |
| [^27] | [LostPaw: Finding Lost Pets using a Contrastive Learning-based Transformer with Visual Input.](http://arxiv.org/abs/2304.14765) | 本研究提出了一种名为LostPaw的基于人工智能的应用程序，利用对比神经网络模型准确区分宠物图像，可用于精准搜索失踪的宠物。该模型达到了90%的测试准确率，并为潜在的 Web 应用程序提供了基础，用户能够上传丢失宠物的图像并在数据库中找到匹配图像时接收通知。 |
| [^28] | [A New Class of Explanations for Classifiers with Non-Binary Features.](http://arxiv.org/abs/2304.14760) | 本文提出了一种适用于具有非二元特征的分类器的新型解释方法，可以提供更多关于决策和基础分类器的信息。 |
| [^29] | [Understanding accountability in algorithmic supply chains.](http://arxiv.org/abs/2304.14749) | 本文研究了算法供应链及其对算法系统治理和责任所带来的困难影响，认为算法责任的讨论必须考虑到供应链。 |
| [^30] | [Made of Steel? Learning Plausible Materials for Components in the Vehicle Repair Domain.](http://arxiv.org/abs/2304.14745) | 本文提出了一种新方法，通过探索预训练语言模型（PLM）学习车辆维修领域组件的特定材料，成功克服了数据稀疏性问题和缺乏注释数据集的问题。 |
| [^31] | [LitCQD: Multi-Hop Reasoning in Incomplete Knowledge Graphs with Numeric Literals.](http://arxiv.org/abs/2304.14742) | 本文提出LitCQD算法，用于在不完整知识图中回答带有数字字面量的复杂多跳查询，并在包含数字字面量的多跳查询数据集上表现更好。 |
| [^32] | [Benchmarking Automated Machine Learning Methods for Price Forecasting Applications.](http://arxiv.org/abs/2304.14735) | 本研究展示了将自动化机器学习解决方案与企业领域知识相结合，以替代手动创建的ML管道，为中小型企业实现自动化价格预测提供可能。 |
| [^33] | [Benchmark dataset and instance generator for Real-World Three-Dimensional Bin Packing Problems.](http://arxiv.org/abs/2304.14712) | 本文提出了一个真实世界装箱问题的基准数据集和实例生成器，可以用来比较不同装箱算法的性能。 |
| [^34] | [Image-based Indian Sign Language Recognition: A Practical Review using Deep Neural Networks.](http://arxiv.org/abs/2304.14710) | 本论文研究开发了一种基于印度手语的手语识别系统，旨在实时将手语翻译成文本以解决聋哑人和听障人士交流障碍。 |
| [^35] | [X-RLflow: Graph Reinforcement Learning for Neural Network Subgraphs Transformation.](http://arxiv.org/abs/2304.14698) | 本论文提出了一种基于强化学习的方法，X-RLflow，用于替换神经网络的子图，以求得更优的计算图结构，可在各种深度学习模型和基准测试中超越现有技术的超优化系统。 |
| [^36] | [NeuralKG-ind: A Python Library for Inductive Knowledge Graph Representation Learning.](http://arxiv.org/abs/2304.14678) | NeuralKG-ind是一种Python库，用于归纳式知识图谱表示学习。它包括标准化的流程、丰富的现有方法、解耦的模块和全面的评估指标。这个库可以帮助研究人员和工程师轻松比较不同的归纳式KGRL方法。 |
| [^37] | [Prompt Engineering for Healthcare: Methodologies and Applications.](http://arxiv.org/abs/2304.14670) | 本文介绍了医疗保健NLP领域中的提示工程最新进展，强调其在问答系统、文本摘要和机器翻译等应用中的贡献。本文提供了有用资源和桥梁，以更好地探索提示工程在医疗保健领域的应用。 |
| [^38] | [Client Recruitment for Federated Learning in ICU Length of Stay Prediction.](http://arxiv.org/abs/2304.14663) | 本研究提出了一种新的基于ICU住院时间预测的联邦学习客户端招募策略，通过准则、相似性和聚类，可以降低通信开销和训练成本，同时保持预测性能。 |
| [^39] | [MultiZenoTravel: a Tunable Benchmark for Multi-Objective Planning with Known Pareto Front.](http://arxiv.org/abs/2304.14659) | 本文提出了一个可调基准测试生成器和专用求解器用于已知帕累托前沿的多目标规划问题，并且通过实例的求解展示了该求解器的可行性和效率。 |
| [^40] | [From Explicit Communication to Tacit Cooperation:A Novel Paradigm for Cooperative MARL.](http://arxiv.org/abs/2304.14656) | 该论文提出了一种从显性沟通到隐性合作的新协作多智能体学习范式，通过在代理之间分享信息和使用本地轨迹重建信息来促进协作，并逐渐减少显式传达信息的比例。实验结果表明，这种范式在具有挑战性的情景下比传统的 CTDE 范式表现更好。 |
| [^41] | [Imbalanced Node Classification Beyond Homophilic Assumption.](http://arxiv.org/abs/2304.14635) | 提出了一种新的GraphSANN模型，用于处理同构和异构图的不平衡节点分类。 |
| [^42] | [CVRecon: Rethinking 3D Geometric Feature Learning For Neural Reconstruction.](http://arxiv.org/abs/2304.14633) | 研究团队提出了一种基于代价体的3D神经重建框架CVRecon，利用丰富的几何嵌入来促进3D几何特征学习。通过引入射线上下文补偿代价体（RCCV），有效提高了视角相关信息的完整性和鲁棒性，并在各种度量方面显着提高了重建质量。 |
| [^43] | [Let the Chart Spark: Embedding Semantic Context into Chart with Text-to-Image Generative Model.](http://arxiv.org/abs/2304.14630) | 本文提出了一个新的系统ChartSpark，利用文本到图像生成模型将语义上下文嵌入到图表中，以生成具有高质量语义上下文的图示可视化。 |
| [^44] | [Deep Intellectual Property: A Survey.](http://arxiv.org/abs/2304.14613) | 这篇综述介绍了利用深度神经网络时所面临的知识产权保护问题，以及近年来防止和发现模型窃取和未经授权重新分发的方法。 |
| [^45] | [Improve Video Representation with Temporal Adversarial Augmentation.](http://arxiv.org/abs/2304.14601) | 本文提出了Temporal Adversarial Augmentation（TA），一种利用时间注意力的视频增强技术，可以通过最大化时间相关的损失函数来改变神经网络对视频片段的注意分布。利用TA，我们提出了Temporal Video Adversarial Fine-tuning（TAF）框架，可以有效地改善视频表示并提高神经网络的泛化能力。 |
| [^46] | [Uncertainty-aware Self-supervised Learning for Cross-domain Technical Skill Assessment in Robot-assisted Surgery.](http://arxiv.org/abs/2304.14589) | 本文提出了一种采用不确定性自监督学习方法的机器人手术技能评估技术，通过将标记数据领域知识转移到未标记数据中进行训练，最终在虚拟现实模拟的训练任务中取得了显著的成果。 |
| [^47] | [\'Epilexie: A digital therapeutic approach for treating intractable epilepsy via Amenable Neurostimulation.](http://arxiv.org/abs/2304.14583) | 本研究探讨了将ANS作为一种数字治疗策略，治疗难治性癫痫的潜力，ANS使用闭环系统，可以降低癫痫的发作频率。 |
| [^48] | [Can deepfakes be created by novice users?.](http://arxiv.org/abs/2304.14576) | 本文通过用户研究发现，虽然新手用户创建Deepfakes可能不容易，但也不是完全困难，并且需要引起研究界和政策制定者的关注。 |
| [^49] | [SceneGenie: Scene Graph Guided Diffusion Models for Image Synthesis.](http://arxiv.org/abs/2304.14573) | 本文提出了SceneGenie模型，利用边界框和分割地图信息引导扩散模型生成高分辨率图像，处理复杂的文本提示。该方法使用了CLIP嵌入的语义特征，从而实现了前所未有的保真度。 |
| [^50] | [SCOPE: Structural Continuity Preservation for Medical Image Segmentation.](http://arxiv.org/abs/2304.14572) | 该论文提出了一种基于图形的方法，可以在医学图像分割中强制执行解剖学形状的连续性和连通性，以改进医学诊断的准确性。 |
| [^51] | [DIAMANT: Dual Image-Attention Map Encoders For Medical Image Segmentation.](http://arxiv.org/abs/2304.14571) | 该论文提出了一种基于双图像注意力映射编码器的医学图像分割架构，仅利用从自监督预训练视觉Transformer网络获得的注意力映射可视化，就可以以更少的计算成本胜过复杂的Transformer架构，这在多个医疗图像数据集上得到验证。 |
| [^52] | [Appropriateness is all you need!.](http://arxiv.org/abs/2304.14553) | 在chatbot的使用中，应该依据适当性原则而非纯粹的安全性原则来进行评估，以避免其受限制。 |
| [^53] | [Optimal partition of feature using Bayesian classifier.](http://arxiv.org/abs/2304.14537) | 本文通过提出一种名为“共单调独立分类器”(CIBer)的新技术，专注于特征的最优分区，旨在克服朴素贝叶斯方法带来的挑战，并且证明该技术在不同数据集上具有更高的准确率和更低的错误率。 |
| [^54] | [Adversarial Policy Optimization in Deep Reinforcement Learning.](http://arxiv.org/abs/2304.14533) | 本文提出了一种新的强化学习算法，其中一个扰动网络通过最大化智能体执行不同动作的概率，同时最小化状态的扭曲，以减轻数据过拟合的影响。 |
| [^55] | [High-dimensional Clustering onto Hamiltonian Cycle.](http://arxiv.org/abs/2304.14531) | 提出了一种基于哈密顿回路的高维聚类框架，将全局结构和局部结构相结合，通过哈密顿回路将不同簇的锚点排序并映射到圆的周长上，改进了聚类的标签，达到更好的分类效果。 |
| [^56] | [pyBibX -- A Python Library for Bibliometric and Scientometric Analysis Powered with Artificial Intelligence Tools.](http://arxiv.org/abs/2304.14516) | pyBibX是一种Python库，旨在通过Scopus、Web of Science和PubMed的原始数据文件进行全面的文献计量和科学计量分析，并将先进的人工智能能力融入到其核心功能中。 |
| [^57] | [An Efficient Ensemble Explainable AI (XAI) Approach for Morphed Face Detection.](http://arxiv.org/abs/2304.14509) | 本文提出了解决面部变形攻击检测的方法，采用多个深度神经卷积架构，但这些模型难以理解和分析，给生物测量学界带来了困扰。 |
| [^58] | [Deep state-space modeling for explainable representation, analysis, and generation of professional human poses.](http://arxiv.org/abs/2304.14502) | 本文提出一种新方法，通过引入三种新方法来创建人类运动的可解释表示，以解决建模人体运动的科学挑战，并且该方法能准确预测人体运动并生成新的运动。 |
| [^59] | [Read My Mind: A Multi-Modal Dataset for Human Belief Prediction.](http://arxiv.org/abs/2304.14501) | 该论文提出了一个大规模多模态视频数据集，用于人类信念预测，以促进人工智能系统推断人类信念的发展和评估。 |
| [^60] | [MWaste: A Deep Learning Approach to Manage Household Waste.](http://arxiv.org/abs/2304.14498) | MWaste是一款基于深度学习的移动应用，能够有效地将垃圾材料分类为垃圾、塑料、纸张、金属、玻璃或硬纸板，可帮助应对气候变化。 |
| [^61] | [Model Explainability in Physiological and Healthcare-based Neural Networks.](http://arxiv.org/abs/2304.14495) | 无需接触式传感器，使用智能手机摄像头测量SpO2的挑战性使得需要提取面部兴趣区域，从中获取光电容抗信号并使用机器学习算法估计SpO2。 |
| [^62] | [Symmetry and Complexity in Object-Centric Deep Active Inference Models.](http://arxiv.org/abs/2304.14493) | 本文研究了深度主动推理下的物体中心表示中的对称性，以生成最简洁而准确的模型，从而学习和预测新的物体视图。 |
| [^63] | [Adversary Aware Continual Learning.](http://arxiv.org/abs/2304.14483) | 本文提出了一种新的防御性框架，针对对抗性后门攻击，利用可感知模式压倒攻击者的不可感知模式，提高了模型的稳健性。 |
| [^64] | [Learning a Diffusion Prior for NeRFs.](http://arxiv.org/abs/2304.14473) | 本文提出了一种使用扩散模型生成编码在规则网格上的NeRFs的方法，该方法可以采样出逼真的NeRFs，并允许有条件的生成，给定某个观察作为指导。 |
| [^65] | [Controllable One-Shot Face Video Synthesis With Semantic Aware Prior.](http://arxiv.org/abs/2304.14471) | 本文提出一种具有语义感知先验的可控单次人脸视频合成方法，通过可靠的面部分割和新颖的语义感知运动扭曲方案，在保证语义准确和实现真实运动的同时，生成高质量的面部视频。 |
| [^66] | [Moccasin: Efficient Tensor Rematerialization for Neural Networks.](http://arxiv.org/abs/2304.14463) | 本文提出了一种名为Moccasin的新型约束编程形式，用于实现在内存预算下最小化计算图的执行时间，相较于最近的研究，该方法显著提高了效率，并成功应用于神经网络的高效张量重算。 |
| [^67] | [Machine Learning for Detection and Mitigation of Web Vulnerabilities and Web Attacks.](http://arxiv.org/abs/2304.14451) | 本文调研了使用经典和先进的机器学习技术进行防御XSS和CSRF的研究，并总结出关键要点，为探讨该研究方向提供了参考。 |
| [^68] | [Unsupervised Learning of Robust Spectral Shape Matching.](http://arxiv.org/abs/2304.14419) | 该方法提出了一种新的学习方法，使用无监督方式进行鲁棒的三维形状匹配，可以获得不同场景下的准确对应关系。 |
| [^69] | [Generative AI Perceptions: A Survey to Measure the Perceptions of Faculty, Staff, and Students on Generative AI Tools in Academia.](http://arxiv.org/abs/2304.14415) | 本文调查了学术界使用生成型人工智能工具ChatGPT的影响，旨在了解其如何革新工程教育并改变技术、教职工与学生之间的关系。调查可供其他大学和机构使用。 |
| [^70] | [Human Semantic Segmentation using Millimeter-Wave Radar Sparse Point Clouds.](http://arxiv.org/abs/2304.14132) | 本文提出了一种在毫米波雷达稀疏点云上进行人类语义分割的框架，该框架优于相机和激光雷达的隐私保护和抗干扰能力。同时，本文引入图结构和拓扑特征，并设计了一个含有全局特征模块和顺序特征模块的语义分割框架，成功解决了稀疏和时间拓扑特征的问题。 |
| [^71] | [Evaluation of GPT-3.5 and GPT-4 for supporting real-world information needs in healthcare delivery.](http://arxiv.org/abs/2304.13714) | 本研究评估了在临床环境中使用GPT-3.5和GPT-4解决医学问题的安全性以及与信息技术咨询服务报告的一致性。研究结果表明，两个LLMs都可以以安全和一致的方式满足医生的信息需求。 |
| [^72] | [End-to-End Lidar-Camera Self-Calibration for Autonomous Vehicles.](http://arxiv.org/abs/2304.12412) | 本文提出了一种名为CaLiCa的端到端深度自标定网络，用于联合自动校准针孔相机和激光雷达的固有和外参参数以确保车辆多模式感知传感器的校准质量，同时采用孪生结构以达到领域共享特征的目的。 |
| [^73] | [Stubborn: An Environment for Evaluating Stubbornness between Agents with Aligned Incentives.](http://arxiv.org/abs/2304.12280) | 本文提出了在完全合作设置下，评估代理之间固执程度的环境Stubborn，通过一个能够体现人类社交行为的指标来促进研究智能体之间的社交动态和固执行为。 |
| [^74] | [LLM as A Robotic Brain: Unifying Egocentric Memory and Control.](http://arxiv.org/abs/2304.09349) | 本文提出了一个统一自我中心记忆和控制的框架LLM-Brain，使用大规模语言模型作为机器人大脑进行零-shot学习。该框架包括封闭式多轮对话，覆盖了感知、规划、控制和记忆，具有很好的泛化性能，适用于多个机器人任务。 |
| [^75] | [Pretrained Language Models as Visual Planners for Human Assistance.](http://arxiv.org/abs/2304.09179) | 本研究提出了视觉辅助计划（VPA）的任务，利用预训练语言模型作为序列模型，在视频行动分割和预测方面优于现有的方法，来实现多模态AI助手指导用户完成复杂多步骤目标的进展。 |
| [^76] | [False Claims against Model Ownership Resolution.](http://arxiv.org/abs/2304.06607) | 该论文研究了模型所有权解决方案中对抗恶意原告的鲁棒性问题，展示了常见的MOR方案可以被恶意原告针对未被盗用的独立模型提出虚假指控。 |
| [^77] | [Qualitative Failures of Image Generation Models and Their Application in Detecting Deepfakes.](http://arxiv.org/abs/2304.06470) | 研究调查了图像生成模型的质量失误及其应用于检测Deepfakes，识别了五种定性缺陷。这些发现有助于改进模型并制定检测Deepfakes的策略。 |
| [^78] | [DR.CPO: Diversified and Realistic 3D Augmentation via Iterative Construction, Random Placement, and HPR Occlusion.](http://arxiv.org/abs/2303.12743) | 该论文提出了一种多样化和逼真的增强方法，可以创建整体对象并灵活地定位和旋转对象，并相应地应用自遮挡和外遮挡。通过迭代构建多个对象来提高整体对象构造的多样性，构造的对象可以在训练帧中随机放置和旋转。 |
| [^79] | [Explainable Contextual Anomaly Detection using Quantile Regression Forests.](http://arxiv.org/abs/2302.11239) | 该论文提出了一种可解释的上下文异常检测方法，运用分位数回归森林来模拟特征之间的依赖关系，能够更准确和可解释地识别偏离类似对象上下文的其他对象。 |
| [^80] | [A Multi-Modal Neural Geometric Solver with Textual Clauses Parsed from Diagram.](http://arxiv.org/abs/2302.11097) | 本论文提出了一种新的神经求解器PGPSNet，通过将图表转化为基本文本子句以有效描述图表特征，并结合结构和语义预训练、数据增强和自我限制解码等技术，PGPSNet拥有丰富的几何定理和几何表示知识，从而在GPS中表现出优越性。 |
| [^81] | [Scalable Real-Time Recurrent Learning Using Sparse Connections and Selective Learning.](http://arxiv.org/abs/2302.05326) | 本文提出了两个限制使得实时循环学习算法具有可扩展性，分别是将网络分解为独立模块或逐步学习网络。与其他可扩展算法不同的是，这些算法不会向梯度估计添加噪声或偏差，而是通过权衡网络的功能能力以实现可扩展学习。 |
| [^82] | [Generating High-Precision Feedback for Programming Syntax Errors using Large Language Models.](http://arxiv.org/abs/2302.04662) | 本文介绍了使用LLMs生成高精度反馈的技术，可用于固定Python程序中的语法错误。使用PyFiXV生成的反馈准确性高达92％，错误覆盖率高达72％，在编程教育中有潜在的应用价值。 |
| [^83] | [A novel framework for medium-term wind power prediction based on temporal attention mechanisms.](http://arxiv.org/abs/2302.01222) | 本文提出了一种基于树状Parzen估计器（TPE）和分解算法的新框架（TPE-VMD-TFT），用于24小时和48小时之前的风电功率预测。在法国电力公司Engie的风能数据集上，所提出的方法表现良好。 |
| [^84] | [Anomaly Segmentation for High-Resolution Remote Sensing Images Based on Pixel Descriptors.](http://arxiv.org/abs/2301.13422) | 本文提出了一个基于像素描述符的模型，用于解决高分辨率遥感图像中异常模式分割问题。模型通过数据增广生成虚拟异常标本，并使用具有区分性的像素描述符进行深度单类分类。 |
| [^85] | [On the Discredibility of Membership Inference Attacks.](http://arxiv.org/abs/2212.02701) | 成员推理攻击不可靠，应该谨慎使用，因为它们在可以识别到的确切成员样本的子种群上具有高误报率。 |
| [^86] | [Automating Rigid Origami Design.](http://arxiv.org/abs/2211.13219) | 这篇论文介绍了一种离散优化问题-刚性折纸游戏，该游戏可以扩展刚性折纸的潜力，使其得到针对应用特定的折痕图案，从而可以得到日常物品的新颖、可折叠和实用的设计。 |
| [^87] | [Low-Resource Music Genre Classification with Cross-Modal Neural Model Reprogramming.](http://arxiv.org/abs/2211.01317) | 本文提出了一种基于神经模型重新编程的迁移学习方法，并针对复杂输入数据提出了输入依赖NMR范式，能够有效地进行音乐风格分类。 |
| [^88] | [Automatic Severity Assessment of Dysarthric speech by using Self-supervised Model with Multi-task Learning.](http://arxiv.org/abs/2210.15387) | 该论文提出了一种使用自监督模型和多任务学习相结合的自动评估发音障碍严重程度的方法，在较少数据的情况下实现了向传统方法的优化，并且相对提高了1.25%的F1-score。 |
| [^89] | [The SZ flux-mass ($Y$-$M$) relation at low halo masses: improvements with symbolic regression and strong constraints on baryonic feedback.](http://arxiv.org/abs/2209.02075) | 本文通过使用液体动力学模拟和机器学习工具对低质量晕的SZ通量质量（$Y$-$M$）关系进行了全面研究，发现通过简单地将$Y \rightarrow Y(1 + M_*/M_\mathrm{gas})$可以使该关系显著自相似，这对于低质量星团和星系群是一种稳健的多波长质量代理。 |
| [^90] | [Diffsound: Discrete Diffusion Model for Text-to-sound Generation.](http://arxiv.org/abs/2207.09983) | 本研究提出了一种新的文本到音频生成框架，其中，我们采用了离散扩散解码器来增强生成性能。 |
| [^91] | [Certain and Uncertain Inference with Indicative Conditionals.](http://arxiv.org/abs/2207.08276) | 本文提出了关于指示条件句的三元语义学和概率，构建了两种条件推理逻辑：从确定前提进行推理的逻辑C和从不确定前提进行推理的逻辑U。它们都能用于分析条件推理的有效性，虽然U不遵守假言推理规则。 |
| [^92] | [A Unified Interpretable Intelligent Learning Diagnosis Framework for Smart Education.](http://arxiv.org/abs/2207.03122) | 本文提出了一种统一的可解释性智能学习诊断框架，结合了深度学习的表示学习能力和基于心理测量的方法的可解释性，使得在智慧教育中能够平衡准确性和可解释性。 |
| [^93] | [Transformer for Partial Differential Equations' Operator Learning.](http://arxiv.org/abs/2205.13671) | 本文提出一种基于注意力机制的数据驱动算子学习框架OFormer，它可以广泛适用于不同的偏微分方程，并且具有与传统方法相当的准确性，甚至在某些情况下具有更好的表现。 |
| [^94] | [CLNet: Complex Input Lightweight Neural Network designed for Massive MIMO CSI Feedback.](http://arxiv.org/abs/2102.07507) | 本文提出了一种名为CLNet的神经网络，可以在大规模MIMO CSI反馈中提高准确性，减少计算开销，同时遵循CSI的内在属性。在室内外场景中，CLNet平均准确度提高了5.41％，计算开销减少了24.1％。 |
| [^95] | [Why Learning of Large-Scale Neural Networks Behaves Like Convex Optimization.](http://arxiv.org/abs/1903.02140) | 本文介绍了利用规范空间证明学习大规模神经网络的目标函数在收敛到全局最小值时是凸优化问题。使用点线性转换的方法建立原始NN模型空间和规范空间之间的关系，证明了使用梯度下降方法，只要差异矩阵保持完整秩，就一定能收敛到零损失的全局最小值。大规模NN具有奇异的差异矩阵的概率非常小。 |
| [^96] | [The Jiminy Advisor: Moral Agreements Among Stakeholders Based on Norms and Argumentation.](http://arxiv.org/abs/1812.04741) | 本文提出了一个名为Jiminy的伦理建议组件，它使用规范系统和形式论证技术，以在利益相关者之间达成道德协议。 Jiminy通过利用规范系统代表每个利益相关者的伦理观点，并通过论证来解决涉及利益相关者意见的道德困境。 |

# 详细

[^1]: LLaMA-Adapter V2: 参数高效的视觉指令模型

    LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model. (arXiv:2304.15010v1 [cs.CV])

    [http://arxiv.org/abs/2304.15010](http://arxiv.org/abs/2304.15010)

    本文提出了LLaMA-Adapter V2，这是一个参数高效的视觉指令模型，通过解锁更多可学习的参数，早期融合策略和联合训练策略，能够更好地处理视觉输入和精确地执行开放式视觉指令。

    

    近期的研究方向是如何将大型语言模型（LLMs）高效地转化为指令跟随者，而为多模态推理训练LLM的研究仍然较少。虽然最近的LLaMA-Adapter证明了用LLM处理视觉输入的潜力，但它仍然不能很好地推广到开放式视觉指令，并且落后于GPT-4。本文提出了LLaMA-Adapter V2，这是一个参数高效的视觉指令模型。

    How to efficiently transform large language models (LLMs) into instruction followers is recently a popular research direction, while training LLM for multi-modal reasoning remains less explored. Although the recent LLaMA-Adapter demonstrates the potential to handle visual inputs with LLMs, it still cannot generalize well to open-ended visual instructions and lags behind GPT-4. In this paper, we present LLaMA-Adapter V2, a parameter-efficient visual instruction model. Specifically, we first augment LLaMA-Adapter by unlocking more learnable parameters (e.g., norm, bias and scale), which distribute the instruction-following ability across the entire LLaMA model besides adapters. Secondly, we propose an early fusion strategy to feed visual tokens only into the early LLM layers, contributing to better visual knowledge incorporation. Thirdly, a joint training paradigm of image-text pairs and instruction-following data is introduced by optimizing disjoint groups of learnable parameters. This 
    
[^2]: 大型语言模型所表现的新兴技能是否为幻觉？

    Are Emergent Abilities of Large Language Models a Mirage?. (arXiv:2304.15004v1 [cs.AI])

    [http://arxiv.org/abs/2304.15004](http://arxiv.org/abs/2304.15004)

    研究指出大型语言模型所谓的新兴技能是研究者分析的产物，不是模型行为的基本变化。研究还展示了度量标准选择和可能研究人员的偏见，可能导致这种新兴技能的出现。

    

    最近的研究声称，大型语言模型展示了新兴技能，这些技能在更小规模的模型中不存在，但在更大规模的模型中存在。新兴技能让人感到困惑的是两方面：它们的清晰度，似乎瞬间从不存在到存在，以及它们的不可预测性，似乎在不可预见的模型规模下出现。本文提出了新兴技能的另一种解释，即对于特定任务和模型族，当分析固定的模型输出时，可以选择导致推断出新兴技能或不导致推断出新兴技能的度量标准。因此，我们的解释表明，现有的新兴技能声明是研究人员分析的产物，而不是特定任务中模型行为的基本变化。我们在一个简单的数学模型中提出了我们的解释，然后通过三种互补的方式进行了测试：我们(1)制作、测试并验证了关于报告的新兴技能的度量选择的三个预测效应；(2)展示了模型架构和训练程序的简单变化会在一个已经确定的任务中产生大的新兴能力差异；(3)展示所谓的新兴技能可以通过有意优化所选择的评估指标来实现。总的来说，我们认为目前大型语言模型中新兴能力的声明很可能并不是真实存在的，而是度量标准任意选择和可能的研究人员偏见的产物。

    Recent work claims that large language models display emergent abilities, abilities not present in smaller-scale models that are present in larger-scale models. What makes emergent abilities intriguing is two-fold: their sharpness, transitioning seemingly instantaneously from not present to present, and their unpredictability, appearing at seemingly unforeseeable model scales. Here, we present an alternative explanation for emergent abilities: that for a particular task and model family, when analyzing fixed model outputs, one can choose a metric which leads to the inference of an emergent ability or another metric which does not. Thus, our alternative suggests that existing claims of emergent abilities are creations of the researcher's analyses, not fundamental changes in model behavior on specific tasks with scale. We present our explanation in a simple mathematical model, then test it in three complementary ways: we (1) make, test and confirm three predictions on the effect of metri
    
[^3]: LLM参数高效微调技术的优势和劣势的实证分析

    Empirical Analysis of the Strengths and Weaknesses of PEFT Techniques for LLMs. (arXiv:2304.14999v1 [cs.CL])

    [http://arxiv.org/abs/2304.14999](http://arxiv.org/abs/2304.14999)

    本文实证分析了参数高效微调技术在大型语言模型中的优势和劣势，提供了选择优化微调技术的框架，同时揭示了在低数据场景下PEFT技术收敛速度较慢的事实。

    

    随着基于语言模型的模型规模呈指数级增长，高效的适应方法变得越来越关键。参数高效微调（PEFT）是目前最流行的适用于大型语言模型（LLM）的方法之一，只需要修改模型参数的一小部分，最近提出了几种具有不同权衡的PEFT技术。我们在代表性的LLM FLAN-T5模型上提供各种PEFT技术的全面和统一的基准测试，并评估在分类和生成数据集的不同数据规模下的模型性能。基于此，我们提供了一个框架，根据任务类型和数据可用性选择最佳的微调技术。与传统观念相反，我们通过实证证明PEFT技术在低数据场景下收敛速度比完全微调慢，并提出了PEFT方法需要表现良好和有效收敛所需要的数据量。

    As foundation models continue to exponentially scale in size, efficient methods of adaptation become increasingly critical. Parameter-efficient fine-tuning (PEFT), a recent class of techniques that require only modifying a small percentage of the model parameters, is currently the most popular method for adapting large language models (LLMs). Several PEFT techniques have recently been proposed with varying tradeoffs. We provide a comprehensive and uniform benchmark of various PEFT techniques across a representative LLM, the FLAN-T5 model, and evaluate model performance across different data scales of classification and generation datasets. Based on this, we provide a framework for choosing the optimal fine-tuning techniques given the task type and data availability. Contrary to popular belief, we also empirically prove that PEFT techniques converge slower than full tuning in low data scenarios, and posit the amount of data required for PEFT methods to both perform well and converge eff
    
[^4]: ChatGPT - 对于本科计算机科学学生和教师是福是祸?

    ChatGPT -- a Blessing or a Curse for Undergraduate Computer Science Students and Instructors?. (arXiv:2304.14993v1 [cs.HC])

    [http://arxiv.org/abs/2304.14993](http://arxiv.org/abs/2304.14993)

    本文分析了ChatGPT在回答本科计算机科学问题上的不可靠性，并提供了在学术界使用ChatGPT的建议。

    

    ChatGPT是由OpenAI开发的AI语言模型，可以理解和生成类人文本。它可用于语言生成、问答、文本摘要、聊天机器人开发、语言翻译、情感分析、内容创作、个性化、文本完成和故事叙述等多种用途。虽然ChatGPT受到了相当积极的关注，但在学术界也引起了一种担忧和不确定感。存在担忧学生可能会利用ChatGPT完成课外作业和考试，并获得有利的成绩，而不真正获得知识。本文采用定量方法，展示了ChatGPT在回答本科计算机科学范围内的各种问题上具有高度的不可靠性。我们的分析表明，学生盲目依赖ChatGPT完成作业和考试可能会自毁前程。我们在这个分析基础上提出了教师和学生如何在学术界使用ChatGPT的建议。

    ChatGPT is an AI language model developed by OpenAI that can understand and generate human-like text. It can be used for a variety of use cases such as language generation, question answering, text summarization, chatbot development, language translation, sentiment analysis, content creation, personalization, text completion, and storytelling. While ChatGPT has garnered significant positive attention, it has also generated a sense of apprehension and uncertainty in academic circles. There is concern that students may leverage ChatGPT to complete take-home assignments and exams and obtain favorable grades without genuinely acquiring knowledge. This paper adopts a quantitative approach to demonstrate ChatGPT's high degree of unreliability in answering a diverse range of questions pertaining to topics in undergraduate computer science. Our analysis shows that students may risk self-sabotage by blindly depending on ChatGPT to complete assignments and exams. We build upon this analysis to p
    
[^5]: 利用语义视觉先验解释视觉和语言生成模型

    Interpreting Vision and Language Generative Models with Semantic Visual Priors. (arXiv:2304.14986v1 [cs.CV])

    [http://arxiv.org/abs/2304.14986](http://arxiv.org/abs/2304.14986)

    本研究提出了一种利用SHAP框架和视觉先验知识生成全面、有意义解释的方法，相较于传统方法具有更低的计算成本、更高的解释表现力，并可以推广到其他模型上。

    

    在应用于图像到文本模型时，可解释性方法通常提供逐个标记的解释，即为所生成的序列中的每个标记计算视觉解释。这些解释计算成本高，无法全面解释模型的输出。因此，这些模型通常需要某种近似方法，最终会导致误导性的解释。本文提出了一种基于SHAP的框架，该框架允许利用输出序列的含义表示生成全面、有意义的解释。此外，通过利用视觉主干网络中的语义先验知识，我们提取了任意数量的特征，并能够在大规模模型上高效计算Shapley值，同时生成高度明确的视觉解释。我们证明了我们的方法在更低的计算成本下生成语义上更具表现力的解释，并且可以推广到其他模型上。

    When applied to Image-to-text models, interpretability methods often provide token-by-token explanations namely, they compute a visual explanation for each token of the generated sequence. Those explanations are expensive to compute and unable to comprehensively explain the model's output. Therefore, these models often require some sort of approximation that eventually leads to misleading explanations. We develop a framework based on SHAP, that allows for generating comprehensive, meaningful explanations leveraging the meaning representation of the output sequence as a whole. Moreover, by exploiting semantic priors in the visual backbone, we extract an arbitrary number of features that allows the efficient computation of Shapley values on large-scale models, generating at the same time highly meaningful visual explanations. We demonstrate that our method generates semantically more expressive explanations than traditional methods at a lower compute cost and that it can be generalized o
    
[^6]: 集合Kemeny投票机制的最优多数规则和数量化博德雷得准则

    Optimal majority rules and quantitative Condorcet properties of setwise Kemeny voting schemes. (arXiv:2304.14980v1 [cs.GT])

    [http://arxiv.org/abs/2304.14980](http://arxiv.org/abs/2304.14980)

    本文研究了集合Kemeny投票机制，提出了最优多数规则和数量化博德雷得准则，并比较了传统Kemeny规则和3-方式Kemeny投票方案的优劣。

    

    Kemeny问题是计算选举的中位数共识排名的重要问题，具有生物学和计算社会选择等重要应用，并通过Gilbert等人的有趣的集合方法最近得到了推广。我们的第一组结果确定了传统Kemeny中位数问题的一致性属性和著名的Betzler等人的3/4多数规则的最优量化扩展。此外，通过详细列出数量化公理属性（如Condorcet和Smith准则，5/6多数规则等）的详尽清单，我们发现对于3个候选人的子集的优胜者之间不仅考虑成对比较还要考虑不一致性，由3-方式Kemeny规则引出的3-方式Kendall-tau距离诱导的3-方式Kemeny投票方案与传统Kemeny规则相比具有有趣的优势。

    The important Kemeny problem, which consists of computing median consensus rankings of an election with respect to the Kemeny voting rule, admits important applications in biology and computational social choice and was generalized recently via an interesting setwise approach by Gilbert et. al. Our first results establish optimal quantitative extensions of the Unanimity property and the well-known $3/4$-majority rule of Betzler et al. for the classical Kemeny median problem. Moreover, by elaborating an exhaustive list of quantified axiomatic properties (such as the Condorcet and Smith criteria, the $5/6$-majority rule, etc.) of the $3$-wise Kemeny rule where not only pairwise comparisons but also the discordance between the winners of subsets of three candidates are also taken into account, we come to the conclusion that the $3$-wise Kemeny voting scheme induced by the $3$-wise Kendall-tau distance presents interesting advantages in comparison with the classical Kemeny rule. For exampl
    
[^7]: MLCopilot：释放大语言模型在解决机器学习任务中的能力

    MLCopilot: Unleashing the Power of Large Language Models in Solving Machine Learning Tasks. (arXiv:2304.14979v1 [cs.LG])

    [http://arxiv.org/abs/2304.14979](http://arxiv.org/abs/2304.14979)

    本文介绍了一种新型框架MLCopilot，通过利用最先进的大语言模型，扩展其能力以理解结构化输入并进行深入推理以解决新型ML任务的能力，展示了MLCopilot在解决图像分类，文本分类和表格分类三项任务方面的巨大潜力。

    

    机器学习（ML）领域受到了广泛的应用，因此逐渐引发了将ML应用于特定场景的需求，但实现起来耗时且不易。 自动化解决ML任务（例如AutoML）的主要方法通常耗费时间且难以理解。 而与之相反，虽然人类工程师具有理解任务和推理解决方案的难以置信的能力，但他们的经验和知识往往不充分且难以借助定量方法利用。 在本文中，我们旨在通过引入一种新颖的框架MLCopilot来弥合机器智能和人类知识之间的差距，该框架利用最先进的LLM来开发新型任务的ML解决方案。 我们展示了扩展LLM的能力以理解结构化输入并进行深入推理以解决新型ML任务的可能性。 经过一些专门设计后，我们发现LLM可以（i）从人类编写的文件中观察现有知识，（ii）制定解决ML任务的具体步骤。 我们对图像分类，文本分类和表格分类三项任务进行了实验，证明了MLCopilot在解决实际ML问题方面的巨大潜力。

    The field of machine learning (ML) has gained widespread adoption, leading to a significant demand for adapting ML to specific scenarios, which is yet expensive and non-trivial. The predominant approaches towards the automation of solving ML tasks (e.g., AutoML) are often time consuming and hard to understand for human developers. In contrast, though human engineers have the incredible ability to understand tasks and reason about solutions, their experience and knowledge are often sparse and difficult to utilize by quantitative approaches. In this paper, we aim to bridge the gap between machine intelligence and human knowledge by introducing a novel framework MLCopilot, which leverages the state-of-the-art LLMs to develop ML solutions for novel tasks. We showcase the possibility of extending the capability of LLMs to comprehend structured inputs and perform thorough reasoning for solving novel ML tasks. And we find that, after some dedicated design, the LLM can (i) observe from the exi
    
[^8]: 一种新的量子Dempster组合规则

    A New Quantum Dempster Rule of Combination. (arXiv:2304.14966v1 [quant-ph])

    [http://arxiv.org/abs/2304.14966](http://arxiv.org/abs/2304.14966)

    该论文提出了一种新的量子Dempster组合规则（QDRC），利用Toffoli门实现，能够应对Dempster组合规则计算复杂度指数级增长的问题。

    

    Dempster组合规则（DRC）被广泛用于智能信息系统中的不确定性推理，最近也被推广到了复杂领域。然而，随着识别框架元素数量的增加，Dempster组合规则的计算复杂度会呈指数级增长。为了解决这个问题，我们通过Toffoli门提出了一种新的量子Dempster组合规则（QDRC）。QDRC组合过程完全使用量子电路实现。

    Dempster rule of combination (DRC) is widely used for uncertainty reasoning in intelligent information system, which is generalized to complex domain recently. However, as the increase of identification framework elements, the computational complexity of Dempster Rule of Combination increases exponentially. To address this issue, we propose a novel quantum Dempster rule of combination (QDRC) by means of Toffoli gate. The QDRC combination process is completely implemented using quantum circuits.
    
[^9]: 一项多模态模型融合的实证研究

    An Empirical Study of Multimodal Model Merging. (arXiv:2304.14933v1 [cs.CV])

    [http://arxiv.org/abs/2304.14933](http://arxiv.org/abs/2304.14933)

    本研究通过融合在不同模态上训练的transformer进行多模态模型融合，并提出一种参数有效的模态不可知架构，形成有效的训练配方。

    

    模型融合（例如插值或任务算术）将在不同任务上训练的多个模型合并以生成多任务解决方案。该技术在先前的研究中已经被证明成功，其中模型是在相似的任务和相同的初始化下训练的。在本文中，我们通过将在不同模态上训练的transformer进行融合，将此概念扩展到多模态设置。此外，我们针对一个新颖的目标进行研究，在该目标中，我们可以将视觉、语言和跨模态的transformer合并到特定模态的架构中，以创建一个参数有效的模态不可知架构。通过全面的实验，我们系统地研究了影响模型融合后性能的关键因素，包括初始化、融合机制和模型架构。我们的分析得出了一个有效的训练配方，可以通过模型融合来匹配模态不可知基线的性能（即从头开始预训练）。我们的代码可供使用。

    Model merging (e.g., via interpolation or task arithmetic) fuses multiple models trained on different tasks to generate a multi-task solution. The technique has been proven successful in previous studies, where the models are trained on similar tasks and with the same initialization. In this paper, we expand on this concept to a multimodal setup by merging transformers trained on different modalities. Furthermore, we conduct our study for a novel goal where we can merge vision, language, and cross-modal transformers of a modality-specific architecture to create a parameter-efficient modality-agnostic architecture. Through comprehensive experiments, we systematically investigate the key factors impacting model performance after merging, including initialization, merging mechanisms, and model architectures. Our analysis leads to an effective training recipe for matching the performance of the modality-agnostic baseline (i.e. pre-trained from scratch) via model merging. Our code is availa
    
[^10]: 基于相似性和敏感性的不确定性感知神经网络

    Uncertainty Aware Neural Network from Similarity and Sensitivity. (arXiv:2304.14925v1 [cs.LG])

    [http://arxiv.org/abs/2304.14925](http://arxiv.org/abs/2304.14925)

    本文提出了一种神经网络训练方法，可以考虑相似样本与敏感性感知，有效地计算神经网络中的不确定性。

    

    计算神经网络（NN）不确定性的研究已有多种方法被提出。然而，大多数的方法都是基于强假设的，并且在某些输入领域中表现不佳，而表现不佳的原因尚不明确。因此，本文提出了一种考虑相似样本与敏感性感知的神经网络训练方法。在这种方法中，我们首先训练一个浅层神经网络进行点预测。然后，我们计算预测值和目标值之间的绝对差值，并训练另一个神经网络来预测这些绝对差值或者绝对误差。平均绝对误差较高的领域表示高度不确定性。在接下来的步骤中，我们逐个选择训练集中的每个样本，并计算预测和误差的敏感性。然后我们选择敏感性考虑的相似样本并保存相似样本的索引。

    Researchers have proposed several approaches for neural network (NN) based uncertainty quantification (UQ). However, most of the approaches are developed considering strong assumptions. Uncertainty quantification algorithms often perform poorly in an input domain and the reason for poor performance remains unknown. Therefore, we present a neural network training method that considers similar samples with sensitivity awareness in this paper. In the proposed NN training method for UQ, first, we train a shallow NN for the point prediction. Then, we compute the absolute differences between prediction and targets and train another NN for predicting those absolute differences or absolute errors. Domains with high average absolute errors represent a high uncertainty. In the next step, we select each sample in the training set one by one and compute both prediction and error sensitivities. Then we select similar samples with sensitivity consideration and save indexes of similar samples. The ra
    
[^11]: 一种通过解释性引导进行司机疲劳检测的脑电信号通道选择框架

    An EEG Channel Selection Framework for Driver Drowsiness Detection via Interpretability Guidance. (arXiv:2304.14920v1 [eess.SP])

    [http://arxiv.org/abs/2304.14920](http://arxiv.org/abs/2304.14920)

    本文提出了一种解释性引导的通道选择框架（ICS）用于司机疲劳检测任务，通过逐步选择关键的贡献通道，在提高司机疲劳检测准确性、可解释性和效率方面具有显著的效果。

    

    疲劳驾驶对行车安全有着至关重要的影响，促使人们迫切需要进行司机疲劳检测。脑电图（EEG）信号能够准确反映精神疲劳状态，因此在疲劳监测方面得到了广泛研究。然而，原始的EEG数据本质上是嘈杂且冗余的，这被现有的研究忽视了，这些研究仅使用单通道EEG数据或全头通道EEG数据进行模型训练，导致司机疲劳检测性能有限。本文首次提出了一种解释性引导的通道选择框架（ICS）用于司机疲劳检测任务。具体而言，我们设计了一个两阶段的训练策略，通过解释性引导逐步选择关键的贡献通道。我们首先在第一阶段使用全头通道EEG数据训练一个教师网络，然后对训练好的教师模型应用类激活映射（CAM）来突出显示对于疲劳检测任务有高贡献的通道。基于选择的关键通道，我们在第二阶段训练一个更轻量级的学生网络，它使用的通道数量少得多，同时实现了与最先进方法相当的性能。在两个公共数据集上的实验结果表明，我们的ICS框架在提高司机疲劳检测的准确性、可解释性和效率方面具有显著的效果。

    Drowsy driving has a crucial influence on driving safety, creating an urgent demand for driver drowsiness detection. Electroencephalogram (EEG) signal can accurately reflect the mental fatigue state and thus has been widely studied in drowsiness monitoring. However, the raw EEG data is inherently noisy and redundant, which is neglected by existing works that just use single-channel EEG data or full-head channel EEG data for model training, resulting in limited performance of driver drowsiness detection. In this paper, we are the first to propose an Interpretability-guided Channel Selection (ICS) framework for the driver drowsiness detection task. Specifically, we design a two-stage training strategy to progressively select the key contributing channels with the guidance of interpretability. We first train a teacher network in the first stage using full-head channel EEG data. Then we apply the class activation mapping (CAM) to the trained teacher model to highlight the high-contributing
    
[^12]: 表示很重要：棋盘游戏对视觉Transformer提出了挑战

    Representation Matters: The Game of Chess Poses a Challenge to Vision Transformers. (arXiv:2304.14918v1 [cs.AI])

    [http://arxiv.org/abs/2304.14918](http://arxiv.org/abs/2304.14918)

    这篇论文通过改变输入表示和价值损失，使棋盘游戏性能获得了高达180 Elo点的增强

    

    虽然Transformer已经成为了“AI的瑞士军刀”，但没有人挑战它们去掌握象棋这个经典的AI基准。但仅仅使用视觉Transformer（ViT）在AlphaZero中无法掌握象棋，主要是因为ViT太慢了。即使使用MobileNet和NextViT的组合使它们更有效，也无法击败实际上更重要的东西：简单改变输入表示和价值损失，从而获得高达180 Elo点的增强。

    While transformers have gained the reputation as the "Swiss army knife of AI", no one has challenged them to master the game of chess, one of the classical AI benchmarks. Simply using vision transformers (ViTs) within AlphaZero does not master the game of chess, mainly because ViTs are too slow. Even making them more efficient using a combination of MobileNet and NextViT does not beat what actually matters: a simple change of the input representation and value loss, resulting in a greater boost of up to 180 Elo points over AlphaZero.
    
[^13]: 通过脉搏波分析估计血压的挑战：能否承受？

    "Can't Take the Pressure?": Examining the Challenges of Blood Pressure Estimation via Pulse Wave Analysis. (arXiv:2304.14916v1 [eess.SP])

    [http://arxiv.org/abs/2304.14916](http://arxiv.org/abs/2304.14916)

    本文分析了脉搏波分析预测血压的任务，发现许多论文常常出现数据泄漏和对任务及预处理步骤的不切实际限制。提出了新的工具来确定输入信号（如PPG）是否能预测所需的量度。

    

    利用可穿戴传感器数据（如光电容积波形图[PPG]）推导健康量度（如葡萄糖水平或血压）是目前非常热门的研究领域。该技术可以对健康筛查、慢性病管理和远程监测产生重大影响。本文分析了从PPG脉搏波分析中预测血压的任务。我们的研究发现，许多论文容易出现数据泄漏以及对任务和预处理步骤的不切实际限制。因此，我们提出了一套工具来确定输入信号（如PPG）是否能够良好地预测所需的量度。

    The use of observed wearable sensor data (e.g., photoplethysmograms [PPG]) to infer health measures (e.g., glucose level or blood pressure) is a very active area of research. Such technology can have a significant impact on health screening, chronic disease management and remote monitoring. A common approach is to collect sensor data and corresponding labels from a clinical grade device (e.g., blood pressure cuff), and train deep learning models to map one to the other. Although well intentioned, this approach often ignores a principled analysis of whether the input sensor data has enough information to predict the desired metric. We analyze the task of predicting blood pressure from PPG pulse wave analysis. Our review of the prior work reveals that many papers fall prey data leakage, and unrealistic constraints on the task and the preprocessing steps. We propose a set of tools to help determine if the input signal in question (e.g., PPG) is indeed a good predictor of the desired label
    
[^14]: 使用自监督表示法识别穿戴数据的人类活动

    Human Activity Recognition Using Self-Supervised Representations of Wearable Data. (arXiv:2304.14912v1 [eess.SP])

    [http://arxiv.org/abs/2304.14912](http://arxiv.org/abs/2304.14912)

    本文提出了一个基于自监督表示法识别人类活动的模型，该模型在大量未标记数据集的基础上获得了较强性能，并在真实世界数据集上展现出了很好的效果。

    

    利用佩戴传感器进行自动化和准确的人类活动识别（HAR）可以实现实用和经济效益的日常生活活动（ADL）的远程监测，这些活动已被证明可提供跨多个治疗领域的临床洞见。准确地识别人类活动（HAR）的算法的发展受到缺乏大型真实世界标记数据集的阻碍。此外，算法很少能够超越它们原型上的特定传感器，引发了有关是否可能基于加速度计的HAR的争议[Tong等人，2020]。在这里，我们开发了一个六类HAR模型，当在训练期间未见过的真实世界数据集上进行评估时，具有较强的性能。我们的模型基于在大型未标记数据集上学习的冻结自监督表示法，结合具有时间平滑的浅层多层感知器。该模型在Capture24数据集[$\kappa$=0.86]内部数据集达到最先进的性能水平。分布外（OOD）表现

    Automated and accurate human activity recognition (HAR) using body-worn sensors enables practical and cost efficient remote monitoring of Activity of DailyLiving (ADL), which are shown to provide clinical insights across multiple therapeutic areas. Development of accurate algorithms for human activity recognition(HAR) is hindered by the lack of large real-world labeled datasets. Furthermore, algorithms seldom work beyond the specific sensor on which they are prototyped, prompting debate about whether accelerometer-based HAR is even possible [Tong et al., 2020]. Here we develop a 6-class HAR model with strong performance when evaluated on real-world datasets not seen during training. Our model is based on a frozen self-supervised representation learned on a large unlabeled dataset, combined with a shallow multi-layer perceptron with temporal smoothing. The model obtains in-dataset state-of-the art performance on the Capture24 dataset ($\kappa= 0.86$). Out-of-distribution (OOD) performan
    
[^15]: 评估CNN中语义概念表示的稳定性，以实现强大的可解释性

    Evaluating the Stability of Semantic Concept Representations in CNNs for Robust Explainability. (arXiv:2304.14864v1 [cs.AI])

    [http://arxiv.org/abs/2304.14864](http://arxiv.org/abs/2304.14864)

    本文提出了一种用于评估语义概念表示在CNN中稳定性的方法，为实现强大的可解释性提供了基础。本文关注计算机视觉CNN中概念表示的稳定性：概念检索稳定性和概念归属稳定性。在此基础上，本文提出了一种新的度量标准以解决概念检索稳定性的问题。

    

    在可解释的人工智能（XAI）中，分析卷积神经网络（CNNs）中语义概念的表示是一种广泛使用的方法。其动机是因为各个领域如自动驾驶等安全关键的基于AI的系统需要透明度。然而，要将这些概念表示用于安全相关目的，例如检查或错误检索，这些表示必须具有高质量，特别是稳定性。本文关注计算机视觉CNN中概念表示的稳定性：概念检索稳定性和概念归属稳定性。以目标检测（OD）CNN的事后可解释性框架为指导目标，成功地将现有的概念分析（CA）方法应用于其上。为了解决概念检索的稳定性问题，我们提出了一种新的度量标准，考虑概念分离和一致性，与层和概念表示无关。

    Analysis of how semantic concepts are represented within Convolutional Neural Networks (CNNs) is a widely used approach in Explainable Artificial Intelligence (XAI) for interpreting CNNs. A motivation is the need for transparency in safety-critical AI-based systems, as mandated in various domains like automated driving. However, to use the concept representations for safety-relevant purposes, like inspection or error retrieval, these must be of high quality and, in particular, stable. This paper focuses on two stability goals when working with concept representations in computer vision CNNs: stability of concept retrieval and of concept attribution. The guiding use-case is a post-hoc explainability framework for object detection (OD) CNNs, towards which existing concept analysis (CA) methods are successfully adapted. To address concept retrieval stability, we propose a novel metric that considers both concept separation and consistency, and is agnostic to layer and concept representati
    
[^16]: 一种用于实时多标签天气识别的MASK-CNN-Transformer模型

    MASK-CNN-Transformer For Real-Time Multi-Label Weather Recognition. (arXiv:2304.14857v1 [cs.CV])

    [http://arxiv.org/abs/2304.14857](http://arxiv.org/abs/2304.14857)

    本文提出了一种考虑天气条件复杂共现依赖关系的多标签识别模型MASK-CNN-Transformer，该模型结合了CNN和Transformer，并利用MASK机制以提高泛化能力。

    

    天气识别对于许多实际生活应用，包括交通安全、环境和气象方面都是至关重要的支持。然而，许多现有的相关工作由于复杂的共现依赖关系而无法全面描述天气条件。本文提出了一种考虑这些依赖关系的新型多标签天气识别模型。该模型名为MASK-CNN-Transformer (MASK-CT)，基于Transformer、卷积过程和MASK机制。

    Weather recognition is an essential support for many practical life applications, including traffic safety, environment, and meteorology. However, many existing related works cannot comprehensively describe weather conditions due to their complex co-occurrence dependencies. This paper proposes a novel multi-label weather recognition model considering these dependencies. The proposed model called MASK-Convolutional Neural Network-Transformer (MASK-CT) is based on the Transformer, the convolutional process, and the MASK mechanism. The model employs multiple convolutional layers to extract features from weather images and a Transformer encoder to calculate the probability of each weather condition based on the extracted features. To improve the generalization ability of MASK-CT, a MASK mechanism is used during the training phase. The effect of the MASK mechanism is explored and discussed. The Mask mechanism randomly withholds some information from one-pair training instances (one image an
    
[^17]: 将音乐人声分离建模为链路预测：将音乐感知任务建模为多轨迹跟踪问题

    Musical Voice Separation as Link Prediction: Modeling a Musical Perception Task as a Multi-Trajectory Tracking Problem. (arXiv:2304.14848v1 [cs.SD])

    [http://arxiv.org/abs/2304.14848](http://arxiv.org/abs/2304.14848)

    本文提出了一种将音乐人声分离的感知任务建模为多轨迹跟踪问题的方法，通过预测音符之间的链接将不同的人声进行分离，从而鼓励单声部（人声）轨迹的产生。

    

    本文旨在解决在多声部音乐中分离不同人声（即单声部旋律流）的感知问题。我们针对符号音乐，即明确编码音符，将此任务建模为从离散观测（即音高-时间空间中的音符）中的多轨迹跟踪问题。我们的方法通过为每个音符创建一个节点来构建音乐片段的图形，并通过预测两个音符之间的链接来分离旋律轨迹，如果它们在同一声部/流中连续。这种局部，贪心的预测是由异质图神经网络创建的节点嵌入所实现的，该节点嵌入可以捕捉轨迹之间和轨迹内的信息。此外，我们提出了一种新的正则化损失，鼓励输出遵守每个节点最多有一个入口和一个出口链接的多轨迹跟踪前提，支持单声部（人声）轨迹；这种损失函数在其他生成序列设置中也可能有用。

    This paper targets the perceptual task of separating the different interacting voices, i.e., monophonic melodic streams, in a polyphonic musical piece. We target symbolic music, where notes are explicitly encoded, and model this task as a Multi-Trajectory Tracking (MTT) problem from discrete observations, i.e., notes in a pitch-time space. Our approach builds a graph from a musical piece, by creating one node for every note, and separates the melodic trajectories by predicting a link between two notes if they are consecutive in the same voice/stream. This kind of local, greedy prediction is made possible by node embeddings created by a heterogeneous graph neural network that can capture inter- and intra-trajectory information. Furthermore, we propose a new regularization loss that encourages the output to respect the MTT premise of at most one incoming and one outgoing link for every node, favouring monophonic (voice) trajectories; this loss function might also be useful in other gener
    
[^18]: 使用同态加密对大规模CNN进行敏感调整以进行端到端安全预测

    Sensitive Tuning of Large Scale CNNs for E2E Secure Prediction using Homomorphic Encryption. (arXiv:2304.14836v1 [cs.LG])

    [http://arxiv.org/abs/2304.14836](http://arxiv.org/abs/2304.14836)

    本论文提出一种新的HE友好模型训练方法，成功演示了在ResNet和ConvNeXt等经典和现代CNN上运行加密样本，并以前所未有的方式演示了如何使用CLIP GPT-2模型进行零知识安全预测，是一种可行的隐私保护机器学习解决方案。

    

    隐私保护的机器学习解决方案近来受到了广泛关注。其中一种有前途的研究趋势是使用同态加密（HE），这是一种在加密数据上执行计算的方法。这种方法的一个主要挑战是训练适用于HE的加密或未加密的深层CNN，以实现良好的准确性。我们提出了一种新的HE友好模型训练方法，并在基本和现代CNN上进行了演示，例如ResNet和ConvNeXt。训练后，我们使用HELayers SDK运行加密样本来评估我们的模型，并证明它们产生了所需的结果。在ImageNet数据集上运行时，我们的ResNet-18/50/101实现仅需要7、31和57分钟，这表明这个解决方案是实用的。此外，我们提供了一些关于在HE下处理激活函数和跳跃连接的见解。最后，我们以前所未有的方式演示了如何使用CLIP GPT-2模型进行零知识安全预测。

    Privacy-preserving machine learning solutions have recently gained significant attention. One promising research trend is using Homomorphic Encryption (HE), a method for performing computation over encrypted data. One major challenge in this approach is training HE-friendly, encrypted or unencrypted, deep CNNs with decent accuracy. We propose a novel training method for HE-friendly models, and demonstrate it on fundamental and modern CNNs, such as ResNet and ConvNeXt. After training, we evaluate our models by running encrypted samples using HELayers SDK and proving that they yield the desired results. When running on a GPU over the ImageNet dataset, our ResNet-18/50/101 implementations take only 7, 31 and 57 minutes, respectively, which shows that this solution is practical. Furthermore, we present several insights on handling the activation functions and skip-connections under HE. Finally, we demonstrate in an unprecedented way how to perform secure zero-shot prediction using a CLIP m
    
[^19]: ViziQuer中的可视化图形查询: 概述和实现

    Visual Diagrammatic Queries in ViziQuer: Overview and Implementation. (arXiv:2304.14825v1 [cs.DB])

    [http://arxiv.org/abs/2304.14825](http://arxiv.org/abs/2304.14825)

    ViziQuer是一种可视化查询符号和工具，提供了可视化图形手段来描述丰富的数据查询。它的创新点在于提供一种可视化的方式来进行数据查询，使得非技术专家也能参与到数据查询的过程中。

    

    知识图谱已成为一种重要的数据组织范式。SPARQL等可用的文本查询语言用于从知识图谱中检索信息，但不提供参与非技术专家的数据访问过程的方法。与基于表单和自然语言的查询一起，可视化查询形式提供了一种简化用户参与数据查询过程的方法。ViziQuer是一种可视化查询符号和工具，提供了可视化图形手段来描述丰富的数据查询，包括可选和否定构造，以及聚合和子查询。在本文中，我们从最终用户的角度回顾了可视化ViziQuer符号，并描述了概念和技术解决方案（包括抽象语法模型，以及文本查询生成模型），这些解决方案允许将可视化图形查询符号映射到文本SPARQL语言，从而实现了实际数据上的丰富可视化查询的执行。

    Knowledge graphs (KG) have become an important data organization paradigm. The available textual query languages for information retrieval from KGs, as SPARQL for RDF-structured data, do not provide means for involving non-technical experts in the data access process. Visual query formalisms, alongside form-based and natural language-based ones, offer means for easing user involvement in the data querying process. ViziQuer is a visual query notation and tool offering visual diagrammatic means for describing rich data queries, involving optional and negation constructs, as well as aggregation and subqueries. In this paper we review the visual ViziQuer notation from the end-user point of view and describe the conceptual and technical solutions (including abstract syntax model, followed by a generation model for textual queries) that allow mapping of the visual diagrammatic query notation into the textual SPARQL language, thus enabling the execution of rich visual queries over the actual 
    
[^20]: 一种基于深度学习辅助微波等离子体相互作用技术的等离子体密度估计方法

    Deep Learning assisted microwave-plasma interaction based technique for plasma density estimation. (arXiv:2304.14807v1 [physics.plasm-ph])

    [http://arxiv.org/abs/2304.14807](http://arxiv.org/abs/2304.14807)

    本文提出了一种基于深度学习辅助微波等离子体相互作用技术的等离子体密度估计方法，通过测量微波散射引起的电场模式来估计密度剖面。

    

    电子密度是表征任何等离子体的关键参数。低温等离子体领域的大部分应用和研究都基于等离子体密度和等离子体温度。传统的电子密度测量方法针对给定线性低温等离子体设备提供轴向和径向剖面。这些方法存在操作范围较小、仪器沉重以及数据分析过程复杂等主要缺点。为了应对这些实际问题，本文提出了一种新颖的机器学习（ML）辅助微波等离子体相互作用的策略，该策略能够确定等离子体内电子密度剖面。通过测量微波散射引起的电场模式来估计密度剖面。该策略针对一个模拟的训练数据集进行了概念验证，其中包括低温、非磁化和碰撞性等离子体的不同类型的高斯形状密度剖面范围内。

    The electron density is a key parameter to characterize any plasma. Most of the plasma applications and research in the area of low-temperature plasmas (LTPs) is based on plasma density and plasma temperature. The conventional methods for electron density measurements offer axial and radial profiles for any given linear LTP device. These methods have major disadvantages of operational range (not very wide), cumbersome instrumentation, and complicated data analysis procedures. To address such practical concerns, the article proposes a novel machine learning (ML) assisted microwave-plasma interaction based strategy which is capable enough to determine the electron density profile within the plasma. The electric field pattern due to microwave scattering is measured to estimate the density profile. The proof of concept is tested for a simulated training data set comprising a low-temperature, unmagnetized, collisional plasma. Different types of Gaussian-shaped density profiles, in the range
    
[^21]: ResiDual：具有双重残差连接的Transformer

    ResiDual: Transformer with Dual Residual Connections. (arXiv:2304.14802v1 [cs.CL])

    [http://arxiv.org/abs/2304.14802](http://arxiv.org/abs/2304.14802)

    本文提出了具有Pre-Post-LN双重残差连接的新型Transformer架构ResiDual，解决了Post-LN和Pre-LN存在的问题，并具有优越的性能表现。

    

    由于其卓越的性能，Transformer网络已成为许多任务的首选架构。然而，如何最优化地实现Transformer中的残差连接仍存在争议，而这些残差连接对于有效训练是必不可少的。两个广泛使用的变体是Post-Layer-Normalization(Post-LN)和Pre-Layer-Normalization(Pre-LN) Transformers，它们分别在每个残差块的输出之后或输入之前应用层规范化。尽管两种变体都有它们的优点，但也存在严重的局限性：Post-LN会导致梯度消失问题，从而阻碍训练深层Transformer，而Pre-LN会导致表示崩溃问题，限制模型容量。本文提出了一种新颖的Transformer架构ResiDual，具有Pre-Post-LN(PPLN)，它将Post-LN和Pre-LN中的连接融合在一起，继承了它们的优点，同时避免了它们的局限性。我们进行了理论分析和实证评估，表明ResiDual比现有方法优越，尤其是训练非常深的Transformer。

    Transformer networks have become the preferred architecture for many tasks due to their state-of-the-art performance. However, the optimal way to implement residual connections in Transformer, which are essential for effective training, is still debated. Two widely used variants are the Post-Layer-Normalization (Post-LN) and Pre-Layer-Normalization (Pre-LN) Transformers, which apply layer normalization after each residual block's output or before each residual block's input, respectively. While both variants enjoy their advantages, they also suffer from severe limitations: Post-LN causes gradient vanishing issue that hinders training deep Transformers, and Pre-LN causes representation collapse issue that limits model capacity. In this paper, we propose ResiDual, a novel Transformer architecture with Pre-Post-LN (PPLN), which fuses the connections in Post-LN and Pre-LN together and inherits their advantages while avoids their limitations. We conduct both theoretical analyses and empiric
    
[^22]: 基于多对单的知识蒸馏的点云语义分割

    Multi-to-Single Knowledge Distillation for Point Cloud Semantic Segmentation. (arXiv:2304.14800v1 [cs.CV])

    [http://arxiv.org/abs/2304.14800](http://arxiv.org/abs/2304.14800)

    本文提出了一个基于多对单知识蒸馏的模型来提高点云语义分割中的分类表现，该模型针对难分类类别只融合它们的实例，并使用多级蒸馏框架和实例感知构形蒸馏算法从多个扫描中蒸馏有价值的知识。

    

    三维点云语义分割是环境理解的基本任务之一。尽管近年来已经取得了显著的进展，但是对于样本较少或点数较少的类的性能仍然不够满意。本文提出了一种新颖的基于多对单知识蒸馏框架，来提高那些难分类的类的性能。不同于直接融合多个扫描的所有点，只融合属于之前定义的难分类类别的实例。为了有效和充分地从多个扫描中蒸馏有价值的知识，我们使用了多级蒸馏框架，即特征表征蒸馏、logit蒸馏和构形蒸馏。我们进一步开发了一种新型的实例感知构形蒸馏算法，用于捕捉高层次的结构知识，以增强难分类的蒸馏效能。最后，在官方数据集上对我们的方法进行了实验。

    3D point cloud semantic segmentation is one of the fundamental tasks for environmental understanding. Although significant progress has been made in recent years, the performance of classes with few examples or few points is still far from satisfactory. In this paper, we propose a novel multi-to-single knowledge distillation framework for the 3D point cloud semantic segmentation task to boost the performance of those hard classes. Instead of fusing all the points of multi-scans directly, only the instances that belong to the previously defined hard classes are fused. To effectively and sufficiently distill valuable knowledge from multi-scans, we leverage a multilevel distillation framework, i.e., feature representation distillation, logit distillation, and affinity distillation. We further develop a novel instance-aware affinity distillation algorithm for capturing high-level structural knowledge to enhance the distillation efficacy for hard classes. Finally, we conduct experiments on 
    
[^23]: 利用精确压缩学习图神经网络

    Learning Graph Neural Networks using Exact Compression. (arXiv:2304.14793v1 [cs.LG])

    [http://arxiv.org/abs/2304.14793](http://arxiv.org/abs/2304.14793)

    本文研究了利用精确压缩来减少在大型图上学习图神经网络的内存需求，并提出了一种证明等效的压缩图神经网络学习问题的方法。

    

    图神经网络是一种深度学习技术，可以对图结构数据进行广泛的机器学习应用。学习这种网络，然而，对于内存受限的设备（如GPU）来说是一大挑战。本文研究了利用精确压缩来减少在大型图上学习图神经网络的内存需求。具体而言，我们采用了一种形式化压缩方法，并提出了一种方法，将图神经网络学习问题转化为证明等效的压缩图神经网络学习问题。在初步的实验评估中，我们洞察了真实世界图上可以获得的压缩比，并将我们的方法应用于现有的一个图神经网络基准测试。

    Graph Neural Networks (GNNs) are a form of deep learning that enable a wide range of machine learning applications on graph-structured data. The learning of GNNs, however, is known to pose challenges for memory-constrained devices such as GPUs. In this paper, we study exact compression as a way to reduce the memory requirements of learning GNNs on large graphs. In particular, we adopt a formal approach to compression and propose a methodology that transforms GNN learning problems into provably equivalent compressed GNN learning problems. In a preliminary experimental evaluation, we give insights into the compression ratios that can be obtained on real-world graphs and apply our methodology to an existing GNN benchmark.
    
[^24]: GPT-SW3多语言分词器的训练与评估

    Training and Evaluation of a Multilingual Tokenizer for GPT-SW3. (arXiv:2304.14780v1 [cs.CL])

    [http://arxiv.org/abs/2304.14780](http://arxiv.org/abs/2304.14780)

    本文介绍了GPT-SW3的多语言分词器，通过使用SentencePiece库和BPE算法在Nordic Pile上训练，评估了其对于不同语言的表现和性能。

    

    本篇论文详细介绍了GPT-SW3所使用的多语言分词器。该分词器使用SentencePiece库和BPE算法在Nordic Pile上进行训练。我们概述了分词器的最重要特点，并分享了其学习词汇的细节。此外，我们系统地分析了分词器在数据中不同语言方面的性能，并进行了评估。

    This paper provides a detailed discussion of the multilingual tokenizer used for GPT-SW3. It was trained on the Nordic Pile using the SentencePiece library and the BPE algorithm. We outline the tokenizer's most important features and share details on its learned vocabulary. In addition, we systematically analyze the properties and evaluate the performance of the tokenizer with regard to the different languages present in the data.
    
[^25]: 基于时间轨迹的度量时间平衡逻辑

    Metric Temporal Equilibrium Logic over Timed Traces. (arXiv:2304.14778v1 [cs.AI])

    [http://arxiv.org/abs/2304.14778](http://arxiv.org/abs/2304.14778)

    提出了基于度量的线性时间平衡逻辑来处理涉及时间约束的动态系统问题，并给出了通过将度量公式转化为单一一阶公式实现模型检查的方法。

    

    在基于线性时间的Answer Set Programming (ASP)的时间扩展中，动态系统的行为通过状态序列来捕获。虽然此表示反映了它们的相对顺序，但它抽象掉了与每个状态关联的具体时间。然而，时间约束在许多应用中是重要的，比如当计划和调度相互配合时。我们通过开发基于度量的线性时间平衡逻辑来解决这个问题，其中时间运算符受自然数区间的约束。由此得到的度量平衡逻辑为指定定性和定量动态约束的基于ASP的方法提供了基础。为此，我们将度量公式转化为单调一阶公式，并分别给出在Metric Equilibrium Logic和Monadic Quantified Equilibrium Logic中的模型之间的对应关系。有趣的是，我们的翻译提供了Metric Equilibrium Logic的实现模型检查的蓝图。

    In temporal extensions of Answer Set Programming (ASP) based on linear-time, the behavior of dynamic systems is captured by sequences of states. While this representation reflects their relative order, it abstracts away the specific times associated with each state. However, timing constraints are important in many applications like, for instance, when planning and scheduling go hand in hand. We address this by developing a metric extension of linear-time temporal equilibrium logic, in which temporal operators are constrained by intervals over natural numbers. The resulting Metric Equilibrium Logic provides the foundation of an ASP-based approach for specifying qualitative and quantitative dynamic constraints. To this end, we define a translation of metric formulas into monadic first-order formulas and give a correspondence between their models in Metric Equilibrium Logic and Monadic Quantified Equilibrium Logic, respectively. Interestingly, our translation provides a blue print for im
    
[^26]: 机器学习和深度学习模型的协同作用在多画家识别中的应用

    Synergy of Machine and Deep Learning Models for Multi-Painter Recognition. (arXiv:2304.14773v1 [cs.CV])

    [http://arxiv.org/abs/2304.14773](http://arxiv.org/abs/2304.14773)

    本文使用机器学习和深度学习模型，结合迁移学习和经典机器学习方法，解决数字化绘画中的画家识别问题，并提出了一个包含约 10,000 张图片和 146 位画家的新型数据集 MultiPaint-10K。

    

    数字化艺术收藏品的增多带来了大量涉及抽象概念的数据管理、分析和分类的需求，这是计算机科学中一个具有挑战性的问题并引发了新的研究视角。人工智能和神经网络的进步提供了应对这一挑战的良好工具。本文使用迁移学习提取适当特征和经典机器学习方法进行评估，在来自 WikiArt 库的一组数字化绘画中处理画家识别的问题。通过测试各种模型和微调它们，我们得出结论：RegNet 在提取特征方面表现更好，而 SVM 基于画家的图片分类最佳，性能高达 85%。此外，我们还引入了一个名为 MultiPaint-10K 的新大型绘画作品数据集，其中包括来自 146 位画家的约 10,000 张图片。

    The growing availability of digitized art collections has created the need to manage, analyze and categorize large amounts of data related to abstract concepts, highlighting a demanding problem of computer science and leading to new research perspectives. Advances in artificial intelligence and neural networks provide the right tools for this challenge. The analysis of artworks to extract features useful in certain works is at the heart of the era. In the present work, we approach the problem of painter recognition in a set of digitized paintings, derived from the WikiArt repository, using transfer learning to extract the appropriate features and classical machine learning methods to evaluate the result. Through the testing of various models and their fine tuning we came to the conclusion that RegNet performs better in exporting features, while SVM makes the best classification of images based on the painter with a performance of up to 85%. Also, we introduced a new large dataset for p
    
[^27]: LostPaw: 使用带视觉输入的对比学习 Transformer 找到失踪的宠物

    LostPaw: Finding Lost Pets using a Contrastive Learning-based Transformer with Visual Input. (arXiv:2304.14765v1 [cs.CV])

    [http://arxiv.org/abs/2304.14765](http://arxiv.org/abs/2304.14765)

    本研究提出了一种名为LostPaw的基于人工智能的应用程序，利用对比神经网络模型准确区分宠物图像，可用于精准搜索失踪的宠物。该模型达到了90%的测试准确率，并为潜在的 Web 应用程序提供了基础，用户能够上传丢失宠物的图像并在数据库中找到匹配图像时接收通知。

    

    失去宠物可能会让宠物主人倍感痛苦，而找到失踪的宠物通常是具有挑战性和耗时的。基于人工智能的应用程序可以显著提高寻找丢失宠物的速度和准确性。为了便于这样的应用程序的实现，本研究介绍了一种对比神经网络模型，能够准确地区分不同宠物的图像。该模型在大量的狗的图像数据集上进行了训练，并通过 3 折交叉验证进行了评估。在 350 个训练周期后，模型取得了90%的测试准确度。此外，由于测试准确性接近训练准确性，避免了过度拟合。我们的研究表明，对比神经网络模型作为定位失踪宠物的工具具有潜力。本文提供了一个潜在的 Web 应用程序的基础，使用户能够上传其丢失宠物的图像，并在应用程序的图像数据库中找到匹配图像时接收通知。

    Losing pets can be highly distressing for pet owners, and finding a lost pet is often challenging and time-consuming. An artificial intelligence-based application can significantly improve the speed and accuracy of finding lost pets. In order to facilitate such an application, this study introduces a contrastive neural network model capable of accurately distinguishing between images of pets. The model was trained on a large dataset of dog images and evaluated through 3-fold cross-validation. Following 350 epochs of training, the model achieved a test accuracy of 90%. Furthermore, overfitting was avoided, as the test accuracy closely matched the training accuracy. Our findings suggest that contrastive neural network models hold promise as a tool for locating lost pets. This paper provides the foundation for a potential web application that allows users to upload images of their missing pets, receiving notifications when matching images are found in the application's image database. Thi
    
[^28]: 具有非二元特征的分类器的新型解释方法

    A New Class of Explanations for Classifiers with Non-Binary Features. (arXiv:2304.14760v1 [cs.AI])

    [http://arxiv.org/abs/2304.14760](http://arxiv.org/abs/2304.14760)

    本文提出了一种适用于具有非二元特征的分类器的新型解释方法，可以提供更多关于决策和基础分类器的信息。

    

    近来，当分析分类器决策时，已经有两种类型的解释受到了文献中的重视。第一种解释是为决策提供充分理由的解释，即缩写为PI解释的诱导式解释；第二种解释是为何不做出其他决策的解释，即对照式或反事实解释的必要理由。这些解释是为二元、离散和在某些情况下为连续特征的分类器定义的。我们展示了当存在非二元特征时，这些解释可以得到显著的改进，从而导致了一类新的解释方法，可以提供更多关于决策和基础分类器的信息。必要和充分原因也被证明是完整原因的主要蕴含项和被蕴含项，可以使用量化算子获得。我们的结果表明，我们改进的必要和充分原因的概念比现有方法更好地适用于具有非二元特征的分类器。

    Two types of explanations have received significant attention in the literature recently when analyzing the decisions made by classifiers. The first type explains why a decision was made and is known as a sufficient reason for the decision, also an abductive or PI-explanation. The second type explains why some other decision was not made and is known as a necessary reason for the decision, also a contrastive or counterfactual explanation. These explanations were defined for classifiers with binary, discrete and, in some cases, continuous features. We show that these explanations can be significantly improved in the presence of non-binary features, leading to a new class of explanations that relay more information about decisions and the underlying classifiers. Necessary and sufficient reasons were also shown to be the prime implicates and implicants of the complete reason for a decision, which can be obtained using a quantification operator. We show that our improved notions of necessa
    
[^29]: 理解算法供应链中的责任问题

    Understanding accountability in algorithmic supply chains. (arXiv:2304.14749v1 [cs.CY])

    [http://arxiv.org/abs/2304.14749](http://arxiv.org/abs/2304.14749)

    本文研究了算法供应链及其对算法系统治理和责任所带来的困难影响，认为算法责任的讨论必须考虑到供应链。

    

    学术和政策上对算法责任的提议常常试图在社会技术背景下理解算法系统，认识到它们由“多方”共同制造。然而，越来越多的算法系统也是由多个参与者组成的供应链生产、部署和使用的，它们之间通过数据流联系在一起。在这种情况下，算法供应链中不同参与者之间的协作是推动系统并产生特定结果的主要因素。我们认为，算法责任的讨论必须考虑到供应链以及它们对算法系统治理和责任所带来的困难影响。因此，本文研究算法供应链，将其定位于广泛的技术和政治经济背景中，并确定了一些关键特征，应在未来的算法治理和责任研究中加以理解。

    Academic and policy proposals on algorithmic accountability often seek to understand algorithmic systems in their socio-technical context, recognising that they are produced by 'many hands'. Increasingly, however, algorithmic systems are also produced, deployed, and used within a supply chain comprising multiple actors tied together by flows of data between them. In such cases, it is the working together of an algorithmic supply chain of different actors who contribute to the production, deployment, use, and functionality that drives systems and produces particular outcomes. We argue that algorithmic accountability discussions must consider supply chains and the difficult implications they raise for the governance and accountability of algorithmic systems. In doing so, we explore algorithmic supply chains, locating them in their broader technical and political economic context and identifying some key features that should be understood in future work on algorithmic governance and accou
    
[^30]: 由什么构成？学习修车领域组件的可信材料

    Made of Steel? Learning Plausible Materials for Components in the Vehicle Repair Domain. (arXiv:2304.14745v1 [cs.CL])

    [http://arxiv.org/abs/2304.14745](http://arxiv.org/abs/2304.14745)

    本文提出了一种新方法，通过探索预训练语言模型（PLM）学习车辆维修领域组件的特定材料，成功克服了数据稀疏性问题和缺乏注释数据集的问题。

    

    我们提出了一种新的方法，通过探索预训练语言模型（PLM）中的cloze任务样式设置来学习车辆维修领域组件的特定材料，以克服缺乏注释数据集的问题。我们设计了一种新方法，聚合了一组cloze查询模板的显著预测，并表明使用小型高质量或定制的维基百科语料库的领域自适应可以提高性能。当探索资源紧缺的替代方案时，我们发现精简的PLM明显优于经典的基于模式的算法。此外，考虑到我们领域特定组件的98％都是多词表达式，我们成功地利用组成性假设来解决数据稀疏性问题。

    We propose a novel approach to learn domain-specific plausible materials for components in the vehicle repair domain by probing Pretrained Language Models (PLMs) in a cloze task style setting to overcome the lack of annotated datasets. We devise a new method to aggregate salient predictions from a set of cloze query templates and show that domain-adaptation using either a small, high-quality or a customized Wikipedia corpus boosts performance. When exploring resource-lean alternatives, we find a distilled PLM clearly outperforming a classic pattern-based algorithm. Further, given that 98% of our domain-specific components are multiword expressions, we successfully exploit the compositionality assumption as a way to address data sparsity.
    
[^31]: LitCQD：带有数值字面量的不完整知识图中的多跳推理

    LitCQD: Multi-Hop Reasoning in Incomplete Knowledge Graphs with Numeric Literals. (arXiv:2304.14742v1 [cs.AI])

    [http://arxiv.org/abs/2304.14742](http://arxiv.org/abs/2304.14742)

    本文提出LitCQD算法，用于在不完整知识图中回答带有数字字面量的复杂多跳查询，并在包含数字字面量的多跳查询数据集上表现更好。

    

    大多数现实世界中的知识图，包括Wikidata，DBpedia和Yago在内，都是不完整的。针对这些不完整的知识图回答查询是一个重要但具有挑战性的问题。最近，提出了一些方法，包括复杂的查询分解（CQD），以回答带有合取和析取的复杂多跳查询。然而，所有最先进的方法都只考虑由实体和关系组成的图，而忽略了字面量值。在本文中，我们提出了LitCQD，一种用于回答包含数字字面量的复杂多跳查询的方法：LitCQD能够回答具有数字答案或满足数字约束的实体答案的查询。例如，它允许查询（1）住在纽约并且年龄在某个范围内的人，以及（2）住在纽约的人的平均年龄。我们在具有和不具有字面量值的查询类型上评估了LitCQD。我们生成了一个包含数字字面量的多跳查询的新数据集，针对Wikidata的一个子集对LitCQD进行评估。实验结果表明，LitCQD在此类查询上显著优于现有最先进的方法。

    Most real-world knowledge graphs, including Wikidata, DBpedia, and Yago are incomplete. Answering queries on such incomplete graphs is an important, but challenging problem. Recently, a number of approaches, including complex query decomposition (CQD), have been proposed to answer complex, multi-hop queries with conjunctions and disjunctions on such graphs. However, all state-of-the-art approaches only consider graphs consisting of entities and relations, neglecting literal values. In this paper, we propose LitCQD -- an approach to answer complex, multi-hop queries where both the query and the knowledge graph can contain numeric literal values: LitCQD can answer queries having numerical answers or having entity answers satisfying numerical constraints. For example, it allows to query (1)~persons living in New York having a certain age, and (2)~the average age of persons living in New York. We evaluate LitCQD on query types with and without literal values. To evaluate LitCQD, we generat
    
[^32]: 基于自动机器学习方法的价格预测应用的基准测试

    Benchmarking Automated Machine Learning Methods for Price Forecasting Applications. (arXiv:2304.14735v1 [cs.LG])

    [http://arxiv.org/abs/2304.14735](http://arxiv.org/abs/2304.14735)

    本研究展示了将自动化机器学习解决方案与企业领域知识相结合，以替代手动创建的ML管道，为中小型企业实现自动化价格预测提供可能。

    

    由于空间和时间的价格波动，在二手建筑设备的价格预测方面是一项具有挑战性的任务。因此，基于当前市场数据自动化预测过程具有极高的兴趣。即使将机器学习（ML）应用于这些数据是预测某些工具残值的一个有前途的方法，但由于中小型企业的ML专业知识不足，因此很难实现。为此，我们展示了用自动化机器学习（AutoML）解决方案代替手动创建的ML管道的可能性，这些解决方案可以自动生成底层管道。我们将AutoML方法与公司的领域知识相结合。基于CRISP-DM过程，我们将手动ML管道分为机器学习部分和非机器学习部分。为了考虑所有复杂的工业要求并展示我们新方法的适用性，我们设计了一种新的名为“方法评估”的度量标准。

    Price forecasting for used construction equipment is a challenging task due to spatial and temporal price fluctuations. It is thus of high interest to automate the forecasting process based on current market data. Even though applying machine learning (ML) to these data represents a promising approach to predict the residual value of certain tools, it is hard to implement for small and medium-sized enterprises due to their insufficient ML expertise. To this end, we demonstrate the possibility of substituting manually created ML pipelines with automated machine learning (AutoML) solutions, which automatically generate the underlying pipelines. We combine AutoML methods with the domain knowledge of the companies. Based on the CRISP-DM process, we split the manual ML pipeline into a machine learning and non-machine learning part. To take all complex industrial requirements into account and to demonstrate the applicability of our new approach, we designed a novel metric named method evalua
    
[^33]: 真实世界三维装箱问题的基准数据集和实例生成器

    Benchmark dataset and instance generator for Real-World Three-Dimensional Bin Packing Problems. (arXiv:2304.14712v1 [cs.AI])

    [http://arxiv.org/abs/2304.14712](http://arxiv.org/abs/2304.14712)

    本文提出了一个真实世界装箱问题的基准数据集和实例生成器，可以用来比较不同装箱算法的性能。

    

    本文提出了一个真实世界装箱问题的基准数据集。该数据集由12个实例组成，涵盖了不同大小和用户需求的问题复杂度水平（包含从38到53个包裹的数量）。实际上，我们考虑了几个面向真实世界的限制条件来构建这些实例：i)物品和箱子尺寸，ii)重量限制，iii)包类别之间的亲和性，iv)包装顺序的偏好和v)负载平衡。除了数据外，我们还提供了一个自主开发的Python脚本用于数据集生成，称为Q4RealBPP-DataGen。该基准首先被设计用于评估量子求解器，因此这组实例的特征是按照量子设备的当前限制设计的。此外，数据集生成器包含在内，允许构建通用基准。本文介绍的数据提供了一个基准，可以用来比较不同方法的性能和对比算法的效果。

    In this paper, a benchmark for real-world bin packing problems is proposed. This dataset is composed of 12 instances comprehending different levels of problem complexity regarding size (with the number of packages ranging from 38 to 53) and user-defined requirements. In fact, several real-world oriented restrictions have been considered for building these instances: i) items and bins dimensions, ii) weight restrictions, iii) affinities among packages categories iv) preferences for package ordering and v) load balancing. Besides the data, we also provide an own-developed Python script for the dataset generation, coined as Q4RealBPP-DataGen. The benchmark was firstly proposed to evaluate quantum solvers, therefore the characteristic of this set of instances were designed according to the current limitations of quantum devices. Additionally, the dataset generator is included to allow the construction of general-purpose benchmarks. The data introduced on this paper provides a baseline that
    
[^34]: 基于图像的印度手语识别：使用深度神经网络的实用综述

    Image-based Indian Sign Language Recognition: A Practical Review using Deep Neural Networks. (arXiv:2304.14710v1 [cs.CV])

    [http://arxiv.org/abs/2304.14710](http://arxiv.org/abs/2304.14710)

    本论文研究开发了一种基于印度手语的手语识别系统，旨在实时将手语翻译成文本以解决聋哑人和听障人士交流障碍。

    

    聋哑人和听障人士使用手语来表达自己的意思。虽然手语是解决听障人士交流困难的一种方式，但大多数人仍然无法理解这种语言，造成交流障碍。手语识别系统是解决这个问题的必要手段。本研究的主要目的是开发一种能够实时翻译手语为文本的单词级手语识别系统。针对印度聋哑人和听障人士的需求，我们开展了以印度手语为基础的手语识别系统研究。

    People with vocal and hearing disabilities use sign language to express themselves using visual gestures and signs. Although sign language is a solution for communication difficulties faced by deaf people, there are still problems as most of the general population cannot understand this language, creating a communication barrier, especially in places such as banks, airports, supermarkets, etc. [1]. A sign language recognition(SLR) system is a must to solve this problem. The main focus of this model is to develop a real-time word-level sign language recognition system that would translate sign language to text. Much research has been done on ASL(American sign language). Thus, we have worked on ISL(Indian sign language) to cater to the needs of the deaf and hard-of-hearing community of India[2]. In this research, we provide an Indian Sign Language-based Sign Language recognition system. For this analysis, the user must be able to take pictures of hand movements using a web camera, and th
    
[^35]: X-RLflow：面向神经网络子图转换的图形增强学习

    X-RLflow: Graph Reinforcement Learning for Neural Network Subgraphs Transformation. (arXiv:2304.14698v1 [cs.LG])

    [http://arxiv.org/abs/2304.14698](http://arxiv.org/abs/2304.14698)

    本论文提出了一种基于强化学习的方法，X-RLflow，用于替换神经网络的子图，以求得更优的计算图结构，可在各种深度学习模型和基准测试中超越现有技术的超优化系统。

    

    张量图超优化系统通过神经网络的一系列子图替换来找到最优的计算图结构。这个图转换过程自然而然地落入了序列决策框架中, 现有系统通常采用贪心搜索方法，无法探索整个搜索空间，因为它不能容忍临时的性能损失。本文提出了一种基于强化学习 (RL) 的替代搜索方法来解决张量图超优化问题。我们提出的方法，X-RLflow，可以学习执行神经网络数据流图重写，一次替换一个子图。X-RLflow 基于一种无模型 RL 代理，使用图神经网络 (GNN) 对目标计算图进行编码，并迭代输出转换后的计算图。我们证明，我们的方法可以在各种深度学习模型和基准测试中超越现有技术的超优化系统。

    Tensor graph superoptimisation systems perform a sequence of subgraph substitution to neural networks, to find the optimal computation graph structure. Such a graph transformation process naturally falls into the framework of sequential decision-making, and existing systems typically employ a greedy search approach, which cannot explore the whole search space as it cannot tolerate a temporary loss of performance. In this paper, we address the tensor graph superoptimisation problem by exploring an alternative search approach, reinforcement learning (RL). Our proposed approach, X-RLflow, can learn to perform neural network dataflow graph rewriting, which substitutes a subgraph one at a time. X-RLflow is based on a model-free RL agent that uses a graph neural network (GNN) to encode the target computation graph and outputs a transformed computation graph iteratively. We show that our approach can outperform state-of-the-art superoptimisation systems over a range of deep learning models an
    
[^36]: NeuralKG-ind: 一种Python库，用于归纳式知识图谱表示学习

    NeuralKG-ind: A Python Library for Inductive Knowledge Graph Representation Learning. (arXiv:2304.14678v1 [cs.AI])

    [http://arxiv.org/abs/2304.14678](http://arxiv.org/abs/2304.14678)

    NeuralKG-ind是一种Python库，用于归纳式知识图谱表示学习。它包括标准化的流程、丰富的现有方法、解耦的模块和全面的评估指标。这个库可以帮助研究人员和工程师轻松比较不同的归纳式KGRL方法。

    

    由于知识图谱的动态特性，近年来提出了许多归纳式知识图谱表示学习（KGRL）方法，专注于实现对新实体的预测。NeuralKG-ind是作为NeuralKG库的重要更新的归纳式KGRL的第一个库。它包括标准化的流程、丰富的现有方法、解耦的模块和全面的评估指标。使用NeuralKG-ind，研究人员和工程师可以轻松地复现、重新开发和比较归纳式KGRL方法。NeuralKG-ind的库、实验方法和模型重新实现的结果都在 https://github.com/zjukg/NeuralKG/tree/ind 上公开发布。

    Since the dynamic characteristics of knowledge graphs, many inductive knowledge graph representation learning (KGRL) works have been proposed in recent years, focusing on enabling prediction over new entities. NeuralKG-ind is the first library of inductive KGRL as an important update of NeuralKG library. It includes standardized processes, rich existing methods, decoupled modules, and comprehensive evaluation metrics. With NeuralKG-ind, it is easy for researchers and engineers to reproduce, redevelop, and compare inductive KGRL methods. The library, experimental methodologies, and model re-implementing results of NeuralKG-ind are all publicly released at https://github.com/zjukg/NeuralKG/tree/ind .
    
[^37]: 医疗保健的提示工程:  方法和应用. (arXiv:2304.14670v1 [cs.AI])

    Prompt Engineering for Healthcare: Methodologies and Applications. (arXiv:2304.14670v1 [cs.AI])

    [http://arxiv.org/abs/2304.14670](http://arxiv.org/abs/2304.14670)

    本文介绍了医疗保健NLP领域中的提示工程最新进展，强调其在问答系统、文本摘要和机器翻译等应用中的贡献。本文提供了有用资源和桥梁，以更好地探索提示工程在医疗保健领域的应用。

    

    本文将介绍自然语言处理（NLP）领域内医疗保健提示工程最新的进展。首先，我们将提供一个简要的提示工程发展概述，并强调其对医疗保健NLP应用如问答系统、文本摘要和机器翻译的重要贡献。随着通用大型语言模型的不断改进，提示工程在医疗保健领域的重要性越来越突出。本文的目的是为医疗保健NLP研究人员提供有用的资源和桥梁，更好地探索提示工程在这一领域的应用。我们希望本文可以提供新的思路，激发医疗NLP的研究和应用的充分可能性。

    This review will introduce the latest advances in prompt engineering in the field of natural language processing (NLP) for the medical domain. First, we will provide a brief overview of the development of prompt engineering and emphasize its significant contributions to healthcare NLP applications such as question-answering systems, text summarization, and machine translation. With the continuous improvement of general large language models, the importance of prompt engineering in the healthcare domain is becoming increasingly prominent. The aim of this article is to provide useful resources and bridges for healthcare NLP researchers to better explore the application of prompt engineering in this field. We hope that this review can provide new ideas and inspire ample possibilities for research and application in medical NLP.
    
[^38]: 基于ICU住院时间预测的联邦学习客户端招募研究

    Client Recruitment for Federated Learning in ICU Length of Stay Prediction. (arXiv:2304.14663v1 [cs.LG])

    [http://arxiv.org/abs/2304.14663](http://arxiv.org/abs/2304.14663)

    本研究提出了一种新的基于ICU住院时间预测的联邦学习客户端招募策略，通过准则、相似性和聚类，可以降低通信开销和训练成本，同时保持预测性能。

    

    近年来，医疗和保健领域的机器学习和深度学习方法取得了显著的进展和改进。这些方法需要大量的训练数据，医疗领域中有大量的这样的数据，但是这些数据是分散的。联邦学习技术非常适合应对这些挑战。本文针对联邦学习中的客户端选择问题，提出了一种新的基于ICU住院时间预测的联邦学习客户端招募策略。我们的策略包括几个阶段：（i）基于准则的客户端预选；（ii）基于相似性的客户端选择；和（iii）客户端聚类。实验结果表明，我们的策略可以降低通信开销和训练成本，同时保持预测性能。

    Machine and deep learning methods for medical and healthcare applications have shown significant progress and performance improvement in recent years. These methods require vast amounts of training data which are available in the medical sector, albeit decentralized. Medical institutions generate vast amounts of data for which sharing and centralizing remains a challenge as the result of data and privacy regulations. The federated learning technique is well-suited to tackle these challenges. However, federated learning comes with a new set of open problems related to communication overhead, efficient parameter aggregation, client selection strategies and more. In this work, we address the step prior to the initiation of a federated network for model training, client recruitment. By intelligently recruiting clients, communication overhead and overall cost of training can be reduced without sacrificing predictive performance. Client recruitment aims at pre-excluding potential clients fro
    
[^39]: MultiZenoTravel：已知帕累托前沿的多目标规划可调基准测试

    MultiZenoTravel: a Tunable Benchmark for Multi-Objective Planning with Known Pareto Front. (arXiv:2304.14659v1 [cs.AI])

    [http://arxiv.org/abs/2304.14659](http://arxiv.org/abs/2304.14659)

    本文提出了一个可调基准测试生成器和专用求解器用于已知帕累托前沿的多目标规划问题，并且通过实例的求解展示了该求解器的可行性和效率。

    

    多目标人工智能规划缺乏展示已知帕累托前沿基准测试。本文提出了一个可调基准测试生成器和一个专用求解器，可证明计算出所得实例的真实帕累托前沿。首先，我们证明了一个命题，描述了该问题的受限版本的最佳计划特征，然后展示了如何将一般问题简化为受限问题。其次，我们提供了一种构造性方法来找到所有帕累托最优计划并讨论了算法的复杂性。我们提供了一个实现，使求解器可以在合理的时间内处理现实情况的实例。最后，作为实际演示，我们使用此求解器在考虑50个最大机场之间路线、机场间的球面距离和一个虚构的风险的情况下，找到了世界上最大的两个机场之间所有帕累托最优计划。

    Multi-objective AI planning suffers from a lack of benchmarks exhibiting known Pareto Fronts. In this work, we propose a tunable benchmark generator, together with a dedicated solver that provably computes the true Pareto front of the resulting instances. First, we prove a proposition allowing us to characterize the optimal plans for a constrained version of the problem, and then show how to reduce the general problem to the constrained one. Second, we provide a constructive way to find all the Pareto-optimal plans and discuss the complexity of the algorithm. We provide an implementation that allows the solver to handle realistic instances in a reasonable time. Finally, as a practical demonstration, we used this solver to find all Pareto-optimal plans between the two largest airports in the world, considering the routes between the 50 largest airports, spherical distances between airports and a made-up risk.
    
[^40]: 从显性沟通到隐性合作：一种新的协作多智能体学习范式

    From Explicit Communication to Tacit Cooperation:A Novel Paradigm for Cooperative MARL. (arXiv:2304.14656v1 [cs.MA])

    [http://arxiv.org/abs/2304.14656](http://arxiv.org/abs/2304.14656)

    该论文提出了一种从显性沟通到隐性合作的新协作多智能体学习范式，通过在代理之间分享信息和使用本地轨迹重建信息来促进协作，并逐渐减少显式传达信息的比例。实验结果表明，这种范式在具有挑战性的情景下比传统的 CTDE 范式表现更好。

    

    集中培训与分散执行（CTDE）是一种广泛使用的学习范式，在复杂任务方面取得了显着成功。然而，局部可观察性问题和代理之间缺乏有效共享信号的存在经常限制了它在促进协作方面的有效性。虽然通信可以解决这一挑战，但同时也降低了算法的实用性。受人类团队合作学习的启发，我们提出了一种新的范式，以促进从显性通信到隐性合作的逐渐转变。在初始训练阶段，我们通过在代理之间分享相关信息和同时使用每个代理的本地轨迹重建该信息来促进协作。然后，我们将显式传达的信息与重建的信息相结合，得到混合信息。在整个训练过程中，我们通过学习到的隐含合作逐渐减少显式传达信息的比例。

    Centralized training with decentralized execution (CTDE) is a widely-used learning paradigm that has achieved significant success in complex tasks. However, partial observability issues and the absence of effectively shared signals between agents often limit its effectiveness in fostering cooperation. While communication can address this challenge, it simultaneously reduces the algorithm's practicality. Drawing inspiration from human team cooperative learning, we propose a novel paradigm that facilitates a gradual shift from explicit communication to tacit cooperation. In the initial training stage, we promote cooperation by sharing relevant information among agents and concurrently reconstructing this information using each agent's local trajectory. We then combine the explicitly communicated information with the reconstructed information to obtain mixed information. Throughout the training process, we progressively reduce the proportion of explicitly communicated information, facilit
    
[^41]: 超越同构假设的不平衡节点分类

    Imbalanced Node Classification Beyond Homophilic Assumption. (arXiv:2304.14635v1 [cs.AI])

    [http://arxiv.org/abs/2304.14635](http://arxiv.org/abs/2304.14635)

    提出了一种新的GraphSANN模型，用于处理同构和异构图的不平衡节点分类。

    

    不平衡节点分类广泛存在于现实世界网络中，图神经网络通常倾向于多数类并且在分类少数类节点时性能严重下降。最近提出了各种不平衡节点分类方法，这些方法构建合成节点和边以平衡标签和拓扑分布。然而，它们都基于同构假设，即相同标签的节点倾向于连接，尽管在现实世界图中广泛存在异构边。因此，它们统一聚合来自同构和异构邻居的特征，并依赖于特征相似性生成合成边，无法应用于高异质性的不平衡图。为了解决这个问题，我们提出了一种新的GraphSANN模型，用于处理同构和异构图的不平衡节点分类。

    Imbalanced node classification widely exists in real-world networks where graph neural networks (GNNs) are usually highly inclined to majority classes and suffer from severe performance degradation on classifying minority class nodes. Various imbalanced node classification methods have been proposed recently which construct synthetic nodes and edges w.r.t. minority classes to balance the label and topology distribution. However, they are all based on the homophilic assumption that nodes of the same label tend to connect despite the wide existence of heterophilic edges in real-world graphs. Thus, they uniformly aggregate features from both homophilic and heterophilic neighbors and rely on feature similarity to generate synthetic edges, which cannot be applied to imbalanced graphs in high heterophily. To address this problem, we propose a novel GraphSANN for imbalanced node classification on both homophilic and heterophilic graphs. Firstly, we propose a unified feature mixer to generate 
    
[^42]: CVRecon: 重新思考神经重建的3D几何特征学习

    CVRecon: Rethinking 3D Geometric Feature Learning For Neural Reconstruction. (arXiv:2304.14633v1 [cs.CV])

    [http://arxiv.org/abs/2304.14633](http://arxiv.org/abs/2304.14633)

    研究团队提出了一种基于代价体的3D神经重建框架CVRecon，利用丰富的几何嵌入来促进3D几何特征学习。通过引入射线上下文补偿代价体（RCCV），有效提高了视角相关信息的完整性和鲁棒性，并在各种度量方面显着提高了重建质量。

    

    最近使用图像序列进行神经重建的进展取得了显着进展。但是，由于缺乏深度信息，现有的基于体积的技术仅沿整个相机光线复制对象表面的2D图像特征。我们认为这种复制会在空洞和遮挡空间中引入噪声，从而产生高质量的3D几何体成形方面产生挑战。受传统多视角立体方法的启发，我们提出了一种端到端的3D神经重建框架CVRecon，旨在利用代价体中丰富的几何嵌入来促进3D几何特征学习。此外，我们提出了一种新颖的3D几何特征表示法——射线上下文补偿代价体（RCCV），它具有更好的完整性和鲁棒性，可以编码视角相关信息。通过全面的实验，我们证明了我们的方法在各种度量方面显着提高了重建质量，并恢复了清晰的

    Recent advances in neural reconstruction using posed image sequences have made remarkable progress. However, due to the lack of depth information, existing volumetric-based techniques simply duplicate 2D image features of the object surface along the entire camera ray. We contend this duplication introduces noise in empty and occluded spaces, posing challenges for producing high-quality 3D geometry. Drawing inspiration from traditional multi-view stereo methods, we propose an end-to-end 3D neural reconstruction framework CVRecon, designed to exploit the rich geometric embedding in the cost volumes to facilitate 3D geometric feature learning. Furthermore, we present Ray-contextual Compensated Cost Volume (RCCV), a novel 3D geometric feature representation that encodes view-dependent information with improved integrity and robustness. Through comprehensive experiments, we demonstrate that our approach significantly improves the reconstruction quality in various metrics and recovers clear
    
[^43]: 让图表闪亮起来：利用文本到图像生成模型将语义上下文嵌入到图表中

    Let the Chart Spark: Embedding Semantic Context into Chart with Text-to-Image Generative Model. (arXiv:2304.14630v1 [cs.AI])

    [http://arxiv.org/abs/2304.14630](http://arxiv.org/abs/2304.14630)

    本文提出了一个新的系统ChartSpark，利用文本到图像生成模型将语义上下文嵌入到图表中，以生成具有高质量语义上下文的图示可视化。

    

    图示可视化将数据和语义上下文良好地整合到视觉表现中，以一种既引人又信息量大的方式传达复杂信息。本文提出了一个新系统ChartSpark，它基于文本到图像生成模型将语义上下文嵌入在图表中生成图示化的可视化。该方法适用于前景和背景的图示生成，旨在创造具有语义上下文的高质量图示可视化。

    Pictorial visualization seamlessly integrates data and semantic context into visual representation, conveying complex information in a manner that is both engaging and informative. Extensive studies have been devoted to developing authoring tools to simplify the creation of pictorial visualizations. However, mainstream works mostly follow a retrieving-and-editing pipeline that heavily relies on retrieved visual elements from a dedicated corpus, which often compromise the data integrity. Text-guided generation methods are emerging, but may have limited applicability due to its predefined recognized entities. In this work, we propose ChartSpark, a novel system that embeds semantic context into chart based on text-to-image generative model. ChartSpark generates pictorial visualizations conditioned on both semantic context conveyed in textual inputs and data information embedded in plain charts. The method is generic for both foreground and background pictorial generation, satisfying the d
    
[^44]: 深度知识产权: 综述

    Deep Intellectual Property: A Survey. (arXiv:2304.14613v1 [cs.AI])

    [http://arxiv.org/abs/2304.14613](http://arxiv.org/abs/2304.14613)

    这篇综述介绍了利用深度神经网络时所面临的知识产权保护问题，以及近年来防止和发现模型窃取和未经授权重新分发的方法。

    

    随着深度神经网络在工业制造和商业服务中的广泛应用，经过充分训练的深度神经网络(DNNs)由于庞大的训练成本和优秀的泛化性能变得越来越有价值和至关重要。这些训练好的模型可以被用户利用，而无需了解太多专业知识，这得益于新兴的“机器学习即服务”(MLaaS)范式。然而，这种范式也使得昂贵的模型面临许多潜在威胁，例如模型窃取和滥用。为了抵御这些威胁的迫切需求，深度知识产权（Deep Intellectual Property，DeepIP）成为了业界和学术界的共识，以保护私有训练数据、费尽心思调整的超参数或昂贵学习的模型权重。为此，近年来提出了许多方法来实现这一目标，特别是防止或发现模型窃取和未经授权的重新分发。鉴于这一快速演变的时期，

    With the widespread application in industrial manufacturing and commercial services, well-trained deep neural networks (DNNs) are becoming increasingly valuable and crucial assets due to the tremendous training cost and excellent generalization performance. These trained models can be utilized by users without much expert knowledge benefiting from the emerging ''Machine Learning as a Service'' (MLaaS) paradigm. However, this paradigm also exposes the expensive models to various potential threats like model stealing and abuse. As an urgent requirement to defend against these threats, Deep Intellectual Property (DeepIP), to protect private training data, painstakingly-tuned hyperparameters, or costly learned model weights, has been the consensus of both industry and academia. To this end, numerous approaches have been proposed to achieve this goal in recent years, especially to prevent or discover model stealing and unauthorized redistribution. Given this period of rapid evolution, the g
    
[^45]: 用时序对抗增强技术改进视频表示

    Improve Video Representation with Temporal Adversarial Augmentation. (arXiv:2304.14601v1 [cs.CV])

    [http://arxiv.org/abs/2304.14601](http://arxiv.org/abs/2304.14601)

    本文提出了Temporal Adversarial Augmentation（TA），一种利用时间注意力的视频增强技术，可以通过最大化时间相关的损失函数来改变神经网络对视频片段的注意分布。利用TA，我们提出了Temporal Video Adversarial Fine-tuning（TAF）框架，可以有效地改善视频表示并提高神经网络的泛化能力。

    

    最近的研究表明，如果以适当的方式使用，对抗增强有助于神经网络的泛化。本文提出了一种使用时间注意力的新型视频增强技术——Temporal Adversarial Augmentation (TA)。与传统的对抗增强不同，TA专为通过最大化时间相关的损失函数来改变神经网络对视频片段的注意分布而设计。我们证明，TA将获得多样化的时间视角，这显著影响神经网络的焦点。使用这些示例进行训练修复了不平衡的时间信息感知缺陷，并增强了抵御时间偏移的能力，最终导致更好的泛化性能。为了利用TA，我们提出了Temporal Video Adversarial Fine-tuning (TAF)框架来改进视频表示。TAF是一种通用的模型无关、可解释性友好的训练策略。

    Recent works reveal that adversarial augmentation benefits the generalization of neural networks (NNs) if used in an appropriate manner. In this paper, we introduce Temporal Adversarial Augmentation (TA), a novel video augmentation technique that utilizes temporal attention. Unlike conventional adversarial augmentation, TA is specifically designed to shift the attention distributions of neural networks with respect to video clips by maximizing a temporal-related loss function. We demonstrate that TA will obtain diverse temporal views, which significantly affect the focus of neural networks. Training with these examples remedies the flaw of unbalanced temporal information perception and enhances the ability to defend against temporal shifts, ultimately leading to better generalization. To leverage TA, we propose Temporal Video Adversarial Fine-tuning (TAF) framework for improving video representations. TAF is a model-agnostic, generic, and interpretability-friendly training strategy. We
    
[^46]: 机器人辅助手术交叉领域技能评估的不确定性自监督学习

    Uncertainty-aware Self-supervised Learning for Cross-domain Technical Skill Assessment in Robot-assisted Surgery. (arXiv:2304.14589v1 [cs.RO])

    [http://arxiv.org/abs/2304.14589](http://arxiv.org/abs/2304.14589)

    本文提出了一种采用不确定性自监督学习方法的机器人手术技能评估技术，通过将标记数据领域知识转移到未标记数据中进行训练，最终在虚拟现实模拟的训练任务中取得了显著的成果。

    

    目标技能评估对新医生进行机器人辅助手术的有效培训至关重要。随着物理和虚拟环境下的手术培训计划的进展，开发自动评估技能的通用方法至关重要。本文提出了一种新颖的方法，通过将标记运动数据的领域知识转移至未标记数据中进行技能评估。我们的方法利用来自常见手术训练任务（如缝合、穿针和打结）的标记数据来联合训练具有标记和未标记数据的模型。通过迭代方式生成未标记数据的伪标签，其中包含不确定度估计以确保准确标记。我们使用来自da Vinci Research Kit（dVRK）的数据在虚拟现实模拟的训练任务（Ring Transfer）上评估我们的方法。结果表明，在机器人辅助下进行培训的实习生具有显著更高的专家概率。

    Objective technical skill assessment is crucial for effective training of new surgeons in robot-assisted surgery. With advancements in surgical training programs in both physical and virtual environments, it is imperative to develop generalizable methods for automatically assessing skills. In this paper, we propose a novel approach for skill assessment by transferring domain knowledge from labeled kinematic data to unlabeled data. Our approach leverages labeled data from common surgical training tasks such as Suturing, Needle Passing, and Knot Tying to jointly train a model with both labeled and unlabeled data. Pseudo labels are generated for the unlabeled data through an iterative manner that incorporates uncertainty estimation to ensure accurate labeling. We evaluate our method on a virtual reality simulated training task (Ring Transfer) using data from the da Vinci Research Kit (dVRK). The results show that trainees with robotic assistance have significantly higher expert probabilit
    
[^47]: Epilexie：一种透过顺应性神经刺激数字治疗方法治疗难治性癫痫的方法

    \'Epilexie: A digital therapeutic approach for treating intractable epilepsy via Amenable Neurostimulation. (arXiv:2304.14583v1 [cs.AI])

    [http://arxiv.org/abs/2304.14583](http://arxiv.org/abs/2304.14583)

    本研究探讨了将ANS作为一种数字治疗策略，治疗难治性癫痫的潜力，ANS使用闭环系统，可以降低癫痫的发作频率。

    

    癫痫是一种神经疾病，表现为持续的抽搐，有时也称为惊厥。尽管有药物和手术等有效治疗方法，但仍有一些患者存在难治性癫痫，无法对标准方法做出反应。难治性癫痫是一种严重的神经疾病，影响着全球数百万人。近年来，大脑可编程电刺激技术的应用已显示出降低难治性癫痫的发作频率的数字治疗策略的潜力。本研究调查了将顺应性神经刺激（ANS）作为数字治疗策略的一部分用于难治性癫痫的情况。

    Epilepsy is a neurological illness that is characterised by continuous spasms of shaking, sometimes known as convulsions. Although there are effective treatments for epilepsy, such as drugs and surgery, there is still a group of individuals who have intractable epilepsy that fails to respond to standard methods. Intractable epilepsy is a severe neurological illness that ripples across the globe and impacts millions of individuals. It is extremely difficult to control intractable epilepsy, which is defined as the lack of response to two or more standard antiepileptic medication treatments. In recent years, the use of programmable electrical stimulation of the brain has shown promise as a digital treatment strategy for lowering seizure frequency in individuals with intractable epilepsy. In this research, the use of Amenable Neurostimulation (ANS) as part of a digital treatment strategy to intractable epilepsy is investigated. When applied to the brain, ANS uses a closed-loop system to se
    
[^48]: 新手用户是否能创建deepfakes？

    Can deepfakes be created by novice users?. (arXiv:2304.14576v1 [cs.CR])

    [http://arxiv.org/abs/2304.14576](http://arxiv.org/abs/2304.14576)

    本文通过用户研究发现，虽然新手用户创建Deepfakes可能不容易，但也不是完全困难，并且需要引起研究界和政策制定者的关注。

    

    机器学习和计算机视觉的最新进展已经导致了Deepfakes的泛滥。随着技术的民主化，越来越担心新手用户可以创建Deepfakes，以打击他人并破坏公共话语。本文通过用户研究来了解具有先进计算机技能和不同计算机科学专业水平的参与者是否可以使用有限的媒体文件创建Deepfakes。我们进行了两项研究，在第一项研究中（n = 39），参与者尝试在约束时间内使用任何工具创建目标Deepfake。在第二项研究中（n = 29），参与者使用预先指定的基于深度学习的工具来创建相同的Deepfake。我们发现，在第一项研究中，23.1%的参与者成功地创建了具有音频和视频的完整Deepfakes，而在第二项用户研究中，58.6%的参与者成功地将目标演讲缝合到源视频中。我们的发现表明，虽然对于新手用户而言创建Deepfakes可能并不容易，但也不是完全困难，因此需要研究界和政策制定者的关注。

    Recent advancements in machine learning and computer vision have led to the proliferation of Deepfakes. As technology democratizes over time, there is an increasing fear that novice users can create Deepfakes, to discredit others and undermine public discourse. In this paper, we conduct user studies to understand whether participants with advanced computer skills and varying levels of computer science expertise can create Deepfakes of a person saying a target statement using limited media files. We conduct two studies; in the first study (n = 39) participants try creating a target Deepfake in a constrained time frame using any tool they desire. In the second study (n = 29) participants use pre-specified deep learning-based tools to create the same Deepfake. We find that for the first study, 23.1% of the participants successfully created complete Deepfakes with audio and video, whereas, for the second user study, 58.6% of the participants were successful in stitching target speech to th
    
[^49]: SceneGenie: 场景图引导扩散模型用于图像合成。

    SceneGenie: Scene Graph Guided Diffusion Models for Image Synthesis. (arXiv:2304.14573v1 [cs.CV])

    [http://arxiv.org/abs/2304.14573](http://arxiv.org/abs/2304.14573)

    本文提出了SceneGenie模型，利用边界框和分割地图信息引导扩散模型生成高分辨率图像，处理复杂的文本提示。该方法使用了CLIP嵌入的语义特征，从而实现了前所未有的保真度。

    

    近年来，基于文本生成图像的技术在生成对抗网络和最新的扩散模型的支持下取得了显着进展。然而，以文本提示为条件的扩散模型在产生印象深刻的高质量图像方面表现出色，但在准确表示特定对象的实例数量等复杂文本提示方面仍然具有挑战性。为了解决这个问题，我们提出了一种新的扩散模型采样过程指导方法，在推理时利用边界框和分割地图信息，无需额外的训练数据。通过采样过程中的新损失，我们的方法使用来自CLIP嵌入的语义特征引导模型，并强制执行几何约束，从而生成准确表示场景的高分辨率图像。为了获得边界框和分割地图信息，我们将文本提示结构化为一个场景图，并使用CLIP嵌入丰富节点信息。我们的模型在从复杂文本提示生成图像方面实现了前所未有的保真度。

    Text-conditioned image generation has made significant progress in recent years with generative adversarial networks and more recently, diffusion models. While diffusion models conditioned on text prompts have produced impressive and high-quality images, accurately representing complex text prompts such as the number of instances of a specific object remains challenging.  To address this limitation, we propose a novel guidance approach for the sampling process in the diffusion model that leverages bounding box and segmentation map information at inference time without additional training data. Through a novel loss in the sampling process, our approach guides the model with semantic features from CLIP embeddings and enforces geometric constraints, leading to high-resolution images that accurately represent the scene. To obtain bounding box and segmentation map information, we structure the text prompt as a scene graph and enrich the nodes with CLIP embeddings. Our proposed model achieve
    
[^50]: SCOPE：医学图像分割的结构连续性保持

    SCOPE: Structural Continuity Preservation for Medical Image Segmentation. (arXiv:2304.14572v1 [cs.CV])

    [http://arxiv.org/abs/2304.14572](http://arxiv.org/abs/2304.14572)

    该论文提出了一种基于图形的方法，可以在医学图像分割中强制执行解剖学形状的连续性和连通性，以改进医学诊断的准确性。

    

    虽然在医学图像分割中保持形状连续性和生理解剖学的假设是自然的，但深度学习方法通常忽视这一点，它们主要旨在统计建模输入数据作为像素，而不是相互连接的结构。然而，在生物结构中，器官并不是独立的实体；例如，在现实中，断开的血管是潜在问题的指标，但传统分割模型并没有被设计为严格执行解剖连续性，可能导致不准确的医学诊断。为了解决这个问题，我们提出了一种基于图形的方法，在医学图像中强制执行解剖拓扑的连续性和连通性。我们的方法将形状的连续性编码为图形约束，确保网络的预测保持这种连续性。我们在两个公共基准测试中对视网膜血管分割进行了评估，显示出在连接性和连续性保持方面的显着改进。

    Although the preservation of shape continuity and physiological anatomy is a natural assumption in the segmentation of medical images, it is often neglected by deep learning methods that mostly aim for the statistical modeling of input data as pixels rather than interconnected structures. In biological structures, however, organs are not separate entities; for example, in reality, a severed vessel is an indication of an underlying problem, but traditional segmentation models are not designed to strictly enforce the continuity of anatomy, potentially leading to inaccurate medical diagnoses. To address this issue, we propose a graph-based approach that enforces the continuity and connectivity of anatomical topology in medical images. Our method encodes the continuity of shapes as a graph constraint, ensuring that the network's predictions maintain this continuity. We evaluate our method on two public benchmarks on retinal vessel segmentation, showing significant improvements in connectiv
    
[^51]: DIAMANT: 基于双图像注意力映射编码器的医学图像分割

    DIAMANT: Dual Image-Attention Map Encoders For Medical Image Segmentation. (arXiv:2304.14571v1 [cs.CV])

    [http://arxiv.org/abs/2304.14571](http://arxiv.org/abs/2304.14571)

    该论文提出了一种基于双图像注意力映射编码器的医学图像分割架构，仅利用从自监督预训练视觉Transformer网络获得的注意力映射可视化，就可以以更少的计算成本胜过复杂的Transformer架构，这在多个医疗图像数据集上得到验证。

    

    虽然纯Transformer架构在许多计算机视觉任务中表现出了很好的性能，但许多由CNN和Transformer块组成的混合模型被引入以适应更专业的任务。然而，尽管相对于CNNs，在医学图像分割中，纯Transformer和混合Transformer架构的性能都有所提升，但它们的高训练成本和复杂性使得在真实场景中使用它们变得具有挑战性。在这项工作中，我们提出了基于纯卷积层的简单架构，并表明仅利用从自监督预训练视觉Transformer网络（例如DINO）获得的注意力映射可视化就可以以更少的计算成本胜过复杂的Transformer架构。所提出的架构由两个编码器分支组成，其中原始图像作为一个分支的输入，而来自预训练视觉Transformer网络中多个自注意力头的注意力映射可视化作为另一个分支的输入。

    Although purely transformer-based architectures showed promising performance in many computer vision tasks, many hybrid models consisting of CNN and transformer blocks are introduced to fit more specialized tasks. Nevertheless, despite the performance gain of both pure and hybrid transformer-based architectures compared to CNNs in medical imaging segmentation, their high training cost and complexity make it challenging to use them in real scenarios. In this work, we propose simple architectures based on purely convolutional layers, and show that by just taking advantage of the attention map visualizations obtained from a self-supervised pretrained vision transformer network (e.g., DINO) one can outperform complex transformer-based networks with much less computation costs. The proposed architecture is composed of two encoder branches with the original image as input in one branch and the attention map visualizations of the same image from multiple self-attention heads from a pre-traine
    
[^52]: 适当性是你所需要的一切！

    Appropriateness is all you need!. (arXiv:2304.14553v1 [cs.AI])

    [http://arxiv.org/abs/2304.14553](http://arxiv.org/abs/2304.14553)

    在chatbot的使用中，应该依据适当性原则而非纯粹的安全性原则来进行评估，以避免其受限制。

    

    保障AI应用程序的“安全性”已成为它们允许使用的主要规范要求，甚至是唯一规范要求。然而，这种“安全性规范性”方法已经显示出在解决chatGPT和其他chatbot引发的问题方面的局限性。本文提出了一种新的限制chatbot话题范围的“适当性规范性”方法，通过对话语的三种适当性（技术交际、社会、道德）进行评估来规定chatbot的语言表达要求，以避免其受约束的范围。

    The strive to make AI applications "safe" has led to the development of safety-measures as the main or even sole normative requirement of their permissible use. Similar can be attested to the latest version of chatbots, such as chatGPT. In this view, if they are "safe", they are supposed to be permissible to deploy. This approach, which we call "safety-normativity", is rather limited in solving the emerging issues that chatGPT and other chatbots have caused thus far. In answering this limitation, in this paper we argue for limiting chatbots in the range of topics they can chat about according to the normative concept of appropriateness. We argue that rather than looking for "safety" in a chatbot's utterances to determine what they may and may not say, we ought to assess those utterances according to three forms of appropriateness: technical-discursive, social, and moral. We then spell out what requirements for chatbots follow from these forms of appropriateness to avoid the limits of p
    
[^53]: 基于贝叶斯分类器的特征最优分区研究

    Optimal partition of feature using Bayesian classifier. (arXiv:2304.14537v1 [cs.LG])

    [http://arxiv.org/abs/2304.14537](http://arxiv.org/abs/2304.14537)

    本文通过提出一种名为“共单调独立分类器”(CIBer)的新技术，专注于特征的最优分区，旨在克服朴素贝叶斯方法带来的挑战，并且证明该技术在不同数据集上具有更高的准确率和更低的错误率。

    

    朴素贝叶斯分类器是一种应用贝叶斯原理的流行分类方法，尽管输入变量之间的条件依赖关系听起来很好，但实际上会导致大多数投票风格的行为。朴素贝叶斯算法中的某些特征被称为独立特征，因为在预测分类时它们没有条件相关性或依赖性。本文通过提出一种名为“共单调独立分类器”(CIBer)的新技术，专注于特征的最优分区，旨在克服朴素贝叶斯方法带来的挑战。在不同的数据集上，我们明确证明了我们的技术的有效性，在错误率更低、准确率更高或相当的情况下，与随机森林和XGBoost等模型相比。

    The Naive Bayesian classifier is a popular classification method employing the Bayesian paradigm. The concept of having conditional dependence among input variables sounds good in theory but can lead to a majority vote style behaviour. Achieving conditional independence is often difficult, and they introduce decision biases in the estimates. In Naive Bayes, certain features are called independent features as they have no conditional correlation or dependency when predicting a classification. In this paper, we focus on the optimal partition of features by proposing a novel technique called the Comonotone-Independence Classifier (CIBer) which is able to overcome the challenges posed by the Naive Bayes method. For different datasets, we clearly demonstrate the efficacy of our technique, where we achieve lower error rates and higher or equivalent accuracy compared to models such as Random Forests and XGBoost.
    
[^54]: 深度强化学习中的对抗策略优化

    Adversarial Policy Optimization in Deep Reinforcement Learning. (arXiv:2304.14533v1 [cs.LG])

    [http://arxiv.org/abs/2304.14533](http://arxiv.org/abs/2304.14533)

    本文提出了一种新的强化学习算法，其中一个扰动网络通过最大化智能体执行不同动作的概率，同时最小化状态的扭曲，以减轻数据过拟合的影响。

    

    由于神经网络表示的策略可以过度拟合观测中的表面特征，这会妨碍强化学习智能体学习有效的策略。在高维状态下，这个问题变得更加严重，智能体难以学习有用的策略。数据增强可以通过减轻过拟合的影响来提供性能提升。然而，这样的数据增强是一种先验知识，如果在环境中简单地应用它们可能会降低智能体的性能。在本文中，我们提出了一种新的强化学习算法，以减轻上述问题并提高学习策略的效率。我们的方法包括一个博弈理论目标，在这个目标中，扰动网络修改状态，以最大化智能体执行不同动作的概率，同时最小化状态的扭曲。相反，策略网络更新其参数，以最小化扰动效果，同时最大化未来奖励的期望值。

    The policy represented by the deep neural network can overfit the spurious features in observations, which hamper a reinforcement learning agent from learning effective policy. This issue becomes severe in high-dimensional state, where the agent struggles to learn a useful policy. Data augmentation can provide a performance boost to RL agents by mitigating the effect of overfitting. However, such data augmentation is a form of prior knowledge, and naively applying them in environments might worsen an agent's performance. In this paper, we propose a novel RL algorithm to mitigate the above issue and improve the efficiency of the learned policy. Our approach consists of a max-min game theoretic objective where a perturber network modifies the state to maximize the agent's probability of taking a different action while minimizing the distortion in the state. In contrast, the policy network updates its parameters to minimize the effect of perturbation while maximizing the expected future r
    
[^55]: 基于哈密顿回路的高维聚类

    High-dimensional Clustering onto Hamiltonian Cycle. (arXiv:2304.14531v1 [cs.AI])

    [http://arxiv.org/abs/2304.14531](http://arxiv.org/abs/2304.14531)

    提出了一种基于哈密顿回路的高维聚类框架，将全局结构和局部结构相结合，通过哈密顿回路将不同簇的锚点排序并映射到圆的周长上，改进了聚类的标签，达到更好的分类效果。

    

    聚类旨在根据样本之间的相似性对未标记的样本进行分组。它已成为分析高维数据的重要工具。然而，大多数聚类方法仅生成伪标签，因此无法同时呈现不同簇和异常值之间的相似性。本文提出了一种新的框架，称为基于哈密顿回路的高维聚类（HCHC），以解决上述问题。首先，HCHC在一个目标函数中将全局结构与局部结构相结合，进行深度聚类，将标签改进为相对概率，以挖掘不同簇之间的相似性，同时保持每个簇内的局部结构。然后，通过簇相似性生成最优哈密顿回路上对不同簇的锚进行排序，并映射到圆的周长上。最后，对于一个更高概率属于某个簇的样本，它会映射到与之相应的锚点更近的位置。通过这种方式，分类效果得到了提高。

    Clustering aims to group unlabelled samples based on their similarities. It has become a significant tool for the analysis of high-dimensional data. However, most of the clustering methods merely generate pseudo labels and thus are unable to simultaneously present the similarities between different clusters and outliers. This paper proposes a new framework called High-dimensional Clustering onto Hamiltonian Cycle (HCHC) to solve the above problems. First, HCHC combines global structure with local structure in one objective function for deep clustering, improving the labels as relative probabilities, to mine the similarities between different clusters while keeping the local structure in each cluster. Then, the anchors of different clusters are sorted on the optimal Hamiltonian cycle generated by the cluster similarities and mapped on the circumference of a circle. Finally, a sample with a higher probability of a cluster will be mapped closer to the corresponding anchor. In this way, ou
    
[^56]: pyBibX--一种基于人工智能工具的用于文献计量和科学计量分析的Python库

    pyBibX -- A Python Library for Bibliometric and Scientometric Analysis Powered with Artificial Intelligence Tools. (arXiv:2304.14516v1 [cs.DL])

    [http://arxiv.org/abs/2304.14516](http://arxiv.org/abs/2304.14516)

    pyBibX是一种Python库，旨在通过Scopus、Web of Science和PubMed的原始数据文件进行全面的文献计量和科学计量分析，并将先进的人工智能能力融入到其核心功能中。

    

    文献计量和科学计量分析提供了对跨学科的复杂研究领域和协作动态的宝贵洞察。本文介绍了 pyBibX，这是一个Python库，旨在在来自Scopus、Web of Science和PubMed的原始数据文件上进行全面的文献计量和科学计量分析，并将最先进的人工智能能力无缝集成到其核心功能中。该库执行全面的EDA，通过视觉吸引人的图形说明结果。网络功能已经巧妙地集成，包括引文、协作和相似性分析。此外，该库还包含了人工智能能力，包括嵌入向量、专题建模、文本摘要和其他一般的自然语言处理任务，使用模型如句子BERT、BerTopic、BERT、chatGPT和PEGASUS。作为示范，我们分析了与多标准决策相关的184份文件。

    Bibliometric and Scientometric analyses offer invaluable perspectives on the complex research terrain and collaborative dynamics spanning diverse academic disciplines. This paper presents pyBibX, a python library devised to conduct comprehensive bibliometric and scientometric analyses on raw data files sourced from Scopus, Web of Science, and PubMed, seamlessly integrating state of the art AI capabilities into its core functionality. The library executes a comprehensive EDA, presenting outcomes via visually appealing graphical illustrations. Network capabilities have been deftly integrated, encompassing Citation, Collaboration, and Similarity Analysis. Furthermore, the library incorporates AI capabilities, including Embedding vectors, Topic Modeling, Text Summarization, and other general Natural Language Processing tasks, employing models such as Sentence-BERT, BerTopic, BERT, chatGPT, and PEGASUS. As a demonstration, we have analyzed 184 documents associated with multiple-criteria dec
    
[^57]: 一种高效的集成可解释人工智能（XAI）方法用于变形人脸检测。

    An Efficient Ensemble Explainable AI (XAI) Approach for Morphed Face Detection. (arXiv:2304.14509v1 [cs.CV])

    [http://arxiv.org/abs/2304.14509](http://arxiv.org/abs/2304.14509)

    本文提出了解决面部变形攻击检测的方法，采用多个深度神经卷积架构，但这些模型难以理解和分析，给生物测量学界带来了困扰。

    

    生物识别认证系统的广泛使用导致攻击者/冒充者通过伪造图像来伪造用户身份。本文提出了面部变形攻击检测（MAD）的多个深度神经卷积架构，以预防这种攻击并减少与其相关的风险。虽然深度学习模型在性能方面取得了最优结果，但由于其黑盒/不透明的特性，难以理解和分析这些网络。因此，可能会做出错误的判断。然而，目前缺乏有关黑匣子深度学习模型的决策方法，这些模型用于生物测量学表示攻击检测（PAD）或MAD可帮助生物测量学界对于使用基于深度学习的生物测量学系统进行身份验证和认证感到信任。

    The extensive utilization of biometric authentication systems have emanated attackers / imposters to forge user identity based on morphed images. In this attack, a synthetic image is produced and merged with genuine. Next, the resultant image is user for authentication. Numerous deep neural convolutional architectures have been proposed in literature for face Morphing Attack Detection (MADs) to prevent such attacks and lessen the risks associated with them. Although, deep learning models achieved optimal results in terms of performance, it is difficult to understand and analyse these networks since they are black box/opaque in nature. As a consequence, incorrect judgments may be made. There is, however, a dearth of literature that explains decision-making methods of black box deep learning models for biometric Presentation Attack Detection (PADs) or MADs that can aid the biometric community to have trust in deep learning-based biometric systems for identification and authentication in 
    
[^58]: 用于可解释的姿势表达、分析和生成的深层状态空间建模

    Deep state-space modeling for explainable representation, analysis, and generation of professional human poses. (arXiv:2304.14502v1 [cs.CV])

    [http://arxiv.org/abs/2304.14502](http://arxiv.org/abs/2304.14502)

    本文提出一种新方法，通过引入三种新方法来创建人类运动的可解释表示，以解决建模人体运动的科学挑战，并且该方法能准确预测人体运动并生成新的运动。

    

    由于其广泛的实际应用，人体动作的分析已被广泛研究。然而，当前的前沿仍然面临建模人体运动的科学挑战。首先，需要新的模型来考虑人类运动的随机性和人体的物理结构，以准确预测全身运动描述符随时间的演变。其次，现有深度学习算法在生成人类运动时，对于其身体姿势预测的可解释性仍需改进，因为它们缺乏人类运动的可理解表示。本文通过引入三种新方法来创建人类运动的可解释表示来解决这些挑战。在这项工作中，全身运动被公式化为动态系统的状态空间模型，其参数使用深度学习和统计算法进行估计。这些表示遵循支持人类运动的结构化原则，并且由用户可以理解。所提出的方法能够准确预测人体运动并生成新的运动，同时提供有意义的身体姿势预测解释。

    The analysis of human movements has been extensively studied due to its wide variety of practical applications. Nevertheless, the state-of-the-art still faces scientific challenges while modeling human movements. Firstly, new models that account for the stochasticity of human movement and the physical structure of the human body are required to accurately predict the evolution of full-body motion descriptors over time. Secondly, the explainability of existing deep learning algorithms regarding their body posture predictions while generating human movements still needs to be improved as they lack comprehensible representations of human movement. This paper addresses these challenges by introducing three novel approaches for creating explainable representations of human movement. In this work, full-body movement is formulated as a state-space model of a dynamic system whose parameters are estimated using deep learning and statistical algorithms. The representations adhere to the structur
    
[^59]: 读懂我的想法：一个用于人类信念预测的多模态数据集

    Read My Mind: A Multi-Modal Dataset for Human Belief Prediction. (arXiv:2304.14501v1 [cs.CV])

    [http://arxiv.org/abs/2304.14501](http://arxiv.org/abs/2304.14501)

    该论文提出了一个大规模多模态视频数据集，用于人类信念预测，以促进人工智能系统推断人类信念的发展和评估。

    

    理解人类意图对于实现有效和高效的人机交互至关重要。为了使人工智能系统推断人类信念的能力得到发展和评估，我们介绍了一个基于物体环境关系的大规模多模态视频数据集，用于意图预测。

    Understanding human intentions is key to enabling effective and efficient human-robot interaction (HRI) in collaborative settings. To enable developments and evaluation of the ability of artificial intelligence (AI) systems to infer human beliefs, we introduce a large-scale multi-modal video dataset for intent prediction based on object-context relations.
    
[^60]: MWaste：管理家庭垃圾的深度学习方法

    MWaste: A Deep Learning Approach to Manage Household Waste. (arXiv:2304.14498v1 [cs.CV])

    [http://arxiv.org/abs/2304.14498](http://arxiv.org/abs/2304.14498)

    MWaste是一款基于深度学习的移动应用，能够有效地将垃圾材料分类为垃圾、塑料、纸张、金属、玻璃或硬纸板，可帮助应对气候变化。

    

    计算机视觉方法已被证明在分类垃圾处理的回收分类方面很有效，但现有方法成本高、不精确且不清晰。为解决这个问题，我们介绍MWaste，一款移动应用程序，利用计算机视觉和深度学习技术将垃圾材料分类为垃圾、塑料、纸张、金属、玻璃或硬纸板。其有效性已在各种神经网络架构和真实世界图像上进行了测试，在测试集上达到了92％的平均精度。该应用程序可以通过使垃圾处理更有效并减少因不正确的垃圾处理而引起的温室气体排放来帮助应对气候变化。

    Computer vision methods have shown to be effective in classifying garbage into recycling categories for waste processing, existing methods are costly, imprecise, and unclear. To tackle this issue, we introduce MWaste, a mobile application that uses computer vision and deep learning techniques to classify waste materials as trash, plastic, paper, metal, glass or cardboard. Its effectiveness was tested on various neural network architectures and real-world images, achieving an average precision of 92\% on the test set. This app can help combat climate change by enabling efficient waste processing and reducing the generation of greenhouse gases caused by incorrect waste disposal.
    
[^61]: 生理和医疗神经网络中的模型可解释性

    Model Explainability in Physiological and Healthcare-based Neural Networks. (arXiv:2304.14495v1 [cs.CV])

    [http://arxiv.org/abs/2304.14495](http://arxiv.org/abs/2304.14495)

    无需接触式传感器，使用智能手机摄像头测量SpO2的挑战性使得需要提取面部兴趣区域，从中获取光电容抗信号并使用机器学习算法估计SpO2。

    

    评估呼吸功能和治疗慢性肺部疾病关键在于估计和监测SpO2。COVID-19大流行凸显了在无症状病人中及早检测SpO2变化的重要性。然而，传统的SpO2测量方法依赖于接触式传感，存在交叉感染和患有肢体灌流障碍的患者并发症的风险。此外，脉搏血氧仪可能在边缘化社区和欠发达国家不可用。最近的研究探讨使用视频测量SpO2以解决这些局限性，但使用智能手机摄像头无接触地测量SpO2，特别是由于智能手机摄像头传感器的生理信号较微弱且光学选择性较低，因此具有挑战性。该系统包括三个主要步骤：1）提取面部区域的兴趣区域（ROI），2）从ROI获取光电容抗（PPG）信号，3）使用机器学习算法从获取的PPG信号估计SpO2。

    The estimation and monitoring of SpO2 are crucial for assessing lung function and treating chronic pulmonary diseases. The COVID-19 pandemic has highlighted the importance of early detection of changes in SpO2, particularly in asymptomatic patients with clinical deterioration. However, conventional SpO2 measurement methods rely on contact-based sensing, presenting the risk of cross-contamination and complications in patients with impaired limb perfusion. Additionally, pulse oximeters may not be available in marginalized communities and undeveloped countries. To address these limitations and provide a more comfortable and unobtrusive way to monitor SpO2, recent studies have investigated SpO2 measurement using videos. However, measuring SpO2 using cameras in a contactless way, particularly from smartphones, is challenging due to weaker physiological signals and lower optical selectivity of smartphone camera sensors. The system includes three main steps: 1) extraction of the region of int
    
[^62]: 对象中心的深度主动推理模型中的对称性与复杂性

    Symmetry and Complexity in Object-Centric Deep Active Inference Models. (arXiv:2304.14493v1 [cs.CV])

    [http://arxiv.org/abs/2304.14493](http://arxiv.org/abs/2304.14493)

    本文研究了深度主动推理下的物体中心表示中的对称性，以生成最简洁而准确的模型，从而学习和预测新的物体视图。

    

    人类每天要感知和互动上百个物体。为此，他们需要使用这些物体的心理模型，并经常利用物体形状和外观的对称性来学习通用和可转移的技能。主动推理是理解和建模有感知能力的代理的一种基本方法。它认为代理人在环境中产生模型，通过最小化上限的惊奇（即自由能）来学习和行动。自由能分解为准确性和复杂性项，这意味着代理倾向于选择最简单的模型，能够准确地解释他们的感觉观察结果。本文研究了特定物体天生对称性在深度主动推理下生成模型的潜在状态空间中也表现为对称性。具体而言，我们关注对象中心的表示，其从像素中训练以预测新的物体视图而年龄。

    Humans perceive and interact with hundreds of objects every day. In doing so, they need to employ mental models of these objects and often exploit symmetries in the object's shape and appearance in order to learn generalizable and transferable skills. Active inference is a first principles approach to understanding and modeling sentient agents. It states that agents entertain a generative model of their environment, and learn and act by minimizing an upper bound on their surprisal, i.e. their Free Energy. The Free Energy decomposes into an accuracy and complexity term, meaning that agents favor the least complex model, that can accurately explain their sensory observations. In this paper, we investigate how inherent symmetries of particular objects also emerge as symmetries in the latent state space of the generative model learnt under deep active inference. In particular, we focus on object-centric representations, which are trained from pixels to predict novel object views as the age
    
[^63]: 对抗感知的迭代学习

    Adversary Aware Continual Learning. (arXiv:2304.14483v1 [cs.LG])

    [http://arxiv.org/abs/2304.14483](http://arxiv.org/abs/2304.14483)

    本文提出了一种新的防御性框架，针对对抗性后门攻击，利用可感知模式压倒攻击者的不可感知模式，提高了模型的稳健性。

    

    类别增量学习方法非常有用，因为它们帮助模型按顺序学习新信息（类别），同时保留之前获得的信息（类别）。然而，这样的方法极易受到对抗性后门攻击的影响，在训练期间，智能对手可以通过引入少量的信息误导模型，从而在测试时故意忘记特定的任务或类别。在这项工作中，我们提出了一种新的防御性框架来反击这种潜在攻击。我们利用攻击者的主要优势--使后门模式对人不可感知--并提议在训练期间学习一个可以压倒攻击者的可感知模式以抵消对抗性攻击者的模式。通过各种常用的Replay-based（两者都

    Class incremental learning approaches are useful as they help the model to learn new information (classes) sequentially, while also retaining the previously acquired information (classes). However, it has been shown that such approaches are extremely vulnerable to the adversarial backdoor attacks, where an intelligent adversary can introduce small amount of misinformation to the model in the form of imperceptible backdoor pattern during training to cause deliberate forgetting of a specific task or class at test time. In this work, we propose a novel defensive framework to counter such an insidious attack where, we use the attacker's primary strength-hiding the backdoor pattern by making it imperceptible to humans-against it, and propose to learn a perceptible (stronger) pattern (also during the training) that can overpower the attacker's imperceptible (weaker) pattern. We demonstrate the effectiveness of the proposed defensive mechanism through various commonly used Replay-based (both 
    
[^64]: 学习扩散先验用于NeRFs

    Learning a Diffusion Prior for NeRFs. (arXiv:2304.14473v1 [cs.CV])

    [http://arxiv.org/abs/2304.14473](http://arxiv.org/abs/2304.14473)

    本文提出了一种使用扩散模型生成编码在规则网格上的NeRFs的方法，该方法可以采样出逼真的NeRFs，并允许有条件的生成，给定某个观察作为指导。

    

    神经辐射场（NeRFs）已成为从2D数据派生出的物体和场景的强大神经3D表示。然而，在许多情况下，生成NeRFs仍然是困难的。例如，只使用少量视图作为监督训练NeRFs仍然具有挑战性，因为它是一个欠参数问题。在这种情况下，需要一些归纳先验来过滤不良局部最小值。引入这样的归纳先验的一种方法是学习NeRFs的生成模型，该模型建模某类场景。在本文中，我们提出使用扩散模型生成编码在规则网格上的NeRFs。我们表明，我们的模型可以采样出逼真的NeRFs，并同时允许有条件的生成，给定某个观察作为指导。

    Neural Radiance Fields (NeRFs) have emerged as a powerful neural 3D representation for objects and scenes derived from 2D data. Generating NeRFs, however, remains difficult in many scenarios. For instance, training a NeRF with only a small number of views as supervision remains challenging since it is an under-constrained problem. In such settings, it calls for some inductive prior to filter out bad local minima. One way to introduce such inductive priors is to learn a generative model for NeRFs modeling a certain class of scenes. In this paper, we propose to use a diffusion model to generate NeRFs encoded on a regularized grid. We show that our model can sample realistic NeRFs, while at the same time allowing conditional generations, given a certain observation as guidance.
    
[^65]: 具有语义感知先验的可控单次人脸视频合成

    Controllable One-Shot Face Video Synthesis With Semantic Aware Prior. (arXiv:2304.14471v1 [cs.CV])

    [http://arxiv.org/abs/2304.14471](http://arxiv.org/abs/2304.14471)

    本文提出一种具有语义感知先验的可控单次人脸视频合成方法，通过可靠的面部分割和新颖的语义感知运动扭曲方案，在保证语义准确和实现真实运动的同时，生成高质量的面部视频。

    

    单次头像合成任务旨在通过使用从驾驶帧中学习的稀疏关键点估计的运动场来扭曲从源提取的外观特征，从而将源图像动画化为另一种姿势和表情。然而，现有方法存在两个主要限制：1）在头部姿势较大时合成质量不佳，源图像和驾驶视频中的第一帧之间存在可观的姿势错配；2）由于缺乏语义理解和适当的脸部几何正则化，因此无法捕捉精细但关键的面部运动细节。为了解决这些缺陷，我们提出了一种新方法，该方法利用丰富的面部先验信息，能够生成具有改进语义一致性和逼真运动细节的面部视频。

    The one-shot talking-head synthesis task aims to animate a source image to another pose and expression, which is dictated by a driving frame. Recent methods rely on warping the appearance feature extracted from the source, by using motion fields estimated from the sparse keypoints, that are learned in an unsupervised manner. Due to their lightweight formulation, they are suitable for video conferencing with reduced bandwidth. However, based on our study, current methods suffer from two major limitations: 1) unsatisfactory generation quality in the case of large head poses and the existence of observable pose misalignment between the source and the first frame in driving videos. 2) fail to capture fine yet critical face motion details due to the lack of semantic understanding and appropriate face geometry regularization. To address these shortcomings, we propose a novel method that leverages the rich face prior information, the proposed model can generate face videos with improved seman
    
[^66]: Moccasin：神经网络的高效张量重算技术

    Moccasin: Efficient Tensor Rematerialization for Neural Networks. (arXiv:2304.14463v1 [cs.LG])

    [http://arxiv.org/abs/2304.14463](http://arxiv.org/abs/2304.14463)

    本文提出了一种名为Moccasin的新型约束编程形式，用于实现在内存预算下最小化计算图的执行时间，相较于最近的研究，该方法显著提高了效率，并成功应用于神经网络的高效张量重算。

    

    在边缘计算设备上部署和训练神经网络面临许多挑战，其中较低的内存是部署大型神经网络模型时经常遇到的最大限制因素之一。张量重算是解决神经网络训练和推理所需高内存需求的一种方式。本文考虑在内存预算下最小化计算图的执行时间问题。具体来说，我们开发了一种新的约束编程形式，称为Moccasin，其中只有$O(n)$个整数变量，$n$是计算图中节点的数量。这相对于最近文献中提出的具有$O(n^2)$布尔变量的公式提出了显着的改进。我们展示了数值研究结果，表明我们的方法在大规模图上比最近的工作快一个数量级。

    The deployment and training of neural networks on edge computing devices pose many challenges. The low memory nature of edge devices is often one of the biggest limiting factors encountered in the deployment of large neural network models. Tensor rematerialization or recompute is a way to address high memory requirements for neural network training and inference. In this paper we consider the problem of execution time minimization of compute graphs subject to a memory budget. In particular, we develop a new constraint programming formulation called \textsc{Moccasin} with only $O(n)$ integer variables, where $n$ is the number of nodes in the compute graph. This is a significant improvement over the works in the recent literature that propose formulations with $O(n^2)$ Boolean variables. We present numerical studies that show that our approach is up to an order of magnitude faster than recent work especially for large-scale graphs.
    
[^67]: 机器学习用于检测和缓解Web漏洞和Web攻击

    Machine Learning for Detection and Mitigation of Web Vulnerabilities and Web Attacks. (arXiv:2304.14451v1 [cs.CR])

    [http://arxiv.org/abs/2304.14451](http://arxiv.org/abs/2304.14451)

    本文调研了使用经典和先进的机器学习技术进行防御XSS和CSRF的研究，并总结出关键要点，为探讨该研究方向提供了参考。

    

    在Web安全领域中，检测和缓解跨站脚本（XSS）和跨站请求伪造（CSRF）等关键Web漏洞和攻击一直是一个重要的问题。这些Web攻击不断演变，越来越难以检测。近年来，研究人员已经开始使用机器学习技术来防御XSS和CSRF，由于取得的积极结果，可以得出结论，这是一个有前途的研究方向。本文的目标是简要介绍已经发表的研究工作，这些研究工作采用经典和先进的机器学习来识别和预防XSS和CSRF。提供这份调查的目的是为了探讨已经实施的不同机器学习方法，了解其中的关键要点。

    Detection and mitigation of critical web vulnerabilities and attacks like cross-site scripting (XSS), and cross-site request forgery (CSRF) have been a great concern in the field of web security. Such web attacks are evolving and becoming more challenging to detect. Several ideas from different perspectives have been put forth that can be used to improve the performance of detecting these web vulnerabilities and preventing the attacks from happening. Machine learning techniques have lately been used by researchers to defend against XSS and CSRF, and given the positive findings, it can be concluded that it is a promising research direction. The objective of this paper is to briefly report on the research works that have been published in this direction of applying classical and advanced machine learning to identify and prevent XSS and CSRF. The purpose of providing this survey is to address different machine learning approaches that have been implemented, understand the key takeaway of 
    
[^68]: 无监督学习鲁棒性谱形匹配

    Unsupervised Learning of Robust Spectral Shape Matching. (arXiv:2304.14419v1 [cs.CV])

    [http://arxiv.org/abs/2304.14419](http://arxiv.org/abs/2304.14419)

    该方法提出了一种新的学习方法，使用无监督方式进行鲁棒的三维形状匹配，可以获得不同场景下的准确对应关系。

    

    我们提出了一种新的学习方法来进行鲁棒的三维形状匹配。我们的方法基于深度函数映射，并可以完全无监督地进行训练。之前的深度函数映射方法主要集中在预测最优化函数映射上，然后依靠现成的后期处理来获得在推理过程中准确的点映射。然而，这个两阶段过程通常会产生次优性能。相比之下，我们提出了一种新的无监督损失，利用函数映射和点映射之间关系的最新见解，从而直接获得点映射而无需任何后期处理。我们的方法不仅可以获得近等距形状的准确对应关系，还可以获得更具挑战性的非等距形状和部分形状，以及存在不同离散化或拓扑噪声的形状的准确对应关系。使用总共九个不同的数据集，我们的方法在不同场景下得到了很好的结果。

    We propose a novel learning-based approach for robust 3D shape matching. Our method builds upon deep functional maps and can be trained in a fully unsupervised manner. Previous deep functional map methods mainly focus on predicting optimised functional maps alone, and then rely on off-the-shelf post-processing to obtain accurate point-wise maps during inference. However, this two-stage procedure for obtaining point-wise maps often yields sub-optimal performance. In contrast, building upon recent insights about the relation between functional maps and point-wise maps, we propose a novel unsupervised loss to couple the functional maps and point-wise maps, and thereby directly obtain point-wise maps without any post-processing. Our approach obtains accurate correspondences not only for near-isometric shapes, but also for more challenging non-isometric shapes and partial shapes, as well as shapes with different discretisation or topological noise. Using a total of nine diverse datasets, we
    
[^69]: 生成型人工智能知觉：关于学术界使用生成型人工智能工具的教职工和学生看法的调查

    Generative AI Perceptions: A Survey to Measure the Perceptions of Faculty, Staff, and Students on Generative AI Tools in Academia. (arXiv:2304.14415v1 [cs.HC])

    [http://arxiv.org/abs/2304.14415](http://arxiv.org/abs/2304.14415)

    本文调查了学术界使用生成型人工智能工具ChatGPT的影响，旨在了解其如何革新工程教育并改变技术、教职工与学生之间的关系。调查可供其他大学和机构使用。

    

    ChatGPT是一种自然语言处理工具，可以进行类似人类对话的交互，并能够根据不同的提示生成连贯且相关的回复。该工具能够理解用户输入的自然文本，并以多种形式生成适当的响应。本文重点探讨了ChatGPT如何革新工程教育，以及技术、学生、教职工之间的关系。因为该工具快速变化和不断改进，因此现在是收集相关数据的关键时期。为此，设计了一项调查，以衡量ChatGPT对教职工和学生的影响，并将该调查作为德克萨斯A&M大学技术报告分享，以便其他大学和机构使用该调查，并在其他地方进行影响评估。

    ChatGPT is a natural language processing tool that can engage in human-like conversations and generate coherent and contextually relevant responses to various prompts. ChatGPT is capable of understanding natural text that is input by a user and generating appropriate responses in various forms. This tool represents a major step in how humans are interacting with technology. This paper specifically focuses on how ChatGPT is revolutionizing the realm of engineering education and the relationship between technology, students, and faculty and staff. Because this tool is quickly changing and improving with the potential for even greater future capability, it is a critical time to collect pertinent data. A survey was created to measure the effects of ChatGPT on students, faculty, and staff. This survey is shared as a Texas A&M University technical report to allow other universities and entities to use this survey and measure the effects elsewhere.
    
[^70]: 使用毫米波雷达稀疏点云进行人类语义分割

    Human Semantic Segmentation using Millimeter-Wave Radar Sparse Point Clouds. (arXiv:2304.14132v1 [cs.CV])

    [http://arxiv.org/abs/2304.14132](http://arxiv.org/abs/2304.14132)

    本文提出了一种在毫米波雷达稀疏点云上进行人类语义分割的框架，该框架优于相机和激光雷达的隐私保护和抗干扰能力。同时，本文引入图结构和拓扑特征，并设计了一个含有全局特征模块和顺序特征模块的语义分割框架，成功解决了稀疏和时间拓扑特征的问题。

    

    本文提出了一种在毫米波雷达稀疏时序点云上进行语义分割的框架。相比相机和激光雷达，毫米波雷达具有不泄露隐私、强抗干扰能力和长检测距离的优势。然而，毫米波数据的稀疏和时间拓扑特征的捕获仍然是一个问题，特别是在人类语义分割任务中，以前的先进分割方法 (如PointNet、PointCNN、Point Transformer) 没有被充分应用于实际场景中。

    This paper presents a framework for semantic segmentation on sparse sequential point clouds of millimeter-wave radar. Compared with cameras and lidars, millimeter-wave radars have the advantage of not revealing privacy, having a strong anti-interference ability, and having long detection distance. The sparsity and capturing temporal-topological features of mmWave data is still a problem. However, the issue of capturing the temporal-topological coupling features under the human semantic segmentation task prevents previous advanced segmentation methods (e.g PointNet, PointCNN, Point Transformer) from being well utilized in practical scenarios. To address the challenge caused by the sparsity and temporal-topological feature of the data, we (i) introduce graph structure and topological features to the point cloud, (ii) propose a semantic segmentation framework including a global feature-extracting module and a sequential feature-extracting module. In addition, we design an efficient and mo
    
[^71]: 评估GPT-3.5和GPT-4在支持医疗保健信息需求方面的实际作用

    Evaluation of GPT-3.5 and GPT-4 for supporting real-world information needs in healthcare delivery. (arXiv:2304.13714v1 [cs.AI])

    [http://arxiv.org/abs/2304.13714](http://arxiv.org/abs/2304.13714)

    本研究评估了在临床环境中使用GPT-3.5和GPT-4解决医学问题的安全性以及与信息技术咨询服务报告的一致性。研究结果表明，两个LLMs都可以以安全和一致的方式满足医生的信息需求。

    

    尽管在医疗保健领域使用大型语言模型(LLMs)越来越受关注，但当前的探索并未评估LLMs在临床环境中的实用性和安全性。我们的目标是确定两个LLM是否可以以安全和一致的方式满足由医生提交的信息需求问题。我们将66个来自信息技术咨询服务的问题通过简单的提示提交给GPT-3.5和GPT-4。12名医生评估了LLM响应对患者造成伤害的可能性以及与信息技术咨询服务的现有报告的一致性。医生的评估基于多数票汇总。对于没有任何问题，大多数医生认为任何一个LLM响应都不会造成伤害。对于GPT-3.5，8个问题的响应与信息技术咨询报告一致，20个不一致，9个无法评估。有29个响应没有多数票表示“同意”、“不同意”和“无法评估”。

    Despite growing interest in using large language models (LLMs) in healthcare, current explorations do not assess the real-world utility and safety of LLMs in clinical settings. Our objective was to determine whether two LLMs can serve information needs submitted by physicians as questions to an informatics consultation service in a safe and concordant manner. Sixty six questions from an informatics consult service were submitted to GPT-3.5 and GPT-4 via simple prompts. 12 physicians assessed the LLM responses' possibility of patient harm and concordance with existing reports from an informatics consultation service. Physician assessments were summarized based on majority vote. For no questions did a majority of physicians deem either LLM response as harmful. For GPT-3.5, responses to 8 questions were concordant with the informatics consult report, 20 discordant, and 9 were unable to be assessed. There were 29 responses with no majority on "Agree", "Disagree", and "Unable to assess". Fo
    
[^72]: 用于自动驾驶车辆的激光雷达-相机端到端自标定

    End-to-End Lidar-Camera Self-Calibration for Autonomous Vehicles. (arXiv:2304.12412v1 [cs.CV])

    [http://arxiv.org/abs/2304.12412](http://arxiv.org/abs/2304.12412)

    本文提出了一种名为CaLiCa的端到端深度自标定网络，用于联合自动校准针孔相机和激光雷达的固有和外参参数以确保车辆多模式感知传感器的校准质量，同时采用孪生结构以达到领域共享特征的目的。

    

    自动驾驶车辆配备了多模式感知传感器，以确保汽车安全行驶。但是如何在汽车运行期间保持传感器的校准质量成为一个有趣的问题，同时如何联合校准多个传感器以确保系统误差不会传播也是一个挑战。本文提出一种名为CaLiCa的端到端深度自标定网络，针对针孔相机和激光雷达的自动校准问题做出了改进。我们通过回归相机图像和激光点云之间的特征相关性，联合预测相机固有参数(焦距和畸变)以及激光雷达-相机外参参数(旋转和平移)。网络采用孪生结构安排以将网络特征学习约束在点云和相机图像领域的共享特征上。

    Autonomous vehicles are equipped with a multi-modal sensor setup to enable the car to drive safely. The initial calibration of such perception sensors is a highly matured topic and is routinely done in an automated factory environment. However, an intriguing question arises on how to maintain the calibration quality throughout the vehicle's operating duration. Another challenge is to calibrate multiple sensors jointly to ensure no propagation of systemic errors. In this paper, we propose CaLiCa, an end-to-end deep self-calibration network which addresses the automatic calibration problem for pinhole camera and Lidar. We jointly predict the camera intrinsic parameters (focal length and distortion) as well as Lidar-Camera extrinsic parameters (rotation and translation), by regressing feature correlation between the camera image and the Lidar point cloud. The network is arranged in a Siamese-twin structure to constrain the network features learning to a mutually shared feature in both poi
    
[^73]: Stubborn：用于评估具有一致激励的代理之间的顽固度的环境

    Stubborn: An Environment for Evaluating Stubbornness between Agents with Aligned Incentives. (arXiv:2304.12280v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2304.12280](http://arxiv.org/abs/2304.12280)

    本文提出了在完全合作设置下，评估代理之间固执程度的环境Stubborn，通过一个能够体现人类社交行为的指标来促进研究智能体之间的社交动态和固执行为。

    

    最近，在多智能体强化学习（MARL）领域的研究已经在学习社交行为和合作方面取得了成功。混合和博弈设置下智能体之间的社交困境已经得到了广泛的研究，但在完全合作的设置下，智能体之间的社交困境研究较少。虽然完全一致的利益有助于智能体之间的合作，并且可以带来奖励，但并不保证合作。我们提出了一种衡量智能体之间“固执”程度的指标，旨在体现其名称所描述的人类社交行为：一个慢慢升级和潜在灾难性的分歧。我们希望促进研究关于智能体固执的倾向，对应智能体的反应以及由此产生的社交动态。在本文中，我们提出了一种名为Stubborn的环境，用于评估具有完全一致激励的代理之间的固执程度。在我们的初步结果中，智能体学会了使用其行为来管理冲突，而不是选择以牺牲自己的最佳利益来达成一致。

    Recent research in multi-agent reinforcement learning (MARL) has shown success in learning social behavior and cooperation. Social dilemmas between agents in mixed-sum settings have been studied extensively, but there is little research into social dilemmas in fullycooperative settings, where agents have no prospect of gaining reward at another agent's expense.  While fully-aligned interests are conducive to cooperation between agents, they do not guarantee it. We propose a measure of "stubbornness" between agents that aims to capture the human social behavior from which it takes its name: a disagreement that is gradually escalating and potentially disastrous. We would like to promote research into the tendency of agents to be stubborn, the reactions of counterpart agents, and the resulting social dynamics.  In this paper we present Stubborn, an environment for evaluating stubbornness between agents with fully-aligned incentives. In our preliminary results, the agents learn to use thei
    
[^74]: LLM作为机器人的大脑：统一自我中心记忆与控制

    LLM as A Robotic Brain: Unifying Egocentric Memory and Control. (arXiv:2304.09349v1 [cs.AI])

    [http://arxiv.org/abs/2304.09349](http://arxiv.org/abs/2304.09349)

    本文提出了一个统一自我中心记忆和控制的框架LLM-Brain，使用大规模语言模型作为机器人大脑进行零-shot学习。该框架包括封闭式多轮对话，覆盖了感知、规划、控制和记忆，具有很好的泛化性能，适用于多个机器人任务。

    

    体感人工智能研究和开发具备物理或虚拟实体（即机器人）并能够与环境动态交互的智能系统。记忆和控制是体感系统的两个基本部分，通常需要分别使用框架进行建模。本文提出了一个新的、可推广的框架，称为LLM-Brain：使用大规模语言模型作为机器人大脑，统一自我中心记忆和控制。LLM-Brain框架集成了多个多模态语言模型用于机器人任务，利用零-shot学习方法。LLM-Brain中的所有组件使用自然语言进行封闭式多轮对话，包括感知、规划、控制和记忆。系统的核心是一个具备自我中心记忆和控制机器人的实体LLM。我们通过研究两个下游任务：主动探索和实体问答来演示LLM-Brain。

    Embodied AI focuses on the study and development of intelligent systems that possess a physical or virtual embodiment (i.e. robots) and are able to dynamically interact with their environment. Memory and control are the two essential parts of an embodied system and usually require separate frameworks to model each of them. In this paper, we propose a novel and generalizable framework called LLM-Brain: using Large-scale Language Model as a robotic brain to unify egocentric memory and control. The LLM-Brain framework integrates multiple multimodal language models for robotic tasks, utilizing a zero-shot learning approach. All components within LLM-Brain communicate using natural language in closed-loop multi-round dialogues that encompass perception, planning, control, and memory. The core of the system is an embodied LLM to maintain egocentric memory and control the robot. We demonstrate LLM-Brain by examining two downstream tasks: active exploration and embodied question answering. The
    
[^75]: 预训练语言模型作为人类辅助视觉计划者

    Pretrained Language Models as Visual Planners for Human Assistance. (arXiv:2304.09179v1 [cs.CV])

    [http://arxiv.org/abs/2304.09179](http://arxiv.org/abs/2304.09179)

    本研究提出了视觉辅助计划（VPA）的任务，利用预训练语言模型作为序列模型，在视频行动分割和预测方面优于现有的方法，来实现多模态AI助手指导用户完成复杂多步骤目标的进展。

    

    为了实现多模态AI助手指导用户完成复杂多步骤目标的进展，本研究提出了视觉辅助计划（VPA）的任务。给定自然语言简要描述的目标，例如“制作书架”，以及用户迄今为止的视频进展，VPA的目标是获得一个计划，即一系列行动，如“砂光书架”、“涂漆书架”等，以实现目标。这需要评估用户在未经修剪的视频中的进展，并与底层目标的要求相关联，即行动的相关性和其中的排序依赖关系。因此，这需要处理长时间的视频历史记录和任意复杂的行动依赖性。为了解决这些问题，我们将VPA分解为视频行动分割和预测。我们将预测步骤公式化为多模态序列建模问题，并提出了基于视觉语言模型的计划者（VLaMP），其中利用预训练的LMs作为序列模型。我们在两个数据集（Epic Kitchen和Charades-Ego）上展示了VLaMP的有效性。我们的实验结果表明，VLaMP在准确性、效率和泛化方面优于现有的方法。

    To make progress towards multi-modal AI assistants which can guide users to achieve complex multi-step goals, we propose the task of Visual Planning for Assistance (VPA). Given a goal briefly described in natural language, e.g., "make a shelf", and a video of the user's progress so far, the aim of VPA is to obtain a plan, i.e., a sequence of actions such as "sand shelf", "paint shelf", etc., to achieve the goal. This requires assessing the user's progress from the untrimmed video, and relating it to the requirements of underlying goal, i.e., relevance of actions and ordering dependencies amongst them. Consequently, this requires handling long video history, and arbitrarily complex action dependencies. To address these challenges, we decompose VPA into video action segmentation and forecasting. We formulate the forecasting step as a multi-modal sequence modeling problem and present Visual Language Model based Planner (VLaMP), which leverages pre-trained LMs as the sequence model. We dem
    
[^76]: 模型所有权争议中的虚假指控

    False Claims against Model Ownership Resolution. (arXiv:2304.06607v1 [cs.CR])

    [http://arxiv.org/abs/2304.06607](http://arxiv.org/abs/2304.06607)

    该论文研究了模型所有权解决方案中对抗恶意原告的鲁棒性问题，展示了常见的MOR方案可以被恶意原告针对未被盗用的独立模型提出虚假指控。

    

    深度神经网络模型是模型所有者的有价值知识产权，构成了竞争优势。因此，开发保护模型不被盗用的技术至关重要。模型所有权解决方案（MOR）是一类可以防止模型被盗的技术。MOR方案使得原告方可以通过提供证据（如水印或指纹）来断言对涉嫌盗用模型的被告方声称所有权，证明涉嫌模型是被盗或者源自于原告方拥有的源模型。现有的大多数 MOR 方案重点放在防范恶意涉嫌方方面，确保如果涉嫌模型确实是被盗版，则原告方将获胜。但是在本文中，我们揭示了现有文献中的常见 MOR 方案存在着另一个同等重要但尚未被充分探讨的鲁棒性问题：恶意原告。我们展示了如何成功地针对未被盗用的独立模型提出虚假指控。

    Deep neural network (DNN) models are valuable intellectual property of model owners, constituting a competitive advantage. Therefore, it is crucial to develop techniques to protect against model theft. Model ownership resolution (MOR) is a class of techniques that can deter model theft. A MOR scheme enables an accuser to assert an ownership claim for a suspect model by presenting evidence, such as a watermark or fingerprint, to show that the suspect model was stolen or derived from a source model owned by the accuser. Most of the existing MOR schemes prioritize robustness against malicious suspects, ensuring that the accuser will win if the suspect model is indeed a stolen model.  In this paper, we show that common MOR schemes in the literature are vulnerable to a different, equally important but insufficiently explored, robustness concern: a malicious accuser. We show how malicious accusers can successfully make false claims against independent suspect models that were not stolen. Our
    
[^77]: 图像生成模型的定性失败及其在检测Deepfakes中的应用

    Qualitative Failures of Image Generation Models and Their Application in Detecting Deepfakes. (arXiv:2304.06470v1 [cs.CV])

    [http://arxiv.org/abs/2304.06470](http://arxiv.org/abs/2304.06470)

    研究调查了图像生成模型的质量失误及其应用于检测Deepfakes，识别了五种定性缺陷。这些发现有助于改进模型并制定检测Deepfakes的策略。

    

    图像和视频生成模型创造出逼真的影像的能力已经达到了前所未有的高度，这使得在许多情况下很难区分真实和伪造的图像。然而，尽管取得了进展，但生成图像的质量和真实世界中的图像之间仍存在差距。为了解决这个问题，我们回顾了大量学术论文和社交媒体内容，以确定图像生成模型的定性缺陷，并将其分类为五类。通过了解这些失败，我们可以确定这些模型需要改进的领域，并制定检测Deepfakes的策略。今天社会中Deepfakes的普遍存在是一个严重的问题，我们的研究发现可以帮助减轻它们的负面影响。

    The ability of image and video generation models to create photorealistic images has reached unprecedented heights, making it difficult to distinguish between real and fake images in many cases. However, despite this progress, a gap remains between the quality of generated images and those found in the real world. To address this, we have reviewed a vast body of literature from both academic publications and social media to identify qualitative shortcomings in image generation models, which we have classified into five categories. By understanding these failures, we can identify areas where these models need improvement, as well as develop strategies for detecting deep fakes. The prevalence of deep fakes in today's society is a serious concern, and our findings can help mitigate their negative impact.
    
[^78]: DR.CPO：通过迭代构建、随机放置和 HPR 遮蔽实现的多样化和逼真的三维增强

    DR.CPO: Diversified and Realistic 3D Augmentation via Iterative Construction, Random Placement, and HPR Occlusion. (arXiv:2303.12743v1 [cs.CV])

    [http://arxiv.org/abs/2303.12743](http://arxiv.org/abs/2303.12743)

    该论文提出了一种多样化和逼真的增强方法，可以创建整体对象并灵活地定位和旋转对象，并相应地应用自遮挡和外遮挡。通过迭代构建多个对象来提高整体对象构造的多样性，构造的对象可以在训练帧中随机放置和旋转。

    

    在自动驾驶中，数据增强常用于改进三维物体检测。最基本的方法包括插入复制对象和旋转和缩放整个训练帧。也已经开发了许多变体。然而，现有方法与现实世界的可能性相比相当有限。在这项工作中，我们开发了一种多样化和逼真增强方法，可以灵活地构造整体对象，自由地定位和旋转对象，并相应地应用自遮挡和外遮挡。为了提高整体对象构造的多样性，我们开发了一种迭代方法，将从现实世界观察到的多个对象随机组合成单个对象。与现有增强方法不同的是，构造的对象可以随机放置和旋转在训练帧中，因为适当的遮挡可以反映在最终整体对象中。最后，为了防止过度增强导致过拟合，我们介绍了一种分层遮挡概率设置，通过对象的位置和大小调整遮挡强度。

    In autonomous driving, data augmentation is commonly used for improving 3D object detection. The most basic methods include insertion of copied objects and rotation and scaling of the entire training frame. Numerous variants have been developed as well. The existing methods, however, are considerably limited when compared to the variety of the real world possibilities. In this work, we develop a diversified and realistic augmentation method that can flexibly construct a whole-body object, freely locate and rotate the object, and apply self-occlusion and external-occlusion accordingly. To improve the diversity of the whole-body object construction, we develop an iterative method that stochastically combines multiple objects observed from the real world into a single object. Unlike the existing augmentation methods, the constructed objects can be randomly located and rotated in the training frame because proper occlusions can be reflected to the whole-body objects in the final step. Fina
    
[^79]: 使用分位数回归森林的可解释上下文异常检测

    Explainable Contextual Anomaly Detection using Quantile Regression Forests. (arXiv:2302.11239v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.11239](http://arxiv.org/abs/2302.11239)

    该论文提出了一种可解释的上下文异常检测方法，运用分位数回归森林来模拟特征之间的依赖关系，能够更准确和可解释地识别偏离类似对象上下文的其他对象。

    

    传统的异常检测方法通过平等对待所有特征来识别偏离大多数其他对象的对象。相比之下，上下文异常检测方法通过将特征划分为上下文特征和行为特征，旨在检测偏离类似对象上下文的其他对象。在本文中，我们建立了依赖于传统的基于依赖的异常检测方法和上下文异常检测方法之间的联系。基于由此获得的见解，我们提出了一种新颖的方法，采用分位数回归森林来模拟特征之间的依赖关系，实现内在的可解释上下文异常检测。各种合成和真实世界数据集上的广泛实验表明，我们的方法在识别上下文异常方面的准确性和可解释性方面优于现有的状态-of-art异常检测方法。

    Traditional anomaly detection methods aim to identify objects that deviate from most other objects by treating all features equally. In contrast, contextual anomaly detection methods aim to detect objects that deviate from other objects within a context of similar objects by dividing the features into contextual features and behavioral features. In this paper, we develop connections between dependency-based traditional anomaly detection methods and contextual anomaly detection methods. Based on resulting insights, we propose a novel approach to inherently interpretable contextual anomaly detection that uses Quantile Regression Forests to model dependencies between features. Extensive experiments on various synthetic and real-world datasets demonstrate that our method outperforms state-of-the-art anomaly detection methods in identifying contextual anomalies in terms of accuracy and interpretability.
    
[^80]: 从图表中解析文本子句的多模态神经几何求解器

    A Multi-Modal Neural Geometric Solver with Textual Clauses Parsed from Diagram. (arXiv:2302.11097v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.11097](http://arxiv.org/abs/2302.11097)

    本论文提出了一种新的神经求解器PGPSNet，通过将图表转化为基本文本子句以有效描述图表特征，并结合结构和语义预训练、数据增强和自我限制解码等技术，PGPSNet拥有丰富的几何定理和几何表示知识，从而在GPS中表现出优越性。

    

    几何问题求解(GPS)是高级数学推理，需要多模态融合和几何知识应用的能力。最近，神经求解器在GPS方面表现出巨大潜力，但仍然在图表表现和模态融合方面存在不足。在这项工作中，我们将图表转化为基本文本子句，以有效描述图表特征，并提出了一种新的神经求解器PGPSNet，以高效地融合多模态信息。结合结构和语义预训练、数据增强和自我限制解码，PGPSNet拥有丰富的几何定理和几何表示知识，从而促进了几何理解和推理。此外，为了促进GPS的研究，我们构建了一个新的大规模精细注释的GPS数据集，名为PGPS9K，标有精细的图表注释和可解释的解决方案程序。在PGPS9K和现有数据集Geometry3K上的实验验证了PGPSNet的优越性。

    Geometry problem solving (GPS) is a high-level mathematical reasoning requiring the capacities of multi-modal fusion and geometric knowledge application. Recently, neural solvers have shown great potential in GPS but still be short in diagram presentation and modal fusion. In this work, we convert diagrams into basic textual clauses to describe diagram features effectively, and propose a new neural solver called PGPSNet to fuse multi-modal information efficiently. Combining structural and semantic pre-training, data augmentation and self-limited decoding, PGPSNet is endowed with rich knowledge of geometry theorems and geometric representation, and therefore promotes geometric understanding and reasoning. In addition, to facilitate the research of GPS, we build a new large-scale and fine-annotated GPS dataset named PGPS9K, labeled with both fine-grained diagram annotation and interpretable solution program. Experiments on PGPS9K and an existing dataset Geometry3K validate the superiorit
    
[^81]: 使用稀疏连接和选择性学习的可扩展实时循环学习

    Scalable Real-Time Recurrent Learning Using Sparse Connections and Selective Learning. (arXiv:2302.05326v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.05326](http://arxiv.org/abs/2302.05326)

    本文提出了两个限制使得实时循环学习算法具有可扩展性，分别是将网络分解为独立模块或逐步学习网络。与其他可扩展算法不同的是，这些算法不会向梯度估计添加噪声或偏差，而是通过权衡网络的功能能力以实现可扩展学习。

    

    从感知观察中构建状态是强化学习代理的重要组成部分。一种用于状态构建的解决方案是使用循环神经网络。 BPTT和实时循环学习（RTRL）是两种流行的基于梯度的循环学习方法。 BPTT在计算梯度之前需要完整的观察序列，不适合在线实时更新。 RTRL可以进行在线更新，但不适用于大型网络。 在本文中，我们提出了两个限制，使RTRL具有可扩展性。我们表明，通过将网络分解为独立模块或逐步学习网络，我们可以使RTRL与参数数量呈线性比例关系。与先前的可扩展梯度估计算法（例如UORO和Truncated-BPTT）不同，我们的算法不会向梯度估计添加噪声或偏差。相反，它们权衡了网络的功能能力以实现可扩展学习。

    State construction from sensory observations is an important component of a reinforcement learning agent. One solution for state construction is to use recurrent neural networks. Back-propagation through time (BPTT), and real-time recurrent learning (RTRL) are two popular gradient-based methods for recurrent learning. BPTT requires the complete sequence of observations before computing gradients and is unsuitable for online real-time updates. RTRL can do online updates but scales poorly to large networks. In this paper, we propose two constraints that make RTRL scalable. We show that by either decomposing the network into independent modules, or learning the network incrementally, we can make RTRL scale linearly with the number of parameters. Unlike prior scalable gradient estimation algorithms, such as UORO and Truncated-BPTT, our algorithms do not add noise or bias to the gradient estimate. Instead, they trade-off the functional capacity of the network to achieve scalable learning. W
    
[^82]: 利用大型语言模型为编程语法错误生成高精度反馈

    Generating High-Precision Feedback for Programming Syntax Errors using Large Language Models. (arXiv:2302.04662v2 [cs.PL] UPDATED)

    [http://arxiv.org/abs/2302.04662](http://arxiv.org/abs/2302.04662)

    本文介绍了使用LLMs生成高精度反馈的技术，可用于固定Python程序中的语法错误。使用PyFiXV生成的反馈准确性高达92％，错误覆盖率高达72％，在编程教育中有潜在的应用价值。

    

    大型语言模型（LLM）比如Codex有望通过自动生成反馈为编程教育提供帮助。本文研究使用LLM为Python程序中的语法错误生成反馈，这是入门编程中的关键场景之一。具体来说，目标是生成包含固定程序和自然语言解释的反馈，以描述错误修复，就像人类导师一样。虽然使用LLM很有前途，但关键挑战在于确保反馈的高精度，这在将此类技术应用于教室之前是至关重要的。我们研究的主要问题是：我们是否可以开发基于LLM的反馈生成技术，具有可调节的精度参数，以便教育工作者控制学生接收到的反馈质量？为此，我们介绍了PyFiXV，我们的技术，它由Codex提供支持，用于生成高精度反馈。

    Large language models (LLMs), such as Codex, hold great promise in enhancing programming education by automatically generating feedback for students. We investigate using LLMs to generate feedback for fixing syntax errors in Python programs, a key scenario in introductory programming. More concretely, given a student's buggy program, our goal is to generate feedback comprising a fixed program along with a natural language explanation describing the errors/fixes, inspired by how a human tutor would give feedback. While using LLMs is promising, the critical challenge is to ensure high precision in the generated feedback, which is imperative before deploying such technology in classrooms. The main research question we study is: Can we develop LLMs-based feedback generation techniques with a tunable precision parameter, giving educators quality control over the feedback that students receive? To this end, we introduce PyFiXV, our technique to generate high-precision feedback powered by Cod
    
[^83]: 基于时间注意机制的中期风电功率预测新框架

    A novel framework for medium-term wind power prediction based on temporal attention mechanisms. (arXiv:2302.01222v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01222](http://arxiv.org/abs/2302.01222)

    本文提出了一种基于树状Parzen估计器（TPE）和分解算法的新框架（TPE-VMD-TFT），用于24小时和48小时之前的风电功率预测。在法国电力公司Engie的风能数据集上，所提出的方法表现良好。

    

    风能是一种广泛分布、可再生和环保的能源，对缓解全球变暖和能源短缺具有重要作用。然而，由于其不确定性和波动性，大规模风电系统的网格集成具有挑战性。中期风电功率预测可以为能量调度提供基本依据，因此精确的风电功率预测至关重要。本文提出了一种基于树状Parzen估计器（TPE）和分解算法的新框架。该框架基于变分模式分解（VMD）和时间融合变压器（TFT）定义了24小时和48小时之前的风电功率预测的TPE-VMD-TFT方法。在法国电力公司Engie的风能数据集上，结果表明所提出的方法优于其他方法。

    Wind energy is a widely distributed, recyclable and environmentally friendly energy source that plays an important role in mitigating global warming and energy shortages. Wind energy's uncertainty and fluctuating nature makes grid integration of large-scale wind energy systems challenging. Medium-term wind power forecasts can provide an essential basis for energy dispatch, so accurate wind power forecasts are essential. Much research has yielded excellent results in recent years. However, many of them require additional experimentation and analysis when applied to other data. In this paper, we propose a novel short-term forecasting framework by tree-structured parzen estimator (TPE) and decomposition algorithms. This framework defines the TPE-VMD-TFT method for 24-h and 48-h ahead wind power forecasting based on variational mode decomposition (VMD) and time fusion transformer (TFT). In the Engie wind dataset from the electricity company in France, the results show that the proposed met
    
[^84]: 基于像素描述符的高分辨率遥感图像异常分割

    Anomaly Segmentation for High-Resolution Remote Sensing Images Based on Pixel Descriptors. (arXiv:2301.13422v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.13422](http://arxiv.org/abs/2301.13422)

    本文提出了一个基于像素描述符的模型，用于解决高分辨率遥感图像中异常模式分割问题。模型通过数据增广生成虚拟异常标本，并使用具有区分性的像素描述符进行深度单类分类。

    

    针对高空间分辨率遥感图像中异常模式的分割问题，本文提出了基于像素描述符的异常分割模型(ASD)。该模型使用具有区分性的像素描述符在特征空间中进行深度单类分类，通过数据增广生成虚拟异常标本，以使得像素描述符紧凑而不会忽略正常数据，并在训练时避免模型崩溃问题。此外，ASD模型还引入了多级和多尺度特征。

    Anomaly segmentation in high spatial resolution (HSR) remote sensing imagery is aimed at segmenting anomaly patterns of the earth deviating from normal patterns, which plays an important role in various Earth vision applications. However, it is a challenging task due to the complex distribution and the irregular shapes of objects, and the lack of abnormal samples. To tackle these problems, an anomaly segmentation model based on pixel descriptors (ASD) is proposed for anomaly segmentation in HSR imagery. Specifically, deep one-class classification is introduced for anomaly segmentation in the feature space with discriminative pixel descriptors. The ASD model incorporates the data argument for generating virtual ab-normal samples, which can force the pixel descriptors to be compact for normal data and meanwhile to be diverse to avoid the model collapse problems when only positive samples participated in the training. In addition, the ASD introduced a multi-level and multi-scale feature e
    
[^85]: 论成员推理攻击的不可靠性

    On the Discredibility of Membership Inference Attacks. (arXiv:2212.02701v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2212.02701](http://arxiv.org/abs/2212.02701)

    成员推理攻击不可靠，应该谨慎使用，因为它们在可以识别到的确切成员样本的子种群上具有高误报率。

    

    随着机器学习模型的广泛应用，研究在敏感数据上训练的模型可能泄漏数据的潜在问题变得至关重要。最近，提出了各种成员推理 (MI) 攻击来确定样本是否属于训练集。问题在于这些攻击是否可靠地应用于实践。我们展示了MI模型经常将附近的非成员样本误分类为成员，并在可以识别到的确切成员样本的子种群上具有高误报率。我们还展示了MI攻击的实际应用，其中这个问题对真实世界产生了影响。在这里，MI攻击被外部审计师（调查员）用来向法官/陪审团展示被审计人非法使用敏感数据。由于MI攻击在成员的子种群上具有高假阳性率，被审计人通过揭示MI攻击的性能来挑战审计师的可信度。我们的结果表明，MI攻击不可靠，应谨慎使用。

    With the wide-spread application of machine learning models, it has become critical to study the potential data leakage of models trained on sensitive data. Recently, various membership inference (MI) attacks are proposed to determine if a sample was part of the training set or not. The question is whether these attacks can be reliably used in practice. We show that MI models frequently misclassify neighboring nonmember samples of a member sample as members. In other words, they have a high false positive rate on the subpopulations of the exact member samples that they can identify. We then showcase a practical application of MI attacks where this issue has a real-world repercussion. Here, MI attacks are used by an external auditor (investigator) to show to a judge/jury that an auditee unlawfully used sensitive data. Due to the high false positive rate of MI attacks on member's subpopulations, auditee challenges the credibility of the auditor by revealing the performance of the MI atta
    
[^86]: 自动化刚性折纸设计

    Automating Rigid Origami Design. (arXiv:2211.13219v2 [cs.GR] UPDATED)

    [http://arxiv.org/abs/2211.13219](http://arxiv.org/abs/2211.13219)

    这篇论文介绍了一种离散优化问题-刚性折纸游戏，该游戏可以扩展刚性折纸的潜力，使其得到针对应用特定的折痕图案，从而可以得到日常物品的新颖、可折叠和实用的设计。

    

    刚性折纸在很多实际应用中展现出了其潜力，然而目前的刚性折纸褶皱图案设计主要依赖于已知的拼贴。这严重限制了可以创建的图案的多样性和新颖性。在这项工作中，我们在最近开发的三单元原则的基础上，将刚性折纸设计成一种离散优化问题，即刚性折纸游戏。我们的实现允许简单定义多样的目标，从而进一步扩展刚性折纸的潜力，得到针对应用特定的折痕图案。我们通过多种搜索方法在几个案例研究中展示了我们公式的灵活性。我们不仅能够构造出近似给定目标形状的各种图案，而且还能够指定基于函数的抽象奖励，从而得到日常物品的新颖、可折叠和实用的设计。

    Rigid origami has shown potential in large diversity of practical applications. However, current rigid origami crease pattern design mostly relies on known tessellations. This strongly limits the diversity and novelty of patterns that can be created. In this work, we build upon the recently developed principle of three units method to formulate rigid origami design as a discrete optimization problem, the rigid origami game. Our implementation allows for a simple definition of diverse objectives and thereby expands the potential of rigid origami further to optimized, application-specific crease patterns. We showcase the flexibility of our formulation through use of a diverse set of search methods in several illustrative case studies. We are not only able to construct various patterns that approximate given target shapes, but to also specify abstract, function-based rewards which result in novel, foldable and functional designs for everyday objects.
    
[^87]: 基于跨模态神经模型重新编程的低资源音乐风格分类

    Low-Resource Music Genre Classification with Cross-Modal Neural Model Reprogramming. (arXiv:2211.01317v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2211.01317](http://arxiv.org/abs/2211.01317)

    本文提出了一种基于神经模型重新编程的迁移学习方法，并针对复杂输入数据提出了输入依赖NMR范式，能够有效地进行音乐风格分类。

    

    迁移学习方法在处理训练数据有限的任务时展现出了很好的效果。然而，微调预训练的神经网络来处理目标领域数据通常需要大量的内存和计算资源。本文提出了一种基于神经模型重新编程 (NMR) 的新方法，用于利用预训练模型进行低资源音乐分类。NMR旨在通过修改冻结的预训练模型的输入，将预训练模型从源域重新调整用于目标域。除了已知的与输入无关的重新编程方法外，我们还提出了一种先进的重新编程范式：输入依赖NMR，以增加对复杂输入数据（如音频）的适应性。实验结果表明，使用这种重新编程方法，基于大规模数据集预训练的神经模型成功地进行音乐风格分类。所提出的两种输入相关的NMR迁移学习方法表现优于传统的迁移学习方法。

    Transfer learning (TL) approaches have shown promising results when handling tasks with limited training data. However, considerable memory and computational resources are often required for fine-tuning pre-trained neural networks with target domain data. In this work, we introduce a novel method for leveraging pre-trained models for low-resource (music) classification based on the concept of Neural Model Reprogramming (NMR). NMR aims at re-purposing a pre-trained model from a source domain to a target domain by modifying the input of a frozen pre-trained model. In addition to the known, input-independent, reprogramming method, we propose an advanced reprogramming paradigm: Input-dependent NMR, to increase adaptability to complex input data such as musical audio. Experimental results suggest that a neural model pre-trained on large-scale datasets can successfully perform music genre classification by using this reprogramming method. The two proposed Input-dependent NMR TL methods outpe
    
[^88]: 自监督模型与多任务学习相结合的发音障碍自动严重程度评估方法

    Automatic Severity Assessment of Dysarthric speech by using Self-supervised Model with Multi-task Learning. (arXiv:2210.15387v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.15387](http://arxiv.org/abs/2210.15387)

    该论文提出了一种使用自监督模型和多任务学习相结合的自动评估发音障碍严重程度的方法，在较少数据的情况下实现了向传统方法的优化，并且相对提高了1.25%的F1-score。

    

    自动评估发音障碍的严重程度对于持续治疗和康复至关重要。然而，获取非典型发音的难度较大，往往会导致数据稀缺问题。为了应对这个问题，我们提出了一种新的自动评估发音障碍严重程度的方法，使用自监督模型与多任务学习相结合。我们联合训练Wav2vec 2.0 XLS-R进行两个不同的任务：严重程度分类和辅助自动语音识别（ASR）。对于基准实验，我们采用手工制作的声学特征和机器学习分类器，如SVM、MLP和XGBoost。在韩国发音障碍QoLT数据库上进行探究，我们的模型优于传统的基准方法，F1-score相对提高1.25%。此外，所提出的模型超过了没有ASR头训练的模型，实现了10.61%的相对百分比提高。此外，我们还展示了多任务学习如何影响障碍严重程度的评估结果。

    Automatic assessment of dysarthric speech is essential for sustained treatments and rehabilitation. However, obtaining atypical speech is challenging, often leading to data scarcity issues. To tackle the problem, we propose a novel automatic severity assessment method for dysarthric speech, using the self-supervised model in conjunction with multi-task learning. Wav2vec 2.0 XLS-R is jointly trained for two different tasks: severity classification and auxiliary automatic speech recognition (ASR). For the baseline experiments, we employ hand-crafted acoustic features and machine learning classifiers such as SVM, MLP, and XGBoost. Explored on the Korean dysarthric speech QoLT database, our model outperforms the traditional baseline methods, with a relative percentage increase of 1.25% for F1-score. In addition, the proposed model surpasses the model trained without ASR head, achieving 10.61% relative percentage improvements. Furthermore, we present how multi-task learning affects the seve
    
[^89]: 在低质量晕的情况下，符号回归和强约束对SZ通量质量（$Y$-$M$）关系的改进：对重子反馈的全面研究

    The SZ flux-mass ($Y$-$M$) relation at low halo masses: improvements with symbolic regression and strong constraints on baryonic feedback. (arXiv:2209.02075v2 [astro-ph.CO] UPDATED)

    [http://arxiv.org/abs/2209.02075](http://arxiv.org/abs/2209.02075)

    本文通过使用液体动力学模拟和机器学习工具对低质量晕的SZ通量质量（$Y$-$M$）关系进行了全面研究，发现通过简单地将$Y \rightarrow Y(1 + M_*/M_\mathrm{gas})$可以使该关系显著自相似，这对于低质量星团和星系群是一种稳健的多波长质量代理。

    

    来自活动星系核和超新星的反馈会影响CMB调查中晕的集成SZ通量（$Y_\mathrm{SZ}$）的测量结果，并导致其与晕质量（$Y_\mathrm{SZ}-M$）的关系偏离维里定理的自相似幂律预测。我们使用具有广泛反馈方案变化的液体动力学模拟套房CAMELS对这种偏离进行了全面研究。我们使用两种机器学习工具（随机森林和符号回归）的组合来搜索$Y-M$关系的类比物，这些类比物对低质量（$M \lesssim 10 ^ {14} \，h ^ {-1} \，M_\odot$）的反馈过程更加稳健。我们发现，在关系中简单地将$Y \rightarrow Y(1 + M_*/M_\mathrm{gas})$可使其显著自相似，这可以用作低质量星团和星系群的稳健多波长质量代理。我们的方法论还可以普遍用于改进其他天体物理的有效范围。

    Feedback from active galactic nuclei (AGN) and supernovae can affect measurements of integrated SZ flux of halos ($Y_\mathrm{SZ}$) from CMB surveys, and cause its relation with the halo mass ($Y_\mathrm{SZ}-M$) to deviate from the self-similar power-law prediction of the virial theorem. We perform a comprehensive study of such deviations using CAMELS, a suite of hydrodynamic simulations with extensive variations in feedback prescriptions. We use a combination of two machine learning tools (random forest and symbolic regression) to search for analogues of the $Y-M$ relation which are more robust to feedback processes for low masses ($M\lesssim 10^{14}\, h^{-1} \, M_\odot$); we find that simply replacing $Y\rightarrow Y(1+M_*/M_\mathrm{gas})$ in the relation makes it remarkably self-similar. This could serve as a robust multiwavelength mass proxy for low-mass clusters and galaxy groups. Our methodology can also be generally useful to improve the domain of validity of other astrophysical 
    
[^90]: Diffsound：离散扩散模型生成文本到音频

    Diffsound: Discrete Diffusion Model for Text-to-sound Generation. (arXiv:2207.09983v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2207.09983](http://arxiv.org/abs/2207.09983)

    本研究提出了一种新的文本到音频生成框架，其中，我们采用了离散扩散解码器来增强生成性能。

    

    人们对于所需声效的生成是一个重要的研究领域，本研究提出一种新的文本到音频生成框架，包括文本编码器，矢量量化变分自编码器(VQ-VAE)，解码器和语音编码器。实验结果表明，在设计解码器方面，传统的自回归解码器预测的实时频谱存在不平滑情况，不适用于该任务，因此我们提出了一种新的离散扩散解码器。

    Generating sound effects that humans want is an important topic. However, there are few studies in this area for sound generation. In this study, we investigate generating sound conditioned on a text prompt and propose a novel text-to-sound generation framework that consists of a text encoder, a Vector Quantized Variational Autoencoder (VQ-VAE), a decoder, and a vocoder. The framework first uses the decoder to transfer the text features extracted from the text encoder to a mel-spectrogram with the help of VQ-VAE, and then the vocoder is used to transform the generated mel-spectrogram into a waveform. We found that the decoder significantly influences the generation performance. Thus, we focus on designing a good decoder in this study. We begin with the traditional autoregressive decoder, which has been proved as a state-of-the-art method in previous sound generation works. However, the AR decoder always predicts the mel-spectrogram tokens one by one in order, which introduces the unidi
    
[^91]: 指示条件句下的确定性和不确定性推理

    Certain and Uncertain Inference with Indicative Conditionals. (arXiv:2207.08276v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2207.08276](http://arxiv.org/abs/2207.08276)

    本文提出了关于指示条件句的三元语义学和概率，构建了两种条件推理逻辑：从确定前提进行推理的逻辑C和从不确定前提进行推理的逻辑U。它们都能用于分析条件推理的有效性，虽然U不遵守假言推理规则。

    

    本文针对自然语言中的指示条件句，提出了三元语义学的真值条件和概率。我们的框架基于W.Cooper最先提出的三元真值条件，提出了两种条件推理逻辑：（i）从确定前提进行推理的逻辑C；（ii）从不确定前提进行推理的逻辑U。然而，C对于条件句是单调的，而U则不是，而且C遵守假言推理规则，U只有在一定限制下才能遵守。我们展示了在这两种框架中进行推理的三元和概率表达之间的系统对应关系，并利用这两个系统的区别，特别是对McGee关于假言推理规则的谜题提出新的解释。结果是一个关于指示条件句的语义和认识论的统一解释，可以有效地应用于分析条件推理的有效性。

    This paper develops a trivalent semantics for the truth conditions and the probability of the natural language indicative conditional. Our framework rests on trivalent truth conditions first proposed by W. Cooper and yields two logics of conditional reasoning: (i) a logic C of inference from certain premises; and (ii) a logic U of inference from uncertain premises. But whereas C is monotonic for the conditional, U is not, and whereas C obeys Modus Ponens, U does not without restrictions. We show systematic correspondences between trivalent and probabilistic representations of inferences in either framework, and we use the distinction between the two systems to cast light, in particular, on McGee's puzzle about Modus Ponens. The result is a unified account of the semantics and epistemology of indicative conditionals that can be fruitfully applied to analyzing the validity of conditional inferences.
    
[^92]: 智能化学习诊断统一可解释性框架在智慧教育中的应用

    A Unified Interpretable Intelligent Learning Diagnosis Framework for Smart Education. (arXiv:2207.03122v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2207.03122](http://arxiv.org/abs/2207.03122)

    本文提出了一种统一的可解释性智能学习诊断框架，结合了深度学习的表示学习能力和基于心理测量的方法的可解释性，使得在智慧教育中能够平衡准确性和可解释性。

    

    智能学习诊断是智能辅导系统的重要引擎，旨在估计学习者当前的知识掌握状况并预测其未来的学习表现。传统的学习诊断方法在诊断准确性和可解释性之间难以平衡。尽管现有的基于心理测量的学习诊断方法通过认知参数提供了一定领域解释，但它们对于大规模学习数据的建模能力不足。而基于深度学习的学习诊断方法虽然提高了学习表现预测的准确性，但其内在的黑盒特性导致缺乏可解释性，使得在教育应用中无法信任其结果。为解决以上问题，本文提出了统一可解释智能学习诊断框架，该框架结合了深度学习的强大表示学习能力和基于心理测量的方法的可解释性。该框架由深度神经网络诊断模块和认知参数解释模块两部分组成，两个模块相互补充，使得框架在准确性和可解释性之间达到平衡。实验结果表明，所提出的框架在准确性和可解释性方面优于现有的学习诊断方法。

    Intelligent learning diagnosis is a critical engine of intelligent tutoring systems, which aims to estimate learners' current knowledge mastery status and predict their future learning performance. The significant challenge with traditional learning diagnosis methods is the inability to balance diagnostic accuracy and interpretability. Although the existing psychometric-based learning diagnosis methods provide some domain interpretation through cognitive parameters, they have insufficient modeling capability with a shallow structure for large-scale learning data. While the deep learning-based learning diagnosis methods have improved the accuracy of learning performance prediction, their inherent black-box properties lead to a lack of interpretability, making their results untrustworthy for educational applications. To settle the above problem, the proposed unified interpretable intelligent learning diagnosis framework, which benefits from the powerful representation learning ability of
    
[^93]: 用Transformer进行偏微分方程算子学习

    Transformer for Partial Differential Equations' Operator Learning. (arXiv:2205.13671v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.13671](http://arxiv.org/abs/2205.13671)

    本文提出一种基于注意力机制的数据驱动算子学习框架OFormer，它可以广泛适用于不同的偏微分方程，并且具有与传统方法相当的准确性，甚至在某些情况下具有更好的表现。

    

    数据驱动的偏微分方程解算子学习近年来已成为一种有前途的范式，用于近似基础解。解算子通常由基于问题特定归纳偏见的深度学习模型参数化。例如，卷积或图神经网络利用了函数值被采样的本地网格结构。另一方面，注意力机制提供了一种灵活的方式来隐式利用输入中的模式，以及任意查询位置和输入之间的关系。在本研究中，我们提出了一种基于注意力的数据驱动算子学习框架，称为Operator Transformer (OFormer)。我们的框架建立在自注意、交叉注意和一组逐点多层感知机(MLP)之上，因此在输入函数或查询位置的采样模式上做出了很少的假设。我们展示了所提出的框架能够广泛适用于不同的偏微分方程，并且具有与先前基于卷积和图神经网络的方法相当的准确性，并且在某些情况下具有更好的表现。

    Data-driven learning of partial differential equations' solution operators has recently emerged as a promising paradigm for approximating the underlying solutions. The solution operators are usually parameterized by deep learning models that are built upon problem-specific inductive biases. An example is a convolutional or a graph neural network that exploits the local grid structure where functions' values are sampled. The attention mechanism, on the other hand, provides a flexible way to implicitly exploit the patterns within inputs, and furthermore, relationship between arbitrary query locations and inputs. In this work, we present an attention-based framework for data-driven operator learning, which we term Operator Transformer (OFormer). Our framework is built upon self-attention, cross-attention, and a set of point-wise multilayer perceptrons (MLPs), and thus it makes few assumptions on the sampling pattern of the input function or query locations. We show that the proposed frame
    
[^94]: CLNet：用于大规模MIMO CSI反馈的复杂输入轻量神经网络

    CLNet: Complex Input Lightweight Neural Network designed for Massive MIMO CSI Feedback. (arXiv:2102.07507v3 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2102.07507](http://arxiv.org/abs/2102.07507)

    本文提出了一种名为CLNet的神经网络，可以在大规模MIMO CSI反馈中提高准确性，减少计算开销，同时遵循CSI的内在属性。在室内外场景中，CLNet平均准确度提高了5.41％，计算开销减少了24.1％。

    

    最近，通过减少CSI反馈的开销来发挥大规模MIMO在FDD模式下的全部潜力已经引起了人们的关注。许多用于大规模MIMO CSI反馈的深度学习方法已经展示了它们的效率和潜力。然而，大多数现有方法提高了准确性，但计算复杂度也随之增加，而且随着CSI压缩率的增加，准确性显著降低。本文提出了一种新颖的神经网络CLNet，针对CSI反馈问题，基于CSI的内在属性，CLNet提出了一个锻造的复杂值输入层来处理信号，并利用注意机制来提高网络的性能。实验结果显示，CLNet在室内外场景中的平均准确度提高了5.41％，计算开销平均减少了24.1％，优于目前的最新方法。深度学习CSI反馈CLNet的代码可在GitHub上获得。

    Unleashing the full potential of massive MIMO in FDD mode by reducing the overhead of CSI feedback has recently garnered attention. Numerous deep learning for massive MIMO CSI feedback approaches have demonstrated their efficiency and potential. However, most existing methods improve accuracy at the cost of computational complexity and the accuracy decreases significantly as the CSI compression rate increases. This paper presents a novel neural network CLNet tailored for CSI feedback problem based on the intrinsic properties of CSI. CLNet proposes a forge complex-valued input layer to process signals and utilizes attention mechanism to enhance the performance of the network. The experiment result shows that CLNet outperforms the state-of-the-art method by average accuracy improvement of 5.41\% in both outdoor and indoor scenarios with average 24.1\% less computational overhead. Codes for deep learning-based CSI feedback CLNet are available at GitHub.
    
[^95]: 大规模神经网络学习为什么行为类似于凸优化

    Why Learning of Large-Scale Neural Networks Behaves Like Convex Optimization. (arXiv:1903.02140v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1903.02140](http://arxiv.org/abs/1903.02140)

    本文介绍了利用规范空间证明学习大规模神经网络的目标函数在收敛到全局最小值时是凸优化问题。使用点线性转换的方法建立原始NN模型空间和规范空间之间的关系，证明了使用梯度下降方法，只要差异矩阵保持完整秩，就一定能收敛到零损失的全局最小值。大规模NN具有奇异的差异矩阵的概率非常小。

    

    本文提出了一些理论工作，以解释为什么简单的梯度下降方法在解决学习大规模神经网络的非凸优化问题中如此成功。在介绍了一种称为规范空间的数学工具之后，我们证明了规范模型空间中的学习NN目标函数是凸的。我们进一步阐明了原始NN模型空间和规范空间之间的梯度之间的关系是通过所谓的差异矩阵表示的逐点线性变换相关的。此外，我们已经证明，如果差异矩阵保持完整秩，梯度下降方法一定会收敛到零损失的全局最小值。如果这个完整秩条件成立，在NN的学习中的行为与正常的凸优化相同。最后，我们证明，大规模NN具有奇异的差异矩阵的概率非常小。特别是，当超参数化的NN是...

    In this paper, we present some theoretical work to explain why simple gradient descent methods are so successful in solving non-convex optimization problems in learning large-scale neural networks (NN). After introducing a mathematical tool called canonical space, we have proved that the objective functions in learning NNs are convex in the canonical model space. We further elucidate that the gradients between the original NN model space and the canonical space are related by a pointwise linear transformation, which is represented by the so-called disparity matrix. Furthermore, we have proved that gradient descent methods surely converge to a global minimum of zero loss provided that the disparity matrices maintain full rank. If this full-rank condition holds, the learning of NNs behaves in the same way as normal convex optimization. At last, we have shown that the chance to have singular disparity matrices is extremely slim in large NNs. In particular, when over-parameterized NNs are 
    
[^96]: Jiminy顾问：基于规范和论证的利益相关者道德协议

    The Jiminy Advisor: Moral Agreements Among Stakeholders Based on Norms and Argumentation. (arXiv:1812.04741v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/1812.04741](http://arxiv.org/abs/1812.04741)

    本文提出了一个名为Jiminy的伦理建议组件，它使用规范系统和形式论证技术，以在利益相关者之间达成道德协议。 Jiminy通过利用规范系统代表每个利益相关者的伦理观点，并通过论证来解决涉及利益相关者意见的道德困境。

    

    一个由制造商构建的自主系统，在受制于规范和法律的社会中运作，并与最终用户互动。所有这些参与者都是受到自主系统行为影响的利益相关者。我们解决了如何将这些利益相关者的伦理观点集成到自主系统行为中的挑战。我们提出了一个名为Jiminy的伦理建议组件，它使用规范系统和形式论证技术，以在利益相关者之间达成道德协议。Jiminy通过使用规范系统来代表每个利益相关者的伦理观点，并具有三种解决涉及利益相关者意见的道德困境的方法。首先，Jiminy考虑利益相关者的论证如何关联彼此，这可能已经解决了道德困境。其次，Jiminy将利益相关者的规范系统合并，以便利益相关者的合并专业知识可以解决道德困境。第三，并且最重要的是，Jiminy可以让利益相关者进行论证，以解决道德困境。我们在一个自主车辆的案例研究中展示了Jiminy，并演示了如何将利益相关者的伦理观点集成到自主系统的行为中。

    An autonomous system is constructed by a manufacturer, operates in a society subject to norms and laws, and interacts with end users. All of these actors are stakeholders affected by the behavior of the autonomous system. We address the challenge of how the ethical views of such stakeholders can be integrated in the behavior of an autonomous system. We propose an ethical recommendation component called Jiminy which uses techniques from normative systems and formal argumentation to reach moral agreements among stakeholders. A Jiminy represents the ethical views of each stakeholder by using normative systems, and has three ways of resolving moral dilemmas that involve the opinions of the stakeholders. First, the Jiminy considers how the arguments of the stakeholders relate to one another, which may already resolve the dilemma. Secondly, the Jiminy combines the normative systems of the stakeholders such that the combined expertise of the stakeholders may resolve the dilemma. Thirdly, and 
    

