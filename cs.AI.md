# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Learning Disentangled Avatars with Hybrid 3D Representations.](http://arxiv.org/abs/2309.06441) | 本文提出了一种名为DELTA的方法，使用混合的显式-隐式3D表示对人体进行解耦合建模。通过将人体或面部表示为分开的层，DELTA能够实现人体和服装/头发的解耦。这种方法在学习可动画和逼真的人体角色方面具有潜力。 |
| [^2] | [LEAP Hand: Low-Cost, Efficient, and Anthropomorphic Hand for Robot Learning.](http://arxiv.org/abs/2309.06440) | LEAP Hand是一种低成本、高效且拟人化的机器学习手。其新颖的运动结构可以实现最大的灵活性，其成本为其他竞争对手的1/8。LEAP Hand在现实世界中执行多个操作任务，并在所有实验中表现出色。 |
| [^3] | [Unveiling the potential of large language models in generating semantic and cross-language clones.](http://arxiv.org/abs/2309.06424) | 本研究利用GPT-3模型在语义和跨语言克隆生成方面的潜力，通过评估、分析和验证，揭示了其在生成给定代码片段的语义和跨语言克隆变体方面的表现。 |
| [^4] | [Verifiable Reinforcement Learning Systems via Compositionality.](http://arxiv.org/abs/2309.06420) | 本研究提出了一个可验证和组合的强化学习框架，通过将多个强化学习子系统组合起来实现整体任务。通过定义子系统之间的接口，实现了任务规范的自动分解，并允许子系统的独立训练和测试。 |
| [^5] | [A Fast Algorithm for Moderating Critical Nodes via Edge Removal.](http://arxiv.org/abs/2309.06392) | 本文研究了一种快速算法，通过删除网络边缘来调节关键节点。通过使用新颖的技术，我们提出了三种近似贪婪算法，以最小化目标节点的信息中心度，同时保持网络连通性。 |
| [^6] | [Towards Reliable and Fluent Large Language Models: Incorporating Feedback Learning Loops in QA Systems.](http://arxiv.org/abs/2309.06384) | 本研究通过构建评论模型和引入反馈学习循环，解决了大型语言模型在问答系统中引用错误、生成虚构信息和缺少关键细节的问题。 |
| [^7] | [Ensemble Mask Networks.](http://arxiv.org/abs/2309.06382) | 本研究引入了两种机制，灵活的掩模和独特的网络剪枝，使得一个前馈网络能够学习矩阵向量乘法，并且在图形模型中可以用来测试依赖关系或交互顺序。 |
| [^8] | [Style2Fab: Functionality-Aware Segmentation for Fabricating Personalized 3D Models with Generative AI.](http://arxiv.org/abs/2309.06379) | 通过使用生成AI进行功能感知分割，在制造3D模型时保留了功能的同时，允许用户有选择性地修改模型的审美部分。 |
| [^9] | [Modeling Recommender Ecosystems: Research Challenges at the Intersection of Mechanism Design, Reinforcement Learning and Generative Models.](http://arxiv.org/abs/2309.06375) | 建模推荐系统生态系统需要考虑参与者激励、行为以及策略引发的相互作用，通过强化学习进行长期优化，使用社会选择方法进行权衡，并减少信息不对称。 |
| [^10] | [Chebyshev Particles.](http://arxiv.org/abs/2309.06373) | 本文提出了一种基于Chebyshev粒子的顺序MCMC采样器，通过最大化加权Riesz极化量，在无穷维欧几里得空间中离散化可矩形子流形，从而有效解决了隐马尔可夫模型推断中的维数灾难问题。 |
| [^11] | [Framework-Based Qualitative Analysis of Free Responses of Large Language Models: Algorithmic Fidelity.](http://arxiv.org/abs/2309.06364) | 本文通过定性分析研究了大型语言模型生成的自由回答，重点考察了算法保真度，并提出高算法保真度可以推广到真实人类的观点。这对于使用语言模型研究人类行为具有重要意义。 |
| [^12] | [Generative Data Augmentation using LLMs improves Distributional Robustness in Question Answering.](http://arxiv.org/abs/2309.06358) | 本论文研究了使用生成式数据增强方法如何提高问答模型在自然分布转换下的鲁棒性，通过实验展示了增强阅读理解数据集的效果。 |
| [^13] | [Grounded Language Acquisition From Object and Action Imagery.](http://arxiv.org/abs/2309.06335) | 本文研究了通过训练新兴语言编码器/解码器来发展基于实践的视觉数据表述的私人语言。使用神经机器翻译和随机森林分类转换符号表示到类别标签，并应用于物体识别和动作识别实验。 |
| [^14] | [Learning Minimalistic Tsetlin Machine Clauses with Markov Boundary-Guided Pruning.](http://arxiv.org/abs/2309.06315) | 本论文提出了一种新的Tsetlin机器（TM）反馈方案，通过引入马尔科夫边界来学习最简化的Tsetlin机器子句，以提供最佳的特征集。 |
| [^15] | [AI4Food-NutritionFW: A Novel Framework for the Automatic Synthesis and Analysis of Eating Behaviours.](http://arxiv.org/abs/2309.06308) | AI4Food-NutritionFW是一个新型框架，利用图像处理和人工智能技术，可以分析个体的健康情况以及根据可配置的饮食行为提供个性化建议，是研究饮食行为和改善营养的有力工具。 |
| [^16] | [Transferability analysis of data-driven additive manufacturing knowledge: a case study between powder bed fusion and directed energy deposition.](http://arxiv.org/abs/2309.06286) | 本论文提出了一种三步知识迁移性分析框架来支持数据驱动的增材制造知识的迁移。研究发现，通过利用各种增材制造技术之间的相似性和应用迁移学习的方法，可以将现有的解决方案从一个工艺或问题转移到另一个工艺或问题中。 |
| [^17] | [Jersey Number Recognition using Keyframe Identification from Low-Resolution Broadcast Videos.](http://arxiv.org/abs/2309.06285) | 本研究提出了一种在低分辨率广播视频中识别球衣号码的方法，通过关键帧识别提取包含球衣号码的关键信息，并结合时空网络预测球衣号码的概率。 |
| [^18] | [Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation.](http://arxiv.org/abs/2309.06255) | 本文提出了一种精细的模态评估指标，用于评估每个模态在样本级别的贡献，并发现多模态模型倾向于依赖一个特定的模态，导致其他模态的贡献较低。 |
| [^19] | [On the Injunction of XAIxArt.](http://arxiv.org/abs/2309.06227) | 这篇论文讨论了解释性人工智能在艺术中的禁令（XAIxArt）引发的一系列问题，并指出XAIxArt旨在解决人类中心的艺术观念的不安和对过时的作者概念的怀旧愿望。 |
| [^20] | [Unveiling Signle-Bit-Flip Attacks on DNN Executables.](http://arxiv.org/abs/2309.06223) | 针对由深度学习编译器编译的DNN可执行文件的单位翻转攻击进行了系统研究，设计了自动搜索工具以识别易受攻击的位，并确定了实际攻击向量，揭示了DNN可执行文件的攻击面。 |
| [^21] | [SCP: Scene Completion Pre-training for 3D Object Detection.](http://arxiv.org/abs/2309.06199) | SCP提出了一种场景完整性预训练方法，以增强3D目标检测器的性能，包括改善点云模型的初始化、消除对额外数据集的需求和减少标记数据量。 |
| [^22] | [360$^\circ$ from a Single Camera: A Few-Shot Approach for LiDAR Segmentation.](http://arxiv.org/abs/2309.06197) | 本论文提出了一种用于LiDAR分割的少样本方法，通过使用图像教师网络在单个摄像机视角下生成语义预测，实现了标度高效的LiDAR分割。 |
| [^23] | [A 3M-Hybrid Model for the Restoration of Unique Giant Murals: A Case Study on the Murals of Yongle Palace.](http://arxiv.org/abs/2309.06194) | 这项研究提出了一个3M混合模型来恢复永乐宫独特巨幅壁画，解决了传统修复方法中的领域偏差和数据稀缺性的问题，同时也能应对壁画巨大尺寸带来的更广泛缺陷类型和尺寸范围的挑战。 |
| [^24] | [Glancing Future for Simultaneous Machine Translation.](http://arxiv.org/abs/2309.06179) | 本文提出了一种新的方法，在同时机器翻译中通过课程学习的逐步减少可用源信息，从整个句子到与延迟对应的前缀，以实现从序列到序列训练到前缀到前缀训练的过渡，从而增强SiMT模型的翻译能力。 |
| [^25] | [Robust-MBDL: A Robust Multi-branch Deep Learning Based Model for Remaining Useful Life Prediction and Operational Condition Identification of Rotating Machines.](http://arxiv.org/abs/2309.06157) | 本文提出了一种稳健的多支路深度学习模型，用于旋转机器的剩余寿命预测和运行状态识别。该模型包括LSTM-Autoencoder对振动数据进行去噪、特征提取和多支路深度学习网络结构等组件，并在实验中证明了它在轴承机器应用中的优越性和潜力。 |
| [^26] | [Measuring vagueness and subjectivity in texts: from symbolic to neural VAGO.](http://arxiv.org/abs/2309.06132) | 本文提出了一种混合方法来自动测量文本中的模糊性和主观性。通过引入专家系统VAGO，以及基于BERT-like架构的神经克隆，该方法在固定语料库和多语言生成方面表现出良好的性能。 |
| [^27] | [JOADAA: joint online action detection and action anticipation.](http://arxiv.org/abs/2309.06130) | JOADAA模型将动作预测和在线动作检测两个任务融合到一个统一的架构中，可以解决推断动作依赖关系的挑战，提高性能。 |
| [^28] | [LEyes: A Lightweight Framework for Deep Learning-Based Eye Tracking using Synthetic Eye Images.](http://arxiv.org/abs/2309.06129) | 本研究提出了一种名为LEyes的轻量级深度学习眼动跟踪框架，利用合成眼部图像进行训练，解决了由于训练数据集不足和眼部图像变异导致的模型泛化问题。实验结果表明，LEyes训练的模型在瞳孔和CR定位方面优于其他算法。 |
| [^29] | [Fidelity-Induced Interpretable Policy Extraction for Reinforcement Learning.](http://arxiv.org/abs/2309.06097) | 本文提出了一种基于保真度诱导的策略提取方法（FIPE）来解决深度强化学习代理不透明的决策问题。实验证明，该方法在星际争霸 II 这样的复杂控制环境下具有良好的性能。 |
| [^30] | [A Machine Learning Framework to Deconstruct the Primary Drivers for Electricity Market Price Events.](http://arxiv.org/abs/2309.06082) | 该论文提出了一个基于机器学习的分析框架，用于解析现代高可再生能源电力市场中价格飙升事件的主要驱动因素。 |
| [^31] | [BatMan-CLR: Making Few-shots Meta-Learners Resilient Against Label Noise.](http://arxiv.org/abs/2309.06046) | 本研究对少样本元学习器受标签噪声影响的性能进行了全面分析，发现在受到标签噪声影响的元训练中，Reptile、iMAML和foMAML在Omniglot和CifarFS数据集上的准确性下降了最高达42%。为了增强对标签噪声的鲁棒性，提出了Man和BatMan两种采样技术，将有噪声的有监督学习器转变为半监督学习器。 |
| [^32] | [Update Monte Carlo tree search (UMCTS) algorithm for heuristic global search of sizing optimization problems for truss structures.](http://arxiv.org/abs/2309.06045) | 本文提出了一种基于启发式全局搜索的算法（UMCTS）用于桁架结构尺寸优化问题，通过结合更新过程和蒙特卡洛树搜索（MCTS）以及使用上界置信度（UCB）来获得合适的设计方案。 |
| [^33] | [Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping.](http://arxiv.org/abs/2309.06038) | 本文提出了一个名为“人类助力灵巧抓取”的新型任务，通过使用Grasping Gradient Field和基于历史条件的残差策略，训练控制机器人手指以适应不同用户意图和物体几何形状的灵巧抓取操作。 |
| [^34] | [Automatically Estimating the Effort Required to Repay Self-Admitted Technical Debt.](http://arxiv.org/abs/2309.06020) | 本研究提出了一种新的方法，利用大规模的数据集自动估算自认技术债务的还款工作量。研究结果表明，不同类型的自认技术债务需要不同程度的还款工作量。 |
| [^35] | [DSLOT-NN: Digit-Serial Left-to-Right Neural Network Accelerator.](http://arxiv.org/abs/2309.06019) | DSLOT-NN是一种数字串行从左到右的神经网络加速器，可以加速深度神经网络中的卷积运算，并且通过评估和终止无效的卷积操作实现功耗和能量的大规模节省。 |
| [^36] | [SoccerNet 2023 Challenges Results.](http://arxiv.org/abs/2309.06006) | SoccerNet 2023挑战是一次视频理解的比赛，包含广播视频理解、场地理解和球员理解三个主题下的多个任务。 |
| [^37] | [Life-inspired Interoceptive Artificial Intelligence for Autonomous and Adaptive Agents.](http://arxiv.org/abs/2309.05999) | 该论文提出了一种基于生命理论和控制论的新视角，通过将控制论、强化学习和神经科学的最新进展与生命理论相结合，将内感知应用于构建具有自主和适应性能力的人工智能代理。 |
| [^38] | [Knowledge-Guided Short-Context Action Anticipation in Human-Centric Videos.](http://arxiv.org/abs/2309.05943) | 该论文提出了一种基于知识引导的短上下文行动预测方法，在人类中心的视频中，通过使用短视频片段来预测长期的人类行动，提高了编辑工作流程的速度和创作性，通过增强变换器网络的注意机制，在行动预测方面取得了优于当前最先进方法9%的性能。 |
| [^39] | [Answering Subjective Induction Questions on Products by Summarizing Multi-sources Multi-viewpoints Knowledge.](http://arxiv.org/abs/2309.05938) | 本文提出了一个新任务：回答产品的主观归纳问题（SUBJPQA）。与传统的QA任务不同，这类问题的答案是非唯一的，并且需要从多个角度总结多个知识源的主观意见和客观知识来解释。为了解决这个任务，我们提出了一个三步骤的方法，包括信息检索、相关性捕捉和摘要生成。 |
| [^40] | [MatSciML: A Broad, Multi-Task Benchmark for Solid-State Materials Modeling.](http://arxiv.org/abs/2309.05934) | MatSciML是一个用于固态材料建模的多任务基准，通过提供多样化的材料系统和属性数据，解决了该领域中方法性能比较困难的问题。 |
| [^41] | [Combining deep learning and street view imagery to map smallholder crop types.](http://arxiv.org/abs/2309.05930) | 本研究利用深度学习和街景图像开发了一个自动化系统，可以生成农作物类型地面参考，解决了在低收入和中等收入国家创建农作物类型地图时的挑战。 |
| [^42] | [Frequency-Aware Masked Autoencoders for Multimodal Pretraining on Biosignals.](http://arxiv.org/abs/2309.05927) | 本研究提出了一种名为$\texttt{bio}$FAME的频率感知掩码自编码器，用于多模态生物信号的预训练。其通过在频率空间中对生物信号进行表示参数化，利用固定大小的傅里叶变换运算符进行全局令牌混合，并通过频率维持预训练策略保持每个输入通道中的频率成分。 |
| [^43] | [On Regularized Sparse Logistic Regression.](http://arxiv.org/abs/2309.05925) | 本文提出了解决正则稀疏逻辑回归的方法，包括$\ell_1$正则化稀疏逻辑回归和一些满足先决条件的非凸惩罚正则化稀疏逻辑回归。经验实验表明，这些算法能够以较低的计算成本有效地进行分类和特征选择。 |
| [^44] | [A Survey of Hallucination in Large Foundation Models.](http://arxiv.org/abs/2309.05922) | 本文调查了大型基础模型中的幻觉问题，包括幻觉现象的分类、评估标准和减轻幻觉的策略，并讨论了未来研究方向。 |
| [^45] | [SAGE: Structured Attribute Value Generation for Billion-Scale Product Catalogs.](http://arxiv.org/abs/2309.05920) | SAGE是一个用于在十亿级产品目录中生成属性值的模型，可以处理跨语言、产品类型和目标属性的问题。它采用了一种新颖的建模方法，可以推断隐式使用迂回语言提到的属性值，并且能够预测属性的不适用性和无法从可用信息中获取属性值。 |
| [^46] | [Stochastic LLMs do not Understand Language: Towards Symbolic, Explainable and Ontologically Based LLMs.](http://arxiv.org/abs/2309.05918) | 随机LLMs无法理解语言的原因是它们无法提供可以依赖的事实信息，它们存储的语言知识埋藏在无意义的微特征中，并在某些语言上下文中无法进行正确推理。本文建议在符号化方法中应用有效的自下而上策略 |
| [^47] | [ACT: Empowering Decision Transformer with Dynamic Programming via Advantage Conditioning.](http://arxiv.org/abs/2309.05915) | 这篇论文提出了一种通过将动态规划应用于决策Transformer来增强其能力的方法。作者提出了三个步骤来实现这一目标：使用样本内值迭代获得近似值函数，结合估计的优势评估动作质量，并训练ACT生成基于估计优势的动作。该方法在测试中表现出良好的性能。 |
| [^48] | [Quality-Agnostic Deepfake Detection with Intra-model Collaborative Learning.](http://arxiv.org/abs/2309.05911) | 本论文提出了一种无关质量的深度伪造检测方法(QAD)，通过模型内协作学习方法实现了同时检测不同质量的深度伪造。是一种具有实际应用可行性和可扩展性的方法。 |
| [^49] | [Strategic Behavior of Large Language Models: Game Structure vs. Contextual Framing.](http://arxiv.org/abs/2309.05898) | 本文研究了三种大规模语言模型在博弈论框架下的战略决策能力，并发现GPT-3.5对情境框架敏感但抽象战略推理能力有限，而GPT-4和LLaMa-2在游戏结构和情境下能调整策略，但LLaMa-2在游戏机制的理解上更加微妙。 |
| [^50] | [The bionic neural network for external simulation of human locomotor system.](http://arxiv.org/abs/2309.05863) | 本文提出了一种基于肌肉骨骼模拟和物理信息深度学习的方法，用于预测关节运动和肌肉力量。 |
| [^51] | [Uncovering mesa-optimization algorithms in Transformers.](http://arxiv.org/abs/2309.05858) | 本研究揭示了Transformer模型中的mesa-optimization算法，该算法通过内部学习目标和相应的优化解决方案驱动预测生成。研究还发现，这种学习的优化算法可以被应用于解决监督式少样本任务，暗示了mesa-optimization可能是大型语言模型上下文学习能力的基础。 |
| [^52] | [Effective Abnormal Activity Detection on Multivariate Time Series Healthcare Data.](http://arxiv.org/abs/2309.05845) | 在多元时间序列医疗数据上，我们提出了一种基于残差的异常检测方法，用于有效的表示学习和异常活动检测。实验结果显示F1分数为0.839。 |
| [^53] | [PACE: Prompting and Augmentation for Calibrated Confidence Estimation with GPT-4 in Cloud Incident Root Cause Analysis.](http://arxiv.org/abs/2309.05833) | 本文提出了一种通过提示检索增强的大语言模型（LLM）来增强云事件根本原因分析工具中置信度估计的方法。 |
| [^54] | [Studying Accuracy of Machine Learning Models Trained on Lab Lifting Data in Solving Real-World Problems Using Wearable Sensors for Workplace Safety.](http://arxiv.org/abs/2309.05831) | 本文研究了将实验室训练的机器学习模型应用于真实世界时的准确性问题，并提出了四种潜在解决方案。 |
| [^55] | [Exploring Geometric Deep Learning For Precipitation Nowcasting.](http://arxiv.org/abs/2309.05828) | 本论文探索了几何深度学习在降水预测中的应用，采用了基于时间的图卷积网络（GCN）模型，该模型能够更好地捕捉地理网格之间的动态空间关系。 |
| [^56] | [PhotoVerse: Tuning-Free Image Customization with Text-to-Image Diffusion Models.](http://arxiv.org/abs/2309.05793) | PhotoVerse是一种无需调参的文本到图像定制化模型，通过双分支调节机制和面部身份损失增强了图像生成过程中的控制能力和身份保留能力，并且仅依赖目标身份的一张面部照片来显著降低图像生成的资源成本。 |
| [^57] | [Adaptive User-centered Neuro-symbolic Learning for Multimodal Interaction with Autonomous Systems.](http://arxiv.org/abs/2309.05787) | 这篇论文提出了一种自适应用户中心的神经符号学习方法，用于支持多模态交互中自主系统对物体和环境的符号化理解能力的提升。 |
| [^58] | [Grey-box Bayesian Optimization for Sensor Placement in Assisted Living Environments.](http://arxiv.org/abs/2309.05784) | 本研究提出了一种基于灰盒贝叶斯优化和仿真评估的方法，通过捕捉关于活动的空间分布的领域特定知识，找到高质量的传感器布置，并在跌倒检测、室内定位和活动识别等领域取得了优于黑盒优化技术的性能。 |
| [^59] | [Large Language Model for Science: A Study on P vs. NP.](http://arxiv.org/abs/2309.05689) | 本研究使用大型语言模型加强和加速对P vs. NP问题的研究，提出了基于苏格拉底推理的通用框架，通过与语言模型进行深入思考解决复杂问题。在P vs. NP问题的实证研究中，GPT-4成功产生了证明架构，并进行了严格的推理，得出了"P ≠ NP"的结论，揭示了语言模型在科学研究中的潜力。 |
| [^60] | [EANet: Expert Attention Network for Online Trajectory Prediction.](http://arxiv.org/abs/2309.05683) | 本论文提出了一个专家注意力网络用于在线轨迹预测的在线学习框架。通过引入专家注意力机制，调整网络层的权重，解决了梯度问题，能够快速学习新场景的知识以提高预测准确度。 |
| [^61] | [A compendium of data sources for data science, machine learning, and artificial intelligence.](http://arxiv.org/abs/2309.05682) | 这篇论文提供了一个跨多个领域的数据源大全，包括金融、法律、生命科学、新闻社交等，以满足数据科学家和机器学习专家的需求。 |
| [^62] | [Knowledge-based Refinement of Scientific Publication Knowledge Graphs.](http://arxiv.org/abs/2309.05681) | 本论文提出了一种基于知识的方法来细化科学出版物知识图谱，通过学习概率逻辑模型并使用功能梯度提升和人类知识引导来识别作者身份。实验证明了人类知识在作者身份领域的定量和定性作用。 |
| [^63] | [Evaluating Chatbots to Promote Users' Trust -- Practices and Open Problems.](http://arxiv.org/abs/2309.05680) | 本文评估了当前聊天机器人测试的实践和开放问题，旨在解决和减轻与用户信任相关的服务或产品性能、用户满意度以及对社会的长期意外后果问题。 |
| [^64] | [Good-looking but Lacking Faithfulness: Understanding Local Explanation Methods through Trend-based Testing.](http://arxiv.org/abs/2309.05679) | 本文通过基于趋势的测试方法评估了解释模型决策的忠诚度，并提出了三种新的趋势测试方法，从实证结果来看，这些新测试方法在图像、自然语言和安全任务中可以更好地评估解释模型的忠诚度。 |
| [^65] | [SHAPE: A Sample-adaptive Hierarchical Prediction Network for Medication Recommendation.](http://arxiv.org/abs/2309.05675) | 本文提出了一种名为SHAPE的适应样本的层次药物预测网络，旨在解决医疗保健中复杂多发病条件下的药物推荐问题。通过设计紧凑的内部病患就诊事件关系编码器和纵向病历编码器，我们能够获得准确的病患表示和纵向序列学习策略。 |
| [^66] | [tSPM+; a high-performance algorithm for mining transitive sequential patterns from clinical data.](http://arxiv.org/abs/2309.05671) | tSPM+算法是一种高性能算法，通过在时间模式中加入持续时间维度，提供了高速运行和内存消耗改进。 |
| [^67] | [Studying the impacts of pre-training using ChatGPT-generated text on downstream tasks.](http://arxiv.org/abs/2309.05668) | 本研究调查了在语言模型的预训练阶段中使用ChatGPT生成文本的人造文本的影响，通过比较分析了使用CNN/DailyMail新闻文章预训练的RoBERTa和使用相同文章预训练的ChatGPT的性能。 |
| [^68] | [Robot Parkour Learning.](http://arxiv.org/abs/2309.05665) | 该论文提出了一个学习基于视觉的多样化公园our技能的系统，该系统使用简单的奖励而不使用参考动作数据，通过强化学习方法生成不同的公园our技能，并将其转移到四足机器人中。 |
| [^69] | [An Empirical Study of NetOps Capability of Pre-Trained Large Language Models.](http://arxiv.org/abs/2309.05557) | 本文通过对预训练大型语言模型（LLMs）进行系统评估，发现LLMs在网络运维（NetOps）领域具有强大的潜力应用，能够提升自动化和智能化的NetOps能力。 |
| [^70] | [Machine Learning for maximizing the memristivity of single and coupled quantum memristors.](http://arxiv.org/abs/2309.05062) | 本文使用机器学习方法来研究单个和耦合量子忆阻器的记忆阻性，并发现最大化记忆阻性可以提高两个量子忆阻器的纠缠程度，揭示了量子相关性与记忆之间的关系。这一发现增强了将量子忆阻器应用于神经形态的量子计算的潜力。 |
| [^71] | [Multi-document Summarization: A Comparative Evaluation.](http://arxiv.org/abs/2309.04951) | 本文评估了多文档摘要领域的最新模型在不同领域和数据集上的表现，发现通用预训练模型LED在MS$^2$数据集上的性能优于其他模型，为未来的MDS研究提供了宝贵的参考和发展方向。 |
| [^72] | [MFPNet: Multi-scale Feature Propagation Nwtwork For Lightweight Semantic Segmentation.](http://arxiv.org/abs/2309.04914) | MFPNet是一个轻量级分割架构，利用特殊的残差块和图卷积网络实现了多尺度特征传播，获得了优越的分割结果。 |
| [^73] | [TMComposites: Plug-and-Play Collaboration Between Specialized Tsetlin Machines.](http://arxiv.org/abs/2309.04801) | TMComposites是一种插拔式协作方式，通过特化和评估成员的能力，使得Tsetlin机器（TM）可以在较复杂的图像分类任务中表现出更强的性能。 |
| [^74] | [FIAT: Fusing learning paradigms with Instruction-Accelerated Tuning.](http://arxiv.org/abs/2309.04663) | FIAT是一种将上下文学习和完全微调范式融合的新的学习方式，可以在最大模型上进行指令和推理，并且在较小模型上进行参数更新，经过多语言任务测试，比之前的方法都表现更好。 |
| [^75] | [Physics-Informed Neural Networks for an optimal counterdiabatic quantum computation.](http://arxiv.org/abs/2309.04434) | 本研究提出了一种利用物理信息神经网络（PINNs）解决量子电路反对角（CD）协议优化问题的方法，通过嵌入物理信息到神经网络中，并利用最小作用量原理和厄米特性条件来获取最适当的反对角项，从而提供了一种可靠的替代方案，摆脱了以往依赖于经典数值逼近的约束。 |
| [^76] | [Navigating Out-of-Distribution Electricity Load Forecasting during COVID-19: A Continual Learning Approach Leveraging Human Mobility.](http://arxiv.org/abs/2309.04296) | 本研究提出了一种利用人类移动数据和持续学习技术的方法来解决COVID-19期间非分布期间的电力负荷预测问题，通过保留过去的见解并整合新的数据，提高了模型的准确性和鲁棒性。 |
| [^77] | [UQ at #SMM4H 2023: ALEX for Public Health Analysis with Social Media.](http://arxiv.org/abs/2309.04213) | 本文提出了一种名为ALEX的框架，通过采用LLMs解释机制来改进社交媒体上的公共卫生分析性能。该方法通过数据增强和平衡训练解决了数据不平衡问题，并有效利用了LLMs的能力。 |
| [^78] | [GPT Can Solve Mathematical Problems Without a Calculator.](http://arxiv.org/abs/2309.03241) | 本研究表明，通过充分训练，一个20亿参数的语言模型可以在没有计算器工具的情况下以几乎100%的准确度执行多位数的算术运算，超越了之前的GPT-4。这项研究还通过在附加的多步骤算术运算和数学问题的数据集上进行微调，展示了一个与GPT-4在中文数学问题上相似的性能。 |
| [^79] | [Spatio-Temporal Contrastive Self-Supervised Learning for POI-level Crowd Flow Inference.](http://arxiv.org/abs/2309.03239) | 本文提出了一种针对POI级别人群流推断的时空对比自监督学习模型，通过自监督属性图表示学习以解决数据标记不足、POI间时空依赖性复杂和人群流量与GPS报告之间相关性多样等挑战。 |
| [^80] | [No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function.](http://arxiv.org/abs/2309.03224) | 该论文提出了一种通过蒙特卡洛树搜索和能量函数引导来释放大型语言模型的数学推理能力的方法，以解决当前在数学推理任务中的不足和错误。该方法不需要进一步的微调步骤，通过重新定义模型和引入路径验证器的方式，实现了对输出空间的搜索和推理路径的评估。 |
| [^81] | [Stylebook: Content-Dependent Speaking Style Modeling for Any-to-Any Voice Conversion using Only Speech Data.](http://arxiv.org/abs/2309.02730) | 这项工作提出了一种新的方法，即 Stylebook，它通过使用自监督学习模型从目标语音中提取丰富的风格信息，并将其高效地转移到源语音内容上，无需文本转录或说话者标记。该方法引入了注意力机制和样式手册，可以实现目标说话者的忠实复制和风格转移。 |
| [^82] | [BEVTrack: A Simple Baseline for 3D Single Object Tracking in Birds's-Eye-View.](http://arxiv.org/abs/2309.02185) | 本文介绍了一种名为BEVTrack的简单却强大的基线框架，用于解决点云中3D单物体跟踪的挑战。通过将点云转换为鸟瞰图表示，并进行简单的逐元素操作，BEVTrack能够编码空间邻近性和捕捉运动线索，从而实现高效的跟踪。 |
| [^83] | [Large Process Models: Business Process Management in the Age of Generative AI.](http://arxiv.org/abs/2309.00900) | 大型过程模型（LPM）结合了大规模信息语料库和基于知识系统的方法的优势，旨在为组织提供过程建议和优化方案。 |
| [^84] | [FonMTL: Towards Multitask Learning for the Fon Language.](http://arxiv.org/abs/2308.14280) | 本文面向Fon语的多任务学习，旨在通过在命名实体识别和词性标注任务上共享知识，增强模型在Fon语自然语言处理中的性能。 |
| [^85] | [Towards a Holodeck-style Simulation Game.](http://arxiv.org/abs/2308.13548) | Infinitia是一个模拟游戏系统，使用生成图像和语言模型根据玩家的描述塑造游戏场景和NPC，类似于全息舱，同时引入了无限生成的幻想世界、可控的NPC行为、幽默对话、成本和时间效率、玩家合作以及游戏内事件的非确定性元素。 |
| [^86] | [Large Language Models for Software Engineering: A Systematic Literature Review.](http://arxiv.org/abs/2308.10620) | 通过系统性文献综述，本研究调查了大规模语言模型（LLM）在软件工程领域中的应用，并集中于了解如何利用LLM来优化软件工程过程和结果。文章总结了不同LLM的特点和用途以及数据收集和预处理方法的重要性。 |
| [^87] | [Adapt Your Teacher: Improving Knowledge Distillation for Exemplar-free Continual Learning.](http://arxiv.org/abs/2308.09544) | 本研究提出了一种适应教师的方法（TA）用于无样本连续学习，解决了知识蒸馏方法在这种情况下的性能下降问题，并在多个基准测试中持续提升模型性能。 |
| [^88] | [From Hope to Safety: Unlearning Biases of Deep Models by Enforcing the Right Reasons in Latent Space.](http://arxiv.org/abs/2308.09437) | 该论文提出了一种通过梯度减小模型对偏见的敏感性的方法，从而在概念级别上确保正确原因，有效减轻深度神经网络中的偏见。该方法在多个数据集和环境中被验证有效。 |
| [^89] | [Why Do We Need Neuro-symbolic AI to Model Pragmatic Analogies?.](http://arxiv.org/abs/2308.01936) | 本文讨论了神经符号人工智能在处理逐渐复杂的类比推理时的必要性，以提供超越文字内容的广泛、多样化的知识，并结合统计和符号人工智能技术来增强和引导映射过程。 |
| [^90] | [Multi-Modality Multi-Loss Fusion Network.](http://arxiv.org/abs/2308.00264) | 多模态多损失融合网络通过最佳选择和融合多个模态的特征，提高了情感检测的性能，并在多个数据集上实现了最先进的结果。这些研究结果表明了用于增强神经网络中情感检测的特征选择和融合方法的优化方向。 |
| [^91] | [Multilingual Code Co-Evolution Using Large Language Models.](http://arxiv.org/abs/2307.14991) | 本文介绍了使用大型语言模型（LLMs）将代码更改从一种编程语言翻译到另一种编程语言的方法。通过设计和实现第一个LLM，Codeditor，以将代码更改建模为编辑序列，并学习不同编程语言之间的关联性，我们为多语言代码共同演进提供了一种新的解决方法。 |
| [^92] | [eXplainable Artificial Intelligence (XAI) in age prediction: A systematic review.](http://arxiv.org/abs/2307.13704) | 本综述探讨了可解释人工智能（XAI）在年龄预测任务中的应用。通过系统性综述，我们讨论了XAI方法在医疗应用和年龄预测领域的益处。 |
| [^93] | [ProbVLM: Probabilistic Adapter for Frozen Vison-Language Models.](http://arxiv.org/abs/2307.00398) | ProbVLM是一种概率适配器，用于估计大规模视觉-语言模型中嵌入的概率分布，以解决固有的嵌入歧义问题，并在多个数据集上展示了其在检索任务中的优越性能表现。 |
| [^94] | [PaLM 2 Technical Report.](http://arxiv.org/abs/2305.10403) | PaLM 2 是一种计算效率更高的最先进的语言模型，提供了更好的多语言和推理能力，并且通过使用多种目标进行训练，获得了在不同模型大小的下游任务上显着的改进质量。此外，PaLM 2 还展示了强大的推理能力和稳定的性能表现，使得模型能够更广泛地部署，并且可以控制毒性推理时间，而不会对其他能力产生影响。 |
| [^95] | [PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel.](http://arxiv.org/abs/2304.11277) | 本论文介绍了基于PyTorch的Fully Sharded Data Parallel（FSDP）解决方案，该方案可扩展大型模型训练，并优化各种硬件配置的资源利用率。 |
| [^96] | [Multi-granulariy Time-based Transformer for Knowledge Tracing.](http://arxiv.org/abs/2304.05257) | 本文提出了一种基于Transformer的架构用于准确地预测学生在标准化测试中的表现。该模型考虑了学生的历史数据，包括他们以往的考试成绩、学习习惯和其他相关信息，并在解码器输入中使用了多个时间特征粒度以显著提高模型性能。与LightGBM相比，该方法更加准确，为教育领域的AI发展提供了一个可伸缩和准确的预测学生成果的工具。 |
| [^97] | [Prompting Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages.](http://arxiv.org/abs/2303.13592) | 本文探讨了使用大型语言模型（LLMs）生成东南亚五种语言和Singlish的混合代码数据的方法，发现ChatGPT展现出最高的潜力。然而，由于词汇选择错误的影响，ChatGPT和InstructGPT在生成混合代码时的熟练程度受到限制。 |
| [^98] | [Open-world Story Generation with Structured Knowledge Enhancement: A Comprehensive Survey.](http://arxiv.org/abs/2212.04634) | 本文对结构化知识增强的故事生成进行了综述，总结了目前的方法与技术，指出了未来的发展方向和尚未解决的问题。 |
| [^99] | [Computationally Efficient Reinforcement Learning: Targeted Exploration leveraging simple Rules.](http://arxiv.org/abs/2211.16691) | 本研究提出了一种基于简单规则的有针对性探索方法，通过避免已知子优的状态-动作空间区域来更快地加速强化学习代理程序的收敛，并在一个房间温度控制案例研究中实现了比传统方法快6-7倍的速度收敛。 |
| [^100] | [A Survey of Deep Graph Clustering: Taxonomy, Challenge, Application, and Open Resource.](http://arxiv.org/abs/2211.12875) | 在这篇论文中，作者对深度图聚类进行了综述研究。首先介绍了该领域的定义、评估和发展，然后提出了深度图聚类方法的分类学，并对现有方法进行了分析，总结出了挑战和机会。 |
| [^101] | [Multi-scale Wasserstein Shortest-path Filtration Kernels on Graphs.](http://arxiv.org/abs/2206.00979) | 这篇论文提出了一种名为多尺度Wasserstein最短路径过滤图核心（MWSPF）的新型最短路径图核心，解决了传统核心的信息丢失和缺乏多个尺度考虑的问题。 |
| [^102] | [Testing the limits of natural language models for predicting human language judgments.](http://arxiv.org/abs/2204.03592) | 该论文通过对争议句对进行实验比较，发现神经网络语言模型中GPT-2与人类判断最为一致，揭示了模型的失败以及找出最符合人类判断的模型。 |
| [^103] | [Measuring Self-Supervised Representation Quality for Downstream Classification using Discriminative Features.](http://arxiv.org/abs/2203.01881) | 从自监督学习模型中提取区分特征，并使用它们压缩表示空间，提出了一种Q-Score自监督表示质量分数，可以可靠地预测线性评估期间的错误分类。 |
| [^104] | [Correct-by-construction reach-avoid control of partially observable linear stochastic systems.](http://arxiv.org/abs/2103.02398) | 本文提出了一种基于构造的方法来合成可观测线性随机系统的避让控制器，通过使用卡尔曼滤波器得到未测量状态的高斯置信度的有限状态抽象，并将其形式化为马尔可夫决策过程（MDP）。这种控制器可以以一种鲁棒的方式避免不安全状态。 |
| [^105] | [Out-of-distribution detection for regression tasks: parameter versus predictor entropy.](http://arxiv.org/abs/2010.12995) | 本研究针对回归任务中的离群样本检测进行了实证评估，发现通过学习多样的预测器可以估计新观测实例的认识不确定性，但参数的多样性并不一定能转化为预测器的多样性。 |

# 详细

[^1]: 使用混合3D表示学习解耦合的虚拟角色

    Learning Disentangled Avatars with Hybrid 3D Representations. (arXiv:2309.06441v1 [cs.CV])

    [http://arxiv.org/abs/2309.06441](http://arxiv.org/abs/2309.06441)

    本文提出了一种名为DELTA的方法，使用混合的显式-隐式3D表示对人体进行解耦合建模。通过将人体或面部表示为分开的层，DELTA能够实现人体和服装/头发的解耦。这种方法在学习可动画和逼真的人体角色方面具有潜力。

    

    为了学习动画化和逼真的人体角色，人们做出了巨大的努力。为了对整个人体（例如身体、服装、面部和头发）进行整体建模和捕捉，已经对显式和隐式的3D表示进行了大量研究，但是这些表示都不是在表示效果方面的最佳选择，因为人体角色的不同部分具有不同的建模要求。例如，网格通常不适合模拟服装和头发。出于这个原因，我们提出了Disentangled Avatars（DELTA），它使用混合的显式-隐式3D表示对人体进行建模。DELTA以单目RGB视频为输入，并生成具有分开身体和服装/头发层的虚拟人体角色。具体来说，我们展示了DELTA的两个重要应用。第一个应用考虑了人体和服装的解耦，第二个应用考虑了面部和头发的解耦。为了实现这个目标，DELTA对身体或面部进行表示。

    Tremendous efforts have been made to learn animatable and photorealistic human avatars. Towards this end, both explicit and implicit 3D representations are heavily studied for a holistic modeling and capture of the whole human (e.g., body, clothing, face and hair), but neither representation is an optimal choice in terms of representation efficacy since different parts of the human avatar have different modeling desiderata. For example, meshes are generally not suitable for modeling clothing and hair. Motivated by this, we present Disentangled Avatars~(DELTA), which models humans with hybrid explicit-implicit 3D representations. DELTA takes a monocular RGB video as input, and produces a human avatar with separate body and clothing/hair layers. Specifically, we demonstrate two important applications for DELTA. For the first one, we consider the disentanglement of the human body and clothing and in the second, we disentangle the face and hair. To do so, DELTA represents the body or face 
    
[^2]: LEAP Hand: 低成本、高效和拟人化机器学习手

    LEAP Hand: Low-Cost, Efficient, and Anthropomorphic Hand for Robot Learning. (arXiv:2309.06440v1 [cs.RO])

    [http://arxiv.org/abs/2309.06440](http://arxiv.org/abs/2309.06440)

    LEAP Hand是一种低成本、高效且拟人化的机器学习手。其新颖的运动结构可以实现最大的灵活性，其成本为其他竞争对手的1/8。LEAP Hand在现实世界中执行多个操作任务，并在所有实验中表现出色。

    

    在机器人学中，灵巧操控一直是一个长期存在的挑战。虽然机器学习技术在这方面显示出一些希望，但结果主要限于模拟。这主要归因于缺乏适当的硬件。在本文中，我们提出了LEAP Hand，这是一种低成本的灵巧和拟人化机器学习手。与以往的手相比，LEAP Hand具有一种新颖的运动结构，无论手指的姿势如何都可以实现最大的灵活性。LEAP Hand成本低廉，并且可以在4个小时内使用现有零件组装而成，成本为2000美元。它能够持续长时间地施加大扭矩。我们展示了LEAP Hand可以在真实世界中执行多个操作任务，从视觉远程操作到从被动视频数据和模拟到真实世界的学习。LEAP Hand在所有实验中都明显优于最接近的竞争对手Allegro Hand，同时成本只有其1/8。我们公开了详细的设计和组装说明，以便其他研究人员可以重复我们的工作。

    Dexterous manipulation has been a long-standing challenge in robotics. While machine learning techniques have shown some promise, results have largely been currently limited to simulation. This can be mostly attributed to the lack of suitable hardware. In this paper, we present LEAP Hand, a low-cost dexterous and anthropomorphic hand for machine learning research. In contrast to previous hands, LEAP Hand has a novel kinematic structure that allows maximal dexterity regardless of finger pose. LEAP Hand is low-cost and can be assembled in 4 hours at a cost of 2000 USD from readily available parts. It is capable of consistently exerting large torques over long durations of time. We show that LEAP Hand can be used to perform several manipulation tasks in the real world -- from visual teleoperation to learning from passive video data and sim2real. LEAP Hand significantly outperforms its closest competitor Allegro Hand in all our experiments while being 1/8th of the cost. We release detailed
    
[^3]: 揭示大型语言模型在生成语义和跨语言克隆方面的潜力

    Unveiling the potential of large language models in generating semantic and cross-language clones. (arXiv:2309.06424v1 [cs.SE])

    [http://arxiv.org/abs/2309.06424](http://arxiv.org/abs/2309.06424)

    本研究利用GPT-3模型在语义和跨语言克隆生成方面的潜力，通过评估、分析和验证，揭示了其在生成给定代码片段的语义和跨语言克隆变体方面的表现。

    

    语义和跨语言代码克隆生成对于代码重用、代码理解、重构和基准测试可能非常有用。OpenAI的GPT模型在这种克隆生成方面有潜力，因为GPT被用于文本生成。当开发人员从Stack Overflow（SO）或系统内部复制/粘贴代码时，可能会出现不一致的更改导致意外行为。同样，如果某人拥有一种编程语言中的代码片段，但在不同的语言中寻找等效功能，则语义跨语言代码克隆生成方法可能会提供有价值的帮助。 在这项研究中，我们使用SemanticCloneBench作为工具，评估了GPT-3模型在生成给定代码片段的语义和跨语言克隆变体方面的表现。我们收集了一组多样化的代码片段，并评估了GPT-3在生成代码变体方面的性能。通过广泛的实验和分析，我们通过9位法官花费了158个小时进行验证。

    Semantic and Cross-language code clone generation may be useful for code reuse, code comprehension, refactoring and benchmarking. OpenAI's GPT model has potential in such clone generation as GPT is used for text generation. When developers copy/paste codes from Stack Overflow (SO) or within a system, there might be inconsistent changes leading to unexpected behaviours. Similarly, if someone possesses a code snippet in a particular programming language but seeks equivalent functionality in a different language, a semantic cross-language code clone generation approach could provide valuable assistance.In this study, using SemanticCloneBench as a vehicle, we evaluated how well the GPT-3 model could help generate semantic and cross-language clone variants for a given fragment.We have comprised a diverse set of code fragments and assessed GPT-3s performance in generating code variants.Through extensive experimentation and analysis, where 9 judges spent 158 hours to validate, we investigate 
    
[^4]: 可验证的组合强化学习系统

    Verifiable Reinforcement Learning Systems via Compositionality. (arXiv:2309.06420v1 [eess.SY])

    [http://arxiv.org/abs/2309.06420](http://arxiv.org/abs/2309.06420)

    本研究提出了一个可验证和组合的强化学习框架，通过将多个强化学习子系统组合起来实现整体任务。通过定义子系统之间的接口，实现了任务规范的自动分解，并允许子系统的独立训练和测试。

    

    我们提出了一个可验证和组合的强化学习（RL）框架，其中一组RL子系统被组合在一起以完成一个整体任务。该框架由一个高级模型和一组低级子系统组成。高级模型作为参数化的马尔可夫决策过程用于规划和分析子系统的组合，而低级子系统则作为部分可观测性下操作的深度RL代理实现。通过定义子系统之间的接口，该框架能够自动分解任务规范成独立的子任务规范，并允许子系统的独立训练和测试。我们提出了理论结果保证了

    We propose a framework for verifiable and compositional reinforcement learning (RL) in which a collection of RL subsystems, each of which learns to accomplish a separate subtask, are composed to achieve an overall task. The framework consists of a high-level model, represented as a parametric Markov decision process, which is used to plan and analyze compositions of subsystems, and of the collection of low-level subsystems themselves. The subsystems are implemented as deep RL agents operating under partial observability. By defining interfaces between the subsystems, the framework enables automatic decompositions of task specifications, e.g., reach a target set of states with a probability of at least 0.95, into individual subtask specifications, i.e. achieve the subsystem's exit conditions with at least some minimum probability, given that its entry conditions are met. This in turn allows for the independent training and testing of the subsystems. We present theoretical results guaran
    
[^5]: 通过删除边缘实现关键节点的快速调节算法

    A Fast Algorithm for Moderating Critical Nodes via Edge Removal. (arXiv:2309.06392v1 [cs.SI])

    [http://arxiv.org/abs/2309.06392](http://arxiv.org/abs/2309.06392)

    本文研究了一种快速算法，通过删除网络边缘来调节关键节点。通过使用新颖的技术，我们提出了三种近似贪婪算法，以最小化目标节点的信息中心度，同时保持网络连通性。

    

    网络中的关键节点极易受到恶意攻击，触发负面级联事件，如错误信息和疾病传播。因此，对关键节点的有效调节对于减轻由此类恶意扩散引起的潜在损害非常重要。目前的调节方法计算成本高昂。此外，它们忽视了信息中心度这一基本指标，该指标衡量节点的传播能力。我们研究了从网络中删除$k$个边缘以最小化目标节点的信息中心度，同时保持网络连通性的问题。我们证明了这个问题具有计算复杂性：它是NP完全的，其目标函数不是超模。然而，我们提出了三种近似贪婪算法，使用了新颖的技术，如基于随机游走的舒尔补逼近和快速求和估计。我们的其中一种算法在近乎线性时间内运行。

    Critical nodes in networks are extremely vulnerable to malicious attacks to trigger negative cascading events such as the spread of misinformation and diseases. Therefore, effective moderation of critical nodes is very vital for mitigating the potential damages caused by such malicious diffusions. The current moderation methods are computationally expensive. Furthermore, they disregard the fundamental metric of information centrality, which measures the dissemination power of nodes.  We investigate the problem of removing $k$ edges from a network to minimize the information centrality of a target node $\lea$ while preserving the network's connectivity. We prove that this problem is computationally challenging: it is NP-complete and its objective function is not supermodular. However, we propose three approximation greedy algorithms using novel techniques such as random walk-based Schur complement approximation and fast sum estimation. One of our algorithms runs in nearly linear time in
    
[^6]: 朝着可靠流利的大型语言模型迈进：在问答系统中引入反馈学习循环

    Towards Reliable and Fluent Large Language Models: Incorporating Feedback Learning Loops in QA Systems. (arXiv:2309.06384v1 [cs.CL])

    [http://arxiv.org/abs/2309.06384](http://arxiv.org/abs/2309.06384)

    本研究通过构建评论模型和引入反馈学习循环，解决了大型语言模型在问答系统中引用错误、生成虚构信息和缺少关键细节的问题。

    

    大型语言模型（LLMs）已成为各种日常应用中多功能的工具。然而，它们存在一些问题，影响了它们的实用性和可信度。这些问题包括引用错误（引文）、生成虚构信息（正确性）以及包含多余或遗漏关键细节（流畅性）。为了改善这些问题，本研究做出了几个重要贡献。首先，我们构建了一个数据集，用于训练评论模型，评估LLMs在问答系统中生成的回答的引文、正确性和流畅性。其次，我们提出了一种自动反馈机制，利用评论模型对生成文本的异构方面进行实时反馈。第三，我们引入了一个反馈学习循环，使用评论模型来迭代改进负责回答生成的LLM的性能。实验结果显示我们的方法的有效性。

    Large language models (LLMs) have emerged as versatile tools in various daily applications. However, they are fraught with issues that undermine their utility and trustworthiness. These include the incorporation of erroneous references (citation), the generation of hallucinated information (correctness), and the inclusion of superfluous or omission of crucial details (fluency). To ameliorate these concerns, this study makes several key contributions. First, we build a dataset to train a critic model capable of evaluating the citation, correctness, and fluency of responses generated by LLMs in QA systems. Second, we propose an automated feedback mechanism that leverages the critic model to offer real-time feedback on heterogeneous aspects of generated text. Third, we introduce a feedback learning loop that uses this critic model to iteratively improve the performance of the LLM responsible for response generation. Experimental results demonstrate the efficacy of our approach, showing su
    
[^7]: 集成掩模网络

    Ensemble Mask Networks. (arXiv:2309.06382v1 [cs.LG])

    [http://arxiv.org/abs/2309.06382](http://arxiv.org/abs/2309.06382)

    本研究引入了两种机制，灵活的掩模和独特的网络剪枝，使得一个前馈网络能够学习矩阵向量乘法，并且在图形模型中可以用来测试依赖关系或交互顺序。

    

    一个$\mathbb{R}^n\rightarrow \mathbb{R}^n$的前馈网络能够学习矩阵向量乘法吗？本研究引入了两种机制：灵活的掩模用于接收矩阵输入，以及一种独特的网络剪枝方法以尊重掩模的依赖结构。网络可以近似固定操作，如矩阵向量乘法$\phi(A,x) \rightarrow Ax$，这激发了引入的机制在基于图的模型中测试依赖关系或交互顺序的应用。

    Can an $\mathbb{R}^n\rightarrow \mathbb{R}^n$ feedforward network learn matrix-vector multiplication? This study introduces two mechanisms - flexible masking to take matrix inputs, and a unique network pruning to respect the mask's dependency structure. Networks can approximate fixed operations such as matrix-vector multiplication $\phi(A,x) \rightarrow Ax$, motivating the mechanisms introduced with applications towards litmus-testing dependencies or interaction order in graph-based models.
    
[^8]: Style2Fab: 使用生成AI的功能感知分割来制造个性化3D模型

    Style2Fab: Functionality-Aware Segmentation for Fabricating Personalized 3D Models with Generative AI. (arXiv:2309.06379v1 [cs.HC])

    [http://arxiv.org/abs/2309.06379](http://arxiv.org/abs/2309.06379)

    通过使用生成AI进行功能感知分割，在制造3D模型时保留了功能的同时，允许用户有选择性地修改模型的审美部分。

    

    随着生成AI的不断进步，自动操作3D模型变得更加容易。然而，当前的方法往往会全局应用编辑，这可能会危及在物理世界中制造的3D模型的预期功能。例如，修改3D模型中的功能段，如花瓶的底座，可能会破坏模型的原始功能，导致花瓶倾倒。我们提出了一种将3D模型自动分割成功能和审美元素的方法。这种方法允许用户有选择性地修改3D模型的审美部分，而不会影响功能部分。为了开发这种方法，我们首先通过定性分析来自知名3D打印仓库Thingiverse的1000个模型，创建了一个功能分类的分类法。借助这个分类法，我们提出了一种半自动分类方法，将3D模型分解为功能和审美元素。我们提出了一个系统...

    With recent advances in Generative AI, it is becoming easier to automatically manipulate 3D models. However, current methods tend to apply edits to models globally, which risks compromising the intended functionality of the 3D model when fabricated in the physical world. For example, modifying functional segments in 3D models, such as the base of a vase, could break the original functionality of the model, thus causing the vase to fall over. We introduce a method for automatically segmenting 3D models into functional and aesthetic elements. This method allows users to selectively modify aesthetic segments of 3D models, without affecting the functional segments. To develop this method we first create a taxonomy of functionality in 3D models by qualitatively analyzing 1000 models sourced from a popular 3D printing repository, Thingiverse. With this taxonomy, we develop a semi-automatic classification method to decompose 3D models into functional and aesthetic elements. We propose a syste
    
[^9]: 建模推荐系统生态系统：机制设计、强化学习和生成模型的交叉研究挑战

    Modeling Recommender Ecosystems: Research Challenges at the Intersection of Mechanism Design, Reinforcement Learning and Generative Models. (arXiv:2309.06375v1 [cs.AI])

    [http://arxiv.org/abs/2309.06375](http://arxiv.org/abs/2309.06375)

    建模推荐系统生态系统需要考虑参与者激励、行为以及策略引发的相互作用，通过强化学习进行长期优化，使用社会选择方法进行权衡，并减少信息不对称。

    

    现代推荐系统位于涵盖用户、内容提供商、广告商和其他参与者行为的复杂生态系统的核心。尽管如此，大多数推荐系统研究的重点，以及大多数重要实用推荐系统，仅限于个别用户推荐的局部、短视优化。这给推荐系统可能为用户带来的长期效用带来了重大成本。我们认为，如果要最大化系统对这些参与者的价值并提高整体生态系统的“健康”状况，有必要明确地对系统中所有参与者的激励和行为进行建模，并对其策略引发的相互作用进行建模。为此需要：使用强化学习等技术进行长期优化；使用社会选择方法为不同参与者的效用进行不可避免的权衡；减少信息不对称。

    Modern recommender systems lie at the heart of complex ecosystems that couple the behavior of users, content providers, advertisers, and other actors. Despite this, the focus of the majority of recommender research -- and most practical recommenders of any import -- is on the local, myopic optimization of the recommendations made to individual users. This comes at a significant cost to the long-term utility that recommenders could generate for its users. We argue that explicitly modeling the incentives and behaviors of all actors in the system -- and the interactions among them induced by the recommender's policy -- is strictly necessary if one is to maximize the value the system brings to these actors and improve overall ecosystem "health". Doing so requires: optimization over long horizons using techniques such as reinforcement learning; making inevitable tradeoffs in the utility that can be generated for different actors using the methods of social choice; reducing information asymm
    
[^10]: Chebyshev粒子

    Chebyshev Particles. (arXiv:2309.06373v1 [cs.AI])

    [http://arxiv.org/abs/2309.06373](http://arxiv.org/abs/2309.06373)

    本文提出了一种基于Chebyshev粒子的顺序MCMC采样器，通过最大化加权Riesz极化量，在无穷维欧几里得空间中离散化可矩形子流形，从而有效解决了隐马尔可夫模型推断中的维数灾难问题。

    

    马尔科夫链蒙特卡洛(MCMC)为推断隐马尔可夫模型提供了可行的方法，然而，由于蒙特卡洛采样器在参数空间中随机采取小步骤在不确定区域中穿越，通常计算量很大，尤其受到维数灾难的限制。我们首次将目标的后验分布视为样本在无穷维欧几里得空间中的映射，确定性子流形嵌入其中，并提出了一种通过最大化加权Riesz极化量来离散化可矩形子流形的新标准。我们研究了Chebyshev粒子的特性，并将它们嵌入顺序MCMC，这是一种具有高接受率且只提出少量评估的新型采样器。我们在线性高斯状态空间模型与合成数据和非线性随机波动率模型的参数推断实验中取得了高性能。

    Markov chain Monte Carlo (MCMC) provides a feasible method for inferring Hidden Markov models, however, it is often computationally prohibitive, especially constrained by the curse of dimensionality, as the Monte Carlo sampler traverses randomly taking small steps within uncertain regions in the parameter space. We are the first to consider the posterior distribution of the objective as a mapping of samples in an infinite-dimensional Euclidean space where deterministic submanifolds are embedded and propose a new criterion by maximizing the weighted Riesz polarization quantity, to discretize rectifiable submanifolds via pairwise interaction. We study the characteristics of Chebyshev particles and embed them into sequential MCMC, a novel sampler with a high acceptance ratio that proposes only a few evaluations. We have achieved high performance from the experiments for parameter inference in a linear Gaussian state-space model with synthetic data and a non-linear stochastic volatility mo
    
[^11]: 基于框架的大型语言模型自由回答的定性分析：算法保真度

    Framework-Based Qualitative Analysis of Free Responses of Large Language Models: Algorithmic Fidelity. (arXiv:2309.06364v1 [cs.CL])

    [http://arxiv.org/abs/2309.06364](http://arxiv.org/abs/2309.06364)

    本文通过定性分析研究了大型语言模型生成的自由回答，重点考察了算法保真度，并提出高算法保真度可以推广到真实人类的观点。这对于使用语言模型研究人类行为具有重要意义。

    

    如今，使用大规模生成式语言模型（LLMs），可以模拟自由回答面试问题，就像传统上使用定性研究方法分析的那样。定性方法涵盖了一系列技术，涉及对开放式访谈或自由进行的自然语言对话的手动分析。本文考虑通过定性方法对LLMs生成的"硅参与者"进行研究，从而产生可能可以推广到真实人群的洞察力。我们分析的关键概念是算法保真度，这是由Argyle等人（2023年）引入的一个术语，用于描述LLM生成的输出与人类亚群体的信念和态度的程度相吻合。根据定义，高算法保真度表明从LLMs中提取的潜在信念可能可以推广到真实人类，而低算法保真度则使得这样的研究无效。本文使用LLM生成面试问答，...

    Today, using Large-scale generative Language Models (LLMs) it is possible to simulate free responses to interview questions like those traditionally analyzed using qualitative research methods. Qualitative methodology encompasses a broad family of techniques involving manual analysis of open-ended interviews or conversations conducted freely in natural language. Here we consider whether artificial "silicon participants" generated by LLMs may be productively studied using qualitative methods aiming to produce insights that could generalize to real human populations. The key concept in our analysis is algorithmic fidelity, a term introduced by Argyle et al. (2023) capturing the degree to which LLM-generated outputs mirror human sub-populations' beliefs and attitudes. By definition, high algorithmic fidelity suggests latent beliefs elicited from LLMs may generalize to real humans, whereas low algorithmic fidelity renders such research invalid. Here we used an LLM to generate interviews wi
    
[^12]: 使用LLMs进行生成式数据增强提高问答中的分布鲁棒性

    Generative Data Augmentation using LLMs improves Distributional Robustness in Question Answering. (arXiv:2309.06358v1 [cs.CL])

    [http://arxiv.org/abs/2309.06358](http://arxiv.org/abs/2309.06358)

    本论文研究了使用生成式数据增强方法如何提高问答模型在自然分布转换下的鲁棒性，通过实验展示了增强阅读理解数据集的效果。

    

    自然语言处理中的鲁棒性问题仍然是一个重要的问题，最先进的模型在自然分布转换下表现不佳。在问答环境中，对领域适应方法的研究工作仍在不断发展。然而，在自然分布转换下的域泛化概念却受到很少关注，因为目标域是未知的。随着生成模型质量和获取方式的大幅提高，我们回答了一个问题：生成的数据集如何影响问答模型在自然分布转换下的性能？我们在4个不同数据集上进行了实验，分析了“野外生成”如何帮助实现域泛化。我们采取了两步生成方法，生成上下文和问答对来增强现有数据集。通过我们的实验，我们展示了如何通过增强阅读理解数据集来提升领域泛化能力。

    Robustness in Natural Language Processing continues to be a pertinent issue, where state of the art models under-perform under naturally shifted distributions. In the context of Question Answering, work on domain adaptation methods continues to be a growing body of research. However, very little attention has been given to the notion of domain generalization under natural distribution shifts, where the target domain is unknown. With drastic improvements in the quality and access to generative models, we answer the question: How do generated datasets influence the performance of QA models under natural distribution shifts? We perform experiments on 4 different datasets under varying amounts of distribution shift, and analyze how "in-the-wild" generation can help achieve domain generalization. We take a two-step generation approach, generating both contexts and QA pairs to augment existing datasets. Through our experiments, we demonstrate how augmenting reading comprehension datasets wit
    
[^13]: 从物体和动作意象中获得基于实践的语言习得

    Grounded Language Acquisition From Object and Action Imagery. (arXiv:2309.06335v1 [cs.CV])

    [http://arxiv.org/abs/2309.06335](http://arxiv.org/abs/2309.06335)

    本文研究了通过训练新兴语言编码器/解码器来发展基于实践的视觉数据表述的私人语言。使用神经机器翻译和随机森林分类转换符号表示到类别标签，并应用于物体识别和动作识别实验。

    

    深度学习方法在自然语言处理方面取得了巨大的进展。虽然这些模型产生了传达了大量多样化知识的符号，但如何将这些符号与来自世界的数据联系起来还不清楚。在本文中，我们探索了在传统的指代游戏环境和利用类内匹配训练范式的对比学习环境中训练新兴语言（EL）编码器/解码器来开发视觉数据表述的私人语言的发展。使用神经机器翻译和随机森林分类来转换符号表示（整数符号序列）到类别标签的额外分类层。这些方法应用于两个实验，重点是物体识别和动作识别。对于物体识别，使用了由真实图像生成的人类参与者绘制的一组素描（Sketchy数据集），对于动作识别，使用了2D轨迹数据集。

    Deep learning approaches to natural language processing have made great strides in recent years. While these models produce symbols that convey vast amounts of diverse knowledge, it is unclear how such symbols are grounded in data from the world. In this paper, we explore the development of a private language for visual data representation by training emergent language (EL) encoders/decoders in both i) a traditional referential game environment and ii) a contrastive learning environment utilizing a within-class matching training paradigm. An additional classification layer utilizing neural machine translation and random forest classification was used to transform symbolic representations (sequences of integer symbols) to class labels. These methods were applied in two experiments focusing on object recognition and action recognition. For object recognition, a set of sketches produced by human participants from real imagery was used (Sketchy dataset) and for action recognition, 2D traje
    
[^14]: 使用马尔科夫边界引导修剪学习最简化Tsetlin机器子句

    Learning Minimalistic Tsetlin Machine Clauses with Markov Boundary-Guided Pruning. (arXiv:2309.06315v1 [cs.LG])

    [http://arxiv.org/abs/2309.06315](http://arxiv.org/abs/2309.06315)

    本论文提出了一种新的Tsetlin机器（TM）反馈方案，通过引入马尔科夫边界来学习最简化的Tsetlin机器子句，以提供最佳的特征集。

    

    如果包含了预测变量所需的所有信息，那么一组变量就是随机变量的马尔科夫盖被。如果盖被无法减少而不丢失有用信息，则被称为马尔科夫边界。识别随机变量的马尔科夫边界是有优势的，因为边界外的所有变量都是多余的。因此，马尔科夫边界提供了最佳的特征集。然而，从数据中学习马尔科夫边界具有两个挑战。如果从马尔科夫边界中移除一个或多个变量，边界外的变量可能开始提供信息。相反，边界内的变量可能停止提供信息。每个候选变量的真正作用只有在识别了马尔科夫边界后才会显现。在本文中，我们提出了一种新的Tsetlin机器（TM）反馈方案，以补充类型I和类型II的反馈。该方案引入了一种新颖的有限状态自动机 - 一种上下文特定的机器。

    A set of variables is the Markov blanket of a random variable if it contains all the information needed for predicting the variable. If the blanket cannot be reduced without losing useful information, it is called a Markov boundary. Identifying the Markov boundary of a random variable is advantageous because all variables outside the boundary are superfluous. Hence, the Markov boundary provides an optimal feature set. However, learning the Markov boundary from data is challenging for two reasons. If one or more variables are removed from the Markov boundary, variables outside the boundary may start providing information. Conversely, variables within the boundary may stop providing information. The true role of each candidate variable is only manifesting when the Markov boundary has been identified. In this paper, we propose a new Tsetlin Machine (TM) feedback scheme that supplements Type I and Type II feedback. The scheme introduces a novel Finite State Automaton - a Context-Specific I
    
[^15]: AI4Food-NutritionFW：用于自动合成和分析饮食行为的新型框架

    AI4Food-NutritionFW: A Novel Framework for the Automatic Synthesis and Analysis of Eating Behaviours. (arXiv:2309.06308v1 [cs.CV])

    [http://arxiv.org/abs/2309.06308](http://arxiv.org/abs/2309.06308)

    AI4Food-NutritionFW是一个新型框架，利用图像处理和人工智能技术，可以分析个体的健康情况以及根据可配置的饮食行为提供个性化建议，是研究饮食行为和改善营养的有力工具。

    

    如今，在社交媒体和网络平台上分享了数以百万计的图片。其中许多是从智能手机上拍摄的食物图片，随时间提供了与个体饮食相关的信息。另一方面，饮食行为与世界上一些最常见的疾病直接相关。利用图像处理和人工智能（AI）的最新进展，这种情况为：i）创建分析个体健康的新方法，来源于他们所吃的东西，以及 ii）在特定情况（如肥胖症或COVID）下制定个性化建议以改善营养和饮食提供了良好的机会。很有必要拥有可调节的工具来创建食物图像数据集，以促进这两个方面的研究。本文提出了AI4Food-NutritionFW，一个根据可配置的饮食行为创建食物图像数据集的框架。AI4Food-NutritionFW模拟了一个用户友好且广泛应用的场景，其中包括图像。

    Nowadays millions of images are shared on social media and web platforms. In particular, many of them are food images taken from a smartphone over time, providing information related to the individual's diet. On the other hand, eating behaviours are directly related to some of the most prevalent diseases in the world. Exploiting recent advances in image processing and Artificial Intelligence (AI), this scenario represents an excellent opportunity to: i) create new methods that analyse the individuals' health from what they eat, and ii) develop personalised recommendations to improve nutrition and diet under specific circumstances (e.g., obesity or COVID). Having tunable tools for creating food image datasets that facilitate research in both lines is very much needed.  This paper proposes AI4Food-NutritionFW, a framework for the creation of food image datasets according to configurable eating behaviours. AI4Food-NutritionFW simulates a user-friendly and widespread scenario where images 
    
[^16]: 数据驱动的增材制造知识的可迁移性分析：粉床熔化和定向能量沉积之间的案例研究

    Transferability analysis of data-driven additive manufacturing knowledge: a case study between powder bed fusion and directed energy deposition. (arXiv:2309.06286v1 [cs.AI])

    [http://arxiv.org/abs/2309.06286](http://arxiv.org/abs/2309.06286)

    本论文提出了一种三步知识迁移性分析框架来支持数据驱动的增材制造知识的迁移。研究发现，通过利用各种增材制造技术之间的相似性和应用迁移学习的方法，可以将现有的解决方案从一个工艺或问题转移到另一个工艺或问题中。

    

    最近几年，数据驱动的增材制造（AM）研究取得了显著的成功，产生了大量的科学文献。这些研究中的知识涉及到AM和人工智能（AI）领域，但没有以一种整合的方式进行挖掘和形式化。此外，目前没有支持数据驱动知识从一个上下文迁移到另一个上下文的工具或指南。因此，仅针对特定的AM工艺技术开发和验证了特定的AI技术的数据驱动解决方案。有潜力利用各种AM技术之间的内在相似性，利用AI（如迁移学习）从一个工艺或问题中适应现有的解决方案。我们提出了一种三步知识迁移性分析框架来支持数据驱动的AM知识迁移。作为迁移性分析的先决条件，AM知识被转化为识别出的知识组件。

    Data-driven research in Additive Manufacturing (AM) has gained significant success in recent years. This has led to a plethora of scientific literature to emerge. The knowledge in these works consists of AM and Artificial Intelligence (AI) contexts that have not been mined and formalized in an integrated way. Moreover, no tools or guidelines exist to support data-driven knowledge transfer from one context to another. As a result, data-driven solutions using specific AI techniques are being developed and validated only for specific AM process technologies. There is a potential to exploit the inherent similarities across various AM technologies and adapt the existing solutions from one process or problem to another using AI, such as Transfer Learning. We propose a three-step knowledge transferability analysis framework in AM to support data-driven AM knowledge transfer. As a prerequisite to transferability analysis, AM knowledge is featurized into identified knowledge components. The fra
    
[^17]: 低分辨率广播视频中的球衣号码识别：基于关键帧识别的方法

    Jersey Number Recognition using Keyframe Identification from Low-Resolution Broadcast Videos. (arXiv:2309.06285v1 [cs.CV])

    [http://arxiv.org/abs/2309.06285](http://arxiv.org/abs/2309.06285)

    本研究提出了一种在低分辨率广播视频中识别球衣号码的方法，通过关键帧识别提取包含球衣号码的关键信息，并结合时空网络预测球衣号码的概率。

    

    球员识别是运用视觉分析的足球应用中的重要组成部分，它可以用于球员评估、比赛分析和广播制作等各种下游任务。然而，在视频中自动检测球员轨迹中的球衣号码存在着因运动模糊、低分辨率、畸变和遮挡等挑战。现有方法利用空间变换网络、卷积神经网络和视觉变换器在图像数据上取得了成功，但在真实世界的视频数据上仍面临困难，因为大多数帧中球衣号码是不可见的。因此，识别包含球衣号码的关键帧成为解决问题的一个关键子问题。为了解决这些问题，我们提出了一个鲁棒的关键帧识别模块，提取包含球衣号码的重要高级信息的帧。然后，采用时空网络来建模空间和时间上下文，并预测视频中球衣号码的概率。此外，我们采用了多种增强技术来提高球衣号码识别的性能。

    Player identification is a crucial component in vision-driven soccer analytics, enabling various downstream tasks such as player assessment, in-game analysis, and broadcast production. However, automatically detecting jersey numbers from player tracklets in videos presents challenges due to motion blur, low resolution, distortions, and occlusions. Existing methods, utilizing Spatial Transformer Networks, CNNs, and Vision Transformers, have shown success in image data but struggle with real-world video data, where jersey numbers are not visible in most of the frames. Hence, identifying frames that contain the jersey number is a key sub-problem to tackle. To address these issues, we propose a robust keyframe identification module that extracts frames containing essential high-level information about the jersey number. A spatio-temporal network is then employed to model spatial and temporal context and predict the probabilities of jersey numbers in the video. Additionally, we adopt a mult
    
[^18]: 通过精细的模态评估增强多模态协作

    Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation. (arXiv:2309.06255v1 [cs.CV])

    [http://arxiv.org/abs/2309.06255](http://arxiv.org/abs/2309.06255)

    本文提出了一种精细的模态评估指标，用于评估每个模态在样本级别的贡献，并发现多模态模型倾向于依赖一个特定的模态，导致其他模态的贡献较低。

    

    多模态学习的一个主要问题是如何将来自不同模态的异质信息共同结合起来。然而，大多数模型在多模态协作方面常常存在不尽人意的问题，不能很好地共同利用所有模态。一些方法被提出来识别和增强学习效果较差的模态，但往往难以在理论上提供对样本级别多模态协作的细粒度观察和支持。因此，合理观察和改进模态之间细粒度的协作尤为重要，尤其是在面对模态差异在不同样本之间可能变化的实际场景时。为了实现这一目标，我们引入了一种精细的模态评估指标，以评估每个模态在样本级别的贡献。通过模态评估，我们遗憾地发现多模态模型倾向于依赖一个特定的模态，导致其他模态的贡献较低。我们进一步分析了这个问题。

    One primary topic of multi-modal learning is to jointly incorporate heterogeneous information from different modalities. However, most models often suffer from unsatisfactory multi-modal cooperation, which could not jointly utilize all modalities well. Some methods are proposed to identify and enhance the worse learnt modality, but are often hard to provide the fine-grained observation of multi-modal cooperation at sample-level with theoretical support. Hence, it is essential to reasonably observe and improve the fine-grained cooperation between modalities, especially when facing realistic scenarios where the modality discrepancy could vary across different samples. To this end, we introduce a fine-grained modality valuation metric to evaluate the contribution of each modality at sample-level. Via modality valuation, we regretfully observe that the multi-modal model tends to rely on one specific modality, resulting in other modalities being low-contributing. We further analyze this iss
    
[^19]: 关于XAIxArt的被禁令（arXiv:2309.06227v1 [cs.HC]）

    On the Injunction of XAIxArt. (arXiv:2309.06227v1 [cs.HC])

    [http://arxiv.org/abs/2309.06227](http://arxiv.org/abs/2309.06227)

    这篇论文讨论了解释性人工智能在艺术中的禁令（XAIxArt）引发的一系列问题，并指出XAIxArt旨在解决人类中心的艺术观念的不安和对过时的作者概念的怀旧愿望。

    

    这篇论文强调了在解释性人工智能在艺术中的禁令（XAIxArt）中涉及的一系列问题。通过一系列简短的子问题，它指出了与“解释”和“相关解释”的含糊之处。本文拒绝了“解释”和“相关解释”，认为XAIxArt是对以人为中心的艺术观念的不安和对过时的作者概念和人类行为的怀旧愿望的症状。为了证明这个立场，本文将解释模型从装饰模型转变为意义生成模型。

    The position paper highlights the range of concerns that are engulfed in the injunction of explainable artificial intelligence in art (XAIxArt). Through a series of quick sub-questions, it points towards the ambiguities concerning 'explanation' and the postpositivist tradition of 'relevant explanation'. Rejecting both 'explanation' and 'relevant explanation', the paper takes a stance that XAIxArt is a symptom of insecurity of the anthropocentric notion of art and a nostalgic desire to return to outmoded notions of authorship and human agency. To justify this stance, the paper makes a distinction between an ornamentation model of explanation to a model of explanation as sense-making.
    
[^20]: 揭示对DNN可执行文件的单位翻转攻击

    Unveiling Signle-Bit-Flip Attacks on DNN Executables. (arXiv:2309.06223v1 [cs.CR])

    [http://arxiv.org/abs/2309.06223](http://arxiv.org/abs/2309.06223)

    针对由深度学习编译器编译的DNN可执行文件的单位翻转攻击进行了系统研究，设计了自动搜索工具以识别易受攻击的位，并确定了实际攻击向量，揭示了DNN可执行文件的攻击面。

    

    最近的研究表明，位翻转攻击(BFA)可以通过DRAM Rowhammer利用来操纵深度神经网络(DNN)。现有的攻击主要针对高级DNN框架（如PyTorch）中的模型权重文件进行位翻转。然而，DNN经常通过深度学习编译器编译成低级可执行文件，以充分利用低级硬件原语。编译后的代码通常速度很快，并且与高级DNN框架具有明显不同的执行范式。本文针对由DL编译器编译的DNN可执行文件的BFA攻击面进行了首次系统研究。我们设计了一种自动搜索工具，用于识别DNN可执行文件中的易受攻击位，并确定利用BFAs攻击DNN可执行文件中的模型结构的实际攻击向量（而以前的工作通常对攻击模型权重做出了强假设）。DNN可执行文件似乎比高级DNN中的模型更加“不透明”。

    Recent research has shown that bit-flip attacks (BFAs) can manipulate deep neural networks (DNNs) via DRAM Rowhammer exploitations. Existing attacks are primarily launched over high-level DNN frameworks like PyTorch and flip bits in model weight files. Nevertheless, DNNs are frequently compiled into low-level executables by deep learning (DL) compilers to fully leverage low-level hardware primitives. The compiled code is usually high-speed and manifests dramatically distinct execution paradigms from high-level DNN frameworks.  In this paper, we launch the first systematic study on the attack surface of BFA specifically for DNN executables compiled by DL compilers. We design an automated search tool to identify vulnerable bits in DNN executables and identify practical attack vectors that exploit the model structure in DNN executables with BFAs (whereas prior works make likely strong assumptions to attack model weights). DNN executables appear more "opaque" than models in high-level DNN 
    
[^21]: SCP: 场景完整性预训练用于3D目标检测

    SCP: Scene Completion Pre-training for 3D Object Detection. (arXiv:2309.06199v1 [cs.CV])

    [http://arxiv.org/abs/2309.06199](http://arxiv.org/abs/2309.06199)

    SCP提出了一种场景完整性预训练方法，以增强3D目标检测器的性能，包括改善点云模型的初始化、消除对额外数据集的需求和减少标记数据量。

    

    在计算机视觉、机器人和自动驾驶等领域，使用LiDAR点云进行3D目标检测是一项基础任务。然而，现有的3D检测器严重依赖于注释数据集，这在标记3D边界框的过程中既耗时又容易出错。本文提出一种场景完整性预训练（SCP）方法，以增强使用较少标记数据的3D目标检测器的性能。SCP具有三个关键优势：（1）改善点云模型的初始化。通过完善场景点云，SCP有效捕捉城市环境中物体间的空间和语义关系。（2）消除对额外数据集的需求。SCP作为有价值的辅助网络，不会对3D检测器施加任何额外的工作或数据要求。（3）减少目标检测所需的标记数据量。借助SCP的帮助，现有的最先进3D检测器可以实现与大量标记数据相当的性能。

    3D object detection using LiDAR point clouds is a fundamental task in the fields of computer vision, robotics, and autonomous driving. However, existing 3D detectors heavily rely on annotated datasets, which are both time-consuming and prone to errors during the process of labeling 3D bounding boxes. In this paper, we propose a Scene Completion Pre-training (SCP) method to enhance the performance of 3D object detectors with less labeled data. SCP offers three key advantages: (1) Improved initialization of the point cloud model. By completing the scene point clouds, SCP effectively captures the spatial and semantic relationships among objects within urban environments. (2) Elimination of the need for additional datasets. SCP serves as a valuable auxiliary network that does not impose any additional efforts or data requirements on the 3D detectors. (3) Reduction of the amount of labeled data for detection. With the help of SCP, the existing state-of-the-art 3D detectors can achieve compa
    
[^22]: 一台摄像机的360°视角：用于LiDAR分割的少样本方法

    360$^\circ$ from a Single Camera: A Few-Shot Approach for LiDAR Segmentation. (arXiv:2309.06197v1 [cs.CV])

    [http://arxiv.org/abs/2309.06197](http://arxiv.org/abs/2309.06197)

    本论文提出了一种用于LiDAR分割的少样本方法，通过使用图像教师网络在单个摄像机视角下生成语义预测，实现了标度高效的LiDAR分割。

    

    LiDAR数据上的深度学习应用在应用于不同的传感器或任务时，会遭受到强烈的域间差距。为了使这些方法在不同数据上获得与公共基准报告值相似的准确性，需要一个大规模的带标注数据集。然而，在实际应用中，标注数据的获取成本和时间成本很高。这些因素引发了对标度效率方法的各种研究，但与完全监督的对照方法相比，仍存在很大差距。因此，我们提出了ImageTo360，一种有效且简洁的少样本方法，用于标度高效的LiDAR分割。我们的方法利用图像教师网络在单个摄像机视角下为LiDAR数据生成语义预测。在对360°数据进行可选微调之前，使用教师网络对LiDAR分割学生网络进行预训练。我们的方法以模块化的方式实现在点级别，并且适用于不同的体系结构。

    Deep learning applications on LiDAR data suffer from a strong domain gap when applied to different sensors or tasks. In order for these methods to obtain similar accuracy on different data in comparison to values reported on public benchmarks, a large scale annotated dataset is necessary. However, in practical applications labeled data is costly and time consuming to obtain. Such factors have triggered various research in label-efficient methods, but a large gap remains to their fully-supervised counterparts. Thus, we propose ImageTo360, an effective and streamlined few-shot approach to label-efficient LiDAR segmentation. Our method utilizes an image teacher network to generate semantic predictions for LiDAR data within a single camera view. The teacher is used to pretrain the LiDAR segmentation student network, prior to optional fine-tuning on 360$^\circ$ data. Our method is implemented in a modular manner on the point level and as such is generalizable to different architectures. We 
    
[^23]: 一个用于恢复独特巨幅壁画的3M混合模型：以永乐宫壁画为例

    A 3M-Hybrid Model for the Restoration of Unique Giant Murals: A Case Study on the Murals of Yongle Palace. (arXiv:2309.06194v1 [cs.CV])

    [http://arxiv.org/abs/2309.06194](http://arxiv.org/abs/2309.06194)

    这项研究提出了一个3M混合模型来恢复永乐宫独特巨幅壁画，解决了传统修复方法中的领域偏差和数据稀缺性的问题，同时也能应对壁画巨大尺寸带来的更广泛缺陷类型和尺寸范围的挑战。

    

    作为有价值的文化遗产，永乐宫壁画遭受了不同程度的损坏，因此对其进行修复具有重要意义。然而，永乐宫壁画的巨大尺寸和独特数据给现有基于深度学习的修复方法带来了挑战：1）独特的风格在传统的迁移学习修复方法中引入了领域偏差，而壁画数据的稀缺性进一步限制了这些方法的适用性。2）此外，这些壁画的巨大尺寸导致了更广泛的缺陷类型和尺寸范围，需要具有更大适应性的模型。因此，目前缺乏针对永乐宫独特巨幅壁画的基于深度学习的修复方法的研究。在这里，提出了一个3M混合模型来解决这些挑战。首先，基于壁画数据频率在低频和高频特征分布中显著，高频和低频特征被分开处理。

    The Yongle Palace murals, as valuable cultural heritage, have suffered varying degrees of damage, making their restoration of significant importance. However, the giant size and unique data of Yongle Palace murals present challenges for existing deep-learning based restoration methods: 1) The distinctive style introduces domain bias in traditional transfer learning-based restoration methods, while the scarcity of mural data further limits the applicability of these methods. 2) Additionally, the giant size of these murals results in a wider range of defect types and sizes, necessitating models with greater adaptability. Consequently, there is a lack of focus on deep learning-based restoration methods for the unique giant murals of Yongle Palace. Here, a 3M-Hybrid model is proposed to address these challenges. Firstly, based on the characteristic that the mural data frequency is prominent in the distribution of low and high frequency features, high and low frequency features are separate
    
[^24]: 在同时机器翻译中展望未来

    Glancing Future for Simultaneous Machine Translation. (arXiv:2309.06179v1 [cs.CL])

    [http://arxiv.org/abs/2309.06179](http://arxiv.org/abs/2309.06179)

    本文提出了一种新的方法，在同时机器翻译中通过课程学习的逐步减少可用源信息，从整个句子到与延迟对应的前缀，以实现从序列到序列训练到前缀到前缀训练的过渡，从而增强SiMT模型的翻译能力。

    

    同时机器翻译（SiMT）在阅读源语句的同时输出翻译。与传统的序列到序列（seq2seq）训练不同，现有的SiMT方法采用前缀到前缀（prefix2prefix）训练，即模型基于部分源标记预测目标标记。然而，前缀到前缀训练降低了模型捕捉全局信息的能力，并且由于缺乏必要的源信息而引入了强制预测。因此，弥合前缀到前缀训练和序列到序列训练之间差距以增强SiMT模型的翻译能力至关重要。在本文中，我们提出了一种新的方法，在课程学习中展望未来，实现从序列到序列训练过渡到前缀到前缀训练。具体而言，我们逐渐减少可用的源信息，从整个句子到与延迟对应的前缀。我们的方法适用于广泛的SiMT方法。

    Simultaneous machine translation (SiMT) outputs translation while reading the source sentence. Unlike conventional sequence-to-sequence (seq2seq) training, existing SiMT methods adopt the prefix-to-prefix (prefix2prefix) training, where the model predicts target tokens based on partial source tokens. However, the prefix2prefix training diminishes the ability of the model to capture global information and introduces forced predictions due to the absence of essential source information. Consequently, it is crucial to bridge the gap between the prefix2prefix training and seq2seq training to enhance the translation capability of the SiMT model. In this paper, we propose a novel method that glances future in curriculum learning to achieve the transition from the seq2seq training to prefix2prefix training. Specifically, we gradually reduce the available source information from the whole sentence to the prefix corresponding to that latency. Our method is applicable to a wide range of SiMT met
    
[^25]: Robust-MBDL:一种用于旋转机器剩余寿命预测和运行状态鉴别的稳健的多支路深度学习模型

    Robust-MBDL: A Robust Multi-branch Deep Learning Based Model for Remaining Useful Life Prediction and Operational Condition Identification of Rotating Machines. (arXiv:2309.06157v1 [cs.LG])

    [http://arxiv.org/abs/2309.06157](http://arxiv.org/abs/2309.06157)

    本文提出了一种稳健的多支路深度学习模型，用于旋转机器的剩余寿命预测和运行状态识别。该模型包括LSTM-Autoencoder对振动数据进行去噪、特征提取和多支路深度学习网络结构等组件，并在实验中证明了它在轴承机器应用中的优越性和潜力。

    

    本文提出了一种用于旋转机器剩余寿命(RUL)预测和运行状态(CO)鉴别的稳健的多支路深度学习系统。具体而言，该系统包括主要组件：(1)采用LSTM-Autoencoder对振动数据进行去噪；(2)使用特征提取从去噪数据中生成时域、频域和时频域特征；(3)采用新颖而稳健的多支路深度学习网络结构来利用多个特征。我们的系统在XJTU-SY和PRONOSTIA两个基准数据集上与现有技术水平进行了评估和比较。实验结果证明我们的系统表现优于现有技术水平，并具有在轴承机器实际应用中的潜力。

    In this paper, a Robust Multi-branch Deep learning-based system for remaining useful life (RUL) prediction and condition operations (CO) identification of rotating machines is proposed. In particular, the proposed system comprises main components: (1) an LSTM-Autoencoder to denoise the vibration data; (2) a feature extraction to generate time-domain, frequency-domain, and time-frequency based features from the denoised data; (3) a novel and robust multi-branch deep learning network architecture to exploit the multiple features. The performance of our proposed system was evaluated and compared to the state-of-the-art systems on two benchmark datasets of XJTU-SY and PRONOSTIA. The experimental results prove that our proposed system outperforms the state-of-the-art systems and presents potential for real-life applications on bearing machines.
    
[^26]: 在文本中测量模糊性和主观性：从符号到神经网络的VAGO

    Measuring vagueness and subjectivity in texts: from symbolic to neural VAGO. (arXiv:2309.06132v1 [cs.CL])

    [http://arxiv.org/abs/2309.06132](http://arxiv.org/abs/2309.06132)

    本文提出了一种混合方法来自动测量文本中的模糊性和主观性。通过引入专家系统VAGO，以及基于BERT-like架构的神经克隆，该方法在固定语料库和多语言生成方面表现出良好的性能。

    

    我们提出了一种混合方法来自动测量文本中的模糊性和主观性。首先，我们介绍了专家系统VAGO，并在一小组事实与观点句子的基准上对其进行了说明，并在更大的法语新闻语料库FreSaDa上进行了测试，以确认讽刺性文本中主观标记的更高流行率。然后，我们构建了一个基于BERT-like架构的VAGO神经克隆，该架构基于在FreSaDa上获得的符号VAGO分数进行训练。使用可解释性工具（LIME），我们展示了这个神经版本在丰富符号版本的词典和生成其他语言版本方面的兴趣。

    We present a hybrid approach to the automated measurement of vagueness and subjectivity in texts. We first introduce the expert system VAGO, we illustrate it on a small benchmark of fact vs. opinion sentences, and then test it on the larger French press corpus FreSaDa to confirm the higher prevalence of subjective markers in satirical vs. regular texts. We then build a neural clone of VAGO, based on a BERT-like architecture, trained on the symbolic VAGO scores obtained on FreSaDa. Using explainability tools (LIME), we show the interest of this neural version for the enrichment of the lexicons of the symbolic version, and for the production of versions in other languages.
    
[^27]: JOADAA:联合在线动作检测和动作预测

    JOADAA: joint online action detection and action anticipation. (arXiv:2309.06130v1 [cs.CV])

    [http://arxiv.org/abs/2309.06130](http://arxiv.org/abs/2309.06130)

    JOADAA模型将动作预测和在线动作检测两个任务融合到一个统一的架构中，可以解决推断动作依赖关系的挑战，提高性能。

    

    动作预测涉及通过连接过去事件与未来事件来预测未来动作。然而，这种推理忽视了真实生活中事件的层次结构，它被认为包括过去、现在和未来三个主要部分。我们认为考虑这三个主要部分及其依赖关系可以提高性能。另一方面，在线动作检测是在流式方式下预测动作的任务。在这种情况下，只能访问过去和现在的信息。因此，在在线动作检测中，现有的方法忽视了语义或未来信息，限制了它们的性能。总的来说，对于这两个任务，缺失了完整的知识集合（过去-现在-未来），这使得推断动作依赖关系具有挑战性，因此性能较低。为了解决这个限制，我们提出将这两个任务融合成一个统一的架构。通过结合动作预测和在线动作检测，

    Action anticipation involves forecasting future actions by connecting past events to future ones. However, this reasoning ignores the real-life hierarchy of events which is considered to be composed of three main parts: past, present, and future. We argue that considering these three main parts and their dependencies could improve performance. On the other hand, online action detection is the task of predicting actions in a streaming manner. In this case, one has access only to the past and present information. Therefore, in online action detection (OAD) the existing approaches miss semantics or future information which limits their performance. To sum up, for both of these tasks, the complete set of knowledge (past-present-future) is missing, which makes it challenging to infer action dependencies, therefore having low performances. To address this limitation, we propose to fuse both tasks into a single uniform architecture. By combining action anticipation and online action detection
    
[^28]: LEyes：一种轻量级深度学习眼动跟踪框架，使用合成眼部图像

    LEyes: A Lightweight Framework for Deep Learning-Based Eye Tracking using Synthetic Eye Images. (arXiv:2309.06129v1 [cs.CV])

    [http://arxiv.org/abs/2309.06129](http://arxiv.org/abs/2309.06129)

    本研究提出了一种名为LEyes的轻量级深度学习眼动跟踪框架，利用合成眼部图像进行训练，解决了由于训练数据集不足和眼部图像变异导致的模型泛化问题。实验结果表明，LEyes训练的模型在瞳孔和CR定位方面优于其他算法。

    

    深度学习已经加强了凝视估计技术，但实际部署受到不足的训练数据集的限制。眼部图像的硬件引起的变异以及记录的参与者之间固有的生物差异会导致特征和像素级别的差异，阻碍了在特定数据集上训练的模型的泛化能力。虚拟数据集可以是一个解决方案，但创建虚拟数据集既需要时间又需要资源。为了解决这个问题，我们提出了一个名为Light Eyes or "LEyes"的框架，与传统的逼真方法不同，LEyes仅模拟视频眼动跟踪所需的关键图像特征。LEyes便于在多样化的凝视估计任务上训练神经网络。我们证明，使用LEyes训练的模型在眼睛瞳孔和CR定位方面优于其他最先进的算法。

    Deep learning has bolstered gaze estimation techniques, but real-world deployment has been impeded by inadequate training datasets. This problem is exacerbated by both hardware-induced variations in eye images and inherent biological differences across the recorded participants, leading to both feature and pixel-level variance that hinders the generalizability of models trained on specific datasets. While synthetic datasets can be a solution, their creation is both time and resource-intensive. To address this problem, we present a framework called Light Eyes or "LEyes" which, unlike conventional photorealistic methods, only models key image features required for video-based eye tracking using simple light distributions. LEyes facilitates easy configuration for training neural networks across diverse gaze-estimation tasks. We demonstrate that models trained using LEyes outperform other state-of-the-art algorithms in terms of pupil and CR localization across well-known datasets. In addit
    
[^29]: 基于保真度诱导的可解释策略提取方法用于强化学习

    Fidelity-Induced Interpretable Policy Extraction for Reinforcement Learning. (arXiv:2309.06097v1 [cs.AI])

    [http://arxiv.org/abs/2309.06097](http://arxiv.org/abs/2309.06097)

    本文提出了一种基于保真度诱导的策略提取方法（FIPE）来解决深度强化学习代理不透明的决策问题。实验证明，该方法在星际争霸 II 这样的复杂控制环境下具有良好的性能。

    

    深度强化学习在顺序决策问题上取得了显著的成功。然而，现有的深度强化学习代理以不透明的方式进行决策，阻碍了用户建立信任和审视代理的弱点。虽然最近的研究开发了一些可解释策略提取方法来解释代理的行为，但它们的解释常常与代理的行为不一致，因此经常无法解释。为了解决这个问题，我们提出了一种新方法，即基于保真度诱导的策略提取（FIPE）。具体而言，我们首先分析了现有可解释策略提取方法的优化机制，阐述了在增加累积奖励时忽视一致性的问题。然后，我们将一个保真度量集成到强化学习反馈中，设计了一个保真度诱导机制。我们在星际争霸 II 的复杂控制环境下进行实验，这是当前可解释策略提取方法通常避免的领域。

    Deep Reinforcement Learning (DRL) has achieved remarkable success in sequential decision-making problems. However, existing DRL agents make decisions in an opaque fashion, hindering the user from establishing trust and scrutinizing weaknesses of the agents. While recent research has developed Interpretable Policy Extraction (IPE) methods for explaining how an agent takes actions, their explanations are often inconsistent with the agent's behavior and thus, frequently fail to explain. To tackle this issue, we propose a novel method, Fidelity-Induced Policy Extraction (FIPE). Specifically, we start by analyzing the optimization mechanism of existing IPE methods, elaborating on the issue of ignoring consistency while increasing cumulative rewards. We then design a fidelity-induced mechanism by integrate a fidelity measurement into the reinforcement learning feedback. We conduct experiments in the complex control environment of StarCraft II, an arena typically avoided by current IPE method
    
[^30]: 一个机器学习框架用于解析电力市场价格事件的主要驱动因素

    A Machine Learning Framework to Deconstruct the Primary Drivers for Electricity Market Price Events. (arXiv:2309.06082v1 [cs.LG])

    [http://arxiv.org/abs/2309.06082](http://arxiv.org/abs/2309.06082)

    该论文提出了一个基于机器学习的分析框架，用于解析现代高可再生能源电力市场中价格飙升事件的主要驱动因素。

    

    电力网络正在向100%可再生能源的大容量电力网络转变，电力系统运行和电力市场的整体动态也在发生变化。电力市场不仅在经济上调度资源，还考虑了各种可控行动，如可再生能源限制、输电阻塞缓解和能量储存优化等，以确保电网可靠性。因此，电力市场的价格形成变得非常复杂。传统的根本原因分析和统计方法无法分析和推断现代电网和具有可变可再生能源（VRE）的市场价格形成背后的主要驱动因素。本文提出了一个基于机器学习的分析框架，用于解析现代高可再生能源电力市场中价格飙升事件的主要驱动因素。这些结果可以应用于市场设计、可再生能源调度等各个关键方面。

    Power grids are moving towards 100% renewable energy source bulk power grids, and the overall dynamics of power system operations and electricity markets are changing. The electricity markets are not only dispatching resources economically but also taking into account various controllable actions like renewable curtailment, transmission congestion mitigation, and energy storage optimization to ensure grid reliability. As a result, price formations in electricity markets have become quite complex. Traditional root cause analysis and statistical approaches are rendered inapplicable to analyze and infer the main drivers behind price formation in the modern grid and markets with variable renewable energy (VRE). In this paper, we propose a machine learning-based analysis framework to deconstruct the primary drivers for price spike events in modern electricity markets with high renewable energy. The outcomes can be utilized for various critical aspects of market design, renewable dispatch an
    
[^31]: BatMan-CLR: 使得少样本元学习器对标签噪声具有鲁棒性

    BatMan-CLR: Making Few-shots Meta-Learners Resilient Against Label Noise. (arXiv:2309.06046v1 [cs.LG])

    [http://arxiv.org/abs/2309.06046](http://arxiv.org/abs/2309.06046)

    本研究对少样本元学习器受标签噪声影响的性能进行了全面分析，发现在受到标签噪声影响的元训练中，Reptile、iMAML和foMAML在Omniglot和CifarFS数据集上的准确性下降了最高达42%。为了增强对标签噪声的鲁棒性，提出了Man和BatMan两种采样技术，将有噪声的有监督学习器转变为半监督学习器。

    

    标签噪声对于经典的监督学习已经有了深入研究，但是在元学习领域仍然是一个开放的研究问题。元学习器旨在通过在元训练中学习一个良好的初始模型，并在元测试期间根据新任务进行连续微调，以适应未知的学习任务。本文首次全面分析了不同程度的标签噪声对最先进的元学习器（特别是基于梯度的N-way K-shot学习器）性能的影响。结果表明，当元训练受到标签噪声的影响时，Reptile、iMAML和foMAML在Omniglot和CifarFS数据集上的准确性下降了最高达42%。为了增强对标签噪声的鲁棒性，我们提出了两种采样技术，即流形（Man）和批次流形（BatMan），将有噪声的有监督学习器转变为半监督学习器，以增加噪声标签的效用。我们首先构建了N-way 2-contrastiv的流形样本

    The negative impact of label noise is well studied in classical supervised learning yet remains an open research question in meta-learning. Meta-learners aim to adapt to unseen learning tasks by learning a good initial model in meta-training and consecutively fine-tuning it according to new tasks during meta-testing. In this paper, we present the first extensive analysis of the impact of varying levels of label noise on the performance of state-of-the-art meta-learners, specifically gradient-based $N$-way $K$-shot learners. We show that the accuracy of Reptile, iMAML, and foMAML drops by up to 42% on the Omniglot and CifarFS datasets when meta-training is affected by label noise. To strengthen the resilience against label noise, we propose two sampling techniques, namely manifold (Man) and batch manifold (BatMan), which transform the noisy supervised learners into semi-supervised ones to increase the utility of noisy labels. We first construct manifold samples of $N$-way $2$-contrastiv
    
[^32]: 基于启发式全局搜索的桁架结构尺寸优化问题的改进蒙特卡洛树搜索（UMCTS）算法

    Update Monte Carlo tree search (UMCTS) algorithm for heuristic global search of sizing optimization problems for truss structures. (arXiv:2309.06045v1 [cs.AI])

    [http://arxiv.org/abs/2309.06045](http://arxiv.org/abs/2309.06045)

    本文提出了一种基于启发式全局搜索的算法（UMCTS）用于桁架结构尺寸优化问题，通过结合更新过程和蒙特卡洛树搜索（MCTS）以及使用上界置信度（UCB）来获得合适的设计方案。

    

    桁架结构尺寸优化是一个复杂的计算问题，强化学习（RL）适用于处理无梯度计算的多模态问题。本研究提出了一种新的高效优化算法——更新蒙特卡洛树搜索（UMCTS），用于获得合适的桁架结构设计。UMCTS是一种基于RL的方法，将新颖的更新过程和蒙特卡洛树搜索（MCTS）与上界置信度（UCB）相结合。更新过程意味着在每一轮中，每个构件的最佳截面积通过搜索树确定，其初始状态是上一轮的最终状态。在UMCTS算法中，引入了加速选择成员面积和迭代次数的加速器，以减少计算时间。此外，对于每个状态，平均奖励被最佳奖励的模拟过程中收集来的奖励替代，确定最优解。本文提出了一种优化算法，通过结合更新过程和MCTS，以及使用UCB来优化桁架结构设计。

    Sizing optimization of truss structures is a complex computational problem, and the reinforcement learning (RL) is suitable for dealing with multimodal problems without gradient computations. In this paper, a new efficient optimization algorithm called update Monte Carlo tree search (UMCTS) is developed to obtain the appropriate design for truss structures. UMCTS is an RL-based method that combines the novel update process and Monte Carlo tree search (MCTS) with the upper confidence bound (UCB). Update process means that in each round, the optimal cross-sectional area of each member is determined by search tree, and its initial state is the final state in the previous round. In the UMCTS algorithm, an accelerator for the number of selections for member area and iteration number is introduced to reduce the computation time. Moreover, for each state, the average reward is replaced by the best reward collected on the simulation process to determine the optimal solution. The proposed optim
    
[^33]: 为人类助力灵巧抓取学习基于得分的抓取原语

    Learning Score-based Grasping Primitive for Human-assisting Dexterous Grasping. (arXiv:2309.06038v1 [cs.RO])

    [http://arxiv.org/abs/2309.06038](http://arxiv.org/abs/2309.06038)

    本文提出了一个名为“人类助力灵巧抓取”的新型任务，通过使用Grasping Gradient Field和基于历史条件的残差策略，训练控制机器人手指以适应不同用户意图和物体几何形状的灵巧抓取操作。

    

    在本文中，我们提出了一种名为“人类助力灵巧抓取”的新型任务，旨在训练控制机器人手指以帮助用户抓取物体的策略。与传统的灵巧抓取不同，这个任务面临着更复杂的挑战，因为策略需要适应不同的用户意图和物体的几何形状。我们通过提出一个由两个子模块组成的方法来解决这个挑战：一种手-物体条件抓取原语称为Grasping Gradient Field（GraspGF），以及一种基于历史条件的残差策略。GraspGF通过估计来自成功抓取示例集的梯度来学习“如何”抓取，而残差策略根据轨迹历史确定“何时”和以何种速度执行抓取动作。实验结果证明了我们方法的有效性。

    The use of anthropomorphic robotic hands for assisting individuals in situations where human hands may be unavailable or unsuitable has gained significant importance. In this paper, we propose a novel task called human-assisting dexterous grasping that aims to train a policy for controlling a robotic hand's fingers to assist users in grasping objects. Unlike conventional dexterous grasping, this task presents a more complex challenge as the policy needs to adapt to diverse user intentions, in addition to the object's geometry. We address this challenge by proposing an approach consisting of two sub-modules: a hand-object-conditional grasping primitive called Grasping Gradient Field~(GraspGF), and a history-conditional residual policy. GraspGF learns `how' to grasp by estimating the gradient from a success grasping example set, while the residual policy determines `when' and at what speed the grasping action should be executed based on the trajectory history. Experimental results demons
    
[^34]: 自动评估偿还自认技术债务所需的工作量

    Automatically Estimating the Effort Required to Repay Self-Admitted Technical Debt. (arXiv:2309.06020v1 [cs.SE])

    [http://arxiv.org/abs/2309.06020](http://arxiv.org/abs/2309.06020)

    本研究提出了一种新的方法，利用大规模的数据集自动估算自认技术债务的还款工作量。研究结果表明，不同类型的自认技术债务需要不同程度的还款工作量。

    

    技术债务是指在软件开发过程中为了短期利益而做出的次优决策所带来的后果。自认技术债务(SATD)是一种特定形式的技术债务，开发人员明确地在软件的源代码注释和提交消息中记录下来。由于SATD可能阻碍软件的开发和维护，因此有效地解决和优先处理它非常重要。然而，目前的方法缺乏根据SATD的文本描述自动评估其还款工作量的能力。为了解决这个限制，我们提出了一种新的方法，利用一个包括1,060个Apache代码库中共2,568,728个提交的341,740个SATD项目的全面数据集来自动估算SATD还款工作量。我们的研究结果表明，不同类型的SATD需要不同程度的还款工作量，其中代码/设计、需求和测试债务需要更多的工作量。

    Technical debt refers to the consequences of sub-optimal decisions made during software development that prioritize short-term benefits over long-term maintainability. Self-Admitted Technical Debt (SATD) is a specific form of technical debt, explicitly documented by developers within software artifacts such as source code comments and commit messages. As SATD can hinder software development and maintenance, it is crucial to address and prioritize it effectively. However, current methodologies lack the ability to automatically estimate the repayment effort of SATD based on its textual descriptions. To address this limitation, we propose a novel approach for automatically estimating SATD repayment effort, utilizing a comprehensive dataset comprising 341,740 SATD items from 2,568,728 commits across 1,060 Apache repositories. Our findings show that different types of SATD require varying levels of repayment effort, with code/design, requirement, and test debt demanding greater effort compa
    
[^35]: DSLOT-NN: 数字串行从左到右的神经网络加速器

    DSLOT-NN: Digit-Serial Left-to-Right Neural Network Accelerator. (arXiv:2309.06019v1 [cs.AR])

    [http://arxiv.org/abs/2309.06019](http://arxiv.org/abs/2309.06019)

    DSLOT-NN是一种数字串行从左到右的神经网络加速器，可以加速深度神经网络中的卷积运算，并且通过评估和终止无效的卷积操作实现功耗和能量的大规模节省。

    

    我们提出了一种名为DSLOT-NN的基于数字串行从左到右（DSLOT）算术处理技术，旨在加速深度神经网络（DNN）中的卷积运算推理。所提出的方法能够评估和终止无效的卷积操作，从而实现大规模的功耗和能量节省。处理引擎由低延迟的最高有效数字优先（MSDF）（也称为在线）乘法器和加法器组成，从左到右处理数据，允许后续操作以数字流水线方式执行。使用在线运算器消除了复杂的负激活识别机制的开发需求，因为首先生成具有最高权重值的输出，并且一旦生成第一个非零数字，即可识别结果的符号。在线运算器的精度可以在运行时进行调整，使其在可以牺牲精度的情况下极其有用。

    We propose a Digit-Serial Left-tO-righT (DSLOT) arithmetic based processing technique called DSLOT-NN with aim to accelerate inference of the convolution operation in the deep neural networks (DNNs). The proposed work has the ability to assess and terminate the ineffective convolutions which results in massive power and energy savings. The processing engine is comprised of low-latency most-significant-digit-first (MSDF) (also called online) multipliers and adders that processes data from left-to-right, allowing the execution of subsequent operations in digit-pipelined manner. Use of online operators eliminates the need for the development of complex mechanism of identifying the negative activation, as the output with highest weight value is generated first, and the sign of the result can be identified as soon as first non-zero digit is generated. The precision of the online operators can be tuned at run-time, making them extremely useful in situations where accuracy can be compromised 
    
[^36]: SoccerNet 2023挑战结果

    SoccerNet 2023 Challenges Results. (arXiv:2309.06006v1 [cs.CV])

    [http://arxiv.org/abs/2309.06006](http://arxiv.org/abs/2309.06006)

    SoccerNet 2023挑战是一次视频理解的比赛，包含广播视频理解、场地理解和球员理解三个主题下的多个任务。

    

    SoccerNet 2023挑战是SoccerNet团队组织的第三届年度视频理解挑战。在第三届中，挑战分为七个基于视觉的任务，分为三个主题。第一个主题是广播视频理解，包括三个与视频广播中发生事件描述相关的高级任务：(1) 动作定位，重点是检索与足球全局动作相关的全部时间戳，(2) 足球动作定位，重点是检索与足球状态改变相关的全部时间戳，以及(3) 密集视频字幕生成，重点是用自然语言和固定时间戳描述广播内容。第二个主题是场地理解，与(4) 相机校准的单一任务相关，重点是从图像中检索内部和外部相机参数。第三个也是最后一个主题，是球员理解，包括三个与提取关于球员信息相关的低级任务

    The SoccerNet 2023 challenges were the third annual video understanding challenges organized by the SoccerNet team. For this third edition, the challenges were composed of seven vision-based tasks split into three main themes. The first theme, broadcast video understanding, is composed of three high-level tasks related to describing events occurring in the video broadcasts: (1) action spotting, focusing on retrieving all timestamps related to global actions in soccer, (2) ball action spotting, focusing on retrieving all timestamps related to the soccer ball change of state, and (3) dense video captioning, focusing on describing the broadcast with natural language and anchored timestamps. The second theme, field understanding, relates to the single task of (4) camera calibration, focusing on retrieving the intrinsic and extrinsic camera parameters from images. The third and last theme, player understanding, is composed of three low-level tasks related to extracting information about the
    
[^37]: 生命启发的自主和适应智能为自主和适应性代理构建具有自主能力和自适应能力的代理一直是人工智能（AI）的终极目标。生物体是这样一个代理的最好例证，它为自适应自主性提供了重要的经验教训。在这里，我们关注内感知，这是一个监控自身内部环境来保持在一定范围内的过程，它为生物体的生存提供了基础。为了开发具有内感知的AI，我们需要将表示内部环境的状态变量与外部环境相分离，并采用生命启发的内部环境状态的数学特性。本文提出了一个新的视角，即通过将控制论、强化学习和神经科学的最新进展与生命理论相结合，内感知如何帮助构建自主和适应性代理。

    Life-inspired Interoceptive Artificial Intelligence for Autonomous and Adaptive Agents. (arXiv:2309.05999v1 [cs.AI])

    [http://arxiv.org/abs/2309.05999](http://arxiv.org/abs/2309.05999)

    该论文提出了一种基于生命理论和控制论的新视角，通过将控制论、强化学习和神经科学的最新进展与生命理论相结合，将内感知应用于构建具有自主和适应性能力的人工智能代理。

    

    构建具有自主能力和自适应能力的代理一直是人工智能（AI）的终极目标。生物体是这样一个代理的最好例证，它为自适应自主性提供了重要的经验教训。本文关注内感知，这是一个监控自身内部环境来保持在一定范围内的过程，它为生物体的生存提供了基础。为了开发具有内感知的AI，我们需要将表示内部环境的状态变量与外部环境相分离，并采用生命启发的内部环境状态的数学特性。本文提出了一个新的视角，即通过将控制论、强化学习和神经科学的最新进展与生命理论相结合，内感知如何帮助构建自主和适应性代理。

    Building autonomous --- i.e., choosing goals based on one's needs -- and adaptive -- i.e., surviving in ever-changing environments -- agents has been a holy grail of artificial intelligence (AI). A living organism is a prime example of such an agent, offering important lessons about adaptive autonomy. Here, we focus on interoception, a process of monitoring one's internal environment to keep it within certain bounds, which underwrites the survival of an organism. To develop AI with interoception, we need to factorize the state variables representing internal environments from external environments and adopt life-inspired mathematical properties of internal environment states. This paper offers a new perspective on how interoception can help build autonomous and adaptive agents by integrating the legacy of cybernetics with recent advances in theories of life, reinforcement learning, and neuroscience.
    
[^38]: 在人类中心的视频中，基于知识引导的短上下文行动预测

    Knowledge-Guided Short-Context Action Anticipation in Human-Centric Videos. (arXiv:2309.05943v1 [cs.CV])

    [http://arxiv.org/abs/2309.05943](http://arxiv.org/abs/2309.05943)

    该论文提出了一种基于知识引导的短上下文行动预测方法，在人类中心的视频中，通过使用短视频片段来预测长期的人类行动，提高了编辑工作流程的速度和创作性，通过增强变换器网络的注意机制，在行动预测方面取得了优于当前最先进方法9%的性能。

    

    本研究旨在通过使用短视频片段来预测长期的人类行动，从而通过提供更好的建议来加快编辑工作流程，同时通过提供叙事来培养创造力。为此，我们运用符号化知识图谱来增强变换器网络在视频片段中的行动预测能力，通过在运行时提升变换器的注意机制的某些方面。在两个基准数据集Breakfast和50Salads上的演示中，我们的方法通过使用短视频上下文进行长期行动预测，超过了当前最先进的方法9%。

    This work focuses on anticipating long-term human actions, particularly using short video segments, which can speed up editing workflows through improved suggestions while fostering creativity by suggesting narratives. To this end, we imbue a transformer network with a symbolic knowledge graph for action anticipation in video segments by boosting certain aspects of the transformer's attention mechanism at run-time. Demonstrated on two benchmark datasets, Breakfast and 50Salads, our approach outperforms current state-of-the-art methods for long-term action anticipation using short video context by up to 9%.
    
[^39]: 通过总结多源多视角知识回答产品的主观归纳问题

    Answering Subjective Induction Questions on Products by Summarizing Multi-sources Multi-viewpoints Knowledge. (arXiv:2309.05938v1 [cs.CL])

    [http://arxiv.org/abs/2309.05938](http://arxiv.org/abs/2309.05938)

    本文提出了一个新任务：回答产品的主观归纳问题（SUBJPQA）。与传统的QA任务不同，这类问题的答案是非唯一的，并且需要从多个角度总结多个知识源的主观意见和客观知识来解释。为了解决这个任务，我们提出了一个三步骤的方法，包括信息检索、相关性捕捉和摘要生成。

    

    本文在回答产品的主观归纳问题（SUBJPQA）的领域中提出了一个新任务。这类问题的答案是非唯一的，但可以从多个角度来解释。例如，对于“手机是否重”的答案有多种不同的观点。一个满意的答案应该能够总结这些来自多个来源的主观意见，并提供客观知识，比如手机的重量。这与传统的QA任务非常不同，传统QA任务中对于事实问题的答案是唯一的，并且可以从单个数据源中找到。为了解决这个新任务，我们提出了一个三步骤的方法。首先，我们从多个知识源中检索所有与答案相关的线索，包括事实和观点。还收集了隐含的常识事实来补充必要但缺失的背景信息。然后，我们通过交互式注意力来捕捉它们与问题的相关性。接下来，我们设计了一个基于强化学习的摘要生成器来聚合这些信息。

    This paper proposes a new task in the field of Answering Subjective Induction Question on Products (SUBJPQA). The answer to this kind of question is non-unique, but can be interpreted from many perspectives. For example, the answer to 'whether the phone is heavy' has a variety of different viewpoints. A satisfied answer should be able to summarize these subjective opinions from multiple sources and provide objective knowledge, such as the weight of a phone. That is quite different from the traditional QA task, in which the answer to a factoid question is unique and can be found from a single data source. To address this new task, we propose a three-steps method. We first retrieve all answer-related clues from multiple knowledge sources on facts and opinions. The implicit commonsense facts are also collected to supplement the necessary but missing contexts. We then capture their relevance with the questions by interactive attention. Next, we design a reinforcement-based summarizer to ag
    
[^40]: MatSciML: 用于固态材料建模的广泛、多任务基准

    MatSciML: A Broad, Multi-Task Benchmark for Solid-State Materials Modeling. (arXiv:2309.05934v1 [cond-mat.mtrl-sci])

    [http://arxiv.org/abs/2309.05934](http://arxiv.org/abs/2309.05934)

    MatSciML是一个用于固态材料建模的多任务基准，通过提供多样化的材料系统和属性数据，解决了该领域中方法性能比较困难的问题。

    

    我们提出了MatSciML，这是一个针对具有周期性晶体结构的固态材料建模的机器学习基准。将机器学习方法应用于固态材料是一个新兴领域，由于所使用的数据集的种类繁多，导致领域内存在着较大的分散性。这种分散性使得比较不同方法的性能和泛化能力变得困难，从而阻碍了该领域的整体研究进展。在开源数据集的基础上，包括OpenCatalyst、OQMD、NOMAD、Carolina材料数据库和Materials Project等大规模数据集，MatSciML基准为模型的训练和评估提供了多样化的材料系统和属性数据，包括模拟能量、原子力、材料能隙以及通过空间群进行晶体对称性的分类数据。

    We propose MatSci ML, a novel benchmark for modeling MATerials SCIence using Machine Learning (MatSci ML) methods focused on solid-state materials with periodic crystal structures. Applying machine learning methods to solid-state materials is a nascent field with substantial fragmentation largely driven by the great variety of datasets used to develop machine learning models. This fragmentation makes comparing the performance and generalizability of different methods difficult, thereby hindering overall research progress in the field. Building on top of open-source datasets, including large-scale datasets like the OpenCatalyst, OQMD, NOMAD, the Carolina Materials Database, and Materials Project, the MatSci ML benchmark provides a diverse set of materials systems and properties data for model training and evaluation, including simulated energies, atomic forces, material bandgaps, as well as classification data for crystal symmetries via space groups. The diversity of properties in MatSc
    
[^41]: 结合深度学习和街景图像来绘制小农户农作物类型的地图

    Combining deep learning and street view imagery to map smallholder crop types. (arXiv:2309.05930v1 [cs.CV])

    [http://arxiv.org/abs/2309.05930](http://arxiv.org/abs/2309.05930)

    本研究利用深度学习和街景图像开发了一个自动化系统，可以生成农作物类型地面参考，解决了在低收入和中等收入国家创建农作物类型地图时的挑战。

    

    准确的农作物类型地图对于监测规模的产量进展、预测全球农作物生产和制定有效政策是一种必要的信息来源。然而，由于在训练机器学习模型时缺乏地面真实标签，迄今为止，低收入和中等收入国家的农作物类型地图制作仍具有挑战性。田间调查在准确性方面是黄金标准，但需要大量的时间、金钱和统计能力。近年来，全球范围内提供了街景图像（如Google Street View，KartaView和Mapillary）。这些图像包含了特定位置和时间的农作物种类的丰富信息。在这项工作中，我们开发了一个使用深度学习和Google Street View图像生成农作物类型地面参考的自动化系统。该方法有效地筛选了一组包含农田的街景图像，通过利用弱标签训练模型来预测农作物类型。

    Accurate crop type maps are an essential source of information for monitoring yield progress at scale, projecting global crop production, and planning effective policies. To date, however, crop type maps remain challenging to create in low and middle-income countries due to a lack of ground truth labels for training machine learning models. Field surveys are the gold standard in terms of accuracy but require an often-prohibitively large amount of time, money, and statistical capacity. In recent years, street-level imagery, such as Google Street View, KartaView, and Mapillary, has become available around the world. Such imagery contains rich information about crop types grown at particular locations and times. In this work, we develop an automated system to generate crop type ground references using deep learning and Google Street View imagery. The method efficiently curates a set of street view images containing crop fields, trains a model to predict crop type by utilizing weakly-label
    
[^42]: 针对生物信号的频率感知掩码自编码器的多模态预训练

    Frequency-Aware Masked Autoencoders for Multimodal Pretraining on Biosignals. (arXiv:2309.05927v1 [cs.LG])

    [http://arxiv.org/abs/2309.05927](http://arxiv.org/abs/2309.05927)

    本研究提出了一种名为$\texttt{bio}$FAME的频率感知掩码自编码器，用于多模态生物信号的预训练。其通过在频率空间中对生物信号进行表示参数化，利用固定大小的傅里叶变换运算符进行全局令牌混合，并通过频率维持预训练策略保持每个输入通道中的频率成分。

    

    利用来自生物信号的多模态信息对人们的身心状态进行综合建模非常重要。然而，多模态生物信号通常在预训练和推断数据集之间存在重大的分布偏移，这源于任务规范的变化或者模态组合的差异。为了在潜在分布偏移的情况下实现有效的预训练，我们提出了一种频率感知的掩码自编码器（$\texttt{bio}$FAME），该自编码器学习在频率空间中对生物信号的表示进行参数化。$\texttt{bio}$FAME包含一个频率感知变压器，利用基于傅里叶变换的固定大小的运算符进行全局令牌混合，与输入的长度和采样率无关。为了保持每个输入通道中的频率成分，我们还采用了一种频率维持预训练策略，在潜空间中执行掩码自编码。最终的架构有效地捕获不同任务间的频率特征和模态组合的变化。

    Leveraging multimodal information from biosignals is vital for building a comprehensive representation of people's physical and mental states. However, multimodal biosignals often exhibit substantial distributional shifts between pretraining and inference datasets, stemming from changes in task specification or variations in modality compositions. To achieve effective pretraining in the presence of potential distributional shifts, we propose a frequency-aware masked autoencoder ($\texttt{bio}$FAME) that learns to parameterize the representation of biosignals in the frequency space. $\texttt{bio}$FAME incorporates a frequency-aware transformer, which leverages a fixed-size Fourier-based operator for global token mixing, independent of the length and sampling rate of inputs. To maintain the frequency components within each input channel, we further employ a frequency-maintain pretraining strategy that performs masked autoencoding in the latent space. The resulting architecture effectivel
    
[^43]: 关于正则稀疏逻辑回归的研究

    On Regularized Sparse Logistic Regression. (arXiv:2309.05925v1 [cs.LG])

    [http://arxiv.org/abs/2309.05925](http://arxiv.org/abs/2309.05925)

    本文提出了解决正则稀疏逻辑回归的方法，包括$\ell_1$正则化稀疏逻辑回归和一些满足先决条件的非凸惩罚正则化稀疏逻辑回归。经验实验表明，这些算法能够以较低的计算成本有效地进行分类和特征选择。

    

    稀疏逻辑回归旨在同时进行高维数据的分类和特征选择。虽然有许多研究解决了$\ell_1$正则化逻辑回归问题，但对于与非凸惩罚相关的稀疏逻辑回归解决方案并没有等量的文献。本文提出了解决$\ell_1$正则化稀疏逻辑回归和一些满足一定先决条件的非凸惩罚正则化稀疏逻辑回归的方法，并采用类似的优化框架。在提出的优化框架中，我们利用不同的线搜索准则来保证不同正则化项的良好收敛性能。通过对真实世界数据集的二元分类任务进行经验实验，我们证明了我们提出的算法能够以较低的计算成本有效地进行分类和特征选择。

    Sparse logistic regression aims to perform classification and feature selection simultaneously for high-dimensional data. Although many studies have been done to solve $\ell_1$-regularized logistic regression, there is no equivalently abundant literature about solving sparse logistic regression associated with nonconvex penalties. In this paper, we propose to solve $\ell_1$-regularized sparse logistic regression and some nonconvex penalties-regularized sparse logistic regression, when the nonconvex penalties satisfy some prerequisites, with similar optimization frameworks. In the proposed optimization frameworks, we utilize different line search criteria to guarantee good convergence performance for different regularization terms. Empirical experiments on binary classification tasks with real-world datasets demonstrate our proposed algorithms are capable of performing classification and feature selection effectively with a lower computational cost.
    
[^44]: 对大型基础模型中幻觉的调查

    A Survey of Hallucination in Large Foundation Models. (arXiv:2309.05922v1 [cs.AI])

    [http://arxiv.org/abs/2309.05922](http://arxiv.org/abs/2309.05922)

    本文调查了大型基础模型中的幻觉问题，包括幻觉现象的分类、评估标准和减轻幻觉的策略，并讨论了未来研究方向。

    

    基础模型中的幻觉指的是生成偏离事实的内容或包含虚构信息。本研究概述了近期努力的广泛概述，这些努力旨在识别、阐明和解决幻觉问题，特别关注“大”基础模型（LFMs）。本文对特定于LFMs的各种类型的幻觉现象进行了分类，并建立了评估幻觉程度的评估标准。它还检查了减轻LFM中幻觉的现有策略，并讨论了未来研究的潜在方向。本文全面探讨了与LFMs中幻觉相关的挑战和解决方案。

    Hallucination in a foundation model (FM) refers to the generation of content that strays from factual reality or includes fabricated information. This survey paper provides an extensive overview of recent efforts that aim to identify, elucidate, and tackle the problem of hallucination, with a particular focus on ``Large'' Foundation Models (LFMs). The paper classifies various types of hallucination phenomena that are specific to LFMs and establishes evaluation criteria for assessing the extent of hallucination. It also examines existing strategies for mitigating hallucination in LFMs and discusses potential directions for future research in this area. Essentially, the paper offers a comprehensive examination of the challenges and solutions related to hallucination in LFMs.
    
[^45]: SAGE: 针对十亿级产品目录的结构化属性值生成

    SAGE: Structured Attribute Value Generation for Billion-Scale Product Catalogs. (arXiv:2309.05920v1 [cs.IR])

    [http://arxiv.org/abs/2309.05920](http://arxiv.org/abs/2309.05920)

    SAGE是一个用于在十亿级产品目录中生成属性值的模型，可以处理跨语言、产品类型和目标属性的问题。它采用了一种新颖的建模方法，可以推断隐式使用迂回语言提到的属性值，并且能够预测属性的不适用性和无法从可用信息中获取属性值。

    

    我们引入了SAGE，一个用于在全球电子商务目录中推断产品属性值的生成模型。我们将属性值预测问题以一种新颖的方式转化为跨语言、产品类型和目标属性的Seq2Seq摘要任务。我们的新模型方法不再局限于在预先指定的选项集内预测属性值，并且也不要求所寻找的属性值在文本中明确提及。SAGE可以推断隐式使用迂回语言提到的属性值，或者根本不提及的常识默认情况下的属性值。此外，SAGE能够预测一个属性对于当前产品是否不适用，或者是否无法从可用信息中获取。SAGE是第一种能够在实际电子商务目录设置中处理属性值预测任务所有方面的方法。一套综合的...

    We introduce SAGE; a Generative LLM for inferring attribute values for products across world-wide e-Commerce catalogs. We introduce a novel formulation of the attribute-value prediction problem as a Seq2Seq summarization task, across languages, product types and target attributes. Our novel modeling approach lifts the restriction of predicting attribute values within a pre-specified set of choices, as well as, the requirement that the sought attribute values need to be explicitly mentioned in the text. SAGE can infer attribute values even when such values are mentioned implicitly using periphrastic language, or not-at-all-as is the case for common-sense defaults. Additionally, SAGE is capable of predicting whether an attribute is inapplicable for the product at hand, or non-obtainable from the available information. SAGE is the first method able to tackle all aspects of the attribute-value-prediction task as they arise in practical settings in e-Commerce catalogs. A comprehensive set o
    
[^46]: 随机LLMs无法理解语言：走向符号化、可解释性和本体论基于的LLMs

    Stochastic LLMs do not Understand Language: Towards Symbolic, Explainable and Ontologically Based LLMs. (arXiv:2309.05918v1 [cs.CL])

    [http://arxiv.org/abs/2309.05918](http://arxiv.org/abs/2309.05918)

    随机LLMs无法理解语言的原因是它们无法提供可以依赖的事实信息，它们存储的语言知识埋藏在无意义的微特征中，并在某些语言上下文中无法进行正确推理。本文建议在符号化方法中应用有效的自下而上策略

    

    在我们看来，围绕数据驱动的大型语言模型（LLMs）相对成功的狂热是有些误导的，原因如下：（i）LLMs不能依赖于事实信息，因为对于LLMs来说，摄入的所有文本（事实或非事实）都是平等的；（ii）由于它们的亚符号性质，这些模型对语言的任何“知识”都将永远埋藏在数十亿个微特征（权重）中，其中没有一个本身是有意义的；以及（iii）LLMs在几种语言上下文中常常无法进行正确推理（如名词复合词、共谓词、量词范围模糊和意向性上下文）。我们相信，数据驱动的大型语言模型（LLMs）的相对成功不是符号与亚符号之辩的反映，而是在规模上应用自下而上的逆向工程语言的成功策略的反映。在本文中，我们建议将有效的自下而上策略应用于符号化方法中

    In our opinion the exuberance surrounding the relative success of data-driven large language models (LLMs) is slightly misguided and for several reasons (i) LLMs cannot be relied upon for factual information since for LLMs all ingested text (factual or non-factual) was created equal; (ii) due to their subsymbolic na-ture, whatever 'knowledge' these models acquire about language will always be buried in billions of microfeatures (weights), none of which is meaningful on its own; and (iii) LLMs will often fail to make the correct inferences in several linguistic contexts (e.g., nominal compounds, copredication, quantifier scope ambi-guities, intensional contexts. Since we believe the relative success of data-driven large language models (LLMs) is not a reflection on the symbolic vs. subsymbol-ic debate but a reflection on applying the successful strategy of a bottom-up reverse engineering of language at scale, we suggest in this paper applying the effective bottom-up strategy in a symbol
    
[^47]: 通过优势调节使用动态规划增强决策Transformer

    ACT: Empowering Decision Transformer with Dynamic Programming via Advantage Conditioning. (arXiv:2309.05915v1 [cs.LG])

    [http://arxiv.org/abs/2309.05915](http://arxiv.org/abs/2309.05915)

    这篇论文提出了一种通过将动态规划应用于决策Transformer来增强其能力的方法。作者提出了三个步骤来实现这一目标：使用样本内值迭代获得近似值函数，结合估计的优势评估动作质量，并训练ACT生成基于估计优势的动作。该方法在测试中表现出良好的性能。

    

    决策Transformer (DT) 利用表达丰富的序列建模技术来执行动作生成，已成为离线策略优化的一种有前景的方法。然而，DT 生成的动作是基于期望未来回报的条件，已知具有某些弱点，比如易受环境随机性影响。为了克服DT的弱点，我们提出了在DT中增加动态规划能力的方法。我们的方法包括三个步骤。首先，我们使用样本内值迭代来获得近似值函数，这涉及到MDP结构上的动态规划。第二，我们结合估计的优势来评估动作的质量。我们引入了两种优势估计器，分别适用于不同的任务。第三，我们训练了一个以估计的优势为条件生成动作的优势条件Transformer (ACT)。最后，在测试阶段，ACT根据所需的优势生成动作。我们的评估结果表明...

    Decision Transformer (DT), which employs expressive sequence modeling techniques to perform action generation, has emerged as a promising approach to offline policy optimization. However, DT generates actions conditioned on a desired future return, which is known to bear some weaknesses such as the susceptibility to environmental stochasticity. To overcome DT's weaknesses, we propose to empower DT with dynamic programming. Our method comprises three steps. First, we employ in-sample value iteration to obtain approximated value functions, which involves dynamic programming over the MDP structure. Second, we evaluate action quality in context with estimated advantages. We introduce two types of advantage estimators, IAE and GAE, which are suitable for different tasks. Third, we train an Advantage-Conditioned Transformer (ACT) to generate actions conditioned on the estimated advantages. Finally, during testing, ACT generates actions conditioned on a desired advantage. Our evaluation resul
    
[^48]: 与模型内协作学习无关质量的深度伪造检测

    Quality-Agnostic Deepfake Detection with Intra-model Collaborative Learning. (arXiv:2309.05911v1 [cs.CV])

    [http://arxiv.org/abs/2309.05911](http://arxiv.org/abs/2309.05911)

    本论文提出了一种无关质量的深度伪造检测方法(QAD)，通过模型内协作学习方法实现了同时检测不同质量的深度伪造。是一种具有实际应用可行性和可扩展性的方法。

    

    近年来，深度伪造引发了诸多社会关注，可能对安全造成威胁并传播虚假信息。已经有很多关于深度伪造检测的研究，但是同时检测低质量和不同质量的深度伪造仍然是一个严峻的挑战。大多数先进方法仅使用单一特定模型来检测特定的深度伪造视频质量类型，这种策略在构建多个模型时会产生显著的计算成本、模型和训练数据开销，而且在实际应用中无法实现可扩展性和实用性。本研究提出了一种通用的模型内协作学习框架，实现了不同质量深度伪造的有效同时检测。换句话说，我们的方法是一种无关质量的深度伪造检测方法，称为QAD。通过观察上界

    Deepfake has recently raised a plethora of societal concerns over its possible security threats and dissemination of fake information. Much research on deepfake detection has been undertaken. However, detecting low quality as well as simultaneously detecting different qualities of deepfakes still remains a grave challenge. Most SOTA approaches are limited by using a single specific model for detecting certain deepfake video quality type. When constructing multiple models with prior information about video quality, this kind of strategy incurs significant computational cost, as well as model and training data overhead. Further, it cannot be scalable and practical to deploy in real-world settings. In this work, we propose a universal intra-model collaborative learning framework to enable the effective and simultaneous detection of different quality of deepfakes. That is, our approach is the quality-agnostic deepfake detection method, dubbed QAD . In particular, by observing the upper bou
    
[^49]: 大规模语言模型的战略行为：游戏结构与情境框架

    Strategic Behavior of Large Language Models: Game Structure vs. Contextual Framing. (arXiv:2309.05898v1 [cs.GT])

    [http://arxiv.org/abs/2309.05898](http://arxiv.org/abs/2309.05898)

    本文研究了三种大规模语言模型在博弈论框架下的战略决策能力，并发现GPT-3.5对情境框架敏感但抽象战略推理能力有限，而GPT-4和LLaMa-2在游戏结构和情境下能调整策略，但LLaMa-2在游戏机制的理解上更加微妙。

    

    本文研究了三种大规模语言模型（LLM）：GPT-3.5、GPT-4和LLaMa-2在博弈论框架下的战略决策能力。通过使用四种典型的双人博弈游戏——囚徒困境、猎兔、雪崩和囚徒的喜悦——我们探讨了这些模型在社会困境中的导航方式，即玩家可以合作获得集体利益，也可以为了个人利益而背叛。关键是，我们扩展了分析，研究情境框架（如外交关系或非正式友谊）在塑造模型决策中的作用。我们的研究结果揭示了一个复杂的景观：虽然GPT-3.5对情境框架非常敏感，但它在抽象战略推理方面能力有限。而GPT-4和LLaMa-2根据游戏结构和情境调整策略，但LLaMa-2在对游戏潜在机制的理解上更加微妙。这些结果突显了当前的局限性和多样化。

    This paper investigates the strategic decision-making capabilities of three Large Language Models (LLMs): GPT-3.5, GPT-4, and LLaMa-2, within the framework of game theory. Utilizing four canonical two-player games -- Prisoner's Dilemma, Stag Hunt, Snowdrift, and Prisoner's Delight -- we explore how these models navigate social dilemmas, situations where players can either cooperate for a collective benefit or defect for individual gain. Crucially, we extend our analysis to examine the role of contextual framing, such as diplomatic relations or casual friendships, in shaping the models' decisions. Our findings reveal a complex landscape: while GPT-3.5 is highly sensitive to contextual framing, it shows limited ability to engage in abstract strategic reasoning. Both GPT-4 and LLaMa-2 adjust their strategies based on game structure and context, but LLaMa-2 exhibits a more nuanced understanding of the games' underlying mechanics. These results highlight the current limitations and varied p
    
[^50]: 仿生神经网络用于外部模拟人类运动系统

    The bionic neural network for external simulation of human locomotor system. (arXiv:2309.05863v1 [cs.LG])

    [http://arxiv.org/abs/2309.05863](http://arxiv.org/abs/2309.05863)

    本文提出了一种基于肌肉骨骼模拟和物理信息深度学习的方法，用于预测关节运动和肌肉力量。

    

    用肌肉骨骼模拟技术估计的肌肉力量和关节动力学提供了描述运动质量的有用指标。基于模型的计算机肌肉骨骼模型能够解释神经驱动肌肉、肌肉动力学、身体和关节动力学以及动力学之间的动态相互作用。然而，这些解决方案在复杂模型中存在计算时间长和肌肉招募问题。近年来，基于数据驱动的方法已经成为一种有前途的替代方案，因为它具有灵活性和适应性的优势。然而，获得大量标记的训练数据并不容易。本文提出了一种基于肌肉骨骼模拟的物理信息深度学习方法，用于预测关节运动和肌肉力量。将肌肉骨骼模型嵌入神经网络中作为一个带有生理参数的常微分方程（ODE）损失函数，用于识别肌肉激活动力学和肌肉收缩动力学。

    Muscle forces and joint kinematics estimated with musculoskeletal (MSK) modeling techniques offer useful metrics describing movement quality. Model-based computational MSK models can interpret the dynamic interaction between the neural drive to muscles, muscle dynamics, body and joint kinematics, and kinetics. Still, such a set of solutions suffers from high computational time and muscle recruitment problems, especially in complex modeling. In recent years, data-driven methods have emerged as a promising alternative due to the benefits of flexibility and adaptability. However, a large amount of labeled training data is not easy to be acquired. This paper proposes a physics-informed deep learning method based on MSK modeling to predict joint motion and muscle forces. The MSK model is embedded into the neural network as an ordinary differential equation (ODE) loss function with physiological parameters of muscle activation dynamics and muscle contraction dynamics to be identified. These 
    
[^51]: 揭示Transformer中的mesa-optimization算法

    Uncovering mesa-optimization algorithms in Transformers. (arXiv:2309.05858v1 [cs.LG])

    [http://arxiv.org/abs/2309.05858](http://arxiv.org/abs/2309.05858)

    本研究揭示了Transformer模型中的mesa-optimization算法，该算法通过内部学习目标和相应的优化解决方案驱动预测生成。研究还发现，这种学习的优化算法可以被应用于解决监督式少样本任务，暗示了mesa-optimization可能是大型语言模型上下文学习能力的基础。

    

    Transformer已经成为深度学习中主导的模型，但其卓越性能的原因尚不清楚。我们假设Transformer的强大性能源于其架构中对mesa-optimization的偏好，即一个学习过程在模型的前向传递中运行，由以下两个步骤组成：（i）构建内部学习目标，和（ii）通过优化找到相应的解决方案。为了验证这个假设，我们对一系列在简单序列建模任务上训练的自回归Transformer进行了逆向工程，揭示了驱动预测生成的基于梯度的底层mesa-optimization算法。此外，我们还展示了学习的前向传递优化算法可以立即被重新应用于解决监督式少样本任务，这表明mesa-optimization可能是大型语言模型的上下文学习能力的基础。最后，我们提出了一种新颖的自注意力机制。

    Transformers have become the dominant model in deep learning, but the reason for their superior performance is poorly understood. Here, we hypothesize that the strong performance of Transformers stems from an architectural bias towards mesa-optimization, a learned process running within the forward pass of a model consisting of the following two steps: (i) the construction of an internal learning objective, and (ii) its corresponding solution found through optimization. To test this hypothesis, we reverse-engineer a series of autoregressive Transformers trained on simple sequence modeling tasks, uncovering underlying gradient-based mesa-optimization algorithms driving the generation of predictions. Moreover, we show that the learned forward-pass optimization algorithm can be immediately repurposed to solve supervised few-shot tasks, suggesting that mesa-optimization might underlie the in-context learning capabilities of large language models. Finally, we propose a novel self-attention 
    
[^52]: 在多元时间序列医疗数据上进行有效的异常活动检测

    Effective Abnormal Activity Detection on Multivariate Time Series Healthcare Data. (arXiv:2309.05845v1 [cs.LG])

    [http://arxiv.org/abs/2309.05845](http://arxiv.org/abs/2309.05845)

    在多元时间序列医疗数据上，我们提出了一种基于残差的异常检测方法，用于有效的表示学习和异常活动检测。实验结果显示F1分数为0.839。

    

    多元时间序列（MTS）数据通过多个传感器收集，为智能医疗场景中准确的异常活动检测提供了潜力。然而，异常表现出多样的模式，并且在MTS数据中变得不容易察觉。因此，实现准确的异常检测是具有挑战性的，我们需要捕捉时间序列的时间依赖性和变量之间的相互关系。为了解决这个问题，我们提出了一种基于残差的异常检测方法Rs-AD，用于有效的表示学习和异常活动检测。我们在一个真实的步态数据集上评估了我们的方案，实验结果显示F1分数为0.839。

    Multivariate time series (MTS) data collected from multiple sensors provide the potential for accurate abnormal activity detection in smart healthcare scenarios. However, anomalies exhibit diverse patterns and become unnoticeable in MTS data. Consequently, achieving accurate anomaly detection is challenging since we have to capture both temporal dependencies of time series and inter-relationships among variables. To address this problem, we propose a Residual-based Anomaly Detection approach, Rs-AD, for effective representation learning and abnormal activity detection. We evaluate our scheme on a real-world gait dataset and the experimental results demonstrate an F1 score of 0.839.
    
[^53]: PACE: 使用GPT-4进行云事件根本原因分析中的提示和增加以进行校准的置信度估计

    PACE: Prompting and Augmentation for Calibrated Confidence Estimation with GPT-4 in Cloud Incident Root Cause Analysis. (arXiv:2309.05833v1 [cs.CL])

    [http://arxiv.org/abs/2309.05833](http://arxiv.org/abs/2309.05833)

    本文提出了一种通过提示检索增强的大语言模型（LLM）来增强云事件根本原因分析工具中置信度估计的方法。

    

    近年来，IT行业向基于云的平台的转变强调了云事件根本原因分析的重要性，以确保服务的可靠性和维护客户信任。核心问题是有效确定根本原因，由于当代云基础设施的复杂性，这一任务变得具有挑战性。尽管出现了许多用于根本原因识别的基于AI的工具，但它们的适用性仍受到其输出质量不一致的限制。本文介绍了一种通过提示检索增强的大语言模型（LLM）来增强根本原因分析工具中置信度估计的方法。此方法分为两个阶段。首先，模型根据历史事件数据评估自身的置信度，考虑其对证据的评估强度。然后，模型审核由预测器生成的根本原因。然后，优化步骤将这些评估结合起来确定最终的置信度估计。

    In recent years, the transition to cloud-based platforms in the IT sector has emphasized the significance of cloud incident root cause analysis to ensure service reliability and maintain customer trust. Central to this process is the efficient determination of root causes, a task made challenging due to the complex nature of contemporary cloud infrastructures. Despite the proliferation of AI-driven tools for root cause identification, their applicability remains limited by the inconsistent quality of their outputs. This paper introduces a method for enhancing confidence estimation in root cause analysis tools by prompting retrieval-augmented large language models (LLMs). This approach operates in two phases. Initially, the model evaluates its confidence based on historical incident data, considering its assessment of the evidence strength. Subsequently, the model reviews the root cause generated by the predictor. An optimization step then combines these evaluations to determine the fin
    
[^54]: 研究使用可穿戴传感器解决工作场所安全问题中，基于实验室承载数据训练的机器学习模型的准确性

    Studying Accuracy of Machine Learning Models Trained on Lab Lifting Data in Solving Real-World Problems Using Wearable Sensors for Workplace Safety. (arXiv:2309.05831v1 [cs.LG])

    [http://arxiv.org/abs/2309.05831](http://arxiv.org/abs/2309.05831)

    本文研究了将实验室训练的机器学习模型应用于真实世界时的准确性问题，并提出了四种潜在解决方案。

    

    将实验室数据训练的机器学习模型应用于现实世界一直以来都是一个挑战。本文讨论了将实验室训练的举重识别模型移植到现实世界的问题。与训练数据相比，模型的性能要低得多，我们探讨了失败的原因，并提出了四种潜在解决方案来提高模型性能。

    Porting ML models trained on lab data to real-world situations has long been a challenge. This paper discusses porting a lab-trained lifting identification model to the real-world. With performance much lower than on training data, we explored causes of the failure and proposed four potential solutions to increase model performance
    
[^55]: 探索几何深度学习在降水预测中的应用

    Exploring Geometric Deep Learning For Precipitation Nowcasting. (arXiv:2309.05828v1 [cs.LG])

    [http://arxiv.org/abs/2309.05828](http://arxiv.org/abs/2309.05828)

    本论文探索了几何深度学习在降水预测中的应用，采用了基于时间的图卷积网络（GCN）模型，该模型能够更好地捕捉地理网格之间的动态空间关系。

    

    降水预测（几小时内）仍然是一项挑战，因为需要准确捕捉复杂的局部相互作用。卷积神经网络依赖于卷积核与网格数据进行卷积，并且提取的特征受限于有限的感知域，通常表现为与真实数据相比过度平滑的输出。因此，它们缺乏对网格之间复杂空间关系的建模能力。几何深度学习旨在将神经网络模型推广到非欧几里德域。这些模型在定义节点和边缘方面更加灵活，并且能够有效地捕捉地理网格之间的动态空间关系。受此启发，我们探索了一种基于几何深度学习的时间图卷积网络（GCN）应用于降水预测。自动学习描述网格单元之间相互作用的邻接矩阵，通过最小化预测值与真实像素值之间的L1损失来实现。

    Precipitation nowcasting (up to a few hours) remains a challenge due to the highly complex local interactions that need to be captured accurately. Convolutional Neural Networks rely on convolutional kernels convolving with grid data and the extracted features are trapped by limited receptive field, typically expressed in excessively smooth output compared to ground truth. Thus they lack the capacity to model complex spatial relationships among the grids. Geometric deep learning aims to generalize neural network models to non-Euclidean domains. Such models are more flexible in defining nodes and edges and can effectively capture dynamic spatial relationship among geographical grids. Motivated by this, we explore a geometric deep learning-based temporal Graph Convolutional Network (GCN) for precipitation nowcasting. The adjacency matrix that simulates the interactions among grid cells is learned automatically by minimizing the L1 loss between prediction and ground truth pixel value durin
    
[^56]: PhotoVerse: 无需调参的文本到图像定制化模型

    PhotoVerse: Tuning-Free Image Customization with Text-to-Image Diffusion Models. (arXiv:2309.05793v1 [cs.CV])

    [http://arxiv.org/abs/2309.05793](http://arxiv.org/abs/2309.05793)

    PhotoVerse是一种无需调参的文本到图像定制化模型，通过双分支调节机制和面部身份损失增强了图像生成过程中的控制能力和身份保留能力，并且仅依赖目标身份的一张面部照片来显著降低图像生成的资源成本。

    

    个性化文本到图像生成已成为一种强大且受追捧的工具，赋予用户根据特定概念和提示创建定制图像的能力。然而，现有的个性化方法面临诸多挑战，包括长时间调参、大量存储需求、对每个身份需要多个输入图像的必要性以及在保留身份和可编辑性方面的限制。为了解决这些障碍，我们提出了一种创新的方法——PhotoVerse，在文本和图像领域中引入了双分支调节机制，从而有效控制图像生成过程。此外，我们还引入了面部身份损失作为一种新颖的组成部分，提升了训练过程中身份保留的能力。值得注意的是，我们的PhotoVerse方法无需测试时间调参，仅依赖目标身份的一张面部照片，显著降低了图像生成所需的资源成本。

    Personalized text-to-image generation has emerged as a powerful and sought-after tool, empowering users to create customized images based on their specific concepts and prompts. However, existing approaches to personalization encounter multiple challenges, including long tuning times, large storage requirements, the necessity for multiple input images per identity, and limitations in preserving identity and editability. To address these obstacles, we present PhotoVerse, an innovative methodology that incorporates a dual-branch conditioning mechanism in both text and image domains, providing effective control over the image generation process. Furthermore, we introduce facial identity loss as a novel component to enhance the preservation of identity during training. Remarkably, our proposed PhotoVerse eliminates the need for test time tuning and relies solely on a single facial photo of the target identity, significantly reducing the resource cost associated with image generation. After
    
[^57]: 自适应用户中心的神经符号学习在多模态交互中的应用于自主系统

    Adaptive User-centered Neuro-symbolic Learning for Multimodal Interaction with Autonomous Systems. (arXiv:2309.05787v1 [cs.AI])

    [http://arxiv.org/abs/2309.05787](http://arxiv.org/abs/2309.05787)

    这篇论文提出了一种自适应用户中心的神经符号学习方法，用于支持多模态交互中自主系统对物体和环境的符号化理解能力的提升。

    

    最近在机器学习，特别是深度学习方面取得的进展使得自主系统能够以感知的非符号化方式识别和理解对象及其环境。这些系统现在可以执行物体检测、传感器数据融合和语言理解任务。然而，要提升这些系统对对象及其环境的概念和符号理解能力，需要综合考虑人类提供的显性教导（例如描述情况或解释如何行动）和通过观察人类行为（通过系统的传感器）获得的隐性教导。因此，系统必须设计具有多模态输入和输出能力，以支持隐性和显性交互模型。在这篇文章中，我们主张同时考虑这两种类型的输入，以及人在循环中的参与和增量学习技术，以推进这一强大的人工智能水平的实现。

    Recent advances in machine learning, particularly deep learning, have enabled autonomous systems to perceive and comprehend objects and their environments in a perceptual subsymbolic manner. These systems can now perform object detection, sensor data fusion, and language understanding tasks. However, there is a growing need to enhance these systems to understand objects and their environments more conceptually and symbolically. It is essential to consider both the explicit teaching provided by humans (e.g., describing a situation or explaining how to act) and the implicit teaching obtained by observing human behavior (e.g., through the system's sensors) to achieve this level of powerful artificial intelligence. Thus, the system must be designed with multimodal input and output capabilities to support implicit and explicit interaction models. In this position paper, we argue for considering both types of inputs, as well as human-in-the-loop and incremental learning techniques, for advan
    
[^58]: 辅助生活环境中传感器布置的灰盒贝叶斯优化

    Grey-box Bayesian Optimization for Sensor Placement in Assisted Living Environments. (arXiv:2309.05784v1 [cs.LG])

    [http://arxiv.org/abs/2309.05784](http://arxiv.org/abs/2309.05784)

    本研究提出了一种基于灰盒贝叶斯优化和仿真评估的方法，通过捕捉关于活动的空间分布的领域特定知识，找到高质量的传感器布置，并在跌倒检测、室内定位和活动识别等领域取得了优于黑盒优化技术的性能。

    

    优化传感器的配置和布置对于可靠的跌倒检测、室内定位和活动识别在辅助生活空间中至关重要。我们提出了一种新颖的、样本高效的方法，基于灰盒贝叶斯优化和基于仿真的评估，在任意室内空间中找到高质量的传感器布置。我们的关键技术贡献在于捕捉关于活动的空间分布的领域特定知识，并将其纳入贝叶斯优化的迭代查询点选择中。通过考虑两个模拟室内环境和包含人类活动和传感器触发的真实数据集，我们表明我们提出的方法在识别高质量传感器布置方面比现有的黑盒优化技术表现更好，在F1得分方面实现了准确的活动识别，同时还需要大幅度减少(平均减少51.3%)昂贵的函数次数。

    Optimizing the configuration and placement of sensors is crucial for reliable fall detection, indoor localization, and activity recognition in assisted living spaces. We propose a novel, sample-efficient approach to find a high-quality sensor placement in an arbitrary indoor space based on grey-box Bayesian optimization and simulation-based evaluation. Our key technical contribution lies in capturing domain-specific knowledge about the spatial distribution of activities and incorporating it into the iterative selection of query points in Bayesian optimization. Considering two simulated indoor environments and a real-world dataset containing human activities and sensor triggers, we show that our proposed method performs better compared to state-of-the-art black-box optimization techniques in identifying high-quality sensor placements, leading to accurate activity recognition in terms of F1-score, while also requiring a significantly lower (51.3% on average) number of expensive function 
    
[^59]: 基于大语言模型的科学研究：对P vs. NP问题的研究

    Large Language Model for Science: A Study on P vs. NP. (arXiv:2309.05689v1 [cs.CL])

    [http://arxiv.org/abs/2309.05689](http://arxiv.org/abs/2309.05689)

    本研究使用大型语言模型加强和加速对P vs. NP问题的研究，提出了基于苏格拉底推理的通用框架，通过与语言模型进行深入思考解决复杂问题。在P vs. NP问题的实证研究中，GPT-4成功产生了证明架构，并进行了严格的推理，得出了"P ≠ NP"的结论，揭示了语言模型在科学研究中的潜力。

    

    在这项工作中，我们使用大型语言模型（LLMs）来增强和加速对P vs. NP问题的研究，这是理论计算机科学和数学中最重要的未解决问题之一。具体而言，我们提出了苏格拉底推理（Socratic reasoning）的通用框架，该框架通过与LLMs进行深入思考来解决复杂问题。苏格拉底推理鼓励LLMs递归地发现、解决和整合问题，同时促进自我评估和改进。我们对P vs. NP问题的试点研究表明，GPT-4在97个对话回合中成功地产生了一个证明架构，并进行了严格的推理，得出了“P ≠ NP”的结论，这与（Xu and Zhou, 2023）的结论一致。该调查在LLMs的广泛解空间中揭示了新的洞察力，为LLM在科学研究中提供了启示。

    In this work, we use large language models (LLMs) to augment and accelerate research on the P versus NP problem, one of the most important open problems in theoretical computer science and mathematics. Specifically, we propose Socratic reasoning, a general framework that promotes in-depth thinking with LLMs for complex problem-solving. Socratic reasoning encourages LLMs to recursively discover, solve, and integrate problems while facilitating self-evaluation and refinement. Our pilot study on the P vs. NP problem shows that GPT-4 successfully produces a proof schema and engages in rigorous reasoning throughout 97 dialogue turns, concluding "P $\neq$ NP", which is in alignment with (Xu and Zhou, 2023). The investigation uncovers novel insights within the extensive solution space of LLMs, shedding light on LLM for Science.
    
[^60]: EANet: 专家注意力网络用于在线轨迹预测

    EANet: Expert Attention Network for Online Trajectory Prediction. (arXiv:2309.05683v1 [cs.LG])

    [http://arxiv.org/abs/2309.05683](http://arxiv.org/abs/2309.05683)

    本论文提出了一个专家注意力网络用于在线轨迹预测的在线学习框架。通过引入专家注意力机制，调整网络层的权重，解决了梯度问题，能够快速学习新场景的知识以提高预测准确度。

    

    轨迹预测在自动驾驶中起着至关重要的作用。现有的主流研究和基于持续学习的方法都需要在完整的数据集上训练，导致在场景突然变化时预测准确度较低，无法及时响应和更新模型。这些方法是否能够实时预测并使用数据实例立即更新模型（即在线学习环境）仍然是个问题。还需要解决由数据实例流引起的梯度爆炸或消失的问题。受到Hedge Propagation算法的启发，我们提出了一个完整的在线学习框架——专家注意力网络，用于轨迹预测。我们引入专家注意力机制，调整网络层的不同深度的权重，避免由于梯度问题导致模型更新缓慢，并能够快速学习新场景的知识以恢复预测准确度。此外，我们还提出了一种短期运动模型。

    Trajectory prediction plays a crucial role in autonomous driving. Existing mainstream research and continuoual learning-based methods all require training on complete datasets, leading to poor prediction accuracy when sudden changes in scenarios occur and failing to promptly respond and update the model. Whether these methods can make a prediction in real-time and use data instances to update the model immediately(i.e., online learning settings) remains a question. The problem of gradient explosion or vanishing caused by data instance streams also needs to be addressed. Inspired by Hedge Propagation algorithm, we propose Expert Attention Network, a complete online learning framework for trajectory prediction. We introduce expert attention, which adjusts the weights of different depths of network layers, avoiding the model updated slowly due to gradient problem and enabling fast learning of new scenario's knowledge to restore prediction accuracy. Furthermore, we propose a short-term mot
    
[^61]: 数据科学、机器学习和人工智能数据源大全

    A compendium of data sources for data science, machine learning, and artificial intelligence. (arXiv:2309.05682v1 [cs.LG])

    [http://arxiv.org/abs/2309.05682](http://arxiv.org/abs/2309.05682)

    这篇论文提供了一个跨多个领域的数据源大全，包括金融、法律、生命科学、新闻社交等，以满足数据科学家和机器学习专家的需求。

    

    数据科学、机器学习和人工智能的最新进展，如大型语言模型的出现，导致对可供这些模型处理的数据的需求不断增加。虽然数据源是应用特定的，无法列出详尽无遗的数据源列表，但一个全面而不完整的列表仍然有利于各级别的数据科学家和机器学习专家。本文的目标是提供这样一个（必然不完整的）列表，即跨多个应用领域的数据源大全或概览，包括金融和经济、法律（法律和法规）、生命科学（医学和药物发现）、新闻情绪和社交媒体、零售和电子商务、卫星图像以及航运和物流，以满足各种需求。

    Recent advances in data science, machine learning, and artificial intelligence, such as the emergence of large language models, are leading to an increasing demand for data that can be processed by such models. While data sources are application-specific, and it is impossible to produce an exhaustive list of such data sources, it seems that a comprehensive, rather than complete, list would still benefit data scientists and machine learning experts of all levels of seniority. The goal of this publication is to provide just such an (inevitably incomplete) list -- or compendium -- of data sources across multiple areas of applications, including finance and economics, legal (laws and regulations), life sciences (medicine and drug discovery), news sentiment and social media, retail and ecommerce, satellite imagery, and shipping and logistics, and sports.
    
[^62]: 基于知识的科学出版物知识图谱的细化

    Knowledge-based Refinement of Scientific Publication Knowledge Graphs. (arXiv:2309.05681v1 [cs.LG])

    [http://arxiv.org/abs/2309.05681](http://arxiv.org/abs/2309.05681)

    本论文提出了一种基于知识的方法来细化科学出版物知识图谱，通过学习概率逻辑模型并使用功能梯度提升和人类知识引导来识别作者身份。实验证明了人类知识在作者身份领域的定量和定性作用。

    

    我们将识别作者身份的问题作为一个知识图构建和细化的问题来考虑。为此，我们将这个问题建模为在人类指导（基于知识的学习）的情况下学习概率逻辑模型。具体而言，我们使用功能梯度提升学习关系回归树，并输出可解释的规则。为了引入人类知识，我们将一阶子句的形式的建议注入到树中进行细化。我们在七个作者身份领域定量和定性地展示了人类知识的有用性。

    We consider the problem of identifying authorship by posing it as a knowledge graph construction and refinement. To this effect, we model this problem as learning a probabilistic logic model in the presence of human guidance (knowledge-based learning). Specifically, we learn relational regression trees using functional gradient boosting that outputs explainable rules. To incorporate human knowledge, advice in the form of first-order clauses is injected to refine the trees. We demonstrate the usefulness of human knowledge both quantitatively and qualitatively in seven authorship domains.
    
[^63]: 评估聊天机器人以促进用户的信任 - 实践和开放问题

    Evaluating Chatbots to Promote Users' Trust -- Practices and Open Problems. (arXiv:2309.05680v1 [cs.HC])

    [http://arxiv.org/abs/2309.05680](http://arxiv.org/abs/2309.05680)

    本文评估了当前聊天机器人测试的实践和开放问题，旨在解决和减轻与用户信任相关的服务或产品性能、用户满意度以及对社会的长期意外后果问题。

    

    聊天机器人是一种人工智能（AI）软件，通过与它们自然地互动来完成任务。尽管聊天机器人从人工智能诞生之初就已经被研究，但自从易于使用且通用的基于大型语言模型的聊天机器人如ChatGPT推出以来，聊天机器人特别吸引了公众和企业的关注。企业将聊天机器人作为一种潜在技术来吸引用户，这些用户可能是最终消费者、供应商，甚至是自己的员工，对聊天机器人进行适当的测试以解决和减轻与服务或产品性能、用户满意度以及对社会的长期意外后果相关的信任问题是重要的。本文回顾了当前聊天机器人测试的实践，确定了追求用户信任的开放问题，并提出了一个前进的路径。

    Chatbots, the common moniker for collaborative assistants, are Artificial Intelligence (AI) software that enables people to naturally interact with them to get tasks done. Although chatbots have been studied since the dawn of AI, they have particularly caught the imagination of the public and businesses since the launch of easy-to-use and general-purpose Large Language Model-based chatbots like ChatGPT. As businesses look towards chatbots as a potential technology to engage users, who may be end customers, suppliers, or even their own employees, proper testing of chatbots is important to address and mitigate issues of trust related to service or product performance, user satisfaction and long-term unintended consequences for society. This paper reviews current practices for chatbot testing, identifies gaps as open problems in pursuit of user trust, and outlines a path forward.
    
[^64]: 外表优美但缺乏忠诚度：通过基于趋势的测试理解局部解释方法

    Good-looking but Lacking Faithfulness: Understanding Local Explanation Methods through Trend-based Testing. (arXiv:2309.05679v1 [cs.LG])

    [http://arxiv.org/abs/2309.05679](http://arxiv.org/abs/2309.05679)

    本文通过基于趋势的测试方法评估了解释模型决策的忠诚度，并提出了三种新的趋势测试方法，从实证结果来看，这些新测试方法在图像、自然语言和安全任务中可以更好地评估解释模型的忠诚度。

    

    尽管深度学习（DL）带来了巨大的成就，但人们也对DL模型的决策感到担忧，因为DL模型的高度非线性使得决策极其难以理解。因此，攻击（如对抗攻击）很容易进行，但很难检测和解释，这导致了局部解释方法的研究激增，以解释模型决策。在本文中，我们评估了解释方法的忠诚度，并发现传统的忠诚度测试遇到了随机优势问题，即随机选择效果最好，尤其是对于复杂的数据。为了进一步解决这个问题，我们提出了三种基于趋势的忠诚度测试，并从实证上证明了新的趋势测试可以比传统的图像、自然语言和安全任务的测试更好地评估忠诚度。我们实现了评估系统，并评估了十种流行的解释方法。

    While enjoying the great achievements brought by deep learning (DL), people are also worried about the decision made by DL models, since the high degree of non-linearity of DL models makes the decision extremely difficult to understand. Consequently, attacks such as adversarial attacks are easy to carry out, but difficult to detect and explain, which has led to a boom in the research on local explanation methods for explaining model decisions. In this paper, we evaluate the faithfulness of explanation methods and find that traditional tests on faithfulness encounter the random dominance problem, \ie, the random selection performs the best, especially for complex data. To further solve this problem, we propose three trend-based faithfulness tests and empirically demonstrate that the new trend tests can better assess faithfulness than traditional tests on image, natural language and security tasks. We implement the assessment system and evaluate ten popular explanation methods. Benefitin
    
[^65]: SHAPE：一种适应样本的层次预测网络用于药物推荐

    SHAPE: A Sample-adaptive Hierarchical Prediction Network for Medication Recommendation. (arXiv:2309.05675v1 [cs.LG])

    [http://arxiv.org/abs/2309.05675](http://arxiv.org/abs/2309.05675)

    本文提出了一种名为SHAPE的适应样本的层次药物预测网络，旨在解决医疗保健中复杂多发病条件下的药物推荐问题。通过设计紧凑的内部病患就诊事件关系编码器和纵向病历编码器，我们能够获得准确的病患表示和纵向序列学习策略。

    

    在医疗保健中，针对复杂的多发病条件进行有效的药物推荐是一项关键任务。大多数现有的工作基于纵向记录预测药物，这种方法假设学习纵向序列数据的信息传输模式是稳定的，并且病患在就诊期间的医疗事件是有序的。然而，他们忽视了以下条件：1）急需一种更紧凑的内部病患就诊事件关系编码器；2）学习病人可变纵向序列的准确表示的策略是不同的。在本文中，我们提出了一种新颖的适应样本的层次药物预测网络，称为SHAPE，来解决药物推荐任务中的上述挑战。具体来说，我们设计了一个紧凑的内部病患就诊事件关系编码器，用于获得就诊级别的表示，并且发展了一个纵向病历编码器，以学习患者的纵向序列表示。

    Effectively medication recommendation with complex multimorbidity conditions is a critical task in healthcare. Most existing works predicted medications based on longitudinal records, which assumed the information transmitted patterns of learning longitudinal sequence data are stable and intra-visit medical events are serialized. However, the following conditions may have been ignored: 1) A more compact encoder for intra-relationship in the intra-visit medical event is urgent; 2) Strategies for learning accurate representations of the variable longitudinal sequences of patients are different. In this paper, we proposed a novel Sample-adaptive Hierarchical medicAtion Prediction nEtwork, termed SHAPE, to tackle the above challenges in the medication recommendation task. Specifically, we design a compact intra-visit set encoder to encode the relationship in the medical event for obtaining visit-level representation and then develop an inter-visit longitudinal encoder to learn the patient-
    
[^66]: tSPM+：一种用于从临床数据中挖掘传递顺序模式的高性能算法

    tSPM+; a high-performance algorithm for mining transitive sequential patterns from clinical data. (arXiv:2309.05671v1 [cs.LG])

    [http://arxiv.org/abs/2309.05671](http://arxiv.org/abs/2309.05671)

    tSPM+算法是一种高性能算法，通过在时间模式中加入持续时间维度，提供了高速运行和内存消耗改进。

    

    越来越多从患者那里收集到的大型临床数据集的可用性，使得使用不同的分析算法对复杂疾病进行计算化特征化成为可能。一种从大型临床数据集中提取知识的有前途的新方法是将时间模式挖掘与机器学习工作流程相结合。然而，挖掘这些时间模式是一项计算密集型任务，并且会对存储器产生影响。目前的算法，如时间序列模式挖掘（tSPM）算法，已经提供了有希望的结果，但仍有优化的空间。在本文中，我们提出了tSPM+算法，这是tSPM算法的一种高性能实现，通过在时间模式中添加持续时间维度，增加了一种新的维度。我们展示了tSPM+算法提供了高达980倍的加速和高达48倍的内存使用改进。此外，我们提供了一个包含R包的docker容器，我们还提供了完整的实验代码。

    The increasing availability of large clinical datasets collected from patients can enable new avenues for computational characterization of complex diseases using different analytic algorithms. One of the promising new methods for extracting knowledge from large clinical datasets involves temporal pattern mining integrated with machine learning workflows. However, mining these temporal patterns is a computational intensive task and has memory repercussions. Current algorithms, such as the temporal sequence pattern mining (tSPM) algorithm, are already providing promising outcomes, but still leave room for optimization. In this paper, we present the tSPM+ algorithm, a high-performance implementation of the tSPM algorithm, which adds a new dimension by adding the duration to the temporal patterns. We show that the tSPM+ algorithm provides a speed up to factor 980 and a up to 48 fold improvement in memory consumption. Moreover, we present a docker container with an R-package, We also provi
    
[^67]: 研究使用ChatGPT生成文本进行预训练对下游任务的影响

    Studying the impacts of pre-training using ChatGPT-generated text on downstream tasks. (arXiv:2309.05668v1 [cs.CL])

    [http://arxiv.org/abs/2309.05668](http://arxiv.org/abs/2309.05668)

    本研究调查了在语言模型的预训练阶段中使用ChatGPT生成文本的人造文本的影响，通过比较分析了使用CNN/DailyMail新闻文章预训练的RoBERTa和使用相同文章预训练的ChatGPT的性能。

    

    最近，在语言模型领域取得了显著进展，特别是随着大型语言模型（LLM）的出现，这些模型使用从互联网档案中提取的大量数据进行训练。这些LLM，例如ChatGPT，已广泛可用，使用户能够为各种目的生成文本，包括文章、论文、笑话和诗歌。由于LLM是在涵盖Reddit和Twitter等平台的各种文本来源上进行训练的，可以预见未来的训练数据集还将包含前几个模型生成的文本。鉴于此发展，我们的研究旨在探究在语言模型的预训练阶段中人造文本的影响。具体而言，我们对一个使用CNN/DailyMail新闻文章进行预训练的语言模型RoBERTa和一个使用相同文章进行训练的ChatGPT进行了比较分析，并评估了它们的表现。

    In recent times, significant advancements have been witnessed in the field of language models, particularly with the emergence of Large Language Models (LLMs) that are trained on vast amounts of data extracted from internet archives. These LLMs, such as ChatGPT, have become widely accessible, allowing users to generate text for various purposes including articles, essays, jokes, and poetry. Given that LLMs are trained on a diverse range of text sources, encompassing platforms like Reddit and Twitter, it is foreseeable that future training datasets will also incorporate text generated by previous iterations of the models themselves. In light of this development, our research aims to investigate the influence of artificial text in the pre-training phase of language models. Specifically, we conducted a comparative analysis between a language model, RoBERTa, pre-trained using CNN/DailyMail news articles, and ChatGPT, which employed the same articles for its training and evaluated their per
    
[^68]: 机器人公园our学习

    Robot Parkour Learning. (arXiv:2309.05665v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2309.05665](http://arxiv.org/abs/2309.05665)

    该论文提出了一个学习基于视觉的多样化公园our技能的系统，该系统使用简单的奖励而不使用参考动作数据，通过强化学习方法生成不同的公园our技能，并将其转移到四足机器人中。

    

    公园our是一个对于机器人来说需要在复杂环境中迅速克服各种障碍的长期挑战。现有的方法通过使用参考动物数据或复杂的奖励，可以生成多样但盲目的运动技能或基于视觉的特殊技能。然而，自主公园our需要机器人学习基于视觉的、多样化的可推广技能，以感知和应对各种情况。在这项工作中，我们提出了一个系统，通过使用简单的奖励而不使用任何参考动作数据，来学习多样化的、基于视觉的公园our技能的单一端到端策略。我们开发了一种受到直接协作的强化学习方法，用于生成公园our技能，包括攀爬高障碍物、跨越大距离间隙、爬行低壁垒、穿越狭窄缝隙和奔跑。我们将这些技能提炼成一个单一基于视觉的公园our策略，并将其转移到四足机器人上，利用其自我中心视角。

    Parkour is a grand challenge for legged locomotion that requires robots to overcome various obstacles rapidly in complex environments. Existing methods can generate either diverse but blind locomotion skills or vision-based but specialized skills by using reference animal data or complex rewards. However, autonomous parkour requires robots to learn generalizable skills that are both vision-based and diverse to perceive and react to various scenarios. In this work, we propose a system for learning a single end-to-end vision-based parkour policy of diverse parkour skills using a simple reward without any reference motion data. We develop a reinforcement learning method inspired by direct collocation to generate parkour skills, including climbing over high obstacles, leaping over large gaps, crawling beneath low barriers, squeezing through thin slits, and running. We distill these skills into a single vision-based parkour policy and transfer it to a quadrupedal robot using its egocentric 
    
[^69]: 预训练大型语言模型的网络运维能力的实证研究

    An Empirical Study of NetOps Capability of Pre-Trained Large Language Models. (arXiv:2309.05557v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.05557](http://arxiv.org/abs/2309.05557)

    本文通过对预训练大型语言模型（LLMs）进行系统评估，发现LLMs在网络运维（NetOps）领域具有强大的潜力应用，能够提升自动化和智能化的NetOps能力。

    

    大型语言模型（LLMs）可以回答人类语言查询，并在网络运维（NetOps）领域展现出强大的潜力应用。由于具备大量常识知识，LLMs在推理准确性上比传统模型更好，并具有更强的泛化能力、推理能力和代码生成能力，这些能力可能对自动化和智能化的NetOps有巨大的提升。然而，LLMs在各种NetOps任务中的表现仍然未被充分探索。本文系统评估了选择的几种LLMs在NetOps领域的能力、优势和限制。评估针对5732个关于NetOps的问题进行，涵盖了26个公开可用的通用领域LLMs，包括ChatGPT、LLaMA、Falcon等。我们还对其中一些LLMs进行了NetOps语料库的微调，并评估了结果模型的性能。评估方法遵循广泛采用的用于生成任务基准测试的方法。

    Large language models (LLMs) can respond to human language queries and have shown powerful potential applications in network operations (NetOps). Thanks to the large amount of commonsense knowledge inherent, LLMs achieve much better inference accuracy than traditional models and emerge with strong abilities in generalization, reasoning, and code generation. These abilities may have a crucial boost to automated and intelligent NetOps. However, it remains under-explored how well LLMs perform in various NetOps tasks. In this work, we make a systematic assessment of the capabilities, strengths, and limitations of selected LLMs in the field of NetOps. The evaluation is conducted on a collection of 5,732 questions about NetOps, encompassing 26 publicly available general-domain LLMs, including ChatGPT, LLaMA, Falcon, etc. We also finetune some of these LLMs with our collected NetOps corpus and evaluate the resulting models. The evaluation method follows the widely adopted benchmarks for gener
    
[^70]: 机器学习用于最大化单个和耦合量子忆阻器的记忆阻性

    Machine Learning for maximizing the memristivity of single and coupled quantum memristors. (arXiv:2309.05062v1 [quant-ph] CROSS LISTED)

    [http://arxiv.org/abs/2309.05062](http://arxiv.org/abs/2309.05062)

    本文使用机器学习方法来研究单个和耦合量子忆阻器的记忆阻性，并发现最大化记忆阻性可以提高两个量子忆阻器的纠缠程度，揭示了量子相关性与记忆之间的关系。这一发现增强了将量子忆阻器应用于神经形态的量子计算的潜力。

    

    我们提出了机器学习方法来表征单个和耦合量子忆阻器的记忆阻性。我们展示了最大化记忆阻性会导致两个量子忆阻器的纠缠程度较大，揭示了量子相关性与记忆之间的密切关系。我们的结果增强了将量子忆阻器作为神经形态的量子计算的关键组件的可能性。

    We propose machine learning (ML) methods to characterize the memristive properties of single and coupled quantum memristors. We show that maximizing the memristivity leads to large values in the degree of entanglement of two quantum memristors, unveiling the close relationship between quantum correlations and memory. Our results strengthen the possibility of using quantum memristors as key components of neuromorphic quantum computing.
    
[^71]: 多文档摘要：一项比较评估

    Multi-document Summarization: A Comparative Evaluation. (arXiv:2309.04951v1 [cs.CL])

    [http://arxiv.org/abs/2309.04951](http://arxiv.org/abs/2309.04951)

    本文评估了多文档摘要领域的最新模型在不同领域和数据集上的表现，发现通用预训练模型LED在MS$^2$数据集上的性能优于其他模型，为未来的MDS研究提供了宝贵的参考和发展方向。

    

    本文旨在评估多文档摘要(MDS)领域的最新模型在不同领域和不同类型数据集上的表现，并研究现有模型的局限性，以确定未来的研究方向。为了填补这个空白，我们进行了广泛的文献评估，以确定最新的模型和数据集。我们对BigSurvey-MDS和MS$^2$数据集上的PRIMERA和PEGASUS模型的性能进行了分析，这些数据集由于领域的不同而带来了独特的挑战。我们的研究结果表明，通用预训练模型LED在MS$^2$数据集上的性能优于PRIMERA和PEGASUS。我们使用ROUGE分数作为性能度量指标，评估了不同数据集上的模型。我们的研究为了解模型的优势和不足提供了宝贵的见解，并为不同领域中准确、鲁棒的模型的发展提供了参考。这项研究对未来的MDS研究具有重要价值。

    This paper is aimed at evaluating state-of-the-art models for Multi-document Summarization (MDS) on different types of datasets in various domains and investigating the limitations of existing models to determine future research directions. To address this gap, we conducted an extensive literature review to identify state-of-the-art models and datasets. We analyzed the performance of PRIMERA and PEGASUS models on BigSurvey-MDS and MS$^2$ datasets, which posed unique challenges due to their varied domains. Our findings show that the General-Purpose Pre-trained Model LED outperforms PRIMERA and PEGASUS on the MS$^2$ dataset. We used the ROUGE score as a performance metric to evaluate the identified models on different datasets. Our study provides valuable insights into the models' strengths and weaknesses, as well as their applicability in different domains. This work serves as a reference for future MDS research and contributes to the development of accurate and robust models which can 
    
[^72]: MFPNet: 轻量级语义分割的多尺度特征传播网络

    MFPNet: Multi-scale Feature Propagation Nwtwork For Lightweight Semantic Segmentation. (arXiv:2309.04914v1 [cs.CV])

    [http://arxiv.org/abs/2309.04914](http://arxiv.org/abs/2309.04914)

    MFPNet是一个轻量级分割架构，利用特殊的残差块和图卷积网络实现了多尺度特征传播，获得了优越的分割结果。

    

    与大规模模型的丰富研究相比，轻量级语义分割的进展似乎进展较慢。然而，现有的紧凑方法由于网络的浅层而导致特征表示能力有限。在本文中，我们提出了一种新颖的轻量级分割架构，称为多尺度特征传播网络（MFPNet），以解决这一困境。具体而言，我们设计了一种强大的编码器-解码器结构，采用对称的残差块，其中包含灵活的瓶颈残差模块（BRM），以探索深度和丰富的多尺度语义上下文。此外，利用图卷积网络（GCNs）建模潜在的长程上下文关系能力，促进了BRM块之间的多尺度特征传播。在基准数据集上评估时，我们提出的方法显示出优越的分割结果。

    In contrast to the abundant research focusing on large-scale models, the progress in lightweight semantic segmentation appears to be advancing at a comparatively slower pace. However, existing compact methods often suffer from limited feature representation capability due to the shallowness of their networks. In this paper, we propose a novel lightweight segmentation architecture, called Multi-scale Feature Propagation Network (MFPNet), to address the dilemma. Specifically, we design a robust Encoder-Decoder structure featuring symmetrical residual blocks that consist of flexible bottleneck residual modules (BRMs) to explore deep and rich muti-scale semantic context. Furthermore, taking benefit from their capacity to model latent long-range contextual relationships, we leverage Graph Convolutional Networks (GCNs) to facilitate multi-scale feature propagation between the BRM blocks. When evaluated on benchmark datasets, our proposed approach shows superior segmentation results.
    
[^73]: TMComposites: 专用Tsetlin机器之间的即插即用协作

    TMComposites: Plug-and-Play Collaboration Between Specialized Tsetlin Machines. (arXiv:2309.04801v1 [cs.CV])

    [http://arxiv.org/abs/2309.04801](http://arxiv.org/abs/2309.04801)

    TMComposites是一种插拔式协作方式，通过特化和评估成员的能力，使得Tsetlin机器（TM）可以在较复杂的图像分类任务中表现出更强的性能。

    

    Tsetlin机器（TM）从基于算术的机器学习转变为基于逻辑的机器学习提供了一种根本性的改变。支持卷积，TM成功地处理像MNIST，Fashion-MNIST和CIFAR-2这样的图像分类数据集。然而，TM在表示更复杂任务的CIFAR-10和CIFAR-100上难以达到最先进的性能。本文介绍了专用TM之间的即插即用协作，称为TM Composites。协作依赖于TM在学习过程中特化的能力和在推理过程中评估自身能力的能力。当团队组合时，最自信的TM做出决策，解决了不确定的问题。通过这种方式，TM组合比其成员更有能力，从他们的专业化中受益。协作的特点是即插即用，即成员可以在任何时间、任何方式下组合，无需微调。在我们的实证评估中，我们实现了三个TM专业化：梯度直方图，自适应高斯

    Tsetlin Machines (TMs) provide a fundamental shift from arithmetic-based to logic-based machine learning. Supporting convolution, they deal successfully with image classification datasets like MNIST, Fashion-MNIST, and CIFAR-2. However, the TM struggles with getting state-of-the-art performance on CIFAR-10 and CIFAR-100, representing more complex tasks. This paper introduces plug-and-play collaboration between specialized TMs, referred to as TM Composites. The collaboration relies on a TM's ability to specialize during learning and to assess its competence during inference. When teaming up, the most confident TMs make the decisions, relieving the uncertain ones. In this manner, a TM Composite becomes more competent than its members, benefiting from their specializations. The collaboration is plug-and-play in that members can be combined in any way, at any time, without fine-tuning. We implement three TM specializations in our empirical evaluation: Histogram of Gradients, Adaptive Gauss
    
[^74]: FIAT: 将学习范式与指令加速调优相融合

    FIAT: Fusing learning paradigms with Instruction-Accelerated Tuning. (arXiv:2309.04663v1 [cs.CL])

    [http://arxiv.org/abs/2309.04663](http://arxiv.org/abs/2309.04663)

    FIAT是一种将上下文学习和完全微调范式融合的新的学习方式，可以在最大模型上进行指令和推理，并且在较小模型上进行参数更新，经过多语言任务测试，比之前的方法都表现更好。

    

    目前用于大型语言模型（LLMs）的学习范式通常分为上下文学习（ICL）和完全微调。每种范式都有其自身的取舍，这取决于可用数据、模型大小、计算成本、易用性和最终质量，但无法在所有情况下都表现良好。在本文中，我们首先以强调它们之间自然联系的方式描述了ICL和微调范式。基于这些联系，我们提出了一种名为FIAT的新学习范式，将这些范式的优点融合在一起，使得在最大模型上可以进行快速工程指令和链式思维推理，同时在参数效率调优的较小模型上使用类似的方法进行参数更新。我们在各种多语言任务上评估了FIAT的有效性，并观察到FIAT在100-10,000个训练样本规模下均比ICL和微调表现更好。我们希望FIAT能提供一种新的解决方案，使得在不同情况下都能取得更好的效果。

    Learning paradigms for large language models (LLMs) currently tend to fall within either in-context learning (ICL) or full fine-tuning. Each of these comes with their own trade-offs based on available data, model size, compute cost, ease-of-use, and final quality with neither solution performing well across-the-board. In this article, we first describe ICL and fine-tuning paradigms in a way that highlights their natural connections. Based on these connections, we propose a new learning paradigm called FIAT that fuses the best of these paradigms together, enabling prompt-engineered instructions and chain-of-thought reasoning with the very largest models while also using similar methods to perform parameter updates on a modestly-sized LLM with parameter-efficient tuning. We evaluate FIAT's effectiveness on a variety of multilingual tasks and observe that FIAT performs better than both ICL and fine-tuning at scales ranging from 100-10,000 training examples. We hope that FIAT provides a pr
    
[^75]: 用物理信息神经网络进行最优反对角量子计算的研究

    Physics-Informed Neural Networks for an optimal counterdiabatic quantum computation. (arXiv:2309.04434v1 [quant-ph] CROSS LISTED)

    [http://arxiv.org/abs/2309.04434](http://arxiv.org/abs/2309.04434)

    本研究提出了一种利用物理信息神经网络（PINNs）解决量子电路反对角（CD）协议优化问题的方法，通过嵌入物理信息到神经网络中，并利用最小作用量原理和厄米特性条件来获取最适当的反对角项，从而提供了一种可靠的替代方案，摆脱了以往依赖于经典数值逼近的约束。

    

    我们引入了一种新的方法，利用物理信息神经网络（PINNs）的优势来解决由$N_{Q}$比特系统组成的量子电路中的反对角（CD）协议优化的问题。主要目标是利用受物理启发的深度学习技术精确地解决量子系统中不同物理可观测量的时间演化。为了实现这个目标，我们将必要的物理信息嵌入到底层神经网络中，以有效地解决这个问题。特别地，我们对所有物理可观测量施加厄米特性条件，并利用最小作用量原理，保证基于物理学的最适当反对角项的获取。所提出的方法提供了一个可靠的替代选择来解决CD驱动问题，摆脱了以往依赖于经典数值逼近的约束。

    We introduce a novel methodology that leverages the strength of Physics-Informed Neural Networks (PINNs) to address the counterdiabatic (CD) protocol in the optimization of quantum circuits comprised of systems with $N_{Q}$ qubits. The primary objective is to utilize physics-inspired deep learning techniques to accurately solve the time evolution of the different physical observables within the quantum system. To accomplish this objective, we embed the necessary physical information into an underlying neural network to effectively tackle the problem. In particular, we impose the hermiticity condition on all physical observables and make use of the principle of least action, guaranteeing the acquisition of the most appropriate counterdiabatic terms based on the underlying physics. The proposed approach offers a dependable alternative to address the CD driving problem, free from the constraints typically encountered in previous methodologies relying on classical numerical approximations.
    
[^76]: 在COVID-19期间导航不在分布范围内的电力负荷预测：利用人类移动的持续学习方法

    Navigating Out-of-Distribution Electricity Load Forecasting during COVID-19: A Continual Learning Approach Leveraging Human Mobility. (arXiv:2309.04296v1 [cs.LG])

    [http://arxiv.org/abs/2309.04296](http://arxiv.org/abs/2309.04296)

    本研究提出了一种利用人类移动数据和持续学习技术的方法来解决COVID-19期间非分布期间的电力负荷预测问题，通过保留过去的见解并整合新的数据，提高了模型的准确性和鲁棒性。

    

    在传统的深度学习算法中，一个关键假设是数据分布在训练和部署过程中保持不变。然而，在面对非分布期间时，如COVID-19的封锁期，数据分布与模型在训练过程中所见的明显偏离。本文采用双重策略：利用持续学习技术更新模型的新数据，并利用在建筑物外部的保护隐私的行人计数器收集的人类移动数据。与在线学习相比，后者常常会遭受“灾难性遗忘”的困扰，因为新获得的知识常常会抹去先前的信息，持续学习则通过保留过去的见解并整合新的数据，提供了一个整体的方法。本研究将FSNet，一种强大的持续学习算法，应用于墨尔本市13个建筑群的真实数据。

    In traditional deep learning algorithms, one of the key assumptions is that the data distribution remains constant during both training and deployment. However, this assumption becomes problematic when faced with Out-of-Distribution periods, such as the COVID-19 lockdowns, where the data distribution significantly deviates from what the model has seen during training. This paper employs a two-fold strategy: utilizing continual learning techniques to update models with new data and harnessing human mobility data collected from privacy-preserving pedestrian counters located outside buildings. In contrast to online learning, which suffers from 'catastrophic forgetting' as newly acquired knowledge often erases prior information, continual learning offers a holistic approach by preserving past insights while integrating new data. This research applies FSNet, a powerful continual learning algorithm, to real-world data from 13 building complexes in Melbourne, Australia, a city which had the s
    
[^77]: UQ在#SMM4H 2023上的论文：利用社交媒体进行公共卫生分析的ALEX方法

    UQ at #SMM4H 2023: ALEX for Public Health Analysis with Social Media. (arXiv:2309.04213v1 [cs.CL])

    [http://arxiv.org/abs/2309.04213](http://arxiv.org/abs/2309.04213)

    本文提出了一种名为ALEX的框架，通过采用LLMs解释机制来改进社交媒体上的公共卫生分析性能。该方法通过数据增强和平衡训练解决了数据不平衡问题，并有效利用了LLMs的能力。

    

    随着社交媒体的普及，与公共卫生相关的活动也越来越多。目前的公共卫生分析技术涉及到流行的模型，如BERT和大型语言模型（LLMs）。然而，为公共卫生域训练LLMs的成本尤其昂贵。此外，社交媒体中这种域内数据集往往存在不平衡的问题。为应对这些挑战，可以通过数据增强和平衡训练来解决数据不平衡的问题。此外，可以通过适当设置模型的引导方式有效利用LLMs的能力。本文提出了一种新颖的ALEX框架，通过采用LLMs解释机制来提高社交媒体上的公共卫生分析性能。结果显示，我们的ALEX模型在Social Media Mining for Health 2023 （SMM4H）的任务2和任务4中获得了最佳性能，并在任务1中得到了较高的评分[1]。我们的代码已在 https:/ /github 上发布。

    As social media becomes increasingly popular, more and more activities related to public health emerge. Current techniques for public health analysis involve popular models such as BERT and large language models (LLMs). However, the costs of training in-domain LLMs for public health are especially expensive. Furthermore, such kinds of in-domain datasets from social media are generally imbalanced. To tackle these challenges, the data imbalance issue can be overcome by data augmentation and balanced training. Moreover, the ability of the LLMs can be effectively utilized by prompting the model properly. In this paper, a novel ALEX framework is proposed to improve the performance of public health analysis on social media by adopting an LLMs explanation mechanism. Results show that our ALEX model got the best performance among all submissions in both Task 2 and Task 4 with a high score in Task 1 in Social Media Mining for Health 2023 (SMM4H)[1]. Our code has been released at https:// github
    
[^78]: GPT可以在没有计算器的情况下解决数学问题

    GPT Can Solve Mathematical Problems Without a Calculator. (arXiv:2309.03241v1 [cs.LG])

    [http://arxiv.org/abs/2309.03241](http://arxiv.org/abs/2309.03241)

    本研究表明，通过充分训练，一个20亿参数的语言模型可以在没有计算器工具的情况下以几乎100%的准确度执行多位数的算术运算，超越了之前的GPT-4。这项研究还通过在附加的多步骤算术运算和数学问题的数据集上进行微调，展示了一个与GPT-4在中文数学问题上相似的性能。

    

    以往的研究通常认为大型语言模型无法在没有计算器工具的情况下准确执行算术运算，特别是超过8位数字的乘法，以及涉及小数和分数的运算。本文旨在挑战这种误解。通过充分的训练数据，一个拥有20亿参数的语言模型可以以近乎100%的准确度执行多位数的算术运算，而且没有数据泄露，显著超过了GPT-4（其多位数乘法准确率仅为4.3%）。我们还演示了我们的MathGLM，它是通过在包含了文本描述的附加多步骤算术运算和数学问题的数据集上从GLM-10B微调而成的，它在一个包含5000个样本的中文数学问题测试集上的表现与GPT-4相似。

    Previous studies have typically assumed that large language models are unable to accurately perform arithmetic operations, particularly multiplication of >8 digits, and operations involving decimals and fractions, without the use of calculator tools. This paper aims to challenge this misconception. With sufficient training data, a 2 billion-parameter language model can accurately perform multi-digit arithmetic operations with almost 100% accuracy without data leakage, significantly surpassing GPT-4 (whose multi-digit multiplication accuracy is only 4.3%). We also demonstrate that our MathGLM, fine-tuned from GLM-10B on a dataset with additional multi-step arithmetic operations and math problems described in text, achieves similar performance to GPT-4 on a 5,000-samples Chinese math problem test set.
    
[^79]: POI级别人群流推断的时空对比自监督学习

    Spatio-Temporal Contrastive Self-Supervised Learning for POI-level Crowd Flow Inference. (arXiv:2309.03239v1 [cs.LG])

    [http://arxiv.org/abs/2309.03239](http://arxiv.org/abs/2309.03239)

    本文提出了一种针对POI级别人群流推断的时空对比自监督学习模型，通过自监督属性图表示学习以解决数据标记不足、POI间时空依赖性复杂和人群流量与GPS报告之间相关性多样等挑战。

    

    准确获取兴趣点（POI）的人群流量对于有效的交通管理、公共服务和城市规划至关重要。尽管如此重要，但由于城市感知技术的限制，大多数数据源的数据质量不足以监测每个POI的人群流动。这使得从低质量数据中推断准确的人群流量成为一项关键且具有挑战性的任务。这一复杂性主要由三个关键因素引起：1）标记数据的稀缺性和罕见性；2）POI之间复杂的时空依赖关系；3）精确人群流量与GPS报告之间的众多相关性。为了应对这些挑战，我们将人群流推断问题重新构建为自监督属性图表示学习任务，并引入一种新的时空数据对比自监督学习框架（model）。我们的方法从构建一个空间图开始。

    Accurate acquisition of crowd flow at Points of Interest (POIs) is pivotal for effective traffic management, public service, and urban planning. Despite this importance, due to the limitations of urban sensing techniques, the data quality from most sources is inadequate for monitoring crowd flow at each POI. This renders the inference of accurate crowd flow from low-quality data a critical and challenging task. The complexity is heightened by three key factors: 1) \emph{The scarcity and rarity of labeled data}, 2) \emph{The intricate spatio-temporal dependencies among POIs}, and 3) \emph{The myriad correlations between precise crowd flow and GPS reports}.  To address these challenges, we recast the crowd flow inference problem as a self-supervised attributed graph representation learning task and introduce a novel \underline{C}ontrastive \underline{S}elf-learning framework for \underline{S}patio-\underline{T}emporal data (\model). Our approach initiates with the construction of a spati
    
[^80]: 无需训练依然能获益：通过蒙特卡洛树搜索和能量函数引导实现大型语言模型的数学推理

    No Train Still Gain. Unleash Mathematical Reasoning of Large Language Models with Monte Carlo Tree Search Guided by Energy Function. (arXiv:2309.03224v1 [cs.AI])

    [http://arxiv.org/abs/2309.03224](http://arxiv.org/abs/2309.03224)

    该论文提出了一种通过蒙特卡洛树搜索和能量函数引导来释放大型语言模型的数学推理能力的方法，以解决当前在数学推理任务中的不足和错误。该方法不需要进一步的微调步骤，通过重新定义模型和引入路径验证器的方式，实现了对输出空间的搜索和推理路径的评估。

    

    大型语言模型（LLMs）展现出令人印象深刻的语言理解和背景学习能力，包括自然语言处理（NLP）任务和具有挑战性的数学推理。然而，由于缺乏过程监督，将PLMs应用于数学推理任务通常无法生成正确的推理步骤和最终答案，即使解决方案概率很高。为了在没有进一步的微调步骤的情况下发挥微调的LLMs的数学推理能力，我们提出了一种方法，通过蒙特卡洛树搜索（MCTS）和轻量级能量函数为LLMs赋予即时反应和精细推理系统。具体而言，我们首先将微调的LLMs重新定义为基于残差的能量模型（Residual-EBM），并应用噪声对比估计来估计能量函数的参数。然后，我们使用带有能量函数的MCTS作为路径验证器来搜索输出空间并评估推理路径。通过广泛的实验证明了我们方法的有效性。

    Large language models (LLMs) exhibit impressive language understanding and in-context learning abilities including natural language processing (NLP) tasks and challenging mathematical reasoning. However, due to the lack of process-supervision, applying PLMs to mathematical reasoning tasks often fail to generate correct reasoning steps and final answer even though solutions have high probabilities. To unleash the mathematical reasoning of finetuned-LLMs without any further fineutuning steps, we propose a method to endow LLMs with immediate reaction and delicate reasoning system via Monte Carlo Tree Search(MCTS) and a light energy function to rank the decision steps. In particular, We first re-formalize the finetuned-LLMs to a Residual-based Energy Model~(Residual-EBM) and apply noise contrastive estimation to estimate the parameters of energy function . Then we use MCTS with energy function as path verifier to search the output space and evaluating the reasoning path. Through extensive 
    
[^81]: Stylebook: 在只使用语音数据的任意-任意语音转换中进行依赖内容的说话风格建模

    Stylebook: Content-Dependent Speaking Style Modeling for Any-to-Any Voice Conversion using Only Speech Data. (arXiv:2309.02730v1 [eess.AS])

    [http://arxiv.org/abs/2309.02730](http://arxiv.org/abs/2309.02730)

    这项工作提出了一种新的方法，即 Stylebook，它通过使用自监督学习模型从目标语音中提取丰富的风格信息，并将其高效地转移到源语音内容上，无需文本转录或说话者标记。该方法引入了注意力机制和样式手册，可以实现目标说话者的忠实复制和风格转移。

    

    尽管许多最近的任意-任意语音转换模型成功地将一些目标语音的风格信息转移到转换的语音中，但它们仍然缺乏忠实地复制目标说话者的说话风格的能力。在这项工作中，我们提出了一种新的方法，从目标语音中提取丰富的风格信息，并将其高效地转移到源语音内容上，而无需文本转录或说话者标记。我们提出的方法引入了一个注意力机制，利用自监督学习（SSL）模型收集与不同音素内容相对应的目标说话者的说话风格。这些风格用一组称为样式手册的嵌入表示。在下一步中，样式手册与源语音的音素内容一起参与，以确定每个源内容的最终目标风格。最后，从源语音中提取的内容信息和依赖内容的目标风格嵌入被输入到一个...

    While many recent any-to-any voice conversion models succeed in transferring some target speech's style information to the converted speech, they still lack the ability to faithfully reproduce the speaking style of the target speaker. In this work, we propose a novel method to extract rich style information from target utterances and to efficiently transfer it to source speech content without requiring text transcriptions or speaker labeling. Our proposed approach introduces an attention mechanism utilizing a self-supervised learning (SSL) model to collect the speaking styles of a target speaker each corresponding to the different phonetic content. The styles are represented with a set of embeddings called stylebook. In the next step, the stylebook is attended with the source speech's phonetic content to determine the final target style for each source content. Finally, content information extracted from the source speech and content-dependent target style embeddings are fed into a dif
    
[^82]: BEVTrack：一种针对鸟瞰图中3D单物体跟踪的简单基线

    BEVTrack: A Simple Baseline for 3D Single Object Tracking in Birds's-Eye-View. (arXiv:2309.02185v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.02185](http://arxiv.org/abs/2309.02185)

    本文介绍了一种名为BEVTrack的简单却强大的基线框架，用于解决点云中3D单物体跟踪的挑战。通过将点云转换为鸟瞰图表示，并进行简单的逐元素操作，BEVTrack能够编码空间邻近性和捕捉运动线索，从而实现高效的跟踪。

    

    由于外观变化、干扰物和点云的高稀疏性，点云中的3D单物体跟踪仍然是一个具有挑战性的问题。值得注意的是，在自动驾驶场景中，目标物体通常在连续帧中保持空间邻近性，主要水平移动。这种空间连续性为目标定位提供了宝贵的先验知识。然而，现有的跟踪器通常采用点级表示，难以有效利用这种知识，因为这种表示的不规则格式。因此，它们需要精心设计并解决多个子任务来建立空间对应关系。在本文中，我们介绍BEVTrack，一个简单但强大的用于3D单物体跟踪的基线框架。通过将连续的点云转换为常见的鸟瞰图表示，BEVTrack通过简单的逐元素操作自然地编码了空间邻近性，并灵活地捕捉了跟踪的运动线索。

    3D single object tracking (SOT) in point clouds is still a challenging problem due to appearance variation, distractors, and high sparsity of point clouds. Notably, in autonomous driving scenarios, the target object typically maintains spatial adjacency across consecutive frames, predominantly moving horizontally. This spatial continuity offers valuable prior knowledge for target localization. However, existing trackers, which often employ point-wise representations, struggle to efficiently utilize this knowledge owing to the irregular format of such representations. Consequently, they require elaborate designs and solving multiple subtasks to establish spatial correspondence. In this paper, we introduce BEVTrack, a simple yet strong baseline framework for 3D SOT. After converting consecutive point clouds into the common Bird's-Eye-View representation, BEVTrack inherently encodes spatial proximity and adeptly captures motion cues for tracking via a simple element-wise operation and con
    
[^83]: 大型过程模型：生成式人工智能时代的业务流程管理

    Large Process Models: Business Process Management in the Age of Generative AI. (arXiv:2309.00900v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2309.00900](http://arxiv.org/abs/2309.00900)

    大型过程模型（LPM）结合了大规模信息语料库和基于知识系统的方法的优势，旨在为组织提供过程建议和优化方案。

    

    大型语言模型（LLMs）和其他生成式人工智能方法的持续成功突显了大规模信息语料库相对于严格定义的符号模型的优势，但也证明了纯统计方法在安全性和可信度方面面临的挑战。为了对LLMs和其他基于基础模型的技术的潜力和限制进行框架化，我们提出了大型过程模型（LPM）的概念，它将LLMs的相关性能力与基于知识系统和自动推理方法的分析精度和可靠性相结合。LPMs被设想为直接利用专家积累的过程管理经验和具有不同特征（例如规模、地区或行业）的组织的过程绩效数据。在这个愿景中，提出的LPM将允许组织接收到对其特征进行了建模的过程建议和优化方案

    The continued success of Large Language Models (LLMs) and other generative artificial intelligence approaches highlights the advantages that large information corpora can have over rigidly defined symbolic models, but also serves as a proof-point of the challenges that purely statistics-based approaches have in terms of safety and trustworthiness. As a framework for contextualizing the potential, as well as the limitations of LLMs and other foundation model-based technologies, we propose the concept of a Large Process Model (LPM) that combines the correlation power of LLMs with the analytical precision and reliability of knowledge-based systems and automated reasoning approaches. LPMs are envisioned to directly utilize the wealth of process management experience that experts have accumulated, as well as process performance data of organizations with diverse characteristics, e.g., regarding size, region, or industry. In this vision, the proposed LPM would allow organizations to receive 
    
[^84]: FonMTL:面向Fon语的多任务学习

    FonMTL: Towards Multitask Learning for the Fon Language. (arXiv:2308.14280v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.14280](http://arxiv.org/abs/2308.14280)

    本文面向Fon语的多任务学习，旨在通过在命名实体识别和词性标注任务上共享知识，增强模型在Fon语自然语言处理中的性能。

    

    Fon语是一种真正的低资源非洲语言，大约有200万人口，其在线存在有限，并且现有数据集也很有限。多任务学习是一种学习范式，旨在通过在不同但相关的任务间共享知识来提高模型的泛化能力，这在数据稀缺的场景中尤为重要。本文提出了第一种探索性的多任务学习方法，用于增强Fon语自然语言处理中的模型能力。具体来说，我们探索了Fon语的命名实体识别（NER）和词性标注（POS）任务。我们利用两个语言模型作为编码器来构建输入的共享表示，并使用线性层块进行每个任务的分类。我们在Fon语的NER和POS任务上的结果与几个多语言预训练语言模型微调的性能相比，表现出竞争力（或更好）。

    The Fon language, spoken by an average 2 million of people, is a truly low-resourced African language, with a limited online presence, and existing datasets (just to name but a few). Multitask learning is a learning paradigm that aims to improve the generalization capacity of a model by sharing knowledge across different but related tasks: this could be prevalent in very data-scarce scenarios. In this paper, we present the first explorative approach to multitask learning, for model capabilities enhancement in Natural Language Processing for the Fon language. Specifically, we explore the tasks of Named Entity Recognition (NER) and Part of Speech Tagging (POS) for Fon. We leverage two language model heads as encoders to build shared representations for the inputs, and we use linear layers blocks for classification relative to each task. Our results on the NER and POS tasks for Fon, show competitive (or better) performances compared to several multilingual pretrained language models finet
    
[^85]: 朝着全息舱式模拟游戏的方向

    Towards a Holodeck-style Simulation Game. (arXiv:2308.13548v1 [cs.AI])

    [http://arxiv.org/abs/2308.13548](http://arxiv.org/abs/2308.13548)

    Infinitia是一个模拟游戏系统，使用生成图像和语言模型根据玩家的描述塑造游戏场景和NPC，类似于全息舱，同时引入了无限生成的幻想世界、可控的NPC行为、幽默对话、成本和时间效率、玩家合作以及游戏内事件的非确定性元素。

    

    我们引入了Infinitia，一个模拟游戏系统，在游戏时间内使用生成图像和语言模型根据玩家的简短描述重新塑造游戏场景和NPC，类似于虚构的全息舱中创建设置的方式。基于《生成代理》论文的思想，我们的系统引入了游戏性元素，如无限生成的幻想世界，NPC行为的可控性，幽默对话，成本和时间效率，玩家之间的合作以及游戏内事件的非确定性元素。Infinitia使用Unity引擎实现了服务器-客户端架构，方便未来社区开发者加入令人兴奋的功能。此外，它使用了多人框架，允许玩家在模拟中存在并进行交互。模拟将很快在https://infinitia.ai/上提供开放式测试版，并且我们期待与社区共同进步。

    We introduce Infinitia, a simulation game system that uses generative image and language models at play time to reshape all aspects of the setting and NPCs based on a short description from the player, in a way similar to how settings are created on the fictional Holodeck. Building off the ideas of the Generative Agents paper, our system introduces gameplay elements, such as infinite generated fantasy worlds, controllability of NPC behavior, humorous dialogue, cost & time efficiency, collaboration between players and elements of non-determinism among in-game events. Infinitia is implemented in the Unity engine with a server-client architecture, facilitating the addition of exciting features by community developers in the future. Furthermore, it uses a multiplayer framework to allow humans to be present and interact in the simulation. The simulation will be available in open-alpha shortly at https://infinitia.ai/ and we are looking forward to building upon it with the community.
    
[^86]: 大规模语言模型在软件工程中的应用：系统性文献综述

    Large Language Models for Software Engineering: A Systematic Literature Review. (arXiv:2308.10620v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2308.10620](http://arxiv.org/abs/2308.10620)

    通过系统性文献综述，本研究调查了大规模语言模型（LLM）在软件工程领域中的应用，并集中于了解如何利用LLM来优化软件工程过程和结果。文章总结了不同LLM的特点和用途以及数据收集和预处理方法的重要性。

    

    大规模语言模型（LLM）在包括软件工程在内的多个领域产生了显著影响。许多最近的文献探讨了LLM在各种软件工程任务和应用中的应用。然而，对LLM在软件工程中的应用、影响和可能的限制的全面理解仍处于初级阶段。为了弥补这一差距，我们对LLM与软件工程的交叉领域进行了系统性文献综述，特别关注LLM在软件工程中如何被利用来优化过程和结果的理解。我们收集和分析了2017年至2023年的229篇研究论文，以回答四个关键研究问题（RQs）。在RQ1中，我们对在软件工程任务中使用的不同LLM进行分类和比较分析，描绘其独特的特点和用途。在RQ2中，我们分析数据收集、预处理和应用中使用的方法，强调了强大、精心策划的数据集对于成功利用LLM非常重要。

    Large Language Models (LLMs) have significantly impacted numerous domains, including Software Engineering (SE). Many recent publications have explored LLMs applied to various SE tasks and applications. Nevertheless, a comprehensive understanding of the application, effects, and possible limitations of LLMs on SE is still in its early stages. To bridge this gap, we conducted a systematic literature review on the intersection of LLMs and SE, with a particular focus on understanding how LLMs can be exploited in SE to optimize processes and outcomes. We collect and analyze a total of 229 research papers from 2017 to 2023 to answer four key research questions (RQs). In RQ1, we categorize and provide a comparative analysis of different LLMs that have been employed in SE tasks, characterising their distinctive features and uses. In RQ2, we analyse the methods used in data collection, preprocessing, and application highlighting the role of robust, well-curated datasets for successful LLM for S
    
[^87]: 适应您的教师: 改进知识蒸馏用于无样本连续学习

    Adapt Your Teacher: Improving Knowledge Distillation for Exemplar-free Continual Learning. (arXiv:2308.09544v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2308.09544](http://arxiv.org/abs/2308.09544)

    本研究提出了一种适应教师的方法（TA）用于无样本连续学习，解决了知识蒸馏方法在这种情况下的性能下降问题，并在多个基准测试中持续提升模型性能。

    

    在这项工作中，我们研究了无样本类别增量学习（CIL），并使用知识蒸馏（KD）作为正则化策略，旨在防止遗忘。KD方法在CIL中取得了成功，但是在没有访问先前任务的训练数据示例的情况下，它们往往很难对模型进行正则化。我们的分析发现，这个问题源于处理分布外数据时教师网络中的显著表示转换。这导致KD损失成分中出现较大的错误，从而导致CIL模型性能下降。受最近的测试时适应方法的启发，我们引入了教师适应（TA）方法，该方法在增量训练过程中同时更新教师和主模型。我们的方法与基于KD的CIL方法无缝集成，能够在多个无样本CIL基准测试中持续提升它们的性能。

    In this work, we investigate exemplar-free class incremental learning (CIL) with knowledge distillation (KD) as a regularization strategy, aiming to prevent forgetting. KD-based methods are successfully used in CIL, but they often struggle to regularize the model without access to exemplars of the training data from previous tasks. Our analysis reveals that this issue originates from substantial representation shifts in the teacher network when dealing with out-of-distribution data. This causes large errors in the KD loss component, leading to performance degradation in CIL models. Inspired by recent test-time adaptation methods, we introduce Teacher Adaptation (TA), a method that concurrently updates the teacher and the main models during incremental training. Our method seamlessly integrates with KD-based CIL approaches and allows for consistent enhancement of their performance across multiple exemplar-free CIL benchmarks.
    
[^88]: 从期望到安全：通过在潜在空间中强制正确的原因来消除深度模型的偏见

    From Hope to Safety: Unlearning Biases of Deep Models by Enforcing the Right Reasons in Latent Space. (arXiv:2308.09437v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2308.09437](http://arxiv.org/abs/2308.09437)

    该论文提出了一种通过梯度减小模型对偏见的敏感性的方法，从而在概念级别上确保正确原因，有效减轻深度神经网络中的偏见。该方法在多个数据集和环境中被验证有效。

    

    深度神经网络容易学习训练数据中潜藏的错误相关性，从而导致可能有偏见的预测。这在将这些模型部署于高风险决策场景（如医学应用）时存在风险。目前的后处理模型校正方法要么需要输入级别的注释，这只适用于局部化偏见，要么通过扩充潜在特征空间，希望能实现正确的原因。我们提出了一种新的方法，通过梯度减小模型对偏见的敏感性，从而在概念级别上确保正确的原因。当通过概念激活向量来建模偏见时，我们强调选择稳健的方向的重要性，因为传统的基于回归的方法（如支持向量机）往往会导致发散的方向。我们使用VGG、ResNet和EfficientN在ISIC、骨龄、ImageNet和CelebA数据集上在受控和真实环境中有效减轻偏见。

    Deep Neural Networks are prone to learning spurious correlations embedded in the training data, leading to potentially biased predictions. This poses risks when deploying these models for high-stake decision-making, such as in medical applications. Current methods for post-hoc model correction either require input-level annotations, which are only possible for spatially localized biases, or augment the latent feature space, thereby hoping to enforce the right reasons. We present a novel method ensuring the right reasons on the concept level by reducing the model's sensitivity towards biases through the gradient. When modeling biases via Concept Activation Vectors, we highlight the importance of choosing robust directions, as traditional regression-based approaches such as Support Vector Machines tend to result in diverging directions. We effectively mitigate biases in controlled and real-world settings on the ISIC, Bone Age, ImageNet and CelebA datasets using VGG, ResNet and EfficientN
    
[^89]: 为什么我们需要神经符号人工智能来建模实用的类比?

    Why Do We Need Neuro-symbolic AI to Model Pragmatic Analogies?. (arXiv:2308.01936v1 [cs.AI])

    [http://arxiv.org/abs/2308.01936](http://arxiv.org/abs/2308.01936)

    本文讨论了神经符号人工智能在处理逐渐复杂的类比推理时的必要性，以提供超越文字内容的广泛、多样化的知识，并结合统计和符号人工智能技术来增强和引导映射过程。

    

    智能的一个特点是能够利用熟悉的领域对不那么熟悉的领域进行推理，即类比推理。本文探讨了大型语言模型（LLMs）在处理在非结构化文本中表达的逐渐复杂的类比时的性能。我们讨论了四个不同复杂级别的类比：词汇类比、句法类比、语义类比和实用类比。随着类比变得越来越复杂，它们需要超出文本内容的广泛、多样化的知识，这在支持LLMs的词汇共现统计中不太可能找到。为了解决这个问题，我们讨论了采用神经符号人工智能技术的必要性，这些技术结合了统计和符号人工智能，根据非结构化文本提供信息以突出和增强相关内容，提供抽象和引导映射过程。我们的知识驱动方法在保持LLMs的效率的同时保持其性能。

    A hallmark of intelligence is the ability to use a familiar domain to make inferences about a less familiar domain, known as analogical reasoning. In this article, we delve into the performance of Large Language Models (LLMs) in dealing with progressively complex analogies expressed in unstructured text. We discuss analogies at four distinct levels of complexity: lexical analogies, syntactic analogies, semantic analogies, and pragmatic analogies. As the analogies become more complex, they require increasingly extensive, diverse knowledge beyond the textual content, unlikely to be found in the lexical co-occurrence statistics that power LLMs. To address this, we discuss the necessity of employing Neuro-symbolic AI techniques that combine statistical and symbolic AI, informing the representation of unstructured text to highlight and augment relevant content, provide abstraction and guide the mapping process. Our knowledge-informed approach maintains the efficiency of LLMs while preservin
    
[^90]: 多模态多损失融合网络

    Multi-Modality Multi-Loss Fusion Network. (arXiv:2308.00264v1 [cs.CL])

    [http://arxiv.org/abs/2308.00264](http://arxiv.org/abs/2308.00264)

    多模态多损失融合网络通过最佳选择和融合多个模态的特征，提高了情感检测的性能，并在多个数据集上实现了最先进的结果。这些研究结果表明了用于增强神经网络中情感检测的特征选择和融合方法的优化方向。

    

    在这项工作中，我们研究了跨多个模态选择和融合特征的最佳方法，并将其组合在神经网络中以改善情感检测。我们比较了不同的融合方法并且研究了多损失训练在多模态融合网络中的影响，从而确定了与子网性能相关的有用发现。我们最好的模型在三个数据集（CMU-MOSI、CMU-MOSEI和CH-SIMS）上实现了最先进的性能，并且在大多数指标上优于其他方法。我们发现，训练多模态特征可以改善单模态测试，并且基于数据集注释模式设计融合方法可以增强模型性能。这些结果表明了在神经网络中增强情感检测的优化特征选择和融合方法的发展方向。

    In this work we investigate the optimal selection and fusion of features across multiple modalities and combine these in a neural network to improve emotion detection. We compare different fusion methods and examine the impact of multi-loss training within the multi-modality fusion network, identifying useful findings relating to subnet performance. Our best model achieves state-of-the-art performance for three datasets (CMU-MOSI, CMU-MOSEI and CH-SIMS), and outperforms the other methods in most metrics. We have found that training on multimodal features improves single modality testing and designing fusion methods based on dataset annotation schema enhances model performance. These results suggest a roadmap towards an optimized feature selection and fusion approach for enhancing emotion detection in neural networks.
    
[^91]: 使用大型语言模型的多语言代码共同演进

    Multilingual Code Co-Evolution Using Large Language Models. (arXiv:2307.14991v1 [cs.SE])

    [http://arxiv.org/abs/2307.14991](http://arxiv.org/abs/2307.14991)

    本文介绍了使用大型语言模型（LLMs）将代码更改从一种编程语言翻译到另一种编程语言的方法。通过设计和实现第一个LLM，Codeditor，以将代码更改建模为编辑序列，并学习不同编程语言之间的关联性，我们为多语言代码共同演进提供了一种新的解决方法。

    

    许多软件项目在多种编程语言中实现API和算法。维护这样的项目很繁琐，因为开发人员必须确保任何变化（例如错误修复或新功能）能够及时且无误地传播到其他编程语言的实现中。在不断变化的软件世界中，使用基于规则的翻译工具（例如转译器）或用于将代码从一种语言翻译成另一种语言的机器学习模型提供有限的价值。每次将整个代码库从一种语言翻译到另一种语言的方式并不符合开发人员的工作方式。在本文中，我们针对一个新颖的任务：使用大型语言模型（LLMs）将代码更改从一种编程语言翻译到另一种编程语言。我们设计并实现了第一个LLM，名为Codeditor，来处理这个任务。Codeditor明确地将代码更改建模为编辑序列，并学习在编程语言之间建立更改的关联性。为了评估Codeditor，我们收集了一个包含6,613个示例的语料库。

    Many software projects implement APIs and algorithms in multiple programming languages. Maintaining such projects is tiresome, as developers have to ensure that any change (e.g., a bug fix or a new feature) is being propagated, timely and without errors, to implementations in other programming languages. In the world of ever-changing software, using rule-based translation tools (i.e., transpilers) or machine learning models for translating code from one language to another provides limited value. Translating each time the entire codebase from one language to another is not the way developers work. In this paper, we target a novel task: translating code changes from one programming language to another using large language models (LLMs). We design and implement the first LLM, dubbed Codeditor, to tackle this task. Codeditor explicitly models code changes as edit sequences and learns to correlate changes across programming languages. To evaluate Codeditor, we collect a corpus of 6,613 ali
    
[^92]: 可解释人工智能（XAI）在年龄预测中的应用：一项系统综述

    eXplainable Artificial Intelligence (XAI) in age prediction: A systematic review. (arXiv:2307.13704v1 [cs.AI])

    [http://arxiv.org/abs/2307.13704](http://arxiv.org/abs/2307.13704)

    本综述探讨了可解释人工智能（XAI）在年龄预测任务中的应用。通过系统性综述，我们讨论了XAI方法在医疗应用和年龄预测领域的益处。

    

    可解释人工智能（XAI）现在是机器学习中的重要组成部分，能够解释复杂模型的预测结果。XAI特别适用于危险应用，特别是在医疗保健领域，人类的生命依赖于AI系统的决策。医疗研究的一个领域是年龄预测和衰老及与年龄相关疾病的生物标志物鉴定。然而，在年龄预测任务中，XAI的作用尚未直接探讨。在本综述中，我们讨论了XAI方法在年龄预测任务中的应用。我们通过器官系统进行了系统性综述，并讨论了XAI在医疗应用以及特别是年龄预测领域的益处。

    eXplainable Artificial Intelligence (XAI) is now an important and essential part of machine learning, allowing to explain the predictions of complex models. XAI is especially required in risky applications, particularly in health care, where human lives depend on the decisions of AI systems. One area of medical research is age prediction and identification of biomarkers of aging and age-related diseases. However, the role of XAI in the age prediction task has not previously been explored directly. In this review, we discuss the application of XAI approaches to age prediction tasks. We give a systematic review of the works organized by body systems, and discuss the benefits of XAI in medical applications and, in particular, in the age prediction domain.
    
[^93]: ProbVLM: 冻结视觉-语言模型的概率适配器

    ProbVLM: Probabilistic Adapter for Frozen Vison-Language Models. (arXiv:2307.00398v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2307.00398](http://arxiv.org/abs/2307.00398)

    ProbVLM是一种概率适配器，用于估计大规模视觉-语言模型中嵌入的概率分布，以解决固有的嵌入歧义问题，并在多个数据集上展示了其在检索任务中的优越性能表现。

    

    大规模视觉-语言模型（VLM）如CLIP成功地在图像和文本之间找到对应关系。通过标准的确定性映射过程，将图像或文本样本映射到嵌入空间中的一个向量。这是有问题的：由于多个样本（图像或文本）可以抽象出物理世界中的相同概念，确定性嵌入不反映嵌入空间中的固有歧义性。我们提出了ProbVLM，一种概率适配器，通过事后方式在预训练的VLM中通过内部/外部模态对齐估计嵌入的概率分布，而无需大规模数据集或计算。在四个具有挑战性的数据集上，即COCO、Flickr、CUB和Oxford-flowers，我们估计了两个VLM（CLIP和BLIP）的多模态嵌入不确定性，量化了嵌入不确定性在检索任务中的校准，并表明ProbVLM优于其他方法。此外，我们提出了主动学习和模型...

    Large-scale vision-language models (VLMs) like CLIP successfully find correspondences between images and text. Through the standard deterministic mapping process, an image or a text sample is mapped to a single vector in the embedding space. This is problematic: as multiple samples (images or text) can abstract the same concept in the physical world, deterministic embeddings do not reflect the inherent ambiguity in the embedding space. We propose ProbVLM, a probabilistic adapter that estimates probability distributions for the embeddings of pre-trained VLMs via inter/intra-modal alignment in a post-hoc manner without needing large-scale datasets or computing. On four challenging datasets, i.e., COCO, Flickr, CUB, and Oxford-flowers, we estimate the multi-modal embedding uncertainties for two VLMs, i.e., CLIP and BLIP, quantify the calibration of embedding uncertainties in retrieval tasks and show that ProbVLM outperforms other methods. Furthermore, we propose active learning and model 
    
[^94]: PaLM 2 技术报告

    PaLM 2 Technical Report. (arXiv:2305.10403v1 [cs.CL])

    [http://arxiv.org/abs/2305.10403](http://arxiv.org/abs/2305.10403)

    PaLM 2 是一种计算效率更高的最先进的语言模型，提供了更好的多语言和推理能力，并且通过使用多种目标进行训练，获得了在不同模型大小的下游任务上显着的改进质量。此外，PaLM 2 还展示了强大的推理能力和稳定的性能表现，使得模型能够更广泛地部署，并且可以控制毒性推理时间，而不会对其他能力产生影响。

    

    我们介绍了 PaLM 2，这是一种新的最先进的语言模型，比其前身 PaLM 在多语言和推理能力方面更加出色，并且计算效率更高。PaLM 2 是一种基于 Transformer 的模型，使用多种目标进行训练。通过对英语和多语言语言以及推理任务的广泛评估，我们展示了 PaLM 2 在不同模型大小的下游任务上具有显着的改进质量，同时展现了比 PaLM 更快和更有效的推理能力。这种改进的效率使得模型能够更广泛地部署，同时也使得模型能够更快地响应，以获得更自然的交互节奏。PaLM 2 展示了强大的推理能力，在 BIG-Bench 和其他推理任务上相对于 PaLM 有巨大的改进。PaLM 2 在一套负责人的 AI 评估中表现出稳定的性能，并且在没有附加运行开销或对其他能力产生影响的情况下，能够对毒性进行推理时间的控制。

    We introduce PaLM 2, a new state-of-the-art language model that has better multilingual and reasoning capabilities and is more compute-efficient than its predecessor PaLM. PaLM 2 is a Transformer-based model trained using a mixture of objectives. Through extensive evaluations on English and multilingual language, and reasoning tasks, we demonstrate that PaLM 2 has significantly improved quality on downstream tasks across different model sizes, while simultaneously exhibiting faster and more efficient inference compared to PaLM. This improved efficiency enables broader deployment while also allowing the model to respond faster, for a more natural pace of interaction. PaLM 2 demonstrates robust reasoning capabilities exemplified by large improvements over PaLM on BIG-Bench and other reasoning tasks. PaLM 2 exhibits stable performance on a suite of responsible AI evaluations, and enables inference-time control over toxicity without additional overhead or impact on other capabilities. Over
    
[^95]: PyTorch FSDP：全面分片数据并行规模化的经验

    PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel. (arXiv:2304.11277v1 [cs.DC])

    [http://arxiv.org/abs/2304.11277](http://arxiv.org/abs/2304.11277)

    本论文介绍了基于PyTorch的Fully Sharded Data Parallel（FSDP）解决方案，该方案可扩展大型模型训练，并优化各种硬件配置的资源利用率。

    

    众所周知，大型模型在广泛领域内具有优异的性能潜力。尽管机器学习系统研究领域取得了显著进展，使得开发和探索大型模型成为可能，但这些能力仍受限于少数高级用户和行业领袖，导致技术上的隐含壁垒阻碍广泛社区访问和利用这些技术。本文介绍了PyTorch Fully Sharded Data Parallel（FSDP）作为大型模型训练的产业级解决方案。FSDP已与几个关键PyTorch核心组件（包括张量实现、分发器系统和CUDA内存缓存分配器）密切协作，以提供非侵入式用户体验和高训练效率。此外，FSDP本地集成了一系列技术和设置，优化了各种硬件配置的资源利用率。

    It is widely acknowledged that large models have the potential to deliver superior performance across a broad range of domains. Despite the remarkable progress made in the field of machine learning systems research, which has enabled the development and exploration of large models, such abilities remain confined to a small group of advanced users and industry leaders, resulting in an implicit technical barrier for the wider community to access and leverage these technologies. In this paper, we introduce PyTorch Fully Sharded Data Parallel (FSDP) as an industry-grade solution for large model training. FSDP has been closely co-designed with several key PyTorch core components including Tensor implementation, dispatcher system, and CUDA memory caching allocator, to provide non-intrusive user experiences and high training efficiency. Additionally, FSDP natively incorporates a range of techniques and settings to optimize resource utilization across a variety of hardware configurations. The 
    
[^96]: 多粒度时间变换器用于知识追踪

    Multi-granulariy Time-based Transformer for Knowledge Tracing. (arXiv:2304.05257v1 [cs.LG])

    [http://arxiv.org/abs/2304.05257](http://arxiv.org/abs/2304.05257)

    本文提出了一种基于Transformer的架构用于准确地预测学生在标准化测试中的表现。该模型考虑了学生的历史数据，包括他们以往的考试成绩、学习习惯和其他相关信息，并在解码器输入中使用了多个时间特征粒度以显著提高模型性能。与LightGBM相比，该方法更加准确，为教育领域的AI发展提供了一个可伸缩和准确的预测学生成果的工具。

    

    本文提出了一种基于Transformer的架构，用于预测标准化测试中学生的表现。具体来说，我们利用学生的历史数据，包括他们以往的考试成绩、学习习惯和其他相关信息，为每个学生创建一个个性化的模型。然后，我们使用这些模型来预测学生在给定测试中的未来表现。将该模型应用于RIIID数据集，我们证明使用多个时间特征粒度作为解码器输入可以显着提高模型性能。我们的结果还表明了我们方法的有效性，相对于LightGBM方法有很大的改进。我们的工作为教育领域的AI发展做出了贡献，提供了一个可伸缩和准确的预测学生成果的工具。

    In this paper, we present a transformer architecture for predicting student performance on standardized tests. Specifically, we leverage students historical data, including their past test scores, study habits, and other relevant information, to create a personalized model for each student. We then use these models to predict their future performance on a given test. Applying this model to the RIIID dataset, we demonstrate that using multiple granularities for temporal features as the decoder input significantly improve model performance. Our results also show the effectiveness of our approach, with substantial improvements over the LightGBM method. Our work contributes to the growing field of AI in education, providing a scalable and accurate tool for predicting student outcomes.
    
[^97]: 大型语言模型生成混合代码文本的提示：东南亚语言的案例

    Prompting Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages. (arXiv:2303.13592v1 [cs.CL])

    [http://arxiv.org/abs/2303.13592](http://arxiv.org/abs/2303.13592)

    本文探讨了使用大型语言模型（LLMs）生成东南亚五种语言和Singlish的混合代码数据的方法，发现ChatGPT展现出最高的潜力。然而，由于词汇选择错误的影响，ChatGPT和InstructGPT在生成混合代码时的熟练程度受到限制。

    

    尽管混合代码在世界许多地区是一种常见的语言实践，但收集高质量且低成本的混合代码数据仍然是自然语言处理（NLP）研究的重大挑战。最近大型语言模型（LLMs）的普及迫使人们问：这些系统能用于数据生成吗？在本文中，我们探讨了在一个零-shot的方式下如何提示LLMs为东南亚（SEA）的五种语言（印尼语，马来语，中文，塔加路语，越南语）及克里奥尔语S ingl ish创造混合代码数据。我们发现，ChatGPT显示出最大的潜力，当明确定义“混合代码”术语时，能够68%的时间生成混合代码文本。此外，ChatGPT和InstructGPT（davinci-003）生成S ingl ish文本的表现也值得注意，它们在各种提示下的成功率平均为96%。但是，ChatGPT和InstructGPT的混合代码熟练程度受到词汇选择错误的影响，导致语义不正确的输出。

    While code-mixing is a common linguistic practice in many parts of the world, collecting high-quality and low-cost code-mixed data remains a challenge for natural language processing (NLP) research. The proliferation of Large Language Models (LLMs) in recent times compels one to ask: can these systems be used for data generation? In this article, we explore prompting LLMs in a zero-shot manner to create code-mixed data for five languages in South East Asia (SEA) -Indonesian, Malay, Chinese, Tagalog, Vietnamese, as well as the creole language Singlish. We find that ChatGPT shows the most potential, capable of producing code-mixed text 68% of the time when the term "code-mixing" is explicitly defined. Moreover, both ChatGPT and InstructGPT's (davinci-003) performances in generating Singlish texts are noteworthy, averaging a 96% success rate across a variety of prompts. The code-mixing proficiency of ChatGPT and InstructGPT, however, is dampened by word choice errors that lead to semant
    
[^98]: 结构化知识增强的开放世界故事生成：一项全面调查

    Open-world Story Generation with Structured Knowledge Enhancement: A Comprehensive Survey. (arXiv:2212.04634v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.04634](http://arxiv.org/abs/2212.04634)

    本文对结构化知识增强的故事生成进行了综述，总结了目前的方法与技术，指出了未来的发展方向和尚未解决的问题。

    

    讲故事和叙事是人类体验的基础，与我们的社会和文化参与密不可分。因此，长期以来，研究人员一直尝试创建能够自动生成故事的系统。近年来，受深度学习和大规模数据资源的推动，自动生成故事已经取得了很大的进展。然而，仍然存在一些重大挑战，例如，需要在生成的故事中实现全局一致性，这使得生成模型无法达到与人类叙述者相同的叙事能力。为了解决这些挑战，许多研究试图在生成过程中注入结构化知识，这被称为结构化知识增强的故事生成。将外部知识纳入其中可以增强故事事件之间的逻辑连贯性，实现更好的知识基础，并减轻故事中过度概括和重复问题。本次调查提供了对该研究领域的最新和全面的回顾：（i）我们提供了对结构化知识增强故事生成的综述，（ii）我们总结了目前的方法与技术，（iii）我们指出了尚待解决的问题与未来的发展方向。

    Storytelling and narrative are fundamental to human experience, intertwined with our social and cultural engagement. As such, researchers have long attempted to create systems that can generate stories automatically. In recent years, powered by deep learning and massive data resources, automatic story generation has shown significant advances. However, considerable challenges, like the need for global coherence in generated stories, still hamper generative models from reaching the same storytelling ability as human narrators. To tackle these challenges, many studies seek to inject structured knowledge into the generation process, which is referred to as structured knowledge-enhanced story generation. Incorporating external knowledge can enhance the logical coherence among story events, achieve better knowledge grounding, and alleviate over-generalization and repetition problems in stories. This survey provides the latest and comprehensive review of this research field: (i) we present a
    
[^99]: 计算效率高的强化学习：基于简单规则的有针对性探索

    Computationally Efficient Reinforcement Learning: Targeted Exploration leveraging simple Rules. (arXiv:2211.16691v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.16691](http://arxiv.org/abs/2211.16691)

    本研究提出了一种基于简单规则的有针对性探索方法，通过避免已知子优的状态-动作空间区域来更快地加速强化学习代理程序的收敛，并在一个房间温度控制案例研究中实现了比传统方法快6-7倍的速度收敛。

    

    强化学习通常由于需要穷举探索状态-动作空间以找到表现良好的策略而导致样本复杂度不太好。然而，我们认为系统的专家知识通常允许我们设计简单规则，我们期望良好的策略始终遵循这些规则。因此，在本研究中，我们提出了一种简单而有效的连续演员-评论家框架的修改版本，以纳入这些规则并避免已知子优的状态-动作空间区域，从而显着加速强化学习代理程序的改进。具体而言，如果代理程序选择的动作不符合我们的直觉，我们会饱和这些动作，关键是修改策略的梯度更新步骤，以确保学习流程不受饱和步骤的影响。在一个房间温度控制案例研究中，它使代理程序以比传统代理程序快6-7倍的速度收敛到表现良好的策略，而不需要消耗额外的计算资源。

    Reinforcement Learning (RL) generally suffers from poor sample complexity, mostly due to the need to exhaustively explore the state-action space to find well-performing policies. On the other hand, we postulate that expert knowledge of the system often allows us to design simple rules we expect good policies to follow at all times. In this work, we hence propose a simple yet effective modification of continuous actor-critic frameworks to incorporate such rules and avoid regions of the state-action space that are known to be suboptimal, thereby significantly accelerating the convergence of RL agents. Concretely, we saturate the actions chosen by the agent if they do not comply with our intuition and, critically, modify the gradient update step of the policy to ensure the learning process is not affected by the saturation step. On a room temperature control case study, it allows agents to converge to well-performing policies up to 6-7x faster than classical agents without computational o
    
[^100]: 深度图聚类综述：分类、挑战、应用和开放资源

    A Survey of Deep Graph Clustering: Taxonomy, Challenge, Application, and Open Resource. (arXiv:2211.12875v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.12875](http://arxiv.org/abs/2211.12875)

    在这篇论文中，作者对深度图聚类进行了综述研究。首先介绍了该领域的定义、评估和发展，然后提出了深度图聚类方法的分类学，并对现有方法进行了分析，总结出了挑战和机会。

    

    图聚类旨在将图中的节点划分为若干不同的簇，是一项基础且具有挑战性的任务。近年来，借助深度学习强大的表示能力，深度图聚类方法取得了巨大成功。然而，对于这个领域的综述论文相对较少，综述该领域的工作势在必行。基于此动机，我们进行了深度图聚类的综述研究。首先，我们介绍了该领域的公式化定义、评估和发展。其次，基于图类型、网络架构、学习范式和聚类方法等四个不同的标准，提出了深度图聚类方法的分类学。第三，我们通过广泛的实验对现有方法进行了详细分析，并从图数据质量、稳定性、可扩展性、辨别能力和未知簇数等五个角度总结了挑战和机会。

    Graph clustering, which aims to divide nodes in the graph into several distinct clusters, is a fundamental yet challenging task. Benefiting from the powerful representation capability of deep learning, deep graph clustering methods have achieved great success in recent years. However, the corresponding survey paper is relatively scarce, and it is imminent to make a summary of this field. From this motivation, we conduct a comprehensive survey of deep graph clustering. Firstly, we introduce formulaic definition, evaluation, and development in this field. Secondly, the taxonomy of deep graph clustering methods is presented based on four different criteria, including graph type, network architecture, learning paradigm, and clustering method. Thirdly, we carefully analyze the existing methods via extensive experiments and summarize the challenges and opportunities from five perspectives, including graph data quality, stability, scalability, discriminative capability, and unknown cluster nu
    
[^101]: 图上的多尺度Wasserstein最短路径过滤核心

    Multi-scale Wasserstein Shortest-path Filtration Kernels on Graphs. (arXiv:2206.00979v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.00979](http://arxiv.org/abs/2206.00979)

    这篇论文提出了一种名为多尺度Wasserstein最短路径过滤图核心（MWSPF）的新型最短路径图核心，解决了传统核心的信息丢失和缺乏多个尺度考虑的问题。

    

    传统的最短路径图核心（SP）是最受欢迎的图核心之一。它将图分解为最短路径，并计算每个图中最短路径的频率。然而，SP面临两个主要挑战：首先，最短路径的三元表示失去了信息。其次，SP比较图时没有考虑到图结构的多个不同尺度，而这在现实世界的图中很常见，例如社交网络中的链状结构、环状结构和星状结构。为了克服这两个挑战，我们开发了一种新颖的最短路径图核心，称为多尺度Wasserstein最短路径过滤图核心（MWSPF）。它使用以每个顶点为根的某个深度的BFS树来限制考虑最短路径的最大长度，考虑到小世界特性。它考虑了最短路径中所有顶点的标签。为了方便在多个不同尺度上比较图，它从顶点和

    The traditional shortest-path graph kernel (SP) is one of the most popular graph kernels. It decomposes graphs into shortest paths and computes their frequencies in each graph. However, SP has two main challenges: Firstly, the triplet representation of the shortest path loses information. Secondly, SP compares graphs without considering the multiple different scales of the graph structure which is common in real-world graphs, e.g., the chain-, ring-, and star-structures in social networks. To overcome these two challenges, we develop a novel shortest-path graph kernel called the Multi-scale Wasserstein Shortest-Path Filtration graph kernel (MWSPF). It uses a BFS tree of a certain depth rooted at each vertex to restrict the maximum length of the shortest path considering the small world property. It considers the labels of all the vertices in the shortest path. To facilitate the comparison of graphs at multiple different scales, it augments graphs from both the aspects of the vertex and
    
[^102]: 检验自然语言模型对人类语言判断预测的极限

    Testing the limits of natural language models for predicting human language judgments. (arXiv:2204.03592v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2204.03592](http://arxiv.org/abs/2204.03592)

    该论文通过对争议句对进行实验比较，发现神经网络语言模型中GPT-2与人类判断最为一致，揭示了模型的失败以及找出最符合人类判断的模型。

    

    神经网络语言模型可以作为关于人类语言处理方式的计算假设。我们使用一种新颖的实验方法对多样的语言模型进行了模型与人类一致性的比较：争议句对。对于每个争议句对，两个语言模型在哪个句子更可能出现在自然文本中上存在不同意见。考虑到九个语言模型（包括n-gram、循环神经网络和变换器模型），我们通过从语料库中选择句子或者合成优化句对来创建了数百个这样的争议句对。然后，人类受试者提供了判断，指示在每个句对中，哪个句子更可能发生。争议句对被证明极为有效，能够揭示模型的失败和识别与人类判断最为一致的模型。经过测试，最符合人类判断的模型是GPT-2，尽管实验还发现了显著的其他模型。

    Neural network language models can serve as computational hypotheses about how humans process language. We compared the model-human consistency of diverse language models using a novel experimental approach: controversial sentence pairs. For each controversial sentence pair, two language models disagree about which sentence is more likely to occur in natural text. Considering nine language models (including n-gram, recurrent neural networks, and transformer models), we created hundreds of such controversial sentence pairs by either selecting sentences from a corpus or synthetically optimizing sentence pairs to be highly controversial. Human subjects then provided judgments indicating for each pair which of the two sentences is more likely. Controversial sentence pairs proved highly effective at revealing model failures and identifying models that aligned most closely with human judgments. The most human-consistent model tested was GPT-2, although experiments also revealed significant s
    
[^103]: 使用区分特征度量下游分类的自监督表示质量

    Measuring Self-Supervised Representation Quality for Downstream Classification using Discriminative Features. (arXiv:2203.01881v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.01881](http://arxiv.org/abs/2203.01881)

    从自监督学习模型中提取区分特征，并使用它们压缩表示空间，提出了一种Q-Score自监督表示质量分数，可以可靠地预测线性评估期间的错误分类。

    

    自监督学习在下游分类任务中展现出了惊人的结果。然而，对于它们的失败模式和学习表示的解释，存在着有限的研究。本文研究了 SimCLR、SwaV、MoCo、BYOL、DINO、SimSiam、VICReg 和 Barlow Twins 等最先进的自监督模型的表示空间。在不使用类标签信息的情况下，我们发现了对应于图像中独特物理属性的区分特征，这些区分特征主要存在于正确分类的表示中。使用这些特征，我们可以将表示空间压缩多达 40%，而不会显著影响线性分类性能。然后，我们提出了自监督表示质量分数（或 Q-Score），这是一种模型无关、无监督的分数，可以可靠地预测一个给定样本在线性评估期间是否可能被错误分类，并在 ImageNet-100 和 ImageNet-1K 上实现了 AUPRC 分别为 91.45 和 78.78。

    Self-supervised learning has shown impressive results in downstream classification tasks. However, there is limited work in understanding their failure modes and interpreting their learned representations. In this paper, we study the representation space of state-of-the-art self-supervised models including SimCLR, SwaV, MoCo, BYOL, DINO, SimSiam, VICReg and Barlow Twins. Without the use of class label information, we discover discriminative features that correspond to unique physical attributes in images, present mostly in correctly-classified representations. Using these features, we can compress the representation space by up to $40\%$ without significantly affecting linear classification performance. We then propose Self-Supervised Representation Quality Score (or Q-Score), a model-agnostic, unsupervised score that can reliably predict if a given sample is likely to be mis-classified during linear evaluation, achieving AUPRC of 91.45 on ImageNet-100 and 78.78 on ImageNet-1K. Q-Score
    
[^104]: 基于构造的可观测线性随机系统的避让控制

    Correct-by-construction reach-avoid control of partially observable linear stochastic systems. (arXiv:2103.02398v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2103.02398](http://arxiv.org/abs/2103.02398)

    本文提出了一种基于构造的方法来合成可观测线性随机系统的避让控制器，通过使用卡尔曼滤波器得到未测量状态的高斯置信度的有限状态抽象，并将其形式化为马尔可夫决策过程（MDP）。这种控制器可以以一种鲁棒的方式避免不安全状态。

    

    我们研究了具有高斯过程和测量噪声的离散时间、线性时不变系统的可观测控制器合成问题。问题是计算一个控制器，使得系统在有限时间内以至少一定的概率达到期望的目标状态，同时避免不安全状态。由于随机性和非凸性，该问题通常不具备精确的算法或闭式解。我们的主要贡献是基于使用卡尔曼滤波器获得的对未测量状态的高斯置信度的有限状态抽象，提出了一个基于构造的控制器合成方案。我们将这种抽象形式化为马尔可夫决策过程（MDP）。为了对近似转移概率的数值不精确性具有鲁棒性，我们使用具有转移概率区间的MDP。通过构造，抽象上的任何策略都可以细化为LTI系统的分段线性反馈控制器。我们证明了

    We study feedback controller synthesis for reach-avoid control of discrete-time, linear time-invariant (LTI) systems with Gaussian process and measurement noise. The problem is to compute a controller such that, with at least some required probability, the system reaches a desired goal state in finite time while avoiding unsafe states. Due to stochasticity and nonconvexity, this problem does not admit exact algorithmic or closed-form solutions in general. Our key contribution is a correct-by-construction controller synthesis scheme based on a finite-state abstraction of a Gaussian belief over the unmeasured state, obtained using a Kalman filter. We formalize this abstraction as a Markov decision process (MDP). To be robust against numerical imprecision in approximating transition probabilities, we use MDPs with intervals of transition probabilities. By construction, any policy on the abstraction can be refined into a piecewise linear feedback controller for the LTI system. We prove tha
    
[^105]: 回归任务中的离群样本检测：参数与预测器熵比较

    Out-of-distribution detection for regression tasks: parameter versus predictor entropy. (arXiv:2010.12995v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2010.12995](http://arxiv.org/abs/2010.12995)

    本研究针对回归任务中的离群样本检测进行了实证评估，发现通过学习多样的预测器可以估计新观测实例的认识不确定性，但参数的多样性并不一定能转化为预测器的多样性。

    

    对于机器学习模型来说，检测样本与训练样本相距太远时至关重要，这被称为离群样本（OOD）检测。对于神经网络而言，一种处理这个任务的方法是学习多样的预测器，这些预测器都能解释训练数据。这些信息可以用来估计新观测实例的认识不确定性，通过预测结果的不一致性来衡量。评估和认证方法检测OOD的能力需要指定在部署中可能发生但没有可用预测的实例。我们选择回归任务作为研究重点，在此任务中选择一个简单而有洞察力的模型来表示OOD分布，并对各种方法在区分OOD样本和数据中的能力进行实证评估。此外，我们还提供证据表明，参数的多样性可能无法转化为预测器的多样性。

    It is crucial to detect when an instance lies downright too far from the training samples for the machine learning model to be trusted, a challenge known as out-of-distribution (OOD) detection. For neural networks, one approach to this task consists of learning a diversity of predictors that all can explain the training data. This information can be used to estimate the epistemic uncertainty at a given newly observed instance in terms of a measure of the disagreement of the predictions. Evaluation and certification of the ability of a method to detect OOD require specifying instances which are likely to occur in deployment yet on which no prediction is available. Focusing on regression tasks, we choose a simple yet insightful model for this OOD distribution and conduct an empirical evaluation of the ability of various methods to discriminate OOD samples from the data. Moreover, we exhibit evidence that a diversity of parameters may fail to translate to a diversity of predictors. Based 
    

