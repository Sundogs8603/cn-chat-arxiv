# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [SoftZoo: A Soft Robot Co-design Benchmark For Locomotion In Diverse Environments.](http://arxiv.org/abs/2303.09555) | SoftZoo是一个面向多种环境的软体机器人协同设计平台，支持广泛、自然启发的材料组合和多种任务，并提供了形态和控制的可微分设计表示。通过一致的评估指标，SoftZoo允许直接比较不同方法，并揭示了软体机器人设计中的权衡。 |
| [^2] | [Dataflow graphs as complete causal graphs.](http://arxiv.org/abs/2303.09552) | 本篇论文介绍了一种替代的软件设计方法——基于流的编程（FBP），并强调了FBP生成的数据流图和结构性因果模型之间的联系，通过这种联系可以改进软件项目中的日常任务，包括故障定位、业务分析和实验室实验。 |
| [^3] | [WebSHAP: Towards Explaining Any Machine Learning Models Anywhere.](http://arxiv.org/abs/2303.09545) | WebSHAP是第一个将先进的模型无关解释技术SHAP适应Web环境的浏览器内工具，可用于解释基于ML的贷款批准决策。 |
| [^4] | [SemDeDup: Data-efficient learning at web-scale through semantic deduplication.](http://arxiv.org/abs/2303.09540) | SemDeDup是一种利用预训练模型的嵌入来识别和删除语义重复项的方法。通过对LAION的子集进行分析，SemDeDup可以最小化性能损失的同时删除50%的数据，实际上将训练时间减半。此外，SemDeDup在提供效率收益的同时改进了先前的方法。 |
| [^5] | [Among Us: Adversarially Robust Collaborative Perception by Consensus.](http://arxiv.org/abs/2303.09495) | ROBOSAC提出了一种基于共识的反对抗鲁棒协同感知防御策略，使用随机子集的队友来对比协同感知和单个感知的结果，以排除潜在攻击者，并推导出确保获得所需无攻击者子集所需的采样试验个数。 |
| [^6] | [Effectively Modeling Time Series with Simple Discrete State Spaces.](http://arxiv.org/abs/2303.09489) | 介绍了一种名为SpaceTime的状态空间时间序列架构，提出了基于伴随矩阵的新的SSM参数化方法，能够学习自回归过程，有效预测远期。 |
| [^7] | [Arbitrary Order Meta-Learning with Simple Population-Based Evolution.](http://arxiv.org/abs/2303.09478) | 本文提出了一种简单的基于群体进化的元学习方法，可以隐式地优化任意高阶的元参数，从而加速学习。 |
| [^8] | [Combining Distance to Class Centroids and Outlier Discounting for Improved Learning with Noisy Labels.](http://arxiv.org/abs/2303.09470) | 本文提出了结合类中心距离和异常值折扣的方法，用于解决在存在噪声标签的情况下训练机器学习模型的问题，并通过实验证明了其有效性 。 |
| [^9] | [Proof Number Based Monte-Carlo Tree Search.](http://arxiv.org/abs/2303.09449) | 本文提出了一种将蒙特卡罗树搜索和证明数搜索相结合的PN-MCTS算法，该算法在多个游戏中均表现出优越的性能，可用于最终走步选择、解决子树以及UCT公式。 |
| [^10] | [Steering Prototype with Prompt-tuning for Rehearsal-free Continual Learning.](http://arxiv.org/abs/2303.09447) | 本研究提出了一个新的连续学习模型——对比原型提示，使用任务特异性提示调整来提高原型性能，同时避免了语义漂移和原型干扰问题。基于此模型的CPP方法在四个具有挑战性的类增量学习基准测试中表现出色，相对于其他最先进的方法有4%至6%的绝对提升。该方法不需要重复训练，性能接近离线联合学习，展示了一种有前途的设计方案。 |
| [^11] | [Controlling High-Dimensional Data With Sparse Input.](http://arxiv.org/abs/2303.09446) | 本论文提出了一种新的控制机制，即将稀疏、易于人理解的控制空间映射到生成模型的潜在空间。通过实验，此方法表现出了效率、鲁棒性和保真性，即使只有少量的输入数值。 |
| [^12] | [Cryptocurrency Price Prediction using Twitter Sentiment Analysis.](http://arxiv.org/abs/2303.09397) | 本研究使用历史价格和Twitter情感分析预测比特币价格，并取得了不错的效果。情感预测的平均绝对百分比误差为9.45％，价格预测的平均绝对百分比误差为3.6％。 |
| [^13] | [Predicting Human Attention using Computational Attention.](http://arxiv.org/abs/2303.09383) | HAT是一种计算注意力模型，使用新颖的基于变换器的结构和简化的凹视网膜，实现了对于目标存在和目标缺失搜索期间注视行为的扫描路径的最新技术水平。 |
| [^14] | [Protecting Society from AI Misuse: When are Restrictions on Capabilities Warranted?.](http://arxiv.org/abs/2303.09377) | 随着人工智能系统能力不断提升，控制某些能力将有助于防止其滥用，这些限制可能包括控制访问、使用目的、输出与溯源以及开发资源，非AI能力限制也是必要的。尽管可能会降低使用率而增加滥用风险，但这些限制是当其他干预行不通、潜在危害性高、有有针对性方式干预时所必要的。 |
| [^15] | [3D Masked Autoencoding and Pseudo-labeling for Domain Adaptive Segmentation of Heterogeneous Infant Brain MRI.](http://arxiv.org/abs/2303.09373) | 本文提出了一种名为 MAPSeg 的新框架，采用 3D 蒙版自编码和伪标签的方式，实现了跨年龄、跨模态和跨场景下对婴儿脑 MRI 中亚皮质区域的分割，充分考虑不同 MRI 扫描仪、供应商或采集序列以及不同的神经发育阶段所造成的内在异质性，提高了分割结果的鲁棒性。 |
| [^16] | [The NCI Imaging Data Commons as a platform for reproducible research in computational pathology.](http://arxiv.org/abs/2303.09354) | 国家癌症研究所影像数据共享平台 (IDC) 旨在促进计算病理学领域的研究可重复性，实现了 FAIR 原则，提供公共库和云端技术支持，方便使用机器学习方法进行癌症组织分类研究。 |
| [^17] | [Real-time elastic partial shape matching using a neural network-based adjoint method.](http://arxiv.org/abs/2303.09343) | 本文提出了一种基于神经网络的伴随方法来实现实时弹性的部分形状匹配，该方法采用前馈神经网络来求解超弹性问题，通过网络的反向传播获得伴随问题，结合最优控制问题来求解未知量应用于物体的表面力分布。该流程大大提高了计算速度，同时提供了可接受的注册误差。 |
| [^18] | [Can Generative Pre-trained Transformers (GPT) Pass Assessments in Higher Education Programming Courses?.](http://arxiv.org/abs/2303.09325) | 该研究评估了生成式预训练变压器（GPT）在高等教育Python编程课程的初级和中级评估中的能力，并发现其在解决复杂的编程问题上遇到困难，限制了其在编程教育中的应用。 |
| [^19] | [TOT: Topology-Aware Optimal Transport For Multimodal Hate Detection.](http://arxiv.org/abs/2303.09314) | 本文针对隐式危害检测的挑战，提出一种面向表情包情境的拓扑感知最优传输框架TOT，利用最优传输核方法从多个模态中捕捉互补信息。 |
| [^20] | [Taking advantage of a very simple property to efficiently infer NFAs.](http://arxiv.org/abs/2303.09311) | 本文提出了一个利用简单属性高效推断NFA的方法，并且在实验证明了该方法比现有技术具有竞争力。 |
| [^21] | [Towards Robust Bangla Complex Named Entity Recognition.](http://arxiv.org/abs/2303.09306) | 本研究构建了基于 CRF 和深度学习（如 BanglaBERT）的鲁棒孟加拉复杂命名实体识别模型，解决了 CNER 任务，填补了孟加拉语复杂命名实体识别领域的空白。 |
| [^22] | [Explaining Groups of Instances Counterfactually for XAI: A Use Case, Algorithm and User Study for Group-Counterfactuals.](http://arxiv.org/abs/2303.09297) | 该论文探索了一种新的用例，使用“群体反事实”集体解释类似实例的组，提出了一种新颖的群体反事实算法来生成高覆盖率的解释，适合人类对连贯、广泛解释的喜好。 |
| [^23] | [Exploring Resiliency to Natural Image Corruptions in Deep Learning using Design Diversity.](http://arxiv.org/abs/2303.09283) | 本文研究了深度学习图像分类器集合的多样性指标、准确性和对自然图像污染的韧性之间的关系，并发现实现设计选择的多样性可以降低故障模式的数量。 |
| [^24] | [Topology optimization with physics-informed neural networks: application to noninvasive detection of hidden geometries.](http://arxiv.org/abs/2303.09280) | 该论文介绍了一种基于物理知识神经网络的拓扑优化方法，应用于无先验知识的几何结构检测，通过材料密度场表示任意解决方案拓扑，并通过Eikonal正则化实现。该方法可用于医疗和工业应用中的非侵入式成像技术。 |
| [^25] | [Finding Minimum-Cost Explanations for Predictions made by Tree Ensembles.](http://arxiv.org/abs/2303.09271) | 本研究提出了一种高效的oracle系统，能够寻找树集成模型预测的最小代价解释，该算法比目前最先进的替代方案的运行表现更好。m-MARCO算法可以计算每个预测的单个最小解释，并证明相对于枚举所有最小解释的MARCO算法，我们的方法具有两倍的总体加速比。 |
| [^26] | [SmartBERT: A Promotion of Dynamic Early Exiting Mechanism for Accelerating BERT Inference.](http://arxiv.org/abs/2303.09266) | SmartBERT是一种改进的动态早期退出与层跳过机制，可以自适应地跳过一些层并自适应地选择是否退出，以加速BERT模型的推理速度。 |
| [^27] | [Human-AI Collaboration: The Effect of AI Delegation on Human Task Performance and Task Satisfaction.](http://arxiv.org/abs/2303.09224) | 人工智能（AI）模型可以学习决定是否为任务的实例预测或将其委派给人类，研究显示AI委派可以提高任务表现和任务满意度，无论人类是否意识到委派。人类高水平的自我效能感是这些改善的基础机制。 |
| [^28] | [A Dual Branch Network for Emotional Reaction Intensity Estimation.](http://arxiv.org/abs/2303.09210) | 本文提出了一种基于双分支的多输出回归模型，利用空间注意力和Mel-Frequency Cepstral Coefficients技术来提取视觉和声学特征，并添加了一种模态丢失方法来融合多模态特征，能够有效地解决情感反应强度估计的挑战。 |
| [^29] | [Recommending the optimal policy by learning to act from temporal data.](http://arxiv.org/abs/2303.09209) | 本文提出了一种基于强化学习算法的方法，可以从过去的执行记录中学习KPI的最佳策略，以推荐优化KPI的最佳操作。 |
| [^30] | [Temporality and Causality in Abstract Argumentation.](http://arxiv.org/abs/2303.09197) | 该论文研究了抽象论证中的时间性和因果关系，提出了一种形式化的方法，将无环抽象论证框架的概念重新编写成一个行动语言，并建立起论据陈述和它们直接或间接后果之间的因果关系。 |
| [^31] | [Learning Logic Specifications for Soft Policy Guidance in POMCP.](http://arxiv.org/abs/2303.09172) | 论文提出了一种从POMCP执行中学习逻辑规范的方法，以实现软政策指导，代替手动定义的策略相关规则，并用于解决环境状态空间大的问题。 |
| [^32] | [Emotional Reaction Intensity Estimation Based on Multimodal Data.](http://arxiv.org/abs/2303.09167) | 本文提出了一种基于多模态数据的情感反应强度估计方法，提高了所提取的特征，改善了Pearson相关系数，并通过一些特殊技能处理数据以提高模型性能。 |
| [^33] | [Bayesian Generalization Error in Linear Neural Networks with Concept Bottleneck Structure and Multitask Formulation.](http://arxiv.org/abs/2303.09154) | 本文数学上澄清了带有概念瓶颈结构和多任务组成的线性神经网络的贝叶斯泛化误差和自由能。 |
| [^34] | [Fiber Tract Shape Measures Inform Prediction of Non-Imaging Phenotypes.](http://arxiv.org/abs/2303.09124) | 本文研究了利用纤维束形状特征预测非成像表型方面的潜力，并在人类连接组计划数据集上进行了实验，表明纤维束形状特征可以显著提高非成像表型的预测性能，为传统微结构和连接特征提供了补充信息。 |
| [^35] | [SigVIC: Spatial Importance Guided Variable-Rate Image Compression.](http://arxiv.org/abs/2303.09112) | SigVIC是一种空间重要性指导的可变比图像压缩方法，通过自适应学习空间重要性掩码指导特征缩放和比特分配，选择Top-K浅层特征来精细调整解码特征，实验结果表明其在速率失真性能和视觉质量方面均实现了最先进的性能。 |
| [^36] | [Maximum Margin Learning of t-SPNs for Cell Classification with Filtering.](http://arxiv.org/abs/2303.09065) | 本研究提出了一种基于t-SPN算法和滤波技术的细胞分类方法，通过最大化边缘和L2正则化，该方法在HEp-2和Feulgen基准数据集上取得了最高的准确率。 |
| [^37] | [Knowledge Transfer for Pseudo-code Generation from Low Resource Programming Language.](http://arxiv.org/abs/2303.09062) | 本文研究了将高资源编程语言中训练的编码器-解码器神经模型通过迭代回译的方法，将其知识转移到低资源编程语言中用于伪代码生成，从而解决了缺少低资源编程语言-伪代码平行数据的问题。 |
| [^38] | [SVDE: Scalable Value-Decomposition Exploration for Cooperative Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2303.09058) | 本文提出了一种面向协作多智能体强化学习的可伸缩价值分解探索方法，通过异步可伸缩训练机制、内在奖励设计和探索性经验回放解决了训练需要大量样本和缺乏主动探索的问题，实验结果显示该方法在多智能体强化学习任务中性能最佳。 |
| [^39] | [Generating synthetic multi-dimensional molecular-mediator time series data for artificial intelligence-based disease trajectory forecasting and drug development digital twins: Considerations.](http://arxiv.org/abs/2303.09056) | 研究发现，在生成多维分子介质时间序列数据方面存在巨大的困难，这种类型的数据对于预测疾病轨迹和药物研发具有重要意义，现有的统计和数据中心机器学习方法无法解决数据稀缺和维度灾难的问题。 |
| [^40] | [Improving Perceptual Quality, Intelligibility, and Acoustics on VoIP Platforms.](http://arxiv.org/abs/2303.09048) | 本文提出一种基于VoIP通信平台进行DNS模型微调的方法，提高其在语音增强方面的性能。这种多任务学习框架能够将噪声抑制和VoIP特有的声学特征相结合，优于行业性能和最先进的方法。 |
| [^41] | [Translating Radiology Reports into Plain Language using ChatGPT and GPT-4 with Prompt Learning: Promising Results, Limitations, and Potential.](http://arxiv.org/abs/2303.09038) | 本文研究探讨利用ChatGPT将放射学报告翻译成通俗易懂的语言，平均得分为5分制的4.1分，信息缺失率和信息错误率均较低，ChatGPT提供的建议大都与放射学报告相关。 |
| [^42] | [A Picture is Worth a Thousand Words: Language Models Plan from Pixels.](http://arxiv.org/abs/2303.09031) | 本文探讨从像素中使用预训练的语言模型进行规划，相对于之前的方法在ALFWorld和VirtualHome基准测试中取得更好的表现。 |
| [^43] | [Commonsense Knowledge Assisted Deep Learning for Resource-constrained and Fine-grained Object Detection.](http://arxiv.org/abs/2303.09026) | 本文提出了一种通识知识辅助的细粒度目标检测方法，利用通识知识推理模块处理由基准深度学习检测器给出的粗粒度标签，从而提高目标检测的准确性。经过实验验证，该方法相比于现有方法需要更少的计算量和标注资源。 |
| [^44] | [Machine Learning for Flow Cytometry Data Analysis.](http://arxiv.org/abs/2303.09007) | 本篇论文介绍了使用机器学习，特别是随机森林算法，来分析流式细胞计数数据的方法。通过此方法，可以提高识别感兴趣的细胞组群的精度和效率，并深入理解数据复杂关系。 |
| [^45] | [Reinforce Data, Multiply Impact: Improved Model Accuracy and Robustness with Dataset Reinforcement.](http://arxiv.org/abs/2303.08983) | 提出了一种名为数据集增强的策略，一次性改进数据集，从而提高任何经过增强的数据集训练的模型的准确性、鲁棒性和校准性。例如，使用ImageDataNet+训练的ResNet-50在ImageNet验证集上的准确率提高了1.7％，在ImageNetV2上提高了3.5％，在ImageNet-R上提高了10.0％。 |
| [^46] | [Relative coordinates are crucial for Ulam's "trick to the train of thought".](http://arxiv.org/abs/2303.08969) | 本文证明了，在视觉信号处理中，相对坐标对于概念形成至关重要，在动物识别特征时也很重要。 |
| [^47] | [Robust Pivoting Manipulation using Contact Implicit Bilevel Optimization.](http://arxiv.org/abs/2303.08965) | 本文使用接触隐式双层优化来规划支点操纵并增加鲁棒性，通过利用摩擦力来弥补物体和环境物理属性估计中的不准确性，以应对不确定性影响。 |
| [^48] | [Exploring the Relevance of Data Privacy-Enhancing Technologies for AI Governance Use Cases.](http://arxiv.org/abs/2303.08956) | 探究数据隐私增强技术对AI治理的重要性，将不同的AI治理目标视为系统信息流，强调解决方案之间的互操作性。 |
| [^49] | [Automated Interactive Domain-Specific Conversational Agents that Understand Human Dialogs.](http://arxiv.org/abs/2303.08941) | 本文介绍了利用大型语言模型和Answer Set Programming实现真正“理解”人类对话的AutoConcierge系统。该系统针对特定领域，为用户提供有关附近餐厅的建议。 |
| [^50] | [Designing Participatory AI: Creative Professionals' Worries and Expectations about Generative AI.](http://arxiv.org/abs/2303.08931) | 本文介绍了一项调查，调查了创意专业人士对生成AI的关注点和期望，并讨论了如何设计参与式AI来赋予创意专业人士在与AI的现在和未来的协作中的自主权。 |
| [^51] | [EvalAttAI: A Holistic Approach to Evaluating Attribution Maps in Robust and Non-Robust Models.](http://arxiv.org/abs/2303.08866) | 该论文提出了一个综合方法EvalAttAI，旨在同时考虑归因映射在各种条件下的稳健性和保真度，以更好地评估归因映射的性能并选择适合特定应用的方法。 |
| [^52] | [Wireless Sensor Networks anomaly detection using Machine Learning: A Survey.](http://arxiv.org/abs/2303.08823) | 本篇综述论文介绍了机器学习技术在无线传感器网络中进行数据异常检测的最新应用。讲述了这种技术能够解决传感数据中异常模式检测的问题，并比较了不同方法的优缺点。 |
| [^53] | [Ask and You Shall Receive (a Graph Drawing): Testing ChatGPT's Potential to Apply Graph Layout Algorithms.](http://arxiv.org/abs/2303.08819) | 本论文探讨了将大语言模型应用于图形绘制算法的潜力，通过在ChatGPT上进行实验，我们相信LLM的能力可以使有限编码背景的用户使用自然语言来创建有效的图形可视化，这将提高图形绘制任务的效率和效果。 |
| [^54] | [Understanding Post-hoc Explainers: The Case of Anchors.](http://arxiv.org/abs/2303.08806) | 本文对Anchors进行了理论分析，这是一种基于规则的可解释性方法，用于解释文本分类器的决策。 |
| [^55] | [GPT-4 Technical Report.](http://arxiv.org/abs/2303.08774) | GPT-4是一个大规模多模态模型，可以接收图像和文本输入并产生文本输出，能够在各种专业和学术基准测试中表现出人类水平的表现，包括通过模拟的律师考试。该项目的核心组件是开发基础设施和优化方法，可在广泛的规模范围内表现预测性。 |
| [^56] | [FactReranker: Fact-guided Reranker for Faithful Radiology Report Summarization.](http://arxiv.org/abs/2303.08335) | FactReranker是一种新颖的辅助评估器，可以在保持摘要与放射学发现实况一致性的基础上，通过事实引导来有效地选择最佳的摘要。 |
| [^57] | [A Comprehensive Study on Post-Training Quantization for Large Language Models.](http://arxiv.org/abs/2303.08302) | 本文基于数万个零-shot实验对基于后训练量化的大型语言模型的不同量化组件进行了综合研究，结果发现细粒度量化和后训练量化方法很重要，用粗粒度量化的更高位数比用非常细粒度的更低位数更强大。我们给出了如何为不同大小的\llms利用量化的建议。 |
| [^58] | [You Can Ground Earlier than See: An Effective and Efficient Pipeline for Temporal Sentence Grounding in Compressed Videos.](http://arxiv.org/abs/2303.07863) | 本文提出了一种新的压缩域TSG设置，通过直接编码压缩位流来增强视觉特征表示能力和提高时间句子对齐的效率，并且在两个基准数据集的实验中表现优于目前最先进的方法。 |
| [^59] | [TriDet: Temporal Action Detection with Relative Boundary Modeling.](http://arxiv.org/abs/2303.07347) | TriDet提出了一个新颖的三叉头模型和SGP特征金字塔来提高时间行为检测的边界预测和聚合多种时间尺度信息。在三个挑战性的基准测试上，TriDet取得了最先进的性能。 |
| [^60] | [Transformer-based Planning for Symbolic Regression.](http://arxiv.org/abs/2303.06833) | 该论文提出了一种基于Transformer和蒙特卡罗树搜索的符号回归规划策略TPSR，可以将非可微的反馈作为知识的外部来源融入到方程生成过程中，提高方程生成的准确性和复杂性。 |
| [^61] | [ODIN: On-demand Data Formulation to Mitigate Dataset Lock-in.](http://arxiv.org/abs/2303.06832) | ODIN采用生成AI模型，通过根据用户需求生成按需数据集，解决了传统零样本学习方法在数据集约束方面的限制，使得人工智能能够学习超出训练数据集的未见知识。 |
| [^62] | [Guiding Pseudo-labels with Uncertainty Estimation for Source-free Unsupervised Domain Adaptation.](http://arxiv.org/abs/2303.03770) | 本研究提出一种基于损失重新加权策略的无源自适应域自适应（SF-UDA）方法，用于适应目标域，其关键是通过估计伪标签的不确定性来指导其进一步精化，并利用自监督对比框架作为目标空间的正则化器以提高预测精度。 |
| [^63] | [BIFRNet: A Brain-Inspired Feature Restoration DNN for Partially Occluded Image Recognition.](http://arxiv.org/abs/2303.01309) | BIFRNet是一种脑启发的深度神经网络，使用特殊的背侧视觉通路来识别部分遮挡的图像，并且能够通过特征重建来填补被遮挡的信息。 |
| [^64] | [AR3n: A Reinforcement Learning-based Assist-As-Needed Controller for Robotic Rehabilitation.](http://arxiv.org/abs/2303.00085) | 本文提出了一种基于强化学习的机器人康复辅助控制器AR3n，通过使用虚拟患者模型实现控制器的泛化，实时调节机器人辅助力度并最小化机器人辅助的量，该控制器在实验验证中表现出良好的效果。 |
| [^65] | [Towards Enhanced Controllability of Diffusion Models.](http://arxiv.org/abs/2302.14368) | 本文介绍了一种基于条件输入的扩散模型，利用两个潜在编码控制生成过程中的空间结构和语义风格，提出了两种通用采样技术和时间步相关的潜在权重调度，实现了对生成过程的更好控制。 |
| [^66] | [Markov Conditions and Factorization in Logical Credal Networks.](http://arxiv.org/abs/2302.14146) | 本文研究逻辑信任网络并探究不同马尔科夫条件的影响。我们发现没有有向循环的网络可以进行因子分解，而带有有向循环的网络则需要特别考虑不同的马尔科夫条件。 |
| [^67] | [Fairguard: Harness Logic-based Fairness Rules in Smart Cities.](http://arxiv.org/abs/2302.11137) | 本文提出了一种基于时间逻辑的公正智慧城市政策调整和生成方法Fairguard，通过两个阶段的静态生成和动态调节，缓解由多种数据和算法偏见导致的不公正预测结果。 |
| [^68] | [See Your Heart: Psychological states Interpretation through Visual Creations.](http://arxiv.org/abs/2302.10276) | 本文提出了一项挑战性任务——视觉情感解读任务(VEIT)，旨在通过AI对创作者的心理状态进行合理的解释。为此，本文提供了一个多模态数据集，该数据集得到了心理学理论的支持和专业的注释。据分析表明，该数据集不仅能够支持VEIT，而且相对于其他字幕数据集更具挑战性。 |
| [^69] | [Knowledge Graph Completion based on Tensor Decomposition for Disease Gene Prediction.](http://arxiv.org/abs/2302.09335) | 本文通过交互式张量分解构建了一个以疾病和基因为中心的生物知识图谱，并开发了一种端到端的疾病基因预测知识图谱补全模型 KDGene。实验结果表明，KDGene明显优于最先进的算法，且对于糖尿病案例的生物学分析也证实了其可行性。 |
| [^70] | [Unsupervised Evaluation of Out-of-distribution Detection: A Data-centric Perspective.](http://arxiv.org/abs/2302.08287) | 本文提出了一种无监督评估外部分布检测方法的问题，并提出了一种基于Gscore的有效性指标，这对于没有真实标签的测试时可作为实用的评估方法。 |
| [^71] | [AI Chat Assistants can Improve Conversations about Divisive Topics.](http://arxiv.org/abs/2302.07268) | 该论文介绍了一个大型实验的结果，证明了使用人工智能工具可以改善关于分裂性话题的在线对话。他们通过使用一种大型语言模型实时提供基于证据的建议，帮助人们在对话中感受到理解的感觉。 |
| [^72] | [Improving Interpretability of Deep Sequential Knowledge Tracing Models with Question-centric Cognitive Representations.](http://arxiv.org/abs/2302.06885) | 本文介绍了一种名为 QIKT 的基于问题的可解释知识追踪模型，通过采用以问题为中心的认知表示方法，明确地模拟学生的知识状态变化，解决了现有模型中同质化问题的假设对实际情况不准确以及解释预测结果具有挑战性的问题。 |
| [^73] | [Zero-Shot Learning for Requirements Classification: An Exploratory Study.](http://arxiv.org/abs/2302.04723) | 本文提出一种使用零样本学习方法进行需求分类的方法，避免使用大量标记数据的限制。 |
| [^74] | [Meta-Learning Siamese Network for Few-Shot Text Classification.](http://arxiv.org/abs/2302.03507) | 本文提出了Meta-SN，一种基于元学习的连对网络，用于解决几乎没有标签的文本分类问题。Meta-SN通过使用外部知识来编码类别标签的低维嵌入向量，并提出新的采样策略，克服了信念网络算法中的一些问题，提高了少样本学习的准确性。 |
| [^75] | [What Decreases Editing Capability? Domain-Specific Hybrid Refinement for Improved GAN Inversion.](http://arxiv.org/abs/2301.12141) | 这篇论文提出了面向特定领域的混合细化方法，用于改善GAN反演结果中的编辑能力减弱问题。该方法通过将图像分为域内和域外部分，并对这两部分进行权重调节细化，以保持域内区域的编辑能力并提高保真度。 |
| [^76] | [FedPH: Privacy-enhanced Heterogeneous Federated Learning.](http://arxiv.org/abs/2301.11705) | 该论文提出了一种利用预训练模型作为本地模型的骨干，共享嵌入类向量来增强本地模型性能的异构联邦学习方法，并采用隐私保护的混合方法来保护隐私。 |
| [^77] | [Efficient Encoders for Streaming Sequence Tagging.](http://arxiv.org/abs/2301.09244) | 本研究提出了一种名为HEAR的混合编码器与自适应重启（HEAR），解决了在流式输入中使用双向编码器的不必要浮点操作和不必要标签翻转的问题，同时提高了流式输入上的标记性能。 |
| [^78] | [Classifying Mental-Disorders through Clinicians Subjective Approach based on Three-way Decision.](http://arxiv.org/abs/2301.03351) | 本文提出了一个基于三分决策框架下的统一模型，用于分析临床医生的主观方法，通过定量和定性分析得出排名列表和权重，并将疾病进行比较分类为三组，该方法可以作为补充工具与手动方法相结合，提高精确性。 |
| [^79] | [Human-Guided Fair Classification for Natural Language Processing.](http://arxiv.org/abs/2212.10154) | 本文提出了一种新方法，通过自动生成表达丰富的候选句子对并结合群众外包的成对人类判断，训练一个映射语义相似性到统计代理的个体公平性的模型，用于弥合人类直觉和公平分类规范之间的差距。该方法在表现能力、与人类直觉的一致性和两个基准数据集的分类准确性方面优于先前的方法。 |
| [^80] | [Multi-Resolution Online Deterministic Annealing: A Hierarchical and Progressive Learning Architecture.](http://arxiv.org/abs/2212.08189) | 本文提出了一种基于逐渐增加子集数量的分区序列的通用的分层学习结构，并使用无梯度随机逼近更新进行在线解决优化问题的方法，可以定义函数逼近问题并使用双时间尺度随机逼近算法的理论解决，模拟了一种退火过程。 |
| [^81] | [On the Robustness of Normalizing Flows for Inverse Problems in Imaging.](http://arxiv.org/abs/2212.04319) | 本文研究了在成像逆问题中使用条件归一化流时出现的严重伪像的问题，发现其原因是由于超出分布范围的条件输入导致条件仿射耦合层“爆炸反演”，并提出相应条件以避免这个问题。 |
| [^82] | [Deep Incubation: Training Large Models by Divide-and-Conquering.](http://arxiv.org/abs/2212.04129) | 本文提出了一种称为深度孵化的训练大型模型的新方法，通过将大型模型分成较小的子模块进行训练并无缝地组装起来，从而实现了大型模型的高效、有效训练。 |
| [^83] | [Learning to Bound Counterfactual Inference from Observational, Biased and Randomised Data.](http://arxiv.org/abs/2212.02932) | 本文提出了从多个可能有偏见的观测和干预研究的数据集中计算结构性因果模型中的反事实的方法，并通过图形转换解决了通用的多个数据集的问题。实验证明了该方法的效果和准确性，同时也提示整合异构数据以获得信息丰富的边界的好处。 |
| [^84] | [Beyond Object Recognition: A New Benchmark towards Object Concept Learning.](http://arxiv.org/abs/2212.02710) | 本文提出了一个挑战性的 Object Concept Learning (OCL) 任务，涉及对象属性、作用及其因果关系。作者构建了密集注释的知识库以支持 OCL，提出了 Object Concept Reasoning Network (OCRN) 作为基线，提升了对象认知的发展。 |
| [^85] | [One-shot Implicit Animatable Avatars with Model-based Priors.](http://arxiv.org/abs/2212.02469) | 本文提出了ELICIT，一种从单张图片学习人类特定神经辐射场的方法，同时利用3D几何先验和视觉语义先验实现了一次性数据高效的逼真可动3D人体的创建。 |
| [^86] | [Direct-Effect Risk Minimization for Domain Generalization.](http://arxiv.org/abs/2211.14594) | 本文提出了一种针对域泛化的直接影响风险最小化算法，通过引入因果推断中的直接和间接影响概念解决了相关性转移问题。该算法与现有域泛化算法具有可比性。 |
| [^87] | [Rickrolling the Artist: Injecting Backdoors into Text Encoders for Text-to-Image Synthesis.](http://arxiv.org/abs/2211.02408) | 本文证明了文本生成图像模型中使用的文本编码器存在重大的篡改风险，并提出了一种基于反向门攻击的方法，可以插入一个单一字符触发器进提示中，从而触发模型生成具有预定义属性的图像或遵循隐藏的、潜在的恶意描述的图像。 |
| [^88] | [Space-fluid Adaptive Sampling by Self-Organisation.](http://arxiv.org/abs/2210.17505) | 本文提出了一种自组织的空间流体自适应采样方法来估计分布式传感数据或计算结果，其动态划分空间的方法具有优越的性能。 |
| [^89] | [Learning Minimally-Violating Continuous Control for Infeasible Linear Temporal Logic Specifications.](http://arxiv.org/abs/2210.01162) | 本文提出了一个模型自由框架，使用深度强化学习来实现复杂高级任务的目标驱动导航。通过将先前的多目标DRL问题转化为一个单一目标问题，并使用基于采样的路径规划算法来指导DRL智能体，该方法可以满足不可行的线性时态逻辑任务并尽可能减少违规。 |
| [^90] | [Mine yOur owN Anatomy: Revisiting Medical Image Segmentation with Extremely Limited Labels.](http://arxiv.org/abs/2209.13476) | 提出了一种新的医学图像分割方法MOAN，该方法可以在极度有限的标签情况下实现高性能。MOAN由两个互补的流水线组成：协同邻域挖掘和自监督对比学习。实验结果表明，MOAN在Dice评分和其他评估指标方面优于现有最先进方法。 |
| [^91] | [LSAP: Rethinking Inversion Fidelity, Perception and Editability in GAN Latent Space.](http://arxiv.org/abs/2209.12746) | LSAP通过对潜空间实现对齐解决了反演和编辑结果中保真度、感知和可编辑性的问题，使得在保留重建保真度的前提下具有更好的感知和可编辑性。 |
| [^92] | [Comparing Feature Importance and Rule Extraction for Interpretability on Text Data.](http://arxiv.org/abs/2207.01420) | 本文比较了文本数据上两类方法：计算每个特征的重要性分数和提取简单逻辑规则，发现在相同模型下产生的解释也不同。我们提出了一种比较解释差异的方法。 |
| [^93] | [WaveMix: A Resource-efficient Neural Network for Image Analysis.](http://arxiv.org/abs/2205.14375) | WaveMix是一种资源高效的神经网络结构，可以在多项任务上达到可比或更好的准确率，并且需要更少的参数和GPU RAM，实现时间、成本和能量的节省。 |
| [^94] | [A Sea of Words: An In-Depth Analysis of Anchors for Text Data.](http://arxiv.org/abs/2205.13789) | Anchors 是一种后处理的规则性可解释性方法，它可以通过凸显出一个小组词语（锚点）来强调模型的决策，我们首次对 Anchors 进行了理论分析，考虑到寻找最佳锚点是详尽的，并通过 TF-IDF 向量化步骤以及模型层次的显式结果，探究其在不同类别模型中的行为特征。我们还发现，在神经网络中，最高偏导数所对应的词汇可以重新加权用作 Anchors 词汇。 |
| [^95] | [Constrained Monotonic Neural Networks.](http://arxiv.org/abs/2205.11775) | 本文针对实际应用场景需要的单调性，提出了一种通过在层中的一部分神经元中采用原始激活函数，同时在另一部分采用其点对称反射来解决构建单调深度神经网络的方法。实验证明，该方法的精度符合要求。 |
| [^96] | [Corrupted Image Modeling for Self-Supervised Visual Pre-Training.](http://arxiv.org/abs/2202.03382) | 本文提出了一种损坏图像建模的自监督视觉预训练方法，通过协同训练生成器和增强网络来学习丰富的视觉表示，适用于多种网络架构，并在多个数据集上获得了优异的性能表现。 |
| [^97] | [Measuring Non-Probabilistic Uncertainty: A cognitive, logical and computational assessment of known and unknown unknowns.](http://arxiv.org/abs/2201.05818) | 该论文提出了一种测量非概率不确定性的方法，该方法可以通过分析文本来检测不确定性对决策因果关系的影响。 |
| [^98] | [Open-Set Representation Learning through Combinatorial Embedding.](http://arxiv.org/abs/2106.15278) | 该论文提出了一种基于组合学习的方法来识别数据集中的新概念，扩展已知和新类别的识别性能。它使用多个监督元分类器给出的组成知识自然地对未见类别中的示例进行聚类，并通过无监督的成对关系学习让组合嵌入所提供的表示更加强健。 |
| [^99] | [SDGNN: Learning Node Representation for Signed Directed Networks.](http://arxiv.org/abs/2101.02390) | 该论文提出了一种新颖的有向有符号图神经网络模型SDGNN，用于学习有向有符号网络中的节点嵌入，该模型重构了链接符号、链接方向和有向有符号三角形，验证了其有效性。 |
| [^100] | [A robot's sense-making of fallacies and rhetorical tropes. Creating ontologies of what humans try to say.](http://arxiv.org/abs/1906.09689) | 本研究针对机器人交流设计中的不足，通过分析谬误和修辞范畴的心理原因、信号检测等因素，开发了一个针对谬误和修辞范畴的安全协议。该协议使用了指代和意义区分、分析表、信息最大程度原则和认识论考虑等技术，从而帮助机器人礼貌地理解用户有时晦涩难懂的要求。 |

# 详细

[^1]: SoftZoo：面向多样环境的软体机器人协同设计基准平台

    SoftZoo: A Soft Robot Co-design Benchmark For Locomotion In Diverse Environments. (arXiv:2303.09555v1 [cs.RO])

    [http://arxiv.org/abs/2303.09555](http://arxiv.org/abs/2303.09555)

    SoftZoo是一个面向多种环境的软体机器人协同设计平台，支持广泛、自然启发的材料组合和多种任务，并提供了形态和控制的可微分设计表示。通过一致的评估指标，SoftZoo允许直接比较不同方法，并揭示了软体机器人设计中的权衡。

    

    虽然在控制方面已经取得了显著的研究进展，但在同时协同优化形态时出现了独特的挑战。现有的工作通常是为特定环境或表示量量身定制的。为了更充分地理解固有的设计和性能权衡，并加速开发新型软体机器人，需要一个包含已建立好的任务、环境和评估指标的全面虚拟平台。在这项工作中，我们介绍了SoftZoo，这是一个面向多样环境的软体机器人协同设计平台。SoftZoo支持广泛、自然启发的材料组合，包括能够模拟平地、沙漠、湿地、黏土、冰、雪、浅水和海洋等多种环境。此外，它提供了多个与软体机器人相关的任务，包括快速移动、灵活转向和路径跟随，以及形态和控制的可微分设计表示。结合一致的评估指标，SoftZoo允许在方法之间进行直接比较，并揭示软体机器人设计中的权衡。

    While significant research progress has been made in robot learning for control, unique challenges arise when simultaneously co-optimizing morphology. Existing work has typically been tailored for particular environments or representations. In order to more fully understand inherent design and performance tradeoffs and accelerate the development of new breeds of soft robots, a comprehensive virtual platform with well-established tasks, environments, and evaluation metrics is needed. In this work, we introduce SoftZoo, a soft robot co-design platform for locomotion in diverse environments. SoftZoo supports an extensive, naturally-inspired material set, including the ability to simulate environments such as flat ground, desert, wetland, clay, ice, snow, shallow water, and ocean. Further, it provides a variety of tasks relevant for soft robotics, including fast locomotion, agile turning, and path following, as well as differentiable design representations for morphology and control. Combi
    
[^2]: 数据流图作为完整因果图

    Dataflow graphs as complete causal graphs. (arXiv:2303.09552v1 [cs.SE])

    [http://arxiv.org/abs/2303.09552](http://arxiv.org/abs/2303.09552)

    本篇论文介绍了一种替代的软件设计方法——基于流的编程（FBP），并强调了FBP生成的数据流图和结构性因果模型之间的联系，通过这种联系可以改进软件项目中的日常任务，包括故障定位、业务分析和实验室实验。

    

    组件化开发是现代软件工程实践的核心原则之一。理解软件系统组件之间的因果关系可以为开发人员带来显著的益处。然而，现代软件设计方法使得在系统规模下跟踪和发现这种关系变得困难，这导致了不断增长的智力负担。在本文中，我们考虑了一种替代的软件设计方法——基于流的编程（FBP），并引起了社区对FBP生成的数据流图和结构性因果模型之间关系的注意。我们通过说明性示例展示了如何利用这种关系来改进软件项目中的日常任务，包括故障定位、业务分析和实验室实验。

    Component-based development is one of the core principles behind modern software engineering practices. Understanding of causal relationships between components of a software system can yield significant benefits to developers. Yet modern software design approaches make it difficult to track and discover such relationships at system scale, which leads to growing intellectual debt. In this paper we consider an alternative approach to software design, flow-based programming (FBP), and draw the attention of the community to the connection between dataflow graphs produced by FBP and structural causal models. With expository examples we show how this connection can be leveraged to improve day-to-day tasks in software projects, including fault localisation, business analysis and experimentation.
    
[^3]: WebSHAP: 面向任意机器学习模型的解释工具

    WebSHAP: Towards Explaining Any Machine Learning Models Anywhere. (arXiv:2303.09545v1 [cs.LG])

    [http://arxiv.org/abs/2303.09545](http://arxiv.org/abs/2303.09545)

    WebSHAP是第一个将先进的模型无关解释技术SHAP适应Web环境的浏览器内工具，可用于解释基于ML的贷款批准决策。

    

    随着机器学习被越来越广泛地应用于我们日常的网络体验中，人们越来越需要透明和可解释的基于Web的机器学习。 然而，现有的解释技术往往需要专用的后端服务器，这限制了它们在向较低延迟和更高隐私性的基于浏览器的Web ML迁移时的实用性。为了解决客户端解释方案的迫切需求，我们提出了WebSHAP，这是第一个将先进的模型无关解释技术SHAP适应Web环境的浏览器内工具。我们的开源工具是使用现代Web技术（如WebGL）开发的，利用客户端硬件能力，易于集成到现有的Web ML应用程序中。我们演示了WebSHAP在解释基于ML的贷款批准决策的使用场景中的应用。 回顾我们的工作，我们讨论了透明Web ML的未来研究机会和挑战。WebSHAP现已提供。

    As machine learning (ML) is increasingly integrated into our everyday Web experience, there is a call for transparent and explainable web-based ML. However, existing explainability techniques often require dedicated backend servers, which limit their usefulness as the Web community moves toward in-browser ML for lower latency and greater privacy. To address the pressing need for a client-side explainability solution, we present WebSHAP, the first in-browser tool that adapts the state-of-the-art model-agnostic explainability technique SHAP to the Web environment. Our open-source tool is developed with modern Web technologies such as WebGL that leverage client-side hardware capabilities and make it easy to integrate into existing Web ML applications. We demonstrate WebSHAP in a usage scenario of explaining ML-based loan approval decisions to loan applicants. Reflecting on our work, we discuss the opportunities and challenges for future research on transparent Web ML. WebSHAP is available
    
[^4]: SemDeDup:通过语义去重实现网络规模数据的高效学习（arXiv:2303.09540v1 [cs.LG]）

    SemDeDup: Data-efficient learning at web-scale through semantic deduplication. (arXiv:2303.09540v1 [cs.LG])

    [http://arxiv.org/abs/2303.09540](http://arxiv.org/abs/2303.09540)

    SemDeDup是一种利用预训练模型的嵌入来识别和删除语义重复项的方法。通过对LAION的子集进行分析，SemDeDup可以最小化性能损失的同时删除50%的数据，实际上将训练时间减半。此外，SemDeDup在提供效率收益的同时改进了先前的方法。

    

    机器学习领域的进展很大程度上是由海量数据的增加推动的。然而，像LAION这样的大型网络规模数据集在除查找精确重复项外，大部分未经精心筛选，可能存在很多冗余。在这里，我们介绍SemDeDup，一种基于预训练模型的嵌入来识别和删除语义重复项的方法：即语义上相似但并非完全相同的数据对。去除语义重复项可以保持性能并加速学习。通过对LAION的子集进行分析，我们展示了SemDeDup可以最小化性能损失的同时删除50%的数据，实际上将训练时间减半。此外，性能在分布以外得到提高。同时，通过分析在部分筛选过的数据集C4上训练的语言模型，我们展示了SemDeDup在提供效率收益的同时改进了先前的方法。SemDeDup提供了一个利用质量嵌入简单方法来使模型更快地学习的示例。

    Progress in machine learning has been driven in large part by massive increases in data. However, large web-scale datasets such as LAION are largely uncurated beyond searches for exact duplicates, potentially leaving much redundancy. Here, we introduce SemDeDup, a method which leverages embeddings from pre-trained models to identify and remove semantic duplicates: data pairs which are semantically similar, but not exactly identical. Removing semantic duplicates preserves performance and speeds up learning. Analyzing a subset of LAION, we show that SemDeDup can remove 50% of the data with minimal performance loss, effectively halving training time. Moreover, performance increases out of distribution. Also, analyzing language models trained on C4, a partially curated dataset, we show that SemDeDup improves over prior approaches while providing efficiency gains. SemDeDup provides an example of how simple ways of leveraging quality embeddings can be used to make models learn faster with le
    
[^5]: Among Us: 基于共识的反对抗鲁棒协同感知

    Among Us: Adversarially Robust Collaborative Perception by Consensus. (arXiv:2303.09495v1 [cs.RO])

    [http://arxiv.org/abs/2303.09495](http://arxiv.org/abs/2303.09495)

    ROBOSAC提出了一种基于共识的反对抗鲁棒协同感知防御策略，使用随机子集的队友来对比协同感知和单个感知的结果，以排除潜在攻击者，并推导出确保获得所需无攻击者子集所需的采样试验个数。

    

    多个机器人之间的协同感知能够比单个机器人更好地感知场景(例如，检测物体)，但在使用深度学习时很容易受到敌对攻击。这一问题可通过对抗性防御来解决，但训练需要了解攻击机制，而这通常是未知的。因此，我们提出了 ROBOSAC，一种基于采样的新型防御策略，该策略具有泛化能力，能应对未知的攻击者。我们的核心思想是，协同感知应该比单个感知更能达成一致，而不应相互产生分歧。这导致我们提出了一种假说和验证的框架：利用一组随机选择的队友，对协同感知与单个感知的结果进行比较，直到达成共识。在这样的框架下，更多的队友通常意味着更好的感知表现，但需要更长的采样时间来排除潜在的攻击者。因此，我们推导出了需要多少个采样试验才能确保获得所需的无攻击者子集。

    Multiple robots could perceive a scene (e.g., detect objects) collaboratively better than individuals, although easily suffer from adversarial attacks when using deep learning. This could be addressed by the adversarial defense, but its training requires the often-unknown attacking mechanism. Differently, we propose ROBOSAC, a novel sampling-based defense strategy generalizable to unseen attackers. Our key idea is that collaborative perception should lead to consensus rather than dissensus in results compared to individual perception. This leads to our hypothesize-and-verify framework: perception results with and without collaboration from a random subset of teammates are compared until reaching a consensus. In such a framework, more teammates in the sampled subset often entail better perception performance but require longer sampling time to reject potential attackers. Thus, we derive how many sampling trials are needed to ensure the desired size of an attacker-free subset, or equival
    
[^6]: 用简单离散状态空间有效地建模时间序列

    Effectively Modeling Time Series with Simple Discrete State Spaces. (arXiv:2303.09489v1 [cs.LG])

    [http://arxiv.org/abs/2303.09489](http://arxiv.org/abs/2303.09489)

    介绍了一种名为SpaceTime的状态空间时间序列架构，提出了基于伴随矩阵的新的SSM参数化方法，能够学习自回归过程，有效预测远期。

    

    时间序列建模是一个已被广泛研究的问题，通常需要方法具备以下三个特性：表达复杂依赖关系，预测远期，以及有效训练长序列。状态空间模型（SSMs）是时间序列的经典模型，之前的工作将SSMs与深度学习层结合，以实现高效的序列建模。然而，我们发现这些先前方法存在根本上的限制，证明了它们的SSM表示不能表达自回归的时间序列过程。因此，我们介绍了SpaceTime，一种新的状态空间时间序列架构，改进了所有三个特性。为了提高表现力，我们提出了一种基于伴随矩阵的新的SSM参数化方法——离散时间过程的规范表示——它使得SpaceTime的SSM层能够学习称心的自回归过程。为了预测远期，我们介绍了一个“闭环”变体的伴随SSM，使得SpaceTime能够预测许多将来的时间点。

    Time series modeling is a well-established problem, which often requires that methods (1) expressively represent complicated dependencies, (2) forecast long horizons, and (3) efficiently train over long sequences. State-space models (SSMs) are classical models for time series, and prior works combine SSMs with deep learning layers for efficient sequence modeling. However, we find fundamental limitations with these prior approaches, proving their SSM representations cannot express autoregressive time series processes. We thus introduce SpaceTime, a new state-space time series architecture that improves all three criteria. For expressivity, we propose a new SSM parameterization based on the companion matrix -- a canonical representation for discrete-time processes -- which enables SpaceTime's SSM layers to learn desirable autoregressive processes. For long horizon forecasting, we introduce a "closed-loop" variation of the companion SSM, which enables SpaceTime to predict many future time
    
[^7]: 简单基于群体进化的任意阶元学习

    Arbitrary Order Meta-Learning with Simple Population-Based Evolution. (arXiv:2303.09478v1 [cs.LG])

    [http://arxiv.org/abs/2303.09478](http://arxiv.org/abs/2303.09478)

    本文提出了一种简单的基于群体进化的元学习方法，可以隐式地优化任意高阶的元参数，从而加速学习。

    

    元学习是学习如何学习的概念，能够使学习系统迅速、灵活地解决新任务。通常需要定义一组外循环元参数，然后用它们来更新一组内部循环参数。大多数元学习方法使用复杂的、计算开销很大的双层优化方案来更新这些元参数，但标准的元学习技术往往不适用于更高阶的元参数，因为元优化过程变得太复杂或不稳定。受到真实世界进化中高阶元学习的启发，我们显示出使用简单基于群体进化可以隐式地优化任意高阶的元参数。首先，我们从理论上证明并经验性地证明了基于群体进化隐式地优化了任意阶元参数。

    Meta-learning, the notion of learning to learn, enables learning systems to quickly and flexibly solve new tasks. This usually involves defining a set of outer-loop meta-parameters that are then used to update a set of inner-loop parameters. Most meta-learning approaches use complicated and computationally expensive bi-level optimisation schemes to update these meta-parameters. Ideally, systems should perform multiple orders of meta-learning, i.e. to learn to learn to learn and so on, to accelerate their own learning. Unfortunately, standard meta-learning techniques are often inappropriate for these higher-order meta-parameters because the meta-optimisation procedure becomes too complicated or unstable. Inspired by the higher-order meta-learning we observe in real-world evolution, we show that using simple population-based evolution implicitly optimises for arbitrarily-high order meta-parameters. First, we theoretically prove and empirically show that population-based evolution implici
    
[^8]: 结合类中心距离和异常值折扣的方法，提高在存在噪声标签的情况下训练机器学习模型的效果

    Combining Distance to Class Centroids and Outlier Discounting for Improved Learning with Noisy Labels. (arXiv:2303.09470v1 [cs.LG])

    [http://arxiv.org/abs/2303.09470](http://arxiv.org/abs/2303.09470)

    本文提出了结合类中心距离和异常值折扣的方法，用于解决在存在噪声标签的情况下训练机器学习模型的问题，并通过实验证明了其有效性 。

    

    本文提出了一种新的方法，用于解决在存在噪声标签的情况下训练机器学习模型的挑战。通过在物品的潜在空间中巧妙地使用距离类中心的方法，再结合折扣策略以减少距离所有类中心（即异常值）远的样本的重要性，我们的方法有效解决了噪声标签的问题。我们的方法是基于这样的想法：在训练的早期阶段，距离各自类中心更远的样本更可能是噪声。通过在几个流行的基准数据集上进行广泛实验，我们证明了我们的方法的有效性。结果表明，我们的方法在存在噪声标签的情况下，可以明显提高分类准确性，表现优于当前领域的最优方法。

    In this paper, we propose a new approach for addressing the challenge of training machine learning models in the presence of noisy labels. By combining a clever usage of distance to class centroids in the items' latent space with a discounting strategy to reduce the importance of samples far away from all the class centroids (i.e., outliers), our method effectively addresses the issue of noisy labels. Our approach is based on the idea that samples farther away from their respective class centroid in the early stages of training are more likely to be noisy. We demonstrate the effectiveness of our method through extensive experiments on several popular benchmark datasets. Our results show that our approach outperforms the state-of-the-art in this area, achieving significant improvements in classification accuracy when the dataset contains noisy labels.
    
[^9]: 基于证明数的蒙特卡罗树搜索

    Proof Number Based Monte-Carlo Tree Search. (arXiv:2303.09449v1 [cs.AI])

    [http://arxiv.org/abs/2303.09449](http://arxiv.org/abs/2303.09449)

    本文提出了一种将蒙特卡罗树搜索和证明数搜索相结合的PN-MCTS算法，该算法在多个游戏中均表现出优越的性能，可用于最终走步选择、解决子树以及UCT公式。

    

    本文提出了一种新的游戏搜索算法PN-MCTS，它将蒙特卡罗树搜索（MCTS）和证明数搜索（PNS）相结合。这两种算法已成功应用于各种领域的决策问题。我们定义了三个领域，即最终走步选择，解决子树以及UCT公式，这些领域可以利用在MCTS树中收集到的证明数和证伪数提供的附加知识。我们在不同的时间设置下对所有可能的组合进行了测试，并在几个游戏中与vanilla UCT MCTS进行对决：动作线（$7$$\times$$7$和$8$$\times$$8$），MiniShogi， Knightthrough， Awari和Gomoku。此外，我们对该算法进行扩展，以适当地处理出现平局的游戏，如Awari，通过在MCTS树的顶部添加一个附加的PNS层。实验结果表明，PN-MCTS在6个游戏领域中有5个的胜率优于MCTS（除了Gomoku），其中在动作线游戏中获得了高达96.2%的胜率。

    This paper proposes a new game search algorithm, PN-MCTS, that combines Monte-Carlo Tree Search (MCTS) and Proof-Number Search (PNS). These two algorithms have been successfully applied for decision making in a range of domains. We define three areas where the additional knowledge provided by the proof and disproof numbers gathered in MCTS trees might be used: final move selection, solving subtrees, and the UCT formula. We test all possible combinations on different time settings, playing against vanilla UCT MCTS on several games: Lines of Action ($7$$\times$$7$ and $8$$\times$$8$), MiniShogi, Knightthrough, Awari, and Gomoku. Furthermore, we extend this new algorithm to properly address games with draws, like Awari, by adding an additional layer of PNS on top of the MCTS tree. The experiments show that PN-MCTS confidently outperforms MCTS in 5 out of 6 game domains (all except Gomoku), achieving win rates up to 96.2% for Lines of Action.
    
[^10]: 使用Prompt-Tuning的原型转向针对无需重复训练的连续学习

    Steering Prototype with Prompt-tuning for Rehearsal-free Continual Learning. (arXiv:2303.09447v1 [cs.LG])

    [http://arxiv.org/abs/2303.09447](http://arxiv.org/abs/2303.09447)

    本研究提出了一个新的连续学习模型——对比原型提示，使用任务特异性提示调整来提高原型性能，同时避免了语义漂移和原型干扰问题。基于此模型的CPP方法在四个具有挑战性的类增量学习基准测试中表现出色，相对于其他最先进的方法有4%至6%的绝对提升。该方法不需要重复训练，性能接近离线联合学习，展示了一种有前途的设计方案。

    

    原型作为类别嵌入的一种表示，已被探索用于减少连续学习情境下的内存占用或减轻遗忘。然而，基于原型的方法仍然存在语义漂移和原型干扰导致的性能急剧恶化的问题。在本研究中，我们提出了对比原型提示（CPP）方法，并展示了任务特定提示调整，当在对比学习目标上进行优化时，可以有效地解决这两个障碍并显着提高原型的性能。我们的实验表明，CPP在四个具有挑战性的类增量学习基准测试中表现出色，相对于现有最先进方法有4%至6%的绝对提升。此外，CPP不需要重复训练，它极大地缩小了连续学习和离线联合学习之间的性能差距，展示了一种有前途的Transformer体系结构下连续学习系统的设计方案。

    Prototype, as a representation of class embeddings, has been explored to reduce memory footprint or mitigate forgetting for continual learning scenarios. However, prototype-based methods still suffer from abrupt performance deterioration due to semantic drift and prototype interference. In this study, we propose Contrastive Prototypical Prompt (CPP) and show that task-specific prompt-tuning, when optimized over a contrastive learning objective, can effectively address both obstacles and significantly improve the potency of prototypes. Our experiments demonstrate that CPP excels in four challenging class-incremental learning benchmarks, resulting in 4% to 6% absolute improvements over state-of-the-art methods. Moreover, CPP does not require a rehearsal buffer and it largely bridges the performance gap between continual learning and offline joint-learning, showcasing a promising design scheme for continual learning systems under a Transformer architecture.
    
[^11]: 用稀疏输入控制高维数据

    Controlling High-Dimensional Data With Sparse Input. (arXiv:2303.09446v1 [eess.AS])

    [http://arxiv.org/abs/2303.09446](http://arxiv.org/abs/2303.09446)

    本论文提出了一种新的控制机制，即将稀疏、易于人理解的控制空间映射到生成模型的潜在空间。通过实验，此方法表现出了效率、鲁棒性和保真性，即使只有少量的输入数值。

    

    本论文解决了人在环路控制生成高度结构化数据的问题。由于现有的生成模型缺乏有效的接口，使得用户可以修改输出，这个任务变得具有挑战性。用户或手动探索不可解释的潜在空间，或者费力地注释数据标签。为了解决这个问题，我们引入了一个新的框架，其中编码器将稀疏、易于人理解的控制空间映射到生成模型的潜在空间。我们将这个框架应用于控制文本转语音合成中的韵律的任务。我们提出了一个模型，称为多实例条件变分自编码器(MICVAE)，它专门设计用于编码稀疏的韵律特征并输出完整的波形。我们通过实验证明，MICVAE表现出了稀疏的人在环路控制机制所需的良好品质：效率、鲁棒性和保真性。即使只有非常少量的输入数值(~4)，MICVAE也能让用户实现控制。

    We address the problem of human-in-the-loop control for generating highly-structured data. This task is challenging because existing generative models lack an efficient interface through which users can modify the output. Users have the option to either manually explore a non-interpretable latent space, or to laboriously annotate the data with conditioning labels. To solve this, we introduce a novel framework whereby an encoder maps a sparse, human interpretable control space onto the latent space of a generative model. We apply this framework to the task of controlling prosody in text-to-speech synthesis. We propose a model, called Multiple-Instance CVAE (MICVAE), that is specifically designed to encode sparse prosodic features and output complete waveforms. We show empirically that MICVAE displays desirable qualities of a sparse human-in-the-loop control mechanism: efficiency, robustness, and faithfulness. With even a very small number of input values (~4), MICVAE enables users to im
    
[^12]: 利用Twitter情感分析预测加密货币价格

    Cryptocurrency Price Prediction using Twitter Sentiment Analysis. (arXiv:2303.09397v1 [q-fin.ST])

    [http://arxiv.org/abs/2303.09397](http://arxiv.org/abs/2303.09397)

    本研究使用历史价格和Twitter情感分析预测比特币价格，并取得了不错的效果。情感预测的平均绝对百分比误差为9.45％，价格预测的平均绝对百分比误差为3.6％。

    

    随着加密货币的波动性及多样化的意见，在许多社交媒体平台上都成为了讨论的中心话题。Twitter 迅速成为新闻来源和比特币讨论的媒介。我们的算法旨在利用历史价格和推文情感来预测比特币的价格。在本研究中，我们开发了一种端到端模型，可使用双向编码器转换的神经网络模型预测推文集的情感，并使用预测的情感以及历史加密货币价格数据、推文数量、用户的追随者数量以及用户是否通过验证来预测比特币的价格。情感预测的平均绝对百分比误差为9.45％，反应了实时数据和测试数据的平均误差。而价格预测的平均绝对百分比误差则为3.6％。

    The cryptocurrency ecosystem has been the centre of discussion on many social media platforms, following its noted volatility and varied opinions. Twitter is rapidly being utilised as a news source and a medium for bitcoin discussion. Our algorithm seeks to use historical prices and sentiment of tweets to forecast the price of Bitcoin. In this study, we develop an end-to-end model that can forecast the sentiment of a set of tweets (using a Bidirectional Encoder Representations from Transformers - based Neural Network Model) and forecast the price of Bitcoin (using Gated Recurrent Unit) using the predicted sentiment and other metrics like historical cryptocurrency price data, tweet volume, a user's following, and whether or not a user is verified. The sentiment prediction gave a Mean Absolute Percentage Error of 9.45%, an average of real-time data, and test data. The mean absolute percent error for the price prediction was 3.6%.
    
[^13]: 使用计算注意力预测人类视觉注意力

    Predicting Human Attention using Computational Attention. (arXiv:2303.09383v1 [cs.CV])

    [http://arxiv.org/abs/2303.09383](http://arxiv.org/abs/2303.09383)

    HAT是一种计算注意力模型，使用新颖的基于变换器的结构和简化的凹视网膜，实现了对于目标存在和目标缺失搜索期间注视行为的扫描路径的最新技术水平。

    

    大多数视觉注意力模型旨在预测自上而下或自下而上控制，采用不同的视觉搜索和自由观看任务进行研究。我们提出了一个称为人类注意力变换器的单一模型，可以预测这两种形式的注意力控制。HAT在预测目标存在和目标缺失搜索期间进行注视行为的扫描路径方面是新的最先进技术，在预测无任务自由观看注视路径方面匹配或超过了当前技术水平。HAT通过使用新颖的基于变换器的结构和简化的凹视网膜，共同创建类似于人类动态视觉工作记忆的时空意识，实现了这种新的技术水平。与以前依赖于粗糙的注视单元格网格并由于离散化固定而经历信息丢失的方法不同，HAT具有密集预测架构，并为每个注视输出密集热图，从而避免离散注视。HAT在计算视觉注意力方面设定了一个新的标准。

    Most models of visual attention are aimed at predicting either top-down or bottom-up control, as studied using different visual search and free-viewing tasks. We propose Human Attention Transformer (HAT), a single model predicting both forms of attention control. HAT is the new state-of-the-art (SOTA) in predicting the scanpath of fixations made during target-present and target-absent search, and matches or exceeds SOTA in the prediction of taskless free-viewing fixation scanpaths. HAT achieves this new SOTA by using a novel transformer-based architecture and a simplified foveated retina that collectively create a spatio-temporal awareness akin to the dynamic visual working memory of humans. Unlike previous methods that rely on a coarse grid of fixation cells and experience information loss due to fixation discretization, HAT features a dense-prediction architecture and outputs a dense heatmap for each fixation, thus avoiding discretizing fixations. HAT sets a new standard in computati
    
[^14]: 保护社会免受AI滥用：何时限制AI能力是必要的？

    Protecting Society from AI Misuse: When are Restrictions on Capabilities Warranted?. (arXiv:2303.09377v1 [cs.AI])

    [http://arxiv.org/abs/2303.09377](http://arxiv.org/abs/2303.09377)

    随着人工智能系统能力不断提升，控制某些能力将有助于防止其滥用，这些限制可能包括控制访问、使用目的、输出与溯源以及开发资源，非AI能力限制也是必要的。尽管可能会降低使用率而增加滥用风险，但这些限制是当其他干预行不通、潜在危害性高、有有针对性方式干预时所必要的。

    

    随着人工智能（AI）系统不断提高能力，其被用于造成伤害的情况将会越来越多。事实上，AI系统已经开始用于自动化的欺诈活动、侵犯人权、创建有害的虚假图像以及识别危险毒素。为了防止AI的某些滥用，我们认为有必要对某些能力进行有针对性的干预。这些限制可能包括控制谁能访问某些类型的AI模型、它们可以用于什么、是否过滤输出或者可以追溯到使用者以及开发它们所需的资源。我们还认为，一些对滥用所需的非AI能力限制也是必要的。虽然能力限制可能会降低使用率而不是滥用率（存在不利的滥用-使用权衡），但我们认为当其他干预行不通、潜在滥用的危害性很高，并且有有针对性的方式来干预能力时，干预能力是必要的。

    Artificial intelligence (AI) systems will increasingly be used to cause harm as they grow more capable. In fact, AI systems are already starting to be used to automate fraudulent activities, violate human rights, create harmful fake images, and identify dangerous toxins. To prevent some misuses of AI, we argue that targeted interventions on certain capabilities will be warranted. These restrictions may include controlling who can access certain types of AI models, what they can be used for, whether outputs are filtered or can be traced back to their user, and the resources needed to develop them. We also contend that some restrictions on non-AI capabilities needed to cause harm will be required. Though capability restrictions risk reducing use more than misuse (facing an unfavorable Misuse-Use Tradeoff), we argue that interventions on capabilities are warranted when other interventions are insufficient, the potential harm from misuse is high, and there are targeted ways to intervene on
    
[^15]: 3D蒙版自编码和伪标签用于异构婴儿脑 MRI 领域间适应性标记

    3D Masked Autoencoding and Pseudo-labeling for Domain Adaptive Segmentation of Heterogeneous Infant Brain MRI. (arXiv:2303.09373v1 [cs.CV])

    [http://arxiv.org/abs/2303.09373](http://arxiv.org/abs/2303.09373)

    本文提出了一种名为 MAPSeg 的新框架，采用 3D 蒙版自编码和伪标签的方式，实现了跨年龄、跨模态和跨场景下对婴儿脑 MRI 中亚皮质区域的分割，充分考虑不同 MRI 扫描仪、供应商或采集序列以及不同的神经发育阶段所造成的内在异质性，提高了分割结果的鲁棒性。

    

    婴儿脑 MRI 在跨年龄、跨模态、跨场景下实现鲁棒的分割仍然是具有挑战性的。本文介绍了一种名为 MAPSeg 的新框架，它使用 3D 蒙版自编码和蒙版伪标签的方式来对婴儿脑MRI的不同亚皮质区域进行分割，并联合学习标记源域数据和未标记目标域数据，以提高分割结果的鲁棒性。

    Robust segmentation of infant brain MRI across multiple ages, modalities, and sites remains challenging due to the intrinsic heterogeneity caused by different MRI scanners, vendors, or acquisition sequences, as well as varying stages of neurodevelopment. To address this challenge, previous studies have explored domain adaptation (DA) algorithms from various perspectives, including feature alignment, entropy minimization, contrast synthesis (style transfer), and pseudo-labeling. This paper introduces a novel framework called MAPSeg (Masked Autoencoding and Pseudo-labelling Segmentation) to address the challenges of cross-age, cross-modality, and cross-site segmentation of subcortical regions in infant brain MRI. Utilizing 3D masked autoencoding as well as masked pseudo-labeling, the model is able to jointly learn from labeled source domain data and unlabeled target domain data. We evaluated our framework on expert-annotated datasets acquired from different ages and sites. MAPSeg consist
    
[^16]: 国家癌症研究所影像数据共享平台：计算病理学可重复研究的基础

    The NCI Imaging Data Commons as a platform for reproducible research in computational pathology. (arXiv:2303.09354v1 [cs.CV])

    [http://arxiv.org/abs/2303.09354](http://arxiv.org/abs/2303.09354)

    国家癌症研究所影像数据共享平台 (IDC) 旨在促进计算病理学领域的研究可重复性，实现了 FAIR 原则，提供公共库和云端技术支持，方便使用机器学习方法进行癌症组织分类研究。

    

    目的：可重复性对于将计算病理学（CompPath）中基于机器学习（ML）的解决方案转化为实践至关重要。然而，越来越多的研究报告难以重复 ML 结果的困难。国家癌症研究所影像数据共享平台（IDC）是一个公共库，包含 >120 个癌症图像收集，包括 >38,000 张全切片图像（WSIs），旨在与云端 ML 服务一起使用。本文探讨了 IDC 促进 CompPath 研究可重复性的潜力。 材料和方法：IDC 实现了 FAIR 原则：所有图像都根据 DICOM 标准进行编码，具有持久化标识符、可通过丰富的元数据进行发现，并可通过开放式工具访问。借此优势，我们在 IDC 的不同数据集上实现了两个实验，针对肺癌组织分类的一种代表性基于 ML 的方法进行了训练和/或评估。为评估可重复性，实验被多次运行。

    Objective: Reproducibility is critical for translating machine learning-based (ML) solutions in computational pathology (CompPath) into practice. However, an increasing number of studies report difficulties in reproducing ML results. The NCI Imaging Data Commons (IDC) is a public repository of >120 cancer image collections, including >38,000 whole-slide images (WSIs), that is designed to be used with cloud-based ML services. Here, we explore the potential of the IDC to facilitate reproducibility of CompPath research.  Materials and Methods: The IDC realizes the FAIR principles: All images are encoded according to the DICOM standard, persistently identified, discoverable via rich metadata, and accessible via open tools. Taking advantage of this, we implemented two experiments in which a representative ML-based method for classifying lung tumor tissue was trained and/or evaluated on different datasets from the IDC. To assess reproducibility, the experiments were run multiple times with i
    
[^17]: 基于神经网络的伴随方法实时弹性部分形状匹配

    Real-time elastic partial shape matching using a neural network-based adjoint method. (arXiv:2303.09343v1 [cs.AI])

    [http://arxiv.org/abs/2303.09343](http://arxiv.org/abs/2303.09343)

    本文提出了一种基于神经网络的伴随方法来实现实时弹性的部分形状匹配，该方法采用前馈神经网络来求解超弹性问题，通过网络的反向传播获得伴随问题，结合最优控制问题来求解未知量应用于物体的表面力分布。该流程大大提高了计算速度，同时提供了可接受的注册误差。

    

    表面匹配通常会提供显著的变形，可能会由于缺乏物理策略导致结构故障。在这种情况下，非线性可变形体的部分表面匹配对于控制结构变形至关重要。本文提出将注册问题作为一个最优控制问题来表达，其中未知量是应用于物体的表面力分布，通过超弹模型计算得到的变形。采用人工神经网络求解优化问题，其中超弹性问题使用前馈神经网络求解，伴随问题通过网络的反向传播获得。我们的流程提高了计算速度，同时提供了可接受的注册误差。

    Surface matching usually provides significant deformations that can lead to structural failure due to the lack of physical policy. In this context, partial surface matching of non-linear deformable bodies is crucial in engineering to govern structure deformations. In this article, we propose to formulate the registration problem as an optimal control problem using an artificial neural network where the unknown is the surface force distribution that applies to the object and the resulting deformation computed using a hyper-elastic model. The optimization problem is solved using an adjoint method where the hyper-elastic problem is solved using the feed-forward neural network and the adjoint problem is obtained through the backpropagation of the network. Our process improves the computation speed by multiple orders of magnitude while providing acceptable registration errors.
    
[^18]: GPT是否能通过高等教育编程课程的评估？

    Can Generative Pre-trained Transformers (GPT) Pass Assessments in Higher Education Programming Courses?. (arXiv:2303.09325v1 [cs.AI])

    [http://arxiv.org/abs/2303.09325](http://arxiv.org/abs/2303.09325)

    该研究评估了生成式预训练变压器（GPT）在高等教育Python编程课程的初级和中级评估中的能力，并发现其在解决复杂的编程问题上遇到困难，限制了其在编程教育中的应用。

    

    我们评估了生成式预训练变压器（GPT）在高等教育Python编程课程的初级和中级评估中的能力。人们对这种新兴技术在编程教育方面的潜在用途（例如，练习生成，代码解释）和不良用途（例如，作弊）的讨论已经加 intens 了，但到目前为止，该模型在具有多种评估工具的广泛编程课程的现实环境中的能力还没有得到严格分析。我们在使用评估从简单的多项选择题（不涉及代码）到代码分布在多个文件中的复杂编程项目的三个Python课程上评估了GPT（总共599个练习题）。此外，我们研究了GPT模型如何成功地利用自动评分器提供的反馈。我们发现，当前的模型不能通过在高等教育Python编程课程中通常涉及的完整评估工具的全谱。虽然GPT模型可以成功地生成简单练习的语法正确代码，但对于更复杂的练习，他们遇到了困难，并且无法生成满足多文件编程项目要求的代码。此外，GPT模型显示了有限的利用自动评分器提供的反馈的能力。我们的研究结果表明GPT模型可能在编程教育中应用受到限制，并强调需要在这个领域进行更多的研究和开发。

    We evaluated the capability of generative pre-trained transformers (GPT), to pass assessments in introductory and intermediate Python programming courses at the postsecondary level. Discussions of potential uses (e.g., exercise generation, code explanation) and misuses (e.g., cheating) of this emerging technology in programming education have intensified, but to date there has not been a rigorous analysis of the models' capabilities in the realistic context of a full-fledged programming course with diverse set of assessment instruments. We evaluated GPT on three Python courses that employ assessments ranging from simple multiple-choice questions (no code involved) to complex programming projects with code bases distributed into multiple files (599 exercises overall). Further, we studied if and how successfully GPT models leverage feedback provided by an auto-grader. We found that the current models are not capable of passing the full spectrum of assessments typically involved in a Pyth
    
[^19]: TOT：面向多模态仇恨检测的拓扑感知最优传输

    TOT: Topology-Aware Optimal Transport For Multimodal Hate Detection. (arXiv:2303.09314v1 [cs.CL])

    [http://arxiv.org/abs/2303.09314](http://arxiv.org/abs/2303.09314)

    本文针对隐式危害检测的挑战，提出一种面向表情包情境的拓扑感知最优传输框架TOT，利用最优传输核方法从多个模态中捕捉互补信息。

    

    多模态仇恨检测旨在识别在线有害内容（如表情包等），是构建健康的互联网环境至关重要。以往的研究重点关注显式仇恨言论的检测，而忽略了隐式危害的分析，这在存在着扭曲或缺乏明显文本标记和人口统计视觉线索的情况下面临着特别大的挑战。本文提出了TOT：一种面向表情包情境的拓扑感知最优传输框架，将跨模态对齐问题转化为最优传输方案的求解。具体来说，我们利用最优传输核方法从多个模态中捕捉互补信息。核嵌入提供了一种非线性转换能力，以重现输入的分布。

    Multimodal hate detection, which aims to identify harmful content online such as memes, is crucial for building a wholesome internet environment. Previous work has made enlightening exploration in detecting explicit hate remarks. However, most of their approaches neglect the analysis of implicit harm, which is particularly challenging as explicit text markers and demographic visual cues are often twisted or missing. The leveraged cross-modal attention mechanisms also suffer from the distributional modality gap and lack logical interpretability. To address these semantic gaps issues, we propose TOT: a topology-aware optimal transport framework to decipher the implicit harm in memes scenario, which formulates the cross-modal aligning problem as solutions for optimal transportation plans. Specifically, we leverage an optimal transport kernel method to capture complementary information from multiple modalities. The kernel embedding provides a non-linear transformation ability to reproduce 
    
[^20]: 利用一个非常简单的属性高效推断NFA

    Taking advantage of a very simple property to efficiently infer NFAs. (arXiv:2303.09311v1 [cs.AI])

    [http://arxiv.org/abs/2303.09311](http://arxiv.org/abs/2303.09311)

    本文提出了一个利用简单属性高效推断NFA的方法，并且在实验证明了该方法比现有技术具有竞争力。

    

    文法推断是学习形式语法作为有限状态机或一组重写规则的过程。本文关注推断必须接受一些词汇并拒绝给定样本中的其他词汇的NFA。这个问题可以在SAT中自然建模。该标准模型非常巨大，因此基于前缀、后缀和混合的模型被设计用于生成更小的SAT实例。有一个非常简单和明显的属性声称：如果给定样本有大小为k的NFA，那么也有大小为k+1的NFA。我们首先通过给k+1的NFA添加一些特征来加强这个属性。因此，我们可以使用此属性来限制给定样本的最小NFA的大小范围。然后，我们提出了大小为k+1的NFA的简化和精简模型，这些模型比大小为k的初始模型要小。我们还提出了一种约简算法，用于从特定样本中构建大小为k的NFA。我们的实验表明，此方法与最先进的技术相比具有竞争力。

    Grammatical inference consists in learning a formal grammar as a finite state machine or as a set of rewrite rules. In this paper, we are concerned with inferring Nondeterministic Finite Automata (NFA) that must accept some words, and reject some other words from a given sample. This problem can naturally be modeled in SAT. The standard model being enormous, some models based on prefixes, suffixes, and hybrids were designed to generate smaller SAT instances. There is a very simple and obvious property that says: if there is an NFA of size k for a given sample, there is also an NFA of size k+1. We first strengthen this property by adding some characteristics to the NFA of size k+1. Hence, we can use this property to tighten the bounds of the size of the minimal NFA for a given sample. We then propose simplified and refined models for NFA of size k+1 that are smaller than the initial models for NFA of size k. We also propose a reduction algorithm to build an NFA of size k from a specific
    
[^21]: 构建鲁棒的孟加拉复杂命名实体识别模型

    Towards Robust Bangla Complex Named Entity Recognition. (arXiv:2303.09306v1 [cs.CL])

    [http://arxiv.org/abs/2303.09306](http://arxiv.org/abs/2303.09306)

    本研究构建了基于 CRF 和深度学习（如 BanglaBERT）的鲁棒孟加拉复杂命名实体识别模型，解决了 CNER 任务，填补了孟加拉语复杂命名实体识别领域的空白。

    

    命名实体识别 (NER) 是自然语言处理中的基础任务，包括在文本中识别和分类命名实体。尽管孟加拉语是全球第七大使用语言，但针对孟加拉语复杂命名实体识别的工作还很少。CNER 是一项更具挑战性的任务，因为它涉及识别和分类复杂和复合实体，而这在孟加拉语中不常见。在本文中，我们提出了解决 BanglaCoNER 数据集上的 CNER 任务的获胜解决方案，使用了两种不同的方法，即条件随机场 (CRF) 和基于 finetuning transformer 的深度学习模型（如 BanglaBERT）。数据集包括 15300 个用于训练的句子和 800 个用于验证的句子，格式为 .conll。对数据集的探索性数据分析 (EDA) 揭示出数据集有 7 种不同的 NER 标签，其中有英语单词的明显存在。

    Named Entity Recognition (NER) is a fundamental task in natural language processing that involves identifying and classifying named entities in text. But much work hasn't been done for complex named entity recognition in Bangla, despite being the seventh most spoken language globally. CNER is a more challenging task than traditional NER as it involves identifying and classifying complex and compound entities, which are not common in Bangla language. In this paper, we present the winning solution of Bangla Complex Named Entity Recognition Challenge - addressing the CNER task on BanglaCoNER dataset using two different approaches, namely Conditional Random Fields (CRF) and finetuning transformer based Deep Learning models such as BanglaBERT.  The dataset consisted of 15300 sentences for training and 800 sentences for validation, in the .conll format. Exploratory Data Analysis (EDA) on the dataset revealed that the dataset had 7 different NER tags, with notable presence of English words, s
    
[^22]: 解释群体实例的反事实推理，用于可解释人工智能：群体反事实推理的使用案例、算法和用户研究。

    Explaining Groups of Instances Counterfactually for XAI: A Use Case, Algorithm and User Study for Group-Counterfactuals. (arXiv:2303.09297v1 [cs.AI])

    [http://arxiv.org/abs/2303.09297](http://arxiv.org/abs/2303.09297)

    该论文探索了一种新的用例，使用“群体反事实”集体解释类似实例的组，提出了一种新颖的群体反事实算法来生成高覆盖率的解释，适合人类对连贯、广泛解释的喜好。

    

    反事实解释是一种越来越受欢迎的事后解释形式，因为它们适用于各种问题领域、提供了法律合规性（例如符合《通用数据保护条例》），并且依赖于人类解释的对比性质。虽然反事实解释通常用于解释单个预测实例，但我们探索了一个新的用例，即使用“群体反事实”来集体解释类似实例的组（例如突出显示一组患者中疾病重复出现的模式）。这些群体反事实满足人们对包含多个事件/实例的连贯、广泛解释的偏好。我们提出了一种新颖的群体反事实算法来生成高覆盖率的解释，这种解释又忠实于待解释模型。还使用客观（即准确性）和主观（即信心、解释满意度）评估了该解释策略在大型控制用户研究（N=207）中的表现。

    Counterfactual explanations are an increasingly popular form of post hoc explanation due to their (i) applicability across problem domains, (ii) proposed legal compliance (e.g., with GDPR), and (iii) reliance on the contrastive nature of human explanation. Although counterfactual explanations are normally used to explain individual predictive-instances, we explore a novel use case in which groups of similar instances are explained in a collective fashion using ``group counterfactuals'' (e.g., to highlight a repeating pattern of illness in a group of patients). These group counterfactuals meet a human preference for coherent, broad explanations covering multiple events/instances. A novel, group-counterfactual algorithm is proposed to generate high-coverage explanations that are faithful to the to-be-explained model. This explanation strategy is also evaluated in a large, controlled user study (N=207), using objective (i.e., accuracy) and subjective (i.e., confidence, explanation satisfa
    
[^23]: 使用设计多样性探索深度学习对自然图像污染的韧性

    Exploring Resiliency to Natural Image Corruptions in Deep Learning using Design Diversity. (arXiv:2303.09283v1 [cs.LG])

    [http://arxiv.org/abs/2303.09283](http://arxiv.org/abs/2303.09283)

    本文研究了深度学习图像分类器集合的多样性指标、准确性和对自然图像污染的韧性之间的关系，并发现实现设计选择的多样性可以降低故障模式的数量。

    

    本文研究了深度学习图像分类器集合的多样性指标、准确性和对自然图像污染的韧性之间的关系。我们调查了基于归因的多样性度量的潜力，以改善传统基于预测的多样性已知的准确性-多样性折衷所存在的问题。我们的动机基于设计多样性的分析研究，其显示如果实现设计选择的多样性，则可以降低常见故障模式的数量。我们通过将ResNet50用作比较基线，评估了多个单独的DL模型结构针对自然图像污染引起的数据集分布偏移的韧性。我们比较了通过神经结构搜索技术独立训练或训练的具有多样性模型结构的集合，并评估了基于预测和基于归因的多样性与最终集合准确性的相关性。我们评估了一组多样性度量，进一步说明了设计多样性的重要性。

    In this paper, we investigate the relationship between diversity metrics, accuracy, and resiliency to natural image corruptions of Deep Learning (DL) image classifier ensembles. We investigate the potential of an attribution-based diversity metric to improve the known accuracy-diversity trade-off of the typical prediction-based diversity. Our motivation is based on analytical studies of design diversity that have shown that a reduction of common failure modes is possible if diversity of design choices is achieved.  Using ResNet50 as a comparison baseline, we evaluate the resiliency of multiple individual DL model architectures against dataset distribution shifts corresponding to natural image corruptions. We compare ensembles created with diverse model architectures trained either independently or through a Neural Architecture Search technique and evaluate the correlation of prediction-based and attribution-based diversity to the final ensemble accuracy. We evaluate a set of diversity 
    
[^24]: 物理知识神经网络拓扑优化：应用于隐藏几何结构的非侵入式探测。

    Topology optimization with physics-informed neural networks: application to noninvasive detection of hidden geometries. (arXiv:2303.09280v1 [cs.LG])

    [http://arxiv.org/abs/2303.09280](http://arxiv.org/abs/2303.09280)

    该论文介绍了一种基于物理知识神经网络的拓扑优化方法，应用于无先验知识的几何结构检测，通过材料密度场表示任意解决方案拓扑，并通过Eikonal正则化实现。该方法可用于医疗和工业应用中的非侵入式成像技术。

    

    在医疗和工业应用中，通过电磁、声学或机械负载从表面测量中检测隐藏的几何结构是非侵入成像技术的目标。由于未知的拓扑和几何形状、数据的稀疏性以及物理规律的复杂性，解决逆问题是具有挑战性的。物理知识神经网络已经表现出许多优点，是一个简单而强大的问题反演工具，但它们尚未应用于具有先验未知拓扑的一般问题。在这里，我们介绍了一个基于PINNs的拓扑优化框架，它可以解决没有形状数量或类型先验知识的几何检测问题。我们允许任意的解决方案拓扑，通过使用材料密度场来表示几何形状，并通过新的Eikonal正则化接近二进制值。我们通过检测隐含虚空和包含物的数量、位置和形状来验证我们的框架。

    Detecting hidden geometrical structures from surface measurements under electromagnetic, acoustic, or mechanical loading is the goal of noninvasive imaging techniques in medical and industrial applications. Solving the inverse problem can be challenging due to the unknown topology and geometry, the sparsity of the data, and the complexity of the physical laws. Physics-informed neural networks (PINNs) have shown promise as a simple-yet-powerful tool for problem inversion, but they have yet to be applied to general problems with a priori unknown topology. Here, we introduce a topology optimization framework based on PINNs that solves geometry detection problems without prior knowledge of the number or types of shapes. We allow for arbitrary solution topology by representing the geometry using a material density field that approaches binary values thanks to a novel eikonal regularization. We validate our framework by detecting the number, locations, and shapes of hidden voids and inclusio
    
[^25]: 寻找树集成模型预测的最小代价解释

    Finding Minimum-Cost Explanations for Predictions made by Tree Ensembles. (arXiv:2303.09271v1 [cs.LG])

    [http://arxiv.org/abs/2303.09271](http://arxiv.org/abs/2303.09271)

    本研究提出了一种高效的oracle系统，能够寻找树集成模型预测的最小代价解释，该算法比目前最先进的替代方案的运行表现更好。m-MARCO算法可以计算每个预测的单个最小解释，并证明相对于枚举所有最小解释的MARCO算法，我们的方法具有两倍的总体加速比。

    

    当机器学习模型作为关键系统的决策支持时，能够解释为何模型做出特定预测的能力至关重要。提供的解释必须是可证明的，并且最好不包含冗余信息，即最小解释。本文旨在寻找树集成模型预测的解释，这些解释不仅是最小的，而且在成本函数方面也是最小的。为此，我们首先提出了一个高效的“神谕”系统，可以确定解释的正确性，在计算最小解释时超越了当前最先进的替代方案的运行表现数个数量级。其次，我们改编了来自相关工作的叫做MARCO的算法（将其称为m-MARCO），目的是计算每个预测的单个最小解释，并证明相对于枚举所有最小解释的MARCO算法，我们的方法具有两倍的总体加速比。

    The ability to explain why a machine learning model arrives at a particular prediction is crucial when used as decision support by human operators of critical systems. The provided explanations must be provably correct, and preferably without redundant information, called minimal explanations. In this paper, we aim at finding explanations for predictions made by tree ensembles that are not only minimal, but also minimum with respect to a cost function.  To this end, we first present a highly efficient oracle that can determine the correctness of explanations, surpassing the runtime performance of current state-of-the-art alternatives by several orders of magnitude when computing minimal explanations.  Secondly, we adapt an algorithm called MARCO from related works (calling it m-MARCO) for the purpose of computing a single minimum explanation per prediction, and demonstrate an overall speedup factor of two compared to the MARCO algorithm which enumerates all minimal explanations.  Final
    
[^26]: SmartBERT：用于加速BERT推理的动态早期退出机制的改进

    SmartBERT: A Promotion of Dynamic Early Exiting Mechanism for Accelerating BERT Inference. (arXiv:2303.09266v1 [cs.CL])

    [http://arxiv.org/abs/2303.09266](http://arxiv.org/abs/2303.09266)

    SmartBERT是一种改进的动态早期退出与层跳过机制，可以自适应地跳过一些层并自适应地选择是否退出，以加速BERT模型的推理速度。

    

    动态早期退出被证明可以提高预训练语言模型（如BERT）的推理速度。然而，所有样本在早期退出之前都必须经过所有连续层，较复杂的样本通常会经历更多的层，仍然存在冗余计算。本文提出了一种名为SmartBERT的Bert推理的新型动态早期退出与层跳过相结合的机制，它将跳过门和退出算子加入到BERT的每一层中。SmartBERT可以自适应地跳过一些层并自适应地选择是否退出。此外，我们提出了跨层对比学习，并将其结合到我们的训练阶段中，以提高中间层和分类器，这对于早期退出是有益的。为了保持训练和推理阶段跳过门的一致使用，我们在训练阶段提出了一种硬权重机制。我们在GLUE基准测试的八个分类数据集上进行了实验。

    Dynamic early exiting has been proven to improve the inference speed of the pre-trained language model like BERT. However, all samples must go through all consecutive layers before early exiting and more complex samples usually go through more layers, which still exists redundant computation. In this paper, we propose a novel dynamic early exiting combined with layer skipping for BERT inference named SmartBERT, which adds a skipping gate and an exiting operator into each layer of BERT. SmartBERT can adaptively skip some layers and adaptively choose whether to exit. Besides, we propose cross-layer contrastive learning and combine it into our training phases to boost the intermediate layers and classifiers which would be beneficial for early exiting. To keep the consistent usage of skipping gates between training and inference phases, we propose a hard weight mechanism during training phase. We conduct experiments on eight classification datasets of the GLUE benchmark. Experimental resul
    
[^27]: 人机协作：AI委派对人类任务表现和任务满意度的影响

    Human-AI Collaboration: The Effect of AI Delegation on Human Task Performance and Task Satisfaction. (arXiv:2303.09224v1 [cs.HC])

    [http://arxiv.org/abs/2303.09224](http://arxiv.org/abs/2303.09224)

    人工智能（AI）模型可以学习决定是否为任务的实例预测或将其委派给人类，研究显示AI委派可以提高任务表现和任务满意度，无论人类是否意识到委派。人类高水平的自我效能感是这些改善的基础机制。

    

    近期研究提出了一种人工智能（AI）模型，可以学习决定是否通过考虑双方的能力来为任务的实例预测或将其委派给人类。在使用合成生成或上下文无关的人预测进行的模拟中，相对于人或AI模型单独完成任务，委派可以帮助改善人机团队的表现。然而，到目前为止，人们在意识到AI模型委派任务实例给他们时如何执行和感知任务仍不清楚。在一项有196名参与者的实验研究中，我们展示了AI委派可以提高任务表现和任务满意度，无论人类是否意识到委派。此外，我们确定了人类高水平的自我效能感是这些表现和满意度改善的基础机制。我们的发现提供了初步的证据，表明允许AI模型接管任务实例可以在人机协作中提高表现和满意度。

    Recent work has proposed artificial intelligence (AI) models that can learn to decide whether to make a prediction for an instance of a task or to delegate it to a human by considering both parties' capabilities. In simulations with synthetically generated or context-independent human predictions, delegation can help improve the performance of human-AI teams -- compared to humans or the AI model completing the task alone. However, so far, it remains unclear how humans perform and how they perceive the task when they are aware that an AI model delegated task instances to them. In an experimental study with 196 participants, we show that task performance and task satisfaction improve through AI delegation, regardless of whether humans are aware of the delegation. Additionally, we identify humans' increased levels of self-efficacy as the underlying mechanism for these improvements in performance and satisfaction. Our findings provide initial evidence that allowing AI models to take over m
    
[^28]: 一种用于情感反应强度估计的双分支网络

    A Dual Branch Network for Emotional Reaction Intensity Estimation. (arXiv:2303.09210v1 [cs.AI])

    [http://arxiv.org/abs/2303.09210](http://arxiv.org/abs/2303.09210)

    本文提出了一种基于双分支的多输出回归模型，利用空间注意力和Mel-Frequency Cepstral Coefficients技术来提取视觉和声学特征，并添加了一种模态丢失方法来融合多模态特征，能够有效地解决情感反应强度估计的挑战。

    

    情感反应强度(ERI)的估计是多模态场景中的一项重要任务，在医学、安全驾驶和其他领域有根本性的应用。本文提出了一个解决第五届野外情感行为分析(ABAW)中ERI挑战的解决方案，它是一种基于双分支的多输出回归模型。空间注意力被用于更好地提取视觉特征，Mel频率倒谱系数技术提取声学特征，并添加了一种名为模态丢失的方法来融合多模态特征。我们的方法在官方验证集上取得了出色的结果。

    Emotional Reaction Intensity(ERI) estimation is an important task in multimodal scenarios, and has fundamental applications in medicine, safe driving and other fields. In this paper, we propose a solution to the ERI challenge of the fifth Affective Behavior Analysis in-the-wild(ABAW), a dual-branch based multi-output regression model. The spatial attention is used to better extract visual features, and the Mel-Frequency Cepstral Coefficients technology extracts acoustic features, and a method named modality dropout is added to fusion multimodal features. Our method achieves excellent results on the official validation set.
    
[^29]: 基于学习算法从时间数据中学习行动以推荐最佳策略

    Recommending the optimal policy by learning to act from temporal data. (arXiv:2303.09209v1 [cs.AI])

    [http://arxiv.org/abs/2303.09209](http://arxiv.org/abs/2303.09209)

    本文提出了一种基于强化学习算法的方法，可以从过去的执行记录中学习KPI的最佳策略，以推荐优化KPI的最佳操作。

    

    整个过程挖掘中最突出的问题是规范性流程监控，它包括确定一组操作以优化感兴趣的目标测量或关键绩效指标（KPI）为目标的推荐过程。这一问题的挑战在于必须仅基于存储在所谓的执行日志中的有时标注（流程）执行数据提供规范性流程监控技术，因缺乏精心制作和人工验证的明确模型。本文旨在提出一种基于人工智能的方法，通过强化学习（RL）的方式从过去的执行记录中学习最佳策略并推荐优化感兴趣的KPI的最佳操作。首先通过从数据中学习针对特定KPI的马尔可夫决策过程，并使用RL训练来学习最佳策略，从而实现该目标。该方法在真实数据集和模拟数据集上得到验证，并与其他方法进行了比较。

    Prescriptive Process Monitoring is a prominent problem in Process Mining, which consists in identifying a set of actions to be recommended with the goal of optimising a target measure of interest or Key Performance Indicator (KPI). One challenge that makes this problem difficult is the need to provide Prescriptive Process Monitoring techniques only based on temporally annotated (process) execution data, stored in, so-called execution logs, due to the lack of well crafted and human validated explicit models. In this paper we aim at proposing an AI based approach that learns, by means of Reinforcement Learning (RL), an optimal policy (almost) only from the observation of past executions and recommends the best activities to carry on for optimizing a KPI of interest. This is achieved first by learning a Markov Decision Process for the specific KPIs from data, and then by using RL training to learn the optimal policy. The approach is validated on real and synthetic datasets and compared wi
    
[^30]: 抽象论证中的时间性和因果关系。

    Temporality and Causality in Abstract Argumentation. (arXiv:2303.09197v1 [cs.AI])

    [http://arxiv.org/abs/2303.09197](http://arxiv.org/abs/2303.09197)

    该论文研究了抽象论证中的时间性和因果关系，提出了一种形式化的方法，将无环抽象论证框架的概念重新编写成一个行动语言，并建立起论据陈述和它们直接或间接后果之间的因果关系。

    

    在抽象论证的背景下，我们提出了考虑时间性和因果关系的好处，即论据被陈述的顺序以及它们之间的因果关系。我们提出了一种形式化的方法，将无环抽象论证框架的概念重新编写成一个行动语言，使我们能够模拟世界的演化，并建立论据陈述和它们的直接或间接后果之间的因果关系。我们还提出了一个Answer Set编程实现，并探讨了解释的发展方向。

    In the context of abstract argumentation, we present the benefits of considering temporality, i.e. the order in which arguments are enunciated, as well as causality. We propose a formal method to rewrite the concepts of acyclic abstract argumentation frameworks into an action language, that allows us to model the evolution of the world, and to establish causal relationships between the enunciation of arguments and their consequences, whether direct or indirect. An Answer Set Programming implementation is also proposed, as well as perspectives towards explanations.
    
[^31]: POMCP中学习逻辑规范以实现软政策指导

    Learning Logic Specifications for Soft Policy Guidance in POMCP. (arXiv:2303.09172v1 [cs.AI])

    [http://arxiv.org/abs/2303.09172](http://arxiv.org/abs/2303.09172)

    论文提出了一种从POMCP执行中学习逻辑规范的方法，以实现软政策指导，代替手动定义的策略相关规则，并用于解决环境状态空间大的问题。

    

    部分可观察的蒙特卡洛规划（POMCP）是一种有效的部分可观察马尔可夫决策过程（POMDP）的解决器。它通过使用基于蒙特卡洛树搜索的策略，在本地和在线计算最优策略的近似，从而使得规模上的扩展成为可能。然而，POMCP在稀疏奖励函数方面存在问题，即仅在达到最终目标时获得奖励，尤其是在具有大状态空间和长时间跨度的环境中。最近，已经将逻辑规范集成到POMCP中，以指导探索并满足安全性要求。然而，在真实世界的情况下，这些与策略相关的规则需要由领域专家手动定义。在本文中，我们使用归纳逻辑编程从POMCP执行的跟踪中学习逻辑规范，即由规划器生成的信念-行为对集合。具体来说，我们学习了用答案集编程范式表示的规则。然后我们将它们集成到POMCP中利用它以实现软指导政策。

    Partially Observable Monte Carlo Planning (POMCP) is an efficient solver for Partially Observable Markov Decision Processes (POMDPs). It allows scaling to large state spaces by computing an approximation of the optimal policy locally and online, using a Monte Carlo Tree Search based strategy. However, POMCP suffers from sparse reward function, namely, rewards achieved only when the final goal is reached, particularly in environments with large state spaces and long horizons. Recently, logic specifications have been integrated into POMCP to guide exploration and to satisfy safety requirements. However, such policy-related rules require manual definition by domain experts, especially in real-world scenarios. In this paper, we use inductive logic programming to learn logic specifications from traces of POMCP executions, i.e., sets of belief-action pairs generated by the planner. Specifically, we learn rules expressed in the paradigm of answer set programming. We then integrate them inside
    
[^32]: 基于多模态数据的情感反应强度估计

    Emotional Reaction Intensity Estimation Based on Multimodal Data. (arXiv:2303.09167v1 [cs.CV])

    [http://arxiv.org/abs/2303.09167](http://arxiv.org/abs/2303.09167)

    本文提出了一种基于多模态数据的情感反应强度估计方法，提高了所提取的特征，改善了Pearson相关系数，并通过一些特殊技能处理数据以提高模型性能。

    

    本论文介绍我们在CVPR 2023 ABAW中情感行为分析工作坊及竞赛中提出的情感反应强度（ERI）估计方法。通过使用预训练模型提取音频和视觉特征，我们利用Transformer编码器和跨模态注意力机制混合多模态特征。在本论文中，我们对所提取的特征进行了改进，同时通过对数据的特殊处理提高了模型的性能。

    This paper introduces our method for the Emotional Reaction Intensity (ERI) Estimation Challenge, in CVPR 2023: 5th Workshop and Competition on Affective Behavior Analysis in-the-wild (ABAW). Based on the multimodal data provided by the originazers, we extract acoustic and visual features with different pretrained models. The multimodal features are mixed together by Transformer Encoders with cross-modal attention mechnism. In this paper, 1. better features are extracted with the SOTA pretrained models. 2. Compared with the baseline, we improve the Pearson's Correlations Coefficient a lot. 3. We process the data with some special skills to enhance performance ability of our model.
    
[^33]: 带有概念瓶颈结构和多任务组成的线性神经网络的贝叶斯泛化误差。

    Bayesian Generalization Error in Linear Neural Networks with Concept Bottleneck Structure and Multitask Formulation. (arXiv:2303.09154v1 [stat.ML])

    [http://arxiv.org/abs/2303.09154](http://arxiv.org/abs/2303.09154)

    本文数学上澄清了带有概念瓶颈结构和多任务组成的线性神经网络的贝叶斯泛化误差和自由能。

    

    概念瓶颈模型（CBM）是一种广泛使用的方法，可以使用概念解释神经网络。在CBM中，概念被插入到输出层和最后一个中间层之间作为可观察值。这有助于理解神经网络生成输出的原因：最后一个隐藏层到输出层的概念对应的权重。然而，在CBM中理解泛化误差行为尚不可能，因为神经网络通常是奇异的统计模型。当模型是奇异的时，从参数到概率分布的一一映射不能创建。这种不可识别性使得分析泛化性能变得困难。在本次研究中，我们数学上澄清了CBM的贝叶斯泛化误差和自由能，当其架构是三层的线性神经网络时。我们还考虑了一个多任务问题，在该问题中，神经网络的输出不再只是一个标签，而是一组任务。

    Concept bottleneck model (CBM) is a ubiquitous method that can interpret neural networks using concepts. In CBM, concepts are inserted between the output layer and the last intermediate layer as observable values. This helps in understanding the reason behind the outputs generated by the neural networks: the weights corresponding to the concepts from the last hidden layer to the output layer. However, it has not yet been possible to understand the behavior of the generalization error in CBM since a neural network is a singular statistical model in general. When the model is singular, a one to one map from the parameters to probability distributions cannot be created. This non-identifiability makes it difficult to analyze the generalization performance. In this study, we mathematically clarify the Bayesian generalization error and free energy of CBM when its architecture is three-layered linear neural networks. We also consider a multitask problem where the neural network outputs not on
    
[^34]: 纤维束形状测量信息可用于预测非成像表型

    Fiber Tract Shape Measures Inform Prediction of Non-Imaging Phenotypes. (arXiv:2303.09124v1 [cs.CV])

    [http://arxiv.org/abs/2303.09124](http://arxiv.org/abs/2303.09124)

    本文研究了利用纤维束形状特征预测非成像表型方面的潜力，并在人类连接组计划数据集上进行了实验，表明纤维束形状特征可以显著提高非成像表型的预测性能，为传统微结构和连接特征提供了补充信息。

    

    大脑白质连接的神经影像学测量可以预测诸如人口统计学和认知测量等非成像表型的变化。本文研究了纤维束形状特征在预测非成像表型方面的潜力，包括长度、直径和伸长比等三个基本形状特征。本研究使用了传统回归方法和基于深度学习的预测方法，利用微结构、连接和形状测量的高效两阶段融合策略进行预测。实验结果表明，纤维束形状特征可以显著提高非成像表型的预测性能，并为传统微结构和连接特征提供了补充信息。

    Neuroimaging measures of the brain's white matter connections can enable the prediction of non-imaging phenotypes, such as demographic and cognitive measures. Existing works have investigated traditional microstructure and connectivity measures from diffusion MRI tractography, without considering the shape of the connections reconstructed by tractography. In this paper, we investigate the potential of fiber tract shape features for predicting non-imaging phenotypes, both individually and in combination with traditional features. We focus on three basic shape features: length, diameter, and elongation. Two different prediction methods are used, including a traditional regression method and a deep-learning-based prediction method. Experiments use an efficient two-stage fusion strategy for prediction using microstructure, connectivity, and shape measures. To reduce predictive bias due to brain size, normalized shape features are also investigated. Experimental results on the Human Connect
    
[^35]: SigVIC: 空间重要性指导的可变比图像压缩

    SigVIC: Spatial Importance Guided Variable-Rate Image Compression. (arXiv:2303.09112v1 [eess.IV])

    [http://arxiv.org/abs/2303.09112](http://arxiv.org/abs/2303.09112)

    SigVIC是一种空间重要性指导的可变比图像压缩方法，通过自适应学习空间重要性掩码指导特征缩放和比特分配，选择Top-K浅层特征来精细调整解码特征，实验结果表明其在速率失真性能和视觉质量方面均实现了最先进的性能。

    

    可变比机制提高了基于学习的图像压缩的灵活性和效率，该方法为不同的速率-失真权衡训练多个模型。变比率的最常见方法之一是按通道或空间均匀缩放内部特征。但是，空间重要性的多样性对于图像压缩的比特分配是有指导意义的。在本文中，我们介绍了一种空间重要性指导的可变比图像压缩方法（SigVIC），其中设计了一个空间门控单元（SGU），用于自适应学习空间重要性掩码。然后，一个空间缩放网络（SSN）使用空间重要性掩码来指导特征缩放和可变比率的比特分配。此外，为了提高解码图像的质量，选择Top-K浅层特征通过浅层特征融合模块（SFFM）来精细地调整解码特征。实验证明，我们的方法在多个基准数据集上优于其他基于学习的方法（无论是变比率还是非变比率），在速率失真性能和视觉质量方面均实现了最先进的性能。

    Variable-rate mechanism has improved the flexibility and efficiency of learning-based image compression that trains multiple models for different rate-distortion tradeoffs. One of the most common approaches for variable-rate is to channel-wisely or spatial-uniformly scale the internal features. However, the diversity of spatial importance is instructive for bit allocation of image compression. In this paper, we introduce a Spatial Importance Guided Variable-rate Image Compression (SigVIC), in which a spatial gating unit (SGU) is designed for adaptively learning a spatial importance mask. Then, a spatial scaling network (SSN) takes the spatial importance mask to guide the feature scaling and bit allocation for variable-rate. Moreover, to improve the quality of decoded image, Top-K shallow features are selected to refine the decoded features through a shallow feature fusion module (SFFM). Experiments show that our method outperforms other learning-based methods (whether variable-rate or 
    
[^36]: 基于t-SPN和滤波的细胞分类的最大间隔学习

    Maximum Margin Learning of t-SPNs for Cell Classification with Filtering. (arXiv:2303.09065v1 [cs.LG])

    [http://arxiv.org/abs/2303.09065](http://arxiv.org/abs/2303.09065)

    本研究提出了一种基于t-SPN算法和滤波技术的细胞分类方法，通过最大化边缘和L2正则化，该方法在HEp-2和Feulgen基准数据集上取得了最高的准确率。

    

    本文探讨了一种基于深度概率体系结构的算法，称为树形求和产品网络(t-SPN)，用于细胞分类。构建t-SPN的目的是表示未归一化概率作为最相似的细胞类别的条件概率。通过最大化边缘来学习构建的t-SPN体系结构，该边缘是真实标签和最有竞争力的错误标签之间的条件概率差。为了增强体系结构的泛化能力，在学习过程中考虑了L2正则化（REG）和最大间隔（MM）标准。为了突出细胞特征，本文探讨了两种通用的高通滤波器的有效性：理想高通滤波和拉普拉斯滤波(Log)。在HEp-2和Feulgen基准数据集上，基于最大间隔准则与正则化学习的t-SPN体系结构产生了最高的准确率。

    An algorithm based on a deep probabilistic architecture referred to as a tree-structured sum-product network (t-SPN) is considered for cell classification. The t-SPN is constructed such that the unnormalized probability is represented as conditional probabilities of a subset of most similar cell classes. The constructed t-SPN architecture is learned by maximizing the margin, which is the difference in the conditional probability between the true and the most competitive false label. To enhance the generalization ability of the architecture, L2-regularization (REG) is considered along with the maximum margin (MM) criterion in the learning process. To highlight cell features, this paper investigates the effectiveness of two generic high-pass filters: ideal high-pass filtering and the Laplacian of Gaussian (LOG) filtering. On both HEp-2 and Feulgen benchmark datasets, the t-SPN architecture learned based on the max-margin criterion with regularization produced the highest accuracy rate co
    
[^37]: 来自低资源编程语言的伪代码生成的知识转移

    Knowledge Transfer for Pseudo-code Generation from Low Resource Programming Language. (arXiv:2303.09062v1 [cs.SE])

    [http://arxiv.org/abs/2303.09062](http://arxiv.org/abs/2303.09062)

    本文研究了将高资源编程语言中训练的编码器-解码器神经模型通过迭代回译的方法，将其知识转移到低资源编程语言中用于伪代码生成，从而解决了缺少低资源编程语言-伪代码平行数据的问题。

    

    生成遗留源代码的伪代码描述以实现软件维护是一项繁琐的任务。最近的编码器-解码器语言模型已经显示出在自动化高资源编程语言（如C++）的伪代码生成方面有潜力，但是它们严重依赖于大量的代码-伪代码语料库的可用性。针对在遗留编程语言（PL）中编写代码的伪代码注释是一项耗时且昂贵的工作，需要深入了解源PL。本文专注于通过使用平行代码-伪代码数据训练的编码器-解码器神经模型获取的知识来实现将这些知识转移到没有PL-伪代码平行数据用于训练的遗留PL（C）上。为了实现此目标，我们利用一种基于测试用例的过滤策略的迭代回译（IBT）方法，以将经过训练的C++-to-pseudocode模型调整为C-to-pseudocode模型。

    Generation of pseudo-code descriptions of legacy source code for software maintenance is a manually intensive task. Recent encoder-decoder language models have shown promise for automating pseudo-code generation for high resource programming languages such as C++, but are heavily reliant on the availability of a large code-pseudocode corpus. Soliciting such pseudocode annotations for codes written in legacy programming languages (PL) is a time consuming and costly affair requiring a thorough understanding of the source PL. In this paper, we focus on transferring the knowledge acquired by the code-to-pseudocode neural model trained on a high resource PL (C++) using parallel code-pseudocode data. We aim to transfer this knowledge to a legacy PL (C) with no PL-pseudocode parallel data for training. To achieve this, we utilize an Iterative Back Translation (IBT) approach with a novel test-cases based filtration strategy, to adapt the trained C++-to-pseudocode model to C-to-pseudocode model
    
[^38]: SVDE: 面向协作多智能体强化学习的可伸缩价值分解探索

    SVDE: Scalable Value-Decomposition Exploration for Cooperative Multi-Agent Reinforcement Learning. (arXiv:2303.09058v1 [cs.AI])

    [http://arxiv.org/abs/2303.09058](http://arxiv.org/abs/2303.09058)

    本文提出了一种面向协作多智能体强化学习的可伸缩价值分解探索方法，通过异步可伸缩训练机制、内在奖励设计和探索性经验回放解决了训练需要大量样本和缺乏主动探索的问题，实验结果显示该方法在多智能体强化学习任务中性能最佳。

    

    在协作多智能体强化学习中，价值分解方法通过将联合状态-动作空间分解为本地观察-动作空间来降低系统难度，已经变得越来越受欢迎。然而，价值分解方法仍然存在训练时需要大量样本和缺乏主动探索的问题。本文提出了一种可伸缩的价值分解探索（SVDE）方法，其中包括可伸缩训练机制、内在奖励设计和探索性经验回放。可伸缩训练机制异步地将策略学习与环境交互解耦，以MapReduce的方式加速样本生成。针对缺乏探索的问题，提出了内在奖励设计和探索性经验回放，以增强探索以产生多样化的样本和过滤非新颖样本。实验结果表明，我们的方法在多智能体强化学习任务中取得了最佳性能。

    Value-decomposition methods, which reduce the difficulty of a multi-agent system by decomposing the joint state-action space into local observation-action spaces, have become popular in cooperative multi-agent reinforcement learning (MARL). However, value-decomposition methods still have the problems of tremendous sample consumption for training and lack of active exploration. In this paper, we propose a scalable value-decomposition exploration (SVDE) method, which includes a scalable training mechanism, intrinsic reward design, and explorative experience replay. The scalable training mechanism asynchronously decouples strategy learning with environmental interaction, so as to accelerate sample generation in a MapReduce manner. For the problem of lack of exploration, an intrinsic reward design and explorative experience replay are proposed, so as to enhance exploration to produce diverse samples and filter non-novel samples, respectively. Empirically, our method achieves the best perfo
    
[^39]: 生成多维分子介质时间序列数据用于基于人工智能的疾病轨迹预测和药物开发数字孪生：考虑因素

    Generating synthetic multi-dimensional molecular-mediator time series data for artificial intelligence-based disease trajectory forecasting and drug development digital twins: Considerations. (arXiv:2303.09056v1 [cs.AI])

    [http://arxiv.org/abs/2303.09056](http://arxiv.org/abs/2303.09056)

    研究发现，在生成多维分子介质时间序列数据方面存在巨大的困难，这种类型的数据对于预测疾病轨迹和药物研发具有重要意义，现有的统计和数据中心机器学习方法无法解决数据稀缺和维度灾难的问题。

    

    合成数据的使用被认为是神经网络人工智能系统开发中的一个关键步骤。虽然生成用于其他领域人工智能应用程序的合成数据的方法在特定的生物医学人工智能系统中具有作用，主要涉及图像处理。但在需要了解系统工作的人工智能任务的时间序列数据的生成中存在明显的差距。最为突出的是在生成多维分子时间序列数据方面存在困难，这是预测各种疾病的生物标记和介质特征研究的基础数据，并且是药物研发流程的核心组成部分。我们认为，由于维度灾难导致数据稀疏不足以及统计和数据中心机器学习（ML）的不适用性，这种类型的合成数据生成存在不足。

    The use of synthetic data is recognized as a crucial step in the development of neural network-based Artificial Intelligence (AI) systems. While the methods for generating synthetic data for AI applications in other domains have a role in certain biomedical AI systems, primarily related to image processing, there is a critical gap in the generation of time series data for AI tasks where it is necessary to know how the system works. This is most pronounced in the ability to generate synthetic multi-dimensional molecular time series data (SMMTSD); this is the type of data that underpins research into biomarkers and mediator signatures for forecasting various diseases and is an essential component of the drug development pipeline. We argue the insufficiency of statistical and data-centric machine learning (ML) means of generating this type of synthetic data is due to a combination of factors: perpetual data sparsity due to the Curse of Dimensionality, the inapplicability of the Central Li
    
[^40]: 在VoIP平台上提高知觉质量、可懂度和声学表现

    Improving Perceptual Quality, Intelligibility, and Acoustics on VoIP Platforms. (arXiv:2303.09048v1 [cs.SD])

    [http://arxiv.org/abs/2303.09048](http://arxiv.org/abs/2303.09048)

    本文提出一种基于VoIP通信平台进行DNS模型微调的方法，提高其在语音增强方面的性能。这种多任务学习框架能够将噪声抑制和VoIP特有的声学特征相结合，优于行业性能和最先进的方法。

    

    本文提出了一种方法，通过调整Deep Noise Suppression (DNS) 2020 Challenge模型在VoIP应用中的表现来提高其性能。我们的方法涉及将DNS 2020模型适应于VoIP通信的特定声学特征，包括因压缩、传输和平台特定处理而引起的失真和伪影。为此，我们提出了一种针对语音增强的VoIP-DNS多任务学习框架，共同优化降噪和VoIP特定的声学表现。我们在各种VoIP场景下评估了我们的方法，并表明它在VoIP应用的语音增强方面优于行业性能和最先进的方法。我们的结果证明了利用VoIP-DNS能够提高和定制DNS-2020训练的模型在不同的VoIP平台上的潜力，这项发现在语音识别、语音助理等领域有重要的应用。

    In this paper, we present a method for fine-tuning models trained on the Deep Noise Suppression (DNS) 2020 Challenge to improve their performance on Voice over Internet Protocol (VoIP) applications. Our approach involves adapting the DNS 2020 models to the specific acoustic characteristics of VoIP communications, which includes distortion and artifacts caused by compression, transmission, and platform-specific processing. To this end, we propose a multi-task learning framework for VoIP-DNS that jointly optimizes noise suppression and VoIP-specific acoustics for speech enhancement. We evaluate our approach on a diverse VoIP scenarios and show that it outperforms both industry performance and state-of-the-art methods for speech enhancement on VoIP applications. Our results demonstrate the potential of models trained on DNS-2020 to be improved and tailored to different VoIP platforms using VoIP-DNS, whose findings have important applications in areas such as speech recognition, voice assi
    
[^41]: 利用ChatGPT和Prompt Learning将放射学报告翻译成通俗易懂的语言：结果、限制和潜力。

    Translating Radiology Reports into Plain Language using ChatGPT and GPT-4 with Prompt Learning: Promising Results, Limitations, and Potential. (arXiv:2303.09038v1 [cs.CL])

    [http://arxiv.org/abs/2303.09038](http://arxiv.org/abs/2303.09038)

    本文研究探讨利用ChatGPT将放射学报告翻译成通俗易懂的语言，平均得分为5分制的4.1分，信息缺失率和信息错误率均较低，ChatGPT提供的建议大都与放射学报告相关。

    

    ChatGPT作为一种大型语言模型，以其类似人类表达和推理能力而备受关注。本研究探讨使用ChatGPT将放射学报告翻译成通俗易懂的语言的可行性，以便患者和医疗服务提供者得到更好的医疗教育。研究采集了62份低剂量胸部CT肺癌筛查扫描和76份脑MRI转移性筛查扫描的放射学报告。根据放射科医师的评价，ChatGPT可以成功将放射学报告翻译成通俗易懂的语言，平均得分为5分制的4.1分，信息缺失0.07处，信息错误0.11处。就ChatGPT提供的建议而言，它们是一般性的相关建议，例如保持与医生的随访和密切监测任何症状，对于共138个病例中的约37％，ChatGPT提供了与放射学报告有关的建议。

    The large language model called ChatGPT has drawn extensively attention because of its human-like expression and reasoning abilities. In this study, we investigate the feasibility of using ChatGPT in experiments on using ChatGPT to translate radiology reports into plain language for patients and healthcare providers so that they are educated for improved healthcare. Radiology reports from 62 low-dose chest CT lung cancer screening scans and 76 brain MRI metastases screening scans were collected in the first half of February for this study. According to the evaluation by radiologists, ChatGPT can successfully translate radiology reports into plain language with an average score of 4.1 in the five-point system with 0.07 places of information missing and 0.11 places of misinformation. In terms of the suggestions provided by ChatGPT, they are general relevant such as keeping following-up with doctors and closely monitoring any symptoms, and for about 37% of 138 cases in total ChatGPT offer
    
[^42]: 一幅图胜过千言万语：语言模型从像素中规划路径

    A Picture is Worth a Thousand Words: Language Models Plan from Pixels. (arXiv:2303.09031v1 [cs.CL])

    [http://arxiv.org/abs/2303.09031](http://arxiv.org/abs/2303.09031)

    本文探讨从像素中使用预训练的语言模型进行规划，相对于之前的方法在ALFWorld和VirtualHome基准测试中取得更好的表现。

    

    规划是人工智能代理执行实际环境中长时间跨度任务的重要能力。本文探讨使用预训练的语言模型（PLMs）来从文本指令中推理出规划序列的方法。之前通过PLM进行规划的方法要么假定观察结果以文本形式可获得（例如由字幕模型提供），要么仅从指令中理解规划，或者只有有限方式地整合了有关视觉环境的信息（例如预训练的可供性函数）。相反，我们展示了即使观察结果直接编码为PLM的输入提示，PLM也能够准确进行规划。我们在ALFWorld和VirtualHome基准测试中实验展示了这种简单方法优于以前的方法。

    Planning is an important capability of artificial agents that perform long-horizon tasks in real-world environments. In this work, we explore the use of pre-trained language models (PLMs) to reason about plan sequences from text instructions in embodied visual environments. Prior PLM based approaches for planning either assume observations are available in the form of text (e.g., provided by a captioning model), reason about plans from the instruction alone, or incorporate information about the visual environment in limited ways (such as a pre-trained affordance function). In contrast, we show that PLMs can accurately plan even when observations are directly encoded as input prompts for the PLM. We show that this simple approach outperforms prior approaches in experiments on the ALFWorld and VirtualHome benchmarks.
    
[^43]: 通识知识辅助的资源受限和细粒度目标检测的深度学习方法

    Commonsense Knowledge Assisted Deep Learning for Resource-constrained and Fine-grained Object Detection. (arXiv:2303.09026v1 [cs.CV])

    [http://arxiv.org/abs/2303.09026](http://arxiv.org/abs/2303.09026)

    本文提出了一种通识知识辅助的细粒度目标检测方法，利用通识知识推理模块处理由基准深度学习检测器给出的粗粒度标签，从而提高目标检测的准确性。经过实验验证，该方法相比于现有方法需要更少的计算量和标注资源。

    

    本文考虑边缘计算等资源受限场景下的细粒度图像目标检测问题。针对使用现代深度学习目标检测器时需要使用大型模型和大量数据标注的精准细粒度检测需求，提出一种方法，即利用通识知识辅助粗粒度目标检测器获取精准的细粒度检测结果。引入通识知识推理模块(CKIM)处理由基准深度学习检测器给出的粗粒度标签，从而生成细粒度标签。论文中考虑了模糊规则和清晰规则的推理，前者用于处理目标语义标签的模糊性。实验结果表明所提方法可以有效提高目标检测的准确性，同时相比于现有方法需要更少的计算量和标注资源。

    In this paper, we consider fine-grained image object detection in resource-constrained cases such as edge computing. Deep learning (DL), namely learning with deep neural networks (DNNs), has become the dominating approach to object detection. To achieve accurate fine-grained detection, one needs to employ a large enough DNN model and a vast amount of data annotations, which brings a challenge for using modern DL object detectors in resource-constrained cases. To this end, we propose an approach, which leverages commonsense knowledge to assist a coarse-grained object detector to get accurate fine-grained detection results. Specifically, we introduce a commonsense knowledge inference module (CKIM) to process coarse-grained lables given by a benchmark DL detector to produce fine-grained lables. We consider both crisp-rule and fuzzy-rule based inference in our CKIM; the latter is used to handle ambiguity in the target semantic labels. We implement our method based on several modern DL dete
    
[^44]: 机器学习在流式细胞术数据分析中的应用

    Machine Learning for Flow Cytometry Data Analysis. (arXiv:2303.09007v1 [cs.LG])

    [http://arxiv.org/abs/2303.09007](http://arxiv.org/abs/2303.09007)

    本篇论文介绍了使用机器学习，特别是随机森林算法，来分析流式细胞计数数据的方法。通过此方法，可以提高识别感兴趣的细胞组群的精度和效率，并深入理解数据复杂关系。

    

    流式细胞术主要用于检测细胞中特定标记物的表达，特别适用于检测膜表面受体、抗原、离子或DNA/RNA 表达过程中。现代的流式细胞计数器可以同时快速分析数以万计的细胞，并从单个细胞中测量多个参数。然而，传统分析方法难以解释流式细胞计数数据。因此，本文提出了使用机器学习，特别是随机森林算法，来分析流式细胞计数数据的方法。通过利用机器学习技术，作者证明了在识别感兴趣的细胞组群方面的精度和效率得到了提高，同时提供了对数据复杂关系的深入理解。

    Flow cytometry mainly used for detecting the characteristics of a number of biochemical substances based on the expression of specific markers in cells. It is particularly useful for detecting membrane surface receptors, antigens, ions, or during DNA/RNA expression. Not only can it be employed as a biomedical research tool for recognising distinctive types of cells in mixed populations, but it can also be used as a diagnostic tool for classifying abnormal cell populations connected with disease. Modern flow cytometers can rapidly analyse tens of thousands of cells at the same time while also measuring multiple parameters from a single cell. However, the rapid development of flow cytometers makes it challenging for conventional analysis methods to interpret flow cytometry data. Researchers need to be able to distinguish interesting-looking cell populations manually in multi-dimensional data collected from millions of cells. Thus, it is essential to find a robust approach for analysing f
    
[^45]: 数据集增强：提高模型准确性和鲁棒性

    Reinforce Data, Multiply Impact: Improved Model Accuracy and Robustness with Dataset Reinforcement. (arXiv:2303.08983v1 [cs.CV])

    [http://arxiv.org/abs/2303.08983](http://arxiv.org/abs/2303.08983)

    提出了一种名为数据集增强的策略，一次性改进数据集，从而提高任何经过增强的数据集训练的模型的准确性、鲁棒性和校准性。例如，使用ImageDataNet+训练的ResNet-50在ImageNet验证集上的准确率提高了1.7％，在ImageNetV2上提高了3.5％，在ImageNet-R上提高了10.0％。

    

    我们提出了一种名为数据集增强的策略，一次性改进数据集，从而提高任何经过增强的数据集训练的模型的准确性，对用户没有额外的训练成本。我们提出了一种基于数据增强和知识蒸馏的数据集增强策略。我们的通用策略是基于广泛的CNN和基于transformer的模型的分析，以及对带有各种数据增强的最先进模型进行大规模的蒸馏研究。我们创建了ImageDataNet+的增强版本，以及增强的数据集CIFAR-100+，Flowers-102+和Food-101+。使用ImageDataNet+训练的模型更准确、更有鲁棒性和校准性，并且对下游任务（例如分割和检测）具有很好的迁移能力。例如，ResNet-50在ImageNet验证集上的准确率提高了1.7％，在ImageNetV2上提高了3.5％，在ImageNet-R上提高了10.0％。在ImageDataNet+上测量的Expected Calibration Error（ECE）也有显著改进。

    We propose Dataset Reinforcement, a strategy to improve a dataset once such that the accuracy of any model architecture trained on the reinforced dataset is improved at no additional training cost for users. We propose a Dataset Reinforcement strategy based on data augmentation and knowledge distillation. Our generic strategy is designed based on extensive analysis across CNN- and transformer-based models and performing large-scale study of distillation with state-of-the-art models with various data augmentations. We create a reinforced version of the ImageNet training dataset, called ImageNet+, as well as reinforced datasets CIFAR-100+, Flowers-102+, and Food-101+. Models trained with ImageNet+ are more accurate, robust, and calibrated, and transfer well to downstream tasks (e.g., segmentation and detection). As an example, the accuracy of ResNet-50 improves by 1.7% on the ImageNet validation set, 3.5% on ImageNetV2, and 10.0% on ImageNet-R. Expected Calibration Error (ECE) on the Ima
    
[^46]: 相对坐标对于乌拉姆的"思维技巧"至关重要(arXiv:2303.08969v1 [cs.AI])

    Relative coordinates are crucial for Ulam's "trick to the train of thought". (arXiv:2303.08969v1 [cs.AI])

    [http://arxiv.org/abs/2303.08969](http://arxiv.org/abs/2303.08969)

    本文证明了，在视觉信号处理中，相对坐标对于概念形成至关重要，在动物识别特征时也很重要。

    

    空间信号处理算法通常使用预设的坐标系来标记像素位置。这些处理算法因此负担着外部参考网格，使得获取相对内部特征变得困难。这与动物的视觉和认知不同：动物可以识别没有外部坐标系统的特征。我们展示了，一个独立于坐标系的视觉信号处理算法不仅对于动物视觉重要，而且也是概念形成的基础。本文开始展示了一个视觉物体变形传递实验，接着我们推导出了一个使用相对坐标实现变形不变性的算法。文章最后讨论了通用概念形成的影响。

    Spatial signal processing algorithms often use pre-given coordinate systems to label pixel positions. These processing algorithms are thus burdened by an external reference grid, making the acquisition of relative, intrinsic features difficult. This is in contrast to animal vision and cognition: animals recognize features without an external coordinate system. We show that a coordinate system-independent algorithm for visual signal processing is not only important for animal vision, but also fundamental for concept formation. In this paper we start with a visual object deformation transfer experiment. We then formulate an algorithm that achieves deformation-invariance with relative coordinates. The paper concludes with implications for general concept formation.
    
[^47]: 使用接触隐式双层优化实现鲁棒的支点操作

    Robust Pivoting Manipulation using Contact Implicit Bilevel Optimization. (arXiv:2303.08965v1 [cs.RO])

    [http://arxiv.org/abs/2303.08965](http://arxiv.org/abs/2303.08965)

    本文使用接触隐式双层优化来规划支点操纵并增加鲁棒性，通过利用摩擦力来弥补物体和环境物理属性估计中的不准确性，以应对不确定性影响。

    

    通用操纵要求机器人能够与新物体和环境进行交互。这个要求使得操纵变得异常具有挑战性，因为机器人必须考虑到不确定因素下的复杂摩擦相互作用及物体和环境的物理属性估计的不准确性。本文研究了支点操作规划的鲁棒优化问题，提供了如何利用摩擦力来弥补物理特性估计中的不准确性的见解。在某些假设下，导出了摩擦力提供的支点操作稳定裕度的解析表达式。然后，在接触隐式双层优化(CIBO)框架中使用该裕度来优化轨迹 ，以增强对物体多个物理参数不确定性的鲁棒性。我们在实际机器人上的实验中，对于严重干扰的参数，分析了稳定裕度，并显示了优化轨迹的改善鲁棒性。

    Generalizable manipulation requires that robots be able to interact with novel objects and environment. This requirement makes manipulation extremely challenging as a robot has to reason about complex frictional interactions with uncertainty in physical properties of the object and the environment. In this paper, we study robust optimization for planning of pivoting manipulation in the presence of uncertainties. We present insights about how friction can be exploited to compensate for inaccuracies in the estimates of the physical properties during manipulation. Under certain assumptions, we derive analytical expressions for stability margin provided by friction during pivoting manipulation. This margin is then used in a Contact Implicit Bilevel Optimization (CIBO) framework to optimize a trajectory that maximizes this stability margin to provide robustness against uncertainty in several physical parameters of the object. We present analysis of the stability margin with respect to sever
    
[^48]: 探究数据隐私增强技术在AI治理应用中的相关性

    Exploring the Relevance of Data Privacy-Enhancing Technologies for AI Governance Use Cases. (arXiv:2303.08956v1 [cs.AI])

    [http://arxiv.org/abs/2303.08956](http://arxiv.org/abs/2303.08956)

    探究数据隐私增强技术对AI治理的重要性，将不同的AI治理目标视为系统信息流，强调解决方案之间的互操作性。

    

    随着隐私增强技术的发展，数据交换和分析中隐私与性能之间的权衡已经得到了极大的改善。类似的透明度结构工具对于AI治理也很有用，因为它们可以提供外部审查、审计和源验证等能力。为了避免治理上的重大漏洞和局限性，需要将这些不同的AI治理目标视为信息流系统。由于在本文提到的AI治理用例所需的软件栈中可能存在重叠，因此在整体上看待系统，了解这些不同的AI治理解决方案之间的互操作性变得很重要。因此，在这些标准、审计程序、软件和规范定型之前，首先紧急需要将AI治理中的这些问题作为系统来研究和解决。

    The development of privacy-enhancing technologies has made immense progress in reducing trade-offs between privacy and performance in data exchange and analysis. Similar tools for structured transparency could be useful for AI governance by offering capabilities such as external scrutiny, auditing, and source verification. It is useful to view these different AI governance objectives as a system of information flows in order to avoid partial solutions and significant gaps in governance, as there may be significant overlap in the software stacks needed for the AI governance use cases mentioned in this text. When viewing the system as a whole, the importance of interoperability between these different AI governance solutions becomes clear. Therefore, it is imminently important to look at these problems in AI governance as a system, before these standards, auditing procedures, software, and norms settle into place.
    
[^49]: 自动化交互式特定领域对话代理，理解人类对话

    Automated Interactive Domain-Specific Conversational Agents that Understand Human Dialogs. (arXiv:2303.08941v1 [cs.AI])

    [http://arxiv.org/abs/2303.08941](http://arxiv.org/abs/2303.08941)

    本文介绍了利用大型语言模型和Answer Set Programming实现真正“理解”人类对话的AutoConcierge系统。该系统针对特定领域，为用户提供有关附近餐厅的建议。

    

    在知识表示与推理以及自然语言处理领域，实现与人类的人类对话相似的通信仍然是一个经典而具有挑战性的主题。这些大型语言模型（LLM）依赖于模式匹配，而不是真正理解句子的语义含义。因此，它们可能会生成错误的响应。要生成保证正确的响应，必须“理解”句子的语义。为了实现这种“理解”，需要基于逻辑的（常识）推理方法，例如答案集编程（ASP）。在本文中，我们描述了AutoConcierge系统，它利用LLMs和ASP开发了一种对话代理，可以真正“理解”受限领域内的人类对话。AutoConcierge专注于一个特定的领域-根据用户的喜好建议他们附近的餐厅。AutoConcierge将交互式地理解用户的话语，确定其中缺失的信息。

    Achieving human-like communication with machines remains a classic, challenging topic in the field of Knowledge Representation and Reasoning and Natural Language Processing. These Large Language Models (LLMs) rely on pattern-matching rather than a true understanding of the semantic meaning of a sentence. As a result, they may generate incorrect responses. To generate an assuredly correct response, one has to "understand" the semantics of a sentence. To achieve this "understanding", logic-based (commonsense) reasoning methods such as Answer Set Programming (ASP) are arguably needed. In this paper, we describe the AutoConcierge system that leverages LLMs and ASP to develop a conversational agent that can truly "understand" human dialogs in restricted domains. AutoConcierge is focused on a specific domain-advising users about restaurants in their local area based on their preferences. AutoConcierge will interactively understand a user's utterances, identify the missing information in them
    
[^50]: 设计参与式AI：创意专业人士对生成AI的忧虑和期望。

    Designing Participatory AI: Creative Professionals' Worries and Expectations about Generative AI. (arXiv:2303.08931v1 [cs.HC])

    [http://arxiv.org/abs/2303.08931](http://arxiv.org/abs/2303.08931)

    本文介绍了一项调查，调查了创意专业人士对生成AI的关注点和期望，并讨论了如何设计参与式AI来赋予创意专业人士在与AI的现在和未来的协作中的自主权。

    

    自动基于文本提示生成视觉或书面内容的生成AI已经在短短几年内经历了复杂性的飞跃并广泛普及。这些技术潜在地对创意领域造成了巨大的冲击。本文介绍了一项定性调研（$N$ = 23），调查了创意专业人士如何思考生成AI。结果表明，这些AI模型的进步促使对定义创造力的重要反思，并探讨了创意专业人士如何想象使用AI来支持他们的工作流程。基于这些思考，我们讨论如何设计在创意专业领域中的\textit{参与式 AI}，以赋予创意专业人士在他们与AI的现在和未来共存中的自主权。

    Generative AI, i.e., the group of technologies that automatically generate visual or written content based on text prompts, has undergone a leap in complexity and become widely available within just a few years. Such technologies potentially introduce a massive disruption to creative fields. This paper presents the results of a qualitative survey ($N$ = 23) investigating how creative professionals think about generative AI. The results show that the advancement of these AI models prompts important reflections on what defines creativity and how creatives imagine using AI to support their workflows. Based on these reflections, we discuss how we might design \textit{participatory AI} in the domain of creative expertise with the goal of empowering creative professionals in their present and future coexistence with AI.
    
[^51]: EvalAttAI：一种综合评估鲁棒和非鲁棒模型中的归因映射方法的方法

    EvalAttAI: A Holistic Approach to Evaluating Attribution Maps in Robust and Non-Robust Models. (arXiv:2303.08866v1 [cs.LG])

    [http://arxiv.org/abs/2303.08866](http://arxiv.org/abs/2303.08866)

    该论文提出了一个综合方法EvalAttAI，旨在同时考虑归因映射在各种条件下的稳健性和保真度，以更好地评估归因映射的性能并选择适合特定应用的方法。

    

    可解释的人工智能作为一个研究领域的扩张，已经产生了许多可视化和理解机器学习模型黑盒的方法。归因映射通常用于突出显示影响模型做出特定决策的输入图像的部分。另一方面，机器学习模型对自然噪声和对抗攻击的鲁棒性也正在积极探索。本文重点评估归因映射方法，以找到鲁棒神经网络是否更可解释。我们将这个问题探索在医学成像的分类应用中。可解释性研究已经陷入了僵局。虽然有许多归因映射方法，但目前并没有共识如何评估它们并确定最好的方法。我们在多个数据集（自然和医学成像）和各种归因方法上进行的实验证明，两种流行的评估指标，删除和插入稳健性，不足以评估鲁棒模型中的归因映射。相反，我们提出了一种综合方法EvalAttAI，在各种条件下考虑归因映射的稳健性和保真度。EvalAttAI可以帮助研究人员和实践者更好地评估归因映射的性能，并选择适合其特定应用的方法。

    The expansion of explainable artificial intelligence as a field of research has generated numerous methods of visualizing and understanding the black box of a machine learning model. Attribution maps are generally used to highlight the parts of the input image that influence the model to make a specific decision. On the other hand, the robustness of machine learning models to natural noise and adversarial attacks is also being actively explored. This paper focuses on evaluating methods of attribution mapping to find whether robust neural networks are more explainable. We explore this problem within the application of classification for medical imaging. Explainability research is at an impasse. There are many methods of attribution mapping, but no current consensus on how to evaluate them and determine the ones that are the best. Our experiments on multiple datasets (natural and medical imaging) and various attribution methods reveal that two popular evaluation metrics, Deletion and Ins
    
[^52]: 无线传感器网络中的机器学习异常检测：综述

    Wireless Sensor Networks anomaly detection using Machine Learning: A Survey. (arXiv:2303.08823v1 [cs.LG])

    [http://arxiv.org/abs/2303.08823](http://arxiv.org/abs/2303.08823)

    本篇综述论文介绍了机器学习技术在无线传感器网络中进行数据异常检测的最新应用。讲述了这种技术能够解决传感数据中异常模式检测的问题，并比较了不同方法的优缺点。

    

    无线传感器网络（WSN）已经在各种公民/军事应用中变得越来越有价值，如工业过程控制、建筑结构强度监测、环境监测、边境入侵、物联网和医疗保健等。然而，WSN产生的传感数据通常噪声和不可靠，这使得检测和诊断异常成为一项挑战。机器学习（ML）技术已广泛应用于解决此问题，通过检测和识别传感数据中的异常模式。本综述论文概述了ML技术在WSN领域数据异常检测方面的最新应用。我们首先介绍WSN的特征和WSN中异常检测的挑战。接着，我们回顾了各种应用于WSN数据异常检测的监督，无监督和半监督学习等ML技术。我们还比较了不同的ML异常检测方法，并强调了它们的优缺点。最后，我们讨论了一些开放的研究问题，并概述了这一领域的未来研究方向。

    Wireless Sensor Networks (WSNs) have become increasingly valuable in various civil/military applications like industrial process control, civil engineering applications such as buildings structural strength monitoring, environmental monitoring, border intrusion, IoT (Internet of Things), and healthcare. However, the sensed data generated by WSNs is often noisy and unreliable, making it a challenge to detect and diagnose anomalies. Machine learning (ML) techniques have been widely used to address this problem by detecting and identifying unusual patterns in the sensed data. This survey paper provides an overview of the state of the art applications of ML techniques for data anomaly detection in WSN domains. We first introduce the characteristics of WSNs and the challenges of anomaly detection in WSNs. Then, we review various ML techniques such as supervised, unsupervised, and semi-supervised learning that have been applied to WSN data anomaly detection. We also compare different ML-base
    
[^53]: 问就能得到（一个图形绘制）：测试ChatGPT应用图形布局算法的潜力

    Ask and You Shall Receive (a Graph Drawing): Testing ChatGPT's Potential to Apply Graph Layout Algorithms. (arXiv:2303.08819v1 [cs.HC])

    [http://arxiv.org/abs/2303.08819](http://arxiv.org/abs/2303.08819)

    本论文探讨了将大语言模型应用于图形绘制算法的潜力，通过在ChatGPT上进行实验，我们相信LLM的能力可以使有限编码背景的用户使用自然语言来创建有效的图形可视化，这将提高图形绘制任务的效率和效果。

    

    大语言模型（LLM）近来风靡全球。它们可以生成连贯的文本，进行有意义的对话，并学习概念和基本指令集-例如算法步骤。在这个背景下，我们有兴趣探索将LLM用于图形绘制算法的应用，并在ChatGPT上进行实验。这些算法用于改善图形可视化的可读性。LLM的概率性质对于正确实现算法提出了挑战，但我们相信LLM学习大量数据并应用复杂操作的能力可能会导致有趣的图形绘制结果。例如，我们可以使有限编码背景的用户使用简单的自然语言来创建有效的图形可视化。自然语言规范会使数据可视化更加易用，使更广泛的用户能够使用。探索LLM在图形绘制方面的能力也可以帮助弥合人类语言与计算机代码之间的差距，提高图形绘制任务的效率和效果。

    Large language models (LLMs) have recently taken the world by storm. They can generate coherent text, hold meaningful conversations, and be taught concepts and basic sets of instructions - such as the steps of an algorithm. In this context, we are interested in exploring the application of LLMs to graph drawing algorithms by performing experiments on ChatGPT. These algorithms are used to improve the readability of graph visualizations. The probabilistic nature of LLMs presents challenges to implementing algorithms correctly, but we believe that LLMs' ability to learn from vast amounts of data and apply complex operations may lead to interesting graph drawing results. For example, we could enable users with limited coding backgrounds to use simple natural language to create effective graph visualizations. Natural language specification would make data visualization more accessible and user-friendly for a wider range of users. Exploring LLMs' capabilities for graph drawing can also help 
    
[^54]: 理解事后解释器：以Anchors为例

    Understanding Post-hoc Explainers: The Case of Anchors. (arXiv:2303.08806v1 [stat.ML])

    [http://arxiv.org/abs/2303.08806](http://arxiv.org/abs/2303.08806)

    本文对Anchors进行了理论分析，这是一种基于规则的可解释性方法，用于解释文本分类器的决策。

    

    在许多情况下，机器学习模型可解释性是一项高度要求但难以实现的任务。为了解释这些模型的个体预测，已经提出了本地模型无关方法。然而，产生解释的过程对于用户来说可能与要解释的预测一样神秘。此外，可解释性方法经常缺乏理论保证，并且它们在简单模型上的行为通常是未知的。本文对Anchors（Ribeiro等人，2018）进行理论分析：一种流行的基于规则的可解释性方法，它强调一小组单词以解释文本分类器的决策。

    In many scenarios, the interpretability of machine learning models is a highly required but difficult task. To explain the individual predictions of such models, local model-agnostic approaches have been proposed. However, the process generating the explanations can be, for a user, as mysterious as the prediction to be explained. Furthermore, interpretability methods frequently lack theoretical guarantees, and their behavior on simple models is frequently unknown. While it is difficult, if not impossible, to ensure that an explainer behaves as expected on a cutting-edge model, we can at least ensure that everything works on simple, already interpretable models. In this paper, we present a theoretical analysis of Anchors (Ribeiro et al., 2018): a popular rule-based interpretability method that highlights a small set of words to explain a text classifier's decision. After formalizing its algorithm and providing useful insights, we demonstrate mathematically that Anchors produces meaningf
    
[^55]: GPT-4技术报告

    GPT-4 Technical Report. (arXiv:2303.08774v1 [cs.CL])

    [http://arxiv.org/abs/2303.08774](http://arxiv.org/abs/2303.08774)

    GPT-4是一个大规模多模态模型，可以接收图像和文本输入并产生文本输出，能够在各种专业和学术基准测试中表现出人类水平的表现，包括通过模拟的律师考试。该项目的核心组件是开发基础设施和优化方法，可在广泛的规模范围内表现预测性。

    

    我们报告了GPT-4的开发，它是一个可以接受图像和文本输入并产生文本输出的大规模多模态模型。虽然在许多现实场景中不如人类，但GPT-4在各种专业和学术基准测试中表现出人类水平的表现，包括通过模拟的律师考试，成绩排名在前10％左右。GPT-4是一个基于Transformer的模型，预训练用于预测文档中的下一个标记。后训练对齐过程提高了事实性和符合期望行为的性能指标。项目的核心组件是开发基础设施和优化方法，可在广泛的规模范围内表现预测性。这使我们能够准确预测GPT-4的某些性能方面，而这些性能是基于使用不超过GPT-4计算能力的1/1,000的模型训练的。

    We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.
    
[^56]: FactReranker：基于事实引导的辅助评估器用于忠实的放射学报告摘要。

    FactReranker: Fact-guided Reranker for Faithful Radiology Report Summarization. (arXiv:2303.08335v1 [cs.CL])

    [http://arxiv.org/abs/2303.08335](http://arxiv.org/abs/2303.08335)

    FactReranker是一种新颖的辅助评估器，可以在保持摘要与放射学发现实况一致性的基础上，通过事实引导来有效地选择最佳的摘要。

    

    自动放射学报告摘要是一项至关重要的临床任务，其主要挑战在于保持所产生的摘要和地面实况放射学发现之间的实际准确性。现有研究采用强化学习来直接优化正确认知度量指标，如CheXBert或RadGraph分数。然而，它们使用贪婪搜索或束搜索的解码方法，在选择最佳候选项时没有考虑事实的一致性，从而导致实际一致性的改善受限。为了解决这个问题，我们提出了一种新颖的第二阶段摘要方法FactReranker，它是第一次尝试基于它们估计的实际一致性得分来学习从所有候选项中选择最佳摘要。我们建议基于RadGraph模式提取输入医疗报告、其黄金摘要和候选摘要的医疗事实，并设计基于事实引导的重新排序器，以有效地结合提取的医疗事实来选择最佳摘要。我们分解了事实-

    Automatic radiology report summarization is a crucial clinical task, whose key challenge is to maintain factual accuracy between produced summaries and ground truth radiology findings. Existing research adopts reinforcement learning to directly optimize factual consistency metrics such as CheXBert or RadGraph score. However, their decoding method using greedy search or beam search considers no factual consistency when picking the optimal candidate, leading to limited factual consistency improvement. To address it, we propose a novel second-stage summarizing approach FactReranker, the first attempt that learns to choose the best summary from all candidates based on their estimated factual consistency score. We propose to extract medical facts of the input medical report, its gold summary, and candidate summaries based on the RadGraph schema and design the fact-guided reranker to efficiently incorporate the extracted medical facts for selecting the optimal summary. We decompose the fact-
    
[^57]: 基于后训练量化的大型语言模型综合研究

    A Comprehensive Study on Post-Training Quantization for Large Language Models. (arXiv:2303.08302v1 [cs.LG])

    [http://arxiv.org/abs/2303.08302](http://arxiv.org/abs/2303.08302)

    本文基于数万个零-shot实验对基于后训练量化的大型语言模型的不同量化组件进行了综合研究，结果发现细粒度量化和后训练量化方法很重要，用粗粒度量化的更高位数比用非常细粒度的更低位数更强大。我们给出了如何为不同大小的\llms利用量化的建议。

    

    后训练量化是一种减少大型语言模型内存消耗和/或计算成本的权衡方法。然而，关于不同量化方案、不同模型族、不同后训练量化方法、不同量化位精度等的影响的全面研究仍缺失。本文通过数万个零-shot实验对这些组件进行了广泛的研究。我们的研究结果表明：(1)细粒度量化和后训练量化方法(而不是朴素的最近舍入量化)是实现良好精度的必要条件；(2) 用粗粒度量化的更高位数（如5位）比用非常细粒度的更低位数（如4位）（其有效位数与5位相似）更强大。我们还提出了如何为不同大小的\llms利用量化的建议，并留下未来机会和系统工作的建议。

    Post-training quantization (\ptq) had been recently shown as a compromising method to reduce the memory consumption and/or compute cost for large language models. However, a comprehensive study about the effect of different quantization schemes, different model families, different \ptq methods, different quantization bit precision, etc, is still missing. In this work, we provide an extensive study on those components over tens of thousands of zero-shot experiments. Our results show that (1) Fine-grained quantization and \ptq methods (instead of naive round-to-nearest quantization) are necessary to achieve good accuracy and (2) Higher bits (e.g., 5 bits) with coarse-grained quantization is more powerful than lower bits (e.g., 4 bits) with very fine-grained quantization (whose effective bits is similar to 5-bits). We also present recommendations about how to utilize quantization for \llms with different sizes, and leave suggestions of future opportunities and system work that are not res
    
[^58]: 一种针对压缩视频的时间句子对齐的有效和高效管道

    You Can Ground Earlier than See: An Effective and Efficient Pipeline for Temporal Sentence Grounding in Compressed Videos. (arXiv:2303.07863v1 [cs.CV])

    [http://arxiv.org/abs/2303.07863](http://arxiv.org/abs/2303.07863)

    本文提出了一种新的压缩域TSG设置，通过直接编码压缩位流来增强视觉特征表示能力和提高时间句子对齐的效率，并且在两个基准数据集的实验中表现优于目前最先进的方法。

    

    时间句子对齐旨在根据句子查询通过语义定位目标瞬间。在本文中，我们提出了一种新的压缩域TSG（Temporal Sentence Grounding）设置，直接使用压缩视频作为视觉输入。针对原始视频比特流输入，我们提出了一种新型三支路压缩空间时间融合框架（TCSF），用于有效且高效地定位。我们通过利用压缩伪影来增强视觉特征的表示能力，提出了一种直接编码压缩位流的方法，而不是先解码整个帧的方法。在两个基准数据集上的实验结果表明，我们的方法在效果和效率方面优于目前最先进的方法。

    Given an untrimmed video, temporal sentence grounding (TSG) aims to locate a target moment semantically according to a sentence query. Although previous respectable works have made decent success, they only focus on high-level visual features extracted from the consecutive decoded frames and fail to handle the compressed videos for query modelling, suffering from insufficient representation capability and significant computational complexity during training and testing. In this paper, we pose a new setting, compressed-domain TSG, which directly utilizes compressed videos rather than fully-decompressed frames as the visual input. To handle the raw video bit-stream input, we propose a novel Three-branch Compressed-domain Spatial-temporal Fusion (TCSF) framework, which extracts and aggregates three kinds of low-level visual features (I-frame, motion vector and residual features) for effective and efficient grounding. Particularly, instead of encoding the whole decoded frames like previous
    
[^59]: TriDet: 使用相对边界建模的时间行为检测

    TriDet: Temporal Action Detection with Relative Boundary Modeling. (arXiv:2303.07347v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.07347](http://arxiv.org/abs/2303.07347)

    TriDet提出了一个新颖的三叉头模型和SGP特征金字塔来提高时间行为检测的边界预测和聚合多种时间尺度信息。在三个挑战性的基准测试上，TriDet取得了最先进的性能。

    

    本文提出了一个单阶段框架TriDet，用于时间行为检测。目前的方法往往由于视频中模糊的动作边界而导致不准确的边界预测。为了解决这个问题，我们提出了一个新颖的三叉头（Trident-head）来通过相对概率分布来建模动作边界。在TriDet的特征金字塔中，我们提出了一个高效的可扩展粒度感知（SGP）层来缓解自注意力在视频特征中发生的排名损失问题，并在不同的时间粒度上聚合信息。由于三叉头和基于SGP的特征金字塔的优势，TriDet在三个具有挑战性的基准测试（THUMOS14、HACS和EPIC-KITCHEN 100）上实现了最先进的性能，与以前的方法相比计算成本更低。例如，在THUMOS14上，TriDet的平均mAP达到$69.3\%$，超过先前最优结果$2.5\%$，但只有$74.6\%$的计算成本。

    In this paper, we present a one-stage framework TriDet for temporal action detection. Existing methods often suffer from imprecise boundary predictions due to the ambiguous action boundaries in videos. To alleviate this problem, we propose a novel Trident-head to model the action boundary via an estimated relative probability distribution around the boundary. In the feature pyramid of TriDet, we propose an efficient Scalable-Granularity Perception (SGP) layer to mitigate the rank loss problem of self-attention that takes place in the video features and aggregate information across different temporal granularities. Benefiting from the Trident-head and the SGP-based feature pyramid, TriDet achieves state-of-the-art performance on three challenging benchmarks: THUMOS14, HACS and EPIC-KITCHEN 100, with lower computational costs, compared to previous methods. For example, TriDet hits an average mAP of $69.3\%$ on THUMOS14, outperforming the previous best by $2.5\%$, but with only $74.6\%$ o
    
[^60]: 基于Transformer的符号回归规划

    Transformer-based Planning for Symbolic Regression. (arXiv:2303.06833v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.06833](http://arxiv.org/abs/2303.06833)

    该论文提出了一种基于Transformer和蒙特卡罗树搜索的符号回归规划策略TPSR，可以将非可微的反馈作为知识的外部来源融入到方程生成过程中，提高方程生成的准确性和复杂性。

    

    符号回归是机器学习中一项具有挑战性的任务，它涉及基于函数值查找其数学表达式。最近，符号回归的一些进展表明，预训练的基于Transformer的模型对于生成方程序列是有效的，这些模型从合成数据集的大规模预训练中获益，并在推理时间方面比基于GP的方法具有显著优势。然而，这些模型关注的是借鉴文本生成的监督预训练目标，而忽略了方程的特定目标，如准确性和复杂性。为了解决这个问题，我们提出了TPSR，一种基于Transformer的符号回归规划策略，将蒙特卡罗树搜索融入到Transformer解码过程中。与传统的解码策略不同，TPSR允许将非可微的反馈（如拟合准确性和复杂性）作为知识的外部来源融入到方程生成过程中。

    Symbolic regression (SR) is a challenging task in machine learning that involves finding a mathematical expression for a function based on its values. Recent advancements in SR have demonstrated the efficacy of pretrained transformer-based models for generating equations as sequences, which benefit from large-scale pretraining on synthetic datasets and offer considerable advantages over GP-based methods in terms of inference time. However, these models focus on supervised pretraining goals borrowed from text generation and ignore equation-specific objectives like accuracy and complexity. To address this, we propose TPSR, a Transformer-based Planning strategy for Symbolic Regression that incorporates Monte Carlo Tree Search into the transformer decoding process. TPSR, as opposed to conventional decoding strategies, allows for the integration of non-differentiable feedback, such as fitting accuracy and complexity, as external sources of knowledge into the equation generation process. Ext
    
[^61]: ODIN：应对数据锁定的按需数据制定方法

    ODIN: On-demand Data Formulation to Mitigate Dataset Lock-in. (arXiv:2303.06832v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.06832](http://arxiv.org/abs/2303.06832)

    ODIN采用生成AI模型，通过根据用户需求生成按需数据集，解决了传统零样本学习方法在数据集约束方面的限制，使得人工智能能够学习超出训练数据集的未见知识。

    

    ODIN是一种创新性的方法，通过整合生成式AI模型来解决数据集约束问题。传统的零样本学习方法受训练数据集的限制较大。为了从根本上克服这一限制，ODIN试图通过根据用户需求生成按需数据集来减轻数据集约束。ODIN由三个主要模块组成：提示生成器、文本到图像生成器和图像后处理器。为了生成高质量的提示和图像，我们采用了大型语言模型（例如ChatGPT）和文本到图像扩散模型（例如Stable Diffusion）。我们在各种数据集上对ODIN进行了模型准确性和数据多样性方面的评估以展示其潜力，并进行了进一步的后处理实验。总的来说，ODIN是一种可行的方法，使人工智能能够学习超出训练数据集的未见知识。

    ODIN is an innovative approach that addresses the problem of dataset constraints by integrating generative AI models. Traditional zero-shot learning methods are constrained by the training dataset. To fundamentally overcome this limitation, ODIN attempts to mitigate the dataset constraints by generating on-demand datasets based on user requirements. ODIN consists of three main modules: a prompt generator, a text-to-image generator, and an image post-processor. To generate high-quality prompts and images, we adopted a large language model (e.g., ChatGPT), and a text-to-image diffusion model (e.g., Stable Diffusion), respectively. We evaluated ODIN on various datasets in terms of model accuracy and data diversity to demonstrate its potential, and conducted post-experiments for further investigation. Overall, ODIN is a feasible approach that enables Al to learn unseen knowledge beyond the training dataset.
    
[^62]: 使用不确定性估计指导伪标签的无源自适应域自适应方法研究

    Guiding Pseudo-labels with Uncertainty Estimation for Source-free Unsupervised Domain Adaptation. (arXiv:2303.03770v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.03770](http://arxiv.org/abs/2303.03770)

    本研究提出一种基于损失重新加权策略的无源自适应域自适应（SF-UDA）方法，用于适应目标域，其关键是通过估计伪标签的不确定性来指导其进一步精化，并利用自监督对比框架作为目标空间的正则化器以提高预测精度。

    

    标准的无监督域自适应方法假定在适应过程中同时可用源域和目标域数据。在这项工作中，我们研究了无源自适应域自适应（SF-UDA）方法，它是UDA的一个特殊情况，在该情况下，模型在没有访问源数据的情况下适应目标域。我们提出了一种新的方法来处理SF-UDA设置，基于损失重新加权策略，以增强对伪标签的噪声的鲁棒性。该分类损失基于估计其不确定性来重新加权，以指导伪标签的进一步精化，并通过聚集相邻样本的知识来逐步提高其准确性。此外，我们引入了自监督对比框架来作为目标空间的正则化器，以增强知识的聚合。同时，我们提出了一种负样本对排除策略，以识别和排除由共享相同特征的样本构成的负样本对。

    Standard Unsupervised Domain Adaptation (UDA) methods assume the availability of both source and target data during the adaptation. In this work, we investigate Source-free Unsupervised Domain Adaptation (SF-UDA), a specific case of UDA where a model is adapted to a target domain without access to source data. We propose a novel approach for the SF-UDA setting based on a loss reweighting strategy that brings robustness against the noise that inevitably affects the pseudo-labels. The classification loss is reweighted based on the reliability of the pseudo-labels that is measured by estimating their uncertainty. Guided by such reweighting strategy, the pseudo-labels are progressively refined by aggregating knowledge from neighbouring samples. Furthermore, a self-supervised contrastive framework is leveraged as a target space regulariser to enhance such knowledge aggregation. A novel negative pairs exclusion strategy is proposed to identify and exclude negative pairs made of samples shari
    
[^63]: BIFRNet: 一种脑启发的特征重建深度神经网络用于部分遮挡图像识别

    BIFRNet: A Brain-Inspired Feature Restoration DNN for Partially Occluded Image Recognition. (arXiv:2303.01309v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.01309](http://arxiv.org/abs/2303.01309)

    BIFRNet是一种脑启发的深度神经网络，使用特殊的背侧视觉通路来识别部分遮挡的图像，并且能够通过特征重建来填补被遮挡的信息。

    

    部分遮挡图像识别（POIR）一直以来是人工智能中的难题。解决POIR问题的一种常见策略是使用未遮挡的特征进行分类。然而，当图像严重遮挡时，该策略将失去效果，因为可见部分只能提供有限的信息。神经科学的几项研究表明，要识别部分遮挡的图像，特征重建（填补被遮挡的信息）非常重要，被称为无模完成。然而，CNN常常忽略特征重建，这可能是CNN对POIR问题无效的原因。受此启发，我们提出了一种新型的脑启发特征重建网络（BIFRNet）来解决POIR问题。它模仿了腹侧视觉通路来提取图像特征和背侧视觉通路来区分被遮挡和可见的图像区域。

    The partially occluded image recognition (POIR) problem has been a challenge for artificial intelligence for a long time. A common strategy to handle the POIR problem is using the non-occluded features for classification. Unfortunately, this strategy will lose effectiveness when the image is severely occluded, since the visible parts can only provide limited information. Several studies in neuroscience reveal that feature restoration which fills in the occluded information and is called amodal completion is essential for human brains to recognize partially occluded images. However, feature restoration is commonly ignored by CNNs, which may be the reason why CNNs are ineffective for the POIR problem. Inspired by this, we propose a novel brain-inspired feature restoration network (BIFRNet) to solve the POIR problem. It mimics a ventral visual pathway to extract image features and a dorsal visual pathway to distinguish occluded and visible image regions. In addition, it also uses a knowle
    
[^64]: AR3n: 一种基于强化学习的机器人康复辅助控制器

    AR3n: A Reinforcement Learning-based Assist-As-Needed Controller for Robotic Rehabilitation. (arXiv:2303.00085v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.00085](http://arxiv.org/abs/2303.00085)

    本文提出了一种基于强化学习的机器人康复辅助控制器AR3n，通过使用虚拟患者模型实现控制器的泛化，实时调节机器人辅助力度并最小化机器人辅助的量，该控制器在实验验证中表现出良好的效果。

    

    本文提出了AR3n（发音为Aaron），一种采用强化学习的辅助控制器，可在机器人辅助的书写康复任务中提供适应性辅助。与以往的辅助控制器不同，我们的方法不依赖于患者特定的控制器参数或物理模型。我们建议使用虚拟患者模型来使AR3n推广到多个受试者。该系统实时调节机器人辅助力度，同时最小化机器人辅助的量，基于被试的跟踪误差。通过一组仿真实验和人体受试实验对控制器进行实验验证。最后，进行了与传统基于规则的控制器的比较研究，以分析两种控制器的辅助机制的差异。

    In this paper, we present AR3n (pronounced as Aaron), an assist-as-needed (AAN) controller that utilizes reinforcement learning to supply adaptive assistance during a robot assisted handwriting rehabilitation task. Unlike previous AAN controllers, our method does not rely on patient specific controller parameters or physical models. We propose the use of a virtual patient model to generalize AR3n across multiple subjects. The system modulates robotic assistance in realtime based on a subject's tracking error, while minimizing the amount of robotic assistance. The controller is experimentally validated through a set of simulations and human subject experiments. Finally, a comparative study with a traditional rule-based controller is conducted to analyze differences in assistance mechanisms of the two controllers.
    
[^65]: 实现扩展扩展扩散模型的可控性

    Towards Enhanced Controllability of Diffusion Models. (arXiv:2302.14368v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.14368](http://arxiv.org/abs/2302.14368)

    本文介绍了一种基于条件输入的扩散模型，利用两个潜在编码控制生成过程中的空间结构和语义风格，提出了两种通用采样技术和时间步相关的潜在权重调度，实现了对生成过程的更好控制。

    

    去噪扩散模型在生成逼真、高质量和多样化图像方面表现出卓越能力。然而，在生成过程中的可控程度尚未得到充分探讨。受基于GAN潜在空间的图像操纵技术启发，我们训练了一个条件于两个潜在编码、一个空间内容掩码和一个扁平的样式嵌入的扩散模型。我们依赖于扩散模型渐进去噪过程的感性偏置，在空间结构掩码中编码姿势/布局信息，在样式代码中编码语义/样式信息。我们提出了两种通用的采样技术来改善可控性。我们扩展了可组合的扩散模型，允许部分依赖于条件输入，以提高生成质量，同时还提供对每个潜在代码和它们的联合分布量的控制。我们还提出了时间步相关的内容和样式潜在权重调度，进一步提高了控制性。

    Denoising Diffusion models have shown remarkable capabilities in generating realistic, high-quality and diverse images. However, the extent of controllability during generation is underexplored. Inspired by techniques based on GAN latent space for image manipulation, we train a diffusion model conditioned on two latent codes, a spatial content mask and a flattened style embedding. We rely on the inductive bias of the progressive denoising process of diffusion models to encode pose/layout information in the spatial structure mask and semantic/style information in the style code. We propose two generic sampling techniques for improving controllability. We extend composable diffusion models to allow for some dependence between conditional inputs, to improve the quality of generations while also providing control over the amount of guidance from each latent code and their joint distribution. We also propose timestep dependent weight scheduling for content and style latents to further impro
    
[^66]: 马尔科夫条件与逻辑信任网络中的因子分解

    Markov Conditions and Factorization in Logical Credal Networks. (arXiv:2302.14146v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.14146](http://arxiv.org/abs/2302.14146)

    本文研究逻辑信任网络并探究不同马尔科夫条件的影响。我们发现没有有向循环的网络可以进行因子分解，而带有有向循环的网络则需要特别考虑不同的马尔科夫条件。

    

    我们研究了最近提出的逻辑信任网络的语言，特别是调查不同马尔科夫条件的后果。我们引入了逻辑信任网络的结构概念，并展示了没有有向循环的结构将导致一个众所周知的因子分解结果。对于带有有向循环的网络，我们分析了马尔科夫条件、因子分解结果和规范要求之间的差异。

    We examine the recently proposed language of Logical Credal Networks, in particular investigating the consequences of various Markov conditions. We introduce the notion of structure for a Logical Credal Network and show that a structure without directed cycles leads to a well-known factorization result. For networks with directed cycles, we analyze the differences between Markov conditions, factorization results, and specification requirements.
    
[^67]: Fairguard: 在智慧城市中利用基于逻辑的公正规则

    Fairguard: Harness Logic-based Fairness Rules in Smart Cities. (arXiv:2302.11137v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.11137](http://arxiv.org/abs/2302.11137)

    本文提出了一种基于时间逻辑的公正智慧城市政策调整和生成方法Fairguard，通过两个阶段的静态生成和动态调节，缓解由多种数据和算法偏见导致的不公正预测结果。

    

    智慧城市运行在计算预测框架上，收集、整合和利用大规模传感器网络的数据。然而，这些框架容易受到多种数据和算法偏见的影响，这经常导致不公正的预测结果。本文首先通过研究田纳西州查塔努加的真实城市数据，展示了偏见在微观层面上在时间和空间上仍然存在。为了缓解这种偏见问题，我们引入了Fairguard，这是一种基于微观层面时间逻辑的方法，用于在复杂的时间空间域中进行公正的智慧城市政策调整和生成。Fairguard框架由两个阶段组成：首先，我们开发了一个静态生成器，能够通过最小化所选属性之间的相关性，基于时间逻辑条件来减少数据偏见。然后，为了确保预测算法的公正性，我们设计了一个动态组件来调节预测结果，并利用逻辑规则生成未来的公正预测。

    Smart cities operate on computational predictive frameworks that collect, aggregate, and utilize data from large-scale sensor networks. However, these frameworks are prone to multiple sources of data and algorithmic bias, which often lead to unfair prediction results. In this work, we first demonstrate that bias persists at a micro-level both temporally and spatially by studying real city data from Chattanooga, TN. To alleviate the issue of such bias, we introduce Fairguard, a micro-level temporal logic-based approach for fair smart city policy adjustment and generation in complex temporal-spatial domains. The Fairguard framework consists of two phases: first, we develop a static generator that is able to reduce data bias based on temporal logic conditions by minimizing correlations between selected attributes. Then, to ensure fairness in predictive algorithms, we design a dynamic component to regulate prediction results and generate future fair predictions by harnessing logic rules. E
    
[^68]: 通过视觉创作解读心理状态：《看见你的内心》

    See Your Heart: Psychological states Interpretation through Visual Creations. (arXiv:2302.10276v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.10276](http://arxiv.org/abs/2302.10276)

    本文提出了一项挑战性任务——视觉情感解读任务(VEIT)，旨在通过AI对创作者的心理状态进行合理的解释。为此，本文提供了一个多模态数据集，该数据集得到了心理学理论的支持和专业的注释。据分析表明，该数据集不仅能够支持VEIT，而且相对于其他字幕数据集更具挑战性。

    

    在精神分析领域中，通过视觉创作生成对个体心理状态的解释正面临着很大的需求。现有的计算机视觉研究主要包括情绪分类和影响标注两个任务，难以满足心理解释的需求。为了满足精神分析的需求，本文提出一项挑战性任务——视觉情感解读任务(VEIT)。VEIT要求人工智能通过视觉创作生成合理的创作者心理状态的解释。为支持该任务，我们提出了一个多模态数据集，称为Sandplay Interpretation Dataset (SpyIn)，该数据集得到了心理学理论的支持和专业的注释。数据集分析表明，SpyIn不仅能够支持VEIT，而且相对于其他字幕数据集更具挑战性。基于SpyIn，我们进行了几项图像生成任务的实验。

    In psychoanalysis, generating interpretations to one's psychological state through visual creations is facing significant demands. The two main tasks of existing studies in the field of computer vision, sentiment/emotion classification and affective captioning, can hardly satisfy the requirement of psychological interpreting. To meet the demands for psychoanalysis, we introduce a challenging task, \textbf{V}isual \textbf{E}motion \textbf{I}nterpretation \textbf{T}ask (VEIT). VEIT requires AI to generate reasonable interpretations of creator's psychological state through visual creations. To support the task, we present a multimodal dataset termed SpyIn (\textbf{S}and\textbf{p}la\textbf{y} \textbf{In}terpretation Dataset), which is psychological theory supported and professional annotated. Dataset analysis illustrates that SpyIn is not only able to support VEIT, but also more challenging compared with other captioning datasets. Building on SpyIn, we conduct experiments of several image 
    
[^69]: 基于张量分解的知识图谱补全在疾病基因预测中的应用

    Knowledge Graph Completion based on Tensor Decomposition for Disease Gene Prediction. (arXiv:2302.09335v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.09335](http://arxiv.org/abs/2302.09335)

    本文通过交互式张量分解构建了一个以疾病和基因为中心的生物知识图谱，并开发了一种端到端的疾病基因预测知识图谱补全模型 KDGene。实验结果表明，KDGene明显优于最先进的算法，且对于糖尿病案例的生物学分析也证实了其可行性。

    

    准确鉴定疾病基因一直是解码疾病分子机制的关键之一。目前，大多数方法集中在构建生物网络和利用机器学习，尤其是深度学习来鉴定疾病基因，但忽略了生物知识图谱中实体之间的复杂关系。本文构建了一个以疾病和基因为中心的生物知识图谱，并利用交互式张量分解 (KDGene) 开发了一种端到端的疾病基因预测知识图谱补全模型。KDGene将实体和关系的嵌入引入张量分解的交互模块，可以有效增强生物知识中的信息交互。实验结果表明，KDGene明显优于最先进的算法。此外，对糖尿病案例的综合生物学分析证实了 KDGene 鉴定潜在疾病基因的能力。

    Accurate identification of disease genes has consistently been one of the keys to decoding a disease's molecular mechanism. Most current approaches focus on constructing biological networks and utilizing machine learning, especially, deep learning to identify disease genes, but ignore the complex relations between entities in the biological knowledge graph. In this paper, we construct a biological knowledge graph centered on diseases and genes, and develop an end-to-end Knowledge graph completion model for Disease Gene Prediction using interactional tensor decomposition (called KDGene). KDGene introduces an interaction module between the embeddings of entities and relations to tensor decomposition, which can effectively enhance the information interaction in biological knowledge. Experimental results show that KDGene significantly outperforms state-of-the-art algorithms. Furthermore, the comprehensive biological analysis of the case of diabetes mellitus confirms KDGene's ability for id
    
[^70]: 无监督评估外部分布检测：基于数据的视角

    Unsupervised Evaluation of Out-of-distribution Detection: A Data-centric Perspective. (arXiv:2302.08287v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.08287](http://arxiv.org/abs/2302.08287)

    本文提出了一种无监督评估外部分布检测方法的问题，并提出了一种基于Gscore的有效性指标，这对于没有真实标签的测试时可作为实用的评估方法。

    

    外部分布检测需要确定测试样本属于内部分布还是外部分布，但现实中我们并不总是拥有这些测试数据的真实标签。本文首次提出了一种无监督评估外部分布检测方法的问题，并提出了三种计算Gscore的方法，作为衡量无监督测试的性能指标。我们还引入了一个名为Gbench的新基准测试数据集，该数据集包含200个真实世界的外部分布数据集，用于训练和评估我们的方法。通过实验，我们发现Gscore与外部分布检测性能之间存在较强的定量相关性。大量实验证明，与AUROC等监督评估方法相比，我们的Gscore的结果一致且具有竞争力，并且可以作为一个实用的有效评估方法用于无监督环境下的外部分布检测。

    Out-of-distribution (OOD) detection methods assume that they have test ground truths, i.e., whether individual test samples are in-distribution (IND) or OOD. However, in the real world, we do not always have such ground truths, and thus do not know which sample is correctly detected and cannot compute the metric like AUROC to evaluate the performance of different OOD detection methods. In this paper, we are the first to introduce the unsupervised evaluation problem in OOD detection, which aims to evaluate OOD detection methods in real-world changing environments without OOD labels. We propose three methods to compute Gscore as an unsupervised indicator of OOD detection performance. We further introduce a new benchmark Gbench, which has 200 real-world OOD datasets of various label spaces to train and evaluate our method. Through experiments, we find a strong quantitative correlation betwwen Gscore and the OOD detection performance. Extensive experiments demonstrate that our Gscore achie
    
[^71]: AI聊天助手可改善关于分裂性话题的对话

    AI Chat Assistants can Improve Conversations about Divisive Topics. (arXiv:2302.07268v4 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2302.07268](http://arxiv.org/abs/2302.07268)

    该论文介绍了一个大型实验的结果，证明了使用人工智能工具可以改善关于分裂性话题的在线对话。他们通过使用一种大型语言模型实时提供基于证据的建议，帮助人们在对话中感受到理解的感觉。

    

    人类在线交流数量正在迅速增长。但是，社交媒体平台、消息应用程序和其他数字论坛上的基于文本的互动可能会产生分裂和冲突。这种有毒性增加了极化的程度，并且重要的是，侵蚀了多元化社会发展解决影响所有人的复杂社会问题的能力。学者和民间社会组织推动干预措施，使面对面的对话不那么具有分裂性或更具生产力，但将这些努力扩展至在线发生的许多话语是极具挑战性的。我们展示了一个大规模实验的结果，该实验证明了人工智能工具如何改善关于分裂性话题的在线对话。具体而言，我们采用大型语言模型实时提供基于证据的建议，以改善参与者在对话中感受到理解的感觉。我们发现这些建议确实可以帮助人们改善对话质量。

    A rapidly increasing amount of human conversation occurs online. But divisiveness and conflict can fester in text-based interactions on social media platforms, in messaging apps, and on other digital forums. Such toxicity increases polarization and, importantly, corrodes the capacity of diverse societies to develop efficient solutions to complex social problems that impact everyone. Scholars and civil society groups promote interventions that can make interpersonal conversations less divisive or more productive in offline settings, but scaling these efforts to the amount of discourse that occurs online is extremely challenging. We present results of a large-scale experiment that demonstrates how online conversations about divisive topics can be improved with artificial intelligence tools. Specifically, we employ a large language model to make real-time, evidence-based recommendations intended to improve participants' perception of feeling understood in conversations. We find that these
    
[^72]: 采用以问题为中心的认知表示改进深度序列知识追踪模型的可解释性

    Improving Interpretability of Deep Sequential Knowledge Tracing Models with Question-centric Cognitive Representations. (arXiv:2302.06885v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.06885](http://arxiv.org/abs/2302.06885)

    本文介绍了一种名为 QIKT 的基于问题的可解释知识追踪模型，通过采用以问题为中心的认知表示方法，明确地模拟学生的知识状态变化，解决了现有模型中同质化问题的假设对实际情况不准确以及解释预测结果具有挑战性的问题。

    

    知识追踪是预测学生未来表现的关键技术，通过观察他们的历史学习过程来实现。由于深度神经网络强大的表示能力，使用深度学习技术来解决知识追踪问题已取得了显著的进展。然而，现有方法中的大部分都依赖于“同质化问题”的假设，即如果问题具有相同的知识组件集，则它们的贡献是等价的。遗憾的是，这种假设在实际教育场景中是不准确的。此外，从现有的基于深度学习的知识追踪模型中解释预测结果非常具有挑战性。因此，在本文中，我们提出了一种名为QIKT的基于问题的可解释知识追踪模型来应对以上挑战。所提出的QIKT方法采用基于问题的认知表示，明确地模拟学生的知识状态变化，并从问题-答案交互中联合学习问题敏感的认知表示。

    Knowledge tracing (KT) is a crucial technique to predict students' future performance by observing their historical learning processes. Due to the powerful representation ability of deep neural networks, remarkable progress has been made by using deep learning techniques to solve the KT problem. The majority of existing approaches rely on the \emph{homogeneous question} assumption that questions have equivalent contributions if they share the same set of knowledge components. Unfortunately, this assumption is inaccurate in real-world educational scenarios. Furthermore, it is very challenging to interpret the prediction results from the existing deep learning based KT models. Therefore, in this paper, we present QIKT, a question-centric interpretable KT model to address the above challenges. The proposed QIKT approach explicitly models students' knowledge state variations at a fine-grained level with question-sensitive cognitive representations that are jointly learned from a question-c
    
[^73]: 零样本学习用于需求分类：一项探索性研究

    Zero-Shot Learning for Requirements Classification: An Exploratory Study. (arXiv:2302.04723v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2302.04723](http://arxiv.org/abs/2302.04723)

    本文提出一种使用零样本学习方法进行需求分类的方法，避免使用大量标记数据的限制。

    

    需求工程研究人员一直在尝试使用机器学习和深度学习方法来完成一系列RE任务，例如需求分类、需求追踪、歧义检测和建模。然而，今天大部分的ML / DL方法都基于监督学习技术，这意味着它们需要使用大量的任务特定标记训练数据进行训练。这个限制对RE研究人员提出了巨大挑战，因为标记数据的缺乏使得他们难以充分利用先进的ML / DL技术的优势。本文旨在解决这个问题，展示如何使用零样本学习方法进行需求分类，而无需使用任何标记的训练数据。我们着重于分类任务，因为许多RE任务可以被框定为分类问题。本研究中使用的ZSL方法采用上下文单词嵌入和基于变压器的语言模型。

    Context: Requirements engineering researchers have been experimenting with machine learning and deep learning approaches for a range of RE tasks, such as requirements classification, requirements tracing, ambiguity detection, and modelling. However, most of today's ML/DL approaches are based on supervised learning techniques, meaning that they need to be trained using a large amount of task-specific labelled training data. This constraint poses an enormous challenge to RE researchers, as the lack of labelled data makes it difficult for them to fully exploit the benefit of advanced ML/DL technologies. Objective: This paper addresses this problem by showing how a zero-shot learning approach can be used for requirements classification without using any labelled training data. We focus on the classification task because many RE tasks can be framed as classification problems. Method: The ZSL approach used in our study employs contextual word-embeddings and transformer-based language models.
    
[^74]: 几乎没有标签的文本分类的元学习连对网络

    Meta-Learning Siamese Network for Few-Shot Text Classification. (arXiv:2302.03507v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.03507](http://arxiv.org/abs/2302.03507)

    本文提出了Meta-SN，一种基于元学习的连对网络，用于解决几乎没有标签的文本分类问题。Meta-SN通过使用外部知识来编码类别标签的低维嵌入向量，并提出新的采样策略，克服了信念网络算法中的一些问题，提高了少样本学习的准确性。

    

    几乎没有标签的文本分类问题可以通过少量样本训练数据来解决，其中元学习方法（例如PROTO）已经被证明是有效的。本文提出了一种元学习连对网络，Meta-SN，来解决PROTO方法中存在的三个问题：（1）忽略了计算原型向量时采样支持集的随机性；（2）忽略了标记样本的重要性；（3）以纯随机方式构建元任务。Meta-SN利用外部知识（例如类别名称和描述文本）来编码类别标签的低维嵌入向量，而不是从采样支持集中计算原型向量。此外，Meta-SN提出了一种新的采样策略，即增加了对难以分类样本的采样概率。在基准数据集上进行了大量的实验，结果表明Meta-SN优于包括PROTO在内的多种最先进的少样本学习方法。

    Few-shot learning has been used to tackle the problem of label scarcity in text classification, of which meta-learning based methods have shown to be effective, such as the prototypical networks (PROTO). Despite the success of PROTO, there still exist three main problems: (1) ignore the randomness of the sampled support sets when computing prototype vectors; (2) disregard the importance of labeled samples; (3) construct meta-tasks in a purely random manner. In this paper, we propose a Meta-Learning Siamese Network, namely, Meta-SN, to address these issues. Specifically, instead of computing prototype vectors from the sampled support sets, Meta-SN utilizes external knowledge (e.g. class names and descriptive texts) for class labels, which is encoded as the low-dimensional embeddings of prototype vectors. In addition, Meta-SN presents a novel sampling strategy for constructing meta-tasks, which gives higher sampling probabilities to hard-to-classify samples. Extensive experiments are con
    
[^75]: 什么会减弱编辑能力？面向特定领域的混合细化方法用于改善GAN反演

    What Decreases Editing Capability? Domain-Specific Hybrid Refinement for Improved GAN Inversion. (arXiv:2301.12141v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.12141](http://arxiv.org/abs/2301.12141)

    这篇论文提出了面向特定领域的混合细化方法，用于改善GAN反演结果中的编辑能力减弱问题。该方法通过将图像分为域内和域外部分，并对这两部分进行权重调节细化，以保持域内区域的编辑能力并提高保真度。

    

    最近，反演方法关注生成器中的额外高比率信息（例如，权重或中间特征），以优化从嵌入式潜在代码进行反演和编辑的结果。虽然这些技术在重建方面取得了合理的改进，但它们会减弱编辑能力，尤其是在复杂图像（例如包含遮挡，详细背景和伪影的图像）上。关键在于精细化反演结果，避免编辑能力降级。为了解决这个问题，我们引入了面向特定领域的混合细化（DHR），利用了两种主流细化技术的优点和缺点，以保持编辑能力和保证保真度的提高。具体来说，我们首先提出了面向特定领域的分割方法，将图像分成两个部分：域内和域外部分。细化过程旨在保持域内区域的可编辑性并提高两个域的保真度。我们通过权重调节来细化这两个部分。

    Recently, inversion methods have focused on additional high-rate information in the generator (e.g., weights or intermediate features) to refine inversion and editing results from embedded latent codes. Although these techniques gain reasonable improvement in reconstruction, they decrease editing capability, especially on complex images (e.g., containing occlusions, detailed backgrounds, and artifacts). A vital crux is refining inversion results, avoiding editing capability degradation. To tackle this problem, we introduce Domain-Specific Hybrid Refinement (DHR), which draws on the advantages and disadvantages of two mainstream refinement techniques to maintain editing ability with fidelity improvement. Specifically, we first propose Domain-Specific Segmentation to segment images into two parts: in-domain and out-of-domain parts. The refinement process aims to maintain the editability for in-domain areas and improve two domains' fidelity. We refine these two parts by weight modulation 
    
[^76]: FedPH: 隐私增强型异构联邦学习

    FedPH: Privacy-enhanced Heterogeneous Federated Learning. (arXiv:2301.11705v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11705](http://arxiv.org/abs/2301.11705)

    该论文提出了一种利用预训练模型作为本地模型的骨干，共享嵌入类向量来增强本地模型性能的异构联邦学习方法，并采用隐私保护的混合方法来保护隐私。

    

    联邦学习是一种分布式机器学习环境，允许客户端在不共享私有数据的情况下进行协作学习，通过交换参数来实现。然而，客户端之间的数据分布和计算资源差异使得相关研究变得困难。为了解决这些异构问题，我们提出了一种新的联邦学习方法。我们的方法利用预训练模型作为本地模型的骨干，完全连接的层构成头部。骨干提取头部特征，类的嵌入向量在客户端之间共享，以改善头部并增强本地模型的性能。通过共享类的嵌入向量而不是梯度参数，客户端可以更好地适应私有数据，服务器和客户端之间的通信更加有效。为了保护隐私，我们提出了一种隐私保护的混合方法，向类的嵌入向量添加噪声。

    Federated Learning is a distributed machine-learning environment that allows clients to learn collaboratively without sharing private data. This is accomplished by exchanging parameters. However, the differences in data distributions and computing resources among clients make related studies difficult. To address these heterogeneous problems, we propose a novel Federated Learning method. Our method utilizes a pre-trained model as the backbone of the local model, with fully connected layers comprising the head. The backbone extracts features for the head, and the embedding vector of classes is shared between clients to improve the head and enhance the performance of the local model. By sharing the embedding vector of classes instead of gradient-based parameters, clients can better adapt to private data, and communication between the server and clients is more effective. To protect privacy, we propose a privacy-preserving hybrid method that adds noise to the embedding vector of classes. 
    
[^77]: 用于流式序列标记的高效编码器。

    Efficient Encoders for Streaming Sequence Tagging. (arXiv:2301.09244v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.09244](http://arxiv.org/abs/2301.09244)

    本研究提出了一种名为HEAR的混合编码器与自适应重启（HEAR），解决了在流式输入中使用双向编码器的不必要浮点操作和不必要标签翻转的问题，同时提高了流式输入上的标记性能。

    

    在增量流输入（例如转录语音）中，为了对流式序列标记应用最先进的双向编码器，需要为每个新标记从头开始对每个标记进行编码。先前计算的不可重用性导致了更高数量的浮点操作（或FLOP）和更高数量的不必要标签翻转。增加的FLOP会导致更高的挂钟时间，而增加的标签翻转会导致流式性能更差。在这项工作中，我们提出了一种名为HEAR的混合编码器与自适应重启（HEAR），它解决了这些问题，同时保持了双向编码器在离线（或完整）输入上的表现，同时提高了流输入（或不完整）上的性能。HEAR具有混合单向 - 双向编码器架构来执行序列标记，以及自适应重启模块（ARM）以有选择地引导编码器的双向部分的重新启动。在四个序列标记数据集上，我们表明，HEAR显著地提高了流式表现，同时保持了离线性能。

    A naive application of state-of-the-art bidirectional encoders for streaming sequence tagging would require encoding each token from scratch for each new token in an incremental streaming input (like transcribed speech). The lack of re-usability of previous computation leads to a higher number of Floating Point Operations (or FLOPs) and higher number of unnecessary label flips. Increased FLOPs consequently lead to higher wall-clock time and increased label flipping leads to poorer streaming performance. In this work, we present a Hybrid Encoder with Adaptive Restart (HEAR) that addresses these issues while maintaining the performance of bidirectional encoders over the offline (or complete) inputs while improving performance on streaming (or incomplete) inputs. HEAR has a Hybrid unidirectional-bidirectional encoder architecture to perform sequence tagging, along with an Adaptive Restart Module (ARM) to selectively guide the restart of bidirectional portion of the encoder. Across four se
    
[^78]: 基于三分决策的临床医生主观方法用于精神障碍分类

    Classifying Mental-Disorders through Clinicians Subjective Approach based on Three-way Decision. (arXiv:2301.03351v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.03351](http://arxiv.org/abs/2301.03351)

    本文提出了一个基于三分决策框架下的统一模型，用于分析临床医生的主观方法，通过定量和定性分析得出排名列表和权重，并将疾病进行比较分类为三组，该方法可以作为补充工具与手动方法相结合，提高精确性。

    

    在精神诊断中，基于数据驱动的手动方法被用于精神障碍分类，但是它存在一些不可避免的缺陷。本文提出了一个三分决策框架下的统一模型，用于分析临床医生的主观方法，包含定量分析、定量分析以及基于评估的分析。基于临床医生最大程度的假设，定性和定量研究得出了排名列表和一组数值权重。我们进一步将疾病进行比较分类为三组，采用三分基于评估的模型，旨在理解和更清晰地描述这些结果。该方法可以作为补充工具与手动方法相结合，提高精确性。

    In psychiatric diagnosis, a contemporary data-driven, manual-based method for mental disorders classification is the most popular technique; however, it has several inevitable flaws. Using the three-way decision as a framework, we propose a unified model that stands for clinicians' subjective approach (CSA) analysis consisting of three parts: quantitative analysis, quantitative analysis, and evaluation-based analysis. A ranking list and a set of numerical weights based on illness magnitude levels according to the clinician's greatest degree of assumptions are the findings of the qualitative and quantitative investigation. We further create a comparative classification of illnesses into three groups with varying important levels; a three-way evaluation-based model is utilized in this study for the aim of understanding and portraying these results in a more clear way. This proposed method might be integrated with the manual-based process as a complementary tool to improve precision while
    
[^79]: 自然语言处理中人类导向的公平分类

    Human-Guided Fair Classification for Natural Language Processing. (arXiv:2212.10154v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10154](http://arxiv.org/abs/2212.10154)

    本文提出了一种新方法，通过自动生成表达丰富的候选句子对并结合群众外包的成对人类判断，训练一个映射语义相似性到统计代理的个体公平性的模型，用于弥合人类直觉和公平分类规范之间的差距。该方法在表现能力、与人类直觉的一致性和两个基准数据集的分类准确性方面优于先前的方法。

    

    文本分类器在简历筛选和内容审核等高风险任务中具有广泛的应用。这些分类器必须是公平的，并通过对敏感属性（如性别或种族）的扰动不变来避免歧视性决策。然而，人类对这些扰动的直觉与捕捉它们的形式相似度规范之间存在差距。尽管现有研究已经开始解决这个问题，但当前的方法基于硬编码单词替换，导致规范的表达能力有限或者无法充分地与人类直觉相一致（例如，在不对称的反事实情况下）。本研究提出了新方法来弥合这一差距，发现具有表现力和直觉公平规范。我们展示了如何利用无监督式转换和GPT-3的零-shot能力自动生成语义上类似但在敏感属性上有所不同的表达丰富的候选句子对。然后，我们采用群众外包获得这些候选人的成对人类判断，并使用它们来训练模型，将语义相似性映射到统计代理的个体公平性。我们的实验表明，我们的方法在表现能力、与人类直觉的一致性和两个基准数据集的分类准确性方面优于先前的方法。

    Text classifiers have promising applications in high-stake tasks such as resume screening and content moderation. These classifiers must be fair and avoid discriminatory decisions by being invariant to perturbations of sensitive attributes such as gender or ethnicity. However, there is a gap between human intuition about these perturbations and the formal similarity specifications capturing them. While existing research has started to address this gap, current methods are based on hardcoded word replacements, resulting in specifications with limited expressivity or ones that fail to fully align with human intuition (e.g., in cases of asymmetric counterfactuals). This work proposes novel methods for bridging this gap by discovering expressive and intuitive individual fairness specifications. We show how to leverage unsupervised style transfer and GPT-3's zero-shot capabilities to automatically generate expressive candidate pairs of semantically similar sentences that differ along sensit
    
[^80]: 多分辨率在线确定性退火：一种分层和渐进学习架构

    Multi-Resolution Online Deterministic Annealing: A Hierarchical and Progressive Learning Architecture. (arXiv:2212.08189v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.08189](http://arxiv.org/abs/2212.08189)

    本文提出了一种基于逐渐增加子集数量的分区序列的通用的分层学习结构，并使用无梯度随机逼近更新进行在线解决优化问题的方法，可以定义函数逼近问题并使用双时间尺度随机逼近算法的理论解决，模拟了一种退火过程。

    

    随着时间和计算资源的限制，逐步逼近基于数据的优化问题的解决方案的分层学习算法对于决策系统至关重要。本研究提出了一种通用的分层学习结构，基于可能的多分辨率数据空间的渐进分区。最优分区通过解决一系列优化子问题逐步逼近，生成具有逐渐增加的子集数量的分区序列。我们展示对每个优化问题的解可以使用无梯度随机逼近更新进行在线估计。因此，可以在分区的每个子集中定义函数逼近问题，并使用双时间尺度随机逼近算法的理论解决。这模拟了一种退火过程，并定义了一种强大且可解释的启发式方法，逐步增加复杂性。

    Hierarchical learning algorithms that gradually approximate a solution to a data-driven optimization problem are essential to decision-making systems, especially under limitations on time and computational resources. In this study, we introduce a general-purpose hierarchical learning architecture that is based on the progressive partitioning of a possibly multi-resolution data space. The optimal partition is gradually approximated by solving a sequence of optimization sub-problems that yield a sequence of partitions with increasing number of subsets. We show that the solution of each optimization problem can be estimated online using gradient-free stochastic approximation updates. As a consequence, a function approximation problem can be defined within each subset of the partition and solved using the theory of two-timescale stochastic approximation algorithms. This simulates an annealing process and defines a robust and interpretable heuristic method to gradually increase the complexi
    
[^81]: 关于归一化流在成像逆问题中的鲁棒性

    On the Robustness of Normalizing Flows for Inverse Problems in Imaging. (arXiv:2212.04319v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.04319](http://arxiv.org/abs/2212.04319)

    本文研究了在成像逆问题中使用条件归一化流时出现的严重伪像的问题，发现其原因是由于超出分布范围的条件输入导致条件仿射耦合层“爆炸反演”，并提出相应条件以避免这个问题。

    

    条件归一化流可以生成各种图像样本以解决成像逆问题。大多数用于成像逆问题的归一化流采用可变换仿射耦合层，可以快速生成各种图像，但偶尔会观察到意外的严重伪像。本文通过研究这些伪像的来源并提出避免它们的条件来解决这个关键问题。我们首先通过经验和理论揭示了这些问题是由于某些超出分布范围的条件输入中的条件仿射耦合层“爆炸反演”所造成的。然后，我们进一步验证，在成像逆问题中，导致像素错误伪像的概率与以Mahalanobis距离为基础的逆问题的异常样本评分高度相关。最后，在我们的调查基础上，我们提出了一条注释以避免“爆炸反演”，然后基于此，我们建议一种简单的解决方法，用其他可变换仿射耦合层替换某些耦合层。

    Conditional normalizing flows can generate diverse image samples for solving inverse problems. Most normalizing flows for inverse problems in imaging employ the conditional affine coupling layer that can generate diverse images quickly. However, unintended severe artifacts are occasionally observed in the output of them. In this work, we address this critical issue by investigating the origins of these artifacts and proposing the conditions to avoid them. First of all, we empirically and theoretically reveal that these problems are caused by "exploding inverse" in the conditional affine coupling layer for certain out-of-distribution (OOD) conditional inputs. Then, we further validated that the probability of causing erroneous artifacts in pixels is highly correlated with a Mahalanobis distance-based OOD score for inverse problems in imaging. Lastly, based on our investigations, we propose a remark to avoid exploding inverse and then based on it, we suggest a simple remedy that substitu
    
[^82]: 深度孵化: 分而治之地训练大型模型

    Deep Incubation: Training Large Models by Divide-and-Conquering. (arXiv:2212.04129v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.04129](http://arxiv.org/abs/2212.04129)

    本文提出了一种称为深度孵化的训练大型模型的新方法，通过将大型模型分成较小的子模块进行训练并无缝地组装起来，从而实现了大型模型的高效、有效训练。

    

    近年来，大型深度学习模型取得了显著成功。然而，由于高计算成本、缓慢的收敛速度和过度拟合等问题，训练这些模型仍然具有挑战性。本文提出了一种称为深度孵化的新方法，通过将大型模型分成较小的子模块进行训练并无缝地组装起来，从而实现了大型模型的高效、有效训练。实现这个想法的一个关键挑战是确保独立训练的子模块的兼容性。为了解决这个问题，我们首先介绍了一个全局的共享元模型，它被用来隐式地将所有模块链接在一起，并且可以设计为一个具有可忽略计算开销的极小网络。然后我们提出了一个模块孵化算法，它训练每个子模块来替换元模型的相应部分并完成给定的学习任务。尽管简单，我们的方法有效地提高了大型模型的训练效率和效果。

    Recent years have witnessed a remarkable success of large deep learning models. However, training these models is challenging due to high computational costs, painfully slow convergence, and overfitting issues. In this paper, we present Deep Incubation, a novel approach that enables the efficient and effective training of large models by dividing them into smaller sub-modules that can be trained separately and assembled seamlessly. A key challenge for implementing this idea is to ensure the compatibility of the independently trained sub-modules. To address this issue, we first introduce a global, shared meta model, which is leveraged to implicitly link all the modules together, and can be designed as an extremely small network with negligible computational overhead. Then we propose a module incubation algorithm, which trains each sub-module to replace the corresponding component of the meta model and accomplish a given learning task. Despite the simplicity, our approach effectively enc
    
[^83]: 从观测、有偏和随机数据中学习边界反事实推断

    Learning to Bound Counterfactual Inference from Observational, Biased and Randomised Data. (arXiv:2212.02932v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.02932](http://arxiv.org/abs/2212.02932)

    本文提出了从多个可能有偏见的观测和干预研究的数据集中计算结构性因果模型中的反事实的方法，并通过图形转换解决了通用的多个数据集的问题。实验证明了该方法的效果和准确性，同时也提示整合异构数据以获得信息丰富的边界的好处。

    

    我们解决了将来自多个可能有偏见的观测和干预研究的数据集集成起来，最终计算结构性因果模型中的反事实的问题。我们从具有选择偏差的单个观测数据集开始。我们证明了可用数据的似然函数没有局部最大值。这使我们能够使用因果期望最大化方案计算部分可识别反事实查询的近似边界，这是本文的重点。然后我们展示了如何通过图形变换将通用的多个数据集（无论是干预还是观测数据，有偏或无偏）映射到前者从而解决同样的问题。系统的数字实验和对姑息治疗的案例研究展示了我们方法的效果和准确性，同时也提示在部分可识别性的情况下，整合异构数据以获得信息丰富的边界的好处。

    We address the problem of integrating data from multiple, possibly biased, observational and interventional studies, to eventually compute counterfactuals in structural causal models. We start from the case of a single observational dataset affected by a selection bias. We show that the likelihood of the available data has no local maxima. This enables us to use the causal expectation-maximisation scheme to compute approximate bounds for partially identifiable counterfactual queries, which are the focus of this paper. We then show how the same approach can solve the general case of multiple datasets, no matter whether interventional or observational, biased or unbiased, by remapping it into the former one via graphical transformations. Systematic numerical experiments and a case study on palliative care show the effectiveness and accuracy of our approach, while hinting at the benefits of integrating heterogeneous data to get informative bounds in case of partial identifiability.
    
[^84]: 超越对象识别：面向对象概念学习的新基准

    Beyond Object Recognition: A New Benchmark towards Object Concept Learning. (arXiv:2212.02710v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.02710](http://arxiv.org/abs/2212.02710)

    本文提出了一个挑战性的 Object Concept Learning (OCL) 任务，涉及对象属性、作用及其因果关系。作者构建了密集注释的知识库以支持 OCL，提出了 Object Concept Reasoning Network (OCRN) 作为基线，提升了对象认知的发展。

    

    理解对象是人工智能的核心，特别是对于具有体验的人工智能而言。虽然深度学习在对象识别方面表现出色，但当前机器仍然难以学习更高层次的知识，例如对象具有哪些属性，以及我们能够使用对象做什么。在本文中，我们提出了一项具有挑战性的 Object Concept Learning (OCL) 任务，以推动对象理解的发展。它要求机器推理出对象的作用，并同时给出原因：是哪些属性使得一个对象具有这些作用。为了支持 OCL，我们构建了一个密集注释的知识库，包括三个层次的对象概念（类别、属性、作用），以及三个层次的因果关系。通过分析 OCL 的因果结构，我们提出了一种基线：Object Concept Reasoning Network (OCRN)。它利用因果干预和概念实例化来推断三个层次，遵循它们之间的因果关系。

    Understanding objects is a central building block of artificial intelligence, especially for embodied AI. Even though object recognition excels with deep learning, current machines still struggle to learn higher-level knowledge, e.g., what attributes an object has, and what can we do with an object. In this work, we propose a challenging Object Concept Learning (OCL) task to push the envelope of object understanding. It requires machines to reason out object affordances and simultaneously give the reason: what attributes make an object possesses these affordances. To support OCL, we build a densely annotated knowledge base including extensive labels for three levels of object concept (category, attribute, affordance), and the causal relations of three levels. By analyzing the causal structure of OCL, we present a baseline, Object Concept Reasoning Network (OCRN). It leverages causal intervention and concept instantiation to infer the three levels following their causal relations. In ex
    
[^85]: 带有基于模型先验的一次性隐式动画化头像制作方法

    One-shot Implicit Animatable Avatars with Model-based Priors. (arXiv:2212.02469v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.02469](http://arxiv.org/abs/2212.02469)

    本文提出了ELICIT，一种从单张图片学习人类特定神经辐射场的方法，同时利用3D几何先验和视觉语义先验实现了一次性数据高效的逼真可动3D人体的创建。

    

    现有的创建人类头像的神经渲染方法通常要么需要稠密输入信号（如视频或多视角图像），要么利用从大规模特定3D人体数据集中学到的先验，使得可以使用稀疏视角输入进行重建。大多数这些方法在仅有一张图像时无法实现逼真重建。为了实现数据高效的逼真可动3D人体的创建，我们提出了ELICIT，这是一种从一张图片学习人体特定神经辐射场的新方法。受到人类可以轻松估计身体几何形状并从一张图片中想象造型完整的衣柜的启示，我们在ELICIT中利用了两个先验：3D几何先验和视觉语义先验。具体来说，ELICIT利用一个蒙皮顶点模板模型（即SMPL）的3D身体形状几何先验，并通过基于CLIP的预训练模型实现了视觉服装语义先验。这两个先验均用于从单个图像进行逼真的可动3D重建。

    Existing neural rendering methods for creating human avatars typically either require dense input signals such as video or multi-view images, or leverage a learned prior from large-scale specific 3D human datasets such that reconstruction can be performed with sparse-view inputs. Most of these methods fail to achieve realistic reconstruction when only a single image is available. To enable the data-efficient creation of realistic animatable 3D humans, we propose ELICIT, a novel method for learning human-specific neural radiance fields from a single image. Inspired by the fact that humans can effortlessly estimate the body geometry and imagine full-body clothing from a single image, we leverage two priors in ELICIT: 3D geometry prior and visual semantic prior. Specifically, ELICIT utilizes the 3D body shape geometry prior from a skinned vertex-based template model (i.e., SMPL) and implements the visual clothing semantic prior with the CLIP-based pre-trained models. Both priors are used 
    
[^86]: 针对域泛化的直接影响风险最小化

    Direct-Effect Risk Minimization for Domain Generalization. (arXiv:2211.14594v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.14594](http://arxiv.org/abs/2211.14594)

    本文提出了一种针对域泛化的直接影响风险最小化算法，通过引入因果推断中的直接和间接影响概念解决了相关性转移问题。该算法与现有域泛化算法具有可比性。

    

    本文研究了域外推 generalization 中属性虚假相关性在训练和测试域间变化的问题，即相关性转移问题，该问题对机器学习的可靠性造成了影响。我们引入了因果推断中的直接和间接影响概念来解决域泛化问题。我们认为能够学习到直接影响的模型可以使最坏情况下的风险最小化。我们的算法分为两个阶段：第一阶段，我们通过最小化使用表示和类标签预测域标签的错误来学习间接影响表示；第二阶段，我们通过将训练和验证阶段中具有相似间接影响表示但标签不同的数据相匹配来消除在第一阶段中学习到的间接影响。我们的方法证明了其可与现有的域泛化算法相比较。

    We study the problem of out-of-distribution (o.o.d.) generalization where spurious correlations of attributes vary across training and test domains. This is known as the problem of correlation shift and has posed concerns on the reliability of machine learning. In this work, we introduce the concepts of direct and indirect effects from causal inference to the domain generalization problem. We argue that models that learn direct effects minimize the worst-case risk across correlation-shifted domains. To eliminate the indirect effects, our algorithm consists of two stages: in the first stage, we learn an indirect-effect representation by minimizing the prediction error of domain labels using the representation and the class labels; in the second stage, we remove the indirect effects learned in the first stage by matching each data with another data of similar indirect-effect representation but of different class labels in the training and validation phase. Our approach is shown to be com
    
[^87]: 插入后门元素的文本编码器对文本生成图像的影响

    Rickrolling the Artist: Injecting Backdoors into Text Encoders for Text-to-Image Synthesis. (arXiv:2211.02408v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.02408](http://arxiv.org/abs/2211.02408)

    本文证明了文本生成图像模型中使用的文本编码器存在重大的篡改风险，并提出了一种基于反向门攻击的方法，可以插入一个单一字符触发器进提示中，从而触发模型生成具有预定义属性的图像或遵循隐藏的、潜在的恶意描述的图像。

    

    尽管文本生成图像技术在研究者和公众中越来越受欢迎，但这些模型的安全性一直被忽视。许多文本生成图像模型依赖于外部来源的预训练文本编码器，并且它们的用户相信检索到的模型会像承诺的那样运行。不幸的是，这可能不是这种情况。我们引入了反向门攻击文本引导的生成模型，并证明它们的文本编码器构成了重大的篡改风险。我们的攻击只是轻微地改变了编码器，使得对于带有干净提示的图像生成没有可疑的模型行为。然后，通过将一个单一字符触发器插入提示中，例如一个非拉丁字符或表情符号，攻击者就可以触发模型生成具有预定义属性的图像或遵循隐藏的、潜在的恶意描述的图像。我们在Stable Diffusion和highligh上经验性地证明了我们攻击的高效性。

    While text-to-image synthesis currently enjoys great popularity among researchers and the general public, the security of these models has been neglected so far. Many text-guided image generation models rely on pre-trained text encoders from external sources, and their users trust that the retrieved models will behave as promised. Unfortunately, this might not be the case. We introduce backdoor attacks against text-guided generative models and demonstrate that their text encoders pose a major tampering risk. Our attacks only slightly alter an encoder so that no suspicious model behavior is apparent for image generations with clean prompts. By then inserting a single character trigger into the prompt, e.g., a non-Latin character or emoji, the adversary can trigger the model to either generate images with pre-defined attributes or images following a hidden, potentially malicious description. We empirically demonstrate the high effectiveness of our attacks on Stable Diffusion and highligh
    
[^88]: 自组织的空间流体自适应采样

    Space-fluid Adaptive Sampling by Self-Organisation. (arXiv:2210.17505v2 [cs.DC] UPDATED)

    [http://arxiv.org/abs/2210.17505](http://arxiv.org/abs/2210.17505)

    本文提出了一种自组织的空间流体自适应采样方法来估计分布式传感数据或计算结果，其动态划分空间的方法具有优越的性能。

    

    协调系统中的一个重要任务是管理（估计、预测或控制）随空间变化的信号，例如分布式传感数据或计算结果。本文提出了一种基于竞争和生长/缩小的动态划分空间方法，协同自适应采样来估计空间现象。我们提供了一个基于场的协调框架中的自适应采样算法，并证明它是自稳定的。我们的模拟结果表明，在估计复杂函数使用高斯过程和跟踪传感器网络中的时空现象方面具有优越的性能。

    A recurrent task in coordinated systems is managing (estimating, predicting, or controlling) signals that vary in space, such as distributed sensed data or computation outcomes. Especially in large-scale settings, the problem can be addressed through decentralised and situated computing systems: nodes can locally sense, process, and act upon signals, and coordinate with neighbours to implement collective strategies. Accordingly, in this work we devise distributed coordination strategies for the estimation of a spatial phenomenon through collaborative adaptive sampling. Our design is based on the idea of dynamically partitioning space into regions that compete and grow/shrink to provide accurate aggregate sampling. Such regions hence define a sort of virtualised space that is "fluid", since its structure adapts in response to pressure forces exerted by the underlying phenomenon. We provide an adaptive sampling algorithm in the field-based coordination framework, and prove it is self-sta
    
[^89]: 学习最小违反连续控制以实现不可行线性时态逻辑规范

    Learning Minimally-Violating Continuous Control for Infeasible Linear Temporal Logic Specifications. (arXiv:2210.01162v4 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2210.01162](http://arxiv.org/abs/2210.01162)

    本文提出了一个模型自由框架，使用深度强化学习来实现复杂高级任务的目标驱动导航。通过将先前的多目标DRL问题转化为一个单一目标问题，并使用基于采样的路径规划算法来指导DRL智能体，该方法可以满足不可行的线性时态逻辑任务并尽可能减少违规。

    

    本文研究了连续时间控制综合，以实现线性时态逻辑(LTL)表达的复杂高级任务的目标驱动导航。我们提出了一个模型自由框架，使用深度强化学习(DRL)，其中底层动态系统未知（透明盒子）。与先前的工作不同，本文考虑了给定的LTL规范可能是不可行的情况，因此无法全局完成。我们不修改给定的LTL公式，而是提供了一个通用的DRL方法，以最小违规满足它。为了做到这一点，我们将先前的多目标DRL问题转化为一个单一目标问题，该问题要求同时实现自动机满足和最小违规代价。通过使用基于采样的路径规划算法来指导可能不可行的LTL任务的DRL智能体，所提出的方法减轻了DRL的近视倾向，这在学习可以具有长或无限持续时间的一般LTL任务时经常是一个问题。

    This paper explores continuous-time control synthesis for target-driven navigation to satisfy complex high-level tasks expressed as linear temporal logic (LTL). We propose a model-free framework using deep reinforcement learning (DRL) where the underlying dynamic system is unknown (an opaque box). Unlike prior work, this paper considers scenarios where the given LTL specification might be infeasible and therefore cannot be accomplished globally. Instead of modifying the given LTL formula, we provide a general DRL-based approach to satisfy it with minimal violation. To do this, we transform a previously multi-objective DRL problem, which requires simultaneous automata satisfaction and minimum violation cost, into a single objective. By guiding the DRL agent with a sampling-based path planning algorithm for the potentially infeasible LTL task, the proposed approach mitigates the myopic tendencies of DRL, which are often an issue when learning general LTL tasks that can have long or infin
    
[^90]: 重新审视医学图像分割:极度有限标签下的医学图像分割

    Mine yOur owN Anatomy: Revisiting Medical Image Segmentation with Extremely Limited Labels. (arXiv:2209.13476v4 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2209.13476](http://arxiv.org/abs/2209.13476)

    提出了一种新的医学图像分割方法MOAN，该方法可以在极度有限的标签情况下实现高性能。MOAN由两个互补的流水线组成：协同邻域挖掘和自监督对比学习。实验结果表明，MOAN在Dice评分和其他评估指标方面优于现有最先进方法。

    

    最近，关于对比学习的研究在医学图像分割的背景下仅凭借几个标签取得了卓越的性能。现有方法主要集中在实体区分和不变映射上。然而，它们面临三个常见瓶颈：(1)尾部分布：医学图像数据通常遵循隐含的长尾类分布。盲目利用所有训练像素可能导致数据不平衡问题，并导致性能恶化；(2)一致性：由于不同解剖特征之间的类内变化，分割模型是否学会了有意义且一致的解剖特征仍不清楚；以及(3)多样性：整个数据集内部切片的相关性受到的关注显著较少。这促使我们寻找一个基于数据集本身的策略方法，从不同的解剖视图中发现相似但不同的样本。在本文中，我们介绍了一个新的框架，称为MOAN，用于极度有限标签下的医学图像分割。 MOAN由两个互补的流水线组成：协同邻域挖掘和自监督对比学习。前者提取共同依赖的像素区域，而后者强制网络学习有意义的解剖学表示。实验结果表明，MOAN在Dice评分和其他评估指标方面优于现有最先进方法。

    Recent studies on contrastive learning have achieved remarkable performance solely by leveraging few labels in the context of medical image segmentation. Existing methods mainly focus on instance discrimination and invariant mapping. However, they face three common pitfalls: (1) tailness: medical image data usually follows an implicit long-tail class distribution. Blindly leveraging all pixels in training hence can lead to the data imbalance issues, and cause deteriorated performance; (2) consistency: it remains unclear whether a segmentation model has learned meaningful and yet consistent anatomical features due to the intra-class variations between different anatomical features; and (3) diversity: the intra-slice correlations within the entire dataset have received significantly less attention. This motivates us to seek a principled approach for strategically making use of the dataset itself to discover similar yet distinct samples from different anatomical views. In this paper, we i
    
[^91]: LSAP: 重新思考GAN潜空间中反演的保真度、感知和可编辑性

    LSAP: Rethinking Inversion Fidelity, Perception and Editability in GAN Latent Space. (arXiv:2209.12746v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.12746](http://arxiv.org/abs/2209.12746)

    LSAP通过对潜空间实现对齐解决了反演和编辑结果中保真度、感知和可编辑性的问题，使得在保留重建保真度的前提下具有更好的感知和可编辑性。

    

    随着方法的发展，反演主要分为两个步骤。第一步是图像嵌入，在这个步骤中，编码器或者优化过程嵌入图像以获取相应的潜在码。之后，第二步旨在改善反演和编辑结果，我们称之为结果细化。尽管第二步显著提高了保真度，但感知和可编辑性几乎没有改变，深度依赖于在第一步中获得的反向潜在码。因此，重要的问题是在保留重建保真度的同时获得具有更好感知和可编辑性的潜在码。在这项工作中，我们首先指出这两个特征与反向码与合成分布的对齐（或不对齐）程度有关。然后，我们提出了潜空间对齐反演范例（LSAP），其中包括评估指标和解决此问题的解决方法。具体而言，我们引入了标准化风格空间（$\mathcal{S^N}$）和标准化内容空间（$\mathcal{C^N}$），分别在风格和内容上对齐正向和负向潜在码和合成分布。 LSAP在各种任务中都取得了最先进的结果，例如图像编辑、图像转换和图像合成。此外，我们证明了LSAP具有比以前方法更好的特性，如改进的可编辑性、视觉质量和更少的模式崩塌。

    As the methods evolve, inversion is mainly divided into two steps. The first step is Image Embedding, in which an encoder or optimization process embeds images to get the corresponding latent codes. Afterward, the second step aims to refine the inversion and editing results, which we named Result Refinement. Although the second step significantly improves fidelity, perception and editability are almost unchanged, deeply dependent on inverse latent codes attained in the first step. Therefore, a crucial problem is gaining the latent codes with better perception and editability while retaining the reconstruction fidelity. In this work, we first point out that these two characteristics are related to the degree of alignment (or disalignment) of the inverse codes with the synthetic distribution. Then, we propose Latent Space Alignment Inversion Paradigm (LSAP), which consists of evaluation metric and solution for this problem. Specifically, we introduce Normalized Style Space ($\mathcal{S^N
    
[^92]: 在文本数据上比较特征重要性和规则提取的可解释性

    Comparing Feature Importance and Rule Extraction for Interpretability on Text Data. (arXiv:2207.01420v1 [cs.LG] CROSS LISTED)

    [http://arxiv.org/abs/2207.01420](http://arxiv.org/abs/2207.01420)

    本文比较了文本数据上两类方法：计算每个特征的重要性分数和提取简单逻辑规则，发现在相同模型下产生的解释也不同。我们提出了一种比较解释差异的方法。

    

    复杂的机器学习算法在涉及文本数据的关键任务中越来越常见，这导致了可解释性方法的发展。在局部方法中，出现了两种族群：一种计算每个特征的重要性分数，另一种则提取简单的逻辑规则。在本文中，我们展示了使用不同方法可以导致意外不同的解释，即使应用于那些我们预计会有定性巧合的简单模型上。为了量化这种影响，我们提出一种比较不同方法产生的解释的新方法。

    Complex machine learning algorithms are used more and more often in critical tasks involving text data, leading to the development of interpretability methods. Among local methods, two families have emerged: those computing importance scores for each feature and those extracting simple logical rules. In this paper we show that using different methods can lead to unexpectedly different explanations, even when applied to simple models for which we would expect qualitative coincidence. To quantify this effect, we propose a new approach to compare explanations produced by different methods.
    
[^93]: WaveMix: 一种用于图像分析的资源高效神经网络

    WaveMix: A Resource-efficient Neural Network for Image Analysis. (arXiv:2205.14375v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2205.14375](http://arxiv.org/abs/2205.14375)

    WaveMix是一种资源高效的神经网络结构，可以在多项任务上达到可比或更好的准确率，并且需要更少的参数和GPU RAM，实现时间、成本和能量的节省。

    

    我们提出了WaveMix——一种新颖的神经网络结构，既具有资源效率性，又具有通用性和可扩展性。WaveMix网络在多项任务上达到了可比或更好的准确率，包括Cityscapes中的分割和Places-365、五个EMNIST数据集和iNAT-mini中的分类，并建立了新的基准。令人惊奇的是，与先前的最先进技术相比，WaveMix结构所需的参数更少。此外，当控制参数数量时，WaveMix所需的GPU RAM更少，这意味着节省时间、成本和能量。为了实现这些收益，我们在WaveMix块中使用了多级二维离散小波变换（2D-DWT），它具有以下优点:(1)它基于三种强图像先验条件重新组织空间信息——尺度不变性，位移不变性和边缘的稀疏性,(2) i

    We propose WaveMix -- a novel neural architecture for computer vision that is resource-efficient yet generalizable and scalable. WaveMix networks achieve comparable or better accuracy than the state-of-the-art convolutional neural networks, vision transformers, and token mixers for several tasks, establishing new benchmarks for segmentation on Cityscapes; and for classification on Places-365, five EMNIST datasets, and iNAT-mini. Remarkably, WaveMix architectures require fewer parameters to achieve these benchmarks compared to the previous state-of-the-art. Moreover, when controlled for the number of parameters, WaveMix requires lesser GPU RAM, which translates to savings in time, cost, and energy. To achieve these gains we used multi-level two-dimensional discrete wavelet transform (2D-DWT) in WaveMix blocks, which has the following advantages: (1) It reorganizes spatial information based on three strong image priors -- scale-invariance, shift-invariance, and sparseness of edges, (2) i
    
[^94]: 一片文字海：针对文本数据的 Anchors 深入分析

    A Sea of Words: An In-Depth Analysis of Anchors for Text Data. (arXiv:2205.13789v2 [stat.ML] CROSS LISTED)

    [http://arxiv.org/abs/2205.13789](http://arxiv.org/abs/2205.13789)

    Anchors 是一种后处理的规则性可解释性方法，它可以通过凸显出一个小组词语（锚点）来强调模型的决策，我们首次对 Anchors 进行了理论分析，考虑到寻找最佳锚点是详尽的，并通过 TF-IDF 向量化步骤以及模型层次的显式结果，探究其在不同类别模型中的行为特征。我们还发现，在神经网络中，最高偏导数所对应的词汇可以重新加权用作 Anchors 词汇。

    

    Anchors 是一种基于后处理的基于规则的可解释性方法，该方法旨在解释模型决策并强调一小组词语（锚点），这些词语存在于文档中时，模型输出类似。本文首次对 Anchors 进行了理论分析，考虑到寻找最佳锚点是详尽的。我们将文本分类的算法形式化后，结合不同类别模型的显式结果，探究了 Anchors 的行为特征。我们分别覆盖了基本 if-then 规则和线性分类器这两种模型。我们还利用这项分析，洞见任何可微分分类器的 Anchors 行为特征。对于神经网络，我们经验性地展示了模型对输入的最高偏导数所对应的词语，通过反向文件重新加权，可以作为 Anchors 词语。

    Anchors (Ribeiro et al., 2018) is a post-hoc, rule-based interpretability method. For text data, it proposes to explain a decision by highlighting a small set of words (an anchor) such that the model to explain has similar outputs when they are present in a document. In this paper, we present the first theoretical analysis of Anchors, considering that the search for the best anchor is exhaustive. After formalizing the algorithm for text classification, we present explicit results on different classes of models when the vectorization step is TF-IDF, and words are replaced by a fixed out-of-dictionary token when removed. Our inquiry covers models such as elementary if-then rules and linear classifiers. We then leverage this analysis to gain insights on the behavior of Anchors for any differentiable classifiers. For neural networks, we empirically show that the words corresponding to the highest partial derivatives of the model with respect to the input, reweighted by the inverse document
    
[^95]: 受限单调神经网络

    Constrained Monotonic Neural Networks. (arXiv:2205.11775v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.11775](http://arxiv.org/abs/2205.11775)

    本文针对实际应用场景需要的单调性，提出了一种通过在层中的一部分神经元中采用原始激活函数，同时在另一部分采用其点对称反射来解决构建单调深度神经网络的方法。实验证明，该方法的精度符合要求。

    

    深度神经网络越来越流行，可以逼近从嘈杂数据中得出的任意函数，但在推广过程中需要解释这些模型并对它们施加额外的限制，其中单调性是最受实际应用场景需要的属性之一，并且是该论文的重点。最早构建单调全连接神经网络的方法是将其权重约束为非负，同时采用单调激活函数。不幸的是，该方法无法与常用的非饱和激活函数（如ReLU，ELU，SELU等）一起使用，因为它只能逼近凸函数。我们通过在层中的一部分神经元中采用原始激活函数，同时在另一部分采用其点对称反射来解决这个问题。我们的实验证明，采用这种方法建立单调深度神经网络的精度与其他方法相当甚至更好，同时满足单调性约束。

    Deep neural networks are becoming increasingly popular in approximating arbitrary functions from noisy data. But wider adoption is being hindered by the need to explain such models and to impose additional constraints on them. Monotonicity constraint is one of the most requested properties in real-world scenarios and is the focus of this paper. One of the oldest ways to construct a monotonic fully connected neural network is to constrain its weights to be non-negative while employing a monotonic activation function. Unfortunately, this construction does not work with popular non-saturated activation functions such as ReLU, ELU, SELU etc, as it can only approximate convex functions. We show this shortcoming can be fixed by employing the original activation function for a part of the neurons in the layer, and employing its point reflection for the other part. Our experiments show this approach of building monotonic deep neural networks have matching or better accuracy when compared to ot
    
[^96]: 自监督视觉预训练中的损坏图像建模

    Corrupted Image Modeling for Self-Supervised Visual Pre-Training. (arXiv:2202.03382v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2202.03382](http://arxiv.org/abs/2202.03382)

    本文提出了一种损坏图像建模的自监督视觉预训练方法，通过协同训练生成器和增强网络来学习丰富的视觉表示，适用于多种网络架构，并在多个数据集上获得了优异的性能表现。

    

    本文介绍了一种自监督的视觉预训练方法——损坏图像建模，使用一个辅助生成器和一个小型的BEiT（Vision Transformer模型），将输入的图像进行破坏，而不是使用人工的[MASK]令牌，生成器在输出分布中采样恰当的备选项用于替换随机选择的一些图像片段。在此基础上，一个增强网络可以学习恢复原始图像或预测每个视觉令牌是否被生成器采样替换。生成器和增强网络同时进行训练，协同更新。预训练后，增强网络可用作下游任务的高容量视觉编码器。该方法适用于多种网络架构，首次证明了ViT和CNN可以使用统一的非孪生框架学习丰富的视觉表示。实验结果表明，本方法在ImageNet、COIL-100和PASCAL VOC 2007数据集上均取得了优异的性能。

    We introduce Corrupted Image Modeling (CIM) for self-supervised visual pre-training. CIM uses an auxiliary generator with a small trainable BEiT to corrupt the input image instead of using artificial [MASK] tokens, where some patches are randomly selected and replaced with plausible alternatives sampled from the BEiT output distribution. Given this corrupted image, an enhancer network learns to either recover all the original image pixels, or predict whether each visual token is replaced by a generator sample or not. The generator and the enhancer are simultaneously trained and synergistically updated. After pre-training, the enhancer can be used as a high-capacity visual encoder for downstream tasks. CIM is a general and flexible visual pre-training framework that is suitable for various network architectures. For the first time, CIM demonstrates that both ViT and CNN can learn rich visual representations using a unified, non-Siamese framework. Experimental results show that our appro
    
[^97]: 测量非概率不确定性：已知和未知未知的认知、逻辑和计算评估

    Measuring Non-Probabilistic Uncertainty: A cognitive, logical and computational assessment of known and unknown unknowns. (arXiv:2201.05818v5 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2201.05818](http://arxiv.org/abs/2201.05818)

    该论文提出了一种测量非概率不确定性的方法，该方法可以通过分析文本来检测不确定性对决策因果关系的影响。

    

    不确定性无法用概率论充分描述的原因有两个。第一个原因是由于独特或几乎独特的事件，这些事件从未发生或发生得太少，以至于无法可靠地测量频率。第二个原因是当人们担心可能发生某些事情，而自己甚至无法想象，例如： "气候变化、金融危机、大流行、战争，下一个是什么？" 在这两种情况下，简单的一对一认知地图将最终崩溃。然而，这种破坏从具体、可识别和差异化的方式影响到企业高管、员工和其他利益相关者的不同讲述。特别是，可以通过分析诸如咨询报告或向股东的信函等文本，以检测这两种不确定性对通常指导决策的因果关系的影响。

    There are two reasons why uncertainty may not be adequately described by Probability Theory. The first one is due to unique or nearly-unique events, that either never realized or occurred too seldom for frequencies to be reliably measured. The second one arises when one fears that something may happen, that one is not even able to figure out, e.g., if one asks: "Climate change, financial crises, pandemic, war, what next?"  In both cases, simple one-to-one cognitive maps between available alternatives and possible consequences eventually melt down. However, such destructions reflect into the changing narratives of business executives, employees and other stakeholders in specific, identifiable and differential ways. In particular, texts such as consultants' reports or letters to shareholders can be analysed in order to detect the impact of both sorts of uncertainty onto the causal relations that normally guide decision-making.  We propose structural measures of cognitive maps as a means 
    
[^98]: 通过组合嵌入进行开放集表示学习

    Open-Set Representation Learning through Combinatorial Embedding. (arXiv:2106.15278v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2106.15278](http://arxiv.org/abs/2106.15278)

    该论文提出了一种基于组合学习的方法来识别数据集中的新概念，扩展已知和新类别的识别性能。它使用多个监督元分类器给出的组成知识自然地对未见类别中的示例进行聚类，并通过无监督的成对关系学习让组合嵌入所提供的表示更加强健。

    

    由于剩余类别的标签不可用，视觉识别任务通常限于处理一小部分类别。我们通过基于有标签和无标签示例的表示学习来识别数据集中的新概念，并将识别扩展到已知和新的类别。为了应对这一具有挑战性的任务，我们提出了一种组合学习方法，该方法使用由多个异质标签空间的监督元分类器给出的组成知识自然地对未见类别中的示例进行聚类。通过无监督的成对关系学习，组合嵌入所提供的表示更加强健。所提出的算法通过联合优化来发现新概念，以增强未见类别的区分性，并学习对新类别具有泛化能力的已知类别的表示。我们广泛的实验展示了我们的方法在各种开放集识别基准测试中的卓越表现，表明了在发现新概念和提高已知和新类别的识别性能方面的有效性。

    Visual recognition tasks are often limited to dealing with a small subset of classes simply because the labels for the remaining classes are unavailable. We are interested in identifying novel concepts in a dataset through representation learning based on both labeled and unlabeled examples, and extending the horizon of recognition to both known and novel classes. To address this challenging task, we propose a combinatorial learning approach, which naturally clusters the examples in unseen classes using the compositional knowledge given by multiple supervised meta-classifiers on heterogeneous label spaces. The representations given by the combinatorial embedding are made more robust by unsupervised pairwise relation learning. The proposed algorithm discovers novel concepts via a joint optimization for enhancing the discrimitiveness of unseen classes as well as learning the representations of known classes generalizable to novel ones. Our extensive experiments demonstrate remarkable per
    
[^99]: SDGNN: 学习有向有符号网络节点表示的方法

    SDGNN: Learning Node Representation for Signed Directed Networks. (arXiv:2101.02390v4 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2101.02390](http://arxiv.org/abs/2101.02390)

    该论文提出了一种新颖的有向有符号图神经网络模型SDGNN，用于学习有向有符号网络中的节点嵌入，该模型重构了链接符号、链接方向和有向有符号三角形，验证了其有效性。

    

    网络嵌入旨在将网络中的节点映射为低维向量表示形式。图神经网络(GNN)已经得到广泛关注，并在学习节点表示方面引领了最先进的性能。但是，大多数GNN仅适用于仅存在正链接的无符号网络。将这些模型转移到有向有符号网络中并不容易，而这种网络在现实世界中广泛存在但研究较少。在本文中，我们首先回顾两个基本的社会学理论（即地位理论和平衡理论），并在真实数据集上进行实证研究以分析有向有符号网络中的社会机制。在相关的社会学理论指导下，我们提出了一种新颖的有向有符号图神经网络模型SDGNN，用于学习有向有符号网络中的节点嵌入。所提出的模型同时重构链接符号、链接方向和有向有符号三角形。我们证实了模型的有效性。

    Network embedding is aimed at mapping nodes in a network into low-dimensional vector representations. Graph Neural Networks (GNNs) have received widespread attention and lead to state-of-the-art performance in learning node representations. However, most GNNs only work in unsigned networks, where only positive links exist. It is not trivial to transfer these models to signed directed networks, which are widely observed in the real world yet less studied. In this paper, we first review two fundamental sociological theories (i.e., status theory and balance theory) and conduct empirical studies on real-world datasets to analyze the social mechanism in signed directed networks. Guided by related sociological theories, we propose a novel Signed Directed Graph Neural Networks model named SDGNN to learn node embeddings for signed directed networks. The proposed model simultaneously reconstructs link signs, link directions, and signed directed triangles. We validate our model's effectiveness o
    
[^100]: 机器人对于谬误和修辞范畴的感知。创建人类尝试所指的本体论。

    A robot's sense-making of fallacies and rhetorical tropes. Creating ontologies of what humans try to say. (arXiv:1906.09689v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/1906.09689](http://arxiv.org/abs/1906.09689)

    本研究针对机器人交流设计中的不足，通过分析谬误和修辞范畴的心理原因、信号检测等因素，开发了一个针对谬误和修辞范畴的安全协议。该协议使用了指代和意义区分、分析表、信息最大程度原则和认识论考虑等技术，从而帮助机器人礼貌地理解用户有时晦涩难懂的要求。

    

    在设计用户友好机器人的过程中，机器人系统应该理解人类交流的意义超越了简单的逻辑和字面意思。长期以来，机器人交流设计忽略了交流和礼貌规则的重要性，而这些规则是“宽容的”和“中止不信仰”的，无法处理人类设计言语的基本隐喻方式。通过分析不合逻辑和非字面陈述的心理原因、信号检测、基本归因错误和拟人化的影响，我们开发了一个安全协议来针对谬误和修辞范畴，在使用弗雷格的指代和意义区分、贝丝的分析表、格赖斯的信息最大程度原则和认识论考虑等方面，使机器人能礼貌地理解用户有时晦涩难懂的要求。

    In the design of user-friendly robots, human communication should be understood by the system beyond mere logics and literal meaning. Robot communication-design has long ignored the importance of communication and politeness rules that are 'forgiving' and 'suspending disbelief' and cannot handle the basically metaphorical way humans design their utterances. Through analysis of the psychological causes of illogical and non-literal statements, signal detection, fundamental attribution errors, and anthropomorphism, we developed a fail-safe protocol for fallacies and tropes that makes use of Frege's distinction between reference and sense, Beth's tableau analytics, Grice's maxim of quality, and epistemic considerations to have the robot politely make sense of a user's sometimes unintelligible demands. Keywords: social robots, logical fallacies, metaphors, reference, sense, maxim of quality, tableau reasoning, epistemics of the virtual
    

