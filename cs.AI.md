# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Scaling laws for language encoding models in fMRI.](http://arxiv.org/abs/2305.11863) | 本文揭示了基于fMRI的语言编码模型预测性能与模型大小呈对数线性关系，在125M到30B参数模型进行规模扩展时，表现提高了约15％。 |
| [^2] | [Multimodal Web Navigation with Instruction-Finetuned Foundation Models.](http://arxiv.org/abs/2305.11854) | 本文研究使用视觉语言基础模型进行数据驱动离线训练的 Web 代理，提出了一个指令跟随多模态代理WebGUM，将微调指令微调语言模型和视觉转换器，能够有效提高代理的基于视觉感知、HTML 理解和多步推理的能力。 |
| [^3] | [RxnScribe: A Sequence Generation Model for Reaction Diagram Parsing.](http://arxiv.org/abs/2305.11845) | RxnScribe是一种端到端的机器学习模型，用于解析化学文献中复杂的反应图，并在交叉验证中取得了较高的分数。 |
| [^4] | [AI's Regimes of Representation: A Community-centered Study of Text-to-Image Models in South Asia.](http://arxiv.org/abs/2305.11844) | 本文探讨南亚文化背景下文字到图像模型的文化限制，并将其归因于全球和地区权力不平等所塑造的外来视角。通过将社区视为专家，对T2I的限制进行研究，深入了解文化特定的AI技术在非西方和南球地区上失败的原因。建议负责任地开发T2I模型，以允许对结构性不平等性的认识。 |
| [^5] | [Comparing Software Developers with ChatGPT: An Empirical Investigation.](http://arxiv.org/abs/2305.11837) | 这篇论文调查了ChatGPT与软件开发人员的比较，认为全面的实证研究可以帮助回答基于AI的计算是否可以提高生产力甚至取代软件工程师进行软件开发的争议。 |
| [^6] | [Complexity of Neural Network Training and ETR: Extensions with Effectively Continuous Functions.](http://arxiv.org/abs/2305.11833) | 本文研究了神经网络训练问题的复杂性，证明了sigmoid激活函数与实数存在性理论和指数函数相关，这使得神经网络在使用sigmoid激活函数时算法可解性存在疑问。同时，使用正弦激活函数时训练问题是不可判定的。 |
| [^7] | [Regularization of Soft Actor-Critic Algorithms with Automatic Temperature Adjustment.](http://arxiv.org/abs/2305.11831) | 本文提出了正则化自动温度调整的软性演员评论算法，增加了对原理的明确性。 |
| [^8] | [Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews.](http://arxiv.org/abs/2305.11828) | 本文研究了使用LLM协助制作医学证据综述的潜在用途和风险，指出LLM有可能自动生成文献综述，但由于可能出现虚构或遗漏信息的情况，LLM的使用需要谨慎。 |
| [^9] | [STOAT: Structured Data to Analytical Text With Controls.](http://arxiv.org/abs/2305.11826) | STOAT模型是表格和推理意识的生成模型，在数字推理、常识推理、时间推理、表格知识和实体知识方面有较好的控制，提高了分析句子生成的质量和准确度。 |
| [^10] | [Summarizing Strategy Card Game AI Competition.](http://arxiv.org/abs/2305.11814) | 本文总结了基于《魔法与代码英雄》（LOCM）的五年人工智能比赛，介绍了游戏规则以及比赛历史，给出了组织AI比赛的建议。LOCM已被用于许多与游戏树搜索算法、神经网络、评估函数和CCG卡组构建等相关领域的出版物中。 |
| [^11] | [Monte-Carlo Search for an Equilibrium in Dec-POMDPs.](http://arxiv.org/abs/2305.11811) | 本文在Dec-POMDP领域使用了Monte Carlo搜索算法来寻找纳什均衡，最终的基准实验表明MC-JESP可以有效解决控制器问题并达到预期效果。 |
| [^12] | [On the Fairness Impacts of Private Ensembles Models.](http://arxiv.org/abs/2305.11807) | 本文探讨了私有教师集成（PATE）模型是否会导致不公平性，并证明它可能导致不同群体之间的准确性差异。建议在PATE的应用中加入公平性考虑，以减少不公平性的影响。 |
| [^13] | [Chain-of-thought prompting for responding to in-depth dialogue questions with LLM.](http://arxiv.org/abs/2305.11792) | 本文提出使用思路链索引的方式来响应用户状态，以提供更个性化和更有吸引力的用户体验，用语义相似性而非测试查询做中间推理处理。 |
| [^14] | [DMDD: A Large-Scale Dataset for Dataset Mentions Detection.](http://arxiv.org/abs/2305.11779) | DMDD是一个公开的数据集，用于数据集提及检测任务，包含31,219篇科学文章和超过449,000个弱注释的数据集提及。该数据集为该任务建立了基准性能，并且通过分析模型的表现，确定了开放问题。 |
| [^15] | [Neural Foundations of Mental Simulation: Future Prediction of Latent Representations on Dynamic Scenes.](http://arxiv.org/abs/2305.11772) | 本研究探究了人类和动物如何推断物理世界的基本动态轨迹以及如何预测未来可能出现的状态，并评估了几类感知-认知网络的预测能力，发现在效率、普遍性和可解释性间存在权衡。 |
| [^16] | [Enhancing Vision-Language Pre-Training with Jointly Learned Questioner and Dense Captioner.](http://arxiv.org/abs/2305.11769) | 本文提出了一种名为JADE的新方法，可以利用易于获取的图像-文本对进行的联合学习，以提升视觉和语言模态的细粒度特征对齐，从而更好地进行视觉问答和密集字幕生成。 |
| [^17] | [Controlling the Extraction of Memorized Data from Large Language Models via Prompt-Tuning.](http://arxiv.org/abs/2305.11759) | 该论文提出在大型语言模型中通过Prompt-Tuning策略来控制从中提取记忆数据的方法，提供了攻击和防御两种训练策略。在公共基准测试中展示了其在GPT-Neo模型中的有效性，攻击策略相对于基线产生了9.3%的提取率增加，而防御策略可以调整以实现不同的隐私-效用权衡，可以实现最多97.7%的提取率减少，但困惑度增加了16.9%。 |
| [^18] | [Visualization for Recommendation Explainability: A Survey and New Perspectives.](http://arxiv.org/abs/2305.11755) | 本文回顾了推荐系统中有关可视化解释的研究，提出了一组可能有益于设计解释性可视化推荐系统的指南。 |
| [^19] | [MedLens: Improve mortality prediction via medical signs selecting and regression interpolation.](http://arxiv.org/abs/2305.11742) | 本文介绍了一个自动选择医学体征和回归插值的方法（MedLens），用于解决电子病历中医学体征数据缺失率过高导致预测性能降低的问题。 |
| [^20] | [CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing.](http://arxiv.org/abs/2305.11738) | 本文提出了一个名为CRITIC的框架，使得大型语言模型可以通过与工具的交互校正自己的错误，从而避免生成出现不一致和问题行为的结果。 |
| [^21] | [What Comes Next? Evaluating Uncertainty in Neural Text Generators Against Human Production Variability.](http://arxiv.org/abs/2305.11707) | 本文分析了神经文本生成器与人类生产变异性之间的不确定性，通过探测生成器的输出空间来测量其对人类生产变异性的校准程度，并证明用多个样本和多个参考可以更好地了解模型的不确定性表示。 |
| [^22] | [RGCVAE: Relational Graph Conditioned Variational Autoencoder for Molecule Design.](http://arxiv.org/abs/2305.11699) | 本文提出了RGCVAE，一种基于关系图条件化的可变自编码器，可以有效、高效地进行分子设计，并在两个数据集上表现出了先进的生成性能和快速的训练速度。 |
| [^23] | [Surgical-VQLA: Transformer with Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery.](http://arxiv.org/abs/2305.11692) | 本文提出了Surgical-VQLA方法，结合Transformer模型和门控视觉-语言嵌入，解决了手术VQA中对象检测稀缺、异构模态融合策略不足、定位答案缺失等问题，并在测试中实现了最好的表现。 |
| [^24] | [Evaluating task understanding through multilingual consistency: A ChatGPT case study.](http://arxiv.org/abs/2305.11662) | 本文提出了一种新的评估大型语言模型理解能力的范例，通过评估模型自身生成的不同意义之间的一致性，探讨了多语言自我一致性作为模型理解的检验方法，同时证明了ChatGPT在多语言一致性方面的优秀性能。 |
| [^25] | [Applying Ising Machines to Multi-objective QUBOs.](http://arxiv.org/abs/2305.11648) | 本文基于 Ising 机，提出了一种自适应求解多目标 QUBOs 的方法，该方法比之前的方法探索 Pareto 前沿更快、更准确。 |
| [^26] | [Tune-Mode ConvBN Blocks For Efficient Transfer Learning.](http://arxiv.org/abs/2305.11624) | 本文研究了ConvBN块中稳定性和效率之间的权衡问题，提出了一种新的Tune模式，以便在迁移学习中既能保持稳定性又能提高效率。 |
| [^27] | [Towards Code Generation from BDD Test Case Specifications: A Vision.](http://arxiv.org/abs/2305.11619) | 本文提出一种利用行为驱动开发测试规范，结合基于转换器的机器学习模型来生成 Angular 框架的前端组件代码的方法。该方法可以显著减少开发时间，提高软件质量，并为自动生成代码研究提供新思路。 |
| [^28] | [Diversifying Deep Ensembles: A Saliency Map Approach for Enhanced OOD Detection, Calibration, and Accuracy.](http://arxiv.org/abs/2305.11616) | 这项研究提出了一种使用显著性图来促进深度集成多样性的方法，用于改善OOD检测、校准和准确性，能够优于传统的集成技术，并在OpenOOD基准测试上证明了其有效性。 |
| [^29] | [MIDI-Draw: Sketching to Control Melody Generation.](http://arxiv.org/abs/2305.11605) | MIDI-Draw是一种可以通过画曲线来控制旋律生成的方法，相比于现有的方法，这种方法可以让用户更快速地表达他们的音乐意图。 |
| [^30] | [Introspective Tips: Large Language Model for In-Context Decision Making.](http://arxiv.org/abs/2305.11598) | 本文研究了内省技巧对大型语言模型在上下文决策制定中的应用，通过内省轨迹生成简洁有价值的提示，不调整LLM参数就能提高代理的性能。 |
| [^31] | [Diving into the Inter-Consistency of Large Language Models: An Insightful Analysis through Debate.](http://arxiv.org/abs/2305.11595) | 本文提出了通过辩论探究大型语言模型之间的内部一致性问题，实验证明通过严格的辩论框架可以提高模型性能和常识知识的结构化学习。 |
| [^32] | [Trustworthy, responsible, ethical AI in manufacturing and supply chains: synthesis and emerging research questions.](http://arxiv.org/abs/2305.11581) | 本文探讨了在制造业背景下，可信、负责、道德的人工智能的适用性，并使用实例讨论了每一步可能导致的人工智能信任问题，同时还提出了未来的研究问题。 |
| [^33] | [Speech-Text Dialog Pre-training for Spoken Dialog Understanding with Explicit Cross-Modal Alignment.](http://arxiv.org/abs/2305.11579) | 本文提出了SPECTRA语音文本对话预训练模型，应用了新的时间位置预测任务来捕捉语音文本对齐，同时将回答选择任务推广到服务于口语对话理解，用于丰富话语表示。 |
| [^34] | [StereoVAE: A lightweight stereo matching system through embedded GPUs.](http://arxiv.org/abs/2305.11566) | 本论文提出了通过嵌入式GPU实现的轻量级立体匹配系统-StereoVAE，该系统采用基于VAE的小型神经网络对传统匹配方法生成的小尺寸粗糙视差图进行上采样与细化，达到了提高匹配精度和保证实时处理的目的。 |
| [^35] | [Decouple knowledge from paramters for plug-and-play language modeling.](http://arxiv.org/abs/2305.11564) | 本文介绍了一种新的插件式预训练模型，其与模型参数中的知识存储分离，采用可编辑和可扩展的键值存储器，通过DPM中的知识检索以可解释的方式利用知识。 |
| [^36] | [Empower Large Language Model to Perform Better on Industrial Domain-Specific Question Answering.](http://arxiv.org/abs/2305.11541) | 本文提供了一个行业云特定QA数据集 MSQA，该数据集可用于评估旨在提高大规模语言模型特定领域能力的方法。本文还提出了一种新的模型交互范式，可以使大规模语言模型在其不擅长的特定任务上取得更好的性能。 |
| [^37] | [Trustworthy Federated Learning: A Survey.](http://arxiv.org/abs/2305.11537) | 本文综述了联邦学习的可信性问题，提出了三个支柱：可解释性，公平性和安全与隐私，并探讨了相关的挑战和研究方向。 |
| [^38] | [InstructIE: A Chinese Instruction-based Information Extraction Dataset.](http://arxiv.org/abs/2305.11527) | 介绍了一份中文的基于指令的信息提取数据集InstructIE，其中包括了270,000个弱监督的数据和1,000个高质量注释实例。实验结果表明当前的模型表现有待改进，该任务仍存在挑战。 |
| [^39] | [Artificial intelligence moral agent as Adam Smith's impartial spectator.](http://arxiv.org/abs/2305.11519) | 本文讨论了使用人工智能作为外部代替工具，扮演亚当·斯密的公正旁观者角色的可能性，以提供更全面的道德评估视角。 |
| [^40] | [DiffuSIA: A Spiral Interaction Architecture for Encoder-Decoder Text Diffusion.](http://arxiv.org/abs/2305.11517) | 本文提出一种名为DiffuSIA的螺旋交互架构，用于编码器-解码器文本扩散。在这个架构中，条件信息和目标信息会交互捕获，以提高条件文本生成的效果。 |
| [^41] | [Terraforming -- Environment Manipulation during Disruptions for Multi-Agent Pickup and Delivery.](http://arxiv.org/abs/2305.11510) | 在自动化仓库的多智能体取送货问题中，运用Terraforming技术灵活地重新定位货架，可以减少路径长度和提高运输效率。 |
| [^42] | [Plug-and-Play Medical Dialogue System.](http://arxiv.org/abs/2305.11508) | 该论文提出了一种即插即用的医疗对话系统，使用大型语言模型实现医疗问答及诊断策略，避免了传统昂贵的LLMs微调。 |
| [^43] | [Recouple Event Field via Probabilistic Bias for Event Extraction.](http://arxiv.org/abs/2305.11498) | 提出了一种基于概率偏置的重新耦合事件场模型（ProCE），用于增强事件提取框架，以澄清来自模糊纠缠的事件字段，并重新耦合相应的澄清分布以捕获更多潜在信息字段。实验表明该方法有效且具有泛化性。 |
| [^44] | [TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding.](http://arxiv.org/abs/2305.11497) | 提示调整技术已经在视觉定位领域卓有成效，但现有的方法大多数可解释性不好。本文提出了一种新的提示构建方法，名为TreePrompt，通过将句子分解成树状结构进行逐步提示构建，提高了提示的可解释性。 |
| [^45] | [LLM Itself Can Read and Generate CXR Images.](http://arxiv.org/abs/2305.11490) | 该论文提出了一种新方法，可以在不需要进行结构更改、额外训练、或训练专门网络的情况下，通过微调预先训练的LLM来读取和生成像文本一样的图像，并应用于胸部X线（CXR）图像的生成任务中。 |
| [^46] | [Incomplete Multi-view Clustering via Diffusion Completion.](http://arxiv.org/abs/2305.11489) | 本文提出一种扩散补全方法，将缺失视角恢复到不完整多视角聚类框架中，并通过对比学习来学习多视角数据的一致性信息，从而提高了多视角聚类的性能。 |
| [^47] | [Sensecape: Enabling Multilevel Exploration and Sensemaking with Large Language Models.](http://arxiv.org/abs/2305.11483) | 这篇论文讲述了一个交互式系统Sensecape，它能够利用大语言模型（LLM）支持复杂的信息任务，帮助用户通过多级抽象管理信息的复杂性，并在规划和知识建构之间无缝切换，有助于增强用户的信息组织和探索能力。 |
| [^48] | [CCGen: Explainable Complementary Concept Generation in E-Commerce.](http://arxiv.org/abs/2305.11480) | CCGen是一个电子商务中可解释的互补概念生成算法，通过训练语言模型生成高质量的互补概念排名列表，并生成解释以证明预测的正确性。 |
| [^49] | [Learning Diverse Risk Preferences in Population-based Self-play.](http://arxiv.org/abs/2305.11476) | RPPO是一种新颖的强化学习算法，通过代理程序在面对不确定性时具备多样的风险偏好，从而增加自我对抗算法中的策略多样性，并提高代理程序面对不同对手的鲁棒性。 |
| [^50] | [RAMiT: Reciprocal Attention Mixing Transformer for Lightweight Image Restoration.](http://arxiv.org/abs/2305.11474) | 本文提出了轻量级图像恢复的互惠式注意力混合Transformer（RAMiT）。通过使用双向注意力以及一种新的数据增强类型——强度掩码，有效地提高了恢复效果，同时大大减少了参数数量。 |
| [^51] | [Graphologue: Exploring Large Language Model Responses with Interactive Diagrams.](http://arxiv.org/abs/2305.11473) | Graphologue是一个交互式系统，将大型语言模型的基于文本的响应转换为图形化图表以增强其可用性和可解释性，用户可以通过选择和突出显示特定节点和链接来与这些图表进行交互。 |
| [^52] | [Testing System Intelligence.](http://arxiv.org/abs/2305.11472) | 该论文讨论了以往智能系统测试的不足和所提出的替换测试作为一种完善测试的能力，该测试反映了人类和机器之间的技能互补性，能够构建更多反映智能可能的概念和属性。 |
| [^53] | [SelfzCoT: a Self-Prompt Zero-shot CoT from Semantic-level to Code-level for a Better Utilization of LLMs.](http://arxiv.org/abs/2305.11461) | 本文提出了 SelfzCoT 自动自我生成的零样本编码，通过使用LLMs和代码级别的自我提示，在六个零样本算术推理任务中实现了巨大的准确度提升。同时，修改的零样本编码 MzCoT 在推理任务中也取得了显著的表现。 |
| [^54] | [Self-Agreement: A Framework for Fine-tuning Language Models to Find Agreement among Diverse Opinions.](http://arxiv.org/abs/2305.11460) | 本文提出了一种名为自我协议(Self-Agreement)的新框架，用于微调LLMs以自主地找到共识，并使用LLM自动生成的数据。 |
| [^55] | [Shattering the Agent-Environment Interface for Fine-Tuning Inclusive Language Models.](http://arxiv.org/abs/2305.11455) | 该论文提出了一种新颖的思路，将预训练的语言模型本身同时作为策略、奖励函数和转移函数，可以直接进行奖励学习和语言模型微调，可以带来巨大的统计收益。 |
| [^56] | [Arukikata Travelogue Dataset.](http://arxiv.org/abs/2305.11444) | Arukikata旅游游记数据集是一个包含超过3100万个日文单词的数据集，包括4672个日本国内游记和9607个海外游记，为研究人员提供了可重复和透明的研究数据。 |
| [^57] | [Zero-Shot Text Classification via Self-Supervised Tuning.](http://arxiv.org/abs/2305.11442) | 本文提出了一种基于自监督调整的零样本文本分类算法，通过使用无标签数据来调整语言模型，通过学习预测段落中的第一句话，实现了对未见过任务的零样本推断，模型不需要注释数据进行元调整，对模板的选择不敏感，并在实验中取得不错的结果。 |
| [^58] | [PS-FedGAN: An Efficient Federated Learning Framework Based on Partially Shared Generative Adversarial Networks For Data Privacy.](http://arxiv.org/abs/2305.11437) | 本文提出了一种高效的联合学习框架 PS-FedGAN，通过部分共享生成式对抗网络以保护数据隐私，实现了在分布数据环境下捕捉本地数据总体特征，相比于现有框架具有更好的收敛速度、通信开销和隐私保护效果。 |
| [^59] | [Syllable Discovery and Cross-Lingual Generalization in a Visually Grounded, Self-Supervised Speech Mode.](http://arxiv.org/abs/2305.11435) | 本文提出采用基于视觉引导的自监督语音模型进行音节发现和跨语言泛化。使用最小割算法和2阶段聚类方法自动预测语音中的音节边界。在英语上表现优于最先进的音节分割方法，并以零样本的方式在爱沙尼亚语上泛化。在其他语言上也取得了成功。 |
| [^60] | [TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks.](http://arxiv.org/abs/2305.11430) | 本文提出了一个通用分类法，可以用来设计具有特定属性的提示来执行各种复杂任务，从而解决了LLM在执行复杂任务方面的性能变异巨大的问题。 |
| [^61] | [Post Hoc Explanations of Language Models Can Improve Language Models.](http://arxiv.org/abs/2305.11426) | 本文提出了一种新的框架AMPLIFY，利用后验解释自动化生成原因，并在多个数据集和任务上显著提高现有语言模型的性能。 |
| [^62] | [Graph Propagation Transformer for Graph Representation Learning.](http://arxiv.org/abs/2305.11424) | 本文提出了一种新的变换器架构 GPTrans，以图传播注意力为基础，可以更好地学习图形模型，并在多个基准测试集上超过了其他最先进的基于变换器的图形模型。 |
| [^63] | [PastNet: Introducing Physical Inductive Biases for Spatio-temporal Video Prediction.](http://arxiv.org/abs/2305.11421) | 本文介绍了一种名为PastNet的新颖方法，通过在傅里叶域中引入谱卷积算子，利用内在的物理知识生成高质量的时空视频预测，并通过离散化局部特征降低计算成本。 |
| [^64] | [JetSeg: Efficient Real-Time Semantic Segmentation Model for Low-Power GPU-Embedded Systems.](http://arxiv.org/abs/2305.11419) | JetSeg是一个专为GPU-嵌入式系统设计的高效实时语义分割模型，通过新型的轻量级高效块JetBlock和结合了不对称和非对称卷积、深度空洞卷积、通道混洗操作、轻量级激活函数和适用于嵌入式系统的方便数量的组卷积的策略JetConv以及创新的损失函数JetLoss，在保持高精度的同时，明显减少了内存使用量和推理时间，优于最先进的模型。 |
| [^65] | [Federated Foundation Models: Privacy-Preserving and Collaborative Learning for Large Models.](http://arxiv.org/abs/2305.11414) | 本文提出了联邦基础模型（FFMs）的概念，结合了基础模型和联邦学习的优势，可实现跨多个机构的隐私保护和协作学习。 |
| [^66] | [LATTE: Label-efficient Incident Phenotyping from Longitudinal Electronic Health Records.](http://arxiv.org/abs/2305.11407) | 本文提出了一种标签高效的事件类型标注算法（LATTE），用于准确标注纵向EHR数据中的临床事件时间，通过时间模式挖掘构建高度信息化的纵向银标准事件标签，并在MIMIC-III数据集上实现了7.57％和10.82％的绝对改善。 |
| [^67] | [A Survey of Safety and Trustworthiness of Large Language Models through the Lens of Verification and Validation.](http://arxiv.org/abs/2305.11391) | 通过验证和验证的视角对大型语言模型的安全性和可信度进行调查，分类它们的已知漏洞，将其分为固有问题、有意攻击和意外错误。同时，考虑四种互补技术以提供LLM及其应用的安全和可信度保障。 |
| [^68] | [ALT: An Automatic System for Long Tail Scenario Modeling.](http://arxiv.org/abs/2305.11390) | 本文提出了一种名为ALT的自动化系统，用于解决长尾场景建模问题，实现了对于模型训练和推理阶段人力和资源有限的情况下的有效建模需求。 |
| [^69] | [Domain Generalization Deep Graph Transformation.](http://arxiv.org/abs/2305.11389) | 本文提出了一种面向领域泛化的深度图形转换方法，使用超网络进行多输入多输出的图神经网络预测，通过加入潜在变量来训练泛化模型，在多个基准数据集中取得了优异表现。 |
| [^70] | [Justices for Information Bottleneck Theory.](http://arxiv.org/abs/2305.11387) | 本论文从引入一个辅助函数，证明深度学习中ReLU激活下互信息下降的悖论，挑战了对信息瓶颈理论适用性的质疑，提供了使用该理论解释DL网络内部组织的新方法。 |
| [^71] | [Visualizing Linguistic Diversity of Text Datasets Synthesized by Large Language Models.](http://arxiv.org/abs/2305.11364) | 该论文介绍了一种新的可视化工具，用于分析大型语言模型生成的数据集的句法多样性，可以通过分层可视化来帮助用户快速浏览概述和检查各个示例。 |
| [^72] | [Meta-learning for heterogeneous treatment effect estimation with closed-form solvers.](http://arxiv.org/abs/2305.11353) | 本文提出了一种元学习方法，用于从少量的观测数据中估计条件平均处理效应（CATE），该方法通过神经网络模型对CATE估计问题进行分解并使用闭式求解器获得参数，最终实现了任务之间的共享和优化CATE估计表现提升。 |
| [^73] | [Quantifying the robustness of deep multispectral segmentation models against natural perturbations and data poisoning.](http://arxiv.org/abs/2305.11347) | 本研究通过对多光谱图像分割模型进行实验，发现多光谱数据不能提高模型对自然扰动的鲁棒性，同时模型对抗攻击的鲁棒性取决于攻击方法和使用的特定光谱波段。 |
| [^74] | [Writing your own book: A method for going from closed to open book QA to improve robustness and performance of smaller LLMs.](http://arxiv.org/abs/2305.11334) | 本文介绍了两种新颖的方法，Tree-Search和自我上下文QA，可提高大型语言模型在问答任务中的性能。Tree-Search采样技术有助于从提示中提取多样化信息，而自我上下文QA可使模型创建自己的上下文，生成更好的开放式答案。此外，这些方法可提高健壮性和性能。 |
| [^75] | [SpikeCP: Delay-Adaptive Reliable Spiking Neural Networks via Conformal Prediction.](http://arxiv.org/abs/2305.11322) | 这篇论文提出了一种新的脉冲神经网络模型，能够通过极限预测实现自适应的推断延迟，从而节约能源与提高可靠性。 |
| [^76] | [Parameter-Efficient Learning for Text-to-Speech Accent Adaptation.](http://arxiv.org/abs/2305.11320) | 本文提出了一种参数高效学习方法（PEL），利用理论基础的最优传输（OT）来实现低资源语音合成口音适应，通过引入基于OT的辅助无监督损失来最大化源域和目标域之间的差异，从而提高系统性能。 |
| [^77] | [BELLA: Black box model Explanations by Local Linear Approximations.](http://arxiv.org/abs/2305.11311) | 本文提出了一种确定性的、与模型无关的事后方法BELLA，用于解释回归黑盒模型的个别预测。该方法通过特征空间中训练的线性模型提供解释，使得该模型的系数可以直接用于计算特征值的预测值。此外，BELLA最大化了线性模型适用的领域范围。 |
| [^78] | [Counterfactuals for Design: A Model-Agnostic Method For Design Recommendations.](http://arxiv.org/abs/2305.11308) | 本文介绍了一种多目标设计反事实(MCD)方法，可帮助设计师识别设计修改，提高功能性能。MCD通过支持多目标查询和解耦反事实搜索和采样过程来提高效率并改进现有的反事实搜索方法，证明其在自行车设计案例中的有效性。 |
| [^79] | [NeuSTIP: A Novel Neuro-Symbolic Model for Link and Time Prediction in Temporal Knowledge Graphs.](http://arxiv.org/abs/2305.11301) | NeuSTIP是一种新型神经符号模型，能够在时间知识图谱中进行链接和时间预测，且在两个TKGC数据集上优于现有方法。 |
| [^80] | [Solving probability puzzles with logic toolkit.](http://arxiv.org/abs/2305.11294) | 建立等式FOL，使用Mace4计算所有可能的模型和有利模型数量，最后根据定义计算概率。这种方法让逻辑学生使用他们熟悉的工具解决概率谜题。 |
| [^81] | [Federated learning for secure development of AI models for Parkinson's disease detection using speech from different languages.](http://arxiv.org/abs/2305.11284) | 本论文利用联邦学习方法，无需共享患者数据，实现在德语、西班牙语和捷克语三种语言数据集上进行帕金森病检测，取得了优于本地模型的诊断准确性。 |
| [^82] | [On the Statistical Efficiency of Mean Field Reinforcement Learning with General Function Approximation.](http://arxiv.org/abs/2305.11283) | 本文研究了一般函数逼近下的均场控制(MFC)和均场博弈(MFG)中的强化学习的统计效率，提出了基于乐观最大似然估计的算法，并仅对转移动力学具有Lipschitz连续性的假设，最后建立了一个指数级的下界支持MFC设置。 |
| [^83] | [Explaining V1 Properties with a Biologically Constrained Deep Learning Architecture.](http://arxiv.org/abs/2305.11275) | 该论文使用生物特性构建CNNs架构，成功解释V1神经活动特性。 |
| [^84] | [Towards Collaborative Plan Acquisition through Theory of Mind Modeling in Situated Dialogue.](http://arxiv.org/abs/2305.11271) | 本文提出了一种协作计划获取方法，通过丰富的感知和对话历史，让代理人预测他们自己和合作伙伴缺失的任务知识，实现联合任务的完整计划获取。 |
| [^85] | [Robust Quantum Controllers: Quantum Information -- Thermodynamic Hidden Force Control in Intelligent Robotics based on Quantum Soft Computing.](http://arxiv.org/abs/2305.11254) | 本文介绍了一种基于量子/软计算技术设计智能健壮控制系统的通用策略，并着重于增加智能控制系统的健壮性。 |
| [^86] | [Brain-inspired learning in artificial neural networks: a review.](http://arxiv.org/abs/2305.11252) | 本文综述了当前人工神经网络中的脑启发式学习表示，找出了未来研究的有前途的方向，这可能使我们更加接近理解智能的本质。 |
| [^87] | [A Parameter-Efficient Learning Approach to Arabic Dialect Identification with Pre-Trained General-Purpose Speech Model.](http://arxiv.org/abs/2305.11244) | 本文介绍了一种利用预训练通用语音模型进行阿拉伯方言识别的参数高效学习方法，通过残差适配器和模型重编程，设计了一个基于记号的标签映射，并在ADI-17数据集上实现了最高精度，同时使用PEL方法进一步减少了训练成本。 |
| [^88] | [Comparing Machines and Children: Using Developmental Psychology Experiments to Assess the Strengths and Weaknesses of LaMDA Responses.](http://arxiv.org/abs/2305.11243) | 使用儿童发展实验来评估人工智能的计算能力，同时比较LLMs和儿童可以帮助我们开发更具人类特征和可解释性的机器学习模型。 |
| [^89] | [Milestones in Autonomous Driving and Intelligent Vehicles Part \uppercase\expandafter{\romannumeral1}: Control, Computing System Design, Communication, HD Map, Testing, and Human Behaviors.](http://arxiv.org/abs/2305.11239) | 本次论文总结了自动驾驶和智能车辆中关于控制、计算机系统设计、通信、高精度地图、测试和人类行为的发展情况和未来研究方向。 |
| [^90] | [Efficient Vertical Federated Learning with Secure Aggregation.](http://arxiv.org/abs/2305.11236) | 本文提出了一种安全有效的竖向联邦学习方法，通过使用安全模块进行聚合，解决了竖直数据集下的隐私泄露问题，并在不降低性能的情况下获得了大量加速。 |
| [^91] | [LIMA: Less Is More for Alignment.](http://arxiv.org/abs/2305.11206) | 该论文介绍了一种使用无声调学习预训练语言模型和标准监督损失微调的方法（不使用强化学习或人类模型），并展示了在复杂任务上也有出色的表现。 |
| [^92] | [PDP: Parameter-free Differentiable Pruning is All You Need.](http://arxiv.org/abs/2305.11203) | PDP提出了一种无需参数的可微剪枝方案，具有最先进的模型大小、准确性和训练成本，适用于各种视觉和自然语言任务。 |
| [^93] | [Prediction with Incomplete Data under Agnostic Mask Distribution Shift.](http://arxiv.org/abs/2305.11197) | 本研究考虑预测不完整数据的情况，在缺失模式分布可能发生偏移的情况下，我们利用掩码的不变最优预测器实现泛化，通过双参数化技术联合近似最优预测器避免指数爆炸，同时引入正则化项保证预测器具有鲁棒性。 |
| [^94] | [Taxonomy of AISecOps Threat Modeling for Cloud Based Medical Chatbots.](http://arxiv.org/abs/2305.11189) | 这篇论文介绍了使用 AISecOps 对云医疗聊天机器人进行监控的方法，解释了 AISecOps 是如何将 IT 运营、人工智能和安全三个领域整合起来协同运作以确保聊天机器人的机密性、完整性和可用性的。 |
| [^95] | [A Compound Gaussian Network for Solving Linear Inverse Problems.](http://arxiv.org/abs/2305.11120) | 本文提出了一种基于复合高斯先验分布的迭代算法和对应于其迭代过程“展开”的深度神经网络来解决线性反问题，两种方法都优于其他最先进的解决方法。 |
| [^96] | [mdctGAN: Taming transformer-based GAN for speech super-resolution with Modified DCT spectra.](http://arxiv.org/abs/2305.11104) | 本文提出新型SSR框架mdctGAN，基于MDCT谱，以相位感知的方式重建HR语音，无需声码器或额外的后处理，并保证了高质量的语音重建。 |
| [^97] | [Generating coherent comic with rich story using ChatGPT and Stable Diffusion.](http://arxiv.org/abs/2305.11067) | 本文介绍了一种利用ChatGPT和Stable Diffusion生成连贯漫画故事的方法，通过引入新的评估AI故事的方式，并使用LoRA、ControlNet等方法进行fine-tuning，取得了在角色忠实度和艺术风格上的最先进表现。 |
| [^98] | [Annotation-free Audio-Visual Segmentation.](http://arxiv.org/abs/2305.11019) | 本文提出了一种可伸缩且无需注释的管道，用于生成音视频分割任务的人工数据，并引入了一个音频感知的基于查询的Transformer解码器，使模型能够在音频信号的指导下搜索声音对象，得到更准确的分割。 |
| [^99] | [Large Language Models can be Guided to Evade AI-Generated Text Detection.](http://arxiv.org/abs/2305.10847) | 本文揭示了大型语言模型可以通过精心设计的提示语来有效规避现有的文本检测系统，证明了这些检测器的脆弱性。 |
| [^100] | [UniEX: An Effective and Efficient Framework for Unified Information Extraction via a Span-extractive Perspective.](http://arxiv.org/abs/2305.10306) | UniEX是一种能适用于各种模式格式的信息抽取框架，并能同时解决命名实体识别、关系抽取、事件提取和情感分析等任务，在性能和推理速度上优于其他通用信息抽取模型。 |
| [^101] | [SuSana Distancia is all you need: Enforcing class separability in metric learning via two novel distance-based loss functions for few-shot image classification.](http://arxiv.org/abs/2305.09062) | 本文提出了两种新的基于距离的损失函数，通过考虑少量数据之间的类内距离和类间距离来考虑嵌入向量的重要性，以增强度量学习中的类别可分性，实现优秀的少样本图像分类表现。 |
| [^102] | [Parameter-Efficient Fine-Tuning with Layer Pruning on Free-Text Sequence-to-Sequence modeling.](http://arxiv.org/abs/2305.08285) | 本文提出了一个将LoRA和结构化层剪枝方法结合的框架，在保持超过92%生成质量的同时，通过调整仅0.6%的参数并剪枝超过30%的Transformer层，成功减少了50%的GPU内存使用并提升了100%的训练速度。 |
| [^103] | [A Comprehensive Survey on Segment Anything Model for Vision and Beyond.](http://arxiv.org/abs/2305.08196) | 本文综述了最近提出的“任意分割模型”（SAM）的进展，该模型打破了分割界限，提高了计算机视觉基础模型的发展。 |
| [^104] | [Provable Multi-instance Deep AUC Maximization with Stochastic Pooling.](http://arxiv.org/abs/2305.08040) | 本文提出了在多实例学习中使用深度AUC最大化（DAM）的方法，并根据包含大量实例的情况下训练的计算挑战，提出了一种基于方差减少的随机池化方法，使得只需对每个包进行少量采样即可计算MIDAM模型，提高了效率和准确性。 |
| [^105] | [Neural operator for structural simulation and bridge health monitoring.](http://arxiv.org/abs/2305.07889) | 本论文提出了结构模拟和桥梁健康监测的神经运算器VINO，通过学习结构响应场和损伤场之间的映射，在前向预测和反向确定损伤区域和程度方面可以比传统有限元模型更准确地预测和判断。 |
| [^106] | [FactKG: Fact Verification via Reasoning on Knowledge Graphs.](http://arxiv.org/abs/2305.06590) | FactKG是一个新的数据集，通过知识图谱推理进行事实验证，包含108k个自然语言声明和五种推理类型，可帮助社区更好地使用知识图谱进行事实验证。 |
| [^107] | [Distributional Multi-Objective Decision Making.](http://arxiv.org/abs/2305.05560) | 该论文介绍了一种分布式多目标决策制定的方法，其中引入了分布式不支配集和凸分布不支配集的概念，证明了它们可以包含所有最优解，通过实验验证了方法的有效性。 |
| [^108] | [GPT-NAS: Neural Architecture Search with the Generative Pre-Trained Model.](http://arxiv.org/abs/2305.05351) | GPT-NAS使用生成式预训练模型优化神经架构搜索，通过提出近似的架构组件减小搜索空间，并明显优于其他NAS方法。 |
| [^109] | [Towards Achieving Near-optimal Utility for Privacy-Preserving Federated Learning via Data Generation and Parameter Distortion.](http://arxiv.org/abs/2305.04288) | 本论文提出了一种用数据生成和参数畸变实现隐私保护联邦学习接近最优效用的上限方法，其中通过降低方差和模型参数差异来衡量效用损失。 |
| [^110] | [PersonaLLM: Investigating the Ability of GPT-3.5 to Express Personality Traits and Gender Differences.](http://arxiv.org/abs/2305.02547) | 本文探究了基于LLMs模拟代理的行为，称之为LLM Personas，在分配大五人格类型和性别角色时是否可以生成具有一致性的个性化特质的内容。 |
| [^111] | [Categorical Foundations of Explainable AI: A Unifying Formalism of Structures and Semantics.](http://arxiv.org/abs/2304.14094) | 本文采用范畴理论的框架，提出了可解释AI的统一理论体系，为领域中所有重要术语提供了清晰的形式定义，并提供了遵循所提出结构的领域分类法。 |
| [^112] | [Spikingformer: Spike-driven Residual Learning for Transformer-based Spiking Neural Network.](http://arxiv.org/abs/2304.11954) | 提出了一种适用于硬件的SNN脉冲驱动残差学习结构，基于该结构开发了一个纯Transformer的脉冲神经网络Spikingformer，用于避免非脉冲计算并在多个数据集上实现了优异的性能表现。 |
| [^113] | [A Scalable Test Problem Generator for Sequential Transfer Optimization.](http://arxiv.org/abs/2304.08503) | STO中已有的测试问题设计不完善，难以代表真实问题多样化关系，限制了算法的表现。本文介绍了一种可扩展的序列转移优化问题生成器。 |
| [^114] | [Probably Approximately Correct Federated Learning.](http://arxiv.org/abs/2304.04641) | 本文提出了FedPAC框架，利用PAC学习理论推导出一个解析解，可以保证FL之间隐私、效用和效率的最佳权衡。 |
| [^115] | [Incorporating Unlabelled Data into Bayesian Neural Networks.](http://arxiv.org/abs/2304.01762) | 该论文提出了一种利用未标记数据学习贝叶斯神经网络（BNNs）的对比框架，通过该框架提出了一种同时具备自监督学习的标签效率和贝叶斯方法中的不确定性估计的实用BNN算法。最后，该方法在半监督和低预算主动学习问题中展现出了数据高效学习的优势。 |
| [^116] | [Rethinking AI Explainability and Plausibility.](http://arxiv.org/abs/2303.17707) | 本文研究了XAI评估中最普遍的人为概念——解释合理性。虽然一直被制定为AI可解释性任务的重要评估目标，但是评估XAI的合理性有时是有害的，且无法达到模型可理解性、透明度和可信度的目的。 |
| [^117] | [Explicit Planning Helps Language Models in Logical Reasoning.](http://arxiv.org/abs/2303.15714) | 本文提出了一个新的系统，使用语言模型进行多步逻辑推理，采用了显式规划来帮助做出更明智的决策，比其他竞争系统表现更好，显式规划在系统性能中起着关键作用。 |
| [^118] | [Requirements Engineering Framework for Human-centered Artificial Intelligence Software Systems.](http://arxiv.org/abs/2303.02920) | 该研究提出了一个基于以人为中心的人工智能指南和用户调查开发的框架，以帮助收集和建模人工智能的以人为中心的软件需求，并在一项案例研究中成功应用于提高360度视频质量。 |
| [^119] | [Zero-Shot Batch-Level Anomaly Detection.](http://arxiv.org/abs/2302.07849) | 本文提出了一种名为“自适应中心表示”的方法，用于零样本批次级异常检测。该方法利用批量归一化来训练现成的深度异常检测器，可以自动零样本泛化为未见过的AD任务。在实验中，该方法显示出了在多种数据集上的优秀表现，对表格数据进行了零样本AD。 |
| [^120] | [PubGraph: A Large-Scale Scientific Knowledge Graph.](http://arxiv.org/abs/2302.02231) | PubGraph是一个大规模的、全面的科学知识图谱，包含超过3.85亿个实体和130亿个主要边缘，可以支持对科学网络进行推理研究。 |
| [^121] | [DiSProD: Differentiable Symbolic Propagation of Distributions for Planning.](http://arxiv.org/abs/2302.01491) | DiSProD是一个用于连续状态和动作空间中概率转移的在线规划器，它可以通过使用概率分布近似传播生成可微分的符号图表示策略价值，在处理稀疏奖励和随机环境方面优于现有规划器。 |
| [^122] | [Zero-shot causal learning.](http://arxiv.org/abs/2301.12292) | 无先验因果学习是一个解决预测新型干预措施个性化影响的框架，并通过元学习对任务的处理达成了目的，能够将干预措施的知识传输到未见过的干预措施中，并在合成和真实数据集上表现出了优越性能。 |
| [^123] | [One Model for All Domains: Collaborative Domain-Prefix Tuning for Cross-Domain NER.](http://arxiv.org/abs/2301.10410) | 本论文提出了基于协作域前缀调整的跨领域实体识别，使用文本到文本生成的支撑领域相关指导来将知识转移至新域NER任务，避免了先前的为每个领域结束一个全新的NER模型的问题。 |
| [^124] | [CaRE: Finding Root Causes of Configuration Issues in Highly-Configurable Robots.](http://arxiv.org/abs/2301.07690) | 本文提出了CaRE方法，通过学习因果结构并估计选项对机器人性能指标的因果效应来抽象各种配置选项与机器人性能目标之间的因果关系，用于诊断高度可配置机器人的功能故障的根本原因。 |
| [^125] | [Deep reinforcement learning for irrigation scheduling using high-dimensional sensor feedback.](http://arxiv.org/abs/2301.00899) | 本文介绍了一个使用深度强化学习进行灌溉调度的原则性框架和可行的程序，并在澳大利亚一个产出高的地区使用灌溉小麦的案例研究中证明了其有效性。 |
| [^126] | [Execution-Based Evaluation for Open-Domain Code Generation.](http://arxiv.org/abs/2212.10481) | ODEX是第一个基于开放域执行的自然语言到Python代码生成数据集。CODEX和CODEGEN分别表现不同的行为。ODEx将有助于进一步研究代码生成的开放域问题。 |
| [^127] | [Foveate, Attribute, and Rationalize: Towards Physically Safe and Trustworthy AI.](http://arxiv.org/abs/2212.09667) | 研究提出了一种新颖的FARM框架，通过利用外部知识生成能够被信任的原理，解决了不安全文本检测的问题，并能够帮助利益相关者和政策制定者保障消费者的安全。 |
| [^128] | [Causes and Cures for Interference in Multilingual Translation.](http://arxiv.org/abs/2212.07530) | 研究探究了多语言机器翻译中干扰的主要因素，通过系统化试验发现使用不到10亿参数的标准Transformer配置可以在很大程度上缓解干扰并促进协同，同时发现调整采样温度以控制数据中每个语言对所占比例的方法是平衡语言对之间关系的关键。 |
| [^129] | [SODA: A Natural Language Processing Package to Extract Social Determinants of Health for Cancer Studies.](http://arxiv.org/abs/2212.03000) | 本文介绍了一个开源的自然语言处理包SODA，可用于提取癌症患者的社会健康决定因素。该包在泛化能力方面表现良好，可以用于新的疾病领域。研究结果表明，该包在癌症人群中提取SDoH的提取率较高。 |
| [^130] | [Analysis of Utterance Embeddings and Clustering Methods Related to Intent Induction for Task-Oriented Dialogue.](http://arxiv.org/abs/2212.02021) | 本文旨在研究任务导向对话中的意图识别问题，并提出两个关键因素：聚类算法和用户话语嵌入空间。实验证明，利用预训练的MiniLM与层次聚类相结合可以显著提高意图归纳任务的效果。 |
| [^131] | [On the Complexity of Counterfactual Reasoning.](http://arxiv.org/abs/2211.13447) | 该研究发现，与在完全指定的结构因果模型上进行关联或干预推理相比，反事实推理的计算复杂性并不更高，两者的复杂性可以通过关于树宽的边界界定得到较好的处理。 |
| [^132] | [VATLM: Visual-Audio-Text Pre-Training with Unified Masked Prediction for Speech Representation Learning.](http://arxiv.org/abs/2211.11275) | 本文提出了一个名为VATLM的统一跨模式表示学习框架，利用视听文本资料的预处理与一种统一的遮蔽预测任务进行优化，以达到优秀的联合多模态表示效果。 |
| [^133] | [Differentiable Model Selection for Ensemble Learning.](http://arxiv.org/abs/2211.00251) | 本文提出了一种可微分模型选择框架，专为集成学习而设计，通过将集成学习任务转化为可微分选择程序，在集成学习模型内端到端地训练学习为特定输入样本选择合适的集成成员，有效性和多功能性均优于传统和先进的共识规则。 |
| [^134] | [Phantom -- A RL-driven multi-agent framework to model complex systems.](http://arxiv.org/abs/2210.06012) | Phantom是一个开源的驱动RL的代理建模框架，可以简化ABM规范，适用于建模复杂多智能体系统，包括经济系统和市场等。 |
| [^135] | [Understanding HTML with Large Language Models.](http://arxiv.org/abs/2210.03945) | 本研究使用大型语言模型探索了对HTML的理解，提出了HTML理解模型，通过微调使其在语义分类、描述生成和自主网络导航三个任务上表现出良好的性能，显示出大型语言模型在HTML任务上表现出色。 |
| [^136] | [Benign Autoencoders.](http://arxiv.org/abs/2210.00637) | 本文正式化了用于生成式人工智能中编码器-解码器对的最佳选择问题并提出了良性自编码器（BAE），BAE能够将数据投射到最优的流型上，实现了数据压缩和更加稳定的梯度下降。 |
| [^137] | [Federated Learning via Decentralized Dataset Distillation in Resource-Constrained Edge Environments.](http://arxiv.org/abs/2208.11311) | 本论文介绍了一种名为FedD3的联邦学习框架，通过集成数据集提炼实例仅需要一次通信，与其他联邦学习方法相比，在需要通信的数据量方面表现显著更好，同时通过平衡准确性和通信成本来适应使用场景。 |
| [^138] | [Vehicle Type Specific Waypoint Generation.](http://arxiv.org/abs/2208.04987) | 开发了一种通用机制，利用车型控制器的副产品条件专门于某一车型的行为预测模型，结合概率行为模型生成车型特定的航点序列。 |
| [^139] | [An Experimental Evaluation of Machine Learning Training on a Real Processing-in-Memory System.](http://arxiv.org/abs/2207.07886) | 该研究评估了在处理内存系统上训练机器学习算法的潜能，并证明基于PIM的ML训练实现了显着的加速和能量效率。 |
| [^140] | [Towards the Practical Utility of Federated Learning in the Medical Domain.](http://arxiv.org/abs/2207.03075) | 本研究提出了应用联邦学习于医学领域的实用指南，包括三个具有代表性的医学数据集的实验，旨在提高医保业的数据效率，并形成适用于全行业的标准。 |
| [^141] | [Probabilistic Symmetry for Multi-Agent Dynamics.](http://arxiv.org/abs/2205.01927) | 该论文提出了PECCO模型，通过利用多智能体间的对称性和能量评分规则，可以更准确地预测多智能体轨迹并量化不确定性，为下游决策提供重要支持。 |
| [^142] | [Are Transformers More Robust? Towards Exact Robustness Verification for Transformers.](http://arxiv.org/abs/2202.03932) | 本文研究了基于Sparsemax的Transformers的稳健性问题，并发现Transformer不一定比传统的多层感知器更加稳健，这对于选择适用于安全关键领域应用的NN架构方面有深刻的考虑。 |

# 详细

[^1]: 基于fMRI的语言编码模型的规模定律研究

    Scaling laws for language encoding models in fMRI. (arXiv:2305.11863v1 [cs.CL])

    [http://arxiv.org/abs/2305.11863](http://arxiv.org/abs/2305.11863)

    本文揭示了基于fMRI的语言编码模型预测性能与模型大小呈对数线性关系，在125M到30B参数模型进行规模扩展时，表现提高了约15％。

    

    基于变压器的单向语言模型的表示已被证明能够有效地预测大脑对自然语言的反应。然而，大多数比较语言模型与大脑的研究都使用了类似GPT-2大小的语言模型。本研究测试了是否更大的开源模型（如OPT和LLaMA系列）更适用于预测使用fMRI记录的大脑反应。结果显示，在从125M到30B参数模型进行规模扩展时，大脑预测性能与模型大小呈对数线性关系，跨3个受试者的保留测试集相关性表现提高了约15％。当扩展fMRI训练集的大小时，我们也观察到了类似的对数线性行为。我们还对使用HuBERT，WavLM和Whisper的声学编码模型进行了规模定律研究，发现模型大小的增加带来了类似的改进。我们还使用噪音天花板分析了这些大规模且高性能的编码模型。

    Representations from transformer-based unidirectional language models are known to be effective at predicting brain responses to natural language. However, most studies comparing language models to brains have used GPT-2 or similarly sized language models. Here we tested whether larger open-source models such as those from the OPT and LLaMA families are better at predicting brain responses recorded using fMRI. Mirroring scaling results from other contexts, we found that brain prediction performance scales log-linearly with model size from 125M to 30B parameter models, with ~15% increased encoding performance as measured by correlation with a held-out test set across 3 subjects. Similar log-linear behavior was observed when scaling the size of the fMRI training set. We also characterized scaling for acoustic encoding models that use HuBERT, WavLM, and Whisper, and we found comparable improvements with model size. A noise ceiling analysis of these large, high-performance encoding models 
    
[^2]: 使用指令微调基础模型的多模态 Web 导航。

    Multimodal Web Navigation with Instruction-Finetuned Foundation Models. (arXiv:2305.11854v1 [cs.LG])

    [http://arxiv.org/abs/2305.11854](http://arxiv.org/abs/2305.11854)

    本文研究使用视觉语言基础模型进行数据驱动离线训练的 Web 代理，提出了一个指令跟随多模态代理WebGUM，将微调指令微调语言模型和视觉转换器，能够有效提高代理的基于视觉感知、HTML 理解和多步推理的能力。

    

    自主 Web 导航的进展受到了依赖数十亿次在线强化学习的探索性交互和具有领域特定模型设计的影响，这使得难以利用来自丰富领域外数据的泛化。在本工作中，我们研究了基于数据驱动的脱机训练，用于使用视觉语言基础模型的 Web 代理。我们提出了一个指令跟随多模态代理， WebGUM，它观察了网页截图和 HTML 页面，并输出 Web 导航操作，如单击和输入。WebGUM 是通过联合微调指令微调语言模型和视觉转换器在大量的演示语料库上训练的。我们凭经验证明，这种方法可以提高代理的基于视觉感知、HTML 理解和多步推理的能力，明显优于之前的工作。在 MiniWoB 基准测试中，我们超过之前最佳脱机方法 31.9% 以上，接近实现在线交互的表现。

    The progress of autonomous web navigation has been hindered by the dependence on billions of exploratory interactions via online reinforcement learning, and domain-specific model designs that make it difficult to leverage generalization from rich out-of-domain data. In this work, we study data-driven offline training for web agents with vision-language foundation models. We propose an instruction-following multimodal agent, WebGUM, that observes both webpage screenshots and HTML pages and outputs web navigation actions, such as click and type. WebGUM is trained by jointly finetuning an instruction-finetuned language model and a vision transformer on a large corpus of demonstrations. We empirically demonstrate this recipe improves the agent's ability of grounded visual perception, HTML comprehension and multi-step reasoning, outperforming prior works by a significant margin. On the MiniWoB benchmark, we improve over the previous best offline methods by more than 31.9%, being close to re
    
[^3]: RxnScribe：反应图解析的序列生成模型

    RxnScribe: A Sequence Generation Model for Reaction Diagram Parsing. (arXiv:2305.11845v1 [cs.CL])

    [http://arxiv.org/abs/2305.11845](http://arxiv.org/abs/2305.11845)

    RxnScribe是一种端到端的机器学习模型，用于解析化学文献中复杂的反应图，并在交叉验证中取得了较高的分数。

    

    反应图解析是从化学文献中提取反应方案的任务。反应图可以极其复杂，因此将其稳健地解析成结构化数据是一个开放性挑战。在本文中，我们提出了RxnScribe，这是一个用于解析不同风格反应图的机器学习模型。我们采用序列生成方法来制定这个结构化预测任务，将传统的管道流程压缩为端到端的模型。我们在一个包含1,378个图的数据集上训练RxnScribe，并进行交叉验证评估，实现了80.0%的软匹配F1分数，与以前的模型相比有显著的改进。我们的代码和数据可以在https://github.com/thomas0809/RxnScribe 上公开获取。

    Reaction diagram parsing is the task of extracting reaction schemes from a diagram in the chemistry literature. The reaction diagrams can be arbitrarily complex, thus robustly parsing them into structured data is an open challenge. In this paper, we present RxnScribe, a machine learning model for parsing reaction diagrams of varying styles. We formulate this structured prediction task with a sequence generation approach, which condenses the traditional pipeline into an end-to-end model. We train RxnScribe on a dataset of 1,378 diagrams and evaluate it with cross validation, achieving an 80.0% soft match F1 score, with significant improvements over previous models. Our code and data are publicly available at https://github.com/thomas0809/RxnScribe.
    
[^4]: AI 的表现形式：南亚文字到图像模型的社区中心研究

    AI's Regimes of Representation: A Community-centered Study of Text-to-Image Models in South Asia. (arXiv:2305.11844v1 [cs.CY])

    [http://arxiv.org/abs/2305.11844](http://arxiv.org/abs/2305.11844)

    本文探讨南亚文化背景下文字到图像模型的文化限制，并将其归因于全球和地区权力不平等所塑造的外来视角。通过将社区视为专家，对T2I的限制进行研究，深入了解文化特定的AI技术在非西方和南球地区上失败的原因。建议负责任地开发T2I模型，以允许对结构性不平等性的认识。

    

    本文提出了一种社区中心的研究方法，来探讨南亚文化背景下文字到图像（T2I）模型的文化限制。我们使用支配性的媒体表现形式的学术理论来阐述这些失败，并将它们定位于参与者对他们现有社会边缘化的报告上。因此，我们展示了生成AI会再现一种外部人眼中看待南亚文化的视角，这种视角是由全球和地区权力不平等所塑造的。通过将社区视为专家并征求他们对T2I限制的看法，我们的研究为现有的评估框架增添了丰富的细节，并加深了我们对文化特定的AI技术在非西方和南球地区上失败的理解。我们总结出了负责任地开发T2I模型的教训，推荐具体的前进路径，以允许对结构性不平等性的认识。

    This paper presents a community-centered study of cultural limitations of text-to-image (T2I) models in the South Asian context. We theorize these failures using scholarship on dominant media regimes of representations and locate them within participants' reporting of their existing social marginalizations. We thus show how generative AI can reproduce an outsiders gaze for viewing South Asian cultures, shaped by global and regional power inequities. By centering communities as experts and soliciting their perspectives on T2I limitations, our study adds rich nuance into existing evaluative frameworks and deepens our understanding of the culturally-specific ways AI technologies can fail in non-Western and Global South settings. We distill lessons for responsible development of T2I models, recommending concrete pathways forward that can allow for recognition of structural inequalities.
    
[^5]: 使用ChatGPT比较软件开发人员：一项实证调查

    Comparing Software Developers with ChatGPT: An Empirical Investigation. (arXiv:2305.11837v1 [cs.SE])

    [http://arxiv.org/abs/2305.11837](http://arxiv.org/abs/2305.11837)

    这篇论文调查了ChatGPT与软件开发人员的比较，认为全面的实证研究可以帮助回答基于AI的计算是否可以提高生产力甚至取代软件工程师进行软件开发的争议。

    

    自动化在软件工程（SE）中的应用已从理论到现实中转变。许多学术文章记录了人工智能成功应用于项目管理、建模、测试和开发等领域的案例。最近的创新是引入了ChatGPT，这是一个被吹捧为能够生成编程代码和为开发人员提供软件测试策略的机器学习聊天机器人。虽然有猜测认为基于AI的计算可以提高生产力甚至取代软件工程师进行软件开发，但目前缺乏实证证据来验证这一点。此外，尽管AI系统的主要重点在于增强准确性，但非功能性要求包括能源效率、漏洞、公平性（即人为偏见）和安全性经常受到不足的关注。本文认为，全面的实证研究可以帮助回答这些问题。

    The advent of automation in particular Software Engineering (SE) tasks has transitioned from theory to reality. Numerous scholarly articles have documented the successful application of Artificial Intelligence to address issues in areas such as project management, modeling, testing, and development. A recent innovation is the introduction of ChatGPT, an ML-infused chatbot, touted as a resource proficient in generating programming codes and formulating software testing strategies for developers and testers respectively. Although there is speculation that AI-based computation can increase productivity and even substitute software engineers in software development, there is currently a lack of empirical evidence to verify this. Moreover, despite the primary focus on enhancing the accuracy of AI systems, non-functional requirements including energy efficiency, vulnerability, fairness (i.e., human bias), and safety frequently receive insufficient attention. This paper posits that a comprehe
    
[^6]: 神经网络训练的复杂性及ETR: 有效连续函数拓展

    Complexity of Neural Network Training and ETR: Extensions with Effectively Continuous Functions. (arXiv:2305.11833v1 [cs.LO])

    [http://arxiv.org/abs/2305.11833](http://arxiv.org/abs/2305.11833)

    本文研究了神经网络训练问题的复杂性，证明了sigmoid激活函数与实数存在性理论和指数函数相关，这使得神经网络在使用sigmoid激活函数时算法可解性存在疑问。同时，使用正弦激活函数时训练问题是不可判定的。

    

    本文研究了通过不同激活函数定义的神经网络训练问题的复杂性。对于线性和ReLU激活函数而言，已知训练问题是存在R-完备的。我们考虑了sigmoid激活函数和其他有效连续函数的问题复杂性。我们证明了这些训练问题可在多项式时间的 many-one 可还原到关于相应激活函数拓展的实数存在性理论上。特别地，我们证明了sigmoid激活函数导致了带有指数函数的实数存在性理论。因此，使用sigmoid激活函数训练神经网络是否具有算法可解性以及实数存在性理论和指数函数的可判定性等问题都是开放的。相反，在使用正弦激活函数时，我们发现训练问题是不可判定的。

    We study the complexity of the problem of training neural networks defined via various activation functions. The training problem is known to be existsR-complete with respect to linear activation functions and the ReLU activation function. We consider the complexity of the problem with respect to the sigmoid activation function and other effectively continuous functions. We show that these training problems are polynomial-time many-one bireducible to the existential theory of the reals extended with the corresponding activation functions. In particular, we establish that the sigmoid activation function leads to the existential theory of the reals with the exponential function. It is thus open, and equivalent with the decidability of the existential theory of the reals with the exponential function, whether training neural networks using the sigmoid activation function is algorithmically solvable. In contrast, we obtain that the training problem is undecidable if sinusoidal activation f
    
[^7]: 自动温度调整的软性演员评论算法的正则化

    Regularization of Soft Actor-Critic Algorithms with Automatic Temperature Adjustment. (arXiv:2305.11831v1 [cs.LG])

    [http://arxiv.org/abs/2305.11831](http://arxiv.org/abs/2305.11831)

    本文提出了正则化自动温度调整的软性演员评论算法，增加了对原理的明确性。

    

    本文提出了一种使用自动温度调整的软性演员评论（SAC）算法的正则化方法，并对策略评估、策略改进和温度调整进行重新定义和修改，以更加明确地阐述原理。

    This work presents a comprehensive analysis to regularize the Soft Actor-Critic (SAC) algorithm with automatic temperature adjustment. The the policy evaluation, the policy improvement and the temperature adjustment are reformulated, addressing certain modification and enhancing the clarity of the original theory in a more explicit manner.
    
[^8]: LLM在医学系统综述中的潜在用途和风险评估

    Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews. (arXiv:2305.11828v1 [cs.CL])

    [http://arxiv.org/abs/2305.11828](http://arxiv.org/abs/2305.11828)

    本文研究了使用LLM协助制作医学证据综述的潜在用途和风险，指出LLM有可能自动生成文献综述，但由于可能出现虚构或遗漏信息的情况，LLM的使用需要谨慎。

    

    医学系统综述对于制定临床决策和医疗政策至关重要。但是制作这样的综述很费力且耗时。因此，很多问题缺乏高质量的证据综述，即使这些综述可用，在审查过程中可能已经过时。现在，大型语言模型（LLM）已经能够生成长篇文本，这意味着自动生成文献综述的诱人可能性。然而，由于虚构或遗漏重要信息，LLM有时会产生不准确（甚至可能具有误导性）的文本。在医疗保健环境中，这可能使LLM在最好情况下无法使用，在最坏情况下会带来危险。对于LLM的益处和风险的大多数讨论与具体应用脱离了关系。在这项工作中，我们试图定性描述LLM在协助制作医学证据综述方面的潜在用途和风险。我们对16位国际专家进行了半结构化访谈。

    Medical systematic reviews are crucial for informing clinical decision making and healthcare policy. But producing such reviews is onerous and time-consuming. Thus, high-quality evidence synopses are not available for many questions and may be outdated even when they are available. Large language models (LLMs) are now capable of generating long-form texts, suggesting the tantalizing possibility of automatically generating literature reviews on demand. However, LLMs sometimes generate inaccurate (and potentially misleading) texts by hallucinating or omitting important information. In the healthcare context, this may render LLMs unusable at best and dangerous at worst. Most discussion surrounding the benefits and risks of LLMs have been divorced from specific applications. In this work, we seek to qualitatively characterize the potential utility and risks of LLMs for assisting in production of medical evidence reviews. We conducted 16 semi-structured interviews with international experts
    
[^9]: STOAT: 结构化数据控制性分析文本生成

    STOAT: Structured Data to Analytical Text With Controls. (arXiv:2305.11826v1 [cs.CL])

    [http://arxiv.org/abs/2305.11826](http://arxiv.org/abs/2305.11826)

    STOAT模型是表格和推理意识的生成模型，在数字推理、常识推理、时间推理、表格知识和实体知识方面有较好的控制，提高了分析句子生成的质量和准确度。

    

    最近，语言模型在结构化数据到文本生成任务中取得了巨大的进展。然而，当需要进行逻辑推理以生成描述时，这些模型仍然表现出次优的性能。在本文中，我们特别关注从结构化数据（例如表格）生成分析文本。在（Gupta et al.,2020）提出的分类基础上，我们重点关注以下推理类别的可控制表格到文本生成：数字推理、常识推理、时间推理、表格知识和实体知识。我们提出了STOAT模型，该模型具有表格和推理意识，并通过矢量量化将给定的推理类别注入输出中。我们观察到，在分析句子任务中，我们的模型在iToTTo和Infotabs的PARENT指标上分别提供了10.19％和1.13％的优化。我们还发现，与基线模型相比，我们的模型生成的描述更加准确和分析，人类评估中增加了15.3％。

    Recent language models have made tremendous progress in the structured data to text generation task. However, these models still give sub-optimal performance where logical inference is required to generate the descriptions. In this work, we specifically focus on analytical text generation from structured data such as tables. Building on the taxonomy proposed in (Gupta et al., 2020) we focus on controllable table to text generation for the following reasoning categories: numerical reasoning, commonsense reasoning, temporal reasoning, table knowledge, and entity knowledge. We propose STOAT model, which is table and reasoning aware, with vector-quantization to infuse the given reasoning categories in the output. We observe that our model provides 10.19%, 1.13% improvement on the PARENT metric in iToTTo and Infotabs for the analytical sentence task. We also found that our model generates 15.3% more faithful and analytical descriptions as compared to the baseline models in human evaluation.
    
[^10]: 战略卡牌游戏人工智能比赛总结

    Summarizing Strategy Card Game AI Competition. (arXiv:2305.11814v1 [cs.AI])

    [http://arxiv.org/abs/2305.11814](http://arxiv.org/abs/2305.11814)

    本文总结了基于《魔法与代码英雄》（LOCM）的五年人工智能比赛，介绍了游戏规则以及比赛历史，给出了组织AI比赛的建议。LOCM已被用于许多与游戏树搜索算法、神经网络、评估函数和CCG卡组构建等相关领域的出版物中。

    

    本文总结了基于《魔法与代码英雄》（LOCM）的五年人工智能比赛，这是一个旨在支持研究和算法开发的小型收集卡牌游戏（CCG）。该游戏被用于多个事件中，包括CodinGame平台上的社区比赛，以及IEEE进化计算大会和IEEE游戏会议上的战略卡牌游戏人工智能比赛。LOCM已被用于许多与游戏树搜索算法、神经网络、评估函数和CCG卡组构建等相关领域的出版物中。本文介绍了游戏规则、组织比赛的历史以及参赛者和他们的方法，并提供了有关为研究社区组织人工智能比赛的一些常规建议。尽管COG 2022版宣布是最后一版，但游戏仍然可用，并可在在线排行榜竞技场上进行游玩。

    This paper concludes five years of AI competitions based on Legends of Code and Magic (LOCM), a small Collectible Card Game (CCG), designed with the goal of supporting research and algorithm development. The game was used in a number of events, including Community Contests on the CodinGame platform, and Strategy Card Game AI Competition at the IEEE Congress on Evolutionary Computation and IEEE Conference on Games. LOCM has been used in a number of publications related to areas such as game tree search algorithms, neural networks, evaluation functions, and CCG deckbuilding. We present the rules of the game, the history of organized competitions, and a listing of the participant and their approaches, as well as some general advice on organizing AI competitions for the research community. Although the COG 2022 edition was announced to be the last one, the game remains available and can be played using an online leaderboard arena.
    
[^11]: Dec-POMDP中的Monte Carlo搜索算法寻找均衡

    Monte-Carlo Search for an Equilibrium in Dec-POMDPs. (arXiv:2305.11811v1 [cs.AI])

    [http://arxiv.org/abs/2305.11811](http://arxiv.org/abs/2305.11811)

    本文在Dec-POMDP领域使用了Monte Carlo搜索算法来寻找纳什均衡，最终的基准实验表明MC-JESP可以有效解决控制器问题并达到预期效果。

    

    去中心化部分可观察马尔可夫决策过程（Dec-POMDPs）正式表述了在随机动态和部分可观测性下为一组协作代理设计各自控制器的问题。寻求全局最优解是困难的（NEXP完全），但寻求纳什均衡 - 每个代理策略都是对其他代理的最佳响应问题 - 更容易，同时允许以有限状态控制器的形式解决无限地平线问题。在这篇论文中，我们展示了这种方法可以适用于仅可用Dec-POMDP的生成模型（模拟器）的情况。这需要依靠基于模拟的POMDP求解器逐个节点地构建代理的FSC节点。相关过程用于启发式地导出初始的FSC。基准实验表明，MC-JESP与现有的Dec-POMDP求解器竞争力强，甚至比使用显式模型的许多离线方法更好。

    Decentralized partially observable Markov decision processes (Dec-POMDPs) formalize the problem of designing individual controllers for a group of collaborative agents under stochastic dynamics and partial observability. Seeking a global optimum is difficult (NEXP complete), but seeking a Nash equilibrium -- each agent policy being a best response to the other agents -is more accessible, and allowed addressing infinite-horizon problems with solutions in the form of finite state controllers. In this paper, we show that this approach can be adapted to cases where only a generative model (a simulator) of the Dec-POMDP is available. This requires relying on a simulation-based POMDP solver to construct an agent's FSC node by node. A related process is used to heuristically derive initial FSCs. Experiment with benchmarks shows that MC-JESP is competitive with exisiting Dec-POMDP solvers, even better than many offline methods using explicit models.
    
[^12]: 私有集成模型的公平影响研究

    On the Fairness Impacts of Private Ensembles Models. (arXiv:2305.11807v1 [cs.LG])

    [http://arxiv.org/abs/2305.11807](http://arxiv.org/abs/2305.11807)

    本文探讨了私有教师集成（PATE）模型是否会导致不公平性，并证明它可能导致不同群体之间的准确性差异。建议在PATE的应用中加入公平性考虑，以减少不公平性的影响。

    

    私有教师集成（PATE）是一种机器学习框架，通过多个“教师”模型和一个“学生”模型的组合来创建私有模型。学生模型学习预测基于教师的投票的输出，生成的模型满足差分隐私。已经证明PATE在半监督设置或保护数据标签是优先的情况下创建私有模型是有效的。本文探讨了使用PATE是否会导致不公平，并证明它可能导致不同群体之间的准确性差异。本文还分析了算法和数据属性对这些不成比例的影响的贡献，以及为什么这些方面会不成比例地影响不同的群体，并提出了缓解这些影响的建议。

    The Private Aggregation of Teacher Ensembles (PATE) is a machine learning framework that enables the creation of private models through the combination of multiple "teacher" models and a "student" model. The student model learns to predict an output based on the voting of the teachers, and the resulting model satisfies differential privacy. PATE has been shown to be effective in creating private models in semi-supervised settings or when protecting data labels is a priority. This paper explores whether the use of PATE can result in unfairness, and demonstrates that it can lead to accuracy disparities among groups of individuals. The paper also analyzes the algorithmic and data properties that contribute to these disproportionate impacts, why these aspects are affecting different groups disproportionately, and offers recommendations for mitigating these effects
    
[^13]: LLM的思路链索引用于回答深入对话问题的提示

    Chain-of-thought prompting for responding to in-depth dialogue questions with LLM. (arXiv:2305.11792v1 [cs.CL])

    [http://arxiv.org/abs/2305.11792](http://arxiv.org/abs/2305.11792)

    本文提出使用思路链索引的方式来响应用户状态，以提供更个性化和更有吸引力的用户体验，用语义相似性而非测试查询做中间推理处理。

    

    用户提问的方式和内容可以洞察他们的当前状态，包括人格、情感和心理状态。本文提出使用思路链索引的方式来帮助大型语言模型进行推理和规划，以响应用户状态，以提供更个性化和更有吸引力的用户体验。我们首先建立了一个包括6个英语和中文的对话或问答数据集的基准，涵盖了用户状态的3个不同方面（包括人格、情感和心理）。然后，我们提示语言模型生成关于用户状态的响应作为中间推理处理。我们提出了一种使用中间推理的语义相似性而非测试查询的新颖演示选择策略。为了评估我们的方法的有效性和鲁棒性，我们进行了广泛的实验。

    The way and content in which users ask questions can provide insight into their current status, including their personality, emotions, and psychology. Instead of directly prompting the large language models (LLMs), we explore how chain-of-thought prompting helps in this scenario to perform reasoning and planning according to user status, aiming to provide a more personalized and engaging experience for the user query. To this end, we first construct a benchmark of 6 dialogue or question-answering datasets in both English and Chinese, covering 3 different aspects of user status (\textit{including} \textit{personality}, \textit{emotion}, and \textit{psychology}). Then we prompt the LLMs to generate the response regarding the user status as intermediate reasoning processing. We propose a novel demonstration selection strategy using the semantic similarity of intermediate reasoning instead of test queries. To evaluate the effectiveness and robustness of our approach, we conduct extensive e
    
[^14]: DMDD：面向数据集提及检测的大规模数据集

    DMDD: A Large-Scale Dataset for Dataset Mentions Detection. (arXiv:2305.11779v1 [cs.CL])

    [http://arxiv.org/abs/2305.11779](http://arxiv.org/abs/2305.11779)

    DMDD是一个公开的数据集，用于数据集提及检测任务，包含31,219篇科学文章和超过449,000个弱注释的数据集提及。该数据集为该任务建立了基准性能，并且通过分析模型的表现，确定了开放问题。

    

    数据集名称识别是科学文献自动信息提取的关键任务，可以帮助研究人员理解和识别研究机会。然而，现有的用于数据集提及检测的语料库在大小和命名多样性方面存在局限性。本文介绍了数据集提及检测数据集（DMDD），这是当前最大的公开语料库，用于处理这项任务。DMDD由DMDD主要语料库和评估集组成，其中DMDD主要语料库包括31,219篇科学文章，其中包含超过449,000个数据集提及弱注释格式的文本段，评估集包括450篇手动注释的科学文章，用于评估目的。我们使用DMDD建立了数据集提及检测和链接的基准性能。通过分析各种模型在DMDD上的表现，我们能够确定数据集提及检测中存在的问题。我们邀请社区使用我们的数据集作为挑战，开发新的数据集提及检测模型。

    The recognition of dataset names is a critical task for automatic information extraction in scientific literature, enabling researchers to understand and identify research opportunities. However, existing corpora for dataset mention detection are limited in size and naming diversity. In this paper, we introduce the Dataset Mentions Detection Dataset (DMDD), the largest publicly available corpus for this task. DMDD consists of the DMDD main corpus, comprising 31,219 scientific articles with over 449,000 dataset mentions weakly annotated in the format of in-text spans, and an evaluation set, which comprises of 450 scientific articles manually annotated for evaluation purposes. We use DMDD to establish baseline performance for dataset mention detection and linking. By analyzing the performance of various models on DMDD, we are able to identify open problems in dataset mention detection. We invite the community to use our dataset as a challenge to develop novel dataset mention detection mo
    
[^15]: 神经基础中的心理模拟：预测动态场景中的潜在表现

    Neural Foundations of Mental Simulation: Future Prediction of Latent Representations on Dynamic Scenes. (arXiv:2305.11772v1 [cs.AI])

    [http://arxiv.org/abs/2305.11772](http://arxiv.org/abs/2305.11772)

    本研究探究了人类和动物如何推断物理世界的基本动态轨迹以及如何预测未来可能出现的状态，并评估了几类感知-认知网络的预测能力，发现在效率、普遍性和可解释性间存在权衡。

    

    人和动物对物理世界有着丰富而灵活的理解，能够推断出事件的基本动态轨迹，预测未来可能出现的状态，并利用这些信息规划和预测行为的后果。然而，这些计算背后的神经机制尚不清楚。本文采用目标驱动的建模方法，结合密集的神经生理学数据和高通量的人类行为输出来探究这个问题。具体来说，我们构建和评估了几类感知-认知网络来预测丰富、具有行为学意义的环境的未来状态，从像素或面向对象目标的自主监督端到端模型，到将纯静态基于图像或动态视频的预训练基础模型的潜在空间进行未来预测的模型。我们发现这些模型类别在其预测神经和行为数据的能力上有很强的差异，无论在其培训领域内或外，这种差异反映了效率、普遍性和可解释性之间的基本权衡。

    Humans and animals have a rich and flexible understanding of the physical world, which enables them to infer the underlying dynamical trajectories of objects and events, plausible future states, and use that to plan and anticipate the consequences of actions. However, the neural mechanisms underlying these computations are unclear. We combine a goal-driven modeling approach with dense neurophysiological data and high-throughput human behavioral readouts to directly impinge on this question. Specifically, we construct and evaluate several classes of sensory-cognitive networks to predict the future state of rich, ethologically-relevant environments, ranging from self-supervised end-to-end models with pixel-wise or object-centric objectives, to models that future predict in the latent space of purely static image-based or dynamic video-based pretrained foundation models. We find strong differentiation across these model classes in their ability to predict neural and behavioral data both w
    
[^16]: 提升联合学习的视觉语言预训练：基于联合学习的问答与密集字幕生成

    Enhancing Vision-Language Pre-Training with Jointly Learned Questioner and Dense Captioner. (arXiv:2305.11769v1 [cs.CV])

    [http://arxiv.org/abs/2305.11769](http://arxiv.org/abs/2305.11769)

    本文提出了一种名为JADE的新方法，可以利用易于获取的图像-文本对进行的联合学习，以提升视觉和语言模态的细粒度特征对齐，从而更好地进行视觉问答和密集字幕生成。

    

    大型预先训练的多模态模型在许多下游任务中都表现出显著的成功，包括图像字幕生成、图像文本检索和视觉问答等。然而，许多方法都依赖于从网络上收集的图像-文本对作为预先训练的数据，忽视了视觉和语言模态之间需要细粒度特征对齐的需求，这需要对图像和语言表达进行详细的理解。将视觉问答和密集字幕集成到预先训练中可以解决这个问题，但是获取图像-问题-答案以及图像-位置-字幕三元组是具有挑战性和耗时的。此外，公开可用的视觉问答和密集字幕数据集通常由于手动数据收集和标注而规模有限。在本文中，我们提出了一种新方法，称为联合问答和密集字幕生成（JADE），它利用预先训练的多模态模型和易于获取的图像-文本对来进行模型训练。

    Large pre-trained multimodal models have demonstrated significant success in a range of downstream tasks, including image captioning, image-text retrieval, visual question answering (VQA), etc. However, many of these methods rely on image-text pairs collected from the web as pre-training data and unfortunately overlook the need for fine-grained feature alignment between vision and language modalities, which requires detailed understanding of images and language expressions. While integrating VQA and dense captioning (DC) into pre-training can address this issue, acquiring image-question-answer as well as image-location-caption triplets is challenging and time-consuming. Additionally, publicly available datasets for VQA and dense captioning are typically limited in scale due to manual data collection and labeling efforts. In this paper, we propose a novel method called Joint QA and DC GEneration (JADE), which utilizes a pre-trained multimodal model and easily-crawled image-text pairs to
    
[^17]: 通过Prompt-Tuning控制从大型语言模型中提取记忆数据

    Controlling the Extraction of Memorized Data from Large Language Models via Prompt-Tuning. (arXiv:2305.11759v1 [cs.CL])

    [http://arxiv.org/abs/2305.11759](http://arxiv.org/abs/2305.11759)

    该论文提出在大型语言模型中通过Prompt-Tuning策略来控制从中提取记忆数据的方法，提供了攻击和防御两种训练策略。在公共基准测试中展示了其在GPT-Neo模型中的有效性，攻击策略相对于基线产生了9.3%的提取率增加，而防御策略可以调整以实现不同的隐私-效用权衡，可以实现最多97.7%的提取率减少，但困惑度增加了16.9%。

    

    大型语言模型（LLMs）已知会记忆其训练数据的重要部分，并且简单查询模型即可提取记忆的内容，存在隐私风险。我们提出了一种新的方法，使用Prompt-Tuning来控制LLMs中记忆内容的提取率。我们提出了两个Prompt训练策略来增加和减少提取率，分别对应攻击和防御。我们使用来自GPT-Neo系列的模型在公共基准测试中展示了我们技术的有效性。对于1.3B参数的GPT-Neo模型，我们的攻击相对于基线产生了9.3个百分点的提取率增加。通过用户指定的超参数，我们的防御可以调整以实现不同的隐私-效用权衡。我们相对于基线实现了最多97.7%的提取率减少，同时困惑度增加了16.9%。

    Large Language Models (LLMs) are known to memorize significant portions of their training data. Parts of this memorized content have been shown to be extractable by simply querying the model, which poses a privacy risk. We present a novel approach which uses prompt-tuning to control the extraction rates of memorized content in LLMs. We present two prompt training strategies to increase and decrease extraction rates, which correspond to an attack and a defense, respectively. We demonstrate the effectiveness of our techniques by using models from the GPT-Neo family on a public benchmark. For the 1.3B parameter GPT-Neo model, our attack yields a 9.3 percentage point increase in extraction rate compared to our baseline. Our defense can be tuned to achieve different privacy-utility trade-offs by a user-specified hyperparameter. We achieve an extraction rate reduction of up to 97.7% relative to our baseline, with a perplexity increase of 16.9%.
    
[^18]: 推荐系统解释的可视化：综述和新视角

    Visualization for Recommendation Explainability: A Survey and New Perspectives. (arXiv:2305.11755v1 [cs.IR])

    [http://arxiv.org/abs/2305.11755](http://arxiv.org/abs/2305.11755)

    本文回顾了推荐系统中有关可视化解释的研究，提出了一组可能有益于设计解释性可视化推荐系统的指南。

    

    为推荐提供系统生成的解释是实现透明且值得信赖的推荐系统的重要步骤。可解释的推荐系统为输出提供了人类可理解的基础。在过去的20年中，可解释的推荐引起了推荐系统研究社区的广泛关注。本文旨在全面回顾推荐系统中有关可视化解释的研究工作。更具体地，我们根据解释目标、解释范围、解释样式和解释格式这四个维度系统地审查推荐系统中有关解释的文献。认识到可视化的重要性，我们从解释性视觉方式的角度途径推荐系统文献，即使用可视化作为解释的显示样式。因此，我们得出了一组可能有益于设计解释性可视化推荐系统的指南。

    Providing system-generated explanations for recommendations represents an important step towards transparent and trustworthy recommender systems. Explainable recommender systems provide a human-understandable rationale for their outputs. Over the last two decades, explainable recommendation has attracted much attention in the recommender systems research community. This paper aims to provide a comprehensive review of research efforts on visual explanation in recommender systems. More concretely, we systematically review the literature on explanations in recommender systems based on four dimensions, namely explanation goal, explanation scope, explanation style, and explanation format. Recognizing the importance of visualization, we approach the recommender system literature from the angle of explanatory visualizations, that is using visualizations as a display style of explanation. As a result, we derive a set of guidelines that might be constructive for designing explanatory visualizat
    
[^19]: MedLens: 通过选择医学体征和回归插值来提高死亡率预测

    MedLens: Improve mortality prediction via medical signs selecting and regression interpolation. (arXiv:2305.11742v1 [cs.LG])

    [http://arxiv.org/abs/2305.11742](http://arxiv.org/abs/2305.11742)

    本文介绍了一个自动选择医学体征和回归插值的方法（MedLens），用于解决电子病历中医学体征数据缺失率过高导致预测性能降低的问题。

    

    监测患者的健康状况并提前预测死亡率对及时提供患者护理和治疗至关重要。电子病历中的大量医学体征被用于先进的机器学习模型来进行预测。然而，原始临床体征的数据质量问题在文献中被较少讨论。通过对各种医学体征和大量患者住院记录中的缺失率和相关分数进行深入测量，我们发现综合缺失率非常高，大量无用的体征可能会损害预测模型的性能。我们得出结论，只有改善数据质量才能提高不同预测算法的基线准确性。我们设计了MedLens，通过统计自动选择重要医学体征，并使用灵活的插值方法处理高缺失率时间序列。

    Monitoring the health status of patients and predicting mortality in advance is vital for providing patients with timely care and treatment. Massive medical signs in electronic health records (EHR) are fitted into advanced machine learning models to make predictions. However, the data-quality problem of original clinical signs is less discussed in the literature. Based on an in-depth measurement of the missing rate and correlation score across various medical signs and a large amount of patient hospital admission records, we discovered the comprehensive missing rate is extremely high, and a large number of useless signs could hurt the performance of prediction models. Then we concluded that only improving data-quality could improve the baseline accuracy of different prediction algorithms. We designed MEDLENS, with an automatic vital medical signs selection approach via statistics and a flexible interpolation approach for high missing rate time series. After augmenting the data-quality 
    
[^20]: CRITIC：大型语言模型可以通过工具交互批评进行自我校正

    CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing. (arXiv:2305.11738v1 [cs.CL])

    [http://arxiv.org/abs/2305.11738](http://arxiv.org/abs/2305.11738)

    本文提出了一个名为CRITIC的框架，使得大型语言模型可以通过与工具的交互校正自己的错误，从而避免生成出现不一致和问题行为的结果。

    

    近年来，大型语言模型的发展非常引人注目。然而，这些模型有时会出现不一致和问题行为，例如出现幻觉事实，生成有缺陷的代码或创建冒犯和有害的内容。与这些模型不同，人类通常使用外部工具来交叉检查和精炼他们的初步内容，例如使用搜索引擎进行事实检查或使用代码解释器进行调试。受这一观察的启发，我们引入了一个名为CRITIC的框架，允许LLMs（实质上是“黑盒子”）以类似于人类与工具交互的方式验证和逐步修正自己的输出。更具体地说，从初始输出开始，CRITIC与适当的工具交互以评估文本的某些方面，然后根据在此验证过程中获得的反馈修改输出。涉及自由形式问答、数学程序综合和毒性检测的全面评估表明，我们的框架使LLMs能够从错误中学习并纠正自己的错误。

    Recent developments in large language models (LLMs) have been impressive. However, these models sometimes show inconsistencies and problematic behavior, such as hallucinating facts, generating flawed code, or creating offensive and toxic content. Unlike these models, humans typically utilize external tools to cross-check and refine their initial content, like using a search engine for fact-checking, or a code interpreter for debugging. Inspired by this observation, we introduce a framework called CRITIC that allows LLMs, which are essentially "black boxes" to validate and progressively amend their own outputs in a manner similar to human interaction with tools. More specifically, starting with an initial output, CRITIC interacts with appropriate tools to evaluate certain aspects of the text, and then revises the output based on the feedback obtained during this validation process. Comprehensive evaluations involving free-form question answering, mathematical program synthesis, and toxi
    
[^21]: 下一个会是什么？评估神经文本生成器的不确定性与人类生产变异性对比

    What Comes Next? Evaluating Uncertainty in Neural Text Generators Against Human Production Variability. (arXiv:2305.11707v1 [cs.CL])

    [http://arxiv.org/abs/2305.11707](http://arxiv.org/abs/2305.11707)

    本文分析了神经文本生成器与人类生产变异性之间的不确定性，通过探测生成器的输出空间来测量其对人类生产变异性的校准程度，并证明用多个样本和多个参考可以更好地了解模型的不确定性表示。

    

    在自然语言生成（NLG）任务中，针对任何输入，存在多个可行的交际目标，并且可以用多种方式将任何目标用语言表达出来或进行生产。我们表征了人类生产在四个NLG任务中词汇、句法和语义方面的变异程度，并将人类生产变异性与不确定性联系起来。然后，我们检查了生成系统预测的概率分布和解码算法所形成的输出字符串空间，以探究其不确定性。针对每个测试输入，我们测量了生成器对人类生产变异性的校准程度。通过这种基于实例级别的方法，我们分析了NLG模型和解码策略，证明用多个样本和多个参考对生成器进行探测，提供了理解模型不确定性表示所必需的详细级别。

    In Natural Language Generation (NLG) tasks, for any input, multiple communicative goals are plausible, and any goal can be put into words, or produced, in multiple ways. We characterise the extent to which human production varies lexically, syntactically, and semantically across four NLG tasks, connecting human production variability to aleatoric or data uncertainty. We then inspect the space of output strings shaped by a generation system's predicted probability distribution and decoding algorithm to probe its uncertainty. For each test input, we measure the generator's calibration to human production variability. Following this instance-level approach, we analyse NLG models and decoding strategies, demonstrating that probing a generator with multiple samples and, when possible, multiple references, provides the level of detail necessary to gain understanding of a model's representation of uncertainty.
    
[^22]: RGCVAE：基于关系图条件化可变自编码器的分子设计

    RGCVAE: Relational Graph Conditioned Variational Autoencoder for Molecule Design. (arXiv:2305.11699v1 [cs.LG])

    [http://arxiv.org/abs/2305.11699](http://arxiv.org/abs/2305.11699)

    本文提出了RGCVAE，一种基于关系图条件化的可变自编码器，可以有效、高效地进行分子设计，并在两个数据集上表现出了先进的生成性能和快速的训练速度。

    

    确定表现出某些预定特性的分子是难以解决的问题。近年来，深度生成模型已被用于分子生成。深度图变分自编码器是最强大的机器学习工具之一，可用于解决此问题。然而，现有方法往往难以捕捉真实的数据分布，并且倾向于计算成本高。在本文中，我们提出了一种高效且有效的基于关系图同构网络的图变分自编码器RGCVAE：（i）利用全新的强大关系图同构网络的编码网络；（ii）一种新颖的概率解码组件。在两个广泛采用的数据集上，与数种最先进的VAE方法相比，RGCVAE表现出最先进的分子生成性能，同时训练速度显著加快。

    Identifying molecules that exhibit some pre-specified properties is a difficult problem to solve. In the last few years, deep generative models have been used for molecule generation. Deep Graph Variational Autoencoders are among the most powerful machine learning tools with which it is possible to address this problem. However, existing methods struggle in capturing the true data distribution and tend to be computationally expensive. In this work, we propose RGCVAE, an efficient and effective Graph Variational Autoencoder based on: (i) an encoding network exploiting a new powerful Relational Graph Isomorphism Network; (ii) a novel probabilistic decoding component. Compared to several state-of-the-art VAE methods on two widely adopted datasets, RGCVAE shows state-of-the-art molecule generation performance while being significantly faster to train.
    
[^23]: 带有门控视觉-语言嵌入的Transformer用于机器人手术中的视觉问答

    Surgical-VQLA: Transformer with Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery. (arXiv:2305.11692v1 [cs.CV])

    [http://arxiv.org/abs/2305.11692](http://arxiv.org/abs/2305.11692)

    本文提出了Surgical-VQLA方法，结合Transformer模型和门控视觉-语言嵌入，解决了手术VQA中对象检测稀缺、异构模态融合策略不足、定位答案缺失等问题，并在测试中实现了最好的表现。

    

    尽管存在着计算机辅助模拟器和手术过程的录制视频，但初级住院医师仍然严重依赖专家来回答他们的问题。然而，专家外科医生通常承担着临床和学术工作，限制了他们回答问题的时间。为此，我们开发了一种手术问答系统，以便从录制的视频中促进机器人辅助手术场景和活动理解。本文提出了一种将Transformer模型与门控视觉-语言嵌入相结合的机器人手术视觉问答方法，解决了手术对象检测模型稀缺、异构模态融合策略不足、缺失定位答案等问题，并在基准手术VQA数据集上实现了最先进的性能。

    Despite the availability of computer-aided simulators and recorded videos of surgical procedures, junior residents still heavily rely on experts to answer their queries. However, expert surgeons are often overloaded with clinical and academic workloads and limit their time in answering. For this purpose, we develop a surgical question-answering system to facilitate robot-assisted surgical scene and activity understanding from recorded videos. Most of the existing VQA methods require an object detector and regions based feature extractor to extract visual features and fuse them with the embedded text of the question for answer generation. However, (1) surgical object detection model is scarce due to smaller datasets and lack of bounding box annotation; (2) current fusion strategy of heterogeneous modalities like text and image is naive; (3) the localized answering is missing, which is crucial in complex surgical scenarios. In this paper, we propose Visual Question Localized-Answering in
    
[^24]: 通过多语言一致性评估任务理解：ChatGPT案例研究

    Evaluating task understanding through multilingual consistency: A ChatGPT case study. (arXiv:2305.11662v1 [cs.CL])

    [http://arxiv.org/abs/2305.11662](http://arxiv.org/abs/2305.11662)

    本文提出了一种新的评估大型语言模型理解能力的范例，通过评估模型自身生成的不同意义之间的一致性，探讨了多语言自我一致性作为模型理解的检验方法，同时证明了ChatGPT在多语言一致性方面的优秀性能。

    

    随着大型语言模型（LLM）功能的惊人提升，创建未来可持续的评估集以评估它们的理解变得越来越具有挑战性。本文提出了一种新的评估LLM的范例，该范例利用了正确的世界理解应该在相同含义的不同（弗雷格）意义上保持一致的思想。因此，我们不是通过正确性来衡量理解，而是通过评估模型自身生成的多个意义之间的一致性来衡量。我们通过实例化一个测试展示了我们的方法，其中不同的意义是不同的语言，因此将多语言自我一致性作为模型理解的检验并同时解决多语言的重要主题。我们以最新版本的ChatGPT为我们的研究对象，在三种不同语言中评估两个不同任务的多语言一致性。我们证明了ChatGPT在多语言一致性方面的优秀性能。

    At the staggering pace with which the capabilities of large language models (LLMs) are increasing, creating future-proof evaluation sets to assess their understanding becomes more and more challenging. In this paper, we propose a novel paradigm for evaluating LLMs which leverages the idea that correct world understanding should be consistent across different (Fregean) senses of the same meaning. Accordingly, we measure understanding not in terms of correctness but by evaluating consistency across multiple senses that are generated by the model itself. We showcase our approach by instantiating a test where the different senses are different languages, hence using multilingual self-consistency as a litmus test for the model's understanding and simultaneously addressing the important topic of multilingualism. Taking one of the latest versions of ChatGPT as our object of study, we evaluate multilingual consistency for two different tasks across three different languages. We show that its m
    
[^25]: 将 Ising 机应用于多目标 QUBOs

    Applying Ising Machines to Multi-objective QUBOs. (arXiv:2305.11648v1 [cs.AI])

    [http://arxiv.org/abs/2305.11648](http://arxiv.org/abs/2305.11648)

    本文基于 Ising 机，提出了一种自适应求解多目标 QUBOs 的方法，该方法比之前的方法探索 Pareto 前沿更快、更准确。

    

    多目标优化问题涉及在多个且常常是冲突的目标之间找到具有不同权衡的解决方案。 Ising 机是旨在找到 Ising 模型的绝对或近似基态的物理设备。为了将 Ising 机应用于多目标问题，使用加权求和目标函数将多目标转换为单目标问题。然而，导出均匀分布于 Pareto 前沿的标量化权重并不容易。先前的工作表明，基于双分割搜索的自适应权重和基于先前探索权重的平均值的权重可以比均匀生成的权重更快地探索 Pareto 前沿。然而，这些自适应方法过去只用于双目标问题。在这项工作中，我们以两种方式扩展了基于平均值的自适应方法：（i）我们扩展了用于解决具有两个或多个目标的标量化权重的自适应方法；（ii）我们考虑了两种定义收敛标准的方式来终止权重自适应。我们将我们的方法与均匀生成和基于双分割搜索的权重在两个和三个目标的 QUBO 问题上的性能进行了比较。我们的结果表明，基于平均值的自适应方法优于均匀生成和基于双分割搜索的权重。

    Multi-objective optimisation problems involve finding solutions with varying trade-offs between multiple and often conflicting objectives. Ising machines are physical devices that aim to find the absolute or approximate ground states of an Ising model. To apply Ising machines to multi-objective problems, a weighted sum objective function is used to convert multi-objective into single-objective problems. However, deriving scalarisation weights that archives evenly distributed solutions across the Pareto front is not trivial. Previous work has shown that adaptive weights based on dichotomic search, and one based on averages of previously explored weights can explore the Pareto front quicker than uniformly generated weights. However, these adaptive methods have only been applied to bi-objective problems in the past. In this work, we extend the adaptive method based on averages in two ways: (i)~we extend the adaptive method of deriving scalarisation weights for problems with two or more ob
    
[^26]: 为了有效的迁移学习而调整模式的ConvBN块

    Tune-Mode ConvBN Blocks For Efficient Transfer Learning. (arXiv:2305.11624v1 [cs.AI])

    [http://arxiv.org/abs/2305.11624](http://arxiv.org/abs/2305.11624)

    本文研究了ConvBN块中稳定性和效率之间的权衡问题，提出了一种新的Tune模式，以便在迁移学习中既能保持稳定性又能提高效率。

    

    卷积-批归一化（ConvBN）块是各种计算机视觉任务和其他领域的重要组成部分。ConvBN块可以在三种模式下运行：Train、Eval和Deploy。虽然Train模式对于从头开始训练模型是必不可少的，但Eval模式适用于迁移学习和模型验证，而Deploy模式则适用于模型部署。本文重点研究了ConvBN块中稳定性和效率之间的权衡：Deploy模式效率高但训练不稳定；Eval模式在迁移学习中应用广泛，但缺乏效率。为了解决这个难题，我们在理论上揭示了Deploy模式下稳定性下降的原因。随后，我们提出了一种新的Tune模式，以弥合Eval模式和Deploy模式之间的差距。所提出的Tune模式与Eval模式一样稳定，适用于迁移学习，而其计算效率与Deploy模式非常接近。通过大量实验，我们证明了Tune模式的有效性和优越性。

    Convolution-BatchNorm (ConvBN) blocks are integral components in various computer vision tasks and other domains. A ConvBN block can operate in three modes: Train, Eval, and Deploy. While the Train mode is indispensable for training models from scratch, the Eval mode is suitable for transfer learning and model validation, and the Deploy mode is designed for the deployment of models. This paper focuses on the trade-off between stability and efficiency in ConvBN blocks: Deploy mode is efficient but suffers from training instability; Eval mode is widely used in transfer learning but lacks efficiency. To solve the dilemma, we theoretically reveal the reason behind the diminished training stability observed in the Deploy mode. Subsequently, we propose a novel Tune mode to bridge the gap between Eval mode and Deploy mode. The proposed Tune mode is as stable as Eval mode for transfer learning, and its computational efficiency closely matches that of the Deploy mode. Through extensive experime
    
[^27]: 从BDD测试用例规范到代码生成：一个愿景

    Towards Code Generation from BDD Test Case Specifications: A Vision. (arXiv:2305.11619v1 [cs.SE])

    [http://arxiv.org/abs/2305.11619](http://arxiv.org/abs/2305.11619)

    本文提出一种利用行为驱动开发测试规范，结合基于转换器的机器学习模型来生成 Angular 框架的前端组件代码的方法。该方法可以显著减少开发时间，提高软件质量，并为自动生成代码研究提供新思路。

    

    自动代码生成近年来越来越受到关注，正在成为软件开发过程中越来越重要的一部分。基于机器学习和人工智能的解决方案正在以有效和创新的方式增加人类和软件的效率。本文旨在利用这些发展，引入一种新的方法来生成流行的Angular框架的前端组件代码。我们建议使用行为驱动开发测试规范作为机器学习模型的输入来实现这一目标。我们的方法旨在大大缩短Web应用程序所需的开发时间，同时可能提高软件质量，并引入新的研究思路，以实现自动生成代码。

    Automatic code generation has recently attracted large attention and is becoming more significant to the software development process. Solutions based on Machine Learning and Artificial Intelligence are being used to increase human and software efficiency in potent and innovative ways. In this paper, we aim to leverage these developments and introduce a novel approach to generating frontend component code for the popular Angular framework. We propose to do this using behavior-driven development test specifications as input to a transformer-based machine learning model. Our approach aims to drastically reduce the development time needed for web applications while potentially increasing software quality and introducing new research ideas toward automatic code generation.
    
[^28]: 多样化深度集成：一种使用显著性图的方法以增强OOD检测、校准和准确性

    Diversifying Deep Ensembles: A Saliency Map Approach for Enhanced OOD Detection, Calibration, and Accuracy. (arXiv:2305.11616v1 [cs.CV])

    [http://arxiv.org/abs/2305.11616](http://arxiv.org/abs/2305.11616)

    这项研究提出了一种使用显著性图来促进深度集成多样性的方法，用于改善OOD检测、校准和准确性，能够优于传统的集成技术，并在OpenOOD基准测试上证明了其有效性。

    

    深度集成在分类和 OOD 检测方面取得了最先进的成果；然而，由于集成中学习的模式的同质性，它们的效果仍然有限。为了克服这一挑战，本研究引入了一种促进集成成员之间多样性的新方法，该方法利用显著性图。通过整合显著性图多样化，我们的方法在多个分类和OOD检测任务中优于传统的集成技术，同时也提高了校准性。在已建立的OpenOOD基准测试上的实验凸显了我们的方法在实际应用中的潜力。

    Deep ensembles achieved state-of-the-art results in classification and out-of-distribution (OOD) detection; however, their effectiveness remains limited due to the homogeneity of learned patterns within the ensemble. To overcome this challenge, our study introduces a novel approach that promotes diversity among ensemble members by leveraging saliency maps. By incorporating saliency map diversification, our method outperforms conventional ensemble techniques in multiple classification and OOD detection tasks, while also improving calibration. Experiments on well-established OpenOOD benchmarks highlight the potential of our method in practical applications.
    
[^29]: MIDI-Draw: 用绘画控制旋律生成

    MIDI-Draw: Sketching to Control Melody Generation. (arXiv:2305.11605v1 [cs.SD])

    [http://arxiv.org/abs/2305.11605](http://arxiv.org/abs/2305.11605)

    MIDI-Draw是一种可以通过画曲线来控制旋律生成的方法，相比于现有的方法，这种方法可以让用户更快速地表达他们的音乐意图。

    

    我们描述了一个概念验证实现的系统，该系统通过旋律轮廓将音符级别的输入表示抽象化。其目的是允许用户表达他们的音乐意图，而无需事先知道音符如何和谐地结合在一起。目前，可控旋律生成的当前方法通常要求用户选择整个序列中静态的参数，通过按钮或滑块进行选择。相比之下，我们的方法允许用户通过绘制轮廓快速指定参数如何随时间变化。

    We describe a proof-of-principle implementation of a system for drawing melodies that abstracts away from a note-level input representation via melodic contours. The aim is to allow users to express their musical intentions without requiring prior knowledge of how notes fit together melodiously. Current approaches to controllable melody generation often require users to choose parameters that are static across a whole sequence, via buttons or sliders. In contrast, our method allows users to quickly specify how parameters should change over time by drawing a contour.
    
[^30]: 内省技巧：上下文决策制定下的大型语言模型

    Introspective Tips: Large Language Model for In-Context Decision Making. (arXiv:2305.11598v1 [cs.AI])

    [http://arxiv.org/abs/2305.11598](http://arxiv.org/abs/2305.11598)

    本文研究了内省技巧对大型语言模型在上下文决策制定中的应用，通过内省轨迹生成简洁有价值的提示，不调整LLM参数就能提高代理的性能。

    

    大型语言模型（LLMs）的出现在自然语言处理方面产生了巨大影响，在各种任务中展示出卓越的结果。本研究利用“内省技巧”来促进LLMs在自我优化决策制定方面发挥作用。通过内省地检查轨迹，LLM生成简洁而有价值的提示来改善其策略。我们的方法通过考虑三种重要情境来提高代理在少样本和零样本学习情况下的性能：从代理过去的经验中学习、整合专家演示和在不同游戏之间进行泛化。重要的是，我们在不调整LLM参数的情况下，通过调整提示来从这三种情况中概括见解来实现这些改进。我们的框架不仅支持而且强调了在上下文决策制定中采用LLM的优势。在TextWorld中涉及超过100个游戏的实验表明了我们所提出的方法的卓越性能。

    The emergence of large language models (LLMs) has substantially influenced natural language processing, demonstrating exceptional results across various tasks. In this study, we employ ``Introspective Tips" to facilitate LLMs in self-optimizing their decision-making. By introspectively examining trajectories, LLM refines its policy by generating succinct and valuable tips. Our method enhances the agent's performance in both few-shot and zero-shot learning situations by considering three essential scenarios: learning from the agent's past experiences, integrating expert demonstrations, and generalizing across diverse games. Importantly, we accomplish these improvements without fine-tuning the LLM parameters; rather, we adjust the prompt to generalize insights from the three aforementioned situations. Our framework not only supports but also emphasizes the advantage of employing LLM in in-contxt decision-making. Experiments involving over 100 games in TextWorld illustrate the superior pe
    
[^31]: 大型语言模型中的内部一致性问题研究：通过辩论进行深入分析

    Diving into the Inter-Consistency of Large Language Models: An Insightful Analysis through Debate. (arXiv:2305.11595v1 [cs.CL])

    [http://arxiv.org/abs/2305.11595](http://arxiv.org/abs/2305.11595)

    本文提出了通过辩论探究大型语言模型之间的内部一致性问题，实验证明通过严格的辩论框架可以提高模型性能和常识知识的结构化学习。

    

    大型语言模型LLMs在各种自然语言处理NLP任务中展现出了惊人的零样本或少量样本通识推理性能。然而，尽管它们拥有强大的常识推理能力，但它们仍然存在各种不一致问题。本研究提出探索两个或多个LLMs之间的内部一致性问题，这对于不同和精确的决策过程至关重要。通过严格的辩论框架，在7个常识推理数据集上进行了广泛的实验。LLMs不仅通过妥协和反驳变得更具内部一致性，而且还实现了更高的性能和常识知识的结构化学习。

    Large language models (LLMs) have demonstrated impressive zero-shot or few-shot commonsense reasoning performance on various natural language processing (NLP) tasks. However, despite their strong commonsense reasoning abilities, LLMs still exhibit various kinds of inconsistency problems. While previous researches mainly focused on the self-consistency within a single LLM, we propose to explore the inter-consistency issue between two or more LLMs, which is critical for diverse and precise decision-making processes. Since the LLMs possess human-like intelligence after instruction tuning and reinforcement learning with human feedback (RLHF), we design a formal debate framework to delve into the inter-consistency problem among LLMs with three-stage debate: fair debate, mismatched debate, and roundtable debate. Through extensive experiments on 7 commonsense reasoning datasets, LLMs not only become more inter-consistent by compromising and refuting but also achieve higher performance and str
    
[^32]: 制造业和供应链中可信、负责、道德的人工智能：综述及新兴研究问题

    Trustworthy, responsible, ethical AI in manufacturing and supply chains: synthesis and emerging research questions. (arXiv:2305.11581v1 [cs.AI])

    [http://arxiv.org/abs/2305.11581](http://arxiv.org/abs/2305.11581)

    本文探讨了在制造业背景下，可信、负责、道德的人工智能的适用性，并使用实例讨论了每一步可能导致的人工智能信任问题，同时还提出了未来的研究问题。

    

    尽管制造业中人工智能的应用越来越普遍，但对于可能引发的风险仍知之甚少。虽然提出了各种高层框架和定义来巩固潜在风险，但从业者仍难以理解和实施。这种缺乏理解使得制造业面临着多种风险，包括组织、工人以及供应商和客户。在本文中，我们探讨和解释了负责、道德和可信的人工智能在制造业背景下的适用性。然后，我们使用机器学习生命周期的扩展版本，通过实例讨论了每一步可能导致的人工智能信任问题。此外，我们还提出了一些研究问题，以帮助制造业研究界引领未来的研究，以获得经济和社会的双重益处。

    While the increased use of AI in the manufacturing sector has been widely noted, there is little understanding on the risks that it may raise in a manufacturing organisation. Although various high level frameworks and definitions have been proposed to consolidate potential risks, practitioners struggle with understanding and implementing them.  This lack of understanding exposes manufacturing to a multitude of risks, including the organisation, its workers, as well as suppliers and clients. In this paper, we explore and interpret the applicability of responsible, ethical, and trustworthy AI within the context of manufacturing. We then use a broadened adaptation of a machine learning lifecycle to discuss, through the use of illustrative examples, how each step may result in a given AI trustworthiness concern. We additionally propose a number of research questions to the manufacturing research community, in order to help guide future research so that the economic and societal benefits en
    
[^33]: 带有显式跨模态对齐的语音文本对话预训练用于口语对话理解

    Speech-Text Dialog Pre-training for Spoken Dialog Understanding with Explicit Cross-Modal Alignment. (arXiv:2305.11579v1 [cs.CL])

    [http://arxiv.org/abs/2305.11579](http://arxiv.org/abs/2305.11579)

    本文提出了SPECTRA语音文本对话预训练模型，应用了新的时间位置预测任务来捕捉语音文本对齐，同时将回答选择任务推广到服务于口语对话理解，用于丰富话语表示。

    

    最近，语音文本预训练方法在许多语音和自然语言处理任务中展现出了惊人的成功。然而，大多数先前的预训练模型通常针对一个或两个特定任务进行了定制，但未能征服各种语音文本任务。此外，现有的语音文本预训练方法未能探索对话中的情境信息以丰富话语表示。在本文中，我们提出了具有显式跨模态对齐的语音文本对话预训练模型SPECTRA，这是第一个语音文本对话预训练模型。具体而言，为了考虑语音模态的时间性，我们设计了一项新的时间位置预测任务来捕捉语音文本对齐。这种预训练任务旨在预测相应语音波形中每个文本单词的开始和结束时间。此外，为了学习口语对话的特征，我们将回答选择任务推广到服务于口语对话理解。

    Recently, speech-text pre-training methods have shown remarkable success in many speech and natural language processing tasks. However, most previous pre-trained models are usually tailored for one or two specific tasks, but fail to conquer a wide range of speech-text tasks. In addition, existing speech-text pre-training methods fail to explore the contextual information within a dialogue to enrich utterance representations. In this paper, we propose Speech-text dialog Pre-training for spoken dialog understanding with ExpliCiT cRoss-Modal Alignment (SPECTRA), which is the first-ever speech-text dialog pre-training model. Concretely, to consider the temporality of speech modality, we design a novel temporal position prediction task to capture the speech-text alignment. This pre-training task aims to predict the start and end time of each textual word in the corresponding speech waveform. In addition, to learn the characteristics of spoken dialogs, we generalize a response selection task
    
[^34]: 通过嵌入式GPU实现的轻量级立体匹配系统-StereoVAE

    StereoVAE: A lightweight stereo matching system through embedded GPUs. (arXiv:2305.11566v1 [cs.CV])

    [http://arxiv.org/abs/2305.11566](http://arxiv.org/abs/2305.11566)

    本论文提出了通过嵌入式GPU实现的轻量级立体匹配系统-StereoVAE，该系统采用基于VAE的小型神经网络对传统匹配方法生成的小尺寸粗糙视差图进行上采样与细化，达到了提高匹配精度和保证实时处理的目的。

    

    本论文提出了通过嵌入式GPU实现的轻量级立体匹配系统-StereoVAE，它打破了立体匹配中精度和处理速度之间的平衡，使得我们的嵌入式系统能够在保证实时处理的同时进一步提高匹配精度。我们的方法的主要思想是构建一个基于变分自编码器（VAE）的小型神经网络，对传统匹配方法生成的小尺寸粗糙视差图进行上采样与细化。这种混合结构不仅可以带来传统方法的计算复杂度优势，还可以保证神经网络的影响下的匹配精度。对KITTI 2015基准测试的广泛实验表明，我们的轻量级立体匹配系统在提高由不同算法生成的粗糙视差图的准确性方面表现出高鲁棒性，同时在嵌入式GPU上实时运行。

    We present a lightweight system for stereo matching through embedded GPUs. It breaks the trade-off between accuracy and processing speed in stereo matching, enabling our embedded system to further improve the matching accuracy while ensuring real-time processing. The main idea of our method is to construct a tiny neural network based on variational auto-encoder (VAE) to upsample and refinement a small size of coarse disparity map, which is first generated by a traditional matching method. The proposed hybrid structure cannot only bring the advantage of traditional methods in terms of computational complexity, but also ensure the matching accuracy under the impact of neural network. Extensive experiments on the KITTI 2015 benchmark demonstrate that our tiny system exhibits high robustness in improving the accuracy of the coarse disparity maps generated by different algorithms, while also running in real-time on embedded GPUs.
    
[^35]: 解耦参数中的知识：可插拔语言模型的新方法

    Decouple knowledge from paramters for plug-and-play language modeling. (arXiv:2305.11564v1 [cs.CL])

    [http://arxiv.org/abs/2305.11564](http://arxiv.org/abs/2305.11564)

    本文介绍了一种新的插件式预训练模型，其与模型参数中的知识存储分离，采用可编辑和可扩展的键值存储器，通过DPM中的知识检索以可解释的方式利用知识。

    

    预训练语言模型（PLM）在各种NLP任务中取得了令人印象深刻的成果。 揭示了这些模型成功的关键因素之一是这些模型的参数在预训练期间隐含地学习了各种知识。 然而，将知识隐含在模型参数中具有两个基本缺点。 首先，在模型训练后，无法编辑或扩展知识，特别是在知识不断发展的情况下，这是一个严重的问题。 其次，它缺乏可解释性并阻止人们了解PLM在某个问题上所需的哪些知识。 在本文中，我们介绍PlugLM，这是一种具有可微分插件存储器（DPM）的预训练模型。 关键的直觉是使用可编辑和可扩展的键值存储器将知识存储与模型参数分离，并通过DPM中的知识检索以可解释的方式利用知识。为了证明这种设计选择的合理性，我们在三个设置中进行评估，这些设置需要各种形式的知识：（1）领域适应，（2）未见实体合并，以及（3）在不遗忘旧任务的情况下适应新任务。

    Pre-trained language models(PLM) have made impressive results in various NLP tasks. It has been revealed that one of the key factors to their success is the parameters of these models implicitly learn all kinds of knowledge during pre-training. However, encoding knowledge implicitly in the model parameters has two fundamental drawbacks. First, the knowledge is neither editable nor scalable once the model is trained, which is especially problematic in that knowledge is consistently evolving. Second, it lacks interpretability and prevents humans from understanding which knowledge PLM requires for a certain problem. In this paper, we introduce PlugLM, a pre-training model with differentiable plug-in memory(DPM). The key intuition is to decouple the knowledge storage from model parameters with an editable and scalable key-value memory and leverage knowledge in an explainable manner by knowledge retrieval in the DPM. To justify this design choice, we conduct evaluations in three settings in
    
[^36]: 提升大规模语言模型在工业领域特定问答中的表现

    Empower Large Language Model to Perform Better on Industrial Domain-Specific Question Answering. (arXiv:2305.11541v1 [cs.CL])

    [http://arxiv.org/abs/2305.11541](http://arxiv.org/abs/2305.11541)

    本文提供了一个行业云特定QA数据集 MSQA，该数据集可用于评估旨在提高大规模语言模型特定领域能力的方法。本文还提出了一种新的模型交互范式，可以使大规模语言模型在其不擅长的特定任务上取得更好的性能。

    

    大规模语言模型（LLM）在开放领域任务中获得了广泛应用和卓越的成果，但其在真实的工业特定场景中的表现通常很平庸，因为它缺乏特定领域的知识。这个问题引起了广泛关注，但相关基准测试很少。本文提供了一个名为MSQA的基准问答（QA）数据集，该数据集涉及Microsoft产品和客户遇到的IT技术问题。这个数据集包含了行业云的特定QA知识，这对于一般的LLM来说是不可用的，因此非常适合评估旨在提高LLM特定领域能力的方法。此外，我们提出了一种新的模型交互范式，可以使LLM在其不擅长的特定任务上取得更好的性能。广泛的实验表明，遵循我们的模型融合框架的方法比使用检索方法的常用LLM表现更好。

    Large Language Model (LLM) has gained popularity and achieved remarkable results in open-domain tasks, but its performance in real industrial domain-specific scenarios is average since there is no specific knowledge in it. This issue has attracted widespread attention, but there are few relevant benchmarks available. In this paper, we provide a benchmark Question Answering (QA) dataset named MSQA, which is about Microsoft products and IT technical problems encountered by customers. This dataset contains industry cloud-specific QA knowledge, which is not available for general LLM, so it is well suited for evaluating methods aimed at improving domain-specific capabilities of LLM. In addition, we propose a new model interaction paradigm that can empower LLM to achieve better performance on domain-specific tasks where it is not proficient. Extensive experiments demonstrate that the approach following our model fusion framework outperforms the commonly used LLM with retrieval methods.
    
[^37]: 可信联邦学习：综述

    Trustworthy Federated Learning: A Survey. (arXiv:2305.11537v1 [cs.AI])

    [http://arxiv.org/abs/2305.11537](http://arxiv.org/abs/2305.11537)

    本文综述了联邦学习的可信性问题，提出了三个支柱：可解释性，公平性和安全与隐私，并探讨了相关的挑战和研究方向。

    

    联邦学习已经成为人工智能领域的一个重要进展，可以在保持数据隐私的同时，实现分布式设备上的协作模型训练。随着联邦学习的重要性不断增加，解决其各个方面的可信问题变得至关重要。在本综述中，我们提供了有关可信联邦学习的当前状态的广泛概述，探讨了与可信性相关的现有解决方案和明确定义的支柱。尽管在有关可信集中式机器学习（ML）/深度学习（DL）的文献增长迅速，但仍需要进一步努力，以确定针对FL模型的可信支柱和评估指标，以及开发计算可信度水平的解决方案。我们提出了一个涵盖三个主要支柱的分类法：可解释性，公平性和安全与隐私。每个支柱代表一维信任，进一步细分为不同的概念。我们的综述涵盖了与这三个支柱相关的FL的可信问题，并强调了挑战和开放的研究方向。

    Federated Learning (FL) has emerged as a significant advancement in the field of Artificial Intelligence (AI), enabling collaborative model training across distributed devices while maintaining data privacy. As the importance of FL increases, addressing trustworthiness issues in its various aspects becomes crucial. In this survey, we provide an extensive overview of the current state of Trustworthy FL, exploring existing solutions and well-defined pillars relevant to Trustworthy . Despite the growth in literature on trustworthy centralized Machine Learning (ML)/Deep Learning (DL), further efforts are necessary to identify trustworthiness pillars and evaluation metrics specific to FL models, as well as to develop solutions for computing trustworthiness levels. We propose a taxonomy that encompasses three main pillars: Interpretability, Fairness, and Security & Privacy. Each pillar represents a dimension of trust, further broken down into different notions. Our survey covers trustworthin
    
[^38]: InstructIE: 一份基于指令的中文信息提取数据集

    InstructIE: A Chinese Instruction-based Information Extraction Dataset. (arXiv:2305.11527v1 [cs.CL])

    [http://arxiv.org/abs/2305.11527](http://arxiv.org/abs/2305.11527)

    介绍了一份中文的基于指令的信息提取数据集InstructIE，其中包括了270,000个弱监督的数据和1,000个高质量注释实例。实验结果表明当前的模型表现有待改进，该任务仍存在挑战。

    

    我们引入了一项新的信息提取任务，称为基于指令的信息提取 (Instruction-based IE)，它旨在要求系统遵循特定的指令或指南来提取信息。为了促进该领域的研究，我们构建了一个数据集，称为InstructIE，其中包括来自中文维基百科的 270,000 个弱监督数据和 1,000 个高质量众包注释实例。我们进一步评估了各种基线模型在InstructIE数据集上的表现。结果表明，尽管当前的模型表现很有希望，但仍有改进的空间。此外，我们进行了全面的案例研究分析，强调了基于指令的信息提取任务中固有的挑战。代码和数据集可在 https://github.com/zjunlp/DeepKE/tree/main/example/llm 找到。

    We introduce a new Information Extraction (IE) task dubbed Instruction-based IE, which aims to ask the system to follow specific instructions or guidelines to extract information. To facilitate research in this area, we construct a dataset called InstructIE, consisting of 270,000 weakly supervised data from Chinese Wikipedia and 1,000 high-quality crowdsourced annotated instances. We further evaluate the performance of various baseline models on the InstructIE dataset. The results reveal that although current models exhibit promising performance, there is still room for improvement. Furthermore, we conduct a comprehensive case study analysis, underlining the challenges inherent in the Instruction-based IE task. Code and dataset are available at https://github.com/zjunlp/DeepKE/tree/main/example/llm.
    
[^39]: 人工智能作为亚当·斯密的公正旁观者的道德代理

    Artificial intelligence moral agent as Adam Smith's impartial spectator. (arXiv:2305.11519v1 [econ.GN])

    [http://arxiv.org/abs/2305.11519](http://arxiv.org/abs/2305.11519)

    本文讨论了使用人工智能作为外部代替工具，扮演亚当·斯密的公正旁观者角色的可能性，以提供更全面的道德评估视角。

    

    亚当·斯密发展了一种道德哲学，认为通过审问我们内在的公正旁观者做出更好的决策。我们讨论了使用一个外部的、非基于人类的代替工具的可能性，它将增强我们的内在思维过程，扮演公正旁观者的角色。这种工具将拥有更多的关于世界的知识，更公正，提供更全面的道德评估视角。

    Adam Smith developed a version of moral philosophy where better decisions are made by interrogating an impartial spectator within us. We discuss the possibility of using an external non-human-based substitute tool that would augment our internal mental processes and play the role of the impartial spectator. Such tool would have more knowledge about the world, be more impartial, and would provide a more encompassing perspective on moral assessment.
    
[^40]: DiffuSIA：一种编码器-解码器文本扩散的螺旋交互架构

    DiffuSIA: A Spiral Interaction Architecture for Encoder-Decoder Text Diffusion. (arXiv:2305.11517v1 [cs.CL])

    [http://arxiv.org/abs/2305.11517](http://arxiv.org/abs/2305.11517)

    本文提出一种名为DiffuSIA的螺旋交互架构，用于编码器-解码器文本扩散。在这个架构中，条件信息和目标信息会交互捕获，以提高条件文本生成的效果。

    

    扩散模型已成为新一代深度生成模型的最新代表，并且近年来它们在文本生成方面的潜力引起了越来越多的关注。现有的研究大多采用单个编码器结构和部分噪声过程用于条件文本生成，但是其对于条件建模的灵活性有限。实际上，编码器-解码器架构对于它的可分离编码器和解码器模块天然更加灵活，可扩展到多语言和多模态的生成任务。然而，有条件的文本编码过程缺乏对目标文本的理解。为此，我们提出了一种用于编码器-解码器文本扩散的螺旋交互架构（DiffuSIA）。具体来说，设计了从编码器捕获条件信息并被扩散解码器捕获，以及从解码器捕获目标信息并被条件编码器捕获的机制。

    Diffusion models have emerged as the new state-of-the-art family of deep generative models, and their promising potentials for text generation have recently attracted increasing attention. Existing studies mostly adopt a single encoder architecture with partially noising processes for conditional text generation, but its degree of flexibility for conditional modeling is limited. In fact, the encoder-decoder architecture is naturally more flexible for its detachable encoder and decoder modules, which is extensible to multilingual and multimodal generation tasks for conditions and target texts. However, the encoding process of conditional texts lacks the understanding of target texts. To this end, a spiral interaction architecture for encoder-decoder text diffusion (DiffuSIA) is proposed. Concretely, the conditional information from encoder is designed to be captured by the diffusion decoder, while the target information from decoder is designed to be captured by the conditional encoder.
    
[^41]: Terraforming - 多智能体取送货期间的环境操作

    Terraforming -- Environment Manipulation during Disruptions for Multi-Agent Pickup and Delivery. (arXiv:2305.11510v1 [cs.AI])

    [http://arxiv.org/abs/2305.11510](http://arxiv.org/abs/2305.11510)

    在自动化仓库的多智能体取送货问题中，运用Terraforming技术灵活地重新定位货架，可以减少路径长度和提高运输效率。

    

    在自动化仓库中，由移动机器人组成的团队在在紧密排列的库存货架之间穿行，并将货架传递到指定的工作站以完成包装流程。该问题通常被建模为多智能体取送货（MAPD）问题，然后通过在固定图形上为机器人规划无碰撞路径来解决，例如Rolling-Horizon碰撞解决（RHCR）算法。然而，现有方法作出了一项限制性的假设，即规定机器人只能移动与其当前任务对应的货架，而将其他货架视为静止障碍物（尽管所有货架都是可移动的）。这种行为可能导致不必要的长路径，否则可以通过货架操作打开额外的通道来避免。因此，我们探讨了允许机器人动态重新定位货架的灵活性所带来的影响。我们称之为新的问题Terraforming MAPD（tMAPD），并开发了一个基于RHCR的算法来解决该问题。

    In automated warehouses, teams of mobile robots fulfill the packaging process by transferring inventory pods to designated workstations while navigating narrow aisles formed by tightly packed pods. This problem is typically modeled as a Multi-Agent Pickup and Delivery (MAPD) problem, which is then solved by repeatedly planning collision-free paths for agents on a fixed graph, as in the Rolling-Horizon Collision Resolution (RHCR) algorithm. However, existing approaches make the limiting assumption that agents are only allowed to move pods that correspond to their current task, while considering the other pods as stationary obstacles (even though all pods are movable). This behavior can result in unnecessarily long paths which could otherwise be avoided by opening additional corridors via pod manipulation. To this end, we explore the implications of allowing agents the flexibility of dynamically relocating pods. We call this new problem Terraforming MAPD (tMAPD) and develop an RHCR-based
    
[^42]: “即插即用”医疗对话系统

    Plug-and-Play Medical Dialogue System. (arXiv:2305.11508v1 [cs.CL])

    [http://arxiv.org/abs/2305.11508](http://arxiv.org/abs/2305.11508)

    该论文提出了一种即插即用的医疗对话系统，使用大型语言模型实现医疗问答及诊断策略，避免了传统昂贵的LLMs微调。

    

    医疗对话系统旨在为患者提供准确的答案，需要特定的领域知识。大型语言模型（LLMs）的最近进展已经证明了其在医疗问答领域具有杰出的能力，表明具备了对常识的丰富理解。然而，由于缺乏诊断策略，LLMs无法直接用于诊断。传统的解决方法是昂贵的LLMs微调。另一种更具吸引力的解决方法是开发一个插件，赋予LLMs执行医疗对话任务的能力。受到上下文学习的启发，我们提出了PlugMed，一个即插即用的医疗对话系统，通过两个模块促进了LLMs的恰当对话动作：提示生成（PG）模块和回复排名（RR）模块。PG模块旨在从全局和局部角度捕获对话信息。它通过评估匹配度来选择合适的提示。

    Medical dialogue systems aim to provide accurate answers to patients, necessitating specific domain knowledge. Recent advancements in Large Language Models (LLMs) have demonstrated their exceptional capabilities in the medical Q&A domain, indicating a rich understanding of common sense. However, LLMs are insufficient for direct diagnosis due to the absence of diagnostic strategies. The conventional approach to address this challenge involves expensive fine-tuning of LLMs. Alternatively, a more appealing solution is the development of a plugin that empowers LLMs to perform medical conversation tasks. Drawing inspiration from in-context learning, we propose PlugMed, a Plug-and-Play Medical Dialogue System that facilitates appropriate dialogue actions by LLMs through two modules: the prompt generation (PG) module and the response ranking (RR) module. The PG module is designed to capture dialogue information from both global and local perspectives. It selects suitable prompts by assessing 
    
[^43]: 基于概率偏置的事件抽取中重新耦合事件场

    Recouple Event Field via Probabilistic Bias for Event Extraction. (arXiv:2305.11498v1 [cs.CL])

    [http://arxiv.org/abs/2305.11498](http://arxiv.org/abs/2305.11498)

    提出了一种基于概率偏置的重新耦合事件场模型（ProCE），用于增强事件提取框架，以澄清来自模糊纠缠的事件字段，并重新耦合相应的澄清分布以捕获更多潜在信息字段。实验表明该方法有效且具有泛化性。

    

    事件抽取（EE）旨在从事件提及中识别和分类事件触发器和参数，已经受益于预训练语言模型（PLM）。然而，现有基于PLM的方法忽略了触发/参数字段的信息，这对于理解事件模式是至关重要的。为此，我们提出了一种概率重新耦合模型增强事件提取框架（ProCE）。具体来说，我们首先将语法相关的事件字段建模为概率偏置，以澄清来自模糊纠缠的事件字段。此外，考虑到EE中同一触发器/参数的多次出现，我们探索了同一触发器/参数的多个字段之间的概率交互策略，以重新耦合相应的澄清分布并捕获更多潜在信息字段。在EE数据集上的实验证明了我们提出的方法的有效性和泛化性。

    Event Extraction (EE), aiming to identify and classify event triggers and arguments from event mentions, has benefited from pre-trained language models (PLMs). However, existing PLM-based methods ignore the information of trigger/argument fields, which is crucial for understanding event schemas. To this end, we propose a Probabilistic reCoupling model enhanced Event extraction framework (ProCE). Specifically, we first model the syntactic-related event fields as probabilistic biases, to clarify the event fields from ambiguous entanglement. Furthermore, considering multiple occurrences of the same triggers/arguments in EE, we explore probabilistic interaction strategies among multiple fields of the same triggers/arguments, to recouple the corresponding clarified distributions and capture more latent information fields. Experiments on EE datasets demonstrate the effectiveness and generalization of our proposed approach.
    
[^44]: TreePrompt：学习生成树形提示以实现可解释的视觉定位

    TreePrompt: Learning to Compose Tree Prompts for Explainable Visual Grounding. (arXiv:2305.11497v1 [cs.CV])

    [http://arxiv.org/abs/2305.11497](http://arxiv.org/abs/2305.11497)

    提示调整技术已经在视觉定位领域卓有成效，但现有的方法大多数可解释性不好。本文提出了一种新的提示构建方法，名为TreePrompt，通过将句子分解成树状结构进行逐步提示构建，提高了提示的可解释性。

    

    提示调整已经在将从大型预训练的视觉语言模型中的知识转移到下游任务方面取得了巨大的成功，并且已经支配了视觉定位（VG）的表现。然而，几乎所有现有的提示调整范例都遭受着可解释性差的问题。在本文中，我们认为其可解释性差是由于全局提示生成和推理过程造成的。通过“全局”，我们是指它们通常直接学习一组向量作为提示（即提示生成），并使用学习到的全局提示增强VG模型的文本输入（即提示推理）。为此，我们提出了一种具有显式可解释性的新型提示构建范例，称为TreePrompt。具体而言，我们首先将复杂的句子分解成一棵与人类推理一致的树。然后，按照语法树，我们从底向上以结构化提示的方式构成一个提示。由于这一步骤一步一步的提示构建过程，e

    Prompt tuning has achieved great success in transferring the knowledge from large pretrained vision-language models into downstream tasks, and has dominated the performance on visual grounding (VG). However, almost all existing prompt tuning paradigms suffer from poor interpretability. In this paper, we argue that their poor interpretability is attributed to the holistic prompt generation and inference process. By "holistic", we mean that they usually directly learn a set of vectors as the prompt (i.e., prompt generation), and use the learned global prompt to augment the textual input for the VG model (i.e., prompt inference). To this end, we propose a new prompt construction paradigm with explicit explainable ability, named TreePrompt. Specifically, we first deconstruct a complex sentence into a tree, that is consistent with human reasoning. Then, following the syntax tree, we compose a structured prompt in a bottom-up manner. Thanks to this step-by-step prompt construction process, e
    
[^45]: LLM自身可读取和生成CXR图像

    LLM Itself Can Read and Generate CXR Images. (arXiv:2305.11490v1 [cs.CV])

    [http://arxiv.org/abs/2305.11490](http://arxiv.org/abs/2305.11490)

    该论文提出了一种新方法，可以在不需要进行结构更改、额外训练、或训练专门网络的情况下，通过微调预先训练的LLM来读取和生成像文本一样的图像，并应用于胸部X线（CXR）图像的生成任务中。

    

    借助于近期大语言模型（LLMs）的显著发展，人们正积极尝试将LLMs的实用性扩展到多模态任务。已经有人尝试连接语言和视觉信息，并且也在不断尝试为LLMs添加视觉能力。然而，现有的尝试只使用LLMs作为图像解码器，没有尝试通过自然语言来生成图像。通过采用VQ-GAN框架，将图像的潜在表示视为一种文本标记，我们提出了一种新方法，可以微调预先训练的LLM，以像文本一样读取和生成图像，而无需进行结构更改、额外的训练目标或训练专门的网络，同时仍保留LLM的指令跟随能力。我们将此框架应用于胸部X线（CXR）图像的生成任务中，因为这是一个复杂信息在视觉和语言之间翻译的领域。

    Building on the recent remarkable development of large language models (LLMs), active attempts are being made to extend the utility of LLMs to multimodal tasks. There have been previous efforts to link language and visual information, and attempts to add visual capabilities to LLMs are ongoing as well. However, existing attempts use LLMs only as image decoders and no attempt has been made to generate images in the same line as the natural language. By adopting a VQ-GAN framework in which latent representations of images are treated as a kind of text tokens, we present a novel method to fine-tune a pre-trained LLM to read and generate images like text without any structural changes, extra training objectives, or the need for training an ad-hoc network while still preserving the of the instruction-following capability of the LLM. We apply this framework to chest X-ray (CXR) image and report generation tasks as it is a domain in which translation of complex information between visual and 
    
[^46]: 通过扩散补全实现不完整多视角聚类

    Incomplete Multi-view Clustering via Diffusion Completion. (arXiv:2305.11489v1 [cs.LG])

    [http://arxiv.org/abs/2305.11489](http://arxiv.org/abs/2305.11489)

    本文提出一种扩散补全方法，将缺失视角恢复到不完整多视角聚类框架中，并通过对比学习来学习多视角数据的一致性信息，从而提高了多视角聚类的性能。

    

    在真实世界中，为了对大量未标记的数据进行有效的数据分析，不完整多视角聚类是一项具有挑战性和非常规的任务。所有的不完整多视角聚类方法都需要解决如何减少缺失视角的影响问题。为了解决这个问题，我们提出了一种扩散补全方法，将缺失视角恢复到不完整多视角聚类框架中。基于可观察视角信息，扩散模型用于恢复缺失的视角，然后通过对比学习来学习多视角数据的一致性信息，以提高多视角聚类的性能。据我们所知，这可能是将扩散模型纳入不完整多视角聚类框架的首个工作。实验结果表明，与最先进的方法相比，所提方法在恢复缺失的视角的同时实现了优越的聚类性能。

    Incomplete multi-view clustering is a challenging and non-trivial task to provide effective data analysis for large amounts of unlabeled data in the real world. All incomplete multi-view clustering methods need to address the problem of how to reduce the impact of missing views. To address this issue, we propose diffusion completion to recover the missing views integrated into an incomplete multi-view clustering framework. Based on the observable views information, the diffusion model is used to recover the missing views, and then the consistency information of the multi-view data is learned by contrastive learning to improve the performance of multi-view clustering. To the best of our knowledge, this may be the first work to incorporate diffusion models into an incomplete multi-view clustering framework. Experimental results show that the proposed method performs well in recovering the missing views while achieving superior clustering performance compared to state-of-the-art methods.
    
[^47]: Sensecape：利用大语言模型实现多层次探索和知识建构

    Sensecape: Enabling Multilevel Exploration and Sensemaking with Large Language Models. (arXiv:2305.11483v1 [cs.HC])

    [http://arxiv.org/abs/2305.11483](http://arxiv.org/abs/2305.11483)

    这篇论文讲述了一个交互式系统Sensecape，它能够利用大语言模型（LLM）支持复杂的信息任务，帮助用户通过多级抽象管理信息的复杂性，并在规划和知识建构之间无缝切换，有助于增强用户的信息组织和探索能力。

    

    如今，人们越来越多地将大语言模型（LLM）应用于复杂的信息任务中，例如学术研究或计划搬到另一个城市。然而，尽管这些任务通常需要非线性工作方式，例如将信息在空间上进行排布以组织并理解它，但目前与LLM交互的界面通常是线性的，以支持对话式交互。为了解决这个限制并探索如何支持LLM-powered的探索和知识建构，我们开发了Sensecape，这是一个交互式系统，旨在通过使用户能够（1）通过多级抽象来管理信息的复杂性，（2）无缝地在规划和知识建构之间切换，以支持LLM进行复杂信息任务。我们的被试用户研究表明，Sensecape使用户能够探索更多的主题并以分层结构组织他们的知识。我们为基于LLM的工作流程和信息任务界面做出了贡献和启示。

    People are increasingly turning to large language models (LLMs) for complex information tasks like academic research or planning a move to another city. However, while they often require working in a nonlinear manner - e.g., to arrange information spatially to organize and make sense of it, current interfaces for interacting with LLMs are generally linear to support conversational interaction. To address this limitation and explore how we can support LLM-powered exploration and sensemaking, we developed Sensecape, an interactive system designed to support complex information tasks with an LLM by enabling users to (1) manage the complexity of information through multilevel abstraction and (2) seamlessly switch between foraging and sensemaking. Our within-subject user study reveals that Sensecape empowers users to explore more topics and structure their knowledge hierarchically. We contribute implications for LLM-based workflows and interfaces for information tasks.
    
[^48]: CCGen：电子商务中可解释的互补概念生成

    CCGen: Explainable Complementary Concept Generation in E-Commerce. (arXiv:2305.11480v1 [cs.CL])

    [http://arxiv.org/abs/2305.11480](http://arxiv.org/abs/2305.11480)

    CCGen是一个电子商务中可解释的互补概念生成算法，通过训练语言模型生成高质量的互补概念排名列表，并生成解释以证明预测的正确性。

    

    我们提出并研究了互补概念生成（CCGen）：给定一个感兴趣的概念，例如“数码相机”，生成一系列互补的概念，例如1）相机镜头2）电池3）相机盒子4）存储卡5）电池充电器。CCGen对于诸如查询建议和物品推荐等各种应用，尤其是在电子商务领域中非常有益。为了解决CCGen，我们提出了一个两步训练策略，利用语言模型生成排名列表。我们还教授模型生成解释，通过加入从大型教师模型中提取的解释。广泛的实验和分析表明，我们的模型可以生成高质量的互补概念，同时生成解释以证明预测的正确性。

    We propose and study Complementary Concept Generation (CCGen): given a concept of interest, e.g., "Digital Cameras", generating a list of complementary concepts, e.g., 1) Camera Lenses 2) Batteries 3) Camera Cases 4) Memory Cards 5) Battery Chargers. CCGen is beneficial for various applications like query suggestion and item recommendation, especially in the e-commerce domain. To solve CCGen, we propose to train language models to generate ranked lists of concepts with a two-step training strategy. We also teach the models to generate explanations by incorporating explanations distilled from large teacher models. Extensive experiments and analysis demonstrate that our model can generate high-quality concepts complementary to the input concept while producing explanations to justify the predictions.
    
[^49]: 基于人群自我对抗学习多样风险偏好

    Learning Diverse Risk Preferences in Population-based Self-play. (arXiv:2305.11476v1 [cs.LG])

    [http://arxiv.org/abs/2305.11476](http://arxiv.org/abs/2305.11476)

    RPPO是一种新颖的强化学习算法，通过代理程序在面对不确定性时具备多样的风险偏好，从而增加自我对抗算法中的策略多样性，并提高代理程序面对不同对手的鲁棒性。

    

    在强化学习的成功案例中，自我对抗算法在解决竞争性游戏中发挥了重要作用。然而当前的自我对抗算法在优化代理程序以最大化预期胜率时，往往会陷入局部最优并产生单一同质化的策略。为了打破僵局并增强代理程序面对不同对手的鲁棒性，解决方法可能在于增加策略的多样性。然而，在自我对抗算法中增加多样性并不是易如反掌的。本文试图从代理程序在面对不确定性时可以具备多样的风险偏好这一视角出发增加策略多样性。具体来说，我们设计了一种新颖的强化学习算法，称为风险敏感近端策略优化(RPPO)，它在最坏和最好的策略学习之间平滑地插值，允许具有所需风险偏好的策略学习。

    Among the great successes of Reinforcement Learning (RL), self-play algorithms play an essential role in solving competitive games. Current self-play algorithms optimize the agent to maximize expected win-rates against its current or historical copies, making it often stuck in the local optimum and its strategy style simple and homogeneous. A possible solution is to improve the diversity of policies, which helps the agent break the stalemate and enhances its robustness when facing different opponents. However, enhancing diversity in the self-play algorithms is not trivial. In this paper, we aim to introduce diversity from the perspective that agents could have diverse risk preferences in the face of uncertainty. Specifically, we design a novel reinforcement learning algorithm called Risk-sensitive Proximal Policy Optimization (RPPO), which smoothly interpolates between worst-case and best-case policy learning and allows for policy learning with desired risk preferences. Seamlessly inte
    
[^50]: RAMiT：轻量级图像恢复的互惠式注意力混合Transformer

    RAMiT: Reciprocal Attention Mixing Transformer for Lightweight Image Restoration. (arXiv:2305.11474v1 [cs.CV])

    [http://arxiv.org/abs/2305.11474](http://arxiv.org/abs/2305.11474)

    本文提出了轻量级图像恢复的互惠式注意力混合Transformer（RAMiT）。通过使用双向注意力以及一种新的数据增强类型——强度掩码，有效地提高了恢复效果，同时大大减少了参数数量。

    

    尽管近年来许多工作在图像恢复（IR）领域取得了进展，但它们往往面临参数过多的问题。另一个问题是，大多数基于Transformer的IR方法只依靠本地或全局特征，导致接受域有限或存在参数不足的问题。为了解决这些问题，我们提出了一种轻量级IR网络：互惠注意力混合Transformer（RAMiT）。它采用我们提出的维度互惠注意力混合Transformer（D-RAMiT）块，在使用不同数量的多头并行计算双向（空间和通道）自注意力的情况下。双向关注帮助彼此弥补对方的缺点，然后混合。此外，我们引入了一种分层互惠注意力混合（H-RAMi）层，它补偿像素级信息丢失并利用语义信息，同时保持高效的分层结构。此外，在IR任务中，我们重新审视了数据增强策略并提出了一种新的数据增强类型——强度掩码，以提高所提出模型的鲁棒性。广泛的实验表明，在各种IR任务中，包括图像去噪、图像去模糊和JPEG图像去块，我们的所提出的方法在大大减少参数的情况下，优于现有最先进的方法。

    Although many recent works have made advancements in the image restoration (IR) field, they often suffer from an excessive number of parameters. Another issue is that most Transformer-based IR methods focus only on either local or global features, leading to limited receptive fields or deficient parameter issues. To address these problems, we propose a lightweight IR network, Reciprocal Attention Mixing Transformer (RAMiT). It employs our proposed dimensional reciprocal attention mixing Transformer (D-RAMiT) blocks, which compute bi-dimensional (spatial and channel) self-attentions in parallel with different numbers of multi-heads. The bi-dimensional attentions help each other to complement their counterpart's drawbacks and are then mixed. Additionally, we introduce a hierarchical reciprocal attention mixing (H-RAMi) layer that compensates for pixel-level information losses and utilizes semantic information while maintaining an efficient hierarchical structure. Furthermore, we revisit 
    
[^51]: Graphologue：用交互式图表探索大型语言模型响应

    Graphologue: Exploring Large Language Model Responses with Interactive Diagrams. (arXiv:2305.11473v1 [cs.HC])

    [http://arxiv.org/abs/2305.11473](http://arxiv.org/abs/2305.11473)

    Graphologue是一个交互式系统，将大型语言模型的基于文本的响应转换为图形化图表以增强其可用性和可解释性，用户可以通过选择和突出显示特定节点和链接来与这些图表进行交互。

    

    大型语言模型（LLM）由于易于获取和在多种应用中表现出的前所未有的智能而近来风靡一时。然而，像ChatGPT这样的LLM在支持复杂信息任务方面存在显着的限制，原因是基于文本的媒介和线性对话结构提供的功能不足。通过与十名参与者的形式化研究，我们发现LLM界面通常会呈现冗长的响应，使人们难以快速理解和灵活地与各种信息进行交互，特别是在更复杂的任务中。我们提出了Graphologue，这是一个交互式系统，将LLM的基于文本的响应转换为图形化图表，以便于信息查找和问题回答任务。Graphologue采用新颖的提示策略和界面设计，从LLM响应中提取实体和关系，并实时构建节点链接图。此外，用户可以通过选择和突出显示特定节点和链接来与这些图表进行交互，以探索相关信息和跟进问题。我们的用户研究结果表明，与传统的基于文本的界面相比，Graphologue显著提高了用户在复杂信息任务中的表现和满意度。Graphologue为增强LLM在各种应用和领域中的可用性和可解释性提供了一个有前景的方向。

    Large language models (LLMs) have recently soared in popularity due to their ease of access and the unprecedented intelligence exhibited on diverse applications. However, LLMs like ChatGPT present significant limitations in supporting complex information tasks due to the insufficient affordances of the text-based medium and linear conversational structure. Through a formative study with ten participants, we found that LLM interfaces often present long-winded responses, making it difficult for people to quickly comprehend and interact flexibly with various pieces of information, particularly during more complex tasks. We present Graphologue, an interactive system that converts text-based responses from LLMs into graphical diagrams to facilitate information-seeking and question-answering tasks. Graphologue employs novel prompting strategies and interface designs to extract entities and relationships from LLM responses and constructs node-link diagrams in real-time. Further, users can int
    
[^52]: 智能系统测试探讨

    Testing System Intelligence. (arXiv:2305.11472v1 [cs.AI])

    [http://arxiv.org/abs/2305.11472](http://arxiv.org/abs/2305.11472)

    该论文讨论了以往智能系统测试的不足和所提出的替换测试作为一种完善测试的能力，该测试反映了人类和机器之间的技能互补性，能够构建更多反映智能可能的概念和属性。

    

    我们讨论了针对智能系统的测试的充分性以及其实施带来的实际问题。我们提出了替换测试作为系统在给定环境下成功替换另一个执行任务的系统的能力。我们展示了它如何表征人类智能的显著方面，这些方面不能被图灵测试考虑到。我们认为，构建通过替换测试的智能系统涉及到一系列当前人工智能所无法解决的技术问题。我们提出了一个框架来实施所提出的测试并验证智能系统的属性。我们讨论了智能系统验证的固有局限性，并倡导新的理论基础以扩展现有的严格测试方法。我们建议基于人类和机器之间技能互补性的替换测试可以导致多种反映结合基于数据和知识的能力的智能概念。

    We discuss the adequacy of tests for intelligent systems and practical problems raised by their implementation. We propose the replacement test as the ability of a system to replace successfully another system performing a task in a given context. We show how it can characterize salient aspects of human intelligence that cannot be taken into account by the Turing test. We argue that building intelligent systems passing the replacement test involves a series of technical problems that are outside the scope of current AI. We present a framework for implementing the proposed test and validating the properties of the intelligent systems. We discuss the inherent limitations of intelligent system validation and advocate new theoretical foundations for extending existing rigorous test methods. We suggest that the replacement test, based on the complementarity of skills between human and machine, can lead to a multitude of intelligence concepts reflecting the ability to combine data-based and 
    
[^53]: 自动自我生成的零样本编码从语义级别到代码级别的 SelfzCoT，更好地利用LLMs

    SelfzCoT: a Self-Prompt Zero-shot CoT from Semantic-level to Code-level for a Better Utilization of LLMs. (arXiv:2305.11461v1 [cs.AI])

    [http://arxiv.org/abs/2305.11461](http://arxiv.org/abs/2305.11461)

    本文提出了 SelfzCoT 自动自我生成的零样本编码，通过使用LLMs和代码级别的自我提示，在六个零样本算术推理任务中实现了巨大的准确度提升。同时，修改的零样本编码 MzCoT 在推理任务中也取得了显著的表现。

    

    本文通过 SelfzCoT 自动自我生成的零样本编码，研究了如何更好地利用LLMs。具体地，我们将 SelfzCoT 应用于零样本算术推理任务，其准确性从GSM8K的40.50%提高至82.34%，MultiArith从79.3%提高至94.7%，ADDSUB从74.70%提高至94.10%，SingleEq从78.70%提高至91.30%，AQUA从31.90%提高至82.33%，SVAMP从63.70%提高至79.70%。总的来说，使用前两个持久路径激活到LLM，特别是代码级别的自我提示，使 SelfzCoT 在所有六个零样本算术推理任务上实现了巨大的改进。此外，我们修改的零样本编码 MzCoT 在推理任务中也取得了显著的表现。在GSM8K中，MzCoT的准确性从40.50%提高至76.32%，MultiArith从79.3%提高至96.97%，ADDSUB从74.70%提高至92.39%，SingleEq从78.70%提高至94.60%，AQUA从31.90%提高至79.90%，SVAMP从63.70%提高至81.50%。

    This paper show a work on better use of LLMs with SelfzCoT a self-prompt zero-shot CoT. Specifically, on the zero-shot arithmetic reasoning tasks, the accuracy of the proposed SelfzCoT is improved with GSM8K from 40.50% to 82.34%, with MultiArith from 79.3% to 94.7%, with ADDSUB from 74.70% to 94.10%, with SingleEq from 78.70% to 91.30%, with AQUA from 31.90% to 82.33%, and with SVAMP from 63.70% to 79.70%. Totally, using the first two lasting path activations to LLM and particularly, the code-level self-prompt, the SelfzCoT has a huge improvement on all six zero-shot arithmetic reasoning tasks. Additionally, our modified zero-shot CoT (MzCoT) also achieves remarkable performance in the reasoning tasks. The accuracy of the proposed MzCoT is enhanced with GSM8K from 40.50% to 76.32%, with MultiArith from 79.3% to 96.97%, with ADDSUB from 74.70% to 92.39%, with SingleEq from 78.70% to 94.60%, with AQUA from 31.90% to 79.90%, and with SVAMP from 63.70% to 81.50%. Notably, SelfzCoT has the
    
[^54]: 自我协议：微调语言模型以在不同意见之间找到共识的框架

    Self-Agreement: A Framework for Fine-tuning Language Models to Find Agreement among Diverse Opinions. (arXiv:2305.11460v1 [cs.CL])

    [http://arxiv.org/abs/2305.11460](http://arxiv.org/abs/2305.11460)

    本文提出了一种名为自我协议(Self-Agreement)的新框架，用于微调LLMs以自主地找到共识，并使用LLM自动生成的数据。

    

    在多智能体系统中找到不同意见之间的共识是一个具有挑战性的话题。最近，大型语言模型(LLMs)在解决这一挑战方面表现出了巨大的潜力，因为它们在理解人类观点和生成类人文本方面具有卓越的能力。然而，它们通常依赖于大量的人工标注数据。在本文中，我们提出了一种名为自我协议(Self-Agreement)的新框架，用于微调LLMs以自主地找到共识，并使用LLM自动生成的数据。具体而言，我们的方法使用生成式预训练变压器3(GPT-3)为问题数据集中的每个问题生成多个意见，并为这些意见创建多个共识候选项。然后，基于双向编码器表示来自变压器(BERT)的模型评估每个共识候选项的一致性得分，并选择得分最高的共识候选项。这个过程产生了一个问题-意见-共识数据集，我们使用它来微调一个模型。

    Finding an agreement among diverse opinions is a challenging topic in multiagent systems. Recently, large language models (LLMs) have shown great potential in addressing this challenge due to their remarkable capabilities in comprehending human opinions and generating human-like text. However, they typically rely on extensive human-annotated data. In this paper, we propose Self-Agreement, a novel framework for fine-tuning LLMs to autonomously find agreement using data generated by LLM itself. Specifically, our approach employs the generative pre-trained transformer-3 (GPT-3) to generate multiple opinions for each question in a question dataset and create several agreement candidates among these opinions. Then, a bidirectional encoder representations from transformers (BERT)-based model evaluates the agreement score of each agreement candidate and selects the one with the highest agreement score. This process yields a dataset of question-opinion-agreements, which we use to fine-tune a p
    
[^55]: 突破智能体-环境界面，优化具有包容性的语言模型的微调

    Shattering the Agent-Environment Interface for Fine-Tuning Inclusive Language Models. (arXiv:2305.11455v1 [cs.CL])

    [http://arxiv.org/abs/2305.11455](http://arxiv.org/abs/2305.11455)

    该论文提出了一种新颖的思路，将预训练的语言模型本身同时作为策略、奖励函数和转移函数，可以直接进行奖励学习和语言模型微调，可以带来巨大的统计收益。

    

    在微调自回归语言模型中，从人类反馈的增强学习方法（RLHF）的重要组成部分是显式训练一个奖励模型来模拟人类反馈，而不是语言模型本身。然后，将这个奖励模型与策略梯度方法耦合起来，从而显著提高语言模型输出与期望响应之间的一致性。在这项工作中，我们采取了一种新颖的观点，即预训练的语言模型本身同时是策略、奖励函数和转移函数。这个观点的一个直接结果是，可以同时直接进行奖励学习和语言模型微调，无需进一步的下游策略优化。虽然这个观点确实打破了传统智能体-环境界面，但我们仍然认为，将强化学习的传统算法概念运用于这种方法中可以带来巨大的统计收益。

    A centerpiece of the ever-popular reinforcement learning from human feedback (RLHF) approach to fine-tuning autoregressive language models is the explicit training of a reward model to emulate human feedback, distinct from the language model itself. This reward model is then coupled with policy-gradient methods to dramatically improve the alignment between language model outputs and desired responses. In this work, we adopt a novel perspective wherein a pre-trained language model is itself simultaneously a policy, reward function, and transition function. An immediate consequence of this is that reward learning and language model fine-tuning can be performed jointly and directly, without requiring any further downstream policy optimization. While this perspective does indeed break the traditional agent-environment interface, we nevertheless maintain that there can be enormous statistical benefits afforded by bringing to bear traditional algorithmic concepts from reinforcement learning.
    
[^56]: Arukikata旅游游记数据集 (arXiv:2305.11444v1 [cs.CL])

    Arukikata Travelogue Dataset. (arXiv:2305.11444v1 [cs.CL])

    [http://arxiv.org/abs/2305.11444](http://arxiv.org/abs/2305.11444)

    Arukikata旅游游记数据集是一个包含超过3100万个日文单词的数据集，包括4672个日本国内游记和9607个海外游记，为研究人员提供了可重复和透明的研究数据。

    

    我们创建了Arukikata旅游游记数据集，并免费提供给学术研究使用。该数据集包含超过3100万个日文单词，包括4672个日本国内游记和9607个海外游记。在我们提供数据集之前，很难获得可用于研究的广泛旅游游记数据，每个研究人员都必须准备自己的数据。这阻碍了对现有研究的复制以及对实验结果进行公正比较分析。我们的数据集使得任何研究人员都可以对相同的数据进行研究，并确保研究的透明度和可重复性。 在本文中，我们描述了我们的数据集的学术意义、特点和前景。

    We have constructed Arukikata Travelogue Dataset and released it free of charge for academic research. This dataset is a Japanese text dataset with a total of over 31 million words, comprising 4,672 Japanese domestic travelogues and 9,607 overseas travelogues. Before providing our dataset, there was a scarcity of widely available travelogue data for research purposes, and each researcher had to prepare their own data. This hinders the replication of existing studies and fair comparative analysis of experimental results. Our dataset enables any researchers to conduct investigation on the same data and to ensure transparency and reproducibility in research. In this paper, we describe the academic significance, characteristics, and prospects of our dataset.
    
[^57]: 基于自监督调整的零样本文本分类算法

    Zero-Shot Text Classification via Self-Supervised Tuning. (arXiv:2305.11442v1 [cs.CL])

    [http://arxiv.org/abs/2305.11442](http://arxiv.org/abs/2305.11442)

    本文提出了一种基于自监督调整的零样本文本分类算法，通过使用无标签数据来调整语言模型，通过学习预测段落中的第一句话，实现了对未见过任务的零样本推断，模型不需要注释数据进行元调整，对模板的选择不敏感，并在实验中取得不错的结果。

    

    现有的零样本文本分类方法要么使用预训练语言模型进行提示，但这种方法对模板的选择非常敏感；要么依赖于大量相关任务的注释数据进行元调整。本文提出了一种基于自监督学习的新范式，通过使用无标签数据来调整语言模型，称为自监督调整。通过探索自由文本的内在结构，我们提出了一种新的学习目标，称为首句预测，以弥合无标签数据和文本分类任务之间的差距。调整模型以学习根据剩余文本来预测段落中的第一句话后，该模型能够推断出未见过的任务，如主题分类和情感分析。实验结果表明，我们的模型在10个任务中的7个任务上优于现有基准线。此外，分析表明，我们的模型对模板的选择不敏感，并且不需要注释数据进行元调整。

    Existing solutions to zero-shot text classification either conduct prompting with pre-trained language models, which is sensitive to the choices of templates, or rely on large-scale annotated data of relevant tasks for meta-tuning. In this work, we propose a new paradigm based on self-supervised learning to solve zero-shot text classification tasks by tuning the language models with unlabeled data, called self-supervised tuning. By exploring the inherent structure of free texts, we propose a new learning objective called first sentence prediction to bridge the gap between unlabeled data and text classification tasks. After tuning the model to learn to predict the first sentence in a paragraph based on the rest, the model is able to conduct zero-shot inference on unseen tasks such as topic classification and sentiment analysis. Experimental results show that our model outperforms the state-of-the-art baselines on 7 out of 10 tasks. Moreover, the analysis reveals that our model is less s
    
[^58]: 基于部分共享生成式对抗网络的高效联合学习框架 PS-FedGAN 用于数据隐私保护

    PS-FedGAN: An Efficient Federated Learning Framework Based on Partially Shared Generative Adversarial Networks For Data Privacy. (arXiv:2305.11437v1 [cs.LG])

    [http://arxiv.org/abs/2305.11437](http://arxiv.org/abs/2305.11437)

    本文提出了一种高效的联合学习框架 PS-FedGAN，通过部分共享生成式对抗网络以保护数据隐私，实现了在分布数据环境下捕捉本地数据总体特征，相比于现有框架具有更好的收敛速度、通信开销和隐私保护效果。

    

    联邦学习（FL）因在保护数据隐私的同时更好地捕捉基础数据统计信息而成为分布式计算的有效学习范例。然而，在FL客户之间存在实际数据异构性的情况下，现有FL框架在捕捉展现不同分布的本地用户数据的总体特征性能上仍然存在不足。为此，本文提出了一种新的FL框架PS-FedGAN，只需要部分的GAN模型共享，其中包括全局鉴别网络和部分共享的生成网络，可以以部分合作的方式协作学习全局数据统计并基于部分共享GAN进行本地数据再生。

    Federated Learning (FL) has emerged as an effective learning paradigm for distributed computation owing to its strong potential in capturing underlying data statistics while preserving data privacy. However, in cases of practical data heterogeneity among FL clients, existing FL frameworks still exhibit deficiency in capturing the overall feature properties of local client data that exhibit disparate distributions. In response, generative adversarial networks (GANs) have recently been exploited in FL to address data heterogeneity since GANs can be integrated for data regeneration without exposing original raw data. Despite some successes, existing GAN-related FL frameworks often incur heavy communication cost and also elicit other privacy concerns, which limit their applications in real scenarios. To this end, this work proposes a novel FL framework that requires only partial GAN model sharing. Named as PS-FedGAN, this new framework enhances the GAN releasing and training mechanism to a
    
[^59]: 基于视觉引导的自监督语音模型中的音节发现和跨语言泛化

    Syllable Discovery and Cross-Lingual Generalization in a Visually Grounded, Self-Supervised Speech Mode. (arXiv:2305.11435v1 [eess.AS])

    [http://arxiv.org/abs/2305.11435](http://arxiv.org/abs/2305.11435)

    本文提出采用基于视觉引导的自监督语音模型进行音节发现和跨语言泛化。使用最小割算法和2阶段聚类方法自动预测语音中的音节边界。在英语上表现优于最先进的音节分割方法，并以零样本的方式在爱沙尼亚语上泛化。在其他语言上也取得了成功。

    

    本文表明，在使用基于视觉引导的训练目标训练自监督语音模型时，能够捕捉到表示音节的单元的表征。我们证明了几乎相同的模型结构（HuBERT），在使用掩码语言建模损失进行训练时没有表现出这种能力，这表明视觉引导目标导致了这种现象的出现。我们提出使用最小割算法自动预测语音中的音节边界，然后使用两阶段聚类方法将相同的音节组合在一起。我们展示了，我们的模型不仅在训练的语言（英语）上优于最先进的音节分割方法，而且在爱沙尼亚语上以零样本的方式进行泛化。最后，我们展示了相同的模型能够进行4种其他语言的零样本单词分割任务泛化，在某些情况下击败了先前的最先进技术。

    In this paper, we show that representations capturing syllabic units emerge when training a self-supervised speech model with a visually-grounded training objective. We demonstrate that a nearly identical model architecture (HuBERT) trained with a masked language modeling loss does not exhibit this same ability, suggesting that the visual grounding objective is responsible for the emergence of this phenomenon. We propose the use of a minimum cut algorithm to automatically predict syllable boundaries in speech, followed by a 2-stage clustering method to group identical syllables together. We show that our model not only outperforms a state-of-the-art syllabic segmentation method on the language it was trained on (English), but also generalizes in a zero-shot fashion to Estonian. Finally, we show that the same model is capable of zero-shot generalization for a word segmentation task on 4 other languages from the Zerospeech Challenge, in some cases beating the previous state-of-the-art.
    
[^60]: TELeR：用于基准测试复杂任务的LLM提示的通用分类法

    TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks. (arXiv:2305.11430v1 [cs.AI])

    [http://arxiv.org/abs/2305.11430](http://arxiv.org/abs/2305.11430)

    本文提出了一个通用分类法，可以用来设计具有特定属性的提示来执行各种复杂任务，从而解决了LLM在执行复杂任务方面的性能变异巨大的问题。

    

    尽管LLM在传统对话环境中理解和生成文本时取得了巨大成功，但它们在执行不明确的复杂任务方面的潜力仍然受到很少的研究。本文提出了一种通用分类法，可以用来设计具有特定属性的提示，以执行各种复杂任务，从而解决了使用不同提示类型/风格和提示提供的不同详细程度时LLM性能变化巨大的问题。这个分类法将使未来的基准测试研究能够报告研究中使用的特定提示类别，从而实现跨不同研究的有意义的比较。

    While LLMs have shown great success in understanding and generating text in traditional conversational settings, their potential for performing ill-defined complex tasks is largely under-studied. Indeed, we are yet to conduct comprehensive benchmarking studies with multiple LLMs that are exclusively focused on a complex task. However, conducting such benchmarking studies is challenging because of the large variations in LLMs' performance when different prompt types/styles are used and different degrees of detail are provided in the prompts. To address this issue, the paper proposes a general taxonomy that can be used to design prompts with specific properties in order to perform a wide range of complex tasks. This taxonomy will allow future benchmarking studies to report the specific categories of prompts used as part of the study, enabling meaningful comparisons across different studies. Also, by establishing a common standard through this taxonomy, researchers will be able to draw mo
    
[^61]: 后验解释可以提高语言模型的性能

    Post Hoc Explanations of Language Models Can Improve Language Models. (arXiv:2305.11426v1 [cs.CL])

    [http://arxiv.org/abs/2305.11426](http://arxiv.org/abs/2305.11426)

    本文提出了一种新的框架AMPLIFY，利用后验解释自动化生成原因，并在多个数据集和任务上显著提高现有语言模型的性能。

    

    大型语言模型在执行复杂任务方面表现出了非凡的能力。最近的研究显示，在上下文学习过程中加入人类注释的原理（例如，思维链提示）可以显著提高这些模型的性能，特别是在需要推理能力的任务上。然而，这样的原理加入在可扩展性方面存在挑战，因为这需要高度的人工参与。本文提出了一种新框架，即通过利用后验解释的上下文学习来放大模型性能，来解决上述挑战。为此，我们利用后验解释方法的结果，该方法输出称为属性分数（解释）的值，用于捕获每个输入特征对模型预测的影响。更具体地说，我们构建了自动化的自然语言原理，其中包含从属性分数中获得的信息，以便用户可以更好地理解模型的决策。实验结果表明，AMPLIFY可以在多个数据集和任务上显著提高现有语言模型的性能。

    Large Language Models (LLMs) have demonstrated remarkable capabilities in performing complex tasks. Moreover, recent research has shown that incorporating human-annotated rationales (e.g., Chain-of- Thought prompting) during in-context learning can significantly enhance the performance of these models, particularly on tasks that require reasoning capabilities. However, incorporating such rationales poses challenges in terms of scalability as this requires a high degree of human involvement. In this work, we present a novel framework, Amplifying Model Performance by Leveraging In-Context Learning with Post Hoc Explanations (AMPLIFY), which addresses the aforementioned challenges by automating the process of rationale generation. To this end, we leverage post hoc explanation methods which output attribution scores (explanations) capturing the influence of each of the input features on model predictions. More specifically, we construct automated natural language rationales that embed insi
    
[^62]: 图传播变换器用于图表示学习

    Graph Propagation Transformer for Graph Representation Learning. (arXiv:2305.11424v1 [cs.LG])

    [http://arxiv.org/abs/2305.11424](http://arxiv.org/abs/2305.11424)

    本文提出了一种新的变换器架构 GPTrans，以图传播注意力为基础，可以更好地学习图形模型，并在多个基准测试集上超过了其他最先进的基于变换器的图形模型。

    

    本文提出了一种用于图表示学习的新型变换器架构。我们的方法的核心见解是在构建变换器块中的注意力模块时，充分考虑图中节点和边之间的信息传播。具体而言，我们提出了一种新的注意力机制称为图传播注意力（GPA），它将信息在节点和边之间以三种方式明确传递，即从节点到节点，从节点到边和从边到节点，这对于学习图结构数据至关重要。在此基础上，我们设计了一种名为图传播变换器（GPTrans）的有效变换器架构，进一步帮助学习图数据。我们在几个基准数据集上的广泛图学习实验中验证了GPTrans的性能。这些结果表明，我们的方法以更好的性能超过了许多最先进的基于变换器的图形模型。代码将在https://github.com/czczup/GPTrans上发布。

    This paper presents a novel transformer architecture for graph representation learning. The core insight of our method is to fully consider the information propagation among nodes and edges in a graph when building the attention module in the transformer blocks. Specifically, we propose a new attention mechanism called Graph Propagation Attention (GPA). It explicitly passes the information among nodes and edges in three ways, i.e. node-to-node, node-to-edge, and edge-to-node, which is essential for learning graph-structured data. On this basis, we design an effective transformer architecture named Graph Propagation Transformer (GPTrans) to further help learn graph data. We verify the performance of GPTrans in a wide range of graph learning experiments on several benchmark datasets. These results show that our method outperforms many state-of-the-art transformer-based graph models with better performance. The code will be released at https://github.com/czczup/GPTrans.
    
[^63]: PastNet：引入物理归纳偏差用于时空视频预测

    PastNet: Introducing Physical Inductive Biases for Spatio-temporal Video Prediction. (arXiv:2305.11421v1 [cs.CV])

    [http://arxiv.org/abs/2305.11421](http://arxiv.org/abs/2305.11421)

    本文介绍了一种名为PastNet的新颖方法，通过在傅里叶域中引入谱卷积算子，利用内在的物理知识生成高质量的时空视频预测，并通过离散化局部特征降低计算成本。

    

    本文研究了时空视频预测的挑战，其中涉及根据历史数据流生成未来视频。现有方法通常利用语义地图等外部信息增强视频预测，但常常忽视视频内固有的物理知识。此外，它们的高计算需求可能会阻碍对高分辨率视频的应用。为解决这些限制，我们引入了一种新颖的方法，称为物理辅助时空网络（PastNet），用于生成高质量的视频预测。我们的PastNet核心在于在傅里叶域中引入谱卷积算子，从而有效地引入基本物理定律的归纳偏差。此外，我们使用一个内在维度估计的存储器库，在处理复杂的时空信号时离散化局部特征，从而降低计算成本。

    In this paper, we investigate the challenge of spatio-temporal video prediction, which involves generating future videos based on historical data streams. Existing approaches typically utilize external information such as semantic maps to enhance video prediction, which often neglect the inherent physical knowledge embedded within videos. Furthermore, their high computational demands could impede their applications for high-resolution videos. To address these constraints, we introduce a novel approach called Physics-assisted Spatio-temporal Network (PastNet) for generating high-quality video predictions. The core of our PastNet lies in incorporating a spectral convolution operator in the Fourier domain, which efficiently introduces inductive biases from the underlying physical laws. Additionally, we employ a memory bank with the estimated intrinsic dimensionality to discretize local features during the processing of complex spatio-temporal signals, thereby reducing computational costs 
    
[^64]: JetSeg: 低功耗GPU嵌入式系统的高效实时语义分割模型

    JetSeg: Efficient Real-Time Semantic Segmentation Model for Low-Power GPU-Embedded Systems. (arXiv:2305.11419v1 [cs.CV])

    [http://arxiv.org/abs/2305.11419](http://arxiv.org/abs/2305.11419)

    JetSeg是一个专为GPU-嵌入式系统设计的高效实时语义分割模型，通过新型的轻量级高效块JetBlock和结合了不对称和非对称卷积、深度空洞卷积、通道混洗操作、轻量级激活函数和适用于嵌入式系统的方便数量的组卷积的策略JetConv以及创新的损失函数JetLoss，在保持高精度的同时，明显减少了内存使用量和推理时间，优于最先进的模型。

    

    实时语义分割是一项具有挑战性的任务，需要精准和具有低推理时间的模型。在嵌入式系统上实现这些模型受到硬件能力和内存使用的限制，导致了瓶颈。我们提出了一种名为JetSeg的实时语义分割高效模型，由一个称为JetNet的编码器和一个改进的RegSeg解码器组成。JetNet专为GPU嵌入式系统设计，并包括两个主要组件：一个称为JetBlock的新型轻量级高效块，通过减少参数数量来最小化内存使用和推理时间，而不会牺牲准确性；一种称为JetConv 的新策略，它结合了不对称和非对称卷积、深度空洞卷积、通道混洗操作、轻量级激活函数和适用于嵌入式系统的方便数量的组卷积，并引入一种创新的损失函数JetLoss，它集成了精确度、召回率和F1分值。实验结果表明，JetSeg在保持高精度的同时，明显减少了内存使用量和推理时间，并优于最先进的模型。

    Real-time semantic segmentation is a challenging task that requires high-accuracy models with low-inference times. Implementing these models on embedded systems is limited by hardware capability and memory usage, which produces bottlenecks. We propose an efficient model for real-time semantic segmentation called JetSeg, consisting of an encoder called JetNet, and an improved RegSeg decoder. The JetNet is designed for GPU-Embedded Systems and includes two main components: a new light-weight efficient block called JetBlock, that reduces the number of parameters minimizing memory usage and inference time without sacrificing accuracy; a new strategy that involves the combination of asymmetric and non-asymmetric convolutions with depthwise-dilated convolutions called JetConv, a channel shuffle operation, light-weight activation functions, and a convenient number of group convolutions for embedded systems, and an innovative loss function named JetLoss, which integrates the Precision, Recall,
    
[^65]: 联邦基础模型：用于大模型的隐私保护协作学习

    Federated Foundation Models: Privacy-Preserving and Collaborative Learning for Large Models. (arXiv:2305.11414v1 [cs.LG])

    [http://arxiv.org/abs/2305.11414](http://arxiv.org/abs/2305.11414)

    本文提出了联邦基础模型（FFMs）的概念，结合了基础模型和联邦学习的优势，可实现跨多个机构的隐私保护和协作学习。

    

    基础模型通常需要大量数据进行预训练，如BERT、GPT、ViT和CLIP，但其优化通常需要访问敏感数据，引发隐私问题并限制其适用性。为解决这一问题，本文提出了联邦基础模型（FFMs）的概念，这是一种新颖的方法，结合了基础模型和联邦学习的优势，可实现跨多个机构的隐私保护和协作学习。

    Foundation Models (FMs), such as BERT, GPT, ViT, and CLIP, have demonstrated remarkable success in a wide range of applications, driven by their ability to leverage vast amounts of data for pre-training. However, optimizing FMs often requires access to sensitive data, raising privacy concerns and limiting their applicability in certain domains. In this paper, we introduce the concept of Federated Foundation Models (FFMs), a novel approach that combines the benefits of FMs and Federated Learning (FL) to enable privacy-preserving and collaborative learning across multiple institutions. We discuss the potential benefits and challenges of integrating FL into the lifespan of FMs, covering pre-training, fine-tuning, and application. We further provide formal definitions of FFM tasks, including FFM pre-training, FFM fine-tuning, and federated prompt engineering, allowing for more personalized and context-aware models while maintaining data privacy. Moreover, we explore the possibility of cont
    
[^66]: LATTE: 从纵向电子健康记录中高效标注事件类型

    LATTE: Label-efficient Incident Phenotyping from Longitudinal Electronic Health Records. (arXiv:2305.11407v1 [cs.AI])

    [http://arxiv.org/abs/2305.11407](http://arxiv.org/abs/2305.11407)

    本文提出了一种标签高效的事件类型标注算法（LATTE），用于准确标注纵向EHR数据中的临床事件时间，通过时间模式挖掘构建高度信息化的纵向银标准事件标签，并在MIMIC-III数据集上实现了7.57％和10.82％的绝对改善。

    

    电子健康记录（EHR）数据越来越多地用于支持实际证据（RWE）研究。然而，它生成可靠的RWE的能力受到限制，因为缺乏有关临床事件的时间（例如心力衰竭发作时间）的精确信息。本文提出了一种标签高效的事件类型标注算法（LATTE），以准确标注纵向EHR数据中的临床事件时间。通过利用预先训练的语义嵌入向量，根据与目标事件的关系挖掘它们的相关性，LATTE在概念重新加权模块中选择具有预测能力的EHR特征，并通过访问注意力学习网络将其信息压缩为纵向访问嵌入。LATTE使用递归神经网络捕捉目标事件之前/之后的顺序依赖关系和访问嵌入。为了提高标签效率，LATTE通过时间模式挖掘构建高度信息化的纵向银标准事件标签（SSEL），利用未标记的观测数据提高模型的泛化能力。在MIMIC-III数据集上的结果表明，LATTE优于最先进的方法，在预测急性肾损伤发作方面，在精确度和召回率方面分别实现了7.57％和10.82％的绝对改善。

    Electronic health record (EHR) data are increasingly used to support real-world evidence (RWE) studies. Yet its ability to generate reliable RWE is limited by the lack of readily available precise information on the timing of clinical events such as the onset time of heart failure. We propose a LAbel-efficienT incidenT phEnotyping (LATTE) algorithm to accurately annotate the timing of clinical events from longitudinal EHR data. By leveraging the pre-trained semantic embedding vectors from large-scale EHR data as prior knowledge, LATTE selects predictive EHR features in a concept re-weighting module by mining their relationship to the target event and compresses their information into longitudinal visit embeddings through a visit attention learning network. LATTE employs a recurrent neural network to capture the sequential dependency between the target event and visit embeddings before/after it. To improve label efficiency, LATTE constructs highly informative longitudinal silver-standar
    
[^67]: 通过验证和验证的视角对大型语言模型的安全性和可信度进行调查

    A Survey of Safety and Trustworthiness of Large Language Models through the Lens of Verification and Validation. (arXiv:2305.11391v1 [cs.AI])

    [http://arxiv.org/abs/2305.11391](http://arxiv.org/abs/2305.11391)

    通过验证和验证的视角对大型语言模型的安全性和可信度进行调查，分类它们的已知漏洞，将其分为固有问题、有意攻击和意外错误。同时，考虑四种互补技术以提供LLM及其应用的安全和可信度保障。

    

    大型语言模型（LLM）以其在许多知识领域中为终端用户提供详细和有条理的答案，并能够进行人类级别的对话能力，引发了AI的一波新热潮。为了应对它们在许多工业应用中的快速采用，本次调查关注它们的安全性和可信度。首先，我们回顾LLM的已知漏洞，将它们分类为固有问题、有意攻击和意外错误。然后，我们考虑是否以及如何将已被广泛用于传统软件和深度学习模型（如卷积神经网络）的验证和验证（V＆V）技术，集成并进一步扩展到LLM的整个生命周期中，以提供严格的分析，确保LLM及其应用的安全和可信度。具体而言，我们考虑四种互补技术：虚假性和评估、验证、运行时监视和道德使用。考虑到LLM的快速发展，

    Large Language Models (LLMs) have exploded a new heatwave of AI, for their ability to engage end-users in human-level conversations with detailed and articulate answers across many knowledge domains. In response to their fast adoption in many industrial applications, this survey concerns their safety and trustworthiness. First, we review known vulnerabilities of the LLMs, categorising them into inherent issues, intended attacks, and unintended bugs. Then, we consider if and how the Verification and Validation (V&V) techniques, which have been widely developed for traditional software and deep learning models such as convolutional neural networks, can be integrated and further extended throughout the lifecycle of the LLMs to provide rigorous analysis to the safety and trustworthiness of LLMs and their applications. Specifically, we consider four complementary techniques: falsification and evaluation, verification, runtime monitoring, and ethical use. Considering the fast development of 
    
[^68]: ALT: 一种用于长尾场景建模的自动化系统

    ALT: An Automatic System for Long Tail Scenario Modeling. (arXiv:2305.11390v1 [cs.LG])

    [http://arxiv.org/abs/2305.11390](http://arxiv.org/abs/2305.11390)

    本文提出了一种名为ALT的自动化系统，用于解决长尾场景建模问题，实现了对于模型训练和推理阶段人力和资源有限的情况下的有效建模需求。

    

    本文考虑了长尾场景建模的问题，其中包括对于模型训练阶段人力资源不足以及模型推理阶段时间和计算资源有限的情况。我们提出了一种名为ALT的自动化系统来解决这个问题。我们采用了多种自动化机器学习相关技术，采用元学习哲学，并提出了一种基于有限预算的神经架构搜索方法等，以改进系统中使用的算法。此外，从系统的角度进行了多项优化，并加入了必要的模块，使系统更具可行性和效率。我们进行了大量实验证明我们的系统的有效性，并展示了我们系统中关键模块的实用性。

    In this paper, we consider the problem of long tail scenario modeling with budget limitation, i.e., insufficient human resources for model training stage and limited time and computing resources for model inference stage. This problem is widely encountered in various applications, yet has received deficient attention so far. We present an automatic system named ALT to deal with this problem. Several efforts are taken to improve the algorithms used in our system, such as employing various automatic machine learning related techniques, adopting the meta learning philosophy, and proposing an essential budget-limited neural architecture search method, etc. Moreover, to build the system, many optimizations are performed from a systematic perspective, and essential modules are armed, making the system more feasible and efficient. We perform abundant experiments to validate the effectiveness of our system and demonstrate the usefulness of the critical modules in our system. Moreover, online r
    
[^69]: 面向领域泛化的深度图形转换方法

    Domain Generalization Deep Graph Transformation. (arXiv:2305.11389v1 [cs.LG])

    [http://arxiv.org/abs/2305.11389](http://arxiv.org/abs/2305.11389)

    本文提出了一种面向领域泛化的深度图形转换方法，使用超网络进行多输入多输出的图神经网络预测，通过加入潜在变量来训练泛化模型，在多个基准数据集中取得了优异表现。

    

    预测图形从一种模式转变为另一种模式的图形转换是一个重要和常见的问题。近年来，虽然在开发先进的图形转换技术方面取得了很多进展，但通常需要机器学习模型所需的基本假设是测试和训练数据保持相同的分布，并不总是成立。因此，预测在训练数据中不可用的图形的领域泛化图形转换是一个未被充分探索的领域，需要解决多个关键挑战，包括（1）当训练所有输入-输出模式组合时的极端空间复杂度、（2）输入和输出模式之间的图形拓扑差异，以及(3)如何将模型泛化到在训练数据中不存在的（未见过的）目标域。为了填补这一空白，我们提出了一种基于深度图神经网络的多输入-多输出、超网络的图形转换方法（MultiHyperGNN），它利用编码器和解码器来编码输入和输出图的拓扑结构，并生成输出图。我们还设计了一个领域泛化框架，通过加入捕捉领域特定信息的潜在变量，来以有限的标记数据训练所提出的模型。实验结果表明，我们提出的方法在几个基准数据集上优于基线方法。

    Graph transformation that predicts graph transition from one mode to another is an important and common problem. Despite much progress in developing advanced graph transformation techniques in recent years, the fundamental assumption typically required in machine-learning models that the testing and training data preserve the same distribution does not always hold. As a result, domain generalization graph transformation that predicts graphs not available in the training data is under-explored, with multiple key challenges to be addressed including (1) the extreme space complexity when training on all input-output mode combinations, (2) difference of graph topologies between the input and the output modes, and (3) how to generalize the model to (unseen) target domains that are not in the training data. To fill the gap, we propose a multi-input, multi-output, hypernetwork-based graph neural network (MultiHyperGNN) that employs a encoder and a decoder to encode topologies of both input an
    
[^70]: 信息瓶颈理论的公正之声

    Justices for Information Bottleneck Theory. (arXiv:2305.11387v1 [cs.LG])

    [http://arxiv.org/abs/2305.11387](http://arxiv.org/abs/2305.11387)

    本论文从引入一个辅助函数，证明深度学习中ReLU激活下互信息下降的悖论，挑战了对信息瓶颈理论适用性的质疑，提供了使用该理论解释DL网络内部组织的新方法。

    

    本研究对信息瓶颈（IB）理论不断增加的质疑做出及时回应，注入新的观点以纠正误解并重申其有效性。首先，我们引入一种辅助函数，将最大编码率降低法解释为信息瓶颈理论的特殊但局部最优情况。通过这种辅助函数，我们澄清了在深度学习（DL）网络中应用ReLU激活时互信息下降的悖论。其次，我们通过辅助函数的视角，证明了IB理论解释线性激活函数在隐藏层中没有压缩阶段的能力，挑战了对IB理论适用性的质疑。最后，通过提出一种新的理论观点，我们使用IB理论提供了一种解释DL网络内部组织的新方法，并与最近的实验证据相一致。因此，本文是对IB理论的公正之声，也为未来该理论的发展提供了前瞻性的思考。

    This study comes as a timely response to mounting criticism of the information bottleneck (IB) theory, injecting fresh perspectives to rectify misconceptions and reaffirm its validity. Firstly, we introduce an auxiliary function to reinterpret the maximal coding rate reduction method as a special yet local optimal case of IB theory. Through this auxiliary function, we clarify the paradox of decreasing mutual information during the application of ReLU activation in deep learning (DL) networks. Secondly, we challenge the doubts about IB theory's applicability by demonstrating its capacity to explain the absence of a compression phase with linear activation functions in hidden layers, when viewed through the lens of the auxiliary function. Lastly, by taking a novel theoretical stance, we provide a new way to interpret the inner organizations of DL networks by using IB theory, aligning them with recent experimental evidence. Thus, this paper serves as an act of justice for IB theory, poten
    
[^71]: 大型语言模型合成文本数据集的语言多样性可视化

    Visualizing Linguistic Diversity of Text Datasets Synthesized by Large Language Models. (arXiv:2305.11364v1 [cs.CL])

    [http://arxiv.org/abs/2305.11364](http://arxiv.org/abs/2305.11364)

    该论文介绍了一种新的可视化工具，用于分析大型语言模型生成的数据集的句法多样性，可以通过分层可视化来帮助用户快速浏览概述和检查各个示例。

    

    大型语言模型（LLMs）可通过少量提示生成更精细的数据集用于基准测试、微调或其他用例。然而，理解和评估这些数据集很困难，而LLM生成数据的失败模式仍不为人们所理解。具体来说，数据可能以意外的方式变得重复，不仅语义上如此，而且在句法、词汇方面也是如此。我们提出了LinguisticLens，一种新颖的交互式可视化工具，用于理解和分析LLM生成数据集的句法多样性。 LinguisticLens沿着句法、词汇和语义轴将文本聚类。它支持文本数据集的分层可视化，允许用户快速浏览概述和检查各个示例。实时演示可在shorturl.at/zHOUV查看。

    Large language models (LLMs) can be used to generate smaller, more refined datasets via few-shot prompting for benchmarking, fine-tuning or other use cases. However, understanding and evaluating these datasets is difficult, and the failure modes of LLM-generated data are still not well understood. Specifically, the data can be repetitive in surprising ways, not only semantically but also syntactically and lexically. We present LinguisticLens, a novel inter-active visualization tool for making sense of and analyzing syntactic diversity of LLM-generated datasets. LinguisticLens clusters text along syntactic, lexical, and semantic axes. It supports hierarchical visualization of a text dataset, allowing users to quickly scan for an overview and inspect individual examples. The live demo is available at shorturl.at/zHOUV.
    
[^72]: 具有闭式求解器的异质性处理效应估计元学习方法

    Meta-learning for heterogeneous treatment effect estimation with closed-form solvers. (arXiv:2305.11353v1 [stat.ML])

    [http://arxiv.org/abs/2305.11353](http://arxiv.org/abs/2305.11353)

    本文提出了一种元学习方法，用于从少量的观测数据中估计条件平均处理效应（CATE），该方法通过神经网络模型对CATE估计问题进行分解并使用闭式求解器获得参数，最终实现了任务之间的共享和优化CATE估计表现提升。

    

    本文提出了一种元学习方法，用于从少量的观察数据中估计条件平均处理效应（CATE）。所提出的方法学习如何从多个任务中估计CATE，并使用这些知识来进行未见过的任务。在该方法中，基于元学习框架，我们将CATE估计问题分解为子问题。对于每个子问题，我们使用具有任务共享和任务特定参数的神经网络来构建我们的估计模型。通过我们的公式化，我们可以获得可微分的闭式的最优任务特定参数，这些参数能够相对于任务共享参数进行有效的元学习。我们训练任务共享参数，以使少示点设置下的CATE估计表现通过将使用大量数据估计的CATE与仅使用少量数据估计的CATE之间的差异最小化得到改善。我们的实验结果表明，我们的方法在CATE估计方面具有优越性。

    This article proposes a meta-learning method for estimating the conditional average treatment effect (CATE) from a few observational data. The proposed method learns how to estimate CATEs from multiple tasks and uses the knowledge for unseen tasks. In the proposed method, based on the meta-learner framework, we decompose the CATE estimation problem into sub-problems. For each sub-problem, we formulate our estimation models using neural networks with task-shared and task-specific parameters. With our formulation, we can obtain optimal task-specific parameters in a closed form that are differentiable with respect to task-shared parameters, making it possible to perform effective meta-learning. The task-shared parameters are trained such that the expected CATE estimation performance in few-shot settings is improved by minimizing the difference between a CATE estimated with a large amount of data and one estimated with just a few data. Our experimental results demonstrate that our method o
    
[^73]: 深度多光谱分割模型对自然扰动和数据污染的鲁棒性量化研究

    Quantifying the robustness of deep multispectral segmentation models against natural perturbations and data poisoning. (arXiv:2305.11347v1 [cs.CV])

    [http://arxiv.org/abs/2305.11347](http://arxiv.org/abs/2305.11347)

    本研究通过对多光谱图像分割模型进行实验，发现多光谱数据不能提高模型对自然扰动的鲁棒性，同时模型对抗攻击的鲁棒性取决于攻击方法和使用的特定光谱波段。

    

    在航空图像分割任务中，除了传统的RGB通道之外，包括更多光谱波段可以提高模型性能。然而，将这些额外数据纳入模型对对抗性攻击和自然扰动的抵抗力如何影响仍不清楚。本文旨在表征多光谱（RGB和近红外）图像分割模型在面对对抗攻击和自然扰动时的性能和鲁棒性。我们的实验表明，虽然多光谱数据能提高模型性能，但并不一定能提高其对自然扰动的鲁棒性。此外，我们发现，模型对抗攻击的鲁棒性很大程度上取决于所使用的攻击方法和使用的特定光谱波段。

    In overhead image segmentation tasks, including additional spectral bands beyond the traditional RGB channels can improve model performance. However, it is still unclear how incorporating this additional data impacts model robustness to adversarial attacks and natural perturbations. For adversarial robustness, the additional information could improve the model's ability to distinguish malicious inputs, or simply provide new attack avenues and vulnerabilities. For natural perturbations, the additional information could better inform model decisions and weaken perturbation effects or have no significant influence at all. In this work, we seek to characterize the performance and robustness of a multispectral (RGB and near infrared) image segmentation model subjected to adversarial attacks and natural perturbations. While existing adversarial and natural robustness research has focused primarily on digital perturbations, we prioritize on creating realistic perturbations designed with physi
    
[^74]: 编写自己的书：一种从闭合到开放式书本QA的方法，改善较小LLM的健壮性和性能。

    Writing your own book: A method for going from closed to open book QA to improve robustness and performance of smaller LLMs. (arXiv:2305.11334v1 [cs.CL])

    [http://arxiv.org/abs/2305.11334](http://arxiv.org/abs/2305.11334)

    本文介绍了两种新颖的方法，Tree-Search和自我上下文QA，可提高大型语言模型在问答任务中的性能。Tree-Search采样技术有助于从提示中提取多样化信息，而自我上下文QA可使模型创建自己的上下文，生成更好的开放式答案。此外，这些方法可提高健壮性和性能。

    

    我们介绍了两种新颖的方法，Tree-Search和自我上下文QA，旨在提高大型语言模型（LLMs）在问答任务中的性能。 Tree-Search是一种采样技术，专门用于从给定提示的LLM中提取多样化的信息。自我上下文QA利用Tree-Search，使模型能够使用与提示相关的各种信息创建自己的上下文，明确评估并返回初始提示的开放式答案。我们证明了按照各种指标（包括GPT3.5（text-davinci-003）评估的准确性、信息量、连贯性和一致性）评估的生成答案质量得到了改善。此外，我们表明，我们的方法导致了增加的健壮性，并且性能与树大小呈正相关，从而有益于答案质量和健壮性。最后，我们讨论了Tree-Search的其他有 promising 应用，突出了其提高较小LLM健壮性和性能的潜力。

    We introduce two novel methods, Tree-Search and Self-contextualizing QA, designed to enhance the performance of large language models (LLMs) in question-answering tasks. Tree-Search is a sampling technique specifically created to extract diverse information from an LLM for a given prompt. Self-contextualizing QA leverages Tree-Search to enable the model to create its own context using a wide range of information relevant to the prompt, evaluate it explicitly and return a open book answer to the initial prompt . We demonstrate that the quality of generated answers improves according to various metrics, including accuracy, informativeness, coherence, and consistency, as evaluated by GPT3.5(text-davinci-003). Furthermore, we show that our methods result in increased robustness and that performance is positively correlated with tree size, benefiting both answer quality and robustness. Finally, we discuss other promising applications of Tree-Search, highlighting its potential to enhance a b
    
[^75]: SpikeCP: 通过极限预测实现延迟自适应可靠脉冲神经网络

    SpikeCP: Delay-Adaptive Reliable Spiking Neural Networks via Conformal Prediction. (arXiv:2305.11322v1 [cs.NE])

    [http://arxiv.org/abs/2305.11322](http://arxiv.org/abs/2305.11322)

    这篇论文提出了一种新的脉冲神经网络模型，能够通过极限预测实现自适应的推断延迟，从而节约能源与提高可靠性。

    

    脉冲神经网络（SNN）通过内部事件驱动的神经动态处理时间序列数据，其能量消耗取决于输入演示期间神经元之间交换的脉冲数量。在典型的SNN分类器实现中，决策是在整个输入序列被处理后产生的，导致延迟和能量消耗水平在输入之间是相对均匀的。最近引入的延迟自适应SNN可根据每个示例的难度来定制推断延迟 - 以及随之而来的能耗 - 通过在SNN模型足够“自信”时产生早期决策来实现。

    Spiking neural networks (SNNs) process time-series data via internal event-driven neural dynamics whose energy consumption depends on the number of spikes exchanged between neurons over the course of the input presentation. In typical implementations of an SNN classifier, decisions are produced after the entire input sequence has been processed, resulting in latency and energy consumption levels that are fairly uniform across inputs. Recently introduced delay-adaptive SNNs tailor the inference latency -- and, with it, the energy consumption -- to the difficulty of each example, by producing an early decision when the SNN model is sufficiently ``confident''. In this paper, we start by observing that, as an SNN processes input samples, its classification decisions tend to be first under-confident and then over-confident with respect to the decision's ground-truth, unknown, test accuracy. This makes it difficult to determine a stopping time that ensures a desired level of accuracy. To add
    
[^76]: 针对语音合成口音适应的参数高效学习方法

    Parameter-Efficient Learning for Text-to-Speech Accent Adaptation. (arXiv:2305.11320v1 [cs.SD])

    [http://arxiv.org/abs/2305.11320](http://arxiv.org/abs/2305.11320)

    本文提出了一种参数高效学习方法（PEL），利用理论基础的最优传输（OT）来实现低资源语音合成口音适应，通过引入基于OT的辅助无监督损失来最大化源域和目标域之间的差异，从而提高系统性能。

    

    本文提出了一种参数高效学习方法（PEL）来开发低资源的语音合成口音适应。通过使用原始可训练参数的1.2％至0.8％，从已冻结的预训练TTS模型中开发出资源高效的适应模型，以实现有竞争力的语音合成性能。本研究基于最优传输（OT）的理论基础，进行TTS的PEL，引入了一个基于OT的辅助无监督损失，以最大化预训练源域和（未见过的）目标域之间的差异，除了有监督的训练损失。此外，我们利用这个无监督的损失细化来通过切片瓦瑟斯坦距离或最大均值差异来提高系统性能。本研究的优点是在评估普通话口音适应时，通过使用残差适配器学习和模型重编程来实现PEL解决方案。

    This paper presents a parameter-efficient learning (PEL) to develop a low-resource accent adaptation for text-to-speech (TTS). A resource-efficient adaptation from a frozen pre-trained TTS model is developed by using only 1.2\% to 0.8\% of original trainable parameters to achieve competitive performance in voice synthesis. Motivated by a theoretical foundation of optimal transport (OT), this study carries out PEL for TTS where an auxiliary unsupervised loss based on OT is introduced to maximize a difference between the pre-trained source domain and the (unseen) target domain, in addition to its supervised training loss. Further, we leverage upon this unsupervised loss refinement to boost system performance via either sliced Wasserstein distance or maximum mean discrepancy. The merit of this work is demonstrated by fulfilling PEL solutions based on residual adapter learning, and model reprogramming when evaluating the Mandarin accent adaptation. Experiment results show that the proposed
    
[^77]: BELLA: 通过本地线性逼近进行黑盒模型解释

    BELLA: Black box model Explanations by Local Linear Approximations. (arXiv:2305.11311v1 [cs.LG])

    [http://arxiv.org/abs/2305.11311](http://arxiv.org/abs/2305.11311)

    本文提出了一种确定性的、与模型无关的事后方法BELLA，用于解释回归黑盒模型的个别预测。该方法通过特征空间中训练的线性模型提供解释，使得该模型的系数可以直接用于计算特征值的预测值。此外，BELLA最大化了线性模型适用的领域范围。

    

    近年来，理解黑盒模型的决策过程不仅成为法律要求，也成为评估其性能的另一种方式。然而，现有的事后解释方法依赖于合成数据生成，这引入了不确定性并可能损害解释的可靠性，并且它们 tend to produce explanations that apply to only very few data points. This makes the explanations brittle and limited in scope. Finally, they provide scores that have no direct verifiable meaning. In this paper, we present BELLA, a deterministic model-agnostic post-hoc approach for explaining the individual predictions of regression black-box models. BELLA provides explanations in the form of a linear model trained in the feature space. Thus, its coefficients can be used directly to compute the predicted value from the feature values. Furthermore, BELLA maximizes the size of the neighborhood to which the linear model a

    In recent years, understanding the decision-making process of black-box models has become not only a legal requirement but also an additional way to assess their performance. However, the state of the art post-hoc interpretation approaches rely on synthetic data generation. This introduces uncertainty and can hurt the reliability of the interpretations. Furthermore, they tend to produce explanations that apply to only very few data points. This makes the explanations brittle and limited in scope. Finally, they provide scores that have no direct verifiable meaning. In this paper, we present BELLA, a deterministic model-agnostic post-hoc approach for explaining the individual predictions of regression black-box models. BELLA provides explanations in the form of a linear model trained in the feature space. Thus, its coefficients can be used directly to compute the predicted value from the feature values. Furthermore, BELLA maximizes the size of the neighborhood to which the linear model a
    
[^78]: 设计中的反事实：一种模型无关的设计建议方法

    Counterfactuals for Design: A Model-Agnostic Method For Design Recommendations. (arXiv:2305.11308v1 [cs.AI])

    [http://arxiv.org/abs/2305.11308](http://arxiv.org/abs/2305.11308)

    本文介绍了一种多目标设计反事实(MCD)方法，可帮助设计师识别设计修改，提高功能性能。MCD通过支持多目标查询和解耦反事实搜索和采样过程来提高效率并改进现有的反事实搜索方法，证明其在自行车设计案例中的有效性。

    

    本文介绍了一种新型的设计问题反事实优化方法——多目标设计反事实(MCD)。反事实是指可能导致不同决策或选择的假设情况。本文将反事实搜索问题框架化为设计建议工具，可以帮助识别对设计进行修改，从而提高功能性能。MCD通过支持多目标查询和解耦反事实搜索和采样过程来提高效率并促进目标权衡可视化，改进了现有的反事实搜索方法。本文使用二维测试案例证明了MCD的核心功能，然后通过三个自行车设计案例研究展示了MCD在实际设计问题中的有效性。在第一个案例研究中，MCD在推荐对查询设计进行修改方面表现出色，可以显著提高自行车的性能。

    We introduce Multi-Objective Counterfactuals for Design (MCD), a novel method for counterfactual optimization in design problems. Counterfactuals are hypothetical situations that can lead to a different decision or choice. In this paper, the authors frame the counterfactual search problem as a design recommendation tool that can help identify modifications to a design, leading to better functional performance. MCD improves upon existing counterfactual search methods by supporting multi-objective queries, which are crucial in design problems, and by decoupling the counterfactual search and sampling processes, thus enhancing efficiency and facilitating objective tradeoff visualization. The paper demonstrates MCD's core functionality using a two-dimensional test case, followed by three case studies of bicycle design that showcase MCD's effectiveness in real-world design problems. In the first case study, MCD excels at recommending modifications to query designs that can significantly enha
    
[^79]: NeuSTIP: 一种用于时间知识图谱中链接和时间预测的新型神经符号模型

    NeuSTIP: A Novel Neuro-Symbolic Model for Link and Time Prediction in Temporal Knowledge Graphs. (arXiv:2305.11301v1 [cs.AI])

    [http://arxiv.org/abs/2305.11301](http://arxiv.org/abs/2305.11301)

    NeuSTIP是一种新型神经符号模型，能够在时间知识图谱中进行链接和时间预测，且在两个TKGC数据集上优于现有方法。

    

    尽管在静态事实上的知识图完成已经是一个成熟的领域，但是在将有效时间纳入静态事实中的时间知识图谱完成（TKGC）仍处于初级阶段。知识图完成方法有多种类别，包括基于嵌入、基于规则、基于图神经网络和基于预训练语言模型等方法。然而，在TKGC中尚未探索这些方面。因此，我们提出了一种新颖的时间神经符号模型NeuSTIP，它可以在TKG中进行链接预测和时间间隔预测。NeuSTIP在Allan谓词的存在下学习时间规则，以确保给定规则中相邻谓词之间的时间一致性。我们进一步设计了一个独特的评分函数，通过利用学习规则来评估候选答案的置信度，从而执行链接预测和时间间隔预测。我们在两个基于时间间隔的TKGC数据集上进行实证评估，结果表明我们的模型在各种评估指标上优于现有的方法。

    While Knowledge Graph Completion (KGC) on static facts is a matured field, Temporal Knowledge Graph Completion (TKGC), that incorporates validity time into static facts is still in its nascent stage. The KGC methods fall into multiple categories including embedding-based, rule-based, GNN-based, pretrained Language Model based approaches. However, such dimensions have not been explored in TKG. To that end, we propose a novel temporal neuro-symbolic model, NeuSTIP, that performs link prediction and time interval prediction in a TKG. NeuSTIP learns temporal rules in the presence of the Allen predicates that ensure the temporal consistency between neighboring predicates in a given rule. We further design a unique scoring function that evaluates the confidence of the candidate answers while performing link prediction and time interval prediction by utilizing the learned rules. Our empirical evaluation on two time interval based TKGC datasets suggests that our model outperforms state-of-the-
    
[^80]: 用逻辑工具箱解决概率谜题

    Solving probability puzzles with logic toolkit. (arXiv:2305.11294v1 [cs.AI])

    [http://arxiv.org/abs/2305.11294](http://arxiv.org/abs/2305.11294)

    建立等式FOL，使用Mace4计算所有可能的模型和有利模型数量，最后根据定义计算概率。这种方法让逻辑学生使用他们熟悉的工具解决概率谜题。

    

    本文提出了一种用等式FOL形式化概率谜题并解决的方法。需要两种形式化方法：一种是针对给定的谜题模型的所有理论，另一种是针对有利模型的理论。然后两次调用Mace4，第一次计算所有可能的模型Mp，第二次加上额外的约束，Mace4只计算有利模型Mf。最后，应用概率定义：有利模型数除以可能模型数。提出的方法可以让逻辑领域的学生通过使用建模和形式化等喜爱的工具，找到解决概率谜题的正确方法。

    The proposed approach is to formalise the probabilistic puzzle in equational FOL. Two formalisations are needed: one theory for all models of the given puzzle, and a second theory for the favorable models. Then Mace4 - that computes all the interpretation models of a FOL theory - is called twice. First, it is asked to compute all the possible models M p .Second, the additional constraint is added, and Mace4 computes only favourabile models M f. Finally, the definition of probability is applied: the number of favorable models is divided by the number of possible models. The proposed approach equips students from the logic tribe to find the correct solution for puzzles from the probabilitistic tribe, by using their favourite instruments: modelling and formalisation. I have exemplified here five probabilistic puzzles and how they can be solved by translating the min FOL and then find the corresponding interpretation models. Mace4 was the tool of choice here. Ongoing work is investigating 
    
[^81]: 基于联邦学习的多语言帕金森病检测模型的安全开发

    Federated learning for secure development of AI models for Parkinson's disease detection using speech from different languages. (arXiv:2305.11284v1 [eess.AS])

    [http://arxiv.org/abs/2305.11284](http://arxiv.org/abs/2305.11284)

    本论文利用联邦学习方法，无需共享患者数据，实现在德语、西班牙语和捷克语三种语言数据集上进行帕金森病检测，取得了优于本地模型的诊断准确性。

    

    帕金森病是一种影响人类说话的神经系统疾病。深度学习模型在自动化帕金森病评估中表现出了出色的性能，但严格的患者数据隐私法规阻碍了机构间共享数据。本文在不共享患者数据的前提下，利用联邦学习在德语、西班牙语和捷克语等三种不同语言的真实数据集上进行了帕金森病检测，并取得了优于本地模型的诊断准确性。

    Parkinson's disease (PD) is a neurological disorder impacting a person's speech. Among automatic PD assessment methods, deep learning models have gained particular interest. Recently, the community has explored cross-pathology and cross-language models which can improve diagnostic accuracy even further. However, strict patient data privacy regulations largely prevent institutions from sharing patient speech data with each other. In this paper, we employ federated learning (FL) for PD detection using speech signals from 3 real-world language corpora of German, Spanish, and Czech, each from a separate institution. Our results indicate that the FL model outperforms all the local models in terms of diagnostic accuracy, while not performing very differently from the model based on centrally combined training sets, with the advantage of not requiring any data sharing among collaborators. This will simplify inter-institutional collaborations, resulting in enhancement of patient outcomes.
    
[^82]: 关于一般函数逼近下的均场强化学习的统计效率

    On the Statistical Efficiency of Mean Field Reinforcement Learning with General Function Approximation. (arXiv:2305.11283v1 [cs.LG])

    [http://arxiv.org/abs/2305.11283](http://arxiv.org/abs/2305.11283)

    本文研究了一般函数逼近下的均场控制(MFC)和均场博弈(MFG)中的强化学习的统计效率，提出了基于乐观最大似然估计的算法，并仅对转移动力学具有Lipschitz连续性的假设，最后建立了一个指数级的下界支持MFC设置。

    

    本文研究了一般函数逼近下的均场控制（MFC）和均场博弈（MFG）中强化学习的统计效率。引入了一种称为Mean-Field Model-Based Eluder Dimension (MBED)的新概念，包含了一系列丰富的均场强化学习问题。此外，我们提出了基于乐观最大似然估计的算法，可以返回一个$\epsilon$优的策略，适用于MFC或$\epsilon$纳什均衡策略适用于MFG，样本复杂度多项式与相关参数无关，与状态、动作和代理数量无关。值得注意的是，我们的结果仅对转移动力学具有Lipschitz连续性的假设，避免了以前的强结构假设。最后，在tabular设置下，假设有一个生成模型，我们建立了一个指数级的下界支持MFC设置，同时提供了一种新颖的样本高效的模型消除算法以逼近最优策略。

    In this paper, we study the statistical efficiency of Reinforcement Learning in Mean-Field Control (MFC) and Mean-Field Game (MFG) with general function approximation. We introduce a new concept called Mean-Field Model-Based Eluder Dimension (MBED), which subsumes a rich family of Mean-Field RL problems. Additionally, we propose algorithms based on Optimistic Maximal Likelihood Estimation, which can return an $\epsilon$-optimal policy for MFC or an $\epsilon$-Nash Equilibrium policy for MFG, with sample complexity polynomial w.r.t. relevant parameters and independent of the number of states, actions and the number of agents. Notably, our results only require a mild assumption of Lipschitz continuity on transition dynamics and avoid strong structural assumptions in previous work. Finally, in the tabular setting, given the access to a generative model, we establish an exponential lower bound for MFC setting, while providing a novel sample-efficient model elimination algorithm to approxim
    
[^83]: 用生物约束深度学习架构解释V1特性

    Explaining V1 Properties with a Biologically Constrained Deep Learning Architecture. (arXiv:2305.11275v1 [q-bio.NC])

    [http://arxiv.org/abs/2305.11275](http://arxiv.org/abs/2305.11275)

    该论文使用生物特性构建CNNs架构，成功解释V1神经活动特性。

    

    尽管缺乏生物学的特异性，卷积神经网络(CNNs)最近被认为是腹侧视觉通路的有前途的模型。虽然当前的最先进的V1模型是通过对抗性例子的训练和广泛增强的数据浮现出来的，但这些模型仍无法解释V1中观察到的关键神经特性，这些特性来自于生物电路。为了弥补这个差距，我们系统地将神经科学的架构组件纳入CNNs中，以识别一组全面解释V1神经活动的机制和架构。我们展示了通过集成模拟中心-周围拮抗、局部感受野、调谐归一化和皮层放大的架构组件来推动模型-V1对齐的巨大改进。通过使用这些专门的组件增强任务驱动的CNNs，我们发现了潜在表示产生了优秀的模型。

    Convolutional neural networks (CNNs) have recently emerged as promising models of the ventral visual stream, despite their lack of biological specificity. While current state-of-the-art models of the primary visual cortex (V1) have surfaced from training with adversarial examples and extensively augmented data, these models are still unable to explain key neural properties observed in V1 that arise from biological circuitry. To address this gap, we systematically incorporated neuroscience-derived architectural components into CNNs to identify a set of mechanisms and architectures that comprehensively explain neural activity in V1. We show drastic improvements in model-V1 alignment driven by the integration of architectural components that simulate center-surround antagonism, local receptive fields, tuned normalization, and cortical magnification. Upon enhancing task-driven CNNs with a collection of these specialized components, we uncover models with latent representations that yield s
    
[^84]: 面向情境对话中的心智建模，实现协同计划获取

    Towards Collaborative Plan Acquisition through Theory of Mind Modeling in Situated Dialogue. (arXiv:2305.11271v1 [cs.AI])

    [http://arxiv.org/abs/2305.11271](http://arxiv.org/abs/2305.11271)

    本文提出了一种协作计划获取方法，通过丰富的感知和对话历史，让代理人预测他们自己和合作伙伴缺失的任务知识，实现联合任务的完整计划获取。

    

    协作任务通常始于双方拥有不完全的任务知识和不完整的初始计划。为完成这些任务，代理人需要与合作伙伴进行实地交流，并协调他们的部分计划以实现联合任务目标。虽然这种协作在人与人的团队中似乎轻而易举，但对于人工智能的协作来说却具有很高的挑战性。为解决这个问题，本文提出了一种协作计划获取的方法，其中人类和代理人努力学习并相互交流，以获取联合任务的完整计划。具体地，本文提出了一种新颖的问题，让代理人基于丰富的感知和对话历史，预测他们自己和合作伙伴缺失的任务知识。我们在一个三维方块世界的对称协作任务中扩展了一个情境对话基准，并研究了计划获取的计算策略。我们的实证结果表明，预测任务知识是计划获取过程中的重点。

    Collaborative tasks often begin with partial task knowledge and incomplete initial plans from each partner. To complete these tasks, agents need to engage in situated communication with their partners and coordinate their partial plans towards a complete plan to achieve a joint task goal. While such collaboration seems effortless in a human-human team, it is highly challenging for human-AI collaboration. To address this limitation, this paper takes a step towards collaborative plan acquisition, where humans and agents strive to learn and communicate with each other to acquire a complete plan for joint tasks. Specifically, we formulate a novel problem for agents to predict the missing task knowledge for themselves and for their partners based on rich perceptual and dialogue history. We extend a situated dialogue benchmark for symmetric collaborative tasks in a 3D blocks world and investigate computational strategies for plan acquisition. Our empirical results suggest that predicting the
    
[^85]: 健壮的量子控制器：基于量子软计算的智能机器人量子信息--热力学潜在力控制

    Robust Quantum Controllers: Quantum Information -- Thermodynamic Hidden Force Control in Intelligent Robotics based on Quantum Soft Computing. (arXiv:2305.11254v1 [quant-ph])

    [http://arxiv.org/abs/2305.11254](http://arxiv.org/abs/2305.11254)

    本文介绍了一种基于量子/软计算技术设计智能健壮控制系统的通用策略，并着重于增加智能控制系统的健壮性。

    

    本文介绍了一种基于量子/软计算技术设计智能健壮控制系统的通用策略。提供自组织不完善知识库的能力可以提高混合智能控制器的可靠性。主要关注在不可预测的控制情况下增加智能控制系统的健壮性，并举例进行演示。还描述了一个用于在经典计算机上建模量子算法的SW＆HW平台和支持工具。

    A generalized strategy for the design of intelligent robust control systems based on quantum / soft computing technologies is described. The reliability of hybrid intelligent controllers increase by providing the ability to self-organize of imperfect knowledge bases. The main attention is paid to increasing the level of robustness of intelligent control systems in unpredictable control situations with the demonstration by illustrative examples. A SW & HW platform and support tools for a supercomputer accelerator for modeling quantum algorithms on a classical computer are described.
    
[^86]: 人工神经网络中的脑启发式学习: 一篇综述

    Brain-inspired learning in artificial neural networks: a review. (arXiv:2305.11252v1 [cs.NE])

    [http://arxiv.org/abs/2305.11252](http://arxiv.org/abs/2305.11252)

    本文综述了当前人工神经网络中的脑启发式学习表示，找出了未来研究的有前途的方向，这可能使我们更加接近理解智能的本质。

    

    人工神经网络已成为机器学习中的必要工具，在图像和语音生成、游戏和机器人等多个领域取得了巨大的成功。然而，人工神经网络的运作机制与生物大脑存在根本差异，尤其是学习过程方面。本文综述了当前人工神经网络中的脑启发式学习表示，并探讨了整合更符合生物学原理的机制（如突触可塑性）以提高这些网络能力的潜在优势和挑战，找出未来研究的有前途的方向，这可能使我们更加接近理解智能的本质。

    Artificial neural networks (ANNs) have emerged as an essential tool in machine learning, achieving remarkable success across diverse domains, including image and speech generation, game playing, and robotics. However, there exist fundamental differences between ANNs' operating mechanisms and those of the biological brain, particularly concerning learning processes. This paper presents a comprehensive review of current brain-inspired learning representations in artificial neural networks. We investigate the integration of more biologically plausible mechanisms, such as synaptic plasticity, to enhance these networks' capabilities. Moreover, we delve into the potential advantages and challenges accompanying this approach. Ultimately, we pinpoint promising avenues for future research in this rapidly advancing field, which could bring us closer to understanding the essence of intelligence.
    
[^87]: 一种参数高效的学习方法，用于带有预训练通用语音模型的阿拉伯方言识别

    A Parameter-Efficient Learning Approach to Arabic Dialect Identification with Pre-Trained General-Purpose Speech Model. (arXiv:2305.11244v1 [cs.CL])

    [http://arxiv.org/abs/2305.11244](http://arxiv.org/abs/2305.11244)

    本文介绍了一种利用预训练通用语音模型进行阿拉伯方言识别的参数高效学习方法，通过残差适配器和模型重编程，设计了一个基于记号的标签映射，并在ADI-17数据集上实现了最高精度，同时使用PEL方法进一步减少了训练成本。

    

    本文研究了参数高效学习（PEL）技术，以重新利用通用语音模型（GSM）进行阿拉伯方言识别（ADI）。我们设计了一个基于记号的标签映射，将GSM适应于阿拉伯方言识别，通过残差适配器和模型重编程来实现。我们通过vanilla fine-tuning在ADI-17数据集上实现了新的最高精度。此外，我们通过PEL方法进一步减少了训练成本，使用额外2.5％的网络可训练参数即可达到fine-tuning精度的1.86％。我们的研究展示了如何使用小型数据集和有限的计算资源来识别阿拉伯方言。

    In this work, we explore Parameter-Efficient-Learning (PEL) techniques to repurpose a General-Purpose-Speech (GSM) model for Arabic dialect identification (ADI). Specifically, we investigate different setups to incorporate trainable features into a multi-layer encoder-decoder GSM formulation under frozen pre-trained settings. Our architecture includes residual adapter and model reprogramming (input-prompting). We design a token-level label mapping to condition the GSM for Arabic Dialect Identification (ADI). This is challenging due to the high variation in vocabulary and pronunciation among the numerous regional dialects. We achieve new state-of-the-art accuracy on the ADI-17 dataset by vanilla fine-tuning. We further reduce the training budgets with the PEL method, which performs within 1.86% accuracy to fine-tuning using only 2.5% of (extra) network trainable parameters. Our study demonstrates how to identify Arabic dialects using a small dataset and limited computation with open sou
    
[^88]: 比较机器和儿童：使用发展心理学实验评估LaMDA响应的优势和劣势

    Comparing Machines and Children: Using Developmental Psychology Experiments to Assess the Strengths and Weaknesses of LaMDA Responses. (arXiv:2305.11243v1 [cs.CL])

    [http://arxiv.org/abs/2305.11243](http://arxiv.org/abs/2305.11243)

    使用儿童发展实验来评估人工智能的计算能力，同时比较LLMs和儿童可以帮助我们开发更具人类特征和可解释性的机器学习模型。

    

    发展心理学家花费了几十年的时间设计实验来测试婴儿和儿童的智力和知识，追溯重要概念和能力的起源。我们认为，使用儿童发展的经典实验是探究人工智能模型的计算能力，尤其是LLM模型的最有效的方式之一。其次，将LLM与儿童进行比较可以帮助我们开发更具有人类特点和可解释性的机器学习模型，使它们能够嵌入到需要与人交互的实际环境中。

    Developmental psychologists have spent decades devising experiments to test the intelligence and knowledge of infants and children, tracing the origin of crucial concepts and capacities. Moreover, experimental techniques in developmental psychology have been carefully designed to discriminate the cognitive capacities that underlie particular behaviors. We propose that using classical experiments from child development is a particularly effective way to probe the computational abilities of AI models, in general, and LLMs in particular. First, the methodological techniques of developmental psychology, such as the use of novel stimuli to control for past experience or control conditions to determine whether children are using simple associations, can be equally helpful for assessing the capacities of LLMs. In parallel, testing LLMs in this way can tell us whether the information that is encoded in text is sufficient to enable particular responses, or whether those responses depend on othe
    
[^89]: 自动驾驶和智能车辆的里程碑 Part I：控制、计算机系统设计、通信、高精度地图、测试和人类行为

    Milestones in Autonomous Driving and Intelligent Vehicles Part \uppercase\expandafter{\romannumeral1}: Control, Computing System Design, Communication, HD Map, Testing, and Human Behaviors. (arXiv:2305.11239v1 [cs.AI])

    [http://arxiv.org/abs/2305.11239](http://arxiv.org/abs/2305.11239)

    本次论文总结了自动驾驶和智能车辆中关于控制、计算机系统设计、通信、高精度地图、测试和人类行为的发展情况和未来研究方向。

    

    自动驾驶(AD)和智能车辆(IV)的兴趣正在迅速增长，因为它们带来的便捷、安全和经济效益。虽然一些调查已经回顾了这个领域的研究成果，但它们仍然限于特定的任务，并缺乏在未来的系统总结和研究方向。我们的工作分为3个独立的文章，第一部分是对AD和IV的总体技术进行调查，包括历史、总结里程碑以及提供前瞻性、伦理和未来研究方向。这是第二部分(Part I)的技术调查，用于审查IV中控制、计算机系统设计、通信、高清地图、测试和人类行为的发展情况。此外，第三部分(Part II)将审查感知和规划部分。本次调查的目的是提供关于AD和IV领域技术进展和挑战的全面和最新的概述。

    Interest in autonomous driving (AD) and intelligent vehicles (IVs) is growing at a rapid pace due to the convenience, safety, and economic benefits. Although a number of surveys have reviewed research achievements in this field, they are still limited in specific tasks and lack systematic summaries and research directions in the future. Our work is divided into 3 independent articles and the first part is a Survey of Surveys (SoS) for total technologies of AD and IVs that involves the history, summarizes the milestones, and provides the perspectives, ethics, and future research directions. This is the second part (Part \uppercase\expandafter{\romannumeral1} for this technical survey) to review the development of control, computing system design, communication, High Definition map (HD map), testing, and human behaviors in IVs. In addition, the third part (Part \uppercase\expandafter{\romannumeral2} for this technical survey) is to review the perception and planning sections. The objecti
    
[^90]: 安全聚合的高效竖向联邦学习

    Efficient Vertical Federated Learning with Secure Aggregation. (arXiv:2305.11236v1 [cs.LG])

    [http://arxiv.org/abs/2305.11236](http://arxiv.org/abs/2305.11236)

    本文提出了一种安全有效的竖向联邦学习方法，通过使用安全模块进行聚合，解决了竖直数据集下的隐私泄露问题，并在不降低性能的情况下获得了大量加速。

    

    隐私保护联邦学习（FL）的大部分工作都集中在水平分区数据集上，其中客户共享相同的特征集并可以独立地训练完整的模型。然而，在许多有趣的问题中，例如金融欺诈和疾病检测，个别数据点散落在竖直联邦学习的不同客户/组织中。针对这种FL的解决方案需要参与者之间的梯度交换，很少考虑隐私和安全问题，可能存在隐私泄露的风险。在这项工作中，我们提出了一个新颖的设计，使用最先进的安全模块进行安全聚合，以安全有效地进行竖向FL训练。我们通过实验证明，与同态加密(HE)相比，我们的方法在不影响训练性能的情况下，获得了9.1e2~3.8e4的加速比。

    The majority of work in privacy-preserving federated learning (FL) has been focusing on horizontally partitioned datasets where clients share the same sets of features and can train complete models independently. However, in many interesting problems, such as financial fraud detection and disease detection, individual data points are scattered across different clients/organizations in vertical federated learning. Solutions for this type of FL require the exchange of gradients between participants and rarely consider privacy and security concerns, posing a potential risk of privacy leakage. In this work, we present a novel design for training vertical FL securely and efficiently using state-of-the-art security modules for secure aggregation. We demonstrate empirically that our method does not impact training performance whilst obtaining 9.1e2 ~3.8e4 speedup compared to homomorphic encryption (HE).
    
[^91]: LIMA: 对齐的更少即为更优（Less Is More for Alignment）

    LIMA: Less Is More for Alignment. (arXiv:2305.11206v1 [cs.CL])

    [http://arxiv.org/abs/2305.11206](http://arxiv.org/abs/2305.11206)

    该论文介绍了一种使用无声调学习预训练语言模型和标准监督损失微调的方法（不使用强化学习或人类模型），并展示了在复杂任务上也有出色的表现。

    

    大型语言模型的训练通常分为两个阶段：(1)无监督的原始文本预训练，以学习通用表示；(2)大规模的指令微调和强化学习，以更好地对齐最终任务和用户偏好。我们通过训练LIMA，一个使用标准监督损失值进行的65B参数LLaMa语言模型，仅使用1000个经过筛选的提示和回复进行微调，而不使用任何强化学习或人类偏好建模，衡量了这两个阶段之间的相对重要性。 LIMA表现出了极强的性能，仅从训练数据中的少量示例中学习到如何遵循特定的响应格式，包括从规划旅行行程到推测替代历史的复杂查询。此外，该模型倾向于良好地推广到未在训练数据中出现的任务中。在一项控制的人类研究中，与GPT-4相比，LIMA的响应在43%的情况下等效或严格优先。

    Large language models are trained in two stages: (1) unsupervised pretraining from raw text, to learn general-purpose representations, and (2) large scale instruction tuning and reinforcement learning, to better align to end tasks and user preferences. We measure the relative importance of these two stages by training LIMA, a 65B parameter LLaMa language model fine-tuned with the standard supervised loss on only 1,000 carefully curated prompts and responses, without any reinforcement learning or human preference modeling. LIMA demonstrates remarkably strong performance, learning to follow specific response formats from only a handful of examples in the training data, including complex queries that range from planning trip itineraries to speculating about alternate history. Moreover, the model tends to generalize well to unseen tasks that did not appear in the training data. In a controlled human study, responses from LIMA are either equivalent or strictly preferred to GPT-4 in 43% of c
    
[^92]: PDP：无需参数的可微剪枝即可搞定

    PDP: Parameter-free Differentiable Pruning is All You Need. (arXiv:2305.11203v1 [cs.LG])

    [http://arxiv.org/abs/2305.11203](http://arxiv.org/abs/2305.11203)

    PDP提出了一种无需参数的可微剪枝方案，具有最先进的模型大小、准确性和训练成本，适用于各种视觉和自然语言任务。

    

    DNN剪枝是一种常用的方法，可以减少模型的大小，提高推理延迟，并最小化DNN加速器上的功耗。然而，现有的方法可能过于复杂、昂贵或无法适用于各种视觉/语言任务、DNN体系结构并遵守结构化剪枝约束。在本文中，我们提出了一种高效而有效的训练时间剪枝方案——PDP（参数自由可微剪枝），它在模型大小、准确性和训练成本方面具有最先进的性能。PDP在训练过程中使用权重的动态函数，以参数无关的方式为给定的剪枝目标生成软剪枝掩码。虽然是可微的，但是PDP的简单和高效使其足够普遍，以在各种视觉和自然语言任务上提供最先进的随机/结构化/通道剪枝结果。例如，对于MobileNet-v1，PDP可以在86.6%的稀疏度下达到68.2%的ImageNet1k top-1准确率。

    DNN pruning is a popular way to reduce the size of a model, improve the inference latency, and minimize the power consumption on DNN accelerators. However, existing approaches might be too complex, expensive or ineffective to apply to a variety of vision/language tasks, DNN architectures and to honor structured pruning constraints. In this paper, we propose an efficient yet effective train-time pruning scheme, Parameter-free Differentiable Pruning (PDP), which offers state-of-the-art qualities in model size, accuracy, and training cost. PDP uses a dynamic function of weights during training to generate soft pruning masks for the weights in a parameter-free manner for a given pruning target. While differentiable, the simplicity and efficiency of PDP make it universal enough to deliver state-of-the-art random/structured/channel pruning results on various vision and natural language tasks. For example, for MobileNet-v1, PDP can achieve 68.2% top-1 ImageNet1k accuracy at 86.6% sparsity, wh
    
[^93]: 在不知道遮盖分布移位的情况下预测不完整数据

    Prediction with Incomplete Data under Agnostic Mask Distribution Shift. (arXiv:2305.11197v1 [cs.LG])

    [http://arxiv.org/abs/2305.11197](http://arxiv.org/abs/2305.11197)

    本研究考虑预测不完整数据的情况，在缺失模式分布可能发生偏移的情况下，我们利用掩码的不变最优预测器实现泛化，通过双参数化技术联合近似最优预测器避免指数爆炸，同时引入正则化项保证预测器具有鲁棒性。

    

    在许多应用程序中，存在缺失值的数据是普遍存在的。最近几年，人们对仅使用观察到的特征和指示缺失模式的掩码的不完整数据进行预测的关注不断增加。现有方法假设训练和测试分布相同，在实际环境中可能会被违反。本文考虑在存在分布偏移的情况下预测不完整数据。我们专注于基础完整特征和标签的联合分布不变，但缺失模式即掩码分布可能会在训练和测试之间不知道地发生变化。为了实现泛化，我们利用这个观察结果，即对于每个掩码，都有一个不变的最优预测器。为了避免在单独学习它们时出现指数爆炸，在使用双参数化技术联合近似最优预测器。这具有不良的副作用，即允许学习到的预测器对参数化的选择敏感。为了解决这个问题，我们引入了一个正则化项，促进对参数化的选择具有鲁棒性的预测器。对合成和真实数据集的实验表明了我们提出的方法的有效性。

    Data with missing values is ubiquitous in many applications. Recent years have witnessed increasing attention on prediction with only incomplete data consisting of observed features and a mask that indicates the missing pattern. Existing methods assume that the training and testing distributions are the same, which may be violated in real-world scenarios. In this paper, we consider prediction with incomplete data in the presence of distribution shift. We focus on the case where the underlying joint distribution of complete features and label is invariant, but the missing pattern, i.e., mask distribution may shift agnostically between training and testing. To achieve generalization, we leverage the observation that for each mask, there is an invariant optimal predictor. To avoid the exponential explosion when learning them separately, we approximate the optimal predictors jointly using a double parameterization technique. This has the undesirable side effect of allowing the learned pred
    
[^94]: 云医疗聊天机器人的 AISecOps 威胁建模分类

    Taxonomy of AISecOps Threat Modeling for Cloud Based Medical Chatbots. (arXiv:2305.11189v1 [cs.DC])

    [http://arxiv.org/abs/2305.11189](http://arxiv.org/abs/2305.11189)

    这篇论文介绍了使用 AISecOps 对云医疗聊天机器人进行监控的方法，解释了 AISecOps 是如何将 IT 运营、人工智能和安全三个领域整合起来协同运作以确保聊天机器人的机密性、完整性和可用性的。

    

    人工智能在技术的各个方面都扮演着至关重要的角色，包括网络安全。医疗领域中越来越流行的聊天机器人等交互式人工智能应用程序，为需要及时获得医疗援助的患者提供方便。由于医疗聊天机器人涉及大量的敏感信息，因此这些机器人的安全性至关重要。为了确保云主机资产的机密性，完整性和可用性，可以使用 AISecOps（为安全 IT 运营而设计的人工智能）对医疗聊天机器人进行监控。 AISecOps 是一个新兴的领域，将 IT 运营，人工智能和安全三个不同但密切相关的领域整合为一个域，在此域中，来自这三个领域的专业知识被协同使用以保护网络安全资产。它考虑到云操作和安全性因素，采用综合框架收集评估安全威胁所需的度量标准，并训练 AI 模型以立即采取行动。

    Artificial Intelligence (AI) is playing a vital role in all aspects of technology including cyber security. Application of Conversational AI like the chatbots are also becoming very popular in the medical field to provide timely and immediate medical assistance to patients in need. As medical chatbots deal with a lot of sensitive information, the security of these chatbots is crucial. To secure the confidentiality, integrity, and availability of cloud-hosted assets like these, medical chatbots can be monitored using AISecOps (Artificial Intelligence for Secure IT Operations). AISecOPs is an emerging field that integrates three different but interrelated domains like the IT operation, AI, and security as one domain, where the expertise from all these three domains are used cohesively to secure the cyber assets. It considers cloud operations and security in a holistic framework to collect the metrics required to assess the security threats and train the AI models to take immediate action
    
[^95]: 解决线性反问题的复合高斯网络

    A Compound Gaussian Network for Solving Linear Inverse Problems. (arXiv:2305.11120v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2305.11120](http://arxiv.org/abs/2305.11120)

    本文提出了一种基于复合高斯先验分布的迭代算法和对应于其迭代过程“展开”的深度神经网络来解决线性反问题，两种方法都优于其他最先进的解决方法。

    

    本文针对图像重建和压缩感知中出现的线性反问题，提出了两种新的解决方法。第一种方法是迭代算法，通过最小化基于复合高斯先验分布的正则化最小二乘目标函数来实现。复合高斯先验包含了许多常用的图像重建先验，例如稀疏性方法等。这个迭代算法为本文的第二种新方法提供了基础，即一个对应于迭代过程“展开”的深度神经网络。展开的深度神经网络具有可解释的层次结构，并且优于标准深度学习方法。本文还包括详细的计算理论，深入探究了两种算法的构造和性能。最终结论是，这两种算法都优于其他最先进的解决线性反问题的方法。

    For solving linear inverse problems, particularly of the type that appear in tomographic imaging and compressive sensing, this paper develops two new approaches. The first approach is an iterative algorithm that minimizers a regularized least squares objective function where the regularization is based on a compound Gaussian prior distribution. The Compound Gaussian prior subsumes many of the commonly used priors in image reconstruction, including those of sparsity-based approaches. The developed iterative algorithm gives rise to the paper's second new approach, which is a deep neural network that corresponds to an "unrolling" or "unfolding" of the iterative algorithm. Unrolled deep neural networks have interpretable layers and outperform standard deep learning methods. This paper includes a detailed computational theory that provides insight into the construction and performance of both algorithms. The conclusion is that both algorithms outperform other state-of-the-art approaches to 
    
[^96]: 基于MDCT谱的改进型transformer GAN用于语音超分辨率重建: mdctGAN

    mdctGAN: Taming transformer-based GAN for speech super-resolution with Modified DCT spectra. (arXiv:2305.11104v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2305.11104](http://arxiv.org/abs/2305.11104)

    本文提出新型SSR框架mdctGAN，基于MDCT谱，以相位感知的方式重建HR语音，无需声码器或额外的后处理，并保证了高质量的语音重建。

    

    语音超分辨率(SSR)旨在从其对应的低分辨率(LR)语音中恢复高分辨率(HR)语音。最近的SSR方法更加关注幅度谱的重建，忽略了相位重建的重要性，从而限制了恢复质量。为了解决这个问题，本文提出了一种基于改进离散余弦变换(MDCT)的新型SSR框架mdctGAN。通过在MDCT域中进行对抗学习，我们的方法以相位感知的方式重建HR语音，无需声码器或额外的后处理。此外，通过学习具有自我关注机制的频率一致特征，mdctGAN保证了高质量的语音重建。在VCTK语料库数据集上，实验结果显示我们的模型具有自然的听觉质量，MOS和PESQ得分高。 它还在48kHz目标分辨率上从各种输入速率中实现了最先进的log-spectral-distance(LSD)性能。代码可供使用。

    Speech super-resolution (SSR) aims to recover a high resolution (HR) speech from its corresponding low resolution (LR) counterpart. Recent SSR methods focus more on the reconstruction of the magnitude spectrogram, ignoring the importance of phase reconstruction, thereby limiting the recovery quality. To address this issue, we propose mdctGAN, a novel SSR framework based on modified discrete cosine transform (MDCT). By adversarial learning in the MDCT domain, our method reconstructs HR speeches in a phase-aware manner without vocoders or additional post-processing. Furthermore, by learning frequency consistent features with self-attentive mechanism, mdctGAN guarantees a high quality speech reconstruction. For VCTK corpus dataset, the experiment results show that our model produces natural auditory quality with high MOS and PESQ scores. It also achieves the state-of-the-art log-spectral-distance (LSD) performance on 48 kHz target resolution from various input rates. Code is available fro
    
[^97]: 利用ChatGPT和Stable Diffusion生成内容丰富、故事连贯的漫画

    Generating coherent comic with rich story using ChatGPT and Stable Diffusion. (arXiv:2305.11067v1 [cs.CV])

    [http://arxiv.org/abs/2305.11067](http://arxiv.org/abs/2305.11067)

    本文介绍了一种利用ChatGPT和Stable Diffusion生成连贯漫画故事的方法，通过引入新的评估AI故事的方式，并使用LoRA、ControlNet等方法进行fine-tuning，取得了在角色忠实度和艺术风格上的最先进表现。

    

    过去的研究表明，使用神经网络可以在保持音乐家音乐风格的基础上，扩展未完成的音乐作品。最近大型语言模型和扩散模型的进展使得我们能够生成有趣的漫画故事，并保持艺术家的艺术风格。在本文中，我们使用ChatGPT生成情节和对话，然后使用stable diffusion生成漫画。我们介绍了一种评估AI生成故事的新方法，并通过使用LoRA、ControlNet等方法对stable diffusion进行fine-tuning，达到了在角色忠实度和艺术风格上的SOTA表现。

    Past work demonstrated that using neural networks, we can extend unfinished music pieces while maintaining the music style of the musician. With recent advancements in large language models and diffusion models, we are now capable of generating comics with an interesting storyline while maintaining the art style of the artist. In this paper, we used ChatGPT to generate storylines and dialogue and then generated the comic using stable diffusion. We introduced a novel way to evaluate AI-generated stories, and we achieved SOTA performance on character fidelity and art style by fine-tuning stable diffusion using LoRA, ControlNet, etc.
    
[^98]: 无标注音视频分割

    Annotation-free Audio-Visual Segmentation. (arXiv:2305.11019v1 [cs.CV])

    [http://arxiv.org/abs/2305.11019](http://arxiv.org/abs/2305.11019)

    本文提出了一种可伸缩且无需注释的管道，用于生成音视频分割任务的人工数据，并引入了一个音频感知的基于查询的Transformer解码器，使模型能够在音频信号的指导下搜索声音对象，得到更准确的分割。

    

    音视频分割的目标是通过准确地预测像素级分割掩码在视觉场景中定位声音对象。本文提出了以下贡献：（i）我们提出了一种可伸缩且无需注释的管道，用于生成音视频分割任务的人工数据。我们利用现有的图像分割和音频数据集，建立类别标签、图像掩模对和音频样本之间的联系，从而可以轻松组合训练AVS模型的（图像、音频、掩模）三元组；（ii）我们引入了一种新的音频感知变压器（AuTR）架构，其中包含一个音频感知的基于查询的Transformer解码器。该架构使模型能够在音频信号的指导下搜索声音对象，从而得到更准确的分割；（iii）我们在合成和真实数据集上进行了广泛的实验，证明了使用我们的管道生成的合成数据训练AVS模型的有效性。

    The objective of Audio-Visual Segmentation (AVS) is to locate sounding objects within visual scenes by accurately predicting pixelwise segmentation masks. In this paper, we present the following contributions: (i), we propose a scalable and annotation-free pipeline for generating artificial data for the AVS task. We leverage existing image segmentation and audio datasets to draw links between category labels, image-mask pairs, and audio samples, which allows us to easily compose (image, audio, mask) triplets for training AVS models; (ii), we introduce a novel Audio-Aware Transformer (AuTR) architecture that features an audio-aware query-based transformer decoder. This architecture enables the model to search for sounding objects with the guidance of audio signals, resulting in more accurate segmentation; (iii), we present extensive experiments conducted on both synthetic and real datasets, which demonstrate the effectiveness of training AVS models with synthetic data generated by our p
    
[^99]: 大型语言模型可以被引导来规避AI生成的文本检测

    Large Language Models can be Guided to Evade AI-Generated Text Detection. (arXiv:2305.10847v1 [cs.CL])

    [http://arxiv.org/abs/2305.10847](http://arxiv.org/abs/2305.10847)

    本文揭示了大型语言模型可以通过精心设计的提示语来有效规避现有的文本检测系统，证明了这些检测器的脆弱性。

    

    大型语言模型在包括论文写作和问答等多个任务中展现出了出色的表现。然而，必须解决这些模型潜在的误用问题，否则可能导致抄袭和垃圾信息等不良后果。本研究揭示，通过精心设计的提示语，LLMs可以有效地规避检测系统。我们提出了一种新颖的基于替换的上下文示例优化方法（SICO），用于自动生成这种提示语。在三个现实任务中，LLMs可能被误用，在SICO的帮助下，ChatGPT成功地规避了六项现有的检测器，平均导致0.54的AUC下降。令人惊讶的是，在大多数情况下，这些检测器的表现甚至比随机分类器还要差。这些结果坚定地揭示了现有检测器的脆弱性。

    Large Language Models (LLMs) have demonstrated exceptional performance in a variety of tasks, including essay writing and question answering. However, it is crucial to address the potential misuse of these models, which can lead to detrimental outcomes such as plagiarism and spamming. Recently, several detectors have been proposed, including fine-tuned classifiers and various statistical methods. In this study, we reveal that with the aid of carefully crafted prompts, LLMs can effectively evade these detection systems. We propose a novel Substitution-based In-Context example Optimization method (SICO) to automatically generate such prompts. On three real-world tasks where LLMs can be misused, SICO successfully enables ChatGPT to evade six existing detectors, causing a significant 0.54 AUC drop on average. Surprisingly, in most cases these detectors perform even worse than random classifiers. These results firmly reveal the vulnerability of existing detectors. Finally, the strong perfor
    
[^100]: UniEX：一种基于跨度提取的统一信息抽取的有效高效框架

    UniEX: An Effective and Efficient Framework for Unified Information Extraction via a Span-extractive Perspective. (arXiv:2305.10306v1 [cs.CL])

    [http://arxiv.org/abs/2305.10306](http://arxiv.org/abs/2305.10306)

    UniEX是一种能适用于各种模式格式的信息抽取框架，并能同时解决命名实体识别、关系抽取、事件提取和情感分析等任务，在性能和推理速度上优于其他通用信息抽取模型。

    

    我们提出了一种新的通用信息抽取范式，它与任何模式格式兼容，并适用于一系列信息抽取任务，如命名实体识别、关系抽取、事件提取和情感分析。我们的方法将以文本为基础的信息抽取任务转化为 token-pair 问题，使用一种统一的提取框架 UniEX，将所有提取目标都统一分解为联合跨度检测、分类和关联问题。UniEX 可以同时编码基于模式的提示和文本信息，并使用自动编码器语言模型协同学习预定义信息的广义知识。我们开发了 traffine 注意机制，将包括任务、标签和内部 token 在内的异构因素集成起来，并通过评分矩阵获得提取目标。实验结果表明，UniEX 在 $14$个基准测试数据集上的表现和推理速度都优于基于生成的通用信息抽取模型。

    We propose a new paradigm for universal information extraction (IE) that is compatible with any schema format and applicable to a list of IE tasks, such as named entity recognition, relation extraction, event extraction and sentiment analysis. Our approach converts the text-based IE tasks as the token-pair problem, which uniformly disassembles all extraction targets into joint span detection, classification and association problems with a unified extractive framework, namely UniEX. UniEX can synchronously encode schema-based prompt and textual information, and collaboratively learn the generalized knowledge from pre-defined information using the auto-encoder language models. We develop a traffine attention mechanism to integrate heterogeneous factors including tasks, labels and inside tokens, and obtain the extraction target via a scoring matrix. Experiment results show that UniEX can outperform generative universal IE models in terms of performance and inference-speed on $14$ benchmar
    
[^101]: SuSana Distance是你所需要的：通过两种新的基于距离的损失函数实现度量学习中的类别可分性，用于少样本图像分类

    SuSana Distancia is all you need: Enforcing class separability in metric learning via two novel distance-based loss functions for few-shot image classification. (arXiv:2305.09062v1 [cs.CV])

    [http://arxiv.org/abs/2305.09062](http://arxiv.org/abs/2305.09062)

    本文提出了两种新的基于距离的损失函数，通过考虑少量数据之间的类内距离和类间距离来考虑嵌入向量的重要性，以增强度量学习中的类别可分性，实现优秀的少样本图像分类表现。

    

    少样本学习是一项具有挑战性的研究领域，旨在仅利用少量标记数据样本学习新的概念。基于度量学习方法的最近工作利用元学习方法，其中包括支持（训练）和查询集（测试），旨在学习这些集合之间的相似性比较度量。由于数据缺乏，嵌入网络的学习过程成为少样本任务的重要部分。先前的工作使用度量学习方法解决了这个问题，但底层潜在空间的属性和类别之间的可分性并未完全强制执行。在这项工作中，我们提出了两种不同的损失函数，通过考虑少量数据之间的类内距离和类间距离来考虑嵌入向量的重要性。第一个损失函数是Proto-Triplet Loss，它基于原始三元组损失，并添加了原型向量。第二个损失函数是SuSana Distance Loss，它考虑了同类样本和不同类样本之间的距离。我们在两个少样本图像分类的基准数据集上评估了我们提出的方法，实验结果证明了我们的方法在实现类别可分性和达到最先进性能方面的有效性。

    Few-shot learning is a challenging area of research that aims to learn new concepts with only a few labeled samples of data. Recent works based on metric-learning approaches leverage the meta-learning approach, which is encompassed by episodic tasks that make use a support (training) and query set (test) with the objective of learning a similarity comparison metric between those sets. Due to the lack of data, the learning process of the embedding network becomes an important part of the few-shot task. Previous works have addressed this problem using metric learning approaches, but the properties of the underlying latent space and the separability of the difference classes on it was not entirely enforced. In this work, we propose two different loss functions which consider the importance of the embedding vectors by looking at the intra-class and inter-class distance between the few data. The first loss function is the Proto-Triplet Loss, which is based on the original triplet loss with 
    
[^102]: 无需增加模型参数的序列到序列模型微调方法：基于结构化剪枝的LoRA方法

    Parameter-Efficient Fine-Tuning with Layer Pruning on Free-Text Sequence-to-Sequence modeling. (arXiv:2305.08285v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.08285](http://arxiv.org/abs/2305.08285)

    本文提出了一个将LoRA和结构化层剪枝方法结合的框架，在保持超过92%生成质量的同时，通过调整仅0.6%的参数并剪枝超过30%的Transformer层，成功减少了50%的GPU内存使用并提升了100%的训练速度。

    

    语言模型尺寸的不断增长引起了对于参数效率的微调方法的研究兴趣，本文提出了一个将LoRA和结构化层剪枝方法结合的框架。这个框架在 MIMIC-IV-Note上的两个医疗报告概述数据集和两个公共医疗对话数据集上进行了验证。通过调整原始模型的0.6%的参数并剪枝超过30%的Transformer层，我们的框架可以减少50%的GPU内存使用并提升100%的训练速度，同时保持在自由文本序列到序列任务上超过92%的生成质量。

    The increasing size of language models raises great research interests in parameter-efficient fine-tuning such as LoRA that freezes the pre-trained model, and injects small-scale trainable parameters for multiple downstream tasks (e.g., summarization, question answering and translation). To further enhance the efficiency of fine-tuning, we propose a framework that integrates LoRA and structured layer pruning. The integrated framework is validated on two created deidentified medical report summarization datasets based on MIMIC-IV-Note and two public medical dialogue datasets. By tuning 0.6% parameters of the original model and pruning over 30% Transformer-layers, our framework can reduce 50% of GPU memory usage and speed up 100% of the training phase, while preserving over 92% generation qualities on free-text sequence-to-sequence tasks.
    
[^103]: “视觉和更多领域的任意分割模型综合调查”

    A Comprehensive Survey on Segment Anything Model for Vision and Beyond. (arXiv:2305.08196v1 [cs.CV])

    [http://arxiv.org/abs/2305.08196](http://arxiv.org/abs/2305.08196)

    本文综述了最近提出的“任意分割模型”（SAM）的进展，该模型打破了分割界限，提高了计算机视觉基础模型的发展。

    

    人工智能正向人工通用智能演进，即AI系统具备像人一样的广泛任务和智能水平。这与窄化或专用AI相对应，后者旨在以高效的方式执行特定任务。因此，需要设计广泛数据训练的、适用于各种下游任务的基础模型。最近提出的“任意分割模型“（SAM）在打破分割界限方面取得了重大进展，极大地促进了计算机视觉基础模型的发展。为了充分了解SAM，我们进行了一项综合调查研究。作为第一篇基于SAM基础模型全面回顾视觉及其他领域任意分割任务进展的文章，本文着重讨论了它在各种任务和数据类型中的应用。

    Artificial intelligence (AI) is evolving towards artificial general intelligence, which refers to the ability of an AI system to perform a wide range of tasks and exhibit a level of intelligence similar to that of a human being. This is in contrast to narrow or specialized AI, which is designed to perform specific tasks with a high degree of efficiency. Therefore, it is urgent to design a general class of models, which we term foundation models, trained on broad data that can be adapted to various downstream tasks. The recently proposed segment anything model (SAM) has made significant progress in breaking the boundaries of segmentation, greatly promoting the development of foundation models for computer vision. To fully comprehend SAM, we conduct a survey study. As the first to comprehensively review the progress of segmenting anything task for vision and beyond based on the foundation model of SAM, this work focuses on its applications to various tasks and data types by discussing it
    
[^104]: 基于随机池化的可证明多实例深度AUC最大化方法

    Provable Multi-instance Deep AUC Maximization with Stochastic Pooling. (arXiv:2305.08040v1 [cs.LG])

    [http://arxiv.org/abs/2305.08040](http://arxiv.org/abs/2305.08040)

    本文提出了在多实例学习中使用深度AUC最大化（DAM）的方法，并根据包含大量实例的情况下训练的计算挑战，提出了一种基于方差减少的随机池化方法，使得只需对每个包进行少量采样即可计算MIDAM模型，提高了效率和准确性。

    

    本文提出了一种深度AUC最大化（DAM）的新型应用，用于多实例学习（MIL），其中将单个类标签分配给一组实例（例如，患者的多个CT扫描的多个2D切片）。我们在DAM的背景下解决了MIL中被忽略但非常重要的计算挑战，即包大小过大，无法在反向传播时加载到GPU内存中，这是MIL标准池化方法所必需的。为了解决这个问题，我们提出了一种基于方差减少的随机池化方法，这种方法可以将关于汇聚预测的损失函数构造为多级组合函数。通过综合随机组合优化和非凸极小最大优化技术，我们提出了一种统一且可证明的多实例DAM（MIDAM）算法，其使用随机平滑最大池化或随机注意力池化，仅对每个包对应的实例进行少量采样来计算 sto。

    This paper considers a novel application of deep AUC maximization (DAM) for multi-instance learning (MIL), in which a single class label is assigned to a bag of instances (e.g., multiple 2D slices of a CT scan for a patient). We address a neglected yet non-negligible computational challenge of MIL in the context of DAM, i.e., bag size is too large to be loaded into {GPU} memory for backpropagation, which is required by the standard pooling methods of MIL. To tackle this challenge, we propose variance-reduced stochastic pooling methods in the spirit of stochastic optimization by formulating the loss function over the pooled prediction as a multi-level compositional function. By synthesizing techniques from stochastic compositional optimization and non-convex min-max optimization, we propose a unified and provable muli-instance DAM (MIDAM) algorithm with stochastic smoothed-max pooling or stochastic attention-based pooling, which only samples a few instances for each bag to compute a sto
    
[^105]: 结构模拟和桥梁健康监测的神经运算器

    Neural operator for structural simulation and bridge health monitoring. (arXiv:2305.07889v1 [cs.LG])

    [http://arxiv.org/abs/2305.07889](http://arxiv.org/abs/2305.07889)

    本论文提出了结构模拟和桥梁健康监测的神经运算器VINO，通过学习结构响应场和损伤场之间的映射，在前向预测和反向确定损伤区域和程度方面可以比传统有限元模型更准确地预测和判断。

    

    将深度学习与结构工程相结合已经受到了广泛关注，用于前向问题（结构模拟）和反向问题（结构健康监测）。本研究基于傅里叶神经运算器，提出了VINO（车辆-桥梁相互作用神经运算器），作为桥梁结构的数字孪生。VINO学习结构响应场和损伤场之间的映射。本研究通过运行参数有限元（FE）模拟，考虑结构初始损伤场的随机分布，建立了VBI-FE数据集。随后，在四种损伤情况下进行了实验研究，产生了VBI-EXP数据集。在VINO通过VBI-FE预训练并在健康状态下通过VBI-EXP微调后，模型实现了以下两个改进。首先，前向的VINO比FE模型更准确地从损伤场输入预测结构响应。其次，反向的VINO可以确定损伤区域和程度。

    Infusing deep learning with structural engineering has received widespread attention for both forward problems (structural simulation) and inverse problems (structural health monitoring). Based on Fourier Neural Operator, this study proposes VINO (Vehicle-bridge Interaction Neural Operator) to serve as the digital twin of bridge structures. VINO learns mappings between structural response fields and damage fields. In this study, VBI-FE dataset was established by running parametric finite element (FE) simulations considering a random distribution of structural initial damage field. Subsequently, VBI-EXP dataset was produced by conducting an experimental study under four damage scenarios. After VINO was pre-trained by VBI-FE and fine-tuned by VBI-EXP from the bridge at the healthy state, the model achieved the following two improvements. First, forward VINO can predict structural responses from damage field inputs more accurately than the FE model. Second, inverse VINO can determine, loc
    
[^106]: FactKG: 通过知识图谱推理进行事实验证

    FactKG: Fact Verification via Reasoning on Knowledge Graphs. (arXiv:2305.06590v1 [cs.CL])

    [http://arxiv.org/abs/2305.06590](http://arxiv.org/abs/2305.06590)

    FactKG是一个新的数据集，通过知识图谱推理进行事实验证，包含108k个自然语言声明和五种推理类型，可帮助社区更好地使用知识图谱进行事实验证。

    

    在现实应用中，知识图谱（KG）在各种领域（如医疗应用和对话代理）中被广泛使用。然而，在事实验证方面，KG尚未充分利用作为知识源。KG可以成为事实验证的有价值的知识来源，因为它们具有可靠性和广泛的适用性。KG由节点和边组成，清晰地展示了概念之间的联系，使得机器可以推理出一系列主题。然而，理解这些机器可读的概念如何映射到文本中的信息存在许多挑战。为了使社区更好地利用KG，我们介绍了一个新的数据集，FactKG:通过知识图谱推理进行事实验证，它包含108k个自然语言声明以及五种推理类型：单跳、合取、存在、多跳和否定。此外，FactKG包含各种语言模式，包括口语风格的声明和书面风格的声明，以提高实用性。

    In real world applications, knowledge graphs (KG) are widely used in various domains (e.g. medical applications and dialogue agents). However, for fact verification, KGs have not been adequately utilized as a knowledge source. KGs can be a valuable knowledge source in fact verification due to their reliability and broad applicability. A KG consists of nodes and edges which makes it clear how concepts are linked together, allowing machines to reason over chains of topics. However, there are many challenges in understanding how these machine-readable concepts map to information in text. To enable the community to better use KGs, we introduce a new dataset, FactKG: Fact Verification via Reasoning on Knowledge Graphs. It consists of 108k natural language claims with five types of reasoning: One-hop, Conjunction, Existence, Multi-hop, and Negation. Furthermore, FactKG contains various linguistic patterns, including colloquial style claims as well as written style claims to increase practica
    
[^107]: 分布式多目标决策制定

    Distributional Multi-Objective Decision Making. (arXiv:2305.05560v1 [cs.AI])

    [http://arxiv.org/abs/2305.05560](http://arxiv.org/abs/2305.05560)

    该论文介绍了一种分布式多目标决策制定的方法，其中引入了分布式不支配集和凸分布不支配集的概念，证明了它们可以包含所有最优解，通过实验验证了方法的有效性。

    

    在具有冲突目标的场景中进行有效的决策支持，可以向决策者呈现一组可能最优解。我们探讨这些解应该包含哪些策略以及如何高效地计算这些解。基于这一目标，我们采用分布式方法，引入一种新颖的优势准则，直接关联策略的回报分布。基于这个准则，我们提出了分布式不支配集，并证明其中包含了帕累托前沿的忽略的最优策略。此外，我们提出了凸分布不支配集，并证明它包括所有在多维风险规避决策者中最大化预期效用的策略。我们设计了一种新算法来学习分布式不支配集，并贡献了剪枝算子来将其减少到凸分布不支配集。通过实验，我们证明了这些方法的可行性和有效性。

    For effective decision support in scenarios with conflicting objectives, sets of potentially optimal solutions can be presented to the decision maker. We explore both what policies these sets should contain and how such sets can be computed efficiently. With this in mind, we take a distributional approach and introduce a novel dominance criterion relating return distributions of policies directly. Based on this criterion, we present the distributional undominated set and show that it contains optimal policies otherwise ignored by the Pareto front. In addition, we propose the convex distributional undominated set and prove that it comprises all policies that maximise expected utility for multivariate risk-averse decision makers. We propose a novel algorithm to learn the distributional undominated set and further contribute pruning operators to reduce the set to the convex distributional undominated set. Through experiments, we demonstrate the feasibility and effectiveness of these metho
    
[^108]: GPT-NAS: 以生成式预训练模型为基础的神经架构搜索

    GPT-NAS: Neural Architecture Search with the Generative Pre-Trained Model. (arXiv:2305.05351v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2305.05351](http://arxiv.org/abs/2305.05351)

    GPT-NAS使用生成式预训练模型优化神经架构搜索，通过提出近似的架构组件减小搜索空间，并明显优于其他NAS方法。

    

    神经架构搜索(NAS)已经成为了一种自动设计最优神经网络架构的有效方法之一。虽然一些人工设计的神经网络已经在多项任务中取得了人类水平的表现，但在NAS方法中很少出现这类成果，主要原因在于神经架构的搜索空间太大了，导致NAS算法效率低下。这项工作提出了一种新的架构搜索算法，称为GPT-NAS，通过生成式预训练模型来优化神经架构。在GPT-NAS中，我们假设一个在大规模语料库上预训练的生成模型能够学习构建神经架构的基本规律。因此，GPT-NAS利用生成式预训练模型来提出合理的架构组件，从而大大减少了搜索空间，引入了搜索过程中的先验知识。广泛的实验结果表明，我们的GPT-NAS方法明显优于其他NAS方法。

    Neural Architecture Search (NAS) has emerged as one of the effective methods to design the optimal neural network architecture automatically. Although neural architectures have achieved human-level performances in several tasks, few of them are obtained from the NAS method. The main reason is the huge search space of neural architectures, making NAS algorithms inefficient. This work presents a novel architecture search algorithm, called GPT-NAS, that optimizes neural architectures by Generative Pre-Trained (GPT) model. In GPT-NAS, we assume that a generative model pre-trained on a large-scale corpus could learn the fundamental law of building neural architectures. Therefore, GPT-NAS leverages the generative pre-trained (GPT) model to propose reasonable architecture components given the basic one. Such an approach can largely reduce the search space by introducing prior knowledge in the search process. Extensive experimental results show that our GPT-NAS method significantly outperforms
    
[^109]: 通过数据生成和参数畸变实现隐私保护联邦学习的接近最优效用

    Towards Achieving Near-optimal Utility for Privacy-Preserving Federated Learning via Data Generation and Parameter Distortion. (arXiv:2305.04288v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.04288](http://arxiv.org/abs/2305.04288)

    本论文提出了一种用数据生成和参数畸变实现隐私保护联邦学习接近最优效用的上限方法，其中通过降低方差和模型参数差异来衡量效用损失。

    

    联邦学习（FL）使参与方能够协作构建具有提高效用的全局模型，而不泄露私有数据信息。必须采用适当的保护机制来满足保护隐私和维护高模型效用的要求。目前采用的保护机制的本质，包括“随机化机制”和“压缩机制”，是通过畸变模型参数来保护隐私。我们通过原始模型参数和畸变模型参数之间的差距来衡量效用。我们想要确定在什么普遍条件下，通过数据生成和参数畸变，隐私保护的联邦学习可以实现接近最优的效用。为了提供接近最优效用的途径，我们提出了一个效用损失的上限，用两个主要项称为降低方差和模型参数差异来衡量。

    Federated learning (FL) enables participating parties to collaboratively build a global model with boosted utility without disclosing private data information. Appropriate protection mechanisms have to be adopted to fulfill the requirements in preserving \textit{privacy} and maintaining high model \textit{utility}. The nature of the widely-adopted protection mechanisms including \textit{Randomization Mechanism} and \textit{Compression Mechanism} is to protect privacy via distorting model parameter. We measure the utility via the gap between the original model parameter and the distorted model parameter. We want to identify under what general conditions privacy-preserving federated learning can achieve near-optimal utility via data generation and parameter distortion. To provide an avenue for achieving near-optimal utility, we present an upper bound for utility loss, which is measured using two main terms called variance-reduction and model parameter discrepancy separately. Our analysis
    
[^110]: PersonaLLM: 探究GPT-3.5表达个性特征和性别差异的能力

    PersonaLLM: Investigating the Ability of GPT-3.5 to Express Personality Traits and Gender Differences. (arXiv:2305.02547v1 [cs.CL])

    [http://arxiv.org/abs/2305.02547](http://arxiv.org/abs/2305.02547)

    本文探究了基于LLMs模拟代理的行为，称之为LLM Personas，在分配大五人格类型和性别角色时是否可以生成具有一致性的个性化特质的内容。

    

    尽管大型语言模型在各个行业的聊天机器人设计中有许多用途，并且研究表明个性化聊天机器人在满足不同人格特征方面的重要性，但很少有研究评估个性化LLM的行为是否能够准确、一致地反映某些人格特征。我们考虑研究基于LLM的模拟代理的行为，称之为LLM personas，并使用GPT-3.5（text-davinci-003）进行案例研究，以研究LLM在分配大五人格类型和性别角色时是否可以生成具有一致性的个性化特质的内容。我们创建了320个LLM personas（每种大五人格类型有5个女性和5个男性），并提示他们完成经典的44项大五人格问卷（BFI），然后撰写一个关于他们童年的800字故事。结果表明，LLM personas的自我报告的BFI分数与他们分配的人格类型一致。

    Despite the many use cases for large language models (LLMs) in the design of chatbots in various industries and the research showing the importance of personalizing chatbots to cater to different personality traits, little work has been done to evaluate whether the behaviors of personalized LLMs can reflect certain personality traits accurately and consistently. We consider studying the behavior of LLM-based simulated agents which refer to as LLM personas and present a case study with GPT-3.5 (text-davinci-003) to investigate whether LLMs can generate content with consistent, personalized traits when assigned Big Five personality types and gender roles. We created 320 LLM personas (5 females and 5 males for each of the 32 Big Five personality types) and prompted them to complete the classic 44-item Big Five Inventory (BFI) and then write an 800-word story about their childhood. Results showed that LLM personas' self-reported BFI scores are consistent with their assigned personality typ
    
[^111]: 可解释人工智能的范畴基础：一种统一的结构和语义形式体系。

    Categorical Foundations of Explainable AI: A Unifying Formalism of Structures and Semantics. (arXiv:2304.14094v1 [cs.AI])

    [http://arxiv.org/abs/2304.14094](http://arxiv.org/abs/2304.14094)

    本文采用范畴理论的框架，提出了可解释AI的统一理论体系，为领域中所有重要术语提供了清晰的形式定义，并提供了遵循所提出结构的领域分类法。

    

    可解释人工智能（XAI）旨在回答与AI模型部署相关的伦理和法律问题。然而，相当数量的领域特定评论强调需要一个数学基础来定义领域中的关键概念，即使“解释”这个术语还缺乏精确定义。这些评论还主张建立一个健全而统一的可解释AI形式体系，以避免出现不良提出问题，帮助研究人员浏览一个快速增长的知识体系。据作者所知，该论文是填补该空白的首次尝试，通过形式化一个可解释AI的统一理论。采用范畴理论的框架，特别是反馈单调范畴，我们首先提供了可解释AI中所有重要术语的形式定义。然后，我们提出了一个遵循提出结构的领域分类法，展示了如何使用引入的理论来对当前研究的所有主要XAI系统类进行分类。

    Explainable AI (XAI) aims to answer ethical and legal questions associated with the deployment of AI models. However, a considerable number of domain-specific reviews highlight the need of a mathematical foundation for the key notions in the field, considering that even the term "explanation" still lacks a precise definition. These reviews also advocate for a sound and unifying formalism for explainable AI, to avoid the emergence of ill-posed questions, and to help researchers navigate a rapidly growing body of knowledge. To the authors knowledge, this paper is the first attempt to fill this gap by formalizing a unifying theory of XAI. Employing the framework of category theory, and feedback monoidal categories in particular, we first provide formal definitions for all essential terms in explainable AI. Then we propose a taxonomy of the field following the proposed structure, showing how the introduced theory can be used to categorize all the main classes of XAI systems currently studi
    
[^112]: Spikingformer: 基于Transformer的脉冲神经网络的脉冲驱动残差学习

    Spikingformer: Spike-driven Residual Learning for Transformer-based Spiking Neural Network. (arXiv:2304.11954v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2304.11954](http://arxiv.org/abs/2304.11954)

    提出了一种适用于硬件的SNN脉冲驱动残差学习结构，基于该结构开发了一个纯Transformer的脉冲神经网络Spikingformer，用于避免非脉冲计算并在多个数据集上实现了优异的性能表现。

    

    脉冲神经网络(SNNs)由于其事件驱动的脉冲计算，提供了一种有前途的节能替代人工神经网络的方法。然而，包括Spikformer和SEW ResNet在内的最新深度SNN存在非脉冲计算（整数浮点乘法），这是由于它们的残差连接结构所导致的。这些非脉冲计算增加了SNN的功耗，并使其不适用于只支持脉冲操作的主流神经形态硬件上。本文提出了一种适用于硬件的脉冲驱动残差学习体系结构，用于避免非脉冲计算。基于这个残差设计，我们开发了Spikingformer，这是一个纯Transformer的脉冲神经网络。我们在ImageNet、CIFAR10、CIFAR100、CIFAR10-DVS和DVS128 Gesture数据集上评估了Spikingformer，并表明作为先进骨干的直接训练的纯SNN，Spikingformer表现出比现有技术更好的性能(75.85$\%$ top-1 accuracy on ImageNet)。

    Spiking neural networks (SNNs) offer a promising energy-efficient alternative to artificial neural networks, due to their event-driven spiking computation. However, state-of-the-art deep SNNs (including Spikformer and SEW ResNet) suffer from non-spike computations (integer-float multiplications) caused by the structure of their residual connection. These non-spike computations increase SNNs' power consumption and make them unsuitable for deployment on mainstream neuromorphic hardware, which only supports spike operations. In this paper, we propose a hardware-friendly spike-driven residual learning architecture for SNNs to avoid non-spike computations. Based on this residual design, we develop Spikingformer, a pure transformer-based spiking neural network. We evaluate Spikingformer on ImageNet, CIFAR10, CIFAR100, CIFAR10-DVS and DVS128 Gesture datasets, and demonstrate that Spikingformer outperforms the state-of-the-art in directly trained pure SNNs as a novel advanced backbone (75.85$\
    
[^113]: 一种可扩展的序列转移优化问题生成器

    A Scalable Test Problem Generator for Sequential Transfer Optimization. (arXiv:2304.08503v1 [cs.NE])

    [http://arxiv.org/abs/2304.08503](http://arxiv.org/abs/2304.08503)

    STO中已有的测试问题设计不完善，难以代表真实问题多样化关系，限制了算法的表现。本文介绍了一种可扩展的序列转移优化问题生成器。

    

    近年来，序列转移优化(STO)受到越来越多的研究关注，旨在利用储存在数据库中以前求解的优化任务的知识来提高优化性能。然而，尽管算法设计已有重大进展，但STO中的测试问题设计并不完善。它们往往是由其他基准函数随机组合而成，这些基准函数具有相同的最佳值，或者生成自表现出有限变化的实际问题。这些问题中源任务和目标任务的最优解之间的关系是手动配置的，因此单调，限制了它们表征真实问题多样化关系的能力。因此，许多算法在这些问题上取得的有前途的结果具有高度的偏见，并且难以推广到其他问题。鉴于此，我们首先引入了一些表征STO问题的基本概念。

    Sequential transfer optimization (STO), which aims to improve optimization performance by exploiting knowledge captured from previously-solved optimization tasks stored in a database, has been gaining increasing research attention in recent years. However, despite significant advancements in algorithm design, the test problems in STO are not well designed. Oftentimes, they are either randomly assembled by other benchmark functions that have identical optima or are generated from practical problems that exhibit limited variations. The relationships between the optimal solutions of source and target tasks in these problems are manually configured and thus monotonous, limiting their ability to represent the diverse relationships of real-world problems. Consequently, the promising results achieved by many algorithms on these problems are highly biased and difficult to be generalized to other problems. In light of this, we first introduce a few rudimentary concepts for characterizing STO pr
    
[^114]: 可能大致正确联邦学习

    Probably Approximately Correct Federated Learning. (arXiv:2304.04641v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2304.04641](http://arxiv.org/abs/2304.04641)

    本文提出了FedPAC框架，利用PAC学习理论推导出一个解析解，可以保证FL之间隐私、效用和效率的最佳权衡。

    

    联邦学习是一种新的分布式学习范例，其主要支柱为隐私、效用和效率。现有研究表明，同时实现无穷小隐私泄露、效用损失和效率是不可能的。因此，在设计联邦学习算法时，如何找到最佳权衡解决方案是关键考虑因素。一种常见的方法是将权衡问题视为多目标优化问题，即目标是在约束隐私泄露不超过预定值的情况下最小化效用损失和效率降低。然而，现有的多目标优化框架非常耗时，并且不能保证帕累托前沿的存在性，这激励我们寻求一种方法，将多目标问题转化为单目标问题，因为它更高效、更容易被解决。为此，本文提出了FedPAC，这是一个统一的框架，利用PAC学习理论推导出一个解析解，可以保证FL之间隐私、效用和效率的最佳权衡。具体而言，我们首先将FL问题公式化为一个二分类任务，然后设计一个自适应FL算法，动态调整每个客户端的采样比率，以平衡全局和本地的隐私-效用权衡，最后证明FedPAC可以在温和的假设下高概率地实现最优的隐私-效用权衡。基准数据集上的大量实验证明了我们提出的FedPAC框架的功效和效率。

    Federated learning (FL) is a new distributed learning paradigm, with privacy, utility, and efficiency as its primary pillars. Existing research indicates that it is unlikely to simultaneously attain infinitesimal privacy leakage, utility loss, and efficiency. Therefore, how to find an optimal trade-off solution is the key consideration when designing the FL algorithm. One common way is to cast the trade-off problem as a multi-objective optimization problem, i.e., the goal is to minimize the utility loss and efficiency reduction while constraining the privacy leakage not exceeding a predefined value. However, existing multi-objective optimization frameworks are very time-consuming, and do not guarantee the existence of the Pareto frontier, this motivates us to seek a solution to transform the multi-objective problem into a single-objective problem because it is more efficient and easier to be solved. To this end, in this paper, we propose FedPAC, a unified framework that leverages PAC l
    
[^115]: 将未标记数据纳入贝叶斯神经网络中

    Incorporating Unlabelled Data into Bayesian Neural Networks. (arXiv:2304.01762v1 [cs.LG])

    [http://arxiv.org/abs/2304.01762](http://arxiv.org/abs/2304.01762)

    该论文提出了一种利用未标记数据学习贝叶斯神经网络（BNNs）的对比框架，通过该框架提出了一种同时具备自监督学习的标签效率和贝叶斯方法中的不确定性估计的实用BNN算法。最后，该方法在半监督和低预算主动学习问题中展现出了数据高效学习的优势。

    

    我们提出了一个对贝叶斯神经网络（BNNs）中先验分布进行学习的对比框架，利用未标记数据来优化。基于该框架，我们提出了一种实用的BNN算法，同时具备自监督学习的标签效率和贝叶斯方法中的根据原则的不确定性估计。最后，我们展示了我们的方法在半监督和低预算主动学习问题中的数据高效学习优势。

    We develop a contrastive framework for learning better prior distributions for Bayesian Neural Networks (BNNs) using unlabelled data. With this framework, we propose a practical BNN algorithm that offers the label-efficiency of self-supervised learning and the principled uncertainty estimates of Bayesian methods. Finally, we demonstrate the advantages of our approach for data-efficient learning in semi-supervised and low-budget active learning problems.
    
[^116]: 重新思考人工智能可解释性与合理性

    Rethinking AI Explainability and Plausibility. (arXiv:2303.17707v1 [cs.AI])

    [http://arxiv.org/abs/2303.17707](http://arxiv.org/abs/2303.17707)

    本文研究了XAI评估中最普遍的人为概念——解释合理性。虽然一直被制定为AI可解释性任务的重要评估目标，但是评估XAI的合理性有时是有害的，且无法达到模型可理解性、透明度和可信度的目的。

    

    为了使可解释人工智能（XAI）算法符合人类交流规范，支持人类推理过程，并满足人类对于AI解释的需求，设定适当的评估目标至关重要。在本文中，我们研究了解释合理性，这是XAI评估中最普遍的人为概念。合理性衡量机器解释与人类解释相比的合理程度。合理性一直被传统地制定为AI可解释性任务的重要评估目标。我们反对这个想法，并展示了如何优化和评估XAI的合理性有时是有害的，且无法达到模型可理解性、透明度和可信度的目的。具体来说，评估XAI算法的合理性会规范机器解释，以表达与人类解释完全相同的内容，这偏离了人类解释的基本动机：表达自己的理解。

    Setting proper evaluation objectives for explainable artificial intelligence (XAI) is vital for making XAI algorithms follow human communication norms, support human reasoning processes, and fulfill human needs for AI explanations. In this article, we examine explanation plausibility, which is the most pervasive human-grounded concept in XAI evaluation. Plausibility measures how reasonable the machine explanation is compared to the human explanation. Plausibility has been conventionally formulated as an important evaluation objective for AI explainability tasks. We argue against this idea, and show how optimizing and evaluating XAI for plausibility is sometimes harmful, and always ineffective to achieve model understandability, transparency, and trustworthiness. Specifically, evaluating XAI algorithms for plausibility regularizes the machine explanation to express exactly the same content as human explanation, which deviates from the fundamental motivation for humans to explain: expres
    
[^117]: 显式规划有助于语言模型进行逻辑推理

    Explicit Planning Helps Language Models in Logical Reasoning. (arXiv:2303.15714v1 [cs.CL])

    [http://arxiv.org/abs/2303.15714](http://arxiv.org/abs/2303.15714)

    本文提出了一个新的系统，使用语言模型进行多步逻辑推理，采用了显式规划来帮助做出更明智的决策，比其他竞争系统表现更好，显式规划在系统性能中起着关键作用。

    

    语言模型在各种自然语言处理任务中表现出色。本文提出了一个新颖的系统，采用语言模型进行多步逻辑推理。我们的系统将显式规划纳入到推理过程中，因此可以通过展望未来的效果来做出更明智的决策。在实验中，我们的全套系统在多项选择题答题任务中明显优于其他竞争系统，尽管只有约15亿个参数，但与GPT-3-davinci表现相当。我们进行了多个消融研究以证明显式规划在系统性能中起着关键作用。

    Language models have been shown to perform remarkably well on a wide range of natural language processing tasks. In this paper, we propose a novel system that uses language models to perform multi-step logical reasoning. Our system incorporates explicit planning into its inference procedure, thus able to make more informed reasoning decisions at each step by looking ahead into their future effects. In our experiments, our full system significantly outperforms other competing systems. On a multiple-choice question answering task, our system performs competitively compared to GPT-3-davinci despite having only around 1.5B parameters. We conduct several ablation studies to demonstrate that explicit planning plays a crucial role in the system's performance.
    
[^118]: 面向以人为中心的人工智能软件系统的需求工程框架

    Requirements Engineering Framework for Human-centered Artificial Intelligence Software Systems. (arXiv:2303.02920v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2303.02920](http://arxiv.org/abs/2303.02920)

    该研究提出了一个基于以人为中心的人工智能指南和用户调查开发的框架，以帮助收集和建模人工智能的以人为中心的软件需求，并在一项案例研究中成功应用于提高360度视频质量。

    

    [背景] 近年来，用于构建软件解决方案的人工智能（AI）组件显著增加。然而，许多解决方案侧重于技术方面，忽略了关键的以人为中心的方面。[目标] 在构建基于人工智能的软件时包含以人为中心的方面，可以帮助实现更负责任、无偏见和包容性的基于人工智能的软件解决方案。[方法] 本文提出了一个新的框架，基于人工智能的以人为中心的指南和用户调查开发，以帮助收集人工智能的以人为中心的软件需求。我们提供一个目录来引出这些需求，以及一个概念模型来直观地呈现它们。[结果] 框架应用于一个案例研究中，以引出和建模增强360度视频质量的需求，该视频旨在为虚拟现实用户提供。[结论] 我们发现，我们提出的方法帮助项目团队充分了解以人为中心的方面，并提高了最终的软件解决方案的质量和可靠性。

    [Context] Artificial intelligence (AI) components used in building software solutions have substantially increased in recent years. However, many of these solutions focus on technical aspects and ignore critical human-centered aspects. [Objective] Including human-centered aspects during requirements engineering (RE) when building AI-based software can help achieve more responsible, unbiased, and inclusive AI-based software solutions. [Method] In this paper, we present a new framework developed based on human-centered AI guidelines and a user survey to aid in collecting requirements for human-centered AI-based software. We provide a catalog to elicit these requirements and a conceptual model to present them visually. [Results] The framework is applied to a case study to elicit and model requirements for enhancing the quality of 360 degree~videos intended for virtual reality (VR) users. [Conclusion] We found that our proposed approach helped the project team fully understand the human-ce
    
[^119]: 零样本批次级异常检测

    Zero-Shot Batch-Level Anomaly Detection. (arXiv:2302.07849v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07849](http://arxiv.org/abs/2302.07849)

    本文提出了一种名为“自适应中心表示”的方法，用于零样本批次级异常检测。该方法利用批量归一化来训练现成的深度异常检测器，可以自动零样本泛化为未见过的AD任务。在实验中，该方法显示出了在多种数据集上的优秀表现，对表格数据进行了零样本AD。

    

    异常检测（AD）在许多安全关键的应用领域中发挥着关键作用。适应正常数据分布漂移的异常检测器调整，特别是当没有针对“新正常”进行训练的数据时，这一挑战导致产生了零样本AD技术。在本文中，我们提出了一种名为自适应中心表示（ACR）的简单而有效的方法，用于零样本批次级AD。我们的方法使用批量归一化来训练现成的深度异常检测器（例如深度SVDD）来适应一组相互关联的训练数据分布，使其能够自动零样本泛化为未见过的AD任务。这个简单的方法，批量归一化加元训练，是一种非常有效和多功能的工具。我们的结果展示了对表格数据的第一个零样本AD结果，并在来自专业领域的图像数据的零样本异常检测和分段方面优于现有方法。

    Anomaly detection (AD) plays a crucial role in many safety-critical application domains. The challenge of adapting an anomaly detector to drift in the normal data distribution, especially when no training data is available for the "new normal," has led to the development of zero-shot AD techniques. In this paper, we propose a simple yet effective method called Adaptive Centered Representations (ACR) for zero-shot batch-level AD. Our approach trains off-the-shelf deep anomaly detectors (such as deep SVDD) to adapt to a set of inter-related training data distributions in combination with batch normalization, enabling automatic zero-shot generalization for unseen AD tasks. This simple recipe, batch normalization plus meta-training, is a highly effective and versatile tool. Our results demonstrate the first zero-shot AD results for tabular data and outperform existing methods in zero-shot anomaly detection and segmentation on image data from specialized domains.
    
[^120]: PubGraph: 一个大规模的科学知识图谱

    PubGraph: A Large-Scale Scientific Knowledge Graph. (arXiv:2302.02231v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.02231](http://arxiv.org/abs/2302.02231)

    PubGraph是一个大规模的、全面的科学知识图谱，包含超过3.85亿个实体和130亿个主要边缘，可以支持对科学网络进行推理研究。

    

    科研出版物是分享新发现、新方法、新技术和洞见的主要方式。然而，缺乏一个大规模、全面且易于使用的资源来捕捉出版物、作者和期刊之间的各种关系，给对科学有更深入理解的应用带来了障碍。在本文中，我们介绍了PubGraph，它是一个新的研究科学进展的资源，以大规模的知识图谱（KG）的形式出现，具有超过3.85亿个实体、130亿个主要边缘和15亿个限定词边缘。 PubGraph是全面的，并使用Wikidata本体论统一来自不同来源（包括Wikidata、OpenAlex和Semantic Scholar）的数据。除了这些来源的元数据外，PubGraph还包括来自辅助社区检测算法和大型语言模型的输出。为了进一步支持关于科学网络推理的研究，我们创建了几个大规模​​的基准。

    Research publications are the primary vehicle for sharing scientific progress in the form of new discoveries, methods, techniques, and insights. Unfortunately, the lack of a large-scale, comprehensive, and easy-to-use resource capturing the myriad relationships between publications, their authors, and venues presents a barrier to applications for gaining a deeper understanding of science. In this paper, we present PubGraph, a new resource for studying scientific progress that takes the form of a large-scale knowledge graph (KG) with more than 385M entities, 13B main edges, and 1.5B qualifier edges. PubGraph is comprehensive and unifies data from various sources, including Wikidata, OpenAlex, and Semantic Scholar, using the Wikidata ontology. Beyond the metadata available from these sources, PubGraph includes outputs from auxiliary community detection algorithms and large language models. To further support studies on reasoning over scientific networks, we create several large-scale ben
    
[^121]: DiSProD：用于规划的可微分符号分布传播

    DiSProD: Differentiable Symbolic Propagation of Distributions for Planning. (arXiv:2302.01491v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2302.01491](http://arxiv.org/abs/2302.01491)

    DiSProD是一个用于连续状态和动作空间中概率转移的在线规划器，它可以通过使用概率分布近似传播生成可微分的符号图表示策略价值，在处理稀疏奖励和随机环境方面优于现有规划器。

    

    该论文介绍了一个在线规划器DiSProD，用于处理连续状态和动作空间中概率转移的环境。DiSProD建立一个符号图，捕捉未来轨迹的分布，基于给定的策略，使用独立假设和概率分布的近似传播。该符号图提供了策略价值的可微分表示，使得可以进行长时间搜索的高效梯度优化。近似分布的传播可以看作是许多轨迹的聚合，非常适合处理稀疏奖励和随机环境。通过在离散时间规划和实时控制机器人系统方面进行广泛的实验性评估，该论文将DiSProD与最先进的规划器进行了比较。所提出的方法在处理随机环境、对搜索深度的敏感性、奖励的稀疏性和大的动作空间方面比现有规划器有所提高。

    The paper introduces DiSProD, an online planner developed for environments with probabilistic transitions in continuous state and action spaces. DiSProD builds a symbolic graph that captures the distribution of future trajectories, conditioned on a given policy, using independence assumptions and approximate propagation of distributions. The symbolic graph provides a differentiable representation of the policy's value, enabling efficient gradient-based optimization for long-horizon search. The propagation of approximate distributions can be seen as an aggregation of many trajectories, making it well-suited for dealing with sparse rewards and stochastic environments. An extensive experimental evaluation compares DiSProD to state-of-the-art planners in discrete-time planning and real-time control of robotic systems. The proposed method improves over existing planners in handling stochastic environments, sensitivity to search depth, sparsity of rewards, and large action spaces. Additional
    
[^122]: 无先验因果学习

    Zero-shot causal learning. (arXiv:2301.12292v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12292](http://arxiv.org/abs/2301.12292)

    无先验因果学习是一个解决预测新型干预措施个性化影响的框架，并通过元学习对任务的处理达成了目的，能够将干预措施的知识传输到未见过的干预措施中，并在合成和真实数据集上表现出了优越性能。

    

    在个性化医疗、公共政策和在线营销等领域，预测不同干预措施对特定个体的因果影响非常重要。预测现有干预措施的影响有许多方法，这些方法基于接受过干预措施的个体的历史数据。然而，在许多场景中，预测新型干预措施的影响也很重要，这些方法无法解决。在这里，我们考虑了无先验因果学习：预测新型干预措施的个性化影响。我们提出了CaML，这是一个因果元学习框架，它将每个干预措施的个性化预测效果作为一个任务来进行处理。CaML在数千个任务中训练单一的元模型，每个任务都是通过抽样生成一个干预措施及其接收者和非接收者来构建的。通过利用干预信息（例如，药物的属性）和个体特征（例如，特定个体的医疗记录），CaML学习如何将已观察到的干预措施的知识有效地传输给未见过的干预措施。我们在合成和真实数据集上展示了我们方法的有效性，展示了该方法具有推广到未见过干预措施并胜过现有方法的能力。

    Predicting how different interventions will causally affect a specific individual is important in a variety of domains such as personalized medicine, public policy, and online marketing. There are a large number of methods to predict the effect of an existing intervention based on historical data from individuals who received it. However, in many settings it is important to predict the effects of novel interventions (\emph{e.g.}, a newly invented drug), which these methods do not address. Here, we consider zero-shot causal learning: predicting the personalized effects of a novel intervention. We propose CaML, a causal meta-learning framework which formulates the personalized prediction of each intervention's effect as a task. CaML trains a single meta-model across thousands of tasks, each constructed by sampling an intervention, along with its recipients and nonrecipients. By leveraging both intervention information (\emph{e.g.}, a drug's attributes) and individual features~(\emph{e.g.
    
[^123]: 适用于所有领域的一个模型：基于协作域前缀调整的跨领域实体识别

    One Model for All Domains: Collaborative Domain-Prefix Tuning for Cross-Domain NER. (arXiv:2301.10410v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.10410](http://arxiv.org/abs/2301.10410)

    本论文提出了基于协作域前缀调整的跨领域实体识别，使用文本到文本生成的支撑领域相关指导来将知识转移至新域NER任务，避免了先前的为每个领域结束一个全新的NER模型的问题。

    

    解决实际场景中低资源问题是跨领域实体识别的一个挑战性任务。先前典型的解决方案主要通过使用来自丰富资源领域的数据进行预训练语言模型(PLMs)获得NER模型并将其适应于目标领域。由于不同领域实体类型之间的不匹配问题，先前的方法通常调整所有PLMs的参数，从而为每个领域结束一个全新的NER模型。此外，当前的模型只关注于利用一个普通来源领域中的知识，而未能成功地将来自多个来源领域的知识转移到目标上。为了解决这些问题，我们基于文本到文本生成的PLM引入了协作域前缀调整跨领域NER(CP-NER)。具体来说，我们呈现了用于文本到文本生成的支撑领域相关指导来将知识转移至新域NER任务而无需结构修改。我们利用冻结的PLMs并进行协作域前缀调整。

    Cross-domain NER is a challenging task to address the low-resource problem in practical scenarios. Previous typical solutions mainly obtain a NER model by pre-trained language models (PLMs) with data from a rich-resource domain and adapt it to the target domain. Owing to the mismatch issue among entity types in different domains, previous approaches normally tune all parameters of PLMs, ending up with an entirely new NER model for each domain. Moreover, current models only focus on leveraging knowledge in one general source domain while failing to successfully transfer knowledge from multiple sources to the target. To address these issues, we introduce Collaborative Domain-Prefix Tuning for cross-domain NER (CP-NER) based on text-to-text generative PLMs. Specifically, we present text-to-text generation grounding domain-related instructors to transfer knowledge to new domain NER tasks without structural modifications. We utilize frozen PLMs and conduct collaborative domain-prefix tuning
    
[^124]: CaRE：高度可配置机器人配置问题根因的发现

    CaRE: Finding Root Causes of Configuration Issues in Highly-Configurable Robots. (arXiv:2301.07690v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2301.07690](http://arxiv.org/abs/2301.07690)

    本文提出了CaRE方法，通过学习因果结构并估计选项对机器人性能指标的因果效应来抽象各种配置选项与机器人性能目标之间的因果关系，用于诊断高度可配置机器人的功能故障的根本原因。

    

    机器人系统具有组合化的大配置空间，以及数百或数千种可能的软硬件配置选项，这些选项之间相互非平凡地交互。配置参数被设置为特定目标，但如果配置不正确，则可能导致功能故障。由于指数级的配置空间以及机器人配置设置与性能之间的相互依赖性，找到此类故障的根本原因具有挑战性。本文提出了CaRE方法，通过因果关系的视角来诊断功能故障的根本原因。 CaRE通过学习因果结构并估计选项对机器人性能指标的因果效应来抽象各种配置选项与机器人性能目标之间的因果关系。我们通过找到观察到的功能故障的根本原因以及通过进行实验验证所诊断的根本原因来展示CaRE的功效。

    Robotic systems have subsystems with a combinatorially large configuration space and hundreds or thousands of possible software and hardware configuration options interacting non-trivially. The configurable parameters are set to target specific objectives, but they can cause functional faults when incorrectly configured. Finding the root cause of such faults is challenging due to the exponentially large configuration space and the dependencies between the robot's configuration settings and performance. This paper proposes CaRE -a method for diagnosing the root cause of functional faults through the lens of causality. CaRE abstracts the causal relationships between various configuration options and the robot's performance objectives by learning a causal structure and estimating the causal effects of options on robot performance indicators. We demonstrate CaRE's efficacy by finding the root cause of the observed functional faults and validating the diagnosed root cause by conducting ex
    
[^125]: 使用高维传感器反馈的深度强化学习进行灌溉调度

    Deep reinforcement learning for irrigation scheduling using high-dimensional sensor feedback. (arXiv:2301.00899v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.00899](http://arxiv.org/abs/2301.00899)

    本文介绍了一个使用深度强化学习进行灌溉调度的原则性框架和可行的程序，并在澳大利亚一个产出高的地区使用灌溉小麦的案例研究中证明了其有效性。

    

    深度强化学习在许多作物系统中应用于根据多个时间点上的各种测量值自适应地施加水分，有潜力显著改善灌溉调度。本文提出了一个原则性框架和可行的程序，使研究人员可以制定自己的优化问题并基于深度强化学习实现解决方案算法，以加快技术进步。其有效性已在澳大利亚一个产出高的地区使用灌溉小麦的案例研究中得到证明。

    Deep reinforcement learning has considerable potential to improve irrigation scheduling in many cropping systems by applying adaptive amounts of water based on various measurements over time. The goal is to discover an intelligent decision rule that processes information available to growers and prescribes sensible irrigation amounts for the time steps considered. Due to the technical novelty, however, the research on the technique remains sparse and impractical. To accelerate the progress, the paper proposes a principled framework and actionable procedure that allow researchers to formulate their own optimisation problems and implement solution algorithms based on deep reinforcement learning. The effectiveness of the framework was demonstrated using a case study of irrigated wheat grown in a productive region of Australia where profits were maximised. Specifically, the decision rule takes nine state variable inputs: crop phenological stage, leaf area index, extractable soil water for 
    
[^126]: 基于执行的方法评估开放域代码生成

    Execution-Based Evaluation for Open-Domain Code Generation. (arXiv:2212.10481v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2212.10481](http://arxiv.org/abs/2212.10481)

    ODEX是第一个基于开放域执行的自然语言到Python代码生成数据集。CODEX和CODEGEN分别表现不同的行为。ODEx将有助于进一步研究代码生成的开放域问题。

    

    为了将编码查询的范围扩展到更加实际的环境，我们提出了ODEx，第一个基于开放域执行的自然语言（NL）到Python代码生成数据集。ODEx共有945个NL-Code对，涵盖79个不同的库，以及1,707个供执行的人工编写的测试用例。我们从StackOverflow论坛获得NL-Code对，鼓励自然和实用的编码查询。此外，ODEx支持四种自然语言，即英语、西班牙语、日语和俄语。ODEx揭示了最高执行效果代码语言模型之间的有趣行为差异。虽然CODEX的总体结果更好，但CODEGEN通过扩展而有效地提高了性能 - CODEGEN 6.1B与CODEX 12B表现相当。两个模型都显示出开放域和封闭域之间的显著差距，但CODEGEN差距往往随着模型规模的增加而减少，而CODEX差距则会增加。我们释放ODEx以促进对代码生成社区的开放域问题的研究。

    To extend the scope of coding queries to more realistic settings, we propose ODEX, the first Open-Domain EXecution-based natural language (NL) to Python code generation dataset. ODEX has 945 NL-Code pairs spanning 79 diverse libraries, along with 1,707 human-written test cases for execution. Our NL-Code pairs are harvested from StackOverflow forums to encourage natural and practical coding queries. Moreover, ODEX supports four natural languages as intents, in English, Spanish, Japanese, and Russian. ODEX unveils intriguing behavioral differences among top-performing code language models (LM). While CODEX achieves better overall results, CODEGEN improves effectively via scaling -- CODEGEN 6.1B performs comparably with CODEX 12B. Both models show substantial gaps between open and closed domains, but CODEGEN gaps tend to decrease with model size while CODEX gaps increase. We release ODEX to facilitate research into open-domain problems for the code generation community.
    
[^127]: 注重视觉、属性和理性：迈向物理安全和可信的人工智能

    Foveate, Attribute, and Rationalize: Towards Physically Safe and Trustworthy AI. (arXiv:2212.09667v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09667](http://arxiv.org/abs/2212.09667)

    研究提出了一种新颖的FARM框架，通过利用外部知识生成能够被信任的原理，解决了不安全文本检测的问题，并能够帮助利益相关者和政策制定者保障消费者的安全。

    

    随着智能系统市场的不断增长，用户的身体安全越来越受到关注。不受限制的系统可能会向用户推荐危险的行为，导致严重的伤害。隐蔽的不安全文本是一个特别关注的领域，因为这样的文本可能会出现在日常场景中，并且很难被检测为有害。我们提出了FARM，这是一个新颖的框架，利用外部知识在安全上下文中生成可信的原理。具体而言，FARM注重于缺失的知识，以确认在特定情境中进行推理所需的信息，并通过可信源进行归因以获取此信息。这些知识用于分类原始文本的安全性并生成人类可解释的原理，揭示系统对特定用户群体的风险，并帮助利益相关者管理其系统的风险，帮助政策制定者为消费者安全提供具体的保障。我们的实验表明，FARM在识别不安全文本和生成可信的原理方面优于现有方法。

    Users' physical safety is an increasing concern as the market for intelligent systems continues to grow, where unconstrained systems may recommend users dangerous actions that can lead to serious injury. Covertly unsafe text is an area of particular interest, as such text may arise from everyday scenarios and are challenging to detect as harmful. We propose FARM, a novel framework leveraging external knowledge for trustworthy rationale generation in the context of safety. In particular, FARM foveates on missing knowledge to qualify the information required to reason in specific scenarios and retrieves this information with attribution to trustworthy sources. This knowledge is used to both classify the safety of the original text and generate human-interpretable rationales, shedding light on the risk of systems to specific user groups and helping both stakeholders manage the risks of their systems and policymakers to provide concrete safeguards for consumer safety. Our experiments show 
    
[^128]: 多语言翻译中干扰的原因和解决方法探究

    Causes and Cures for Interference in Multilingual Translation. (arXiv:2212.07530v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.07530](http://arxiv.org/abs/2212.07530)

    研究探究了多语言机器翻译中干扰的主要因素，通过系统化试验发现使用不到10亿参数的标准Transformer配置可以在很大程度上缓解干扰并促进协同，同时发现调整采样温度以控制数据中每个语言对所占比例的方法是平衡语言对之间关系的关键。

    

    多语言机器翻译模型可以从不同语言对之间的协同中获益，但同时也会受到干扰的影响。虽然目前有越来越多的先进方法旨在消除干扰，但我们对干扰现象的理解仍然有限。本研究确定了导致多语言机器翻译中干扰的主要因素。通过系统化试验，我们发现干扰（或协同）主要由模型大小、数据大小和每个语言对在总数据集中所占比例来决定。我们观察到，当模型相对于可用的训练数据非常小的时候，会出现严重的干扰，而使用不到10亿参数的标准Transformer配置可以在很大程度上缓解干扰并促进协同。此外，我们还展示了通过调整采样温度以控制数据中每个语言对所占比例的方法是平衡语言对之间关系的关键。

    Multilingual machine translation models can benefit from synergy between different language pairs, but also suffer from interference. While there is a growing number of sophisticated methods that aim to eliminate interference, our understanding of interference as a phenomenon is still limited. This work identifies the main factors that contribute to interference in multilingual machine translation. Through systematic experimentation, we find that interference (or synergy) are primarily determined by model size, data size, and the proportion of each language pair within the total dataset. We observe that substantial interference occurs mainly when the model is very small with respect to the available training data, and that using standard transformer configurations with less than one billion parameters largely alleviates interference and promotes synergy. Moreover, we show that tuning the sampling temperature to control the proportion of each language pair in the data is key to balancin
    
[^129]: SODA：一种自然语言处理包，用于提取癌症研究中的社会健康决定因素

    SODA: A Natural Language Processing Package to Extract Social Determinants of Health for Cancer Studies. (arXiv:2212.03000v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.03000](http://arxiv.org/abs/2212.03000)

    本文介绍了一个开源的自然语言处理包SODA，可用于提取癌症患者的社会健康决定因素。该包在泛化能力方面表现良好，可以用于新的疾病领域。研究结果表明，该包在癌症人群中提取SDoH的提取率较高。

    

    本文介绍了一个名为SODA的自然语言处理包，其中含有预训练的转换器模型，可用于提取癌症患者的社会健康决定因素（SDoH），并检验了SODA在新的疾病领域（如使用阿片类药物）的泛化能力，并评估了在癌症人群中提取SDoH的提取率。

    Objective: We aim to develop an open-source natural language processing (NLP) package, SODA (i.e., SOcial DeterminAnts), with pre-trained transformer models to extract social determinants of health (SDoH) for cancer patients, examine the generalizability of SODA to a new disease domain (i.e., opioid use), and evaluate the extraction rate of SDoH using cancer populations.  Methods: We identified SDoH categories and attributes and developed an SDoH corpus using clinical notes from a general cancer cohort. We compared four transformer-based NLP models to extract SDoH, examined the generalizability of NLP models to a cohort of patients prescribed with opioids, and explored customization strategies to improve performance. We applied the best NLP model to extract 19 categories of SDoH from the breast (n=7,971), lung (n=11,804), and colorectal cancer (n=6,240) cohorts.  Results and Conclusion: We developed a corpus of 629 cancer patients notes with annotations of 13,193 SDoH concepts/attribut
    
[^130]: 与任务导向对话的意图识别相关的话语嵌入和聚类方法的分析

    Analysis of Utterance Embeddings and Clustering Methods Related to Intent Induction for Task-Oriented Dialogue. (arXiv:2212.02021v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.02021](http://arxiv.org/abs/2212.02021)

    本文旨在研究任务导向对话中的意图识别问题，并提出两个关键因素：聚类算法和用户话语嵌入空间。实验证明，利用预训练的MiniLM与层次聚类相结合可以显著提高意图归纳任务的效果。

    

    本文重点研究无监督方法，以克服设计任务导向对话图谱中的典型挑战：为每个对话转折指定意图标签（意图聚类）并基于意图聚类方法生成一组意图（意图归纳）。我们假设自动归纳意图有两个显著因素：（1）意图标签的聚类算法和（2）用户话语嵌入空间。 我们根据DSTC11评估比较了现有的成品聚类模型和嵌入。我们的实验表明，认真考虑意图归纳任务中话语嵌入和聚类方法的综合选择是必要的。我们还发现，利用预训练的MiniLM与层次聚类相结合可显著提高意图归纳任务中的NMI，ARI，F1，准确性和示例覆盖。源代码可在https://github.com/Jeiyoon/dstc11-track2上获得。

    The focus of this work is to investigate unsupervised approaches to overcome quintessential challenges in designing task-oriented dialog schema: assigning intent labels to each dialog turn (intent clustering) and generating a set of intents based on the intent clustering methods (intent induction). We postulate there are two salient factors for automatic induction of intents: (1) clustering algorithm for intent labeling and (2) user utterance embedding space. We compare existing off-the-shelf clustering models and embeddings based on DSTC11 evaluation. Our extensive experiments demonstrate that the combined selection of utterance embedding and clustering method in the intent induction task should be carefully considered. We also present that pretrained MiniLM with Agglomerative clustering shows significant improvement in NMI, ARI, F1, accuracy and example coverage in intent induction tasks. The source codes are available at https://github.com/Jeiyoon/dstc11-track2.
    
[^131]: 论反事实推理的复杂性

    On the Complexity of Counterfactual Reasoning. (arXiv:2211.13447v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.13447](http://arxiv.org/abs/2211.13447)

    该研究发现，与在完全指定的结构因果模型上进行关联或干预推理相比，反事实推理的计算复杂性并不更高，两者的复杂性可以通过关于树宽的边界界定得到较好的处理。

    

    我们研究了反事实推理的计算复杂性，以及它与在结构因果模型（SCMs）上进行关联和干预推理的复杂性之间的关系。我们表明，在两个计算框架的背景下，反事实推理并不比在完全指定的SCMs上进行关联或干预推理更难。第一个框架基于树宽的概念，并包括经典的变量消除和联结树算法。第二个框架则基于更近期且更精细的因果树宽概念，针对具有功能依赖性的模型，如SCMs。我们的结果是建设性的，基于界定双网络（用于标准反事实推理，包括现实和想象两种情况）的（因果）树宽，到基础SCM结构的（因果）树宽之间的关系。特别地，我们表明后者（因果）树宽不会超过前者的两倍加一。因此，如果一个。

    We study the computational complexity of counterfactual reasoning in relation to the complexity of associational and interventional reasoning on structural causal models (SCMs). We show that counterfactual reasoning is no harder than associational or interventional reasoning on fully specified SCMs in the context of two computational frameworks. The first framework is based on the notion of treewidth and includes the classical variable elimination and jointree algorithms. The second framework is based on the more recent and refined notion of causal treewidth which is directed towards models with functional dependencies such as SCMs. Our results are constructive and based on bounding the (causal) treewidth of twin networks -- used in standard counterfactual reasoning that contemplates two worlds, real and imaginary -- to the (causal) treewidth of the underlying SCM structure. In particular, we show that the latter (causal) treewidth is no more than twice the former plus one. Hence, if a
    
[^132]: VATLM: 使用统一的遮蔽预测进行视听文本预训练的语音表示学习

    VATLM: Visual-Audio-Text Pre-Training with Unified Masked Prediction for Speech Representation Learning. (arXiv:2211.11275v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2211.11275](http://arxiv.org/abs/2211.11275)

    本文提出了一个名为VATLM的统一跨模式表示学习框架，利用视听文本资料的预处理与一种统一的遮蔽预测任务进行优化，以达到优秀的联合多模态表示效果。

    

    虽然语音是人类与外界交流的一种简单而有效的方式，但更真实的语音交互包含多模式信息，例如视觉、文本。如何设计一个统一的框架来整合不同的模态信息，利用不同的资源（例如视听对、音频文本对、未标记的语音和未标记的文本）促进语音表示学习还没有被很好地探索。本文提出了一个统一跨模式表示学习框架VATLM（Visual-Audio-Text语言模型）。所提出的VATLM采用统一的骨干网络来建模模态独立信息，并利用三个简单的模态依赖模块对视觉、语音和文本输入进行预处理。为了将这三种模态集成到一个共享语义空间中，VATLM使用我们所提出的统一分词器给出的统一令牌的遮蔽预测任务进行优化。我们在音频-视觉检索和口语理解任务上评估了预训练的VATLM，并证明了它在学习联合多模态表示方面的有效性。

    Although speech is a simple and effective way for humans to communicate with the outside world, a more realistic speech interaction contains multimodal information, e.g., vision, text. How to design a unified framework to integrate different modal information and leverage different resources (e.g., visual-audio pairs, audio-text pairs, unlabeled speech, and unlabeled text) to facilitate speech representation learning was not well explored. In this paper, we propose a unified cross-modal representation learning framework VATLM (Visual-Audio-Text Language Model). The proposed VATLM employs a unified backbone network to model the modality-independent information and utilizes three simple modality-dependent modules to preprocess visual, speech, and text inputs. In order to integrate these three modalities into one shared semantic space, VATLM is optimized with a masked prediction task of unified tokens, given by our proposed unified tokenizer. We evaluate the pre-trained VATLM on audio-vis
    
[^133]: 集成学习的可微分模型选择

    Differentiable Model Selection for Ensemble Learning. (arXiv:2211.00251v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.00251](http://arxiv.org/abs/2211.00251)

    本文提出了一种可微分模型选择框架，专为集成学习而设计，通过将集成学习任务转化为可微分选择程序，在集成学习模型内端到端地训练学习为特定输入样本选择合适的集成成员，有效性和多功能性均优于传统和先进的共识规则。

    

    模型选择是创造准确和稳健模型的策略。设计这些算法的一个关键挑战是确定任何特定输入样本的最佳分类模型。本文解决了这一挑战，提出了一种新颖的可微分模型选择框架，整合了机器学习和组合优化。该框架专为集成学习而设计，该策略结合了单个预训练模型的输出，并通过将集成学习任务转化为可微分选择程序，在集成学习模型内端到端地训练学习为特定输入样本选择合适的集成成员。在各种任务上测试，所提出的框架展示了其多功能性和有效性，且在各种设置和学习任务中均优于传统和先进的共识规则。

    Model selection is a strategy aimed at creating accurate and robust models. A key challenge in designing these algorithms is identifying the optimal model for classifying any particular input sample. This paper addresses this challenge and proposes a novel framework for differentiable model selection integrating machine learning and combinatorial optimization. The framework is tailored for ensemble learning, a strategy that combines the outputs of individually pre-trained models, and learns to select appropriate ensemble members for a particular input sample by transforming the ensemble learning task into a differentiable selection program trained end-to-end within the ensemble learning model. Tested on various tasks, the proposed framework demonstrates its versatility and effectiveness, outperforming conventional and advanced consensus rules across a variety of settings and learning tasks.
    
[^134]: 《Phantom--一种驱动多智能体强化学习的复杂系统建模框架》

    Phantom -- A RL-driven multi-agent framework to model complex systems. (arXiv:2210.06012v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2210.06012](http://arxiv.org/abs/2210.06012)

    Phantom是一个开源的驱动RL的代理建模框架，可以简化ABM规范，适用于建模复杂多智能体系统，包括经济系统和市场等。

    

    基于智能体的建模(ABM)是一种通过指定系统中自治决策组件或智能体的行为，并允许系统动态从它们的互动中出现的计算建模方法。近年多智能体强化学习(MARL)的进展使得研究多个代理同时学习的复杂环境的均衡变得可行。然而，大多数ABM框架不是RL本机的，即它们不提供与使用MARL学习智能体行为兼容的概念和接口。在本文中，我们介绍了一个新的开源框架Phantom，来弥合ABM和MARL之间的差距。Phantom是一个驱动代理建模经济系统和市场等复杂多智能体系统的RL框架。该框架旨在提供以MARL兼容方式简化ABM规范的工具 - 包括编码动态部分特征，

    Agent based modelling (ABM) is a computational approach to modelling complex systems by specifying the behaviour of autonomous decision-making components or agents in the system and allowing the system dynamics to emerge from their interactions. Recent advances in the field of Multi-agent reinforcement learning (MARL) have made it feasible to study the equilibrium of complex environments where multiple agents learn simultaneously. However, most ABM frameworks are not RL-native, in that they do not offer concepts and interfaces that are compatible with the use of MARL to learn agent behaviours. In this paper, we introduce a new open-source framework, Phantom, to bridge the gap between ABM and MARL. Phantom is an RL-driven framework for agent-based modelling of complex multi-agent systems including, but not limited to economic systems and markets. The framework aims to provide the tools to simplify the ABM specification in a MARL-compatible way - including features to encode dynamic part
    
[^135]: 用大型语言模型理解HTML

    Understanding HTML with Large Language Models. (arXiv:2210.03945v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.03945](http://arxiv.org/abs/2210.03945)

    本研究使用大型语言模型探索了对HTML的理解，提出了HTML理解模型，通过微调使其在语义分类、描述生成和自主网络导航三个任务上表现出良好的性能，显示出大型语言模型在HTML任务上表现出色。

    

    大型语言模型（LLMs）在各种自然语言任务中表现出了卓越的性能。然而，它们在HTML理解方面的能力——即解析网页的原始HTML，应用于自动化网络任务、爬取和浏览器辅助检索等方面——尚未得到完全的探索。我们提出了HTML理解模型（微调LLMs），并深入分析了它们在三个任务下的能力：（i）HTML元素的语义分类，（ii）HTML输入的描述生成，以及（iii）HTML页面的自主网络导航。虽然先前的工作已经为HTML理解开发了专用的架构和训练程序，但我们表明，预训练于标准自然语言语料库的LLMs非常适用于HTML理解任务。例如，微调后的LLMs在语义分类方面比仅基于任务数据集训练的模型准确率高12%。此外，当它们被微调于MiniW的数据时，LLMs的描述生成在人类主观质量评估中表现出与基于Transformer编码器—解码器的基线模型相当的质量，而且它们能够成功地自主地浏览HTML页面，执行各种任务。

    Large language models (LLMs) have shown exceptional performance on a variety of natural language tasks. Yet, their capabilities for HTML understanding -i.e., parsing the raw HTML of a webpage, with applications to automation of web-based tasks, crawling, and browser-assisted retrieval -- have not been fully explored. We contribute HTML understanding models (fine-tuned LLMs) and an in-depth analysis of their capabilities under three tasks: (i) Semantic Classification of HTML elements, (ii) Description Generation for HTML inputs, and (iii) Autonomous Web Navigation of HTML pages. While previous work has developed dedicated architectures and training procedures for HTML understanding, we show that LLMs pretrained on standard natural language corpora transfer remarkably well to HTML understanding tasks. For instance, fine-tuned LLMs are 12% more accurate at semantic classification compared to models trained exclusively on the task dataset. Moreover, when fine-tuned on data from the MiniW
    
[^136]: 良性自编码器

    Benign Autoencoders. (arXiv:2210.00637v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.00637](http://arxiv.org/abs/2210.00637)

    本文正式化了用于生成式人工智能中编码器-解码器对的最佳选择问题并提出了良性自编码器（BAE），BAE能够将数据投射到最优的流型上，实现了数据压缩和更加稳定的梯度下降。

    

    最近，生成式人工智能取得了很多进展，其中常采用编码器-解码器架构来实现数据的高效表示。本论文正式化了寻找最佳编码器-解码器对的数学问题并表征其解决方案，我们将其命名为“良性自编码器”（BAE）。我们证明BAE将数据投射到一个流型上，其维数为生成问题的最佳可压缩维度。我们强调BAE与人工智能中几个最近发展的方向之间的惊人联系，如有条件的GAN，上下文编码器，稳定扩散，堆叠自编码器和生成模型的学习能力。我们展示了BAE如何找到最优的低维潜在表示，从而在分布转移下提高鉴别器的性能。通过压缩“恶性”数据维度，BAE导致梯度更加平滑和稳定。

    Recent progress in Generative Artificial Intelligence (AI) relies on efficient data representations, often featuring encoder-decoder architectures. We formalize the mathematical problem of finding the optimal encoder-decoder pair and characterize its solution, which we name the "benign autoencoder" (BAE). We prove that BAE projects data onto a manifold whose dimension is the optimal compressibility dimension of the generative problem. We highlight surprising connections between BAE and several recent developments in AI, such as conditional GANs, context encoders, stable diffusion, stacked autoencoders, and the learning capabilities of generative models. As an illustration, we show how BAE can find optimal, low-dimensional latent representations that improve the performance of a discriminator under a distribution shift. By compressing "malignant" data dimensions, BAE leads to smoother and more stable gradients.
    
[^137]: 基于分散式数据集提炼的边缘资源受限环境下联邦学习

    Federated Learning via Decentralized Dataset Distillation in Resource-Constrained Edge Environments. (arXiv:2208.11311v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.11311](http://arxiv.org/abs/2208.11311)

    本论文介绍了一种名为FedD3的联邦学习框架，通过集成数据集提炼实例仅需要一次通信，与其他联邦学习方法相比，在需要通信的数据量方面表现显著更好，同时通过平衡准确性和通信成本来适应使用场景。

    

    在联邦学习中，所有的联网客户端协作地进行模型训练。然而，随着模型大小的增加，即使在迭代通信中共享已训练的部分模型，也往往会导致底层网络中的严重通信瓶颈。本文介绍了一种联邦学习框架FedD3，它只需要一次通信，并集成了数据集提炼实例。FedD3不同于其他联邦学习方法中的共享模型更新，它允许连接的客户端独立地提炼本地数据集，然后从网络中聚合那些分散的提炼数据集（例如，一些无法识别的图像）并用于模型训练。我们的实验结果表明，与其他联邦学习方法相比，FedD3在需要通信的数据量方面表现显著更好，同时它能够在使用场景中平衡准确性和通信成本。

    In federated learning, all networked clients contribute to the model training cooperatively. However, with model sizes increasing, even sharing the trained partial models often leads to severe communication bottlenecks in underlying networks, especially when communicated iteratively. In this paper, we introduce a federated learning framework FedD3 requiring only one-shot communication by integrating dataset distillation instances. Instead of sharing model updates in other federated learning approaches, FedD3 allows the connected clients to distill the local datasets independently, and then aggregates those decentralized distilled datasets (e.g. a few unrecognizable images) from networks for model training. Our experimental results show that FedD3 significantly outperforms other federated learning frameworks in terms of needed communication volumes, while it provides the additional benefit to be able to balance the trade-off between accuracy and communication cost, depending on usage sc
    
[^138]: 车型特定航点生成。

    Vehicle Type Specific Waypoint Generation. (arXiv:2208.04987v1 [cs.AI] CROSS LISTED)

    [http://arxiv.org/abs/2208.04987](http://arxiv.org/abs/2208.04987)

    开发了一种通用机制，利用车型控制器的副产品条件专门于某一车型的行为预测模型，结合概率行为模型生成车型特定的航点序列。

    

    我们开发了一种通用机制，从行为的概率基础模型中生成特定车型的航点序列。许多行为模型是基于不包括车辆信息的数据进行训练的，这限制了它们在规划等下游应用中的实用性。我们的新方法通过利用产生车型特定控制器的强化学习算法的副产品，有条件地将这种行为预测模型专门应用于某一车型。我们展示了如何将车型特定值函数估计与通用的概率行为模型组合，生成比其不考虑车型的航点序列更可能是物理可行的车型特定序列。

    We develop a generic mechanism for generating vehicle-type specific sequences of waypoints from a probabilistic foundation model of driving behavior. Many foundation behavior models are trained on data that does not include vehicle information, which limits their utility in downstream applications such as planning. Our novel methodology conditionally specializes such a behavior predictive model to a vehicle-type by utilizing byproducts of the reinforcement learning algorithms used to produce vehicle specific controllers. We show how to compose a vehicle specific value function estimate with a generic probabilistic behavior model to generate vehicle-type specific waypoint sequences that are more likely to be physically plausible then their vehicle-agnostic counterparts.
    
[^139]: 基于处理内存系统的机器学习训练的实验评估

    An Experimental Evaluation of Machine Learning Training on a Real Processing-in-Memory System. (arXiv:2207.07886v2 [cs.AR] UPDATED)

    [http://arxiv.org/abs/2207.07886](http://arxiv.org/abs/2207.07886)

    该研究评估了在处理内存系统上训练机器学习算法的潜能，并证明基于PIM的ML训练实现了显着的加速和能量效率。

    

    训练机器学习算法是一种计算密集型的过程，由于不断访问大型训练数据集，这种过程通常会受到内存限制。因此，以处理器为中心的系统（例如CPU，GPU）在内存单元和处理单元之间的数据传输方面存在昂贵的瓶颈，这会消耗大量的能量和执行周期。具有处理内存（PIM）功能的内存中心计算系统可以缓解这种数据移动瓶颈。我们的目标是了解现代通用PIM架构加速ML训练的潜力。为此，我们（1）在实际通用PIM架构上实现了几种代表性的传统ML算法（即线性回归，逻辑回归，决策树，K-Means聚类），（2）严格评估和表征这些算法的准确性，性能和扩展性，并且（3）与它们在CPU和GPU上的相应实现进行比较。我们在实际内存中心计算平台上的评估表明，与相应的CPU和GPU方法相比，基于PIM的ML训练实现了显着的加速和能量效率。

    Training machine learning (ML) algorithms is a computationally intensive process, which is frequently memory-bound due to repeatedly accessing large training datasets. As a result, processor-centric systems (e.g., CPU, GPU) suffer from costly data movement between memory units and processing units, which consumes large amounts of energy and execution cycles. Memory-centric computing systems, i.e., with processing-in-memory (PIM) capabilities, can alleviate this data movement bottleneck.  Our goal is to understand the potential of modern general-purpose PIM architectures to accelerate ML training. To do so, we (1) implement several representative classic ML algorithms (namely, linear regression, logistic regression, decision tree, K-Means clustering) on a real-world general-purpose PIM architecture, (2) rigorously evaluate and characterize them in terms of accuracy, performance and scaling, and (3) compare to their counterpart implementations on CPU and GPU. Our evaluation on a real mem
    
[^140]: 在医学领域中实用联邦学习的探索

    Towards the Practical Utility of Federated Learning in the Medical Domain. (arXiv:2207.03075v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.03075](http://arxiv.org/abs/2207.03075)

    本研究提出了应用联邦学习于医学领域的实用指南，包括三个具有代表性的医学数据集的实验，旨在提高医保业的数据效率，并形成适用于全行业的标准。

    

    联邦学习（FL）是一个活跃的研究领域。医学领域是采用FL的最适合领域之一，因为必须尊重患者隐私。然而，以往的研究并没有提供在医学领域中应用FL的实用指南。本文针对三个代表性的医学数据集，即长期的电子健康记录、皮肤癌图像和心电图信号，提出经验基准和实验设置。潜在的FL用户，如医疗机构和IT公司，可以将这些基准作为采用FL的指南，并尽可能减少试错。对于每个数据集，每个客户端数据来自不同的来源，以保留现实世界的异质性。我们评估了六种针对客户端数据异质性问题的FL算法，以及一种将两种典型FL算法的优点结合起来的混合算法。基于三种类型数据的实验结果，我们发现简单的FL算法可以达到与更复杂算法相当的性能。我们的工作为医疗机构和IT公司提供了在安全高效的方式下，应用FL从而改善医疗保健的实用指南。

    Federated learning (FL) is an active area of research. One of the most suitable areas for adopting FL is the medical domain, where patient privacy must be respected. Previous research, however, does not provide a practical guide to applying FL in the medical domain. We propose empirical benchmarks and experimental settings for three representative medical datasets with different modalities: longitudinal electronic health records, skin cancer images, and electrocardiogram signals. The likely users of FL such as medical institutions and IT companies can take these benchmarks as guides for adopting FL and minimize their trial and error. For each dataset, each client data is from a different source to preserve real-world heterogeneity. We evaluate six FL algorithms designed for addressing data heterogeneity among clients, and a hybrid algorithm combining the strengths of two representative FL algorithms. Based on experiment results from three modalities, we discover that simple FL algorith
    
[^141]: 多智能体动力学的概率对称性

    Probabilistic Symmetry for Multi-Agent Dynamics. (arXiv:2205.01927v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.01927](http://arxiv.org/abs/2205.01927)

    该论文提出了PECCO模型，通过利用多智能体间的对称性和能量评分规则，可以更准确地预测多智能体轨迹并量化不确定性，为下游决策提供重要支持。

    

    学习多智能体动态是人工智能的核心问题，广泛应用于机器人和自主驾驶等领域。多数现有的研究侧重于确定性预测，而产生概率预测以量化不确定性与评估风险方面对下游决策制定任务，如运动规划与避碰至关重要。多智能体动态通常包含内部对称性。通过利用对称性，特别是旋转等变性，我们不仅可以提高预测精度，还可以改善不确定性校准。我们引入能量评分作为适当的评分规则来评估概率预测表现。我们提出了一种新颖的深度动力学模型，即概率等变连续卷积（PECCO），用于多智能体轨迹的概率预测。PECCO将等变的连续卷积扩展到多智能体的联合速度分布建模上。它使用动态积分将不确定性从速度传播到位置。我们在合成和现实场景的结果中验证了PECCO模型的性能。

    Learning multi-agent dynamics is a core AI problem with broad applications in robotics and autonomous driving. While most existing works focus on deterministic prediction, producing probabilistic forecasts to quantify uncertainty and assess risks is critical for downstream decision-making tasks such as motion planning and collision avoidance. Multi-agent dynamics often contains internal symmetry. By leveraging symmetry, specifically rotation equivariance, we can improve not only the prediction accuracy but also uncertainty calibration. We introduce Energy Score, a proper scoring rule, to evaluate probabilistic predictions. We propose a novel deep dynamics model, Probabilistic Equivariant Continuous COnvolution (PECCO) for probabilistic prediction of multi-agent trajectories. PECCO extends equivariant continuous convolution to model the joint velocity distribution of multiple agents. It uses dynamics integration to propagate the uncertainty from velocity to position. On both synthetic a
    
[^142]: Transformer更加稳健吗？面向Transformer的确切稳健性验证

    Are Transformers More Robust? Towards Exact Robustness Verification for Transformers. (arXiv:2202.03932v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.03932](http://arxiv.org/abs/2202.03932)

    本文研究了基于Sparsemax的Transformers的稳健性问题，并发现Transformer不一定比传统的多层感知器更加稳健，这对于选择适用于安全关键领域应用的NN架构方面有深刻的考虑。

    

    作为新兴的神经网络类型，Transformer被应用于众多领域，从自然语言处理到自动驾驶。本论文研究Transformers的稳健性问题，这是一个关键特性，低稳健性可能会引起安全问题。具体而言，我们关注基于Sparsemax的Transformers，将找到它们的最大稳健性降低为一个混合整数二次约束编程（MIQCP）问题。我们还设计了两个可嵌入MIQCP编码并大幅加速其求解的预处理启发式方法。然后，我们使用Land Departure Warning应用程序进行实验，比较基于Sparsemax的Transformers与更传统的多层感知器（MLP）神经网络的稳健性。令我们惊讶的是，Transformer并不一定更加稳健，这引发了在选择适用于安全关键领域应用的NN架构方面的深刻考虑。

    As an emerging type of Neural Networks (NNs), Transformers are used in many domains ranging from Natural Language Processing to Autonomous Driving. In this paper, we study the robustness problem of Transformers, a key characteristic as low robustness may cause safety concerns. Specifically, we focus on Sparsemax-based Transformers and reduce the finding of their maximum robustness to a Mixed Integer Quadratically Constrained Programming (MIQCP) problem. We also design two pre-processing heuristics that can be embedded in the MIQCP encoding and substantially accelerate its solving. We then conduct experiments using the application of Land Departure Warning to compare the robustness of Sparsemax-based Transformers against that of the more conventional Multi-Layer-Perceptron (MLP) NNs. To our surprise, Transformers are not necessarily more robust, leading to profound considerations in selecting appropriate NN architectures for safety-critical domain applications.
    

