# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?](https://arxiv.org/abs/2402.19475) | 大多数代码语言模型对生成的冒牌样本的理解较为肤浅，存在三种明显的失败模式：误将冒牌样本分类为正确、在推理冒牌样本的执行行为时表现更差、修复冒牌样本的成功率往往低于生成它们的成功率。 |
| [^2] | [Loose LIPS Sink Ships: Asking Questions in Battleship with Language-Informed Program Sampling](https://arxiv.org/abs/2402.19471) | 研究利用大型语言模型提出信息量丰富的问题，在Battleship游戏中展示出与人类表现相匹配的效果，并揭示了贝叶斯模型如何指导问问题行为。 |
| [^3] | [TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning](https://arxiv.org/abs/2402.19467) | TV-TREES是第一个多模态蕴涵树生成器，通过生成视频直接蕴涵的简单前提与高级结论之间的蕴涵关系树，实现了可解释联合模态推理，并在挑战性的TVQA数据集上展示了最先进的零-shot性能。 |
| [^4] | [Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models](https://arxiv.org/abs/2402.19465) | 本文研究探索了大型语言模型在预训练期间的可信度，揭示了早期预训练LLMs已经能够区分各个可信度维度中的概念，提出了从预训练检查点中提取转向向量以增强LLM可信度的方法。 |
| [^5] | [Curiosity-driven Red-teaming for Large Language Models](https://arxiv.org/abs/2402.19464) | 研究提出了一种新方法，能够通过训练红队LLM，自动化生成测试案例，以最大化引出目标LLM不良响应，以解决当前RL方法生成测试案例覆盖范围较低的问题。 |
| [^6] | [$\texttt{COSMIC}$: Mutual Information for Task-Agnostic Summarization Evaluation](https://arxiv.org/abs/2402.19457) | $\texttt{COSMIC}$是一种以相互信息为基础的新的摘要评估方法，有效预测下游任务表现，并与人类判断相关性强。竞争性能优于$\texttt{BERTScore}$和$\texttt{ROUGE}$。 |
| [^7] | [Functional Benchmarks for Robust Evaluation of Reasoning Performance, and the Reasoning Gap](https://arxiv.org/abs/2402.19450) | 提出了一个用于评估语言模型推理能力的框架，通过功能变体的基准进行鲁棒性评估，发现静态基准和功能基准的准确性之间存在推理差距 |
| [^8] | [ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL](https://arxiv.org/abs/2402.19446) | 本文提出了一个用于构建LLMs的多轮强化学习算法的框架 |
| [^9] | [Probing the Information Encoded in Neural-based Acoustic Models of Automatic Speech Recognition Systems](https://arxiv.org/abs/2402.19443) | 本文提出了一个协议，旨在确定自动语音识别系统中声学模型中编码的信息的位置和影响。 |
| [^10] | [Training Dynamics of Multi-Head Softmax Attention for In-Context Learning: Emergence, Convergence, and Optimality](https://arxiv.org/abs/2402.19442) | 研究了多头softmax注意力模型在上下文学习中的训练动态，证明了全局收敛性，并发现了“任务分配”现象，梯度流动分为热身、涌现和收敛三个阶段，最终证明了梯度流的最优性。 |
| [^11] | [Differentially Private Worst-group Risk Minimization](https://arxiv.org/abs/2402.19437) | 该论文介绍了在差分隐私下进行最坏组风险最小化的系统研究，提出了一种新算法，通过稳定性分析实现了接近最优的风险控制效果。 |
| [^12] | [Compositional API Recommendation for Library-Oriented Code Generation](https://arxiv.org/abs/2402.19431) | 提出了CAPIR（Compositional API Recommendation）来为粗粒度需求推荐API，并采用“分而治之”的策略将任务描述分解为详细的子任务。 |
| [^13] | [Leveraging AI Predicted and Expert Revised Annotations in Interactive Segmentation: Continual Tuning or Full Training?](https://arxiv.org/abs/2402.19423) | 交互式分割结合了人工智能算法和人类专业知识，通过反复调整人工智能预测和专家修订的注释来持续改善人工智能，但如何在避免灾难性遗忘的同时提高计算效率仍是关键挑战。 |
| [^14] | [PEM: Prototype-based Efficient MaskFormer for Image Segmentation](https://arxiv.org/abs/2402.19422) | PEM提出了基于原型的高效MaskFormer，通过引入原型交叉注意力和多尺度特征金字塔网络，实现了在多个分割任务中的高效运行。 |
| [^15] | [Crafting Knowledge: Exploring the Creative Mechanisms of Chat-Based Search Engines](https://arxiv.org/abs/2402.19421) | 探索基于聊天的搜索引擎的创造性机制，并解析了大型语言模型如何选择信息源以生成人类一样理解性和创造性的响应。 |
| [^16] | [Understanding Iterative Combinatorial Auction Designs via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2402.19420) | 多智能体强化学习算法可能有助于理解迭代组合拍卖，但其有效部署具有挑战性，需要考虑保持游戏可处理性以及避免各种算法的陷阱。 |
| [^17] | [On the Scaling Laws of Geographical Representation in Language Models](https://arxiv.org/abs/2402.19406) | 地理知识可以在大型语言模型中观察到，随着模型规模增加而一致扩展，但更大的模型无法消除训练数据中的地理偏见。 |
| [^18] | [A Scalable and Transferable Time Series Prediction Framework for Demand Forecasting](https://arxiv.org/abs/2402.19402) | 提出了一种名为Forchestra的时间序列预测框架，能够准确预测各种物品的未来需求，并且在模型规模和泛化能力上均表现优异。 |
| [^19] | [Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy](https://arxiv.org/abs/2402.19379) | 该研究通过将十二个LLMs组成的LLM集成方法与925名人类预测者的群体预测进行比较，发现LLM群体优于简单的无信息基准，并在统计上等效于人类群体。 |
| [^20] | [OpenMedLM: Prompt engineering can out-perform fine-tuning in medical question-answering with open-source large language models](https://arxiv.org/abs/2402.19371) | OpenMedLM 提出了一个提示平台，利用提示工程在医学问答中能够超越对开源大型语言模型进行微调，实现了在医学基准上的 SOTA 性能。 |
| [^21] | [SoK: Exploring the Potential of Large Language Models for Improving Digital Forensic Investigation Efficiency](https://arxiv.org/abs/2402.19366) | 将大型语言模型（LLMs）整合到数字取证调查中有望提升调查效率，改善可追溯性，并缓解执法机构面临的技术和司法障碍。 |
| [^22] | [Watermark Stealing in Large Language Models](https://arxiv.org/abs/2402.19361) | LLM水印技术可能存在水印窃取漏洞，我们提出了自动WS算法并展示了攻击者可以在不到50美元的成本下通过欺骗和擦除攻击破解之前认为安全的最先进方案，成功率超过80%。 |
| [^23] | [Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy, Advances, and Outlook](https://arxiv.org/abs/2402.19348) | 这项调查系统地回顾了针对城市计算量身定制的深度学习数据融合方法的最新进展，将方法分为四大类别，并对不同数据来源和模态在跨领域数据融合中的作用进行了深入研究。 |
| [^24] | [Stitching Gaps: Fusing Situated Perceptual Knowledge with Vision Transformers for High-Level Image Classification](https://arxiv.org/abs/2402.19339) | 利用文化图像的具有定位感知知识增强高级图像分类的性能和解释性 |
| [^25] | [RL-GPT: Integrating Reinforcement Learning and Code-as-policy](https://arxiv.org/abs/2402.19299) | RL-GPT 是一个两级分层框架，结合了慢速代理和快速代理，能够高效地整合强化学习和编码任务，在Minecraft游戏中表现出卓越效率。 |
| [^26] | [Degradation Modeling and Prognostic Analysis Under Unknown Failure Modes](https://arxiv.org/abs/2402.19294) | 提出了一种利用UMAP技术的新型故障模式诊断方法，能够有效应对复杂系统中多种故障模式导致的不同降解路径，提高故障模式的准确识别能力。 |
| [^27] | [Robust Guidance for Unsupervised Data Selection: Capturing Perplexing Named Entities for Domain-Specific Machine Translation](https://arxiv.org/abs/2402.19267) | 提出了一种新颖的无监督数据选择方法，通过捕获领域特定机器翻译中令人困扰的命名实体，实现了高质量翻译效果。 |
| [^28] | [Learning Logic Specifications for Policy Guidance in POMDPs: an Inductive Logic Programming Approach](https://arxiv.org/abs/2402.19265) | 通过归纳逻辑编程方法，从POMDP执行痕迹中学习高质量启发式，以指导政策选择过程。 |
| [^29] | [Spinal Osteophyte Detection via Robust Patch Extraction on minimally annotated X-rays](https://arxiv.org/abs/2402.19263) | 通过新颖的 SegPatch 自动斑块提取技术，本研究实现了对脊柱 X 射线中骨赘的自动化检测，准确率达到 84.5\%，比基线方法高出 9.5%，有望帮助临床医生加速骨赘识别过程。 |
| [^30] | [A Cognitive-Based Trajectory Prediction Approach for Autonomous Driving](https://arxiv.org/abs/2402.19251) | 本文引入了人类化轨迹预测（HLTP）模型，通过采用受人类认知过程启发的师生知识蒸馏框架，使自主驾驶车辆更准确地预测周围车辆的运动。 |
| [^31] | [Context-based Interpretable Spatio-Temporal Graph Convolutional Network for Human Motion Forecasting](https://arxiv.org/abs/2402.19237) | 提出了基于上下文的可解释的时空图卷积网络（CIST-GCN），用于人体运动预测，在提高模型可解释性的基础上融合了GCN，在多个数据集上实验证明其优于其他方法。 |
| [^32] | [Fine Structure-Aware Sampling: A New Sampling Training Scheme for Pixel-Aligned Implicit Models in Single-View Human Reconstruction](https://arxiv.org/abs/2402.19197) | FSS是一种新的用于单视图人体重建中像素对齐隐式模型的采样训练方案，通过主动适应表面的厚度和复杂性，以及利用样本点的法线来改善结果，同时引入网格厚度损失信号来进一步改进训练过程。 |
| [^33] | [Negative Sampling in Knowledge Graph Representation Learning: A Review](https://arxiv.org/abs/2402.19195) | 负采样方法对知识图谱表示学习的成功至关重要，本综述系统地审查了各种负采样方法及其对知识图谱表示学习成功的贡献。 |
| [^34] | [StarCoder 2 and The Stack v2: The Next Generation](https://arxiv.org/abs/2402.19173) | BigCode项目引入了StarCoder2和The Stack v2，在SWH存储库的基础上构建，并通过综合的Code LLM基准测试表明，StarCoder2-3B模型在大多数基准测试上优于其他同等规模的模型，甚至优于StarCoderBase-15B。 |
| [^35] | [Improving Legal Judgement Prediction in Romanian with Long Text Encoders](https://arxiv.org/abs/2402.19170) | 本研究关注通过扩展Transformer模型的序列长度来更好理解法律语料库中的长文档，并在罗马尼亚的4个LJP数据集上进行了广泛实验。 |
| [^36] | [MemoNav: Working Memory Model for Visual Navigation](https://arxiv.org/abs/2402.19161) | MemoNav提出了一种用于图像目标导航的新型记忆模型，通过三种导航记忆类型和遗忘模块提高了导航性能。 |
| [^37] | [Think Fast, Think Slow, Think Critical: Designing an Automated Propaganda Detection Tool](https://arxiv.org/abs/2402.19135) | 设计了一款名为ClarifAI的自动化宣传检测工具，利用大型语言模型检测新闻中的宣传并提供丰富解释，以激发更多批判性阅读，实验证明其有效性，强调了解释对于培养批判性思维的重要性 |
| [^38] | [How to Understand "Support"? An Implicit-enhanced Causal Inference Approach for Weakly-supervised Phrase Grounding](https://arxiv.org/abs/2402.19116) | 提出了一种隐式增强因果推断方法（IECI），用于解决弱监督短语定位任务中的挑战，通过标注高质量数据集进行评估，并相比基线方法展现出明显优势。 |
| [^39] | [CollaFuse: Navigating Limited Resources and Privacy in Collaborative Generative AI](https://arxiv.org/abs/2402.19105) | CollaFuse是一个受拆分学习启发的框架，通过共享服务器训练和推理，在协作使用去噪扩散概率模型时减轻客户端的计算负担，从而提高隐私保护能力。 |
| [^40] | [Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models](https://arxiv.org/abs/2402.19103) | 该论文对大型语言模型中的虚假前提幻觉进行了全面分析，提出了一种名为“FAITH”的方法，用于减轻虚假前提幻觉。 |
| [^41] | [FlatNAS: optimizing Flatness in Neural Architecture Search for Out-of-Distribution Robustness](https://arxiv.org/abs/2402.19102) | FlatNAS是文献中首个系统探索神经网络丢失函数平坦区域的NAS方法，同时优化其在分布数据和分布之外鲁棒性的性能，以及约束其架构参数数量。 |
| [^42] | [Survey in Characterization of Semantic Change](https://arxiv.org/abs/2402.19088) | 语义变化对计算语言学算法的结果质量可能会产生影响，因此重要性日益凸显。 |
| [^43] | [Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment](https://arxiv.org/abs/2402.19085) | 引入了可控偏好优化（CPO）方法，明确为不同目标指定偏好分数，从而引导模型生成符合需求的响应。 |
| [^44] | [Smooth Tchebycheff Scalarization for Multi-Objective Optimization](https://arxiv.org/abs/2402.19078) | 通过光滑 Tchebycheff 标量化方法，本文提出了一种轻量级的方法，用于梯度型多目标优化，具有更低的计算复杂性但仍能找到所有帕累托解。 |
| [^45] | [TimeXer: Empowering Transformers for Time Series Forecasting with Exogenous Variables](https://arxiv.org/abs/2402.19072) | 本文提出了一个新框架TimeXer，利用外部信息增强变压器对内生变量进行预测，弥补了以往多变量或单变量预测中忽视外生信息的不足。 |
| [^46] | [RobWE: Robust Watermark Embedding for Personalized Federated Learning Model Ownership Protection](https://arxiv.org/abs/2402.19054) | 本文提出了一种名为RobWE的强大水印嵌入方案，以保护个性化联邦学习中个性化模型的所有权。 |
| [^47] | [Atmospheric Turbulence Removal with Video Sequence Deep Visual Priors](https://arxiv.org/abs/2402.19041) | 本文提出了一种自监督学习方法，通过像素重排和时间滑动窗口有效地学习时空先验，从而提高任何原始输入序列或预处理序列的质量。 |
| [^48] | [How to Train your Antivirus: RL-based Hardening through the Problem-Space](https://arxiv.org/abs/2402.19027) | 引入了一种基于强化学习的方法，可在问题空间内构建对抗样本，对抗防病毒软件中的恶意软件攻击。 |
| [^49] | [Combination of Weak Learners eXplanations to Improve Random Forest eXplicability Robustness](https://arxiv.org/abs/2402.19025) | 引入了将弱学习者解释组合的方法来改进随机森林的解释性和稳健性，通过对集成方法中解释进行判别平均，取得了成功的实验结果和定量改进。 |
| [^50] | [Generating, Reconstructing, and Representing Discrete and Continuous Data: Generalized Diffusion with Learnable Encoding-Decoding](https://arxiv.org/abs/2402.19009) | 引入了具有可学习编码器-解码器的广义扩散（DiLED），用于在不同数据类型上无缝整合生成新实例、重建输入和学习紧凑表示，扩展了现有模型家族的性能。 |
| [^51] | [GoalNet: Goal Areas Oriented Pedestrian Trajectory Prediction](https://arxiv.org/abs/2402.19002) | 通过利用场景背景和观察到的轨迹信息，该研究提出了一种基于行人目标区域的轨迹预测神经网络，可以将不确定性限制在几个目标区域内。 |
| [^52] | [Negative-Binomial Randomized Gamma Markov Processes for Heterogeneous Overdispersed Count Time Series](https://arxiv.org/abs/2402.18995) | 提出了一种负二项随机Gamma马尔可夫过程，用于改进异质过度离散计数时间序列的预测性能，并加快推断算法的收敛速度。 |
| [^53] | [Theoretically Achieving Continuous Representation of Oriented Bounding Boxes](https://arxiv.org/abs/2402.18975) | 该研究提出了Continuous OBB（COBB）的新型表示方法，可以在定向对象检测中确保边界框回归的连续性。 |
| [^54] | [Towards Out-of-Distribution Detection for breast cancer classification in Point-of-Care Ultrasound Imaging](https://arxiv.org/abs/2402.18960) | 研究在便携式超声图像中对乳腺癌进行分类，探讨了三种不同的OOD检测方法（softmax、能量分数和深度集成），结果表明能量分数方法表现优秀，而集成方法对于所有三个OOD数据集上检测OOD样本效果最好。 |
| [^55] | [Syntactic Ghost: An Imperceptible General-purpose Backdoor Attacks on Pre-trained Language Models](https://arxiv.org/abs/2402.18945) | 论文提出了一种名为Syntactic Ghost的新方法，实现了对预训练语言模型进行无感知和通用的后门植入。 |
| [^56] | [SemEval 2024 -- Task 10: Emotion Discovery and Reasoning its Flip in Conversation (EDiReF)](https://arxiv.org/abs/2402.18944) | SemEval-2024的任务10旨在识别对话中的情绪并找出背后的原因，参与者需自动执行情绪识别和情绪转变推理的子任务，取得了不错的结果。 |
| [^57] | [Navigating Beyond Dropout: An Intriguing Solution Towards Generalizable Image Super Resolution](https://arxiv.org/abs/2402.18929) | 本文探讨了超越Dropout的图像超分辨率新解决方案，提出了一种能够改善模型泛化能力的训练策略，同时避免了Dropout引入的不良副作用。 |
| [^58] | [Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation](https://arxiv.org/abs/2402.18920) | 该研究提出了一个统一的框架，结合光谱和空间域的映射，以预测3D形状之间的点对应和形状插值，相比先前方法，取得更准确、平滑的点对应结果，并且在计算上更高效。 |
| [^59] | [AdaMergeX: Cross-Lingual Transfer with Large Language Models via Adaptive Adapter Merging](https://arxiv.org/abs/2402.18913) | 提出一种新的跨语言转移方法 $\texttt{AdaMergeX}$，利用自适应适配器融合来解决任务能力和语言能力之间的关系。 |
| [^60] | [DIGIC: Domain Generalizable Imitation Learning by Causal Discovery](https://arxiv.org/abs/2402.18910) | 通过在只有单一领域数据的情况下发现因果特征，提出了一种新颖的领域泛化模仿学习框架DIGIC，可以作为非结构化假设下基于跨领域变化方法的补充 |
| [^61] | [Updating Language Models with Unstructured Facts: Towards Practical Knowledge Editing](https://arxiv.org/abs/2402.18909) | 本文提出了一个新的基准，非结构化知识编辑（UKE），旨在使用非结构化文本作为知识更新，避免了繁琐的结构化事实构建，具有更高效和响应性的知识编辑能力。 |
| [^62] | [Facility Location Games with Scaling Effects](https://arxiv.org/abs/2402.18908) | 研究了具有规模效应的设施选址游戏，提供了对于连续比例函数和分段线性比例函数的结果，适用于许多实际情景，同时探讨了近似机制设计设置下代理可能不再单峰偏好的条件与成本近似比率。 |
| [^63] | [On the Convergence of Differentially-Private Fine-tuning: To Linearly Probe or to Fully Fine-tune?](https://arxiv.org/abs/2402.18905) | 本文分析了差分隐私线性探测（LP）和完全微调（FT）的训练动态，探索了从线性探测过渡到完全微调（LP-FT）的顺序微调现象及其对测试损失的影响，提供了关于在超参数化神经网络中差分隐私微调收敛性的理论洞见和隐私预算分配的效用曲线。 |
| [^64] | [Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient Tuning](https://arxiv.org/abs/2402.18865) | 通过模式连接调查了连续微调中不同极小值之间的几何连接，揭示了大型语言模型中的灾难性遗忘问题。 |
| [^65] | [Rethinking Multi-domain Generalization with A General Learning Objective](https://arxiv.org/abs/2402.18853) | 提出了一个通用学习目标范式，通过Y-mapping来放松约束并设计新的学习目标，包括学习域无关的条件特征和最大化后验概率，通过正则化项解决放松约束引起的问题 |
| [^66] | [Applications of 0-1 Neural Networks in Prescription and Prediction](https://arxiv.org/abs/2402.18851) | 引入了处方网络（PNNs）这种新型神经网络，通过混合整数规划训练，结合反事实估计，在医疗决策中展现出优于现有方法的表现，可优化治疗策略，并具有更大的可解释性和更复杂的策略编码能力。 |
| [^67] | [Enhancing Steganographic Text Extraction: Evaluating the Impact of NLP Models on Accuracy and Semantic Coherence](https://arxiv.org/abs/2402.18849) | 通过整合NLP大型模型，本研究提出一种LSB-NLP混合框架，显著提高了隐写文本提取的准确性和鲁棒性，尤其在处理中文字符时表现优异。 |
| [^68] | [The Machine Can't Replace the Human Heart](https://arxiv.org/abs/2402.18826) | 人工智能和虚拟治疗技术的发展带来了更广泛的接触机会，但在实施中需要平衡效率和同理心，以确保技术始终是由医护人员的智慧指导的辅助工具。 |
| [^69] | [How do Large Language Models Handle Multilingualism?](https://arxiv.org/abs/2402.18815) | 大型语言模型展示了处理多语言任务的出色性能，研究发现在不同层次中处理多语言输入的策略，以及处理特定语言时的语言特定神经元存在。 |
| [^70] | [On the Decision-Making Abilities in Role-Playing using Large Language Models](https://arxiv.org/abs/2402.18807) | 本文评估了大型语言模型在角色扮演中的决策能力，并提供了指标和指导以增强其在此任务中的表现。 |
| [^71] | [Brain-inspired and Self-based Artificial Intelligence](https://arxiv.org/abs/2402.18784) | 该论文介绍了一种名为Brain-inspired and Self-based Artificial Intelligence（BriSe AI）的新人工智能范式，通过自我组织的方式协调各种认知功能和学习策略，以构建人类水平的AI模型和机器人应用。 |
| [^72] | [Learning with Language-Guided State Abstractions](https://arxiv.org/abs/2402.18759) | 利用自然语言和语言模型引导的方法，实现自动构建适用于未见任务的状态表示，有助于高维观测空间中泛化策略学习。 |
| [^73] | [Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains](https://arxiv.org/abs/2402.18747) | 细调的机器翻译度量在未知领域中表现出明显的性能下降，相对于依赖表面形式的度量和未经MT质量判断细调的预训练度量。 |
| [^74] | [A revision on Multi-Criteria Decision Making methods for Multi-UAV Mission Planning Support](https://arxiv.org/abs/2402.18743) | 该论文设计了一个决策支持系统，通过排名和过滤系统减少多无人机任务规划中的最优解，并提出了修订的多准则决策方法。 |
| [^75] | [GAIA: Categorical Foundations of Generative AI](https://arxiv.org/abs/2402.18732) | 提出了一种基于范畴论的生成AI架构GAIA，采用层次模型和单纯复合体组织模块，将参数更新建模为单纯集上的提升图表，并采用余代数的形式进行深度学习。 |
| [^76] | [Unveiling Privacy, Memorization, and Input Curvature Links](https://arxiv.org/abs/2402.18726) | 本研究揭示了记忆与输入损失曲率之间的联系，并建立了差分隐私、记忆和输入损失曲率之间的理论联系。 |
| [^77] | [Learning Associative Memories with Gradient Descent](https://arxiv.org/abs/2402.18724) | 该论文研究了一个关联记忆模块的训练动态，通过理论和实验揭示了在过参数化和欠参数化情况下的学习动态和误差特性。 |
| [^78] | [Commonsense Ontology Micropatterns](https://arxiv.org/abs/2402.18715) | 本文提出了一套包含104个本体设计模式的集合，这些模式代表常见的名词，从大型语言模型中的常识知识中策划，组织成一个注释完整的模块化本体设计库，可与MOMo一起使用。 |
| [^79] | [Learning to Compress Prompt in Natural Language Formats](https://arxiv.org/abs/2402.18700) | 该研究旨在通过提出自然语言提示封装（Nano-Capsulator）框架，解决了在自然语言格式中压缩提示的挑战，以提高大型语言模型的可转移性和性能。 |
| [^80] | [Data Interpreter: An LLM Agent For Data Science](https://arxiv.org/abs/2402.18679) | 本研究引入了数据解释器，采用动态规划、工具集成和逻辑错误识别等关键技术，旨在增强数据科学中的问题解决能力。 |
| [^81] | [Fault Tolerant Neural Control Barrier Functions for Robotic Systems under Sensor Faults and Attacks](https://arxiv.org/abs/2402.18677) | 本文研究了面向传感器故障和攻击的机器人系统的安全关键控制综合，提出了一种新的容错神经控制屏障函数（FT-NCBF）。 |
| [^82] | [Trends, Applications, and Challenges in Human Attention Modelling](https://arxiv.org/abs/2402.18673) | 人类注意力建模为深度学习模型的整合提供了重要支持，有助于解决图像处理、视频处理、视觉与语言应用和语言建模等领域的问题。 |
| [^83] | [Large Language Models and Games: A Survey and Roadmap](https://arxiv.org/abs/2402.18659) | 这项研究调查了大型语言模型在游戏领域中的多种应用及其角色，指出了未开发领域和未来发展方向，同时探讨了在游戏领域中大型语言模型的潜力和限制。 |
| [^84] | [Quantifying Human Priors over Social and Navigation Networks](https://arxiv.org/abs/2402.18651) | 本研究利用图的组合结构来量化人类对社交和导航网络的先验知识，揭示了一些一致的特征和特定领域的倾向，为高效建模数据中的潜在偏见提供了方法。 |
| [^85] | [A New Era in LLM Security: Exploring Security Concerns in Real-World LLM-based Systems](https://arxiv.org/abs/2402.18649) | 本文系统分析了LLM系统的安全性，引入信息流对齐约束以控制LLM系统的攻击面 |
| [^86] | [ELA: Exploited Level Augmentation for Offline Learning in Zero-Sum Games](https://arxiv.org/abs/2402.18617) | 该研究提出了一种新颖的方法，利用无监督学习技术估计不同示范者制作的零和博弈离线数据集中每条轨迹的被利用水平，并将其融入离线学习以最大化支配策略的影响力。 |
| [^87] | [JCLEC-MO: a Java suite for solving many-objective optimization engineering problems](https://arxiv.org/abs/2402.18616) | JCLEC-MO 是一个Java框架，旨在解决多目标优化工程问题，为工程师提供了在很少编程工作情况下应用或调整大量多目标算法的能力。 |
| [^88] | [ICE-SEARCH: A Language Model-Driven Feature Selection Approach](https://arxiv.org/abs/2402.18609) | ICE-SEARCH是首个将语言模型与进化算法相结合用于特征选择任务的方法，在医学预测分析应用中取得了State-of-the-Art(SOTA)表现。 |
| [^89] | [Exploring Privacy and Fairness Risks in Sharing Diffusion Models: An Adversarial Perspective](https://arxiv.org/abs/2402.18607) | 本文从对抗性的角度研究了分享扩散模型可能存在的隐私和公平风险，特别是探讨了在一方使用私人数据训练模型后提供给另一方黑盒访问权限的情况。 |
| [^90] | [Impact of network topology on the performance of Decentralized Federated Learning](https://arxiv.org/abs/2402.18606) | 研究探讨了不同类型的网络结构如何影响去中心化联邦学习中的知识传播，并通过三种网络拓扑和六种数据分布方法研究了网络结构与学习性能之间的复杂相互作用。 |
| [^91] | [MMSR: Symbolic Regression is a Multimodal Task](https://arxiv.org/abs/2402.18603) | 符号回归被视为一个多模态任务，研究人员将数据到表达式的映射视为翻译问题，引入大规模预训练模型。 |
| [^92] | [Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina](https://arxiv.org/abs/2402.18600) | 通过视网膜图像与血管状况，人工智能系统用于高通量糖尿病视网膜病变（DR）检测，并具有潜力解决糖尿病患者整体护理挑战。 |
| [^93] | [Meta-Tasks: An alternative view on Meta-Learning Regularization](https://arxiv.org/abs/2402.18599) | 该论文提出了一种新颖的解决方案，通过使用meta-tasks作为元学习正则化的视角，实现了对训练和新颖任务的泛化，避免标记数据稀缺的困扰，并在实验中表现优越，相较于原型网络提高了3.9%的性能。 |
| [^94] | [Note: Evolutionary Game Theory Focus Informational Health: The Cocktail Party Effect Through Werewolfgame under Incomplete Information and ESS Search Method Using Expected Gains of Repeated Dilemmas](https://arxiv.org/abs/2402.18598) | 通过研究非完全信息游戏和多狼人进化博弈框架中的鸡尾酒派对效应，本研究探讨了假新闻传播风险对策略演化和演化稳定策略的影响。 |
| [^95] | [Sustainable Supercomputing for AI: GPU Power Capping at HPC Scale](https://arxiv.org/abs/2402.18593) | 该研究探讨在超级计算中心对GPU进行功率限制对温度和功耗的影响，通过适当的功率限制，实现了降低能耗、改善硬件寿命的目的。 |
| [^96] | [Exploring the Impact of Large Language Models on Recommender Systems: An Extensive Review](https://arxiv.org/abs/2402.18590) | 大型语言模型在推荐系统中展现出卓越的推荐能力和语言理解，重塑了推荐任务的基础。 |
| [^97] | [Verif.ai: Towards an Open-Source Scientific Generative Question-Answering System with Referenced and Verifiable Answers](https://arxiv.org/abs/2402.18589) | Verif.ai是一个具有引用和可验证答案的开源科学生成式问答系统，通过信息检索、生成模型和验证引擎的结合实现对主张的生成和验证。 |
| [^98] | [At the Dawn of Generative AI Era: A Tutorial-cum-Survey on New Frontiers in 6G Wireless Intelligence](https://arxiv.org/abs/2402.18587) | GenAI在无线领域是关键资产，能够处理稀缺、不完整、难以获取和理解的真实世界数据，可以取代或补充判别式人工智能方法，本文汇总了6G和无线智能领域的新前沿。 |
| [^99] | [Streamlining the Selection Phase of Systematic Literature Reviews (SLRs) Using AI-Enabled GPT-4 Assistant API](https://arxiv.org/abs/2402.18582) | 该研究引入了一种基于AI的工具，利用GPT-4助手API简化系统文献评审选择阶段的效率，加速文献评审过程，并对管理和经济领域具有重要意义。 |
| [^100] | [Multi-objective Optimal Roadside Units Deployment in Urban Vehicular Networks](https://arxiv.org/abs/2402.18581) | 城市车辆网络中多目标最优边路单元部署涉及克服多个优化目标之间的冲突，以及解决城市环境中各种障碍带来的部署困难。 |
| [^101] | [Wilcoxon Nonparametric CFAR Scheme for Ship Detection in SAR Image](https://arxiv.org/abs/2402.18579) | 提出并分析了用于SAR图像中船只检测的Wilcoxon非参数CFAR方案，可以在没有已知杂波分布假设的情况下维持目标检测的恒定虚警率 |
| [^102] | [Motion Guided Token Compression for Efficient Masked Video Modeling](https://arxiv.org/abs/2402.18577) | 运动引导的令牌压缩（MGTC）方法旨在通过提供更小但更具代表性的令牌集来减少Transformer模型处理视频时的计算负担。 |
| [^103] | [Improved Forecasting Using a PSO-RDV Framework to Enhance Artificial Neural Network](https://arxiv.org/abs/2402.18576) | 本研究提出利用PSO-RDV框架改进预测方法，通过采用随机下降速度惯性权重（RDV IW）技术提高了粒子群优化（PSO）的收敛性和人工神经网络（ANN）的准确性。 |
| [^104] | [DiffuseRAW: End-to-End Generative RAW Image Processing for Low-Light Images](https://arxiv.org/abs/2402.18575) | 本研究提出了DiffuseRAW，一个端到端生成RAW图像处理方法，重点解决了低光照图像处理中整个图像处理管道学习的问题。 |
| [^105] | [Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards](https://arxiv.org/abs/2402.18571) | 提出了方向偏好对齐（DPA）框架，通过多目标奖励模拟不同偏好配置，以实现用户相关的偏好控制。 |
| [^106] | [Language Models Represent Beliefs of Self and Others](https://arxiv.org/abs/2402.18496) | 通过神经激活线性解析语言模型中代理人观点下的信念状态，揭示了大型语言模型内部表述自我和他人信念，这对社会推理过程至关重要，并在多样社会推理任务中具有潜在的泛化能力。 |
| [^107] | [FinAgent: A Multimodal Foundation Agent for Financial Trading: Tool-Augmented, Diversified, and Generalist](https://arxiv.org/abs/2402.18485) | FinAgent是一个多模态基础代理，通过工具增强用于金融交易，具有独特的双重反射模块，可以处理多样化的数据并快速适应市场动态。 |
| [^108] | [A Cognitive Evaluation Benchmark of Image Reasoning and Description for Large Vision Language Models](https://arxiv.org/abs/2402.18409) | 提出了一个新颖的评估基准，用于评估大型视觉语言模型的认知能力，发现LVLMs与人类之间存在较大的认知能力差距。 |
| [^109] | [Out-of-Domain Generalization in Dynamical Systems Reconstruction](https://arxiv.org/abs/2402.18377) | 该论文提供了一个解决动力系统重构中泛化问题的正式框架, 并阐述了跨领域泛化在DSR中与机器学习其他领域的不同之处 |
| [^110] | [HearHere: Mitigating Echo Chambers in News Consumption through an AI-based Web System](https://arxiv.org/abs/2402.18222) | HearHere是一个基于人工智能的网络系统，旨在帮助用户从不同视角融合信息和观点，以减轻新闻消费中“回声室”现象。 |
| [^111] | [A Quantum Approach to Synthetic Minority Oversampling Technique (SMOTE)](https://arxiv.org/abs/2402.17398) | 使用量子计算技术提出了Quantum-SMOTE方法，可以解决机器学习数据集中的类别不平衡问题，并引入了旋转角度、少数类百分比和分裂因子等超参数，实现了对合成数据生成过程的更好控制。 |
| [^112] | [Active propulsion noise shaping for multi-rotor aircraft localization](https://arxiv.org/abs/2402.17289) | 本文提出通过主动控制和塑造旋翼产生的飞行器推进噪声来有利于定位任务，提出了一种基于自噪声和时间变化旋翼相位调制的神经网络架构，实现了准确和稳健的定位。 |
| [^113] | [MISC: Ultra-low Bitrate Image Semantic Compression Driven by Large Multimodal Model](https://arxiv.org/abs/2402.16749) | 本文提出了一种名为MISC的方法，通过大型多模态模型实现了超低比特率图像语义压缩，在保持与真实数据一致性的同时实现了感知质量的平衡。 |
| [^114] | [GenAINet: Enabling Wireless Collective Intelligence via Knowledge Transfer and Reasoning](https://arxiv.org/abs/2402.16631) | 该论文提出了基于GenAI的GenAINet框架，通过知识传输和推理实现无线集体智能，为6G时代铺平了通向人工通用智能的道路。 |
| [^115] | [Defending LLMs against Jailbreaking Attacks via Backtranslation](https://arxiv.org/abs/2402.16459) | 通过反向翻译来防御LLMs免受越狱攻击，将生成的反向翻译提示用于揭示原始提示的实际意图，提高了模型的安全性。 |
| [^116] | [LLM Inference Unveiled: Survey and Roofline Model Insights](https://arxiv.org/abs/2402.16363) | 本文提出了一个基于Roofline模型的框架，用于系统分析LLM推断技术，帮助识别部署中的瓶颈，并为更有效地部署LLM提供策略。 |
| [^117] | [Human-AI Co-Creation of Worked Examples for Programming Classes](https://arxiv.org/abs/2402.16235) | 人工智能与人类合作创作Java编程课程的示例，以减轻教师逐行解释大量示例的负担 |
| [^118] | [ROS-Causal: A ROS-based Causal Analysis Framework for Human-Robot Interaction Applications](https://arxiv.org/abs/2402.16068) | ROS-Causal是一个基于ROS的框架，用于在人机空间交互中进行数据收集和因果发现，解决了机器人领域中缺乏因果发现方法在ROS生态系统内实现的问题。 |
| [^119] | [GraphEdit: Large Language Models for Graph Structure Learning](https://arxiv.org/abs/2402.15183) | 本研究提出了一种名为GraphEdit的方法，利用大型语言模型（LLMs）学习复杂的图结构化数据中的节点关系，通过在图结构上进行指导调整，增强LLMs的推理能力，从而提高图结构学习的可靠性。 |
| [^120] | [EyeTrans: Merging Human and Machine Attention for Neural Code Summarization](https://arxiv.org/abs/2402.14096) | 引入EyeTrans方法，将人类注意力融入机器注意力，以增强神经代码摘要能力。 |
| [^121] | [E2USD: Efficient-yet-effective Unsupervised State Detection for Multivariate Time Series](https://arxiv.org/abs/2402.14041) | E2USD提出了一种有效的无监督多元时间序列状态检测方法，利用了快速傅里叶变换和双视图嵌入模块进行编码，以及通过对抗学习方法消除假阴性，从而实现了SOTA准确性并显著降低了计算开销。 |
| [^122] | [A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence](https://arxiv.org/abs/2402.12928) | 本文旨在提供对模式分析与机器智能领域文献综述的全面评估，引入大语言模型驱动的文献计量指标，并构建了RiPAMI元数据数据库和主题数据集以获取PAMI综述的统计特征。 |
| [^123] | [Random Projection Layers for Multidimensional Time Sires Forecasting](https://arxiv.org/abs/2402.10487) | 提出了一种全MLP时间序列预测架构RPMixer，通过将随机投影层集成到模型中，增加了块输出之间的多样性，提高了整体性能 |
| [^124] | [Multi-Excitation Projective Simulation with a Many-Body Physics Inspired Inductive Bias](https://arxiv.org/abs/2402.10192) | 该论文引入了多激发投影模拟（mePS），通过在超图上多个粒子的随机游走，解决了投影模拟（PS）无法模拟同时结合多个概念的思维的问题。 |
| [^125] | [Inherent Diverse Redundant Safety Mechanisms for AI-based Software Elements in Automotive Applications](https://arxiv.org/abs/2402.08208) | 本文研究了自动驾驶系统中基于人工智能的软件元素的作用和挑战，探讨了泛化问题以及过度自信的AI模型所带来的风险，并提出了解决方法。 |
| [^126] | [Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation](https://arxiv.org/abs/2402.05699) | 本文提出了一个通过社交场景模拟来自对齐大型语言模型的方法，以减轻其被滥用造成的潜在不良影响。通过一个名为MATRIX的虚拟排练空间，LLM可以在回答查询前考虑社交后果，并通过MATRIX-simulated数据的微调，保持对人类价值的遵从和推理速度的平衡。实验证明，在温和假设下，带有MATRIX的LLM胜过了宪法AI。 |
| [^127] | [Advancing Legal Reasoning: The Integration of AI to Navigate Complexities and Biases in Global Jurisprudence with Semi-Automated Arbitration Processes (SAAPs)](https://arxiv.org/abs/2402.04140) | 本研究通过整合先进的语言模型和人工智能技术，开发了名为SHIRLEY的应用程序，旨在识别法律判决中的偏见和逻辑不一致，并促进自动化、有效和一致的多方论证，以保证法律在不同司法管辖区内的一致应用。 |
| [^128] | [Unveiling Molecular Moieties through Hierarchical Graph Explainability](https://arxiv.org/abs/2402.01744) | 本论文提出了一种使用图神经网络和分层可解释人工智能技术的方法，能够准确预测生物活性并找到与之相关的最重要的成分。 |
| [^129] | [BPDec: Unveiling the Potential of Masked Language Modeling Decoder in BERT pretraining](https://arxiv.org/abs/2401.15861) | 本文揭示了BPDec（BERT预训练解码器）的潜力，强调增强的掩码语言建模解码器设计及研究在BERT预训练中的重要性。 |
| [^130] | [SERNet-Former: Semantic Segmentation by Efficient Residual Network with Attention-Boosting Gates and Attention-Fusion Networks](https://arxiv.org/abs/2401.15741) | 这篇论文提出了一种名为SERNet-Former的高效剩余网络语义分割方法。它通过引入注意力增强门和注意力融合网络来改善语义分割方法的效率，并解决了从全局和局部上融合语义信息的问题。实验结果表明，该方法在挑战性的数据集上取得了良好的性能。 |
| [^131] | [A Study of Acquisition Functions for Medical Imaging Deep Active Learning](https://arxiv.org/abs/2401.15721) | 本研究探讨了在医学图像领域中如何应用主动学习以解决数据稀缺的问题，并通过对比不同的选择标准和获取池大小对模型性能的影响，结果表明不确定性对于黑色素瘤检测任务是有帮助的。 |
| [^132] | [Neutrino Reconstruction in TRIDENT Based on Graph Neural Network](https://arxiv.org/abs/2401.15324) | TRIDENT中微子望远镜采用基于图神经网络的新型重建方法，提高了中微子事件的重建性能。 |
| [^133] | [OK-Robot: What Really Matters in Integrating Open-Knowledge Models for Robotics](https://arxiv.org/abs/2401.12202) | 该研究提出了一种新型基于开放知识的机器人框架OK-Robot，通过整合视觉-语言模型、导航原语和抓取原语，为Pick-and-Drop操作提供了一个集成解决方案，无需任何训练。 |
| [^134] | [Tight Verification of Probabilistic Robustness in Bayesian Neural Networks](https://arxiv.org/abs/2401.11627) | 通过引入两种算法，实现了对Bayesian神经网络概率鲁棒性的严格验证，相比标准神经网络，这些算法更加高效且能够搜索参数空间以找到安全权重。 |
| [^135] | [The NPU-ASLP-LiAuto System Description for Visual Speech Recognition in CNVSRC 2023](https://arxiv.org/abs/2401.06788) | NPU-ASLP-LiAuto团队在2023年CNVSRC中提出了一种视觉语音识别系统，采用端到端架构和多样的数据处理和增强技术，取得了在单说话者和多说话者任务中的优异表现，排名第一。 |
| [^136] | [LLM Interactive Optimization of Open Source Python Libraries -- Case Studies and Generalization](https://arxiv.org/abs/2312.14949) | 本文研究了如何利用当代LLM ChatGPT-4来优化开源Python库，发现在与人类专家互动的情况下，该模型在优化能源和计算效率方面表现出惊人的灵活性。 |
| [^137] | [Safe Reinforcement Learning in a Simulated Robotic Arm](https://arxiv.org/abs/2312.09468) | 本文通过在Panda机器人臂上创建定制环境，扩展了安全强化学习算法的适用性，实现了安全RL算法在物理环境中的测试。 |
| [^138] | [RMS: Redundancy-Minimizing Point Cloud Sampling for Real-Time Pose Estimation](https://arxiv.org/abs/2312.07337) | 提出了一种名为RMS的点云采样方法，通过最小化冗余优化了3D点云的翻译空间可观测性，解决了移动机器人状态估计中潜在的问题。 |
| [^139] | [Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games](https://arxiv.org/abs/2312.00746) | 探索在《巨本砂》这个中国侦探角色扮演游戏中应用LLMs，引入首个专为该游戏设计的数据集，提出多智能体交互框架，通过改进信息收集、凶手识别和逻辑推理等方面的方法来提高AI智能体的游戏表现。 |
| [^140] | [Generalized Large-Scale Data Condensation via Various Backbone and Statistical Matching](https://arxiv.org/abs/2311.17950) | 本文提出了广义匹配的概念，并在此基础上提出了Generalized Various Backbone and Statistical Matching (G-VBSM)方法，可以创建一个具有丰富信息和更好概括能力的压缩数据集。 |
| [^141] | [Appearance-based gaze estimation enhanced with synthetic images using deep neural networks](https://arxiv.org/abs/2311.14175) | 使用深度神经网络，通过合成图像以及基于外观的方法提高了注视估计准确性，无需特殊硬件，眼睛平均误差低于两度 |
| [^142] | [Revisiting the Hypothesis: Do pretrained Transformers Learn In-Context by Gradient Descent?](https://arxiv.org/abs/2310.08540) | 本研究重新审视了预训练的Transformer是否通过梯度下降在上下文中学习的假设，并发现现有研究中的假设存在限制性假设，使其与实际语言模型训练时的语境存在显著差异。同时，通过对真实模型的观察和比较，揭示了ICL和GD在观察演示顺序上的不同敏感性。 |
| [^143] | [Efficient Online Scheduling and Routing for Automated Guided Vehicles In Loop-Based Graphs](https://arxiv.org/abs/2310.02195) | 提出了一种用于自动引导车的在线、无冲突调度和路径规划问题的基于循环图的算法，实验结果表明该算法要么优于其他算法，要么在更短的计算时间内获得同样良好的解决方案 |
| [^144] | [Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic](https://arxiv.org/abs/2309.13339) | 提出了LoT（Logical Thoughts）提示，一个自我改进框架，利用根植于符号逻辑的原则，特别是归谬法，逐步验证和纠正大型语言模型的零射链推理过程。 |
| [^145] | [Differential Diffusion: Giving Each Pixel Its Strength](https://arxiv.org/abs/2306.00950) | 该论文介绍了一种新颖的框架，允许对每个像素或图像区域的改变量进行定制化，为扩散模型增加了粒度控制的能力，进一步扩展了图像编辑的功能。 |
| [^146] | [Transferability-Guided Cross-Domain Cross-Task Transfer Learning](https://arxiv.org/abs/2207.05510) | 提出了两种新的传递性度量标准 F-OTCE 和 JC-OTCE，用于评估源模型对目标任务的受益程度，并为跨领域跨任务迁移学习学习更具传递性的表示。 |
| [^147] | [Self-Initiated Open World Learning for Autonomous AI Agents](https://arxiv.org/abs/2110.11385) | 论文提出了一种自主开放世界学习的方法，使人工智能代理能够在自主、自我激励和自我监督的方式下学习，以应对未知或新颖性环境中的挑战，实现逐步学习和提升知识与能力。 |
| [^148] | [Practical Transferability Estimation for Image Classification Tasks](https://arxiv.org/abs/2106.10479) | 提出了一个实用的转移性度量JC-NCE分数，通过显著改善OTCE中任务差异估计的鲁棒性，消除了对辅助任务的需求。 |
| [^149] | [Finetuning Large Language Models for Vulnerability Detection.](http://arxiv.org/abs/2401.17010) | 本文优化了大规模语言模型用于源代码中的漏洞检测任务，通过微调最先进的代码语言模型WizardCoder并改进其训练过程和策略，实现了对漏洞数据集的分类性能的提升。 |
| [^150] | [AST-2: Single and bi-layered 2-D acoustic soft tactile skin.](http://arxiv.org/abs/2401.14292) | 本文提出了一个创新且成本效益的设计，可以显著提高二维触觉特征估计的准确性。通过利用声学能量和分析幅度调制，可以有效改善触觉特征估计。实际测试证明了该设计的有效性，达到了显著的精度。 |
| [^151] | [WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models.](http://arxiv.org/abs/2401.13919) | WebVoyager是一种创新的基于大型多模态模型的Web代理，能够通过与真实网站交互来端到端地完成用户指令。它提出了一个新的Web代理评估协议，并在实际任务中取得了显著的成功率。 |
| [^152] | [BIBench: Benchmarking Data Analysis Knowledge of Large Language Models.](http://arxiv.org/abs/2401.02982) | BIBench是一个旨在评估大型语言模型（LLMs）在商业智能（BI）数据分析领域中能力的综合基准测试，其通过测试模型在BI基础知识、应用知识和技术技能三个维度上的表现来进行评估。 |
| [^153] | [Score Models for Offline Goal-Conditioned Reinforcement Learning.](http://arxiv.org/abs/2311.02013) | 本文提出了一种新颖的离线目标条件强化学习方法，称为SMORe，它将占有匹配的视角与混合分布匹配相结合，无需学习鉴别器，从而提高了GCRL在离线环境中的表现。 |
| [^154] | [Ask more, know better: Reinforce-Learned Prompt Questions for Decision Making with Large Language Models.](http://arxiv.org/abs/2310.18127) | 本文提出了一种利用大型语言模型的强化学习框架，能够学习提问相关问题并进行推理来指导在实际环境中执行的行为的学习。 |
| [^155] | [PlaceNav: Topological Navigation through Place Recognition.](http://arxiv.org/abs/2309.17260) | PlaceNav是一种通过地点识别进行拓扑导航的方法，将机器人无关部分分为导航特定和通用的计算机视觉组件，通过使用非机器人来源的大规模数据集增加训练数据的可用性，同时通过地点识别来提高导航性能。新模型的性能提高了76%。 |
| [^156] | [ASAP: Automated Sequence Planning for Complex Robotic Assembly with Physical Feasibility.](http://arxiv.org/abs/2309.16909) | ASAP是一个基于物理的计划方法，用于自动生成一般形状组装的物理可行性序列。它通过考虑重力和使用高效的树搜索算法，能够在大型数据集上生成物理实际的组装序列规划，适用于仿真和真实世界机器人设置。 |
| [^157] | [Towards Green AI in Fine-tuning Large Language Models via Adaptive Backpropagation.](http://arxiv.org/abs/2309.13192) | 本文提出了GreenTrainer，一种新的LLM细调技术，通过自适应评估不同张量的反向传播成本和对细调模型准确性的贡献，以实现绿色AI。 |
| [^158] | [Rehearsal: Simulating Conflict to Teach Conflict Resolution.](http://arxiv.org/abs/2309.12309) | 演练是一个系统，通过模拟冲突和提供反馈，教授用户冲突解决的技能。利用演练，用户可以练习处理各种冲突场景，并学习如何运用冲突策略。 |
| [^159] | [CoT-BERT: Enhancing Unsupervised Sentence Representation through Chain-of-Thought.](http://arxiv.org/abs/2309.11143) | CoT-BERT提出了一种通过思维链条增强无监督句子表示的方法，通过两个阶段的处理，引入思维链条的概念进行向量化，以提高模型性能。 |
| [^160] | [Memory Injections: Correcting Multi-Hop Reasoning Failures during Inference in Transformer-Based Language Models.](http://arxiv.org/abs/2309.05605) | 本文提出了一种通过向Transformer-Based语言模型的LLM注意力头部定向注入内存来纠正多跳推理错误的方法，从而提高了模型在处理多跳推理问题时的表现。 |
| [^161] | [Physically Grounded Vision-Language Models for Robotic Manipulation.](http://arxiv.org/abs/2309.02561) | 该论文介绍了一个用于机器人操作的具有物理基础的视觉语言模型，通过在物体上微调模型，提高了模型对物理概念的理解，在语言交互框架中展现了良好的性能。 |
| [^162] | [Application of Zone Method based Machine Learning and Physics-Informed Neural Networks in Reheating Furnaces.](http://arxiv.org/abs/2308.16089) | 本文将经典的Hottel区域方法与机器学习和深度学习相结合，利用生成的数据进行加热炉控制系统的训练，为基础产业的可持续制造和能耗降低目标做出贡献。 |
| [^163] | [ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation.](http://arxiv.org/abs/2308.11131) | 本论文提出了一种名为ReLLa的检索增强大型语言模型框架，用于零样本和小样本推荐任务。通过语义用户行为检索（SUBR）来提取上下文中的有用信息，以改善LLMs的推荐性能。 |
| [^164] | [Normative Conditional Reasoning as a Fragment of HOL.](http://arxiv.org/abs/2308.10686) | 本论文报告了关于正式化条件推理的研究结果，包括Aqvist的条件义务系统E的机械化和伦理论据评估的工具的开发。 |
| [^165] | [web crawler strategies for web pages under robot.txt restriction.](http://arxiv.org/abs/2308.04689) | 本文研究了在robot.txt限制下的网络爬虫策略，讨论了搜索引擎如何确定网页排名以及如何获取数据库中的网页。并介绍了机器人排除协议规则和robot.txt文件的基本格式。 |
| [^166] | [Dimensionless Policies based on the Buckingham $\pi$ Theorem: Is it a good way to Generalize Numerical Results?.](http://arxiv.org/abs/2307.15852) | 通过使用无量纲变量和制度的概念，我们可以将数值生成的最优控制法则推广到量纲相似的系统，这对于推广解决更复杂的高维问题的策略具有潜在意义。 |
| [^167] | ["It Felt Like Having a Second Mind": Investigating Human-AI Co-creativity in Prewriting with Large Language Models.](http://arxiv.org/abs/2307.10811) | 通过三节次的定性研究，探究了人类与大型语言模型在预写过程中的合作模式，并发现了一个三阶段的人机共创过程：构思、启发和实施。在这个合作过程中，人类扮演着主导角色。 |
| [^168] | [Towards Open Federated Learning Platforms: Survey and Vision from Technical and Legal Perspectives.](http://arxiv.org/abs/2307.02140) | 本文探讨了开放联邦学习平台的技术和法律观察，提出了基于查询和基于合同的两种适用于开放联邦学习的合作框架，并对构建开放的FL平台的可行性进行了全面评估。 |
| [^169] | [SelfzCoT: a Self-Prompt Zero-shot CoT from Semantic-level to Code-level for a Better Utilization of LLMs.](http://arxiv.org/abs/2305.11461) | 本文提出了 SelfzCoT 自动自我生成的零样本编码，通过使用LLMs和代码级别的自我提示，在六个零样本算术推理任务中实现了巨大的准确度提升。同时，修改的零样本编码 MzCoT 在推理任务中也取得了显著的表现。 |
| [^170] | [Human Choice Prediction in Non-Cooperative Games: Simulation-based Off-Policy Evaluation.](http://arxiv.org/abs/2305.10361) | 本文研究了语言游戏中的离线策略评估，并提出了一种结合真实和模拟数据的新方法。 |
| [^171] | [Exploring Linguistic Properties of Monolingual BERTs with Typological Classification among Languages.](http://arxiv.org/abs/2305.02215) | 本文研究使用语言分类方法探究单语BERT的语言属性，核心发现为BERT正在复制传统的语言模型。 |
| [^172] | [GDP nowcasting with artificial neural networks: How much does long-term memory matter?.](http://arxiv.org/abs/2304.05805) | 通过比较四种人工神经网络和动态因子模型对美国GDP季度增长的预测表现，研究发现在平衡经济增长期间，更长的输入序列能够实现更准确的预测，但是这种效果会在不到两年的时间内消失。在经济动荡时期，长期记忆的效果变得明显。 |
| [^173] | [Learning to Generalize towards Unseen Domains via a Content-Aware Style Invariant Model for Disease Detection from Chest X-rays.](http://arxiv.org/abs/2302.13991) | 通过内容感知的风格不变模型，我们提出了一种解决深度学习医学图像分析中源领域不匹配挑战的方法。我们采用了风格随机化模块来提取既是风格不变又是内容偏好的领域不变特征，在胸部X射线疾病检测中取得了良好的性能。 |
| [^174] | [Understanding Expertise through Demonstrations: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning.](http://arxiv.org/abs/2302.07457) | 通过提出的双层优化公式，我们提供了一个离线逆向强化学习的最大似然框架，该框架通过最大化奖励来估计专家的保守模型以及专家的环境动态，能够更准确地推断专业技能。 |
| [^175] | [Cooperative Open-ended Learning Framework for Zero-shot Coordination.](http://arxiv.org/abs/2302.04831) | 该论文提出了一个COLE框架，通过构建合作游戏的开放式目标，从图论的角度评估和确定每个策略的协作能力，以有效地解决零样本协调中的合作不兼容性问题。 |
| [^176] | [Does GPT-3 Demonstrate Psychopathy? Evaluating Large Language Models from a Psychological Perspective.](http://arxiv.org/abs/2212.10529) | 本文从心理学角度评估大型语言模型的安全性，发现所有模型在短暗三合一测验上的得分都高于人类平均水平，存在相对较暗的人格模式。尽管经过指标微调，两种模型仍呈现隐含的黑暗人格模式。同时，本文观察到GPT-3和InstructGPT的幸福感得分持续增加。 |

# 详细

[^1]: 冒牌难题：代码语言模型能理解其不正确生成的微妙之处吗？

    The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?

    [https://arxiv.org/abs/2402.19475](https://arxiv.org/abs/2402.19475)

    大多数代码语言模型对生成的冒牌样本的理解较为肤浅，存在三种明显的失败模式：误将冒牌样本分类为正确、在推理冒牌样本的执行行为时表现更差、修复冒牌样本的成功率往往低于生成它们的成功率。

    

    尽管语言模型在代码生成方面变得越来越熟练，它们仍然经常生成不正确的程序。许多这些程序显然是错误的，但其他一些则更为微妙，可以通过更弱的正确性检查，例如能够编译。在这项工作中，我们关注这些伪造的样本：从语言模型中抽样得到的程序，这些程序1）在适度温度下生成的对数概率足够高，2）通过弱正确性检查。总体而言，我们发现大多数模型对伪造品的理解非常肤浅，存在三种明显的失败模式。首先，模型错误地将它们分类为正确。其次，模型在推理伪造品的执行行为方面更差，通常将它们的执行结果预测为如果它们是正确的一样。第三，在要求模型修复伪造品时，模型成功修复伪造品的可能性往往甚至低于抽样生成伪造品的可能性。

    arXiv:2402.19475v1 Announce Type: cross  Abstract: While language models are increasingly more proficient at code generation, they still frequently generate incorrect programs. Many of these programs are obviously wrong, but others are more subtle and pass weaker correctness checks such as being able to compile. In this work, we focus on these counterfeit samples: programs sampled from a language model that 1) have a high enough log-probability to be generated at a moderate temperature and 2) pass weak correctness checks. Overall, we discover that most models have a very shallow understanding of counterfeits through three clear failure modes. First, models mistakenly classify them as correct. Second, models are worse at reasoning about the execution behaviour of counterfeits and often predict their execution results as if they were correct. Third, when asking models to fix counterfeits, the likelihood of a model successfully repairing a counterfeit is often even lower than that of samp
    
[^2]: 严格的LIPS沉没舰船：在Battleship中使用语言信息程序抽样提出问题

    Loose LIPS Sink Ships: Asking Questions in Battleship with Language-Informed Program Sampling

    [https://arxiv.org/abs/2402.19471](https://arxiv.org/abs/2402.19471)

    研究利用大型语言模型提出信息量丰富的问题，在Battleship游戏中展示出与人类表现相匹配的效果，并揭示了贝叶斯模型如何指导问问题行为。

    

    问题结合了我们对语言的掌握和我们对于在有限认知资源情况下推断不确定性的出色能力。人们如何在巨大假设空间中提出信息量丰富的问题？我们研究了这些在基于战舰游戏Battleship的经典提问任务中的权衡。我们的语言信息程序抽样（LIPS）模型利用大型语言模型（LLMs）生成自然语言问题，将其转化为符号程序，并评估其预期信息增益。我们发现，即使在一个令人惊讶的资源预算下，这种简单的蒙特卡罗优化策略也能产生反映人类在各种Battleship棋盘场景中表现的丰富问题。相比之下，仅使用LLM的基线在将问题与棋盘状态联系起来方面存在困难；值得注意的是，GPT-4V并没有比无视觉基线提供改进。我们的结果展示了贝叶斯提问模型如何可能模拟和指导人类的问问题行为。

    arXiv:2402.19471v1 Announce Type: cross  Abstract: Questions combine our mastery of language with our remarkable facility for reasoning about uncertainty. How do people navigate vast hypothesis spaces to pose informative questions given limited cognitive resources? We study these tradeoffs in a classic grounded question-asking task based on the board game Battleship. Our language-informed program sampling (LIPS) model uses large language models (LLMs) to generate natural language questions, translate them into symbolic programs, and evaluate their expected information gain. We find that with a surprisingly modest resource budget, this simple Monte Carlo optimization strategy yields informative questions that mirror human performance across varied Battleship board scenarios. In contrast, LLM-only baselines struggle to ground questions in the board state; notably, GPT-4V provides no improvement over non-visual baselines. Our results illustrate how Bayesian models of question-asking can l
    
[^3]: TV-TREES：用于神经符号视频推理的多模态蕴涵树

    TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning

    [https://arxiv.org/abs/2402.19467](https://arxiv.org/abs/2402.19467)

    TV-TREES是第一个多模态蕴涵树生成器，通过生成视频直接蕴涵的简单前提与高级结论之间的蕴涵关系树，实现了可解释联合模态推理，并在挑战性的TVQA数据集上展示了最先进的零-shot性能。

    

    在处理电视剪辑等复杂的多模态内容进行问答是一项具有挑战性的任务。这部分是因为当前的视频-语言模型依赖于单模态推理，在处理长输入时性能下降，并且缺乏可解释性。我们提出了TV-TREES，这是第一个多模态蕴涵树生成器。TV-TREES作为一种促进可解释联合模态推理的视频理解方法，通过生成视频直接蕴涵的简单前提与高级结论之间的蕴涵关系树。随后，我们引入了多模态蕴涵树生成任务来评估此类方法的推理质量。我们的方法在具有挑战性的TVQA数据集上的实验结果展示了可解释的、具有最先进零-shot性能的完整视频剪辑，展示了与黑盒方法相比的最佳实践。

    arXiv:2402.19467v1 Announce Type: cross  Abstract: It is challenging to perform question-answering over complex, multimodal content such as television clips. This is in part because current video-language models rely on single-modality reasoning, have lowered performance on long inputs, and lack interpetability. We propose TV-TREES, the first multimodal entailment tree generator. TV-TREES serves as an approach to video understanding that promotes interpretable joint-modality reasoning by producing trees of entailment relationships between simple premises directly entailed by the videos and higher-level conclusions. We then introduce the task of multimodal entailment tree generation to evaluate the reasoning quality of such methods. Our method's experimental results on the challenging TVQA dataset demonstrate intepretable, state-of-the-art zero-shot performance on full video clips, illustrating a best of both worlds contrast to black-box methods.
    
[^4]: 追踪可信度动态：重访大型语言模型的预训练期

    Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models

    [https://arxiv.org/abs/2402.19465](https://arxiv.org/abs/2402.19465)

    本文研究探索了大型语言模型在预训练期间的可信度，揭示了早期预训练LLMs已经能够区分各个可信度维度中的概念，提出了从预训练检查点中提取转向向量以增强LLM可信度的方法。

    

    确保大型语言模型（LLMs）的可信度至关重要。大多数研究集中在充分预训练的LLMs上，以更好地理解和提高LLMs的可信度。本文旨在揭示预训练的潜力，首次探索了LLMs在此期间的可信度，专注于五个关键维度：可靠性、隐私、有害度、公平性和稳健性。我们首先对LLMs应用线性探测。高探测准确度表明，\textit{早期预训练的LLMs已经能够区分每个可信度维度中的概念}。因此，为了进一步揭示预训练的潜在可能性，我们从LLM的预训练检查点中提取转向向量，以增强LLM的可信度。最后，受到~\citet{choi2023understanding} 的启发，相互信息估计受线性探测准确度的限制，我们还用相互信息探测LLMs来探究

    arXiv:2402.19465v1 Announce Type: cross  Abstract: Ensuring the trustworthiness of large language models (LLMs) is crucial. Most studies concentrate on fully pre-trained LLMs to better understand and improve LLMs' trustworthiness. In this paper, to reveal the untapped potential of pre-training, we pioneer the exploration of LLMs' trustworthiness during this period, focusing on five key dimensions: reliability, privacy, toxicity, fairness, and robustness. To begin with, we apply linear probing to LLMs. The high probing accuracy suggests that \textit{LLMs in early pre-training can already distinguish concepts in each trustworthiness dimension}. Therefore, to further uncover the hidden possibilities of pre-training, we extract steering vectors from a LLM's pre-training checkpoints to enhance the LLM's trustworthiness. Finally, inspired by~\citet{choi2023understanding} that mutual information estimation is bounded by linear probing accuracy, we also probe LLMs with mutual information to in
    
[^5]: 大语言模型的好奇驱动的红队对抗

    Curiosity-driven Red-teaming for Large Language Models

    [https://arxiv.org/abs/2402.19464](https://arxiv.org/abs/2402.19464)

    研究提出了一种新方法，能够通过训练红队LLM，自动化生成测试案例，以最大化引出目标LLM不良响应，以解决当前RL方法生成测试案例覆盖范围较低的问题。

    

    大型语言模型（LLMs）在许多自然语言应用中具有巨大潜力，但存在生成不正确或有毒内容的风险。为了探究LLM何时生成不需要的内容，当前的范例是招募一个人类测试者\textit{红队}来设计输入提示（即测试案例），这些提示可以引出LLMs的不良反应。然而，仅依赖人类测试者是昂贵且耗时的。近期的研究通过训练一个单独的采用强化学习（RL）的红队LLM自动化红队对抗，生成最大化引出目标LLMs不良响应的测试案例。然而，当前的RL方法只能生成少量有效的测试案例，导致对引出目标LLMs不良响应提示范围的覆盖率较低。为了克服这一限制，我们将增加生成测试案例覆盖范围的问题与.

    arXiv:2402.19464v1 Announce Type: cross  Abstract: Large language models (LLMs) hold great potential for many natural language applications but risk generating incorrect or toxic content. To probe when an LLM generates unwanted content, the current paradigm is to recruit a \textit{red team} of human testers to design input prompts (i.e., test cases) that elicit undesirable responses from LLMs. However, relying solely on human testers is expensive and time-consuming. Recent works automate red teaming by training a separate red team LLM with reinforcement learning (RL) to generate test cases that maximize the chance of eliciting undesirable responses from the target LLM. However, current RL methods are only able to generate a small number of effective test cases resulting in a low coverage of the span of prompts that elicit undesirable responses from the target LLM. To overcome this limitation, we draw a connection between the problem of increasing the coverage of generated test cases an
    
[^6]: $\texttt{COSMIC}$: 相互信息用于任务无关摘要评估

    $\texttt{COSMIC}$: Mutual Information for Task-Agnostic Summarization Evaluation

    [https://arxiv.org/abs/2402.19457](https://arxiv.org/abs/2402.19457)

    $\texttt{COSMIC}$是一种以相互信息为基础的新的摘要评估方法，有效预测下游任务表现，并与人类判断相关性强。竞争性能优于$\texttt{BERTScore}$和$\texttt{ROUGE}$。

    

    评估总结质量存在显著挑战。为此，我们提出了一种新颖的面向任务的评估方法，根据总结器生成对下游任务有用且保留任务结果的摘要能力。我们在理论上建立了这些任务的结果错误概率与源文本和生成摘要之间的相互信息之间的直接关系。我们引入了$\texttt{COSMIC}$作为这一度量的实际实现，展示了它与基于人类判断的度量之间的强相关性，以及它在预测下游任务性能方面的有效性。对已建立的度量如$\texttt{BERTScore}$和$\texttt{ROUGE}$的比较分析凸显了$\texttt{COSMIC}$的竞争性能。

    arXiv:2402.19457v1 Announce Type: cross  Abstract: Assessing the quality of summarizers poses significant challenges. In response, we propose a novel task-oriented evaluation approach that assesses summarizers based on their capacity to produce summaries that are useful for downstream tasks, while preserving task outcomes. We theoretically establish a direct relationship between the resulting error probability of these tasks and the mutual information between source texts and generated summaries. We introduce $\texttt{COSMIC}$ as a practical implementation of this metric, demonstrating its strong correlation with human judgment-based metrics and its effectiveness in predicting downstream task performance. Comparative analyses against established metrics like $\texttt{BERTScore}$ and $\texttt{ROUGE}$ highlight the competitive performance of $\texttt{COSMIC}$.
    
[^7]: 用于鲁棒推理性能评估的功能基准及推理差距

    Functional Benchmarks for Robust Evaluation of Reasoning Performance, and the Reasoning Gap

    [https://arxiv.org/abs/2402.19450](https://arxiv.org/abs/2402.19450)

    提出了一个用于评估语言模型推理能力的框架，通过功能变体的基准进行鲁棒性评估，发现静态基准和功能基准的准确性之间存在推理差距

    

    我们提出了一个框架，利用基准的功能变体对语言模型的推理能力进行鲁棒评估。解决推理测试的模型在静态问题的表现与功能变体快照相比应该没有差异。我们将MATH基准的相关片段重写为其功能变体MATH()，并将其他基准的功能化随之而来。在对当前最先进模型在MATH()快照上进行评估时，我们发现了推理差距--静态准确性与功能准确性之间的百分比差异。我们发现了在表现良好的静态基准上的最先进封闭和开放权重模型之间的推理差距，从58.35%到80.31%，但要注意的是，这些差距可能在使用更复杂提示策略时更小。在这里，我们展示了这样的模型，在真实情况下具有良好的推理性能

    arXiv:2402.19450v1 Announce Type: new  Abstract: We propose a framework for robust evaluation of reasoning capabilities of language models, using functional variants of benchmarks. Models that solve a reasoning test should exhibit no difference in performance over the static version of a problem compared to a snapshot of the functional variant. We have rewritten the relevant fragment of the MATH benchmark into its functional variant MATH(), with functionalization of other benchmarks to follow. When evaluating current state-of-the-art models over snapshots of MATH(), we find a reasoning gap -- the percentage difference between the static and functional accuracies. We find reasoning gaps from 58.35% to 80.31% among the state-of-the-art closed and open weights models that perform well on static benchmarks, with the caveat that the gaps are likely to be smaller with more sophisticated prompting strategies. Here we show that models which anecdotally have good reasoning performance over real
    
[^8]: ArCHer: 通过分层多轮强化学习训练语言模型代理

    ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL

    [https://arxiv.org/abs/2402.19446](https://arxiv.org/abs/2402.19446)

    本文提出了一个用于构建LLMs的多轮强化学习算法的框架

    

    大型语言模型（LLMs）的一个广泛应用案例是目标导向的决策任务（或“代理”任务），在这些任务中，LLM不仅需要为给定提示生成完成，而且需要在多轮交互中做出智能决策以完成任务（例如，与网络交互，使用工具或提供客户支持）。本文提出了一个用于构建LLMs的多轮强化学习算法的框架。

    arXiv:2402.19446v1 Announce Type: cross  Abstract: A broad use case of large language models (LLMs) is in goal-directed decision-making tasks (or "agent" tasks), where an LLM needs to not just generate completions for a given prompt, but rather make intelligent decisions over a multi-turn interaction to accomplish a task (e.g., when interacting with the web, using tools, or providing customer support). Reinforcement learning (RL) provides a general paradigm to address such agent tasks, but current RL methods for LLMs largely focus on optimizing single-turn rewards. By construction, most single-turn RL methods cannot endow LLMs with the ability to intelligently seek information over multiple turns, perform credit assignment, or reason about their past actions -- all of which are critical in agent tasks. This raises the question: how can we design effective and efficient multi-turn RL algorithms for LLMs? In this paper, we develop a framework for building multi-turn RL algorithms for fin
    
[^9]: 探究神经网络声学模型中编码的信息对自动语音识别系统的影响

    Probing the Information Encoded in Neural-based Acoustic Models of Automatic Speech Recognition Systems

    [https://arxiv.org/abs/2402.19443](https://arxiv.org/abs/2402.19443)

    本文提出了一个协议，旨在确定自动语音识别系统中声学模型中编码的信息的位置和影响。

    

    深度学习架构在许多研究领域的性能方面取得了显著进展。自动语音识别（ASR）领域因此受益于这些科学和技术进步，特别是在声学建模方面，现在已经整合了深度神经网络架构。然而，这些性能增益已经转化为关于通过这些黑匣子架构学到和传达的信息的增加复杂性。在许多神经网络可解释性研究之后，我们在本文中提出了一个旨在确定ASR声学模型(AM)中信息位置的协议。为此，我们建议使用中间表示（在这里，不同层级的中间表示）评估AM在确定任务集上的性能。关于性能变化和目标任务，我们可以提出关于哪些信息在不同层级上是增强或扰动的假设。

    arXiv:2402.19443v1 Announce Type: cross  Abstract: Deep learning architectures have made significant progress in terms of performance in many research areas. The automatic speech recognition (ASR) field has thus benefited from these scientific and technological advances, particularly for acoustic modeling, now integrating deep neural network architectures. However, these performance gains have translated into increased complexity regarding the information learned and conveyed through these black-box architectures. Following many researches in neural networks interpretability, we propose in this article a protocol that aims to determine which and where information is located in an ASR acoustic model (AM). To do so, we propose to evaluate AM performance on a determined set of tasks using intermediate representations (here, at different layer levels). Regarding the performance variation and targeted tasks, we can emit hypothesis about which information is enhanced or perturbed at differen
    
[^10]: 多头softmax注意力机制在上下文学习中的训练动态：涌现、收敛和最优性

    Training Dynamics of Multi-Head Softmax Attention for In-Context Learning: Emergence, Convergence, and Optimality

    [https://arxiv.org/abs/2402.19442](https://arxiv.org/abs/2402.19442)

    研究了多头softmax注意力模型在上下文学习中的训练动态，证明了全局收敛性，并发现了“任务分配”现象，梯度流动分为热身、涌现和收敛三个阶段，最终证明了梯度流的最优性。

    

    我们研究了用于上下文学习的多任务线性回归的多头softmax注意力模型的梯度流动力学。我们证明了在适当的初始化选择下，梯度流动的全局收敛性。此外，我们证明了在梯度流动动力学中出现了有趣的“任务分配”现象，每个注意力头都专注于解决多任务模型中的单个任务。具体而言，我们证明了梯度流动动力学可以分为三个阶段——热身阶段，在这个阶段损失减少速度较慢，注意力头逐渐倾向于各自的任务；涌现阶段，在这个阶段，每个头选择一个单独的任务，损失迅速减少；和收敛阶段，在这个阶段，注意力参数收敛到一个极限。此外，我们证明了梯度流在学习极限模型方面的最优性。

    arXiv:2402.19442v1 Announce Type: cross  Abstract: We study the dynamics of gradient flow for training a multi-head softmax attention model for in-context learning of multi-task linear regression. We establish the global convergence of gradient flow under suitable choices of initialization. In addition, we prove that an interesting "task allocation" phenomenon emerges during the gradient flow dynamics, where each attention head focuses on solving a single task of the multi-task model. Specifically, we prove that the gradient flow dynamics can be split into three phases -- a warm-up phase where the loss decreases rather slowly and the attention heads gradually build up their inclination towards individual tasks, an emergence phase where each head selects a single task and the loss rapidly decreases, and a convergence phase where the attention parameters converge to a limit. Furthermore, we prove the optimality of gradient flow in the sense that the limiting model learned by gradient flo
    
[^11]: 差分隐私下的最坏组风险最小化

    Differentially Private Worst-group Risk Minimization

    [https://arxiv.org/abs/2402.19437](https://arxiv.org/abs/2402.19437)

    该论文介绍了在差分隐私下进行最坏组风险最小化的系统研究，提出了一种新算法，通过稳定性分析实现了接近最优的风险控制效果。

    

    我们在$(\epsilon, \delta)$-差分隐私（DP）下对最坏组风险最小化进行了系统研究。目标是找到一个可以在$p$个具有不同分布的子人群（组）中近似最小化最大风险的私有模型，其中每个组的分布通过样本访问。我们首先提出了一种新算法，其实现的最坏组群体风险超出度为$\tilde{O}(\frac{p\sqrt{d}}{K\epsilon} + \sqrt{\frac{p}{K}})$，其中$K$是从所有组中抽取的样本的总数，$d$是问题维度。当每个分布通过大小为$K/p$的固定大小数据集观察时，我们的速率几乎是最优的。我们的结果基于对泛化误差的新稳定性分析。特别是，我们表明$\Delta$-一致性参数稳定性意味着相对于最坏组风险的$\tilde{O}(\Delta + \frac{1}{\sqrt{n}})$泛化误差，其中$n$是个数。

    arXiv:2402.19437v1 Announce Type: cross  Abstract: We initiate a systematic study of worst-group risk minimization under $(\epsilon, \delta)$-differential privacy (DP). The goal is to privately find a model that approximately minimizes the maximal risk across $p$ sub-populations (groups) with different distributions, where each group distribution is accessed via a sample oracle. We first present a new algorithm that achieves excess worst-group population risk of $\tilde{O}(\frac{p\sqrt{d}}{K\epsilon} + \sqrt{\frac{p}{K}})$, where $K$ is the total number of samples drawn from all groups and $d$ is the problem dimension. Our rate is nearly optimal when each distribution is observed via a fixed-size dataset of size $K/p$. Our result is based on a new stability-based analysis for the generalization error. In particular, we show that $\Delta$-uniform argument stability implies $\tilde{O}(\Delta + \frac{1}{\sqrt{n}})$ generalization error w.r.t. the worst-group risk, where $n$ is the number 
    
[^12]: 面向库导向代码生成的组合式API推荐

    Compositional API Recommendation for Library-Oriented Code Generation

    [https://arxiv.org/abs/2402.19431](https://arxiv.org/abs/2402.19431)

    提出了CAPIR（Compositional API Recommendation）来为粗粒度需求推荐API，并采用“分而治之”的策略将任务描述分解为详细的子任务。

    

    大型语言模型在代码生成方面取得了出色的表现，但在生成面向库的代码方面表现仍不尽如人意，尤其是针对LLM训练数据中不存在的库。先前的工作利用API推荐技术帮助LLMs使用库：它检索与用户需求相关的API，然后将它们作为上下文来提示LLMs。然而，开发需求可能是粗粒度的，需要结合多个细粒度API。这种粒度不一致使API推荐成为一项具有挑战性的任务。为了解决这个问题，我们提出了CAPIR（组合式API推荐），它采用“分而治之”的策略为粗粒度要求推荐API。具体而言，CAPIR采用基于LLM的分解器将粗粒度任务描述分解为几个详细的子任务。然后，CAPIR应用基于嵌入的

    arXiv:2402.19431v1 Announce Type: cross  Abstract: Large language models (LLMs) have achieved exceptional performance in code generation. However, the performance remains unsatisfactory in generating library-oriented code, especially for the libraries not present in the training data of LLMs. Previous work utilizes API recommendation technology to help LLMs use libraries: it retrieves APIs related to the user requirements, then leverages them as context to prompt LLMs. However, developmental requirements can be coarse-grained, requiring a combination of multiple fine-grained APIs. This granularity inconsistency makes API recommendation a challenging task. To address this, we propose CAPIR (Compositional API Recommendation), which adopts a "divide-and-conquer" strategy to recommend APIs for coarse-grained requirements. Specifically, CAPIR employs an LLM-based Decomposer to break down a coarse-grained task description into several detailed subtasks. Then, CAPIR applies an embedding-based
    
[^13]: 利用人工智能预测和专家修订的注释在交互式分割中：持续调整还是完全训练？

    Leveraging AI Predicted and Expert Revised Annotations in Interactive Segmentation: Continual Tuning or Full Training?

    [https://arxiv.org/abs/2402.19423](https://arxiv.org/abs/2402.19423)

    交互式分割结合了人工智能算法和人类专业知识，通过反复调整人工智能预测和专家修订的注释来持续改善人工智能，但如何在避免灾难性遗忘的同时提高计算效率仍是关键挑战。

    

    交互式分割是人工智能算法和人类专业知识相结合的一种方法，旨在提高在医疗保健领域中筛选大规模、详细标注数据集的准确性和效率。人类专家会修订人工智能预测的注释，而人工智能则通过学习这些修订的注释来改善其预测。这种交互过程不断增强注释的质量，直到不再需要专家进行重大修订。关键挑战在于如何利用人工智能预测和专家修订的注释来迭代地改善人工智能。存在两个问题：（1）灾难性遗忘的风险--如果仅使用专家修订的类别进行重新训练，人工智能往往会忘记先前学习的类别。 （2）当使用人工智能预测和专家修订的注释重新训练人工智能时存在计算效率低下的问题；此外，考虑到数据集中占主导地位的人工智能预测注释，新注释的贡献可能会被低估。

    arXiv:2402.19423v1 Announce Type: cross  Abstract: Interactive segmentation, an integration of AI algorithms and human expertise, premises to improve the accuracy and efficiency of curating large-scale, detailed-annotated datasets in healthcare. Human experts revise the annotations predicted by AI, and in turn, AI improves its predictions by learning from these revised annotations. This interactive process continues to enhance the quality of annotations until no major revision is needed from experts. The key challenge is how to leverage AI predicted and expert revised annotations to iteratively improve the AI. Two problems arise: (1) The risk of catastrophic forgetting--the AI tends to forget the previously learned classes if it is only retrained using the expert revised classes. (2) Computational inefficiency when retraining the AI using both AI predicted and expert revised annotations; moreover, given the dominant AI predicted annotations in the dataset, the contribution of newly rev
    
[^14]: PEM：基于原型的高效MaskFormer用于图像分割

    PEM: Prototype-based Efficient MaskFormer for Image Segmentation

    [https://arxiv.org/abs/2402.19422](https://arxiv.org/abs/2402.19422)

    PEM提出了基于原型的高效MaskFormer，通过引入原型交叉注意力和多尺度特征金字塔网络，实现了在多个分割任务中的高效运行。

    

    近期基于transformer的架构在图像分割领域展现出令人印象深刻的结果。由于其灵活性，它们在多个分割任务中获得出色的性能，如语义分割和全景分割，在一个统一的框架下。为了填补这一差距，我们提出了基于原型的高效MaskFormer（PEM），这是一个可以在多个分割任务中运行的高效transformer架构。PEM提出了一种新颖的基于原型的交叉注意力，利用视觉特征的冗余性来限制计算并提高效率而不损害性能。此外，PEM引入了一个高效的多尺度特征金字塔网络，能够提取具有高语义的特征。

    arXiv:2402.19422v1 Announce Type: cross  Abstract: Recent transformer-based architectures have shown impressive results in the field of image segmentation. Thanks to their flexibility, they obtain outstanding performance in multiple segmentation tasks, such as semantic and panoptic, under a single unified framework. To achieve such impressive performance, these architectures employ intensive operations and require substantial computational resources, which are often not available, especially on edge devices. To fill this gap, we propose Prototype-based Efficient MaskFormer (PEM), an efficient transformer-based architecture that can operate in multiple segmentation tasks. PEM proposes a novel prototype-based cross-attention which leverages the redundancy of visual features to restrict the computation and improve the efficiency without harming the performance. In addition, PEM introduces an efficient multi-scale feature pyramid network, capable of extracting features that have high seman
    
[^15]: 知识塑造：探索基于聊天的搜索引擎的创造性机制

    Crafting Knowledge: Exploring the Creative Mechanisms of Chat-Based Search Engines

    [https://arxiv.org/abs/2402.19421](https://arxiv.org/abs/2402.19421)

    探索基于聊天的搜索引擎的创造性机制，并解析了大型语言模型如何选择信息源以生成人类一样理解性和创造性的响应。

    

    在数字信息传播领域，搜索引擎扮演着关键的角色，连接信息寻找者和信息提供者。采用大型语言模型和检索增强生成技术的基于聊天的搜索引擎的出现，例如必应聊天，标志着搜索生态系统的进化飞跃。它们展示了元认知能力，能够解释网络信息并具有类似于人类的理解和创造力。然而，大型语言模型的复杂性使得它们的“认知”过程变得不透明，甚至挑战了设计师对其理解。本研究旨在解剖一个基于大型语言模型的基于聊天的搜索引擎（具体为必应聊天）选择信息源以作为其响应的机制。为此，通过与新版必应的互动，编制了一个庞大的数据集，记录了它引用的网站以及传统搜索引擎列出的网站。

    arXiv:2402.19421v1 Announce Type: cross  Abstract: In the domain of digital information dissemination, search engines act as pivotal conduits linking information seekers with providers. The advent of chat-based search engines utilizing Large Language Models (LLMs) and Retrieval Augmented Generation (RAG), exemplified by Bing Chat, marks an evolutionary leap in the search ecosystem. They demonstrate metacognitive abilities in interpreting web information and crafting responses with human-like understanding and creativity. Nonetheless, the intricate nature of LLMs renders their "cognitive" processes opaque, challenging even their designers' understanding. This research aims to dissect the mechanisms through which an LLM-powered chat-based search engine, specifically Bing Chat, selects information sources for its responses. To this end, an extensive dataset has been compiled through engagements with New Bing, documenting the websites it cites alongside those listed by the conventional sea
    
[^16]: 通过多智能体强化学习理解迭代组合拍卖设计

    Understanding Iterative Combinatorial Auction Designs via Multi-Agent Reinforcement Learning

    [https://arxiv.org/abs/2402.19420](https://arxiv.org/abs/2402.19420)

    多智能体强化学习算法可能有助于理解迭代组合拍卖，但其有效部署具有挑战性，需要考虑保持游戏可处理性以及避免各种算法的陷阱。

    

    迭代组合拍卖在高风险场景如频谱拍卖中被广泛使用。然而，这类拍卖难以在理论上理解，使得竞标者很难决定如何行动以及设计者很难优化拍卖规则以确保理想的结果，如高收入或福利。本文探讨了多智能体强化学习算法是否能够用于理解迭代组合拍卖，鉴于这些算法最近在其他领域已经显示出实证成功。我们发现，多智能体强化学习确实可以受益于拍卖分析，但有效部署并不容易。我们首先描述了保持结果游戏可处理的建模决策，同时不牺牲诸如信息不完全或竞标者间不对称等重要特征。我们还讨论了如何避免各种多智能体强化学习算法的陷阱，如何克服挑战以及如何应对各种问题。

    arXiv:2402.19420v1 Announce Type: cross  Abstract: Iterative combinatorial auctions are widely used in high stakes settings such as spectrum auctions. Such auctions can be hard to understand analytically, making it difficult for bidders to determine how to behave and for designers to optimize auction rules to ensure desirable outcomes such as high revenue or welfare. In this paper, we investigate whether multi-agent reinforcement learning (MARL) algorithms can be used to understand iterative combinatorial auctions, given that these algorithms have recently shown empirical success in several other domains. We find that MARL can indeed benefit auction analysis, but that deploying it effectively is nontrivial. We begin by describing modelling decisions that keep the resulting game tractable without sacrificing important features such as imperfect information or asymmetry between bidders. We also discuss how to navigate pitfalls of various MARL algorithms, how to overcome challenges in ver
    
[^17]: 关于语言模型中地理表示的规模定律研究

    On the Scaling Laws of Geographical Representation in Language Models

    [https://arxiv.org/abs/2402.19406](https://arxiv.org/abs/2402.19406)

    地理知识可以在大型语言模型中观察到，随着模型规模增加而一致扩展，但更大的模型无法消除训练数据中的地理偏见。

    

    语言模型长期以来被证明在其隐藏表示中嵌入了地理信息。最近的一项研究将这一结果扩展到了大型语言模型(LLMs)。本文通过观察语言模型规模扩大时地理知识的演化，提出填补现有和最近文献之间的空白。我们展示了即使对于微小模型，地理知识也是可观测的，并且随着模型大小的增加而一致扩展。值得注意的是，我们发现更大的语言模型无法消除训练数据中固有的地理偏见。

    arXiv:2402.19406v1 Announce Type: cross  Abstract: Language models have long been shown to embed geographical information in their hidden representations. This line of work has recently been revisited by extending this result to Large Language Models (LLMs). In this paper, we propose to fill the gap between well-established and recent literature by observing how geographical knowledge evolves when scaling language models. We show that geographical knowledge is observable even for tiny models, and that it scales consistently as we increase the model size. Notably, we observe that larger language models cannot mitigate the geographical bias that is inherent to the training data.
    
[^18]: 一种可扩展且可迁移的时间序列预测框架用于需求预测

    A Scalable and Transferable Time Series Prediction Framework for Demand Forecasting

    [https://arxiv.org/abs/2402.19402](https://arxiv.org/abs/2402.19402)

    提出了一种名为Forchestra的时间序列预测框架，能够准确预测各种物品的未来需求，并且在模型规模和泛化能力上均表现优异。

    

    时间序列预测是许多业务问题中最基本且最普遍的任务之一，包括需求预测和物流优化。然而，传统的时间序列预测方法由于在保持高准确性的同时难以扩展其模型大小，导致其模型规模较小且表现力有限。在本文中，我们提出了Forecasting orchestra (Forchestra)，这是一个简单但功能强大的框架，能够准确预测各种物品的未来需求。我们从经验上证明，模型规模可扩展至高达0.8亿个参数。所提出的方法不仅明显优于现有的预测模型，而且在零样本方式评估下游数据集时也能很好地泛化到未见数据点。最后，我们进行了广泛的定性和定量研究，以分析所提出的模型

    arXiv:2402.19402v1 Announce Type: cross  Abstract: Time series forecasting is one of the most essential and ubiquitous tasks in many business problems, including demand forecasting and logistics optimization. Traditional time series forecasting methods, however, have resulted in small models with limited expressive power because they have difficulty in scaling their model size up while maintaining high accuracy. In this paper, we propose Forecasting orchestra (Forchestra), a simple but powerful framework capable of accurately predicting future demand for a diverse range of items. We empirically demonstrate that the model size is scalable to up to 0.8 billion parameters. The proposed method not only outperforms existing forecasting models with a significant margin, but it could generalize well to unseen data points when evaluated in a zero-shot fashion on downstream datasets. Last but not least, we present extensive qualitative and quantitative studies to analyze how the proposed model 
    
[^19]: 硅谷人群的智慧：LLM集成预测能力达到人群准确率水平

    Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy

    [https://arxiv.org/abs/2402.19379](https://arxiv.org/abs/2402.19379)

    该研究通过将十二个LLMs组成的LLM集成方法与925名人类预测者的群体预测进行比较，发现LLM群体优于简单的无信息基准，并在统计上等效于人类群体。

    

    实践中人类预测准确性依赖于“群体智慧”效应，即通过聚合一群个体预测者的预测可以显著提高对未来事件的预测。过去关于大型语言模型（LLMs）预测能力的研究表明，作为个体预测者的前沿LLMs表现不佳，与人类群体预测比赛的黄金标准相比。我们通过使用一个由十二个LLMs组成的LLM集成方法，扩展了研究。我们将31个二元问题的聚合LLM预测与一个来自三个月预测比赛的925名人类预测者的群体预测进行比较。我们的主要分析表明，LLM群体的表现优于简单的无信息基准，并在统计上等效于人类群体。我们还观察到一种顺从效应，平均模型预测明显高于50%，尽管几乎是平等的。

    arXiv:2402.19379v1 Announce Type: cross  Abstract: Human forecasting accuracy in practice relies on the 'wisdom of the crowd' effect, in which predictions about future events are significantly improved by aggregating across a crowd of individual forecasters. Past work on the forecasting ability of large language models (LLMs) suggests that frontier LLMs, as individual forecasters, underperform compared to the gold standard of a human crowd forecasting tournament aggregate. In Study 1, we expand this research by using an LLM ensemble approach consisting of a crowd of twelve LLMs. We compare the aggregated LLM predictions on 31 binary questions to that of a crowd of 925 human forecasters from a three-month forecasting tournament. Our main analysis shows that the LLM crowd outperforms a simple no-information benchmark and is statistically equivalent to the human crowd. We also observe an acquiescence effect, with mean model predictions being significantly above 50%, despite an almost even
    
[^20]: OpenMedLM：在医学问答中，提示工程可以胜过对开源大型语言模型进行微调

    OpenMedLM: Prompt engineering can out-perform fine-tuning in medical question-answering with open-source large language models

    [https://arxiv.org/abs/2402.19371](https://arxiv.org/abs/2402.19371)

    OpenMedLM 提出了一个提示平台，利用提示工程在医学问答中能够超越对开源大型语言模型进行微调，实现了在医学基准上的 SOTA 性能。

    

    LLMs 在完成一系列专门任务方面变得越来越有能力，并且可以用来扩大对医学知识的公平访问。大多数医学 LLMs 都涉及大量微调，利用专门的医学数据和大量的计算资源，因此成本高昂。许多表现前列的 LLMs 是专有的，他们的访问仅限于少数研究团体。然而，开源（OS）模型代表了医学 LLMs 的一个重要增长领域，由于性能显著提升以及提供卫生保健所需的透明度和合规性的内在能力。我们提出了 OpenMedLM，这是一个提示平台，为医学基准上的 OS LLMs 提供了最先进的性能。我们在四个医学基准（MedQA、MedMCQA、PubMedQA、MMLU 医学子集）上评估了一系列 OS 基础 LLMs（7B-70B）。我们采用了一系列提示策略，包括零s

    arXiv:2402.19371v1 Announce Type: cross  Abstract: LLMs have become increasingly capable at accomplishing a range of specialized-tasks and can be utilized to expand equitable access to medical knowledge. Most medical LLMs have involved extensive fine-tuning, leveraging specialized medical data and significant, thus costly, amounts of computational power. Many of the top performing LLMs are proprietary and their access is limited to very few research groups. However, open-source (OS) models represent a key area of growth for medical LLMs due to significant improvements in performance and an inherent ability to provide the transparency and compliance required in healthcare. We present OpenMedLM, a prompting platform which delivers state-of-the-art (SOTA) performance for OS LLMs on medical benchmarks. We evaluated a range of OS foundation LLMs (7B-70B) on four medical benchmarks (MedQA, MedMCQA, PubMedQA, MMLU medical-subset). We employed a series of prompting strategies, including zero-s
    
[^21]: SoK: 探索大型语言模型在提高数字取证调查效率方面的潜力

    SoK: Exploring the Potential of Large Language Models for Improving Digital Forensic Investigation Efficiency

    [https://arxiv.org/abs/2402.19366](https://arxiv.org/abs/2402.19366)

    将大型语言模型（LLMs）整合到数字取证调查中有望提升调查效率，改善可追溯性，并缓解执法机构面临的技术和司法障碍。

    

    随着需要数字取证分析的案件数量增长，对执法机构及时进行调查的能力产生了担忧。因此，这篇系统化知识论文深入探讨了将大型语言模型（LLMs）整合到数字取证调查中以解决这些挑战的潜力和有效性。对现有的数字取证模型、工具、LLMs、深度学习技术以及在调查中利用LLMs的全面文献综述进行了研究。综述确定了现有数字取证流程中的挑战，并探讨了整合LLMs的障碍和可能性。最终，研究断言，在适当的约束条件下，数字取证中采用LLMs有望提升调查效率，改善可追溯性，并缓解执法机构面临的技术和司法障碍。

    arXiv:2402.19366v1 Announce Type: cross  Abstract: The growing number of cases requiring digital forensic analysis raises concerns about law enforcement's ability to conduct investigations promptly. Consequently, this systemisation of knowledge paper delves into the potential and effectiveness of integrating Large Language Models (LLMs) into digital forensic investigation to address these challenges. A thorough literature review is undertaken, encompassing existing digital forensic models, tools, LLMs, deep learning techniques, and the utilisation of LLMs in investigations. The review identifies current challenges within existing digital forensic processes and explores both the obstacles and possibilities of incorporating LLMs. In conclusion, the study asserts that the adoption of LLMs in digital forensics, with appropriate constraints, holds the potential to enhance investigation efficiency, improve traceability, and alleviate technical and judicial barriers faced by law enforcement e
    
[^22]: 大型语言模型中的水印窃取

    Watermark Stealing in Large Language Models

    [https://arxiv.org/abs/2402.19361](https://arxiv.org/abs/2402.19361)

    LLM水印技术可能存在水印窃取漏洞，我们提出了自动WS算法并展示了攻击者可以在不到50美元的成本下通过欺骗和擦除攻击破解之前认为安全的最先进方案，成功率超过80%。

    

    LLM水印技术作为一种检测AI生成内容的有效方式，受到了关注。然而，我们在这项研究中争辩称当前方案可能已经可以部署，我们认为水印窃取（WS）是这些方案的一个根本性漏洞。我们展示了通过查询带有水印的LLM的API来近似逆向水印，从而实现实用的欺骗攻击，同时大幅增加了之前未被注意到的擦除攻击。我们是第一个提出自动WS算法并将其用于在现实环境中进行欺骗和擦除的全面研究。我们展示了仅需不到50美元的成本，攻击者就能够欺骗并擦除之前被认为是安全的最先进方案，平均成功率超过80%。我们的研究挑战了关于LLM水印技术的常见信念，强调了更加健壮方案的必要性。

    arXiv:2402.19361v1 Announce Type: cross  Abstract: LLM watermarking has attracted attention as a promising way to detect AI-generated content, with some works suggesting that current schemes may already be fit for deployment. In this work we dispute this claim, identifying watermark stealing (WS) as a fundamental vulnerability of these schemes. We show that querying the API of the watermarked LLM to approximately reverse-engineer a watermark enables practical spoofing attacks, as suggested in prior work, but also greatly boosts scrubbing attacks, which was previously unnoticed. We are the first to propose an automated WS algorithm and use it in the first comprehensive study of spoofing and scrubbing in realistic settings. We show that for under $50 an attacker can both spoof and scrub state-of-the-art schemes previously considered safe, with average success rate of over 80%. Our findings challenge common beliefs about LLM watermarking, stressing the need for more robust schemes. We mak
    
[^23]: 深度学习在城市计算中的跨域数据融合：分类、进展和展望

    Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy, Advances, and Outlook

    [https://arxiv.org/abs/2402.19348](https://arxiv.org/abs/2402.19348)

    这项调查系统地回顾了针对城市计算量身定制的深度学习数据融合方法的最新进展，将方法分为四大类别，并对不同数据来源和模态在跨领域数据融合中的作用进行了深入研究。

    

    随着城市的不断蓬勃发展，城市计算作为一门关键学科，通过利用来自各种来源（如地理、交通、社交媒体和环境数据）和模态（如时空、视觉和文本模态）的跨领域数据融合的力量，成为可持续发展的关键。最近，我们正在见证一种利用各种深度学习方法促进智慧城市中的跨领域数据融合的趋势。为此，我们提出了第一份系统地回顾了专门为城市计算量身定制的基于深度学习的数据融合方法的最新进展的调查。具体而言，我们首先深入研究数据视角，以理解每种模态和数据来源的作用。其次，我们将方法论分类为四大主要类别：基于特征、基于对齐、基于对比和基于生成的融合方法。第三，我们进一步对多模态城市应用进行分类。

    arXiv:2402.19348v1 Announce Type: cross  Abstract: As cities continue to burgeon, Urban Computing emerges as a pivotal discipline for sustainable development by harnessing the power of cross-domain data fusion from diverse sources (e.g., geographical, traffic, social media, and environmental data) and modalities (e.g., spatio-temporal, visual, and textual modalities). Recently, we are witnessing a rising trend that utilizes various deep-learning methods to facilitate cross-domain data fusion in smart cities. To this end, we propose the first survey that systematically reviews the latest advancements in deep learning-based data fusion methods tailored for urban computing. Specifically, we first delve into data perspective to comprehend the role of each modality and data source. Secondly, we classify the methodology into four primary categories: feature-based, alignment-based, contrast-based, and generation-based fusion methods. Thirdly, we further categorize multi-modal urban applicatio
    
[^24]: 缝合间隙：将具有定位感知知识的与视觉转换器融合以进行高级图像分类

    Stitching Gaps: Fusing Situated Perceptual Knowledge with Vision Transformers for High-Level Image Classification

    [https://arxiv.org/abs/2402.19339](https://arxiv.org/abs/2402.19339)

    利用文化图像的具有定位感知知识增强高级图像分类的性能和解释性

    

    针对自动化高级图像理解的增长需求，特别是在检测图像中的抽象概念（AC）方面，强调了创新和更可解释方法的必要性。这些方法需要将传统的深度视觉方法与人类用于解释图像的微妙、依赖于环境的知识相协调，以便在复杂的语义层面上解释图像。在这项工作中，我们利用文化图像的具有定位感知知识来增强AC图像分类的性能和可解释性。我们自动从图像中提取感知语义单元，然后对其进行建模和整合到ARTstract知识图（AKG）中。该资源捕获了从14,000多个文化图像中获得的具有定位感知语义的知识。此外，我们通过高级语言框架增强了AKG。我们计算知识图嵌入并尝试相对表示和混合方法

    arXiv:2402.19339v1 Announce Type: cross  Abstract: The increasing demand for automatic high-level image understanding, particularly in detecting abstract concepts (AC) within images, underscores the necessity for innovative and more interpretable approaches. These approaches need to harmonize traditional deep vision methods with the nuanced, context-dependent knowledge humans employ to interpret images at intricate semantic levels. In this work, we leverage situated perceptual knowledge of cultural images to enhance performance and interpretability in AC image classification. We automatically extract perceptual semantic units from images, which we then model and integrate into the ARTstract Knowledge Graph (AKG). This resource captures situated perceptual semantics gleaned from over 14,000 cultural images labeled with ACs. Additionally, we enhance the AKG with high-level linguistic frames. We compute KG embeddings and experiment with relative representations and hybrid approaches that 
    
[^25]: RL-GPT: 将强化学习和代码作为策略进行整合

    RL-GPT: Integrating Reinforcement Learning and Code-as-policy

    [https://arxiv.org/abs/2402.19299](https://arxiv.org/abs/2402.19299)

    RL-GPT 是一个两级分层框架，结合了慢速代理和快速代理，能够高效地整合强化学习和编码任务，在Minecraft游戏中表现出卓越效率。

    

    大型语言模型(LLMs)表现出在利用编码时各种工具方面的熟练程度，但在处理复杂逻辑和精确控制方面存在局限性。在具体任务中，高层规划适宜于直接编码，而低层动作通常需要任务特定的细化，比如强化学习（RL）。为了无缝整合这两种模式，我们引入了一个两级分层框架RL-GPT，包括一个慢速代理和一个快速代理。慢速代理分析适合编码的动作，而快速代理执行编码任务。这种分解有效地使每个代理专注于特定任务，在我们的流水线中证明是非常高效的。我们的方法胜过传统的RL方法和现有的GPT代理，表现出卓越的效率。在Minecraft游戏中，它在RTX3090上在一天内迅速获得了钻石。此外，它在所有设计方面实现了SOTA性能。

    arXiv:2402.19299v1 Announce Type: new  Abstract: Large Language Models (LLMs) have demonstrated proficiency in utilizing various tools by coding, yet they face limitations in handling intricate logic and precise control. In embodied tasks, high-level planning is amenable to direct coding, while low-level actions often necessitate task-specific refinement, such as Reinforcement Learning (RL). To seamlessly integrate both modalities, we introduce a two-level hierarchical framework, RL-GPT, comprising a slow agent and a fast agent. The slow agent analyzes actions suitable for coding, while the fast agent executes coding tasks. This decomposition effectively focuses each agent on specific tasks, proving highly efficient within our pipeline. Our approach outperforms traditional RL methods and existing GPT agents, demonstrating superior efficiency. In the Minecraft game, it rapidly obtains diamonds within a single day on an RTX3090. Additionally, it achieves SOTA performance across all desig
    
[^26]: 未知故障模式下的降解建模与预测分析

    Degradation Modeling and Prognostic Analysis Under Unknown Failure Modes

    [https://arxiv.org/abs/2402.19294](https://arxiv.org/abs/2402.19294)

    提出了一种利用UMAP技术的新型故障模式诊断方法，能够有效应对复杂系统中多种故障模式导致的不同降解路径，提高故障模式的准确识别能力。

    

    操作单元经常在复杂系统中经历各种故障模式，导致不同的降解路径。依赖于在单一故障模式上训练的预测模型可能会导致跨多个故障模式的泛化性能较差。因此，准确识别故障模式至关重要。当前的预测方法要么在降解过程中忽略故障模式，要么假定已知的故障模式标签，而在实践中获得这些标签可能具有挑战性。此外，传感器信号的高维度和复杂关系使得准确识别故障模式具有挑战性。为解决这些问题，我们提出了一种新颖的故障模式诊断方法，利用一种名为UMAP（Uniform Manifold Approximation and Projection）的降维技术将每个单元的降解轨迹投影和可视化到较低维度。然后，利用这些降解轨迹，我们发展了

    arXiv:2402.19294v1 Announce Type: cross  Abstract: Operating units often experience various failure modes in complex systems, leading to distinct degradation paths. Relying on a prognostic model trained on a single failure mode may lead to poor generalization performance across multiple failure modes. Therefore, accurately identifying the failure mode is of critical importance. Current prognostic approaches either ignore failure modes during degradation or assume known failure mode labels, which can be challenging to acquire in practice. Moreover, the high dimensionality and complex relations of sensor signals make it challenging to identify the failure modes accurately. To address these issues, we propose a novel failure mode diagnosis method that leverages a dimension reduction technique called UMAP (Uniform Manifold Approximation and Projection) to project and visualize each unit's degradation trajectory into a lower dimension. Then, using these degradation trajectories, we develop 
    
[^27]: 强大的无监督数据选择指导：捕获领域特定机器翻译中令人困扰的命名实体

    Robust Guidance for Unsupervised Data Selection: Capturing Perplexing Named Entities for Domain-Specific Machine Translation

    [https://arxiv.org/abs/2402.19267](https://arxiv.org/abs/2402.19267)

    提出了一种新颖的无监督数据选择方法，通过捕获领域特定机器翻译中令人困扰的命名实体，实现了高质量翻译效果。

    

    使用大量数据集可以训练多语言机器翻译模型；然而，这些模型通常无法准确翻译专业领域中的句子。获得和翻译领域特定数据虽然成本高昂，但对于高质量翻译是不可避免的。因此，在无监督设置中找到最“有效”的数据成为减少标注成本的实用策略。最近的研究表明，可以通过选择“适当困难的数据”来找到这些有效数据，这意味着数据不应过于困难或过于简单，尤其是在数据量有限的情况下。然而，我们发现建立无监督数据选择标准仍具挑战性，因为“适当困难度”可能因所训练的数据领域而异。我们引入了一种新颖的无监督数据选择方法，‘Capturing Perplexing Named Entities’。

    arXiv:2402.19267v1 Announce Type: cross  Abstract: Employing extensive datasets enables the training of multilingual machine translation models; however, these models often fail to accurately translate sentences within specialized domains. Although obtaining and translating domain-specific data incurs high costs, it is inevitable for high-quality translations. Hence, finding the most 'effective' data with an unsupervised setting becomes a practical strategy for reducing labeling costs. Recent research indicates that this effective data could be found by selecting 'properly difficult data' based on its volume. This means the data should not be excessively challenging or overly simplistic, especially if the amount of data is limited. However, we found that establishing a criterion for unsupervised data selection remains challenging, as the 'proper difficulty' might vary based on the data domain being trained on. We introduce a novel unsupervised data selection method, 'Capturing Perplexi
    
[^28]: 在POMDPs中学习逻辑规范以指导政策：归纳逻辑编程方法

    Learning Logic Specifications for Policy Guidance in POMDPs: an Inductive Logic Programming Approach

    [https://arxiv.org/abs/2402.19265](https://arxiv.org/abs/2402.19265)

    通过归纳逻辑编程方法，从POMDP执行痕迹中学习高质量启发式，以指导政策选择过程。

    

    部分可观察马尔可夫决策过程（POMDPs）是一个强大的不确定性规划框架，允许将状态不确定性建模为信念概率分布。基于蒙特卡洛采样的近似求解器显示出很大成功，以放宽计算需求并执行在线规划。然而，扩展到具有许多动作和长期规划视野的复杂现实域仍然是一个重大挑战，实现良好性能的关键点是通过定制特定应用域的领域相关策略启发来引导行动选择过程。我们提出从由任何求解器生成的POMDP执行痕迹中学习高质量启发式。我们将信念-动作对转换为逻辑语义，并利用数据和时间高效的归纳逻辑编程（ILP）生成可解释的基于信念的策略规范，然后将其用作在线启发式。

    arXiv:2402.19265v1 Announce Type: new  Abstract: Partially Observable Markov Decision Processes (POMDPs) are a powerful framework for planning under uncertainty. They allow to model state uncertainty as a belief probability distribution. Approximate solvers based on Monte Carlo sampling show great success to relax the computational demand and perform online planning. However, scaling to complex realistic domains with many actions and long planning horizons is still a major challenge, and a key point to achieve good performance is guiding the action-selection process with domain-dependent policy heuristics which are tailored for the specific application domain. We propose to learn high-quality heuristics from POMDP traces of executions generated by any solver. We convert the belief-action pairs to a logical semantics, and exploit data- and time-efficient Inductive Logic Programming (ILP) to generate interpretable belief-based policy specifications, which are then used as online heuristi
    
[^29]: 通过对 X 射线上的鲜有标注的强大斑块提取来检测脊柱骨赘

    Spinal Osteophyte Detection via Robust Patch Extraction on minimally annotated X-rays

    [https://arxiv.org/abs/2402.19263](https://arxiv.org/abs/2402.19263)

    通过新颖的 SegPatch 自动斑块提取技术，本研究实现了对脊柱 X 射线中骨赘的自动化检测，准确率达到 84.5\%，比基线方法高出 9.5%，有望帮助临床医生加速骨赘识别过程。

    

    关节炎的发展和进展与骨赘密切相关，骨赘是小而难以察觉的骨增生物。本文提出了针对脊柱 X 射线中自动检测脊柱骨赘的首次努力。提出了一种新颖的自动斑块提取过程，称为 SegPatch，基于深度学习驱动的椎骨分割和掩模轮廓的扩大。最终获得了 84.5\% 的最终斑块分类准确率，比基线瓦片化斑块生成技术高出 9.5\%。这表明，即使有限的注释，SegPatch 也可以为骨赘等微小结构的检测提供优越性能。所提出的方法有潜力帮助临床医生加快手动识别脊柱 X 射线中的骨赘的过程。

    arXiv:2402.19263v1 Announce Type: cross  Abstract: The development and progression of arthritis is strongly associated with osteophytes, which are small and elusive bone growths. This paper presents one of the first efforts towards automated spinal osteophyte detection in spinal X-rays. A novel automated patch extraction process, called SegPatch, has been proposed based on deep learning-driven vertebrae segmentation and the enlargement of mask contours. A final patch classification accuracy of 84.5\% is secured, surpassing a baseline tiling-based patch generation technique by 9.5%. This demonstrates that even with limited annotations, SegPatch can deliver superior performance for detection of tiny structures such as osteophytes. The proposed approach has potential to assist clinicians in expediting the process of manually identifying osteophytes in spinal X-ray.
    
[^30]: 自主驾驶车辆的基于认知的轨迹预测方法

    A Cognitive-Based Trajectory Prediction Approach for Autonomous Driving

    [https://arxiv.org/abs/2402.19251](https://arxiv.org/abs/2402.19251)

    本文引入了人类化轨迹预测（HLTP）模型，通过采用受人类认知过程启发的师生知识蒸馏框架，使自主驾驶车辆更准确地预测周围车辆的运动。

    

    在自主驾驶汽车（AV）技术中，准确预测周围车辆的运动对于确保安全和运行效率至关重要。融入人类决策洞察力使AV能够更有效地预测其他车辆的潜在动作，在动态环境中显著提高预测准确性和响应性。本文介绍了人类化轨迹预测（HLTP）模型，该模型采用了受人类认知过程启发的师生知识蒸馏框架。HLTP模型集成了一个复杂的师生知识蒸馏框架。具有自适应视觉扇区的“教师”模型模拟了人脑的视觉处理，特别是枕叶和颞叶的功能。 “学生”模型关注实时交互和决策制定，并与前额叶和顶叶类似。

    arXiv:2402.19251v1 Announce Type: new  Abstract: In autonomous vehicle (AV) technology, the ability to accurately predict the movements of surrounding vehicles is paramount for ensuring safety and operational efficiency. Incorporating human decision-making insights enables AVs to more effectively anticipate the potential actions of other vehicles, significantly improving prediction accuracy and responsiveness in dynamic environments. This paper introduces the Human-Like Trajectory Prediction (HLTP) model, which adopts a teacher-student knowledge distillation framework inspired by human cognitive processes. The HLTP model incorporates a sophisticated teacher-student knowledge distillation framework. The "teacher" model, equipped with an adaptive visual sector, mimics the visual processing of the human brain, particularly the functions of the occipital and temporal lobes. The "student" model focuses on real-time interaction and decision-making, drawing parallels to prefrontal and parieta
    
[^31]: 基于上下文的可解释的时空图卷积网络用于人体运动预测

    Context-based Interpretable Spatio-Temporal Graph Convolutional Network for Human Motion Forecasting

    [https://arxiv.org/abs/2402.19237](https://arxiv.org/abs/2402.19237)

    提出了基于上下文的可解释的时空图卷积网络（CIST-GCN），用于人体运动预测，在提高模型可解释性的基础上融合了GCN，在多个数据集上实验证明其优于其他方法。

    

    人类运动预测仍然是一个重要但困难的问题，对自动驾驶和安全应用非常重要。在本文中，我们提出了一种基于上下文的可解释的时空图卷积网络（CIST-GCN），作为一种有效的基于GCN的3D人体姿势预测模型，具有特定层，辅助模型可解释性，并提供在分析运动分布和身体行为时可能有用的信息。我们的架构从姿势序列中提取有意义的信息，将位移和加速度聚合到输入模型中，最终预测输出位移。在Human 3.6M、AMASS、3DPW和ExPI数据集上的广泛实验表明，CIST-GCN的性能优于其他方法。

    arXiv:2402.19237v1 Announce Type: cross  Abstract: Human motion prediction is still an open problem extremely important for autonomous driving and safety applications. Due to the complex spatiotemporal relation of motion sequences, this remains a challenging problem not only for movement prediction but also to perform a preliminary interpretation of the joint connections. In this work, we present a Context-based Interpretable Spatio-Temporal Graph Convolutional Network (CIST-GCN), as an efficient 3D human pose forecasting model based on GCNs that encompasses specific layers, aiding model interpretability and providing information that might be useful when analyzing motion distribution and body behavior. Our architecture extracts meaningful information from pose sequences, aggregates displacements and accelerations into the input model, and finally predicts the output displacements. Extensive experiments on Human 3.6M, AMASS, 3DPW, and ExPI datasets demonstrate that CIST-GCN outperforms
    
[^32]: 细结构感知采样: 一种新的用于单视图人体重建中像素对齐隐式模型的采样训练方案

    Fine Structure-Aware Sampling: A New Sampling Training Scheme for Pixel-Aligned Implicit Models in Single-View Human Reconstruction

    [https://arxiv.org/abs/2402.19197](https://arxiv.org/abs/2402.19197)

    FSS是一种新的用于单视图人体重建中像素对齐隐式模型的采样训练方案，通过主动适应表面的厚度和复杂性，以及利用样本点的法线来改善结果，同时引入网格厚度损失信号来进一步改进训练过程。

    

    像素对齐的隐式模型，如PIFu、PIFuHD和ICON，用于单视图着装人体重建。这些模型需要使用采样训练方案进行训练。现有的采样训练方案要么无法捕捉薄表面（如耳朵、手指），要么会导致重建网格中的噪声伪影。为解决这些问题，我们引入了细结构感知采样（FSS），这是一种新的用于单视图人体重建中训练像素对齐隐式模型的采样训练方案。FSS通过主动适应表面的厚度和复杂性来解决前述问题。此外，与现有的采样训练方案不同，FSS显示了如何利用样本点的法线在训练过程中提高结果。最后，为进一步改进训练过程，FSS提出了一个用于像素对齐隐式模型的网格厚度损失信号。这使得在训练过程中利用法线变得计算上可行。

    arXiv:2402.19197v1 Announce Type: cross  Abstract: Pixel-aligned implicit models, such as PIFu, PIFuHD, and ICON, are used for single-view clothed human reconstruction. These models need to be trained using a sampling training scheme. Existing sampling training schemes either fail to capture thin surfaces (e.g. ears, fingers) or cause noisy artefacts in reconstructed meshes. To address these problems, we introduce Fine Structured-Aware Sampling (FSS), a new sampling training scheme to train pixel-aligned implicit models for single-view human reconstruction. FSS resolves the aforementioned problems by proactively adapting to the thickness and complexity of surfaces. In addition, unlike existing sampling training schemes, FSS shows how normals of sample points can be capitalized in the training process to improve results. Lastly, to further improve the training process, FSS proposes a mesh thickness loss signal for pixel-aligned implicit models. It becomes computationally feasible to int
    
[^33]: 知识图谱表示学习中的负采样：一项综述

    Negative Sampling in Knowledge Graph Representation Learning: A Review

    [https://arxiv.org/abs/2402.19195](https://arxiv.org/abs/2402.19195)

    负采样方法对知识图谱表示学习的成功至关重要，本综述系统地审查了各种负采样方法及其对知识图谱表示学习成功的贡献。

    

    知识图谱表示学习（KGRL）或知识图谱嵌入（KGE）在知识构建和信息探索的AI应用中起着关键作用。这些模型旨在将知识图谱中的实体和关系编码为低维向量空间。在KGE模型的训练过程中，使用正负样本对于区分目的至关重要。然而，直接从现有知识图谱中获取负样本面临挑战，强调了有效生成技术的必要性。这些负样本的质量对学习到的嵌入的准确性有着很大影响，使得它们的生成成为KGRL的关键方面。本全面调研论文系统地审查了各种负采样（NS）方法及其对KGRL成功的贡献。通过对现有NS方法的分类，概述了它们各自的优缺点。

    arXiv:2402.19195v1 Announce Type: new  Abstract: Knowledge graph representation learning (KGRL) or knowledge graph embedding (KGE) plays a crucial role in AI applications for knowledge construction and information exploration. These models aim to encode entities and relations present in a knowledge graph into a lower-dimensional vector space. During the training process of KGE models, using positive and negative samples becomes essential for discrimination purposes. However, obtaining negative samples directly from existing knowledge graphs poses a challenge, emphasizing the need for effective generation techniques. The quality of these negative samples greatly impacts the accuracy of the learned embeddings, making their generation a critical aspect of KGRL. This comprehensive survey paper systematically reviews various negative sampling (NS) methods and their contributions to the success of KGRL. Their respective advantages and disadvantages are outlined by categorizing existing NS me
    
[^34]: StarCoder 2和The Stack v2: 下一代

    StarCoder 2 and The Stack v2: The Next Generation

    [https://arxiv.org/abs/2402.19173](https://arxiv.org/abs/2402.19173)

    BigCode项目引入了StarCoder2和The Stack v2，在SWH存储库的基础上构建，并通过综合的Code LLM基准测试表明，StarCoder2-3B模型在大多数基准测试上优于其他同等规模的模型，甚至优于StarCoderBase-15B。

    

    BigCode项目是一个专注于对代码（代码LLMs）进行负责任开发的开放科学合作项目，引入了StarCoder2。我们与Software Heritage（SWH）合作，在他们的源代码存档的数字公共资源之上构建The Stack v2。除了涵盖619种编程语言的SWH存储库外，我们还精心选择其他高质量的数据来源，如GitHub拉取请求、Kaggle笔记本和代码文档。这导致一个训练集，比第一个StarCoder数据集大4倍。我们使用3B、7B和15B参数的StarCoder2模型训练3.3至4.3万亿个标记，并在一套全面的Code LLM基准测试中进行彻底评估。我们发现，我们的小型模型StarCoder2-3B在大多数基准测试上表现优于其他类似规模的Code LLM，并且也优于StarCoderBase-15B。我们的大型模型StarCoder2-15B明显优于其他模型。

    arXiv:2402.19173v1 Announce Type: cross  Abstract: The BigCode project, an open-scientific collaboration focused on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder2. In partnership with Software Heritage (SWH), we build The Stack v2 on top of the digital commons of their source code archive. Alongside the SWH repositories spanning 619 programming languages, we carefully select other high-quality data sources, such as GitHub pull requests, Kaggle notebooks, and code documentation. This results in a training set that is 4x larger than the first StarCoder dataset. We train StarCoder2 models with 3B, 7B, and 15B parameters on 3.3 to 4.3 trillion tokens and thoroughly evaluate them on a comprehensive set of Code LLM benchmarks. We find that our small model, StarCoder2-3B, outperforms other Code LLMs of similar size on most benchmarks, and also outperforms StarCoderBase-15B. Our large model, StarCoder2- 15B, significantly outperforms other mode
    
[^35]: 通过长文本编码器提升罗马尼亚法律判决预测的能力

    Improving Legal Judgement Prediction in Romanian with Long Text Encoders

    [https://arxiv.org/abs/2402.19170](https://arxiv.org/abs/2402.19170)

    本研究关注通过扩展Transformer模型的序列长度来更好理解法律语料库中的长文档，并在罗马尼亚的4个LJP数据集上进行了广泛实验。

    

    最近几年，自然语言处理（NLP）领域取得了惊人的新成果，在各种任务上实现了接近人类水平的性能。法律NLP领域也随之发展迅猛。然而，通用模型并不直接适用于法律领域。由于其专业词汇、长文档等特点，法律NLP通常需要特定模型和方法。本文研究了专业和通用模型用于预测法律案例的最终裁决的方法，即法律判决预测（LJP）任务。我们特别关注如何扩展基于Transformer模型的序列长度，以更好地理解法律语料库中的长文档。在来自两个来源、规模和文档长度显著不同时的4个罗马尼亚LJP数据集上进行了大量实验，结果显示专门模型...

    arXiv:2402.19170v1 Announce Type: cross  Abstract: In recent years,the entire field of Natural Language Processing (NLP) has enjoyed amazing novel results achieving almost human-like performance on a variety of tasks. Legal NLP domain has also been part of this process, as it has seen an impressive growth. However, general-purpose models are not readily applicable for legal domain. Due to the nature of the domain (e.g. specialized vocabulary, long documents) specific models and methods are often needed for Legal NLP. In this work we investigate both specialized and general models for predicting the final ruling of a legal case, task known as Legal Judgment Prediction (LJP). We particularly focus on methods to extend to sequence length of Transformer-based models to better understand the long documents present in legal corpora. Extensive experiments on 4 LJP datasets in Romanian, originating from 2 sources with significantly different sizes and document lengths, show that specialized mo
    
[^36]: MemoNav：视觉导航的工作记忆模型

    MemoNav: Working Memory Model for Visual Navigation

    [https://arxiv.org/abs/2402.19161](https://arxiv.org/abs/2402.19161)

    MemoNav提出了一种用于图像目标导航的新型记忆模型，通过三种导航记忆类型和遗忘模块提高了导航性能。

    

    图像目标导航是一项具有挑战性的任务，需要一个agent在陌生环境中导航到由图像指示的目标。现有方法利用不同的场景记忆存在着效率低下的探索问题，因为它们利用了所有历史观察结果进行决策，而没有考虑与目标相关的部分。为了解决这一限制，我们提出了MemoNav，一种新颖的用于图像目标导航的记忆模型，它利用了类似工作记忆的流程来提高导航性能。具体来说，我们采用了三种导航记忆类型。地图上的节点特征存储在短期记忆（STM）中，因为这些特征是动态更新的。然后，一个遗忘模块保留信息量大的STM部分以提高效率。我们还引入了长期记忆（LTM）来学习全局场景表示，逐渐聚合STM特征。随后，一个图注意力模块对重新...

    arXiv:2402.19161v1 Announce Type: cross  Abstract: Image-goal navigation is a challenging task that requires an agent to navigate to a goal indicated by an image in unfamiliar environments. Existing methods utilizing diverse scene memories suffer from inefficient exploration since they use all historical observations for decision-making without considering the goal-relevant fraction. To address this limitation, we present MemoNav, a novel memory model for image-goal navigation, which utilizes a working memory-inspired pipeline to improve navigation performance. Specifically, we employ three types of navigation memory. The node features on a map are stored in the short-term memory (STM), as these features are dynamically updated. A forgetting module then retains the informative STM fraction to increase efficiency. We also introduce long-term memory (LTM) to learn global scene representations by progressively aggregating STM features. Subsequently, a graph attention module encodes the re
    
[^37]: 快速思考，慢速思考，批判性思考：设计一款自动化疫情检测工具

    Think Fast, Think Slow, Think Critical: Designing an Automated Propaganda Detection Tool

    [https://arxiv.org/abs/2402.19135](https://arxiv.org/abs/2402.19135)

    设计了一款名为ClarifAI的自动化宣传检测工具，利用大型语言模型检测新闻中的宣传并提供丰富解释，以激发更多批判性阅读，实验证明其有效性，强调了解释对于培养批判性思维的重要性

    

    在当今数字化时代，快速的新闻消费和日益对宣传的脆弱性成为特点，培养公民的批判性思维对于稳定的民主至关重要。本文介绍了ClarifAI的设计，这是一款新颖的自动化宣传检测工具，旨在通过激活分析性思维模式，遵循康曼的认知双系统理论，推动读者更加批判性地消费新闻。利用大型语言模型，ClarifAI可以检测新闻文章中的宣传，并提供丰富的背景解释，增强用户的理解和批判性思维。我们的贡献有三个方面：首先，我们提出了ClarifAI的设计；其次，在一项在线实验中，我们证明这一设计有效地鼓励新闻读者更多地进行批判性阅读；第三，我们强调了解释对于培养批判性思维的价值。因此，本研究既提供了一个实用工具，又提供了实验结果支撑。

    arXiv:2402.19135v1 Announce Type: cross  Abstract: In today's digital age, characterized by rapid news consumption and increasing vulnerability to propaganda, fostering citizens' critical thinking is crucial for stable democracies. This paper introduces the design of ClarifAI, a novel automated propaganda detection tool designed to nudge readers towards more critical news consumption by activating the analytical mode of thinking, following Kahneman's dual-system theory of cognition. Using Large Language Models, ClarifAI detects propaganda in news articles and provides context-rich explanations, enhancing users' understanding and critical thinking. Our contribution is threefold: first, we propose the design of ClarifAI; second, in an online experiment, we demonstrate that this design effectively encourages news readers to engage in more critical reading; and third, we emphasize the value of explanations for fostering critical thinking. The study thus offers both a practical tool and use
    
[^38]: 如何理解“支持”？一种隐式增强因果推断方法用于弱监督短语定位

    How to Understand "Support"? An Implicit-enhanced Causal Inference Approach for Weakly-supervised Phrase Grounding

    [https://arxiv.org/abs/2402.19116](https://arxiv.org/abs/2402.19116)

    提出了一种隐式增强因果推断方法（IECI），用于解决弱监督短语定位任务中的挑战，通过标注高质量数据集进行评估，并相比基线方法展现出明显优势。

    

    弱监督短语定位（WPG）是一个新兴的任务，用于推断细粒度短语-区域匹配，仅利用粗粒度的句子-图像对进行训练。然而，现有关于WPG的研究很大程度上忽略了隐式短语-区域匹配关系，这对于评估模型理解深层多模态语义的能力至关重要。为此，本文提出了一种隐式增强因果推断（IECI）方法来解决对建模隐式关系和突出显性关系的挑战。具体而言，该方法分别利用干预和反事实技术来应对上述两个挑战。此外，还标注了一个高质量的隐式增强数据集来评估IECI，详细评估显示IECI相比最先进基线方法有很大优势。特别地，我们观察到了一个有趣的发现。

    arXiv:2402.19116v1 Announce Type: cross  Abstract: Weakly-supervised Phrase Grounding (WPG) is an emerging task of inferring the fine-grained phrase-region matching, while merely leveraging the coarse-grained sentence-image pairs for training. However, existing studies on WPG largely ignore the implicit phrase-region matching relations, which are crucial for evaluating the capability of models in understanding the deep multimodal semantics. To this end, this paper proposes an Implicit-Enhanced Causal Inference (IECI) approach to address the challenges of modeling the implicit relations and highlighting them beyond the explicit. Specifically, this approach leverages both the intervention and counterfactual techniques to tackle the above two challenges respectively. Furthermore, a high-quality implicit-enhanced dataset is annotated to evaluate IECI and detailed evaluations show the great advantages of IECI over the state-of-the-art baselines. Particularly, we observe an interesting findi
    
[^39]: CollaFuse：在协作生成人工智能中导航有限资源和隐私

    CollaFuse: Navigating Limited Resources and Privacy in Collaborative Generative AI

    [https://arxiv.org/abs/2402.19105](https://arxiv.org/abs/2402.19105)

    CollaFuse是一个受拆分学习启发的框架，通过共享服务器训练和推理，在协作使用去噪扩散概率模型时减轻客户端的计算负担，从而提高隐私保护能力。

    

    在生成人工智能领域，扩散式模型在数据需求和隐私方面给社会技术系统带来挑战。传统方法如联邦学习分发学习过程，但会给个别客户带来压力，尤其是在资源受限情况下（例如边缘设备）。为了解决这些挑战，我们引入了CollaFuse，这是一个受拆分学习启发的新框架。为了有效协作使用去噪扩散概率模型，CollaFuse实现了共享服务器训练和推理，减轻了客户端的计算负担。这通过在每个客户端本地保留数据和计算成本低廉的GPU进程，同时将计算成本高昂的进程外包给共享服务器来实现。在医疗环境中展示，CollaFuse通过大大减少对敏感信息共享的需求来增强隐私保护能力。

    arXiv:2402.19105v1 Announce Type: cross  Abstract: In the landscape of generative artificial intelligence, diffusion-based models present challenges for socio-technical systems in data requirements and privacy. Traditional approaches like federated learning distribute the learning process but strain individual clients, especially with constrained resources (e.g., edge devices). In response to these challenges, we introduce CollaFuse, a novel framework inspired by split learning. Tailored for efficient and collaborative use of denoising diffusion probabilistic models, CollaFuse enables shared server training and inference, alleviating client computational burdens. This is achieved by retaining data and computationally inexpensive GPU processes locally at each client while outsourcing the computationally expensive processes to the shared server. Demonstrated in a healthcare context, CollaFuse enhances privacy by highly reducing the need for sensitive information sharing. These capabiliti
    
[^40]: 震撼基础的细语：分析和减轻大型语言模型中的虚假前提幻觉

    Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models

    [https://arxiv.org/abs/2402.19103](https://arxiv.org/abs/2402.19103)

    该论文对大型语言模型中的虚假前提幻觉进行了全面分析，提出了一种名为“FAITH”的方法，用于减轻虚假前提幻觉。

    

    大型语言模型(LLMs)展现出令人印象深刻的能力，但仍然受到幻觉问题的困扰。这个问题的一个重要类型是虚假前提幻觉，我们定义为当LLMs面对虚假前提问题时生成幻觉文本的现象。本文对虚假前提幻觉进行了全面分析，并阐明了其内部工作机制：一小部分注意力头(我们将其指定为虚假前提头)扰乱了知识提取过程，导致虚假前提幻觉的发生。基于我们的分析，我们提出了“FAITH”(虚假前提注意力头约束以减轻幻觉)这一新颖有效的方法来减轻虚假前提幻觉。它在模型推理过程中约束虚假前提注意力头。令人印象深刻的是，

    arXiv:2402.19103v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have shown impressive capabilities but still suffer from the issue of hallucinations. A significant type of this issue is the false premise hallucination, which we define as the phenomenon when LLMs generate hallucinated text when confronted with false premise questions. In this paper, we perform a comprehensive analysis of the false premise hallucination and elucidate its internal working mechanism: a small subset of attention heads (which we designate as false premise heads) disturb the knowledge extraction process, leading to the occurrence of false premise hallucination. Based on our analysis, we propose \textbf{FAITH} (\textbf{F}alse premise \textbf{A}ttention head constra\textbf{I}ining for mi\textbf{T}igating \textbf{H}allucinations), a novel and effective method to mitigate false premise hallucinations. It constrains the false premise attention heads during the model inference process. Impressively,
    
[^41]: FlatNAS：优化神经结构搜索中的平坦性以实现对分布之外的鲁棒性

    FlatNAS: optimizing Flatness in Neural Architecture Search for Out-of-Distribution Robustness

    [https://arxiv.org/abs/2402.19102](https://arxiv.org/abs/2402.19102)

    FlatNAS是文献中首个系统探索神经网络丢失函数平坦区域的NAS方法，同时优化其在分布数据和分布之外鲁棒性的性能，以及约束其架构参数数量。

    

    神经结构搜索（NAS）为神经网络（NN）架构的自动定义铺平了道路，在各种场景中引起越来越多的研究关注并提供解决方案。本研究介绍了一种名为Flat Neural Architecture Search（FlatNAS）的新颖NAS解决方案，它探讨了基于对权重扰动的鲁棒性和具有锐度感知最小化（SAM）的单一NN优化的相互关系。与当前主要集中于OOD算法的研究不同，FlatNAS成功地评估了NN架构对OOD鲁棒性的影响，这是一个关键方面。

    arXiv:2402.19102v1 Announce Type: cross  Abstract: Neural Architecture Search (NAS) paves the way for the automatic definition of Neural Network (NN) architectures, attracting increasing research attention and offering solutions in various scenarios. This study introduces a novel NAS solution, called Flat Neural Architecture Search (FlatNAS), which explores the interplay between a novel figure of merit based on robustness to weight perturbations and single NN optimization with Sharpness-Aware Minimization (SAM). FlatNAS is the first work in the literature to systematically explore flat regions in the loss landscape of NNs in a NAS procedure, while jointly optimizing their performance on in-distribution data, their out-of-distribution (OOD) robustness, and constraining the number of parameters in their architecture. Differently from current studies primarily concentrating on OOD algorithms, FlatNAS successfully evaluates the impact of NN architectures on OOD robustness, a crucial aspect
    
[^42]: 对语义变化特征的调查

    Survey in Characterization of Semantic Change

    [https://arxiv.org/abs/2402.19088](https://arxiv.org/abs/2402.19088)

    语义变化对计算语言学算法的结果质量可能会产生影响，因此重要性日益凸显。

    

    活语言不断发展，以吸纳人类社会的文化变化。这种演变通过新词语（新单词）或单词的语义变化（赋予已有单词新的含义）来体现。理解单词的含义对解释来自不同文化（地方用语或俚语）、领域（例如技术术语）或时代的文本至关重要。在计算机科学中，这些单词与计算语言学算法相关，例如翻译、信息检索、问答等。语义变化可能会影响这些算法的结果质量。因此，了解和形式化表征这些变化是很重要的。研究这种影响是计算语言学界近期引起关注的问题。几种方法提出了检测语义变化的方法，具有较高的精度，但需要更多努力来对其进行表征。

    arXiv:2402.19088v1 Announce Type: cross  Abstract: Live languages continuously evolve to integrate the cultural change of human societies. This evolution manifests through neologisms (new words) or \textbf{semantic changes} of words (new meaning to existing words). Understanding the meaning of words is vital for interpreting texts coming from different cultures (regionalism or slang), domains (e.g., technical terms), or periods. In computer science, these words are relevant to computational linguistics algorithms such as translation, information retrieval, question answering, etc. Semantic changes can potentially impact the quality of the outcomes of these algorithms. Therefore, it is important to understand and characterize these changes formally. The study of this impact is a recent problem that has attracted the attention of the computational linguistics community. Several approaches propose methods to detect semantic changes with good precision, but more effort is needed to charact
    
[^43]: 可控偏好优化：朝着可控多目标对齐方向发展

    Controllable Preference Optimization: Toward Controllable Multi-Objective Alignment

    [https://arxiv.org/abs/2402.19085](https://arxiv.org/abs/2402.19085)

    引入了可控偏好优化（CPO）方法，明确为不同目标指定偏好分数，从而引导模型生成符合需求的响应。

    

    人工智能中的对齐工作旨在追求模型响应与人类偏好和价值的一致性。本文引入了可控偏好优化（CPO）方法，明确为不同目标指定偏好分数，从而引导模型生成符合需求的响应。实验分析表明，经过对齐的模型可以提供符合各种偏好的响应。

    arXiv:2402.19085v1 Announce Type: new  Abstract: Alignment in artificial intelligence pursues the consistency between model responses and human preferences as well as values. In practice, the multifaceted nature of human preferences inadvertently introduces what is known as the "alignment tax" -a compromise where enhancements in alignment within one objective (e.g.,harmlessness) can diminish performance in others (e.g.,helpfulness). However, existing alignment techniques are mostly unidirectional, leading to suboptimal trade-offs and poor flexibility over various objectives. To navigate this challenge, we argue the prominence of grounding LLMs with evident preferences. We introduce controllable preference optimization (CPO), which explicitly specifies preference scores for different objectives, thereby guiding the model to generate responses that meet the requirements. Our experimental analysis reveals that the aligned models can provide responses that match various preferences among t
    
[^44]: 光滑 Tchebycheff 标量化用于多目标优化

    Smooth Tchebycheff Scalarization for Multi-Objective Optimization

    [https://arxiv.org/abs/2402.19078](https://arxiv.org/abs/2402.19078)

    通过光滑 Tchebycheff 标量化方法，本文提出了一种轻量级的方法，用于梯度型多目标优化，具有更低的计算复杂性但仍能找到所有帕累托解。

    

    多目标优化问题在许多现实世界应用中都能找到，在这些问题中，目标经常相互冲突，不能通过单个解进行优化。在过去的几十年中，已经提出了许多方法来找到帕累托解，这些解代表了对于给定问题的不同最佳权衡。然而，这些现有方法可能具有较高的计算复杂性，或者可能不能具备解决一般可微分多目标优化问题的良好理论属性。在本项工作中，通过利用光滑优化技术，我们提出了一种新颖且轻量的光滑 Tchebycheff 标量化方法，用于基于梯度的多目标优化。它对于找到所有帕累托解具有良好的理论属性，同时相对于其他方法具有显着较低的计算复杂性。在各种实验结果上

    arXiv:2402.19078v1 Announce Type: cross  Abstract: Multi-objective optimization problems can be found in many real-world applications, where the objectives often conflict each other and cannot be optimized by a single solution. In the past few decades, numerous methods have been proposed to find Pareto solutions that represent different optimal trade-offs among the objectives for a given problem. However, these existing methods could have high computational complexity or may not have good theoretical properties for solving a general differentiable multi-objective optimization problem. In this work, by leveraging the smooth optimization technique, we propose a novel and lightweight smooth Tchebycheff scalarization approach for gradient-based multi-objective optimization. It has good theoretical properties for finding all Pareto solutions with valid trade-off preferences, while enjoying significantly lower computational complexity compared to other methods. Experimental results on variou
    
[^45]: TimeXer：利用外生变量增强变压器进行时间序列预测

    TimeXer: Empowering Transformers for Time Series Forecasting with Exogenous Variables

    [https://arxiv.org/abs/2402.19072](https://arxiv.org/abs/2402.19072)

    本文提出了一个新框架TimeXer，利用外部信息增强变压器对内生变量进行预测，弥补了以往多变量或单变量预测中忽视外生信息的不足。

    

    最近的研究表明，在时间序列预测方面取得了显著的性能。然而，由于现实应用的部分观测性质，仅专注于感兴趣的目标，也就是所谓的内生变量，通常是不足以保证准确预测的。值得注意的是，系统通常记录为多个变量，其中外生序列可以为内生变量提供有价值的外部信息。因此，与先前确立的多变量或单变量预测不同，它们要么将所有变量等同对待，要么忽视外生信息，本文关注的是一种实际设置，即具有外生变量的时间序列预测。我们提出了一个新颖的框架TimeXer，利用外部信息增强内生变量的预测。通过巧妙设计的嵌入层，TimeXer使传统的Transformer架构具有重新

    arXiv:2402.19072v1 Announce Type: cross  Abstract: Recent studies have demonstrated remarkable performance in time series forecasting. However, due to the partially-observed nature of real-world applications, solely focusing on the target of interest, so-called endogenous variables, is usually insufficient to guarantee accurate forecasting. Notably, a system is often recorded into multiple variables, where the exogenous series can provide valuable external information for endogenous variables. Thus, unlike prior well-established multivariate or univariate forecasting that either treats all the variables equally or overlooks exogenous information, this paper focuses on a practical setting, which is time series forecasting with exogenous variables. We propose a novel framework, TimeXer, to utilize external information to enhance the forecasting of endogenous variables. With a deftly designed embedding layer, TimeXer empowers the canonical Transformer architecture with the ability to reco
    
[^46]: RobWE: Robust Watermark Embedding for Personalized Federated Learning Model Ownership Protection

    RobWE: Robust Watermark Embedding for Personalized Federated Learning Model Ownership Protection

    [https://arxiv.org/abs/2402.19054](https://arxiv.org/abs/2402.19054)

    本文提出了一种名为RobWE的强大水印嵌入方案，以保护个性化联邦学习中个性化模型的所有权。

    

    在联邦学习（FL）中，将水印嵌入到模型中已被广泛应用以保护模型所有权。然而，现有方法对于保护个性化联邦学习（PFL）中客户获取的个性化模型所有权是不足的。本文提出了一种名为RobWE的强大水印嵌入方案，以保护PFL中个性化模型的所有权。我们首先将个性化模型的水印嵌入分为两部分：头部层嵌入和表示层嵌入。

    arXiv:2402.19054v1 Announce Type: cross  Abstract: Embedding watermarks into models has been widely used to protect model ownership in federated learning (FL). However, existing methods are inadequate for protecting the ownership of personalized models acquired by clients in personalized FL (PFL). This is due to the aggregation of the global model in PFL, resulting in conflicts over clients' private watermarks. Moreover, malicious clients may tamper with embedded watermarks to facilitate model leakage and evade accountability. This paper presents a robust watermark embedding scheme, named RobWE, to protect the ownership of personalized models in PFL. We first decouple the watermark embedding of personalized models into two parts: head layer embedding and representation layer embedding. The head layer belongs to clients' private part without participating in model aggregation, while the representation layer is the shared part for aggregation. For representation layer embedding, we emplo
    
[^47]: 具有视频序列深度视觉先验的大气湍流去除

    Atmospheric Turbulence Removal with Video Sequence Deep Visual Priors

    [https://arxiv.org/abs/2402.19041](https://arxiv.org/abs/2402.19041)

    本文提出了一种自监督学习方法，通过像素重排和时间滑动窗口有效地学习时空先验，从而提高任何原始输入序列或预处理序列的质量。

    

    大气湍流对视觉图像的解释和感知造成挑战，由于其失真效果。本文提出了一种自监督学习方法，不需要地面真值，通过像素重排和时间滑动窗口有效地学习时空先验，从而提高任何原始输入序列或预处理序列的质量。

    arXiv:2402.19041v1 Announce Type: cross  Abstract: Atmospheric turbulence poses a challenge for the interpretation and visual perception of visual imagery due to its distortion effects. Model-based approaches have been used to address this, but such methods often suffer from artefacts associated with moving content. Conversely, deep learning based methods are dependent on large and diverse datasets that may not effectively represent any specific content. In this paper, we address these problems with a self-supervised learning method that does not require ground truth. The proposed method is not dependent on any dataset outside of the single data sequence being processed but is also able to improve the quality of any input raw sequences or pre-processed sequences. Specifically, our method is based on an accelerated Deep Image Prior (DIP), but integrates temporal information using pixel shuffling and a temporal sliding window. This efficiently learns spatio-temporal priors leading to a s
    
[^48]: 如何训练您的防病毒软件：基于强化学习的问题空间加固

    How to Train your Antivirus: RL-based Hardening through the Problem-Space

    [https://arxiv.org/abs/2402.19027](https://arxiv.org/abs/2402.19027)

    引入了一种基于强化学习的方法，可在问题空间内构建对抗样本，对抗防病毒软件中的恶意软件攻击。

    

    本文探讨了一种特定的机器学习架构，用于加固一家著名商业防病毒公司流程中的机器学习防御技术，以对抗恶意软件。我们引入了一种新颖的强化学习方法，用于构建对抗样本，这是对抗逃避攻击的模型训练的重要组成部分。

    arXiv:2402.19027v1 Announce Type: cross  Abstract: ML-based malware detection on dynamic analysis reports is vulnerable to both evasion and spurious correlations. In this work, we investigate a specific ML architecture employed in the pipeline of a widely-known commercial antivirus company, with the goal to harden it against adversarial malware. Adversarial training, the sole defensive technique that can confer empirical robustness, is not applicable out of the box in this domain, for the principal reason that gradient-based perturbations rarely map back to feasible problem-space programs. We introduce a novel Reinforcement Learning approach for constructing adversarial examples, a constituent part of adversarially training a model against evasion. Our approach comes with multiple advantages. It performs modifications that are feasible in the problem-space, and only those; thus it circumvents the inverse mapping problem. It also makes possible to provide theoretical guarantees on the r
    
[^49]: 将弱学习者解释的组合用于改进随机森林的解释性和稳健性

    Combination of Weak Learners eXplanations to Improve Random Forest eXplicability Robustness

    [https://arxiv.org/abs/2402.19025](https://arxiv.org/abs/2402.19025)

    引入了将弱学习者解释组合的方法来改进随机森林的解释性和稳健性，通过对集成方法中解释进行判别平均，取得了成功的实验结果和定量改进。

    

    XAI中的稳健性概念指的是观察到的关于学习模型预测解释在对导致该预测的输入变化时的变化。直觉上，如果要解释的输入略微变化，以至于不会太大程度改变模型的预测，那么我们期望对于该新输入的解释也不会有太大变化。我们认为，通过对弱学习者解释进行判别平均的组合可以提高集成方法中解释的稳健性。该方法已经在后续SHAP方法和随机森林集成中得到实施和测试，并取得了成功的结果。所获得的改进已经通过定量方式进行了测量，并提供了一些关于集成方法中解释性稳健性的见解。

    arXiv:2402.19025v1 Announce Type: cross  Abstract: The notion of robustness in XAI refers to the observed variations in the explanation of the prediction of a learned model with respect to changes in the input leading to that prediction. Intuitively, if the input being explained is modified slightly subtly enough so as to not change the prediction of the model too much, then we would expect that the explanation provided for that new input does not change much either. We argue that a combination through discriminative averaging of ensembles weak learners explanations can improve the robustness of explanations in ensemble methods.This approach has been implemented and tested with post-hoc SHAP method and Random Forest ensemble with successful results. The improvements obtained have been measured quantitatively and some insights into the explicability robustness in ensemble methods are presented.
    
[^50]: 生成、重建和表示离散和连续数据：具有可学习编码-解码器的广义扩散

    Generating, Reconstructing, and Representing Discrete and Continuous Data: Generalized Diffusion with Learnable Encoding-Decoding

    [https://arxiv.org/abs/2402.19009](https://arxiv.org/abs/2402.19009)

    引入了具有可学习编码器-解码器的广义扩散（DiLED），用于在不同数据类型上无缝整合生成新实例、重建输入和学习紧凑表示，扩展了现有模型家族的性能。

    

    深度生成模型的广泛应用基于三项核心能力--生成新实例、重建输入和学习紧凑表示--跨不同数据类型，如离散文本/蛋白序列和连续图像。现有的模型家族，如变分自动编码器（VAEs）、生成对抗网络（GANs）、自回归模型和扩散模型，通常在特定能力和数据类型上表现优异，但在其他方面表现不佳。我们引入了具有可学习编码器-解码器的广义扩散（DiLED），它无缝地集成了广泛适用性和增强性能的核心能力。DiLED通过引入参数化编码-解码来将标准扩散中的高斯加噪-去噪进行了泛化。关键是，DiLED与成熟的扩散模型目标和训练方法兼容，可有效学习编码-解码器。

    arXiv:2402.19009v1 Announce Type: cross  Abstract: The vast applications of deep generative models are anchored in three core capabilities -- generating new instances, reconstructing inputs, and learning compact representations -- across various data types, such as discrete text/protein sequences and continuous images. Existing model families, like Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), autoregressive models, and diffusion models, generally excel in specific capabilities and data types but fall short in others. We introduce generalized diffusion with learnable encoder-decoder (DiLED), that seamlessly integrates the core capabilities for broad applicability and enhanced performance. DiLED generalizes the Gaussian noising-denoising in standard diffusion by introducing parameterized encoding-decoding. Crucially, DiLED is compatible with the well-established diffusion model objective and training recipes, allowing effective learning of the encoder-decoder 
    
[^51]: GoalNet: 面向目标区域的行人轨迹预测

    GoalNet: Goal Areas Oriented Pedestrian Trajectory Prediction

    [https://arxiv.org/abs/2402.19002](https://arxiv.org/abs/2402.19002)

    通过利用场景背景和观察到的轨迹信息，该研究提出了一种基于行人目标区域的轨迹预测神经网络，可以将不确定性限制在几个目标区域内。

    

    预测道路上行人未来的轨迹是自动驾驶中的重要任务。行人轨迹预测受场景路径、行人意图和决策影响，这是一个多模态问题。最近的研究大多使用过去的轨迹来预测各种潜在的未来轨迹分布，这并未考虑场景背景和行人目标。我们提出了一种不直接预测未来轨迹的方法，即首先使用场景背景和观察到的轨迹来预测目标点，然后重复使用目标点来预测未来轨迹。通过利用场景背景和观察到的轨迹信息，我们可以将不确定性限制在几个目标区域内，这些区域代表了行人的“目标”。在本文中，我们提出了GoalNet，一种基于行人目标区域的新轨迹预测神经网络。

    arXiv:2402.19002v1 Announce Type: cross  Abstract: Predicting the future trajectories of pedestrians on the road is an important task for autonomous driving. The pedestrian trajectory prediction is affected by scene paths, pedestrian's intentions and decision-making, which is a multi-modal problem. Most recent studies use past trajectories to predict a variety of potential future trajectory distributions, which do not account for the scene context and pedestrian targets. Instead of predicting the future trajectory directly, we propose to use scene context and observed trajectory to predict the goal points first, and then reuse the goal points to predict the future trajectories. By leveraging the information from scene context and observed trajectory, the uncertainty can be limited to a few target areas, which represent the "goals" of the pedestrians. In this paper, we propose GoalNet, a new trajectory prediction neural network based on the goal areas of a pedestrian. Our network can pr
    
[^52]: 用于异质过度离散计数时间序列的负二项随机Gamma马尔可夫过程

    Negative-Binomial Randomized Gamma Markov Processes for Heterogeneous Overdispersed Count Time Series

    [https://arxiv.org/abs/2402.18995](https://arxiv.org/abs/2402.18995)

    提出了一种负二项随机Gamma马尔可夫过程，用于改进异质过度离散计数时间序列的预测性能，并加快推断算法的收敛速度。

    

    对于计数值时间序列的建模自然地在物理和社会领域中引起越来越多的关注。Poisson gamma动态系统（PGDSs）是新开发的方法，可以很好地捕捉计数序列背后表现出的明显的潜在转换结构和突发动态。特别是，与基于经典线性动态系统（LDS）的方法相比，PGDSs在数据填充和预测方面表现出优越性能。尽管具有这些优势，PGDS不能捕捉基础动态过程的异质过度离散行为。为了减轻这一缺陷，我们提出了一种负二项随机Gamma马尔可夫过程，它不仅显著改善了所提出的动态系统的预测性能，还促进了推断算法的快速收敛。此外，我们开发了估计因子结构和图结构的方法。

    arXiv:2402.18995v1 Announce Type: cross  Abstract: Modeling count-valued time series has been receiving increasing attention since count time series naturally arise in physical and social domains. Poisson gamma dynamical systems (PGDSs) are newly-developed methods, which can well capture the expressive latent transition structure and bursty dynamics behind count sequences. In particular, PGDSs demonstrate superior performance in terms of data imputation and prediction, compared with canonical linear dynamical system (LDS) based methods. Despite these advantages, PGDS cannot capture the heterogeneous overdispersed behaviours of the underlying dynamic processes. To mitigate this defect, we propose a negative-binomial-randomized gamma Markov process, which not only significantly improves the predictive performance of the proposed dynamical system, but also facilitates the fast convergence of the inference algorithm. Moreover, we develop methods to estimate both factor-structured and graph
    
[^53]: 理论上实现定向包围框的连续表示

    Theoretically Achieving Continuous Representation of Oriented Bounding Boxes

    [https://arxiv.org/abs/2402.18975](https://arxiv.org/abs/2402.18975)

    该研究提出了Continuous OBB（COBB）的新型表示方法，可以在定向对象检测中确保边界框回归的连续性。

    

    本文致力于解决有关定向包围框（OBB）表示中的不连续性问题，提出了一种名为Continuous OBB（COBB）的新型表示方法，可以确保边界框回归的连续性，可以轻松地集成到现有的检测器中，例如Faster-RCNN。

    arXiv:2402.18975v1 Announce Type: cross  Abstract: Considerable efforts have been devoted to Oriented Object Detection (OOD). However, one lasting issue regarding the discontinuity in Oriented Bounding Box (OBB) representation remains unresolved, which is an inherent bottleneck for extant OOD methods. This paper endeavors to completely solve this issue in a theoretically guaranteed manner and puts an end to the ad-hoc efforts in this direction. Prior studies typically can only address one of the two cases of discontinuity: rotation and aspect ratio, and often inadvertently introduce decoding discontinuity, e.g. Decoding Incompleteness (DI) and Decoding Ambiguity (DA) as discussed in literature. Specifically, we propose a novel representation method called Continuous OBB (COBB), which can be readily integrated into existing detectors e.g. Faster-RCNN as a plugin. It can theoretically ensure continuity in bounding box regression which to our best knowledge, has not been achieved in liter
    
[^54]: 在便携式超声成像中实现乳腺癌分类的越区检测

    Towards Out-of-Distribution Detection for breast cancer classification in Point-of-Care Ultrasound Imaging

    [https://arxiv.org/abs/2402.18960](https://arxiv.org/abs/2402.18960)

    研究在便携式超声图像中对乳腺癌进行分类，探讨了三种不同的OOD检测方法（softmax、能量分数和深度集成），结果表明能量分数方法表现优秀，而集成方法对于所有三个OOD数据集上检测OOD样本效果最好。

    

    深度学习在医学应用中展现了巨大潜力。在这样的关键领域中，拥有可以判断何时无法提供可靠评估的可信算法至关重要。检测越区（OOD）样本是构建安全分类器的关键步骤。本研究跟随之前的一项研究，展示了在便携式超声图像中可以对乳腺癌进行分类，探讨了使用三种不同方法进行OOD检测：softmax、能量分数和深度集成。所有方法都在三个不同的OOD数据集上进行了测试。结果显示能量分数方法优于softmax方法，在两个数据集上表现良好。集成方法最为稳健，在所有三个OOD数据集上最擅长检测OOD样本。

    arXiv:2402.18960v1 Announce Type: cross  Abstract: Deep learning has shown to have great potential in medical applications. In critical domains as such, it is of high interest to have trustworthy algorithms which are able to tell when reliable assessments cannot be guaranteed. Detecting out-of-distribution (OOD) samples is a crucial step towards building a safe classifier. Following a previous study, showing that it is possible to classify breast cancer in point-of-care ultrasound images, this study investigates OOD detection using three different methods: softmax, energy score and deep ensembles. All methods are tested on three different OOD data sets. The results show that the energy score method outperforms the softmax method, performing well on two of the data sets. The ensemble method is the most robust, performing the best at detecting OOD samples for all three OOD data sets.
    
[^55]: Syntactic Ghost：一种对预训练语言模型进行的无感知通用后门攻击

    Syntactic Ghost: An Imperceptible General-purpose Backdoor Attacks on Pre-trained Language Models

    [https://arxiv.org/abs/2402.18945](https://arxiv.org/abs/2402.18945)

    论文提出了一种名为Syntactic Ghost的新方法，实现了对预训练语言模型进行无感知和通用的后门植入。

    

    预训练语言模型（PLMs）被发现容易受到后门攻击，可以将漏洞转移到各种下游任务中。然而，现有的PLM后门攻击采用明显的触发器，在手动对准的情况下进行，因此在效果、隐匿性和通用性方面无法同时满足期望目标。本文提出了一种新方法，实现了不可见和通用的后门植入，称为Syntactic Ghost（简称为synGhost）。具体来说，该方法敌意地使用具有不同预定义句法结构的毒害样本作为隐蔽触发器，然后将后门植入到预训练表示空间，而不会破坏原始知识。毒害样本的输出表示在特征空间中尽可能均匀地分布，通过对比学习形成广泛的后门。此外，在亮

    arXiv:2402.18945v1 Announce Type: cross  Abstract: Pre-trained language models (PLMs) have been found susceptible to backdoor attacks, which can transfer vulnerabilities to various downstream tasks. However, existing PLM backdoors are conducted with explicit triggers under the manually aligned, thus failing to satisfy expectation goals simultaneously in terms of effectiveness, stealthiness, and universality. In this paper, we propose a novel approach to achieve invisible and general backdoor implantation, called \textbf{Syntactic Ghost} (synGhost for short). Specifically, the method hostilely manipulates poisoned samples with different predefined syntactic structures as stealth triggers and then implants the backdoor to pre-trained representation space without disturbing the primitive knowledge. The output representations of poisoned samples are distributed as uniformly as possible in the feature space via contrastive learning, forming a wide range of backdoors. Additionally, in light 
    
[^56]: SemEval 2024 -- 任务10：情绪发现及对话中情绪转变的推理（EDiReF）

    SemEval 2024 -- Task 10: Emotion Discovery and Reasoning its Flip in Conversation (EDiReF)

    [https://arxiv.org/abs/2402.18944](https://arxiv.org/abs/2402.18944)

    SemEval-2024的任务10旨在识别对话中的情绪并找出背后的原因，参与者需自动执行情绪识别和情绪转变推理的子任务，取得了不错的结果。

    

    我们提出了SemEval-2024任务10，这是一个关于在单语种英语和印地语-英语混合对话中识别情绪并找出情绪转变背后原因的共享任务。该任务包括三个不同的子任务 - 用于混合对话中情绪识别、混合对话中情绪转变推理、以及英文对话中情绪转变推理。参与系统被要求自动执行一个或多个这些子任务。这些任务的数据集包括手动注释的对话，重点放在情绪和触发情绪转变的原因上（任务数据可在https://github.com/LCS2-IIITD/EDiReF-SemEval2024.git获取）。总共有84个参与者参与了这个任务，其中最擅长的系统在各个子任务上获得了0.70、0.79和0.76的F1分数。本文总结了来自24个团队的结果和发现以及他们系统的描述。

    arXiv:2402.18944v1 Announce Type: cross  Abstract: We present SemEval-2024 Task 10, a shared task centred on identifying emotions and finding the rationale behind their flips within monolingual English and Hindi-English code-mixed dialogues. This task comprises three distinct subtasks - emotion recognition in conversation for code-mixed dialogues, emotion flip reasoning for code-mixed dialogues, and emotion flip reasoning for English dialogues. Participating systems were tasked to automatically execute one or more of these subtasks. The datasets for these tasks comprise manually annotated conversations focusing on emotions and triggers for emotion shifts (The task data is available at https://github.com/LCS2-IIITD/EDiReF-SemEval2024.git). A total of 84 participants engaged in this task, with the most adept systems attaining F1-scores of 0.70, 0.79, and 0.76 for the respective subtasks. This paper summarises the results and findings from 24 teams alongside their system descriptions.
    
[^57]: 超越Dropout：通向可推广图像超分辨率的引人注目解决方案

    Navigating Beyond Dropout: An Intriguing Solution Towards Generalizable Image Super Resolution

    [https://arxiv.org/abs/2402.18929](https://arxiv.org/abs/2402.18929)

    本文探讨了超越Dropout的图像超分辨率新解决方案，提出了一种能够改善模型泛化能力的训练策略，同时避免了Dropout引入的不良副作用。

    

    深度学习近年来在单图像超分辨率（SISR）性能方面取得了巨大进展。尽管大多数现有工作假设了简单且固定的降级模型（比如双三次下采样），但盲SR的研究旨在通过未知降级改进模型的泛化能力。最近，Kong等人首次探讨了使用Dropout进行盲SR更合适的训练策略。尽管这种方法通过减少过拟合确实带来了实质性的泛化改进，但我们认为Dropout同时引入了不良副作用，损害了模型忠实重构细节的能力。我们在论文中展示了理论和实验分析，此外，我们还提出了另一种简单有效的训练策略，通过简单调节模型的一阶和二阶来增强模型的泛化能力。

    arXiv:2402.18929v1 Announce Type: cross  Abstract: Deep learning has led to a dramatic leap on Single Image Super-Resolution (SISR) performances in recent years. %Despite the substantial advancement% While most existing work assumes a simple and fixed degradation model (e.g., bicubic downsampling), the research of Blind SR seeks to improve model generalization ability with unknown degradation. Recently, Kong et al pioneer the investigation of a more suitable training strategy for Blind SR using Dropout. Although such method indeed brings substantial generalization improvements via mitigating overfitting, we argue that Dropout simultaneously introduces undesirable side-effect that compromises model's capacity to faithfully reconstruct fine details. We show both the theoretical and experimental analyses in our paper, and furthermore, we present another easy yet effective training strategy that enhances the generalization ability of the model by simply modulating its first and second-orde
    
[^58]: 光谱遇见空间: 和谐3D形状匹配和插值

    Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation

    [https://arxiv.org/abs/2402.18920](https://arxiv.org/abs/2402.18920)

    该研究提出了一个统一的框架，结合光谱和空间域的映射，以预测3D形状之间的点对应和形状插值，相比先前方法，取得更准确、平滑的点对应结果，并且在计算上更高效。

    

    虽然3D形状匹配和插值密切相关，但它们经常被分开研究并依次应用于关联不同的3D形状，从而导致性能不佳。在这项工作中，我们提出了一个统一的框架，用于预测3D形状之间的点对应和形状插值。为此，我们将深度功能映射框架与经典表面变形模型结合起来，以在光谱和空间域中映射形状。一方面，通过整合空间映射，我们的方法相对于先前用于形状匹配的功能映射方法获得更精确和平滑的点对应。另一方面，通过引入光谱映射，我们的方法摆脱了通常使用但计算昂贵的仅对近等距形状变形有效的测地距离约束。

    arXiv:2402.18920v1 Announce Type: cross  Abstract: Although 3D shape matching and interpolation are highly interrelated, they are often studied separately and applied sequentially to relate different 3D shapes, thus resulting in sub-optimal performance. In this work we present a unified framework to predict both point-wise correspondences and shape interpolation between 3D shapes. To this end, we combine the deep functional map framework with classical surface deformation models to map shapes in both spectral and spatial domains. On the one hand, by incorporating spatial maps, our method obtains more accurate and smooth point-wise correspondences compared to previous functional map methods for shape matching. On the other hand, by introducing spectral maps, our method gets rid of commonly used but computationally expensive geodesic distance constraints that are only valid for near-isometric shape deformations. Furthermore, we propose a novel test-time adaptation scheme to capture both 
    
[^59]: AdaMergeX: 跨语言大语言模型的自适应适配器融合

    AdaMergeX: Cross-Lingual Transfer with Large Language Models via Adaptive Adapter Merging

    [https://arxiv.org/abs/2402.18913](https://arxiv.org/abs/2402.18913)

    提出一种新的跨语言转移方法 $\texttt{AdaMergeX}$，利用自适应适配器融合来解决任务能力和语言能力之间的关系。

    

    作为在特定语言的目标任务上进行直接微调的有效替代方案，跨语言转移通过在源语言上微调目标任务并在目标语言中选择另一个任务来解耦了有限训练数据的挑战，从而分离了“任务能力”和“语言能力”。然而，它们未能充分将任务能力与源语言或者语言能力与选择的任务完全分开。本文承认任务能力和语言能力之间的相互依赖，并将我们的注意力集中在目标语言和源语言之间的任务差距上。由于该差距消除了任务的影响，我们假定它在各任务间保持一致。基于这一假设，我们提出了一种名为 $\texttt{AdaMergeX}$ 的新的跨语言转移方法，利用自适应适配器融合。

    arXiv:2402.18913v1 Announce Type: cross  Abstract: As an effective alternative to the direct fine-tuning on target tasks in specific languages, cross-lingual transfer addresses the challenges of limited training data by decoupling ''task ability'' and ''language ability'' by fine-tuning on the target task in the source language and another selected task in the target language, respectively. However, they fail to fully separate the task ability from the source language or the language ability from the chosen task. In this paper, we acknowledge the mutual reliance between task ability and language ability and direct our attention toward the gap between the target language and the source language on tasks. As the gap removes the impact of tasks, we assume that it remains consistent across tasks. Based on this assumption, we propose a new cross-lingual transfer method called $\texttt{AdaMergeX}$ that utilizes adaptive adapter merging. By introducing a reference task, we can determine that 
    
[^60]: DIGIC: 通过因果发现实现领域泛化的模仿学习

    DIGIC: Domain Generalizable Imitation Learning by Causal Discovery

    [https://arxiv.org/abs/2402.18910](https://arxiv.org/abs/2402.18910)

    通过在只有单一领域数据的情况下发现因果特征，提出了一种新颖的领域泛化模仿学习框架DIGIC，可以作为非结构化假设下基于跨领域变化方法的补充

    

    因果性已经与机器学习相结合，产生了针对领域泛化的强大表示。大多数现有的这类方法需要来自多个领域的大量数据，通过跨领域变化来识别引起特征，这可能昂贵甚至不可行，在某些情况下可能会导致误识别。在这项工作中，我们通过利用演示数据分布来发现领域泛化策略的因果特征，提出了一种不同的尝试。我们设计了一个名为DIGIC的新领域泛化模仿学习框架，通过因果发现从演示数据分布中找出专家动作的直接原因来识别因果特征。我们的框架可以在只有单一领域数据的情况下实现领域泛化的模仿学习，并在基础因果模型的非结构化假设下作为基于跨领域变化方法的补充。

    arXiv:2402.18910v1 Announce Type: cross  Abstract: Causality has been combined with machine learning to produce robust representations for domain generalization. Most existing methods of this type require massive data from multiple domains to identify causal features by cross-domain variations, which can be expensive or even infeasible and may lead to misidentification in some cases. In this work, we make a different attempt by leveraging the demonstration data distribution to discover the causal features for a domain generalizable policy. We design a novel framework, called DIGIC, to identify the causal features by finding the direct cause of the expert action from the demonstration data distribution via causal discovery. Our framework can achieve domain generalizable imitation learning with only single-domain data and serve as a complement for cross-domain variation-based methods under non-structural assumptions on the underlying causal models. Our empirical study in various control 
    
[^61]: 使用非结构化事实更新语言模型：迈向实用知识编辑

    Updating Language Models with Unstructured Facts: Towards Practical Knowledge Editing

    [https://arxiv.org/abs/2402.18909](https://arxiv.org/abs/2402.18909)

    本文提出了一个新的基准，非结构化知识编辑（UKE），旨在使用非结构化文本作为知识更新，避免了繁琐的结构化事实构建，具有更高效和响应性的知识编辑能力。

    

    知识编辑旨在将知识更新注入语言模型中，使其保持正确性和最新性。然而，当前的评估策略明显不切实际：它们仅使用精心策划的结构化事实（主题、关系和对象的三元组）进行更新，而现实世界的知识更新通常出现在新闻文章等非结构化文本中。本文提出了一个新的基准，非结构化知识编辑（UKE）。它使用非结构化文本直接评估编辑性能，称为非结构化事实。因此，UKE避免了繁琐的结构化事实构建，实现了高效和响应迅速的知识编辑，成为一个更实用的基准。我们在新构建的数据集上进行了大量实验，并展示了UKE对最先进的知识编辑方法构成了重大挑战，导致它们的关键性能下降。

    arXiv:2402.18909v1 Announce Type: cross  Abstract: Knowledge editing aims to inject knowledge updates into language models to keep them correct and up-to-date. However, its current evaluation strategies are notably impractical: they solely update with well-curated structured facts (triplets with subjects, relations, and objects), whereas real-world knowledge updates commonly emerge in unstructured texts like news articles. In this paper, we propose a new benchmark, Unstructured Knowledge Editing (UKE). It evaluates editing performance directly using unstructured texts as knowledge updates, termed unstructured facts. Hence UKE avoids the laborious construction of structured facts and enables efficient and responsive knowledge editing, becoming a more practical benchmark. We conduct extensive experiments on newly built datasets and demonstrate that UKE poses a significant challenge to state-of-the-art knowledge editing methods, resulting in their critical performance declines. We further
    
[^62]: 具有规模效应的设施选址游戏

    Facility Location Games with Scaling Effects

    [https://arxiv.org/abs/2402.18908](https://arxiv.org/abs/2402.18908)

    研究了具有规模效应的设施选址游戏，提供了对于连续比例函数和分段线性比例函数的结果，适用于许多实际情景，同时探讨了近似机制设计设置下代理可能不再单峰偏好的条件与成本近似比率。

    

    我们考虑了经典的设施选址问题的一个变种，其中每个代理的个人成本函数等于他们距离设施的距离乘以一个由设施位置确定的比例因子。除了一般类别的连续比例函数外，我们还提供了适用于许多实际情景的比例函数的分段线性比例函数的结果。我们关注总成本和最大成本的目标，并描述了最优解的计算。然后我们转向近似机制设计设置，观察到代理的偏好可能不再是单峰的。因此，我们表征了确保代理具有单峰偏好的比例函数条件。在这些条件下，我们找到了能够通过strategyproof和anonymous me达到的总成本和最大成本近似比率的结果。

    arXiv:2402.18908v1 Announce Type: cross  Abstract: We take the classic facility location problem and consider a variation, in which each agent's individual cost function is equal to their distance from the facility multiplied by a scaling factor which is determined by the facility placement. In addition to the general class of continuous scaling functions, we also provide results for piecewise linear scaling functions which can effectively approximate or model the scaling of many real world scenarios. We focus on the objectives of total and maximum cost, describing the computation of the optimal solution. We then move to the approximate mechanism design setting, observing that the agents' preferences may no longer be single-peaked. Consequently, we characterize the conditions on scaling functions which ensure that agents have single-peaked preferences. Under these conditions, we find results on the total and maximum cost approximation ratios achievable by strategyproof and anonymous me
    
[^63]: 论差分隐私微调的收敛性：应线性探测还是完全微调？

    On the Convergence of Differentially-Private Fine-tuning: To Linearly Probe or to Fully Fine-tune?

    [https://arxiv.org/abs/2402.18905](https://arxiv.org/abs/2402.18905)

    本文分析了差分隐私线性探测（LP）和完全微调（FT）的训练动态，探索了从线性探测过渡到完全微调（LP-FT）的顺序微调现象及其对测试损失的影响，提供了关于在超参数化神经网络中差分隐私微调收敛性的理论洞见和隐私预算分配的效用曲线。

    

    差分隐私（DP）机器学习流水线通常包括两个阶段的过程：在公共数据集上进行非私有预训练，然后使用DP优化技术在私有数据上进行微调。在DP设置中，已经观察到完全微调有时候并不总是产生最佳的测试准确度，即使对于分布内数据也是如此。本文（1）分析了DP线性探测（LP）和完全微调（FT）的训练动态，以及（2）探索了顺序微调的现象，从线性探测开始，过渡到完全微调（LP-FT），以及它对测试损失的影响。我们提供了有关DP微调在超参数化神经网络中的收敛性的理论洞见，并建立了一个确定隐私预算在线性探测和完全微调之间分配的效用曲线。理论结果得到了对各种基准和模型的经验评估支持。

    arXiv:2402.18905v1 Announce Type: cross  Abstract: Differentially private (DP) machine learning pipelines typically involve a two-phase process: non-private pre-training on a public dataset, followed by fine-tuning on private data using DP optimization techniques. In the DP setting, it has been observed that full fine-tuning may not always yield the best test accuracy, even for in-distribution data. This paper (1) analyzes the training dynamics of DP linear probing (LP) and full fine-tuning (FT), and (2) explores the phenomenon of sequential fine-tuning, starting with linear probing and transitioning to full fine-tuning (LP-FT), and its impact on test loss. We provide theoretical insights into the convergence of DP fine-tuning within an overparameterized neural network and establish a utility curve that determines the allocation of privacy budget between linear probing and full fine-tuning. The theoretical results are supported by empirical evaluations on various benchmarks and models.
    
[^64]: 分析和减少参数高效调整中的灾难性遗忘

    Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient Tuning

    [https://arxiv.org/abs/2402.18865](https://arxiv.org/abs/2402.18865)

    通过模式连接调查了连续微调中不同极小值之间的几何连接，揭示了大型语言模型中的灾难性遗忘问题。

    

    已有研究显示，大型语言模型（LLMs）在语言理解和生成方面表现出色。然而，当LLMs不断在复杂和多样化的特定领域下游任务上进行微调时，对历史任务的推理性能会急剧下降，这被称为灾难性遗忘问题。需要在学习可塑性和记忆稳定性之间保持权衡。已有很多研究探讨了诸如记忆重放、正则化和参数隔离等策略，但在连续的LLMs微调场景中，对各个相邻极小值之间的几何连接知之甚少。在这项工作中，我们通过模式连接的视角调查了不同极小值之间的几何连接，这意味着不同极小值可以通过一个低损失的山谷相连接。通过大量实验，我们揭示了LLMs微调中的模式连接现象。

    arXiv:2402.18865v1 Announce Type: cross  Abstract: Existing research has shown that large language models (LLMs) exhibit remarkable performance in language understanding and generation. However, when LLMs are continuously fine-tuned on complex and diverse domain-specific downstream tasks, the inference performance on historical tasks decreases dramatically, which is known as a catastrophic forgetting problem. A trade-off needs to be kept between learning plasticity and memory stability. Plenty of existing works have explored strategies like memory replay, regularization and parameter isolation, but little is known about the geometric connection of various adjacent minima in the continual LLMs fine-tuning scenarios. In this work, we investigate the geometric connections of different minima through the lens of mode connectivity, which means different minima can be connected by a low-loss valley. Through extensive experiments, we uncover the mode connectivity phenomenon in the LLMs contin
    
[^65]: 重新思考带有通用学习目标的多领域泛化

    Rethinking Multi-domain Generalization with A General Learning Objective

    [https://arxiv.org/abs/2402.18853](https://arxiv.org/abs/2402.18853)

    提出了一个通用学习目标范式，通过Y-mapping来放松约束并设计新的学习目标，包括学习域无关的条件特征和最大化后验概率，通过正则化项解决放松约束引起的问题

    

    多领域泛化（mDG）的普遍目标是最小化训练和测试分布之间的差异，以增强边际到标签分布映射。然而，现有的mDG文献缺乏一个通用的学习目标范式，通常对静态目标边际分布施加约束。在本文中，我们提议利用一个$Y$-mapping来放松约束。我们重新思考了mDG的学习目标，并设计了一个新的通用学习目标来解释和分析大多数现有的mDG智慧。这个通用目标分为两个协同的目标：学习与域无关的条件特征和最大化一个后验。我们探索了两个有效的正则化项，这些项结合了先验信息并抑制了无效的因果关系，减轻了放松约束所带来的问题。我们在理论上为域对齐提供了一个上限。

    arXiv:2402.18853v1 Announce Type: cross  Abstract: Multi-domain generalization (mDG) is universally aimed to minimize the discrepancy between training and testing distributions to enhance marginal-to-label distribution mapping. However, existing mDG literature lacks a general learning objective paradigm and often imposes constraints on static target marginal distributions. In this paper, we propose to leverage a $Y$-mapping to relax the constraint. We rethink the learning objective for mDG and design a new \textbf{general learning objective} to interpret and analyze most existing mDG wisdom. This general objective is bifurcated into two synergistic amis: learning domain-independent conditional features and maximizing a posterior. Explorations also extend to two effective regularization terms that incorporate prior information and suppress invalid causality, alleviating the issues that come with relaxed constraints. We theoretically contribute an upper bound for the domain alignment of 
    
[^66]: 在处方和预测中应用0-1神经网络

    Applications of 0-1 Neural Networks in Prescription and Prediction

    [https://arxiv.org/abs/2402.18851](https://arxiv.org/abs/2402.18851)

    引入了处方网络（PNNs）这种新型神经网络，通过混合整数规划训练，结合反事实估计，在医疗决策中展现出优于现有方法的表现，可优化治疗策略，并具有更大的可解释性和更复杂的策略编码能力。

    

    医疗决策中的一个关键挑战是在有限的观察数据下学习针对患者的治疗策略。为了解决这个问题，我们引入了处方网络（PNNs），这是用混合整数规划训练的浅层0-1神经网络，可以与反事实估计一起在中等数据情况下优化策略。这些模型比深度神经网络具有更大的可解释性，并且可以编码比常见模型（如决策树）更复杂的策略。我们展示了PNNs在合成数据实验和产后高血压治疗分配案例研究中表现优于现有方法。特别是，PNNs被证明能够产生可降低高血压峰值的治疗策略。

    arXiv:2402.18851v1 Announce Type: cross  Abstract: A key challenge in medical decision making is learning treatment policies for patients with limited observational data. This challenge is particularly evident in personalized healthcare decision-making, where models need to take into account the intricate relationships between patient characteristics, treatment options, and health outcomes. To address this, we introduce prescriptive networks (PNNs), shallow 0-1 neural networks trained with mixed integer programming that can be used with counterfactual estimation to optimize policies in medium data settings. These models offer greater interpretability than deep neural networks and can encode more complex policies than common models such as decision trees. We show that PNNs can outperform existing methods in both synthetic data experiments and in a case study of assigning treatments for postpartum hypertension. In particular, PNNs are shown to produce policies that could reduce peak bloo
    
[^67]: 提升隐写文本提取：评估自然语言处理模型对准确性和语义连贯性的影响

    Enhancing Steganographic Text Extraction: Evaluating the Impact of NLP Models on Accuracy and Semantic Coherence

    [https://arxiv.org/abs/2402.18849](https://arxiv.org/abs/2402.18849)

    通过整合NLP大型模型，本研究提出一种LSB-NLP混合框架，显著提高了隐写文本提取的准确性和鲁棒性，尤其在处理中文字符时表现优异。

    

    这项研究讨论了一种新方法，将图像隐写术技术与自然语言处理（NLP）大型模型相结合，旨在提高提取隐写文本的准确性和鲁棒性。传统的最低有效位（LSB）隐写术技术在处理复杂字符编码（如中文字符）时在信息提取的准确性和鲁棒性方面面临挑战。为了解决这一问题，本研究提出了一种创新的LSB-NLP混合框架。该框架集成了NLP大型模型的先进能力，如错误检测、纠正和语义一致性分析，以及信息重建技术，从而显著提高了隐写文本提取的鲁棒性。实验结果显示，LSB-NLP混合框架在提高隐写文本提取准确性方面表现出色，特别是在处理中文字符方面。

    arXiv:2402.18849v1 Announce Type: cross  Abstract: This study discusses a new method combining image steganography technology with Natural Language Processing (NLP) large models, aimed at improving the accuracy and robustness of extracting steganographic text. Traditional Least Significant Bit (LSB) steganography techniques face challenges in accuracy and robustness of information extraction when dealing with complex character encoding, such as Chinese characters. To address this issue, this study proposes an innovative LSB-NLP hybrid framework. This framework integrates the advanced capabilities of NLP large models, such as error detection, correction, and semantic consistency analysis, as well as information reconstruction techniques, thereby significantly enhancing the robustness of steganographic text extraction. Experimental results show that the LSB-NLP hybrid framework excels in improving the extraction accuracy of steganographic text, especially in handling Chinese characters. 
    
[^68]: 机器无法取代人类的心灵

    The Machine Can't Replace the Human Heart

    [https://arxiv.org/abs/2402.18826](https://arxiv.org/abs/2402.18826)

    人工智能和虚拟治疗技术的发展带来了更广泛的接触机会，但在实施中需要平衡效率和同理心，以确保技术始终是由医护人员的智慧指导的辅助工具。

    

    这里是翻译过的论文摘要

    arXiv:2402.18826v1 Announce Type: cross  Abstract: What is the true heart of mental healthcare -- innovation or humanity? Can virtual therapy ever replicate the profound human bonds where healing arises? As artificial intelligence and immersive technologies promise expanded access, safeguards must ensure technologies remain supplementary tools guided by providers' wisdom. Implementation requires nuance balancing efficiency and empathy. If conscious of ethical risks, perhaps AI could restore humanity by automating tasks, giving providers more time to listen. Yet no algorithm can replicate the seat of dignity within. We must ask ourselves: What future has people at its core? One where AI thoughtfully plays a collaborative role? Or where pursuit of progress leaves vulnerability behind? This commentary argues for a balanced approach thoughtfully integrating technology while retaining care's irreplaceable human essence, at the heart of this profoundly human profession. Ultimately, by nurtur
    
[^69]: 大型语言模型如何处理多语言？

    How do Large Language Models Handle Multilingualism?

    [https://arxiv.org/abs/2402.18815](https://arxiv.org/abs/2402.18815)

    大型语言模型展示了处理多语言任务的出色性能，研究发现在不同层次中处理多语言输入的策略，以及处理特定语言时的语言特定神经元存在。

    

    大型语言模型（LLMs）展现出在各种语言上出色的性能。本文探讨了一个问题：大型语言模型如何处理多语言？我们引入了一个框架，描述了LLMs处理多语言输入的过程：在前几层中，LLMs理解问题，将多语言输入转换为英语以便促进任务解决阶段。在中间层中，LLMs通过以英语思考并整合多语言知识来进行解决问题，利用自注意力和前馈结构，分别获取事实内容。在最后几层中，LLMs生成与查询的原始语言一致的响应。此外，我们研究了处理特定语言时特定语言神经元的存在。为了检测由输入语言激活的神经元，即使没有标签，我们创新性地设计了一个并行语言特定的

    arXiv:2402.18815v1 Announce Type: cross  Abstract: Large language models (LLMs) demonstrate remarkable performance across a spectrum of languages. In this work, we delve into the question: How do LLMs handle multilingualism? We introduce a framework that depicts LLMs' processing of multilingual inputs: In the first several layers, LLMs understand the question, converting multilingual inputs into English to facilitate the task-solving phase. In the intermediate layers, LLMs engage in problem-solving by thinking in English and incorporating multilingual knowledge to obtain factual content, leveraging the self-attention and feed-forward structures, respectively. In the last several layers, LLMs generate responses that align with the original language of the query. In addition, we investigate the existence of language-specific neurons when processing a certain language. To detect neurons activated by the input language, even without labels, we innovatively design a Parallel Language specif
    
[^70]: 论使用大型语言模型进行角色扮演中的决策能力

    On the Decision-Making Abilities in Role-Playing using Large Language Models

    [https://arxiv.org/abs/2402.18807](https://arxiv.org/abs/2402.18807)

    本文评估了大型语言模型在角色扮演中的决策能力，并提供了指标和指导以增强其在此任务中的表现。

    

    大型语言模型（LLMs）现在越来越多地用于角色扮演任务，特别是在模仿特定领域专家时，主要通过角色扮演提示。在实际场景中互动时，角色的决策能力显著地塑造其行为模式。本文集中评估LLMs在角色扮演后的决策能力，从而验证角色扮演的有效性。我们的目标是为增强LLMs在角色扮演任务中的决策能力提供指标和指导。具体来说，我们首先使用LLMs生成对应于迈尔斯-布里格斯类型指标（MBTI）的16种人格类型的虚拟角色描述，代表人口的细分。然后，我们设计了具体的定量操作，从适应性、探索性等四个方面评估LLMs在角色扮演后的决策能力。

    arXiv:2402.18807v1 Announce Type: cross  Abstract: Large language models (LLMs) are now increasingly utilized for role-playing tasks, especially in impersonating domain-specific experts, primarily through role-playing prompts. When interacting in real-world scenarios, the decision-making abilities of a role significantly shape its behavioral patterns. In this paper, we concentrate on evaluating the decision-making abilities of LLMs post role-playing thereby validating the efficacy of role-playing. Our goal is to provide metrics and guidance for enhancing the decision-making abilities of LLMs in role-playing tasks. Specifically, we first use LLMs to generate virtual role descriptions corresponding to the 16 personality types of Myers-Briggs Type Indicator (abbreviated as MBTI) representing a segmentation of the population. Then we design specific quantitative operations to evaluate the decision-making abilities of LLMs post role-playing from four aspects: adaptability, exploration$\&$ex
    
[^71]: 大脑启发和基于自我的人工智能

    Brain-inspired and Self-based Artificial Intelligence

    [https://arxiv.org/abs/2402.18784](https://arxiv.org/abs/2402.18784)

    该论文介绍了一种名为Brain-inspired and Self-based Artificial Intelligence（BriSe AI）的新人工智能范式，通过自我组织的方式协调各种认知功能和学习策略，以构建人类水平的AI模型和机器人应用。

    

    这篇论文挑战了当前AI的支持者所谓 "思考机器" 的观念，因为它们缺乏自我意识。该论文提出了一种名为Brain-inspired and Self-based Artificial Intelligence（BriSe AI）的新人工智能范式，旨在通过自我组织的方式协调各种认知功能和学习策略，构建人类水平的AI模型和机器人应用。

    arXiv:2402.18784v1 Announce Type: new  Abstract: The question "Can machines think?" and the Turing Test to assess whether machines could achieve human-level intelligence is one of the roots of AI. With the philosophical argument "I think, therefore I am", this paper challenge the idea of a "thinking machine" supported by current AIs since there is no sense of self in them. Current artificial intelligence is only seemingly intelligent information processing and does not truly understand or be subjectively aware of oneself and perceive the world with the self as human intelligence does. In this paper, we introduce a Brain-inspired and Self-based Artificial Intelligence (BriSe AI) paradigm. This BriSe AI paradigm is dedicated to coordinating various cognitive functions and learning strategies in a self-organized manner to build human-level AI models and robotic applications. Specifically, BriSe AI emphasizes the crucial role of the Self in shaping the future AI, rooted with a practical hi
    
[^72]: 基于语言引导的状态抽象学习

    Learning with Language-Guided State Abstractions

    [https://arxiv.org/abs/2402.18759](https://arxiv.org/abs/2402.18759)

    利用自然语言和语言模型引导的方法，实现自动构建适用于未见任务的状态表示，有助于高维观测空间中泛化策略学习。

    

    我们描述了一个利用自然语言设计状态抽象用于模仿学习的框架。在高维观测空间中实现泛化策略学习的关键在于精心设计的状态表示，这可以将环境中的重要特征展现出来并隐藏不相关的特征。这些状态表示通常是手动指定的，或者是从其他繁重的标记过程中导出的。我们的方法LGA（语言引导的抽象）利用自然语言监督和语言模型的背景知识的结合自动构建适用于未见任务的状态表示。在LGA中，用户首先使用自然语言提供目标任务的（可能是不完整的）描述；接下来，一个预训练的语言模型将这个任务描述转化为掩盖不相关特征的状态抽象函数；最后，使用少量演示数据训练一个模仿策略。

    arXiv:2402.18759v1 Announce Type: cross  Abstract: We describe a framework for using natural language to design state abstractions for imitation learning. Generalizable policy learning in high-dimensional observation spaces is facilitated by well-designed state representations, which can surface important features of an environment and hide irrelevant ones. These state representations are typically manually specified, or derived from other labor-intensive labeling procedures. Our method, LGA (language-guided abstraction), uses a combination of natural language supervision and background knowledge from language models (LMs) to automatically build state representations tailored to unseen tasks. In LGA, a user first provides a (possibly incomplete) description of a target task in natural language; next, a pre-trained LM translates this task description into a state abstraction function that masks out irrelevant features; finally, an imitation policy is trained using a small number of demo
    
[^73]: 细调的机器翻译度量在未知领域中存在困难

    Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains

    [https://arxiv.org/abs/2402.18747](https://arxiv.org/abs/2402.18747)

    细调的机器翻译度量在未知领域中表现出明显的性能下降，相对于依赖表面形式的度量和未经MT质量判断细调的预训练度量。

    

    我们引入了一个新的、涵盖生物医学领域中11种语言对的广泛的多维质量度量(MQM)注释数据集。我们利用这个数据集来探究在训练和推断之间的领域转移时，是否那些根据人工生成的机器翻译质量判断进行细调的MT度量是稳健的。我们发现，在未知领域的情况下，细调的度量相对于依赖表面形式的度量以及未经MT质量判断细调的预训练度量表现出显著的性能下降。

    arXiv:2402.18747v1 Announce Type: cross  Abstract: We introduce a new, extensive multidimensional quality metrics (MQM) annotated dataset covering 11 language pairs in the biomedical domain. We use this dataset to investigate whether machine translation (MT) metrics which are fine-tuned on human-generated MT quality judgements are robust to domain shifts between training and inference. We find that fine-tuned metrics exhibit a substantial performance drop in the unseen domain scenario relative to metrics that rely on the surface form, as well as pre-trained metrics which are not fine-tuned on MT quality judgments.
    
[^74]: 多无人机任务规划支持的多准则决策方法修订

    A revision on Multi-Criteria Decision Making methods for Multi-UAV Mission Planning Support

    [https://arxiv.org/abs/2402.18743](https://arxiv.org/abs/2402.18743)

    该论文设计了一个决策支持系统，通过排名和过滤系统减少多无人机任务规划中的最优解，并提出了修订的多准则决策方法。

    

    在过去的十年里，由于其易管理性和风险规避能力，无人机在许多商业应用中被广泛使用。其中一个主要问题是多无人机的任务规划，需要找到一个满足问题不同约束条件的解决方案。本问题有多个同时需要优化的变量，如任务完成时间、任务成本或风险等。因此，问题有很多可能的最优解，操作员必须在其中选择要执行的最终解决方案。为了减少操作员在这个决策过程中的工作量，决策支持系统（DSS）变得必要。在这项工作中，设计了一个由排名和过滤系统组成的DSS，用于排序和减少最优解。就排名系统而言，涉及广泛的多准则决策方法

    arXiv:2402.18743v1 Announce Type: new  Abstract: Over the last decade, Unmanned Aerial Vehicles (UAVs) have been extensively used in many commercial applications due to their manageability and risk avoidance. One of the main problems considered is the Mission Planning for multiple UAVs, where a solution plan must be found satisfying the different constraints of the problem. This problem has multiple variables that must be optimized simultaneously, such as the makespan, the cost of the mission or the risk. Therefore, the problem has a lot of possible optimal solutions, and the operator must select the final solution to be executed among them. In order to reduce the workload of the operator in this decision process, a Decision Support System (DSS) becomes necessary. In this work, a DSS consisting of ranking and filtering systems, which order and reduce the optimal solutions, has been designed. With regard to the ranking system, a wide range of Multi-Criteria Decision Making (MCDM) method
    
[^75]: GAIA: 生成AI的范畴基础

    GAIA: Categorical Foundations of Generative AI

    [https://arxiv.org/abs/2402.18732](https://arxiv.org/abs/2402.18732)

    提出了一种基于范畴论的生成AI架构GAIA，采用层次模型和单纯复合体组织模块，将参数更新建模为单纯集上的提升图表，并采用余代数的形式进行深度学习。

    

    在本文中，我们提出了GAIA，一种基于范畴论的生成AI架构。GAIA基于一个层次模型，其中模块被组织为一个单纯复合体。每个单纯复合体根据从其上级单纯体接收到的信息更新其内部参数，并将更新传递给其下级子单纯体。参数更新以单纯集上的提升图表的形式进行，其中内部和外部角扩展对应不同类型的学习问题。反向传播被建模为参数范畴上的一个自函子，导致深度学习的一个余代数形式。

    arXiv:2402.18732v1 Announce Type: new  Abstract: In this paper, we propose GAIA, a generative AI architecture based on category theory. GAIA is based on a hierarchical model where modules are organized as a simplicial complex. Each simplicial complex updates its internal parameters biased on information it receives from its superior simplices and in turn relays updates to its subordinate sub-simplices. Parameter updates are formulated in terms of lifting diagrams over simplicial sets, where inner and outer horn extensions correspond to different types of learning problems. Backpropagation is modeled as an endofunctor over the category of parameters, leading to a coalgebraic formulation of deep learning.
    
[^76]: 揭示隐私、记忆和输入曲率之间的联系

    Unveiling Privacy, Memorization, and Input Curvature Links

    [https://arxiv.org/abs/2402.18726](https://arxiv.org/abs/2402.18726)

    本研究揭示了记忆与输入损失曲率之间的联系，并建立了差分隐私、记忆和输入损失曲率之间的理论联系。

    

    深度神经网络(DNNs)已成为解决许多新兴问题的普遍工具。然而，它们往往会过度拟合和记忆训练集。记忆是一个备受关注的问题，因为它与诸多概念如泛化、有噪学习和隐私密切相关。最近的研究显示了输入损失曲率（通过损失Hessian矩阵对输入的迹进行测量）与记忆之间的经验性联系。它被证明比计算记忆分数要高效约3个数量级。然而，目前缺乏将记忆与输入损失曲率联系起来的理论理解。本文不仅研究了这种联系，还扩展了我们的分析，建立了差分隐私、记忆和输入损失曲率之间的理论联系。

    arXiv:2402.18726v1 Announce Type: cross  Abstract: Deep Neural Nets (DNNs) have become a pervasive tool for solving many emerging problems. However, they tend to overfit to and memorize the training set. Memorization is of keen interest since it is closely related to several concepts such as generalization, noisy learning, and privacy. To study memorization, Feldman (2019) proposed a formal score, however its computational requirements limit its practical use. Recent research has shown empirical evidence linking input loss curvature (measured by the trace of the loss Hessian w.r.t inputs) and memorization. It was shown to be ~3 orders of magnitude more efficient than calculating the memorization score. However, there is a lack of theoretical understanding linking memorization with input loss curvature. In this paper, we not only investigate this connection but also extend our analysis to establish theoretical links between differential privacy, memorization, and input loss curvature. F
    
[^77]: 使用梯度下降学习关联记忆

    Learning Associative Memories with Gradient Descent

    [https://arxiv.org/abs/2402.18724](https://arxiv.org/abs/2402.18724)

    该论文研究了一个关联记忆模块的训练动态，通过理论和实验揭示了在过参数化和欠参数化情况下的学习动态和误差特性。

    

    这项工作主要关注存储标记嵌入的外积的一个关联记忆模块的训练动态。我们将这个问题简化为研究一个粒子系统，这些粒子根据数据分布的特性以及嵌入之间的相关性进行交互。通过理论和实验，我们提供了一些见解。在过参数化的情况下，我们获得了“分类边界”的对数增长。然而，我们表明标记频率的不平衡和由相关嵌入导致的内存干扰会导致振荡的瞬态区域。振荡在步长较大时更为明显，这可能导致良性损失峰，尽管这些学习率加速了动态并加速了渐近收敛。在欠参数化的情况下，我们阐明了交叉熵损失如何导致次优的记忆方案。最后，我们评估了我们发现的在小规模Tr上的有效性。

    arXiv:2402.18724v1 Announce Type: cross  Abstract: This work focuses on the training dynamics of one associative memory module storing outer products of token embeddings. We reduce this problem to the study of a system of particles, which interact according to properties of the data distribution and correlations between embeddings. Through theory and experiments, we provide several insights. In overparameterized regimes, we obtain logarithmic growth of the ``classification margins.'' Yet, we show that imbalance in token frequencies and memory interferences due to correlated embeddings lead to oscillatory transitory regimes. The oscillations are more pronounced with large step sizes, which can create benign loss spikes, although these learning rates speed up the dynamics and accelerate the asymptotic convergence. In underparameterized regimes, we illustrate how the cross-entropy loss can lead to suboptimal memorization schemes. Finally, we assess the validity of our findings on small Tr
    
[^78]: 常识本体微模式

    Commonsense Ontology Micropatterns

    [https://arxiv.org/abs/2402.18715](https://arxiv.org/abs/2402.18715)

    本文提出了一套包含104个本体设计模式的集合，这些模式代表常见的名词，从大型语言模型中的常识知识中策划，组织成一个注释完整的模块化本体设计库，可与MOMo一起使用。

    

    先前引入的模块本体建模方法（MOMo）试图通过使用模块化模式来拼凑更复杂的概念，以模仿人类类比过程。为了支持这一点，MOMo将本体设计模式组织到设计库中，这些设计库可以通过程序查询，以支持加速本体开发，适用于人类和自动化流程。然而，MOMo大规模部署的一个主要瓶颈是（迄今为止）准备就绪的本体设计模式的有限可用性。与此同时，大型语言模型已迅速成为通识知识的来源，在某些情况下取代搜索引擎回答问题。因此，在本文中，我们提出了一套包含104个本体设计模式的集合，这些模式代表常见的名词，从大型语言模型中的常识知识中策划，组织成一个注释完整的模块化本体设计库，可与MOMo一起使用。

    arXiv:2402.18715v1 Announce Type: new  Abstract: The previously introduced Modular Ontology Modeling methodology (MOMo) attempts to mimic the human analogical process by using modular patterns to assemble more complex concepts. To support this, MOMo organizes organizes ontology design patterns into design libraries, which are programmatically queryable, to support accelerated ontology development, for both human and automated processes. However, a major bottleneck to large-scale deployment of MOMo is the (to-date) limited availability of ready-to-use ontology design patterns. At the same time, Large Language Models have quickly become a source of common knowledge and, in some cases, replacing search engines for questions. In this paper, we thus present a collection of 104 ontology design patterns representing often occurring nouns, curated from the common-sense knowledge available in LLMs, organized into a fully-annotated modular ontology design library ready for use with MOMo.
    
[^79]: 学习在自然语言格式中压缩提示

    Learning to Compress Prompt in Natural Language Formats

    [https://arxiv.org/abs/2402.18700](https://arxiv.org/abs/2402.18700)

    该研究旨在通过提出自然语言提示封装（Nano-Capsulator）框架，解决了在自然语言格式中压缩提示的挑战，以提高大型语言模型的可转移性和性能。

    

    大型语言模型（LLMs）擅长处理多个自然语言处理任务，但它们的能力受到长上下文、推理速度慢以及计算结果成本高的限制。部署具有精确和信息丰富上下文的LLMs有助于用户更有效和更具成本效益地处理大规模数据集。现有作品依赖将长提示上下文压缩为软提示。然而，软提示压缩在不同LLM之间的可转移性受到限制，尤其是基于API的LLMs。因此，本研究旨在以LLM可转移性的形式压缩长提示的自然语言形式。这带来两个挑战：(i) 自然语言（NL）提示不兼容反向传播，(ii) NL提示在施加长度约束方面缺乏灵活性。在本研究中，我们提出了一种自然语言提示封装（Nano-Capsulator）框架

    arXiv:2402.18700v1 Announce Type: cross  Abstract: Large language models (LLMs) are great at processing multiple natural language processing tasks, but their abilities are constrained by inferior performance with long context, slow inference speed, and the high cost of computing the results. Deploying LLMs with precise and informative context helps users process large-scale datasets more effectively and cost-efficiently. Existing works rely on compressing long prompt contexts into soft prompts. However, soft prompt compression encounters limitations in transferability across different LLMs, especially API-based LLMs. To this end, this work aims to compress lengthy prompts in the form of natural language with LLM transferability. This poses two challenges: (i) Natural Language (NL) prompts are incompatible with back-propagation, and (ii) NL prompts lack flexibility in imposing length constraints. In this work, we propose a Natural Language Prompt Encapsulation (Nano-Capsulator) framewor
    
[^80]: 数据解释器：用于数据科学的LLM代理

    Data Interpreter: An LLM Agent For Data Science

    [https://arxiv.org/abs/2402.18679](https://arxiv.org/abs/2402.18679)

    本研究引入了数据解释器，采用动态规划、工具集成和逻辑错误识别等关键技术，旨在增强数据科学中的问题解决能力。

    

    大型语言模型（LLM）代理已表现出显著的有效性。然而，在需要实时数据调整、优化专业知识以应对各种任务间复杂依赖性以及精确推理的逻辑错误识别的数据科学场景中，它们的性能可能会受到影响。本研究介绍了数据解释器，这是一个设计用于解决强调三种关键技术以增强数据科学中问题解决的方案的代码：1）具有分层图结构的动态规划，用于实时数据适应性；2）工具集成动态化，以增强代码执行过程中的熟练度，丰富必要的专业知识；3）在反馈中识别逻辑不一致性，并通过经验记录来提高效率。我们评估了数据解释器在各种数据科学和现实任务上的表现。与开源基线相比，它展现了s

    arXiv:2402.18679v1 Announce Type: new  Abstract: Large Language Model (LLM)-based agents have demonstrated remarkable effectiveness. However, their performance can be compromised in data science scenarios that require real-time data adjustment, expertise in optimization due to complex dependencies among various tasks, and the ability to identify logical errors for precise reasoning. In this study, we introduce the Data Interpreter, a solution designed to solve with code that emphasizes three pivotal techniques to augment problem-solving in data science: 1) dynamic planning with hierarchical graph structures for real-time data adaptability;2) tool integration dynamically to enhance code proficiency during execution, enriching the requisite expertise;3) logical inconsistency identification in feedback, and efficiency enhancement through experience recording. We evaluate the Data Interpreter on various data science and real-world tasks. Compared to open-source baselines, it demonstrated s
    
[^81]: 面向传感器故障和攻击的机器人系统的容错神经控制屏障函数

    Fault Tolerant Neural Control Barrier Functions for Robotic Systems under Sensor Faults and Attacks

    [https://arxiv.org/abs/2402.18677](https://arxiv.org/abs/2402.18677)

    本文研究了面向传感器故障和攻击的机器人系统的安全关键控制综合，提出了一种新的容错神经控制屏障函数（FT-NCBF）。

    

    安全是许多机器人系统的基本要求。控制屏障函数（CBF）的方法已被提出，用于确保机器人系统的安全性。然而，这些方法的有效性在很大程度上取决于CBF的选择。受神经网络的通用逼近能力启发，越来越多的人开始倾向于使用神经网络表示CBF，从而引出了神经CBF（NCBF）的概念。然而，目前的NCBF是在良性环境中进行训练和部署的，这使得它们在机器人系统经历传感器故障和攻击的情况下无效。在本文中，我们研究了在传感器故障和攻击下机器人系统的安全关键控制综合。我们的主要贡献是开发和综合一类新的CBF，我们将其称为容错神经控制屏障函数（FT-NCBF）。我们推导了FT-NCBF确保s

    arXiv:2402.18677v1 Announce Type: cross  Abstract: Safety is a fundamental requirement of many robotic systems. Control barrier function (CBF)-based approaches have been proposed to guarantee the safety of robotic systems. However, the effectiveness of these approaches highly relies on the choice of CBFs. Inspired by the universal approximation power of neural networks, there is a growing trend toward representing CBFs using neural networks, leading to the notion of neural CBFs (NCBFs). Current NCBFs, however, are trained and deployed in benign environments, making them ineffective for scenarios where robotic systems experience sensor faults and attacks. In this paper, we study safety-critical control synthesis for robotic systems under sensor faults and attacks. Our main contribution is the development and synthesis of a new class of CBFs that we term fault tolerant neural control barrier function (FT-NCBF). We derive the necessary and sufficient conditions for FT-NCBFs to guarantee s
    
[^82]: 人类注意力建模的趋势、应用和挑战

    Trends, Applications, and Challenges in Human Attention Modelling

    [https://arxiv.org/abs/2402.18673](https://arxiv.org/abs/2402.18673)

    人类注意力建模为深度学习模型的整合提供了重要支持，有助于解决图像处理、视频处理、视觉与语言应用和语言建模等领域的问题。

    

    近年来，人类注意力建模不仅在理解视觉探索背后的认知过程方面特别有用，而且在为旨在解决各个领域问题的人工智能模型提供支持方面也表现出色，包括图像和视频处理、视觉与语言应用以及语言建模。本调查提供了综述最新努力将人类注意机制整合到当代深度学习模型中的理由，并讨论了未来的研究方向和挑战。有关正在进行研究的全面概述，请参阅我们在 https://github.com/aimagelab/awesome-human-visual-attention 上提供的专用存储库。

    arXiv:2402.18673v1 Announce Type: cross  Abstract: Human attention modelling has proven, in recent years, to be particularly useful not only for understanding the cognitive processes underlying visual exploration, but also for providing support to artificial intelligence models that aim to solve problems in various domains, including image and video processing, vision-and-language applications, and language modelling. This survey offers a reasoned overview of recent efforts to integrate human attention mechanisms into contemporary deep learning models and discusses future research directions and challenges. For a comprehensive overview on the ongoing research refer to our dedicated repository available at https://github.com/aimagelab/awesome-human-visual-attention.
    
[^83]: 大型语言模型与游戏：调研与路线图

    Large Language Models and Games: A Survey and Roadmap

    [https://arxiv.org/abs/2402.18659](https://arxiv.org/abs/2402.18659)

    这项研究调查了大型语言模型在游戏领域中的多种应用及其角色，指出了未开发领域和未来发展方向，同时探讨了在游戏领域中大型语言模型的潜力和限制。

    

    近年来，大型语言模型（LLMs）的研究急剧增加，并伴随着公众对该主题的参与。尽管起初是自然语言处理中的一小部分，LLMs在广泛的应用和领域中展现出显著潜力，包括游戏。本文调查了LLMs在游戏中及为游戏提供支持的各种应用的最新技术水平，并明确了LLMs在游戏中可以扮演的不同角色。重要的是，我们讨论了尚未开发的领域和LLMs在游戏中未来应用的有前途的方向，以及在游戏领域中LLMs的潜力和限制。作为LLMs和游戏交叉领域的第一份综合调查和路线图，我们希望本文能够成为这一激动人心的新领域的开创性研究和创新的基础。

    arXiv:2402.18659v1 Announce Type: cross  Abstract: Recent years have seen an explosive increase in research on large language models (LLMs), and accompanying public engagement on the topic. While starting as a niche area within natural language processing, LLMs have shown remarkable potential across a broad range of applications and domains, including games. This paper surveys the current state of the art across the various applications of LLMs in and for games, and identifies the different roles LLMs can take within a game. Importantly, we discuss underexplored areas and promising directions for future uses of LLMs in games and we reconcile the potential and limitations of LLMs within the games domain. As the first comprehensive survey and roadmap at the intersection of LLMs and games, we are hopeful that this paper will serve as the basis for groundbreaking research and innovation in this exciting new field.
    
[^84]: 量化人类对社交和导航网络的先验知识

    Quantifying Human Priors over Social and Navigation Networks

    [https://arxiv.org/abs/2402.18651](https://arxiv.org/abs/2402.18651)

    本研究利用图的组合结构来量化人类对社交和导航网络的先验知识，揭示了一些一致的特征和特定领域的倾向，为高效建模数据中的潜在偏见提供了方法。

    

    人类知识主要是隐含的和关系型的 —— 我们是否有共同的朋友？我能从这里走到那里吗？本研究利用图的组合结构来量化人类对这种关系数据的先验知识。我们的实验着重于两个在进化时间尺度上持续相关的领域：社交互动和空间导航。我们发现一些推断得到的先验知识特征非常一致，例如稀疏性倾向随着图的大小变化。其他特征是特定于领域的，例如社交互动中的三元闭合倾向。更广泛地，我们的工作展示了如何利用间接行为实验的非经典统计分析来高效建模数据中的潜在偏见。

    arXiv:2402.18651v1 Announce Type: cross  Abstract: Human knowledge is largely implicit and relational -- do we have a friend in common? can I walk from here to there? In this work, we leverage the combinatorial structure of graphs to quantify human priors over such relational data. Our experiments focus on two domains that have been continuously relevant over evolutionary timescales: social interaction and spatial navigation. We find that some features of the inferred priors are remarkably consistent, such as the tendency for sparsity as a function of graph size. Other features are domain-specific, such as the propensity for triadic closure in social interactions. More broadly, our work demonstrates how nonclassical statistical analysis of indirect behavioral experiments can be used to efficiently model latent biases in the data.
    
[^85]: LLM安全领域的新时代：探讨现实世界LLM系统中的安全问题

    A New Era in LLM Security: Exploring Security Concerns in Real-World LLM-based Systems

    [https://arxiv.org/abs/2402.18649](https://arxiv.org/abs/2402.18649)

    本文系统分析了LLM系统的安全性，引入信息流对齐约束以控制LLM系统的攻击面

    

    大型语言模型（LLM）系统在本质上是组合的，单个LLM作为核心基础，带有插件、沙盒等附加层对象。除了巨大潜力外，人们对这种概率智能系统的安全性也日益关注。然而，现有关于LLM安全性的研究通常集中在个别LLM上，而没有通过LLM系统与其他对象（例如前端、Web工具、沙盒等）的视角来检视生态系统。在本文中，我们系统分析了LLM系统的安全性，而不是专注于个别LLM。为此，我们基于信息流构建，并将LLM系统的安全性表述为LLM内部以及LLM与其他对象之间信息流对齐的约束。基于这一构建以及LLM独特的概率性质，LLM系统的攻击面可以被控制。

    arXiv:2402.18649v1 Announce Type: cross  Abstract: Large Language Model (LLM) systems are inherently compositional, with individual LLM serving as the core foundation with additional layers of objects such as plugins, sandbox, and so on. Along with the great potential, there are also increasing concerns over the security of such probabilistic intelligent systems. However, existing studies on LLM security often focus on individual LLM, but without examining the ecosystem through the lens of LLM systems with other objects (e.g., Frontend, Webtool, Sandbox, and so on). In this paper, we systematically analyze the security of LLM systems, instead of focusing on the individual LLMs. To do so, we build on top of the information flow and formulate the security of LLM systems as constraints on the alignment of the information flow within LLM and between LLM and other objects. Based on this construction and the unique probabilistic nature of LLM, the attack surface of the LLM system can be deco
    
[^86]: ELA：零和博弈中融入利用水平的离线学习

    ELA: Exploited Level Augmentation for Offline Learning in Zero-Sum Games

    [https://arxiv.org/abs/2402.18617](https://arxiv.org/abs/2402.18617)

    该研究提出了一种新颖的方法，利用无监督学习技术估计不同示范者制作的零和博弈离线数据集中每条轨迹的被利用水平，并将其融入离线学习以最大化支配策略的影响力。

    

    离线学习由于能够从专家示范者收集的离线数据集中推导出有效策略而不需要直接与环境进行交互，已经被广泛使用。最近的研究探索了通过考虑数据集的特征（例如，专业水平或多个示范者）来增强离线学习效率的各种方式。然而，在零和博弈的背景下，需要一种不同的方法，因为结果根据对手的策略而显著变化。在本研究中，我们介绍了一种新颖的方法，利用无监督学习技术估计由不同示范者制作的零和博弈的离线数据集中每条轨迹的被利用水平。随后，我们将估计的被利用水平结合到离线学习中，以最大化支配策略的影响力。我们的方法实现了在多个示范者的零和博弈离线数据集中可解释的被利用水平估计。

    arXiv:2402.18617v1 Announce Type: cross  Abstract: Offline learning has become widely used due to its ability to derive effective policies from offline datasets gathered by expert demonstrators without interacting with the environment directly. Recent research has explored various ways to enhance offline learning efficiency by considering the characteristics (e.g., expertise level or multiple demonstrators) of the dataset. However, a different approach is necessary in the context of zero-sum games, where outcomes vary significantly based on the strategy of the opponent. In this study, we introduce a novel approach that uses unsupervised learning techniques to estimate the exploited level of each trajectory from the offline dataset of zero-sum games made by diverse demonstrators. Subsequently, we incorporate the estimated exploited level into the offline learning to maximize the influence of the dominant strategy. Our method enables interpretable exploited level estimation in multiple z
    
[^87]: JCLEC-MO：用于解决多目标优化工程问题的Java套件

    JCLEC-MO: a Java suite for solving many-objective optimization engineering problems

    [https://arxiv.org/abs/2402.18616](https://arxiv.org/abs/2402.18616)

    JCLEC-MO 是一个Java框架，旨在解决多目标优化工程问题，为工程师提供了在很少编程工作情况下应用或调整大量多目标算法的能力。

    

    尽管元启发式方法被广泛认为是解决实际优化问题的高效技术，但对于没有编程技能的领域专家来说，从头开始实现它们仍然很困难。在这种情况下，元启发式优化框架是一个实际的选择，因为它们提供了由定制元素组成的各种算法，以及实验支持。最近，许多工程问题需要优化多个甚至多个目标，这增加了对适当元启发式算法和框架的兴趣，这些算法和框架可能整合新的特定要求，同时保持它们最初构想的通用性和可重用性原则。基于这个想法，本文介绍了JCLEC-MO，一个Java框架，用于多目标和多目标优化，它使工程师可以在很少编程工作的情况下应用或调整大量多目标算法。

    arXiv:2402.18616v1 Announce Type: cross  Abstract: Although metaheuristics have been widely recognized as efficient techniques to solve real-world optimization problems, implementing them from scratch remains difficult for domain-specific experts without programming skills. In this scenario, metaheuristic optimization frameworks are a practical alternative as they provide a variety of algorithms composed of customized elements, as well as experimental support. Recently, many engineering problems require to optimize multiple or even many objectives, increasing the interest in appropriate metaheuristic algorithms and frameworks that might integrate new specific requirements while maintaining the generality and reusability principles they were conceived for. Based on this idea, this paper introduces JCLEC-MO, a Java framework for both multi- and many-objective optimization that enables engineers to apply, or adapt, a great number of multi-objective algorithms with little coding effort. A 
    
[^88]: ICE-SEARCH: 一种基于语言模型驱动的特征选择方法

    ICE-SEARCH: A Language Model-Driven Feature Selection Approach

    [https://arxiv.org/abs/2402.18609](https://arxiv.org/abs/2402.18609)

    ICE-SEARCH是首个将语言模型与进化算法相结合用于特征选择任务的方法，在医学预测分析应用中取得了State-of-the-Art(SOTA)表现。

    

    本研究揭示了In-Context Evolutionary Search (ICE-SEARCH)方法，这是首个将语言模型(LMs)与进化算法相结合用于特征选择(FS)任务的工作，并展示了其在医学预测分析(MPA)应用中的有效性。ICE-SEARCH利用语言模型中固有的交叉和突变能力，在一个进化框架内显着改进特征选择，通过模型的全面世界知识和其适应各种角色的能力。我们对该方法的评估涵盖了三个关键的MPA任务：中风、心血管疾病和糖尿病，在这些任务中ICE-SEARCH在确定医学应用的关键特征方面优于传统的FS方法。ICE-SEARCH在中风预测和糖尿病预测中实现了领先水平；决策随机化ICE-SEARCH在心血管疾病预测中排名为领先水平。我们的结果不仅证明了

    arXiv:2402.18609v1 Announce Type: cross  Abstract: This study unveils the In-Context Evolutionary Search (ICE-SEARCH) method, the first work that melds language models (LMs) with evolutionary algorithms for feature selection (FS) tasks and demonstrates its effectiveness in Medical Predictive Analytics (MPA) applications. ICE-SEARCH harnesses the crossover and mutation capabilities inherent in LMs within an evolutionary framework, significantly improving FS through the model's comprehensive world knowledge and its adaptability to a variety of roles. Our evaluation of this methodology spans three crucial MPA tasks: stroke, cardiovascular disease, and diabetes, where ICE-SEARCH outperforms traditional FS methods in pinpointing essential features for medical applications. ICE-SEARCH achieves State-of-the-Art (SOTA) performance in stroke prediction and diabetes prediction; the Decision-Randomized ICE-SEARCH ranks as SOTA in cardiovascular disease prediction. Our results not only demonstrate
    
[^89]: 在分享扩散模型中探讨隐私和公平风险：一种对抗性视角

    Exploring Privacy and Fairness Risks in Sharing Diffusion Models: An Adversarial Perspective

    [https://arxiv.org/abs/2402.18607](https://arxiv.org/abs/2402.18607)

    本文从对抗性的角度研究了分享扩散模型可能存在的隐私和公平风险，特别是探讨了在一方使用私人数据训练模型后提供给另一方黑盒访问权限的情况。

    

    扩散模型近年来在学术界和工业界引起了广泛关注，因为其在采样质量和分布覆盖方面表现出色。因此，提出了跨不同组织分享预训练扩散模型的建议，以提高数据利用率同时通过避免直接分享私人数据来增强隐私保护。然而，与这种方法相关的潜在风险尚未得到全面调查。本文从对抗性的角度探讨了与分享扩散模型相关的潜在隐私和公平风险。具体而言，我们调查了一方（分享者）使用私人数据训练扩散模型并向另一方（接收者）提供预训练模型的黑盒访问权限用于下游任务的情况。我们展示了分享者可以实行的行动

    arXiv:2402.18607v1 Announce Type: cross  Abstract: Diffusion models have recently gained significant attention in both academia and industry due to their impressive generative performance in terms of both sampling quality and distribution coverage. Accordingly, proposals are made for sharing pre-trained diffusion models across different organizations, as a way of improving data utilization while enhancing privacy protection by avoiding sharing private data directly. However, the potential risks associated with such an approach have not been comprehensively examined.   In this paper, we take an adversarial perspective to investigate the potential privacy and fairness risks associated with the sharing of diffusion models. Specifically, we investigate the circumstances in which one party (the sharer) trains a diffusion model using private data and provides another party (the receiver) black-box access to the pre-trained model for downstream tasks. We demonstrate that the sharer can execut
    
[^90]: 网络拓扑对分布式联邦学习性能的影响

    Impact of network topology on the performance of Decentralized Federated Learning

    [https://arxiv.org/abs/2402.18606](https://arxiv.org/abs/2402.18606)

    研究探讨了不同类型的网络结构如何影响去中心化联邦学习中的知识传播，并通过三种网络拓扑和六种数据分布方法研究了网络结构与学习性能之间的复杂相互作用。

    

    完全去中心化的学习正在蓬勃发展，用于在互联网边缘训练人工智能模型，解决基础设施挑战和隐私问题。在去中心化机器学习系统中，数据分布在多个节点上，每个节点根据其各自的数据集训练本地模型。然后这些本地模型被共享和合并，形成能够对新数据进行准确预测的全局模型。我们的研究重点是不同类型的网络结构如何影响知识传播，即节点如何吸收来自网络上其他节点可用数据学习模式的洞见。具体而言，这项研究通过三种网络拓扑和六种数据分布方法探讨网络结构与学习性能之间的复杂相互作用。这些方法考虑了不同的顶点属性，包括度中心性，介数中心性等。

    arXiv:2402.18606v1 Announce Type: cross  Abstract: Fully decentralized learning is gaining momentum for training AI models at the Internet's edge, addressing infrastructure challenges and privacy concerns. In a decentralized machine learning system, data is distributed across multiple nodes, with each node training a local model based on its respective dataset. The local models are then shared and combined to form a global model capable of making accurate predictions on new data. Our exploration focuses on how different types of network structures influence the spreading of knowledge - the process by which nodes incorporate insights gained from learning patterns in data available on other nodes across the network. Specifically, this study investigates the intricate interplay between network structure and learning performance using three network topologies and six data distribution methods. These methods consider different vertex properties, including degree centrality, betweenness cent
    
[^91]: MMSR：符号回归是一个多模态任务

    MMSR: Symbolic Regression is a Multimodal Task

    [https://arxiv.org/abs/2402.18603](https://arxiv.org/abs/2402.18603)

    符号回归被视为一个多模态任务，研究人员将数据到表达式的映射视为翻译问题，引入大规模预训练模型。

    

    数学公式是探索自然规律几千年来人类智慧的结晶。用简洁的数学公式描述复杂的自然规律是科学家不断追求的目标，也是人工智能面临的重大挑战。这一领域被称为符号回归。在本文中，研究人员将从数据到表达式的映射视为翻译问题，并引入了相应的大规模预训练模型。

    arXiv:2402.18603v1 Announce Type: cross  Abstract: Mathematical formulas are the crystallization of human wisdom in exploring the laws of nature for thousands of years. Describing the complex laws of nature with a concise mathematical formula is a constant pursuit of scientists and a great challenge for artificial intelligence. This field is called symbolic regression. Symbolic regression was originally formulated as a combinatorial optimization problem, and GP and reinforcement learning algorithms were used to solve it. However, GP is sensitive to hyperparameters, and these two types of algorithms are inefficient. To solve this problem, researchers treat the mapping from data to expressions as a translation problem. And the corresponding large-scale pre-trained model is introduced. However, the data and expression skeletons do not have very clear word correspondences as the two languages do. Instead, they are more like two modalities (e.g., image and text). Therefore, in this paper, w
    
[^92]: 人工智能与糖尿病：通过视网膜深入探究

    Artificial Intelligence and Diabetes Mellitus: An Inside Look Through the Retina

    [https://arxiv.org/abs/2402.18600](https://arxiv.org/abs/2402.18600)

    通过视网膜图像与血管状况，人工智能系统用于高通量糖尿病视网膜病变（DR）检测，并具有潜力解决糖尿病患者整体护理挑战。

    

    糖尿病（DM）使患者易患血管并发症。视网膜图像和血管反映了身体的微血管和大血管健康状况。它们可用于诊断DM并发症，包括糖尿病视网膜病变（DR）、神经病变、肾病以及动脉粥样硬化心血管疾病，还可预测心血管事件的风险。应用人工智能（AI）技术开发的高通量DR检测系统已被临床采用。除DR筛查外，AI整合还具有巨大潜力应对糖尿病患者整体护理的挑战。本文旨在全面审查与DM诊断、预后和管理相关的基于视网膜图像的AI应用研究文献。我们将描述综合AI辅助糖尿病护理的研究结果，包括但不限于DR筛查。

    arXiv:2402.18600v1 Announce Type: cross  Abstract: Diabetes mellitus (DM) predisposes patients to vascular complications. Retinal images and vasculature reflect the body's micro- and macrovascular health. They can be used to diagnose DM complications, including diabetic retinopathy (DR), neuropathy, nephropathy, and atherosclerotic cardiovascular disease, as well as forecast the risk of cardiovascular events. Artificial intelligence (AI)-enabled systems developed for high-throughput detection of DR using digitized retinal images have become clinically adopted. Beyond DR screening, AI integration also holds immense potential to address challenges associated with the holistic care of the patient with DM. In this work, we aim to comprehensively review the literature for studies on AI applications based on retinal images related to DM diagnosis, prognostication, and management. We will describe the findings of holistic AI-assisted diabetes care, including but not limited to DR screening, a
    
[^93]: Meta-Tasks: 元学习正则化的另一种视角

    Meta-Tasks: An alternative view on Meta-Learning Regularization

    [https://arxiv.org/abs/2402.18599](https://arxiv.org/abs/2402.18599)

    该论文提出了一种新颖的解决方案，通过使用meta-tasks作为元学习正则化的视角，实现了对训练和新颖任务的泛化，避免标记数据稀缺的困扰，并在实验中表现优越，相较于原型网络提高了3.9%的性能。

    

    Few-shot learning (FSL)是一个具有挑战性的机器学习问题，因为标记数据稀缺。这篇论文提出了一种新颖的解决方案，可以泛化到训练和新颖的任务，同时利用未标记样本。该方法在更新外层循环之前，使用无监督技术对嵌入模型进行了细化，将其作为“元任务”。实验结果表明，我们提出的方法在新颖和训练任务上表现良好，收敛更快、更好，泛化误差和标准差更低，表明其在FSL中的实际应用潜力。实验结果表明，所提出的方法的表现比原型网络高出3.9%。

    arXiv:2402.18599v1 Announce Type: cross  Abstract: Few-shot learning (FSL) is a challenging machine learning problem due to a scarcity of labeled data. The ability to generalize effectively on both novel and training tasks is a significant barrier to FSL. This paper proposes a novel solution that can generalize to both training and novel tasks while also utilizing unlabeled samples. The method refines the embedding model before updating the outer loop using unsupervised techniques as ``meta-tasks''. The experimental results show that our proposed method performs well on novel and training tasks, with faster and better convergence, lower generalization, and standard deviation error, indicating its potential for practical applications in FSL. The experimental results show that the proposed method outperforms prototypical networks by 3.9%.
    
[^94]: 注意：进化博弈论聚焦信息健康：通过不完全信息下的狼人游戏的鸡尾酒派对效应和利用重复困境中期望收益的ESS搜索方法

    Note: Evolutionary Game Theory Focus Informational Health: The Cocktail Party Effect Through Werewolfgame under Incomplete Information and ESS Search Method Using Expected Gains of Repeated Dilemmas

    [https://arxiv.org/abs/2402.18598](https://arxiv.org/abs/2402.18598)

    通过研究非完全信息游戏和多狼人进化博弈框架中的鸡尾酒派对效应，本研究探讨了假新闻传播风险对策略演化和演化稳定策略的影响。

    

    我们探讨了鸡尾酒派对效应在非完全信息游戏和具有多个狼人的进化博弈框架中引起的信息干扰状态。具体来说，我们数学建模和分析了每种策略选择的收益以及演化稳定策略（ESS）的形成过程，假设在重复困境的情境中假新闻的污染风险是随机分配的。我们将详细开发计算过程，从构建收益矩阵开始，使用复制方程对演化动态进行建模，并确定ESS。此外，将进行数值模拟以观察系统在不同初始条件和参数设置下的行为，以更好地了解假新闻传播对策略演化的影响。这项研究将为复杂问题提供理论见解。

    arXiv:2402.18598v1 Announce Type: cross  Abstract: We explore the state of information disruption caused by the cocktail party effect within the framework of non-perfect information games and evolutive games with multiple werewolves. In particular, we mathematically model and analyze the effects on the gain of each strategy choice and the formation process of evolutionary stable strategies (ESS) under the assumption that the pollution risk of fake news is randomly assigned in the context of repeated dilemmas. We will develop the computational process in detail, starting with the construction of the gain matrix, modeling the evolutionary dynamics using the replicator equation, and identifying the ESS. In addition, numerical simulations will be performed to observe system behavior under different initial conditions and parameter settings to better understand the impact of the spread of fake news on strategy evolution. This research will provide theoretical insights into the complex issue
    
[^95]: 可持续的AI超级计算：HPC规模下的GPU功率限制

    Sustainable Supercomputing for AI: GPU Power Capping at HPC Scale

    [https://arxiv.org/abs/2402.18593](https://arxiv.org/abs/2402.18593)

    该研究探讨在超级计算中心对GPU进行功率限制对温度和功耗的影响，通过适当的功率限制，实现了降低能耗、改善硬件寿命的目的。

    

    随着人工智能的研究和部署不断增长，支持和维持其进展的计算负担也必然增加。为了训练或微调自然语言处理、计算机视觉等领域的最先进模型，某种形式的AI硬件加速几乎是必需的。最近的大型语言模型需要大量资源来训练和部署，导致能源消耗巨大，潜在碳排放增加，并对GPU和其他硬件加速器的需求激增。然而，这种增长对HPC/数据中心级别的能源可持续性带来重大影响。本文研究了在研究超级计算中心对GPU进行功率限制的总体效果对GPU温度和功率消耗的影响。通过适当的功率限制，我们显示出温度和功率消耗显著降低，减少功耗，并可能在最小影响作业性能的情况下改善硬件寿命。

    arXiv:2402.18593v1 Announce Type: cross  Abstract: As research and deployment of AI grows, the computational burden to support and sustain its progress inevitably does too. To train or fine-tune state-of-the-art models in NLP, computer vision, etc., some form of AI hardware acceleration is virtually a requirement. Recent large language models require considerable resources to train and deploy, resulting in significant energy usage, potential carbon emissions, and massive demand for GPUs and other hardware accelerators. However, this surge carries large implications for energy sustainability at the HPC/datacenter level. In this paper, we study the aggregate effect of power-capping GPUs on GPU temperature and power draw at a research supercomputing center. With the right amount of power-capping, we show significant decreases in both temperature and power draw, reducing power consumption and potentially improving hardware life-span with minimal impact on job performance. While power-cappi
    
[^96]: 探究大型语言模型对推荐系统的影响：一项广泛综述

    Exploring the Impact of Large Language Models on Recommender Systems: An Extensive Review

    [https://arxiv.org/abs/2402.18590](https://arxiv.org/abs/2402.18590)

    大型语言模型在推荐系统中展现出卓越的推荐能力和语言理解，重塑了推荐任务的基础。

    

    该论文强调了大型语言模型（LLMs）在重塑推荐系统中的重要性，将它们的价值归因于传统推荐系统所缺乏的独特推理能力。不同于缺乏直接用户互动数据的传统系统，LLMs在推荐物品方面表现出卓越的能力，展示了它们在理解语言复杂性方面的熟练程度。这标志着推荐领域的一个根本性范式转变。在充满活力的研究领域中，研究人员积极利用LLMs的语言理解和生成能力重新定义推荐任务的基础。该研究彻底探讨了LLMs在推荐框架内固有的优势，包括细致的语境理解，跨不同领域的平稳过渡，采用统一的方法，利用共享数据池的全面学习策略，透明度

    arXiv:2402.18590v1 Announce Type: cross  Abstract: The paper underscores the significance of Large Language Models (LLMs) in reshaping recommender systems, attributing their value to unique reasoning abilities absent in traditional recommenders. Unlike conventional systems lacking direct user interaction data, LLMs exhibit exceptional proficiency in recommending items, showcasing their adeptness in comprehending intricacies of language. This marks a fundamental paradigm shift in the realm of recommendations. Amidst the dynamic research landscape, researchers actively harness the language comprehension and generation capabilities of LLMs to redefine the foundations of recommendation tasks. The investigation thoroughly explores the inherent strengths of LLMs within recommendation frameworks, encompassing nuanced contextual comprehension, seamless transitions across diverse domains, adoption of unified approaches, holistic learning strategies leveraging shared data reservoirs, transparent
    
[^97]: Verif.ai: 一种具有引用和可验证答案的开源科学生成式问答系统

    Verif.ai: Towards an Open-Source Scientific Generative Question-Answering System with Referenced and Verifiable Answers

    [https://arxiv.org/abs/2402.18589](https://arxiv.org/abs/2402.18589)

    Verif.ai是一个具有引用和可验证答案的开源科学生成式问答系统，通过信息检索、生成模型和验证引擎的结合实现对主张的生成和验证。

    

    在本文中，我们介绍了项目Verif.ai的当前进展，这是一个具有引用和可验证答案的开源科学生成式问答系统。该系统的组成部分包括（1）一个信息检索系统，结合语义和词汇搜索技术对科学论文（PubMed）进行检索，（2）一个经过微调的生成模型（Mistral 7B），获取前几个答案并生成附有从中得出主张的论文引用的答案，以及（3）一个验证引擎，用于交叉检查生成的主张和从中得出主张的摘要或论文，验证生成主张时是否存在任何错觉。我们通过提供上下文中的摘要加强了生成模型，但此外，一个独立的方法和模型集正在验证答案并检查是否存在错觉。因此，我们相信通过使用我们的方法，我们可以使科学家们

    arXiv:2402.18589v1 Announce Type: cross  Abstract: In this paper, we present the current progress of the project Verif.ai, an open-source scientific generative question-answering system with referenced and verified answers. The components of the system are (1) an information retrieval system combining semantic and lexical search techniques over scientific papers (PubMed), (2) a fine-tuned generative model (Mistral 7B) taking top answers and generating answers with references to the papers from which the claim was derived, and (3) a verification engine that cross-checks the generated claim and the abstract or paper from which the claim was derived, verifying whether there may have been any hallucinations in generating the claim. We are reinforcing the generative model by providing the abstract in context, but in addition, an independent set of methods and models are verifying the answer and checking for hallucinations. Therefore, we believe that by using our method, we can make scientis
    
[^98]: 处于生成式人工智能时代之初：关于6G无线智能新领域的教程和调研

    At the Dawn of Generative AI Era: A Tutorial-cum-Survey on New Frontiers in 6G Wireless Intelligence

    [https://arxiv.org/abs/2402.18587](https://arxiv.org/abs/2402.18587)

    GenAI在无线领域是关键资产，能够处理稀缺、不完整、难以获取和理解的真实世界数据，可以取代或补充判别式人工智能方法，本文汇总了6G和无线智能领域的新前沿。

    

    大多数基于数据驱动的无线研究严重依赖于需要大量真实世界数据集的判别式人工智能（DAI）。与DAI不同，生成式人工智能（GenAI）涉及能够识别输入数据的潜在数据分布、模式和特征的生成模型（GMs）。这使得GenAI在无线领域成为一个关键资产，其中真实世界数据通常稀缺、不完整、获取成本高，难以建模或理解。有了这些吸引人的特征，GenAI可以取代或补充DAI方法的各种能力。因此，这篇结合了教程和调研的论文从6G和无线智能的基础开始，通过概述候选6G应用和服务、提出现代DAI模型的分类法、举例说明著名的DAI用例，并阐明GenAI如何增强DAI的多方面方式。接着，我们通过重点介绍开创性的GMs来呈现一个GMs的教程。

    arXiv:2402.18587v1 Announce Type: cross  Abstract: The majority of data-driven wireless research leans heavily on discriminative AI (DAI) that requires vast real-world datasets. Unlike the DAI, Generative AI (GenAI) pertains to generative models (GMs) capable of discerning the underlying data distribution, patterns, and features of the input data. This makes GenAI a crucial asset in wireless domain wherein real-world data is often scarce, incomplete, costly to acquire, and hard to model or comprehend. With these appealing attributes, GenAI can replace or supplement DAI methods in various capacities. Accordingly, this combined tutorial-survey paper commences with preliminaries of 6G and wireless intelligence by outlining candidate 6G applications and services, presenting a taxonomy of state-of-the-art DAI models, exemplifying prominent DAI use cases, and elucidating the multifaceted ways through which GenAI enhances DAI. Subsequently, we present a tutorial on GMs by spotlighting seminal
    
[^99]: 利用AI-Enabled GPT-4助手API简化系统文献评审（SLRs）的选择阶段

    Streamlining the Selection Phase of Systematic Literature Reviews (SLRs) Using AI-Enabled GPT-4 Assistant API

    [https://arxiv.org/abs/2402.18582](https://arxiv.org/abs/2402.18582)

    该研究引入了一种基于AI的工具，利用GPT-4助手API简化系统文献评审选择阶段的效率，加速文献评审过程，并对管理和经济领域具有重要意义。

    

    学术文献数量不断增加，使得跟踪最新的研究进展成为一项巨大挑战。为解决这一问题，本研究引入了一种开创性的基于人工智能的工具，专门配置以简化系统文献评审（SLRs）的文章选择阶段的效率。利用OpenAI的GPT-4助手API强大的功能，该工具成功地在广泛的学术领域中使文章选择过程变得一致。通过数据准备、AI辅助文章评估和结构化结果呈现的三方面方法，该工具显著加快了文献评审这个耗时的任务。重要的是，该工具在管理和经济等领域具有很高的益处，这些领域的SLR过程涉及大量人类判断。采用标准GPT模型可以显著减少潜在

    arXiv:2402.18582v1 Announce Type: cross  Abstract: The escalating volume of academic literature presents a formidable challenge in staying updated with the newest research developments. Addressing this, this study introduces a pioneering AI-based tool, configured specifically to streamline the efficiency of the article selection phase in Systematic Literature Reviews (SLRs). Utilizing the robust capabilities of OpenAI's GPT-4 Assistant API, the tool successfully homogenizes the article selection process across a broad array of academic disciplines. Implemented through a tripartite approach consisting of data preparation, AI-mediated article assessment, and structured result presentation, this tool significantly accelerates the time-consuming task of literature reviews. Importantly, this tool could be highly beneficial in fields such as management and economics, where the SLR process involves substantial human judgment. The adoption of a standard GPT model can substantially reduce poten
    
[^100]: 城市车辆网络中多目标最优边路单元部署

    Multi-objective Optimal Roadside Units Deployment in Urban Vehicular Networks

    [https://arxiv.org/abs/2402.18581](https://arxiv.org/abs/2402.18581)

    城市车辆网络中多目标最优边路单元部署涉及克服多个优化目标之间的冲突，以及解决城市环境中各种障碍带来的部署困难。

    

    运输效率、安全性和相关服务的重要性在城市车辆网络中日益增加。在这样的网络中，边路单元（RSUs）作为促进通信的中间者。因此，RSUs的部署对于确保通信服务的质量至关重要。然而，优化目标，如时间延迟和部署成本，通常是从不同的视角发展而来。因此，可能出现目标之间的冲突。此外，在城市环境中，建筑物、公园、湖泊和其他基础设施等各种障碍的存在给RSUs的部署带来挑战。因此，部署由于存在多个目标、障碍物所施加的约束以及需要探索大规模优化空间而遇到重大困难。为了解决这个问题，提出了两个多目标最优边路单元部署的版本。

    arXiv:2402.18581v1 Announce Type: cross  Abstract: The significance of transportation efficiency, safety, and related services is increasing in urban vehicular networks. Within such networks, roadside units (RSUs) serve as intermediates in facilitating communication. Therefore, the deployment of RSUs is of utmost importance in ensuring the quality of communication services. However, the optimization objectives, such as time delay and deployment cost, are commonly developed from diverse perspectives. As a result, it is possible that conflicts may arise among the objectives. Furthermore, in urban environments, the presence of various obstacles, such as buildings, gardens, lakes, and other infrastructure, poses challenges for the deployment of RSUs. Hence, the deployment encounters significant difficulties due to the existence of multiple objectives, constraints imposed by obstacles, and the necessity to explore a large-scale optimization space. To address this issue, two versions of mult
    
[^101]: SAR图像中用于船只检测的Wilcoxon非参数化CFAR方案

    Wilcoxon Nonparametric CFAR Scheme for Ship Detection in SAR Image

    [https://arxiv.org/abs/2402.18579](https://arxiv.org/abs/2402.18579)

    提出并分析了用于SAR图像中船只检测的Wilcoxon非参数CFAR方案，可以在没有已知杂波分布假设的情况下维持目标检测的恒定虚警率

    

    常数虚警率（CFAR）检测算法广泛应用于目前SAR图像中检测船只目标，这些算法基于各种统计分布，如高斯分布、Gamma分布、Weibull分布、对数正态分布、G0分布、alpha稳定分布等。然而，SAR图像中的杂散背景复杂多变。当实际杂散背景偏离假定的统计分布时，参数化CFAR检测器的性能将下降。除了参数化CFAR方案，还有另一类非参数化CFAR检测器，可以在没有已知杂波分布的假设情况下保持目标检测的恒定虚警率。在这项工作中，提出并分析了用于SAR图像中船只检测的Wilcoxon非参数化CFAR方案，并推导了Wilcoxon非参数检测器的虚警率的封闭形式以确定

    arXiv:2402.18579v1 Announce Type: cross  Abstract: The parametric constant false alarm rate (CFAR) detection algorithms which are based on various statistical distributions, such as Gaussian, Gamma, Weibull, log-normal, G0 distribution, alpha-stable distribution, etc, are most widely used to detect the ship targets in SAR image at present. However, the clutter background in SAR images is complicated and variable. When the actual clutter background deviates from the assumed statistical distribution, the performance of the parametric CFAR detector will deteriorate. In addition to the parametric CFAR schemes, there is another class of nonparametric CFAR detectors which can maintain a constant false alarm rate for the target detection without the assumption of a known clutter distribution. In this work, the Wilcoxon nonparametric CFAR scheme for ship detection in SAR image is proposed and analyzed, and a closed form of the false alarm rate for the Wilcoxon nonparametric detector to determi
    
[^102]: 运动引导的令牌压缩用于高效的遮蔽视频建模

    Motion Guided Token Compression for Efficient Masked Video Modeling

    [https://arxiv.org/abs/2402.18577](https://arxiv.org/abs/2402.18577)

    运动引导的令牌压缩（MGTC）方法旨在通过提供更小但更具代表性的令牌集来减少Transformer模型处理视频时的计算负担。

    

    近期Transformer模型在增强视频理解方面取得了显著进展。然而，由于注意力机制所带来的O($N^2$)计算复杂度使得面对视频的高维度时存在着相当大的计算障碍。当我们尝试增加每秒帧数（FPS）以提高运动捕捉能力时，这一挑战尤为突出。这样的追求很可能引入冗余，加剧现有的计算限制。本文首先展示了通过提高FPS率所实现的增强性能。此外，我们提出了一种新颖的方法，即运动引导的令牌压缩（MGTC），以赋能Transformer模型利用更小但更具代表性的令牌集来进行全面的视频表示。因此，这大大减少了计算负担，而且保持了整体

    arXiv:2402.18577v1 Announce Type: cross  Abstract: Recent developments in Transformers have achieved notable strides in enhancing video comprehension. Nonetheless, the O($N^2$) computation complexity associated with attention mechanisms presents substantial computational hurdles when dealing with the high dimensionality of videos. This challenge becomes particularly pronounced when striving to increase the frames per second (FPS) to enhance the motion capturing capabilities. Such a pursuit is likely to introduce redundancy and exacerbate the existing computational limitations. In this paper, we initiate by showcasing the enhanced performance achieved through an escalation in the FPS rate. Additionally, we present a novel approach, Motion Guided Token Compression (MGTC), to empower Transformer models to utilize a smaller yet more representative set of tokens for comprehensive video representation. Consequently, this yields substantial reductions in computational burden and remains seaml
    
[^103]: 利用PSO-RDV框架改善人工神经网络的预测能力

    Improved Forecasting Using a PSO-RDV Framework to Enhance Artificial Neural Network

    [https://arxiv.org/abs/2402.18576](https://arxiv.org/abs/2402.18576)

    本研究提出利用PSO-RDV框架改进预测方法，通过采用随机下降速度惯性权重（RDV IW）技术提高了粒子群优化（PSO）的收敛性和人工神经网络（ANN）的准确性。

    

    决策和规划长期以来一直严重依赖于基于人工智能的预测。政府和公众在潜在未来公共卫生不确定性面临风险最小化和利益最大化。本研究利用改进的预测方法，利用随机下降速度惯性权重（RDV IW）技术来提高粒子群优化（PSO）的收敛和人工神经网络（ANN）的准确性。 受高尔夫球运动启发，IW技术修改了粒子接近解决方案点时的速度，使其呈现抛物线下降结构。 仿真结果显示，建议的预测模型使用[0.4, 0.9]的alpha和alpha_dump组合，相对于旧模型在位置误差上有6.36％的改进，计算时间上有11.75％的改进，从而提高了其收敛性。 它达到了最优水平。

    arXiv:2402.18576v1 Announce Type: cross  Abstract: Decision making and planning have long relied heavily on AI-driven forecasts. The government and the general public are working to minimize the risks while maximizing benefits in the face of potential future public health uncertainties. This study used an improved method of forecasting utilizing the Random Descending Velocity Inertia Weight (RDV IW) technique to improve the convergence of Particle Swarm Optimization (PSO) and the accuracy of Artificial Neural Network (ANN). The IW technique, inspired by the motions of a golf ball, modified the particles' velocities as they approached the solution point to a parabolically descending structure. Simulation results revealed that the proposed forecasting model with [0.4, 0.9] combination of alpha and alpha_dump exhibits a 6.36% improvement in position error and 11.75% improvement in computational time compared to the old model, thus, improving its convergence. It reached the optimum level a
    
[^104]: DiffuseRAW：端到端生成RAW图像处理用于低光照图像

    DiffuseRAW: End-to-End Generative RAW Image Processing for Low-Light Images

    [https://arxiv.org/abs/2402.18575](https://arxiv.org/abs/2402.18575)

    本研究提出了DiffuseRAW，一个端到端生成RAW图像处理方法，重点解决了低光照图像处理中整个图像处理管道学习的问题。

    

    在极低光条件下成像面临着巨大挑战，由于最小光子捕获引起的低信噪比（SNR），这是一个逆问题。以前，扩散模型已经用于多种生成任务和图像到图像任务，但这些模型作为后处理步骤。这些扩散模型是在处理后的图像上训练的，并在处理后的图像上进行学习。然而，这种方法通常不适用于极低光任务。与低光图像增强或图像到图像增强任务不同，我们解决了从RAW图像到处理后图像的整个图像处理管道学习任务。对于这个任务，传统的图像处理管道通常由多个专门化部分组成，过度依赖下游任务。与这些不同，我们开发了一种新的生成ISP，依赖于微调潜在的扩散模型o

    arXiv:2402.18575v1 Announce Type: cross  Abstract: Imaging under extremely low-light conditions presents a significant challenge and is an ill-posed problem due to the low signal-to-noise ratio (SNR) caused by minimal photon capture. Previously, diffusion models have been used for multiple kinds of generative tasks and image-to-image tasks, however, these models work as a post-processing step. These diffusion models are trained on processed images and learn on processed images. However, such approaches are often not well-suited for extremely low-light tasks. Unlike the task of low-light image enhancement or image-to-image enhancement, we tackle the task of learning the entire image-processing pipeline, from the RAW image to a processed image. For this task, a traditional image processing pipeline often consists of multiple specialized parts that are overly reliant on the downstream tasks. Unlike these, we develop a new generative ISP that relies on fine-tuning latent diffusion models o
    
[^105]: 用于满足多样用户偏好的算术控制LLMs：具有多目标奖励的方向偏好对齐

    Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards

    [https://arxiv.org/abs/2402.18571](https://arxiv.org/abs/2402.18571)

    提出了方向偏好对齐（DPA）框架，通过多目标奖励模拟不同偏好配置，以实现用户相关的偏好控制。

    

    针对大型语言模型（LLMs）的精细控制仍然是一个重要挑战，阻碍了它们适应各种用户需求。本文提出了方向偏好对齐（DPA）框架，通过多目标奖励建模来表示多样化的偏好配置，将用户偏好建模为奖励空间中的方向（即单位向量）以实现用户相关的偏好控制。

    arXiv:2402.18571v1 Announce Type: cross  Abstract: Fine-grained control over large language models (LLMs) remains a significant challenge, hindering their adaptability to diverse user needs. While Reinforcement Learning from Human Feedback (RLHF) shows promise in aligning LLMs, its reliance on scalar rewards often limits its ability to capture diverse user preferences in real-world applications. To address this limitation, we introduce the Directional Preference Alignment (DPA) framework. Unlike the scalar-reward RLHF, DPA incorporates multi-objective reward modeling to represent diverse preference profiles. Additionally, DPA models user preferences as directions (i.e., unit vectors) in the reward space to achieve user-dependent preference control. Our method involves training a multi-objective reward model and then fine-tuning the LLM with a preference-conditioned variant of Rejection Sampling Finetuning (RSF), an RLHF method adopted by Llama 2. This method enjoys a better performance
    
[^106]: 语言模型表达自我和他人信念

    Language Models Represent Beliefs of Self and Others

    [https://arxiv.org/abs/2402.18496](https://arxiv.org/abs/2402.18496)

    通过神经激活线性解析语言模型中代理人观点下的信念状态，揭示了大型语言模型内部表述自我和他人信念，这对社会推理过程至关重要，并在多样社会推理任务中具有潜在的泛化能力。

    

    理解和归因心理状态，即心灵理论（ToM），被视为人类社会推理的基本能力。虽然大型语言模型（LLMs）似乎具有某些ToM能力，但这些能力背后的机制仍然令人费解。在本研究中，我们发现通过语言模型的神经激活线性解码各个代理人观点下的信念状态是可能的，这表明存在自我的内部表述和他人信念的表示。通过操纵这些表征，我们观察到模型的ToM性能发生显著变化，突显了其在社会推理过程中的关键作用。此外，我们的发现还延伸到涉及不同因果推理模式的多样社会推理任务，暗示了这些表征的潜在泛化能力。

    arXiv:2402.18496v1 Announce Type: new  Abstract: Understanding and attributing mental states, known as Theory of Mind (ToM), emerges as a fundamental capability for human social reasoning. While Large Language Models (LLMs) appear to possess certain ToM abilities, the mechanisms underlying these capabilities remain elusive. In this study, we discover that it is possible to linearly decode the belief status from the perspectives of various agents through neural activations of language models, indicating the existence of internal representations of self and others' beliefs. By manipulating these representations, we observe dramatic changes in the models' ToM performance, underscoring their pivotal role in the social reasoning process. Additionally, our findings extend to diverse social reasoning tasks that involve different causal inference patterns, suggesting the potential generalizability of these representations.
    
[^107]: FinAgent: 用于金融交易的多模态基础代理：工具增强、多样化和通用

    FinAgent: A Multimodal Foundation Agent for Financial Trading: Tool-Augmented, Diversified, and Generalist

    [https://arxiv.org/abs/2402.18485](https://arxiv.org/abs/2402.18485)

    FinAgent是一个多模态基础代理，通过工具增强用于金融交易，具有独特的双重反射模块，可以处理多样化的数据并快速适应市场动态。

    

    金融交易是市场的重要组成部分，受到新闻、价格和K线图等多模态信息构成的信息景观的影响，涵盖了诸如量化交易和不同资产的高频交易等多样化任务。尽管深度学习和强化学习等先进AI技术在金融领域得到广泛应用，但它们在金融交易任务中的应用往往面临着多模态数据处理不足和跨不同任务有限泛化能力的挑战。为了解决这些挑战，我们提出了FinAgent，一个具有工具增强功能的多模态基础代理，用于金融交易。FinAgent的市场智能模块处理各种数据-数值、文本和图像-以准确分析金融市场。其独特的双重反射模块不仅能够快速适应市场动态，还融合了多样化的记忆检索。

    arXiv:2402.18485v1 Announce Type: cross  Abstract: Financial trading is a crucial component of the markets, informed by a multimodal information landscape encompassing news, prices, and Kline charts, and encompasses diverse tasks such as quantitative trading and high-frequency trading with various assets. While advanced AI techniques like deep learning and reinforcement learning are extensively utilized in finance, their application in financial trading tasks often faces challenges due to inadequate handling of multimodal data and limited generalizability across various tasks. To address these challenges, we present FinAgent, a multimodal foundational agent with tool augmentation for financial trading. FinAgent's market intelligence module processes a diverse range of data-numerical, textual, and visual-to accurately analyze the financial market. Its unique dual-level reflection module not only enables rapid adaptation to market dynamics but also incorporates a diversified memory retri
    
[^108]: 一个针对大型视觉语言模型图像推理和描述的认知评估基准

    A Cognitive Evaluation Benchmark of Image Reasoning and Description for Large Vision Language Models

    [https://arxiv.org/abs/2402.18409](https://arxiv.org/abs/2402.18409)

    提出了一个新颖的评估基准，用于评估大型视觉语言模型的认知能力，发现LVLMs与人类之间存在较大的认知能力差距。

    

    尽管大型视觉语言模型(LVLMs)近年来取得了成功，但它们很少受到全面的认知能力测试。受到人类认知测试中广泛使用的“偷饼干”任务的启发，我们提出了一个新颖的评估基准，利用具有丰富语义的图像评估LVLMs的高级认知能力。它定义了八种推理能力，并包括图像描述任务和视觉问答任务。我们对知名LVLMs进行的评估表明，在LVLMs和人类之间仍存在较大的认知能力差距。

    arXiv:2402.18409v1 Announce Type: new  Abstract: Large Vision Language Models (LVLMs), despite their recent success, are hardly comprehensively tested for their cognitive abilities. Inspired by the prevalent use of the "Cookie Theft" task in human cognition test, we propose a novel evaluation benchmark to evaluate high-level cognitive ability of LVLMs using images with rich semantics. It defines eight reasoning capabilities and consists of an image description task and a visual question answering task. Our evaluation on well-known LVLMs shows that there is still a large gap in cognitive ability between LVLMs and humans.
    
[^109]: 动力系统重构中的跨领域泛化

    Out-of-Domain Generalization in Dynamical Systems Reconstruction

    [https://arxiv.org/abs/2402.18377](https://arxiv.org/abs/2402.18377)

    该论文提供了一个解决动力系统重构中泛化问题的正式框架, 并阐述了跨领域泛化在DSR中与机器学习其他领域的不同之处

    

    在科学中，我们致力于找到在经验现象背后的控制方程和动力规则。传统上，科学模型是通过人类洞察和实验周期推导出来的，最近深度学习技术已经被用来直接从时间序列数据中重构动力系统（DS）。最先进的动力系统重构（DSR）方法在捕捉观察到的DS的不变和长期特性方面表现出前景，但它们泛化到未观察领域的能力仍然是一个待解决的挑战。然而，这是我们期望从任何可行的科学理论中获得的至关重要的属性。在这项工作中，我们提供了一个正式框架，用于解决DSR中的泛化问题。我们解释了为什么以及如何DSR中的跨领域（OOD）泛化（OODG）与其他机器学习领域中考虑的OODG有根本区别。我们介绍基于拓扑概念和符号的数学概念，并说明

    arXiv:2402.18377v1 Announce Type: new  Abstract: In science we are interested in finding the governing equations, the dynamical rules, underlying empirical phenomena. While traditionally scientific models are derived through cycles of human insight and experimentation, recently deep learning (DL) techniques have been advanced to reconstruct dynamical systems (DS) directly from time series data. State-of-the-art dynamical systems reconstruction (DSR) methods show promise in capturing invariant and long-term properties of observed DS, but their ability to generalize to unobserved domains remains an open challenge. Yet, this is a crucial property we would expect from any viable scientific theory. In this work, we provide a formal framework that addresses generalization in DSR. We explain why and how out-of-domain (OOD) generalization (OODG) in DSR profoundly differs from OODG considered elsewhere in machine learning. We introduce mathematical notions based on topological concepts and ergo
    
[^110]: HearHere: 通过基于人工智能的网络系统缓解新闻消费中的“回声室”现象

    HearHere: Mitigating Echo Chambers in News Consumption through an AI-based Web System

    [https://arxiv.org/abs/2402.18222](https://arxiv.org/abs/2402.18222)

    HearHere是一个基于人工智能的网络系统，旨在帮助用户从不同视角融合信息和观点，以减轻新闻消费中“回声室”现象。

    

    目前正在大力努力减轻“回声室”所带来的负面影响，包括更容易受到虚假新闻的影响以及对接受科学证据的抗拒。本文提出了HearHere，这是一个基于人工智能的网络系统，旨在帮助用户从不同视角融合信息和观点。HearHere通过两种可视化方式促进了新闻信息消费的关键流程。

    arXiv:2402.18222v1 Announce Type: cross  Abstract: Considerable efforts are currently underway to mitigate the negative impacts of echo chambers, such as increased susceptibility to fake news and resistance towards accepting scientific evidence. Prior research has presented the development of computer systems that support the consumption of news information from diverse political perspectives to mitigate the echo chamber effect. However, existing studies still lack the ability to effectively support the key processes of news information consumption and quantitatively identify a political stance towards the information. In this paper, we present HearHere, an AI-based web system designed to help users accommodate information and opinions from diverse perspectives. HearHere facilitates the key processes of news information consumption through two visualizations. Visualization 1 provides political news with quantitative political stance information, derived from our graph-based political c
    
[^111]: 量子方法研究合成少数类过采样技术（SMOTE）

    A Quantum Approach to Synthetic Minority Oversampling Technique (SMOTE)

    [https://arxiv.org/abs/2402.17398](https://arxiv.org/abs/2402.17398)

    使用量子计算技术提出了Quantum-SMOTE方法，可以解决机器学习数据集中的类别不平衡问题，并引入了旋转角度、少数类百分比和分裂因子等超参数，实现了对合成数据生成过程的更好控制。

    

    这篇论文提出了Quantum-SMOTE方法，这是一种使用量子计算技术来解决机器学习数据集中普遍存在的类别不平衡问题的新颖解决方案。Quantum-SMOTE受到合成少数类过采样技术（SMOTE）的启发，利用量子过程如交换测试和量子旋转生成合成数据点。该方法与传统的SMOTE算法使用K-最近邻（KNN）和欧氏距离的方式有所不同，能够从少数类数据点生成合成实例而无需依赖于邻近性。算法通过引入旋转角度、少数类百分比和分裂因子等超参数，可以更好地控制合成数据生成过程，从而实现对特定数据集需求的定制。该方法在TelecomChurn公共数据集上进行了测试，并与两种主要的分类算法进行了评估。

    arXiv:2402.17398v1 Announce Type: cross  Abstract: The paper proposes the Quantum-SMOTE method, a novel solution that uses quantum computing techniques to solve the prevalent problem of class imbalance in machine learning datasets. Quantum-SMOTE, inspired by the Synthetic Minority Oversampling Technique (SMOTE), generates synthetic data points using quantum processes such as swap tests and quantum rotation. The process varies from the conventional SMOTE algorithm's usage of K-Nearest Neighbors (KNN) and Euclidean distances, enabling synthetic instances to be generated from minority class data points without relying on neighbor proximity. The algorithm asserts greater control over the synthetic data generation process by introducing hyperparameters such as rotation angle, minority percentage, and splitting factor, which allow for customization to specific dataset requirements. The approach is tested on a public dataset of TelecomChurn and evaluated alongside two prominent classification
    
[^112]: 多旋翼飞行器定位的主动推进噪声塑造

    Active propulsion noise shaping for multi-rotor aircraft localization

    [https://arxiv.org/abs/2402.17289](https://arxiv.org/abs/2402.17289)

    本文提出通过主动控制和塑造旋翼产生的飞行器推进噪声来有利于定位任务，提出了一种基于自噪声和时间变化旋翼相位调制的神经网络架构，实现了准确和稳健的定位。

    

    多旋翼空中自主载具(MAVs)主要依赖视觉进行导航。然而，视觉定位和测距技术在低或直射阳光下表现不佳，视野有限，并且容易受到遮挡的影响。声学传感可以作为视觉的补充或甚至替代方式在许多情况下使用，而且还具有更低的系统成本和能源占用量，这对微型飞行器尤为重要。本文提出通过主动控制和塑造由旋翼产生的飞行器推进噪声，以有利于定位任务，而非将其视为有害噪声。我们提出了一种基于自噪声的神经网络架构，用于在已知环境中进行定位。我们表明，同时训练学习时间变化的旋翼相位调制，可以实现准确和稳健的定位。所提出的方法进行了评估。

    arXiv:2402.17289v1 Announce Type: cross  Abstract: Multi-rotor aerial autonomous vehicles (MAVs) primarily rely on vision for navigation purposes. However, visual localization and odometry techniques suffer from poor performance in low or direct sunlight, a limited field of view, and vulnerability to occlusions. Acoustic sensing can serve as a complementary or even alternative modality for vision in many situations, and it also has the added benefits of lower system cost and energy footprint, which is especially important for micro aircraft. This paper proposes actively controlling and shaping the aircraft propulsion noise generated by the rotors to benefit localization tasks, rather than considering it a harmful nuisance. We present a neural network architecture for selfnoise-based localization in a known environment. We show that training it simultaneously with learning time-varying rotor phase modulation achieves accurate and robust localization. The proposed methods are evaluated u
    
[^113]: MISC: 由大型多模态模型驱动的超低比特率图像语义压缩

    MISC: Ultra-low Bitrate Image Semantic Compression Driven by Large Multimodal Model

    [https://arxiv.org/abs/2402.16749](https://arxiv.org/abs/2402.16749)

    本文提出了一种名为MISC的方法，通过大型多模态模型实现了超低比特率图像语义压缩，在保持与真实数据一致性的同时实现了感知质量的平衡。

    

    随着存储和通信协议的演变，超低比特率图像压缩已成为一个极具需求的话题。然而，现有的压缩算法必须在超低比特率下要么牺牲与真实数据的一致性，要么牺牲感知质量。近年来，大型多模态模型（LMM）的快速发展使得平衡这两个目标变得可能。为解决这一问题，本文提出了一种称为多模态图像语义压缩（MISC）的方法，包括一个LMM编码器用于提取图像的语义信息、一个地图编码器用于定位与语义对应的区域、一个图像编码器生成极度压缩的比特流，以及一个解码器根据上述信息重构图像。实验结果表明，我们提出的MISC适用于压缩传统自然感知图像（NSIs）和新兴AI生成图像。

    arXiv:2402.16749v2 Announce Type: replace-cross  Abstract: With the evolution of storage and communication protocols, ultra-low bitrate image compression has become a highly demanding topic. However, existing compression algorithms must sacrifice either consistency with the ground truth or perceptual quality at ultra-low bitrate. In recent years, the rapid development of the Large Multimodal Model (LMM) has made it possible to balance these two goals. To solve this problem, this paper proposes a method called Multimodal Image Semantic Compression (MISC), which consists of an LMM encoder for extracting the semantic information of the image, a map encoder to locate the region corresponding to the semantic, an image encoder generates an extremely compressed bitstream, and a decoder reconstructs the image based on the above information. Experimental results show that our proposed MISC is suitable for compressing both traditional Natural Sense Images (NSIs) and emerging AI-Generated Images 
    
[^114]: GenAINet：通过知识传输和推理实现无线集体智能

    GenAINet: Enabling Wireless Collective Intelligence via Knowledge Transfer and Reasoning

    [https://arxiv.org/abs/2402.16631](https://arxiv.org/abs/2402.16631)

    该论文提出了基于GenAI的GenAINet框架，通过知识传输和推理实现无线集体智能，为6G时代铺平了通向人工通用智能的道路。

    

    arXiv:2402.16631v2 声明类型：替换 摘要：生成人工智能（GenAI）和通信网络被期望在6G中具有突破性的协同作用。通过无线网络连接GenAI代理可能会释放集体智能的力量，并为人工通用智能（AGI）铺平道路。然而，当前的无线网络设计为“数据管道”，并不适合容纳和利用GenAI的力量。在本文中，我们提出了GenAINet框架，其中分布式GenAI代理传达知识（高级概念或摘要）以完成任意任务。首先，我们提供一个网络架构，整合了GenAI能力，以管理网络协议和应用程序。在此基础上，我们通过提出一种语义本地化的GenAINet来研究有效的通信和推理问题。具体来说，GenAI代理从多模态原始数据中提取语义概念，构建一个知识库表示

    arXiv:2402.16631v2 Announce Type: replace  Abstract: Generative artificial intelligence (GenAI) and communication networks are expected to have groundbreaking synergies in 6G. Connecting GenAI agents over a wireless network can potentially unleash the power of collective intelligence and pave the way for artificial general intelligence (AGI). However, current wireless networks are designed as a "data pipe" and are not suited to accommodate and leverage the power of GenAI. In this paper, we propose the GenAINet framework in which distributed GenAI agents communicate knowledge (high-level concepts or abstracts) to accomplish arbitrary tasks. We first provide a network architecture integrating GenAI capabilities to manage both network protocols and applications. Building on this, we investigate effective communication and reasoning problems by proposing a semantic-native GenAINet. Specifically, GenAI agents extract semantic concepts from multi-modal raw data, build a knowledgebase represe
    
[^115]: 通过反向翻译防御LLMs免受越狱攻击

    Defending LLMs against Jailbreaking Attacks via Backtranslation

    [https://arxiv.org/abs/2402.16459](https://arxiv.org/abs/2402.16459)

    通过反向翻译来防御LLMs免受越狱攻击，将生成的反向翻译提示用于揭示原始提示的实际意图，提高了模型的安全性。

    

    尽管许多大型语言模型（LLMs）已经被训练成拒绝有害请求，但它们仍然容易受到越狱攻击的影响，这种攻击会重写原始提示以隐藏其有害意图。在本文中，我们提出了一种新方法，通过“反向翻译”来防御LLMs免受越狱攻击。具体来说，给定目标LLM从输入提示生成的初始响应，我们的反向翻译提示一个语言模型来推断可以导致该响应的输入提示。推断的提示称为反向翻译提示，倾向于揭示原始提示的实际意图，因为它是基于LLM的响应生成的，不是直接由攻击者操纵的。然后，我们再次在反向翻译提示上运行目标LLM，如果模型拒绝了反向翻译提示，则拒绝原始提示。我们解释了所提出的防御措施对其有效性的几个好处。

    arXiv:2402.16459v1 Announce Type: cross  Abstract: Although many large language models (LLMs) have been trained to refuse harmful requests, they are still vulnerable to jailbreaking attacks, which rewrite the original prompt to conceal its harmful intent. In this paper, we propose a new method for defending LLMs against jailbreaking attacks by ``backtranslation''. Specifically, given an initial response generated by the target LLM from an input prompt, our backtranslation prompts a language model to infer an input prompt that can lead to the response. The inferred prompt is called the backtranslated prompt which tends to reveal the actual intent of the original prompt, since it is generated based on the LLM's response and is not directly manipulated by the attacker. We then run the target LLM again on the backtranslated prompt, and we refuse the original prompt if the model refuses the backtranslated prompt. We explain that the proposed defense provides several benefits on its effectiv
    
[^116]: LLM推断揭示：调查与Roofline模型见解

    LLM Inference Unveiled: Survey and Roofline Model Insights

    [https://arxiv.org/abs/2402.16363](https://arxiv.org/abs/2402.16363)

    本文提出了一个基于Roofline模型的框架，用于系统分析LLM推断技术，帮助识别部署中的瓶颈，并为更有效地部署LLM提供策略。

    

    高效大语言模型（LLM）推断领域正在迅速发展，提供了机遇和挑战的独特结合。虽然该领域已经扩展并充满活力，但至今还没有一个简明的框架来分析LLM推断的各种方法，以便清晰地理解这一领域。我们的调查不仅总结了当前研究现状，还基于Roofline模型引入了一个框架，用于系统分析LLM推断技术。这一框架能够帮助识别LLM部署中的瓶颈，并更深入地了解在实际设备上的实际方面，从而为部署LLM提供更有效的策略。此外，我们还系统地汇总了高效LLM推断的最新进展，涵盖关键领域，比如权重优化（如知识蒸馏和量化）。

    arXiv:2402.16363v1 Announce Type: cross  Abstract: The field of efficient Large Language Model (LLM) inference is rapidly evolving, presenting a unique blend of opportunities and challenges. Although the field has expanded and is vibrant, there hasn't been a concise framework that analyzes the various methods of LLM Inference to provide a clear understanding of this domain. Our survey stands out from traditional literature reviews by not only summarizing the current state of research but also by introducing a framework based on roofline model for systematic analysis of LLM inference techniques. This framework enables identifying the bottlenecks in LLM deployments and provides a deeper understanding of the practical aspects on real devices, thereby informing more effective strategies for deploying LLM. Furthermore, we systematically collate the latest advancements in efficient LLM inference, covering crucial areas such as weight optimization (e.g., Knowledge Distillation and Quantizatio
    
[^117]: 人工智能与人类共同创作编程课程中的示例

    Human-AI Co-Creation of Worked Examples for Programming Classes

    [https://arxiv.org/abs/2402.16235](https://arxiv.org/abs/2402.16235)

    人工智能与人类合作创作Java编程课程的示例，以减轻教师逐行解释大量示例的负担

    

    工作示例（典型编程问题的解决方案，以某种语言的源代码呈现，并用于解释编程课程中的主题）是编程课程中最受欢迎的学习内容之一。大多数用于向学生展示这些示例的方法和工具都基于对示例代码的逐行解释。然而，教师很少有时间为编程课程中通常使用的大量示例提供逐行解释。本文探讨并评估了一种人工智能与人类合作的方法，用于为Java编程撰写示例。我们介绍了一个用于创建Java工作示例的编写系统，该系统生成代码解释的初始版本，并将其呈现给教师以在必要时进行编辑。我们还提出了一项评估使用此方法创建的解释质量的研究。

    arXiv:2402.16235v1 Announce Type: cross  Abstract: Worked examples (solutions to typical programming problems presented as a source code in a certain language and are used to explain the topics from a programming class) are among the most popular types of learning content in programming classes. Most approaches and tools for presenting these examples to students are based on line-by-line explanations of the example code. However, instructors rarely have time to provide line-by-line explanations for a large number of examples typically used in a programming class. In this paper, we explore and assess a human-AI collaboration approach to authoring worked examples for Java programming. We introduce an authoring system for creating Java worked examples that generates a starting version of code explanations and presents it to the instructor to edit if necessary.We also present a study that assesses the quality of explanations created with this approach
    
[^118]: ROS-Causal：基于ROS的人机交互应用因果分析框架

    ROS-Causal: A ROS-based Causal Analysis Framework for Human-Robot Interaction Applications

    [https://arxiv.org/abs/2402.16068](https://arxiv.org/abs/2402.16068)

    ROS-Causal是一个基于ROS的框架，用于在人机空间交互中进行数据收集和因果发现，解决了机器人领域中缺乏因果发现方法在ROS生态系统内实现的问题。

    

    在人类共享空间部署机器人需要理解附近Agent和物体之间的交互。通过因果推理对因果关系建模有助于预测人类行为并预测机器人干预。然而，一个关键挑战是现有的因果发现方法目前缺乏在ROS生态系统内部的实现，这是机器人领域的事实标准，阻碍了在机器人领域的有效利用。为了解决这一差距，本文引入了ROS-Causal，这是一个基于ROS的框架，用于机器人上的数据收集和因果发现在人机空间交互中。集成了ROS的临时模拟器展示了该方法的有效性，展示了机器人在数据收集过程中生成因果模型。ROS-Causal可在GitHub上找到：https://github.com/lcastri/roscausal.git。

    arXiv:2402.16068v1 Announce Type: cross  Abstract: Deploying robots in human-shared spaces requires understanding interactions among nearby agents and objects. Modelling cause-and-effect relations through causal inference aids in predicting human behaviours and anticipating robot interventions. However, a critical challenge arises as existing causal discovery methods currently lack an implementation inside the ROS ecosystem, the standard de facto in robotics, hindering effective utilisation in robotics. To address this gap, this paper introduces ROS-Causal, a ROS-based framework for onboard data collection and causal discovery in human-robot spatial interactions. An ad-hoc simulator, integrated with ROS, illustrates the approach's effectiveness, showcasing the robot onboard generation of causal models during data collection. ROS-Causal is available on GitHub: https://github.com/lcastri/roscausal.git.
    
[^119]: GraphEdit：用于图结构学习的大型语言模型

    GraphEdit: Large Language Models for Graph Structure Learning

    [https://arxiv.org/abs/2402.15183](https://arxiv.org/abs/2402.15183)

    本研究提出了一种名为GraphEdit的方法，利用大型语言模型（LLMs）学习复杂的图结构化数据中的节点关系，通过在图结构上进行指导调整，增强LLMs的推理能力，从而提高图结构学习的可靠性。

    

    图结构学习（GSL）致力于通过生成新颖的图结构来捕捉图结构数据中节点之间的固有依赖性和相互作用。本文提出了一种名为GraphEdit的方法，利用大型语言模型（LLMs）学习图结构化数据中复杂的节点关系。通过在图结构上进行指导调整，增强LLMs的推理能力，我们旨在克服显式图结构信息带来的挑战，并提高图结构学习的可靠性。

    arXiv:2402.15183v1 Announce Type: cross  Abstract: Graph Structure Learning (GSL) focuses on capturing intrinsic dependencies and interactions among nodes in graph-structured data by generating novel graph structures. Graph Neural Networks (GNNs) have emerged as promising GSL solutions, utilizing recursive message passing to encode node-wise inter-dependencies. However, many existing GSL methods heavily depend on explicit graph structural information as supervision signals, leaving them susceptible to challenges such as data noise and sparsity. In this work, we propose GraphEdit, an approach that leverages large language models (LLMs) to learn complex node relationships in graph-structured data. By enhancing the reasoning capabilities of LLMs through instruction-tuning over graph structures, we aim to overcome the limitations associated with explicit graph structural information and enhance the reliability of graph structure learning. Our approach not only effectively denoises noisy co
    
[^120]: EyeTrans: 合并人类和机器注意力以实现神经代码摘要

    EyeTrans: Merging Human and Machine Attention for Neural Code Summarization

    [https://arxiv.org/abs/2402.14096](https://arxiv.org/abs/2402.14096)

    引入EyeTrans方法，将人类注意力融入机器注意力，以增强神经代码摘要能力。

    

    Neural code summarization 利用深度学习模型自动生成代码片段的简要自然语言摘要。Transformer模型的发展导致在模型设计中广泛使用注意力机制。本文提出一种将人类注意力融入机器注意力以增强神经代码摘要的方法。为了实现这一融合并验证这一假设，引入了EyeTrans，包括三个步骤：(1) 进行了大量的眼动人类研究，收集和预分析数据用于模型训练，(2) 我们设计了一个以数据为中心的方法来整合人类注意力及

    arXiv:2402.14096v1 Announce Type: cross  Abstract: Neural code summarization leverages deep learning models to automatically generate brief natural language summaries of code snippets. The development of Transformer models has led to extensive use of attention during model design. While existing work has primarily and almost exclusively focused on static properties of source code and related structural representations like the Abstract Syntax Tree (AST), few studies have considered human attention, that is, where programmers focus while examining and comprehending code. In this paper, we develop a method for incorporating human attention into machine attention to enhance neural code summarization. To facilitate this incorporation and vindicate this hypothesis, we introduce EyeTrans, which consists of three steps: (1) we conduct an extensive eye-tracking human study to collect and pre-analyze data for model training, (2) we devise a data-centric approach to integrate human attention wit
    
[^121]: E2USD：用于多元时间序列的高效而有效的无监督状态检测

    E2USD: Efficient-yet-effective Unsupervised State Detection for Multivariate Time Series

    [https://arxiv.org/abs/2402.14041](https://arxiv.org/abs/2402.14041)

    E2USD提出了一种有效的无监督多元时间序列状态检测方法，利用了快速傅里叶变换和双视图嵌入模块进行编码，以及通过对抗学习方法消除假阴性，从而实现了SOTA准确性并显著降低了计算开销。

    

    我们提出了E2USD方法，能够实现高效而准确的无监督多元时间序列状态检测。E2USD利用基于快速傅立叶变换的时间序列压缩器(FFTCompress)和分解的双视图嵌入模块(DDEM)，一起以低计算开销对输入的多元时间序列进行编码。此外，我们提出了一种假阴性取消对比学习方法(FNCCLearning)，以抵消假阴性的影响，并实现更友好的簇嵌入空间。为了在流式设置中进一步减少计算开销，我们引入了自适应阈值检测(ADATD)。通过使用六个基线模型和六个数据集进行全面实验，我们证明E2USD能够在显著降低计算开销的情况下达到SOTA的准确性。我们的代码可在https://github.com/AI4CTS/E2Usd 找到。

    arXiv:2402.14041v1 Announce Type: cross  Abstract: We propose E2USD that enables efficient-yet-accurate unsupervised MTS state detection. E2USD exploits a Fast Fourier Transform-based Time Series Compressor (FFTCompress) and a Decomposed Dual-view Embedding Module (DDEM) that together encode input MTSs at low computational overhead. Additionally, we propose a False Negative Cancellation Contrastive Learning method (FNCCLearning) to counteract the effects of false negatives and to achieve more cluster-friendly embedding spaces. To reduce computational overhead further in streaming settings, we introduce Adaptive Threshold Detection (ADATD). Comprehensive experiments with six baselines and six datasets offer evidence that E2USD is capable of SOTA accuracy at significantly reduced computational overhead. Our code is available at https://github.com/AI4CTS/E2Usd.
    
[^122]: 模式分析与机器智能领域文献综述的文献综述

    A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence

    [https://arxiv.org/abs/2402.12928](https://arxiv.org/abs/2402.12928)

    本文旨在提供对模式分析与机器智能领域文献综述的全面评估，引入大语言模型驱动的文献计量指标，并构建了RiPAMI元数据数据库和主题数据集以获取PAMI综述的统计特征。

    

    通过整合分散的知识，文献综述提供了对所研究主题的全面了解。然而，在模式分析与机器智能（PAMI）这一蓬勃发展的领域中，过多的综述引起了研究人员和评论者的关注。作为对这些关注的回应，本文旨在从多个角度全面审视PAMI领域的综述文献。

    arXiv:2402.12928v1 Announce Type: cross  Abstract: By consolidating scattered knowledge, the literature review provides a comprehensive understanding of the investigated topic. However, excessive reviews, especially in the booming field of pattern analysis and machine intelligence (PAMI), raise concerns for both researchers and reviewers. In response to these concerns, this Analysis aims to provide a thorough review of reviews in the PAMI field from diverse perspectives. First, large language model-empowered bibliometric indicators are proposed to evaluate literature reviews automatically. To facilitate this, a meta-data database dubbed RiPAMI, and a topic dataset are constructed, which are utilized to obtain statistical characteristics of PAMI reviews. Unlike traditional bibliometric measurements, the proposed article-level indicators provide real-time and field-normalized quantified assessments of reviews without relying on user-defined keywords. Second, based on these indicators, th
    
[^123]: 针对多维时间序列预测的随机投影层

    Random Projection Layers for Multidimensional Time Sires Forecasting

    [https://arxiv.org/abs/2402.10487](https://arxiv.org/abs/2402.10487)

    提出了一种全MLP时间序列预测架构RPMixer，通过将随机投影层集成到模型中，增加了块输出之间的多样性，提高了整体性能

    

    多层感知器（MLP）混合模型已被证明对时间序列预测问题有效。然而，当将此类模型应用于高维时间序列（例如空间-时间数据集中的时间序列）时，由于过拟合问题，其性能可能会下降。本文提出了一种全MLP时间序列预测架构，称为RPMixer。我们的方法利用了深度神经网络的集成式行为，其中网络中的每个单独块的作用类似于集成模型中的基本学习器，特别是在引入身份映射残差连接时。通过将随机投影层集成到我们的模型中，我们增加了块输出之间的多样性，从而提高了RPMixer的整体性能。对大规模空间-时间预测基准数据集进行的大量实验表明，我们提出的方法胜过了

    arXiv:2402.10487v1 Announce Type: cross  Abstract: All-Multi-Layer Perceptron (all-MLP) mixer models have been shown to be effective for time series forecasting problems. However, when such a model is applied to high-dimensional time series (e.g., the time series in a spatial-temporal dataset), its performance is likely to degrade due to overfitting issues. In this paper, we propose an all-MLP time series forecasting architecture, referred to as RPMixer. Our method leverages the ensemble-like behavior of deep neural networks, where each individual block within the network acts like a base learner in an ensemble model, especially when identity mapping residual connections are incorporated. By integrating random projection layers into our model, we increase the diversity among the blocks' outputs, thereby enhancing the overall performance of RPMixer. Extensive experiments conducted on large-scale spatial-temporal forecasting benchmark datasets demonstrate that our proposed method outperf
    
[^124]: 借鉴多体物理的归纳偏置的多激发投影模拟

    Multi-Excitation Projective Simulation with a Many-Body Physics Inspired Inductive Bias

    [https://arxiv.org/abs/2402.10192](https://arxiv.org/abs/2402.10192)

    该论文引入了多激发投影模拟（mePS），通过在超图上多个粒子的随机游走，解决了投影模拟（PS）无法模拟同时结合多个概念的思维的问题。

    

    随着深度学习的进步，依赖于机器学习的应用正在越来越多地融入日常生活。然而，大多数深度学习模型具有不透明的、类似于神谕般的特性，使得解释和理解它们的决策变得困难。这个问题导致了被称为可解释人工智能（XAI）的领域的发展。该领域中的一种方法称为投影模拟（PS），将思维过程建模为一个在具有概念附加的顶点的图上的粒子的随机游走。虽然这种描述具有各种好处，包括量化的可能性，但不能自然地用来模拟同时结合多个概念的思维。为了克服这个限制，我们引入了一种称为多激发投影模拟（mePS）的推广，它将思维过程视为超图上多个粒子的随机游走。

    arXiv:2402.10192v1 Announce Type: cross  Abstract: With the impressive progress of deep learning, applications relying on machine learning are increasingly being integrated into daily life. However, most deep learning models have an opaque, oracle-like nature making it difficult to interpret and understand their decisions. This problem led to the development of the field known as eXplainable Artificial Intelligence (XAI). One method in this field known as Projective Simulation (PS) models a chain-of-thought as a random walk of a particle on a graph with vertices that have concepts attached to them. While this description has various benefits, including the possibility of quantization, it cannot be naturally used to model thoughts that combine several concepts simultaneously. To overcome this limitation, we introduce Multi-Excitation Projective Simulation (mePS), a generalization that considers a chain-of-thought to be a random walk of several particles on a hypergraph. A definition for
    
[^125]: 自动驾驶应用中基于人工智能的软件元素固有多样化冗余安全机制

    Inherent Diverse Redundant Safety Mechanisms for AI-based Software Elements in Automotive Applications

    [https://arxiv.org/abs/2402.08208](https://arxiv.org/abs/2402.08208)

    本文研究了自动驾驶系统中基于人工智能的软件元素的作用和挑战，探讨了泛化问题以及过度自信的AI模型所带来的风险，并提出了解决方法。

    

    本文探讨了人工智能算法在自动驾驶系统中的作用和挑战，特别是基于人工智能的软件元素。这些人工智能系统在复杂和高维环境中执行实时关键功能，处理多模态感知、认知和决策任务，如运动规划、车道保持和紧急制动。一个主要关注点是AI模型在初始训练数据之外如何进行泛化。这种泛化问题在实时场景中变得明显，模型经常遇到不在其训练或验证数据中表示的输入。在这种情况下，尽管面临分布或领域转移，AI系统仍必须有效地运行。本文调查了在自动驾驶等安全关键应用中，过度自信的AI模型带来的风险。为了减轻这些风险，本文提出了训练AI模型的一些方法。

    This paper explores the role and challenges of Artificial Intelligence (AI) algorithms, specifically AI-based software elements, in autonomous driving systems. These AI systems are fundamental in executing real-time critical functions in complex and high-dimensional environments. They handle vital tasks like multi-modal perception, cognition, and decision-making tasks such as motion planning, lane keeping, and emergency braking. A primary concern relates to the ability (and necessity) of AI models to generalize beyond their initial training data. This generalization issue becomes evident in real-time scenarios, where models frequently encounter inputs not represented in their training or validation data. In such cases, AI systems must still function effectively despite facing distributional or domain shifts. This paper investigates the risk associated with overconfident AI models in safety-critical applications like autonomous driving. To mitigate these risks, methods for training AI m
    
[^126]: 通过基于垄断对话的社交场景模拟实现大型语言模型的自对齐

    Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation

    [https://arxiv.org/abs/2402.05699](https://arxiv.org/abs/2402.05699)

    本文提出了一个通过社交场景模拟来自对齐大型语言模型的方法，以减轻其被滥用造成的潜在不良影响。通过一个名为MATRIX的虚拟排练空间，LLM可以在回答查询前考虑社交后果，并通过MATRIX-simulated数据的微调，保持对人类价值的遵从和推理速度的平衡。实验证明，在温和假设下，带有MATRIX的LLM胜过了宪法AI。

    

    将大型语言模型(LLMs)与人类价值对齐，以减轻其被滥用造成的潜在不良影响，具有重要意义。本文借鉴社会学的见解，即认识到所有各方的关切是塑造人类价值观的关键因素，提出了一种自对齐LLMs的新方向：社交场景模拟。为此，我们提出了一个名为MATRIX的创新社交场景模拟器，它可以模拟用户输入查询周围的现实场景，使LLM在回答前能够考虑社交后果。MATRIX类似于一个“垄断对话”下的虚拟排练空间，LLM在其中扮演与查询相关的多个角色并进行自我实践。为了引入这种对齐能力，我们使用MATRIX模拟数据对LLM进行微调，确保其在不影响推理速度的情况下符合人类价值观。理论上，我们证明了在温和假设下，带有MATRIX的LLM胜过了宪法AI。最后，大量实验证实了我们的方法在多个任务上都取得了最佳性能。

    Aligning large language models (LLMs) with human values is imperative to mitigate potential adverse effects resulting from their misuse. Drawing from the sociological insight that acknowledging all parties' concerns is a key factor in shaping human values, this paper proposes a novel direction to align LLMs by themselves: social scene simulation. To achieve this, we present MATRIX, a novel social scene simulator that emulates realistic scenes around a user's input query, enabling the LLM to take social consequences into account before responding. MATRIX serves as a virtual rehearsal space, akin to a Monopolylogue, where the LLM performs diverse roles related to the query and practice by itself. To inject this alignment, we fine-tune the LLM with MATRIX-simulated data, ensuring adherence to human values without compromising inference speed. We theoretically show that the LLM with MATRIX outperforms Constitutional AI under mild assumptions. Finally, extensive experiments validate that ou
    
[^127]: 推进法律推理：将人工智能应用于处理全球法理中的复杂性和偏见的半自动化仲裁流程（SAAPs）

    Advancing Legal Reasoning: The Integration of AI to Navigate Complexities and Biases in Global Jurisprudence with Semi-Automated Arbitration Processes (SAAPs)

    [https://arxiv.org/abs/2402.04140](https://arxiv.org/abs/2402.04140)

    本研究通过整合先进的语言模型和人工智能技术，开发了名为SHIRLEY的应用程序，旨在识别法律判决中的偏见和逻辑不一致，并促进自动化、有效和一致的多方论证，以保证法律在不同司法管辖区内的一致应用。

    

    本研究采用了一种新颖的方法，对包括美国、英国、卢旺达、瑞典和香港在内的五个国家的法院判决进行了分析。本研究还探讨了人工智能（特别是生成式人工智能）和法律分析的最新进展交叉领域，强调了人工智能在识别人类偏见和促进法院判决的多方论证的自动化、有效和一致的角色，从而确保法律在各个司法管辖区内和跨司法管辖区的一致应用。通过结合先进的语言模型（ALMs）和新引入的人工智能与人类合作框架，本文旨在分析以ALMs为基础的基于Grounded Theory的法学实践研究设计。SHIRLEY是基于OpenAI的GPT技术构建的基于人工智能的应用程序，主要用于检测各种法律决定中的逻辑不一致和偏见。

    This study consists of a novel approach toward the analysis of court judgments spanning five countries, including the United States, the United Kingdom, Rwanda, Sweden and Hong Kong. This study also explores the intersection of the latest advancements in artificial intelligence (AI) and legal analysis, emphasizing the role of AI (specifically generative AI) in identifying human biases and facilitating automated, valid, and coherent multisided argumentation of court judgments with the goal of ensuring consistent application of laws in and across various jurisdictions. By incorporating Advanced Language Models (ALMs) and a newly introduced human-AI collaborative framework, this paper seeks to analyze Grounded Theory-based research design with Advanced Language Models (ALMs) in the practice of law. SHIRLEY is the name of the AI-based application (built on top of OpenAI's GPT technology), focusing on detecting logical inconsistencies and biases across various legal decisions. SHIRLEY analy
    
[^128]: 通过分层图解释揭示分子成分

    Unveiling Molecular Moieties through Hierarchical Graph Explainability

    [https://arxiv.org/abs/2402.01744](https://arxiv.org/abs/2402.01744)

    本论文提出了一种使用图神经网络和分层可解释人工智能技术的方法，能够准确预测生物活性并找到与之相关的最重要的成分。

    

    背景：图神经网络（GNN）作为一种强大的工具，在支持体外虚拟筛选方面已经出现多年。在这项工作中，我们提出了一种使用图卷积架构实现高精度多靶标筛选的GNN。我们还设计了一种分层可解释人工智能（XAI）技术，通过利用信息传递机制，在原子、环和整个分子层面上直接捕获信息，从而找到与生物活性预测相关的最重要的成分。结果：我们在支持虚拟筛选方面的二十个细胞周期依赖性激酶靶标上报道了一种最先进的GNN分类器。我们的分类器超越了作者提出的先前最先进方法。此外，我们还设计了一个仅针对CDK1的高灵敏度版本的GNN，以使用我们的解释器来避免多类别模型固有的偏差。分层解释器已经由一位专家化学家在19个CDK1批准药物上进行了验证。

    Background: Graph Neural Networks (GNN) have emerged in very recent years as a powerful tool for supporting in silico Virtual Screening. In this work we present a GNN which uses Graph Convolutional architectures to achieve very accurate multi-target screening. We also devised a hierarchical Explainable Artificial Intelligence (XAI) technique to catch information directly at atom, ring, and whole molecule level by leveraging the message passing mechanism. In this way, we find the most relevant moieties involved in bioactivity prediction. Results: We report a state-of-the-art GNN classifier on twenty Cyclin-dependent Kinase targets in support of VS. Our classifier outperforms previous SOTA approaches proposed by the authors. Moreover, a CDK1-only high-sensitivity version of the GNN has been designed to use our explainer in order to avoid the inherent bias of multi-class models. The hierarchical explainer has been validated by an expert chemist on 19 approved drugs on CDK1. Our explainer 
    
[^129]: BPDec: 揭示BERT预训练中掩码语言建模解码器的潜力

    BPDec: Unveiling the Potential of Masked Language Modeling Decoder in BERT pretraining

    [https://arxiv.org/abs/2401.15861](https://arxiv.org/abs/2401.15861)

    本文揭示了BPDec（BERT预训练解码器）的潜力，强调增强的掩码语言建模解码器设计及研究在BERT预训练中的重要性。

    

    BERT（来自Transformer的双向编码表示）通过其在许多任务上出色的性能彻底改变了自然语言处理领域。然而，大多数研究人员主要集中在与模型结构相关的增强，例如相对位置嵌入和更有效的注意机制。还有一些人深入研究了与掩码语言建模相关的预训练技巧，包括整词掩码。DeBERTa引入了一种针对BERT编码器模型进行预训练的增强解码器，证明效果非常显著。我们认为围绕增强掩码语言建模解码器的设计和研究并未得到应有的重视。在本文中，我们提出了几种增强解码器的设计，并介绍了BPDec（BERT预训练解码器），这是一种用于建模训练的新方法。通常，预训练的BERT模型会针对特定的自然语

    arXiv:2401.15861v2 Announce Type: replace-cross  Abstract: BERT (Bidirectional Encoder Representations from Transformers) has revolutionized the field of natural language processing through its exceptional performance on numerous tasks. Yet, the majority of researchers have mainly concentrated on enhancements related to the model structure, such as relative position embedding and more efficient attention mechanisms. Others have delved into pretraining tricks associated with Masked Language Modeling, including whole word masking. DeBERTa introduced an enhanced decoder adapted for BERT's encoder model for pretraining, proving to be highly effective. We argue that the design and research around enhanced masked language modeling decoders have been underappreciated. In this paper, we propose several designs of enhanced decoders and introduce BPDec (BERT Pretraining Decoder), a novel method for modeling training. Typically, a pretrained BERT model is fine-tuned for specific Natural Language 
    
[^130]: SERNet-Former: 带有注意力增强门和注意力融合网络的高效剩余网络语义分割方法

    SERNet-Former: Semantic Segmentation by Efficient Residual Network with Attention-Boosting Gates and Attention-Fusion Networks

    [https://arxiv.org/abs/2401.15741](https://arxiv.org/abs/2401.15741)

    这篇论文提出了一种名为SERNet-Former的高效剩余网络语义分割方法。它通过引入注意力增强门和注意力融合网络来改善语义分割方法的效率，并解决了从全局和局部上融合语义信息的问题。实验结果表明，该方法在挑战性的数据集上取得了良好的性能。

    

    在语义分割领域，改善最先进方法的效率需要解决不断增长的计算成本以及从全局和局部上融合语义信息的问题。基于最近在语义分割中卷积神经网络（CNN）的成功和问题，本研究提出了一种带有独特高效剩余网络的编码器-解码器架构。通过引入注意力增强门（AbGs）和注意力增强模块（AbMs），目标是在编码器中将基于特征的语义信息与高效剩余网络的全局上下文相结合。同时，在解码器部分采用了受到AbM启发的额外注意力融合网络（AfNs）。AfNs旨在通过在解码器部分部署额外的卷积层，改善语义信息的逐一转换的效率。我们将网络在具有挑战性的CamVid和Cityscapes数据集上进行了测试。

    Improving the efficiency of state-of-the-art methods in semantic segmentation requires overcoming the increasing computational cost as well as issues such as fusing semantic information from global and local contexts. Based on the recent success and problems that convolutional neural networks (CNNs) encounter in semantic segmentation, this research proposes an encoder-decoder architecture with a unique efficient residual network. Attention-boosting gates (AbGs) and attention-boosting modules (AbMs) are deployed by aiming to fuse the feature-based semantic information with the global context of the efficient residual network in the encoder. Respectively, the decoder network is developed with the additional attention-fusion networks (AfNs) inspired by AbM. AfNs are designed to improve the efficiency in the one-to-one conversion of the semantic information by deploying additional convolution layers in the decoder part. Our network is tested on the challenging CamVid and Cityscapes dataset
    
[^131]: 用于医学图像深度主动学习的获取函数研究

    A Study of Acquisition Functions for Medical Imaging Deep Active Learning

    [https://arxiv.org/abs/2401.15721](https://arxiv.org/abs/2401.15721)

    本研究探讨了在医学图像领域中如何应用主动学习以解决数据稀缺的问题，并通过对比不同的选择标准和获取池大小对模型性能的影响，结果表明不确定性对于黑色素瘤检测任务是有帮助的。

    

    深度学习革命已经在近年取得了突破性成就。 从乳腺癌检测到蛋白质折叠，深度学习算法一直是非常重要的进步的核心。 但是，这些现代进步越来越需要数据，特别是标记数据，其可用性稀缺：在医学背景下更为常见。在这项工作中，我们展示了在数据稀缺情况下主动学习可能非常有效，其中获取标记数据（或注释预算非常有限）。 我们在ISIC 2016数据集上比较了几种选择标准（BALD，MeanSTD和MaxEntropy）。 我们还探讨了获取的池大小对模型性能的影响。 我们的结果表明，不确定性对于黑色素瘤检测任务是有帮助的，并且证实了作者的猜测，即\textit {bald} 平均比其他方式更好执行。

    arXiv:2401.15721v2 Announce Type: replace-cross  Abstract: The Deep Learning revolution has enabled groundbreaking achievements in recent years. From breast cancer detection to protein folding, deep learning algorithms have been at the core of very important advancements. However, these modern advancements are becoming more and more data-hungry, especially on labeled data whose availability is scarce: this is even more prevalent in the medical context. In this work, we show how active learning could be very effective in data scarcity situations, where obtaining labeled data (or annotation budget is very limited). We compare several selection criteria (BALD, MeanSTD, and MaxEntropy) on the ISIC 2016 dataset. We also explored the effect of acquired pool size on the model's performance. Our results suggest that uncertainty is useful to the Melanoma detection task, and confirms the hypotheses of the author of the paper of interest, that \textit{bald} performs on average better than other a
    
[^132]: 基于图神经网络的TRIDENT中微子重建

    Neutrino Reconstruction in TRIDENT Based on Graph Neural Network

    [https://arxiv.org/abs/2401.15324](https://arxiv.org/abs/2401.15324)

    TRIDENT中微子望远镜采用基于图神经网络的新型重建方法，提高了中微子事件的重建性能。

    

    arXiv:2401.15324v1 公告类型:交叉摘要:热带深海中微子望远镜(TRIDENT)是一种下一代中微子望远镜，将位于南中国海。通过具有大探测器体积和使用先进的混合数字光模块(hDOMs)，TRIDENT旨在发现多个天体中微子源并探测全味中微子物理。 主要中微子的重建分辨率是实现这些科学目标的关键因素。我们基于图神经网络(GNN)开发了一种新的TRIDENT重建方法。 本文介绍了GNN方法在TRIDENT中轨迹型和淋球状中微子事件上的重建性能。

    arXiv:2401.15324v1 Announce Type: cross  Abstract: TRopIcal DEep-sea Neutrino Telescope (TRIDENT) is a next-generation neutrino telescope to be located in the South China Sea. With a large detector volume and the use of advanced hybrid digital optical modules (hDOMs), TRIDENT aims to discover multiple astrophysical neutrino sources and probe all-flavor neutrino physics. The reconstruction resolution of primary neutrinos is on the critical path to these scientific goals. We have developed a novel reconstruction method based on graph neural network (GNN) for TRIDENT. In this paper, we present the reconstruction performance of the GNN-based approach on both track- and shower-like neutrino events in TRIDENT.
    
[^133]: OK-Robot: 整合开放知识模型在机器人领域的重要性

    OK-Robot: What Really Matters in Integrating Open-Knowledge Models for Robotics

    [https://arxiv.org/abs/2401.12202](https://arxiv.org/abs/2401.12202)

    该研究提出了一种新型基于开放知识的机器人框架OK-Robot，通过整合视觉-语言模型、导航原语和抓取原语，为Pick-and-Drop操作提供了一个集成解决方案，无需任何训练。

    

    近年来在视觉、语言和机器人领域取得了显著进展。我们现在拥有能够根据语言查询识别物体的视觉模型，能有效控制移动系统的导航系统，以及能够处理各种物体的抓取模型。尽管取得了这些进步，但机器人的通用应用仍然落后，尽管它们依赖于识别、导航和抓取等基本能力。在本文中，我们采用了系统优先的方法，开发了一个名为OK-Robot的新型基于开放知识的机器人框架。通过将用于对象检测的视觉-语言模型（VLMs）、用于移动的导航原语和用于物体操作的抓取原语结合在一起，OK-Robot为Pick-and-Drop操作提供了一个集成解决方案，而无需任何训练。为了评估其性能，我们在10个真实家庭环境中运行了OK-Robot。

    arXiv:2401.12202v2 Announce Type: replace-cross  Abstract: Remarkable progress has been made in recent years in the fields of vision, language, and robotics. We now have vision models capable of recognizing objects based on language queries, navigation systems that can effectively control mobile systems, and grasping models that can handle a wide range of objects. Despite these advancements, general-purpose applications of robotics still lag behind, even though they rely on these fundamental capabilities of recognition, navigation, and grasping. In this paper, we adopt a systems-first approach to develop a new Open Knowledge-based robotics framework called OK-Robot. By combining Vision-Language Models (VLMs) for object detection, navigation primitives for movement, and grasping primitives for object manipulation, OK-Robot offers a integrated solution for pick-and-drop operations without requiring any training. To evaluate its performance, we run OK-Robot in 10 real-world home environme
    
[^134]: Bayesian神经网络中概率鲁棒性的严格验证

    Tight Verification of Probabilistic Robustness in Bayesian Neural Networks

    [https://arxiv.org/abs/2401.11627](https://arxiv.org/abs/2401.11627)

    通过引入两种算法，实现了对Bayesian神经网络概率鲁棒性的严格验证，相比标准神经网络，这些算法更加高效且能够搜索参数空间以找到安全权重。

    

    我们介绍了两种用于计算Bayesian神经网络（BNNs）的概率鲁棒性上严格保证的算法。计算BNNs的鲁棒性保证要比验证标准神经网络（NNs）的鲁棒性困难得多，因为它需要在参数空间中搜索安全权重。此外，标准NNs验证的紧密和完整方法，例如基于混合整数线性规划（MILP）的方法，不能直接用于BNNs的验证，因为由于编码权重的变量连续相乘而产生的多项式项。我们的算法通过使用迭代扩展和网络的梯度有效地搜索参数空间以寻找安全权重，并且可以与BNNs的任何验证算法一起使用。

    arXiv:2401.11627v2 Announce Type: replace-cross  Abstract: We introduce two algorithms for computing tight guarantees on the probabilistic robustness of Bayesian Neural Networks (BNNs). Computing robustness guarantees for BNNs is a significantly more challenging task than verifying the robustness of standard Neural Networks (NNs) because it requires searching the parameters' space for safe weights. Moreover, tight and complete approaches for the verification of standard NNs, such as those based on Mixed-Integer Linear Programming (MILP), cannot be directly used for the verification of BNNs because of the polynomial terms resulting from the consecutive multiplication of variables encoding the weights. Our algorithms efficiently and effectively search the parameters' space for safe weights by using iterative expansion and the network's gradient and can be used with any verification algorithm of choice for BNNs. In addition to proving that our algorithms compute tighter bounds than the So
    
[^135]: NPU-ASLP-LiAuto团队在CNVSRC 2023中视觉语音识别系统描述

    The NPU-ASLP-LiAuto System Description for Visual Speech Recognition in CNVSRC 2023

    [https://arxiv.org/abs/2401.06788](https://arxiv.org/abs/2401.06788)

    NPU-ASLP-LiAuto团队在2023年CNVSRC中提出了一种视觉语音识别系统，采用端到端架构和多样的数据处理和增强技术，取得了在单说话者和多说话者任务中的优异表现，排名第一。

    

    本文描述了NPU-ASLP-LiAuto（Team 237）在2023年第一届中国连续视觉语音识别挑战赛（CNVSRC）中推出的视觉语音识别（VSR）系统，参与了单说话者VSR任务的固定和开放轨迹，以及多说话者VSR任务的开放轨迹。在数据处理方面，我们利用基线1中的唇部运动提取器生成多尺度视频数据。此外，训练过程中应用了各种增强技术，包括速度扰动、随机旋转、水平翻转和颜色转换。VSR模型采用了端到端架构，联合CTC/注意力损失，包括ResNet3D视觉前端、E-Branchformer编码器和Transformer解码器。实验表明，我们的系统在多系统融合后实现了单说话者任务的34.76% CER和多说话者任务的41.06% CER，排名第一。

    arXiv:2401.06788v2 Announce Type: replace-cross  Abstract: This paper delineates the visual speech recognition (VSR) system introduced by the NPU-ASLP-LiAuto (Team 237) in the first Chinese Continuous Visual Speech Recognition Challenge (CNVSRC) 2023, engaging in the fixed and open tracks of Single-Speaker VSR Task, and the open track of Multi-Speaker VSR Task. In terms of data processing, we leverage the lip motion extractor from the baseline1 to produce multi-scale video data. Besides, various augmentation techniques are applied during training, encompassing speed perturbation, random rotation, horizontal flipping, and color transformation. The VSR model adopts an end-to-end architecture with joint CTC/attention loss, comprising a ResNet3D visual frontend, an E-Branchformer encoder, and a Transformer decoder. Experiments show that our system achieves 34.76% CER for the Single-Speaker Task and 41.06% CER for the Multi-Speaker Task after multi-system fusion, ranking first place in all 
    
[^136]: LLM互动优化开源Python库--案例研究与概括

    LLM Interactive Optimization of Open Source Python Libraries -- Case Studies and Generalization

    [https://arxiv.org/abs/2312.14949](https://arxiv.org/abs/2312.14949)

    本文研究了如何利用当代LLM ChatGPT-4来优化开源Python库，发现在与人类专家互动的情况下，该模型在优化能源和计算效率方面表现出惊人的灵活性。

    

    随着大型语言模型（LLMs）如GPT-3的出现，一个自然的问题是这些模型在源代码优化中的利用程度。本文提出了方法论严谨的案例研究，应用于著名的开源Python库pillow和numpy。我们发现，当与人类专家互动时，当代LLM ChatGPT-4（截至2023年9月和10月）在优化能源和计算效率方面表现出惊人的灵活性。然而，这仅适用于互动使用，且需要人类专家协助。为了避免实验者偏见，我们详细记录了我们的定性方法，并提供了对话和源代码。我们首先详细描述了与LLM对话以优化pillow库中的_getextrema函数的方法，并量化评估了性能改进。为了展示定性可复制性，我们报告了在pillow的另一个位置上进一步尝试的情况。

    arXiv:2312.14949v2 Announce Type: replace-cross  Abstract: With the advent of large language models (LLMs) like GPT-3, a natural question is the extent to which these models can be utilized for source code optimization. This paper presents methodologically stringent case studies applied to well-known open source python libraries pillow and numpy. We find that contemporary LLM ChatGPT-4 (state September and October 2023) is surprisingly adept at optimizing energy and compute efficiency. However, this is only the case in interactive use, with a human expert in the loop. Aware of experimenter bias, we document our qualitative approach in detail, and provide transcript and source code. We start by providing a detailed description of our approach in conversing with the LLM to optimize the _getextrema function in the pillow library, and a quantitative evaluation of the performance improvement. To demonstrate qualitative replicability, we report further attempts on another locus in the pillow
    
[^137]: 在模拟机器人臂中的安全强化学习

    Safe Reinforcement Learning in a Simulated Robotic Arm

    [https://arxiv.org/abs/2312.09468](https://arxiv.org/abs/2312.09468)

    本文通过在Panda机器人臂上创建定制环境，扩展了安全强化学习算法的适用性，实现了安全RL算法在物理环境中的测试。

    

    强化学习（RL）代理需要探索环境以学习最优策略。在许多环境和任务中，安全性至关重要。模拟器的广泛使用提供了许多优势，其中包括安全探索，当RL系统需要直接在物理环境（例如在人机交互中）中进行训练时，安全探索将是不可避免的。流行的Safety Gym库提供了三种移动代理类型，可以学习目标导向任务同时考虑各种安全约束。本文通过创建一个带有Panda机器人臂的定制环境，扩展了安全RL算法的适用性，以便测试Safety Gym算法。我们使用流行的PPO算法进行了试点实验，比较了基线与受限版本，并表明受限版本能够学习出同样优秀的策略，同时更好地符合安全性。

    arXiv:2312.09468v2 Announce Type: replace-cross  Abstract: Reinforcement learning (RL) agents need to explore their environments in order to learn optimal policies. In many environments and tasks, safety is of critical importance. The widespread use of simulators offers a number of advantages, including safe exploration which will be inevitable in cases when RL systems need to be trained directly in the physical environment (e.g. in human-robot interaction). The popular Safety Gym library offers three mobile agent types that can learn goal-directed tasks while considering various safety constraints. In this paper, we extend the applicability of safe RL algorithms by creating a customized environment with Panda robotic arm where Safety Gym algorithms can be tested. We performed pilot experiments with the popular PPO algorithm comparing the baseline with the constrained version and show that the constrained version is able to learn the equally good policy while better complying with safe
    
[^138]: RMS：实时姿态估计的最小冗余点云采样

    RMS: Redundancy-Minimizing Point Cloud Sampling for Real-Time Pose Estimation

    [https://arxiv.org/abs/2312.07337](https://arxiv.org/abs/2312.07337)

    提出了一种名为RMS的点云采样方法，通过最小化冗余优化了3D点云的翻译空间可观测性，解决了移动机器人状态估计中潜在的问题。

    

    在移动机器人状态估计中使用的典型点云采样方法保留了高水平的点冗余。这种冗余不必要地减慢了估计流程并可能在实时约束下导致漂移。这种不必要的延迟成为资源受限的机器人（尤其是无人机）的瓶颈，需要最小的延迟以进行敏捷和准确的操作。我们提出了一种名为RMS的新颖、确定性、未知和单参数点云采样方法，它最小化了3D点云中的冗余。

    arXiv:2312.07337v2 Announce Type: replace-cross  Abstract: The typical point cloud sampling methods used in state estimation for mobile robots preserve a high level of point redundancy. This redundancy unnecessarily slows down the estimation pipeline and may cause drift under real-time constraints. Such undue latency becomes a bottleneck for resource-constrained robots (especially UAVs), requiring minimal delay for agile and accurate operation. We propose a novel, deterministic, uninformed, and single-parameter point cloud sampling method named RMS that minimizes redundancy within a 3D point cloud. In contrast to the state of the art, RMS balances the translation-space observability by leveraging the fact that linear and planar surfaces inherently exhibit high redundancy propagated into iterative estimation pipelines. We define the concept of gradient flow, quantifying the local surface underlying a point. We also show that maximizing the entropy of the gradient flow minimizes point re
    
[^139]: 解读数字侦探：理解LLM在多智能体推理游戏中的行为和能力

    Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games

    [https://arxiv.org/abs/2312.00746](https://arxiv.org/abs/2312.00746)

    探索在《巨本砂》这个中国侦探角色扮演游戏中应用LLMs，引入首个专为该游戏设计的数据集，提出多智能体交互框架，通过改进信息收集、凶手识别和逻辑推理等方面的方法来提高AI智能体的游戏表现。

    

    在这项研究中，我们探讨了大型语言模型（LLMs）在《巨本砂》中的应用，这是一款中国侦探角色扮演游戏，也是人工智能驱动游戏中的一个新领域。我们介绍了首个专为《巨本砂》设计的数据集，包括角色台词和游戏规则，以促进在这个复杂叙事环境中的AI智能体发展。我们的工作还提出了一种独特的利用LLMs的多智能体交互框架，使得AI智能体能够自主参与游戏。为了评估这些AI智能体在游戏中的表现，我们开发了衡量它们对案件信息和推理技能掌握程度的新方法。此外，我们还融入了最新的上下文学习技术，以提高智能体在信息收集、凶手识别和逻辑推理方面的表现。实验结果验证了我们提出方法的有效性。这项工作旨在提供一种新颖的p

    arXiv:2312.00746v2 Announce Type: replace  Abstract: In this study, we explore the application of Large Language Models (LLMs) in \textit{Jubensha}, a Chinese detective role-playing game and a novel area in Artificial Intelligence (AI) driven gaming. We introduce the first dataset specifically for Jubensha, including character scripts and game rules, to foster AI agent development in this complex narrative environment. Our work also presents a unique multi-agent interaction framework using LLMs, allowing AI agents to autonomously engage in this game. To evaluate the gaming performance of these AI agents, we developed novel methods measuring their mastery of case information and reasoning skills. Furthermore, we incorporated the latest advancements in in-context learning to improve the agents' performance in information gathering, murderer identification, and logical reasoning. The experimental results validate the effectiveness of our proposed methods. This work aims to offer a novel p
    
[^140]: 通过不同的主干和统计匹配进行广义大规模数据压缩

    Generalized Large-Scale Data Condensation via Various Backbone and Statistical Matching

    [https://arxiv.org/abs/2311.17950](https://arxiv.org/abs/2311.17950)

    本文提出了广义匹配的概念，并在此基础上提出了Generalized Various Backbone and Statistical Matching (G-VBSM)方法，可以创建一个具有丰富信息和更好概括能力的压缩数据集。

    

    SRe2L引入的轻量级“局部匹配-全局匹配”成功地创造了一个经过精心筛选的数据集，其中包含来自完整的224x224 ImageNet-1k的全面信息。然而，这种单边方法只适用于特定的主干、层和统计数据，从而限制了精简数据集概括能力的提升。我们建议充分而各异的“局部匹配-全局匹配”比单一匹配更加精确和有效，并能够创造出更丰富信息和更好概括能力的压缩数据集。我们称之为“广义匹配”观点，并在本文中提出了广义不同主干和统计匹配 (G-VBSM)，旨在创建一个具有密度的合成数据集，确保在不同的主干、层和统计数据上与完整数据集保持一致。实验证明，G-VBSM是第一个获得强大性能的算法。

    arXiv:2311.17950v2 Announce Type: replace-cross  Abstract: The lightweight "local-match-global" matching introduced by SRe2L successfully creates a distilled dataset with comprehensive information on the full 224x224 ImageNet-1k. However, this one-sided approach is limited to a particular backbone, layer, and statistics, which limits the improvement of the generalization of a distilled dataset. We suggest that sufficient and various "local-match-global" matching are more precise and effective than a single one and has the ability to create a distilled dataset with richer information and better generalization. We call this perspective "generalized matching" and propose Generalized Various Backbone and Statistical Matching (G-VBSM) in this work, which aims to create a synthetic dataset with densities, ensuring consistency with the complete dataset across various backbones, layers, and statistics. As experimentally demonstrated, G-VBSM is the first algorithm to obtain strong performance a
    
[^141]: 基于外观的注视估计通过使用深度神经网络增强合成图像

    Appearance-based gaze estimation enhanced with synthetic images using deep neural networks

    [https://arxiv.org/abs/2311.14175](https://arxiv.org/abs/2311.14175)

    使用深度神经网络，通过合成图像以及基于外观的方法提高了注视估计准确性，无需特殊硬件，眼睛平均误差低于两度

    

    人眼注视估计对于成功的人机交互是一个重要的认知因素，使机器人能够读取和预测人类行为。我们采用人工神经网络来解决这个问题，并构建了一个模块化系统，通过分开裁剪的眼睛估计注视，利用现有的用于人脸检测（RetinaFace）和头部姿态估计（6DRepNet）的良好工作的组件。我们提出的方法不需要任何特殊硬件或红外滤光片，而是使用标准笔记本内置的RGB摄像头，通常采用基于外观的方法。通过MetaHuman工具，我们还生成了一个包含超过57,000张人脸的大型合成数据集，并公开提供了这一数据集。将这个数据集（带有眼睛注视和头部姿态信息）与标准的哥伦比亚注视数据集结合起来训练模型，导致更高的准确性，眼睛的平均误差低于两度。

    arXiv:2311.14175v2 Announce Type: replace-cross  Abstract: Human eye gaze estimation is an important cognitive ingredient for successful human-robot interaction, enabling the robot to read and predict human behavior. We approach this problem using artificial neural networks and build a modular system estimating gaze from separately cropped eyes, taking advantage of existing well-functioning components for face detection (RetinaFace) and head pose estimation (6DRepNet). Our proposed method does not require any special hardware or infrared filters but uses a standard notebook-builtin RGB camera, as often approached with appearance-based methods. Using the MetaHuman tool, we also generated a large synthetic dataset of more than 57,000 human faces and made it publicly available. The inclusion of this dataset (with eye gaze and head pose information) on top of the standard Columbia Gaze dataset into training the model led to better accuracy with a mean average error below two degrees in eye
    
[^142]: 重新审视假设：预训练的Transformer是否通过梯度下降在上下文中学习？

    Revisiting the Hypothesis: Do pretrained Transformers Learn In-Context by Gradient Descent?

    [https://arxiv.org/abs/2310.08540](https://arxiv.org/abs/2310.08540)

    本研究重新审视了预训练的Transformer是否通过梯度下降在上下文中学习的假设，并发现现有研究中的假设存在限制性假设，使其与实际语言模型训练时的语境存在显著差异。同时，通过对真实模型的观察和比较，揭示了ICL和GD在观察演示顺序上的不同敏感性。

    

    LLM中的In-Context Learning（ICL）的出现仍然是一个重要现象，但我们对其了解甚少。为了解释ICL，最近的研究尝试在理论上将其与梯度下降（GD）联系起来。我们问，这种联系在实际预训练模型中是否成立？我们强调先前作品中的限制性假设使得它们的语境与语言模型实际训练时的实际语境差别很大。例如，这些研究中使用的理论手工构造的权重具有与真实LLM不匹配的属性。此外，他们的实验验证使用ICL目标（明确为ICL训练模型），这与野外出现的ICL有所不同。我们还寻找了真实模型中的证据。我们观察到ICL和GD对于观察演示的顺序有不同的敏感性。最后，我们在自然环境中探讨并比较ICL与GD假设。

    arXiv:2310.08540v4 Announce Type: replace-cross  Abstract: The emergence of In-Context Learning (ICL) in LLMs remains a significant phenomenon with little understanding. To explain ICL, recent studies try to theoretically connect it to Gradient Descent (GD). We ask, does this connection hold up in actual pre-trained models?   We highlight the limiting assumptions in prior works that make their context considerably different from the practical context in which language models are trained. For example, the theoretical hand-constructed weights used in these studies have properties that don't match those of real LLMs. Furthermore, their experimental verification uses ICL objective (training models explicitly for ICL), which differs from the emergent ICL in the wild.   We also look for evidence in real models. We observe that ICL and GD have different sensitivity to the order in which they observe demonstrations. Finally, we probe and compare the ICL vs. GD hypothesis in a natural setting. 
    
[^143]: 高效在线调度和路径规划：基于循环图的自动引导车

    Efficient Online Scheduling and Routing for Automated Guided Vehicles In Loop-Based Graphs

    [https://arxiv.org/abs/2310.02195](https://arxiv.org/abs/2310.02195)

    提出了一种用于自动引导车的在线、无冲突调度和路径规划问题的基于循环图的算法，实验结果表明该算法要么优于其他算法，要么在更短的计算时间内获得同样良好的解决方案

    

    自动引导车（AGVs）广泛应用于各行各业，以无冲突方式对它们进行调度和路径规划对于它们的高效运行至关重要。我们提出了一种基于循环图的算法，用于解决具有任意容量和顺序作业的AGVs的在线、无冲突调度和路径规划问题。该算法与精确方法、贪婪启发式方法和元启发式方法进行了比较。我们通过在代表实际制造厂的模型上使用理论和真实实例进行实验，证明了该算法要么优于其他算法，要么在更短的计算时间内获得同样良好的解决方案。

    arXiv:2310.02195v2 Announce Type: replace-cross  Abstract: Automated guided vehicles (AGVs) are widely used in various industries, and scheduling and routing them in a conflict-free manner is crucial to their efficient operation. We propose a loop-based algorithm that solves the online, conflict-free scheduling and routing problem for AGVs with any capacity and ordered jobs in loop-based graphs. The proposed algorithm is compared against an exact method, a greedy heuristic and a metaheuristic. We experimentally show, using theoretical and real instances on a model representing a real manufacturing plant, that this algorithm either outperforms the other algorithms or gets an equally good solution in less computing time.
    
[^144]: 通过逻辑增强大型语言模型中的零射链推理能力

    Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic

    [https://arxiv.org/abs/2309.13339](https://arxiv.org/abs/2309.13339)

    提出了LoT（Logical Thoughts）提示，一个自我改进框架，利用根植于符号逻辑的原则，特别是归谬法，逐步验证和纠正大型语言模型的零射链推理过程。

    

    大型语言模型的最新进展展示了它们在各个领域的 remarkable generalizability。然而，它们的推理能力仍有很大的提升空间，特别是在需要多步推理的情况下。尽管大型语言模型具有广泛的知识，但它们的推理经常未能有效利用这些知识来建立连贯的思维范式。这些模型有时会出现幻觉，因为它们的推理过程未受逻辑原则的限制。为了改进大型语言模型的零射链推理能力，我们提出了 LoT（Logical Thoughts）提示，这是一个自我改进的框架，利用根植于符号逻辑的原则，特别是归谬法，逐步系统地验证和纠正推理过程。在语言任务上进行的实验评估

    arXiv:2309.13339v2 Announce Type: replace-cross  Abstract: Recent advancements in large language models have showcased their remarkable generalizability across various domains. However, their reasoning abilities still have significant room for improvement, especially when confronted with scenarios requiring multi-step reasoning. Although large language models possess extensive knowledge, their reasoning often fails to effectively utilize this knowledge to establish a coherent thinking paradigm. These models sometimes show hallucinations as their reasoning procedures are unconstrained by logical principles. Aiming at improving the zero-shot chain-of-thought reasoning ability of large language models, we propose LoT (Logical Thoughts) prompting, a self-improvement framework that leverages principles rooted in symbolic logic, particularly Reductio ad Absurdum, to systematically verify and rectify the reasoning processes step by step. Experimental evaluations conducted on language tasks in
    
[^145]: 差分扩散：赋予每个像素以其强度

    Differential Diffusion: Giving Each Pixel Its Strength

    [https://arxiv.org/abs/2306.00950](https://arxiv.org/abs/2306.00950)

    该论文介绍了一种新颖的框架，允许对每个像素或图像区域的改变量进行定制化，为扩散模型增加了粒度控制的能力，进一步扩展了图像编辑的功能。

    

    扩散模型在图像生成和编辑方面产生了革命性的变化，取得了在有条件和无条件图像合成方面的最新结果。该论文引入了一种新颖的框架，使得每个像素或图像区域的改变量可以进行定制化。我们的框架可以集成到任何现有的扩散模型中，为其增加这种功能。对变化量的粒度控制打开了各种新的编辑能力，如控制单个对象被修改的程度，或者引入逐渐的空间变化等。此外，我们展示了该框架在软修复方面的有效性，即在完成图像部分的同时，微调周围区域以确保一致。

    arXiv:2306.00950v2 Announce Type: replace-cross  Abstract: Diffusion models have revolutionized image generation and editing, producing state-of-the-art results in conditioned and unconditioned image synthesis. While current techniques enable user control over the degree of change in an image edit, the controllability is limited to global changes over an entire edited region. This paper introduces a novel framework that enables customization of the amount of change per pixel or per image region. Our framework can be integrated into any existing diffusion model, enhancing it with this capability. Such granular control on the quantity of change opens up a diverse array of new editing capabilities, such as control of the extent to which individual objects are modified, or the ability to introduce gradual spatial changes. Furthermore, we showcase the framework's effectiveness in soft-inpainting -- the completion of portions of an image while subtly adjusting the surrounding areas to ensure
    
[^146]: 跨领域跨任务迁移学习中的传递性指导

    Transferability-Guided Cross-Domain Cross-Task Transfer Learning

    [https://arxiv.org/abs/2207.05510](https://arxiv.org/abs/2207.05510)

    提出了两种新的传递性度量标准 F-OTCE 和 JC-OTCE，用于评估源模型对目标任务的受益程度，并为跨领域跨任务迁移学习学习更具传递性的表示。

    

    我们提出了两种新的传递性度量标准 F-OTCE（基于快速最优传输的条件熵）和 JC-OTCE（联合对应 OTCE），用于评估源模型（任务）对目标任务学习的受益程度，并为跨领域跨任务迁移学习学习更具传递性的表示。与现有的度量标准不同，它们需要在辅助任务上评估经验传递性，我们的度量标准是无需辅助的，因此可以更高效地计算。具体而言，F-OTCE首先通过在源和目标分布之间解决最优传输（OT）问题来估计传递性，然后使用最优耦合来计算源和目标标签之间的负条件熵。它还可以作为损失函数，在微调目标任务之前最大化源模型的传递性。同时，JC-OTCE改善了传递性...

    arXiv:2207.05510v2 Announce Type: replace-cross  Abstract: We propose two novel transferability metrics F-OTCE (Fast Optimal Transport based Conditional Entropy) and JC-OTCE (Joint Correspondence OTCE) to evaluate how much the source model (task) can benefit the learning of the target task and to learn more transferable representations for cross-domain cross-task transfer learning. Unlike the existing metric that requires evaluating the empirical transferability on auxiliary tasks, our metrics are auxiliary-free such that they can be computed much more efficiently. Specifically, F-OTCE estimates transferability by first solving an Optimal Transport (OT) problem between source and target distributions, and then uses the optimal coupling to compute the Negative Conditional Entropy between source and target labels. It can also serve as a loss function to maximize the transferability of the source model before finetuning on the target task. Meanwhile, JC-OTCE improves the transferability r
    
[^147]: 自主人工智能代理的自主开放世界学习

    Self-Initiated Open World Learning for Autonomous AI Agents

    [https://arxiv.org/abs/2110.11385](https://arxiv.org/abs/2110.11385)

    论文提出了一种自主开放世界学习的方法，使人工智能代理能够在自主、自我激励和自我监督的方式下学习，以应对未知或新颖性环境中的挑战，实现逐步学习和提升知识与能力。

    

    随着越来越多的人工智能代理被实际应用，是时候考虑如何使这些代理完全自主，以便它们可以自主学习，而不是定期由人类工程师启动并使用扩展的训练数据进行重新训练。由于现实世界是一个具有未知或新颖性的开放环境，检测新颖性或未知性，描述它们，适应或适应它们，收集地面真实训练数据，并逐步学习未知和新颖性对于使代理越来越有知识和能力变得至关重要。关键挑战在于如何自动化这个过程，使其由代理主动进行并通过其与人类和环境的互动进行。由于人工智能代理通常有一个性能任务，因此对每种新颖性进行特征化变得至关重要和必要，以便代理可以制定

    arXiv:2110.11385v3 Announce Type: replace  Abstract: As more and more AI agents are used in practice, it is time to think about how to make these agents fully autonomous so that they can learn by themselves in a self-motivated and self-supervised manner rather than being retrained periodically on the initiation of human engineers using expanded training data. As the real-world is an open environment with unknowns or novelties, detecting novelties or unknowns, characterizing them, accommodating or adapting to them, gathering ground-truth training data, and incrementally learning the unknowns/novelties are critical to making the agent more and more knowledgeable and powerful over time. The key challenge is how to automate the process so that it is carried out on the agent's own initiative and through its own interactions with humans and the environment. Since an AI agent usually has a performance task, characterizing each novelty becomes critical and necessary so that the agent can formu
    
[^148]: 图像分类任务的实用可转移性估计

    Practical Transferability Estimation for Image Classification Tasks

    [https://arxiv.org/abs/2106.10479](https://arxiv.org/abs/2106.10479)

    提出了一个实用的转移性度量JC-NCE分数，通过显著改善OTCE中任务差异估计的鲁棒性，消除了对辅助任务的需求。

    

    可转移性估计是迁移学习中的一个关键问题，用于预测将源模型（或源任务）转移到目标任务时性能有多好。最近，分析性的转移性度量已被广泛用于源模型选择和多任务学习。主要挑战是如何在跨领域跨任务的设置下使转移性估计具有鲁棒性。最近提出的OTCE分数通过考虑域和任务差异来解决这个问题，借助辅助任务的转移经验，但这会导致效率开销。在这项工作中，我们提出了一个称为JC-NCE分数的实用转移性度量，显著改善了OTCE中任务差异估计的鲁棒性，从而消除了对辅助任务的需求。具体而言，通过解决最优输运问题建立源数据和目标数据之间的联合对应。

    arXiv:2106.10479v3 Announce Type: replace-cross  Abstract: Transferability estimation is an essential problem in transfer learning to predict how good the performance is when transferring a source model (or source task) to a target task. Recent analytical transferability metrics have been widely used for source model selection and multi-task learning. A major challenge is how to make transfereability estimation robust under the cross-domain cross-task settings. The recently proposed OTCE score solves this problem by considering both domain and task differences, with the help of transfer experiences on auxiliary tasks, which causes an efficiency overhead. In this work, we propose a practical transferability metric called JC-NCE score that dramatically improves the robustness of the task difference estimation in OTCE, thus removing the need for auxiliary tasks. Specifically, we build the joint correspondences between source and target data via solving an optimal transport problem with a 
    
[^149]: 优化大规模语言模型用于漏洞检测

    Finetuning Large Language Models for Vulnerability Detection. (arXiv:2401.17010v1 [cs.CR])

    [http://arxiv.org/abs/2401.17010](http://arxiv.org/abs/2401.17010)

    本文优化了大规模语言模型用于源代码中的漏洞检测任务，通过微调最先进的代码语言模型WizardCoder并改进其训练过程和策略，实现了对漏洞数据集的分类性能的提升。

    

    本文介绍了对大规模语言模型进行微调，并将其用于源代码中的漏洞检测的结果。我们利用最先进的语言模型StarCoder的改进版本WizardCoder，并通过进一步微调将其适应于漏洞检测任务。为了加速训练，我们修改了WizardCoder的训练过程，并探究了最佳的训练策略。针对负样本远多于正样本的不平衡数据集，我们还尝试了不同的技术来提高分类性能。微调后的WizardCoder模型在平衡和不平衡的漏洞数据集上在ROC AUC和F1度量上实现了改进，证明了将预训练的语言模型用于源代码中的漏洞检测的有效性。主要贡献包括对最先进的代码语言模型WizardCoder进行微调，提高其训练速度而不影响性能，并对训练过程和策略进行了优化。

    This paper presents the results of finetuning large language models (LLMs) for the task of detecting vulnerabilities in source code. We leverage WizardCoder, a recent improvement of the state-of-the-art LLM StarCoder, and adapt it for vulnerability detection through further finetuning. To accelerate training, we modify WizardCoder's training procedure, also we investigate optimal training regimes. For the imbalanced dataset with many more negative examples than positive, we also explore different techniques to improve classification performance. The finetuned WizardCoder model achieves improvement in ROC AUC and F1 measures on balanced and imbalanced vulnerability datasets over CodeBERT-like model, demonstrating the effectiveness of adapting pretrained LLMs for vulnerability detection in source code. The key contributions are finetuning the state-of-the-art code LLM, WizardCoder, increasing its training speed without the performance harm, optimizing the training procedure and regimes, 
    
[^150]: AST-2:单层和双层二维声学软触觉皮肤

    AST-2: Single and bi-layered 2-D acoustic soft tactile skin. (arXiv:2401.14292v1 [cs.RO])

    [http://arxiv.org/abs/2401.14292](http://arxiv.org/abs/2401.14292)

    本文提出了一个创新且成本效益的设计，可以显著提高二维触觉特征估计的准确性。通过利用声学能量和分析幅度调制，可以有效改善触觉特征估计。实际测试证明了该设计的有效性，达到了显著的精度。

    

    本文旨在提出一种创新且具有成本效益的声学软触觉(AST)皮肤设计，主要目标是显著提高二维触觉特征估计的准确性。现有的挑战在于使用成本效益的解决方案实现精确的触觉特征估计，特别是涉及接触几何特征。我们假设通过在感测表面下的两层专用声学通道中利用声学能量，并分析幅度调制，可以有效解码感测表面上的交互作用，从而改善触觉特征估计。我们的方法涉及硬件组件明确分离，负责发射和接收声学信号，从而实现模块化和高度可定制的皮肤设计。实际测试证明了这种新颖设计的有效性，达到了在估计接触法向力(MAE <0.8 N)和二维接触定位方面的显著精度

    This paper aims to present an innovative and cost-effective design for Acoustic Soft Tactile (AST) Skin, with the primary goal of significantly enhancing the accuracy of 2-D tactile feature estimation. The existing challenge lies in achieving precise tactile feature estimation, especially concerning contact geometry characteristics, using cost-effective solutions. We hypothesise that by harnessing acoustic energy through dedicated acoustic channels in 2 layers beneath the sensing surface and analysing amplitude modulation, we can effectively decode interactions on the sensory surface, thereby improving tactile feature estimation. Our approach involves the distinct separation of hardware components responsible for emitting and receiving acoustic signals, resulting in a modular and highly customizable skin design. Practical tests demonstrate the effectiveness of this novel design, achieving remarkable precision in estimating contact normal forces (MAE < 0.8 N), 2D contact localisation (M
    
[^151]: WebVoyager：使用大型多模态模型构建端到端的Web Agent

    WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models. (arXiv:2401.13919v1 [cs.CL])

    [http://arxiv.org/abs/2401.13919](http://arxiv.org/abs/2401.13919)

    WebVoyager是一种创新的基于大型多模态模型的Web代理，能够通过与真实网站交互来端到端地完成用户指令。它提出了一个新的Web代理评估协议，并在实际任务中取得了显著的成功率。

    

    大型语言模型（LLMs）的进步引领了一个由真实世界中自主应用程序的发展所标志的新时代，推动了基于网络的高级代理的创新。现有的网络代理通常只处理一个输入模态，并且仅在简化的网络模拟器或静态的网络快照中进行评估，极大地限制了它们在真实场景中的适用性。为了填补这一差距，我们引入了WebVoyager，一种创新的基于大型多模态模型（LMM）的Web代理，通过与真实网站进行交互，能够端到端地完成用户指令。此外，我们提出了一个新的Web代理评估协议，以解决开放式Web代理任务的自动评估挑战，利用了GPT-4V的强大多模态理解能力。我们通过收集来自15个广泛使用的网站的真实世界任务来创建一个新的基准来评估我们的代理。我们展示了WebVoyager实现了55.7％的任务成功率，显著地.....

    The advancement of large language models (LLMs) leads to a new era marked by the development of autonomous applications in the real world, which drives innovation in the creation of advanced web-based agents. Existing web agents typically only handle one input modality and are evaluated only in simplified web simulators or static web snapshots, greatly limiting their applicability in real-world scenarios. To bridge this gap, we introduce WebVoyager, an innovative Large Multimodal Model (LMM) powered web agent that can complete user instructions end-to-end by interacting with real-world websites. Moreover, we propose a new evaluation protocol for web agents to address the challenges of automatic evaluation of open-ended web agent tasks, leveraging the robust multimodal comprehension capabilities of GPT-4V. We create a new benchmark by gathering real-world tasks from 15 widely used websites to evaluate our agents. We show that WebVoyager achieves a 55.7% task success rate, significantly 
    
[^152]: BIBench: 大型语言模型数据分析知识基准测试

    BIBench: Benchmarking Data Analysis Knowledge of Large Language Models. (arXiv:2401.02982v1 [cs.CL])

    [http://arxiv.org/abs/2401.02982](http://arxiv.org/abs/2401.02982)

    BIBench是一个旨在评估大型语言模型（LLMs）在商业智能（BI）数据分析领域中能力的综合基准测试，其通过测试模型在BI基础知识、应用知识和技术技能三个维度上的表现来进行评估。

    

    大型语言模型（LLMs）在各种任务中展示了令人印象深刻的能力。然而，它们在数据分析的专业领域中的熟练度和可靠性，特别是在以数据驱动思维为重点的领域中，仍然存在不确定性。为了填补这一差距，我们介绍了BIBench，这是一个全面的基准测试，旨在评估LLMs在商业智能（BI）的背景下的数据分析能力。BIBench通过三个维度评估LLMs：1）BI基础知识，评估模型的数值推理能力和对金融概念的熟悉程度；2）BI知识应用，确定模型快速理解文本信息并从多个视角生成分析问题的能力；3）BI技术技能，检查模型使用技术知识解决现实数据分析挑战的能力。BIBench包括11个子任务，涵盖分类、提取和生成三种任务类型。

    Large Language Models (LLMs) have demonstrated impressive capabilities across a wide range of tasks. However, their proficiency and reliability in the specialized domain of Data Analysis, particularly with a focus on data-driven thinking, remain uncertain. To bridge this gap, we introduce BIBench, a comprehensive benchmark designed to evaluate the data analysis capabilities of LLMs within the context of Business Intelligence (BI). BIBench assesses LLMs across three dimensions: 1) BI foundational knowledge, evaluating the models' numerical reasoning and familiarity with financial concepts; 2) BI knowledge application, determining the models' ability to quickly comprehend textual information and generate analysis questions from multiple views; and 3) BI technical skills, examining the models' use of technical knowledge to address real-world data analysis challenges. BIBench comprises 11 sub-tasks, spanning three categories of task types: classification, extraction, and generation. Additi
    
[^153]: 离线目标条件强化学习的评分模型

    Score Models for Offline Goal-Conditioned Reinforcement Learning. (arXiv:2311.02013v1 [cs.LG])

    [http://arxiv.org/abs/2311.02013](http://arxiv.org/abs/2311.02013)

    本文提出了一种新颖的离线目标条件强化学习方法，称为SMORe，它将占有匹配的视角与混合分布匹配相结合，无需学习鉴别器，从而提高了GCRL在离线环境中的表现。

    

    离线目标条件强化学习（GCRL）的任务是使用稀疏奖励函数从离线数据集中学习在环境中实现多个目标。离线GCRL对于开发能够利用预先存在的数据集学习多样化和可复用技能的通用型代理至关重要，而无需手工设计奖励函数。然而，基于监督学习和对比学习的现代GCRL方法在离线环境中往往不太理想。GCRL的另一种观点是优化占有匹配，但需要学习鉴别器，随后该鉴别器作为下游强化学习的伪奖励。学习到的鉴别器的不准确性可能会导致负面影响，进而影响生成的策略。我们提出了一种新颖的GCRL方法，基于混合分布匹配的新视角，采用无鉴别器的方法：SMORe。关键洞见是将GCRL的占有匹配视角与一个有效的聚类算法相结合，从而得到了我们的无鉴别器方法：SMORe。

    Offline Goal-Conditioned Reinforcement Learning (GCRL) is tasked with learning to achieve multiple goals in an environment purely from offline datasets using sparse reward functions. Offline GCRL is pivotal for developing generalist agents capable of leveraging pre-existing datasets to learn diverse and reusable skills without hand-engineering reward functions. However, contemporary approaches to GCRL based on supervised learning and contrastive learning are often suboptimal in the offline setting. An alternative perspective on GCRL optimizes for occupancy matching, but necessitates learning a discriminator, which subsequently serves as a pseudo-reward for downstream RL. Inaccuracies in the learned discriminator can cascade, negatively influencing the resulting policy. We present a novel approach to GCRL under a new lens of mixture-distribution matching, leading to our discriminator-free method: SMORe. The key insight is combining the occupancy matching perspective of GCRL with a conve
    
[^154]: 提问更多，了解更多：利用大型语言模型强化学习的决策问题与思维链

    Ask more, know better: Reinforce-Learned Prompt Questions for Decision Making with Large Language Models. (arXiv:2310.18127v1 [cs.LG])

    [http://arxiv.org/abs/2310.18127](http://arxiv.org/abs/2310.18127)

    本文提出了一种利用大型语言模型的强化学习框架，能够学习提问相关问题并进行推理来指导在实际环境中执行的行为的学习。

    

    大型语言模型通过将基于行动的策略与思维链（CoT）推理相结合，展示了解决复杂实际挑战的潜力。然而，对于该框架的有效性来说，具有高质量的提示非常重要。目前，这些提示是通过广泛使用人力手工制作的，导致CoT策略经常无法推广。为了确保低层控制器适当地处理CoT推理，还需要人为介入来开发接地函数。在本文中，我们迈出了迈向在复杂推理中应用实际环境中的任务解决的完全集成的端到端框架的第一步。为此，我们提供了一个新的领导者-追随者双层框架，能够学习提问相关问题（提示），并随后进行推理，指导在环境中执行的行为的学习。一个好的提示应该基于历史的自省性修订来进行修改。

    Large language models (LLMs) demonstrate their promise in tackling complicated practical challenges by combining action-based policies with chain of thought (CoT) reasoning. Having high-quality prompts on hand, however, is vital to the framework's effectiveness. Currently, these prompts are handcrafted utilizing extensive human labor, resulting in CoT policies that frequently fail to generalize. Human intervention is also required in order to develop grounding functions that ensure low-level controllers appropriately process CoT reasoning. In this paper, we take the first step towards a fully integrated end-to-end framework for task-solving in real settings employing complicated reasoning. To that purpose, we offer a new leader-follower bilevel framework capable of learning to ask relevant questions (prompts) and subsequently undertaking reasoning to guide the learning of actions to be performed in an environment. A good prompt should make introspective revisions based on historical fi
    
[^155]: PlaceNav: 通过地点识别进行拓扑导航

    PlaceNav: Topological Navigation through Place Recognition. (arXiv:2309.17260v1 [cs.RO])

    [http://arxiv.org/abs/2309.17260](http://arxiv.org/abs/2309.17260)

    PlaceNav是一种通过地点识别进行拓扑导航的方法，将机器人无关部分分为导航特定和通用的计算机视觉组件，通过使用非机器人来源的大规模数据集增加训练数据的可用性，同时通过地点识别来提高导航性能。新模型的性能提高了76%。

    

    最近的研究结果表明，将拓扑导航分为机器人无关和机器人特定的组件可以提高导航性能，通过使用不同类型机器人收集的数据来训练机器人无关部分。然而，导航方法仍受到适合训练数据的稀缺性和计算缩放性差的限制。在本文中，我们提出了一个名为PlaceNav的方法，将机器人无关部分分为导航特定和通用的计算机视觉组件。我们利用视觉地点识别来选择拓扑导航流程中的子目标。这使得子目标选择更高效，并能够利用非机器人来源的大规模数据集增加训练数据的可用性。地点识别使得贝叶斯滤波成为可能，进一步通过增加子目标的时间一致性来提高导航性能。我们的实验结果验证了这一设计，并且新模型的性能提高了76%。

    Recent results suggest that splitting topological navigation into robot-independent and robot-specific components improves navigation performance by enabling the robot-independent part to be trained with data collected by different robot types. However, the navigation methods are still limited by the scarcity of suitable training data and suffer from poor computational scaling. In this work, we present~\methodname, subdividing the robot-independent part into navigation-specific and generic computer vision components. We utilize visual place recognition for the subgoal selection of the topological navigation pipeline. This makes subgoal selection more efficient and enables leveraging large-scale datasets from non-robotics sources, increasing training data availability. Bayes filtering, enabled by place recognition, further improves navigation performance by increasing the temporal consistency of subgoals. Our experimental results verify the design and the new model obtains a 76% higher 
    
[^156]: ASAP: 自动化复杂机器人组装的物理可行性序列规划

    ASAP: Automated Sequence Planning for Complex Robotic Assembly with Physical Feasibility. (arXiv:2309.16909v1 [cs.RO])

    [http://arxiv.org/abs/2309.16909](http://arxiv.org/abs/2309.16909)

    ASAP是一个基于物理的计划方法，用于自动生成一般形状组装的物理可行性序列。它通过考虑重力和使用高效的树搜索算法，能够在大型数据集上生成物理实际的组装序列规划，适用于仿真和真实世界机器人设置。

    

    复杂产品的自动化组装需要一个系统能够自动规划一个物理可行的动作序列来组装多个部件。在本文中，我们提出了ASAP，一种基于物理的计划方法，用于自动生成一般形状组装的序列。ASAP考虑了重力，设计了一个序列，其中每个子组件在有限数量的零件被保持和支撑表面的情况下保持物理稳定。我们应用高效的树搜索算法来减少确定这样一个组装序列的组合复杂性。搜索可以由几何启发式或训练有模拟标签数据的图神经网络来引导。最后，我们展示了ASAP在数百个复杂产品组装的大型数据集上生成物理实际的组装序列规划的优越性能。我们进一步证明了ASAP在仿真和真实世界机器人设置上的适用性。

    The automated assembly of complex products requires a system that can automatically plan a physically feasible sequence of actions for assembling many parts together. In this paper, we present ASAP, a physics-based planning approach for automatically generating such a sequence for general-shaped assemblies. ASAP accounts for gravity to design a sequence where each sub-assembly is physically stable with a limited number of parts being held and a support surface. We apply efficient tree search algorithms to reduce the combinatorial complexity of determining such an assembly sequence. The search can be guided by either geometric heuristics or graph neural networks trained on data with simulation labels. Finally, we show the superior performance of ASAP at generating physically realistic assembly sequence plans on a large dataset of hundreds of complex product assemblies. We further demonstrate the applicability of ASAP on both simulation and real-world robotic setups. Project website: asa
    
[^157]: 通过自适应反向传播实现大型语言模型的绿色AI细调

    Towards Green AI in Fine-tuning Large Language Models via Adaptive Backpropagation. (arXiv:2309.13192v1 [cs.LG])

    [http://arxiv.org/abs/2309.13192](http://arxiv.org/abs/2309.13192)

    本文提出了GreenTrainer，一种新的LLM细调技术，通过自适应评估不同张量的反向传播成本和对细调模型准确性的贡献，以实现绿色AI。

    

    细调是将预训练的大型语言模型（LLMs）适应到下游应用中最有效的方法。随着LLM驱动的AI应用的快速增长以及开源LLM的民主化，非专业人员也可以进行细调，但是全球范围内对LLM的大规模细调可能导致能源消耗和碳足迹显著增加，从而对环境产生重大影响。实现绿色AI以减少细调的FLOPs直接相关，但是现有的高效LLM细调技术只能实现有限的FLOPs降低，因为它们忽视了细调中的反向传播成本。为了解决这个限制，本文提出了GreenTrainer，一种新的LLM细调技术，通过自适应评估不同张量的反向传播成本和对细调模型准确性的贡献，通过选择最有效的张量来最小化细调成本。

    Fine-tuning is the most effective way of adapting pre-trained large language models (LLMs) to downstream applications. With the fast growth of LLM-enabled AI applications and democratization of open-souced LLMs, fine-tuning has become possible for non-expert individuals, but intensively performed LLM fine-tuning worldwide could result in significantly high energy consumption and carbon footprint, which may bring large environmental impact. Mitigating such environmental impact towards Green AI directly correlates to reducing the FLOPs of fine-tuning, but existing techniques on efficient LLM fine-tuning can only achieve limited reduction of such FLOPs, due to their ignorance of the backpropagation cost in fine-tuning. To address this limitation, in this paper we present GreenTrainer, a new LLM fine-tuning technique that adaptively evaluates different tensors' backpropagation costs and contributions to the fine-tuned model accuracy, to minimize the fine-tuning cost by selecting the most a
    
[^158]: 演练：通过模拟冲突来教授冲突解决方法

    Rehearsal: Simulating Conflict to Teach Conflict Resolution. (arXiv:2309.12309v1 [cs.HC])

    [http://arxiv.org/abs/2309.12309](http://arxiv.org/abs/2309.12309)

    演练是一个系统，通过模拟冲突和提供反馈，教授用户冲突解决的技能。利用演练，用户可以练习处理各种冲突场景，并学习如何运用冲突策略。

    

    人际冲突是一种令人不舒服但不可避免的生活事实。成功地处理冲突是一种技能，可以通过刻意练习来学习，但是很少有人能够获得有效的培训或反馈。为了扩大这种机会，我们介绍了演练（Rehearsal）系统，该系统允许用户与可信的模拟对话者一起排练冲突，探索如果情况如何的“假设”场景以识别替代的对话路径，并通过反馈学习何时以及如何应用特定的冲突策略。用户可以使用演练来练习处理各种已定义的冲突场景，从办公室争议到情感问题，或者他们也可以选择创建自己的冲突场景。为了实现演练，我们开发了IRP提示方法，该方法通过冲突解决中具有影响力的利益-权力-能力（IRP）理论来调节大型语言模型的输出。演练使用IRP生成基于冲突解决理论的话语，引导用户实践应用冲突解决策略。

    Interpersonal conflict is an uncomfortable but unavoidable fact of life. Navigating conflict successfully is a skill -- one that can be learned through deliberate practice -- but few have access to effective training or feedback. To expand this access, we introduce Rehearsal, a system that allows users to rehearse conflicts with a believable simulated interlocutor, explore counterfactual "what if?" scenarios to identify alternative conversational paths, and learn through feedback on how and when to apply specific conflict strategies. Users can utilize Rehearsal to practice handling a variety of predefined conflict scenarios, from office disputes to relationship issues, or they can choose to create their own. To enable Rehearsal, we develop IRP prompting, a method of conditioning output of a large language model on the influential Interest-Rights-Power (IRP) theory from conflict resolution. Rehearsal uses IRP to generate utterances grounded in conflict resolution theory, guiding users t
    
[^159]: CoT-BERT: 通过思维链条增强无监督句子表示

    CoT-BERT: Enhancing Unsupervised Sentence Representation through Chain-of-Thought. (arXiv:2309.11143v1 [cs.CL])

    [http://arxiv.org/abs/2309.11143](http://arxiv.org/abs/2309.11143)

    CoT-BERT提出了一种通过思维链条增强无监督句子表示的方法，通过两个阶段的处理，引入思维链条的概念进行向量化，以提高模型性能。

    

    无监督句子表示学习旨在将输入句子转化为富含复杂语义信息的固定长度向量，同时消除对标注数据的依赖。近年来，在对比学习和提示工程的推动下，该领域取得了显著进展，极大地缩小了无监督和有监督策略之间的差距。然而，在这个轨迹中，仍然没有充分利用思维链条的潜在能力。为了释放预训练模型（如BERT）中的潜能，我们提出了一个句子表示的两阶段方法：理解和摘要。随后，后一阶段的输出被利用为输入句子的向量化表示。为了进一步提高性能，我们对对比学习损失函数和模板去噪技术进行了精细调整。严格的实验验证了我们的方法CoT-BERT的优越性。

    Unsupervised sentence representation learning aims to transform input sentences into fixed-length vectors enriched with intricate semantic information while obviating the reliance on labeled data. Recent progress within this field, propelled by contrastive learning and prompt engineering, has significantly bridged the gap between unsupervised and supervised strategies. Nonetheless, the potential utilization of Chain-of-Thought, remains largely untapped within this trajectory. To unlock latent capabilities within pre-trained models, such as BERT, we propose a two-stage approach for sentence representation: comprehension and summarization. Subsequently, the output of the latter phase is harnessed as the vectorized representation of the input sentence. For further performance enhancement, we meticulously refine both the contrastive learning loss function and the template denoising technique for prompt engineering. Rigorous experimentation substantiates our method, CoT-BERT, transcending a
    
[^160]: 内存注入：在Transformer-Based语言模型中纠正多跳推理错误

    Memory Injections: Correcting Multi-Hop Reasoning Failures during Inference in Transformer-Based Language Models. (arXiv:2309.05605v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.05605](http://arxiv.org/abs/2309.05605)

    本文提出了一种通过向Transformer-Based语言模型的LLM注意力头部定向注入内存来纠正多跳推理错误的方法，从而提高了模型在处理多跳推理问题时的表现。

    

    回答多跳推理问题需要从多个信息源中检索和综合信息。大语言模型(LLMs)往往难以保持一致的推理能力。本文提出了一种通过在LLM注意力头部进行定向内存注入来确定和纠正多跳推理错误的方法。首先，我们分析了GPT-2模型在单跳和多跳提示下各层的激活情况。然后，我们提出了一种机制，允许用户在推理过程中向关键LLM位置注入相关的提示特定信息，我们将其称为“记忆”。通过在推理过程中使LLM能够整合额外的相关信息，我们提高了多跳提示生成的质量。我们实证表明，将简单、高效且定向的记忆注入到关键注意力层中往往能够提高多跳任务中所需下一个标记的概率，提高了达到424%。

    Answering multi-hop reasoning questions requires retrieving and synthesizing information from diverse sources. Large Language Models (LLMs) struggle to perform such reasoning consistently. Here we propose an approach to pinpoint and rectify multi-hop reasoning failures through targeted memory injections on LLM attention heads. First, we analyze the per-layer activations of GPT-2 models in response to single and multi-hop prompts. We then propose a mechanism that allows users to inject pertinent prompt-specific information, which we refer to as "memories," at critical LLM locations during inference. By thus enabling the LLM to incorporate additional relevant information during inference, we enhance the quality of multi-hop prompt completions. We show empirically that a simple, efficient, and targeted memory injection into a key attention layer can often increase the probability of the desired next token in multi-hop tasks, by up to 424%.
    
[^161]: 用于机器人操作的具有物理基础的视觉语言模型

    Physically Grounded Vision-Language Models for Robotic Manipulation. (arXiv:2309.02561v1 [cs.RO])

    [http://arxiv.org/abs/2309.02561](http://arxiv.org/abs/2309.02561)

    该论文介绍了一个用于机器人操作的具有物理基础的视觉语言模型，通过在物体上微调模型，提高了模型对物理概念的理解，在语言交互框架中展现了良好的性能。

    

    最近对于视觉语言模型（VLMs）的研究进展导致在视觉问答和图像描述等任务上的性能得到了提升。因此，这些模型现在可以在物理世界中进行推理，特别是在机器人操作领域。然而，当前的VLMs在对常见物体的物理概念（例如材料、脆弱性）的理解方面存在局限，这限制了它们在涉及与这些物体的相互作用和物理推理的机器人操作任务中的实用性。为了解决这个问题，我们提出了PhysObjects，这是一个以物体为中心的数据集，包含36.9K个众包和417K个自动化的常见家居物品的物理概念注释。我们证明，在PhysObjects上对VLM进行微调可以提高其对物理物体概念的理解，通过从视觉外观中捕捉这些概念的人类先验知识。我们在一个大型的语言交互框架中将这个具有物理基础的VLM结合在一起。

    Recent advances in vision-language models (VLMs) have led to improved performance on tasks such as visual question answering and image captioning. Consequently, these models are now well-positioned to reason about the physical world, particularly within domains such as robotic manipulation. However, current VLMs are limited in their understanding of the physical concepts (e.g., material, fragility) of common objects, which restricts their usefulness for robotic manipulation tasks that involve interaction and physical reasoning about such objects. To address this limitation, we propose PhysObjects, an object-centric dataset of 36.9K crowd-sourced and 417K automated physical concept annotations of common household objects. We demonstrate that fine-tuning a VLM on PhysObjects improves its understanding of physical object concepts, by capturing human priors of these concepts from visual appearance. We incorporate this physically-grounded VLM in an interactive framework with a large languag
    
[^162]: 基于区域方法的机器学习和物理约束神经网络在加热炉中的应用

    Application of Zone Method based Machine Learning and Physics-Informed Neural Networks in Reheating Furnaces. (arXiv:2308.16089v1 [cs.LG])

    [http://arxiv.org/abs/2308.16089](http://arxiv.org/abs/2308.16089)

    本文将经典的Hottel区域方法与机器学习和深度学习相结合，利用生成的数据进行加热炉控制系统的训练，为基础产业的可持续制造和能耗降低目标做出贡献。

    

    尽管基础产业的经济重要性很高，但其生产链中的一些组件，如加热炉，能耗较高。通过减少加热炉中的整体加热时间，可以显著降低能耗。在基础产业可持续制造中，计算机集成的机器学习（ML）和人工智能（AI）控制系统可能是实现“零净排放”目标的关键。本文中，由于在加热炉等场景中无法获得高质量的数据的可行性，采用经典的Hottel区域方法基于计算模型生成数据，用于ML和深度学习（DL）模型的回归训练。值得注意的是，区域方法提供了一种优雅的方式来建模辐射传热（RHT）的物理现象，这是加热炉内高温过程中占主导地位的传热机制。利用这些数据，进行了详细的实验研究。

    Despite the high economic relevance of Foundation Industries, certain components like Reheating furnaces within their manufacturing chain are energy-intensive. Notable energy consumption reduction could be obtained by reducing the overall heating time in furnaces. Computer-integrated Machine Learning (ML) and Artificial Intelligence (AI) powered control systems in furnaces could be enablers in achieving the Net-Zero goals in Foundation Industries for sustainable manufacturing.  In this work, due to the infeasibility of achieving good quality data in scenarios like reheating furnaces, classical Hottel's zone method based computational model has been used to generate data for ML and Deep Learning (DL) based model training via regression. It should be noted that the zone method provides an elegant way to model the physical phenomenon of Radiative Heat Transfer (RHT), the dominating heat transfer mechanism in high-temperature processes inside heating furnaces. Using this data, an extensive
    
[^163]: ReLLa: 基于检索增强的大型语言模型的推荐系统中的生命周期序列行为理解

    ReLLa: Retrieval-enhanced Large Language Models for Lifelong Sequential Behavior Comprehension in Recommendation. (arXiv:2308.11131v1 [cs.IR])

    [http://arxiv.org/abs/2308.11131](http://arxiv.org/abs/2308.11131)

    本论文提出了一种名为ReLLa的检索增强大型语言模型框架，用于零样本和小样本推荐任务。通过语义用户行为检索（SUBR）来提取上下文中的有用信息，以改善LLMs的推荐性能。

    

    随着大型语言模型（LLMs）在自然语言处理（NLP）领域取得了显著突破，基于LLM的推荐系统引起了广泛关注并被积极探索。本文专注于适应和增强纯大型语言模型以用于零样本和小样本推荐任务。首先，我们针对推荐领域中LLMs无法从长用户行为序列的文本上下文中提取有用信息的问题，提出并定义了生命周期序列行为理解问题。为了解决这个问题并提高LLMs的推荐性能，我们提出了一种新的框架，即检索增强的大型语言模型（ReLLa）。针对零样本推荐，我们执行语义用户行为检索（SUBR）来提高数据的利用率。

    With large language models (LLMs) achieving remarkable breakthroughs in natural language processing (NLP) domains, LLM-enhanced recommender systems have received much attention and have been actively explored currently. In this paper, we focus on adapting and empowering a pure large language model for zero-shot and few-shot recommendation tasks. First and foremost, we identify and formulate the lifelong sequential behavior incomprehension problem for LLMs in recommendation domains, i.e., LLMs fail to extract useful information from a textual context of long user behavior sequence, even if the length of context is far from reaching the context limitation of LLMs. To address such an issue and improve the recommendation performance of LLMs, we propose a novel framework, namely Retrieval-enhanced Large Language models (ReLLa) for recommendation tasks in both zero-shot and few-shot settings. For zero-shot recommendation, we perform semantic user behavior retrieval (SUBR) to improve the data
    
[^164]: 总括荷尔蒙体系作为HOL的一个片段

    Normative Conditional Reasoning as a Fragment of HOL. (arXiv:2308.10686v2 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2308.10686](http://arxiv.org/abs/2308.10686)

    本论文报告了关于正式化条件推理的研究结果，包括Aqvist的条件义务系统E的机械化和伦理论据评估的工具的开发。

    

    我们报告了关于正式化（基于偏好的）条件推理的一些结果。我们关注的是Aqvist的条件义务系统E（及其扩展）。我们通过Isabelle/HOL中的浅表语义嵌入来实现我们的正式化。我们考虑了该框架的两种可能用途。第一种是作为对所考虑逻辑进行元推理的工具。我们将其用于自动验证权利义务对应关系（广义上理解）及相关事项，类似于之前对模态逻辑立方体所取得的成果。第二种用途是作为伦理论据评估的工具。我们提供了人口伦理学中一个众所周知的悖论Parfit的令人厌恶的结论的计算机编码。如何通过这个编码增加或减少令人厌恶的结论的吸引力和说服力是一个我们希望向哲学和伦理学提出的问题。

    We report some results regarding the mechanization of normative (preference-based) conditional reasoning. Our focus is on Aqvist's system E for conditional obligation (and its extensions). Our mechanization is achieved via a shallow semantical embedding in Isabelle/HOL. We consider two possible uses of the framework. The first one is as a tool for meta-reasoning about the considered logic. We employ it for the automated verification of deontic correspondences (broadly conceived) and related matters, analogous to what has been previously achieved for the modal logic cube. The second use is as a tool for assessing ethical arguments. We provide a computer encoding of a well-known paradox in population ethics, Parfit's repugnant conclusion. Whether the presented encoding increases or decreases the attractiveness and persuasiveness of the repugnant conclusion is a question we would like to pass on to philosophy and ethics.
    
[^165]: 网络爬虫在robot.txt限制下的策略研究

    web crawler strategies for web pages under robot.txt restriction. (arXiv:2308.04689v1 [cs.AI])

    [http://arxiv.org/abs/2308.04689](http://arxiv.org/abs/2308.04689)

    本文研究了在robot.txt限制下的网络爬虫策略，讨论了搜索引擎如何确定网页排名以及如何获取数据库中的网页。并介绍了机器人排除协议规则和robot.txt文件的基本格式。

    

    当今，所有人都了解互联网并每天在互联网上工作。本文介绍了为用户输入的关键字进行搜索的搜索引擎。搜索引擎使用不同的搜索算法，为上网者提供方便的结果。上网者选择排名靠前的搜索结果，但是网页的排名是如何由搜索引擎确定的？搜索引擎如何获取数据库中的所有网页？本文给出了所有这些基本问题的答案。本研究论文还讨论了为搜索引擎工作的网络爬虫和网络爬虫的机器人排除协议规则。网站管理员使用robot.txt文件中的不同限制规则指导网络爬虫，本文还提到了一些基本的robot.txt格式。

    In the present time, all know about World Wide Web and work over the Internet daily. In this paper, we introduce the search engines working for keywords that are entered by users to find something. The search engine uses different search algorithms for convenient results for providing to the net surfer. Net surfers go with the top search results but how did the results of web pages get higher ranks over search engines? how the search engine got that all the web pages in the database? This paper gives the answers to all these kinds of basic questions. Web crawlers working for search engines and robot exclusion protocol rules for web crawlers are also addressed in this research paper. Webmaster uses different restriction facts in robot.txt file to instruct web crawler, some basic formats of robot.txt are also mentioned in this paper.
    
[^166]: 基于巴克汉姆π定理的无量纲策略：是推广数值结果的好方法吗？

    Dimensionless Policies based on the Buckingham $\pi$ Theorem: Is it a good way to Generalize Numerical Results?. (arXiv:2307.15852v1 [math.OC])

    [http://arxiv.org/abs/2307.15852](http://arxiv.org/abs/2307.15852)

    通过使用无量纲变量和制度的概念，我们可以将数值生成的最优控制法则推广到量纲相似的系统，这对于推广解决更复杂的高维问题的策略具有潜在意义。

    

    如果上下文环境和定义运动控制问题的变量列表是在量纲上相似的话，是可以的。我们在这里展示了通过使用无量纲变量修改问题的形式，可以将数值生成的最优控制法则重新应用于在量纲上相似的子空间系统。我们通过对受扭矩限制的倒立摆经典运动控制问题进行数值生成的最优控制器的展示来证明这一点。我们还讨论了制度的概念，即上下文变量空间中的一个区域，可以帮助放宽量纲相似性的条件。此外，我们还讨论了将上下文特定策略的输入和输出进行量纲缩放与在分析方程中用新的系统参数替代量纲相似系统的等价性。尚需进一步研究此方法是否也适用于推广更复杂的高维问题的策略。

    Yes if the context, the list of variables defining the motion control problem, is dimensionally similar. Here we show that by modifying the problem formulation using dimensionless variables, we can re-use the optimal control law generated numerically for a specific system to a sub-space of dimensionally similar systems. This is demonstrated, with numerically generated optimal controllers, for the classic motion control problem of swinging-up a torque-limited inverted pendulum. We also discuss the concept of regime, a region in the space of context variables, that can help relax the condition on dimensional similarity. Futhermore, we discuss how applying dimensionnal scaling of the input and output of a context-specific policy is equivalent to substituing the new systems parameters in an analytical equation for dimentionnaly similar systems. It remains to be seen if this approach can also help generalizing policies for more complex high-dimensional problems.
    
[^167]: "感觉像有第二个思维": 探究在大型语言模型中进行创意可写性预写的人机共创

    "It Felt Like Having a Second Mind": Investigating Human-AI Co-creativity in Prewriting with Large Language Models. (arXiv:2307.10811v1 [cs.HC])

    [http://arxiv.org/abs/2307.10811](http://arxiv.org/abs/2307.10811)

    通过三节次的定性研究，探究了人类与大型语言模型在预写过程中的合作模式，并发现了一个三阶段的人机共创过程：构思、启发和实施。在这个合作过程中，人类扮演着主导角色。

    

    预写是在第一稿之前发现和发展思想的过程，它需要发散性思维，通常涉及到无结构的策略，如图表、概述和自由写作等。虽然已经证明大型语言模型（LLMs）在各种任务中都是有用的，包括创意写作，但对用户如何与LLMs合作来支持预写的方式知之甚少。在这种创造性过程中，LLMs的首选合作角色和主动性也不明确。为了研究人类与LLMs在预写过程中的合作模式和动力学，我们进行了一项三节次的定性研究，与15位参与者进行了两个创造性任务：写故事和写口号。研究结果表明，在合作的预写过程中，似乎存在着一个三阶段迭代的人机共创过程，包括构思、启发和实施阶段。这个合作过程以人类在主导角色中取得了成功。

    Prewriting is the process of discovering and developing ideas before a first draft, which requires divergent thinking and often implies unstructured strategies such as diagramming, outlining, free-writing, etc. Although large language models (LLMs) have been demonstrated to be useful for a variety of tasks including creative writing, little is known about how users would collaborate with LLMs to support prewriting. The preferred collaborative role and initiative of LLMs during such a creativity process is also unclear. To investigate human-LLM collaboration patterns and dynamics during prewriting, we conducted a three-session qualitative study with 15 participants in two creative tasks: story writing and slogan writing. The findings indicated that during collaborative prewriting, there appears to be a three-stage iterative Human-AI Co-creativity process that includes Ideation, Illumination, and Implementation stages. This collaborative process champions the human in a dominant role, in
    
[^168]: 开放联邦学习平台：技术和法律观察的综述和愿景

    Towards Open Federated Learning Platforms: Survey and Vision from Technical and Legal Perspectives. (arXiv:2307.02140v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2307.02140](http://arxiv.org/abs/2307.02140)

    本文探讨了开放联邦学习平台的技术和法律观察，提出了基于查询和基于合同的两种适用于开放联邦学习的合作框架，并对构建开放的FL平台的可行性进行了全面评估。

    

    传统的联邦学习（FL）遵循服务器主导的合作模式，限制了FL的应用场景，并降低了数据持有者参与的热情。为了充分释放FL的潜力，我们主张重新思考当前FL框架的设计，并将其扩展为更通用的概念：开放联邦学习平台。我们提出了两个相互合作的FL框架：基于查询的FL和基于合同的FL。在这个综述中，我们从技术和法律的角度对构建开放的FL平台的可行性进行了全面的评估。我们首先回顾了FL的定义，并总结了其固有的局限性，包括服务器-客户端耦合、模型可重用性低和非公开性。在基于查询的FL平台中，这是一个由社区赋能的开放模型共享和重用平台，我们探讨了一系列有价值的主题，包括全球最新可用模型和模型的查询、服务质量保证和奖励机制。

    Traditional Federated Learning (FL) follows a server-domincated cooperation paradigm which narrows the application scenarios of FL and decreases the enthusiasm of data holders to participate. To fully unleash the potential of FL, we advocate rethinking the design of current FL frameworks and extending it to a more generalized concept: Open Federated Learning Platforms. We propose two reciprocal cooperation frameworks for FL to achieve this: query-based FL and contract-based FL. In this survey, we conduct a comprehensive review of the feasibility of constructing an open FL platform from both technical and legal perspectives. We begin by reviewing the definition of FL and summarizing its inherent limitations, including server-client coupling, low model reusability, and non-public. In the query-based FL platform, which is an open model sharing and reusing platform empowered by the community for model mining, we explore a wide range of valuable topics, including the availability of up-to-d
    
[^169]: 自动自我生成的零样本编码从语义级别到代码级别的 SelfzCoT，更好地利用LLMs

    SelfzCoT: a Self-Prompt Zero-shot CoT from Semantic-level to Code-level for a Better Utilization of LLMs. (arXiv:2305.11461v1 [cs.AI])

    [http://arxiv.org/abs/2305.11461](http://arxiv.org/abs/2305.11461)

    本文提出了 SelfzCoT 自动自我生成的零样本编码，通过使用LLMs和代码级别的自我提示，在六个零样本算术推理任务中实现了巨大的准确度提升。同时，修改的零样本编码 MzCoT 在推理任务中也取得了显著的表现。

    

    本文通过 SelfzCoT 自动自我生成的零样本编码，研究了如何更好地利用LLMs。具体地，我们将 SelfzCoT 应用于零样本算术推理任务，其准确性从GSM8K的40.50%提高至82.34%，MultiArith从79.3%提高至94.7%，ADDSUB从74.70%提高至94.10%，SingleEq从78.70%提高至91.30%，AQUA从31.90%提高至82.33%，SVAMP从63.70%提高至79.70%。总的来说，使用前两个持久路径激活到LLM，特别是代码级别的自我提示，使 SelfzCoT 在所有六个零样本算术推理任务上实现了巨大的改进。此外，我们修改的零样本编码 MzCoT 在推理任务中也取得了显著的表现。在GSM8K中，MzCoT的准确性从40.50%提高至76.32%，MultiArith从79.3%提高至96.97%，ADDSUB从74.70%提高至92.39%，SingleEq从78.70%提高至94.60%，AQUA从31.90%提高至79.90%，SVAMP从63.70%提高至81.50%。

    This paper show a work on better use of LLMs with SelfzCoT a self-prompt zero-shot CoT. Specifically, on the zero-shot arithmetic reasoning tasks, the accuracy of the proposed SelfzCoT is improved with GSM8K from 40.50% to 82.34%, with MultiArith from 79.3% to 94.7%, with ADDSUB from 74.70% to 94.10%, with SingleEq from 78.70% to 91.30%, with AQUA from 31.90% to 82.33%, and with SVAMP from 63.70% to 79.70%. Totally, using the first two lasting path activations to LLM and particularly, the code-level self-prompt, the SelfzCoT has a huge improvement on all six zero-shot arithmetic reasoning tasks. Additionally, our modified zero-shot CoT (MzCoT) also achieves remarkable performance in the reasoning tasks. The accuracy of the proposed MzCoT is enhanced with GSM8K from 40.50% to 76.32%, with MultiArith from 79.3% to 96.97%, with ADDSUB from 74.70% to 92.39%, with SingleEq from 78.70% to 94.60%, with AQUA from 31.90% to 79.90%, and with SVAMP from 63.70% to 81.50%. Notably, SelfzCoT has the
    
[^170]: 非合作博弈中的人类选择预测：基于模拟的离线策略评估

    Human Choice Prediction in Non-Cooperative Games: Simulation-based Off-Policy Evaluation. (arXiv:2305.10361v1 [cs.LG])

    [http://arxiv.org/abs/2305.10361](http://arxiv.org/abs/2305.10361)

    本文研究了语言游戏中的离线策略评估，并提出了一种结合真实和模拟数据的新方法。

    

    说服游戏在经济和人工智能研究中具有重要意义并具有重要的实际应用。本文探讨了在基于语言的说服游戏中离线策略评估（OPE）的挑战性问题，提出了一种结合真实和模拟人类 - 机器人交互数据的新方法，并给出了一种深度学习训练算法，该算法有效地整合了真实交互和模拟数据。

    Persuasion games have been fundamental in economics and AI research, and have significant practical applications. Recent works in this area have started to incorporate natural language, moving beyond the traditional stylized message setting. However, previous research has focused on on-policy prediction, where the train and test data have the same distribution, which is not representative of real-life scenarios. In this paper, we tackle the challenging problem of off-policy evaluation (OPE) in language-based persuasion games. To address the inherent difficulty of human data collection in this setup, we propose a novel approach which combines real and simulated human-bot interaction data. Our simulated data is created by an exogenous model assuming decision makers (DMs) start with a mixture of random and decision-theoretic based behaviors and improve over time. We present a deep learning training algorithm that effectively integrates real interaction and simulated data, substantially im
    
[^171]: 用语言分类探究单语BERT的语言属性

    Exploring Linguistic Properties of Monolingual BERTs with Typological Classification among Languages. (arXiv:2305.02215v1 [cs.CL])

    [http://arxiv.org/abs/2305.02215](http://arxiv.org/abs/2305.02215)

    本文研究使用语言分类方法探究单语BERT的语言属性，核心发现为BERT正在复制传统的语言模型。

    

    Transformer模型的巨大成功使人们产生了一个问题：这些机器是在复制某些传统的语言模型，还是发现了根本性的新理论？在本文中，我们提出了一种新的研究观点，使用语言之间的类型相似性来对比不同语言的transformer模型，观察这些相似性是否出现在特定的层次。为了进行这项研究，我们提出了基于中心核对齐的权重矩阵相似度测量方法。我们发现，句法类型学相似性与中间层权重之间的相似性是一致的。这一发现确认了通过句法探针方法获得的BERT的结果，并因此重要地证明了BERT正在复制传统的语言模型。

    The overwhelming success of transformers is a real conundrum stimulating a compelling question: are these machines replicating some traditional linguistic models or discovering radically new theories? In this paper, we propose a novel standpoint to investigate this important question. Using typological similarities among languages, we aim to layer-wise compare transformers for different languages to observe whether these similarities emerge for particular layers. For this investigation, we propose to use Centered kernel alignment to measure similarity among weight matrices. We discovered that syntactic typological similarity is consistent with the similarity among weights in the middle layers. This finding confirms results obtained by syntactically probing BERT and, thus, gives an important confirmation that BERT is replicating traditional linguistic models.
    
[^172]: 用人工神经网络预测国内生产总值：长期记忆有多大的作用？

    GDP nowcasting with artificial neural networks: How much does long-term memory matter?. (arXiv:2304.05805v1 [econ.EM])

    [http://arxiv.org/abs/2304.05805](http://arxiv.org/abs/2304.05805)

    通过比较四种人工神经网络和动态因子模型对美国GDP季度增长的预测表现，研究发现在平衡经济增长期间，更长的输入序列能够实现更准确的预测，但是这种效果会在不到两年的时间内消失。在经济动荡时期，长期记忆的效果变得明显。

    

    在本研究中，我们将不同的统计模型应用于美国经济季度国内生产总值（GDP）增长预测。使用每月的FRED-MD数据库，我们比较了动态因子模型（DFM）和四个人工神经网络（ANNs）的预测表现：多层感知机（MLP）、一维卷积神经网络（1D CNN）、长短期记忆网络（LSTM）和门控循环单元（GRU）。实证分析呈现了两个不同评估周期的结果。第一个周期（2010年第1季度至2019年第4季度）具有平衡的经济增长，而第二个周期（2010年第1季度至2022年第3季度）还包括COVID-19衰退期间的时间。根据我们的结果，更长的输入序列在平衡经济增长期间能够实现更准确的预测。然而，在一个相对较低的阈值值（约六个季度或十八个月）以后，这种效应会消失。在经济动荡期（如COVID-19衰退期间），长期记忆的效果会变得较为明显。

    In our study, we apply different statistical models to nowcast quarterly GDP growth for the US economy. Using the monthly FRED-MD database, we compare the nowcasting performance of the dynamic factor model (DFM) and four artificial neural networks (ANNs): the multilayer perceptron (MLP), the one-dimensional convolutional neural network (1D CNN), the long short-term memory network (LSTM), and the gated recurrent unit (GRU). The empirical analysis presents the results from two distinctively different evaluation periods. The first (2010:Q1 -- 2019:Q4) is characterized by balanced economic growth, while the second (2010:Q1 -- 2022:Q3) also includes periods of the COVID-19 recession. According to our results, longer input sequences result in more accurate nowcasts in periods of balanced economic growth. However, this effect ceases above a relatively low threshold value of around six quarters (eighteen months). During periods of economic turbulence (e.g., during the COVID-19 recession), long
    
[^173]: 通过内容感知的风格不变模型学习对未知领域进行泛化：用于胸部X射线疾病检测的翻译摘要

    Learning to Generalize towards Unseen Domains via a Content-Aware Style Invariant Model for Disease Detection from Chest X-rays. (arXiv:2302.13991v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.13991](http://arxiv.org/abs/2302.13991)

    通过内容感知的风格不变模型，我们提出了一种解决深度学习医学图像分析中源领域不匹配挑战的方法。我们采用了风格随机化模块来提取既是风格不变又是内容偏好的领域不变特征，在胸部X射线疾病检测中取得了良好的性能。

    

    在基于深度学习的医学图像分析中，由于源领域不匹配而导致性能降低一直是一个长期存在的挑战，特别是在胸部X射线（CXR）领域。为了解决这种领域转移问题，已经提出了一些方法（如对抗训练，多领域混合），用于提取领域不变的高级特征。然而，这些方法并没有明确规范提取的领域不变特征的内容和风格特征。最近的研究表明，CNN模型对风格（例如，无信息的纹理）有很强的偏好，而不是对内容（例如，形状）的偏好，这与人类视觉系统形成鲜明对比。放射科医师倾向于从CXR图像中学习视觉线索，并因此在多个领域中表现良好。因此，在从CXR图像进行病理诊断的医学成像中，模型应该提取既是风格不变又是内容偏好的领域不变特征。受此启发，我们在实验中使用了新颖的风格随机化模块（SRMs）。

    Performance degradation due to source domain mismatch is a longstanding challenge in deep learning-based medical image analysis, particularly for chest X-rays (CXRs). Several methods (e.g., adversarial training, multi-domain mixups) have been proposed to extract domain-invariant high-level features to address this domain shift. However, these methods do not explicitly regularize the content and style characteristics of the extracted domain-invariant features. Recent studies have demonstrated that CNN models exhibit a strong bias toward styles (e.g., uninformative textures) rather than content (e.g., shape), in stark contrast to the human-vision system. Radiologists tend to learn visual cues from CXRs and thus perform well across multiple domains. Therefore, in medical imaging for pathology diagnosis from CXR images, models should extract domain-invariant features that are style-invariant and content-biased. Motivated by this, we employ the novel style randomization modules (SRMs) at bo
    
[^174]: 通过演示来理解专业技能：离线逆向强化学习的最大似然框架

    Understanding Expertise through Demonstrations: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning. (arXiv:2302.07457v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07457](http://arxiv.org/abs/2302.07457)

    通过提出的双层优化公式，我们提供了一个离线逆向强化学习的最大似然框架，该框架通过最大化奖励来估计专家的保守模型以及专家的环境动态，能够更准确地推断专业技能。

    

    离线逆向强化学习（Offline IRL）旨在从专家代理的固定有限演示中恢复支撑观察到的操作的奖励和环境动态的结构。准确的专业执行任务的模型在安全敏感的应用中具有重要应用，例如临床决策和自动驾驶。然而，专家喜好隐含在观察到的操作中的结构与专家对环境动态的模型（即“世界”）密切相关。因此，从具有有限覆盖范围的有限数据中获得的不准确世界模型可能会导致估计的奖励的不准确性变得更加严重。为了解决这个问题，我们提出了一个双层优化公式的估计任务，其中上层是基于专家策略的保守模型的最大似然估计（下层）。策略模型是保守的，因为它在惩罚（惩罚会随着专家对世界模型的不确定性而增加）下最大化奖励。我们的实验表明，我们的方法在各种基准测试任务中提高了离线IRL方法的准确性。

    Offline inverse reinforcement learning (Offline IRL) aims to recover the structure of rewards and environment dynamics that underlie observed actions in a fixed, finite set of demonstrations from an expert agent. Accurate models of expertise in executing a task has applications in safety-sensitive applications such as clinical decision making and autonomous driving. However, the structure of an expert's preferences implicit in observed actions is closely linked to the expert's model of the environment dynamics (i.e. the ``world''). Thus, inaccurate models of the world obtained from finite data with limited coverage could compound inaccuracy in estimated rewards. To address this issue, we propose a bi-level optimization formulation of the estimation task wherein the upper level is likelihood maximization based upon a conservative model of the expert's policy (lower level). The policy model is conservative in that it maximizes reward subject to a penalty that is increasing in the uncerta
    
[^175]: 零样本协同合作学习框架的合作开放式学习

    Cooperative Open-ended Learning Framework for Zero-shot Coordination. (arXiv:2302.04831v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.04831](http://arxiv.org/abs/2302.04831)

    该论文提出了一个COLE框架，通过构建合作游戏的开放式目标，从图论的角度评估和确定每个策略的协作能力，以有效地解决零样本协调中的合作不兼容性问题。

    

    协作人工智能中的零样本协调仍然是一个重大挑战，有效地协调一系列看不见的合作伙伴。先前的算法试图通过优化种群中的固定目标来改善策略或行为的多样性来解决这一挑战。然而，这些方法可能导致学习损失和与种群中某些策略无法合作，即合作不兼容性。为了解决这个问题，我们提出了合作开放式学习（COLE）框架，该框架从图论的角度构建了协作游戏的开放式目标，以评估和确定每个策略的协作能力。我们进一步明确了框架并提出了一种实用的算法，该算法利用了博弈论和图论的知识。此外，对算法的学习过程进行的分析显示，它可以有效地克服学习困难。

    Zero-shot coordination in cooperative artificial intelligence (AI) remains a significant challenge, which means effectively coordinating with a wide range of unseen partners. Previous algorithms have attempted to address this challenge by optimizing fixed objectives within a population to improve strategy or behaviour diversity. However, these approaches can result in a loss of learning and an inability to cooperate with certain strategies within the population, known as cooperative incompatibility. To address this issue, we propose the Cooperative Open-ended LEarning (COLE) framework, which constructs open-ended objectives in cooperative games with two players from the perspective of graph theory to assess and identify the cooperative ability of each strategy. We further specify the framework and propose a practical algorithm that leverages knowledge from game theory and graph theory. Furthermore, an analysis of the learning process of the algorithm shows that it can efficiently overc
    
[^176]: GPT-3是否展示出精神病态？从心理学角度评估大型语言模型

    Does GPT-3 Demonstrate Psychopathy? Evaluating Large Language Models from a Psychological Perspective. (arXiv:2212.10529v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10529](http://arxiv.org/abs/2212.10529)

    本文从心理学角度评估大型语言模型的安全性，发现所有模型在短暗三合一测验上的得分都高于人类平均水平，存在相对较暗的人格模式。尽管经过指标微调，两种模型仍呈现隐含的黑暗人格模式。同时，本文观察到GPT-3和InstructGPT的幸福感得分持续增加。

    

    本文旨在从心理学角度确定大型语言模型（LLMs）的安全性。我们设计了无偏的提示来系统性地评估LLMs。首先，我们使用了两个人格测试——短暗三合一测验（SD-3）和大五人格问卷（BFI）测试了三个不同的LLMs。所有模型在SD-3上的得分都高于人类平均水平，表明存在相对较暗的人格模式。尽管经过指标微调以减少毒性，InstructGPT和FLAN-T5仍然呈现出隐含的黑暗人格模式；在SD-3的玛基雅维利主义和自恋狂特征上，这两种模型的得分都高于自监督GPT-3。然后，我们使用幸福感测试评估了GPT-3系列中的LLMs，以研究更多训练数据的微调对其影响。我们观察到GPT-3和InstructGPT的幸福感得分持续增加。鉴于这些观察结果，我们展示了使用正面回答从而指标微调FLAN-T5的方法。

    In this work, we determined whether large language models (LLMs) are psychologically safe. We designed unbiased prompts to systematically evaluate LLMs from a psychological perspective. First, we tested three different LLMs by using two personality tests: Short Dark Triad (SD-3) and Big Five Inventory (BFI). All models scored higher than the human average on SD-3, suggesting a relatively darker personality pattern. Despite being instruction fine-tuned with safety metrics to reduce toxicity, InstructGPT and FLAN-T5 still showed implicit dark personality patterns; both models scored higher than self-supervised GPT-3 on the Machiavellianism and narcissism traits on SD-3. Then, we evaluated the LLMs in the GPT-3 series by using well-being tests to study the impact of fine-tuning with more training data. We observed a continuous increase in the well-being scores of GPT-3 and InstructGPT. Following these observations, we showed that instruction fine-tuning FLAN-T5 with positive answers from 
    

