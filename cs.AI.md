# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Deep Reinforcement Learning for Traveling Purchaser Problems](https://arxiv.org/abs/2404.02476) | 提出了一种基于深度强化学习的方法，该方法分别解决了旅行购买者问题中的路由构建和购买规划问题，并从全局角度评估和优化解决方案。 |
| [^2] | [Efficient Online Unlearning via Hessian-Free Recollection of Individual Data Statistics](https://arxiv.org/abs/2404.01712) | 通过提出的Hessian-free在线遗忘方法，实现了近乎瞬时的在线遗忘，仅需要进行矢量加法操作。 |
| [^3] | [Finding Regions of Interest in Whole Slide Images Using Multiple Instance Learning](https://arxiv.org/abs/2404.01446) | 本研究使用多实例学习方法来解决整张切片图像中准确预测癌症表型和在图块级别找到与之相关的细胞形态学的挑战。 |
| [^4] | [Source-Aware Training Enables Knowledge Attribution in Language Models](https://arxiv.org/abs/2404.01019) | 源感知训练使语言模型具备知识归因能力，进而增强了其透明度、可解释性和可验证性。 |
| [^5] | [Concept-based Analysis of Neural Networks via Vision-Language Models](https://arxiv.org/abs/2403.19837) | 本文提出利用视觉语言模型作为透镜，通过其隐含的高层次概念来进行对视觉模型的分析。 |
| [^6] | [KTbench: A Novel Data Leakage-Free Framework for Knowledge Tracing](https://arxiv.org/abs/2403.15304) | KTbench提出了一种无数据泄漏的知识追踪框架，解决了KT模型中KC之间的相关性学习可能导致的性能下降问题。 |
| [^7] | [Provable Privacy with Non-Private Pre-Processing](https://arxiv.org/abs/2403.13041) | 提出了一个框架，能够评估非私密数据相关预处理算法引起的额外隐私成本，并利用平滑DP和预处理算法的有界敏感性建立整体隐私保证的上限 |
| [^8] | [StateFlow: Enhancing LLM Task-Solving through State-Driven Workflows](https://arxiv.org/abs/2403.11322) | 提出了一种使用StateFlow的新颖LLM任务解决范式，将复杂任务解决过程概念化为状态机，通过状态转换确保LLM响应的清晰跟踪和管理。 |
| [^9] | [Gemma: Open Models Based on Gemini Research and Technology](https://arxiv.org/abs/2403.08295) | Gemma是基于Gemini研究和技术所构建的开放模型系列，在语言理解、推理和安全性等方面表现出色，负责任地发布这些大型语言模型对于提高前沿模型的安全性至关重要。 |
| [^10] | [Implications of Identity of AI: Creators, Creations, and Consequences](https://arxiv.org/abs/2403.07924) | 该论文探讨了人工智能领域的身份问题，强调了通过身份视角促进AI多样性在创造者、创作物和后果方面的重要性。 |
| [^11] | [Evaluation of LLMs on Syntax-Aware Code Fill-in-the-Middle Tasks](https://arxiv.org/abs/2403.04814) | 该研究引入了一个新的基准SAFIM用于评估LLMs在代码填空任务上的句法感知完成表现，发现FIM预训练不仅提高了FIM的熟练度，还改善了LLMs的左到右推理，挑战了传统观念并表明预训练方法和数据品质对模型性能的影响更甚于模型大小。 |
| [^12] | [Multi-Scale Subgraph Contrastive Learning](https://arxiv.org/abs/2403.02719) | 提出了一种多尺度子图对比学习方法，能够表征细粒度语义信息，解决了在图增强后原有假设不再成立的问题 |
| [^13] | [GEM3D: GEnerative Medial Abstractions for 3D Shape Synthesis](https://arxiv.org/abs/2402.16994) | GEM3D提出了一种新的深度、拓扑感知的三维形状生成模型，通过神经骨架编码了拓扑和几何信息，通过骨架驱动的神经隐式公式生成准确和多样化的表面。 |
| [^14] | [Me LLaMA: Foundation Large Language Models for Medical Applications](https://arxiv.org/abs/2402.12749) | Me LLaMA是一个医学领域的大型语言模型系列，通过持续预训练和指导调整在大型医学数据集上训练而成，其在零-shot和少-shot学习方面表现优于现有的医学语言模型和商业巨头ChatGPT。 |
| [^15] | [Optimal Task Assignment and Path Planning using Conflict-Based Search with Precedence and Temporal Constraints](https://arxiv.org/abs/2402.08772) | 本文研究了任务分配和路径规划问题，并提出了一种使用基于冲突的搜索方法解决具有先决和时间约束的任务分配和路径规划问题，最大化用户定义的指标的回报。 |
| [^16] | [LLaGA: Large Language and Graph Assistant](https://arxiv.org/abs/2402.08170) | LLaGA是一个创新的模型，它有效地整合了大型语言模型（LLM）的能力，以处理图结构数据的复杂性。通过重新组织图节点以作为结构感知的序列，并通过一个多功能投影仪将其映射到标记嵌入空间中，LLaGA在多样性、泛化性和可解释性方面表现出色。 |
| [^17] | [Driving Everywhere with Large Language Model Policy Adaptation](https://arxiv.org/abs/2402.05932) | 本文介绍了LLaDA，一种使用大型语言模型的工具，使得驾驶员和自动驾驶车辆能够在各地驾驶，通过将任务和运动计划调整到新位置的交通规则。通过广泛的用户研究，证明了LLaDA指导在解决意外情况和适应AV运动计划策略方面的有效性。 |
| [^18] | [On the $O(\frac{\sqrt{d}}{T^{1/4}})$ Convergence Rate of RMSProp and Its Momentum Extension Measured by $\ell_1$ Norm: Better Dependence on the Dimension](https://arxiv.org/abs/2402.00389) | 这项研究探讨了RMSProp及其动量扩展方法的收敛速度，并发现使用$\ell_1$范数测度时，收敛速度为$O(\frac{\sqrt{d}}{T^{1/4}})$，在维度极大的问题中具有改进依赖性。 |
| [^19] | [Generating High-Precision Force Fields for Molecular Dynamics Simulations to Study Chemical Reaction Mechanisms using Molecular Configuration Transformer](https://arxiv.org/abs/2401.00499) | 使用分子配置转换器生成高精度力场，以解决计算速度限制，从而在分子动力学模拟中研究化学反应机理。 |
| [^20] | [Supervised Fine-tuning in turn Improves Visual Foundation Models.](http://arxiv.org/abs/2401.10222) | 本文提出了一个叫做ViSFT（Vision SFT）的两阶段方法，通过在领域内任务上进行视觉联合学习来提升视觉基础模型的生成能力，在各种领域外基准测试中取得了改进。 |
| [^21] | [EgoGen: An Egocentric Synthetic Data Generator.](http://arxiv.org/abs/2401.08739) | EgoGen是一种新的合成数据生成器，它可以为具体化自我的感知任务生成准确和丰富的地面真实训练数据，并利用自我视觉输入来感知3D环境。 |
| [^22] | [Deep Automated Mechanism Design for Integrating Ad Auction and Allocation in Feed.](http://arxiv.org/abs/2401.01656) | 本论文提出了一种深度自动化的机制设计，用于在Feed中集成广告拍卖和分配。这种设计解决了广告拍卖不考虑外部性和广告分配无法保持激励兼容性的问题。 |
| [^23] | [A Quantitative Autonomy Quantification Framework for Fully Autonomous Robotic Systems.](http://arxiv.org/abs/2311.01939) | 本文提出了一个基于任务需求的自主度评估框架，主要关注完全自主模式，通过确定机器人任务特性，推导出自主度的三个度量标准，并将自主度分为自主度水平和自主度程度两部分。 |
| [^24] | [A Systematic Comparison of Syllogistic Reasoning in Humans and Language Models.](http://arxiv.org/abs/2311.00445) | 这项研究通过对比人类和语言模型在三段论推理中的表现，发现较大的语言模型更合逻辑，甚至比人类更合逻辑，但即使最大的语言模型也会出现与人类推理类似的错误，总体上认为语言模型在某些情况下能够克服人类偏见。 |
| [^25] | [SE(3)-Stochastic Flow Matching for Protein Backbone Generation.](http://arxiv.org/abs/2310.02391) | 通过SE(3)-Stochastic Flow Matching，我们提出了一系列新型生成模型FoldFlow，可以准确建模蛋白质主链。这些模型通过无需模拟训练和Riemannian最优传输的结合，具有更好的稳定性和建模能力。 |
| [^26] | [ChatGPT and Simple Linguistic Inferences: Blind Spots and Blinds.](http://arxiv.org/abs/2305.14785) | 本文研究了ChatGPT语言模型的局限性，指出其在简单语言推断任务中存在困难，并探讨了如何改善其对基本语言概念的理解。 |
| [^27] | [Deep Temporal Graph Clustering.](http://arxiv.org/abs/2305.10738) | 提出通用框架TGC 用于 deep temporal graph clustering, 解决了时间图只能作为静态图处理的难题，实现了对动态信息的聚类。实验证明了 TGC 的优越性。 |
| [^28] | [Impact of Position Bias on Language Models in Token Classification.](http://arxiv.org/abs/2304.13567) | 研究了语言模型在token分类任务中的位置偏差问题，通过实验表明在具体任务中，BERT、ERNIE、ELECTRA等编码器以及GPT2和BLOOM等解码器的平均性能下降了3%和9%。 |
| [^29] | [On the Computation of Meaning, Language Models and Incomprehensible Horrors.](http://arxiv.org/abs/2304.12686) | 本文提出了一个全面的机械化解释，涉及意义、交流和符号出现的现象，揭示了当前的语言模型并不具备与人类相同的意义理解，作者建议模拟人类情感并优化模型以构建弱表示形式来解决这个问题。 |
| [^30] | [Emergent Causality & the Foundation of Consciousness.](http://arxiv.org/abs/2302.03189) | 讨论了不需要显式实现干预表示的 Pareto 最优数学形式，通过归纳性地出现相关因果干预的表示，作为自我和任何其他对象的表示。 |
| [^31] | [The Optimal Choice of Hypothesis Is the Weakest, Not the Shortest.](http://arxiv.org/abs/2301.12987) | 本研究表明，在构建假设的过程中，选择最短的假设不如选择最弱的假设，而弱点是比长度或简单性更好的推广表现代理。 |

# 详细

[^1]: 用于旅行购买者问题的深度强化学习

    Deep Reinforcement Learning for Traveling Purchaser Problems

    [https://arxiv.org/abs/2404.02476](https://arxiv.org/abs/2404.02476)

    提出了一种基于深度强化学习的方法，该方法分别解决了旅行购买者问题中的路由构建和购买规划问题，并从全局角度评估和优化解决方案。

    

    旅行购买者问题（TPP）是一种具有广泛应用的重要组合优化问题。本文提出了一种基于深度强化学习（DRL）的新方法，该方法分别解决了路由构建和购买规划问题，同时从全局角度评估和优化解决方案。我们的方法的关键组成部分包括用于捕捉市场-产品关系的TPP的二部图表示，以及从二部图中提取信息并将其用于顺序构建路由的策略网络。

    arXiv:2404.02476v1 Announce Type: cross  Abstract: The traveling purchaser problem (TPP) is an important combinatorial optimization problem with broad applications. Due to the coupling between routing and purchasing, existing works on TPPs commonly address route construction and purchase planning simultaneously, which, however, leads to exact methods with high computational cost and heuristics with sophisticated design but limited performance. In sharp contrast, we propose a novel approach based on deep reinforcement learning (DRL), which addresses route construction and purchase planning separately, while evaluating and optimizing the solution from a global perspective. The key components of our approach include a bipartite graph representation for TPPs to capture the market-product relations, and a policy network that extracts information from the bipartite graph and uses it to sequentially construct the route. One significant benefit of our framework is that we can efficiently const
    
[^2]: 通过免Hessian重新整合个体数据统计实现高效在线遗忘

    Efficient Online Unlearning via Hessian-Free Recollection of Individual Data Statistics

    [https://arxiv.org/abs/2404.01712](https://arxiv.org/abs/2404.01712)

    通过提出的Hessian-free在线遗忘方法，实现了近乎瞬时的在线遗忘，仅需要进行矢量加法操作。

    

    机器遗忘旨在通过使模型能够选择性地忘记特定数据来维护数据所有者的被遗忘权利。最近的方法表明，一种数据遗忘的方法是通过预先计算和存储携带二阶信息的统计数据，以改进计算和内存效率。然而，它们依赖于苛刻的假设，而且计算/存储受到模型参数维度的诅咒，这使得难以应用到大多数深度神经网络中。在本工作中，我们提出了一种免Hessian在线遗忘方法。我们建议为每个数据点维护一个统计向量，通过重新训练和学习模型之间的差异的仿射随机递归逼近来计算。我们提出的算法实现了近乎瞬时的在线遗忘，因为它只需要进行矢量加法操作。基于重新收集遗忘数据统计的策略，

    arXiv:2404.01712v1 Announce Type: cross  Abstract: Machine unlearning strives to uphold the data owners' right to be forgotten by enabling models to selectively forget specific data. Recent methods suggest that one approach of data forgetting is by precomputing and storing statistics carrying second-order information to improve computational and memory efficiency. However, they rely on restrictive assumptions and the computation/storage suffer from the curse of model parameter dimensionality, making it challenging to apply to most deep neural networks. In this work, we propose a Hessian-free online unlearning method. We propose to maintain a statistical vector for each data point, computed through affine stochastic recursion approximation of the difference between retrained and learned models. Our proposed algorithm achieves near-instantaneous online unlearning as it only requires a vector addition operation. Based on the strategy that recollecting statistics for forgetting data, the p
    
[^3]: 使用多实例学习在整张切片图像中找到感兴趣区域

    Finding Regions of Interest in Whole Slide Images Using Multiple Instance Learning

    [https://arxiv.org/abs/2404.01446](https://arxiv.org/abs/2404.01446)

    本研究使用多实例学习方法来解决整张切片图像中准确预测癌症表型和在图块级别找到与之相关的细胞形态学的挑战。

    

    Whole Slide Images (WSI)是通过高分辨率数字扫描显微镜切片在多个尺度下获得的，是现代数字病理学的基石。然而，它们对基于人工智能的/人工智能中介分析提出特殊挑战，因为病理标注通常是在切片级别而不是图块级别进行的。本文探讨了一种弱监督的多实例学习（MIL）方法，用于两种常见癌症类型，侵袭性乳腺癌（TCGA-BRCA）和肺鳞状细胞癌（TCGA-LUSC）。

    arXiv:2404.01446v1 Announce Type: cross  Abstract: Whole Slide Images (WSI), obtained by high-resolution digital scanning of microscope slides at multiple scales, are the cornerstone of modern Digital Pathology. However, they represent a particular challenge to AI-based/AI-mediated analysis because pathology labeling is typically done at slide-level, instead of tile-level. It is not just that medical diagnostics is recorded at the specimen level, the detection of oncogene mutation is also experimentally obtained, and recorded by initiatives like The Cancer Genome Atlas (TCGA), at the slide level. This configures a dual challenge: a) accurately predicting the overall cancer phenotype and b) finding out what cellular morphologies are associated with it at the tile level. To address these challenges, a weakly supervised Multiple Instance Learning (MIL) approach was explored for two prevalent cancer types, Invasive Breast Carcinoma (TCGA-BRCA) and Lung Squamous Cell Carcinoma (TCGA-LUSC). 
    
[^4]: 源感知训练使语言模型具备知识归因能力

    Source-Aware Training Enables Knowledge Attribution in Language Models

    [https://arxiv.org/abs/2404.01019](https://arxiv.org/abs/2404.01019)

    源感知训练使语言模型具备知识归因能力，进而增强了其透明度、可解释性和可验证性。

    

    大型语言模型（LLMs）在预训练期间学到了大量知识，但往往对此类知识的来源毫不在意。本文研究了内在源引用问题，要求LLMs引用支持生成响应的预训练来源。内在源引用可以增强LLMs的透明度、可解释性和可验证性。为赋予LLMs这种能力，我们探索了源感知训练——一个后预训练配方，包括（i）训练LLMs将唯一源文档标识符与每个文档中的知识关联起来，然后（ii）进行指示调整，教导LLMs在被提示时引用支持的预训练来源。源感知训练可以轻松应用于即插即用的预训练LLMs，并与现有的预训练/微调框架的差异最小。通过对精心策划的数据进行实验，我们展示了我们的训练配方可以实现

    arXiv:2404.01019v1 Announce Type: cross  Abstract: Large language models (LLMs) learn a vast amount of knowledge during pretraining, but they are often oblivious to the source(s) of such knowledge. We investigate the problem of intrinsic source citation, where LLMs are required to cite the pretraining source supporting a generated response. Intrinsic source citation can enhance LLM transparency, interpretability, and verifiability. To give LLMs such ability, we explore source-aware training -- a post pretraining recipe that involves (i) training the LLM to associate unique source document identifiers with the knowledge in each document, followed by (ii) an instruction-tuning to teach the LLM to cite a supporting pretraining source when prompted. Source-aware training can easily be applied to pretrained LLMs off the shelf, and diverges minimally from existing pretraining/fine-tuning frameworks. Through experiments on carefully curated data, we demonstrate that our training recipe can en
    
[^5]: 通过视觉语言模型对神经网络进行基于概念的分析

    Concept-based Analysis of Neural Networks via Vision-Language Models

    [https://arxiv.org/abs/2403.19837](https://arxiv.org/abs/2403.19837)

    本文提出利用视觉语言模型作为透镜，通过其隐含的高层次概念来进行对视觉模型的分析。

    

    视觉深度神经网络（DNNs）的形式化分析非常可取，但由于难以表达视觉任务的形式化规范以及缺乏高效的验证程序，这是非常具有挑战性的。在本文中，我们提出利用新兴的多模态、视觉语言、基础模型（VLMs）作为一种通过其可以推理视觉模型的透镜。VLMs已经在大量图像及其文本描述上进行了训练，因此隐式地了解描述这些图像的高层次、人类可理解的概念。我们描述了一种名为$\texttt{Con}_{\texttt{spec}}$的逻辑规范语言，旨在便于按照这些概念编写规范。为了定义和形式化检查$\texttt{Con}_{\texttt{spec}}$规范，我们利用了一个VLM，它提供了一种编码和高效检查视觉模型的自然语言属性的方法。我们展示了我们的te

    arXiv:2403.19837v1 Announce Type: cross  Abstract: Formal analysis of vision-based deep neural networks (DNNs) is highly desirable but it is very challenging due to the difficulty of expressing formal specifications for vision tasks and the lack of efficient verification procedures. In this paper, we propose to leverage emerging multimodal, vision-language, foundation models (VLMs) as a lens through which we can reason about vision models. VLMs have been trained on a large body of images accompanied by their textual description, and are thus implicitly aware of high-level, human-understandable concepts describing the images. We describe a logical specification language $\texttt{Con}_{\texttt{spec}}$ designed to facilitate writing specifications in terms of these concepts. To define and formally check $\texttt{Con}_{\texttt{spec}}$ specifications, we leverage a VLM, which provides a means to encode and efficiently check natural-language properties of vision models. We demonstrate our te
    
[^6]: KTbench：一种全新的无数据泄漏的知识追踪框架

    KTbench: A Novel Data Leakage-Free Framework for Knowledge Tracing

    [https://arxiv.org/abs/2403.15304](https://arxiv.org/abs/2403.15304)

    KTbench提出了一种无数据泄漏的知识追踪框架，解决了KT模型中KC之间的相关性学习可能导致的性能下降问题。

    

    知识追踪（KT）涉及在智能辅导系统中预测学生对学习项目的未来表现。学习项目被标记为称为知识概念（KCs）的技能标签。许多KT模型通过用构成KC的学习项目取代学习项目来将学习项目-学生交互序列扩展为KC-学生交互序列，从而解决了稀疏的学习项目-学生交互问题并最小化了模型参数。然而，这种方法存在两个问题。第一个问题是模型学习同一项目内的KC之间的相关性的能力，这可能导致基本事实标签的泄漏并阻碍模型性能。第二个问题是现有的基准实现忽略了计数问题

    arXiv:2403.15304v1 Announce Type: cross  Abstract: Knowledge Tracing (KT) is concerned with predicting students' future performance on learning items in intelligent tutoring systems. Learning items are tagged with skill labels called knowledge concepts (KCs). Many KT models expand the sequence of item-student interactions into KC-student interactions by replacing learning items with their constituting KCs. This often results in a longer sequence length. This approach addresses the issue of sparse item-student interactions and minimises model parameters. However, two problems have been identified with such models.   The first problem is the model's ability to learn correlations between KCs belonging to the same item, which can result in the leakage of ground truth labels and hinder performance. This problem can lead to a significant decrease in performance on datasets with a higher number of KCs per item. The second problem is that the available benchmark implementations ignore accounti
    
[^7]: 具有非私密预处理的可证明隐私

    Provable Privacy with Non-Private Pre-Processing

    [https://arxiv.org/abs/2403.13041](https://arxiv.org/abs/2403.13041)

    提出了一个框架，能够评估非私密数据相关预处理算法引起的额外隐私成本，并利用平滑DP和预处理算法的有界敏感性建立整体隐私保证的上限

    

    当分析差分私密（DP）机器学习管道时，通常会忽略数据相关的预处理的潜在隐私成本。在这项工作中，我们提出了一个通用框架，用于评估由非私密数据相关预处理算法引起的额外隐私成本。我们的框架通过利用两个新的技术概念建立了整体隐私保证的上限：一种称为平滑DP的DP变体以及预处理算法的有界敏感性。

    arXiv:2403.13041v1 Announce Type: cross  Abstract: When analysing Differentially Private (DP) machine learning pipelines, the potential privacy cost of data-dependent pre-processing is frequently overlooked in privacy accounting. In this work, we propose a general framework to evaluate the additional privacy cost incurred by non-private data-dependent pre-processing algorithms. Our framework establishes upper bounds on the overall privacy guarantees by utilising two new technical notions: a variant of DP termed Smooth DP and the bounded sensitivity of the pre-processing algorithms. In addition to the generic framework, we provide explicit overall privacy guarantees for multiple data-dependent pre-processing algorithms, such as data imputation, quantization, deduplication and PCA, when used in combination with several DP algorithms. Notably, this framework is also simple to implement, allowing direct integration into existing DP pipelines.
    
[^8]: 使用StateFlow增强LLM任务解决能力通过状态驱动工作流

    StateFlow: Enhancing LLM Task-Solving through State-Driven Workflows

    [https://arxiv.org/abs/2403.11322](https://arxiv.org/abs/2403.11322)

    提出了一种使用StateFlow的新颖LLM任务解决范式，将复杂任务解决过程概念化为状态机，通过状态转换确保LLM响应的清晰跟踪和管理。

    

    使用大型语言模型（LLM）来解决复杂任务的趋势日益明显，例如需要一系列操作和与工具环境动态交互的任务。本文提出了StateFlow，一种新颖的基于LLM的任务求解范式，将由LLM支持的复杂任务解决过程概念化为状态机。通过正确构建状态和定义状态转换，StateFlow确定了任务求解的进展，确保清晰跟踪和管理LLM在整个任务求解过程中的响应。在每个状态中，StateFlow允许执行一系列动作，不仅包括根据特定提示指导生成LLM响应，还包括根据需要利用外部工具。状态转换由LLM做出的特定规则或决策控制，允许通过任务的预定义StateFlow模型动态自适应地进行进展。

    arXiv:2403.11322v1 Announce Type: cross  Abstract: It is a notable trend to use Large Language Models (LLMs) to tackle complex tasks, e.g., tasks that require a sequence of actions and dynamic interaction with tools and environments. In this paper, we propose StateFlow, a novel LLM-based task-solving paradigm that conceptualizes complex task-solving processes backed by LLMs as state machines. With proper construction of states and definition of state transitions, StateFlow grounds the progress of task-solving, ensuring clear tracking and management of LLMs' responses throughout the task-solving process. Within each state, StateFlow allows execution of a series of actions, involving not only the generation of LLM's responses guided by a specific prompt, but also the utilization of external tools as needed. State transitions are controlled by specific rules or decisions made by the LLM, allowing for a dynamic and adaptive progression through the task's pre-defined StateFlow model. Evalua
    
[^9]: Gemma：基于Gemini研究和技术的开放模型

    Gemma: Open Models Based on Gemini Research and Technology

    [https://arxiv.org/abs/2403.08295](https://arxiv.org/abs/2403.08295)

    Gemma是基于Gemini研究和技术所构建的开放模型系列，在语言理解、推理和安全性等方面表现出色，负责任地发布这些大型语言模型对于提高前沿模型的安全性至关重要。

    

    本文介绍了Gemma，这是一个基于Gemini模型研究和技术构建的轻量级、最先进的开放模型系列。Gemma模型在语言理解、推理和安全性等学术基准上表现出色。我们发布了两个规模的模型（20亿和70亿参数），并提供了预训练和微调的检查点。Gemma在18个基于文本的任务中，有11个任务优于类似规模的开放模型，并对模型的安全性和责任方面进行了全面评估，同时详细描述了模型开发过程。我们相信负责任地发布大型语言模型对于提高前沿模型的安全性，并实现下一波大型语言模型创新至关重要。

    arXiv:2403.08295v1 Announce Type: cross  Abstract: This work introduces Gemma, a family of lightweight, state-of-the art open models built from the research and technology used to create Gemini models. Gemma models demonstrate strong performance across academic benchmarks for language understanding, reasoning, and safety. We release two sizes of models (2 billion and 7 billion parameters), and provide both pretrained and fine-tuned checkpoints. Gemma outperforms similarly sized open models on 11 out of 18 text-based tasks, and we present comprehensive evaluations of safety and responsibility aspects of the models, alongside a detailed description of model development. We believe the responsible release of LLMs is critical for improving the safety of frontier models, and for enabling the next wave of LLM innovations.
    
[^10]: AI身份的意义：创造者、创作物和后果的含义

    Implications of Identity of AI: Creators, Creations, and Consequences

    [https://arxiv.org/abs/2403.07924](https://arxiv.org/abs/2403.07924)

    该论文探讨了人工智能领域的身份问题，强调了通过身份视角促进AI多样性在创造者、创作物和后果方面的重要性。

    

    人工智能（AI）领域正在快速发展，具有显著潜力改变社会。然而，它面临着一个明显的挑战：缺乏多样性，这是STEM领域长期存在的问题。本立场论文探讨了人工智能和身份的交叉点，作为理解AI发展和应用中的偏见、不平等和道德考虑的途径。我们提出了一个多维度的AI身份定义，涵盖其创造者、应用以及它们的更广泛影响。理解AI的身份涉及分析参与AI发展的各种个体、所产生的技术以及社会、道德和心理影响。在探讨AI身份生态系统及其社会动态后，我们提出了一个框架，强调了通过身份视角跨三个维度——创造者、创作物和后果，在AI中需要多样性的必要性。

    arXiv:2403.07924v1 Announce Type: cross  Abstract: The field of Artificial Intelligence (AI) is rapidly advancing, with significant potential to transform society. However, it faces a notable challenge: lack of diversity, a longstanding issue in STEM fields. In this context, This position paper examines the intersection of AI and identity as a pathway to understand biases, inequalities, and ethical considerations in AI development and deployment. We present a multifaceted definition of AI identity, which encompasses its creators, applications, and their broader impacts. Understanding AI's identity involves analyzing the diverse individuals involved in AI's development, the technologies produced, and the social, ethical, and psychological implications. After exploring the AI identity ecosystem and its societal dynamics, We propose a framework that highlights the need for diversity in AI across three dimensions: Creators, Creations, and Consequences through the lens of identity. This pap
    
[^11]: 在句法感知代码填空任务上评估LLMs

    Evaluation of LLMs on Syntax-Aware Code Fill-in-the-Middle Tasks

    [https://arxiv.org/abs/2403.04814](https://arxiv.org/abs/2403.04814)

    该研究引入了一个新的基准SAFIM用于评估LLMs在代码填空任务上的句法感知完成表现，发现FIM预训练不仅提高了FIM的熟练度，还改善了LLMs的左到右推理，挑战了传统观念并表明预训练方法和数据品质对模型性能的影响更甚于模型大小。

    

    我们介绍了一种名为Syntax-Aware Fill-In-the-Middle（SAFIM）的新基准，用于评估大型语言模型（LLMs）在代码填空（FIM）任务上的表现。该基准侧重于程序结构的句法感知完成，如代码块和条件表达式，并包括来自多种编程语言的17,720个示例，来源于2022年4月之后的最新代码提交，以最小化数据污染。 SAFIM提供了一个强大的框架，具有各种提示设计和新颖的句法感知后处理技术，有助于在LLMs之间进行准确和公平的比较。我们对15个LLMs进行了全面评估，结果表明FIM预训练不仅提升了FIM的熟练程度，还改进了LLMs的左到右（L2R）推理。我们的发现挑战了传统观念，并表明预训练方法和数据质量对模型性能的影响大于模型大小。因此，SAFIM为未来构建

    arXiv:2403.04814v1 Announce Type: cross  Abstract: We introduce Syntax-Aware Fill-In-the-Middle (SAFIM), a new benchmark for evaluating Large Language Models (LLMs) on the code Fill-in-the-Middle (FIM) task. This benchmark focuses on syntax-aware completions of program structures such as code blocks and conditional expressions, and includes 17,720 examples from multiple programming languages, sourced from recent code submissions after April 2022 to minimize data contamination. SAFIM provides a robust framework with various prompt designs and novel syntax-aware post-processing techniques, facilitating accurate and fair comparisons across LLMs. Our comprehensive evaluation of 15 LLMs shows that FIM pretraining not only enhances FIM proficiency but also improves Left-to-Right (L2R) inference using LLMs. Our findings challenge conventional beliefs and suggest that pretraining methods and data quality have more impact than model size. SAFIM thus serves as a foundational platform for future 
    
[^12]: 多尺度子图对比学习

    Multi-Scale Subgraph Contrastive Learning

    [https://arxiv.org/abs/2403.02719](https://arxiv.org/abs/2403.02719)

    提出了一种多尺度子图对比学习方法，能够表征细粒度语义信息，解决了在图增强后原有假设不再成立的问题

    

    图级对比学习旨在通过对比两个增强图来学习每个图的表示，受到了广泛关注。先前的研究通常简单地假设一个图及其增强图为正对，否则为负对。然而，众所周知，图结构通常复杂且多尺度，这带来了一个根本问题：在图增强后，先前的假设是否仍然成立？通过实验分析，我们发现增强图结构的语义信息可能不一致于原始图结构，并且两个增强图是正对还是负对与多尺度结构密切相关。基于这一发现，我们提出了一种能够表征细粒度语义信息的多尺度子图对比学习方法。具体地，我们生成全局和局部

    arXiv:2403.02719v1 Announce Type: new  Abstract: Graph-level contrastive learning, aiming to learn the representations for each graph by contrasting two augmented graphs, has attracted considerable attention. Previous studies usually simply assume that a graph and its augmented graph as a positive pair, otherwise as a negative pair. However, it is well known that graph structure is always complex and multi-scale, which gives rise to a fundamental question: after graph augmentation, will the previous assumption still hold in reality? By an experimental analysis, we discover the semantic information of an augmented graph structure may be not consistent as original graph structure, and whether two augmented graphs are positive or negative pairs is highly related with the multi-scale structures. Based on this finding, we propose a multi-scale subgraph contrastive learning method which is able to characterize the fine-grained semantic information. Specifically, we generate global and local 
    
[^13]: GEM3D：三维形状合成的生成媒体抽象

    GEM3D: GEnerative Medial Abstractions for 3D Shape Synthesis

    [https://arxiv.org/abs/2402.16994](https://arxiv.org/abs/2402.16994)

    GEM3D提出了一种新的深度、拓扑感知的三维形状生成模型，通过神经骨架编码了拓扑和几何信息，通过骨架驱动的神经隐式公式生成准确和多样化的表面。

    

    我们介绍了GEM3D——一种新的深度、拓扑感知的三维形状生成模型。我们方法的关键部分是基于神经骨架的表示，编码了关于形状拓扑和几何的信息。通过一个去噪扩散概率模型，我们的方法首先生成遵循中轴变换（MAT）的基于骨架的表示，然后通过一个骨架驱动的神经隐式公式生成表面。神经隐式考虑了在生成的骨架表示中存储的拓扑和几何信息，产生的表面与之前的神经场公式相比更加拓扑和几何准确。我们讨论了我们的方法在形状合成和点云重建任务中的应用，并对我们的方法进行了定性和定量评估。我们展示了比以前更为准确和多样化的形状重建。

    arXiv:2402.16994v1 Announce Type: cross  Abstract: We introduce GEM3D -- a new deep, topology-aware generative model of 3D shapes. The key ingredient of our method is a neural skeleton-based representation encoding information on both shape topology and geometry. Through a denoising diffusion probabilistic model, our method first generates skeleton-based representations following the Medial Axis Transform (MAT), then generates surfaces through a skeleton-driven neural implicit formulation. The neural implicit takes into account the topological and geometric information stored in the generated skeleton representations to yield surfaces that are more topologically and geometrically accurate compared to previous neural field formulations. We discuss applications of our method in shape synthesis and point cloud reconstruction tasks, and evaluate our method both qualitatively and quantitatively. We demonstrate significantly more faithful surface reconstruction and diverse shape generation r
    
[^14]: Me LLaMA: 为医疗应用构建大型语言模型的基础

    Me LLaMA: Foundation Large Language Models for Medical Applications

    [https://arxiv.org/abs/2402.12749](https://arxiv.org/abs/2402.12749)

    Me LLaMA是一个医学领域的大型语言模型系列，通过持续预训练和指导调整在大型医学数据集上训练而成，其在零-shot和少-shot学习方面表现优于现有的医学语言模型和商业巨头ChatGPT。

    

    最近，诸如ChatGPT和LLaMA等大型语言模型(LLMs)在许多人工智能应用中展现出巨大的潜力。然而，它们在医学任务上的表现不够理想，并且可以通过在大型领域特定数据集上进行训练来进一步改进。本研究引入了Me LLaMA，一个医学LLM系列，包括基础模型- Me LLaMA 13/70B及其 chat-enhanced 版本- Me LLaMA 13/70B-chat，通过持续对LLaMA2进行预训练和指导调整，使用大规模医学数据开发而成。我们用于训练和评估的领域特定数据套件包括一个具有129B tokens的大规模持续预训练数据集，一个包含214k个样本的指导调整数据集，以及跨越14个数据集的六项任务的医学评估基准(MIBE)。我们使用MIBE进行的广泛评估显示，Me LLaMA模型在零-shot和少-shot学习方面超越了现有的开源医学LLMs，并且在商业巨头如ChatGPT上表现出色。

    arXiv:2402.12749v1 Announce Type: cross  Abstract: Recent large language models (LLMs) like ChatGPT and LLaMA have shown great promise in many AI applications. However, their performance on medical tasks is suboptimal and can be further improved by training on large domain-specific datasets. This study introduces Me LLaMA, a medical LLM family including foundation models - Me LLaMA 13/70B and their chat-enhanced versions - Me LLaMA 13/70B-chat, developed through the continual pre-training and instruction tuning of LLaMA2 using large medical data. Our domain-specific data suite for training and evaluation, includes a large-scale continual pre-training dataset with 129B tokens, an instruction tuning dataset with 214k samples, and a medical evaluation benchmark (MIBE) across six tasks with 14 datasets. Our extensive evaluation using MIBE shows that Me LLaMA models surpass existing open-source medical LLMs in zero-shot and few-shot learning and outperform commercial giants like ChatGPT on 
    
[^15]: 使用基于冲突的搜索和先决和时间约束的最优任务分配和路径规划

    Optimal Task Assignment and Path Planning using Conflict-Based Search with Precedence and Temporal Constraints

    [https://arxiv.org/abs/2402.08772](https://arxiv.org/abs/2402.08772)

    本文研究了任务分配和路径规划问题，并提出了一种使用基于冲突的搜索方法解决具有先决和时间约束的任务分配和路径规划问题，最大化用户定义的指标的回报。

    

    多智能体路径规划（MAPF）问题涉及为一组智能体找到无碰撞路径，引导它们从起点到目标位置。然而，MAPF没有考虑几个实际的任务相关约束。例如，智能体可能需要在目标位置执行具有特定执行时间的动作，遵循预定的顺序和时间框架。此外，目标分配可能不是预先定义的，优化目标可能缺乏明确定义。为了将任务分配、路径规划和用户定义的目标结合成一个连贯的框架，本文研究了具有先决和时间约束的任务分配和路径规划（TAPF-PTC）问题。我们增加了基于冲突的搜索（CBS）以同时生成遵守先决和时间约束的任务分配和无碰撞路径，并最大化基于用户定义的指标的回报。

    arXiv:2402.08772v1 Announce Type: new Abstract: The Multi-Agent Path Finding (MAPF) problem entails finding collision-free paths for a set of agents, guiding them from their start to goal locations. However, MAPF does not account for several practical task-related constraints. For example, agents may need to perform actions at goal locations with specific execution times, adhering to predetermined orders and timeframes. Moreover, goal assignments may not be predefined for agents, and the optimization objective may lack an explicit definition. To incorporate task assignment, path planning, and a user-defined objective into a coherent framework, this paper examines the Task Assignment and Path Finding with Precedence and Temporal Constraints (TAPF-PTC) problem. We augment Conflict-Based Search (CBS) to simultaneously generate task assignments and collision-free paths that adhere to precedence and temporal constraints, maximizing an objective quantified by the return from a user-defined r
    
[^16]: LLaGA: 大型语言和图形助手

    LLaGA: Large Language and Graph Assistant

    [https://arxiv.org/abs/2402.08170](https://arxiv.org/abs/2402.08170)

    LLaGA是一个创新的模型，它有效地整合了大型语言模型（LLM）的能力，以处理图结构数据的复杂性。通过重新组织图节点以作为结构感知的序列，并通过一个多功能投影仪将其映射到标记嵌入空间中，LLaGA在多样性、泛化性和可解释性方面表现出色。

    

    图神经网络（GNN）已经推动了图结构数据分析的进步。最近，大型语言模型（LLM）如GPT-4的崛起预示着深度学习的一个新时代。然而，将它们应用于图数据还面临着独特的挑战，由于将图结构转化为文本的固有难度。为此，我们引入了一个创新模型——大型语言和图形助手（LLaGA），它有效地整合了LLM的能力，以处理图结构数据的复杂性。LLaGA保留了LLM的通用性，同时将图数据转化为与LLM输入兼容的格式。LLaGA通过重新组织图节点以作为结构感知的序列，然后通过一个多功能投影仪将其映射到标记嵌入空间中。LLaGA在多样性、泛化性和可解释性方面表现出色，使其能够在不同数据集和任务上表现出一致的良好性能。

    Graph Neural Networks (GNNs) have empowered the advance in graph-structured data analysis. Recently, the rise of Large Language Models (LLMs) like GPT-4 has heralded a new era in deep learning. However, their application to graph data poses distinct challenges due to the inherent difficulty of translating graph structures to language. To this end, we introduce the \textbf{L}arge \textbf{L}anguage \textbf{a}nd \textbf{G}raph \textbf{A}ssistant (\textbf{LLaGA}), an innovative model that effectively integrates LLM capabilities to handle the complexities of graph-structured data. LLaGA retains the general-purpose nature of LLMs while adapting graph data into a format compatible with LLM input. LLaGA achieves this by reorganizing graph nodes to structure-aware sequences and then mapping these into the token embedding space through a versatile projector. LLaGA excels in versatility, generalizability and interpretability, allowing it to perform consistently well across different datasets and 
    
[^17]: 通过大型语言模型政策适应在各处驾驶

    Driving Everywhere with Large Language Model Policy Adaptation

    [https://arxiv.org/abs/2402.05932](https://arxiv.org/abs/2402.05932)

    本文介绍了LLaDA，一种使用大型语言模型的工具，使得驾驶员和自动驾驶车辆能够在各地驾驶，通过将任务和运动计划调整到新位置的交通规则。通过广泛的用户研究，证明了LLaDA指导在解决意外情况和适应AV运动计划策略方面的有效性。

    

    自动驾驶中，将驾驶行为适应新环境、习俗和法律是一个长期存在的问题，这限制了自动驾驶车辆(AVs)的广泛部署。本文介绍了LLaDA，一种简单而强大的工具，可以使人类驾驶员和自动驾驶车辆都能在各处行驶，通过将任务和运动计划调整到新位置的交通规则。LLaDA利用大型语言模型(LLMs)在解释本地驾驶手册中的交通规则时具有令人印象深刻的零-shot泛化能力。通过广泛的用户研究，我们展示了LLaDA的指导在解决现实世界中的意外情况时的有用性。我们还展示了LLaDA在真实世界数据集中调整AV运动计划策略的能力；LLaDA在所有指标上优于基线规划方法。请访问我们的网站了解更多详细信息：https://boyiliee.github.io/llada.

    Adapting driving behavior to new environments, customs, and laws is a long-standing problem in autonomous driving, precluding the widespread deployment of autonomous vehicles (AVs). In this paper, we present LLaDA, a simple yet powerful tool that enables human drivers and autonomous vehicles alike to drive everywhere by adapting their tasks and motion plans to traffic rules in new locations. LLaDA achieves this by leveraging the impressive zero-shot generalizability of large language models (LLMs) in interpreting the traffic rules in the local driver handbook. Through an extensive user study, we show that LLaDA's instructions are useful in disambiguating in-the-wild unexpected situations. We also demonstrate LLaDA's ability to adapt AV motion planning policies in real-world datasets; LLaDA outperforms baseline planning approaches on all our metrics. Please check our website for more details: https://boyiliee.github.io/llada.
    
[^18]: 关于RMSProp及其动量扩展方法的$O(\frac{\sqrt{d}}{T^{1/4}})$收敛速度和对维度的改进依赖性

    On the $O(\frac{\sqrt{d}}{T^{1/4}})$ Convergence Rate of RMSProp and Its Momentum Extension Measured by $\ell_1$ Norm: Better Dependence on the Dimension

    [https://arxiv.org/abs/2402.00389](https://arxiv.org/abs/2402.00389)

    这项研究探讨了RMSProp及其动量扩展方法的收敛速度，并发现使用$\ell_1$范数测度时，收敛速度为$O(\frac{\sqrt{d}}{T^{1/4}})$，在维度极大的问题中具有改进依赖性。

    

    尽管自适应梯度方法在深度学习中被广泛使用，但其收敛速度尚未得到彻底研究，特别是对于其对维度的依赖性。本文考虑了经典的RMSProp及其动量扩展方法，并通过$\ell_1$范数建立了收敛率$\frac{1}{T}\sum_{k=1}^TE\left[\|\nabla f(x^k)\|_1\right]\leq O(\frac{\sqrt{d}}{T^{1/4}})$，无需假设梯度有界，其中$d$是优化变量的维度，$T$是迭代次数。由于对于维度极大的问题，$\|x\|_2\ll\|x\|_1\leq\sqrt{d}\|x\|_2$，因此我们的收敛速度可以类比为SGD的$\frac{1}{T}\sum_{k=1}^TE\left[\|\nabla f(x^k)\|_2\right]\leq O(\frac{1}{T^{1/4}})$，测度为$\ell_1$范数。

    Although adaptive gradient methods have been extensively used in deep learning, their convergence rates have not been thoroughly studied, particularly with respect to their dependence on the dimension. This paper considers the classical RMSProp and its momentum extension and establishes the convergence rate of $\frac{1}{T}\sum_{k=1}^TE\left[\|\nabla f(x^k)\|_1\right]\leq O(\frac{\sqrt{d}}{T^{1/4}})$ measured by $\ell_1$ norm without the bounded gradient assumption, where $d$ is the dimension of the optimization variable and $T$ is the iteration number. Since $\|x\|_2\ll\|x\|_1\leq\sqrt{d}\|x\|_2$ for problems with extremely large $d$, our convergence rate can be considered to be analogous to the $\frac{1}{T}\sum_{k=1}^TE\left[\|\nabla f(x^k)\|_2\right]\leq O(\frac{1}{T^{1/4}})$ one of SGD measured by $\ell_1$ norm.
    
[^19]: 使用分子配置转换器生成用于分子动力学模拟的高精度力场，研究化学反应机理

    Generating High-Precision Force Fields for Molecular Dynamics Simulations to Study Chemical Reaction Mechanisms using Molecular Configuration Transformer

    [https://arxiv.org/abs/2401.00499](https://arxiv.org/abs/2401.00499)

    使用分子配置转换器生成高精度力场，以解决计算速度限制，从而在分子动力学模拟中研究化学反应机理。

    

    在有机化学中，化学反应机理的理论研究至关重要。传统上，使用量子化学计算计算手动构建的过渡态分子构型是最常用的方法。然而，这种方法在很大程度上依赖于个人经验和化学直觉。在我们之前的研究中，我们提出了一种使用分子动力学模拟中的增强采样来研究化学反应的研究范式。这种方法可以直接模拟化学反应的整个过程。然而，计算速度限制了用于模拟的高精度势能函数的使用。为解决这个问题，我们提出了一种方案，使用先前开发的基于图神经网络的分子模型-分子配置转换器来训练高精度分子建模力场。

    arXiv:2401.00499v2 Announce Type: replace-cross  Abstract: Theoretical studies on chemical reaction mechanisms have been crucial in organic chemistry. Traditionally, calculating the manually constructed molecular conformations of transition states for chemical reactions using quantum chemical calculations is the most commonly used method. However, this way is heavily dependent on individual experience and chemical intuition. In our previous study, we proposed a research paradigm that uses enhanced sampling in molecular dynamics simulations to study chemical reactions. This approach can directly simulate the entire process of a chemical reaction. However, the computational speed limits the use of high-precision potential energy functions for simulations. To address this issue, we present a scheme for training high-precision force fields for molecular modeling using a previously developed graph-neural-network-based molecular model, molecular configuration transformer. This potential ener
    
[^20]: 监督微调进一步改进了视觉基础模型

    Supervised Fine-tuning in turn Improves Visual Foundation Models. (arXiv:2401.10222v1 [cs.CV])

    [http://arxiv.org/abs/2401.10222](http://arxiv.org/abs/2401.10222)

    本文提出了一个叫做ViSFT（Vision SFT）的两阶段方法，通过在领域内任务上进行视觉联合学习来提升视觉基础模型的生成能力，在各种领域外基准测试中取得了改进。

    

    近年来，像CLIP这样的图像-文本训练方法已经主导了视觉基础模型的预训练。随后，为了将区域级别的视觉学习引入CLIP的预训练中，在大规模区域级别数据集的缺乏下面临可扩展性挑战。受到自然语言处理中监督微调（SFT）的启发，比如指令微调，我们探索了在视觉基础模型的预训练之后，微粒SFT能够提升其生成能力的潜力。因此，我们提出了一个两阶段的方法ViSFT（Vision SFT），来释放视觉基础模型的细粒度知识。在ViSFT中，通过在一些领域内任务上进行视觉联合学习来增强视觉基础模型，然后在领域外基准测试中进行测试。通过使用ViSFT在少于2天内在8个V100 GPU上进行更新，一个具有超过4.4B参数的视觉Transformer在各种领域外基准测试中显示出改进。

    Image-text training like CLIP has dominated the pretraining of vision foundation models in recent years. Subsequent efforts have been made to introduce region-level visual learning into CLIP's pretraining but face scalability challenges due to the lack of large-scale region-level datasets. Drawing inspiration from supervised fine-tuning (SFT) in natural language processing such as instruction tuning, we explore the potential of fine-grained SFT in enhancing the generation of vision foundation models after their pretraining. Thus a two-stage method ViSFT (Vision SFT) is proposed to unleash the fine-grained knowledge of vision foundation models. In ViSFT, the vision foundation model is enhanced by performing visual joint learning on some in-domain tasks and then tested on out-of-domain benchmarks. With updating using ViSFT on 8 V100 GPUs in less than 2 days, a vision transformer with over 4.4B parameters shows improvements across various out-of-domain benchmarks including vision and visi
    
[^21]: EgoGen:一种自我的合成数据生成器

    EgoGen: An Egocentric Synthetic Data Generator. (arXiv:2401.08739v1 [cs.CV])

    [http://arxiv.org/abs/2401.08739](http://arxiv.org/abs/2401.08739)

    EgoGen是一种新的合成数据生成器，它可以为具体化自我的感知任务生成准确和丰富的地面真实训练数据，并利用自我视觉输入来感知3D环境。

    

    在增强现实（AR）中，以第一人称视角理解世界是基础性的。这种身临其境的视角相对于第三人称视角带来了戏剧性的视觉变化和独特的挑战。合成数据已经赋予了第三人称视角视觉模型的能力，但其应用于具体化自我的感知任务仍然很少被探索。一个重要的挑战在于模拟自然的人类运动和行为，以有效地操纵实体相机捕捉到3D世界的真实自我的表达。为了解决这个挑战，我们引入了一个新的合成数据生成器EgoGen，它可以为具体化自我的感知任务生成准确和丰富的地面真实训练数据。EgoGen的核心是一种新颖的人体运动合成模型，它直接利用虚拟人类的自我视觉输入感知3D环境。结合避免碰撞的运动基元和两阶段强化学习方法，我们的运动合成模型实现了高效的自我的合成。

    Understanding the world in first-person view is fundamental in Augmented Reality (AR). This immersive perspective brings dramatic visual changes and unique challenges compared to third-person views. Synthetic data has empowered third-person-view vision models, but its application to embodied egocentric perception tasks remains largely unexplored. A critical challenge lies in simulating natural human movements and behaviors that effectively steer the embodied cameras to capture a faithful egocentric representation of the 3D world. To address this challenge, we introduce EgoGen, a new synthetic data generator that can produce accurate and rich ground-truth training data for egocentric perception tasks. At the heart of EgoGen is a novel human motion synthesis model that directly leverages egocentric visual inputs of a virtual human to sense the 3D environment. Combined with collision-avoiding motion primitives and a two-stage reinforcement learning approach, our motion synthesis model off
    
[^22]: 在Feed中集成广告拍卖和分配的深度自动化机制设计

    Deep Automated Mechanism Design for Integrating Ad Auction and Allocation in Feed. (arXiv:2401.01656v1 [cs.GT])

    [http://arxiv.org/abs/2401.01656](http://arxiv.org/abs/2401.01656)

    本论文提出了一种深度自动化的机制设计，用于在Feed中集成广告拍卖和分配。这种设计解决了广告拍卖不考虑外部性和广告分配无法保持激励兼容性的问题。

    

    为了响应每个用户的页面请求，电子商务平台通常呈现一个有序列表，其中包含几个有机物品和一个广告。这个列表是广告拍卖和分配过程的结果，直接影响平台的广告收入和总交易额。广告拍卖确定显示的广告和相应的支付，而广告分配决定广告和有机物品的显示位置。目前的方法将广告拍卖和分配分为两个不同的阶段，面临两个问题：1）广告拍卖没有考虑外部性，如实际显示位置和上下文对广告点击率的影响；2）广告分配利用拍卖获胜广告的支付来动态确定显示位置，未能保持广告的激励兼容性。例如，在使用传统的广义二价(GSP)拍卖阶段，广告分配阶段无法维持激励兼容性。

    E-commerce platforms usually present an ordered list, mixed with several organic items and an advertisement, in response to each user's page view request. This list, the outcome of ad auction and allocation processes, directly impacts the platform's ad revenue and gross merchandise volume (GMV). Specifically, the ad auction determines which ad is displayed and the corresponding payment, while the ad allocation decides the display positions of the advertisement and organic items. The prevalent methods of segregating the ad auction and allocation into two distinct stages face two problems: 1) Ad auction does not consider externalities, such as the influence of actual display position and context on ad Click-Through Rate (CTR); 2) The ad allocation, which utilizes the auction-winning ad's payment to determine the display position dynamically, fails to maintain incentive compatibility (IC) for the advertisement. For instance, in the auction stage employing the traditional Generalized Secon
    
[^23]: 自主机器人系统的量化自主度评价框架

    A Quantitative Autonomy Quantification Framework for Fully Autonomous Robotic Systems. (arXiv:2311.01939v1 [cs.RO])

    [http://arxiv.org/abs/2311.01939](http://arxiv.org/abs/2311.01939)

    本文提出了一个基于任务需求的自主度评估框架，主要关注完全自主模式，通过确定机器人任务特性，推导出自主度的三个度量标准，并将自主度分为自主度水平和自主度程度两部分。

    

    尽管自主功能促进了机器人系统在有限人类监督的领域及更远处的部署，但在任务需求和自主能力之间找到对应关系仍然是一个开放的挑战。因此，在过去三十年中提出了许多量化自主度的方法，但据我们所知，所有这些方法都没有辨别自主度变化的子模式特征，并且一些方法基于违反Goodhart定律的度量标准。本文侧重于完全自主模式，并提出了一个基于任务需求的自主度评估框架。该框架通过确定机器人任务特性，推导出三个自主度度量标准，即所需能力、可靠性和响应性，并通过确定自主度水平和自主度程度的函数，将自主度作为两部分度量来衡量。这些特性基于机器人最终取代人类的观念。

    Although autonomous functioning facilitates deployment of robotic systems in domains that admit limited human oversight on our planet and beyond, finding correspondence between task requirements and autonomous capability is still an open challenge. Consequently, a number of methods for quantifying autonomy have been proposed over the last three decades, but to our knowledge all these have no discernment of sub-mode features of variation of autonomy and some are based on metrics that violet the Goodhart's law. This paper focuses on the full autonomous mode and proposes a task-requirements based autonomy assessment framework. The framework starts by establishing robot task characteristics from which three autonomy metrics, namely requisite capability, reliability and responsiveness, and functions for determining autonomy as a two-part measure, namely of level of autonomy and degree of autonomy are derived. These characteristics are founded on the realization that robots ultimately replac
    
[^24]: 人类和语言模型中的三段论推理的系统比较

    A Systematic Comparison of Syllogistic Reasoning in Humans and Language Models. (arXiv:2311.00445v1 [cs.CL])

    [http://arxiv.org/abs/2311.00445](http://arxiv.org/abs/2311.00445)

    这项研究通过对比人类和语言模型在三段论推理中的表现，发现较大的语言模型更合逻辑，甚至比人类更合逻辑，但即使最大的语言模型也会出现与人类推理类似的错误，总体上认为语言模型在某些情况下能够克服人类偏见。

    

    理性行为的一个核心组成部分是逻辑推理：确定哪些结论可以从一组前提中得出。心理学家已经记录下人类推理与逻辑规则不符的几种方式。语言模型是否能够复制这些偏差，或者它们能够克服这些偏差？我们关注三段论的情况 - 从两个简单前提中推导出的推理，这在心理学中已经广泛研究 - 我们发现较大的模型比较合逻辑，而且比人类更合逻辑。与此同时，即使是最大的模型也会出现系统性错误，其中一些错误与人类推理的偏见相似，例如排序效应和逻辑谬误。总体上，我们发现语言模型模仿了训练数据中包含的人类偏见，但在某些情况下能够克服这些偏见。

    A central component of rational behavior is logical inference: the process of determining which conclusions follow from a set of premises. Psychologists have documented several ways in which humans' inferences deviate from the rules of logic. Do language models, which are trained on text generated by humans, replicate these biases, or are they able to overcome them? Focusing on the case of syllogisms -- inferences from two simple premises, which have been studied extensively in psychology -- we show that larger models are more logical than smaller ones, and also more logical than humans. At the same time, even the largest models make systematic errors, some of which mirror human reasoning biases such as ordering effects and logical fallacies. Overall, we find that language models mimic the human biases included in their training data, but are able to overcome them in some cases.
    
[^25]: SE(3)-蛋白质主链生成中的随机流匹配

    SE(3)-Stochastic Flow Matching for Protein Backbone Generation. (arXiv:2310.02391v1 [cs.LG])

    [http://arxiv.org/abs/2310.02391](http://arxiv.org/abs/2310.02391)

    通过SE(3)-Stochastic Flow Matching，我们提出了一系列新型生成模型FoldFlow，可以准确建模蛋白质主链。这些模型通过无需模拟训练和Riemannian最优传输的结合，具有更好的稳定性和建模能力。

    

    通过基于三维刚体运动（即SE(3)群）的流匹配范式，我们引入了一系列具有不断增强建模能力的新型生成模型：FoldFlow，从而实现了对蛋白质主链的准确建模。首先，我们介绍了FoldFlow-Base，一种无需模拟的学习确定性连续时间动力学和匹配不变目标分布的方法。接下来，我们通过引入Riemannian最优传输来加速训练，创建了FoldFlow-OT，从而构建了更简单和稳定的流。最后，我们设计了FoldFlow-SFM，将Riemannian最优传输和无需模拟训练相结合，可以学习SE(3)上的随机连续时间动力学。我们的FoldFlow生成模型家族相比之前的方法具有几个关键优势。

    The computational design of novel protein structures has the potential to impact numerous scientific disciplines greatly. Toward this goal, we introduce $\text{FoldFlow}$ a series of novel generative models of increasing modeling power based on the flow-matching paradigm over $3\text{D}$ rigid motions -i.e. the group $\text{SE(3)}$ -- enabling accurate modeling of protein backbones. We first introduce $\text{FoldFlow-Base}$, a simulation-free approach to learning deterministic continuous-time dynamics and matching invariant target distributions on $\text{SE(3)}$. We next accelerate training by incorporating Riemannian optimal transport to create $\text{FoldFlow-OT}$, leading to the construction of both more simple and stable flows. Finally, we design $\text{FoldFlow-SFM}$ coupling both Riemannian OT and simulation-free training to learn stochastic continuous-time dynamics over $\text{SE(3)}$. Our family of $\text{FoldFlow}$ generative models offer several key advantages over previous
    
[^26]: ChatGPT和简单的语言推断：盲点和缺陷

    ChatGPT and Simple Linguistic Inferences: Blind Spots and Blinds. (arXiv:2305.14785v1 [cs.CL])

    [http://arxiv.org/abs/2305.14785](http://arxiv.org/abs/2305.14785)

    本文研究了ChatGPT语言模型的局限性，指出其在简单语言推断任务中存在困难，并探讨了如何改善其对基本语言概念的理解。

    

    本文研究了ChatGPT的理解能力限制，针对对于人类来说通常简单的推断任务，但这些似乎对该模型具有挑战性。具体来说，我们针对(i)语法规定的蕴含，(ii)带有不确定性证据副词的前提，以及(iii)单调蕴含性进行了研究。我们为这些推理类型提供了专家设计的评估集，并在零样本设置下进行实验。我们的结果表明，该模型在这些推理类型方面存在困难，展示中等到低精度。此外，尽管ChatGPT在直接提示下表现出对底层语言概念的了解，但它经常不能利用这些知识作出正确的推断。更有趣的是，进一步的实验表明，将前提嵌入前提条件触发或非实际性动词会导致模型更频繁地预测蕴含，而不考虑正确的语义标签。总的来说，这些结果揭示了当前语言模型的局限性，以及继续改善它们对基本语言概念的理解的必要性。

    This paper sheds light on the limitations of ChatGPT's understanding capabilities, focusing on simple inference tasks that are typically easy for humans but appear to be challenging for the model. Specifically, we target (i) grammatically-specified entailments, (ii) premises with evidential adverbs of uncertainty, and (iii) monotonicity entailments. We present expert-designed evaluation sets for these inference types and conduct experiments in a zero-shot setup. Our results show that the model struggles with these types of inferences, exhibiting moderate to low accuracy. Moreover, while ChatGPT demonstrates knowledge of the underlying linguistic concepts when prompted directly, it often fails to incorporate this knowledge to make correct inferences. Even more strikingly, further experiments show that embedding the premise under presupposition triggers or non-factive verbs causes the model to predict entailment more frequently {regardless} of the correct semantic label. Overall these re
    
[^27]: 深度时间图聚类

    Deep Temporal Graph Clustering. (arXiv:2305.10738v1 [cs.LG])

    [http://arxiv.org/abs/2305.10738](http://arxiv.org/abs/2305.10738)

    提出通用框架TGC 用于 deep temporal graph clustering, 解决了时间图只能作为静态图处理的难题，实现了对动态信息的聚类。实验证明了 TGC 的优越性。

    

    最近深度图聚类已经引起了很多关注，因为它可以增强模型在无监督场景下的表示学习能力。然而，适用于时间图的深度聚类方法 - 可以捕获关键的动态交互信息，并没有得到充分的探索。这意味着在许多面向聚类的现实场景中，时间图只能作为静态图来处理。这不仅导致了动态信息的丢失，也引发了巨大的计算消耗。为了解决这个问题，我们提出了一个名为TGC的通用框架，用于时间图深度聚类，它调整了深度聚类技术（聚类分配分布和邻接矩阵重构），以适应时间图基于交互序列的批处理模式。此外，我们还从几个方面讨论了时间图聚类与现有静态图聚类的差异。实验证明了TGC的卓越性能。

    Deep graph clustering has recently received significant attention due to its ability to enhance the representation learning capabilities of models in unsupervised scenarios. Nevertheless, deep clustering for temporal graphs, which could capture crucial dynamic interaction information, has not been fully explored. It means that in many clustering-oriented real-world scenarios, temporal graphs can only be processed as static graphs. This not only causes the loss of dynamic information but also triggers huge computational consumption. To solve the problem, we propose a general framework for deep Temporal Graph Clustering called TGC, which adjusts deep clustering techniques (clustering assignment distribution and adjacency matrix reconstruction) to suit the interaction sequence-based batch-processing pattern of temporal graphs. In addition, we discuss differences between temporal graph clustering and existing static graph clustering from several levels. To verify the superiority of the pro
    
[^28]: 位置偏差对token分类中的语言模型的影响

    Impact of Position Bias on Language Models in Token Classification. (arXiv:2304.13567v1 [cs.CL])

    [http://arxiv.org/abs/2304.13567](http://arxiv.org/abs/2304.13567)

    研究了语言模型在token分类任务中的位置偏差问题，通过实验表明在具体任务中，BERT、ERNIE、ELECTRA等编码器以及GPT2和BLOOM等解码器的平均性能下降了3%和9%。

    

    语言模型在自然语言处理任务中表现出了最先进的性能。命名实体识别(NER)或词性标注等下游任务已知存在数据不平衡问题，特别是在正负示例的比例和类不平衡方面。本文研究了语言模型的另一个特定问题，即token分类任务中正示例的位置偏差。因此，我们对基于Token分类基准测试的语言模型的性能进行了深入的位置偏差评估。我们的研究包括CoNLL03和OntoNote5.0用于NER，English Tree Bank UD_en和TweeBank用于POS标记。我们提出了一种评估方法，以研究Transformer模型中的位置偏差。我们发现像BERT、ERNIE、ELECTRA这样的编码器和像GPT2 和BLOOM这样的解码器平均性能下降了3%和9%。

    Language Models (LMs) have shown state-of-the-art performance in Natural Language Processing (NLP) tasks. Downstream tasks such as Named Entity Recognition (NER) or Part-of-Speech (POS) tagging are known to suffer from data imbalance issues, specifically in terms of the ratio of positive to negative examples, and class imbalance. In this paper, we investigate an additional specific issue for language models, namely the position bias of positive examples in token classification tasks. Therefore, we conduct an in-depth evaluation of the impact of position bias on the performance of LMs when fine-tuned on Token Classification benchmarks. Our study includes CoNLL03 and OntoNote5.0 for NER, English Tree Bank UD_en and TweeBank for POS tagging. We propose an evaluation approach to investigate position bias in Transformer models. We show that encoders like BERT, ERNIE, ELECTRA, and decoders such as GPT2 and BLOOM can suffer from this bias with an average drop of 3\% and 9\% in their performan
    
[^29]: 关于意义计算、语言模型与不可理解恐惧的研究

    On the Computation of Meaning, Language Models and Incomprehensible Horrors. (arXiv:2304.12686v1 [cs.AI])

    [http://arxiv.org/abs/2304.12686](http://arxiv.org/abs/2304.12686)

    本文提出了一个全面的机械化解释，涉及意义、交流和符号出现的现象，揭示了当前的语言模型并不具备与人类相同的意义理解，作者建议模拟人类情感并优化模型以构建弱表示形式来解决这个问题。

    

    我们将意义的基础理论与人工通用智能的数学形式结合起来，提出了一个全面的机械化解释，涉及意义、交流和符号出现的现象，这对通用人工智能和关于语言本质的辩论都具有重要意义。通过研究机器在什么条件下能够生成有意义的话语或理解人类的意义，我们发现当前的语言模型并不具备与人类相同的意义理解，也不意味着它们的回答具有我们所归属的任何意义。因此，我们建议模拟人类情感并优化模型以构建弱表示形式来解决这个问题。我们的研究成果揭示了意义与...

    We integrate foundational theories of meaning with a mathematical formalism of artificial general intelligence (AGI) to offer a comprehensive mechanistic explanation of meaning, communication, and symbol emergence. This synthesis holds significance for both AGI and broader debates concerning the nature of language, as it unifies pragmatics, logical truth conditional semantics, Peircean semiotics, and a computable model of enactive cognition, addressing phenomena that have traditionally evaded mechanistic explanation. By examining the conditions under which a machine can generate meaningful utterances or comprehend human meaning, we establish that the current generation of language models do not possess the same understanding of meaning as humans nor intend any meaning that we might attribute to their responses. To address this, we propose simulating human feelings and optimising models to construct weak representations. Our findings shed light on the relationship between meaning and in
    
[^30]: 新兴因果性与意识基础

    Emergent Causality & the Foundation of Consciousness. (arXiv:2302.03189v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.03189](http://arxiv.org/abs/2302.03189)

    讨论了不需要显式实现干预表示的 Pareto 最优数学形式，通过归纳性地出现相关因果干预的表示，作为自我和任何其他对象的表示。

    

    为了在交互环境中做出准确的推断，智能体不能把被动观察事件与干预引起它们混淆。$do$ 操作符将干预形式化，以便我们可以推断其影响。然而，在交互环境中存在无需显式实现干预表示的 Pareto 最优数学形式，可以做出最大程度的准确推断。本文考察了其中一个这样的形式。我们展示了在不存在 $do$ 操作符的情况下，可以通过变量表示干预。然后我们认为变量是抽象的，需要显式预先表示干预只是因为我们预设了这类抽象概念。前述的形式避免了这种困扰，因此，如果有适当的初始条件，则相关因果干预的表示将通过归纳性地出现。这些新兴的抽象作为自我和任何其他对象的表示。

    To make accurate inferences in an interactive setting, an agent must not confuse passive observation of events with having intervened to cause them. The $do$ operator formalises interventions so that we may reason about their effect. Yet there exist pareto optimal mathematical formalisms of general intelligence in an interactive setting which, presupposing no explicit representation of intervention, make maximally accurate inferences. We examine one such formalism. We show that in the absence of a $do$ operator, an intervention can be represented by a variable. We then argue that variables are abstractions, and that need to explicitly represent interventions in advance arises only because we presuppose these sorts of abstractions. The aforementioned formalism avoids this and so, initial conditions permitting, representations of relevant causal interventions will emerge through induction. These emergent abstractions function as representations of one`s self and of any other object, inas
    
[^31]: 假设的最佳选择是最弱的而不是最短的

    The Optimal Choice of Hypothesis Is the Weakest, Not the Shortest. (arXiv:2301.12987v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.12987](http://arxiv.org/abs/2301.12987)

    本研究表明，在构建假设的过程中，选择最短的假设不如选择最弱的假设，而弱点是比长度或简单性更好的推广表现代理。

    

    如果$A$和$B$是这样的集合，即$A \subset B$，那么一般化可以被理解为从$A$推断出一个足以构建$B$的假设。可以从$A$推断出任意数量的假设，但只有其中的一些可以推广到$B$。怎样知道哪些假设可能推广？一种策略是选择最短的，将压缩信息的能力与推广的能力（智能的代理）等同起来。我们在主动认知的数学形式主义背景下研究了这一点。我们证明了，压缩既不是最大化表现（用假设推广的概率衡量）的必要条件，也不是充分条件。我们制定了一个与长度或简单性无关的代理，称为弱点。我们表明，如果任务是均匀分布的，则不存在任何代理的选择，可以在所有任务中至少与弱点最大化的表现相同，同时在至少一个任务中表现更好。在比较最大弱点和最小描述长度(MDL)的实验中，我们发现最大弱点在各种任务上表现优于MDL。我们认为弱点是比长度或简单性更好的推广表现代理。

    If $A$ and $B$ are sets such that $A \subset B$, generalisation may be understood as the inference from $A$ of a hypothesis sufficient to construct $B$. One might infer any number of hypotheses from $A$, yet only some of those may generalise to $B$. How can one know which are likely to generalise? One strategy is to choose the shortest, equating the ability to compress information with the ability to generalise (a proxy for intelligence). We examine this in the context of a mathematical formalism of enactive cognition. We show that compression is neither necessary nor sufficient to maximise performance (measured in terms of the probability of a hypothesis generalising). We formulate a proxy unrelated to length or simplicity, called weakness. We show that if tasks are uniformly distributed, then there is no choice of proxy that performs at least as well as weakness maximisation in all tasks while performing strictly better in at least one. In experiments comparing maximum weakness and m
    

