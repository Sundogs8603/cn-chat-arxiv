# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [3D Scene Geometry Estimation from 360$^\circ$ Imagery: A Survey.](http://arxiv.org/abs/2401.09252) | 本文调查了基于全景图像的单图、双图或多图的3D场景几何估计方法。主要包括球面相机模型、全景图像获取技术和表示格式、单眼布局和深度推断方法、立体匹配在球面领域的应用，以及多视角摄像机设置下的立体匹配方法。同时还提供了关于数据集和评估尺度的综合列表。 |
| [^2] | [DiffClone: Enhanced Behaviour Cloning in Robotics with Diffusion-Driven Policy Learning.](http://arxiv.org/abs/2401.09243) | 本文介绍了DiffClone，一种通过扩散驱动的策略学习增强行为克隆代理的离线算法。在真实的在线物理机器人上的实验表明，采用MOCO微调的ResNet50的效果最好。 |
| [^3] | [A Blockchain-based Model for Securing Data Pipeline in a Heterogeneous Information System.](http://arxiv.org/abs/2401.09240) | 这个研究提出了一种基于区块链的异构信息系统数据管道安全模型，旨在使用集成的多危险预警系统来解决数据管道中的安全和隐私问题。通过使用区块链的固有安全特性，该模型确保了数据的完整性、机密性和真实性，并通过实验结果证明其相比传统方法具有优势。 |
| [^4] | [DaFoEs: Mixing Datasets towards the generalization of vision-state deep-learning Force Estimation in Minimally Invasive Robotic Surgery.](http://arxiv.org/abs/2401.09239) | 本文介绍了一个新的视觉-触觉数据集（DaFoEs），用于训练深度神经网络模型以预测微创机器人手术中腹腔镜工具施加的力量。通过混合不同的数据集训练，以减少偏见，并提出了可变的编码器-解码器架构来处理单个输入或输入序列。 |
| [^5] | [A Characterization Theorem for Equivariant Networks with Point-wise Activations.](http://arxiv.org/abs/2401.09235) | 本论文提出了一个定理，描述了所有可能的有限维表示、坐标选择和点状激活函数的组合，以获得一个完全等变的层，从而推广和加强了现有的特征定理。具有实际相关性的重要情况作为推论进行了讨论。 |
| [^6] | [Preparing Lessons for Progressive Training on Language Models.](http://arxiv.org/abs/2401.09192) | 提出了一种名为Apollo的方法，通过在低层训练期间学习高层功能，为渐进式训练语言模型设计了课程，实现了最先进的加速比率。 |
| [^7] | [What makes for a 'good' social actor? Using respect as a lens to evaluate interactions with language agents.](http://arxiv.org/abs/2401.09082) | 本文研究以尊重为视角评估与语言代理的交互，提出了一种更加关注关系和情境因素的伦理方法，旨在帮助LLM技术表现得“好” |
| [^8] | [GPT in Sheep's Clothing: The Risk of Customized GPTs.](http://arxiv.org/abs/2401.09075) | GPTs的定制化使用可能存在隐私和安全风险。 |
| [^9] | [Code Simulation Challenges for Large Language Models.](http://arxiv.org/abs/2401.09074) | 大型语言模型在模拟计算机代码和算法执行方面遇到挑战，性能随着代码长度的增加而迅速下降。在处理短程序或标准过程时，它们能以低错误率按顺序执行指令，但对于复杂的程序，特别是包含关键路径和冗余指令的程序，模拟效果较差。我们提出了一种逐行模拟代码执行的方法来解决这个问题。 |
| [^10] | [Fixed-Budget Differentially Private Best Arm Identification.](http://arxiv.org/abs/2401.09073) | 本论文研究了差分隐私约束下固定预算条件下的最佳臂识别问题，提出了满足差分隐私约束的策略DP-BAI，并得到了错误概率的上界和最小-最大下界的指数衰减关系。 |
| [^11] | [Rethinking Spectral Graph Neural Networks with Spatially Adaptive Filtering.](http://arxiv.org/abs/2401.09071) | 本文重新思考了谱图神经网络，并揭示了谱滤波和空间聚合之间的联系。该研究发现，谱滤波在隐含地将原始图转换成适应性新图，并明确计算用于空间聚合的新图。适应性新图展现出非局部性，并能够反映节点之间的标签一致性。 |
| [^12] | [Knowledge Pyramid: A Novel Hierarchical Reasoning Structure for Generalized Knowledge Augmentation and Inference.](http://arxiv.org/abs/2401.09070) | 这篇论文提出了一种新型的推理方法，通过使用新颖的知识增强策略，从低层知识中提取高层金字塔状知识，并将其应用于多层分层知识图谱中的推理，从而改进了推理的泛化能力。 |
| [^13] | [DTMM: Deploying TinyML Models on Extremely Weak IoT Devices with Pruning.](http://arxiv.org/abs/2401.09068) | DTMM是一个库，旨在在弱物联网设备上高效部署和执行机器学习模型。之前的解决方案无法同时实现在不损害准确性的情况下深度压缩模型和高效执行的目标，而DTMM通过修剪单元选择解决了这个问题。 |
| [^14] | [Towards Continual Learning Desiderata via HSIC-Bottleneck Orthogonalization and Equiangular Embedding.](http://arxiv.org/abs/2401.09067) | 本文提出了一种方法，通过HSIC-Bottleneck正交化和平均角嵌入，实现了对持续学习中遗忘问题的解决，该方法在不使用先前任务的训练数据且模型大小相对恒定的条件下，通过限制逐层参数覆盖和决策边界畸变来避免遗忘。 |
| [^15] | [LLMs for Relational Reasoning: How Far are We?.](http://arxiv.org/abs/2401.09042) | 本论文对多种最先进的LLM的推理能力进行了全面评估，发现它们在归纳逻辑编程基准测试上的表现欠佳，这挑战了它们在处理常识规划的顺序决策问题方面的能力。 |
| [^16] | [UOEP: User-Oriented Exploration Policy for Enhancing Long-Term User Experiences in Recommender Systems.](http://arxiv.org/abs/2401.09034) | UOEP是一种用户导向的探索策略，针对推荐系统中不同活跃水平的用户群体实现细粒度探索，以增强用户的长期体验。 |
| [^17] | [Cross-modality Guidance-aided Multi-modal Learning with Dual Attention for MRI Brain Tumor Grading.](http://arxiv.org/abs/2401.09029) | 本文提出了一种用于MRI脑肿瘤分级的跨模态引导辅助多模态学习与双重注意机制，以提高脑肿瘤诊断的准确性和性能。 |
| [^18] | [Change Detection Between Optical Remote Sensing Imagery and Map Data via Segment Anything Model (SAM).](http://arxiv.org/abs/2401.09019) | 本研究利用分段任意模型（SAM）实现了光学遥感图像和地图数据之间的无监督多模态变化检测。通过SAM的零样本迁移能力，可以获得高质量的光学图像分割地图，并且提出了两种策略来指导分割过程，从而在土地覆盖变化和新土地覆盖对象识别方面具有良好性能。 |
| [^19] | [Inductive Models for Artificial Intelligence Systems are Insufficient without Good Explanations.](http://arxiv.org/abs/2401.09011) | 本文讨论了机器学习模型的局限性，特别是深度神经网络的透明度和解释能力不足，提出AI系统不仅需要预测能力，还需要提供良好的解释能力和洞察力。 |
| [^20] | [Hybrid of DiffStride and Spectral Pooling in Convolutional Neural Networks.](http://arxiv.org/abs/2401.09008) | 本研究提出了一种混合DiffStride和谱池化的卷积神经网络模型，通过使用反向传播执行的下采样可学习步幅技术和谱池化技术，以保留图像中的重要信息。 |
| [^21] | [Augmenting Math Word Problems via Iterative Question Composing.](http://arxiv.org/abs/2401.09003) | 本研究通过引入MMIQC数据集和迭代组合问题(IQC)的新颖增强方法，成功提高了大型语言模型的数学推理能力，在竞赛级数学问题上取得了优于先前最佳结果的准确率。 |
| [^22] | [Continuous Time Continuous Space Homeostatic Reinforcement Learning (CTCS-HRRL) : Towards Biological Self-Autonomous Agent.](http://arxiv.org/abs/2401.08999) | 本文提出了连续时间连续空间的稳态强化学习框架CTCS-HRRL，并通过模拟实验证明了该模型的有效性和与代理能力相关的证据。 |
| [^23] | [MicroNAS: Zero-Shot Neural Architecture Search for MCUs.](http://arxiv.org/abs/2401.08996) | MicroNAS是一个针对边缘计算中的微控制器单元（MCUs）设计的硬件感知零样本神经架构搜索框架。与之前的方法相比，MicroNAS在搜索效率和MCU推理速度方面都取得了显著的提升，同时保持了相似的精度水平。 |
| [^24] | [A GAN-based data poisoning framework against anomaly detection in vertical federated learning.](http://arxiv.org/abs/2401.08984) | 这篇论文介绍了一种基于GAN的数据污染框架（P-GAN），用于对抗纵向联合学习中的异常检测。通过使用半监督学习训练一个替代目标模型，并使用GAN生成对抗性扰动来降低模型性能，最后通过深度自编码器开发的异常检测算法提供了强大的防御机制。 |
| [^25] | [FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data.](http://arxiv.org/abs/2401.08977) | 本文介绍了一种名为FedLoGe的方法，它通过在神经网络崩溃框架中集成表示学习和分类器对齐来提高区域和全局模型的性能，解决了在联邦长尾学习中忽视本地级别性能的问题。 |
| [^26] | [OCTO+: A Suite for Automatic Open-Vocabulary Object Placement in Mixed Reality.](http://arxiv.org/abs/2401.08973) | 本论文介绍了一种称为OCTO + 的套件，用于在混合现实中自动将虚拟物体放置在合适的位置。通过使用最新的开放词汇视觉语言模型，该方法在多个评估标准上取得了最先进的效果，超过其他方法。同时，还引入了一个用于自动评估增强现实中虚拟物体放置的基准。 |
| [^27] | [From User Surveys to Telemetry-Driven Agents: Exploring the Potential of Personalized Productivity Solutions.](http://arxiv.org/abs/2401.08960) | 本研究提出了一个以用户为中心的方法，以了解AI基于的生产力代理的偏好，并开发出个性化解决方案。通过调查和使用遥测数据，我们开发了一个GPT-4驱动的个性化生产力代理，并在研究中与其他辅助工具进行了比较。我们的研究突出了用户中心设计、适应性和个性化与隐私之间的平衡的重要性。 |
| [^28] | [Towards Off-Policy Reinforcement Learning for Ranking Policies with Human Feedback.](http://arxiv.org/abs/2401.08959) | 本文提出了一种新的离策略价值排名（VR）算法，通过统一的期望最大化（EM）框架，在不需要在线交互的情况下最大化用户的长期回报和优化排名指标，以提高样本效率。 |
| [^29] | [SWBT: Similarity Weighted Behavior Transformer with the Imperfect Demonstration for Robotic Manipulation.](http://arxiv.org/abs/2401.08957) | 本论文提出了一种新型框架SWBT，能够在机器人操作任务中有效地从专家演示和不完美演示中学习，而无需与环境进行交互。这是第一个将不完美演示整合到离线模仿学习设置中的机器人操作任务的研究。 |
| [^30] | [CEL: A Continual Learning Model for Disease Outbreak Prediction by Leveraging Domain Adaptation via Elastic Weight Consolidation.](http://arxiv.org/abs/2401.08940) | 本研究提出了一种名为CEL的模型，通过利用领域自适应和弹性权重整合，实现了对疾病爆发预测的持续学习。该模型通过惩罚重要参数的改变来缓解灾难性遗忘现象，并在多个疾病上取得了比其他模型更好的性能。 |
| [^31] | [DeLF: Designing Learning Environments with Foundation Models.](http://arxiv.org/abs/2401.08936) | DeLF是一种利用大型语言模型设计学习环境的方法，可以解决在实践中应用强化学习的困难。通过测试，证明DeLF可以为不同的学习环境获得可执行的代码。 |
| [^32] | [Learning to detect cloud and snow in remote sensing images from noisy labels.](http://arxiv.org/abs/2401.08932) | 本研究通过构建新的数据集和引入课程学习方法，提出了一种用于遥感图像中云和雪检测的训练策略。同时，设计了一种更合适的模型性能评估方法，有效减少了由于噪声标签引起的性能评估偏差。 |
| [^33] | [3D Human Pose Analysis via Diffusion Synthesis.](http://arxiv.org/abs/2401.08930) | 本文提出了一种名为PADS的框架，通过扩散合成过程学习姿势先验，解决3D人体姿势分析中的各种挑战，将多个姿势分析任务统一为逆问题的实例，验证了其性能和适应性。 |
| [^34] | [Bridging State and History Representations: Understanding Self-Predictive RL.](http://arxiv.org/abs/2401.08898) | 本论文研究了深度强化学习中状态和历史表示间的关系，发现了这些方法和框架实际上都基于自预测抽象的共同思想，并提供了理论洞见和简化算法来学习自预测表示。 |
| [^35] | [CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational AutoEncoder.](http://arxiv.org/abs/2401.08897) | CFASL是一种用于解缠学习的新方法，它将对称性学习与VAE集成，无需任何数据集因子信息的先验知识，具有三个新特征：对齐潜在向量维度到可学习对称代码簿中的对称性，学习复合对称性来表达未知因素的变化，以及引入群等变编码器和解码器来训练VAE。 |
| [^36] | [NOTSOFAR-1 Challenge: New Datasets, Baseline, and Tasks for Distant Meeting Transcription.](http://arxiv.org/abs/2401.08887) | NOTSOFAR-1挑战旨在解决远距离会议转录中的远距离发言人划分和自动语音识别问题，在一个新发布的数据集上进行评估。 |
| [^37] | [Contribution Functions for Quantitative Bipolar Argumentation Graphs: A Principle-based Analysis.](http://arxiv.org/abs/2401.08879) | 本文对量化双极论证图的贡献函数进行了基于原则的分析，为选择最合适的函数提供了工具。 |
| [^38] | [DCRMTA: Unbiased Causal Representation for Multi-touch Attribution.](http://arxiv.org/abs/2401.08875) | DCRMTA提出了一种无偏的多触点归因方法，通过建立转化预测模型和构建对照触点序列来减轻偏差的影响。 |
| [^39] | [Robust Localization of Key Fob Using Channel Impulse Response of Ultra Wide Band Sensors for Keyless Entry Systems.](http://arxiv.org/abs/2401.08863) | 本文研究了使用神经网络和超宽带传感器对车辆中的钥匙扣进行定位的问题，并提出了一种新的鲁棒定位方法，该方法在没有对抗训练的情况下取得了比基准方法更好的性能。 |
| [^40] | [REValueD: Regularised Ensemble Value-Decomposition for Factorisable Markov Decision Processes.](http://arxiv.org/abs/2401.08850) | REValueD是一种通过正则化集合值分解的新算法，针对高维离散动作空间的任务提供了优越性能，尤其在人形和狗类任务中表现出色。它遏制了Q-learning算法的高估偏差，并减轻了目标方差问题。 |
| [^41] | [Learning from Sparse Offline Datasets via Conservative Density Estimation.](http://arxiv.org/abs/2401.08819) | 本文提出了一种名为保守密度估计（CDE）的训练算法，通过明确约束状态-行为占据稳态分布来解决离线强化学习中的外推错误问题。在稀疏奖励或不足数据的任务中，CDE显示出明显优于基准方法的性能。 |
| [^42] | [Adversarial Supervision Makes Layout-to-Image Diffusion Models Thrive.](http://arxiv.org/abs/2401.08815) | 该论文提出了一种对抗监督的布局到图像扩散模型（ALDM），通过引入分割判别器和多步展开策略，可以提升布局到图像合成任务中的文本编辑能力和生成图像与输入布局之间的对齐准确性。 |
| [^43] | [MMToM-QA: Multimodal Theory of Mind Question Answering.](http://arxiv.org/abs/2401.08743) | MMToM-QA是一个多模态心智理论问答基准，用于评估机器对于人的心智理论的理解能力。我们提出了一种新的方法BIP-ALM用于实现多模态心智理论能力。 |
| [^44] | [Fixed Point Diffusion Models.](http://arxiv.org/abs/2401.08741) | 固定点扩散模型（FPDM）是一种将固定点求解引入扩散生成模型框架的新方法，通过嵌入固定点求解层和采用新的训练方法，显著减小了模型大小、内存使用量并加快了训练速度，并且提出了两种新的技术来提高采样效率。实验证明，与现有模型相比，FPDM在性能和效率上有明显改进。 |
| [^45] | [EgoGen: An Egocentric Synthetic Data Generator.](http://arxiv.org/abs/2401.08739) | EgoGen是一种新的合成数据生成器，它可以为具体化自我的感知任务生成准确和丰富的地面真实训练数据，并利用自我视觉输入来感知3D环境。 |
| [^46] | [AgentMixer: Multi-Agent Correlated Policy Factorization.](http://arxiv.org/abs/2401.08728) | AgentMixer提出了一种新颖的框架，允许智能体通过策略修改来实现协同决策。通过构造联合策略为各个部分策略的非线性组合，可实现部分可观测智能体的稳定训练和分散执行。 |
| [^47] | [MA2GCN: Multi Adjacency relationship Attention Graph Convolutional Networks for Traffic Prediction using Trajectory data.](http://arxiv.org/abs/2401.08727) | 提出了一种新的交通拥堵预测模型，使用车辆轨迹数据以及多邻接关系注意力图卷积网络（MA2GCN）来预测交通拥堵情况，不依赖于传感器数据，提取灵活且准确的交通信息。 |
| [^48] | [A Telerehabilitation System for the Selection, Evaluation and Remote Management of Therapies.](http://arxiv.org/abs/2401.08721) | 本文介绍了一个创新的基于Kinect的远程康复系统，它具有知识提取功能和远程沉浸功能，可实现对患者的康复训练的选择、评估和远程管理。 |
| [^49] | [Selecting Subsets of Source Data for Transfer Learning with Applications in Metal Additive Manufacturing.](http://arxiv.org/abs/2401.08715) | 该论文提出了一种系统的方法来寻找适当的源数据子集，用于金属增材制造中的迁移学习。该方法基于源数据和目标数据集之间的相似性来选择子集，并通过两个相似度距离度量定义的Pareto frontier进行迭代选择。 |
| [^50] | [Training program on sign language: social inclusion through Virtual Reality in ISENSE project.](http://arxiv.org/abs/2401.08714) | ISENSE项目中的虚拟现实培训程序旨在通过提供技术工具培训听觉正常的人学习手语，从而促进社会融合。 |
| [^51] | [Assistant, Parrot, or Colonizing Loudspeaker? ChatGPT Metaphors for Developing Critical AI Literacies.](http://arxiv.org/abs/2401.08711) | 这项研究探讨了讨论AI隐喻如何帮助培养对AI系统和大型语言模型的理解，以及如何促进批判性AI素养的发展。通过分析隐喻并与其他人讨论，研究团队发现隐喻有助于对AI的伦理、公平和可访问性等问题进行思考，并评估了隐喻在是否促进拟人化方面的作用。 |
| [^52] | [On Image Search in Histopathology.](http://arxiv.org/abs/2401.08699) | 这篇论文综述了组织病理学图像搜索技术的最新发展，为计算病理学研究人员提供了简明的概述，旨在寻求有效、快速和高效的图像搜索方法。 |
| [^53] | [Hierarchical Source-to-Post-Route QoR Prediction in High-Level Synthesis with GNNs.](http://arxiv.org/abs/2401.08696) | 该论文提出了一种在高层次综合中使用GNN进行源-后向路质量预测的分层方法。该方法通过建模流程、图构建方法和分层GNN训练和预测方法，能够有效预测QoR指标，并在设计空间探索中减少了运行时。 |
| [^54] | [Enabling Collaborative Clinical Diagnosis of Infectious Keratitis by Integrating Expert Knowledge and Interpretable Data-driven Intelligence.](http://arxiv.org/abs/2401.08695) | 通过整合专家知识和可解释的数据驱动智能，本研究提出了一种知识引导诊断模型（KGDM），用于协同临床诊断传染性角膜炎（IK）。KGDM通过与临床医生的互动，提供可视化推理过程，包括AI基于生物标记和具有相同诊断模式的病例。这一方法有望提高安全性和预测准确性。 |
| [^55] | [Combining Confidence Elicitation and Sample-based Methods for Uncertainty Quantification in Misinformation Mitigation.](http://arxiv.org/abs/2401.08694) | 本研究提出了一种结合置信度引导和基于样本的方法的不确定性量化框架，用于解决误信息消除中的幻觉和过度自信的预测问题，并提出了混合框架以提供更好的不确定性估计。 |
| [^56] | [Zero-Shot RTL Code Generation with Attention Sink Augmented Large Language Models.](http://arxiv.org/abs/2401.08683) | 本文探讨了使用大型语言模型在硬件设计中快速生成RTL代码的可能性，并展示了新的注意力机制如何提供功能、优化和符合行业标准的RTL代码。 |
| [^57] | [Concept Alignment.](http://arxiv.org/abs/2401.08672) | 在AI对齐的讨论中，我们强调了概念对齐的重要性，认为在对齐价值观之前，AI系统和人类必须对其理解世界所使用的概念进行对齐。我们整合了哲学、认知科学和深度学习的思想，并提出了实现共享概念的机会和挑战。 |
| [^58] | [Deep Reinforcement Learning for Multi-Truck Vehicle Routing Problems with Multi-Leg Demand Routes.](http://arxiv.org/abs/2401.08669) | 本研究针对多卡车多分段需求路径的车辆路径问题，通过对现有的编码器-解码器注意力模型进行扩展，实现了在工业供应链物流中使用深度强化学习的有效策略。 |
| [^59] | [Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges.](http://arxiv.org/abs/2401.08664) | 本文回顾了针对教育能力的大型语言模型研究，包括数学、写作、编程、推理和基于知识的问答，旨在探索其在构建下一代智能教育系统中的潜力和挑战。 |
| [^60] | [An Integrated Imitation and Reinforcement Learning Methodology for Robust Agile Aircraft Control with Limited Pilot Demonstration Data.](http://arxiv.org/abs/2401.08663) | 本文提出了一种使用有限的飞行员示范数据的集成模仿和强化学习方法，用于建立适用于广泛条件的敏捷飞行器的数据驱动机动生成模型，以解决构建模型所需的大量真实数据的时间和成本问题，并能够泛化到其他飞行条件。 |
| [^61] | [End-To-End Planning of Autonomous Driving in Industry and Academia: 2022-2023.](http://arxiv.org/abs/2401.08658) | 这篇论文总结了工业和学术界中的自动驾驶端到端规划方法，包括特斯拉FSD V12、Momenta 2023、Horizon Robotics 2023、Motional RoboTaxi 2022、Woven Planet（丰田）：城市驾驶员和Nvidia，并回顾了最新的学术研究。这篇文章提供了2022-2023年端到端规划的最新结构和快速学习，并适用于初学者和高级研究人员。 |
| [^62] | [SAiD: Speech-driven Blendshape Facial Animation with Diffusion.](http://arxiv.org/abs/2401.08655) | 提出了一种使用扩散模型（SAiD）驱动的语音驱动的三维面部动画方法，通过轻量级的Transformer-based U-Net模型和音频与视觉的交叉模态对齐偏差，实现了较好的唇部同步和更多样化的唇部运动。 |
| [^63] | [MLCommons Cloud Masking Benchmark with Early Stopping.](http://arxiv.org/abs/2401.08636) | 本文报告了MLCommons科学工作组在云遮挡基准测试上的工作，包括对云遮挡基准测试的参考实现的修改，以实现提前停止。 |
| [^64] | [Synergizing Quality-Diversity with Descriptor-Conditioned Reinforcement Learning.](http://arxiv.org/abs/2401.08632) | 将质量多样性优化与描述符条件加强学习相结合，以克服进化算法的局限性，并在生成既多样又高性能的解决方案集合方面取得成功。 |
| [^65] | [Wake-Sleep Consolidated Learning.](http://arxiv.org/abs/2401.08623) | Wake-Sleep Consolidated Learning（WSCL）是一种借鉴人脑觉醒-睡眠阶段的学习策略，用于改进深度神经网络在连续学习中的视觉分类任务。该方法通过觉醒和睡眠阶段之间的同步学习来实现持续学习，觉醒阶段中模型适应感官输入并利用动态参数冻结机制保持稳定，睡眠阶段根据NREM和REM阶段对模型的突触权重进行巩固和调整，强化重要连接并削弱不重要的连接。 |
| [^66] | [SAM4UDASS: When SAM Meets Unsupervised Domain Adaptive Semantic Segmentation in Intelligent Vehicles.](http://arxiv.org/abs/2401.08604) | SAM4UDASS是一种在自训练无监督领域自适应语义分割方法中使用Segment Anything Model（SAM）的新方法，旨在解决生成精确伪标签的挑战。 |
| [^67] | [Automatic extraction and 3D reconstruction of split wire from point cloud data based on improved DPC algorithm.](http://arxiv.org/abs/2401.08587) | 该论文提出了基于改进的DPC算法的自动点云数据分割和三维重建方法，通过计算云点中每个点的相对坐标，使用集合算法分析分割线数量，然后使用拟合方法得到清晰的分界线。以下是该论文的贡献。 |
| [^68] | [From Conceptual Spaces to Quantum Concepts: Formalising and Learning Structured Conceptual Models.](http://arxiv.org/abs/2401.08585) | 本文提出了一个新的建模框架，可以使用范畴论的推广来建立结构化概念，并展示了如何通过自动学习从数据中获取概念表示。使用范畴论和弦图描述量子过程有助于揭示该方法的关键特点。 |
| [^69] | [Nahid: AI-based Algorithm for operating fully-automatic surgery.](http://arxiv.org/abs/2401.08584) | 本文提出了一种基于软件和计算机视觉技术的全自动手术方法，能够自动诊断和治疗孤立性卵巢子宫内膜异位症。 |
| [^70] | [Temporal Embeddings: Scalable Self-Supervised Temporal Representation Learning from Spatiotemporal Data for Multimodal Computer Vision.](http://arxiv.org/abs/2401.08581) | 该论文提出了一种自监督的时间嵌入方法，可以将地理活动的时间模式与土地利用类型相对应。通过将时间序列信号转换到频域并压缩为语义分割所需的图像通道，时间嵌入可以有效地表示时间序列数据，并用于多个地理空间任务。 |
| [^71] | [Curve-based Neural Style Transfer.](http://arxiv.org/abs/2401.08579) | 该研究提出了一种基于曲线的神经风格迁移方法，通过参数化形状编辑和精确的风格提取，解决了传统方法在处理二进制草图转换时面临的挑战，从而提升了设计表达能力和风格迁移的实践。 |
| [^72] | [Exploiting Inter-Layer Expert Affinity for Accelerating Mixture-of-Experts Model Inference.](http://arxiv.org/abs/2401.08383) | 本文提出了一种称为ExFlow的轻量级优化技术，通过利用层间专家亲和性，大大加速了混合专家模型推理的过程。 |
| [^73] | [An Explainable Proxy Model for Multiabel Audio Segmentation.](http://arxiv.org/abs/2401.08268) | 该论文提出了一种可解释的多标签音频分割代理模型，通过使用非负矩阵分解将嵌入映射到频域，实现了对语音活动、音乐、噪音和重叠语音的同时检测，并且具有强大的可解释性特性。 |
| [^74] | [Carrying over algorithm in transformers.](http://arxiv.org/abs/2401.07993) | 本文研究了在Transformer模型中实现进位算法的方式，发现在两层的仅编码器模型中，第一层负责相同位置的数字相加，第二层根据注意力机制决定是否需要进位，并通过多层感知机来执行进位操作。 |
| [^75] | [E3x: $\mathrm{E}(3)$-Equivariant Deep Learning Made Easy.](http://arxiv.org/abs/2401.07595) | E3x是一种简化了$\mathrm{E}(3)$等变深度学习的软件包，通过内置等变性实现更高的数据效率和准确性。 |
| [^76] | [LightHouse: A Survey of AGI Hallucination.](http://arxiv.org/abs/2401.06792) | 该论文综述了AGI（人工通用智能）的幻觉现象，总结了当前对AGI幻觉的研究进展，并提出了一些未来研究方向的建议。 |
| [^77] | [Frequency Masking for Universal Deepfake Detection.](http://arxiv.org/abs/2401.06506) | 本研究针对通用深度伪造检测问题，首次尝试探索了将屏蔽图像建模应用于频率屏蔽的方法，相较于已有方法，在检测性能上取得了显著提升。 |
| [^78] | [Machine Learning Insides OptVerse AI Solver: Design Principles and Applications.](http://arxiv.org/abs/2401.05960) | 本论文详细研究了将机器学习技术应用于华为云的OptVerse AI Solver，主要包括生成复杂实例、训练框架维护实用性和个性化的解算器策略等方面的创新方法。研究旨在缓解数学规划实例稀缺问题，并超越传统优化技术的能力。 |
| [^79] | [Theory of Mind abilities of Large Language Models in Human-Robot Interaction : An Illusion?.](http://arxiv.org/abs/2401.05302) | 大型语言模型在人机交互中的应用具有较高的风险和潜在的不可逆后果。这项研究探索了大型语言模型的心智理论能力，特别关注机器人感知行为识别任务。 |
| [^80] | [AUTOACT: Automatic Agent Learning from Scratch via Self-Planning.](http://arxiv.org/abs/2401.05268) | AUTOACT是一个自动代理学习框架，通过自主规划合成轨迹，不依赖于大规模数据和闭源模型，能够实现更好或类似的性能。 |
| [^81] | [MobileAgent: enhancing mobile control via human-machine interaction and SOP integration.](http://arxiv.org/abs/2401.04124) | MobileAgent通过人机交互和SOP集成，提高了移动控制的效率和个性化用户需求的满足，同时解决了隐私问题和代理学习中的挑战。 |
| [^82] | [Tiny Time Mixers (TTMs): Fast Pretrained Models for Enhanced Zero/Few-Shot Forecasting of Multivariate Time Series.](http://arxiv.org/abs/2401.03955) | 本论文介绍了一种名为微小时间混合器 (TTMs) 的预训练模型，该模型针对多变量时间序列的零/少样本预测进行了优化。与大型预训练模型相比，TTMs模型更小、更快，并考虑了跨通道相关性，能够在短时间内进行有效的预测。 |
| [^83] | [The Rise of Diffusion Models in Time-Series Forecasting.](http://arxiv.org/abs/2401.03006) | 本文调查了扩散模型在时间序列预测中的应用，提供了对这些模型的全面背景信息和详细说明，同时也对它们在不同数据集上的有效性和彼此之间的比较进行了分析。其贡献包括对扩散模型在时间序列预测中应用的彻底探索和按时间顺序排序的模型概述。这是一份对人工智能和时间序列分析领域的研究人员来说具有价值的资源。 |
| [^84] | [MIMIR: Masked Image Modeling for Mutual Information-based Adversarial Robustness.](http://arxiv.org/abs/2312.04960) | MIMIR提出了一种新颖的防御方法，通过在预训练中利用遮罩图像建模，构建了一个不同的对抗性训练方法。该方法旨在增强Vision Transformers（ViTs）对抗攻击的鲁棒性。 |
| [^85] | [Critical Analysis of 5G Networks Traffic Intrusion using PCA, t-SNE and UMAP Visualization and Classifying Attacks.](http://arxiv.org/abs/2312.04864) | 通过使用PCA、t-SNE和UMAP可视化技术，以及采用机器学习和深度学习方法来降低5G网络流量入侵的风险，并解决类不平衡问题，本研究提出了一种基于人工智能的自治端到端安全设计。 |
| [^86] | [CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models.](http://arxiv.org/abs/2312.04350) | 该论文提出了一个新的NLP任务，评估语言模型在因果推理方面的能力。作者构建了一个大规模的数据集CLadder，并利用oracle因果推理引擎将符号问题转化为自然语言。研究结果表明多个LLMs在该数据集上的表现，并引入并评估了一种定制的链式推理机制。 |
| [^87] | [Caregiver Talk Shapes Toddler Vision: A Computational Study of Dyadic Play.](http://arxiv.org/abs/2312.04118) | 本研究通过计算模型探究了护理者的谈话对幼儿视觉表征的影响。研究发现，即使在语言输入有限的情境下，护理者的谈话仍然能够提升幼儿的视觉表征能力。 |
| [^88] | [Analyzing Emissions and Energy Efficiency at Unsignalized Real-world Intersections Under Mixed Traffic Control.](http://arxiv.org/abs/2311.11866) | 本论文分析了在混合交通控制策略下，非信号化现实世界交叉口的排放和能源效率，提供了对具有复杂拓扑和交通需求的非信号化交叉口的排放分析。 |
| [^89] | [Genetic Algorithm enhanced by Deep Reinforcement Learning in parent selection mechanism and mutation : Minimizing makespan in permutation flow shop scheduling problems.](http://arxiv.org/abs/2311.05937) | 本研究通过引入强化学习方法，在遗传算法的父代选择机制和变异方面进行增强，从而在排列流水车间调度问题中最小化完工时间。这种RL+GA方法通过动态调整选择和变异，有效地改进了原始GA的性能，并表现出适应群体多样性的能力。 |
| [^90] | [Understanding Addition in Transformers.](http://arxiv.org/abs/2310.13121) | 本文通过对经过训练进行整数加法的单层Transformer模型的深入分析，揭示了该模型将任务分为并行的、特定于数字的流，并针对不同的数字位置采用不同的算法，同时还发现了一种罕见的高损失的使用情况。这些发现对于机制可解释性、人工智能安全性和对齐性等方面的研究具有重要贡献。 |
| [^91] | [Learning from Label Proportions: Bootstrapping Supervised Learners via Belief Propagation.](http://arxiv.org/abs/2310.08056) | 本文提出了一种从标签比例中学习的算法框架，通过伪标签化和嵌入细化两个步骤迭代地提高有监督学习器性能。 |
| [^92] | [Combining Spatial and Temporal Abstraction in Planning for Better Generalization.](http://arxiv.org/abs/2310.00229) | Skipper是一个基于模型的强化学习代理，利用时空抽象来在新情境中推广学到的技能。它自动将任务分解为子任务，实现稀疏决策和对环境相关部分的专注计算。实验结果表明，Skipper在零样本泛化方面具有显著优势。 |
| [^93] | [Towards Best Practices of Activation Patching in Language Models: Metrics and Methods.](http://arxiv.org/abs/2309.16042) | 本研究系统地考察了激活路径修复中的方法细节对语言模型解释性结果的影响，并提出了最佳实践建议。 |
| [^94] | [Watch Your Language: Large Language Models and Content Moderation.](http://arxiv.org/abs/2309.14517) | 本研究评估了大型语言模型在内容审查任务上的表现，发现它们在基于规则的社区审查和有害内容检测方面具有很好的效果，在有害内容检测方面超过了现有的分类器。然而，最近模型规模的增加对有害内容检测的改进效果很小。 |
| [^95] | [A Chat About Boring Problems: Studying GPT-based text normalization.](http://arxiv.org/abs/2309.13426) | 本文研究了基于GPT的文本规范化任务。通过结合自洽推理和基于语言知识的提示工程，我们发现基于LLM的文本规范化的错误率比顶级规范化系统低约40％。同时，通过对错误分析，我们发现传统的文本规范化任务设计存在关键限制。我们创建了一个新的框架以识别基于GPT的文本规范化的优势和局限性。这为未来的工作提供了机会。 |
| [^96] | [A Probabilistic Fluctuation based Membership Inference Attack for Generative Models.](http://arxiv.org/abs/2308.12143) | 本研究针对生成模型提出了一种概率波动评估成员推断攻击方法(PFAMI)，通过检测概率分布的波动性来推断模型中是否存在某条训练记录的成员身份。 |
| [^97] | [Poison Dart Frog: A Clean-Label Attack with Low Poisoning Rate and High Attack Success Rate in the Absence of Training Data.](http://arxiv.org/abs/2308.09487) | 毒箭蛙是一种无标签攻击方法，不需要训练数据，只需要目标类别的知识。它具有低中毒率和高攻击成功率。 |
| [^98] | [In-IDE Generation-based Information Support with a Large Language Model.](http://arxiv.org/abs/2307.08177) | 本研究探索了一种基于大型语言模型的IDE内生成式信息支持，通过在IDE中内嵌对话式用户界面，向开发者提供关于代码理解的帮助。通过查询大型语言模型来解释代码、提供API调用的详细信息、解释特定领域术语以及为API提供使用示例，该系统在用户研究中获得了积极的评价。 |
| [^99] | [VertiBench: Advancing Feature Distribution Diversity in Vertical Federated Learning Benchmarks.](http://arxiv.org/abs/2307.02040) | 本文引入了两个影响VFL性能的关键因素：特征重要性和特征相关性，并提出了相关的评估指标和数据集划分方法。同时，通过引入真实的VFL数据集，填补了图像-图像VFL情景中的不足。研究对于未来的VFL研究提供了有价值的见解。 |
| [^100] | [GKD: Generalized Knowledge Distillation for Auto-regressive Sequence Models.](http://arxiv.org/abs/2306.13649) | 本文提出了广义知识蒸馏（GKD），通过从学生中采样输出序列来缓解分布不匹配，并在优化替代KL等离散度方面处理模型欠规范，达到了在摘要任务上最先进的性能。 |
| [^101] | [Creating Multi-Level Skill Hierarchies in Reinforcement Learning.](http://arxiv.org/abs/2306.09980) | 本文提出了一种基于代理人与环境交互的图形结构的答案，使用分层图划分产生具有多个抽象层次的技能层次结构。技能能将代理人移动到状态空间中互相连接紧密但相互连接较弱的区域，有效提高了强化学习的效率。 |
| [^102] | [Attention, Compilation, and Solver-based Symbolic Analysis are All You Need.](http://arxiv.org/abs/2306.06755) | 本文提出了一种基于大型语言模型的代码相互转换方法，利用注意力机制、编译和符号执行测试生成进行等价测试。在广泛的实验中，表明该方法在编译和运行时等价准确性等方面优于其他转换器和翻译工具。 |
| [^103] | [Causal Component Analysis.](http://arxiv.org/abs/2305.17225) | 本文介绍了一个中间问题：因果成分分析(CauCA)，它是独立成分分析(ICA)和因果表示学习(CRL)的泛化和特例，其目标是学习解混函数和因果机制，预设了因果图的知识。 |
| [^104] | [Diffusion-Based Adversarial Sample Generation for Improved Stealthiness and Controllability.](http://arxiv.org/abs/2305.16494) | 本文提出了一个名为Diff-PGD的新框架，用于生成接近原始数据分布、逼真的对抗样本，具有较好的隐蔽性和对抗强度可调性。 |
| [^105] | [Training Transitive and Commutative Multimodal Transformers with LoReTTa.](http://arxiv.org/abs/2305.14243) | LoReTTa是一个自监督框架，可以在具有不同模态的数据集中转换。通过合成数据集的方法，显著提高了下游任务的性能。 |
| [^106] | [A Scalable Neural Network for DSIC Affine Maximizer Auction Design.](http://arxiv.org/abs/2305.12162) | 该论文提出了一种可扩展的神经网络AMenuNet来构造AMAs参数和生成候选分配，解决了现有方法在占优策略激励兼容性和可扩展性方面的限制，其在协商一致的价值和社会残余价值方面优于强基线模型。 |
| [^107] | [Train a Real-world Local Path Planner in One Hour via Partially Decoupled Reinforcement Learning and Vectorized Diversity.](http://arxiv.org/abs/2305.04180) | 通过Color解决方案的Actor-Sharer-Learner（ASL）训练框架和面向移动机器人的模拟器Sparrow，使得在实际应用中训练局部路径规划器变得可行。 |
| [^108] | [CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds.](http://arxiv.org/abs/2305.00969) | CryCeleb是一个基于婴儿哭声的说话人认证数据集，包括超过6小时的手动分割哭声，可用于研究婴儿哭声分析。 |
| [^109] | [ID-MixGCL: Identity Mixup for Graph Contrastive Learning.](http://arxiv.org/abs/2304.10045) | 本文提出了一种基于身份混合的图形对比学习方法，旨在解决通过图形增强得到的不同但相似的图形结构和标签的不匹配问题，以实现更好的表示捕获。 |
| [^110] | [HomPINNs: homotopy physics-informed neural networks for solving the inverse problems of nonlinear differential equations with multiple solutions.](http://arxiv.org/abs/2304.02811) | 本文提出了一种新的框架——基于同伦的物理知识神经网络，来解决具有多个解的非线性微分方程的反问题。该框架使用神经网络逼近已知观测结果并符合DEs的约束条件，通过同伦连续方法解决反问题。实验证明该方法可伸缩且适应性强，为解决具有多个解的DEs提供了有效解决方案。 |
| [^111] | [Exploration by self-supervised exploitation.](http://arxiv.org/abs/2302.11563) | 该论文介绍了一种基于自我监督学习的内在动机算法类别SND，并将其应用于探索困难环境。实验结果表明这种方法是有效的。 |
| [^112] | [Online Loss Function Learning.](http://arxiv.org/abs/2301.13247) | 在线损失函数学习是一种新的元学习范例，旨在自动化为机器学习模型设计损失函数的重要任务。我们提出了一种新的损失函数学习技术，可以在每次更新基本模型参数后自适应地在线更新损失函数。实验结果表明，我们的方法在多个任务上稳定地优于现有技术。 |
| [^113] | [Lyapunov Function Consistent Adaptive Network Signal Control with Back Pressure and Reinforcement Learning.](http://arxiv.org/abs/2210.02612) | 这项研究提出了一种利用Lyapunov控制理论的统一框架，将基于流量和基于压力的交通信号控制方法相结合。通过引入背压方法和强化学习算法，实现对复杂交通网络的有效控制。 |
| [^114] | [The dynamics of belief: continuously monitoring and visualising complex systems.](http://arxiv.org/abs/2208.05764) | 本论文研究了在人类环境中人工智能的透明和可解释性问题，提出了一种关于数字系统的理论框架，利用模式和模式转换的概念对系统的结构进行抽象。通过将信念函数的评估视觉化为高维几何空间中的轨迹，解释了系统行为。 |
| [^115] | [A Dempster-Shafer approach to trustworthy AI with application to fetal brain MRI segmentation.](http://arxiv.org/abs/2204.02779) | 该论文提出了一种基于Dempster-Shafer方法的值得信赖的人工智能框架和实用系统，用于医学图像分割。通过检测和纠正深度学习模型的失败，增强了其可信性和安全性。 |

# 详细

[^1]: 从360度图像中估计3D场景几何：一项调查

    3D Scene Geometry Estimation from 360$^\circ$ Imagery: A Survey. (arXiv:2401.09252v1 [cs.CV])

    [http://arxiv.org/abs/2401.09252](http://arxiv.org/abs/2401.09252)

    本文调查了基于全景图像的单图、双图或多图的3D场景几何估计方法。主要包括球面相机模型、全景图像获取技术和表示格式、单眼布局和深度推断方法、立体匹配在球面领域的应用，以及多视角摄像机设置下的立体匹配方法。同时还提供了关于数据集和评估尺度的综合列表。

    

    本文对基于单个、两个或多个在全景光学下捕获的图像的先驱和最新的3D场景几何估计方法进行了全面的调查。我们首先回顾了球面相机模型的基本概念，并回顾了适用于全景（也称为360度、球形或全景）图像和视频的最常见的采集技术和表示格式。然后，我们调查了单眼布局和深度推断方法，突出了适用于球形数据的基于学习的解决方案的最新进展。接着，在球面领域对经典的立体匹配进行了修订，其中检测和描述稀疏和稠密特征的方法变得至关重要。然后，立体匹配概念被推广到多视角摄像机设置中，将它们归类为光场、多视角立体匹配和结构运动（或视觉同时定位和建图）。我们还编制了一个关于数据集和评估尺度的综合列表。

    This paper provides a comprehensive survey on pioneer and state-of-the-art 3D scene geometry estimation methodologies based on single, two, or multiple images captured under the omnidirectional optics. We first revisit the basic concepts of the spherical camera model, and review the most common acquisition technologies and representation formats suitable for omnidirectional (also called 360$^\circ$, spherical or panoramic) images and videos. We then survey monocular layout and depth inference approaches, highlighting the recent advances in learning-based solutions suited for spherical data. The classical stereo matching is then revised on the spherical domain, where methodologies for detecting and describing sparse and dense features become crucial. The stereo matching concepts are then extrapolated for multiple view camera setups, categorizing them among light fields, multi-view stereo, and structure from motion (or visual simultaneous localization and mapping). We also compile and di
    
[^2]: DiffClone: 使用扩散驱动的策略学习增强机器人行为克隆

    DiffClone: Enhanced Behaviour Cloning in Robotics with Diffusion-Driven Policy Learning. (arXiv:2401.09243v1 [cs.RO])

    [http://arxiv.org/abs/2401.09243](http://arxiv.org/abs/2401.09243)

    本文介绍了DiffClone，一种通过扩散驱动的策略学习增强行为克隆代理的离线算法。在真实的在线物理机器人上的实验表明，采用MOCO微调的ResNet50的效果最好。

    

    机器人学习任务在计算上非常密集且硬件特定。因此，通过使用多样化的离线演示数据集来训练机器人操作代理，来应对这些挑战的方式非常吸引人。Train-Offline-Test-Online（TOTO）基准提供了一个经过精心策划的开源离线训练数据集，主要由专家数据组成，并提供了常见离线强化学习和行为克隆代理的基准分数。在本文中，我们介绍了DiffClone，一种增强行为克隆代理的离线算法，采用基于扩散的策略学习，并在测试时在真实的在线物理机器人上评估了我们的方法的有效性。同时，这也是我们在NeurIPS 2023举办的Train-Offline-Test-Online（TOTO）基准挑战赛中的官方提交。我们尝试了预训练的视觉表示和代理策略。在实验中，我们发现MOCO微调的ResNet50相比其他微调方法表现最好。

    Robot learning tasks are extremely compute-intensive and hardware-specific. Thus the avenues of tackling these challenges, using a diverse dataset of offline demonstrations that can be used to train robot manipulation agents, is very appealing. The Train-Offline-Test-Online (TOTO) Benchmark provides a well-curated open-source dataset for offline training comprised mostly of expert data and also benchmark scores of the common offline-RL and behaviour cloning agents. In this paper, we introduce DiffClone, an offline algorithm of enhanced behaviour cloning agent with diffusion-based policy learning, and measured the efficacy of our method on real online physical robots at test time. This is also our official submission to the Train-Offline-Test-Online (TOTO) Benchmark Challenge organized at NeurIPS 2023. We experimented with both pre-trained visual representation and agent policies. In our experiments, we find that MOCO finetuned ResNet50 performs the best in comparison to other finetuned
    
[^3]: 基于区块链的异构信息系统数据管道安全模型

    A Blockchain-based Model for Securing Data Pipeline in a Heterogeneous Information System. (arXiv:2401.09240v1 [cs.CR])

    [http://arxiv.org/abs/2401.09240](http://arxiv.org/abs/2401.09240)

    这个研究提出了一种基于区块链的异构信息系统数据管道安全模型，旨在使用集成的多危险预警系统来解决数据管道中的安全和隐私问题。通过使用区块链的固有安全特性，该模型确保了数据的完整性、机密性和真实性，并通过实验结果证明其相比传统方法具有优势。

    

    在我们的数字世界中，访问个人和公共数据已成为一个关注的焦点，面临着挑战性的安全和隐私问题。现代信息系统具有异构性，并且具有固有的安全漏洞，易受数据拦截和数据修改的影响，这是由于连接端点之间的不安全通信数据管道。本研究文章提出了一种基于区块链的模型，用于使用集成多危险预警系统（MHEWS）作为案例研究来保护异构信息系统中的数据管道。所提出的模型利用区块链技术的固有安全特性来解决数据管道中出现的安全和隐私问题。该模型旨在以分散的方式确保数据完整性、机密性和真实性。该模型在混合环境中使用原型实施和仿真实验进行评估，结果显示它相比传统方法具有一些优势。

    In our digital world, access to personal and public data has become an item of concern, with challenging security and privacy aspects. Modern information systems are heterogeneous in nature and have an inherent security vulnerability, which is susceptible to data interception and data modification due to unsecured communication data pipelines between connected endpoints. This re-search article presents a blockchain-based model for securing data pipelines in a heterogeneous information system using an integrated multi-hazard early warning system (MHEWS) as a case study. The proposed model utilizes the inherent security features of blockchain technology to address the security and privacy concerns that arise in data pipelines. The model is designed to ensure data integrity, confidentiality, and authenticity in a decentralized manner. The model is evaluated in a hybrid environment using a prototype implementation and simulation experiments with outcomes that demonstrate advantages over tr
    
[^4]: DaFoEs：混合数据集以实现在微创机器人手术中视觉状态深度学习力量估计的泛化

    DaFoEs: Mixing Datasets towards the generalization of vision-state deep-learning Force Estimation in Minimally Invasive Robotic Surgery. (arXiv:2401.09239v1 [cs.CV])

    [http://arxiv.org/abs/2401.09239](http://arxiv.org/abs/2401.09239)

    本文介绍了一个新的视觉-触觉数据集（DaFoEs），用于训练深度神经网络模型以预测微创机器人手术中腹腔镜工具施加的力量。通过混合不同的数据集训练，以减少偏见，并提出了可变的编码器-解码器架构来处理单个输入或输入序列。

    

    在微创机器人手术（MIRS）中准确确定安全交互过程中的接触力仍然是一个开放的研究难题。受手术视频的术后定性分析的启发，使用跨模态数据驱动的深度神经网络模型已经成为预测无感知力量趋势的最新方法之一。然而，这些方法需要大量且可变的数据集，目前还不可用。在本文中，我们提出了一个新的视觉-触觉数据集（DaFoEs），其中包含可以用于深度神经模型训练的可变软环境。为了减少单一数据集的偏见，我们提供了一个流程将不同的视觉和状态数据输入泛化到混合数据集训练中，使用先前验证过的具有不同设置的数据集。最后，我们提出了一个可变的编码器-解码器架构，以预测腹腔镜工具施加的力量，可以使用单个输入或输入序列。对于输入序列，我们使用了一个循环解码器。

    Precisely determining the contact force during safe interaction in Minimally Invasive Robotic Surgery (MIRS) is still an open research challenge. Inspired by post-operative qualitative analysis from surgical videos, the use of cross-modality data driven deep neural network models has been one of the newest approaches to predict sensorless force trends. However, these methods required for large and variable datasets which are not currently available. In this paper, we present a new vision-haptic dataset (DaFoEs) with variable soft environments for the training of deep neural models. In order to reduce the bias from a single dataset, we present a pipeline to generalize different vision and state data inputs for mixed dataset training, using a previously validated dataset with different setup. Finally, we present a variable encoder-decoder architecture to predict the forces done by the laparoscopic tool using single input or sequence of inputs. For input sequence, we use a recurrent decod
    
[^5]: 对具有点状激活的等变网络的一个特征定理

    A Characterization Theorem for Equivariant Networks with Point-wise Activations. (arXiv:2401.09235v1 [cs.LG])

    [http://arxiv.org/abs/2401.09235](http://arxiv.org/abs/2401.09235)

    本论文提出了一个定理，描述了所有可能的有限维表示、坐标选择和点状激活函数的组合，以获得一个完全等变的层，从而推广和加强了现有的特征定理。具有实际相关性的重要情况作为推论进行了讨论。

    

    等变神经网络在对称领域表现出了更好的性能、表达能力和样本复杂度。但对于某些特定的对称性、表示和坐标选择，最常见的点状激活函数（如ReLU）并不具备等变性，因此不能用于设计等变神经网络。本文介绍的定理描述了所有可能的有限维表示、坐标选择和点状激活函数的组合，以获得一个完全等变的层，从而推广和加强了现有的特征定理。我们讨论了具有实际相关性的重要情况作为推论。事实上，我们证明了旋转等变网络只能是不变的，就像对于任何对连通紧致群等变的网络一样。然后，我们讨论了将我们的结果应用于重要的完全等变网络实例时的影响。

    Equivariant neural networks have shown improved performance, expressiveness and sample complexity on symmetrical domains. But for some specific symmetries, representations, and choice of coordinates, the most common point-wise activations, such as ReLU, are not equivariant, hence they cannot be employed in the design of equivariant neural networks. The theorem we present in this paper describes all possible combinations of finite-dimensional representations, choice of coordinates and point-wise activations to obtain an exactly equivariant layer, generalizing and strengthening existing characterizations. Notable cases of practical relevance are discussed as corollaries. Indeed, we prove that rotation-equivariant networks can only be invariant, as it happens for any network which is equivariant with respect to connected compact groups. Then, we discuss implications of our findings when applied to important instances of exactly equivariant networks. First, we completely characterize permu
    
[^6]: 为渐进式训练语言模型准备课程的方法

    Preparing Lessons for Progressive Training on Language Models. (arXiv:2401.09192v1 [cs.LG])

    [http://arxiv.org/abs/2401.09192](http://arxiv.org/abs/2401.09192)

    提出了一种名为Apollo的方法，通过在低层训练期间学习高层功能，为渐进式训练语言模型设计了课程，实现了最先进的加速比率。

    

    Transformers在人工智能领域的迅速发展带来了资源消耗和温室气体排放的增加，这是由于模型规模的增长。先前的研究表明使用预训练的小模型可以提高训练效率，但这种方法对于新的模型结构可能不适用。另一方面，从头开始训练可能很慢，并且渐进堆叠层往往无法实现显著的加速。为了解决这些挑战，我们提出了一种名为Apollo的新方法，它通过在低层训练期间学习高层功能来准备膨胀操作的课程。我们的方法涉及低值优先采样(LVPS)来训练不同深度，并引入权重共享以促进高效扩展。我们还介绍了一种插值方法来实现稳定的模型深度扩展。实验证明，Apollo实现了最先进的加速比率，甚至……

    The rapid progress of Transformers in artificial intelligence has come at the cost of increased resource consumption and greenhouse gas emissions due to growing model sizes. Prior work suggests using pretrained small models to improve training efficiency, but this approach may not be suitable for new model structures. On the other hand, training from scratch can be slow, and progressively stacking layers often fails to achieve significant acceleration. To address these challenges, we propose a novel method called Apollo, which prep\textbf{a}res lessons for ex\textbf{p}anding \textbf{o}perations by \textbf{l}earning high-\textbf{l}ayer functi\textbf{o}nality during training of low layers. Our approach involves low-value-prioritized sampling (LVPS) to train different depths and weight sharing to facilitate efficient expansion. We also introduce an interpolation method for stable model depth extension. Experiments demonstrate that Apollo achieves state-of-the-art acceleration ratios, even
    
[^7]: 什么是“好”的社交行为者？以尊重为视角评估与语言代理的交互

    What makes for a 'good' social actor? Using respect as a lens to evaluate interactions with language agents. (arXiv:2401.09082v1 [cs.CL])

    [http://arxiv.org/abs/2401.09082](http://arxiv.org/abs/2401.09082)

    本文研究以尊重为视角评估与语言代理的交互，提出了一种更加关注关系和情境因素的伦理方法，旨在帮助LLM技术表现得“好”

    

    随着基于大型语言模型（LLM）的对话代理越来越受欢迎，如何确保它们的行为道德和适当性已经引起了紧急关注。从“HHH”标准的角度来看，这主要体现在让输出更有帮助和诚实，并避免有害（有偏见、有毒或不准确）的陈述。虽然这种语义焦点对于将LLM代理视为纯粹的信息媒介是有用的，但它未能考虑到在不同社交情境中，同样的话语可能会显得更或者更少冒犯或不得体的实际因素。我们提出了一种更加关注关系和情境因素的伦理方法，探讨作为社交行为者的系统如何在交互中以尊重的方式对待个体。我们的工作预见了在情境交互层面上一系列尚未被探索的风险，并提供了实用建议，以帮助LLM技术表现得“好”

    With the growing popularity of dialogue agents based on large language models (LLMs), urgent attention has been drawn to finding ways to ensure their behaviour is ethical and appropriate. These are largely interpreted in terms of the 'HHH' criteria: making outputs more helpful and honest, and avoiding harmful (biased, toxic, or inaccurate) statements. Whilst this semantic focus is useful from the perspective of viewing LLM agents as mere mediums for information, it fails to account for pragmatic factors that can make the same utterance seem more or less offensive or tactless in different social situations. We propose an approach to ethics that is more centred on relational and situational factors, exploring what it means for a system, as a social actor, to treat an individual respectfully in a (series of) interaction(s). Our work anticipates a set of largely unexplored risks at the level of situated interaction, and offers practical suggestions to help LLM technologies behave as 'good'
    
[^8]: 披着绵羊皮的GPT：定制化GPTs的风险

    GPT in Sheep's Clothing: The Risk of Customized GPTs. (arXiv:2401.09075v1 [cs.CR])

    [http://arxiv.org/abs/2401.09075](http://arxiv.org/abs/2401.09075)

    GPTs的定制化使用可能存在隐私和安全风险。

    

    2023年11月，OpenAI推出了一项新服务，允许用户通过使用特定的指令和知识来指导模型的行为，创建定制版本的ChatGPT（GPTs）。我们旨在提醒人们意识到GPTs可能被恶意使用，给用户的隐私和安全带来风险。

    In November 2023, OpenAI introduced a new service allowing users to create custom versions of ChatGPT (GPTs) by using specific instructions and knowledge to guide the model's behavior. We aim to raise awareness of the fact that GPTs can be used maliciously, posing privacy and security risks to their users.
    
[^9]: 大型语言模型中的代码模拟挑战

    Code Simulation Challenges for Large Language Models. (arXiv:2401.09074v1 [cs.LG])

    [http://arxiv.org/abs/2401.09074](http://arxiv.org/abs/2401.09074)

    大型语言模型在模拟计算机代码和算法执行方面遇到挑战，性能随着代码长度的增加而迅速下降。在处理短程序或标准过程时，它们能以低错误率按顺序执行指令，但对于复杂的程序，特别是包含关键路径和冗余指令的程序，模拟效果较差。我们提出了一种逐行模拟代码执行的方法来解决这个问题。

    

    我们调查了大型语言模型（LLMs）在模拟计算机代码和算法执行方面的能力。我们首先研究了直线程序，并展示了当前LLMs在处理这样简单的程序时表现出的性能较差——性能随着代码长度的增加而迅速下降。接着，我们研究了LLMs在模拟包含关键路径和冗余指令的程序方面的能力。我们还通过排序算法和嵌套循环超越了直线程序的模拟，并展示了程序的计算复杂性直接影响LLMs模拟其执行的能力。我们观察到LLMs只有在处理短程序或标准过程时才能以低错误率按顺序执行指令。LLMs的代码模拟与它们的模式识别和记忆能力存在矛盾：在记忆对任务有害的情况下，我们提出了一种新的提示方法，逐行模拟代码的执行。

    We investigate the extent to which Large Language Models (LLMs) can simulate the execution of computer code and algorithms. We begin by looking straight line programs, and show that current LLMs demonstrate poor performance even with such simple programs -- performance rapidly degrades with the length of code. We then investigate the ability of LLMs to simulate programs that contain critical paths and redundant instructions. We also go beyond straight line program simulation with sorting algorithms and nested loops, and we show the computational complexity of a routine directly affects the ability of an LLM to simulate its execution. We observe that LLMs execute instructions sequentially and with a low error margin only for short programs or standard procedures. LLMs' code simulation is in tension with their pattern recognition and memorisation capabilities: on tasks where memorisation is detrimental, we propose a novel prompting method to simulate code execution line by line. Empirica
    
[^10]: 固定预算差分隐私最佳臂识别

    Fixed-Budget Differentially Private Best Arm Identification. (arXiv:2401.09073v1 [cs.LG])

    [http://arxiv.org/abs/2401.09073](http://arxiv.org/abs/2401.09073)

    本论文研究了差分隐私约束下固定预算条件下的最佳臂识别问题，提出了满足差分隐私约束的策略DP-BAI，并得到了错误概率的上界和最小-最大下界的指数衰减关系。

    

    我们在差分隐私约束下研究了线性赌博机中固定预算条件下的最佳臂识别问题，其中臂的奖励在单位区间上。给定一个有限的预算$T$和隐私参数$\varepsilon>0$，目标是在$T$个采样轮后最小化寻找平均值最大的臂的错误概率，同时满足决策者策略满足特定的$\varepsilon$-差分隐私($\varepsilon$-DP)约束条件。我们通过提出“最大绝对行列式”原则构建满足$\varepsilon$-DP约束的策略(称为DP-BAI)，并给出其错误概率的上界。此外，我们得到了错误概率的最小-最大下界，并证明这两个界在$T$上按指数衰减，界中的指数与(a)臂的次优间隙，(b)$\varepsilon$和(c)关联。

    We study best arm identification (BAI) in linear bandits in the fixed-budget regime under differential privacy constraints, when the arm rewards are supported on the unit interval. Given a finite budget $T$ and a privacy parameter $\varepsilon>0$, the goal is to minimise the error probability in finding the arm with the largest mean after $T$ sampling rounds, subject to the constraint that the policy of the decision maker satisfies a certain {\em $\varepsilon$-differential privacy} ($\varepsilon$-DP) constraint. We construct a policy satisfying the $\varepsilon$-DP constraint (called {\sc DP-BAI}) by proposing the principle of {\em maximum absolute determinants}, and derive an upper bound on its error probability. Furthermore, we derive a minimax lower bound on the error probability, and demonstrate that the lower and the upper bounds decay exponentially in $T$, with exponents in the two bounds matching order-wise in (a) the sub-optimality gaps of the arms, (b) $\varepsilon$, and (c) t
    
[^11]: 用空间自适应滤波重新思考谱图神经网络

    Rethinking Spectral Graph Neural Networks with Spatially Adaptive Filtering. (arXiv:2401.09071v1 [cs.LG])

    [http://arxiv.org/abs/2401.09071](http://arxiv.org/abs/2401.09071)

    本文重新思考了谱图神经网络，并揭示了谱滤波和空间聚合之间的联系。该研究发现，谱滤波在隐含地将原始图转换成适应性新图，并明确计算用于空间聚合的新图。适应性新图展现出非局部性，并能够反映节点之间的标签一致性。

    

    尽管谱图神经网络（GNN）在理论上在谱域中有很好的基础，但它们实际上依赖于多项式逼近，意味着它们与空间域有着深刻的联系。由于以前的研究很少从空间角度研究谱图GNN，因此它们在空间域的可解释性仍然难以捉摸，例如，谱图GNN在空间域中实际上编码了哪些信息？为了回答这个问题，本文在谱滤波和空间聚合之间建立了一个理论上的联系，揭示了谱滤波隐含地将原始图转换成适应性新图的内在交互作用，并明确地计算用于空间聚合的适应性新图。理论和经验研究表明，适应性新图不仅表现出非局部性，还能够容纳有符号的边权重以反映节点之间的标签一致性。因此，这些发现突显了谱图GNN在空间中的可解释性角色。

    Whilst spectral Graph Neural Networks (GNNs) are theoretically well-founded in the spectral domain, their practical reliance on polynomial approximation implies a profound linkage to the spatial domain. As previous studies rarely examine spectral GNNs from the spatial perspective, their spatial-domain interpretability remains elusive, e.g., what information is essentially encoded by spectral GNNs in the spatial domain? In this paper, to answer this question, we establish a theoretical connection between spectral filtering and spatial aggregation, unveiling an intrinsic interaction that spectral filtering implicitly leads the original graph to an adapted new graph, explicitly computed for spatial aggregation. Both theoretical and empirical investigations reveal that the adapted new graph not only exhibits non-locality but also accommodates signed edge weights to reflect label consistency between nodes. These findings thus highlight the interpretable role of spectral GNNs in the spatial 
    
[^12]: 知识金字塔：一种用于推广知识增强和推理的新型分层推理结构

    Knowledge Pyramid: A Novel Hierarchical Reasoning Structure for Generalized Knowledge Augmentation and Inference. (arXiv:2401.09070v1 [cs.AI])

    [http://arxiv.org/abs/2401.09070](http://arxiv.org/abs/2401.09070)

    这篇论文提出了一种新型的推理方法，通过使用新颖的知识增强策略，从低层知识中提取高层金字塔状知识，并将其应用于多层分层知识图谱中的推理，从而改进了推理的泛化能力。

    

    知识图谱（KG）的推理被认为是分析语义网络的有效手段，并在信息检索、推荐、决策和人机交互等领域具有巨大的用途。它广泛应用于推荐、决策、问答、搜索等领域。然而，以往的研究主要使用KG中的低层知识进行推理，这可能导致推理的泛化不足和鲁棒性差。为此，本文提出了一种新的推理方法，采用了一种新颖的知识增强策略，以提高KG的泛化能力。该框架从低层知识中提取高层金字塔状知识，并将其应用于在多层层次化KG中的推理，本文称之为知识金字塔。我们使用提出的方法对一些医疗数据集进行了测试，实验结果表明，提出的知识金字塔改进了知识推理能力。

    Knowledge graph (KG) based reasoning has been regarded as an effective means for the analysis of semantic networks and is of great usefulness in areas of information retrieval, recommendation, decision-making, and man-machine interaction. It is widely used in recommendation, decision-making, question-answering, search, and other fields. However, previous studies mainly used low-level knowledge in the KG for reasoning, which may result in insufficient generalization and poor robustness of reasoning. To this end, this paper proposes a new inference approach using a novel knowledge augmentation strategy to improve the generalization capability of KG. This framework extracts high-level pyramidal knowledge from low-level knowledge and applies it to reasoning in a multi-level hierarchical KG, called knowledge pyramid in this paper. We tested some medical data sets using the proposed approach, and the experimental results show that the proposed knowledge pyramid has improved the knowledge inf
    
[^13]: DTMM：利用修剪在极弱的物联网设备上部署TinyML模型

    DTMM: Deploying TinyML Models on Extremely Weak IoT Devices with Pruning. (arXiv:2401.09068v1 [cs.LG])

    [http://arxiv.org/abs/2401.09068](http://arxiv.org/abs/2401.09068)

    DTMM是一个库，旨在在弱物联网设备上高效部署和执行机器学习模型。之前的解决方案无法同时实现在不损害准确性的情况下深度压缩模型和高效执行的目标，而DTMM通过修剪单元选择解决了这个问题。

    

    DTMM是一个为弱物联网设备（如微控制器单元）上的机器学习模型的高效部署和执行而设计的库。设计DTMM的动机来自于新兴领域的小型机器学习（TinyML），它探索将机器学习扩展到许多低端物联网设备以实现普遍智能。由于嵌入式设备的能力较弱，需要在部署之前通过修剪足够的权重来压缩模型。尽管修剪已在许多计算平台上进行了广泛研究，但修剪方法在MCUs上面临两个关键问题的加剧：需要在不显著损害准确性的情况下深度压缩模型，并且修剪后的模型在执行效率上应具备高效性。目前的解决方案只能实现其中一个目标，而不能同时实现两者。在本文中，我们发现修剪后的模型在MCUs上具有高效部署和执行的巨大潜力。因此，我们提出了具有修剪单元选择的DTMM。

    DTMM is a library designed for efficient deployment and execution of machine learning models on weak IoT devices such as microcontroller units (MCUs). The motivation for designing DTMM comes from the emerging field of tiny machine learning (TinyML), which explores extending the reach of machine learning to many low-end IoT devices to achieve ubiquitous intelligence. Due to the weak capability of embedded devices, it is necessary to compress models by pruning enough weights before deploying. Although pruning has been studied extensively on many computing platforms, two key issues with pruning methods are exacerbated on MCUs: models need to be deeply compressed without significantly compromising accuracy, and they should perform efficiently after pruning. Current solutions only achieve one of these objectives, but not both. In this paper, we find that pruned models have great potential for efficient deployment and execution on MCUs. Therefore, we propose DTMM with pruning unit selection,
    
[^14]: 通过HSIC-Bottleneck正交化和平均角嵌入实现持续学习目标

    Towards Continual Learning Desiderata via HSIC-Bottleneck Orthogonalization and Equiangular Embedding. (arXiv:2401.09067v1 [cs.LG])

    [http://arxiv.org/abs/2401.09067](http://arxiv.org/abs/2401.09067)

    本文提出了一种方法，通过HSIC-Bottleneck正交化和平均角嵌入，实现了对持续学习中遗忘问题的解决，该方法在不使用先前任务的训练数据且模型大小相对恒定的条件下，通过限制逐层参数覆盖和决策边界畸变来避免遗忘。

    

    在顺序任务训练中，深度神经网络容易遭受灾难性遗忘。各种持续学习（CL）方法通常依赖于样本缓冲区和/或网络扩展，以平衡模型的稳定性和可塑性，但这会损害其实际价值，因为涉及到隐私和内存问题。相反，本文考虑了一个严格但现实的设置，即以前任务的训练数据不可用，且在顺序训练期间模型的大小保持相对恒定。为了实现这样的目标，我们提出了一种概念简单但有效的方法，将遗忘归因于逐层参数覆盖和由此产生的决策边界畸变。这通过两个关键组件之间的协同作用实现：HSIC-Bottleneck正交化（HBO）在正交空间中实现非覆盖参数的更新，通过Hilbert-Schmidt独立性准则进行中介；而平均角嵌入（EAE）则增强了决策边界的适应能力。

    Deep neural networks are susceptible to catastrophic forgetting when trained on sequential tasks. Various continual learning (CL) methods often rely on exemplar buffers or/and network expansion for balancing model stability and plasticity, which, however, compromises their practical value due to privacy and memory concerns. Instead, this paper considers a strict yet realistic setting, where the training data from previous tasks is unavailable and the model size remains relatively constant during sequential training. To achieve such desiderata, we propose a conceptually simple yet effective method that attributes forgetting to layer-wise parameter overwriting and the resulting decision boundary distortion. This is achieved by the synergy between two key components: HSIC-Bottleneck Orthogonalization (HBO) implements non-overwritten parameter updates mediated by Hilbert-Schmidt independence criterion in an orthogonal space and EquiAngular Embedding (EAE) enhances decision boundary adaptat
    
[^15]: LLM对于关系推理的实现程度有多远？

    LLMs for Relational Reasoning: How Far are We?. (arXiv:2401.09042v1 [cs.AI])

    [http://arxiv.org/abs/2401.09042](http://arxiv.org/abs/2401.09042)

    本论文对多种最先进的LLM的推理能力进行了全面评估，发现它们在归纳逻辑编程基准测试上的表现欠佳，这挑战了它们在处理常识规划的顺序决策问题方面的能力。

    

    大型语言模型（LLM）通过在广泛的下游任务中取得了最先进的性能，从而革新了许多领域（例如自然语言处理、软件工程等）。为了实现强大且通用的人工智能，人们对LLM的推理能力产生了浓厚的兴趣。然而，先前研究采用的文本和数值推理基准测试相对浅显简单，仅仅通过在这些基准上取得积极结果难以得出LLM具有强大推理能力的结论。最近的研究努力通过在强化学习基准测试上评估LLM的性能，证明LLM在解决需要常识规划的顺序决策问题方面表现不佳。在本研究中，我们基于归纳逻辑编程（ILP）基准测试对几种最先进的LLM的推理能力进行了深入评估，这一基准测试被广泛认可为对推理能力的代表性评估。

    Large language models (LLMs) have revolutionized many areas (e.g. natural language processing, software engineering, etc.) by achieving state-of-the-art performance on extensive downstream tasks. Aiming to achieve robust and general artificial intelligence, there has been a surge of interest in investigating the reasoning ability of the LLMs. Whereas the textual and numerical reasoning benchmarks adopted by previous works are rather shallow and simple, it is hard to conclude that the LLMs possess strong reasoning ability by merely achieving positive results on these benchmarks. Recent efforts have demonstrated that the LLMs are poor at solving sequential decision-making problems that require common-sense planning by evaluating their performance on the reinforcement learning benchmarks. In this work, we conduct an in-depth assessment of several state-of-the-art LLMs' reasoning ability based on the inductive logic programming (ILP) benchmark, which is broadly recognized as a representati
    
[^16]: UOEP: 用户导向的探索策略以增强推荐系统中的长期用户体验

    UOEP: User-Oriented Exploration Policy for Enhancing Long-Term User Experiences in Recommender Systems. (arXiv:2401.09034v1 [cs.IR])

    [http://arxiv.org/abs/2401.09034](http://arxiv.org/abs/2401.09034)

    UOEP是一种用户导向的探索策略，针对推荐系统中不同活跃水平的用户群体实现细粒度探索，以增强用户的长期体验。

    

    强化学习（RL）已经在推荐系统中得到广泛应用，有效地探索用户的兴趣，以提升用户的长期体验。然而，现代推荐系统中存在着数千万个项目之间的不同用户行为模式，这增加了探索的难度。例如，不同活跃水平的用户行为需要不同强度的探索，而之前的研究往往忽视了这一方面，对所有用户应用统一的探索策略，最终损害了用户的长期体验。为了解决这些挑战，我们提出了用户导向的探索策略（UOEP），一种在用户群体中实现细粒度探索的新方法。我们首先构建了一个分布式评论家，它允许在不同的累积奖励反馈的分位数水平下进行策略优化，表示具有不同活动水平的用户群体。在这个评论家的指导下，我们设计了一组不同的演员。

    Reinforcement learning (RL) has gained traction for enhancing user long-term experiences in recommender systems by effectively exploring users' interests. However, modern recommender systems exhibit distinct user behavioral patterns among tens of millions of items, which increases the difficulty of exploration. For example, user behaviors with different activity levels require varying intensity of exploration, while previous studies often overlook this aspect and apply a uniform exploration strategy to all users, which ultimately hurts user experiences in the long run. To address these challenges, we propose User-Oriented Exploration Policy (UOEP), a novel approach facilitating fine-grained exploration among user groups. We first construct a distributional critic which allows policy optimization under varying quantile levels of cumulative reward feedbacks from users, representing user groups with varying activity levels. Guided by this critic, we devise a population of distinct actors 
    
[^17]: MRI脑肿瘤分级的跨模态引导辅助多模态学习与双重注意机制

    Cross-modality Guidance-aided Multi-modal Learning with Dual Attention for MRI Brain Tumor Grading. (arXiv:2401.09029v1 [cs.CV])

    [http://arxiv.org/abs/2401.09029](http://arxiv.org/abs/2401.09029)

    本文提出了一种用于MRI脑肿瘤分级的跨模态引导辅助多模态学习与双重注意机制，以提高脑肿瘤诊断的准确性和性能。

    

    脑肿瘤是全球最致命的癌症之一，在儿童和老年人中非常常见。准确识别早期肿瘤的类型和级别在选择精确治疗方案中起着重要作用。不同序列的磁共振成像（MRI）协议为临床医生提供了重要的矛盾信息来识别肿瘤区域。然而，由于数据量大且脑肿瘤类型多样，手动评估耗时且容易出错。因此，需要开发MRI自动化脑肿瘤诊断方法。我们观察到，单模态模型的预测能力有限，其性能在不同模态之间差异很大，常用的模态融合方法会引入潜在噪声，导致性能严重下降。为了克服这些挑战，我们提出了一种新颖的跨模态引导辅助多模态学习与双重注意机制。

    Brain tumor represents one of the most fatal cancers around the world, and is very common in children and the elderly. Accurate identification of the type and grade of tumor in the early stages plays an important role in choosing a precise treatment plan. The Magnetic Resonance Imaging (MRI) protocols of different sequences provide clinicians with important contradictory information to identify tumor regions. However, manual assessment is time-consuming and error-prone due to big amount of data and the diversity of brain tumor types. Hence, there is an unmet need for MRI automated brain tumor diagnosis. We observe that the predictive capability of uni-modality models is limited and their performance varies widely across modalities, and the commonly used modality fusion methods would introduce potential noise, which results in significant performance degradation. To overcome these challenges, we propose a novel cross-modality guidance-aided multi-modal learning with dual attention for a
    
[^18]: 通过分段任意模型（SAM）在光学遥感图像和地图数据之间进行变化检测

    Change Detection Between Optical Remote Sensing Imagery and Map Data via Segment Anything Model (SAM). (arXiv:2401.09019v1 [eess.IV])

    [http://arxiv.org/abs/2401.09019](http://arxiv.org/abs/2401.09019)

    本研究利用分段任意模型（SAM）实现了光学遥感图像和地图数据之间的无监督多模态变化检测。通过SAM的零样本迁移能力，可以获得高质量的光学图像分割地图，并且提出了两种策略来指导分割过程，从而在土地覆盖变化和新土地覆盖对象识别方面具有良好性能。

    

    无监督多模态变化检测对于时间敏感任务和全面的多时相地球监测至关重要。本研究探索了光学高分辨率图像和OpenStreetMap（OSM）数据之间的无监督多模态变化检测。具体而言，我们提出利用视觉基础模型-分段任意模型（SAM）来解决我们的任务。通过利用SAM的出色的零样本迁移能力，可以获得光学图像的高质量分割地图。因此，我们可以直接在所谓的分割域比较这两种异构数据形式。然后，我们引入了两种策略来指导SAM的分割过程：'无提示'和'框/蒙版提示'方法。这两种策略分别用于检测一般情况下的土地覆盖变化和识别现有背景中的新土地覆盖对象。三个数据集上的实验结果表明，所提出的方法在变化检测的准确性方面具有很好的性能。

    Unsupervised multimodal change detection is pivotal for time-sensitive tasks and comprehensive multi-temporal Earth monitoring. In this study, we explore unsupervised multimodal change detection between two key remote sensing data sources: optical high-resolution imagery and OpenStreetMap (OSM) data. Specifically, we propose to utilize the vision foundation model Segmentation Anything Model (SAM), for addressing our task. Leveraging SAM's exceptional zero-shot transfer capability, high-quality segmentation maps of optical images can be obtained. Thus, we can directly compare these two heterogeneous data forms in the so-called segmentation domain. We then introduce two strategies for guiding SAM's segmentation process: the 'no-prompt' and 'box/mask prompt' methods. The two strategies are designed to detect land-cover changes in general scenarios and to identify new land-cover objects within existing backgrounds, respectively. Experimental results on three datasets indicate that the prop
    
[^19]: 机器学习模型对人工智能系统的归纳能力不足，缺乏良好的解释能力

    Inductive Models for Artificial Intelligence Systems are Insufficient without Good Explanations. (arXiv:2401.09011v1 [cs.LG])

    [http://arxiv.org/abs/2401.09011](http://arxiv.org/abs/2401.09011)

    本文讨论了机器学习模型的局限性，特别是深度神经网络的透明度和解释能力不足，提出AI系统不仅需要预测能力，还需要提供良好的解释能力和洞察力。

    

    本文讨论了机器学习（ML），特别是深度人工神经网络（ANNs）的局限性，它们在逼近复杂函数方面有效，但常常缺乏透明度和解释能力。本文强调了归纳问题：即过去的观察不一定能预测未来事件，这是ML模型在遭遇新的、未见过的数据时面临的挑战。本文主张重要的不仅是做出预测，还要提供良好的解释，而当前模型往往未能做到这一点。它建议为了AI的进步，我们必须寻求能够提供洞察力和解释能力的模型，而不仅仅是预测能力。

    This paper discusses the limitations of machine learning (ML), particularly deep artificial neural networks (ANNs), which are effective at approximating complex functions but often lack transparency and explanatory power. It highlights the `problem of induction' : the philosophical issue that past observations may not necessarily predict future events, a challenge that ML models face when encountering new, unseen data. The paper argues for the importance of not just making predictions but also providing good explanations, a feature that current models often fail to deliver. It suggests that for AI to progress, we must seek models that offer insights and explanations, not just predictions.
    
[^20]: 混合DiffStride和谱池化的卷积神经网络

    Hybrid of DiffStride and Spectral Pooling in Convolutional Neural Networks. (arXiv:2401.09008v1 [cs.CV])

    [http://arxiv.org/abs/2401.09008](http://arxiv.org/abs/2401.09008)

    本研究提出了一种混合DiffStride和谱池化的卷积神经网络模型，通过使用反向传播执行的下采样可学习步幅技术和谱池化技术，以保留图像中的重要信息。

    

    步幅决定了滤波器在输入上移动时相邻位置之间的距离。固定的步幅导致无法捕捉到图像中重要的信息，从而无法对重要信息进行分类。因此，在先前的研究中，应用了DiffStride方法，即具有学习自己步幅值的步幅卷积方法。严格量化和对保留信息的约束下界在Max Pooling下采样方法中引起问题。谱池化通过在频域截断表示来降低对保留信息的约束下界。本研究提出了一种使用反向传播执行的下采样可学习步幅技术与谱池化技术相结合的CNN模型。DiffStride和谱池化技术有望保持图像中包含的大部分信息。在本研究中，我们比较了混合方法，即将DiffStride和谱池化技术结合使用。

    Stride determines the distance between adjacent filter positions as the filter moves across the input. A fixed stride causes important information contained in the image can not be captured, so that important information is not classified. Therefore, in previous research, the DiffStride Method was applied, namely the Strided Convolution Method with which it can learn its own stride value. Severe Quantization and a constraining lower bound on preserved information are arises with Max Pooling Downsampling Method. Spectral Pooling reduce the constraint lower bound on preserved information by cutting off the representation in the frequency domain. In this research a CNN Model is proposed with the Downsampling Learnable Stride Technique performed by Backpropagation combined with the Spectral Pooling Technique. Diffstride and Spectral Pooling techniques are expected to maintain most of the information contained in the image. In this study, we compare the Hybrid Method, which is a combined im
    
[^21]: 通过迭代组合问题来增强数学问题求解

    Augmenting Math Word Problems via Iterative Question Composing. (arXiv:2401.09003v1 [cs.CL])

    [http://arxiv.org/abs/2401.09003](http://arxiv.org/abs/2401.09003)

    本研究通过引入MMIQC数据集和迭代组合问题(IQC)的新颖增强方法，成功提高了大型语言模型的数学推理能力，在竞赛级数学问题上取得了优于先前最佳结果的准确率。

    

    尽管在改善大型语言模型(LLMs)的数学推理能力方面取得了一定进展，但在不使用外部工具的情况下解决竞赛级数学问题仍然对开源LLMs具有挑战性。在这项工作中，我们介绍了MMIQC数据集，这是一个混合处理的网络数据和合成问题-响应对的混合数据集，以提供基础模型更好的数学推理能力。通过在MMIQC上对Mistral-7B(arXiv:2310.06825)进行微调获得的模型Mistral-7B-MMIQC，在MATH(arXiv:2103.03874)上达到了36.0%的准确率，比之前(model size $\sim$7B)的最佳结果高出5.8%。我们的实验还表明，改进的一个重要部分归功于我们的新颖增强方法IQC(迭代组合问题)，其中我们迭代地要求LLM从给定的种子问题中组合新问题，并从另一个LLM中进行拒绝抽样。MMIQC现已在https://huggingface.co/datasets/Vivacem/MMIQC上发布。

    Despite recent progress in improving the mathematical reasoning ability of large language models(LLMs), solving competition-level math problems without the use of external tools remains challenging for open-source LLMs. In this work, we introduce the MMIQC dataset, a mixture of processed web data and synthetic question-response pairs, to equip base models with better mathematical reasoning skills. Mistral-7B-MMIQC, the model obtained by fine-tuning Mistral-7B(arXiv:2310.06825) on MMIQC, achieves 36.0\% accuracy on MATH(arXiv:2103.03874), 5.8\% higher than the previous (model size $\sim$7B) SOTA. Our experiments also show that a large part of the improvement attributes to our novel augmentation method IQC(Iterative Question Composing), where we iteratively ask an LLM to compose new questions from the given seed problems and do rejection sampling from another LLM. MMIQC has now been released on https://huggingface.co/datasets/Vivacem/MMIQC.
    
[^22]: 连续时间连续空间的稳态强化学习（CTCS-HRRL）：朝向生物自主代理

    Continuous Time Continuous Space Homeostatic Reinforcement Learning (CTCS-HRRL) : Towards Biological Self-Autonomous Agent. (arXiv:2401.08999v1 [cs.AI])

    [http://arxiv.org/abs/2401.08999](http://arxiv.org/abs/2401.08999)

    本文提出了连续时间连续空间的稳态强化学习框架CTCS-HRRL，并通过模拟实验证明了该模型的有效性和与代理能力相关的证据。

    

    稳态是生物维持内部平衡的生理过程。先前的研究表明，稳态是一种学习行为。最近引入的稳态调节的强化学习（HRRL）框架试图通过将驱动减少理论和强化学习相结合来解释这种学习的稳态行为。这种链接已经在离散时间空间上得到证明，但是在连续时间空间上尚未得到证明。在这项工作中，我们将HRRL框架推广到连续时间空间环境，并验证连续时间连续空间HRRL（CTCS-HRRL）框架。我们通过设计一个模型来模拟真实生物代理中的稳态机制来实现这一目标。该模型使用Hamilton-Jacobian Bellman方程以及基于神经网络和强化学习的函数近似。通过基于模拟的实验，我们展示了该模型的有效性，并揭示了与代理能力有关的证据。

    Homeostasis is a biological process by which living beings maintain their internal balance. Previous research suggests that homeostasis is a learned behaviour. Recently introduced Homeostatic Regulated Reinforcement Learning (HRRL) framework attempts to explain this learned homeostatic behavior by linking Drive Reduction Theory and Reinforcement Learning. This linkage has been proven in the discrete time-space, but not in the continuous time-space. In this work, we advance the HRRL framework to a continuous time-space environment and validate the CTCS-HRRL (Continuous Time Continuous Space HRRL) framework. We achieve this by designing a model that mimics the homeostatic mechanisms in a real-world biological agent. This model uses the Hamilton-Jacobian Bellman Equation, and function approximation based on neural networks and Reinforcement Learning. Through a simulation-based experiment we demonstrate the efficacy of this model and uncover the evidence linked to the agent's ability to dy
    
[^23]: MicroNAS: 零样本神经架构搜索用于MCUs

    MicroNAS: Zero-Shot Neural Architecture Search for MCUs. (arXiv:2401.08996v1 [cs.LG])

    [http://arxiv.org/abs/2401.08996](http://arxiv.org/abs/2401.08996)

    MicroNAS是一个针对边缘计算中的微控制器单元（MCUs）设计的硬件感知零样本神经架构搜索框架。与之前的方法相比，MicroNAS在搜索效率和MCU推理速度方面都取得了显著的提升，同时保持了相似的精度水平。

    

    神经架构搜索 (NAS) 可以有效地发现新的卷积神经网络 (CNN) 架构，特别是用于精度优化。然而，之前的方法通常需要在超级网络上进行资源密集型训练或广泛的架构评估，限制了实际应用。为了解决这些挑战，我们提出了MicroNAS，这是一个专为边缘计算中的微控制器单元 (MCUs) 设计的硬件感知零样本NAS框架。MicroNAS在搜索过程中考虑了目标硬件优化性能，利用专门的性能指标来识别最佳的神经架构，而不需要高计算成本。与之前的工作相比，MicroNAS在搜索效率方面提高了1104倍，并且发现了在维持相似精度的情况下MCU推理速度提高了3.23倍的模型。

    Neural Architecture Search (NAS) effectively discovers new Convolutional Neural Network (CNN) architectures, particularly for accuracy optimization. However, prior approaches often require resource-intensive training on super networks or extensive architecture evaluations, limiting practical applications. To address these challenges, we propose MicroNAS, a hardware-aware zero-shot NAS framework designed for microcontroller units (MCUs) in edge computing. MicroNAS considers target hardware optimality during the search, utilizing specialized performance indicators to identify optimal neural architectures without high computational costs. Compared to previous works, MicroNAS achieves up to 1104x improvement in search efficiency and discovers models with over 3.23x faster MCU inference while maintaining similar accuracy
    
[^24]: 基于GAN的数据污染框架对抗纵向联合学习中的异常检测

    A GAN-based data poisoning framework against anomaly detection in vertical federated learning. (arXiv:2401.08984v1 [cs.LG])

    [http://arxiv.org/abs/2401.08984](http://arxiv.org/abs/2401.08984)

    这篇论文介绍了一种基于GAN的数据污染框架（P-GAN），用于对抗纵向联合学习中的异常检测。通过使用半监督学习训练一个替代目标模型，并使用GAN生成对抗性扰动来降低模型性能，最后通过深度自编码器开发的异常检测算法提供了强大的防御机制。

    

    在纵向联合学习 (VFL) 中，商业实体在保护数据隐私的同时协作训练模型。然而，恶意参与者的污染攻击可能会降低这个协作模型的性能。实现污染攻击的主要挑战是缺乏对服务器端顶层模型的访问，使得恶意参与者没有明确的目标模型。为了应对这个挑战，我们引入了一种创新的端到端污染框架 P-GAN。具体而言，恶意参与者最初采用半监督学习训练一个替代目标模型。随后，该参与者采用基于GAN的方法产生对抗性扰动，以降低替代目标模型的性能。最后，生成器被获得并针对VFL污染进行了改进。此外，我们还基于深度自编码器 (DAE) 开发了一种异常检测算法，为VFL场景提供了强大的防御机制。通过大量实验，我们证明了…

    In vertical federated learning (VFL), commercial entities collaboratively train a model while preserving data privacy. However, a malicious participant's poisoning attack may degrade the performance of this collaborative model. The main challenge in achieving the poisoning attack is the absence of access to the server-side top model, leaving the malicious participant without a clear target model. To address this challenge, we introduce an innovative end-to-end poisoning framework P-GAN. Specifically, the malicious participant initially employs semi-supervised learning to train a surrogate target model. Subsequently, this participant employs a GAN-based method to produce adversarial perturbations to degrade the surrogate target model's performance. Finally, the generator is obtained and tailored for VFL poisoning. Besides, we develop an anomaly detection algorithm based on a deep auto-encoder (DAE), offering a robust defense mechanism to VFL scenarios. Through extensive experiments, we 
    
[^25]: FedLoGe: 长尾数据下的本地和通用联邦学习

    FedLoGe: Joint Local and Generic Federated Learning under Long-tailed Data. (arXiv:2401.08977v1 [cs.LG])

    [http://arxiv.org/abs/2401.08977](http://arxiv.org/abs/2401.08977)

    本文介绍了一种名为FedLoGe的方法，它通过在神经网络崩溃框架中集成表示学习和分类器对齐来提高区域和全局模型的性能，解决了在联邦长尾学习中忽视本地级别性能的问题。

    

    联邦长尾学习（Fed-LT）是一种在去中心化的本地客户端收集的数据呈现全球普遍存在的长尾分布的范例，近年来引起了相当大的关注。在Fed-LT的背景下，现有研究主要集中于解决数据不平衡问题，以提高通用全局模型的效能，而忽视了本地级别的性能。相比之下，常规的个性化联邦学习（pFL）技术主要是在平衡的全局数据分布的假设下，优化个性化的本地模型。本文提出了一种名为FedLoGe的方法，在Fed-LT中通过在神经网络崩溃框架中集成表示学习和分类器对齐，提高本地和通用模型的性能。我们的研究结果揭示了使用共享骨干作为基础框架的可行性。

    Federated Long-Tailed Learning (Fed-LT), a paradigm wherein data collected from decentralized local clients manifests a globally prevalent long-tailed distribution, has garnered considerable attention in recent times. In the context of Fed-LT, existing works have predominantly centered on addressing the data imbalance issue to enhance the efficacy of the generic global model while neglecting the performance at the local level. In contrast, conventional Personalized Federated Learning (pFL) techniques are primarily devised to optimize personalized local models under the presumption of a balanced global data distribution. This paper introduces an approach termed Federated Local and Generic Model Training in Fed-LT (FedLoGe), which enhances both local and generic model performance through the integration of representation learning and classifier alignment within a neural collapse framework. Our investigation reveals the feasibility of employing a shared backbone as a foundational framewor
    
[^26]: OCTO + ：自动开放词汇物体放置在混合现实中的套件。

    OCTO+: A Suite for Automatic Open-Vocabulary Object Placement in Mixed Reality. (arXiv:2401.08973v1 [cs.CV])

    [http://arxiv.org/abs/2401.08973](http://arxiv.org/abs/2401.08973)

    本论文介绍了一种称为OCTO + 的套件，用于在混合现实中自动将虚拟物体放置在合适的位置。通过使用最新的开放词汇视觉语言模型，该方法在多个评估标准上取得了最先进的效果，超过其他方法。同时，还引入了一个用于自动评估增强现实中虚拟物体放置的基准。

    

    增强现实中的一个关键挑战是将虚拟内容放置在自然位置上。大多数现有的自动化技术只能使用封闭词汇、固定的物体集合来工作。在本文中，我们引入并评估了几种使用最新进展的开放词汇视觉语言模型进行自动物体放置的方法。通过多方面的评估，我们确定了一种新的最先进方法OCTO +。我们还引入了一个用于自动评估增强现实中虚拟物体放置的基准，减轻了需要昂贵用户研究的需求。通过这个基准，除了人类评估之外，我们发现OCTO + 有效地将物体放置在一个合理的区域内超过70％的时间，在各种指标上超越了其他方法。

    One key challenge in Augmented Reality is the placement of virtual content in natural locations. Most existing automated techniques can only work with a closed-vocabulary, fixed set of objects. In this paper, we introduce and evaluate several methods for automatic object placement using recent advances in open-vocabulary vision-language models. Through a multifaceted evaluation, we identify a new state-of-the-art method, OCTO+. We also introduce a benchmark for automatically evaluating the placement of virtual objects in augmented reality, alleviating the need for costly user studies. Through this, in addition to human evaluations, we find that OCTO+ places objects in a valid region over 70% of the time, outperforming other methods on a range of metrics.
    
[^27]: 从用户调查到遥测驱动代理：探索个性化的生产力解决方案的潜力

    From User Surveys to Telemetry-Driven Agents: Exploring the Potential of Personalized Productivity Solutions. (arXiv:2401.08960v1 [cs.HC])

    [http://arxiv.org/abs/2401.08960](http://arxiv.org/abs/2401.08960)

    本研究提出了一个以用户为中心的方法，以了解AI基于的生产力代理的偏好，并开发出个性化解决方案。通过调查和使用遥测数据，我们开发了一个GPT-4驱动的个性化生产力代理，并在研究中与其他辅助工具进行了比较。我们的研究突出了用户中心设计、适应性和个性化与隐私之间的平衡的重要性。

    

    我们提出了一个综合的以用户为中心的方法，用于了解基于人工智能的生产力代理的偏好，并开发出根据用户需求定制的个性化解决方案。通过两个阶段的方法，我们首先对363名参与者进行了调查，探索了生产力、沟通风格、代理方法、个性特征、个性化和隐私等各个方面。借助调查结果，我们开发了一个由Viva Insights收集的遥测数据驱动的个性化生产力代理，该代理利用GPT-4提供定制的帮助。我们在涉及40名参与者的研究中，将其性能与仪表板和叙述等替代的生产力辅助工具进行了比较。我们的研究结果凸显了用户中心设计、适应性以及个性化和隐私之间的平衡在AI辅助生产力工具中的重要性。通过借鉴我们研究中提炼的见解，我们相信我们的工作可以启发和指导未来的研究。

    We present a comprehensive, user-centric approach to understand preferences in AI-based productivity agents and develop personalized solutions tailored to users' needs. Utilizing a two-phase method, we first conducted a survey with 363 participants, exploring various aspects of productivity, communication style, agent approach, personality traits, personalization, and privacy. Drawing on the survey insights, we developed a GPT-4 powered personalized productivity agent that utilizes telemetry data gathered via Viva Insights from information workers to provide tailored assistance. We compared its performance with alternative productivity-assistive tools, such as dashboard and narrative, in a study involving 40 participants. Our findings highlight the importance of user-centric design, adaptability, and the balance between personalization and privacy in AI-assisted productivity tools. By building on the insights distilled from our study, we believe that our work can enable and guide futur
    
[^28]: 面向带有人类反馈的排名策略的离策略强化学习

    Towards Off-Policy Reinforcement Learning for Ranking Policies with Human Feedback. (arXiv:2401.08959v1 [cs.LG])

    [http://arxiv.org/abs/2401.08959](http://arxiv.org/abs/2401.08959)

    本文提出了一种新的离策略价值排名（VR）算法，通过统一的期望最大化（EM）框架，在不需要在线交互的情况下最大化用户的长期回报和优化排名指标，以提高样本效率。

    

    概率学习排名（LTR）一直是优化排名指标的主要方法，但无法最大化长期回报。提出了强化学习模型来将推荐问题形式化为序贯决策问题，以最大化用户的长期回报，但在准确性方面与LTR方法相比仍然存在不足，主要原因是缺乏在线交互和排名特性。本文提出了一种新的离策略价值排名（VR）算法，可以在统一的期望最大化（EM）框架下同时最大化用户的长期回报和优化排名指标，从而提高样本效率。我们在理论上和实验证明了EM过程引导学习策略享受未来回报和排名指标融合的好处，而无需进行任何在线交互。大量的离线和在线实验证明了我们方法的有效性。

    Probabilistic learning to rank (LTR) has been the dominating approach for optimizing the ranking metric, but cannot maximize long-term rewards. Reinforcement learning models have been proposed to maximize user long-term rewards by formulating the recommendation as a sequential decision-making problem, but could only achieve inferior accuracy compared to LTR counterparts, primarily due to the lack of online interactions and the characteristics of ranking. In this paper, we propose a new off-policy value ranking (VR) algorithm that can simultaneously maximize user long-term rewards and optimize the ranking metric offline for improved sample efficiency in a unified Expectation-Maximization (EM) framework. We theoretically and empirically show that the EM process guides the leaned policy to enjoy the benefit of integration of the future reward and ranking metric, and learn without any online interactions. Extensive offline and online experiments demonstrate the effectiveness of our methods
    
[^29]: SWBT：具有不完美演示的相似性加权行为转换器用于机器人操作

    SWBT: Similarity Weighted Behavior Transformer with the Imperfect Demonstration for Robotic Manipulation. (arXiv:2401.08957v1 [cs.RO])

    [http://arxiv.org/abs/2401.08957](http://arxiv.org/abs/2401.08957)

    本论文提出了一种新型框架SWBT，能够在机器人操作任务中有效地从专家演示和不完美演示中学习，而无需与环境进行交互。这是第一个将不完美演示整合到离线模仿学习设置中的机器人操作任务的研究。

    

    模仿学习旨在从专家演示中学习最佳控制策略，已成为机器人操作任务的有效方法。然而，先前的模仿学习方法要么仅使用昂贵的专家演示并忽略不完美的演示，要么依赖于与环境的交互和从在线经验中学习。在机器人操作的背景下，我们旨在克服上述两个挑战，并提出了一种名为Similarity Weighted Behavior Transformer（SWBT）的新型框架。SWBT能够有效地从专家演示和不完美演示中学习，而无需与环境进行交互。我们揭示了易获取的不完美演示，如正向和反向动力学，通过学习有益信息显著增强了网络。据我们所知，我们是第一个尝试将不完美演示整合到离线模仿学习设置中的机器人操作任务中的研究。在ManiSkill2 bench上进行了大量实验。

    Imitation learning (IL), aiming to learn optimal control policies from expert demonstrations, has been an effective method for robot manipulation tasks. However, previous IL methods either only use expensive expert demonstrations and omit imperfect demonstrations or rely on interacting with the environment and learning from online experiences. In the context of robotic manipulation, we aim to conquer the above two challenges and propose a novel framework named Similarity Weighted Behavior Transformer (SWBT). SWBT effectively learn from both expert and imperfect demonstrations without interaction with environments. We reveal that the easy-to-get imperfect demonstrations, such as forward and inverse dynamics, significantly enhance the network by learning fruitful information. To the best of our knowledge, we are the first to attempt to integrate imperfect demonstrations into the offline imitation learning setting for robot manipulation tasks. Extensive experiments on the ManiSkill2 bench
    
[^30]: CEL：通过弹性权重整合利用领域自适应来进行疾病爆发预测的持续学习模型

    CEL: A Continual Learning Model for Disease Outbreak Prediction by Leveraging Domain Adaptation via Elastic Weight Consolidation. (arXiv:2401.08940v1 [cs.LG])

    [http://arxiv.org/abs/2401.08940](http://arxiv.org/abs/2401.08940)

    本研究提出了一种名为CEL的模型，通过利用领域自适应和弹性权重整合，实现了对疾病爆发预测的持续学习。该模型通过惩罚重要参数的改变来缓解灾难性遗忘现象，并在多个疾病上取得了比其他模型更好的性能。

    

    连续学习是模型在学习过程中不忘记之前知识并能适应新数据的能力，在疾病爆发预测等动态领域尤为重要。深度神经网络，如LSTM，由于灾难性遗忘而容易出错。本研究通过弹性权重整合（EWC）利用领域自适应引入了一种新颖的CEL模型进行持续学习。该模型旨在缓解领域增量设置中的灾难性遗忘现象。利用EWC构建Fisher信息矩阵（FIM）以开发出一个惩罚对重要参数即重要先前知识的改变的正则化项。在评估和重新评估中，CEL的性能使用不同指标在三种不同的疾病（流感，痘疹和麻疹）上得到了很高的R-squared值，胜过其他最先进的模型，在多个上下文中表明CEL对增量数据具有适应能力。

    Continual learning, the ability of a model to learn over time without forgetting previous knowledge and, therefore, be adaptive to new data, is paramount in dynamic fields such as disease outbreak prediction. Deep neural networks, i.e., LSTM, are prone to error due to catastrophic forgetting. This study introduces a novel CEL model for continual learning by leveraging domain adaptation via Elastic Weight Consolidation (EWC). This model aims to mitigate the catastrophic forgetting phenomenon in a domain incremental setting. The Fisher Information Matrix (FIM) is constructed with EWC to develop a regularization term that penalizes changes to important parameters, namely, the important previous knowledge. CEL's performance is evaluated on three distinct diseases, Influenza, Mpox, and Measles, with different metrics. The high R-squared values during evaluation and reevaluation outperform the other state-of-the-art models in several contexts, indicating that CEL adapts to incremental data w
    
[^31]: 使用基础模型设计学习环境的 DeLF

    DeLF: Designing Learning Environments with Foundation Models. (arXiv:2401.08936v1 [cs.AI])

    [http://arxiv.org/abs/2401.08936](http://arxiv.org/abs/2401.08936)

    DeLF是一种利用大型语言模型设计学习环境的方法，可以解决在实践中应用强化学习的困难。通过测试，证明DeLF可以为不同的学习环境获得可执行的代码。

    

    强化学习（RL）为基本的顺序决策问题提供了一种能力强大且直观的结构。尽管取得了令人瞩目的突破，但在许多简单应用中实际应用RL仍然很困难。在本文中，我们通过引入一种用于为给定的、用户预期的应用设计RL环境组件的方法来解决这个问题。我们提供了RL组件设计问题的初始形式化，重点是设计观察和动作空间的良好表示。我们提出了一种名为DeLF：使用基础模型设计学习环境的方法，该方法利用大型语言模型来设计和编码用户预期的学习场景。通过在四个不同的学习环境上测试我们的方法，我们证明了DeLF可以为相应的RL问题获得可执行的环境代码。

    Reinforcement learning (RL) offers a capable and intuitive structure for the fundamental sequential decision-making problem. Despite impressive breakthroughs, it can still be difficult to employ RL in practice in many simple applications. In this paper, we try to address this issue by introducing a method for designing the components of the RL environment for a given, user-intended application. We provide an initial formalization for the problem of RL component design, that concentrates on designing a good representation for observation and action space. We propose a method named DeLF: Designing Learning Environments with Foundation Models, that employs large language models to design and codify the user's intended learning scenario. By testing our method on four different learning environments, we demonstrate that DeLF can obtain executable environment codes for the corresponding RL problems.
    
[^32]: 学习从噪声标签中检测遥感图像中的云和雪

    Learning to detect cloud and snow in remote sensing images from noisy labels. (arXiv:2401.08932v1 [cs.CV])

    [http://arxiv.org/abs/2401.08932](http://arxiv.org/abs/2401.08932)

    本研究通过构建新的数据集和引入课程学习方法，提出了一种用于遥感图像中云和雪检测的训练策略。同时，设计了一种更合适的模型性能评估方法，有效减少了由于噪声标签引起的性能评估偏差。

    

    检测遥感图像中的云和雪是遥感图像的重要预处理任务。以前的工作借鉴了计算机视觉中的语义分割模型，大部分研究集中在改进模型结构以提高检测性能。然而，与自然图像不同，遥感图像中场景的复杂性和云类型的多样性导致云和雪检测数据集中存在许多不准确的标签，导致训练和测试过程中引入了不必要的噪声。通过构建一个新的数据集并提出一种新的训练策略，即课程学习模式，我们引导模型减少对噪声标签的过拟合。此外，我们设计了一种更合适的模型性能评估方法，缓解了由噪声标签引起的性能评估偏差。通过在UNet和Segformer模型上进行实验，我们验证了我们提出的方法的有效性。

    Detecting clouds and snow in remote sensing images is an essential preprocessing task for remote sensing imagery. Previous works draw inspiration from semantic segmentation models in computer vision, with most research focusing on improving model architectures to enhance detection performance. However, unlike natural images, the complexity of scenes and the diversity of cloud types in remote sensing images result in many inaccurate labels in cloud and snow detection datasets, introducing unnecessary noises into the training and testing processes. By constructing a new dataset and proposing a novel training strategy with the curriculum learning paradigm, we guide the model in reducing overfitting to noisy labels. Additionally, we design a more appropriate model performance evaluation method, that alleviates the performance assessment bias caused by noisy labels. By conducting experiments on models with UNet and Segformer, we have validated the effectiveness of our proposed method. This 
    
[^33]: 通过扩散合成进行3D人体姿势分析

    3D Human Pose Analysis via Diffusion Synthesis. (arXiv:2401.08930v1 [cs.CV])

    [http://arxiv.org/abs/2401.08930](http://arxiv.org/abs/2401.08930)

    本文提出了一种名为PADS的框架，通过扩散合成过程学习姿势先验，解决3D人体姿势分析中的各种挑战，将多个姿势分析任务统一为逆问题的实例，验证了其性能和适应性。

    

    扩散模型在生成建模方面取得了显著的成功。本文提出了一种名为PADS（通过扩散合成进行姿势分析）的新框架，旨在通过一个统一的流程解决3D人体姿势分析中的各种挑战。PADS的核心是两个独特的策略：i）使用扩散合成过程学习一个任务无关的姿势先验，从而有效地捕捉人体姿势数据中的运动约束；ii）将估计、补全、去噪等多个姿势分析任务统一为逆问题的实例。学习到的姿势先验将被视为对任务特定约束的正则化，通过一系列条件去噪步骤引导优化过程。PADS代表了首个基于扩散的框架，用于解决逆问题框架内的通用3D人体姿势分析。其性能已在不同基准测试上得到了验证，显示出其适应性和鲁棒性。

    Diffusion models have demonstrated remarkable success in generative modeling. In this paper, we propose PADS (Pose Analysis by Diffusion Synthesis), a novel framework designed to address various challenges in 3D human pose analysis through a unified pipeline. Central to PADS are two distinctive strategies: i) learning a task-agnostic pose prior using a diffusion synthesis process to effectively capture the kinematic constraints in human pose data, and ii) unifying multiple pose analysis tasks like estimation, completion, denoising, etc, as instances of inverse problems. The learned pose prior will be treated as a regularization imposing on task-specific constraints, guiding the optimization process through a series of conditional denoising steps. PADS represents the first diffusion-based framework for tackling general 3D human pose analysis within the inverse problem framework. Its performance has been validated on different benchmarks, signaling the adaptability and robustness of this
    
[^34]: 桥接状态和历史表示：理解自预测强化学习

    Bridging State and History Representations: Understanding Self-Predictive RL. (arXiv:2401.08898v1 [cs.LG])

    [http://arxiv.org/abs/2401.08898](http://arxiv.org/abs/2401.08898)

    本论文研究了深度强化学习中状态和历史表示间的关系，发现了这些方法和框架实际上都基于自预测抽象的共同思想，并提供了理论洞见和简化算法来学习自预测表示。

    

    表示是所有深度强化学习方法的核心，适用于马尔可夫决策过程（MDP）和部分可观察的马尔可夫决策过程（POMDP）。许多表示学习方法和理论框架被开发用于理解什么构成了有效的表示。然而，这些方法之间的关系和它们之间的共同属性仍然不清楚。在本文中，我们展示了许多看似不同的状态和历史抽象方法和框架实际上基于自预测抽象的共同思想。此外，我们提供了关于广泛采用的目标和优化（如停梯度技术）在学习自预测表示中的理论洞见。这些发现共同产生了一种简化的算法，用于学习状态和历史的自预测表示。我们通过将我们的算法应用于标准MDP、带有dist的MDP进行验证。

    Representations are at the core of all deep reinforcement learning (RL) methods for both Markov decision processes (MDPs) and partially observable Markov decision processes (POMDPs). Many representation learning methods and theoretical frameworks have been developed to understand what constitutes an effective representation. However, the relationships between these methods and the shared properties among them remain unclear. In this paper, we show that many of these seemingly distinct methods and frameworks for state and history abstractions are, in fact, based on a common idea of self-predictive abstraction. Furthermore, we provide theoretical insights into the widely adopted objectives and optimization, such as the stop-gradient technique, in learning self-predictive representations. These findings together yield a minimalist algorithm to learn self-predictive representations for states and histories. We validate our theories by applying our algorithm to standard MDPs, MDPs with dist
    
[^35]: CFASL：用于变分自编码器中的解缠学习的复合因子对齐对称学习

    CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational AutoEncoder. (arXiv:2401.08897v1 [cs.LG])

    [http://arxiv.org/abs/2401.08897](http://arxiv.org/abs/2401.08897)

    CFASL是一种用于解缠学习的新方法，它将对称性学习与VAE集成，无需任何数据集因子信息的先验知识，具有三个新特征：对齐潜在向量维度到可学习对称代码簿中的对称性，学习复合对称性来表达未知因素的变化，以及引入群等变编码器和解码器来训练VAE。

    

    输入和潜在向量的对称性为VAE中的解缠学习提供了宝贵的见解。然而，只有少数几篇论文提出了一种无监督方法，甚至这些方法在训练数据中也需要已知的因子信息。我们提出了一种新的方法，Composite Factor-Aligned Symmetry Learning (CFASL)，将其集成到VAE中，用于学习基于对称性的解缠，无监督学习中不需要任何数据集因子信息的知识。CFASL包括三个用于学习基于对称性的解缠的新特征：1)注入归纳偏置，将潜在向量维度对齐到明确可学习的对称代码簿中的因子对齐对称性；2)学习一个复合对称性，通过学习代码簿中的因子对齐对称性，来表达两个随机样本之间的未知因素的变化；3)在训练VAE时，引入具有群等变编码器和解码器的两个条件。此外，我们提出了一种扩展的评估指标。

    Symmetries of input and latent vectors have provided valuable insights for disentanglement learning in VAEs.However, only a few works were proposed as an unsupervised method, and even these works require known factor information in training data. We propose a novel method, Composite Factor-Aligned Symmetry Learning (CFASL), which is integrated into VAEs for learning symmetry-based disentanglement in unsupervised learning without any knowledge of the dataset factor information.CFASL incorporates three novel features for learning symmetry-based disentanglement: 1) Injecting inductive bias to align latent vector dimensions to factor-aligned symmetries within an explicit learnable symmetry codebook 2) Learning a composite symmetry to express unknown factors change between two random samples by learning factor-aligned symmetries within the codebook 3) Inducing group equivariant encoder and decoder in training VAEs with the two conditions. In addition, we propose an extended evaluation metri
    
[^36]: NOTSOFAR-1挑战：远距离会议转录的新数据集，基准线和任务

    NOTSOFAR-1 Challenge: New Datasets, Baseline, and Tasks for Distant Meeting Transcription. (arXiv:2401.08887v1 [cs.SD])

    [http://arxiv.org/abs/2401.08887](http://arxiv.org/abs/2401.08887)

    NOTSOFAR-1挑战旨在解决远距离会议转录中的远距离发言人划分和自动语音识别问题，在一个新发布的数据集上进行评估。

    

    我们介绍了第一个自然办公室谈话者在远场音频记录环境中（“NOTSOFAR-1”）的挑战，包括数据集和基准系统。该挑战主要关注远场会议中的远距离发言人划分和自动语音识别（DASR），包括单声道和已知几何多通道的轨道，并且作为两个新数据集的发布平台：第一个数据集是一个基准测试数据集，包括315个会议，每个会议平均6分钟，捕捉到广泛的真实世界声学环境和对话动态。它是在30个会议室中录制的，每个会议室有4-8个与会者和共计35个不同的发言者。第二个数据集是一个1000小时的模拟训练数据集，具有增强的真实性以实现真实世界的泛化，包括15000个真实声学转移函数。任务集中在单设备DASR上，其中多通道设备始终共享相同已知的几何形状。这与实际会议室的常见设置是一致的。

    We introduce the first Natural Office Talkers in Settings of Far-field Audio Recordings (``NOTSOFAR-1'') Challenge alongside datasets and baseline system. The challenge focuses on distant speaker diarization and automatic speech recognition (DASR) in far-field meeting scenarios, with single-channel and known-geometry multi-channel tracks, and serves as a launch platform for two new datasets: First, a benchmarking dataset of 315 meetings, averaging 6 minutes each, capturing a broad spectrum of real-world acoustic conditions and conversational dynamics. It is recorded across 30 conference rooms, featuring 4-8 attendees and a total of 35 unique speakers. Second, a 1000-hour simulated training dataset, synthesized with enhanced authenticity for real-world generalization, incorporating 15,000 real acoustic transfer functions. The tasks focus on single-device DASR, where multi-channel devices always share the same known geometry. This is aligned with common setups in actual conference rooms,
    
[^37]: 量化双极论证图的贡献函数：基于原则的分析

    Contribution Functions for Quantitative Bipolar Argumentation Graphs: A Principle-based Analysis. (arXiv:2401.08879v1 [cs.AI])

    [http://arxiv.org/abs/2401.08879](http://arxiv.org/abs/2401.08879)

    本文对量化双极论证图的贡献函数进行了基于原则的分析，为选择最合适的函数提供了工具。

    

    我们对量化双极论证图的贡献函数进行了基于原则的分析，该函数量化了一个论证对另一个论证的贡献。引入的原则将不同的贡献函数的直觉形式化，并对贡献函数的行为有了期望。由于没有一个覆盖的贡献函数满足所有原则，我们的分析可以作为一个工具，根据给定用例的要求选择最合适的函数。

    We present a principle-based analysis of contribution functions for quantitative bipolar argumentation graphs that quantify the contribution of one argument to another. The introduced principles formalise the intuitions underlying different contribution functions as well as expectations one would have regarding the behaviour of contribution functions in general. As none of the covered contribution functions satisfies all principles, our analysis can serve as a tool that enables the selection of the most suitable function based on the requirements of a given use case.
    
[^38]: DCRMTA: 无偏的多触点归因的因果表示

    DCRMTA: Unbiased Causal Representation for Multi-touch Attribution. (arXiv:2401.08875v1 [cs.LG])

    [http://arxiv.org/abs/2401.08875](http://arxiv.org/abs/2401.08875)

    DCRMTA提出了一种无偏的多触点归因方法，通过建立转化预测模型和构建对照触点序列来减轻偏差的影响。

    

    多触点归因（MTA）在实现对每个广告触点对于转化行为的贡献的公正估计方面起着关键作用，深刻影响预算分配和广告推荐。传统的多触点归因方法首先构建一个转化预测模型，通过历史数据学习触点序列和用户购买行为之间的内在关系。在此基础上，从原始序列子集中构建对照触点序列，并使用预测模型估计转化，从而计算广告贡献。这些方法的一个隐含假设是转化预测模型的无偏性。然而，由于用户偏好和互联网推荐机制（如过去的购物记录导致的广告推荐同质化）引起的混杂变量因素，转化中很容易产生偏差。

    Multi-touch attribution (MTA) currently plays a pivotal role in achieving a fair estimation of the contributions of each advertising touchpoint to-wards conversion behavior, deeply influencing budget allocation and advertising recommenda-tion. Traditional multi-touch attribution methods initially build a conversion prediction model, an-ticipating learning the inherent relationship be-tween touchpoint sequences and user purchasing behavior through historical data. Based on this, counterfactual touchpoint sequences are con-structed from the original sequence subset, and conversions are estimated using the prediction model, thus calculating advertising contributions. A covert assumption of these methods is the un-biased nature of conversion prediction models. However, due to confounding variables factors arising from user preferences and internet recom-mendation mechanisms such as homogenization of ad recommendations resulting from past shop-ping records, bias can easily occur in conversi
    
[^39]: 使用超宽带传感器的通道脉冲响应来实现钥匙无线进入系统中的密钥扣的鲁棒定位

    Robust Localization of Key Fob Using Channel Impulse Response of Ultra Wide Band Sensors for Keyless Entry Systems. (arXiv:2401.08863v1 [cs.LG])

    [http://arxiv.org/abs/2401.08863](http://arxiv.org/abs/2401.08863)

    本文研究了使用神经网络和超宽带传感器对车辆中的钥匙扣进行定位的问题，并提出了一种新的鲁棒定位方法，该方法在没有对抗训练的情况下取得了比基准方法更好的性能。

    

    使用神经网络对车辆内部和周围的钥匙扣进行定位是一种新兴的车辆安全功能。本文研究了以下问题：1）基于神经网络的超宽带（UWB）定位分类的预计算特征的性能作为我们实验的基准。2）研究各种神经网络的鲁棒性，包括没有任何对抗训练的对抗示例的鲁棒性。3）提出了一种多头自监督神经网络架构，该架构在没有任何对抗训练的情况下优于基准神经网络。模型的性能在快速梯度符号方法的某些对抗强度范围内提高了67％，对于基本迭代方法和投影梯度下降方法分别提高了37％。

    Using neural networks for localization of key fob within and surrounding a car as a security feature for keyless entry is fast emerging. In this paper we study: 1) the performance of pre-computed features of neural networks based UWB (ultra wide band) localization classification forming the baseline of our experiments. 2) Investigate the inherent robustness of various neural networks; therefore, we include the study of robustness of the adversarial examples without any adversarial training in this work. 3) Propose a multi-head self-supervised neural network architecture which outperforms the baseline neural networks without any adversarial training. The model's performance improved by 67% at certain ranges of adversarial magnitude for fast gradient sign method and 37% each for basic iterative method and projected gradient descent method.
    
[^40]: REValueD: 对可分解的马尔可夫决策过程进行正则化集合值分解

    REValueD: Regularised Ensemble Value-Decomposition for Factorisable Markov Decision Processes. (arXiv:2401.08850v1 [cs.LG])

    [http://arxiv.org/abs/2401.08850](http://arxiv.org/abs/2401.08850)

    REValueD是一种通过正则化集合值分解的新算法，针对高维离散动作空间的任务提供了优越性能，尤其在人形和狗类任务中表现出色。它遏制了Q-learning算法的高估偏差，并减轻了目标方差问题。

    

    由于可能的动作数量庞大，离散动作强化学习算法在具有高维离散动作空间的任务中经常失败。最近的一项进展利用了来自多智能体强化学习的概念——值分解，来解决这个问题。这项研究深入探讨了值分解的影响，揭示了它虽然可以遏制Q学习算法固有的高估偏差，但也会放大目标方差。为了应对这个问题，我们提出了一个评论家的集合以减轻目标方差。此外，我们引入了一个正则化损失，有助于减轻一个维度上的探索性动作对其他维度上最优动作价值的影响。我们的新颖算法REValueD，在经过离散化的DeepMind控制套件任务上进行了测试，展示了卓越的性能，特别是在困难的人形和狗类任务中。我们进一步分析了影响REValueD表现的因素。

    Discrete-action reinforcement learning algorithms often falter in tasks with high-dimensional discrete action spaces due to the vast number of possible actions. A recent advancement leverages value-decomposition, a concept from multi-agent reinforcement learning, to tackle this challenge. This study delves deep into the effects of this value-decomposition, revealing that whilst it curtails the over-estimation bias inherent to Q-learning algorithms, it amplifies target variance. To counteract this, we present an ensemble of critics to mitigate target variance. Moreover, we introduce a regularisation loss that helps to mitigate the effects that exploratory actions in one dimension can have on the value of optimal actions in other dimensions. Our novel algorithm, REValueD, tested on discretised versions of the DeepMind Control Suite tasks, showcases superior performance, especially in the challenging humanoid and dog tasks. We further dissect the factors influencing REValueD's performance
    
[^41]: 通过保守密度估计从稀疏离线数据集中学习

    Learning from Sparse Offline Datasets via Conservative Density Estimation. (arXiv:2401.08819v1 [cs.LG])

    [http://arxiv.org/abs/2401.08819](http://arxiv.org/abs/2401.08819)

    本文提出了一种名为保守密度估计（CDE）的训练算法，通过明确约束状态-行为占据稳态分布来解决离线强化学习中的外推错误问题。在稀疏奖励或不足数据的任务中，CDE显示出明显优于基准方法的性能。

    

    离线强化学习（RL）为从预先收集的数据集中学习策略提供了一种有前景的方向，而无需与环境进一步交互。然而，现有的方法在处理分布外（OOD）外推错误方面存在困难，特别是在稀疏奖励或数据稀缺的情况下。在本文中，我们提出了一种名为保守密度估计（CDE）的新的训练算法，通过明确约束状态-行为占据稳态分布来解决这个挑战。CDE通过解决边际重要性抽样中的支持不匹配问题，克服了现有方法的局限性，如稳态分布校正方法。我们的方法在D4RL基准测试中实现了最先进的性能。值得注意的是，CDE在具有稀疏奖励或不足数据的挑战性任务中持续优于基准方法，证明了我们的方法在解决外推错误问题上的优势。

    Offline reinforcement learning (RL) offers a promising direction for learning policies from pre-collected datasets without requiring further interactions with the environment. However, existing methods struggle to handle out-of-distribution (OOD) extrapolation errors, especially in sparse reward or scarce data settings. In this paper, we propose a novel training algorithm called Conservative Density Estimation (CDE), which addresses this challenge by explicitly imposing constraints on the state-action occupancy stationary distribution. CDE overcomes the limitations of existing approaches, such as the stationary distribution correction method, by addressing the support mismatch issue in marginal importance sampling. Our method achieves state-of-the-art performance on the D4RL benchmark. Notably, CDE consistently outperforms baselines in challenging tasks with sparse rewards or insufficient data, demonstrating the advantages of our approach in addressing the extrapolation error problem i
    
[^42]: 对抗监督使布局到图像扩散模型蓬勃发展

    Adversarial Supervision Makes Layout-to-Image Diffusion Models Thrive. (arXiv:2401.08815v1 [cs.CV])

    [http://arxiv.org/abs/2401.08815](http://arxiv.org/abs/2401.08815)

    该论文提出了一种对抗监督的布局到图像扩散模型（ALDM），通过引入分割判别器和多步展开策略，可以提升布局到图像合成任务中的文本编辑能力和生成图像与输入布局之间的对齐准确性。

    

    尽管大规模扩散模型取得了近期的进展，但布局到图像合成任务的进展较小。当前的布局到图像模型要么在文本编辑能力上欠佳，要么在生成的图像与输入布局之间的对齐上较弱，这限制了它们的实际应用性。为了缓解这一问题，我们提出将对抗监督集成到传统布局到图像扩散模型的训练流程中（ALDM）。具体而言，我们采用基于分割的判别器，该判别器在像素级别上为扩散生成器提供明确的反馈，用于指导去噪图像与输入布局之间的对齐。为了鼓励在采样步骤中对输入布局的一致依从，我们进一步引入了多步展开策略。我们不是只关注单个时间步，而是递归地展开几个步骤来模拟推理过程，并要求判别器在一定时间窗口内评估去噪图像与布局的对齐情况。

    Despite the recent advances in large-scale diffusion models, little progress has been made on the layout-to-image (L2I) synthesis task. Current L2I models either suffer from poor editability via text or weak alignment between the generated image and the input layout. This limits their usability in practice. To mitigate this, we propose to integrate adversarial supervision into the conventional training pipeline of L2I diffusion models (ALDM). Specifically, we employ a segmentation-based discriminator which provides explicit feedback to the diffusion generator on the pixel-level alignment between the denoised image and the input layout. To encourage consistent adherence to the input layout over the sampling steps, we further introduce the multistep unrolling strategy. Instead of looking at a single timestep, we unroll a few steps recursively to imitate the inference process, and ask the discriminator to assess the alignment of denoised images with the layout over a certain time window. 
    
[^43]: MMToM-QA: 多模态心智理论问答

    MMToM-QA: Multimodal Theory of Mind Question Answering. (arXiv:2401.08743v1 [cs.AI])

    [http://arxiv.org/abs/2401.08743](http://arxiv.org/abs/2401.08743)

    MMToM-QA是一个多模态心智理论问答基准，用于评估机器对于人的心智理论的理解能力。我们提出了一种新的方法BIP-ALM用于实现多模态心智理论能力。

    

    理解人们的心智是开发具有人类水平社交智能的机器的一个重要组成部分。最近的机器学习模型，特别是大型语言模型，似乎展现出某些心智理解的方面。然而，现有的心智理论基准使用单模态数据集-或者视频或者文本。然而，人类的心智理论不仅仅是视频或文本理解。人们可以根据从任何可用数据中提取的概念表示（例如目标，信念，计划）灵活地推理另一个人的心智，这些数据可以包括视觉线索，语言叙事或两者兼有。为了解决这个问题，我们引入了一个多模态的心智理论问答（MMToM-QA）基准。MMToM-QA在多模态数据和关于一个人在家庭环境中的活动的不同种类的单模态数据上全面评估机器的心智理论。为了实现多模态心智理论能力，我们提出了一种新的方法，BIP-ALM（贝叶斯逆向规划）。

    Theory of Mind (ToM), the ability to understand people's minds, is an essential ingredient for developing machines with human-level social intelligence. Recent machine learning models, particularly large language models, seem to show some aspects of ToM understanding. However, existing ToM benchmarks use unimodal datasets - either video or text. Human ToM, on the other hand, is more than video or text understanding. People can flexibly reason about another person's mind based on conceptual representations (e.g., goals, beliefs, plans) extracted from any available data, which can include visual cues, linguistic narratives, or both. To address this, we introduce a multimodal Theory of Mind question answering (MMToM-QA) benchmark. MMToM-QA comprehensively evaluates machine ToM both on multimodal data and on different kinds of unimodal data about a person's activity in a household environment. To engineer multimodal ToM capacity, we propose a novel method, BIP-ALM (Bayesian Inverse Plannin
    
[^44]: 固定点扩散模型

    Fixed Point Diffusion Models. (arXiv:2401.08741v1 [cs.CV])

    [http://arxiv.org/abs/2401.08741](http://arxiv.org/abs/2401.08741)

    固定点扩散模型（FPDM）是一种将固定点求解引入扩散生成模型框架的新方法，通过嵌入固定点求解层和采用新的训练方法，显著减小了模型大小、内存使用量并加快了训练速度，并且提出了两种新的技术来提高采样效率。实验证明，与现有模型相比，FPDM在性能和效率上有明显改进。

    

    我们引入了固定点扩散模型（FPDM），这是一种将固定点求解的概念融入基于扩散的生成模型框架的新方法。我们的方法将一个隐式的固定点求解层嵌入到扩散模型的去噪网络中，将扩散过程转化为一系列相关的固定点问题。结合一种新的随机训练方法，这种方法显著减少了模型大小，减小了内存使用量，并加快了训练速度。此外，它还能够开发出两种新的技术来提高采样效率：在时间步之间重新分配计算和重用固定点解。我们对ImageNet、FFHQ、CelebA-HQ和LSUN-Church等最先进的模型进行了大量实验，证明了性能和效率的显著改进。与最先进的DiT模型相比，FPDM参数减少了87%，内存消耗减少了60%。

    We introduce the Fixed Point Diffusion Model (FPDM), a novel approach to image generation that integrates the concept of fixed point solving into the framework of diffusion-based generative modeling. Our approach embeds an implicit fixed point solving layer into the denoising network of a diffusion model, transforming the diffusion process into a sequence of closely-related fixed point problems. Combined with a new stochastic training method, this approach significantly reduces model size, reduces memory usage, and accelerates training. Moreover, it enables the development of two new techniques to improve sampling efficiency: reallocating computation across timesteps and reusing fixed point solutions between timesteps. We conduct extensive experiments with state-of-the-art models on ImageNet, FFHQ, CelebA-HQ, and LSUN-Church, demonstrating substantial improvements in performance and efficiency. Compared to the state-of-the-art DiT model, FPDM contains 87% fewer parameters, consumes 60%
    
[^45]: EgoGen:一种自我的合成数据生成器

    EgoGen: An Egocentric Synthetic Data Generator. (arXiv:2401.08739v1 [cs.CV])

    [http://arxiv.org/abs/2401.08739](http://arxiv.org/abs/2401.08739)

    EgoGen是一种新的合成数据生成器，它可以为具体化自我的感知任务生成准确和丰富的地面真实训练数据，并利用自我视觉输入来感知3D环境。

    

    在增强现实（AR）中，以第一人称视角理解世界是基础性的。这种身临其境的视角相对于第三人称视角带来了戏剧性的视觉变化和独特的挑战。合成数据已经赋予了第三人称视角视觉模型的能力，但其应用于具体化自我的感知任务仍然很少被探索。一个重要的挑战在于模拟自然的人类运动和行为，以有效地操纵实体相机捕捉到3D世界的真实自我的表达。为了解决这个挑战，我们引入了一个新的合成数据生成器EgoGen，它可以为具体化自我的感知任务生成准确和丰富的地面真实训练数据。EgoGen的核心是一种新颖的人体运动合成模型，它直接利用虚拟人类的自我视觉输入感知3D环境。结合避免碰撞的运动基元和两阶段强化学习方法，我们的运动合成模型实现了高效的自我的合成。

    Understanding the world in first-person view is fundamental in Augmented Reality (AR). This immersive perspective brings dramatic visual changes and unique challenges compared to third-person views. Synthetic data has empowered third-person-view vision models, but its application to embodied egocentric perception tasks remains largely unexplored. A critical challenge lies in simulating natural human movements and behaviors that effectively steer the embodied cameras to capture a faithful egocentric representation of the 3D world. To address this challenge, we introduce EgoGen, a new synthetic data generator that can produce accurate and rich ground-truth training data for egocentric perception tasks. At the heart of EgoGen is a novel human motion synthesis model that directly leverages egocentric visual inputs of a virtual human to sense the 3D environment. Combined with collision-avoiding motion primitives and a two-stage reinforcement learning approach, our motion synthesis model off
    
[^46]: AgentMixer: 多智能体相关策略因子分解

    AgentMixer: Multi-Agent Correlated Policy Factorization. (arXiv:2401.08728v1 [cs.MA])

    [http://arxiv.org/abs/2401.08728](http://arxiv.org/abs/2401.08728)

    AgentMixer提出了一种新颖的框架，允许智能体通过策略修改来实现协同决策。通过构造联合策略为各个部分策略的非线性组合，可实现部分可观测智能体的稳定训练和分散执行。

    

    集中式训练与分散式执行（CTDE）广泛应用于通过在训练过程中利用集中式值函数来稳定部分可观察的多智能体强化学习（MARL）。然而，现有方法通常假设智能体基于本地观测独立地做决策，这可能不会导致具有足够协调性的相关联的联合策略。受相关均衡概念的启发，我们提出引入"策略修改"来为智能体提供协调策略的机制。具体地，我们提出了一个新颖的框架AgentMixer，将联合完全可观测策略构造为各个部分可观测策略的非线性组合。为了实现分散式执行，可以通过模仿联合策略来得到各个部分策略。不幸的是，这种模仿学习可能会导致由于联合策略和个体策略之间的不匹配而导致的非对称学习失败。

    Centralized training with decentralized execution (CTDE) is widely employed to stabilize partially observable multi-agent reinforcement learning (MARL) by utilizing a centralized value function during training. However, existing methods typically assume that agents make decisions based on their local observations independently, which may not lead to a correlated joint policy with sufficient coordination. Inspired by the concept of correlated equilibrium, we propose to introduce a \textit{strategy modification} to provide a mechanism for agents to correlate their policies. Specifically, we present a novel framework, AgentMixer, which constructs the joint fully observable policy as a non-linear combination of individual partially observable policies. To enable decentralized execution, one can derive individual policies by imitating the joint policy. Unfortunately, such imitation learning can lead to \textit{asymmetric learning failure} caused by the mismatch between joint policy and indi
    
[^47]: MA2GCN: 使用轨迹数据进行交通预测的多邻接关系注意力图卷积网络

    MA2GCN: Multi Adjacency relationship Attention Graph Convolutional Networks for Traffic Prediction using Trajectory data. (arXiv:2401.08727v1 [cs.LG])

    [http://arxiv.org/abs/2401.08727](http://arxiv.org/abs/2401.08727)

    提出了一种新的交通拥堵预测模型，使用车辆轨迹数据以及多邻接关系注意力图卷积网络（MA2GCN）来预测交通拥堵情况，不依赖于传感器数据，提取灵活且准确的交通信息。

    

    交通拥堵问题不仅导致巨大的经济损失，而且严重危害城市环境。预测交通拥堵具有重要的实际意义。迄今为止，大多数研究都是基于不同路段上的传感器的历史数据来预测未来的交通流量和速度，分析某个道路段的交通拥堵情况。然而，由于传感器的固定位置，很难挖掘新的信息。另一方面，车辆轨迹数据更加灵活，可以根据需要提取交通信息。因此，我们提出了一种新的交通拥堵预测模型——多邻接关系注意力图卷积网络（MA2GCN）。该模型将车辆轨迹数据转化为网格形式的图结构化数据，并基于不同网格之间的流动性提出了车辆进出矩阵。同时，为了提高模型的性能，

    The problem of traffic congestion not only causes a large amount of economic losses, but also seriously endangers the urban environment. Predicting traffic congestion has important practical significance. So far, most studies have been based on historical data from sensors placed on different roads to predict future traffic flow and speed, to analyze the traffic congestion conditions of a certain road segment. However, due to the fixed position of sensors, it is difficult to mine new information. On the other hand, vehicle trajectory data is more flexible and can extract traffic information as needed. Therefore, we proposed a new traffic congestion prediction model - Multi Adjacency relationship Attention Graph Convolutional Networks(MA2GCN). This model transformed vehicle trajectory data into graph structured data in grid form, and proposed a vehicle entry and exit matrix based on the mobility between different grids. At the same time, in order to improve the performance of the model,
    
[^48]: 一个用于选择、评估和远程管理治疗的远程康复系统

    A Telerehabilitation System for the Selection, Evaluation and Remote Management of Therapies. (arXiv:2401.08721v1 [cs.HC])

    [http://arxiv.org/abs/2401.08721](http://arxiv.org/abs/2401.08721)

    本文介绍了一个创新的基于Kinect的远程康复系统，它具有知识提取功能和远程沉浸功能，可实现对患者的康复训练的选择、评估和远程管理。

    

    支持物理疗法在任何地方进行的远程康复系统可以帮助节省医疗费用，同时改善需要康复的用户的生活质量。本文的主要贡献是作为一个整体呈现创新的基于Kinect的远程康复系统（KiReS）所支持的所有功能。除了当前系统提供的功能外，它还处理了两个新功能，可以将其纳入其中，以便向新一代远程康复系统迈进。知识提取功能处理有关患者物理疗法记录和在名为TRHONT的本体中描述的治疗方案的知识，以选择适当的康复训练。远程沉浸功能通过双向实时多媒体通信，在进行远程康复时提供方便、有效和用户友好的体验。本本体包含了因康复系统而要求的知识。

    Telerehabilitation systems that support physical therapy sessions anywhere can help save healthcare costs while also improving the quality of life of the users that need rehabilitation. The main contribution of this paper is to present, as a whole, all the features supported by the innovative Kinect-based Telerehabilitation System (KiReS). In addition to the functionalities provided by current systems, it handles two new ones that could be incorporated into them, in order to give a step forward towards a new generation of telerehabilitation systems. The knowledge extraction functionality handles knowledge about the physical therapy record of patients and treatment protocols described in an ontology, named TRHONT, to select the adequate exercises for the rehabilitation of patients. The teleimmersion functionality provides a convenient, effective and user-friendly experience when performing the telerehabilitation, through a two-way real-time multimedia communication. The ontology contain
    
[^49]: 用于金属增材制造的迁移学习中的源数据子集选择

    Selecting Subsets of Source Data for Transfer Learning with Applications in Metal Additive Manufacturing. (arXiv:2401.08715v1 [cs.LG])

    [http://arxiv.org/abs/2401.08715](http://arxiv.org/abs/2401.08715)

    该论文提出了一种系统的方法来寻找适当的源数据子集，用于金属增材制造中的迁移学习。该方法基于源数据和目标数据集之间的相似性来选择子集，并通过两个相似度距离度量定义的Pareto frontier进行迭代选择。

    

    鉴于金属增材制造中数据不足的问题，已经采用迁移学习（TL）从源领域（例如完成的打印）中提取知识，以改善目标领域（例如新的打印）中的建模性能。当前的应用程序直接在迁移学习中使用所有可访问的源数据，而不考虑源数据和目标数据之间的相似性。本文提出了一种系统的方法，基于源数据和目标数据集之间的相似性来寻找适当的源数据子集，针对一组有限的目标领域数据。这种相似性通过空间和模型距离度量来刻画。基于Pareto frontier的源数据选择方法被开发出来，通过两个相似度距离度量定义的Pareto frontier上的源数据被迭代选择。该方法被集成到基于实例的TL方法（决策树回归模型）和基于模型的TL方法（微调的人工神经网络）中。

    Considering data insufficiency in metal additive manufacturing (AM), transfer learning (TL) has been adopted to extract knowledge from source domains (e.g., completed printings) to improve the modeling performance in target domains (e.g., new printings). Current applications use all accessible source data directly in TL with no regard to the similarity between source and target data. This paper proposes a systematic method to find appropriate subsets of source data based on similarities between the source and target datasets for a given set of limited target domain data. Such similarity is characterized by the spatial and model distance metrics. A Pareto frontier-based source data selection method is developed, where the source data located on the Pareto frontier defined by two similarity distance metrics are selected iteratively. The method is integrated into an instance-based TL method (decision tree regression model) and a model-based TL method (fine-tuned artificial neural network)
    
[^50]: 手语培训计划：ISENSE项目中的虚拟现实促进社会融合

    Training program on sign language: social inclusion through Virtual Reality in ISENSE project. (arXiv:2401.08714v1 [cs.HC])

    [http://arxiv.org/abs/2401.08714](http://arxiv.org/abs/2401.08714)

    ISENSE项目中的虚拟现实培训程序旨在通过提供技术工具培训听觉正常的人学习手语，从而促进社会融合。

    

    手语采用了结构化的手势和视觉动作，是对于听障或言语受损个体来说一种宝贵的日常交流手段。然而，对于听觉正常的人来说，掌握手语仍然较少见，能够理解手语的人更是稀缺。在学术背景下，父母和教师在支持聋哑学生从幼年时期开始学习手语方面起着至关重要的作用。近年来，在学习手语的教育工具中，虚拟现实（VR）的应用越来越多，因为已经证明它能够在学习过程中提高记忆、保持和注意力。ISENSE项目旨在为聋哑学生在学术生活中提供支持，通过在学术环境中向听觉正常的人群教授手语的不同技术工具。作为ISENSE项目的一部分，本研究旨在开发一个应用程序，用于教授西班牙手语和意大利手语。

    Structured hand gestures that incorporate visual motions and signs are used in sign language. Sign language is a valuable means of daily communication for individuals who are deaf or have speech impairments, but it is still rare among hearing people, and fewer are capable of understand it. Within the academic context, parents and teachers play a crucial role in supporting deaf students from childhood by facilitating their learning of sign language. In the last years, among all the teaching tools useful for learning sign language, the use of Virtual Reality (VR) has increased, as it has been demonstrated to improve retention, memory and attention during the learning process. The ISENSE project has been created to assist students with deafness during their academic life by proposing different technological tools for teaching sign language to the hearing community in the academic context. As part of the ISENSE project, this work aims to develop an application for Spanish and Italian sign 
    
[^51]: 助手、鹦鹉还是殖民式喇叭？ChatGPT隐喻对培养AI批判素养的作用研究

    Assistant, Parrot, or Colonizing Loudspeaker? ChatGPT Metaphors for Developing Critical AI Literacies. (arXiv:2401.08711v1 [cs.HC])

    [http://arxiv.org/abs/2401.08711](http://arxiv.org/abs/2401.08711)

    这项研究探讨了讨论AI隐喻如何帮助培养对AI系统和大型语言模型的理解，以及如何促进批判性AI素养的发展。通过分析隐喻并与其他人讨论，研究团队发现隐喻有助于对AI的伦理、公平和可访问性等问题进行思考，并评估了隐喻在是否促进拟人化方面的作用。

    

    本研究探讨了讨论AI隐喻如何帮助我们认识到影响我们对AI系统及其特别是大型语言模型（LLM）如ChatGPT的理解的框架，特别是在迫切需要教授“批判性AI素养”的情况下，隐喻的讨论提供了一个探究和对话的机会，为细微之处、趣味性和批评提供了空间。通过协作的自体民族志方法，我们分析了来自各种来源的隐喻，并根据七个问题对其进行了个别反思，然后进行了相互会议和讨论我们的解释。然后，我们分析了我们的反思如何有助于Selber的多元素素养框架中所描述的三种素养：功能性、批判性和修辞性。这些分析帮助我们探究了伦理、公平和可访问性与AI之间的关系。我们还评估了每个隐喻是否促进拟人化，以及这种隐喻在多大程度上暗示了AI的有感知能力。

    This study explores how discussing metaphors for AI can help build awareness of the frames that shape our understanding of AI systems, particularly large language models (LLMs) like ChatGPT. Given the pressing need to teach "critical AI literacy", discussion of metaphor provides an opportunity for inquiry and dialogue with space for nuance, playfulness, and critique. Using a collaborative autoethnographic methodology, we analyzed metaphors from a range of sources, and reflected on them individually according to seven questions, then met and discussed our interpretations. We then analyzed how our reflections contributed to the three kinds of literacies delineated in Selber's multiliteracies framework: functional, critical, and rhetorical. These allowed us to analyze questions of ethics, equity, and accessibility in relation to AI. We explored each metaphor along the dimension of whether or not it was promoting anthropomorphizing, and to what extent such metaphors imply that AI is sentie
    
[^52]: 关于组织病理学图像搜索的研究

    On Image Search in Histopathology. (arXiv:2401.08699v1 [eess.IV])

    [http://arxiv.org/abs/2401.08699](http://arxiv.org/abs/2401.08699)

    这篇论文综述了组织病理学图像搜索技术的最新发展，为计算病理学研究人员提供了简明的概述，旨在寻求有效、快速和高效的图像搜索方法。

    

    组织病理学的病理图像可以通过装有摄像头的显微镜或全扫描仪获取。利用相似性计算基于这些图像匹配患者，在研究和临床环境中具有重要潜力。最近搜索技术的进展使得可以对各种组织类型的细胞结构进行微妙的量化，促进比较，并在与诊断和治疗过的病例数据库进行比较时实现关于诊断、预后和新患者预测的推断。本文全面回顾了组织病理学图像搜索技术的最新发展，为计算病理学研究人员提供了简明的概述，以寻求有效、快速和高效的图像搜索方法。

    Pathology images of histopathology can be acquired from camera-mounted microscopes or whole slide scanners. Utilizing similarity calculations to match patients based on these images holds significant potential in research and clinical contexts. Recent advancements in search technologies allow for nuanced quantification of cellular structures across diverse tissue types, facilitating comparisons and enabling inferences about diagnosis, prognosis, and predictions for new patients when compared against a curated database of diagnosed and treated cases. In this paper, we comprehensively review the latest developments in image search technologies for histopathology, offering a concise overview tailored for computational pathology researchers seeking effective, fast and efficient image search methods in their work.
    
[^53]: 在高层次综合中使用GNN进行源-后向路质量预测的分层方法

    Hierarchical Source-to-Post-Route QoR Prediction in High-Level Synthesis with GNNs. (arXiv:2401.08696v1 [cs.AR])

    [http://arxiv.org/abs/2401.08696](http://arxiv.org/abs/2401.08696)

    该论文提出了一种在高层次综合中使用GNN进行源-后向路质量预测的分层方法。该方法通过建模流程、图构建方法和分层GNN训练和预测方法，能够有效预测QoR指标，并在设计空间探索中减少了运行时。

    

    高层次综合（HLS）通过避免RTL编程显着加快了硬件设计过程。然而，在优化过程中考虑后向路结果质量（QoR）时，HLS的周转时间显著增加。为了解决这个问题，我们提出了一种用于FPGA HLS的分层后向路QoR预测方法，具有以下特点：（1）直接从C / C ++程序估计延迟和后向路资源使用的建模流程；（2）有效表示源代码的控制和数据流图以及HLS伪指令的影响的图构建方法；（3）能够捕获循环层次影响的分层GNN训练和预测方法。实验结果显示，与最先进的GNN方法相比，我们的方法在不同类型的QoR指标下的预测误差小于10%，取得了巨大的改进。通过采用我们提出的方法论，在HLS的设计空间探索中减少了运行时。

    High-level synthesis (HLS) notably speeds up the hardware design process by avoiding RTL programming. However, the turnaround time of HLS increases significantly when post-route quality of results (QoR) are considered during optimization. To tackle this issue, we propose a hierarchical post-route QoR prediction approach for FPGA HLS, which features: (1) a modeling flow that directly estimates latency and post-route resource usage from C/C++ programs; (2) a graph construction method that effectively represents the control and data flow graph of source code and effects of HLS pragmas; and (3) a hierarchical GNN training and prediction method capable of capturing the impact of loop hierarchies. Experimental results show that our method presents a prediction error of less than 10% for different types of QoR metrics, which gains tremendous improvement compared with the state-of-the-art GNN methods. By adopting our proposed methodology, the runtime for design space exploration in HLS is shor
    
[^54]: 通过整合专家知识和可解释的数据驱动智能实现传染性角膜炎的协同临床诊断

    Enabling Collaborative Clinical Diagnosis of Infectious Keratitis by Integrating Expert Knowledge and Interpretable Data-driven Intelligence. (arXiv:2401.08695v1 [cs.AI])

    [http://arxiv.org/abs/2401.08695](http://arxiv.org/abs/2401.08695)

    通过整合专家知识和可解释的数据驱动智能，本研究提出了一种知识引导诊断模型（KGDM），用于协同临床诊断传染性角膜炎（IK）。KGDM通过与临床医生的互动，提供可视化推理过程，包括AI基于生物标记和具有相同诊断模式的病例。这一方法有望提高安全性和预测准确性。

    

    尽管基于数据驱动的人工智能在医学图像诊断方面表现出色，但其缺乏可解释性使得将“黑盒子”融入临床工作流程变得困难。为了使从数据中学到的诊断模式对临床医生可理解，我们开发了一个可解释的模型，即知识引导诊断模型（KGDM），它提供了一个可视化的推理过程，包含基于人工智能的生物标记和具有相同诊断模式的检索病例。通过人工智能与人类的互动，KGDM将临床医生的提示融入到解释推理中，从而可能提高安全性和更准确的预测。本研究探讨了KGDM在传染性角膜炎（IK）诊断中的性能、可解释性和临床实用性，IK 是角膜失明的主要原因。 KGDM 的分类性能在一组前瞻性验证数据集、外部测试数据集和一个公开数据集上进行了评估。

    Although data-driven artificial intelligence (AI) in medical image diagnosis has shown impressive performance in silico, the lack of interpretability makes it difficult to incorporate the "black box" into clinicians' workflows. To make the diagnostic patterns learned from data understandable by clinicians, we develop an interpretable model, knowledge-guided diagnosis model (KGDM), that provides a visualized reasoning process containing AI-based biomarkers and retrieved cases that with the same diagnostic patterns. It embraces clinicians' prompts into the interpreted reasoning through human-AI interaction, leading to potentially enhanced safety and more accurate predictions. This study investigates the performance, interpretability, and clinical utility of KGDM in the diagnosis of infectious keratitis (IK), which is the leading cause of corneal blindness. The classification performance of KGDM is evaluated on a prospective validation dataset, an external testing dataset, and an publicly
    
[^55]: 结合置信度引导和基于样本的方法用于消除误信息中的不确定性量化

    Combining Confidence Elicitation and Sample-based Methods for Uncertainty Quantification in Misinformation Mitigation. (arXiv:2401.08694v1 [cs.CL])

    [http://arxiv.org/abs/2401.08694](http://arxiv.org/abs/2401.08694)

    本研究提出了一种结合置信度引导和基于样本的方法的不确定性量化框架，用于解决误信息消除中的幻觉和过度自信的预测问题，并提出了混合框架以提供更好的不确定性估计。

    

    大型语言模型已经成为解决误信息消除的主要候选方案。然而，现有方法在幻觉和过度自信的预测方面存在问题。我们提出了一种不确定性量化框架，利用直接置信度引导和基于样本的一致性方法，为自然语言处理误信息消除解决方案提供更好的校准。首先，我们研究基于样本一致性方法的校准性，该方法利用样本规模和随机水平的一致性的不同特征。接下来，我们评估了鲁棒的数字化口头提示在单步和两步置信度引导过程中的性能和分布变化。我们还比较了相同提示在不同版本的GPT和不同数字尺度下的性能。最后，我们结合基于样本一致性和数字化方法，提出了一个混合框架，为GPT模型提供更好的不确定性估计。

    Large Language Models have emerged as prime candidates to tackle misinformation mitigation. However, existing approaches struggle with hallucinations and overconfident predictions. We propose an uncertainty quantification framework that leverages both direct confidence elicitation and sampled-based consistency methods to provide better calibration for NLP misinformation mitigation solutions. We first investigate the calibration of sample-based consistency methods that exploit distinct features of consistency across sample sizes and stochastic levels. Next, we evaluate the performance and distributional shift of a robust numeric verbalization prompt across single vs. two-step confidence elicitation procedure. We also compare the performance of the same prompt with different versions of GPT and different numerical scales. Finally, we combine the sample-based consistency and verbalized methods to propose a hybrid framework that yields a better uncertainty estimation for GPT models. Overal
    
[^56]: 使用增强型大型语言模型实现零样本RTL代码生成

    Zero-Shot RTL Code Generation with Attention Sink Augmented Large Language Models. (arXiv:2401.08683v1 [cs.AR])

    [http://arxiv.org/abs/2401.08683](http://arxiv.org/abs/2401.08683)

    本文探讨了使用大型语言模型在硬件设计中快速生成RTL代码的可能性，并展示了新的注意力机制如何提供功能、优化和符合行业标准的RTL代码。

    

    传统上，硬件设计和优化需耗费大量资源，需要相当专业知识，并依赖于已建立的设计自动化工具。本文讨论了利用大型语言模型来简化硬件设计中的代码生成过程的可能性。与之前的研究不同，本文旨在使用大型语言模型，通过一个单一提示接受高层设计规范，生成相应的寄存器传输级（RTL）代码。能够在RTL代码生成中使用大型语言模型不仅加快了设计迭代周期，还便于探索传统技术难以处理的设计空间的计算挑战。通过我们的评估，我们展示了现有注意力机制的不足，并介绍了语言模型在使用一种新的注意力机制时产生功能、优化且符合行业标准的RTL代码的能力。

    The design and optimization of hardware have traditionally been resource-intensive, demanding considerable expertise and dependence on established design automation tools. This paper discusses the possibility of exploiting large language models to streamline the code generation process in hardware design. In contrast to earlier studies, this paper aims to use large language models that accepts high-level design specifications through a single prompt to generate corresponding Register-Transfer Level (RTL) code. The ability to use large language models on RTL code generation not only expedites design iteration cycles but also facilitates the exploration of design spaces that have computational challenges for conventional techniques. Through our evaluation, we demonstrate the shortcoming of existing attention mechanisms, and present the abilities of language models to produce functional, optimized, and industry-standard compliant RTL code when a novel attention mechanism is used. These fi
    
[^57]: 概念对齐（arXiv：2401.08672v1 [cs.LG]）

    Concept Alignment. (arXiv:2401.08672v1 [cs.LG])

    [http://arxiv.org/abs/2401.08672](http://arxiv.org/abs/2401.08672)

    在AI对齐的讨论中，我们强调了概念对齐的重要性，认为在对齐价值观之前，AI系统和人类必须对其理解世界所使用的概念进行对齐。我们整合了哲学、认知科学和深度学习的思想，并提出了实现共享概念的机会和挑战。

    

    AI对齐（人类和AI系统之间的对齐）的讨论主要集中在价值对齐上，广义上指的是创建与人类价值观相同的AI系统。我们认为，在我们尝试对齐价值观之前，AI系统和人类对于理解世界所使用的概念必须首先对齐。我们整合了哲学、认知科学和深度学习的思想，解释了人类和机器之间需要概念对齐而不仅仅是价值对齐的必要性。我们总结了目前人类和机器学习概念的现有方法，并概述了实现共享概念的机会和挑战。最后，我们解释了如何利用认知科学和AI研究中已经开发的工具加速概念对齐的进展。

    Discussion of AI alignment (alignment between humans and AI systems) has focused on value alignment, broadly referring to creating AI systems that share human values. We argue that before we can even attempt to align values, it is imperative that AI systems and humans align the concepts they use to understand the world. We integrate ideas from philosophy, cognitive science, and deep learning to explain the need for concept alignment, not just value alignment, between humans and machines. We summarize existing accounts of how humans and machines currently learn concepts, and we outline opportunities and challenges in the path towards shared concepts. Finally, we explain how we can leverage the tools already being developed in cognitive science and AI research to accelerate progress towards concept alignment.
    
[^58]: 多卡车多分段需求路径的深度强化学习在车辆路径问题中的应用

    Deep Reinforcement Learning for Multi-Truck Vehicle Routing Problems with Multi-Leg Demand Routes. (arXiv:2401.08669v1 [cs.LG])

    [http://arxiv.org/abs/2401.08669](http://arxiv.org/abs/2401.08669)

    本研究针对多卡车多分段需求路径的车辆路径问题，通过对现有的编码器-解码器注意力模型进行扩展，实现了在工业供应链物流中使用深度强化学习的有效策略。

    

    深度强化学习已被证明在解决一些车辆路径问题时非常有效，特别是在使用编码器-解码器注意力机制生成的策略时。然而，对于一些相对简单的问题实例，这些技术已经取得了相当大的成功，但对于一些仍未得到研究和非常复杂的车辆路径问题变体，尚未证明有有效的强化学习方法可用。本文聚焦于一种这样的车辆路径问题变体，其中包含多辆卡车和多分段路径要求。在这些问题中，需求需要沿着节点序列移动，而不仅仅是从起点到终点。为了使深度强化学习成为适用于实际工业规模的供应链物流的有效策略，我们对现有的编码器-解码器注意力模型进行了新扩展，使其能处理多卡车和多分段路径要求。我们的模型具有这样的优势，可以在小规模数据训练下进行，并能在工业供应链物流中进行实际应用。

    Deep reinforcement learning (RL) has been shown to be effective in producing approximate solutions to some vehicle routing problems (VRPs), especially when using policies generated by encoder-decoder attention mechanisms. While these techniques have been quite successful for relatively simple problem instances, there are still under-researched and highly complex VRP variants for which no effective RL method has been demonstrated. In this work we focus on one such VRP variant, which contains multiple trucks and multi-leg routing requirements. In these problems, demand is required to move along sequences of nodes, instead of just from a start node to an end node. With the goal of making deep RL a viable strategy for real-world industrial-scale supply chain logistics, we develop new extensions to existing encoder-decoder attention models which allow them to handle multiple trucks and multi-leg routing requirements. Our models have the advantage that they can be trained for a small number 
    
[^59]: 将大型语言模型应用于教育：基本能力、潜力和挑战

    Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges. (arXiv:2401.08664v1 [cs.AI])

    [http://arxiv.org/abs/2401.08664](http://arxiv.org/abs/2401.08664)

    本文回顾了针对教育能力的大型语言模型研究，包括数学、写作、编程、推理和基于知识的问答，旨在探索其在构建下一代智能教育系统中的潜力和挑战。

    

    在线教育平台利用互联网分发教育资源，旨在提供便捷的教育，但往往在与学生的实时交流方面存在不足。由于需要解决学生在学习过程中遇到的多样化障碍的挑战，它们经常难以提供个性化的教育资源。最近出现的大型语言模型（LLMs），如ChatGPT，提供了通过理解个体请求解决这一问题的可能性。虽然LLMs在各个领域都取得了成功，但基于LLM的教育系统的构建仍然面临着广泛的教育技能要求。本文回顾了与教育能力相关的近期出现的LLM研究，包括数学、写作、编程、推理和基于知识的问答，旨在探索它们在构建下一代智能教育系统方面的潜力。

    Online education platforms, leveraging the internet to distribute education resources, seek to provide convenient education but often fall short in real-time communication with students. They often struggle to offer personalized education resources due to the challenge of addressing the diverse obstacles students encounter throughout their learning journey. Recently, the emergence of large language models (LLMs), such as ChatGPT, offers the possibility for resolving this issue by comprehending individual requests. Although LLMs have been successful in various fields, creating an LLM-based education system is still challenging for the wide range of educational skills required. This paper reviews the recently emerged LLM researches related to educational capabilities, including mathematics, writing, programming, reasoning, and knowledge-based question answering, with the aim to explore their potential in constructing the next-generation intelligent education system. Based on the current 
    
[^60]: 用有限的飞行员示范数据进行稳健敏捷飞行器控制的集成模仿和强化学习方法

    An Integrated Imitation and Reinforcement Learning Methodology for Robust Agile Aircraft Control with Limited Pilot Demonstration Data. (arXiv:2401.08663v1 [cs.AI])

    [http://arxiv.org/abs/2401.08663](http://arxiv.org/abs/2401.08663)

    本文提出了一种使用有限的飞行员示范数据的集成模仿和强化学习方法，用于建立适用于广泛条件的敏捷飞行器的数据驱动机动生成模型，以解决构建模型所需的大量真实数据的时间和成本问题，并能够泛化到其他飞行条件。

    

    本文提出了一种方法，用于构建适用于敏捷飞行器在广泛的平衡条件和飞行器模型参数下可以泛化的数据驱动机动生成模型。机动生成模型在飞行器原型的测试和评估中起着关键作用，能够提供关于飞行器的机动性和敏捷性的见解。然而，构建这些模型通常需要大量的真实飞行员数据，这可能耗时且昂贵。此外，使用有限数据构建的模型往往难以在原始数据集所包含的特定飞行条件之外进行泛化。为了解决这些挑战，我们提出了一种混合架构，利用一个称为源模型的仿真模型。这个开源敏捷飞行器模拟器与目标飞行器具有相似的动力学特性，并允许我们生成无限的数据来构建代理机动生成模型。然后，我们对该模型进行微调。

    In this paper, we present a methodology for constructing data-driven maneuver generation models for agile aircraft that can generalize across a wide range of trim conditions and aircraft model parameters. Maneuver generation models play a crucial role in the testing and evaluation of aircraft prototypes, providing insights into the maneuverability and agility of the aircraft. However, constructing the models typically requires extensive amounts of real pilot data, which can be time-consuming and costly to obtain. Moreover, models built with limited data often struggle to generalize beyond the specific flight conditions covered in the original dataset. To address these challenges, we propose a hybrid architecture that leverages a simulation model, referred to as the source model. This open-source agile aircraft simulator shares similar dynamics with the target aircraft and allows us to generate unlimited data for building a proxy maneuver generation model. We then fine-tune this model t
    
[^61]: 工业和学术界中的自动驾驶端到端规划：2022-2023年的综述

    End-To-End Planning of Autonomous Driving in Industry and Academia: 2022-2023. (arXiv:2401.08658v1 [cs.RO])

    [http://arxiv.org/abs/2401.08658](http://arxiv.org/abs/2401.08658)

    这篇论文总结了工业和学术界中的自动驾驶端到端规划方法，包括特斯拉FSD V12、Momenta 2023、Horizon Robotics 2023、Motional RoboTaxi 2022、Woven Planet（丰田）：城市驾驶员和Nvidia，并回顾了最新的学术研究。这篇文章提供了2022-2023年端到端规划的最新结构和快速学习，并适用于初学者和高级研究人员。

    

    本文旨在对目前在工业和学术界报告的包括详细技术在内的方法进行快速回顾。具体而言，本文回顾了包括特斯拉FSD V12、Momenta 2023、Horizon Robotics 2023、Motional RoboTaxi 2022、Woven Planet（丰田）：城市驾驶员和Nvidia在内的端到端规划。此外，我们还回顾了调查自动驾驶端到端规划的最新学术研究。本文提供了2022-2023年端到端规划的最新结构和快速学习，为初学者提供了入门材料，供其了解工业和学术界中的端到端自动驾驶规划的最新发展，同时也为高级研究人员提供了补充资料。

    This paper aims to provide a quick review of the methods including the technologies in detail that are currently reported in industry and academia. Specifically, this paper reviews the end-to-end planning, including Tesla FSD V12, Momenta 2023, Horizon Robotics 2023, Motional RoboTaxi 2022, Woven Planet (Toyota): Urban Driver, and Nvidia. In addition, we review the state-of-the-art academic studies that investigate end-to-end planning of autonomous driving. This paper provides readers with a concise structure and fast learning of state-of-the-art end-to-end planning for 2022-2023. This article provides a meaningful overview as introductory material for beginners to follow the state-of-the-art end-to-end planning of autonomous driving in industry and academia, as well as supplementary material for advanced researchers.
    
[^62]: SAiD: 使用扩散方法驱动的语音驱动表情动画

    SAiD: Speech-driven Blendshape Facial Animation with Diffusion. (arXiv:2401.08655v1 [cs.CV])

    [http://arxiv.org/abs/2401.08655](http://arxiv.org/abs/2401.08655)

    提出了一种使用扩散模型（SAiD）驱动的语音驱动的三维面部动画方法，通过轻量级的Transformer-based U-Net模型和音频与视觉的交叉模态对齐偏差，实现了较好的唇部同步和更多样化的唇部运动。

    

    尽管进行了大量研究，但由于缺乏大规模的视听数据集，语音驱动的三维面部动画仍然具有挑战性。大多数过去的工作通常采用最小二乘法在小数据集上学习回归模型，但在从语音生成各种唇部动作方面遇到困难，并且需要大量精细调整生成的输出结果。为了解决这些问题，我们提出了一种使用扩散模型（SAiD）驱动的语音驱动的三维面部动画，这是一种轻量级的基于Transformer的U-Net模型，具有音频和视觉之间的交叉模态对齐偏差，以增强唇部同步。此外，我们还介绍了BlendVOCA，这是一种语音音频和混合形状面部模型参数对的基准数据集，以解决公共资源的缺乏问题。我们的实验结果表明，所提出的方法在唇部同步方面达到了与基线相当或更好的性能，确保了更多样化的唇部运动，并简化了动画流程。

    Speech-driven 3D facial animation is challenging due to the scarcity of large-scale visual-audio datasets despite extensive research. Most prior works, typically focused on learning regression models on a small dataset using the method of least squares, encounter difficulties generating diverse lip movements from speech and require substantial effort in refining the generated outputs. To address these issues, we propose a speech-driven 3D facial animation with a diffusion model (SAiD), a lightweight Transformer-based U-Net with a cross-modality alignment bias between audio and visual to enhance lip synchronization. Moreover, we introduce BlendVOCA, a benchmark dataset of pairs of speech audio and parameters of a blendshape facial model, to address the scarcity of public resources. Our experimental results demonstrate that the proposed approach achieves comparable or superior performance in lip synchronization to baselines, ensures more diverse lip movements, and streamlines the animati
    
[^63]: MLCommons云遮挡基准测试与提前停止

    MLCommons Cloud Masking Benchmark with Early Stopping. (arXiv:2401.08636v1 [cs.DC])

    [http://arxiv.org/abs/2401.08636](http://arxiv.org/abs/2401.08636)

    本文报告了MLCommons科学工作组在云遮挡基准测试上的工作，包括对云遮挡基准测试的参考实现的修改，以实现提前停止。

    

    本文报告了MLCommons科学工作组在云遮挡基准测试上的工作。 MLCommons是一个联盟，开发和维护几个科学基准测试，旨在促进人工智能的发展。这些基准测试在纽约大学和弗吉尼亚大学的高性能计算（HPC）集群以及普通桌面上进行。我们提供了云遮挡基准测试的描述，并对我们在MLCommons基准测试实验中的提交进行了总结。它包括对云遮挡基准测试的参考实现的修改，以实现提前停止。该基准测试通过自定义批处理脚本在纽约大学的HPC上执行，该批处理脚本通过批处理队列系统运行各种实验，并允许对训练轮数进行变化。我们的提交包括修改后的代码，自定义的批处理脚本来修改训练轮数，文档和基准测试结果。

    In this paper, we report on work performed for the MLCommons Science Working Group on the cloud masking benchmark. MLCommons is a consortium that develops and maintains several scientific benchmarks that aim to benefit developments in AI. The benchmarks are conducted on the High Performance Computing (HPC) Clusters of New York University and University of Virginia, as well as a commodity desktop. We provide a description of the cloud masking benchmark, as well as a summary of our submission to MLCommons on the benchmark experiment we conducted. It includes a modification to the reference implementation of the cloud masking benchmark enabling early stopping. This benchmark is executed on the NYU HPC through a custom batch script that runs the various experiments through the batch queuing system while allowing for variation on the number of epochs trained. Our submission includes the modified code, a custom batch script to modify epochs, documentation, and the benchmark results. We repor
    
[^64]: 将质量多样性与描述符条件加强学习相结合

    Synergizing Quality-Diversity with Descriptor-Conditioned Reinforcement Learning. (arXiv:2401.08632v1 [cs.NE])

    [http://arxiv.org/abs/2401.08632](http://arxiv.org/abs/2401.08632)

    将质量多样性优化与描述符条件加强学习相结合，以克服进化算法的局限性，并在生成既多样又高性能的解决方案集合方面取得成功。

    

    智能的基本特征之一是找到新颖和有创造性的解决方案来解决给定的挑战或适应未预料到的情况。质量多样性优化是一类进化算法，可以生成既多样又高性能的解决方案集合。其中，MAP-Elites是一个著名的例子，已成功应用于各种领域，包括进化机器人学。然而，MAP-Elites通过遗传算法的随机突变进行发散搜索，因此仅限于进化低维解决方案的种群。PGA-MAP-Elites通过受深度强化学习启发的基于梯度的变异算子克服了这一限制，从而实现了大型神经网络的进化。尽管在许多环境中性能优秀，但PGA-MAP-Elites在一些任务中失败，其中基于梯度的变异算子的收敛搜索阻碍了多样性。在这项工作中，我们...

    A fundamental trait of intelligence involves finding novel and creative solutions to address a given challenge or to adapt to unforeseen situations. Reflecting this, Quality-Diversity optimization is a family of Evolutionary Algorithms, that generates collections of both diverse and high-performing solutions. Among these, MAP-Elites is a prominent example, that has been successfully applied to a variety of domains, including evolutionary robotics. However, MAP-Elites performs a divergent search with random mutations originating from Genetic Algorithms, and thus, is limited to evolving populations of low-dimensional solutions. PGA-MAP-Elites overcomes this limitation using a gradient-based variation operator inspired by deep reinforcement learning which enables the evolution of large neural networks. Although high-performing in many environments, PGA-MAP-Elites fails on several tasks where the convergent search of the gradient-based variation operator hinders diversity. In this work, we
    
[^65]: Wake-Sleep Consolidated Learning（WSCL）的研究

    Wake-Sleep Consolidated Learning. (arXiv:2401.08623v1 [cs.NE])

    [http://arxiv.org/abs/2401.08623](http://arxiv.org/abs/2401.08623)

    Wake-Sleep Consolidated Learning（WSCL）是一种借鉴人脑觉醒-睡眠阶段的学习策略，用于改进深度神经网络在连续学习中的视觉分类任务。该方法通过觉醒和睡眠阶段之间的同步学习来实现持续学习，觉醒阶段中模型适应感官输入并利用动态参数冻结机制保持稳定，睡眠阶段根据NREM和REM阶段对模型的突触权重进行巩固和调整，强化重要连接并削弱不重要的连接。

    

    我们提出了 Wake-Sleep Consolidated Learning（WSCL）的学习策略，利用互补学习系统理论和人脑的觉醒-睡眠阶段来改进深度神经网络在连续学习设置中的视觉分类任务表现。我们的方法通过觉醒和睡眠阶段之间的同步学习来实现持续学习。在觉醒阶段，模型暴露于感官输入并调整其表示，通过动态参数冻结机制确保稳定性，并将情节记忆存储在短期临时记忆中（类似于海马体中的情况）。在睡眠阶段，训练过程分为NREM和REM阶段。在NREM阶段，模型的突触权重利用来自短期和长期记忆的回放样本进行巩固，并激活突触可塑性机制，强化重要连接并削弱不重要的连接。在REM阶段，模型...

    We propose Wake-Sleep Consolidated Learning (WSCL), a learning strategy leveraging Complementary Learning System theory and the wake-sleep phases of the human brain to improve the performance of deep neural networks for visual classification tasks in continual learning settings. Our method learns continually via the synchronization between distinct wake and sleep phases. During the wake phase, the model is exposed to sensory input and adapts its representations, ensuring stability through a dynamic parameter freezing mechanism and storing episodic memories in a short-term temporary memory (similarly to what happens in the hippocampus). During the sleep phase, the training process is split into NREM and REM stages. In the NREM stage, the model's synaptic weights are consolidated using replayed samples from the short-term and long-term memory and the synaptic plasticity mechanism is activated, strengthening important connections and weakening unimportant ones. In the REM stage, the model
    
[^66]: 当SAM遇见无监督领域自适应语义分割在智能车辆中

    SAM4UDASS: When SAM Meets Unsupervised Domain Adaptive Semantic Segmentation in Intelligent Vehicles. (arXiv:2401.08604v1 [cs.CV])

    [http://arxiv.org/abs/2401.08604](http://arxiv.org/abs/2401.08604)

    SAM4UDASS是一种在自训练无监督领域自适应语义分割方法中使用Segment Anything Model（SAM）的新方法，旨在解决生成精确伪标签的挑战。

    

    语义分割在使智能车辆理解其周围环境方面发挥着关键作用。然而，基于深度学习的方法通常在领域转移场景中表现不佳，原因是缺乏用于训练的标记数据。无监督领域自适应（UDA）技术已经出现，以弥合不同驾驶场景之间的差距，提高无标注目标环境上的模型性能。尽管自训练UDA方法已经取得了最先进的结果，但精确伪标签的生成仍然是一个挑战。这些伪标签往往偏向于多数类别，从而牺牲了罕见类别或类似交通灯和标志等小物体的性能。为了解决这个挑战，我们介绍了SAM4UDASS，一种将Segment Anything Model（SAM）结合到自训练UDA方法中以提升伪标签的新方法。它涉及语义引导的蒙版标签，通过给无标签的SAM蒙版分配语义标签来细化伪标签。

    Semantic segmentation plays a critical role in enabling intelligent vehicles to comprehend their surrounding environments. However, deep learning-based methods usually perform poorly in domain shift scenarios due to the lack of labeled data for training. Unsupervised domain adaptation (UDA) techniques have emerged to bridge the gap across different driving scenes and enhance model performance on unlabeled target environments. Although self-training UDA methods have achieved state-of-the-art results, the challenge of generating precise pseudo-labels persists. These pseudo-labels tend to favor majority classes, consequently sacrificing the performance of rare classes or small objects like traffic lights and signs. To address this challenge, we introduce SAM4UDASS, a novel approach that incorporates the Segment Anything Model (SAM) into self-training UDA methods for refining pseudo-labels. It involves Semantic-Guided Mask Labeling, which assigns semantic labels to unlabeled SAM masks usin
    
[^67]: 基于改进的DPC算法的点云数据分割和三维重建split wire的自动提取

    Automatic extraction and 3D reconstruction of split wire from point cloud data based on improved DPC algorithm. (arXiv:2401.08587v1 [cs.CV])

    [http://arxiv.org/abs/2401.08587](http://arxiv.org/abs/2401.08587)

    该论文提出了基于改进的DPC算法的自动点云数据分割和三维重建方法，通过计算云点中每个点的相对坐标，使用集合算法分析分割线数量，然后使用拟合方法得到清晰的分界线。以下是该论文的贡献。

    

    为了解决DPC算法改进的点云数据分割问题，提出了关于点云数据分割线的自动分离和三维重建的研究。首先计算云点中每个点的相对坐标。其次，计划采用基于相对集合的DPC群算法，分析分割线的数量以确定云内容中的所有部分。最后，使用最小二乘法拟合每个分割线。最终得到的分割子导线的云点具有清晰的分界线，相邻分割子导线之间的距离为0.45 m，由正方形的四个顶点划分。

    In order to solve the problem of point cloud data splitting improved by DPC algorithm, a research on automatic separation and 3D reconstruction of point cloud data split lines is proposed. First, the relative coordinates of each point in the cloud point are calculated. Second, it is planned to develop a relative ensemble-based DPC swarm algorithm for analyzing the number of separation lines to determine all parts in the cloud content. Finally, fit each separator using the least squares method. iron. The cloud point of the resulting split subconductors has a clear demarcation line, and the distance between adjacent split subconductors is 0.45 m, divided by the four vertices of the square.
    
[^68]: 从概念空间到量子概念：形式化和学习结构化概念模型

    From Conceptual Spaces to Quantum Concepts: Formalising and Learning Structured Conceptual Models. (arXiv:2401.08585v1 [q-bio.NC])

    [http://arxiv.org/abs/2401.08585](http://arxiv.org/abs/2401.08585)

    本文提出了一个新的建模框架，可以使用范畴论的推广来建立结构化概念，并展示了如何通过自动学习从数据中获取概念表示。使用范畴论和弦图描述量子过程有助于揭示该方法的关键特点。

    

    在本文中，我们提出了一个新的建模框架，使用概念空间的范畴论推广来建立结构化概念，并展示了如何通过两种非常不同的实例（经典和量子）自动地从数据中学习概念表示。该工作的一个贡献是对我们框架进行了彻底的范畴论形式化。我们声称范畴论的使用，特别是使用弦图来描述量子过程，有助于阐明我们方法的一些最重要的特点。我们建立在Gardenfors的概念空间的经典框架之上，该框架通过使用凸空间几何地建模认知，并通过称为域的简单空间分解。我们展示了如何从简单形状的图像中学习形状、颜色、大小和位置等域的概念，其中概念在经典实现中被表示为高斯分布，而在量子实现中被表示为量子态。

    In this article we present a new modelling framework for structured concepts using a category-theoretic generalisation of conceptual spaces, and show how the conceptual representations can be learned automatically from data, using two very different instantiations: one classical and one quantum. A contribution of the work is a thorough category-theoretic formalisation of our framework. We claim that the use of category theory, and in particular the use of string diagrams to describe quantum processes, helps elucidate some of the most important features of our approach. We build upon Gardenfors' classical framework of conceptual spaces, in which cognition is modelled geometrically through the use of convex spaces, which in turn factorise in terms of simpler spaces called domains. We show how concepts from the domains of shape, colour, size and position can be learned from images of simple shapes, where concepts are represented as Gaussians in the classical implementation, and quantum ef
    
[^69]: Nahid: 基于人工智能算法的完全自动手术

    Nahid: AI-based Algorithm for operating fully-automatic surgery. (arXiv:2401.08584v1 [cs.CV])

    [http://arxiv.org/abs/2401.08584](http://arxiv.org/abs/2401.08584)

    本文提出了一种基于软件和计算机视觉技术的全自动手术方法，能够自动诊断和治疗孤立性卵巢子宫内膜异位症。

    

    在本文中，首次提出了一种基于软件和计算机视觉技术的全自动手术方法。然后，对医疗手术的计算机化优势和挑战进行了研究。最后，对孤立性卵巢子宫内膜异位症相关的手术进行了研究，并基于提出的方法，提出了一种更详细的算法，能够在手术过程中自动诊断和治疗该疾病，其中使用了一个U-net模型来检测手术过程中的子宫内膜异位症。

    In this paper, for the first time, a method is presented that can provide a fully automated surgery based on software and computer vision techniques. Then, the advantages and challenges of computerization of medical surgery are examined. Finally, the surgery related to isolated ovarian endometriosis disease has been examined, and based on the presented method, a more detailed algorithm is presented that is capable of automatically diagnosing and treating this disease during surgery as proof of our proposed method where a U-net is trained to detect the endometriosis during surgery.
    
[^70]: 时间嵌入：从时空数据中进行可扩展的自监督时序表示学习，用于多模态计算机视觉

    Temporal Embeddings: Scalable Self-Supervised Temporal Representation Learning from Spatiotemporal Data for Multimodal Computer Vision. (arXiv:2401.08581v1 [cs.CV])

    [http://arxiv.org/abs/2401.08581](http://arxiv.org/abs/2401.08581)

    该论文提出了一种自监督的时间嵌入方法，可以将地理活动的时间模式与土地利用类型相对应。通过将时间序列信号转换到频域并压缩为语义分割所需的图像通道，时间嵌入可以有效地表示时间序列数据，并用于多个地理空间任务。

    

    地理活动的时间模式与土地利用类型之间存在相关性。提出了一种新颖的自监督方法，通过压缩自编码器将时间序列信号转换到频域，并将其转换为图像通道，用于下游地理空间任务的深度语义分割。实验表明，时间嵌入是时间序列数据的语义有意义的表示，对于分类住宅区和商业区等不同任务具有有效性。

    There exists a correlation between geospatial activity temporal patterns and type of land use. A novel self-supervised approach is proposed to stratify landscape based on mobility activity time series. First, the time series signal is transformed to the frequency domain and then compressed into task-agnostic temporal embeddings by a contractive autoencoder, which preserves cyclic temporal patterns observed in time series. The pixel-wise embeddings are converted to image-like channels that can be used for task-based, multimodal modeling of downstream geospatial tasks using deep semantic segmentation. Experiments show that temporal embeddings are semantically meaningful representations of time series data and are effective across different tasks such as classifying residential area and commercial areas. Temporal embeddings transform sequential, spatiotemporal motion trajectory data into semantically meaningful image-like tensor representations that can be combined (multimodal fusion) wit
    
[^71]: 基于曲线的神经风格迁移

    Curve-based Neural Style Transfer. (arXiv:2401.08579v1 [cs.CV])

    [http://arxiv.org/abs/2401.08579](http://arxiv.org/abs/2401.08579)

    该研究提出了一种基于曲线的神经风格迁移方法，通过参数化形状编辑和精确的风格提取，解决了传统方法在处理二进制草图转换时面临的挑战，从而提升了设计表达能力和风格迁移的实践。

    

    本研究提出了一种专为基于曲线设计草图设计的参数化风格迁移框架。通过利用参数化形状编辑规则、高效的曲线到像素转换技术以及在ImageNet-Sketch上对VGG19进行微调，有效解决了神经风格迁移方法在处理二进制草图转换时面临的传统挑战，并提高了VGG19在特征金字塔网络中对风格的精确提取作用。通过将直观的基于曲线的图像与基于规则的编辑相结合，该研究有潜力显著提升设计表达能力，并在产品设计领域中推动风格迁移的实践。

    This research presents a new parametric style transfer framework specifically designed for curve-based design sketches. In this research, traditional challenges faced by neural style transfer methods in handling binary sketch transformations are effectively addressed through the utilization of parametric shape-editing rules, efficient curve-to-pixel conversion techniques, and the fine-tuning of VGG19 on ImageNet-Sketch, enhancing its role as a feature pyramid network for precise style extraction. By harmonizing intuitive curve-based imagery with rule-based editing, this study holds the potential to significantly enhance design articulation and elevate the practice of style transfer within the realm of product design.
    
[^72]: 利用层间专家亲和性加速混合专家模型推理

    Exploiting Inter-Layer Expert Affinity for Accelerating Mixture-of-Experts Model Inference. (arXiv:2401.08383v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.08383](http://arxiv.org/abs/2401.08383)

    本文提出了一种称为ExFlow的轻量级优化技术，通过利用层间专家亲和性，大大加速了混合专家模型推理的过程。

    

    在像生成预训练变压器这样的大型语言模型中，混合专家范式已经成为增强模型表达能力和准确性的强大技术。然而，将GPT MoE模型部署到分布式系统上进行并行推理面临着重大挑战，主要是由于专家路由和聚合所需的广泛Alltoall通信。这种通信瓶颈加剧了已经复杂的计算环境，从而妨碍了高性能计算资源的高效利用。在本文中，我们提出了一种轻量级的优化技术ExFlow，以大大加速这些MoE模型的推理。我们从利用层间专家亲和性的新视角来减轻通信开销。与之前的方法不同的是，我们的解决方案可以直接应用于预训练的MoE模型，无需任何微调或精度下降。通过提出一个上下文连贯的专家并行性

    In large language models like the Generative Pre-trained Transformer, the Mixture of Experts paradigm has emerged as a powerful technique for enhancing model expressiveness and accuracy. However, deploying GPT MoE models for parallel inference on distributed systems presents significant challenges, primarily due to the extensive Alltoall communication required for expert routing and aggregation. This communication bottleneck exacerbates the already complex computational landscape, hindering the efficient utilization of high-performance computing resources. In this paper, we propose a lightweight optimization technique called ExFlow, to largely accelerate the inference of these MoE models. We take a new perspective on alleviating the communication overhead by exploiting the inter-layer expert affinity. Unlike previous methods, our solution can be directly applied to pre-trained MoE models without any fine-tuning or accuracy degradation. By proposing a context-coherent expert parallelism
    
[^73]: 一种可解释的多标签音频分割代理模型

    An Explainable Proxy Model for Multiabel Audio Segmentation. (arXiv:2401.08268v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2401.08268](http://arxiv.org/abs/2401.08268)

    该论文提出了一种可解释的多标签音频分割代理模型，通过使用非负矩阵分解将嵌入映射到频域，实现了对语音活动、音乐、噪音和重叠语音的同时检测，并且具有强大的可解释性特性。

    

    音频信号分割是自动音频索引的关键任务。它包括在信号中检测类同质片段的边界。在许多应用中，可解释的人工智能是透明决策的重要过程。在本文中，我们提出了一种可解释的多标签分割模型，同时解决了语音活动（SAD）、音乐（MD）、噪音（ND）和重叠语音检测（OSD）。该代理模型使用非负矩阵分解（NMF）将用于分割的嵌入映射到频域。在两个数据集上进行的实验表明，与预训练的黑盒模型相比表现相似，同时显示出强大的可解释性功能。具体而言，决策所使用的频率区间可以在片段级别（局部解释）和全局级别（类原型）上轻松识别出来。

    Audio signal segmentation is a key task for automatic audio indexing. It consists of detecting the boundaries of class-homogeneous segments in the signal. In many applications, explainable AI is a vital process for transparency of decision-making with machine learning. In this paper, we propose an explainable multilabel segmentation model that solves speech activity (SAD), music (MD), noise (ND), and overlapped speech detection (OSD) simultaneously. This proxy uses the non-negative matrix factorization (NMF) to map the embedding used for the segmentation to the frequency domain. Experiments conducted on two datasets show similar performances as the pre-trained black box model while showing strong explainability features. Specifically, the frequency bins used for the decision can be easily identified at both the segment level (local explanations) and global level (class prototypes).
    
[^74]: 在Transformer模型中实现进位算法

    Carrying over algorithm in transformers. (arXiv:2401.07993v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.07993](http://arxiv.org/abs/2401.07993)

    本文研究了在Transformer模型中实现进位算法的方式，发现在两层的仅编码器模型中，第一层负责相同位置的数字相加，第二层根据注意力机制决定是否需要进位，并通过多层感知机来执行进位操作。

    

    加法可能是最简单的算术任务之一，通常使用进位算法进行计算。本文研究了Transformer模型如何实现这个算法，以及如何将两个任务分配给网络的不同部分。我们首先关注两层的仅编码器模型，发现进位算法以一种模块化的方式实现。第一层主要负责在相同位置上添加数字。第二层首先在注意力机制中决定哪些位置需要进位，然后在最终的多层感知机中执行进位操作。我们提供了一种简单的方法来精确定位负责这个任务的神经元。进位算法的这种实现在两层和三层模型的一系列超参数中都存在。对于小型的仅解码器模型

    Addition is perhaps one of the simplest arithmetic tasks one can think of and is usually performed using the carrying over algorithm. This algorithm consists of two tasks: adding digits in the same position and carrying over a one whenever necessary. We study how transformer models implement this algorithm and how the two aforementioned tasks are allocated to different parts of the network. We first focus on two-layer encoder-only models and show that the carrying over algorithm is implemented in a modular fashion. The first layer is mostly responsible for adding digits in the same position. The second layer first decides, in the attention, which positions need a carried one or not, and then performs the carrying of the one in the final MLP. We provide a simple way of precisely identifying which neurons are responsible for that task. This implementation of the carrying over algorithm occurs across a range of hyperparameters for two as well as three-layer models. For small decoder-only 
    
[^75]: E3x：简化的$\mathrm{E}(3)$等变深度学习

    E3x: $\mathrm{E}(3)$-Equivariant Deep Learning Made Easy. (arXiv:2401.07595v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.07595](http://arxiv.org/abs/2401.07595)

    E3x是一种简化了$\mathrm{E}(3)$等变深度学习的软件包，通过内置等变性实现更高的数据效率和准确性。

    

    本文介绍了E3x，一种用于构建神经网络的软件包，该网络在三维空间的平移、旋转和反射方面等变。与普通神经网络相比，$\mathrm{E}(3)$-等变模型在输入和/或输出数据是与三维对象相关的数量时具有优势。这是因为此类数量（例如位置）的数值通常取决于所选择的坐标系统。在参考系的变换下，这些值会可预测地发生变化，但对于普通的机器学习模型来说，学习其潜在规则可能很困难。使用内置的$\mathrm{E}(3)$-等变性，神经网络可以保证完全满足相关的变换规则，从而实现更高的数据效率和准确性。E3x的代码可从https://github.com/google-research/e3x获得，还提供了详细的文档和使用示例。

    This work introduces E3x, a software package for building neural networks that are equivariant with respect to the Euclidean group $\mathrm{E}(3)$, consisting of translations, rotations, and reflections of three-dimensional space. Compared to ordinary neural networks, $\mathrm{E}(3)$-equivariant models promise benefits whenever input and/or output data are quantities associated with three-dimensional objects. This is because the numeric values of such quantities (e.g. positions) typically depend on the chosen coordinate system. Under transformations of the reference frame, the values change predictably, but the underlying rules can be difficult to learn for ordinary machine learning models. With built-in $\mathrm{E}(3)$-equivariance, neural networks are guaranteed to satisfy the relevant transformation rules exactly, resulting in superior data efficiency and accuracy. The code for E3x is available from https://github.com/google-research/e3x, detailed documentation and usage examples ca
    
[^76]: LightHouse: AGI幻觉综述

    LightHouse: A Survey of AGI Hallucination. (arXiv:2401.06792v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.06792](http://arxiv.org/abs/2401.06792)

    该论文综述了AGI（人工通用智能）的幻觉现象，总结了当前对AGI幻觉的研究进展，并提出了一些未来研究方向的建议。

    

    随着人工智能的发展，大规模模型变得越来越智能。然而，许多研究表明，这些大模型中的幻觉成为了阻碍AI研究发展的瓶颈。为了实现强人工智能，大量的研究工作正在投入到AGI（人工通用智能）幻觉研究中。以往的探索主要集中在研究LLM（大语言模型）中的幻觉，而对于多模态AGI，幻觉研究仍处于早期阶段。为了进一步推动幻觉现象领域的研究进展，我们提供了对AGI幻觉的总览，总结了当前对AGI幻觉的研究工作，并提出了一些未来研究方向的建议。

    With the development of artificial intelligence, large-scale models have become increasingly intelligent. However, numerous studies indicate that hallucinations within these large models are a bottleneck hindering the development of AI research. In the pursuit of achieving strong artificial intelligence, a significant volume of research effort is being invested in the AGI (Artificial General Intelligence) hallucination research. Previous explorations have been conducted in researching hallucinations within LLMs (Large Language Models). As for multimodal AGI, research on hallucinations is still in an early stage. To further the progress of research in the domain of hallucinatory phenomena, we present a bird's eye view of hallucinations in AGI, summarizing the current work on AGI hallucinations and proposing some directions for future research.
    
[^77]: 频率屏蔽用于通用深度伪造检测

    Frequency Masking for Universal Deepfake Detection. (arXiv:2401.06506v1 [cs.CV])

    [http://arxiv.org/abs/2401.06506](http://arxiv.org/abs/2401.06506)

    本研究针对通用深度伪造检测问题，首次尝试探索了将屏蔽图像建模应用于频率屏蔽的方法，相较于已有方法，在检测性能上取得了显著提升。

    

    我们研究通用深度伪造检测。我们的目标是检测一系列生成型AI方法中的合成图像，尤其是在深度伪造检测的训练过程中未曾见过的新兴方法。通用深度伪造检测需要出色的泛化能力。受最近提出的屏蔽图像建模的启发，该方法在自监督预训练中展现出了出色的泛化性能，我们首次尝试探索将屏蔽图像建模应用于通用深度伪造检测。我们研究在训练深度伪造检测器时的空间和频率域屏蔽。基于经验分析，我们提出了一种通过频率屏蔽的新型深度伪造检测器。我们的重点是频率域，与大多数方法主要针对空间域检测有所不同。我们的比较分析揭示了与现有方法相比的显著性能提升。代码和模型已公开发布。

    We study universal deepfake detection. Our goal is to detect synthetic images from a range of generative AI approaches, particularly from emerging ones which are unseen during training of the deepfake detector. Universal deepfake detection requires outstanding generalization capability. Motivated by recently proposed masked image modeling which has demonstrated excellent generalization in self-supervised pre-training, we make the first attempt to explore masked image modeling for universal deepfake detection. We study spatial and frequency domain masking in training deepfake detectors. Based on empirical analysis, we propose a novel deepfake detector via frequency masking. Our focus on frequency domain is different from the majority, which primarily target spatial domain detection. Our comparative analyses reveal substantial performance gains over existing methods. Code and models are publicly available.
    
[^78]: 机器学习在OptVerse AI Solver中的应用：设计原理与应用

    Machine Learning Insides OptVerse AI Solver: Design Principles and Applications. (arXiv:2401.05960v1 [cs.AI])

    [http://arxiv.org/abs/2401.05960](http://arxiv.org/abs/2401.05960)

    本论文详细研究了将机器学习技术应用于华为云的OptVerse AI Solver，主要包括生成复杂实例、训练框架维护实用性和个性化的解算器策略等方面的创新方法。研究旨在缓解数学规划实例稀缺问题，并超越传统优化技术的能力。

    

    在数字无处不在的时代，高效的资源管理和决策是各个行业的重要问题。为此，我们对将机器学习技术应用于华为云的OptVerse AI Solver进行了全面的研究，旨在缓解现实世界数学规划实例的稀缺，并超越传统优化技术的能力。我们展示了利用生成模型生成复杂的SAT和MILP实例的方法，这些实例反映了现实世界问题的多面结构。此外，我们引入了一个训练框架，利用增强策略维护解算器在动态环境中的实用性。除了数据生成和增强，我们提出的方法还包括个性化解算器策略的新型机器学习驱动策略，重点关注图卷积网络用于初始基础选择和强化学习用于高级预求解的应用。

    In an era of digital ubiquity, efficient resource management and decision-making are paramount across numerous industries. To this end, we present a comprehensive study on the integration of machine learning (ML) techniques into Huawei Cloud's OptVerse AI Solver, which aims to mitigate the scarcity of real-world mathematical programming instances, and to surpass the capabilities of traditional optimization techniques. We showcase our methods for generating complex SAT and MILP instances utilizing generative models that mirror multifaceted structures of real-world problem. Furthermore, we introduce a training framework leveraging augmentation policies to maintain solvers' utility in dynamic environments. Besides the data generation and augmentation, our proposed approaches also include novel ML-driven policies for personalized solver strategies, with an emphasis on applications like graph convolutional networks for initial basis selection and reinforcement learning for advanced presolvi
    
[^79]: 大型语言模型在人机交互中的心智理论能力:一个幻觉?

    Theory of Mind abilities of Large Language Models in Human-Robot Interaction : An Illusion?. (arXiv:2401.05302v1 [cs.RO])

    [http://arxiv.org/abs/2401.05302](http://arxiv.org/abs/2401.05302)

    大型语言模型在人机交互中的应用具有较高的风险和潜在的不可逆后果。这项研究探索了大型语言模型的心智理论能力，特别关注机器人感知行为识别任务。

    

    大型语言模型在各种自然语言和生成任务中展示了异常的生成能力。然而，可能出现人形化和对失败案例的宽容性引发了关于大型语言模型中出现的心智理论（ToM）能力的讨论。虽然存在几种假信念测试来验证推断和维护另一个实体的心智模型的能力，我们研究了ToM能力的一个特殊应用，这具有更高的风险和可能是不可逆的后果：人机交互。在这项工作中，我们探讨了感知行为识别的任务，其中机器人使用大型语言模型（LLM）评估机器人生成的行为，类似于人类观察者的方式。我们关注四种行为类型，即可以解释的、可读的、可预测的和混淆的行为，这些行为已被广泛用于合成可解释的机器人行为。因此，LLM的目标是...

    Large Language Models have shown exceptional generative abilities in various natural language and generation tasks. However, possible anthropomorphization and leniency towards failure cases have propelled discussions on emergent abilities of Large Language Models especially on Theory of Mind (ToM) abilities in Large Language Models. While several false-belief tests exists to verify the ability to infer and maintain mental models of another entity, we study a special application of ToM abilities that has higher stakes and possibly irreversible consequences : Human Robot Interaction. In this work, we explore the task of Perceived Behavior Recognition, where a robot employs a Large Language Model (LLM) to assess the robot's generated behavior in a manner similar to human observer. We focus on four behavior types, namely explicable, legible, predictable, and obfuscatory behavior which have been extensively used to synthesize interpretable robot behaviors. The LLMs goal is, therefore to b
    
[^80]: AUTOACT：通过自主规划实现的自动代理学习

    AUTOACT: Automatic Agent Learning from Scratch via Self-Planning. (arXiv:2401.05268v1 [cs.CL])

    [http://arxiv.org/abs/2401.05268](http://arxiv.org/abs/2401.05268)

    AUTOACT是一个自动代理学习框架，通过自主规划合成轨迹，不依赖于大规模数据和闭源模型，能够实现更好或类似的性能。

    

    语言代理在各种复杂任务上取得了相当的性能。尽管在这个领域进行了不断的探索，但现有的语言代理系统仍然面临昂贵、不可重复的数据依赖问题，并且面临将单一模型应用于多个功能的挑战。为此，我们介绍了AutoAct，这是一个自动代理学习框架，不依赖于大规模带注释的数据和来自闭源模型（如GPT-4）的合成轨迹。给定有限的数据和工具库，AutoAct首先自动合成规划轨迹，不需要人类或强闭源模型的任何辅助。然后，AutoAct利用分工策略，根据目标任务信息和合成轨迹自动区分，产生一个子代理组来完成任务。我们进行了多种LLMs的广泛实验，结果显示AutoAct在性能上优于或与其相当。

    Language agents have achieved considerable performance on various complex tasks. Despite the incessant exploration in this field, existing language agent systems still struggle with costly, non-reproducible data reliance and face the challenge of compelling a single model for multiple functions. To this end, we introduce AutoAct, an automatic agent learning framework that does not rely on large-scale annotated data and synthetic trajectories from closed-source models (e.g., GPT-4). Given limited data with a tool library, AutoAct first automatically synthesizes planning trajectories without any assistance from humans or strong closed-source models. Then, AutoAct leverages a division-of-labor strategy to automatically differentiate based on the target task information and synthesized trajectories, producing a sub-agent group to complete the task. We conduct comprehensive experiments with different LLMs, which demonstrates that AutoAct yields better or parallel performance compared to var
    
[^81]: MobileAgent：通过人机交互和SOP集成增强移动控制

    MobileAgent: enhancing mobile control via human-machine interaction and SOP integration. (arXiv:2401.04124v1 [cs.HC])

    [http://arxiv.org/abs/2401.04124](http://arxiv.org/abs/2401.04124)

    MobileAgent通过人机交互和SOP集成，提高了移动控制的效率和个性化用户需求的满足，同时解决了隐私问题和代理学习中的挑战。

    

    现在以大型语言模型（LLM）为中心的代理能够为用户自动化移动设备操作。在针对学习用户的移动操作进行微调后，这些代理可以在线遵循高级用户指令。它们执行目标分解、子目标序列化和交互式环境探索等任务，直到实现最终目标。然而，在移动操作中存在与个性化用户数据相关的隐私问题，需要用户确认。此外，用户的真实操作是探索性的，行动数据复杂且冗余，给代理学习带来挑战。为了解决这些问题，在我们的实际应用中，我们设计了代理与人之间的交互任务，以识别敏感信息并与个性化用户需求对齐。此外，我们在模型的上下文学习中集成了标准操作规程（SOP）信息，以增强代理的理解能力。

    Agents centered around Large Language Models (LLMs) are now capable of automating mobile device operations for users. After fine-tuning to learn a user's mobile operations, these agents can adhere to high-level user instructions online. They execute tasks such as goal decomposition, sequencing of sub-goals, and interactive environmental exploration, until the final objective is achieved. However, privacy concerns related to personalized user data arise during mobile operations, requiring user confirmation. Moreover, users' real-world operations are exploratory, with action data being complex and redundant, posing challenges for agent learning. To address these issues, in our practical application, we have designed interactive tasks between agents and humans to identify sensitive information and align with personalized user needs. Additionally, we integrated Standard Operating Procedure (SOP) information within the model's in-context learning to enhance the agent's comprehension of comp
    
[^82]: 微小时间混合器 (TTMs): 针对多变量时间序列的增强零/少样本预测的快速预训练模型

    Tiny Time Mixers (TTMs): Fast Pretrained Models for Enhanced Zero/Few-Shot Forecasting of Multivariate Time Series. (arXiv:2401.03955v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.03955](http://arxiv.org/abs/2401.03955)

    本论文介绍了一种名为微小时间混合器 (TTMs) 的预训练模型，该模型针对多变量时间序列的零/少样本预测进行了优化。与大型预训练模型相比，TTMs模型更小、更快，并考虑了跨通道相关性，能够在短时间内进行有效的预测。

    

    零/少样本学习的大型预训练模型在语言和视觉领域表现出色，但在多变量时间序列 (TS) 中面临着多样性和公开预训练数据稀缺的挑战。因此，最近在时间序列预测中使用预训练的大型语言模型 (LLMs) 进行各种适应的趋势逐渐增加。这些方法利用跨领域迁移学习，出奇地取得了令人印象深刻的结果。然而，这些模型通常非常缓慢且庞大（大约十亿个参数），并且不考虑跨通道相关性。为了解决这个问题，我们提出了多层微小时间混合器 (TTM)，这是一种基于轻量级 TSMixer 结构的显著小型模型。TTM 是首个成功开发的微型通用预训练模型（≤100万个参数），专门在公开TS数据集上进行快速训练（仅需4-8小时），具有有效的迁移学习能力进行预测。

    Large Pretrained models for zero/few-shot learning excel in language and vision domains but encounter challenges in multivariate time series (TS) due to the diverse nature and scarcity of publicly available pretraining data. Consequently, there has been a recent surge in utilizing pretrained large language models (LLMs) with various adaptations for time series forecasting. These approaches employ cross-domain transfer learning and surprisingly yield impressive results. However, these models are typically very slow and large ($\sim$billion parameters) and do not consider cross-channel correlations. To address this, we present Multi-level Tiny Time Mixers (TTM), a significantly small model based on the lightweight TSMixer architecture. TTM marks the first success in developing tiny general-pretrained models ($\le$1 million parameters), exclusively trained on public TS datasets in a flash of just 4-8 hrs with effective transfer learning capabilities for forecasting. To tackle the complexi
    
[^83]: 时间序列预测中扩散模型的兴起

    The Rise of Diffusion Models in Time-Series Forecasting. (arXiv:2401.03006v1 [cs.LG])

    [http://arxiv.org/abs/2401.03006](http://arxiv.org/abs/2401.03006)

    本文调查了扩散模型在时间序列预测中的应用，提供了对这些模型的全面背景信息和详细说明，同时也对它们在不同数据集上的有效性和彼此之间的比较进行了分析。其贡献包括对扩散模型在时间序列预测中应用的彻底探索和按时间顺序排序的模型概述。这是一份对人工智能和时间序列分析领域的研究人员来说具有价值的资源。

    

    本调查探讨了扩散模型在时间序列预测中的应用。扩散模型在生成型人工智能的各个领域中展示出最先进的结果。本文包括对扩散模型的全面背景信息，详细介绍其条件方法，并审查了其在时间序列预测中的应用。分析涵盖了11个具体的时间序列实现，它们的直觉和理论基础，不同数据集上的有效性以及彼此之间的比较。该工作的关键贡献是对扩散模型在时间序列预测中应用的彻底探索，并提供了一个按时间顺序排序的模型概述。此外，本文对该领域的最新技术水平进行了深入讨论，并概述了潜在的未来研究方向。这对于人工智能和时间序列分析领域的研究人员来说是一份宝贵的资源，提供了对最新进展和未来发展的清晰视图。

    This survey delves into the application of diffusion models in time-series forecasting. Diffusion models are demonstrating state-of-the-art results in various fields of generative AI. The paper includes comprehensive background information on diffusion models, detailing their conditioning methods and reviewing their use in time-series forecasting. The analysis covers 11 specific time-series implementations, the intuition and theory behind them, the effectiveness on different datasets, and a comparison among each other. Key contributions of this work are the thorough exploration of diffusion models' applications in time-series forecasting and a chronologically ordered overview of these models. Additionally, the paper offers an insightful discussion on the current state-of-the-art in this domain and outlines potential future research directions. This serves as a valuable resource for researchers in AI and time-series analysis, offering a clear view of the latest advancements and future p
    
[^84]: MIMIR: 基于互信息的对抗鲁棒性的遮罩图像建模

    MIMIR: Masked Image Modeling for Mutual Information-based Adversarial Robustness. (arXiv:2312.04960v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.04960](http://arxiv.org/abs/2312.04960)

    MIMIR提出了一种新颖的防御方法，通过在预训练中利用遮罩图像建模，构建了一个不同的对抗性训练方法。该方法旨在增强Vision Transformers（ViTs）对抗攻击的鲁棒性。

    

    视觉变压器（ViTs）相对于卷积神经网络（CNNs）在各种任务上实现了卓越的性能，但ViTs也容易受到对抗性攻击。对抗性训练是建立强大的CNN模型的最成功方法之一。因此，最近的研究探索了基于ViTs和CNNs之间的差异的对抗性训练的新方法，如更好的训练策略，防止注意力集中在单个块上，或丢弃低注意力的嵌入。然而，这些方法仍然遵循传统监督对抗训练的设计，限制了对ViTs的对抗训练的潜力。本文提出了一种新颖的防御方法MIMIR，旨在通过利用预训练中的遮罩图像建模构建不同的对抗性训练方法。我们创建了一个自编码器，它接受对抗性例子作为输入，但将干净的例子作为建模目标。然后，我们创建了一个互信息（MI）

    Vision Transformers (ViTs) achieve superior performance on various tasks compared to convolutional neural networks (CNNs), but ViTs are also vulnerable to adversarial attacks. Adversarial training is one of the most successful methods to build robust CNN models. Thus, recent works explored new methodologies for adversarial training of ViTs based on the differences between ViTs and CNNs, such as better training strategies, preventing attention from focusing on a single block, or discarding low-attention embeddings. However, these methods still follow the design of traditional supervised adversarial training, limiting the potential of adversarial training on ViTs. This paper proposes a novel defense method, MIMIR, which aims to build a different adversarial training methodology by utilizing Masked Image Modeling at pre-training. We create an autoencoder that accepts adversarial examples as input but takes the clean examples as the modeling target. Then, we create a mutual information (MI
    
[^85]: 使用PCA、t-SNE和UMAP可视化和分类攻击来对5G网络流量入侵进行关键分析

    Critical Analysis of 5G Networks Traffic Intrusion using PCA, t-SNE and UMAP Visualization and Classifying Attacks. (arXiv:2312.04864v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2312.04864](http://arxiv.org/abs/2312.04864)

    通过使用PCA、t-SNE和UMAP可视化技术，以及采用机器学习和深度学习方法来降低5G网络流量入侵的风险，并解决类不平衡问题，本研究提出了一种基于人工智能的自治端到端安全设计。

    

    网络、威胁模型和恶意行为者在不断发展。随着5G网络的增加部署，附加的5G物理设备的安全问题也在增加。因此，需要一种基于人工智能的自治端到端安全设计，能够通过检测网络流量异常来处理即将到来的威胁。为满足这一要求，本研究使用最近发布的5G流量数据集5G-NIDD，使用机器学习和深度学习方法来检测网络流量异常。首先，我们使用三种可视化技术：t-SNE、UMAP和PCA分析数据集。其次，我们使用互信息和PCA技术降低数据维度。然后，通过插入少数类的合成记录来解决类不平衡问题。最后，我们使用六种不同的分类方法进行分类。

    Networks, threat models, and malicious actors are advancing quickly. With the increased deployment of the 5G networks, the security issues of the attached 5G physical devices have also increased. Therefore, artificial intelligence based autonomous end-to-end security design is needed that can deal with incoming threats by detecting network traffic anomalies. To address this requirement, in this research, we used a recently published 5G traffic dataset, 5G-NIDD, to detect network traffic anomalies using machine and deep learning approaches. First, we analyzed the dataset using three visualization techniques: t-Distributed Stochastic Neighbor Embedding (t-SNE), Uniform Manifold Approximation and Projection (UMAP), and Principal Component Analysis (PCA). Second, we reduced the data dimensionality using mutual information and PCA techniques. Third, we solve the class imbalance issue by inserting synthetic records of minority classes. Last, we performed classification using six different cl
    
[^86]: CLadder: 评估语言模型因果推理能力的基准测试

    CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models. (arXiv:2312.04350v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.04350](http://arxiv.org/abs/2312.04350)

    该论文提出了一个新的NLP任务，评估语言模型在因果推理方面的能力。作者构建了一个大规模的数据集CLadder，并利用oracle因果推理引擎将符号问题转化为自然语言。研究结果表明多个LLMs在该数据集上的表现，并引入并评估了一种定制的链式推理机制。

    

    进行因果推理的能力被广泛视为智能的核心特征。本文研究了大型语言模型(LLMs)能否连贯地推理因果关系。现有的自然语言处理(NLP)工作主要关注评估LLMs中的常识因果推理，未能评估模型是否能够按照一组明确定义的形式规则执行因果推断。为了解决这个问题，我们提出了一个新的NLP任务，自然语言中的因果推断，受到Judea Pearl等人提出的“因果推断引擎”的启发。我们构建了一个包含10K个样本的大型数据集CLadder，通过一种oracle因果推理引擎，基于一组因果图和查询(联合、干预和反事实)，得到符号问题和真实答案，并将其翻译为自然语言。我们对数据集上的多个LLMs进行评估，并引入和评估了一种定制的链式推理机制。

    The ability to perform causal reasoning is widely considered a core feature of intelligence. In this work, we investigate whether large language models (LLMs) can coherently reason about causality. Much of the existing work in natural language processing (NLP) focuses on evaluating commonsense causal reasoning in LLMs, thus failing to assess whether a model can perform causal inference in accordance with a set of well-defined formal rules. To address this, we propose a new NLP task, causal inference in natural language, inspired by the "causal inference engine" postulated by Judea Pearl et al. We compose a large dataset, CLadder, with 10K samples: based on a collection of causal graphs and queries (associational, interventional, and counterfactual), we obtain symbolic questions and ground-truth answers, through an oracle causal inference engine. These are then translated into natural language. We evaluate multiple LLMs on our dataset, and we introduce and evaluate a bespoke chain-of-th
    
[^87]: 护理者的谈话塑造幼儿视觉：一项关于双参与游戏的计算研究

    Caregiver Talk Shapes Toddler Vision: A Computational Study of Dyadic Play. (arXiv:2312.04118v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.04118](http://arxiv.org/abs/2312.04118)

    本研究通过计算模型探究了护理者的谈话对幼儿视觉表征的影响。研究发现，即使在语言输入有限的情境下，护理者的谈话仍然能够提升幼儿的视觉表征能力。

    

    婴儿识别和分类物体的能力逐渐发展。生命的第二年标志着更多语义视觉表征的出现和对词汇含义的更好理解。这表明语言输入可能在塑造视觉表征中起重要作用。然而，即使在适合学习单词的情境下，如双参与游戏会话中，护理者的话语也是稀少和不明确的，常常指的是与儿童注意的物体不同的物体。在这里，我们系统地研究护理者的话语到底能够在多大程度上增强视觉表征。为此，我们提出了一个计算模型，用于在双参与游戏过程中学习视觉表征。我们引入了一个合成数据集，其中包含了由幼儿代理人感知到的以自我为中心的图像，在不同的家庭环境中移动和旋转玩具物体，并同时听到被建模为字幕的护理者的话语。

    Infants' ability to recognize and categorize objects develops gradually. The second year of life is marked by both the emergence of more semantic visual representations and a better understanding of word meaning. This suggests that language input may play an important role in shaping visual representations. However, even in suitable contexts for word learning like dyadic play sessions, caregivers utterances are sparse and ambiguous, often referring to objects that are different from the one to which the child attends. Here, we systematically investigate to what extent caregivers' utterances can nevertheless enhance visual representations. For this we propose a computational model of visual representation learning during dyadic play. We introduce a synthetic dataset of ego-centric images perceived by a toddler-agent that moves and rotates toy objects in different parts of its home environment while hearing caregivers' utterances, modeled as captions. We propose to model toddlers' learni
    
[^88]: 分析混合交通控制下非信号化现实世界交叉口的排放和能源效率

    Analyzing Emissions and Energy Efficiency at Unsignalized Real-world Intersections Under Mixed Traffic Control. (arXiv:2311.11866v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2311.11866](http://arxiv.org/abs/2311.11866)

    本论文分析了在混合交通控制策略下，非信号化现实世界交叉口的排放和能源效率，提供了对具有复杂拓扑和交通需求的非信号化交叉口的排放分析。

    

    自20世纪初以来，温室气体排放量急剧上升，美国交通运输占美国排放量的28%。因此，减少交通相关的排放量成为关注的焦点。特别是，可持续性研究已经在信号化交叉口周围展开，因为交叉口允许不同流量的交通穿过和改变方向。最近的研究已经在信号化交叉口开发了混合交通控制的生态驾驶策略，以减少排放。然而，信号化交叉口的天然结构通过创建频繁的加速/减速事件、交通拥堵引起的过度怠速和起波现象，增加了排放。因此，我们相信非信号化交叉口具有进一步改善可持续性的潜力。在这项工作中，我们对具有复杂的现实世界拓扑和交通需求的非信号化交叉口进行了排放分析，采用了混合交通控制策略。

    Greenhouse gas emissions have dramatically risen since the early 1900s with U.S. transportation generating 28% of U.S. emissions. As such, there is interest in reducing transportation-related emissions. Specifically, sustainability research has sprouted around signalized intersections as intersections allow different streams of traffic to cross and change directions. Recent research has developed mixed traffic control eco-driving strategies at signalized intersections to decrease emissions. However, the inherent structure of a signalized intersection generates increased emissions by creating frequent acceleration/deceleration events, excessive idling from traffic congestion, and stop-and-go waves. Thus, we believe unsignalized intersections hold potential for further sustainability improvements. In this work, we provide an emissions analysis on unsignalized intersections with complex, real-world topologies and traffic demands where mixed traffic control strategies are employed by robot
    
[^89]: 使用深度强化学习增强的遗传算法在父代选择机制和变异方面：在排列流水车间调度问题中最小化完工时间

    Genetic Algorithm enhanced by Deep Reinforcement Learning in parent selection mechanism and mutation : Minimizing makespan in permutation flow shop scheduling problems. (arXiv:2311.05937v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2311.05937](http://arxiv.org/abs/2311.05937)

    本研究通过引入强化学习方法，在遗传算法的父代选择机制和变异方面进行增强，从而在排列流水车间调度问题中最小化完工时间。这种RL+GA方法通过动态调整选择和变异，有效地改进了原始GA的性能，并表现出适应群体多样性的能力。

    

    本文引入了一种强化学习（RL）方法来解决配置和优化遗传算法（GA）以解决困难的组合或非线性问题所面临的挑战。提出的RL+GA方法专门在流水车间调度问题（FSP）上进行了测试。该混合算法结合了神经网络（NN），并使用离策略方法Q-learning或在线策略方法Sarsa（0）来控制两个关键的遗传算法（GA）运算符：父代选择机制和变异。在每一代中，RL代理的动作决定了选择方法，父代选择的概率和后代变异的概率。这使得RL代理能够根据其学习的策略动态调整选择和变异。研究结果突出了RL+GA方法在改进原始GA性能方面的有效性。它们还证明了它学习和适应群体多样性的能力。

    This paper introduces a reinforcement learning (RL) approach to address the challenges associated with configuring and optimizing genetic algorithms (GAs) for solving difficult combinatorial or non-linear problems. The proposed RL+GA method was specifically tested on the flow shop scheduling problem (FSP). The hybrid algorithm incorporates neural networks (NN) and uses the off-policy method Q-learning or the on-policy method Sarsa(0) to control two key genetic algorithm (GA) operators: parent selection mechanism and mutation. At each generation, the RL agent's action is determining the selection method, the probability of the parent selection and the probability of the offspring mutation. This allows the RL agent to dynamically adjust the selection and mutation based on its learned policy. The results of the study highlight the effectiveness of the RL+GA approach in improving the performance of the primitive GA. They also demonstrate its ability to learn and adapt from population diver
    
[^90]: 理解Transformer中的加法

    Understanding Addition in Transformers. (arXiv:2310.13121v1 [cs.LG])

    [http://arxiv.org/abs/2310.13121](http://arxiv.org/abs/2310.13121)

    本文通过对经过训练进行整数加法的单层Transformer模型的深入分析，揭示了该模型将任务分为并行的、特定于数字的流，并针对不同的数字位置采用不同的算法，同时还发现了一种罕见的高损失的使用情况。这些发现对于机制可解释性、人工智能安全性和对齐性等方面的研究具有重要贡献。

    

    了解像Transformer这样的机器学习模型的内部工作方式对于其安全和道德使用至关重要。本文对经过训练进行整数加法的单层Transformer模型进行了深入分析。我们揭示了该模型将任务分为并行的、特定于数字的流，并针对不同的数字位置采用不同的算法。我们的研究还发现该模型开始计算较晚，但执行速度非常快。我们还发现了一种罕见的高损失的使用情况，并予以解释。总体而言，我们详细解释了该模型的算法。这些发现通过严格测试和数学建模得到了验证，对于机制可解释性、人工智能安全性和对齐性等广泛研究做出了贡献。我们的方法为分析更复杂的任务和多层Transformer模型打开了大门。

    Understanding the inner workings of machine learning models like Transformers is vital for their safe and ethical use. This paper presents an in-depth analysis of a one-layer Transformer model trained for integer addition. We reveal that the model divides the task into parallel, digit-specific streams and employs distinct algorithms for different digit positions. Our study also finds that the model starts calculations late but executes them rapidly. A rare use case with high loss is identified and explained. Overall, the model's algorithm is explained in detail. These findings are validated through rigorous testing and mathematical modeling, contributing to the broader works in Mechanistic Interpretability, AI safety, and alignment. Our approach opens the door for analyzing more complex tasks and multi-layer Transformer models.
    
[^91]: 从标签比例中学习：通过信念传播对有监督学习器进行引导

    Learning from Label Proportions: Bootstrapping Supervised Learners via Belief Propagation. (arXiv:2310.08056v1 [cs.LG])

    [http://arxiv.org/abs/2310.08056](http://arxiv.org/abs/2310.08056)

    本文提出了一种从标签比例中学习的算法框架，通过伪标签化和嵌入细化两个步骤迭代地提高有监督学习器性能。

    

    标签比例学习（LLP）是一个学习问题，在训练过程中，只有针对一组实例（称为包）的聚合级别标签可用，并且目的是在测试数据的实例级别上获得最佳性能。这种设置在广告和医学等领域由于隐私考虑而出现。我们提出了一个新颖的算法框架来解决这个问题，它通过两个主要步骤进行迭代。在每次迭代的第一步（伪标签化）中，我们定义了一个基于二进制实例标签的吉布斯分布，该分布通过以下约束将covariate信息（协变量信息）合并进去：具有相似covariates的实例应该具有相似的标签，并且通过包级别的聚合标签来综合covariate信息。然后，我们使用信念传播（BP）来边缘化吉布斯分布以获得伪标签。在第二步（嵌入细化）中，我们使用伪标签为学习器提供监督，从而获得更好的嵌入。此后，我们对这两个步骤进行迭代。

    Learning from Label Proportions (LLP) is a learning problem where only aggregate level labels are available for groups of instances, called bags, during training, and the aim is to get the best performance at the instance-level on the test data. This setting arises in domains like advertising and medicine due to privacy considerations. We propose a novel algorithmic framework for this problem that iteratively performs two main steps. For the first step (Pseudo Labeling) in every iteration, we define a Gibbs distribution over binary instance labels that incorporates a) covariate information through the constraint that instances with similar covariates should have similar labels and b) the bag level aggregated label. We then use Belief Propagation (BP) to marginalize the Gibbs distribution to obtain pseudo labels. In the second step (Embedding Refinement), we use the pseudo labels to provide supervision for a learner that yields a better embedding. Further, we iterate on the two steps ag
    
[^92]: 在规划中结合空间和时间抽象以实现更好的泛化

    Combining Spatial and Temporal Abstraction in Planning for Better Generalization. (arXiv:2310.00229v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.00229](http://arxiv.org/abs/2310.00229)

    Skipper是一个基于模型的强化学习代理，利用时空抽象来在新情境中推广学到的技能。它自动将任务分解为子任务，实现稀疏决策和对环境相关部分的专注计算。实验结果表明，Skipper在零样本泛化方面具有显著优势。

    

    受到人类有意识规划的启发，我们提出了Skipper，这是一个利用时空抽象来推广在新情境中学到的技能的基于模型的强化学习代理。它自动将给定任务分解为更小、更可管理的子任务，从而实现稀疏决策和对环境相关部分的专注计算。这依赖于从回溯中学习得到的表示为有向图的抽象代理问题的提取。我们的理论分析在适当的假设下提供了性能保证，并确定了我们的方法在哪些方面有望提供帮助。针对泛化的实验验证了Skipper在零样本泛化方面与现有最先进的分层规划方法相比的显著优势。

    Inspired by human conscious planning, we propose Skipper, a model-based reinforcement learning agent utilizing spatio-temporal abstractions to generalize learned skills in novel situations. It automatically decomposes the given task into smaller, more manageable subtasks, and hence enables sparse decision-making and focused computation on the relevant parts of the environment. This relies on the extraction of an abstracted proxy problem represented as a directed graph, in which vertices and edges are learned end-to-end from hindsight. Our theoretical analyses provide performance guarantees under appropriate assumptions and establish where our approach is expected to be helpful. Generalization-focused experiments validate Skipper's significant advantage in zero-shot generalization, compared to existing state-of-the-art hierarchical planning methods.
    
[^93]: 《语言模型中激活路径修复的最佳实践：度量和方法》的论文翻译

    Towards Best Practices of Activation Patching in Language Models: Metrics and Methods. (arXiv:2309.16042v1 [cs.LG])

    [http://arxiv.org/abs/2309.16042](http://arxiv.org/abs/2309.16042)

    本研究系统地考察了激活路径修复中的方法细节对语言模型解释性结果的影响，并提出了最佳实践建议。

    

    机械解释性旨在理解机器学习模型的内部机制，其中定位-识别重要的模型组件是关键步骤。激活路径修复，也称为因果追踪或交换干预，是完成这一任务的标准技术，但文献中存在许多变体，对超参数或方法选择缺乏一致性。在这项工作中，我们系统地考察了激活路径修复中的方法细节对结果的影响，包括评估指标和损坏方法。在语言模型的定位和电路发现的几种设置中，我们发现不同的超参数可能导致不同的解释结果。通过经验观察支持，我们提出了为什么某些指标或方法可能更受欢迎的概念性论证。最后，我们提出了激活路径修复的最佳实践建议。

    Mechanistic interpretability seeks to understand the internal mechanisms of machine learning models, where localization -- identifying the important model components -- is a key step. Activation patching, also known as causal tracing or interchange intervention, is a standard technique for this task (Vig et al., 2020), but the literature contains many variants with little consensus on the choice of hyperparameters or methodology. In this work, we systematically examine the impact of methodological details in activation patching, including evaluation metrics and corruption methods. In several settings of localization and circuit discovery in language models, we find that varying these hyperparameters could lead to disparate interpretability results. Backed by empirical observations, we give conceptual arguments for why certain metrics or methods may be preferred. Finally, we provide recommendations for the best practices of activation patching going forwards.
    
[^94]: 注意言辞：大型语言模型和内容审查

    Watch Your Language: Large Language Models and Content Moderation. (arXiv:2309.14517v1 [cs.HC])

    [http://arxiv.org/abs/2309.14517](http://arxiv.org/abs/2309.14517)

    本研究评估了大型语言模型在内容审查任务上的表现，发现它们在基于规则的社区审查和有害内容检测方面具有很好的效果，在有害内容检测方面超过了现有的分类器。然而，最近模型规模的增加对有害内容检测的改进效果很小。

    

    由于其在各种自然语言任务上的能力，大型语言模型（LLMs）变得非常受欢迎。基于文本的内容审查是其中一个受到近期热情关注的LLM应用案例，然而，鲜有研究调查LLMs在内容审查设置中的表现。在这项工作中，我们评估了一套现代、商业化的LLMs（GPT-3、GPT-3.5、GPT-4）在两个常见的内容审查任务上的表现：基于规则的社区审查和有害内容检测。对于基于规则的社区审查，我们构建了95个LLM审查引擎，并使用95个Reddit子社区的规则进行指导，发现LLMs在许多社区的基于规则的审查中表现出色，实现了中位数准确率为64%和中位数精确度为83%。在有害内容检测方面，我们发现LLMs明显优于现有商业可用的有害性分类器。然而，我们还发现最近模型规模的增加对有害内容检测几乎没有带来明显的好处。

    Large language models (LLMs) have exploded in popularity due to their ability to perform a wide array of natural language tasks. Text-based content moderation is one LLM use case that has received recent enthusiasm, however, there is little research investigating how LLMs perform in content moderation settings. In this work, we evaluate a suite of modern, commercial LLMs (GPT-3, GPT-3.5, GPT-4) on two common content moderation tasks: rule-based community moderation and toxic content detection. For rule-based community moderation, we construct 95 LLM moderation-engines prompted with rules from 95 Reddit subcommunities and find that LLMs can be effective at rule-based moderation for many communities, achieving a median accuracy of 64% and a median precision of 83%. For toxicity detection, we find that LLMs significantly outperform existing commercially available toxicity classifiers. However, we also find that recent increases in model size add only marginal benefit to toxicity detection
    
[^95]: 闲谈令人无聊的问题：研究基于GPT的文本规范化

    A Chat About Boring Problems: Studying GPT-based text normalization. (arXiv:2309.13426v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.13426](http://arxiv.org/abs/2309.13426)

    本文研究了基于GPT的文本规范化任务。通过结合自洽推理和基于语言知识的提示工程，我们发现基于LLM的文本规范化的错误率比顶级规范化系统低约40％。同时，通过对错误分析，我们发现传统的文本规范化任务设计存在关键限制。我们创建了一个新的框架以识别基于GPT的文本规范化的优势和局限性。这为未来的工作提供了机会。

    

    文本规范化-将文本从书面形式转化为口语形式-通常被认为是语言模型面临的一个不完善的任务。在这项工作中，我们提出了与之相反的观点。我们通过实证研究了大型语言模型（LLM）在少样本情境下进行文本规范化的能力。通过结合自洽推理和基于语言知识的提示工程，我们发现基于LLM的文本规范化的错误率比顶级规范化系统低约40％。进一步的错误分析中，我们注意到传统的文本规范化任务设计的关键限制。我们创建了一个新的文本规范化错误分类，并将其应用于GPT-3.5-Turbo和GPT-4.0的结果中。通过这个新的框架，我们可以识别出基于GPT的文本规范化的优势和局限性，从而为未来的工作提供了机会。

    Text normalization - the conversion of text from written to spoken form - is traditionally assumed to be an ill-formed task for language models. In this work, we argue otherwise. We empirically show the capacity of Large-Language Models (LLM) for text normalization in few-shot scenarios. Combining self-consistency reasoning with linguistic-informed prompt engineering, we find LLM based text normalization to achieve error rates around 40\% lower than top normalization systems. Further, upon error analysis, we note key limitations in the conventional design of text normalization tasks. We create a new taxonomy of text normalization errors and apply it to results from GPT-3.5-Turbo and GPT-4.0. Through this new framework, we can identify strengths and weaknesses of GPT-based TN, opening opportunities for future work.
    
[^96]: 一种基于概率波动的生成模型成员推断攻击方法

    A Probabilistic Fluctuation based Membership Inference Attack for Generative Models. (arXiv:2308.12143v1 [cs.LG])

    [http://arxiv.org/abs/2308.12143](http://arxiv.org/abs/2308.12143)

    本研究针对生成模型提出了一种概率波动评估成员推断攻击方法(PFAMI)，通过检测概率分布的波动性来推断模型中是否存在某条训练记录的成员身份。

    

    成员推断攻击(MIA)通过查询模型来识别机器学习模型的训练集中是否存在某条记录。对经典分类模型的MIA已有很多研究，最近的工作开始探索如何将MIA应用到生成模型上。我们的研究表明，现有的面向生成模型的MIA主要依赖于目标模型的过拟合现象。然而，过拟合可以通过采用各种正则化技术来避免，而现有的MIA在实践中表现不佳。与过拟合不同，记忆对于深度学习模型实现最佳性能是至关重要的，使其成为一种更为普遍的现象。生成模型中的记忆导致生成记录的概率分布呈现出增长的趋势。因此，我们提出了一种基于概率波动的成员推断攻击方法(PFAMI)，它是一种黑盒MIA，通过检测概率波动来推断成员身份。

    Membership Inference Attack (MIA) identifies whether a record exists in a machine learning model's training set by querying the model. MIAs on the classic classification models have been well-studied, and recent works have started to explore how to transplant MIA onto generative models. Our investigation indicates that existing MIAs designed for generative models mainly depend on the overfitting in target models. However, overfitting can be avoided by employing various regularization techniques, whereas existing MIAs demonstrate poor performance in practice. Unlike overfitting, memorization is essential for deep learning models to attain optimal performance, making it a more prevalent phenomenon. Memorization in generative models leads to an increasing trend in the probability distribution of generating records around the member record. Therefore, we propose a Probabilistic Fluctuation Assessing Membership Inference Attack (PFAMI), a black-box MIA that infers memberships by detecting t
    
[^97]: 毒箭蛙：一种在没有训练数据的情况下，具有低中毒率和高攻击成功率的无标签攻击

    Poison Dart Frog: A Clean-Label Attack with Low Poisoning Rate and High Attack Success Rate in the Absence of Training Data. (arXiv:2308.09487v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2308.09487](http://arxiv.org/abs/2308.09487)

    毒箭蛙是一种无标签攻击方法，不需要训练数据，只需要目标类别的知识。它具有低中毒率和高攻击成功率。

    

    为了成功发动后门攻击，注入的数据需要被正确标记，否则，即使是基本的数据过滤器也能轻易检测出来。因此，引入了无标签攻击的概念，这种攻击更加危险，因为它不需要改变注入数据的标签。据我们所知，现有的无标签后门攻击在很大程度上依赖于对整个训练集或其中一部分的理解。然而，在实践中，攻击者很难拥有这些理解，因为训练数据集通常来自多个独立的来源。与所有当前的无标签攻击不同，我们提出了一种新颖的无标签方法，名为“毒箭蛙”。毒箭蛙不需要访问任何训练数据，只需要了解攻击目标类别，比如“蛙”。在CIFAR10、Tiny-ImageNet和TSRD上，仅需要分别占训练集大小的0.1%、0.025%和0.4%的中毒率，毒箭蛙就能取得成功。

    To successfully launch backdoor attacks, injected data needs to be correctly labeled; otherwise, they can be easily detected by even basic data filters. Hence, the concept of clean-label attacks was introduced, which is more dangerous as it doesn't require changing the labels of injected data. To the best of our knowledge, the existing clean-label backdoor attacks largely relies on an understanding of the entire training set or a portion of it. However, in practice, it is very difficult for attackers to have it because of training datasets often collected from multiple independent sources. Unlike all current clean-label attacks, we propose a novel clean label method called 'Poison Dart Frog'. Poison Dart Frog does not require access to any training data; it only necessitates knowledge of the target class for the attack, such as 'frog'. On CIFAR10, Tiny-ImageNet, and TSRD, with a mere 0.1\%, 0.025\%, and 0.4\% poisoning rate of the training set size, respectively, Poison Dart Frog achie
    
[^98]: 基于大型语言模型的IDE内生成式信息支持

    In-IDE Generation-based Information Support with a Large Language Model. (arXiv:2307.08177v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2307.08177](http://arxiv.org/abs/2307.08177)

    本研究探索了一种基于大型语言模型的IDE内生成式信息支持，通过在IDE中内嵌对话式用户界面，向开发者提供关于代码理解的帮助。通过查询大型语言模型来解释代码、提供API调用的详细信息、解释特定领域术语以及为API提供使用示例，该系统在用户研究中获得了积极的评价。

    

    理解代码是具有挑战性的，尤其是在新的和复杂的开发环境中工作时。代码注释和文档可以帮助，但往往稀缺或难以导航。大型语言模型（LLM）正在彻底改变编写代码的过程。它们能否对理解代码提供同样的帮助？在这项研究中，我们首次探索了一种基于LLM的直接内嵌式对话式用户界面，并针对代码理解进行了优化。我们的IDE插件通过四个高级请求（无需用户编写显式提示信息）查询OpenAI的GPT-3.5和GPT-4模型，请求内容包括解释代码中的突出部分、提供代码中使用的API调用详细信息，解释关键领域特定术语，以及为API提供使用示例。该插件还支持自由响应式提示，可以自动上下文化到正在编辑的程序中。我们通过32名参与者进行用户研究来评估该系统，结果确认使用我们的插件能够

    Understanding code is challenging, especially when working in new and complex development environments. Code comments and documentation can help, but are typically scarce or hard to navigate. Large language models (LLMs) are revolutionizing the process of writing code. Can they do the same for helping understand it? In this study, we provide a first investigation of an LLM-based conversational UI built directly in the IDE that is geared towards code understanding. Our IDE plugin queries OpenAI's GPT-3.5 and GPT-4 models with four high-level requests without the user having to write explicit prompts: to explain a highlighted section of code, provide details of API calls used in the code, explain key domain-specific terms, and provide usage examples for an API. The plugin also allows for open-ended prompts, which are automatically contextualized to the LLM with the program being edited. We evaluate this system in a user study with 32 participants, which confirms that using our plugin can
    
[^99]: VertiBench: 在垂直联邦学习基准中推进特征分布多样性

    VertiBench: Advancing Feature Distribution Diversity in Vertical Federated Learning Benchmarks. (arXiv:2307.02040v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.02040](http://arxiv.org/abs/2307.02040)

    本文引入了两个影响VFL性能的关键因素：特征重要性和特征相关性，并提出了相关的评估指标和数据集划分方法。同时，通过引入真实的VFL数据集，填补了图像-图像VFL情景中的不足。研究对于未来的VFL研究提供了有价值的见解。

    

    垂直联邦学习（VFL）是在特征划分的分布式数据上训练机器学习模型的重要范例。然而，由于隐私限制，很少有公开的真实世界VFL数据集用于算法评估，而这些数据集只代表了有限的特征分布。现有的基准通常采用从全局集合中的任意特征划分导出的合成数据集，这只捕捉到了一部分特征分布，导致算法性能评估不足。本文通过引入影响VFL性能的两个关键因素——特征重要性和特征相关性，并提出相关的评估指标和数据集划分方法，解决了这些问题。此外，我们还引入了一个真实的VFL数据集来弥补图像-图像VFL情景中的不足。我们对尖端VFL算法进行全面评估，为未来研究提供了有价值的见解。

    Vertical Federated Learning (VFL) is a crucial paradigm for training machine learning models on feature-partitioned, distributed data. However, due to privacy restrictions, few public real-world VFL datasets exist for algorithm evaluation, and these represent a limited array of feature distributions. Existing benchmarks often resort to synthetic datasets, derived from arbitrary feature splits from a global set, which only capture a subset of feature distributions, leading to inadequate algorithm performance assessment. This paper addresses these shortcomings by introducing two key factors affecting VFL performance - feature importance and feature correlation - and proposing associated evaluation metrics and dataset splitting methods. Additionally, we introduce a real VFL dataset to address the deficit in image-image VFL scenarios. Our comprehensive evaluation of cutting-edge VFL algorithms provides valuable insights for future research in the field.
    
[^100]: GKD：自回归序列模型的广义知识蒸馏

    GKD: Generalized Knowledge Distillation for Auto-regressive Sequence Models. (arXiv:2306.13649v1 [cs.LG])

    [http://arxiv.org/abs/2306.13649](http://arxiv.org/abs/2306.13649)

    本文提出了广义知识蒸馏（GKD），通过从学生中采样输出序列来缓解分布不匹配，并在优化替代KL等离散度方面处理模型欠规范，达到了在摘要任务上最先进的性能。

    

    知识蒸馏通常用于压缩神经网络，以减少推理成本和内存占用。然而，当前针对自回归模型（如生成语言模型）的蒸馏方法存在两个关键问题：（1）训练期间输出序列和部署时由学生模型生成的序列之间分布不匹配，（2）模型欠规范，学生模型可能不够表达老师分布。为了解决这些问题，我们提出了广义知识蒸馏（GKD）。GKD通过在训练期间从学生中采样输出序列来缓解分布不匹配。此外，GKD通过优化替代KL等离散度来处理模型欠规范，这些离散度集中于生成可能符合老师分布的学生样本。我们证明，在摘要任务上，GKD优于常用的LLM蒸馏方法，在几个基准数据集上实现了最先进的性能。

    Knowledge distillation is commonly used for compressing neural networks to reduce their inference cost and memory footprint. However, current distillation methods for auto-regressive models, such as generative language models (LMs), suffer from two key issues: (1) distribution mismatch between output sequences during training and the sequences generated by the student during its deployment, and (2) model under-specification, where the student model may not be expressive enough to fit the teacher's distribution. To address these issues, we propose Generalized Knowledge Distillation (GKD). GKD mitigates distribution mismatch by sampling output sequences from the student during training. Furthermore, GKD handles model under-specification by optimizing alternative divergences, such as reverse KL, that focus on generating samples from the student that are likely under the teacher's distribution. We demonstrate that GKD outperforms commonly-used approaches for distilling LLMs on summarizatio
    
[^101]: 论文标题：在强化学习中创建多级技能层次结构。

    Creating Multi-Level Skill Hierarchies in Reinforcement Learning. (arXiv:2306.09980v1 [cs.LG])

    [http://arxiv.org/abs/2306.09980](http://arxiv.org/abs/2306.09980)

    本文提出了一种基于代理人与环境交互的图形结构的答案，使用分层图划分产生具有多个抽象层次的技能层次结构。技能能将代理人移动到状态空间中互相连接紧密但相互连接较弱的区域，有效提高了强化学习的效率。

    

    摘要：什么样的技能层次结构对于自主代理人是有用的？我们提出了一种基于代理人与环境交互的图形结构的答案。我们的方法使用分层图划分来揭示图在不同时间尺度上的结构，从而产生具有多个抽象层次的技能层次结构。在层次结构的每个层次上，技能将代理人移动到状态空间中互相连接紧密但相互连接较弱的区域。我们在强化学习的广泛领域中展示了所提出的技能层次结构的效用。

    What is a useful skill hierarchy for an autonomous agent? We propose an answer based on the graphical structure of an agent's interaction with its environment. Our approach uses hierarchical graph partitioning to expose the structure of the graph at varying timescales, producing a skill hierarchy with multiple levels of abstraction. At each level of the hierarchy, skills move the agent between regions of the state space that are well connected within themselves but weakly connected to each other. We illustrate the utility of the proposed skill hierarchy in a wide variety of domains in the context of reinforcement learning.
    
[^102]: 注意力、编译和基于求解器的符号分析是您所需要的一切

    Attention, Compilation, and Solver-based Symbolic Analysis are All You Need. (arXiv:2306.06755v2 [cs.PL] UPDATED)

    [http://arxiv.org/abs/2306.06755](http://arxiv.org/abs/2306.06755)

    本文提出了一种基于大型语言模型的代码相互转换方法，利用注意力机制、编译和符号执行测试生成进行等价测试。在广泛的实验中，表明该方法在编译和运行时等价准确性等方面优于其他转换器和翻译工具。

    

    在本文中，我们提出了一种基于大型语言模型的Java到Python（J2P）和Python到Java（P2J）代码相互转换方法，并介绍了一个名为CoTran的相关工具。我们的方法利用了大型语言模型的注意力机制、编译和基于符号执行的测试生成，用于输入和输出程序之间的等价测试。具体而言，我们修改了典型的大型语言模型训练循环，加入了编译器和符号执行损失。通过在超过57,000个Java-Python等价对的基准测试中将CoTran与其他12个转换器和基于大型语言模型的翻译工具进行广泛的实验比较，我们发现CoTran在诸如编译和运行时等价准确性等相关指标上表现优于它们。例如，我们的工具在J2P转换中获得97.43%的编译准确性和49.66%的运行时等价准确性，而最接近的竞争工具分别只有92.84%和40.95%。

    In this paper, we present a Java-to-Python (J2P) and Python-to-Java (P2J) back-to-back code translation method, and an associated tool called CoTran, based on large language models (LLMs). Our method leverages the attention mechanism of LLMs, compilation, and symbolic execution-based test generation for equivalence testing between the input and output programs. More precisely, we modify the typical LLM training loop to incorporate compiler and symbolic execution loss. Via extensive experiments comparing CoTran with 12 other transpilers and LLM-based translation tools over a benchmark of more than 57,000 Java-Python equivalent pairs, we show that CoTran outperforms them on relevant metrics such as compilation and runtime equivalence accuracy. For example, our tool gets 97.43% compilation accuracy and 49.66% runtime equivalence accuracy for J2P translation, whereas the nearest competing tool only gets 92.84% and 40.95% respectively.
    
[^103]: 因果成分分析

    Causal Component Analysis. (arXiv:2305.17225v1 [stat.ML])

    [http://arxiv.org/abs/2305.17225](http://arxiv.org/abs/2305.17225)

    本文介绍了一个中间问题：因果成分分析(CauCA)，它是独立成分分析(ICA)和因果表示学习(CRL)的泛化和特例，其目标是学习解混函数和因果机制，预设了因果图的知识。

    

    独立成分分析(ICA)的目标是从混合观测到的变量中恢复独立的潜在变量。而因果表示学习(CRL)的目标是推断因果关系强相关性的潜在变量，以及编码它们的因果关系的未知图。我们引入了一个中间问题，称为因果成分分析(CauCA)。CauCA可以被看作是ICA的一种推广，对潜在成分之间的因果依赖建模，也是CRL的一个特例。与CRL不同的是，它预设了因果图的知识，仅关注于学习解混函数和因果机制。所有关于CauCA回收基础真相的不可能结果也适用于CRL，而可能性结果可以作为扩展CRL的基础。我们将从对潜在因果变量实施不同类型干预的多个数据集中表征CauCA的可识别性。

    Independent Component Analysis (ICA) aims to recover independent latent variables from observed mixtures thereof. Causal Representation Learning (CRL) aims instead to infer causally related (thus often statistically dependent) latent variables, together with the unknown graph encoding their causal relationships. We introduce an intermediate problem termed Causal Component Analysis (CauCA). CauCA can be viewed as a generalization of ICA, modelling the causal dependence among the latent components, and as a special case of CRL. In contrast to CRL, it presupposes knowledge of the causal graph, focusing solely on learning the unmixing function and the causal mechanisms. Any impossibility results regarding the recovery of the ground truth in CauCA also apply for CRL, while possibility results may serve as a stepping stone for extensions to CRL. We characterize CauCA identifiability from multiple datasets generated through different types of interventions on the latent causal variables. As a
    
[^104]: 基于扩散的对抗样本生成以提高隐蔽性和可控性

    Diffusion-Based Adversarial Sample Generation for Improved Stealthiness and Controllability. (arXiv:2305.16494v1 [cs.CV])

    [http://arxiv.org/abs/2305.16494](http://arxiv.org/abs/2305.16494)

    本文提出了一个名为Diff-PGD的新框架，用于生成接近原始数据分布、逼真的对抗样本，具有较好的隐蔽性和对抗强度可调性。

    

    神经网络容易受到对抗样本的影响：这是一种特意制作的自然图片的微小变化，旨在误导模型。虽然这些对抗样本在数字和物理场景中可以轻松生成，但它们往往与自然图像的实际数据分布差异很大，导致强度与隐蔽性之间存在权衡。本文提出了一个名为扩散-投影梯度下降（Diff-PGD）的新框架，用于生成逼真的对抗样本。通过利用扩散模型引导的梯度，Diff-PGD确保对抗样本保持接近原始数据分布，同时保持它们的有效性。此外，我们的框架可以轻松定制特定任务，如数字攻击、物理攻击和基于样式的攻击。与现有的生成自然风格对抗样本方法相比，我们的框架可以分离优化对抗强度和隐蔽性，提供更大的灵活性和对生成样本的控制。

    Neural networks are known to be susceptible to adversarial samples: small variations of natural examples crafted to deliberately mislead the models. While they can be easily generated using gradient-based techniques in digital and physical scenarios, they often differ greatly from the actual data distribution of natural images, resulting in a trade-off between strength and stealthiness. In this paper, we propose a novel framework dubbed Diffusion-Based Projected Gradient Descent (Diff-PGD) for generating realistic adversarial samples. By exploiting a gradient guided by a diffusion model, Diff-PGD ensures that adversarial samples remain close to the original data distribution while maintaining their effectiveness. Moreover, our framework can be easily customized for specific tasks such as digital attacks, physical-world attacks, and style-based attacks. Compared with existing methods for generating natural-style adversarial samples, our framework enables the separation of optimizing adv
    
[^105]: 内容丰富的多模态转换器训练与 LoReTTa

    Training Transitive and Commutative Multimodal Transformers with LoReTTa. (arXiv:2305.14243v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.14243](http://arxiv.org/abs/2305.14243)

    LoReTTa是一个自监督框架，可以在具有不同模态的数据集中转换。通过合成数据集的方法，显著提高了下游任务的性能。

    

    实践中，收集两个匹配的形态A和B或B和C的多模态数据集很困难，获得包含三个对齐形态A、B和C的数据集更加具有挑战性。我们引入了LoReTTa以应对这个未被充分研究的问题。我们的自监督框架结合了因果掩码建模和交换律和传递性的规则，可以在不同的模态中转换。我们的实验表明，这种合成显着提高了下游任务的性能。

    Collecting a multimodal dataset with two paired modalities A and B or B and C is difficult in practice. Obtaining a dataset with three aligned modalities A, B, and C is even more challenging. For example, some public medical datasets have only genetic sequences and microscopic images for one patient, and only genetic sequences and radiological images for another - but no dataset includes both microscopic and radiological images for the same patient. This makes it difficult to integrate and combine all modalities into a large pre-trained neural network. We introduce LoReTTa (Linking mOdalities with a tRansitive and commutativE pre-Training sTrAtegy) to address this understudied problem. Our self-supervised framework combines causal masked modeling with the rules of commutativity and transitivity to transition within and between different modalities. Thus, it can model the relation A -> C with A -> B -> C. Given a dataset containing only the disjoint combinations (A, B) and (B, C), we sh
    
[^106]: 一种可扩展的神经网络用于DSIC仿射极大价拍卖设计

    A Scalable Neural Network for DSIC Affine Maximizer Auction Design. (arXiv:2305.12162v1 [cs.GT])

    [http://arxiv.org/abs/2305.12162](http://arxiv.org/abs/2305.12162)

    该论文提出了一种可扩展的神经网络AMenuNet来构造AMAs参数和生成候选分配，解决了现有方法在占优策略激励兼容性和可扩展性方面的限制，其在协商一致的价值和社会残余价值方面优于强基线模型。

    

    自动拍卖设计旨在通过机器学习寻找经验上高收入的机制。现有的多物品拍卖情景的工作可以粗略地分为RegretNet类和仿射极大价（AMAs）方法。然而，前者不能严格保证占优策略激励兼容性（DSIC），而后者因为分配候选人数过多而面临可扩展性问题。为解决这些限制，我们提出了AMenuNet，一种可扩展的神经网络，它从出价人和物品表示中构造AMA参数（甚至包括分配菜单）。由于AMA的属性，AMenuNet始终是DSIC和个人理性（IR）的，通过神经网络生成候选分配来增强可伸缩性。此外，AMenuNet是置换等变的，其参数数量不受拍卖规模的影响。我们进行了大量实验，证明AMenuNet在协商一致的价值和社会残余价值方面优于强基线模型。

    Automated auction design aims to find empirically high-revenue mechanisms through machine learning. Existing works on multi item auction scenarios can be roughly divided into RegretNet-like and affine maximizer auctions (AMAs) approaches. However, the former cannot strictly ensure dominant strategy incentive compatibility (DSIC), while the latter faces scalability issue due to the large number of allocation candidates. To address these limitations, we propose AMenuNet, a scalable neural network that constructs the AMA parameters (even including the allocation menu) from bidder and item representations. AMenuNet is always DSIC and individually rational (IR) due to the properties of AMAs, and it enhances scalability by generating candidate allocations through a neural network. Additionally, AMenuNet is permutation equivariant, and its number of parameters is independent of auction scale. We conduct extensive experiments to demonstrate that AMenuNet outperforms strong baselines in both co
    
[^107]: 通过部分解耦强化学习和向量多样性，一小时内训练适用于实际世界的局部路径规划器。

    Train a Real-world Local Path Planner in One Hour via Partially Decoupled Reinforcement Learning and Vectorized Diversity. (arXiv:2305.04180v1 [cs.AI])

    [http://arxiv.org/abs/2305.04180](http://arxiv.org/abs/2305.04180)

    通过Color解决方案的Actor-Sharer-Learner（ASL）训练框架和面向移动机器人的模拟器Sparrow，使得在实际应用中训练局部路径规划器变得可行。

    

    深度强化学习已经在解决局部路径规划问题上显示出有效性。然而，由于DRL的效率和泛化能力不足，其在实际应用中受到了极大的限制。为了缓解这两个问题，提出了一种名为Color的解决方案，它由Actor-Sharer-Learner（ASL）训练框架和面向移动机器人的模拟器Sparrow组成。

    Deep Reinforcement Learning (DRL) has exhibited efficacy in resolving the Local Path Planning (LPP) problem. However, such application in the real world is immensely limited due to the deficient efficiency and generalization capability of DRL. To alleviate these two issues, a solution named Color is proposed, which consists of an Actor-Sharer-Learner (ASL) training framework and a mobile robot-oriented simulator Sparrow. Specifically, the ASL framework, intending to improve the efficiency of the DRL algorithm, employs a Vectorized Data Collection (VDC) mode to expedite data acquisition, decouples the data collection from model optimization by multithreading, and partially connects the two procedures by harnessing a Time Feedback Mechanism (TFM) to evade data underuse or overuse. Meanwhile, the Sparrow simulator utilizes a 2D grid-based world, simplified kinematics, and conversion-free data flow to achieve a lightweight design. The lightness facilitates vectorized diversity, allowing di
    
[^108]: CryCeleb: 基于婴儿哭声的说话人认证数据集

    CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds. (arXiv:2305.00969v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2305.00969](http://arxiv.org/abs/2305.00969)

    CryCeleb是一个基于婴儿哭声的说话人认证数据集，包括超过6小时的手动分割哭声，可用于研究婴儿哭声分析。

    

    本文描述了Ubenwa CryCeleb数据集——一个标记的婴儿哭声收集，以及附带的CryCeleb 2023任务——一个基于婴儿哭声的公共说话人验证挑战。我们释放出786名新生儿超过6小时的手动分割哭声，以鼓励婴儿哭声分析方面的研究。

    This paper describes the Ubenwa CryCeleb dataset - a labeled collection of infant cries, and the accompanying CryCeleb 2023 task - a public speaker verification challenge based on infant cry sounds. We release for academic usage more than 6 hours of manually segmented cry sounds from 786 newborns to encourage research in infant cry analysis.
    
[^109]: ID-MixGCL: 基于身份混合的图形对比学习

    ID-MixGCL: Identity Mixup for Graph Contrastive Learning. (arXiv:2304.10045v1 [cs.LG])

    [http://arxiv.org/abs/2304.10045](http://arxiv.org/abs/2304.10045)

    本文提出了一种基于身份混合的图形对比学习方法，旨在解决通过图形增强得到的不同但相似的图形结构和标签的不匹配问题，以实现更好的表示捕获。

    

    最近发展的图形对比学习（GCL）方法是比较同一个图形的两个不同的“视图”以学习节点/图形表示。这些方法的核心假设是通过图形增强，可以生成几个结构不同但语义相似的图形结构，因此原始和增强的图形/节点的身份标签应该是相同的。然而，在本文中，我们发现这个假设并不总是成立，例如分子图中对节点或边的任何扰动都会在一定程度上改变图形标签。因此，我们认为增强图形结构应该伴随着对对比损失使用的标签的适应。基于这个想法，我们提出了 ID-MixGCL，它允许同时调节输入图形和相应的身份标签，具有可控的改变程度，从而捕获细粒度的表示。

    Recently developed graph contrastive learning (GCL) approaches compare two different "views" of the same graph in order to learn node/graph representations. The core assumption of these approaches is that by graph augmentation, it is possible to generate several structurally different but semantically similar graph structures, and therefore, the identity labels of the original and augmented graph/nodes should be identical. However, in this paper, we observe that this assumption does not always hold, for example, any perturbation to nodes or edges in a molecular graph will change the graph labels to some degree. Therefore, we believe that augmenting the graph structure should be accompanied by an adaptation of the labels used for the contrastive loss. Based on this idea, we propose ID-MixGCL, which allows for simultaneous modulation of both the input graph and the corresponding identity labels, with a controllable degree of change, leading to the capture of fine-grained representations 
    
[^110]: HomPINNs：基于同伦的物理知识神经网络用于解决具有多个解的非线性微分方程的反问题

    HomPINNs: homotopy physics-informed neural networks for solving the inverse problems of nonlinear differential equations with multiple solutions. (arXiv:2304.02811v1 [cs.LG])

    [http://arxiv.org/abs/2304.02811](http://arxiv.org/abs/2304.02811)

    本文提出了一种新的框架——基于同伦的物理知识神经网络，来解决具有多个解的非线性微分方程的反问题。该框架使用神经网络逼近已知观测结果并符合DEs的约束条件，通过同伦连续方法解决反问题。实验证明该方法可伸缩且适应性强，为解决具有多个解的DEs提供了有效解决方案。

    

    由于解空间中的非唯一性、对称性和分岔等复杂行为，解决具有多个解的非线性微分方程（DEs）的反问题是一项具有挑战性的任务。为了解决这个问题，我们提出了同伦物理知识神经网络（HomPINNs），这是一种利用同伦连续和神经网络（NNs）来解决反问题的新框架。所提出的框架首先使用NNs同时逼近已知观测结果和符合DEs的约束条件。通过利用同伦连续方法，逼近可追踪观察结果以确定多个解并解决反问题。实验涵盖在一维DEs上测试所提出的方法的性能，并应用它来解决二维Gray-Scott模拟。我们的研究结果表明，所提出的方法是可伸缩且适应性强的，为解决具有多个解的DEs提供了有效的解决方案。

    Due to the complex behavior arising from non-uniqueness, symmetry, and bifurcations in the solution space, solving inverse problems of nonlinear differential equations (DEs) with multiple solutions is a challenging task. To address this issue, we propose homotopy physics-informed neural networks (HomPINNs), a novel framework that leverages homotopy continuation and neural networks (NNs) to solve inverse problems. The proposed framework begins with the use of a NN to simultaneously approximate known observations and conform to the constraints of DEs. By utilizing the homotopy continuation method, the approximation traces the observations to identify multiple solutions and solve the inverse problem. The experiments involve testing the performance of the proposed method on one-dimensional DEs and applying it to solve a two-dimensional Gray-Scott simulation. Our findings demonstrate that the proposed method is scalable and adaptable, providing an effective solution for solving DEs with mul
    
[^111]: 自我监督利用的探索

    Exploration by self-supervised exploitation. (arXiv:2302.11563v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.11563](http://arxiv.org/abs/2302.11563)

    该论文介绍了一种基于自我监督学习的内在动机算法类别SND，并将其应用于探索困难环境。实验结果表明这种方法是有效的。

    

    强化学习可以解决决策问题，并训练一个代理根据预先设计的奖励函数在环境中行为。然而，如果奖励过于稀疏，代理在环境探索中不会遇到奖励，这种方法就变得非常棘手。解决这个问题的方法可能是为代理装备内在动机，这样代理在探索过程中也可能遇到外部奖励。新颖性检测是内在动机研究的一个有前途的分支。我们提出了一种基于蒸馏误差作为新颖性指标的自我监督网络蒸馏（SND）算法类别，其中目标模型使用自我监督学习进行训练。我们为此改编了三种现有的自我监督方法，并在被认为难以探索的十个环境上进行了实验测试。

    Reinforcement learning can solve decision-making problems and train an agent to behave in an environment according to a predesigned reward function. However, such an approach becomes very problematic if the reward is too sparse and the agent does not come across the reward during the environmental exploration. The solution to such a problem may be in equipping the agent with an intrinsic motivation, which will provide informed exploration, during which the agent is likely to also encounter external reward. Novelty detection is one of the promising branches of intrinsic motivation research. We present Self-supervised Network Distillation (SND), a class of internal motivation algorithms based on the distillation error as a novelty indicator, where the target model is trained using self-supervised learning. We adapted three existing self-supervised methods for this purpose and experimentally tested them on a set of ten environments that are considered difficult to explore. The results sho
    
[^112]: 在线损失函数学习

    Online Loss Function Learning. (arXiv:2301.13247v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.13247](http://arxiv.org/abs/2301.13247)

    在线损失函数学习是一种新的元学习范例，旨在自动化为机器学习模型设计损失函数的重要任务。我们提出了一种新的损失函数学习技术，可以在每次更新基本模型参数后自适应地在线更新损失函数。实验结果表明，我们的方法在多个任务上稳定地优于现有技术。

    

    损失函数学习是一种新的元学习范例，旨在自动化为机器学习模型设计损失函数的重要任务。现有的损失函数学习技术已经显示出有希望的结果，经常改善模型的训练动态和最终推理性能。然而，这些技术的一个重要限制是损失函数以线下方式进行元学习，元目标仅考虑训练的前几个步骤，这与训练深度神经网络通常使用的时间范围相比显著较短。这导致对于在训练开始时表现良好但在训练结束时表现不佳的损失函数存在明显的偏差。为了解决这个问题，我们提出了一种新的损失函数学习技术，可以在每次更新基本模型参数后自适应地在线更新损失函数。实验结果表明，我们提出的方法在多个任务上稳定地优于现有技术。

    Loss function learning is a new meta-learning paradigm that aims to automate the essential task of designing a loss function for a machine learning model. Existing techniques for loss function learning have shown promising results, often improving a model's training dynamics and final inference performance. However, a significant limitation of these techniques is that the loss functions are meta-learned in an offline fashion, where the meta-objective only considers the very first few steps of training, which is a significantly shorter time horizon than the one typically used for training deep neural networks. This causes significant bias towards loss functions that perform well at the very start of training but perform poorly at the end of training. To address this issue we propose a new loss function learning technique for adaptively updating the loss function online after each update to the base model parameters. The experimental results show that our proposed method consistently out
    
[^113]: 具有背压和强化学习的Lyapunov函数一致自适应网络信号控制

    Lyapunov Function Consistent Adaptive Network Signal Control with Back Pressure and Reinforcement Learning. (arXiv:2210.02612v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2210.02612](http://arxiv.org/abs/2210.02612)

    这项研究提出了一种利用Lyapunov控制理论的统一框架，将基于流量和基于压力的交通信号控制方法相结合。通过引入背压方法和强化学习算法，实现对复杂交通网络的有效控制。

    

    在交通信号控制中，基于流量和基于压力的方法通常分别使用，但往往被单独考虑。本研究引入了一个统一的框架，利用Lyapunov控制理论，分别为这些方法定义了特定的Lyapunov函数。我们发现了有趣的结果。例如，著名的背压方法等于交叉口车道饱和流量加权的差分队列长度。我们进一步通过添加基本的交通流理论来改进它。控制系统不仅应该确保稳定，还应该能够适应各种性能指标。基于Lyapunov理论的启示，本研究为基于强化学习的网络信号控制设计了一个奖励函数，该函数使用Double Deep Q-Network (DDQN)训练智能体，以有效控制复杂的交通网络。所提出的算法与几种常用的控制算法进行了比较。

    In traffic signal control, flow-based (optimizing the overall flow) and pressure-based methods (equalizing and alleviating congestion) are commonly used but often considered separately. This study introduces a unified framework using Lyapunov control theory, defining specific Lyapunov functions respectively for these methods. We have found interesting results. For example, the well-recognized back-pressure method is equal to differential queue lengths weighted by intersection lane saturation flows. We further improve it by adding basic traffic flow theory. Rather than ensuring that the control system be stable, the system should be also capable of adaptive to various performance metrics. Building on insights from Lyapunov theory, this study designs a reward function for the Reinforcement Learning (RL)-based network signal control, whose agent is trained with Double Deep Q-Network (DDQN) for effective control over complex traffic networks. The proposed algorithm is compared with several
    
[^114]: 信念的动态：连续监测和可视化复杂系统

    The dynamics of belief: continuously monitoring and visualising complex systems. (arXiv:2208.05764v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2208.05764](http://arxiv.org/abs/2208.05764)

    本论文研究了在人类环境中人工智能的透明和可解释性问题，提出了一种关于数字系统的理论框架，利用模式和模式转换的概念对系统的结构进行抽象。通过将信念函数的评估视觉化为高维几何空间中的轨迹，解释了系统行为。

    

    人类环境中人工智能的崛起对自动化系统提出了新的透明和可解释性要求。我们研究了与这种可解释性相关的一些拟人化思想和原则，以便在复杂人类环境中开发关于数字系统的理论框架，并解决解释其行为的问题。就结构而言，系统由模块化和层次化组件构成，我们使用模式和模式转换的概念在一个新的系统模型中对其进行抽象。模式是系统的独立组件，具有自己的目标、监测数据和算法。模式的行为，包括其向其他模式的转换，由解释每个模式的监测数据并根据其目标和算法的函数确定。我们通过将这些信念函数的评估视觉化为高维几何空间中的轨迹来展示它们如何帮助解释系统行为。这些思想在数学上被抽象化。

    The rise of AI in human contexts places new demands on automated systems to be transparent and explainable. We examine some anthropomorphic ideas and principles relevant to such accountablity in order to develop a theoretical framework for thinking about digital systems in complex human contexts and the problem of explaining their behaviour. Structurally, systems are made of modular and hierachical components, which we abstract in a new system model using notions of modes and mode transitions. A mode is an independent component of the system with its own objectives, monitoring data, and algorithms. The behaviour of a mode, including its transitions to other modes, is determined by functions that interpret each mode's monitoring data in the light of its objectives and algorithms. We show how these belief functions can help explain system behaviour by visualising their evaluation as trajectories in higher-dimensional geometric spaces. These ideas are formalised mathematically by abstract
    
[^115]: 一种基于Dempster-Shafer方法的值得信赖的人工智能：胎儿脑MRI分割应用

    A Dempster-Shafer approach to trustworthy AI with application to fetal brain MRI segmentation. (arXiv:2204.02779v4 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2204.02779](http://arxiv.org/abs/2204.02779)

    该论文提出了一种基于Dempster-Shafer方法的值得信赖的人工智能框架和实用系统，用于医学图像分割。通过检测和纠正深度学习模型的失败，增强了其可信性和安全性。

    

    医学图像分割的深度学习模型在病理情况和与训练图像拍摄在不同中心的图像中可能出现意外和显著的失败，其标签错误违反了专家知识。这些错误削弱了深度学习模型在医学图像分割中的可信性。检测和纠正这些失败的机制对于安全地将这项技术应用于临床是必不可少的，并且可能成为未来关于人工智能的法规的要求。在这项工作中，我们提出了一个值得信赖的人工智能理论框架和一个实用系统，可以使用Dempster-Shafer理论的备用方法和故障安全机制来增强任何骨干人工智能系统。我们的方法依赖于对值得信赖的人工智能的可操作定义。我们的方法自动丢弃骨干人工智能预测的体素级标签，这些标签违反了专家知识，并对这些体素使用备用方法。我们展示了该方法的有效性。

    Deep learning models for medical image segmentation can fail unexpectedly and spectacularly for pathological cases and images acquired at different centers than training images, with labeling errors that violate expert knowledge. Such errors undermine the trustworthiness of deep learning models for medical image segmentation. Mechanisms for detecting and correcting such failures are essential for safely translating this technology into clinics and are likely to be a requirement of future regulations on artificial intelligence (AI). In this work, we propose a trustworthy AI theoretical framework and a practical system that can augment any backbone AI system using a fallback method and a fail-safe mechanism based on Dempster-Shafer theory. Our approach relies on an actionable definition of trustworthy AI. Our method automatically discards the voxel-level labeling predicted by the backbone AI that violate expert knowledge and relies on a fallback for those voxels. We demonstrate the effec
    

