# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Stop Regressing: Training Value Functions via Classification for Scalable Deep RL](https://arxiv.org/abs/2403.03950) | 通过使用分类代替回归训练值函数，本文提出了一种简单方法来改善深度强化学习的性能和可扩展性 |
| [^2] | [Reconciling Reality through Simulation: A Real-to-Sim-to-Real Approach for Robust Manipulation](https://arxiv.org/abs/2403.03949) | 该论文提出了一种名为RialTo的系统，通过在“数字孪生”模拟环境中进行强化学习来稳健化真实世界的模仿学习策略，以实现在不需要大量不安全真实世界数据采集或广泛人类监督的情况下学习性能优越、稳健的策略。 |
| [^3] | [Extreme Precipitation Nowcasting using Transformer-based Generative Models](https://arxiv.org/abs/2403.03929) | 使用基于Transformer的生成模型NowcastingGPT-EVL在极端降水预测中表现出优越性能，尤其在处理极端降水事件时。 |
| [^4] | [Consciousness qua Mortal Computation](https://arxiv.org/abs/2403.03925) | 意识被看作是一种新型的计算，称为有限计算，这与传统的图灵计算不同。 |
| [^5] | [Enhancing Instructional Quality: Leveraging Computer-Assisted Textual Analysis to Generate In-Depth Insights from Educational Artifacts](https://arxiv.org/abs/2403.03920) | 通过计算机辅助文本分析，本文揭示了人工智能和机器学习方法在教学质量提升中的重要作用，为教育工作者提供了深入见解和可操作的反馈。 |
| [^6] | [IRCoder: Intermediate Representations Make Language Models Robust Multilingual Code Generators](https://arxiv.org/abs/2403.03894) | 通过利用编译器中间表示来改进代码-LMs的多语言能力和促进跨语言转移。 |
| [^7] | [From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models](https://arxiv.org/abs/2403.03893) | 该研究拓展了语言模型中毒性缓解的范围，涵盖了多语言环境，通过翻译数据评估和增强缓解技术，比较了不同缓解方法，并探讨了模型大小和数据量对缓解效果的影响。 |
| [^8] | [Hierarchical Diffusion Policy for Kinematics-Aware Multi-Task Robotic Manipulation](https://arxiv.org/abs/2403.03890) | 这项研究提出了一种分层扩散策略（HDP）用于多任务机器人操作，通过将操纵策略分解为分层结构，同时解决长期任务规划和生成细粒度的低层动作，同时提出了一种新颖的机器人运动学感知目标条件控制代理（RK-Diffuser）。 |
| [^9] | [Latent Dataset Distillation with Diffusion Models](https://arxiv.org/abs/2403.03881) | 这项研究提出了使用扩散模型进行潜在数据集蒸馏（LD3M），结合潜在空间中的扩散和数据集蒸馏的方法，以解决不同模型架构导致准确性下降和生成高分辨率图像的挑战。 |
| [^10] | [Redefining cystoscopy with ai: bladder cancer diagnosis using an efficient hybrid cnn-transformer model](https://arxiv.org/abs/2403.03879) | 提出了一种混合CNN-Transformer模型，结合了双重注意力门机制，用于膀胱癌检测和分割，实现了在膀胱镜检查中计算效率和诊断准确性之间的平衡。 |
| [^11] | [Impoverished Language Technology: The Lack of (Social) Class in NLP](https://arxiv.org/abs/2403.03874) | 该论文探讨了NLP领域中缺乏对社会阶级因素的研究，呼吁研究者在NLP技术中考虑和操作化阶级因素。 |
| [^12] | [Are Language Models Puzzle Prodigies? Algorithmic Puzzles Unveil Serious Challenges in Multimodal Reasoning](https://arxiv.org/abs/2403.03864) | 这项研究提出了多模态解谜任务AlgoPuzzleVQA，通过算法谜题挑战评估了多模态语言模型在需要视觉理解、语言理解和复杂算法推理的能力，旨在评估视觉数据解释与算法问题解决能力之间的差距。 |
| [^13] | [Accelerating Convergence of Score-Based Diffusion Models, Provably](https://arxiv.org/abs/2403.03852) | 设计了新颖的无需训练的算法，以加速流行的确定性和随机采样器，改进了确定性采样器的收敛速率至$O(1/{T}^2)$，提升了随机采样器的收敛速率至$O(1/T)$。 |
| [^14] | [Cobweb: An Incremental and Hierarchical Model of Human-Like Category Learning](https://arxiv.org/abs/2403.03835) | Cobweb是一种类似人类类别学习系统，采用类别效用度量构建分层组织的类似树状结构，能够捕捉心理效应并在单一模型中展现出实例和原型学习的灵活性，为将来研究人类类别学习提供了基础。 |
| [^15] | [Your device may know you better than you know yourself -- continuous authentication on novel dataset using machine learning](https://arxiv.org/abs/2403.03832) | 通过新数据集和机器学习技术，研究展示了触摸动态可以有效地区分用户，最具鲁棒性的模型是支持向量分类器（SVC），其平均准确率约为90% |
| [^16] | [From Clicks to Security: Investigating Continuous Authentication via Mouse Dynamics](https://arxiv.org/abs/2403.03828) | 本研究探讨了鼠标移动动态作为持续认证的一种一致度量的潜力，并通过机器学习模型分析用户行为，发现鼠标移动动态可以作为可靠的认证指标。 |
| [^17] | [Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ](https://arxiv.org/abs/2403.03814) | 本研究通过引入MultiQ基准，调查了最先进的开放LLMs在其预期使用范围之外的基本多语能力，发现这些模型对于至少某些语言能够忠实和准确地进行回答。 |
| [^18] | [ProbSAINT: Probabilistic Tabular Regression for Used Car Pricing](https://arxiv.org/abs/2403.03812) | ProbSAINT是一种提出了一种原则性方法来量化其价格预测的不确定性，并且提供了与最先进的提升技术相媲美的准确点预测的模型。 |
| [^19] | [Confidence-Aware Decision-Making and Control for Tool Selection](https://arxiv.org/abs/2403.03808) | 引入了一个数学框架，使机器人能够利用他们的控制自信心做出更加明智的决策，并且推导出了动态系统的控制自信度的数学闭合形式表达式 |
| [^20] | [KG-TREAT: Pre-training for Treatment Effect Estimation by Synergizing Patient Data with Knowledge Graphs](https://arxiv.org/abs/2403.03791) | KG-TREAT框架通过协同患者数据和知识图谱，引入双重关注的知识图谱和深度双层注意力协同方法，实现了治疗相关因素和结果相关因素的独立编码，表现优于现有方法。 |
| [^21] | [Neural Architecture Search using Particle Swarm and Ant Colony Optimization](https://arxiv.org/abs/2403.03781) | 本研究开发了一种集成用于图像分类的神经结构搜索开源工具系统（OpenNAS），通过采用粒子群和蚁群优化等元启发式方法，自动生成卷积神经网络架构，以显著提高模型准确性。 |
| [^22] | [ENOT: Expectile Regularization for Fast and Accurate Training of Neural Optimal Transport](https://arxiv.org/abs/2403.03777) | 通过期望回归正则化，本论文提出了一种新的神经优化传输（NOT）训练程序扩展，能够有效地估计最优输运方案，并使学习变得稳定。 |
| [^23] | [DeepCRE: Revolutionizing Drug R&D with Cutting-Edge Computational Models](https://arxiv.org/abs/2403.03768) | DeepCRE是一种新型的计算模型，在患者级别CRE性能上平均提高了17.7％，在指示级别CRE增加了5倍，并成功确定了六个具有显着优势的药物候选者。 |
| [^24] | [German also Hallucinates! Inconsistency Detection in News Summaries with the Absinth Dataset](https://arxiv.org/abs/2403.03750) | 本文提出了一个用于德语新闻摘要中幻觉检测的数据集absinth，探讨了LLMs在该任务中的应用。 |
| [^25] | [Towards Safe and Aligned Large Language Models for Medicine](https://arxiv.org/abs/2403.03744) | 对医学LLMs进行了首次安全评估，并探讨了如何定义医学安全和对齐性，开发了有害医学问题数据集，评估了医学LLMs的安全性和对齐性，展示了微调是一种有效的缓解策略。 |
| [^26] | [SUPClust: Active Learning at the Boundaries](https://arxiv.org/abs/2403.03741) | 提出了一种名为SUPClust的新型主动学习方法，旨在识别类别之间的决策边界上的点，通过标记这些点来优化模型预测的性能。 |
| [^27] | [A&B BNN: Add&Bit-Operation-Only Hardware-Friendly Binary Neural Network](https://arxiv.org/abs/2403.03739) | A&B BNN 提出了一种只使用加和位操作的硬件友好二值神经网络，通过引入掩码层和量化 RPReLU 结构，能够更高效地进行计算，并在CIFA数据集上取得了良好的实验结果。 |
| [^28] | [Learning 3D object-centric representation through prediction](https://arxiv.org/abs/2403.03730) | 通过预测未来场景，该研究开发了一种网络架构，同时学习对象分割、3D位置推断和深度感知，从而以类似人类婴儿的约束条件学习物体的表示方式 |
| [^29] | [Bridging Diversity and Uncertainty in Active learning with Self-Supervised Pre-Training](https://arxiv.org/abs/2403.03728) | 通过引入TCM启发式方法，本研究在主动学习中成功结合了多样性采样和不确定性采样策略，解决了冷启动问题并在各种数据水平上表现出色。 |
| [^30] | [Diffusion on language model embeddings for protein sequence generation](https://arxiv.org/abs/2403.03726) | 使用DiMA模型，在蛋白语言模型嵌入进行扩散来生成氨基酸序列，比传统解决方案表现更好，并通过设计选择的影响来量化其优越性能。 |
| [^31] | [Towards Controllable Time Series Generation](https://arxiv.org/abs/2403.03698) | 提出了 Controllable Time Series (CTS) 框架，通过解耦映射过程来实现对复杂交互模式的精确学习，从而创新了针对可控时间序列生成 (CTSG) 的方法。 |
| [^32] | [MolNexTR: A Generalized Deep Learning Model for Molecular Image Recognition](https://arxiv.org/abs/2403.03691) | MolNexTR是一种用于分子图像识别的通用深度学习模型，能够更细致提取分子图像的局部和全局特征，同时能够预测原子和键，理解布局规则，灵活整合符号化的化学原则，并且包含多种先进算法。 |
| [^33] | [Rapidly Developing High-quality Instruction Data and Evaluation Benchmark for Large Language Models with Minimal Human Effort: A Case Study on Japanese](https://arxiv.org/abs/2403.03690) | 通过GPT-4自指导方法，快速开发高质量的日语指令数据和评估基准，无需大量人力投入，并为大型语言模型提供了有效的资源 |
| [^34] | [General2Specialized LLMs Translation for E-commerce](https://arxiv.org/abs/2403.03689) | 提出了一个名为G2ST的两步微调范式，通过自对比语义增强将通用NMT模型转换为专门用于电子商务的NMT模型，以提高翻译质量。 |
| [^35] | [K-Link: Knowledge-Link Graph from LLMs for Enhanced Representation Learning in Multivariate Time-Series Data](https://arxiv.org/abs/2403.03645) | 提出了一种名为K-Link的框架，利用大型语言模型编码通用知识，提取了Knowledge-Link图以捕获传感器之间的广泛语义知识和联系。 |
| [^36] | [A Survey on Applications of Reinforcement Learning in Spatial Resource Allocation](https://arxiv.org/abs/2403.03643) | 运用强化学习解决空间资源分配问题的新方法具有快速解决方法收敛和强大的模型泛化能力等优势，为这一问题领域提供了新的视角。 |
| [^37] | [Apollo: Lightweight Multilingual Medical LLMs towards Democratizing Medical AI to 6B People](https://arxiv.org/abs/2403.03640) | Apollo项目开发了多语言医学LLMs，创建了全球人口61亿的医学数据集，并发布了各种尺寸的最佳性能模型，其中Apollo-7B是最先进的多语言医学LLMs，可改善更大模型的多语言医学能力。 |
| [^38] | [SheetAgent: A Generalist Agent for Spreadsheet Reasoning and Manipulation via Large Language Models](https://arxiv.org/abs/2403.03636) | SheetAgent是一种利用大型语言模型进行电子表格推理和操作的通用代理，提供了处理复杂现实任务的解决方案 |
| [^39] | [Multimodal Large Language Models to Support Real-World Fact-Checking](https://arxiv.org/abs/2403.03627) | 多模态大型语言模型在支持现实世界事实核查中展现出优越性能，并能够解释恶意和误导性声明的不合理之处和潜在动机。 |
| [^40] | [GSNeRF: Generalizable Semantic Neural Radiance Fields with Enhanced 3D Scene Understanding](https://arxiv.org/abs/2403.03608) | GSNeRF通过引入图像语义，实现了对未知场景的新视图图像和相关语义地图的生成，并在图像和语义渲染方面取得了改进性能。 |
| [^41] | [The Geometric Structure of Topic Models](https://arxiv.org/abs/2403.03607) | 提出了一种从平面话题模型中导出序数结构的关联几何方法，可以在高维度分析话题模型，提取多个主题之间的概念关系 |
| [^42] | [Enhancing Price Prediction in Cryptocurrency Using Transformer Neural Network and Technical Indicators](https://arxiv.org/abs/2403.03606) | 该研究提出了通过引入Transformer神经网络和技术指标来提升加密货币价格预测的方法，该方法对于捕获时间动态和提取重要特征具有显著的优势 |
| [^43] | [A Privacy-Preserving Framework with Multi-Modal Data for Cross-Domain Recommendation](https://arxiv.org/abs/2403.03600) | 提出了一种基于多模态数据的隐私保护框架用于跨领域推荐，通过设计多模态解耦编码器实现更好的特征学习。 |
| [^44] | [Assessing the Aesthetic Evaluation Capabilities of GPT-4 with Vision: Insights from Group and Individual Assessments](https://arxiv.org/abs/2403.03594) | 本研究评估了GPT-4与Vision在处理图像输入的最先进语言模型在审美评价任务中的表现，结果显示其在预测审美评价方面表现出色，并展现了对美和丑的不同反应的特性。 |
| [^45] | [Do You Trust Your Model? Emerging Malware Threats in the Deep Learning Ecosystem](https://arxiv.org/abs/2403.03593) | 介绍了MaleficNet 2.0，一种在神经网络中嵌入恶意软件的新技术，其注入技术具有隐蔽性，不会降低模型性能，并且对神经网络参数中的恶意有效负载进行注入 |
| [^46] | [Wildest Dreams: Reproducible Research in Privacy-preserving Neural Network Training](https://arxiv.org/abs/2403.03592) | 隐私保护技术的最新进展使得可以在受保护数据上进行机器学习训练和推断，但在实际应用中仍面临挑战。 |
| [^47] | [RouteExplainer: An Explanation Framework for Vehicle Routing Problem](https://arxiv.org/abs/2403.03585) | 提出了一种车辆路径问题的解释框架RouteExplainer，实现了边的影响解释和意图推断，通过大型语言模型生成解释文本，并在多个VRP上进行了量化评估 |
| [^48] | [Design of an Open-Source Architecture for Neural Machine Translation](https://arxiv.org/abs/2403.03582) | 该开源应用程序 adaptNMT 简化了神经机器翻译模型的开发和部署，提供了图形化训练进展展示、子词分割模型和一键式模型开发方法。 |
| [^49] | [Causal Disentanglement for Regulating Social Influence Bias in Social Recommendation](https://arxiv.org/abs/2403.03578) | 提出了一种基于因果分解的框架CDRSB，用于调节社交推荐中的社交影响偏差，以提高推荐性能。 |
| [^50] | [gaHealth: An English-Irish Bilingual Corpus of Health Data](https://arxiv.org/abs/2403.03575) | 开发了一份用于低资源英语到爱尔兰语言对的特定健康领域数据集，实证证明使用领域数据对健康领域具有明显好处，并展示的最大BLEU分数提升为22.2点（40%）。 |
| [^51] | [Emotional Manipulation Through Prompt Engineering Amplifies Disinformation Generation in AI Large Language Models](https://arxiv.org/abs/2403.03550) | 研究通过提示工程和情绪操纵研究了OpenAI的大型语言模型在生成虚假信息方面的反应，发现它们能够成功生成虚假信息并对情绪提示有细致的理解。 |
| [^52] | [Prompt Mining for Language-based Human Mobility Forecasting](https://arxiv.org/abs/2403.03544) | 使用信息熵进行提示挖掘，探索多样化的提示设计策略，提高基于语言的人类移动预测的准确性和效果 |
| [^53] | [RADIA -- Radio Advertisement Detection with Intelligent Analytics](https://arxiv.org/abs/2403.03538) | 本研究提出了一种新型自动广播广告检测技术RADIA，利用先进的语音识别和文本分类算法，能够在不需要先验知识的情况下检测广播中的即兴和新广告，为广播广告检测提供了全面的解决方案，并取得了较高的F1-macro得分。 |
| [^54] | [Towards Efficient and Effective Unlearning of Large Language Models for Recommendation](https://arxiv.org/abs/2403.03536) | 提出了E2URec，这是为了解决大型语言模型在推荐系统中遗忘特定用户数据所面临的效率和有效性方面的挑战。 |
| [^55] | [IB-Net: Initial Branch Network for Variable Decision in Boolean Satisfiability](https://arxiv.org/abs/2403.03517) | IB-Net 提出了一种创新的框架，利用图神经网络和新颖的图编码技术来加速布尔可满足性问题的求解。 |
| [^56] | [Towards Detecting AI-Generated Text within Human-AI Collaborative Hybrid Texts](https://arxiv.org/abs/2403.03506) | 本研究探索了在人工智能协作混合文本中句子级人工智能生成文本检测的挑战，并提出了一种基于分割的两步骤流程来检测各段落的一致作者句子。 |
| [^57] | [DLP-GAN: Learning to Draw Modern Chinese Landscape Photos with Generative Adversarial Network](https://arxiv.org/abs/2403.03456) | 该论文提出了DLP-GAN模型，使用生成对抗网络实现了现代中国风景照片的绘制，引入了不对称循环映射和双一致性损失来平衡现实感和抽象性。 |
| [^58] | [Uncertainty quantification for deeponets with ensemble kalman inversion](https://arxiv.org/abs/2403.03444) | 使用集合卡尔曼反演方法针对DeepONets提出了一种高效的不确定性量化推断方法。 |
| [^59] | [Mixture-of-LoRAs: An Efficient Multitask Tuning for Large Language Models](https://arxiv.org/abs/2403.03432) | 提出了一种新颖且参数高效的混合LoRAs（MoA）架构，通过引入领域标签和显式路由策略，解决了大型语言模型多任务学习中的灾难性遗忘和任务干扰问题，从而提升了每个任务的性能。 |
| [^60] | [LEAD: Learning Decomposition for Source-free Universal Domain Adaptation](https://arxiv.org/abs/2403.03421) | 提出了LEAD方法，通过将特征分解为源已知和未知组件来识别目标私有数据。 |
| [^61] | [Negating Negatives: Alignment without Human Positive Samples via Distributional Dispreference Optimization](https://arxiv.org/abs/2403.03419) | 通过提出Distributional Dispreference Optimization (D$^2$O)方法，在不需要人类正样本的情况下实现了对齐，减少了有害信息的传播。 |
| [^62] | [Sparse Spiking Neural Network: Exploiting Heterogeneity in Timescales for Pruning Recurrent SNN](https://arxiv.org/abs/2403.03409) | 该论文提出了一种利用 Lyapunov Noise Pruning (LNP) 算法，通过随机初始化模型修剪神经元，利用神经元时间尺度的异质性设计出稀疏RSNN，实现了设计稀疏脉冲神经网络的任务-无关方法。 |
| [^63] | [Human vs. Machine: Language Models and Wargames](https://arxiv.org/abs/2403.03407) | 人工智能大型语言模型在战争游戏中与人类响应存在一致性，但也存在显著的差异，这表明在政策制定者交出自主权或听从基于AI的战略建议之前应谨慎对待。 |
| [^64] | [An EnKF-LSTM Assimilation Algorithm for Crop Growth Model](https://arxiv.org/abs/2403.03406) | 本文提出了一种EnKF-LSTM数据同化方法，通过结合集合卡尔曼滤波器和LSTM神经网络，提高了作物生长预测的准确性。 |
| [^65] | [BAIT: Benchmarking (Embedding) Architectures for Interactive Theorem-Proving](https://arxiv.org/abs/2403.03401) | BAIT框架提供了公平且简化的ITP学习方法比较，发现Structure Aware Transformers在公式嵌入问题上表现出色。 |
| [^66] | [Interactive Melody Generation System for Enhancing the Creativity of Musicians](https://arxiv.org/abs/2403.03395) | 该系统通过整合多个循环神经网络模型，提供了一种类似与多位作曲家合作的体验，从而促进多样化的创造力，并通过动态适应用户创意意图来增强生成旋律的能力。 |
| [^67] | [Multi-modal Deep Learning](https://arxiv.org/abs/2403.03385) | 本研究通过CCT、Patch Up和新颖的CamCenterLoss技术对临床数据处理进行创新，提高了预测准确性，对危重病人的关注更多，为未来的多模态医学研究铺平道路。 |
| [^68] | [Adaptive Discovering and Merging for Incremental Novel Class Discovery](https://arxiv.org/abs/2403.03382) | 提出了自适应发现和合并（ADM）范例，以在增量阶段自适应地发现新类别并将新知识集成到模型中，同时减少对原有知识的影响。 |
| [^69] | [RACE-SM: Reinforcement Learning Based Autonomous Control for Social On-Ramp Merging](https://arxiv.org/abs/2403.03359) | 该论文提出了一种基于强化学习的自主控制模型，专注于并行式匝道合流，考虑了道路上其他车辆的影响，并提出了新颖的激励函数。 |
| [^70] | [The Case for Globalizing Fairness: A Mixed Methods Study on Colonialism, AI, and Health in Africa](https://arxiv.org/abs/2403.03357) | 该研究探讨了全球卫生公平性，以非洲为案例研究，通过范围审查和定性研究揭示了ML技术在非洲健康领域中可能出现的不公平现象，并特别关注殖民主义作为一个重要属性。 |
| [^71] | [Learning to Maximize Mutual Information for Chain-of-Thought Distillation](https://arxiv.org/abs/2403.03348) | 通过最大化两个任务的表示特征的互信息，提出了一种解决思维链蒸馏中标签预测任务与知识集成不足问题的变分方法。 |
| [^72] | [Learn to Code Sustainably: An Empirical Study on LLM-based Green Code Generation](https://arxiv.org/abs/2403.03344) | 本研究提供了一个关于绿色编码实践和AI模型可持续性意识的实证研究，评估了商业AI语言模型生成的自动生成代码的可持续性。 |
| [^73] | [DIVERSE: Deciphering Internet Views on the U.S. Military Through Video Comment Stance Analysis, A Novel Benchmark Dataset for Stance Classification](https://arxiv.org/abs/2403.03334) | 本文提出了一个名为DIVERSE的数据集，其中包含超过173,000条YouTube视频评论，标注了这些评论对美国军事视频的立场，采用了一种通过人类引导、机器辅助的标注方法，使用了句子中的弱信号作为支持指标。 |
| [^74] | [Deep Configuration Performance Learning: A Systematic Survey and Taxonomy](https://arxiv.org/abs/2403.03322) | 性能是可配置软件系统行为的关键属性，本文针对深度学习在可配置软件性能学习方面进行了全面的调查与分类研究。 |
| [^75] | [Best of Both Worlds: A Pliable and Generalizable Neuro-Symbolic Approach for Relation Classification](https://arxiv.org/abs/2403.03305) | 该论文介绍了一种将基于规则的方法与深度学习技术相结合的神经符号架构，通过神经组件提升规则泛化能力，实现了两种范式的优势，且在少样本关系分类数据集上取得了优于之前最先进模型的表现 |
| [^76] | [AI Insights: A Case Study on Utilizing ChatGPT Intelligence for Research Paper Analysis](https://arxiv.org/abs/2403.03293) | 本文讨论了如何利用ChatGPT智能对研究论文进行分析，以有效撰写科学文献调查，在乳腺癌治疗这一研究课题上取得了较高准确度。 |
| [^77] | [Should We Fear Large Language Models? A Structural Analysis of the Human Reasoning System for Elucidating LLM Capabilities and Risks Through the Lens of Heidegger's Philosophy](https://arxiv.org/abs/2403.03288) | 本研究通过比较LLMs中的统计模式与海德格尔哲学概念，探讨了LLMs作为知识能力数字化对应和人类推理模拟的能力，并通过海德格尔的真理概念对人类推理进行结构性分析。 |
| [^78] | [Credibility-Aware Multi-Modal Fusion Using Probabilistic Circuits](https://arxiv.org/abs/2403.03281) | 提出了一种使用概率电路进行可信度感知的多模态融合方法，在维持竞争性能的同时能够可靠推断可信度。 |
| [^79] | [ARNN: Attentive Recurrent Neural Network for Multi-channel EEG Signals to Identify Epileptic Seizures](https://arxiv.org/abs/2403.03276) | ARNN提出了一种注意力循环神经网络，用于处理多通道脑电图信号，具有线性复杂度和并行计算，结合注意力和LSTM gate的优势，并避免了它们的缺点。 |
| [^80] | [From Noise to Signal: Unveiling Treatment Effects from Digital Health Data through Pharmacology-Informed Neural-SDE](https://arxiv.org/abs/2403.03274) | 通过药理学启发的神经随机微分方程模型，有效地识别数字健康数据中的治疗效果和学习因果关系，从而实现反事实能力。 |
| [^81] | [Note: Harnessing Tellurium Nanoparticles in the Digital Realm Plasmon Resonance, in the Context of Brewster's Angle and the Drude Model for Fake News Adsorption in Incomplete Information Games](https://arxiv.org/abs/2403.03239) | 这篇论文探讨了孤子理论和等离子现象在数字健康平台中建模用户行为和参与方面的创新应用，通过引入孤子解的概念，提出了理解健康改善行为模式的新方法，同时深入研究了硒化镉纳米颗粒在吸附假新闻中的等离子特性对用户互动和参与水平的影响。 |
| [^82] | [Large language models surpass human experts in predicting neuroscience results](https://arxiv.org/abs/2403.03230) | 大型语言模型通过整合广泛科学文献中的相关发现，能够优于人类专家预测神经科学实验结果，预示着人类与大型语言模型共同进行发现的未来。 |
| [^83] | [Reinforcement Learning Jazz Improvisation: When Music Meets Game Theory](https://arxiv.org/abs/2403.03224) | 介绍了一个新颖的数学博弈论模型用于研究爵士即兴演奏，探索不同的随机即兴策略和其在即兴演奏中的配对表现，发现最有效的策略对是逐步改变和和弦跟随强化学习。 |
| [^84] | [Knowledge-guided EEG Representation Learning](https://arxiv.org/abs/2403.03222) | 提出了一个知识引导的EEG自监督学习模型，通过使用基于状态空间的深度学习架构，实现了稳健的性能和显著的参数效率。 |
| [^85] | [Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation](https://arxiv.org/abs/2403.02951) | 大型语言模型在文本生成SQL任务中表现出色，但对于最佳提示模板和设计框架仍无共识，新数据集和评估任务有助于全面评估各种方法的表现，并提出了优化解决方案。 |
| [^86] | [ImgTrojan: Jailbreaking Vision-Language Models with ONE Image](https://arxiv.org/abs/2403.02910) | 本文提出了一种针对视觉-语言模型的新型越狱攻击，通过在训练数据中插入恶意文本提示，成功实施越狱攻击，并分析了有毒数据比率和可训练参数位置对攻击成功率的影响。 |
| [^87] | [NeuroVoz: a Castillian Spanish corpus of parkinsonian speech](https://arxiv.org/abs/2403.02371) | 这一研究提出了一个包含108位母语为卡斯蒂利亚语说话者的帕金森病患者语音语料库，涵盖了多种语音任务，通过手动和自动转录确保了数据的准确性和可靠性。 |
| [^88] | [Deep Reinforcement Learning for Dynamic Algorithm Selection: A Proof-of-Principle Study on Differential Evolution](https://arxiv.org/abs/2403.02131) | 本论文提出了一种基于深度强化学习的动态算法选择框架，旨在通过训练代理根据优化过程中观察到的特征选择最合适的算法，以解决单个算法有效性在不同问题实例上变化的问题。 |
| [^89] | [Position Paper: Towards Implicit Prompt For Text-To-Image Models](https://arxiv.org/abs/2403.02118) | 该位置论文讨论了文本到图像模型在隐式提示方面的现状，提出了名为ImplicitBench的新基准，并对 T2I 模型在隐式提示下的表现及影响进行了调查。 |
| [^90] | [AllSpark: Reborn Labeled Features from Unlabeled in Transformer for Semi-Supervised Semantic Segmentation](https://arxiv.org/abs/2403.01818) | AllSpark利用通道级交叉注意机制从未标记的特征中重新生成标记特征，以改善半监督语义分割中低质量伪标签的问题。 |
| [^91] | [Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy](https://arxiv.org/abs/2402.19379) | 该研究通过将十二个LLMs组成的LLM集成方法与925名人类预测者的群体预测进行比较，发现LLM群体优于简单的无信息基准，并在统计上等效于人类群体。 |
| [^92] | [Learning with Language-Guided State Abstractions](https://arxiv.org/abs/2402.18759) | 利用自然语言和语言模型引导的方法，实现自动构建适用于未见任务的状态表示，有助于高维观测空间中泛化策略学习。 |
| [^93] | [Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards](https://arxiv.org/abs/2402.18571) | 提出了方向偏好对齐（DPA）框架，通过多目标奖励模拟不同偏好配置，以实现用户相关的偏好控制。 |
| [^94] | [On the use of Silver Standard Data for Zero-shot Classification Tasks in Information Extraction](https://arxiv.org/abs/2402.18061) | 本研究提出了一个新框架Clean-LaVe，旨在利用银标准数据来增强零样本分类性能。 |
| [^95] | [Structure-Guided Adversarial Training of Diffusion Models](https://arxiv.org/abs/2402.17563) | SADM通过对抗训练的方式引入结构指导，使得模型能够学习每个训练批次中样本之间的流形结构。 |
| [^96] | [A prior Estimates for Deep Residual Network in Continuous-time Reinforcement Learning](https://arxiv.org/abs/2402.16899) | 本研究针对连续时间控制问题，提出了一种可以直接分析Bellman最优损失\emph{先验}泛化误差的方法，避免了有界性假设，并通过最大算子的分解方法实现了损失函数的转换。 |
| [^97] | [Cross-Modal Contextualized Diffusion Models for Text-Guided Visual Generation and Editing](https://arxiv.org/abs/2402.16627) | 提出了一种新颖且通用的上下文化扩散模型（ContextDiff），通过在正向和逆向过程中融入文本条件和视觉样本之间的交互和对齐，以便在视觉生成中更准确地传达文本语义 |
| [^98] | [Pfeed: Generating near real-time personalized feeds using precomputed embedding similarities](https://arxiv.org/abs/2402.16073) | 使用预计算的嵌入相似性生成个性化信息流，提高了电子商务平台上的客户参与度和体验，转化率提升4.9％。 |
| [^99] | [Brant-2: Foundation Model for Brain Signals](https://arxiv.org/abs/2402.10251) | Brant-2是脑信号领域最大的基础模型，相比于Brant，它不仅对数据变化和建模尺度具有稳健性，还能适用于更广泛范围的脑神经数据。 |
| [^100] | [Average-Case Analysis of Iterative Voting](https://arxiv.org/abs/2402.08144) | 这项工作通过分析代理人偏好分布的平均情况，扩展了迭代投票模型的效果分析。并且区分了迭代多数制何时改善或降低渐近福利。 |
| [^101] | [Error Estimation for Physics-informed Neural Networks Approximating Semilinear Wave Equations](https://arxiv.org/abs/2402.07153) | 本文提供了物理信息神经网络逼近半线性波动方程的严格误差界限，包括泛化误差和训练误差的界限，并在数值实验中展示了理论界限的有效性。 |
| [^102] | [Prompt Learning on Temporal Interaction Graphs](https://arxiv.org/abs/2402.06326) | 这个论文提出了一种在时间交互图上进行提示学习的方法，以解决当前模型在预训练和下游预测阶段所面临的时间差异和语义差异的问题。 |
| [^103] | [Read to Play (R2-Play): Decision Transformer with Multimodal Game Instruction](https://arxiv.org/abs/2402.04154) | 本论文探索了为智能体提供增强形式的任务指导，使其能够理解游戏指导并实现"读玩游戏"的能力。通过将多模态指导调优的成功应用于视觉任务中的强化学习任务，构建了一组... (内容太长，无法继续显示) |
| [^104] | [Integration of cognitive tasks into artificial general intelligence test for large models](https://arxiv.org/abs/2402.02547) | 建议将认知任务整合到大型模型的人工通用智能测试中，以建立一个综合框架，能够评估大型模型的多维智能。这个框架结合了认知科学和自然语言处理，包含了稳态智力、流态智力和社交智能等方面。 |
| [^105] | [MedLM: Exploring Language Models for Medical Question Answering Systems](https://arxiv.org/abs/2401.11389) | 本研究比较了用于医疗问答的通用和医学特定的精炼语言模型的表现，以填补领域特定任务中这些模型性能的研究空白。 |
| [^106] | [SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene Understanding](https://arxiv.org/abs/2401.09340) | 本研究通过系统性地扩展室内环境中的3D视觉-语言学习，提出了首个百万规模的3D视觉-语言数据集SceneVerse，以解决3D视觉-语言对齐面临的几个重要挑战。 |
| [^107] | [Understanding Distributed Representations of Concepts in Deep Neural Networks without Supervision](https://arxiv.org/abs/2312.17285) | 本文提出了一种无监督方法，通过选择主要神经元来发现概念的分布表示，可以用于识别数据中的未标记子类和检测误分类的原因。 |
| [^108] | [Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models](https://arxiv.org/abs/2312.14197) | 该研究引入了第一个间接提示注入攻击基准测试BIPIA，对大型语言模型在面对此类攻击时的风险进行评估，并分析了攻击成功的原因，从而开发了防御方法。 |
| [^109] | [Parameterized Projected Bellman Operator](https://arxiv.org/abs/2312.12869) | 本论文提出了一种基于学习的近似贝尔曼算子的新方法，以解决近似值迭代算法中样本不确定性和计算复杂度的问题。 |
| [^110] | [A Novel Image Classification Framework Based on Variational Quantum Algorithms](https://arxiv.org/abs/2312.07932) | 这项研究提出了一种基于变分量子算法的新型图像分类框架，通过消除全局池化操作，保留了更多图像的判别特征和细节，从而增强了分类性能。 |
| [^111] | [Large-scale Training of Foundation Models for Wearable Biosignals](https://arxiv.org/abs/2312.05409) | 利用自监督学习和大规模可穿戴设备数据，本研究训练了基础模型用于衡量光电容积描记（PPG）和心电图信号，以解决医学数据集规模较小的难题。 |
| [^112] | [Fair Text-to-Image Diffusion via Fair Mapping](https://arxiv.org/abs/2311.17695) | 本文提出了一种通过Fair Mapping控制模型提示来修改文本到图像扩散模型，实现公平图像生成的方法，具有高效性和能够生成相对平衡人口统计结果的优势。 |
| [^113] | [Self-Supervised Deconfounding Against Spatio-Temporal Shifts: Theory and Modeling](https://arxiv.org/abs/2311.12472) | 该论文针对时空数据中常见的分布变化问题提出了一种自监督去混淆方法并提出了名为DCA的理论解决方案。 |
| [^114] | [From Coupled Oscillators to Graph Neural Networks: Reducing Over-smoothing via a Kuramoto Model-based Approach](https://arxiv.org/abs/2311.03260) | 提出了一种新型的连续深度图神经网络KuramotoGNN，通过采用Kuramoto模型来减轻GNN中的过度平滑现象，实现节点特征的差异化，取得了优于基线GNN和现有方法的实验效果。 |
| [^115] | [Improving Adversarial Attacks on Latent Diffusion Model](https://arxiv.org/abs/2310.04687) | 提出了一种改进 Latent Diffusion Model 的对抗攻击方法 ACE，其通过统一模式的额外误差来促使模型学习特定的偏差，从而胜过了目前最先进的方法 |
| [^116] | [AI-Dentify: Deep learning for proximal caries detection on bitewing x-ray -- HUNT4 Oral Health Study](https://arxiv.org/abs/2310.00354) | 通过深度学习模型，研究展示了对HUNT4口腔健康研究中全景X光图像进行快速准确齿龈龋齿检测的潜力 |
| [^117] | [Continual Driving Policy Optimization with Closed-Loop Individualized Curricula](https://arxiv.org/abs/2309.14209) | 开发了连续驾驶政策优化框架，提出了闭环个性化课程（CLIC）概念，允许重复利用广泛场景来迭代改进自主驾驶车辆模型。 |
| [^118] | [Prompting and Fine-Tuning Open-Sourced Large Language Models for Stance Classification](https://arxiv.org/abs/2309.13734) | 本研究探讨了使用大型语言模型作为立场检测方法以减少手动注释的需求，发现它们与域内监督模型具有竞争力，但性能不一致。 |
| [^119] | [THC: Accelerating Distributed Deep Learning Using Tensor Homomorphic Compression](https://arxiv.org/abs/2302.08545) | 引入了Tensor Homomorphic Compression (THC)，一种新颖的双向压缩框架，可以加速分布式深度学习中的模型训练 |
| [^120] | [Spatio-Temporal Self-Supervised Learning for Traffic Flow Prediction](https://arxiv.org/abs/2212.04475) | 提出了一种新的时空自监督学习（ST-SSL）交通预测框架，通过辅助自监督学习范式增强交通模式表示，既反映空间异质性又反映时间异质性。 |
| [^121] | [Decision-making with Speculative Opponent Models](https://arxiv.org/abs/2211.11940) | 提出了一种使用纯粹局部信息实现推测对手建模的多智能体分布式演员-评论家算法，能够帮助受控代理做出决策。 |
| [^122] | [Seamful XAI: Operationalizing Seamful Design in Explainable AI](https://arxiv.org/abs/2211.06753) | 通过揭示和利用社会技术和基础设施不匹配，无缝设计可以促进AI可解释性 |
| [^123] | [SemSegDepth: A Combined Model for Semantic Segmentation and Depth Completion](https://arxiv.org/abs/2209.00381) | 在本文中，我们提出了一个新的端到端模型，用于同时进行语义分割和深度完成。我们的方法结合了语义分割和深度完成任务，在多任务网络中有效提高了每个任务的性能。 |
| [^124] | [The Who in XAI: How AI Background Shapes Perceptions of AI Explanations](https://arxiv.org/abs/2107.13509) | AI背景如何影响解释的解读，揭示了“谁”对于AI解释的重要性。 |
| [^125] | [SelectLLM: Can LLMs Select Important Instructions to Annotate?.](http://arxiv.org/abs/2401.16553) | 这项工作提出了一种名为SelectLLM的新方法，利用LLMs选择高质量指令。通过提示LLMs估计每个无标签指令的有用性和影响力，并使用聚类算法将指令分为多个聚类。 |
| [^126] | [Q&A Prompts: Discovering Rich Visual Clues through Mining Question-Answer Prompts for VQA requiring Diverse World Knowledge.](http://arxiv.org/abs/2401.10712) | 本论文提出了一种叫做Q&A提示的方法，通过挖掘图像中的问题-回答对来发现丰富的视觉线索，以帮助AI模型更好地理解复杂视觉问题，提高跨模态推理能力。 |
| [^127] | [DevEval: Evaluating Code Generation in Practical Software Projects.](http://arxiv.org/abs/2401.06401) | 本文提出了一个名为DevEval的新基准测试，用于评估实际软件项目中的代码生成。与之前的基准测试相比，DevEval在真实的项目分布、充足的依赖和足够规模的项目背景等方面更贴合实际。通过对五个流行的大型语言模型进行评估，我们揭示了它们在代码生成中的实际能力。 |
| [^128] | [Let's Go Shopping (LGS) -- Web-Scale Image-Text Dataset for Visual Concept Understanding.](http://arxiv.org/abs/2401.04575) | Let's Go Shopping (LGS) dataset is a large-scale public dataset with 15 million image-caption pairs from publicly available e-commerce websites, providing a more efficient way to collect and annotate images for vision and vision-language applications. |
| [^129] | [A white box solution to the black box problem of AI.](http://arxiv.org/abs/2401.03093) | 一种解决人工智能黑盒问题的白盒解决方案是使用基于相关领域一般理论的确定性逻辑细胞自动机的规则，该细胞自动机实现自动并行逻辑推理。 |
| [^130] | [Leveraging Ensemble Diversity for Robust Self-Training in the Presence of Sample Selection Bias.](http://arxiv.org/abs/2310.14814) | 本文提出了一种在样本选择偏差存在的情况下，利用集成多样性进行鲁棒的自训练的方法，并引入了一种新的自信度度量方法-$\mathcal{T}$-相似度。实验证明该方法在三种不同伪标签策略下具有良好的效果。 |
| [^131] | [Scalable Neural Network Kernels.](http://arxiv.org/abs/2310.13225) | 可扩展神经网络内核（SNNKs）是一种替代常规前馈层的方法，能够近似实现常规前馈层的功能，但具有更优的计算特性。通过将内核与参数-输入向量的点积联系起来，SNNKs能够有效地解开参数与输入之间的联系，从而模拟复杂关系。此外，我们还引入了神经网络捆绑过程，将SNNKs应用于深度神经网络压缩，进一步提高了压缩效果。最终捆绑网络甚至可以绕过反向传播，通过显式公式求解最优参数。 |
| [^132] | [A Prefrontal Cortex-inspired Architecture for Planning in Large Language Models.](http://arxiv.org/abs/2310.00194) | 这个论文提出了一个受前额叶皮层启发的大型语言模型规划架构，利用多个基于LLM的模块实现规划的自主协调，从而在处理需要多步推理或目标导向规划的任务时取得了较好的效果。 |
| [^133] | [On Generating Explanations for Reinforcement Learning Policies: An Empirical Study.](http://arxiv.org/abs/2309.16960) | 本文通过引入一组线性时态逻辑（LTL）公式，介绍了一种生成强化学习策略解释的方法，并展示了其在模拟夺旗环境中的有效性。 |
| [^134] | [Causal-Story: Local Causal Attention Utilizing Parameter-Efficient Tuning For Visual Story Synthesis.](http://arxiv.org/abs/2309.09553) | 提出了一种称为因果故事的新模型，利用局部因果注意力机制来改进视觉故事合成的全局一致性，该模型考虑了历史标题、帧和当前标题之间的因果关系，实现了更好的生成效果。 |
| [^135] | [Projected Task-Specific Layers for Multi-Task Reinforcement Learning.](http://arxiv.org/abs/2309.08776) | 本研究提出了一种新的架构，Projected Task-Specific Layers (PTSL)，通过任务特定的层来表达共享和可变的任务信息，成功解决了多任务强化学习中的推广和干扰问题。 |
| [^136] | [PyGraft: Configurable Generation of Schemas and Knowledge Graphs at Your Fingertips.](http://arxiv.org/abs/2309.03685) | PyGraft是一个Python工具，可以根据需要生成高度定制的模式和知识图谱，并确保生成的资源的逻辑一致性。 |
| [^137] | [xxMD: Benchmarking Neural Force Fields Using Extended Dynamics beyond Equilibrium.](http://arxiv.org/abs/2308.11155) | 在神经力场模型中，常用的MD17数据集对于表示经历化学反应的系统不足。为了解决这一问题，我们引入了xxMD数据集，该数据集采样自扩展激发态分子动力学，包含了能量和力的信息。 |
| [^138] | [VQGraph: Graph Vector-Quantization for Bridging GNNs and MLPs.](http://arxiv.org/abs/2308.02117) | VQGraph是一个框架，通过学习一个强大的图形表示空间，用于连接GNN和MLPs。它采用矢量量化变分自编码器（VQ-VAE）的编码器作为结构感知图标记器，有效地表示底层图的多样化局部结构。通过 VQGraph，可以实现从GNN到MLP的知识转移。 |
| [^139] | [Arithmetic with Language Models: from Memorization to Computation.](http://arxiv.org/abs/2308.01154) | 本研究探索了使用语言模型进行算术计算的能力，发现语言模型可以通过内部的值空间进行计算，并取得了成功的实验结果。 |
| [^140] | [Interpretable Stereotype Identification through Reasoning.](http://arxiv.org/abs/2308.00071) | 本研究通过使用推理方法，在零射击刻板印象识别中取得了重要的进展，并发现推理的性能增益远远超过模型规模扩展的增益。推理不仅提高了准确性，还提高了决策的可解释性。 |
| [^141] | [Unstoppable Attack: Label-Only Model Inversion via Conditional Diffusion Model.](http://arxiv.org/abs/2307.08424) | 本论文提出了一种在标签仅黑盒场景下的模型逆推攻击方法，使用条件扩散模型恢复目标的精确样本，无需额外的优化。 |
| [^142] | [BERTTM: Leveraging Contextualized Word Embeddings from Pre-trained Language Models for Neural Topic Modeling.](http://arxiv.org/abs/2305.09329) | 本文提出了一种新颖的神经主题模型，利用来自预训练语言模型BERT的上下文化词嵌入，可以在不使用任何BoW信息的情况下推断出文档的主题分布，并直接从上下文化词嵌入中推断出文档中每个单词的主题分布。实验结果表明，该模型优于仅依赖BoW表示和其他神经主题模型的现有最先进方法。 |
| [^143] | [Treat Different Negatives Differently: Enriching Loss Functions with Domain and Range Constraints for Link Prediction.](http://arxiv.org/abs/2303.00286) | 通过引入领域和范围约束，我们提出了基于语义的损失函数来区分不同质量的负样本，实验证明在链接预测任务上有效。 |
| [^144] | [Optimal Settings for Cryptocurrency Trading Pairs.](http://arxiv.org/abs/2210.10971) | 本文研究了加密货币交易对的最优设置问题，并提出了一个两阶段过程来解决这个优化问题。该问题的特殊之处在于大部分可能的交易对之间的交易量无法直接观察，且需要满足连通性约束。 |

# 详细

[^1]: 停止回归：通过分类训练值函数实现可扩展的深度强化学习

    Stop Regressing: Training Value Functions via Classification for Scalable Deep RL

    [https://arxiv.org/abs/2403.03950](https://arxiv.org/abs/2403.03950)

    通过使用分类代替回归训练值函数，本文提出了一种简单方法来改善深度强化学习的性能和可扩展性

    

    值函数是深度强化学习（RL）的核心组件。这些通过神经网络参数化的函数，使用均方误差回归目标进行训练，以匹配自举目标值。然而，将使用回归的价值型RL方法扩展到大型网络，如高容量的Transformers，已被证明是具有挑战性的。本文观察到了这一差异，探讨了通过使用分类而不是回归来训练值函数是否也可以简单地提高深度RL的可扩展性。我们证明，使用分类交叉熵训练的值函数在各种领域中显著提高了性能和可扩展性。这些领域包括：在Atari 2600游戏上使用SoftMoEs进行单一任务RL。

    arXiv:2403.03950v1 Announce Type: cross  Abstract: Value functions are a central component of deep reinforcement learning (RL). These functions, parameterized by neural networks, are trained using a mean squared error regression objective to match bootstrapped target values. However, scaling value-based RL methods that use regression to large networks, such as high-capacity Transformers, has proven challenging. This difficulty is in stark contrast to supervised learning: by leveraging a cross-entropy classification loss, supervised methods have scaled reliably to massive networks. Observing this discrepancy, in this paper, we investigate whether the scalability of deep RL can also be improved simply by using classification in place of regression for training value functions. We demonstrate that value functions trained with categorical cross-entropy significantly improves performance and scalability in a variety of domains. These include: single-task RL on Atari 2600 games with SoftMoEs
    
[^2]: 通过模拟调和现实：一种用于稳健操作的实-模-实方法

    Reconciling Reality through Simulation: A Real-to-Sim-to-Real Approach for Robust Manipulation

    [https://arxiv.org/abs/2403.03949](https://arxiv.org/abs/2403.03949)

    该论文提出了一种名为RialTo的系统，通过在“数字孪生”模拟环境中进行强化学习来稳健化真实世界的模仿学习策略，以实现在不需要大量不安全真实世界数据采集或广泛人类监督的情况下学习性能优越、稳健的策略。

    

    仿真学习方法需要大量人类监督来学习对物体姿势变化、物理干扰和视觉扰动鲁棒的策略。另一方面，强化学习可以自主探索环境以学习稳健行为，但可能需要大量不安全的真实世界数据采集。为了在没有不安全真实世界数据采集或广泛人类监督的负担下学习性能优越、稳健的策略，我们提出了RialTo，一个通过在即将从少量真实世界数据构建的“数字孪生”模拟环境中进行强化学习来稳健化真实世界的模仿学习策略的系统。为了实现这种实-模-实流水线，RialTo提出了一个易于使用的接口，用于快速扫描和构建真实世界环境的数字孪生。我们还引入了一种新颖的“反向提炼”过程，用于给真实世界演示带来

    arXiv:2403.03949v1 Announce Type: cross  Abstract: Imitation learning methods need significant human supervision to learn policies robust to changes in object poses, physical disturbances, and visual distractors. Reinforcement learning, on the other hand, can explore the environment autonomously to learn robust behaviors but may require impractical amounts of unsafe real-world data collection. To learn performant, robust policies without the burden of unsafe real-world data collection or extensive human supervision, we propose RialTo, a system for robustifying real-world imitation learning policies via reinforcement learning in "digital twin" simulation environments constructed on the fly from small amounts of real-world data. To enable this real-to-sim-to-real pipeline, RialTo proposes an easy-to-use interface for quickly scanning and constructing digital twins of real-world environments. We also introduce a novel "inverse distillation" procedure for bringing real-world demonstrations
    
[^3]: 使用基于Transformer的生成模型进行极端降水即时预报

    Extreme Precipitation Nowcasting using Transformer-based Generative Models

    [https://arxiv.org/abs/2403.03929](https://arxiv.org/abs/2403.03929)

    使用基于Transformer的生成模型NowcastingGPT-EVL在极端降水预测中表现出优越性能，尤其在处理极端降水事件时。

    

    本文提出了一种创新的方法，通过使用基于Transformer的生成模型，即带有极值损失（EVL）正则化的NowcastingGPT，进行极端降水即时预报。利用来自荷兰皇家气象研究所（KNMI）的全面数据集，我们的研究重点是高精度地预测短期降水。我们引入了一种新颖的计算EVL的方法，而不是假定固定的极端表示，从而解决了当前模型在捕捉极端天气事件方面的局限性。我们展示了定性和定量分析，证明了所提议的NowcastingGPT-EVL在生成准确的降水预报方面的优越性能，特别是在处理极端降水事件时。代码可在\url{https://github.com/Cmeo97/NowcastingGPT}上找到。

    arXiv:2403.03929v1 Announce Type: cross  Abstract: This paper presents an innovative approach to extreme precipitation nowcasting by employing Transformer-based generative models, namely NowcastingGPT with Extreme Value Loss (EVL) regularization. Leveraging a comprehensive dataset from the Royal Netherlands Meteorological Institute (KNMI), our study focuses on predicting short-term precipitation with high accuracy. We introduce a novel method for computing EVL without assuming fixed extreme representations, addressing the limitations of current models in capturing extreme weather events. We present both qualitative and quantitative analyses, demonstrating the superior performance of the proposed NowcastingGPT-EVL in generating accurate precipitation forecasts, especially when dealing with extreme precipitation events. The code is available at \url{https://github.com/Cmeo97/NowcastingGPT}.
    
[^4]: 意识作为有限计算

    Consciousness qua Mortal Computation

    [https://arxiv.org/abs/2403.03925](https://arxiv.org/abs/2403.03925)

    意识被看作是一种新型的计算，称为有限计算，这与传统的图灵计算不同。

    

    计算功能主义认为意识是一种计算。在这里，我们展示出，或许令人惊讶的是，它不能是图灵计算。相反，计算功能主义暗示着意识是一种新型计算，由Geoffrey Hinton最近提出，称为有限计算。

    arXiv:2403.03925v1 Announce Type: cross  Abstract: Computational functionalism posits that consciousness is a computation. Here we show, perhaps surprisingly, that it cannot be a Turing computation. Rather, computational functionalism implies that consciousness is a novel type of computation that has recently been proposed by Geoffrey Hinton, called mortal computation.
    
[^5]: 提升教学质量：利用计算机辅助文本分析从教育文献中生成深入见解

    Enhancing Instructional Quality: Leveraging Computer-Assisted Textual Analysis to Generate In-Depth Insights from Educational Artifacts

    [https://arxiv.org/abs/2403.03920](https://arxiv.org/abs/2403.03920)

    通过计算机辅助文本分析，本文揭示了人工智能和机器学习方法在教学质量提升中的重要作用，为教育工作者提供了深入见解和可操作的反馈。

    

    本文探讨了计算机辅助文本分析在通过教育文献提供深入见解以提升教学质量中的变革潜力。我们整合了理查德·埃尔莫尔的教学核心框架来研究人工智能（AI）和机器学习（ML）方法，尤其是自然语言处理（NLP），可以分析教育内容、教师话语和学生回应以促进教学改进。通过对教学核心框架内的综合评论和案例研究，我们确定了AI/ML整合提供显著优势的关键领域，包括教师辅导、学生支持和内容开发。我们揭示出的模式表明，AI/ML 不仅简化了行政任务，还为个性化学习开辟了新途径，为教育工作者提供可操作的反馈，并有助于更深入地理解教学。

    arXiv:2403.03920v1 Announce Type: new  Abstract: This paper explores the transformative potential of computer-assisted textual analysis in enhancing instructional quality through in-depth insights from educational artifacts. We integrate Richard Elmore's Instructional Core Framework to examine how artificial intelligence (AI) and machine learning (ML) methods, particularly natural language processing (NLP), can analyze educational content, teacher discourse, and student responses to foster instructional improvement. Through a comprehensive review and case studies within the Instructional Core Framework, we identify key areas where AI/ML integration offers significant advantages, including teacher coaching, student support, and content development. We unveil patterns that indicate AI/ML not only streamlines administrative tasks but also introduces novel pathways for personalized learning, providing actionable feedback for educators and contributing to a richer understanding of instructi
    
[^6]: IRCoder: 中间表示使语言模型成为稳健的多语言代码生成器

    IRCoder: Intermediate Representations Make Language Models Robust Multilingual Code Generators

    [https://arxiv.org/abs/2403.03894](https://arxiv.org/abs/2403.03894)

    通过利用编译器中间表示来改进代码-LMs的多语言能力和促进跨语言转移。

    

    arXiv:2403.03894v1 公告类型: 新的 摘要: 代码理解和生成已迅速成为语言模型（LMs）最受欢迎的应用之一。然而，与自然语言LM的研究相比，对代码-LMs（即用于代码生成的LMs）的多语言方面的研究，如不同编程语言之间的跨语言转移，特定于语言的数据增强以及事后LM调整，以及利用原始文本内容之外的数据源，要稀少得多。特别是，大多数主流代码-LMs仅在源代码文件上进行了预训练。在这项工作中，我们研究了利用现成的编译器中间表示（跨编程语言共享）来改进代码-LMs的多语言能力并促进跨语言转移的前景。为此，我们首先编制了SLTrans，一个由近400万个自包含源代码文件组成的并行数据集。

    arXiv:2403.03894v1 Announce Type: new  Abstract: Code understanding and generation have fast become some of the most popular applications of language models (LMs). Nonetheless, research on multilingual aspects of Code-LMs (i.e., LMs for code generation) such as cross-lingual transfer between different programming languages, language-specific data augmentation, and post-hoc LM adaptation, alongside exploitation of data sources other than the original textual content, has been much sparser than for their natural language counterparts. In particular, most mainstream Code-LMs have been pre-trained on source code files alone. In this work, we investigate the prospect of leveraging readily available compiler intermediate representations - shared across programming languages - to improve the multilingual capabilities of Code-LMs and facilitate cross-lingual transfer.   To this end, we first compile SLTrans, a parallel dataset consisting of nearly 4M self-contained source code files coupled wi
    
[^7]: 从单一到多样：拓展语言模型中毒性缓解的范围

    From One to Many: Expanding the Scope of Toxicity Mitigation in Language Models

    [https://arxiv.org/abs/2403.03893](https://arxiv.org/abs/2403.03893)

    该研究拓展了语言模型中毒性缓解的范围，涵盖了多语言环境，通过翻译数据评估和增强缓解技术，比较了不同缓解方法，并探讨了模型大小和数据量对缓解效果的影响。

    

    迄今为止，语言模型中的毒性缓解几乎完全集中在单语言环境中。随着语言模型拥抱多语言能力，我们的安全措施跟上步伐至关重要。我们意识到了这一研究空白，我们的方法将传统的毒性缓解范围扩展到应对多语言带来的复杂性。在缺乏跨语言的足够标注数据集的情况下，我们使用翻译数据来评估和增强我们的缓解技术。我们还在静态和持续毒性缓解场景下比较了微调缓解方法和检索增强技术。这使我们能够检验翻译质量和跨语言转移对毒性缓解的影响。我们还探讨了模型大小和数据数量如何影响这些缓解工作的成功。涵盖了九种语言，我们的研究代表了广泛的语言学领域。

    arXiv:2403.03893v1 Announce Type: cross  Abstract: To date, toxicity mitigation in language models has almost entirely been focused on single-language settings. As language models embrace multilingual capabilities, it's crucial our safety measures keep pace. Recognizing this research gap, our approach expands the scope of conventional toxicity mitigation to address the complexities presented by multiple languages. In the absence of sufficient annotated datasets across languages, we employ translated data to evaluate and enhance our mitigation techniques. We also compare finetuning mitigation approaches against retrieval-augmented techniques under both static and continual toxicity mitigation scenarios. This allows us to examine the effects of translation quality and the cross-lingual transfer on toxicity mitigation. We also explore how model size and data quantity affect the success of these mitigation efforts. Covering nine languages, our study represents a broad array of linguistic f
    
[^8]: 分层扩散策略用于考虑运动学的多任务机器人操作

    Hierarchical Diffusion Policy for Kinematics-Aware Multi-Task Robotic Manipulation

    [https://arxiv.org/abs/2403.03890](https://arxiv.org/abs/2403.03890)

    这项研究提出了一种分层扩散策略（HDP）用于多任务机器人操作，通过将操纵策略分解为分层结构，同时解决长期任务规划和生成细粒度的低层动作，同时提出了一种新颖的机器人运动学感知目标条件控制代理（RK-Diffuser）。

    

    本文介绍了分层扩散策略（HDP），这是一种用于多任务机器人操作的分层代理。HDP将操纵策略分解为分层结构：高层任务规划代理预测远端最佳末端执行器姿势（NBP），低层目标条件扩散策略生成最佳运动轨迹。这种分解的策略表示使HDP能够同时解决长期任务规划和生成细粒度的低层动作。为了生成符合机器人运动学约束的上下文感知运动轨迹，我们提出了一种新颖的运动学感知目标条件控制代理，机器人运动学扩散器（RK-Diffuser）。具体来说，RK-Diffuser学习生成末端执行器姿势和关节位置轨迹，并将精确但缺乏运动学意识的末端执行器姿势扩散器提炼为运动学感知但不太精确的关节位置。

    arXiv:2403.03890v1 Announce Type: cross  Abstract: This paper introduces Hierarchical Diffusion Policy (HDP), a hierarchical agent for multi-task robotic manipulation. HDP factorises a manipulation policy into a hierarchical structure: a high-level task-planning agent which predicts a distant next-best end-effector pose (NBP), and a low-level goal-conditioned diffusion policy which generates optimal motion trajectories. The factorised policy representation allows HDP to tackle both long-horizon task planning while generating fine-grained low-level actions. To generate context-aware motion trajectories while satisfying robot kinematics constraints, we present a novel kinematics-aware goal-conditioned control agent, Robot Kinematics Diffuser (RK-Diffuser). Specifically, RK-Diffuser learns to generate both the end-effector pose and joint position trajectories, and distill the accurate but kinematics-unaware end-effector pose diffuser to the kinematics-aware but less accurate joint positio
    
[^9]: 使用扩散模型进行潜在数据集蒸馏

    Latent Dataset Distillation with Diffusion Models

    [https://arxiv.org/abs/2403.03881](https://arxiv.org/abs/2403.03881)

    这项研究提出了使用扩散模型进行潜在数据集蒸馏（LD3M），结合潜在空间中的扩散和数据集蒸馏的方法，以解决不同模型架构导致准确性下降和生成高分辨率图像的挑战。

    

    机器学习的有效性传统上依赖于越来越大的数据集的可用性。然而，大型数据集带来存储挑战，并且包含一些非影响力样本，在训练过程中可以被忽略而不影响模型最终的准确性。为了应对这些限制，出现了将数据集信息蒸馏成一组压缩样本（合成样本），即蒸馏数据集的概念。其中一个关键方面是选择用于连接原始和合成数据集的架构（通常是ConvNet）。然而，如果所使用的模型架构与蒸馏过程中使用的模型不同，则最终准确性会降低。另一个挑战是生成高分辨率图像，例如128x128及更高。

    arXiv:2403.03881v1 Announce Type: cross  Abstract: The efficacy of machine learning has traditionally relied on the availability of increasingly larger datasets. However, large datasets pose storage challenges and contain non-influential samples, which could be ignored during training without impacting the final accuracy of the model. In response to these limitations, the concept of distilling the information on a dataset into a condensed set of (synthetic) samples, namely a distilled dataset, emerged. One crucial aspect is the selected architecture (usually ConvNet) for linking the original and synthetic datasets. However, the final accuracy is lower if the employed model architecture differs from the model used during distillation. Another challenge is the generation of high-resolution images, e.g., 128x128 and higher. In this paper, we propose Latent Dataset Distillation with Diffusion Models (LD3M) that combine diffusion in latent space with dataset distillation to tackle both chal
    
[^10]: 重新定义膀胱镜检查：使用高效混合CNN-Transformer模型进行膀胱癌诊断

    Redefining cystoscopy with ai: bladder cancer diagnosis using an efficient hybrid cnn-transformer model

    [https://arxiv.org/abs/2403.03879](https://arxiv.org/abs/2403.03879)

    提出了一种混合CNN-Transformer模型，结合了双重注意力门机制，用于膀胱癌检测和分割，实现了在膀胱镜检查中计算效率和诊断准确性之间的平衡。

    

    膀胱癌在全球最常诊断的癌症中排名前十，并且由于高复发率，治疗成本高昂，需要终身随访。诊断的主要工具是膀胱镜检查，严重依赖医生的专业知识和解释。因此，每年都有大量病例要么未被诊断，要么被误诊为尿路感染。为了解决这一问题，我们提出了一种深度学习方法，结合了CNN和轻量级的无位置编码变压器以及融合自注意力和空间注意力进行特征增强的双重注意力门机制，用于膀胱癌检测和分割。本文提出的架构高效，适用于需要实时推理的医疗场景。实验证明，这种模型解决了在膀胱镜检查中计算效率和诊断准确性之间取得平衡的迫切需求。

    arXiv:2403.03879v1 Announce Type: cross  Abstract: Bladder cancer ranks within the top 10 most diagnosed cancers worldwide and is among the most expensive cancers to treat due to the high recurrence rates which require lifetime follow-ups. The primary tool for diagnosis is cystoscopy, which heavily relies on doctors' expertise and interpretation. Therefore, annually, numerous cases are either undiagnosed or misdiagnosed and treated as urinary infections. To address this, we suggest a deep learning approach for bladder cancer detection and segmentation which combines CNNs with a lightweight positional-encoding-free transformer and dual attention gates that fuse self and spatial attention for feature enhancement. The architecture suggested in this paper is efficient making it suitable for medical scenarios that require real time inference. Experiments have proven that this model addresses the critical need for a balance between computational efficiency and diagnostic accuracy in cystosco
    
[^11]: 贫困的语言技术：NLP中缺乏（社会）阶级因素

    Impoverished Language Technology: The Lack of (Social) Class in NLP

    [https://arxiv.org/abs/2403.03874](https://arxiv.org/abs/2403.03874)

    该论文探讨了NLP领域中缺乏对社会阶级因素的研究，呼吁研究者在NLP技术中考虑和操作化阶级因素。

    

    自Labov（1964年）关于语言社会层级的基础性工作以来，语言学界致力于理解社会人口因素和语言生产和感知之间的关系。尽管大量证据表明社会人口因素与语言生产之间存在显著关系，但相对较少的因素在NLP技术的背景下得到研究。虽然年龄和性别得到了很好的覆盖，Labov最初关注的社会经济阶级却几乎不被涉及。我们调查了现有的自然语言处理（NLP）文献，并发现只有20篇论文提到了社会经济地位。然而，这些论文中的大部分并没有探讨超出收集注释者人口信息之外的阶级。鉴于这一研究空白，我们提供了一个可以被NLP研究人员操作的阶级定义，并主张包含该因素

    arXiv:2403.03874v1 Announce Type: cross  Abstract: Since Labov's (1964) foundational work on the social stratification of language, linguistics has dedicated concerted efforts towards understanding the relationships between socio-demographic factors and language production and perception. Despite the large body of evidence identifying significant relationships between socio-demographic factors and language production, relatively few of these factors have been investigated in the context of NLP technology. While age and gender are well covered, Labov's initial target, socio-economic class, is largely absent. We survey the existing Natural Language Processing (NLP) literature and find that only 20 papers even mention socio-economic status. However, the majority of those papers do not engage with class beyond collecting information of annotator-demographics. Given this research lacuna, we provide a definition of class that can be operationalised by NLP researchers, and argue for including
    
[^12]: 语言模型是否是解谜天才？算法谜题揭示了多模态推理中的严峻挑战

    Are Language Models Puzzle Prodigies? Algorithmic Puzzles Unveil Serious Challenges in Multimodal Reasoning

    [https://arxiv.org/abs/2403.03864](https://arxiv.org/abs/2403.03864)

    这项研究提出了多模态解谜任务AlgoPuzzleVQA，通过算法谜题挑战评估了多模态语言模型在需要视觉理解、语言理解和复杂算法推理的能力，旨在评估视觉数据解释与算法问题解决能力之间的差距。

    

    这篇论文介绍了多模态解谜任务，将其放在视觉问答的背景中。我们提出了一个新的数据集AlgoPuzzleVQA，旨在挑战和评估多模态语言模型在解决需要视觉理解、语言理解和复杂算法推理的算法谜题方面的能力。我们创建了涵盖布尔逻辑、组合数学、图论、优化、搜索等多种数学和算法主题的谜题，旨在评估视觉数据解释与算法问题解决能力之间的差距。数据集是通过人类编写的代码自动生成的。我们所有的谜题都有精确的解决方案，可以从算法中找到，无需繁琐的人工计算。这确保了我们的数据集在推理复杂性和数据集大小方面可以任意扩展。

    arXiv:2403.03864v1 Announce Type: cross  Abstract: This paper introduces the novel task of multimodal puzzle solving, framed within the context of visual question-answering. We present a new dataset, AlgoPuzzleVQA designed to challenge and evaluate the capabilities of multimodal language models in solving algorithmic puzzles that necessitate both visual understanding, language understanding, and complex algorithmic reasoning. We create the puzzles to encompass a diverse array of mathematical and algorithmic topics such as boolean logic, combinatorics, graph theory, optimization, search, etc., aiming to evaluate the gap between visual data interpretation and algorithmic problem-solving skills. The dataset is generated automatically from code authored by humans. All our puzzles have exact solutions that can be found from the algorithm without tedious human calculations. It ensures that our dataset can be scaled up arbitrarily in terms of reasoning complexity and dataset size. Our investi
    
[^13]: 加速基于分数的扩散模型的收敛性，有保证

    Accelerating Convergence of Score-Based Diffusion Models, Provably

    [https://arxiv.org/abs/2403.03852](https://arxiv.org/abs/2403.03852)

    设计了新颖的无需训练的算法，以加速流行的确定性和随机采样器，改进了确定性采样器的收敛速率至$O(1/{T}^2)$，提升了随机采样器的收敛速率至$O(1/T)$。

    

    基于分数的扩散模型在实践中取得了显著的经验性能，但通常由于在采样阶段需要进行大量函数评估而导致采样速度较慢。尽管近年来一系列工作致力于加速扩散生成建模，但加速技术的理论基础仍然严重有限。在本文中，我们设计了新颖的无需训练的算法来加速流行的确定性（即DDIM）和随机（即DDPM）采样器。我们的加速确定性采样器以$O(1/{T}^2)$的速率收敛，其中$T$为步数，改进了DDIM采样器的$O(1/T)$速率；而我们的加速随机采样器以$O(1/T)$的速率收敛，优于DDPM采样器的$O(1/\sqrt{T})$速率。我们算法的设计利用了更高阶逼近的见解，并具有类似于流行的高阶ODE求解器的直觉。

    arXiv:2403.03852v1 Announce Type: cross  Abstract: Score-based diffusion models, while achieving remarkable empirical performance, often suffer from low sampling speed, due to extensive function evaluations needed during the sampling phase. Despite a flurry of recent activities towards speeding up diffusion generative modeling in practice, theoretical underpinnings for acceleration techniques remain severely limited. In this paper, we design novel training-free algorithms to accelerate popular deterministic (i.e., DDIM) and stochastic (i.e., DDPM) samplers. Our accelerated deterministic sampler converges at a rate $O(1/{T}^2)$ with $T$ the number of steps, improving upon the $O(1/T)$ rate for the DDIM sampler; and our accelerated stochastic sampler converges at a rate $O(1/T)$, outperforming the rate $O(1/\sqrt{T})$ for the DDPM sampler. The design of our algorithms leverages insights from higher-order approximation, and shares similar intuitions as popular high-order ODE solvers like 
    
[^14]: Cobweb：一种增量和分层式的人类类别学习模型

    Cobweb: An Incremental and Hierarchical Model of Human-Like Category Learning

    [https://arxiv.org/abs/2403.03835](https://arxiv.org/abs/2403.03835)

    Cobweb是一种类似人类类别学习系统，采用类别效用度量构建分层组织的类似树状结构，能够捕捉心理效应并在单一模型中展现出实例和原型学习的灵活性，为将来研究人类类别学习提供了基础。

    

    Cobweb是一种类似人类的类别学习系统，与其他增量分类模型不同的是，它利用类别效用度量构建分层组织的类似树状结构。先前的研究表明，Cobweb能够捕捉心理效应，如基本水平、典型性和扇形效应。然而，对Cobweb作为人类分类模型的更广泛评估仍然缺乏。本研究填补了这一空白。它确定了Cobweb与经典的人类类别学习效应的一致性。还探讨了Cobweb展现出在单一模型中既有实例又有原型学习的灵活性。这些发现为将来研究Cobweb作为人类类别学习的综合模型奠定了基础。

    arXiv:2403.03835v1 Announce Type: cross  Abstract: Cobweb, a human like category learning system, differs from other incremental categorization models in constructing hierarchically organized cognitive tree-like structures using the category utility measure. Prior studies have shown that Cobweb can capture psychological effects such as the basic level, typicality, and fan effects. However, a broader evaluation of Cobweb as a model of human categorization remains lacking. The current study addresses this gap. It establishes Cobweb's alignment with classical human category learning effects. It also explores Cobweb's flexibility to exhibit both exemplar and prototype like learning within a single model. These findings set the stage for future research on Cobweb as a comprehensive model of human category learning.
    
[^15]: 您的设备可能比您更了解您自己——使用机器学习在新数据集上进行持续认证

    Your device may know you better than you know yourself -- continuous authentication on novel dataset using machine learning

    [https://arxiv.org/abs/2403.03832](https://arxiv.org/abs/2403.03832)

    通过新数据集和机器学习技术，研究展示了触摸动态可以有效地区分用户，最具鲁棒性的模型是支持向量分类器（SVC），其平均准确率约为90%

    

    这项研究旨在通过行为生物特征进一步探讨持续认证领域。我们贡献了一个新数据集，包含了15位用户使用三星平板玩“Minecraft”时的手势数据，每位用户持续15分钟。利用这一数据集，我们使用了机器学习二元分类器，包括随机森林（RF）、K-最近邻算法（KNN）和支持向量分类器（SVC），以确定特定用户操作的真实性。我们最具鲁棒性的模型是SVC，其平均准确率约为90%，表明触摸动态能有效区分用户。然而，还需要进一步研究，以使其成为认证系统的可行选项。

    arXiv:2403.03832v1 Announce Type: new  Abstract: This research aims to further understanding in the field of continuous authentication using behavioral biometrics. We are contributing a novel dataset that encompasses the gesture data of 15 users playing Minecraft with a Samsung Tablet, each for a duration of 15 minutes. Utilizing this dataset, we employed machine learning (ML) binary classifiers, being Random Forest (RF), K-Nearest Neighbors (KNN), and Support Vector Classifier (SVC), to determine the authenticity of specific user actions. Our most robust model was SVC, which achieved an average accuracy of approximately 90%, demonstrating that touch dynamics can effectively distinguish users. However, further studies are needed to make it viable option for authentication systems
    
[^16]: 从点击到安全：通过鼠标动态认证的持续认证研究

    From Clicks to Security: Investigating Continuous Authentication via Mouse Dynamics

    [https://arxiv.org/abs/2403.03828](https://arxiv.org/abs/2403.03828)

    本研究探讨了鼠标移动动态作为持续认证的一种一致度量的潜力，并通过机器学习模型分析用户行为，发现鼠标移动动态可以作为可靠的认证指标。

    

    在计算机安全领域，高效可靠的用户认证方法的重要性日益突出。本文探讨了鼠标移动动态作为持续认证的一种一致度量的潜力。通过分析用户在两种截然不同的游戏场景中的鼠标移动模式，“团队要塞”和Poly Bridge，我们调查了高强度和低强度UI交互中固有的行为模式。本研究超越了传统方法，采用了一系列机器学习模型。这些模型经过精心选择，以评估它们在捕捉和解释用户行为微妙之处方面的有效性，正如其体现在鼠标移动中的。这种多层面的方法使我们能够更加细致和全面地理解用户互动模式。我们的研究结果表明，鼠标移动动态可以作为连续认证的可靠指标。

    arXiv:2403.03828v1 Announce Type: new  Abstract: In the realm of computer security, the importance of efficient and reliable user authentication methods has become increasingly critical. This paper examines the potential of mouse movement dynamics as a consistent metric for continuous authentication. By analyzing user mouse movement patterns in two contrasting gaming scenarios, "Team Fortress" and Poly Bridge we investigate the distinctive behavioral patterns inherent in high-intensity and low-intensity UI interactions. The study extends beyond conventional methodologies by employing a range of machine learning models. These models are carefully selected to assess their effectiveness in capturing and interpreting the subtleties of user behavior as reflected in their mouse movements. This multifaceted approach allows for a more nuanced and comprehensive understanding of user interaction patterns. Our findings reveal that mouse movement dynamics can serve as a reliable indicator for cont
    
[^17]: 用MultiQ评估大型语言模型的基本多语能力

    Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ

    [https://arxiv.org/abs/2403.03814](https://arxiv.org/abs/2403.03814)

    本研究通过引入MultiQ基准，调查了最先进的开放LLMs在其预期使用范围之外的基本多语能力，发现这些模型对于至少某些语言能够忠实和准确地进行回答。

    

    大型语言模型（LLMs）需要为全球大多数非英语使用者提供服务。然而，大多数LLMs今天，特别是开放的LLMs，通常仅意为在英语（例如Llama2、Mistral）或少数几种高资源语言（例如Mixtral、Qwen）中使用。最近的研究表明，尽管存在使用上的限制，人们会用许多不同的语言提示LLMs。因此，在本文中，我们调查了最先进的开放LLMs在其预期使用范围之外的基本多语能力。为此，我们引入了MultiQ，一个新的用于基本开放式问答的银标准基准，涵盖137种语言的27.4k个测试问题。通过MultiQ，我们评估了语言忠实度，即模型是否以提示的语言回复，以及问题回答准确性。我们测试的所有LLMs对至少某些语言响应得忠实和/或准确。

    arXiv:2403.03814v1 Announce Type: cross  Abstract: Large language models (LLMs) need to serve everyone, including a global majority of non-English speakers. However, most LLMs today, and open LLMs in particular, are often intended for use in just English (e.g. Llama2, Mistral) or a small handful of high-resource languages (e.g. Mixtral, Qwen). Recent research shows that, despite limits in their intended use, people prompt LLMs in many different languages. Therefore, in this paper, we investigate the basic multilingual capabilities of state-of-the-art open LLMs beyond their intended use. For this purpose, we introduce MultiQ, a new silver standard benchmark for basic open-ended question answering with 27.4k test questions across a typologically diverse set of 137 languages. With MultiQ, we evaluate language fidelity, i.e.\ whether models respond in the prompted language, and question answering accuracy. All LLMs we test respond faithfully and/or accurately for at least some languages be
    
[^18]: ProbSAINT：概率表格回归用于二手车定价

    ProbSAINT: Probabilistic Tabular Regression for Used Car Pricing

    [https://arxiv.org/abs/2403.03812](https://arxiv.org/abs/2403.03812)

    ProbSAINT是一种提出了一种原则性方法来量化其价格预测的不确定性，并且提供了与最先进的提升技术相媲美的准确点预测的模型。

    

    二手车定价是汽车行业的关键领域，受许多经济因素和市场动态的影响。随着在线市场的激增和二手车需求的增加，准确的定价将使买家和卖家受益，确保公平交易。然而，当前向使用机器学习的自动定价算法的转变需要理解模型不确定性，特别是标记模型不确定的预测的能力。虽然最近的文献提出使用提升算法或基于最近邻的方法进行迅速和精准的价格预测，但用这些算法封装模型不确定性面临着复杂的挑战。我们介绍了ProbSAINT，这是一种模型，提供了一个原则性的方法来量化其价格预测的不确定性，以及与最先进的提升技术相媲美的准确点预测。

    arXiv:2403.03812v1 Announce Type: cross  Abstract: Used car pricing is a critical aspect of the automotive industry, influenced by many economic factors and market dynamics. With the recent surge in online marketplaces and increased demand for used cars, accurate pricing would benefit both buyers and sellers by ensuring fair transactions. However, the transition towards automated pricing algorithms using machine learning necessitates the comprehension of model uncertainties, specifically the ability to flag predictions that the model is unsure about. Although recent literature proposes the use of boosting algorithms or nearest neighbor-based approaches for swift and precise price predictions, encapsulating model uncertainties with such algorithms presents a complex challenge. We introduce ProbSAINT, a model that offers a principled approach for uncertainty quantification of its price predictions, along with accurate point predictions that are comparable to state-of-the-art boosting tec
    
[^19]: 自信意识决策与控制在工具选择中的应用

    Confidence-Aware Decision-Making and Control for Tool Selection

    [https://arxiv.org/abs/2403.03808](https://arxiv.org/abs/2403.03808)

    引入了一个数学框架，使机器人能够利用他们的控制自信心做出更加明智的决策，并且推导出了动态系统的控制自信度的数学闭合形式表达式

    

    自我反思我们的表现（例如，我们的自信程度）在进行任务之前对于决策是至关重要的，比如选择最合适的工具或选择最佳驾驶路线。虽然这种意识形式——思考我们的表现或元认知表现——在人类中是众所周知的，但机器人仍然缺乏这种认知能力。这种反思监控可以增强他们的体现决策能力、鲁棒性和安全性。在这里，我们朝着这个方向迈出了一步，通过引入一个数学框架，使机器人能够利用他们的控制自信心做出更加明智的决定。我们推导了一个用于动态系统的控制自信度的数学闭合形式表达式（即控制动作的后验逆协方差）。这种控制自信度无缝地集成在一个用于决策制定的客观函数中，平衡了：i）任务完成的性能，ii）控制努力

    arXiv:2403.03808v1 Announce Type: cross  Abstract: Self-reflecting about our performance (e.g., how confident we are) before doing a task is essential for decision making, such as selecting the most suitable tool or choosing the best route to drive. While this form of awareness -- thinking about our performance or metacognitive performance -- is well-known in humans, robots still lack this cognitive ability. This reflective monitoring can enhance their embodied decision power, robustness and safety. Here, we take a step in this direction by introducing a mathematical framework that allows robots to use their control self-confidence to make better-informed decisions. We derive a mathematical closed-form expression for control confidence for dynamic systems (i.e., the posterior inverse covariance of the control action). This control confidence seamlessly integrates within an objective function for decision making, that balances the: i) performance for task completion, ii) control effort,
    
[^20]: KG-TREAT: 通过在患者数据和知识图谱之间进行协同作用进行治疗效果估计的预训练

    KG-TREAT: Pre-training for Treatment Effect Estimation by Synergizing Patient Data with Knowledge Graphs

    [https://arxiv.org/abs/2403.03791](https://arxiv.org/abs/2403.03791)

    KG-TREAT框架通过协同患者数据和知识图谱，引入双重关注的知识图谱和深度双层注意力协同方法，实现了治疗相关因素和结果相关因素的独立编码，表现优于现有方法。

    

    治疗效果估计（TEE）是确定各种治疗对患者结果影响的任务。KG-TREAT引入了一种新颖的预训练和微调框架，通过将大规模观察性患者数据与生物医学知识图谱（KGs）进行协同以增强TEE，以解决有限标记数据依赖和稀疏和高维观察性患者数据带来的挑战。

    arXiv:2403.03791v1 Announce Type: cross  Abstract: Treatment effect estimation (TEE) is the task of determining the impact of various treatments on patient outcomes. Current TEE methods fall short due to reliance on limited labeled data and challenges posed by sparse and high-dimensional observational patient data. To address the challenges, we introduce a novel pre-training and fine-tuning framework, KG-TREAT, which synergizes large-scale observational patient data with biomedical knowledge graphs (KGs) to enhance TEE. Unlike previous approaches, KG-TREAT constructs dual-focus KGs and integrates a deep bi-level attention synergy method for in-depth information fusion, enabling distinct encoding of treatment-covariate and outcome-covariate relationships. KG-TREAT also incorporates two pre-training tasks to ensure a thorough grounding and contextualization of patient data and KGs. Evaluation on four downstream TEE tasks shows KG-TREAT's superiority over existing methods, with an average
    
[^21]: 使用粒子群和蚁群优化的神经结构搜索

    Neural Architecture Search using Particle Swarm and Ant Colony Optimization

    [https://arxiv.org/abs/2403.03781](https://arxiv.org/abs/2403.03781)

    本研究开发了一种集成用于图像分类的神经结构搜索开源工具系统（OpenNAS），通过采用粒子群和蚁群优化等元启发式方法，自动生成卷积神经网络架构，以显著提高模型准确性。

    

    神经网络模型具有许多超参数，必须选择其结构。这对于初学者来说是一个沉重的负担，他们需要选择哪种结构以及分配给参数的值。在大多数情况下，使用默认的超参数和结构。通过评估多种结构，可以显著提高模型准确性。一种称为神经结构搜索（NAS）的过程可以自动评估大量这样的结构。作为本研究的一部分，已开发了一个集成用于图像分类的神经结构搜索开源工具系统（OpenNAS）。OpenNAS接受任何灰度或RGB图像数据集，并根据一系列元启发式方法使用AutoKeras，迁移学习或Swarm Intelligence (SI)方法生成卷积神经网络（CNN）架构。

    arXiv:2403.03781v1 Announce Type: cross  Abstract: Neural network models have a number of hyperparameters that must be chosen along with their architecture. This can be a heavy burden on a novice user, choosing which architecture and what values to assign to parameters. In most cases, default hyperparameters and architectures are used. Significant improvements to model accuracy can be achieved through the evaluation of multiple architectures. A process known as Neural Architecture Search (NAS) may be applied to automatically evaluate a large number of such architectures. A system integrating open source tools for Neural Architecture Search (OpenNAS), in the classification of images, has been developed as part of this research. OpenNAS takes any dataset of grayscale, or RBG images, and generates Convolutional Neural Network (CNN) architectures based on a range of metaheuristics using either an AutoKeras, a transfer learning or a Swarm Intelligence (SI) approach. Particle Swarm Optimizat
    
[^22]: ENOT：期望回归用于神经优化传输的快速和准确训练

    ENOT: Expectile Regularization for Fast and Accurate Training of Neural Optimal Transport

    [https://arxiv.org/abs/2403.03777](https://arxiv.org/abs/2403.03777)

    通过期望回归正则化，本论文提出了一种新的神经优化传输（NOT）训练程序扩展，能够有效地估计最优输运方案，并使学习变得稳定。

    

    我们提出了一种新的神经优化传输（NOT）训练程序扩展，通过特定的共轭势正则化能够准确和高效地估计最优输运方案。现有NOT求解器的主要瓶颈在于找到共轭算子（即c-transform）的接近精确近似的过程，这要么通过优化最小-最大目标，要么通过计算密集型的对初始近似预测的精细调整来完成。我们通过提出一种新的、在期望回归形式上强制适应性条件于学习对偶势的理论上合理化损失来解决这两个问题。这样的正则化提供了可能共轭势分布的上限估计，并使学习变得稳定，消除了对额外广泛微调的需求。我们正式证明了我们的方法的效率。

    arXiv:2403.03777v1 Announce Type: cross  Abstract: We present a new extension for Neural Optimal Transport (NOT) training procedure, capable of accurately and efficiently estimating optimal transportation plan via specific regularisation on conjugate potentials. The main bottleneck of existing NOT solvers is associated with the procedure of finding a near-exact approximation of the conjugate operator (i.e., the c-transform), which is done either by optimizing over maximin objectives or by the computationally-intensive fine-tuning of the initial approximated prediction. We resolve both issues by proposing a new, theoretically justified loss in the form of expectile regularization that enforces binding conditions on the learning dual potentials. Such a regularization provides the upper bound estimation over the distribution of possible conjugate potentials and makes the learning stable, eliminating the need for additional extensive finetuning. We formally justify the efficiency of our me
    
[^23]: DeepCRE：利用尖端计算模型改革药物研发

    DeepCRE: Revolutionizing Drug R&D with Cutting-Edge Computational Models

    [https://arxiv.org/abs/2403.03768](https://arxiv.org/abs/2403.03768)

    DeepCRE是一种新型的计算模型，在患者级别CRE性能上平均提高了17.7％，在指示级别CRE增加了5倍，并成功确定了六个具有显着优势的药物候选者。

    

    arXiv:2403.03768v1 公告类型：新摘要：药物开发领域和治疗应用领域都面临着重大挑战。治疗领域需要更多的治疗选择，同时大量有前景的临床前药物在临床试验中失败。一个原因是在药物开发的后期阶段交叉药物反应评估（CRE）的不足。尽管计算机模拟的CRE模型为解决这一问题提供了一种解决方案，但现有方法学要么局限于早期开发阶段，要么缺乏对全面CRE分析的能力。在这里，我们介绍了一种名为DeepCRE的新型计算模型，并展示了DeepCRE在推动治疗发现和发展方面的潜力。DeepCRE通过实现患者级别CRE平均性能提高17.7\%，指示级别CRE增加了5倍，优于现有最佳模型。此外，DeepCRE已经确定了六个显示出明显更大优势的药物候选者。

    arXiv:2403.03768v1 Announce Type: new  Abstract: The field of pharmaceutical development and therapeutic application both face substantial challenges. Therapeutic domain calls for more treatment alternatives while numerous promising pre-clinical drugs fail in clinical trails. One of the reasons is the inadequacy of Cross-drug Response Evaluation (CRE) during the late stage of drug development. Although in-silico CRE models offer a solution to this problem, existing methodologies are either limited to early development stages or lack the capacity for a comprehensive CRE analysis. Herein, we introduce a novel computational model named DeepCRE and present the potential of DeepCRE in advancing therapeutic discovery and development. DeepCRE outperforms the existing best models by achieving an average performance improvement of 17.7\% in patient-level CRE, and a 5-fold increase in indication-level CRE. Furthermore, DeepCRE has identified six drug candidates that show significantly greater ef
    
[^24]: 德语也产生幻觉！使用Absinth数据集检测新闻摘要中的不一致性

    German also Hallucinates! Inconsistency Detection in News Summaries with the Absinth Dataset

    [https://arxiv.org/abs/2403.03750](https://arxiv.org/abs/2403.03750)

    本文提出了一个用于德语新闻摘要中幻觉检测的数据集absinth，探讨了LLMs在该任务中的应用。

    

    大型语言模型（LLMs）的出现在自然语言处理任务中取得了显著进展，然而，这些大型模型仍然存在产生信息幻觉的问题，这在自动文本摘要中至关重要。先前的研究主要集中在英语上，并且最近的多语言方法缺乏德语数据。本文提出了absinth，一个用于德语新闻摘要中幻觉检测的手动注释数据集，并探讨了新型开源LLMs在这一任务上的能力，包括微调和上下文学习设置。我们开源并发布了这个数据集。

    arXiv:2403.03750v1 Announce Type: cross  Abstract: The advent of Large Language Models (LLMs) has led to remarkable progress on a wide range of natural language processing tasks. Despite the advances, these large-sized models still suffer from hallucinating information in their output, which poses a major issue in automatic text summarization, as we must guarantee that the generated summary is consistent with the content of the source document. Previous research addresses the challenging task of detecting hallucinations in the output (i.e. inconsistency detection) in order to evaluate the faithfulness of the generated summaries. However, these works primarily focus on English and recent multilingual approaches lack German data. This work presents absinth, a manually annotated dataset for hallucination detection in German news summarization and explores the capabilities of novel open-source LLMs on this task in both fine-tuning and in-context learning settings. We open-source and releas
    
[^25]: 为医药领域打造安全和对齐的大型语言模型

    Towards Safe and Aligned Large Language Models for Medicine

    [https://arxiv.org/abs/2403.03744](https://arxiv.org/abs/2403.03744)

    对医学LLMs进行了首次安全评估，并探讨了如何定义医学安全和对齐性，开发了有害医学问题数据集，评估了医学LLMs的安全性和对齐性，展示了微调是一种有效的缓解策略。

    

    大型语言模型（LLMs）的能力正在以惊人的速度进步，即使是它们的开发者也对它们的潜力和风险的深度感到困惑。尽管已经采取了初步步骤评估通用知识LLMs的安全性和对齐性，揭示了一些弱点，但据我们所知，尽管在个人健康和安全、公共健康和安全以及人权方面存在风险，医学LLMs的安全性和对齐性尚未得到评估。为此，我们进行了对医学LLMs的首次安全评估。具体而言，我们提出了医学人工智能系统的医学安全性和对齐性的定义，开发了一个有害医学问题的数据集来评估LLM的医学安全性和对齐性，评估了医学LLMs的通用安全性和对齐性，展示了微调作为一种有效的缓解策略，并讨论了更广泛的、大规模的方法。

    arXiv:2403.03744v1 Announce Type: new  Abstract: The capabilities of large language models (LLMs) have been progressing at a breathtaking speed, leaving even their own developers grappling with the depth of their potential and risks. While initial steps have been taken to evaluate the safety and alignment of general-knowledge LLMs, exposing some weaknesses, to our knowledge, the safety and alignment of medical LLMs has not been evaluated despite their risks for personal health and safety, public health and safety, and human rights. To this end, we carry out the first safety evaluation for medical LLMs. Specifically, we set forth a definition of medical safety and alignment for medical artificial intelligence systems, develop a dataset of harmful medical questions to evaluate the medical safety and alignment of an LLM, evaluate both general and medical safety and alignment of medical LLMs, demonstrate fine-tuning as an effective mitigation strategy, and discuss broader, large-scale appr
    
[^26]: SUPClust: 边界处的主动学习

    SUPClust: Active Learning at the Boundaries

    [https://arxiv.org/abs/2403.03741](https://arxiv.org/abs/2403.03741)

    提出了一种名为SUPClust的新型主动学习方法，旨在识别类别之间的决策边界上的点，通过标记这些点来优化模型预测的性能。

    

    主动学习是一种机器学习范式，旨在在获取标记数据昂贵的情况下优化模型性能。本文提出了一种名为SUPClust的新型主动学习方法，旨在识别类别之间的决策边界上的点。通过针对这些点，SUPClust旨在收集对于精细化模型对复杂决策区域的预测最具信息量的信息。我们在实验证明，标记这些点会导致强大的模型性能。即使在存在强烈类别不平衡的情况下，也观察到了这种改进。

    arXiv:2403.03741v1 Announce Type: cross  Abstract: Active learning is a machine learning paradigm designed to optimize model performance in a setting where labeled data is expensive to acquire. In this work, we propose a novel active learning method called SUPClust that seeks to identify points at the decision boundary between classes. By targeting these points, SUPClust aims to gather information that is most informative for refining the model's prediction of complex decision regions. We demonstrate experimentally that labeling these points leads to strong model performance. This improvement is observed even in scenarios characterized by strong class imbalance.
    
[^27]: A&B BNN: A&B BNN：仅使用加和位操作的硬件友好的二值神经网络

    A&B BNN: Add&Bit-Operation-Only Hardware-Friendly Binary Neural Network

    [https://arxiv.org/abs/2403.03739](https://arxiv.org/abs/2403.03739)

    A&B BNN 提出了一种只使用加和位操作的硬件友好二值神经网络，通过引入掩码层和量化 RPReLU 结构，能够更高效地进行计算，并在CIFA数据集上取得了良好的实验结果。

    

    二值神经网络利用1位量化的权重和激活来减少模型的存储需求和计算负担。然而，先进的二值架构仍然包含数百万个低效且对硬件不友好的全精度乘法操作。A&B BNN 提出了直接移除传统 BNN 中的部分乘法操作，并用相同数量的位操作替换剩余部分，引入了基于无归一化网络架构的掩码层和量化 RPReLU 结构。掩码层可以通过利用 BNN 的内在特征以及简单的数学变换在推断期间将其移除，以避免相关的乘法操作。量化 RPReLU 结构通过将其斜率限制为2的整数幂，实现更高效的位操作。实验结果在CIFA数据集上达到了92.30%、69.35%和66.89%的准确率。

    arXiv:2403.03739v1 Announce Type: cross  Abstract: Binary neural networks utilize 1-bit quantized weights and activations to reduce both the model's storage demands and computational burden. However, advanced binary architectures still incorporate millions of inefficient and nonhardware-friendly full-precision multiplication operations. A&B BNN is proposed to directly remove part of the multiplication operations in a traditional BNN and replace the rest with an equal number of bit operations, introducing the mask layer and the quantized RPReLU structure based on the normalizer-free network architecture. The mask layer can be removed during inference by leveraging the intrinsic characteristics of BNN with straightforward mathematical transformations to avoid the associated multiplication operations. The quantized RPReLU structure enables more efficient bit operations by constraining its slope to be integer powers of 2. Experimental results achieved 92.30%, 69.35%, and 66.89% on the CIFA
    
[^28]: 通过预测学习三维物体中心表示

    Learning 3D object-centric representation through prediction

    [https://arxiv.org/abs/2403.03730](https://arxiv.org/abs/2403.03730)

    通过预测未来场景，该研究开发了一种网络架构，同时学习对象分割、3D位置推断和深度感知，从而以类似人类婴儿的约束条件学习物体的表示方式

    

    作为人类核心知识的一部分，对象的表示是支持高层概念和符号推理的心理表示的基本构件。尽管人类能够在3D环境中无需监督地感知对象，但缺乏能够以类似于人类婴儿面临的相似约束条件学习相同能力的模型。为此，我们开发了一种新颖的网络架构，同时学习以下能力：1) 从离散图像中分割对象，2) 推断它们的3D位置，以及3) 感知深度，而仅使用了直接可用于大脑训练数据，即图像序列和自我运动。核心思想是将对象视为视觉输入的潜在原因，大脑利用这些原因做出对未来场景的有效预测。这导致对象表示作为学习预测的基本副产品被学习。

    arXiv:2403.03730v1 Announce Type: cross  Abstract: As part of human core knowledge, the representation of objects is the building block of mental representation that supports high-level concepts and symbolic reasoning. While humans develop the ability of perceiving objects situated in 3D environments without supervision, models that learn the same set of abilities with similar constraints faced by human infants are lacking. Towards this end, we developed a novel network architecture that simultaneously learns to 1) segment objects from discrete images, 2) infer their 3D locations, and 3) perceive depth, all while using only information directly available to the brain as training data, namely: sequences of images and self-motion. The core idea is treating objects as latent causes of visual input which the brain uses to make efficient predictions of future scenes. This results in object representations being learned as an essential byproduct of learning to predict.
    
[^29]: 通过自监督预训练在主动学习中弥合多样性与不确定性

    Bridging Diversity and Uncertainty in Active learning with Self-Supervised Pre-Training

    [https://arxiv.org/abs/2403.03728](https://arxiv.org/abs/2403.03728)

    通过引入TCM启发式方法，本研究在主动学习中成功结合了多样性采样和不确定性采样策略，解决了冷启动问题并在各种数据水平上表现出色。

    

    本研究探讨了在主动学习中集成基于多样性和基于不确定性的采样策略，特别是在自监督预训练模型的背景下。我们引入了一个称为TCM的简单启发式方法，可以缓解冷启动问题，同时在各种数据水平上保持强大性能。通过首先应用TypiClust进行多样性采样，随后过渡到使用Margin进行不确定性采样，我们的方法有效地结合了两种策略的优势。我们的实验表明，TCM在低数据和高数据情况下始终优于现有方法。

    arXiv:2403.03728v1 Announce Type: cross  Abstract: This study addresses the integration of diversity-based and uncertainty-based sampling strategies in active learning, particularly within the context of self-supervised pre-trained models. We introduce a straightforward heuristic called TCM that mitigates the cold start problem while maintaining strong performance across various data levels. By initially applying TypiClust for diversity sampling and subsequently transitioning to uncertainty sampling with Margin, our approach effectively combines the strengths of both strategies. Our experiments demonstrate that TCM consistently outperforms existing methods across various datasets in both low and high data regimes.
    
[^30]: 蛋白质序列生成的语言模型嵌入扩散

    Diffusion on language model embeddings for protein sequence generation

    [https://arxiv.org/abs/2403.03726](https://arxiv.org/abs/2403.03726)

    使用DiMA模型，在蛋白语言模型嵌入进行扩散来生成氨基酸序列，比传统解决方案表现更好，并通过设计选择的影响来量化其优越性能。

    

    蛋白设计需要对蛋白质宇宙固有复杂性的深入了解。尽管许多工作倾向于有条件的生成或专注于特定蛋白质家族，但无条件生成的基础任务仍未得到充分探索和重视。在这里，我们探索这个关键领域，引入了DiMA，这是一个利用从蛋白语言模型ESM-2衍生的嵌入进行连续扩散以生成氨基酸序列的模型。DiMA超越了包括自回归变换器和离散扩散模型在内的主要解决方案，我们定量地说明了导致其卓越性能的设计选择所带来的影响。我们使用各种指标跨多种形式广泛评估生成序列的质量、多样性、分布相似性和生物相关性。我们的方法始终产生新颖、多样化的蛋白质序列，精准

    arXiv:2403.03726v1 Announce Type: cross  Abstract: Protein design requires a deep understanding of the inherent complexities of the protein universe. While many efforts lean towards conditional generation or focus on specific families of proteins, the foundational task of unconditional generation remains underexplored and undervalued. Here, we explore this pivotal domain, introducing DiMA, a model that leverages continuous diffusion on embeddings derived from the protein language model, ESM-2, to generate amino acid sequences. DiMA surpasses leading solutions, including autoregressive transformer-based and discrete diffusion models, and we quantitatively illustrate the impact of the design choices that lead to its superior performance. We extensively evaluate the quality, diversity, distribution similarity, and biological relevance of the generated sequences using multiple metrics across various modalities. Our approach consistently produces novel, diverse protein sequences that accura
    
[^31]: 朝向可控时间序列生成

    Towards Controllable Time Series Generation

    [https://arxiv.org/abs/2403.03698](https://arxiv.org/abs/2403.03698)

    提出了 Controllable Time Series (CTS) 框架，通过解耦映射过程来实现对复杂交互模式的精确学习，从而创新了针对可控时间序列生成 (CTSG) 的方法。

    

    时间序列生成（TSG）已经成为合成准确反映现实世界时间序列数据的关键技术，在许多应用中变得不可或缺。尽管TSG取得了显著进展，但其有效性经常取决于具有大型训练数据集。这种依赖性在数据稀缺的情况下，特别是在处理罕见或独特条件时，构成了一个重大挑战。为了应对这些挑战，我们探索了一个新问题，即可控时间序列生成（CTSG），旨在产生能够适应各种外部条件的合成时间序列，从而解决数据稀缺问题。

    arXiv:2403.03698v1 Announce Type: cross  Abstract: Time Series Generation (TSG) has emerged as a pivotal technique in synthesizing data that accurately mirrors real-world time series, becoming indispensable in numerous applications. Despite significant advancements in TSG, its efficacy frequently hinges on having large training datasets. This dependency presents a substantial challenge in data-scarce scenarios, especially when dealing with rare or unique conditions. To confront these challenges, we explore a new problem of Controllable Time Series Generation (CTSG), aiming to produce synthetic time series that can adapt to various external conditions, thereby tackling the data scarcity issue.   In this paper, we propose \textbf{C}ontrollable \textbf{T}ime \textbf{S}eries (\textsf{CTS}), an innovative VAE-agnostic framework tailored for CTSG. A key feature of \textsf{CTS} is that it decouples the mapping process from standard VAE training, enabling precise learning of a complex interpla
    
[^32]: MolNexTR：一种用于分子图像识别的通用深度学习模型

    MolNexTR: A Generalized Deep Learning Model for Molecular Image Recognition

    [https://arxiv.org/abs/2403.03691](https://arxiv.org/abs/2403.03691)

    MolNexTR是一种用于分子图像识别的通用深度学习模型，能够更细致提取分子图像的局部和全局特征，同时能够预测原子和键，理解布局规则，灵活整合符号化的化学原则，并且包含多种先进算法。

    

    在化学结构识别领域，将分子图像转换为图结构和SMILES字符串的任务是一个重要挑战，主要是由于化学文献中流行的各种绘图风格和约定。为了弥合这一差距，我们提出了MolNexTR，一种新颖的图像到图结构的深度学习模型，它合并了ConvNext和Vision-TRansformer的优势，实现了对分子图像中的局部和全局特征的更细致提取。MolNexTR可以同时预测原子和键，并理解它们的布局规则。它还擅长灵活地将符号化的化学原则融入其中，以识别手性并解析缩写结构。我们进一步整合了一系列先进算法，包括改进的数据增强模块、图像污染模块和后处理模块。

    arXiv:2403.03691v1 Announce Type: cross  Abstract: In the field of chemical structure recognition, the task of converting molecular images into graph structures and SMILES string stands as a significant challenge, primarily due to the varied drawing styles and conventions prevalent in chemical literature. To bridge this gap, we proposed MolNexTR, a novel image-to-graph deep learning model that collaborates to fuse the strengths of ConvNext, a powerful Convolutional Neural Network variant, and Vision-TRansformer. This integration facilitates a more nuanced extraction of both local and global features from molecular images. MolNexTR can predict atoms and bonds simultaneously and understand their layout rules. It also excels at flexibly integrating symbolic chemistry principles to discern chirality and decipher abbreviated structures. We further incorporate a series of advanced algorithms, including improved data augmentation module, image contamination module, and a post-processing modul
    
[^33]: 快速开发高质量的指令数据和评估基准，减少人力投入：以日语为例的案例研究

    Rapidly Developing High-quality Instruction Data and Evaluation Benchmark for Large Language Models with Minimal Human Effort: A Case Study on Japanese

    [https://arxiv.org/abs/2403.03690](https://arxiv.org/abs/2403.03690)

    通过GPT-4自指导方法，快速开发高质量的日语指令数据和评估基准，无需大量人力投入，并为大型语言模型提供了有效的资源

    

    为了为大型语言模型提供服务，创建指令数据和评估基准通常需要大量的人工标注。当为日语等非英语语言快速开发这些资源时，这个问题尤为突出。我们提出了一种基于GPT-4的高效自指导方法，而不是直接将现有的英语资源翻译成日语（例如Japanese-Alpaca）。我们首先将少量英语指令翻译成日语，并进行后期编辑以获得native-level质量。然后，GPT-4利用这些指令作为示范，自动生成日语指令数据。我们还利用GPT-4构建了一个包含80个问题跨8个类别的评估基准，使用GPT-4自动评估LLMs的响应质量，无需人工参考。实证结果表明，对我们的GPT-4自指导数据进行微调的模型显著

    arXiv:2403.03690v1 Announce Type: cross  Abstract: The creation of instruction data and evaluation benchmarks for serving Large language models often involves enormous human annotation. This issue becomes particularly pronounced when rapidly developing such resources for a non-English language like Japanese. Instead of following the popular practice of directly translating existing English resources into Japanese (e.g., Japanese-Alpaca), we propose an efficient self-instruct method based on GPT-4. We first translate a small amount of English instructions into Japanese and post-edit them to obtain native-level quality. GPT-4 then utilizes them as demonstrations to automatically generate Japanese instruction data. We also construct an evaluation benchmark containing 80 questions across 8 categories, using GPT-4 to automatically assess the response quality of LLMs without human references. The empirical results suggest that the models fine-tuned on our GPT-4 self-instruct data significant
    
[^34]: 通用到专业的电子商务LLMs翻译

    General2Specialized LLMs Translation for E-commerce

    [https://arxiv.org/abs/2403.03689](https://arxiv.org/abs/2403.03689)

    提出了一个名为G2ST的两步微调范式，通过自对比语义增强将通用NMT模型转换为专门用于电子商务的NMT模型，以提高翻译质量。

    

    现有的神经机器翻译（NMT）模型主要处理通用领域的翻译，忽略了具有特殊写作公式的领域，比如电子商务和法律文件。以电子商务为例，文本通常包含大量领域相关词汇，并且存在更多的语法问题，这导致当前NMT方法的性能较差。为解决这些问题，我们收集了两个与领域相关的资源，包括一组术语对（对齐的中英双语术语）和一个针对电子商务领域进行注释的平行语料库。此外，我们提出了一个两步微调范式（名为G2ST），其中包括自对比语义增强，以将一个通用NMT模型转换为专门用于电子商务的NMT模型。该范式适用于基于大型语言模型（LLMs）的NMT模型。对真实电子商务标题的广泛评估表明了卓越的翻译质量。

    arXiv:2403.03689v1 Announce Type: cross  Abstract: Existing Neural Machine Translation (NMT) models mainly handle translation in the general domain, while overlooking domains with special writing formulas, such as e-commerce and legal documents. Taking e-commerce as an example, the texts usually include amounts of domain-related words and have more grammar problems, which leads to inferior performances of current NMT methods. To address these problems, we collect two domain-related resources, including a set of term pairs (aligned Chinese-English bilingual terms) and a parallel corpus annotated for the e-commerce domain. Furthermore, we propose a two-step fine-tuning paradigm (named G2ST) with self-contrastive semantic enhancement to transfer one general NMT model to the specialized NMT model for e-commerce. The paradigm can be used for the NMT models based on Large language models (LLMs). Extensive evaluations on real e-commerce titles demonstrate the superior translation quality and 
    
[^35]: K-Link：基于LLMs的知识链接图在多元时间序列数据增强表示学习中的应用

    K-Link: Knowledge-Link Graph from LLMs for Enhanced Representation Learning in Multivariate Time-Series Data

    [https://arxiv.org/abs/2403.03645](https://arxiv.org/abs/2403.03645)

    提出了一种名为K-Link的框架，利用大型语言模型编码通用知识，提取了Knowledge-Link图以捕获传感器之间的广泛语义知识和联系。

    

    从各种传感器采集并按时间顺序组织的多元时间序列（MTS）数据涉及关键的时空依赖性，如传感器之间的相关性。为了捕捉这些依赖关系，图神经网络（GNNs）已经成为强大的工具，但它们的有效性受到从MTS数据构建图的质量限制。通常，现有方法仅从MTS信号构建图，这可能会由于小训练数据集而引入偏差，并可能无法准确表示底层依赖关系。为了解决这一挑战，我们提出了一个名为K-Link的新框架，利用大型语言模型（LLMs）来编码广泛的通用知识，从而提供有效的解决方案以减少偏差。利用LLMs中嵌入的知识，例如物理原理，我们提取了一个Knowledge-Link图，捕获了传感器的广泛语义知识和传感器之间的链接。

    arXiv:2403.03645v1 Announce Type: new  Abstract: Sourced from various sensors and organized chronologically, Multivariate Time-Series (MTS) data involves crucial spatial-temporal dependencies, e.g., correlations among sensors. To capture these dependencies, Graph Neural Networks (GNNs) have emerged as powerful tools, yet their effectiveness is restricted by the quality of graph construction from MTS data. Typically, existing approaches construct graphs solely from MTS signals, which may introduce bias due to a small training dataset and may not accurately represent underlying dependencies. To address this challenge, we propose a novel framework named K-Link, leveraging Large Language Models (LLMs) to encode extensive general knowledge and thereby providing effective solutions to reduce the bias. Leveraging the knowledge embedded in LLMs, such as physical principles, we extract a \textit{Knowledge-Link graph}, capturing vast semantic knowledge of sensors and the linkage of the sensor-le
    
[^36]: 强化学习在空间资源分配中的应用调查

    A Survey on Applications of Reinforcement Learning in Spatial Resource Allocation

    [https://arxiv.org/abs/2403.03643](https://arxiv.org/abs/2403.03643)

    运用强化学习解决空间资源分配问题的新方法具有快速解决方法收敛和强大的模型泛化能力等优势，为这一问题领域提供了新的视角。

    

    空间资源分配的挑战在交通运输、工业和日常生活等各个领域普遍存在。随着现实世界问题规模不断扩大以及对实时解决方案的需求增加，传统算法面临着巨大的计算压力，难以实现最佳效率和实时能力。近年来，随着计算机计算能力的不断提升，强化学习在诸如围棋和机器人领域取得了显著成就，展示了其强大的学习和序贯决策能力。鉴于这些进展，近年来出现了大量运用强化学习解决空间资源分配问题的新方法。这些方法具有快速解决方法收敛和强大的模型泛化能力等优势，为解决空间资源分配问题提供了新的视角。

    arXiv:2403.03643v1 Announce Type: cross  Abstract: The challenge of spatial resource allocation is pervasive across various domains such as transportation, industry, and daily life. As the scale of real-world issues continues to expand and demands for real-time solutions increase, traditional algorithms face significant computational pressures, struggling to achieve optimal efficiency and real-time capabilities. In recent years, with the escalating computational power of computers, the remarkable achievements of reinforcement learning in domains like Go and robotics have demonstrated its robust learning and sequential decision-making capabilities. Given these advancements, there has been a surge in novel methods employing reinforcement learning to tackle spatial resource allocation problems. These methods exhibit advantages such as rapid solution convergence and strong model generalization abilities, offering a new perspective on resolving spatial resource allocation problems. Therefor
    
[^37]: Apollo：轻量级多语言医学LLMs：让医学人工智能普惠60亿人

    Apollo: Lightweight Multilingual Medical LLMs towards Democratizing Medical AI to 6B People

    [https://arxiv.org/abs/2403.03640](https://arxiv.org/abs/2403.03640)

    Apollo项目开发了多语言医学LLMs，创建了全球人口61亿的医学数据集，并发布了各种尺寸的最佳性能模型，其中Apollo-7B是最先进的多语言医学LLMs，可改善更大模型的多语言医学能力。

    

    尽管全球医学知识的庞大存储库主要是以英语为主，但在传递量身定制医疗服务方面，本地语言对于在医疗资源有限的地区尤为重要。为了将医学人工智能的进展扩展到更广泛的人群，我们旨在开发涵盖全球61亿人口的六种最常用语言的医学LLMs。这一努力最终促成了ApolloCorpora多语言医学数据集和XMedBench基准的创建。在多语言医学基准测试中，发布的Apollo模型，在各种相对较小尺寸（即0.5B、1.8B、2B、6B和7B）上取得了与同等大小模型最佳性能。特别地，Apollo-7B是迄今为止达到70B的最先进的多语言医学LLMs。此外，这些轻量级模型可用于在不需要微调的情况下改进较大模型的多语言医学能力。

    arXiv:2403.03640v1 Announce Type: cross  Abstract: Despite the vast repository of global medical knowledge predominantly being in English, local languages are crucial for delivering tailored healthcare services, particularly in areas with limited medical resources. To extend the reach of medical AI advancements to a broader population, we aim to develop medical LLMs across the six most widely spoken languages, encompassing a global population of 6.1 billion. This effort culminates in the creation of the ApolloCorpora multilingual medical dataset and the XMedBench benchmark. In the multilingual medical benchmark, the released Apollo models, at various relatively-small sizes (i.e., 0.5B, 1.8B, 2B, 6B, and 7B), achieve the best performance among models of equivalent size. Especially, Apollo-7B is the state-of-the-art multilingual medical LLMs up to 70B. Additionally, these lite models could be used to improve the multi-lingual medical capabilities of larger models without fine-tuning in a
    
[^38]: SheetAgent：通过大型语言模型进行电子表格推理和操作的通用代理

    SheetAgent: A Generalist Agent for Spreadsheet Reasoning and Manipulation via Large Language Models

    [https://arxiv.org/abs/2403.03636](https://arxiv.org/abs/2403.03636)

    SheetAgent是一种利用大型语言模型进行电子表格推理和操作的通用代理，提供了处理复杂现实任务的解决方案

    

    电子表格操作广泛存在于大多数日常工作中，并显著提高了工作效率。最近尝试使用大型语言模型(LLM)进行自动电子表格操作，但尚未在存在推理挑战的复杂和现实任务中进行探究（例如，具有多步推理和模糊要求的长视野操作）。为了弥合与真实世界要求之间的差距，我们引入了$\textbf{SheetRM}$，一个特点是长视野和多类任务的基准，具有推理相关操纵，由真实挑战引起。为了缓解以上挑战，我们进一步提出了$\textbf{SheetAgent}$，一种利用LLMs能力的新型自主代理。SheetAgent由三个协作模块组成：$\textit{Planner}$、$\textit{Informer}$和$\textit{Retriever}$，实现了对电子表格的高级推理和准确操作，而不需人类

    arXiv:2403.03636v1 Announce Type: new  Abstract: Spreadsheet manipulation is widely existing in most daily works and significantly improves working efficiency. Large language model (LLM) has been recently attempted for automatic spreadsheet manipulation but has not yet been investigated in complicated and realistic tasks where reasoning challenges exist (e.g., long horizon manipulation with multi-step reasoning and ambiguous requirements). To bridge the gap with the real-world requirements, we introduce $\textbf{SheetRM}$, a benchmark featuring long-horizon and multi-category tasks with reasoning-dependent manipulation caused by real-life challenges. To mitigate the above challenges, we further propose $\textbf{SheetAgent}$, a novel autonomous agent that utilizes the power of LLMs. SheetAgent consists of three collaborative modules: $\textit{Planner}$, $\textit{Informer}$, and $\textit{Retriever}$, achieving both advanced reasoning and accurate manipulation over spreadsheets without hu
    
[^39]: 多模态大型语言模型支持现实世界事实核查

    Multimodal Large Language Models to Support Real-World Fact-Checking

    [https://arxiv.org/abs/2403.03627](https://arxiv.org/abs/2403.03627)

    多模态大型语言模型在支持现实世界事实核查中展现出优越性能，并能够解释恶意和误导性声明的不合理之处和潜在动机。

    

    多模态大型语言模型（MLLMs）具有潜力支持人类处理大量信息。虽然MLLMs已经被用作事实核查工具，但就其在此方面的能力和局限性而言，尚未得到充分研究。我们旨在弥合这一差距。具体而言，我们提出了一个框架，系统评估当前多模态模型促进现实世界事实核查的能力。我们的方法论是无需证据的，仅利用这些模型的固有知识和推理能力。通过设计能够提取模型预测、解释和置信水平的提示，我们深入研究关于模型准确性、鲁棒性以及失败原因的研究问题。我们在实证上发现，(1) GPT-4V在识别恶意和误导性多模态声明方面表现出超凡性能，能够解释不合理的方面和潜在动机，以及(2)现有的o

    arXiv:2403.03627v1 Announce Type: cross  Abstract: Multimodal large language models (MLLMs) carry the potential to support humans in processing vast amounts of information. While MLLMs are already being used as a fact-checking tool, their abilities and limitations in this regard are understudied. Here is aim to bridge this gap. In particular, we propose a framework for systematically assessing the capacity of current multimodal models to facilitate real-world fact-checking. Our methodology is evidence-free, leveraging only these models' intrinsic knowledge and reasoning capabilities. By designing prompts that extract models' predictions, explanations, and confidence levels, we delve into research questions concerning model accuracy, robustness, and reasons for failure. We empirically find that (1) GPT-4V exhibits superior performance in identifying malicious and misleading multimodal claims, with the ability to explain the unreasonable aspects and underlying motives, and (2) existing o
    
[^40]: GSNeRF: 增强了3D场景理解的通用语义神经辐射场

    GSNeRF: Generalizable Semantic Neural Radiance Fields with Enhanced 3D Scene Understanding

    [https://arxiv.org/abs/2403.03608](https://arxiv.org/abs/2403.03608)

    GSNeRF通过引入图像语义，实现了对未知场景的新视图图像和相关语义地图的生成，并在图像和语义渲染方面取得了改进性能。

    

    在这项工作中，我们引入了一种通用的语义神经辐射场（GSNeRF），它独特地将图像语义纳入合成过程，因此可以为未知场景生成新视图图像和相关的语义地图。我们的GSNeRF由两个阶段组成：语义地理推理和深度引导可视渲染。前者能够观察多视图图像输入，从场景中提取语义和几何特征。在后者的指导下，根据生成的图像几何信息，进行了具有改进性能的图像和语义渲染。我们的实验证实了GSNeRF在新视图图像和语义分割合成方面优于先前工作，并且证明了我们的采样策略对于可视渲染的有效性。

    arXiv:2403.03608v1 Announce Type: cross  Abstract: Utilizing multi-view inputs to synthesize novel-view images, Neural Radiance Fields (NeRF) have emerged as a popular research topic in 3D vision. In this work, we introduce a Generalizable Semantic Neural Radiance Field (GSNeRF), which uniquely takes image semantics into the synthesis process so that both novel view images and the associated semantic maps can be produced for unseen scenes. Our GSNeRF is composed of two stages: Semantic Geo-Reasoning and Depth-Guided Visual rendering. The former is able to observe multi-view image inputs to extract semantic and geometry features from a scene. Guided by the resulting image geometry information, the latter performs both image and semantic rendering with improved performances. Our experiments not only confirm that GSNeRF performs favorably against prior works on both novel-view image and semantic segmentation synthesis but the effectiveness of our sampling strategy for visual rendering is 
    
[^41]: 话题模型的几何结构

    The Geometric Structure of Topic Models

    [https://arxiv.org/abs/2403.03607](https://arxiv.org/abs/2403.03607)

    提出了一种从平面话题模型中导出序数结构的关联几何方法，可以在高维度分析话题模型，提取多个主题之间的概念关系

    

    话题模型是一种用于聚类和分析文本数据的流行工具。它们允许根据其与先前计算的主题的关联来对文本进行分类。尽管话题模型在研究和应用中被广泛使用，但对话题模型的深入分析仍然是一个开放的研究课题。解释话题模型的最新方法基于简单的可视化，如相似性矩阵、高频词列表或嵌入，但这些方法仅限于最多三维。本文提出了一种用于从平面话题模型（如非负矩阵分解）中导出序数结构的关联几何方法。这使得可以在更高的（阶）维度分析话题模型，并有可能一次性提取多个主题之间的概念关系。由于使用了概念尺度，我们的方法不引入任何人为的主题关系，如ar

    arXiv:2403.03607v1 Announce Type: new  Abstract: Topic models are a popular tool for clustering and analyzing textual data. They allow texts to be classified on the basis of their affiliation to the previously calculated topics. Despite their widespread use in research and application, an in-depth analysis of topic models is still an open research topic. State-of-the-art methods for interpreting topic models are based on simple visualizations, such as similarity matrices, top-term lists or embeddings, which are limited to a maximum of three dimensions. In this paper, we propose an incidence-geometric method for deriving an ordinal structure from flat topic models, such as non-negative matrix factorization. These enable the analysis of the topic model in a higher (order) dimension and the possibility of extracting conceptual relationships between several topics at once. Due to the use of conceptual scaling, our approach does not introduce any artificial topical relationships, such as ar
    
[^42]: 通过Transformer神经网络和技术指标提升加密货币价格预测

    Enhancing Price Prediction in Cryptocurrency Using Transformer Neural Network and Technical Indicators

    [https://arxiv.org/abs/2403.03606](https://arxiv.org/abs/2403.03606)

    该研究提出了通过引入Transformer神经网络和技术指标来提升加密货币价格预测的方法，该方法对于捕获时间动态和提取重要特征具有显著的优势

    

    本研究提出了一种创新的方法，用于预测加密货币时间序列，特别关注比特币、以太坊和莱特币。该方法整合了技术指标、Performer神经网络和BiLSTM（双向长短期记忆网络）来捕获时间动态并从原始加密货币数据中提取重要特征。技术指标的应用有助于提取复杂模式、动量、波动性和趋势。Performer神经网络使用快速关注正交随机特征（FAVOR+）相对于传统的Transformer模型中的多头注意力机制，展现出更优越的计算效率和可伸缩性。此外，将BiLSTM集成到前馈网络中增强了模型捕获数据时间动态的能力，向前和向后两个方向进行处理。

    arXiv:2403.03606v1 Announce Type: cross  Abstract: This study presents an innovative approach for predicting cryptocurrency time series, specifically focusing on Bitcoin, Ethereum, and Litecoin. The methodology integrates the use of technical indicators, a Performer neural network, and BiLSTM (Bidirectional Long Short-Term Memory) to capture temporal dynamics and extract significant features from raw cryptocurrency data. The application of technical indicators, such facilitates the extraction of intricate patterns, momentum, volatility, and trends. The Performer neural network, employing Fast Attention Via positive Orthogonal Random features (FAVOR+), has demonstrated superior computational efficiency and scalability compared to the traditional Multi-head attention mechanism in Transformer models. Additionally, the integration of BiLSTM in the feedforward network enhances the model's capacity to capture temporal dynamics in the data, processing it in both forward and backward direction
    
[^43]: 一种基于多模态数据的隐私保护框架用于跨领域推荐

    A Privacy-Preserving Framework with Multi-Modal Data for Cross-Domain Recommendation

    [https://arxiv.org/abs/2403.03600](https://arxiv.org/abs/2403.03600)

    提出了一种基于多模态数据的隐私保护框架用于跨领域推荐，通过设计多模态解耦编码器实现更好的特征学习。

    

    交叉领域推荐（CDR）旨在通过利用源领域中丰富的信息来增强目标领域推荐的准确性，从而解决数据稀疏问题。针对这些挑战，我们提出了一种名为P2M2-CDR的基于多模态数据的隐私保护框架，通过设计了一个多模态解耦编码器，结合了多模态信息来更好地学习领域共有和领域特定特征，从而实现跨领域推荐任务。

    arXiv:2403.03600v1 Announce Type: new  Abstract: Cross-domain recommendation (CDR) aims to enhance recommendation accuracy in a target domain with sparse data by leveraging rich information in a source domain, thereby addressing the data-sparsity problem. Some existing CDR methods highlight the advantages of extracting domain-common and domain-specific features to learn comprehensive user and item representations. However, these methods can't effectively disentangle these components as they often rely on simple user-item historical interaction information (such as ratings, clicks, and browsing), neglecting the rich multi-modal features. Additionally, they don't protect user-sensitive data from potential leakage during knowledge transfer between domains. To address these challenges, we propose a Privacy-Preserving Framework with Multi-Modal Data for Cross-Domain Recommendation, called P2M2-CDR. Specifically, we first design a multi-modal disentangled encoder that utilizes multi-modal in
    
[^44]: 评估GPT-4与Vision的审美评价能力：来自群体和个体评估的见解

    Assessing the Aesthetic Evaluation Capabilities of GPT-4 with Vision: Insights from Group and Individual Assessments

    [https://arxiv.org/abs/2403.03594](https://arxiv.org/abs/2403.03594)

    本研究评估了GPT-4与Vision在处理图像输入的最先进语言模型在审美评价任务中的表现，结果显示其在预测审美评价方面表现出色，并展现了对美和丑的不同反应的特性。

    

    最近，人们意识到大型语言模型在各种智力任务上表现出色。然而，很少有研究调查这些模型在涉及审美评价等涉及感性的行为中与人类的一致性。本研究调查了能够处理图像输入的最先进语言模型GPT-4与Vision在图像的审美评价任务中的表现。我们进行了两个任务，预测群体的平均评价值和个体的评价值。通过探索提示并分析预测行为，我们调查了GPT-4与Vision的表现。实验结果显示，GPT-4与Vision在预测审美评价方面表现出色，并展现了对美和丑的不同反应的特性。最后，我们讨论了基于人类对美感知的科学知识发展审美评价的AI系统。

    arXiv:2403.03594v1 Announce Type: new  Abstract: Recently, it has been recognized that large language models demonstrate high performance on various intellectual tasks. However, few studies have investigated alignment with humans in behaviors that involve sensibility, such as aesthetic evaluation. This study investigates the performance of GPT-4 with Vision, a state-of-the-art language model that can handle image input, on the task of aesthetic evaluation of images. We employ two tasks, prediction of the average evaluation values of a group and an individual's evaluation values. We investigate the performance of GPT-4 with Vision by exploring prompts and analyzing prediction behaviors. Experimental results reveal GPT-4 with Vision's superior performance in predicting aesthetic evaluations and the nature of different responses to beauty and ugliness. Finally, we discuss developing an AI system for aesthetic evaluation based on scientific knowledge of the human perception of beauty, empl
    
[^45]: 您信任您的模型吗？深度学习生态系统中新兴的恶意软件威胁

    Do You Trust Your Model? Emerging Malware Threats in the Deep Learning Ecosystem

    [https://arxiv.org/abs/2403.03593](https://arxiv.org/abs/2403.03593)

    介绍了MaleficNet 2.0，一种在神经网络中嵌入恶意软件的新技术，其注入技术具有隐蔽性，不会降低模型性能，并且对神经网络参数中的恶意有效负载进行注入

    

    训练高质量的深度学习模型是一项具有挑战性的任务，这是因为需要计算和技术要求。越来越多的个人、机构和公司越来越多地依赖于在公共代码库中提供的预训练的第三方模型。这些模型通常直接使用或集成到产品管道中而没有特殊的预防措施，因为它们实际上只是以张量形式的数据，被认为是安全的。在本文中，我们提出了一种针对神经网络的新的机器学习供应链威胁。我们介绍了MaleficNet 2.0，一种在神经网络中嵌入自解压自执行恶意软件的新技术。MaleficNet 2.0使用扩频信道编码结合纠错技术在深度神经网络的参数中注入恶意有效载荷。MaleficNet 2.0注入技术具有隐蔽性，不会降低模型的性能，并且对...

    arXiv:2403.03593v1 Announce Type: cross  Abstract: Training high-quality deep learning models is a challenging task due to computational and technical requirements. A growing number of individuals, institutions, and companies increasingly rely on pre-trained, third-party models made available in public repositories. These models are often used directly or integrated in product pipelines with no particular precautions, since they are effectively just data in tensor form and considered safe. In this paper, we raise awareness of a new machine learning supply chain threat targeting neural networks. We introduce MaleficNet 2.0, a novel technique to embed self-extracting, self-executing malware in neural networks. MaleficNet 2.0 uses spread-spectrum channel coding combined with error correction techniques to inject malicious payloads in the parameters of deep neural networks. MaleficNet 2.0 injection technique is stealthy, does not degrade the performance of the model, and is robust against 
    
[^46]: Wildest Dreams: 隐私保护神经网络训练中可复现的研究

    Wildest Dreams: Reproducible Research in Privacy-preserving Neural Network Training

    [https://arxiv.org/abs/2403.03592](https://arxiv.org/abs/2403.03592)

    隐私保护技术的最新进展使得可以在受保护数据上进行机器学习训练和推断，但在实际应用中仍面临挑战。

    

    机器学习（ML）涉及多个学科的复杂问题，包括社会科学、金融和医学研究。ML模型需要大量计算资源，其强大程度取决于所使用的数据。由于ML方法的高计算成本，数据科学家经常使用机器学习即服务（MLaaS）将计算外包给外部服务器。然而，当处理私人信息（如财务数据或健康记录）时，将计算外包可能会导致隐私问题。隐私保护技术（PPTs）的最新进展通过隐私保护机器学习（PPML）使得可以在受保护数据上进行ML训练和推断。然而，这些技术仍处于初步阶段，它们在实际情况中的应用要求较高。为了理解理论研究建议与实际应用之间的差异，

    arXiv:2403.03592v1 Announce Type: cross  Abstract: Machine Learning (ML), addresses a multitude of complex issues in multiple disciplines, including social sciences, finance, and medical research. ML models require substantial computing power and are only as powerful as the data utilized. Due to high computational cost of ML methods, data scientists frequently use Machine Learning-as-a-Service (MLaaS) to outsource computation to external servers. However, when working with private information, like financial data or health records, outsourcing the computation might result in privacy issues. Recent advances in Privacy-Preserving Techniques (PPTs) have enabled ML training and inference over protected data through the use of Privacy-Preserving Machine Learning (PPML). However, these techniques are still at a preliminary stage and their application in real-world situations is demanding. In order to comprehend discrepancy between theoretical research suggestions and actual applications, thi
    
[^47]: RouteExplainer：一种车辆路径问题的解释框架

    RouteExplainer: An Explanation Framework for Vehicle Routing Problem

    [https://arxiv.org/abs/2403.03585](https://arxiv.org/abs/2403.03585)

    提出了一种车辆路径问题的解释框架RouteExplainer，实现了边的影响解释和意图推断，通过大型语言模型生成解释文本，并在多个VRP上进行了量化评估

    

    车辆路径问题（VRP）是一个广泛研究的组合优化问题，已应用于各种实际问题。尽管对VRP的可解释性对于改善实际VRP应用中的可靠性和互动性至关重要，但这个领域仍未被探索。本文提出了RouteExplainer，一种事后解释框架，用于解释在生成路径中每条边的影响。我们的框架通过重新思考路径为动作序列并基于动作影响模型扩展对VRP的反事实解释来实现这一点。为了增强解释，我们额外提出了一个边界分类器，推断每个边界的意图，一个用于训练边界分类器的损失函数，以及通过大型语言模型（LLMs）生成解释文本。我们在四种不同的VRP上定量评估了我们的边界分类器。结果表明，在保持计算速度的同时

    arXiv:2403.03585v1 Announce Type: cross  Abstract: The Vehicle Routing Problem (VRP) is a widely studied combinatorial optimization problem and has been applied to various practical problems. While the explainability for VRP is significant for improving the reliability and interactivity in practical VRP applications, it remains unexplored. In this paper, we propose RouteExplainer, a post-hoc explanation framework that explains the influence of each edge in a generated route. Our framework realizes this by rethinking a route as the sequence of actions and extending counterfactual explanations based on the action influence model to VRP. To enhance the explanation, we additionally propose an edge classifier that infers the intentions of each edge, a loss function to train the edge classifier, and explanation-text generation by Large Language Models (LLMs). We quantitatively evaluate our edge classifier on four different VRPs. The results demonstrate its rapid computation while maintaining
    
[^48]: 为神经机器翻译设计的开源架构

    Design of an Open-Source Architecture for Neural Machine Translation

    [https://arxiv.org/abs/2403.03582](https://arxiv.org/abs/2403.03582)

    该开源应用程序 adaptNMT 简化了神经机器翻译模型的开发和部署，提供了图形化训练进展展示、子词分割模型和一键式模型开发方法。

    

    arXiv:2403.03582v1 公告类型: 跨领域 adaptNMT 是一个开源应用程序，提供了一种简化的方法来开发和部署循环神经网络和Transformer模型。该应用程序构建在广泛采用的OpenNMT生态系统之上，特别适用于该领域的新进入者，因为它简化了开发环境的设置以及训练、验证和测试数据集的创建。该应用程序提供了一个图形化功能，用于展示模型训练的进展，并采用SentencePiece来创建子词分割模型。此外，该应用程序提供了一个直观的用户界面，简化了超参数的定制。值得注意的是，该应用实现了一键式模型开发方法，通过adaptNMT开发的模型可以使用各种指标进行评估。为了鼓励环保研究，adaptNMT集成了一个环保报告，标志着能源消耗和二氧化碳排放量。

    arXiv:2403.03582v1 Announce Type: cross  Abstract: adaptNMT is an open-source application that offers a streamlined approach to the development and deployment of Recurrent Neural Networks and Transformer models. This application is built upon the widely-adopted OpenNMT ecosystem, and is particularly useful for new entrants to the field, as it simplifies the setup of the development environment and creation of train, validation, and test splits. The application offers a graphing feature that illustrates the progress of model training, and employs SentencePiece for creating subword segmentation models. Furthermore, the application provides an intuitive user interface that facilitates hyperparameter customization. Notably, a single-click model development approach has been implemented, and models developed by adaptNMT can be evaluated using a range of metrics. To encourage eco-friendly research, adaptNMT incorporates a green report that flags the power consumption and kgCO${_2}$ emissions
    
[^49]: 用于调节社交推荐中社交影响偏差的因果分解

    Causal Disentanglement for Regulating Social Influence Bias in Social Recommendation

    [https://arxiv.org/abs/2403.03578](https://arxiv.org/abs/2403.03578)

    提出了一种基于因果分解的框架CDRSB，用于调节社交推荐中的社交影响偏差，以提高推荐性能。

    

    社交推荐系统面临着社交影响偏差的问题，这可能导致过分强调推荐朋友互动过的物品。解决这一问题至关重要，现有方法通常依赖于权重调整或利用无偏数据来消除这种偏差。然而，我们认为并非所有偏差都是有害的，即一些朋友推荐的物品可能与用户的兴趣相符。盲目消除这些偏差可能会削弱这些积极影响，可能降低推荐准确性。在本文中，我们提出了一种基于因果分解的框架，用于调节社交推荐中的社交影响偏差，名为CDRSB，以提高推荐性能。从因果推断的角度来看，我们发现用户社交网络可以被视为用户和物品嵌入（处理）以及评分（结果）之间的共变量。

    arXiv:2403.03578v1 Announce Type: cross  Abstract: Social recommendation systems face the problem of social influence bias, which can lead to an overemphasis on recommending items that friends have interacted with. Addressing this problem is crucial, and existing methods often rely on techniques such as weight adjustment or leveraging unbiased data to eliminate this bias. However, we argue that not all biases are detrimental, i.e., some items recommended by friends may align with the user's interests. Blindly eliminating such biases could undermine these positive effects, potentially diminishing recommendation accuracy. In this paper, we propose a Causal Disentanglement-based framework for Regulating Social influence Bias in social recommendation, named CDRSB, to improve recommendation performance. From the perspective of causal inference, we find that the user social network could be regarded as a confounder between the user and item embeddings (treatment) and ratings (outcome). Due t
    
[^50]: gaHealth: 一份英语-爱尔兰爱尔兰双语健康数据语料库

    gaHealth: An English-Irish Bilingual Corpus of Health Data

    [https://arxiv.org/abs/2403.03575](https://arxiv.org/abs/2403.03575)

    开发了一份用于低资源英语到爱尔兰语言对的特定健康领域数据集，实证证明使用领域数据对健康领域具有明显好处，并展示的最大BLEU分数提升为22.2点（40%）。

    

    arXiv:2403.03575v1 公告类型：跨界  摘要：机器翻译是一种成熟的技术，适用于许多高资源语言对。然而，在低资源语言环境中，目前很少有可用于开发翻译模型的平行数据数据集。此外，针对低资源语言开发数据集的工作往往集中于简单地创建用于通用翻译的尽可能大的数据集。很容易忽视使用小型领域数据集的好处和发展。为了评估使用领域数据的优点，为低资源的英语到爱尔兰语言对特定领域的健康数据开发了一个数据集。我们的研究概述了开发语料库所使用的过程，并从经验上展示了使用健康领域的领域数据的好处。在翻译与健康相关数据的背景下，使用gaHealth语料库开发的模型在比较时显示出最大BLEU分数提升22.2点（40%）。

    arXiv:2403.03575v1 Announce Type: cross  Abstract: Machine Translation is a mature technology for many high-resource language pairs. However in the context of low-resource languages, there is a paucity of parallel data datasets available for developing translation models. Furthermore, the development of datasets for low-resource languages often focuses on simply creating the largest possible dataset for generic translation. The benefits and development of smaller in-domain datasets can easily be overlooked. To assess the merits of using in-domain data, a dataset for the specific domain of health was developed for the low-resource English to Irish language pair. Our study outlines the process used in developing the corpus and empirically demonstrates the benefits of using an in-domain dataset for the health domain. In the context of translating health-related data, models developed using the gaHealth corpus demonstrated a maximum BLEU score improvement of 22.2 points (40%) when compared
    
[^51]: 通过提示工程加大了人工智能大语言模型中生成虚假信息的情绪操纵

    Emotional Manipulation Through Prompt Engineering Amplifies Disinformation Generation in AI Large Language Models

    [https://arxiv.org/abs/2403.03550](https://arxiv.org/abs/2403.03550)

    研究通过提示工程和情绪操纵研究了OpenAI的大型语言模型在生成虚假信息方面的反应，发现它们能够成功生成虚假信息并对情绪提示有细致的理解。

    

    这项研究通过提示工程调查了OpenAI的大型语言模型（LLMs）生成合成虚假信息，并探讨了它们对情绪提示的响应。利用davinci-002、davinci-003、gpt-3.5-turbo和gpt-4等各种LLM迭代，我们设计了实验来评估它们在生成虚假信息方面的成功率。基于一组包含19,800条合成虚假社交媒体帖子的语料库，我们的研究发现OpenAI的所有LLMs都能成功生成虚假信息，并且它们有效地响应情绪提示，表明它们对文本生成中的情绪线索有微妙的理解。在礼貌提示下，所有研究中的LLMs都以高频率一致地生成虚假信息。相反，当以不礼貌方式提示时，虚假信息生成的频率会降低，因为这些模型通常会拒绝生成虚假信息，而是警告用户该工具不适用

    arXiv:2403.03550v1 Announce Type: new  Abstract: This study investigates the generation of synthetic disinformation by OpenAI's Large Language Models (LLMs) through prompt engineering and explores their responsiveness to emotional prompting. Leveraging various LLM iterations using davinci-002, davinci-003, gpt-3.5-turbo and gpt-4, we designed experiments to assess their success in producing disinformation. Our findings, based on a corpus of 19,800 synthetic disinformation social media posts, reveal that all LLMs by OpenAI can successfully produce disinformation, and that they effectively respond to emotional prompting, indicating their nuanced understanding of emotional cues in text generation. When prompted politely, all examined LLMs consistently generate disinformation at a high frequency. Conversely, when prompted impolitely, the frequency of disinformation production diminishes, as the models often refuse to generate disinformation and instead caution users that the tool is not in
    
[^52]: 基于语言的人类移动预测的提示挖掘

    Prompt Mining for Language-based Human Mobility Forecasting

    [https://arxiv.org/abs/2403.03544](https://arxiv.org/abs/2403.03544)

    使用信息熵进行提示挖掘，探索多样化的提示设计策略，提高基于语言的人类移动预测的准确性和效果

    

    随着大型语言模型的发展，基于语言的预测最近作为一种创新方法出现，用于预测人类移动模式。其核心思想是使用提示将以数字值给出的原始移动数据转化为自然语言句子，从而可以利用语言模型生成未来观察的描述。然而，先前的研究仅采用固定和手动设计的模板将数字值转化为句子。由于语言模型的预测性能严重依赖于提示，使用固定模板进行提示可能限制语言模型的预测能力。在本文中，我们提出了一种新颖的基于语言的移动预测提示挖掘框架，旨在探索多样化的提示设计策略。具体而言，该框架包括基于提示信息熵的提示生成阶段和

    arXiv:2403.03544v1 Announce Type: new  Abstract: With the advancement of large language models, language-based forecasting has recently emerged as an innovative approach for predicting human mobility patterns. The core idea is to use prompts to transform the raw mobility data given as numerical values into natural language sentences so that the language models can be leveraged to generate the description for future observations. However, previous studies have only employed fixed and manually designed templates to transform numerical values into sentences. Since the forecasting performance of language models heavily relies on prompts, using fixed templates for prompting may limit the forecasting capability of language models. In this paper, we propose a novel framework for prompt mining in language-based mobility forecasting, aiming to explore diverse prompt design strategies. Specifically, the framework includes a prompt generation stage based on the information entropy of prompts and 
    
[^53]: RADIA -- 具有智能分析的广播广告检测

    RADIA -- Radio Advertisement Detection with Intelligent Analytics

    [https://arxiv.org/abs/2403.03538](https://arxiv.org/abs/2403.03538)

    本研究提出了一种新型自动广播广告检测技术RADIA，利用先进的语音识别和文本分类算法，能够在不需要先验知识的情况下检测广播中的即兴和新广告，为广播广告检测提供了全面的解决方案，并取得了较高的F1-macro得分。

    

    广播广告仍然是现代营销策略中不可或缺的一部分，其吸引力和针对性传播的潜力不可否认。然而，广播播出时间的动态性和多个广播广告的日益增长趋势为监测广告播出的有效性提出了要求。本研究调查了一种结合先进语音识别和文本分类算法的新型自动广播广告检测技术。RADIA的方法通过消除对广播内容的先验知识的需求，超越了传统方法。这一贡献允许检测即兴和新引入的广告，为广播广告检测提供了全面的解决方案。实验结果表明，该模型在精心分割和标记的文本数据上训练，达到了F1-macro得分87.76，理论最大值为89.33。

    arXiv:2403.03538v1 Announce Type: cross  Abstract: Radio advertising remains an integral part of modern marketing strategies, with its appeal and potential for targeted reach undeniably effective. However, the dynamic nature of radio airtime and the rising trend of multiple radio spots necessitates an efficient system for monitoring advertisement broadcasts. This study investigates a novel automated radio advertisement detection technique incorporating advanced speech recognition and text classification algorithms. RadIA's approach surpasses traditional methods by eliminating the need for prior knowledge of the broadcast content. This contribution allows for detecting impromptu and newly introduced advertisements, providing a comprehensive solution for advertisement detection in radio broadcasting. Experimental results show that the resulting model, trained on carefully segmented and tagged text data, achieves an F1-macro score of 87.76 against a theoretical maximum of 89.33. This pape
    
[^54]: 为推荐而设计的大型语言模型的高效和有效的遗忘

    Towards Efficient and Effective Unlearning of Large Language Models for Recommendation

    [https://arxiv.org/abs/2403.03536](https://arxiv.org/abs/2403.03536)

    提出了E2URec，这是为了解决大型语言模型在推荐系统中遗忘特定用户数据所面临的效率和有效性方面的挑战。

    

    大型语言模型（LLMs）的显著进展产生了一项有前途的研究方向，即利用LLMs作为推荐系统（LLMRec）。 LLMRec的有效性源自LLMs固有的开放世界知识和推理能力。 LLMRec通过基于用户互动数据的指导调整获得推荐功能。 然而，为了保护用户隐私并优化效用，LLMRec还必须有意忘记特定用户数据，这通常称为推荐遗忘。 在LLMs时代，推荐遗忘在\textit{效率}和\textit{有效性}方面为LLMRec带来了新挑战。 现有的遗忘方法需要更新LLMRec中数十亿参数，这是昂贵且耗时的。 此外，它们在遗忘过程中总是影响模型效用。 为此，我们提出了\textbf{E2URec}，第一

    arXiv:2403.03536v1 Announce Type: cross  Abstract: The significant advancements in large language models (LLMs) give rise to a promising research direction, i.e., leveraging LLMs as recommenders (LLMRec). The efficacy of LLMRec arises from the open-world knowledge and reasoning capabilities inherent in LLMs. LLMRec acquires the recommendation capabilities through instruction tuning based on user interaction data. However, in order to protect user privacy and optimize utility, it is also crucial for LLMRec to intentionally forget specific user data, which is generally referred to as recommendation unlearning. In the era of LLMs, recommendation unlearning poses new challenges for LLMRec in terms of \textit{inefficiency} and \textit{ineffectiveness}. Existing unlearning methods require updating billions of parameters in LLMRec, which is costly and time-consuming. Besides, they always impact the model utility during the unlearning process. To this end, we propose \textbf{E2URec}, the first
    
[^55]: IB-Net: 布尔可满足性中变量决策的初始分支网络

    IB-Net: Initial Branch Network for Variable Decision in Boolean Satisfiability

    [https://arxiv.org/abs/2403.03517](https://arxiv.org/abs/2403.03517)

    IB-Net 提出了一种创新的框架，利用图神经网络和新颖的图编码技术来加速布尔可满足性问题的求解。

    

    布尔可满足性问题是电子设计自动化中的重要组成部分，特别是在逻辑等效检查过程中。目前，SAT求解器被用于这些问题，并尝试将神经网络作为求解器的辅助。然而，在LEC上下文中的SAT问题由于其主要为不可满足性质和大量UNSAT-core变量而与众不同，现有的神经网络辅助在这一专业领域中表现不佳。为了解决这一挑战，我们提出了IB-Net，一种创新框架，利用图神经网络和新颖的图编码技术来建模不可满足问题，并与最先进的求解器互动。对求解器和数据集进行全面评估表明，IB-Net在工业数据上的平均运行时间加速了5.0%，在SAT竞赛数据上加快了8.3% 的速度。

    arXiv:2403.03517v1 Announce Type: new  Abstract: Boolean Satisfiability problems are vital components in Electronic Design Automation, particularly within the Logic Equivalence Checking process. Currently, SAT solvers are employed for these problems and neural network is tried as assistance to solvers. However, as SAT problems in the LEC context are distinctive due to their predominantly unsatisfiability nature and a substantial proportion of UNSAT-core variables, existing neural network assistance has proven unsuccessful in this specialized domain. To tackle this challenge, we propose IB-Net, an innovative framework utilizing graph neural networks and novel graph encoding techniques to model unsatisfiable problems and interact with state-of-the-art solvers. Extensive evaluations across solvers and datasets demonstrate IB-Net's acceleration, achieving an average runtime speedup of 5.0% on industrial data and 8.3% on SAT competition data empirically. This breakthrough advances efficient
    
[^56]: 人工智能生成文本与人工智能协作混合文本中的检测方法

    Towards Detecting AI-Generated Text within Human-AI Collaborative Hybrid Texts

    [https://arxiv.org/abs/2403.03506](https://arxiv.org/abs/2403.03506)

    本研究探索了在人工智能协作混合文本中句子级人工智能生成文本检测的挑战，并提出了一种基于分割的两步骤流程来检测各段落的一致作者句子。

    

    本研究探讨了在人工智能协作混合文本中句子级人工智能生成文本检测的挑战。现有的关于混合文本中AI生成文本检测的研究通常依赖于合成数据集，这些数据集通常涉及带有有限边界的混合文本。我们认为，检测混合文本中AI生成内容的研究应覆盖在真实环境中生成的不同类型混合文本，以更好地指导实际应用。因此，我们的研究利用了CoAuthor数据集，该数据集包括通过人类作者和智能写作系统之间的协作生成的多轮交互中产生的多样化、真实的混合文本。我们采用了两步分割为基础的流程：(i)检测给定混合文本中的各个段落，其中每个段落包含一致作者的句子，以及(ii)分类每个确定段落的作者。我们的实证

    arXiv:2403.03506v1 Announce Type: cross  Abstract: This study explores the challenge of sentence-level AI-generated text detection within human-AI collaborative hybrid texts. Existing studies of AI-generated text detection for hybrid texts often rely on synthetic datasets. These typically involve hybrid texts with a limited number of boundaries. We contend that studies of detecting AI-generated content within hybrid texts should cover different types of hybrid texts generated in realistic settings to better inform real-world applications. Therefore, our study utilizes the CoAuthor dataset, which includes diverse, realistic hybrid texts generated through the collaboration between human writers and an intelligent writing system in multi-turn interactions. We adopt a two-step, segmentation-based pipeline: (i) detect segments within a given hybrid text where each segment contains sentences of consistent authorship, and (ii) classify the authorship of each identified segment. Our empirical 
    
[^57]: DLP-GAN：使用生成对抗网络学习绘制现代中国风景照片

    DLP-GAN: Learning to Draw Modern Chinese Landscape Photos with Generative Adversarial Network

    [https://arxiv.org/abs/2403.03456](https://arxiv.org/abs/2403.03456)

    该论文提出了DLP-GAN模型，使用生成对抗网络实现了现代中国风景照片的绘制，引入了不对称循环映射和双一致性损失来平衡现实感和抽象性。

    

    中国山水画具有独特和艺术的风格，其绘画技术在色彩使用和物体的逼真表现上高度抽象。先前的方法主要集中在从现代照片转换到古代水墨画上，但很少关注将风景画转化为现代照片。为了解决这些问题，本文提出了DLP-GAN（使用生成对抗网络绘制现代中国风景照片），一个具有新颖的不对称循环映射的无监督跨域图像转换框架，并引入了基于密集融合模块的生成器来匹配不同的转换方向。此外，提出了双一致性损失以平衡模型绘画的逼真性和抽象性，使我们的模型能够以现代感绘制风景照片和素描。

    arXiv:2403.03456v1 Announce Type: cross  Abstract: Chinese landscape painting has a unique and artistic style, and its drawing technique is highly abstract in both the use of color and the realistic representation of objects. Previous methods focus on transferring from modern photos to ancient ink paintings. However, little attention has been paid to translating landscape paintings into modern photos. To solve such problems, in this paper, we (1) propose DLP-GAN (\textbf{D}raw Modern Chinese \textbf{L}andscape \textbf{P}hotos with \textbf{G}enerative \textbf{A}dversarial \textbf{N}etwork), an unsupervised cross-domain image translation framework with a novel asymmetric cycle mapping, and (2) introduce a generator based on a dense-fusion module to match different translation directions. Moreover, a dual-consistency loss is proposed to balance the realism and abstraction of model painting. In this way, our model can draw landscape photos and sketches in the modern sense. Finally, based o
    
[^58]: 使用集合卡尔曼反演进行DeepONets的不确定性量化

    Uncertainty quantification for deeponets with ensemble kalman inversion

    [https://arxiv.org/abs/2403.03444](https://arxiv.org/abs/2403.03444)

    使用集合卡尔曼反演方法针对DeepONets提出了一种高效的不确定性量化推断方法。

    

    近年来，操作员学习，特别是DeepONet，因其高效地学习跨不同领域的输入和输出函数之间的复杂映射而受到广泛关注。在有限且带噪声数据的实际场景中，访问DeepONet预测中的不确定性变得至关重要，特别是在使命关键或安全关键应用中。现有方法要么计算密集，要么产生令人不满意的不确定性量化，为DeepONets量身定制高效且信息丰富的不确定性量化（UQ）技术留下了空间。在这项工作中，我们提出了一种利用集合卡尔曼反演（EKI）方法的新型推断方法，用于操作员学习的高效UQ。EKI以其无导数、噪声抗干扰和高度可并行化的特性而闻名，已经证明了在面向物理的神经网络的UQ中的优势。

    arXiv:2403.03444v1 Announce Type: cross  Abstract: In recent years, operator learning, particularly the DeepONet, has received much attention for efficiently learning complex mappings between input and output functions across diverse fields. However, in practical scenarios with limited and noisy data, accessing the uncertainty in DeepONet predictions becomes essential, especially in mission-critical or safety-critical applications. Existing methods, either computationally intensive or yielding unsatisfactory uncertainty quantification, leave room for developing efficient and informative uncertainty quantification (UQ) techniques tailored for DeepONets. In this work, we proposed a novel inference approach for efficient UQ for operator learning by harnessing the power of the Ensemble Kalman Inversion (EKI) approach. EKI, known for its derivative-free, noise-robust, and highly parallelizable feature, has demonstrated its advantages for UQ for physics-informed neural networks [28]. Our inn
    
[^59]: 混合LoRAs：大型语言模型的高效多任务调优

    Mixture-of-LoRAs: An Efficient Multitask Tuning for Large Language Models

    [https://arxiv.org/abs/2403.03432](https://arxiv.org/abs/2403.03432)

    提出了一种新颖且参数高效的混合LoRAs（MoA）架构，通过引入领域标签和显式路由策略，解决了大型语言模型多任务学习中的灾难性遗忘和任务干扰问题，从而提升了每个任务的性能。

    

    指导调优有潜力激发或增强大型语言模型（LLMs）的特定能力。然而，实现数据的正确平衡对于防止灾难性遗忘和任务之间的干扰至关重要。为了解决这些限制并增强训练灵活性，我们提出了适用于LLMs的新颖和参数高效的调优方法——混合LoRAs（MoA）架构。在本文中，我们通过使用相应的监督语料库数据单独训练多个特定领域的LoRA模块。这些LoRA模块可以与在专家设计原则中观察到的专家混合（MoE）相一致。随后，我们利用显式路由策略组合多个LoRAs，并引入领域标签以促进多任务学习，这有助于防止任务之间的干扰，并最终提升每个个别任务的性能。

    arXiv:2403.03432v1 Announce Type: cross  Abstract: Instruction Tuning has the potential to stimulate or enhance specific capabilities of large language models (LLMs). However, achieving the right balance of data is crucial to prevent catastrophic forgetting and interference between tasks. To address these limitations and enhance training flexibility, we propose the Mixture-of-LoRAs (MoA) architecture which is a novel and parameter-efficient tuning method designed for multi-task learning with LLMs. In this paper, we start by individually training multiple domain-specific LoRA modules using corresponding supervised corpus data. These LoRA modules can be aligned with the expert design principles observed in Mixture-of-Experts (MoE). Subsequently, we combine the multiple LoRAs using an explicit routing strategy and introduce domain labels to facilitate multi-task learning, which help prevent interference between tasks and ultimately enhances the performance of each individual task. Further
    
[^60]: LEAD：学习分解用于无源通用领域自适应

    LEAD: Learning Decomposition for Source-free Universal Domain Adaptation

    [https://arxiv.org/abs/2403.03421](https://arxiv.org/abs/2403.03421)

    提出了LEAD方法，通过将特征分解为源已知和未知组件来识别目标私有数据。

    

    通用领域自适应（UniDA）旨在实现在存在协变量和标签转移的情况下进行知识转移。 最近，无源通用领域自适应（SF-UniDA）已经出现，旨在实现UniDA而无需访问源数据，这更实用由于数据保护政策。 本文提出了一个新的LEArning Decomposition（LEAD）的想法，通过将特征分解为源已知和未知组件来识别目标私有数据。

    arXiv:2403.03421v1 Announce Type: cross  Abstract: Universal Domain Adaptation (UniDA) targets knowledge transfer in the presence of both covariate and label shifts. Recently, Source-free Universal Domain Adaptation (SF-UniDA) has emerged to achieve UniDA without access to source data, which tends to be more practical due to data protection policies. The main challenge lies in determining whether covariate-shifted samples belong to target-private unknown categories. Existing methods tackle this either through hand-crafted thresholding or by developing time-consuming iterative clustering strategies. In this paper, we propose a new idea of LEArning Decomposition (LEAD), which decouples features into source-known and -unknown components to identify target-private data. Technically, LEAD initially leverages the orthogonal decomposition analysis for feature decomposition. Then, LEAD builds instance-level decision boundaries to adaptively identify target-private data. Extensive experiments a
    
[^61]: 否定否定：通过分布式反喜好优化实现对齐而无需人类正样本

    Negating Negatives: Alignment without Human Positive Samples via Distributional Dispreference Optimization

    [https://arxiv.org/abs/2403.03419](https://arxiv.org/abs/2403.03419)

    通过提出Distributional Dispreference Optimization (D$^2$O)方法，在不需要人类正样本的情况下实现了对齐，减少了有害信息的传播。

    

    大型语言模型（LLM）改变了人工智能的角色，但也可能存在传播不道德内容的潜在风险。对齐技术被引入以引导LLM朝着人类偏好方向发展，并受到越来越多的关注。尽管在这个方向上取得了显著突破，但现有方法严重依赖于高质量的正负训练对，受到嘈杂标签和首选和非首选响应数据之间的边缘区别的困扰。鉴于最近LLM在生成有用响应方面的高水平，本文将研究重点转向一个新的方向：仅使用人工注释的负样本来实现对齐，保留有用性的同时降低有害性。为此，我们提出了分布式反喜好优化（D$^2$O），通过最大化生成的响应与非首选响应之间的差异，有效地排除有害信息。我们在理论上证明

    arXiv:2403.03419v1 Announce Type: cross  Abstract: Large language models (LLMs) have revolutionized the role of AI, yet also pose potential risks of propagating unethical content. Alignment technologies have been introduced to steer LLMs towards human preference, gaining increasing attention. Despite notable breakthroughs in this direction, existing methods heavily rely on high-quality positive-negative training pairs, suffering from noisy labels and the marginal distinction between preferred and dispreferred response data. Given recent LLMs' proficiency in generating helpful responses, this work pivots towards a new research focus: achieving alignment using solely human-annotated negative samples, preserving helpfulness while reducing harmfulness. For this purpose, we propose Distributional Dispreference Optimization (D$^2$O), which maximizes the discrepancy between the generated responses and the dispreferred ones to effectively eschew harmful information. We theoretically demonstrat
    
[^62]: 稀疏脉冲神经网络：利用时间尺度的异质性来剪枝循环SNN

    Sparse Spiking Neural Network: Exploiting Heterogeneity in Timescales for Pruning Recurrent SNN

    [https://arxiv.org/abs/2403.03409](https://arxiv.org/abs/2403.03409)

    该论文提出了一种利用 Lyapunov Noise Pruning (LNP) 算法，通过随机初始化模型修剪神经元，利用神经元时间尺度的异质性设计出稀疏RSNN，实现了设计稀疏脉冲神经网络的任务-无关方法。

    

    递归脉冲神经网络（RSNNs）已经被证明是一种计算效率高且启发于大脑的学习模型。稀疏RSNNs的设计通过减少神经元和突触的数量来降低RSNNs的计算复杂度。传统上，稀疏SNNs是通过首先训练一个密集而复杂的SNN来实现的，然后在保持任务性能的同时修剪低活跃度的神经元（基于活动的剪枝）来获得的。相比之下，本文提出了一种用于设计稀疏RSNNs的与任务无关的方法，通过修剪一个大型随机初始化模型。我们介绍了一种新颖的Lyapunov噪声剪枝（LNP）算法，该算法使用图的稀疏化方法，并利用Lyapunov指数从随机初始化的RSNN设计一个稳定的稀疏RSNN。我们展示LNP可以利用神经元时间尺度的多样性来设计稀疏异质RSNN（HRSNN）。此外，我们展示了相同的稀疏HRSNN模型可以被训练。

    arXiv:2403.03409v1 Announce Type: cross  Abstract: Recurrent Spiking Neural Networks (RSNNs) have emerged as a computationally efficient and brain-inspired learning model. The design of sparse RSNNs with fewer neurons and synapses helps reduce the computational complexity of RSNNs. Traditionally, sparse SNNs are obtained by first training a dense and complex SNN for a target task, and, then, pruning neurons with low activity (activity-based pruning) while maintaining task performance. In contrast, this paper presents a task-agnostic methodology for designing sparse RSNNs by pruning a large randomly initialized model. We introduce a novel Lyapunov Noise Pruning (LNP) algorithm that uses graph sparsification methods and utilizes Lyapunov exponents to design a stable sparse RSNN from a randomly initialized RSNN. We show that the LNP can leverage diversity in neuronal timescales to design a sparse Heterogeneous RSNN (HRSNN). Further, we show that the same sparse HRSNN model can be trained 
    
[^63]: 人类对抗机器：语言模型与战争游戏

    Human vs. Machine: Language Models and Wargames

    [https://arxiv.org/abs/2403.03407](https://arxiv.org/abs/2403.03407)

    人工智能大型语言模型在战争游戏中与人类响应存在一致性，但也存在显著的差异，这表明在政策制定者交出自主权或听从基于AI的战略建议之前应谨慎对待。

    

    战争游戏在军事战略的发展和国家对威胁或攻击的响应中有着悠久的历史。人工智能（AI）的出现承诺了更好的决策制定和增强的军事效果。然而，关于AI系统，尤其是大型语言模型（LLMs），与人类的行为有何不同仍存在争议。为此，我们进行了一项战争游戏实验，共有107位国家安全专家人类参与者参与，旨在研究在一个虚构的美中情景中的危机升级，并比较人类参与者与LLM模拟响应之间的差异。我们发现LLM和人类响应存在显著一致性，但在战争游戏中模拟和人类参与者之间也存在显著的定量和定性差异，这促使决策者在交出自主权或遵循基于AI的战略建议之前谨慎对待。

    arXiv:2403.03407v1 Announce Type: cross  Abstract: Wargames have a long history in the development of military strategy and the response of nations to threats or attacks. The advent of artificial intelligence (AI) promises better decision-making and increased military effectiveness. However, there is still debate about how AI systems, especially large language models (LLMs), behave as compared to humans. To this end, we use a wargame experiment with 107 national security expert human players designed to look at crisis escalation in a fictional US-China scenario and compare human players to LLM-simulated responses. We find considerable agreement in the LLM and human responses but also significant quantitative and qualitative differences between simulated and human players in the wargame, motivating caution to policymakers before handing over autonomy or following AI-based strategy recommendations.
    
[^64]: 一种用于作物生长模型的EnKF-LSTM同化算法

    An EnKF-LSTM Assimilation Algorithm for Crop Growth Model

    [https://arxiv.org/abs/2403.03406](https://arxiv.org/abs/2403.03406)

    本文提出了一种EnKF-LSTM数据同化方法，通过结合集合卡尔曼滤波器和LSTM神经网络，提高了作物生长预测的准确性。

    

    准确及时地预测作物生长对于确保作物产量具有重要意义，研究人员开发了几种用于预测作物生长的模型。然而，作物模型得到的模拟结果与实际结果之间存在较大差异，因此本文提出将模拟结果与采集的作物数据结合进行数据同化，从而提高预测的准确性。本文提出了一种EnKF-LSTM数据同化方法，通过结合集合卡尔曼滤波器和LSTM神经网络，有效避免了现有数据同化方法的过度拟合问题，并消除了测量数据的不确定性。利用传感器设备收集的数据集对所提出的EnKF-LSTM方法进行了验证，并与其他数据同化方法进行了比较。

    arXiv:2403.03406v1 Announce Type: new  Abstract: Accurate and timely prediction of crop growth is of great significance to ensure crop yields and researchers have developed several crop models for the prediction of crop growth. However, there are large difference between the simulation results obtained by the crop models and the actual results, thus in this paper, we proposed to combine the simulation results with the collected crop data for data assimilation so that the accuracy of prediction will be improved. In this paper, an EnKF-LSTM data assimilation method for various crops is proposed by combining ensemble Kalman filter and LSTM neural network, which effectively avoids the overfitting problem of existing data assimilation methods and eliminates the uncertainty of the measured data. The verification of the proposed EnKF-LSTM method and the comparison of the proposed method with other data assimilation methods were performed using datasets collected by sensor equipment deployed o
    
[^65]: BAIT: 交互定理证明嵌入架构的基准测试

    BAIT: Benchmarking (Embedding) Architectures for Interactive Theorem-Proving

    [https://arxiv.org/abs/2403.03401](https://arxiv.org/abs/2403.03401)

    BAIT框架提供了公平且简化的ITP学习方法比较，发现Structure Aware Transformers在公式嵌入问题上表现出色。

    

    人工智能定理证明催生了大量基准测试和方法论，尤其是在交互式定理证明领域。该领域的研究分散，采用多种方法散布在几个交互式定理证明系统中。这给方法的比较带来了重大挑战，因为这些方法通常复杂且难以复制。为了解决这一问题，我们提出了BAIT，一个用于公平和简化比较ITP学习方法的框架。我们通过全面比较展示了BAIT的能力，涵盖了应用于公式嵌入问题的最先进架构在多个ITP基准测试中的表现。我们发现结构感知变压器表现特别出色，改进了与原问题集相关的技术。BAIT还允许我们评估建立在交互环境中的系统的端到端证明性能。这种统一的视角揭示

    arXiv:2403.03401v1 Announce Type: new  Abstract: Artificial Intelligence for Theorem Proving has given rise to a plethora of benchmarks and methodologies, particularly in Interactive Theorem Proving (ITP). Research in the area is fragmented, with a diverse set of approaches being spread across several ITP systems. This presents a significant challenge to the comparison of methods, which are often complex and difficult to replicate. Addressing this, we present BAIT, a framework for fair and streamlined comparison of learning approaches in ITP. We demonstrate BAIT's capabilities with an in-depth comparison, across several ITP benchmarks, of state-of-the-art architectures applied to the problem of formula embedding. We find that Structure Aware Transformers perform particularly well, improving on techniques associated with the original problem sets. BAIT also allows us to assess the end-to-end proving performance of systems built on interactive environments. This unified perspective revea
    
[^66]: 用于增强音乐家创造力的交互式旋律生成系统

    Interactive Melody Generation System for Enhancing the Creativity of Musicians

    [https://arxiv.org/abs/2403.03395](https://arxiv.org/abs/2403.03395)

    该系统通过整合多个循环神经网络模型，提供了一种类似与多位作曲家合作的体验，从而促进多样化的创造力，并通过动态适应用户创意意图来增强生成旋律的能力。

    

    本研究提出了一个系统，旨在通过使用自动音乐作曲技术，列举人类协作创作的过程。通过整合多个循环神经网络（RNN）模型，该系统提供了一种类似与多位作曲家合作的体验，从而促进多样化的创造力。通过根据反馈动态适应用户的创意意图，系统增强了生成与用户喜好和创造需求一致的旋律的能力。通过对具有不同背景的作曲家进行实验评估了系统的有效性，揭示了该系统促进音乐创造力的潜力，并提出了进一步改进的途径。该研究强调了作曲家与人工智能之间的互动的重要性，旨在使音乐创作更具可访问性和个性化。这个系统代表了将人工智能整合到创造性过程的一步。

    arXiv:2403.03395v1 Announce Type: cross  Abstract: This study proposes a system designed to enumerate the process of collaborative composition among humans, using automatic music composition technology. By integrating multiple Recurrent Neural Network (RNN) models, the system provides an experience akin to collaborating with several composers, thereby fostering diverse creativity. Through dynamic adaptation to the user's creative intentions, based on feedback, the system enhances its capability to generate melodies that align with user preferences and creative needs. The system's effectiveness was evaluated through experiments with composers of varying backgrounds, revealing its potential to facilitate musical creativity and suggesting avenues for further refinement. The study underscores the importance of interaction between the composer and AI, aiming to make music composition more accessible and personalized. This system represents a step towards integrating AI into the creative pro
    
[^67]: 多模态深度学习

    Multi-modal Deep Learning

    [https://arxiv.org/abs/2403.03385](https://arxiv.org/abs/2403.03385)

    本研究通过CCT、Patch Up和新颖的CamCenterLoss技术对临床数据处理进行创新，提高了预测准确性，对危重病人的关注更多，为未来的多模态医学研究铺平道路。

    

    本文探讨了用于单模态临床数据分析的深度学习方法，作为未来多模态医学研究的关键前提。借鉴了郭靖元的工作，通过紧凑卷积变换器（CCT）、Patch Up 和创新的 CamCenterLoss 技术对临床数据处理进行了改进，为未来的多模态研究奠定了基础。提出的方法在预测准确性和对危重病人的关注方面相对于郭靖元的 ResNet 和 StageNet 方法表现出了改进。该研究的创新之处在于利用图像预先训练的视觉变换器骨干进行时间序列临床数据的迁移学习。该研究突出了在深度学习框架中利用 CCT、Patch Up 和新颖的 CamCenterLoss 处理单一模态临床数据的潜力，为未来的多模态医学研究铺平了道路，并推动了精准和个性化医疗。

    arXiv:2403.03385v1 Announce Type: cross  Abstract: This article investigates deep learning methodologies for single-modality clinical data analysis, as a crucial precursor to multi-modal medical research. Building on Guo JingYuan's work, the study refines clinical data processing through Compact Convolutional Transformer (CCT), Patch Up, and the innovative CamCenterLoss technique, establishing a foundation for future multimodal investigations. The proposed methodology demonstrates improved prediction accuracy and at tentiveness to critically ill patients compared to Guo JingYuan's ResNet and StageNet approaches. Novelty that using image-pretrained vision transformer backbone to perform transfer learning time-series clinical data.The study highlights the potential of CCT, Patch Up, and novel CamCenterLoss in processing single modality clinical data within deep learning frameworks, paving the way for future multimodal medical research and promoting precision and personalized healthcare
    
[^68]: 自适应发现和合并用于增量式新类别发现

    Adaptive Discovering and Merging for Incremental Novel Class Discovery

    [https://arxiv.org/abs/2403.03382](https://arxiv.org/abs/2403.03382)

    提出了自适应发现和合并（ADM）范例，以在增量阶段自适应地发现新类别并将新知识集成到模型中，同时减少对原有知识的影响。

    

    一种终身学习的重要目标是以持续的方式从未标记数据中发现新类别。 中心挑战是双重的：在较少知识灾厄性遗忘的情况下发现和学习新类别。 为此，我们介绍了一种新范例，称为自适应发现和合并（ADM），以在增量阶段自适应地发现新类别，并将新知识集成到模型中而不影响原有知识。 为了自适应地发现新类别，我们将表示学习和新类别发现解耦，并使用三重比较（TC）和概率正则化（PR）来约束概率差异和多样性以实现自适应类别分配。 为了自适应地合并学习到的新知识，我们提出了一个具有基础和新分支的混合结构，名为自适应模型合并（AMM），其减少了对原有知识干扰的影响。

    arXiv:2403.03382v1 Announce Type: new  Abstract: One important desideratum of lifelong learning aims to discover novel classes from unlabelled data in a continuous manner. The central challenge is twofold: discovering and learning novel classes while mitigating the issue of catastrophic forgetting of established knowledge. To this end, we introduce a new paradigm called Adaptive Discovering and Merging (ADM) to discover novel categories adaptively in the incremental stage and integrate novel knowledge into the model without affecting the original knowledge. To discover novel classes adaptively, we decouple representation learning and novel class discovery, and use Triple Comparison (TC) and Probability Regularization (PR) to constrain the probability discrepancy and diversity for adaptive category assignment. To merge the learned novel knowledge adaptively, we propose a hybrid structure with base and novel branches named Adaptive Model Merging (AMM), which reduces the interference of t
    
[^69]: RACE-SM:基于强化学习的社交式匝道合流自主控制

    RACE-SM: Reinforcement Learning Based Autonomous Control for Social On-Ramp Merging

    [https://arxiv.org/abs/2403.03359](https://arxiv.org/abs/2403.03359)

    该论文提出了一种基于强化学习的自主控制模型，专注于并行式匝道合流，考虑了道路上其他车辆的影响，并提出了新颖的激励函数。

    

    自主并行式匝道合流在人控车辆交通中仍然是自主车辆控制中存在的问题。现有非学习型车辆控制解决方案主要依赖规则和优化，但这些方法往往面临重大挑战。最近深度强化学习的进展展现了希望，并受到了重要学术关注，然而现有的基于学习的方法对其他高速公路车辆关注不足，且经常依赖不准确的道路交通假设。此外，并行式情况很少被考虑。提出了一种新颖的学习模型，用于加速和变道决策制定，该模型明确考虑了对于车辆本身及其周围车辆（可能合作或不合作）的效用，以产生符合社会规范的行为。这种新颖的奖励函数利用社交

    arXiv:2403.03359v1 Announce Type: new  Abstract: Autonomous parallel-style on-ramp merging in human controlled traffic continues to be an existing issue for autonomous vehicle control. Existing non-learning based solutions for vehicle control rely on rules and optimization primarily. These methods have been seen to present significant challenges. Recent advancements in Deep Reinforcement Learning have shown promise and have received significant academic interest however the available learning based approaches show inadequate attention to other highway vehicles and often rely on inaccurate road traffic assumptions. In addition, the parallel-style case is rarely considered. A novel learning based model for acceleration and lane change decision making that explicitly considers the utility to both the ego vehicle and its surrounding vehicles which may be cooperative or uncooperative to produce behaviour that is socially acceptable is proposed. The novel reward function makes use of Social 
    
[^70]: 全球推广公平性的理由：关于殖民主义、人工智能和非洲健康的混合方法研究

    The Case for Globalizing Fairness: A Mixed Methods Study on Colonialism, AI, and Health in Africa

    [https://arxiv.org/abs/2403.03357](https://arxiv.org/abs/2403.03357)

    该研究探讨了全球卫生公平性，以非洲为案例研究，通过范围审查和定性研究揭示了ML技术在非洲健康领域中可能出现的不公平现象，并特别关注殖民主义作为一个重要属性。

    

    随着机器学习（ML）技术在医疗保健中的应用日益增长，人们呼吁开发技术来理解和减轻这些系统可能表现出的偏见。 公平性在为健康开发基于ML的解决方案时具有特定对非洲有重要影响，非洲已经面临全球南北之间不公平的权力失衡。 本文旨在探讨全球健康的公平性，以非洲为案例研究。我们进行范围审查，提出在非洲环境中考虑公平性的差距轴，并勾画它们可能在不同ML启用的医疗模式中产生影响的区域。 然后，我们进行了对672名一般人口研究参与者和28名专家进行的定性研究，他们关注的是与非洲有关的ML、健康和政策，以获得关于已提出的差距轴的证实性证据。 我们的分析聚焦于殖民主义作为综合的特征。

    arXiv:2403.03357v1 Announce Type: new  Abstract: With growing application of machine learning (ML) technologies in healthcare, there have been calls for developing techniques to understand and mitigate biases these systems may exhibit. Fair-ness considerations in the development of ML-based solutions for health have particular implications for Africa, which already faces inequitable power imbalances between the Global North and South.This paper seeks to explore fairness for global health, with Africa as a case study. We conduct a scoping review to propose axes of disparities for fairness consideration in the African context and delineate where they may come into play in different ML-enabled medical modalities. We then conduct qualitative research studies with 672 general population study participants and 28 experts inML, health, and policy focused on Africa to obtain corroborative evidence on the proposed axes of disparities. Our analysis focuses on colonialism as the attribute of inte
    
[^71]: 学习最大化互信息进行思维链提炼

    Learning to Maximize Mutual Information for Chain-of-Thought Distillation

    [https://arxiv.org/abs/2403.03348](https://arxiv.org/abs/2403.03348)

    通过最大化两个任务的表示特征的互信息，提出了一种解决思维链蒸馏中标签预测任务与知识集成不足问题的变分方法。

    

    知识蒸馏是将大型复杂模型的知识传递给较小模型的技术，是实现高效人工智能部署的关键一步。通过利用思维链 (CoT) 蒸馏的新方法——逐步蒸馏 (DSS)，已经展示出为较小模型赋予其较大同行的优越推理能力的潜力。在DSS中，蒸馏模型通过一个多任务学习框架同时获得生成理由和预测标签的能力。然而，DSS忽略了这两个训练任务之间的内在关系，导致CoT知识与标签预测任务的有效整合不足。为此，我们从信息瓶颈的角度研究了两个任务之间的相互关系，并将其表述为最大化两个任务的表示特征的互信息。我们提出了一种变分方法来解决这个问题。

    arXiv:2403.03348v1 Announce Type: cross  Abstract: Knowledge distillation, the technique of transferring knowledge from large, complex models to smaller ones, marks a pivotal step towards efficient AI deployment. Distilling Step-by-Step (DSS), a novel method utilizing chain-of-thought (CoT) distillation, has demonstrated promise by imbuing smaller models with the superior reasoning capabilities of their larger counterparts. In DSS, the distilled model acquires the ability to generate rationales and predict labels concurrently through a multi-task learning framework. However, DSS overlooks the intrinsic relationship between the two training tasks, leading to ineffective integration of CoT knowledge with the task of label prediction. To this end, we investigate the mutual relationship of the two tasks from Information Bottleneck perspective and formulate it as maximizing the mutual information of the representation features of the two tasks. We propose a variational approach to solve thi
    
[^72]: 学习可持续编程：基于LLM的绿色代码生成的实证研究

    Learn to Code Sustainably: An Empirical Study on LLM-based Green Code Generation

    [https://arxiv.org/abs/2403.03344](https://arxiv.org/abs/2403.03344)

    本研究提供了一个关于绿色编码实践和AI模型可持续性意识的实证研究，评估了商业AI语言模型生成的自动生成代码的可持续性。

    

    信息技术的日益广泛应用导致数据中心的能耗和碳排放占比显著增加。随着对大数据分析、数字化以及大型人工智能模型的需求增长，这些贡献有望继续增加。在软件开发中需要解决环境影响的需求导致了对绿色（可持续）编码的兴趣增加，以及对AI模型可以带来能效提升的声明。本文提供了关于绿色代码的实证研究和绿色编码实践概述，以及用于量化AI模型可持续意识的指标。在这个框架内，我们评估了自动生成代码的可持续性。本研究考虑的自动生成代码由生成式商业AI语言模型、GitHub Copilot、OpenAI ChatGPT-3和Amazon CodeWhisperer生成。

    arXiv:2403.03344v1 Announce Type: cross  Abstract: The increasing use of information technology has led to a significant share of energy consumption and carbon emissions from data centers. These contributions are expected to rise with the growing demand for big data analytics, increasing digitization, and the development of large artificial intelligence (AI) models. The need to address the environmental impact of software development has led to increased interest in green (sustainable) coding and claims that the use of AI models can lead to energy efficiency gains. Here, we provide an empirical study on green code and an overview of green coding practices, as well as metrics used to quantify the sustainability awareness of AI models. In this framework, we evaluate the sustainability of auto-generated code. The auto-generate codes considered in this study are produced by generative commercial AI language models, GitHub Copilot, OpenAI ChatGPT-3, and Amazon CodeWhisperer. Within our meth
    
[^73]: DIVERSE：通过视频评论态度分析解读互联网对美国军事的看法，一个用于立场分类的新颖基准数据集

    DIVERSE: Deciphering Internet Views on the U.S. Military Through Video Comment Stance Analysis, A Novel Benchmark Dataset for Stance Classification

    [https://arxiv.org/abs/2403.03334](https://arxiv.org/abs/2403.03334)

    本文提出了一个名为DIVERSE的数据集，其中包含超过173,000条YouTube视频评论，标注了这些评论对美国军事视频的立场，采用了一种通过人类引导、机器辅助的标注方法，使用了句子中的弱信号作为支持指标。

    

    社交媒体文本的立场检测是涉及识别在有争议主题上拥有相反观点的用户群组的下游任务的关键组成部分，如疫苗接种和争论中。具体来说，立场提供了对实体立场的指示。本文介绍了DIVERSE，这是一个包含对超过173,000个YouTube视频评论进行标注的数据集，标注了这些评论对于美国军事视频的立场。这些立场通过一种由人类引导、机器辅助的标注方法进行标注，该方法利用了句子中蕴含的语气弱信号作为支持指标，而非使用人类手动注释。这些弱信号包括仇恨言论和讽刺的存在，特定关键词的存在，文本的情感以及从两个大型语言模型中推断的立场。然后，在每个评论被注释之前，这些弱信号使用数据编程模型进行 consol

    arXiv:2403.03334v1 Announce Type: cross  Abstract: Stance detection of social media text is a key component of downstream tasks involving the identification of groups of users with opposing opinions on contested topics such as vaccination and within arguments. In particular, stance provides an indication of an opinion towards an entity. This paper introduces DIVERSE, a dataset of over 173,000 YouTube video comments annotated for their stance towards videos of the U.S. military. The stance is annotated through a human-guided, machine-assisted labeling methodology that makes use of weak signals of tone within the sentence as supporting indicators, as opposed to using manual annotations by humans. These weak signals consist of the presence of hate speech and sarcasm, the presence of specific keywords, the sentiment of the text, and the stance inference from two Large Language Models. The weak signals are then consolidated using a data programming model before each comment is annotated wit
    
[^74]: 深度配置性能学习：一项系统性调查与分类

    Deep Configuration Performance Learning: A Systematic Survey and Taxonomy

    [https://arxiv.org/abs/2403.03322](https://arxiv.org/abs/2403.03322)

    性能是可配置软件系统行为的关键属性，本文针对深度学习在可配置软件性能学习方面进行了全面的调查与分类研究。

    

    性能可以说是反映可配置软件系统行为的最关键属性。然而，随着现代软件规模和复杂性不断增加，对各种配置如何影响性能进行建模和预测成为软件维护中的主要挑战之一。因此，性能通常是在没有对软件系统有透彻了解的情况下建模的，主要依赖数据，这正好符合深度学习的目的。在这篇论文中，我们专注于深度学习在可配置软件性能学习方面进行了全面的回顾，涵盖了948篇来自六个索引服务的论文，基于此提取并分析了85篇主要论文。我们的结果总结了配置数据如何准备，深度配置性能学习模型如何构建，以及该模型如何进行评估等关键主题和统计信息。

    arXiv:2403.03322v1 Announce Type: cross  Abstract: Performance is arguably the most crucial attribute that reflects the behavior of a configurable software system. However, given the increasing scale and complexity of modern software, modeling and predicting how various configurations can impact performance becomes one of the major challenges in software maintenance. As such, performance is often modeled without having a thorough knowledge of the software system, but relying mainly on data, which fits precisely with the purpose of deep learning.   In this paper, we conduct a comprehensive review exclusively on the topic of deep learning for performance learning of configurable software, covering 948 searched papers spanning six indexing services, based on which 85 primary papers were extracted and analyzed. Our results summarize the key topics and statistics on how the configuration data is prepared; how the deep configuration performance learning model is built; how the model is evalu
    
[^75]: 两全其美：一种灵活且通用的神经符号方法用于关系分类

    Best of Both Worlds: A Pliable and Generalizable Neuro-Symbolic Approach for Relation Classification

    [https://arxiv.org/abs/2403.03305](https://arxiv.org/abs/2403.03305)

    该论文介绍了一种将基于规则的方法与深度学习技术相结合的神经符号架构，通过神经组件提升规则泛化能力，实现了两种范式的优势，且在少样本关系分类数据集上取得了优于之前最先进模型的表现

    

    本文介绍了一种新颖的神经符号架构，用于关系分类（RC），将基于规则的方法与当代深度学习技术相结合。这种方法充分发挥了两种范式的优势：基于规则的系统的适应性和神经网络的泛化能力。我们的架构由两个组件组成：一个用于透明分类的声明性基于规则的模型，以及一个通过语义文本匹配增强规则泛化能力的神经组件。值得注意的是，我们的语义匹配器仅通过合成数据在无监督领域无关方式进行训练。此外，这些组件松散耦合，允许对规则进行修改而无需重新训练语义匹配器。在我们的评估中，我们专注于两个少样本关系分类数据集：Few-Shot TACRED 和 Few-Shot 版本的 NYT29。我们展示了我们提出的方法优于先前的最先进模型

    arXiv:2403.03305v1 Announce Type: cross  Abstract: This paper introduces a novel neuro-symbolic architecture for relation classification (RC) that combines rule-based methods with contemporary deep learning techniques. This approach capitalizes on the strengths of both paradigms: the adaptability of rule-based systems and the generalization power of neural networks. Our architecture consists of two components: a declarative rule-based model for transparent classification and a neural component to enhance rule generalizability through semantic text matching. Notably, our semantic matcher is trained in an unsupervised domain-agnostic way, solely with synthetic data. Further, these components are loosely coupled, allowing for rule modifications without retraining the semantic matcher. In our evaluation, we focused on two few-shot relation classification datasets: Few-Shot TACRED and a Few-Shot version of NYT29. We show that our proposed method outperforms previous state-of-the-art models 
    
[^76]: AI Insights: 利用ChatGPT智能进行研究论文分析的案例研究

    AI Insights: A Case Study on Utilizing ChatGPT Intelligence for Research Paper Analysis

    [https://arxiv.org/abs/2403.03293](https://arxiv.org/abs/2403.03293)

    本文讨论了如何利用ChatGPT智能对研究论文进行分析，以有效撰写科学文献调查，在乳腺癌治疗这一研究课题上取得了较高准确度。

    

    本文讨论了利用Chatbot: Generative Pre-trained Transformer (ChatGPT) 3.5和4版本分析研究论文以有效撰写科学文献调查的有效性。 研究选择《人工智能在乳腺癌治疗中的应用》作为研究课题。 从三个主要出版数据库Google Scholar、Pubmed和Scopus收集了与该主题相关的研究论文。 使用ChatGPT模型识别研究论文的类别、范围和相关信息，以自动识别与乳腺癌治疗（BCT）相关的相关论文，根据范围组织论文，识别撰写调查论文的关键信息。 使用专家标注的基准数据进行的评估表明，GPT-4在识别研究论文类别方面达到77.3%的准确率，对调查论文撰写的关键信息的识别率为50%。

    arXiv:2403.03293v1 Announce Type: new  Abstract: This paper discusses the effectiveness of leveraging Chatbot: Generative Pre-trained Transformer (ChatGPT) versions 3.5 and 4 for analyzing research papers for effective writing of scientific literature surveys. The study selected the \textit{Application of Artificial Intelligence in Breast Cancer Treatment} as the research topic. Research papers related to this topic were collected from three major publication databases Google Scholar, Pubmed, and Scopus. ChatGPT models were used to identify the category, scope, and relevant information from the research papers for automatic identification of relevant papers related to Breast Cancer Treatment (BCT), organization of papers according to scope, and identification of key information for survey paper writing. Evaluations performed using ground truth data annotated using subject experts reveal, that GPT-4 achieves 77.3\% accuracy in identifying the research paper categories and 50\% of the pa
    
[^77]: 我们应该担心大型语言模型吗？通过海德格尔哲学视角阐明LLM的能力和风险的人类推理系统的结构分析

    Should We Fear Large Language Models? A Structural Analysis of the Human Reasoning System for Elucidating LLM Capabilities and Risks Through the Lens of Heidegger's Philosophy

    [https://arxiv.org/abs/2403.03288](https://arxiv.org/abs/2403.03288)

    本研究通过比较LLMs中的统计模式与海德格尔哲学概念，探讨了LLMs作为知识能力数字化对应和人类推理模拟的能力，并通过海德格尔的真理概念对人类推理进行结构性分析。

    

    在快速发展的大型语言模型（LLMs）领域，有必要彻底分析它们的能力和风险。我们研究的核心是两个创新元素。首先，是LLMs中单词关系的统计模式与马丁·海德格尔的"就绪"和"现存"概念之间的创新类比，它概括了人类与世界互动中使用的实用和科学态度。这种比较奠定了将LLMs定位为数字化对应人类知识能力的基础，揭示了它们模拟人类推理某些方面的能力。其次，通过海德格尔将真理理解为"揭示"的概念对人类推理进行结构分析。这一基础原则使我们能够绘制推理系统的输入和输出，并将推理划分为四个不同类别。

    arXiv:2403.03288v1 Announce Type: new  Abstract: In the rapidly evolving field of Large Language Models (LLMs), there is a critical need to thoroughly analyze their capabilities and risks. Central to our investigation are two novel elements. Firstly, it is the innovative parallels between the statistical patterns of word relationships within LLMs and Martin Heidegger's concepts of "ready-to-hand" and "present-at-hand," which encapsulate the utilitarian and scientific altitudes humans employ in interacting with the world. This comparison lays the groundwork for positioning LLMs as the digital counterpart to the Faculty of Verbal Knowledge, shedding light on their capacity to emulate certain facets of human reasoning. Secondly, a structural analysis of human reasoning, viewed through Heidegger's notion of truth as "unconcealment" is conducted This foundational principle enables us to map out the inputs and outputs of the reasoning system and divide reasoning into four distinct categories
    
[^78]: 使用概率电路进行可信度感知的多模态融合

    Credibility-Aware Multi-Modal Fusion Using Probabilistic Circuits

    [https://arxiv.org/abs/2403.03281](https://arxiv.org/abs/2403.03281)

    提出了一种使用概率电路进行可信度感知的多模态融合方法，在维持竞争性能的同时能够可靠推断可信度。

    

    我们考虑了针对辨别学习的迟到多模态融合问题。受到需要理解每个数据源可靠性的嘈杂的多源领域的启发，我们探讨了在多模态融合中的可信度概念。我们提出了一种使用概率电路（PCs）来结合个体模态上的预测分布的组合函数。我们还定义了一种概率度量来评估每个模态的可信度，通过PC上的推理查询。我们的实验评估表明，我们的融合方法能够可靠地推断可信度，并且与最先进技术保持竞争性能。

    arXiv:2403.03281v1 Announce Type: cross  Abstract: We consider the problem of late multi-modal fusion for discriminative learning. Motivated by noisy, multi-source domains that require understanding the reliability of each data source, we explore the notion of credibility in the context of multi-modal fusion. We propose a combination function that uses probabilistic circuits (PCs) to combine predictive distributions over individual modalities. We also define a probabilistic measure to evaluate the credibility of each modality via inference queries over the PC. Our experimental evaluation demonstrates that our fusion method can reliably infer credibility while maintaining competitive performance with the state-of-the-art.
    
[^79]: ARNN: 用于识别癫痫发作的多通道脑电图信号的注意力循环神经网络

    ARNN: Attentive Recurrent Neural Network for Multi-channel EEG Signals to Identify Epileptic Seizures

    [https://arxiv.org/abs/2403.03276](https://arxiv.org/abs/2403.03276)

    ARNN提出了一种注意力循环神经网络，用于处理多通道脑电图信号，具有线性复杂度和并行计算，结合注意力和LSTM gate的优势，并避免了它们的缺点。

    

    我们提出了一种注意力循环神经网络（ARNN），其沿着序列循环应用注意力层，并且具有与序列长度相关的线性复杂度。该模型在多通道脑电图信号上运行，而不是单通道信号，并利用并行计算。在该模型中，注意力层是一种计算单元，可以有效地应用自注意力机制和交叉注意力机制来计算一组广泛数量的状态向量和输入信号的递归函数。我们的架构在某种程度上受到了注意力层和长短期记忆（LSTM）单元的启发，并使用长短风格门，但通过多个阶段将这种典型单元扩展到多通道脑电图信号的并行化。它继承了注意力层和LSTM门的优势，同时避免了它们各自的缺点。我们通过对异质实验进行了广泛的模型有效性评估。

    arXiv:2403.03276v1 Announce Type: cross  Abstract: We proposed an Attentive Recurrent Neural Network (ARNN), which recurrently applies attention layers along a sequence and has linear complexity with respect to the sequence length. The proposed model operates on multi-channel EEG signals rather than single channel signals and leverages parallel computation. In this cell, the attention layer is a computational unit that efficiently applies self-attention and cross-attention mechanisms to compute a recurrent function over a wide number of state vectors and input signals. Our architecture is inspired in part by the attention layer and long short-term memory (LSTM) cells, and it uses long-short style gates, but it scales this typical cell up by several orders to parallelize for multi-channel EEG signals. It inherits the advantages of attention layers and LSTM gate while avoiding their respective drawbacks. We evaluated the model effectiveness through extensive experiments with heterogeneou
    
[^80]: 从噪音到信号：通过药理学启发的神经随机微分方程解密数字健康数据中的治疗效果

    From Noise to Signal: Unveiling Treatment Effects from Digital Health Data through Pharmacology-Informed Neural-SDE

    [https://arxiv.org/abs/2403.03274](https://arxiv.org/abs/2403.03274)

    通过药理学启发的神经随机微分方程模型，有效地识别数字健康数据中的治疗效果和学习因果关系，从而实现反事实能力。

    

    数字健康技术（DHT），如可穿戴设备，提供个性化、持续、实时监测患者的能力。这些技术正在为新疗法和个性化医学的发展做出贡献。从这些技术中获取洞察力需要适当的建模技术来捕捉疾病状态中的临床相关变化。这些设备产生的数据具有随机性，可能存在缺失元素，并表现出相当大的个体间变异性，因此很难使用传统的纵向建模技术进行分析。我们提出了一种能够应对这些挑战的新颖药理学启发的神经随机微分方程（SDE）模型。通过合成数据，我们演示了我们的方法在识别治疗效果和从随机数据中学习因果关系方面的有效性，从而实现反事实能力。

    arXiv:2403.03274v1 Announce Type: cross  Abstract: Digital health technologies (DHT), such as wearable devices, provide personalized, continuous, and real-time monitoring of patient. These technologies are contributing to the development of novel therapies and personalized medicine. Gaining insight from these technologies requires appropriate modeling techniques to capture clinically-relevant changes in disease state. The data generated from these devices is characterized by being stochastic in nature, may have missing elements, and exhibits considerable inter-individual variability - thereby making it difficult to analyze using traditional longitudinal modeling techniques. We present a novel pharmacology-informed neural stochastic differential equation (SDE) model capable of addressing these challenges. Using synthetic data, we demonstrate that our approach is effective in identifying treatment effects and learning causal relationships from stochastic data, thereby enabling counterfac
    
[^81]: 注意：利用硒化镉纳米颗粒在数字领域的布鲁斯特角和德鲁德模型中等离激元共振，用于假新闻吸附在不完全信息游戏中的背景

    Note: Harnessing Tellurium Nanoparticles in the Digital Realm Plasmon Resonance, in the Context of Brewster's Angle and the Drude Model for Fake News Adsorption in Incomplete Information Games

    [https://arxiv.org/abs/2403.03239](https://arxiv.org/abs/2403.03239)

    这篇论文探讨了孤子理论和等离子现象在数字健康平台中建模用户行为和参与方面的创新应用，通过引入孤子解的概念，提出了理解健康改善行为模式的新方法，同时深入研究了硒化镉纳米颗粒在吸附假新闻中的等离子特性对用户互动和参与水平的影响。

    

    这篇笔记探讨了孤子理论和等离子现象在建模数字健康平台内用户行为和参与方面的创新应用。通过引入孤子解的概念，我们提出了理解随时间稳定的健康改善行为模式的新方法。此外，我们深入探讨了硒化镉纳米颗粒及其在吸附假新闻中的等离子特性，从而影响用户互动和参与水平。通过将非线性动力学与硒化镉纳米颗粒的独特特征相结合的理论框架，我们旨在提供新的见解，以了解数字健康环境中用户参与动态。我们的分析突出了孤子理论在捕捉用户行为的复杂非线性动态方面的潜力，而等离子现象的应用为提高灵敏度和效果提供了一个有前景的途径。

    arXiv:2403.03239v1 Announce Type: cross  Abstract: This note explores the innovative application of soliton theory and plasmonic phenomena in modeling user behavior and engagement within digital health platforms. By introducing the concept of soliton solutions, we present a novel approach to understanding stable patterns of health improvement behaviors over time. Additionally, we delve into the role of tellurium nanoparticles and their plasmonic properties in adsorbing fake news, thereby influencing user interactions and engagement levels. Through a theoretical framework that combines nonlinear dynamics with the unique characteristics of tellurium nanoparticles, we aim to provide new insights into the dynamics of user engagement in digital health environments. Our analysis highlights the potential of soliton theory in capturing the complex, nonlinear dynamics of user behavior, while the application of plasmonic phenomena offers a promising avenue for enhancing the sensitivity and effec
    
[^82]: 大型语言模型在预测神经科学结果方面超越人类专家

    Large language models surpass human experts in predicting neuroscience results

    [https://arxiv.org/abs/2403.03230](https://arxiv.org/abs/2403.03230)

    大型语言模型通过整合广泛科学文献中的相关发现，能够优于人类专家预测神经科学实验结果，预示着人类与大型语言模型共同进行发现的未来。

    

    科学发现常常取决于综合几十年的研究，这一任务可能超出人类信息处理能力。大型语言模型（LLMs）提供了一个解决方案。在广泛的科学文献上训练的LLMs可能能够整合嘈杂但相关的发现，以优于人类专家来预测新颖结果。为了评估这种可能性，我们创建了BrainBench，一个前瞻性的基准，用于预测神经科学结果。我们发现LLMs在预测实验结果方面超越了专家。在神经科学文献上调整的一个LLM，BrainGPT表现得更好。与人类专家一样，当LLMs对他们的预测有信心时，他们更有可能是正确的，这预示着未来人类和LLMs将合作进行发现。我们的方法并非特定于神经科学，并且可转移到其他知识密集型事业中。

    arXiv:2403.03230v1 Announce Type: cross  Abstract: Scientific discoveries often hinge on synthesizing decades of research, a task that potentially outstrips human information processing capacities. Large language models (LLMs) offer a solution. LLMs trained on the vast scientific literature could potentially integrate noisy yet interrelated findings to forecast novel results better than human experts. To evaluate this possibility, we created BrainBench, a forward-looking benchmark for predicting neuroscience results. We find that LLMs surpass experts in predicting experimental outcomes. BrainGPT, an LLM we tuned on the neuroscience literature, performed better yet. Like human experts, when LLMs were confident in their predictions, they were more likely to be correct, which presages a future where humans and LLMs team together to make discoveries. Our approach is not neuroscience-specific and is transferable to other knowledge-intensive endeavors.
    
[^83]: 强化学习爵士即兴演奏：音乐遇上博弈论

    Reinforcement Learning Jazz Improvisation: When Music Meets Game Theory

    [https://arxiv.org/abs/2403.03224](https://arxiv.org/abs/2403.03224)

    介绍了一个新颖的数学博弈论模型用于研究爵士即兴演奏，探索不同的随机即兴策略和其在即兴演奏中的配对表现，发现最有效的策略对是逐步改变和和弦跟随强化学习。

    

    音乐的现场表演总是迷人的，即兴演奏的不可预测性是由于音乐家之间的动态关系和与观众的互动。爵士即兴演奏是一个特别值得从理论视角进一步研究的例子。本文引入了一个新颖的数学博弈论模型来研究爵士即兴演奏，为研究音乐理论和即兴演奏方法学提供了一个框架。我们使用计算建模，主要是强化学习，来探索不同的随机即兴策略及其在即兴演奏中的配对表现。我们发现，最有效的策略对是一种对最近收益作出反应的策略（逐步改变），配合强化学习策略，其仅限于给定和弦中的音符（和弦跟随强化学习）。相反，一种对伙伴的上一个音符作出反应，并试图与之和谐的策略（和谐P

    arXiv:2403.03224v1 Announce Type: cross  Abstract: Live performances of music are always charming, with the unpredictability of improvisation due to the dynamic between musicians and interactions with the audience. Jazz improvisation is a particularly noteworthy example for further investigation from a theoretical perspective. Here, we introduce a novel mathematical game theory model for jazz improvisation, providing a framework for studying music theory and improvisational methodologies. We use computational modeling, mainly reinforcement learning, to explore diverse stochastic improvisational strategies and their paired performance on improvisation. We find that the most effective strategy pair is a strategy that reacts to the most recent payoff (Stepwise Changes) with a reinforcement learning strategy limited to notes in the given chord (Chord-Following Reinforcement Learning). Conversely, a strategy that reacts to the partner's last note and attempts to harmonize with it (Harmony P
    
[^84]: 知识引导的EEG表示学习

    Knowledge-guided EEG Representation Learning

    [https://arxiv.org/abs/2403.03222](https://arxiv.org/abs/2403.03222)

    提出了一个知识引导的EEG自监督学习模型，通过使用基于状态空间的深度学习架构，实现了稳健的性能和显著的参数效率。

    

    arXiv:2403.03222v1 公告类型:跨领域 摘要:自监督学习在音频、视觉和语音等多媒体领域取得了令人瞩目的成果。由于这些情景中标记数据的稀缺性，这种范式对于生物信号领域同样重要，甚至更重要。利用大规模未标记数据来学习稳健的表示能够帮助提高生物信号上许多推断任务的性能。考虑到多媒体模态和生物信号之间固有的领域差异，为自监督学习建立的传统目标可能无法很好地转化到这一领域。因此，有必要将这些方法调整到生物信号分析中。在这项工作中，我们提出了一个基于状态空间的深度学习架构的自监督EEG模型，该模型通过提出一种新颖的知识引导的预训练目标来提供稳健的性能和显著的参数效率。

    arXiv:2403.03222v1 Announce Type: cross  Abstract: Self-supervised learning has produced impressive results in multimedia domains of audio, vision and speech. This paradigm is equally, if not more, relevant for the domain of biosignals, owing to the scarcity of labelled data in such scenarios. The ability to leverage large-scale unlabelled data to learn robust representations could help improve the performance of numerous inference tasks on biosignals. Given the inherent domain differences between multimedia modalities and biosignals, the established objectives for self-supervised learning may not translate well to this domain. Hence, there is an unmet need to adapt these methods to biosignal analysis. In this work we propose a self-supervised model for EEG, which provides robust performance and remarkable parameter efficiency by using state space-based deep learning architecture. We also propose a novel knowledge-guided pre-training objective that accounts for the idiosyncrasies of th
    
[^85]: 评估大型语言模型的文本生成SQL能力：全面评估

    Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation

    [https://arxiv.org/abs/2403.02951](https://arxiv.org/abs/2403.02951)

    大型语言模型在文本生成SQL任务中表现出色，但对于最佳提示模板和设计框架仍无共识，新数据集和评估任务有助于全面评估各种方法的表现，并提出了优化解决方案。

    

    大型语言模型（LLMs）已经成为推动文本生成SQL任务的强大工具，明显优于传统方法。然而，作为一个新兴的研究领域，对于最佳提示模板和设计框架仍然没有达成共识。

    arXiv:2403.02951v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have emerged as a powerful tool in advancing the Text-to-SQL task, significantly outperforming traditional methods. Nevertheless, as a nascent research field, there is still no consensus on the optimal prompt templates and design frameworks. Additionally, existing benchmarks inadequately explore the performance of LLMs across the various sub-tasks of the Text-to-SQL process, which hinders the assessment of LLMs' cognitive capabilities and the optimization of LLM-based solutions.To address the aforementioned issues, we firstly construct a new dataset designed to mitigate the risk of overfitting in LLMs. Then we formulate five evaluation tasks to comprehensively assess the performance of diverse methods across various LLMs throughout the Text-to-SQL process.Our study highlights the performance disparities among LLMs and proposes optimal in-context learning solutions tailored to each task. These findings offer
    
[^86]: ImgTrojan: 用一张图片对视觉-语言模型进行越狱

    ImgTrojan: Jailbreaking Vision-Language Models with ONE Image

    [https://arxiv.org/abs/2403.02910](https://arxiv.org/abs/2403.02910)

    本文提出了一种针对视觉-语言模型的新型越狱攻击，通过在训练数据中插入恶意文本提示，成功实施越狱攻击，并分析了有毒数据比率和可训练参数位置对攻击成功率的影响。

    

    近来，对于大型语言模型（LLMs）与人类价值观的对齐引起了越来越多的关注。然而，它们与视觉模块集成的安全问题，即视觉-语言模型（VLMs），仍然相对未被充分探讨。本文提出了一种针对VLMs的新型越狱攻击，旨在当用户输入有害指令时绕过其安全阻碍。假设我们的有毒（图像，文本）数据对包含在训练数据中。通过用恶意越狱提示替换原始文本标题，我们的方法可以利用有毒图像执行越狱攻击。此外，我们分析了有毒比率和可训练参数位置对攻击成功率的影响。为了评估，我们设计了两个度量标准来量化我们攻击的成功率和隐蔽性。结合一系列策划的有害指令，可以衡量攻击的有效性。

    arXiv:2403.02910v1 Announce Type: cross  Abstract: There has been an increasing interest in the alignment of large language models (LLMs) with human values. However, the safety issues of their integration with a vision module, or vision language models (VLMs), remain relatively underexplored. In this paper, we propose a novel jailbreaking attack against VLMs, aiming to bypass their safety barrier when a user inputs harmful instructions. A scenario where our poisoned (image, text) data pairs are included in the training data is assumed. By replacing the original textual captions with malicious jailbreak prompts, our method can perform jailbreak attacks with the poisoned images. Moreover, we analyze the effect of poison ratios and positions of trainable parameters on our attack's success rate. For evaluation, we design two metrics to quantify the success rate and the stealthiness of our attack. Together with a list of curated harmful instructions, a benchmark for measuring attack efficac
    
[^87]: NeuroVoz：帕金森病患者语音的卡斯蒂利亚语语料库

    NeuroVoz: a Castillian Spanish corpus of parkinsonian speech

    [https://arxiv.org/abs/2403.02371](https://arxiv.org/abs/2403.02371)

    这一研究提出了一个包含108位母语为卡斯蒂利亚语说话者的帕金森病患者语音语料库，涵盖了多种语音任务，通过手动和自动转录确保了数据的准确性和可靠性。

    

    通过语音分析进行帕金森病（PD）诊断的进展受到公开可用、多样化的语言数据集的显著缺乏的阻碍，限制了现有研究结果的可再现性和进一步探索。为了弥补这一空白，我们引入了一个全面的语料库，包括来自108位母语为卡斯蒂利亚语的说话者，包括55名健康对照组和53名被诊断患有PD的个体，所有这些个体都在药物治疗下，并且在药物优化状态下进行记录。 这一独特数据集涵盖了广泛的语音任务，包括持续发音五个西班牙元音、发音测试、16个听后重复的话语以及自由独白。该数据集通过专家手动转录听后重复任务强调准确性和可靠性，并利用Whisper进行自动独白转录，使其成为帕金森病患者语音的最完整的公开语料库。

    arXiv:2403.02371v1 Announce Type: cross  Abstract: The advancement of Parkinson's Disease (PD) diagnosis through speech analysis is hindered by a notable lack of publicly available, diverse language datasets, limiting the reproducibility and further exploration of existing research.   In response to this gap, we introduce a comprehensive corpus from 108 native Castilian Spanish speakers, comprising 55 healthy controls and 53 individuals diagnosed with PD, all of whom were under pharmacological treatment and recorded in their medication-optimized state. This unique dataset features a wide array of speech tasks, including sustained phonation of the five Spanish vowels, diadochokinetic tests, 16 listen-and-repeat utterances, and free monologues. The dataset emphasizes accuracy and reliability through specialist manual transcriptions of the listen-and-repeat tasks and utilizes Whisper for automated monologue transcriptions, making it the most complete public corpus of Parkinsonian speech, 
    
[^88]: 深度强化学习用于动态算法选择：以微分进化为例的原理研究

    Deep Reinforcement Learning for Dynamic Algorithm Selection: A Proof-of-Principle Study on Differential Evolution

    [https://arxiv.org/abs/2403.02131](https://arxiv.org/abs/2403.02131)

    本论文提出了一种基于深度强化学习的动态算法选择框架，旨在通过训练代理根据优化过程中观察到的特征选择最合适的算法，以解决单个算法有效性在不同问题实例上变化的问题。

    

    进化算法，如微分进化，在解决实数参数优化挑战方面表现出色。然而，单个算法的有效性在不同问题实例上变化，需要在算法选择或配置方面投入相当多的努力。本文旨在通过利用一组算法的互补优势，并在优化过程中为特定问题动态调度它们来解决这一限制。我们提出了一个基于深度强化学习的动态算法选择框架来完成这一任务。我们的方法将动态算法选择建模为马尔科夫决策过程，以策略梯度方式训练代理选择根据优化过程中观察到的特征选择最合适的算法。为了使代理具备必要的信息，我们的框架结合了一个经过深思熟虑的景观和算法设计。

    arXiv:2403.02131v1 Announce Type: cross  Abstract: Evolutionary algorithms, such as Differential Evolution, excel in solving real-parameter optimization challenges. However, the effectiveness of a single algorithm varies across different problem instances, necessitating considerable efforts in algorithm selection or configuration. This paper aims to address the limitation by leveraging the complementary strengths of a group of algorithms and dynamically scheduling them throughout the optimization progress for specific problems. We propose a deep reinforcement learning-based dynamic algorithm selection framework to accomplish this task. Our approach models the dynamic algorithm selection a Markov Decision Process, training an agent in a policy gradient manner to select the most suitable algorithm according to the features observed during the optimization process. To empower the agent with the necessary information, our framework incorporates a thoughtful design of landscape and algorith
    
[^89]: 位置论文：面向文本到图像模型的隐式提示

    Position Paper: Towards Implicit Prompt For Text-To-Image Models

    [https://arxiv.org/abs/2403.02118](https://arxiv.org/abs/2403.02118)

    该位置论文讨论了文本到图像模型在隐式提示方面的现状，提出了名为ImplicitBench的新基准，并对 T2I 模型在隐式提示下的表现及影响进行了调查。

    

    近期文本到图像（T2I）模型取得了巨大成功，并提出了许多基准来评估它们的性能和安全性。然而，它们只考虑了显式提示，而忽略了隐式提示（暗示目标而不明确提到）。这些提示可能消除安全约束，并对这些模型的应用构成潜在威胁。本文介绍了当下T2I模型朝着隐式提示的现状。我们提出了一个名为ImplicitBench的基准，并对流行的T2I模型在隐式提示下的性能和影响进行了调查。具体来说，我们设计并收集了三个方面的超过2,000个隐式提示：通用符号、名人隐私和不安全的问题，并评估了六个知名T2I模型在这些隐式提示下的能力。实验结果显示，（1）T2I模型能够准确地创建各种目标。

    arXiv:2403.02118v1 Announce Type: cross  Abstract: Recent text-to-image (T2I) models have had great success, and many benchmarks have been proposed to evaluate their performance and safety. However, they only consider explicit prompts while neglecting implicit prompts (hint at a target without explicitly mentioning it). These prompts may get rid of safety constraints and pose potential threats to the applications of these models. This position paper highlights the current state of T2I models toward implicit prompts. We present a benchmark named ImplicitBench and conduct an investigation on the performance and impacts of implicit prompts with popular T2I models. Specifically, we design and collect more than 2,000 implicit prompts of three aspects: General Symbols, Celebrity Privacy, and Not-Safe-For-Work (NSFW) Issues, and evaluate six well-known T2I models' capabilities under these implicit prompts. Experiment results show that (1) T2I models are able to accurately create various targe
    
[^90]: AllSpark: 利用Transformer中未标记的特征重新生成标记特征，用于半监督语义分割

    AllSpark: Reborn Labeled Features from Unlabeled in Transformer for Semi-Supervised Semantic Segmentation

    [https://arxiv.org/abs/2403.01818](https://arxiv.org/abs/2403.01818)

    AllSpark利用通道级交叉注意机制从未标记的特征中重新生成标记特征，以改善半监督语义分割中低质量伪标签的问题。

    

    半监督语义分割（SSSS）旨在减轻耗时的像素级手动标注负担，它利用有限的标记数据以及更多的未标记数据。目前最先进的方法使用基准真值训练标记数据和使用伪标签训练未标记数据。然而，这两种训练流程是分开的，这使得标记数据主导训练过程，导致低质量的伪标签和从而次优的结果。为了解决这个问题，我们提出了AllSpark，利用通道级交叉注意机制从未标记的特征中重新生成标记的特征。我们进一步引入了语义记忆和通道语义分组策略，以确保未标记特征充分代表标记特征。AllSpark为SSSS的架构级设计带来了新的视角，而非框架级别，避免了越来越常见的问题。

    arXiv:2403.01818v1 Announce Type: cross  Abstract: Semi-supervised semantic segmentation (SSSS) has been proposed to alleviate the burden of time-consuming pixel-level manual labeling, which leverages limited labeled data along with larger amounts of unlabeled data. Current state-of-the-art methods train the labeled data with ground truths and unlabeled data with pseudo labels. However, the two training flows are separate, which allows labeled data to dominate the training process, resulting in low-quality pseudo labels and, consequently, sub-optimal results. To alleviate this issue, we present AllSpark, which reborns the labeled features from unlabeled ones with the channel-wise cross-attention mechanism. We further introduce a Semantic Memory along with a Channel Semantic Grouping strategy to ensure that unlabeled features adequately represent labeled features. The AllSpark shed new light on the architecture level designs of SSSS rather than framework level, which avoids increasingly
    
[^91]: 硅谷人群的智慧：LLM集成预测能力达到人群准确率水平

    Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy

    [https://arxiv.org/abs/2402.19379](https://arxiv.org/abs/2402.19379)

    该研究通过将十二个LLMs组成的LLM集成方法与925名人类预测者的群体预测进行比较，发现LLM群体优于简单的无信息基准，并在统计上等效于人类群体。

    

    实践中人类预测准确性依赖于“群体智慧”效应，即通过聚合一群个体预测者的预测可以显著提高对未来事件的预测。过去关于大型语言模型（LLMs）预测能力的研究表明，作为个体预测者的前沿LLMs表现不佳，与人类群体预测比赛的黄金标准相比。我们通过使用一个由十二个LLMs组成的LLM集成方法，扩展了研究。我们将31个二元问题的聚合LLM预测与一个来自三个月预测比赛的925名人类预测者的群体预测进行比较。我们的主要分析表明，LLM群体的表现优于简单的无信息基准，并在统计上等效于人类群体。我们还观察到一种顺从效应，平均模型预测明显高于50%，尽管几乎是平等的。

    arXiv:2402.19379v1 Announce Type: cross  Abstract: Human forecasting accuracy in practice relies on the 'wisdom of the crowd' effect, in which predictions about future events are significantly improved by aggregating across a crowd of individual forecasters. Past work on the forecasting ability of large language models (LLMs) suggests that frontier LLMs, as individual forecasters, underperform compared to the gold standard of a human crowd forecasting tournament aggregate. In Study 1, we expand this research by using an LLM ensemble approach consisting of a crowd of twelve LLMs. We compare the aggregated LLM predictions on 31 binary questions to that of a crowd of 925 human forecasters from a three-month forecasting tournament. Our main analysis shows that the LLM crowd outperforms a simple no-information benchmark and is statistically equivalent to the human crowd. We also observe an acquiescence effect, with mean model predictions being significantly above 50%, despite an almost even
    
[^92]: 基于语言引导的状态抽象学习

    Learning with Language-Guided State Abstractions

    [https://arxiv.org/abs/2402.18759](https://arxiv.org/abs/2402.18759)

    利用自然语言和语言模型引导的方法，实现自动构建适用于未见任务的状态表示，有助于高维观测空间中泛化策略学习。

    

    我们描述了一个利用自然语言设计状态抽象用于模仿学习的框架。在高维观测空间中实现泛化策略学习的关键在于精心设计的状态表示，这可以将环境中的重要特征展现出来并隐藏不相关的特征。这些状态表示通常是手动指定的，或者是从其他繁重的标记过程中导出的。我们的方法LGA（语言引导的抽象）利用自然语言监督和语言模型的背景知识的结合自动构建适用于未见任务的状态表示。在LGA中，用户首先使用自然语言提供目标任务的（可能是不完整的）描述；接下来，一个预训练的语言模型将这个任务描述转化为掩盖不相关特征的状态抽象函数；最后，使用少量演示数据训练一个模仿策略。

    arXiv:2402.18759v1 Announce Type: cross  Abstract: We describe a framework for using natural language to design state abstractions for imitation learning. Generalizable policy learning in high-dimensional observation spaces is facilitated by well-designed state representations, which can surface important features of an environment and hide irrelevant ones. These state representations are typically manually specified, or derived from other labor-intensive labeling procedures. Our method, LGA (language-guided abstraction), uses a combination of natural language supervision and background knowledge from language models (LMs) to automatically build state representations tailored to unseen tasks. In LGA, a user first provides a (possibly incomplete) description of a target task in natural language; next, a pre-trained LM translates this task description into a state abstraction function that masks out irrelevant features; finally, an imitation policy is trained using a small number of demo
    
[^93]: 用于满足多样用户偏好的算术控制LLMs：具有多目标奖励的方向偏好对齐

    Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards

    [https://arxiv.org/abs/2402.18571](https://arxiv.org/abs/2402.18571)

    提出了方向偏好对齐（DPA）框架，通过多目标奖励模拟不同偏好配置，以实现用户相关的偏好控制。

    

    针对大型语言模型（LLMs）的精细控制仍然是一个重要挑战，阻碍了它们适应各种用户需求。本文提出了方向偏好对齐（DPA）框架，通过多目标奖励建模来表示多样化的偏好配置，将用户偏好建模为奖励空间中的方向（即单位向量）以实现用户相关的偏好控制。

    arXiv:2402.18571v1 Announce Type: cross  Abstract: Fine-grained control over large language models (LLMs) remains a significant challenge, hindering their adaptability to diverse user needs. While Reinforcement Learning from Human Feedback (RLHF) shows promise in aligning LLMs, its reliance on scalar rewards often limits its ability to capture diverse user preferences in real-world applications. To address this limitation, we introduce the Directional Preference Alignment (DPA) framework. Unlike the scalar-reward RLHF, DPA incorporates multi-objective reward modeling to represent diverse preference profiles. Additionally, DPA models user preferences as directions (i.e., unit vectors) in the reward space to achieve user-dependent preference control. Our method involves training a multi-objective reward model and then fine-tuning the LLM with a preference-conditioned variant of Rejection Sampling Finetuning (RSF), an RLHF method adopted by Llama 2. This method enjoys a better performance
    
[^94]: 关于在信息提取中利用银标准数据进行零样本分类任务的研究

    On the use of Silver Standard Data for Zero-shot Classification Tasks in Information Extraction

    [https://arxiv.org/abs/2402.18061](https://arxiv.org/abs/2402.18061)

    本研究提出了一个新框架Clean-LaVe，旨在利用银标准数据来增强零样本分类性能。

    

    在信息提取（IE）领域，监督分类方法的卓越性能严重依赖于大量的黄金标准数据。最近的零样本分类方法将任务转化为其他NLP任务（例如，文本蕴涵），并使用这些NLP任务的现成模型直接对测试数据进行推理，而无需使用大量的IE注释数据。这些方法的一个潜在有价值的副产品是大规模的银标准数据，即其他NLP任务的现成模型生成的伪标记数据。然而，对于这些数据的利用并没有进一步的研究。本文提出了一个新框架Clean-LaVe，旨在利用银标准数据来增强零样本分类性能。Clean-LaVe包括四个阶段：（1）获取银标准数据；（2）从银标准数据中识别相对干净的数据；（3）使用干净数据微调现成模型；

    arXiv:2402.18061v1 Announce Type: cross  Abstract: The superior performance of supervised classification methods in the information extraction (IE) area heavily relies on a large amount of gold standard data. Recent zero-shot classification methods converted the task to other NLP tasks (e.g., textual entailment) and used off-the-shelf models of these NLP tasks to directly perform inference on the test data without using a large amount of IE annotation data. A potentially valuable by-product of these methods is the large-scale silver standard data, i.e., pseudo-labeled data by the off-the-shelf models of other NLP tasks. However, there is no further investigation into the use of these data. In this paper, we propose a new framework, Clean-LaVe, which aims to utilize silver standard data to enhance the zero-shot performance. Clean-LaVe includes four phases: (1) Obtaining silver data; (2) Identifying relatively clean data from silver data; (3) Finetuning the off-the-shelf model using clea
    
[^95]: 结构引导的扩散模型对抗训练

    Structure-Guided Adversarial Training of Diffusion Models

    [https://arxiv.org/abs/2402.17563](https://arxiv.org/abs/2402.17563)

    SADM通过对抗训练的方式引入结构指导，使得模型能够学习每个训练批次中样本之间的流形结构。

    

    扩散模型在各种生成应用中展现出卓越的功效。为了解决现有模型主要侧重于最小化加权去噪评分匹配损失以进行数据分布建模的训练局限性，我们引入了结构引导的扩散模型对抗训练（SADM）。在这种开创性方法中，我们强迫模型在每个训练批次中学习样本之间的流形结构。

    arXiv:2402.17563v2 Announce Type: cross  Abstract: Diffusion models have demonstrated exceptional efficacy in various generative applications. While existing models focus on minimizing a weighted sum of denoising score matching losses for data distribution modeling, their training primarily emphasizes instance-level optimization, overlooking valuable structural information within each mini-batch, indicative of pair-wise relationships among samples. To address this limitation, we introduce Structure-guided Adversarial training of Diffusion Models (SADM). In this pioneering approach, we compel the model to learn manifold structures between samples in each training batch. To ensure the model captures authentic manifold structures in the data distribution, we advocate adversarial training of the diffusion generator against a novel structure discriminator in a minimax game, distinguishing real manifold structures from the generated ones. SADM substantially improves existing diffusion transf
    
[^96]: 连续时间强化学习中深度残差网络的\emph{先验估计}

    A prior Estimates for Deep Residual Network in Continuous-time Reinforcement Learning

    [https://arxiv.org/abs/2402.16899](https://arxiv.org/abs/2402.16899)

    本研究针对连续时间控制问题，提出了一种可以直接分析Bellman最优损失\emph{先验}泛化误差的方法，避免了有界性假设，并通过最大算子的分解方法实现了损失函数的转换。

    

    深度强化学习在许多大规模实际应用中表现出色。然而，现有的性能分析忽略了连续时间控制问题的独特特征，无法直接估计Bellman最优损失的泛化误差，并且需要一个有界性假设。我们的工作侧重于连续时间控制问题，并提出了一种适用于所有满足半群和Lipschitz性质的问题的方法。在该方法下，我们能够直接分析Bellman最优损失的\emph{先验}泛化误差。该方法的核心在于损失函数的两次转换。为了完成转换，我们提出了最大算子的分解方法。此外，这个分析方法不需要有界性假设。最终我们维得到了一个没有“维度诅咒”的\emph{先验}泛化误差。

    arXiv:2402.16899v1 Announce Type: cross  Abstract: Deep reinforcement learning excels in numerous large-scale practical applications. However, existing performance analyses ignores the unique characteristics of continuous-time control problems, is unable to directly estimate the generalization error of the Bellman optimal loss and require a boundedness assumption. Our work focuses on continuous-time control problems and proposes a method that is applicable to all such problems where the transition function satisfies semi-group and Lipschitz properties. Under this method, we can directly analyze the \emph{a priori} generalization error of the Bellman optimal loss. The core of this method lies in two transformations of the loss function. To complete the transformation, we propose a decomposition method for the maximum operator. Additionally, this analysis method does not require a boundedness assumption. Finally, we obtain an \emph{a priori} generalization error without the curse of dime
    
[^97]: 文本引导下的跨模态上下文扩散模型用于视觉生成与编辑

    Cross-Modal Contextualized Diffusion Models for Text-Guided Visual Generation and Editing

    [https://arxiv.org/abs/2402.16627](https://arxiv.org/abs/2402.16627)

    提出了一种新颖且通用的上下文化扩散模型（ContextDiff），通过在正向和逆向过程中融入文本条件和视觉样本之间的交互和对齐，以便在视觉生成中更准确地传达文本语义

    

    有条件的扩散模型在高保真度文本引导的视觉生成和编辑中展现出卓越的性能。然而，当前的文本引导视觉扩散模型主要集中于将文本-视觉关系独占地融入到逆过程中，往往忽略了它们在正向过程中的相关性。这种正反过程之间的不一致可能限制了在视觉合成结果中精确传达文本语义。为了解决这个问题，我们提出了一种新颖且通用的上下文化扩散模型（ContextDiff），通过将跨模态上下文包含文本条件和视觉样本之间的交互和对齐融入到正向和逆向过程中。我们将这个上下文传播到两个过程中的所有时间步，以调整它们的轨迹，从而促进跨模态条件建模。我们将我们的上下文化扩散推广到DDPMs和...

    arXiv:2402.16627v2 Announce Type: cross  Abstract: Conditional diffusion models have exhibited superior performance in high-fidelity text-guided visual generation and editing. Nevertheless, prevailing text-guided visual diffusion models primarily focus on incorporating text-visual relationships exclusively into the reverse process, often disregarding their relevance in the forward process. This inconsistency between forward and reverse processes may limit the precise conveyance of textual semantics in visual synthesis results. To address this issue, we propose a novel and general contextualized diffusion model (ContextDiff) by incorporating the cross-modal context encompassing interactions and alignments between text condition and visual sample into forward and reverse processes. We propagate this context to all timesteps in the two processes to adapt their trajectories, thereby facilitating cross-modal conditional modeling. We generalize our contextualized diffusion to both DDPMs and 
    
[^98]: 使用预计算的嵌入相似性生成几乎实时个性化信息流

    Pfeed: Generating near real-time personalized feeds using precomputed embedding similarities

    [https://arxiv.org/abs/2402.16073](https://arxiv.org/abs/2402.16073)

    使用预计算的嵌入相似性生成个性化信息流，提高了电子商务平台上的客户参与度和体验，转化率提升4.9％。

    

    在个性化推荐系统中，通常使用嵌入来编码用户动作和项目，然后在嵌入空间中进行检索，使用近似最近邻搜索。然而，这种方法可能会导致两个挑战：1）用户嵌入可能限制所捕获的兴趣多样性，2）保持它们最新需要昂贵的实时基础设施。本文提出了一种在实际工业环境中克服这些挑战的方法。该方法动态更新客户配置文件，并每两分钟组成一个信息流，利用预计算的嵌入及其各自的相似性。我们在荷兰和比利时最大的电子商务平台之一Bol上测试并部署了这种方法，该方法提高了客户参与度和体验，导致转化率显著提高了4.9％。

    arXiv:2402.16073v1 Announce Type: cross  Abstract: In personalized recommender systems, embeddings are often used to encode customer actions and items, and retrieval is then performed in the embedding space using approximate nearest neighbor search. However, this approach can lead to two challenges: 1) user embeddings can restrict the diversity of interests captured and 2) the need to keep them up-to-date requires an expensive, real-time infrastructure. In this paper, we propose a method that overcomes these challenges in a practical, industrial setting. The method dynamically updates customer profiles and composes a feed every two minutes, employing precomputed embeddings and their respective similarities. We tested and deployed this method to personalise promotional items at Bol, one of the largest e-commerce platforms of the Netherlands and Belgium. The method enhanced customer engagement and experience, leading to a significant 4.9% uplift in conversions.
    
[^99]: Brant-2：脑信号基础模型

    Brant-2: Foundation Model for Brain Signals

    [https://arxiv.org/abs/2402.10251](https://arxiv.org/abs/2402.10251)

    Brant-2是脑信号领域最大的基础模型，相比于Brant，它不仅对数据变化和建模尺度具有稳健性，还能适用于更广泛范围的脑神经数据。

    

    基础模型受益于在大量未标记数据上进行预训练，并且在少量标记数据的情况下能够在各种应用中表现出色。这种模型在分析脑信号方面特别有效，因为这一领域涵盖了众多应用场景，并且进行大规模注释是成本高昂的。在这项工作中，我们提出了脑信号领域最大的基础模型，Brant-2。与用于颅内神经信号的基础模型Brant相比，Brant-2不仅对数据变化和建模尺度表现出稳健性，而且可以应用于更广泛范围的脑神经数据。通过在大量任务上进行实验，我们展示了Brant-2对脑信号中各种应用场景的适应性。进一步分析揭示了Brant-2的可扩展性，验证了每个组件的有效性，并展示了我们模型保持的能力。

    arXiv:2402.10251v1 Announce Type: cross  Abstract: Foundational models benefit from pre-training on large amounts of unlabeled data and enable strong performance in a wide variety of applications with a small amount of labeled data. Such models can be particularly effective in analyzing brain signals, as this field encompasses numerous application scenarios, and it is costly to perform large-scale annotation. In this work, we present the largest foundation model in brain signals, Brant-2. Compared to Brant, a foundation model designed for intracranial neural signals, Brant-2 not only exhibits robustness towards data variations and modeling scales but also can be applied to a broader range of brain neural data. By experimenting on an extensive range of tasks, we demonstrate that Brant-2 is adaptive to various application scenarios in brain signals. Further analyses reveal the scalability of the Brant-2, validate each component's effectiveness, and showcase our model's ability to maintai
    
[^100]: 迭代投票的平均情况分析

    Average-Case Analysis of Iterative Voting

    [https://arxiv.org/abs/2402.08144](https://arxiv.org/abs/2402.08144)

    这项工作通过分析代理人偏好分布的平均情况，扩展了迭代投票模型的效果分析。并且区分了迭代多数制何时改善或降低渐近福利。

    

    迭代投票是社会选择中重复战略决策的自然模型，当代理可以在最终确定群体决策之前更新他们的投票时。之前的研究通过对无序文化下代理人偏好的最坏情况和平均情况表现进行分析，通过改进安纳基价格来分析迭代多数制对平衡点选出的结果福利的有效性。然而，之前的分析只研究了在代理人偏好通过无偏文化分布的最坏情况和平均情况下的性能。本研究将平均情况分析扩展到更广泛的分布类，并区分出迭代多数制何时改善或降低渐近福利。

    Iterative voting is a natural model of repeated strategic decision-making in social choice when agents have the opportunity to update their votes prior to finalizing the group decision. Prior work has analyzed the efficacy of iterative plurality on the welfare of the chosen outcome at equilibrium, relative to the truthful vote profile, via an adaptation of the price of anarchy. However, prior analyses have only studied the worst-case and average-case performances when agents' preferences are distributed by the impartial culture. This work extends average-case analyses to a wider class of distributions and distinguishes when iterative plurality improves or degrades asymptotic welfare.
    
[^101]: 物理信息神经网络逼近半线性波动方程的误差估计

    Error Estimation for Physics-informed Neural Networks Approximating Semilinear Wave Equations

    [https://arxiv.org/abs/2402.07153](https://arxiv.org/abs/2402.07153)

    本文提供了物理信息神经网络逼近半线性波动方程的严格误差界限，包括泛化误差和训练误差的界限，并在数值实验中展示了理论界限的有效性。

    

    本文对物理信息神经网络逼近半线性波动方程提供了严格的误差界限。我们针对具有两个隐藏层的tanh神经网络，基于网络层宽度和训练点数量，提供了对泛化误差和训练误差的界限。我们的主要结果是在一些假设下，将总误差以$H^1([0,T];L^2(\Omega))$-范数的形式表示，并能够随着训练点数量的增加而任意减小。我们通过数值实验验证了我们的理论界限。

    This paper provides rigorous error bounds for physics-informed neural networks approximating the semilinear wave equation. We provide bounds for the generalization and training error in terms of the width of the network's layers and the number of training points for a tanh neural network with two hidden layers. Our main result is a bound of the total error in the $H^1([0,T];L^2(\Omega))$-norm in terms of the training error and the number of training points, which can be made arbitrarily small under some assumptions. We illustrate our theoretical bounds with numerical experiments.
    
[^102]: 时间交互图上的提示学习

    Prompt Learning on Temporal Interaction Graphs

    [https://arxiv.org/abs/2402.06326](https://arxiv.org/abs/2402.06326)

    这个论文提出了一种在时间交互图上进行提示学习的方法，以解决当前模型在预训练和下游预测阶段所面临的时间差异和语义差异的问题。

    

    时间交互图(TIGs)被广泛用于表示真实世界系统。为了促进在TIGs上的表示学习，研究人员提出了一系列的TIG模型。然而，这些模型在“预训练，预测”训练范式中依然面临着两个难题。首先，预训练和推理数据之间的时间差异严重削弱了模型在动态演化数据上进行遥远未来预测的适用性。其次，预文本任务和下游任务之间的语义差异阻碍了它们在实际应用中的使用，因为它们在应用场景中很难对齐其学习和预测能力。

    Temporal Interaction Graphs (TIGs) are widely utilized to represent real-world systems. To facilitate representation learning on TIGs, researchers have proposed a series of TIG models. However, these models are still facing two tough gaps between the pre-training and downstream predictions in their ``pre-train, predict'' training paradigm. First, the temporal discrepancy between the pre-training and inference data severely undermines the models' applicability in distant future predictions on the dynamically evolving data. Second, the semantic divergence between pretext and downstream tasks hinders their practical applications, as they struggle to align with their learning and prediction capabilities across application scenarios.   Recently, the ``pre-train, prompt'' paradigm has emerged as a lightweight mechanism for model generalization. Applying this paradigm is a potential solution to solve the aforementioned challenges. However, the adaptation of this paradigm to TIGs is not straig
    
[^103]: 《读玩游戏（R2-Play）: 多模态游戏指导下的决策 Transformer》

    Read to Play (R2-Play): Decision Transformer with Multimodal Game Instruction

    [https://arxiv.org/abs/2402.04154](https://arxiv.org/abs/2402.04154)

    本论文探索了为智能体提供增强形式的任务指导，使其能够理解游戏指导并实现"读玩游戏"的能力。通过将多模态指导调优的成功应用于视觉任务中的强化学习任务，构建了一组... (内容太长，无法继续显示)

    

    在人工智能领域，开发一款通用智能体一直是一个长期的目标。先前的研究利用来自各种任务的大量离线数据集，在强化学习的多任务场景中表现出了出色的性能。然而，这些工作在扩展到新任务方面面临挑战。最近的方法将文本指导或视觉轨迹整合到决策网络中，提供任务特定的上下文提示，代表了一个有前途的方向。然而，观察到仅依赖于文本指导或视觉轨迹对于准确传达任务的上下文信息是不足够的。本文探索了增强智能体任务指导的形式，使其能够理解游戏指导，从而实现"读玩游戏"的能力。受到多模态指导调优在视觉任务中的成功启发，我们将基于视觉的强化学习任务视为一个长期视觉任务，并构建了一组... (内容太长，无法继续显示)

    Developing a generalist agent is a longstanding objective in artificial intelligence. Previous efforts utilizing extensive offline datasets from various tasks demonstrate remarkable performance in multitasking scenarios within Reinforcement Learning.However, these works encounter challenges in extending their capabilities to new tasks.Recent approaches integrate textual guidance or visual trajectory into decision networks to provide task-specific contextual cues, representing a promising direction.However, it is observed that relying solely on textual guidance or visual trajectory is insufficient for accurately conveying the contextual information of tasks.This paper explores enhanced forms of task guidance for agents, enabling them to comprehend gameplay instructions, thereby facilitating a "read-to-play" capability.Drawing inspiration from the success of multimodal instruction tuning in visual tasks, we treat the visual-based RL task as a long-horizon vision task and construct a set 
    
[^104]: 将认知任务整合到大型模型的人工通用智能测试中

    Integration of cognitive tasks into artificial general intelligence test for large models

    [https://arxiv.org/abs/2402.02547](https://arxiv.org/abs/2402.02547)

    建议将认知任务整合到大型模型的人工通用智能测试中，以建立一个综合框架，能够评估大型模型的多维智能。这个框架结合了认知科学和自然语言处理，包含了稳态智力、流态智力和社交智能等方面。

    

    在大型模型的发展过程中，必须对中间模型进行性能评估以评估其能力，并对经过充分训练的模型进行安全性评估，以确保在实际应用之前的安全性。然而，当前的模型评估主要依赖于特定任务和数据集，缺乏对大型模型的多维智能评估的统一框架。在这个视角中，我们提倡建立一个人工通用智能测试的综合框架，旨在满足大型语言模型和多模态大型模型的测试需求，以提高其能力。该人工通用智能测试框架将认知科学和自然语言处理联系起来，包括智力的各个方面，包括稳态智力，即积累的知识和经验的反映; 流态智力，特点是解决问题和适应性推理; 社交智能，表示在多方面理解和适应的能力。

    During the evolution of large models, performance evaluation is necessarily performed on the intermediate models to assess their capabilities, and on the well-trained model to ensure safety before practical application. However, current model evaluations mainly rely on specific tasks and datasets, lacking a united framework for assessing the multidimensional intelligence of large models. In this perspective, we advocate for a comprehensive framework of artificial general intelligence (AGI) test, aimed at fulfilling the testing needs of large language models and multi-modal large models with enhanced capabilities. The AGI test framework bridges cognitive science and natural language processing to encompass the full spectrum of intelligence facets, including crystallized intelligence, a reflection of amassed knowledge and experience; fluid intelligence, characterized by problem-solving and adaptive reasoning; social intelligence, signifying comprehension and adaptation within multifacete
    
[^105]: MedLM: 探索用于医疗问答系统的语言模型

    MedLM: Exploring Language Models for Medical Question Answering Systems

    [https://arxiv.org/abs/2401.11389](https://arxiv.org/abs/2401.11389)

    本研究比较了用于医疗问答的通用和医学特定的精炼语言模型的表现，以填补领域特定任务中这些模型性能的研究空白。

    

    面对迅速扩大的在线医学文献，自动化系统用于聚合和总结信息对于医疗保健专业人员和患者变得日益关键。大型语言模型（LLM）以其先进的生成能力在各种自然语言处理任务中显示出潜力，它们在医疗领域的潜力，特别是在封闭式生成问答方面，是显著的。然而，这些模型在医学问答等领域特定任务中的性能仍然较少被探索。本研究旨在通过比较通用和专门用于医学的精炼语言模型在医疗问答中的表现来填补这一空白。我们旨在评估微调领域特定语言模型的效果，并比较不同类型语言模型的性能。本研究将探讨这些模型的可靠性、比较性能和在医疗问答背景下的有效性等关键问题。

    arXiv:2401.11389v2 Announce Type: replace-cross  Abstract: In the face of rapidly expanding online medical literature, automated systems for aggregating and summarizing information are becoming increasingly crucial for healthcare professionals and patients. Large Language Models (LLMs), with their advanced generative capabilities, have shown promise in various NLP tasks, and their potential in the healthcare domain, particularly for Closed-Book Generative QnA, is significant. However, the performance of these models in domain-specific tasks such as medical Q&A remains largely unexplored. This study aims to fill this gap by comparing the performance of general and medical-specific distilled LMs for medical Q&A. We aim to evaluate the effectiveness of fine-tuning domain-specific LMs and compare the performance of different families of Language Models. The study will address critical questions about these models' reliability, comparative performance, and effectiveness in the context of me
    
[^106]: SceneVerse：为基于场景的场景理解扩展3D视觉-语言学习

    SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene Understanding

    [https://arxiv.org/abs/2401.09340](https://arxiv.org/abs/2401.09340)

    本研究通过系统性地扩展室内环境中的3D视觉-语言学习，提出了首个百万规模的3D视觉-语言数据集SceneVerse，以解决3D视觉-语言对齐面临的几个重要挑战。

    

    3D视觉-语言对齐，即将语言与3D物理环境对齐，是发展具身体能力的智能体的基石。与2D领域最近的进展相比，将语言与3D场景对齐面临着几个重要挑战：（i）3D场景固有复杂性，由于多样的物体配置、丰富的属性和错综复杂的关系；（ii）支持基于场景学习的配对3D视觉-语言数据的稀缺性；以及（iii）缺乏从基于场景的3D数据中提炼知识的统一学习框架。在这项工作中，我们旨在通过系统地扩展室内环境中的3D视觉-语言学习，从而解决3D视觉-语言领域中的这三大挑战。我们介绍首个百万规模的3D视觉-语言数据集SceneVerse，包含约68K个3D室内场景，包括250万个视觉语言

    arXiv:2401.09340v2 Announce Type: replace-cross  Abstract: 3D vision-language grounding, which focuses on aligning language with the 3D physical environment, stands as a cornerstone in the development of embodied agents. In comparison to recent advancements in the 2D domain, grounding language in 3D scenes faces several significant challenges: (i) the inherent complexity of 3D scenes due to the diverse object configurations, their rich attributes, and intricate relationships; (ii) the scarcity of paired 3D vision-language data to support grounded learning; and (iii) the absence of a unified learning framework to distill knowledge from grounded 3D data. In this work, we aim to address these three major challenges in 3D vision-language by examining the potential of systematically upscaling 3D vision-language learning in indoor environments. We introduce the first million-scale 3D vision-language dataset, SceneVerse, encompassing about 68K 3D indoor scenes and comprising 2.5M vision-langu
    
[^107]: 无监督学习下理解深度神经网络中概念的分布表示

    Understanding Distributed Representations of Concepts in Deep Neural Networks without Supervision

    [https://arxiv.org/abs/2312.17285](https://arxiv.org/abs/2312.17285)

    本文提出了一种无监督方法，通过选择主要神经元来发现概念的分布表示，可以用于识别数据中的未标记子类和检测误分类的原因。

    

    理解深度学习分类器学习的概念的中间表示对解释模型的一般行为至关重要。现有揭示学习概念的方法通常依赖于人类监督，例如预定义的概念集或分割过程。本文提出了一种新颖的无监督方法，通过选择主要子集的神经元来发现概念的分布表示。我们的实证结果表明，具有类似神经元激活状态的实例往往共享一致的概念。根据观察，所提出的方法选择构建可解释区域的主要神经元，即涵盖特征空间中具有一致概念的实例的放松决策区域（RDR）。它可用于识别数据中的未标记子类并检测误分类的原因。此外，我们的方法可应用于

    arXiv:2312.17285v2 Announce Type: replace-cross  Abstract: Understanding intermediate representations of the concepts learned by deep learning classifiers is indispensable for interpreting general model behaviors. Existing approaches to reveal learned concepts often rely on human supervision, such as pre-defined concept sets or segmentation processes. In this paper, we propose a novel unsupervised method for discovering distributed representations of concepts by selecting a principal subset of neurons. Our empirical findings demonstrate that instances with similar neuron activation states tend to share coherent concepts. Based on the observations, the proposed method selects principal neurons that construct an interpretable region, namely a Relaxed Decision Region (RDR), encompassing instances with coherent concepts in the feature space. It can be utilized to identify unlabeled subclasses within data and to detect the causes of misclassifications. Furthermore, the applicability of our 
    
[^108]: 在大型语言模型上进行间接提示注入攻击的基准测试和防御

    Benchmarking and Defending Against Indirect Prompt Injection Attacks on Large Language Models

    [https://arxiv.org/abs/2312.14197](https://arxiv.org/abs/2312.14197)

    该研究引入了第一个间接提示注入攻击基准测试BIPIA，对大型语言模型在面对此类攻击时的风险进行评估，并分析了攻击成功的原因，从而开发了防御方法。

    

    大型语言模型（LLMs）与外部内容的整合已经实现了LLMs的更新和广泛应用，比如微软Copilot。然而，这种整合也让LLMs面临了间接提示注入攻击的风险，攻击者可以在外部内容中嵌入恶意指令，从而ompromising LLM输出并导致响应偏离用户期望。为了研究这个重要但未被充分探讨的问题，我们引入了第一个间接提示注入攻击基准测试BIPIA，以评估这类攻击的风险。基于评估，我们的工作重点分析了该攻击成功的潜在原因，即LLMs无法区分指令和外部内容以及缺乏意识不执行外部内容内的指令。基于这一分析，我们开发了两种黑盒方法。

    arXiv:2312.14197v2 Announce Type: replace-cross  Abstract: The integration of large language models (LLMs) with external content has enabled more up-to-date and wide-ranging applications of LLMs, such as Microsoft Copilot. However, this integration has also exposed LLMs to the risk of indirect prompt injection attacks, where an attacker can embed malicious instructions within external content, compromising LLM output and causing responses to deviate from user expectations. To investigate this important but underexplored issue, we introduce the first benchmark for indirect prompt injection attacks, named BIPIA, to evaluate the risk of such attacks. Based on the evaluation, our work makes a key analysis of the underlying reason for the success of the attack, namely the inability of LLMs to distinguish between instructions and external content and the absence of LLMs' awareness to not execute instructions within external content. Building upon this analysis, we develop two black-box metho
    
[^109]: 参数化投影贝尔曼算子

    Parameterized Projected Bellman Operator

    [https://arxiv.org/abs/2312.12869](https://arxiv.org/abs/2312.12869)

    本论文提出了一种基于学习的近似贝尔曼算子的新方法，以解决近似值迭代算法中样本不确定性和计算复杂度的问题。

    

    近似值迭代（AVI）是一类用于强化学习（RL）的算法家族，旨在获得最优值函数的近似。通常，AVI算法采用迭代过程，每个步骤包括（i）贝尔曼算子的应用和（ii）投影步骤到考虑的函数空间中。众所周知，贝尔曼算子利用转移样本，这些样本强烈影响其行为，因为无信息的样本可能导致可忽略的更新或长时间的绕行，而计算密集的投影步骤进一步加剧了这些不利影响。为了解决这些问题，我们提出了一种新颖的替代方法，该方法采用学习的方式得到贝尔曼算子的近似版本，而不是像AVI方法那样通过样本进行估计。通过这种方式，我们能够（i）在转移样本之间进行泛化，（ii）避免计算密集的投影步骤。因此，我们称我们的新算子为"projec"算子。

    Approximate value iteration (AVI) is a family of algorithms for reinforcement learning (RL) that aims to obtain an approximation of the optimal value function. Generally, AVI algorithms implement an iterated procedure where each step consists of (i) an application of the Bellman operator and (ii) a projection step into a considered function space. Notoriously, the Bellman operator leverages transition samples, which strongly determine its behavior, as uninformative samples can result in negligible updates or long detours, whose detrimental effects are further exacerbated by the computationally intensive projection step. To address these issues, we propose a novel alternative approach based on learning an approximate version of the Bellman operator rather than estimating it through samples as in AVI approaches. This way, we are able to (i) generalize across transition samples and (ii) avoid the computationally intensive projection step. For this reason, we call our novel operator projec
    
[^110]: 基于变分量子算法的新型图像分类框架

    A Novel Image Classification Framework Based on Variational Quantum Algorithms

    [https://arxiv.org/abs/2312.07932](https://arxiv.org/abs/2312.07932)

    这项研究提出了一种基于变分量子算法的新型图像分类框架，通过消除全局池化操作，保留了更多图像的判别特征和细节，从而增强了分类性能。

    

    图像分类在机器学习中是一项至关重要的任务，具有广泛的实际应用。现有的图像分类传统框架通常在网络末端使用全局池化操作来减少计算复杂性并减轻过拟合。然而，该操作通常导致信息严重丢失，影响分类模型的性能。为了克服这一局限性，我们引入了一种新型图像分类框架，利用了变分量子算法（VQAs）- 在量子机器学习中结合了量子和经典计算范式的混合方法。我们框架的主要优势在于消除了网络末端的全局池化操作的需求。通过这种方式，我们的方法保留了图像中更多的判别特征和细粒度细节，从而提升了分类性能。

    arXiv:2312.07932v2 Announce Type: replace-cross  Abstract: Image classification is a crucial task in machine learning with widespread practical applications. The existing classical framework for image classification typically utilizes a global pooling operation at the end of the network to reduce computational complexity and mitigate overfitting. However, this operation often results in a significant loss of information, which can affect the performance of classification models. To overcome this limitation, we introduce a novel image classification framework that leverages variational quantum algorithms (VQAs)-hybrid approaches combining quantum and classical computing paradigms within quantum machine learning. The major advantage of our framework is the elimination of the need for the global pooling operation at the end of the network. In this way, our approach preserves more discriminative features and fine-grained details in the images, which enhances classification performance. Add
    
[^111]: 可穿戴生物信号基础模型的大规模训练

    Large-scale Training of Foundation Models for Wearable Biosignals

    [https://arxiv.org/abs/2312.05409](https://arxiv.org/abs/2312.05409)

    利用自监督学习和大规模可穿戴设备数据，本研究训练了基础模型用于衡量光电容积描记（PPG）和心电图信号，以解决医学数据集规模较小的难题。

    

    跟踪生物信号对于监测健康状况并预防严重医学状况的发展至关重要。如今，可穿戴设备可以方便地记录各种生物信号，从而有机会在不干扰日常生活的情况下监测健康状况。虽然可穿戴设备被广泛使用且存在数字生物标志物，但缺乏带有注释医学标签的筛选数据，阻碍了开发衡量常见健康状况的新生物标志物。事实上，与其他领域相比，医学数据集通常较小，这是开发生物信号神经网络模型的障碍。为解决这一挑战，我们利用在知情同意下从大规模纵向Apple心脏和运动研究（AHMS）中收集的未标记传感器数据，采用自监督学习，为两种常见生物信号（光电容积描记（PPG）和心电图）

    arXiv:2312.05409v2 Announce Type: replace-cross  Abstract: Tracking biosignals is crucial for monitoring wellness and preempting the development of severe medical conditions. Today, wearable devices can conveniently record various biosignals, creating the opportunity to monitor health status without disruption to one's daily routine. Despite widespread use of wearable devices and existing digital biomarkers, the absence of curated data with annotated medical labels hinders the development of new biomarkers to measure common health conditions. In fact, medical datasets are usually small in comparison to other domains, which is an obstacle for developing neural network models for biosignals. To address this challenge, we have employed self-supervised learning using the unlabeled sensor data collected under informed consent from the large longitudinal Apple Heart and Movement Study (AHMS) to train foundation models for two common biosignals: photoplethysmography (PPG) and electrocardiogra
    
[^112]: 通过公平映射实现公平文本到图像扩散

    Fair Text-to-Image Diffusion via Fair Mapping

    [https://arxiv.org/abs/2311.17695](https://arxiv.org/abs/2311.17695)

    本文提出了一种通过Fair Mapping控制模型提示来修改文本到图像扩散模型，实现公平图像生成的方法，具有高效性和能够生成相对平衡人口统计结果的优势。

    

    在本文中，我们解决了现有文本到图像扩散模型在生成与人类相关描述时出现人口统计上公平结果的局限性。这些模型经常难以将目标语言环境与社会文化偏见分离开，导致生成偏见图像。为了克服这一挑战，我们提出了一种灵活、与模型无关且轻量级的方法Fair Mapping，通过控制提示来修改预训练的文本到图像扩散模型，从而实现公平图像生成。我们方法的一个关键优势在于其高效性。它只需要以低计算成本更新少量参数的额外线性网络。通过开发一个将条件嵌入映射到去偏空间的线性网络，我们能够根据指定的文本条件生成相对平衡的人口统计结果。

    arXiv:2311.17695v2 Announce Type: replace-cross  Abstract: In this paper, we address the limitations of existing text-to-image diffusion models in generating demographically fair results when given human-related descriptions. These models often struggle to disentangle the target language context from sociocultural biases, resulting in biased image generation. To overcome this challenge, we propose Fair Mapping, a flexible, model-agnostic, and lightweight approach that modifies a pre-trained text-to-image diffusion model by controlling the prompt to achieve fair image generation. One key advantage of our approach is its high efficiency. It only requires updating an additional linear network with few parameters at a low computational cost. By developing a linear network that maps conditioning embeddings into a debiased space, we enable the generation of relatively balanced demographic results based on the specified text condition. With comprehensive experiments on face image generation, 
    
[^113]: 针对时空偏移的自监督去混淆：理论与建模

    Self-Supervised Deconfounding Against Spatio-Temporal Shifts: Theory and Modeling

    [https://arxiv.org/abs/2311.12472](https://arxiv.org/abs/2311.12472)

    该论文针对时空数据中常见的分布变化问题提出了一种自监督去混淆方法并提出了名为DCA的理论解决方案。

    

    作为时空（ST）数据的重要应用，ST交通预测在提高城市出行效率和促进可持续发展中起着至关重要的作用。本文首先通过构建过去交通数据、未来交通数据和外部ST上下文的因果图，系统地阐明了过去艺术作品在OOD交通数据上的失败是由于ST上下文充当了混淆因素，即过去数据和未来数据的共同原因。然后，我们从因果角度提出了一种理论解决方案，称为Disentangled Contextual Adjustment（DCA）。

    arXiv:2311.12472v2 Announce Type: replace  Abstract: As an important application of spatio-temporal (ST) data, ST traffic forecasting plays a crucial role in improving urban travel efficiency and promoting sustainable development. In practice, the dynamics of traffic data frequently undergo distributional shifts attributed to external factors such as time evolution and spatial differences. This entails forecasting models to handle the out-of-distribution (OOD) issue where test data is distributed differently from training data. In this work, we first formalize the problem by constructing a causal graph of past traffic data, future traffic data, and external ST contexts. We reveal that the failure of prior arts in OOD traffic data is due to ST contexts acting as a confounder, i.e., the common cause for past data and future ones. Then, we propose a theoretical solution named Disentangled Contextual Adjustment (DCA) from a causal lens. It differentiates invariant causal correlations again
    
[^114]: 从耦合振荡器到图神经网络：基于Kuramoto模型的方法减轻过度平滑现象

    From Coupled Oscillators to Graph Neural Networks: Reducing Over-smoothing via a Kuramoto Model-based Approach

    [https://arxiv.org/abs/2311.03260](https://arxiv.org/abs/2311.03260)

    提出了一种新型的连续深度图神经网络KuramotoGNN，通过采用Kuramoto模型来减轻GNN中的过度平滑现象，实现节点特征的差异化，取得了优于基线GNN和现有方法的实验效果。

    

    我们提出了Kuramoto图神经网络（KuramotoGNN），一种新颖的连续深度图神经网络（GNN），它采用Kuramoto模型来缓解过度平滑现象，即随着层数增加，GNN中节点特征变得难以区分的问题。Kuramoto模型捕捉了非线性耦合振荡器的同步行为。从耦合振荡器的视角，我们首先展示了Kuramoto模型与基本GNN之间的联系，然后说明了GNN中的过度平滑现象可以被解释为Kuramoto模型中的相位同步。KuramotoGNN用频率同步取代了这种相位同步，以防止节点特征收敛到一起，同时使系统达到稳定的同步状态。我们在各种实验中验证了KuramotoGNN在减少过度平滑方面相对于基线GNN和现有方法的优势。

    arXiv:2311.03260v2 Announce Type: replace-cross  Abstract: We propose the Kuramoto Graph Neural Network (KuramotoGNN), a novel class of continuous-depth graph neural networks (GNNs) that employs the Kuramoto model to mitigate the over-smoothing phenomenon, in which node features in GNNs become indistinguishable as the number of layers increases. The Kuramoto model captures the synchronization behavior of non-linear coupled oscillators. Under the view of coupled oscillators, we first show the connection between Kuramoto model and basic GNN and then over-smoothing phenomenon in GNNs can be interpreted as phase synchronization in Kuramoto model. The KuramotoGNN replaces this phase synchronization with frequency synchronization to prevent the node features from converging into each other while allowing the system to reach a stable synchronized state. We experimentally verify the advantages of the KuramotoGNN over the baseline GNNs and existing methods in reducing over-smoothing on various 
    
[^115]: 改进潜在扩散模型的对抗攻击

    Improving Adversarial Attacks on Latent Diffusion Model

    [https://arxiv.org/abs/2310.04687](https://arxiv.org/abs/2310.04687)

    提出了一种改进 Latent Diffusion Model 的对抗攻击方法 ACE，其通过统一模式的额外误差来促使模型学习特定的偏差，从而胜过了目前最先进的方法

    

    对 Latent Diffusion Model (LDM)，这种最先进的图像生成模型，进行对抗攻击已经被证明是有效防止 LDM 在未经授权的图像上进行恶意微调的保护手段。我们展示了这些攻击会对 LDM 预测的对抗样本的评分函数添加额外的误差。在这些对抗样本上进行微调的 LDM 学习通过一个偏差降低误差，从而遭受攻击并使用偏差预测评分函数。基于这一动态，我们提出了通过一致得分函数错误进行攻击（ACE）来改进 LDM 的对抗攻击。ACE 统一了添加到预测得分函数的额外误差的模式。这促使微调的 LDM 学习与对评分函数进行预测的偏差学习相同的模式。然后我们引入一个精心设计的模式来改进攻击。我们的方法在对 LDM 的对抗攻击中胜过了最先进的方法。

    arXiv:2310.04687v3 Announce Type: replace-cross  Abstract: Adversarial attacks on Latent Diffusion Model (LDM), the state-of-the-art image generative model, have been adopted as effective protection against malicious finetuning of LDM on unauthorized images. We show that these attacks add an extra error to the score function of adversarial examples predicted by LDM. LDM finetuned on these adversarial examples learns to lower the error by a bias, from which the model is attacked and predicts the score function with biases.   Based on the dynamics, we propose to improve the adversarial attack on LDM by Attacking with Consistent score-function Errors (ACE). ACE unifies the pattern of the extra error added to the predicted score function. This induces the finetuned LDM to learn the same pattern as a bias in predicting the score function. We then introduce a well-crafted pattern to improve the attack. Our method outperforms state-of-the-art methods in adversarial attacks on LDM.
    
[^116]: AI-Dentify: 深度学习用于近邻牙龈龋齿在全景X光上的检测--HUNT4口腔健康研究

    AI-Dentify: Deep learning for proximal caries detection on bitewing x-ray -- HUNT4 Oral Health Study

    [https://arxiv.org/abs/2310.00354](https://arxiv.org/abs/2310.00354)

    通过深度学习模型，研究展示了对HUNT4口腔健康研究中全景X光图像进行快速准确齿龈龋齿检测的潜力

    

    背景：牙齿龋坏的诊断需要对患者的诊断性全景X光图像进行手动检查，然后通过视觉检查和触诊识别具有潜在病变的牙齿。然而，人工智能的使用，特别是深度学习，有望通过提供快速和信息丰富的全景X光图像分析来帮助诊断。

    arXiv:2310.00354v2 Announce Type: replace-cross  Abstract: Background: Dental caries diagnosis requires the manual inspection of diagnostic bitewing images of the patient, followed by a visual inspection and probing of the identified dental pieces with potential lesions. Yet the use of artificial intelligence, and in particular deep-learning, has the potential to aid in the diagnosis by providing a quick and informative analysis of the bitewing images.   Methods: A dataset of 13,887 bitewings from the HUNT4 Oral Health Study were annotated individually by six different experts, and used to train three different object detection deep-learning architectures: RetinaNet (ResNet50), YOLOv5 (M size), and EfficientDet (D0 and D1 sizes). A consensus dataset of 197 images, annotated jointly by the same six dentist, was used for evaluation. A five-fold cross validation scheme was used to evaluate the performance of the AI models.   Results: he trained models show an increase in average precision
    
[^117]: 具有闭环个性化课程的连续驾驶政策优化

    Continual Driving Policy Optimization with Closed-Loop Individualized Curricula

    [https://arxiv.org/abs/2309.14209](https://arxiv.org/abs/2309.14209)

    开发了连续驾驶政策优化框架，提出了闭环个性化课程（CLIC）概念，允许重复利用广泛场景来迭代改进自主驾驶车辆模型。

    

    自主驾驶车辆（AV）的安全一直是一个长期的头等关注点，根源于长尾自然驾驶分布中罕见的安全关键场景的缺失。为了解决这一挑战，出现了大量基于场景的自动驾驶研究，重点是生成高风险驾驶场景并将它们应用于对AV模型进行安全关键测试。然而，有限的工作探讨了重复利用这些广泛场景来迭代改进AV模型。此外，从具有不同行为的其他AV模型收集的巨大场景库中滤出可传递信息以改进当前AV仍然是难以解决的且具有挑战性。因此，我们开发了一个具有闭环个性化课程（CLIC）特点的连续驾驶政策优化框架，我们将其分解为一组标准化的子模块。

    arXiv:2309.14209v3 Announce Type: replace-cross  Abstract: The safety of autonomous vehicles (AV) has been a long-standing top concern, stemming from the absence of rare and safety-critical scenarios in the long-tail naturalistic driving distribution. To tackle this challenge, a surge of research in scenario-based autonomous driving has emerged, with a focus on generating high-risk driving scenarios and applying them to conduct safety-critical testing of AV models. However, limited work has been explored on the reuse of these extensive scenarios to iteratively improve AV models. Moreover, it remains intractable and challenging to filter through gigantic scenario libraries collected from other AV models with distinct behaviors, attempting to extract transferable information for current AV improvement. Therefore, we develop a continual driving policy optimization framework featuring Closed-Loop Individualized Curricula (CLIC), which we factorize into a set of standardized sub-modules for
    
[^118]: 使用大型开源语言模型进行立场分类的提示和微调

    Prompting and Fine-Tuning Open-Sourced Large Language Models for Stance Classification

    [https://arxiv.org/abs/2309.13734](https://arxiv.org/abs/2309.13734)

    本研究探讨了使用大型语言模型作为立场检测方法以减少手动注释的需求，发现它们与域内监督模型具有竞争力，但性能不一致。

    

    立场分类是一个长期以来研究重点领域，从社会科学到机器学习领域，这项任务涉及预测作者对感兴趣主题的观点。当前的立场检测方法主要依赖于手动注释句子，然后训练监督式机器学习模型。然而，这种手动注释过程需要大量的注释工作，因此限制了它在不同环境中泛化的潜力。在这项工作中，我们调查了大型语言模型（LLMs）作为一种可以减少甚至消除手动注释需求的立场检测方法。我们研究了10个开源模型和7种提示方案，发现LLMs在与域内监督模型具竞争力，但性能并不一定一致。我们还进行了LLMs的微调，但发现微调过程不必然

    arXiv:2309.13734v2 Announce Type: replace-cross  Abstract: Stance classification, the task of predicting the viewpoint of an author on a subject of interest, has long been a focal point of research in domains ranging from social science to machine learning. Current stance detection methods rely predominantly on manual annotation of sentences, followed by training a supervised machine learning model. However, this manual annotation process requires laborious annotation effort, and thus hampers its potential to generalize across different contexts. In this work, we investigate the use of Large Language Models (LLMs) as a stance detection methodology that can reduce or even eliminate the need for manual annotations. We investigate 10 open-source models and 7 prompting schemes, finding that LLMs are competitive with in-domain supervised models but are not necessarily consistent in their performance. We also fine-tuned the LLMs, but discovered that fine-tuning process does not necessarily l
    
[^119]: THC：使用张量同态压缩加速分布式深度学习

    THC: Accelerating Distributed Deep Learning Using Tensor Homomorphic Compression

    [https://arxiv.org/abs/2302.08545](https://arxiv.org/abs/2302.08545)

    引入了Tensor Homomorphic Compression (THC)，一种新颖的双向压缩框架，可以加速分布式深度学习中的模型训练

    

    深度神经网络（DNNs）已经成为必要用例（如图像分类、计算机视觉和自然语言处理）的事实标准。随着DNNs和数据集变得越来越大，它们需要在越来越大的集群上进行分布式训练。 主要瓶颈是由工作者在每轮基础上交换模型更新（即梯度）产生的通信开销。 为了解决这一瓶颈并加速训练，一个广泛部署的方法是压缩。 但是，先前的部署通常只是在每个方向上使用单方向梯度压缩方案来应用双向压缩方案。 这导致参数服务器上的显着计算开销和压缩误差增加，从而导致训练时间更长和准确性更低。 我们介绍了张量同态压缩（THC），这是一种新颖的双向压缩框架，能够直接聚合

    arXiv:2302.08545v2 Announce Type: replace-cross  Abstract: Deep neural networks (DNNs) are the de facto standard for essential use cases, such as image classification, computer vision, and natural language processing. As DNNs and datasets get larger, they require distributed training on increasingly larger clusters. A main bottleneck is the resulting communication overhead where workers exchange model updates (i.e., gradients) on a per-round basis. To address this bottleneck and accelerate training, a widely-deployed approach is compression. However, previous deployments often apply bi-directional compression schemes by simply using a uni-directional gradient compression scheme in each direction. This results in significant computational overheads at the parameter server and increased compression error, leading to longer training and lower accuracy. We introduce Tensor Homomorphic Compression (THC), a novel bi-directional compression framework that enables the direct aggregation of com
    
[^120]: 交通流量预测的时空自监督学习

    Spatio-Temporal Self-Supervised Learning for Traffic Flow Prediction

    [https://arxiv.org/abs/2212.04475](https://arxiv.org/abs/2212.04475)

    提出了一种新的时空自监督学习（ST-SSL）交通预测框架，通过辅助自监督学习范式增强交通模式表示，既反映空间异质性又反映时间异质性。

    

    城市范围内在不同时间段对交通流量进行稳健预测在智能交通系统中起着至关重要的作用。尽管先前的工作已经为建模时空相关性做出了巨大努力，但现有方法仍然存在两个关键限制：i) 大多数模型在预测所有区域的流量时没有考虑空间异质性，即不同区域可能具有倾斜的交通流量分布。 ii) 这些模型未能捕捉由于时间变化的交通模式而引起的时间异质性，因为它们通常使用一个共享参数化空间来模拟所有时间段的时间相关性。为解决这些挑战，我们提出了一种新的时空自监督学习（ST-SSL）交通预测框架，通过辅助自监督学习范式增强交通模式表示，使其既反映空间异质性又反映时间异质性。

    arXiv:2212.04475v2 Announce Type: replace-cross  Abstract: Robust prediction of citywide traffic flows at different time periods plays a crucial role in intelligent transportation systems. While previous work has made great efforts to model spatio-temporal correlations, existing methods still suffer from two key limitations: i) Most models collectively predict all regions' flows without accounting for spatial heterogeneity, i.e., different regions may have skewed traffic flow distributions. ii) These models fail to capture the temporal heterogeneity induced by time-varying traffic patterns, as they typically model temporal correlations with a shared parameterized space for all time periods. To tackle these challenges, we propose a novel Spatio-Temporal Self-Supervised Learning (ST-SSL) traffic prediction framework which enhances the traffic pattern representations to be reflective of both spatial and temporal heterogeneity, with auxiliary self-supervised learning paradigms. Specificall
    
[^121]: 用推测对手模型进行决策

    Decision-making with Speculative Opponent Models

    [https://arxiv.org/abs/2211.11940](https://arxiv.org/abs/2211.11940)

    提出了一种使用纯粹局部信息实现推测对手建模的多智能体分布式演员-评论家算法，能够帮助受控代理做出决策。

    

    对手建模通过构建其他代理的模型，使受控代理的决策受益。现有方法通常假设可以访问对手的观察和行为，但当对手的行为不可观察或难以获得时，这是不可行的。我们提出了一种新颖的多智能体分布式演员-评论家算法，通过纯粹的局部信息（即受控代理的观察、行为和奖励）实现推测对手建模。具体而言，演员维持对对手的推测信念，我们称之为推测对手模型，以使用局部观察来预测对手的动作，并相应地做出决策。此外，分布式评论家模型政策的回报分布。它反映了演员的质量，因此可以指导演员所依赖的推测对手模型的训练。大量实验证实了我们的方法成功地...

    arXiv:2211.11940v2 Announce Type: replace  Abstract: Opponent modeling has benefited a controlled agent's decision-making by constructing models of other agents. Existing methods commonly assume access to opponents' observations and actions, which is infeasible when opponents' behaviors are unobservable or hard to obtain. We propose a novel multi-agent distributional actor-critic algorithm to achieve speculative opponent modeling with purely local information (i.e., the controlled agent's observations, actions, and rewards). Specifically, the actor maintains a speculated belief of the opponents, which we call the speculative opponent models, to predict opponent actions using local observations and makes decisions accordingly. Further, the distributional critic models the return distribution of the policy. It reflects the quality of the actor and thus can guide the training of the speculative opponent model that the actor relies on. Extensive experiments confirm that our method successf
    
[^122]: Seamful XAI: 将无缝设计运用于可解释人工智能

    Seamful XAI: Operationalizing Seamful Design in Explainable AI

    [https://arxiv.org/abs/2211.06753](https://arxiv.org/abs/2211.06753)

    通过揭示和利用社会技术和基础设施不匹配，无缝设计可以促进AI可解释性

    

    人工智能系统中的错误是不可避免的，这些错误既来自技术限制，也来自社会技术差距。虽然将AI系统设为黑匣子可以使用户体验更流畅，但隐藏接缝会使用户失去减轻AI错误后果的能力。我们提出，可以利用这些AI不完美来帮助用户，而不是将其隐藏起来。虽然可解释人工智能（XAI）主要解决了算法不透明性，但我们认为通过揭示和利用社会技术和基础设施不匹配，无缝设计可以促进AI可解释性。我们引入了Seamful XAI的概念，通过（1）将“接缝”概念转移到AI背景下和（2）开发帮助利益相关者预见和设计接缝的设计过程。我们将这一过程与43名AI从业者和真实终端用户一起探讨，使用基于场景的协同设计活动，并根据现实用例进行信息。我们发现，Seamful XAI设计过程有助于使用

    arXiv:2211.06753v2 Announce Type: replace-cross  Abstract: Mistakes in AI systems are inevitable, arising from both technical limitations and sociotechnical gaps. While black-boxing AI systems can make the user experience seamless, hiding the seams risks disempowering users to mitigate fallouts from AI mistakes. Instead of hiding these AI imperfections, can we leverage them to help the user? While Explainable AI (XAI) has predominantly tackled algorithmic opaqueness, we propose that seamful design can foster AI explainability by revealing and leveraging sociotechnical and infrastructural mismatches. We introduce the concept of Seamful XAI by (1) conceptually transferring "seams" to the AI context and (2) developing a design process that helps stakeholders anticipate and design with seams. We explore this process with 43 AI practitioners and real end-users, using a scenario-based co-design activity informed by real-world use cases. We found that the Seamful XAI design process helped use
    
[^123]: SemSegDepth: 一个集成模型用于语义分割和深度完成

    SemSegDepth: A Combined Model for Semantic Segmentation and Depth Completion

    [https://arxiv.org/abs/2209.00381](https://arxiv.org/abs/2209.00381)

    在本文中，我们提出了一个新的端到端模型，用于同时进行语义分割和深度完成。我们的方法结合了语义分割和深度完成任务，在多任务网络中有效提高了每个任务的性能。

    

    综合场景理解对于自主机器的性能至关重要。本文提出了一个新的端到端模型，用于同时进行语义分割和深度完成。我们的方法依赖于RGB和稀疏深度作为模型的输入，并产生密集深度图和相应的语义分割图像。它包括一个特征提取器，一个深度完成分支，一个语义分割分支以及一个联合分支，进一步同时处理语义和深度信息。在Virtual KITTI 2数据集上进行的实验证明，并提供了进一步的证据，即在多任务网络中结合语义分割和深度完成任务可以有效提高每个任务的性能。

    arXiv:2209.00381v2 Announce Type: replace-cross  Abstract: Holistic scene understanding is pivotal for the performance of autonomous machines. In this paper we propose a new end-to-end model for performing semantic segmentation and depth completion jointly. The vast majority of recent approaches have developed semantic segmentation and depth completion as independent tasks. Our approach relies on RGB and sparse depth as inputs to our model and produces a dense depth map and the corresponding semantic segmentation image. It consists of a feature extractor, a depth completion branch, a semantic segmentation branch and a joint branch which further processes semantic and depth information altogether. The experiments done on Virtual KITTI 2 dataset, demonstrate and provide further evidence, that combining both tasks, semantic segmentation and depth completion, in a multi-task network can effectively improve the performance of each task. Code is available at https://github.com/juanb09111/sem
    
[^124]: XAI中的“谁”：AI背景如何塑造AI解释的感知

    The Who in XAI: How AI Background Shapes Perceptions of AI Explanations

    [https://arxiv.org/abs/2107.13509](https://arxiv.org/abs/2107.13509)

    AI背景如何影响解释的解读，揭示了“谁”对于AI解释的重要性。

    

    AI系统的可解释性对用户采取知情行动至关重要。理解AI黑盒中的“谁”与打开它同样重要。我们进行了一项混合方法研究，研究了两组不同的人群——具有和不具有AI背景的人群——如何感知不同类型的AI解释。在定量上，我们分享用户在五个维度上的看法。在定性上，我们描述了AI背景如何影响解释的解读，通过拟人和认知启发的视角阐明了差异。我们发现（1）两组人出于不同原因对数字表现出不必要的信任，以及（2）每组人都发现不同于其预期设计的解释的价值。我们的发现对XAI领域具有重要意义，展示了即使出于最好的用意，AI生成的解释也可能产生负面后果，可能导致有害的信任操纵。我们提出设计

    arXiv:2107.13509v2 Announce Type: replace-cross  Abstract: Explainability of AI systems is critical for users to take informed actions. Understanding "who" opens the black-box of AI is just as important as opening it. We conduct a mixed-methods study of how two different groups--people with and without AI background--perceive different types of AI explanations. Quantitatively, we share user perceptions along five dimensions. Qualitatively, we describe how AI background can influence interpretations, elucidating the differences through lenses of appropriation and cognitive heuristics. We find that (1) both groups showed unwarranted faith in numbers for different reasons and (2) each group found value in different explanations beyond their intended design. Carrying critical implications for the field of XAI, our findings showcase how AI generated explanations can have negative consequences despite best intentions and how that could lead to harmful manipulation of trust. We propose design
    
[^125]: SelectLLM：LLMs能否选择重要的指令进行注释？

    SelectLLM: Can LLMs Select Important Instructions to Annotate?. (arXiv:2401.16553v1 [cs.CL])

    [http://arxiv.org/abs/2401.16553](http://arxiv.org/abs/2401.16553)

    这项工作提出了一种名为SelectLLM的新方法，利用LLMs选择高质量指令。通过提示LLMs估计每个无标签指令的有用性和影响力，并使用聚类算法将指令分为多个聚类。

    

    使用大量且多样化的指令数据集训练大型语言模型(LLMs)可以使模型理解和遵循人类指令。最近的研究表明，使用一小组高质量的指令可以超过使用大量更嘈杂的指令。由于指令是无标签的，且响应是自然文本，传统的主动学习方案无法直接应用于选择无标签指令。在这项工作中，我们提出了一种新的指令选择方法，称为SelectLLM，它利用LLMs选择高质量指令。我们的高级思想是利用LLMs通过提示来估计每个指令在没有相应标签（即响应）的情况下的有用性和影响力。SelectLLM包括两个步骤：使用聚类算法（例如CoreSet）将无标签指令划分为多个聚类，然后提示LLMs在其中选择高质量指令。

    Training large language models (LLMs) with a large and diverse instruction dataset aligns the models to comprehend and follow human instructions. Recent works have shown that using a small set of high-quality instructions can outperform using large yet more noisy ones. Because instructions are unlabeled and their responses are natural text, traditional active learning schemes with the model's confidence cannot be directly applied to the selection of unlabeled instructions. In this work, we propose a novel method for instruction selection, called SelectLLM, that leverages LLMs for the selection of high-quality instructions. Our high-level idea is to use LLMs to estimate the usefulness and impactfulness of each instruction without the corresponding labels (i.e., responses), via prompting. SelectLLM involves two steps: dividing the unlabelled instructions using a clustering algorithm (e.g., CoreSet) to multiple clusters, and then prompting LLMs to choose high-quality instructions within e
    
[^126]: Q&A提示：通过挖掘问题-回答提示来发现丰富的视觉线索，以满足对多样世界知识的视觉问答的需求

    Q&A Prompts: Discovering Rich Visual Clues through Mining Question-Answer Prompts for VQA requiring Diverse World Knowledge. (arXiv:2401.10712v1 [cs.CV])

    [http://arxiv.org/abs/2401.10712](http://arxiv.org/abs/2401.10712)

    本论文提出了一种叫做Q&A提示的方法，通过挖掘图像中的问题-回答对来发现丰富的视觉线索，以帮助AI模型更好地理解复杂视觉问题，提高跨模态推理能力。

    

    随着多模态大型语言模型的突破，回答需要高级推理能力和世界知识的复杂视觉问题比以往任何时候都更重要。然而，为AI模型配备强大的跨模态推理能力仍然具有挑战性，因为人类的认知方案尚未系统地被理解。在本文中，我们相信，如果我们能尽可能收集给定图像中的视觉线索，我们将能更准确地识别图像，更好地理解问题，更容易回忆相关知识，并最终推理出答案。我们通过在图像中挖掘问题-回答对来发现这些丰富的视觉线索，并将它们作为提示发送到多模态大型语言模型中。我们称之为Q&A提示的方法。具体而言，我们首先使用训练集中的图像-答案对和相应的问题作为输入和输出来训练一个视觉问题生成模型。

    With the breakthrough of multi-modal large language models, answering complex visual questions that demand advanced reasoning abilities and world knowledge has become a much more important testbed for developing AI models than ever. However, equipping AI models with robust cross-modality reasoning ability remains challenging since the cognition scheme of humans has not been understood systematically. In this paper, we believe that if we can collect visual clues in the given image as much as possible, we will recognize the image more accurately, understand the question better, recall relevant knowledge more easily, and finally reason out the answer. We discover these rich visual clues by mining question-answer pairs in images and sending them into multi-modal large language models as prompts. We call the proposed method Q&A Prompts. Specifically, we first use the image-answer pairs and the corresponding questions in the training set as inputs and outputs to train a visual question gener
    
[^127]: DevEval: 评估实际软件项目中的代码生成

    DevEval: Evaluating Code Generation in Practical Software Projects. (arXiv:2401.06401v1 [cs.SE])

    [http://arxiv.org/abs/2401.06401](http://arxiv.org/abs/2401.06401)

    本文提出了一个名为DevEval的新基准测试，用于评估实际软件项目中的代码生成。与之前的基准测试相比，DevEval在真实的项目分布、充足的依赖和足够规模的项目背景等方面更贴合实际。通过对五个流行的大型语言模型进行评估，我们揭示了它们在代码生成中的实际能力。

    

    如何评估大型语言模型（LLMs）在代码生成中的表现是一个开放的问题。许多基准测试已经提出，但是与实际软件项目不一致，例如虚构的程序分布，依赖不足和小规模项目背景。因此，LLMs在实际项目中的能力还不清楚。在本文中，我们提出了一个名为DevEval的新基准测试，与开发人员在实际项目中的经验相吻合。DevEval通过一个严格的流程收集到了来自119个实际项目的2690个样本，涵盖10个领域。与之前的基准测试相比，DevEval在多个维度上与实际项目相吻合，例如真实的程序分布，充足的依赖和足够规模的项目背景。我们在DevEval上评估了五个流行的LLMs（例如gpt-4，gpt-3.5-turbo，CodeLLaMa和StarCoder），并揭示了它们在代码生成中的实际能力。例如，gpt-3.5-turbo的最高Pass@1只有42。

    How to evaluate Large Language Models (LLMs) in code generation is an open question. Many benchmarks have been proposed but are inconsistent with practical software projects, e.g., unreal program distributions, insufficient dependencies, and small-scale project contexts. Thus, the capabilities of LLMs in practical projects are still unclear. In this paper, we propose a new benchmark named DevEval, aligned with Developers' experiences in practical projects. DevEval is collected through a rigorous pipeline, containing 2,690 samples from 119 practical projects and covering 10 domains. Compared to previous benchmarks, DevEval aligns to practical projects in multiple dimensions, e.g., real program distributions, sufficient dependencies, and enough-scale project contexts. We assess five popular LLMs on DevEval (e.g., gpt-4, gpt-3.5-turbo, CodeLLaMa, and StarCoder) and reveal their actual abilities in code generation. For instance, the highest Pass@1 of gpt-3.5-turbo only is 42 in our experim
    
[^128]: Let's Go Shopping (LGS) -- 用于视觉概念理解的大规模图像文本数据集

    Let's Go Shopping (LGS) -- Web-Scale Image-Text Dataset for Visual Concept Understanding. (arXiv:2401.04575v1 [cs.CV])

    [http://arxiv.org/abs/2401.04575](http://arxiv.org/abs/2401.04575)

    Let's Go Shopping (LGS) dataset is a large-scale public dataset with 15 million image-caption pairs from publicly available e-commerce websites, providing a more efficient way to collect and annotate images for vision and vision-language applications.

    

    神经网络的视觉和视觉-语言应用，如图像分类和字幕，依赖于需要非平凡的数据收集过程的大规模注释数据集。这种耗时的努力限制了大规模数据集的出现，使研究人员和实践者只能选择少数几种选择。因此，我们寻求更有效的方法来收集和注释图像。以往的倡议已经从HTML alt文本和爬取的社交媒体帖子中收集了字幕，但这些数据源存在噪声、稀疏或主观性的问题。因此，我们转向商业购物网站，其数据符合三个标准：干净、信息丰富和流畅。我们介绍了Let's Go Shopping（LGS）数据集，这是一个来自公开可用的电子商务网站的1500万个图像-字幕对的大规模公共数据集。与现有的通用领域数据集相比，LGS图像侧重于前景对象，背景复杂度较低。

    Vision and vision-language applications of neural networks, such as image classification and captioning, rely on large-scale annotated datasets that require non-trivial data-collecting processes. This time-consuming endeavor hinders the emergence of large-scale datasets, limiting researchers and practitioners to a small number of choices. Therefore, we seek more efficient ways to collect and annotate images. Previous initiatives have gathered captions from HTML alt-texts and crawled social media postings, but these data sources suffer from noise, sparsity, or subjectivity. For this reason, we turn to commercial shopping websites whose data meet three criteria: cleanliness, informativeness, and fluency. We introduce the Let's Go Shopping (LGS) dataset, a large-scale public dataset with 15 million image-caption pairs from publicly available e-commerce websites. When compared with existing general-domain datasets, the LGS images focus on the foreground object and have less complex backgro
    
[^129]: 一种解决人工智能黑盒问题的白盒解决方案

    A white box solution to the black box problem of AI. (arXiv:2401.03093v1 [cs.AI])

    [http://arxiv.org/abs/2401.03093](http://arxiv.org/abs/2401.03093)

    一种解决人工智能黑盒问题的白盒解决方案是使用基于相关领域一般理论的确定性逻辑细胞自动机的规则，该细胞自动机实现自动并行逻辑推理。

    

    基于神经网络的人工智能取得了重大进展。然而，由于缺乏透明性，对其可靠性和安全性存在担忧。这就是人工智能的黑盒问题。在这里，我们展示了如何使用符号 AI 来解决这个问题，符号 AI 具有透明的白盒性质。符号 AI 的广泛应用受到数学模型和自然语言术语的不透明性、缺乏统一本体论以及搜索选项的组合爆炸的阻碍。为了解决人工智能的黑盒问题并实现通用的符号 AI，我们提议使用基于相关领域一般理论的确定性逻辑细胞自动机的规则。在这种情况下，相关领域的一般理论起到了细胞自动机推理的知识库的作用。细胞自动机在复杂系统的三个层次上实现自动并行逻辑推理。

    Artificial intelligence based on neural networks has made significant progress. However, there are concerns about the reliability and security of this approach due to its lack of transparency. This is the black box problem of AI. Here we show how this problem can be solved using symbolic AI, which has a transparent white box nature. The widespread use of symbolic AI is hindered by the opacity of mathematical models and natural language terms, the lack of a unified ontology, and the combinatorial explosion of search options. To solve the AI black box problem and to implement general-purpose symbolic AI, we propose to use deterministic logic cellular automata with rules based on first principles of the general theory of the relevant domain. In this case, the general theory of the relevant domain plays the role of a knowledge base for the cellular automaton inference. A cellular automaton implements automatic parallel logical inference at three levels of organization of a complex system. 
    
[^130]: 在样本选择偏差存在的情况下，利用集成多样性进行鲁棒的自训练

    Leveraging Ensemble Diversity for Robust Self-Training in the Presence of Sample Selection Bias. (arXiv:2310.14814v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.14814](http://arxiv.org/abs/2310.14814)

    本文提出了一种在样本选择偏差存在的情况下，利用集成多样性进行鲁棒的自训练的方法，并引入了一种新的自信度度量方法-$\mathcal{T}$-相似度。实验证明该方法在三种不同伪标签策略下具有良好的效果。

    

    自训练是半监督学习中一种众所周知的方法。它包括对模型自信度高的未标记数据进行伪标签分配，并将其视为标记样本进行处理。对于神经网络，通常使用softmax预测概率作为自信度度量，尽管已知它们对错误预测也过于自信。当数据标注受到某种约束时，这种现象尤为明显，即样本选择偏差存在。为了解决这个问题，我们提出了一种新的自信度度量方法，称为$\mathcal{T}$-相似度，它基于线性分类器的集成预测多样性。我们通过研究稳定点并描述单个成员的多样性与其性能之间的关系来提供我们方法的理论分析。我们通过对三种不同伪标签策略的实验验证了我们自信度度量的好处。

    Self-training is a well-known approach for semi-supervised learning. It consists of iteratively assigning pseudo-labels to unlabeled data for which the model is confident and treating them as labeled examples. For neural networks, softmax prediction probabilities are often used as a confidence measure, despite the fact that they are known to be overconfident, even for wrong predictions. This phenomenon is particularly intensified in the presence of sample selection bias, i.e., when data labeling is subject to some constraint. To address this issue, we propose a novel confidence measure, called $\mathcal{T}$-similarity, built upon the prediction diversity of an ensemble of linear classifiers. We provide the theoretical analysis of our approach by studying stationary points and describing the relationship between the diversity of the individual members and their performance. We empirically demonstrate the benefit of our confidence measure for three different pseudo-labeling policies on c
    
[^131]: 可扩展的神经网络内核

    Scalable Neural Network Kernels. (arXiv:2310.13225v1 [cs.LG])

    [http://arxiv.org/abs/2310.13225](http://arxiv.org/abs/2310.13225)

    可扩展神经网络内核（SNNKs）是一种替代常规前馈层的方法，能够近似实现常规前馈层的功能，但具有更优的计算特性。通过将内核与参数-输入向量的点积联系起来，SNNKs能够有效地解开参数与输入之间的联系，从而模拟复杂关系。此外，我们还引入了神经网络捆绑过程，将SNNKs应用于深度神经网络压缩，进一步提高了压缩效果。最终捆绑网络甚至可以绕过反向传播，通过显式公式求解最优参数。

    

    我们引入了可扩展神经网络内核（SNNKs）的概念，这是常规前馈层（FFLs）的替代品，能够近似实现后者，但具有有利的计算属性。SNNKs有效地解开了FFL中参数与输入之间的联系，并通过点积内核在最终计算中连接它们。它们也更加表达力强，能够模拟复杂关系，超出参数-输入向量的函数范围。我们还引入了神经网络捆绑过程，将SNNKs应用于压缩深度神经网络结构，从而获得额外的压缩效益。在极端情况下，它导致完全捆绑网络，其最优参数可以通过多个损失函数（例如均方误差）的显式公式来表示，从而有可能绕过反向传播。作为我们分析的副产品，我们引入了普遍性机制的机制。

    We introduce the concept of scalable neural network kernels (SNNKs), the replacements of regular feedforward layers (FFLs), capable of approximating the latter, but with favorable computational properties. SNNKs effectively disentangle the inputs from the parameters of the neural network in the FFL, only to connect them in the final computation via the dot-product kernel. They are also strictly more expressive, as allowing to model complicated relationships beyond the functions of the dot-products of parameter-input vectors. We also introduce the neural network bundling process that applies SNNKs to compactify deep neural network architectures, resulting in additional compression gains. In its extreme version, it leads to the fully bundled network whose optimal parameters can be expressed via explicit formulae for several loss functions (e.g. mean squared error), opening a possibility to bypass backpropagation. As a by-product of our analysis, we introduce the mechanism of the universa
    
[^132]: 受前额叶皮层启发的大型语言模型规划架构

    A Prefrontal Cortex-inspired Architecture for Planning in Large Language Models. (arXiv:2310.00194v1 [cs.AI])

    [http://arxiv.org/abs/2310.00194](http://arxiv.org/abs/2310.00194)

    这个论文提出了一个受前额叶皮层启发的大型语言模型规划架构，利用多个基于LLM的模块实现规划的自主协调，从而在处理需要多步推理或目标导向规划的任务时取得了较好的效果。

    

    大型语言模型（LLM）在许多任务上展现出惊人的性能，但它们经常在需要多步推理或目标导向规划的任务中遇到困难。为了解决这个问题，我们从人脑中获取灵感，即通过前额叶皮层（PFC）中专门模块的重复交互来完成规划。这些模块执行冲突监测、状态预测、状态评估、任务分解和任务协调等功能。我们发现LLM有时能够单独执行这些功能，但在服务于一个目标时往往难以自主协调它们。因此，我们提出了一个带有多个基于LLM（GPT-4）模块的黑盒架构。该架构通过专门的PFC启发模块的交互将一个更大的问题分解为多个对LLM的简短自动调用，从而改善规划能力。我们在两个具有挑战性的规划任务上评估了组合架构。

    Large language models (LLMs) demonstrate impressive performance on a wide variety of tasks, but they often struggle with tasks that require multi-step reasoning or goal-directed planning. To address this, we take inspiration from the human brain, in which planning is accomplished via the recurrent interaction of specialized modules in the prefrontal cortex (PFC). These modules perform functions such as conflict monitoring, state prediction, state evaluation, task decomposition, and task coordination. We find that LLMs are sometimes capable of carrying out these functions in isolation, but struggle to autonomously coordinate them in the service of a goal. Therefore, we propose a black box architecture with multiple LLM-based (GPT-4) modules. The architecture improves planning through the interaction of specialized PFC-inspired modules that break down a larger problem into multiple brief automated calls to the LLM. We evaluate the combined architecture on two challenging planning tasks -
    
[^133]: 生成强化学习策略解释的实证研究

    On Generating Explanations for Reinforcement Learning Policies: An Empirical Study. (arXiv:2309.16960v1 [cs.AI])

    [http://arxiv.org/abs/2309.16960](http://arxiv.org/abs/2309.16960)

    本文通过引入一组线性时态逻辑（LTL）公式，介绍了一种生成强化学习策略解释的方法，并展示了其在模拟夺旗环境中的有效性。

    

    本文引入了一组设计用于提供策略解释的线性时态逻辑（LTL）公式。我们的重点是构建既阐明策略所实现的最终目标又阐明其执行过程中所维持的前提条件的解释。这些基于LTL的解释具有结构化表示，特别适用于局部搜索技术。通过模拟的夺旗环境，证明了我们提出的方法的有效性。论文最后提出了未来研究的建议方向。

    In this paper, we introduce a set of \textit{Linear Temporal Logic} (LTL) formulae designed to provide explanations for policies. Our focus is on crafting explanations that elucidate both the ultimate objectives accomplished by the policy and the prerequisites it upholds throughout its execution. These LTL-based explanations feature a structured representation, which is particularly well-suited for local-search techniques. The effectiveness of our proposed approach is illustrated through a simulated capture the flag environment. The paper concludes with suggested directions for future research.
    
[^134]: 因果故事：利用参数高效调整的局部因果注意力实现视觉故事合成

    Causal-Story: Local Causal Attention Utilizing Parameter-Efficient Tuning For Visual Story Synthesis. (arXiv:2309.09553v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.09553](http://arxiv.org/abs/2309.09553)

    提出了一种称为因果故事的新模型，利用局部因果注意力机制来改进视觉故事合成的全局一致性，该模型考虑了历史标题、帧和当前标题之间的因果关系，实现了更好的生成效果。

    

    演化模型在文本到图像合成方面具有出色的能力，推动了连贯视觉故事的合成进展。目前最先进的方法将历史标题、历史帧和当前标题的特征作为生成当前帧的条件进行组合。然而，该方法将每个历史帧和标题都视为同样的贡献，并以相等的权重将它们连接起来，忽视了并非所有历史条件都与生成当前帧相关。为了解决这个问题，我们提出了因果故事。该模型引入了一种考虑先前标题、帧和当前标题之间因果关系的局部因果注意机制。通过根据这种关系分配权重，因果故事生成当前帧，从而提高了故事生成的全局一致性。我们在PororoSV和FlintstonesSV数据集上评估了我们的模型，并获得了最先进的FID分数。

    The excellent text-to-image synthesis capability of diffusion models has driven progress in synthesizing coherent visual stories. The current state-of-the-art method combines the features of historical captions, historical frames, and the current captions as conditions for generating the current frame. However, this method treats each historical frame and caption as the same contribution. It connects them in order with equal weights, ignoring that not all historical conditions are associated with the generation of the current frame. To address this issue, we propose Causal-Story. This model incorporates a local causal attention mechanism that considers the causal relationship between previous captions, frames, and current captions. By assigning weights based on this relationship, Causal-Story generates the current frame, thereby improving the global consistency of story generation. We evaluated our model on the PororoSV and FlintstonesSV datasets and obtained state-of-the-art FID score
    
[^135]: 多任务强化学习中的Projected Task-Specific Layers

    Projected Task-Specific Layers for Multi-Task Reinforcement Learning. (arXiv:2309.08776v1 [cs.LG])

    [http://arxiv.org/abs/2309.08776](http://arxiv.org/abs/2309.08776)

    本研究提出了一种新的架构，Projected Task-Specific Layers (PTSL)，通过任务特定的层来表达共享和可变的任务信息，成功解决了多任务强化学习中的推广和干扰问题。

    

    多任务强化学习可以使机器人在家庭和工作场所的各种操作任务中实现规模化。然而，从一个任务推广到另一个任务并减轻负面任务干扰仍然是一个挑战。成功地在任务之间共享信息并取得良好效果将取决于对任务底层结构的有效捕捉。在这项工作中，我们介绍了一种新的架构，即Projected Task-Specific Layers（PTSL），它通过任务特定的层，通过稠密的任务特定的修正来更好地表达共享和可变的任务信息。然后，我们展示了我们的模型在Meta-World的MT10和MT50基准中（包括Sawyer机器人臂上的10个和50个目标条件任务）的表现优于现有技术水平。

    Multi-task reinforcement learning could enable robots to scale across a wide variety of manipulation tasks in homes and workplaces. However, generalizing from one task to another and mitigating negative task interference still remains a challenge. Addressing this challenge by successfully sharing information across tasks will depend on how well the structure underlying the tasks is captured. In this work, we introduce our new architecture, Projected Task-Specific Layers (PTSL), that leverages a common policy with dense task-specific corrections through task-specific layers to better express shared and variable task information. We then show that our model outperforms the state of the art on the MT10 and MT50 benchmarks of Meta-World consisting of 10 and 50 goal-conditioned tasks for a Sawyer arm.
    
[^136]: PyGraft: 在你的指尖生成可配置的模式和知识图谱

    PyGraft: Configurable Generation of Schemas and Knowledge Graphs at Your Fingertips. (arXiv:2309.03685v1 [cs.AI])

    [http://arxiv.org/abs/2309.03685](http://arxiv.org/abs/2309.03685)

    PyGraft是一个Python工具，可以根据需要生成高度定制的模式和知识图谱，并确保生成的资源的逻辑一致性。

    

    知识图谱（KG）已经成为一种重要的数据表示和管理范式。KG通常基于模式（例如本体论）来捕获事实信息和上下文知识。在某些任务中，一些KG已经成为标准的基准测试数据集。然而，最近的研究发现，仅依赖有限的数据集合是不足以评估方法的泛化能力的。在一些数据敏感领域，如教育或医学，公共数据集的获取更加有限。为了解决上述问题，我们发布了PyGraft，一个基于Python的工具，用于生成高度定制的、与领域无关的模式和知识图谱。合成的模式包括各种RDFS和OWL构造，而合成的KG则模拟了真实KG的特性和规模。通过运行描述逻辑（DL）推理器，最终确保生成资源的逻辑一致性。

    Knowledge graphs (KGs) have emerged as a prominent data representation and management paradigm. Being usually underpinned by a schema (e.g. an ontology), KGs capture not only factual information but also contextual knowledge. In some tasks, a few KGs established themselves as standard benchmarks. However, recent works outline that relying on a limited collection of datasets is not sufficient to assess the generalization capability of an approach. In some data-sensitive fields such as education or medicine, access to public datasets is even more limited. To remedy the aforementioned issues, we release PyGraft, a Python-based tool that generates highly customized, domain-agnostic schemas and knowledge graphs. The synthesized schemas encompass various RDFS and OWL constructs, while the synthesized KGs emulate the characteristics and scale of real-world KGs. Logical consistency of the generated resources is ultimately ensured by running a description logic (DL) reasoner. By providing a way
    
[^137]: 通过超出平衡状态的扩展动力学性能评估神经力场

    xxMD: Benchmarking Neural Force Fields Using Extended Dynamics beyond Equilibrium. (arXiv:2308.11155v1 [cs.LG])

    [http://arxiv.org/abs/2308.11155](http://arxiv.org/abs/2308.11155)

    在神经力场模型中，常用的MD17数据集对于表示经历化学反应的系统不足。为了解决这一问题，我们引入了xxMD数据集，该数据集采样自扩展激发态分子动力学，包含了能量和力的信息。

    

    神经力场已成为计算化学中的重要模型，取代了从头算的分子动力学中的量子化学计算。目前对神经力场的主要评估基准是MD17数据集及其后续扩展。这些数据集主要包含来自基态势能面平衡区域的几何结构，采样自直接绝热动力学。然而，许多化学反应涉及到较大的分子变形，特别是键断裂。我们展示了MD17数据集中内坐标和能量的约束分布，凸显了其在表示经历化学反应的系统方面的不足。为了解决这种采样限制，我们引入了xxMD（扩展激发态分子动力学）数据集，从非绝热动力学中派生。该数据集包含了从多参考波函数理论和密度泛函中确定的能量和力。

    Neural force fields (NFFs) have gained prominence in computational chemistry as surrogate models, superseding quantum-chemistry calculations in ab initio molecular dynamics. The prevalent benchmark for NFFs has been the MD17 dataset and its subsequent extension. These datasets predominantly comprise geometries from the equilibrium region of the ground electronic state potential energy surface, sampling from direct adiabatic dynamics. However, many chemical reactions entail significant molecular deformations, notably bond breaking. We demonstrate the constrained distribution of internal coordinates and energies in the MD17 datasets, underscoring their inadequacy for representing systems undergoing chemical reactions. Addressing this sampling limitation, we introduce the xxMD (Extended Excited-state Molecular Dynamics) dataset, derived from non-adiabatic dynamics. This dataset encompasses energies and forces ascertained from both multireference wave function theory and density functional
    
[^138]: VQGraph: 图形向量量化用于连接GNN和MLPs

    VQGraph: Graph Vector-Quantization for Bridging GNNs and MLPs. (arXiv:2308.02117v1 [cs.LG])

    [http://arxiv.org/abs/2308.02117](http://arxiv.org/abs/2308.02117)

    VQGraph是一个框架，通过学习一个强大的图形表示空间，用于连接GNN和MLPs。它采用矢量量化变分自编码器（VQ-VAE）的编码器作为结构感知图标记器，有效地表示底层图的多样化局部结构。通过 VQGraph，可以实现从GNN到MLP的知识转移。

    

    图神经网络（GNNs）进行信息传递，聚合局部邻居以更新节点表示。这种信息传递导致在实际的延迟约束应用程序中存在可扩展性问题。为了解决这个问题，最近的方法采用知识蒸馏（KD）通过模仿GNN的输出来学习计算效率高的多层感知机（MLP）。然而，现有的GNN表示空间可能不足以表示底层图的多样化局部结构，这限制了从GNN到MLP的知识转移。在这里，我们提出了一个新颖的框架VQGraph，用于学习一个强大的图形表示空间，用于连接GNN和MLPs。我们采用一种变体的矢量量化变分自编码器（VQ-VAE）的编码器作为结构感知图标记器，它将多样化的局部结构节点明确表示为大量离散令牌，并构成一个有意义的代码书。配备了学习的代码书，我们提出

    Graph Neural Networks (GNNs) conduct message passing which aggregates local neighbors to update node representations. Such message passing leads to scalability issues in practical latency-constrained applications. To address this issue, recent methods adopt knowledge distillation (KD) to learn computationally-efficient multi-layer perceptron (MLP) by mimicking the output of GNN. However, the existing GNN representation space may not be expressive enough for representing diverse local structures of the underlying graph, which limits the knowledge transfer from GNN to MLP. Here we present a novel framework VQGraph to learn a powerful graph representation space for bridging GNNs and MLPs. We adopt the encoder of a variant of a vector-quantized variational autoencoder (VQ-VAE) as a structure-aware graph tokenizer, which explicitly represents the nodes of diverse local structures as numerous discrete tokens and constitutes a meaningful codebook. Equipped with the learned codebook, we propos
    
[^139]: 使用语言模型进行算术运算：从记忆到计算

    Arithmetic with Language Models: from Memorization to Computation. (arXiv:2308.01154v1 [cs.AI])

    [http://arxiv.org/abs/2308.01154](http://arxiv.org/abs/2308.01154)

    本研究探索了使用语言模型进行算术计算的能力，发现语言模型可以通过内部的值空间进行计算，并取得了成功的实验结果。

    

    更好地理解最近的大型语言模型的出现性计算和问题解决能力对于进一步改进它们并拓宽其适用性至关重要。本研究探讨了一个训练用于预测下一个标记的语言模型如何在训练数据之外执行算术计算。二进制加法和乘法是一个很好的测试基础，因为它们需要一个非常小的词汇表，并且在输入/输出上展示了相关的不连续性，使得对新数据进行平滑的输入插值无效。我们成功地训练了一个轻量级的语言模型来学习这些任务，并进行了一系列实验证明其外推能力和内部信息处理。我们的研究结果支持这样一个假设，即语言模型作为一个编码-回归-解码机器，一旦将输入标记表示映射到合适的内部值空间，计算就在值空间中进行。

    A better understanding of the emergent computation and problem-solving capabilities of recent large language models is of paramount importance to further improve them and broaden their applicability. This work investigates how a language model, trained to predict the next token, can perform arithmetic computations generalizing beyond training data. Binary addition and multiplication constitute a good testbed for this purpose, since they require a very small vocabulary and exhibit relevant input/output discontinuities making smooth input interpolation ineffective for novel data. We successfully trained a light language model to learn these tasks and ran a number of experiments to investigate the extrapolation capabilities and internal information processing. Our findings support the hypotheses that the language model works as an Encoding-Regression-Decoding machine where the computation takes place in the value space once the input token representation is mapped to an appropriate intern
    
[^140]: 可解释的推理方法用于刻板印象识别

    Interpretable Stereotype Identification through Reasoning. (arXiv:2308.00071v1 [cs.CL])

    [http://arxiv.org/abs/2308.00071](http://arxiv.org/abs/2308.00071)

    本研究通过使用推理方法，在零射击刻板印象识别中取得了重要的进展，并发现推理的性能增益远远超过模型规模扩展的增益。推理不仅提高了准确性，还提高了决策的可解释性。

    

    鉴于语言模型训练使用了包含固有偏见的大量数据集，可能会不经意地持续系统性歧视，因此，审查和解决语言模型中的偏见变得至关重要，将公平性整合到它们的发展中，以确保这些模型具有公正和无偏的特性。在这项工作中，我们展示了基于Vicuna-13B-v1.3的零射击刻板印象识别中推理的重要性。尽管我们观察到从13B到33B的规模扩展会提高准确性，但我们表明推理的性能增益远远超过规模扩展的增益。我们的研究结果表明，推理可能是使LLMs在刻板印象等领域任务上超越规模定律的关键因素。此外，通过对选定的推理追踪进行定性分析，我们突出显示了推理不仅提高了准确性，还提高了决策的可解释性。

    Given that language models are trained on vast datasets that may contain inherent biases, there is a potential danger of inadvertently perpetuating systemic discrimination. Consequently, it becomes essential to examine and address biases in language models, integrating fairness into their development to ensure these models are equitable and free from bias. In this work, we demonstrate the importance of reasoning in zero-shot stereotype identification based on Vicuna-13B-v1.3. While we do observe improved accuracy by scaling from 13B to 33B, we show that the performance gain from reasoning significantly exceeds the gain from scaling up. Our findings suggest that reasoning could be a key factor that enables LLMs to trescend the scaling law on out-of-domain tasks such as stereotype identification. Additionally, through a qualitative analysis of select reasoning traces, we highlight how reasoning enhances not just accuracy but also the interpretability of the decision.
    
[^141]: 无法阻止的攻击: 基于条件扩散模型的标签仅模型逆推

    Unstoppable Attack: Label-Only Model Inversion via Conditional Diffusion Model. (arXiv:2307.08424v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2307.08424](http://arxiv.org/abs/2307.08424)

    本论文提出了一种在标签仅黑盒场景下的模型逆推攻击方法，使用条件扩散模型恢复目标的精确样本，无需额外的优化。

    

    模型逆推攻击(MIAs)旨在从目标模型的训练集中恢复私密数据，这对深度学习模型的隐私构成威胁。MIAs主要关注白盒情景，在此情况下，攻击者可以完全访问目标模型的结构和参数。然而，实际应用是黑盒情景，对手很难获取与模型相关的参数，许多模型仅输出预测标签。现有的黑盒MIAs主要集中在设计优化策略上，而生成模型只是从白盒MIA中使用的GAN迁移而来。据我们所知，我们的研究是标签仅黑盒情景下可行攻击模型的开创性研究。在本文中，我们使用条件扩散模型开发了一种新颖的MIA方法，可以在目标模型输出标签的情况下无需任何额外的优化来恢复目标的精确样本。引入了两个主要技术

    Model inversion attacks (MIAs) are aimed at recovering private data from a target model's training set, which poses a threat to the privacy of deep learning models. MIAs primarily focus on the white-box scenario where the attacker has full access to the structure and parameters of the target model. However, practical applications are black-box, it is not easy for adversaries to obtain model-related parameters, and various models only output predicted labels. Existing black-box MIAs primarily focused on designing the optimization strategy, and the generative model is only migrated from the GAN used in white-box MIA. Our research is the pioneering study of feasible attack models in label-only black-box scenarios, to the best of our knowledge.  In this paper, we develop a novel method of MIA using the conditional diffusion model to recover the precise sample of the target without any extra optimization, as long as the target model outputs the label. Two primary techniques are introduced t
    
[^142]: BERTTM: 利用来自预训练语言模型的上下文化词向量进行神经主题建模

    BERTTM: Leveraging Contextualized Word Embeddings from Pre-trained Language Models for Neural Topic Modeling. (arXiv:2305.09329v1 [cs.CL])

    [http://arxiv.org/abs/2305.09329](http://arxiv.org/abs/2305.09329)

    本文提出了一种新颖的神经主题模型，利用来自预训练语言模型BERT的上下文化词嵌入，可以在不使用任何BoW信息的情况下推断出文档的主题分布，并直接从上下文化词嵌入中推断出文档中每个单词的主题分布。实验结果表明，该模型优于仅依赖BoW表示和其他神经主题模型的现有最先进方法。

    

    随着近年来神经主题模型的发展，主题建模在自然语言理解中扮演着日益重要的角色。然而，大多数现有的主题模型仍然依赖于词袋（BoW）信息，无论是作为训练输入还是训练目标。这限制了它们捕捉文档中的单词顺序信息的能力，并导致它们在处理新文档中的未观察到的单词时遇到困难。预训练语言模型中的上下文化词向量在词义消歧的能力上表现优越，并证明了它们在处理OOV单词时是有效的。在这项工作中，我们开发了一种新颖的神经主题模型，结合了预训练语言模型BERT的上下文化词嵌入。该模型可以在不使用任何BoW信息的情况下推断出文档的主题分布。此外，该模型可以直接从上下文化词嵌入中推断出文档中每个单词的主题分布。基准数据集的实验表明，我们的模型优于仅依赖BoW表示和其他神经主题模型的现有最先进方法。

    With the development of neural topic models in recent years, topic modelling is playing an increasingly important role in natural language understanding. However, most existing topic models still rely on bag-of-words (BoW) information, either as training input or training target. This limits their ability to capture word order information in documents and causes them to suffer from the out-of-vocabulary (OOV) issue, i.e. they cannot handle unobserved words in new documents. Contextualized word embeddings from pre-trained language models show superiority in the ability of word sense disambiguation and prove to be effective in dealing with OOV words. In this work, we developed a novel neural topic model combining contextualized word embeddings from the pre-trained language model BERT. The model can infer the topic distribution of a document without using any BoW information. In addition, the model can infer the topic distribution of each word in a document directly from the contextualize
    
[^143]: 针对链接预测，对待不同的负样本有差异性：利用领域和范围约束丰富损失函数

    Treat Different Negatives Differently: Enriching Loss Functions with Domain and Range Constraints for Link Prediction. (arXiv:2303.00286v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00286](http://arxiv.org/abs/2303.00286)

    通过引入领域和范围约束，我们提出了基于语义的损失函数来区分不同质量的负样本，实验证明在链接预测任务上有效。

    

    知识图谱嵌入模型（KGEMs）用于与知识图谱（KGs）相关的各种任务，包括链接预测。它们使用考虑了一批得分三元组及其相应标签的损失函数进行训练。传统方法认为三元组的标签要么为真，要么为假。然而，最近的研究表明，并非所有的负样本应该被平等对待。与这一最近的假设一致，我们认为基于领域和范围约束在语义上有效的负样本可能是高质量的负样本。因此，损失函数应该将它们与语义上无效的负样本区别对待。为此，我们针对链接预测的三个主要损失函数提出了基于语义的版本。通过广泛和受控的实验设置，我们展示了所提出的损失函数在三个具有不同模式的公共基准KG上系统地提供了令人满意的结果。

    Knowledge graph embedding models (KGEMs) are used for various tasks related to knowledge graphs (KGs), including link prediction. They are trained with loss functions that are computed considering a batch of scored triples and their corresponding labels. Traditional approaches consider the label of a triple to be either true or false. However, recent works suggest that all negative triples should not be valued equally. In line with this recent assumption, we posit that negative triples that are semantically valid w.r.t. domain and range constraints might be high-quality negative triples. As such, loss functions should treat them differently from semantically invalid negative ones. To this aim, we propose semantic-driven versions for the three main loss functions for link prediction. In an extensive and controlled experimental setting, we show that the proposed loss functions systematically provide satisfying results on three public benchmark KGs underpinned with different schemas, whic
    
[^144]: 加密货币交易对的最优设置

    Optimal Settings for Cryptocurrency Trading Pairs. (arXiv:2210.10971v2 [q-fin.TR] UPDATED)

    [http://arxiv.org/abs/2210.10971](http://arxiv.org/abs/2210.10971)

    本文研究了加密货币交易对的最优设置问题，并提出了一个两阶段过程来解决这个优化问题。该问题的特殊之处在于大部分可能的交易对之间的交易量无法直接观察，且需要满足连通性约束。

    

    加密货币的目标是去中心化，所有货币原则上地位相等。与传统股市不同，没有默认的货币单位（法币），因此可以自由设置交易对。然而，为每两种货币之间建立一个交易市场是不切实际的。为了控制管理成本并确保足够的流动性，我们必须优先考虑那些大量交易的交易对，并确保所有货币都是可以交易的。我们注意到这是一个优化问题，其特殊之处在于：1）大部分（>99.5%）可能的交易对之间的交易量无法直接观察。2）它满足连通性约束，即保证所有货币都可以交易。为了解决这个问题，我们采用了一个两阶段的过程：1）基于正则化的截断特征值分解填充缺失值，其中正则化项用于控制缺失值被限制为零的程度。

    The goal of cryptocurrencies is decentralization. In principle, all currencies have equal status. Unlike traditional stock markets, there is no default currency of denomination (fiat), thus the trading pairs can be set freely. However, it is impractical to set up a trading market between every two currencies. In order to control management costs and ensure sufficient liquidity, we must give priority to covering those large-volume trading pairs and ensure that all coins are reachable. We note that this is an optimization problem. Its particularity lies in: 1) the trading volume between most (>99.5%) possible trading pairs cannot be directly observed. 2) It satisfies the connectivity constraint, that is, all currencies are guaranteed to be tradable.  To solve this problem, we use a two-stage process: 1) Fill in missing values based on a regularized, truncated eigenvalue decomposition, where the regularization term is used to control what extent missing values should be limited to zero. 2
    

