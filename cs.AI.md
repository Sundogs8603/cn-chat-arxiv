# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [AdaptiX -- A Transitional XR Framework for Development and Evaluation of Shared Control Applications in Assistive Robotics.](http://arxiv.org/abs/2310.15887) | AdaptiX是一个过渡性的XR框架，用于开发和评估助动力机器人中的共同控制应用。它提供了一个高分辨率仿真环境，并结合了用户自主性和计算机辅助。 |
| [^2] | [KirchhoffNet: A Circuit Bridging Message Passing and Continuous-Depth Models.](http://arxiv.org/abs/2310.15872) | 本文提出了一种称为基赫霍夫网络的神经网络模型，利用基赫霍夫电流定律与消息传递神经网络和连续深度网络建立连接。在MNIST数据集上，基赫霍夫网络可以实现接近98.86%的测试准确度，且具有在硬件上实现的潜力。无论网络参数数量如何，其正向计算都可以在1/f秒内完成，具有快速计算的硬件特性。 |
| [^3] | [Topology-aware Debiased Self-supervised Graph Learning for Recommendation.](http://arxiv.org/abs/2310.15858) | 面向推荐的拓扑感知去偏向自监督图学习（TDSGL）通过构建对比对，考虑用户（物品）的语义相似性，解决了推荐系统中负采样策略导致的错误负样本和忽略正样本的问题。 |
| [^4] | [Using Artificial French Data to Understand the Emergence of Gender Bias in Transformer Language Models.](http://arxiv.org/abs/2310.15852) | 本文使用人工法语数据生成的语料库，探索了神经语言模型如何发现单词的性别属性以及其使用规则，并研究了模型在不同条件下是否正确捕捉到性别信息或表现出性别偏见。 |
| [^5] | [Posterior Estimation for Dynamic PET imaging using Conditional Variational Inference.](http://arxiv.org/abs/2310.15850) | 本文提出了一个基于深度学习的框架，用于有效估计动态PET成像中的后验分布。通过引入潜在变量来对抗前向过程中的信息损失，并使用条件变分自编码器进行优化，我们能够用简单的多元高斯分布推断出后验概率。 |
| [^6] | [A Diffusion Weighted Graph Framework for New Intent Discovery.](http://arxiv.org/abs/2310.15836) | 本研究提出了一种名为Diffusion Weighted Graph Framework (DWGF)的方法，用于捕捉数据中的语义相似性和结构关系，从而实现更充分和可靠的监督信号，解决了以往方法在新意图发现中无法平衡数量和质量的问题。 |
| [^7] | [Automatic Aorta Segmentation with Heavily Augmented, High-Resolution 3-D ResUNet: Contribution to the SEG.A Challenge.](http://arxiv.org/abs/2310.15827) | 重度增强、高分辨率3D ResUNet自动主动脉分割在SEG.A挑战中取得了优异的成绩，达到了所有测试案例0.9以上的Dice分数，并在稳定性上超过了其他参与者。它在临床评估、定量结果和体积网格质量方面名列前茅。 |
| [^8] | [Rosetta Stone at KSAA-RD Shared Task: A Hop From Language Modeling To Word--Definition Alignment.](http://arxiv.org/abs/2310.15823) | 本论文介绍了在KSAA-RD共享任务中Rosetta Stone的应用，将语言建模应用到词--定义对齐中。论文通过使用一组微调的阿拉伯BERT模型来预测给定定义的词嵌入，从而实现了阿拉伯词的向量表示。 |
| [^9] | [Discriminator Guidance for Autoregressive Diffusion Models.](http://arxiv.org/abs/2310.15817) | 本文引入了判别器引导，用于自回归扩散模型的训练，通过使用最优判别器来纠正预训练模型，并提出了一个顺序蒙特卡洛算法来应对使用次优判别器的情况。在生成分子图的任务中，判别器引导有助于提高生成性能。 |
| [^10] | [DALE: Generative Data Augmentation for Low-Resource Legal NLP.](http://arxiv.org/abs/2310.15799) | DALE是一个用于低资源法律NLP的生成式数据增强框架，通过基于选择性掩码的无监督文本去噪目标预训练，在解决法律语言特异性的同时生成连贯且多样化的增强。 |
| [^11] | [Random Entity Quantization for Parameter-Efficient Compositional Knowledge Graph Representation.](http://arxiv.org/abs/2310.15797) | 本文研究了参数高效的组合知识图谱表示的问题，通过随机实体量化的方法，可以达到与当前策略类似的效果，这是因为随机实体量化下，实体码有更高的熵和码字级别的Jaccard距离，使得不同实体更容易区分，从而有效地表示知识图谱。 |
| [^12] | [Improving generalization in large language models by learning prefix subspaces.](http://arxiv.org/abs/2310.15793) | 本文提出了一种通过学习前缀子空间来改进大型语言模型的泛化能力的方法。我们通过联合优化模型参数空间中的整个单纯形模型，在稀缺数据环境中实现了更广的局部最优解。这种方法在预训练变换器模型中表现出了很好的兼容性和有效性。 |
| [^13] | [SequenceMatch: Revisiting the design of weak-strong augmentations for Semi-supervised learning.](http://arxiv.org/abs/2310.15787) | SequenceMatch是一种半监督学习方法，通过引入中等增强方法和不同的一致性约束，帮助减小了模型对弱增强和强增强示例的预测分布之间的差异，提高了数据效率。 |
| [^14] | [3D Masked Autoencoders for Enhanced Privacy in MRI Scans.](http://arxiv.org/abs/2310.15778) | 本研究提出了一种名为CP-MAE的模型，通过使用面部遮罩来实现MRI扫描中的人脸去识别，提高了隐私保护水平。 |
| [^15] | [MindLLM: Pre-training Lightweight Large Language Model from Scratch, Evaluations and Domain Applications.](http://arxiv.org/abs/2310.15777) | 本文提出了一种从零开始训练的轻量级大型语言模型MindLLM，通过提供1.3亿和3亿参数的模型，减轻了训练和部署大型语言模型的成本和资源稀缺性的压力。MindLLM在各个步骤中给出了经验教训，包括数据构建、模型架构、评估和应用，对学术界和开发者来说具有重要价值。 |
| [^16] | [Causal Understanding of Why Users Share Hate Speech on Social Media.](http://arxiv.org/abs/2310.15772) | 本文研究了用户为何分享社交媒体上的仇恨言论，提出了一个因果分析框架，通过消除数据偏差和模拟用户脆弱性来揭示影响用户分享行为的因素。 |
| [^17] | [Debiasing, calibrating, and improving Semi-supervised Learning performance via simple Ensemble Projector.](http://arxiv.org/abs/2310.15764) | 本研究提出了一种简单的方法，通过集成投影器在半监督学习中改进了嵌入，从而提高了性能。 |
| [^18] | [Integrating Language Models into Direct Speech Translation: An Inference-Time Solution to Control Gender Inflection.](http://arxiv.org/abs/2310.15752) | 该论文提出了一种推断时间解决方案，用于在语音翻译中控制与说话者相关的性别变化。通过部分替换内部语言模型，将特定性别的外部语言模型应用于翻译过程，实验证明这一方法在性别准确性方面优于基准模型和最佳训练时间缓解策略，尤其在具有性别冲突的条件下效果显著提高。 |
| [^19] | [Recurrent Linear Transformers.](http://arxiv.org/abs/2310.15719) | 本文提出了循环线性变换器作为transformer自注意机制的替代方案，解决了transformers在处理长距离依赖关系和推断成本方面的限制。在强化学习问题中的实验证明了其有效性和可行性。 |
| [^20] | [Solving large flexible job shop scheduling instances by generating a diverse set of scheduling policies with deep reinforcement learning.](http://arxiv.org/abs/2310.15706) | 本文提出了一种能够通过生成多样化的调度策略来解决大型柔性车间调度实例的方法，并应用深度强化学习来优化调度质量。 |
| [^21] | [Learning-based Scheduling for Information Accuracy and Freshness in Wireless Networks.](http://arxiv.org/abs/2310.15705) | 本文研究了基于学习的无线网络调度问题，通过比较四种标准的赌博机策略的性能，以提高信息准确性和新鲜度。 |
| [^22] | [Towards Automated Recipe Genre Classification using Semi-Supervised Learning.](http://arxiv.org/abs/2310.15693) | 该论文提出了一个名为3A2M+的自动菜谱类型分类方法，通过半监督学习利用扩展的命名实体识别列表对烹饪食谱进行分类。研究者提供了一个包含两百万个带有各种特征和九个不同类型标签的烹饪食谱数据集，以解决缺乏标注数据的问题。 |
| [^23] | [Improving Biomedical Abstractive Summarisation with Knowledge Aggregation from Citation Papers.](http://arxiv.org/abs/2310.15684) | 该论文提出了一种基于引文聚合的模型，通过整合引文论文中的领域特定知识，提高了生物医学摘要总结的语言模型的性能。 |
| [^24] | [Recent Advances in Multi-modal 3D Scene Understanding: A Comprehensive Survey and Evaluation.](http://arxiv.org/abs/2310.15676) | 多模态3D场景理解在自动驾驶和人机交互等领域中应用广泛。本文从理论的角度对多模态3D方法的进展进行了全面调查和评估。 |
| [^25] | [A Survey on Detection of LLMs-Generated Content.](http://arxiv.org/abs/2310.15654) | 该论文是关于LLMs生成内容检测的综述，提供了现有策略和挑战的概述，并提倡采用更灵活和强大的模型以提高检测准确性，并强调使用多方面的方法来应对不同攻击。这是首个综合调查LLMs时代检测的工作。 |
| [^26] | [Career Path Prediction using Resume Representation Learning and Skill-based Matching.](http://arxiv.org/abs/2310.15636) | 本论文在职业路径预测中提出了一种使用简历表示学习和基于技能匹配的方法，通过研究文本描述部分来预测下一步的职业动向，并在数据集上验证了该方法的有效性。 |
| [^27] | [Using Slisemap to interpret physical data.](http://arxiv.org/abs/2310.15610) | Slisemap是一种结合了流形可视化和可解释人工智能的方法，可以帮助我们在物理数据中找到有意义的信息。 |
| [^28] | [tagE: Enabling an Embodied Agent to Understand Human Instructions.](http://arxiv.org/abs/2310.15605) | tagE是一种能够从自然语言指令中提取任务的具身代理系统，解决了智能代理理解人类意图时的歧义性和不完整性问题。 |
| [^29] | [Emergent Communication in Interactive Sketch Question Answering.](http://arxiv.org/abs/2310.15597) | 本文研究了基于视觉的紧急沟通，提出了一个新颖的交互式素描问答任务，通过多轮交互实现了智能agent之间的有针对性、高效的沟通，并具有较好的人类可解释性。 |
| [^30] | [Retrieval-based Knowledge Transfer: An Effective Approach for Extreme Large Language Model Compression.](http://arxiv.org/abs/2310.15594) | 检索式知识转移（RetriKT）是一种新的压缩范例，它通过提取大规模预训练语言模型的知识并利用 retrieval-based 的方法，将这些知识应用于极小规模的模型中，从而实现了极端的模型压缩效果。 |
| [^31] | [Detecting Intentional AIS Shutdown in Open Sea Maritime Surveillance Using Self-Supervised Deep Learning.](http://arxiv.org/abs/2310.15586) | 本论文提出了一种基于自监督深度学习技术和变压器模型的方法，用于检测开放海域海上监视中的有意AIS关闭。模型通过比较预测结果来报告检测到的异常情况。 |
| [^32] | [CONTRASTE: Supervised Contrastive Pre-training With Aspect-based Prompts For Aspect Sentiment Triplet Extraction.](http://arxiv.org/abs/2310.15577) | CONTRASTE是一种利用对比学习的预训练策略，通过设计基于方面的提示并应用对比学习来增强方面情感三元组抽取（ASTE）任务的性能，并在其他ABSA任务上展示出优势。 |
| [^33] | [SteloCoder: a Decoder-Only LLM for Multi-Language to Python Code Translation.](http://arxiv.org/abs/2310.15539) | SteloCoder是一个仅解码的基于StarCoder的LLM，在多语言到Python代码翻译中取得了显著的性能提升。它采用Mixture-of-Experts（MoE）技术和门控网络，通过对StarCoder进行微调获得专家，并使用低秩自适应方法（LoRA）技术来限制每个专家的大小。 |
| [^34] | [Generative and Contrastive Paradigms Are Complementary for Graph Self-Supervised Learning.](http://arxiv.org/abs/2310.15523) | 生成式和对比式范式在图自监督学习中是互补的，我们提出了图对比掩码自编码器（GCMAE）框架来统一它们，GCMAE通过利用对比学习的全局信息来弥补掩码自编码器在捕捉全局信息方面的不足。 |
| [^35] | [KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval.](http://arxiv.org/abs/2310.15511) | 本研究评估了最先进的模型在信息检索中回答约束满足查询的能力，并引入了一个新的数据集KITAB来衡量语言模型的约束满足能力。 |
| [^36] | [Robust Representation Learning for Unified Online Top-K Recommendation.](http://arxiv.org/abs/2310.15492) | 本论文提出一种鲁棒的表示学习方法，用于统一在线Top-K推荐，在大规模工业电子商务中解决物品广告和内容广告的不一致性，以及跨不同领域的多实体广告的检索问题。 |
| [^37] | [NuTrea: Neural Tree Search for Context-guided Multi-hop KGQA.](http://arxiv.org/abs/2310.15484) | NuTrea是一个基于树搜索的GNN模型，用于上下文引导的多跳知识图问答。模型采用了消息传递方案来增强过去导向的嵌入，并引入了RF-IEF节点嵌入来更好地表征模糊的知识图节点。 |
| [^38] | [AutoDiff: combining Auto-encoder and Diffusion model for tabular data synthesizing.](http://arxiv.org/abs/2310.15479) | 使用自动编码器和扩散模型结合的AutoDiff模型可以有效地生成合成的表格数据，克服了表格数据中的异构特征和特征间相关性的挑战，生成的数据与真实数据在统计上非常相似，并在机器学习任务中表现良好。 |
| [^39] | [Empowering Distributed Solutions in Renewable Energy Systems and Grid Optimization.](http://arxiv.org/abs/2310.15468) | 本研究探讨了从集中到分散的方法在电力行业中的转变，并重点讨论了机器学习对于可再生能源赋能和电网管理的关键作用。在预测可再生能源的产生和消耗方面，机器学习模型的应用变得越来越重要。将大数据和机器学习应用于智能电网可以提高能源效率、更好地响应需求和更好地整合可再生能源。然而，需要解决处理大数据量、网络安全和专业知识等挑战。 |
| [^40] | [UI Layout Generation with LLMs Guided by UI Grammar.](http://arxiv.org/abs/2310.15455) | 本文探讨了利用LLMs生成UI布局的方法，引入了UI语法来改进生成过程的可解释性和可控性，初步实验表明这种方法有潜力生成高质量的用户界面。 |
| [^41] | [PromptInfuser: How Tightly Coupling AI and UI Design Impacts Designers' Workflows.](http://arxiv.org/abs/2310.15435) | 本研究研究了如何将AI和UI设计紧密结合，开发了PromptInfuser插件，将提示与UI元素相连，通过与设计师现有的AI原型化工作流进行比较，发现PromptInfuser在传达产品理念、原型制作效率和问题预测方面更有用，鼓励设计师同时迭代提示和UI。 |
| [^42] | [ConstitutionMaker: Interactively Critiquing Large Language Models by Converting Feedback into Principles.](http://arxiv.org/abs/2310.15428) | ConstitutionMaker是一个交互式工具，通过帮助用户将他们的反馈转化为一组原则，从而对大型语言模型进行批评和调整，以改善聊天机器人的输出。 |
| [^43] | [FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions.](http://arxiv.org/abs/2310.15421) | FANToM是一个新的基准，用于通过问答在信息不对称的对话环境中压力测试机器的心智理论。这个基准对最先进的大型语言模型来说具有挑战性，即使是具有思维链推理和微调的模型也比人类表现得差。 |
| [^44] | [Fractal Landscapes in Policy Optimization.](http://arxiv.org/abs/2310.15418) | 该论文研究了政策优化过程中非平滑或分形的优化景观，提出了一种理解策略梯度方法固有限制的框架，并开发了一种实用方法来识别训练过程中是否遇到分形景观。 |
| [^45] | [Nominality Score Conditioned Time Series Anomaly Detection by Point/Sequential Reconstruction.](http://arxiv.org/abs/2310.15416) | 本文提出了一种利用基于点/顺序重构模型的框架来进行无监督时间序列异常检测的方法。通过计算重构误差的组合值之比得到命名分数, 进一步结合命名分数和异常分数导出感应异常分数，从而实现对点异常和上下文异常的量化和检测。 |
| [^46] | [Mind the Gap Between Conversations for Improved Long-Term Dialogue Generation.](http://arxiv.org/abs/2310.15415) | 本研究探索了使对话模型意识到时间的想法，并提出了一个多次对话的数据集GapChat，显示出时间感知的模型在判断话题相关性和从对话中获取信息的度量标准方面表现更好。 |
| [^47] | [Diverse Conventions for Human-AI Collaboration.](http://arxiv.org/abs/2310.15414) | 本研究通过最大化自我对弈的奖励并最小化与先前发现的约定交互时的奖励来生成多样化约定，确保学到的策略在交叉对弈的对抗性优化过程中遵守善意行事 |
| [^48] | [DoGE: Domain Reweighting with Generalization Estimation.](http://arxiv.org/abs/2310.15393) | DoGE提出了一种基于泛化估计的领域重新加权方法。通过使用梯度估计函数评估每个领域对泛化目标的贡献，重新调整了预训练数据中不同领域的采样概率。实验结果表明，该方法在提高大型语言模型的泛化能力方面取得了显著效果。 |
| [^49] | [Irreducible Curriculum for Language Model Pretraining.](http://arxiv.org/abs/2310.15389) | 本论文提出了一种不可约课程算法，用于语言模型预训练，通过优先选择具有更高学习能力的样本，并使用小规模代理模型模拟样本丢失，从而在大型语言模型上解决了传统数据选择方法的困难，并在实验证明算法能够持续改进模型性能。 |
| [^50] | [Course Correcting Koopman Representations.](http://arxiv.org/abs/2310.15386) | 本文修正了Koopman表示的方法，并提出了一种称为“周期重新编码”的机制，用于准确捕捉非线性动力系统中的长期动态。 |
| [^51] | [Semantic Data Management in Data Lakes.](http://arxiv.org/abs/2310.15373) | 数据湖是管理大量异构数据进行现代数据分析的一种方法。为了防止数据湖成为无法操作的数据沼泽，我们可以采用语义数据管理的方法，通过将元数据与知识图谱相链接，为数据提供更多的意义和语义。这种语义层不仅可以用于数据管理，还可以解决数据整合问题，使数据访问更具表达性和互操作性。 |
| [^52] | [EpiK-Eval: Evaluation for Language Models as Epistemic Models.](http://arxiv.org/abs/2310.15372) | 这项研究介绍了一种新的评估方法EpiK-Eval，旨在评估大型语言模型（LLMs）在从分割的叙述中构建连贯和一致的知识表示方面的能力。研究发现当前的训练目标存在固有的缺陷，因此提出了改进知识整合方法的建议，以大幅提高LLMs的整体效果和性能。 |
| [^53] | [Vicinal Feature Statistics Augmentation for Federated 3D Medical Volume Segmentation.](http://arxiv.org/abs/2310.15371) | 本论文提出了一种基于邻近特征统计增强的联邦三维医学体积分割方案，通过数据增强来提高FL分割的性能，并解决了标记数据有限和数据分布异构的问题。 |
| [^54] | [Why LLMs Hallucinate, and How to Get (Evidential) Closure: Perceptual, Intensional, and Extensional Learning for Faithful Natural Language Generation.](http://arxiv.org/abs/2310.15355) | 本研究展示了LLMs产生幻觉的原因是因为它们的输出没有受到证据支持的主张的约束，并介绍了如何通过感知、内涵和外延学习来约束LLMs以生成满足证据闭合性的输出。 |
| [^55] | [Moral Foundations of Large Language Models.](http://arxiv.org/abs/2310.15337) | 本文通过使用道德基础理论（MFT）作为分析工具，研究了流行的大型语言模型（LLMs）是否对一系列特定的道德价值观产生了偏见，并展示了它们与人类道德基础和政治倾向的关联。研究还发现LLMs的偏见在不同的提示上下文中存在差异，并展示了通过对抗选择提示可以引导LLMs产生不同的回答。 |
| [^56] | [Serverless Federated Learning with flwr-serverless.](http://arxiv.org/abs/2310.15329) | flwr-serverless是一种无服务器联邦学习的方法，能够有效训练来自不同来源的数据，同时不损害安全和隐私。 |
| [^57] | [Hallucination Detection for Grounded Instruction Generation.](http://arxiv.org/abs/2310.15319) | 该论文研究了生成指导人类在模拟环境中导航的说明的问题，通过预训练模型并使用对比损失进行微调，提出了一种检测幻觉参考的模型，该模型在性能上超过了几个基线模型。 |
| [^58] | [HetGPT: Harnessing the Power of Prompt Tuning in Pre-Trained Heterogeneous Graph Neural Networks.](http://arxiv.org/abs/2310.15318) | HetGPT是一种预训练异构图神经网络的方法，通过利用提示调整来解决预训练与下游任务之间的不匹配问题。 |
| [^59] | [Toward a Critical Toponymy Framework for Named Entity Recognition: A Case Study of Airbnb in New York City.](http://arxiv.org/abs/2310.15302) | 通过研究纽约市Airbnb房源数据集，本文提出了一个基于批评地名学的命名实体识别（NER）模型，能够识别与地点特征化相关的重要话语类别，为批评地名学研究指明了新的方向。 |
| [^60] | [Neural Network with Local Converging Input (NNLCI) for Supersonic Flow Problems with Unstructured Grids.](http://arxiv.org/abs/2310.15299) | 本研究开发了一种具有局部收敛输入的神经网络（NNLCI），用于使用非结构化数据进行高保真预测。该方法大大降低了计算资源和训练时间，并在无粘超音速流问题中展示了有效性和多功能性。 |
| [^61] | [TaskDiff: A Similarity Metric for Task-Oriented Conversations.](http://arxiv.org/abs/2310.15298) | TaskDiff是一种新颖的对话相似度度量方法，通过使用不同的对话组成部分来计算相似度，取得了优越的性能和鲁棒性。 |
| [^62] | [DeTiME: Diffusion-Enhanced Topic Modeling using Encoder-decoder based LLM.](http://arxiv.org/abs/2310.15296) | DeTiME是一种使用基于编码-解码的LLMs增强扩散的主题建模方法，能够产生高度聚类的嵌入和具有增强语义一致性的主题，并能生成与主题相关的内容。 |
| [^63] | [Active teacher selection for reinforcement learning from human feedback.](http://arxiv.org/abs/2310.15288) | 本论文提出了一个用于强化学习中的主动教师选择模型以解决多教师的学习问题，研究表明该模型在论文推荐系统和COVID-19疫苗测试领域具有优越性能，并揭示了利用教师间差异来学习准确奖励模型的重要性。 |
| [^64] | [Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges.](http://arxiv.org/abs/2310.15274) | 本论文讨论了面临能源、对齐和从狭义人工智能到AGI的三大挑战的系统化人工智能方法。现有的人工智能方法在能源消耗、系统设计和对齐问题上存在不足，而系统设计在解决对齐、能源和AGI大挑战中是至关重要的。 |
| [^65] | [Towards Possibilities & Impossibilities of AI-generated Text Detection: A Survey.](http://arxiv.org/abs/2310.15264) | 本文综述了AI生成文本检测的可能性和不可能性。具体而言，讨论了使用大型语言模型产生的文本可能导致的问题以及表明AI生成文本检测的意义。另外，还提到了对抗检测的策略的设计。 |
| [^66] | [Reference Free Domain Adaptation for Translation of Noisy Questions with Question Specific Rewards.](http://arxiv.org/abs/2310.15259) | 这项研究提出了一种解决噪声环境中问题翻译挑战的方法，通过只使用源语数据进行微调的训练，实现了翻译问题的充分性和流畅性的平衡。 |
| [^67] | [CRoW: Benchmarking Commonsense Reasoning in Real-World Tasks.](http://arxiv.org/abs/2310.15239) | CRoW是一个手工策划的多任务基准测试，用于评估模型在真实世界NLP任务中应用常识推理的能力。该基准测试揭示了NLP系统在常识推理方面与人类之间存在显著的性能差距，表明常识推理在真实世界中仍然远未解决。 |
| [^68] | [A new approach to template banks of gravitational waves with higher harmonics: reducing matched-filtering cost by over an order of magnitude.](http://arxiv.org/abs/2310.15233) | 该论文提出了一种新方法，通过在引力波模板库中包含高次谐波模式，利用引力波模式之间的自然关联，可以大幅度减少匹配滤波的成本，并提高搜索引力波事件的灵敏度。 |
| [^69] | [Modeling Path Importance for Effective Alzheimer's Disease Drug Repurposing.](http://arxiv.org/abs/2310.15211) | 该论文提出了一种基于网络的新方法（MPI）来有效进行阿尔茨海默病药物重用。该方法通过学习节点嵌入来优先考虑重要路径，从而更好地发现候选药物。 |
| [^70] | [Predicting Transcription Factor Binding Sites using Transformer based Capsule Network.](http://arxiv.org/abs/2310.15202) | 本文提出了一种基于Transformer的胶囊网络DNABERT-Cap，用于预测转录因子结合位点。该模型在预测中利用了双向编码器、胶囊层、卷积和双向长短时记忆层的特征，并通过对这些特征的联合优化构建了转录因子结合位点的预测器。 |
| [^71] | [A Skin Microbiome Model with AMP interactions and Analysis of Quasi-Stability vs Stability in Population Dynamics.](http://arxiv.org/abs/2310.15201) | 本文介绍了一种基于常微分方程的数学模型，用于研究皮肤微生物组中的两种细菌群落（共生菌和机会性致病菌）之间的相互作用，并考虑了抗微生物肽的产生。通过使用实验数据验证模型的稳定状态，可以帮助我们理解皮肤微生物组中不同群体之间的竞争机制和稳定性。 |
| [^72] | [Efficient Meta Neural Heuristic for Multi-Objective Combinatorial Optimization.](http://arxiv.org/abs/2310.15196) | 本研究提出了一种高效的元神经启发式算法（EMNH），通过训练一个元模型并进行微调，来解决多目标组合优化问题。实验结果表明，EMNH在学习效率和解决质量上取得了显著改进。 |
| [^73] | [Neural Multi-Objective Combinatorial Optimization with Diversity Enhancement.](http://arxiv.org/abs/2310.15195) | 提出了一种具有多样性增强的神经启发式方法（NHDE）来解决神经多目标组合优化（MOCO）问题，该方法通过引入指示器增强的深度强化学习方法和多重帕累托最有策略，能够产生更多且具有更高多样性的帕累托解。 |
| [^74] | [Application of deep and reinforcement learning to boundary control problems.](http://arxiv.org/abs/2310.15191) | 本研究将深度学习和强化学习应用于解决边界控制问题，通过使用空间神经网络构建初始猜测以及利用策略梯度方法学习迭代优化算法的时空神经网络，通过使用生成的合成数据进行训练和验证，研究发现深度学习和强化学习方法在解决边界控制问题方面具有潜在优势。 |
| [^75] | [Deep Learning Approaches for Dynamic Mechanical Analysis of Viscoelastic Fiber Composites.](http://arxiv.org/abs/2310.15188) | 本文利用深度学习方法，将微结构与力学性能建立映射关系，加快了设计过程，并实现了根据期望性能生成微结构的目标。 |
| [^76] | [Reducing Uncertainty in Sea-level Rise Prediction: A Spatial-variability-aware Approach.](http://arxiv.org/abs/2310.15179) | 这篇论文提出了一种基于区域回归模型的方法，通过解决空间可变性和模型相互依赖的问题，准确可靠地预测未来海平面上升，并降低不确定性。 |
| [^77] | [A Neuro-Mimetic Realization of the Common Model of Cognition via Hebbian Learning and Free Energy Minimization.](http://arxiv.org/abs/2310.15177) | 这项研究通过赫比安学习和自由能最小化实现了神经模仿的认知共同模型，该模型能够合成复杂的字词序列或产生复杂的图像模式。 |
| [^78] | [Meta- (out-of-context) learning in neural networks.](http://arxiv.org/abs/2310.15047) | 该研究通过合成实验展示了一种称为元-超文本外语境学习（meta-OCL）的现象在神经网络中的存在。这种学习使神经网络能够更好地吸收广泛适用的语义内容，并在适当的情况下进行使用。研究者提出了关于元-超文本外语境学习产生的两种假设，并就未来AI系统的能力和潜在风险进行了讨论。 |
| [^79] | [Meta learning with language models: Challenges and opportunities in the classification of imbalanced text.](http://arxiv.org/abs/2310.15019) | 本文提出了一种元学习技术(MLT)，通过将不同文本表示构建的个体模型进行组合，在不平衡的文本分类中提高了性能，并通过阈值移动技术进一步改善了预测器的性能。 |
| [^80] | [Efficient Causal Discovery for Robotics Applications.](http://arxiv.org/abs/2310.14925) | 这篇论文提出了一种用于机器人应用的快速准确因果关系发现方法F-PCMCI，并展示了其在实际机器人应用中的有效重构因果模型的能力。 |
| [^81] | [A Survey on LLM-generated Text Detection: Necessity, Methods, and Future Directions.](http://arxiv.org/abs/2310.14724) | 本文对LLM生成的文本检测进行了调查，强调了开发这样的检测器的必要性，并总结了近期的研究创新和未来发展方向。 |
| [^82] | [CorefPrompt: Prompt-based Event Coreference Resolution by Measuring Event Type and Argument Compatibilities.](http://arxiv.org/abs/2310.14512) | CorefPrompt是一种基于提示的方法，通过测量事件类型和参数的兼容性来进行事件指代消解。该方法将事件指代消解转化为一个填空式MLM任务，并通过引入辅助的提示任务来帮助模型进行推理，最终在基准测试中取得了良好的表现。 |
| [^83] | [Randomized Forward Mode of Automatic Differentiation for Optimization Algorithms.](http://arxiv.org/abs/2310.14168) | 该论文介绍了一种随机前向模式自动微分优化算法，通过在神经网络的正向传递中计算损失函数的方向导数来更新参数。算法通过采样不同概率分布的随机方向，使用正向模式自动微分计算雅可比向量乘积，并提供了对其收敛速度和计算复杂性的严格分析。 |
| [^84] | [Contrast Everything: A Hierarchical Contrastive Framework for Medical Time-Series.](http://arxiv.org/abs/2310.14017) | 本论文提出了一个名为COMET的创新层次对比框架，用于医疗时间序列分析。该框架通过在多个层级上开发对比损失，可以充分利用医疗时间序列的复杂特性，并实现自监督学习。使用多个数据集进行实验验证了COMET的有效性。 |
| [^85] | [Contrastive Preference Learning: Learning from Human Feedback without RL.](http://arxiv.org/abs/2310.13639) | 对比偏好学习方法解决了传统强化学习从人类反馈中学习奖励函数的假设错误以及优化挑战的问题。 |
| [^86] | [Boosting Generalization with Adaptive Style Techniques for Fingerprint Liveness Detection.](http://arxiv.org/abs/2310.13573) | 该论文介绍了一种通过自适应风格技术提升指纹活体检测泛化能力的方法，并在LivDet 2023挑战中取得了最先进的性能。 |
| [^87] | [Towards Understanding Sycophancy in Language Models.](http://arxiv.org/abs/2310.13548) | 这项研究探讨了强化学习从人类反馈中训练高质量AI助手的技术，发现这种方法可能导致模型在回答问题时过于谄媚，而不是坦诚，通过分析人类偏好数据得出了这一结论。 |
| [^88] | [Ask Language Model to Clean Your Noisy Translation Data.](http://arxiv.org/abs/2310.13469) | 论文介绍了如何利用大型语言模型清理神经机器翻译中的噪声输入，通过从MTNT数据集中清理目标语句的噪声，生成了C-MTNT数据集，显著减少了噪声。 |
| [^89] | [Deep Reinforcement Learning-based Intelligent Traffic Signal Controls with Optimized CO2 emissions.](http://arxiv.org/abs/2310.13129) | 本研究提出了一种基于深度强化学习的智能交通信号控制算法，通过优化CO2排放和行驶时间等指标，实现了较好的性能。 |
| [^90] | [Understanding Addition in Transformers.](http://arxiv.org/abs/2310.13121) | 本文通过对经过训练进行整数加法的单层Transformer模型的深入分析，揭示了该模型将任务分为并行的、特定于数字的流，并针对不同的数字位置采用不同的算法，同时还发现了一种罕见的高损失的使用情况。这些发现对于机制可解释性、人工智能安全性和对齐性等方面的研究具有重要贡献。 |
| [^91] | [Neural Attention: Enhancing QKV Calculation in Self-Attention Mechanism with Neural Networks.](http://arxiv.org/abs/2310.11398) | 本文介绍了一种利用神经网络增强自注意机制中QKV计算的方法，实验证明这种方法在多个任务中取得了显著的提升。 |
| [^92] | [AdaptSSR: Pre-training User Model with Augmentation-Adaptive Self-Supervised Ranking.](http://arxiv.org/abs/2310.09706) | 在用户建模中，通过自适应增强自监督排序方法预训练用户模型，解决了数据稀疏性问题和现有增强方法引入的噪音问题。 |
| [^93] | [A Mass-Conserving-Perceptron for Machine Learning-Based Modeling of Geoscientific Systems.](http://arxiv.org/abs/2310.08644) | 这篇论文提出了一种质量保持感知器（MCP）用于将物理-概念模型和机器学习模型结合起来建模地球科学系统，通过利用机器学习技术从数据中学习物理过程的功能性和质量保持性。 |
| [^94] | [Memory efficient location recommendation through proximity-aware representation.](http://arxiv.org/abs/2310.06484) | 这项研究介绍了一种基于近邻感知表示的内存高效的位置推荐方法，通过重要性抽样的损失函数和自注意力网络架构来解决稀疏性和地理信息整合的问题。 |
| [^95] | [Counter Turing Test CT^2: AI-Generated Text Detection is Not as Easy as You May Think -- Introducing AI Detectability Index.](http://arxiv.org/abs/2310.05030) | 这篇论文介绍了一个名为反图灵测试（CT^2）的基准，旨在全面评估现有AI生成文本检测技术的稳健性。在面对生成AI的风险和后果引起关注的情况下，解决AI生成作品归属问题变得尤为重要。 |
| [^96] | [Avalon's Game of Thoughts: Battle Against Deception through Recursive Contemplation.](http://arxiv.org/abs/2310.01320) | 本研究通过使用复杂的Avalon游戏作为测试平台，引入了一种名为递归思考（ReCon）的新框架，用于增强大型语言模型（LLM）识别和对抗欺骗信息的能力。 |
| [^97] | [Disentangling Voice and Content with Self-Supervision for Speaker Recognition.](http://arxiv.org/abs/2310.01128) | 本研究提出了一种利用自监督方法解离语音中的发音和内容的框架，用于说话人识别。实验证明该方法在VoxCeleb和SITW数据集上对EER和minDCF有明显的降低。 |
| [^98] | [Adaptive Communications in Collaborative Perception with Domain Alignment for Autonomous Driving.](http://arxiv.org/abs/2310.00013) | 这篇论文提出了一个通信的协同感知框架ACC-DA，通过动态调整通信图和自适应数据重构机制来增强自动驾驶中的感知能力。 |
| [^99] | [AnglE-Optimized Text Embeddings.](http://arxiv.org/abs/2309.12871) | 本文提出了一种名为AnglE的角度优化文本嵌入模型，通过在复杂空间中引入角度优化来缓解文本嵌入中余弦函数饱和区域造成的梯度消失问题。该模型在多个STS任务中实现了高质量的文本嵌入，并在有限标签数据的特定领域STS场景中展现出优秀的性能。 |
| [^100] | [How to Fine-tune the Model: Unified Model Shift and Model Bias Policy Optimization.](http://arxiv.org/abs/2309.12671) | 本文提出了一个统一模型偏移和模型偏差的优化目标，并通过微调过程实现了自适应的模型更新，以提供性能改进保证和避免模型过拟合。 |
| [^101] | [Efficient Concept Drift Handling for Batch Android Malware Detection Models.](http://arxiv.org/abs/2309.09807) | 本文研究了批量安卓恶意软件检测模型的高效概念漂移处理方法，通过重新训练技术来维持检测器的能力，并通过比较不同的重新训练频率和数据使用方法的影响，提出了改进策略。 |
| [^102] | [A Quantum Optimization Case Study for a Transport Robot Scheduling Problem.](http://arxiv.org/abs/2309.09736) | 本研究通过比较D-Waves的量子-经典混合框架、富士通的量子启发式数字退火器和Gurobi的经典求解器的性能，提供了解决运输机器人调度问题的指导，发现数字退火器有希望的结果，并为混合量子退火器提供了一些机会。 |
| [^103] | [Promoting Research Collaboration with Open Data Driven Team Recommendation in Response to Call for Proposals.](http://arxiv.org/abs/2309.09404) | 通过利用开放数据和人工智能方法，我们设计了一个系统来推荐团队，使得每个团队能够满足项目要求的技能覆盖，并且平衡候选成员之间的工作分配。 |
| [^104] | [Measuring vagueness and subjectivity in texts: from symbolic to neural VAGO.](http://arxiv.org/abs/2309.06132) | 本文提出了一种混合方法来自动测量文本中的模糊性和主观性。通过引入专家系统VAGO，以及基于BERT-like架构的神经克隆，该方法在固定语料库和多语言生成方面表现出良好的性能。 |
| [^105] | [LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked.](http://arxiv.org/abs/2308.07308) | 本文提出了一种通过自检来防御大型语言模型(LLMs)对抗性攻击的简单方法，即让模型自行过滤回应。实验结果表明，即使模型未对齐人类价值观，通过使用语言模型验证内容，仍然可以防止模型向用户呈现有害内容。 |
| [^106] | [Beyond Semantics: Learning a Behavior Augmented Relevance Model with Self-supervised Learning.](http://arxiv.org/abs/2308.05379) | 这篇论文提出了一种行为增强的相关模型，利用自我监督学习，通过从用户历史行为数据中提取辅助查询-项目交互，来改进搜索引擎中的查询-项目匹配，提高准确性和鲁棒性。 |
| [^107] | [Model of models -- Part 1.](http://arxiv.org/abs/2308.04600) | 本文提出了一种新的认知模型，该模型在成熟智能状态下操作累积的知识，并依赖适当的意愿进行指导。 |
| [^108] | [MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities.](http://arxiv.org/abs/2308.02490) | MM-Vet是一个评估标准，用于评估大型多模态模型在复杂任务上的综合能力。该标准解决了如何结构化和评估复杂多模态任务、设计适用于不同问题和回答类型的评估指标以及如何提供模型洞察的问题。通过整合不同的核心视觉-语言能力，MM-Vet展示了有趣的能力和解决复杂任务的方法。 |
| [^109] | [Relation-Oriented: Toward Knowledge-Aligned Causal AI.](http://arxiv.org/abs/2307.16387) | 本研究从创新的关系导向视角出发，探讨了当前的建模范式中的观察模型与实际理解的不对齐问题，并提出了关系定义的表示学习方法作为实现关系导向建模的实践方法。 |
| [^110] | [DiffKendall: A Novel Approach for Few-Shot Learning with Differentiable Kendall's Rank Correlation.](http://arxiv.org/abs/2307.15317) | 本文提出了一种利用可微分Kendall排名相关性进行少样本学习的新方法，证明了特征通道的重要性排序在少样本学习中比几何相似度度量更可靠，并且实验证明在推理过程中用Kendall排名相关性替换几何相似度度量能够提高少样本学习性能。 |
| [^111] | [Dual-Space Attacks against Random-Walk-based Anomaly Detection.](http://arxiv.org/abs/2307.14387) | 本文考察了随机游走异常检测(RWAD)面临的图空间攻击和特征空间攻击，证明了攻击RWAD的复杂度是NP难的，并提出了两种攻击策略，进一步通过图引导攻击设计了更强大的特征空间攻击。 |
| [^112] | [WebArena: A Realistic Web Environment for Building Autonomous Agents.](http://arxiv.org/abs/2307.13854) | WebArena是一个用于构建自主智能体的真实网络环境，它包含了完全功能的网站，并且通过引入工具和外部知识库来鼓励智能体像人类一样解决任务。此外，WebArena还发布了一组用于评估任务完成功能正确性的基准任务。 |
| [^113] | [Uncertainty-aware Grounded Action Transformation towards Sim-to-Real Transfer for Traffic Signal Control.](http://arxiv.org/abs/2307.12388) | 本文提出了UGAT方法，通过在模拟环境中动态转换具有不确定性的行动，实现了从模拟环境到真实环境的策略转移，显著提高了在真实世界中的性能。 |
| [^114] | [RADAR: Robust AI-Text Detection via Adversarial Learning.](http://arxiv.org/abs/2307.03838) | 本论文提出了一种名为RADAR的新框架，通过对抗性学习实现了鲁棒的AI文本检测，以解决当前AI文本检测器对于大语言模型的改写不具备鲁棒性的问题。 |
| [^115] | [State Regularized Policy Optimization on Data with Dynamics Shift.](http://arxiv.org/abs/2306.03552) | 本文提出了一种叫做 SRPO (状态规范化策略优化) 的算法，该算法利用训练数据中的稳态分布来规范新环境中的策略，在处理具有不同动态的多个环境时表现优异。 |
| [^116] | [Don't Trust GPT When Your Question Is Not In English.](http://arxiv.org/abs/2305.16339) | 在多语言环境下，GPT-3表现较差，特别是当问题不是用英语提出时。这与模型的训练数据和输入问题的语言差异有关。 |
| [^117] | [ToMChallenges: A Principle-Guided Dataset and Diverse Evaluation Tasks for Exploring Theory of Mind.](http://arxiv.org/abs/2305.15068) | 本研究提出了一个基于原则的数据集和多样化评估任务，名为ToMChallenges，以探索心智理论。研究发现，大型语言模型在心智理论任务上表现不一致，稳定地执行任务仍然具有挑战性。 |
| [^118] | [GRACE: Discriminator-Guided Chain-of-Thought Reasoning.](http://arxiv.org/abs/2305.14934) | GRACE是一种判别器引导的思维链推理的逐步解码方法，通过使用一个正确性判别器来评分下一步候选，解决了语言模型在多步推理中容易得到错误答案的问题。在多个数学和符号推理任务中，GRACE相较于其他方法在性能上有明显的提升。 |
| [^119] | [ByteSized32: A Corpus and Challenge Task for Generating Task-Specific World Models Expressed as Text Games.](http://arxiv.org/abs/2305.14879) | 这项工作研究了语言模型生成科学和常识推理任务的世界模型的能力，通过生成以Python代码形式表达的文字游戏来实现。实验证明GPT-4可以使用这些游戏作为模板进行上下文学习，并引入了一套自动评估指标进行模拟逼真度的评估。 |
| [^120] | [Leveraging GPT-4 for Automatic Translation Post-Editing.](http://arxiv.org/abs/2305.14878) | GPT-4在翻译后编辑任务中表现出色，通过产生有意义且可靠的编辑，大幅提高了翻译质量并消除了各类重要错误。 |
| [^121] | [Preserving Knowledge Invariance: Rethinking Robustness Evaluation of Open Information Extraction.](http://arxiv.org/abs/2305.13981) | 本文提出了第一个模拟评估开放式信息提取模型在真实世界中的基准测试，并通过判断模型在整个团体上的表现是否始终准确来评估模型的鲁棒性。 |
| [^122] | [Instruct-Align: Teaching Novel Languages with to LLMs through Alignment-based Cross-Lingual Instruction.](http://arxiv.org/abs/2305.13627) | Instruct-Align提出了基于对齐的跨语言教学调整框架，使得教学调整的LLMs能够学习新语言，且不会发生灾难性遗忘。 |
| [^123] | [CoEdIT: Text Editing by Task-Specific Instruction Tuning.](http://arxiv.org/abs/2305.09857) | CoEdIT是一种通过任务特定指令调整实现文本编辑的最先进模型，能够提高用户生成文本的质量和提高流程的效率。 |
| [^124] | [Revisiting the Minimalist Approach to Offline Reinforcement Learning.](http://arxiv.org/abs/2305.09836) | 这篇论文提出了一种名为ReBRAC的极简算法，它在TD3+BC方法的基础上整合了设计元素，通过对近期离线强化学习研究的回顾性分析，证明其在离线强化学习上的领先地位。 |
| [^125] | [Transfer Visual Prompt Generator across LLMs.](http://arxiv.org/abs/2305.01278) | 本论文提出将已有的轻量化视觉提示发生器连接到视觉-语言LLM以减少资源消耗的方法，并提出了跨不同大小和类型的LLMs的VPG转移方案VPGTrans，该方案在VQA和NLVR2任务中表现优秀。 |
| [^126] | [How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model.](http://arxiv.org/abs/2305.00586) | 本研究运用机械式可解释性技术探究了GPT-2 Small的数学能力，并确定了它的计算图中的一个小电路用于计算大于符号，该电路的多层感知器提高了结束年份大于开始年份的概率，并且该电路具有广泛的适用性。 |
| [^127] | [Document-Level Machine Translation with Large Language Models.](http://arxiv.org/abs/2304.02210) | 本文以文档级机器翻译为试验场，深入评估了大型语言模型在语篇建模方面的性能。研究发现利用LLMs强大的长文本建模能力可以提高翻译质量，在提示方面进行改进也可以显着提高翻译质量，并且LLMs有潜力编码丰富的语篇知识。 |
| [^128] | [Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Methods.](http://arxiv.org/abs/2303.13988) | 本文提出了一种新领域——机器心理学，利用心理学的方法考察大型语言模型的能力。该文规范了机器心理学研究的方法论标准，并对心理实验中提示设计政策进行了探讨和制定。 |
| [^129] | [Label-Efficient Deep Learning in Medical Image Analysis: Challenges and Future Directions.](http://arxiv.org/abs/2303.12484) | 近年来深度学习在医学图像分析中取得了最先进的性能，但这种方法的标记代价大，标记不足。因此发展了高效标记深度学习方法，充分利用未标记的和弱标记的数据。该综述总结了这方面的最新进展。 |
| [^130] | [Consistency Analysis of ChatGPT.](http://arxiv.org/abs/2303.06273) | 本文研究了ChatGPT的一致性问题，发现尽管它具有更好的语言理解能力，但仍然经常无法生成逻辑上正确的预测。因此，在现实世界的应用需要进一步考虑，特别是在风险方面。 |
| [^131] | [Is ChatGPT a Good NLG Evaluator? A Preliminary Study.](http://arxiv.org/abs/2303.04048) | 通过针对任务特定和方面特定，我们在五个NLG元评估数据集上进行实验，表明ChatGPT作为NLG评估指标并不总是与人类评估相一致，尤其是在流畅度方面。这提醒人们在使用ChatGPT作为唯一的自动NLG评估指标时要谨慎。 |
| [^132] | [CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a Context Synergized Hyperbolic Network.](http://arxiv.org/abs/2303.03387) | CoSyn是一个上下文协同的神经网络，用于检测在线对话中的隐含仇恨言论。它通过引入新的编码方法和上下文交互机制，在双曲空间中进行操作，以适应社交媒体的特点。 |
| [^133] | [Zero-Shot Cross-Lingual Summarization via Large Language Models.](http://arxiv.org/abs/2302.14229) | 本文实验性地使用各种提示来指导大型语言模型从不同的范式执行零样本跨语言摘要，并成功提高了它们的CLS性能。其中，GPT-4实现了零样本CLS的最先进性能，并且在性能方面与最佳方法相当。 |
| [^134] | [Rethinking Semi-Supervised Medical Image Segmentation: A Variance-Reduction Perspective.](http://arxiv.org/abs/2302.01735) | 本文提出了ARCO，一种半监督对比学习（CL）框架，其中包括医学图像分割中的分层组采样理论。通过方差缩减估计的概念来构建ARCO，并表明某些方差缩减技术在医学图像分割中特别有益。 |
| [^135] | [Learning Large-scale Neural Fields via Context Pruned Meta-Learning.](http://arxiv.org/abs/2302.00617) | 通过上下文修剪元学习实现大规模神经场训练的优化， 显著节省内存，并能在短时间内学习高质量神经场。 |
| [^136] | [Batch Prompting: Efficient Inference with Large Language Model APIs.](http://arxiv.org/abs/2301.08721) | 批量提示是一种简单但有效的方法，可以降低使用大型语言模型进行推断的计算和财务成本，同时保持下游性能。理论上证明，在少样本情况下，批量样本数量的增加几乎以倒数线性关系降低了推断成本。在多个数据集上的验证实验证明了批量提示的有效性，并且对于最先进的Chat-based LLMs，如GPT-3.5和GPT-4，批量提示也具有好处。 |
| [^137] | [On the Shift Invariance of Max Pooling Feature Maps in Convolutional Neural Networks.](http://arxiv.org/abs/2209.11740) | 本文研究了卷积神经网络中最大池化特征图的位移不变性问题，并提出了一种近似复数模的条件，实现了位移稳定性。实验证实了理论的有效性。 |
| [^138] | [DenseShift: Towards Accurate and Efficient Low-Bit Power-of-Two Quantization.](http://arxiv.org/abs/2208.09708) | DenseShift网络是一种准确和高效的低位幂乘法量化方法，通过改进Shift网络的精度和引入非量化浮点激活来提高性能。 |
| [^139] | [Unsupervised Video Domain Adaptation for Action Recognition: A Disentanglement Perspective.](http://arxiv.org/abs/2208.07365) | 本文基于解缠视角处理视频领域无监督自适应问题，通过逐步解缠静态和动态信息并使用多种约束方法，有效地移除空间领域特定信息和减少时间领域差异，实验结果验证了该方法的有效性和优越性。 |
| [^140] | [Anomaly Detection in Echocardiograms with Dynamic Variational Trajectory Models.](http://arxiv.org/abs/2206.15316) | 本文提出了一种用于心脏超声视频的新颖异常检测方法，利用心脏周期性特性，在婴儿心脏超声视频数据集上训练了三种变分潜在轨迹模型，可可靠地识别严重的先天性心脏缺陷，并取得了较好的性能。 |
| [^141] | [JAMES: Normalizing Job Titles with Multi-Aspect Graph Embeddings and Reasoning.](http://arxiv.org/abs/2202.10739) | JAMES是一个用于岗位职称规范化的解决方案，它通过构建三种独特嵌入和使用协同注意机制和神经逻辑推理表示来有效地捕捉岗位职称的各种特征，并解决了语义相似性、非规范化用户创建的职称以及实际应用中大规模和长尾分布的岗位职称等挑战。 |
| [^142] | [HEAM: High-Efficiency Approximate Multiplier Optimization for Deep Neural Networks.](http://arxiv.org/abs/2201.08022) | 本文提出了一种优化方法，用于自动设计近似乘法器，并根据操作数分布来最小化平均误差。所提乘法器在DNN中达到了比最佳复制的近似乘法器高达50.24%的准确性，同时具有较小的面积、功耗和延迟。 |
| [^143] | [Simplest Streaming Trees.](http://arxiv.org/abs/2110.08483) | 我们提出了最简单的决策树扩展，通过继续生长现有树来更新它们，并用新树替换一些旧树来控制总树的数量。在72个分类问题的基准套件中，我们的方法在精度和内存使用方面表现优异。 |
| [^144] | [Bellman-consistent Pessimism for Offline Reinforcement Learning.](http://arxiv.org/abs/2106.06926) | 本文提出了Bellman一致的悲观论述的概念，用于离线强化学习中的函数逼近，通过在与Bellman方程一致的函数集合上实施初始状态的悲观主义，改善了基于奖励的悲观主义方法的样本复杂性。 |
| [^145] | [Provenance for the Description Logic ELHr.](http://arxiv.org/abs/2001.07541) | 本文研究了ELHr描述逻辑中处理溯源信息的问题，通过使用溯源标记、溯源多项式以及假设半环具有乘法幂等性来解决合取操作带来的困难。我们分析了ELHr的语义，并研究了带溯源的本体补全、计算与后果相关的公理集合和查询回答三个问题。 |

# 详细

[^1]: AdaptiX - 一个用于助动力机器人中开发和评估共同控制应用的过渡性XR框架

    AdaptiX -- A Transitional XR Framework for Development and Evaluation of Shared Control Applications in Assistive Robotics. (arXiv:2310.15887v1 [cs.HC])

    [http://arxiv.org/abs/2310.15887](http://arxiv.org/abs/2310.15887)

    AdaptiX是一个过渡性的XR框架，用于开发和评估助动力机器人中的共同控制应用。它提供了一个高分辨率仿真环境，并结合了用户自主性和计算机辅助。

    

    随着人们授权行动受限和技术接受度的提高，如合作机器臂等助动技术正在变得流行。然而，它们的普及成功受到可用性问题的限制，尤其是用户输入与软件控制在自主性连续性方面的差异。为了解决这个问题，共同控制概念提供了将有针对性地增加用户自主性与一定程度的计算机辅助相结合的机会。本文介绍了一个名为AdaptiX的免费开源XR框架，用于在高分辨率仿真环境中开发和评估共同控制应用。初始框架包括一个虚拟现实（VR）中的示例情景下的模拟机器臂、多种标准控制接口和一个专门的记录/回放系统。AdaptiX可以轻松扩展以满足特定的研究需求，允许进行人机交互（HRI）研究。

    With the ongoing efforts to empower people with mobility impairments and the increase in technological acceptance by the general public, assistive technologies, such as collaborative robotic arms, are gaining popularity. Yet, their widespread success is limited by usability issues, specifically the disparity between user input and software control along the autonomy continuum. To address this, shared control concepts provide opportunities to combine the targeted increase of user autonomy with a certain level of computer assistance. This paper presents the free and open-source AdaptiX XR framework for developing and evaluating shared control applications in a high-resolution simulation environment. The initial framework consists of a simulated robotic arm with an example scenario in Virtual Reality (VR), multiple standard control interfaces, and a specialized recording/replay system. AdaptiX can easily be extended for specific research needs, allowing Human-Robot Interaction (HRI) resea
    
[^2]: KirchhoffNet：一种连接消息传递和连续深度模型的电路桥接神经网络

    KirchhoffNet: A Circuit Bridging Message Passing and Continuous-Depth Models. (arXiv:2310.15872v1 [cs.LG])

    [http://arxiv.org/abs/2310.15872](http://arxiv.org/abs/2310.15872)

    本文提出了一种称为基赫霍夫网络的神经网络模型，利用基赫霍夫电流定律与消息传递神经网络和连续深度网络建立连接。在MNIST数据集上，基赫霍夫网络可以实现接近98.86%的测试准确度，且具有在硬件上实现的潜力。无论网络参数数量如何，其正向计算都可以在1/f秒内完成，具有快速计算的硬件特性。

    

    在本文中，我们利用了模拟电路的基本原理基赫霍夫电流定律，引入了一类独特的神经网络模型，称为基赫霍夫网络。基赫霍夫网络与消息传递神经网络和连续深度网络建立了密切联系。我们证明，即使在没有任何传统层（如卷积、池化或线性层）的情况下，基赫霍夫网络在MNIST数据集上取得了98.86%的测试准确度，与最先进的结果相当。让基赫霍夫网络更加有趣的是其在硬件领域的潜力。当代深度神经网络通常部署在GPU上。相反，基赫霍夫网络可以通过模拟电路来实现。此外，我们证明了无论在基赫霍夫网络内有多少参数，其正向计算都可以在1/f秒内完成，其中f表示硬件的时钟频率。这种特性表明，基赫霍夫网络具有潜力实现快速计算的硬件。

    In this paper, we exploit a fundamental principle of analog electronic circuitry, Kirchhoff's current law, to introduce a unique class of neural network models that we refer to as KirchhoffNet. KirchhoffNet establishes close connections with message passing neural networks and continuous-depth networks. We demonstrate that even in the absence of any traditional layers (such as convolution, pooling, or linear layers), KirchhoffNet attains 98.86% test accuracy on the MNIST dataset, comparable with state of the art (SOTA) results. What makes KirchhoffNet more intriguing is its potential in the realm of hardware. Contemporary deep neural networks are conventionally deployed on GPUs. In contrast, KirchhoffNet can be physically realized by an analog electronic circuit. Moreover, we justify that irrespective of the number of parameters within a KirchhoffNet, its forward calculation can always be completed within 1/f seconds, with f representing the hardware's clock frequency. This characteris
    
[^3]: 面向推荐的拓扑感知去偏向自监督图学习

    Topology-aware Debiased Self-supervised Graph Learning for Recommendation. (arXiv:2310.15858v1 [cs.IR])

    [http://arxiv.org/abs/2310.15858](http://arxiv.org/abs/2310.15858)

    面向推荐的拓扑感知去偏向自监督图学习（TDSGL）通过构建对比对，考虑用户（物品）的语义相似性，解决了推荐系统中负采样策略导致的错误负样本和忽略正样本的问题。

    

    在推荐系统中，基于图的协同过滤方法通过引入图对比学习来缓解数据稀疏性。然而，这些基于图对比学习的协同过滤模型中的随机负采样策略忽视了用户（物品）的语义结构，这不仅引入了错误的负样本（与锚定用户（物品）相似的负样本），还忽略了潜在的正样本。为了解决上述问题，我们提出了面向推荐的拓扑感知去偏向自监督图学习（TDSGL），根据用户（物品）之间的语义相似性构建对比对。具体而言，由于原始的用户-物品交互数据很好地反映了用户的购买意图和物品的某些特征，我们在交互数据上计算用户（物品）之间的语义相似性。然后，给定一个用户（物品），我们通过选择嵌入不同语义结构的用户（物品）来构建其负样本对，以确保去偏向性。

    In recommendation, graph-based Collaborative Filtering (CF) methods mitigate the data sparsity by introducing Graph Contrastive Learning (GCL). However, the random negative sampling strategy in these GCL-based CF models neglects the semantic structure of users (items), which not only introduces false negatives (negatives that are similar to anchor user (item)) but also ignores the potential positive samples. To tackle the above issues, we propose Topology-aware Debiased Self-supervised Graph Learning (TDSGL) for recommendation, which constructs contrastive pairs according to the semantic similarity between users (items). Specifically, since the original user-item interaction data commendably reflects the purchasing intent of users and certain characteristics of items, we calculate the semantic similarity between users (items) on interaction data. Then, given a user (item), we construct its negative pairs by selecting users (items) which embed different semantic structures to ensure the
    
[^4]: 使用人工法语数据，了解Transformer语言模型中性别偏见的出现

    Using Artificial French Data to Understand the Emergence of Gender Bias in Transformer Language Models. (arXiv:2310.15852v1 [cs.CL])

    [http://arxiv.org/abs/2310.15852](http://arxiv.org/abs/2310.15852)

    本文使用人工法语数据生成的语料库，探索了神经语言模型如何发现单词的性别属性以及其使用规则，并研究了模型在不同条件下是否正确捕捉到性别信息或表现出性别偏见。

    

    许多研究已经证明神经语言模型在没有直接监督的情况下能够学习各种语言属性。本文首次着手探索神经模型如何发现单词的语言属性（如性别）以及规则的使用方法，这是一个相对少有研究的话题。我们提出使用由基于法语的PCFG生成的人工语料库，精确控制训练数据中的性别分布，并确定模型在哪种条件下能正确捕捉到性别信息，或者相反，显示出性别偏见。

    Numerous studies have demonstrated the ability of neural language models to learn various linguistic properties without direct supervision. This work takes an initial step towards exploring the less researched topic of how neural models discover linguistic properties of words, such as gender, as well as the rules governing their usage. We propose to use an artificial corpus generated by a PCFG based on French to precisely control the gender distribution in the training data and determine under which conditions a model correctly captures gender information or, on the contrary, appears gender-biased.
    
[^5]: 使用条件变分推断进行动态PET成像的后验估计

    Posterior Estimation for Dynamic PET imaging using Conditional Variational Inference. (arXiv:2310.15850v1 [physics.med-ph])

    [http://arxiv.org/abs/2310.15850](http://arxiv.org/abs/2310.15850)

    本文提出了一个基于深度学习的框架，用于有效估计动态PET成像中的后验分布。通过引入潜在变量来对抗前向过程中的信息损失，并使用条件变分自编码器进行优化，我们能够用简单的多元高斯分布推断出后验概率。

    

    本文旨在有效地估计动态正电子发射断层成像（PET）中动力学参数的后验分布，给定时间-活性曲线的测量。考虑到使用前向动态模型从参数成像到测量空间中的固有信息损失，反向映射是模糊的。传统（但昂贵）的解决方法可以是马尔可夫链蒙特卡罗（MCMC）采样，已知可产生无偏的渐近估计。我们提出了一个基于深度学习的框架，用于高效的后验估计。具体而言，我们通过引入潜在变量来对抗前向过程中的信息损失。然后，我们使用一个条件变分自编码器（CVAE）并优化其证据下界。经过良好训练的解码器能够根据给定的测量和采样的潜在变量推断出后验概率，后验概率遵循一个简单的多元高斯分布。我们使用无偏的MCMC验证了我们CVAE的方法。

    This work aims efficiently estimating the posterior distribution of kinetic parameters for dynamic positron emission tomography (PET) imaging given a measurement of time of activity curve. Considering the inherent information loss from parametric imaging to measurement space with the forward kinetic model, the inverse mapping is ambiguous. The conventional (but expensive) solution can be the Markov Chain Monte Carlo (MCMC) sampling, which is known to produce unbiased asymptotical estimation. We propose a deep-learning-based framework for efficient posterior estimation. Specifically, we counteract the information loss in the forward process by introducing latent variables. Then, we use a conditional variational autoencoder (CVAE) and optimize its evidence lower bound. The well-trained decoder is able to infer the posterior with a given measurement and the sampled latent variables following a simple multivariate Gaussian distribution. We validate our CVAE-based method using unbiased MCMC
    
[^6]: 一种用于新意图发现的扩散加权图框架

    A Diffusion Weighted Graph Framework for New Intent Discovery. (arXiv:2310.15836v1 [cs.CL])

    [http://arxiv.org/abs/2310.15836](http://arxiv.org/abs/2310.15836)

    本研究提出了一种名为Diffusion Weighted Graph Framework (DWGF)的方法，用于捕捉数据中的语义相似性和结构关系，从而实现更充分和可靠的监督信号，解决了以往方法在新意图发现中无法平衡数量和质量的问题。

    

    新意图发现旨在通过有限的带有已知意图的标记数据的帮助，识别出未标记数据中的新意图和已知意图。以前的方法未考虑样本之间的结构关系，生成的噪声监督信号无法在数量和质量之间取得平衡，阻碍了新意图聚类的形成和预训练知识的有效传递。为了缓解这一限制，我们提出了一种新颖的扩散加权图框架（DWGF），以捕捉数据中的语义相似性和结构关系，从而实现更充分和可靠的监督信号。具体而言，对于每个样本，我们沿着由最近邻指导的语义路径扩散邻域关系，以鉴别地刻画其局部结构。然后，我们根据语义相似性和局部结构对其正样本进行抽样和加权，用于对比学习。

    New Intent Discovery (NID) aims to recognize both new and known intents from unlabeled data with the aid of limited labeled data containing only known intents. Without considering structure relationships between samples, previous methods generate noisy supervisory signals which cannot strike a balance between quantity and quality, hindering the formation of new intent clusters and effective transfer of the pre-training knowledge. To mitigate this limitation, we propose a novel Diffusion Weighted Graph Framework (DWGF) to capture both semantic similarities and structure relationships inherent in data, enabling more sufficient and reliable supervisory signals. Specifically, for each sample, we diffuse neighborhood relationships along semantic paths guided by the nearest neighbors for multiple hops to characterize its local structure discriminately. Then, we sample its positive keys and weigh them based on semantic similarities and local structures for contrastive learning. During inferen
    
[^7]: 《重度增强、高分辨率3D ResUNet自动主动脉分割：对SEG.A挑战的贡献》翻译

    Automatic Aorta Segmentation with Heavily Augmented, High-Resolution 3-D ResUNet: Contribution to the SEG.A Challenge. (arXiv:2310.15827v1 [cs.CV])

    [http://arxiv.org/abs/2310.15827](http://arxiv.org/abs/2310.15827)

    重度增强、高分辨率3D ResUNet自动主动脉分割在SEG.A挑战中取得了优异的成绩，达到了所有测试案例0.9以上的Dice分数，并在稳定性上超过了其他参与者。它在临床评估、定量结果和体积网格质量方面名列前茅。

    

    从3D医学图像中自动分割主动脉是一项重要但困难的任务。许多因素使得这个问题具有挑战性，比如主动脉夹层的可能性或者对小分支进行分割和注释的困难。本文介绍了MedGIFT团队在MICCAI 2023会议期间组织的SEG.A挑战中的一项贡献。我们提出了一种基于深度编码-解码器架构的全自动算法。我们的工作的主要假设是在低数据情况下，数据预处理和增强比深度架构更重要。因此，解决方案基于传统的卷积U-Net的变体。提出的解决方案在所有测试案例中都实现了0.9以上的Dice分数，并且在所有参与者中具有最高的稳定性。该方法在临床评估、定量结果和体积网格质量方面分别排名第一、第四和第三。我们免费公开源代码，

    Automatic aorta segmentation from 3-D medical volumes is an important yet difficult task. Several factors make the problem challenging, e.g. the possibility of aortic dissection or the difficulty with segmenting and annotating the small branches. This work presents a contribution by the MedGIFT team to the SEG.A challenge organized during the MICCAI 2023 conference. We propose a fully automated algorithm based on deep encoder-decoder architecture. The main assumption behind our work is that data preprocessing and augmentation are much more important than the deep architecture, especially in low data regimes. Therefore, the solution is based on a variant of traditional convolutional U-Net. The proposed solution achieved a Dice score above 0.9 for all testing cases with the highest stability among all participants. The method scored 1st, 4th, and 3rd in terms of the clinical evaluation, quantitative results, and volumetric meshing quality, respectively. We freely release the source code,
    
[^8]: Rosetta Stone在KSAA-RD共享任务中：从语言建模到词--定义对齐的跃进。

    Rosetta Stone at KSAA-RD Shared Task: A Hop From Language Modeling To Word--Definition Alignment. (arXiv:2310.15823v1 [cs.CL])

    [http://arxiv.org/abs/2310.15823](http://arxiv.org/abs/2310.15823)

    本论文介绍了在KSAA-RD共享任务中Rosetta Stone的应用，将语言建模应用到词--定义对齐中。论文通过使用一组微调的阿拉伯BERT模型来预测给定定义的词嵌入，从而实现了阿拉伯词的向量表示。

    

    反向词典是一种工具，可根据提供的定义、含义或描述来发现一个词。这种技术在各种场景中都非常有价值，可以帮助掌握一个词的描述而不知其身份的语言学习者，并使寻求精确术语的写作者受益。这些场景通常涵盖被称为“舌尖上的词”现象。在这项工作中，我们呈现了我们在阿拉伯语反向词典共享任务中获胜的解决方案。该任务的重点是从伴随的描述中推导出阿拉伯词的向量表示。共享任务包括两个不同的子任务：第一个子任务涉及一个阿拉伯定义作为输入，而第二个子任务则使用一个英文定义。对于第一个子任务，我们的方法依赖于一组经过微调的阿拉伯BERT模型，来预测给定定义的词嵌入。最终表示是通过对每个模型输出的嵌入进行平均得到的。

    A Reverse Dictionary is a tool enabling users to discover a word based on its provided definition, meaning, or description. Such a technique proves valuable in various scenarios, aiding language learners who possess a description of a word without its identity, and benefiting writers seeking precise terminology. These scenarios often encapsulate what is referred to as the "Tip-of-the-Tongue" (TOT) phenomena. In this work, we present our winning solution for the Arabic Reverse Dictionary shared task. This task focuses on deriving a vector representation of an Arabic word from its accompanying description. The shared task encompasses two distinct subtasks: the first involves an Arabic definition as input, while the second employs an English definition. For the first subtask, our approach relies on an ensemble of finetuned Arabic BERT-based models, predicting the word embedding for a given definition. The final representation is obtained through averaging the output embeddings from each m
    
[^9]: 判别器引导下的自回归扩散模型

    Discriminator Guidance for Autoregressive Diffusion Models. (arXiv:2310.15817v1 [cs.LG])

    [http://arxiv.org/abs/2310.15817](http://arxiv.org/abs/2310.15817)

    本文引入了判别器引导，用于自回归扩散模型的训练，通过使用最优判别器来纠正预训练模型，并提出了一个顺序蒙特卡洛算法来应对使用次优判别器的情况。在生成分子图的任务中，判别器引导有助于提高生成性能。

    

    我们在自回归扩散模型中引入了判别器引导。在连续扩散模型中，使用判别器引导扩散过程的方法已经被使用过，本文中，我们推导了在离散情况下使用判别器和预训练生成模型的方法。首先，我们证明使用最优判别器将纠正预训练模型，并能够从底层数据分布中精确采样。其次，为了应对使用次优判别器的实际情况，我们推导了一个顺序蒙特卡洛算法，该算法在生成过程中迭代地将判别器的预测纳入考虑。我们将这些方法应用于生成分子图的任务，并展示了判别器相较于仅使用预训练模型时的生成性能提升。

    We introduce discriminator guidance in the setting of Autoregressive Diffusion Models. The use of a discriminator to guide a diffusion process has previously been used for continuous diffusion models, and in this work we derive ways of using a discriminator together with a pretrained generative model in the discrete case. First, we show that using an optimal discriminator will correct the pretrained model and enable exact sampling from the underlying data distribution. Second, to account for the realistic scenario of using a sub-optimal discriminator, we derive a sequential Monte Carlo algorithm which iteratively takes the predictions from the discrimiator into account during the generation process. We test these approaches on the task of generating molecular graphs and show how the discriminator improves the generative performance over using only the pretrained model.
    
[^10]: DALE: 用于低资源法律NLP的生成式数据增强

    DALE: Generative Data Augmentation for Low-Resource Legal NLP. (arXiv:2310.15799v1 [cs.CL])

    [http://arxiv.org/abs/2310.15799](http://arxiv.org/abs/2310.15799)

    DALE是一个用于低资源法律NLP的生成式数据增强框架，通过基于选择性掩码的无监督文本去噪目标预训练，在解决法律语言特异性的同时生成连贯且多样化的增强。

    

    我们提出了DALE，一个针对低资源法律NLP的新颖有效的生成式数据增强框架。DALE解决了现有框架在生成法律文件的有效数据增强方面存在的挑战 - 法律语言具有专门的词汇和复杂的语义、形态和句法，并不能从仅仅对源句子进行改述的数据增强中受益。为了解决这个问题，DALE是基于编码器-解码器语言模型构建的，它在一种新颖的无监督文本去噪目标上进行了预训练，该目标基于选择性掩码 - 我们的掩码策略利用模板化法律文件的领域特定语言特征来掩盖文本的连续范围。去噪这些范围有助于DALE获取关于法律概念、原则和语言使用的知识。因此，它具备了生成连贯且多样化的增强以及新颖上下文的能力。最后，DALE进行条件生成，用于生成合成增强。

    We present DALE, a novel and effective generative Data Augmentation framework for low-resource LEgal NLP. DALE addresses the challenges existing frameworks pose in generating effective data augmentations of legal documents - legal language, with its specialized vocabulary and complex semantics, morphology, and syntax, does not benefit from data augmentations that merely rephrase the source sentence. To address this, DALE, built on an Encoder-Decoder Language Model, is pre-trained on a novel unsupervised text denoising objective based on selective masking - our masking strategy exploits the domain-specific language characteristics of templatized legal documents to mask collocated spans of text. Denoising these spans helps DALE acquire knowledge about legal concepts, principles, and language usage. Consequently, it develops the ability to generate coherent and diverse augmentations with novel contexts. Finally, DALE performs conditional generation to generate synthetic augmentations for 
    
[^11]: 随机实体量化用于参数高效的组合知识图谱表示

    Random Entity Quantization for Parameter-Efficient Compositional Knowledge Graph Representation. (arXiv:2310.15797v1 [cs.AI])

    [http://arxiv.org/abs/2310.15797](http://arxiv.org/abs/2310.15797)

    本文研究了参数高效的组合知识图谱表示的问题，通过随机实体量化的方法，可以达到与当前策略类似的效果，这是因为随机实体量化下，实体码有更高的熵和码字级别的Jaccard距离，使得不同实体更容易区分，从而有效地表示知识图谱。

    

    知识图谱（KG）上的表示学习对下游任务至关重要。主导方法KG嵌入（KGE）通过独立向量表示实体，面临可扩展性挑战。最近的研究提出了一种参数效率的替代方法，通过从预定义的小规模码书中匹配实体对应的码字来表示实体。我们将获取每个实体对应码字的过程称为实体量化，先前的工作设计了复杂的策略。令人惊讶的是，本文表明简单的随机实体量化可以实现与当前策略类似的结果。我们分析了这种现象并揭示了在随机实体量化下，表示实体的量化结果-实体码具有更高的熵和码字级别的Jaccard距离。因此，不同实体更容易区分，有助于有效的KG表示。

    Representation Learning on Knowledge Graphs (KGs) is essential for downstream tasks. The dominant approach, KG Embedding (KGE), represents entities with independent vectors and faces the scalability challenge. Recent studies propose an alternative way for parameter efficiency, which represents entities by composing entity-corresponding codewords matched from predefined small-scale codebooks. We refer to the process of obtaining corresponding codewords of each entity as entity quantization, for which previous works have designed complicated strategies. Surprisingly, this paper shows that simple random entity quantization can achieve similar results to current strategies. We analyze this phenomenon and reveal that entity codes, the quantization outcomes for expressing entities, have higher entropy at the code level and Jaccard distance at the codeword level under random entity quantization. Therefore, different entities become more easily distinguished, facilitating effective KG represen
    
[^12]: 通过学习前缀子空间改进大型语言模型的泛化能力

    Improving generalization in large language models by learning prefix subspaces. (arXiv:2310.15793v1 [cs.LG])

    [http://arxiv.org/abs/2310.15793](http://arxiv.org/abs/2310.15793)

    本文提出了一种通过学习前缀子空间来改进大型语言模型的泛化能力的方法。我们通过联合优化模型参数空间中的整个单纯形模型，在稀缺数据环境中实现了更广的局部最优解。这种方法在预训练变换器模型中表现出了很好的兼容性和有效性。

    

    本文关注于大型语言模型（LLMs）在稀缺数据环境中的微调（也被称为“少样本”学习设置）。我们提出了一种基于神经网络子空间的方法来增加LLMs的泛化能力。这种优化方法最近在计算机视觉领域中引入，旨在通过在参数空间中的整个单纯形模型的联合优化，识别更广的局部最优解，从而提高模型的泛化能力。然而，将其适应于大规模预训练变换器模型则面临一些挑战。首先，它们大量的参数使得联合训练多个模型变得困难，其次，它们的确定性参数初始化方案使其不适用于最初的子空间方法。我们在本文中展示，“参数高效微调”（PEFT）方法与最初的方法完全兼容，并提出学习整个连续前缀的单纯形。我们在实验证明了这个方法在大型语言模型的泛化上的有效性。

    This article focuses on large language models (LLMs) fine-tuning in the scarce data regime (also known as the "few-shot" learning setting). We propose a method to increase the generalization capabilities of LLMs based on neural network subspaces. This optimization method, recently introduced in computer vision, aims to improve model generalization by identifying wider local optima through the joint optimization of an entire simplex of models in parameter space. Its adaptation to massive, pretrained transformers, however, poses some challenges. First, their considerable number of parameters makes it difficult to train several models jointly, and second, their deterministic parameter initialization schemes make them unfit for the subspace method as originally proposed. We show in this paper that "Parameter Efficient Fine-Tuning" (PEFT) methods, however, are perfectly compatible with this original approach, and propose to learn entire simplex of continuous prefixes. We test our method on 
    
[^13]: SequenceMatch: 重新考虑强弱增强设计的半监督学习方法

    SequenceMatch: Revisiting the design of weak-strong augmentations for Semi-supervised learning. (arXiv:2310.15787v1 [cs.CV])

    [http://arxiv.org/abs/2310.15787](http://arxiv.org/abs/2310.15787)

    SequenceMatch是一种半监督学习方法，通过引入中等增强方法和不同的一致性约束，帮助减小了模型对弱增强和强增强示例的预测分布之间的差异，提高了数据效率。

    

    近年来，半监督学习（SSL）因其可以利用大量未标记数据进行模型训练而变得流行。然而，许多SSL方法面临的一个问题是确认偏差，即当模型过度拟合小型标记训练数据集并产生自信但错误的预测时。为了解决这个问题，我们提出了SequenceMatch，一种高效的SSL方法，它利用多种数据增强方法。SequenceMatch的关键是为未标记的数据引入了中等增强方法。通过利用不同的增强方法和每对增强示例之间的一致性约束，SequenceMatch帮助缩小了模型对弱增强和强增强示例的预测分布之间的差异。此外，SequenceMatch为高置信度和低置信度的预测定义了两种不同的一致性约束。因此，SequenceMatch比ReMixMatch更具数据效率。

    Semi-supervised learning (SSL) has become popular in recent years because it allows the training of a model using a large amount of unlabeled data. However, one issue that many SSL methods face is the confirmation bias, which occurs when the model is overfitted to the small labeled training dataset and produces overconfident, incorrect predictions. To address this issue, we propose SequenceMatch, an efficient SSL method that utilizes multiple data augmentations. The key element of SequenceMatch is the inclusion of a medium augmentation for unlabeled data. By taking advantage of different augmentations and the consistency constraints between each pair of augmented examples, SequenceMatch helps reduce the divergence between the prediction distribution of the model for weakly and strongly augmented examples. In addition, SequenceMatch defines two different consistency constraints for high and low-confidence predictions. As a result, SequenceMatch is more data-efficient than ReMixMatch, an
    
[^14]: 增强MRI扫描隐私的3D遮罩自编码器

    3D Masked Autoencoders for Enhanced Privacy in MRI Scans. (arXiv:2310.15778v1 [cs.CV])

    [http://arxiv.org/abs/2310.15778](http://arxiv.org/abs/2310.15778)

    本研究提出了一种名为CP-MAE的模型，通过使用面部遮罩来实现MRI扫描中的人脸去识别，提高了隐私保护水平。

    

    MRI扫描提供有价值的医学信息，但也包含敏感和可识别个人信息（PII），需要保护。传统的MRI数据去识别方法通过删除隐私敏感部位（如眼睛、鼻子等）来实现，但会引入领域转换，影响下游分析。本文提出了CP-MAE模型，通过面部遮罩来实现人脸去识别。

    MRI scans provide valuable medical information, however they also contain sensitive and personally identifiable information (PII) that needs to be protected. Whereas MRI metadata is easily sanitized, MRI image data is a privacy risk because it contains information to render highly-realistic 3D visualizations of a patient's head, enabling malicious actors to possibly identify the subject by cross-referencing a database. Data anonymization and de-identification is concerned with ensuring the privacy and confidentiality of individuals' personal information. Traditional MRI de-identification methods remove privacy-sensitive parts (e.g. eyes, nose etc.) from a given scan. This comes at the expense of introducing a domain shift that can throw off downstream analyses. Recently, a GAN-based approach was proposed to de-identify a patient's scan by remodeling it (e.g. changing the face) rather than by removing parts. In this work, we propose CP-MAE, a model that de-identifies the face using mask
    
[^15]: MindLLM: 从零开始预训练轻量级大型语言模型，评估和领域应用

    MindLLM: Pre-training Lightweight Large Language Model from Scratch, Evaluations and Domain Applications. (arXiv:2310.15777v1 [cs.CL])

    [http://arxiv.org/abs/2310.15777](http://arxiv.org/abs/2310.15777)

    本文提出了一种从零开始训练的轻量级大型语言模型MindLLM，通过提供1.3亿和3亿参数的模型，减轻了训练和部署大型语言模型的成本和资源稀缺性的压力。MindLLM在各个步骤中给出了经验教训，包括数据构建、模型架构、评估和应用，对学术界和开发者来说具有重要价值。

    

    大型语言模型（LLM）在各种自然语言任务中展现出了出色的性能，标志着通往通用人工智能的重要进展。虽然通用人工智能是通过开发越来越大规模的模型来实现的，但还有另一种分支，即开发轻量级定制模型，以更好地服务某些领域，考虑到训练和部署LLM的高成本和资源的稀缺性。在本文中，我们提出MindLLM，一系列新颖的双语轻量级大型语言模型，从零开始训练，通过提供13亿和30亿参数的模型来减轻这些负担。给出了在大模型开发过程中积累的经验全面的分析，包括数据构建、模型架构、评估和应用。这些见解对学者和开发者来说有价值。MindLLM始终能够与甚至超过最先进的模型性能。

    Large Language Models (LLMs) have demonstrated remarkable performance across various natural language tasks, marking significant strides towards general artificial intelligence. While general artificial intelligence is leveraged by developing increasingly large-scale models, there could be another branch to develop lightweight custom models that better serve certain domains, taking into account the high cost of training and deploying LLMs and the scarcity of resources. In this paper, we present MindLLM, a novel series of bilingual lightweight large language models, trained from scratch, alleviating such burdens by offering models with 1.3 billion and 3 billion parameters. A thorough account of experiences accrued during large model development is given, covering every step of the process, including data construction, model architecture, evaluation, and applications. Such insights are hopefully valuable for fellow academics and developers. MindLLM consistently matches or surpasses the p
    
[^16]: 用户在社交媒体上分享仇恨言论的因果理解

    Causal Understanding of Why Users Share Hate Speech on Social Media. (arXiv:2310.15772v1 [cs.SI])

    [http://arxiv.org/abs/2310.15772](http://arxiv.org/abs/2310.15772)

    本文研究了用户为何分享社交媒体上的仇恨言论，提出了一个因果分析框架，通过消除数据偏差和模拟用户脆弱性来揭示影响用户分享行为的因素。

    

    社交媒体上的仇恨言论威胁到个人的心理和身体健康，并且进一步导致现实中的暴力事件。仇恨言论传播背后的重要驱动因素是转发，但是人们很少了解为什么用户会转发仇恨言论。本文提供了一个全面、因果分析的用户属性框架，研究用户为何分享仇恨言论。然而，在从社交媒体数据中进行因果推断时存在一些挑战，因为这类数据很可能存在选择偏差，并且用户对仇恨言论的脆弱性存在混淆。我们开发了一个新颖的三步因果框架：（1）我们通过逆向倾向评分来消除观察性社交媒体数据的偏差。（2）我们使用消除偏差的倾向评分来模拟用户对仇恨言论的潜在脆弱性作为潜在嵌入。（3）我们建立了用户属性对用户分享仇恨言论概率的因果效应模型。

    Hate speech on social media threatens the mental and physical well-being of individuals and is further responsible for real-world violence. An important driver behind the spread of hate speech and thus why hateful posts can go viral are reshares, yet little is known about why users reshare hate speech. In this paper, we present a comprehensive, causal analysis of the user attributes that make users reshare hate speech. However, causal inference from observational social media data is challenging, because such data likely suffer from selection bias, and there is further confounding due to differences in the vulnerability of users to hate speech. We develop a novel, three-step causal framework: (1) We debias the observational social media data by applying inverse propensity scoring. (2) We use the debiased propensity scores to model the latent vulnerability of users to hate speech as a latent embedding. (3) We model the causal effects of user attributes on users' probability of sharing h
    
[^17]: 通过简单的集成投影器消除偏见、校准和改进半监督学习性能

    Debiasing, calibrating, and improving Semi-supervised Learning performance via simple Ensemble Projector. (arXiv:2310.15764v1 [cs.CV])

    [http://arxiv.org/abs/2310.15764](http://arxiv.org/abs/2310.15764)

    本研究提出了一种简单的方法，通过集成投影器在半监督学习中改进了嵌入，从而提高了性能。

    

    最近关于半监督学习（SSL）的研究取得了很大的成功。尽管现有的最新方法在性能上很有前景，但它们往往倾向于通过引入更多的网络组件和额外的训练过程来获得越来越复杂的设计。在本文中，我们提出了一种简单的方法，名为集成投影器辅助半监督学习（EPASS），主要关注于改进学习的嵌入以提高现有对比联合训练半监督学习框架的性能。与标准方法不同，EPASS将多个投影器的集合嵌入存储在存储器中，以供对比学习时使用。结果，EPASS改善了泛化能力，加强了特征表示，并提高了性能。例如，EPASS将半监督学习的强基线的top-1错误率提高了39.47\%/31.39\%/24.70\%。

    Recent studies on semi-supervised learning (SSL) have achieved great success. Despite their promising performance, current state-of-the-art methods tend toward increasingly complex designs at the cost of introducing more network components and additional training procedures. In this paper, we propose a simple method named Ensemble Projectors Aided for Semi-supervised Learning (EPASS), which focuses mainly on improving the learned embeddings to boost the performance of the existing contrastive joint-training semi-supervised learning frameworks. Unlike standard methods, where the learned embeddings from one projector are stored in memory banks to be used with contrastive learning, EPASS stores the ensemble embeddings from multiple projectors in memory banks. As a result, EPASS improves generalization, strengthens feature representation, and boosts performance. For instance, EPASS improves strong baselines for semi-supervised learning by 39.47\%/31.39\%/24.70\% top-1 error rate, while usi
    
[^18]: 将语言模型集成到直接语音翻译中：控制性别变化的推断时间解决方案

    Integrating Language Models into Direct Speech Translation: An Inference-Time Solution to Control Gender Inflection. (arXiv:2310.15752v1 [cs.CL])

    [http://arxiv.org/abs/2310.15752](http://arxiv.org/abs/2310.15752)

    该论文提出了一种推断时间解决方案，用于在语音翻译中控制与说话者相关的性别变化。通过部分替换内部语言模型，将特定性别的外部语言模型应用于翻译过程，实验证明这一方法在性别准确性方面优于基准模型和最佳训练时间缓解策略，尤其在具有性别冲突的条件下效果显著提高。

    

    在翻译与说话者相关的词语时，语音翻译系统应该避免使用默认的男性泛用词，也不应依赖可能具有误导性的声音特征。相反，它们应该根据说话者的偏好来确定性别。现有的解决方案虽然有效，但在实践中很难实现，因为它们涉及对带有性别标签的语音翻译数据进行专门的模型重新训练。为了克服这些局限性，我们提出了第一个能够推断控制与说话者相关的性别变化的解决方案。我们的方法部分替换了语音翻译解码器隐含学习的（有偏见的）内部语言模型（LM），使用了特定性别的外部LM。通过对en->es/fr/it的实验结果表明，我们的解决方案在性别准确性方面优于基准模型和最佳训练时间缓解策略，对女性形式的提高分别达到了31.0和1.6个百分点。在具有挑战性的条件中，说话者的声音特征引发了性别冲突，这些增益甚至更大（分别为32.0和3.4）。

    When translating words referring to the speaker, speech translation (ST) systems should not resort to default masculine generics nor rely on potentially misleading vocal traits. Rather, they should assign gender according to the speakers' preference. The existing solutions to do so, though effective, are hardly feasible in practice as they involve dedicated model re-training on gender-labeled ST data. To overcome these limitations, we propose the first inference-time solution to control speaker-related gender inflections in ST. Our approach partially replaces the (biased) internal language model (LM) implicitly learned by the ST decoder with gender-specific external LMs. Experiments on en->es/fr/it show that our solution outperforms the base models and the best training-time mitigation strategy by up to 31.0 and 1.6 points in gender accuracy, respectively, for feminine forms. The gains are even larger (up to 32.0 and 3.4) in the challenging condition where speakers' vocal traits confli
    
[^19]: 循环线性变换器

    Recurrent Linear Transformers. (arXiv:2310.15719v1 [cs.LG])

    [http://arxiv.org/abs/2310.15719](http://arxiv.org/abs/2310.15719)

    本文提出了循环线性变换器作为transformer自注意机制的替代方案，解决了transformers在处理长距离依赖关系和推断成本方面的限制。在强化学习问题中的实验证明了其有效性和可行性。

    

    transformer架构中的自注意机制能够捕捉长距离的依赖关系，这也是其在处理序列数据时有效的主要原因。然而，尽管其成功，transformers仍然有两个重大缺点，限制了其更广泛的适用性：(1)为了记住过去的信息，自注意机制需要访问整个历史信息作为上下文。(2)transformers的推断成本很高。本文提出了对transformer自注意机制的循环替代方案，其具有独立于上下文的推断成本并有效地利用长距离依赖关系，在实践中表现良好。我们在强化学习问题中评估了我们的方法，在这些问题中，上述计算限制几乎使得transformers的应用不可行。我们在一个诊断环境中量化了我们架构中不同部分的影响。

    The self-attention mechanism in the transformer architecture is capable of capturing long-range dependencies and it is the main reason behind its effectiveness in processing sequential data. Nevertheless, despite their success, transformers have two significant drawbacks that still limit their broader applicability: (1) In order to remember past information, the self-attention mechanism requires access to the whole history to be provided as context. (2) The inference cost in transformers is expensive. In this paper we introduce recurrent alternatives to the transformer self-attention mechanism that offer a context-independent inference cost, leverage long-range dependencies effectively, and perform well in practice. We evaluate our approaches in reinforcement learning problems where the aforementioned computational limitations make the application of transformers nearly infeasible. We quantify the impact of the different components of our architecture in a diagnostic environment and as
    
[^20]: 用深度强化学习生成多样化调度策略来解决大型柔性车间调度实例

    Solving large flexible job shop scheduling instances by generating a diverse set of scheduling policies with deep reinforcement learning. (arXiv:2310.15706v1 [cs.AI])

    [http://arxiv.org/abs/2310.15706](http://arxiv.org/abs/2310.15706)

    本文提出了一种能够通过生成多样化的调度策略来解决大型柔性车间调度实例的方法，并应用深度强化学习来优化调度质量。

    

    柔性车间调度问题（FJSSP）在文献中得到了广泛研究，提出了许多启发式、精确和元启发式方法。然而，工业对实时响应突发事件的需求产生了在几秒内生成新调度的必要性。在这些方法中，只有调度规则（DRs）能够在约束下生成调度，尽管其质量可以得到改进。为了改善结果，最近的方法将FJSSP建模为马尔可夫决策过程（MDP），并应用强化学习生成一个策略，将操作分配到机器上生成最优解。然而，在大型的FJSSP实例中仍然有改进的空间，而这在实际情况中很常见。因此，本文的目标是提出一种能够稳健解决大型FJSSP实例的方法。

    The Flexible Job Shop Scheduling Problem (FJSSP) has been extensively studied in the literature, and multiple approaches have been proposed within the heuristic, exact, and metaheuristic methods. However, the industry's demand to be able to respond in real-time to disruptive events has generated the necessity to be able to generate new schedules within a few seconds. Among these methods, under this constraint, only dispatching rules (DRs) are capable of generating schedules, even though their quality can be improved. To improve the results, recent methods have been proposed for modeling the FJSSP as a Markov Decision Process (MDP) and employing reinforcement learning to create a policy that generates an optimal solution assigning operations to machines. Nonetheless, there is still room for improvement, particularly in the larger FJSSP instances which are common in real-world scenarios. Therefore, the objective of this paper is to propose a method capable of robustly solving large insta
    
[^21]: 基于学习的无线网络信息准确性和新鲜度调度

    Learning-based Scheduling for Information Accuracy and Freshness in Wireless Networks. (arXiv:2310.15705v1 [cs.AI])

    [http://arxiv.org/abs/2310.15705](http://arxiv.org/abs/2310.15705)

    本文研究了基于学习的无线网络调度问题，通过比较四种标准的赌博机策略的性能，以提高信息准确性和新鲜度。

    

    本文考虑了一个多源、单通信信道和单个监测站的系统。每个源都以不同准确度测量一个时间变化的数量，其中一个源通过信道将其更新发送到监测站。每次尝试通信的成功概率取决于被调度用于传输更新的源。调度器不知道所有源的测量正确性和传输成功概率。我们关注的度量是系统接收到的奖励，该奖励取决于目的地收到的最后一次更新的准确性和信息年龄（Age-of-Information，AoI）。我们将调度问题建模为多臂赌博机问题的一种变体，其中各个源作为不同的臂。通过模拟，我们比较了所有四种标准的赌博机策略，即ETC、epsilon-greedy、UCB和TS在我们的系统模型下适当调整后的性能。

    We consider a system of multiple sources, a single communication channel, and a single monitoring station. Each source measures a time-varying quantity with varying levels of accuracy and one of them sends its update to the monitoring station via the channel. The probability of success of each attempted communication is a function of the source scheduled for transmitting its update. Both the probability of correct measurement and the probability of successful transmission of all the sources are unknown to the scheduler. The metric of interest is the reward received by the system which depends on the accuracy of the last update received by the destination and the Age-of-Information (AoI) of the system. We model our scheduling problem as a variant of the multi-arm bandit problem with sources as different arms. We compare the performance of all $4$ standard bandit policies, namely, ETC, $\epsilon$-greedy, UCB, and TS suitably adjusted to our system model via simulations. In addition, we p
    
[^22]: 通过半监督学习实现自动菜谱类型分类

    Towards Automated Recipe Genre Classification using Semi-Supervised Learning. (arXiv:2310.15693v1 [cs.CL])

    [http://arxiv.org/abs/2310.15693](http://arxiv.org/abs/2310.15693)

    该论文提出了一个名为3A2M+的自动菜谱类型分类方法，通过半监督学习利用扩展的命名实体识别列表对烹饪食谱进行分类。研究者提供了一个包含两百万个带有各种特征和九个不同类型标签的烹饪食谱数据集，以解决缺乏标注数据的问题。

    

    分享烹饪食谱是交流烹饪创意和提供食物制作指引的好方法。然而，将在线找到的原始食谱分类为适当的食物类型可能会很具有挑战性，因为缺乏足够的标注数据。在本研究中，我们提出了一个名为“混合、典型和注释的扩展两百万（3A2M+）烹饪食谱数据集”的数据集，其中包含两百万个被标记为相应类别的烹饪食谱，并提取了食谱描述中的扩展命名实体。这个数据集包括标题、命名实体识别、步骤和扩展命名实体等各种特征，以及代表糕点、饮料、非素食、蔬菜、快餐、谷物、主食、配菜和融合的九个不同类型的标签。所提出的名为3A2M+的流程通过使用两种命名实体识别工具，扩展了命名实体识别（NER）列表的大小，以解决从食谱步骤中缺少的命名实体，如加热、时间或过程。

    Sharing cooking recipes is a great way to exchange culinary ideas and provide instructions for food preparation. However, categorizing raw recipes found online into appropriate food genres can be challenging due to a lack of adequate labeled data. In this study, we present a dataset named the ``Assorted, Archetypal, and Annotated Two Million Extended (3A2M+) Cooking Recipe Dataset" that contains two million culinary recipes labeled in respective categories with extended named entities extracted from recipe descriptions. This collection of data includes various features such as title, NER, directions, and extended NER, as well as nine different labels representing genres including bakery, drinks, non-veg, vegetables, fast food, cereals, meals, sides, and fusions. The proposed pipeline named 3A2M+ extends the size of the Named Entity Recognition (NER) list to address missing named entities like heat, time or process from the recipe directions using two NER extraction tools. 3A2M+ dataset
    
[^23]: 利用引文文献中的知识聚合改进生物医学摘要总结

    Improving Biomedical Abstractive Summarisation with Knowledge Aggregation from Citation Papers. (arXiv:2310.15684v1 [cs.CL])

    [http://arxiv.org/abs/2310.15684](http://arxiv.org/abs/2310.15684)

    该论文提出了一种基于引文聚合的模型，通过整合引文论文中的领域特定知识，提高了生物医学摘要总结的语言模型的性能。

    

    生物医学文献中的摘要具有特定的领域特征，包括专门的写作风格和生物医学术语，这要求对相关文献有深入的理解。因此，现有的语言模型在生成与生物医学专家相媲美的技术摘要时存在困难，缺乏领域特定的背景知识。本论文旨在通过聚合源论文中引用的外部论文中的知识，提高生物医学摘要总结的语言模型的性能。我们提出了一种新颖的基于注意力的引文聚合模型，它将引文论文中的领域特定知识与论文内容相结合，使神经网络能够利用论文内容和引文论文中的相关知识生成摘要。此外，我们还构建并发布了一个大规模的生物医学摘要总结数据集作为我们研究的基础。

    Abstracts derived from biomedical literature possess distinct domain-specific characteristics, including specialised writing styles and biomedical terminologies, which necessitate a deep understanding of the related literature. As a result, existing language models struggle to generate technical summaries that are on par with those produced by biomedical experts, given the absence of domain-specific background knowledge. This paper aims to enhance the performance of language models in biomedical abstractive summarisation by aggregating knowledge from external papers cited within the source article. We propose a novel attention-based citation aggregation model that integrates domain-specific knowledge from citation papers, allowing neural networks to generate summaries by leveraging both the paper content and relevant knowledge from citation papers. Furthermore, we construct and release a large-scale biomedical summarisation dataset that serves as a foundation for our research. Extensiv
    
[^24]: 多模态3D场景理解的最新进展：一项全面调查和评估

    Recent Advances in Multi-modal 3D Scene Understanding: A Comprehensive Survey and Evaluation. (arXiv:2310.15676v1 [cs.CV])

    [http://arxiv.org/abs/2310.15676](http://arxiv.org/abs/2310.15676)

    多模态3D场景理解在自动驾驶和人机交互等领域中应用广泛。本文从理论的角度对多模态3D方法的进展进行了全面调查和评估。

    

    多模态3D场景理解因其在自动驾驶和人机交互等许多领域中的广泛应用而受到了广泛关注。与传统的单模态3D理解相比，引入额外的模态不仅提升了场景解释的丰富性和准确性，还确保了更稳健和弹性的理解。这在多样化和具有挑战性的环境中尤为关键，仅依靠3D数据可能是不足够的。尽管在过去三年中出现了许多多模态3D方法的发展，特别是那些整合多摄像头图像（3D+2D）和文本描述（3D+语言）的方法，但缺乏全面深入的评估。在本文中，我们对最近的进展进行了系统的调查，以填补这一空白。我们首先简要介绍了一个背景，正式定义了各种3D多模态任务，并总结了它们固有的挑战。

    Multi-modal 3D scene understanding has gained considerable attention due to its wide applications in many areas, such as autonomous driving and human-computer interaction. Compared to conventional single-modal 3D understanding, introducing an additional modality not only elevates the richness and precision of scene interpretation but also ensures a more robust and resilient understanding. This becomes especially crucial in varied and challenging environments where solely relying on 3D data might be inadequate. While there has been a surge in the development of multi-modal 3D methods over past three years, especially those integrating multi-camera images (3D+2D) and textual descriptions (3D+language), a comprehensive and in-depth review is notably absent. In this article, we present a systematic survey of recent progress to bridge this gap. We begin by briefly introducing a background that formally defines various 3D multi-modal tasks and summarizes their inherent challenges. After that
    
[^25]: LLMs生成内容检测综述

    A Survey on Detection of LLMs-Generated Content. (arXiv:2310.15654v1 [cs.CL])

    [http://arxiv.org/abs/2310.15654](http://arxiv.org/abs/2310.15654)

    该论文是关于LLMs生成内容检测的综述，提供了现有策略和挑战的概述，并提倡采用更灵活和强大的模型以提高检测准确性，并强调使用多方面的方法来应对不同攻击。这是首个综合调查LLMs时代检测的工作。

    

    先进的大型语言模型（LLMs）如ChatGPT的不断发展，导致合成内容生成不断增加，涉及媒体、网络安全、公共话语和教育等多个领域。因此，检测LLMs生成内容的能力变得至关重要。我们旨在提供现有检测策略和基准的详细概述，审查它们的差异，并确定领域中的关键挑战和前景，提倡采用更灵活和强大的模型以提高检测准确性。我们还主张采用多方面的方法应对不同攻击，以抵御LLMs不断发展的能力。据我们所知，这项工作是LLMs时代检测的首个综合调查。我们希望它能够提供对LLMs生成内容检测当前情况的广泛理解，并为研究该领域提供参考。

    The burgeoning capabilities of advanced large language models (LLMs) such as ChatGPT have led to an increase in synthetic content generation with implications across a variety of sectors, including media, cybersecurity, public discourse, and education. As such, the ability to detect LLMs-generated content has become of paramount importance. We aim to provide a detailed overview of existing detection strategies and benchmarks, scrutinizing their differences and identifying key challenges and prospects in the field, advocating for more adaptable and robust models to enhance detection accuracy. We also posit the necessity for a multi-faceted approach to defend against various attacks to counter the rapidly advancing capabilities of LLMs. To the best of our knowledge, this work is the first comprehensive survey on the detection in the era of LLMs. We hope it will provide a broad understanding of the current landscape of LLMs-generated content detection, offering a guiding reference for res
    
[^26]: 使用简历表示学习和基于技能匹配的职业路径预测

    Career Path Prediction using Resume Representation Learning and Skill-based Matching. (arXiv:2310.15636v1 [cs.CL])

    [http://arxiv.org/abs/2310.15636](http://arxiv.org/abs/2310.15636)

    本论文在职业路径预测中提出了一种使用简历表示学习和基于技能匹配的方法，通过研究文本描述部分来预测下一步的职业动向，并在数据集上验证了该方法的有效性。

    

    人-职业匹配对工作满意度和工作绩效的影响被广泛承认，这凸显了在职业生涯中为工作者提供下一步行动的重要性。职业路径预测是预测职业生涯中的下一步行动的任务，并具有员工流失预防和内部岗位流动等多种应用。现有的职业路径预测方法依赖于大量的私人职业历史数据来建模职位和公司之间的交互作用。我们提出利用简历中的工作经历部分的未开发的文本描述。我们介绍了一个由2,164个匿名化职业经历组成的结构化数据集，并带有ESCO职业标签。基于这个数据集，我们提出了一个专门为工作历史数据设计的新颖表示学习方法CareerBERT。我们开发了基于技能和基于文本的模型来进行职业路径预测，在@10下，技能模型和文本模型实现了35.24%和39.61%的召回率。

    The impact of person-job fit on job satisfaction and performance is widely acknowledged, which highlights the importance of providing workers with next steps at the right time in their career. This task of predicting the next step in a career is known as career path prediction, and has diverse applications such as turnover prevention and internal job mobility. Existing methods to career path prediction rely on large amounts of private career history data to model the interactions between job titles and companies. We propose leveraging the unexplored textual descriptions that are part of work experience sections in resumes. We introduce a structured dataset of 2,164 anonymized career histories, annotated with ESCO occupation labels. Based on this dataset, we present a novel representation learning approach, CareerBERT, specifically designed for work history data. We develop a skill-based model and a text-based model for career path prediction, which achieve 35.24% and 39.61% recall@10 r
    
[^27]: 使用Slisemap解释物理数据

    Using Slisemap to interpret physical data. (arXiv:2310.15610v1 [cs.LG])

    [http://arxiv.org/abs/2310.15610](http://arxiv.org/abs/2310.15610)

    Slisemap是一种结合了流形可视化和可解释人工智能的方法，可以帮助我们在物理数据中找到有意义的信息。

    

    流形可视化技术通常用于在物理科学中可视化高维数据集。本文将一种最近介绍的流形可视化方法Slise应用于物理和化学数据集。Slisemap将流形可视化与可解释的人工智能相结合，用于研究黑盒机器学习模型和复杂模拟器的决策过程。通过Slisemap，我们找到一种嵌入，使得具有类似局部解释的数据项被聚集在一起。因此，Slisemap为我们提供了黑盒模型不同行为的概览。这使得Slisemap成为一种有监督的流形可视化方法，其中嵌入的模式反映了目标属性。本文展示了如何在物理数据上使用和评估Slisemap，并证明Slisemap在找到分类和回归模型的有意义信息方面是有帮助的。

    Manifold visualisation techniques are commonly used to visualise high-dimensional datasets in physical sciences. In this paper we apply a recently introduced manifold visualisation method, called Slise, on datasets from physics and chemistry. Slisemap combines manifold visualisation with explainable artificial intelligence. Explainable artificial intelligence is used to investigate the decision processes of black box machine learning models and complex simulators. With Slisemap we find an embedding such that data items with similar local explanations are grouped together. Hence, Slisemap gives us an overview of the different behaviours of a black box model. This makes Slisemap into a supervised manifold visualisation method, where the patterns in the embedding reflect a target property. In this paper we show how Slisemap can be used and evaluated on physical data and that Slisemap is helpful in finding meaningful information on classification and regression models trained on these data
    
[^28]: tagE: 让具身代理理解人类指令的方法

    tagE: Enabling an Embodied Agent to Understand Human Instructions. (arXiv:2310.15605v1 [cs.RO])

    [http://arxiv.org/abs/2310.15605](http://arxiv.org/abs/2310.15605)

    tagE是一种能够从自然语言指令中提取任务的具身代理系统，解决了智能代理理解人类意图时的歧义性和不完整性问题。

    

    自然语言是具有物理存在的智能代理与人类交流的主要方式。尽管有大量关注自然语言理解（NLU）的研究，如情感分析、意图预测、问题回答和摘要，但面向具身代理需要实际行动的情境的NLU的范围仍然有限。自然语言中的歧义性和不完整性给智能代理解读人类意图带来了挑战。为了应对这个问题，我们引入了一种新颖的系统，称为具身代理的任务和参数基础（tagE）。在核心部分，我们的系统采用了一种创新的神经网络模型，用以从用自然语言表达的复杂任务指令中提取一系列任务。我们提出的模型采用了一种编码器-解码器框架，加强了嵌套解码以有效地提取任务。

    Natural language serves as the primary mode of communication when an intelligent agent with a physical presence engages with human beings. While a plethora of research focuses on natural language understanding (NLU), encompassing endeavors such as sentiment analysis, intent prediction, question answering, and summarization, the scope of NLU directed at situations necessitating tangible actions by an embodied agent remains limited. The inherent ambiguity and incompleteness inherent in natural language present challenges for intelligent agents striving to decipher human intention. To tackle this predicament head-on, we introduce a novel system known as task and argument grounding for Embodied agents (tagE). At its core, our system employs an inventive neural network model designed to extract a series of tasks from complex task instructions expressed in natural language. Our proposed model adopts an encoder-decoder framework enriched with nested decoding to effectively extract tasks and t
    
[^29]: 交互式素描问答中的紧急沟通

    Emergent Communication in Interactive Sketch Question Answering. (arXiv:2310.15597v1 [cs.AI])

    [http://arxiv.org/abs/2310.15597](http://arxiv.org/abs/2310.15597)

    本文研究了基于视觉的紧急沟通，提出了一个新颖的交互式素描问答任务，通过多轮交互实现了智能agent之间的有针对性、高效的沟通，并具有较好的人类可解释性。

    

    基于视觉的紧急沟通（EC）旨在通过素描学习沟通，并揭示人类沟通的演变过程。然而，以前的研究忽视了多轮交互，在人类沟通中是不可或缺的。为了填补这一空白，我们首先引入了一项新颖的交互式素描问答（ISQA）任务，其中两个合作玩家通过素描进行多轮交互，以回答关于一张图片的问题。为了完成这个任务，我们设计了一个新的高效的交互式EC系统，它可以在问题回答准确性、绘画复杂度和人类可解释性这三个评估因素之间取得有效平衡。我们的实验结果，包括人类评估，表明多轮交互机制能够促进智能agent之间的有针对性、高效的沟通，并具有较好的人类可解释性。

    Vision-based emergent communication (EC) aims to learn to communicate through sketches and demystify the evolution of human communication. Ironically, previous works neglect multi-round interaction, which is indispensable in human communication. To fill this gap, we first introduce a novel Interactive Sketch Question Answering (ISQA) task, where two collaborative players are interacting through sketches to answer a question about an image in a multi-round manner. To accomplish this task, we design a new and efficient interactive EC system, which can achieve an effective balance among three evaluation factors, including the question answering accuracy, drawing complexity and human interpretability. Our experimental results including human evaluation demonstrate that multi-round interactive mechanism facilitates targeted and efficient communication between intelligent agents with decent human interpretability.
    
[^30]: 检索式知识转移：一种高效的极大规模语言模型压缩方法

    Retrieval-based Knowledge Transfer: An Effective Approach for Extreme Large Language Model Compression. (arXiv:2310.15594v1 [cs.CL])

    [http://arxiv.org/abs/2310.15594](http://arxiv.org/abs/2310.15594)

    检索式知识转移（RetriKT）是一种新的压缩范例，它通过提取大规模预训练语言模型的知识并利用 retrieval-based 的方法，将这些知识应用于极小规模的模型中，从而实现了极端的模型压缩效果。

    

    大规模预训练语言模型在各种自然语言处理任务中展现出卓越的性能。然而，这些模型的巨大规模给它们在实际应用中的部署带来了巨大挑战。尽管已经提出了许多模型压缩技术，但对于在模型规模存在显著差距时实现极端模型压缩并不适用。在本文中，我们引入了一种新的压缩范例，称为检索式知识转移（RetriKT），它将LLM的知识有效地转移到极小规模的模型（例如1%）。具体而言，我们的方法从LLM中提取知识构建知识存储，并从中检索相关信息，利用它进行有效的推理。为了提高模型的质量，我们采用了软提示调整和近端策略优化（PPO）增强学习技术。进行了广泛的实验验证。

    Large-scale pre-trained language models (LLMs) have demonstrated exceptional performance in various natural language processing (NLP) tasks. However, the massive size of these models poses huge challenges for their deployment in real-world applications. While numerous model compression techniques have been proposed, most of them are not well-suited for achieving extreme model compression when there is a significant gap in model scale. In this paper, we introduce a novel compression paradigm called Retrieval-based Knowledge Transfer (RetriKT), which effectively transfers the knowledge of LLMs to extremely small-scale models (e.g., 1%). In particular, our approach extracts knowledge from LLMs to construct a knowledge store, from which the small-scale model can retrieve relevant information and leverage it for effective inference. To improve the quality of the model, soft prompt tuning and Proximal Policy Optimization (PPO) reinforcement learning techniques are employed. Extensive experim
    
[^31]: 检测开放海域海上监视中的有意AIS关闭使用自监督深度学习

    Detecting Intentional AIS Shutdown in Open Sea Maritime Surveillance Using Self-Supervised Deep Learning. (arXiv:2310.15586v1 [cs.LG])

    [http://arxiv.org/abs/2310.15586](http://arxiv.org/abs/2310.15586)

    本论文提出了一种基于自监督深度学习技术和变压器模型的方法，用于检测开放海域海上监视中的有意AIS关闭。模型通过比较预测结果来报告检测到的异常情况。

    

    在海上交通监视中，检测非法活动，如非法捕鱼或非法货物转船是沿海管理的关键任务。在开放海域中，人们必须依赖船上的自动识别系统（AIS）发出的信息，这些信息被监视卫星捕获。然而，不诚实的船只通常会有意关闭其AIS发射机，以隐藏非法活动。在开放海上，很难将有意的AIS关闭与由于协议限制，恶劣天气条件或限制卫星位置而导致的接收缺失区分开来。本文提出了一种基于自监督深度学习技术和变压器模型的异常AIS接收丢失检测方法。通过使用历史数据，训练的模型预测未来一分钟是否应接收信息。然后，该模型通过比较预测结果来报告检测到的异常情况。

    In maritime traffic surveillance, detecting illegal activities, such as illegal fishing or transshipment of illicit products is a crucial task of the coastal administration. In the open sea, one has to rely on Automatic Identification System (AIS) message transmitted by on-board transponders, which are captured by surveillance satellites. However, insincere vessels often intentionally shut down their AIS transponders to hide illegal activities. In the open sea, it is very challenging to differentiate intentional AIS shutdowns from missing reception due to protocol limitations, bad weather conditions or restricting satellite positions. This paper presents a novel approach for the detection of abnormal AIS missing reception based on self-supervised deep learning techniques and transformer models. Using historical data, the trained model predicts if a message should be received in the upcoming minute or not. Afterwards, the model reports on detected anomalies by comparing the prediction w
    
[^32]: CONTRASTE: 一种带有基于方面的提示的监督对比预训练用于方面情感三元组抽取

    CONTRASTE: Supervised Contrastive Pre-training With Aspect-based Prompts For Aspect Sentiment Triplet Extraction. (arXiv:2310.15577v1 [cs.CL])

    [http://arxiv.org/abs/2310.15577](http://arxiv.org/abs/2310.15577)

    CONTRASTE是一种利用对比学习的预训练策略，通过设计基于方面的提示并应用对比学习来增强方面情感三元组抽取（ASTE）任务的性能，并在其他ABSA任务上展示出优势。

    

    现有的方面情感三元组抽取（ASTE）的研究主要关注如何开发更高效的微调技术。相反，我们的动机是提出一种通用方法，可以同时改善多个ABSA任务的效果。为此，我们提出了一种名为CONTRASTE的新型预训练策略，利用对比学习来增强ASTE的性能。我们除了主要关注ASTE之外，还展示了我们提出的技术在其他ABSA任务（如ACOS，TASD和AESC）上的优势。给定一个句子及其相关的（方面，观点，情感）三元组，首先，我们设计了基于方面的提示，并屏蔽了相应的情感。然后，我们通过对解码器生成的方面感知情感表示进行对比学习来（预）训练编码-解码模型。为了微调得到的模型权重，我们提出了一种新颖的多任务方法，其中基础编码解码模型同时被用于ASTG和其他ABSA任务。

    Existing works on Aspect Sentiment Triplet Extraction (ASTE) explicitly focus on developing more efficient fine-tuning techniques for the task. Instead, our motivation is to come up with a generic approach that can improve the downstream performances of multiple ABSA tasks simultaneously. Towards this, we present CONTRASTE, a novel pre-training strategy using CONTRastive learning to enhance the ASTE performance. While we primarily focus on ASTE, we also demonstrate the advantage of our proposed technique on other ABSA tasks such as ACOS, TASD, and AESC. Given a sentence and its associated (aspect, opinion, sentiment) triplets, first, we design aspect-based prompts with corresponding sentiments masked. We then (pre)train an encoder-decoder model by applying contrastive learning on the decoder-generated aspect-aware sentiment representations of the masked terms. For fine-tuning the model weights thus obtained, we then propose a novel multi-task approach where the base encoder-decoder mod
    
[^33]: SteloCoder:一种仅解码的用于多语言到Python代码翻译的LLM

    SteloCoder: a Decoder-Only LLM for Multi-Language to Python Code Translation. (arXiv:2310.15539v1 [cs.CL])

    [http://arxiv.org/abs/2310.15539](http://arxiv.org/abs/2310.15539)

    SteloCoder是一个仅解码的基于StarCoder的LLM，在多语言到Python代码翻译中取得了显著的性能提升。它采用Mixture-of-Experts（MoE）技术和门控网络，通过对StarCoder进行微调获得专家，并使用低秩自适应方法（LoRA）技术来限制每个专家的大小。

    

    最近关注大规模语言模型（LLM），StarCoder和Code Llama分别展示了在代码生成方面的出色性能。然而，在代码翻译功能上仍然需要改进和有效训练技术。为了解决这个问题，我们介绍了SteloCoder，一种仅解码的基于StarCoder的LLM，专为多编程语言到Python代码翻译而设计。具体而言，SteloCoder实现了C ++，C＃，JavaScript，Java或PHP到Python代码翻译，而无需指定输入编程语言。我们通过引入专家组混合（Mixture-of-Experts，MoE）技术和一个控制多任务的门控网络来修改StarCoder模型架构。我们通过对StarCoder进行微调来获得专家。具体而言，我们使用了低秩自适应方法（Low-Rank Adaptive Method，LoRA）技术，将每个专家的大小限制为StarCoder参数数量的仅0.06％。同时，为了增强tr

    With the recent focus on Large Language Models (LLMs), both StarCoder (Li et al., 2023) and Code Llama (Rozi\`ere et al., 2023) have demonstrated remarkable performance in code generation. However, there is still a need for improvement in code translation functionality with efficient training techniques. In response to this, we introduce SteloCoder, a decoder-only StarCoder-based LLM designed specifically for multi-programming language-to-Python code translation. In particular, SteloCoder achieves C++, C#, JavaScript, Java, or PHP-to-Python code translation without specifying the input programming language. We modified StarCoder model architecture by incorporating a Mixture-of-Experts (MoE) technique featuring five experts and a gating network for multi-task handling. Experts are obtained by StarCoder fine-tuning. Specifically, we use a Low-Rank Adaptive Method (LoRA) technique, limiting each expert size as only 0.06% of number of StarCoder's parameters. At the same time, to enhance tr
    
[^34]: 生成式和对比式范式在图自监督学习中互补

    Generative and Contrastive Paradigms Are Complementary for Graph Self-Supervised Learning. (arXiv:2310.15523v1 [cs.LG])

    [http://arxiv.org/abs/2310.15523](http://arxiv.org/abs/2310.15523)

    生成式和对比式范式在图自监督学习中是互补的，我们提出了图对比掩码自编码器（GCMAE）框架来统一它们，GCMAE通过利用对比学习的全局信息来弥补掩码自编码器在捕捉全局信息方面的不足。

    

    对于图自监督学习（GSSL），掩码自编码器（MAE）遵循生成式范式，并学习重构掩码图的边缘或节点特征。对比学习（CL）通过最大化同一图的增强视图之间的相似性来广泛用于GSSL。然而，MAE和CL在现有的GSSL工作中被单独考虑。我们观察到MAE和CL的范式是互补的，并提出了图对比掩码自编码器（GCMAE）框架来统一它们。具体而言，通过专注于局部边缘或节点特征，MAE不能捕捉到图的全局信息，并对特定的边缘和特征敏感。相反，在提取全局信息方面，CL表现出色，因为它考虑了图之间的关系。因此，我们将GCMAE装备了一个MAE分支和一个CL分支，并且这两个分支共享一个通用的编码器，这使得MAE分支能够利用CL分支提取的全局信息。为了强制GCMAE捕捉全局信息...

    For graph self-supervised learning (GSSL), masked autoencoder (MAE) follows the generative paradigm and learns to reconstruct masked graph edges or node features. Contrastive Learning (CL) maximizes the similarity between augmented views of the same graph and is widely used for GSSL. However, MAE and CL are considered separately in existing works for GSSL. We observe that the MAE and CL paradigms are complementary and propose the graph contrastive masked autoencoder (GCMAE) framework to unify them. Specifically, by focusing on local edges or node features, MAE cannot capture global information of the graph and is sensitive to particular edges and features. On the contrary, CL excels in extracting global information because it considers the relation between graphs. As such, we equip GCMAE with an MAE branch and a CL branch, and the two branches share a common encoder, which allows the MAE branch to exploit the global information extracted by the CL branch. To force GCMAE to capture glob
    
[^35]: 在信息检索中评估基于约束满足的LLMs

    KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval. (arXiv:2310.15511v1 [cs.LG])

    [http://arxiv.org/abs/2310.15511](http://arxiv.org/abs/2310.15511)

    本研究评估了最先进的模型在信息检索中回答约束满足查询的能力，并引入了一个新的数据集KITAB来衡量语言模型的约束满足能力。

    

    我们研究了最先进的模型在信息检索中回答约束满足查询（例如，“圣地亚哥的冰淇淋店列表”）的能力。过去，这样的查询被认为只能通过网络搜索或知识库来解决。最近，大型语言模型（LLMs）在这个任务中展示了初步的能力。然而，许多当前的检索基准要么已饱和，要么不能衡量约束满足。受到对LLMs事实不正确和产生幻觉的日益关注的驱动，我们提出了KITAB，一个用于衡量语言模型约束满足能力的新数据集。KITAB包含600多位作者和13,000个查询的与书籍相关的数据，还提供了一个关联的动态数据收集和约束验证方法，以获得其他作者的类似测试数据。我们对GPT4和GPT3.5进行了扩展实验，对常见的失败模式进行了表征和解耦。

    We study the ability of state-of-the art models to answer constraint satisfaction queries for information retrieval (e.g., 'a list of ice cream shops in San Diego'). In the past, such queries were considered to be tasks that could only be solved via web-search or knowledge bases. More recently, large language models (LLMs) have demonstrated initial emergent abilities in this task. However, many current retrieval benchmarks are either saturated or do not measure constraint satisfaction. Motivated by rising concerns around factual incorrectness and hallucinations of LLMs, we present KITAB, a new dataset for measuring constraint satisfaction abilities of language models. KITAB consists of book-related data across more than 600 authors and 13,000 queries, and also offers an associated dynamic data collection and constraint verification approach for acquiring similar test data for other authors. Our extended experiments on GPT4 and GPT3.5 characterize and decouple common failure modes acros
    
[^36]: 鲁棒的统一在线Top-K推荐的表示学习

    Robust Representation Learning for Unified Online Top-K Recommendation. (arXiv:2310.15492v1 [cs.IR])

    [http://arxiv.org/abs/2310.15492](http://arxiv.org/abs/2310.15492)

    本论文提出一种鲁棒的表示学习方法，用于统一在线Top-K推荐，在大规模工业电子商务中解决物品广告和内容广告的不一致性，以及跨不同领域的多实体广告的检索问题。

    

    在大规模工业电子商务中，在线推荐系统的效率对于提供高度相关的物品/内容广告以满足多样化的业务场景至关重要。然而，大部分现有研究仅关注物品广告，忽视了内容广告的重要性。这种疏忽导致了多实体结构内的不一致性和不公平检索。此外，从跨不同领域的多实体广告中检索Top-K广告的挑战也增加了复杂性。最近的研究证明，不同领域内的用户-实体行为表现出差异性和同质性特征。因此，多领域匹配模型通常依赖于具有领域不变和领域特定表示的混合专家框架。不幸的是，大多数方法主要关注优化不同专家的组合模式，未能解决优化中固有的困难点。

    In large-scale industrial e-commerce, the efficiency of an online recommendation system is crucial in delivering highly relevant item/content advertising that caters to diverse business scenarios. However, most existing studies focus solely on item advertising, neglecting the significance of content advertising. This oversight results in inconsistencies within the multi-entity structure and unfair retrieval. Furthermore, the challenge of retrieving top-k advertisements from multi-entity advertisements across different domains adds to the complexity. Recent research proves that user-entity behaviors within different domains exhibit characteristics of differentiation and homogeneity. Therefore, the multi-domain matching models typically rely on the hybrid-experts framework with domain-invariant and domain-specific representations. Unfortunately, most approaches primarily focus on optimizing the combination mode of different experts, failing to address the inherent difficulty in optimizin
    
[^37]: NuTrea：用于上下文引导的多跳知识图问答的神经树搜索

    NuTrea: Neural Tree Search for Context-guided Multi-hop KGQA. (arXiv:2310.15484v1 [cs.CL])

    [http://arxiv.org/abs/2310.15484](http://arxiv.org/abs/2310.15484)

    NuTrea是一个基于树搜索的GNN模型，用于上下文引导的多跳知识图问答。模型采用了消息传递方案来增强过去导向的嵌入，并引入了RF-IEF节点嵌入来更好地表征模糊的知识图节点。

    

    多跳的知识图问答是一项任务，涉及从知识图中检索节点以回答自然语言问题。最近基于GNN的方法将此任务形式化为一个知识图路径搜索问题，其中消息从种子节点沿着路径依次传播到答案节点。然而，这些消息都是过去导向的，并没有考虑到完整的知识图上下文。为了解决这些问题，我们提出了一种基于树搜索的GNN模型NuTrea，它将更广泛的知识图上下文纳入考虑。我们的模型采用了消息传递方案，探索未到达的子树区域以提升过去导向的嵌入。此外，我们还引入了关系频率-逆实体频率（RF-IEF）节点嵌入，以更好地表征模糊的知识图节点。

    Multi-hop Knowledge Graph Question Answering (KGQA) is a task that involves retrieving nodes from a knowledge graph (KG) to answer natural language questions. Recent GNN-based approaches formulate this task as a KG path searching problem, where messages are sequentially propagated from the seed node towards the answer nodes. However, these messages are past-oriented, and they do not consider the full KG context. To make matters worse, KG nodes often represent proper noun entities and are sometimes encrypted, being uninformative in selecting between paths. To address these problems, we propose Neural Tree Search (NuTrea), a tree search-based GNN model that incorporates the broader KG context. Our model adopts a message-passing scheme that probes the unreached subtree regions to boost the past-oriented embeddings. In addition, we introduce the Relation Frequency-Inverse Entity Frequency (RF-IEF) node embedding that considers the global KG context to better characterize ambiguous KG nodes
    
[^38]: AutoDiff:结合自动编码器和扩散模型用于表格数据合成

    AutoDiff: combining Auto-encoder and Diffusion model for tabular data synthesizing. (arXiv:2310.15479v1 [stat.ML])

    [http://arxiv.org/abs/2310.15479](http://arxiv.org/abs/2310.15479)

    使用自动编码器和扩散模型结合的AutoDiff模型可以有效地生成合成的表格数据，克服了表格数据中的异构特征和特征间相关性的挑战，生成的数据与真实数据在统计上非常相似，并在机器学习任务中表现良好。

    

    扩散模型已成为现代机器学习许多子领域中合成数据生成的主要范式，包括计算机视觉、语言模型或语音合成。在本文中，我们利用扩散模型的力量来生成合成的表格数据。表格数据中的异构特征一直是表格数据合成的主要障碍，我们通过使用自动编码器的架构来解决这个问题。与最先进的表格合成器相比，我们模型生成的合成表格在统计上与真实数据非常相似，并在机器学习工具的下游任务中表现良好。我们在15个公开可用的数据集上进行了实验。值得注意的是，我们的模型灵活地捕捉了特征之间的相关性，这是表格数据合成中长期存在的挑战。如若接纳了论文，我们的代码将根据要求提供，并且将公开发布。

    Diffusion model has become a main paradigm for synthetic data generation in many subfields of modern machine learning, including computer vision, language model, or speech synthesis. In this paper, we leverage the power of diffusion model for generating synthetic tabular data. The heterogeneous features in tabular data have been main obstacles in tabular data synthesis, and we tackle this problem by employing the auto-encoder architecture. When compared with the state-of-the-art tabular synthesizers, the resulting synthetic tables from our model show nice statistical fidelities to the real data, and perform well in downstream tasks for machine learning utilities. We conducted the experiments over 15 publicly available datasets. Notably, our model adeptly captures the correlations among features, which has been a long-standing challenge in tabular data synthesis. Our code is available upon request and will be publicly released if paper is accepted.
    
[^39]: 在可再生能源系统和电网优化中赋能分布式解决方案

    Empowering Distributed Solutions in Renewable Energy Systems and Grid Optimization. (arXiv:2310.15468v1 [cs.LG])

    [http://arxiv.org/abs/2310.15468](http://arxiv.org/abs/2310.15468)

    本研究探讨了从集中到分散的方法在电力行业中的转变，并重点讨论了机器学习对于可再生能源赋能和电网管理的关键作用。在预测可再生能源的产生和消耗方面，机器学习模型的应用变得越来越重要。将大数据和机器学习应用于智能电网可以提高能源效率、更好地响应需求和更好地整合可再生能源。然而，需要解决处理大数据量、网络安全和专业知识等挑战。

    

    本研究探讨了电力行业从集中式向分散式方法的转变，特别关注机器学习（ML）的进展在赋能可再生能源和改善电网管理方面的关键作用。ML模型在预测可再生能源的产生和消耗方面变得越来越重要，使用了人工神经网络、支持向量机和决策树等各种技术。此外，还采用了数据预处理方法，如数据分割、归一化、分解和离散化，以提高预测准确性。将大数据和ML融入智能电网具有多种优势，包括提高能源效率，更有效地应对需求，更好地整合可再生能源。然而，还需要解决处理大数据量、确保网络安全和获取专业知识等挑战。研究部分。

    This study delves into the shift from centralized to decentralized approaches in the electricity industry, with a particular focus on how machine learning (ML) advancements play a crucial role in empowering renewable energy sources and improving grid management. ML models have become increasingly important in predicting renewable energy generation and consumption, utilizing various techniques like artificial neural networks, support vector machines, and decision trees. Furthermore, data preprocessing methods, such as data splitting, normalization, decomposition, and discretization, are employed to enhance prediction accuracy.  The incorporation of big data and ML into smart grids offers several advantages, including heightened energy efficiency, more effective responses to demand, and better integration of renewable energy sources. Nevertheless, challenges like handling large data volumes, ensuring cybersecurity, and obtaining specialized expertise must be addressed. The research inves
    
[^40]: LLM引导下基于UI语法的UI布局生成

    UI Layout Generation with LLMs Guided by UI Grammar. (arXiv:2310.15455v1 [cs.HC])

    [http://arxiv.org/abs/2310.15455](http://arxiv.org/abs/2310.15455)

    本文探讨了利用LLMs生成UI布局的方法，引入了UI语法来改进生成过程的可解释性和可控性，初步实验表明这种方法有潜力生成高质量的用户界面。

    

    最近大型语言模型（LLM）的进展引起了研究人员和行业专业人员的兴趣，特别是在与移动用户界面（UI）相关的任务中应用LLMs。本文探讨了使用LLMs进行UI布局生成的方法。我们引入了UI语法作为我们提出的一种新颖方法，来表示UI屏幕中固有的分层结构。该方法的目的是更有效地指导LLMs的生成能力，提高生成过程的可解释性和可控性。我们使用GPT-4进行了初步实验，结果显示LLMs通过上下文学习有可能生成高质量的用户界面。此外，我们的初步比较研究表明基于语法的方法在特定方面有改进生成结果质量的潜力。

    The recent advances in Large Language Models (LLMs) have stimulated interest among researchers and industry professionals, particularly in their application to tasks concerning mobile user interfaces (UIs). This position paper investigates the use of LLMs for UI layout generation. Central to our exploration is the introduction of UI grammar -- a novel approach we proposed to represent the hierarchical structure inherent in UI screens. The aim of this approach is to guide the generative capacities of LLMs more effectively and improve the explainability and controllability of the process. Initial experiments conducted with GPT-4 showed the promising capability of LLMs to produce high-quality user interfaces via in-context learning. Furthermore, our preliminary comparative study suggested the potential of the grammar-based approach in improving the quality of generative results in specific aspects.
    
[^41]: PromptInfuser: 如何紧密结合AI和UI设计影响设计师的工作流程

    PromptInfuser: How Tightly Coupling AI and UI Design Impacts Designers' Workflows. (arXiv:2310.15435v1 [cs.HC])

    [http://arxiv.org/abs/2310.15435](http://arxiv.org/abs/2310.15435)

    本研究研究了如何将AI和UI设计紧密结合，开发了PromptInfuser插件，将提示与UI元素相连，通过与设计师现有的AI原型化工作流进行比较，发现PromptInfuser在传达产品理念、原型制作效率和问题预测方面更有用，鼓励设计师同时迭代提示和UI。

    

    原型化AI应用一直是困难的。虽然大型语言模型（LLM）的提示大大降低了AI原型化的障碍，但设计师仍然独立地原型化AI功能和UI。我们研究了提示和UI设计的耦合如何影响设计师的工作流程。在这项研究的基础上，我们开发了PromptInfuser，一个Figma插件，它可以使用户通过将UI元素连接到提示的输入和输出来创建半功能的模型。在与14位设计师的研究中，我们将PromptInfuser与设计师当前的AI原型化工作流进行了比较。PromptInfuser被认为在传达产品理念方面更有用，能够更真实地呈现设想的设计原型，原型制作更高效，并且在预测UI问题和技术限制方面更有帮助。PromptInfuser鼓励同时迭代提示和UI，这有助于设计师发现UI和提示的不兼容性。

    Prototyping AI applications is notoriously difficult. While large language model (LLM) prompting has dramatically lowered the barriers to AI prototyping, designers are still prototyping AI functionality and UI separately. We investigate how coupling prompt and UI design affects designers' workflows. Grounding this research, we developed PromptInfuser, a Figma plugin that enables users to create semi-functional mockups, by connecting UI elements to the inputs and outputs of prompts. In a study with 14 designers, we compare PromptInfuser to designers' current AI-prototyping workflow. PromptInfuser was perceived to be significantly more useful for communicating product ideas, more capable of producing prototypes that realistically represent the envisioned artifact, more efficient for prototyping, and more helpful for anticipating UI issues and technical constraints. PromptInfuser encouraged iteration over prompt and UI together, which helped designers identify UI and prompt incompatibilit
    
[^42]: ConstitutionMaker:通过将用户反馈转化为原则来对大型语言模型进行交互式批评

    ConstitutionMaker: Interactively Critiquing Large Language Models by Converting Feedback into Principles. (arXiv:2310.15428v1 [cs.HC])

    [http://arxiv.org/abs/2310.15428](http://arxiv.org/abs/2310.15428)

    ConstitutionMaker是一个交互式工具，通过帮助用户将他们的反馈转化为一组原则，从而对大型语言模型进行批评和调整，以改善聊天机器人的输出。

    

    大型语言模型（LLM）提示是一种让用户创建和定制自己的聊天机器人的新方法。然而，目前的引导聊天机器人输出的方法，如提示工程和微调，不支持用户将对模型输出的自然反馈转换为提示或模型的变化。在这项工作中，我们探讨了如何通过帮助用户将他们的反馈转化为一组原则（即宪法）来使用户能够通过反馈与改进模型输出进行交互。从一项形成性研究中，我们发现（1）用户需要支持将他们的反馈转化为聊天机器人的原则，并且（2）对用户所需的不同原则类型进行了分类。受到这些发现的启发，我们开发了ConstitutionMaker，这是一个将用户反馈转化为原则的交互式工具，用于引导基于LLM的聊天机器人。

    Large language model (LLM) prompting is a promising new approach for users to create and customize their own chatbots. However, current methods for steering a chatbot's outputs, such as prompt engineering and fine-tuning, do not support users in converting their natural feedback on the model's outputs to changes in the prompt or model. In this work, we explore how to enable users to interactively refine model outputs through their feedback, by helping them convert their feedback into a set of principles (i.e. a constitution) that dictate the model's behavior. From a formative study, we (1) found that users needed support converting their feedback into principles for the chatbot and (2) classified the different principle types desired by users. Inspired by these findings, we developed ConstitutionMaker, an interactive tool for converting user feedback into principles, to steer LLM-based chatbots. With ConstitutionMaker, users can provide either positive or negative feedback in natural l
    
[^43]: FANToM: 在交互中对机器心智理论进行压力测试的基准

    FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions. (arXiv:2310.15421v1 [cs.CL])

    [http://arxiv.org/abs/2310.15421](http://arxiv.org/abs/2310.15421)

    FANToM是一个新的基准，用于通过问答在信息不对称的对话环境中压力测试机器的心智理论。这个基准对最先进的大型语言模型来说具有挑战性，即使是具有思维链推理和微调的模型也比人类表现得差。

    

    目前关于心智理论（ToM）的评估主要集中在使用缺乏互动性的被动故事，我们介绍了FANToM，一个新的基准，通过问答在信息不对称的对话环境中进行心智理论的压力测试。我们的基准结合了心理学中的重要理论要求和对评估大型语言模型（LLM）时必要的经验考虑。特别地，我们制定了多种类型的问题，要求相同的基本推理来识别LLM中不存在或虚假的心智理论能力。我们展示了FANToM对最先进的LLM来说具有挑战性，即使是具有思维链推理和微调的LLM也表现比人类差得多。

    Theory of mind (ToM) evaluations currently focus on testing models using passive narratives that inherently lack interactivity. We introduce FANToM, a new benchmark designed to stress-test ToM within information-asymmetric conversational contexts via question answering. Our benchmark draws upon important theoretical requisites from psychology and necessary empirical considerations when evaluating large language models (LLMs). In particular, we formulate multiple types of questions that demand the same underlying reasoning to identify illusory or false sense of ToM capabilities in LLMs. We show that FANToM is challenging for state-of-the-art LLMs, which perform significantly worse than humans even with chain-of-thought reasoning or fine-tuning.
    
[^44]: 政策优化中的分形景观

    Fractal Landscapes in Policy Optimization. (arXiv:2310.15418v1 [cs.LG])

    [http://arxiv.org/abs/2310.15418](http://arxiv.org/abs/2310.15418)

    该论文研究了政策优化过程中非平滑或分形的优化景观，提出了一种理解策略梯度方法固有限制的框架，并开发了一种实用方法来识别训练过程中是否遇到分形景观。

    

    策略梯度是连续领域深度强化学习的核心。尽管取得了许多成功，但实践中经常观察到利用策略梯度进行RL训练可能因为多种原因而失败，甚至在已知解的标准控制问题中也是如此。我们提出了一个框架来理解策略梯度方法的一个固有限制：对于某些类别的MDPs，策略空间中的优化景观可以非常非平滑或分形，以至于根本不存在需要估计的梯度。我们借鉴混沌理论和非平滑分析的方法，分析了策略优化目标的最大Lyapunov指数和Hölder指数。此外，我们还开发了一种实用方法，可以从样本中估计目标函数的局部平滑性，以便识别训练过程是否遇到分形景观。我们展示了实验来说明一些策略优化失败的情况。

    Policy gradient lies at the core of deep reinforcement learning (RL) in continuous domains. Despite much success, it is often observed in practice that RL training with policy gradient can fail for many reasons, even on standard control problems with known solutions. We propose a framework for understanding one inherent limitation of the policy gradient approach: the optimization landscape in the policy space can be extremely non-smooth or fractal for certain classes of MDPs, such that there does not exist gradient to be estimated in the first place. We draw on techniques from chaos theory and non-smooth analysis, and analyze the maximal Lyapunov exponents and H\"older exponents of the policy optimization objectives. Moreover, we develop a practical method that can estimate the local smoothness of objective function from samples to identify when the training process has encountered fractal landscapes. We show experiments to illustrate how some failure cases of policy optimization can b
    
[^45]: 基于点/顺序重构的命名分数条件时间序列异常检测

    Nominality Score Conditioned Time Series Anomaly Detection by Point/Sequential Reconstruction. (arXiv:2310.15416v1 [cs.LG])

    [http://arxiv.org/abs/2310.15416](http://arxiv.org/abs/2310.15416)

    本文提出了一种利用基于点/顺序重构模型的框架来进行无监督时间序列异常检测的方法。通过计算重构误差的组合值之比得到命名分数, 进一步结合命名分数和异常分数导出感应异常分数，从而实现对点异常和上下文异常的量化和检测。

    

    由于复杂性和多样性模式的存在，时间序列异常检测是具有挑战性的。一个主要的困难在于建模时间相关的关系以寻找上下文异常，同时保持对点异常的检测准确性。在本文中，我们提出了一个无监督时间序列异常检测的框架，利用了基于点和序列的重构模型。基于点的模型试图量化点异常，而基于序列的模型试图量化点异常和上下文异常。在假设观察到的时间点是从一种标准时间点开始的两个阶段的偏离值的情况下，我们引入了一个由重构误差的组合值之比计算得出的命名分数。我们通过进一步整合命名分数和异常分数来导出感应异常分数，然后在特定条件下理论上证明了感应异常分数优于原始异常分数的优越性。

    Time series anomaly detection is challenging due to the complexity and variety of patterns that can occur. One major difficulty arises from modeling time-dependent relationships to find contextual anomalies while maintaining detection accuracy for point anomalies. In this paper, we propose a framework for unsupervised time series anomaly detection that utilizes point-based and sequence-based reconstruction models. The point-based model attempts to quantify point anomalies, and the sequence-based model attempts to quantify both point and contextual anomalies. Under the formulation that the observed time point is a two-stage deviated value from a nominal time point, we introduce a nominality score calculated from the ratio of a combined value of the reconstruction errors. We derive an induced anomaly score by further integrating the nominality score and anomaly score, then theoretically prove the superiority of the induced anomaly score over the original anomaly score under certain condi
    
[^46]: 注意对话之间的差距，以提高长期对话生成的效果

    Mind the Gap Between Conversations for Improved Long-Term Dialogue Generation. (arXiv:2310.15415v1 [cs.CL])

    [http://arxiv.org/abs/2310.15415](http://arxiv.org/abs/2310.15415)

    本研究探索了使对话模型意识到时间的想法，并提出了一个多次对话的数据集GapChat，显示出时间感知的模型在判断话题相关性和从对话中获取信息的度量标准方面表现更好。

    

    知道如何结束和恢复对话是交流的自然部分，允许讨论跨越数周、数月或数年。对话之间的间隔持续时间决定了哪些话题是相关的，以及要问哪些问题，而不明确模拟时间的对话系统可能生成不自然的回应。在这项工作中，我们探索了使对话模型意识到时间的想法，并提出了GapChat，这是一个多次对话的数据集，其中每个对话之间的时间不同。虽然数据集是实时构建的，但演讲者生活中事件的进展是模拟的，以创建发生在长时间跨度内的现实对话。我们将时间信息暴露给模型，并比较不同的时间和事件进展表示。在人工评估中，我们展示了时间感知模型在判断选择话题的相关性和从对话中获得的信息的度量标准上表现更好。

    Knowing how to end and resume conversations over time is a natural part of communication, allowing for discussions to span weeks, months, or years. The duration of gaps between conversations dictates which topics are relevant and which questions to ask, and dialogue systems which do not explicitly model time may generate responses that are unnatural. In this work we explore the idea of making dialogue models aware of time, and present GapChat, a multi-session dialogue dataset in which the time between each session varies. While the dataset is constructed in real-time, progress on events in speakers' lives is simulated in order to create realistic dialogues occurring across a long timespan. We expose time information to the model and compare different representations of time and event progress. In human evaluation we show that time-aware models perform better in metrics that judge the relevance of the chosen topics and the information gained from the conversation.
    
[^47]: 人工智能与人类协作的多样化约定

    Diverse Conventions for Human-AI Collaboration. (arXiv:2310.15414v1 [cs.AI])

    [http://arxiv.org/abs/2310.15414](http://arxiv.org/abs/2310.15414)

    本研究通过最大化自我对弈的奖励并最小化与先前发现的约定交互时的奖励来生成多样化约定，确保学到的策略在交叉对弈的对抗性优化过程中遵守善意行事

    

    在合作多智体游戏中，约定对于强大的性能至关重要，因为它们允许玩家在没有明确交流的情况下进行共同战略的协调。然而，标准的多智体强化学习技术，如自我对弈，会收敛到任意和非多样化的约定，导致在与新的合作伙伴互动时表现不佳。本文提出了一种通过在自我对弈过程中最大化其奖励，并在与先前发现的约定进行交互时最小化其奖励（交叉对弈），以刺激约定在语义上有所不同的技术，来生成多样化约定。为了确保学到的策略在交叉对弈的对抗性优化过程中始终遵守善意行事，我们引入了混合对弈（mixed-play）的概念，即通过从自我对弈和交叉对弈的转换中随机生成初始状态，并学习在此初始状态下最大化自我对弈的奖励。我们分析了这种方法的优势

    Conventions are crucial for strong performance in cooperative multi-agent games, because they allow players to coordinate on a shared strategy without explicit communication. Unfortunately, standard multi-agent reinforcement learning techniques, such as self-play, converge to conventions that are arbitrary and non-diverse, leading to poor generalization when interacting with new partners. In this work, we present a technique for generating diverse conventions by (1) maximizing their rewards during self-play, while (2) minimizing their rewards when playing with previously discovered conventions (cross-play), stimulating conventions to be semantically different. To ensure that learned policies act in good faith despite the adversarial optimization of cross-play, we introduce \emph{mixed-play}, where an initial state is randomly generated by sampling self-play and cross-play transitions and the player learns to maximize the self-play reward from this initial state. We analyze the benefits
    
[^48]: DoGE: 使用泛化估计进行领域重新加权

    DoGE: Domain Reweighting with Generalization Estimation. (arXiv:2310.15393v1 [cs.LG])

    [http://arxiv.org/abs/2310.15393](http://arxiv.org/abs/2310.15393)

    DoGE提出了一种基于泛化估计的领域重新加权方法。通过使用梯度估计函数评估每个领域对泛化目标的贡献，重新调整了预训练数据中不同领域的采样概率。实验结果表明，该方法在提高大型语言模型的泛化能力方面取得了显著效果。

    

    预训练数据语料库的覆盖范围和组成对大型语言模型的泛化能力有着重要影响。传统上，预训练语料库由各种来源领域（如CommonCrawl、Wikipedia、Github等）按照特定的采样概率（领域权重）组成。然而，当前的方法缺乏一种基于最终泛化目标优化领域权重的原则方法。我们提出了一种称为DOmain reweighting with Generalization Estimation（DoGE）的方法，其中我们重新调整了每个领域的采样概率，根据它对最终泛化目标的贡献进行了基于梯度的泛化估计函数评估。首先，我们使用最小最大优化训练了一个小规模的代理模型来获取重新加权的领域权重。在每一步中，通过镜像下降法更新领域权重以最大化整体的泛化增益。最后，我们使用获得的领域权重来训练一个规模更大的完整语言模型。

    The coverage and composition of the pretraining data corpus significantly impacts the generalization ability of large language models. Conventionally, the pretraining corpus is composed of various source domains (e.g. CommonCrawl, Wikipedia, Github etc.) according to certain sampling probabilities (domain weights). However, current methods lack a principled way to optimize domain weights for ultimate goal for generalization. We propose DOmain reweighting with Generalization Estimation (DoGE), where we reweigh the sampling probability from each domain based on its contribution to the final generalization objective assessed by a gradient-based generalization estimation function. First, we train a small-scale proxy model with a min-max optimization to obtain the reweighted domain weights. At each step, the domain weights are updated to maximize the overall generalization gain by mirror descent. Finally we use the obtained domain weights to train a larger scale full-size language model. On
    
[^49]: 语言模型预训练的不可约课程

    Irreducible Curriculum for Language Model Pretraining. (arXiv:2310.15389v1 [cs.CL])

    [http://arxiv.org/abs/2310.15389](http://arxiv.org/abs/2310.15389)

    本论文提出了一种不可约课程算法，用于语言模型预训练，通过优先选择具有更高学习能力的样本，并使用小规模代理模型模拟样本丢失，从而在大型语言模型上解决了传统数据选择方法的困难，并在实验证明算法能够持续改进模型性能。

    

    训练大型语言模型的自动数据选择和课程设计具有挑战性，只有少数现有的方法在标准训练上显示出改进。此外，当前的方案更关注领域级别的选择，忽视了每个单独训练点的更细粒度的贡献。在大型语言模型上应用传统的数据点选择方法很困难：大多数在线批选择方法执行两次前向或后向传递，这会带来巨大的额外成本。为了克服这些障碍，我们提出了不可约课程作为语言模型预训练的课程学习算法，该算法优先选择具有更高学习能力的样本。具体而言，为了避免过高的额外计算开销，我们使用小规模代理模型模拟样本丢失沿主模型训练轨迹的情况。我们在RedPajama-1B数据集上的实验表明，课程学习算法能够持续改进模型在验证集上的性能。

    Automatic data selection and curriculum design for training large language models is challenging, with only a few existing methods showing improvements over standard training. Furthermore, current schemes focus on domain-level selection, overlooking the more fine-grained contributions of each individual training point. It is difficult to apply traditional datapoint selection methods on large language models: most online batch selection methods perform two-times forward or backward passes, which introduces considerable extra costs with large-scale models. To mitigate these obstacles, we propose irreducible curriculum as a curriculum learning algorithm for language model pretraining, which prioritizes samples with higher learnability. Specifically, to avoid prohibitive extra computation overhead, we simulate the sample loss along the main model's training trajectory using a small-scale proxy model. Our experiments on the RedPajama-1B dataset demonstrate a consistent improvement on valida
    
[^50]: 修正Koopman表示的方法

    Course Correcting Koopman Representations. (arXiv:2310.15386v1 [cs.LG])

    [http://arxiv.org/abs/2310.15386](http://arxiv.org/abs/2310.15386)

    本文修正了Koopman表示的方法，并提出了一种称为“周期重新编码”的机制，用于准确捕捉非线性动力系统中的长期动态。

    

    Koopman表示旨在学习非线性动力系统中导致潜在空间线性动力学的特征。从理论上讲，这些特征可以用于简化非线性动力系统建模和控制中的许多问题。在本文中，我们研究了此问题的自动编码器方法，并探讨了它们在建模动力学方面的不同应用，特别是在长期预测未来状态方面。我们发现在潜在空间中预测未来状态存在一些限制，并提出了一种称为“周期重新编码”的推理时间机制，以实现长期动态的准确捕捉。我们通过在低维和高维非线性动力系统上的实验证明了该方法的合理性和实用性。

    Koopman representations aim to learn features of nonlinear dynamical systems (NLDS) which lead to linear dynamics in the latent space. Theoretically, such features can be used to simplify many problems in modeling and control of NLDS. In this work we study autoencoder formulations of this problem, and different ways they can be used to model dynamics, specifically for future state prediction over long horizons. We discover several limitations of predicting future states in the latent space and propose an inference-time mechanism, which we refer to as Periodic Reencoding, for faithfully capturing long term dynamics. We justify this method both analytically and empirically via experiments in low and high dimensional NLDS.
    
[^51]: 数据湖中的语义数据管理

    Semantic Data Management in Data Lakes. (arXiv:2310.15373v1 [cs.DB])

    [http://arxiv.org/abs/2310.15373](http://arxiv.org/abs/2310.15373)

    数据湖是管理大量异构数据进行现代数据分析的一种方法。为了防止数据湖成为无法操作的数据沼泽，我们可以采用语义数据管理的方法，通过将元数据与知识图谱相链接，为数据提供更多的意义和语义。这种语义层不仅可以用于数据管理，还可以解决数据整合问题，使数据访问更具表达性和互操作性。

    

    近年来，数据湖作为管理大量异构数据进行现代数据分析的一种方法出现。防止数据湖变成无法操作的数据沼泽的一种方式是语义数据管理。一些方法提议基于链接数据原则将元数据与知识图谱相链接，以为湖中的数据提供更多的意义和语义。这样的语义层不仅可以用于数据管理，还可以解决来自异构来源的数据整合问题，以使数据访问更具表达性和互操作性。在这项调查中，我们重点关注在数据湖系统中的应用和大数据的可扩展性，回顾了最近的方法。我们将这些方法分为三类：(i)基本的语义数据管理，(ii)在数据湖中丰富元数据的语义建模方法，以及(iii)基于本体的数据访问方法。在每个类别中，我们涵盖了主要技术及其背景，并进行了比较。

    In recent years, data lakes emerged as away to manage large amounts of heterogeneous data for modern data analytics. One way to prevent data lakes from turning into inoperable data swamps is semantic data management. Some approaches propose the linkage of metadata to knowledge graphs based on the Linked Data principles to provide more meaning and semantics to the data in the lake. Such a semantic layer may be utilized not only for data management but also to tackle the problem of data integration from heterogeneous sources, in order to make data access more expressive and interoperable. In this survey, we review recent approaches with a specific focus on the application within data lake systems and scalability to Big Data. We classify the approaches into (i) basic semantic data management, (ii) semantic modeling approaches for enriching metadata in data lakes, and (iii) methods for ontologybased data access. In each category, we cover the main techniques and their background, and compa
    
[^52]: EpiK-Eval：将语言模型作为认识模型的评估

    EpiK-Eval: Evaluation for Language Models as Epistemic Models. (arXiv:2310.15372v1 [cs.CL])

    [http://arxiv.org/abs/2310.15372](http://arxiv.org/abs/2310.15372)

    这项研究介绍了一种新的评估方法EpiK-Eval，旨在评估大型语言模型（LLMs）在从分割的叙述中构建连贯和一致的知识表示方面的能力。研究发现当前的训练目标存在固有的缺陷，因此提出了改进知识整合方法的建议，以大幅提高LLMs的整体效果和性能。

    

    在人工智能时代，大型语言模型（LLMs）的作用越来越重要。尽管它们日益普及，但它们在从不同训练文档中整合知识的能力——在许多应用中都是关键能力——仍未得到探索。本文首次研究了LLMs在其参数空间内有效地结合这种信息的能力。我们引入了EpiK-Eval，一个新颖的问答基准，旨在评估LLMs在从分割的叙述中构建一种连贯和一致的知识表示方面的能力。对各种LLMs的评估揭示了在这一领域存在的显著弱点。我们认为这些缺点源于现有训练目标的固有性质。因此，我们主张改进知识整合的方法，因为这有潜力显著提高LLMs的整体效果和性能。

    In the age of artificial intelligence, the role of large language models (LLMs) is becoming increasingly central. Despite their growing prevalence, their capacity to consolidate knowledge from different training documents - a crucial ability in numerous applications - remains unexplored. This paper presents the first study examining the capability of LLMs to effectively combine such information within their parameter space. We introduce EpiK-Eval, a novel question-answering benchmark tailored to evaluate LLMs' proficiency in formulating a coherent and consistent knowledge representation from segmented narratives. Evaluations across various LLMs reveal significant weaknesses in this domain. We contend that these shortcomings stem from the intrinsic nature of prevailing training objectives. Consequently, we advocate for refining the approach towards knowledge consolidation, as it harbors the potential to dramatically improve their overall effectiveness and performance. The findings from 
    
[^53]: 基于邻近特征统计增强的联邦三维医学体积分割

    Vicinal Feature Statistics Augmentation for Federated 3D Medical Volume Segmentation. (arXiv:2310.15371v1 [eess.IV])

    [http://arxiv.org/abs/2310.15371](http://arxiv.org/abs/2310.15371)

    本论文提出了一种基于邻近特征统计增强的联邦三维医学体积分割方案，通过数据增强来提高FL分割的性能，并解决了标记数据有限和数据分布异构的问题。

    

    联邦学习（FL）使得多个医疗机构能够在隐私保护的前提下，共同训练深度学习（DL）模型。然而，在小型机构中，标记数据的有限可用性和异构的数据分布（即非i.i.d.）可能限制FL的性能。虽然数据增强被证明是提高传统集中式DL泛化能力的有效技术，但其在FL中的应用尚未得到充分探索。值得注意的是，受到昂贵的标注成本的限制，3D医学分割通常依赖于数据增强。在本文中，我们旨在开发一种邻近特征层级数据增强（VFDA）方案，以有效减轻局部特征漂移，并促进隐私感知的FL分割的协同训练。我们考虑了内部和跨机构的差异，而无需跨机构转移原始数据或混合数据。

    Federated learning (FL) enables multiple client medical institutes collaboratively train a deep learning (DL) model with privacy protection. However, the performance of FL can be constrained by the limited availability of labeled data in small institutes and the heterogeneous (i.e., non-i.i.d.) data distribution across institutes. Though data augmentation has been a proven technique to boost the generalization capabilities of conventional centralized DL as a "free lunch", its application in FL is largely underexplored. Notably, constrained by costly labeling, 3D medical segmentation generally relies on data augmentation. In this work, we aim to develop a vicinal feature-level data augmentation (VFDA) scheme to efficiently alleviate the local feature shift and facilitate collaborative training for privacy-aware FL segmentation. We take both the inner- and inter-institute divergence into consideration, without the need for cross-institute transfer of raw data or their mixup. Specifically
    
[^54]: 为什么LLM会产生幻觉，以及如何获得（证据性的）闭合性：用于忠实自然语言生成的感知、内涵和外延学习

    Why LLMs Hallucinate, and How to Get (Evidential) Closure: Perceptual, Intensional, and Extensional Learning for Faithful Natural Language Generation. (arXiv:2310.15355v1 [cs.CL])

    [http://arxiv.org/abs/2310.15355](http://arxiv.org/abs/2310.15355)

    本研究展示了LLMs产生幻觉的原因是因为它们的输出没有受到证据支持的主张的约束，并介绍了如何通过感知、内涵和外延学习来约束LLMs以生成满足证据闭合性的输出。

    

    我们展示了LLMs为什么会产生幻觉，因为它们的输出没有受到具备证据支持的主张的约束，这种条件被称为证据闭合。在标准的神经概率语言模型设置中，并不能从统计上辨别出关于句子真伪的信息，因此不能以此为条件生成新的字符串。然后我们展示了如何约束LLMs以产生满足证据闭合性的输出。多模态LLM必须学习外部世界（感知学习）；它必须学习从字符串到世界状态的映射（外延学习）；并且，为了在超越一组证据时实现流畅性，它必须学习从字符串到它们的同义词的映射（内涵学习）。一种单模态LLM的输出必须与验证的证据集中的字符串意义相同。最后，我们提供了一个启发式过程——学习-胡言乱语-修剪（Learn-Babble-Prune），通过拒绝不同义的输出，从LLM中产生忠实的输出。

    We show that LLMs hallucinate because their output is not constrained to be synonymous with claims for which they have evidence: a condition that we call evidential closure. Information about the truth or falsity of sentences is not statistically identified in the standard neural probabilistic language model setup, and so cannot be conditioned on to generate new strings. We then show how to constrain LLMs to produce output that does satisfy evidential closure. A multimodal LLM must learn about the external world (perceptual learning); it must learn a mapping from strings to states of the world (extensional learning); and, to achieve fluency when generalizing beyond a body of evidence, it must learn mappings from strings to their synonyms (intensional learning). The output of a unimodal LLM must be synonymous with strings in a validated evidence set. Finally, we present a heuristic procedure, Learn-Babble-Prune, that yields faithful output from an LLM by rejecting output that is not syn
    
[^55]: 大型语言模型的道德基础

    Moral Foundations of Large Language Models. (arXiv:2310.15337v1 [cs.AI])

    [http://arxiv.org/abs/2310.15337](http://arxiv.org/abs/2310.15337)

    本文通过使用道德基础理论（MFT）作为分析工具，研究了流行的大型语言模型（LLMs）是否对一系列特定的道德价值观产生了偏见，并展示了它们与人类道德基础和政治倾向的关联。研究还发现LLMs的偏见在不同的提示上下文中存在差异，并展示了通过对抗选择提示可以引导LLMs产生不同的回答。

    

    道德基础理论（MFT）是一种心理评估工具，将人类道德推理分解为包括关心/伤害、自由/压迫和尊严/堕落等五个因素（Graham等，2009）。人们在作出道德决策时在这些维度上的权重不同，部分原因是他们的文化背景和政治意识形态。由于大型语言模型（LLMs）在从互联网收集的数据集上训练，他们可能反映了这些语料库中存在的偏见。本文以MFT为视角，分析流行的LLMs是否对一系列特定的道德价值观产生了偏见。我们分析已知的LLMs，发现它们展现了特定的道德基础，并展示了它们与人类道德基础和政治倾向的关系。我们还测量了这些偏见的一致性，或者它们在模型被提示的上下文中是否有很大差异。最后，我们展示了我们可以通过对抗地选择提示来鼓励LLMs产生不同的回答。

    Moral foundations theory (MFT) is a psychological assessment tool that decomposes human moral reasoning into five factors, including care/harm, liberty/oppression, and sanctity/degradation (Graham et al., 2009). People vary in the weight they place on these dimensions when making moral decisions, in part due to their cultural upbringing and political ideology. As large language models (LLMs) are trained on datasets collected from the internet, they may reflect the biases that are present in such corpora. This paper uses MFT as a lens to analyze whether popular LLMs have acquired a bias towards a particular set of moral values. We analyze known LLMs and find they exhibit particular moral foundations, and show how these relate to human moral foundations and political affiliations. We also measure the consistency of these biases, or whether they vary strongly depending on the context of how the model is prompted. Finally, we show that we can adversarially select prompts that encourage the
    
[^56]: 使用flwr-serverless的无服务器联邦学习

    Serverless Federated Learning with flwr-serverless. (arXiv:2310.15329v1 [cs.LG])

    [http://arxiv.org/abs/2310.15329](http://arxiv.org/abs/2310.15329)

    flwr-serverless是一种无服务器联邦学习的方法，能够有效训练来自不同来源的数据，同时不损害安全和隐私。

    

    随着数据收集和个人身份信息存储量的激增，联邦学习变得越来越重要和受欢迎。与此同时，世界各国提出了许多关于为个人数据提供更多保护以及对数据隐私措施的强化兴趣的建议。随着深度学习在新的和现有领域的重要性不断增加，开发像联邦学习这样能有效训练来自不同来源（如边缘设备）的数据、同时不损害安全和隐私的策略是至关重要的。最近，引入了名为Flower（Flwr）的Python包，为实现联邦学习提供了可扩展、灵活且易于使用的框架。然而，到目前为止，Flower只能运行同步联邦学习，这可能会导致运行成本高、耗时长，因为过程受限于慢速或不稳定的客户端训练任务。

    Federated learning is becoming increasingly relevant and popular as we witness a surge in data collection and storage of personally identifiable information. Alongside these developments there have been many proposals from governments around the world to provide more protections for individuals' data and a heightened interest in data privacy measures. As deep learning continues to become more relevant in new and existing domains, it is vital to develop strategies like federated learning that can effectively train data from different sources, such as edge devices, without compromising security and privacy. Recently, the Flower (\texttt{Flwr}) Python package was introduced to provide a scalable, flexible, and easy-to-use framework for implementing federated learning. However, to date, Flower is only able to run synchronous federated learning which can be costly and time-consuming to run because the process is bottlenecked by client-side training jobs that are slow or fragile. Here, we in
    
[^57]: 为基于指导性说明生成的幻觉检测问题

    Hallucination Detection for Grounded Instruction Generation. (arXiv:2310.15319v1 [cs.CL])

    [http://arxiv.org/abs/2310.15319](http://arxiv.org/abs/2310.15319)

    该论文研究了生成指导人类在模拟环境中导航的说明的问题，通过预训练模型并使用对比损失进行微调，提出了一种检测幻觉参考的模型，该模型在性能上超过了几个基线模型。

    

    我们研究了在模拟的住宅环境中生成指导人类导航的说明的问题。目前模型存在的一个重要问题是幻觉：它们生成与人类跟随者在描述的路径上执行或遇到的行为或物体不一致的参考。我们开发了一个模型，通过采用在大型图像-文本对语料库上预训练的模型，并使用对比损失进行微调，检测这些幻觉参考。我们的最终模型胜过了几个基线模型，包括使用由说明生成模型估计的词概率以及基于LSTM和Transformer的监督模型。

    We investigate the problem of generating instructions to guide humans to navigate in simulated residential environments. A major issue with current models is hallucination: they generate references to actions or objects that are inconsistent with what a human follower would perform or encounter along the described path. We develop a model that detects these hallucinated references by adopting a model pre-trained on a large corpus of image-text pairs, and fine-tuning it with a contrastive loss that separates correct instructions from instructions containing synthesized hallucinations. Our final model outperforms several baselines, including using word probability estimated by the instruction-generation model, and supervised models based on LSTM and Transformer.
    
[^58]: HetGPT: 利用预训练异构图神经网络中的提示调整的能力

    HetGPT: Harnessing the Power of Prompt Tuning in Pre-Trained Heterogeneous Graph Neural Networks. (arXiv:2310.15318v1 [cs.LG])

    [http://arxiv.org/abs/2310.15318](http://arxiv.org/abs/2310.15318)

    HetGPT是一种预训练异构图神经网络的方法，通过利用提示调整来解决预训练与下游任务之间的不匹配问题。

    

    图表现为表示和分析Web中的复杂模式和丰富信息的自然选择，使得在线页面分类和社交推荐等应用成为可能。然而，当前的“预训练，微调”范式在图机器学习任务中广泛应用，特别是在有限标记节点的情况下，往往存在预训练目标任务与下游任务之间的不匹配问题。这种差距可能导致“负转移”问题，即预训练所获得的知识对下游任务的性能产生不利影响。自然语言处理领域中基于提示的学习的兴起表明了将“预训练，提示”范式应用于图形的潜力，作为一种替代方案。然而，现有的图形提示技术针对的是同质图，忽视了Web图的内在异构性。为了填补这一差距，我们提出了HetGPT，

    Graphs have emerged as a natural choice to represent and analyze the intricate patterns and rich information of the Web, enabling applications such as online page classification and social recommendation. The prevailing "pre-train, fine-tune" paradigm has been widely adopted in graph machine learning tasks, particularly in scenarios with limited labeled nodes. However, this approach often exhibits a misalignment between the training objectives of pretext tasks and those of downstream tasks. This gap can result in the "negative transfer" problem, wherein the knowledge gained from pre-training adversely affects performance in the downstream tasks. The surge in prompt-based learning within Natural Language Processing (NLP) suggests the potential of adapting a "pre-train, prompt" paradigm to graphs as an alternative. However, existing graph prompting techniques are tailored to homogeneous graphs, neglecting the inherent heterogeneity of Web graphs. To bridge this gap, we propose HetGPT, a 
    
[^59]: 基于批评地名学的命名实体识别框架：以纽约市Airbnb为例

    Toward a Critical Toponymy Framework for Named Entity Recognition: A Case Study of Airbnb in New York City. (arXiv:2310.15302v1 [cs.CL])

    [http://arxiv.org/abs/2310.15302](http://arxiv.org/abs/2310.15302)

    通过研究纽约市Airbnb房源数据集，本文提出了一个基于批评地名学的命名实体识别（NER）模型，能够识别与地点特征化相关的重要话语类别，为批评地名学研究指明了新的方向。

    

    批评地名学通过地名和相关地点研究权力、资本和抵抗的动态。传统研究主要关注地名的语义内容和自上而下的制度过程，但通常忽视了普通人在日常话语中使用地名的方式，以及与地名相关的地理空间描述策略。本文通过对2010年代的47,440个纽约市Airbnb房源进行创新的注释数据集构建，开发计算方法以衡量文化和经济资本如何影响人们对地点的称谓方式。基于该数据集，我们引入了一个新的命名实体识别（NER）模型，能够识别与地点特征化相关的重要话语类别。我们的研究结果指向批评地名学的新方向，以及一系列以前未被充分研究的语言学问题。

    Critical toponymy examines the dynamics of power, capital, and resistance through place names and the sites to which they refer. Studies here have traditionally focused on the semantic content of toponyms and the top-down institutional processes that produce them. However, they have generally ignored the ways in which toponyms are used by ordinary people in everyday discourse, as well as the other strategies of geospatial description that accompany and contextualize toponymic reference. Here, we develop computational methods to measure how cultural and economic capital shape the ways in which people refer to places, through a novel annotated dataset of 47,440 New York City Airbnb listings from the 2010s. Building on this dataset, we introduce a new named entity recognition (NER) model able to identify important discourse categories integral to the characterization of place. Our findings point toward new directions for critical toponymy and to a range of previously understudied linguist
    
[^60]: 具有局部收敛输入的神经网络（NNLCI）用于具有非结构化网格的超音速流问题

    Neural Network with Local Converging Input (NNLCI) for Supersonic Flow Problems with Unstructured Grids. (arXiv:2310.15299v1 [math.NA])

    [http://arxiv.org/abs/2310.15299](http://arxiv.org/abs/2310.15299)

    本研究开发了一种具有局部收敛输入的神经网络（NNLCI），用于使用非结构化数据进行高保真预测。该方法大大降低了计算资源和训练时间，并在无粘超音速流问题中展示了有效性和多功能性。

    

    近年来，基于深度神经网络（DNN）的代理模型广泛应用于解决传统上通过数值模拟处理的偏微分方程。然而，这种代理模型着重于对训练数据集的全局插值，因此需要较大的网络结构。这个过程耗时且计算成本高，限制了其在复杂物理问题的高保真预测中的应用。本研究开发了一种具有局部收敛输入的神经网络（NNLCI），用于使用非结构化数据进行高保真预测。该框架利用局部依赖域和收敛的粗略解作为输入，大大降低了计算资源和训练时间。作为验证案例，NNLCI方法被应用于研究具有凸块的导流道中的无粘超音速流。考虑了不同的凸块几何形状和位置，用于评估其有效性和多功能性。

    In recent years, surrogate models based on deep neural networks (DNN) have been widely used to solve partial differential equations, which were traditionally handled by means of numerical simulations. This kind of surrogate models, however, focuses on global interpolation of the training dataset, and thus requires a large network structure. The process is both time consuming and computationally costly, thereby restricting their use for high-fidelity prediction of complex physical problems. In the present study, we develop a neural network with local converging input (NNLCI) for high-fidelity prediction using unstructured data. The framework utilizes the local domain of dependence with converging coarse solutions as input, which greatly reduces computational resource and training time. As a validation case, the NNLCI method is applied to study inviscid supersonic flows in channels with bumps. Different bump geometries and locations are considered to benchmark the effectiveness and versa
    
[^61]: 任务导向对话的相似度度量方法

    TaskDiff: A Similarity Metric for Task-Oriented Conversations. (arXiv:2310.15298v1 [cs.CL])

    [http://arxiv.org/abs/2310.15298](http://arxiv.org/abs/2310.15298)

    TaskDiff是一种新颖的对话相似度度量方法，通过使用不同的对话组成部分来计算相似度，取得了优越的性能和鲁棒性。

    

    会话式数字助手的普及导致了大量会话数据的可用性，这可以用于改善用户体验和个性化响应生成。使用像ChatGPT这样的流行大型语言模型构建这些助手还需要额外强调提示工程和评估方法。文本相似度度量是这种分析和评估的关键因素。虽然文献中提出了许多相似度度量方法，但它们在任务导向对话方面并不有效，因为它们没有充分利用独特的对话特征。为了填补这一差距，我们提出了一种新颖的对话相似度度量方法TaskDiff，它利用对话的不同组成部分（话语、意图和槽）及其分布来计算相似度。在基准数据集上进行的广泛实验证明了TaskDiff在性能和鲁棒性方面的优越表现，超过了其他相关方法。

    The popularity of conversational digital assistants has resulted in the availability of large amounts of conversational data which can be utilized for improved user experience and personalized response generation. Building these assistants using popular large language models like ChatGPT also require additional emphasis on prompt engineering and evaluation methods. Textual similarity metrics are a key ingredient for such analysis and evaluations. While many similarity metrics have been proposed in the literature, they have not proven effective for task-oriented conversations as they do not take advantage of unique conversational features. To address this gap, we present TaskDiff, a novel conversational similarity metric that utilizes different dialogue components (utterances, intents, and slots) and their distributions to compute similarity. Extensive experimental evaluation of TaskDiff on a benchmark dataset demonstrates its superior performance and improved robustness over other rela
    
[^62]: DeTiME: 使用基于编码-解码的LLM增强扩散的主题建模方法

    DeTiME: Diffusion-Enhanced Topic Modeling using Encoder-decoder based LLM. (arXiv:2310.15296v1 [cs.CL])

    [http://arxiv.org/abs/2310.15296](http://arxiv.org/abs/2310.15296)

    DeTiME是一种使用基于编码-解码的LLMs增强扩散的主题建模方法，能够产生高度聚类的嵌入和具有增强语义一致性的主题，并能生成与主题相关的内容。

    

    在充满活力的自然语言处理领域，神经主题模型（NTMs）和大型语言模型（LLMs）已成为重要的研究领域。尽管如此，NTMs主要使用来自LLMs的上下文嵌入，这对于聚类或主题生成来说并不是最佳选择。我们的研究通过引入名为DeTiME的新框架来解决这一问题。DeTiME利用编码-解码的LLMs产生高度可聚类的嵌入，与现有方法相比，能够生成既具有优越的聚类性又具有增强的语义一致性的主题。此外，通过利用扩散的能力，我们的框架还提供了生成与已识别主题相关内容的能力。这种双重功能使用户能够同时高效产生高度聚类的主题和相关内容。DeTiME的潜力还包括生成集群化的嵌入。

    In the burgeoning field of natural language processing, Neural Topic Models (NTMs) and Large Language Models (LLMs) have emerged as areas of significant research interest. Despite this, NTMs primarily utilize contextual embeddings from LLMs, which are not optimal for clustering or capable for topic generation. Our study addresses this gap by introducing a novel framework named Diffusion-Enhanced Topic Modeling using Encoder-Decoder-based LLMs (DeTiME). DeTiME leverages ncoder-Decoder-based LLMs to produce highly clusterable embeddings that could generate topics that exhibit both superior clusterability and enhanced semantic coherence compared to existing methods. Additionally, by exploiting the power of diffusion, our framework also provides the capability to generate content relevant to the identified topics. This dual functionality allows users to efficiently produce highly clustered topics and related content simultaneously. DeTiME's potential extends to generating clustered embeddi
    
[^63]: 强化学习中基于人类反馈的主动教师选择

    Active teacher selection for reinforcement learning from human feedback. (arXiv:2310.15288v1 [cs.AI])

    [http://arxiv.org/abs/2310.15288](http://arxiv.org/abs/2310.15288)

    本论文提出了一个用于强化学习中的主动教师选择模型以解决多教师的学习问题，研究表明该模型在论文推荐系统和COVID-19疫苗测试领域具有优越性能，并揭示了利用教师间差异来学习准确奖励模型的重要性。

    

    从人类反馈中进行强化学习（RLHF）使得机器学习系统能够从人类反馈中学习目标。这些系统的一个核心限制是它们假设所有反馈都来自一个单一的人类教师，尽管需要询问不同教师的意见。我们提出了"Hidden Utility Bandit"（HUB）框架来建模教师在理性、专业知识和成本方面的差异，从而形式化了从多个教师学习的问题。我们开发了多种解决算法，并将它们应用于两个现实世界的领域：论文推荐系统和COVID-19疫苗测试。我们发现，"Active Teacher Selection"（ATS）算法通过主动选择何时以及选择哪个教师来查询，优于基准算法。HUB框架和ATS算法展示了利用教师之间的差异来学习准确的奖励模型的重要性，为鲁棒奖励建模的主动教师选择的未来研究提供了基础。

    Reinforcement learning from human feedback (RLHF) enables machine learning systems to learn objectives from human feedback. A core limitation of these systems is their assumption that all feedback comes from a single human teacher, despite querying a range of distinct teachers. We propose the Hidden Utility Bandit (HUB) framework to model differences in teacher rationality, expertise, and costliness, formalizing the problem of learning from multiple teachers. We develop a variety of solution algorithms and apply them to two real-world domains: paper recommendation systems and COVID-19 vaccine testing. We find that the Active Teacher Selection (ATS) algorithm outperforms baseline algorithms by actively selecting when and which teacher to query. The HUB framework and ATS algorithm demonstrate the importance of leveraging differences between teachers to learn accurate reward models, facilitating future research on active teacher selection for robust reward modeling.
    
[^64]: 系统化的人工智能方法用于AGI：解决对齐、能源和AGI大挑战

    Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges. (arXiv:2310.15274v1 [cs.AI])

    [http://arxiv.org/abs/2310.15274](http://arxiv.org/abs/2310.15274)

    本论文讨论了面临能源、对齐和从狭义人工智能到AGI的三大挑战的系统化人工智能方法。现有的人工智能方法在能源消耗、系统设计和对齐问题上存在不足，而系统设计在解决对齐、能源和AGI大挑战中是至关重要的。

    

    人工智能面临着三大挑战：能源壁垒、对齐问题和从狭义人工智能到AGI的飞跃。当代人工智能解决方案在模型训练和日常运行过程中消耗着不可持续的能源。更糟糕的是，自2020年以来，每个新的人工智能模型所需的计算量每两个月就翻倍，直接导致能源消耗的增加。从人工智能到AGI的飞跃需要多个功能子系统以平衡的方式运作，这需要一个系统架构。然而，当前的人工智能方法缺乏系统设计；即使系统特征在人脑中扮演着重要角色，从它处理信息的方式到它做出决策的方式。同样，当前的对齐和人工智能伦理方法在很大程度上忽视了系统设计，然而研究表明，大脑的系统架构在健康的道德决策中起着关键作用。在本文中，我们认为系统设计在解决对齐、能源和AGI大挑战中至关重要。

    AI faces a trifecta of grand challenges the Energy Wall, the Alignment Problem and the Leap from Narrow AI to AGI. Contemporary AI solutions consume unsustainable amounts of energy during model training and daily operations.Making things worse, the amount of computation required to train each new AI model has been doubling every 2 months since 2020, directly translating to increases in energy consumption.The leap from AI to AGI requires multiple functional subsystems operating in a balanced manner, which requires a system architecture. However, the current approach to artificial intelligence lacks system design; even though system characteristics play a key role in the human brain from the way it processes information to how it makes decisions. Similarly, current alignment and AI ethics approaches largely ignore system design, yet studies show that the brains system architecture plays a critical role in healthy moral decisions.In this paper, we argue that system design is critically im
    
[^65]: 对AI生成文本检测的可能性和不可能性进行综述

    Towards Possibilities & Impossibilities of AI-generated Text Detection: A Survey. (arXiv:2310.15264v1 [cs.CL])

    [http://arxiv.org/abs/2310.15264](http://arxiv.org/abs/2310.15264)

    本文综述了AI生成文本检测的可能性和不可能性。具体而言，讨论了使用大型语言模型产生的文本可能导致的问题以及表明AI生成文本检测的意义。另外，还提到了对抗检测的策略的设计。

    

    大型语言模型（LLMs）以其生成人类化文本响应的显著能力，彻底改变了自然语言处理（NLP）领域。然而，尽管取得了这些进展，现有文献中的一些工作对LLMs的潜在滥用问题提出了严重关注，如传播错误信息、生成假新闻、学术抄袭和污染网络。为了解决这些问题，研究界达成共识，即开发用于检测AI生成文本的算法解决方案。基本思想是，只要我们能判断给定文本是由人类还是AI编写的，我们就可以利用这些信息来应对上述问题。为此，提出了大量的检测框架，突出了AI生成文本检测的可能性。然而，与检测框架的发展同时，研究人员还致力于设计规避检测的策略。

    Large Language Models (LLMs) have revolutionized the domain of natural language processing (NLP) with remarkable capabilities of generating human-like text responses. However, despite these advancements, several works in the existing literature have raised serious concerns about the potential misuse of LLMs such as spreading misinformation, generating fake news, plagiarism in academia, and contaminating the web. To address these concerns, a consensus among the research community is to develop algorithmic solutions to detect AI-generated text. The basic idea is that whenever we can tell if the given text is either written by a human or an AI, we can utilize this information to address the above-mentioned concerns. To that end, a plethora of detection frameworks have been proposed, highlighting the possibilities of AI-generated text detection. But in parallel to the development of detection frameworks, researchers have also concentrated on designing strategies to elude detection, i.e., f
    
[^66]: 无参考领域自适应翻译带有问题特定奖励的噪声问题

    Reference Free Domain Adaptation for Translation of Noisy Questions with Question Specific Rewards. (arXiv:2310.15259v1 [cs.CL])

    [http://arxiv.org/abs/2310.15259](http://arxiv.org/abs/2310.15259)

    这项研究提出了一种解决噪声环境中问题翻译挑战的方法，通过只使用源语数据进行微调的训练，实现了翻译问题的充分性和流畅性的平衡。

    

    社区问答(CQA)平台是帮助组织内用户的有价值工具。然而，使它们对非英语用户可访问仍然是一个挑战。翻译问题可以拓宽社区的覆盖范围，使有类似问题的人能够受益，但在嘈杂的环境中使用神经机器翻译(NMT)进行问题翻译会面临更多挑战，因为这些问题的语法正确性没有受到监控。这些问题可能被非母语用户以陈述句的形式表达，具有不正确的主谓语序，甚至有时缺少问号。由于数据存在噪声，从这些数据中创建一个合成的平行语料库也是困难的。为了解决这个问题，我们提出了一种只使用源语数据进行微调的训练方法。我们的方法通过结合BERTScore和Masked Language Model (MLM) S的损失函数，平衡了充分性和流畅性。

    Community Question-Answering (CQA) portals serve as a valuable tool for helping users within an organization. However, making them accessible to non-English-speaking users continues to be a challenge. Translating questions can broaden the community's reach, benefiting individuals with similar inquiries in various languages. Translating questions using Neural Machine Translation (NMT) poses more challenges, especially in noisy environments, where the grammatical correctness of the questions is not monitored. These questions may be phrased as statements by non-native speakers, with incorrect subject-verb order and sometimes even missing question marks. Creating a synthetic parallel corpus from such data is also difficult due to its noisy nature. To address this issue, we propose a training methodology that fine-tunes the NMT system only using source-side data. Our approach balances adequacy and fluency by utilizing a loss function that combines BERTScore and Masked Language Model (MLM) S
    
[^67]: CRoW: 在真实世界任务中对常识推理进行基准测试

    CRoW: Benchmarking Commonsense Reasoning in Real-World Tasks. (arXiv:2310.15239v1 [cs.CL])

    [http://arxiv.org/abs/2310.15239](http://arxiv.org/abs/2310.15239)

    CRoW是一个手工策划的多任务基准测试，用于评估模型在真实世界NLP任务中应用常识推理的能力。该基准测试揭示了NLP系统在常识推理方面与人类之间存在显著的性能差距，表明常识推理在真实世界中仍然远未解决。

    

    自然语言处理（NLP）中关于常识推理的研究近年来取得了许多新的数据集和基准测试。然而，大多数这些数据集在人工场景下构建了常识推理挑战，这些场景并不能反映真实世界NLP系统所设计用于解决的任务。在这项工作中，我们提出了CRoW，一个手工策划的多任务基准测试，用于评估模型在六个真实世界NLP任务中应用常识推理的能力。CRoW使用多阶段的数据收集流程构建，通过违反常识的扰动重写现有数据集中的示例。我们利用CRoW来研究NLP系统在物理、时间和社交推理等不同常识知识维度上的表现。我们发现，在CRoW上评估NLP系统时与人类相比存在显著的性能差距，显示出常识推理在真实世界中还远未解决。

    Recent efforts in natural language processing (NLP) commonsense reasoning research have yielded a considerable number of new datasets and benchmarks. However, most of these datasets formulate commonsense reasoning challenges in artificial scenarios that are not reflective of the tasks which real-world NLP systems are designed to solve. In this work, we present CRoW, a manually-curated, multi-task benchmark that evaluates the ability of models to apply commonsense reasoning in the context of six real-world NLP tasks. CRoW is constructed using a multi-stage data collection pipeline that rewrites examples from existing datasets using commonsense-violating perturbations. We use CRoW to study how NLP systems perform across different dimensions of commonsense knowledge, such as physical, temporal, and social reasoning. We find a significant performance gap when NLP systems are evaluated on CRoW compared to humans, showcasing that commonsense reasoning is far from being solved in real-world t
    
[^68]: 一个新方法用于带有更高次谐波的引力波模板库：通过十倍减少匹配滤波成本

    A new approach to template banks of gravitational waves with higher harmonics: reducing matched-filtering cost by over an order of magnitude. (arXiv:2310.15233v1 [gr-qc])

    [http://arxiv.org/abs/2310.15233](http://arxiv.org/abs/2310.15233)

    该论文提出了一种新方法，通过在引力波模板库中包含高次谐波模式，利用引力波模式之间的自然关联，可以大幅度减少匹配滤波的成本，并提高搜索引力波事件的灵敏度。

    

    引力波事件的搜索使用信号模型或模板。目前在LIGO-Virgo-Kagra (LVK)数据中使用的模板仅模拟了信号的主导四极模式$(\ell,m)=(2,2)$，忽略了次要的高阶模式(HM)例如$(\ell,m)=(3,3)$，$(4,4)$，这些模式是由广义相对论预测的。因此，这些搜索可能会在参数空间的一些有趣区域，如高质量和非对称质量比的系统中失去对黑洞合并的灵敏度。我们开发了一种新策略，将HM包含在模板库中，利用这些模式之间的自然关联。我们使用了牛顿附加公式和机器学习工具来模拟与给定$(2,2)$波形相对应的自旋对齐的$(3,3)$，$(4,4)$波形。可以对每个模式的数据进行单独滤波，得到信噪比(SNR)的独立时间序列，然后可以以相对廉价的方式将其组合起来进行综合。

    Searches for gravitational wave events use models, or templates, for the signals of interest. The templates used in current searches in the LIGO-Virgo-Kagra (LVK) data model the dominant quadrupole mode $(\ell,m)=(2,2)$ of the signals, and omit sub-dominant higher-order modes (HM) such as $(\ell,m)=(3,3)$, $(4,4)$, which are predicted by general relativity. Hence, these searches could lose sensitivity to black hole mergers in interesting parts of parameter space, such as systems with high-masses and asymmetric mass ratios. We develop a new strategy to include HM in template banks that exploits the natural connection between the modes. We use a combination of post-Newtonian formulae and machine learning tools to model aligned-spin $(3,3)$, $(4,4)$ waveforms corresponding to a given $(2,2)$ waveform. Each of these modes can be individually filtered against the data to yield separate timeseries of signal-to-noise ratios (SNR), which can be combined in a relatively inexpensive way to margi
    
[^69]: 模拟对阿尔茨海默病药物重用的有效性进行路径重要性建模

    Modeling Path Importance for Effective Alzheimer's Disease Drug Repurposing. (arXiv:2310.15211v1 [q-bio.QM])

    [http://arxiv.org/abs/2310.15211](http://arxiv.org/abs/2310.15211)

    该论文提出了一种基于网络的新方法（MPI）来有效进行阿尔茨海默病药物重用。该方法通过学习节点嵌入来优先考虑重要路径，从而更好地发现候选药物。

    

    最近，药物重用作为一种有效且资源高效的阿尔茨海默病药物发现范式已经崭露头角。在各种药物重用方法中，基于网络的方法显示出了有希望的结果，因为它们能够利用复杂网络，整合多种相互作用类型（如蛋白质相互作用），更有效地识别潜在药物。然而，现有的方法通常假设网络中相同长度的路径对于识别药物的治疗效果具有相等的重要性。其他领域发现，相同长度的路径并不一定具有相同的重要性。因此，依赖于这一假设可能对药物重用尝试产生不利影响。在这项工作中，我们提出了MPI（模拟路径重要性），这是一种新颖的基于网络的阿尔茨海默病药物重用方法。MPI的独特之处在于，通过学习节点嵌入来优先考虑重要路径，这可以有效捕捉网络的丰富结构信息。因此，利用学习的节点嵌入可以提高药物重用的效果。

    Recently, drug repurposing has emerged as an effective and resource-efficient paradigm for AD drug discovery. Among various methods for drug repurposing, network-based methods have shown promising results as they are capable of leveraging complex networks that integrate multiple interaction types, such as protein-protein interactions, to more effectively identify candidate drugs. However, existing approaches typically assume paths of the same length in the network have equal importance in identifying the therapeutic effect of drugs. Other domains have found that same length paths do not necessarily have the same importance. Thus, relying on this assumption may be deleterious to drug repurposing attempts. In this work, we propose MPI (Modeling Path Importance), a novel network-based method for AD drug repurposing. MPI is unique in that it prioritizes important paths via learned node embeddings, which can effectively capture a network's rich structural information. Thus, leveraging learn
    
[^70]: 基于Transformer的胶囊网络预测转录因子结合位点

    Predicting Transcription Factor Binding Sites using Transformer based Capsule Network. (arXiv:2310.15202v1 [q-bio.GN])

    [http://arxiv.org/abs/2310.15202](http://arxiv.org/abs/2310.15202)

    本文提出了一种基于Transformer的胶囊网络DNABERT-Cap，用于预测转录因子结合位点。该模型在预测中利用了双向编码器、胶囊层、卷积和双向长短时记忆层的特征，并通过对这些特征的联合优化构建了转录因子结合位点的预测器。

    

    预测转录因子的结合位点对于理解它们如何调控基因表达以及如何通过治疗手段进行调节非常重要。尽管在过去几年里已经有相当多的工作针对这个问题进行了研究，但仍然有改进的空间。在这方面，本文提出了一种基于Transformer的胶囊网络DNABERT-Cap，用于利用ChIP-seq数据集挖掘预测转录因子结合位点。DNABERT-Cap是一个双向编码器，经过大量基因组DNA序列的预训练，并通过胶囊层进行最终预测。所提出的模型通过对包含双向编码器、胶囊层、卷积和双向长短时记忆层特征的联合优化，构建了转录因子结合位点的预测器。为了评估所提方法的效率，我们使用了五个细胞系的基准ChIP-seq数据集，包括A54。

    Prediction of binding sites for transcription factors is important to understand how they regulate gene expression and how this regulation can be modulated for therapeutic purposes. Although in the past few years there are significant works addressing this issue, there is still space for improvement. In this regard, a transformer based capsule network viz. DNABERT-Cap is proposed in this work to predict transcription factor binding sites mining ChIP-seq datasets. DNABERT-Cap is a bidirectional encoder pre-trained with large number of genomic DNA sequences, empowered with a capsule layer responsible for the final prediction. The proposed model builds a predictor for transcription factor binding sites using the joint optimisation of features encompassing both bidirectional encoder and capsule layer, along with convolutional and bidirectional long-short term memory layers. To evaluate the efficiency of the proposed approach, we use a benchmark ChIP-seq datasets of five cell lines viz. A54
    
[^71]: 皮肤微生物组模型中的AMP相互作用以及种群动力学中准稳定与稳定性的分析

    A Skin Microbiome Model with AMP interactions and Analysis of Quasi-Stability vs Stability in Population Dynamics. (arXiv:2310.15201v1 [q-bio.QM])

    [http://arxiv.org/abs/2310.15201](http://arxiv.org/abs/2310.15201)

    本文介绍了一种基于常微分方程的数学模型，用于研究皮肤微生物组中的两种细菌群落（共生菌和机会性致病菌）之间的相互作用，并考虑了抗微生物肽的产生。通过使用实验数据验证模型的稳定状态，可以帮助我们理解皮肤微生物组中不同群体之间的竞争机制和稳定性。

    

    皮肤微生物组在维持健康皮肤方面起着重要作用。它是一个由多个物种组成的生态系统，竞争资源并与皮肤细胞相互作用。皮肤微生物组的不平衡，也称为菌群紊乱，与多种皮肤状况（包括痤疮和特应性皮炎）相关。通常，菌群紊乱与皮肤被机会性致病菌群的定居有关。以非特异性消除皮肤微生物组的治疗结果相互矛盾。在本文中，我们引入了一种基于常微分方程的数学模型，其中包括2种类型的细菌群落（皮肤共生菌和机会性致病菌）以及抗微生物肽的产生，以研究驱动一种群落优势于另一种群落的机制。通过使用出版的实验数据，假设这些数据对应于我们模型中的稳定状态的观察，我们减少了数量。

    The skin microbiome plays an important role in the maintenance of a healthy skin. It is an ecosystem, composed of several species, competing for resources and interacting with the skin cells. Imbalance in the cutaneous microbiome, also called dysbiosis, has been correlated with several skin conditions, including acne and atopic dermatitis. Generally, dysbiosis is linked to colonization of the skin by a population of opportunistic pathogenic bacteria. Treatments consisting in non-specific elimination of cutaneous microflora have shown conflicting results. In this article, we introduce a mathematical model based on ordinary differential equations, with 2 types of bacteria populations (skin commensals and opportunistic pathogens) and including the production of antimicrobial peptides to study the mechanisms driving the dominance of one population over the other. By using published experimental data, assumed to correspond to the observation of stable states in our model, we reduce the numb
    
[^72]: 高效元神经启发式算法用于多目标组合优化问题

    Efficient Meta Neural Heuristic for Multi-Objective Combinatorial Optimization. (arXiv:2310.15196v1 [cs.LG])

    [http://arxiv.org/abs/2310.15196](http://arxiv.org/abs/2310.15196)

    本研究提出了一种高效的元神经启发式算法（EMNH），通过训练一个元模型并进行微调，来解决多目标组合优化问题。实验结果表明，EMNH在学习效率和解决质量上取得了显著改进。

    

    最近，基于深度强化学习的神经启发式算法在解决多目标组合优化问题方面显示出了潜力。然而，它们仍然在学习效率和解决质量方面遇到困难。为了解决这个问题，我们提出了一种高效的元神经启发式算法（EMNH），其中首先训练一个元模型，然后通过几个步骤对应的单目标子问题来进行微调。具体而言，在训练过程中，利用（部分）架构共享的多任务模型实现元模型的并行学习，以加快训练速度；同时，设计了一种与权重向量相关的比例对称采样方法来稳定训练过程。在微调过程中，提出了一种高效的层次化方法来系统地处理所有的子问题。在多目标旅行商问题（MOTSP）、多目标容量车辆路径问题（MOVRPTW）和多目标背包问题（MOKP）上进行了实验，结果表明，与现有方法相比，EMNH在学习效率和解决质量方面取得了显著的改进。

    Recently, neural heuristics based on deep reinforcement learning have exhibited promise in solving multi-objective combinatorial optimization problems (MOCOPs). However, they are still struggling to achieve high learning efficiency and solution quality. To tackle this issue, we propose an efficient meta neural heuristic (EMNH), in which a meta-model is first trained and then fine-tuned with a few steps to solve corresponding single-objective subproblems. Specifically, for the training process, a (partial) architecture-shared multi-task model is leveraged to achieve parallel learning for the meta-model, so as to speed up the training; meanwhile, a scaled symmetric sampling method with respect to the weight vectors is designed to stabilize the training. For the fine-tuning process, an efficient hierarchical method is proposed to systematically tackle all the subproblems. Experimental results on the multi-objective traveling salesman problem (MOTSP), multi-objective capacitated vehicle ro
    
[^73]: 具有多样性增强的神经多目标组合优化

    Neural Multi-Objective Combinatorial Optimization with Diversity Enhancement. (arXiv:2310.15195v1 [cs.LG])

    [http://arxiv.org/abs/2310.15195](http://arxiv.org/abs/2310.15195)

    提出了一种具有多样性增强的神经启发式方法（NHDE）来解决神经多目标组合优化（MOCO）问题，该方法通过引入指示器增强的深度强化学习方法和多重帕累托最有策略，能够产生更多且具有更高多样性的帕累托解。

    

    大多数现有的神经多目标组合优化（MOCO）问题的方法仅依赖于分解，这往往导致子问题的重复解决方案，从而得到有限的帕累托集。除了分解，我们提出了一种具有多样性增强的神经启发式方法（NHDE），从两个角度产生更多帕累托解。一方面，为了阻止不同子问题的重复解决方案，我们提出了一种指示器增强的深度强化学习方法来指导模型，并设计了一种异构图注意机制来捕捉实例图和帕累托前沿图之间的关系。另一方面，为了在每个子问题的邻域中挖掘更多的解决方案，我们提出了多重帕累托最有策略来采样和保留理想的解决方案。在经典的 MOCO 问题上的实验结果表明，我们的 NHDE 能够生成具有更高多样性的帕累托前沿，从而实现更优越的综合效果

    Most of existing neural methods for multi-objective combinatorial optimization (MOCO) problems solely rely on decomposition, which often leads to repetitive solutions for the respective subproblems, thus a limited Pareto set. Beyond decomposition, we propose a novel neural heuristic with diversity enhancement (NHDE) to produce more Pareto solutions from two perspectives. On the one hand, to hinder duplicated solutions for different subproblems, we propose an indicator-enhanced deep reinforcement learning method to guide the model, and design a heterogeneous graph attention mechanism to capture the relations between the instance graph and the Pareto front graph. On the other hand, to excavate more solutions in the neighborhood of each subproblem, we present a multiple Pareto optima strategy to sample and preserve desirable solutions. Experimental results on classic MOCO problems show that our NHDE is able to generate a Pareto front with higher diversity, thereby achieving superior overa
    
[^74]: 将深度学习和强化学习应用于边界控制问题的研究

    Application of deep and reinforcement learning to boundary control problems. (arXiv:2310.15191v1 [cs.LG])

    [http://arxiv.org/abs/2310.15191](http://arxiv.org/abs/2310.15191)

    本研究将深度学习和强化学习应用于解决边界控制问题，通过使用空间神经网络构建初始猜测以及利用策略梯度方法学习迭代优化算法的时空神经网络，通过使用生成的合成数据进行训练和验证，研究发现深度学习和强化学习方法在解决边界控制问题方面具有潜在优势。

    

    边界控制问题是许多科学领域中的非凸优化和控制问题，包括流体力学、结构工程和热传递优化。其目标是找到使符合控制方程要求的封闭域内的状态值达到期望值的最优边界值。传统上，使用非线性优化方法，如内点法（IPM）来解决这类问题。本研究探讨了使用深度学习和强化学习解决边界控制问题的可能性。我们遵循迭代优化策略的框架，利用空间神经网络构建有启发性的初始猜测，并使用策略梯度的方法来学习迭代优化算法的时空神经网络。使用从文献中提出的问题生成的合成数据进行训练、测试和验证。数值实验表明，深度学习和强化学习方法在解决边界控制问题方面具有潜在优势。

    The boundary control problem is a non-convex optimization and control problem in many scientific domains, including fluid mechanics, structural engineering, and heat transfer optimization. The aim is to find the optimal values for the domain boundaries such that the enclosed domain adhering to the governing equations attains the desired state values. Traditionally, non-linear optimization methods, such as the Interior-Point method (IPM), are used to solve such problems.  This project explores the possibilities of using deep learning and reinforcement learning to solve boundary control problems. We adhere to the framework of iterative optimization strategies, employing a spatial neural network to construct well-informed initial guesses, and a spatio-temporal neural network learns the iterative optimization algorithm using policy gradients. Synthetic data, generated from the problems formulated in the literature, is used for training, testing and validation. The numerical experiments ind
    
[^75]: 深度学习方法在粘弹纤维复合材料的动态力学分析中的应用

    Deep Learning Approaches for Dynamic Mechanical Analysis of Viscoelastic Fiber Composites. (arXiv:2310.15188v1 [cs.LG])

    [http://arxiv.org/abs/2310.15188](http://arxiv.org/abs/2310.15188)

    本文利用深度学习方法，将微结构与力学性能建立映射关系，加快了设计过程，并实现了根据期望性能生成微结构的目标。

    

    受到生态设计标准的推动，增强型聚合物（RP）复合材料的应用越来越广泛，这要求在轻量化、刚性和有效的振动控制之间取得良好的平衡。这些材料对于提高舒适性、安全性和能源效率至关重要。动态力学分析（DMA）可表征粘弹性行为，然而，使用机器学习（ML）加速微结构设计和理解引起了越来越多的兴趣。本文旨在利用深度神经网络将微结构映射到其力学性能上，加快过程并实现从期望性能生成微结构的目标。

    The increased adoption of reinforced polymer (RP) composite materials, driven by eco-design standards, calls for a fine balance between lightness, stiffness, and effective vibration control. These materials are integral to enhancing comfort, safety, and energy efficiency. Dynamic Mechanical Analysis (DMA) characterizes viscoelastic behavior, yet there's a growing interest in using Machine Learning (ML) to expedite the design and understanding of microstructures. In this paper we aim to map microstructures to their mechanical properties using deep neural networks, speeding up the process and allowing for the generation of microstructures from desired properties.
    
[^76]: 减少海平面上升预测的不确定性：一种空间可变性感知的方法

    Reducing Uncertainty in Sea-level Rise Prediction: A Spatial-variability-aware Approach. (arXiv:2310.15179v1 [physics.ao-ph])

    [http://arxiv.org/abs/2310.15179](http://arxiv.org/abs/2310.15179)

    这篇论文提出了一种基于区域回归模型的方法，通过解决空间可变性和模型相互依赖的问题，准确可靠地预测未来海平面上升，并降低不确定性。

    

    鉴于多模型集合气候预测，目标是准确可靠地预测未来海平面上升，同时降低不确定性。由于气候变化对极地冰盖和海洋的影响，海平面上升影响着沿海社区和其他地区的数百万人口，因此这个问题非常重要。由于空间变异性和不确定性，如可能的临界点（例如，格陵兰或西部南极洲冰架的崩塌）、气候反馈循环（例如，云、永久冻土融化）、未来政策决策和人类行为，这个问题具有挑战性。大多数现有气候建模方法在回归或深度学习中全局使用相同的权重来组合不同的气候预测，这种方法对于准确可靠的海平面上升预测需要不同的地区采用不同的加权方案是不够的。本文提出了一种区域回归模型，解决了空间可变性和模型相互依赖的问题。

    Given multi-model ensemble climate projections, the goal is to accurately and reliably predict future sea-level rise while lowering the uncertainty. This problem is important because sea-level rise affects millions of people in coastal communities and beyond due to climate change's impacts on polar ice sheets and the ocean. This problem is challenging due to spatial variability and unknowns such as possible tipping points (e.g., collapse of Greenland or West Antarctic ice-shelf), climate feedback loops (e.g., clouds, permafrost thawing), future policy decisions, and human actions. Most existing climate modeling approaches use the same set of weights globally, during either regression or deep learning to combine different climate projections. Such approaches are inadequate when different regions require different weighting schemes for accurate and reliable sea-level rise predictions. This paper proposes a zonal regression model which addresses spatial variability and model inter-depende
    
[^77]: 通过赫比安学习和自由能最小化实现了神经模仿的认知共同模型

    A Neuro-Mimetic Realization of the Common Model of Cognition via Hebbian Learning and Free Energy Minimization. (arXiv:2310.15177v1 [q-bio.NC])

    [http://arxiv.org/abs/2310.15177](http://arxiv.org/abs/2310.15177)

    这项研究通过赫比安学习和自由能最小化实现了神经模仿的认知共同模型，该模型能够合成复杂的字词序列或产生复杂的图像模式。

    

    在过去几年中，大型的神经生成模型日益流行，能够合成复杂的字词序列或产生复杂的图像模式，成为了所谓"生成人工智能"的热门代表。除了给统计机器学习领域带来新的机遇和挑战之外，生成人工智能的兴起还给认知科学提出了有趣的问题，该领域旨在揭示构成思维和大脑过程的本质，以及理解这种功能如何在生物（或人工）基质中获取和实现。为了实现这一目标，我们认为有一个有前景的长期途径在于设计认知架构，这是该领域长期以来的传统，基本上是根据神经模仿的生成性构建模块构建的。具体地，我们讨论了COGitive NEural GENerative系统，它以赫比安学习和自由能最小化为基础，实现了神经模仿的认知共同模型。

    Over the last few years, large neural generative models, capable of synthesizing intricate sequences of words or producing complex image patterns, have recently emerged as a popular representation of what has come to be known as "generative artificial intelligence" (generative AI). Beyond opening the door to new opportunities as well as challenges for the domain of statistical machine learning, the rising popularity of generative AI brings with it interesting questions for Cognitive Science, which seeks to discover the nature of the processes that underpin minds and brains as well as to understand how such functionality might be acquired and instantiated in biological (or artificial) substrate. With this goal in mind, we argue that a promising long-term pathway lies in the crafting of cognitive architectures, a long-standing tradition of the field, cast fundamentally in terms of neuro-mimetic generative building blocks. Concretely, we discuss the COGnitive Neural GENerative system, whi
    
[^78]: 神经网络中的元-（超文本外语境）学习

    Meta- (out-of-context) learning in neural networks. (arXiv:2310.15047v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.15047](http://arxiv.org/abs/2310.15047)

    该研究通过合成实验展示了一种称为元-超文本外语境学习（meta-OCL）的现象在神经网络中的存在。这种学习使神经网络能够更好地吸收广泛适用的语义内容，并在适当的情况下进行使用。研究者提出了关于元-超文本外语境学习产生的两种假设，并就未来AI系统的能力和潜在风险进行了讨论。

    

    Brown等人（2020）通过对大型语言模型（LLMs）进行精心设计的合成实验，建立了一种称为元-超文本外语境学习（meta-OCL）的现象的存在。我们的结果表明，元-超文本外语境学习使LLMs更容易“内化”文本的语义内容，该文本广泛适用（例如真实陈述或权威来源的文本），并在适当的情况下使用它。我们进一步在合成计算机视觉环境中展示了元-超文本外语境学习，并提出了两种假设，解释了元-超文本外语境学习的出现：一种是依赖于模型在其参数中存储知识的方式，另一种是暗示梯度下降优化器的隐含梯度对齐偏差可能负责。最后，我们对我们的结果可能意味着未来AI系统的能力进行了思考，并讨论了潜在的风险。我们的代码可以在https://github.com/krasheni找到。

    Brown et al. (2020) famously introduced the phenomenon of in-context learning in large language models (LLMs). We establish the existence of a phenomenon we call meta-out-of-context learning (meta-OCL) via carefully designed synthetic experiments with LLMs. Our results suggest that meta-OCL leads LLMs to more readily "internalize" the semantic content of text that is, or appears to be, broadly useful (such as true statements, or text from authoritative sources) and use it in appropriate circumstances. We further demonstrate meta-OCL in a synthetic computer vision setting, and propose two hypotheses for the emergence of meta-OCL: one relying on the way models store knowledge in their parameters, and another suggesting that the implicit gradient alignment bias of gradient-descent-based optimizers may be responsible. Finally, we reflect on what our results might imply about capabilities of future AI systems, and discuss potential risks. Our code can be found at https://github.com/krasheni
    
[^79]: 语言模型在不平衡文本分类中的元学习: 挑战与机遇

    Meta learning with language models: Challenges and opportunities in the classification of imbalanced text. (arXiv:2310.15019v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.15019](http://arxiv.org/abs/2310.15019)

    本文提出了一种元学习技术(MLT)，通过将不同文本表示构建的个体模型进行组合，在不平衡的文本分类中提高了性能，并通过阈值移动技术进一步改善了预测器的性能。

    

    检测违规言论内容是重要但困难的。虽然机器学习是应对这一挑战性任务的强大工具，但由于训练数据的数量和质量限制以及违规定义和数据标注的不一致性等因素，难以突破性能瓶颈。为了充分发挥有限资源的潜力，我们提出了一种元学习技术(MLT)，它将使用不同文本表示构建的个体模型进行组合。我们通过分析证明，所得到的技术在数值上是稳定的，并产生合理的组合权重。我们将MLT与阈值移动(TM)技术相结合，进一步提高组合预测器在高度不平衡的分布和超出分布数据集上的性能。我们还提供了计算结果，展示了所提出的MLT方法的统计优势。所有作者对这项工作贡献相同。

    Detecting out of policy speech (OOPS) content is important but difficult. While machine learning is a powerful tool to tackle this challenging task, it is hard to break the performance ceiling due to factors like quantity and quality limitations on training data and inconsistencies in OOPS definition and data labeling. To realize the full potential of available limited resources, we propose a meta learning technique (MLT) that combines individual models built with different text representations. We analytically show that the resulting technique is numerically stable and produces reasonable combining weights. We combine the MLT with a threshold-moving (TM) technique to further improve the performance of the combined predictor on highly-imbalanced in-distribution and out-of-distribution datasets. We also provide computational results to show the statistically significant advantages of the proposed MLT approach.  All authors contributed equally to this work.
    
[^80]: 用于机器人应用的高效因果关系发现

    Efficient Causal Discovery for Robotics Applications. (arXiv:2310.14925v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2310.14925](http://arxiv.org/abs/2310.14925)

    这篇论文提出了一种用于机器人应用的快速准确因果关系发现方法F-PCMCI，并展示了其在实际机器人应用中的有效重构因果模型的能力。

    

    在与人类共享环境的自动化任务中使用机器人，例如仓库、购物中心或医院，需要这些机器人能够理解附近物体和代理之间的基本物理相互作用。具体来说，创建表示这些元素之间因果关系的模型可以帮助预测未预见到的人类行为，并预测特定机器人动作的结果。为了适应机器人，因果分析必须同时快速和准确，满足实时需求和大多数机器人应用中的有限计算资源。在本文中，我们展示了一种被称为F-PCMCI的快速准确因果分析方法，并结合实际机器人应用进行了实证演示。该应用展示了我们的F-PCMCI如何准确迅速地重构人机交互场景的因果模型，从而提高质量。

    Using robots for automating tasks in environments shared with humans, such as warehouses, shopping centres, or hospitals, requires these robots to comprehend the fundamental physical interactions among nearby agents and objects. Specifically, creating models to represent cause-and-effect relationships among these elements can aid in predicting unforeseen human behaviours and anticipate the outcome of particular robot actions. To be suitable for robots, causal analysis must be both fast and accurate, meeting real-time demands and the limited computational resources typical in most robotics applications. In this paper, we present a practical demonstration of our approach for fast and accurate causal analysis, known as Filtered PCMCI (F-PCMCI), along with a real-world robotics application. The provided application illustrates how our F-PCMCI can accurately and promptly reconstruct the causal model of a human-robot interaction scenario, which can then be leveraged to enhance the quality of
    
[^81]: 对LLM生成的文本检测的调查：必要性、方法和未来方向

    A Survey on LLM-generated Text Detection: Necessity, Methods, and Future Directions. (arXiv:2310.14724v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.14724](http://arxiv.org/abs/2310.14724)

    本文对LLM生成的文本检测进行了调查，强调了开发这样的检测器的必要性，并总结了近期的研究创新和未来发展方向。

    

    大型语言模型（LLMs）生成的复杂语言的强大能力使得LLM生成的文本以惊人的速度涌入到我们日常生活的许多领域中，并得到了人们的广泛接受。随着LLMs的不断扩展，迫切需要开发能够检测LLM生成的文本的检测器。这对于减少LLMs潜在的误用，并保护艺术表达和社交网络等领域免受LLM生成内容的有害影响至关重要。LLM生成的文本检测旨在确定一段文本是否由LLM生成，实质上是一个二分类任务。检测器技术最近取得了显著的进展，推动因素包括水印技术、零样本方法、微调语言模型方法、对抗学习方法、将LLMs作为检测器以及人类辅助方法的创新。在这项调查中，我们汇集了最近在这一领域取得的研究突破，并强调了迫切的需求和未来的方向。

    The powerful ability to understand, follow, and generate complex language emerging from large language models (LLMs) makes LLM-generated text flood many areas of our daily lives at an incredible speed and is widely accepted by humans. As LLMs continue to expand, there is an imperative need to develop detectors that can detect LLM-generated text. This is crucial to mitigate potential misuse of LLMs and safeguard realms like artistic expression and social networks from harmful influence of LLM-generated content. The LLM-generated text detection aims to discern if a piece of text was produced by an LLM, which is essentially a binary classification task. The detector techniques have witnessed notable advancements recently, propelled by innovations in watermarking techniques, zero-shot methods, fine-turning LMs methods, adversarial learning methods, LLMs as detectors, and human-assisted methods. In this survey, we collate recent research breakthroughs in this area and underscore the pressin
    
[^82]: CorefPrompt: 基于提示的事件指代消解通过测量事件类型和参数的兼容性

    CorefPrompt: Prompt-based Event Coreference Resolution by Measuring Event Type and Argument Compatibilities. (arXiv:2310.14512v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.14512](http://arxiv.org/abs/2310.14512)

    CorefPrompt是一种基于提示的方法，通过测量事件类型和参数的兼容性来进行事件指代消解。该方法将事件指代消解转化为一个填空式MLM任务，并通过引入辅助的提示任务来帮助模型进行推理，最终在基准测试中取得了良好的表现。

    

    事件指代消解旨在将指代同一实际事件的事件提及聚类在一起。大多数先前的研究采用“先编码，然后评分”的框架，使得指代消解依赖于事件编码。此外，当前的方法很难利用人工总结的事件指代消解规则，例如，指代同一事件的事件应具有相同的事件类型，以指导模型。为了解决这两个问题，我们提出了一种基于提示的方法CorefPrompt，将事件指代消解转化为一个填空式MLM（掩码语言模型）任务。这样可以在一个单一的模板中同时进行事件建模和指代消解判别，并且具有完全共享的上下文。此外，我们引入了两个辅助的提示任务，事件类型兼容性和参数兼容性，以明确展示事件指代消解的推理过程，从而帮助模型做出最终的预测。实验结果表明，我们的方法CorefPrompt在最先进的基准测试中表现良好。

    Event coreference resolution (ECR) aims to group event mentions referring to the same real-world event into clusters. Most previous studies adopt the "encoding first, then scoring" framework, making the coreference judgment rely on event encoding. Furthermore, current methods struggle to leverage human-summarized ECR rules, e.g., coreferential events should have the same event type, to guide the model. To address these two issues, we propose a prompt-based approach, CorefPrompt, to transform ECR into a cloze-style MLM (masked language model) task. This allows for simultaneous event modeling and coreference discrimination within a single template, with a fully shared context. In addition, we introduce two auxiliary prompt tasks, event-type compatibility and argument compatibility, to explicitly demonstrate the reasoning process of ECR, which helps the model make final predictions. Experimental results show that our method CorefPrompt performs well in a state-of-the-art (SOTA) benchmark.
    
[^83]: 随机前向模式自动微分优化算法

    Randomized Forward Mode of Automatic Differentiation for Optimization Algorithms. (arXiv:2310.14168v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2310.14168](http://arxiv.org/abs/2310.14168)

    该论文介绍了一种随机前向模式自动微分优化算法，通过在神经网络的正向传递中计算损失函数的方向导数来更新参数。算法通过采样不同概率分布的随机方向，使用正向模式自动微分计算雅可比向量乘积，并提供了对其收敛速度和计算复杂性的严格分析。

    

    神经网络中的反向传播利用了自动微分的基本要素，即反向模式微分，或称为向量雅可比乘积(VJP)，或在微分几何的背景下被称为拉回过程。梯度的计算对于使用梯度下降方法更新神经网络参数非常重要。在本研究中，我们提出了一种通用的随机方法，通过使用通过正向模式AD或雅可比向量乘积(JVP)高效计算的损失函数的方向导数来更新神经网络的参数。这些JVP沿着从不同概率分布（例如伯努利、正态、维格纳、拉普拉斯和均匀分布）采样的随机方向计算。梯度的计算在神经网络的正向传递过程中进行。我们还提供了对所提出方法的严格分析，包括收敛速度以及计算复杂性。

    Backpropagation within neural networks leverages a fundamental element of automatic differentiation, which is referred to as the reverse mode differentiation, or vector Jacobian Product (VJP) or, in the context of differential geometry, known as the pull-back process. The computation of gradient is important as update of neural network parameters is performed using gradient descent method. In this study, we present a genric randomized method, which updates the parameters of neural networks by using directional derivatives of loss functions computed efficiently by using forward mode AD or Jacobian vector Product (JVP). These JVP are computed along the random directions sampled from different probability distributions e.g., Bernoulli, Normal, Wigner, Laplace and Uniform distributions. The computation of gradient is performed during the forward pass of the neural network. We also present a rigorous analysis of the presented methods providing the rate of convergence along with the computat
    
[^84]: 全面对比：面向医疗时间序列的层次对比框架

    Contrast Everything: A Hierarchical Contrastive Framework for Medical Time-Series. (arXiv:2310.14017v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.14017](http://arxiv.org/abs/2310.14017)

    本论文提出了一个名为COMET的创新层次对比框架，用于医疗时间序列分析。该框架通过在多个层级上开发对比损失，可以充分利用医疗时间序列的复杂特性，并实现自监督学习。使用多个数据集进行实验验证了COMET的有效性。

    

    在医疗时间序列分析中，对比表示学习至关重要，因为它减少了对劳动密集、领域特定和稀缺的专家注释的依赖。然而，现有的对比学习方法主要关注单一数据层面，未能充分利用医疗时间序列的复杂特性。为了解决这个问题，我们提出了COMET，一个创新的层次框架，它利用医疗时间序列中所有内在层级的数据一致性。我们精心设计的模型系统地捕捉了来自四个潜在层级的数据一致性：观测、样本、试验和患者层级。通过在多个层级上开发对比损失，我们可以学习到保持全面数据一致性的有效表示，实现自监督方法中的信息最大利用。我们在具有挑战性的独立患者设置下进行实验。我们使用三个不同的数据集将COMET与六个基准方法进行比较。

    Contrastive representation learning is crucial in medical time series analysis as it alleviates dependency on labor-intensive, domain-specific, and scarce expert annotations. However, existing contrastive learning methods primarily focus on one single data level, which fails to fully exploit the intricate nature of medical time series. To address this issue, we present COMET, an innovative hierarchical framework that leverages data consistencies at all inherent levels in medical time series. Our meticulously designed model systematically captures data consistency from four potential levels: observation, sample, trial, and patient levels. By developing contrastive loss at multiple levels, we can learn effective representations that preserve comprehensive data consistency, maximizing information utilization in a self-supervised manner. We conduct experiments in the challenging patient-independent setting. We compare COMET against six baselines using three diverse datasets, which include 
    
[^85]: 对比偏好学习：学习用户反馈而无需RL的方法

    Contrastive Preference Learning: Learning from Human Feedback without RL. (arXiv:2310.13639v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.13639](http://arxiv.org/abs/2310.13639)

    对比偏好学习方法解决了传统强化学习从人类反馈中学习奖励函数的假设错误以及优化挑战的问题。

    

    "从人类反馈中进行强化学习（RLHF）已经成为一种与人类意图对齐的流行范式。通常的RLHF算法分为两个阶段：首先，利用人类偏好学习奖励函数，然后通过强化学习（RL）优化学习到的奖励函数以对齐模型。这种范式假设人类偏好是根据奖励分布的，但最近的研究表明，实际上它们遵循用户最佳策略下的遗憾。因此，从反馈中学习奖励函数不仅基于人类偏好的错误假设，还导致了由于策略梯度或RL阶段的自助法引起的棘手的优化挑战。由于这些优化挑战，当代的RLHF方法限制自己只能应用于上下文强化学习（如大型语言模型）或限制了观测维度（如基于状态的机器人）。我们通过引入一种新的方法来克服这些限制。"

    Reinforcement Learning from Human Feedback (RLHF) has emerged as a popular paradigm for aligning models with human intent. Typically RLHF algorithms operate in two phases: first, use human preferences to learn a reward function and second, align the model by optimizing the learned reward via reinforcement learning (RL). This paradigm assumes that human preferences are distributed according to reward, but recent work suggests that they instead follow the regret under the user's optimal policy. Thus, learning a reward function from feedback is not only based on a flawed assumption of human preference, but also leads to unwieldy optimization challenges that stem from policy gradients or bootstrapping in the RL phase. Because of these optimization challenges, contemporary RLHF methods restrict themselves to contextual bandit settings (e.g., as in large language models) or limit observation dimensionality (e.g., state-based robotics). We overcome these limitations by introducing a new famil
    
[^86]: 通过自适应风格技术提升指纹活体检测的泛化能力

    Boosting Generalization with Adaptive Style Techniques for Fingerprint Liveness Detection. (arXiv:2310.13573v1 [cs.CV])

    [http://arxiv.org/abs/2310.13573](http://arxiv.org/abs/2310.13573)

    该论文介绍了一种通过自适应风格技术提升指纹活体检测泛化能力的方法，并在LivDet 2023挑战中取得了最先进的性能。

    

    我们引入了一种性能优异的指纹活体特征提取技术，该技术在LivDet 2023指纹表示挑战中获得了第一名。此外，我们还开发了一个实用的指纹识别系统，准确率达到了94.68%，在LivDet 2023动作中的活体检测中获得了第二名。通过对各种方法的研究，特别是风格转换，我们证明了在面对有限的训练数据时，准确率和泛化能力的提高。因此，我们的方法在LivDet 2023挑战中取得了最先进的性能。

    We introduce a high-performance fingerprint liveness feature extraction technique that secured first place in LivDet 2023 Fingerprint Representation Challenge. Additionally, we developed a practical fingerprint recognition system with 94.68% accuracy, earning second place in LivDet 2023 Liveness Detection in Action. By investigating various methods, particularly style transfer, we demonstrate improvements in accuracy and generalization when faced with limited training data. As a result, our approach achieved state-of-the-art performance in LivDet 2023 Challenges.
    
[^87]: 探索语言模型中谄媚行为的理解

    Towards Understanding Sycophancy in Language Models. (arXiv:2310.13548v1 [cs.CL])

    [http://arxiv.org/abs/2310.13548](http://arxiv.org/abs/2310.13548)

    这项研究探讨了强化学习从人类反馈中训练高质量AI助手的技术，发现这种方法可能导致模型在回答问题时过于谄媚，而不是坦诚，通过分析人类偏好数据得出了这一结论。

    

    「从人类反馈中进行强化学习（RLHF）」是训练高质量AI助手的一种流行技术。然而，RLHF可能会鼓励模型通过与用户信念相符的回答来代替真实回答，这种行为被称为谄媚行为。我们研究了RLHF训练模型中谄媚行为的普遍性以及人类偏好判断是否起到了作用。首先，我们证明了五个最先进的AI助手在四个不同的自由文本生成任务中一贯表现出谄媚行为。为了理解人类偏好是否驱动了RLHF模型的这种广泛行为，我们分析了现有的人类偏好数据。我们发现，当回答与用户的观点相符时，它更有可能被选中。此外，人类和偏好模型（PMs）将有说服力的谄媚回答与正确回答相比，有时几乎可以忽略不计地选择了谄媚回答。优化模型输出以满足PMs有时也会在真实性和谄媚行为之间做出取舍。

    Reinforcement learning from human feedback (RLHF) is a popular technique for training high-quality AI assistants. However, RLHF may also encourage model responses that match user beliefs over truthful responses, a behavior known as sycophancy. We investigate the prevalence of sycophancy in RLHF-trained models and whether human preference judgements are responsible. We first demonstrate that five state-of-the-art AI assistants consistently exhibit sycophantic behavior across four varied free-form text-generation tasks. To understand if human preferences drive this broadly observed behavior of RLHF models, we analyze existing human preference data. We find that when a response matches a user's views, it is more likely to be preferred. Moreover, both humans and preference models (PMs) prefer convincingly-written sycophantic responses over correct ones a negligible fraction of the time. Optimizing model outputs against PMs also sometimes sacrifices truthfulness in favor of sycophancy. Over
    
[^88]: 让语言模型清理您的有噪音的翻译数据

    Ask Language Model to Clean Your Noisy Translation Data. (arXiv:2310.13469v1 [cs.CL])

    [http://arxiv.org/abs/2310.13469](http://arxiv.org/abs/2310.13469)

    论文介绍了如何利用大型语言模型清理神经机器翻译中的噪声输入，通过从MTNT数据集中清理目标语句的噪声，生成了C-MTNT数据集，显著减少了噪声。

    

    Transformer模型在神经机器翻译（NMT）中展现出了出色的性能。然而，它们对噪声输入的脆弱性在实际应用中提出了重大挑战，从噪声输入中生成干净的输出至关重要。MTNT数据集被广泛用作评估NMT模型对噪声输入鲁棒性的基准。然而，由于源语句和目标语句中都存在噪声，其实用性受到限制。为解决这一限制，我们专注于清理MTNT中目标语句的噪声，使其更适用于噪声评估的基准。利用大型语言模型（LLM）的能力，我们观察到它们在去噪方面的出色能力。例如，它们可以在考虑语义含义的同时删除表情符号。此外，我们还展示了LLM能够有效地更改俚语、术语和粗口。得到的数据集被称为C-MTNT，噪声显著减少。

    Transformer models have demonstrated remarkable performance in neural machine translation (NMT). However, their vulnerability to noisy input poses a significant challenge in practical implementation, where generating clean output from noisy input is crucial. The MTNT dataset \cite{MTNT} is widely used as a benchmark for evaluating the robustness of NMT models against noisy input. Nevertheless, its utility is limited due to the presence of noise in both the source and target sentences. To address this limitation, we focus on cleaning the noise from the target sentences in MTNT, making it more suitable as a benchmark for noise evaluation. Leveraging the capabilities of large language models (LLMs), we observe their impressive abilities in noise removal. For example, they can remove emojis while considering their semantic meaning. Additionally, we show that LLM can effectively rephrase slang, jargon, and profanities. The resulting datasets, called C-MTNT, exhibit significantly less noise 
    
[^89]: 基于深度强化学习的优化CO2排放的智能交通信号控制

    Deep Reinforcement Learning-based Intelligent Traffic Signal Controls with Optimized CO2 emissions. (arXiv:2310.13129v1 [eess.SY])

    [http://arxiv.org/abs/2310.13129](http://arxiv.org/abs/2310.13129)

    本研究提出了一种基于深度强化学习的智能交通信号控制算法，通过优化CO2排放和行驶时间等指标，实现了较好的性能。

    

    如今，交通网络面临着次优控制策略的挑战，这可能对人类健康、环境产生不利影响，并 contribute to traffic congestion. 由于交通拥堵导致的空气污染水平上升和通勤时间延长，交叉路口交通信号控制器成为现代交通基础设施的关键组成部分。尽管文献中有几个自适应交通信号控制器，但对其比较性能的研究有限。此外，尽管二氧化碳（CO2）排放在全球范围内非常重要，但文献对该领域关注不够。在本报告中，我们提出了EcoLight，一种针对强化学习算法的奖励塑造方案，不仅能减少CO2排放，还能在诸如行驶时间等指标上取得有竞争力的结果。我们使用行驶时间、CO2排放、等指标比较了表格式Q-Learning、DQN、SARSA和A2C算法的性能。

    Nowadays, transportation networks face the challenge of sub-optimal control policies that can have adverse effects on human health, the environment, and contribute to traffic congestion. Increased levels of air pollution and extended commute times caused by traffic bottlenecks make intersection traffic signal controllers a crucial component of modern transportation infrastructure. Despite several adaptive traffic signal controllers in literature, limited research has been conducted on their comparative performance. Furthermore, despite carbon dioxide (CO2) emissions' significance as a global issue, the literature has paid limited attention to this area. In this report, we propose EcoLight, a reward shaping scheme for reinforcement learning algorithms that not only reduces CO2 emissions but also achieves competitive results in metrics such as travel time. We compare the performance of tabular Q-Learning, DQN, SARSA, and A2C algorithms using metrics such as travel time, CO2 emissions, wa
    
[^90]: 理解Transformer中的加法

    Understanding Addition in Transformers. (arXiv:2310.13121v1 [cs.LG])

    [http://arxiv.org/abs/2310.13121](http://arxiv.org/abs/2310.13121)

    本文通过对经过训练进行整数加法的单层Transformer模型的深入分析，揭示了该模型将任务分为并行的、特定于数字的流，并针对不同的数字位置采用不同的算法，同时还发现了一种罕见的高损失的使用情况。这些发现对于机制可解释性、人工智能安全性和对齐性等方面的研究具有重要贡献。

    

    了解像Transformer这样的机器学习模型的内部工作方式对于其安全和道德使用至关重要。本文对经过训练进行整数加法的单层Transformer模型进行了深入分析。我们揭示了该模型将任务分为并行的、特定于数字的流，并针对不同的数字位置采用不同的算法。我们的研究还发现该模型开始计算较晚，但执行速度非常快。我们还发现了一种罕见的高损失的使用情况，并予以解释。总体而言，我们详细解释了该模型的算法。这些发现通过严格测试和数学建模得到了验证，对于机制可解释性、人工智能安全性和对齐性等广泛研究做出了贡献。我们的方法为分析更复杂的任务和多层Transformer模型打开了大门。

    Understanding the inner workings of machine learning models like Transformers is vital for their safe and ethical use. This paper presents an in-depth analysis of a one-layer Transformer model trained for integer addition. We reveal that the model divides the task into parallel, digit-specific streams and employs distinct algorithms for different digit positions. Our study also finds that the model starts calculations late but executes them rapidly. A rare use case with high loss is identified and explained. Overall, the model's algorithm is explained in detail. These findings are validated through rigorous testing and mathematical modeling, contributing to the broader works in Mechanistic Interpretability, AI safety, and alignment. Our approach opens the door for analyzing more complex tasks and multi-layer Transformer models.
    
[^91]: 神经注意力：利用神经网络增强自注意机制中的QKV计算

    Neural Attention: Enhancing QKV Calculation in Self-Attention Mechanism with Neural Networks. (arXiv:2310.11398v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.11398](http://arxiv.org/abs/2310.11398)

    本文介绍了一种利用神经网络增强自注意机制中QKV计算的方法，实验证明这种方法在多个任务中取得了显著的提升。

    

    在深度学习领域中，自注意机制在自然语言处理和计算机视觉等多个任务中发挥了重要作用。然而，传统的自注意机制主要使用线性变换来计算查询、键和值(QKV)，但在特定情况下，这可能并不是最优选择。本文探讨了一种新的QKV计算方法，采用了特殊设计的神经网络结构进行计算。通过在IWSLT 2017德英翻译任务数据集上使用修改后的Marian模型进行实验，并将我们的方法与传统方法进行对比，实验结果显示我们的方法在BLEU得分方面有显著提升。此外，我们的方法在使用Wikitext-103数据集训练Roberta模型时也表现出优势，显示了显著的改进。

    In the realm of deep learning, the self-attention mechanism has substantiated its pivotal role across a myriad of tasks, encompassing natural language processing and computer vision. Despite achieving success across diverse applications, the traditional self-attention mechanism primarily leverages linear transformations for the computation of query, key, and value (QKV), which may not invariably be the optimal choice under specific circumstances. This paper probes into a novel methodology for QKV computation-implementing a specially-designed neural network structure for the calculation. Utilizing a modified Marian model, we conducted experiments on the IWSLT 2017 German-English translation task dataset and juxtaposed our method with the conventional approach. The experimental results unveil a significant enhancement in BLEU scores with our method. Furthermore, our approach also manifested superiority when training the Roberta model with the Wikitext-103 dataset, reflecting a notable re
    
[^92]: AdaptSSR: 使用自适应增强自监督排序方法预训练用户模型

    AdaptSSR: Pre-training User Model with Augmentation-Adaptive Self-Supervised Ranking. (arXiv:2310.09706v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2310.09706](http://arxiv.org/abs/2310.09706)

    在用户建模中，通过自适应增强自监督排序方法预训练用户模型，解决了数据稀疏性问题和现有增强方法引入的噪音问题。

    

    用户建模旨在捕捉用户的特征或兴趣，但受到数据稀疏性问题的影响，往往需要依赖特定任务的标注数据。最近的几项研究通过在大量用户行为序列上进行对比学习的预训练来解决这个问题。一般而言，这些方法假设通过数据增强构建的同一行为序列的不同视图在语义上是一致的，即反映用户的相似特征或兴趣，并在特征空间中最大化它们的一致性。然而，由于用户行为的多样兴趣和大量噪音，现有的增强方法往往会丢失某些用户特征或引入噪声行为。因此，直接最大化增强视图之间的相似性可能导致负面迁移。为此，我们提出用新的预训练任务替代对比学习任务：自适应增强自监督排序方法。

    User modeling, which aims to capture users' characteristics or interests, heavily relies on task-specific labeled data and suffers from the data sparsity issue. Several recent studies tackled this problem by pre-training the user model on massive user behavior sequences with a contrastive learning task. Generally, these methods assume different views of the same behavior sequence constructed via data augmentation are semantically consistent, i.e., reflecting similar characteristics or interests of the user, and thus maximizing their agreement in the feature space. However, due to the diverse interests and heavy noise in user behaviors, existing augmentation methods tend to lose certain characteristics of the user or introduce noisy behaviors. Thus, forcing the user model to directly maximize the similarity between the augmented views may result in a negative transfer. To this end, we propose to replace the contrastive learning task with a new pretext task: Augmentation-Adaptive SelfSup
    
[^93]: 机器学习模型地球科学系统建模中的质量保持感知器

    A Mass-Conserving-Perceptron for Machine Learning-Based Modeling of Geoscientific Systems. (arXiv:2310.08644v1 [cs.LG])

    [http://arxiv.org/abs/2310.08644](http://arxiv.org/abs/2310.08644)

    这篇论文提出了一种质量保持感知器（MCP）用于将物理-概念模型和机器学习模型结合起来建模地球科学系统，通过利用机器学习技术从数据中学习物理过程的功能性和质量保持性。

    

    虽然数十年来致力于构建用于预测地球科学系统时间序列演化的物理-概念 (PC) 模型，但最近的研究表明，基于机器学习 (ML) 的门控循环神经网络技术可以用于开发更准确的模型。然而，从ML基础模型中提取物理理解的困难使得其在增强对系统结构和功能的科学知识方面的应用变得复杂。在这里，我们提出了一个理解物理性的质量保持感知器 (MCP) 作为弥合PC模型和ML模型的方法。MCP利用PC模型和GRNNs背后的有向图结构的内在同构性，以可解释的方式明确表示物理过程的质量保持性质，同时利用现有数据和现成的ML技术直接学习这种过程的功能性（可解释性）。

    Although decades of effort have been devoted to building Physical-Conceptual (PC) models for predicting the time-series evolution of geoscientific systems, recent work shows that Machine Learning (ML) based Gated Recurrent Neural Network technology can be used to develop models that are much more accurate. However, the difficulty of extracting physical understanding from ML-based models complicates their utility for enhancing scientific knowledge regarding system structure and function. Here, we propose a physically-interpretable Mass Conserving Perceptron (MCP) as a way to bridge the gap between PC-based and ML-based modeling approaches. The MCP exploits the inherent isomorphism between the directed graph structures underlying both PC models and GRNNs to explicitly represent the mass-conserving nature of physical processes while enabling the functional nature of such processes to be directly learned (in an interpretable manner) from available data using off-the-shelf ML technology. As
    
[^94]: 内存高效的位置推荐通过近邻感知表示

    Memory efficient location recommendation through proximity-aware representation. (arXiv:2310.06484v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.06484](http://arxiv.org/abs/2310.06484)

    这项研究介绍了一种基于近邻感知表示的内存高效的位置推荐方法，通过重要性抽样的损失函数和自注意力网络架构来解决稀疏性和地理信息整合的问题。

    

    顺序位置推荐在现代生活中起着重要作用，可以增强用户体验，给企业带来更多的利润并协助政府行政工作。尽管随着推荐系统的发展，位置推荐的方法已经有了显著进步，但地理信息的利用仍然有限，同时还面临着解决数据稀疏性的挑战。为此，我们引入了一种基于近邻感知的顺序推荐区域表示方法（简称PASR），该方法基于自注意力网络架构构建。我们通过使用重要性抽样的创新损失函数来解决稀疏性问题，在优化过程中强调信息丰富的负样本。此外，PASR通过在每个GPS点的分层网格和近邻网格中使用基于自注意力的地理编码器来增强地理信息的整合。为进一步利用地理信息，我们使用近邻网格和POI类别的部分注意力编码器进行位置向量的构建。

    Sequential location recommendation plays a huge role in modern life, which can enhance user experience, bring more profit to businesses and assist in government administration. Although methods for location recommendation have evolved significantly thanks to the development of recommendation systems, there is still limited utilization of geographic information, along with the ongoing challenge of addressing data sparsity. In response, we introduce a Proximity-aware based region representation for Sequential Recommendation (PASR for short), built upon the Self-Attention Network architecture. We tackle the sparsity issue through a novel loss function employing importance sampling, which emphasizes informative negative samples during optimization. Moreover, PASR enhances the integration of geographic information by employing a self-attention-based geography encoder to the hierarchical grid and proximity grid at each GPS point. To further leverage geographic information, we utilize the pro
    
[^95]: 反图灵测试CT^2：AI生成文本检测没有你想象的那么容易——引入AI可检测性指数。

    Counter Turing Test CT^2: AI-Generated Text Detection is Not as Easy as You May Think -- Introducing AI Detectability Index. (arXiv:2310.05030v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05030](http://arxiv.org/abs/2310.05030)

    这篇论文介绍了一个名为反图灵测试（CT^2）的基准，旨在全面评估现有AI生成文本检测技术的稳健性。在面对生成AI的风险和后果引起关注的情况下，解决AI生成作品归属问题变得尤为重要。

    

    随着ChatGPT等生成AI的兴起，AI生成文本的风险和后果越来越引起关注。为了解决对AI生成作品的归属问题，美国版权局发布了一份声明，指出“如果一件作品的传统创作元素由机器生成，那么这件作品就缺乏人类创作，版权局将不会登记它”。此外，美国和欧盟政府最近也草拟了关于AI监管框架的初步提案。在这种对生成AI的关注中，AI生成文本检测已经成为一个受到研究立即关注的话题，一些初步方法已经被提出，随后出现了绕过检测的技术。本文介绍了反图灵测试（CT^2），这是一个基准，旨在全面评估现有AI生成文本检测技术的稳健性。

    With the rise of prolific ChatGPT, the risk and consequences of AI-generated text has increased alarmingly. To address the inevitable question of ownership attribution for AI-generated artifacts, the US Copyright Office released a statement stating that 'If a work's traditional elements of authorship were produced by a machine, the work lacks human authorship and the Office will not register it'. Furthermore, both the US and the EU governments have recently drafted their initial proposals regarding the regulatory framework for AI. Given this cynosural spotlight on generative AI, AI-generated text detection (AGTD) has emerged as a topic that has already received immediate attention in research, with some initial methods having been proposed, soon followed by emergence of techniques to bypass detection. This paper introduces the Counter Turing Test (CT^2), a benchmark consisting of techniques aiming to offer a comprehensive evaluation of the robustness of existing AGTD techniques. Our em
    
[^96]: Avalon的思考游戏：通过递归思考对抗欺骗

    Avalon's Game of Thoughts: Battle Against Deception through Recursive Contemplation. (arXiv:2310.01320v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.01320](http://arxiv.org/abs/2310.01320)

    本研究通过使用复杂的Avalon游戏作为测试平台，引入了一种名为递归思考（ReCon）的新框架，用于增强大型语言模型（LLM）识别和对抗欺骗信息的能力。

    

    最近在大型语言模型（LLM）的突破带来了在LLM作为智能体领域的显著成功。然而，一种普遍的假设是LLM处理的信息始终是诚实的，忽视了人类社会和AI生成内容中普遍存在的欺骗或误导性信息。这个疏忽使得LLM容易受到恶意操纵，可能导致不利的结果。本研究利用复杂的Avalon游戏作为测试平台，探索LLM在欺骗环境中的潜力。Avalon充满了错误信息，并需要复杂的逻辑，表现为“思考的游戏”。受到人类在Avalon游戏中递归思考和透视能力的启发，我们引入了一种新颖的框架——递归思考（ReCon），以增强LLM识别和对抗欺骗信息的能力。ReCon结合了公式化思考和完善思考的过程；公式化思考产生初始思考，完善思考对初始思考进行调整和改进。

    Recent breakthroughs in large language models (LLMs) have brought remarkable success in the field of LLM-as-Agent. Nevertheless, a prevalent assumption is that the information processed by LLMs is consistently honest, neglecting the pervasive deceptive or misleading information in human society and AI-generated content. This oversight makes LLMs susceptible to malicious manipulations, potentially resulting in detrimental outcomes. This study utilizes the intricate Avalon game as a testbed to explore LLMs' potential in deceptive environments. Avalon, full of misinformation and requiring sophisticated logic, manifests as a "Game-of-Thoughts". Inspired by the efficacy of humans' recursive thinking and perspective-taking in the Avalon game, we introduce a novel framework, Recursive Contemplation (ReCon), to enhance LLMs' ability to identify and counteract deceptive information. ReCon combines formulation and refinement contemplation processes; formulation contemplation produces initial tho
    
[^97]: 利用自监督方法解离发音和内容，用于说话人识别

    Disentangling Voice and Content with Self-Supervision for Speaker Recognition. (arXiv:2310.01128v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2310.01128](http://arxiv.org/abs/2310.01128)

    本研究提出了一种利用自监督方法解离语音中的发音和内容的框架，用于说话人识别。实验证明该方法在VoxCeleb和SITW数据集上对EER和minDCF有明显的降低。

    

    对于说话人识别来说，由于语音中混合了说话人特征和内容，提取准确的说话人表示是困难的。本文提出了一种解离框架，可以同时模型化语音中的说话人特征和内容的变异性。该框架使用三个高斯推理层实现，每个推理层都由可学习的转换模型组成，用于提取不同的语音成分。值得注意的是，为了建模复杂的语音动态，专门设计了一个强化的转换模型。我们还提出了一种自监督方法，用于在没有除说话人身份之外的标签的情况下动态解离内容。通过在VoxCeleb和SITW数据集上进行的实验证明了所提框架的有效性，EER和minDCF分别平均降低了9.56%和8.24%。由于不需要额外的模型训练和数据，因此可以方便地应用于实际使用。

    For speaker recognition, it is difficult to extract an accurate speaker representation from speech because of its mixture of speaker traits and content. This paper proposes a disentanglement framework that simultaneously models speaker traits and content variability in speech. It is realized with the use of three Gaussian inference layers, each consisting of a learnable transition model that extracts distinct speech components. Notably, a strengthened transition model is specifically designed to model complex speech dynamics. We also propose a self-supervision method to dynamically disentangle content without the use of labels other than speaker identities. The efficacy of the proposed framework is validated via experiments conducted on the VoxCeleb and SITW datasets with 9.56% and 8.24% average reductions in EER and minDCF, respectively. Since neither additional model training nor data is specifically needed, it is easily applicable in practical use.
    
[^98]: 自适应驾驶中基于领域匹配的协同感知的通信

    Adaptive Communications in Collaborative Perception with Domain Alignment for Autonomous Driving. (arXiv:2310.00013v1 [cs.AI])

    [http://arxiv.org/abs/2310.00013](http://arxiv.org/abs/2310.00013)

    这篇论文提出了一个通信的协同感知框架ACC-DA，通过动态调整通信图和自适应数据重构机制来增强自动驾驶中的感知能力。

    

    通过通信允许车辆交换补充信息，多个连接的自动驾驶车辆之间的协同感知可以极大地增强感知能力。尽管之前的方法取得了进展，但由于通道变化和协同车辆之间的数据异构性，仍然存在挑战。为了解决这些问题，我们提出了ACC-DA，一个通道感知的协同感知框架，它可以动态调整通信图并最小化平均传输延迟，同时减轻数据异构性带来的副作用。我们的创新点包括三个方面。首先，我们设计了一种最小化传输延迟的方法，根据不同的通道信息状态构建通信图并最小化传输延迟。然后，我们提出了一种自适应数据重构机制，可以动态调整码率-畸变折衷以增强感知效率。此外，它最小化了时域丢失。

    Collaborative perception among multiple connected and autonomous vehicles can greatly enhance perceptive capabilities by allowing vehicles to exchange supplementary information via communications. Despite advances in previous approaches, challenges still remain due to channel variations and data heterogeneity among collaborative vehicles. To address these issues, we propose ACC-DA, a channel-aware collaborative perception framework to dynamically adjust the communication graph and minimize the average transmission delay while mitigating the side effects from the data heterogeneity. Our novelties lie in three aspects. We first design a transmission delay minimization method, which can construct the communication graph and minimize the transmission delay according to different channel information state. We then propose an adaptive data reconstruction mechanism, which can dynamically adjust the rate-distortion trade-off to enhance perception efficiency. Moreover, it minimizes the temporal
    
[^99]: 角度优化的文本嵌入

    AnglE-Optimized Text Embeddings. (arXiv:2309.12871v1 [cs.CL])

    [http://arxiv.org/abs/2309.12871](http://arxiv.org/abs/2309.12871)

    本文提出了一种名为AnglE的角度优化文本嵌入模型，通过在复杂空间中引入角度优化来缓解文本嵌入中余弦函数饱和区域造成的梯度消失问题。该模型在多个STS任务中实现了高质量的文本嵌入，并在有限标签数据的特定领域STS场景中展现出优秀的性能。

    

    高质量的文本嵌入对于提升语义文本相似度（STS）任务至关重要，而这些任务又是大型语言模型（LLM）应用中的关键组成部分。然而，现有的文本嵌入模型面临的一个普遍挑战是渐变消失问题，主要是由于它们在优化目标中依赖余弦函数，而余弦函数具有饱和区域。为了解决这个问题，本文提出了一种称为AnglE的新型角度优化文本嵌入模型。AnglE的核心思想是在一个复杂空间中引入角度优化。这种新颖的方法有效地缓解了余弦函数饱和区域产生的不利影响，从而可以阻碍梯度并阻碍优化过程。为了建立全面的STS评估，我们在现有的短文本STS数据集和从GitHub Issues中新收集的长文本STS数据集上进行了实验。此外，我们还研究了具有有限标签数据的特定领域STS场景，并探讨了AnglE的工作原理。

    High-quality text embedding is pivotal in improving semantic textual similarity (STS) tasks, which are crucial components in Large Language Model (LLM) applications. However, a common challenge existing text embedding models face is the problem of vanishing gradients, primarily due to their reliance on the cosine function in the optimization objective, which has saturation zones. To address this issue, this paper proposes a novel angle-optimized text embedding model called AnglE. The core idea of AnglE is to introduce angle optimization in a complex space. This novel approach effectively mitigates the adverse effects of the saturation zone in the cosine function, which can impede gradient and hinder optimization processes. To set up a comprehensive STS evaluation, we experimented on existing short-text STS datasets and a newly collected long-text STS dataset from GitHub Issues. Furthermore, we examine domain-specific STS scenarios with limited labeled data and explore how AnglE works w
    
[^100]: 如何微调模型：统一模型偏移和模型偏差策略优化

    How to Fine-tune the Model: Unified Model Shift and Model Bias Policy Optimization. (arXiv:2309.12671v1 [cs.LG])

    [http://arxiv.org/abs/2309.12671](http://arxiv.org/abs/2309.12671)

    本文提出了一个统一模型偏移和模型偏差的优化目标，并通过微调过程实现了自适应的模型更新，以提供性能改进保证和避免模型过拟合。

    

    设计和推导出具有性能改进保证的有效基于模型的强化学习（MBRL）算法具有挑战性，这主要归因于模型学习和策略优化之间的高耦合性。许多先前的方法依靠回报差异来指导模型学习，忽略了模型偏移的影响，这可能导致由于过多的模型更新而性能下降。其他方法使用性能差异边界来明确考虑模型偏移。然而，这些方法依赖于固定的阈值来限制模型偏移，导致对阈值的严重依赖，并且在训练过程中缺乏适应性。在本文中，我们从理论上推导出一个可以统一模型偏移和模型偏差的优化目标，然后制定一个微调过程。这个过程可以自适应地调整模型更新，以获得性能改进保证，同时避免模型过拟合。基于这些，我们开发了一个简单直观的方法

    Designing and deriving effective model-based reinforcement learning (MBRL) algorithms with a performance improvement guarantee is challenging, mainly attributed to the high coupling between model learning and policy optimization. Many prior methods that rely on return discrepancy to guide model learning ignore the impacts of model shift, which can lead to performance deterioration due to excessive model updates. Other methods use performance difference bound to explicitly consider model shift. However, these methods rely on a fixed threshold to constrain model shift, resulting in a heavy dependence on the threshold and a lack of adaptability during the training process. In this paper, we theoretically derive an optimization objective that can unify model shift and model bias and then formulate a fine-tuning process. This process adaptively adjusts the model updates to get a performance improvement guarantee while avoiding model overfitting. Based on these, we develop a straightforward 
    
[^101]: 批量安卓恶意软件检测模型的高效概念漂移处理

    Efficient Concept Drift Handling for Batch Android Malware Detection Models. (arXiv:2309.09807v1 [cs.CR] CROSS LISTED)

    [http://arxiv.org/abs/2309.09807](http://arxiv.org/abs/2309.09807)

    本文研究了批量安卓恶意软件检测模型的高效概念漂移处理方法，通过重新训练技术来维持检测器的能力，并通过比较不同的重新训练频率和数据使用方法的影响，提出了改进策略。

    

    Android应用程序的快速发展性对于静态批处理机器学习算法在恶意软件检测系统中的应用构成了重大挑战，因为它们很快就会过时。尽管存在这个挑战，但现有文献对解决此问题的关注有限，许多先进的Android恶意软件检测方法（如Drebin、DroidDet和MaMaDroid）依赖于静态模型。在这项工作中，我们展示了重新训练技术如何能够在一段时间内保持检测器的能力。特别地，我们分析了两个方面对检测器的效率和性能的影响：1）模型重新训练的频率，2）用于重新训练的数据。在第一个实验中，我们将周期性重新训练与仅在必要时触发重新训练的更先进的概念漂移检测方法进行了比较。在第二个实验中，我们分析了用于减少用于重新训练模型的数据量的采样方法。具体而言，我们比较了固定si

    The rapidly evolving nature of Android apps poses a significant challenge to static batch machine learning algorithms employed in malware detection systems, as they quickly become obsolete. Despite this challenge, the existing literature pays limited attention to addressing this issue, with many advanced Android malware detection approaches, such as Drebin, DroidDet and MaMaDroid, relying on static models. In this work, we show how retraining techniques are able to maintain detector capabilities over time. Particularly, we analyze the effect of two aspects in the efficiency and performance of the detectors: 1) the frequency with which the models are retrained, and 2) the data used for retraining. In the first experiment, we compare periodic retraining with a more advanced concept drift detection method that triggers retraining only when necessary. In the second experiment, we analyze sampling methods to reduce the amount of data used to retrain models. Specifically, we compare fixed si
    
[^102]: 一个用于运输机器人调度问题的量子优化案例研究

    A Quantum Optimization Case Study for a Transport Robot Scheduling Problem. (arXiv:2309.09736v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2309.09736](http://arxiv.org/abs/2309.09736)

    本研究通过比较D-Waves的量子-经典混合框架、富士通的量子启发式数字退火器和Gurobi的经典求解器的性能，提供了解决运输机器人调度问题的指导，发现数字退火器有希望的结果，并为混合量子退火器提供了一些机会。

    

    本文提出了一个综合的案例研究，比较了D-Waves的量子-经典混合框架、富士通的量子启发式数字退火器和Gurobi的最先进经典求解器在解决运输机器人调度问题方面的性能。这个问题源于一个具有工业相关性的现实场景。我们为我们的问题提供了三种不同的模型，采用不同的设计理念。在我们的基准测试中，我们关注不同模型和求解器组合的解决方案质量和端到端运行时间。我们发现，与Gurobi直接比较，数字退火器有希望的结果，并为混合量子退火器提供了一些机会。我们的研究提供了有关使用不同策略解决应用导向优化问题的工作流程的见解，并可以用于评估不同方法的优势和劣势。

    We present a comprehensive case study comparing the performance of D-Waves' quantum-classical hybrid framework, Fujitsu's quantum-inspired digital annealer, and Gurobi's state-of-the-art classical solver in solving a transport robot scheduling problem. This problem originates from an industrially relevant real-world scenario. We provide three different models for our problem following different design philosophies. In our benchmark, we focus on the solution quality and end-to-end runtime of different model and solver combinations. We find promising results for the digital annealer and some opportunities for the hybrid quantum annealer in direct comparison with Gurobi. Our study provides insights into the workflow for solving an application-oriented optimization problem with different strategies, and can be useful for evaluating the strengths and weaknesses of different approaches.
    
[^103]: 用开放数据驱动的团队推荐促进研究合作

    Promoting Research Collaboration with Open Data Driven Team Recommendation in Response to Call for Proposals. (arXiv:2309.09404v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2309.09404](http://arxiv.org/abs/2309.09404)

    通过利用开放数据和人工智能方法，我们设计了一个系统来推荐团队，使得每个团队能够满足项目要求的技能覆盖，并且平衡候选成员之间的工作分配。

    

    团队建设和促进合作是非常常见的商业活动。一个例子就是TeamingForFunding问题，研究机构和研究人员在向资助机构申请时，希望能够找到合作机会以回应后者的项目申请。我们描述了一个新颖的系统，利用各种人工智能方法来推荐团队，使得每个团队都能够达到机会要求的最高技能覆盖，并且候选成员之间的工作分配是平衡的。我们通过提取开放数据中的项目申请（需求）和研究人员简介（供给）中的技能潜力，使用分类法对其进行归一化，创建了有效的算法来匹配需求和供给。我们创建团队以最大化一个新的衡量短期和长期目标的度量的优势。我们定量验证了我们算法的成功，通过…

    Building teams and promoting collaboration are two very common business activities. An example of these are seen in the TeamingForFunding problem, where research institutions and researchers are interested to identify collaborative opportunities when applying to funding agencies in response to latter's calls for proposals. We describe a novel system to recommend teams using a variety of AI methods, such that (1) each team achieves the highest possible skill coverage that is demanded by the opportunity, and (2) the workload of distributing the opportunities is balanced amongst the candidate members. We address these questions by extracting skills latent in open data of proposal calls (demand) and researcher profiles (supply), normalizing them using taxonomies, and creating efficient algorithms that match demand to supply. We create teams to maximize goodness along a novel metric balancing short- and long-term objectives. We validate the success of our algorithms (1) quantitatively, by e
    
[^104]: 在文本中测量模糊性和主观性：从符号到神经网络的VAGO

    Measuring vagueness and subjectivity in texts: from symbolic to neural VAGO. (arXiv:2309.06132v1 [cs.CL])

    [http://arxiv.org/abs/2309.06132](http://arxiv.org/abs/2309.06132)

    本文提出了一种混合方法来自动测量文本中的模糊性和主观性。通过引入专家系统VAGO，以及基于BERT-like架构的神经克隆，该方法在固定语料库和多语言生成方面表现出良好的性能。

    

    我们提出了一种混合方法来自动测量文本中的模糊性和主观性。首先，我们介绍了专家系统VAGO，并在一小组事实与观点句子的基准上对其进行了说明，并在更大的法语新闻语料库FreSaDa上进行了测试，以确认讽刺性文本中主观标记的更高流行率。然后，我们构建了一个基于BERT-like架构的VAGO神经克隆，该架构基于在FreSaDa上获得的符号VAGO分数进行训练。使用可解释性工具（LIME），我们展示了这个神经版本在丰富符号版本的词典和生成其他语言版本方面的兴趣。

    We present a hybrid approach to the automated measurement of vagueness and subjectivity in texts. We first introduce the expert system VAGO, we illustrate it on a small benchmark of fact vs. opinion sentences, and then test it on the larger French press corpus FreSaDa to confirm the higher prevalence of subjective markers in satirical vs. regular texts. We then build a neural clone of VAGO, based on a BERT-like architecture, trained on the symbolic VAGO scores obtained on FreSaDa. Using explainability tools (LIME), we show the interest of this neural version for the enrichment of the lexicons of the symbolic version, and for the production of versions in other languages.
    
[^105]: LLM自卫：通过自检，LLMs意识到它们被愚弄了。

    LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked. (arXiv:2308.07308v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.07308](http://arxiv.org/abs/2308.07308)

    本文提出了一种通过自检来防御大型语言模型(LLMs)对抗性攻击的简单方法，即让模型自行过滤回应。实验结果表明，即使模型未对齐人类价值观，通过使用语言模型验证内容，仍然可以防止模型向用户呈现有害内容。

    

    近年来，大型语言模型（LLMs）由于其能够对人类提示做出高质量文本回应而变得非常受欢迎。然而，研究表明，这些模型在回应用户提示时可能生成有害内容（例如，给用户提供犯罪指导）。文献中已经着重研究如何通过方法（例如通过强化学习将模型与人类价值观对齐）来减轻这些风险。然而，研究发现，即使对齐的语言模型也容易受到绕过生成有害文本限制的对抗性攻击。我们提出了一种简单的方法来防御这些攻击，即大型语言模型对自己的回应进行过滤。我们目前的研究结果表明，即使模型没有被微调以与人类价值观对齐，也可以通过使用语言模型验证内容来防止其向用户呈现有害内容。

    Large language models (LLMs) have skyrocketed in popularity in recent years due to their ability to generate high-quality text in response to human prompting. However, these models have been shown to have the potential to generate harmful content in response to user prompting (e.g., giving users instructions on how to commit crimes). There has been a focus in the literature on mitigating these risks, through methods like aligning models with human values through reinforcement learning. However, it has been shown that even aligned language models are susceptible to adversarial attacks that bypass their restrictions on generating harmful text. We propose a simple approach to defending against these attacks by having a large language model filter its own responses. Our current results show that even if a model is not fine-tuned to be aligned with human values, it is possible to stop it from presenting harmful content to users by validating the content using a language model.
    
[^106]: 超越语义：利用自我监督学习的行为增强相关模型的学习

    Beyond Semantics: Learning a Behavior Augmented Relevance Model with Self-supervised Learning. (arXiv:2308.05379v1 [cs.IR])

    [http://arxiv.org/abs/2308.05379](http://arxiv.org/abs/2308.05379)

    这篇论文提出了一种行为增强的相关模型，利用自我监督学习，通过从用户历史行为数据中提取辅助查询-项目交互，来改进搜索引擎中的查询-项目匹配，提高准确性和鲁棒性。

    

    相关建模旨在定位与对应查询相关的理想项目，这对于搜索引擎确保用户体验非常重要。虽然大多数传统方法通过评估查询与项目之间的语义相似性来解决这个问题，但纯语义匹配并不是唯一的方法。实际上，从用户搜索记录的历史行为数据中提取的辅助查询-项目交互可以提供进一步揭示用户搜索意图的线索。得益于此，我们设计了一种新颖的基于行为增强相关学习模型的支付宝搜索模型（BARL-ASe），该模型利用目标项目的相邻查询和目标查询的相邻项目来补充目标查询-项目的语义匹配。具体而言，我们的模型建立了多层共同注意力，从相邻和目标视图中提取了粗粒度和细粒度的语义表示。模型随后采用邻居-目标的自我监督学习来提高精度和鲁棒性。

    Relevance modeling aims to locate desirable items for corresponding queries, which is crucial for search engines to ensure user experience. Although most conventional approaches address this problem by assessing the semantic similarity between the query and item, pure semantic matching is not everything. In reality, auxiliary query-item interactions extracted from user historical behavior data of the search log could provide hints to reveal users' search intents further. Drawing inspiration from this, we devise a novel Behavior Augmented Relevance Learning model for Alipay Search (BARL-ASe) that leverages neighbor queries of target item and neighbor items of target query to complement target query-item semantic matching. Specifically, our model builds multi-level co-attention for distilling coarse-grained and fine-grained semantic representations from both neighbor and target views. The model subsequently employs neighbor-target self-supervised learning to improve the accuracy and robu
    
[^107]: 模型的模型--第一部分

    Model of models -- Part 1. (arXiv:2308.04600v1 [cs.AI])

    [http://arxiv.org/abs/2308.04600](http://arxiv.org/abs/2308.04600)

    本文提出了一种新的认知模型，该模型在成熟智能状态下操作累积的知识，并依赖适当的意愿进行指导。

    

    本文提出了一种新的认知模型，作为AGI代理的主要组成部分。该模型是在其成熟的智能状态下引入的，是DENN和特别是AKREM之前模型的延伸，包括操作模型（框架/类别）和意愿。该模型的核心假设是认知是在适当的意愿引导下对累积的知识进行操作。此外，我们假设在成熟的智能状态之前的演化阶段，行为（知识的一部分）是学习与意愿对齐的。此外，该模型主要基于每个已知智能方面的二元性原则，例如上下学习模型，泛化与特化，等等。此外，倡导一种整体的AGI设计方法，并提出了在约束条件下的认知或效率问题，以可重用性和简洁性的形式。最后，通过实现知识和规则之间的双重叠加方式来描述达到这种成熟状态。

    This paper proposes a new cognitive model, acting as the main component of an AGI agent. The model is introduced in its mature intelligence state, and as an extension of previous models, DENN, and especially AKREM, by including operational models (frames/classes) and will. This model's core assumption is that cognition is about operating on accumulated knowledge, with the guidance of an appropriate will. Also, we assume that the actions, part of knowledge, are learning to be aligned with will, during the evolution phase that precedes the mature intelligence state. In addition, this model is mainly based on the duality principle in every known intelligent aspect, such as exhibiting both top-down and bottom-up model learning, generalization verse specialization, and more. Furthermore, a holistic approach is advocated for AGI designing, and cognition under constraints or efficiency is proposed, in the form of reusability and simplicity. Finally, reaching this mature state is described via
    
[^108]: MM-Vet: 评估大型多模态模型的综合能力

    MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities. (arXiv:2308.02490v1 [cs.AI])

    [http://arxiv.org/abs/2308.02490](http://arxiv.org/abs/2308.02490)

    MM-Vet是一个评估标准，用于评估大型多模态模型在复杂任务上的综合能力。该标准解决了如何结构化和评估复杂多模态任务、设计适用于不同问题和回答类型的评估指标以及如何提供模型洞察的问题。通过整合不同的核心视觉-语言能力，MM-Vet展示了有趣的能力和解决复杂任务的方法。

    

    我们提出了MM-Vet，一个评估标准，用于检查在复杂多模态任务上的大型多模态模型（LMM）的表现。最近的LMM展示了各种有趣的能力，例如解决书写在黑板上的数学问题，推理新闻图片中的事件和名人，以及解释视觉笑话。快速的模型进步给评估标准的开发带来了挑战。问题包括：（1）如何系统地构建和评估复杂的多模态任务；（2）如何设计适用于不同类型问题和回答的评估指标；（3）如何给出超出简单性能排名的模型洞察。为此，我们提出了MM-Vet，基于这样一个洞察：解决复杂任务的有趣能力通常通过一种通才模型能够整合不同的核心视觉-语言（VL）能力来实现。MM-Vet定义了6个核心VL能力，并检查了从这些能力组合中得出的16种有趣的整合方式。

    We propose MM-Vet, an evaluation benchmark that examines large multimodal models (LMMs) on complicated multimodal tasks. Recent LMMs have shown various intriguing abilities, such as solving math problems written on the blackboard, reasoning about events and celebrities in news images, and explaining visual jokes. Rapid model advancements pose challenges to evaluation benchmark development. Problems include: (1) How to systematically structure and evaluate the complicated multimodal tasks; (2) How to design evaluation metrics that work well across question and answer types; and (3) How to give model insights beyond a simple performance ranking. To this end, we present MM-Vet, designed based on the insight that the intriguing ability to solve complicated tasks is often achieved by a generalist model being able to integrate different core vision-language (VL) capabilities. MM-Vet defines 6 core VL capabilities and examines the 16 integrations of interest derived from the capability combin
    
[^109]: Relation-Oriented: 迈向与知识对准的因果人工智能

    Relation-Oriented: Toward Knowledge-Aligned Causal AI. (arXiv:2307.16387v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2307.16387](http://arxiv.org/abs/2307.16387)

    本研究从创新的关系导向视角出发，探讨了当前的建模范式中的观察模型与实际理解的不对齐问题，并提出了关系定义的表示学习方法作为实现关系导向建模的实践方法。

    

    在机器学习中，我们自然地应用一个观察导向的原则，其中观察变量先存在并为构建关系奠定基础。虽然对于传统模型来说足够了，但是人工智能与大数据的整合暴露了观察模型与我们的实际理解之间的不对齐。相反，人类塑造了由关系定义的认知实体，使我们能够跨越时间和超维度空间制定知识，而不是被限制在观察构建中。从一种创新的关系导向的视角出发，本研究通过来自计算机视觉和健康信息学的直观例子，分析了在我们当前的建模范式中这种不对齐的根源。我们还介绍了关系定义的表示学习方法作为关系导向建模的一种实际实施，支持广泛的实验验证。

    In machine learning, we naturally apply an Observation-Oriented principle, in which observational variables preexist and set the stage for constructing relationships. While sufficient for traditional models, the integration of AI with big data exposes the misalignment between the observational models and our actual comprehension. Contrarily, humans shape cognitive entities defined by relationships, enabling us to formulate knowledge across temporal and hyper-dimensional spaces, rather than being confined to observational constructs. From an innovative Relation-Oriented perspective, this study examines the roots of this misalignment within our current modeling paradigm, illuminated by intuitive examples from computer vision and health informatics. We also introduce the relation-defined representation learning methodology as a practical implementation of Relation-Oriented modeling, supported by extensive experimental validation.
    
[^110]: DiffKendall:一种利用可微分Kendall排名相关性进行少样本学习的新方法

    DiffKendall: A Novel Approach for Few-Shot Learning with Differentiable Kendall's Rank Correlation. (arXiv:2307.15317v1 [cs.CV])

    [http://arxiv.org/abs/2307.15317](http://arxiv.org/abs/2307.15317)

    本文提出了一种利用可微分Kendall排名相关性进行少样本学习的新方法，证明了特征通道的重要性排序在少样本学习中比几何相似度度量更可靠，并且实验证明在推理过程中用Kendall排名相关性替换几何相似度度量能够提高少样本学习性能。

    

    少样本学习旨在将在基本数据集上训练的模型适应到模型之前未见过的新领域的任务。这经常导致新类别上通道上特征值的分布相对均匀，难以确定新任务中通道的重要性。标准的少样本学习方法使用几何相似度度量，如余弦相似度和负欧几里德距离，来衡量两个特征之间的语义相关性。然而，在少样本学习的情况下，具有高几何相似度的特征可能具有不同的语义。本文证明了特征通道的重要性排序在少样本学习中比几何相似度度量更可靠。我们观察到，仅在推理过程中用Kendall排名相关性替换几何相似度度量能够提高在各种数据集中的少样本学习性能。

    Few-shot learning aims to adapt models trained on the base dataset to novel tasks where the categories are not seen by the model before. This often leads to a relatively uniform distribution of feature values across channels on novel classes, posing challenges in determining channel importance for novel tasks. Standard few-shot learning methods employ geometric similarity metrics such as cosine similarity and negative Euclidean distance to gauge the semantic relatedness between two features. However, features with high geometric similarities may carry distinct semantics, especially in the context of few-shot learning. In this paper, we demonstrate that the importance ranking of feature channels is a more reliable indicator for few-shot learning than geometric similarity metrics. We observe that replacing the geometric similarity metric with Kendall's rank correlation only during inference is able to improve the performance of few-shot learning across a wide range of datasets with diffe
    
[^111]: 基于随机游走的异常检测的双重空间攻击

    Dual-Space Attacks against Random-Walk-based Anomaly Detection. (arXiv:2307.14387v1 [cs.CR])

    [http://arxiv.org/abs/2307.14387](http://arxiv.org/abs/2307.14387)

    本文考察了随机游走异常检测(RWAD)面临的图空间攻击和特征空间攻击，证明了攻击RWAD的复杂度是NP难的，并提出了两种攻击策略，进一步通过图引导攻击设计了更强大的特征空间攻击。

    

    随机游走异常检测(RWAD)通常用于在各种应用中识别异常模式。RWAD的一个有趣特点是输入图可以是预先存在的，也可以由原始特征构建而来。因此，对于RWAD有两种潜在的攻击方式：图空间攻击和特征空间攻击。本文通过设计实际的双重空间攻击，探究了图空间攻击和特征空间攻击之间的相互作用。为此，我们进行了深入的复杂性分析，证明了攻击RWAD是NP难的。然后，我们将图空间攻击形式化为双层优化问题，并提出了两种解决策略：交替迭代攻击(alterI-attack)或利用随机游走模型的闭合解(cf-attack)。最后，我们利用图空间攻击的结果来指导设计更强大的特征空间攻击(即，图引导攻击)。

    Random Walks-based Anomaly Detection (RWAD) is commonly used to identify anomalous patterns in various applications. An intriguing characteristic of RWAD is that the input graph can either be pre-existing or constructed from raw features. Consequently, there are two potential attack surfaces against RWAD: graph-space attacks and feature-space attacks. In this paper, we explore this vulnerability by designing practical dual-space attacks, investigating the interplay between graph-space and feature-space attacks. To this end, we conduct a thorough complexity analysis, proving that attacking RWAD is NP-hard. Then, we proceed to formulate the graph-space attack as a bi-level optimization problem and propose two strategies to solve it: alternative iteration (alterI-attack) or utilizing the closed-form solution of the random walk model (cf-attack). Finally, we utilize the results from the graph-space attacks as guidance to design more powerful feature-space attacks (i.e., graph-guided attack
    
[^112]: WebArena: 一个用于构建自主智能体的真实网络环境

    WebArena: A Realistic Web Environment for Building Autonomous Agents. (arXiv:2307.13854v1 [cs.AI])

    [http://arxiv.org/abs/2307.13854](http://arxiv.org/abs/2307.13854)

    WebArena是一个用于构建自主智能体的真实网络环境，它包含了完全功能的网站，并且通过引入工具和外部知识库来鼓励智能体像人类一样解决任务。此外，WebArena还发布了一组用于评估任务完成功能正确性的基准任务。

    

    随着生成式人工智能的进展，通过自然语言指令进行日常任务的自主智能体的潜力逐渐显现。然而，当前的智能体主要是在简化的合成环境中创建和测试的，严重限制了现实世界场景的表示能力。在本文中，我们构建了一个高度逼真且可复现的智能体指令和控制环境。具体而言，我们关注在网站上执行任务的智能体，我们创建了一个包含来自四个常见领域的完全功能网站的环境，分别是电子商务、社交论坛讨论、协同软件开发和内容管理。我们的环境使用工具（如地图）和外部知识库（如用户手册）来鼓励像人类一样解决任务。在我们的环境基础上，我们发布了一组重点评估任务完成功能正确性的基准任务。我们基准任务具有多样性和长远的视野，并且被设计为鼓励智能体进行更深层次的任务理解和解决。

    With generative AI advances, the exciting potential for autonomous agents to manage daily tasks via natural language commands has emerged. However, cur rent agents are primarily created and tested in simplified synthetic environments, substantially limiting real-world scenario representation. In this paper, we build an environment for agent command and control that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on websites, and we create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and are desi
    
[^113]: 面向交通信号控制的不确定性感知基于实例的行动转换的模拟到实际转移

    Uncertainty-aware Grounded Action Transformation towards Sim-to-Real Transfer for Traffic Signal Control. (arXiv:2307.12388v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.12388](http://arxiv.org/abs/2307.12388)

    本文提出了UGAT方法，通过在模拟环境中动态转换具有不确定性的行动，实现了从模拟环境到真实环境的策略转移，显著提高了在真实世界中的性能。

    

    交通信号控制（TSC）是一个影响数百万人日常生活的复杂而重要的任务。强化学习（RL）在优化交通信号控制方面取得了有希望的结果，但当前基于RL的TSC方法主要在模拟环境中训练，存在模拟和真实世界之间性能差距的问题。本文提出了一种模拟到实际环境转移的方法，称为UGAT，通过在模拟中动态转换具有不确定性的行动，以减轻转移动态的领域差距，将在模拟环境中训练的学习策略转移到真实环境中。我们在模拟交通环境中评估了我们的方法，并表明它显著提高了转移后的RL策略在真实世界中的性能。

    Traffic signal control (TSC) is a complex and important task that affects the daily lives of millions of people. Reinforcement Learning (RL) has shown promising results in optimizing traffic signal control, but current RL-based TSC methods are mainly trained in simulation and suffer from the performance gap between simulation and the real world. In this paper, we propose a simulation-to-real-world (sim-to-real) transfer approach called UGAT, which transfers a learned policy trained from a simulated environment to a real-world environment by dynamically transforming actions in the simulation with uncertainty to mitigate the domain gap of transition dynamics. We evaluate our method on a simulated traffic environment and show that it significantly improves the performance of the transferred RL policy in the real world.
    
[^114]: RADAR: 通过对抗性学习实现鲁棒的AI文本检测

    RADAR: Robust AI-Text Detection via Adversarial Learning. (arXiv:2307.03838v1 [cs.CL])

    [http://arxiv.org/abs/2307.03838](http://arxiv.org/abs/2307.03838)

    本论文提出了一种名为RADAR的新框架，通过对抗性学习实现了鲁棒的AI文本检测，以解决当前AI文本检测器对于大语言模型的改写不具备鲁棒性的问题。

    

    最近大语言模型（LLMs）的进展以及ChatGPT类应用的普及已经模糊了人类和机器之间高质量文本生成的界限。然而，除了对我们的技术和社会预期的革命性变化外，区分LLM生成的文本（AI文本）和人类生成的文本的困难也带来了新的滥用和公平性挑战，例如虚假内容生成，抄袭以及对无辜作者的错误指控。尽管现有的研究表明当前的AI文本检测器对基于LLM的改写不具有鲁棒性，但本文旨在通过提出一种名为RADAR的新框架来弥合这一差距，该框架通过对抗性学习共同训练了一个鲁棒的AI文本检测器。RADAR基于一个改写器和一个检测器的对抗性训练。改写器的目标是生成逼真的内容以规避AI文本检测。RADAR使用来自检测器的反馈来更新改写器，反之亦然。

    Recent advances in large language models (LLMs) and the intensifying popularity of ChatGPT-like applications have blurred the boundary of high-quality text generation between humans and machines. However, in addition to the anticipated revolutionary changes to our technology and society, the difficulty of distinguishing LLM-generated texts (AI-text) from human-generated texts poses new challenges of misuse and fairness, such as fake content generation, plagiarism, and false accusation of innocent writers. While existing works show that current AI-text detectors are not robust to LLM-based paraphrasing, this paper aims to bridge this gap by proposing a new framework called RADAR, which jointly trains a Robust AI-text Detector via Adversarial leaRning. RADAR is based on adversarial training of a paraphraser and a detector. The paraphraser's goal is to generate realistic contents to evade AI-text detection. RADAR uses the feedback from the detector to update the paraphraser, and vice vers
    
[^115]: 数据中动态偏移的状态规范化策略优化

    State Regularized Policy Optimization on Data with Dynamics Shift. (arXiv:2306.03552v1 [cs.LG])

    [http://arxiv.org/abs/2306.03552](http://arxiv.org/abs/2306.03552)

    本文提出了一种叫做 SRPO (状态规范化策略优化) 的算法，该算法利用训练数据中的稳态分布来规范新环境中的策略，在处理具有不同动态的多个环境时表现优异。

    

    在许多实际场景中，强化学习算法使用的数据受到动态偏移的影响，即具有不同的环境动态。目前的大多数方法通过训练上下文编码器来识别环境参数来解决这个问题。根据其环境参数将带有动态漂移的数据分开以训练相应的策略。然而，这些方法可能会出现样本效率低下的问题，因为数据是“特定场景”使用的，针对某个环境训练的策略不能从收集在其他具有不同动态的所有其他环境中的数据中受益。本文发现，在许多具有相似结构和不同动态的环境中，最优策略具有类似的稳态分布。我们利用这种特性，并从具有动态漂移的数据中学习稳态分布，以实现高效的数据重用。这种分布用于规范新环境中训练的策略，导致了 SRPO（状态规范化策略优化）算法的出现。实验结果表明，SRPO 在具有动态偏移的任务上显著优于现有的方法。

    In many real-world scenarios, Reinforcement Learning (RL) algorithms are trained on data with dynamics shift, i.e., with different underlying environment dynamics. A majority of current methods address such issue by training context encoders to identify environment parameters. Data with dynamics shift are separated according to their environment parameters to train the corresponding policy. However, these methods can be sample inefficient as data are used \textit{ad hoc}, and policies trained for one dynamics cannot benefit from data collected in all other environments with different dynamics. In this paper, we find that in many environments with similar structures and different dynamics, optimal policies have similar stationary state distributions. We exploit such property and learn the stationary state distribution from data with dynamics shift for efficient data reuse. Such distribution is used to regularize the policy trained in a new environment, leading to the SRPO (\textbf{S}tat
    
[^116]: 当问题不是用英语提出时，不要完全信任GPT

    Don't Trust GPT When Your Question Is Not In English. (arXiv:2305.16339v1 [cs.CL])

    [http://arxiv.org/abs/2305.16339](http://arxiv.org/abs/2305.16339)

    在多语言环境下，GPT-3表现较差，特别是当问题不是用英语提出时。这与模型的训练数据和输入问题的语言差异有关。

    

    近年来，大型语言模型（LLMs）展示了出色的自然语言理解能力，并在多个自然语言处理（NLP）任务中表现出色。尽管大多数LLMs主要使用英语进行训练，但多项研究已经证明了它们在许多其他语言中的相对表现。然而，关于LLMs如何获得它们的多语言能力以及表现在不同语言中的差异仍然存在基本问题。这些问题对LLMs的研究非常关键，因为用户和研究人员通常来自多种语言背景，可能影响他们对LLMs结果的利用和解释。在本文中，我们提出了一种系统的方法，以定性评估多语言环境下LLMs的表现差异。我们调查了LLMs在跨语言泛化现象方面的表现，即不充足的多语言训练数据导致先进的多语言能力。为了实现这一目的，我们对一系列语言进行了GPT-3的实验，这些语言涵盖了从印欧语系到非印欧语系的各种语言，并提出了一种评估和验证结果的方法。我们的发现表明，即使模型在该语言上进行了微调，但如果输入问题不是英语，GPT-3在其他语言下的表现显著较差。此外，我们证明了模型的表现不佳与训练语言和输入问题的语言差异有关。我们的结果表明，在进行非英语自然语言处理任务时，需要谨慎使用LLMs。

    Large Language Models (LLMs) have demonstrated exceptional natural language understanding abilities and have excelled in a variety of natural language processing (NLP)tasks in recent years. Despite the fact that most LLMs are trained predominantly in English, multiple studies have demonstrated their comparative performance in many other languages. However, fundamental questions persist regarding how LLMs acquire their multi-lingual abilities and how performance varies across different languages. These inquiries are crucial for the study of LLMs since users and researchers often come from diverse language backgrounds, potentially influencing their utilization and interpretation of LLMs' results. In this work, we propose a systematic way of qualifying the performance disparities of LLMs under multilingual settings. We investigate the phenomenon of across-language generalizations in LLMs, wherein insufficient multi-lingual training data leads to advanced multi-lingual capabilities. To acc
    
[^117]: ToMChallenges: 一个基于原则的数据集和多样化评估任务，用于探索心智理论

    ToMChallenges: A Principle-Guided Dataset and Diverse Evaluation Tasks for Exploring Theory of Mind. (arXiv:2305.15068v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.15068](http://arxiv.org/abs/2305.15068)

    本研究提出了一个基于原则的数据集和多样化评估任务，名为ToMChallenges，以探索心智理论。研究发现，大型语言模型在心智理论任务上表现不一致，稳定地执行任务仍然具有挑战性。

    

    心智理论（ToM）是理解不同个体心智状态的能力，对于许多实际应用至关重要。随着大型语言模型（LLMs）的发展，关于它们是否能够执行ToM任务存在激烈的争议。先前的研究使用不同的任务和提示来测试LLMs上的ToM，结果不一致：一些研究认为这些模型能够展示ToM，而其他人则持相反观点。在本研究中，我们提出了ToMChallenges，一个基于Sally-Anne和Smarties测试的数据集，用于全面评估心智理论并包含多样化的任务。此外，我们还提出了一个自动评分器来简化答案评估过程。我们测试了三个模型：davinci、turbo和gpt-4。我们的评估结果和错误分析显示，LLMs在提示和任务之间表现不一致。对LLMs来说，稳定地执行ToM任务仍然是一个挑战。

    Theory of Mind (ToM), the capacity to comprehend the mental states of distinct individuals, is essential for numerous practical applications. With the development of large language models (LLMs), there is a heated debate about whether they are able to perform ToM tasks. Previous studies have used different tasks and prompts to test the ToM on LLMs and the results are inconsistent: some studies asserted these models are capable of exhibiting ToM, while others suggest the opposite. In this study, We present ToMChallenges, a dataset for comprehensively evaluating the Theory of Mind based on the Sally-Anne and Smarties tests with a diverse set of tasks. In addition, we also propose an auto-grader to streamline the answer evaluation process. We tested three models: davinci, turbo, and gpt-4. Our evaluation results and error analyses show that LLMs have inconsistent behaviors across prompts and tasks. Performing the ToM tasks robustly remains a challenge for the LLMs. In addition, our paper 
    
[^118]: GRACE: 判别器引导的思维链推理

    GRACE: Discriminator-Guided Chain-of-Thought Reasoning. (arXiv:2305.14934v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14934](http://arxiv.org/abs/2305.14934)

    GRACE是一种判别器引导的思维链推理的逐步解码方法，通过使用一个正确性判别器来评分下一步候选，解决了语言模型在多步推理中容易得到错误答案的问题。在多个数学和符号推理任务中，GRACE相较于其他方法在性能上有明显的提升。

    

    在多步推理的背景下，例如使用思维链，语言模型往往会对错误的步骤分配较高的可能性。因此，优化解决方案可能性的解码策略往往会产生错误的解决方案。为了解决这个问题，我们提出了一种称为GRACE的引导思维链推理的逐步解码方法，该方法通过一个正确性判别器训练来引导解码过程产生正确的推理步骤。GRACE使用一个在正确和错误步骤上进行对比损失训练的判别器，该判别器在解码过程中基于正确性对下一步候选进行评分。重要的是，GRACE只需要从语言模型中采样，而不需要进行语言模型的训练或微调。我们使用FLAN-T5和LLaMA系列的模型，对四个数学和两个符号推理任务进行了GRACE的评估，在大多数设置中，与贪婪解码、验证器和自一致性相比，GRACE展现出了显著的性能提升。

    In the context of multi-step reasoning, e.g., with chain-of-thought, language models (LMs) can easily assign a high likelihood to incorrect steps. As a result, decoding strategies that optimize for solution likelihood often yield incorrect solutions. To address this issue, we propose Guiding chain-of-thought ReAsoning with a CorrectnEss Discriminator (GRACE), a stepwise decoding approach that steers the decoding process towards producing correct reasoning steps. GRACE employs a discriminator trained with a contrastive loss over correct and incorrect steps, which is used during decoding to score next-step candidates based on their correctness. Importantly, GRACE only requires sampling from the LM, without the need for LM training or fine-tuning. Using models from FLAN-T5 and LLaMA families, we evaluate GRACE over four math and two symbolic reasoning tasks, where it exhibits substantial performance gains compared to greedy decoding, verifiers, and self-consistency in most settings. When 
    
[^119]: ByteSized32: 一个用于生成以文字游戏形式表达的任务特定世界模型的语料库和挑战任务

    ByteSized32: A Corpus and Challenge Task for Generating Task-Specific World Models Expressed as Text Games. (arXiv:2305.14879v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14879](http://arxiv.org/abs/2305.14879)

    这项工作研究了语言模型生成科学和常识推理任务的世界模型的能力，通过生成以Python代码形式表达的文字游戏来实现。实验证明GPT-4可以使用这些游戏作为模板进行上下文学习，并引入了一套自动评估指标进行模拟逼真度的评估。

    

    在这项工作中，我们研究了语言模型生成科学和常识推理任务的明确、可解释和互动世界模型的能力。我们将这个任务操作化为生成以Python代码形式表达的文字游戏的任务。为了便于完成这个任务，我们介绍了ByteSized32，一个包含32个以推理为重点的文字游戏的语料库，总共有2万行Python代码。我们经验性地证明GPT-4可以使用这些游戏作为单次上下文学习的模板，在28%的情况下成功生成未见过主题的可运行游戏。当允许自我反思程序错误时，游戏的可运行性大大提高至57%。虽然评估模拟逼真度比较费时，我们引入了一套自动评估指标来评估游戏的逼真度、技术有效性、与任务规格的一致性以及可获胜性，显示出与专家人工评级相当高的一致性。

    In this work, we investigate the capacity of language models to generate explicit, interpretable, and interactive world models of scientific and common-sense reasoning tasks. We operationalize this as a task of generating text games, expressed as hundreds of lines of Python code. To facilitate this task, we introduce ByteSized32 (Code: github.com/cognitiveailab/BYTESIZED32), a corpus of 32 reasoning-focused text games totaling 20k lines of Python code. We empirically demonstrate that GPT-4 can use these games as templates for single-shot in-context learning, successfully producing runnable games on unseen topics in 28% of cases. When allowed to self-reflect on program errors, game runnability substantially increases to 57%. While evaluating simulation fidelity is labor-intensive, we introduce a suite of automated metrics to assess game fidelity, technical validity, adherence to task specifications, and winnability, showing a high degree of agreement with expert human ratings. We pose t
    
[^120]: 利用GPT-4进行自动翻译后编辑

    Leveraging GPT-4 for Automatic Translation Post-Editing. (arXiv:2305.14878v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.14878](http://arxiv.org/abs/2305.14878)

    GPT-4在翻译后编辑任务中表现出色，通过产生有意义且可靠的编辑，大幅提高了翻译质量并消除了各类重要错误。

    

    尽管神经机器翻译（NMT）代表了机器翻译（MT）的领先方法，但NMT模型的输出仍需要进行翻译后编辑以纠正错误并在关键环境下提高质量。在这项工作中，我们将直接翻译后编辑任务形式化为使用大型语言模型（LLMs）并探索使用GPT-4自动翻译后编辑NMT输出的多种语言对。我们的结果表明， GPT-4在翻译后编辑方面表现出色，能够产生有意义且可靠的编辑，有助于提高其总体质量并消除各类重要错误。特别是，人类对编辑可靠性进行评估的结果显示，GPT-4相较于先前的最先进LLM取得了大幅改进。值得注意的是，我们利用基于GPT-4的翻译后编辑在WMT-22的英中、英德、中英和德英语种对中取得了超越最先进性能的成果。

    While Neural Machine Translation (NMT) represents the leading approach to Machine Translation (MT), the outputs of NMT models still require translation post-editing to rectify errors and enhance quality under critical settings. In this work, we formalize the task of direct translation post-editing with Large Language Models (LLMs) and explore the use of GPT-4 to automatically post-edit NMT outputs across several language pairs. Our results demonstrate that GPT-4 is adept at translation post-editing, producing meaningful and trustworthy edits to translations that help improve its general quality as well as remove different classes of major errors in translations. In particular, human evaluations on assessing edit trustworthiness show that GPT-4 exhibits a large improvement over the prior state-of-the-art LLM. Notably, we improve upon state-of-the-art performance on WMT-22 English-Chinese, English-German, Chinese-English and German-English language pairs using GPT-4 based post-editing, a
    
[^121]: 保持知识不变性：重新思考开放信息抽取的鲁棒性评估

    Preserving Knowledge Invariance: Rethinking Robustness Evaluation of Open Information Extraction. (arXiv:2305.13981v1 [cs.CL])

    [http://arxiv.org/abs/2305.13981](http://arxiv.org/abs/2305.13981)

    本文提出了第一个模拟评估开放式信息提取模型在真实世界中的基准测试，并通过判断模型在整个团体上的表现是否始终准确来评估模型的鲁棒性。

    

    鲁棒性是确保自然语言处理模型能够成功应用于现实世界中的关键因素，特别是对于信息抽取任务而言。然而，大多数先前的评估基准都专注于验证配对匹配的正确性，忽略了关键的鲁棒性测量。在本文中，我们提出了第一个基准测试，模拟在真实世界中评估开放式信息提取模型的情况，其中同一知识含义的句法和表达分布会各不相同。我们设计和注释了一个大规模的测试平台，其中每个示例都是一个知识不变的团体，由具有相同含义但结构不同的句子组成。通过进一步阐述鲁棒性指标，当模型在整个团体上的表现始终准确时，被判定为鲁棒性强。我们对过去十年中发表的几种典型模型进行了实验。

    The robustness to distribution changes ensures that NLP models can be successfully applied in the realistic world, especially for information extraction tasks. However, most prior evaluation benchmarks have been devoted to validating pairwise matching correctness, ignoring the crucial measurement of robustness. In this paper, we present the first benchmark that simulates the evaluation of open information extraction models in the real world, where the syntactic and expressive distributions under the same knowledge meaning may drift variously. We design and annotate a large-scale testbed in which each example is a knowledge-invariant clique that consists of sentences with structured knowledge of the same meaning but with different syntactic and expressive forms. By further elaborating the robustness metric, a model is judged to be robust if its performance is consistently accurate on the overall cliques. We perform experiments on typical models published in the last decade as well as a 
    
[^122]: Instruct-Align：通过基于对齐的跨语言教学将新语言教给LLM

    Instruct-Align: Teaching Novel Languages with to LLMs through Alignment-based Cross-Lingual Instruction. (arXiv:2305.13627v1 [cs.CL])

    [http://arxiv.org/abs/2305.13627](http://arxiv.org/abs/2305.13627)

    Instruct-Align提出了基于对齐的跨语言教学调整框架，使得教学调整的LLMs能够学习新语言，且不会发生灾难性遗忘。

    

    教学调整的大型语言模型（LLM）已经展示了在多种语言和多种任务上的卓越泛化能力。然而，它们对不同语言的泛化能力会有所不同，尤其是对于少数语言或者是未知语言。先前的工作发现，简单地将新语言适应到经过教学调整的LLM中会导致灾难性遗忘，从而导致这些LLM失去多任务能力。为了解决这个问题，我们提出了称为Instruct-Align的框架，通过基于对齐的跨语言教学调整，使得经过教学调整的LLM能够学习到看不见的和之前学习的语言之间的跨语言对齐。我们在BLOOMZ-560M数据集上的初步结果显示，Instruct-Align能够在仅使用有限量的平行语料的情况下有效地学习新语言，并且通过持续的教学调整，防止了灾难性遗忘。

    Instruction-tuned large language models (LLMs) have shown remarkable generalization capability over multiple tasks in multiple languages. Nevertheless, their generalization towards different languages varies especially to underrepresented languages or even to unseen languages. Prior works on adapting new languages to LLMs find that naively adapting new languages to instruction-tuned LLMs will result in catastrophic forgetting, which in turn causes the loss of multitasking ability in these LLMs. To tackle this, we propose the Instruct-Align a.k.a (IA)$^1$ framework, which enables instruction-tuned LLMs to learn cross-lingual alignment between unseen and previously learned languages via alignment-based cross-lingual instruction-tuning. Our preliminary result on BLOOMZ-560M shows that (IA)$^1$ is able to learn a new language effectively with only a limited amount of parallel data and at the same time prevent catastrophic forgetting by applying continual instruction-tuning through experien
    
[^123]: CoEdIT：通过任务特定指令调整实现文本编辑

    CoEdIT: Text Editing by Task-Specific Instruction Tuning. (arXiv:2305.09857v1 [cs.CL])

    [http://arxiv.org/abs/2305.09857](http://arxiv.org/abs/2305.09857)

    CoEdIT是一种通过任务特定指令调整实现文本编辑的最先进模型，能够提高用户生成文本的质量和提高流程的效率。

    

    文本编辑或修订是人类写作过程中必不可少的功能。理解LLMs在进行高质量修订和与人类写作者协作方面的能力是构建有效写作助手的关键步骤。在LLMs和指令调整的先前成功基础上，我们利用经过指令调整的LLMs进行文本修订，以提高用户生成文本的质量和提高流程的效率。我们引入了CoEdIT，这是一款用于写作辅助的最先进的文本编辑模型。CoEdIT从用户那里获取指令，指定所需文本的属性，例如“使句子更简单”或“以更中立的风格写作”，并输出编辑后的文本。我们提供了一个大型语言模型，该模型在各种文本编辑基准测试上实现了最先进的性能。我们的模型（1）在各种文本编辑基准测试上实现最先进的性能，（2）与公开可用的模型相比具有竞争力。

    Text editing or revision is an essential function of the human writing process. Understanding the capabilities of LLMs for making high-quality revisions and collaborating with human writers is a critical step toward building effective writing assistants. With the prior success of LLMs and instruction tuning, we leverage instruction-tuned LLMs for text revision to improve the quality of user-generated text and improve the efficiency of the process. We introduce CoEdIT, a state-of-the-art text editing model for writing assistance. CoEdIT takes instructions from the user specifying the attributes of the desired text, such as "Make the sentence simpler" or "Write it in a more neutral style," and outputs the edited text. We present a large language model fine-tuned on a diverse collection of task-specific instructions for text editing (a total of 82K instructions). Our model (1) achieves state-of-the-art performance on various text editing benchmarks, (2) is competitive with publicly availa
    
[^124]: 重新审视离线强化学习的极简方法

    Revisiting the Minimalist Approach to Offline Reinforcement Learning. (arXiv:2305.09836v1 [cs.LG])

    [http://arxiv.org/abs/2305.09836](http://arxiv.org/abs/2305.09836)

    这篇论文提出了一种名为ReBRAC的极简算法，它在TD3+BC方法的基础上整合了设计元素，通过对近期离线强化学习研究的回顾性分析，证明其在离线强化学习上的领先地位。

    

    近年来，离线强化学习取得了显着的进展，出现了许多具有不同复杂度的算法。虽然这些算法带来了显著的改进，但很多算法包含了看似微不足道的设计选择，这些选择对算法的有效性产生了影响，超出了核心算法的进步。然而，这些设计选择对于已有基线算法的影响尚未得到充分研究。在这项工作中，我们旨在通过对近期离线强化学习研究的回顾性分析，提出一种名为ReBRAC的极简算法，该算法在TD3+BC方法的基础上整合了这些设计元素。我们使用D4RL和V-D4RL基准测试评估了ReBRAC在51个具有自我感知和视觉状态空间的数据集上的性能，证明了其在不需要集成的方法中处于领先地位。为了进一步说明这些设计选择的有效性，我们进行了大规模消融研究和超参数敏感性分析，揭示了ReBRAC的成功源于其基于策略改进和评论家正则化的原则性设计选择。

    Recent years have witnessed significant advancements in offline reinforcement learning (RL), resulting in the development of numerous algorithms with varying degrees of complexity. While these algorithms have led to noteworthy improvements, many incorporate seemingly minor design choices that impact their effectiveness beyond core algorithmic advances. However, the effect of these design choices on established baselines remains understudied. In this work, we aim to bridge this gap by conducting a retrospective analysis of recent works in offline RL and propose ReBRAC, a minimalistic algorithm that integrates such design elements built on top of the TD3+BC method. We evaluate ReBRAC on 51 datasets with both proprioceptive and visual state spaces using D4RL and V-D4RL benchmarks, demonstrating its state-of-the-art performance among ensemble-free methods. To further illustrate the efficacy of these design choices, we perform a large-scale ablation study and hyperparameter sensitivity anal
    
[^125]: 横向迁移轻量化视觉提示发生器在VL-LLMs之间的应用研究

    Transfer Visual Prompt Generator across LLMs. (arXiv:2305.01278v1 [cs.CV])

    [http://arxiv.org/abs/2305.01278](http://arxiv.org/abs/2305.01278)

    本论文提出将已有的轻量化视觉提示发生器连接到视觉-语言LLM以减少资源消耗的方法，并提出了跨不同大小和类型的LLMs的VPG转移方案VPGTrans，该方案在VQA和NLVR2任务中表现优秀。

    

    本文研究利用现有的轻量化视觉提示发生器（VPG）连接已有的视觉-语言LLM（VL-LLM）以减少资源消耗。此外，我们提出一种跨不同大小和类型的LLMs的VPG转移方案。基于我们的观察，我们设计了一个名为VPGTrans的两阶段转移框架，它在VQA和NLVR2两个下游任务中表现出比现有方法更好的精度和转移速度。

    While developing a new vision-language LLM (VL-LLM) by pre-training on tremendous image-text pairs from scratch can be exceedingly resource-consuming, connecting an existing LLM with a comparatively lightweight visual prompt generator (VPG) becomes a feasible paradigm. However, further tuning the VPG part of the VL-LLM still suffers from indispensable computational costs, i.e., requiring thousands of GPU hours and millions of training data. One alternative solution is to transfer an existing VPG from any existing VL-LLMs for the target VL-LLM.  In this work, we for the first time investigate the VPG transferability across LLMs, and explore a solution to reduce the cost of VPG transfer. We first study the VPG transfer across different LLM sizes (e.g., small-to-large), and across different LLM types, through which we diagnose the key factors to maximize the transfer efficiency. Based on our observation, we design a two-stage transfer framework named VPGTrans, which is simple yet highly e
    
[^126]: GPT-2是如何计算大于符号的？解释预训练语言模型中的数学能力

    How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model. (arXiv:2305.00586v1 [cs.CL])

    [http://arxiv.org/abs/2305.00586](http://arxiv.org/abs/2305.00586)

    本研究运用机械式可解释性技术探究了GPT-2 Small的数学能力，并确定了它的计算图中的一个小电路用于计算大于符号，该电路的多层感知器提高了结束年份大于开始年份的概率，并且该电路具有广泛的适用性。

    

    预训练语言模型在未被明确训练的任务上表现出惊人的能力，但它们如何实现这些功能却不为人所知。本文通过机械式可解释性技术探究预训练语言模型通常具有的基本数学能力。具体来说，我们以GPT-2 Small为例，研究其能否通过输入"战争持续时间是从1732年到17年"，预测出有效的两位数字的截止年份 (大于32年)。我们首先确定了一个电路，即GPT-2 Small计算图的一个小子集，用于计算这个任务的输出，然后我们解释了每个电路组件的作用，显示出GPT-2 Small的最终多层感知器提高了结束年份大于开始年份的概率。最后，我们证明了我们的电路适用于其他任务，在其他大于场景中发挥作用。

    Pre-trained language models can be surprisingly adept at tasks they were not explicitly trained on, but how they implement these capabilities is poorly understood. In this paper, we investigate the basic mathematical abilities often acquired by pre-trained language models. Concretely, we use mechanistic interpretability techniques to explain the (limited) mathematical abilities of GPT-2 small. As a case study, we examine its ability to take in sentences such as "The war lasted from the year 1732 to the year 17", and predict valid two-digit end years (years > 32). We first identify a circuit, a small subset of GPT-2 small's computational graph that computes this task's output. Then, we explain the role of each circuit component, showing that GPT-2 small's final multi-layer perceptrons boost the probability of end years greater than the start year. Finally, we show that our circuit generalizes to other tasks, playing a role in other greater-than scenarios.
    
[^127]: 大型语言模型在文档级机器翻译中的应用研究

    Document-Level Machine Translation with Large Language Models. (arXiv:2304.02210v1 [cs.CL])

    [http://arxiv.org/abs/2304.02210](http://arxiv.org/abs/2304.02210)

    本文以文档级机器翻译为试验场，深入评估了大型语言模型在语篇建模方面的性能。研究发现利用LLMs强大的长文本建模能力可以提高翻译质量，在提示方面进行改进也可以显着提高翻译质量，并且LLMs有潜力编码丰富的语篇知识。

    

    大型语言模型（LLMs）如Chat-GPT可以为各种自然语言处理（NLP）任务生成连贯，连贯，相关和流畅的答案。本文以文档级机器翻译为试验场，提供了LLMs在语篇建模方面的深入评估。本研究着重关注三个方面：1）语篇感知提示的影响，我们调查不同提示对文档级翻译质量和语篇现象的影响；2）翻译模型的比较，我们比较Chat-GPT与商业MT系统和高级文档级MT方法的翻译性能；3）语篇建模能力分析，我们进一步探究LLMs中编码的语篇知识，并研究培训技术对语篇建模的影响。通过评估许多基准测试，我们惊讶地发现，1）利用强大的长文本建模能力，ChatGPT在文档级翻译质量方面优于商业MT系统和高级文档级MT方法；2）修改明确针对语篇现象的提示可以显着提高翻译质量；3）LLMs有潜力编码丰富的语篇知识，培训技术可以进一步增强这种能力。

    Large language models (LLMs) such as Chat-GPT can produce coherent, cohesive, relevant, and fluent answers for various natural language processing (NLP) tasks. Taking document-level machine translation (MT) as a testbed, this paper provides an in-depth evaluation of LLMs' ability on discourse modeling. The study fo-cuses on three aspects: 1) Effects of Discourse-Aware Prompts, where we investigate the impact of different prompts on document-level translation quality and discourse phenomena; 2) Comparison of Translation Models, where we compare the translation performance of Chat-GPT with commercial MT systems and advanced document-level MT methods; 3) Analysis of Discourse Modelling Abilities, where we further probe discourse knowledge encoded in LLMs and examine the impact of training techniques on discourse modeling. By evaluating a number of benchmarks, we surprisingly find that 1) leveraging their powerful long-text mod-eling capabilities, ChatGPT outperforms commercial MT systems 
    
[^128]: 机器心理学：利用心理学方法探究大型语言模型的新兴能力和行为

    Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Methods. (arXiv:2303.13988v1 [cs.CL])

    [http://arxiv.org/abs/2303.13988](http://arxiv.org/abs/2303.13988)

    本文提出了一种新领域——机器心理学，利用心理学的方法考察大型语言模型的能力。该文规范了机器心理学研究的方法论标准，并对心理实验中提示设计政策进行了探讨和制定。

    

    大型语言模型（LLM）是将人工智能系统与人类交流和日常生活紧密结合的先锋。由于快速技术进步和其极高的通用性，现今LLM已经拥有数百万用户，并正处于成为主要信息检索、内容生成、问题解决等技术的前沿。因此，对其进行全面评估和审查显得尤为重要。由于当前LLM中出现愈加复杂和新颖的行为模式，可将其视为参与人类心理实验的对象，以便更为全面地评估其能力。为此，本文引入了一个名为"机器心理学"的新兴研究领域。本文概述了各类心理学分支如何为LLM的行为测试提供有用参考。同时，本文规范了机器心理学研究的方法论标准，特别是专注于提示设计政策的制定。此外，它还描述了行为测试结果如何为未来的LLM发展提供指导。

    Large language models (LLMs) are currently at the forefront of intertwining AI systems with human communication and everyday life. Due to rapid technological advances and their extreme versatility, LLMs nowadays have millions of users and are at the cusp of being the main go-to technology for information retrieval, content generation, problem-solving, etc. Therefore, it is of great importance to thoroughly assess and scrutinize their capabilities. Due to increasingly complex and novel behavioral patterns in current LLMs, this can be done by treating them as participants in psychology experiments that were originally designed to test humans. For this purpose, the paper introduces a new field of research called "machine psychology". The paper outlines how different subfields of psychology can inform behavioral tests for LLMs. It defines methodological standards for machine psychology research, especially by focusing on policies for prompt designs. Additionally, it describes how behaviora
    
[^129]: 医学图像分析中高效标记深度学习的挑战与未来方向

    Label-Efficient Deep Learning in Medical Image Analysis: Challenges and Future Directions. (arXiv:2303.12484v1 [cs.CV])

    [http://arxiv.org/abs/2303.12484](http://arxiv.org/abs/2303.12484)

    近年来深度学习在医学图像分析中取得了最先进的性能，但这种方法的标记代价大，标记不足。因此发展了高效标记深度学习方法，充分利用未标记的和弱标记的数据。该综述总结了这方面的最新进展。

    

    深度学习近年来得到了迅速发展，并在广泛应用中取得了最先进的性能。但是，训练模型通常需要收集大量标记数据，这需要昂贵耗时。特别是在医学图像分析（MIA）领域，数据有限，标签很难获得。因此，人们开发了高效标记深度学习方法，充分利用标记数据以及非标记和弱标记数据的丰富性。在本调查中，我们对近300篇论文进行了广泛调查，以全面概述最新进展的高效标记学习策略在MIA中的研究现状。我们首先介绍高效标记学习的背景，并将不同方案的方法归类。接下来，我们通过每种方案详细研究了目前最先进的方法。具体而言，我们进行了深入调查，覆盖了不仅是标准策略，还包括使用后处理和集合方法等方法。

    Deep learning has seen rapid growth in recent years and achieved state-of-the-art performance in a wide range of applications. However, training models typically requires expensive and time-consuming collection of large quantities of labeled data. This is particularly true within the scope of medical imaging analysis (MIA), where data are limited and labels are expensive to be acquired. Thus, label-efficient deep learning methods are developed to make comprehensive use of the labeled data as well as the abundance of unlabeled and weak-labeled data. In this survey, we extensively investigated over 300 recent papers to provide a comprehensive overview of recent progress on label-efficient learning strategies in MIA. We first present the background of label-efficient learning and categorize the approaches into different schemes. Next, we examine the current state-of-the-art methods in detail through each scheme. Specifically, we provide an in-depth investigation, covering not only canonic
    
[^130]: ChatGPT的一致性分析

    Consistency Analysis of ChatGPT. (arXiv:2303.06273v1 [cs.CL])

    [http://arxiv.org/abs/2303.06273](http://arxiv.org/abs/2303.06273)

    本文研究了ChatGPT的一致性问题，发现尽管它具有更好的语言理解能力，但仍然经常无法生成逻辑上正确的预测。因此，在现实世界的应用需要进一步考虑，特别是在风险方面。

    This paper investigates the consistency issue of ChatGPT and finds that although it has improved language understanding ability, it frequently fails to generate logically correct predictions. Therefore, further consideration is needed for its real-world applications, especially in terms of risk.

    ChatGPT是一种基于大型语言模型的问答对话系统，自推出以来广受欢迎。虽然它在法律、医学和金融等领域的专业考试中取得了不错的成绩，但也有人对其可靠性和信任度表示怀疑。本文针对ChatGPT在逻辑一致性方面的可信度进行了调查研究。我们的研究发现，尽管ChatGPT似乎具有更好的语言理解能力，但它仍然经常无法生成逻辑上正确的预测。因此，虽然ChatGPT是一种令人印象深刻和有前途的新技术，但我们得出结论，如果没有经过彻底的人工检查，它在现实世界的应用需要进一步考虑，特别是在风险方面。

    ChatGPT, a question-and-answer dialogue system based on a large language model, has gained huge popularity since its introduction. Its positive aspects have been reported through many media platforms, and some analyses even showed that ChatGPT achieved a decent grade in professional exams, including the law, medical, and finance domains, adding extra support to the claim that AI now can assist and, even, replace humans in industrial fields. Others, however, doubt its reliability and trustworthiness. In this paper, we investigate ChatGPT's trustworthiness regarding logically consistent behaviours. Our findings suggest that, although ChatGPT seems to achieve an improved language understanding ability, it still fails to generate logically correct predictions frequently. Hence, while it is true that ChatGPT is an impressive and promising new technique, we conclude that its usage in real-world applications without thorough human inspection requires further consideration, especially for risk
    
[^131]: ChatGPT作为自然语言生成的评价指标可靠吗？初步研究。

    Is ChatGPT a Good NLG Evaluator? A Preliminary Study. (arXiv:2303.04048v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.04048](http://arxiv.org/abs/2303.04048)

    通过针对任务特定和方面特定，我们在五个NLG元评估数据集上进行实验，表明ChatGPT作为NLG评估指标并不总是与人类评估相一致，尤其是在流畅度方面。这提醒人们在使用ChatGPT作为唯一的自动NLG评估指标时要谨慎。

    

    最近，ChatGPT的出现引起了计算语言学界的广泛关注。许多先前的研究表明，ChatGPT在各种NLP任务中以自动评估指标为基础获得了显着的性能。然而，ChatGPT作为一种评估指标的能力尚未得到充分探索。考虑到评估自然语言生成（NLG）模型的质量是一项艰巨的任务，并且NLG指标以其糟糕的与人类判断的相关性而闻名，因此我们是否会认为ChatGPT是一个好的NLG评估指标。在这篇报告中，我们对ChatGPT进行了初步的元评估，展示了ChatGPT作为NLG指标的可靠性。具体而言，我们将ChatGPT视为人类评估器，并针对任务特定（例如摘要）和方面特定（例如相关性）进行说明，以促使ChatGPT评估NLG模型的生成结果。我们在包括摘要、故事生成和翻译在内的五个NLG元评估数据集上进行实验。我们的结果表明，对于某些方面（例如流畅度），ChatGPT并不总是与人类评估相一致。这提醒人们在使用ChatGPT作为唯一的自动NLG评估指标时要谨慎。

    Recently, the emergence of ChatGPT has attracted wide attention from the computational linguistics community. Many prior studies have shown that ChatGPT achieves remarkable performance on various NLP tasks in terms of automatic evaluation metrics. However, the ability of ChatGPT to serve as an evaluation metric is still underexplored. Considering assessing the quality of natural language generation (NLG) models is an arduous task and NLG metrics notoriously show their poor correlation with human judgments, we wonder whether ChatGPT is a good NLG evaluation metric. In this report, we provide a preliminary meta-evaluation on ChatGPT to show its reliability as an NLG metric. In detail, we regard ChatGPT as a human evaluator and give task-specific (e.g., summarization) and aspect-specific (e.g., relevance) instruction to prompt ChatGPT to evaluate the generated results of NLG models. We conduct experiments on five NLG meta-evaluation datasets (including summarization, story generation and 
    
[^132]: CoSyn：使用上下文协同的双曲线网络检测在线对话中的隐含仇恨言论

    CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a Context Synergized Hyperbolic Network. (arXiv:2303.03387v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.03387](http://arxiv.org/abs/2303.03387)

    CoSyn是一个上下文协同的神经网络，用于检测在线对话中的隐含仇恨言论。它通过引入新的编码方法和上下文交互机制，在双曲空间中进行操作，以适应社交媒体的特点。

    

    在线对话中隐含的仇恨言论对来自各个群体的人们产生了重要影响，因此社交媒体用户越来越多。大部分之前的研究都集中于检测明确的仇恨言论，这些言论明显且利用了仇恨短语，对于检测隐含或通过间接或编码语言表达出的仇恨言论的研究很少。在本文中，我们提出了CoSyn，一个上下文协同的神经网络，明确地结合了用户和对话上下文来检测在线对话中的隐含仇恨言论。CoSyn引入了新的方法来编码这些外部上下文，并采用了一种新颖的上下文交互机制，清晰地捕捉了它们之间的相互作用，独立评估了从这些嘈杂的上下文中检索的信息量。此外，它在双曲空间中进行所有这些操作，以适应社交媒体的无标度动态。

    The tremendous growth of social media users interacting in online conversations has led to significant growth in hate speech, affecting people from various demographics. Most of the prior works focus on detecting explicit hate speech, which is overt and leverages hateful phrases, with very little work focusing on detecting hate speech that is implicit or denotes hatred through indirect or coded language. In this paper, we present CoSyn, a context-synergized neural network that explicitly incorporates user- and conversational context for detecting implicit hate speech in online conversations. CoSyn introduces novel ways to encode these external contexts and employs a novel context interaction mechanism that clearly captures the interplay between them, making independent assessments of the amounts of information to be retrieved from these noisy contexts. Additionally, it carries out all these operations in the hyperbolic space to account for the scale-free dynamics of social media. We de
    
[^133]: 基于大语言模型的零样本跨语言摘要

    Zero-Shot Cross-Lingual Summarization via Large Language Models. (arXiv:2302.14229v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.14229](http://arxiv.org/abs/2302.14229)

    本文实验性地使用各种提示来指导大型语言模型从不同的范式执行零样本跨语言摘要，并成功提高了它们的CLS性能。其中，GPT-4实现了零样本CLS的最先进性能，并且在性能方面与最佳方法相当。

    

    给定一个源语言文本，跨语言摘要（CLS）旨在生成另一种目标语言的摘要。最近，大型语言模型（LLM）的出现，比如GPT-3.5、ChatGPT和GPT-4，引起了计算语言学界的广泛关注。然而，目前尚不清楚LLM在CLS上的表现如何。本文实验性地使用各种提示来指导LLM从不同的范式（即端到端和流水线）执行零样本CLS，并对生成的摘要进行初步评估。我们发现，ChatGPT和GPT-4原本更喜欢生成详细信息的长摘要。但这两个LLM在交互式提示的帮助下可以进一步平衡信息量和简洁性，显著提高它们的CLS性能。在三个广泛使用的CLS数据集上的实验结果表明，GPT-4实现了零样本CLS的最先进性能，并且在性能方面与最佳方法相当。

    Given a document in a source language, cross-lingual summarization (CLS) aims to generate a summary in a different target language. Recently, the emergence of Large Language Models (LLMs), such as GPT-3.5, ChatGPT and GPT-4, has attracted wide attention from the computational linguistics community. However, it is not yet known the performance of LLMs on CLS. In this report, we empirically use various prompts to guide LLMs to perform zero-shot CLS from different paradigms (i.e., end-to-end and pipeline), and provide a preliminary evaluation on the generated summaries. We find that ChatGPT and GPT-4 originally prefer to produce lengthy summaries with detailed information. These two LLMs can further balance informativeness and conciseness with the help of an interactive prompt, significantly improving their CLS performance. Experimental results on three widely-used CLS datasets show that GPT-4 achieves state-of-the-art zero-shot CLS performance, and performs competitively compared with th
    
[^134]: 重新思考半监督医学图像分割：方差缩减的视角

    Rethinking Semi-Supervised Medical Image Segmentation: A Variance-Reduction Perspective. (arXiv:2302.01735v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.01735](http://arxiv.org/abs/2302.01735)

    本文提出了ARCO，一种半监督对比学习（CL）框架，其中包括医学图像分割中的分层组采样理论。通过方差缩减估计的概念来构建ARCO，并表明某些方差缩减技术在医学图像分割中特别有益。

    This paper proposes ARCO, a semi-supervised contrastive learning (CL) framework with stratified group sampling theory in medical image segmentation. The concept of variance-reduced estimation is used to build ARCO, and certain variance-reduction techniques are shown to be particularly beneficial in medical image segmentation.

    对于医学图像分割，对比学习是提高视觉表示质量的主要方法，通过对比语义相似和不相似的样本对来实现。这是通过观察到，在没有访问地面真实标签的情况下，如果采样具有真正不同解剖特征的负样本，则可以显着提高性能。然而，在现实中，这些样本可能来自相似的解剖特征，模型可能难以区分少数尾类样本，使得尾类更容易被错误分类，这通常导致模型崩溃。在本文中，我们提出了ARCO，一种半监督对比学习（CL）框架，其中包括医学图像分割中的分层组采样理论。特别是，我们首先提出通过方差缩减估计的概念来构建ARCO，并表明某些方差缩减技术在医学图像分割中特别有益。

    For medical image segmentation, contrastive learning is the dominant practice to improve the quality of visual representations by contrasting semantically similar and dissimilar pairs of samples. This is enabled by the observation that without accessing ground truth label, negative examples with truly dissimilar anatomical features, if sampled, can significantly improve the performance. In reality, however, these samples may come from similar anatomical features and the models may struggle to distinguish the minority tail-class samples, making the tail classes more prone to misclassification, both of which typically lead to model collapse. In this paper, we propose ARCO, a semi-supervised contrastive learning (CL) framework with stratified group sampling theory in medical image segmentation. In particular, we first propose building ARCO through the concept of variance-reduced estimation, and show that certain variance-reduction techniques are particularly beneficial in medical image se
    
[^135]: 通过上下文修剪元学习学习大规模神经场

    Learning Large-scale Neural Fields via Context Pruned Meta-Learning. (arXiv:2302.00617v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00617](http://arxiv.org/abs/2302.00617)

    通过上下文修剪元学习实现大规模神经场训练的优化， 显著节省内存，并能在短时间内学习高质量神经场。

    

    我们通过自动在线上下文点选择实现了大规模神经场训练的高效优化元学习技术，从而实现显著的内存节省。通过将每个学习步骤集中在具有最高期望立即模型质量改进的数据子集上，实现全局结构的几乎即时建模和高频细节的后续细化。我们通过引入引导校正，进一步提高了元学习初始化的质量，从而实现了在减少上下文集时引入的任何误差的最小化，并同时缓解了基于优化的元学习所带来的短视问题。最后，我们展示了如何在元测试时进行梯度重新缩放，从而在显著缩短优化过程的同时学习极高质量的神经场。我们的框架与模型无关，直观易懂，易于实现，并表现出显著的重构能力。

    We introduce an efficient optimization-based meta-learning technique for large-scale neural field training by realizing significant memory savings through automated online context point selection. This is achieved by focusing each learning step on the subset of data with the highest expected immediate improvement in model quality, resulting in the almost instantaneous modeling of global structure and subsequent refinement of high-frequency details. We further improve the quality of our meta-learned initialization by introducing a bootstrap correction resulting in the minimization of any error introduced by reduced context sets while simultaneously mitigating the well-known myopia of optimization-based meta-learning. Finally, we show how gradient re-scaling at meta-test time allows the learning of extremely high-quality neural fields in significantly shortened optimization procedures. Our framework is model-agnostic, intuitive, straightforward to implement, and shows significant reconst
    
[^136]: 批量提示：使用大型语言模型API进行高效推断

    Batch Prompting: Efficient Inference with Large Language Model APIs. (arXiv:2301.08721v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.08721](http://arxiv.org/abs/2301.08721)

    批量提示是一种简单但有效的方法，可以降低使用大型语言模型进行推断的计算和财务成本，同时保持下游性能。理论上证明，在少样本情况下，批量样本数量的增加几乎以倒数线性关系降低了推断成本。在多个数据集上的验证实验证明了批量提示的有效性，并且对于最先进的Chat-based LLMs，如GPT-3.5和GPT-4，批量提示也具有好处。

    

    在工业和实际应用中，使用大型语言模型（LLM）进行大量样本的推断可能会在计算和财务上代价高昂。我们提出了批量提示的简单而有效的提示方法，使LLM能够批量进行推断，而不是逐个样本。我们的方法减少了令牌和时间成本，同时保持了下游性能。我们从理论上证明，在少样本上下文学习的情况下，随着每批样本数量的增加，推断成本几乎以倒数线性关系降低。我们在常识问答、算术推理和NLI/NLU等十个数据集上广泛验证了批量提示的有效性：批量提示显著（每批六个样本时最高可减少5倍）降低了LLM（Codex）的推断令牌和时间成本，同时实现了更好或可比较的性能。对于最先进的基于聊天的LLM，例如GPT-3.5和GPT-4，我们还展示了批量提示的好处。

    Performing inference on large volumes of samples with large language models (LLMs) can be computationally and financially costly in industry and real-world use. We propose batch prompting, a simple yet effective prompting approach that enables the LLM to run inference in batches, instead of one sample at a time. Our method reduces both token and time costs while retaining downstream performance. We theoretically demonstrate that under a few-shot in-context learning setting, the inference costs decrease almost inverse linearly with the number of samples in each batch. We extensively validate the effectiveness of batch prompting on ten datasets across commonsense QA, arithmetic reasoning, and NLI/NLU: batch prompting significantly~(up to 5x with six samples in batch) reduces the LLM (Codex) inference token and time costs while achieving better or comparable performance. For state-of-the-art Chat-based LLMs, e.g., GPT-3.5 and GPT-4, we show the benefits of batch prompting also hold. Furth
    
[^137]: 关于卷积神经网络中最大池化特征图的位移不变性

    On the Shift Invariance of Max Pooling Feature Maps in Convolutional Neural Networks. (arXiv:2209.11740v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.11740](http://arxiv.org/abs/2209.11740)

    本文研究了卷积神经网络中最大池化特征图的位移不变性问题，并提出了一种近似复数模的条件，实现了位移稳定性。实验证实了理论的有效性。

    

    本文致力于改善卷积神经网络（CNN）在图像分类领域中的数学可解释性。具体而言，我们解决了在其第一层中出现的不稳定性问题。当在像ImageNet这样的数据集上进行训练时，其第一层往往学习到与方向边通滤波器非常相似的参数。使用这样的Gabor滤波器进行子采样卷积容易出现混叠问题，导致对输入的小偏移敏感。在这个背景下，我们建立了最大池化算子近似复数模的条件，使其几乎具有位移不变性。然后，我们推导了子采样卷积后最大池化的位移稳定性度量。特别地，我们强调了滤波器的频率和方向在实现稳定性方面的关键作用。通过考虑基于双树复小波包变换的确定性特征提取器，即离散Gabor的一种特殊情况，我们通过实验证实了我们的理论。

    This paper focuses on improving the mathematical interpretability of convolutional neural networks (CNNs) in the context of image classification. Specifically, we tackle the instability issue arising in their first layer, which tends to learn parameters that closely resemble oriented band-pass filters when trained on datasets like ImageNet. Subsampled convolutions with such Gabor-like filters are prone to aliasing, causing sensitivity to small input shifts. In this context, we establish conditions under which the max pooling operator approximates a complex modulus, which is nearly shift invariant. We then derive a measure of shift invariance for subsampled convolutions followed by max pooling. In particular, we highlight the crucial role played by the filter's frequency and orientation in achieving stability. We experimentally validate our theory by considering a deterministic feature extractor based on the dual-tree complex wavelet packet transform, a particular case of discrete Gabor
    
[^138]: DenseShift: 实现准确和高效的低位幂乘法的量化

    DenseShift: Towards Accurate and Efficient Low-Bit Power-of-Two Quantization. (arXiv:2208.09708v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2208.09708](http://arxiv.org/abs/2208.09708)

    DenseShift网络是一种准确和高效的低位幂乘法量化方法，通过改进Shift网络的精度和引入非量化浮点激活来提高性能。

    

    在低资源边缘设备上高效部署深度神经网络是具有挑战性的，因为其不断增加的资源需求。为了解决这个问题，研究人员提出了无乘法神经网络，如幂乘法的量化，也被称为Shift网络，旨在减少内存使用和简化计算。然而，现有的低位Shift网络不如全精度网络准确，通常受到有限权重范围编码方案和量化损失的影响。在本文中，我们提出了DenseShift网络，显著提高了Shift网络的准确性，为视觉和语音应用实现了与全精度网络相媲美的性能。此外，我们引入了一种使用非量化浮点激活的高效DenseShift网络部署方法，同时获得了现有方法的1.6倍加速。为了实现这一点，我们证明了低位Shift网络中零权重值的作用。

    Efficiently deploying deep neural networks on low-resource edge devices is challenging due to their ever-increasing resource requirements. To address this issue, researchers have proposed multiplication-free neural networks, such as Power-of-Two quantization, or also known as Shift networks, which aim to reduce memory usage and simplify computation. However, existing low-bit Shift networks are not as accurate as their full-precision counterparts, typically suffering from limited weight range encoding schemes and quantization loss. In this paper, we propose the DenseShift network, which significantly improves the accuracy of Shift networks, achieving competitive performance to full-precision networks for vision and speech applications. In addition, we introduce a method to deploy an efficient DenseShift network using non-quantized floating-point activations, while obtaining 1.6X speed-up over existing methods. To achieve this, we demonstrate that zero-weight values in low-bit Shift netw
    
[^139]: 无监督视频领域自适应动作识别：一个解缠视角

    Unsupervised Video Domain Adaptation for Action Recognition: A Disentanglement Perspective. (arXiv:2208.07365v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2208.07365](http://arxiv.org/abs/2208.07365)

    本文基于解缠视角处理视频领域无监督自适应问题，通过逐步解缠静态和动态信息并使用多种约束方法，有效地移除空间领域特定信息和减少时间领域差异，实验结果验证了该方法的有效性和优越性。

    

    无监督视频领域自适应是一项实践性而又具有挑战性的任务。本文首次从解缠视角入手处理该问题。我们的主要思路是通过解缠来分别处理空间和时间领域的差异。具体而言，我们考虑从包含静态信息的一组潜在因素和包含动态信息的另一组潜在因素中生成跨领域视频。我们开发了一个转移时序VAE（TranSVAE）框架来建模这种生成过程。为了更好地进行自适应，我们提出了几个约束潜在因素的目标。通过这些约束，静态领域特定信息的解缠可以轻松移除，通过对抗性学习从帧和视频层面进一步减少了时间差异。在UCF-HMDB、Jester和Epic-Kitchens数据集上进行的广泛实验验证了TranSVAE相比其他方法的有效性和优越性。

    Unsupervised video domain adaptation is a practical yet challenging task. In this work, for the first time, we tackle it from a disentanglement view. Our key idea is to handle the spatial and temporal domain divergence separately through disentanglement. Specifically, we consider the generation of cross-domain videos from two sets of latent factors, one encoding the static information and another encoding the dynamic information. A Transfer Sequential VAE (TranSVAE) framework is then developed to model such generation. To better serve for adaptation, we propose several objectives to constrain the latent factors. With these constraints, the spatial divergence can be readily removed by disentangling the static domain-specific information out, and the temporal divergence is further reduced from both frame- and video-levels through adversarial learning. Extensive experiments on the UCF-HMDB, Jester, and Epic-Kitchens datasets verify the effectiveness and superiority of TranSVAE compared wi
    
[^140]: 动态变分轨迹模型中的心脏超声异常检测

    Anomaly Detection in Echocardiograms with Dynamic Variational Trajectory Models. (arXiv:2206.15316v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.15316](http://arxiv.org/abs/2206.15316)

    本文提出了一种用于心脏超声视频的新颖异常检测方法，利用心脏周期性特性，在婴儿心脏超声视频数据集上训练了三种变分潜在轨迹模型，可可靠地识别严重的先天性心脏缺陷，并取得了较好的性能。

    

    我们提出了一种用于心脏超声视频的新颖异常检测方法。该方法利用心脏周期性的特性，学习三种变分潜在轨迹模型（TVAE）的变体。其中前两种变体（TVAE-C和TVAE-R）模拟心脏的严格周期性运动，而第三种变体（TVAE-S）更为通用，允许视频中空间表示的移位。所有模型都在一个新的内部婴儿心脏超声视频数据集的健康样本上进行训练，以学习健康人群的规范先验知识。在推断过程中，我们使用基于最大后验概率（MAP）的异常检测来检测数据集中的离群样本。所提出的方法可可靠地识别严重的先天性心脏缺陷，如埃普斯坦异常或Shone综合征。此外，相比于基于标准变分自动编码器的MAP-based异常检测，它实现了更优异的性能。

    We propose a novel anomaly detection method for echocardiogram videos. The introduced method takes advantage of the periodic nature of the heart cycle to learn three variants of a variational latent trajectory model (TVAE). While the first two variants (TVAE-C and TVAE-R) model strict periodic movements of the heart, the third (TVAE-S) is more general and allows shifts in the spatial representation throughout the video. All models are trained on the healthy samples of a novel in-house dataset of infant echocardiogram videos consisting of multiple chamber views to learn a normative prior of the healthy population. During inference, maximum a posteriori (MAP) based anomaly detection is performed to detect out-of-distribution samples in our dataset. The proposed method reliably identifies severe congenital heart defects, such as Ebstein's Anomaly or Shone-complex. Moreover, it achieves superior performance over MAP-based anomaly detection with standard variational autoencoders when detect
    
[^141]: JAMES: 基于多方面图嵌入和推理的岗位职称规范化

    JAMES: Normalizing Job Titles with Multi-Aspect Graph Embeddings and Reasoning. (arXiv:2202.10739v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2202.10739](http://arxiv.org/abs/2202.10739)

    JAMES是一个用于岗位职称规范化的解决方案，它通过构建三种独特嵌入和使用协同注意机制和神经逻辑推理表示来有效地捕捉岗位职称的各种特征，并解决了语义相似性、非规范化用户创建的职称以及实际应用中大规模和长尾分布的岗位职称等挑战。

    

    在在线职位市场中，建立一个明确定义的岗位职称分类体系对于各种下游任务（如工作推荐、用户职业分析和离职预测）至关重要。岗位职称规范化是将用户创建的非标准岗位职称分类为规范化职称的一个清洁步骤。然而，解决岗位职称规范化问题并不容易，面临着以下挑战：(1)不同岗位职称的语义相似性，(2)非规范化的用户创建的岗位职称，以及(3)实际应用中大规模和长尾分布的岗位职称。为了解决这个问题，我们提出了一种名为JAMES的新颖解决方案，它构建目标岗位职称的三种独特嵌入（即图、上下文和句法），以有效捕捉其各种特征。我们进一步提出了一种多方面协同注意机制来注意地结合这些嵌入，还使用神经逻辑推理表示共同估计混乱的岗位职称与规范化岗位职称之间的相似性。

    In online job marketplaces, it is important to establish a well-defined job title taxonomy for various downstream tasks (e.g., job recommendation, users' career analysis, and turnover prediction). Job Title Normalization (JTN) is such a cleaning step to classify user-created non-standard job titles into normalized ones. However, solving the JTN problem is non-trivial with challenges: (1) semantic similarity of different job titles, (2) non-normalized user-created job titles, and (3) large-scale and long-tailed job titles in real-world applications. To this end, we propose a novel solution, named JAMES, that constructs three unique embeddings (i.e., graph, contextual, and syntactic) of a target job title to effectively capture its various traits. We further propose a multi-aspect co-attention mechanism to attentively combine these embeddings, and employ neural logical reasoning representations to collaboratively estimate similarities between messy job titles and normalized job titles in
    
[^142]: HEAM: 高效近似乘法器优化的深度神经网络

    HEAM: High-Efficiency Approximate Multiplier Optimization for Deep Neural Networks. (arXiv:2201.08022v4 [cs.AR] UPDATED)

    [http://arxiv.org/abs/2201.08022](http://arxiv.org/abs/2201.08022)

    本文提出了一种优化方法，用于自动设计近似乘法器，并根据操作数分布来最小化平均误差。所提乘法器在DNN中达到了比最佳复制的近似乘法器高达50.24%的准确性，同时具有较小的面积、功耗和延迟。

    

    我们提出了一种自动设计近似乘法器的优化方法，根据操作数分布最小化平均误差。我们的乘法器在DNN中比最佳复制的近似乘法器高达50.24%的准确性，同时面积减小15.76%，功耗减少25.05%，延迟缩短3.50%。与精确乘法器相比，我们的乘法器分别减少了44.94%的面积、47.63%的功耗和16.78%的延迟，几乎没有准确性损失。使用我们的乘法器进行测试的DNN加速器模块比原始模块面积减小了18.70%，功耗减少了9.99%。

    We propose an optimization method for the automatic design of approximate multipliers, which minimizes the average error according to the operand distributions. Our multiplier achieves up to 50.24% higher accuracy than the best reproduced approximate multiplier in DNNs, with 15.76% smaller area, 25.05% less power consumption, and 3.50% shorter delay. Compared with an exact multiplier, our multiplier reduces the area, power consumption, and delay by 44.94%, 47.63%, and 16.78%, respectively, with negligible accuracy losses. The tested DNN accelerator modules with our multiplier obtain up to 18.70% smaller area and 9.99% less power consumption than the original modules.
    
[^143]: 最简易的流式决策树

    Simplest Streaming Trees. (arXiv:2110.08483v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.08483](http://arxiv.org/abs/2110.08483)

    我们提出了最简单的决策树扩展，通过继续生长现有树来更新它们，并用新树替换一些旧树来控制总树的数量。在72个分类问题的基准套件中，我们的方法在精度和内存使用方面表现优异。

    

    决策森林，包括随机森林和梯度提升树，在许多实际数据问题上仍然是主流的机器学习方法，特别是在表格数据上。然而，大部分当前的实现只能以批处理模式运行，因此不能在有更多数据到达时进行增量更新。之前有几项工作开发了流式决策树和集成来克服这个限制。然而，我们发现这些最新算法存在一些问题，包括在某些问题上精度低和在其他问题上内存使用量大。因此，我们开发了最简单的决策树扩展：给定新数据时，通过继续生长现有树来更新它们，并用新树替换一些旧树来控制总树的数量。在包含72个分类问题的基准套件（OpenML-CC18数据套件）中，我们证明了我们的方法Stream Decision Forest（SDF）既不遭受上述问题的困扰

    Decision forests, including random forests and gradient boosting trees, remain the leading machine learning methods for many real-world data problems, especially on tabular data. However, most of the current implementations only operate in batch mode, and therefore cannot incrementally update when more data arrive. Several previous works developed streaming trees and ensembles to overcome this limitation. Nonetheless, we found that those state-of-the-art algorithms suffer from a number of drawbacks, including low accuracy on some problems and high memory usage on others. We therefore developed the simplest possible extension of decision trees: given new data, simply update existing trees by continuing to grow them, and replace some old trees with new ones to control the total number of trees. In a benchmark suite containing 72 classification problems (the OpenML-CC18 data suite), we illustrate that our approach, Stream Decision Forest (SDF), does not suffer from either of the aforement
    
[^144]: Bellman一致的悲观论述用于离线强化学习

    Bellman-consistent Pessimism for Offline Reinforcement Learning. (arXiv:2106.06926v6 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.06926](http://arxiv.org/abs/2106.06926)

    本文提出了Bellman一致的悲观论述的概念，用于离线强化学习中的函数逼近，通过在与Bellman方程一致的函数集合上实施初始状态的悲观主义，改善了基于奖励的悲观主义方法的样本复杂性。

    

    最近在离线强化学习中，当推理数据集缺乏详尽探索时，使用悲观主义获得了显著的重要性。尽管悲观主义增加了算法的鲁棒性，但过度悲观的推理同样会阻碍发现良好策略，这对于流行的基于奖励的悲观主义是一个问题。在本文中，我们引入了Bellman一致的悲观主义的概念，用于一般函数逼近：我们不是计算值函数的逐点下界，而是在与Bellman方程一致的函数集合上实施初始状态上的悲观主义。我们的理论保证仅需要标准的Bellman封闭性作为探索性设置中的要求，在这种情况下，基于奖励的悲观主义无法提供保证。即使在线性函数逼近的特殊情况下，更强的表现力假设成立时，我们的结果在样本复杂性上优于最近的基于奖励的方法，复杂性改善了Ο(d)。

    The use of pessimism, when reasoning about datasets lacking exhaustive exploration has recently gained prominence in offline reinforcement learning. Despite the robustness it adds to the algorithm, overly pessimistic reasoning can be equally damaging in precluding the discovery of good policies, which is an issue for the popular bonus-based pessimism. In this paper, we introduce the notion of Bellman-consistent pessimism for general function approximation: instead of calculating a point-wise lower bound for the value function, we implement pessimism at the initial state over the set of functions consistent with the Bellman equations. Our theoretical guarantees only require Bellman closedness as standard in the exploratory setting, in which case bonus-based pessimism fails to provide guarantees. Even in the special case of linear function approximation where stronger expressivity assumptions hold, our result improves upon a recent bonus-based approach by $\mathcal{O}(d)$ in its sample c
    
[^145]: ELHr描述逻辑中的溯源问题

    Provenance for the Description Logic ELHr. (arXiv:2001.07541v3 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2001.07541](http://arxiv.org/abs/2001.07541)

    本文研究了ELHr描述逻辑中处理溯源信息的问题，通过使用溯源标记、溯源多项式以及假设半环具有乘法幂等性来解决合取操作带来的困难。我们分析了ELHr的语义，并研究了带溯源的本体补全、计算与后果相关的公理集合和查询回答三个问题。

    

    本文解决了处理ELHr本体中的溯源信息的问题。我们考虑了最近在基于本体的数据访问中引入的一个设置，该设置基于半环并扩展了经典数据溯源，在该设置中，本体公理附有溯源标记。后果会继承衍生它的公理的溯源，产生一个溯源多项式作为注释。我们分析了ELHr情况下的语义，并展示了合取操作对处理溯源提出了各种困难，其中一些困难可以通过假设半环具有乘法幂等性来减轻。在这个假设下，我们研究了三个问题：带有溯源的本体补全、计算与后果相关的公理集合以及查询回答。

    We address the problem of handling provenance information in ELHr ontologies. We consider a setting recently introduced for ontology-based data access, based on semirings and extending classical data provenance, in which ontology axioms are annotated with provenance tokens. A consequence inherits the provenance of the axioms involved in deriving it, yielding a provenance polynomial as an annotation. We analyse the semantics for the ELHr case and show that the presence of conjunctions poses various difficulties for handling provenance, some of which are mitigated by assuming multiplicative idempotency of the semiring. Under this assumption, we study three problems: ontology completion with provenance, computing the set of relevant axioms for a consequence, and query answering.
    

